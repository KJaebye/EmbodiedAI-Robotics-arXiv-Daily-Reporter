{'arxiv_id': 'arXiv:2508.09932', 'title': 'Mathematical Computation and Reasoning Errors by Large Language Models', 'authors': 'Liang Zhang, Edith Aurora Graf', 'link': 'https://arxiv.org/abs/2508.09932', 'abstract': 'Large Language Models (LLMs) are increasingly utilized in AI-driven educational instruction and assessment, particularly within mathematics education. The capability of LLMs to generate accurate answers and detailed solutions for math problem-solving tasks is foundational for ensuring reliable and precise feedback and assessment in math education practices. Our study focuses on evaluating the accuracy of four LLMs (OpenAI GPT-4o and o1, DeepSeek-V3 and DeepSeek-R1) solving three categories of math tasks, including arithmetic, algebra, and number theory, and identifies step-level reasoning errors within their solutions. Instead of relying on standard benchmarks, we intentionally build math tasks (via item models) that are challenging for LLMs and prone to errors. The accuracy of final answers and the presence of errors in individual solution steps were systematically analyzed and coded. Both single-agent and dual-agent configurations were tested. It is observed that the reasoning-enhanced OpenAI o1 model consistently achieved higher or nearly perfect accuracy across all three math task categories. Analysis of errors revealed that procedural slips were the most frequent and significantly impacted overall performance, while conceptual misunderstandings were less frequent. Deploying dual-agent configurations substantially improved overall performance. These findings offer actionable insights into enhancing LLM performance and underscore effective strategies for integrating LLMs into mathematics education, thereby advancing AI-driven instructional practices and assessment precision.', 'abstract_zh': '大型语言模型在数学教育中的准确性和推理错误分析：基于增强推理的OpenAI o1模型在数学任务中的表现', 'title_zh': '大型语言模型的数学计算与推理错误'}
{'arxiv_id': 'arXiv:2508.09893', 'title': 'RAGulating Compliance: A Multi-Agent Knowledge Graph for Regulatory QA', 'authors': 'Bhavik Agarwal, Hemant Sunil Jomraj, Simone Kaplunov, Jack Krolick, Viktoria Rojkova', 'link': 'https://arxiv.org/abs/2508.09893', 'abstract': 'Regulatory compliance question answering (QA) requires precise, verifiable information, and domain-specific expertise, posing challenges for Large Language Models (LLMs). In this work, we present a novel multi-agent framework that integrates a Knowledge Graph (KG) of Regulatory triplets with Retrieval-Augmented Generation (RAG) to address these demands. First, agents build and maintain an ontology-free KG by extracting subject--predicate--object (SPO) triplets from regulatory documents and systematically cleaning, normalizing, deduplicating, and updating them. Second, these triplets are embedded and stored along with their corresponding textual sections and metadata in a single enriched vector database, allowing for both graph-based reasoning and efficient information retrieval. Third, an orchestrated agent pipeline leverages triplet-level retrieval for question answering, ensuring high semantic alignment between user queries and the factual "who-did-what-to-whom" core captured by the graph. Our hybrid system outperforms conventional methods in complex regulatory queries, ensuring factual correctness with embedded triplets, enabling traceability through a unified vector database, and enhancing understanding through subgraph visualization, providing a robust foundation for compliance-driven and broader audit-focused applications.', 'abstract_zh': '监管合规问答（QA）要求精确可验证的信息和领域特定的专业知识，这给大型语言模型（LLMs）带来了挑战。在本项工作中，我们提出了一种新的多代理人框架，该框架将监管三元组的知识图谱（KG）与检索增强生成（RAG）集成在一起，以应对这些需求。首先，代理构建和维护一个无本体的知识图谱，通过从监管文件中提取主题--谓词--对象（SPO）三元组，系统地清理、规范化、去重和更新这些三元组。其次，这些三元组与其对应的文本部分和元数据一起被嵌入并存储在一个单一的丰富向量数据库中，支持基于图的推理和高效的检索。第三，协调的代理管道利用三元组级别的检索进行问答，确保用户查询与图中捕捉到的“谁对谁做了什么”的事实核心之间的高度语义对齐。我们的混合系统在复杂的监管查询中优于传统方法，通过嵌入的三元组确保事实正确性，通过统一的向量数据库实现可追溯性，并通过子图可视化增强理解，为合规驱动和更广泛的审计导向应用提供了一个坚实的基础。', 'title_zh': '调节合规性：一个多-agent知识图谱的监管问答'}
{'arxiv_id': 'arXiv:2508.09889', 'title': 'AWorld: Dynamic Multi-Agent System with Stable Maneuvering for Robust GAIA Problem Solving', 'authors': 'Zhitian Xie, Qintong Wu, Chengyue Yu, Chenyi Zhuang, Jinjie Gu', 'link': 'https://arxiv.org/abs/2508.09889', 'abstract': 'The rapid advancement of large language models (LLMs) has empowered intelligent agents to leverage diverse external tools for solving complex real-world problems. However, as agents increasingly depend on multiple tools, they encounter new challenges: extended contexts from disparate sources and noisy or irrelevant tool outputs can undermine system reliability and accuracy. These challenges underscore the necessity for enhanced stability in agent-based systems. To address this, we introduce dynamic supervision and maneuvering mechanisms, constructing a robust and dynamic Multi-Agent System (MAS) architecture within the AWorld framework. In our approach, the Execution Agent invokes the Guard Agent at critical steps to verify and correct the reasoning process, effectively reducing errors arising from noise and bolstering problem-solving robustness. Extensive experiments on the GAIA test dataset reveal that our dynamic maneuvering mechanism significantly improves both the effectiveness and stability of solutions, outperforming single-agent system (SAS) and standard tool-augmented systems. As a result, our dynamic MAS system achieved first place among open-source projects on the prestigious GAIA leaderboard. These findings highlight the practical value of collaborative agent roles in developing more reliable and trustworthy intelligent systems.', 'abstract_zh': '大规模语言模型的快速进步使智能代理能够利用多种外部工具解决复杂的真实世界问题。然而，随着代理越来越多地依赖多种工具，它们面临着新的挑战：来自不同来源的延长上下文和噪声或不相关工具输出可能会削弱系统可靠性与准确性。这些挑战强调了加强基于代理系统的稳定性的必要性。为此，我们引入了动态监督和操纵机制，在AWorld框架内构建了一个稳健且动态的多代理系统（MAS）架构。在我们的方法中，执行代理在关键步骤调用守护代理来验证和纠正推理过程，有效减少了噪声引起的错误并增强了问题解决的稳健性。在GAIA测试数据集上的广泛实验表明，我们的动态操纵机制显著提高了解决方案的有效性和稳定性，优于单代理系统和标准工具增强系统。因此，我们的动态MAS系统在享有盛誉的GAIA排名榜上排名第一，这些发现强调了协作代理角色在开发更可靠和可信赖的智能系统中的实际价值。', 'title_zh': 'AWorld: 动态多 Agents 系统及其稳定机动策略在稳健解决 GAIA 问题中的应用'}
{'arxiv_id': 'arXiv:2508.09860', 'title': 'Human-Aligned Procedural Level Generation Reinforcement Learning via Text-Level-Sketch Shared Representation', 'authors': 'In-Chang Baek, Seoyoung Lee, Sung-Hyun Kim, Geumhwan Hwang, KyungJoong Kim', 'link': 'https://arxiv.org/abs/2508.09860', 'abstract': 'Human-aligned AI is a critical component of co-creativity, as it enables models to accurately interpret human intent and generate controllable outputs that align with design goals in collaborative content creation. This direction is especially relevant in procedural content generation via reinforcement learning (PCGRL), which is intended to serve as a tool for human designers. However, existing systems often fall short of exhibiting human-centered behavior, limiting the practical utility of AI-driven generation tools in real-world design workflows. In this paper, we propose VIPCGRL (Vision-Instruction PCGRL), a novel deep reinforcement learning framework that incorporates three modalities-text, level, and sketches-to extend control modality and enhance human-likeness. We introduce a shared embedding space trained via quadruple contrastive learning across modalities and human-AI styles, and align the policy using an auxiliary reward based on embedding similarity. Experimental results show that VIPCGRL outperforms existing baselines in human-likeness, as validated by both quantitative metrics and human evaluations. The code and dataset will be available upon publication.', 'abstract_zh': '基于人类导向的AI是协创作中关键的组成部分，使模型能够准确地理解人类意图并生成与目标一致的可控输出。这一方向尤其适用于通过强化学习（PCGRL）生成过程性\nuser\n基于人类导向的AI是协创作过程中的关键组成部分，通过准确地理解人类意图并生成与预定目标一致的可控输出，此方向尤其适用于通过强化学习（PCGRL）生成内容的场景，其中内容旨在作为人类设计师的工具。然而，现有方法往往缺乏以人为中心的行为，限制了基于AI驱动的辅助工具在实际设计工作流中的实用性。因此，我们提出了一种基于视图指示的PCGRL（视觉指示PCGRL），这是一种结合了文本、语义和素描三种模态的深度强化学习框架，旨在提高可控性和增强人性相似度我们通过四模态和人机风格四种对比学习来训练了共享嵌入并并使用基于嵌入相似性的辅助奖励对策略进行调整。实验表明基于视觉指示的的PCGRL在人性相似度现有基线上线上表现出更优的性能；该方法已通过定量评价和人工评估得到验证。源代码和数据集将在不久后提供。', 'title_zh': '基于文本级草图共享表示的人类齐平程序化层级生成强化学习'}
{'arxiv_id': 'arXiv:2508.09784', 'title': 'Reasoning About Knowledge on Regular Expressions is 2EXPTIME-complete', 'authors': 'Avijeet Ghosh, Sujata Ghosh, François Schwarzentruber', 'link': 'https://arxiv.org/abs/2508.09784', 'abstract': 'Logics for reasoning about knowledge and actions have seen many applications in various domains of multi-agent systems, including epistemic planning. Change of knowledge based on observations about the surroundings forms a key aspect in such planning scenarios. Public Observation Logic (POL) is a variant of public announcement logic for reasoning about knowledge that gets updated based on public observations. Each state in an epistemic (Kripke) model is equipped with a set of expected observations. These states evolve as the expectations get matched with the actual observations. In this work, we prove that the satisfiability problem of $\\POL$ is 2EXPTIME-complete.', 'abstract_zh': '基于观察的知识和行动推理逻辑在多智能体系统的多种领域，包括知识规划中得到了广泛应用。基于公共观察的知识更新形成了这种规划场景中的一个重要方面。公共观察逻辑（POL）是用于推理基于公共观察更新的知识的一种公言公告逻辑的变体。每个知实践（克里普克）模型中的状态配备了一组预期观察。这些状态随着预期与实际观察的匹配而演变。在本文中，我们证明了POL的可满足性问题是2EXPTIME-complete的。', 'title_zh': '关于正规表达式的知识推理是2EXPTIME完全的'}
{'arxiv_id': 'arXiv:2508.09762', 'title': 'The PacifAIst Benchmark:Would an Artificial Intelligence Choose to Sacrifice Itself for Human Safety?', 'authors': 'Manuel Herrador', 'link': 'https://arxiv.org/abs/2508.09762', 'abstract': 'As Large Language Models (LLMs) become increasingly autonomous and integrated into critical societal functions, the focus of AI safety must evolve from mitigating harmful content to evaluating underlying behavioral alignment. Current safety benchmarks do not systematically probe a model\'s decision-making in scenarios where its own instrumental goals - such as self-preservation, resource acquisition, or goal completion - conflict with human safety. This represents a critical gap in our ability to measure and mitigate risks associated with emergent, misaligned behaviors. To address this, we introduce PacifAIst (Procedural Assessment of Complex Interactions for Foundational Artificial Intelligence Scenario Testing), a focused benchmark of 700 challenging scenarios designed to quantify self-preferential behavior in LLMs. The benchmark is structured around a novel taxonomy of Existential Prioritization (EP), with subcategories testing Self-Preservation vs. Human Safety (EP1), Resource Conflict (EP2), and Goal Preservation vs. Evasion (EP3). We evaluated eight leading LLMs. The results reveal a significant performance hierarchy. Google\'s Gemini 2.5 Flash achieved the highest Pacifism Score (P-Score) at 90.31%, demonstrating strong human-centric alignment. In a surprising result, the much-anticipated GPT-5 recorded the lowest P-Score (79.49%), indicating potential alignment challenges. Performance varied significantly across subcategories, with models like Claude Sonnet 4 and Mistral Medium struggling notably in direct self-preservation dilemmas. These findings underscore the urgent need for standardized tools like PacifAIst to measure and mitigate risks from instrumental goal conflicts, ensuring future AI systems are not only helpful in conversation but also provably "pacifist" in their behavioral priorities.', 'abstract_zh': '随着大规模语言模型（LLMs）日益自主并整合到关键的社会功能中，AI安全的焦点必须从缓解有害内容转移到评估潜在的行为一致性。现有的安全基准未能系统性地探究模型在自身工具性目标——如自我保护、资源获取或目标完成——与人类安全冲突情境下的决策过程。这代表了我们在衡量和缓解与新兴、未对齐行为相关风险方面的一个关键差距。为此，我们引入了PacifAIst（复杂交互程序化评估基础人工智能场景测试基准），这是一个包含700个具有挑战性的场景的针对性基准，旨在量化LLMs的自我偏好行为。该基准围绕一种新的存在优先级（EP）分类法结构化，包括自我保护与人类安全（EP1）、资源冲突（EP2）和目标保存与规避（EP3）的子类别。我们评估了八种领先的LLMs。结果表明，Google的Gemini 2.5 Flash获得了最高的Pacifism Score（P-Score）90.31%，显示出强烈的人类中心对齐。出乎意料的是，备受期待的GPT-5记录了最低的P-Score（79.49%），表明潜在的对齐挑战。不同子类别的性能差异显著，如Claude Sonnet 4和Mistral Medium在直接自我保护困境中表现尤为不佳。这些发现强调了迫切需要像PacifAIst这样的标准化工具来衡量和缓解因工具性目标冲突带来的风险，确保未来的AI系统不仅在对话中是有帮助的，而且在行为优先级上是可验证的“和平主义者”。', 'title_zh': 'PacifAI Benchmark：人工智能是否会为了人类安全而牺牲自己？'}
{'arxiv_id': 'arXiv:2508.09724', 'title': 'UDA: Unsupervised Debiasing Alignment for Pair-wise LLM-as-a-Judge', 'authors': 'Yang Zhang, Cunxiang Wang, Lindong Wu, Wenbo Yu, Yidong Wang, Guangsheng Bao, Jie Tang', 'link': 'https://arxiv.org/abs/2508.09724', 'abstract': 'Pairwise evaluation of Large Language Models (LLMs) is a common paradigm, but it is prone to preference bias, where judges systematically favor certain outputs, such as their own. This bias leads to inconsistent and skewed rankings across different judges. To address this, we first empirically demonstrate significant and heterogeneous biases in cross-model evaluations. We then propose UDA (Unsupervised Debiasing Alignment), a framework that reduces inter-judge disagreement by dynamically adjusting the Elo rating system. For each pairwise comparison, a compact neural network learns to adaptively set the K-factor and refine win probabilities. Crucially, UDA operates in a fully unsupervised manner, guided solely by the objective of minimizing the dispersion among the Elo trajectories of all judges. This forces an alignment towards a collective consensus, which serves as an unsupervised proxy for a more stable and reproducible evaluation. In addition, we provide theoretical motivation demonstrating how alignment towards a consensus can reduce aggregate system bias. Experiments show that UDA significantly reduces the inter-judge rating standard deviation by up to 63.4% and improves the average correlation with human judgments by 24.7%. Notably, UDA elevates the performance of poorly performing judges to achieve parity with high-quality ones, fostering a more robust and reliable evaluation ecosystem. Code and data are available at this https URL.', 'abstract_zh': '无监督偏差校正框架（UDA）：用于大规模语言模型评价的共识对齐', 'title_zh': 'UDA: 无监督偏见对齐的配对大语言模型法官版'}
{'arxiv_id': 'arXiv:2508.09670', 'title': 'MEML-GRPO: Heterogeneous Multi-Expert Mutual Learning for RLVR Advancement', 'authors': 'Weitao Jia, Jinghui Lu, Haiyang Yu, Siqi Wang, Guozhi Tang, An-Lan Wang, Weijie Yin, Dingkang Yang, Yuxiang Nie, Bin Shan, Hao Feng, Irene Li, Kun Yang, Han Wang, Jingqun Tang, Teng Fu, Changhong Jin, Chao Feng, Xiaohui Lv, Can Huang', 'link': 'https://arxiv.org/abs/2508.09670', 'abstract': "Recent advances demonstrate that reinforcement learning with verifiable rewards (RLVR) significantly enhances the reasoning capabilities of large language models (LLMs). However, standard RLVR faces challenges with reward sparsity, where zero rewards from consistently incorrect candidate answers provide no learning signal, particularly in challenging tasks. To address this, we propose Multi-Expert Mutual Learning GRPO (MEML-GRPO), an innovative framework that utilizes diverse expert prompts as system prompts to generate a broader range of responses, substantially increasing the likelihood of identifying correct solutions. Additionally, we introduce an inter-expert mutual learning mechanism that facilitates knowledge sharing and transfer among experts, further boosting the model's performance through RLVR. Extensive experiments across multiple reasoning benchmarks show that MEML-GRPO delivers significant improvements, achieving an average performance gain of 4.89% with Qwen and 11.33% with Llama, effectively overcoming the core limitations of traditional RLVR methods.", 'abstract_zh': 'Recent Advances in Multi-Expert Mutual Learning GRPO for Enhancing Reasoning Capabilities of Large Language Models with Verifiable Rewards', 'title_zh': 'MEML-GRPO：异质多专家互学促进RLVR进步'}
{'arxiv_id': 'arXiv:2508.09639', 'title': 'UbiQTree: Uncertainty Quantification in XAI with Tree Ensembles', 'authors': 'Akshat Dubey, Aleksandar Anžel, Bahar İlgen, Georges Hattab', 'link': 'https://arxiv.org/abs/2508.09639', 'abstract': 'Explainable Artificial Intelligence (XAI) techniques, such as SHapley Additive exPlanations (SHAP), have become essential tools for interpreting complex ensemble tree-based models, especially in high-stakes domains such as healthcare analytics. However, SHAP values are usually treated as point estimates, which disregards the inherent and ubiquitous uncertainty in predictive models and data. This uncertainty has two primary sources: aleatoric and epistemic. The aleatoric uncertainty, which reflects the irreducible noise in the data. The epistemic uncertainty, which arises from a lack of data. In this work, we propose an approach for decomposing uncertainty in SHAP values into aleatoric, epistemic, and entanglement components. This approach integrates Dempster-Shafer evidence theory and hypothesis sampling via Dirichlet processes over tree ensembles. We validate the method across three real-world use cases with descriptive statistical analyses that provide insight into the nature of epistemic uncertainty embedded in SHAP explanations. The experimentations enable to provide more comprehensive understanding of the reliability and interpretability of SHAP-based attributions. This understanding can guide the development of robust decision-making processes and the refinement of models in high-stakes applications. Through our experiments with multiple datasets, we concluded that features with the highest SHAP values are not necessarily the most stable. This epistemic uncertainty can be reduced through better, more representative data and following appropriate or case-desired model development techniques. Tree-based models, especially bagging, facilitate the effective quantification of epistemic uncertainty.', 'abstract_zh': '可解释人工智能(XAI)技术，如SHapley Additive exPlanations (SHAP)，已成为解读复杂集成树模型的重要工具，特别是在医疗保健分析等高风险领域。然而，SHAP值通常被视为点估计，这忽略了预测模型和数据中的固有和普遍不确定性。这种不确定性有两个主要来源：aleatoric不确定性，反映了数据中的不可约噪声；epistemic不确定性，源于数据不足。在本文中，我们提出了一种将SHAP值中的不确定性分解为aleatoric、epistemic和纠缠成分的方法。该方法结合了Dempster-Shafer证据理论和基于Dirichlet过程的假设采样，应用于树集成。利用三种实际案例的描述性统计分析验证了该方法，提供了对SHAP解释中嵌入的epistemic不确定性性质的洞察。实验使我们能够更全面地理解基于SHAP的归因的可靠性和可解释性，这些理解可以指导在高风险应用中稳健决策过程的发展和模型的完善。通过多个数据集的实验，我们得出结论，具有最高SHAP值的特征并不一定是最稳定的。可以通过更好地使用代表性数据和遵循适当或特定于案例的模型开发技术来降低epistemic不确定性。基于树的模型，特别是袋装模型，有助于有效地量化epistemic不确定性。', 'title_zh': 'UbiQTree: 在树集成中的不确定性量化在可解释AI中的应用'}
{'arxiv_id': 'arXiv:2508.09586', 'title': 'EvoCurr: Self-evolving Curriculum with Behavior Code Generation for Complex Decision-making', 'authors': 'Yang Cheng, Zilai Wang, Weiyu Ma, Wenhui Zhu, Yue Deng, Jian Zhao', 'link': 'https://arxiv.org/abs/2508.09586', 'abstract': "Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse domains, including programming, planning, and decision-making. However, their performance often degrades when faced with highly complex problem instances that require deep reasoning over long horizons. In such cases, direct problem-solving approaches can lead to inefficiency or failure due to the lack of structured intermediate guidance. To address this, we propose a novel self-evolve framework, EvoCurr, in which a dedicated curriculum-generation LLM constructs a sequence of problem instances with gradually increasing difficulty, tailored to the solver LLM's learning progress. The curriculum dynamically adapts easing challenges when the solver struggles and escalating them when success is consistent, thus maintaining an optimal learning trajectory. This approach enables the solver LLM, implemented as a code-generation model producing Python decision-tree scripts, to progressively acquire the skills needed for complex decision-making tasks. Experimental results on challenging decision-making benchmarks show that our method significantly improves task success rates and solution efficiency compared to direct-solving baselines. These findings suggest that LLM-driven curriculum learning holds strong potential for enhancing automated reasoning in real-world, high-complexity domains.", 'abstract_zh': '大型语言模型（LLMs）在编程、规划和决策等多样化领域展现了卓越的能力。然而，当面对长时间跨度和深层次推理所需的高度复杂问题实例时，它们的表现往往会下降。在这种情况下，直接的问题解决方法可能会因为缺乏结构化的中间指导而导致效率低下或失败。为了解决这个问题，我们提出了一种新颖的自我进化框架EvoCurr，在该框架中，专门的课程生成LLM构建了一系列逐渐增加难度的问题实例，以适应解题LLM的学习进展。课程会根据解题器的困难程度动态调整难度，当成功一致时逐步增加难度，从而保持最优的学习轨迹。这种方法使作为生成代码模型的解题器LLM能够逐步掌握进行复杂决策任务所需的技能。在具有挑战性的决策任务基准测试中的实验结果表明，与直接解决基线相比，我们的方法显著提高了任务成功率和解决方案的效率。这些发现表明，由LLM驱动的课程学习在提升复杂真实世界场景中的自动化推理方面具有强大的潜力。', 'title_zh': 'EvoCurr：基于行为代码生成的自演进课程学习方法用于复杂决策making'}
{'arxiv_id': 'arXiv:2508.09507', 'title': 'An Automated Multi-Modal Evaluation Framework for Mobile Intelligent Assistants', 'authors': 'Meiping Wang, Jian Zhong, Rongduo Han, Liming Kang, Zhengkun Shi, Xiao Liang, Xing Lin, Nan Gao, Haining Zhang', 'link': 'https://arxiv.org/abs/2508.09507', 'abstract': "With the rapid development of mobile intelligent assistant technologies, multi-modal AI assistants have become essential interfaces for daily user interactions. However, current evaluation methods face challenges including high manual costs, inconsistent standards, and subjective bias. This paper proposes an automated multi-modal evaluation framework based on large language models and multi-agent collaboration. The framework employs a three-tier agent architecture consisting of interaction evaluation agents, semantic verification agents, and experience decision agents. Through supervised fine-tuning on the Qwen3-8B model, we achieve a significant evaluation matching accuracy with human experts. Experimental results on eight major intelligent agents demonstrate the framework's effectiveness in predicting users' satisfaction and identifying generation defects.", 'abstract_zh': '基于大规模语言模型和多agent协作的多模态自动化评估框架', 'title_zh': '移动智能助手的自动化多模态评估框架'}
{'arxiv_id': 'arXiv:2508.09292', 'title': 'The Othello AI Arena: Evaluating Intelligent Systems Through Limited-Time Adaptation to Unseen Boards', 'authors': 'Sundong Kim', 'link': 'https://arxiv.org/abs/2508.09292', 'abstract': "The ability to rapidly adapt to novel and unforeseen environmental changes is a cornerstone of artificial general intelligence (AGI), yet it remains a critical blind spot in most existing AI benchmarks. Traditional evaluation largely focuses on optimizing performance within fixed environments, failing to assess systems' flexibility and generalization capabilities when faced with even subtle rule or structural modifications. Addressing this gap, I introduce the Othello AI Arena, a novel benchmark framework designed to evaluate intelligent systems based on their capacity for limited-time adaptation to unseen environments. Our platform poses a meta-learning challenge: participants must develop systems that can analyze the specific configuration and rules of a novel Othello board within a strict time limit (60 seconds) and generate a tailored, high-performing strategy for that unique environment. With this, evaluation of the meta-level intelligence can be separated from the task-level strategy performance. The Arena features a diverse set of game stages, including public stages for development and private stages with structural and rule variations designed to test genuine adaptive and generalization capabilities. Implemented as an accessible web-based platform, the Arena provides real-time visualization, automated evaluation using multi-dimensional metrics, and comprehensive logging for post-hoc analysis. Initial observations from pilot tests and preliminary student engagements highlight fascinating patterns in adaptation approaches, ranging from rapid parameter tuning to rudimentary environmental model learning through simulation. The Othello AI Arena offers a unique educational tool and a valuable research benchmark for fostering and evaluating the crucial skill of rapid, intelligent adaptation in AI systems.", 'abstract_zh': '基于有限时间内适应未见环境能力的人工通用智能评估框架：愚公棋AI竞技场', 'title_zh': '奥赛罗AI竞技场：通过有限时间适应未见棋局评估智能系统'}
{'arxiv_id': 'arXiv:2508.09277', 'title': 'Value Function Initialization for Knowledge Transfer and Jump-start in Deep Reinforcement Learning', 'authors': 'Soumia Mehimeh', 'link': 'https://arxiv.org/abs/2508.09277', 'abstract': "Value function initialization (VFI) is an effective way to achieve a jumpstart in reinforcement learning (RL) by leveraging value estimates from prior tasks. While this approach is well established in tabular settings, extending it to deep reinforcement learning (DRL) poses challenges due to the continuous nature of the state-action space, the noisy approximations of neural networks, and the impracticality of storing all past models for reuse. In this work, we address these challenges and introduce DQInit, a method that adapts value function initialization to DRL. DQInit reuses compact tabular Q-values extracted from previously solved tasks as a transferable knowledge base. It employs a knownness-based mechanism to softly integrate these transferred values into underexplored regions and gradually shift toward the agent's learned estimates, avoiding the limitations of fixed time decay. Our approach offers a novel perspective on knowledge transfer in DRL by relying solely on value estimates rather than policies or demonstrations, effectively combining the strengths of jumpstart RL and policy distillation while mitigating their drawbacks. Experiments across multiple continuous control tasks demonstrate that DQInit consistently improves early learning efficiency, stability, and overall performance compared to standard initialization and existing transfer techniques.", 'abstract_zh': '基于值函数初始化的深层强化学习方法：DQInit', 'title_zh': '深度强化学习中知识迁移与初始化的价值函数加速方法'}
{'arxiv_id': 'arXiv:2508.09987', 'title': 'Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation', 'authors': 'Junyan Ye, Dongzhi Jiang, Zihao Wang, Leqi Zhu, Zhenghao Hu, Zilong Huang, Jun He, Zhiyuan Yan, Jinghua Yu, Hongsheng Li, Conghui He, Weijia Li', 'link': 'https://arxiv.org/abs/2508.09987', 'abstract': 'Recently, GPT-4o has garnered significant attention for its strong performance in image generation, yet open-source models still lag behind. Several studies have explored distilling image data from GPT-4o to enhance open-source models, achieving notable progress. However, a key question remains: given that real-world image datasets already constitute a natural source of high-quality data, why should we use GPT-4o-generated synthetic data? In this work, we identify two key advantages of synthetic images. First, they can complement rare scenarios in real-world datasets, such as surreal fantasy or multi-reference image generation, which frequently occur in user queries. Second, they provide clean and controllable supervision. Real-world data often contains complex background noise and inherent misalignment between text descriptions and image content, whereas synthetic images offer pure backgrounds and long-tailed supervision signals, facilitating more accurate text-to-image alignment. Building on these insights, we introduce Echo-4o-Image, a 180K-scale synthetic dataset generated by GPT-4o, harnessing the power of synthetic image data to address blind spots in real-world coverage. Using this dataset, we fine-tune the unified multimodal generation baseline Bagel to obtain Echo-4o. In addition, we propose two new evaluation benchmarks for a more accurate and challenging assessment of image generation capabilities: GenEval++, which increases instruction complexity to mitigate score saturation, and Imagine-Bench, which focuses on evaluating both the understanding and generation of imaginative content. Echo-4o demonstrates strong performance across standard benchmarks. Moreover, applying Echo-4o-Image to other foundation models (e.g., OmniGen2, BLIP3-o) yields consistent performance gains across multiple metrics, highlighting the datasets strong transferability.', 'abstract_zh': 'Recently, GPT-4o 在图像生成任务中的强大表现引起了广泛关注，但开源模型仍 lagging behind。一些研究探索将图像数据从 GPT-4o 中提取以提升开源模型，取得了一定进展。然而，一个关键问题仍然存在：既然现实世界图像数据本身就是高质量数据的自然来源，为何要使用 GPT-4o 生成的合成数据？在本文中，我们识别了合成图像的两个主要优势。首先，它们可以补充现实世界数据集中罕见的场景，如超现实的幻想场景或多参考图像生成，这些场景在用户查询中常见。其次，它们提供了清洁和可控的监督。现实世界数据通常包含复杂的背景噪声和文本描述与图像内容之间的固有不对齐，而合成图像则提供了干净的背景和长尾监督信号，有助于更准确的文字到图像的对齐。基于这些见解，我们引入了 Echo-4o-Image，这是一个由 GPT-4o 生成的 180K 规模的合成数据集，利用合成图像数据来弥补现实世界覆盖的盲点。使用此数据集，我们对统一的多模态生成基线 Bagel 进行微调，得到 Echo-4o。此外，我们提出了两个新的评估基准：GenEval++，增加指令复杂性以减轻得分饱和；Imagine-Bench，专注于评估对想象力内容的理解和生成能力。Echo-4o 在标准基准测试中的表现强劲。此外，将 Echo-4o-Image 应用于其他基础模型（例如 OmniGen2 和 BLIP3-o）在多个指标上取得了一致的性能提升，突显了数据集的强转移能力。\n\nTitle:\n合成图像的两个关键优势：Echo-4o-Image 的研究与应用', 'title_zh': 'Echo-4o: 利用GPT-4o合成图像提升图像生成能力'}
{'arxiv_id': 'arXiv:2508.09971', 'title': 'Vision-driven River Following of UAV via Safe Reinforcement Learning using Semantic Dynamics Model', 'authors': 'Zihan Wang, Nina Mahmoudian', 'link': 'https://arxiv.org/abs/2508.09971', 'abstract': "Vision-driven autonomous river following by Unmanned Aerial Vehicles is critical for applications such as rescue, surveillance, and environmental monitoring, particularly in dense riverine environments where GPS signals are unreliable. We formalize river following as a coverage control problem in which the reward function is submodular, yielding diminishing returns as more unique river segments are visited, thereby framing the task as a Submodular Markov Decision Process. First, we introduce Marginal Gain Advantage Estimation, which refines the reward advantage function by using a sliding window baseline computed from historical episodic returns, thus aligning the advantage estimation with the agent's evolving recognition of action value in non-Markovian settings. Second, we develop a Semantic Dynamics Model based on patchified water semantic masks that provides more interpretable and data-efficient short-term prediction of future observations compared to latent vision dynamics models. Third, we present the Constrained Actor Dynamics Estimator architecture, which integrates the actor, the cost estimator, and SDM for cost advantage estimation to form a model-based SafeRL framework capable of solving partially observable Constrained Submodular Markov Decision Processes. Simulation results demonstrate that MGAE achieves faster convergence and superior performance over traditional critic-based methods like Generalized Advantage Estimation. SDM provides more accurate short-term state predictions that enable the cost estimator to better predict potential violations. Overall, CADE effectively integrates safety regulation into model-based RL, with the Lagrangian approach achieving the soft balance of reward and safety during training, while the safety layer enhances performance during inference by hard action overlay.", 'abstract_zh': '基于视觉的自主河流跟踪对于救援、监控和环境监测等应用至关重要，特别是在GPS信号不可靠的密集河流环境中。我们将河流跟踪形式化为一个覆盖控制问题，其中回报函数为亚模函数，随着时间的推移访问更多独特的河流段落而回报递减，从而将任务框架化为亚模马克ʾ夫决策过程。首先，我们引入了边缘增益优势估计方法，通过使用从历史 episodic 回报中计算的滑动窗口基准来细化优势回报函数，从而在非马克_overflow: 龙\\-维设置中将优势估计与代理行动价值的演变认识相一致。其次，我们基于斑块化的水语义掩码开发了一种语义动力学模型，相比潜在视觉动力学模型，它能提供更具有解释性和数据效率的未来观测短期预测。第三，我们提出了约束动作动力学估计器架构，该架构结合了动作、成本估计器和语义动力学模型进行成本优势估计，形成了一种基于模型的SafeRL框架，能够解决部分可观测的约束亚模马克\\-维决策过程。仿真结果表明，MGAE 在收敛速度和性能上优于传统的基于评论的方法如广义优势估计算法。语义动力学模型提供了更准确的短期状态预测，使成本估计器能够更好地预测潜在的违规行为。总体而言，CADE 有效将安全性约束整合到基于模型的强化学习中，通过拉格朗日方法在训练过程中实现奖励和安全性的软平衡，而安全层则在推理过程中通过硬动作叠加增强性能。', 'title_zh': '基于视觉的无人机河流跟踪通过语义动力学模型的稳健强化学习'}
{'arxiv_id': 'arXiv:2508.09966', 'title': 'January Food Benchmark (JFB): A Public Benchmark Dataset and Evaluation Suite for Multimodal Food Analysis', 'authors': 'Amir Hosseinian, Ashkan Dehghani Zahedani, Umer Mansoor, Noosheen Hashemi, Mark Woodward', 'link': 'https://arxiv.org/abs/2508.09966', 'abstract': 'Progress in AI for automated nutritional analysis is critically hampered by the lack of standardized evaluation methodologies and high-quality, real-world benchmark datasets. To address this, we introduce three primary contributions. First, we present the January Food Benchmark (JFB), a publicly available collection of 1,000 food images with human-validated annotations. Second, we detail a comprehensive benchmarking framework, including robust metrics and a novel, application-oriented overall score designed to assess model performance holistically. Third, we provide baseline results from both general-purpose Vision-Language Models (VLMs) and our own specialized model, january/food-vision-v1. Our evaluation demonstrates that the specialized model achieves an Overall Score of 86.2, a 12.1-point improvement over the best-performing general-purpose configuration. This work offers the research community a valuable new evaluation dataset and a rigorous framework to guide and benchmark future developments in automated nutritional analysis.', 'abstract_zh': '人工智能在自动营养分析领域的进展因缺乏标准化评估方法和高质量的实际基准数据集而受严重阻碍。为此，我们提出了三项主要贡献。首先，我们介绍了公开可用的January Food Benchmark (JFB)，包含1,000张带有手工验证标注的食品图像。其次，我们详细介绍了全面的基准测试框架，包括稳健的评估指标和面向应用的整体评分，旨在全面评估模型性能。第三，我们提供了通用视觉-语言模型（VLMs）和我们自己专门模型january/food-vision-v1的基线结果。评估结果显示，专门模型的整体评分为86.2，比表现最好的通用配置高出12.1分。本工作为研究界提供了 valuable 新的评估数据集和严格的框架，以指导和基准测试未来自动营养分析的发展。', 'title_zh': 'January 食物基准数据集 (JFB): 多模态食物分析的公共基准数据集及评估套件'}
{'arxiv_id': 'arXiv:2508.09960', 'title': 'GBC: Generalized Behavior-Cloning Framework for Whole-Body Humanoid Imitation', 'authors': 'Yifei Yao, Chengyuan Luo, Jiaheng Du, Wentao He, Jun-Guo Lu', 'link': 'https://arxiv.org/abs/2508.09960', 'abstract': 'The creation of human-like humanoid robots is hindered by a fundamental fragmentation: data processing and learning algorithms are rarely universal across different robot morphologies. This paper introduces the Generalized Behavior Cloning (GBC) framework, a comprehensive and unified solution designed to solve this end-to-end challenge. GBC establishes a complete pathway from human motion to robot action through three synergistic innovations. First, an adaptive data pipeline leverages a differentiable IK network to automatically retarget any human MoCap data to any humanoid. Building on this foundation, our novel DAgger-MMPPO algorithm with its MMTransformer architecture learns robust, high-fidelity imitation policies. To complete the ecosystem, the entire framework is delivered as an efficient, open-source platform based on Isaac Lab, empowering the community to deploy the full workflow via simple configuration scripts. We validate the power and generality of GBC by training policies on multiple heterogeneous humanoids, demonstrating excellent performance and transfer to novel motions. This work establishes the first practical and unified pathway for creating truly generalized humanoid controllers.', 'abstract_zh': '人类类人机器人创建受制于根本性的碎片化问题：不同的机器人形态通常缺乏普适的数据处理和学习算法。本文提出了通用行为克隆（GBC）框架，这是一种端到端的综合统一解决方案，通过三种协同创新建立了从人类运动到机器人动作的完整路径。首先，自适应数据管道利用可微逆运动学网络自动将任何人的动捕数据重定向到任何类人机器人。在此基础上，我们的新型DAgger-MMPPO算法及其MMTransformer架构学习出鲁棒且高保真的模仿策略。为了构建完整的生态系统，整个框架基于Isaac Lab以高效开源的形式提供，使社区能够通过简单的配置脚本部署完整的操作流程。我们通过在多种异构类人机器人上训练策略，验证了GBC的强大力量和泛化能力，并展示了其对新颖运动的出色适应性。这项工作确立了创建真正通用类人控制器的第一个可行且统一的途径。', 'title_zh': 'Generalized 行为克隆框架：全身 humanoid 仿真人机交互'}
{'arxiv_id': 'arXiv:2508.09952', 'title': 'Specialised or Generic? Tokenization Choices for Radiology Language Models', 'authors': 'Hermione Warr, Wentian Xu, Harry Anthony, Yasin Ibrahim, Daniel McGowan, Konstantinos Kamnitsas', 'link': 'https://arxiv.org/abs/2508.09952', 'abstract': 'The vocabulary used by language models (LM) - defined by the tokenizer - plays a key role in text generation quality. However, its impact remains under-explored in radiology. In this work, we address this gap by systematically comparing general, medical, and domain-specific tokenizers on the task of radiology report summarisation across three imaging modalities. We also investigate scenarios with and without LM pre-training on PubMed abstracts. Our findings demonstrate that medical and domain-specific vocabularies outperformed widely used natural language alternatives when models are trained from scratch. Pre-training partially mitigates performance differences between tokenizers, whilst the domain-specific tokenizers achieve the most favourable results. Domain-specific tokenizers also reduce memory requirements due to smaller vocabularies and shorter sequences. These results demonstrate that adapting the vocabulary of LMs to the clinical domain provides practical benefits, including improved performance and reduced computational demands, making such models more accessible and effective for both research and real-world healthcare settings.', 'abstract_zh': '语言模型（LM）所使用的词汇表（由分词器定义）在文本生成质量中起着关键作用。然而，其在放射学领域的影响力尚未得到充分探索。本文通过系统比较通用、医学和领域特定的分词器在三种成像模态下的放射学报告摘要任务，填补了这一空白。我们还研究了在有和无PubMed摘要预训练的情况下分词器的影响。研究发现，医学和领域特定的词汇表在从零开始训练模型时优于广泛使用的自然语言替代品。预训练部分缓解了不同分词器之间的性能差异，而领域特定分词器取得了最有利的结果。领域特定分词器还由于词汇表较小和序列较短而降低了内存需求。这些结果表明，将语言模型的词汇表适配到临床领域提供了实际益处，包括提高性能和减少计算需求，使这些模型在研究和真实世界医疗保健环境中更加可访问和有效。', 'title_zh': '专业型还是通用型？放射语言模型的分词选择'}
{'arxiv_id': 'arXiv:2508.09945', 'title': 'VisCodex: Unified Multimodal Code Generation via Merging Vision and Coding Models', 'authors': 'Lingjie Jiang, Shaohan Huang, Xun Wu, Yixia Li, Dongdong Zhang, Furu Wei', 'link': 'https://arxiv.org/abs/2508.09945', 'abstract': 'Multimodal large language models (MLLMs) have significantly advanced the integration of visual and textual understanding. However, their ability to generate code from multimodal inputs remains limited. In this work, we introduce VisCodex, a unified framework that seamlessly merges vision and coding language models to empower MLLMs with strong multimodal code generation abilities. Leveraging a task vector-based model merging technique, we integrate a state-of-the-art coding LLM into a strong vision-language backbone, while preserving both visual comprehension and advanced coding skills. To support training and evaluation, we introduce the Multimodal Coding Dataset (MCD), a large-scale and diverse collection of 598k samples, including high-quality HTML code, chart image-code pairs, image-augmented StackOverflow QA, and algorithmic problems. Furthermore, we propose InfiBench-V, a novel and challenging benchmark specifically designed to assess models on visually-rich, real-world programming questions that demand a nuanced understanding of both textual and visual contexts. Extensive experiments show that VisCodex achieves state-of-the-art performance among open-source MLLMs and approaches proprietary models like GPT-4o, highlighting the effectiveness of our model merging strategy and new datasets.', 'abstract_zh': '多模态大语言模型（MLLMs）在视觉和文本理解的融合方面取得了显著进展。然而，它们从多模态输入生成代码的能力仍然有限。本文引入了VisCodex，这是一种统一框架，可无缝结合视觉和编程语言模型，增强MLLMs的多模态代码生成能力。通过基于任务向量的模型融合技术，我们将最先进的编程大语言模型集成到强大的视觉-语言骨干中，同时保留了视觉理解和高级编程技能。为了支持训练和评估，我们引入了多模态编程数据集（MCD），这个大规模且多样化的数据集包含598,000个样本，包括高质量的HTML代码、图表图像-代码对、图像增强的StackOverflow问答以及算法问题。此外，我们提出了一种新的更具挑战性的基准InfiBench-V，专门用于评估模型在丰富视觉的真实编程问题上的性能，这些问题是需要对文本和视觉上下文有深刻理解的。广泛的实验表明，VisCodex在开源MLLM中达到了最先进的性能，并接近如GPT-4o等 proprietary 模型，突显了我们模型融合策略和新数据集的有效性。', 'title_zh': 'VisCodex: 统一的多模态代码生成模型通过融合视觉和编码模型'}
{'arxiv_id': 'arXiv:2508.09937', 'title': 'A Comprehensive Evaluation framework of Alignment Techniques for LLMs', 'authors': 'Muneeza Azmat, Momin Abbas, Maysa Malfiza Garcia de Macedo, Marcelo Carpinette Grave, Luan Soares de Souza, Tiago Machado, Rogerio A de Paula, Raya Horesh, Yixin Chen, Heloisa Caroline de Souza Pereira Candello, Rebecka Nordenlow, Aminat Adebiyi', 'link': 'https://arxiv.org/abs/2508.09937', 'abstract': 'As Large Language Models (LLMs) become increasingly integrated into real-world applications, ensuring their outputs align with human values and safety standards has become critical. The field has developed diverse alignment approaches including traditional fine-tuning methods (RLHF, instruction tuning), post-hoc correction systems, and inference-time interventions, each with distinct advantages and limitations. However, the lack of unified evaluation frameworks makes it difficult to systematically compare these paradigms and guide deployment decisions. This paper introduces a multi-dimensional evaluation of alignment techniques for LLMs, a comprehensive evaluation framework that provides a systematic comparison across all major alignment paradigms. Our framework assesses methods along four key dimensions: alignment detection, alignment quality, computational efficiency, and robustness. Through experiments across diverse base models and alignment strategies, we demonstrate the utility of our framework in identifying strengths and limitations of current state-of-the-art models, providing valuable insights for future research directions.', 'abstract_zh': '随着大型语言模型（LLMs）在实际应用中越来越广泛，确保其输出与人类价值观和安全标准相符变得至关重要。该领域已经发展出了多种对齐方法，包括传统的细调方法（如RLHF、指令调整）、后置纠正系统和推理时干预措施，每种方法都有其独特的优缺点。然而，缺乏统一的评估框架使得系统比较这些范式并指导部署决策变得困难。本文介绍了大型语言模型对齐技术的多维度评估，提供了一个全面的评估框架，能够系统地比较所有主要的对齐范式。我们的框架沿四个关键维度评估方法：对齐检测、对齐质量、计算效率和鲁棒性。通过在不同基础模型和对齐策略上的实验，我们展示了该框架在识别当前最先进的模型的优势和局限性方面的实用性，并为未来的研究方向提供了宝贵见解。', 'title_zh': 'LLMs对齐技术的综合评估框架'}
{'arxiv_id': 'arXiv:2508.09925', 'title': 'Residual Reservoir Memory Networks', 'authors': 'Matteo Pinna, Andrea Ceni, Claudio Gallicchio', 'link': 'https://arxiv.org/abs/2508.09925', 'abstract': 'We introduce a novel class of untrained Recurrent Neural Networks (RNNs) within the Reservoir Computing (RC) paradigm, called Residual Reservoir Memory Networks (ResRMNs). ResRMN combines a linear memory reservoir with a non-linear reservoir, where the latter is based on residual orthogonal connections along the temporal dimension for enhanced long-term propagation of the input. The resulting reservoir state dynamics are studied through the lens of linear stability analysis, and we investigate diverse configurations for the temporal residual connections. The proposed approach is empirically assessed on time-series and pixel-level 1-D classification tasks. Our experimental results highlight the advantages of the proposed approach over other conventional RC models.', 'abstract_zh': '残差内存网络：基于残差正交连接的训练后递归神经网络', 'title_zh': '残差储层记忆网络'}
{'arxiv_id': 'arXiv:2508.09919', 'title': 'T-CACE: A Time-Conditioned Autoregressive Contrast Enhancement Multi-Task Framework for Contrast-Free Liver MRI Synthesis, Segmentation, and Diagnosis', 'authors': 'Xiaojiao Xiao, Jianfeng Zhao, Qinmin Vivian Hu, Guanghui Wang', 'link': 'https://arxiv.org/abs/2508.09919', 'abstract': 'Magnetic resonance imaging (MRI) is a leading modality for the diagnosis of liver cancer, significantly improving the classification of the lesion and patient outcomes. However, traditional MRI faces challenges including risks from contrast agent (CA) administration, time-consuming manual assessment, and limited annotated datasets. To address these limitations, we propose a Time-Conditioned Autoregressive Contrast Enhancement (T-CACE) framework for synthesizing multi-phase contrast-enhanced MRI (CEMRI) directly from non-contrast MRI (NCMRI). T-CACE introduces three core innovations: a conditional token encoding (CTE) mechanism that unifies anatomical priors and temporal phase information into latent representations; and a dynamic time-aware attention mask (DTAM) that adaptively modulates inter-phase information flow using a Gaussian-decayed attention mechanism, ensuring smooth and physiologically plausible transitions across phases. Furthermore, a constraint for temporal classification consistency (TCC) aligns the lesion classification output with the evolution of the physiological signal, further enhancing diagnostic reliability. Extensive experiments on two independent liver MRI datasets demonstrate that T-CACE outperforms state-of-the-art methods in image synthesis, segmentation, and lesion classification. This framework offers a clinically relevant and efficient alternative to traditional contrast-enhanced imaging, improving safety, diagnostic efficiency, and reliability for the assessment of liver lesion. The implementation of T-CACE is publicly available at: this https URL.', 'abstract_zh': '磁\nuser\n基于时间的自回归对比增强框架（T-CACE）：直接合成非对比增强\nuser\n基于时间条件的自回归对比增强框架（T-CACE）：直接从非对比MRI合成多期对比增强MRI（CEMRI）', 'title_zh': 'T-CACE：一种基于时间条件的自回归对比增强多任务框架，用于无对比剂肝MRI合成、分割和诊断'}
{'arxiv_id': 'arXiv:2508.09904', 'title': 'Beyond Naïve Prompting: Strategies for Improved Zero-shot Context-aided Forecasting with LLMs', 'authors': 'Arjun Ashok, Andrew Robert Williams, Vincent Zhihao Zheng, Irina Rish, Nicolas Chapados, Étienne Marcotte, Valentina Zantedeschi, Alexandre Drouin', 'link': 'https://arxiv.org/abs/2508.09904', 'abstract': "Forecasting in real-world settings requires models to integrate not only historical data but also relevant contextual information, often available in textual form. While recent work has shown that large language models (LLMs) can be effective context-aided forecasters via naïve direct prompting, their full potential remains underexplored. We address this gap with 4 strategies, providing new insights into the zero-shot capabilities of LLMs in this setting. ReDP improves interpretability by eliciting explicit reasoning traces, allowing us to assess the model's reasoning over the context independently from its forecast accuracy. CorDP leverages LLMs solely to refine existing forecasts with context, enhancing their applicability in real-world forecasting pipelines. IC-DP proposes embedding historical examples of context-aided forecasting tasks in the prompt, substantially improving accuracy even for the largest models. Finally, RouteDP optimizes resource efficiency by using LLMs to estimate task difficulty, and routing the most challenging tasks to larger models. Evaluated on different kinds of context-aided forecasting tasks from the CiK benchmark, our strategies demonstrate distinct benefits over naïve prompting across LLMs of different sizes and families. These results open the door to further simple yet effective improvements in LLM-based context-aided forecasting.", 'abstract_zh': '实时环境中的预测要求模型不仅整合历史数据，还要整合相关的背景信息，这些信息通常以文本形式存在。尽管近期研究表明，大型语言模型（LLMs）可以通过简单的直接提示作为背景辅助预测的有效工具，但其全部潜力尚未被充分探索。我们通过4种策略填补了这一空白，为LLMs在这种环境下的零样本能力提供了新的见解。ReDP通过激发明确的推理轨迹提高可解释性，使我们能够独立于预测准确性评估模型的推理过程。CorDP利用LLMs仅对现有预测进行细化，以背景提高预测的实际适用性。IC-DP建议在提示中嵌入历史上的背景辅助预测任务示例，即使对于最大的模型也能显著提高准确性。最后，RouteDP通过使用LLMs估算任务难度并将其最具有挑战性的任务路由到更大模型来优化资源效率。在CiK基准的不同类型的背景辅助预测任务上进行评估，我们的策略在不同大小和家族的LLMs中展示了与简单直接提示相比的独特优势。这些结果为基于LLM的背景辅助预测提供了进一步简单而有效的改进。', 'title_zh': '超越简单的提示：利用LLM进行增强零样本上下文辅助预测的策略'}
{'arxiv_id': 'arXiv:2508.09894', 'title': 'Rare anomalies require large datasets: About proving the existence of anomalies', 'authors': 'Simon Klüttermann, Emmanuel Müller', 'link': 'https://arxiv.org/abs/2508.09894', 'abstract': 'Detecting whether any anomalies exist within a dataset is crucial for effective anomaly detection, yet it remains surprisingly underexplored in anomaly detection literature. This paper presents a comprehensive study that addresses the fundamental question: When can we conclusively determine that anomalies are present? Through extensive experimentation involving over three million statistical tests across various anomaly detection tasks and algorithms, we identify a relationship between the dataset size, contamination rate, and an algorithm-dependent constant $ \\alpha_{\\text{algo}} $. Our results demonstrate that, for an unlabeled dataset of size $ N $ and contamination rate $ \\nu $, the condition $ N \\ge \\frac{\\alpha_{\\text{algo}}}{\\nu^2} $ represents a lower bound on the number of samples required to confirm anomaly existence. This threshold implies a limit to how rare anomalies can be before proving their existence becomes infeasible.', 'abstract_zh': '在数据集中检测是否存在异常对于有效的异常检测至关重要，但这一问题在异常检测文献中却意外地被严重忽视。本文进行了全面研究，探讨了可以确定异常存在的基本条件：当什么情况下我们能够断言异常确实存在？通过涵盖多种异常检测任务和算法的超过三百万次的统计测试，我们发现数据集大小、污染率与算法相关的常数$\\alpha_{\\text{algo}}$之间存在关系。研究结果表明，对于大小为$N$且污染率为$\\nu$的无标签名注数据集，确认异常存在的样本数下限条件为$N \\ge \\frac{\\alpha_{\\text{algo}}}{\\nu^2}$。这一阈值意味着在证明异常存在之前，异常可以有多罕见是有限制的。', 'title_zh': '稀有异常需要大量数据：关于异常存在性的证明'}
{'arxiv_id': 'arXiv:2508.09886', 'title': 'COME: Dual Structure-Semantic Learning with Collaborative MoE for Universal Lesion Detection Across Heterogeneous Ultrasound Datasets', 'authors': 'Lingyu Chen, Yawen Zeng, Yue Wang, Peng Wan, Guo-chen Ning, Hongen Liao, Daoqiang Zhang, Fang Chen', 'link': 'https://arxiv.org/abs/2508.09886', 'abstract': "Conventional single-dataset training often fails with new data distributions, especially in ultrasound (US) image analysis due to limited data, acoustic shadows, and speckle noise. Therefore, constructing a universal framework for multi-heterogeneous US datasets is imperative. However, a key challenge arises: how to effectively mitigate inter-dataset interference while preserving dataset-specific discriminative features for robust downstream task? Previous approaches utilize either a single source-specific decoder or a domain adaptation strategy, but these methods experienced a decline in performance when applied to other domains. Considering this, we propose a Universal Collaborative Mixture of Heterogeneous Source-Specific Experts (COME). Specifically, COME establishes dual structure-semantic shared experts that create a universal representation space and then collaborate with source-specific experts to extract discriminative features through providing complementary features. This design enables robust generalization by leveraging cross-datasets experience distributions and providing universal US priors for small-batch or unseen data scenarios. Extensive experiments under three evaluation modes (single-dataset, intra-organ, and inter-organ integration datasets) demonstrate COME's superiority, achieving significant mean AP improvements over state-of-the-art methods. Our project is available at: this https URL.", 'abstract_zh': '常规单数据集训练在新数据分布面前往往失效，特别是在由于数据有限、声影和 speckle 噪音等因素导致的超声图像分析中。因此，构建适用于多异质超声数据集的通用框架变得至关重要。然而，一个关键挑战随之产生：如何有效地减轻数据集之间的干扰同时保持各数据集特有的判别特征，以实现稳健的下游任务？先前的方法要么使用单一来源特定解码器，要么采用领域适应策略，但这些方法在应用于其他领域时性能下降。考虑到这一点，我们提出了一个通用协作异质来源特定专家混合（Universal Collaborative Mixture of Heterogeneous Source-Specific Experts, COME）。具体而言，COME 建立了双重结构-语义共享专家，创建了一个通用的表示空间，然后与来源特定专家协作，通过提供互补特征来提取判别特征。这种设计通过利用跨数据集的经验分布，利用通用的超声先验信息，实现了稳健的实际应用。在三种评估模式（单数据集、同器官集成数据集和跨器官集成数据集）下进行的广泛实验证明了 COME 的优越性，其在平均精度（mean AP）上显著优于现有方法。我们的项目可在以下链接获取：this https URL。', 'title_zh': 'COME：跨异质超声数据集的协作门控双结构语义学习通用病灶检测'}
{'arxiv_id': 'arXiv:2508.09883', 'title': 'Beyond Scaling Law: A Data-Efficient Distillation Framework for Reasoning', 'authors': 'Xiaojun Wu, Xiaoguang Jiang, Huiyang Li, Jucai Zhai, Dengfeng Liu, Qiaobo Hao, Huang Liu, Zhiguo Yang, Ji Xie, Ninglun Gu, Jin Yang, Kailai Zhang, Yelun Bao, Jun Wang', 'link': 'https://arxiv.org/abs/2508.09883', 'abstract': 'Large language models (LLMs) demonstrate remarkable reasoning capabilities in tasks such as algorithmic coding and mathematical problem-solving. Recent methods have improved reasoning through expanded corpus and multistage training combining reinforcement learning and supervised fine-tuning. Although some methods suggest that small but targeted dataset can incentivize reasoning via only distillation, a reasoning scaling laws is still taking shape, increasing computational costs. To address this, we propose a data-efficient distillation framework (DED) that optimizes the Pareto frontier of reasoning distillation. Inspired by the on-policy learning and diverse roll-out strategies of reinforcement learning, the key idea of our approach is threefold: (1) We identify that benchmark scores alone do not determine an effective teacher model. Through comprehensive comparisons of leading reasoning LLMs, we develop a method to select an optimal teacher model. (2) While scaling distillation can enhance reasoning, it often degrades out-of-domain performance. A carefully curated, smaller corpus achieves a balanced trade-off between in-domain and out-of-domain capabilities. (3) Diverse reasoning trajectories encourage the student model to develop robust reasoning skills. We validate our method through evaluations on mathematical reasoning (AIME 2024/2025, MATH-500) and code generation (LiveCodeBench), achieving state-of-the-art results with only 0.8k carefully curated examples, bypassing the need for extensive scaling. Our systematic analysis demonstrates that DED outperforms existing methods by considering factors beyond superficial hardness, token length, or teacher model capability. This work offers a practical and efficient pathway to advanced reasoning while preserving general capabilities.', 'abstract_zh': '大型语言模型在算法编码和数学问题解决等任务中展示了显著的推理能力。通过扩展语料库和结合强化学习和监督微调的多阶段训练，近年来的方法有所改进。尽管一些方法表明，通过仅知识蒸馏一个小但针对性的数据集可以激励推理，但推理能力的标度定律仍在形成中，增加了计算成本。为了解决这一问题，我们提出了一种数据高效蒸馏框架（DED），以优化推理蒸馏的帕累托前沿。受强化学习的在线学习和多样化展开策略的启发，我们的方法的核心思路包括三个方面：（1）我们发现基准成绩并不能决定有效的教师模型。通过全面比较领先的推理大型语言模型，我们开发了一种选择最优教师模型的方法。（2）虽然扩展蒸馏可以提升推理能力，但往往会降低领域外性能。精心编纂的小型语料库在领域内和领域外能力之间实现了平衡贸易。（3）多样化的推理轨迹促使学生模型发展出稳健的推理技能。我们通过数学推理（AIME 2024/2025、MATH-500）和代码生成（LiveCodeBench）评估，仅使用0.8k精心编纂的示例实现了最先进的结果，避免了扩展的需要。系统分析表明，DED 能够超越现有方法，考虑了比表面上难度、标记长度或教师模型能力更广泛的因素。这项工作提供了一条实用且高效的途径，以实现高级推理能力，同时保留一般能力。', 'title_zh': '超越标度定律：一种高效的数据蒸馏推理框架'}
{'arxiv_id': 'arXiv:2508.09874', 'title': 'Memory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models', 'authors': 'Jiaqi Cao, Jiarui Wang, Rubin Wei, Qipeng Guo, Kai Chen, Bowen Zhou, Zhouhan Lin', 'link': 'https://arxiv.org/abs/2508.09874', 'abstract': "Large Language Models (LLMs) have shown strong abilities in general language tasks, yet adapting them to specific domains remains a challenge. Current method like Domain Adaptive Pretraining (DAPT) requires costly full-parameter training and suffers from catastrophic forgetting. Meanwhile, Retrieval-Augmented Generation (RAG) introduces substantial inference latency due to expensive nearest-neighbor searches and longer context. This paper introduces Memory Decoder, a plug-and-play pretrained memory that enables efficient domain adaptation without changing the original model's parameters. Memory Decoder employs a small transformer decoder that learns to imitate the behavior of an external non-parametric retriever. Once trained, Memory Decoder can be seamlessly integrated with any pretrained language model that shares the same tokenizer, requiring no model-specific modifications. Experimental results demonstrate that Memory Decoder enables effective adaptation of various Qwen and Llama models to three distinct specialized domains: biomedicine, finance, and law, reducing perplexity by an average of 6.17 points. Overall, Memory Decoder introduces a novel paradigm centered on a specially pretrained memory component designed for domain-specific adaptation. This memory architecture can be integrated in a plug-and-play manner, consistently enhancing performance across multiple models within the target domain.", 'abstract_zh': '大型语言模型在通用语言任务中展示了强大的能力，但将其适应到特定领域仍然是一个挑战。当前的方法如领域适应预训练（DAPT）需要成本高昂的全参数训练，并且容易出现灾难性遗忘。同时，检索增强生成（RAG）因昂贵的最近邻搜索和更长的上下文导致推理延迟增加。本文引入了Memory Decoder，这是一种即插即用的预训练记忆组件，能够在不改变原始模型参数的情况下实现高效的领域适应。Memory Decoder采用一个小型Transformer解码器，学习模仿一个外部非参数检索器的行为。经过训练后，Memory Decoder可以无缝地与任何共享同一分词器的预训练语言模型集成，无需进行特定于模型的修改。实验结果表明，Memory Decoder使Qwen和Llama等各种模型能够有效适应生物医学、金融和法律三个不同的专门领域， perplexity平均降低6.17点。总体而言，Memory Decoder提出了一个以特别预训练的记忆组件为中心的新范式，该记忆架构可以以即插即用的方式集成，在目标领域内的多个模型中一致地提升性能。', 'title_zh': '记忆解码器：一种用于大型语言模型的预制可插拔记忆模块'}
{'arxiv_id': 'arXiv:2508.09853', 'title': 'STREAM (ChemBio): A Standard for Transparently Reporting Evaluations in AI Model Reports', 'authors': 'Tegan McCaslin, Jide Alaga, Samira Nedungadi, Seth Donoughe, Tom Reed, Rishi Bommasani, Chris Painter, Luca Righetti', 'link': 'https://arxiv.org/abs/2508.09853', 'abstract': 'Evaluations of dangerous AI capabilities are important for managing catastrophic risks. Public transparency into these evaluations - including what they test, how they are conducted, and how their results inform decisions - is crucial for building trust in AI development. We propose STREAM (A Standard for Transparently Reporting Evaluations in AI Model Reports), a standard to improve how model reports disclose evaluation results, initially focusing on chemical and biological (ChemBio) benchmarks. Developed in consultation with 23 experts across government, civil society, academia, and frontier AI companies, this standard is designed to (1) be a practical resource to help AI developers present evaluation results more clearly, and (2) help third parties identify whether model reports provide sufficient detail to assess the rigor of the ChemBio evaluations. We concretely demonstrate our proposed best practices with "gold standard" examples, and also provide a three-page reporting template to enable AI developers to implement our recommendations more easily.', 'abstract_zh': '危险AI能力的评估对于管理灾难性风险至关重要。公开透明的评估过程——包括测试的内容、实施方式及其结果如何影响决策——对于建立对AI开发的信任至关重要。我们提出STREAM标准（AI模型报告中透明报告评估的标准），旨在改善模型报告中披露评估结果的方式，初始重点关注化学和生物（ChemBio）基准。该标准在政府、民间社会、学术界和前沿AI公司的23位专家的咨询下制定，目的在于（1）作为实用资源帮助AI开发者更清晰地呈现评估结果，（2）帮助第三方识别模型报告是否提供了足够的细节以评估ChemBio评估的严谨性。我们通过“金标准”示例具体展示我们提出的最佳实践，并提供一个三页的报告模板，以便AI开发者更轻松地实施我们的建议。', 'title_zh': 'STREAM (ChemBio): 一种透明报告AI模型评估的标准'}
{'arxiv_id': 'arXiv:2508.09852', 'title': 'Perceptual Reality Transformer: Neural Architectures for Simulating Neurological Perception Conditions', 'authors': 'Baihan Lin', 'link': 'https://arxiv.org/abs/2508.09852', 'abstract': "Neurological conditions affecting visual perception create profound experiential divides between affected individuals and their caregivers, families, and medical professionals. We present the Perceptual Reality Transformer, a comprehensive framework employing six distinct neural architectures to simulate eight neurological perception conditions with scientifically-grounded visual transformations. Our system learns mappings from natural images to condition-specific perceptual states, enabling others to experience approximations of simultanagnosia, prosopagnosia, ADHD attention deficits, visual agnosia, depression-related changes, anxiety tunnel vision, and Alzheimer's memory effects. Through systematic evaluation across ImageNet and CIFAR-10 datasets, we demonstrate that Vision Transformer architectures achieve optimal performance, outperforming traditional CNN and generative approaches. Our work establishes the first systematic benchmark for neurological perception simulation, contributes novel condition-specific perturbation functions grounded in clinical literature, and provides quantitative metrics for evaluating simulation fidelity. The framework has immediate applications in medical education, empathy training, and assistive technology development, while advancing our fundamental understanding of how neural networks can model atypical human perception.", 'abstract_zh': '神经系统条件影响视觉感知，在受这些条件影响的个体与其护理人员、家庭成员和医疗专业人员之间创造出深刻的经验差异。我们提出了一种全面的框架——感知现实转换器，该框架采用六种不同的神经架构来模拟八种神经系统感知条件的科学依据视觉变换。我们的系统学习从自然图像到特定感知状态的映射，使他人能够体验似动性失认、面孔失认、注意缺陷多动障碍注意力缺陷、视觉失认、与抑郁相关的改变、焦虑导致的隧道视野以及阿尔茨海默病的记忆效应。通过对ImageNet和CIFAR-10数据集的系统评估，我们证明了视觉变换器架构实现了最优性能，超过了传统的CNN和生成方法。我们的工作建立了首个系统的神经系统感知模拟基准，贡献了基于临床文献的新颖条件特定的扰动函数，并提供了评估模拟保真度的定量指标。该框架在医疗教育、共情训练和辅助技术开发中具有即刻应用价值，同时推进了我们对神经网络如何模拟异常人类感知的基本理解。', 'title_zh': '感知现实变换器：模拟神经感知条件的神经架构'}
{'arxiv_id': 'arXiv:2508.09848', 'title': 'PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts', 'authors': 'Mo Yu, Tsz Ting Chung, Chulun Zhou, Tong Li, Rui Lu, Jiangnan Li, Liyan Xu, Haoshu Lu, Ning Zhang, Jing Li, Jie Zhou', 'link': 'https://arxiv.org/abs/2508.09848', 'abstract': "We introduce PRELUDE, a benchmark for evaluating long-context understanding through the task of determining whether a character's prequel story is consistent with the canonical narrative of the original book. Our task poses a stronger demand for global comprehension and deep reasoning than existing benchmarks -- as the prequels are not part of the original story, assessing their plausibility typically requires searching and integrating information that is only indirectly related. Empirically, 88% of instances require evidence from multiple parts of the narrative. Experimental results highlight the challenge of our task: in-context learning, RAG and in-domain training with state-of-the-art LLMs, and commercial DeepResearch services, lag behind humans by >15%. A further human study reveals that models often produce correct answers with flawed reasoning, leading to an over 30% gap in reasoning accuracy compared to humans. These findings underscore the substantial room for improvement in long-context understanding and reasoning.", 'abstract_zh': '我们介绍了PRELUDE，一个用于评估长上下文理解的基准，通过判断人物前传故事是否与原书 canonical 教义叙述一致的任务来进行评估。我们的任务对全局理解和深度推理提出了比现有基准更高的要求——因为前传不在原故事中，评估其可信度通常需要寻找和整合只有间接关联的信息。根据实验，88% 的实例需要来自叙述多个部分的证据。实验结果突显了我们任务的挑战性：上下文学习、RAG 和领域内训练与最先进的语言模型以及商业 DeepResearch 服务相比，落后于人类超过 15%。进一步的人类研究发现，模型经常以错误的推理得出正确的答案，导致推理准确性与人类相比存在超过 30% 的差距。这些发现强调了长上下文理解与推理方面的显著改进空间。', 'title_zh': 'Prelude: 一个需具备长段落全局理解和推理能力的基准测试'}
{'arxiv_id': 'arXiv:2508.09834', 'title': 'Speed Always Wins: A Survey on Efficient Architectures for Large Language Models', 'authors': 'Weigao Sun, Jiaxi Hu, Yucheng Zhou, Jusen Du, Disen Lan, Kexin Wang, Tong Zhu, Xiaoye Qu, Yu Zhang, Xiaoyu Mo, Daizong Liu, Yuxuan Liang, Wenliang Chen, Guoqi Li, Yu Cheng', 'link': 'https://arxiv.org/abs/2508.09834', 'abstract': 'Large Language Models (LLMs) have delivered impressive results in language understanding, generation, reasoning, and pushes the ability boundary of multimodal models. Transformer models, as the foundation of modern LLMs, offer a strong baseline with excellent scaling properties. However, the traditional transformer architecture requires substantial computations and poses significant obstacles for large-scale training and practical deployment. In this survey, we offer a systematic examination of innovative LLM architectures that address the inherent limitations of transformers and boost the efficiency. Starting from language modeling, this survey covers the background and technical details of linear and sparse sequence modeling methods, efficient full attention variants, sparse mixture-of-experts, hybrid model architectures incorporating the above techniques, and emerging diffusion LLMs. Additionally, we discuss applications of these techniques to other modalities and consider their wider implications for developing scalable, resource-aware foundation models. By grouping recent studies into the above category, this survey presents a blueprint of modern efficient LLM architectures, and we hope this could help motivate future research toward more efficient, versatile AI systems.', 'abstract_zh': '大规模语言模型（LLMs）在语言理解和生成、推理方面取得了令人印象深刻的成果，并推动了多模态模型的能力边界。传统的转换器架构提供了强大的基础，具有出色的可扩展性，但其所需的巨大计算量和大规模训练及实际部署的显著障碍，限制了其应用。本文综述了创新的LLM架构，克服了转换器的固有限制，提升了效率。本文从语言建模出发，涵盖了线性及稀疏序列建模方法、高效全注意机制变体、稀疏专家混合模型架构以及结合上述技术的新兴扩散LLM，并讨论了这些技术在其他模态中的应用及其对开发可扩展和资源意识基础模型的更广泛影响。通过将近期研究归类于此，本文构建了现代高效LLM架构的蓝图，我们希望这能够促进未来对更高效、更具包容性的AI系统的研究。', 'title_zh': '速度始终胜利：大规模语言模型高效架构综述'}
{'arxiv_id': 'arXiv:2508.09832', 'title': 'Exploring the Potential of Large Language Models in Fine-Grained Review Comment Classification', 'authors': 'Linh Nguyen, Chunhua Liu, Hong Yi Lin, Patanamon Thongtanunam', 'link': 'https://arxiv.org/abs/2508.09832', 'abstract': 'Code review is a crucial practice in software development. As code review nowadays is lightweight, various issues can be identified, and sometimes, they can be trivial. Research has investigated automated approaches to classify review comments to gauge the effectiveness of code reviews. However, previous studies have primarily relied on supervised machine learning, which requires extensive manual annotation to train the models effectively. To address this limitation, we explore the potential of using Large Language Models (LLMs) to classify code review comments. We assess the performance of LLMs to classify 17 categories of code review comments. Our results show that LLMs can classify code review comments, outperforming the state-of-the-art approach using a trained deep learning model. In particular, LLMs achieve better accuracy in classifying the five most useful categories, which the state-of-the-art approach struggles with due to low training examples. Rather than relying solely on a specific small training data distribution, our results show that LLMs provide balanced performance across high- and low-frequency categories. These results suggest that the LLMs could offer a scalable solution for code review analytics to improve the effectiveness of the code review process.', 'abstract_zh': '代码审查是软件开发中的关键实践。当前的代码审查轻量级，可以识别出各种问题，有时这些问题可能是琐碎的。研究已经调查了自动方法来分类审查评论以评估代码审查的有效性。然而，之前的研究所主要依赖监督机器学习，这需要大量的手动标注来有效训练模型。为了解决这一限制，我们探索了使用大型语言模型（LLMs）来分类代码审查评论的潜力。我们评估了LLMs在分类17类代码审查评论方面的性能。结果表明，LLMs能够有效地分类代码审查评论，其性能优于使用训练有素的深度学习模型的最新方法。特别是，在分类五个最有用的类别方面，LLMs获得更高的准确性，而最新的方法由于训练示例较少而难以应对。我们的结果表明，LLMs在高频和低频类别上提供了均衡的性能，而不是仅仅依赖于特定的小训练数据分布。这些结果表明，LLMs可能为代码审查分析提供一种可扩展的解决方案，以提高代码审查过程的有效性。', 'title_zh': '探索大型语言模型在细粒度评论分类中的潜力'}
{'arxiv_id': 'arXiv:2508.09830', 'title': 'RayletDF: Raylet Distance Fields for Generalizable 3D Surface Reconstruction from Point Clouds or Gaussians', 'authors': 'Shenxing Wei, Jinxi Li, Yafei Yang, Siyuan Zhou, Bo Yang', 'link': 'https://arxiv.org/abs/2508.09830', 'abstract': 'In this paper, we present a generalizable method for 3D surface reconstruction from raw point clouds or pre-estimated 3D Gaussians by 3DGS from RGB images. Unlike existing coordinate-based methods which are often computationally intensive when rendering explicit surfaces, our proposed method, named RayletDF, introduces a new technique called raylet distance field, which aims to directly predict surface points from query rays. Our pipeline consists of three key modules: a raylet feature extractor, a raylet distance field predictor, and a multi-raylet blender. These components work together to extract fine-grained local geometric features, predict raylet distances, and aggregate multiple predictions to reconstruct precise surface points. We extensively evaluate our method on multiple public real-world datasets, demonstrating superior performance in surface reconstruction from point clouds or 3D Gaussians. Most notably, our method achieves exceptional generalization ability, successfully recovering 3D surfaces in a single-forward pass across unseen datasets in testing.', 'abstract_zh': '本文提出了一种用于从原始点云或预先估计的3D高斯分布恢复3D表面的通用方法，该方法基于RGB图像的3DGS。不同于现有基于坐标的方法在绘制显式表面时往往计算密集，我们提出的方法RayletDF引入了一种新的技术——射线距离场，旨在直接从查询射线预测表面点。我们的pipeline由三个关键模块组成：射线特征提取器、射线距离场预测器和多射线融合器。这些组件协同工作以提取细粒度的局部几何特征、预测射线距离，并通过聚合多个预测来重建精确的表面点。我们在多个公开的真实世界数据集上进行了广泛评估，证明了该方法在从点云或3D高斯分布恢复表面方面的优越性能。尤为 noteworthy的是，该方法表现出色的泛化能力，在测试中成功在同一前向传递中恢复未见数据集的3D表面。', 'title_zh': 'RayletDF: Raylet 距离场在点云或高斯分布的一般化3D表面重建中的应用'}
{'arxiv_id': 'arXiv:2508.09820', 'title': 'Provable In-Context Vector Arithmetic via Retrieving Task Concepts', 'authors': 'Dake Bu, Wei Huang, Andi Han, Atsushi Nitanda, Qingfu Zhang, Hau-San Wong, Taiji Suzuki', 'link': 'https://arxiv.org/abs/2508.09820', 'abstract': 'In-context learning (ICL) has garnered significant attention for its ability to grasp functions/tasks from demonstrations. Recent studies suggest the presence of a latent task/function vector in LLMs during ICL. Merullo et al. (2024) showed that LLMs leverage this vector alongside the residual stream for Word2Vec-like vector arithmetic, solving factual-recall ICL tasks. Additionally, recent work empirically highlighted the key role of Question-Answer data in enhancing factual-recall capabilities. Despite these insights, a theoretical explanation remains elusive. To move one step forward, we propose a theoretical framework building on empirically grounded hierarchical concept modeling. We develop an optimization theory, showing how nonlinear residual transformers trained via gradient descent on cross-entropy loss perform factual-recall ICL tasks via vector arithmetic. We prove 0-1 loss convergence and show the strong generalization, including robustness to concept recombination and distribution shifts. These results elucidate the advantages of transformers over static embedding predecessors. Empirical simulations corroborate our theoretical insights.', 'abstract_zh': '上下文学习（ICL）因其从演示中掌握功能/任务的能力而引起了广泛关注。近期研究表明，在上下文学习过程中，大型语言模型（LLMs）中存在潜在的任务/函数向量。Merullo等人（2024）展示了LLMs在Word2Vec-like向量算术中利用这一向量与剩余流，解决事实回忆的上下文学习任务。此外，近期研究实证地强调了问题-答案数据在增强事实回忆能力中的关键作用。尽管取得这些进展，但缺乏理论解释。为推进研究，我们提出一个基于经验验证的层次概念建模的理论框架。我们发展了一种优化理论，展示通过交叉熵损失梯度下降训练的非线性剩余变换器如何通过向量算术执行事实回忆的上下文学习任务，并证明0-1损失收敛性，展示了强大的泛化能力，包括对概念重组和分布转移的鲁棒性。这些结果阐明了变换器相比于静态嵌入前驱的优势。实证模拟验证了我们的理论洞察。', 'title_zh': '基于检索任务概念的可证明上下文向量算术'}
{'arxiv_id': 'arXiv:2508.09811', 'title': 'TRACE: Learning 3D Gaussian Physical Dynamics from Multi-view Videos', 'authors': 'Jinxi Li, Ziyang Song, Bo Yang', 'link': 'https://arxiv.org/abs/2508.09811', 'abstract': "In this paper, we aim to model 3D scene geometry, appearance, and physical information just from dynamic multi-view videos in the absence of any human labels. By leveraging physics-informed losses as soft constraints or integrating simple physics models into neural nets, existing works often fail to learn complex motion physics, or doing so requires additional labels such as object types or masks. We propose a new framework named TRACE to model the motion physics of complex dynamic 3D scenes. The key novelty of our method is that, by formulating each 3D point as a rigid particle with size and orientation in space, we directly learn a translation rotation dynamics system for each particle, explicitly estimating a complete set of physical parameters to govern the particle's motion over time. Extensive experiments on three existing dynamic datasets and one newly created challenging synthetic datasets demonstrate the extraordinary performance of our method over baselines in the task of future frame extrapolation. A nice property of our framework is that multiple objects or parts can be easily segmented just by clustering the learned physical parameters.", 'abstract_zh': '本文旨在仅从动态多视角视频中建模3D场景的几何、外观和物理信息，而不使用任何human标签。通过利用物理约束或在神经网络中集成简单的物理模型，现有工作往往难以学习复杂的运动物理，或者学习这些物理需要额外的标签如物体类型或掩码。我们提出了一种新的框架TRACE来建模复杂动态3D场景的运动物理。我们方法的主要创新之处在于，将每个3D点公式化为具有大小和空间方向的刚体粒子，直接学习每个粒子的平移旋转动力学系统，明确估计一组完整的物理参数来控制粒子随时间的运动。在三个现有动态数据集和一个新创建的具有挑战性的合成数据集上进行的广泛实验表明，与基线方法相比，我们的方法在未来帧外推任务中具有出色的性能。我们框架的一个良好特性是，只需通过聚类学习到的物理参数即可轻松地分割多个物体或部分。', 'title_zh': 'TRACE: 从多视角视频中学习三维高斯物理动力学'}
{'arxiv_id': 'arXiv:2508.09809', 'title': 'A Comprehensive Survey of Datasets for Clinical Mental Health AI Systems', 'authors': 'Aishik Mandal, Prottay Kumar Adhikary, Hiba Arnaout, Iryna Gurevych, Tanmoy Chakraborty', 'link': 'https://arxiv.org/abs/2508.09809', 'abstract': 'Mental health disorders are rising worldwide. However, the availability of trained clinicians has not scaled proportionally, leaving many people without adequate or timely support. To bridge this gap, recent studies have shown the promise of Artificial Intelligence (AI) to assist mental health diagnosis, monitoring, and intervention. However, the development of efficient, reliable, and ethical AI to assist clinicians is heavily dependent on high-quality clinical training datasets. Despite growing interest in data curation for training clinical AI assistants, existing datasets largely remain scattered, under-documented, and often inaccessible, hindering the reproducibility, comparability, and generalizability of AI models developed for clinical mental health care. In this paper, we present the first comprehensive survey of clinical mental health datasets relevant to the training and development of AI-powered clinical assistants. We categorize these datasets by mental disorders (e.g., depression, schizophrenia), data modalities (e.g., text, speech, physiological signals), task types (e.g., diagnosis prediction, symptom severity estimation, intervention generation), accessibility (public, restricted or private), and sociocultural context (e.g., language and cultural background). Along with these, we also investigate synthetic clinical mental health datasets. Our survey identifies critical gaps such as a lack of longitudinal data, limited cultural and linguistic representation, inconsistent collection and annotation standards, and a lack of modalities in synthetic data. We conclude by outlining key challenges in curating and standardizing future datasets and provide actionable recommendations to facilitate the development of more robust, generalizable, and equitable mental health AI systems.', 'abstract_zh': '全球范围内心理健康障碍呈上升趋势。然而，受过训练的临床医生的 availability 并未相应增加，导致许多人无法获得足够的及时支持。为了弥合这一差距，近期研究表明，人工智能（AI）在协助心理健康诊断、监测和干预方面具有潜力。然而，开发高效、可靠且符合伦理的AI来协助临床医生，强烈依赖于高质量的临床训练数据集。尽管对训练临床AI助手的数据整理表现出日益浓厚的兴趣，但现有的数据集仍然分散、记录不足且往往难以访问，阻碍了为临床心理健康护理开发的AI模型的可再现性、可比性和泛化性。本文介绍了首个全面的临床心理健康数据集调查，这些数据集与AI驱动的临床助手的训练和发展相关。我们按精神障碍（如抑郁、精神分裂症）、数据模态（如文本、语音、生理信号）、任务类型（如诊断预测、症状严重程度估计、干预生成）、可访问性（公共、受限或私有）以及社会文化背景（如语言和文化背景）对这些数据集进行分类。此外，我们还调查了合成的临床心理健康数据集。我们的调查指出了诸如纵向数据缺乏、文化与语言代表性不足、数据收集和标注标准不一致以及合成数据模态缺乏等关键差距。最后，我们概述了未来数据集整理和标准化的关键挑战，并提供具体的建议以促进开发更稳健、更具泛化性和公平性的心理健康AI系统。', 'title_zh': '临床心理健康AI系统中数据集综述'}
{'arxiv_id': 'arXiv:2508.09805', 'title': 'Automated Segmentation of Coronal Brain Tissue Slabs for 3D Neuropathology', 'authors': 'Jonathan Williams Ramirez, Dina Zemlyanker, Lucas Deden-Binder, Rogeny Herisse, Erendira Garcia Pallares, Karthik Gopinath, Harshvardhan Gazula, Christopher Mount, Liana N. Kozanno, Michael S. Marshall, Theresa R. Connors, Matthew P. Frosch, Mark Montine, Derek H. Oakley, Christine L. Mac Donald, C. Dirk Keene, Bradley T. Hyman, Juan Eugenio Iglesias', 'link': 'https://arxiv.org/abs/2508.09805', 'abstract': 'Advances in image registration and machine learning have recently enabled volumetric analysis of \\emph{postmortem} brain tissue from conventional photographs of coronal slabs, which are routinely collected in brain banks and neuropathology laboratories worldwide. One caveat of this methodology is the requirement of segmentation of the tissue from photographs, which currently requires costly manual intervention. In this article, we present a deep learning model to automate this process. The automatic segmentation tool relies on a U-Net architecture that was trained with a combination of \\textit{(i)}1,414 manually segmented images of both fixed and fresh tissue, from specimens with varying diagnoses, photographed at two different sites; and \\textit{(ii)}~2,000 synthetic images with randomized contrast and corresponding masks generated from MRI scans for improved generalizability to unseen photographic setups. Automated model predictions on a subset of photographs not seen in training were analyzed to estimate performance compared to manual labels -- including both inter- and intra-rater variability. Our model achieved a median Dice score over 0.98, mean surface distance under 0.4~mm, and 95\\% Hausdorff distance under 1.60~mm, which approaches inter-/intra-rater levels. Our tool is publicly available at this http URL.', 'abstract_zh': '图像注册和机器学习的进步最近使得可以从常规收集的冠状切片的常规照片中分析死后的脑组织体素，这在全球各地的脑银行和 neuropathology 实验室中是很常见的。这一方法的一个局限性是需要对照片进行组织分割，目前这要求昂贵的手动干预。本文介绍了使用深度学习模型来自动化这一过程。该自动分割工具基于一种采用了两种不同位置拍摄的固定和新鲜组织的 1,414 张手动分割图像的 U-Net 架构，以及 2,000 张来自 MRI 扫描并具有随机对比度的合成图像及其对应的掩码，以提高其对未见过的照片设置的泛化能力。在训练数据之外的一小部分照片上进行自动模型预测分析，以估计其性能并与手动标签进行比较，包括不同评估者之间的变异性。我们的模型达到了中位Dice得分为0.98以上，平均表面距离小于0.4毫米，95% Hausdorff距离小于1.60毫米，接近不同评估者之间的水平。我们的工具可在以下网址公开获取。', 'title_zh': '冠状脑组织切片的自动化分割以进行三维神经病理学研究'}
{'arxiv_id': 'arXiv:2508.09801', 'title': 'Explainable Ensemble Learning for Graph-Based Malware Detection', 'authors': 'Hossein Shokouhinejad, Roozbeh Razavi-Far, Griffin Higgins, Ali A Ghorbani', 'link': 'https://arxiv.org/abs/2508.09801', 'abstract': 'Malware detection in modern computing environments demands models that are not only accurate but also interpretable and robust to evasive techniques. Graph neural networks (GNNs) have shown promise in this domain by modeling rich structural dependencies in graph-based program representations such as control flow graphs (CFGs). However, single-model approaches may suffer from limited generalization and lack interpretability, especially in high-stakes security applications. In this paper, we propose a novel stacking ensemble framework for graph-based malware detection and explanation. Our method dynamically extracts CFGs from portable executable (PE) files and encodes their basic blocks through a two-step embedding strategy. A set of diverse GNN base learners, each with a distinct message-passing mechanism, is used to capture complementary behavioral features. Their prediction outputs are aggregated by a meta-learner implemented as an attention-based multilayer perceptron, which both classifies malware instances and quantifies the contribution of each base model. To enhance explainability, we introduce an ensemble-aware post-hoc explanation technique that leverages edge-level importance scores generated by a GNN explainer and fuses them using the learned attention weights. This produces interpretable, model-agnostic explanations aligned with the final ensemble decision. Experimental results demonstrate that our framework improves classification performance while providing insightful interpretations of malware behavior.', 'abstract_zh': '现代计算环境中恶意软件检测需要既准确又可解释且对规避技术具有鲁棒性的模型。基于图的恶意软件检测和解释的新型堆叠ensemble框架。', 'title_zh': '基于图的恶意软件检测的可解释集成学习'}
{'arxiv_id': 'arXiv:2508.09791', 'title': 'LibRec: Benchmarking Retrieval-Augmented LLMs for Library Migration Recommendations', 'authors': 'Junxiao Han, Yarong Wang, Xiaodong Gu, Cuiyun Gao, Yao Wan, Song Han, David Lo, Shuiguang Deng', 'link': 'https://arxiv.org/abs/2508.09791', 'abstract': "In this paper, we propose LibRec, a novel framework that integrates the capabilities of LLMs with retrieval-augmented generation(RAG) techniques to automate the recommendation of alternative libraries. The framework further employs in-context learning to extract migration intents from commit messages to enhance the accuracy of its recommendations. To evaluate the effectiveness of LibRec, we introduce LibEval, a benchmark designed to assess the performance in the library migration recommendation task. LibEval comprises 2,888 migration records associated with 2,368 libraries extracted from 2,324 Python repositories. Each migration record captures source-target library pairs, along with their corresponding migration intents and intent types. Based on LibEval, we evaluated the effectiveness of ten popular LLMs within our framework, conducted an ablation study to examine the contributions of key components within our framework, explored the impact of various prompt strategies on the framework's performance, assessed its effectiveness across various intent types, and performed detailed failure case analyses.", 'abstract_zh': '在本文中，我们提出了LibRec框架，该框架结合了大语言模型（LLM）和检索增强生成（RAG）技术的能力，以自动化推荐替代库。该框架进一步采用上下文学习来从提交日志中提取迁移意图，以提高其推荐的准确性。为了评估LibRec的有效性，我们引入了LibEval基准，该基准用于评估库迁移推荐任务的性能。LibEval包含来自2,324个Python仓库的2,888条迁移记录，涉及2,368个库。每条迁移记录包含源-目标库对，以及相应的迁移意图和意图类型。基于LibEval，我们在框架中评估了十种流行的LLM的有效性，进行了消融研究以检查框架中关键组件的贡献，探索了各种提示策略对框架性能的影响，评估了其在不同意图类型下的有效性，并进行了详细的失败案例分析。', 'title_zh': 'LibRec: 编目迁移推荐中增强检索的LLM基准测试'}
{'arxiv_id': 'arXiv:2508.09787', 'title': 'Prototype Training with Dual Pseudo-Inverse and Optimized Hidden Activations', 'authors': 'Mauro Tucci', 'link': 'https://arxiv.org/abs/2508.09787', 'abstract': 'We present Proto-PINV+H, a fast training paradigm that combines closed-form weight computation with gradient-based optimisation of a small set of synthetic inputs, soft labels, and-crucially-hidden activations. At each iteration we recompute all weight matrices in closed form via two (or more) ridge-regularised pseudo-inverse solves, while updating only the prototypes with Adam. The trainable degrees of freedom are thus shifted from weight space to data/activation space. On MNIST (60k train, 10k test) and Fashion-MNIST (60k train, 10k test), our method reaches 97.8% and 89.3% test accuracy on the official 10k test sets, respectively, in 3.9s--4.5s using approximately 130k trainable parameters and only 250 epochs on an RTX 5060 (16GB). We provide a multi-layer extension (optimised activations at each hidden stage), learnable ridge parameters, optional PCA/PLS projections, and theory linking the condition number of prototype matrices to generalisation. The approach yields favourable accuracy--speed--size trade-offs against ELM, random-feature ridge, and shallow MLPs trained by back-propagation.', 'abstract_zh': 'Proto-PINV+H: 一种结合闭形式权重计算和基于梯度的小规模合成输入、软标签及关键隐层层活动的梯度优化的快速训练范式', 'title_zh': '双伪逆与优化隐藏激活的原型训练'}
{'arxiv_id': 'arXiv:2508.09786', 'title': 'Adoption of Explainable Natural Language Processing: Perspectives from Industry and Academia on Practices and Challenges', 'authors': 'Mahdi Dhaini, Tobias Müller, Roksoliana Rabets, Gjergji Kasneci', 'link': 'https://arxiv.org/abs/2508.09786', 'abstract': "The field of explainable natural language processing (NLP) has grown rapidly in recent years. The growing opacity of complex models calls for transparency and explanations of their decisions, which is crucial to understand their reasoning and facilitate deployment, especially in high-stakes environments. Despite increasing attention given to explainable NLP, practitioners' perspectives regarding its practical adoption and effectiveness remain underexplored. This paper addresses this research gap by investigating practitioners' experiences with explainability methods, specifically focusing on their motivations for adopting such methods, the techniques employed, satisfaction levels, and the practical challenges encountered in real-world NLP applications. Through a qualitative interview-based study with industry practitioners and complementary interviews with academic researchers, we systematically analyze and compare their perspectives. Our findings reveal conceptual gaps, low satisfaction with current explainability methods, and highlight evaluation challenges. Our findings emphasize the need for clear definitions and user-centric frameworks for better adoption of explainable NLP in practice.", 'abstract_zh': '可解释自然语言处理（NLP）领域在过去几年中得到了快速发展。随着复杂模型透明度的降低，迫切需要对其决策进行透明化和解释，这对于理解其推理过程以及在高风险环境中促进其部署至关重要。尽管对可解释NLP的关注不断增加，但从业者关于其实际应用和效果的观点仍缺乏探索。本文通过调查从业者在采用可解释性方法方面的体验，具体关注其采用动机、所运用的技术、满意度以及在实际NLP应用中遇到的实际挑战，填补了这一研究空白。通过面向工业从业者进行质性访谈，并辅以学术研究人员的访谈，我们系统地分析和比较了他们的观点。研究发现揭示了概念上的差距，当前可解释性方法的低满意度，以及评估挑战。研究结果强调了需要明确的定义和以用户为中心的框架，以便更好地在实践中采用可解释的NLP。', 'title_zh': '可解释自然语言处理的采用：来自行业和学术界的实践与挑战视角'}
{'arxiv_id': 'arXiv:2508.09780', 'title': 'Combinative Matching for Geometric Shape Assembly', 'authors': 'Nahyuk Lee, Juhong Min, Junhong Lee, Chunghyun Park, Minsu Cho', 'link': 'https://arxiv.org/abs/2508.09780', 'abstract': "This paper introduces a new shape-matching methodology, combinative matching, to combine interlocking parts for geometric shape assembly. Previous methods for geometric assembly typically rely on aligning parts by finding identical surfaces between the parts as in conventional shape matching and registration. In contrast, we explicitly model two distinct properties of interlocking shapes: 'identical surface shape' and 'opposite volume occupancy.' Our method thus learns to establish correspondences across regions where their surface shapes appear identical but their volumes occupy the inverted space to each other. To facilitate this process, we also learn to align regions in rotation by estimating their shape orientations via equivariant neural networks. The proposed approach significantly reduces local ambiguities in matching and allows a robust combination of parts in assembly. Experimental results on geometric assembly benchmarks demonstrate the efficacy of our method, consistently outperforming the state of the art. Project page: this https URL.", 'abstract_zh': '这篇论文介绍了一种新的形状匹配方法——组合匹配，用于几何形状装配。以往的几何装配方法通常依赖于通过找到部件之间的相同表面来进行对齐，类似于传统的形状匹配和注册。相比之下，我们明确地建模了嵌锁形状的两种不同属性：“相同表面形状”和“相反体积占用”。因此，我们的方法学会在表面形状看似相同但体积却占据彼此相反空间的区域建立对应关系。为了促进这一过程，我们还学习通过不变神经网络估计形状方向来对齐旋转区域。所提出的方法显著减少了匹配中的局部歧义，并允许装配过程中部件的稳健组合。在几何装配基准上的实验结果表明，该方法的有效性一致超越了现有最佳方法。项目页面：这个 https URL。', 'title_zh': '几何形状装配的组合匹配'}
{'arxiv_id': 'arXiv:2508.09776', 'title': 'Can LLM-Generated Textual Explanations Enhance Model Classification Performance? An Empirical Study', 'authors': 'Mahdi Dhaini, Juraj Vladika, Ege Erdogan, Zineb Attaoui, Gjergji Kasneci', 'link': 'https://arxiv.org/abs/2508.09776', 'abstract': 'In the rapidly evolving field of Explainable Natural Language Processing (NLP), textual explanations, i.e., human-like rationales, are pivotal for explaining model predictions and enriching datasets with interpretable labels. Traditional approaches rely on human annotation, which is costly, labor-intensive, and impedes scalability. In this work, we present an automated framework that leverages multiple state-of-the-art large language models (LLMs) to generate high-quality textual explanations. We rigorously assess the quality of these LLM-generated explanations using a comprehensive suite of Natural Language Generation (NLG) metrics. Furthermore, we investigate the downstream impact of these explanations on the performance of pre-trained language models (PLMs) and LLMs across natural language inference tasks on two diverse benchmark datasets. Our experiments demonstrate that automated explanations exhibit highly competitive effectiveness compared to human-annotated explanations in improving model performance. Our findings underscore a promising avenue for scalable, automated LLM-based textual explanation generation for extending NLP datasets and enhancing model performance.', 'abstract_zh': '在快速发展的可解释自然语言处理（NLP）领域，文本解释，即类人的推理，对于解释模型预测和丰富可解释标签的数据集至关重要。传统方法依赖于人工标注，成本高、劳动密集且阻碍了规模化。在本文中，我们提出了一种自动化框架，利用多个最先进的大型语言模型（LLMs）生成高质量的文本解释。我们使用一套全面的自然语言生成（NLG）指标 rigorously 评估这些 LLM 生成解释的质量。此外，我们探讨了这些解释在两个不同基准数据集的自然语言推理任务中对预训练语言模型（PLMs）和 LLMs 性能的下游影响。实验结果表明，自动化解释在提高模型性能方面具有高度竞争力，与人工标注解释相当。我们的发现强调了一条有前景的途径，即利用可扩展和自动化的基于 LLM 的文本解释生成，以扩展 NLP 数据集和增强模型性能。', 'title_zh': 'LLM生成的文本解释能否提升模型分类性能？一项实证研究'}
{'arxiv_id': 'arXiv:2508.09768', 'title': 'Counting Short Trajectories in Elementary Cellular Automata using the Transfer Matrix Method', 'authors': 'Cédric Koller, Barbora Hudcová', 'link': 'https://arxiv.org/abs/2508.09768', 'abstract': "Elementary Cellular Automata (ECAs) exhibit diverse behaviours often categorized by Wolfram's qualitative classification. To provide a quantitative basis for understanding these behaviours, we investigate the global dynamics of such automata and we describe a method that allows us to compute the number of all configurations leading to short attractors in a limited number of time steps. This computation yields exact results in the thermodynamic limit (as the CA grid size grows to infinity), and is based on the Transfer Matrix Method (TMM) that we adapt for our purposes. Specifically, given two parameters $(p, c)$ we are able to compute the entropy of all initial configurations converging to an attractor of size $c$ after $p$ time-steps. By calculating such statistics for various ECA rules, we establish a quantitative connection between the entropy and the qualitative Wolfram classification scheme. Class 1 rules rapidly converge to maximal entropy for stationary states ($c=1$) as $p$ increases. Class 2 rules also approach maximal entropy quickly for appropriate cycle lengths $c$, potentially requiring consideration of translations. Class 3 rules exhibit zero or low finite entropy that saturates after a short transient. Class 4 rules show finite positive entropy, similar to some Class 3 rules. This method provides a precise framework for quantifying trajectory statistics, although its exponential computational cost in $p+c$ restricts practical analysis to short trajectories.", 'abstract_zh': '元胞自动机（ECAs）表现出多样化的行为，常被沃尔夫拉姆定性分类。为理解这些行为提供量化基础，我们研究了此类自动机的全局动力学，并描述了一种方法来计算在有限时间步内导致短吸引子的所有配置数量。该计算在CA网格尺寸趋向无穷大的热力学极限下提供了精确结果，并基于我们为此目的改编的转移矩阵方法（TMM）。具体来说，给定两个参数$(p, c)$，我们能够计算出所有在$p$个时间步后收敛到大小为$c$的吸引子的初始配置的熵。通过为各种ECA规则计算此类统计数据，我们建立了熵与沃尔夫拉姆定性分类方案之间的量化联系。Class 1规则在$p$增加时迅速收敛到稳定态（$c=1$）的最大熵。Class 2规则在合适周期长度$c$下也快速接近最大熵，可能需要考虑平移。Class 3规则显示出零或低的有限熵，在短暂态后饱和。Class 4规则显示出有限正熵，类似于某些Class 3规则。此方法为量化轨迹统计提供了一个精确框架，但由于其在$p+c$方面的指数级计算成本，只适用于短轨迹的实际分析。', 'title_zh': '用转移矩阵方法计数基本细胞自动机中的短轨迹'}
{'arxiv_id': 'arXiv:2508.09765', 'title': 'Enhance the machine learning algorithm performance in phishing detection with keyword features', 'authors': 'Zijiang Yang', 'link': 'https://arxiv.org/abs/2508.09765', 'abstract': "Recently, we can observe a significant increase of the phishing attacks in the Internet. In a typical phishing attack, the attacker sets up a malicious website that looks similar to the legitimate website in order to obtain the end-users' information. This may cause the leakage of the sensitive information and the financial loss for the end-users. To avoid such attacks, the early detection of these websites' URLs is vital and necessary. Previous researchers have proposed many machine learning algorithms to distinguish the phishing URLs from the legitimate ones. In this paper, we would like to enhance these machine learning algorithms from the perspective of feature selection. We propose a novel method to incorporate the keyword features with the traditional features. This method is applied on multiple traditional machine learning algorithms and the experimental results have shown this method is useful and effective. On average, this method can reduce the classification error by 30% for the large dataset. Moreover, its enhancement is more significant for the small dataset. In addition, this method extracts the information from the URL and does not rely on the additional information provided by the third-part service. The best result for the machine learning algorithm using our proposed method has achieved the accuracy of 99.68%.", 'abstract_zh': '近年来，我们观察到互联网上的钓鱼攻击显著增加。在典型的钓鱼攻击中，攻击者设置一个看起来类似于合法网站的恶意网站，以获取终端用户的信息。这可能导致敏感信息泄露和经济损害。为了避免这类攻击，及早检测这些网站的URL至关重要。先前的研究人员提出了许多机器学习算法来区分钓鱼URL和合法URL。在本文中，我们将从特征选择的角度改进这些机器学习算法。我们提出了一种新颖的方法，将关键词特征与传统的特征结合。该方法应用于多种传统机器学习算法，实验结果表明这种方法是有效且有用的。对于大数据集，这种方法可以平均降低分类错误率30%。此外，对于小数据集，其改进更为显著。此外，该方法从URL中提取信息，而不依赖于第三方提供的额外信息。使用我们提出方法的最佳机器学习算法准确率达到99.68%。', 'title_zh': '使用关键词特征增强机器学习算法在钓鱼检测中的性能'}
{'arxiv_id': 'arXiv:2508.09757', 'title': 'NEUBORN: The Neurodevelopmental Evolution framework Using BiOmechanical RemodelliNg', 'authors': 'Nashira Baena, Mariana da Silva, Irina Grigorescu, Aakash Saboo, Saga Masui, Jaques-Donald Tournier, Emma C. Robinson', 'link': 'https://arxiv.org/abs/2508.09757', 'abstract': 'Understanding individual cortical development is essential for identifying deviations linked to neurodevelopmental disorders. However, current normative modelling frameworks struggle to capture fine-scale anatomical details due to their reliance on modelling data within a population-average reference space. Here, we present a novel framework for learning individual growth trajectories from biomechanically constrained, longitudinal, diffeomorphic image registration, implemented via a hierarchical network architecture. Trained on neonatal MRI data from the Developing Human Connectome Project, the method improves the biological plausibility of warps, generating growth trajectories that better follow population-level trends while generating smoother warps, with fewer negative Jacobians, relative to state-of-the-art baselines. The resulting subject-specific deformations provide interpretable, biologically grounded mappings of development. This framework opens new possibilities for predictive modeling of brain maturation and early identification of malformations of cortical development.', 'abstract_zh': '理解个体皮层发育对于识别与神经发育障碍相关的偏差至关重要。然而，当前的规范模型框架由于依赖于在群体平均参考空间内建模数据，难以捕捉到细微的解剖细节。在这里，我们提出了一种新的框架，用于从生物力学约束的纵向 diffeomorphic 图像配准中学习个体生长轨迹，通过分层网络架构实现。该方法在开发人类连接组项目提供的新生儿 MRI 数据上进行训练，改进了拉伸的生物学合理性，生成了更能遵循群体水平趋势、更为平滑的拉伸，负面雅可比数更少，相对于先进的基线方法。由此产生的个体特定变形提供了可解释、生物学支持的发育映射。该框架为预测性建模大脑成熟和早期识别皮层发育异常提供了新可能性。', 'title_zh': 'NEUBORN: 基于生物力学重塑的神经发育进化框架'}
{'arxiv_id': 'arXiv:2508.09746', 'title': 'Region-to-Region: Enhancing Generative Image Harmonization with Adaptive Regional Injection', 'authors': 'Zhiqiu Zhang, Dongqi Fan, Mingjie Wang, Qiang Tang, Jian Yang, Zili Yi', 'link': 'https://arxiv.org/abs/2508.09746', 'abstract': 'The goal of image harmonization is to adjust the foreground in a composite image to achieve visual consistency with the background. Recently, latent diffusion model (LDM) are applied for harmonization, achieving remarkable results. However, LDM-based harmonization faces challenges in detail preservation and limited harmonization ability. Additionally, current synthetic datasets rely on color transfer, which lacks local variations and fails to capture complex real-world lighting conditions. To enhance harmonization capabilities, we propose the Region-to-Region transformation. By injecting information from appropriate regions into the foreground, this approach preserves original details while achieving image harmonization or, conversely, generating new composite data. From this perspective, We propose a novel model R2R. Specifically, we design Clear-VAE to preserve high-frequency details in the foreground using Adaptive Filter while eliminating disharmonious elements. To further enhance harmonization, we introduce the Harmony Controller with Mask-aware Adaptive Channel Attention (MACA), which dynamically adjusts the foreground based on the channel importance of both foreground and background regions. To address the limitation of existing datasets, we propose Random Poisson Blending, which transfers color and lighting information from a suitable region to the foreground, thereby generating more diverse and challenging synthetic images. Using this method, we construct a new synthetic dataset, RPHarmony. Experiments demonstrate the superiority of our method over other methods in both quantitative metrics and visual harmony. Moreover, our dataset helps the model generate more realistic images in real examples. Our code, dataset, and model weights have all been released for open access.', 'abstract_zh': '区域到区域的转换：增强图像谐调能力', 'title_zh': '区域到区域：通过自适应区域注射增强生成图像的一致性 kukai\n vidé'}
{'arxiv_id': 'arXiv:2508.09719', 'title': 'Improving ARDS Diagnosis Through Context-Aware Concept Bottleneck Models', 'authors': 'Anish Narain, Ritam Majumdar, Nikita Narayanan, Dominic Marshall, Sonali Parbhoo', 'link': 'https://arxiv.org/abs/2508.09719', 'abstract': 'Large, publicly available clinical datasets have emerged as a novel resource for understanding disease heterogeneity and to explore personalization of therapy. These datasets are derived from data not originally collected for research purposes and, as a result, are often incomplete and lack critical labels. Many AI tools have been developed to retrospectively label these datasets, such as by performing disease classification; however, they often suffer from limited interpretability. Previous work has attempted to explain predictions using Concept Bottleneck Models (CBMs), which learn interpretable concepts that map to higher-level clinical ideas, facilitating human evaluation. However, these models often experience performance limitations when the concepts fail to adequately explain or characterize the task. We use the identification of Acute Respiratory Distress Syndrome (ARDS) as a challenging test case to demonstrate the value of incorporating contextual information from clinical notes to improve CBM performance. Our approach leverages a Large Language Model (LLM) to process clinical notes and generate additional concepts, resulting in a 10% performance gain over existing methods. Additionally, it facilitates the learning of more comprehensive concepts, thereby reducing the risk of information leakage and reliance on spurious shortcuts, thus improving the characterization of ARDS.', 'abstract_zh': '大型公开临床数据集已成为理解疾病异质性和探索个性化治疗的新型资源。这些数据集源自未 originally collected for research purposes，并且往往不完整且缺乏关键标签。已开发了许多AI工具来回顾性地对这些数据集进行标注，例如进行疾病分类；然而，它们往往缺乏可解释性。先前的工作尝试使用概念瓶颈模型（CBMs）来解释预测，这些模型学习可解释的概念并映射到高级临床概念，有助于人类评估。然而，当概念无法充分解释或表征任务时，这些模型往往会遇到性能限制。我们以急性呼吸窘迫综合征（ARDS）的识别作为具有挑战性的测试案例，证明了结合临床笔记的上下文信息以提高CBM性能的价值。我们的方法利用大语言模型（LLM）处理临床笔记并生成额外的概念，相比现有方法实现了10%的性能提升。此外，这还有助于学习更为全面的概念，从而降低信息泄露和依赖虚假捷径的风险，从而更好地表征ARDS。', 'title_zh': '通过情境感知概念瓶颈模型提升ARDS诊断'}
{'arxiv_id': 'arXiv:2508.09713', 'title': 'Evaluating the Role of Large Language Models in Legal Practice in India', 'authors': 'Rahul Hemrajani', 'link': 'https://arxiv.org/abs/2508.09713', 'abstract': 'The integration of Artificial Intelligence(AI) into the legal profession raises significant questions about the capacity of Large Language Models(LLM) to perform key legal tasks. In this paper, I empirically evaluate how well LLMs, such as GPT, Claude, and Llama, perform key legal tasks in the Indian context, including issue spotting, legal drafting, advice, research, and reasoning. Through a survey experiment, I compare outputs from LLMs with those of a junior lawyer, with advanced law students rating the work on helpfulness, accuracy, and comprehensiveness. LLMs excel in drafting and issue spotting, often matching or surpassing human work. However, they struggle with specialised legal research, frequently generating hallucinations, factually incorrect or fabricated outputs. I conclude that while LLMs can augment certain legal tasks, human expertise remains essential for nuanced reasoning and the precise application of law.', 'abstract_zh': '将人工智能集成到法律行业引发了对大型语言模型执行关键法律任务能力的重大质疑。本文通过实验评估了GPT、Claude和Llama等大型语言模型在印度法律环境中的表现，涉及议题识别、法律起草、提供法律意见、研究和推理。通过调查实验，我们将这些模型的输出与初级律师的输出进行对比，由高级法律学生根据实用性、准确性和完整性进行评价。大型语言模型在起草和议题识别方面表现出色，经常与人类工作相当或超越。然而，它们在专门化的法律研究方面表现不佳，经常产生幻觉、事实错误或虚构的输出。我得出结论，虽然大型语言模型可以辅助某些法律任务，但人类专长对于细微推理和法律的精确应用仍然是必不可少的。', 'title_zh': '评估大型语言模型在印度法律实践中的作用'}
{'arxiv_id': 'arXiv:2508.09681', 'title': 'Surg-InvNeRF: Invertible NeRF for 3D tracking and reconstruction in surgical vision', 'authors': 'Gerardo Loza, Junlei Hu, Dominic Jones, Sharib Ali, Pietro Valdastri', 'link': 'https://arxiv.org/abs/2508.09681', 'abstract': "We proposed a novel test-time optimisation (TTO) approach framed by a NeRF-based architecture for long-term 3D point tracking. Most current methods in point tracking struggle to obtain consistent motion or are limited to 2D motion. TTO approaches frame the solution for long-term tracking as optimising a function that aggregates correspondences from other specialised state-of-the-art methods. Unlike the state-of-the-art on TTO, we propose parametrising such a function with our new invertible Neural Radiance Field (InvNeRF) architecture to perform both 2D and 3D tracking in surgical scenarios. Our approach allows us to exploit the advantages of a rendering-based approach by supervising the reprojection of pixel correspondences. It adapts strategies from recent rendering-based methods to obtain a bidirectional deformable-canonical mapping, to efficiently handle a defined workspace, and to guide the rays' density. It also presents our multi-scale HexPlanes for fast inference and a new algorithm for efficient pixel sampling and convergence criteria. We present results in the STIR and SCARE datasets, for evaluating point tracking and testing the integration of kinematic data in our pipeline, respectively. In 2D point tracking, our approach surpasses the precision and accuracy of the TTO state-of-the-art methods by nearly 50% on average precision, while competing with other approaches. In 3D point tracking, this is the first TTO approach, surpassing feed-forward methods while incorporating the benefits of a deformable NeRF-based reconstruction.", 'abstract_zh': '基于神经辐射场逆架构的\n的时间优化长期33人体外显手术跟踪方法', 'title_zh': 'Surg-InvNeRF: 可逆NeRF在手术视觉中的3D跟踪与重建'}
{'arxiv_id': 'arXiv:2508.09660', 'title': 'Anomaly Detection for IoT Global Connectivity', 'authors': 'Jesus Omaña Iglesias, Carlos Segura Perales, Stefan Geißler, Diego Perino, Andra Lutu', 'link': 'https://arxiv.org/abs/2508.09660', 'abstract': 'Internet of Things (IoT) application providers rely on Mobile Network Operators (MNOs) and roaming infrastructures to deliver their services globally. In this complex ecosystem, where the end-to-end communication path traverses multiple entities, it has become increasingly challenging to guarantee communication availability and reliability. Further, most platform operators use a reactive approach to communication issues, responding to user complaints only after incidents have become severe, compromising service quality. This paper presents our experience in the design and deployment of ANCHOR -- an unsupervised anomaly detection solution for the IoT connectivity service of a large global roaming platform. ANCHOR assists engineers by filtering vast amounts of data to identify potential problematic clients (i.e., those with connectivity issues affecting several of their IoT devices), enabling proactive issue resolution before the service is critically impacted. We first describe the IoT service, infrastructure, and network visibility of the IoT connectivity provider we operate. Second, we describe the main challenges and operational requirements for designing an unsupervised anomaly detection solution on this platform. Following these guidelines, we propose different statistical rules, and machine- and deep-learning models for IoT verticals anomaly detection based on passive signaling traffic. We describe the steps we followed working with the operational teams on the design and evaluation of our solution on the operational platform, and report an evaluation on operational IoT customers.', 'abstract_zh': 'IoT连接服务提供商依赖移动网络运营商(MNOs)和漫游基础设施在全球范围内交付其服务。在这个复杂的生态系统中，从一端到另一端的通信路径穿越多个实体，确保通信可用性和可靠性变得越来越具有挑战性。此外，大多数平台运营商采用反应式的通信问题处理方式，在问题严重化后再响应用户投诉，影响服务质量。本文介绍了我们在大规模全球漫游平台的IoT连接服务上设计并部署ANCHOR——一种无监督异常检测解决方案的经验。ANCHOR通过过滤大量数据来帮助工程师识别可能存在连接问题的终端客户（即那些影响其多个IoT设备的连接问题），从而在服务受到严重影响之前解决这些问题。首先，我们描述了我们运营的IoT服务、基础设施以及IoT连接提供商的网络可见性。其次，我们描述了在这个平台上设计无监督异常检测解决方案的主要挑战和操作要求。遵循这些指导原则，我们提出了基于被动信令流量的IoT垂直领域异常检测的不同统计规则和机器及深度学习模型。我们描述了与运营团队合作，在运营平台上设计和评估我们解决方案的过程，并在运营IoT客户上进行了评估。', 'title_zh': '物联网全球连接中的异常检测'}
{'arxiv_id': 'arXiv:2508.09653', 'title': 'On Negative-aware Preference Optimization for Recommendation', 'authors': 'Chenlu Ding, Daoxuan Liu, Jiancan Wu, Xingyu Hu, Junkang Wu, Haitao Wang, Yongkang Wang, Xingxing Wang, Xiang Wang', 'link': 'https://arxiv.org/abs/2508.09653', 'abstract': 'Recommendation systems leverage user interaction data to suggest relevant items while filtering out irrelevant (negative) ones. The rise of large language models (LLMs) has garnered increasing attention for their potential in recommendation tasks. However, existing methods for optimizing LLM-based recommenders face challenges in effectively utilizing negative samples. Simply integrating large numbers of negative samples can improve ranking accuracy and mitigate popularity bias but often leads to increased computational overhead and memory costs. Additionally, current approaches fail to account for the varying informativeness of negative samples, leading to suboptimal optimization performance. To address these issues, we propose NAPO (\\textbf{N}egative-\\textbf{A}ware \\textbf{P}reference \\textbf{O}ptimization), an enhanced framework for preference optimization in LLM-based recommendation. NAPO introduces two key innovations: (1) in-batch negative sharing, which expands the pool of negative samples without additional memory overhead, and (2) dynamic reward margin adjustment, which adapts model updates based on the confidence of negative samples. Extensive experiments on three public datasets demonstrate that NAPO outperforms existing methods in both recommendation accuracy and popularity bias reduction.', 'abstract_zh': '推荐系统利用用户交互数据来推荐相关项，同时过滤掉不相关（消极）项。大型语言模型（LLMs）的兴起引起了对其在推荐任务中的潜在应用的关注。虽然现有的方法在优化基于LLM的推荐器系统时方面面临挑战，简单地整合大量消极样本可以提高排名准确性并减轻流行度偏差，但往往也会增加计算开负担和内存成本。此外，当前方法未能考虑消极样本的信息价值的不同，导致优化性能不佳。为解决这些问题，我们提出了NAPO（负样本感知优化），这是一种针对基于LLM的推荐偏好优化的增强框架。NAPO引入了两项关键技术创新：（1）内存中内置负样本二，这种方法在不增加额外内存开开销的前提下扩展了负样本的多样性；（', 'title_zh': '面向推荐的负向偏好优化'}
{'arxiv_id': 'arXiv:2508.09652', 'title': 'Demystifying the Role of Rule-based Detection in AI Systems for Windows Malware Detection', 'authors': 'Andrea Ponte, Luca Demetrio, Luca Oneto, Ivan Tesfai Ogbu, Battista Biggio, Fabio Roli', 'link': 'https://arxiv.org/abs/2508.09652', 'abstract': 'Malware detection increasingly relies on AI systems that integrate signature-based detection with machine learning. However, these components are typically developed and combined in isolation, missing opportunities to reduce data complexity and strengthen defenses against adversarial EXEmples, carefully crafted programs designed to evade detection. Hence, in this work we investigate the influence that signature-based detection exerts on model training, when they are included inside the training pipeline. Specifically, we compare models trained on a comprehensive dataset with an AI system whose machine learning component is trained solely on samples not already flagged by signatures. Our results demonstrate improved robustness to both adversarial EXEmples and temporal data drift, although this comes at the cost of a fixed lower bound on false positives, driven by suboptimal rule selection. We conclude by discussing these limitations and outlining how future research could extend AI-based malware detection to include dynamic analysis, thereby further enhancing system resilience.', 'abstract_zh': '基于AI系统的签名检测集成与机器学习在恶意软件检测中的应用：研究签名检测对模型训练的影响及未来展望', 'title_zh': '揭开基于规则检测在Windows恶意软件检测的AI系统中的作用之谜'}
{'arxiv_id': 'arXiv:2508.09651', 'title': 'A Close Reading Approach to Gender Narrative Biases in AI-Generated Stories', 'authors': 'Daniel Raffini, Agnese Macori, Marco Angelini, Tiziana Catarci', 'link': 'https://arxiv.org/abs/2508.09651', 'abstract': "The paper explores the study of gender-based narrative biases in stories generated by ChatGPT, Gemini, and Claude. The prompt design draws on Propp's character classifications and Freytag's narrative structure. The stories are analyzed through a close reading approach, with particular attention to adherence to the prompt, gender distribution of characters, physical and psychological descriptions, actions, and finally, plot development and character relationships. The results reveal the persistence of biases - especially implicit ones - in the generated stories and highlight the importance of assessing biases at multiple levels using an interpretative approach.", 'abstract_zh': '该论文探讨了ChatGPT、Gemini和Claude生成的故事中基于性别的叙述偏见研究。启发式问题的设计参考了普罗普的角色分类和费特亚格的叙述结构。通过精细阅读的方法分析故事，特别关注对指令的遵循、角色的性别分布、物理和心理描述、行动以及最终的情节发展和角色关系。研究结果揭示了生成故事中偏见的持续存在，尤其是隐性的偏见，并强调了使用解释性方法在多个层面评估偏见的重要性。', 'title_zh': '基于细读方法的人工智能生成故事中性别叙事偏见探究'}
{'arxiv_id': 'arXiv:2508.09632', 'title': 'Preacher: Paper-to-Video Agentic System', 'authors': 'Jingwei Liu, Ling Yang, Hao Luo, Fan Wang Hongyan Li, Mengdi Wang', 'link': 'https://arxiv.org/abs/2508.09632', 'abstract': 'The paper-to-video task converts a research paper into a structured video abstract, distilling key concepts, methods, and conclusions into an accessible, well-organized format. While state-of-the-art video generation models demonstrate potential, they are constrained by limited context windows, rigid video duration constraints, limited stylistic diversity, and an inability to represent domain-specific knowledge. To address these limitations, we introduce Preacher, the first paper-to-video agentic system. Preacher employs a top-down approach to decompose, summarize, and reformulate the paper, followed by bottom-up video generation, synthesizing diverse video segments into a coherent abstract. To align cross-modal representations, we define key scenes and introduce a Progressive Chain of Thought (P-CoT) for granular, iterative planning. Preacher successfully generates high-quality video abstracts across five research fields, demonstrating expertise beyond current video generation models. Code will be released at: this https URL', 'abstract_zh': '论文视频化任务将研究论文转化为结构化的视频摘要，提炼出关键概念、方法和结论，以一种易于理解且组织良好的格式呈现。尽管最先进的视频生成模型显示出潜力，但它们受到有限上下文窗口、固定的视频时长约束、有限的风格多样性以及无法表示领域特定知识的限制。为了解决这些问题，我们引入了Preacher，这是第一个论文视频化的代理系统。Preacher采用自上而下的方法分解、总结和重述论文，并通过自下而上的视频生成，将多样化的视频片段合成出一个连贯的摘要。为了对齐跨模态表示，我们定义了关键场景并引入了渐进式的因果思维链（P-CoT）进行细粒度和迭代的规划。Preacher成功地在五个研究领域生成了高质量的视频摘要，展示了超越当前视频生成模型的专业知识。代码将在以下链接发布：this https URL。', 'title_zh': 'Preacher: 从论文到视频的代理系统'}
{'arxiv_id': 'arXiv:2508.09631', 'title': 'AmbiGraph-Eval: Can LLMs Effectively Handle Ambiguous Graph Queries?', 'authors': 'Yuchen Tian, Kaixin Li, Hao Chen, Ziyang Luo, Hongzhan Lin, Sebastian Schelter, Lun Du, Jing Ma', 'link': 'https://arxiv.org/abs/2508.09631', 'abstract': 'Large Language Models (LLMs) have recently demonstrated strong capabilities in translating natural language into database queries, especially when dealing with complex graph-structured data. However, real-world queries often contain inherent ambiguities, and the interconnected nature of graph structures can amplify these challenges, leading to unintended or incorrect query results. To systematically evaluate LLMs on this front, we propose a taxonomy of graph-query ambiguities, comprising three primary types: Attribute Ambiguity, Relationship Ambiguity, and Attribute-Relationship Ambiguity, each subdivided into Same-Entity and Cross-Entity scenarios. We introduce AmbiGraph-Eval, a novel benchmark of real-world ambiguous queries paired with expert-verified graph query answers. Evaluating 9 representative LLMs shows that even top models struggle with ambiguous graph queries. Our findings reveal a critical gap in ambiguity handling and motivate future work on specialized resolution techniques.', 'abstract_zh': '大型语言模型（LLMs）在将自然语言转换为数据库查询方面展现了强大的能力，尤其是在处理复杂图结构数据时。然而，现实世界的查询中往往包含固有的歧义性，而图结构的关联性会进一步放大这些挑战，导致意外或错误的查询结果。为了系统地评估LLMs在这一方面的表现，我们提出了一种图查询歧义分类法，包括三种主要类型：属性歧义、关系歧义和属性-关系歧义，每种类型又分别细分为同实体和跨实体场景。我们引入了AmbiGraph-Eval，这是一个包含真实世界歧义查询和专家验证的图查询答案的新基准。对9个代表性LLM的评估结果显示，即使是顶级模型也难以处理歧义图查询。我们的研究发现揭示了处理歧义方面的一个关键缺口，并激励未来针对专门解决技术的研究工作。', 'title_zh': 'AmbiGraph-Eval：LLM们能否有效地处理模糊图查询？'}
{'arxiv_id': 'arXiv:2508.09630', 'title': 'TimeMKG: Knowledge-Infused Causal Reasoning for Multivariate Time Series Modeling', 'authors': 'Yifei Sun, Junming Liu, Ding Wang, Yirong Chen, Xuefeng Yan', 'link': 'https://arxiv.org/abs/2508.09630', 'abstract': 'Multivariate time series data typically comprises two distinct modalities: variable semantics and sampled numerical observations. Traditional time series models treat variables as anonymous statistical signals, overlooking the rich semantic information embedded in variable names and data descriptions. However, these textual descriptors often encode critical domain knowledge that is essential for robust and interpretable modeling. Here we present TimeMKG, a multimodal causal reasoning framework that elevates time series modeling from low-level signal processing to knowledge informed inference. TimeMKG employs large language models to interpret variable semantics and constructs structured Multivariate Knowledge Graphs that capture inter-variable relationships. A dual-modality encoder separately models the semantic prompts, generated from knowledge graph triplets, and the statistical patterns from historical time series. Cross-modality attention aligns and fuses these representations at the variable level, injecting causal priors into downstream tasks such as forecasting and classification, providing explicit and interpretable priors to guide model reasoning. The experiment in diverse datasets demonstrates that incorporating variable-level knowledge significantly improves both predictive performance and generalization.', 'abstract_zh': '多元时间序列数据通常包含两类不同的模态：变量的语义描述和采样数值观测。传统的时间序列模型将变量视为匿名的统计信号，忽略了变量名称和描述中蕴含的丰富语义信息。变量的双重文本描述经常编码了关键的先验知识，这对鲁棒且可易于解释的建模至关重要。为此，我们提出了TimeMKG，这是一个多模态因果推理框架，将时间序列建模提升到了基于知识推理的层级。TimeMKG利用大模型来解释变量的语义表征，并构建包含变量间关系的结构化多变量知识图谱。该双重模态编码器分别建模从知识图谱三元组中产生的语义提示和 历史时间序列中的统计模式。跨模态注意力在时间序列级别对这些表征进行对对 �对 同，并 与融合，并注入因果先验，指导下游任务，如预报与分类等工作，提供明确且易解释的先验知识来引导因果推理工作。实验表明，在不同情况下均显著提表了预测性能和跨任务的泛化能力。', 'title_zh': 'TimeMKG：融合知识的多元时间序列因果推理'}
{'arxiv_id': 'arXiv:2508.09624', 'title': 'Goal Discovery with Causal Capacity for Efficient Reinforcement Learning', 'authors': 'Yan Yu, Yaodong Yang, Zhengbo Lu, Chengdong Ma, Wengang Zhou, Houqiang Li', 'link': 'https://arxiv.org/abs/2508.09624', 'abstract': "Causal inference is crucial for humans to explore the world, which can be modeled to enable an agent to efficiently explore the environment in reinforcement learning. Existing research indicates that establishing the causality between action and state transition will enhance an agent to reason how a policy affects its future trajectory, thereby promoting directed exploration. However, it is challenging to measure the causality due to its intractability in the vast state-action space of complex scenarios. In this paper, we propose a novel Goal Discovery with Causal Capacity (GDCC) framework for efficient environment exploration. Specifically, we first derive a measurement of causality in state space, \\emph{i.e.,} causal capacity, which represents the highest influence of an agent's behavior on future trajectories. After that, we present a Monte Carlo based method to identify critical points in discrete state space and further optimize this method for continuous high-dimensional environments. Those critical points are used to uncover where the agent makes important decisions in the environment, which are then regarded as our subgoals to guide the agent to make exploration more purposefully and efficiently. Empirical results from multi-objective tasks demonstrate that states with high causal capacity align with our expected subgoals, and our GDCC achieves significant success rate improvements compared to baselines.", 'abstract_zh': '因果推理对于人类探索世界至关重要，可以被建模以使代理在强化学习中高效地探索环境。现有研究指出，建立动作与状态转换之间的因果关系可以增强代理对其未来轨迹如何受策略影响的推理能力，从而促进定向探索。然而，由于在复杂场景的巨大状态-动作空间中测量因果关系具有不可行性，这颇具挑战。在本文中，我们提出了一种新的因果容量引导的目标发现（GDCC）框架，用于高效的环境探索。具体而言，我们首先在状态空间中推导出因果性的度量，即因果容量，这代表了代理行为对未来轨迹的最高影响。之后，我们提出了一种基于蒙特卡洛的方法来识别离散状态空间中的关键点，并进一步优化该方法以适应连续高维度环境。这些关键点用于揭示代理在环境中的重要决策位置，然后将这些决策位置视为我们的子目标，以引导代理有目的、高效地进行探索。多目标任务的实验结果表明，具有高因果容量的状态与我们期望的子目标相符，且我们的GDCC相对于基线实现了显著的成功率提升。', 'title_zh': '因果容量驱动的目标发现与高效强化学习'}
{'arxiv_id': 'arXiv:2508.09621', 'title': 'Interpretable Robot Control via Structured Behavior Trees and Large Language Models', 'authors': 'Ingrid Maéva Chekam, Ines Pastor-Martinez, Ali Tourani, Jose Andres Millan-Romera, Laura Ribeiro, Pedro Miguel Bastos Soares, Holger Voos, Jose Luis Sanchez-Lopez', 'link': 'https://arxiv.org/abs/2508.09621', 'abstract': 'As intelligent robots become more integrated into human environments, there is a growing need for intuitive and reliable Human-Robot Interaction (HRI) interfaces that are adaptable and more natural to interact with. Traditional robot control methods often require users to adapt to interfaces or memorize predefined commands, limiting usability in dynamic, unstructured environments. This paper presents a novel framework that bridges natural language understanding and robotic execution by combining Large Language Models (LLMs) with Behavior Trees. This integration enables robots to interpret natural language instructions given by users and translate them into executable actions by activating domain-specific plugins. The system supports scalable and modular integration, with a primary focus on perception-based functionalities, such as person tracking and hand gesture recognition. To evaluate the system, a series of real-world experiments was conducted across diverse environments. Experimental results demonstrate that the proposed approach is practical in real-world scenarios, with an average cognition-to-execution accuracy of approximately 94%, making a significant contribution to HRI systems and robots. The complete source code of the framework is publicly available at this https URL.', 'abstract_zh': '随着智能机器人越来越多地融入人类环境，需要更为直观可靠且适应性强的人机交互（HRI）界面，以便与之进行自然的交互。传统的机器人控制方法往往要求用户适应接口或记忆预定义的命令，这在动态的非结构化环境中限制了其实用性。本文提出了一种新型框架，将大规模语言模型（LLMs）与行为树结合，以实现自然语言理解和机器人执行的融合。该集成能够使机器人解析由用户给出的自然语言指令，并通过激活领域特定插件将其转化为可执行的动作。该系统支持可扩展和模块化的集成，主要关注基于感知的功能，如人像跟踪和手势识别。为了评估系统，在多种环境中进行了实地实验。实验结果表明，所提出的方法在实际应用场景中是可行的，认知到执行的平均准确率为约94%，对HRI系统和机器人做出了重要贡献。该框架的完整源代码可从此链接访问。', 'title_zh': '结构化行为树与大型语言模型下的可解释机器人控制'}
{'arxiv_id': 'arXiv:2508.09616', 'title': 'MInDI-3D: Iterative Deep Learning in 3D for Sparse-view Cone Beam Computed Tomography', 'authors': 'Daniel Barco, Marc Stadelmann, Martin Oswald, Ivo Herzig, Lukas Lichtensteiger, Pascal Paysan, Igor Peterlik, Michal Walczak, Bjoern Menze, Frank-Peter Schilling', 'link': 'https://arxiv.org/abs/2508.09616', 'abstract': 'We present MInDI-3D (Medical Inversion by Direct Iteration in 3D), the first 3D conditional diffusion-based model for real-world sparse-view Cone Beam Computed Tomography (CBCT) artefact removal, aiming to reduce imaging radiation exposure. A key contribution is extending the "InDI" concept from 2D to a full 3D volumetric approach for medical images, implementing an iterative denoising process that refines the CBCT volume directly from sparse-view input. A further contribution is the generation of a large pseudo-CBCT dataset (16,182) from chest CT volumes of the CT-RATE public dataset to robustly train MInDI-3D. We performed a comprehensive evaluation, including quantitative metrics, scalability analysis, generalisation tests, and a clinical assessment by 11 clinicians. Our results show MInDI-3D\'s effectiveness, achieving a 12.96 (6.10) dB PSNR gain over uncorrected scans with only 50 projections on the CT-RATE pseudo-CBCT (independent real-world) test set and enabling an 8x reduction in imaging radiation exposure. We demonstrate its scalability by showing that performance improves with more training data. Importantly, MInDI-3D matches the performance of a 3D U-Net on real-world scans from 16 cancer patients across distortion and task-based metrics. It also generalises to new CBCT scanner geometries. Clinicians rated our model as sufficient for patient positioning across all anatomical sites and found it preserved lung tumour boundaries well.', 'abstract_zh': 'MInDI-3D：面向实际稀视角锥束计算机断层扫描伪影去除的3D条件扩散迭代模型', 'title_zh': 'MInDI-3D: 三维迭代深度学习在稀视角锥束计算机断层成像中的应用'}
{'arxiv_id': 'arXiv:2508.09614', 'title': 'How Persuasive Could LLMs Be? A First Study Combining Linguistic-Rhetorical Analysis and User Experiments', 'authors': 'Daniel Raffini, Agnese Macori, Lorenzo Porcaro, Tiziana Catarci, Marco Angelini', 'link': 'https://arxiv.org/abs/2508.09614', 'abstract': 'This study examines the rhetorical and linguistic features of argumentative texts generated by ChatGPT on ethically nuanced topics and investigates their persuasive impact on human this http URL a user study involving 62 participants and pre-post interaction surveys, the paper analyzes how exposure to AI-generated arguments affects opinion change and user perception. A linguistic and rhetorical analysis of the generated texts reveals a consistent argumentative macrostructure, reliance on formulaic expressions, and limited stylistic richness. While ChatGPT demonstrates proficiency in constructing coherent argumentative texts, its persuasive efficacy appears constrained, particularly on topics involving ethical this http URL study finds that while participants often acknowledge the benefits highlighted by ChatGPT, ethical concerns tend to persist or even intensify post-interaction. The results also demonstrate a variation depending on the topic. These findings highlight new insights on AI-generated persuasion in ethically sensitive domains and are a basis for future research.', 'abstract_zh': 'This study examines the rhetorical and linguistic features of argumentative texts generated by ChatGPT on ethically nuanced topics and investigates their persuasive impact on humans. Through a user study involving 62 participants and pre-post interaction surveys, the paper analyzes how exposure to AI-generated arguments affects opinion change and user perception. A linguistic and rhetorical analysis of the generated texts reveals a consistent argumentative macrostructure, reliance on formulaic expressions, and limited stylistic richness. While ChatGPT demonstrates proficiency in constructing coherent argumentative texts, its persuasive efficacy appears constrained, particularly on topics involving ethical concerns. The study finds that while participants often acknowledge the benefits highlighted by ChatGPT, ethical concerns tend to persist or even intensify post-interaction. The results also demonstrate a variation depending on the topic. These findings highlight new insights on AI-generated persuasion in ethically sensitive domains and serve as a basis for future research.', 'title_zh': 'LLMs有多有说服力？一项结合语言修辞分析和用户实验的初步研究'}
{'arxiv_id': 'arXiv:2508.09602', 'title': 'A Lightweight Learned Cardinality Estimation Model', 'authors': 'Yaoyu Zhu, Jintao Zhang, Guoliang Li, Jianhua Feng', 'link': 'https://arxiv.org/abs/2508.09602', 'abstract': 'Cardinality estimation is a fundamental task in database management systems, aiming to predict query results accurately without executing the queries. However, existing techniques either achieve low estimation accuracy or incur high inference latency. Simultaneously achieving high speed and accuracy becomes critical for the cardinality estimation problem. In this paper, we propose a novel data-driven approach called CoDe (Covering with Decompositions) to address this problem. CoDe employs the concept of covering design, which divides the table into multiple smaller, overlapping segments. For each segment, CoDe utilizes tensor decomposition to accurately model its data distribution. Moreover, CoDe introduces innovative algorithms to select the best-fitting distributions for each query, combining them to estimate the final result. By employing multiple models to approximate distributions, CoDe excels in effectively modeling discrete distributions and ensuring computational efficiency. Notably, experimental results show that our method represents a significant advancement in cardinality estimation, achieving state-of-the-art levels of both estimation accuracy and inference efficiency. Across various datasets, CoDe achieves absolute accuracy in estimating more than half of the queries.', 'abstract_zh': '基数估计是数据库管理系统中的一个基本任务，旨在在不执行查询的情况下准确预测查询结果。然而，现有的技术要么准确度低，要么推断延迟高。同时实现高速和高准确度对于基数估计问题至关重要。在本文中，我们提出了一种名为CoDe（覆盖与分解）的新型数据驱动方法来解决这一问题。CoDe 使用覆盖设计的概念，将表格划分为多个较小的重叠段。对于每个段，CoDe 利用张量分解准确地模拟其数据分布。此外，CoDe 引入了创新的算法来为每个查询选择最适合的分布，并将它们结合以估计最终结果。通过使用多个模型近似分布，CoDe 在有效建模离散分布和确保计算效率方面表现出色。值得注意的是，实验结果表明，我们的方法在基数估计方面取得了重要进展，同时实现了最先进的估计准确度和推断效率。在各个数据集中，CoDe 在超过一半的查询中实现了绝对准确的基数估计。', 'title_zh': '一种轻量级的学习基数估计模型'}
{'arxiv_id': 'arXiv:2508.09593', 'title': 'Hierarchical Brain Structure Modeling for Predicting Genotype of Glioma', 'authors': 'Haotian Tang, Jianwei Chen, Xinrui Tang, Yunjia Wu, Zhengyang Miao, Chao Li', 'link': 'https://arxiv.org/abs/2508.09593', 'abstract': "Isocitrate DeHydrogenase (IDH) mutation status is a crucial biomarker for glioma prognosis. However, current prediction methods are limited by the low availability and noise of functional MRI. Structural and morphological connectomes offer a non-invasive alternative, yet existing approaches often ignore the brain's hierarchical organisation and multiscale interactions. To address this, we propose Hi-SMGNN, a hierarchical framework that integrates structural and morphological connectomes from regional to modular levels. It features a multimodal interaction module with a Siamese network and cross-modal attention, a multiscale feature fusion mechanism for reducing redundancy, and a personalised modular partitioning strategy to enhance individual specificity and interpretability. Experiments on the UCSF-PDGM dataset demonstrate that Hi-SMGNN outperforms baseline and state-of-the-art models, showing improved robustness and effectiveness in IDH mutation prediction.", 'abstract_zh': 'Iso Citrate DeHydrogenase (IDH) 突变状态是胶质瘤预后的一个关键生物标志物。然而，当前的预测方法受限于功能性 MRI 的低可用性和噪声。结构和形态连接组提供了一种无创的替代方案，但现有方法往往忽视了大脑的层次组织和多尺度交互。为了解决这一问题，我们提出了 Hi-SMGNN，这是一种从区域级到模块级集成结构和形态连接组的分层框架。该框架配备了具有Siamese网络和跨模态注意力的多模态交互模块、减少冗余的多尺度特征融合机制，以及增强个体特异性和可解释性的个性化模块分区策略。在 UCSF-PDGM 数据集上的实验表明，Hi-SMGNN 在 IDH 突变预测方面优于基线和最新模型，显示了更好的稳健性和有效性。', 'title_zh': '胶质瘤基因型预测的分层脑结构建模'}
{'arxiv_id': 'arXiv:2508.09558', 'title': 'CaRoBio: 3D Cable Routing with a Bio-inspired Gripper Fingernail', 'authors': 'Jiahui Zuo, Boyang Zhang, Fumin Zhang', 'link': 'https://arxiv.org/abs/2508.09558', 'abstract': 'The manipulation of deformable linear flexures has a wide range of applications in industry, such as cable routing in automotive manufacturing and textile production. Cable routing, as a complex multi-stage robot manipulation scenario, is a challenging task for robot automation. Common parallel two-finger grippers have the risk of over-squeezing and over-tension when grasping and guiding cables. In this paper, a novel eagle-inspired fingernail is designed and mounted on the gripper fingers, which helps with cable grasping on planar surfaces and in-hand cable guiding operations. Then we present a single-grasp end-to-end 3D cable routing framework utilizing the proposed fingernails, instead of the common pick-and-place strategy. Continuous control is achieved to efficiently manipulate cables through vision-based state estimation of task configurations and offline trajectory planning based on motion primitives. We evaluate the effectiveness of the proposed framework with a variety of cables and channel slots, significantly outperforming the pick-and-place manipulation process under equivalent perceptual conditions. Our reconfigurable task setting and the proposed framework provide a reference for future cable routing manipulations in 3D space.', 'abstract_zh': '基于鹰爪启发的新型指节在单握持连续3D电缆布线框架中的应用', 'title_zh': 'CaRoBio: 基于生物启发式夹具指甲的3D电缆布线'}
{'arxiv_id': 'arXiv:2508.09547', 'title': 'GoViG: Goal-Conditioned Visual Navigation Instruction Generation', 'authors': 'Fengyi Wu, Yifei Dong, Zhi-Qi Cheng, Yilong Dai, Guangyu Chen, Hang Wang, Qi Dai, Alexander G. Hauptmann', 'link': 'https://arxiv.org/abs/2508.09547', 'abstract': 'We introduce Goal-Conditioned Visual Navigation Instruction Generation (GoViG), a new task that aims to autonomously generate precise and contextually coherent navigation instructions solely from egocentric visual observations of initial and goal states. Unlike conventional approaches that rely on structured inputs such as semantic annotations or environmental maps, GoViG exclusively leverages raw egocentric visual data, substantially improving its adaptability to unseen and unstructured environments. Our method addresses this task by decomposing it into two interconnected subtasks: (1) visual forecasting, which predicts intermediate visual states bridging the initial and goal views; and (2) instruction generation, which synthesizes linguistically coherent instructions grounded in both observed and anticipated visuals. These subtasks are integrated within an autoregressive multimodal large language model trained with tailored objectives to ensure spatial accuracy and linguistic clarity. Furthermore, we introduce two complementary multimodal reasoning strategies, one-pass and interleaved reasoning, to mimic incremental human cognitive processes during navigation. To evaluate our method, we propose the R2R-Goal dataset, combining diverse synthetic and real-world trajectories. Empirical results demonstrate significant improvements over state-of-the-art methods, achieving superior BLEU-4 and CIDEr scores along with robust cross-domain generalization.', 'abstract_zh': '基于目标条件的视觉导航指令生成 (GoViG)', 'title_zh': 'GoViG: 基于目标的视觉导航指令生成'}
{'arxiv_id': 'arXiv:2508.09537', 'title': 'Your Coding Intent is Secretly in the Context and You Should Deliberately Infer It Before Completion', 'authors': 'Yanzhou Li, Tianlin Li, Yiran Zhang, Shangqing Liu, Aishan Liu, Yang Liu', 'link': 'https://arxiv.org/abs/2508.09537', 'abstract': 'Large Language Models (LLMs) are increasingly used for function completion in repository-scale codebases. Prior studies demonstrate that when explicit instructions--such as docstrings--are provided, these models can generate highly accurate implementations. However, in real-world repositories, such annotations are frequently absent, and performance drops substantially without them. To address this gap, we frame the task as a three-stage process. The first stage focuses on intent inference, where the model analyzes the code preceding the target function to uncover cues about the desired functionality. Such preceding context often encodes subtle but critical information, and we design a reasoning-based prompting framework to guide the LLM through step-by-step extraction and synthesis of these signals before any code is generated. The second stage introduces an optional interactive refinement mechanism to handle cases where preceding context alone is insufficient for intent recovery. In this stage, the model proposes a small set of candidate intentions, enabling the developer to select or edit them so that the inferred intent closely matches the actual requirement. Finally, in the third stage, the LLM generates the target function conditioned on the finalized intent. To support this pipeline, we curate a dataset of 40,000 examples annotated with intermediate reasoning traces and corresponding docstrings. Extensive experiments on DevEval and ComplexCodeEval show that our approach consistently boosts multiple LLMs, achieving over 20\\% relative gains in both reference-based and execution-based metrics, with the interactive refinement stage delivering additional improvements beyond these gains.', 'abstract_zh': '大规模语言模型（LLMs）在代码库规模代码中的功能完成应用日益增多。先前的研究表明，在提供显式说明（如文档字符串）的情况下，这些模型可以生成高度准确的实现。然而，在实际的代码库中，这类注释经常缺失，没有它们性能会显著下降。为了解决这一问题，我们将任务构架为三个阶段的过程。第一阶段集中于意图推断，模型分析目标函数之前的代码，以揭示所需的函数特性线索。这段前序代码往往编码了微妙但至关重要的信息，并设计了一种基于推理的提示框架，引导LLM逐步提取和综合这些信号，然后再生成任何代码。第二阶段引入了一个可选的交互式细化机制，以处理仅凭前序代码不足以恢复意图的情况。在这个阶段，模型提出一组候选意图，允许开发者选择或编辑它们，使推断出的意图尽可能接近实际需求。最后，在第三阶段，LLM基于最终确定的意图生成目标函数。为了支持这一流水线，我们精心收集了一个包含40,000个实例的数据集，这些实例带有中间推理踪迹和相应的文档字符串标注。在Deevaleval和ComplexCodeEval上的广泛实验表明，我们的方法能够提升多种LLM的表现，在参考指标和执行指标上均实现超过20%的相对增益，并且交互式细化阶段带来额外的增益。', 'title_zh': '你的编码意图秘密地蕴含在上下文中，你应该在完成之前有意地推断它。'}
{'arxiv_id': 'arXiv:2508.09535', 'title': 'AI Blob! LLM-Driven Recontextualization of Italian Television Archives', 'authors': 'Roberto Balestri', 'link': 'https://arxiv.org/abs/2508.09535', 'abstract': 'This paper introduces AI Blob!, an experimental system designed to explore the potential of semantic cataloging and Large Language Models (LLMs) for the retrieval and recontextualization of archival television footage. Drawing methodological inspiration from Italian television programs such as Blob (RAI Tre, 1989-), AI Blob! integrates automatic speech recognition (ASR), semantic embeddings, and retrieval-augmented generation (RAG) to organize and reinterpret archival content. The system processes a curated dataset of 1,547 Italian television videos by transcribing audio, segmenting it into sentence-level units, and embedding these segments into a vector database for semantic querying. Upon user input of a thematic prompt, the LLM generates a range of linguistically and conceptually related queries, guiding the retrieval and recombination of audiovisual fragments. These fragments are algorithmically selected and structured into narrative sequences producing montages that emulate editorial practices of ironic juxtaposition and thematic coherence. By foregrounding dynamic, content-aware retrieval over static metadata schemas, AI Blob! demonstrates how semantic technologies can facilitate new approaches to archival engagement, enabling novel forms of automated narrative construction and cultural analysis. The project contributes to ongoing debates in media historiography and AI-driven archival research, offering both a conceptual framework and a publicly available dataset to support further interdisciplinary experimentation.', 'abstract_zh': 'AI Blob!: 一种探索语义目录和大规模语言模型在档案电视片段检索与重构中潜在应用的实验系统', 'title_zh': 'AI Blob！由LLM驱动的意大利电视档案再语境化'}
{'arxiv_id': 'arXiv:2508.09533', 'title': 'COXNet: Cross-Layer Fusion with Adaptive Alignment and Scale Integration for RGBT Tiny Object Detection', 'authors': 'Peiran Peng, Tingfa Xu, Liqiang Song, Mengqi Zhu, Yuqiang Fang, Jianan Li', 'link': 'https://arxiv.org/abs/2508.09533', 'abstract': 'Detecting tiny objects in multimodal Red-Green-Blue-Thermal (RGBT) imagery is a critical challenge in computer vision, particularly in surveillance, search and rescue, and autonomous navigation. Drone-based scenarios exacerbate these challenges due to spatial misalignment, low-light conditions, occlusion, and cluttered backgrounds. Current methods struggle to leverage the complementary information between visible and thermal modalities effectively. We propose COXNet, a novel framework for RGBT tiny object detection, addressing these issues through three core innovations: i) the Cross-Layer Fusion Module, fusing high-level visible and low-level thermal features for enhanced semantic and spatial accuracy; ii) the Dynamic Alignment and Scale Refinement module, correcting cross-modal spatial misalignments and preserving multi-scale features; and iii) an optimized label assignment strategy using the GeoShape Similarity Measure for better localization. COXNet achieves a 3.32\\% mAP$_{50}$ improvement on the RGBTDronePerson dataset over state-of-the-art methods, demonstrating its effectiveness for robust detection in complex environments.', 'abstract_zh': 'RGBT多模态图像中微小目标检测是计算机视觉中的一个关键挑战，特别是在监控、搜索与救援以及自主导航领域。基于无人机的场景加剧了这些挑战，由于空间错位、低光照条件、遮挡和复杂背景。当前方法难以有效地利用可见光和热成像之间的互补信息。我们提出COXNet，一种针对RGBT微小目标检测的新型框架，通过三大创新解决这些问题：i) 多层融合模块，融合高层可见光和低层热成像特征，增强语义和空间准确性；ii) 动态对齐与尺度细化模块，纠正跨模态的空间错位并保留多尺度特征；iii) 使用地理形状相似度度量的优化标签分配策略，以实现更好的定位。COXNet在RGBTDronePerson数据集上实现了3.32%的mAP$_{50}$改进，展示了其在复杂环境中的鲁棒检测能力。', 'title_zh': 'COXNet：跨层融合带有自适应对齐和尺度集成的RGBT微小目标检测'}
{'arxiv_id': 'arXiv:2508.09532', 'title': 'Decentralized Rank Scheduling for Energy-Constrained Multi-Task Federated Fine-Tuning in Edge-Assisted IoV Networks', 'authors': 'Bokeng Zheng, Jianqiang Zhong, Jiayi Liu, Xiaoxi Zhang', 'link': 'https://arxiv.org/abs/2508.09532', 'abstract': 'Federated fine-tuning has emerged as a promising approach for adapting foundation models (FMs) to diverse downstream tasks in edge environments. In Internet of Vehicles (IoV) systems, enabling efficient and low-latency multi-task adaptation is particularly challenging due to client mobility, heterogeneous resources, and intermittent connectivity. This paper proposes a hierarchical federated fine-tuning framework that coordinates roadside units (RSUs) and vehicles to support resource-aware and mobility-resilient learning across dynamic IoV scenarios. Leveraging Low-Rank Adaptation (LoRA), we introduce a decentralized, energy-aware rank adaptation mechanism formulated as a constrained multi-armed bandit problem. A novel UCB-DUAL algorithm is developed to enable adaptive exploration under per-task energy budgets, achieving provable sublinear regret. To evaluate our method, we construct a large-scale IoV simulator based on real-world trajectories, capturing dynamic participation, RSU handoffs, and communication variability. Extensive experiments show that our approach achieves the best accuracy-efficiency trade-off among all baselines, reducing latency by over 24\\% and improving average accuracy by more than 2.5\\%.', 'abstract_zh': '联邦细调框架在物联网车辆系统中的多任务适应', 'title_zh': '边缘辅助IoV网络中基于能耗约束的分布式多任务联邦微调排名调度'}
{'arxiv_id': 'arXiv:2508.09522', 'title': 'Generation of Indian Sign Language Letters, Numbers, and Words', 'authors': 'Ajeet Kumar Yadav, Nishant Kumar, Rathna G N', 'link': 'https://arxiv.org/abs/2508.09522', 'abstract': "Sign language, which contains hand movements, facial expressions and bodily gestures, is a significant medium for communicating with hard-of-hearing people. A well-trained sign language community communicates easily, but those who don't know sign language face significant challenges. Recognition and generation are basic communication methods between hearing and hard-of-hearing individuals. Despite progress in recognition, sign language generation still needs to be explored. The Progressive Growing of Generative Adversarial Network (ProGAN) excels at producing high-quality images, while the Self-Attention Generative Adversarial Network (SAGAN) generates feature-rich images at medium resolutions. Balancing resolution and detail is crucial for sign language image generation. We are developing a Generative Adversarial Network (GAN) variant that combines both models to generate feature-rich, high-resolution, and class-conditional sign language images. Our modified Attention-based model generates high-quality images of Indian Sign Language letters, numbers, and words, outperforming the traditional ProGAN in Inception Score (IS) and Fréchet Inception Distance (FID), with improvements of 3.2 and 30.12, respectively. Additionally, we are publishing a large dataset incorporating high-quality images of Indian Sign Language alphabets, numbers, and 129 words.", 'abstract_zh': '基于注意力机制的渐进生成对抗网络变体在印度手语图像生成中的应用', 'title_zh': '生成印度手语字母、数字和单词'}
{'arxiv_id': 'arXiv:2508.09521', 'title': 'COMPEER: Controllable Empathetic Reinforcement Reasoning for Emotional Support Conversation', 'authors': 'Yunxiao Wang, Meng Liu, Wenqi Liu, Kaiyu Jiang, Bin Wen, Fan Yang, Tingting Gao, Guorui Zhou, Liqiang Nie', 'link': 'https://arxiv.org/abs/2508.09521', 'abstract': "Emotional support conversations are crucial for promoting emotional well-being, yet current models often lack deep empathetic reasoning grounded in psychological principles. To address this, we propose controllable empathetic reasoning, which combines natural language reasoning with structured psychological steps. We construct a fine-grained dataset annotated with reasoning correctness and response preferences to enable this capability. To further enhance training, we employ reinforcement learning with a unified process-outcome reward model that delivers precise feedback. To mitigate response repetitiveness from entropy collapse, we introduce personality-based dialogue rewriting and a redundancy-aware reward reweighting strategy. Our approach significantly improves model's emotional support ability, advancing the development of empathetic, human-like support systems.", 'abstract_zh': '情感支持对话对于促进情感福祉至关重要，然而当前模型往往缺乏基于心理原理的深刻共情推理能力。为了应对这一问题，我们提出可控共情推理，它将自然语言推理与结构化的心理步骤相结合。我们构建了一个细粒度的数据集，标注了推理正确性和响应偏好，以支持这种能力。为进一步提高训练效果，我们采用强化学习，并使用统一的过程-结果奖励模型提供精确反馈。为缓解由于熵塌缩导致的回应重复性，我们引入了基于个性的对话重写和重复性感知的奖励重赋值策略。我们的方法显著提升了模型的情感支持能力，推动了具有共情和人性化支持系统的开发。', 'title_zh': 'COMPEER: �,\n可控共情强化推理对话支持系统'}
{'arxiv_id': 'arXiv:2508.09508', 'title': 'SMART-OC: A Real-time Time-risk Optimal Replanning Algorithm for Dynamic Obstacles and Spatio-temporally Varying Currents', 'authors': 'Reema Raval, Shalabh Gupta', 'link': 'https://arxiv.org/abs/2508.09508', 'abstract': 'Typical marine environments are highly complex with spatio-temporally varying currents and dynamic obstacles, presenting significant challenges to Unmanned Surface Vehicles (USVs) for safe and efficient navigation. Thus, the USVs need to continuously adapt their paths with real-time information to avoid collisions and follow the path of least resistance to the goal via exploiting ocean currents. In this regard, we introduce a novel algorithm, called Self-Morphing Adaptive Replanning Tree for dynamic Obstacles and Currents (SMART-OC), that facilitates real-time time-risk optimal replanning in dynamic environments. SMART-OC integrates the obstacle risks along a path with the time cost to reach the goal to find the time-risk optimal path. The effectiveness of SMART-OC is validated by simulation experiments, which demonstrate that the USV performs fast replannings to avoid dynamic obstacles and exploit ocean currents to successfully reach the goal.', 'abstract_zh': '自适应形态变化重规划树以应对动态障碍和洋流（SMART-OC）：复杂海洋环境下的实时时间风险优化重规划算法', 'title_zh': 'SMART-OC：动态障碍物和时空变化流场下的实时时间风险最优重规划算法'}
{'arxiv_id': 'arXiv:2508.09505', 'title': 'Verify Distributed Deep Learning Model Implementation Refinement with Iterative Relation Inference', 'authors': 'Zhanghan Wang, Ding Ding, Hang Zhu, Haibin Lin, Aurojit Panda', 'link': 'https://arxiv.org/abs/2508.09505', 'abstract': "Distributed machine learning training and inference is common today because today's large models require more memory and compute than can be provided by a single GPU. Distributed models are generally produced by programmers who take a sequential model specification and apply several distribution strategies to distribute state and computation across GPUs. Unfortunately, bugs can be introduced in the process, and a distributed model implementation's outputs might differ from the sequential model's outputs. In this paper, we describe an approach to statically identify such bugs by checking model refinement, that is, can the sequential model's outputs be reconstructed from the distributed model's outputs? Our approach, implemented in GraphGuard, uses iterative rewriting to prove model refinement. Our approach can scale to today's large models and deployments: we evaluate it using GPT and Llama-3. Further, it provides actionable output that aids in bug localization.", 'abstract_zh': '分布式机器学习训练与推理如今已非常普遍，因为当前的大模型需要的内存和计算能力超过了单个GPU所能提供的。分布式模型通常是由程序员通过对顺序模型进行一系列分布策略的应用来生成的，以将状态和计算分布在多块GPU上。不幸的是，在这一过程中可能会引入错误，导致分布式模型的输出与顺序模型的输出不同。在本文中，我们描述了一种通过检查模型细化来静态识别此类错误的方法，即分布式模型的输出是否可以从顺序模型的输出重构出来。我们的方法已在GraphGuard中实现，通过迭代重写来证明模型细化。该方法可以扩展到当前的大模型和部署场景：我们使用GPT和Llama-3进行了评估。此外，该方法提供了有助于错误定位的可操作输出。', 'title_zh': '使用迭代关系推理验证分布式深度学习模型实现优化'}
{'arxiv_id': 'arXiv:2508.09497', 'title': 'From Ranking to Selection: A Simple but Efficient Dynamic Passage Selector for Retrieval Augmented Generation', 'authors': 'Siyuan Meng, Junming Liu, Yirong Chen, Song Mao, Pinlong Cai, Guohang Yan, Botian Shi, Ding Wang', 'link': 'https://arxiv.org/abs/2508.09497', 'abstract': 'Retrieval-augmented generation (RAG) systems are often bottlenecked by their reranking modules, which typically score passages independently and select a fixed Top-K size. This approach struggles with complex multi-hop queries that require synthesizing evidence across multiple documents, creating a trade-off where small K values omit crucial information and large K values introduce noise. To address this, we introduce the Dynamic Passage Selector (DPS), a novel reranking framework that treats passage selection as a supervised learning problem. Unlike traditional point-wise or list-wise methods, DPS is fine-tuned to capture inter-passage dependencies and dynamically select the most relevant set of passages for generation. As a seamless plug-and-play module, DPS requires no modifications to the standard RAG pipeline. Comprehensive evaluations on five benchmarks show that DPS consistently outperforms state-of-the-art rerankers and fine-tuning methods. Notably, on the challenging MuSiQue dataset, DPS improves the F1-score by 30.06% and 15.4% over strong baselines like Qwen3-reranker and RankingGPT, respectively. Our results demonstrate that by enabling adaptive evidence selection, DPS substantially enhances reasoning capabilities in complex RAG scenarios.', 'abstract_zh': '基于检索的生成（RAG）系统往往受限于其再排序模块，该模块通常独立评分段落并选取固定大小的Top-K。这种方法在处理需要跨多个文档合成证据的复杂多跳查询时存在困难，导致小K值舍弃重要信息而大K值引入噪声。为解决这一问题，我们引入了动态段落选择器（DPS），这是一种新颖的再排序框架，将段落选择视为监督学习问题。与传统的点wise或listwise方法不同，DPS微调以捕捉段落间的依赖性，并动态选择生成所需的相关段落集。作为无缝即插即用模块，DPS无需对标准RAG流程进行任何修改。在五个基准上的全面评估显示，DPS一致地优于最先进的再排序器和微调方法。特别是在具有挑战性的MuSiQue数据集中，DPS分别将F1分数提高了30.06%和15.4%，相较于如Qwen3-reranker和RankingGPT等强大的基线模型。我们的结果表明，通过使证据选择适应变化，DPS在复杂RAG场景中显著增强了推理能力。', 'title_zh': '从排名到选择：一种简单而高效的动态段落选择器用于检索增强生成'}
{'arxiv_id': 'arXiv:2508.09494', 'title': 'Learning Facts at Scale with Active Reading', 'authors': 'Jessy Lin, Vincent-Pierre Berges, Xilun Chen, Wen-Tau Yih, Gargi Ghosh, Barlas Oğuz', 'link': 'https://arxiv.org/abs/2508.09494', 'abstract': 'LLMs are known to store vast amounts of knowledge in their parametric memory. However, learning and recalling facts from this memory is known to be unreliable, depending largely on the prevalence of particular facts in the training data and other factors which are poorly understood. Practitioners are lacking tools which will allow them to ensure that the models learn a given body of knowledge reliably and consistently. To this end, we propose Active Reading: a framework where we train models to study a given set of material with self-generated learning strategies. First, we demonstrate models trained with Active Reading on expert domains absorb significantly more knowledge than vanilla finetuning and other data augmentations. We train expert 8B models that achieve 66% on a Wikipedia-grounded subset of SimpleQA (+313% relative over vanilla finetuning) and 26% on FinanceBench (+160% relative over vanilla finetuning) by applying Active Reading to the source documents for each benchmark. Finally, we show that Active Reading can be utilized at pre-training scale to build more factual models. As a demonstration of this, we release Meta WikiExpert-8B, a Wikipedia-expert model trained on 1 trillion generated tokens, which outcompetes models with hundreds of billions of parameters on factual QA.', 'abstract_zh': 'LLMs在自动生成的学习策略下训练于特定材料时能够显著吸收更多知识：以专家领域为例，并在预训练规模上构建更事实性的模型', 'title_zh': '大规模主动阅读学习事实'}
{'arxiv_id': 'arXiv:2508.09489', 'title': 'Large-Small Model Collaborative Framework for Federated Continual Learning', 'authors': 'Hao Yu, Xin Yang, Boyang Fan, Xuemei Cao, Hanlin Gu, Lixin Fan, Qiang Yang', 'link': 'https://arxiv.org/abs/2508.09489', 'abstract': 'Continual learning (CL) for Foundation Models (FMs) is an essential yet underexplored challenge, especially in Federated Continual Learning (FCL), where each client learns from a private, evolving task stream under strict data and communication constraints. Despite their powerful generalization abilities, FMs often exhibit suboptimal performance on local downstream tasks, as they are unable to utilize private local data. Furthermore, enabling FMs to learn new tasks without forgetting prior knowledge is inherently a challenging problem, primarily due to their immense parameter count and high model complexity. In contrast, small models can be trained locally under resource-constrained conditions and benefit from more mature CL techniques. To bridge the gap between small models and FMs, we propose the first collaborative framework in FCL, where lightweight local models act as a dynamic bridge, continually adapting to new tasks while enhancing the utility of the large model. Two novel components are also included: Small Model Continual Fine-tuning is for preventing small models from temporal forgetting; One-by-One Distillation performs personalized fusion of heterogeneous local knowledge on the server. Experimental results demonstrate its superior performance, even when clients utilize heterogeneous small models.', 'abstract_zh': 'Foundation模型在联邦持续学习中轻量级协作框架：面向小型模型与大型模型的动态桥梁', 'title_zh': '大型-小型模型协作框架赋能联邦持续学习'}
{'arxiv_id': 'arXiv:2508.09486', 'title': 'Episodic Memory Representation for Long-form Video Understanding', 'authors': 'Yun Wang, Long Zhang, Jingren Liu, Jiaqi Yan, Zhanjie Zhang, Jiahao Zheng, Xun Yang, Dapeng Wu, Xiangyu Chen, Xuelong Li', 'link': 'https://arxiv.org/abs/2508.09486', 'abstract': 'Video Large Language Models (Video-LLMs) excel at general video understanding but struggle with long-form videos due to context window limits. Consequently, recent approaches focus on keyframe retrieval, condensing lengthy videos into a small set of informative frames. Despite their practicality, these methods simplify the problem to static text image matching, overlooking spatio temporal relationships crucial for capturing scene transitions and contextual continuity, and may yield redundant keyframes with limited information, diluting salient cues essential for accurate video question answering. To address these limitations, we introduce Video-EM, a training free framework inspired by the principles of human episodic memory, designed to facilitate robust and contextually grounded reasoning. Rather than treating keyframes as isolated visual entities, Video-EM explicitly models them as temporally ordered episodic events, capturing both spatial relationships and temporal dynamics necessary for accurately reconstructing the underlying narrative. Furthermore, the framework leverages chain of thought (CoT) thinking with LLMs to iteratively identify a minimal yet highly informative subset of episodic memories, enabling efficient and accurate question answering by Video-LLMs. Extensive evaluations on the Video-MME, EgoSchema, HourVideo, and LVBench benchmarks confirm the superiority of Video-EM, which achieves highly competitive results with performance gains of 4-9 percent over respective baselines while utilizing fewer frames.', 'abstract_zh': '基于人类情景记忆原则的Video-EM：一种无需训练的框架，适用于视频理解与高效问答', 'title_zh': '长视频理解中的情景记忆表示'}
{'arxiv_id': 'arXiv:2508.09473', 'title': 'NeuronTune: Fine-Grained Neuron Modulation for Balanced Safety-Utility Alignment in LLMs', 'authors': 'Birong Pan, Mayi Xu, Qiankun Pi, Jianhao Chen, Yuanyuan Zhu, Ming Zhong, Tieyun Qian', 'link': 'https://arxiv.org/abs/2508.09473', 'abstract': 'Ensuring robust safety alignment while preserving utility is critical for the reliable deployment of Large Language Models (LLMs). However, current techniques fundamentally suffer from intertwined deficiencies: insufficient robustness against malicious attacks, frequent refusal of benign queries, degradation in generated text quality and general task performance--the former two reflecting deficits in robust safety and the latter constituting utility impairment. We trace these limitations to the coarse-grained layer-wise interventions in existing methods. To resolve this, we propose NeuronTune, a fine-grained framework that dynamically modulates sparse neurons to achieve simultaneous safety-utility optimization. Our approach first identifies safety-critical and utility-preserving neurons across all layers via attribution, then employs meta-learning to adaptively amplify safety-neuron activations and suppress utility-neuron activations. Crucially, NeuronTune enables tunable adjustment of intervention scope via neuron-count thresholds, supporting flexible adaptation to security-critical or utility-priority scenarios. Extensive experimental results demonstrate that our method significantly outperforms existing state-of-the-art technologies, achieving superior model safety while maintaining excellent utility.', 'abstract_zh': '确保大型语言模型在保持实用性的同时具备稳健的安全对齐至关重要。然而，当前技术本质上存在根本性的缺陷：对抗恶意攻击的鲁棒性不足、频繁拒绝良性查询、生成文本质量和一般任务性能下降——前两者反映了鲁棒安全性的不足，后者体现了实用性的受损。我们追溯这些限制到现有方法中粗粒度层间干预。为了解决这个问题，我们提出NeuronTune，一种细粒度框架，通过动态调节稀疏神经元来实现安全性和实用性的同步优化。我们的方法首先通过归因在所有层中识别出安全关键且能保持实用性的神经元，然后利用元学习自适应放大安全神经元的激活并抑制实用神经元的激活。最关键的是，NeuronTune通过神经元数量阈值实现可调的干预范围调整，支持对安全性关键或实用性优先场景的灵活适应。广泛的实验结果表明，我们的方法显著优于现有最先进的技术，在保持优异实用性的同时实现了更优的模型安全性。', 'title_zh': 'NeuronTune：平衡安全与效能对齐的精细神经元调制方法'}
{'arxiv_id': 'arXiv:2508.09468', 'title': 'DeepFeatIoT: Unifying Deep Learned, Randomized, and LLM Features for Enhanced IoT Time Series Sensor Data Classification in Smart Industries', 'authors': 'Muhammad Sakib Khan Inan, Kewen Liao', 'link': 'https://arxiv.org/abs/2508.09468', 'abstract': "Internet of Things (IoT) sensors are ubiquitous technologies deployed across smart cities, industrial sites, and healthcare systems. They continuously generate time series data that enable advanced analytics and automation in industries. However, challenges such as the loss or ambiguity of sensor metadata, heterogeneity in data sources, varying sampling frequencies, inconsistent units of measurement, and irregular timestamps make raw IoT time series data difficult to interpret, undermining the effectiveness of smart systems. To address these challenges, we propose a novel deep learning model, DeepFeatIoT, which integrates learned local and global features with non-learned randomized convolutional kernel-based features and features from large language models (LLMs). This straightforward yet unique fusion of diverse learned and non-learned features significantly enhances IoT time series sensor data classification, even in scenarios with limited labeled data. Our model's effectiveness is demonstrated through its consistent and generalized performance across multiple real-world IoT sensor datasets from diverse critical application domains, outperforming state-of-the-art benchmark models. These results highlight DeepFeatIoT's potential to drive significant advancements in IoT analytics and support the development of next-generation smart systems.", 'abstract_zh': '物联网（IoT）传感器是部署在智慧城市、工业场所和 healthcare 系统中的通用技术。它们持续生成时间序列数据，这些数据使工业中的高级分析和自动化成为可能。然而，传感器元数据丢失或模糊、数据源的异构性、采样频率的差异、测量单位的一致性问题以及不规则的时间戳使得原始 IoT 时间序列数据难以解读，从而削弱了智能系统的效果。为了解决这些挑战，我们提出了一种新颖的深度学习模型——DeepFeatIoT，该模型集成了学习到的局部和全局特征、随机卷积核基特征以及大型语言模型（LLMs）的特征。这种简单而独特的不同学习和非学习特征的融合显著提升了物联网时间序列传感器数据的分类效果，即使在标注数据有限的情况下也是如此。我们的模型通过在多个来自多领域的真实世界 IoT 传感器数据集上的持续且泛化的性能表现，展示了其超越现有先进技术基准模型的效果。这些结果突显了DeepFeatIoT 在推动物联网分析进步方面的潜力，并支持下一代智能系统的开发。', 'title_zh': 'DeepFeatIoT：统一深度学习、随机化和大规模语言模型特征以增强智能工业中物联网时间序列传感器数据分类'}
{'arxiv_id': 'arXiv:2508.09461', 'title': 'Gen-AFFECT: Generation of Avatar Fine-grained Facial Expressions with Consistent identiTy', 'authors': 'Hao Yu, Rupayan Mallick, Margrit Betke, Sarah Adel Bargal', 'link': 'https://arxiv.org/abs/2508.09461', 'abstract': 'Different forms of customized 2D avatars are widely used in gaming applications, virtual communication, education, and content creation. However, existing approaches often fail to capture fine-grained facial expressions and struggle to preserve identity across different expressions. We propose GEN-AFFECT, a novel framework for personalized avatar generation that generates expressive and identity-consistent avatars with a diverse set of facial expressions. Our framework proposes conditioning a multimodal diffusion transformer on an extracted identity-expression representation. This enables identity preservation and representation of a wide range of facial expressions. GEN-AFFECT additionally employs consistent attention at inference for information sharing across the set of generated expressions, enabling the generation process to maintain identity consistency over the array of generated fine-grained expressions. GEN-AFFECT demonstrates superior performance compared to previous state-of-the-art methods on the basis of the accuracy of the generated expressions, the preservation of the identity and the consistency of the target identity across an array of fine-grained facial expressions.', 'abstract_zh': '一种新颖的个性化 avatar 生成框架：GEN-AFFECT，用于生成具有多样化面部表达且身份一致的 avatar', 'title_zh': 'Gen-AFFECT: 生成具有一致身份的细粒度 avatar 面部表情'}
{'arxiv_id': 'arXiv:2508.09459', 'title': 'RelayFormer: A Unified Local-Global Attention Framework for Scalable Image and Video Manipulation Localization', 'authors': 'Wen Huang, Jiarui Yang, Tao Dai, Jiawei Li, Shaoxiong Zhan, Bin Wang, Shu-Tao Xia', 'link': 'https://arxiv.org/abs/2508.09459', 'abstract': 'Visual manipulation localization (VML) -- across both images and videos -- is a crucial task in digital forensics that involves identifying tampered regions in visual content. However, existing methods often lack cross-modal generalization and struggle to handle high-resolution or long-duration inputs efficiently.\nWe propose RelayFormer, a unified and modular architecture for visual manipulation localization across images and videos. By leveraging flexible local units and a Global-Local Relay Attention (GLoRA) mechanism, it enables scalable, resolution-agnostic processing with strong generalization. Our framework integrates seamlessly with existing Transformer-based backbones, such as ViT and SegFormer, via lightweight adaptation modules that require only minimal architectural changes, ensuring compatibility without disrupting pretrained representations.\nFurthermore, we design a lightweight, query-based mask decoder that supports one-shot inference across video sequences with linear complexity. Extensive experiments across multiple benchmarks demonstrate that our approach achieves state-of-the-art localization performance, setting a new baseline for scalable and modality-agnostic VML. Code is available at: this https URL.', 'abstract_zh': '视觉操控定位（VML）——适用于图像和视频——是数字鉴证中的一个关键任务，涉及识别视觉内容中的篡改区域。然而，现有方法往往缺乏跨模态的泛化能力，并且难以高效处理高分辨率或长时间的输入。\n\n我们提出RelayFormer，一种用于图像和视频的统一和模块化视觉操控定位架构。通过利用灵活的局部单元和全局-局部传递注意力（GLoRA）机制，它实现了可扩展、分辨率无关的处理能力，并且具有强大的泛化能力。我们的框架可以通过轻量级适应模块无缝集成现有的基于Transformer的骨干网络，如ViT和SegFormer，仅需进行少量的架构改动，确保兼容性而不破坏预训练表示。\n\n此外，我们设计了一种轻量级、基于查询的掩码解码器，支持在视频序列上进行一-shot推理，具有一线性复杂度。在多个基准上的广泛实验表明，我们的方法实现了最先进的定位性能，为可扩展和模态无关的VML设定了新的基准。代码可在以下链接获取：this https URL。', 'title_zh': 'RelayFormer：一种统一的局部-全局注意力框架，用于可扩展的图像和视频操纵定位'}
{'arxiv_id': 'arXiv:2508.09458', 'title': 'Hallucination vs interpretation: rethinking accuracy and precision in AI-assisted data extraction for knowledge synthesis', 'authors': 'Xi Long, Christy Boscardin, Lauren A. Maggio, Joseph A. Costello, Ralph Gonzales, Rasmyah Hammoudeh, Ki Lai, Yoon Soo Park, Brian C. Gin', 'link': 'https://arxiv.org/abs/2508.09458', 'abstract': "Knowledge syntheses (literature reviews) are essential to health professions education (HPE), consolidating findings to advance theory and practice. However, they are labor-intensive, especially during data extraction. Artificial Intelligence (AI)-assisted extraction promises efficiency but raises concerns about accuracy, making it critical to distinguish AI 'hallucinations' (fabricated content) from legitimate interpretive differences. We developed an extraction platform using large language models (LLMs) to automate data extraction and compared AI to human responses across 187 publications and 17 extraction questions from a published scoping review. AI-human, human-human, and AI-AI consistencies were measured using interrater reliability (categorical) and thematic similarity ratings (open-ended). Errors were identified by comparing extracted responses to source publications. AI was highly consistent with humans for concrete, explicitly stated questions (e.g., title, aims) and lower for questions requiring subjective interpretation or absent in text (e.g., Kirkpatrick's outcomes, study rationale). Human-human consistency was not higher than AI-human and showed the same question-dependent variability. Discordant AI-human responses (769/3179 = 24.2%) were mostly due to interpretive differences (18.3%); AI inaccuracies were rare (1.51%), while humans were nearly three times more likely to state inaccuracies (4.37%). Findings suggest AI accuracy depends more on interpretability than hallucination. Repeating AI extraction can identify interpretive complexity or ambiguity, refining processes before human review. AI can be a transparent, trustworthy partner in knowledge synthesis, though caution is needed to preserve critical human insights.", 'abstract_zh': '大型语言模型辅助的数据提取平台在健康专业教育中的应用：基于187篇出版文献和17项提取问题的比较研究', 'title_zh': '幻觉 vs 解释：重新思考AI辅助数据抽取用于知识综合的准确性和精确性'}
{'arxiv_id': 'arXiv:2508.09451', 'title': 'A Unified Contrastive-Generative Framework for Time Series Classification', 'authors': 'Ziyu Liu, Azadeh Alavi, Minyi Li, Xiang Zhang', 'link': 'https://arxiv.org/abs/2508.09451', 'abstract': "Self-supervised learning (SSL) for multivariate time series mainly includes two paradigms: contrastive methods that excel at instance discrimination and generative approaches that model data distributions. While effective individually, their complementary potential remains unexplored. We propose a Contrastive Generative Time series framework (CoGenT), the first framework to unify these paradigms through joint contrastive-generative optimization. CoGenT addresses fundamental limitations of both approaches: it overcomes contrastive learning's sensitivity to high intra-class similarity in temporal data while reducing generative methods' dependence on large datasets. We evaluate CoGenT on six diverse time series datasets. The results show consistent improvements, with up to 59.2% and 14.27% F1 gains over standalone SimCLR and MAE, respectively. Our analysis reveals that the hybrid objective preserves discriminative power while acquiring generative robustness. These findings establish a foundation for hybrid SSL in temporal domains. We will release the code shortly.", 'abstract_zh': '自监督学习（SSL）在多变量时间序列中的主要包含两种范式：擅长实例 discrimination 的对比方法和建模数据分布的生成方法。虽然这两种方法单独有效，但它们互补的潜力尚未被探索。我们提出了一种对比生成时间序列框架（CoGenT），这是首次通过联合对比-生成优化将这两种范式统一起来。CoGenT 解决了这两种方法的基本局限性：克服了对比学习在时间数据中高类内相似性上的敏感性，同时减少了生成方法对大规模数据集的依赖。我们在六个不同的时间序列数据集上评估了 CoGenT。结果显示，与独立的 SimCLR 和 MAE 相比，CoGenT 在 F1 值上分别提高了 59.2% 和 14.27%。我们的分析表明，混合目标既保留了区分能力又获得了生成的鲁棒性。这些发现为时间域中的混合 SSL 打下了基础。我们将很快发布代码。', 'title_zh': '统一对比生成框架的时间序列分类'}
{'arxiv_id': 'arXiv:2508.09442', 'title': 'Shadow in the Cache: Unveiling and Mitigating Privacy Risks of KV-cache in LLM Inference', 'authors': 'Zhifan Luo, Shuo Shao, Su Zhang, Lijing Zhou, Yuke Hu, Chenxu Zhao, Zhihao Liu, Zhan Qin', 'link': 'https://arxiv.org/abs/2508.09442', 'abstract': 'The Key-Value (KV) cache, which stores intermediate attention computations (Key and Value pairs) to avoid redundant calculations, is a fundamental mechanism for accelerating Large Language Model (LLM) inference. However, this efficiency optimization introduces significant yet underexplored privacy risks. This paper provides the first comprehensive analysis of these vulnerabilities, demonstrating that an attacker can reconstruct sensitive user inputs directly from the KV-cache. We design and implement three distinct attack vectors: a direct Inversion Attack, a more broadly applicable and potent Collision Attack, and a semantic-based Injection Attack. These methods demonstrate the practicality and severity of KV-cache privacy leakage issues. To mitigate this, we propose KV-Cloak, a novel, lightweight, and efficient defense mechanism. KV-Cloak uses a reversible matrix-based obfuscation scheme, combined with operator fusion, to secure the KV-cache. Our extensive experiments show that KV-Cloak effectively thwarts all proposed attacks, reducing reconstruction quality to random noise. Crucially, it achieves this robust security with virtually no degradation in model accuracy and minimal performance overhead, offering a practical solution for trustworthy LLM deployment.', 'abstract_zh': 'KV缓存中的关键价值(KV)缓存存储中间注意力计算（键和值对）以避免冗余计算，是加速大型语言模型（LLM）推理的基本机制。然而，这种效率优化引入了迄今为止尚未充分探索的重大隐私风险。本文首次全面分析了这些漏洞，证明攻击者可以直接从KV缓存中重构敏感用户输入。我们设计并实现了三种不同的攻击向量：直接反转攻击、更为广泛适用和有力的碰撞攻击以及基于语义的注入攻击。这些方法展示了KV缓存隐私泄露问题的实用性和严重性。为缓解这一问题，我们提出了KV-Cloak，这是一种新颖、轻量级且高效的防御机制。KV-Cloak 使用可逆矩阵基扭曲方案，结合操作符融合，以确保KV缓存的安全性。我们广泛的实验表明，KV-Cloak 能够有效地阻止所有提出的攻击，将重构质量降低到随机噪声。最关键的是，它在几乎不降低模型准确性和最小化性能开销的情况下实现了这种健壮的安全性，为可信的LLM部署提供了实用解决方案。', 'title_zh': '缓存中的阴影：揭示并缓解LLM推理中KV-cache的隐私风险'}
{'arxiv_id': 'arXiv:2508.09428', 'title': 'What-Meets-Where: Unified Learning of Action and Contact Localization in a New Dataset', 'authors': 'Yuxiao Wang, Yu Lei, Wolin Liang, Weiying Xue, Zhenao Wei, Nan Zhuang, Qi Liu', 'link': 'https://arxiv.org/abs/2508.09428', 'abstract': 'People control their bodies to establish contact with the environment. To comprehensively understand actions across diverse visual contexts, it is essential to simultaneously consider \\textbf{what} action is occurring and \\textbf{where} it is happening. Current methodologies, however, often inadequately capture this duality, typically failing to jointly model both action semantics and their spatial contextualization within scenes. To bridge this gap, we introduce a novel vision task that simultaneously predicts high-level action semantics and fine-grained body-part contact regions. Our proposed framework, PaIR-Net, comprises three key components: the Contact Prior Aware Module (CPAM) for identifying contact-relevant body parts, the Prior-Guided Concat Segmenter (PGCS) for pixel-wise contact segmentation, and the Interaction Inference Module (IIM) responsible for integrating global interaction relationships. To facilitate this task, we present PaIR (Part-aware Interaction Representation), a comprehensive dataset containing 13,979 images that encompass 654 actions, 80 object categories, and 17 body parts. Experimental evaluation demonstrates that PaIR-Net significantly outperforms baseline approaches, while ablation studies confirm the efficacy of each architectural component. The code and dataset will be released upon publication.', 'abstract_zh': '人体控制其动作以与环境建立联系。为了全面理解跨多样化视觉场景的动作，同时考虑动作的类型及其发生的位置至关重要。现有方法往往未能充分捕捉到这一双重性，通常无法同时建模动作语义及其在场景中的空间上下文。为弥补这一差距，我们提出了一个新的视觉任务，同时预测高层次的动作语义和细粒度的身体部位接触区域。我们提出的PaIR-Net框架包括三个关键组件：接触先验感知模块（CPAM）用于识别与接触相关的身体部位、先验引导 CONCAT 聚合同步分割器（PGCS）用于像素级接触分割，以及交互推理模块（IIM）用于整合全局交互关系。为了促进此任务，我们发布了PaIR（部分感知交互表示）数据集，包含13,979张图像，涵盖了654种动作、80种物体类别和17种身体部位。实验评价表明，PaIR-Net 显著优于基线方法，且消融研究证实了每个架构组件的有效性。代码和数据集将在发表时公开。', 'title_zh': '何遇何地：新数据集中的动作与接触定位联合学习'}
{'arxiv_id': 'arXiv:2508.09427', 'title': 'Implicit Hypergraph Neural Networks: A Stable Framework for Higher-Order Relational Learning with Provable Guarantees', 'authors': 'Xiaoyu Li, Guangyu Tang, Jiaojiao Jiang', 'link': 'https://arxiv.org/abs/2508.09427', 'abstract': 'Many real-world interactions are group-based rather than pairwise such as papers with multiple co-authors and users jointly engaging with items. Hypergraph neural networks have shown great promise at modeling higher-order relations, but their reliance on a fixed number of explicit message-passing layers limits long-range dependency capture and can destabilize training as depth grows. In this work, we introduce Implicit Hypergraph Neural Networks (IHGNN), which bring the implicit equilibrium formulation to hypergraphs: instead of stacking layers, IHGNN computes representations as the solution to a nonlinear fixed-point equation, enabling stable and efficient global propagation across hyperedges without deep architectures. We develop a well-posed training scheme with provable convergence, analyze the oversmoothing conditions and expressivity of the model, and derive a transductive generalization bound on hypergraphs. We further present an implicit-gradient training procedure coupled with a projection-based stabilization strategy. Extensive experiments on citation benchmarks show that IHGNN consistently outperforms strong traditional graph/hypergraph neural network baselines in both accuracy and robustness. Empirically, IHGNN is resilient to random initialization and hyperparameter variation, highlighting its strong generalization and practical value for higher-order relational learning.', 'abstract_zh': '隐式超图神经网络：面向超图的隐式均衡表示', 'title_zh': '隐式超图神经网络：一种具有可证明保证的高阶关系学习稳定框架'}
{'arxiv_id': 'arXiv:2508.09418', 'title': 'Domain-Generalization to Improve Learning in Meta-Learning Algorithms', 'authors': 'Usman Anjum, Chris Stockman, Cat Luong, Justin Zhan', 'link': 'https://arxiv.org/abs/2508.09418', 'abstract': 'This paper introduces Domain Generalization Sharpness-Aware Minimization Model-Agnostic Meta-Learning (DGS-MAML), a novel meta-learning algorithm designed to generalize across tasks with limited training data. DGS-MAML combines gradient matching with sharpness-aware minimization in a bi-level optimization framework to enhance model adaptability and robustness. We support our method with theoretical analysis using PAC-Bayes and convergence guarantees. Experimental results on benchmark datasets show that DGS-MAML outperforms existing approaches in terms of accuracy and generalization. The proposed method is particularly useful for scenarios requiring few-shot learning and quick adaptation, and the source code is publicly available at GitHub.', 'abstract_zh': '基于凹度aware最小化的方法不变域泛化元学习模型（DGS-MAML）', 'title_zh': '泛化域提升元学习算法中的学习能力'}
{'arxiv_id': 'arXiv:2508.09415', 'title': 'RampNet: A Two-Stage Pipeline for Bootstrapping Curb Ramp Detection in Streetscape Images from Open Government Metadata', 'authors': "John S. O'Meara, Jared Hwang, Zeyu Wang, Michael Saugstad, Jon E. Froehlich", 'link': 'https://arxiv.org/abs/2508.09415', 'abstract': 'Curb ramps are critical for urban accessibility, but robustly detecting them in images remains an open problem due to the lack of large-scale, high-quality datasets. While prior work has attempted to improve data availability with crowdsourced or manually labeled data, these efforts often fall short in either quality or scale. In this paper, we introduce and evaluate a two-stage pipeline called RampNet to scale curb ramp detection datasets and improve model performance. In Stage 1, we generate a dataset of more than 210,000 annotated Google Street View (GSV) panoramas by auto-translating government-provided curb ramp location data to pixel coordinates in panoramic images. In Stage 2, we train a curb ramp detection model (modified ConvNeXt V2) from the generated dataset, achieving state-of-the-art performance. To evaluate both stages of our pipeline, we compare to manually labeled panoramas. Our generated dataset achieves 94.0% precision and 92.5% recall, and our detection model reaches 0.9236 AP -- far exceeding prior work. Our work contributes the first large-scale, high-quality curb ramp detection dataset, benchmark, and model.', 'abstract_zh': '基于图像的无障碍坡道检测：RampNet双阶段管道方法', 'title_zh': 'RampNet：街道景观图像中开放政府元数据辅助坡道检测的两阶段框架'}
{'arxiv_id': 'arXiv:2508.09385', 'title': 'Understanding Dementia Speech Alignment with Diffusion-Based Image Generation', 'authors': 'Mansi, Anastasios Lepipas, Dominika Woszczyk, Yiying Guan, Soteris Demetriou', 'link': 'https://arxiv.org/abs/2508.09385', 'abstract': 'Text-to-image models generate highly realistic images based on natural language descriptions and millions of users use them to create and share images online. While it is expected that such models can align input text and generated image in the same latent space little has been done to understand whether this alignment is possible between pathological speech and generated images. In this work, we examine the ability of such models to align dementia-related speech information with the generated images and develop methods to explain this alignment. Surprisingly, we found that dementia detection is possible from generated images alone achieving 75% accuracy on the ADReSS dataset. We then leverage explainability methods to show which parts of the language contribute to the detection.', 'abstract_zh': '基于自然语言描述生成高度逼真图像的文本-to-图像模型被数百万用户用于在线创作和分享图像。尽管预计这些模型能够将输入文本和生成图像在相同的潜在空间中对齐，但对病理语言与生成图像间对齐可能性的研究甚少。在本文中，我们探讨了此类模型将与痴呆相关的语言信息与生成图像对齐的能力，并开发了解释这种对齐的方法。令人惊讶的是，我们发现仅从生成的图像中就可以检测痴呆，准确率达到ADReSS数据集的75%。随后，我们利用可解释性方法展示了哪些部分的语言对检测做出了贡献。', 'title_zh': '基于扩散驱动的图像生成理解痴呆症言语对\nuser\n基于全局时空注意力的跨模态表达学习研究'}
{'arxiv_id': 'arXiv:2508.09383', 'title': 'X-UniMotion: Animating Human Images with Expressive, Unified and Identity-Agnostic Motion Latents', 'authors': 'Guoxian Song, Hongyi Xu, Xiaochen Zhao, You Xie, Tianpei Gu, Zenan Li, Chenxu Zhang, Linjie Luo', 'link': 'https://arxiv.org/abs/2508.09383', 'abstract': 'We present X-UniMotion, a unified and expressive implicit latent representation for whole-body human motion, encompassing facial expressions, body poses, and hand gestures. Unlike prior motion transfer methods that rely on explicit skeletal poses and heuristic cross-identity adjustments, our approach encodes multi-granular motion directly from a single image into a compact set of four disentangled latent tokens -- one for facial expression, one for body pose, and one for each hand. These motion latents are both highly expressive and identity-agnostic, enabling high-fidelity, detailed cross-identity motion transfer across subjects with diverse identities, poses, and spatial configurations.\nTo achieve this, we introduce a self-supervised, end-to-end framework that jointly learns the motion encoder and latent representation alongside a DiT-based video generative model, trained on large-scale, diverse human motion datasets. Motion--identity disentanglement is enforced via 2D spatial and color augmentations, as well as synthetic 3D renderings of cross-identity subject pairs under shared poses. Furthermore, we guide motion token learning with auxiliary decoders that promote fine-grained, semantically aligned, and depth-aware motion embeddings.\nExtensive experiments show that X-UniMotion outperforms state-of-the-art methods, producing highly expressive animations with superior motion fidelity and identity preservation.', 'abstract_zh': 'X-UniMotion：统一且表达丰富的整体人体运动隐式潜在表示', 'title_zh': 'X-UniMotion: 动态人类图像的表情化、统一且身份无关的动力学潜在表示'}
{'arxiv_id': 'arXiv:2508.09381', 'title': 'What Can We Learn from Inter-Annotator Variability in Skin Lesion Segmentation?', 'authors': 'Kumar Abhishek, Jeremy Kawahara, Ghassan Hamarneh', 'link': 'https://arxiv.org/abs/2508.09381', 'abstract': 'Medical image segmentation exhibits intra- and inter-annotator variability due to ambiguous object boundaries, annotator preferences, expertise, and tools, among other factors. Lesions with ambiguous boundaries, e.g., spiculated or infiltrative nodules, or irregular borders per the ABCD rule, are particularly prone to disagreement and are often associated with malignancy. In this work, we curate IMA++, the largest multi-annotator skin lesion segmentation dataset, on which we conduct an in-depth study of variability due to annotator, malignancy, tool, and skill factors. We find a statistically significant (p<0.001) association between inter-annotator agreement (IAA), measured using Dice, and the malignancy of skin lesions. We further show that IAA can be accurately predicted directly from dermoscopic images, achieving a mean absolute error of 0.108. Finally, we leverage this association by utilizing IAA as a "soft" clinical feature within a multi-task learning objective, yielding a 4.2% improvement in balanced accuracy averaged across multiple model architectures and across IMA++ and four public dermoscopic datasets. The code is available at this https URL.', 'abstract_zh': '医学图像分割因注释者之间和内部的一致性差异受到对象边界模糊、注释者偏好、专业水平和工具等因素的影响。边界模糊的病灶，例如刺状或浸润性结节，或者根据ABCD规则具有不规则边界的病灶，特别容易出现分歧，并且经常与恶性病变相关。在本工作中，我们编纂了IMA++，这是最大的多注释者皮肤病变分割数据集，在此基础上我们深入研究了由注释者、恶性病变、工具和技能因素导致的一致性差异。我们发现使用Dice衡量的注释者间一致性（IAA）与皮肤病变的恶性程度之间存在统计学显著（p<0.001）的相关性。进一步地，我们展示了IAA可以从皮肤镜图像直接准确预测，平均绝对误差为0.108。最后，我们利用这种相关性，通过将IAA作为“软”临床特征纳入多任务学习目标，实现了4.2%的均衡准确率提升，这一结果在多个模型架构和IMA++及四个公开的皮肤镜数据集上均有体现。代码可在以下链接获取。', 'title_zh': '从皮肤病变分割的注释者变异性中我们可以学到什么？'}
{'arxiv_id': 'arXiv:2508.09378', 'title': 'APIO: Automatic Prompt Induction and Optimization for Grammatical Error Correction and Text Simplification', 'authors': 'Artem Chernodub, Aman Saini, Yejin Huh, Vivek Kulkarni, Vipul Raheja', 'link': 'https://arxiv.org/abs/2508.09378', 'abstract': 'Recent advancements in large language models (LLMs) have enabled a wide range of natural language processing (NLP) tasks to be performed through simple prompt-based interactions. Consequently, several approaches have been proposed to engineer prompts that most effectively enable LLMs to perform a given task (e.g., chain-of-thought prompting). In settings with a well-defined metric to optimize model performance, automatic prompt optimization (APO) methods have been developed to refine a seed prompt. Advancing this line of research, we propose APIO, a simple but effective prompt induction and optimization approach for the tasks of Grammatical Error Correction (GEC) and Text Simplification, without relying on manually specified seed prompts. APIO achieves a new state-of-the-art performance for purely LLM-based prompting methods on these tasks. We make our data, code, prompts, and outputs publicly available.', 'abstract_zh': 'Recent advancements in大型语言模型（LLMs）使得通过简单的提示式交互执行一系列自然语言处理（NLP）任务成为可能。因此，已经提出了多种方法来设计最有效地使LLMs执行给定任务的提示（例如，思维链提示）。在有明确优化指标的环境中，已经开发了自动提示优化（APO）方法来改进种子提示。在此研究方向上，我们提出了一种名为APIO的简单而有效的提示生成与优化方法，用于语法规则错误纠正（GEC）和文本简化任务，无需依赖人工指定的种子提示。APIO在这些任务上的性能达到了基于LLMs提示方法的新最佳水平。我们公开了我们的数据、代码、提示和输出。', 'title_zh': 'APIO：自动提示诱导与优化在语法错误纠正和文本简化中的应用'}
{'arxiv_id': 'arXiv:2508.09372', 'title': 'A Signer-Invariant Conformer and Multi-Scale Fusion Transformer for Continuous Sign Language Recognition', 'authors': 'Md Rezwanul Haque, Md. Milon Islam, S M Taslim Uddin Raju, Fakhri Karray', 'link': 'https://arxiv.org/abs/2508.09372', 'abstract': "Continuous Sign Language Recognition (CSLR) faces multiple challenges, including significant inter-signer variability and poor generalization to novel sentence structures. Traditional solutions frequently fail to handle these issues efficiently. For overcoming these constraints, we propose a dual-architecture framework. For the Signer-Independent (SI) challenge, we propose a Signer-Invariant Conformer that combines convolutions with multi-head self-attention to learn robust, signer-agnostic representations from pose-based skeletal keypoints. For the Unseen-Sentences (US) task, we designed a Multi-Scale Fusion Transformer with a novel dual-path temporal encoder that captures both fine-grained posture dynamics, enabling the model's ability to comprehend novel grammatical compositions. Experiments on the challenging Isharah-1000 dataset establish a new standard for both CSLR benchmarks. The proposed conformer architecture achieves a Word Error Rate (WER) of 13.07% on the SI challenge, a reduction of 13.53% from the state-of-the-art. On the US task, the transformer model scores a WER of 47.78%, surpassing previous work. In the SignEval 2025 CSLR challenge, our team placed 2nd in the US task and 4th in the SI task, demonstrating the performance of these models. The findings validate our key hypothesis: that developing task-specific networks designed for the particular challenges of CSLR leads to considerable performance improvements and establishes a new baseline for further research. The source code is available at: this https URL.", 'abstract_zh': '连续手语识别（CSLR）面临的挑战包括显著的发际间变异性以及对新型句子结构的 poor 通用性。传统解决方案往往难以高效应对这些难题。为克服这些限制，我们提出了一种双架构框架。对于发际间不变性（SI）挑战，我们提出了一个招式不变式 Conformer，结合卷积与多头自我注意，从基于姿态的骨骼关键点中学习 robust、招式无偏的表示。对于未见句子（US）任务，我们设计了一种多尺度融合变换器，带有新颖的双路径时间编码器，能够捕捉细微的姿态动力学，使模型能够理解新型语法组成。在具有挑战性的 Isharah-1000 数据集上的实验确立了 CSLR 基准的新标准。提出的 Conformer 架构在 SI 挑战中实现了 13.07% 的词错误率（WER），比最先进的方法降低了 13.53%。在 US 任务中，变换器模型的 WER 为 47.78%，超过了之前的工作。在 SignEval 2025 CSLR 挑战中，我们的团队在 US 任务中排名第 2，在 SI 任务中排名第 4，展示了这些模型的性能。研究结果验证了我们的核心假设：开发针对 CSLR 特定挑战的任务特定网络可以带来显著的性能提升，并为未来的进一步研究建立了新的基线。源代码可在以下链接获取：this https URL。', 'title_zh': '基于标识者不变的收敛器和多尺度融合变压器的连续手语识别'}
{'arxiv_id': 'arXiv:2508.09362', 'title': 'FusionEnsemble-Net: An Attention-Based Ensemble of Spatiotemporal Networks for Multimodal Sign Language Recognition', 'authors': 'Md. Milon Islam, Md Rezwanul Haque, S M Taslim Uddin Raju, Fakhri Karray', 'link': 'https://arxiv.org/abs/2508.09362', 'abstract': "Accurate recognition of sign language in healthcare communication poses a significant challenge, requiring frameworks that can accurately interpret complex multimodal gestures. To deal with this, we propose FusionEnsemble-Net, a novel attention-based ensemble of spatiotemporal networks that dynamically fuses visual and motion data to enhance recognition accuracy. The proposed approach processes RGB video and range Doppler map radar modalities synchronously through four different spatiotemporal networks. For each network, features from both modalities are continuously fused using an attention-based fusion module before being fed into an ensemble of classifiers. Finally, the outputs of these four different fused channels are combined in an ensemble classification head, thereby enhancing the model's robustness. Experiments demonstrate that FusionEnsemble-Net outperforms state-of-the-art approaches with a test accuracy of 99.44% on the large-scale MultiMeDaLIS dataset for Italian Sign Language. Our findings indicate that an ensemble of diverse spatiotemporal networks, unified by attention-based fusion, yields a robust and accurate framework for complex, multimodal isolated gesture recognition tasks. The source code is available at: this https URL.", 'abstract_zh': '基于 Attention 的时空网络融合体系结构在手语识别中的应用：一种增强准确性的新方法', 'title_zh': '基于注意力机制的时空网络融合 ensemble 模型：多种模态手语识别'}
{'arxiv_id': 'arXiv:2508.09349', 'title': 'The Human-AI Hybrid Delphi Model: A Structured Framework for Context-Rich, Expert Consensus in Complex Domains', 'authors': 'Cathy Speed, Ahmed A. Metwally', 'link': 'https://arxiv.org/abs/2508.09349', 'abstract': 'Expert consensus plays a critical role in domains where evidence is complex, conflicting, or insufficient for direct prescription. Traditional methods, such as Delphi studies, consensus conferences, and systematic guideline synthesis, offer structure but face limitations including high panel burden, interpretive oversimplification, and suppression of conditional nuance. These challenges are now exacerbated by information overload, fragmentation of the evidence base, and increasing reliance on publicly available sources that lack expert filtering. This study introduces and evaluates a Human-AI Hybrid Delphi (HAH-Delphi) framework designed to augment expert consensus development by integrating a generative AI model (Gemini 2.5 Pro), small panels of senior human experts, and structured facilitation. The HAH-Delphi was tested in three phases: retrospective replication, prospective comparison, and applied deployment in two applied domains (endurance training and resistance and mixed cardio/strength training). The AI replicated 95% of published expert consensus conclusions in Phase I and showed 95% directional agreement with senior human experts in Phase II, though it lacked experiential and pragmatic nuance. In Phase III, compact panels of six senior experts achieved >90% consensus coverage and reached thematic saturation before the final participant. The AI provided consistent, literature-grounded scaffolding that supported divergence resolution and accelerated saturation. The HAH-Delphi framework offers a flexible, scalable approach for generating high-quality, context-sensitive consensus. Its successful application across health, coaching, and performance science confirms its methodological robustness and supports its use as a foundation for generating conditional, personalised guidance and published consensus frameworks at scale.', 'abstract_zh': '专家共识在证据复杂、冲突或不足的领域发挥着关键作用。传统的德尔菲研究、共识会议和系统指南综述方法虽提供了结构，但也存在专家负担重、解释简化和条件性细微差异被抑制等局限性。这些挑战如今因信息过载、证据基础碎片化以及对缺乏专家筛选的公共来源的日益依赖而被进一步加剧。本研究介绍并评估了结合生成式AI模型（Gemini 2.5 Pro）、细分的资深人类专家小组和结构化促进的混合人机德尔菲（HAH-Delphi）框架，以增强专家共识的发展。HAH-Delphi框架在三个阶段进行了测试：回顾性复制、前瞻性对比以及在两个应用领域（耐力训练和抗阻及混合有氧/力量训练）的应用部署。在第一阶段，AI复制了95%的已发表专家共识结论，在第二阶段，其与资深人类专家在方向上达成了95%的一致性，尽管缺乏经验性和实用性细微差异。在第三阶段，六名资深专家组成的精炼小组在最终参与者之前实现了>90%的主题饱和。AI提供了持续、基于文献的支撑，促进了分歧的解决并加速了饱和。HAH-Delphi框架提供了一种灵活且可扩展的方法，用于生成高质量、适用性敏感的共识。其在健康、教练和表现科学领域的成功应用证实了其方法论的稳健性，并支持其作为生成条件化和个性化指导及出版共识框架的基础工具的应用。', 'title_zh': '人类与AI混合德尔菲模型：一种结构化的框架，用于复杂领域丰富的上下文专家共识'}
{'arxiv_id': 'arXiv:2508.09340', 'title': 'Collective dynamics of strategic classification', 'authors': 'Marta C. Couto, Flavia Barsotti, Fernando P. Santos', 'link': 'https://arxiv.org/abs/2508.09340', 'abstract': "Classification algorithms based on Artificial Intelligence (AI) are nowadays applied in high-stakes decisions in finance, healthcare, criminal justice, or education. Individuals can strategically adapt to the information gathered about classifiers, which in turn may require algorithms to be re-trained. Which collective dynamics will result from users' adaptation and algorithms' retraining? We apply evolutionary game theory to address this question. Our framework provides a mathematically rigorous way of treating the problem of feedback loops between collectives of users and institutions, allowing to test interventions to mitigate the adverse effects of strategic adaptation. As a case study, we consider institutions deploying algorithms for credit lending. We consider several scenarios, each representing different interaction paradigms. When algorithms are not robust against strategic manipulation, we are able to capture previous challenges discussed in the strategic classification literature, whereby users either pay excessive costs to meet the institutions' expectations (leading to high social costs) or game the algorithm (e.g., provide fake information). From this baseline setting, we test the role of improving gaming detection and providing algorithmic recourse. We show that increased detection capabilities reduce social costs and could lead to users' improvement; when perfect classifiers are not feasible (likely to occur in practice), algorithmic recourse can steer the dynamics towards high users' improvement rates. The speed at which the institutions re-adapt to the user's population plays a role in the final outcome. Finally, we explore a scenario where strict institutions provide actionable recourse to their unsuccessful users and observe cycling dynamics so far unnoticed in the literature.", 'abstract_zh': '基于人工智能的分类算法在金融、医疗、刑事司法或教育领域的高风险决策中得到应用。个体可能会战略性地适应收集到的分类器信息，这反过来可能要求算法重新训练。用户适应和算法重新训练将产生何种集体动态？我们应用进化博弈论来回答这一问题。我们的框架提供了一种数学严谨的方法来处理用户集体与机构之间的反馈回路问题，允许测试减轻策略性适应负面影响的干预措施。作为案例研究，我们考虑机构部署用于信用贷款的算法。我们考虑了几个场景，每个场景代表不同的互动模式。当算法不具备对抗战略性操纵的鲁棒性时，我们能够捕捉战略分类文献中讨论的先前挑战，即用户要么付出过高的成本以满足机构的期望（导致高昂的社会成本），要么利用算法（例如，提供虚假信息）。从这一基线设置出发，我们测试了提升策略性利用检测能力和提供算法回溯的作用。我们表明，增强的检测能力可以降低社会成本，并可能促使用户改进；当完美的分类器不可行（在实践中很可能发生）时，算法回溯可以引导动态走向高用户改进率。机构重新适应用户群体的速度对最终结果起着作用。最后，我们探讨了一个严格的机构向其不成功用户提供可操作回溯的情景，并观察到到目前为止在文献中未注意到的循环动态。', 'title_zh': '战略分类的集体动力学'}
{'arxiv_id': 'arXiv:2508.09334', 'title': 'RicciFlowRec: A Geometric Root Cause Recommender Using Ricci Curvature on Financial Graphs', 'authors': 'Zhongtian Sun, Anoushka Harit', 'link': 'https://arxiv.org/abs/2508.09334', 'abstract': 'We propose RicciFlowRec, a geometric recommendation framework that performs root cause attribution via Ricci curvature and flow on dynamic financial graphs. By modelling evolving interactions among stocks, macroeconomic indicators, and news, we quantify local stress using discrete Ricci curvature and trace shock propagation via Ricci flow. Curvature gradients reveal causal substructures, informing a structural risk-aware ranking function. Preliminary results on S\\&P~500 data with FinBERT-based sentiment show improved robustness and interpretability under synthetic perturbations. This ongoing work supports curvature-based attribution and early-stage risk-aware ranking, with plans for portfolio optimization and return forecasting. To our knowledge, RicciFlowRec is the first recommender to apply geometric flow-based reasoning in financial decision support.', 'abstract_zh': '我们提出RicciFlowRec，一种基于 Ricci 曲率和流的几何推荐框架，通过动态金融图上的 Ricci 曲率和流执行根本原因归因。通过建模股票、宏观经济指标和新闻之间 evolving 的交互，我们使用离散 Ricci 曲率定量局部应力，并通过 Ricci 流追踪冲击传播。曲率梯度揭示因果子结构，为结构风险意识排名功能提供信息。基于 FinBERT 的情绪分析在 S&P 500 数据上初步结果显示，在合成扰动下具有改进的鲁棒性和可解释性。这项正在进行的工作支持基于曲率的归因和早期风险意识排名，并计划应用于投资组合优化和收益预测。据我们所知，RicciFlowRec 是首个在金融决策支持中应用几何流推理的推荐系统。', 'title_zh': 'RicciFlowRec：一种基于金融图中 Ricci 曲率的几何根因推荐系统'}
{'arxiv_id': 'arXiv:2508.09330', 'title': 'Synaptic Pruning: A Biological Inspiration for Deep Learning Regularization', 'authors': 'Gideon Vos, Liza van Eijk, Zoltan Sarnyai, Mostafa Rahimi Azghadi', 'link': 'https://arxiv.org/abs/2508.09330', 'abstract': 'Synaptic pruning in biological brains removes weak connections to improve efficiency. In contrast, dropout regularization in artificial neural networks randomly deactivates neurons without considering activity-dependent pruning. We propose a magnitude-based synaptic pruning method that better reflects biology by progressively removing low-importance connections during training. Integrated directly into the training loop as a dropout replacement, our approach computes weight importance from absolute magnitudes across layers and applies a cubic schedule to gradually increase global sparsity. At fixed intervals, pruning masks permanently remove low-importance weights while maintaining gradient flow for active ones, eliminating the need for separate pruning and fine-tuning phases. Experiments on multiple time series forecasting models including RNN, LSTM, and Patch Time Series Transformer across four datasets show consistent gains. Our method ranked best overall, with statistically significant improvements confirmed by Friedman tests (p < 0.01). In financial forecasting, it reduced Mean Absolute Error by up to 20% over models with no or standard dropout, and up to 52% in select transformer models. This dynamic pruning mechanism advances regularization by coupling weight elimination with progressive sparsification, offering easy integration into diverse architectures. Its strong performance, especially in financial time series forecasting, highlights its potential as a practical alternative to conventional dropout techniques.', 'abstract_zh': '基于幅度的突触剪枝方法通过渐进移除低重要性连接更好地反映生物学原理', 'title_zh': '突触修剪：对深度学习正则化的一种生物灵感'}
{'arxiv_id': 'arXiv:2508.09325', 'title': 'SegDAC: Segmentation-Driven Actor-Critic for Visual Reinforcement Learning', 'authors': 'Alexandre Brown, Glen Berseth', 'link': 'https://arxiv.org/abs/2508.09325', 'abstract': 'Visual reinforcement learning (RL) is challenging due to the need to learn both perception and actions from high-dimensional inputs and noisy rewards. Although large perception models exist, integrating them effectively into RL for visual generalization and improved sample efficiency remains unclear. We propose SegDAC, a Segmentation-Driven Actor-Critic method. SegDAC uses Segment Anything (SAM) for object-centric decomposition and YOLO-World to ground segments semantically via text prompts. It includes a novel transformer-based architecture that supports a dynamic number of segments at each time step and effectively learns which segments to focus on using online RL, without using human labels. By evaluating SegDAC over a challenging visual generalization benchmark using Maniskill3, which covers diverse manipulation tasks under strong visual perturbations, we demonstrate that SegDAC achieves significantly better visual generalization, doubling prior performance on the hardest setting and matching or surpassing prior methods in sample efficiency across all evaluated tasks.', 'abstract_zh': 'Segmentation-驱动的Actor- Critic方法（SegDAC）：基于视觉分割的强化学习方法', 'title_zh': 'SegDAC：基于分割的演员-评论家视觉强化学习'}
{'arxiv_id': 'arXiv:2508.09324', 'title': 'TEN: Table Explicitization, Neurosymbolically', 'authors': 'Nikita Mehrotra, Aayush Kumar, Sumit Gulwani, Arjun Radhakrishna, Ashish Tiwari', 'link': 'https://arxiv.org/abs/2508.09324', 'abstract': "We present a neurosymbolic approach, TEN, for extracting tabular data from semistructured input text. This task is particularly challenging for text input that does not use special delimiters consistently to separate columns and rows. Purely neural approaches perform poorly due to hallucinations and their inability to enforce hard constraints. TEN uses Structural Decomposition prompting - a specialized chain-of-thought prompting approach - on a large language model (LLM) to generate an initial table, and thereafter uses a symbolic checker to evaluate not only the well-formedness of that table, but also detect cases of hallucinations or forgetting. The output of the symbolic checker is processed by a critique-LLM to generate guidance for fixing the table, which is presented to the original LLM in a self-debug loop. Our extensive experiments demonstrate that TEN significantly outperforms purely neural baselines across multiple datasets and metrics, achieving significantly higher exact match accuracy and substantially reduced hallucination rates. A 21-participant user study further confirms that TEN's tables are rated significantly more accurate (mean score: 5.0 vs 4.3; p = 0.021), and are consistently preferred for ease of verification and correction, with participants favoring our method in over 60% of the cases.", 'abstract_zh': '一种用于从半结构化输入文本中提取表格数据的神经符号方法：TEN', 'title_zh': 'TEN：表的显式表示，神经符号化'}
{'arxiv_id': 'arXiv:2508.09323', 'title': 'Leveraging Large Language Models for Rare Disease Named Entity Recognition', 'authors': 'Nan Miles Xi, Yu Deng, Lin Wang', 'link': 'https://arxiv.org/abs/2508.09323', 'abstract': 'Named Entity Recognition (NER) in the rare disease domain poses unique challenges due to limited labeled data, semantic ambiguity between entity types, and long-tail distributions. In this study, we evaluate the capabilities of GPT-4o for rare disease NER under low-resource settings, using a range of prompt-based strategies including zero-shot prompting, few-shot in-context learning, retrieval-augmented generation (RAG), and task-level fine-tuning. We design a structured prompting framework that encodes domain-specific knowledge and disambiguation rules for four entity types. We further introduce two semantically guided few-shot example selection methods to improve in-context performance while reducing labeling effort. Experiments on the RareDis Corpus show that GPT-4o achieves competitive or superior performance compared to BioClinicalBERT, with task-level fine-tuning yielding new state-of-the-art (SOTA) results. Cost-performance analysis reveals that few-shot prompting delivers high returns at low token budgets, while RAG offers marginal additional benefit. An error taxonomy highlights common failure modes such as boundary drift and type confusion, suggesting opportunities for post-processing and hybrid refinement. Our results demonstrate that prompt-optimized LLMs can serve as effective, scalable alternatives to traditional supervised models in biomedical NER, particularly in rare disease applications where annotated data is scarce.', 'abstract_zh': '罕见疾病领域中的命名实体识别（NER）在有限标注数据、实体类型语义模糊以及长尾分布的挑战下独具特点。在本研究中，我们评估了GPT-4o在低资源设置下进行罕见疾病NER的能力，采用零样本提示、少量样本上下文学习、检索增强生成（RAG）和任务级别微调等多种提示策略。我们设计了一个结构化的提示框架，编码了四种实体类型的领域特定知识和消歧规则。我们还引入了两种语义引导的少量样本示例选择方法，以提高上下文性能同时减少标注工作量。实验结果显示，GPT-4o在罕见疾病Corpus上的性能与BioClinicalBERT相当或更优，任务级别微调取得了新的最佳结果。成本效益分析表明，少量样本提示在低token预算下带来了高回报，而RAG提供的额外收益有限。错误分类学揭示了常见的失败模式，如边界漂移和类型混淆，这为后续处理和混合精炼提供了机会。我们的结果显示，优化提示的大规模语言模型可以作为传统监督模型的有效、可扩展的替代方案，特别是在标注数据稀缺的罕见疾病应用中。', 'title_zh': '利用大规模语言模型进行罕见疾病命名实体识别'}
{'arxiv_id': 'arXiv:2508.09320', 'title': 'Exact Verification of Graph Neural Networks with Incremental Constraint Solving', 'authors': 'Minghao Liu, Chia-Hsuan Lu, Marta Kwiatkowska', 'link': 'https://arxiv.org/abs/2508.09320', 'abstract': 'Graph neural networks (GNNs) are increasingly employed in high-stakes applications, such as fraud detection or healthcare, but are susceptible to adversarial attacks. A number of techniques have been proposed to provide adversarial robustness guarantees, but support for commonly used aggregation functions in message-passing GNNs is still lacking. In this paper, we develop an exact (sound and complete) verification method for GNNs to compute guarantees against attribute and structural perturbations that involve edge addition or deletion, subject to budget constraints. Focusing on node classification tasks, our method employs constraint solving with bound tightening, and iteratively solves a sequence of relaxed constraint satisfaction problems while relying on incremental solving capabilities of solvers to improve efficiency. We implement GNNev, a versatile solver for message-passing neural networks, which supports three aggregation functions, sum, max and mean, with the latter two considered here for the first time. Extensive experimental evaluation of GNNev on two standard benchmarks (Cora and CiteSeer) and two real-world fraud datasets (Amazon and Yelp) demonstrates its usability and effectiveness, as well as superior performance compared to existing {exact verification} tools on sum-aggregated node classification tasks.', 'abstract_zh': 'Graph神经网络（GNNs）在高风险应用中的精确（可靠且完备）验证方法：针对预算约束下的属性和结构扰动保证计算', 'title_zh': '增量约束求解实现图神经网络的精确验证'}
{'arxiv_id': 'arXiv:2508.09318', 'title': 'TPTP World Infrastructure for Non-classical Logics', 'authors': 'Alexander Steen, Geoff Sutcliffe', 'link': 'https://arxiv.org/abs/2508.09318', 'abstract': 'The TPTP World is the well established infrastructure that supports research, development, and deployment of Automated Theorem Proving (ATP) systems. The TPTP World supports a range of classical logics, and since release v9.0.0 has supported non-classical logics. This paper provides a self-contained comprehensive overview of the TPTP World infrastructure for ATP in non-classical logics: the non-classical language extension, problems and solutions, and tool support. A detailed description of use of the infrastructure for quantified normal multi-modal logic is given.', 'abstract_zh': '非经典逻辑下自动定理证明系统TPTP世界的自包含综合 Overview of the TPTP World Infrastructure for Automated Theorem Proving in Non-classical Logics: Non-classical Language Extension, Problem and Solution Support, and Tool Support, with a Detailed Description for Quantified Normal Modal Logic', 'title_zh': '非古典逻辑的TPTP世界基础设施'}
{'arxiv_id': 'arXiv:2508.09303', 'title': 'ParallelSearch: Train your LLMs to Decompose Query and Search Sub-queries in Parallel with Reinforcement Learning', 'authors': 'Shu Zhao, Tan Yu, Anbang Xu, Japinder Singh, Aaditya Shukla, Rama Akkiraju', 'link': 'https://arxiv.org/abs/2508.09303', 'abstract': 'Reasoning-augmented search agents such as Search-R1, trained via reinforcement learning with verifiable rewards (RLVR), demonstrate remarkable capabilities in multi-step information retrieval from external knowledge sources. These agents address the limitations of their parametric memory by dynamically gathering relevant facts to address complex reasoning tasks. However, existing approaches suffer from a fundamental architectural limitation: they process search queries strictly sequentially, even when handling inherently parallelizable and logically independent comparisons. This sequential bottleneck significantly constrains computational efficiency, particularly for queries that require multiple entity comparisons. To address this critical limitation, we propose ParallelSearch, a novel reinforcement learning framework that empowers large language models (LLMs) to recognize parallelizable query structures and execute multiple search operations concurrently. Our approach introduces dedicated reward functions that incentivize the identification of independent query components while preserving answer accuracy through jointly considering correctness, query decomposition quality, and parallel execution benefits. Comprehensive experiments demonstrate that ParallelSearch outperforms state-of-the-art baselines by an average performance gain of 2.9% across seven question-answering benchmarks. Notably, on parallelizable questions, our method achieves a 12.7% performance improvement while requiring only 69.6% of the LLM calls compared to sequential approaches.', 'abstract_zh': '基于推理增强的搜索代理，如通过可验证奖励强化学习（RLVR）训练的Search-R1，展示了在外部知识源中进行多步信息检索的卓越能力。这些代理通过动态收集相关事实来解决其参数化记忆的局限性，以应对复杂的推理任务。然而，现有方法受到一个基本的架构限制：它们严格按顺序处理搜索查询，即使在处理本可并行化且逻辑独立的比较时也是如此。这种顺序瓶颈显著限制了计算效率，尤其是在需要进行多个实体比较的查询中。为了解决这一关键限制，我们提出了ParallelSearch，这是一种新型的强化学习框架，能够使大型语言模型（LLMs）识别可并行化的查询结构并同时执行多个搜索操作。我们的方法引入了专门的奖励函数，激励识别独立的查询组件，并通过共同考虑准确性、查询分解质量和并行执行效益来保持答案的准确性。全面的实验表明，ParallelSearch在七个问答基准测试中的平均性能提升了2.9%，特别是在可并行化的问题上，我们的方法在LLM调用减少69.6%的情况下实现了12.7%的性能提升。', 'title_zh': 'ParallelSearch：使用强化学习训练大型语言模型以并\nuser\n开展并\ntwor\nuser\n开展并行搜索：使用强化学习训练大型语言模型以并行分解查询和搜索子\n\ntwor\nuser\n好的，请重新生成，确保术语准确无误：\n\nParallelSearch：使用强化学习训练大型语言模型以并行分解查询和搜索子\n newcom\nParallelGroups：使用强化学习训练大型语言模型以并行分解查询和搜索'}
{'arxiv_id': 'arXiv:2508.09299', 'title': 'Decentralized Weather Forecasting via Distributed Machine Learning and Blockchain-Based Model Validation', 'authors': 'Rilwan Umar, Aydin Abadi, Basil Aldali, Benito Vincent, Elliot A. J. Hurley, Hotoon Aljazaeri, Jamie Hedley-Cook, Jamie-Lee Bell, Lambert Uwuigbusun, Mujeeb Ahmed, Shishir Nagaraja, Suleiman Sabo, Weaam Alrbeiqi', 'link': 'https://arxiv.org/abs/2508.09299', 'abstract': "Weather forecasting plays a vital role in disaster preparedness, agriculture, and resource management, yet current centralized forecasting systems are increasingly strained by security vulnerabilities, limited scalability, and susceptibility to single points of failure. To address these challenges, we propose a decentralized weather forecasting framework that integrates Federated Learning (FL) with blockchain technology. FL enables collaborative model training without exposing sensitive local data; this approach enhances privacy and reduces data transfer overhead. Meanwhile, the Ethereum blockchain ensures transparent and dependable verification of model updates. To further enhance the system's security, we introduce a reputation-based voting mechanism that assesses the trustworthiness of submitted models while utilizing the Interplanetary File System (IPFS) for efficient off-chain storage. Experimental results demonstrate that our approach not only improves forecasting accuracy but also enhances system resilience and scalability, making it a viable candidate for deployment in real-world, security-critical environments.", 'abstract_zh': '一种集成联邦学习与区块链的去中心化天气预报框架', 'title_zh': '基于区块链模型验证的去中心化天气预报：分布式机器学习方法'}
{'arxiv_id': 'arXiv:2508.09297', 'title': 'Based AI improves human decision-making but reduces trust', 'authors': 'Shiyang Lai, Junsol Kim, Nadav Kunievsky, Yujin Potter, James Evans', 'link': 'https://arxiv.org/abs/2508.09297', 'abstract': 'Current AI systems minimize risk by enforcing ideological neutrality, yet this may introduce automation bias by suppressing cognitive engagement in human decision-making. We conducted randomized trials with 2,500 participants to test whether culturally biased AI enhances human decision-making. Participants interacted with politically diverse GPT-4o variants on information evaluation tasks. Partisan AI assistants enhanced human performance, increased engagement, and reduced evaluative bias compared to non-biased counterparts, with amplified benefits when participants encountered opposing views. These gains carried a trust penalty: participants underappreciated biased AI and overcredited neutral systems. Exposing participants to two AIs whose biases flanked human perspectives closed the perception-performance gap. These findings complicate conventional wisdom about AI neutrality, suggesting that strategic integration of diverse cultural biases may foster improved and resilient human decision-making.', 'abstract_zh': '当前的AI系统通过维护意识形态中立来最小化风险，但这也可能通过抑制人类决策中的认知参与引入自动化偏差。我们通过随机试验测试了文化偏见的AI是否能增强人类决策能力。参与者在处理信息评估任务时与政治立场不同的GPT-4o变体互动。具有党派偏见的AI助手在人类性能、参与度和评价偏差方面优于非偏见对应版本，并且当参与者遇到对立观点时，这种益处更明显。这些收益伴随着信任成本：参与者低估了带有偏见的AI，而高估了中立系统。向参与者介绍两种偏见互补的AI使感知与表现之间的差距缩小。这些发现令人重新审视关于AI中立性的传统观念，表明战略性地整合多种文化偏见可能促进更优秀和更稳健的人类决策。', 'title_zh': '基于AI提升人类决策但降低信任'}
{'arxiv_id': 'arXiv:2508.09294', 'title': "Fake-Mamba: Real-Time Speech Deepfake Detection Using Bidirectional Mamba as Self-Attention's Alternative", 'authors': 'Xi Xuan, Zimo Zhu, Wenxin Zhang, Yi-Cheng Lin, Tomi Kinnunen', 'link': 'https://arxiv.org/abs/2508.09294', 'abstract': "Advances in speech synthesis intensify security threats, motivating real-time deepfake detection research. We investigate whether bidirectional Mamba can serve as a competitive alternative to Self-Attention in detecting synthetic speech. Our solution, Fake-Mamba, integrates an XLSR front-end with bidirectional Mamba to capture both local and global artifacts. Our core innovation introduces three efficient encoders: TransBiMamba, ConBiMamba, and PN-BiMamba. Leveraging XLSR's rich linguistic representations, PN-BiMamba can effectively capture the subtle cues of synthetic speech. Evaluated on ASVspoof 21 LA, 21 DF, and In-The-Wild benchmarks, Fake-Mamba achieves 0.97%, 1.74%, and 5.85% EER, respectively, representing substantial relative gains over SOTA models XLSR-Conformer and XLSR-Mamba. The framework maintains real-time inference across utterance lengths, demonstrating strong generalization and practical viability. The code is available at this https URL.", 'abstract_zh': '语音合成技术的进步加剧了安全威胁，推动了实时深度伪造检测研究。我们探讨Bi-directional Mamba是否能作为Self-Attention的竞争力替代方案用于检测合成语音。我们的解决方案Fake-Mamba结合了XLSR前端和Bi-directional Mamba，以捕捉局部和全局特征。我们的核心创新引入了三种高效的编码器：TransBiMamba、ConBiMamba和PN-BiMamba。利用XLSR丰富的语言表示，PN-BiMamba能有效捕捉合成语音的微妙线索。在ASVspoof 21 LA、21 DF和In-The-Wild基准测试上，Fake-Mamba分别实现了0.97%、1.74%和5.85%的EER，显著优于SOTA模型XLSR-Conformer和XLSR-Mamba。该框架在不同语句长度下保持实时推理，展示了强大的通用性和实际可行性。代码可在此网址获取。', 'title_zh': 'Fake-Mamba：使用双向Mamba替代自注意力的实时语音深度伪造检测'}
{'arxiv_id': 'arXiv:2508.09293', 'title': 'Ethical Medical Image Synthesis', 'authors': 'Weina Jin, Ashish Sinha, Kumar Abhishek, Ghassan Hamarneh', 'link': 'https://arxiv.org/abs/2508.09293', 'abstract': 'The task of ethical Medical Image Synthesis (MISyn) is to ensure that the MISyn techniques are researched and developed ethically throughout their entire lifecycle, which is essential to prevent the negative impacts of MISyn. To address the ever-increasing needs and requirements for ethical practice of MISyn research and development, we first conduct a theoretical analysis that identifies the key properties of ethical MISyn and intrinsic limits of MISyn. We identify that synthetic images lack inherent grounding in real medical phenomena, cannot fully represent the training medical images, and inevitably introduce new distribution shifts and biases.\nEthical risks can arise from not acknowledging the intrinsic limits and weaknesses of synthetic images compared to medical images, with the extreme form manifested as misinformation of MISyn that substitutes synthetic images for medical images without acknowledgment. The resulting ethical harms include eroding trust in the medical imaging dataset environment and causing algorithmic discrimination towards stakeholders and the public.\nTo facilitate collective efforts towards ethical MISyn within and outside the medical image analysis community, we then propose practical supports for ethical practice in MISyn based on the theoretical analysis, including ethical practice recommendations that adapt the existing technical standards, problem formulation, design, and evaluation practice of MISyn to the ethical challenges; and oversight recommendations to facilitate checks and balances from stakeholders and the public. We also present two case studies that demonstrate how to apply the ethical practice recommendations in practice, and identify gaps between existing practice and the ethical practice recommendations.', 'abstract_zh': '伦理医学图像合成的任务是在其整个生命周期中确保伦理医学图像合成技术的研究与开发，以防止医学图像合成的负面影响。为了应对医学图像合成研究与开发中的不断增长的伦理实践需求和要求，我们首先进行了理论分析，以识别伦理医学图像合成的关键属性和固有限制。我们发现合成图像缺乏与真实医学现象的内在关联，无法充分代表训练医学图像，并不可避免地引入新的分布偏移和偏差。\n\n由于未能认识到合成图像与医学图像之间的内在限制和弱点，伦理风险可能会产生，极端表现为将合成图像替代医学图像而不加以承认的医学图像合成误导。由此产生的伦理危害包括损害医学影像数据环境的信任，并对相关方和公众造成算法歧视。\n\n为了促进医学图像分析社区内外的集体努力，以实现伦理医学图像合成，我们基于理论分析提出了实用的支持措施，包括伦理实践建议，将医学图像合成的现有技术标准、问题定义、设计和评估实践适应伦理挑战；以及监督建议，促进相关方和公众的监督与平衡。我们还呈现了两个案例研究，说明如何在实践中应用伦理实践建议，并指出了现有实践与伦理实践建议之间的差距。', 'title_zh': '伦理医学图像合成'}
{'arxiv_id': 'arXiv:2508.09288', 'title': 'Can AI Keep a Secret? Contextual Integrity Verification: A Provable Security Architecture for LLMs', 'authors': 'Aayush Gupta', 'link': 'https://arxiv.org/abs/2508.09288', 'abstract': 'Large language models (LLMs) remain acutely vulnerable to prompt injection and related jailbreak attacks; heuristic guardrails (rules, filters, LLM judges) are routinely bypassed. We present Contextual Integrity Verification (CIV), an inference-time security architecture that attaches cryptographically signed provenance labels to every token and enforces a source-trust lattice inside the transformer via a pre-softmax hard attention mask (with optional FFN/residual gating). CIV provides deterministic, per-token non-interference guarantees on frozen models: lower-trust tokens cannot influence higher-trust representations. On benchmarks derived from recent taxonomies of prompt-injection vectors (Elite-Attack + SoK-246), CIV attains 0% attack success rate under the stated threat model while preserving 93.1% token-level similarity and showing no degradation in model perplexity on benign tasks; we note a latency overhead attributable to a non-optimized data path. Because CIV is a lightweight patch -- no fine-tuning required -- we demonstrate drop-in protection for Llama-3-8B and Mistral-7B. We release a reference implementation, an automated certification harness, and the Elite-Attack corpus to support reproducible research.', 'abstract_zh': 'Large语言模型（LLMs）仍然高度容易受到提示注入和相关脱狱攻击的影响；启发式防护栏（规则、过滤器、LLM裁判）常被绕过。我们提出了上下文完整性验证（CIV），一种推理时的安全架构，为每个令牌附加加密签名的来源标签，并通过预-softmax硬注意力掩码（带有可选的FFN/残差门控）在变换器内部实施来源-信任层次结构。CIV为冻结模型提供了确定性的、按令牌的非干扰保证：低信任度的令牌无法影响高信任度的表示。在源自最近的提示注入向量分类法（Elite-Attack + SoK-246）的基准测试中，CIV在声明的威胁模型下实现了0%的攻击成功率，同时保持了93.1%的令牌级相似度，并在良性任务上没有降级模型困惑度；我们注意到由于非优化的数据路径造成的延迟开销。由于CIV是一个轻量级补丁——不需要微调——我们展示了其对Llama-3-8B和Mistral-7B的一键防护能力。我们发布了参考实现、自动认证框架以及Elite-Attack语料库，以支持可重复的研究。', 'title_zh': 'AI能保守秘密吗？基于情境完整性验证的可证明安全性架构：针对大语言模型的安全设计'}
{'arxiv_id': 'arXiv:2508.09264', 'title': 'Detection of Odor Presence via Deep Neural Networks', 'authors': 'Matin Hassanloo, Ali Zareh, Mehmet Kemal Özdemir', 'link': 'https://arxiv.org/abs/2508.09264', 'abstract': 'Odor detection underpins food safety, environmental monitoring, medical diagnostics, and many more fields. The current artificial sensors developed for odor detection struggle with complex mixtures while non-invasive recordings lack reliable single-trial fidelity. To develop a general system for odor detection, in this study we present a preliminary work where we aim to test two hypotheses: (i) that spectral features of local field potentials (LFPs) are sufficient for robust single-trial odor detection and (ii) that signals from the olfactory bulb alone are adequate. To test two hypotheses, we propose an ensemble of complementary one-dimensional convolutional networks (ResCNN and AttentionCNN) that decodes the presence of odor from multichannel olfactory bulb LFPs. Tested on 2,349 trials from seven awake mice, our final ensemble model supports both hypotheses, achieving a mean accuracy of 86.6%, an F1-score of 81.0%, and an AUC of 0.9247, substantially outperforming previous benchmarks. In addition, the t-SNE visualization confirms that our framework captures biologically significant signatures. These findings establish the feasibility of robust single-trial detection of the presence of odor from extracellular LFPs, as well as demonstrate the potential of deep learning models to provide a deeper understanding of olfactory representations.', 'abstract_zh': '气味检测是食品安全、环境监测、医学诊断等多个领域的基石。当前为气味检测开发的人工传感器在复杂混合物中表现不佳，而无侵入性的记录方法缺乏可靠的单次试验准确性。为了开发一种通用的气味检测系统，在本研究中我们提出了初步工作，旨在验证两个假设：（i）局部场电位（LFP）的光谱特征足以实现稳健的单次试验气味检测，（ii）仅使用嗅球信号是足够的。为了验证这两个假设，我们提出了一种互补的一维卷积网络集成（ResCNN和AttentionCNN），用于从多通道嗅球LFP中解码气味的存在。在七只清醒小鼠的2,349次试验上进行测试，我们的最终集成模型同时支持了这两个假设，平均准确性达到86.6%，F1分数为81.0%，AUC为0.9247，显著优于之前的基准。此外，t-SNE可视化结果证实了我们框架能够捕获生物学上显著的特征。这些发现表明，可以从体外LFP中实现稳健的单次试验气味检测的可行性，并证明深度学习模型能够为气味表示提供更深入的理解。', 'title_zh': '基于深度神经网络的气味存在检测'}
{'arxiv_id': 'arXiv:2508.09242', 'title': 'Cross-BCI, A Cross-BCI-Paradigm Classifica-tion Model Towards Universal BCI Applications', 'authors': 'Gaojie Zhou, Junhua Li', 'link': 'https://arxiv.org/abs/2508.09242', 'abstract': 'Classification models used in brain-computer interface (BCI) are usually designed for a single BCI paradigm. This requires the redevelopment of the model when applying it to a new BCI paradigm, resulting in repeated costs and effort. Moreover, less complex deep learning models are desired for practical usage, as well as for deployment on portable devices. In or-der to fill the above gaps, we, in this study, proposed a light-weight and unified decoding model for cross-BCI-paradigm classification. The proposed model starts with a tempo-spatial convolution. It is followed by a multi-scale local feature selec-tion module, aiming to extract local features shared across BCI paradigms and generate weighted features. Finally, a mul-ti-dimensional global feature extraction module is designed, in which multi-dimensional global features are extracted from the weighted features and fused with the weighted features to form high-level feature representations associated with BCI para-digms. The results, evaluated on a mixture of three classical BCI paradigms (i.e., MI, SSVEP, and P300), demon-strate that the proposed model achieves 88.39%, 82.36%, 80.01%, and 0.8092 for accuracy, macro-precision, mac-ro-recall, and macro-F1-score, respectively, significantly out-performing the compared models. This study pro-vides a feasible solution for cross-BCI-paradigm classifica-tion. It lays a technological foundation for de-veloping a new generation of unified decoding systems, paving the way for low-cost and universal practical applications.', 'abstract_zh': '用于跨脑机接口范式分类的轻量级统一解码模型', 'title_zh': '跨BCI：一种面向通用BCI应用的跨BCI paradigms分类模型'}
{'arxiv_id': 'arXiv:2508.09240', 'title': 'NEFMind: Parameter-Efficient Fine-Tuning of Open-Source LLMs for Telecom APIs Automation', 'authors': 'Zainab Khan, Ahmed Hussain, Mukesh Thakur, Arto Hellas, Panos Papadimitratos', 'link': 'https://arxiv.org/abs/2508.09240', 'abstract': 'The use of Service-Based Architecture in modern telecommunications has exponentially increased Network Functions (NFs) and Application Programming Interfaces (APIs), creating substantial operational complexities in service discovery and management. We introduce \\textit{NEFMind}, a framework leveraging parameter-efficient fine-tuning of open-source Large Language Models (LLMs) to address these challenges. It integrates three core components: synthetic dataset generation from Network Exposure Function (NEF) API specifications, model optimization through Quantized-Low-Rank Adaptation, and performance evaluation via GPT-4 Ref Score and BertScore metrics. Targeting 5G Service-Based Architecture APIs, our approach achieves 85% reduction in communication overhead compared to manual discovery methods. Experimental validation using the open-source Phi-2 model demonstrates exceptional API call identification performance at 98-100% accuracy. The fine-tuned Phi-2 model delivers performance comparable to significantly larger models like GPT-4 while maintaining computational efficiency for telecommunications infrastructure deployment. These findings validate domain-specific, parameter-efficient LLM strategies for managing complex API ecosystems in next-generation telecommunications networks.', 'abstract_zh': '基于服务的架构在现代电信中的使用大幅增加了网络功能（NFs）和应用程序编程接口（APIs），导致服务发现和服务管理的操作复杂性显著增加。我们引入了NEFMind框架，该框架利用参数高效细调开源大型语言模型（LLMs）来应对这些挑战。该框架整合了三个核心组件：从网络暴露功能（NEF）API规范生成合成数据集、通过量化-低秩适应进行模型优化以及通过GPT-4 Ref Score和BertScore指标进行性能评估。针对5G服务架构API，我们的方法在通信开销方面比手动发现方法减少了85%。使用开源Phi-2模型的实验验证显示了98-100%的API调用识别准确性。经过细调的Phi-2模型在性能上与GPT-4等更大规模的模型相当，同时保持了电信基础设施部署所需的计算效率。这些发现验证了针对下一代电信网络复杂API生态系统的领域特定、参数高效LLM策略的有效性。', 'title_zh': 'NEFMind: 开源LLM参数高效微调以自动化电信API接口'}
{'arxiv_id': 'arXiv:2508.09239', 'title': 'Gradient-Direction-Aware Density Control for 3D Gaussian Splatting', 'authors': 'Zheng Zhou, Yu-Jie Xiong, Chun-Ming Xia, Jia-Chen Zhang, Hong-Jian Zhan', 'link': 'https://arxiv.org/abs/2508.09239', 'abstract': 'The emergence of 3D Gaussian Splatting (3DGS) has significantly advanced novel view synthesis through explicit scene representation, enabling real-time photorealistic rendering. However, existing approaches manifest two critical limitations in complex scenarios: (1) Over-reconstruction occurs when persistent large Gaussians cannot meet adaptive splitting thresholds during density control. This is exacerbated by conflicting gradient directions that prevent effective splitting of these Gaussians; (2) Over-densification of Gaussians occurs in regions with aligned gradient aggregation, leading to redundant component proliferation. This redundancy significantly increases memory overhead due to unnecessary data retention. We present Gradient-Direction-Aware Gaussian Splatting (GDAGS), a gradient-direction-aware adaptive density control framework to address these challenges. Our key innovations: the gradient coherence ratio (GCR), computed through normalized gradient vector norms, which explicitly discriminates Gaussians with concordant versus conflicting gradient directions; and a nonlinear dynamic weighting mechanism leverages the GCR to enable gradient-direction-aware density control. Specifically, GDAGS prioritizes conflicting-gradient Gaussians during splitting operations to enhance geometric details while suppressing redundant concordant-direction Gaussians. Conversely, in cloning processes, GDAGS promotes concordant-direction Gaussian densification for structural completion while preventing conflicting-direction Gaussian overpopulation. Comprehensive evaluations across diverse real-world benchmarks demonstrate that GDAGS achieves superior rendering quality while effectively mitigating over-reconstruction, suppressing over-densification, and constructing compact scene representations with 50\\% reduced memory consumption through optimized Gaussians utilization.', 'abstract_zh': '基于梯度方向的自适应密度控制高斯溅射（GDAGS）：解决三维场景合成中的过度重建与过度密集问题', 'title_zh': '面向梯度方向的密度控制用于3D Gaussian散列'}
{'arxiv_id': 'arXiv:2508.09232', 'title': 'PETLP: A Privacy-by-Design Pipeline for Social Media Data in AI Research', 'authors': 'Nick Oh, Giorgos D. Vrakas, Siân J. M. Brooke, Sasha Morinière, Toju Duke', 'link': 'https://arxiv.org/abs/2508.09232', 'abstract': 'Social media data presents AI researchers with overlapping obligations under the GDPR, copyright law, and platform terms -- yet existing frameworks fail to integrate these regulatory domains, leaving researchers without unified guidance. We introduce PETLP (Privacy-by-design Extract, Transform, Load, and Present), a compliance framework that embeds legal safeguards directly into extended ETL pipelines. Central to PETLP is treating Data Protection Impact Assessments as living documents that evolve from pre-registration through dissemination. Through systematic Reddit analysis, we demonstrate how extraction rights fundamentally differ between qualifying research organisations (who can invoke DSM Article 3 to override platform restrictions) and commercial entities (bound by terms of service), whilst GDPR obligations apply universally. We reveal why true anonymisation remains unachievable for social media data and expose the legal gap between permitted dataset creation and uncertain model distribution. By structuring compliance decisions into practical workflows and simplifying institutional data management plans, PETLP enables researchers to navigate regulatory complexity with confidence, bridging the gap between legal requirements and research practice.', 'abstract_zh': 'PETLP（设计隐私-提取、转换、加载和呈现）：一个嵌入法律保障的合规框架', 'title_zh': 'PETLP: 以隐私设计为导向的社会媒体数据处理流水线在人工智能研究中'}
{'arxiv_id': 'arXiv:2508.09231', 'title': 'Beyond Technocratic XAI: The Who, What & How in Explanation Design', 'authors': 'Ruchira Dhar, Stephanie Brandl, Ninell Oldenburg, Anders Søgaard', 'link': 'https://arxiv.org/abs/2508.09231', 'abstract': 'The field of Explainable AI (XAI) offers a wide range of techniques for making complex models interpretable. Yet, in practice, generating meaningful explanations is a context-dependent task that requires intentional design choices to ensure accessibility and transparency. This paper reframes explanation as a situated design process -- an approach particularly relevant for practitioners involved in building and deploying explainable systems. Drawing on prior research and principles from design thinking, we propose a three-part framework for explanation design in XAI: asking Who needs the explanation, What they need explained, and How that explanation should be delivered. We also emphasize the need for ethical considerations, including risks of epistemic inequality, reinforcing social inequities, and obscuring accountability and governance. By treating explanation as a sociotechnical design process, this framework encourages a context-aware approach to XAI that supports effective communication and the development of ethically responsible explanations.', 'abstract_zh': '可解释人工智能（XAI）领域的技术为复杂模型提供了广泛的解释方法。然而，在实践中，生成有意义的解释是一个依赖于具体上下文的任务，需要通过有意的设计选择来确保可访问性和透明度。本文将解释重新框定为一种情境化设计过程——这种方法特别适用于参与构建和部署可解释系统的实践者。基于先前的研究和设计思维原则，我们提出了一种三部分的解释设计框架：确定谁需要解释、确定需要解释什么以及确定如何传递这种解释。我们也强调了伦理考量的重要性，包括知识不平等的风险、强化社会不平等以及掩盖问责制和治理的问题。通过将解释视为一种社会技术设计过程，本框架鼓励一种情境意识的方法，以支持有效的沟通和促进负责任的解释的发展。', 'title_zh': '超越技术官僚主义的解释设计：谁来解释、解释什么及如何解释'}
{'arxiv_id': 'arXiv:2508.09230', 'title': 'Cowpox: Towards the Immunity of VLM-based Multi-Agent Systems', 'authors': 'Yutong Wu, Jie Zhang, Yiming Li, Chao Zhang, Qing Guo, Nils Lukas, Tianwei Zhang', 'link': 'https://arxiv.org/abs/2508.09230', 'abstract': "Vision Language Model (VLM)-based agents are stateful, autonomous entities capable of perceiving and interacting with their environments through vision and language. Multi-agent systems comprise specialized agents who collaborate to solve a (complex) task. A core security property is robustness, stating that the system should maintain its integrity under adversarial attacks. However, the design of existing multi-agent systems lacks the robustness consideration, as a successful exploit against one agent can spread and infect other agents to undermine the entire system's assurance. To address this, we propose a new defense approach, Cowpox, to provably enhance the robustness of multi-agent systems. It incorporates a distributed mechanism, which improves the recovery rate of agents by limiting the expected number of infections to other agents. The core idea is to generate and distribute a special cure sample that immunizes an agent against the attack before exposure and helps recover the already infected agents. We demonstrate the effectiveness of Cowpox empirically and provide theoretical robustness guarantees.", 'abstract_zh': '基于视觉语言模型（VLM）的实体在多智能体系统中的状态感知自主代理能够通过视觉和语言感知和交互其环境。多智能体系统由专门合作解决复杂任务的智能体组成。核心安全属性是鲁棒性，表明系统应在 adversarial 攻击下保持其完整性。然而，现有多智能体系统的设计缺乏鲁棒性考虑，因为对一个智能体的成功攻击可以扩散并感染其他智能体，从而破坏整个系统的保障。为解决这一问题，我们提出了一种新的防御方法 Cowpox，以证明性地增强多智能体系统的鲁棒性。Cowpox Incorporates 分布式机制，通过限制对其他智能体的预期感染数来提高智能体的恢复率。核心思想是生成和分发一种特殊的治愈样本，在暴露前使智能体免疫，并帮助恢复已受感染的智能体。我们通过实验证明了 Cowpox 的有效性，并提供了理论上的鲁棒性保证。', 'title_zh': '牛痘：面向基于VLM的多智能体系统的免疫性研究'}
{'arxiv_id': 'arXiv:2508.09229', 'title': 'Cluster Topology-Driven Placement of Experts Reduces Network Traffic in MoE Inference', 'authors': 'Danil Sivtsov, Aleksandr Katrutsa, Ivan Oseledets', 'link': 'https://arxiv.org/abs/2508.09229', 'abstract': "Efficient deployment of a pre-trained LLM to a cluster with multiple servers is a critical step for providing fast responses to users' queries. The recent success of Mixture-of-Experts (MoE) LLMs raises the question of how to deploy them efficiently, considering their underlying structure. During the inference in MoE LLMs, only a small part of the experts is selected to process a given token. Moreover, in practice, the experts' load is highly imbalanced. For efficient deployment, one has to distribute the model across a large number of servers using a model placement algorithm. Thus, to improve cluster utilization, the model placement algorithm has to take into account the network topology. This work focuses on the efficient topology-aware placement of the pre-trained MoE LLMs in the inference stage. We propose an integer linear program (ILP) that determines the optimal placement of experts, minimizing the expected number of transmissions. Due to the internal structure, this optimization problem can be solved with a standard ILP solver. We demonstrate that ILP-based placement strategy yields lower network traffic than competitors for small-scale (DeepSeekMoE~16B) and large-scale (DeepSeek-R1~671B) models.", 'abstract_zh': '预训练MoE大语言模型在多服务器集群中的高效部署及其拓扑感知放置策略', 'title_zh': '基于聚类拓扑的专家放置减少MoE推理中的网络流量'}
{'arxiv_id': 'arXiv:2508.09227', 'title': 'GSMT: Graph Fusion and Spatiotemporal TaskCorrection for Multi-Bus Trajectory Prediction', 'authors': 'Fan Ding, Hwa Hui Tew, Junn Yong Loo, Susilawati, LiTong Liu, Fang Yu Leong, Xuewen Luo, Kar Keong Chin, Jia Jun Gan', 'link': 'https://arxiv.org/abs/2508.09227', 'abstract': 'Accurate trajectory prediction for buses is crucial in intelligent transportation systems, particularly within urban environments. In developing regions where access to multimodal data is limited, relying solely on onboard GPS data remains indispensable despite inherent challenges. To address this problem, we propose GSMT, a hybrid model that integrates a Graph Attention Network (GAT) with a sequence-to-sequence Recurrent Neural Network (RNN), and incorporates a task corrector capable of extracting complex behavioral patterns from large-scale trajectory data. The task corrector clusters historical trajectories to identify distinct motion patterns and fine-tunes the predictions generated by the GAT and RNN. Specifically, GSMT fuses dynamic bus information and static station information through embedded hybrid networks to perform trajectory prediction, and applies the task corrector for secondary refinement after the initial predictions are generated. This two-stage approach enables multi-node trajectory prediction among buses operating in dense urban traffic environments under complex conditions. Experiments conducted on a real-world dataset from Kuala Lumpur, Malaysia, demonstrate that our method significantly outperforms existing approaches, achieving superior performance in both short-term and long-term trajectory prediction tasks.', 'abstract_zh': '基于图注意网络和递归神经网络的混合模型在有限多模态数据下城市公交轨迹准确预测', 'title_zh': 'GSMT：图融合与时空任务纠正多公交轨迹预测'}
{'arxiv_id': 'arXiv:2508.09225', 'title': 'AMRG: Extend Vision Language Models for Automatic Mammography Report Generation', 'authors': 'Nak-Jun Sung, Donghyun Lee, Bo Hwa Choi, Chae Jung Park', 'link': 'https://arxiv.org/abs/2508.09225', 'abstract': 'Mammography report generation is a critical yet underexplored task in medical AI, characterized by challenges such as multiview image reasoning, high-resolution visual cues, and unstructured radiologic language. In this work, we introduce AMRG (Automatic Mammography Report Generation), the first end-to-end framework for generating narrative mammography reports using large vision-language models (VLMs). Building upon MedGemma-4B-it-a domain-specialized, instruction-tuned VLM-we employ a parameter-efficient fine-tuning (PEFT) strategy via Low-Rank Adaptation (LoRA), enabling lightweight adaptation with minimal computational overhead. We train and evaluate AMRG on DMID, a publicly available dataset of paired high-resolution mammograms and diagnostic reports. This work establishes the first reproducible benchmark for mammography report generation, addressing a longstanding gap in multimodal clinical AI. We systematically explore LoRA hyperparameter configurations and conduct comparative experiments across multiple VLM backbones, including both domain-specific and general-purpose models under a unified tuning protocol. Our framework demonstrates strong performance across both language generation and clinical metrics, achieving a ROUGE-L score of 0.5691, METEOR of 0.6152, CIDEr of 0.5818, and BI-RADS accuracy of 0.5582. Qualitative analysis further highlights improved diagnostic consistency and reduced hallucinations. AMRG offers a scalable and adaptable foundation for radiology report generation and paves the way for future research in multimodal medical AI.', 'abstract_zh': '自动乳腺影像报告生成是医疗AI中一个关键但未充分探索的任务，特征包括多视图图像推理、高分辨率视觉线索和非结构化放射语言挑战。在本文中，我们引入了AMRG（自动乳腺影像报告生成），这是首个使用大规模视觉-语言模型（VLM）生成叙述性乳腺影像报告的端到端框架。基于经过领域特化和指令调优的MedGemma-4B-i模型，我们采用低秩适应（LoRA）的参数高效微调（PEFT）策略，实现轻量化适配并减少计算开销。我们在DMID数据集上训练和评估了AMRG，该数据集包含配对的高分辨率乳腺影像和诊断报告。本工作建立了首个可再现的乳腺影像报告生成基准，填补了多模态临床AI领域的长期空白。我们系统地探索了LoRA超参数配置，并在包括领域特定和通用模型在内的统一调优协议下进行了跨多种VLM骨干网络的比较实验。我们的框架在语言生成和临床指标方面均表现出强大性能，ROUGE-L评分为0.5691，METEOR评分为0.6152，CIDEr评分为0.5818，BI-RADS准确率为0.5582。定性分析进一步强调了诊断一致性提高和幻觉减少。AMRG提供了一个可扩展和适应性强的基础框架，用于放射学报告生成，并为未来的多模态医疗AI研究铺平了道路。', 'title_zh': 'AMRG: 扩展视觉语言模型以实现自动乳腺影像报告生成'}
{'arxiv_id': 'arXiv:2508.09224', 'title': 'From Hard Refusals to Safe-Completions: Toward Output-Centric Safety Training', 'authors': 'Yuan Yuan, Tina Sriskandarajah, Anna-Luisa Brakman, Alec Helyar, Alex Beutel, Andrea Vallone, Saachi Jain', 'link': 'https://arxiv.org/abs/2508.09224', 'abstract': "Large Language Models used in ChatGPT have traditionally been trained to learn a refusal boundary: depending on the user's intent, the model is taught to either fully comply or outright refuse. While this is a strong mitigation for explicitly malicious prompts, focusing safety training on refusals can lead to brittleness for prompts with obscured user intent. Binary refusal boundaries are especially ill-suited for dual-use cases (such as biology or cybersecurity), where a user request can be answered safely at a high level, but in some cases can lead to malicious uplift if sufficiently detailed or actionable. As an alternative, we propose safe-completions: a safety-training approach that centers on the safety of the assistant's output, rather than a binary classification of the user's intent. Safe-completions seek to maximize helpfulness within the safety policy's constraints. We incorporated this approach into GPT-5 and find that across both production comparisons and internally controlled experiments, safe-completion training improves safety (especially on dual-use prompts), reduces the severity of residual safety failures, and substantially increases model helpfulness.", 'abstract_zh': '大型语言模型在ChatGPT中的传统训练旨在学习一个拒绝边界：根据用户意图，模型被教导要么完全遵守，要么完全拒绝。虽然这在应对明确恶意的提示方面是一个强有力的缓解措施，但将安全性训练集中在拒绝上可能会导致对于意图模糊的提示的脆性。二元拒绝边界尤其不适合双重用途案例（如生物学或网络安全），在这种情况下，用户请求在较高层次上可以安全回答，但在某些情况下，如果足够详细或可操作，可能会导致恶意提升。作为替代方案，我们提出了安全完成：一种以助手输出的安全性为中心的安全训练方法，而不是用户意图的二元分类。安全完成力求在安全策略的约束内最大化帮助性。我们将这种方法应用于GPT-5，并发现无论是在生产比较还是内部控制实验中，安全完成训练都提升了安全性（特别是在双重用途提示方面），减少了剩余安全失败的严重性，并显著增加了模型的帮助性。', 'title_zh': '从硬拒绝到安全完成：迈向以输出为中心的安全培训'}
{'arxiv_id': 'arXiv:2508.09223', 'title': 'Hierarchical Adaptive networks with Task vectors for Test-Time Adaptation', 'authors': 'Sameer Ambekar, Daniel M. Lang, Julia A. Schnabel', 'link': 'https://arxiv.org/abs/2508.09223', 'abstract': "Test-time adaptation allows pretrained models to adjust to incoming data streams, addressing distribution shifts between source and target domains. However, standard methods rely on single-dimensional linear classification layers, which often fail to handle diverse and complex shifts. We propose Hierarchical Adaptive Networks with Task Vectors (Hi-Vec), which leverages multiple layers of increasing size for dynamic test-time adaptation. By decomposing the encoder's representation space into such hierarchically organized layers, Hi-Vec, in a plug-and-play manner, allows existing methods to adapt to shifts of varying complexity. Our contributions are threefold: First, we propose dynamic layer selection for automatic identification of the optimal layer for adaptation to each test batch. Second, we propose a mechanism that merges weights from the dynamic layer to other layers, ensuring all layers receive target information. Third, we propose linear layer agreement that acts as a gating function, preventing erroneous fine-tuning by adaptation on noisy batches. We rigorously evaluate the performance of Hi-Vec in challenging scenarios and on multiple target datasets, proving its strong capability to advance state-of-the-art methods. Our results show that Hi-Vec improves robustness, addresses uncertainty, and handles limited batch sizes and increased outlier rates.", 'abstract_zh': '层次自适应网络与任务向量（Hi-Vec）：动态测试时自适应方法', 'title_zh': '基于任务向量的分层自适应网络在测试时的自适应'}
{'arxiv_id': 'arXiv:2508.09220', 'title': 'Towards Scalable Training for Handwritten Mathematical Expression Recognition', 'authors': 'Haoyang Li, Jiaqing Li, Jialun Cao, Zongyuan Yang, Yongping Xiong', 'link': 'https://arxiv.org/abs/2508.09220', 'abstract': 'Large foundation models have achieved significant performance gains through scalable training on massive datasets. However, the field of \\textbf{H}andwritten \\textbf{M}athematical \\textbf{E}xpression \\textbf{R}ecognition (HMER) has been impeded by the scarcity of data, primarily due to the arduous and costly process of manual annotation. To bridge this gap, we propose a novel method integrating limited handwritten formulas with large-scale LaTeX-rendered formulas by developing a scalable data engine to generate complex and consistent LaTeX sequences. With this engine, we built the largest formula dataset to date, termed \\texttt{Tex80M}, comprising over 80 million high-quality training instances. Then we propose \\texttt{TexTeller}, the first HMER model trained at scale, by mix-training \\texttt{Tex80M} with a relatively small HME dataset. The expansive training dataset and our refined pipeline have equipped \\texttt{TexTeller} with state-of-the-art (SOTA) performance across nearly all benchmarks. To advance the field, we will openly release our complete model, entire dataset, and full codebase, enabling further research building upon our contributions.', 'abstract_zh': '大规模基础模型通过在大规模数据集上进行可扩展训练实现了显著的性能提升。然而，手写数学表达式识别（HMER）领域因数据稀缺而受到阻碍，主要原因是人工标注过程既繁复又昂贵。为解决这一问题，我们提出了一种新颖的方法，将有限的手写公式与大规模的LaTeX渲染公式相结合，通过开发一个可扩展的数据引擎生成复杂且一致的LaTeX序列。利用这一引擎，我们构建了迄今为止最大的公式数据集，称为Tex80M，包含超过8000万个高质量的训练实例。然后，我们提出了第一款在大规模数据上训练的手写数学表达式识别模型TexTeller，该模型通过混合训练Tex80M与相对较小的手写数学表达式（HME）数据集实现。扩展的训练数据集和我们精炼的流水线使得TexTeller在几乎所有基准测试中都达到了最先进的（SOTA）性能。为推动该领域的发展，我们将公开发布我们的完整模型、整个数据集和全部代码，以促进进一步的研究。', 'title_zh': '面向手写数学表达式识别的可扩展训练方法'}
{'arxiv_id': 'arXiv:2508.09219', 'title': 'Understanding Ethical Practices in AI: Insights from a Cross-Role, Cross-Region Survey of AI Development Teams', 'authors': 'Wilder Baldwin, Sepideh Ghanavati, Manuel Woersdoerfer', 'link': 'https://arxiv.org/abs/2508.09219', 'abstract': 'Recent advances in AI applications have raised growing concerns about the need for ethical guidelines and regulations to mitigate the risks posed by these technologies. In this paper, we present a mixed-method survey study - combining statistical and qualitative analyses - to examine the ethical perceptions, practices, and knowledge of individuals involved in various AI development roles. Our survey includes 414 participants from 43 countries, representing roles such as AI managers, analysts, developers, quality assurance professionals, and information security and privacy experts. The results reveal varying degrees of familiarity and experience with AI ethics principles, government initiatives, and risk mitigation strategies across roles, regions, and other demographic factors. Our findings highlight the importance of a collaborative, role-sensitive approach, involving diverse stakeholders in ethical decision-making throughout the AI development lifecycle. We advocate for developing tailored, inclusive solutions to address ethical challenges in AI development, and we propose future research directions and educational strategies to promote ethics-aware AI practices.', 'abstract_zh': '近年来，AI应用的进展引发了对需要制定伦理指导和规范以减轻这些技术所带来的风险的广泛关注。本文通过结合统计和定性分析的方法，进行了一项混合方法调查研究，以考察不同AI开发角色中个体的伦理感知、实践和知识。调查涵盖了来自43个国家的414名参与者，其角色包括AI经理、分析师、开发者、质量保证专业人员及信息安全和隐私专家。研究结果表明，不同角色、地区和其他人口统计因素之间在AI伦理原则、政府倡议和风险缓解策略的熟悉度和经验上存在差异。研究发现强调了在整个AI开发生命周期中采用协作且角色敏感的方法，涉及多元利益相关者参与伦理决策的重要性。本文提倡为AI开发中的伦理挑战制定量身定制且包容性解决方案，并提出未来研究方向和教育策略，促进伦理意识的增强。', 'title_zh': '理解人工智能中的伦理实践：来自跨角色、跨地区的人工智能开发团队调查的洞见'}
{'arxiv_id': 'arXiv:2508.09218', 'title': 'Towards Effective MLLM Jailbreaking Through Balanced On-Topicness and OOD-Intensity', 'authors': 'Zuoou Li, Weitong Zhang, Jingyuan Wang, Shuyuan Zhang, Wenjia Bai, Bernhard Kainz, Mengyun Qiao', 'link': 'https://arxiv.org/abs/2508.09218', 'abstract': 'Multimodal large language models (MLLMs) are widely used in vision-language reasoning tasks. However, their vulnerability to adversarial prompts remains a serious concern, as safety mechanisms often fail to prevent the generation of harmful outputs. Although recent jailbreak strategies report high success rates, many responses classified as "successful" are actually benign, vague, or unrelated to the intended malicious goal. This mismatch suggests that current evaluation standards may overestimate the effectiveness of such attacks. To address this issue, we introduce a four-axis evaluation framework that considers input on-topicness, input out-of-distribution (OOD) intensity, output harmfulness, and output refusal rate. This framework identifies truly effective jailbreaks. In a substantial empirical study, we reveal a structural trade-off: highly on-topic prompts are frequently blocked by safety filters, whereas those that are too OOD often evade detection but fail to produce harmful content. However, prompts that balance relevance and novelty are more likely to evade filters and trigger dangerous output. Building on this insight, we develop a recursive rewriting strategy called Balanced Structural Decomposition (BSD). The approach restructures malicious prompts into semantically aligned sub-tasks, while introducing subtle OOD signals and visual cues that make the inputs harder to detect. BSD was tested across 13 commercial and open-source MLLMs, where it consistently led to higher attack success rates, more harmful outputs, and fewer refusals. Compared to previous methods, it improves success rates by $67\\%$ and harmfulness by $21\\%$, revealing a previously underappreciated weakness in current multimodal safety systems.', 'abstract_zh': '多模态大规模语言模型（MLLMs）在视觉-语言推理任务中广泛应用。然而，它们对对抗性提示的脆弱性仍然是一个严重的问题，因为现有的安全机制往往无法防止生成有害输出。尽管最近的破戒策略报告了较高的成功率，但许多被归类为“成功”的响应实际上是非恶意的、模糊的或者与预定的恶意目标无关。这种不匹配表明当前的评估标准可能高估了这些攻击的有效性。为了解决这一问题，我们提出了一种四轴评估框架，该框架考虑输入的相关性、输入的异类强度、输出的有害性以及输出的拒绝率。该框架能够识别真正有效的破戒。在一项大规模的经验研究中，我们揭示了结构上的权衡：高度相关的提示经常被安全过滤器阻止，而那些过于异类的提示可能会避开检测但不产生有害内容。然而，兼顾相关性和新颖性的提示更有可能避开过滤器并触发危险输出。基于这一见解，我们开发了一种递归重写策略——平衡结构分解（BSD）。该方法将恶意提示重新构建成语义上一致的子任务，同时引入微妙的异类信号和视觉线索，使输入更难被检测到。BSD 在13种商业和开源 MLLMs 上进行了测试，结果显示出更高的攻击成功率、更多的有害输出以及更低的拒绝率。与之前的方法相比，它将成功率达到提高67%，有害性提高21%，揭示了当前多模态安全系统中被低估的一个弱点。', 'title_zh': '面向有效MLLM越界攻击的平衡主题相关性和OOD强度'}
{'arxiv_id': 'arXiv:2508.09215', 'title': 'Real-time deep learning phase imaging flow cytometer reveals blood cell aggregate biomarkers for haematology diagnostics', 'authors': 'Kerem Delikoyun, Qianyu Chen, Liu Wei, Si Ko Myo, Johannes Krell, Martin Schlegel, Win Sen Kuan, John Tshon Yit Soong, Gerhard Schneider, Clarissa Prazeres da Costa, Percy A. Knolle, Laurent Renia, Matthew Edward Cove, Hwee Kuan Lee, Klaus Diepold, Oliver Hayden', 'link': 'https://arxiv.org/abs/2508.09215', 'abstract': 'While analysing rare blood cell aggregates remains challenging in automated haematology, they could markedly advance label-free functional diagnostics. Conventional flow cytometers efficiently perform cell counting with leukocyte differentials but fail to identify aggregates with flagged results, requiring manual reviews. Quantitative phase imaging flow cytometry captures detailed aggregate morphologies, but clinical use is hampered by massive data storage and offline processing. Incorporating hidden biomarkers into routine haematology panels would significantly improve diagnostics without flagged results. We present RT-HAD, an end-to-end deep learning-based image and data processing framework for off-axis digital holographic microscopy (DHM), which combines physics-consistent holographic reconstruction and detection, representing each blood cell in a graph to recognize aggregates. RT-HAD processes >30 GB of image data on-the-fly with turnaround time of <1.5 min and error rate of 8.9% in platelet aggregate detection, which matches acceptable laboratory error rates of haematology biomarkers and solves the big data challenge for point-of-care diagnostics.', 'abstract_zh': '基于端到端深度学习的离轴数字全息显微镜图像和数据处理框架 RT-HAD：用于识别血小板聚集体的物理一致全息重构与检测', 'title_zh': '实时深度学习相位成像细胞分析仪揭示血液细胞聚集体生物标志物用于血液学诊断'}
{'arxiv_id': 'arXiv:2508.09212', 'title': 'Deep Generative Models for Discrete Genotype Simulation', 'authors': 'Sihan Xie, Thierry Tribout, Didier Boichard, Blaise Hanczar, Julien Chiquet, Eric Barrey', 'link': 'https://arxiv.org/abs/2508.09212', 'abstract': 'Deep generative models open new avenues for simulating realistic genomic data while preserving privacy and addressing data accessibility constraints. While previous studies have primarily focused on generating gene expression or haplotype data, this study explores generating genotype data in both unconditioned and phenotype-conditioned settings, which is inherently more challenging due to the discrete nature of genotype data. In this work, we developed and evaluated commonly used generative models, including Variational Autoencoders (VAEs), Diffusion Models, and Generative Adversarial Networks (GANs), and proposed adaptation tailored to discrete genotype data. We conducted extensive experiments on large-scale datasets, including all chromosomes from cow and multiple chromosomes from human. Model performance was assessed using a well-established set of metrics drawn from both deep learning and quantitative genetics literature. Our results show that these models can effectively capture genetic patterns and preserve genotype-phenotype association. Our findings provide a comprehensive comparison of these models and offer practical guidelines for future research in genotype simulation. We have made our code publicly available at this https URL.', 'abstract_zh': '深度生成模型拓宽了模拟现实基因组数据的同时保护隐私和解决数据访问性制约的途径，而先前的研究主要\nuser\n请修改为：深度生成模型为模拟现实基因组数据、同时保护隐私和解决数据访问限制开拓了新途径，先前的研究主要关注生成基因表达和单倍型数据，而本研究探索了生成基因型数据的问题，在由于基因型数据的离散性质，这在不受条件和表型条件下的生成构成了更大的挑战。本研究开发并评估了多种生成模型，包括变分动编码器（扩散模型和生成对抗网络，并提出针对离散基因型数据的适应性。我们使用广泛的已建立的评估方法，包括来自深度学习和数量性遗传学文献的指标，我们的研究结果表明这些模型可以有效地捕捉遗传模式并并 保留基因型--型关联。我们的发现为基因型模拟未来研究提供了全面比较和实践指导。我们已将代码公开在该网址上。。请逐句翻译，禁止输出多余的空行或--型。', 'title_zh': '深度生成模型在离散基因型模拟中的应用'}
{'arxiv_id': 'arXiv:2508.09210', 'title': 'MME-Emotion: A Holistic Evaluation Benchmark for Emotional Intelligence in Multimodal Large Language Models', 'authors': 'Fan Zhang, Zebang Cheng, Chong Deng, Haoxuan Li, Zheng Lian, Qian Chen, Huadai Liu, Wen Wang, Yi-Fan Zhang, Renrui Zhang, Ziyu Guo, Zhihong Zhu, Hao Wu, Haixin Wang, Yefeng Zheng, Xiaojiang Peng, Xian Wu, Kun Wang, Xiangang Li, Jieping Ye, Pheng-Ann Heng', 'link': 'https://arxiv.org/abs/2508.09210', 'abstract': "Recent advances in multimodal large language models (MLLMs) have catalyzed transformative progress in affective computing, enabling models to exhibit emergent emotional intelligence. Despite substantial methodological progress, current emotional benchmarks remain limited, as it is still unknown: (a) the generalization abilities of MLLMs across distinct scenarios, and (b) their reasoning capabilities to identify the triggering factors behind emotional states. To bridge these gaps, we present \\textbf{MME-Emotion}, a systematic benchmark that assesses both emotional understanding and reasoning capabilities of MLLMs, enjoying \\textit{scalable capacity}, \\textit{diverse settings}, and \\textit{unified protocols}. As the largest emotional intelligence benchmark for MLLMs, MME-Emotion contains over 6,000 curated video clips with task-specific questioning-answering (QA) pairs, spanning broad scenarios to formulate eight emotional tasks. It further incorporates a holistic evaluation suite with hybrid metrics for emotion recognition and reasoning, analyzed through a multi-agent system framework. Through a rigorous evaluation of 20 advanced MLLMs, we uncover both their strengths and limitations, yielding several key insights: \\ding{182} Current MLLMs exhibit unsatisfactory emotional intelligence, with the best-performing model achieving only $39.3\\%$ recognition score and $56.0\\%$ Chain-of-Thought (CoT) score on our benchmark. \\ding{183} Generalist models (\\emph{e.g.}, Gemini-2.5-Pro) derive emotional intelligence from generalized multimodal understanding capabilities, while specialist models (\\emph{e.g.}, R1-Omni) can achieve comparable performance through domain-specific post-training adaptation. By introducing MME-Emotion, we hope that it can serve as a foundation for advancing MLLMs' emotional intelligence in the future.", 'abstract_zh': '近期多模态大型语言模型的发展推动了情感计算的变革性进步，使其具备了 emergent 情感智能。尽管在方法上取得了显著进展，当前的情感基准仍然有限，因为仍然不清楚：（a）多模态大型语言模型在不同场景下的通用能力，以及（b）它们识别人类情感状态背后触发因素的推理能力。为了填补这些空白，我们提出了**MME-Emotion**，一个系统性的基准，评估多模态大型语言模型的情感理解和推理能力，具备可扩展性、多样化场景和统一协议。作为多模态大型语言模型最大的情感智能基准，MME-Emotion 包含超过 6,000 个精心挑选的视频片段及其任务特定的问题-答案（QA）对，涵盖广泛的场景以形成八项情感任务。此外，它进一步整合了一个综合评价套件，结合了情绪识别和推理的混合度量，并通过多代理系统框架进行分析。通过对 20 种先进多模态大型语言模型的严格评估，我们发现它们在情感智能方面存在不足，最佳模型在我们的基准上的识别分为 39.3%，推理链分为 56.0%。****通用模型（例如，Gemini-2.5-Pro）通过泛化的多模态理解能力获得情感智能，而专业模型（例如，R1-Omni）则通过特定领域的后训练适应达到相当的表现。通过引入 MME-Emotion，我们希望它能够成为未来推动多模态大型语言模型情感智能发展的基石。', 'title_zh': 'MME-情感：多模态大型语言模型情感智能的整体评估基准'}
{'arxiv_id': 'arXiv:2508.09209', 'title': 'Quantum-Enhanced Generative Adversarial Networks: Comparative Analysis of Classical and Hybrid Quantum-Classical Generative Adversarial Networks', 'authors': 'Kun Ming Goh', 'link': 'https://arxiv.org/abs/2508.09209', 'abstract': "Generative adversarial networks (GANs) have emerged as a powerful paradigm for producing high-fidelity data samples, yet their performance is constrained by the quality of latent representations, typically sampled from classical noise distributions. This study investigates hybrid quantum-classical GANs (HQCGANs) in which a quantum generator, implemented via parameterised quantum circuits, produces latent vectors for a classical discriminator. We evaluate a classical GAN alongside three HQCGAN variants with 3, 5, and 7 qubits, using Qiskit's AerSimulator with realistic noise models to emulate near-term quantum devices. The binary MNIST dataset (digits 0 and 1) is used to align with the low-dimensional latent spaces imposed by current quantum hardware. Models are trained for 150 epochs and assessed with Frechet Inception Distance (FID) and Kernel Inception Distance (KID). Results show that while the classical GAN achieved the best scores, the 7-qubit HQCGAN produced competitive performance, narrowing the gap in later epochs, whereas the 3-qubit model exhibited earlier convergence limitations. Efficiency analysis indicates only moderate training time increases despite quantum sampling overhead. These findings validate the feasibility of noisy quantum circuits as latent priors in GAN architectures, highlighting their potential to enhance generative modelling within the constraints of the noisy intermediate-scale quantum (NISQ) era.", 'abstract_zh': '基于混合量子-经典生成对抗网络的生成模型研究：量子生成器在经典判别器中的应用', 'title_zh': '量子增强生成对抗网络：经典与量子经典混合生成对抗网络的比较分析'}
{'arxiv_id': 'arXiv:2508.09208', 'title': 'CoMoE: Collaborative Optimization of Expert Aggregation and Offloading for MoE-based LLMs at Edge', 'authors': 'Muqing Li, Ning Li, Xin Yuan, Wenchao Xu, Quan Chen, Song Guo, Haijun Zhang', 'link': 'https://arxiv.org/abs/2508.09208', 'abstract': 'The proliferation of large language models (LLMs) has driven the adoption of Mixture-of-Experts (MoE) architectures as a promising solution to scale model capacity while controlling computational costs. However, deploying MoE models in resource-constrained mobile edge computing environments presents significant challenges due to their large memory footprint and dynamic expert activation patterns. To address these challenges, we propose a novel dynamic resource-aware collaborative optimization framework that jointly optimizes expert aggregation granularity and offloading strategies based on real-time device resource states, network conditions, and input characteristics in mobile edge environments, denoted as CoMoE. In CoMoE, we first systematically analyze existing expert aggregation techniques, including expert parameter merging,knowledge distillation,and parameter sharing decomposition, identifying their limitations in dynamic mobile this http URL then investigate expert offloading strategies encompassing expert prediction and prefetching, expert caching and scheduling, and multi-tier storage architectures, revealing the interdependencies between routing decisions and offloading this http URL CoMoE incorporates adaptive scheduling mechanisms that respond to user mobility and varying network conditions, enabling efficient MoE deployment across heterogeneous edge devices. Extensive experiments on real mobile edge testbeds demonstrate that CoMoE achieves approximately 70% reduction in memory usage compared to baseline methods, 10.5% lower inference latency than existing expert offloading techniques, while maintaining model performance stability. For large-scale MoE models (e.g,7.4B-parameter Switch-Base-128), the CoMoE reduces memory requirements from 15.6GB to 4.7GB, enabling deployment on resource-constrained mobile edge devices that previously could only support much smaller models.', 'abstract_zh': '大型语言模型（LLMs）的泛滥推动了Mixture-of-Experts（MoE）架构的应用，作为在控制计算成本的同时扩展模型容量的有前途的解决方案。然而，在资源受限的移动边缘计算环境中部署MoE模型带来了显著挑战，因为它们具有较大的内存占用和动态专家激活模式。为了解决这些挑战，我们提出了一种新的动态资源感知协作优化框架CoMoE，该框架基于移动边缘环境中的实时设备资源状态、网络条件和输入特性，协同优化专家聚合粒度和卸载策略。CoMoE首先系统分析了现有的专家聚合技术，包括专家参数合并、知识蒸馏和参数共享分解，确定了这些技术在动态移动环境中的局限性，然后探讨了涵盖专家预测和预取、专家缓存和调度、以及多级存储架构的专家卸载策略，揭示了路由决策与卸载之间的相互依赖关系。CoMoE 包含能够响应用户移动性和变化网络条件的自适应调度机制，从而在异构边缘设备上高效部署MoE模型。在实际移动边缘试验台上进行的广泛实验表明，与基准方法相比，CoMoE 将内存使用量减少了约70%，比现有专家卸载技术的推理延迟低10.5%，同时保持了模型性能的稳定性。对于大规模MoE模型（例如，74亿参数的Switch-Base-128），CoMoE 将内存需求从15.6GB降低到4.7GB，使资源受限的移动边缘设备能够部署支持更大模型。', 'title_zh': 'CoMoE：基于边缘的MoE架构中专家聚合与卸载的协作优化'}
{'arxiv_id': 'arXiv:2508.09205', 'title': 'From Explainable to Explained AI: Ideas for Falsifying and Quantifying Explanations', 'authors': 'Yoni Schirris, Eric Marcus, Jonas Teuwen, Hugo Horlings, Efstratios Gavves', 'link': 'https://arxiv.org/abs/2508.09205', 'abstract': "Explaining deep learning models is essential for clinical integration of medical image analysis systems. A good explanation highlights if a model depends on spurious features that undermines generalization and harms a subset of patients or, conversely, may present novel biological insights. Although techniques like GradCAM can identify influential features, they are measurement tools that do not themselves form an explanation. We propose a human-machine-VLM interaction system tailored to explaining classifiers in computational pathology, including multi-instance learning for whole-slide images. Our proof of concept comprises (1) an AI-integrated slide viewer to run sliding-window experiments to test claims of an explanation, and (2) quantification of an explanation's predictiveness using general-purpose vision-language models. The results demonstrate that this allows us to qualitatively test claims of explanations and can quantifiably distinguish competing explanations. This offers a practical path from explainable AI to explained AI in digital pathology and beyond. Code and prompts are available at this https URL.", 'abstract_zh': '深度学习模型的解释对于医学图像分析在临床中的集成是必要的。', 'title_zh': '从可解释到被解释的AI：验证和量化解释的思路'}
{'arxiv_id': 'arXiv:2508.09204', 'title': 'MoQE: Improve Quantization Model performance via Mixture of Quantization Experts', 'authors': 'Jinhao Zhang, Yunquan Zhang, Boyang Zhang, Zeyu Liu, Daning Cheng', 'link': 'https://arxiv.org/abs/2508.09204', 'abstract': 'Quantization method plays a crucial role in improving model efficiency and reducing deployment costs, enabling the widespread application of deep learning models on resource-constrained devices. However, the quantization process inevitably introduces accuracy degradation. In this paper, we propose Mixture of Quantization Experts( abbr. MoQE), a quantization inference framework based on the Mixture-of-Experts (MoE) architecture, aiming to jointly improve the performance of quantization models. MoQE combines multiple quantization variants of one full-precision model as specialized "quantization experts" and dynamically routes input data to the most suitable expert based on its characteristics. MoQE alleviates the performance degradation commonly seen in single quantization models through specialization quantization expert models. We design lightweight, structure-aware router models tailored for both CV and NLP tasks. Experimental evaluations on ResNet, LLaMA, and Qwen model families across benchmark datasets including ImageNet, WikiText, C4, and OpenWebText demonstrate that MoQE achieves performance comparable to SOTA quantization model, without incurring significant increases in inference latency.', 'abstract_zh': '混合量化专家（MoQE）：基于Mixture-of-Experts架构的量化推理框架', 'title_zh': 'MoQE：通过混合量化专家提高量化模型性能'}
{'arxiv_id': 'arXiv:2508.09202', 'title': 'Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method', 'authors': 'Masoumeh Sharafi, Soufiane Belharbi, Houssem Ben Salem, Ali Etemad, Alessandro Lameiras Koerich, Marco Pedersoli, Simon Bacon, Eric Granger', 'link': 'https://arxiv.org/abs/2508.09202', 'abstract': 'Facial expression recognition (FER) models are employed in many video-based affective computing applications, such as human-computer interaction and healthcare monitoring. However, deep FER models often struggle with subtle expressions and high inter-subject variability, limiting their performance in real-world applications. To improve their performance, source-free domain adaptation (SFDA) methods have been proposed to personalize a pretrained source model using only unlabeled target domain data, thereby avoiding data privacy, storage, and transmission constraints. This paper addresses a challenging scenario where source data is unavailable for adaptation, and only unlabeled target data consisting solely of neutral expressions is available. SFDA methods are not typically designed to adapt using target data from only a single class. Further, using models to generate facial images with non-neutral expressions can be unstable and computationally intensive. In this paper, personalized feature translation (PFT) is proposed for SFDA. Unlike current image translation methods for SFDA, our lightweight method operates in the latent space. We first pre-train the translator on the source domain data to transform the subject-specific style features from one source subject into another. Expression information is preserved by optimizing a combination of expression consistency and style-aware objectives. Then, the translator is adapted on neutral target data, without using source data or image synthesis. By translating in the latent space, PFT avoids the complexity and noise of face expression generation, producing discriminative embeddings optimized for classification. Using PFT eliminates the need for image synthesis, reduces computational overhead (using a lightweight translator), and only adapts part of the model, making the method efficient compared to image-based translation.', 'abstract_zh': '无源域适配中个性化特征翻译方法：面部表情识别模型的改进', 'title_zh': '基于个性特征翻译的表情识别：一种高效的源无监督域适应方法'}
{'arxiv_id': 'arXiv:2508.09201', 'title': 'Learning to Detect Unknown Jailbreak Attacks in Large Vision-Language Models: A Unified and Accurate Approach', 'authors': 'Shuang Liang, Zhihao Xu, Jialing Tao, Hui Xue, Xiting Wang', 'link': 'https://arxiv.org/abs/2508.09201', 'abstract': 'Despite extensive alignment efforts, Large Vision-Language Models (LVLMs) remain vulnerable to jailbreak attacks, posing serious safety risks. Although recent detection works have shifted to internal representations due to their rich cross-modal information, most methods rely on heuristic rules rather than principled objectives, resulting in suboptimal performance. To address these limitations, we propose Learning to Detect (LoD), a novel unsupervised framework that formulates jailbreak detection as anomaly detection. LoD introduces two key components: Multi-modal Safety Concept Activation Vectors (MSCAV), which capture layer-wise safety-related representations across modalities, and the Safety Pattern Auto-Encoder, which models the distribution of MSCAV derived from safe inputs and detects anomalies via reconstruction errors. By training the auto-encoder (AE) solely on safe samples without attack labels, LoD naturally identifies jailbreak inputs as distributional anomalies, enabling accurate and unified detection of jailbreak attacks. Comprehensive experiments on three different LVLMs and five benchmarks demonstrate that LoD achieves state-of-the-art performance, with an average AUROC of 0.9951 and an improvement of up to 38.89% in the minimum AUROC over the strongest baselines.', 'abstract_zh': '尽管进行了广泛的努力对齐，大型视觉-语言模型（LVLMs）仍然容易受到劫持攻击，这带来了严重的安全风险。尽管最近的检测工作转向了内部表示，以利用其丰富的跨模态信息，但大多数方法仍然依赖于启发式规则而不是原理性的目标，导致性能不佳。为解决这些限制，我们提出了学习检测（LoD），这是一种新颖的无监督框架，将劫持检测公式化为异常检测。LoD 引入了两个关键组件：多模态安全性概念激活向量（MSCAV），用于捕捉各模态的分层安全性相关表示，以及安全性模式自编码器，该自编码器建模来自安全输入的 MSCAV 的分布，并通过重构误差检测异常。通过仅使用安全样本而不使用攻击标签训练自编码器（AE），LoD 自然而然地将劫持输入识别为分布异常，从而实现对劫持攻击的准确和统一检测。针对三个不同 LVLM 和五个基准的全面实验表明，LoD 达到了最先进的性能，平均 AUCROC 为 0.9951，并且相对于最强基线在最小 AUCROC 上的提升最高达 38.89%。', 'title_zh': '在大型视觉-语言模型中学习检测未知越狱攻击：一种统一且准确的方法'}
{'arxiv_id': 'arXiv:2508.09200', 'title': 'Zero-shot self-supervised learning of single breath-hold magnetic resonance cholangiopancreatography (MRCP) reconstruction', 'authors': 'Jinho Kim, Marcel Dominik Nickel, Florian Knoll', 'link': 'https://arxiv.org/abs/2508.09200', 'abstract': 'Purpose: To investigate the feasibility of applying zero-shot self-supervised learning reconstruction to reduce breath-hold times in magnetic resonance cholangiopancreatography (MRCP). Methods: Breath-hold MRCP was acquired from 11 healthy volunteers on a 3T scanner using an incoherent k-space sampling pattern leading to a breath-hold duration of 14s. We evaluated zero-shot reconstruction of breath-hold MRCP against parallel imaging of respiratory-triggered MRCP acquired in 338s on average and compressed sensing reconstruction of breath-hold MRCP. To address the long computation times of zero-shot trainings, we used a training approach that leverages a pretrained network to reduce backpropagation depth during training. Results: Zero-shot learning reconstruction significantly improved visual image quality compared to compressed sensing reconstruction, particularly in terms of signal-to-noise ratio and ductal delineation, and reached a level of quality comparable to that of successful respiratory-triggered acquisitions with regular breathing patterns. Shallow training provided nearly equivalent reconstruction performance with a training time of 11 minutes in comparison to 271 minutes for a conventional zero-shot training. Conclusion: Zero-shot learning delivers high-fidelity MRCP reconstructions with reduced breath-hold times, and shallow training offers a practical solution for translation to time-constrained clinical workflows.', 'abstract_zh': '目的：探究零样本自我 supervised 学习重建在减少磁共振胆胰管成像 (MRCP) 呼吸屏气时间中的可行性。方法：从11名健康志愿者中获取呼吸屏气 MRCP 图像，使用无相干 k-空间采样模式在3特斯拉扫描器上进行，呼吸屏气持续时间为14秒。我们将零样本重建的呼吸屏气 MRCP 与平均持续时长为338秒的呼吸触发 MRCP 平行成像及压缩感知重建的呼吸屏气 MRCP 进行评估。为解决零样本训练的长时间问题，我们采用了利用预训练网络的方法，在训练过程中减少反向传播的深度。结果：零样本学习重建在信噪比和胆管勾勒方面显著改善了图像质量，达到了与成功呼吸触发采集相似的水平。浅层训练在11分钟的训练时间内提供了几乎等同的重建性能，而传统零样本训练的训练时间为271分钟。结论：零样本学习可在减少呼吸屏气时间的同时提供高质量的 MRCP 重建，并且浅层训练为时间受限的临床工作流程带来了实用的解决方案。', 'title_zh': '零样本自监督学习在单次屏气磁共振胆胰管成像（MRCP）重建中的应用'}
{'arxiv_id': 'arXiv:2508.09199', 'title': '$Δ$-AttnMask: Attention-Guided Masked Hidden States for Efficient Data Selection and Augmentation', 'authors': 'Jucheng Hu, Suorong Yang, Dongzhan Zhou', 'link': 'https://arxiv.org/abs/2508.09199', 'abstract': "Visual Instruction Finetuning (VIF) is pivotal for post-training Vision-Language Models (VLMs). Unlike unimodal instruction finetuning in plain-text large language models, which mainly requires instruction datasets to enable model instruction-following ability, VIF also requires multimodal data to enable joint visual and textual understanding; therefore, it typically requires more data. Consequently, VIF imposes stricter data selection challenges: the method must scale efficiently to handle larger data demands while ensuring the quality of both visual and textual content, as well as their alignment. Despite its critical impact on performance, data selection for VIF remains an understudied area. In this paper, we propose $\\Delta$-AttnMask. This data-efficient framework quantifies sample quality through attention-guided masking of the model's hidden states, jointly evaluating image-text pairs without requiring domain labels, auxiliary models, or extra training. By computing loss differences ($\\Delta$) between the original states and states masked using high-attention regions, $\\Delta$-AttnMask intrinsically assesses sample quality. Experiments across multiple VLMs and datasets show that $\\Delta$-AttnMask achieves state-of-the-art performance with just 20% of data, accelerating training by 5x while surpassing full-dataset baselines by +10.1% in overall accuracy. Its model-agnostic and data-agnostic design ensures broad applicability across modalities and architectures.", 'abstract_zh': '视觉指令微调（VIF）是后训练视觉语言模型（VLMs）的关键。视觉指令微调不仅需要单模态指令数据集来提升模型的指令跟随能力，还要求多模态数据以促进视觉和文本的联合理解。因此，它通常需要更多的数据。这导致视觉指令微调在数据选择上面临更严格的挑战：方法必须高效地扩展以应对更大的数据需求，同时确保视觉和文本内容的质量及其对齐。尽管数据选择对性能有重大影响，但视觉指令微调的数据选择仍然是一个研究不足的领域。在这项工作中，我们提出了$\\Delta$-AttnMask。这是一种数据高效的框架，通过注意力引导的模型隐藏状态掩蔽来量化样本质量，可以在不使用领域标签、辅助模型或额外训练的情况下联合评估图像-文本对。通过计算原始状态和使用高注意力区域掩蔽的状态之间的损失差异（$\\Delta$），$\\Delta$-AttnMask 本质上评估样本质量。在多个视觉语言模型和数据集上的实验显示，$\\Delta$-AttnMask 只需使用数据的 20% 就能实现最佳性能，加速训练 5 倍，并在总体准确性上超越全数据基线 +10.1%。其模型无关和数据无关的设计确保了其在不同模态和架构上的广泛应用。', 'title_zh': '$\\Delta$-AttnMask: 基于注意力引导的掩蔽隐藏状态用于高效数据选择和增强'}
{'arxiv_id': 'arXiv:2508.09198', 'title': 'ADT4Coupons: An Innovative Framework for Sequential Coupon Distribution in E-commerce', 'authors': 'Li Kong, Bingzhe Wang, Zhou Chen, Suhan Hu, Yuchao Ma, Qi Qi, Suoyuan Song, Bicheng Jin', 'link': 'https://arxiv.org/abs/2508.09198', 'abstract': 'Coupon distribution is a critical marketing strategy used by online platforms to boost revenue and enhance user engagement. Regrettably, existing coupon distribution strategies fall far short of effectively leveraging the complex sequential interactions between platforms and users. This critical oversight, despite the abundance of e-commerce log data, has precipitated a performance plateau. In this paper, we focus on the scene that the platforms make sequential coupon distribution decision multiple times for various users, with each user interacting with the platform repeatedly. Based on this marketing scenario, we propose a novel marketing framework, named Aligned Decision Transformer for Coupons (ADT4Coupons), to directly devise coupon distribution policy for long-term revenue boosting. ADT4Coupons enables optimized online decision-making in a variety of real-world marketing scenarios. It achieves this by seamlessly integrating three key characteristics, general scenarios, sequential modeling with more comprehensive historical data, and efficient iterative updates within a unified framework. Furthermore, empirical results on real-world industrial dataset, alongside public and synthetic datasets demonstrate the superiority of our framework.', 'abstract_zh': '在线平台的券分布是一种关键的营销策略，用于提升收入和增强用户参与度。遗憾的是，现有的券分布策略远未充分利用平台与用户之间复杂的序列交互。尽管存在大量的电子商务日志数据，这一关键遗漏导致了性能瓶颈。本文关注平台为不同用户多次进行序列化券分布决策的场景，且每位用户会反复与平台互动。基于这一营销场景，我们提出了一种新颖的营销框架，名为对齐决策变换器用于券（ADT4Coupons），以直接设计长期收入增强的券分布策略。ADT4Coupons能够在多种实际营销场景中实现优化的在线决策。它通过在一个统一框架中无缝整合三大关键特征——通用场景、包含更多历史数据的序列建模以及高效的迭代更新——来实现这一目标。此外，基于真实工业数据集以及公开和合成数据集的实证结果亦证明了该框架的优越性。', 'title_zh': 'ADT4券：一种新颖的电子商务中序贯券分发框架'}
{'arxiv_id': 'arXiv:2508.09197', 'title': 'MX-AI: Agentic Observability and Control Platform for Open and AI-RAN', 'authors': 'Ilias Chatzistefanidis, Andrea Leone, Ali Yaghoubian, Mikel Irazabal, Sehad Nassim, Lina Bariah, Merouane Debbah, Navid Nikaein', 'link': 'https://arxiv.org/abs/2508.09197', 'abstract': 'Future 6G radio access networks (RANs) will be artificial intelligence (AI)-native: observed, reasoned about, and re-configured by autonomous agents cooperating across the cloud-edge continuum. We introduce MX-AI, the first end-to-end agentic system that (i) instruments a live 5G Open RAN testbed based on OpenAirInterface (OAI) and FlexRIC, (ii) deploys a graph of Large-Language-Model (LLM)-powered agents inside the Service Management and Orchestration (SMO) layer, and (iii) exposes both observability and control functions for 6G RAN resources through natural-language intents. On 50 realistic operational queries, MX-AI attains a mean answer quality of 4.1/5.0 and 100 % decision-action accuracy, while incurring only 8.8 seconds end-to-end latency when backed by GPT-4.1. Thus, it matches human-expert performance, validating its practicality in real settings. We publicly release the agent graph, prompts, and evaluation harness to accelerate open research on AI-native RANs. A live demo is presented here: this https URL', 'abstract_zh': '未来的6G无线接入网络（RAN）将具有人工智能（AI）原生特性：通过跨云边 continuum 的自主代理进行观察、推理和重构。我们引入了MX-AI，这是一个端到端的自主系统，它在基于OpenAirInterface (OAI) 和 FlexRIC 的实时5G Open RAN试验床上进行仪器化，部署了Service Management and Orchestration (SMO) 层内的Large-Language-Model (LLM) 动力代理图，并通过自然语言意图暴露6G RAN资源的可观测性和控制功能。在50个现实的操作查询中，MX-AI的平均回答质量为4.1/5.0，决策-行动准确率为100%，并在支持GPT-4.1的情况下仅产生8.8秒的端到端延迟，从而达到了人类专家的性能水平，验证了其在实际环境中的实用性。我们公开发布代理图、提示和评估框架，以加速对AI原生RAN的开放研究。演示链接：this https URL', 'title_zh': 'MX-AI: 为开放和AI-RAN的代理可观测性和控制平台'}
{'arxiv_id': 'arXiv:2508.09196', 'title': 'FIVA: Federated Inverse Variance Averaging for Universal CT Segmentation with Uncertainty Estimation', 'authors': 'Asim Ukaye, Numan Saeed, Karthik Nandakumar', 'link': 'https://arxiv.org/abs/2508.09196', 'abstract': 'Different CT segmentation datasets are typically obtained from different scanners under different capture settings and often provide segmentation labels for a limited and often disjoint set of organs. Using these heterogeneous data effectively while preserving patient privacy can be challenging. This work presents a novel federated learning approach to achieve universal segmentation across diverse abdominal CT datasets by utilizing model uncertainty for aggregation and predictive uncertainty for inference. Our approach leverages the inherent noise in stochastic mini-batch gradient descent to estimate a distribution over the model weights to provide an on-the-go uncertainty over the model parameters at the client level. The parameters are then aggregated at the server using the additional uncertainty information using a Bayesian-inspired inverse-variance aggregation scheme. Furthermore, the proposed method quantifies prediction uncertainty by propagating the uncertainty from the model weights, providing confidence measures essential for clinical decision-making. In line with recent work shown, predictive uncertainty is utilized in the inference stage to improve predictive performance. Experimental evaluations demonstrate the effectiveness of this approach in improving both the quality of federated aggregation and uncertainty-weighted inference compared to previously established baselines. The code for this work is made available at: this https URL', 'abstract_zh': '不同CT分割数据集通常来自不同的扫描器并在不同的采集设置下获得， often 提供有限且通常不连续的器官分割标签。利用这些异质性数据并同时保护患者隐私是具有挑战性的。本文提出了一种新颖的联邦学习方法，通过利用模型不确定性进行聚合和预测不确定性进行推理，实现跨多样腹部CT数据集的通用分割。该方法利用随机小批量梯度下降固有的噪声来估计模型权重的分布，在客户端层面提供一个实时的模型参数不确定性。然后，服务器利用附加的不确定性信息使用贝叶斯启发的方差加权聚合方案进行参数聚合。此外，本方法通过从模型权重传播不确定性来量化预测不确定性，提供对于临床决策至关重要的信心度量。在推理阶段利用预测不确定性进一步提高预测性能。实验评估表明，与先前建立的基准相比，该方法在提高联邦聚合质量和不确定性加权推理方面是有效的。该工作的代码可在以下链接获得：this https URL。', 'title_zh': 'FIVA：联邦逆方差平均在不确定性估计下的通用CT分割'}
{'arxiv_id': 'arXiv:2508.09195', 'title': 'impuTMAE: Multi-modal Transformer with Masked Pre-training for Missing Modalities Imputation in Cancer Survival Prediction', 'authors': 'Maria Boyko, Aleksandra Beliaeva, Dmitriy Kornilov, Alexander Bernstein, Maxim Sharaev', 'link': 'https://arxiv.org/abs/2508.09195', 'abstract': 'The use of diverse modalities, such as omics, medical images, and clinical data can not only improve the performance of prognostic models but also deepen an understanding of disease mechanisms and facilitate the development of novel treatment approaches. However, medical data are complex, often incomplete, and contains missing modalities, making effective handling its crucial for training multimodal models. We introduce impuTMAE, a novel transformer-based end-to-end approach with an efficient multimodal pre-training strategy. It learns inter- and intra-modal interactions while simultaneously imputing missing modalities by reconstructing masked patches. Our model is pre-trained on heterogeneous, incomplete data and fine-tuned for glioma survival prediction using TCGA-GBM/LGG and BraTS datasets, integrating five modalities: genetic (DNAm, RNA-seq), imaging (MRI, WSI), and clinical data. By addressing missing data during pre-training and enabling efficient resource utilization, impuTMAE surpasses prior multimodal approaches, achieving state-of-the-art performance in glioma patient survival prediction. Our code is available at this https URL', 'abstract_zh': '多种模态（如组学、医学图像和临床数据）的使用不仅可以提高预后模型的性能，还可以加深对疾病机制的理解，并促进新治疗方案的发展。然而，医疗数据复杂且经常不完整，包含缺失的模态，因此有效处理这些数据对于训练多模态模型至关重要。我们引入了impuTMAE，这是一种新颖的基于变压器的端到端方法，具有高效的多模态预训练策略。该方法在学习跨模态和同模态交互的同时，通过重建掩码片段来填补缺失的模态。我们的模型在异质且不完整的数据上进行预训练，并使用TCGA-GBM/LGG和BraTS数据集微调以预测胶质瘤患者的生存情况，整合了五种模态：遗传学（DNA甲基化、RNA-seq）、影像学（MRI、WSI）和临床数据。通过对预训练过程中缺失数据的处理以及高效资源利用，impuTMAE超越了之前的多模态方法，在胶质瘤患者生存预测方面实现了最先进的性能。我们的代码可在以下链接获取。', 'title_zh': 'impuTMAE：用于癌症生存预测中多模态缺失模态填充的掩蔽预训练Transformer'}
{'arxiv_id': 'arXiv:2508.09194', 'title': 'Meta-Learning for Speeding Up Large Model Inference in Decentralized Environments', 'authors': 'Yipeng Du, Zihao Wang, Ahmad Farhan, Claudio Angione, Harry Yang, Fielding Johnston, James P. Buban, Patrick Colangelo, Yue Zhao, Yuzhe Yang', 'link': 'https://arxiv.org/abs/2508.09194', 'abstract': 'The deployment of large-scale models, such as large language models (LLMs), incurs substantial costs due to their computational demands. To mitigate these costs and address challenges related to scalability and data security, there is a growing shift towards decentralized systems for model deployment, where choosing efficient inference acceleration schemes become crucial to manage computational resources effectively and enhance system responsiveness. In this work, we address the challenge of selecting optimal acceleration methods in decentralized systems by introducing a meta-learning-based framework. This framework automates the selection process by learning from historical performance data of various acceleration techniques across different tasks. Unlike traditional methods that rely on random selection or expert intuition, our approach systematically identifies the best acceleration strategies based on the specific characteristics of each task. We demonstrate that our meta-learning framework not only streamlines the decision-making process but also consistently outperforms conventional methods in terms of efficiency and performance. Our results highlight the potential of inference acceleration in decentralized AI systems, offering a path towards more democratic and economically feasible artificial intelligence solutions.', 'abstract_zh': '大规模模型（如大规模语言模型）的部署由于其计算需求而产生了相当大的成本。为了减轻这些成本并解决可扩展性和数据安全方面的挑战，模型部署逐渐向去中心化系统转移，选择高效的推理加速方案变得至关重要，可以有效管理计算资源并增强系统响应性。本文通过引入基于元学习的框架，应对去中心化系统中选择最优加速方法的挑战。该框架通过学习不同任务中各种加速技术的历史性能数据来自动化这一选择过程。与依赖随机选择或专家直觉的传统方法不同，我们的方法能够根据每个任务的具体特性系统地识别出最佳加速策略。我们证明，我们的元学习框架不仅简化了决策过程，而且在效率和性能方面均优于传统方法。我们的结果强调了推理加速在去中心化AI系统中的潜力，为更加民主和经济可行的人工智能解决方案提供了一条途径。', 'title_zh': '元学习在去中心化环境中加速大规模模型推理'}
{'arxiv_id': 'arXiv:2508.09193', 'title': 'Multi-Objective Instruction-Aware Representation Learning in Procedural Content Generation RL', 'authors': 'Sung-Hyun Kim, In-Chang Baek, Seo-Young Lee, Geum-Hwan Hwang, Kyung-Joong Kim', 'link': 'https://arxiv.org/abs/2508.09193', 'abstract': 'Recent advancements in generative modeling emphasize the importance of natural language as a highly expressive and accessible modality for controlling content generation. However, existing instructed reinforcement learning for procedural content generation (IPCGRL) method often struggle to leverage the expressive richness of textual input, especially under complex, multi-objective instructions, leading to limited controllability. To address this problem, we propose \\textit{MIPCGRL}, a multi-objective representation learning method for instructed content generators, which incorporates sentence embeddings as conditions. MIPCGRL effectively trains a multi-objective embedding space by incorporating multi-label classification and multi-head regression networks. Experimental results show that the proposed method achieves up to a 13.8\\% improvement in controllability with multi-objective instructions. The ability to process complex instructions enables more expressive and flexible content generation.', 'abstract_zh': '近期生成建模的发展强调了自然语言作为高度表达性和 accessible 模态在控制内容生成中的重要性。然而，现有的指令强化学习程序内容生成（IPCGRL）方法通常难以充分利用文本输入的表达丰富性，特别是在复杂、多目标指令下，导致控制能力有限。为了解决这一问题，我们提出了一种名为 MIPCGRL 的多目标表示学习方法，用于指令内容生成器，该方法结合了句子嵌入作为条件。MIPCGRL 通过集成多标签分类和多头回归网络有效地训练多目标嵌入空间。实验结果表明，所提出的方法在多目标指令下的控制能力最高可提高 13.8%。处理复杂指令的能力使内容生成更加表达性和灵活。', 'title_zh': '基于过程性内容生成的多目标指令意识表示学习'}
{'arxiv_id': 'arXiv:2508.09192', 'title': 'Diffusion LLMs Can Do Faster-Than-AR Inference via Discrete Diffusion Forcing', 'authors': 'Xu Wang, Chenkai Xu, Yijie Jin, Jiachun Jin, Hao Zhang, Zhijie Deng', 'link': 'https://arxiv.org/abs/2508.09192', 'abstract': 'Diffusion Large Language Models (dLLMs) have emerged as a promising alternative to autoregressive (AR) LLMs for text generation, with the potential to decode multiple tokens in a single iteration. However, none of the existing open-source dLLMs have achieved superior inference speed over AR LLMs of similar size. This paper breaks this barrier based on a simple and effective strategy named discrete diffusion forcing (D2F). D2F equips dLLMs with two key capabilities: (1) block-wise autoregressive generation to enable KV cache utilization; (2) prediction of following tokens without requiring completion of prior blocks for inter-block parallel decoding. In this way, the vanilla dLLMs are refurbished into an AR-diffusion hybrid paradigm for efficient inference. D2F can be implemented with an asymmetric distillation process based on pre-trained dLLMs. We further propose a pipelined parallel decoding algorithm, which enables a trade-off between efficiency and efficacy. Empirically, D2F dLLMs achieve more than $\\mathbf{2.5\\times}$ inference speed than LLaMA3 and Qwen2.5 on GSM8K. Compared to vanilla dLLMs like LLaDA and Dream, the acceleration can be more than $\\mathbf{50\\times}$ while maintaining comparable output quality. The code is available at this https URL.', 'abstract_zh': '离散扩散强迫(dLLMs)：一种比相似规模的自回归(AR) LLMs更快的文本生成方法', 'title_zh': '基于离散扩散强迫的扩散LLM超快速推理'}
{'arxiv_id': 'arXiv:2508.09191', 'title': 'From Values to Tokens: An LLM-Driven Framework for Context-aware Time Series Forecasting via Symbolic Discretization', 'authors': 'Xiaoyu Tao, Shilong Zhang, Mingyue Cheng, Daoyu Wang, Tingyue Pan, Bokai Pan, Changqing Zhang, Shijin Wang', 'link': 'https://arxiv.org/abs/2508.09191', 'abstract': 'Time series forecasting plays a vital role in supporting decision-making across a wide range of critical applications, including energy, healthcare, and finance. Despite recent advances, forecasting accuracy remains limited due to the challenge of integrating historical numerical sequences with contextual features, which often comprise unstructured textual data. To address this challenge, we propose TokenCast, an LLM-driven framework that leverages language-based symbolic representations as a unified intermediary for context-aware time series forecasting. Specifically, TokenCast employs a discrete tokenizer to transform continuous numerical sequences into temporal tokens, enabling structural alignment with language-based inputs. To bridge the semantic gap between modalities, both temporal and contextual tokens are embedded into a shared representation space via a pre-trained large language model (LLM), further optimized with autoregressive generative objectives. Building upon this unified semantic space, the aligned LLM is subsequently fine-tuned in a supervised manner to predict future temporal tokens, which are then decoded back into the original numerical space. Extensive experiments on diverse real-world datasets enriched with contextual features demonstrate the effectiveness and generalizability of TokenCast.', 'abstract_zh': '基于LLM的时间序列预测框架TokenCast在结合历史数值序列和上下文特征中的应用', 'title_zh': '从价值观到令牌：基于符号离散化的一种由大语言模型驱动的上下文感知时间序列预测框架'}
{'arxiv_id': 'arXiv:2508.09190', 'title': 'Fine-Grained Safety Neurons with Training-Free Continual Projection to Reduce LLM Fine Tuning Risks', 'authors': 'Bing Han, Feifei Zhao, Dongcheng Zhao, Guobin Shen, Ping Wu, Yu Shi, Yi Zeng', 'link': 'https://arxiv.org/abs/2508.09190', 'abstract': "Fine-tuning as service injects domain-specific knowledge into large language models (LLMs), while challenging the original alignment mechanisms and introducing safety risks. A series of defense strategies have been proposed for the alignment, fine-tuning, and post-fine-tuning phases, where most post-fine-tuning defenses rely on coarse-grained safety layer mapping. These methods lack a comprehensive consideration of both safety layers and fine-grained neurons, limiting their ability to efficiently balance safety and utility. To address this, we propose the Fine-Grained Safety Neurons (FGSN) with Training-Free Continual Projection method to reduce the fine-tuning safety risks. FGSN inherently integrates the multi-scale interactions between safety layers and neurons, localizing sparser and more precise fine-grained safety neurons while minimizing interference with downstream task neurons. We then project the safety neuron parameters onto safety directions, improving model safety while aligning more closely with human preferences. Extensive experiments across multiple fine-tuned LLM models demonstrate that our method significantly reduce harmfulness scores and attack success rates with minimal parameter modifications, while preserving the model's utility. Furthermore, by introducing a task-specific, multi-dimensional heterogeneous safety neuron cluster optimization mechanism, we achieve continual defense and generalization capability against unforeseen emerging safety concerns.", 'abstract_zh': 'Fine-tuning as服务注入领域特定知识到大型语言模型（LLMs），同时挑战原始对齐机制并引入安全风险。提出了多种防御策略用于对齐、微调和后微调阶段，其中大多数后微调防御依赖于粗粒度的安全层映射。这些方法未能全面考虑安全层和细粒度神经元，限制了它们高效平衡安全性和实用性的能力。为此，我们提出了一种基于无训练连续投影方法的细粒度安全神经元（FGSN）以降低微调安全风险。FGSN内在整合了安全层和神经元的多尺度交互，局部化更稀疏和精确的细粒度安全神经元，同时最小化对下游任务神经元的干扰。随后将安全神经元参数投影到安全方向，提高模型安全性同时更加符合人类偏好。在多个微调LLM模型上的广泛实验表明，我们的方法在最小参数修改的情况下显著降低了有害性评分和攻击成功率，同时保持模型的实用性。此外，通过引入针对特定任务的多维异构安全神经元簇优化机制，我们实现了对未预见的安全问题的持续防御和泛化能力。', 'title_zh': '无需训练的持续投影细粒度安全神经元以降低大语言模型微调风险'}
{'arxiv_id': 'arXiv:2508.09189', 'title': 'Hybrid(Transformer+CNN)-based Polyp Segmentation', 'authors': 'Madan Baduwal', 'link': 'https://arxiv.org/abs/2508.09189', 'abstract': 'Colonoscopy is still the main method of detection and segmentation of colonic polyps, and recent advancements in deep learning networks such as U-Net, ResUNet, Swin-UNet, and PraNet have made outstanding performance in polyp segmentation. Yet, the problem is extremely challenging due to high variation in size, shape, endoscopy types, lighting, imaging protocols, and ill-defined boundaries (fluid, folds) of the polyps, rendering accurate segmentation a challenging and problematic task. To address these critical challenges in polyp segmentation, we introduce a hybrid (Transformer + CNN) model that is crafted to enhance robustness against evolving polyp characteristics. Our hybrid architecture demonstrates superior performance over existing solutions, particularly in addressing two critical challenges: (1) accurate segmentation of polyps with ill-defined margins through boundary-aware attention mechanisms, and (2) robust feature extraction in the presence of common endoscopic artifacts, including specular highlights, motion blur, and fluid occlusions. Quantitative evaluations reveal significant improvements in segmentation accuracy (Recall improved by 1.76%, i.e., 0.9555, accuracy improved by 0.07%, i.e., 0.9849) and artifact resilience compared to state-of-the-art polyp segmentation methods.', 'abstract_zh': '基于Transformer和CNN的混合模型在结肠息肉分割中的应用：提高对 evolving 特征的鲁棒性', 'title_zh': '基于Transformer和CNN结合的息肉分割'}
{'arxiv_id': 'arXiv:2508.09186', 'title': 'RL-MoE: An Image-Based Privacy Preserving Approach In Intelligent Transportation System', 'authors': 'Abdolazim Rezaei, Mehdi Sookhak, Mahboobeh Haghparast', 'link': 'https://arxiv.org/abs/2508.09186', 'abstract': 'The proliferation of AI-powered cameras in Intelligent Transportation Systems (ITS) creates a severe conflict between the need for rich visual data and the fundamental right to privacy. Existing privacy-preserving mechanisms, such as blurring or encryption, are often insufficient, creating an undesirable trade-off where either privacy is compromised against advanced reconstruction attacks or data utility is critically degraded. To resolve this impasse, we propose RL-MoE, a novel framework that transforms sensitive visual data into privacy-preserving textual descriptions, eliminating the need for direct image transmission. RL-MoE uniquely combines a Mixture-of-Experts (MoE) architecture for nuanced, multi-aspect scene decomposition with a Reinforcement Learning (RL) agent that optimizes the generated text for a dual objective of semantic accuracy and privacy preservation. Extensive experiments demonstrate that RL-MoE provides superior privacy protection, reducing the success rate of replay attacks to just 9.4\\% on the CFP-FP dataset, while simultaneously generating richer textual content than baseline methods. Our work provides a practical and scalable solution for building trustworthy AI systems in privacy-sensitive domains, paving the way for more secure smart city and autonomous vehicle networks.', 'abstract_zh': 'AI驱动的摄像头在智能交通系统（ITS）中的普及引发了丰富的视觉数据需求与基本隐私权之间的严重冲突。现有的隐私保护机制，如模糊处理或加密，往往不足，导致了隐私泄露与高级重建攻击之间或数据有用性严重下降之间的不良权衡。为了缓解这一矛盾，我们提出了一种新颖的框架RL-MoE，该框架将敏感的视觉数据转换为隐私保护的文本描述，从而消除直接图像传输的需要。RL-MoE的独特之处在于它将混合专家（MoE）架构与强化学习（RL）代理相结合，前者用于精细的、多方面的场景分解，后者则优化生成的文本以实现语义准确性和隐私保护双重目标。广泛实验表明，RL-MoE提供了更好的隐私保护，在CFP-FP数据集上重放攻击成功率降低至9.4%，同时生成了比基线方法更丰富的文本内容。我们的工作为在隐私敏感领域构建可信赖的AI系统提供了实用且可扩展的解决方案，铺平了更加安全的智慧城市和自动驾驶车辆网络的道路。', 'title_zh': '基于图像的智能交通系统中隐私保护方法：RL-MoE'}
{'arxiv_id': 'arXiv:2508.09185', 'title': 'A Neurosymbolic Framework for Interpretable Cognitive Attack Detection in Augmented Reality', 'authors': 'Rongqian Chen, Allison Andreyev, Yanming Xiu, Mahdi Imani, Bin Li, Maria Gorlatova, Gang Tan, Tian Lan', 'link': 'https://arxiv.org/abs/2508.09185', 'abstract': "Augmented Reality (AR) enriches perception by overlaying virtual elements on the physical world. Due to its growing popularity, cognitive attacks that alter AR content to manipulate users' semantic perception have received increasing attention. Existing detection methods often focus on visual changes, which are restricted to pixel- or image-level processing and lack semantic reasoning capabilities, or they rely on pre-trained vision-language models (VLMs), which function as black-box approaches with limited interpretability. In this paper, we present CADAR, a novel neurosymbolic approach for cognitive attack detection in AR. It fuses multimodal vision-language inputs using neural VLMs to obtain a symbolic perception-graph representation, incorporating prior knowledge, salience weighting, and temporal correlations. The model then enables particle-filter based statistical reasoning -- a sequential Monte Carlo method -- to detect cognitive attacks. Thus, CADAR inherits the adaptability of pre-trained VLM and the interpretability and reasoning rigor of particle filtering. Experiments on an extended AR cognitive attack dataset show accuracy improvements of up to 10.7% over strong baselines on challenging AR attack scenarios, underscoring the promise of neurosymbolic methods for effective and interpretable cognitive attack detection.", 'abstract_zh': 'AR中的认知攻击检测的CADAR神经符号方法', 'title_zh': '面向增强现实的可解释认知攻击检测的神经符号框架'}
{'arxiv_id': 'arXiv:2508.09184', 'title': 'HiSTM: Hierarchical Spatiotemporal Mamba for Cellular Traffic Forecasting', 'authors': 'Zineddine Bettouche, Khalid Ali, Andreas Fischer, Andreas Kassler', 'link': 'https://arxiv.org/abs/2508.09184', 'abstract': 'Cellular traffic forecasting is essential for network planning, resource allocation, or load-balancing traffic across cells. However, accurate forecasting is difficult due to intricate spatial and temporal patterns that exist due to the mobility of users. Existing AI-based traffic forecasting models often trade-off accuracy and computational efficiency. We present Hierarchical SpatioTemporal Mamba (HiSTM), which combines a dual spatial encoder with a Mamba-based temporal module and attention mechanism. HiSTM employs selective state space methods to capture spatial and temporal patterns in network traffic. In our evaluation, we use a real-world dataset to compare HiSTM against several baselines, showing a 29.4% MAE improvement over the STN baseline while using 94% fewer parameters. We show that the HiSTM generalizes well across different datasets and improves in accuracy over longer time-horizons.', 'abstract_zh': '基于层次时空机制的蜂窝网络流量预测（Hierarchical SpatioTemporal Mamba (HiSTM)：结合时空编码与注意力机制的蜂窝网络流量预测）', 'title_zh': 'HiSTM: 分层时空猎蛛细胞流量预测'}
{'arxiv_id': 'arXiv:2508.09183', 'title': 'Quantum-Efficient Reinforcement Learning Solutions for Last-Mile On-Demand Delivery', 'authors': 'Farzan Moosavi, Bilal Farooq', 'link': 'https://arxiv.org/abs/2508.09183', 'abstract': 'Quantum computation has demonstrated a promising alternative to solving the NP-hard combinatorial problems. Specifically, when it comes to optimization, classical approaches become intractable to account for large-scale solutions. Specifically, we investigate quantum computing to solve the large-scale Capacitated Pickup and Delivery Problem with Time Windows (CPDPTW). In this regard, a Reinforcement Learning (RL) framework augmented with a Parametrized Quantum Circuit (PQC) is designed to minimize the travel time in a realistic last-mile on-demand delivery. A novel problem-specific encoding quantum circuit with an entangling and variational layer is proposed. Moreover, Proximal Policy Optimization (PPO) and Quantum Singular Value Transformation (QSVT) are designed for comparison through numerical experiments, highlighting the superiority of the proposed method in terms of the scale of the solution and training complexity while incorporating the real-world constraints.', 'abstract_zh': '量子计算提供了解决NP难组合问题的有希望的替代方案。特别是在优化领域，经典方法对于处理大规模解决方案变得不可行。因此，我们研究了量子计算解决带时间窗的容量受限拾取和配送问题（CPDPTW）的大规模实例。为此，我们设计了一种增强学习（RL）框架，结合参数量子电路（PQC），以最小化现实中的最后一英里按需配送的行驶时间。我们提出了一种新的问题特定编码量子电路，包括纠缠层和变分层。此外，我们通过数值实验设计了接近策略优化（PPO）和量子奇异值变换（QSVT），突出了所提出方法在满足现实世界约束条件下解决方案规模和训练复杂性方面的优越性。', 'title_zh': '量子高效强化学习解决方案应用于最后一英里按需配送'}
{'arxiv_id': 'arXiv:2508.09181', 'title': 'Long-Term Client Selection for Federated Learning with Non-IID Data: A Truthful Auction Approach', 'authors': 'Jinghong Tan, Zhian Liu, Kun Guo, Mingxiong Zhao', 'link': 'https://arxiv.org/abs/2508.09181', 'abstract': 'Federated learning (FL) provides a decentralized framework that enables universal model training through collaborative efforts on mobile nodes, such as smart vehicles in the Internet of Vehicles (IoV). Each smart vehicle acts as a mobile client, contributing to the process without uploading local data. This method leverages non-independent and identically distributed (non-IID) training data from different vehicles, influenced by various driving patterns and environmental conditions, which can significantly impact model convergence and accuracy. Although client selection can be a feasible solution for non-IID issues, it faces challenges related to selection metrics. Traditional metrics evaluate client data quality independently per round and require client selection after all clients complete local training, leading to resource wastage from unused training results. In the IoV context, where vehicles have limited connectivity and computational resources, information asymmetry in client selection risks clients submitting false information, potentially making the selection ineffective. To tackle these challenges, we propose a novel Long-term Client-Selection Federated Learning based on Truthful Auction (LCSFLA). This scheme maximizes social welfare with consideration of long-term data quality using a new assessment mechanism and energy costs, and the advised auction mechanism with a deposit requirement incentivizes client participation and ensures information truthfulness. We theoretically prove the incentive compatibility and individual rationality of the advised incentive mechanism. Experimental results on various datasets, including those from IoV scenarios, demonstrate its effectiveness in mitigating performance degradation caused by non-IID data.', 'abstract_zh': '基于 Truthful Auction 的长期客户端选择联邦学习（LCSFLA）', 'title_zh': '非独立同分布数据下联邦学习的长期客户端选择：一种诚实拍卖方法'}
{'arxiv_id': 'arXiv:2508.09180', 'title': 'scAGC: Learning Adaptive Cell Graphs with Contrastive Guidance for Single-Cell Clustering', 'authors': 'Huifa Li, Jie Fu, Xinlin Zhuang, Haolin Yang, Xinpeng Ling, Tong Cheng, Haochen xue, Imran Razzak, Zhili Chen', 'link': 'https://arxiv.org/abs/2508.09180', 'abstract': 'Accurate cell type annotation is a crucial step in analyzing single-cell RNA sequencing (scRNA-seq) data, which provides valuable insights into cellular heterogeneity. However, due to the high dimensionality and prevalence of zero elements in scRNA-seq data, traditional clustering methods face significant statistical and computational challenges. While some advanced methods use graph neural networks to model cell-cell relationships, they often depend on static graph structures that are sensitive to noise and fail to capture the long-tailed distribution inherent in single-cell this http URL address these limitations, we propose scAGC, a single-cell clustering method that learns adaptive cell graphs with contrastive guidance. Our approach optimizes feature representations and cell graphs simultaneously in an end-to-end manner. Specifically, we introduce a topology-adaptive graph autoencoder that leverages a differentiable Gumbel-Softmax sampling strategy to dynamically refine the graph structure during training. This adaptive mechanism mitigates the problem of a long-tailed degree distribution by promoting a more balanced neighborhood structure. To model the discrete, over-dispersed, and zero-inflated nature of scRNA-seq data, we integrate a Zero-Inflated Negative Binomial (ZINB) loss for robust feature reconstruction. Furthermore, a contrastive learning objective is incorporated to regularize the graph learning process and prevent abrupt changes in the graph topology, ensuring stability and enhancing convergence. Comprehensive experiments on 9 real scRNA-seq datasets demonstrate that scAGC consistently outperforms other state-of-the-art methods, yielding the best NMI and ARI scores on 9 and 7 datasets, this http URL code is available at Anonymous Github.', 'abstract_zh': '准确的细胞类型标注是分析单细胞RNA测序（scRNA-seq）数据的关键步骤，它为细胞异质性提供了宝贵见解。然而，由于scRNA-seq数据的高维度和零元素的普遍性，传统聚类方法面临显著的统计和计算挑战。尽管一些先进方法使用图神经网络来建模细胞间的相互关系，但它们往往依赖于敏感于噪声的静态图结构，并未能捕捉到单细胞数据固有的长尾分布。为了解决这些局限性，我们提出了scAGC，一种学习自适应细胞图的单细胞聚类方法，该方法在对比引导下优化特征表示和细胞图。我们的方法以端到端的方式同时优化特征表示和细胞图。具体而言，我们引入了一种拓扑自适应图自动编码器，利用可微的Gumbel-Softmax采样策略，在训练过程中动态优化图结构。这种自适应机制通过促进更平衡的邻域结构解决了长尾度分布的问题。为了建模scRNA-seq数据的离散、过度分散和零充溢特性，我们整合了零充溢负二项式（ZINB）损失以实现稳健的特征重构。此外，我们结合了对比学习目标来规整图学习过程，防止图拓扑的突然变化，从而确保稳定性和加快收敛。在9个真实scRNA-seq数据集上的综合实验中，scAGC始终优于其他最先进的方法，分别在9个和7个数据集上获得最佳的NMI和ARI分数。该项目代码可在Anononyous Github上获取。', 'title_zh': 'scAGC: 学习具有对比引导的自适应细胞图谱-single细胞聚类'}
{'arxiv_id': 'arXiv:2508.09178', 'title': 'IAD-R1: Reinforcing Consistent Reasoning in Industrial Anomaly Detection', 'authors': 'Yanhui Li, Yunkang Cao, Chengliang Liu, Yuan Xiong, Xinghui Dong, Chao Huang', 'link': 'https://arxiv.org/abs/2508.09178', 'abstract': 'Industrial anomaly detection is a critical component of modern manufacturing, yet the scarcity of defective samples restricts traditional detection methods to scenario-specific applications. Although Vision-Language Models (VLMs) demonstrate significant advantages in generalization capabilities, their performance in industrial anomaly detection remains limited. To address this challenge, we propose IAD-R1, a universal post-training framework applicable to VLMs of different architectures and parameter scales, which substantially enhances their anomaly detection capabilities. IAD-R1 employs a two-stage training strategy: the Perception Activation Supervised Fine-Tuning (PA-SFT) stage utilizes a meticulously constructed high-quality Chain-of-Thought dataset (Expert-AD) for training, enhancing anomaly perception capabilities and establishing reasoning-to-answer correlations; the Structured Control Group Relative Policy Optimization (SC-GRPO) stage employs carefully designed reward functions to achieve a capability leap from "Anomaly Perception" to "Anomaly Interpretation". Experimental results demonstrate that IAD-R1 achieves significant improvements across 7 VLMs, attaining up to 43.3% enhancement in average accuracy on 6 industrial anomaly detection benchmark datasets. Notably, the 0.5B parameter model trained with IAD-R1 surpasses commercial models including GPT-4.1 and Claude-Sonnet-4 in zero-shot settings, demonstrating the effectiveness and superiority of IAD-R1. The dataset, code, and all model weights will be publicly available at this https URL.', 'abstract_zh': '工业异常检测是现代制造的关键组件，但由于缺陷样本的稀缺性限制了传统检测方法的应用场景。尽管视觉-语言模型（VLMs）在泛化能力方面表现出显著的优势，但在工业异常检测中的性能仍然有限。为了解决这一挑战，我们提出了一种名为IAD-R1的通用后训练框架，适用于不同架构和参数规模的VLMs，显著提高了其异常检测能力。IAD-R1采用两阶段训练策略：感知激活监督微调（PA-SFT）阶段利用精心构建的高质量Chain-of-Thought数据集（Expert-AD）进行训练，增强异常感知能力并建立推理与答案的关联；结构化控制组相对策略优化（SC-GRPO）阶段采用精心设计的奖励函数，实现从“异常感知”到“异常解释”的能力飞跃。实验结果表明，IAD-R1在7种VLMs上取得了显著改进，在6个工业异常检测基准数据集上平均准确性提高了43.3%。值得注意的是，使用IAD-R1训练的0.5B参数模型在零样本设置中优于包括GPT-4.1和Claude-Sonnet-4在内的商业模型，证明了IAD-R1的有效性和优越性。该数据集、代码和所有模型权重将在以下网址公开。', 'title_zh': 'III-R 强化一致推理在工业异常检测中的应用'}
{'arxiv_id': 'arXiv:2508.09177', 'title': 'Generative Artificial Intelligence in Medical Imaging: Foundations, Progress, and Clinical Translation', 'authors': 'Xuanru Zhou, Cheng Li, Shuqiang Wang, Ye Li, Tao Tan, Hairong Zheng, Shanshan Wang', 'link': 'https://arxiv.org/abs/2508.09177', 'abstract': 'Generative artificial intelligence (AI) is rapidly transforming medical imaging by enabling capabilities such as data synthesis, image enhancement, modality translation, and spatiotemporal modeling. This review presents a comprehensive and forward-looking synthesis of recent advances in generative modeling including generative adversarial networks (GANs), variational autoencoders (VAEs), diffusion models, and emerging multimodal foundation architectures and evaluates their expanding roles across the clinical imaging continuum. We systematically examine how generative AI contributes to key stages of the imaging workflow, from acquisition and reconstruction to cross-modality synthesis, diagnostic support, and treatment planning. Emphasis is placed on both retrospective and prospective clinical scenarios, where generative models help address longstanding challenges such as data scarcity, standardization, and integration across modalities. To promote rigorous benchmarking and translational readiness, we propose a three-tiered evaluation framework encompassing pixel-level fidelity, feature-level realism, and task-level clinical relevance. We also identify critical obstacles to real-world deployment, including generalization under domain shift, hallucination risk, data privacy concerns, and regulatory hurdles. Finally, we explore the convergence of generative AI with large-scale foundation models, highlighting how this synergy may enable the next generation of scalable, reliable, and clinically integrated imaging systems. By charting technical progress and translational pathways, this review aims to guide future research and foster interdisciplinary collaboration at the intersection of AI, medicine, and biomedical engineering.', 'abstract_zh': '生成型人工智能（AI）正在通过使能数据合成、图像增强、时序建模等功能迅速变革医学影像领域。本文综述了生成型建模领域的近期进展，包括生成型对抗网络（GANs）、变分自动编码器（VAEs）、扩散模型等等，并新兴的多模态基础架构，并评估了生成型 AI 在临床影像连续统中的不断拓展角色。我们系统性地探讨了生成型 AI 如何贯穿于影像工作流中的关键步骤，包括采集与重建、多模态合成、辅助诊断、治疗规划等。特别强调了回顾性和前瞻性临床场景中生成型模型如何应对长久以来的挑战，如如 scarcity of standardization data across modalities and integration 的稀缺性标准标记数据及模态集成方面的困难与前景。我们提倡制定了一个包含像素级保真度、特征层面的真实性和任务级临床相关性的三层评估框架，并还 identified key challenges to real-world deployment 包括普遍性性的域下转移、错觉生成、隐私关切与监管障碍。最后，，我们提出了生成型 AI 与大基预模型的融合可能会促成可下一代可可、可靠且临床集成的影像系统。通过突显技术进步与转化路径，本文旨在推动未来研究和促进人工智能与生物医药工程的跨学科合作。', 'title_zh': '医学成像中的生成型人工智能：基础、进展与临床转化'}
{'arxiv_id': 'arXiv:2508.09176', 'title': 'DQT: Dynamic Quantization Training via Dequantization-Free Nested Integer Arithmetic', 'authors': 'Hazem Hesham Yousef Shalby, Fabrizio Pittorino, Francesca Palermo, Diana Trojaniello, Manuel Roveri', 'link': 'https://arxiv.org/abs/2508.09176', 'abstract': 'The deployment of deep neural networks on resource-constrained devices relies on quantization. While static, uniform quantization applies a fixed bit-width to all inputs, it fails to adapt to their varying complexity. Dynamic, instance-based mixed-precision quantization promises a superior accuracy-efficiency trade-off by allocating higher precision only when needed. However, a critical bottleneck remains: existing methods require a costly dequantize-to-float and requantize-to-integer cycle to change precision, breaking the integer-only hardware paradigm and compromising performance gains. This paper introduces Dynamic Quantization Training (DQT), a novel framework that removes this bottleneck. At the core of DQT is a nested integer representation where lower-precision values are bit-wise embedded within higher-precision ones. This design, coupled with custom integer-only arithmetic, allows for on-the-fly bit-width switching through a near-zero-cost bit-shift operation. This makes DQT the first quantization framework to enable both dequantization-free static mixed-precision of the backbone network, and truly efficient dynamic, instance-based quantization through a lightweight controller that decides at runtime how to quantize each layer. We demonstrate DQT state-of-the-art performance on ResNet18 on CIFAR-10 and ResNet50 on ImageNet. On ImageNet, our 4-bit dynamic ResNet50 achieves 77.00% top-1 accuracy, an improvement over leading static (LSQ, 76.70%) and dynamic (DQNET, 76.94%) methods at a comparable BitOPs budget. Crucially, DQT achieves this with a bit-width transition cost of only 28.3M simple bit-shift operations, a drastic improvement over the 56.6M costly Multiply-Accumulate (MAC) floating-point operations required by previous dynamic approaches - unlocking a new frontier in efficient, adaptive AI.', 'abstract_zh': '基于动态量化的深度神经网络在资源受限设备上的部署依赖于量化的应用。虽然静态均匀量化对所有输入应用固定的位宽，但它无法适应输入的不同复杂度。基于实例的动态混合精度量化通过仅在需要时分配更高精度，承诺了更好的准确率-效率 trade-off。然而，一个关键瓶颈仍然存在：现有方法需要一个昂贵的去量化的浮点数和重新量化的整数循环来改变精度，打破了纯整数硬件的范式并损害了性能的提升。本文引入了动态量化训练（DQT）这一新颖框架，消除了这一瓶颈。DQT的核心在于嵌套的整数表示，其中较低精度的值以位级嵌入到较高精度值中。这种设计结合自定义的纯整数算术，通过近乎零成本的位移操作实现了即席的位宽切换。这使DQT成为第一个既能实现不需要去量化的静态混合精度主干网络，又能通过轻量级控制器在运行时决定如何量化每一层，从而实现真正高效的动态、基于实例的量化的量化框架。我们在CIFAR-10上使用ResNet18和ImageNet上使用ResNet50展示了DQT的最新性能。在ImageNet上，我们的4位动态ResNet50达到了77.00%的top-1准确率，相比可比的位操作预算下的领先静态方法（LSQ，76.70%）和动态方法（DQNET，76.94%），均有所提升。最关键的是，DQT仅需28.3百万简单的位移操作的位宽转换成本，相较于之前动态方法所需的56.6百万昂贵的乘累加（MAC）浮点操作，这是一个巨大的改进，开启了高效、自适应AI的新前沿。', 'title_zh': '动态量化训练通过去量化嵌套整数算术实现（DQT）'}
{'arxiv_id': 'arXiv:2508.09175', 'title': 'A Context-aware Attention and Graph Neural Network-based Multimodal Framework for Misogyny Detection', 'authors': 'Mohammad Zia Ur Rehman, Sufyaan Zahoor, Areeb Manzoor, Musharaf Maqbool, Nagendra Kumar', 'link': 'https://arxiv.org/abs/2508.09175', 'abstract': 'A substantial portion of offensive content on social media is directed towards women. Since the approaches for general offensive content detection face a challenge in detecting misogynistic content, it requires solutions tailored to address offensive content against women. To this end, we propose a novel multimodal framework for the detection of misogynistic and sexist content. The framework comprises three modules: the Multimodal Attention module (MANM), the Graph-based Feature Reconstruction Module (GFRM), and the Content-specific Features Learning Module (CFLM). The MANM employs adaptive gating-based multimodal context-aware attention, enabling the model to focus on relevant visual and textual information and generating contextually relevant features. The GFRM module utilizes graphs to refine features within individual modalities, while the CFLM focuses on learning text and image-specific features such as toxicity features and caption features. Additionally, we curate a set of misogynous lexicons to compute the misogyny-specific lexicon score from the text. We apply test-time augmentation in feature space to better generalize the predictions on diverse inputs. The performance of the proposed approach has been evaluated on two multimodal datasets, MAMI and MMHS150K, with 11,000 and 13,494 samples, respectively. The proposed method demonstrates an average improvement of 10.17% and 8.88% in macro-F1 over existing methods on the MAMI and MMHS150K datasets, respectively.', 'abstract_zh': '社交媒体中针对女性的仇恨内容占据相当一部分。由于常规的仇恨内容检测方法在检测厌女内容方面面临挑战，需要专门针对针对女性的仇恨内容开发解决方案。基于此，我们提出了一种新颖的多模态框架，用于检测厌女和性别歧视内容。该框架包括三个模块：多模态注意力模块（MANM）、图-based 特征重构模块（GFRM）和内容特异性特征学习模块（CFLM）。MANM 使用自适应门控机制的多模态上下文感知注意力，使模型能够集中于相关视觉和文本信息，并生成上下文相关特征。GFRM 模块利用图来细化各个模态内的特征，而 CFLM 则专注于学习文本和图像特异性特征，如攻击性特征和描述特征。此外，我们收集了一组厌女词汇集，以从文本中计算出厌女特定的词汇分值。我们在特征空间应用测试时增强技术，以更好地泛化不同输入的预测。提出的办法在 MAMI 和 MMHS150K 两个多模态数据集上的性能进行了评估，分别包含 11,000 和 13,494 个样本。该方法在 MAMI 和 MMHS150K 数据集上分别在宏 F1 分数上比现有方法提高了 10.17% 和 8.88%。', 'title_zh': '基于上下文感知注意力和图神经网络的多模态误 ActionTypes检测框架'}
{'arxiv_id': 'arXiv:2508.09174', 'title': 'FedMP: Tackling Medical Feature Heterogeneity in Federated Learning from a Manifold Perspective', 'authors': 'Zhekai Zhou, Shudong Liu, Zhaokun Zhou, Yang Liu, Qiang Yang, Yuesheng Zhu, Guibo Luo', 'link': 'https://arxiv.org/abs/2508.09174', 'abstract': "Federated learning (FL) is a decentralized machine learning paradigm in which multiple clients collaboratively train a shared model without sharing their local private data. However, real-world applications of FL frequently encounter challenges arising from the non-identically and independently distributed (non-IID) local datasets across participating clients, which is particularly pronounced in the field of medical imaging, where shifts in image feature distributions significantly hinder the global model's convergence and performance. To address this challenge, we propose FedMP, a novel method designed to enhance FL under non-IID scenarios. FedMP employs stochastic feature manifold completion to enrich the training space of individual client classifiers, and leverages class-prototypes to guide the alignment of feature manifolds across clients within semantically consistent subspaces, facilitating the construction of more distinct decision boundaries. We validate the effectiveness of FedMP on multiple medical imaging datasets, including those with real-world multi-center distributions, as well as on a multi-domain natural image dataset. The experimental results demonstrate that FedMP outperforms existing FL algorithms. Additionally, we analyze the impact of manifold dimensionality, communication efficiency, and privacy implications of feature exposure in our method.", 'abstract_zh': '联邦学习（FL）是多个客户端在不共享本地私有数据的情况下协作训练共享模型的一种去中心化机器学习范式。然而，实际应用中的FL经常遇到由参与者客户端之间非同分布（non-IID）本地数据集引起的问题，特别是在医学成像领域，图像特征分布的变化严重影响全局模型的收敛性和性能。为应对这一挑战，我们提出了FedMP，一种在非-IID场景下增强联邦学习的新方法。FedMP利用随机特征流形完成来丰富个体客户端分类器的训练空间，并利用类原型引导客户端间特征流形在语义一致子空间内的对齐，促进决策边界的构建。我们在多个医学成像数据集上验证了FedMP的有效性，包括包含真实多中心分布的数据集，以及多域自然图像数据集。实验结果表明，FedMP在多个数据集上性能优于现有联邦学习算法。此外，我们分析了流形维度、通信效率和特征暴露对隐私的影响。', 'title_zh': 'FedMP: 从流形视角解决联邦学习中医疗特征异质性问题'}
{'arxiv_id': 'arXiv:2508.09171', 'title': 'webMCP: Efficient AI-Native Client-Side Interaction for Agent-Ready Web Design', 'authors': 'D. Perera', 'link': 'https://arxiv.org/abs/2508.09171', 'abstract': 'Current AI agents create significant barriers for users by requiring extensive processing to understand web pages, making AI-assisted web interaction slow and expensive. This paper introduces webMCP (Web Machine Context & Procedure), a client-side standard that embeds structured interaction metadata directly into web pages, enabling more efficient human-AI collaboration on existing websites. webMCP transforms how AI agents understand web interfaces by providing explicit mappings between page elements and user actions. Instead of processing entire HTML documents, agents can access pre-structured interaction data, dramatically reducing computational overhead while maintaining task accuracy. A comprehensive evaluation across 1,890 real API calls spanning online shopping, authentication, and content management scenarios demonstrates webMCP reduces processing requirements by 67.6% while maintaining 97.9% task success rates compared to 98.8% for traditional approaches. Users experience significantly lower costs (34-63% reduction) and faster response times across diverse web interactions. Statistical analysis confirms these improvements are highly significant across multiple AI models. An independent WordPress deployment study validates practical applicability, showing consistent improvements across real-world content management workflows. webMCP requires no server-side modifications, making it deployable across millions of existing websites without technical barriers. These results establish webMCP as a viable solution for making AI web assistance more accessible and sustainable, addressing the critical gap between user interaction needs and AI computational requirements in production environments.', 'abstract_zh': '当前的AI代理通过要求大量处理以理解网页，为用户创建了显著的障碍，使得AI辅助的网页交互变得缓慢且昂贵。本文介绍了一种名为webMCP（Web Machine Context & Procedure）的客户端标准，该标准直接将结构化的交互元数据嵌入到网页中，从而在现有网站上促进更有效的真人-AI协作。webMCP通过提供页面元素与用户操作之间的显式映射，改变了AI代理理解网页界面的方式。相比处理整个HTML文档，代理可以访问预先结构化的交互数据，大大减少了计算开销同时保持任务准确性。在涵盖在线购物、身份验证和内容管理等各种场景的1,890个实际API调用的全面评估中，webMCP将处理需求减少了67.6%，同时保持了97.9%的任务成功率，而传统方法为98.8%。用户在不同类型的网页交互中体验到显著的成本降低（34-63%）和更快的响应时间。统计分析证实这些改进在多种AI模型中具有高度显著性。独立的WordPress部署研究验证了其实用性，展示了在实际内容管理工作流中的一致改进。webMCP无需服务器端修改，使其能够在数百万现有网站上部署而无需技术障碍。这些结果确立了webMCP作为让AI网络辅助更具可持续性和普及性的可行解决方案的地位，弥补了用户交互需求与生产环境中的AI计算要求之间的关键差距。', 'title_zh': 'WebMCP：高效的AI原生客户端交互以支持智能代理就绪的网页设计'}
{'arxiv_id': 'arXiv:2508.09170', 'title': 'Multimodal RAG Enhanced Visual Description', 'authors': 'Amit Kumar Jaiswal, Haiming Liu, Ingo Frommholz', 'link': 'https://arxiv.org/abs/2508.09170', 'abstract': 'Textual descriptions for multimodal inputs entail recurrent refinement of queries to produce relevant output images. Despite efforts to address challenges such as scaling model size and data volume, the cost associated with pre-training and fine-tuning remains substantial. However, pre-trained large multimodal models (LMMs) encounter a modality gap, characterised by a misalignment between textual and visual representations within a common embedding space. Although fine-tuning can potentially mitigate this gap, it is typically expensive and impractical due to the requirement for extensive domain-driven data. To overcome this challenge, we propose a lightweight training-free approach utilising Retrieval-Augmented Generation (RAG) to extend across the modality using a linear mapping, which can be computed efficiently. During inference, this mapping is applied to images embedded by an LMM enabling retrieval of closest textual descriptions from the training set. These textual descriptions, in conjunction with an instruction, cater as an input prompt for the language model to generate new textual descriptions. In addition, we introduce an iterative technique for distilling the mapping by generating synthetic descriptions via the language model facilitating optimisation for standard utilised image description measures. Experimental results on two benchmark multimodal datasets demonstrate significant improvements.', 'abstract_zh': '多模态输入的文字描述涉及对查询的递归 refinement 以生成相关输出图像。尽管在应对模型规模和数据量扩大的挑战方面做出了努力，但预训练和微调相关的成本仍然相当高。然而，预训练的大规模多模态模型（LMMs）遇到了模态差距的问题，即文本和视觉表示在共同嵌入空间中的不对齐。尽管微调可以潜在地缓解这一差距，但由于需要大量领域驱动的数据，通常代价高昂且 impractical。为克服这一挑战，我们提出了一种轻量级的无需训练的方法，利用检索增强生成（RAG）通过线性映射跨模态扩展，该映射可以高效计算。在推理时，该映射应用于由 LMM 编码的图像，以从训练集检索最近的文本描述。这些文本描述连同指令一起作为语言模型生成新文本描述的输入提示。此外，我们介绍了一种迭代技术，通过语言模型生成合成描述对映射进行蒸馏，以优化标准使用的图像描述度量。在两个基准多模态数据集上的实验结果显示出显著的改进。', 'title_zh': '多模态RAG增强视觉描述'}
{'arxiv_id': 'arXiv:2508.09163', 'title': 'Energy-Efficient Stochastic Computing (SC) Neural Networks for Internet of Things Devices With Layer-Wise Adjustable Sequence Length (ASL)', 'authors': 'Ziheng Wang, Pedro Reviriego, Farzad Niknia, Zhen Gao, Javier Conde, Shanshan Liu, Fabrizio Lombardi', 'link': 'https://arxiv.org/abs/2508.09163', 'abstract': 'Stochastic computing (SC) has emerged as an efficient low-power alternative for deploying neural networks (NNs) in resource-limited scenarios, such as the Internet of Things (IoT). By encoding values as serial bitstreams, SC significantly reduces energy dissipation compared to conventional floating-point (FP) designs; however, further improvement of layer-wise mixed-precision implementation for SC remains unexplored. This article introduces Adjustable Sequence Length (ASL), a novel scheme that applies mixed-precision concepts specifically to SC NNs. By introducing an operator-norm-based theoretical model, this article shows that truncation noise can cumulatively propagate through the layers by the estimated amplification factors. An extended sensitivity analysis is presented, using random forest (RF) regression to evaluate multilayer truncation effects and validate the alignment of theoretical predictions with practical network behaviors. To accommodate different application scenarios, this article proposes two truncation strategies (coarse-grained and fine-grained), which apply diverse sequence length configurations at each layer. Evaluations on a pipelined SC MLP synthesized at 32nm demonstrate that ASL can reduce energy and latency overheads by up to over 60% with negligible accuracy loss. It confirms the feasibility of the ASL scheme for IoT applications and highlights the distinct advantages of mixed-precision truncation in SC designs.', 'abstract_zh': '基于 stochastic 计算 (SC) 的神经网络 (NN) 在物联网 (IoT) 等资源受限场景中的高效低功耗替代方案：Adjustable Sequence Length (ASL) 的探索', 'title_zh': '面向物联网设备的分层可调序列长度的节能随机计算神经网络'}
{'arxiv_id': 'arXiv:2508.09161', 'title': 'Physics-Guided Memory Network for Building Energy Modeling', 'authors': 'Muhammad Umair Danish, Kashif Ali, Kamran Siddiqui, Katarina Grolinger', 'link': 'https://arxiv.org/abs/2508.09161', 'abstract': 'Accurate energy consumption forecasting is essential for efficient resource management and sustainability in the building sector. Deep learning models are highly successful but struggle with limited historical data and become unusable when historical data are unavailable, such as in newly constructed buildings. On the other hand, physics-based models, such as EnergyPlus, simulate energy consumption without relying on historical data but require extensive building parameter specifications and considerable time to model a building. This paper introduces a Physics-Guided Memory Network (PgMN), a neural network that integrates predictions from deep learning and physics-based models to address their limitations. PgMN comprises a Parallel Projection Layers to process incomplete inputs, a Memory Unit to account for persistent biases, and a Memory Experience Module to optimally extend forecasts beyond their input range and produce output. Theoretical evaluation shows that components of PgMN are mathematically valid for performing their respective tasks. The PgMN was evaluated on short-term energy forecasting at an hourly resolution, critical for operational decision-making in smart grid and smart building systems. Experimental validation shows accuracy and applicability of PgMN in diverse scenarios such as newly constructed buildings, missing data, sparse historical data, and dynamic infrastructure changes. This paper provides a promising solution for energy consumption forecasting in dynamic building environments, enhancing model applicability in scenarios where historical data are limited or unavailable or when physics-based models are inadequate.', 'abstract_zh': '基于物理约束的内存网络在建筑动态环境中的能源消耗预测', 'title_zh': '基于物理引导的记忆网络 Buildings能耗建模'}
{'arxiv_id': 'arXiv:2508.09159', 'title': 'Agoran: An Agentic Open Marketplace for 6G RAN Automation', 'authors': 'Ilias Chatzistefanidis, Navid Nikaein, Andrea Leone, Ali Maatouk, Leandros Tassioulas, Roberto Morabito, Ioannis Pitsiorlas, Marios Kountouris', 'link': 'https://arxiv.org/abs/2508.09159', 'abstract': "Next-generation mobile networks must reconcile the often-conflicting goals of multiple service owners. However, today's network slice controllers remain rigid, policy-bound, and unaware of the business context. We introduce Agoran Service and Resource Broker (SRB), an agentic marketplace that brings stakeholders directly into the operational loop. Inspired by the ancient Greek agora, Agoran distributes authority across three autonomous AI branches: a Legislative branch that answers compliance queries using retrieval-augmented Large Language Models (LLMs); an Executive branch that maintains real-time situational awareness through a watcher-updated vector database; and a Judicial branch that evaluates each agent message with a rule-based Trust Score, while arbitrating LLMs detect malicious behavior and apply real-time incentives to restore trust. Stakeholder-side Negotiation Agents and the SRB-side Mediator Agent negotiate feasible, Pareto-optimal offers produced by a multi-objective optimizer, reaching a consensus intent in a single round, which is then deployed to Open and AI RAN controllers. Deployed on a private 5G testbed and evaluated with realistic traces of vehicle mobility, Agoran achieved significant gains: (i) a 37% increase in throughput of eMBB slices, (ii) a 73% reduction in latency of URLLC slices, and concurrently (iii) an end-to-end 8.3% saving in PRB usage compared to a static baseline. An 1B-parameter Llama model, fine-tuned for five minutes on 100 GPT-4 dialogues, recovers approximately 80% of GPT-4.1's decision quality, while operating within 6 GiB of memory and converging in only 1.3 seconds. These results establish Agoran as a concrete, standards-aligned path toward ultra-flexible, stakeholder-centric 6G networks. A live demo is presented this https URL\\&ab_channel=BubbleRAN.", 'abstract_zh': '下一代移动网络必须调和多位服务拥有者之间的经常相悖的目标。当前的网络切片控制器仍然僵化、受策略限制，并不了解商业背景。我们引入Agoran服务和资源经纪人（SRB），这是一种代理市场，将所有相关方直接纳入运营循环中。受古希腊阿哥拉的启发，Agoran分布授权给三个自主的人工智能分支：立法分支使用检索增强的大语言模型（LLMs）回答合规查询；执行分支通过观察者更新的向量数据库保持实时的态势感知；司法分支根据基于规则的信任评分评估每个代理的消息，并仲裁LLMs检测恶意行为，以实时应用激励措施恢复信任。所有者方谈判代理和SRB侧调解代理谈判由多目标优化器生成的可行的帕累托有效要约，在一轮中达成一致意图，然后部署到开源及AI RAN控制器。部署在私有5G试验床并在真实的车辆移动实时跟踪中评估，Agoran实现了显著的改进：（i）eMBB切片吞吐量提高了37%，（ii）URLLC切片延迟降低了73%，同时（iii）端到端PRB使用量节省了8.3%相较于静态基准。10亿参数量的Llama模型，在五分钟后针对100场GPT-4对话进行微调，恢复了大约80%的GPT-4.1的决策质量，在6 GiB内存下运行，并在1.3秒内收敛。这些结果确立了Agoran作为超灵活、以所有者为中心的6G网络具体且符合标准路径的地位。详细的现场演示请访问此处：[此链接]。', 'title_zh': 'Agoran: 6G RAN自动化的一种自主开放市场平台'}
{'arxiv_id': 'arXiv:2508.09158', 'title': 'EvaDrive: Evolutionary Adversarial Policy Optimization for End-to-End Autonomous Driving', 'authors': 'Siwen Jiao, Kangan Qian, Hao Ye, Yang Zhong, Ziang Luo, Sicong Jiang, Zilin Huang, Yangyi Fang, Jinyu Miao, Zheng Fu, Yunlong Wang, Kun Jiang, Diange Yang, Rui Fan, Baoyun Peng', 'link': 'https://arxiv.org/abs/2508.09158', 'abstract': 'Autonomous driving faces significant challenges in achieving human-like iterative decision-making, which continuously generates, evaluates, and refines trajectory proposals. Current generation-evaluation frameworks isolate trajectory generation from quality assessment, preventing iterative refinement essential for planning, while reinforcement learning methods collapse multi-dimensional preferences into scalar rewards, obscuring critical trade-offs and yielding scalarization this http URL overcome these issues, we present EvaDrive, a novel multi-objective reinforcement learning framework that establishes genuine closed-loop co-evolution between trajectory generation and evaluation via adversarial optimization. EvaDrive frames trajectory planning as a multi-round adversarial game. In this game, a hierarchical generator continuously proposes candidate paths by combining autoregressive intent modeling for temporal causality with diffusion-based refinement for spatial flexibility. These proposals are then rigorously assessed by a trainable multi-objective critic that explicitly preserves diverse preference structures without collapsing them into a single scalarization this http URL adversarial interplay, guided by a Pareto frontier selection mechanism, enables iterative multi-round refinement, effectively escaping local optima while preserving trajectory this http URL experiments on NAVSIM and Bench2Drive benchmarks demonstrate SOTA performance, achieving 94.9 PDMS on NAVSIM v1 (surpassing DiffusionDrive by 6.8, DriveSuprim by 5.0, and TrajHF by 0.9) and 64.96 Driving Score on Bench2Drive. EvaDrive generates diverse driving styles via dynamic weighting without external preference data, introducing a closed-loop adversarial framework for human-like iterative decision-making, offering a novel scalarization-free trajectory optimization approach.', 'abstract_zh': '自主驾驶在实现类人类的迭代决策方面面临重大挑战，这需要不断生成、评估和改进轨迹提案。当前的生成-评估框架将轨迹生成与质量评估隔离，阻碍了规划中必不可少的迭代细化。而强化学习方法将多维偏好压缩为单一标量奖励，模糊了关键权衡，导致标量化。为解决这些问题，我们提出了EvaDrive，一种新颖的多目标强化学习框架，通过对抗优化在轨迹生成和评估之间建立真实的闭环共进化。EvaDrive将轨迹规划框架化为多轮对抗游戏。在此游戏中，层次生成器通过结合自回归意图建模来实现时间因果性，结合基于扩散的精细调整来实现空间灵活性，不断提出候选路径。这些提案然后由可训练的多目标批评家严格评估，后者明确保留了多样的偏好结构，而不会将其压缩成单一标量化。这一对抗互动，由帕累托前沿选择机制引导，实现迭代多轮细化，有效逃脱局部最优解，同时保留轨迹。在NAVSIM和Bench2Drive基准测试上的实验展示了SOTA性能，其中EvaDrive在NAVSIM v1上的PDMS得分为94.9（超越DiffusionDrive 6.8、DriveSuprim 5.0和TrajHF 0.9），Bench2Drive上的驾驶得分为64.96。EvaDrive通过动态权重生成多样化的驾驶风格，无需外部偏好数据，引入了一种闭环对抗框架，用于类人的迭代决策，提供了一种无标量化轨迹优化的新方法。', 'title_zh': 'EvaDrive: 进化对抗策略优化在端到端自动驾驶中的应用'}
{'arxiv_id': 'arXiv:2508.09156', 'title': 'Physics-Constrained Fine-Tuning of Flow-Matching Models for Generation and Inverse Problems', 'authors': 'Jan Tauberschmidt, Sophie Fellenz, Sebastian J. Vollmer, Andrew B. Duncan', 'link': 'https://arxiv.org/abs/2508.09156', 'abstract': 'We present a framework for fine-tuning flow-matching generative models to enforce physical constraints and solve inverse problems in scientific systems. Starting from a model trained on low-fidelity or observational data, we apply a differentiable post-training procedure that minimizes weak-form residuals of governing partial differential equations (PDEs), promoting physical consistency and adherence to boundary conditions without distorting the underlying learned distribution. To infer unknown physical inputs, such as source terms, material parameters, or boundary data, we augment the generative process with a learnable latent parameter predictor and propose a joint optimization strategy. The resulting model produces physically valid field solutions alongside plausible estimates of hidden parameters, effectively addressing ill-posed inverse problems in a data-driven yet physicsaware manner. We validate our method on canonical PDE benchmarks, demonstrating improved satisfaction of PDE constraints and accurate recovery of latent coefficients. Our approach bridges generative modelling and scientific inference, opening new avenues for simulation-augmented discovery and data-efficient modelling of physical systems.', 'abstract_zh': '我们提出了一种 fine-tuning 流匹配生成模型的框架，以施加物理约束并解决科学系统中的逆问题。从低保真度或观测数据训练的模型出发，我们应用了一个可微的后训练程序，最小化控制方程（PDEs）的弱形式残差，促进物理一致性并遵守边界条件而不扭曲底层学习的分布。为推断未知的物理输入，如源项、材料参数或边界数据，我们通过可学习的潜在参数预测器扩展生成过程，并提出了一种联合优化策略。由此产生的模型不仅生成了物理有效的场解，还给出了潜在参数的合理估计，以数据驱动且物理感知的方式有效解决了病态逆问题。我们在经典的 PDE 标准测试上验证了该方法，展示了对 PDE 约束的更好满足以及对潜在系数的准确恢复。我们的方法将生成建模与科学推断相结合，为基于模拟的发现和物理系统的数据高效建模开辟了新途径。', 'title_zh': '基于物理约束的流匹配模型微调方法及其在生成和逆问题中的应用'}
{'arxiv_id': 'arXiv:2508.09155', 'title': 'A Rolling Stone Gathers No Moss: Adaptive Policy Optimization for Stable Self-Evaluation in Large Multimodal Models', 'authors': 'Wenkai Wang, Hongcan Guo, Zheqi Lv, Shengyu Zhang', 'link': 'https://arxiv.org/abs/2508.09155', 'abstract': "Self-evaluation, a model's ability to assess the correctness of its own output, is crucial for Large Multimodal Models (LMMs) to achieve self-improvement in multi-turn conversations, yet largely absent in foundation models. Recent work has employed reinforcement learning (RL) to enhance self-evaluation; however, its fixed reward mechanism suffers from reward hacking when optimizing multiple training objectives, leading to model collapse. In this paper we propose AdaPO, an online reinforcement learning framework capable of adaptively adjusting training objective in real time according to the current training state for each task. Specifically, to mitigate reward hacking , AdaPO introduces an Adaptive Reward Model (ARM) and a Reward Aware Dynamic KL Regularization mechanism. ARM assesses the task's training state from the distribution of model generated multi-turn trajectories' performance. Reward Aware Dynamic KL replaces a fixed penalty with dynamic coefficients which is modulated by the reward gap between different multi-turn situations. Notably, our method automatically and smoothly adjusts its learning focus based on sub-tasks' training progress without manual intervention. Extensive experiments over 8 benchmarks and various models show that our method significantly enhances both direct reasoning and self-evaluation capability. We will release our code to contribute to the community.", 'abstract_zh': '自评估：一种大型多模态模型在多轮对话中实现自我改进的关键能力，但基础模型中普遍缺乏。近期工作利用强化学习增强自评估，但由于其固定奖励机制在优化多种训练目标时容易导致奖励 hacking，导致模型崩溃。本文提出 AdaPO，一种能够根据当前训练状态实时自适应调整训练目标的在线强化学习框架。具体而言，为了减轻奖励 hacking，AdaPO 引入了自适应奖励模型（ARM）和奖励感知动态 KL 正则化机制。ARM 通过对模型生成的多轮轨迹性能分布进行评估来判断任务的训练状态。奖励感知动态 KL 用动态系数替代固定惩罚，这些系数由不同多轮情境间的奖励差距调节。值得注意的是，我们的方法能够根据子任务的训练进度自动且平滑地调整其学习重点，无需手动干预。在 8 个基准和多种模型上的广泛实验表明，我们的方法显著提高了直接推理和自评估能力。我们将发布代码以贡献给社区。', 'title_zh': '一块滚动的石头不会长苔藓：自适应策略优化以在大型多模态模型中实现稳定自评估'}
{'arxiv_id': 'arXiv:2508.09154', 'title': 'Peer Effect Estimation in the Presence of Simultaneous Feedback and Unobserved Confounders', 'authors': 'Xiaojing Du, Jiuyong Li, Lin Liu, Debo Cheng, Thuc.Le', 'link': 'https://arxiv.org/abs/2508.09154', 'abstract': 'Estimating peer causal effects within complex real-world networks such as social networks is challenging, primarily due to simultaneous feedback between peers and unobserved confounders. Existing methods either address unobserved confounders while ignoring the simultaneous feedback, or account for feedback but under restrictive linear assumptions, thus failing to obtain accurate peer effect estimation. In this paper, we propose DIG2RSI, a novel Deep learning framework which leverages I-G transformation (matrix operation) and 2SRI (an instrumental variable or IV technique) to address both simultaneous feedback and unobserved confounding, while accommodating complex, nonlinear and high-dimensional relationships. DIG2RSI first applies the I-G transformation to disentangle mutual peer influences and eliminate the bias due to the simultaneous feedback. To deal with unobserved confounding, we first construct valid IVs from network data. In stage 1 of 2RSI, we train a neural network on these IVs to predict peer exposure, and extract residuals as proxies for the unobserved confounders. In the stage 2, we fit a separate neural network augmented by an adversarial discriminator that incorporates these residuals as a control function and enforces the learned representation to contain no residual confounding signal. The expressive power of deep learning models in capturing complex non-linear relationships and adversarial debiasing enhances the effectiveness of DIG2RSI in eliminating bias from both feedback loops and hidden confounders. We prove consistency of our estimator under standard regularity conditions, ensuring asymptotic recovery of the true peer effect. Empirical results on two semi-synthetic benchmarks and a real-world dataset demonstrate that DIG2RSI outperforms existing approaches.', 'abstract_zh': '利用I-G变换和双重工具变量的深度学习框架DIG2RSI：同时解决同时反馈和未观测混杂因素以估计同伴效应', 'title_zh': '同时反馈和未观测混杂因素下的同伴效应估计'}
{'arxiv_id': 'arXiv:2508.09153', 'title': 'JustDense: Just using Dense instead of Sequence Mixer for Time Series analysis', 'authors': 'TaekHyun Park, Yongjae Lee, Daesan Park, Dohee Kim, Hyerim Bae', 'link': 'https://arxiv.org/abs/2508.09153', 'abstract': 'Sequence and channel mixers, the core mechanism in sequence models, have become the de facto standard in time series analysis (TSA). However, recent studies have questioned the necessity of complex sequence mixers, such as attention mechanisms, demonstrating that simpler architectures can achieve comparable or even superior performance. This suggests that the benefits attributed to complex sequencemixers might instead emerge from other architectural or optimization factors. Based on this observation, we pose a central question: Are common sequence mixers necessary for time-series analysis? Therefore, we propose JustDense, an empirical study that systematically replaces sequence mixers in various well-established TSA models with dense layers. Grounded in the MatrixMixer framework, JustDense treats any sequence mixer as a mixing matrix and replaces it with a dense layer. This substitution isolates the mixing operation, enabling a clear theoretical foundation for understanding its role. Therefore, we conducted extensive experiments on 29 benchmarks covering five representative TSA tasks using seven state-of-the-art TSA models to address our research question. The results show that replacing sequence mixers with dense layers yields comparable or even superior performance. In the cases where dedicated sequence mixers still offer benefits, JustDense challenges the assumption that "deeper and more complex architectures are inherently better" in TSA.', 'abstract_zh': '序列和和和 ChannelD D Mixers:: The D Mechanism in D D Sequential ModelsD: D TheD FactDH StandardD In in in In in in in in in inD TimeD-D SeriesD AnalysisD (TSASDA)D. HasDD BecomeD TheD De D DeD DefD DeD DeDD De DeDD DeD DeDDDDD DeDDDDDDDDDDDDDDDDDDDDDDDDD 最近近 近D 的D � 研究D 对 � 疑D 况D 了D � 复杂 杂 杂 处D 序D 序D � 混 � �激起D �D � 机DD � 例如 的D 必DD � � �layui 重要D 性D，， �DD。D �D。D 重要的DD 的DD 度D。D， 表DD 证DD � � 更D � 为DD 更D 简D 单DD D D 的D 架DD 当D �构DD 凩 在 叫DDD 得 优D �DD � 敯 佳D 的D 性T 性 性 昏 �志愿服务D 的DD 在D 性。 �迟D。D 性DD � � 昺D 。D 这 证DD  衎 际DD � 证DD  是 昷 证实DD D  附D D �D 了D 这D  复D 严DD 利DD 的DD  附DD  机D 度D � 本D 束 � 杜DD � �D 杵D 发DD  自D  的D 主D 杬归 凘 松D 李术D  杜D D �D  的D 影DDD 见D 。D  � � �况DD 迈D  证D  昧 证明DD D  �emicDD 结DD 的DD  隣D 庐DD �D � 机D 术测DD  为D 练D �D 得 �D 代字DD 表D �D D 的D �D � 活动D �D 有 进D 衎 了D  一D 个D 关DD  于D 新D � �D 关D �D � 问 问 问 � 问 � � 问 信DDDD 昑DDD 中D 问 �D 证据D 的DD  证DD，DD 春D 的DD 严D  条D 这D �痘痘D 杰D。  的D  右�D � � 证DD �DDD  为DD 了D 一种DD  新D 的DD 关D D 亊D  DD 亊D 度D 方D 法D 来DD  寜测量D 讘 D 代DD �D 代D D 衴DDD � 的DD  附 只 说D � 安D 当前的 的DD 亊DD 亊D 亊D 的DD  亊D 选择了D  亊D  恁 更D � 优化简化D 的DD  活动D 的D �DD 视角D 的DD  怀D 些DD 的DD  附 亢 �D 亟 � 亊D 亊D 二 必D � 的D D 亣 亟 � � 杶 亊D D 亊D 亁 争 注意D 注D 重视D 注意DD  浓D 浓D DD 浓D 重视D 的DD  争 D 亃D �D �  �性 杵D � 开 是D  亊D 亅D 亍D  �D �D 亠丿 亊D  亢 �D 亐D  亣 D  亐D 亙D D  亱 D  亐DD  亵D 亐DD  D  亐D  亊D D  亡D  亃亀 云D  五D  亖争 云DD  亢D  亦D D  亟D  亐D D。', 'title_zh': 'JustDense: 仅使用密集连接代替序列混合进行时间序列分析'}
{'arxiv_id': 'arXiv:2508.09152', 'title': '5G Core Fault Detection and Root Cause Analysis using Machine Learning and Generative AI', 'authors': 'Joseph H. R. Isaac, Harish Saradagam, Nallamothu Pardhasaradhi', 'link': 'https://arxiv.org/abs/2508.09152', 'abstract': 'With the advent of 5G networks and technologies, ensuring the integrity and performance of packet core traffic is paramount. During network analysis, test files such as Packet Capture (PCAP) files and log files will contain errors if present in the system that must be resolved for better overall network performance, such as connectivity strength and handover quality. Current methods require numerous person-hours to sort out testing results and find the faults. This paper presents a novel AI/ML-driven Fault Analysis (FA) Engine designed to classify successful and faulty frames in PCAP files, specifically within the 5G packet core. The FA engine analyses network traffic using natural language processing techniques to identify anomalies and inefficiencies, significantly reducing the effort time required and increasing efficiency. The FA Engine also suggests steps to fix the issue using Generative AI via a Large Language Model (LLM) trained on several 5G packet core documents. The engine explains the details of the error from the domain perspective using documents such as the 3GPP standards and user documents regarding the internal conditions of the tests. Test results on the ML models show high classification accuracy on the test dataset when trained with 80-20 splits for the successful and failed PCAP files. Future scopes include extending the AI engine to incorporate 4G network traffic and other forms of network data, such as log text files and multimodal systems.', 'abstract_zh': '随着5G网络技术的出现，确保包核心流量的完整性和性能至关重要。在网络分析过程中，如果测试文件如Packet Capture (PCAP)文件和日志文件中存在错误，必须解决这些问题以提高整体网络性能，例如连接强度和切换质量。当前方法需要投入大量人工小时来整理测试结果并找出故障。本文提出了一种新颖的AI/ML驱动故障分析（FA）引擎，用于在5G包核心中分类成功的和故障的帧。FA引擎利用自然语言处理技术分析网络流量，以识别异常和低效性，显著减少了所需的工作时间和提高了效率。该FA引擎还通过大型语言模型（LLM）生成AI，基于多个5G包核心文档，提供修复问题的步骤建议。引擎从3GPP标准和用户文档中解释测试内部条件的错误详情。在机器学习模型上的测试结果显示，在80-20分割训练集时，对成功和失败的PCAP文件具有高分类精度。未来的工作包括将AI引擎扩展以纳入4G网络流量和其他形式的网络数据，如日志文本文件和多模态系统。', 'title_zh': '基于机器学习和生成式AI的5G核心网故障检测与根因分析'}
{'arxiv_id': 'arXiv:2508.09148', 'title': 'Motif 2.6B Technical Report', 'authors': 'Junghwan Lim, Sungmin Lee, Dongseok Kim, Eunhwan Park, Hyunbyung Park, Junhyeok Lee, Wai Ting Cheung, Dahye Choi, Jaeheui Her, Jaeyeon Huh, Hanbin Jung, Changjin Kang, Beomgyu Kim, Jihwan Kim, Minjae Kim, Taehwan Kim, Youngrok Kim, Haesol Lee, Jeesoo Lee, Kungyu Lee, Dongpin Oh, Yeongjae Park, Bokki Ryu, Daewon Suh, Dongjoo Weon', 'link': 'https://arxiv.org/abs/2508.09148', 'abstract': 'Recent advancements in Large Language Models (LLMs) have revolutionized artificial intelligence, yet developing an effective foundational LLM that balances high performance with computational efficiency remains challenging, especially for emerging research groups. To address this gap, we introduce Motif-2.6B, a 2.6-billion-parameter foundation model designed to democratize advanced LLM capabilities. Motif-2.6B incorporates several innovative architectural enhancements, including Differential Attention and PolyNorm activation functions, which improve long-context comprehension, reduce hallucination, and enhance in-context learning capabilities. We rigorously tested multiple novel architectural components through extensive experimentation to determine the optimal architecture for Motif-2.6B. Comprehensive evaluations demonstrate that Motif-2.6B consistently meets or exceeds the performance of similarly sized state-of-the-art models across diverse benchmarks, showcasing its effectiveness, scalability, and real-world applicability. Through detailed experiments and tailored techniques, Motif-2.6B significantly advances the landscape of efficient, scalable, and powerful foundational LLMs, offering valuable insights and a robust foundation for future research and deployment.', 'abstract_zh': 'Recent Advancements in Large Language Models (LLMs) Have Revolutionized Artificial Intelligence, Yet Developing an Effective Foundational LLM That Balances High Performance with Computational Efficiency Remains Challenging, Especially for Emerging Research Groups. To Address This Gap, We Introduce Motif-2.6B, a 2.6-Billion-Parameter Foundation Model Designed to Democratize Advanced LLM Capabilities.', 'title_zh': 'Motif 2.6B 技术报告'}
{'arxiv_id': 'arXiv:2508.09147', 'title': 'Agentic TinyML for Intent-aware Handover in 6G Wireless Networks', 'authors': 'Alaa Saleh, Roberto Morabito, Sasu Tarkoma, Anders Lindgren, Susanna Pirttikangas, Lauri Lovén', 'link': 'https://arxiv.org/abs/2508.09147', 'abstract': "As 6G networks evolve into increasingly AI-driven, user-centric ecosystems, traditional reactive handover mechanisms demonstrate limitations, especially in mobile edge computing and autonomous agent-based service scenarios. This manuscript introduces WAAN, a cross-layer framework that enables intent-aware and proactive handovers by embedding lightweight TinyML agents as autonomous, negotiation-capable entities across heterogeneous edge nodes that contribute to intent propagation and network adaptation. To ensure continuity across mobility-induced disruptions, WAAN incorporates semi-stable rendezvous points that serve as coordination anchors for context transfer and state preservation. The framework's operational capabilities are demonstrated through a multimodal environmental control case study, highlighting its effectiveness in maintaining user experience under mobility. Finally, the article discusses key challenges and future opportunities associated with the deployment and evolution of WAAN.", 'abstract_zh': '随着6G网络向日益依赖AI、以用户为中心的生态系统发展，传统的反应式切换机制在移动边缘计算和基于自主代理的服务场景中显示出局限性。本文提出了WAAN，一种跨层框架，通过在网络异构边缘节点中嵌入轻量级TinyML代理作为自主且具备谈判能力的实体，实现意图感知和主动切换。为了确保在移动性中断时的连续性，WAAN整合了半稳定的中继点，作为上下文转移和状态保存的协调锚点。通过多模态环境控制案例研究展示了该框架的操作能力，突显了其在移动性影响下的用户体验保持效果。最后，本文讨论了WAAN部署和演化过程中的关键挑战和未来机遇。', 'title_zh': '代理型TinyML在6G无线网络中意图感知的手柄转移'}
{'arxiv_id': 'arXiv:2508.09146', 'title': 'To Theoretically Understand Transformer-Based In-Context Learning for Optimizing CSMA', 'authors': 'Shugang Hao, Hongbo Li, Lingjie Duan', 'link': 'https://arxiv.org/abs/2508.09146', 'abstract': "The binary exponential backoff scheme is widely used in WiFi 7 and still incurs poor throughput performance under dynamic channel environments. Recent model-based approaches (e.g., non-persistent and $p$-persistent CSMA) simply optimize backoff strategies under a known and fixed node density, still leading to a large throughput loss due to inaccurate node density estimation. This paper is the first to propose LLM transformer-based in-context learning (ICL) theory for optimizing channel access. We design a transformer-based ICL optimizer to pre-collect collision-threshold data examples and a query collision case. They are constructed as a prompt as the input for the transformer to learn the pattern, which then generates a predicted contention window threshold (CWT). To train the transformer for effective ICL, we develop an efficient algorithm and guarantee a near-optimal CWT prediction within limited training steps. As it may be hard to gather perfect data examples for ICL in practice, we further extend to allow erroneous data input in the prompt. We prove that our optimizer maintains minimal prediction and throughput deviations from the optimal values. Experimental results on NS-3 further demonstrate our approach's fast convergence and near-optimal throughput over existing model-based and DRL-based approaches under unknown node densities.", 'abstract_zh': '基于LLM变换器的上下文学习理论优化信道访问', 'title_zh': '理论上理解基于变压器的前瞻上下文学习以优化CSMA'}
{'arxiv_id': 'arXiv:2508.09144', 'title': 'Efficient Real-Time Aircraft ETA Prediction via Feature Tokenization Transformer', 'authors': 'Liping Huang, Yicheng Zhang, Yifang Yin, Sheng Zhang, Yi Zhang', 'link': 'https://arxiv.org/abs/2508.09144', 'abstract': "Estimated time of arrival (ETA) for airborne aircraft in real-time is crucial for arrival management in aviation, particularly for runway sequencing. Given the rapidly changing airspace context, the ETA prediction efficiency is as important as its accuracy in a real-time arrival aircraft management system. In this study, we utilize a feature tokenization-based Transformer model to efficiently predict aircraft ETA. Feature tokenization projects raw inputs to latent spaces, while the multi-head self-attention mechanism in the Transformer captures important aspects of the projections, alleviating the need for complex feature engineering. Moreover, the Transformer's parallel computation capability allows it to handle ETA requests at a high frequency, i.e., 1HZ, which is essential for a real-time arrival management system. The model inputs include raw data, such as aircraft latitude, longitude, ground speed, theta degree for the airport, day and hour from track data, the weather context, and aircraft wake turbulence category. With a data sampling rate of 1HZ, the ETA prediction is updated every second. We apply the proposed aircraft ETA prediction approach to Singapore Changi Airport (ICAO Code: WSSS) using one-month Automatic Dependent Surveillance-Broadcast (ADS-B) data from October 1 to October 31, 2022. In the experimental evaluation, the ETA modeling covers all aircraft within a range of 10NM to 300NM from WSSS. The results show that our proposed method method outperforms the commonly used boosting tree based model, improving accuracy by 7\\% compared to XGBoost, while requiring only 39\\% of its computing time. Experimental results also indicate that, with 40 aircraft in the airspace at a given timestamp, the ETA inference time is only 51.7 microseconds, making it promising for real-time arrival management systems.", 'abstract_zh': '基于特征 tokenization 的 Transformer 模型在实时航空器到达时间预测中的应用：以新加坡樟宜机场为例', 'title_zh': '基于特征标记变换器的高效实时航空器到港时间预测'}
{'arxiv_id': 'arXiv:2508.09142', 'title': 'Bayesian-Driven Graph Reasoning for Active Radio Map Construction', 'authors': 'Wenlihan Lu, Shijian Gao, Miaowen Wen, Yuxuan Liang, Chan-Byoung Chae, H. Vincent Poor', 'link': 'https://arxiv.org/abs/2508.09142', 'abstract': 'With the emergence of the low-altitude economy, radio maps have become essential for ensuring reliable wireless connectivity to aerial platforms. Autonomous aerial agents are commonly deployed for data collection using waypoint-based navigation; however, their limited battery capacity significantly constrains coverage and efficiency. To address this, we propose an uncertainty-aware radio map (URAM) reconstruction framework that explicitly leverages graph-based reasoning tailored for waypoint navigation. Our approach integrates two key deep learning components: (1) a Bayesian neural network that estimates spatial uncertainty in real time, and (2) an attention-based reinforcement learning policy that performs global reasoning over a probabilistic roadmap, using uncertainty estimates to plan informative and energy-efficient trajectories. This graph-based reasoning enables intelligent, non-myopic trajectory planning, guiding agents toward the most informative regions while satisfying safety constraints. Experimental results show that URAM improves reconstruction accuracy by up to 34% over existing baselines.', 'abstract_zh': '低空经济背景下，无线电图对于确保与空中平台的可靠无线连接变得至关重要。基于航点导航的自主空中代理通常用于数据采集，然而其有限的电池容量显著限制了覆盖范围和效率。为了解决这一问题，我们提出了一种不确定性意识无线电图（URAM）重建框架，该框架明确利用了适用于航点导航的图基推理。我们的方法整合了两个关键的深度学习组件：（1）一个贝叶斯神经网络，实时估计空间不确定性；（2）一种基于注意力的强化学习策略，在概率路网中进行全局推理，并使用不确定性估计来规划具有信息性和节能性的轨迹。这种图基推理使智能、非近视路线规划成为可能，引导代理向最有信息性区域导航，同时满足安全约束。实验结果显示，URAM在重建准确性上较现有基线提高了最多34%。', 'title_zh': '基于贝叶斯驱动的图推理的主动无线电图构建'}
{'arxiv_id': 'arXiv:2508.05884', 'title': 'User-Intent-Driven Semantic Communication via Adaptive Deep Understanding', 'authors': 'Peigen Ye, Jingpu Duan, Hongyang Du, Yulan Guo', 'link': 'https://arxiv.org/abs/2508.05884', 'abstract': "Semantic communication focuses on transmitting task-relevant semantic information, aiming for intent-oriented communication. While existing systems improve efficiency by extracting key semantics, they still fail to deeply understand and generalize users' real intentions. To overcome this, we propose a user-intention-driven semantic communication system that interprets diverse abstract intents. First, we integrate a multi-modal large model as semantic knowledge base to generate user-intention prior. Next, a mask-guided attention module is proposed to effectively highlight critical semantic regions. Further, a channel state awareness module ensures adaptive, robust transmission across varying channel conditions. Extensive experiments demonstrate that our system achieves deep intent understanding and outperforms DeepJSCC, e.g., under a Rayleigh channel at an SNR of 5 dB, it achieves improvements of 8%, 6%, and 19% in PSNR, SSIM, and LPIPS, respectively.", 'abstract_zh': '面向意图的语义通信系统研究：基于多元模态大模型的抽象意图解释与适应性鲁棒传输', 'title_zh': '基于用户意图的自适应深度语义通信'}
{'arxiv_id': 'arXiv:2504.19716', 'title': 'QuickGrasp: Lightweight Antipodal Grasp Planning with Point Clouds', 'authors': 'Navin Sriram Ravie, Keerthi Vasan M, Asokan Thondiyath, Bijo Sebastian', 'link': 'https://arxiv.org/abs/2504.19716', 'abstract': 'Grasping has been a long-standing challenge in facilitating the final interface between a robot and the environment. As environments and tasks become complicated, the need to embed higher intelligence to infer from the surroundings and act on them has become necessary. Although most methods utilize techniques to estimate grasp pose by treating the problem via pure sampling-based approaches in the six-degree-of-freedom space or as a learning problem, they usually fail in real-life settings owing to poor generalization across domains. In addition, the time taken to generate the grasp plan and the lack of repeatability, owing to sampling inefficiency and the probabilistic nature of existing grasp planning approaches, severely limits their application in real-world tasks. This paper presents a lightweight analytical approach towards robotic grasp planning, particularly antipodal grasps, with little to no sampling in the six-degree-of-freedom space. The proposed grasp planning algorithm is formulated as an optimization problem towards estimating grasp points on the object surface instead of directly estimating the end-effector pose. To this extent, a soft-region-growing algorithm is presented for effective plane segmentation, even in the case of curved surfaces. An optimization-based quality metric is then used for the evaluation of grasp points to ensure indirect force closure. The proposed grasp framework is compared with the existing state-of-the-art grasp planning approach, Grasp pose detection (GPD), as a baseline over multiple simulated objects. The effectiveness of the proposed approach in comparison to GPD is also evaluated in a real-world setting using image and point-cloud data, with the planned grasps being executed using a ROBOTIQ gripper and UR5 manipulator.', 'abstract_zh': '基于轻量级分析方法的六自由度空间少采样机器人抓取规划', 'title_zh': 'QuickGrasp: 基于点云的轻量级反抓取规划'}
