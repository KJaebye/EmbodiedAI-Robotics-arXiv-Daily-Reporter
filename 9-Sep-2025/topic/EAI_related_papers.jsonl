{'arxiv_id': 'arXiv:2509.06953', 'title': 'Deep Reactive Policy: Learning Reactive Manipulator Motion Planning for Dynamic Environments', 'authors': 'Jiahui Yang, Jason Jingzhou Liu, Yulong Li, Youssef Khaky, Kenneth Shaw, Deepak Pathak', 'link': 'https://arxiv.org/abs/2509.06953', 'abstract': "Generating collision-free motion in dynamic, partially observable environments is a fundamental challenge for robotic manipulators. Classical motion planners can compute globally optimal trajectories but require full environment knowledge and are typically too slow for dynamic scenes. Neural motion policies offer a promising alternative by operating in closed-loop directly on raw sensory inputs but often struggle to generalize in complex or dynamic settings. We propose Deep Reactive Policy (DRP), a visuo-motor neural motion policy designed for reactive motion generation in diverse dynamic environments, operating directly on point cloud sensory input. At its core is IMPACT, a transformer-based neural motion policy pretrained on 10 million generated expert trajectories across diverse simulation scenarios. We further improve IMPACT's static obstacle avoidance through iterative student-teacher finetuning. We additionally enhance the policy's dynamic obstacle avoidance at inference time using DCP-RMP, a locally reactive goal-proposal module. We evaluate DRP on challenging tasks featuring cluttered scenes, dynamic moving obstacles, and goal obstructions. DRP achieves strong generalization, outperforming prior classical and neural methods in success rate across both simulated and real-world settings. Video results and code available at this https URL", 'abstract_zh': '在动态部分可观测环境中超剐蹭自由运动生成是机器人 manipulator 的一个基本挑战。经典运动规划器可以计算全局最优轨迹，但需要完整环境信息且通常对于动态场景来说速度太慢。神经运动策略通过直接处理原始传感器输入提供了一种有前途的替代方案，但在复杂或动态环境中往往难以泛化。我们提出了 Deep Reactive Policy (DRP)，这是一种用于在多样动态环境中生成反应性运动的视觉-运动神经运动策略，直接处理点云传感器输入。其核心是 IMPACT，这是一种基于转换器的预训练神经运动策略，在包含各种模拟场景的 10 百万生成专家轨迹上进行预训练。我们进一步通过迭代的学生-教师微调增强了 IMPACT 的静态障碍物回避能力。我们还在推理时通过 DCP-RMP，一种局部反应性目标提议模块，增强了其对动态障碍物的回避能力。我们通过包括堆积场景、动态移动障碍物和目标障碍在内的挑战性任务评估了 DRP。DRP 在模拟和真实世界设置中均表现出强大的泛化能力，优于之前的经典和神经方法。视频结果和代码可在以下链接获取：this https URL。', 'title_zh': '深度反应策略：学习动态环境中的反应式 manipulator 运动规划'}
{'arxiv_id': 'arXiv:2509.06951', 'title': 'F1: A Vision-Language-Action Model Bridging Understanding and Generation to Actions', 'authors': 'Qi Lv, Weijie Kong, Hao Li, Jia Zeng, Zherui Qiu, Delin Qu, Haoming Song, Qizhi Chen, Xiang Deng, Jiangmiao Pang', 'link': 'https://arxiv.org/abs/2509.06951', 'abstract': 'Executing language-conditioned tasks in dynamic visual environments remains a central challenge in embodied AI. Existing Vision-Language-Action (VLA) models predominantly adopt reactive state-to-action mappings, often leading to short-sighted behaviors and poor robustness in dynamic scenes. In this paper, we introduce F1, a pretrained VLA framework which integrates the visual foresight generation into decision-making pipeline. F1 adopts a Mixture-of-Transformer architecture with dedicated modules for perception, foresight generation, and control, thereby bridging understanding, generation, and actions. At its core, F1 employs a next-scale prediction mechanism to synthesize goal-conditioned visual foresight as explicit planning targets. By forecasting plausible future visual states, F1 reformulates action generation as a foresight-guided inverse dynamics problem, enabling actions that implicitly achieve visual goals. To endow F1 with robust and generalizable capabilities, we propose a three-stage training recipe on an extensive dataset comprising over 330k trajectories across 136 diverse tasks. This training scheme enhances modular reasoning and equips the model with transferable visual foresight, which is critical for complex and dynamic environments. Extensive evaluations on real-world tasks and simulation benchmarks demonstrate F1 consistently outperforms existing approaches, achieving substantial gains in both task success rate and generalization ability.', 'abstract_zh': '在动态视觉环境中的语言条件任务执行仍然是嵌入式AI中的核心挑战。现有视觉-语言-动作（VLA）模型主要采用反应式的状态到动作映射，这常常导致短视行为并在动态场景中表现出较差的鲁棒性。在本文中，我们介绍了F1，这是一种预训练的VLA框架，将视觉前瞻生成集成到决策流程中。F1采用混合变换器架构，并专门设置了感知、前瞻生成和控制模块，从而实现理解和动作之间的衔接。F1的核心是采用下一尺度预测机制以合成目标条件下的视觉前瞻作为明确的规划目标。通过预测可能的未来视觉状态，F1将动作生成重新表述为由前瞻指导的逆动力学问题，使动作隐含地实现视觉目标。为使F1具备鲁棒性和可推广的能力，我们在包含超过33万条轨迹的广泛数据集上提出了一个三阶段的训练方案，涉及136种多样的任务。该训练方案增强了模块化推理，并使模型具备可转移的视觉前瞻能力，这对于复杂和动态的环境至关重要。在现实世界任务和仿真基准上的广泛评估表明，F1在任务成功率和通用性方面均显著优于现有方法。', 'title_zh': 'F1: 一种连接理解与生成到行动的视觉-语言-动作模型'}
{'arxiv_id': 'arXiv:2509.06768', 'title': 'Embodied Hazard Mitigation using Vision-Language Models for Autonomous Mobile Robots', 'authors': 'Oluwadamilola Sotomi, Devika Kodi, Kiruthiga Chandra Shekar, Aliasghar Arab', 'link': 'https://arxiv.org/abs/2509.06768', 'abstract': "Autonomous robots operating in dynamic environments should identify and report anomalies. Embodying proactive mitigation improves safety and operational continuity. This paper presents a multimodal anomaly detection and mitigation system that integrates vision-language models and large language models to identify and report hazardous situations and conflicts in real-time. The proposed system enables robots to perceive, interpret, report, and if possible respond to urban and environmental anomalies through proactive detection mechanisms and automated mitigation actions. A key contribution in this paper is the integration of Hazardous and Conflict states into the robot's decision-making framework, where each anomaly type can trigger specific mitigation strategies. User studies (n = 30) demonstrated the effectiveness of the system in anomaly detection with 91.2% prediction accuracy and relatively low latency response times using edge-ai architecture.", 'abstract_zh': '自主机器人在动态环境中应识别并报告异常，通过积极的缓解措施提高安全性和操作连续性。本文提出了一种结合视觉语言模型和大型语言模型的多模态异常检测与缓解系统，能够实现实时识别和报告城市和环境中的危险情况和冲突。该提出的系统使机器人能够通过前瞻性的检测机制和自动化的缓解行动感知、解释、报告并在必要时响应异常情况。本文的一大贡献在于将危险状态和冲突状态整合到机器人的决策框架中，每种异常类型可以触发特定的缓解策略。用户研究（n=30）表明，该系统在异常检测方面的预测准确率为91.2%，且具有相对较低的延迟响应时间，使用边缘AI架构。', 'title_zh': '基于视觉-语言模型的自主移动机器人 embodied风险 mitigation'}
{'arxiv_id': 'arXiv:2509.06644', 'title': 'T-araVLN: Translator for Agricultural Robotic Agents on Vision-and-Language Navigation', 'authors': 'Xiaobei Zhao, Xingqi Lyu, Xiang Li', 'link': 'https://arxiv.org/abs/2509.06644', 'abstract': 'Agricultural robotic agents have been becoming powerful helpers in a wide range of agricultural tasks, nevertheless, still heavily rely on manual operation or untransportable railway for movement. The AgriVLN method and the A2A benchmark pioneeringly extend Vision-and-Language Navigation (VLN) to the agricultural domain, enabling agents navigate to the target position following the natural language instructions. AgriVLN effectively understands the simple instructions, however, often misunderstands the complicated instructions. To bridge this gap, we propose the method of Translator for Agricultural Robotic Agents on Vision-and-Language Navigation (T-araVLN), in which the Instruction Translator module translates the original instruction to be both refined and precise. Being evaluated on the A2A benchmark, our T-araVLN effectively improves SR from 0.47 to 0.63 and reduces NE from 2.91m to 2.28m, demonstrating the state-of-the-art performance in the agricultural domain. Code: this https URL.', 'abstract_zh': '农业机器人代理在广泛农业任务中已成为强大的助手，但仍主要依赖手动操作或不可移动的铁路进行移动。AgriVLN方法和A2A基准首次将视觉-语言导航（VLN）扩展到农业领域，使代理能够遵循自然语言指令导航至目标位置。AgriVLN能够有效理解简单的指令，但对于复杂的指令经常产生误解。为解决这一问题，我们提出了农业机器人代理在视觉-语言导航中的翻译方法（T-araVLN），其中指令翻译模块将原始指令翻译为更加精确和完善的版本。在A2A基准上的评估表明，我们的T-araVLN将成功率（SR）从0.47提高到0.63，将导航误差（NE）从2.91m减少到2.28m，展示了在农业领域的先进性能。代码：这个链接。', 'title_zh': 'T-araVLN: 农业机器人代理的视觉-语言导航翻译器'}
{'arxiv_id': 'arXiv:2509.06469', 'title': 'Interactive Shaping of Granular Media Using Reinforcement Learning', 'authors': 'Benedikt Kreis, Malte Mosbach, Anny Ripke, Muhammad Ehsan Ullah, Sven Behnke, Maren Bennewitz', 'link': 'https://arxiv.org/abs/2509.06469', 'abstract': 'Autonomous manipulation of granular media, such as sand, is crucial for applications in construction, excavation, and additive manufacturing. However, shaping granular materials presents unique challenges due to their high-dimensional configuration space and complex dynamics, where traditional rule-based approaches struggle without extensive engineering efforts. Reinforcement learning (RL) offers a promising alternative by enabling agents to learn adaptive manipulation strategies through trial and error. In this work, we present an RL framework that enables a robotic arm with a cubic end-effector and a stereo camera to shape granular media into desired target structures. We show the importance of compact observations and concise reward formulations for the large configuration space, validating our design choices with an ablation study. Our results demonstrate the effectiveness of the proposed approach for the training of visual policies that manipulate granular media including their real-world deployment, outperforming two baseline approaches.', 'abstract_zh': '自主操控颗粒介质，如沙子，对于建筑、挖掘和增材制造等领域具有重要意义。然而，由于颗粒材料高维配置空间和复杂动力学带来的独特挑战，传统的基于规则的方法在没有大量工程努力的情况下难以应对。增强学习（RL）提供了一种有前景的替代方案，通过试错使代理学习适应性的操控策略。在本文中，我们提出了一种RL框架，使配备立方体末端执行器和立体相机的机械臂能够将颗粒介质塑造成目标结构。我们强调了紧凑观测和简洁奖励公式对于大配置空间的重要性，并通过消融研究验证了我们的设计选择。我们的结果表明，所提出的方法在训练视觉策略操控颗粒介质方面非常有效，包括其实验室部署，优于两种基准方法。', 'title_zh': '使用强化学习交互塑造颗粒介质'}
{'arxiv_id': 'arXiv:2509.06433', 'title': 'Real-time Photorealistic Mapping for Situational Awareness in Robot Teleoperation', 'authors': 'Ian Page, Pierre Susbielle, Olivier Aycard, Pierre-Brice Wieber', 'link': 'https://arxiv.org/abs/2509.06433', 'abstract': "Achieving efficient remote teleoperation is particularly challenging in unknown environments, as the teleoperator must rapidly build an understanding of the site's layout. Online 3D mapping is a proven strategy to tackle this challenge, as it enables the teleoperator to progressively explore the site from multiple perspectives. However, traditional online map-based teleoperation systems struggle to generate visually accurate 3D maps in real-time due to the high computational cost involved, leading to poor teleoperation performances. In this work, we propose a solution to improve teleoperation efficiency in unknown environments. Our approach proposes a novel, modular and efficient GPU-based integration between recent advancement in gaussian splatting SLAM and existing online map-based teleoperation systems. We compare the proposed solution against state-of-the-art teleoperation systems and validate its performances through real-world experiments using an aerial vehicle. The results show significant improvements in decision-making speed and more accurate interaction with the environment, leading to greater teleoperation efficiency. In doing so, our system enhances remote teleoperation by seamlessly integrating photorealistic mapping generation with real-time performances, enabling effective teleoperation in unfamiliar environments.", 'abstract_zh': '在未知环境实现高效远程遥控操作尤其具有挑战性，因为遥控操作员必须迅速理解现场布局。在线三维建图是一种应对这一挑战的有效策略，因为它使遥控操作员能够从多个视角逐步探索现场。然而，传统基于在线地图的遥控操作系统由于计算成本高，难以实时生成视觉上准确的三维地图，导致遥控操作性能较差。在这项工作中，我们提出了一种改进未知环境中遥控操作效率的解决方案。我们的方法提出了一种新颖、模块化和基于GPU的集成，将近期的高斯点云SLAM技术和现有的基于在线地图的遥控操作系统相结合。我们将提出的解决方案与最先进的遥控操作系统进行比较，并通过使用飞行器的实际实验验证其性能。结果显示，在决策速度和环境交互准确性方面取得了显著改善，从而提高了遥控操作效率。我们的系统通过无缝集成逼真映射生成与实时性能，增强了远程遥控操作，在不熟悉的环境中实现有效的遥控操作。', 'title_zh': '机器人远程操作中的实时 photorealistic 映射以增强情境感知'}
{'arxiv_id': 'arXiv:2509.06342', 'title': 'Towards bridging the gap: Systematic sim-to-real transfer for diverse legged robots', 'authors': 'Filip Bjelonic, Fabian Tischhauser, Marco Hutter', 'link': 'https://arxiv.org/abs/2509.06342', 'abstract': 'Legged robots must achieve both robust locomotion and energy efficiency to be practical in real-world environments. Yet controllers trained in simulation often fail to transfer reliably, and most existing approaches neglect actuator-specific energy losses or depend on complex, hand-tuned reward formulations. We propose a framework that integrates sim-to-real reinforcement learning with a physics-grounded energy model for permanent magnet synchronous motors. The framework requires a minimal parameter set to capture the simulation-to-reality gap and employs a compact four-term reward with a first-principle-based energetic loss formulation that balances electrical and mechanical dissipation. We evaluate and validate the approach through a bottom-up dynamic parameter identification study, spanning actuators, full-robot in-air trajectories and on-ground locomotion. The framework is tested on three primary platforms and deployed on ten additional robots, demonstrating reliable policy transfer without randomization of dynamic parameters. Our method improves energetic efficiency over state-of-the-art methods, achieving a 32 percent reduction in the full Cost of Transport of ANYmal (value 1.27). All code, models, and datasets will be released.', 'abstract_zh': '腿式机器人必须在具备稳健运动能力和能量效率之间取得平衡，才能在真实环境中 practical 应用。然而，在仿真中训练得到的控制器往往无法可靠地迁移，且大多数现有方法忽视了特定执行器的能量损失，或依赖于复杂的手动调 Tune 的奖励公式。我们提出了一种框架，将仿真到现实的强化学习与基于物理的能量模型相结合，用于永磁同步电机。该框架只需要一个小型参数集来捕捉仿真与现实之间的差距，并采用一个由四项组成的紧凑型奖励，其中包括基于第一性原理的能量损失公式，能够平衡电能和机械能的损耗。我们通过从部件到整体的动力学参数识别研究对方法进行了评估和验证，覆盖了执行器、完整机器人在空中的轨迹以及地面运动。该框架在三个主要平台上进行了测试，并部署在十台额外的机器人上，展示了无需随机化动态参数即可实现可靠的策略迁移。我们的方法在能量效率方面优于当前最先进的方法，实现了 ANYmal 的全方位运输成本（值 1.27）降低了 32%。所有代码、模型和数据集都将会公开。', 'title_zh': '向目标迈进：面向多样化腿足机器人的一贯的从仿真到现实的转移方法'}
{'arxiv_id': 'arXiv:2509.06296', 'title': 'Learning to Walk with Less: a Dyna-Style Approach to Quadrupedal Locomotion', 'authors': 'Francisco Affonso, Felipe Andrade G. Tommaselli, Juliano Negri, Vivian S. Medeiros, Mateus V. Gasparino, Girish Chowdhary, Marcelo Becker', 'link': 'https://arxiv.org/abs/2509.06296', 'abstract': 'Traditional RL-based locomotion controllers often suffer from low data efficiency, requiring extensive interaction to achieve robust performance. We present a model-based reinforcement learning (MBRL) framework that improves sample efficiency for quadrupedal locomotion by appending synthetic data to the end of standard rollouts in PPO-based controllers, following the Dyna-Style paradigm. A predictive model, trained alongside the policy, generates short-horizon synthetic transitions that are gradually integrated using a scheduling strategy based on the policy update iterations. Through an ablation study, we identified a strong correlation between sample efficiency and rollout length, which guided the design of our experiments. We validated our approach in simulation on the Unitree Go1 robot and showed that replacing part of the simulated steps with synthetic ones not only mimics extended rollouts but also improves policy return and reduces variance. Finally, we demonstrate that this improvement transfers to the ability to track a wide range of locomotion commands using fewer simulated steps.', 'abstract_zh': '基于模型的强化学习（MBRL）框架通过在PPO控制器的标准卷积末尾附加合成数据，提高四足运动的学习效率，遵循Dyna-Style范式。通过消融研究，我们发现样本效率与卷积长度之间存在较强的相关性，指导了实验设计。我们在模拟环境中使用Unitree Go1机器人验证了该方法，结果显示用合成步骤替换部分模拟步骤不仅模仿了扩展卷积，还提高了策略回报并减小了方差。最后，我们证明了这种改进使机器人能够使用更少的模拟步骤跟踪各种运动命令。', 'title_zh': '学习用更少：一种四足行走的Dyna风格方法'}
{'arxiv_id': 'arXiv:2509.06233', 'title': 'O$^3$Afford: One-Shot 3D Object-to-Object Affordance Grounding for Generalizable Robotic Manipulation', 'authors': 'Tongxuan Tian, Xuhui Kang, Yen-Ling Kuo', 'link': 'https://arxiv.org/abs/2509.06233', 'abstract': "Grounding object affordance is fundamental to robotic manipulation as it establishes the critical link between perception and action among interacting objects. However, prior works predominantly focus on predicting single-object affordance, overlooking the fact that most real-world interactions involve relationships between pairs of objects. In this work, we address the challenge of object-to-object affordance grounding under limited data contraints. Inspired by recent advances in few-shot learning with 2D vision foundation models, we propose a novel one-shot 3D object-to-object affordance learning approach for robotic manipulation. Semantic features from vision foundation models combined with point cloud representation for geometric understanding enable our one-shot learning pipeline to generalize effectively to novel objects and categories. We further integrate our 3D affordance representation with large language models (LLMs) for robotics manipulation, significantly enhancing LLMs' capability to comprehend and reason about object interactions when generating task-specific constraint functions. Our experiments on 3D object-to-object affordance grounding and robotic manipulation demonstrate that our O$^3$Afford significantly outperforms existing baselines in terms of both accuracy and generalization capability.", 'abstract_zh': '基于对象间蕴含的三维对象间即物功能grounding对于机器人操作至关重要，因为它建立了感知与行动之间的重要联系。然而，先前的工作主要关注单个对象的即物功能预测，忽视了大多数现实世界中的交互涉及对象对间的关系这一事实。在本工作中，我们解决了有限数据约束下的对象到对象即物功能grounding挑战。受2D视觉基础模型在少样本学习方面最新进展的启发，我们提出了一种新颖的一次性三维对象到对象即物功能学习方法，用于机器人操作。视觉基础模型的语义特征与点云表示的几何理解相结合，使我们的一次性学习管道能够有效泛化到新的对象和类别。我们进一步将我们的三维即物功能表示与大型语言模型（LLMs）集成到机器人操作中，显著增强了LLMs在生成任务特定约束函数时理解并推理对象交互的能力。我们在三维对象到对象即物功能grounding和机器人操作方面的实验表明，我们的O$^3$Afford在准确性和泛化能力方面均显著优于现有基线方法。', 'title_zh': 'O$^3$Afford: 一次性构建的一般化机器人操作中的三维物体间功能性匹配'}
{'arxiv_id': 'arXiv:2509.06031', 'title': 'ZLATTE: A Geometry-Aware, Learning-Free Framework for Language-Driven Trajectory Reshaping in Human-Robot Interaction', 'authors': 'Junhui Huang, Yuhe Gong, Changsheng Li, Xingguang Duan, Luis Figueredo', 'link': 'https://arxiv.org/abs/2509.06031', 'abstract': 'We present ZLATTE, a geometry-aware, learning-free framework for language-driven trajectory reshaping in human-robot interaction. Unlike prior learning-based methods, ZLATTE leverages Vision-Language Models to register objects as geometric primitives and employs a Large Language Model to translate natural language instructions into explicit geometric and kinematic constraints. These constraints are integrated into a potential field optimization to adapt initial trajectories while preserving feasibility and safety. A multi-agent strategy further enhances robustness under complex or conflicting commands. Simulation and real-world experiments demonstrate that ZLATTE achieves smoother, safer, and more interpretable trajectory modifications compared to state-of-the-art baselines.', 'abstract_zh': 'ZLATTE：一种基于几何感知的语言驱动轨迹重塑框架，在人机交互中的应用', 'title_zh': 'ZLATTE：一种几何导向、无需学习的语言驱动轨迹重塑框架在人机交互中'}
{'arxiv_id': 'arXiv:2509.05581', 'title': 'Learning to Walk in Costume: Adversarial Motion Priors for Aesthetically Constrained Humanoids', 'authors': 'Arturo Flores Alvarez, Fatemeh Zargarbashi, Havel Liu, Shiqi Wang, Liam Edwards, Jessica Anz, Alex Xu, Fan Shi, Stelian Coros, Dennis W. Hong', 'link': 'https://arxiv.org/abs/2509.05581', 'abstract': "We present a Reinforcement Learning (RL)-based locomotion system for Cosmo, a custom-built humanoid robot designed for entertainment applications. Unlike traditional humanoids, entertainment robots present unique challenges due to aesthetic-driven design choices. Cosmo embodies these with a disproportionately large head (16% of total mass), limited sensing, and protective shells that considerably restrict movement. To address these challenges, we apply Adversarial Motion Priors (AMP) to enable the robot to learn natural-looking movements while maintaining physical stability. We develop tailored domain randomization techniques and specialized reward structures to ensure safe sim-to-real, protecting valuable hardware components during deployment. Our experiments demonstrate that AMP generates stable standing and walking behaviors despite Cosmo's extreme mass distribution and movement constraints. These results establish a promising direction for robots that balance aesthetic appeal with functional performance, suggesting that learning-based methods can effectively adapt to aesthetic-driven design constraints.", 'abstract_zh': '基于强化学习的Cosmo娱乐 humanoid 机器人运动系统：对抗运动先验在美学驱动设计下的运动学习与物理稳定性', 'title_zh': '穿着 costumes 走路的学习：受美学约束的人形角色的对抗运动先验知识'}
{'arxiv_id': 'arXiv:2509.05475', 'title': 'Learning Tool-Aware Adaptive Compliant Control for Autonomous Regolith Excavation', 'authors': 'Andrej Orsula, Matthieu Geist, Miguel Olivares-Mendez, Carol Martinez', 'link': 'https://arxiv.org/abs/2509.05475', 'abstract': 'Autonomous regolith excavation is a cornerstone of in-situ resource utilization for a sustained human presence beyond Earth. However, this task is fundamentally hindered by the complex interaction dynamics of granular media and the operational need for robots to use diverse tools. To address these challenges, this work introduces a framework where a model-based reinforcement learning agent learns within a parallelized simulation. This environment leverages high-fidelity particle physics and procedural generation to create a vast distribution of both lunar terrains and excavation tool geometries. To master this diversity, the agent learns an adaptive interaction strategy by dynamically modulating its own stiffness and damping at each control step through operational space control. Our experiments demonstrate that training with a procedural distribution of tools is critical for generalization and enables the development of sophisticated tool-aware behavior. Furthermore, we show that augmenting the agent with visual feedback significantly improves task success. These results represent a validated methodology for developing the robust and versatile autonomous systems required for the foundational tasks of future space missions.', 'abstract_zh': '自主月壤挖掘是月球地外长期驻留原位资源利用的关键基础。然而，这一任务从根本上受到粒状介质复杂相互作用动力学以及机器人需要使用多种工具的操作需求的限制。为应对这些挑战，本文提出了一种基于模型的强化学习框架，在并行仿真环境中进行学习。该环境利用高保真颗粒物理和程序化生成技术，创建了广泛的月壤地形和挖掘工具几何分布。为了掌握这种多样性，代理通过操作空间控制，在每个控制步骤中动态调节自身的刚度和阻尼来学习一种适应性的交互策略。我们的实验表明，使用工具的程序化分布进行训练对于泛化至关重要，并使开发出了复杂工具感知行为成为可能。此外，我们证明，将视觉反馈增强到代理中可以显著提高任务成功率。这些结果代表了一种验证过的开发未来太空任务基础任务所需的鲁棒且多功能自主系统的方法。', 'title_zh': '学具自适应 compliant 控制技术以实现自主月壤挖掘'}
{'arxiv_id': 'arXiv:2509.05356', 'title': 'Spiking Neural Networks for Continuous Control via End-to-End Model-Based Learning', 'authors': 'Justus Huebotter, Pablo Lanillos, Marcel van Gerven, Serge Thill', 'link': 'https://arxiv.org/abs/2509.05356', 'abstract': 'Despite recent progress in training spiking neural networks (SNNs) for classification, their application to continuous motor control remains limited. Here, we demonstrate that fully spiking architectures can be trained end-to-end to control robotic arms with multiple degrees of freedom in continuous environments. Our predictive-control framework combines Leaky Integrate-and-Fire dynamics with surrogate gradients, jointly optimizing a forward model for dynamics prediction and a policy network for goal-directed action. We evaluate this approach on both a planar 2D reaching task and a simulated 6-DOF Franka Emika Panda robot. Results show that SNNs can achieve stable training and accurate torque control, establishing their viability for high-dimensional motor tasks. An extensive ablation study highlights the role of initialization, learnable time constants, and regularization in shaping training dynamics. We conclude that while stable and effective control can be achieved, recurrent spiking networks remain highly sensitive to hyperparameter settings, underscoring the importance of principled design choices.', 'abstract_zh': '尽管在训练神经脉冲网络（SNNs）进行分类方面取得了近期进展，但它们在连续运动控制中的应用仍受到限制。在此，我们证明完全脉冲架构可以通过端到端训练来控制具有多个自由度的连续环境中的机器人手臂。我们的预测控制框架结合了Leaky Integrate-and-Fire动力学和代理梯度，联合优化了动力学预测的前向模型和用于目标导向动作的策略网络。我们在一个平面2D抓取任务和一个模拟的6-DOF Franka Emika Panda机器人上评估了这种方法。结果显示，SNNs可以实现稳定的训练和精确的扭矩控制，确立了其在高维运动任务中的可行性。通过广泛的消融研究，我们强调了初始化、可学习的时间常数和正则化在塑造训练动态中的作用。我们得出结论，虽然可以实现稳定和有效的控制，但循环脉冲网络对超参数设置的高度敏感性强调了原理性设计选择的重要性。', 'title_zh': '基于端到端模型导向学习的脉冲神经网络连续控制'}
{'arxiv_id': 'arXiv:2509.05355', 'title': 'Human-LLM Synergy in Context-Aware Adaptive Architecture for Scalable Drone Swarm Operation', 'authors': 'Ahmed R. Sadik, Muhammad Ashfaq, Niko Mäkitalo, Tommi Mikkonen', 'link': 'https://arxiv.org/abs/2509.05355', 'abstract': 'The deployment of autonomous drone swarms in disaster response missions necessitates the development of flexible, scalable, and robust coordination systems. Traditional fixed architectures struggle to cope with dynamic and unpredictable environments, leading to inefficiencies in energy consumption and connectivity. This paper addresses this gap by proposing an adaptive architecture for drone swarms, leveraging a Large Language Model to dynamically select the optimal architecture as centralized, hierarchical, or holonic based on real time mission parameters such as task complexity, swarm size, and communication stability. Our system addresses the challenges of scalability, adaptability, and robustness,ensuring efficient energy consumption and maintaining connectivity under varying conditions. Extensive simulations demonstrate that our adaptive architecture outperforms traditional static models in terms of scalability, energy efficiency, and connectivity. These results highlight the potential of our approach to provide a scalable, adaptable, and resilient solution for real world disaster response scenarios.', 'abstract_zh': '自主无人机集群在灾害响应任务中的部署需要开发灵活、可扩展且 robust 的协调系统。传统的固定架构难以应对动态和不可预测的环境，导致能量消耗和连接性效率低下。本文通过提出一个基于大型语言模型的自适应架构来解决这一问题，该架构根据实时任务复杂性、集群规模和通信稳定性等因素动态选择集中式、层次式或holonic架构。我们的系统解决了可扩展性、适应性和鲁棒性的问题，确保在不同条件下高效能量消耗和保持连接性。广泛仿真结果显示，我们的自适应架构在可扩展性、能量效率和连接性方面优于传统的静态模型。这些结果强调了我们方法在提供一种适用于现实世界灾害响应场景的可扩展、适应性和鲁棒性解决方案方面的潜力。', 'title_zh': '人类-大型语言模型协同在上下文感知自适应架构中的可扩展无人机群操作'}
{'arxiv_id': 'arXiv:2509.05338', 'title': 'Plantbot: Integrating Plant and Robot through LLM Modular Agent Networks', 'authors': 'Atsushi Masumori, Norihiro Maruyama, Itsuki Doi, johnsmith, Hiroki Sato, Takashi Ikegami', 'link': 'https://arxiv.org/abs/2509.05338', 'abstract': 'We introduce Plantbot, a hybrid lifeform that connects a living plant with a mobile robot through a network of large language model (LLM) modules. Each module - responsible for sensing, vision, dialogue, or action - operates asynchronously and communicates via natural language, enabling seamless interaction across biological and artificial domains. This architecture leverages the capacity of LLMs to serve as hybrid interfaces, where natural language functions as a universal protocol, translating multimodal data (soil moisture, temperature, visual context) into linguistic messages that coordinate system behaviors. The integrated network transforms plant states into robotic actions, installing normativity essential for agency within the sensor-motor loop. By combining biological and robotic elements through LLM-mediated communication, Plantbot behaves as an embodied, adaptive agent capable of responding autonomously to environmental conditions. This approach suggests possibilities for a new model of artificial life, where decentralized, LLM modules coordination enable novel interactions between biological and artificial systems.', 'abstract_zh': 'Plantbot：一种通过大型语言模型模块连接生物植物与移动机器人的混合生命体', 'title_zh': 'Plantbot：通过LLM模块化代理网络整合植物与机器人'}
{'arxiv_id': 'arXiv:2509.05314', 'title': 'ManipDreamer3D : Synthesizing Plausible Robotic Manipulation Video with Occupancy-aware 3D Trajectory', 'authors': 'Ying Li, Xiaobao Wei, Xiaowei Chi, Yuming Li, Zhongyu Zhao, Hao Wang, Ningning Ma, Ming Lu, Shanghang Zhang', 'link': 'https://arxiv.org/abs/2509.05314', 'abstract': 'Data scarcity continues to be a major challenge in the field of robotic manipulation. Although diffusion models provide a promising solution for generating robotic manipulation videos, existing methods largely depend on 2D trajectories, which inherently face issues with 3D spatial ambiguity. In this work, we present a novel framework named ManipDreamer3D for generating plausible 3D-aware robotic manipulation videos from the input image and the text instruction. Our method combines 3D trajectory planning with a reconstructed 3D occupancy map created from a third-person perspective, along with a novel trajectory-to-video diffusion model. Specifically, ManipDreamer3D first reconstructs the 3D occupancy representation from the input image and then computes an optimized 3D end-effector trajectory, minimizing path length while avoiding collisions. Next, we employ a latent editing technique to create video sequences from the initial image latent and the optimized 3D trajectory. This process conditions our specially trained trajectory-to-video diffusion model to produce robotic pick-and-place videos. Our method generates robotic videos with autonomously planned plausible 3D trajectories, significantly reducing human intervention requirements. Experimental results demonstrate superior visual quality compared to existing methods.', 'abstract_zh': '基于3D感知的从文本指令生成可信机器人操纵视频的新框架ManipDreamer3D', 'title_zh': 'ManipDreamer3D：基于占用感知的3D轨迹合成可信机器人操作视频'}
{'arxiv_id': 'arXiv:2509.06934', 'title': '"It was Tragic": Exploring the Impact of a Robot\'s Shutdown', 'authors': 'Agam Oberlender, Hadas Erel', 'link': 'https://arxiv.org/abs/2509.06934', 'abstract': 'It is well established that people perceive robots as social entities, even when they are not designed for social interaction. We evaluated whether the social interpretation of robotic gestures should also be considered when turning off a robot. In the experiment, participants engaged in a brief preliminary neutral interaction while a robotic arm showed interest in their actions. At the end of the task, participants were asked to turn off the robotic arm under two conditions: (1) a Non-designed condition, where all of the robot\'s engines were immediately and simultaneously turned off, as robots typically shut down; (2) a Designed condition, where the robot\'s engines gradually folded inward in a motion resembling "falling asleep." Our findings revealed that all participants anthropomorphized the robot\'s movement when it was turned off. In the Non-designed condition, most participants interpreted the robot\'s turn-off movement negatively, as if the robot had "died." In the Designed condition, most participants interpreted it more neutrally, stating that the robot "went to sleep." The robot\'s turn-off movement also impacted its perception, leading to higher likeability, perceived intelligence, and animacy in the Designed condition. We conclude that the impact of common edge interactions, such as turning off a robot, should be carefully designed while considering people\'s automatic tendency to perceive robots as social entities.', 'abstract_zh': '已经确立了人们会将机器人视为社会实体的事实，即使这些机器人并非为社会互动设计。我们评估了在关闭机器人时，是否也应该考虑其社会行为的解释。在实验中，参与者进行了短暂的初步中性互动，期间机器人手臂对他们的动作表现出兴趣。任务结束后，参与者在两种条件下被要求关闭机器人手臂：（1）非设计条件，所有机器人引擎立即同时关闭，这是机器人通常关闭的方式；（2）设计条件，机器人引擎逐渐向内折叠，动作类似于“入睡”。研究发现，所有参与者在机器人关闭时都将其行为拟人化。在非设计条件下，大多数参与者将机器人关闭的动作解读为负面的，仿佛机器人“死了”。在设计条件下，大多数参与者将它解读为更中性的行为，认为机器人“睡着了”。机器人的关闭动作也影响了其感知，导致在设计条件下人们对机器人的喜爱度、感知智能水平和生机感更高。我们得出结论，在考虑人们对机器人作为社会实体的天然倾向时，应当仔细设计常见的边缘交互，如关闭机器人等行为。', 'title_zh': '“真悲剧”：探究机器人关闭的影响'}
{'arxiv_id': 'arXiv:2509.06893', 'title': 'Nanobot Algorithms for Treatment of Diffuse Cancer', 'authors': 'Noble Harasha, Nancy Lynch', 'link': 'https://arxiv.org/abs/2509.06893', 'abstract': 'Motile nanosized particles, or "nanobots", promise more effective and less toxic targeted drug delivery because of their unique scale and precision. We consider the case in which the cancer is "diffuse", dispersed such that there are multiple distinct cancer sites. We investigate the problem of a swarm of nanobots locating these sites and treating them by dropping drug payloads at the sites. To improve the success of the treatment, the drug payloads must be allocated between sites according to their "demands"; this requires extra nanobot coordination. We present a mathematical model of the behavior of the nanobot agents and of their colloidal environment. This includes a movement model for agents based upon experimental findings from actual nanoparticles in which bots noisily ascend and descend chemical gradients. We present three algorithms: The first algorithm, called KM, is the most representative of reality, with agents simply following naturally existing chemical signals that surround each cancer site. The second algorithm, KMA, includes an additional chemical payload which amplifies the existing natural signals. The third algorithm, KMAR, includes another additional chemical payload which counteracts the other signals, instead inducing negative chemotaxis in agents such that they are repelled from sites that are already sufficiently treated. We present simulation results for all algorithms across different types of cancer arrangements. For KM, we show that the treatment is generally successful unless the natural chemical signals are weak, in which case the treatment progresses too slowly. For KMA, we demonstrate a significant improvement in treatment speed but a drop in eventual success, except for concentrated cancer patterns. For KMAR, our results show great performance across all types of cancer patterns, demonstrating robustness and adaptability.', 'abstract_zh': '可移动的纳米大小颗粒或“纳米机器人”因其独特的尺度和精度，承诺实现更有效和更少毒性的靶向药物输送。当癌症是“弥漫性”的，即分散在多个独立的癌症部位时，我们探讨了纳米机器人集群定位这些部位并通过在这些部位释放药物有效载荷进行治疗的问题。为了提高治疗成功率，药物有效载荷需要根据各个部位的“需求”进行分配；这需要额外的纳米机器人协调。我们建立了一个数学模型来描述纳米机器人代理及其胶体环境的行为。该模型包括基于实际纳米颗粒的实验发现的代理运动模型，这些模型中的机器人在化学梯度中嘈杂地上升和下降。我们提出了三种算法：第一个算法称为KM，最能代表现实情况，代理简单地遵循每个癌症部位周围的自然存在的化学信号。第二个算法称为KMA，在现有自然信号的基础上增加了额外的化学有效载荷，以增强这些信号。第三个算法称为KMAR，在另一个额外的化学有效载荷中加入，该有效载荷中和了其他信号，反而诱导负趋化行为，使代理远离已经充分治疗的部位。我们展示了所有算法在不同类型的癌症布局下的仿真结果。对于KM，我们表明，除非自然化学信号较弱，否则治疗通常会成功，但在这种情况下，治疗进展得太慢。对于KMA，我们证明了在治疗速度上的显著改进，但最终成功率的下降，这主要发生在集中分布的癌症模式下。对于KMAR，我们的结果表明，该算法在所有类型的癌症布局中表现出色，显示出稳健性和适应性。', 'title_zh': '纳米机器人治疗弥漫性癌症的算法'}
{'arxiv_id': 'arXiv:2509.06426', 'title': 'Musculoskeletal simulation of limb movement biomechanics in Drosophila melanogaster', 'authors': 'Pembe Gizem Özdil, Chuanfang Ning, Jasper S. Phelps, Sibo Wang-Chen, Guy Elisha, Alexander Blanke, Auke Ijspeert, Pavan Ramdya', 'link': 'https://arxiv.org/abs/2509.06426', 'abstract': 'Computational models are critical to advance our understanding of how neural, biomechanical, and physical systems interact to orchestrate animal behaviors. Despite the availability of near-complete reconstructions of the Drosophila melanogaster central nervous system, musculature, and exoskeleton, anatomically and physically grounded models of fly leg muscles are still missing. These models provide an indispensable bridge between motor neuron activity and joint movements. Here, we introduce the first 3D, data-driven musculoskeletal model of Drosophila legs, implemented in both OpenSim and MuJoCo simulation environments. Our model incorporates a Hill-type muscle representation based on high-resolution X-ray scans from multiple fixed specimens. We present a pipeline for constructing muscle models using morphological imaging data and for optimizing unknown muscle parameters specific to the fly. We then combine our musculoskeletal models with detailed 3D pose estimation data from behaving flies to achieve muscle-actuated behavioral replay in OpenSim. Simulations of muscle activity across diverse walking and grooming behaviors predict coordinated muscle synergies that can be tested experimentally. Furthermore, by training imitation learning policies in MuJoCo, we test the effect of different passive joint properties on learning speed and find that damping and stiffness facilitate learning. Overall, our model enables the investigation of motor control in an experimentally tractable model organism, providing insights into how biomechanics contribute to generation of complex limb movements. Moreover, our model can be used to control embodied artificial agents to generate naturalistic and compliant locomotion in simulated environments.', 'abstract_zh': '基于计算模型探讨果蝇腿部神经、生物力学和物理系统如何协同 orchestrating 动物行为至关重要。尽管获得了近乎完整重建的果蝇中枢神经系统、肌肉和外骨骼，但仍缺少基于解剖和物理的果蝇后腿肌肉模型。这些模型提供了从运动神经元活动到关节运动的必不可少的桥梁。在这里，我们介绍了一个首个基于数据的果蝇腿部3D肌骨模型，该模型分别在OpenSim和MuJoCo仿真环境中实现。我们的模型基于高分辨率X射线扫描数据构建Hill型肌肉表示。我们提出了一种使用形态成像数据构建肌肉模型的管道，并优化了特定于果蝇的未知肌肉参数。然后，我们将肌骨模型与活跃果蝇的详细3D姿态估计数据结合，在OpenSim中实现肌肉驱动的行为回放。对不同步行和梳理行为的肌肉活动进行的模拟预测了协调的肌肉协同作用，这些协同作用可以进行实验验证。此外，通过在MuJoCo中训练模仿学习策略，我们测试了不同被动关节特性对学习速度的影响，发现阻尼和刚度有助于学习。总体而言，我们的模型使我们能够研究实验可操作模式动物的运动控制，提供了关于生物力学如何贡献于复杂肢体运动生成的见解。此外，我们的模型可以用于控制体现式人工代理，以在虚拟环境中生成自然和顺应的运动。', 'title_zh': '果蝇 melanogaster 肢体运动骨肌力学的模拟'}
{'arxiv_id': 'arXiv:2509.06733', 'title': 'Reinforcement Learning Foundations for Deep Research Systems: A Survey', 'authors': 'Wenjun Li, Zhi Chen, Jingru Lin, Hannan Cao, Wei Han, Sheng Liang, Zhi Zhang, Kuicai Dong, Dexun Li, Chen Zhang, Yong Liu', 'link': 'https://arxiv.org/abs/2509.06733', 'abstract': 'Deep research systems, agentic AI that solve complex, multi-step tasks by coordinating reasoning, search across the open web and user files, and tool use, are moving toward hierarchical deployments with a Planner, Coordinator, and Executors. In practice, training entire stacks end-to-end remains impractical, so most work trains a single planner connected to core tools such as search, browsing, and code. While SFT imparts protocol fidelity, it suffers from imitation and exposure biases and underuses environment feedback. Preference alignment methods such as DPO are schema and proxy-dependent, off-policy, and weak for long-horizon credit assignment and multi-objective trade-offs. A further limitation of SFT and DPO is their reliance on human defined decision points and subskills through schema design and labeled comparisons. Reinforcement learning aligns with closed-loop, tool-interaction research by optimizing trajectory-level policies, enabling exploration, recovery behaviors, and principled credit assignment, and it reduces dependence on such human priors and rater biases.\nThis survey is, to our knowledge, the first dedicated to the RL foundations of deep research systems. It systematizes work after DeepSeek-R1 along three axes: (i) data synthesis and curation; (ii) RL methods for agentic research covering stability, sample efficiency, long context handling, reward and credit design, multi-objective optimization, and multimodal integration; and (iii) agentic RL training systems and frameworks. We also cover agent architecture and coordination, as well as evaluation and benchmarks, including recent QA, VQA, long-form synthesis, and domain-grounded, tool-interaction tasks. We distill recurring patterns, surface infrastructure bottlenecks, and offer practical guidance for training robust, transparent deep research agents with RL.', 'abstract_zh': '深层研究系统的RL基础：从规划者、协调者和执行者的人工智能到层次化部署的研究', 'title_zh': '深度研究系统 reinforcement 学习基础：一个综述'}
{'arxiv_id': 'arXiv:2509.06490', 'title': 'MORSE: Multi-Objective Reinforcement Learning via Strategy Evolution for Supply Chain Optimization', 'authors': 'Niki Kotecha, Ehecatl Antonio del Rio Chanona', 'link': 'https://arxiv.org/abs/2509.06490', 'abstract': 'In supply chain management, decision-making often involves balancing multiple conflicting objectives, such as cost reduction, service level improvement, and environmental sustainability. Traditional multi-objective optimization methods, such as linear programming and evolutionary algorithms, struggle to adapt in real-time to the dynamic nature of supply chains. In this paper, we propose an approach that combines Reinforcement Learning (RL) and Multi-Objective Evolutionary Algorithms (MOEAs) to address these challenges for dynamic multi-objective optimization under uncertainty. Our method leverages MOEAs to search the parameter space of policy neural networks, generating a Pareto front of policies. This provides decision-makers with a diverse population of policies that can be dynamically switched based on the current system objectives, ensuring flexibility and adaptability in real-time decision-making. We also introduce Conditional Value-at-Risk (CVaR) to incorporate risk-sensitive decision-making, enhancing resilience in uncertain environments. We demonstrate the effectiveness of our approach through case studies, showcasing its ability to respond to supply chain dynamics and outperforming state-of-the-art methods in an inventory management case study. The proposed strategy not only improves decision-making efficiency but also offers a more robust framework for managing uncertainty and optimizing performance in supply chains.', 'abstract_zh': '在供应链管理中，决策往往需要平衡多个冲突的目标，如成本降低、服务水平提升和环境可持续性。传统的多目标优化方法，如线性规划和演化算法，难以实时适应供应链的动态性。本文提出了一种结合强化学习（RL）和多目标演化算法（MOEAs）的方法，以应对动态多目标优化过程中的不确定性挑战。该方法利用MOEAs搜索策略神经网络的参数空间，生成帕累托前沿的策略，为决策者提供多样化的策略群体，可以根据当前系统目标动态切换，确保实时决策的灵活性和适应性。此外，我们引入条件值-at-风险（CVaR）以纳入风险敏感决策，增强在不确定环境中的韧性。通过案例研究，我们证明了该方法的有效性，并在库存管理案例中表现出优于现有先进方法的能力。所提出的方法不仅提高了决策效率，还提供了一种更稳健的框架来管理不确定性并优化供应链性能。', 'title_zh': 'MORSE: 多目标强化学习在供应链优化中的策略进化方法'}
{'arxiv_id': 'arXiv:2509.06409', 'title': 'Teaching AI Stepwise Diagnostic Reasoning with Report-Guided Chain-of-Thought Learning', 'authors': 'Yihong Luo, Wenwu He, Zhuo-Xu Cui, Dong Liang', 'link': 'https://arxiv.org/abs/2509.06409', 'abstract': "This study presents DiagCoT, a multi-stage framework that applies supervised fine-tuning to general-purpose vision-language models (VLMs) to emulate radiologists' stepwise diagnostic reasoning using only free-text reports. DiagCoT combines contrastive image-report tuning for domain alignment, chain-of-thought supervision to capture inferential logic, and reinforcement tuning with clinical reward signals to enhance factual accuracy and fluency. On the MIMIC-CXR benchmark, DiagCoT improved zero-shot disease classification AUC from 0.52 to 0.76 (absolute gain of 0.24), pathology grounding mIoU from 0.08 to 0.31 (absolute gain of 0.23), and report generation BLEU from 0.11 to 0.33 (absolute gain of 0.22). It outperformed state-of-the-art models including LLaVA-Med and CXR-LLAVA on long-tailed diseases and external datasets. By converting unstructured clinical narratives into structured supervision, DiagCoT offers a scalable approach for developing interpretable and diagnostically competent AI systems for radiology.", 'abstract_zh': 'DiagCoT：一种用于模仿放射科医生逐步诊断推理的多阶段框架，仅使用自由文本报告对通用视觉-语言模型进行监督微调', 'title_zh': '基于报告引导的链式思考教学：逐步诊断推理的AI教学'}
{'arxiv_id': 'arXiv:2509.06278', 'title': 'TableMind: An Autonomous Programmatic Agent for Tool-Augmented Table Reasoning', 'authors': 'Chuang Jiang, Mingyue Cheng, Xiaoyu Tao, Qingyang Mao, Jie Ouyang, Qi Liu', 'link': 'https://arxiv.org/abs/2509.06278', 'abstract': 'Table reasoning is crucial for leveraging structured data in domains such as finance, healthcare, and scientific research. While large language models (LLMs) show promise in multi-step reasoning, purely text-based methods often struggle with the complex numerical computations and fine-grained operations inherently required in this task. Tool-integrated reasoning improves computational accuracy via explicit code execution, yet existing systems frequently rely on rigid patterns, supervised imitation, and lack true autonomous adaptability. In this paper, we present TableMind, an LLM-driven table reasoning agent that (i) autonomously performs multi-turn tool invocation, (ii) writes and executes data-analyzing code in a secure sandbox environment for data analysis and precise numerical reasoning, and (iii) exhibits high-level capabilities such as planning and self-reflection to adapt strategies. To realize these capabilities, we adopt a two-stage fine-tuning paradigm built on top of a powerful pre-trained language model: supervised fine-tuning on high-quality reasoning trajectories to establish effective tool usage patterns, followed by reinforcement fine-tuning to optimize multi-objective strategies. In particular, we propose Rank-Aware Policy Optimization (RAPO), which increases the update weight of high-quality trajectories when their output probabilities are lower than those of low-quality ones, thereby guiding the model more consistently toward better and more accurate answers. Extensive experiments on several mainstream benchmarks demonstrate that TableMind achieves superior performance compared to competitive baselines, yielding substantial gains in both reasoning accuracy and computational precision.', 'abstract_zh': 'TableMind：基于大型语言模型的自主表推理代理', 'title_zh': 'TableMind: 一种用于工具增强表格推理的自主程序化代理'}
{'arxiv_id': 'arXiv:2509.06269', 'title': 'REMI: A Novel Causal Schema Memory Architecture for Personalized Lifestyle Recommendation Agents', 'authors': 'Vishal Raman, Vijai Aravindh R, Abhijith Ragav', 'link': 'https://arxiv.org/abs/2509.06269', 'abstract': "Personalized AI assistants often struggle to incorporate complex personal data and causal knowledge, leading to generic advice that lacks explanatory power. We propose REMI, a Causal Schema Memory architecture for a multimodal lifestyle agent that integrates a personal causal knowledge graph, a causal reasoning engine, and a schema based planning module. The idea is to deliver explainable, personalized recommendations in domains like fashion, personal wellness, and lifestyle planning. Our architecture uses a personal causal graph of the user's life events and habits, performs goal directed causal traversals enriched with external knowledge and hypothetical reasoning, and retrieves adaptable plan schemas to generate tailored action plans. A Large Language Model orchestrates these components, producing answers with transparent causal explanations. We outline the CSM system design and introduce new evaluation metrics for personalization and explainability, including Personalization Salience Score and Causal Reasoning Accuracy, to rigorously assess its performance. Results indicate that CSM based agents can provide more context aware, user aligned recommendations compared to baseline LLM agents. This work demonstrates a novel approach to memory augmented, causal reasoning in personalized agents, advancing the development of transparent and trustworthy AI lifestyle assistants.", 'abstract_zh': '个性化AI助手往往难以整合复杂的个人数据和因果知识，导致提供的建议缺乏解释力。我们提出了一种因果模式记忆架构REMI，该架构用于多模态生活方式代理，集成了个人因果知识图、因果推理引擎和基于模式的规划模块。目的是在时尚、个人健康和生活方式规划等领域提供可解释的个性化推荐。该架构使用用户的生平事件和个人习惯的个人因果图，进行目标导向的因果遍历，结合外部知识和假设推理，并检索适应性计划模式生成定制化的行动计划。大规模语言模型协调这些组件，生成具有透明因果解释的答案。我们概述了CSM系统设计，并引入了新的个性化和解释性评估指标，包括个性化显著性评分和个人因果推理准确性，以严格评估其性能。结果表明，基于CSM的代理可以比基线语言模型代理提供更具上下文关联和个人导向的建议。这项工作展示了增强记忆和因果推理的新颖方法在个性化代理中的应用，推动了透明和可信赖的生活方式AI助手的发展。', 'title_zh': 'REMI: 一种新型因果模式记忆架构的个性化生活方式推荐代理'}
{'arxiv_id': 'arXiv:2509.05933', 'title': 'MapAgent: A Hierarchical Agent for Geospatial Reasoning with Dynamic Map Tool Integration', 'authors': 'Md Hasebul Hasan, Mahir Labib Dihan, Mohammed Eunus Ali, Md Rizwan Parvez', 'link': 'https://arxiv.org/abs/2509.05933', 'abstract': 'Agentic AI has significantly extended the capabilities of large language models (LLMs) by enabling complex reasoning and tool use. However, most existing frameworks are tailored to domains such as mathematics, coding, or web automation, and fall short on geospatial tasks that require spatial reasoning, multi-hop planning, and real-time map interaction. To address these challenges, we introduce MapAgent, a hierarchical multi-agent plug-and-play framework with customized toolsets and agentic scaffolds for map-integrated geospatial reasoning. Unlike existing flat agent-based approaches that treat tools uniformly-often overwhelming the LLM when handling similar but subtly different geospatial APIs-MapAgent decouples planning from execution. A high-level planner decomposes complex queries into subgoals, which are routed to specialized modules. For tool-heavy modules-such as map-based services-we then design a dedicated map-tool agent that efficiently orchestrates related APIs adaptively in parallel to effectively fetch geospatial data relevant for the query, while simpler modules (e.g., solution generation or answer extraction) operate without additional agent overhead. This hierarchical design reduces cognitive load, improves tool selection accuracy, and enables precise coordination across similar APIs. We evaluate MapAgent on four diverse geospatial benchmarks-MapEval-Textual, MapEval-API, MapEval-Visual, and MapQA-and demonstrate substantial gains over state-of-the-art tool-augmented and agentic baselines. We open-source our framwork at this https URL.', 'abstract_zh': '代理型AI显著扩展了大语言模型（LLMs）的能力，通过实现复杂的推理和工具使用。然而，现有的大多数框架主要针对数学、编码或网页自动化等领域，而在需要空间推理、多跳规划和实时地图交互的地理空间任务上表现不足。为应对这些挑战，我们提出了一种分级多代理插件式框架——MapAgent，该框架具有定制化的工具集和地理空间推理的代理式支架。与现有的平铺代理方法不同，后者在处理相似但细微不同的地理空间API时往往会压倒LLM，MapAgent将规划与执行分离。高级规划器将复杂查询分解为子目标，这些子目标被路由到专业模块中。对于工具密集型模块，如基于地图的服务，我们设计了一个专用的地图工具代理，能够有效地并行协调相关API，以适配地获取查询相关的地理空间数据，而较简单的模块（如解决方案生成或答案提取）则无需额外的代理开销。这种分级设计减轻了认知负担，提高了工具选择的准确性，并允许跨类似API进行精确协调。我们在四个不同的地理空间基准测试上评估了MapAgent——MapEval-Textual、MapEval-API、MapEval-Visual 和 MapQA，并展示了与现有最先进的工具增强和代理式基线相比的显著改进。我们已在以下网址开源了该框架：this https URL。', 'title_zh': 'MapAgent：一种集成动态地图工具的分级代理地理空间推理模型'}
{'arxiv_id': 'arXiv:2509.05378', 'title': 'Code Like Humans: A Multi-Agent Solution for Medical Coding', 'authors': 'Andreas Motzfeldt, Joakim Edin, Casper L. Christensen, Christian Hardmeier, Lars Maaløe, Anna Rogers', 'link': 'https://arxiv.org/abs/2509.05378', 'abstract': "In medical coding, experts map unstructured clinical notes to alphanumeric codes for diagnoses and procedures. We introduce Code Like Humans: a new agentic framework for medical coding with large language models. It implements official coding guidelines for human experts, and it is the first solution that can support the full ICD-10 coding system (+70K labels). It achieves the best performance to date on rare diagnosis codes (fine-tuned discriminative classifiers retain an advantage for high-frequency codes, to which they are limited). Towards future work, we also contribute an analysis of system performance and identify its `blind spots' (codes that are systematically undercoded).", 'abstract_zh': '人类like的医疗编码：一种基于大语言模型的自主医疗编码框架', 'title_zh': '像人类一样编码：一种多代理医疗编码解决方案'}
{'arxiv_id': 'arXiv:2509.05324', 'title': 'Perception Graph for Cognitive Attack Reasoning in Augmented Reality', 'authors': 'Rongqian Chen, Shu Hong, Rifatul Islam, Mahdi Imani, G. Gary Tan, Tian Lan', 'link': 'https://arxiv.org/abs/2509.05324', 'abstract': "Augmented reality (AR) systems are increasingly deployed in tactical environments, but their reliance on seamless human-computer interaction makes them vulnerable to cognitive attacks that manipulate a user's perception and severely compromise user decision-making. To address this challenge, we introduce the Perception Graph, a novel model designed to reason about human perception within these systems. Our model operates by first mimicking the human process of interpreting key information from an MR environment and then representing the outcomes using a semantically meaningful structure. We demonstrate how the model can compute a quantitative score that reflects the level of perception distortion, providing a robust and measurable method for detecting and analyzing the effects of such cognitive attacks.", 'abstract_zh': '增强现实（AR）系统在战术环境中越来越广泛地应用，但由于其对无缝人机交互的依赖，使其容易受到操纵用户感知的认知攻击，严重影响用户决策。为应对这一挑战，我们提出了感知图这一新型模型，该模型旨在在这些系统中推理人类感知。该模型首先模仿人类从MR环境中解读关键信息的过程，然后通过语义上有意义的结构表示结果。我们展示了该模型如何计算反映感知扭曲程度的量化得分，提供了一种 robust 和可测量的方法来检测和分析此类认知攻击的影响。', 'title_zh': '感知图 dla 认知攻击推理在增强现实中的应用'}
{'arxiv_id': 'arXiv:2509.06853', 'title': 'Reinforcement learning meets bioprocess control through behaviour cloning: Real-world deployment in an industrial photobioreactor', 'authors': 'Juan D. Gil, Ehecatl Antonio Del Rio Chanona, José L. Guzmán, Manuel Berenguel', 'link': 'https://arxiv.org/abs/2509.06853', 'abstract': 'The inherent complexity of living cells as production units creates major challenges for maintaining stable and optimal bioprocess conditions, especially in open Photobioreactors (PBRs) exposed to fluctuating environments. To address this, we propose a Reinforcement Learning (RL) control approach, combined with Behavior Cloning (BC), for pH regulation in open PBR systems. This represents, to the best of our knowledge, the first application of an RL-based control strategy to such a nonlinear and disturbance-prone bioprocess. Our method begins with an offline training stage in which the RL agent learns from trajectories generated by a nominal Proportional-Integral-Derivative (PID) controller, without direct interaction with the real system. This is followed by a daily online fine-tuning phase, enabling adaptation to evolving process dynamics and stronger rejection of fast, transient disturbances. This hybrid offline-online strategy allows deployment of an adaptive control policy capable of handling the inherent nonlinearities and external perturbations in open PBRs. Simulation studies highlight the advantages of our method: the Integral of Absolute Error (IAE) was reduced by 8% compared to PID control and by 5% relative to standard off-policy RL. Moreover, control effort decreased substantially-by 54% compared to PID and 7% compared to standard RL-an important factor for minimizing operational costs. Finally, an 8-day experimental validation under varying environmental conditions confirmed the robustness and reliability of the proposed approach. Overall, this work demonstrates the potential of RL-based methods for bioprocess control and paves the way for their broader application to other nonlinear, disturbance-prone systems.', 'abstract_zh': '基于强化学习的行为仿slug控制在开放光生物反应器pH调节中的应用：一种处理非线性和干扰的新方法', 'title_zh': '强化学习与生物过程控制相结合：工业光生物反应器中的实际部署'}
{'arxiv_id': 'arXiv:2509.06759', 'title': 'Aligning Large Vision-Language Models by Deep Reinforcement Learning and Direct Preference Optimization', 'authors': 'Thanh Thi Nguyen, Campbell Wilson, Janis Dalins', 'link': 'https://arxiv.org/abs/2509.06759', 'abstract': 'Large Vision-Language Models (LVLMs) or multimodal large language models represent a significant advancement in artificial intelligence, enabling systems to understand and generate content across both visual and textual modalities. While large-scale pretraining has driven substantial progress, fine-tuning these models for aligning with human values or engaging in specific tasks or behaviors remains a critical challenge. Deep Reinforcement Learning (DRL) and Direct Preference Optimization (DPO) offer promising frameworks for this aligning process. While DRL enables models to optimize actions using reward signals instead of relying solely on supervised preference data, DPO directly aligns the policy with preferences, eliminating the need for an explicit reward model. This overview explores paradigms for fine-tuning LVLMs, highlighting how DRL and DPO techniques can be used to align models with human preferences and values, improve task performance, and enable adaptive multimodal interaction. We categorize key approaches, examine sources of preference data, reward signals, and discuss open challenges such as scalability, sample efficiency, continual learning, generalization, and safety. The goal is to provide a clear understanding of how DRL and DPO contribute to the evolution of robust and human-aligned LVLMs.', 'abstract_zh': '大规模多模态语言模型：通过深度强化学习和直接偏好优化实现人类价值观对齐', 'title_zh': '通过深度强化学习和直接偏好优化对 largVision-语言模型进行对齐'}
{'arxiv_id': 'arXiv:2509.06213', 'title': 'Toward a Metrology for Artificial Intelligence: Hidden-Rule Environments and Reinforcement Learning', 'authors': 'Christo Mathew, Wentian Wang, Lazaros Gallos, Paul Kantor, Vladimir Menkov, Hao Wang', 'link': 'https://arxiv.org/abs/2509.06213', 'abstract': 'We investigate reinforcement learning in the Game Of Hidden Rules (GOHR) environment, a complex puzzle in which an agent must infer and execute hidden rules to clear a 6$\\times$6 board by placing game pieces into buckets. We explore two state representation strategies, namely Feature-Centric (FC) and Object-Centric (OC), and employ a Transformer-based Advantage Actor-Critic (A2C) algorithm for training. The agent has access only to partial observations and must simultaneously infer the governing rule and learn the optimal policy through experience. We evaluate our models across multiple rule-based and trial-list-based experimental setups, analyzing transfer effects and the impact of representation on learning efficiency.', 'abstract_zh': '我们研究了在Game Of Hidden Rules (GOHR) 环境中的强化学习，GOHR 是一个复杂的谜题，在其中智能体必须推断并执行隐藏规则，通过将游戏部件放入桶中来清理一个 6×6 的板。我们探索了两种状态表示策略，即特征中心化（FC）和对象中心化（OC），并使用基于Transformer 的优势演员评论家（A2C）算法进行训练。智能体只能访问部分观察信息，并且必须同时推断支配规则并通过对经验的学习来学习最优策略。我们在多个基于规则和试验列表的实验设置中评估了我们的模型，分析了迁移效应以及表示对学习效率的影响。', 'title_zh': '面向人工智能的度量标准研究：隐藏规则环境与强化学习'}
{'arxiv_id': 'arXiv:2509.06201', 'title': 'Grasp-MPC: Closed-Loop Visual Grasping via Value-Guided Model Predictive Control', 'authors': 'Jun Yamada, Adithyavairavan Murali, Ajay Mandlekar, Clemens Eppner, Ingmar Posner, Balakumar Sundaralingam', 'link': 'https://arxiv.org/abs/2509.06201', 'abstract': 'Grasping of diverse objects in unstructured environments remains a significant challenge. Open-loop grasping methods, effective in controlled settings, struggle in cluttered environments. Grasp prediction errors and object pose changes during grasping are the main causes of failure. In contrast, closed-loop methods address these challenges in simplified settings (e.g., single object on a table) on a limited set of objects, with no path to generalization. We propose Grasp-MPC, a closed-loop 6-DoF vision-based grasping policy designed for robust and reactive grasping of novel objects in cluttered environments. Grasp-MPC incorporates a value function, trained on visual observations from a large-scale synthetic dataset of 2 million grasp trajectories that include successful and failed attempts. We deploy this learned value function in an MPC framework in combination with other cost terms that encourage collision avoidance and smooth execution. We evaluate Grasp-MPC on FetchBench and real-world settings across diverse environments. Grasp-MPC improves grasp success rates by up to 32.6% in simulation and 33.3% in real-world noisy conditions, outperforming open-loop, diffusion policy, transformer policy, and IQL approaches. Videos and more at this http URL.', 'abstract_zh': '在未结构化环境中抓取多样物体仍是一项重大挑战。闭环方法在简化设置（如桌面上的单个物体）和少量物体上解决了开环方法在杂乱环境中难以应对的问题，但缺乏泛化途径。我们提出了一种名为Grasp-MPC的闭环6自由度基于视觉的抓取策略，旨在在杂乱环境中对新颖物体进行稳健和反应式的抓取。Grasp-MPC结合了一种在包含成功和失败尝试的大规模合成数据集的200万抓取轨迹上训练的价值函数。我们通过与鼓励碰撞避免和平滑执行的其他成本项结合，在MPC框架中部署了这一学习价值函数。我们在FetchBench和多种环境的真实世界设置中评估了Grasp-MPC。在模拟环境中，Grasp-MPC的抓取成功率提高了32.6%，在真实世界的嘈杂条件下提高了33.3%，优于开环、扩散策略、变压器策略和IQL方法。更多内容请访问此链接。', 'title_zh': '抓取-MPC：基于价值导向模型预测控制的闭环视觉抓取'}
{'arxiv_id': 'arXiv:2509.06169', 'title': 'Reasoning Language Model for Personalized Lung Cancer Screening', 'authors': 'Chuang Niu, Ge Wang', 'link': 'https://arxiv.org/abs/2509.06169', 'abstract': 'Accurate risk assessment in lung cancer screening is critical for enabling early cancer detection and minimizing unnecessary invasive procedures. The Lung CT Screening Reporting and Data System (Lung-RADS) has been widely used as the standard framework for patient management and follow-up. Nevertheless, Lung-RADS faces trade-offs between sensitivity and specificity, as it stratifies risk solely based on lung nodule characteristics without incorporating various risk factors. Here we propose a reasoning language model (RLM) to integrate radiology findings with longitudinal medical records for individualized lung cancer risk assessment. Through a systematic study including dataset construction and distillation, supervised fine-tuning, reinforcement learning, and comprehensive evaluation, our model makes significant improvements in risk prediction performance on datasets in the national lung screening trial. Notably, RLM can decompose the risk evaluation task into sub-components, analyze the contributions of diverse risk factors, and synthesize them into a final risk score computed using our data-driven system equation. Our approach improves both predictive accuracy and monitorability through the chain of thought reasoning process, thereby facilitating clinical translation into lung cancer screening.', 'abstract_zh': '准确的肺癌筛查风险评估对于早期癌症检测和减少不必要的侵入性程序至关重要。肺部CT筛查报告和数据系统（Lung-RADS）已被广泛用作患者管理与随访的标准框架，然而，Lung-RADS在敏感性和特异性之间存在权衡，因为它仅根据肺结节特征进行风险分层，而不考虑多种风险因素。为此，我们提出了一种推理语言模型（RLM），将放射学发现与 longitudinal 医疗记录相结合，进行个性化肺癌风险评估。通过包括数据集构建与提炼、监督微调、强化学习和综合评价在内的系统研究，我们的模型在国家肺癌筛查试验数据集中的风险预测性能取得了显著提升。值得注意的是，RLM能够将风险评估任务分解为子组件，分析多种风险因素的贡献，并将它们综合成一个最终的风险评分，该评分由我们数据驱动的系统方程计算得出。我们的方法通过推理过程改进了预测准确性和监控性，从而促进了肺癌筛查中的临床转化。', 'title_zh': '个性化肺癌筛查的推理语言模型'}
{'arxiv_id': 'arXiv:2509.06094', 'title': 'Teaching Precommitted Agents: Model-Free Policy Evaluation and Control in Quasi-Hyperbolic Discounted MDPs', 'authors': 'S.R. Eshwar', 'link': 'https://arxiv.org/abs/2509.06094', 'abstract': 'Time-inconsistent preferences, where agents favor smaller-sooner over larger-later rewards, are a key feature of human and animal decision-making. Quasi-Hyperbolic (QH) discounting provides a simple yet powerful model for this behavior, but its integration into the reinforcement learning (RL) framework has been limited. This paper addresses key theoretical and algorithmic gaps for precommitted agents with QH preferences. We make two primary contributions: (i) we formally characterize the structure of the optimal policy, proving for the first time that it reduces to a simple one-step non-stationary form; and (ii) we design the first practical, model-free algorithms for both policy evaluation and Q-learning in this setting, both with provable convergence guarantees. Our results provide foundational insights for incorporating QH preferences in RL.', 'abstract_zh': '时间不一致偏好，其中 Agents 更偏好较小较早的奖励而非较大较晚的奖励，是人类和动物决策的重要特征。接近指数折现 (Quasi-Hyperbolic, QH) 提供了一个简单而强大的模型来解释这种行为，但将其整合进强化学习 (Reinforcement Learning, RL) 框架中仍存在限制。本文针对具有 QH 偏好的预承诺代理的关键理论和算法缺口进行了探讨。我们做出了两项主要贡献：(i) 我们正式刻画了最优策略的结构，首次证明其简化为单一非稳态一步形式；(ii) 我们设计了首个适用于此情境的实际无模型策略评估和 Q 学习算法，并提供了收敛性保证。我们的结果为在 RL 中整合 QH 偏好提供了基础性洞见。', 'title_zh': '前瞻承诺代理的教学：准_hyperbolic 折扣MDP中的模型_free策略评估与控制'}
{'arxiv_id': 'arXiv:2509.05732', 'title': 'Simulation Priors for Data-Efficient Deep Learning', 'authors': 'Lenart Treven, Bhavya Sukhija, Jonas Rothfuss, Stelian Coros, Florian Dörfler, Andreas Krause', 'link': 'https://arxiv.org/abs/2509.05732', 'abstract': "How do we enable AI systems to efficiently learn in the real-world? First-principles models are widely used to simulate natural systems, but often fail to capture real-world complexity due to simplifying assumptions. In contrast, deep learning approaches can estimate complex dynamics with minimal assumptions but require large, representative datasets. We propose SimPEL, a method that efficiently combines first-principles models with data-driven learning by using low-fidelity simulators as priors in Bayesian deep learning. This enables SimPEL to benefit from simulator knowledge in low-data regimes and leverage deep learning's flexibility when more data is available, all the while carefully quantifying epistemic uncertainty. We evaluate SimPEL on diverse systems, including biological, agricultural, and robotic domains, showing superior performance in learning complex dynamics. For decision-making, we demonstrate that SimPEL bridges the sim-to-real gap in model-based reinforcement learning. On a high-speed RC car task, SimPEL learns a highly dynamic parking maneuver involving drifting with substantially less data than state-of-the-art baselines. These results highlight the potential of SimPEL for data-efficient learning and control in complex real-world environments.", 'abstract_zh': '如何使AI系统在实际环境中高效学习？SimPEL：结合基础原理模型与数据驱动学习的方法', 'title_zh': '数据高效的深度学习的模拟先验'}
{'arxiv_id': 'arXiv:2509.05728', 'title': 'LiDAR-BIND-T: Improving SLAM with Temporally Consistent Cross-Modal LiDAR Reconstruction', 'authors': 'Niels Balemans, Ali Anwar, Jan Steckel, Siegfried Mercelis', 'link': 'https://arxiv.org/abs/2509.05728', 'abstract': 'This paper extends LiDAR-BIND, a modular multi-modal fusion framework that binds heterogeneous sensors (radar, sonar) to a LiDAR-defined latent space, with mechanisms that explicitly enforce temporal consistency. We introduce three contributions: (i) temporal embedding similarity that aligns consecutive latents, (ii) a motion-aligned transformation loss that matches displacement between predictions and ground truth LiDAR, and (iii) windows temporal fusion using a specialised temporal module. We further update the model architecture to better preserve spatial structure. Evaluations on radar/sonar-to-LiDAR translation demonstrate improved temporal and spatial coherence, yielding lower absolute trajectory error and better occupancy map accuracy in Cartographer-based SLAM (Simultaneous Localisation and Mapping). We propose different metrics based on the Fréchet Video Motion Distance (FVMD) and a correlation-peak distance metric providing practical temporal quality indicators to evaluate SLAM performance. The proposed temporal LiDAR-BIND, or LiDAR-BIND-T, maintains plug-and-play modality fusion while substantially enhancing temporal stability, resulting in improved robustness and performance for downstream SLAM.', 'abstract_zh': '本文将LiDAR-BIND扩展为一种模块化的多模态融合框架，该框架将雷达和声纳等异构传感器绑定到由LiDAR定义的潜在空间中，并通过显式机制确保时间一致性。我们引入了三项贡献：（i）时间嵌入相似性，使连续的潜在变量对齐；（ii）运动对齐变换损失，匹配预测值和地面实测LiDAR之间的位移；（iii）使用专门的时间模块进行窗口时间融合。我们进一步更新了模型架构，以更好地保留空间结构。在雷达/声纳到LiDAR的转换评估中，展示了改进的时间一致性和空间一致性，得到了更低的绝对轨迹误差和更好的Occupancy地图精度，在基于Cartographer的SLAM中。我们提出了基于Fréchet视频运动距离（FVMD）和相关峰距离度量的不同指标，用以评估基于SLAM的性能的时间质量。提出的时序LiDAR-BIND，或LiDAR-BIND-T，在保持即插即用模态融合的同时，显著增强了时间稳定性，从而提高了下游SLAM的鲁棒性和性能。', 'title_zh': 'LiDAR-BIND-T：通过具有一致时序的跨模态LiDAR重建改善SLAM'}
{'arxiv_id': 'arXiv:2509.05333', 'title': 'RT-VLM: Re-Thinking Vision Language Model with 4-Clues for Real-World Object Recognition Robustness', 'authors': 'Junghyun Park, Tuan Anh Nguyen, Dugki Min', 'link': 'https://arxiv.org/abs/2509.05333', 'abstract': 'Real world deployments often expose modern object recognition models to domain shifts that precipitate a severe drop in accuracy. Such shifts encompass (i) variations in low level image statistics, (ii) changes in object pose and viewpoint, (iii) partial occlusion, and (iv) visual confusion across adjacent classes. To mitigate this degradation, we introduce the Re-Thinking Vision Language Model (RT-VLM) framework. The foundation of this framework is a unique synthetic dataset generation pipeline that produces images annotated with "4-Clues": precise bounding boxes, class names, detailed object-level captions, and a comprehensive context-level caption for the entire scene. We then perform parameter efficient supervised tuning of Llama 3.2 11B Vision Instruct on this resource. At inference time, a two stage Re-Thinking scheme is executed: the model first emits its own four clues, then re examines these responses as evidence and iteratively corrects them. Across robustness benchmarks that isolate individual domain shifts, RT-VLM consistently surpasses strong baselines. These findings indicate that the integration of structured multimodal evidence with an explicit self critique loop constitutes a promising route toward reliable and transferable visual understanding.', 'abstract_zh': 'Real World Deployments Often Expose Modern Object Recognition Models to Domain Shifts That Precipitate a Severe Drop in Accuracy: The Re-Thinking Vision Language Model (RT-VLM) Framework', 'title_zh': 'RT-VLM: 重新思考具有4线索的视觉语言模型以提高现实世界物体识别 robustness'}
{'arxiv_id': 'arXiv:2509.05332', 'title': 'Integrated Simulation Framework for Adversarial Attacks on Autonomous Vehicles', 'authors': 'Christos Anagnostopoulos, Ioulia Kapsali, Alexandros Gkillas, Nikos Piperigkos, Aris S. Lalos', 'link': 'https://arxiv.org/abs/2509.05332', 'abstract': "Autonomous vehicles (AVs) rely on complex perception and communication systems, making them vulnerable to adversarial attacks that can compromise safety. While simulation offers a scalable and safe environment for robustness testing, existing frameworks typically lack comprehensive supportfor modeling multi-domain adversarial scenarios. This paper introduces a novel, open-source integrated simulation framework designed to generate adversarial attacks targeting both perception and communication layers of AVs. The framework provides high-fidelity modeling of physical environments, traffic dynamics, and V2X networking, orchestrating these components through a unified core that synchronizes multiple simulators based on a single configuration file. Our implementation supports diverse perception-level attacks on LiDAR sensor data, along with communication-level threats such as V2X message manipulation and GPS spoofing. Furthermore, ROS 2 integration ensures seamless compatibility with third-party AV software stacks. We demonstrate the framework's effectiveness by evaluating the impact of generated adversarial scenarios on a state-of-the-art 3D object detector, revealing significant performance degradation under realistic conditions.", 'abstract_zh': '自主驾驶车辆（AVs）依赖复杂的感知和通信系统，使其容易受到攻击，这些攻击会损害安全性。尽管模拟提供了可扩展且安全的环境来进行鲁棒性测试，但现有框架通常缺乏全面支持多域 adversarial 场景建模的能力。本文介绍了一种新型的开源集成模拟框架，旨在针对AVs的感知和通信层生成 adversarial 攻击。该框架提供了对物理环境、交通动态和V2X网络的高保真建模，并通过一个统一的核心组件协调这些组件，该组件基于一个单一的配置文件进行同步。我们的实现支持对激光雷达传感器数据的各种感知层攻击，以及消息操纵和GPS欺骗等通信层威胁。此外，ROS 2 集成确保了与第三方AV软件堆栈的无缝兼容性。通过评估所生成的 adversarial 场景对最先进的3D物体检测器的影响，展示了该框架的有效性，在实际条件下显示出显著的性能退化。', 'title_zh': '面向自动驾驶车辆对抗攻击的集成仿真框架'}
{'arxiv_id': 'arXiv:2509.05298', 'title': 'Livia: An Emotion-Aware AR Companion Powered by Modular AI Agents and Progressive Memory Compression', 'authors': 'Rui Xi, Xianghan Wang', 'link': 'https://arxiv.org/abs/2509.05298', 'abstract': "Loneliness and social isolation pose significant emotional and health challenges, prompting the development of technology-based solutions for companionship and emotional support. This paper introduces Livia, an emotion-aware augmented reality (AR) companion app designed to provide personalized emotional support by combining modular artificial intelligence (AI) agents, multimodal affective computing, progressive memory compression, and AR driven embodied interaction. Livia employs a modular AI architecture with specialized agents responsible for emotion analysis, dialogue generation, memory management, and behavioral orchestration, ensuring robust and adaptive interactions. Two novel algorithms-Temporal Binary Compression (TBC) and Dynamic Importance Memory Filter (DIMF)-effectively manage and prioritize long-term memory, significantly reducing storage requirements while retaining critical context. Our multimodal emotion detection approach achieves high accuracy, enhancing proactive and empathetic engagement. User evaluations demonstrated increased emotional bonds, improved satisfaction, and statistically significant reductions in loneliness. Users particularly valued Livia's adaptive personality evolution and realistic AR embodiment. Future research directions include expanding gesture and tactile interactions, supporting multi-user experiences, and exploring customized hardware implementations.", 'abstract_zh': '孤独和社会隔离对情感和健康造成重大挑战，促使开发基于技术的解决方案以提供陪伴和情感支持。本文介绍了Livia，一款情感感知增强现实（AR）伴侣应用程序，通过模块化人工智能量子、多模态情感计算、渐进式记忆压缩和AR驱动的实体互动相结合，提供个性化的情感支持。Livia采用模块化AI架构，各专门代理负责情绪分析、对话生成、记忆管理和行为编排，确保强大的适应性互动。两种新型算法——时间二进制压缩（TBC）和动态重要性记忆过滤器（DIMF）——有效管理并优先处理长期记忆，显著减少存储需求同时保留关键背景。我们的多模态情绪检测方法达到了高精度，增强了主动和同理心的参与度。用户评估显示，情感纽带增强，满意度提高，并且孤独感有统计学意义上的显著减少。用户特别重视Livia的适应性个性演变和逼真的AR表现。未来的研究方向包括扩展手势和触觉交互、支持多用户体验以及探索定制硬件实现。', 'title_zh': 'Liviana：一种基于模块化AI代理和渐进式内存压缩的情感感知AR伴侣'}
{'arxiv_id': 'arXiv:2508.11849', 'title': 'LocoMamba: Vision-Driven Locomotion via End-to-End Deep Reinforcement Learning with Mamba', 'authors': 'Yinuo Wang, Gavin Tao', 'link': 'https://arxiv.org/abs/2508.11849', 'abstract': 'We introduce LocoMamba, a vision-driven cross-modal DRL framework built on selective state-space models, specifically leveraging Mamba, that achieves near-linear-time sequence modeling, effectively captures long-range dependencies, and enables efficient training with longer sequences. First, we embed proprioceptive states with a multilayer perceptron and patchify depth images with a lightweight convolutional neural network, producing compact tokens that improve state representation. Second, stacked Mamba layers fuse these tokens via near-linear-time selective scanning, reducing latency and memory footprint, remaining robust to token length and image resolution, and providing an inductive bias that mitigates overfitting. Third, we train the policy end-to-end with Proximal Policy Optimization under terrain and appearance randomization and an obstacle-density curriculum, using a compact state-centric reward that balances progress, smoothness, and safety. We evaluate our method in challenging simulated environments with static and moving obstacles as well as uneven terrain. Compared with state-of-the-art baselines, our method achieves higher returns and success rates with fewer collisions, exhibits stronger generalization to unseen terrains and obstacle densities, and improves training efficiency by converging in fewer updates under the same compute budget.', 'abstract_zh': 'LocoMamba：一种基于选择性状态空间模型的视觉导向跨模态DRL框架', 'title_zh': 'LocoMamba：通过盲视运动的端到端深度强化学习'}
{'arxiv_id': 'arXiv:2505.00275', 'title': 'AdCare-VLM: Leveraging Large Vision Language Model (LVLM) to Monitor Long-Term Medication Adherence and Care', 'authors': 'Md Asaduzzaman Jabin, Hanqi Jiang, Yiwei Li, Patrick Kaggwa, Eugene Douglass, Juliet N. Sekandi, Tianming Liu', 'link': 'https://arxiv.org/abs/2505.00275', 'abstract': "Chronic diseases, including diabetes, hypertension, asthma, HIV-AIDS, epilepsy, and tuberculosis, necessitate rigorous adherence to medication to avert disease progression, manage symptoms, and decrease mortality rates. Adherence is frequently undermined by factors including patient behavior, caregiver support, elevated medical costs, and insufficient healthcare infrastructure. We propose AdCare-VLM, a specialized Video-LLaVA-based multimodal large vision language model (LVLM) aimed at visual question answering (VQA) concerning medication adherence through patient videos. We employ a private dataset comprising 806 custom-annotated tuberculosis (TB) medication monitoring videos, which have been labeled by clinical experts, to fine-tune the model for adherence pattern detection. We present LLM-TB-VQA, a detailed medical adherence VQA dataset that encompasses positive, negative, and ambiguous adherence cases. Our method identifies correlations between visual features, such as the clear visibility of the patient's face, medication, water intake, and the act of ingestion, and their associated medical concepts in captions. This facilitates the integration of aligned visual-linguistic representations and improves multimodal interactions. Experimental results indicate that our method surpasses parameter-efficient fine-tuning (PEFT) enabled VLM models, such as LLaVA-V1.5 and Chat-UniVi, with absolute improvements ranging from 3.1% to 3.54% across pre-trained, regular, and low-rank adaptation (LoRA) configurations. Comprehensive ablation studies and attention map visualizations substantiate our approach, enhancing interpretability.", 'abstract_zh': '慢性疾病（包括糖尿病、高血压、哮喘、HIV/AIDS、癫痫和结核病）需要严格遵守药物治疗以防止疾病进展、管理症状并降低死亡率。依从性常因患者行为、护理支持不足、医疗成本上升以及卫生基础设施不足等因素而受到阻碍。我们提出AdCare-VLM，这是一种专门基于Video-LLaVA的多模态大型视觉语言模型（LVLM），旨在通过患者的视频进行用药依从性的视觉问答（VQA）。我们使用包含806个由临床专家标注的结核病（TB）药物监控视频的私人数据集对模型进行微调，以检测用药依从性模式。我们提供了LLM-TB-VQA，这是一种详细的医疗依从性VQA数据集，包含了正面、负面和模棱两可的用药依从性案例。我们的方法识别了视觉特征（如患者面部、药物、饮水和吞咽等行为）与其相关医学概念之间的关联，促进了视觉-语言表示的对齐，并改善了多模态交互。实验结果表明，我们的方法优于参数高效微调（PEFT）启用的VLM模型，如LLaVA-V1.5和Chat-UniVi，绝对改进率在预训练、常规和低秩适应（LoRA）配置中分别为3.1%至3.54%。全面的消融研究和注意力图可视化证实了我们的方法，增强了可解释性。', 'title_zh': 'AdCare-VLM: 利用大型ビジョン言語モデル监控长期用药依从性和护理'}
