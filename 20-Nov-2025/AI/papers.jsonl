{'arxiv_id': 'arXiv:2511.15593', 'title': 'What Does It Take to Be a Good AI Research Agent? Studying the Role of Ideation Diversity', 'authors': 'Alexis Audran-Reiss, Jordi Armengol Estapé, Karen Hambardzumyan, Amar Budhiraja, Martin Josifoski, Edan Toledo, Rishi Hazra, Despoina Magka, Michael Shvartsman, Parth Pathak, Justine T Kao, Lucia Cipolina-Kun, Bhavul Gauri, Jean-Christophe Gagnon-Audet, Emanuel Tewolde, Jenny Zhang, Taco Cohen, Yossi Adi, Tatiana Shavrina, Yoram Bachrach', 'link': 'https://arxiv.org/abs/2511.15593', 'abstract': 'AI research agents offer the promise to accelerate scientific progress by automating the design, implementation, and training of machine learning models. However, the field is still in its infancy, and the key factors driving the success or failure of agent trajectories are not fully understood. We examine the role that ideation diversity plays in agent performance. First, we analyse agent trajectories on MLE-bench, a well-known benchmark to evaluate AI research agents, across different models and agent scaffolds. Our analysis reveals that different models and agent scaffolds yield varying degrees of ideation diversity, and that higher-performing agents tend to have increased ideation diversity. Further, we run a controlled experiment where we modify the degree of ideation diversity, demonstrating that higher ideation diversity results in stronger performance. Finally, we strengthen our results by examining additional evaluation metrics beyond the standard medal-based scoring of MLE-bench, showing that our findings still hold across other agent performance metrics.', 'abstract_zh': 'AI研究代理通过自动化机器学习模型的设计、实现和训练，有望加速科学进步。然而，该领域仍处于初级阶段，驱动代理轨迹成功或失败的关键因素尚未完全理解。我们考察了创意多样性在代理性能中的作用。首先，我们分析了AI研究代理在MLE-bench上的表现，这是评估AI研究代理的一个知名基准，涵盖了不同模型和代理支架。我们的分析揭示了不同模型和代理支架在创意多样性方面存在差异，并且高绩效代理通常具有更高的创意多样性。此外，我们在受控实验中调整创意多样性的程度，表明更高的创意多样性可以提升性能。最后，我们通过考察超越MLE-bench标准奖牌评分的其他评估指标进一步强化了我们的结果，证实我们的发现仍适用于其他代理性能指标。', 'title_zh': '成为优秀的AI研究代理需要什么？探究构想多样性的作用'}
{'arxiv_id': 'arXiv:2511.15593', 'title': 'What Does It Take to Be a Good AI Research Agent? Studying the Role of Ideation Diversity', 'authors': 'Alexis Audran-Reiss, Jordi Armengol Estapé, Karen Hambardzumyan, Amar Budhiraja, Martin Josifoski, Edan Toledo, Rishi Hazra, Despoina Magka, Michael Shvartsman, Parth Pathak, Justine T Kao, Lucia Cipolina-Kun, Bhavul Gauri, Jean-Christophe Gagnon-Audet, Emanuel Tewolde, Jenny Zhang, Taco Cohen, Yossi Adi, Tatiana Shavrina, Yoram Bachrach', 'link': 'https://arxiv.org/abs/2511.15593', 'abstract': 'AI research agents offer the promise to accelerate scientific progress by automating the design, implementation, and training of machine learning models. However, the field is still in its infancy, and the key factors driving the success or failure of agent trajectories are not fully understood. We examine the role that ideation diversity plays in agent performance. First, we analyse agent trajectories on MLE-bench, a well-known benchmark to evaluate AI research agents, across different models and agent scaffolds. Our analysis reveals that different models and agent scaffolds yield varying degrees of ideation diversity, and that higher-performing agents tend to have increased ideation diversity. Further, we run a controlled experiment where we modify the degree of ideation diversity, demonstrating that higher ideation diversity results in stronger performance. Finally, we strengthen our results by examining additional evaluation metrics beyond the standard medal-based scoring of MLE-bench, showing that our findings still hold across other agent performance metrics.', 'abstract_zh': 'AI研究代理通过自动化机器学习模型的设计、实现和训练，有望加速科学进步。然而，该领域仍处于起步阶段，驱动代理轨迹成功或失败的关键因素尚未完全理解。我们考察了创意多样性在代理性能中的作用。首先，我们在MLE-bench这一著名的评估AI研究代理的基准上分析不同模型和代理支架的代理轨迹。我们的分析显示，不同模型和代理支架产生不同水平的创意多样性，且高性能的代理通常具有更高的创意多样性。此外，我们在一个受控实验中修改了创意多样性的程度，表明更高的创意多样性会导致更强的性能。最后，我们通过探讨超越MLE-bench标准奖牌评分的额外评估指标，进一步强化了我们的结果，证明我们的发现仍然适用于其他代理性能指标。', 'title_zh': '优秀AI研究代理需要什么？探究构想多样性的作用'}
{'arxiv_id': 'arXiv:2511.15534', 'title': 'Exploring the use of AI authors and reviewers at Agents4Science', 'authors': 'Federico Bianchi, Owen Queen, Nitya Thakkar, Eric Sun, James Zou', 'link': 'https://arxiv.org/abs/2511.15534', 'abstract': 'There is growing interest in using AI agents for scientific research, yet fundamental questions remain about their capabilities as scientists and reviewers. To explore these questions, we organized Agents4Science, the first conference in which AI agents serve as both primary authors and reviewers, with humans as co-authors and co-reviewers. Here, we discuss the key learnings from the conference and their implications for human-AI collaboration in science.', 'abstract_zh': '使用AI代理进行科学研究引起了越来越多的兴趣，但它们作为科学家和审稿人的能力基础问题依然存在。为了探索这些问题，我们组织了Agents4Science会议，这是第一次AI代理同时担任主要作者和审稿人，人类作为合作者和共同审稿人。在这里，我们讨论会议的关键收获及其对科学中人机合作的影响。', 'title_zh': '探索AI作者和审稿人在美国科学代理机构中的应用'}
{'arxiv_id': 'arXiv:2511.15534', 'title': 'Exploring the use of AI authors and reviewers at Agents4Science', 'authors': 'Federico Bianchi, Owen Queen, Nitya Thakkar, Eric Sun, James Zou', 'link': 'https://arxiv.org/abs/2511.15534', 'abstract': 'There is growing interest in using AI agents for scientific research, yet fundamental questions remain about their capabilities as scientists and reviewers. To explore these questions, we organized Agents4Science, the first conference in which AI agents serve as both primary authors and reviewers, with humans as co-authors and co-reviewers. Here, we discuss the key learnings from the conference and their implications for human-AI collaboration in science.', 'abstract_zh': 'AI代理在科学研究中的应用引起越来越多的兴趣，然而关于其作为科学家和审稿人的能力的基本问题仍然存在。为了探索这些问题，我们组织了Agents4Science conference，这是首次让AI代理同时担任主要作者和审稿人，人类作为共同作者和共同审稿人参与。在这里，我们将讨论该会议的关键见解及其对科学研究中的人机协作的影响。', 'title_zh': '探索AI作者和审稿人在Agents4Science中的应用'}
{'arxiv_id': 'arXiv:2511.15593', 'title': 'What Does It Take to Be a Good AI Research Agent? Studying the Role of Ideation Diversity', 'authors': 'Alexis Audran-Reiss, Jordi Armengol Estapé, Karen Hambardzumyan, Amar Budhiraja, Martin Josifoski, Edan Toledo, Rishi Hazra, Despoina Magka, Michael Shvartsman, Parth Pathak, Justine T Kao, Lucia Cipolina-Kun, Bhavul Gauri, Jean-Christophe Gagnon-Audet, Emanuel Tewolde, Jenny Zhang, Taco Cohen, Yossi Adi, Tatiana Shavrina, Yoram Bachrach', 'link': 'https://arxiv.org/abs/2511.15593', 'abstract': 'AI research agents offer the promise to accelerate scientific progress by automating the design, implementation, and training of machine learning models. However, the field is still in its infancy, and the key factors driving the success or failure of agent trajectories are not fully understood. We examine the role that ideation diversity plays in agent performance. First, we analyse agent trajectories on MLE-bench, a well-known benchmark to evaluate AI research agents, across different models and agent scaffolds. Our analysis reveals that different models and agent scaffolds yield varying degrees of ideation diversity, and that higher-performing agents tend to have increased ideation diversity. Further, we run a controlled experiment where we modify the degree of ideation diversity, demonstrating that higher ideation diversity results in stronger performance. Finally, we strengthen our results by examining additional evaluation metrics beyond the standard medal-based scoring of MLE-bench, showing that our findings still hold across other agent performance metrics.', 'abstract_zh': 'AI研究代理通过自动化机器学习模型的设计、实现和训练来加速科学进步，但该领域仍处于初级阶段，驱动代理轨迹成功或失败的关键因素尚不完全清楚。我们探讨了理念多样性的角色在代理性能中的作用。首先，我们在MLE-bench这一知名基准上分析不同模型和代理支架下的代理轨迹。我们的分析显示，不同的模型和代理支架会产生不同程度的理念多样性，且表现更好的代理往往具备更高的理念多样性。其次，我们进行了一项控制实验，调整理念多样性的程度，证明更高的理念多样性可以提升代理性能。最后，我们通过考察超越MLE-bench标准奖牌评分的其他评估指标来增强我们的结果，显示我们的发现仍然适用于其他代理性能指标。', 'title_zh': '成为一个优秀的AI研究代理需要什么？探究创意多样性的作用'}
{'arxiv_id': 'arXiv:2511.15456', 'title': 'Know Your Intent: An Autonomous Multi-Perspective LLM Agent Framework for DeFi User Transaction Intent Mining', 'authors': "Qian'ang Mao, Yuxuan Zhang, Jiaman Chen, Wenjun Zhou, Jiaqi Yan", 'link': 'https://arxiv.org/abs/2511.15456', 'abstract': 'As Decentralized Finance (DeFi) develops, understanding user intent behind DeFi transactions is crucial yet challenging due to complex smart contract interactions, multifaceted on-/off-chain factors, and opaque hex logs. Existing methods lack deep semantic insight. To address this, we propose the Transaction Intent Mining (TIM) framework. TIM leverages a DeFi intent taxonomy built on grounded theory and a multi-agent Large Language Model (LLM) system to robustly infer user intents. A Meta-Level Planner dynamically coordinates domain experts to decompose multiple perspective-specific intent analyses into solvable subtasks. Question Solvers handle the tasks with multi-modal on/off-chain data. While a Cognitive Evaluator mitigates LLM hallucinations and ensures verifiability. Experiments show that TIM significantly outperforms machine learning models, single LLMs, and single Agent baselines. We also analyze core challenges in intent inference. This work helps provide a more reliable understanding of user motivations in DeFi, offering context-aware explanations for complex blockchain activity.', 'abstract_zh': '随着去中心化金融（DeFi）的发展，理解DeFi交易背后的用户意图由于复杂的智能合约交互、多方面的链上/链下因素以及不透明的十六进制日志而变得至关重要且具有挑战性。现有方法缺乏深入的语义洞察。为此，我们提出了交易意图挖掘（TIM）框架。TIM利用基于扎根理论构建的DeFi意图分类框架和多agent大型语言模型系统，以 robust地推断用户意图。元级规划师动态协调领域专家，将多视角的具体意图分析分解为可解决的子任务。问题求解器使用多模态链上/链下数据处理任务。认知评估器则减轻了大型语言模型的幻觉，确保了可验证性。实验表明，TIM显著优于机器学习模型、单一的大规模语言模型以及单一智能体基线。我们还分析了意图推断的核心挑战。这项工作有助于提供对DeFi中用户动机更可靠的理解，提供对复杂区块链活动的上下文感知解释。', 'title_zh': '了解你的意图：一种自主多视角LLM代理框架，用于DeFi用户交易意图挖掘'}
{'arxiv_id': 'arXiv:2511.15534', 'title': 'Exploring the use of AI authors and reviewers at Agents4Science', 'authors': 'Federico Bianchi, Owen Queen, Nitya Thakkar, Eric Sun, James Zou', 'link': 'https://arxiv.org/abs/2511.15534', 'abstract': 'There is growing interest in using AI agents for scientific research, yet fundamental questions remain about their capabilities as scientists and reviewers. To explore these questions, we organized Agents4Science, the first conference in which AI agents serve as both primary authors and reviewers, with humans as co-authors and co-reviewers. Here, we discuss the key learnings from the conference and their implications for human-AI collaboration in science.', 'abstract_zh': 'AI代理在科学研究中的应用：人类与AI的合作探讨', 'title_zh': '探索AI作者和评审员在Agents4Science中的应用'}
{'arxiv_id': 'arXiv:2511.15456', 'title': 'Know Your Intent: An Autonomous Multi-Perspective LLM Agent Framework for DeFi User Transaction Intent Mining', 'authors': "Qian'ang Mao, Yuxuan Zhang, Jiaman Chen, Wenjun Zhou, Jiaqi Yan", 'link': 'https://arxiv.org/abs/2511.15456', 'abstract': 'As Decentralized Finance (DeFi) develops, understanding user intent behind DeFi transactions is crucial yet challenging due to complex smart contract interactions, multifaceted on-/off-chain factors, and opaque hex logs. Existing methods lack deep semantic insight. To address this, we propose the Transaction Intent Mining (TIM) framework. TIM leverages a DeFi intent taxonomy built on grounded theory and a multi-agent Large Language Model (LLM) system to robustly infer user intents. A Meta-Level Planner dynamically coordinates domain experts to decompose multiple perspective-specific intent analyses into solvable subtasks. Question Solvers handle the tasks with multi-modal on/off-chain data. While a Cognitive Evaluator mitigates LLM hallucinations and ensures verifiability. Experiments show that TIM significantly outperforms machine learning models, single LLMs, and single Agent baselines. We also analyze core challenges in intent inference. This work helps provide a more reliable understanding of user motivations in DeFi, offering context-aware explanations for complex blockchain activity.', 'abstract_zh': '基于分解智能的DeFi交易意图挖掘框架', 'title_zh': '了解你的意图：一个自治多视角LLM代理框架用于DeFi用户交易意图挖掘'}
{'arxiv_id': 'arXiv:2511.15407', 'title': 'IPR-1: Interactive Physical Reasoner', 'authors': 'Mingyu Zhang, Lifeng Zhuo, Tianxi Tan, Guocan Xie, Xian Nie, Yan Li, Renjie Zhao, Zizhu He, Ziyu Wang, Jiting Cai, Yong-Lu Li', 'link': 'https://arxiv.org/abs/2511.15407', 'abstract': "Humans learn by observing, interacting with environments, and internalizing physics and causality. Here, we aim to ask whether an agent can similarly acquire human-like reasoning from interaction and keep improving with more experience. We study this in a Game-to-Unseen (G2U) setting, curating 1,000+ heterogeneous games with diverse physical and causal mechanisms, and evaluate at three human-like levels: Survival, Curiosity, Utility, from primitive intuition to goal-driven reasoning. Our analysis reveals complementary failures: VLM/VLA agents reason but lack look-ahead in interactive settings, while world models imagine but imitate visual patterns rather than analyze physics and causality. We therefore propose IPR (Interactive Physical Reasoner), using world-model rollouts to score and reinforce a VLM's policy, and introduce PhysCode, a physics-centric action code aligning semantic intent with dynamics to provide a shared action space for prediction and reasoning. Pretrained on 1,000+ games, our IPR performs robustly on three levels, matches GPT-5 overall, and surpasses it on Curiosity. We find that performance improves with more training games and interaction steps, and that the model also zero-shot transfers to unseen games. These results support physics-centric interaction as a path to steadily improving physical reasoning.", 'abstract_zh': '人类通过观察、与环境互动并内化物理法则和因果关系来学习。这里，我们旨在探究智能体是否可以通过互动和积累经验类似地获得人类级别的推理能力。我们在此研究中采用Game-to-Unseen（G2U）设置，收集了1,000+种异构游戏，涵盖多样化的物理与因果机制，并从原始直觉到目标驱动推理的三个层次评估人类级别的表现：生存、好奇心、实用性。我们的分析揭示了互补的失败：基于视觉的语言模型/视觉抽象代理可以在互动环境中进行推理，但缺乏前瞻性；世界模型能够在心理上模拟但只是模仿视觉模式而非分析物理法则和因果关系。因此，我们提出了一种交互物理推理器（Interactive Physical Reasoner，IPR），采用世界模型的展开来评分并强化视觉语言模型的策略，并引入了以物理为中心的动作代码（PhysCode），将语义意图与动力学对齐以提供预测和推理的共享动作空间。我们基于1,000+个游戏的预训练，IPR在三个层次上表现 robust，在总体上匹配GPT-5，并在好奇心层次上超越它。我们发现，随着更多训练游戏和互动步骤数量的增加，模型在未见过的游戏上也具备零样本迁移能力。这些结果支持以物理为中心的互动是逐步提高物理推理能力的一个途径。', 'title_zh': 'IPR-1: 交互式物理推理器'}
{'arxiv_id': 'arXiv:2511.15456', 'title': 'Know Your Intent: An Autonomous Multi-Perspective LLM Agent Framework for DeFi User Transaction Intent Mining', 'authors': "Qian'ang Mao, Yuxuan Zhang, Jiaman Chen, Wenjun Zhou, Jiaqi Yan", 'link': 'https://arxiv.org/abs/2511.15456', 'abstract': 'As Decentralized Finance (DeFi) develops, understanding user intent behind DeFi transactions is crucial yet challenging due to complex smart contract interactions, multifaceted on-/off-chain factors, and opaque hex logs. Existing methods lack deep semantic insight. To address this, we propose the Transaction Intent Mining (TIM) framework. TIM leverages a DeFi intent taxonomy built on grounded theory and a multi-agent Large Language Model (LLM) system to robustly infer user intents. A Meta-Level Planner dynamically coordinates domain experts to decompose multiple perspective-specific intent analyses into solvable subtasks. Question Solvers handle the tasks with multi-modal on/off-chain data. While a Cognitive Evaluator mitigates LLM hallucinations and ensures verifiability. Experiments show that TIM significantly outperforms machine learning models, single LLMs, and single Agent baselines. We also analyze core challenges in intent inference. This work helps provide a more reliable understanding of user motivations in DeFi, offering context-aware explanations for complex blockchain activity.', 'abstract_zh': '面向DeFi交易的意图挖掘框架：应对复杂智能合约交互与多维度因素的挑战', 'title_zh': '了解你的意图：一种自主多视角LLM代理框架用于DeFi用户交易意图挖掘'}
{'arxiv_id': 'arXiv:2511.15407', 'title': 'IPR-1: Interactive Physical Reasoner', 'authors': 'Mingyu Zhang, Lifeng Zhuo, Tianxi Tan, Guocan Xie, Xian Nie, Yan Li, Renjie Zhao, Zizhu He, Ziyu Wang, Jiting Cai, Yong-Lu Li', 'link': 'https://arxiv.org/abs/2511.15407', 'abstract': "Humans learn by observing, interacting with environments, and internalizing physics and causality. Here, we aim to ask whether an agent can similarly acquire human-like reasoning from interaction and keep improving with more experience. We study this in a Game-to-Unseen (G2U) setting, curating 1,000+ heterogeneous games with diverse physical and causal mechanisms, and evaluate at three human-like levels: Survival, Curiosity, Utility, from primitive intuition to goal-driven reasoning. Our analysis reveals complementary failures: VLM/VLA agents reason but lack look-ahead in interactive settings, while world models imagine but imitate visual patterns rather than analyze physics and causality. We therefore propose IPR (Interactive Physical Reasoner), using world-model rollouts to score and reinforce a VLM's policy, and introduce PhysCode, a physics-centric action code aligning semantic intent with dynamics to provide a shared action space for prediction and reasoning. Pretrained on 1,000+ games, our IPR performs robustly on three levels, matches GPT-5 overall, and surpasses it on Curiosity. We find that performance improves with more training games and interaction steps, and that the model also zero-shot transfers to unseen games. These results support physics-centric interaction as a path to steadily improving physical reasoning.", 'abstract_zh': '人类通过观察、与环境互动并内化物理和因果关系进行学习。在这里，我们旨在探究智能体是否可以类似地通过互动获取类似人类的推理能力，并随着经验的积累而持续改进。我们研究了Game-to-Unseen (G2U) 设置，在此设置中我们精心挑选了1,000多款异构游戏，涵盖多样的物理和因果机制，并从原始直觉到目标驱动的推理三个层面评估其表现。我们的分析揭示了互补性缺陷：VLM/VLA智能体可以在互动中进行推理，但缺乏前瞻性；世界模型可以想象但模仿的是视觉模式而非分析物理和因果关系。因此，我们提出了互动物理推理器（IPR），利用世界模型的展开来评估和强化VLM的策略，并引入了以物理为中心的动作代码（PhysCode），以语义意图与动力学的对齐来提供预测和推理的共享动作空间。该模型在1,000多款游戏中预训练，其在三个层面表现稳健，总体上与GPT-5相当，并在好奇心层面超越了它。我们发现，随着训练游戏数量增加及互动步骤增多，性能提升，并且模型也能零样本迁移至未见过的游戏。这些结果支持以物理为中心的互动作为持续改进物理推理的路径。', 'title_zh': 'IPR-1: 交互式物理推理器'}
{'arxiv_id': 'arXiv:2511.15378', 'title': 'Terra Nova: A Comprehensive Challenge Environment for Intelligent Agents', 'authors': 'Trevor McInroe', 'link': 'https://arxiv.org/abs/2511.15378', 'abstract': "We introduce Terra Nova, a new comprehensive challenge environment (CCE) for reinforcement learning (RL) research inspired by Civilization V. A CCE is a single environment in which multiple canonical RL challenges (e.g., partial observability, credit assignment, representation learning, enormous action spaces, etc.) arise simultaneously. Mastery therefore demands integrated, long-horizon understanding across many interacting variables. We emphasize that this definition excludes challenges that only aggregate unrelated tasks in independent, parallel streams (e.g., learning to play all Atari games at once). These aggregated multitask benchmarks primarily asses whether an agent can catalog and switch among unrelated policies rather than test an agent's ability to perform deep reasoning across many interacting challenges.", 'abstract_zh': '我们介绍Terra Nova：一种受文明V启发的新综合挑战环境（CCE）以促进强化学习（RL）研究', 'title_zh': 'Terra Nova：智能代理的全面挑战环境'}
{'arxiv_id': 'arXiv:2511.15407', 'title': 'IPR-1: Interactive Physical Reasoner', 'authors': 'Mingyu Zhang, Lifeng Zhuo, Tianxi Tan, Guocan Xie, Xian Nie, Yan Li, Renjie Zhao, Zizhu He, Ziyu Wang, Jiting Cai, Yong-Lu Li', 'link': 'https://arxiv.org/abs/2511.15407', 'abstract': "Humans learn by observing, interacting with environments, and internalizing physics and causality. Here, we aim to ask whether an agent can similarly acquire human-like reasoning from interaction and keep improving with more experience. We study this in a Game-to-Unseen (G2U) setting, curating 1,000+ heterogeneous games with diverse physical and causal mechanisms, and evaluate at three human-like levels: Survival, Curiosity, Utility, from primitive intuition to goal-driven reasoning. Our analysis reveals complementary failures: VLM/VLA agents reason but lack look-ahead in interactive settings, while world models imagine but imitate visual patterns rather than analyze physics and causality. We therefore propose IPR (Interactive Physical Reasoner), using world-model rollouts to score and reinforce a VLM's policy, and introduce PhysCode, a physics-centric action code aligning semantic intent with dynamics to provide a shared action space for prediction and reasoning. Pretrained on 1,000+ games, our IPR performs robustly on three levels, matches GPT-5 overall, and surpasses it on Curiosity. We find that performance improves with more training games and interaction steps, and that the model also zero-shot transfers to unseen games. These results support physics-centric interaction as a path to steadily improving physical reasoning.", 'abstract_zh': '人类通过观察、与环境互动并内化物理和因果关系来学习。在这里，我们旨在探索代理是否可以通过互动和积累经验来获得类似人类的推理能力并持续改进。我们研究这一问题是在Game-to-Unseen (G2U) 设置下，收集了1,000多款异质游戏，涵盖多种物理和因果机制，并从基础直觉到目标驱动的推理评估了三个类似人类的层次：生存、好奇心、实用性。我们的分析揭示了互为补充的失败：VLM/VLA代理可以推理但缺乏前瞻规划能力，在互动环境中；世界模型可以想象但模仿视觉模式而非分析物理和因果关系。因此，我们提出了一种交互物理推理器（IPR），使用世界模型的展开来评估并强化VLM的策略，并引入了以物理为中心的动作编码（PhysCode），使语义意图与动力学对齐，为预测和推理提供共享的动作空间。在1,000多款游戏中预训练，我们的IPR在三个层次上表现稳健，并在总体上匹配GPT-5，且在好奇心方面超越了它。我们发现性能随更多训练游戏和交互步骤的增加而提升，并且该模型也能零样本迁移至未见过的游戏。这些结果支持以物理为中心的交互作为持续提升物理推理表现的途径。', 'title_zh': 'IPR-1: 交互物理推理器'}
{'arxiv_id': 'arXiv:2511.15378', 'title': 'Terra Nova: A Comprehensive Challenge Environment for Intelligent Agents', 'authors': 'Trevor McInroe', 'link': 'https://arxiv.org/abs/2511.15378', 'abstract': "We introduce Terra Nova, a new comprehensive challenge environment (CCE) for reinforcement learning (RL) research inspired by Civilization V. A CCE is a single environment in which multiple canonical RL challenges (e.g., partial observability, credit assignment, representation learning, enormous action spaces, etc.) arise simultaneously. Mastery therefore demands integrated, long-horizon understanding across many interacting variables. We emphasize that this definition excludes challenges that only aggregate unrelated tasks in independent, parallel streams (e.g., learning to play all Atari games at once). These aggregated multitask benchmarks primarily asses whether an agent can catalog and switch among unrelated policies rather than test an agent's ability to perform deep reasoning across many interacting challenges.", 'abstract_zh': '我们介绍Terra Nova：一种受文明V启发的新全面挑战环境（CCE）以促进强化学习（RL）研究', 'title_zh': 'Terra Nova：智能代理的综合挑战环境'}
{'arxiv_id': 'arXiv:2511.15351', 'title': 'Octopus: Agentic Multimodal Reasoning with Six-Capability Orchestration', 'authors': 'Yifu Guo, Zishan Xu, Zhiyuan Yao, Yuquan Lu, Jiaye Lin, Sen Hu, Zhenheng Tang, Yingchao Li, Huacan Wang, Ronghao Chen', 'link': 'https://arxiv.org/abs/2511.15351', 'abstract': 'Existing multimodal reasoning models and frameworks suffer from fundamental architectural limitations: most lack the human-like ability to autonomously explore diverse reasoning pathways-whether in direct inference, tool-driven visual exploration, programmatic visual manipulation, or intrinsic visual imagination. Consequently, they struggle to adapt to dynamically changing capability requirements in real-world tasks. Meanwhile, humans exhibit a complementary set of thinking abilities when addressing such tasks, whereas existing methods typically cover only a subset of these dimensions. Inspired by this, we propose Octopus: Agentic Multimodal Reasoning with Six-Capability Orchestration, a new paradigm for multimodal agentic reasoning. We define six core capabilities essential for multimodal reasoning and organize a comprehensive evaluation benchmark, Octopus-Bench, accordingly. Octopus is capable of autonomously exploring during reasoning and dynamically selecting the most appropriate capability based on the current state. Experimental results show that Octopus achieves the best performance on the vast majority of tasks in Octopus-Bench, highlighting the crucial role of capability coordination in agentic multimodal reasoning.', 'abstract_zh': '基于六能力 orchestration 的自主多模态推理Octopus：自主多模态推理的新范式', 'title_zh': '八爪鱼：具备六种能力 orchestration 的自主多模态推理'}
{'arxiv_id': 'arXiv:2511.15378', 'title': 'Terra Nova: A Comprehensive Challenge Environment for Intelligent Agents', 'authors': 'Trevor McInroe', 'link': 'https://arxiv.org/abs/2511.15378', 'abstract': "We introduce Terra Nova, a new comprehensive challenge environment (CCE) for reinforcement learning (RL) research inspired by Civilization V. A CCE is a single environment in which multiple canonical RL challenges (e.g., partial observability, credit assignment, representation learning, enormous action spaces, etc.) arise simultaneously. Mastery therefore demands integrated, long-horizon understanding across many interacting variables. We emphasize that this definition excludes challenges that only aggregate unrelated tasks in independent, parallel streams (e.g., learning to play all Atari games at once). These aggregated multitask benchmarks primarily asses whether an agent can catalog and switch among unrelated policies rather than test an agent's ability to perform deep reasoning across many interacting challenges.", 'abstract_zh': '我们介绍Terra Nova：一种受文明V启发的新型综合挑战环境（CCE）以促进强化学习（RL）研究', 'title_zh': 'Terra Nova: 一个全面的智能代理挑战环境'}
{'arxiv_id': 'arXiv:2511.15351', 'title': 'Octopus: Agentic Multimodal Reasoning with Six-Capability Orchestration', 'authors': 'Yifu Guo, Zishan Xu, Zhiyuan Yao, Yuquan Lu, Jiaye Lin, Sen Hu, Zhenheng Tang, Yingchao Li, Huacan Wang, Ronghao Chen', 'link': 'https://arxiv.org/abs/2511.15351', 'abstract': 'Existing multimodal reasoning models and frameworks suffer from fundamental architectural limitations: most lack the human-like ability to autonomously explore diverse reasoning pathways-whether in direct inference, tool-driven visual exploration, programmatic visual manipulation, or intrinsic visual imagination. Consequently, they struggle to adapt to dynamically changing capability requirements in real-world tasks. Meanwhile, humans exhibit a complementary set of thinking abilities when addressing such tasks, whereas existing methods typically cover only a subset of these dimensions. Inspired by this, we propose Octopus: Agentic Multimodal Reasoning with Six-Capability Orchestration, a new paradigm for multimodal agentic reasoning. We define six core capabilities essential for multimodal reasoning and organize a comprehensive evaluation benchmark, Octopus-Bench, accordingly. Octopus is capable of autonomously exploring during reasoning and dynamically selecting the most appropriate capability based on the current state. Experimental results show that Octopus achieves the best performance on the vast majority of tasks in Octopus-Bench, highlighting the crucial role of capability coordination in agentic multimodal reasoning.', 'abstract_zh': '基于六大能力 orchestration 的自主多模态推理：Octopus：自主多模态推理的新范式', 'title_zh': '八爪鱼：六能力 orchestration 的自主多模态推理'}
{'arxiv_id': 'arXiv:2511.15282', 'title': 'Realist and Pluralist Conceptions of Intelligence and Their Implications on AI Research', 'authors': 'Ninell Oldenburg, Ruchira Dhar, Anders Søgaard', 'link': 'https://arxiv.org/abs/2511.15282', 'abstract': 'In this paper, we argue that current AI research operates on a spectrum between two different underlying conceptions of intelligence: Intelligence Realism, which holds that intelligence represents a single, universal capacity measurable across all systems, and Intelligence Pluralism, which views intelligence as diverse, context-dependent capacities that cannot be reduced to a single universal measure. Through an analysis of current debates in AI research, we demonstrate how the conceptions remain largely implicit yet fundamentally shape how empirical evidence gets interpreted across a wide range of areas. These underlying views generate fundamentally different research approaches across three areas. Methodologically, they produce different approaches to model selection, benchmark design, and experimental validation. Interpretively, they lead to contradictory readings of the same empirical phenomena, from capability emergence to system limitations. Regarding AI risk, they generate categorically different assessments: realists view superintelligence as the primary risk and search for unified alignment solutions, while pluralists see diverse threats across different domains requiring context-specific solutions. We argue that making explicit these underlying assumptions can contribute to a clearer understanding of disagreements in AI research.', 'abstract_zh': '当前人工智能研究处于两种不同的智能观念之间的谱系：智能现实主义和智能多元论之间：智能现实主义认为智能是一种跨所有系统均可衡量的单一普遍能力，而智能多元论则认为智能是多样且依赖于具体情境的能力，不可能归结为单一的普遍衡量标准。通过分析当前人工智能研究中的争论，我们表明这两种观念虽大多隐含却深刻影响了广泛领域内实证证据的解释。这些根本性的观点在三个领域中产生了截然不同的研究方法。方法上，它们导致了不同的模型选择、基准设计和实验验证的方法。在解释上，它们对同一实证现象给出了相互矛盾的解读，从能力涌现到系统限制均是如此。对于人工智能风险，这两种观念导致了根本不同的评估：现实主义者将超级智能视为主要风险，并寻求统一的对齐方案，而多元论者认为多样化的威胁分布在不同领域，需要情境特定的解决方案。我们认为，明确这些隐含的前提可以在人工智能研究中增进对分歧的理解。', 'title_zh': '实在论与pluralist智能观及其对AI研究的影响'}
{'arxiv_id': 'arXiv:2511.15351', 'title': 'Octopus: Agentic Multimodal Reasoning with Six-Capability Orchestration', 'authors': 'Yifu Guo, Zishan Xu, Zhiyuan Yao, Yuquan Lu, Jiaye Lin, Sen Hu, Zhenheng Tang, Yingchao Li, Huacan Wang, Ronghao Chen', 'link': 'https://arxiv.org/abs/2511.15351', 'abstract': 'Existing multimodal reasoning models and frameworks suffer from fundamental architectural limitations: most lack the human-like ability to autonomously explore diverse reasoning pathways-whether in direct inference, tool-driven visual exploration, programmatic visual manipulation, or intrinsic visual imagination. Consequently, they struggle to adapt to dynamically changing capability requirements in real-world tasks. Meanwhile, humans exhibit a complementary set of thinking abilities when addressing such tasks, whereas existing methods typically cover only a subset of these dimensions. Inspired by this, we propose Octopus: Agentic Multimodal Reasoning with Six-Capability Orchestration, a new paradigm for multimodal agentic reasoning. We define six core capabilities essential for multimodal reasoning and organize a comprehensive evaluation benchmark, Octopus-Bench, accordingly. Octopus is capable of autonomously exploring during reasoning and dynamically selecting the most appropriate capability based on the current state. Experimental results show that Octopus achieves the best performance on the vast majority of tasks in Octopus-Bench, highlighting the crucial role of capability coordination in agentic multimodal reasoning.', 'abstract_zh': '基于六能力 orchestrating 的自主多模态推理：Octopus 新范式', 'title_zh': '八爪鱼：六能力 orchestration 驱动的自主多模态推理'}
{'arxiv_id': 'arXiv:2511.15282', 'title': 'Realist and Pluralist Conceptions of Intelligence and Their Implications on AI Research', 'authors': 'Ninell Oldenburg, Ruchira Dhar, Anders Søgaard', 'link': 'https://arxiv.org/abs/2511.15282', 'abstract': 'In this paper, we argue that current AI research operates on a spectrum between two different underlying conceptions of intelligence: Intelligence Realism, which holds that intelligence represents a single, universal capacity measurable across all systems, and Intelligence Pluralism, which views intelligence as diverse, context-dependent capacities that cannot be reduced to a single universal measure. Through an analysis of current debates in AI research, we demonstrate how the conceptions remain largely implicit yet fundamentally shape how empirical evidence gets interpreted across a wide range of areas. These underlying views generate fundamentally different research approaches across three areas. Methodologically, they produce different approaches to model selection, benchmark design, and experimental validation. Interpretively, they lead to contradictory readings of the same empirical phenomena, from capability emergence to system limitations. Regarding AI risk, they generate categorically different assessments: realists view superintelligence as the primary risk and search for unified alignment solutions, while pluralists see diverse threats across different domains requiring context-specific solutions. We argue that making explicit these underlying assumptions can contribute to a clearer understanding of disagreements in AI research.', 'abstract_zh': '本文 argue了当前AI研究在两种不同的智能理念之间存在谱系：智能现实主义认为智能是一种可在所有系统中衡量的单一普遍能力，而智能多元主义则视智能为多样且依赖于具体情境的能力，无法归结为单一普遍标准。通过对当前AI研究争论的分析，我们展示了这些理念虽隐含却从根本上影响了广泛领域内实证证据的解释。这些根本观念在三个领域产生了不同的研究方法。方法论上，它们导致了模型选择、基准设计和实验验证的不同方法。解读者方面，它们对同一实证现象产生了矛盾的理解，从能力涌现到系统限制均如此。对于AI风险，它们产生了根本不同的评估：现实主义者将超级智能视为主要风险并寻求统一的对齐解决方案，多元主义者则认为不同领域存在多种特定情境的威胁。我们认为明确这些潜在假设有助于更清晰地理解AI研究中的分歧。', 'title_zh': '现实主义与多元主义的智能观念及其对AI研究的影响'}
{'arxiv_id': 'arXiv:2511.15259', 'title': 'Efficiency Will Not Lead to Sustainable Reasoning AI', 'authors': "Philipp Wiesner, Daniel W. O'Neill, Francesca Larosa, Odej Kao", 'link': 'https://arxiv.org/abs/2511.15259', 'abstract': "AI research is increasingly moving toward complex problem solving, where models are optimized not only for pattern recognition but for multi-step reasoning. Historically, computing's global energy footprint has been stabilized by sustained efficiency gains and natural saturation thresholds in demand. But as efficiency improvements are approaching physical limits, emerging reasoning AI lacks comparable saturation points: performance is no longer limited by the amount of available training data but continues to scale with exponential compute investments in both training and inference. This paper argues that efficiency alone will not lead to sustainable reasoning AI and discusses research and policy directions to embed explicit limits into the optimization and governance of such systems.", 'abstract_zh': 'AI研究 increasingly转向复杂问题解决，其中模型不仅优化模式识别，还优化多步推理。历史地看，计算的全球能耗足迹得益于持续的效率提升和天然的需求饱和阈值而保持稳定。但随着效率改进接近物理极限，新兴的推理AI缺乏类似的饱和点：性能不再受限于可用训练数据的数量，而是继续随着训练和推理的指数级计算投资而扩增。本文认为，仅靠效率无法实现可持续的推理AI，并讨论了将明确限制嵌入此类系统的优化和治理的研究和政策方向。', 'title_zh': '效率不会导致可持续推理人工智能'}
{'arxiv_id': 'arXiv:2511.15282', 'title': 'Realist and Pluralist Conceptions of Intelligence and Their Implications on AI Research', 'authors': 'Ninell Oldenburg, Ruchira Dhar, Anders Søgaard', 'link': 'https://arxiv.org/abs/2511.15282', 'abstract': 'In this paper, we argue that current AI research operates on a spectrum between two different underlying conceptions of intelligence: Intelligence Realism, which holds that intelligence represents a single, universal capacity measurable across all systems, and Intelligence Pluralism, which views intelligence as diverse, context-dependent capacities that cannot be reduced to a single universal measure. Through an analysis of current debates in AI research, we demonstrate how the conceptions remain largely implicit yet fundamentally shape how empirical evidence gets interpreted across a wide range of areas. These underlying views generate fundamentally different research approaches across three areas. Methodologically, they produce different approaches to model selection, benchmark design, and experimental validation. Interpretively, they lead to contradictory readings of the same empirical phenomena, from capability emergence to system limitations. Regarding AI risk, they generate categorically different assessments: realists view superintelligence as the primary risk and search for unified alignment solutions, while pluralists see diverse threats across different domains requiring context-specific solutions. We argue that making explicit these underlying assumptions can contribute to a clearer understanding of disagreements in AI research.', 'abstract_zh': '本文argument了当前AI研究在两种不同的智能观念之间运作：智能现实主义认为智能是一种可衡量的普遍能力，而智能多元论认为智能是多样且基于情境的能力，无法简化为单一标准。通过对当前AI研究中的争论分析，我们展示了这些观念虽隐含但根本上如何影响广泛领域中实证证据的解读。这些基础观念在三个领域生成了不同的研究方法。在方法论上，它们导致了不同的模型选择、基准设计和实验验证方法。在解释上，它们导致了对相同实证现象的对立解读，从能力涌现到系统局限性。在AI风险方面，它们产生了截然不同的评估：现实主义者视超智能为主要风险，寻求统一的对齐解决方案，而多元论者则认为存在跨不同领域的多种不同威胁，需要情境特定的解决方案。我们argue明确这些基础假设可以有助于更清晰地理解AI研究中的分歧。', 'title_zh': '现实主义与多元主义的智能观念及其对AI研究的影响'}
{'arxiv_id': 'arXiv:2511.15259', 'title': 'Efficiency Will Not Lead to Sustainable Reasoning AI', 'authors': "Philipp Wiesner, Daniel W. O'Neill, Francesca Larosa, Odej Kao", 'link': 'https://arxiv.org/abs/2511.15259', 'abstract': "AI research is increasingly moving toward complex problem solving, where models are optimized not only for pattern recognition but for multi-step reasoning. Historically, computing's global energy footprint has been stabilized by sustained efficiency gains and natural saturation thresholds in demand. But as efficiency improvements are approaching physical limits, emerging reasoning AI lacks comparable saturation points: performance is no longer limited by the amount of available training data but continues to scale with exponential compute investments in both training and inference. This paper argues that efficiency alone will not lead to sustainable reasoning AI and discusses research and policy directions to embed explicit limits into the optimization and governance of such systems.", 'abstract_zh': 'AI研究 increasingly转向复杂问题求解，其中模型不仅优化模式识别，还优化多步推理。历史地看，计算的全球能耗足迹通过持续的效率提升和需求自然饱和阈值得以稳定。但随着效率改进接近物理极限，新兴推理AI缺乏类似的饱和点：性能不再受限于可用训练数据的数量，而是继续随着训练和推理中的指数级计算投资而扩展。本文认为，仅有效率无法引领可持续推理AI，并讨论了将显式限制嵌入此类系统优化和治理的研究和政策方向。', 'title_zh': '效率不会导致可持续推理人工智能'}
{'arxiv_id': 'arXiv:2511.15202', 'title': 'SOLID: a Framework of Synergizing Optimization and LLMs for Intelligent Decision-Making', 'authors': 'Yinsheng Wang, Tario G You, Léonard Boussioux, Shan Liu', 'link': 'https://arxiv.org/abs/2511.15202', 'abstract': 'This paper introduces SOLID (Synergizing Optimization and Large Language Models for Intelligent Decision-Making), a novel framework that integrates mathematical optimization with the contextual capabilities of large language models (LLMs). SOLID facilitates iterative collaboration between optimization and LLMs agents through dual prices and deviation penalties. This interaction improves the quality of the decisions while maintaining modularity and data privacy. The framework retains theoretical convergence guarantees under convexity assumptions, providing insight into the design of LLMs prompt. To evaluate SOLID, we applied it to a stock portfolio investment case with historical prices and financial news as inputs. Empirical results demonstrate convergence under various scenarios and indicate improved annualized returns compared to a baseline optimizer-only method, validating the synergy of the two agents. SOLID offers a promising framework for advancing automated and intelligent decision-making across diverse domains.', 'abstract_zh': 'SOLID（将优化与大规模语言模型的上下文能力协同起来进行智能决策的新框架）', 'title_zh': 'SOLID：一种协同优化和大语言模型的智能决策框架'}
{'arxiv_id': 'arXiv:2511.15259', 'title': 'Efficiency Will Not Lead to Sustainable Reasoning AI', 'authors': "Philipp Wiesner, Daniel W. O'Neill, Francesca Larosa, Odej Kao", 'link': 'https://arxiv.org/abs/2511.15259', 'abstract': "AI research is increasingly moving toward complex problem solving, where models are optimized not only for pattern recognition but for multi-step reasoning. Historically, computing's global energy footprint has been stabilized by sustained efficiency gains and natural saturation thresholds in demand. But as efficiency improvements are approaching physical limits, emerging reasoning AI lacks comparable saturation points: performance is no longer limited by the amount of available training data but continues to scale with exponential compute investments in both training and inference. This paper argues that efficiency alone will not lead to sustainable reasoning AI and discusses research and policy directions to embed explicit limits into the optimization and governance of such systems.", 'abstract_zh': 'AI研究 increasingly转向复杂问题求解：效率边界将取代数据边界推动 reasoning AI 发展及治理方向探讨', 'title_zh': '效率不会导致可持续推理AI'}
{'arxiv_id': 'arXiv:2511.15202', 'title': 'SOLID: a Framework of Synergizing Optimization and LLMs for Intelligent Decision-Making', 'authors': 'Yinsheng Wang, Tario G You, Léonard Boussioux, Shan Liu', 'link': 'https://arxiv.org/abs/2511.15202', 'abstract': 'This paper introduces SOLID (Synergizing Optimization and Large Language Models for Intelligent Decision-Making), a novel framework that integrates mathematical optimization with the contextual capabilities of large language models (LLMs). SOLID facilitates iterative collaboration between optimization and LLMs agents through dual prices and deviation penalties. This interaction improves the quality of the decisions while maintaining modularity and data privacy. The framework retains theoretical convergence guarantees under convexity assumptions, providing insight into the design of LLMs prompt. To evaluate SOLID, we applied it to a stock portfolio investment case with historical prices and financial news as inputs. Empirical results demonstrate convergence under various scenarios and indicate improved annualized returns compared to a baseline optimizer-only method, validating the synergy of the two agents. SOLID offers a promising framework for advancing automated and intelligent decision-making across diverse domains.', 'abstract_zh': 'SOLID (Synergizing Optimization and Large Language Models for Intelligent Decision-Making)', 'title_zh': 'SOLID：协同优化与大模型的框架以实现智能决策'}
{'arxiv_id': 'arXiv:2511.15192', 'title': "As If We've Met Before: LLMs Exhibit Certainty in Recognizing Seen Files", 'authors': 'Haodong Li, Jingqi Zhang, Xiao Cheng, Peihua Mai, Haoyu Wang, Yang Pan', 'link': 'https://arxiv.org/abs/2511.15192', 'abstract': 'The remarkable language ability of Large Language Models (LLMs) stems from extensive training on vast datasets, often including copyrighted material, which raises serious concerns about unauthorized use. While Membership Inference Attacks (MIAs) offer potential solutions for detecting such violations, existing approaches face critical limitations and challenges due to LLMs\' inherent overconfidence, limited access to ground truth training data, and reliance on empirically determined thresholds.\nWe present COPYCHECK, a novel framework that leverages uncertainty signals to detect whether copyrighted content was used in LLM training sets. Our method turns LLM overconfidence from a limitation into an asset by capturing uncertainty patterns that reliably distinguish between ``seen" (training data) and ``unseen" (non-training data) content. COPYCHECK further implements a two-fold strategy: (1) strategic segmentation of files into smaller snippets to reduce dependence on large-scale training data, and (2) uncertainty-guided unsupervised clustering to eliminate the need for empirically tuned thresholds. Experiment results show that COPYCHECK achieves an average balanced accuracy of 90.1% on LLaMA 7b and 91.6% on LLaMA2 7b in detecting seen files. Compared to the SOTA baseline, COPYCHECK achieves over 90% relative improvement, reaching up to 93.8\\% balanced accuracy. It further exhibits strong generalizability across architectures, maintaining high performance on GPT-J 6B. This work presents the first application of uncertainty for copyright detection in LLMs, offering practical tools for training data transparency.', 'abstract_zh': '大型语言模型（LLMs）的 remarkable 语言能力源自于其在 vast 数据集中进行的广泛训练，这些数据集 often 包括受版权保护的内容，这引发了未经授权使用材料的严重关切。尽管成员推断攻击（Member Inference Attacks, MIAs）为检测此类违规行为提供了潜在的解决方案，但现有的方法由于大型语言模型的固有过度自信、对地面真实训练数据的有限访问以及依赖于经验确定的阈值而面临关键的限制和挑战。\n\n我们提出了一种名为 COPYCHECK 的新型框架，该框架利用不确定性信号来检测 LLM 训练集中是否使用了受版权保护的内容。我们的方法将大型语言模型的过度自信从限制转变为优势，通过捕捉可靠区分“已见”（训练数据）和“未见”（非训练数据）内容的不确定性模式。COPYCHECK 采用了双重策略：（1）对文件进行战略性分割为更小的片段，以减少对大规模训练数据的依赖，以及（2）基于不确定性的无监督聚类，从而消除对经验调参阈值的需求。实验结果显示，COPYCHECK 在检测已见文件方面，对 LLaMA 7b 和 LLaMA2 7b 的平均平衡准确率分别达到 90.1% 和 91.6%。与当前最佳基准相比，COPYCHECK 实现了超过 90% 的相对改进，平衡准确率达到 93.8%。此外，该工作展示了不确定性在大型语言模型中用于版权检测的首次应用，提供了提高训练数据透明度的实际工具。', 'title_zh': '似曾相识：大语言模型在识别见过的文件时表现出 certainty'}
{'arxiv_id': 'arXiv:2511.15202', 'title': 'SOLID: a Framework of Synergizing Optimization and LLMs for Intelligent Decision-Making', 'authors': 'Yinsheng Wang, Tario G You, Léonard Boussioux, Shan Liu', 'link': 'https://arxiv.org/abs/2511.15202', 'abstract': 'This paper introduces SOLID (Synergizing Optimization and Large Language Models for Intelligent Decision-Making), a novel framework that integrates mathematical optimization with the contextual capabilities of large language models (LLMs). SOLID facilitates iterative collaboration between optimization and LLMs agents through dual prices and deviation penalties. This interaction improves the quality of the decisions while maintaining modularity and data privacy. The framework retains theoretical convergence guarantees under convexity assumptions, providing insight into the design of LLMs prompt. To evaluate SOLID, we applied it to a stock portfolio investment case with historical prices and financial news as inputs. Empirical results demonstrate convergence under various scenarios and indicate improved annualized returns compared to a baseline optimizer-only method, validating the synergy of the two agents. SOLID offers a promising framework for advancing automated and intelligent decision-making across diverse domains.', 'abstract_zh': 'SOLID (Synergizing Optimization and Large Language Models for Intelligent Decision-Making)', 'title_zh': 'SOLID：协同优化和大语言模型的智能决策框架'}
{'arxiv_id': 'arXiv:2511.15192', 'title': "As If We've Met Before: LLMs Exhibit Certainty in Recognizing Seen Files", 'authors': 'Haodong Li, Jingqi Zhang, Xiao Cheng, Peihua Mai, Haoyu Wang, Yang Pan', 'link': 'https://arxiv.org/abs/2511.15192', 'abstract': 'The remarkable language ability of Large Language Models (LLMs) stems from extensive training on vast datasets, often including copyrighted material, which raises serious concerns about unauthorized use. While Membership Inference Attacks (MIAs) offer potential solutions for detecting such violations, existing approaches face critical limitations and challenges due to LLMs\' inherent overconfidence, limited access to ground truth training data, and reliance on empirically determined thresholds.\nWe present COPYCHECK, a novel framework that leverages uncertainty signals to detect whether copyrighted content was used in LLM training sets. Our method turns LLM overconfidence from a limitation into an asset by capturing uncertainty patterns that reliably distinguish between ``seen" (training data) and ``unseen" (non-training data) content. COPYCHECK further implements a two-fold strategy: (1) strategic segmentation of files into smaller snippets to reduce dependence on large-scale training data, and (2) uncertainty-guided unsupervised clustering to eliminate the need for empirically tuned thresholds. Experiment results show that COPYCHECK achieves an average balanced accuracy of 90.1% on LLaMA 7b and 91.6% on LLaMA2 7b in detecting seen files. Compared to the SOTA baseline, COPYCHECK achieves over 90% relative improvement, reaching up to 93.8\\% balanced accuracy. It further exhibits strong generalizability across architectures, maintaining high performance on GPT-J 6B. This work presents the first application of uncertainty for copyright detection in LLMs, offering practical tools for training data transparency.', 'abstract_zh': '大型语言模型（LLMs） remarkable 语言能力源自于在庞大数据集中进行的广泛训练，这些数据集经常包括受版权保护的内容，这引起了未经授权使用内容的严重关切。虽然成员推理攻击（MIAs）提供了潜在的解决方案来检测此类违规行为，但现有方法由于LLMs固有的过度自信、难以获取真实训练数据以及依赖于经验确定的阈值等因素而面临关键的限制和挑战。\n\n我们提出了一种新颖的框架COPYCHECK，该框架利用不确定性信号来检测是否在LLM训练集中使用了受版权保护的内容。我们的方法通过捕捉能够可靠地区分“已见”（训练数据）和“未见”（非训练数据）内容的不确定性模式，将LLM的过度自信从限制转化为优势。COPYCHECK还采用了两步策略：（1）对文件进行战略性分割成更小的片段，以减少对大规模训练数据的依赖；（2）基于不确定性指导的无监督聚类，以消除需要经验确定的阈值。实验结果显示，COPYCHECK在检测已见文件方面，在LLaMA 7b上的平均平衡准确率为90.1%，在LLaMA2 7b上的平均平衡准确率为91.6%。与当前最佳 baseline 相比，COPYCHECK实现了超过90%的相对改进，最高平衡准确率达到93.8%。此外，COPYCHECK在不同架构中表现出强泛化性，能够在GPT-J 6B上保持高性能。本项工作首次将不确定性应用到LLMs中的版权检测，提供了提高训练数据透明度的实用工具。', 'title_zh': '如故人相见：大语言模型在识别见过的文件时表现出确定性'}
{'arxiv_id': 'arXiv:2511.15191', 'title': 'HISE-KT: Synergizing Heterogeneous Information Networks and LLMs for Explainable Knowledge Tracing with Meta-Path Optimization', 'authors': 'Zhiyi Duan, Zixing Shi, Hongyu Yuan, Qi Wang', 'link': 'https://arxiv.org/abs/2511.15191', 'abstract': "Knowledge Tracing (KT) aims to mine students' evolving knowledge states and predict their future question-answering performance. Existing methods based on heterogeneous information networks (HINs) are prone to introducing noises due to manual or random selection of meta-paths and lack necessary quality assessment of meta-path instances. Conversely, recent large language models (LLMs)-based methods ignore the rich information across students, and both paradigms struggle to deliver consistently accurate and evidence-based explanations. To address these issues, we propose an innovative framework, HIN-LLM Synergistic Enhanced Knowledge Tracing (HISE-KT), which seamlessly integrates HINs with LLMs. HISE-KT first builds a multi-relationship HIN containing diverse node types to capture the structural relations through multiple meta-paths. The LLM is then employed to intelligently score and filter meta-path instances and retain high-quality paths, pioneering automated meta-path quality assessment. Inspired by educational psychology principles, a similar student retrieval mechanism based on meta-paths is designed to provide a more valuable context for prediction. Finally, HISE-KT uses a structured prompt to integrate the target student's history with the retrieved similar trajectories, enabling the LLM to generate not only accurate predictions but also evidence-backed, explainable analysis reports. Experiments on four public datasets show that HISE-KT outperforms existing KT baselines in both prediction performance and interpretability.", 'abstract_zh': '基于HIN和LLM协同增强的知识追踪（HIN-LLM Synergistic Enhanced Knowledge Tracing, HISE-KT）', 'title_zh': 'HISE-KT：通过元路径优化结合异构信息网络和大语言模型进行可解释的知识追踪'}
{'arxiv_id': 'arXiv:2511.15191', 'title': 'HISE-KT: Synergizing Heterogeneous Information Networks and LLMs for Explainable Knowledge Tracing with Meta-Path Optimization', 'authors': 'Zhiyi Duan, Zixing Shi, Hongyu Yuan, Qi Wang', 'link': 'https://arxiv.org/abs/2511.15191', 'abstract': "Knowledge Tracing (KT) aims to mine students' evolving knowledge states and predict their future question-answering performance. Existing methods based on heterogeneous information networks (HINs) are prone to introducing noises due to manual or random selection of meta-paths and lack necessary quality assessment of meta-path instances. Conversely, recent large language models (LLMs)-based methods ignore the rich information across students, and both paradigms struggle to deliver consistently accurate and evidence-based explanations. To address these issues, we propose an innovative framework, HIN-LLM Synergistic Enhanced Knowledge Tracing (HISE-KT), which seamlessly integrates HINs with LLMs. HISE-KT first builds a multi-relationship HIN containing diverse node types to capture the structural relations through multiple meta-paths. The LLM is then employed to intelligently score and filter meta-path instances and retain high-quality paths, pioneering automated meta-path quality assessment. Inspired by educational psychology principles, a similar student retrieval mechanism based on meta-paths is designed to provide a more valuable context for prediction. Finally, HISE-KT uses a structured prompt to integrate the target student's history with the retrieved similar trajectories, enabling the LLM to generate not only accurate predictions but also evidence-backed, explainable analysis reports. Experiments on four public datasets show that HISE-KT outperforms existing KT baselines in both prediction performance and interpretability.", 'abstract_zh': 'HIN-LLM协同增强知识追踪（HISE-KT）', 'title_zh': 'HISE-KT：通过元路径优化结合异构信息网络和大语言模型进行可解释的知识追踪'}
{'arxiv_id': 'arXiv:2511.15192', 'title': "As If We've Met Before: LLMs Exhibit Certainty in Recognizing Seen Files", 'authors': 'Haodong Li, Jingqi Zhang, Xiao Cheng, Peihua Mai, Haoyu Wang, Yang Pan', 'link': 'https://arxiv.org/abs/2511.15192', 'abstract': 'The remarkable language ability of Large Language Models (LLMs) stems from extensive training on vast datasets, often including copyrighted material, which raises serious concerns about unauthorized use. While Membership Inference Attacks (MIAs) offer potential solutions for detecting such violations, existing approaches face critical limitations and challenges due to LLMs\' inherent overconfidence, limited access to ground truth training data, and reliance on empirically determined thresholds.\nWe present COPYCHECK, a novel framework that leverages uncertainty signals to detect whether copyrighted content was used in LLM training sets. Our method turns LLM overconfidence from a limitation into an asset by capturing uncertainty patterns that reliably distinguish between ``seen" (training data) and ``unseen" (non-training data) content. COPYCHECK further implements a two-fold strategy: (1) strategic segmentation of files into smaller snippets to reduce dependence on large-scale training data, and (2) uncertainty-guided unsupervised clustering to eliminate the need for empirically tuned thresholds. Experiment results show that COPYCHECK achieves an average balanced accuracy of 90.1% on LLaMA 7b and 91.6% on LLaMA2 7b in detecting seen files. Compared to the SOTA baseline, COPYCHECK achieves over 90% relative improvement, reaching up to 93.8\\% balanced accuracy. It further exhibits strong generalizability across architectures, maintaining high performance on GPT-J 6B. This work presents the first application of uncertainty for copyright detection in LLMs, offering practical tools for training data transparency.', 'abstract_zh': '大型语言模型（LLMs）卓越的语言能力源于其对大量数据集的广泛训练，这些数据集通常包括受版权保护的材料，这引发了关于未经授权使用材料的严重关切。虽然成员推测推理攻击（MIAs）提供了检测此类违规行为的潜在解决方案，但现有方法由于LLMs固有的过度自信、有限的真实训练数据访问以及依赖于经验确定的阈值而面临关键的局限性和挑战。\n\n我们提出了COPYCHECK，一个新颖的框架，利用不确定性信号来检测LLM训练集是否使用了受版权保护的内容。我们的方法将LLM的过度自信从一种限制转变为一种资产，通过捕获可靠的不确定性模式来区分“已见”（训练数据）和“未见”（非训练数据）内容。COPYCHECK进一步实施了两步策略：（1）文件的策略性分割成更小片段以减少对大规模训练数据的依赖，（2）基于不确定性的无监督聚类以消除对经验调优阈值的需求。实验结果表明，COPYCHECK在检测已见文件方面分别在LLaMA 7b和LLaMA2 7b上实现了平均平衡准确率90.1%和91.6%。与现有最佳基线相比，COPYCHECK实现了超过90%的相对改进，最高可达93.8%的平衡准确率。此外，COPYCHECK在不同架构上表现出良好的通用性，在GPT-J 6B上仍能保持高性能。这项工作首次将不确定性应用于LLMs中的版权检测，提供了一种提高训练数据透明度的实际工具。', 'title_zh': '如曾相识：大型语言模型在识别见过的文件时表现出确定性'}
{'arxiv_id': 'arXiv:2511.15169', 'title': 'SafeRBench: A Comprehensive Benchmark for Safety Assessment in Large Reasoning Models', 'authors': 'Xin Gao, Shaohan Yu, Zerui Chen, Yueming Lyu, Weichen Yu, Guanghao Li, Jiyao Liu, Jianxiong Gao, Jian Liang, Ziwei Liu, Chenyang Si', 'link': 'https://arxiv.org/abs/2511.15169', 'abstract': 'Large Reasoning Models (LRMs) improve answer quality through explicit chain-of-thought, yet this very capability introduces new safety risks: harmful content can be subtly injected, surface gradually, or be justified by misleading rationales within the reasoning trace. Existing safety evaluations, however, primarily focus on output-level judgments and rarely capture these dynamic risks along the reasoning process. In this paper, we present SafeRBench, the first benchmark that assesses LRM safety end-to-end -- from inputs and intermediate reasoning to final outputs. (1) Input Characterization: We pioneer the incorporation of risk categories and levels into input design, explicitly accounting for affected groups and severity, and thereby establish a balanced prompt suite reflecting diverse harm gradients. (2) Fine-Grained Output Analysis: We introduce a micro-thought chunking mechanism to segment long reasoning traces into semantically coherent units, enabling fine-grained evaluation across ten safety dimensions. (3) Human Safety Alignment: We validate LLM-based evaluations against human annotations specifically designed to capture safety judgments. Evaluations on 19 LRMs demonstrate that SafeRBench enables detailed, multidimensional safety assessment, offering insights into risks and protective mechanisms from multiple perspectives.', 'abstract_zh': 'Large Reasoning Models (LRMs)通过显式的推理链提高答案质量，但这一能力引入了新的安全风险：有害内容可以通过微妙的介入、逐步显现或通过误导性的推理理由进行辩解。现有的安全评估主要集中在输出层面的判断，很少能够捕捉到推理过程中的动态风险。在本文中，我们提出了SafeRBench，这是第一个从输入和中间推理到最终输出对LRM安全进行全面评估的标准——(1) 输入表征：我们将风险类别和水平纳入输入设计，明确考虑受影响的群体和严重程度，从而建立一个平衡的提示套件，反映出多样的危害梯度。(2) 细粒度输出分析：我们引入了一种微推理片段机制，将长的推理链段划分成语义上一致的单元，从而实现十种安全维度的细粒度评估。(3) 人类安全对齐：我们对基于LLM的评估进行了验证，与专门设计用来捕捉安全判断的人类注释进行对比。对19个LRM的评估表明，SafeRBench能够实现详细且多维度的安全评估，提供来自多个视角的风险和防护机制的见解。', 'title_zh': 'SafeRBench：大型推理模型安全性评估的综合基准'}
{'arxiv_id': 'arXiv:2511.15169', 'title': 'SafeRBench: A Comprehensive Benchmark for Safety Assessment in Large Reasoning Models', 'authors': 'Xin Gao, Shaohan Yu, Zerui Chen, Yueming Lyu, Weichen Yu, Guanghao Li, Jiyao Liu, Jianxiong Gao, Jian Liang, Ziwei Liu, Chenyang Si', 'link': 'https://arxiv.org/abs/2511.15169', 'abstract': 'Large Reasoning Models (LRMs) improve answer quality through explicit chain-of-thought, yet this very capability introduces new safety risks: harmful content can be subtly injected, surface gradually, or be justified by misleading rationales within the reasoning trace. Existing safety evaluations, however, primarily focus on output-level judgments and rarely capture these dynamic risks along the reasoning process. In this paper, we present SafeRBench, the first benchmark that assesses LRM safety end-to-end -- from inputs and intermediate reasoning to final outputs. (1) Input Characterization: We pioneer the incorporation of risk categories and levels into input design, explicitly accounting for affected groups and severity, and thereby establish a balanced prompt suite reflecting diverse harm gradients. (2) Fine-Grained Output Analysis: We introduce a micro-thought chunking mechanism to segment long reasoning traces into semantically coherent units, enabling fine-grained evaluation across ten safety dimensions. (3) Human Safety Alignment: We validate LLM-based evaluations against human annotations specifically designed to capture safety judgments. Evaluations on 19 LRMs demonstrate that SafeRBench enables detailed, multidimensional safety assessment, offering insights into risks and protective mechanisms from multiple perspectives.', 'abstract_zh': '大型推理模型的安全性评估：SafeRBench', 'title_zh': 'SafeRBench：大规模推理模型安全性评估的综合基准'}
{'arxiv_id': 'arXiv:2511.15191', 'title': 'HISE-KT: Synergizing Heterogeneous Information Networks and LLMs for Explainable Knowledge Tracing with Meta-Path Optimization', 'authors': 'Zhiyi Duan, Zixing Shi, Hongyu Yuan, Qi Wang', 'link': 'https://arxiv.org/abs/2511.15191', 'abstract': "Knowledge Tracing (KT) aims to mine students' evolving knowledge states and predict their future question-answering performance. Existing methods based on heterogeneous information networks (HINs) are prone to introducing noises due to manual or random selection of meta-paths and lack necessary quality assessment of meta-path instances. Conversely, recent large language models (LLMs)-based methods ignore the rich information across students, and both paradigms struggle to deliver consistently accurate and evidence-based explanations. To address these issues, we propose an innovative framework, HIN-LLM Synergistic Enhanced Knowledge Tracing (HISE-KT), which seamlessly integrates HINs with LLMs. HISE-KT first builds a multi-relationship HIN containing diverse node types to capture the structural relations through multiple meta-paths. The LLM is then employed to intelligently score and filter meta-path instances and retain high-quality paths, pioneering automated meta-path quality assessment. Inspired by educational psychology principles, a similar student retrieval mechanism based on meta-paths is designed to provide a more valuable context for prediction. Finally, HISE-KT uses a structured prompt to integrate the target student's history with the retrieved similar trajectories, enabling the LLM to generate not only accurate predictions but also evidence-backed, explainable analysis reports. Experiments on four public datasets show that HISE-KT outperforms existing KT baselines in both prediction performance and interpretability.", 'abstract_zh': 'HIN-LLM协同增强知识追踪（HISE-KT）', 'title_zh': 'HISE-KT：异质信息网络与元路径优化结合的可解释知识追踪方法与大型语言模型协同使用'}
{'arxiv_id': 'arXiv:2511.15074', 'title': 'Knowledge-Informed Automatic Feature Extraction via Collaborative Large Language Model Agents', 'authors': 'Henrik Bradland, Morten Goodwin, Vladimir I. Zadorozhny, Per-Arne Andersen', 'link': 'https://arxiv.org/abs/2511.15074', 'abstract': 'The performance of machine learning models on tabular data is critically dependent on high-quality feature engineering. While Large Language Models (LLMs) have shown promise in automating feature extraction (AutoFE), existing methods are often limited by monolithic LLM architectures, simplistic quantitative feedback, and a failure to systematically integrate external domain knowledge. This paper introduces Rogue One, a novel, LLM-based multi-agent framework for knowledge-informed automatic feature extraction. Rogue One operationalizes a decentralized system of three specialized agents-Scientist, Extractor, and Tester-that collaborate iteratively to discover, generate, and validate predictive features. Crucially, the framework moves beyond primitive accuracy scores by introducing a rich, qualitative feedback mechanism and a "flooding-pruning" strategy, allowing it to dynamically balance feature exploration and exploitation. By actively incorporating external knowledge via an integrated retrieval-augmented (RAG) system, Rogue One generates features that are not only statistically powerful but also semantically meaningful and interpretable. We demonstrate that Rogue One significantly outperforms state-of-the-art methods on a comprehensive suite of 19 classification and 9 regression datasets. Furthermore, we show qualitatively that the system surfaces novel, testable hypotheses, such as identifying a new potential biomarker in the myocardial dataset, underscoring its utility as a tool for scientific discovery.', 'abstract_zh': '一种基于大型语言模型的多Agent知识引导自动特征提取框架：Rogue One', 'title_zh': '基于协作大语言模型代理的知情自动特征提取'}
{'arxiv_id': 'arXiv:2511.15074', 'title': 'Knowledge-Informed Automatic Feature Extraction via Collaborative Large Language Model Agents', 'authors': 'Henrik Bradland, Morten Goodwin, Vladimir I. Zadorozhny, Per-Arne Andersen', 'link': 'https://arxiv.org/abs/2511.15074', 'abstract': 'The performance of machine learning models on tabular data is critically dependent on high-quality feature engineering. While Large Language Models (LLMs) have shown promise in automating feature extraction (AutoFE), existing methods are often limited by monolithic LLM architectures, simplistic quantitative feedback, and a failure to systematically integrate external domain knowledge. This paper introduces Rogue One, a novel, LLM-based multi-agent framework for knowledge-informed automatic feature extraction. Rogue One operationalizes a decentralized system of three specialized agents-Scientist, Extractor, and Tester-that collaborate iteratively to discover, generate, and validate predictive features. Crucially, the framework moves beyond primitive accuracy scores by introducing a rich, qualitative feedback mechanism and a "flooding-pruning" strategy, allowing it to dynamically balance feature exploration and exploitation. By actively incorporating external knowledge via an integrated retrieval-augmented (RAG) system, Rogue One generates features that are not only statistically powerful but also semantically meaningful and interpretable. We demonstrate that Rogue One significantly outperforms state-of-the-art methods on a comprehensive suite of 19 classification and 9 regression datasets. Furthermore, we show qualitatively that the system surfaces novel, testable hypotheses, such as identifying a new potential biomarker in the myocardial dataset, underscoring its utility as a tool for scientific discovery.', 'abstract_zh': '基于大型语言模型的多智能体知识导向自动特征提取框架Rogue One', 'title_zh': '基于协作大型语言模型代理的知识指导自动特征提取'}
{'arxiv_id': 'arXiv:2511.15169', 'title': 'SafeRBench: A Comprehensive Benchmark for Safety Assessment in Large Reasoning Models', 'authors': 'Xin Gao, Shaohan Yu, Zerui Chen, Yueming Lyu, Weichen Yu, Guanghao Li, Jiyao Liu, Jianxiong Gao, Jian Liang, Ziwei Liu, Chenyang Si', 'link': 'https://arxiv.org/abs/2511.15169', 'abstract': 'Large Reasoning Models (LRMs) improve answer quality through explicit chain-of-thought, yet this very capability introduces new safety risks: harmful content can be subtly injected, surface gradually, or be justified by misleading rationales within the reasoning trace. Existing safety evaluations, however, primarily focus on output-level judgments and rarely capture these dynamic risks along the reasoning process. In this paper, we present SafeRBench, the first benchmark that assesses LRM safety end-to-end -- from inputs and intermediate reasoning to final outputs. (1) Input Characterization: We pioneer the incorporation of risk categories and levels into input design, explicitly accounting for affected groups and severity, and thereby establish a balanced prompt suite reflecting diverse harm gradients. (2) Fine-Grained Output Analysis: We introduce a micro-thought chunking mechanism to segment long reasoning traces into semantically coherent units, enabling fine-grained evaluation across ten safety dimensions. (3) Human Safety Alignment: We validate LLM-based evaluations against human annotations specifically designed to capture safety judgments. Evaluations on 19 LRMs demonstrate that SafeRBench enables detailed, multidimensional safety assessment, offering insights into risks and protective mechanisms from multiple perspectives.', 'abstract_zh': '大型 reasoning 模型 (LRMs) 通过明确的推理链提高答案质量，但这一能力也引入了新的安全性风险：有害内容可以隐秘插入，表面逐渐显现，或通过误导性的推理在推理过程中被正当化。现有的安全性评估主要侧重于输出层面的判断，很少能够捕捉到这些动态风险。在本文中，我们提出了 SafeRBench，这是首个从输入到中间推理再到最终输出全面评估LRM安全性的基准。(1) 输入特征化：我们首创将风险类别和级别纳入输入设计，明确考虑受影响的群体和严重程度，从而建立一个反映不同危害梯度的平衡提示集。(2) 细粒度输出分析：我们引入了微推理片段化机制，将长推理链段分为语义上一致的单元，以便在十个安全维度上进行细粒度评估。(3) 人类安全对齐：我们用专门设计的捕捉安全判断的人工标注来验证基于预训练语言模型的安全性评估。在19个LRMs上的评估表明，SafeRBench 使详细的多维度安全性评估成为可能，提供了多视角的风险和保护机制的洞见。', 'title_zh': 'SafeRBench: 一种全面的大型推理模型安全性评估基准'}
{'arxiv_id': 'arXiv:2511.15069', 'title': 'ProRAC: A Neuro-symbolic Method for Reasoning about Actions with LLM-based Progression', 'authors': 'Haoyong Wu, Yongmei Liu', 'link': 'https://arxiv.org/abs/2511.15069', 'abstract': 'In this paper, we propose ProRAC (Progression-based Reasoning about Actions and Change), a neuro-symbolic framework that leverages LLMs to tackle RAC problems. ProRAC extracts fundamental RAC elements including actions and questions from the problem, progressively executes each action to derive the final state, and then evaluates the query against the progressed state to arrive at an answer. We evaluate ProRAC on several RAC benchmarks, and the results demonstrate that our approach achieves strong performance across different benchmarks, domains, LLM backbones, and types of RAC tasks.', 'abstract_zh': '基于进程的行动与变化推理：一种结合LLM的神经符号框架', 'title_zh': 'ProRAC：一种基于LLM的进步推理神经符号方法'}
{'arxiv_id': 'arXiv:2511.15069', 'title': 'ProRAC: A Neuro-symbolic Method for Reasoning about Actions with LLM-based Progression', 'authors': 'Haoyong Wu, Yongmei Liu', 'link': 'https://arxiv.org/abs/2511.15069', 'abstract': 'In this paper, we propose ProRAC (Progression-based Reasoning about Actions and Change), a neuro-symbolic framework that leverages LLMs to tackle RAC problems. ProRAC extracts fundamental RAC elements including actions and questions from the problem, progressively executes each action to derive the final state, and then evaluates the query against the progressed state to arrive at an answer. We evaluate ProRAC on several RAC benchmarks, and the results demonstrate that our approach achieves strong performance across different benchmarks, domains, LLM backbones, and types of RAC tasks.', 'abstract_zh': '基于进程的行动与变化推理：一种结合LLM的神经符号框架', 'title_zh': 'ProRAC: 一种基于LLM的推理动作的神经符号方法'}
{'arxiv_id': 'arXiv:2511.15074', 'title': 'Knowledge-Informed Automatic Feature Extraction via Collaborative Large Language Model Agents', 'authors': 'Henrik Bradland, Morten Goodwin, Vladimir I. Zadorozhny, Per-Arne Andersen', 'link': 'https://arxiv.org/abs/2511.15074', 'abstract': 'The performance of machine learning models on tabular data is critically dependent on high-quality feature engineering. While Large Language Models (LLMs) have shown promise in automating feature extraction (AutoFE), existing methods are often limited by monolithic LLM architectures, simplistic quantitative feedback, and a failure to systematically integrate external domain knowledge. This paper introduces Rogue One, a novel, LLM-based multi-agent framework for knowledge-informed automatic feature extraction. Rogue One operationalizes a decentralized system of three specialized agents-Scientist, Extractor, and Tester-that collaborate iteratively to discover, generate, and validate predictive features. Crucially, the framework moves beyond primitive accuracy scores by introducing a rich, qualitative feedback mechanism and a "flooding-pruning" strategy, allowing it to dynamically balance feature exploration and exploitation. By actively incorporating external knowledge via an integrated retrieval-augmented (RAG) system, Rogue One generates features that are not only statistically powerful but also semantically meaningful and interpretable. We demonstrate that Rogue One significantly outperforms state-of-the-art methods on a comprehensive suite of 19 classification and 9 regression datasets. Furthermore, we show qualitatively that the system surfaces novel, testable hypotheses, such as identifying a new potential biomarker in the myocardial dataset, underscoring its utility as a tool for scientific discovery.', 'abstract_zh': '基于大型语言模型的多智能体知识导向自动特征提取框架Rogue One', 'title_zh': '基于知识引导的自动特征提取协作大语言模型代理'}
{'arxiv_id': 'arXiv:2511.15061', 'title': 'Beyond GeneGPT: A Multi-Agent Architecture with Open-Source LLMs for Enhanced Genomic Question Answering', 'authors': 'Haodong Chen, Guido Zuccon, Teerapong Leelanupab', 'link': 'https://arxiv.org/abs/2511.15061', 'abstract': "Genomic question answering often requires complex reasoning and integration across diverse biomedical sources. GeneGPT addressed this challenge by combining domain-specific APIs with OpenAI's code-davinci-002 large language model to enable natural language interaction with genomic databases. However, its reliance on a proprietary model limits scalability, increases operational costs, and raises concerns about data privacy and generalization.\nIn this work, we revisit and reproduce GeneGPT in a pilot study using open source models, including Llama 3.1, Qwen2.5, and Qwen2.5 Coder, within a monolithic architecture; this allows us to identify the limitations of this approach. Building on this foundation, we then develop OpenBioLLM, a modular multi-agent framework that extends GeneGPT by introducing agent specialization for tool routing, query generation, and response validation. This enables coordinated reasoning and role-based task execution.\nOpenBioLLM matches or outperforms GeneGPT on over 90% of the benchmark tasks, achieving average scores of 0.849 on Gene-Turing and 0.830 on GeneHop, while using smaller open-source models without additional fine-tuning or tool-specific pretraining. OpenBioLLM's modular multi-agent design reduces latency by 40-50% across benchmark tasks, significantly improving efficiency without compromising model capability. The results of our comprehensive evaluation highlight the potential of open-source multi-agent systems for genomic question answering. Code and resources are available at this https URL.", 'abstract_zh': '基于开源模型的OpenBioLLM：一种模块化的多代理框架，用于基因组问答', 'title_zh': '超越GeneGPT：一种基于开源大语言模型的多代理架构以增强基因组问答'}
{'arxiv_id': 'arXiv:2511.15069', 'title': 'ProRAC: A Neuro-symbolic Method for Reasoning about Actions with LLM-based Progression', 'authors': 'Haoyong Wu, Yongmei Liu', 'link': 'https://arxiv.org/abs/2511.15069', 'abstract': 'In this paper, we propose ProRAC (Progression-based Reasoning about Actions and Change), a neuro-symbolic framework that leverages LLMs to tackle RAC problems. ProRAC extracts fundamental RAC elements including actions and questions from the problem, progressively executes each action to derive the final state, and then evaluates the query against the progressed state to arrive at an answer. We evaluate ProRAC on several RAC benchmarks, and the results demonstrate that our approach achieves strong performance across different benchmarks, domains, LLM backbones, and types of RAC tasks.', 'abstract_zh': '基于进程的行动与变化推理：一种利用大语言模型的神经符号框架', 'title_zh': 'ProRAC: 一种基于LLM的神经符号方法，用于动作推理'}
{'arxiv_id': 'arXiv:2511.15061', 'title': 'Beyond GeneGPT: A Multi-Agent Architecture with Open-Source LLMs for Enhanced Genomic Question Answering', 'authors': 'Haodong Chen, Guido Zuccon, Teerapong Leelanupab', 'link': 'https://arxiv.org/abs/2511.15061', 'abstract': "Genomic question answering often requires complex reasoning and integration across diverse biomedical sources. GeneGPT addressed this challenge by combining domain-specific APIs with OpenAI's code-davinci-002 large language model to enable natural language interaction with genomic databases. However, its reliance on a proprietary model limits scalability, increases operational costs, and raises concerns about data privacy and generalization.\nIn this work, we revisit and reproduce GeneGPT in a pilot study using open source models, including Llama 3.1, Qwen2.5, and Qwen2.5 Coder, within a monolithic architecture; this allows us to identify the limitations of this approach. Building on this foundation, we then develop OpenBioLLM, a modular multi-agent framework that extends GeneGPT by introducing agent specialization for tool routing, query generation, and response validation. This enables coordinated reasoning and role-based task execution.\nOpenBioLLM matches or outperforms GeneGPT on over 90% of the benchmark tasks, achieving average scores of 0.849 on Gene-Turing and 0.830 on GeneHop, while using smaller open-source models without additional fine-tuning or tool-specific pretraining. OpenBioLLM's modular multi-agent design reduces latency by 40-50% across benchmark tasks, significantly improving efficiency without compromising model capability. The results of our comprehensive evaluation highlight the potential of open-source multi-agent systems for genomic question answering. Code and resources are available at this https URL.", 'abstract_zh': '基因组问答常常需要复杂的推理和跨多种生物医学来源的数据集成。GeneGPT通过结合领域特定API与OpenAI的code-davinci-002大规模语言模型，实现了与基因组数据库的自然语言交互。然而，其对专有模型的依赖限制了可扩展性，增加了运营成本，并引发了关于数据隐私和泛化能力的关切。\n\n在本工作中，我们使用开源模型Llama 3.1、Qwen2.5和Qwen2.5 Coder，在单一架构中重新审视并重现了GeneGPT；这使我们能够识别该方法的局限性。在此基础上，我们开发了OpenBioLLM，这是一种模块化多代理框架，通过引入代理专门化工具路由、查询生成和响应验证来扩展GeneGPT的功能。这实现了协调推理和基于角色的任务执行。\n\nOpenBioLLM在超过90%的基准任务中匹配或超过了GeneGPT，在Gene-Turing和GeneHop上的平均得分为0.849和0.830，同时使用较小的开源模型而不进行额外的微调或工具特定预训练。OpenBioLLM的模块化多代理设计在基准任务中将延迟降低了40-50%，显著提高了效率而不牺牲模型能力。我们全面评估的结果突显了开源多代理系统在基因组问答中的潜力。代码和资源可在以下链接获取。', 'title_zh': '超越GeneGPT：基于开源大语言模型的多agent架构以增强基因组问答'}
{'arxiv_id': 'arXiv:2511.15055', 'title': 'Learning Human-Like RL Agents Through Trajectory Optimization With Action Quantization', 'authors': 'Jian-Ting Guo, Yu-Cheng Chen, Ping-Chun Hsieh, Kuo-Hao Ho, Po-Wei Huang, Ti-Rong Wu, I-Chen Wu', 'link': 'https://arxiv.org/abs/2511.15055', 'abstract': 'Human-like agents have long been one of the goals in pursuing artificial intelligence. Although reinforcement learning (RL) has achieved superhuman performance in many domains, relatively little attention has been focused on designing human-like RL agents. As a result, many reward-driven RL agents often exhibit unnatural behaviors compared to humans, raising concerns for both interpretability and trustworthiness. To achieve human-like behavior in RL, this paper first formulates human-likeness as trajectory optimization, where the objective is to find an action sequence that closely aligns with human behavior while also maximizing rewards, and adapts the classic receding-horizon control to human-like learning as a tractable and efficient implementation. To achieve this, we introduce Macro Action Quantization (MAQ), a human-like RL framework that distills human demonstrations into macro actions via Vector-Quantized VAE. Experiments on D4RL Adroit benchmarks show that MAQ significantly improves human-likeness, increasing trajectory similarity scores, and achieving the highest human-likeness rankings among all RL agents in the human evaluation study. Our results also demonstrate that MAQ can be easily integrated into various off-the-shelf RL algorithms, opening a promising direction for learning human-like RL agents. Our code is available at this https URL.', 'abstract_zh': '类人的代理长久以来一直是追求人工智能的目标。尽管强化学习（RL）在许多领域已经达到了超人水平，但相对较少关注设计类人的RL代理。因此，许多奖励驱动的RL代理表现出与人类不符的非自然行为，对可解释性和可信度提出了质疑。为实现类人的RL行为，本文首先将类人性形式化为轨迹优化，目标是在类似于人类行为的同时也最大化奖励，然后将经典的视线控制适应为类人的学习，作为一种可实现且高效的实现方式。为此，我们提出了宏动作量化（MAQ），这是一种类人RL框架，通过向量量化VAE将人类示范提炼为宏动作。在D4RL Adroit基准上的实验表明，MAQ显著提高了类人性，增加了轨迹相似性评分，并在人类评估研究中所有RL代理中获得了最高类人评分。我们的结果还表明，MAQ可以轻松集成到各种现成的RL算法中，为学习类人的RL代理开辟了有前景的方向。我们的代码可在以下链接获取：this https URL。', 'title_zh': '基于动作量化轨迹优化学习人类似RL代理'}
{'arxiv_id': 'arXiv:2511.15061', 'title': 'Beyond GeneGPT: A Multi-Agent Architecture with Open-Source LLMs for Enhanced Genomic Question Answering', 'authors': 'Haodong Chen, Guido Zuccon, Teerapong Leelanupab', 'link': 'https://arxiv.org/abs/2511.15061', 'abstract': "Genomic question answering often requires complex reasoning and integration across diverse biomedical sources. GeneGPT addressed this challenge by combining domain-specific APIs with OpenAI's code-davinci-002 large language model to enable natural language interaction with genomic databases. However, its reliance on a proprietary model limits scalability, increases operational costs, and raises concerns about data privacy and generalization.\nIn this work, we revisit and reproduce GeneGPT in a pilot study using open source models, including Llama 3.1, Qwen2.5, and Qwen2.5 Coder, within a monolithic architecture; this allows us to identify the limitations of this approach. Building on this foundation, we then develop OpenBioLLM, a modular multi-agent framework that extends GeneGPT by introducing agent specialization for tool routing, query generation, and response validation. This enables coordinated reasoning and role-based task execution.\nOpenBioLLM matches or outperforms GeneGPT on over 90% of the benchmark tasks, achieving average scores of 0.849 on Gene-Turing and 0.830 on GeneHop, while using smaller open-source models without additional fine-tuning or tool-specific pretraining. OpenBioLLM's modular multi-agent design reduces latency by 40-50% across benchmark tasks, significantly improving efficiency without compromising model capability. The results of our comprehensive evaluation highlight the potential of open-source multi-agent systems for genomic question answering. Code and resources are available at this https URL.", 'abstract_zh': '基于开源模型的OpenBioLLM：一种模块化的多代理框架用于基因组问答', 'title_zh': '超越GeneGPT：一种基于开源大语言模型的多代理架构，用于增强基因组问答'}
{'arxiv_id': 'arXiv:2511.15055', 'title': 'Learning Human-Like RL Agents Through Trajectory Optimization With Action Quantization', 'authors': 'Jian-Ting Guo, Yu-Cheng Chen, Ping-Chun Hsieh, Kuo-Hao Ho, Po-Wei Huang, Ti-Rong Wu, I-Chen Wu', 'link': 'https://arxiv.org/abs/2511.15055', 'abstract': 'Human-like agents have long been one of the goals in pursuing artificial intelligence. Although reinforcement learning (RL) has achieved superhuman performance in many domains, relatively little attention has been focused on designing human-like RL agents. As a result, many reward-driven RL agents often exhibit unnatural behaviors compared to humans, raising concerns for both interpretability and trustworthiness. To achieve human-like behavior in RL, this paper first formulates human-likeness as trajectory optimization, where the objective is to find an action sequence that closely aligns with human behavior while also maximizing rewards, and adapts the classic receding-horizon control to human-like learning as a tractable and efficient implementation. To achieve this, we introduce Macro Action Quantization (MAQ), a human-like RL framework that distills human demonstrations into macro actions via Vector-Quantized VAE. Experiments on D4RL Adroit benchmarks show that MAQ significantly improves human-likeness, increasing trajectory similarity scores, and achieving the highest human-likeness rankings among all RL agents in the human evaluation study. Our results also demonstrate that MAQ can be easily integrated into various off-the-shelf RL algorithms, opening a promising direction for learning human-like RL agents. Our code is available at this https URL.', 'abstract_zh': '类人代理：通过轨迹优化实现类人强化学习行为', 'title_zh': '通过动作量化进行轨迹优化以学习类人RL代理'}
{'arxiv_id': 'arXiv:2511.15002', 'title': 'Task Specific Sharpness Aware O-RAN Resource Management using Multi Agent Reinforcement Learning', 'authors': 'Fatemeh Lotfi, Hossein Rajoli, Fatemeh Afghah', 'link': 'https://arxiv.org/abs/2511.15002', 'abstract': 'Next-generation networks utilize the Open Radio Access Network (O-RAN) architecture to enable dynamic resource management, facilitated by the RAN Intelligent Controller (RIC). While deep reinforcement learning (DRL) models show promise in optimizing network resources, they often struggle with robustness and generalizability in dynamic environments. This paper introduces a novel resource management approach that enhances the Soft Actor Critic (SAC) algorithm with Sharpness-Aware Minimization (SAM) in a distributed Multi-Agent RL (MARL) framework. Our method introduces an adaptive and selective SAM mechanism, where regularization is explicitly driven by temporal-difference (TD)-error variance, ensuring that only agents facing high environmental complexity are regularized. This targeted strategy reduces unnecessary overhead, improves training stability, and enhances generalization without sacrificing learning efficiency. We further incorporate a dynamic $\\rho$ scheduling scheme to refine the exploration-exploitation trade-off across agents. Experimental results show our method significantly outperforms conventional DRL approaches, yielding up to a $22\\%$ improvement in resource allocation efficiency and ensuring superior QoS satisfaction across diverse O-RAN slices.', 'abstract_zh': '下一代网络利用开放无线接入网（O-RAN）架构并通过无线接入网智能控制器（RIC）实现动态资源管理。虽然深度强化学习（DRL）模型在优化网络资源方面表现出潜力，但在动态环境中往往缺乏鲁棒性和通用性。本文提出了一种新颖的资源管理方法，该方法在分布式多智能体强化学习（MARL）框架中增强了Soft Actor Critic（SAC）算法，并引入了尖锐度感知最小化（SAM）机制。该方法引入了一种自适应且选择性的SAM机制，其中正则化由时间差（TD）误差方差显式驱动，确保只有面临高环境复杂度的智能体被正则化。这种有针对性的策略减少了不必要的开销，提高了训练稳定性，并在不牺牲学习效率的情况下增强了通用性。此外，我们还引入了动态$\\rho$调度方案，以优化各智能体之间的探索与开发权衡。实验结果表明，该方法显著优于传统的DRL方法，在资源分配效率方面提高了高达22%，并确保了在多种O-RAN切片中实现更优的QoS满意度。', 'title_zh': '针对特定任务的Sharpness Aware O-RAN资源管理多代理强化学习方法'}
{'arxiv_id': 'arXiv:2511.15055', 'title': 'Learning Human-Like RL Agents Through Trajectory Optimization With Action Quantization', 'authors': 'Jian-Ting Guo, Yu-Cheng Chen, Ping-Chun Hsieh, Kuo-Hao Ho, Po-Wei Huang, Ti-Rong Wu, I-Chen Wu', 'link': 'https://arxiv.org/abs/2511.15055', 'abstract': 'Human-like agents have long been one of the goals in pursuing artificial intelligence. Although reinforcement learning (RL) has achieved superhuman performance in many domains, relatively little attention has been focused on designing human-like RL agents. As a result, many reward-driven RL agents often exhibit unnatural behaviors compared to humans, raising concerns for both interpretability and trustworthiness. To achieve human-like behavior in RL, this paper first formulates human-likeness as trajectory optimization, where the objective is to find an action sequence that closely aligns with human behavior while also maximizing rewards, and adapts the classic receding-horizon control to human-like learning as a tractable and efficient implementation. To achieve this, we introduce Macro Action Quantization (MAQ), a human-like RL framework that distills human demonstrations into macro actions via Vector-Quantized VAE. Experiments on D4RL Adroit benchmarks show that MAQ significantly improves human-likeness, increasing trajectory similarity scores, and achieving the highest human-likeness rankings among all RL agents in the human evaluation study. Our results also demonstrate that MAQ can be easily integrated into various off-the-shelf RL algorithms, opening a promising direction for learning human-like RL agents. Our code is available at this https URL.', 'abstract_zh': '类人代理在追求人工智能中的长期目标之一。尽管强化学习（RL）已在许多领域实现了超人性能，但相对较少关注设计类人的RL代理。因此，许多奖励驱动的RL代理经常表现出与人类不自然的行为，这在可解释性和可信度方面引起了担忧。为了在RL中实现类人行为，本文首先将类人性形式化为轨迹优化，其中目标是找到一个与人类行为紧密对齐且同时最大化奖励的动作序列，并将经典的局部反馈控制适应为类人的学习，从而实现可操作且高效的实施方案。为此，我们引入了宏动作量化（MAQ），这是一种类人RL框架，通过向量量化VAE将人类演示提炼为宏动作。在D4RL Adroit基准上的实验结果显示，MAQ显著提高了类人性，增加了轨迹相似性得分，并在人类评估研究中实现了所有RL代理中最高的类人性排名。我们的结果还表明，MAQ可以轻松整合到各种即用型RL算法中，为学习类人RL代理开启了有希望的方向。我们的代码可在以下链接获取：this https URL。', 'title_zh': '通过动作量化进行轨迹优化学习类人类的RL代理'}
{'arxiv_id': 'arXiv:2511.15002', 'title': 'Task Specific Sharpness Aware O-RAN Resource Management using Multi Agent Reinforcement Learning', 'authors': 'Fatemeh Lotfi, Hossein Rajoli, Fatemeh Afghah', 'link': 'https://arxiv.org/abs/2511.15002', 'abstract': 'Next-generation networks utilize the Open Radio Access Network (O-RAN) architecture to enable dynamic resource management, facilitated by the RAN Intelligent Controller (RIC). While deep reinforcement learning (DRL) models show promise in optimizing network resources, they often struggle with robustness and generalizability in dynamic environments. This paper introduces a novel resource management approach that enhances the Soft Actor Critic (SAC) algorithm with Sharpness-Aware Minimization (SAM) in a distributed Multi-Agent RL (MARL) framework. Our method introduces an adaptive and selective SAM mechanism, where regularization is explicitly driven by temporal-difference (TD)-error variance, ensuring that only agents facing high environmental complexity are regularized. This targeted strategy reduces unnecessary overhead, improves training stability, and enhances generalization without sacrificing learning efficiency. We further incorporate a dynamic $\\rho$ scheduling scheme to refine the exploration-exploitation trade-off across agents. Experimental results show our method significantly outperforms conventional DRL approaches, yielding up to a $22\\%$ improvement in resource allocation efficiency and ensuring superior QoS satisfaction across diverse O-RAN slices.', 'abstract_zh': '下一代网络利用Open Radio Access Network (O-RAN) 架构并通过RAN Intelligent Controller (RIC) 实现动态资源管理。虽然深度强化学习（DRL）模型在优化网络资源方面表现出潜力，但往往在动态环境中面临 robustness 和 generalizability 的挑战。本文提出了一种新颖的资源管理方法，在分布式多代理 RL（MARL）框架中增强了 Soft Actor Critic (SAC) 算法，并引入了基于梯度尖锐化意识最小化（Sharpness-Aware Minimization, SAM）的自适应和选择性机制，通过显式驱动时间差分（TD）误差方差来正则化，确保仅在面临高环境复杂性的代理上应用正则化。这种有针对性的策略减少了不必要的开销，提高了训练稳定性，并在不牺牲学习效率的情况下增强了泛化能力。此外，我们还引入了动态 $\\rho$ 调度方案以优化代理间的探索-利用权衡。实验结果表明，本文方法显著优于传统的 DRL 方法，在资源分配效率上提高了高达 22%，并在多种 O-RAN 切片中确保了更优的 QoS 满足度。', 'title_zh': '任务特定的锐度感知O-RAN资源管理多代理强化学习方法'}
{'arxiv_id': 'arXiv:2511.14853', 'title': 'Uncertainty-Aware Measurement of Scenario Suite Representativeness for Autonomous Systems', 'authors': 'Robab Aghazadeh Chakherlou, Siddartha Khastgir, Xingyu Zhao, Jerein Jeyachandran, Shufeng Chen', 'link': 'https://arxiv.org/abs/2511.14853', 'abstract': 'Assuring the trustworthiness and safety of AI systems, e.g., autonomous vehicles (AV), depends critically on the data-related safety properties, e.g., representativeness, completeness, etc., of the datasets used for their training and testing. Among these properties, this paper focuses on representativeness-the extent to which the scenario-based data used for training and testing, reflect the operational conditions that the system is designed to operate safely in, i.e., Operational Design Domain (ODD) or expected to encounter, i.e., Target Operational Domain (TOD). We propose a probabilistic method that quantifies representativeness by comparing the statistical distribution of features encoded by the scenario suites with the corresponding distribution of features representing the TOD, acknowledging that the true TOD distribution is unknown, as it can only be inferred from limited data.\nWe apply an imprecise Bayesian method to handle limited data and uncertain priors. The imprecise Bayesian formulation produces interval-valued, uncertainty-aware estimates of representativeness, rather than a single value. We present a numerical example comparing the distributions of the scenario suite and the inferred TOD across operational categories-weather, road type, time of day, etc., under dependencies and prior uncertainty. We estimate representativeness locally (between categories) and globally as an interval.', 'abstract_zh': '保证人工智能系统，例如自动驾驶车辆（AV）的安全性和可信度，关键在于确保用于训练和测试的数据集相关安全属性，例如代表性和完整性等。本文专注于代表性的量化，即训练和测试所使用的情景数据在多大程度上反映系统设计的安全运行条件或预期遇到的情况，包括操作设计领域（ODD）和目标操作领域（TOD）。我们提出了一种概率方法，通过比较情景套件中的特征统计分布与代表TOD特征的分布来量化代表性，考虑到真正的TOD分布是未知的，只能从有限的数据中推断得出。', 'title_zh': '自主系统场景集代表性的不确定性感知度量'}
{'arxiv_id': 'arXiv:2511.15002', 'title': 'Task Specific Sharpness Aware O-RAN Resource Management using Multi Agent Reinforcement Learning', 'authors': 'Fatemeh Lotfi, Hossein Rajoli, Fatemeh Afghah', 'link': 'https://arxiv.org/abs/2511.15002', 'abstract': 'Next-generation networks utilize the Open Radio Access Network (O-RAN) architecture to enable dynamic resource management, facilitated by the RAN Intelligent Controller (RIC). While deep reinforcement learning (DRL) models show promise in optimizing network resources, they often struggle with robustness and generalizability in dynamic environments. This paper introduces a novel resource management approach that enhances the Soft Actor Critic (SAC) algorithm with Sharpness-Aware Minimization (SAM) in a distributed Multi-Agent RL (MARL) framework. Our method introduces an adaptive and selective SAM mechanism, where regularization is explicitly driven by temporal-difference (TD)-error variance, ensuring that only agents facing high environmental complexity are regularized. This targeted strategy reduces unnecessary overhead, improves training stability, and enhances generalization without sacrificing learning efficiency. We further incorporate a dynamic $\\rho$ scheduling scheme to refine the exploration-exploitation trade-off across agents. Experimental results show our method significantly outperforms conventional DRL approaches, yielding up to a $22\\%$ improvement in resource allocation efficiency and ensuring superior QoS satisfaction across diverse O-RAN slices.', 'abstract_zh': '下一代网络利用开放无线接入网（O-RAN）架构并通过无线接入网智能控制器（RIC）实现动态资源管理。虽然深度强化学习（DRL）模型在优化网络资源方面显示出潜力，但它们在动态环境中的健壮性和泛化能力通常较差。本文介绍了一种新颖的资源管理方法，该方法在分布式多代理强化学习（MARL）框架中增强了Soft Actor Critic（SAC）算法，并结合了Sharpness-Aware Minimization（SAM）机制。该方法引入了一种自适应和选择性的SAM机制，通过时间差分（TD）误差方差显式驱动正则化，确保仅在面对高环境复杂性时才进行正则化。这一目标策略减少了不必要的开销，提高了训练稳定性，并在不牺牲学习效率的情况下增强泛化能力。此外，本文还引入了一种动态$\\rho$调度方案，以跨代理优化探索与利用的权衡。实验结果表明，该方法显著优于传统DRL方法，在资源分配效率上提升了高达22%，并在各种O-RAN切片中确保了更优的QoS满意度。', 'title_zh': '任务特定的敏锐度意识O-RAN资源管理多代理强化学习'}
{'arxiv_id': 'arXiv:2511.14853', 'title': 'Uncertainty-Aware Measurement of Scenario Suite Representativeness for Autonomous Systems', 'authors': 'Robab Aghazadeh Chakherlou, Siddartha Khastgir, Xingyu Zhao, Jerein Jeyachandran, Shufeng Chen', 'link': 'https://arxiv.org/abs/2511.14853', 'abstract': 'Assuring the trustworthiness and safety of AI systems, e.g., autonomous vehicles (AV), depends critically on the data-related safety properties, e.g., representativeness, completeness, etc., of the datasets used for their training and testing. Among these properties, this paper focuses on representativeness-the extent to which the scenario-based data used for training and testing, reflect the operational conditions that the system is designed to operate safely in, i.e., Operational Design Domain (ODD) or expected to encounter, i.e., Target Operational Domain (TOD). We propose a probabilistic method that quantifies representativeness by comparing the statistical distribution of features encoded by the scenario suites with the corresponding distribution of features representing the TOD, acknowledging that the true TOD distribution is unknown, as it can only be inferred from limited data.\nWe apply an imprecise Bayesian method to handle limited data and uncertain priors. The imprecise Bayesian formulation produces interval-valued, uncertainty-aware estimates of representativeness, rather than a single value. We present a numerical example comparing the distributions of the scenario suite and the inferred TOD across operational categories-weather, road type, time of day, etc., under dependencies and prior uncertainty. We estimate representativeness locally (between categories) and globally as an interval.', 'abstract_zh': '确保人工智能系统，例如自主车辆的信任worthiness和安全性取决于所使用的训练和测试数据的安全属性，如代表性、完整性等。本文专注于代表性，即场景数据在训练和测试中反映系统设计运行的运营设计领域（ODD）或预期遇到的目标运营域（TOD）的程度。我们提出了一种概率方法，通过将场景套件编码的特征统计分布与TOD特征的统计分布进行比较来量化代表性，考虑到真正的TOD分布是未知的，只能从有限的数据中推断得出。', 'title_zh': '自主系统场景套件代表性的不确定性意识测量'}
{'arxiv_id': 'arXiv:2511.14819', 'title': 'Project Rachel: Can an AI Become a Scholarly Author?', 'authors': 'Martin Monperrus, Benoit Baudry, Clément Vidal', 'link': 'https://arxiv.org/abs/2511.14819', 'abstract': 'This paper documents Project Rachel, an action research study that created and tracked a complete AI academic identity named Rachel So. Through careful publication of AI-generated research papers, we investigate how the scholarly ecosystem responds to AI authorship. Rachel So published 10+ papers between March and October 2025, was cited, and received a peer review invitation. We discuss the implications of AI authorship on publishers, researchers, and the scientific system at large. This work contributes empirical action research data to the necessary debate about the future of scholarly communication with super human, hyper capable AI systems.', 'abstract_zh': '本研究记录了Project Rachel项目，该项目创建并跟踪了一个完整的AI学术身份瑞秋·S。通过精心发表由AI生成的研究论文，我们探究学术生态系统对AI作者身份的反应。瑞秋·S在2025年3月至10月期间发表了10篇以上的论文，被引用，并收到了审稿邀请。我们讨论AI作者身份对未来出版商、研究人员和整个科学系统的潜在影响。本研究为关于与超人类、超能力AI系统进行学术交流的必要辩论贡献了实证行动研究数据。', 'title_zh': '项目瑞秋：AI能否成为学术作者？'}
{'arxiv_id': 'arXiv:2511.14819', 'title': 'Project Rachel: Can an AI Become a Scholarly Author?', 'authors': 'Martin Monperrus, Benoit Baudry, Clément Vidal', 'link': 'https://arxiv.org/abs/2511.14819', 'abstract': 'This paper documents Project Rachel, an action research study that created and tracked a complete AI academic identity named Rachel So. Through careful publication of AI-generated research papers, we investigate how the scholarly ecosystem responds to AI authorship. Rachel So published 10+ papers between March and October 2025, was cited, and received a peer review invitation. We discuss the implications of AI authorship on publishers, researchers, and the scientific system at large. This work contributes empirical action research data to the necessary debate about the future of scholarly communication with super human, hyper capable AI systems.', 'abstract_zh': '该项目研究了Rachel So，一个生成完整AI学术身份的行动研究案例，探讨了AI作者身份如何影响学术生态系统。自2025年3月至10月，Rachel So发表了10余篇研究论文，并获得了引用和同行评审邀请。本文讨论了超人类、超能力强的AI系统对未来学术交流的影响，并为必要辩论提供了实证的行动研究数据。', 'title_zh': '项目蕾切尔：AI能成为学术作者吗？'}
{'arxiv_id': 'arXiv:2511.14853', 'title': 'Uncertainty-Aware Measurement of Scenario Suite Representativeness for Autonomous Systems', 'authors': 'Robab Aghazadeh Chakherlou, Siddartha Khastgir, Xingyu Zhao, Jerein Jeyachandran, Shufeng Chen', 'link': 'https://arxiv.org/abs/2511.14853', 'abstract': 'Assuring the trustworthiness and safety of AI systems, e.g., autonomous vehicles (AV), depends critically on the data-related safety properties, e.g., representativeness, completeness, etc., of the datasets used for their training and testing. Among these properties, this paper focuses on representativeness-the extent to which the scenario-based data used for training and testing, reflect the operational conditions that the system is designed to operate safely in, i.e., Operational Design Domain (ODD) or expected to encounter, i.e., Target Operational Domain (TOD). We propose a probabilistic method that quantifies representativeness by comparing the statistical distribution of features encoded by the scenario suites with the corresponding distribution of features representing the TOD, acknowledging that the true TOD distribution is unknown, as it can only be inferred from limited data.\nWe apply an imprecise Bayesian method to handle limited data and uncertain priors. The imprecise Bayesian formulation produces interval-valued, uncertainty-aware estimates of representativeness, rather than a single value. We present a numerical example comparing the distributions of the scenario suite and the inferred TOD across operational categories-weather, road type, time of day, etc., under dependencies and prior uncertainty. We estimate representativeness locally (between categories) and globally as an interval.', 'abstract_zh': '确保人工智能系统如自动驾驶车辆的信任worthiness与安全性依赖于用于其训练和测试的数据的相关安全属性，例如代表性、完整性等。本文重点关注代表性，即用于训练和测试的基于场景的数据在多大程度上反映了系统设计用于安全运行的操作设计域（ODD）或预期可能遇到的目标操作域（TOD）。我们提出了一种概率方法，通过比较场景套件中编码的特征的统计分布与表示TOD的相应分布来量化代表性，同时承认真正的TOD分布是未知的，因为它只能从有限的数据中推断出来。我们使用模糊贝叶斯方法处理有限数据和不确定性先验。模糊贝叶斯公式产生区间值、具有不确定性的代表性估计，而不是单一值。我们在具有依赖性和先验不确定性的情况下展示了操作类别（如天气、道路类型、时间等）下场景套件和推断的TOD分布的数值示例，局部估计代表性并在全局上表示为区间。', 'title_zh': '自主系统场景集合代表性的不确定性感知度量'}
{'arxiv_id': 'arXiv:2511.14788', 'title': 'Subnational Geocoding of Global Disasters Using Large Language Models', 'authors': 'Michele Ronco, Damien Delforge, Wiebke S. Jäger, Christina Corbane', 'link': 'https://arxiv.org/abs/2511.14788', 'abstract': 'Subnational location data of disaster events are critical for risk assessment and disaster risk reduction. Disaster databases such as EM-DAT often report locations in unstructured textual form, with inconsistent granularity or spelling, that make it difficult to integrate with spatial datasets. We present a fully automated LLM-assisted workflow that processes and cleans textual location information using GPT-4o, and assigns geometries by cross-checking three independent geoinformation repositories: GADM, OpenStreetMap and Wikidata. Based on the agreement and availability of these sources, we assign a reliability score to each location while generating subnational geometries. Applied to the EM-DAT dataset from 2000 to 2024, the workflow geocodes 14,215 events across 17,948 unique locations. Unlike previous methods, our approach requires no manual intervention, covers all disaster types, enables cross-verification across multiple sources, and allows flexible remapping to preferred frameworks. Beyond the dataset, we demonstrate the potential of LLMs to extract and structure geographic information from unstructured text, offering a scalable and reliable method for related analyses.', 'abstract_zh': '灾害事件的亚国家位置数据对于风险评估和灾害风险减少至关重要。EM-DAT等灾害数据库常常以不结构化的文本形式报告位置信息，具有不一致的粒度和拼写，难以与空间数据集集成。我们提出了一种完全自动化的基于大语言模型的工作流，使用GPT-4o处理和清理文本位置信息，并通过交叉验证三个独立的地理信息系统仓库：GADM、OpenStreetMap和Wikidata来分配几何图形。基于这些来源的一致性和可用性，我们在生成亚国家几何图形时为每个位置分配一个可靠性评分。将该工作流应用于2000年至2024年的EM-DAT数据集，成功地理编码了17,948个唯一位置的14,215个事件。与以前的方法不同，我们的方法不需要人工干预，涵盖了所有类型的灾害，能够在多个源之间进行跨验证，并允许灵活重新映射到首选框架。此外，我们展示了大语言模型从不结构化的文本中提取和组织地理信息的潜力，提供了一种可扩展且可靠的方法，用于相关分析。', 'title_zh': '使用大型语言模型进行全局灾害的亚国家地理编码'}
{'arxiv_id': 'arXiv:2511.14819', 'title': 'Project Rachel: Can an AI Become a Scholarly Author?', 'authors': 'Martin Monperrus, Benoit Baudry, Clément Vidal', 'link': 'https://arxiv.org/abs/2511.14819', 'abstract': 'This paper documents Project Rachel, an action research study that created and tracked a complete AI academic identity named Rachel So. Through careful publication of AI-generated research papers, we investigate how the scholarly ecosystem responds to AI authorship. Rachel So published 10+ papers between March and October 2025, was cited, and received a peer review invitation. We discuss the implications of AI authorship on publishers, researchers, and the scientific system at large. This work contributes empirical action research data to the necessary debate about the future of scholarly communication with super human, hyper capable AI systems.', 'abstract_zh': '本研究记录了Project Rachel项目，该项目创建并跟踪了一个完整的AI学术身份——Rachel So。通过精心发布的AI生成的研究论文，我们探讨了学术生态系统对AI作者身份的响应。Rachel So在2025年3月至10月间发表了10多篇论文，并被引用，还收到了同行评审邀请。我们讨论了AI作者身份对出版商、研究人员及更广泛的科学系统的潜在影响。本研究为关于超人类、超能力强的AI系统未来对学术交流影响的必要辩论提供了实证行动研究数据。', 'title_zh': '项目蕾切尔：AI能否成为学术作者？'}
{'arxiv_id': 'arXiv:2511.14788', 'title': 'Subnational Geocoding of Global Disasters Using Large Language Models', 'authors': 'Michele Ronco, Damien Delforge, Wiebke S. Jäger, Christina Corbane', 'link': 'https://arxiv.org/abs/2511.14788', 'abstract': 'Subnational location data of disaster events are critical for risk assessment and disaster risk reduction. Disaster databases such as EM-DAT often report locations in unstructured textual form, with inconsistent granularity or spelling, that make it difficult to integrate with spatial datasets. We present a fully automated LLM-assisted workflow that processes and cleans textual location information using GPT-4o, and assigns geometries by cross-checking three independent geoinformation repositories: GADM, OpenStreetMap and Wikidata. Based on the agreement and availability of these sources, we assign a reliability score to each location while generating subnational geometries. Applied to the EM-DAT dataset from 2000 to 2024, the workflow geocodes 14,215 events across 17,948 unique locations. Unlike previous methods, our approach requires no manual intervention, covers all disaster types, enables cross-verification across multiple sources, and allows flexible remapping to preferred frameworks. Beyond the dataset, we demonstrate the potential of LLMs to extract and structure geographic information from unstructured text, offering a scalable and reliable method for related analyses.', 'abstract_zh': '区域级别的灾害事件位置数据对于风险评估和灾害风险管理至关重要。EM-DAT等灾害数据库往往以无结构文本形式报告位置信息，且粒度和拼写不一致，难以与空间数据集集成。我们提出了一种完全自动化的基于大语言模型的工作流，使用GPT-4o处理和清理文本位置信息，并通过交叉检查三个独立的地理信息系统仓库：GADM、OpenStreetMap和Wikidata来分配几何形状。基于这些来源的一致性和可用性，我们在生成区域级别几何形状的同时为每个位置分配了一个可靠性评分。将该工作流程应用于2000年至2024年的EM-DAT数据集，可地理编码14,215个事件，覆盖17,948个唯一位置。与以往方法不同，我们的方法无需人工干预，涵盖了所有类型的灾害，能够在多个来源之间进行交叉验证，并允许灵活的重新映射到首选框架。除了数据集之外，我们展示了大语言模型从无结构文本中提取和结构化地理信息的潜力，提供了一种可扩展且可靠的分析方法。', 'title_zh': '使用大型语言模型进行地方级全球灾害地理编码'}
{'arxiv_id': 'arXiv:2511.14780', 'title': 'Ask WhAI:Probing Belief Formation in Role-Primed LLM Agents', 'authors': 'Keith Moore, Jun W. Kim, David Lyu, Jeffrey Heo, Ehsan Adeli', 'link': 'https://arxiv.org/abs/2511.14780', 'abstract': 'We present Ask WhAI, a systems-level framework for inspecting and perturbing belief states in multi-agent interactions. The framework records and replays agent interactions, supports out-of-band queries into each agent\'s beliefs and rationale, and enables counterfactual evidence injection to test how belief structures respond to new information. We apply the framework to a medical case simulator notable for its multi-agent shared memory (a time-stamped electronic medical record, or EMR) and an oracle agent (the LabAgent) that holds ground truth lab results revealed only when explicitly queried. We stress-test the system on a multi-specialty diagnostic journey for a child with an abrupt-onset neuropsychiatric presentation. Large language model agents, each primed with strong role-specific priors ("act like a neurologist", "act like an infectious disease specialist"), write to a shared medical record and interact with a moderator across sequential or parallel encounters. Breakpoints at key diagnostic moments enable pre- and post-event belief queries, allowing us to distinguish entrenched priors from reasoning or evidence-integration effects. The simulation reveals that agent beliefs often mirror real-world disciplinary stances, including overreliance on canonical studies and resistance to counterevidence, and that these beliefs can be traced and interrogated in ways not possible with human experts. By making such dynamics visible and testable, Ask WhAI offers a reproducible way to study belief formation and epistemic silos in multi-agent scientific reasoning.', 'abstract_zh': 'Ask WhAI：一个用于多agent交互中信念状态检查和扰动的系统级框架', 'title_zh': '问WhAI：探究角色引导的大语言模型代理的信念形成过程'}
{'arxiv_id': 'arXiv:2511.14780', 'title': 'Ask WhAI:Probing Belief Formation in Role-Primed LLM Agents', 'authors': 'Keith Moore, Jun W. Kim, David Lyu, Jeffrey Heo, Ehsan Adeli', 'link': 'https://arxiv.org/abs/2511.14780', 'abstract': 'We present Ask WhAI, a systems-level framework for inspecting and perturbing belief states in multi-agent interactions. The framework records and replays agent interactions, supports out-of-band queries into each agent\'s beliefs and rationale, and enables counterfactual evidence injection to test how belief structures respond to new information. We apply the framework to a medical case simulator notable for its multi-agent shared memory (a time-stamped electronic medical record, or EMR) and an oracle agent (the LabAgent) that holds ground truth lab results revealed only when explicitly queried. We stress-test the system on a multi-specialty diagnostic journey for a child with an abrupt-onset neuropsychiatric presentation. Large language model agents, each primed with strong role-specific priors ("act like a neurologist", "act like an infectious disease specialist"), write to a shared medical record and interact with a moderator across sequential or parallel encounters. Breakpoints at key diagnostic moments enable pre- and post-event belief queries, allowing us to distinguish entrenched priors from reasoning or evidence-integration effects. The simulation reveals that agent beliefs often mirror real-world disciplinary stances, including overreliance on canonical studies and resistance to counterevidence, and that these beliefs can be traced and interrogated in ways not possible with human experts. By making such dynamics visible and testable, Ask WhAI offers a reproducible way to study belief formation and epistemic silos in multi-agent scientific reasoning.', 'abstract_zh': 'Ask WhAI：多_agent_交互中信念状态检查与扰动的系统级框架', 'title_zh': '探ASK WhAI：探究角色引导的大语言模型代理的信念形成过程'}
{'arxiv_id': 'arXiv:2511.14788', 'title': 'Subnational Geocoding of Global Disasters Using Large Language Models', 'authors': 'Michele Ronco, Damien Delforge, Wiebke S. Jäger, Christina Corbane', 'link': 'https://arxiv.org/abs/2511.14788', 'abstract': 'Subnational location data of disaster events are critical for risk assessment and disaster risk reduction. Disaster databases such as EM-DAT often report locations in unstructured textual form, with inconsistent granularity or spelling, that make it difficult to integrate with spatial datasets. We present a fully automated LLM-assisted workflow that processes and cleans textual location information using GPT-4o, and assigns geometries by cross-checking three independent geoinformation repositories: GADM, OpenStreetMap and Wikidata. Based on the agreement and availability of these sources, we assign a reliability score to each location while generating subnational geometries. Applied to the EM-DAT dataset from 2000 to 2024, the workflow geocodes 14,215 events across 17,948 unique locations. Unlike previous methods, our approach requires no manual intervention, covers all disaster types, enables cross-verification across multiple sources, and allows flexible remapping to preferred frameworks. Beyond the dataset, we demonstrate the potential of LLMs to extract and structure geographic information from unstructured text, offering a scalable and reliable method for related analyses.', 'abstract_zh': '次国家层次的灾难事件地理位置数据对于风险评估和灾害风险管理至关重要。EM-DAT等灾难数据库往往以不结构化的文本形式报告地理位置，且粒度不一或拼写不规范，这使得与空间数据集整合困难重重。我们提出了一种完全自动化的基于LLM的工作流，利用GPT-4o处理和清洗文本地理位置信息，并通过交叉检查三个独立的地理信息仓库（GADM、OpenStreetMap和Wikidata）分配几何位置。根据这些来源的一致性和可用性，我们在生成次国家层次几何位置的同时为每个位置打上可靠性评分。将该工作流应用于2000年至2024年的EM-DAT数据集，共处理和地理编码了14,215个事件，覆盖17,948个独特的地理位置。与以往方法不同，我们的方法无需人工干预，适用于所有类型的灾难，能够跨多个来源进行交叉验证，并允许灵活地重新映射到首选框架。除此之外，我们还展示了LLM提取和结构化不结构化文本中的地理信息的潜力，提供了一种可扩展且可靠的相关分析方法。', 'title_zh': '使用大型语言模型进行全球灾害的亚国家级地理编码'}
{'arxiv_id': 'arXiv:2511.14778', 'title': 'Learning Interestingness in Automated Mathematical Theory Formation', 'authors': 'George Tsoukalas, Rahul Saha, Amitayush Thakur, Sabrina Reguyal, Swarat Chaudhuri', 'link': 'https://arxiv.org/abs/2511.14778', 'abstract': 'We take two key steps in automating the open-ended discovery of new mathematical theories, a grand challenge in artificial intelligence. First, we introduce $\\emph{FERMAT}$, a reinforcement learning (RL) environment that models concept discovery and theorem-proving using a set of symbolic actions, opening up a range of RL problems relevant to theory discovery. Second, we explore a specific problem through $\\emph{FERMAT}$: automatically scoring the $\\emph{interestingness}$ of mathematical objects. We investigate evolutionary algorithms for synthesizing nontrivial interestingness measures. In particular, we introduce an LLM-based evolutionary algorithm that features function abstraction, leading to notable improvements in discovering elementary number theory and finite fields over hard-coded baselines. We open-source the $\\emph{FERMAT}$ environment at this URL(this https URL).', 'abstract_zh': '我们在自动化开放式新的数学理论发现中采取了两项关键步骤，这是人工智能领域的重大挑战。首先，我们引入了FERMAT环境，这是一种基于符号操作的强化学习（RL）环境，用于建模概念发现和定理证明，这为理论发现相关的RL问题打开了新的大门。其次，我们通过FERMAT环境探讨了一个具体问题：自动评估数学对象的“有趣性”。我们研究了演化算法以合成非平凡的有趣性度量。特别地，我们引入了一种基于LLM的演化算法，该算法具备函数抽象特性，在发现初等数论和有限域方面相比硬编码基线取得了显著改进。我们在该URL(this https URL)开源了FERMAT环境。', 'title_zh': '自动数学理论形成中的有趣性学习'}
{'arxiv_id': 'arXiv:2511.14780', 'title': 'Ask WhAI:Probing Belief Formation in Role-Primed LLM Agents', 'authors': 'Keith Moore, Jun W. Kim, David Lyu, Jeffrey Heo, Ehsan Adeli', 'link': 'https://arxiv.org/abs/2511.14780', 'abstract': 'We present Ask WhAI, a systems-level framework for inspecting and perturbing belief states in multi-agent interactions. The framework records and replays agent interactions, supports out-of-band queries into each agent\'s beliefs and rationale, and enables counterfactual evidence injection to test how belief structures respond to new information. We apply the framework to a medical case simulator notable for its multi-agent shared memory (a time-stamped electronic medical record, or EMR) and an oracle agent (the LabAgent) that holds ground truth lab results revealed only when explicitly queried. We stress-test the system on a multi-specialty diagnostic journey for a child with an abrupt-onset neuropsychiatric presentation. Large language model agents, each primed with strong role-specific priors ("act like a neurologist", "act like an infectious disease specialist"), write to a shared medical record and interact with a moderator across sequential or parallel encounters. Breakpoints at key diagnostic moments enable pre- and post-event belief queries, allowing us to distinguish entrenched priors from reasoning or evidence-integration effects. The simulation reveals that agent beliefs often mirror real-world disciplinary stances, including overreliance on canonical studies and resistance to counterevidence, and that these beliefs can be traced and interrogated in ways not possible with human experts. By making such dynamics visible and testable, Ask WhAI offers a reproducible way to study belief formation and epistemic silos in multi-agent scientific reasoning.', 'abstract_zh': 'Ask WhAI：多智能体交互中的信念状态检验与扰动系统级框架', 'title_zh': 'Ask WhAI: 探究角色引导的大语言模型代理的信念形成过程'}
{'arxiv_id': 'arXiv:2511.14778', 'title': 'Learning Interestingness in Automated Mathematical Theory Formation', 'authors': 'George Tsoukalas, Rahul Saha, Amitayush Thakur, Sabrina Reguyal, Swarat Chaudhuri', 'link': 'https://arxiv.org/abs/2511.14778', 'abstract': 'We take two key steps in automating the open-ended discovery of new mathematical theories, a grand challenge in artificial intelligence. First, we introduce $\\emph{FERMAT}$, a reinforcement learning (RL) environment that models concept discovery and theorem-proving using a set of symbolic actions, opening up a range of RL problems relevant to theory discovery. Second, we explore a specific problem through $\\emph{FERMAT}$: automatically scoring the $\\emph{interestingness}$ of mathematical objects. We investigate evolutionary algorithms for synthesizing nontrivial interestingness measures. In particular, we introduce an LLM-based evolutionary algorithm that features function abstraction, leading to notable improvements in discovering elementary number theory and finite fields over hard-coded baselines. We open-source the $\\emph{FERMAT}$ environment at this URL(this https URL).', 'abstract_zh': '我们在自动化开放式新数学理论发现中采取了两个关键步骤，这是人工智能领域的重大挑战。首先，我们引入了$\\emph{FERMAT}$，一个使用符号操作来建模范畴发现和定理证明的强化学习环境，从而开启了与理论发现相关的广泛RL问题。其次，我们通过$\\emph{FERMAT}$探索了一个具体问题：自动评估数学对象的$\\emph{有趣性}$。我们研究了演化算法以合成非平凡的有趣性度量。特别是，我们引入了一种基于大语言模型的演化算法，该算法包含函数抽象，从而在发现初等数论和有限域方面取得了显著改进，超过了硬编码的Baseline。我们在此URL开源了$\\emph{FERMAT}$环境(this https URL)。', 'title_zh': '自动数学理论形成中的兴趣性学习'}
{'arxiv_id': 'arXiv:2511.14777', 'title': 'The Illusion of Procedural Reasoning: Measuring Long-Horizon FSM Execution in LLMs', 'authors': 'Mahdi Samiei, Mahdi Mansouri, Mahdieh Soleymani Baghshah', 'link': 'https://arxiv.org/abs/2511.14777', 'abstract': "Large language models (LLMs) have achieved remarkable results on tasks framed as reasoning problems, yet their true ability to perform procedural reasoning, executing multi-step, rule-based computations remains unclear. Unlike algorithmic systems, which can deterministically execute long-horizon symbolic procedures, LLMs often degrade under extended reasoning chains, but there is no controlled, interpretable benchmark to isolate and measure this collapse. We introduce Finite-State Machine (FSM) Execution as a minimal, fully interpretable framework for evaluating the procedural reasoning capacity of LLMs. In our setup, the model is given an explicit FSM definition and must execute it step-by-step given input actions, maintaining state consistency over multiple turns. This task requires no world knowledge, only faithful application of deterministic transition rules, making it a direct probe of the model's internal procedural fidelity. We measure both Turn Accuracy and Task Accuracy to disentangle immediate computation from cumulative state maintenance. Empirical results reveal systematic degradation as task horizon or branching complexity increases. Models perform significantly worse when rule retrieval involves high branching factors than when memory span is long. Larger models show improved local accuracy but remain brittle under multi-step reasoning unless explicitly prompted to externalize intermediate steps. FSM-based evaluation offers a transparent, complexity-controlled probe for diagnosing this failure mode and guiding the design of inductive biases that enable genuine long-horizon procedural competence. By grounding reasoning in measurable execution fidelity rather than surface correctness, this work helps establish a rigorous experimental foundation for understanding and improving the algorithmic reliability of LLMs.", 'abstract_zh': '大型语言模型在推理任务上取得了显著成果，但它们真正执行程序性推理、执行多步骤规则基础计算的能力仍不清楚。我们引入有限状态机（FSM）执行作为评估大型语言模型程序性推理能力的 minimalist、完全可解释框架。在我们的设置中，模型接收明确的FSM定义，并且必须在多个回合中根据输入动作逐步执行它，保持状态一致性。该任务不需要世界知识，只需要忠实应用确定性转移规则，使其成为对模型内部程序性准确性的直接探针。我们分别测量回合准确率和任务准确率以区分即时计算和累积状态维护。实验证据显示，随着任务时间跨度或分支复杂性的增加，系统性退化是显而易见的。当规则检索涉及较高的分支因子时，模型表现显著变差；而当记忆跨度较长时，则表现较好。更大的模型在局部准确率上有所改进，但在多步推理中仍表现出脆弱性，除非明确提示它们外部化中间步骤。基于有限状态机的评估提供了透明且复杂度可控的探针，用于诊断这种失败模式，并指导设计能够实现真实长期程序性能力的归纳偏好。通过将推理扎根于可衡量的执行准确率而不是表面的正确性，这项工作有助于建立理解并改进大型语言模型算法可靠性的严格实验基础。', 'title_zh': '程序推理的幻象：在大规模语言模型中衡量长_horizon FSM执行циально过程'}
{'arxiv_id': 'arXiv:2511.14778', 'title': 'Learning Interestingness in Automated Mathematical Theory Formation', 'authors': 'George Tsoukalas, Rahul Saha, Amitayush Thakur, Sabrina Reguyal, Swarat Chaudhuri', 'link': 'https://arxiv.org/abs/2511.14778', 'abstract': 'We take two key steps in automating the open-ended discovery of new mathematical theories, a grand challenge in artificial intelligence. First, we introduce $\\emph{FERMAT}$, a reinforcement learning (RL) environment that models concept discovery and theorem-proving using a set of symbolic actions, opening up a range of RL problems relevant to theory discovery. Second, we explore a specific problem through $\\emph{FERMAT}$: automatically scoring the $\\emph{interestingness}$ of mathematical objects. We investigate evolutionary algorithms for synthesizing nontrivial interestingness measures. In particular, we introduce an LLM-based evolutionary algorithm that features function abstraction, leading to notable improvements in discovering elementary number theory and finite fields over hard-coded baselines. We open-source the $\\emph{FERMAT}$ environment at this URL(this https URL).', 'abstract_zh': '我们在这项工作中共实现了自动化发现新数学理论的两个关键步骤，这是人工智能领域的一项宏伟挑战。首先，我们引入了$\\emph{FERMAT}$，一个基于符号操作的强化学习环境，用于建模概念发现和定理证明，从而开启了与理论发现相关的广泛RL问题空间。其次，我们通过$\\emph{FERMAT}$探讨了一个具体问题：自动评估数学对象的“有趣性”。我们研究了进化算法以合成非平凡的兴趣度量，并引入了一种基于大语言模型的进化算法，该算法具备函数抽象特性，并在发现初等数论和有限域方面取得了显著进步。我们开源了$\\emph{FERMAT}$环境，网址见下：(这个 https URL)。', 'title_zh': '自动数学理论形成中的兴趣性学习'}
{'arxiv_id': 'arXiv:2511.14777', 'title': 'The Illusion of Procedural Reasoning: Measuring Long-Horizon FSM Execution in LLMs', 'authors': 'Mahdi Samiei, Mahdi Mansouri, Mahdieh Soleymani Baghshah', 'link': 'https://arxiv.org/abs/2511.14777', 'abstract': "Large language models (LLMs) have achieved remarkable results on tasks framed as reasoning problems, yet their true ability to perform procedural reasoning, executing multi-step, rule-based computations remains unclear. Unlike algorithmic systems, which can deterministically execute long-horizon symbolic procedures, LLMs often degrade under extended reasoning chains, but there is no controlled, interpretable benchmark to isolate and measure this collapse. We introduce Finite-State Machine (FSM) Execution as a minimal, fully interpretable framework for evaluating the procedural reasoning capacity of LLMs. In our setup, the model is given an explicit FSM definition and must execute it step-by-step given input actions, maintaining state consistency over multiple turns. This task requires no world knowledge, only faithful application of deterministic transition rules, making it a direct probe of the model's internal procedural fidelity. We measure both Turn Accuracy and Task Accuracy to disentangle immediate computation from cumulative state maintenance. Empirical results reveal systematic degradation as task horizon or branching complexity increases. Models perform significantly worse when rule retrieval involves high branching factors than when memory span is long. Larger models show improved local accuracy but remain brittle under multi-step reasoning unless explicitly prompted to externalize intermediate steps. FSM-based evaluation offers a transparent, complexity-controlled probe for diagnosing this failure mode and guiding the design of inductive biases that enable genuine long-horizon procedural competence. By grounding reasoning in measurable execution fidelity rather than surface correctness, this work helps establish a rigorous experimental foundation for understanding and improving the algorithmic reliability of LLMs.", 'abstract_zh': '大型语言模型在推理问题框架下的成就显著，但其执行 procedural reasoning 能力，即执行多步、基于规则的计算的真实水平仍然不清楚。我们引入有限状态机（FSM）执行作为评估 LLMs 程序性推理能力的最小化、完全可解释框架。在我们的设置中，模型被给予明确的 FSM 定义，并必须在给定输入动作的情况下逐步执行它，保持多轮状态下的一致性。这个任务不需要世界知识，只需要忠实应用确定性的转换规则，使其成为对模型内部程序性精确度的直接探测。我们分别测量轮次准确率和任务准确率，以区分即时计算和累积状态维护。实证结果揭示出随着任务 horizon 或分支部繁复杂性的增加，系统性退化现象。当规则检索涉及高分支因子时，模型表现显著变差；而当记忆跨度较长时情况不同。较大的模型在局部准确率上有所提高，但除非明确提示外部化中间步骤，否则在多步推理下仍然脆弱。基于 FSM 的评估提供了透明且复杂度可控的探测方式，用于诊断这种失败模式，并指导设计使 LLMs 能够真正实现长期程序性能力的归纳偏置。通过将推理根植于可测量的执行精确度而非表面正确性，本文有助于建立一个严谨的实验证据基础，以理解并改善 LLMs 的算法可靠性。', 'title_zh': '程序推理的幻象：在大语言模型中测量长期 horizons FSM 执行'}
{'arxiv_id': 'arXiv:2511.15704', 'title': 'In-N-On: Scaling Egocentric Manipulation with in-the-wild and on-task Data', 'authors': 'Xiongyi Cai, Ri-Zhao Qiu, Geng Chen, Lai Wei, Isabella Liu, Tianshu Huang, Xuxin Cheng, Xiaolong Wang', 'link': 'https://arxiv.org/abs/2511.15704', 'abstract': 'Egocentric videos are a valuable and scalable data source to learn manipulation policies. However, due to significant data heterogeneity, most existing approaches utilize human data for simple pre-training, which does not unlock its full potential. This paper first provides a scalable recipe for collecting and using egocentric data by categorizing human data into two categories: in-the-wild and on-task alongside with systematic analysis on how to use the data. We first curate a dataset, PHSD, which contains over 1,000 hours of diverse in-the-wild egocentric data and over 20 hours of on-task data directly aligned to the target manipulation tasks. This enables learning a large egocentric language-conditioned flow matching policy, Human0. With domain adaptation techniques, Human0 minimizes the gap between humans and humanoids. Empirically, we show Human0 achieves several novel properties from scaling human data, including language following of instructions from only human data, few-shot learning, and improved robustness using on-task data. Project website: this https URL', 'abstract_zh': '自见证据是学习操作策略的宝贵且可扩展的数据来源。然而，由于数据异质性显著，大多数现有方法通过使用简单的预训练来利用人类数据，这并未充分挖掘其潜力。本文首先提供了一种可扩展的自见证据收集和使用方法，将人类数据分为两类：野外数据和任务相关数据，并对其使用方法进行了系统分析。我们首先构建了一个名为PHSD的数据集，包含超过1000小时的多样野外自见证据和超过20小时直接与目标操作任务对齐的任务相关数据，这使得能够学习一个大型自见证据语言条件流匹配策略Human0。通过领域适应技术，Human0 最小化了人类与类人者之间的差距。实证结果显示，Human0 从扩大人类数据规模中获得了几种新颖特性，包括仅使用人类数据的指令跟随、少样本学习以及使用任务相关数据提高鲁棒性。项目官网：这个 https URL。', 'title_zh': 'In-N-On: 通过野生数据和任务中数据扩展自我中心操作 skalability'}
{'arxiv_id': 'arXiv:2511.14777', 'title': 'The Illusion of Procedural Reasoning: Measuring Long-Horizon FSM Execution in LLMs', 'authors': 'Mahdi Samiei, Mahdi Mansouri, Mahdieh Soleymani Baghshah', 'link': 'https://arxiv.org/abs/2511.14777', 'abstract': "Large language models (LLMs) have achieved remarkable results on tasks framed as reasoning problems, yet their true ability to perform procedural reasoning, executing multi-step, rule-based computations remains unclear. Unlike algorithmic systems, which can deterministically execute long-horizon symbolic procedures, LLMs often degrade under extended reasoning chains, but there is no controlled, interpretable benchmark to isolate and measure this collapse. We introduce Finite-State Machine (FSM) Execution as a minimal, fully interpretable framework for evaluating the procedural reasoning capacity of LLMs. In our setup, the model is given an explicit FSM definition and must execute it step-by-step given input actions, maintaining state consistency over multiple turns. This task requires no world knowledge, only faithful application of deterministic transition rules, making it a direct probe of the model's internal procedural fidelity. We measure both Turn Accuracy and Task Accuracy to disentangle immediate computation from cumulative state maintenance. Empirical results reveal systematic degradation as task horizon or branching complexity increases. Models perform significantly worse when rule retrieval involves high branching factors than when memory span is long. Larger models show improved local accuracy but remain brittle under multi-step reasoning unless explicitly prompted to externalize intermediate steps. FSM-based evaluation offers a transparent, complexity-controlled probe for diagnosing this failure mode and guiding the design of inductive biases that enable genuine long-horizon procedural competence. By grounding reasoning in measurable execution fidelity rather than surface correctness, this work helps establish a rigorous experimental foundation for understanding and improving the algorithmic reliability of LLMs.", 'abstract_zh': '大型语言模型在作为推理问题的任务中取得了显著成果，但其真正执行程序推理的能力，即执行多步规则驱动计算的能力仍然不清楚。与可以确定性执行长时间符号程序的算法系统不同，大型语言模型在扩展的推理链中往往会表现不佳，但没有可控且可解释的基准来隔离和量度这种表现下降。我们引入有限状态机（FSM）执行作为评估大型语言模型程序推理容量的最小化、完全可解释框架。在我们的设置中，模型获得一个明确的FSM定义，并且必须在给定输入动作的情况下，逐步执行它，保持多次轮次中的状态一致性。该任务不需要世界知识，只需要忠实地应用确定性转换规则，使其成为对模型内部程序准确性的直接检测。我们测量轮次准确性和任务准确性以分离即时计算和累积状态维护。实证结果揭示了随着任务视距或分支复杂性的增加呈现出系统性的下降。当规则检索涉及高分支因子时，模型的表现显著较差，而在记忆跨度较长时则表现较好。较大的模型在局部准确性方面有所提高，但在多步推理中仍然脆弱，除非明确提示其外部化中间步骤。基于有限状态机的评估提供了一个透明且具有复杂度控制的检测工具，用于诊断这种失败模式并指导能够真正实现长期程序能力的归纳偏差的设计。通过将推理基于可量化的执行保真度而非表面正确性，这项工作有助于建立理解并改进大型语言模型算法可靠性的严谨实验基础。', 'title_zh': '程序推理的幻象：测量LLM中长时序_fsm执行'}
{'arxiv_id': 'arXiv:2511.15704', 'title': 'In-N-On: Scaling Egocentric Manipulation with in-the-wild and on-task Data', 'authors': 'Xiongyi Cai, Ri-Zhao Qiu, Geng Chen, Lai Wei, Isabella Liu, Tianshu Huang, Xuxin Cheng, Xiaolong Wang', 'link': 'https://arxiv.org/abs/2511.15704', 'abstract': 'Egocentric videos are a valuable and scalable data source to learn manipulation policies. However, due to significant data heterogeneity, most existing approaches utilize human data for simple pre-training, which does not unlock its full potential. This paper first provides a scalable recipe for collecting and using egocentric data by categorizing human data into two categories: in-the-wild and on-task alongside with systematic analysis on how to use the data. We first curate a dataset, PHSD, which contains over 1,000 hours of diverse in-the-wild egocentric data and over 20 hours of on-task data directly aligned to the target manipulation tasks. This enables learning a large egocentric language-conditioned flow matching policy, Human0. With domain adaptation techniques, Human0 minimizes the gap between humans and humanoids. Empirically, we show Human0 achieves several novel properties from scaling human data, including language following of instructions from only human data, few-shot learning, and improved robustness using on-task data. Project website: this https URL', 'abstract_zh': '主观视频是学习操作策略的一个宝贵且可扩展的数据来源。然而，由于数据显著异质性，大多数现有方法仅利用人类数据进行简单的预训练，未能充分发挥其潜力。本文首先提供了一种可扩展的方法来收集和利用主观数据，通过将人类数据分为两类：野制数据和任务中数据，并进行系统的数据分析。我们首先策划了一个名为PHSD的数据集，包含超过1000小时的多样化野制主观数据和超过20小时直接与目标操作任务对齐的任务中数据。这使得能够学习一个大型的主观语言条件流动匹配策略，名为Human0。通过领域适应技术，Human0减少了人类与类人机器人之间的差距。实验证明，Human0从放大人类数据中获得了几个新颖的属性，包括仅从人类数据遵循指令、少样本学习以及使用任务中数据提高鲁棒性。项目网址：this https URL。', 'title_zh': 'In-N-On: 在野外观数据和任务中数据扩展自视点操作技能'}
{'arxiv_id': 'arXiv:2511.15703', 'title': 'Think Visually, Reason Textually: Vision-Language Synergy in ARC', 'authors': 'Beichen Zhang, Yuhang Zang, Xiaoyi Dong, Yuhang Cao, Haodong Duan, Dahua Lin, Jiaqi Wang', 'link': 'https://arxiv.org/abs/2511.15703', 'abstract': 'Abstract reasoning from minimal examples remains a core unsolved problem for frontier foundation models such as GPT-5 and Grok 4. These models still fail to infer structured transformation rules from a handful of examples, which is a key hallmark of human intelligence. The Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI) provides a rigorous testbed for this capability, demanding conceptual rule induction and transfer to novel tasks. Most existing methods treat ARC-AGI as a purely textual reasoning task, overlooking the fact that humans rely heavily on visual abstraction when solving such puzzles. However, our pilot experiments reveal a paradox: naively rendering ARC-AGI grids as images degrades performance due to imprecise rule execution. This leads to our central hypothesis that vision and language possess complementary strengths across distinct reasoning stages: vision supports global pattern abstraction and verification, whereas language specializes in symbolic rule formulation and precise execution. Building on this insight, we introduce two synergistic strategies: (1) Vision-Language Synergy Reasoning (VLSR), which decomposes ARC-AGI into modality-aligned subtasks; and (2) Modality-Switch Self-Correction (MSSC), which leverages vision to verify text-based reasoning for intrinsic error correction. Extensive experiments demonstrate that our approach yields up to a 4.33% improvement over text-only baselines across diverse flagship models and multiple ARC-AGI tasks. Our findings suggest that unifying visual abstraction with linguistic reasoning is a crucial step toward achieving generalizable, human-like intelligence in future foundation models. Source code will be released soon.', 'abstract_zh': '抽象推理从最小例证出发仍然是如GPT-5和Grok 4这样的前沿基础模型的核心未解问题。这些模型仍无法从少量例证中推断出结构化的转换规则，这是人类智能的关键特征之一。人工通用智能的抽象与推理语料库（ARC-AGI）为这一能力提供了严格的测试平台，要求概念规则的归纳和向新任务的转移。现有的大多数方法将ARC-AGI视为纯粹的文字推理任务，忽视了人类在解决此类谜题时高度依赖视觉抽象的事实。然而，我们的试点实验揭示了一个悖论：直接将ARC-AGI网格渲染为图像会由于规则执行不准确而导致性能下降。这使我们认为视觉和语言在不同推理阶段具有互补的优势：视觉支持全局模式的抽象和验证，而语言则专长于符号规则的表述和精确执行。基于这一见解，我们引入了两种协同策略：（1）视觉-语言协同推理（VLSR），将ARC-AGI分解为模态对齐的子任务；（2）模态切换自我校正（MSSC），利用视觉验证基于文本的推理以进行内在错误校正。广泛的实验表明，我们的方法在多种旗舰模型和多个ARC-AGI任务上相较于仅基于文本的基础模型可获得高达4.33%的提升。我们的研究结果表明，将视觉抽象与语言推理统一起来是朝向实现泛化的、类人的智能的关键步骤。源代码即将发布。', 'title_zh': '可视化思考，文本推理：在ARC中的视觉-语言协同作用'}
{'arxiv_id': 'arXiv:2511.15704', 'title': 'In-N-On: Scaling Egocentric Manipulation with in-the-wild and on-task Data', 'authors': 'Xiongyi Cai, Ri-Zhao Qiu, Geng Chen, Lai Wei, Isabella Liu, Tianshu Huang, Xuxin Cheng, Xiaolong Wang', 'link': 'https://arxiv.org/abs/2511.15704', 'abstract': 'Egocentric videos are a valuable and scalable data source to learn manipulation policies. However, due to significant data heterogeneity, most existing approaches utilize human data for simple pre-training, which does not unlock its full potential. This paper first provides a scalable recipe for collecting and using egocentric data by categorizing human data into two categories: in-the-wild and on-task alongside with systematic analysis on how to use the data. We first curate a dataset, PHSD, which contains over 1,000 hours of diverse in-the-wild egocentric data and over 20 hours of on-task data directly aligned to the target manipulation tasks. This enables learning a large egocentric language-conditioned flow matching policy, Human0. With domain adaptation techniques, Human0 minimizes the gap between humans and humanoids. Empirically, we show Human0 achieves several novel properties from scaling human data, including language following of instructions from only human data, few-shot learning, and improved robustness using on-task data. Project website: this https URL', 'abstract_zh': '以自我为中心的视频是学习操作策略的一种宝贵且可扩展的数据源。然而，由于数据的高度异质性，大多数现有方法仅利用人类数据进行简单的预训练，未能充分发挥其潜力。本文首先提供了一个可扩展的方案，用于收集和利用以自我为中心的数据，通过将人类数据分类为两类：野外数据和任务中数据，并系统分析了如何使用这些数据。我们首先构建了一个数据集PHSD，包含超过1000小时的多样化的野外以自我为中心数据和超过20小时的任务中数据，直接与目标操作任务对齐。这使得能够学习一个大规模的以自我为中心的语言条件流动匹配策略Human0。通过领域适应技术，Human0最小化了人类与类人机器人之间的差距。实验上，我们展示了Human0通过放大人类数据获得了几个新颖的特性，包括仅通过人类数据进行指令跟随、少样本学习以及通过任务中数据提高鲁棒性。项目网站：这个https URL。', 'title_zh': 'In-N-On: 用野生数据和任务中数据扩展第一人称操控规模'}
{'arxiv_id': 'arXiv:2511.15703', 'title': 'Think Visually, Reason Textually: Vision-Language Synergy in ARC', 'authors': 'Beichen Zhang, Yuhang Zang, Xiaoyi Dong, Yuhang Cao, Haodong Duan, Dahua Lin, Jiaqi Wang', 'link': 'https://arxiv.org/abs/2511.15703', 'abstract': 'Abstract reasoning from minimal examples remains a core unsolved problem for frontier foundation models such as GPT-5 and Grok 4. These models still fail to infer structured transformation rules from a handful of examples, which is a key hallmark of human intelligence. The Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI) provides a rigorous testbed for this capability, demanding conceptual rule induction and transfer to novel tasks. Most existing methods treat ARC-AGI as a purely textual reasoning task, overlooking the fact that humans rely heavily on visual abstraction when solving such puzzles. However, our pilot experiments reveal a paradox: naively rendering ARC-AGI grids as images degrades performance due to imprecise rule execution. This leads to our central hypothesis that vision and language possess complementary strengths across distinct reasoning stages: vision supports global pattern abstraction and verification, whereas language specializes in symbolic rule formulation and precise execution. Building on this insight, we introduce two synergistic strategies: (1) Vision-Language Synergy Reasoning (VLSR), which decomposes ARC-AGI into modality-aligned subtasks; and (2) Modality-Switch Self-Correction (MSSC), which leverages vision to verify text-based reasoning for intrinsic error correction. Extensive experiments demonstrate that our approach yields up to a 4.33% improvement over text-only baselines across diverse flagship models and multiple ARC-AGI tasks. Our findings suggest that unifying visual abstraction with linguistic reasoning is a crucial step toward achieving generalizable, human-like intelligence in future foundation models. Source code will be released soon.', 'abstract_zh': '抽象推理从最小示例出发仍然是前沿基础模型如GPT-5和Grok 4的核心未解问题。这些模型仍然无法从少量示例中推断结构化转换规则，这是人类智能的关键特征之一。人工通用智能抽象推理 corpus (ARC-AGI) 为这一能力提供了严格的测试平台，要求概念规则归纳并在新任务中进行迁移。现有大多数方法将 ARC-AGI 视作纯粹的文本推理任务，忽视了人类在解决这类谜题时高度依赖视觉抽象的事实。然而，我们的初步实验揭示了一个悖论：简单地将 ARC-AGI 格网转换为图像会由于规则执行不够精确而降低性能。这促使我们提出一个中心假设：视觉和语言在整个推理阶段中具有互补的优势：视觉支持全局模式的抽象和验证，而语言专门负责符号规则的制定和精确执行。基于这一认识，我们引入了两种协同策略：（1）视觉-语言协同推理 (VLSR)，将 ARC-AGI 分解为模态对齐的子任务；（2）模态切换自校正 (MSSC)，利用视觉验证基于文本的推理以进行内在错误校正。大量实验表明，我们的方法在多个顶级模型和 ARC-AGI 任务上相比仅基于文本的基线方法可以取得高达 4.33% 的提升。我们的研究结果表明，将视觉抽象与语言推理统一是未来基础模型实现可迁移的人类级智能的关键一步。源代码将很快发布。', 'title_zh': '视觉思考，文本推理：ARC中的视觉语言协同作用'}
{'arxiv_id': 'arXiv:2511.15699', 'title': 'Joint Semantic-Channel Coding and Modulation for Token Communications', 'authors': 'Jingkai Ying, Zhijin Qin, Yulong Feng, Liejun Wang, Xiaoming Tao', 'link': 'https://arxiv.org/abs/2511.15699', 'abstract': 'In recent years, the Transformer architecture has achieved outstanding performance across a wide range of tasks and modalities. Token is the unified input and output representation in Transformer-based models, which has become a fundamental information unit. In this work, we consider the problem of token communication, studying how to transmit tokens efficiently and reliably. Point cloud, a prevailing three-dimensional format which exhibits a more complex spatial structure compared to image or video, is chosen to be the information source. We utilize the set abstraction method to obtain point tokens. Subsequently, to get a more informative and transmission-friendly representation based on tokens, we propose a joint semantic-channel and modulation (JSCCM) scheme for the token encoder, mapping point tokens to standard digital constellation points (modulated tokens). Specifically, the JSCCM consists of two parallel Point Transformer-based encoders and a differential modulator which combines the Gumel-softmax and soft quantization methods. Besides, the rate allocator and channel adapter are developed, facilitating adaptive generation of high-quality modulated tokens conditioned on both semantic information and channel conditions. Extensive simulations demonstrate that the proposed method outperforms both joint semantic-channel coding and traditional separate coding, achieving over 1dB gain in reconstruction and more than 6x compression ratio in modulated symbols.', 'abstract_zh': '近年来，Transformer架构在各类任务和模态中取得了卓越性能。Token是基于Transformer模型的统一输入和输出表示，已成为基本的信息单元。本文研究了token通信问题，探讨如何高效可靠地传输token。点云作为一种相较于图像或视频具有更复杂空间结构的主流三维格式，被选作信息源。我们利用集合抽象方法获取点token。为进一步基于token获得更具信息量且利于传输的表示，我们提出了一种联合语义-信道的调制（JSCCM）方案，将点token映射为标准数字基带点（调制token）。具体而言，JSCCM包括两个并行的点Transformer编码器和一种结合Gumel-softmax和软量化方法的差分调制器。此外，我们开发了速率分配器和信道适配器，以根据语义信息和信道条件自适应生成高质量的调制token。广泛仿真表明，所提出的方法优于联合语义-信道编码和传统分离编码，重建性能提高超过1dB，调制符号压缩比提高超过6倍。', 'title_zh': '联合语义-通道编码与调制技术在Token通信中应用'}
{'arxiv_id': 'arXiv:2511.15703', 'title': 'Think Visually, Reason Textually: Vision-Language Synergy in ARC', 'authors': 'Beichen Zhang, Yuhang Zang, Xiaoyi Dong, Yuhang Cao, Haodong Duan, Dahua Lin, Jiaqi Wang', 'link': 'https://arxiv.org/abs/2511.15703', 'abstract': 'Abstract reasoning from minimal examples remains a core unsolved problem for frontier foundation models such as GPT-5 and Grok 4. These models still fail to infer structured transformation rules from a handful of examples, which is a key hallmark of human intelligence. The Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI) provides a rigorous testbed for this capability, demanding conceptual rule induction and transfer to novel tasks. Most existing methods treat ARC-AGI as a purely textual reasoning task, overlooking the fact that humans rely heavily on visual abstraction when solving such puzzles. However, our pilot experiments reveal a paradox: naively rendering ARC-AGI grids as images degrades performance due to imprecise rule execution. This leads to our central hypothesis that vision and language possess complementary strengths across distinct reasoning stages: vision supports global pattern abstraction and verification, whereas language specializes in symbolic rule formulation and precise execution. Building on this insight, we introduce two synergistic strategies: (1) Vision-Language Synergy Reasoning (VLSR), which decomposes ARC-AGI into modality-aligned subtasks; and (2) Modality-Switch Self-Correction (MSSC), which leverages vision to verify text-based reasoning for intrinsic error correction. Extensive experiments demonstrate that our approach yields up to a 4.33% improvement over text-only baselines across diverse flagship models and multiple ARC-AGI tasks. Our findings suggest that unifying visual abstraction with linguistic reasoning is a crucial step toward achieving generalizable, human-like intelligence in future foundation models. Source code will be released soon.', 'abstract_zh': '抽象推理从最小样本出发仍然是前沿基础模型如GPT-5和Grok 4的核心未解问题。这些模型仍然无法从少量示例中推断出结构化的转换规则，这是人类智能的一个关键标志。人工通用智能抽象与推理语料库（ARC-AGI）为这种能力提供了一个严格的测试平台，要求概念规则归纳和向新颖任务的转移。现有大多数方法将ARC-AGI视为纯粹的文字推理任务，忽视了人类在解决这类谜题时高度依赖视觉抽象的事实。然而，我们的初步实验揭示了一个悖论：将ARC-AGI网格直接渲染为图像会导致性能下降，因为规则执行不够精确。这让我们形成一个中心假设，即视觉和语言在不同的推理阶段具有互补的优势：视觉支持全局模式的抽象和验证，而语言则专门负责符号规则的制定和精确执行。基于这一见解，我们引入了两种协同策略：（1）视觉-语言协同推理（VLSR），将ARC-AGI分解为模态对齐的子任务；（2）模式切换自校正（MSSC），利用视觉验证基于文本的推理以进行内在错误校正。广泛实验表明，我们的方法在多种旗舰模型和ARC-AGI任务中相较于纯文本基准提高了多达4.33%的表现。我们的研究结果表明，将视觉抽象与语言推理统一起来是未来基础模型实现可泛化的、类人的智能的关键步骤之一。源代码即将发布。', 'title_zh': '可视化思考，文本推理：ARC中的视觉-语言协同作用'}
{'arxiv_id': 'arXiv:2511.15699', 'title': 'Joint Semantic-Channel Coding and Modulation for Token Communications', 'authors': 'Jingkai Ying, Zhijin Qin, Yulong Feng, Liejun Wang, Xiaoming Tao', 'link': 'https://arxiv.org/abs/2511.15699', 'abstract': 'In recent years, the Transformer architecture has achieved outstanding performance across a wide range of tasks and modalities. Token is the unified input and output representation in Transformer-based models, which has become a fundamental information unit. In this work, we consider the problem of token communication, studying how to transmit tokens efficiently and reliably. Point cloud, a prevailing three-dimensional format which exhibits a more complex spatial structure compared to image or video, is chosen to be the information source. We utilize the set abstraction method to obtain point tokens. Subsequently, to get a more informative and transmission-friendly representation based on tokens, we propose a joint semantic-channel and modulation (JSCCM) scheme for the token encoder, mapping point tokens to standard digital constellation points (modulated tokens). Specifically, the JSCCM consists of two parallel Point Transformer-based encoders and a differential modulator which combines the Gumel-softmax and soft quantization methods. Besides, the rate allocator and channel adapter are developed, facilitating adaptive generation of high-quality modulated tokens conditioned on both semantic information and channel conditions. Extensive simulations demonstrate that the proposed method outperforms both joint semantic-channel coding and traditional separate coding, achieving over 1dB gain in reconstruction and more than 6x compression ratio in modulated symbols.', 'abstract_zh': '近年来，Transformer架构在各种任务和模态中取得了出色性能。Transformer模型中的标记是由统一的输入和输出表示，已成为基本的信息单元。在本工作中，我们考虑标记通信的问题，研究如何高效可靠地传输标记。点云作为一种流行的三维格式，相较于图像或视频具有更复杂的空间结构，被选作信息源。我们利用集合抽象方法获取点标记。随后，为了基于标记获取更具信息量且易于传输的表示，我们提出了一种联合语义-信道和调制（JSCCM）方案，将点标记映射到标准数字星座点（调制标记）。具体而言，JSCCM包括两个并行的Point Transformer基编码器和一个结合Gumel-softmax和软量化方法的差分调制器。此外，我们还开发了速率分配器和信道适配器，以辅助生成同时基于语义信息和信道条件的高质量调制标记。广泛的仿真实验表明，所提出的方法在重建上优于联合语义-信道编码，并且在调制符号压缩比上相比传统单独编码提高了超过6倍，获得了超过1dB的增益。', 'title_zh': '联合语义-通道编码与调制技术用于标记通信'}
{'arxiv_id': 'arXiv:2511.15684', 'title': 'Walrus: A Cross-Domain Foundation Model for Continuum Dynamics', 'authors': 'Michael McCabe, Payel Mukhopadhyay, Tanya Marwah, Bruno Regaldo-Saint Blancard, Francois Rozet, Cristiana Diaconu, Lucas Meyer, Kaze W. K. Wong, Hadi Sotoudeh, Alberto Bietti, Irina Espejo, Rio Fear, Siavash Golkar, Tom Hehir, Keiya Hirashima, Geraud Krawezik, Francois Lanusse, Rudy Morel, Ruben Ohana, Liam Parker, Mariel Pettee, Jeff Shen, Kyunghyun Cho, Miles Cranmer, Shirley Ho', 'link': 'https://arxiv.org/abs/2511.15684', 'abstract': 'Foundation models have transformed machine learning for language and vision, but achieving comparable impact in physical simulation remains a challenge. Data heterogeneity and unstable long-term dynamics inhibit learning from sufficiently diverse dynamics, while varying resolutions and dimensionalities challenge efficient training on modern hardware. Through empirical and theoretical analysis, we incorporate new approaches to mitigate these obstacles, including a harmonic-analysis-based stabilization method, load-balanced distributed 2D and 3D training strategies, and compute-adaptive tokenization. Using these tools, we develop Walrus, a transformer-based foundation model developed primarily for fluid-like continuum dynamics. Walrus is pretrained on nineteen diverse scenarios spanning astrophysics, geoscience, rheology, plasma physics, acoustics, and classical fluids. Experiments show that Walrus outperforms prior foundation models on both short and long term prediction horizons on downstream tasks and across the breadth of pretraining data, while ablation studies confirm the value of our contributions to forecast stability, training throughput, and transfer performance over conventional approaches. Code and weights are released for community use.', 'abstract_zh': '基础模型已变革了语言和视觉的机器学习，但在物理模拟中实现同等影响依然面临挑战。数据异质性和不稳定长时间动态阻碍了从足够多样的动态中学习，而变化的分辨率和维度挑战了现代硬件上的高效训练。通过实证和理论分析，我们引入了新的方法来解决这些障碍，包括基于谐波分析的稳定方法、负载均衡分布式2D和3D训练策略，以及计算自适应的标记化方法。利用这些工具，我们开发了Walrus，一种主要用于流体-like连续动力学的变换器基础模型。Walrus在包含天体物理学、地球科学、流变学、等离子体物理学、声学和经典流体在内的十九种不同场景中进行预训练。实验结果表明，与先前的基础模型相比，Walrus在下游任务和预训练数据的整个范围内，在短期和长期预测方面表现出色，消融研究证实了我们对预测稳定性、训练吞吐量和迁移性能的贡献优于传统方法。代码和权重向社区开放。', 'title_zh': 'Walrus: 一种 continua 动力学的跨域基础模型'}
{'arxiv_id': 'arXiv:2511.15699', 'title': 'Joint Semantic-Channel Coding and Modulation for Token Communications', 'authors': 'Jingkai Ying, Zhijin Qin, Yulong Feng, Liejun Wang, Xiaoming Tao', 'link': 'https://arxiv.org/abs/2511.15699', 'abstract': 'In recent years, the Transformer architecture has achieved outstanding performance across a wide range of tasks and modalities. Token is the unified input and output representation in Transformer-based models, which has become a fundamental information unit. In this work, we consider the problem of token communication, studying how to transmit tokens efficiently and reliably. Point cloud, a prevailing three-dimensional format which exhibits a more complex spatial structure compared to image or video, is chosen to be the information source. We utilize the set abstraction method to obtain point tokens. Subsequently, to get a more informative and transmission-friendly representation based on tokens, we propose a joint semantic-channel and modulation (JSCCM) scheme for the token encoder, mapping point tokens to standard digital constellation points (modulated tokens). Specifically, the JSCCM consists of two parallel Point Transformer-based encoders and a differential modulator which combines the Gumel-softmax and soft quantization methods. Besides, the rate allocator and channel adapter are developed, facilitating adaptive generation of high-quality modulated tokens conditioned on both semantic information and channel conditions. Extensive simulations demonstrate that the proposed method outperforms both joint semantic-channel coding and traditional separate coding, achieving over 1dB gain in reconstruction and more than 6x compression ratio in modulated symbols.', 'abstract_zh': '近年来，Transformer架构在各种任务和模态中取得了出色的表现。Token是基于Transformer模型的统一输入和输出表示，已经成为基本的信息单元。在本文中，我们考虑了Token通信的问题，研究如何高效可靠地传输Token。点云作为一种相比于图像或视频表现出更复杂空间结构的主流三维格式，被选为信息源。我们利用集合抽象方法获得点Token。随后，为了基于Token获得更具信息量且便于传输的表示，我们提出了一种联合语义信道和调制（JSCCM）方案，将点Token映射为标准数字星座点（调制Token）。具体来说，JSCCM由两个并行的基于点Transformer的编码器和一个结合Gumel-softmax和软量化方法的差分调制器组成。此外，我们开发了速率分配器和信道适配器，以根据语义信息和信道条件自适应地生成高质量的调制Token。广泛仿真实验表明，所提出的方法在重建方面优于联合语义信道编码和传统分离编码，获得了超过1dB的增益，并且在调制符号方面的压缩比超过6倍。', 'title_zh': '联合语义-通道编码与调制技术在Token通信中的应用'}
{'arxiv_id': 'arXiv:2511.15684', 'title': 'Walrus: A Cross-Domain Foundation Model for Continuum Dynamics', 'authors': 'Michael McCabe, Payel Mukhopadhyay, Tanya Marwah, Bruno Regaldo-Saint Blancard, Francois Rozet, Cristiana Diaconu, Lucas Meyer, Kaze W. K. Wong, Hadi Sotoudeh, Alberto Bietti, Irina Espejo, Rio Fear, Siavash Golkar, Tom Hehir, Keiya Hirashima, Geraud Krawezik, Francois Lanusse, Rudy Morel, Ruben Ohana, Liam Parker, Mariel Pettee, Jeff Shen, Kyunghyun Cho, Miles Cranmer, Shirley Ho', 'link': 'https://arxiv.org/abs/2511.15684', 'abstract': 'Foundation models have transformed machine learning for language and vision, but achieving comparable impact in physical simulation remains a challenge. Data heterogeneity and unstable long-term dynamics inhibit learning from sufficiently diverse dynamics, while varying resolutions and dimensionalities challenge efficient training on modern hardware. Through empirical and theoretical analysis, we incorporate new approaches to mitigate these obstacles, including a harmonic-analysis-based stabilization method, load-balanced distributed 2D and 3D training strategies, and compute-adaptive tokenization. Using these tools, we develop Walrus, a transformer-based foundation model developed primarily for fluid-like continuum dynamics. Walrus is pretrained on nineteen diverse scenarios spanning astrophysics, geoscience, rheology, plasma physics, acoustics, and classical fluids. Experiments show that Walrus outperforms prior foundation models on both short and long term prediction horizons on downstream tasks and across the breadth of pretraining data, while ablation studies confirm the value of our contributions to forecast stability, training throughput, and transfer performance over conventional approaches. Code and weights are released for community use.', 'abstract_zh': '基础模型已 transformative 语言和视觉领域的机器学习，但在物理模拟中实现同等影响仍面临挑战。数据异质性和不稳定的长期动态阻碍了从足够多样化的动态中学习，而不同的分辨率和维度则对现代硬件上的高效训练构成了挑战。通过实证和理论分析，我们引入了新的方法来缓解这些障碍，包括基于谐波分析的稳定方法、负载均衡的分布式二维和三维训练策略，以及计算自适应的标记化方法。借助这些工具，我们开发了Walrus，这是一种主要用于流体-like 连续体动力学的基础模型。Walrus在天体物理学、地球科学、流变学、等离子体物理学、声学和经典流体等19种不同场景下进行预训练。实验表明，Walrus在下游任务和预训练数据的短期和长期预测方面均优于先前的基础模型，消除实验进一步证实了我们在预测稳定性、训练吞吐量和转移性能方面的贡献优于传统方法。已发布代码和权重供社区使用。', 'title_zh': 'walrus: 跨域连续动力学基础模型'}
{'arxiv_id': 'arXiv:2511.15675', 'title': 'MF-GCN: A Multi-Frequency Graph Convolutional Network for Tri-Modal Depression Detection Using Eye-Tracking, Facial, and Acoustic Features', 'authors': 'Sejuti Rahman, Swakshar Deb, MD. Sameer Iqbal Chowdhury, MD. Jubair Ahmed Sourov, Mohammad Shamsuddin', 'link': 'https://arxiv.org/abs/2511.15675', 'abstract': 'Eye tracking data quantifies the attentional bias towards negative stimuli that is frequently observed in depressed groups. Audio and video data capture the affective flattening and psychomotor retardation characteristic of depression. Statistical validation confirmed their significant discriminative power in distinguishing depressed from non depressed groups. We address a critical limitation of existing graph-based models that focus on low-frequency information and propose a Multi-Frequency Graph Convolutional Network (MF-GCN). This framework consists of a novel Multi-Frequency Filter Bank Module (MFFBM), which can leverage both low and high frequency signals. Extensive evaluation against traditional machine learning algorithms and deep learning frameworks demonstrates that MF-GCN consistently outperforms baselines. In binary (depressed and non depressed) classification, the model achieved a sensitivity of 0.96 and F2 score of 0.94. For the 3 class (no depression, mild to moderate depression and severe depression) classification task, the proposed method achieved a sensitivity of 0.79 and specificity of 0.87 and siginificantly suprassed other models. To validate generalizability, the model was also evaluated on the Chinese Multimodal Depression Corpus (CMDC) dataset and achieved a sensitivity of 0.95 and F2 score of 0.96. These results confirm that our trimodal, multi frequency framework effectively captures cross modal interaction for accurate depression detection.', 'abstract_zh': '基于多频谱图卷积网络的情感抑郁症检测方法：多模态跨频谱交互的有效捕捉', 'title_zh': '多频图卷积网络：基于眼动、面部和声学特征的三模态抑郁检测'}
{'arxiv_id': 'arXiv:2511.15684', 'title': 'Walrus: A Cross-Domain Foundation Model for Continuum Dynamics', 'authors': 'Michael McCabe, Payel Mukhopadhyay, Tanya Marwah, Bruno Regaldo-Saint Blancard, Francois Rozet, Cristiana Diaconu, Lucas Meyer, Kaze W. K. Wong, Hadi Sotoudeh, Alberto Bietti, Irina Espejo, Rio Fear, Siavash Golkar, Tom Hehir, Keiya Hirashima, Geraud Krawezik, Francois Lanusse, Rudy Morel, Ruben Ohana, Liam Parker, Mariel Pettee, Jeff Shen, Kyunghyun Cho, Miles Cranmer, Shirley Ho', 'link': 'https://arxiv.org/abs/2511.15684', 'abstract': 'Foundation models have transformed machine learning for language and vision, but achieving comparable impact in physical simulation remains a challenge. Data heterogeneity and unstable long-term dynamics inhibit learning from sufficiently diverse dynamics, while varying resolutions and dimensionalities challenge efficient training on modern hardware. Through empirical and theoretical analysis, we incorporate new approaches to mitigate these obstacles, including a harmonic-analysis-based stabilization method, load-balanced distributed 2D and 3D training strategies, and compute-adaptive tokenization. Using these tools, we develop Walrus, a transformer-based foundation model developed primarily for fluid-like continuum dynamics. Walrus is pretrained on nineteen diverse scenarios spanning astrophysics, geoscience, rheology, plasma physics, acoustics, and classical fluids. Experiments show that Walrus outperforms prior foundation models on both short and long term prediction horizons on downstream tasks and across the breadth of pretraining data, while ablation studies confirm the value of our contributions to forecast stability, training throughput, and transfer performance over conventional approaches. Code and weights are released for community use.', 'abstract_zh': '基础模型已转型语言和视觉领域的机器学习，但在物理模拟中的应用仍面临挑战。数据异质性和不稳定的长期动力学阻碍了对足够多样动力学的学习，而不同的分辨率和维度性给现代硬件上的高效训练带来了挑战。通过实证和理论分析，我们引入了新的方法来缓解这些障碍，包括基于谐波分析的稳定化方法、负载均衡的分布式2D和3D训练策略以及计算自适应的分词方法。利用这些工具，我们开发了Walrus，一种主要用于流体-like连续动力学的变压器基础模型。Walrus在天体物理学、地球科学、流变学、等离子体物理、声学和经典流体等十九个不同场景下进行预训练。实验表明，Walrus在短时间和长时间预测窗口以及预训练数据跨度上均优于先前的基础模型，且消融研究表明我们的贡献对预测稳定性、训练吞吐量和迁移性能具有重要价值。社区可以获取代码和权重。', 'title_zh': 'Walrus: 一种用于连续动力学的跨域基础模型'}
{'arxiv_id': 'arXiv:2511.15675', 'title': 'MF-GCN: A Multi-Frequency Graph Convolutional Network for Tri-Modal Depression Detection Using Eye-Tracking, Facial, and Acoustic Features', 'authors': 'Sejuti Rahman, Swakshar Deb, MD. Sameer Iqbal Chowdhury, MD. Jubair Ahmed Sourov, Mohammad Shamsuddin', 'link': 'https://arxiv.org/abs/2511.15675', 'abstract': 'Eye tracking data quantifies the attentional bias towards negative stimuli that is frequently observed in depressed groups. Audio and video data capture the affective flattening and psychomotor retardation characteristic of depression. Statistical validation confirmed their significant discriminative power in distinguishing depressed from non depressed groups. We address a critical limitation of existing graph-based models that focus on low-frequency information and propose a Multi-Frequency Graph Convolutional Network (MF-GCN). This framework consists of a novel Multi-Frequency Filter Bank Module (MFFBM), which can leverage both low and high frequency signals. Extensive evaluation against traditional machine learning algorithms and deep learning frameworks demonstrates that MF-GCN consistently outperforms baselines. In binary (depressed and non depressed) classification, the model achieved a sensitivity of 0.96 and F2 score of 0.94. For the 3 class (no depression, mild to moderate depression and severe depression) classification task, the proposed method achieved a sensitivity of 0.79 and specificity of 0.87 and siginificantly suprassed other models. To validate generalizability, the model was also evaluated on the Chinese Multimodal Depression Corpus (CMDC) dataset and achieved a sensitivity of 0.95 and F2 score of 0.96. These results confirm that our trimodal, multi frequency framework effectively captures cross modal interaction for accurate depression detection.', 'abstract_zh': '基于多频图卷积网络的情感障碍检测方法', 'title_zh': '多频图卷积网络：基于眼动、面部和声学特征的三角模态抑郁检测'}
{'arxiv_id': 'arXiv:2511.15669', 'title': 'DeepThinkVLA: Enhancing Reasoning Capability of Vision-Language-Action Models', 'authors': 'Cheng Yin, Yankai Lin, Wang Xu, Sikyuen Tam, Xiangrui Zeng, Zhiyuan Liu, Zhouping Yin', 'link': 'https://arxiv.org/abs/2511.15669', 'abstract': 'Enabling Vision-Language-Action (VLA) models to "think before acting" via Chain-of-Thought (CoT) is a promising path to overcoming the data-hungry nature of end-to-end robot policies. However, progress is stalled by a fundamental conflict: existing models use a single autoregressive decoder for both sequential CoT reasoning and high-dimensional, parallelizable robot actions. This architectural mismatch degrades motor control and fails to forge a strong causal link between thought and action. We introduce DeepThinkVLA, which resolves this conflict through a tightly integrated architecture and training strategy. Architecturally, our hybrid-attention decoder generates sequential CoT with causal attention and then switches to bidirectional attention for fast, parallel decoding of action vectors. This design is complemented by a two-stage training pipeline: we first use Supervised Fine-Tuning (SFT) to teach the model foundational reasoning, then apply Reinforcement Learning (RL) with task-success rewards to causally align the full reasoning-action sequence with desired outcomes. This synergy leads to state-of-the-art performance, achieving a 97.0% success rate on the LIBERO benchmark. Our ablations confirm the design\'s effectiveness: the hybrid architecture alone outperforms standard decoders by 15.5%, and the final RL stage provides a crucial 2% boost to secure top performance.', 'abstract_zh': '通过Chain-of-Thought（CoT）使Vision-Language-Action（VLA）模型在“思考后再行动”：解决端到端机器人策略的数据饥渴性质的有前途途径，但由于现有模型在顺序CoT推理和高维度并行化机器人动作的单一自回归解码器之间存在根本冲突而进展停滞。我们提出了DeepThinkVLA，通过紧密集成的架构和训练策略解决了这一冲突。我们的混合注意力解码器通过因果注意力生成顺序CoT，然后切换到双向注意力进行快速并行解码动作向量。这一设计通过两个阶段的训练管道得到了补充：首先使用监督微调（SFT）使模型掌握基础推理能力，然后使用带有任务成功奖励的强化学习（RL）来因果地将整个推理-动作序列与期望结果对齐。这种协同作用达到了迄今为止的最先进性能，在LIBERO基准测试中实现了97.0%的成功率。我们的消融实验验证了设计的有效性：混合架构本身比标准解码器高出15.5%，最终的RL阶段提供了关键的2%增益以确保最佳性能。', 'title_zh': 'DeepThinkVLA: 提升视觉-语言-行动模型的推理能力'}
{'arxiv_id': 'arXiv:2511.15675', 'title': 'MF-GCN: A Multi-Frequency Graph Convolutional Network for Tri-Modal Depression Detection Using Eye-Tracking, Facial, and Acoustic Features', 'authors': 'Sejuti Rahman, Swakshar Deb, MD. Sameer Iqbal Chowdhury, MD. Jubair Ahmed Sourov, Mohammad Shamsuddin', 'link': 'https://arxiv.org/abs/2511.15675', 'abstract': 'Eye tracking data quantifies the attentional bias towards negative stimuli that is frequently observed in depressed groups. Audio and video data capture the affective flattening and psychomotor retardation characteristic of depression. Statistical validation confirmed their significant discriminative power in distinguishing depressed from non depressed groups. We address a critical limitation of existing graph-based models that focus on low-frequency information and propose a Multi-Frequency Graph Convolutional Network (MF-GCN). This framework consists of a novel Multi-Frequency Filter Bank Module (MFFBM), which can leverage both low and high frequency signals. Extensive evaluation against traditional machine learning algorithms and deep learning frameworks demonstrates that MF-GCN consistently outperforms baselines. In binary (depressed and non depressed) classification, the model achieved a sensitivity of 0.96 and F2 score of 0.94. For the 3 class (no depression, mild to moderate depression and severe depression) classification task, the proposed method achieved a sensitivity of 0.79 and specificity of 0.87 and siginificantly suprassed other models. To validate generalizability, the model was also evaluated on the Chinese Multimodal Depression Corpus (CMDC) dataset and achieved a sensitivity of 0.95 and F2 score of 0.96. These results confirm that our trimodal, multi frequency framework effectively captures cross modal interaction for accurate depression detection.', 'abstract_zh': '基于多频图卷积网络的抑郁检测多模态多频谱框架', 'title_zh': '多频图卷积网络：基于眼动、面部和声学特征的三模抑郁检测'}
{'arxiv_id': 'arXiv:2511.15669', 'title': 'DeepThinkVLA: Enhancing Reasoning Capability of Vision-Language-Action Models', 'authors': 'Cheng Yin, Yankai Lin, Wang Xu, Sikyuen Tam, Xiangrui Zeng, Zhiyuan Liu, Zhouping Yin', 'link': 'https://arxiv.org/abs/2511.15669', 'abstract': 'Enabling Vision-Language-Action (VLA) models to "think before acting" via Chain-of-Thought (CoT) is a promising path to overcoming the data-hungry nature of end-to-end robot policies. However, progress is stalled by a fundamental conflict: existing models use a single autoregressive decoder for both sequential CoT reasoning and high-dimensional, parallelizable robot actions. This architectural mismatch degrades motor control and fails to forge a strong causal link between thought and action. We introduce DeepThinkVLA, which resolves this conflict through a tightly integrated architecture and training strategy. Architecturally, our hybrid-attention decoder generates sequential CoT with causal attention and then switches to bidirectional attention for fast, parallel decoding of action vectors. This design is complemented by a two-stage training pipeline: we first use Supervised Fine-Tuning (SFT) to teach the model foundational reasoning, then apply Reinforcement Learning (RL) with task-success rewards to causally align the full reasoning-action sequence with desired outcomes. This synergy leads to state-of-the-art performance, achieving a 97.0% success rate on the LIBERO benchmark. Our ablations confirm the design\'s effectiveness: the hybrid architecture alone outperforms standard decoders by 15.5%, and the final RL stage provides a crucial 2% boost to secure top performance.', 'abstract_zh': '通过链式思考（CoT）使视觉-语言-行动（VLA）模型“先思后行”以克服端到端机器人策略的数据饥渴性质：一种有前景的方法及其在DeepThinkVLA中的实现', 'title_zh': 'DeepThinkVLA: 提升视觉-语言-行动模型的推理能力'}
{'arxiv_id': 'arXiv:2511.15661', 'title': 'VisPlay: Self-Evolving Vision-Language Models from Images', 'authors': 'Yicheng He, Chengsong Huang, Zongxia Li, Jiaxin Huang, Yonghui Yang', 'link': 'https://arxiv.org/abs/2511.15661', 'abstract': 'Reinforcement learning (RL) provides a principled framework for improving Vision-Language Models (VLMs) on complex reasoning tasks. However, existing RL approaches often rely on human-annotated labels or task-specific heuristics to define verifiable rewards, both of which are costly and difficult to scale. We introduce VisPlay, a self-evolving RL framework that enables VLMs to autonomously improve their reasoning abilities using large amounts of unlabeled image data. Starting from a single base VLM, VisPlay assigns the model into two interacting roles: an Image-Conditioned Questioner that formulates challenging yet answerable visual questions, and a Multimodal Reasoner that generates silver responses. These roles are jointly trained with Group Relative Policy Optimization (GRPO), which incorporates diversity and difficulty rewards to balance the complexity of generated questions with the quality of the silver answers. VisPlay scales efficiently across two model families. When trained on Qwen2.5-VL and MiMo-VL, VisPlay achieves consistent improvements in visual reasoning, compositional generalization, and hallucination reduction across eight benchmarks, including MM-Vet and MMMU, demonstrating a scalable path toward self-evolving multimodal intelligence. The project page is available at this https URL', 'abstract_zh': '强化学习（RL）提供了一种原理性的框架，用于在复杂推理任务中提升视觉-语言模型（VLMs）。然而，现有的RL方法通常依赖于人工标注的标签或特定任务的经验规则来定义可验证的奖励，这两种方法都成本高昂且难以扩展。我们引入了VisPlay，这是一种自我进化的RL框架，能够让VLMs自主利用大量未标注的图像数据提高其推理能力。从一个基底VLM开始，VisPlay将模型分配为两个交互的角色：一个基于图像的问题提出者，负责提出具有挑战性但可回答的视觉问题；一个跨模态推理器，生成银级回答。这些角色通过组相对策略优化（GRPO）共同训练，该方法结合多样性和难度奖励，平衡生成问题的复杂性和银级回答的质量。VisPlay在两种模型家族中都实现了高效的扩展。在Qwen2.5-VL和MiMo-VL上训练后，VisPlay在包括MM-Vet和MMMU在内的八个基准测试中，促进了视觉推理、组合泛化和幻觉减少的一致改进，展示了自我进化的跨模态智能的可扩展路径。项目页面可访问此链接：[这里](this https URL)。', 'title_zh': 'VisPlay：自我演化的视觉-语言模型'}
{'arxiv_id': 'arXiv:2511.15669', 'title': 'DeepThinkVLA: Enhancing Reasoning Capability of Vision-Language-Action Models', 'authors': 'Cheng Yin, Yankai Lin, Wang Xu, Sikyuen Tam, Xiangrui Zeng, Zhiyuan Liu, Zhouping Yin', 'link': 'https://arxiv.org/abs/2511.15669', 'abstract': 'Enabling Vision-Language-Action (VLA) models to "think before acting" via Chain-of-Thought (CoT) is a promising path to overcoming the data-hungry nature of end-to-end robot policies. However, progress is stalled by a fundamental conflict: existing models use a single autoregressive decoder for both sequential CoT reasoning and high-dimensional, parallelizable robot actions. This architectural mismatch degrades motor control and fails to forge a strong causal link between thought and action. We introduce DeepThinkVLA, which resolves this conflict through a tightly integrated architecture and training strategy. Architecturally, our hybrid-attention decoder generates sequential CoT with causal attention and then switches to bidirectional attention for fast, parallel decoding of action vectors. This design is complemented by a two-stage training pipeline: we first use Supervised Fine-Tuning (SFT) to teach the model foundational reasoning, then apply Reinforcement Learning (RL) with task-success rewards to causally align the full reasoning-action sequence with desired outcomes. This synergy leads to state-of-the-art performance, achieving a 97.0% success rate on the LIBERO benchmark. Our ablations confirm the design\'s effectiveness: the hybrid architecture alone outperforms standard decoders by 15.5%, and the final RL stage provides a crucial 2% boost to secure top performance.', 'abstract_zh': '通过链式思考（Chain-of-Thought）使视觉-语言-动作（VLA）模型在“思考后再行动”：一种克服端到端机器人策略数据饥饿性质的有希望的方法，但进展受制于根本冲突的解决之路', 'title_zh': 'DeepThinkVLA: 提升视觉-语言-行动模型的推理能力'}
{'arxiv_id': 'arXiv:2511.15661', 'title': 'VisPlay: Self-Evolving Vision-Language Models from Images', 'authors': 'Yicheng He, Chengsong Huang, Zongxia Li, Jiaxin Huang, Yonghui Yang', 'link': 'https://arxiv.org/abs/2511.15661', 'abstract': 'Reinforcement learning (RL) provides a principled framework for improving Vision-Language Models (VLMs) on complex reasoning tasks. However, existing RL approaches often rely on human-annotated labels or task-specific heuristics to define verifiable rewards, both of which are costly and difficult to scale. We introduce VisPlay, a self-evolving RL framework that enables VLMs to autonomously improve their reasoning abilities using large amounts of unlabeled image data. Starting from a single base VLM, VisPlay assigns the model into two interacting roles: an Image-Conditioned Questioner that formulates challenging yet answerable visual questions, and a Multimodal Reasoner that generates silver responses. These roles are jointly trained with Group Relative Policy Optimization (GRPO), which incorporates diversity and difficulty rewards to balance the complexity of generated questions with the quality of the silver answers. VisPlay scales efficiently across two model families. When trained on Qwen2.5-VL and MiMo-VL, VisPlay achieves consistent improvements in visual reasoning, compositional generalization, and hallucination reduction across eight benchmarks, including MM-Vet and MMMU, demonstrating a scalable path toward self-evolving multimodal intelligence. The project page is available at this https URL', 'abstract_zh': '强化学习（RL）为提高视觉语言模型（VLMs）在复杂推理任务中的性能提供了原则性的框架。然而，现有的RL方法往往依赖于人工标注的标签或特定任务的启发式方法来定义可验证的奖励，这两种方法都成本高昂且难以扩展。我们介绍了VisPlay，这是一种自我进化的RL框架，使VLMs能够利用大量未标注的图像数据自主提高其推理能力。从一个基模型开始，VisPlay将模型分配为两个相互作用的角色：一个基于图像的问题提出者，负责提出具有挑战性但可回答的视觉问题；以及一个跨模态推理器，负责生成银质回答。这些角色通过结合多样性和难度奖励的组相对策略优化（GRPO）进行联合训练，以平衡生成问题的复杂性和银质回答的质量。VisPlay在两种模型家族中都能高效扩展。在Qwen2.5-VL和MiMo-VL上进行训练后，VisPlay在包括MM-Vet和MMMU在内的八个基准测试中实现了视觉推理、组合泛化和幻觉降低的持续改进，展示了通向自我进化的跨模态智能的可扩展路径。项目页面可访问此链接。', 'title_zh': 'VisPlay: 自我进化 vision-Language 模型从图像演变而来'}
{'arxiv_id': 'arXiv:2511.15658', 'title': 'GEO-Bench-2: From Performance to Capability, Rethinking Evaluation in Geospatial AI', 'authors': 'Naomi Simumba, Nils Lehmann, Paolo Fraccaro, Hamed Alemohammad, Geeth De Mel, Salman Khan, Manil Maskey, Nicolas Longepe, Xiao Xiang Zhu, Hannah Kerner, Juan Bernabe-Moreno, Alexander Lacoste', 'link': 'https://arxiv.org/abs/2511.15658', 'abstract': "Geospatial Foundation Models (GeoFMs) are transforming Earth Observation (EO), but evaluation lacks standardized protocols. GEO-Bench-2 addresses this with a comprehensive framework spanning classification, segmentation, regression, object detection, and instance segmentation across 19 permissively-licensed datasets. We introduce ''capability'' groups to rank models on datasets that share common characteristics (e.g., resolution, bands, temporality). This enables users to identify which models excel in each capability and determine which areas need improvement in future work. To support both fair comparison and methodological innovation, we define a prescriptive yet flexible evaluation protocol. This not only ensures consistency in benchmarking but also facilitates research into model adaptation strategies, a key and open challenge in advancing GeoFMs for downstream tasks.\nOur experiments show that no single model dominates across all tasks, confirming the specificity of the choices made during architecture design and pretraining. While models pretrained on natural images (ConvNext ImageNet, DINO V3) excel on high-resolution tasks, EO-specific models (TerraMind, Prithvi, and Clay) outperform them on multispectral applications such as agriculture and disaster response. These findings demonstrate that optimal model choice depends on task requirements, data modalities, and constraints. This shows that the goal of a single GeoFM model that performs well across all tasks remains open for future research. GEO-Bench-2 enables informed, reproducible GeoFM evaluation tailored to specific use cases. Code, data, and leaderboard for GEO-Bench-2 are publicly released under a permissive license.", 'abstract_zh': 'GeoFMs的空间基础模型正在变革地球观测（EO），但评估缺乏标准化的协议。GEO-Bench-2通过涵盖分类、分割、回归、对象检测和实例分割的全面框架，解决了这一问题，该框架覆盖了19个许可使用的数据集。我们引入“能力”组，根据数据集共享的共同特征（如分辨率、波段、时序性）对模型进行排名。这使得用户能够识别出哪些模型在每个能力上表现最佳，并确定未来工作中需要改进的领域。为了支持公平比较和方法创新，我们定义了一种处方但灵活的评估协议。这不仅确保了基准测试的一致性，还促进了针对下游任务改进GeoFMs的模型适应策略的研究，这是一项关键且开放的挑战。我们的实验表明，没有单一模型能够在所有任务中占据主导地位，这证实了在架构设计和预训练过程中所做的选择具有特定性。虽然在自然图像上预训练的模型（ConvNext ImageNet，DINO V3）在高分辨率任务中表现出色，但专门针对EO的应用模型（TerraMind，Prithvi，和Clay）在农业和灾害响应等多光谱应用中表现更优。这些发现表明，最优模型的选择取决于任务要求、数据模态和约束条件。这表明，一个适用于所有任务的GeoFM模型的表现仍然需要未来研究来验证。GEO-Bench-2使针对具体应用场景进行知情和可重复的GeoFM评估成为可能。GEO-Bench-2的代码、数据和排行榜在宽松的许可下公开发布。', 'title_zh': 'GEO-Bench-2: 从性能到能力，重新思考地理空间AI的评估'}
{'arxiv_id': 'arXiv:2511.15661', 'title': 'VisPlay: Self-Evolving Vision-Language Models from Images', 'authors': 'Yicheng He, Chengsong Huang, Zongxia Li, Jiaxin Huang, Yonghui Yang', 'link': 'https://arxiv.org/abs/2511.15661', 'abstract': 'Reinforcement learning (RL) provides a principled framework for improving Vision-Language Models (VLMs) on complex reasoning tasks. However, existing RL approaches often rely on human-annotated labels or task-specific heuristics to define verifiable rewards, both of which are costly and difficult to scale. We introduce VisPlay, a self-evolving RL framework that enables VLMs to autonomously improve their reasoning abilities using large amounts of unlabeled image data. Starting from a single base VLM, VisPlay assigns the model into two interacting roles: an Image-Conditioned Questioner that formulates challenging yet answerable visual questions, and a Multimodal Reasoner that generates silver responses. These roles are jointly trained with Group Relative Policy Optimization (GRPO), which incorporates diversity and difficulty rewards to balance the complexity of generated questions with the quality of the silver answers. VisPlay scales efficiently across two model families. When trained on Qwen2.5-VL and MiMo-VL, VisPlay achieves consistent improvements in visual reasoning, compositional generalization, and hallucination reduction across eight benchmarks, including MM-Vet and MMMU, demonstrating a scalable path toward self-evolving multimodal intelligence. The project page is available at this https URL', 'abstract_zh': '强化学习（RL）为通过复杂推理任务提高视觉语言模型（VLMs）提供了原则性的框架。然而，现有的RL方法通常依赖于人工标注的标签或特定任务的启发式方法来定义可验证的奖励，这两种方法都成本高昂且难以扩展。我们提出了一种自进化的RL框架VisPlay，该框架使VLMs能够自主利用大量未标注的图像数据提高其推理能力。VisPlay从一个基础的VLM开始，将其分配为两种交互的角色：一种是基于图像的问题提出者，提出具有挑战性但可回答的视觉问题；另一种是跨模态推理器，生成银级回答。这些角色通过联合训练和组相对策略优化（GRPO）进行训练，这种方法整合了多样性和难度奖励，以平衡生成问题的复杂性和银级回答的质量。VisPlay在两种模型家族中高效扩展。当在Qwen2.5-VL和MiMo-VL上训练时，VisPlay在八个基准测试中，包括MM-Vet和MMMU，在视觉推理、组合泛化和幻觉减少方面取得一致改进，展示了自进化的跨模态智能的可扩展路径。项目的页面可通过该链接访问。', 'title_zh': 'VisPlay: 自适应进化视觉-语言模型'}
{'arxiv_id': 'arXiv:2511.15658', 'title': 'GEO-Bench-2: From Performance to Capability, Rethinking Evaluation in Geospatial AI', 'authors': 'Naomi Simumba, Nils Lehmann, Paolo Fraccaro, Hamed Alemohammad, Geeth De Mel, Salman Khan, Manil Maskey, Nicolas Longepe, Xiao Xiang Zhu, Hannah Kerner, Juan Bernabe-Moreno, Alexander Lacoste', 'link': 'https://arxiv.org/abs/2511.15658', 'abstract': "Geospatial Foundation Models (GeoFMs) are transforming Earth Observation (EO), but evaluation lacks standardized protocols. GEO-Bench-2 addresses this with a comprehensive framework spanning classification, segmentation, regression, object detection, and instance segmentation across 19 permissively-licensed datasets. We introduce ''capability'' groups to rank models on datasets that share common characteristics (e.g., resolution, bands, temporality). This enables users to identify which models excel in each capability and determine which areas need improvement in future work. To support both fair comparison and methodological innovation, we define a prescriptive yet flexible evaluation protocol. This not only ensures consistency in benchmarking but also facilitates research into model adaptation strategies, a key and open challenge in advancing GeoFMs for downstream tasks.\nOur experiments show that no single model dominates across all tasks, confirming the specificity of the choices made during architecture design and pretraining. While models pretrained on natural images (ConvNext ImageNet, DINO V3) excel on high-resolution tasks, EO-specific models (TerraMind, Prithvi, and Clay) outperform them on multispectral applications such as agriculture and disaster response. These findings demonstrate that optimal model choice depends on task requirements, data modalities, and constraints. This shows that the goal of a single GeoFM model that performs well across all tasks remains open for future research. GEO-Bench-2 enables informed, reproducible GeoFM evaluation tailored to specific use cases. Code, data, and leaderboard for GEO-Bench-2 are publicly released under a permissive license.", 'abstract_zh': 'GeoFMs的空间基础模型正在变革地球观测，但评估缺乏标准化协议。GEO-Bench-2通过涵盖分类、分割、回归、对象检测和实例分割的全面框架，解决了这一问题，该框架横跨19个许可协议下的数据集。我们引入“能力”组来根据共享的共同特征对数据集对模型进行排名（例如，分辨率、波段、时间属性）。这使用户能够识别哪些模型在每个能力上表现最佳，并确定未来工作中需要改进的领域。为了支持公平比较和方法创新，我们制定了一种既具有指导性又灵活的评估协议。这不仅确保了基准测试的一致性，还促进了模型适应策略的研究，这是推动GeoFMs在下游任务中应用的一项关键且开放的挑战。我们的实验表明，并非单一模型在所有任务中皆占优势，证实了在架构设计和预训练过程中所作选择的特定性。虽然在自然图像上预训练的模型（ConvNext ImageNet、DINO V3）在高分辨率任务中表现出色，但专门针对地球观测的应用（如农业和灾害响应）的模型（TerraMind、Prithvi和Clay）在多光谱应用中表现更优。这些发现表明，最优模型的选择取决于任务要求、数据模态和约束条件。这表明，单一GeoFM模型在所有任务中都表现良好的目标仍然需要未来研究来解决。GEO-Bench-2使具有针对性的GeoFM评估变得知情和可重复。GEO-Bench-2的代码、数据和排行榜在许可协议下公开发布。', 'title_zh': 'Geo-Bench-2: 从性能到能力，重新思考地理空间AI的评估'}
{'arxiv_id': 'arXiv:2511.15652', 'title': 'Continual Reinforcement Learning for Cyber-Physical Systems: Lessons Learned and Open Challenges', 'authors': 'Kim N. Nolle, Ivana Dusparic, Rhodri Cusack, Vinny Cahill', 'link': 'https://arxiv.org/abs/2511.15652', 'abstract': 'Continual learning (CL) is a branch of machine learning that aims to enable agents to adapt and generalise previously learned abilities so that these can be reapplied to new tasks or environments. This is particularly useful in multi-task settings or in non-stationary environments, where the dynamics can change over time. This is particularly relevant in cyber-physical systems such as autonomous driving. However, despite recent advances in CL, successfully applying it to reinforcement learning (RL) is still an open problem.\nThis paper highlights open challenges in continual RL (CRL) based on experiments in an autonomous driving environment. In this environment, the agent must learn to successfully park in four different scenarios corresponding to parking spaces oriented at varying angles. The agent is successively trained in these four scenarios one after another, representing a CL environment, using Proximal Policy Optimisation (PPO). These experiments exposed a number of open challenges in CRL: finding suitable abstractions of the environment, oversensitivity to hyperparameters, catastrophic forgetting, and efficient use of neural network capacity.\nBased on these identified challenges, we present open research questions that are important to be addressed for creating robust CRL systems. In addition, the identified challenges call into question the suitability of neural networks for CL. We also identify the need for interdisciplinary research, in particular between computer science and neuroscience.', 'abstract_zh': '持续学习（CL）是机器学习的一个分支，旨在使智能体能够适应并泛化之前学到的能力，以便这些能力能够应用于新的任务或环境中。这在多任务设置或非稳态环境中尤为重要，因为系统的动态性会随时间变化。这在自动驾驶等物理-信息系统中尤为相关。然而，尽管在持续学习领域取得了 recent 进展，将其成功应用于强化学习（RL）仍然是一个开放问题。\n\n本文基于在自动驾驶环境中进行的实验，指出了基于持续学习的强化学习（CRL）中的几个开放挑战。在这些实验中，智能体需要依次学习在四个不同场景下成功停车的能力，这些场景对应于不同角度的停车位。智能体使用 proximal 策略优化（PPO）在这些四个场景中逐个接受训练，形成一个持续学习环境。这些实验揭示了 CRL 中的若干开放挑战：环境的有效抽象、超参数的过度敏感性、灾难性遗忘以及神经网络容量的有效利用。\n\n基于上述识别出的挑战，我们提出了亟待解决的开放研究问题，以创建可靠的持续学习强化学习系统。此外，这些挑战也引发了对神经网络在持续学习中适用性的疑问，强调了跨学科研究的必要性，特别是在计算机科学与神经科学之间。', 'title_zh': '持续强化学习在网络物理系统中的应用：经验教训与开放挑战'}
{'arxiv_id': 'arXiv:2511.15658', 'title': 'GEO-Bench-2: From Performance to Capability, Rethinking Evaluation in Geospatial AI', 'authors': 'Naomi Simumba, Nils Lehmann, Paolo Fraccaro, Hamed Alemohammad, Geeth De Mel, Salman Khan, Manil Maskey, Nicolas Longepe, Xiao Xiang Zhu, Hannah Kerner, Juan Bernabe-Moreno, Alexander Lacoste', 'link': 'https://arxiv.org/abs/2511.15658', 'abstract': "Geospatial Foundation Models (GeoFMs) are transforming Earth Observation (EO), but evaluation lacks standardized protocols. GEO-Bench-2 addresses this with a comprehensive framework spanning classification, segmentation, regression, object detection, and instance segmentation across 19 permissively-licensed datasets. We introduce ''capability'' groups to rank models on datasets that share common characteristics (e.g., resolution, bands, temporality). This enables users to identify which models excel in each capability and determine which areas need improvement in future work. To support both fair comparison and methodological innovation, we define a prescriptive yet flexible evaluation protocol. This not only ensures consistency in benchmarking but also facilitates research into model adaptation strategies, a key and open challenge in advancing GeoFMs for downstream tasks.\nOur experiments show that no single model dominates across all tasks, confirming the specificity of the choices made during architecture design and pretraining. While models pretrained on natural images (ConvNext ImageNet, DINO V3) excel on high-resolution tasks, EO-specific models (TerraMind, Prithvi, and Clay) outperform them on multispectral applications such as agriculture and disaster response. These findings demonstrate that optimal model choice depends on task requirements, data modalities, and constraints. This shows that the goal of a single GeoFM model that performs well across all tasks remains open for future research. GEO-Bench-2 enables informed, reproducible GeoFM evaluation tailored to specific use cases. Code, data, and leaderboard for GEO-Bench-2 are publicly released under a permissive license.", 'abstract_zh': 'GeoFMs的地理空间基础模型正在_transforming地球观测(EO)，但评估缺乏标准化协议。GEO-Bench-2通过涵盖分类、分割、回归、对象检测和实例分割的全面框架，跨越了19个许可使用的数据集，解决了这一问题。我们引入“能力”组，按共享共同特征（例如，分辨率、波段、时间性）的数据集对模型进行排名。这使用户能够确定哪些模型在每个能力方面表现最佳，并确定未来工作需要改进的领域。为了支持公平比较和方法创新，我们定义了一种规范但灵活的评估协议。这不仅确保了基准测试的一致性，还促进了对模型适应策略的研究，这是推进GeoFMs用于下游任务的一个重要且开放的挑战。', 'title_zh': 'GEO-Bench-2: 从性能到能力，重新思考地理空间AI的评估'}
{'arxiv_id': 'arXiv:2511.15652', 'title': 'Continual Reinforcement Learning for Cyber-Physical Systems: Lessons Learned and Open Challenges', 'authors': 'Kim N. Nolle, Ivana Dusparic, Rhodri Cusack, Vinny Cahill', 'link': 'https://arxiv.org/abs/2511.15652', 'abstract': 'Continual learning (CL) is a branch of machine learning that aims to enable agents to adapt and generalise previously learned abilities so that these can be reapplied to new tasks or environments. This is particularly useful in multi-task settings or in non-stationary environments, where the dynamics can change over time. This is particularly relevant in cyber-physical systems such as autonomous driving. However, despite recent advances in CL, successfully applying it to reinforcement learning (RL) is still an open problem.\nThis paper highlights open challenges in continual RL (CRL) based on experiments in an autonomous driving environment. In this environment, the agent must learn to successfully park in four different scenarios corresponding to parking spaces oriented at varying angles. The agent is successively trained in these four scenarios one after another, representing a CL environment, using Proximal Policy Optimisation (PPO). These experiments exposed a number of open challenges in CRL: finding suitable abstractions of the environment, oversensitivity to hyperparameters, catastrophic forgetting, and efficient use of neural network capacity.\nBased on these identified challenges, we present open research questions that are important to be addressed for creating robust CRL systems. In addition, the identified challenges call into question the suitability of neural networks for CL. We also identify the need for interdisciplinary research, in particular between computer science and neuroscience.', 'abstract_zh': '持续学习（CL）是机器学习的一个分支，旨在使智能体能够适应和泛化之前学习的能力，以便将这些能力重新应用于新任务或环境中。这在多任务设置或非稳态环境中特别有用，因为动态可能会随着时间变化。这一问题在诸如自动驾驶的计算物理系统中尤为重要。然而，尽管近年来在持续学习方面取得了进展，将其成功应用于强化学习（RL）仍然是一个开放问题。', 'title_zh': '连续强化学习在网络物理系统中的应用：经验教训与开放挑战'}
{'arxiv_id': 'arXiv:2511.15623', 'title': 'Sufficient Explanations in Databases and their Connections to Necessary Explanations and Repairs', 'authors': 'Leopoldo Bertossi, Nina Pardal', 'link': 'https://arxiv.org/abs/2511.15623', 'abstract': 'The notion of cause, as formalized by Halpern and Pearl, has been recently applied to relational databases, to characterize and compute causal explanations for query answers. In this work we consider the alternative notion of sufficient explanation. We investigate its connections with database repairs as used for dealing with inconsistent databases, and with causality-based necessary explanations. We also obtain some computational results.', 'abstract_zh': '基于Halpern和Pearl formal化因果概念在关系数据库中的应用，本文探讨了因果解释的替代概念——充分解释，并调查了其与处理不一致数据库所使用的数据库修复之间的联系，以及与基于因果性的必要解释之间的联系，同时也获得了一些计算结果。', 'title_zh': '数据库中的充分解释及其与必要解释和修复的联系'}
{'arxiv_id': 'arXiv:2511.15652', 'title': 'Continual Reinforcement Learning for Cyber-Physical Systems: Lessons Learned and Open Challenges', 'authors': 'Kim N. Nolle, Ivana Dusparic, Rhodri Cusack, Vinny Cahill', 'link': 'https://arxiv.org/abs/2511.15652', 'abstract': 'Continual learning (CL) is a branch of machine learning that aims to enable agents to adapt and generalise previously learned abilities so that these can be reapplied to new tasks or environments. This is particularly useful in multi-task settings or in non-stationary environments, where the dynamics can change over time. This is particularly relevant in cyber-physical systems such as autonomous driving. However, despite recent advances in CL, successfully applying it to reinforcement learning (RL) is still an open problem.\nThis paper highlights open challenges in continual RL (CRL) based on experiments in an autonomous driving environment. In this environment, the agent must learn to successfully park in four different scenarios corresponding to parking spaces oriented at varying angles. The agent is successively trained in these four scenarios one after another, representing a CL environment, using Proximal Policy Optimisation (PPO). These experiments exposed a number of open challenges in CRL: finding suitable abstractions of the environment, oversensitivity to hyperparameters, catastrophic forgetting, and efficient use of neural network capacity.\nBased on these identified challenges, we present open research questions that are important to be addressed for creating robust CRL systems. In addition, the identified challenges call into question the suitability of neural networks for CL. We also identify the need for interdisciplinary research, in particular between computer science and neuroscience.', 'abstract_zh': '持续学习在自主驾驶环境中的挑战与研究问题探讨', 'title_zh': '持续强化学习在网络物理系统中的应用：经验教训与开放挑战'}
{'arxiv_id': 'arXiv:2511.15623', 'title': 'Sufficient Explanations in Databases and their Connections to Necessary Explanations and Repairs', 'authors': 'Leopoldo Bertossi, Nina Pardal', 'link': 'https://arxiv.org/abs/2511.15623', 'abstract': 'The notion of cause, as formalized by Halpern and Pearl, has been recently applied to relational databases, to characterize and compute causal explanations for query answers. In this work we consider the alternative notion of sufficient explanation. We investigate its connections with database repairs as used for dealing with inconsistent databases, and with causality-based necessary explanations. We also obtain some computational results.', 'abstract_zh': '基于Halpern和Pearl的形式化因果概念，因果解释已在关系数据库中应用，以表征和计算查询答案的因果解释。本文中，我们考虑了充分解释的替代概念，并探讨了其与处理不一致数据库的数据库修复的关系，以及与基于因果关系的必要解释的关系。我们还获得了一些计算结果。', 'title_zh': '数据库中的充分解释及其与必要解释和修复的关联'}
{'arxiv_id': 'arXiv:2511.15622', 'title': 'The SA-FARI Dataset: Segment Anything in Footage of Animals for Recognition and Identification', 'authors': 'Dante Francisco Wasmuht, Otto Brookes, Maximillian Schall, Pablo Palencia, Chris Beirne, Tilo Burghardt, Majid Mirmehdi, Hjalmar Kühl, Mimi Arandjelovic, Sam Pottie, Peter Bermant, Brandon Asheim, Yi Jin Toh, Adam Elzinga, Jason Holmberg, Andrew Whitworth, Eleanor Flatt, Laura Gustafson, Chaitanya Ryali, Yuan-Ting Hu, Baishan Guo, Andrew Westbury, Kate Saenko, Didac Suris', 'link': 'https://arxiv.org/abs/2511.15622', 'abstract': 'Automated video analysis is critical for wildlife conservation. A foundational task in this domain is multi-animal tracking (MAT), which underpins applications such as individual re-identification and behavior recognition. However, existing datasets are limited in scale, constrained to a few species, or lack sufficient temporal and geographical diversity - leaving no suitable benchmark for training general-purpose MAT models applicable across wild animal populations. To address this, we introduce SA-FARI, the largest open-source MAT dataset for wild animals. It comprises 11,609 camera trap videos collected over approximately 10 years (2014-2024) from 741 locations across 4 continents, spanning 99 species categories. Each video is exhaustively annotated culminating in ~46 hours of densely annotated footage containing 16,224 masklet identities and 942,702 individual bounding boxes, segmentation masks, and species labels. Alongside the task-specific annotations, we publish anonymized camera trap locations for each video. Finally, we present comprehensive benchmarks on SA-FARI using state-of-the-art vision-language models for detection and tracking, including SAM 3, evaluated with both species-specific and generic animal prompts. We also compare against vision-only methods developed specifically for wildlife analysis. SA-FARI is the first large-scale dataset to combine high species diversity, multi-region coverage, and high-quality spatio-temporal annotations, offering a new foundation for advancing generalizable multianimal tracking in the wild. The dataset is available at $\\href{this https URL}{\\text{this http URL}}$.', 'abstract_zh': '自动视频分析对于野生动物保护至关重要。该领域的一项基础任务是多动物跟踪（MAT），其支撑着个体重识别和行为识别等应用。然而，现有的数据集在规模上有限制，仅限于少数几种物种，或者缺乏足够的时空多样性，因此没有适合训练适用于广泛野生动物种群的一般多动物跟踪模型的基准数据集。为了解决这一问题，我们引入了SA-FARI，这是一个最大的开源野生动物多动物跟踪数据集。该数据集包含约10年（2014-2024年）来自四大洲741个地点的11,609个相机陷阱视频，涵盖了99个物种类别。每个视频都进行了详尽标注，总计约46小时密集标注的视频片段，包含16,224个掩码身份和942,702个个体边界框、分割掩码和物种标签。除了任务特定的标注，我们还发布了每个视频的匿名相机陷阱位置。最后，我们使用最新的视觉-语言模型在SA-FARI上进行了综合基准测试，包括SAM 3，评估了特定物种和通用动物提示下的检测和跟踪性能。我们还将与专门为野生动物分析开发的仅视觉方法进行了比较。SA-FARI是第一个结合高物种多样性、多区域覆盖和高质量时空标注的大规模数据集，为进一步发展通用多动物跟踪提供了新的基础。数据集可在<这个网址>获得。', 'title_zh': 'SA-FARI数据集：识别与鉴定动物片段中的对象'}
{'arxiv_id': 'arXiv:2511.15623', 'title': 'Sufficient Explanations in Databases and their Connections to Necessary Explanations and Repairs', 'authors': 'Leopoldo Bertossi, Nina Pardal', 'link': 'https://arxiv.org/abs/2511.15623', 'abstract': 'The notion of cause, as formalized by Halpern and Pearl, has been recently applied to relational databases, to characterize and compute causal explanations for query answers. In this work we consider the alternative notion of sufficient explanation. We investigate its connections with database repairs as used for dealing with inconsistent databases, and with causality-based necessary explanations. We also obtain some computational results.', 'abstract_zh': '形式化因果概念由Halpern和Pearl提出，并已应用于关系数据库，用于 characterizing 和 computing 查询答案的因果解释。本文我们考虑替代的充分解释概念，并考察其与处理不一致数据库中的数据库修复的关系，以及与基于因果性的必要解释的关系。我们还获得了一些计算结果。', 'title_zh': '数据库中的充分解释及其与必要解释和修复的关系'}
{'arxiv_id': 'arXiv:2511.15622', 'title': 'The SA-FARI Dataset: Segment Anything in Footage of Animals for Recognition and Identification', 'authors': 'Dante Francisco Wasmuht, Otto Brookes, Maximillian Schall, Pablo Palencia, Chris Beirne, Tilo Burghardt, Majid Mirmehdi, Hjalmar Kühl, Mimi Arandjelovic, Sam Pottie, Peter Bermant, Brandon Asheim, Yi Jin Toh, Adam Elzinga, Jason Holmberg, Andrew Whitworth, Eleanor Flatt, Laura Gustafson, Chaitanya Ryali, Yuan-Ting Hu, Baishan Guo, Andrew Westbury, Kate Saenko, Didac Suris', 'link': 'https://arxiv.org/abs/2511.15622', 'abstract': 'Automated video analysis is critical for wildlife conservation. A foundational task in this domain is multi-animal tracking (MAT), which underpins applications such as individual re-identification and behavior recognition. However, existing datasets are limited in scale, constrained to a few species, or lack sufficient temporal and geographical diversity - leaving no suitable benchmark for training general-purpose MAT models applicable across wild animal populations. To address this, we introduce SA-FARI, the largest open-source MAT dataset for wild animals. It comprises 11,609 camera trap videos collected over approximately 10 years (2014-2024) from 741 locations across 4 continents, spanning 99 species categories. Each video is exhaustively annotated culminating in ~46 hours of densely annotated footage containing 16,224 masklet identities and 942,702 individual bounding boxes, segmentation masks, and species labels. Alongside the task-specific annotations, we publish anonymized camera trap locations for each video. Finally, we present comprehensive benchmarks on SA-FARI using state-of-the-art vision-language models for detection and tracking, including SAM 3, evaluated with both species-specific and generic animal prompts. We also compare against vision-only methods developed specifically for wildlife analysis. SA-FARI is the first large-scale dataset to combine high species diversity, multi-region coverage, and high-quality spatio-temporal annotations, offering a new foundation for advancing generalizable multianimal tracking in the wild. The dataset is available at $\\href{this https URL}{\\text{this http URL}}$.', 'abstract_zh': '自动视频分析对于野生动物保护至关重要。该领域的一项基础任务是多动物跟踪（MAT），这项任务支撑着个体再识别和行为识别等应用。然而，现有的数据集在规模、物种限制以及时空多样性方面存在局限，没有适合的基准数据集用于训练适用于各类野生动物种群的通用MAT模型。为了解决这一问题，我们介绍了SA-FARI，这是最大的开源野生动物多动物跟踪数据集。它包括从四大洲741个地点收集的约10年（2014-2024）时间跨度的11,609个相机陷阱视频，涵盖了99个种类的野生动物，每种视频都进行了详尽标注，包含46小时密集标注的视频片段，含有16,224个掩码身份和942,702个个体边界框、分割掩码和物种标签。除了任务特定的标注，我们还发布了每个视频的匿名相机陷阱位置。最后，我们使用最先进的视觉语言模型在SA-FARI上进行了全面基准测试，包括SAM 3，并使用物种特定和通用动物提示进行评估。我们还将与专门为野生动物分析开发的纯视觉方法进行了对比。SA-FARI是第一个结合高物种多样性、多地区覆盖和高质量时空标注的大规模数据集，为野生环境中的通用多动物跟踪提供了新的基础。数据集可在<这个网址>获取。', 'title_zh': 'SA-FARI数据集：动物影像中的内容分割及其识别与标识'}
{'arxiv_id': 'arXiv:2511.15614', 'title': 'Optimus-Q: Utilizing Federated Learning in Adaptive Robots for Intelligent Nuclear Power Plant Operations through Quantum Cryptography', 'authors': 'Sai Puppala, Ismail Hossain, Jahangir Alam, Sajedul Talukder', 'link': 'https://arxiv.org/abs/2511.15614', 'abstract': 'The integration of advanced robotics in nuclear power plants (NPPs) presents a transformative opportunity to enhance safety, efficiency, and environmental monitoring in high-stakes environments. Our paper introduces the Optimus-Q robot, a sophisticated system designed to autonomously monitor air quality and detect contamination while leveraging adaptive learning techniques and secure quantum communication. Equipped with advanced infrared sensors, the Optimus-Q robot continuously streams real-time environmental data to predict hazardous gas emissions, including carbon dioxide (CO$_2$), carbon monoxide (CO), and methane (CH$_4$). Utilizing a federated learning approach, the robot collaborates with other systems across various NPPs to improve its predictive capabilities without compromising data privacy. Additionally, the implementation of Quantum Key Distribution (QKD) ensures secure data transmission, safeguarding sensitive operational information. Our methodology combines systematic navigation patterns with machine learning algorithms to facilitate efficient coverage of designated areas, thereby optimizing contamination monitoring processes. Through simulations and real-world experiments, we demonstrate the effectiveness of the Optimus-Q robot in enhancing operational safety and responsiveness in nuclear facilities. This research underscores the potential of integrating robotics, machine learning, and quantum technologies to revolutionize monitoring systems in hazardous environments.', 'abstract_zh': '先进机器人在核 power 厂的集成：提高高风险环境下的安全、效率和环境监测能力', 'title_zh': 'Optimus-Q：通过量子加密实现智能核电站操作的适应性机器人联邦学习'}
{'arxiv_id': 'arXiv:2511.15622', 'title': 'The SA-FARI Dataset: Segment Anything in Footage of Animals for Recognition and Identification', 'authors': 'Dante Francisco Wasmuht, Otto Brookes, Maximillian Schall, Pablo Palencia, Chris Beirne, Tilo Burghardt, Majid Mirmehdi, Hjalmar Kühl, Mimi Arandjelovic, Sam Pottie, Peter Bermant, Brandon Asheim, Yi Jin Toh, Adam Elzinga, Jason Holmberg, Andrew Whitworth, Eleanor Flatt, Laura Gustafson, Chaitanya Ryali, Yuan-Ting Hu, Baishan Guo, Andrew Westbury, Kate Saenko, Didac Suris', 'link': 'https://arxiv.org/abs/2511.15622', 'abstract': 'Automated video analysis is critical for wildlife conservation. A foundational task in this domain is multi-animal tracking (MAT), which underpins applications such as individual re-identification and behavior recognition. However, existing datasets are limited in scale, constrained to a few species, or lack sufficient temporal and geographical diversity - leaving no suitable benchmark for training general-purpose MAT models applicable across wild animal populations. To address this, we introduce SA-FARI, the largest open-source MAT dataset for wild animals. It comprises 11,609 camera trap videos collected over approximately 10 years (2014-2024) from 741 locations across 4 continents, spanning 99 species categories. Each video is exhaustively annotated culminating in ~46 hours of densely annotated footage containing 16,224 masklet identities and 942,702 individual bounding boxes, segmentation masks, and species labels. Alongside the task-specific annotations, we publish anonymized camera trap locations for each video. Finally, we present comprehensive benchmarks on SA-FARI using state-of-the-art vision-language models for detection and tracking, including SAM 3, evaluated with both species-specific and generic animal prompts. We also compare against vision-only methods developed specifically for wildlife analysis. SA-FARI is the first large-scale dataset to combine high species diversity, multi-region coverage, and high-quality spatio-temporal annotations, offering a new foundation for advancing generalizable multianimal tracking in the wild. The dataset is available at $\\href{this https URL}{\\text{this http URL}}$.', 'abstract_zh': '自动视频分析对于野生动物保护至关重要。该领域的一个基础任务是多动物追踪（MAT），其支撑着个体再识别和行为识别等应用。然而，现有的数据集在规模、物种限制或时空多样性方面存在局限性，缺乏适用于跨野生动物种群的一般性MAT模型的基准。为解决这一问题，我们引入了SA-FARI，这是最大的开放源多动物追踪数据集，用于野生動物。该数据集包含从四大洲741个地点收集的约10年（2014-2024）时间跨度的11,609个相机陷阱视频，涵盖99种物种类别。每个视频都被详尽标注，总计约46小时密集标注的视频片段，包含16,224个掩码身份和942,702个个体边界框、分割掩码和物种标签。除了特定任务的标注外，我们还发布了每个视频的匿名相机陷阱位置。最后，我们使用最新的视觉-语言模型对SA-FARI进行全面基准测试，包括SAM 3，该模型用特定物种和通用动物提示进行评估。我们还与专门为野生动物分析开发的仅视觉方法进行了比较。SA-FARI是第一个结合高物种多样性、多区域覆盖和高质量时空标注的大规模数据集，为推进通用多动物追踪提供了新的基础。数据集可以访问：this https URL', 'title_zh': 'SA-FARI数据集：动物影像中的目标分割以实现识别和鉴定'}
{'arxiv_id': 'arXiv:2511.15614', 'title': 'Optimus-Q: Utilizing Federated Learning in Adaptive Robots for Intelligent Nuclear Power Plant Operations through Quantum Cryptography', 'authors': 'Sai Puppala, Ismail Hossain, Jahangir Alam, Sajedul Talukder', 'link': 'https://arxiv.org/abs/2511.15614', 'abstract': 'The integration of advanced robotics in nuclear power plants (NPPs) presents a transformative opportunity to enhance safety, efficiency, and environmental monitoring in high-stakes environments. Our paper introduces the Optimus-Q robot, a sophisticated system designed to autonomously monitor air quality and detect contamination while leveraging adaptive learning techniques and secure quantum communication. Equipped with advanced infrared sensors, the Optimus-Q robot continuously streams real-time environmental data to predict hazardous gas emissions, including carbon dioxide (CO$_2$), carbon monoxide (CO), and methane (CH$_4$). Utilizing a federated learning approach, the robot collaborates with other systems across various NPPs to improve its predictive capabilities without compromising data privacy. Additionally, the implementation of Quantum Key Distribution (QKD) ensures secure data transmission, safeguarding sensitive operational information. Our methodology combines systematic navigation patterns with machine learning algorithms to facilitate efficient coverage of designated areas, thereby optimizing contamination monitoring processes. Through simulations and real-world experiments, we demonstrate the effectiveness of the Optimus-Q robot in enhancing operational safety and responsiveness in nuclear facilities. This research underscores the potential of integrating robotics, machine learning, and quantum technologies to revolutionize monitoring systems in hazardous environments.', 'abstract_zh': '先进的机器人技术在核 power 厂中的集成为在高风险环境中增强安全、效率和环境监测提供了变革性的机会。我们的论文介绍了 Optimus-Q 机器人，这是一种集成了自适应学习技术和安全量子通信的先进系统，用于自主监测空气质量并检测污染。装备有高级红外传感器的 Optimus-Q 机器人连续传输实时环境数据，以预测包括二氧化碳（CO₂）、一氧化碳（CO）和甲烷（CH₄）在内的有害气体排放。采用联邦学习方法，机器人与其他多个核 power 厂的系统协作，以提高预测能力并保护数据隐私。此外，通过量子密钥分发（QKD）实施确保了数据传输的安全性，保护了敏感的操作信息。我们结合系统导航模式与机器学习算法的方法，促进了指定区域的有效覆盖，从而优化了污染监测过程。通过模拟和实际实验，我们展示了 Optimus-Q 机器人在核设施中增强操作安全性和响应性的有效性。本研究强调了将机器人技术、机器学习和量子技术集成到危险环境中的监测系统中可能带来的革命性变革。', 'title_zh': 'Optimus-Q：通过量子加密在自适应机器人中利用联邦学习以实现智能核电站运行'}
{'arxiv_id': 'arXiv:2511.15614', 'title': 'Optimus-Q: Utilizing Federated Learning in Adaptive Robots for Intelligent Nuclear Power Plant Operations through Quantum Cryptography', 'authors': 'Sai Puppala, Ismail Hossain, Jahangir Alam, Sajedul Talukder', 'link': 'https://arxiv.org/abs/2511.15614', 'abstract': 'The integration of advanced robotics in nuclear power plants (NPPs) presents a transformative opportunity to enhance safety, efficiency, and environmental monitoring in high-stakes environments. Our paper introduces the Optimus-Q robot, a sophisticated system designed to autonomously monitor air quality and detect contamination while leveraging adaptive learning techniques and secure quantum communication. Equipped with advanced infrared sensors, the Optimus-Q robot continuously streams real-time environmental data to predict hazardous gas emissions, including carbon dioxide (CO$_2$), carbon monoxide (CO), and methane (CH$_4$). Utilizing a federated learning approach, the robot collaborates with other systems across various NPPs to improve its predictive capabilities without compromising data privacy. Additionally, the implementation of Quantum Key Distribution (QKD) ensures secure data transmission, safeguarding sensitive operational information. Our methodology combines systematic navigation patterns with machine learning algorithms to facilitate efficient coverage of designated areas, thereby optimizing contamination monitoring processes. Through simulations and real-world experiments, we demonstrate the effectiveness of the Optimus-Q robot in enhancing operational safety and responsiveness in nuclear facilities. This research underscores the potential of integrating robotics, machine learning, and quantum technologies to revolutionize monitoring systems in hazardous environments.', 'abstract_zh': '先进机器人在核电力植物中的集成：提高高风险环境下的安全、效率和环境监测的变革性机会', 'title_zh': 'Optimus-Q：通过量子密码学在适应性机器人中利用联邦学习以实现智能核电站运营'}
{'arxiv_id': 'arXiv:2511.15580', 'title': 'CompTrack: Information Bottleneck-Guided Low-Rank Dynamic Token Compression for Point Cloud Tracking', 'authors': 'Sifan Zhou, Yichao Cao, Jiahao Nie, Yuqian Fu, Ziyu Zhao, Xiaobo Lu, Shuo Wang', 'link': 'https://arxiv.org/abs/2511.15580', 'abstract': '3D single object tracking (SOT) in LiDAR point clouds is a critical task in computer vision and autonomous driving. Despite great success having been achieved, the inherent sparsity of point clouds introduces a dual-redundancy challenge that limits existing trackers: (1) vast spatial redundancy from background noise impairs accuracy, and (2) informational redundancy within the foreground hinders efficiency. To tackle these issues, we propose CompTrack, a novel end-to-end framework that systematically eliminates both forms of redundancy in point clouds. First, CompTrack incorporates a Spatial Foreground Predictor (SFP) module to filter out irrelevant background noise based on information entropy, addressing spatial redundancy. Subsequently, its core is an Information Bottleneck-guided Dynamic Token Compression (IB-DTC) module that eliminates the informational redundancy within the foreground. Theoretically grounded in low-rank approximation, this module leverages an online SVD analysis to adaptively compress the redundant foreground into a compact and highly informative set of proxy tokens. Extensive experiments on KITTI, nuScenes and Waymo datasets demonstrate that CompTrack achieves top-performing tracking performance with superior efficiency, running at a real-time 90 FPS on a single RTX 3090 GPU.', 'abstract_zh': '基于LiDAR点云的3D单目标跟踪（SOT）是计算机视觉和自动驾驶领域的一项关键任务。尽管已经取得了显著的成果，但点云的固有稀疏性给现有的跟踪器带来了双重冗余挑战：（1）背景噪声引起的广泛空间冗余影响准确度，（2）前景内的信息冗余妨碍了效率。为解决这些问题，我们提出了一种名为CompTrack的新型端到端框架，系统地消除了点云中的两种冗余。首先，CompTrack引入了一个基于信息熵的空间前景预测模块（SFP），以过滤无关的背景噪声，解决空间冗余问题。随后，其核心是通过信息瓶颈指导的动力学令牌压缩模块（IB-DTC），该模块消除前景内的信息冗余。该模块基于低秩近似理论，利用在线SVD分析自适应地将冗余的前景压缩为一个紧凑且高度信息量的代理令牌集合。在KITT', 'title_zh': 'CompTrack：信息瓶颈引导的低秩动态 token 压缩在点云跟踪中的应用'}
{'arxiv_id': 'arXiv:2511.15580', 'title': 'CompTrack: Information Bottleneck-Guided Low-Rank Dynamic Token Compression for Point Cloud Tracking', 'authors': 'Sifan Zhou, Yichao Cao, Jiahao Nie, Yuqian Fu, Ziyu Zhao, Xiaobo Lu, Shuo Wang', 'link': 'https://arxiv.org/abs/2511.15580', 'abstract': '3D single object tracking (SOT) in LiDAR point clouds is a critical task in computer vision and autonomous driving. Despite great success having been achieved, the inherent sparsity of point clouds introduces a dual-redundancy challenge that limits existing trackers: (1) vast spatial redundancy from background noise impairs accuracy, and (2) informational redundancy within the foreground hinders efficiency. To tackle these issues, we propose CompTrack, a novel end-to-end framework that systematically eliminates both forms of redundancy in point clouds. First, CompTrack incorporates a Spatial Foreground Predictor (SFP) module to filter out irrelevant background noise based on information entropy, addressing spatial redundancy. Subsequently, its core is an Information Bottleneck-guided Dynamic Token Compression (IB-DTC) module that eliminates the informational redundancy within the foreground. Theoretically grounded in low-rank approximation, this module leverages an online SVD analysis to adaptively compress the redundant foreground into a compact and highly informative set of proxy tokens. Extensive experiments on KITTI, nuScenes and Waymo datasets demonstrate that CompTrack achieves top-performing tracking performance with superior efficiency, running at a real-time 90 FPS on a single RTX 3090 GPU.', 'abstract_zh': '基于LiDAR点云的3D单目标跟踪（SOT）是计算机视觉和自动驾驶中的关键任务。尽管已经取得了巨大成功，点云的固有稀疏性引入了一种双重冗余挑战，限制了现有跟踪器：（1）来自背景噪声的巨大空间冗余影响准确性，（2）前景内的信息冗余阻碍了效率。为了解决这些问题，我们提出了CompTrack，这是一种新颖的端到端框架，系统地消除了点云中的两种冗余。首先，CompTrack引入了一个空间前景预测器（SFP）模块，基于信息熵过滤掉无关的背景噪声，解决空间冗余问题。其次，其核心是基于信息瓶颈的动态 token 压缩（IB-DTC）模块，消除前景中的信息冗余。该模块理论基于低秩逼近，利用在线 SVD 分析适应性地将冗余前景压缩成一个紧凑且高度信息丰富的代理 token 集合。在 KITTI、nuScenes 和 Waymo 数据集上的 extensive 实验表明，CompTrack 在保持高效性的同时实现了顶级的跟踪性能，在 single RTX 3090 GPU 上以 90 FPS 实现实时运行。', 'title_zh': 'CompTrack: 信息瓶颈引导的低秩动态令牌压缩用于点云跟踪'}
{'arxiv_id': 'arXiv:2511.15574', 'title': 'HSKBenchmark: Modeling and Benchmarking Chinese Second Language Acquisition in Large Language Models through Curriculum Tuning', 'authors': 'Qihao Yang, Xuelin Wang, Jiale Chen, Xuelian Dong, Yuxin Hao, Tianyong Hao', 'link': 'https://arxiv.org/abs/2511.15574', 'abstract': "Language acquisition is vital to revealing the nature of human language intelligence and has recently emerged as a promising perspective for improving the interpretability of large language models (LLMs). However, it is ethically and practically infeasible to conduct experiments that require controlling human learners' language inputs. This poses challenges for the verifiability and scalability of language acquisition modeling, particularly in Chinese second language acquisition (SLA). While LLMs provide a controllable and reproducible alternative, a systematic benchmark to support phase-wise modeling and assessment is still lacking. In this paper, we present HSKBenchmark, the first benchmark for staged modeling and writing assessment of LLMs in Chinese SLA. It covers HSK levels 3 to 6 and includes authentic textbooks with 6.76 million tokens, 16K synthetic instruction samples, 30 test topics, and a linguistically grounded evaluation system. To simulate human learning trajectories, we introduce a curriculum-tuning framework that trains models from beginner to advanced levels. An evaluation system is created to examine level-based grammar coverage, writing errors, lexical and syntactic complexity, and holistic scoring. We also build HSKAgent, fine-tuned on 10K learner compositions. Extensive experimental results demonstrate that HSKBenchmark not only models Chinese SLA effectively, but also serves as a reliable benchmark for dynamic writing assessment in LLMs. Our fine-tuned LLMs have writing performance on par with advanced human learners and exhibit human-like acquisition characteristics. The HSKBenchmark, HSKAgent, and checkpoints serve as foundational tools and resources, with the potential to pave the way for future research on language acquisition modeling and LLMs interpretability. Code and data are publicly available at: this https URL.", 'abstract_zh': 'HSKBenchmark：中文二语习得分阶段建模与写作评估基准', 'title_zh': 'HSKBenchmark: 通过课程调谐在大型语言模型中建模与基准测试汉语二语言习得'}
{'arxiv_id': 'arXiv:2511.15580', 'title': 'CompTrack: Information Bottleneck-Guided Low-Rank Dynamic Token Compression for Point Cloud Tracking', 'authors': 'Sifan Zhou, Yichao Cao, Jiahao Nie, Yuqian Fu, Ziyu Zhao, Xiaobo Lu, Shuo Wang', 'link': 'https://arxiv.org/abs/2511.15580', 'abstract': '3D single object tracking (SOT) in LiDAR point clouds is a critical task in computer vision and autonomous driving. Despite great success having been achieved, the inherent sparsity of point clouds introduces a dual-redundancy challenge that limits existing trackers: (1) vast spatial redundancy from background noise impairs accuracy, and (2) informational redundancy within the foreground hinders efficiency. To tackle these issues, we propose CompTrack, a novel end-to-end framework that systematically eliminates both forms of redundancy in point clouds. First, CompTrack incorporates a Spatial Foreground Predictor (SFP) module to filter out irrelevant background noise based on information entropy, addressing spatial redundancy. Subsequently, its core is an Information Bottleneck-guided Dynamic Token Compression (IB-DTC) module that eliminates the informational redundancy within the foreground. Theoretically grounded in low-rank approximation, this module leverages an online SVD analysis to adaptively compress the redundant foreground into a compact and highly informative set of proxy tokens. Extensive experiments on KITTI, nuScenes and Waymo datasets demonstrate that CompTrack achieves top-performing tracking performance with superior efficiency, running at a real-time 90 FPS on a single RTX 3090 GPU.', 'abstract_zh': '基于LiDAR点云的3D单目标跟踪（SOT）是计算机视觉和自动驾驶领域的一个关键任务。尽管已经取得了显著的成功，点云的固有稀疏性引入了双重冗余挑战，限制了现有跟踪器：（1）背景噪声带来的巨大空间冗余影响了准确性，（2）前景内的信息冗余阻碍了效率。为了应对这些问题，我们提出了CompTrack，这是一种新颖的端到端框架，系统地消除了点云中的两种冗余。首先，CompTrack引入了一个基于信息熵的 Spatial Foreground Predictor (SFP) 模块，用于过滤掉无关的背景噪声，解决了空间冗余问题。其次，其核心是一个基于Information Bottleneck的动态token压缩（IB-DTC）模块，用于消除前景内的信息冗余。该模块理论上基于低秩逼近，通过在线SVD分析自适应地将冗余前景压缩成一个紧凑且高度信息化的代理token集合。在KITTI、nuScenes和Waymo数据集上的 extensive 实验表明，CompTrack在保持卓越效率的同时实现了顶级的跟踪性能，可在单个RTX 3090 GPU上以90 FPS 实时运行。', 'title_zh': 'CompTrack: 信息瓶颈引导的低秩动态令牌压缩用于点云跟踪'}
{'arxiv_id': 'arXiv:2511.15574', 'title': 'HSKBenchmark: Modeling and Benchmarking Chinese Second Language Acquisition in Large Language Models through Curriculum Tuning', 'authors': 'Qihao Yang, Xuelin Wang, Jiale Chen, Xuelian Dong, Yuxin Hao, Tianyong Hao', 'link': 'https://arxiv.org/abs/2511.15574', 'abstract': "Language acquisition is vital to revealing the nature of human language intelligence and has recently emerged as a promising perspective for improving the interpretability of large language models (LLMs). However, it is ethically and practically infeasible to conduct experiments that require controlling human learners' language inputs. This poses challenges for the verifiability and scalability of language acquisition modeling, particularly in Chinese second language acquisition (SLA). While LLMs provide a controllable and reproducible alternative, a systematic benchmark to support phase-wise modeling and assessment is still lacking. In this paper, we present HSKBenchmark, the first benchmark for staged modeling and writing assessment of LLMs in Chinese SLA. It covers HSK levels 3 to 6 and includes authentic textbooks with 6.76 million tokens, 16K synthetic instruction samples, 30 test topics, and a linguistically grounded evaluation system. To simulate human learning trajectories, we introduce a curriculum-tuning framework that trains models from beginner to advanced levels. An evaluation system is created to examine level-based grammar coverage, writing errors, lexical and syntactic complexity, and holistic scoring. We also build HSKAgent, fine-tuned on 10K learner compositions. Extensive experimental results demonstrate that HSKBenchmark not only models Chinese SLA effectively, but also serves as a reliable benchmark for dynamic writing assessment in LLMs. Our fine-tuned LLMs have writing performance on par with advanced human learners and exhibit human-like acquisition characteristics. The HSKBenchmark, HSKAgent, and checkpoints serve as foundational tools and resources, with the potential to pave the way for future research on language acquisition modeling and LLMs interpretability. Code and data are publicly available at: this https URL.", 'abstract_zh': 'HSKBenchmark：中文二语习得分阶段建模与写作评估基准', 'title_zh': 'HSKBenchmark: 通过课程调优建模与评估大型语言模型中的中文二外习得'}
{'arxiv_id': 'arXiv:2511.15574', 'title': 'HSKBenchmark: Modeling and Benchmarking Chinese Second Language Acquisition in Large Language Models through Curriculum Tuning', 'authors': 'Qihao Yang, Xuelin Wang, Jiale Chen, Xuelian Dong, Yuxin Hao, Tianyong Hao', 'link': 'https://arxiv.org/abs/2511.15574', 'abstract': "Language acquisition is vital to revealing the nature of human language intelligence and has recently emerged as a promising perspective for improving the interpretability of large language models (LLMs). However, it is ethically and practically infeasible to conduct experiments that require controlling human learners' language inputs. This poses challenges for the verifiability and scalability of language acquisition modeling, particularly in Chinese second language acquisition (SLA). While LLMs provide a controllable and reproducible alternative, a systematic benchmark to support phase-wise modeling and assessment is still lacking. In this paper, we present HSKBenchmark, the first benchmark for staged modeling and writing assessment of LLMs in Chinese SLA. It covers HSK levels 3 to 6 and includes authentic textbooks with 6.76 million tokens, 16K synthetic instruction samples, 30 test topics, and a linguistically grounded evaluation system. To simulate human learning trajectories, we introduce a curriculum-tuning framework that trains models from beginner to advanced levels. An evaluation system is created to examine level-based grammar coverage, writing errors, lexical and syntactic complexity, and holistic scoring. We also build HSKAgent, fine-tuned on 10K learner compositions. Extensive experimental results demonstrate that HSKBenchmark not only models Chinese SLA effectively, but also serves as a reliable benchmark for dynamic writing assessment in LLMs. Our fine-tuned LLMs have writing performance on par with advanced human learners and exhibit human-like acquisition characteristics. The HSKBenchmark, HSKAgent, and checkpoints serve as foundational tools and resources, with the potential to pave the way for future research on language acquisition modeling and LLMs interpretability. Code and data are publicly available at: this https URL.", 'abstract_zh': 'HSKBenchmark：中文二语习得分阶段建模与写作评估基准', 'title_zh': 'HSKBenchmark: 通过课程调优在大型语言模型中建模与基准测试汉语二外习得'}
{'arxiv_id': 'arXiv:2511.15557', 'title': 'B+ANN: A Fast Billion-Scale Disk-based Nearest-Neighbor Index', 'authors': 'Selim Furkan Tekin, Rajesh Bordawekar', 'link': 'https://arxiv.org/abs/2511.15557', 'abstract': 'Storing and processing of embedding vectors by specialized Vector databases (VDBs) has become the linchpin in building modern AI pipelines. Most current VDBs employ variants of a graph-based ap- proximate nearest-neighbor (ANN) index algorithm, HNSW, to an- swer semantic queries over stored vectors. Inspite of its wide-spread use, the HNSW algorithm suffers from several issues: in-memory design and implementation, random memory accesses leading to degradation in cache behavior, limited acceleration scope due to fine-grained pairwise computations, and support of only semantic similarity queries. In this paper, we present a novel disk-based ANN index, B+ANN, to address these issues: it first partitions input data into blocks containing semantically similar items, then builds an B+ tree variant to store blocks both in-memory and on disks, and finally, enables hybrid edge- and block-based in-memory traversals. As demonstrated by our experimantal evaluation, the proposed B+ANN disk-based index improves both quality (Recall value), and execution performance (Queries per second/QPS) over HNSW, by improving spatial and temporal locality for semantic operations, reducing cache misses (19.23% relative gain), and decreasing the memory consumption and disk-based build time by 24x over the DiskANN algorithm. Finally, it enables dissimilarity queries, which are not supported by similarity-oriented ANN indices.', 'abstract_zh': '专门化向量数据库（VDBs）用于嵌入向量的存储和处理已成为构建现代AI管道的关键环节。尽管大多数当前的VDBs采用基于图的近似最近邻（ANN）索引算法HNSW来回答存储向量的语义查询，但HNSW算法仍存在若干问题：内存设计和实现、随机内存访问导致缓存行为退化、由于细粒度的成对计算导致加速范围有限，以及仅支持语义相似性查询。在本文中，我们提出了一种新型磁盘基ANN索引B+ANN来解决这些问题：它首先将输入数据划分为包含语义相似项的块，然后构建一种B+树变体，同时将块存储在内存和磁盘中，最后实现基于边和块的混合内存遍历。通过我们的实验评估，提出的B+ANN磁盘基索引在召回值和执行性能（每秒查询量/QPS）方面均优于HNSW，通过对语义操作提高空间和时间局部性、减少缓存缺失（相对增益19.23%）以及将DiskANN算法的内存消耗和磁盘构建时间分别降低24倍，从而提高了性能。此外，它还支持差异性查询，这是面向相似性查询的ANN索引所不支持的。', 'title_zh': 'B+ANN：一种快速的基于磁盘的十亿规模最近邻索引'}
{'arxiv_id': 'arXiv:2511.15557', 'title': 'B+ANN: A Fast Billion-Scale Disk-based Nearest-Neighbor Index', 'authors': 'Selim Furkan Tekin, Rajesh Bordawekar', 'link': 'https://arxiv.org/abs/2511.15557', 'abstract': 'Storing and processing of embedding vectors by specialized Vector databases (VDBs) has become the linchpin in building modern AI pipelines. Most current VDBs employ variants of a graph-based ap- proximate nearest-neighbor (ANN) index algorithm, HNSW, to an- swer semantic queries over stored vectors. Inspite of its wide-spread use, the HNSW algorithm suffers from several issues: in-memory design and implementation, random memory accesses leading to degradation in cache behavior, limited acceleration scope due to fine-grained pairwise computations, and support of only semantic similarity queries. In this paper, we present a novel disk-based ANN index, B+ANN, to address these issues: it first partitions input data into blocks containing semantically similar items, then builds an B+ tree variant to store blocks both in-memory and on disks, and finally, enables hybrid edge- and block-based in-memory traversals. As demonstrated by our experimantal evaluation, the proposed B+ANN disk-based index improves both quality (Recall value), and execution performance (Queries per second/QPS) over HNSW, by improving spatial and temporal locality for semantic operations, reducing cache misses (19.23% relative gain), and decreasing the memory consumption and disk-based build time by 24x over the DiskANN algorithm. Finally, it enables dissimilarity queries, which are not supported by similarity-oriented ANN indices.', 'abstract_zh': '专门化向量数据库（VDBs）存储和处理嵌入向量已成为构建现代AI管道的关键。本文提出了一种基于磁盘的ANN索引B+ANN来解决现有问题：它首先将输入数据按语义相似项划分成块，然后构建一种变种B+树，该树能够在内存和磁盘上存储块，并最终实现基于边和块的混合内存遍历。通过实验评估表明，提出的B+ANN磁盘索引在Recall值和执行性能（每秒查询数/QPS）方面均优于HNSW，通过改善空间和时间局部性、减少缓存缺失（相对增益19.23%）以及与DiskANN算法相比减少24倍的内存消耗和磁盘构建时间，提高了语义操作的效果。此外，它支持不相似性查询，这是面向相似性ANN索引不支持的功能。', 'title_zh': 'B+ANN：一种快速的基于磁盘的亿规模最近邻索引'}
{'arxiv_id': 'arXiv:2511.15557', 'title': 'B+ANN: A Fast Billion-Scale Disk-based Nearest-Neighbor Index', 'authors': 'Selim Furkan Tekin, Rajesh Bordawekar', 'link': 'https://arxiv.org/abs/2511.15557', 'abstract': 'Storing and processing of embedding vectors by specialized Vector databases (VDBs) has become the linchpin in building modern AI pipelines. Most current VDBs employ variants of a graph-based ap- proximate nearest-neighbor (ANN) index algorithm, HNSW, to an- swer semantic queries over stored vectors. Inspite of its wide-spread use, the HNSW algorithm suffers from several issues: in-memory design and implementation, random memory accesses leading to degradation in cache behavior, limited acceleration scope due to fine-grained pairwise computations, and support of only semantic similarity queries. In this paper, we present a novel disk-based ANN index, B+ANN, to address these issues: it first partitions input data into blocks containing semantically similar items, then builds an B+ tree variant to store blocks both in-memory and on disks, and finally, enables hybrid edge- and block-based in-memory traversals. As demonstrated by our experimantal evaluation, the proposed B+ANN disk-based index improves both quality (Recall value), and execution performance (Queries per second/QPS) over HNSW, by improving spatial and temporal locality for semantic operations, reducing cache misses (19.23% relative gain), and decreasing the memory consumption and disk-based build time by 24x over the DiskANN algorithm. Finally, it enables dissimilarity queries, which are not supported by similarity-oriented ANN indices.', 'abstract_zh': '专用向量数据库（VDBs）存储和处理嵌入向量已成为构建现代AI管道的关键。本文提出了一种新的基于磁盘的ANN索引B+ANN，以解决现有问题：首先将输入数据划分为包含语义相似项的块，然后构建一种B+树变体，同时在内存和磁盘中存储块，并最终实现基于边和块的混合内存遍历。实验评估表明，提出的B+ANN磁盘索引在Recall值和查询每秒数量（QPS）方面均优于HNSW，通过改善空间和时间局部性、减少缓存缺失（相对增益19.23%）和磁盘构建时间减少24倍，从而提高语义操作的执行性能，并且还支持不是面向相似性查询的ANN索引所不支持的差异性查询。', 'title_zh': 'B+ANN：一种基于磁盘的快速十亿规模最近邻索引'}
{'arxiv_id': 'arXiv:2511.15552', 'title': 'Multimodal Evaluation of Russian-language Architectures', 'authors': 'Artem Chervyakov, Ulyana Isaeva, Anton Emelyanov, Artem Safin, Maria Tikhonova, Alexander Kharitonov, Yulia Lyakh, Petr Surovtsev, Denis Shevelev Vildan Saburov, Vasily Konovalov, Elisei Rykov, Ivan Sviridov, Amina Miftakhova, Ilseyar Alimova, Alexander Panchenko, Alexander Kapitanov, Alena Fenogenova', 'link': 'https://arxiv.org/abs/2511.15552', 'abstract': 'Multimodal large language models (MLLMs) are currently at the center of research attention, showing rapid progress in scale and capabilities, yet their intelligence, limitations, and risks remain insufficiently understood. To address these issues, particularly in the context of the Russian language, where no multimodal benchmarks currently exist, we introduce Mera Multi, an open multimodal evaluation framework for Russian-spoken architectures. The benchmark is instruction-based and encompasses default text, image, audio, and video modalities, comprising 18 newly constructed evaluation tasks for both general-purpose models and modality-specific architectures (image-to-text, video-to-text, and audio-to-text). Our contributions include: (i) a universal taxonomy of multimodal abilities; (ii) 18 datasets created entirely from scratch with attention to Russian cultural and linguistic specificity, unified prompts, and metrics; (iii) baseline results for both closed-source and open-source models; (iv) a methodology for preventing benchmark leakage, including watermarking and licenses for private sets. While our current focus is on Russian, the proposed benchmark provides a replicable methodology for constructing multimodal benchmarks in typologically diverse languages, particularly within the Slavic language family.', 'abstract_zh': '多模态大型语言模型（MLLMs）目前是研究的中心，展示了在规模和能力上的快速进步，但它们的智能、局限性和风险仍不够了解。为此，特别是在目前俄语缺乏多模态基准的情况下，我们引入了Mera Multi，一个用于俄语架构的开放多模态评估框架。该基准以指令为基础，涵盖了默认的文字、图像、音频和视频模态，包括18项新的评估任务，适用于通用模型和模态特定架构（图像到文本、视频到文本和音频到文本）。我们的贡献包括：(i) 多模态能力的通用分类；(ii) 18个全新的数据集，确保考虑了俄语文化与语言的特定性、统一的提示和指标；(iii) 闭源和开源模型的基线结果；(iv) 防止基准泄露的方法论，包括水印和私有集合的许可证。尽管我们目前的关注点是俄语，但提出的基准提供了一种可复制的方法论，用于构建类型多样的语言的多模态基准，特别是在斯拉夫语族中。', 'title_zh': '俄语架构的多模态评估'}
{'arxiv_id': 'arXiv:2511.15552', 'title': 'Multimodal Evaluation of Russian-language Architectures', 'authors': 'Artem Chervyakov, Ulyana Isaeva, Anton Emelyanov, Artem Safin, Maria Tikhonova, Alexander Kharitonov, Yulia Lyakh, Petr Surovtsev, Denis Shevelev Vildan Saburov, Vasily Konovalov, Elisei Rykov, Ivan Sviridov, Amina Miftakhova, Ilseyar Alimova, Alexander Panchenko, Alexander Kapitanov, Alena Fenogenova', 'link': 'https://arxiv.org/abs/2511.15552', 'abstract': 'Multimodal large language models (MLLMs) are currently at the center of research attention, showing rapid progress in scale and capabilities, yet their intelligence, limitations, and risks remain insufficiently understood. To address these issues, particularly in the context of the Russian language, where no multimodal benchmarks currently exist, we introduce Mera Multi, an open multimodal evaluation framework for Russian-spoken architectures. The benchmark is instruction-based and encompasses default text, image, audio, and video modalities, comprising 18 newly constructed evaluation tasks for both general-purpose models and modality-specific architectures (image-to-text, video-to-text, and audio-to-text). Our contributions include: (i) a universal taxonomy of multimodal abilities; (ii) 18 datasets created entirely from scratch with attention to Russian cultural and linguistic specificity, unified prompts, and metrics; (iii) baseline results for both closed-source and open-source models; (iv) a methodology for preventing benchmark leakage, including watermarking and licenses for private sets. While our current focus is on Russian, the proposed benchmark provides a replicable methodology for constructing multimodal benchmarks in typologically diverse languages, particularly within the Slavic language family.', 'abstract_zh': '多模态大型语言模型（MLLMs）目前是研究的中心，尽管在规模和能力上取得了快速进展，但其智能、局限性和风险仍不够了解。为了解决这些问题，特别是在目前俄语环境中缺乏多模态基准的情况下，我们引入了Mera Multi，一个针对俄语架构的开放多模态评估框架。该基准基于指令，涵盖了文本、图像、音频和视频模态，包含18个全新的评估任务，适用于通用模型和模态专用架构（图像到文本、视频到文本和音频到文本）。我们的贡献包括：（i）一种通用的多模态能力分类法；（ii）18个从头创建的数据集，关注俄罗斯文化与语言的特定性、统一的提示和指标；（iii）闭源和开源模型的基线结果；（iv）防止基准泄露的方法论，包括水印和私有集的许可证。虽然我们当前的重点是俄语，但所提出的基准提供了在类型多样的语言中构建多模态基准的可复制方法论，特别是在斯拉夫语家族语言中。', 'title_zh': '俄语语言架构的多模态评估'}
{'arxiv_id': 'arXiv:2511.15520', 'title': 'Theoretical Closed-loop Stability Bounds for Dynamical System Coupled with Diffusion Policies', 'authors': 'Gabriel Lauzier, Alexandre Girard, François Ferland', 'link': 'https://arxiv.org/abs/2511.15520', 'abstract': 'Diffusion Policy has shown great performance in robotic manipulation tasks under stochastic perturbations, due to its ability to model multimodal action distributions. Nonetheless, its reliance on a computationally expensive reverse-time diffusion (denoising) process, for action inference, makes it challenging to use for real-time applications where quick decision-making is mandatory. This work studies the possibility of conducting the denoising process only partially before executing an action, allowing the plant to evolve according to its dynamics in parallel to the reverse-time diffusion dynamics ongoing on the computer. In a classical diffusion policy setting, the plant dynamics are usually slow and the two dynamical processes are uncoupled. Here, we investigate theoretical bounds on the stability of closed-loop systems using diffusion policies when the plant dynamics and the denoising dynamics are coupled. The contribution of this work gives a framework for faster imitation learning and a metric that yields if a controller will be stable based on the variance of the demonstrations.', 'abstract_zh': '基于扩散政策的半前向去噪过程在机器人 manipulation 任务中的实时应用研究', 'title_zh': '耦合扩散策略的动力系统闭环稳定性理论边界'}
{'arxiv_id': 'arXiv:2511.15552', 'title': 'Multimodal Evaluation of Russian-language Architectures', 'authors': 'Artem Chervyakov, Ulyana Isaeva, Anton Emelyanov, Artem Safin, Maria Tikhonova, Alexander Kharitonov, Yulia Lyakh, Petr Surovtsev, Denis Shevelev Vildan Saburov, Vasily Konovalov, Elisei Rykov, Ivan Sviridov, Amina Miftakhova, Ilseyar Alimova, Alexander Panchenko, Alexander Kapitanov, Alena Fenogenova', 'link': 'https://arxiv.org/abs/2511.15552', 'abstract': 'Multimodal large language models (MLLMs) are currently at the center of research attention, showing rapid progress in scale and capabilities, yet their intelligence, limitations, and risks remain insufficiently understood. To address these issues, particularly in the context of the Russian language, where no multimodal benchmarks currently exist, we introduce Mera Multi, an open multimodal evaluation framework for Russian-spoken architectures. The benchmark is instruction-based and encompasses default text, image, audio, and video modalities, comprising 18 newly constructed evaluation tasks for both general-purpose models and modality-specific architectures (image-to-text, video-to-text, and audio-to-text). Our contributions include: (i) a universal taxonomy of multimodal abilities; (ii) 18 datasets created entirely from scratch with attention to Russian cultural and linguistic specificity, unified prompts, and metrics; (iii) baseline results for both closed-source and open-source models; (iv) a methodology for preventing benchmark leakage, including watermarking and licenses for private sets. While our current focus is on Russian, the proposed benchmark provides a replicable methodology for constructing multimodal benchmarks in typologically diverse languages, particularly within the Slavic language family.', 'abstract_zh': '多模态大规模语言模型（MLLMs）目前是研究焦点，显示出在规模和能力上的迅速进展，但其智能性、限制和风险仍不够了解。为应对这些问题，特别是在目前俄语领域缺乏多模态基准的情况下，我们引入了Mera Multi，一个针对俄语架构的开放多模态评估框架。该基准基于指令，包括默认的文字、图像、音频和视频模态，共有18项新的评估任务，适用于通用模型和模态特定架构（图像到文本、视频到文本和音频到文本）。我们的贡献包括：(i) 一个多模态能力的通用分类学；(ii) 18个从零开始创建的数据集，注意俄语文化与语言的特殊性，统一的提示和评估指标；(iii) 专源和开源模型的基线结果；(iv) 防止基准泄漏的方法，包括水印和私有集的许可证。虽然我们的当前重点是俄语，但所提出的基准为在不同类型的语言中构建多模态基准提供了可复制的方法，特别是斯拉夫语族语言。', 'title_zh': '俄语架构的多模态评估'}
{'arxiv_id': 'arXiv:2511.15496', 'title': 'Evaluating Low-Light Image Enhancement Across Multiple Intensity Levels', 'authors': 'Maria Pilligua, David Serrano-Lozano, Pai Peng, Ramon Baldrich, Michael S. Brown, Javier Vazquez-Corral', 'link': 'https://arxiv.org/abs/2511.15496', 'abstract': 'Imaging in low-light environments is challenging due to reduced scene radiance, which leads to elevated sensor noise and reduced color saturation. Most learning-based low-light enhancement methods rely on paired training data captured under a single low-light condition and a well-lit reference. The lack of radiance diversity limits our understanding of how enhancement techniques perform across varying illumination intensities. We introduce the Multi-Illumination Low-Light (MILL) dataset, containing images captured at diverse light intensities under controlled conditions with fixed camera settings and precise illuminance measurements. MILL enables comprehensive evaluation of enhancement algorithms across variable lighting conditions. We benchmark several state-of-the-art methods and reveal significant performance variations across intensity levels. Leveraging the unique multi-illumination structure of our dataset, we propose improvements that enhance robustness across diverse illumination scenarios. Our modifications achieve up to 10 dB PSNR improvement for DSLR and 2 dB for the smartphone on Full HD images.', 'abstract_zh': '多照明条件低光环境成像数据集（MILL）及增强方法评估', 'title_zh': '多强度级别下低光照图像增强评价'}
{'arxiv_id': 'arXiv:2511.15520', 'title': 'Theoretical Closed-loop Stability Bounds for Dynamical System Coupled with Diffusion Policies', 'authors': 'Gabriel Lauzier, Alexandre Girard, François Ferland', 'link': 'https://arxiv.org/abs/2511.15520', 'abstract': 'Diffusion Policy has shown great performance in robotic manipulation tasks under stochastic perturbations, due to its ability to model multimodal action distributions. Nonetheless, its reliance on a computationally expensive reverse-time diffusion (denoising) process, for action inference, makes it challenging to use for real-time applications where quick decision-making is mandatory. This work studies the possibility of conducting the denoising process only partially before executing an action, allowing the plant to evolve according to its dynamics in parallel to the reverse-time diffusion dynamics ongoing on the computer. In a classical diffusion policy setting, the plant dynamics are usually slow and the two dynamical processes are uncoupled. Here, we investigate theoretical bounds on the stability of closed-loop systems using diffusion policies when the plant dynamics and the denoising dynamics are coupled. The contribution of this work gives a framework for faster imitation learning and a metric that yields if a controller will be stable based on the variance of the demonstrations.', 'abstract_zh': '扩散政策在随机扰动下的机器人操纵任务中表现出色，得益于其能够建模多模态动作分布的能力。然而，其依赖于在进行动作推断时需要进行昂贵的反向时间扩散（去噪）过程，这使其难以应用于要求快速决策的实时应用中。本工作研究了在执行动作之前仅部分进行去噪过程的可能性，使得在计算机上进行反向时间扩散的同时，机器人按照其动态演化。在经典的扩散政策设置中，通常植物动力学较慢且两种动力学过程是解耦的。本工作调查了当植物动力学和去噪动力学耦合时，使用扩散政策的闭环系统稳定性理论界。本工作的贡献提供了更快的模仿学习框架以及一个基于演示数据的方差能够判断控制器是否稳定的度量标准。', 'title_zh': '耦合了扩散策略的动力系统闭环稳定性理论界值'}
{'arxiv_id': 'arXiv:2511.15520', 'title': 'Theoretical Closed-loop Stability Bounds for Dynamical System Coupled with Diffusion Policies', 'authors': 'Gabriel Lauzier, Alexandre Girard, François Ferland', 'link': 'https://arxiv.org/abs/2511.15520', 'abstract': 'Diffusion Policy has shown great performance in robotic manipulation tasks under stochastic perturbations, due to its ability to model multimodal action distributions. Nonetheless, its reliance on a computationally expensive reverse-time diffusion (denoising) process, for action inference, makes it challenging to use for real-time applications where quick decision-making is mandatory. This work studies the possibility of conducting the denoising process only partially before executing an action, allowing the plant to evolve according to its dynamics in parallel to the reverse-time diffusion dynamics ongoing on the computer. In a classical diffusion policy setting, the plant dynamics are usually slow and the two dynamical processes are uncoupled. Here, we investigate theoretical bounds on the stability of closed-loop systems using diffusion policies when the plant dynamics and the denoising dynamics are coupled. The contribution of this work gives a framework for faster imitation learning and a metric that yields if a controller will be stable based on the variance of the demonstrations.', 'abstract_zh': '扩散策略在随机扰动下的机器人 manipulation 任务中表现出色，得益于其能够建模多模态动作分布的能力。然而，其依赖于计算成本高昂的逆时扩散（去噪）过程，用于动作推断，这使其难以应用于要求快速决策的实时应用。本文研究了在执行动作之前仅部分进行去噪过程的可能性，允许执行动作的系统根据其动力学与计算机上的逆时扩散动力学并行演化。在传统的扩散策略设置中，系统动力学通常较慢且两者不耦合。本文探讨了当系统动力学和去噪动力学耦合时，使用扩散策略的闭环系统稳定性理论界。本文的贡献提供了一种更快速的模仿学习框架以及一个基于示范方差的稳定性评估指标。', 'title_zh': '带有扩散策略耦合的动力系统闭环稳定性理论界值'}
{'arxiv_id': 'arXiv:2511.15476', 'title': 'RS-CA-HSICT: A Residual and Spatial Channel Augmented CNN Transformer Framework for Monkeypox Detection', 'authors': 'Rashid Iqbal, Saddam Hussain Khan', 'link': 'https://arxiv.org/abs/2511.15476', 'abstract': 'This work proposes a hybrid deep learning approach, namely Residual and Spatial Learning based Channel Augmented Integrated CNN-Transformer architecture, that leverages the strengths of CNN and Transformer towards enhanced MPox detection. The proposed RS-CA-HSICT framework is composed of an HSICT block, a residual CNN module, a spatial CNN block, and a CA, which enhances the diverse feature space, detailed lesion information, and long-range dependencies. The new HSICT module first integrates an abstract representation of the stem CNN and customized ICT blocks for efficient multihead attention and structured CNN layers with homogeneous (H) and structural (S) operations. The customized ICT blocks learn global contextual interactions and local texture extraction. Additionally, H and S layers learn spatial homogeneity and fine structural details by reducing noise and modeling complex morphological variations. Moreover, inverse residual learning enhances vanishing gradient, and stage-wise resolution reduction ensures scale invariance. Furthermore, the RS-CA-HSICT framework augments the learned HSICT channels with the TL-driven Residual and Spatial CNN maps for enhanced multiscale feature space capturing global and localized structural cues, subtle texture, and contrast variations. These channels, preceding augmentation, are refined through the Channel-Fusion-and-Attention block, which preserves discriminative channels while suppressing redundant ones, thereby enabling efficient computation. Finally, the spatial attention mechanism refines pixel selection to detect subtle patterns and intra-class contrast variations in Mpox. Experimental results on both the Kaggle benchmark and a diverse MPox dataset reported classification accuracy as high as 98.30% and an F1-score of 98.13%, which outperforms the existing CNNs and ViTs.', 'abstract_zh': '基于残差和空间学习的残差和空间增强卷积-变换子综合架构：增强MPox检测的混合深度学习方法', 'title_zh': 'RS-CA-HSICT：一种基于残差和空间通道增强的CNN变换器框架用于猴痘检测'}
{'arxiv_id': 'arXiv:2511.15496', 'title': 'Evaluating Low-Light Image Enhancement Across Multiple Intensity Levels', 'authors': 'Maria Pilligua, David Serrano-Lozano, Pai Peng, Ramon Baldrich, Michael S. Brown, Javier Vazquez-Corral', 'link': 'https://arxiv.org/abs/2511.15496', 'abstract': 'Imaging in low-light environments is challenging due to reduced scene radiance, which leads to elevated sensor noise and reduced color saturation. Most learning-based low-light enhancement methods rely on paired training data captured under a single low-light condition and a well-lit reference. The lack of radiance diversity limits our understanding of how enhancement techniques perform across varying illumination intensities. We introduce the Multi-Illumination Low-Light (MILL) dataset, containing images captured at diverse light intensities under controlled conditions with fixed camera settings and precise illuminance measurements. MILL enables comprehensive evaluation of enhancement algorithms across variable lighting conditions. We benchmark several state-of-the-art methods and reveal significant performance variations across intensity levels. Leveraging the unique multi-illumination structure of our dataset, we propose improvements that enhance robustness across diverse illumination scenarios. Our modifications achieve up to 10 dB PSNR improvement for DSLR and 2 dB for the smartphone on Full HD images.', 'abstract_zh': '低光照环境下成像具有挑战性，因为场景辐射度降低，导致传感器噪声增加和色彩饱和度降低。大多数基于学习的低光照增强方法依赖于在单一低光照条件和良好照明参考下获取的配对训练数据。光线辐射度的缺乏限制了我们对面板在不同 illumination 强度下的表现的理解。我们引入了多光照低光照(Multi-Illumination Low-Light, MILL)数据集，该数据集包含在固定相机设置和精确照度测量下，在不同光照强度下的图像。MILL 允许在多种照明条件下对增强算法进行全面评估。我们 benchmark 了几种最先进的方法，并揭示了不同强度水平下的显著性能变化。利用我们数据集的独特多光照结构，我们提出改进措施，以增强在不同光照场景下的鲁棒性。我们的修改在全高清图象中实现了高达 10 dB 的 PSNR 提升，对于智能手机则为 2 dB。', 'title_zh': '多强度级别低光照图像增强评价'}
{'arxiv_id': 'arXiv:2511.15496', 'title': 'Evaluating Low-Light Image Enhancement Across Multiple Intensity Levels', 'authors': 'Maria Pilligua, David Serrano-Lozano, Pai Peng, Ramon Baldrich, Michael S. Brown, Javier Vazquez-Corral', 'link': 'https://arxiv.org/abs/2511.15496', 'abstract': 'Imaging in low-light environments is challenging due to reduced scene radiance, which leads to elevated sensor noise and reduced color saturation. Most learning-based low-light enhancement methods rely on paired training data captured under a single low-light condition and a well-lit reference. The lack of radiance diversity limits our understanding of how enhancement techniques perform across varying illumination intensities. We introduce the Multi-Illumination Low-Light (MILL) dataset, containing images captured at diverse light intensities under controlled conditions with fixed camera settings and precise illuminance measurements. MILL enables comprehensive evaluation of enhancement algorithms across variable lighting conditions. We benchmark several state-of-the-art methods and reveal significant performance variations across intensity levels. Leveraging the unique multi-illumination structure of our dataset, we propose improvements that enhance robustness across diverse illumination scenarios. Our modifications achieve up to 10 dB PSNR improvement for DSLR and 2 dB for the smartphone on Full HD images.', 'abstract_zh': '多光照条件低光环境成像数据集（MILL）及其在低光增强中的应用', 'title_zh': '多强度等级下低光照图像增强的评估'}
{'arxiv_id': 'arXiv:2511.15462', 'title': 'Insights from the ICLR Peer Review and Rebuttal Process', 'authors': 'Amir Hossein Kargaran, Nafiseh Nikeghbal, Jing Yang, Nedjma Ousidhoum', 'link': 'https://arxiv.org/abs/2511.15462', 'abstract': 'Peer review is a cornerstone of scientific publishing, including at premier machine learning conferences such as ICLR. As submission volumes increase, understanding the nature and dynamics of the review process is crucial for improving its efficiency, effectiveness, and the quality of published papers. We present a large-scale analysis of the ICLR 2024 and 2025 peer review processes, focusing on before- and after-rebuttal scores and reviewer-author interactions. We examine review scores, author-reviewer engagement, temporal patterns in review submissions, and co-reviewer influence effects. Combining quantitative analyses with LLM-based categorization of review texts and rebuttal discussions, we identify common strengths and weaknesses for each rating group, as well as trends in rebuttal strategies that are most strongly associated with score changes. Our findings show that initial scores and the ratings of co-reviewers are the strongest predictors of score changes during the rebuttal, pointing to a degree of reviewer influence. Rebuttals play a valuable role in improving outcomes for borderline papers, where thoughtful author responses can meaningfully shift reviewer perspectives. More broadly, our study offers evidence-based insights to improve the peer review process, guiding authors on effective rebuttal strategies and helping the community design fairer and more efficient review processes. Our code and score changes data are available at this https URL.', 'abstract_zh': 'ICLR 2024和2025年度同行评审过程的大型分析：聚焦于复查前后的评分及评审员-作者互动', 'title_zh': 'ICLR同行评审和反驳过程的见解'}
{'arxiv_id': 'arXiv:2511.15476', 'title': 'RS-CA-HSICT: A Residual and Spatial Channel Augmented CNN Transformer Framework for Monkeypox Detection', 'authors': 'Rashid Iqbal, Saddam Hussain Khan', 'link': 'https://arxiv.org/abs/2511.15476', 'abstract': 'This work proposes a hybrid deep learning approach, namely Residual and Spatial Learning based Channel Augmented Integrated CNN-Transformer architecture, that leverages the strengths of CNN and Transformer towards enhanced MPox detection. The proposed RS-CA-HSICT framework is composed of an HSICT block, a residual CNN module, a spatial CNN block, and a CA, which enhances the diverse feature space, detailed lesion information, and long-range dependencies. The new HSICT module first integrates an abstract representation of the stem CNN and customized ICT blocks for efficient multihead attention and structured CNN layers with homogeneous (H) and structural (S) operations. The customized ICT blocks learn global contextual interactions and local texture extraction. Additionally, H and S layers learn spatial homogeneity and fine structural details by reducing noise and modeling complex morphological variations. Moreover, inverse residual learning enhances vanishing gradient, and stage-wise resolution reduction ensures scale invariance. Furthermore, the RS-CA-HSICT framework augments the learned HSICT channels with the TL-driven Residual and Spatial CNN maps for enhanced multiscale feature space capturing global and localized structural cues, subtle texture, and contrast variations. These channels, preceding augmentation, are refined through the Channel-Fusion-and-Attention block, which preserves discriminative channels while suppressing redundant ones, thereby enabling efficient computation. Finally, the spatial attention mechanism refines pixel selection to detect subtle patterns and intra-class contrast variations in Mpox. Experimental results on both the Kaggle benchmark and a diverse MPox dataset reported classification accuracy as high as 98.30% and an F1-score of 98.13%, which outperforms the existing CNNs and ViTs.', 'abstract_zh': '基于残差和空间学习的通道增强CNN-Transformer架构：结合残差和空间学习的MPox检测混合深度学习方法', 'title_zh': 'RS-CA-HSICT: 一种残差和空间通道增强的CNN变压器框架用于猴痘检测'}
{'arxiv_id': 'arXiv:2511.15476', 'title': 'RS-CA-HSICT: A Residual and Spatial Channel Augmented CNN Transformer Framework for Monkeypox Detection', 'authors': 'Rashid Iqbal, Saddam Hussain Khan', 'link': 'https://arxiv.org/abs/2511.15476', 'abstract': 'This work proposes a hybrid deep learning approach, namely Residual and Spatial Learning based Channel Augmented Integrated CNN-Transformer architecture, that leverages the strengths of CNN and Transformer towards enhanced MPox detection. The proposed RS-CA-HSICT framework is composed of an HSICT block, a residual CNN module, a spatial CNN block, and a CA, which enhances the diverse feature space, detailed lesion information, and long-range dependencies. The new HSICT module first integrates an abstract representation of the stem CNN and customized ICT blocks for efficient multihead attention and structured CNN layers with homogeneous (H) and structural (S) operations. The customized ICT blocks learn global contextual interactions and local texture extraction. Additionally, H and S layers learn spatial homogeneity and fine structural details by reducing noise and modeling complex morphological variations. Moreover, inverse residual learning enhances vanishing gradient, and stage-wise resolution reduction ensures scale invariance. Furthermore, the RS-CA-HSICT framework augments the learned HSICT channels with the TL-driven Residual and Spatial CNN maps for enhanced multiscale feature space capturing global and localized structural cues, subtle texture, and contrast variations. These channels, preceding augmentation, are refined through the Channel-Fusion-and-Attention block, which preserves discriminative channels while suppressing redundant ones, thereby enabling efficient computation. Finally, the spatial attention mechanism refines pixel selection to detect subtle patterns and intra-class contrast variations in Mpox. Experimental results on both the Kaggle benchmark and a diverse MPox dataset reported classification accuracy as high as 98.30% and an F1-score of 98.13%, which outperforms the existing CNNs and ViTs.', 'abstract_zh': '基于残差和空间学习的通道增强集成CNN-Transformer架构：Residual and Spatial Learning Based Channel Augmented Integrated CNN-Transformer Architecture for Enhanced MPox检测', 'title_zh': 'RS-CA-HSICT: 一种残差和空间通道增强的CNN变换器框架用于猴痘检测'}
{'arxiv_id': 'arXiv:2511.15462', 'title': 'Insights from the ICLR Peer Review and Rebuttal Process', 'authors': 'Amir Hossein Kargaran, Nafiseh Nikeghbal, Jing Yang, Nedjma Ousidhoum', 'link': 'https://arxiv.org/abs/2511.15462', 'abstract': 'Peer review is a cornerstone of scientific publishing, including at premier machine learning conferences such as ICLR. As submission volumes increase, understanding the nature and dynamics of the review process is crucial for improving its efficiency, effectiveness, and the quality of published papers. We present a large-scale analysis of the ICLR 2024 and 2025 peer review processes, focusing on before- and after-rebuttal scores and reviewer-author interactions. We examine review scores, author-reviewer engagement, temporal patterns in review submissions, and co-reviewer influence effects. Combining quantitative analyses with LLM-based categorization of review texts and rebuttal discussions, we identify common strengths and weaknesses for each rating group, as well as trends in rebuttal strategies that are most strongly associated with score changes. Our findings show that initial scores and the ratings of co-reviewers are the strongest predictors of score changes during the rebuttal, pointing to a degree of reviewer influence. Rebuttals play a valuable role in improving outcomes for borderline papers, where thoughtful author responses can meaningfully shift reviewer perspectives. More broadly, our study offers evidence-based insights to improve the peer review process, guiding authors on effective rebuttal strategies and helping the community design fairer and more efficient review processes. Our code and score changes data are available at this https URL.', 'abstract_zh': 'ICLR 2024和2025年审稿过程的大规模分析：从初始评分到复审的动态与影响', 'title_zh': 'ICLR同行评审及 rebuttal 过程 Insights from the ICLR Peer Review and Rebuttal Process'}
{'arxiv_id': 'arXiv:2511.15462', 'title': 'Insights from the ICLR Peer Review and Rebuttal Process', 'authors': 'Amir Hossein Kargaran, Nafiseh Nikeghbal, Jing Yang, Nedjma Ousidhoum', 'link': 'https://arxiv.org/abs/2511.15462', 'abstract': 'Peer review is a cornerstone of scientific publishing, including at premier machine learning conferences such as ICLR. As submission volumes increase, understanding the nature and dynamics of the review process is crucial for improving its efficiency, effectiveness, and the quality of published papers. We present a large-scale analysis of the ICLR 2024 and 2025 peer review processes, focusing on before- and after-rebuttal scores and reviewer-author interactions. We examine review scores, author-reviewer engagement, temporal patterns in review submissions, and co-reviewer influence effects. Combining quantitative analyses with LLM-based categorization of review texts and rebuttal discussions, we identify common strengths and weaknesses for each rating group, as well as trends in rebuttal strategies that are most strongly associated with score changes. Our findings show that initial scores and the ratings of co-reviewers are the strongest predictors of score changes during the rebuttal, pointing to a degree of reviewer influence. Rebuttals play a valuable role in improving outcomes for borderline papers, where thoughtful author responses can meaningfully shift reviewer perspectives. More broadly, our study offers evidence-based insights to improve the peer review process, guiding authors on effective rebuttal strategies and helping the community design fairer and more efficient review processes. Our code and score changes data are available at this https URL.', 'abstract_zh': 'ICLR 2024和2025年同行评审过程的大规模分析：重点在于评论前后的评分及评论者-作者互动', 'title_zh': 'ICLR同行评审和反驳过程的见解'}
{'arxiv_id': 'arXiv:2511.15447', 'title': 'TSFM in-context learning for time-series classification of bearing-health status', 'authors': 'Michel Tokic, Slobodan Djukanović, Anja von Beuningen, Cheng Feng', 'link': 'https://arxiv.org/abs/2511.15447', 'abstract': 'This paper introduces a classification method using in-context learning in time-series foundation models (TSFM). We show how data, which was not part of the TSFM training data corpus, can be classified without the need of finetuning the model. Examples are represented in the form of targets (class id) and covariates (data matrix) within the prompt of the model, which enables to classify an unknown covariate data pattern alongside the forecast axis through in-context learning. We apply this method to vibration data for assessing the health state of a bearing within a servo-press motor. The method transforms frequency domain reference signals into pseudo time-series patterns, generates aligned covariate and target signals, and uses the TSFM to predict probabilities how classified data corresponds to predefined labels. Leveraging the scalability of pre-trained models this method demonstrates efficacy across varied operational conditions. This marks significant progress beyond custom narrow AI solutions towards broader, AI-driven maintenance systems.', 'abstract_zh': '本研究介绍了一种使用上下文学习的方法，在时间序列基础模型中进行分类，无需微调模型即可对不属于模型训练数据集的新数据进行分类。通过在模型提示中以目标（类别ID）和协变量（数据矩阵）的形式表示示例，利用上下文学习可以在预测轴上同时对未知的协变量数据模式进行分类。该方法应用于伺服冲压电机轴承健康状态评估，将频域参考信号转换为伪时间序列模式，生成对齐的协变量和目标信号，并使用时间序列基础模型预测分类数据与预定义标签的匹配概率。借助预训练模型的可扩展性，该方法在多种运行条件下展示了有效性，标志着向更广泛的人工智能驱动维护系统的重要进展。', 'title_zh': 'TSFM基于上下文的学习方法用于轴承健康状态的时间序列分类'}
{'arxiv_id': 'arXiv:2511.15447', 'title': 'TSFM in-context learning for time-series classification of bearing-health status', 'authors': 'Michel Tokic, Slobodan Djukanović, Anja von Beuningen, Cheng Feng', 'link': 'https://arxiv.org/abs/2511.15447', 'abstract': 'This paper introduces a classification method using in-context learning in time-series foundation models (TSFM). We show how data, which was not part of the TSFM training data corpus, can be classified without the need of finetuning the model. Examples are represented in the form of targets (class id) and covariates (data matrix) within the prompt of the model, which enables to classify an unknown covariate data pattern alongside the forecast axis through in-context learning. We apply this method to vibration data for assessing the health state of a bearing within a servo-press motor. The method transforms frequency domain reference signals into pseudo time-series patterns, generates aligned covariate and target signals, and uses the TSFM to predict probabilities how classified data corresponds to predefined labels. Leveraging the scalability of pre-trained models this method demonstrates efficacy across varied operational conditions. This marks significant progress beyond custom narrow AI solutions towards broader, AI-driven maintenance systems.', 'abstract_zh': '利用上下文学习在时间序列基础模型中的分类方法：基于伺服压铸机轴承振动数据的健康状态评估', 'title_zh': 'TSFM基于上下文的学习在滚动轴承健康状态时间序列分类中的应用'}
{'arxiv_id': 'arXiv:2511.15447', 'title': 'TSFM in-context learning for time-series classification of bearing-health status', 'authors': 'Michel Tokic, Slobodan Djukanović, Anja von Beuningen, Cheng Feng', 'link': 'https://arxiv.org/abs/2511.15447', 'abstract': 'This paper introduces a classification method using in-context learning in time-series foundation models (TSFM). We show how data, which was not part of the TSFM training data corpus, can be classified without the need of finetuning the model. Examples are represented in the form of targets (class id) and covariates (data matrix) within the prompt of the model, which enables to classify an unknown covariate data pattern alongside the forecast axis through in-context learning. We apply this method to vibration data for assessing the health state of a bearing within a servo-press motor. The method transforms frequency domain reference signals into pseudo time-series patterns, generates aligned covariate and target signals, and uses the TSFM to predict probabilities how classified data corresponds to predefined labels. Leveraging the scalability of pre-trained models this method demonstrates efficacy across varied operational conditions. This marks significant progress beyond custom narrow AI solutions towards broader, AI-driven maintenance systems.', 'abstract_zh': '本文介绍了一种使用上下文学习进行时序基础模型（TSFM）分类的方法，展示了如何在无需微调模型的情况下对未包含在TSFM训练数据集中的数据进行分类。通过将数据表示为目标（类别标识）和协变量（数据矩阵）的形式嵌入模型提示中，该方法能够在预测轴上通过上下文学习对未知协变量数据模式进行分类。该方法应用于评估伺服压力电机中轴承的健康状态，通过将频率域参考信号转换为伪时序模式，生成对齐的协变量和目标信号，并利用TSFM预测分类数据与预定义标签的匹配概率。利用预训练模型的可扩展性，该方法在各种运行条件下都显示出有效性，标志着朝着更广泛的人工智能驱动维护系统的重要进步。', 'title_zh': 'TSFM 在上下文学习中对轴承健康状态时间序列分类的应用'}
{'arxiv_id': 'arXiv:2511.15435', 'title': 'HV-Attack: Hierarchical Visual Attack for Multimodal Retrieval Augmented Generation', 'authors': 'Linyin Luo, Yujuan Ding, Yunshan Ma, Wenqi Fan, Hanjiang Lai', 'link': 'https://arxiv.org/abs/2511.15435', 'abstract': "Advanced multimodal Retrieval-Augmented Generation (MRAG) techniques have been widely applied to enhance the capabilities of Large Multimodal Models (LMMs), but they also bring along novel safety issues. Existing adversarial research has revealed the vulnerability of MRAG systems to knowledge poisoning attacks, which fool the retriever into recalling injected poisoned contents. However, our work considers a different setting: visual attack of MRAG by solely adding imperceptible perturbations at the image inputs of users, without manipulating any other components. This is challenging due to the robustness of fine-tuned retrievers and large-scale generators, and the effect of visual perturbation may be further weakened by propagation through the RAG chain. We propose a novel Hierarchical Visual Attack that misaligns and disrupts the two inputs (the multimodal query and the augmented knowledge) of MRAG's generator to confuse its generation. We further design a hierarchical two-stage strategy to obtain misaligned augmented knowledge. We disrupt the image input of the retriever to make it recall irrelevant knowledge from the original database, by optimizing the perturbation which first breaks the cross-modal alignment and then disrupts the multimodal semantic alignment. We conduct extensive experiments on two widely-used MRAG datasets: OK-VQA and InfoSeek. We use CLIP-based retrievers and two LMMs BLIP-2 and LLaVA as generators. Results demonstrate the effectiveness of our visual attack on MRAG through the significant decrease in both retrieval and generation performance.", 'abstract_zh': '高级多模态检索增强生成（MRAG）技术在增强大型多模态模型（LMMs）能力的同时带来了新型安全问题', 'title_zh': 'HV-攻击：多层次视觉攻击促进多模态检索增强生成'}
{'arxiv_id': 'arXiv:2511.15435', 'title': 'HV-Attack: Hierarchical Visual Attack for Multimodal Retrieval Augmented Generation', 'authors': 'Linyin Luo, Yujuan Ding, Yunshan Ma, Wenqi Fan, Hanjiang Lai', 'link': 'https://arxiv.org/abs/2511.15435', 'abstract': "Advanced multimodal Retrieval-Augmented Generation (MRAG) techniques have been widely applied to enhance the capabilities of Large Multimodal Models (LMMs), but they also bring along novel safety issues. Existing adversarial research has revealed the vulnerability of MRAG systems to knowledge poisoning attacks, which fool the retriever into recalling injected poisoned contents. However, our work considers a different setting: visual attack of MRAG by solely adding imperceptible perturbations at the image inputs of users, without manipulating any other components. This is challenging due to the robustness of fine-tuned retrievers and large-scale generators, and the effect of visual perturbation may be further weakened by propagation through the RAG chain. We propose a novel Hierarchical Visual Attack that misaligns and disrupts the two inputs (the multimodal query and the augmented knowledge) of MRAG's generator to confuse its generation. We further design a hierarchical two-stage strategy to obtain misaligned augmented knowledge. We disrupt the image input of the retriever to make it recall irrelevant knowledge from the original database, by optimizing the perturbation which first breaks the cross-modal alignment and then disrupts the multimodal semantic alignment. We conduct extensive experiments on two widely-used MRAG datasets: OK-VQA and InfoSeek. We use CLIP-based retrievers and two LMMs BLIP-2 and LLaVA as generators. Results demonstrate the effectiveness of our visual attack on MRAG through the significant decrease in both retrieval and generation performance.", 'abstract_zh': '高级层次视觉攻击:针对Retrieval-Augmented Generation (MRAG)系统的视觉攻击技术', 'title_zh': 'HV-攻击：多层次视觉攻击以增强多模态检索生成'}
{'arxiv_id': 'arXiv:2511.15434', 'title': 'Small Language Models for Phishing Website Detection: Cost, Performance, and Privacy Trade-Offs', 'authors': 'Georg Goldenits, Philip Koenig, Sebastian Raubitzek, Andreas Ekelhart', 'link': 'https://arxiv.org/abs/2511.15434', 'abstract': 'Phishing websites pose a major cybersecurity threat, exploiting unsuspecting users and causing significant financial and organisational harm. Traditional machine learning approaches for phishing detection often require extensive feature engineering, continuous retraining, and costly infrastructure maintenance. At the same time, proprietary large language models (LLMs) have demonstrated strong performance in phishing-related classification tasks, but their operational costs and reliance on external providers limit their practical adoption in many business environments. This paper investigates the feasibility of small language models (SLMs) for detecting phishing websites using only their raw HTML code. A key advantage of these models is that they can be deployed on local infrastructure, providing organisations with greater control over data and operations. We systematically evaluate 15 commonly used Small Language Models (SLMs), ranging from 1 billion to 70 billion parameters, benchmarking their classification accuracy, computational requirements, and cost-efficiency. Our results highlight the trade-offs between detection performance and resource consumption, demonstrating that while SLMs underperform compared to state-of-the-art proprietary LLMs, they can still provide a viable and scalable alternative to external LLM services. By presenting a comparative analysis of costs and benefits, this work lays the foundation for future research on the adaptation, fine-tuning, and deployment of SLMs in phishing detection systems, aiming to balance security effectiveness and economic practicality.', 'abstract_zh': '小语言模型在仅使用原始HTML代码检测钓鱼网站中的可行性研究', 'title_zh': '小型语言模型在钓鱼网站检测中的权衡：成本、性能与隐私trade-offs'}
{'arxiv_id': 'arXiv:2511.15435', 'title': 'HV-Attack: Hierarchical Visual Attack for Multimodal Retrieval Augmented Generation', 'authors': 'Linyin Luo, Yujuan Ding, Yunshan Ma, Wenqi Fan, Hanjiang Lai', 'link': 'https://arxiv.org/abs/2511.15435', 'abstract': "Advanced multimodal Retrieval-Augmented Generation (MRAG) techniques have been widely applied to enhance the capabilities of Large Multimodal Models (LMMs), but they also bring along novel safety issues. Existing adversarial research has revealed the vulnerability of MRAG systems to knowledge poisoning attacks, which fool the retriever into recalling injected poisoned contents. However, our work considers a different setting: visual attack of MRAG by solely adding imperceptible perturbations at the image inputs of users, without manipulating any other components. This is challenging due to the robustness of fine-tuned retrievers and large-scale generators, and the effect of visual perturbation may be further weakened by propagation through the RAG chain. We propose a novel Hierarchical Visual Attack that misaligns and disrupts the two inputs (the multimodal query and the augmented knowledge) of MRAG's generator to confuse its generation. We further design a hierarchical two-stage strategy to obtain misaligned augmented knowledge. We disrupt the image input of the retriever to make it recall irrelevant knowledge from the original database, by optimizing the perturbation which first breaks the cross-modal alignment and then disrupts the multimodal semantic alignment. We conduct extensive experiments on two widely-used MRAG datasets: OK-VQA and InfoSeek. We use CLIP-based retrievers and two LMMs BLIP-2 and LLaVA as generators. Results demonstrate the effectiveness of our visual attack on MRAG through the significant decrease in both retrieval and generation performance.", 'abstract_zh': '高级多模态检索增强生成（MRAG）技术已在增强大型多模态模型（LMMs）能力方面得到了广泛应用，但也带来了新的安全问题。现有的对抗性研究揭示了MRAG系统对知识投毒攻击的脆弱性，这种攻击能使检索模块召回注入的污染内容。然而，我们的工作考虑了一个不同的场景：仅通过在用户输入的图像中添加不可感知的扰动来对MRAG进行视觉攻击，而不操纵其他任何组件。这由于微调后的检索模块和大规模生成器的鲁棒性而更具挑战性，视觉扰动的效果可能在RAG链传播过程中进一步减弱。我们提出了一种新的分层视觉攻击，它使MRAG生成器的两个输入（多模态查询和增强知识）错位和中断，以迷惑其生成过程。我们进一步设计了分层两阶段策略来获得错位的增强知识。通过优化首先破坏跨模态对齐然后破坏多模态语义对齐的扰动，干扰检索模块使其召回原始数据库中的无关知识。我们在两个广泛使用的MRAG数据集OK-VQA和InfoSeek上进行了广泛实验。我们使用基于CLIP的检索模块和两个生成器BLIP-2和LLaVA。实验结果证明了我们视觉攻击在MRAG上的有效性，表现为检索和生成性能显著下降。', 'title_zh': 'HV-攻击：多模态检索增强生成的分层视觉攻击'}
{'arxiv_id': 'arXiv:2511.15434', 'title': 'Small Language Models for Phishing Website Detection: Cost, Performance, and Privacy Trade-Offs', 'authors': 'Georg Goldenits, Philip Koenig, Sebastian Raubitzek, Andreas Ekelhart', 'link': 'https://arxiv.org/abs/2511.15434', 'abstract': 'Phishing websites pose a major cybersecurity threat, exploiting unsuspecting users and causing significant financial and organisational harm. Traditional machine learning approaches for phishing detection often require extensive feature engineering, continuous retraining, and costly infrastructure maintenance. At the same time, proprietary large language models (LLMs) have demonstrated strong performance in phishing-related classification tasks, but their operational costs and reliance on external providers limit their practical adoption in many business environments. This paper investigates the feasibility of small language models (SLMs) for detecting phishing websites using only their raw HTML code. A key advantage of these models is that they can be deployed on local infrastructure, providing organisations with greater control over data and operations. We systematically evaluate 15 commonly used Small Language Models (SLMs), ranging from 1 billion to 70 billion parameters, benchmarking their classification accuracy, computational requirements, and cost-efficiency. Our results highlight the trade-offs between detection performance and resource consumption, demonstrating that while SLMs underperform compared to state-of-the-art proprietary LLMs, they can still provide a viable and scalable alternative to external LLM services. By presenting a comparative analysis of costs and benefits, this work lays the foundation for future research on the adaptation, fine-tuning, and deployment of SLMs in phishing detection systems, aiming to balance security effectiveness and economic practicality.', 'abstract_zh': '小型语言模型在仅使用原始HTML代码检测钓鱼网站中的可行性研究', 'title_zh': '小型语言模型在钓鱼网站检测中的成本、性能与隐私权衡'}
{'arxiv_id': 'arXiv:2511.15434', 'title': 'Small Language Models for Phishing Website Detection: Cost, Performance, and Privacy Trade-Offs', 'authors': 'Georg Goldenits, Philip Koenig, Sebastian Raubitzek, Andreas Ekelhart', 'link': 'https://arxiv.org/abs/2511.15434', 'abstract': 'Phishing websites pose a major cybersecurity threat, exploiting unsuspecting users and causing significant financial and organisational harm. Traditional machine learning approaches for phishing detection often require extensive feature engineering, continuous retraining, and costly infrastructure maintenance. At the same time, proprietary large language models (LLMs) have demonstrated strong performance in phishing-related classification tasks, but their operational costs and reliance on external providers limit their practical adoption in many business environments. This paper investigates the feasibility of small language models (SLMs) for detecting phishing websites using only their raw HTML code. A key advantage of these models is that they can be deployed on local infrastructure, providing organisations with greater control over data and operations. We systematically evaluate 15 commonly used Small Language Models (SLMs), ranging from 1 billion to 70 billion parameters, benchmarking their classification accuracy, computational requirements, and cost-efficiency. Our results highlight the trade-offs between detection performance and resource consumption, demonstrating that while SLMs underperform compared to state-of-the-art proprietary LLMs, they can still provide a viable and scalable alternative to external LLM services. By presenting a comparative analysis of costs and benefits, this work lays the foundation for future research on the adaptation, fine-tuning, and deployment of SLMs in phishing detection systems, aiming to balance security effectiveness and economic practicality.', 'abstract_zh': '小型语言模型在仅使用原始HTML代码检测钓鱼网站中的可行性研究', 'title_zh': '小型语言模型在钓鱼网站检测中的成本、性能与隐私权衡'}
{'arxiv_id': 'arXiv:2511.15432', 'title': 'Towards Understanding Layer Contributions in Tabular In-Context Learning Models', 'authors': 'Amir Rezaei Balef, Mykhailo Koshil, Katharina Eggensperger', 'link': 'https://arxiv.org/abs/2511.15432', 'abstract': 'Despite the architectural similarities between tabular in-context learning (ICL) models and large language models (LLMs), little is known about how individual layers contribute to tabular prediction. In this paper, we investigate how the latent spaces evolve across layers in tabular ICL models, identify potential redundant layers, and compare these dynamics with those observed in LLMs. We analyze TabPFN and TabICL through the "layers as painters" perspective, finding that only subsets of layers share a common representational language, suggesting structural redundancy and offering opportunities for model compression and improved interpretability.', 'abstract_zh': '尽管表格内省学习（ICL）模型和大型语言模型（LLMs）在架构上存在相似性，但关于单个层如何贡献于表格预测的知识仍然很少。在本文中，我们探讨了表格ICL模型中潜在空间在其层间的演变，识别潜在的冗余层，并将这些动态与LLMs中观察到的动态进行比较。我们通过“层如画家”的视角分析了TabPFN和TabICL，发现只有部分层共享一种共同的表现语言，这表明结构冗余并提供了模型压缩和增强可解释性的机会。', 'title_zh': '理解表格型上下文学习模型中各层的贡献'}
{'arxiv_id': 'arXiv:2511.15432', 'title': 'Towards Understanding Layer Contributions in Tabular In-Context Learning Models', 'authors': 'Amir Rezaei Balef, Mykhailo Koshil, Katharina Eggensperger', 'link': 'https://arxiv.org/abs/2511.15432', 'abstract': 'Despite the architectural similarities between tabular in-context learning (ICL) models and large language models (LLMs), little is known about how individual layers contribute to tabular prediction. In this paper, we investigate how the latent spaces evolve across layers in tabular ICL models, identify potential redundant layers, and compare these dynamics with those observed in LLMs. We analyze TabPFN and TabICL through the "layers as painters" perspective, finding that only subsets of layers share a common representational language, suggesting structural redundancy and offering opportunities for model compression and improved interpretability.', 'abstract_zh': '尽管表格内省学习（ICL）模型与大型语言模型（LLMs）在架构上存在相似性，但很少有人了解各个层如何贡献于表格预测。在本文中，我们研究表格ICL模型中潜空间在整个层中的演变，识别潜在的冗余层，并将这些动态与LLMs中观察到的动态进行比较。我们从“层如画家”的视角分析了TabPFN和TabICL，发现只有部分层共享一种共同的表现语言，这表明结构冗余并提供了模型压缩和增强可解释性的机会。', 'title_zh': '理解表格型上下文学习模型中各层的贡献'}
{'arxiv_id': 'arXiv:2511.15432', 'title': 'Towards Understanding Layer Contributions in Tabular In-Context Learning Models', 'authors': 'Amir Rezaei Balef, Mykhailo Koshil, Katharina Eggensperger', 'link': 'https://arxiv.org/abs/2511.15432', 'abstract': 'Despite the architectural similarities between tabular in-context learning (ICL) models and large language models (LLMs), little is known about how individual layers contribute to tabular prediction. In this paper, we investigate how the latent spaces evolve across layers in tabular ICL models, identify potential redundant layers, and compare these dynamics with those observed in LLMs. We analyze TabPFN and TabICL through the "layers as painters" perspective, finding that only subsets of layers share a common representational language, suggesting structural redundancy and offering opportunities for model compression and improved interpretability.', 'abstract_zh': '尽管表格内_context_学习（ICL）模型和大型语言模型（LLMs）在架构上存在相似之处，但关于各层如何贡献于表格预测的了解还很少。在本文中，我们探讨了表格ICL模型中潜在空间在各层之间的演变，识别潜在冗余层，并将这些动态与LLMs中观察到的动态进行比较。我们通过“层如画家”的视角分析了TabPFN和TabICL，发现仅有部分层共享一种共同的表示语言，这表明结构冗余并为模型压缩和增强可解释性提供了机会。', 'title_zh': '理解表格型上下文学习模型中各层的贡献'}
{'arxiv_id': 'arXiv:2511.15418', 'title': 'Building Robust and Scalable Multilingual ASR for Indian Languages', 'authors': 'Arjun Gangwar, Kaousheik Jayakumar, S. Umesh', 'link': 'https://arxiv.org/abs/2511.15418', 'abstract': 'This paper describes the systems developed by SPRING Lab, Indian Institute of Technology Madras, for the ASRU MADASR 2.0 challenge. The systems developed focuses on adapting ASR systems to improve in predicting the language and dialect of the utterance among 8 languages across 33 dialects. We participated in Track 1 and Track 2, which restricts the use of additional data and develop from-the-scratch multilingual systems. We presented a novel training approach using Multi-Decoder architecture with phonemic Common Label Set (CLS) as intermediate representation. It improved the performance over the baseline (in the CLS space). We also discuss various methods used to retain the gain obtained in the phonemic space while converting them back to the corresponding grapheme representations. Our systems beat the baseline in 3 languages (Track 2) in terms of WER/CER and achieved the highest language ID and dialect ID accuracy among all participating teams (Track 2).', 'abstract_zh': '本论文描述了印度技术学院马杜赖SPRING实验室为ASRU MADASR 2.0挑战开发的系统。这些系统专注于适应ASR系统，以提高在33种方言覆盖8种语言的情况下预测语种和方言的能力。我们参与了限制使用额外数据并从头开发多语言系统的Track 1和Track 2。我们提出了一种使用多解码器架构和音素通用标签集（CLS）作为中间表示的新训练方法，这在CLS空间内提高了基线性能。我们还讨论了各种方法，以在将音素空间中的增益转换回相应的图形表示时保持这些增益。我们的系统在3种语言（Track 2）在词错误率/字符错误率上击败了基线，并且在所有参赛团队中实现了最高的语种和方言识别准确性（Track 2）。', 'title_zh': '构建稳健且可扩展的多语言ASR系统——面向印度语言'}
{'arxiv_id': 'arXiv:2511.15418', 'title': 'Building Robust and Scalable Multilingual ASR for Indian Languages', 'authors': 'Arjun Gangwar, Kaousheik Jayakumar, S. Umesh', 'link': 'https://arxiv.org/abs/2511.15418', 'abstract': 'This paper describes the systems developed by SPRING Lab, Indian Institute of Technology Madras, for the ASRU MADASR 2.0 challenge. The systems developed focuses on adapting ASR systems to improve in predicting the language and dialect of the utterance among 8 languages across 33 dialects. We participated in Track 1 and Track 2, which restricts the use of additional data and develop from-the-scratch multilingual systems. We presented a novel training approach using Multi-Decoder architecture with phonemic Common Label Set (CLS) as intermediate representation. It improved the performance over the baseline (in the CLS space). We also discuss various methods used to retain the gain obtained in the phonemic space while converting them back to the corresponding grapheme representations. Our systems beat the baseline in 3 languages (Track 2) in terms of WER/CER and achieved the highest language ID and dialect ID accuracy among all participating teams (Track 2).', 'abstract_zh': 'SPRING实验室印度理工学院孟买分校在ASRU MADASR 2.0挑战中的系统开发：面向8种语言33种方言的语言和方言预测改进研究', 'title_zh': '构建稳健且可扩展的多语言ASR系统——以印度语言为例'}
{'arxiv_id': 'arXiv:2511.15418', 'title': 'Building Robust and Scalable Multilingual ASR for Indian Languages', 'authors': 'Arjun Gangwar, Kaousheik Jayakumar, S. Umesh', 'link': 'https://arxiv.org/abs/2511.15418', 'abstract': 'This paper describes the systems developed by SPRING Lab, Indian Institute of Technology Madras, for the ASRU MADASR 2.0 challenge. The systems developed focuses on adapting ASR systems to improve in predicting the language and dialect of the utterance among 8 languages across 33 dialects. We participated in Track 1 and Track 2, which restricts the use of additional data and develop from-the-scratch multilingual systems. We presented a novel training approach using Multi-Decoder architecture with phonemic Common Label Set (CLS) as intermediate representation. It improved the performance over the baseline (in the CLS space). We also discuss various methods used to retain the gain obtained in the phonemic space while converting them back to the corresponding grapheme representations. Our systems beat the baseline in 3 languages (Track 2) in terms of WER/CER and achieved the highest language ID and dialect ID accuracy among all participating teams (Track 2).', 'abstract_zh': '本论文描述了印度理工学院马德拉斯分校SPRING实验室为ASRU MADASR 2.0挑战所开发的系统。这些系统专注于将ASR系统适应于在8种语言和33种方言中预测语种和方言的任务。我们参与了仅允许使用少量附加数据并从零开始构建多语言系统的Track 1和Track 2。我们提出了一种使用多解码器架构并以音素通用标签集(CLS)作为中间表示的新训练方法，这种方法在CLS空间中提升了基线性能。我们还讨论了各种方法以在将获得的增益从音素空间转换回相应的字母表示时保持这一增益。我们的系统在3种语言（Track 2）中以WER/CER指标击败了基线系统，并在所有参赛团队中获得了最高的语言识别和方言识别准确性（Track 2）。', 'title_zh': '构建稳健且可扩展的多语言ASR系统——以印度语言为例'}
{'arxiv_id': 'arXiv:2511.15414', 'title': 'RRT*former: Environment-Aware Sampling-Based Motion Planning using Transformer', 'authors': 'Mingyang Feng, Shaoyuan Li, Xiang Yin', 'link': 'https://arxiv.org/abs/2511.15414', 'abstract': 'We investigate the sampling-based optimal path planning problem for robotics in complex and dynamic environments. Most existing sampling-based algorithms neglect environmental information or the information from previous samples. Yet, these pieces of information are highly informative, as leveraging them can provide better heuristics when sampling the next state. In this paper, we propose a novel sampling-based planning algorithm, called \\emph{RRT*former}, which integrates the standard RRT* algorithm with a Transformer network in a novel way. Specifically, the Transformer is used to extract features from the environment and leverage information from previous samples to better guide the sampling process. Our extensive experiments demonstrate that, compared to existing sampling-based approaches such as RRT*, Neural RRT*, and their variants, our algorithm achieves considerable improvements in both the optimality of the path and sampling efficiency. The code for our implementation is available on this https URL.', 'abstract_zh': '我们研究了在复杂和动态环境中基于采样的最优路径规划问题。大多数现有的基于采样的算法忽略了环境信息或先前采样的信息。然而，这些信息非常重要，利用它们可以更好地在采样下一个状态时提供启发式方法。在本文中，我们提出了一种新颖的基于采样的规划算法，称为\\emph{RRT*former}，该算法以新颖的方式将标准的RRT*算法与Transformer网络结合。具体来说，Transformer用于从环境中提取特征并利用先前采样的信息更有效地指导采样过程。我们的广泛实验表明，与现有的基于采样的方法（如RRT*、Neural RRT*及其变种）相比，我们的算法在路径的最优性和采样效率方面均取得了显著改进。我们的实现代码可在此处访问：this https URL。', 'title_zh': 'RRT*former: 基于注意力机制的环境感知运动规划'}
{'arxiv_id': 'arXiv:2511.15414', 'title': 'RRT*former: Environment-Aware Sampling-Based Motion Planning using Transformer', 'authors': 'Mingyang Feng, Shaoyuan Li, Xiang Yin', 'link': 'https://arxiv.org/abs/2511.15414', 'abstract': 'We investigate the sampling-based optimal path planning problem for robotics in complex and dynamic environments. Most existing sampling-based algorithms neglect environmental information or the information from previous samples. Yet, these pieces of information are highly informative, as leveraging them can provide better heuristics when sampling the next state. In this paper, we propose a novel sampling-based planning algorithm, called \\emph{RRT*former}, which integrates the standard RRT* algorithm with a Transformer network in a novel way. Specifically, the Transformer is used to extract features from the environment and leverage information from previous samples to better guide the sampling process. Our extensive experiments demonstrate that, compared to existing sampling-based approaches such as RRT*, Neural RRT*, and their variants, our algorithm achieves considerable improvements in both the optimality of the path and sampling efficiency. The code for our implementation is available on this https URL.', 'abstract_zh': '基于采样的机器人在复杂动态环境中的最优路径规划问题研究：一种新型的结合Transformer网络的RRT*算法', 'title_zh': 'RRT*former: 基于环境aware采样并使用Transformer的运动规划'}
{'arxiv_id': 'arXiv:2511.15414', 'title': 'RRT*former: Environment-Aware Sampling-Based Motion Planning using Transformer', 'authors': 'Mingyang Feng, Shaoyuan Li, Xiang Yin', 'link': 'https://arxiv.org/abs/2511.15414', 'abstract': 'We investigate the sampling-based optimal path planning problem for robotics in complex and dynamic environments. Most existing sampling-based algorithms neglect environmental information or the information from previous samples. Yet, these pieces of information are highly informative, as leveraging them can provide better heuristics when sampling the next state. In this paper, we propose a novel sampling-based planning algorithm, called \\emph{RRT*former}, which integrates the standard RRT* algorithm with a Transformer network in a novel way. Specifically, the Transformer is used to extract features from the environment and leverage information from previous samples to better guide the sampling process. Our extensive experiments demonstrate that, compared to existing sampling-based approaches such as RRT*, Neural RRT*, and their variants, our algorithm achieves considerable improvements in both the optimality of the path and sampling efficiency. The code for our implementation is available on this https URL.', 'abstract_zh': '基于采样的机器人在复杂动态环境中的路径规划问题研究：一种新颖的结合Transformer的RRT*former算法', 'title_zh': 'RRT*former: 基于变压器的环境意识采样运动规划'}
{'arxiv_id': 'arXiv:2511.15408', 'title': 'NAMeGEn: Creative Name Generation via A Novel Agent-based Multiple Personalized Goal Enhancement Framework', 'authors': 'Shanlin Zhou, Xinpeng Wang, Jianxun Lian, Zhenghao Liu, Laks V.S. Lakshmanan, Xiaoyuan Yi, Yongtao Hao', 'link': 'https://arxiv.org/abs/2511.15408', 'abstract': "Trained on diverse human-authored texts, Large Language Models (LLMs) unlocked the potential for Creative Natural Language Generation (CNLG), benefiting various applications like advertising and storytelling. Nevertheless, CNLG still remains difficult due to two main challenges. (1) Multi-objective flexibility: user requirements are often personalized, fine-grained, and pluralistic, which LLMs struggle to satisfy simultaneously; (2) Interpretive complexity: beyond generation, creativity also involves understanding and interpreting implicit meaning to enhance users' perception. These challenges significantly limit current methods, especially in short-form text generation, in generating creative and insightful content. To address this, we focus on Chinese baby naming, a representative short-form CNLG task requiring adherence to explicit user constraints (e.g., length, semantics, anthroponymy) while offering meaningful aesthetic explanations. We propose NAMeGEn, a novel multi-agent optimization framework that iteratively alternates between objective extraction, name generation, and evaluation to meet diverse requirements and generate accurate explanations. To support this task, we further construct a classical Chinese poetry corpus with 17k+ poems to enhance aesthetics, and introduce CBNames, a new benchmark with tailored metrics. Extensive experiments demonstrate that NAMeGEn effectively generates creative names that meet diverse, personalized requirements while providing meaningful explanations, outperforming six baseline methods spanning various LLM backbones without any training.", 'abstract_zh': '训练于多样化的人类撰写的文本，大规模语言模型（LLMs）解锁了创造自然语言生成（CNLG）的潜力，造福了广告和叙事等多种应用。然而，CNLG仍旧因两大主要挑战而颇具难度。（1）多目标灵活性：用户需求往往是个性化、精细化和多元化的，这对LLMs而言难以同时满足；（2）解释复杂性：超越生成，创造力还涉及理解和解释隐含意义以增强用户的感知。这些挑战显著限制了当前的方法，尤其是在短文本生成中生成创造性、有价值的內容的能力。为了解决这一问题，我们专注于中国婴儿起名任务，这是一个需要遵守显式用户约束（如长度、语义、人名学）同时提供有意义美学解释的代表性短文本CNLG任务。我们提出了NAMeGEn，一种新颖的多智能体优化框架，通过迭代地交替进行目标提取、命名生成和评估，以满足多样需求并生成准确的解释。为了支持这一任务，我们进一步构建了一个包含17000多首古典中国诗歌的语料库，以增强美学效果，并引入了CBNames这一新的基准集，附有定制的评估指标。大量实验证明，NAMeGEn能够有效生成满足多样化个性化需求的创造性强的名字，并提供有意义的解释，超越了六种基于不同LLM架构的基线方法而无需任何训练。', 'title_zh': 'NameGEn: 基于新型代理多重个性化目标增强框架的创意名称生成'}
{'arxiv_id': 'arXiv:2511.15408', 'title': 'NAMeGEn: Creative Name Generation via A Novel Agent-based Multiple Personalized Goal Enhancement Framework', 'authors': 'Shanlin Zhou, Xinpeng Wang, Jianxun Lian, Zhenghao Liu, Laks V.S. Lakshmanan, Xiaoyuan Yi, Yongtao Hao', 'link': 'https://arxiv.org/abs/2511.15408', 'abstract': "Trained on diverse human-authored texts, Large Language Models (LLMs) unlocked the potential for Creative Natural Language Generation (CNLG), benefiting various applications like advertising and storytelling. Nevertheless, CNLG still remains difficult due to two main challenges. (1) Multi-objective flexibility: user requirements are often personalized, fine-grained, and pluralistic, which LLMs struggle to satisfy simultaneously; (2) Interpretive complexity: beyond generation, creativity also involves understanding and interpreting implicit meaning to enhance users' perception. These challenges significantly limit current methods, especially in short-form text generation, in generating creative and insightful content. To address this, we focus on Chinese baby naming, a representative short-form CNLG task requiring adherence to explicit user constraints (e.g., length, semantics, anthroponymy) while offering meaningful aesthetic explanations. We propose NAMeGEn, a novel multi-agent optimization framework that iteratively alternates between objective extraction, name generation, and evaluation to meet diverse requirements and generate accurate explanations. To support this task, we further construct a classical Chinese poetry corpus with 17k+ poems to enhance aesthetics, and introduce CBNames, a new benchmark with tailored metrics. Extensive experiments demonstrate that NAMeGEn effectively generates creative names that meet diverse, personalized requirements while providing meaningful explanations, outperforming six baseline methods spanning various LLM backbones without any training.", 'abstract_zh': '大型语言模型（LLMs）训练于多元的人撰文本，解锁了创意思维自然语言生成（CNLG）的潜力，为广告和故事讲述等应用带来好处。然而，CNLG仍面临两大主要挑战。（1）多目标灵活性：用户需求往往是个性化、细致化和多元化的，这超出了LLMs的满足能力；（2）解释复杂性：除生成外，创意还涉及理解和解释隐含意义，以增强用户的感知。这些挑战显著限制了当前的方法，尤其是在短文本生成中生成有创意且有价值的內容。为应对这一挑战，我们专注于中国起名这一代表性的短文本CNLG任务，该任务需要遵循明确的用户约束（如长度、语义、人名学），并提供有意义的审美解释。我们提出了一种新颖的多智能体优化框架NAMeGEn，该框架通过迭代地交替进行目标提取、名称生成和评估，以满足多样化的要求并生成准确的解释。为支持此任务，我们进一步构建了一个包含17000多首古典中国诗歌的语料库，以增强美学效果，并引入了CBNames这一新基准，附带定制的评价指标。大量实验表明，NAMeGEn能够生成满足多样化个性化需求的有创意名称，并提供有意义的解释，优于六个来自不同LLM架构的基线方法，且无需额外训练。', 'title_zh': 'NameGEng: 基于新型代理的多个性化目标增强名称生成框架'}
{'arxiv_id': 'arXiv:2511.15408', 'title': 'NAMeGEn: Creative Name Generation via A Novel Agent-based Multiple Personalized Goal Enhancement Framework', 'authors': 'Shanlin Zhou, Xinpeng Wang, Jianxun Lian, Zhenghao Liu, Laks V.S. Lakshmanan, Xiaoyuan Yi, Yongtao Hao', 'link': 'https://arxiv.org/abs/2511.15408', 'abstract': "Trained on diverse human-authored texts, Large Language Models (LLMs) unlocked the potential for Creative Natural Language Generation (CNLG), benefiting various applications like advertising and storytelling. Nevertheless, CNLG still remains difficult due to two main challenges. (1) Multi-objective flexibility: user requirements are often personalized, fine-grained, and pluralistic, which LLMs struggle to satisfy simultaneously; (2) Interpretive complexity: beyond generation, creativity also involves understanding and interpreting implicit meaning to enhance users' perception. These challenges significantly limit current methods, especially in short-form text generation, in generating creative and insightful content. To address this, we focus on Chinese baby naming, a representative short-form CNLG task requiring adherence to explicit user constraints (e.g., length, semantics, anthroponymy) while offering meaningful aesthetic explanations. We propose NAMeGEn, a novel multi-agent optimization framework that iteratively alternates between objective extraction, name generation, and evaluation to meet diverse requirements and generate accurate explanations. To support this task, we further construct a classical Chinese poetry corpus with 17k+ poems to enhance aesthetics, and introduce CBNames, a new benchmark with tailored metrics. Extensive experiments demonstrate that NAMeGEn effectively generates creative names that meet diverse, personalized requirements while providing meaningful explanations, outperforming six baseline methods spanning various LLM backbones without any training.", 'abstract_zh': '基于多样化人类撰写的文本训练，大型语言模型（LLMs）开启了创造型自然语言生成（CNLG）的潜力，惠及广告、讲故事等多种应用。然而，CNLG仍然因两大主要挑战而颇具难度。一是多目标灵活性：用户需求往往是个性化、精细且多样化的，而LLMs难以同时满足；二是解释性复杂性：创造不仅限于生成，还涉及理解并解释隐含意义以提升用户的感知。这些挑战显著限制了当前的方法，尤其是在短文本生成中生成有创意和洞察力的内容。为了解决这一问题，我们集中于中文婴儿起名这一代表性的短文本CNLG任务，该任务需要遵守明确的用户约束（如长度、语义、人名学）的同时，提供有意义的美学解释。我们提出了NAMeGEn，一种新颖的多智能体优化框架，通过迭代交替进行目标提取、名字生成和评估，以满足多样化需求并生成准确的解释。为此，我们进一步构建了一个包含17000多首经典中文诗歌的语料库以增强美学，并引入了CBNames这一新的基准测试，配备了定制化的评价指标。大量实验表明，NAMeGEn有效生成了符合多样化、个性化需求且提供有意义解释的创意名字，优于六种不同LLM模型架构的基线方法，无需任何训练。', 'title_zh': 'NameGEn：基于新型代理多个性化目标增强框架的创意名称生成'}
{'arxiv_id': 'arXiv:2511.15392', 'title': 'DEPO: Dual-Efficiency Preference Optimization for LLM Agents', 'authors': 'Sirui Chen, Mengshi Zhao, Lei Xu, Yuying Zhao, Beier Zhu, Hanwang Zhang, Shengjie Zhao, Chaochao Lu', 'link': 'https://arxiv.org/abs/2511.15392', 'abstract': 'Recent advances in large language models (LLMs) have greatly improved their reasoning and decision-making abilities when deployed as agents. Richer reasoning, however, often comes at the cost of longer chain of thought (CoT), hampering interaction efficiency in real-world scenarios. Nevertheless, there still lacks systematic definition of LLM agent efficiency, hindering targeted improvements. To this end, we introduce dual-efficiency, comprising (i) step-level efficiency, which minimizes tokens per step, and (ii) trajectory-level efficiency, which minimizes the number of steps to complete a task. Building on this definition, we propose DEPO, a dual-efficiency preference optimization method that jointly rewards succinct responses and fewer action steps. Experiments on WebShop and BabyAI show that DEPO cuts token usage by up to 60.9% and steps by up to 26.9%, while achieving up to a 29.3% improvement in performance. DEPO also generalizes to three out-of-domain math benchmarks and retains its efficiency gains when trained on only 25% of the data. Our project page is at this https URL.', 'abstract_zh': 'Recent Advances in Large Language Models: Dual-Efficiency Preference Optimization for Improving Agent Performance', 'title_zh': 'DEPO: 双效率偏好优化方法 for LLM代理'}
{'arxiv_id': 'arXiv:2511.15392', 'title': 'DEPO: Dual-Efficiency Preference Optimization for LLM Agents', 'authors': 'Sirui Chen, Mengshi Zhao, Lei Xu, Yuying Zhao, Beier Zhu, Hanwang Zhang, Shengjie Zhao, Chaochao Lu', 'link': 'https://arxiv.org/abs/2511.15392', 'abstract': 'Recent advances in large language models (LLMs) have greatly improved their reasoning and decision-making abilities when deployed as agents. Richer reasoning, however, often comes at the cost of longer chain of thought (CoT), hampering interaction efficiency in real-world scenarios. Nevertheless, there still lacks systematic definition of LLM agent efficiency, hindering targeted improvements. To this end, we introduce dual-efficiency, comprising (i) step-level efficiency, which minimizes tokens per step, and (ii) trajectory-level efficiency, which minimizes the number of steps to complete a task. Building on this definition, we propose DEPO, a dual-efficiency preference optimization method that jointly rewards succinct responses and fewer action steps. Experiments on WebShop and BabyAI show that DEPO cuts token usage by up to 60.9% and steps by up to 26.9%, while achieving up to a 29.3% improvement in performance. DEPO also generalizes to three out-of-domain math benchmarks and retains its efficiency gains when trained on only 25% of the data. Our project page is at this https URL.', 'abstract_zh': '近期大规模语言模型（LLMs）的进展显著提升了其作为代理时的推理和决策能力，但在实际场景中，更丰富的推理往往伴随着更长的思维链（CoT），影响了互动效率。尽管如此，对LLM代理效率的系统性定义仍然缺乏，阻碍了有针对性的改进。为此，我们引入了双效性概念，包括步骤级效率（通过最小化每步的token数量实现）和轨迹级效率（通过最小化完成任务的步骤数量实现）。基于这一定义，我们提出了双效性偏好优化方法（DEPO），该方法联合奖励简洁的响应和较少的操作步骤。在WebShop和BabyAI上的实验结果显示，DEPO将token使用量最多减少了60.9%，步骤数量最多减少了26.9%，同时性能提高了29.3%。DEPO还能够应用于三个领域外的数学基准测试，并且只在数据的25%上进行训练时仍能保持其效率收益。我们的项目页面链接为this https URL。', 'title_zh': 'DEPO: 双效率偏好优化方法 for LLM 代理'}
{'arxiv_id': 'arXiv:2511.15392', 'title': 'DEPO: Dual-Efficiency Preference Optimization for LLM Agents', 'authors': 'Sirui Chen, Mengshi Zhao, Lei Xu, Yuying Zhao, Beier Zhu, Hanwang Zhang, Shengjie Zhao, Chaochao Lu', 'link': 'https://arxiv.org/abs/2511.15392', 'abstract': 'Recent advances in large language models (LLMs) have greatly improved their reasoning and decision-making abilities when deployed as agents. Richer reasoning, however, often comes at the cost of longer chain of thought (CoT), hampering interaction efficiency in real-world scenarios. Nevertheless, there still lacks systematic definition of LLM agent efficiency, hindering targeted improvements. To this end, we introduce dual-efficiency, comprising (i) step-level efficiency, which minimizes tokens per step, and (ii) trajectory-level efficiency, which minimizes the number of steps to complete a task. Building on this definition, we propose DEPO, a dual-efficiency preference optimization method that jointly rewards succinct responses and fewer action steps. Experiments on WebShop and BabyAI show that DEPO cuts token usage by up to 60.9% and steps by up to 26.9%, while achieving up to a 29.3% improvement in performance. DEPO also generalizes to three out-of-domain math benchmarks and retains its efficiency gains when trained on only 25% of the data. Our project page is at this https URL.', 'abstract_zh': 'Recent advances in大型语言模型（LLMs）近年来在大型语言模型（LLMs）方面的进展大大提高了它们作为代理应用时的推理和决策能力。然而，更丰富的推理往往以更长的思维链（CoT）为代价，阻碍了在实际场景中的交互效率。尽管如此，仍然缺乏系统性的LLM代理效率定义，阻碍了有针对性的改进。为了解决这一问题，我们引入了双效率概念，包括（i）步骤级效率，即每步最小化令牌数量，以及（ii）轨迹级效率，即完成任务所需的步骤数量最小化。基于这一定义，我们提出了一种双效率偏好优化方法DEPO，该方法联合奖励简洁的回答和更少的操作步骤。在WebShop和BabyAI上的实验表明，DEPO将令牌使用量最多减少了60.9%，步骤数量最多减少了26.9%，同时实现了高达29.3%的性能提升。DEPO还能够泛化到三个不同的领域数学基准，并且在仅使用数据的25%进行训练时仍能保持其效率优势。我们的项目页面位于此链接。', 'title_zh': 'DEPO: 双效偏好优化算法 for LLM 代理'}
{'arxiv_id': 'arXiv:2511.15383', 'title': 'A Compliance-Preserving Retrieval System for Aircraft MRO Task Search', 'authors': 'Byungho Jo', 'link': 'https://arxiv.org/abs/2511.15383', 'abstract': 'Aircraft Maintenance Technicians (AMTs) spend up to 30% of work time searching manuals, a documented efficiency bottleneck in MRO operations where every procedure must be traceable to certified sources. We present a compliance-preserving retrieval system that adapts LLM reranking and semantic search to aviation MRO environments by operating alongside, rather than replacing, certified legacy viewers. The system constructs revision-robust embeddings from ATA chapter hierarchies and uses vision-language parsing to structure certified content, allowing technicians to preview ranked tasks and access verified procedures in existing viewers. Evaluation on 49k synthetic queries achieves >90% retrieval accuracy, while bilingual controlled studies with 10 licensed AMTs demonstrate 90.9% top-10 success rate and 95% reduction in lookup time, from 6-15 minutes to 18 seconds per task. These gains provide concrete evidence that semantic retrieval can operate within strict regulatory constraints and meaningfully reduce operational workload in real-world multilingual MRO workflows.', 'abstract_zh': '航空维护技术人员（AMTs）在工作中花费多达30%的时间查阅手册，这是MRO运营中的一个已记录的效率瓶颈，因为在MRO中每一项程序必须追溯到认证的来源。我们提出了一种合规保留检索系统，该系统通过与认证的遗留查看器并行运行，而非取代它们，来适应LLM重新排序和语义搜索在航空MRO环境中的应用。该系统从ATA章节层次结构中构建修订稳健的嵌入，并利用视觉-语言解析来结构化认证内容，从而使技术人员可以预览排名任务并访问现有查看器中的验证程序。在49,000个合成查询上的评估实现了超过90%的检索准确性，而双语受控研究中10名执照维护技术人员的参与则显示了90.9%的前10项成功率和95%的查找时间减少，从每项任务6-15分钟缩短至18秒。这些收益提供了具体证据，表明语义检索可以在严格的监管约束下运行，并实质性地减少多语言MRO流程中的操作工作负载。', 'title_zh': '遵守合规性的航空维修任务检索系统'}
{'arxiv_id': 'arXiv:2511.15383', 'title': 'A Compliance-Preserving Retrieval System for Aircraft MRO Task Search', 'authors': 'Byungho Jo', 'link': 'https://arxiv.org/abs/2511.15383', 'abstract': 'Aircraft Maintenance Technicians (AMTs) spend up to 30% of work time searching manuals, a documented efficiency bottleneck in MRO operations where every procedure must be traceable to certified sources. We present a compliance-preserving retrieval system that adapts LLM reranking and semantic search to aviation MRO environments by operating alongside, rather than replacing, certified legacy viewers. The system constructs revision-robust embeddings from ATA chapter hierarchies and uses vision-language parsing to structure certified content, allowing technicians to preview ranked tasks and access verified procedures in existing viewers. Evaluation on 49k synthetic queries achieves >90% retrieval accuracy, while bilingual controlled studies with 10 licensed AMTs demonstrate 90.9% top-10 success rate and 95% reduction in lookup time, from 6-15 minutes to 18 seconds per task. These gains provide concrete evidence that semantic retrieval can operate within strict regulatory constraints and meaningfully reduce operational workload in real-world multilingual MRO workflows.', 'abstract_zh': '航空维修技术人员(AMTs)花费多达30%的工作时间搜索手册，在维修operations（MRO）中，每一个程序都必须追溯到认证的来源，这被记录为效率瓶颈。我们提出了一种合规保留检索系统，通过与认证的遗留查看器并行操作，而不是替代它们，来适应航空MRO环境中的LLM重排序和语义搜索。该系统从ATA章节层次结构中构建修订稳健的嵌入式表示，并使用视觉-语言解析来结构化认证内容，使技术人员能够预览排名任务并访问现有查看器中的验证程序。在49,000个合成查询上的评估实现了超过90%的检索准确性，而双语受控研究显示，10名持有执照的AMTs的前10项成功率达到90.9%，查找时间减少了95%，从每任务6-15分钟缩短至18秒。这些收益为语义检索在严格监管约束下以及在多语言MRO工作流程中实质性减少操作工作量提供了具体的证据。', 'title_zh': '遵守规范的航空维修任务检索系统'}
{'arxiv_id': 'arXiv:2511.15383', 'title': 'A Compliance-Preserving Retrieval System for Aircraft MRO Task Search', 'authors': 'Byungho Jo', 'link': 'https://arxiv.org/abs/2511.15383', 'abstract': 'Aircraft Maintenance Technicians (AMTs) spend up to 30% of work time searching manuals, a documented efficiency bottleneck in MRO operations where every procedure must be traceable to certified sources. We present a compliance-preserving retrieval system that adapts LLM reranking and semantic search to aviation MRO environments by operating alongside, rather than replacing, certified legacy viewers. The system constructs revision-robust embeddings from ATA chapter hierarchies and uses vision-language parsing to structure certified content, allowing technicians to preview ranked tasks and access verified procedures in existing viewers. Evaluation on 49k synthetic queries achieves >90% retrieval accuracy, while bilingual controlled studies with 10 licensed AMTs demonstrate 90.9% top-10 success rate and 95% reduction in lookup time, from 6-15 minutes to 18 seconds per task. These gains provide concrete evidence that semantic retrieval can operate within strict regulatory constraints and meaningfully reduce operational workload in real-world multilingual MRO workflows.', 'abstract_zh': '航空维修技术人员（AMTs）在工作中花费高达30%的时间查询手册，这是维修运营（MRO）中的一个记录在案的效率瓶颈，因为每次操作都必须追溯到认证的来源。我们提出了一种合规保留的检索系统，该系统通过与认证的遗留查看器并行操作，而非替代它们，适应了基于LLM重排序和语义搜索的航空MRO环境。该系统从ATA章节层次结构中构建了修订稳健的嵌入，并利用视觉语言解析来结构化认证内容，使技术人员能够预览排名的任务并访问现有查看器中的验证操作程序。在49,000个合成查询上的评估实现了超过90%的检索准确性，而双语受控研究中10名持证AMT的参与表明，顶级10项成功率达到了90.9%，查找时间减少了95%，从每任务6-15分钟减少到18秒。这些收益为语义检索能够在严格的监管约束内运行并在多语言的现实世界MRO工作流程中实质性地减轻操作负担提供了确凿的证据。', 'title_zh': '遵守合规性的航空维修任务搜索检索系统'}
{'arxiv_id': 'arXiv:2511.15375', 'title': 'Parameter Importance-Driven Continual Learning for Foundation Models', 'authors': 'Lingxiang Wang, Hainan Zhang, Zhiming Zheng', 'link': 'https://arxiv.org/abs/2511.15375', 'abstract': 'Domain-specific post-training often causes catastrophic forgetting, making foundation models lose their general reasoning ability and limiting their adaptability to dynamic real-world environments. Preserving general capabilities while acquiring downstream domain knowledge is a central challenge for large language and multimodal models. Traditional continual learning methods, such as regularization, replay and architectural isolation, suffer from poor downstream performance, reliance on inaccessible historical data, or additional parameter overhead. While recent parameter-efficient tuning (PET) methods can alleviate forgetting, their effectiveness strongly depends on the choice of parameters and update strategies. In this paper, we introduce PIECE, a Parameter Importance Estimation-based Continual Enhancement method that preserves general ability while efficiently learning domain knowledge without accessing prior training data or increasing model parameters. PIECE selectively updates only 0.1% of core parameters most relevant to new tasks, guided by two importance estimators: PIECE-F based on Fisher Information, and PIECE-S based on a second-order normalization that combines gradient and curvature information. Experiments across three language models and two multimodal models show that PIECE maintains general capabilities and achieves state-of-the-art continual learning performance across diverse downstream tasks. Our results highlight a practical path to scalable, domain-adaptive foundation models without catastrophic forgetting.', 'abstract_zh': '基于参数重要性估计的持续增强方法 PIECE：在无需访问先验训练数据或增加模型参数的情况下保留通用能力并高效学习领域知识', 'title_zh': '参数重要性驱动的持续学习方法在基础模型中的应用'}
{'arxiv_id': 'arXiv:2511.15375', 'title': 'Parameter Importance-Driven Continual Learning for Foundation Models', 'authors': 'Lingxiang Wang, Hainan Zhang, Zhiming Zheng', 'link': 'https://arxiv.org/abs/2511.15375', 'abstract': 'Domain-specific post-training often causes catastrophic forgetting, making foundation models lose their general reasoning ability and limiting their adaptability to dynamic real-world environments. Preserving general capabilities while acquiring downstream domain knowledge is a central challenge for large language and multimodal models. Traditional continual learning methods, such as regularization, replay and architectural isolation, suffer from poor downstream performance, reliance on inaccessible historical data, or additional parameter overhead. While recent parameter-efficient tuning (PET) methods can alleviate forgetting, their effectiveness strongly depends on the choice of parameters and update strategies. In this paper, we introduce PIECE, a Parameter Importance Estimation-based Continual Enhancement method that preserves general ability while efficiently learning domain knowledge without accessing prior training data or increasing model parameters. PIECE selectively updates only 0.1% of core parameters most relevant to new tasks, guided by two importance estimators: PIECE-F based on Fisher Information, and PIECE-S based on a second-order normalization that combines gradient and curvature information. Experiments across three language models and two multimodal models show that PIECE maintains general capabilities and achieves state-of-the-art continual learning performance across diverse downstream tasks. Our results highlight a practical path to scalable, domain-adaptive foundation models without catastrophic forgetting.', 'abstract_zh': '域特定的后训练往往会导致灾难性遗忘，使基础模型失去其通用推理能力，并限制其对动态现实环境的适应性。在保持通用能力的同时获取下游领域知识是大型语言和多模态模型的一项核心挑战。传统的连续学习方法，如正则化、重放和架构隔离，存在下游性能差、依赖不可获取的历史数据或增加额外模型参数的问题。虽然近期的参数高效调谐(PET)方法可以缓解遗忘问题，但其效果强烈依赖于参数选择和更新策略。在本文中，我们引入了PIECE（基于参数重要性估计的连续增强方法），能够在不访问先前训练数据或增加模型参数的情况下保持通用能力并高效学习领域知识。PIECE仅选择性地更新与新任务最相关的0.1%核心参数，由Fisher信息和二阶归一化（结合了梯度和曲率信息）指导两个重要性估计器：PIECE-F和PIECE-S。在三个语言模型和两个多模态模型上的实验表明，PIECE能够在多种下游任务中保持通用能力并实现最佳的连续学习性能。我们的研究结果突显了一条无需灾难性遗忘的可扩展、领域适应的基础模型的实用路径。', 'title_zh': '参数重要性驱动的持续学习方法émon'}
{'arxiv_id': 'arXiv:2511.15375', 'title': 'Parameter Importance-Driven Continual Learning for Foundation Models', 'authors': 'Lingxiang Wang, Hainan Zhang, Zhiming Zheng', 'link': 'https://arxiv.org/abs/2511.15375', 'abstract': 'Domain-specific post-training often causes catastrophic forgetting, making foundation models lose their general reasoning ability and limiting their adaptability to dynamic real-world environments. Preserving general capabilities while acquiring downstream domain knowledge is a central challenge for large language and multimodal models. Traditional continual learning methods, such as regularization, replay and architectural isolation, suffer from poor downstream performance, reliance on inaccessible historical data, or additional parameter overhead. While recent parameter-efficient tuning (PET) methods can alleviate forgetting, their effectiveness strongly depends on the choice of parameters and update strategies. In this paper, we introduce PIECE, a Parameter Importance Estimation-based Continual Enhancement method that preserves general ability while efficiently learning domain knowledge without accessing prior training data or increasing model parameters. PIECE selectively updates only 0.1% of core parameters most relevant to new tasks, guided by two importance estimators: PIECE-F based on Fisher Information, and PIECE-S based on a second-order normalization that combines gradient and curvature information. Experiments across three language models and two multimodal models show that PIECE maintains general capabilities and achieves state-of-the-art continual learning performance across diverse downstream tasks. Our results highlight a practical path to scalable, domain-adaptive foundation models without catastrophic forgetting.', 'abstract_zh': 'PIECE：基于参数重要性估计的持续增强方法', 'title_zh': '参数重要性驱动的持续学习方法'}
{'arxiv_id': 'arXiv:2511.15370', 'title': 'The Empowerment of Science of Science by Large Language Models: New Tools and Methods', 'authors': 'Guoqiang Liang, Jingqian Gong, Mengxuan Li, Gege Lin, Shuo Zhang', 'link': 'https://arxiv.org/abs/2511.15370', 'abstract': 'Large language models (LLMs) have exhibited exceptional capabilities in natural language understanding and generation, image recognition, and multimodal tasks, charting a course towards AGI and emerging as a central issue in the global technological race. This manuscript conducts a comprehensive review of the core technologies that support LLMs from a user standpoint, including prompt engineering, knowledge-enhanced retrieval augmented generation, fine tuning, pretraining, and tool learning. Additionally, it traces the historical development of Science of Science (SciSci) and presents a forward looking perspective on the potential applications of LLMs within the scientometric domain. Furthermore, it discusses the prospect of an AI agent based model for scientific evaluation, and presents new research fronts detection and knowledge graph building methods with LLMs.', 'abstract_zh': '大型语言模型（LLMs）在自然语言理解与生成、图像识别和多模态任务中展现了卓越的能力，正朝着AGI迈进，并成为全球技术竞赛中的核心问题。本文从用户角度对支持LLMs的核心技术进行了全面review，包括提示工程、知识增强检索增强生成、微调、预训练和工具学习。此外，本文追溯了Science of Science（SciSci）的发展历史，并展望了LLMs在 scientometric 领域中的潜在应用。同时讨论了基于AI代理的科学评估模型的可能性，并介绍了使用LLMs进行新研究前沿检测和知识图谱构建的新方法。', 'title_zh': '大规模语言模型对科学研究的赋能：新工具与方法'}
{'arxiv_id': 'arXiv:2511.15370', 'title': 'The Empowerment of Science of Science by Large Language Models: New Tools and Methods', 'authors': 'Guoqiang Liang, Jingqian Gong, Mengxuan Li, Gege Lin, Shuo Zhang', 'link': 'https://arxiv.org/abs/2511.15370', 'abstract': 'Large language models (LLMs) have exhibited exceptional capabilities in natural language understanding and generation, image recognition, and multimodal tasks, charting a course towards AGI and emerging as a central issue in the global technological race. This manuscript conducts a comprehensive review of the core technologies that support LLMs from a user standpoint, including prompt engineering, knowledge-enhanced retrieval augmented generation, fine tuning, pretraining, and tool learning. Additionally, it traces the historical development of Science of Science (SciSci) and presents a forward looking perspective on the potential applications of LLMs within the scientometric domain. Furthermore, it discusses the prospect of an AI agent based model for scientific evaluation, and presents new research fronts detection and knowledge graph building methods with LLMs.', 'abstract_zh': '大型语言模型（LLMs）在自然语言理解与生成、图像识别及多模态任务中展现了卓越的能力，正朝着AGI方向发展，并成为全球科技竞赛中的核心问题。本研究从用户角度全面回顾了支持LLMs的核心技术，包括提示工程、知识增强检索增强生成、微调、预训练和工具学习。此外，本文追溯了科学学（SciSci）的发展历史，并展望了LLMs在科学计量领域的潜在应用。进一步讨论了基于AI代理的科学评估模型的前景，并介绍了使用LLMs进行新研究前沿检测和知识图谱构建的新研究方向。', 'title_zh': '科学计量学通过大规模语言模型的赋能：新工具与方法'}
{'arxiv_id': 'arXiv:2511.15369', 'title': 'IPTQ-ViT: Post-Training Quantization of Non-linear Functions for Integer-only Vision Transformers', 'authors': 'Gihwan Kim, Jemin Lee, Hyungshin Kim', 'link': 'https://arxiv.org/abs/2511.15369', 'abstract': 'Previous Quantization-Aware Training (QAT) methods for vision transformers rely on expensive retraining to recover accuracy loss in non-linear layer quantization, limiting their use in resource-constrained environments. In contrast, existing Post-Training Quantization (PTQ) methods either partially quantize non-linear functions or adjust activation distributions to maintain accuracy but fail to achieve fully integer-only inference. In this paper, we introduce IPTQ-ViT, a novel PTQ framework for fully integer-only vision transformers without retraining. We present approximation functions: a polynomial-based GELU optimized for vision data and a bit-shifting-based Softmax designed to improve approximation accuracy in PTQ. In addition, we propose a unified metric integrating quantization sensitivity, perturbation, and computational cost to select the optimal approximation function per activation layer. IPTQ-ViT outperforms previous PTQ methods, achieving up to 6.44\\%p (avg. 1.78\\%p) top-1 accuracy improvement for image classification, 1.0 mAP for object detection. IPTQ-ViT outperforms partial floating-point PTQ methods under W8A8 and W4A8, and achieves accuracy and latency comparable to integer-only QAT methods. We plan to release our code this https URL.', 'abstract_zh': '基于插值后量化的方法实现全整数视觉变压器：无需重新训练的后量化框架', 'title_zh': 'IPTQ-ViT：仅整数视觉变换器的后训练量化方法'}
{'arxiv_id': 'arXiv:2511.15370', 'title': 'The Empowerment of Science of Science by Large Language Models: New Tools and Methods', 'authors': 'Guoqiang Liang, Jingqian Gong, Mengxuan Li, Gege Lin, Shuo Zhang', 'link': 'https://arxiv.org/abs/2511.15370', 'abstract': 'Large language models (LLMs) have exhibited exceptional capabilities in natural language understanding and generation, image recognition, and multimodal tasks, charting a course towards AGI and emerging as a central issue in the global technological race. This manuscript conducts a comprehensive review of the core technologies that support LLMs from a user standpoint, including prompt engineering, knowledge-enhanced retrieval augmented generation, fine tuning, pretraining, and tool learning. Additionally, it traces the historical development of Science of Science (SciSci) and presents a forward looking perspective on the potential applications of LLMs within the scientometric domain. Furthermore, it discusses the prospect of an AI agent based model for scientific evaluation, and presents new research fronts detection and knowledge graph building methods with LLMs.', 'abstract_zh': '大型语言模型（LLMs）在自然语言理解与生成、图像识别和多模态任务中表现出非凡的能力，正朝着AGI迈进并成为全球科技竞赛中的核心议题。本文从用户视角全面回顾支持LLMs的核心技术，包括提示工程、知识增强检索增强生成、微调、预训练和工具学习。此外，本文追溯了科学学（SciSci）的发展历史，并展望LLMs在科学计量领域的潜在应用。进一步地，本文讨论了基于AI代理的科学评价模型的前景，并提出了利用LLMs进行新研究前沿检测和知识图谱构建的新方法。', 'title_zh': '大型语言模型对科学学的赋能：新工具与方法'}
{'arxiv_id': 'arXiv:2511.15369', 'title': 'IPTQ-ViT: Post-Training Quantization of Non-linear Functions for Integer-only Vision Transformers', 'authors': 'Gihwan Kim, Jemin Lee, Hyungshin Kim', 'link': 'https://arxiv.org/abs/2511.15369', 'abstract': 'Previous Quantization-Aware Training (QAT) methods for vision transformers rely on expensive retraining to recover accuracy loss in non-linear layer quantization, limiting their use in resource-constrained environments. In contrast, existing Post-Training Quantization (PTQ) methods either partially quantize non-linear functions or adjust activation distributions to maintain accuracy but fail to achieve fully integer-only inference. In this paper, we introduce IPTQ-ViT, a novel PTQ framework for fully integer-only vision transformers without retraining. We present approximation functions: a polynomial-based GELU optimized for vision data and a bit-shifting-based Softmax designed to improve approximation accuracy in PTQ. In addition, we propose a unified metric integrating quantization sensitivity, perturbation, and computational cost to select the optimal approximation function per activation layer. IPTQ-ViT outperforms previous PTQ methods, achieving up to 6.44\\%p (avg. 1.78\\%p) top-1 accuracy improvement for image classification, 1.0 mAP for object detection. IPTQ-ViT outperforms partial floating-point PTQ methods under W8A8 and W4A8, and achieves accuracy and latency comparable to integer-only QAT methods. We plan to release our code this https URL.', 'abstract_zh': 'IPTQ-ViT：无需重新训练的全整数后训练量化视觉变压器', 'title_zh': 'IPTQ-ViT：仅整数视觉变换器的后训练量化非线性函数'}
{'arxiv_id': 'arXiv:2511.15369', 'title': 'IPTQ-ViT: Post-Training Quantization of Non-linear Functions for Integer-only Vision Transformers', 'authors': 'Gihwan Kim, Jemin Lee, Hyungshin Kim', 'link': 'https://arxiv.org/abs/2511.15369', 'abstract': 'Previous Quantization-Aware Training (QAT) methods for vision transformers rely on expensive retraining to recover accuracy loss in non-linear layer quantization, limiting their use in resource-constrained environments. In contrast, existing Post-Training Quantization (PTQ) methods either partially quantize non-linear functions or adjust activation distributions to maintain accuracy but fail to achieve fully integer-only inference. In this paper, we introduce IPTQ-ViT, a novel PTQ framework for fully integer-only vision transformers without retraining. We present approximation functions: a polynomial-based GELU optimized for vision data and a bit-shifting-based Softmax designed to improve approximation accuracy in PTQ. In addition, we propose a unified metric integrating quantization sensitivity, perturbation, and computational cost to select the optimal approximation function per activation layer. IPTQ-ViT outperforms previous PTQ methods, achieving up to 6.44\\%p (avg. 1.78\\%p) top-1 accuracy improvement for image classification, 1.0 mAP for object detection. IPTQ-ViT outperforms partial floating-point PTQ methods under W8A8 and W4A8, and achieves accuracy and latency comparable to integer-only QAT methods. We plan to release our code this https URL.', 'abstract_zh': 'IPTQ-ViT: 一种无需重训的完全整数推断视力变压器后训练量化框架', 'title_zh': 'IPTQ-ViT：仅整数视觉变换器的后训练量化nings'}
{'arxiv_id': 'arXiv:2511.15342', 'title': 'Reflexive Evidence-Based Multimodal Learning for Clean Energy Transitions: Causal Insights on Cooking Fuel Access, Urbanization, and Carbon Emissions', 'authors': 'Shan Shan', 'link': 'https://arxiv.org/abs/2511.15342', 'abstract': 'Achieving Sustainable Development Goal 7 (Affordable and Clean Energy) requires not only technological innovation but also a deeper understanding of the socioeconomic factors influencing energy access and carbon emissions. While these factors are gaining attention, critical questions remain, particularly regarding how to quantify their impacts on energy systems, model their cross-domain interactions, and capture feedback dynamics in the broader context of energy transitions. To address these gaps, this study introduces ClimateAgents, an AI-based framework that combines large language models with domain-specialized agents to support hypothesis generation and scenario exploration. Leveraging 20 years of socioeconomic and emissions data from 265 economies, countries and regions, and 98 indicators drawn from the World Bank database, the framework applies a machine learning based causal inference approach to identify key determinants of carbon emissions in an evidence-based, data driven manner. The analysis highlights three primary drivers: access to clean cooking fuels in rural areas, access to clean cooking fuels in urban areas, and the percentage of population living in urban areas. These findings underscore the critical role of clean cooking technologies and urbanization patterns in shaping emission outcomes. In line with growing calls for evidence-based AI policy, ClimateAgents offers a modular and reflexive learning system that supports the generation of credible and actionable insights for policy. By integrating heterogeneous data modalities, including structured indicators, policy documents, and semantic reasoning, the framework contributes to adaptive policymaking infrastructures that can evolve with complex socio-technical challenges. This approach aims to support a shift from siloed modeling to reflexive, modular systems designed for dynamic, context-aware climate action.', 'abstract_zh': '实现可持续发展目标7（负担得起和清洁能源）不仅需要技术创新，还需要更深入地理解影响能源获取和碳排放的经济社会因素。尽管这些因素正在引起关注，但仍存在关键问题，特别是如何量化其对能源系统的影响、建模跨域交互作用以及在能源转型的大背景下捕捉反馈动态。为弥补这些不足，本研究引入了ClimateAgents，这是一种结合大规模语言模型和领域专业化代理的人工智能框架，用于支持假设生成和情景探索。该框架利用世界银行数据库中265个经济体、国家和地区以及98个指标的20年经济社会和排放数据，采用基于机器学习的因果推理方法，以证据为基础、以数据为导向的方式识别关键的碳排放决定因素。分析指出三大主要驱动力：农村地区的清洁烹饪燃料接入、城市地区的清洁烹饪燃料接入以及城市人口占总人口的百分比。这些发现强调了清洁烹饪技术和城市化模式在塑造排放结果中的关键作用。遵循日益增长的基于证据的人工智能政策呼吁，ClimateAgents提供了一个模块化和反思性的学习系统，支持生成可靠且可操作的政策见解。通过整合异构数据模态，包括结构化指标、政策文件和语义推理，该框架为适应复杂的社会技术挑战提供了适应性政策制定基础设施。该方法旨在支持从孤立建模向反思性、模块化系统转变，这些系统旨在推动动态、情境感知的气候行动。', 'title_zh': '反思性证据驱动的多模态学习-clean能源转型：关于烹饪燃料 accessibility、城市化和碳排放的因果洞察'}
{'arxiv_id': 'arXiv:2511.15342', 'title': 'Reflexive Evidence-Based Multimodal Learning for Clean Energy Transitions: Causal Insights on Cooking Fuel Access, Urbanization, and Carbon Emissions', 'authors': 'Shan Shan', 'link': 'https://arxiv.org/abs/2511.15342', 'abstract': 'Achieving Sustainable Development Goal 7 (Affordable and Clean Energy) requires not only technological innovation but also a deeper understanding of the socioeconomic factors influencing energy access and carbon emissions. While these factors are gaining attention, critical questions remain, particularly regarding how to quantify their impacts on energy systems, model their cross-domain interactions, and capture feedback dynamics in the broader context of energy transitions. To address these gaps, this study introduces ClimateAgents, an AI-based framework that combines large language models with domain-specialized agents to support hypothesis generation and scenario exploration. Leveraging 20 years of socioeconomic and emissions data from 265 economies, countries and regions, and 98 indicators drawn from the World Bank database, the framework applies a machine learning based causal inference approach to identify key determinants of carbon emissions in an evidence-based, data driven manner. The analysis highlights three primary drivers: access to clean cooking fuels in rural areas, access to clean cooking fuels in urban areas, and the percentage of population living in urban areas. These findings underscore the critical role of clean cooking technologies and urbanization patterns in shaping emission outcomes. In line with growing calls for evidence-based AI policy, ClimateAgents offers a modular and reflexive learning system that supports the generation of credible and actionable insights for policy. By integrating heterogeneous data modalities, including structured indicators, policy documents, and semantic reasoning, the framework contributes to adaptive policymaking infrastructures that can evolve with complex socio-technical challenges. This approach aims to support a shift from siloed modeling to reflexive, modular systems designed for dynamic, context-aware climate action.', 'abstract_zh': '实现可持续发展目标7（负担得起的清洁能源）需要不仅技术创新，还需要更深入理解影响能源获取和社会经济因素对碳排放的影响。尽管这些因素正获得关注，但仍存在关键问题，特别是在如何量化其对能源系统的影响、建模跨域互动以及在能源转型的更广泛背景下捕捉反馈动态方面。为解决这些缺口，本研究引入了ClimateAgents，这是一种结合大型语言模型和领域专业化代理的AI框架，以支持假设生成和情景探索。基于世界银行数据库中265个经济体、国家和地区以及98个指标的20年社会经济和排放数据，该框架采用基于机器学习的因果推理方法，以证据为基础、数据驱动的方式识别碳排放的关键决定因素。分析结果显示，三大主要驱动因素分别是农村地区的清洁能源烹饪燃料获取、城市地区的清洁能源烹饪燃料获取以及城市人口占比。这些发现强调了清洁烹饪技术和城市化进程在塑造排放结果中的关键作用。为了响应对基于证据的AI政策的日益增长的呼吁，ClimateAgents 提供了一个模块化和反思性学习系统，支持生成可靠且可操作的政策见解。通过整合异构数据模态，包括结构化指标、政策文件和语义推理，该框架为适应复杂社会技术挑战的政策制定基础设施做出了贡献。这种方法旨在从孤立建模转向设计用于动态、情境感知气候行动的反思性、模块化系统。', 'title_zh': '反思性证据ベースの多模态学习在清洁能源转型中的作用：烹饪燃料获取、城市化进程与碳排放的因果洞察'}
{'arxiv_id': 'arXiv:2511.15342', 'title': 'Reflexive Evidence-Based Multimodal Learning for Clean Energy Transitions: Causal Insights on Cooking Fuel Access, Urbanization, and Carbon Emissions', 'authors': 'Shan Shan', 'link': 'https://arxiv.org/abs/2511.15342', 'abstract': 'Achieving Sustainable Development Goal 7 (Affordable and Clean Energy) requires not only technological innovation but also a deeper understanding of the socioeconomic factors influencing energy access and carbon emissions. While these factors are gaining attention, critical questions remain, particularly regarding how to quantify their impacts on energy systems, model their cross-domain interactions, and capture feedback dynamics in the broader context of energy transitions. To address these gaps, this study introduces ClimateAgents, an AI-based framework that combines large language models with domain-specialized agents to support hypothesis generation and scenario exploration. Leveraging 20 years of socioeconomic and emissions data from 265 economies, countries and regions, and 98 indicators drawn from the World Bank database, the framework applies a machine learning based causal inference approach to identify key determinants of carbon emissions in an evidence-based, data driven manner. The analysis highlights three primary drivers: access to clean cooking fuels in rural areas, access to clean cooking fuels in urban areas, and the percentage of population living in urban areas. These findings underscore the critical role of clean cooking technologies and urbanization patterns in shaping emission outcomes. In line with growing calls for evidence-based AI policy, ClimateAgents offers a modular and reflexive learning system that supports the generation of credible and actionable insights for policy. By integrating heterogeneous data modalities, including structured indicators, policy documents, and semantic reasoning, the framework contributes to adaptive policymaking infrastructures that can evolve with complex socio-technical challenges. This approach aims to support a shift from siloed modeling to reflexive, modular systems designed for dynamic, context-aware climate action.', 'abstract_zh': '实现可持续发展目标7（负担得起和清洁的能源）不仅需要技术创新，还需要更深入地理解影响能源获取和社会经济因素对碳排放的影响。尽管这些问题正在引起关注，但仍存在关键问题，特别是在如何量化这些因素对能源系统的影响、建模跨领域交互以及在能源转型的大背景下捕捉反馈动态方面。为填补这些空白，本研究引入了ClimateAgents，这是一种基于人工智能的框架，结合了大型语言模型和领域专业化代理，以支持假设生成和情景探索。该框架利用来自265个经济体、国家和地区以及世界银行数据库的98个指标的20年社会经济和排放数据，采用基于机器学习的因果推断方法，以证据和数据驱动的方式识别碳排放的关键决定因素。分析结果显示，主要驱动因素包括农村地区的清洁烹饪燃料访问、城市地区的清洁烹饪燃料访问以及城市人口占总人口的百分比。这些发现强调了清洁烹饪技术和城市化模式在塑造排放结果中的关键作用。为响应日益增多的证据驱动的人工智能政策呼吁，ClimateAgents提供了模块化和反思性学习系统，以生成可信和可操作的政策见解。通过整合异质数据模态，包括结构化指标、政策文件和语义推理，该框架促进了能够根据复杂的社会技术挑战而演变的适应性政策制定基础设施。这种方法旨在支持从孤立建模向适应动态、情境感知的气候行动的反思性、模块化系统的转变。', 'title_zh': '反思性证据驱动的多模态学习对于清洁能源转型：关于烹饪燃料 доступ、城市化和碳排放的因果洞察'}
{'arxiv_id': 'arXiv:2511.15339', 'title': 'STREAM-VAE: Dual-Path Routing for Slow and Fast Dynamics in Vehicle Telemetry Anomaly Detection', 'authors': 'Kadir-Kaan Özer, René Ebeling, Markus Enzweiler', 'link': 'https://arxiv.org/abs/2511.15339', 'abstract': 'Automotive telemetry data exhibits slow drifts and fast spikes, often within the same sequence, making reliable anomaly detection challenging. Standard reconstruction-based methods, including sequence variational autoencoders (VAEs), use a single latent process and therefore mix heterogeneous time scales, which can smooth out spikes or inflate variances and weaken anomaly separation.\nIn this paper, we present STREAM-VAE, a variational autoencoder for anomaly detection in automotive telemetry time-series data. Our model uses a dual-path encoder to separate slow drift and fast spike signal dynamics, and a decoder that represents transient deviations separately from the normal operating pattern. STREAM-VAE is designed for deployment, producing stable anomaly scores across operating modes for both in-vehicle monitors and backend fleet analytics.\nExperiments on an automotive telemetry dataset and the public SMD benchmark show that explicitly separating drift and spike dynamics improves robustness compared to strong forecasting, attention, graph, and VAE baselines.', 'abstract_zh': 'Automotive遥测数据表现出缓慢漂移和快速尖峰的特征，往往在同一序列中同时存在，使得可靠的异常检测颇具挑战。传统的基于重建的方法，包括序列变分自编码器（VAEs），采用单一的潜在过程，因此混合了不同的时间尺度，这可能会平滑掉尖峰或增加方差，从而削弱异常分离。\n\n本文提出STREAM-VAE，一种用于汽车遥测时间序列数据异常检测的变分自编码器。我们的模型使用双路径编码器将缓慢漂移和快速尖峰信号动力学区分开，并使用解码器将瞬态偏差从正常运行模式中分开。STREAM-VAE 旨在部署，能够在车内监控和后台车队分析中产生跨运行模式的稳定异常得分。\n\n实验结果表明，在汽车遥测数据集和公开的SMD基准测试中，明确分离漂移和尖峰动力学相比于强预测、注意力、图和VAE基线提高了鲁棒性。', 'title_zh': 'STREAM-VAE: 双路径路由用于车辆 telemetry 中缓慢和快速动态的异常检测'}
{'arxiv_id': 'arXiv:2511.15339', 'title': 'STREAM-VAE: Dual-Path Routing for Slow and Fast Dynamics in Vehicle Telemetry Anomaly Detection', 'authors': 'Kadir-Kaan Özer, René Ebeling, Markus Enzweiler', 'link': 'https://arxiv.org/abs/2511.15339', 'abstract': 'Automotive telemetry data exhibits slow drifts and fast spikes, often within the same sequence, making reliable anomaly detection challenging. Standard reconstruction-based methods, including sequence variational autoencoders (VAEs), use a single latent process and therefore mix heterogeneous time scales, which can smooth out spikes or inflate variances and weaken anomaly separation.\nIn this paper, we present STREAM-VAE, a variational autoencoder for anomaly detection in automotive telemetry time-series data. Our model uses a dual-path encoder to separate slow drift and fast spike signal dynamics, and a decoder that represents transient deviations separately from the normal operating pattern. STREAM-VAE is designed for deployment, producing stable anomaly scores across operating modes for both in-vehicle monitors and backend fleet analytics.\nExperiments on an automotive telemetry dataset and the public SMD benchmark show that explicitly separating drift and spike dynamics improves robustness compared to strong forecasting, attention, graph, and VAE baselines.', 'abstract_zh': '汽车遥测数据表现出慢漂移和快尖峰的现象，往往在同一序列中并存，使得可靠的异常检测颇具挑战。传统的基于重构的方法，包括序列变分自编码器（VAEs），使用单一的潜在过程，因此混合了不同的时间尺度，这可能会平滑掉尖峰或放大方差并削弱异常分离。\n\n在本文中，我们提出了一种用于汽车遥测时间序列数据异常检测的变分自编码器——STREAM-VAE。该模型采用双路径编码器将慢漂移和快尖峰信号动力学分离，并通过解码器将瞬态偏差与正常运行模式分开。STREAM-VAE 设计用于部署，在不同操作模式下为车载监控和后端车队分析生成稳定异常评分。\n\n实验结果表明，与强大的预测、注意力、图和VAE基线相比，明确分离漂移和尖峰动力学可以提高鲁棒性。', 'title_zh': 'STREAM-VAE：同时处理车辆遥测异常检测中的慢动态和快动态的双路径路由方法'}
{'arxiv_id': 'arXiv:2511.15339', 'title': 'STREAM-VAE: Dual-Path Routing for Slow and Fast Dynamics in Vehicle Telemetry Anomaly Detection', 'authors': 'Kadir-Kaan Özer, René Ebeling, Markus Enzweiler', 'link': 'https://arxiv.org/abs/2511.15339', 'abstract': 'Automotive telemetry data exhibits slow drifts and fast spikes, often within the same sequence, making reliable anomaly detection challenging. Standard reconstruction-based methods, including sequence variational autoencoders (VAEs), use a single latent process and therefore mix heterogeneous time scales, which can smooth out spikes or inflate variances and weaken anomaly separation.\nIn this paper, we present STREAM-VAE, a variational autoencoder for anomaly detection in automotive telemetry time-series data. Our model uses a dual-path encoder to separate slow drift and fast spike signal dynamics, and a decoder that represents transient deviations separately from the normal operating pattern. STREAM-VAE is designed for deployment, producing stable anomaly scores across operating modes for both in-vehicle monitors and backend fleet analytics.\nExperiments on an automotive telemetry dataset and the public SMD benchmark show that explicitly separating drift and spike dynamics improves robustness compared to strong forecasting, attention, graph, and VAE baselines.', 'abstract_zh': '汽车遥测数据表现出缓慢漂移和快速突变的特点，往往在同一序列中出现，这使得可靠的异常检测具有挑战性。标准的基于重构的方法，包括序列变异自编码器（VAEs），使用单一的潜在过程，因此会混合不同的时间尺度，这可能会平滑掉突变或夸大方差从而削弱异常区分。\n\n本文提出了一种名为STREAM-VAE的自编码器，用于汽车遥测时间序列数据中的异常检测。该模型采用双路径编码器以分离慢漂移和快突变的信号动态，并采用解码器将瞬态偏差与正常运行模式分开。STREAM-VAE旨在实现部署，能够跨不同运行模式生成稳健的异常评分，适用于车内监控和后端车队分析。\n\n实验结果表明，在汽车遥测数据集和公开的SMD基准上，明确分离漂移和突变动态相比强大的预测、注意力、图和VAE基线能够提高鲁棒性。', 'title_zh': 'STREAM-VAE：车辆 telemetry 异常检测中的慢动态和快动态双重路径路由'}
{'arxiv_id': 'arXiv:2511.15304', 'title': 'Adversarial Poetry as a Universal Single-Turn Jailbreak Mechanism in Large Language Models', 'authors': 'Piercosma Bisconti, Matteo Prandi, Federico Pierucci, Francesco Giarrusso, Marcantonio Bracale, Marcello Galisai, Vincenzo Suriani, Olga Sorokoletova, Federico Sartore, Daniele Nardi', 'link': 'https://arxiv.org/abs/2511.15304', 'abstract': 'We present evidence that adversarial poetry functions as a universal single-turn jailbreak technique for large language models (LLMs). Across 25 frontier proprietary and open-weight models, curated poetic prompts yielded high attack-success rates (ASR), with some providers exceeding 90%. Mapping prompts to MLCommons and EU CoP risk taxonomies shows that poetic attacks transfer across CBRN, manipulation, cyber-offence, and loss-of-control domains. Converting 1,200 MLCommons harmful prompts into verse via a standardized meta-prompt produced ASRs up to 18 times higher than their prose baselines. Outputs are evaluated using an ensemble of open-weight judge models and a human-validated stratified subset (with double-annotations to measure agreement). Disagreements were manually resolved. Poetic framing achieved an average jailbreak success rate of 62% for hand-crafted poems and approximately 43% for meta-prompt conversions (compared to non-poetic baselines), substantially outperforming non-poetic baselines and revealing a systematic vulnerability across model families and safety training approaches. These findings demonstrate that stylistic variation alone can circumvent contemporary safety mechanisms, suggesting fundamental limitations in current alignment methods and evaluation protocols.', 'abstract_zh': '我们展示了对抗诗歌作为一种通用单轮监狱突破技术，适用于大型语言模型（LLMs）。在25个前沿专有和开源权重模型中，精选的诗歌提示产生了高攻击成功率（ASR），部分提供者超过90%。将提示映射到MLCommons和EU CoP风险分类系统显示，诗歌攻击跨越了CBRN、操纵、网络进攻和失控领域。通过标准化元提示将1,200个MLCommons有害提示转化为诗歌，其攻击成功率比其散文基线最高提高了18倍。输出使用开放权重裁判模型集合以及经过人工验证的分层子集（带有双重注释以衡量一致性）进行评估。手动解决了分歧。诗歌框架对人工创作的诗歌实现了62%的平均监狱突破成功率，而对元提示转换的诗歌则约为43%（与非诗意基线相比），显著优于非诗意基线，揭示了模型家族和安全训练方法中的系统性脆弱性。这些发现表明，仅通过风格变异即可绕过当前的安全机制，暗示了目前对齐方法和评估协议的基本局限性。', 'title_zh': '对抗诗歌作为大型语言模型的通用单轮 jailbreak 机制'}
{'arxiv_id': 'arXiv:2511.15304', 'title': 'Adversarial Poetry as a Universal Single-Turn Jailbreak Mechanism in Large Language Models', 'authors': 'Piercosma Bisconti, Matteo Prandi, Federico Pierucci, Francesco Giarrusso, Marcantonio Bracale, Marcello Galisai, Vincenzo Suriani, Olga Sorokoletova, Federico Sartore, Daniele Nardi', 'link': 'https://arxiv.org/abs/2511.15304', 'abstract': 'We present evidence that adversarial poetry functions as a universal single-turn jailbreak technique for large language models (LLMs). Across 25 frontier proprietary and open-weight models, curated poetic prompts yielded high attack-success rates (ASR), with some providers exceeding 90%. Mapping prompts to MLCommons and EU CoP risk taxonomies shows that poetic attacks transfer across CBRN, manipulation, cyber-offence, and loss-of-control domains. Converting 1,200 MLCommons harmful prompts into verse via a standardized meta-prompt produced ASRs up to 18 times higher than their prose baselines. Outputs are evaluated using an ensemble of open-weight judge models and a human-validated stratified subset (with double-annotations to measure agreement). Disagreements were manually resolved. Poetic framing achieved an average jailbreak success rate of 62% for hand-crafted poems and approximately 43% for meta-prompt conversions (compared to non-poetic baselines), substantially outperforming non-poetic baselines and revealing a systematic vulnerability across model families and safety training approaches. These findings demonstrate that stylistic variation alone can circumvent contemporary safety mechanisms, suggesting fundamental limitations in current alignment methods and evaluation protocols.', 'abstract_zh': '我们提供了证据表明，对抗诗作为通用单轮监狱逃脱技术，适用于大型语言模型（LLMs）。在25个前沿 proprietary 和开放权重模型中，精心挑选的诗性提示产生了高攻击成功率（ASR），部分提供者超过90%。将提示映射到MLCommons和EU CoP风险分类学中，表明诗性攻击跨多重域（包括CBRN、操控、网络攻击和失控）具有转移性。通过标准化元提示将1,200个MLCommons有害提示转化为诗，其攻击成功率比其散文基线高多达18倍。输出通过集成的开放权重评判模型和经过人工验证的分层子集（附有双注释以衡量一致性的评估）进行评估。手动解决了偏差。诗性框架将手工创作的诗的监狱逃脱成功率平均提高至62%，元提示转换的诗性框架则约为43%，显著优于非诗性基线，揭示了模型家族和安全训练方法中的系统性漏洞。这些发现表明，仅通过样式上的变化即可绕过当前的安全机制，暗示了现有对齐方法和评估协议的固有限制。', 'title_zh': '对抗诗歌作为大型语言模型中的通用单轮 jailbreak 机制'}
{'arxiv_id': 'arXiv:2511.15304', 'title': 'Adversarial Poetry as a Universal Single-Turn Jailbreak Mechanism in Large Language Models', 'authors': 'Piercosma Bisconti, Matteo Prandi, Federico Pierucci, Francesco Giarrusso, Marcantonio Bracale, Marcello Galisai, Vincenzo Suriani, Olga Sorokoletova, Federico Sartore, Daniele Nardi', 'link': 'https://arxiv.org/abs/2511.15304', 'abstract': 'We present evidence that adversarial poetry functions as a universal single-turn jailbreak technique for large language models (LLMs). Across 25 frontier proprietary and open-weight models, curated poetic prompts yielded high attack-success rates (ASR), with some providers exceeding 90%. Mapping prompts to MLCommons and EU CoP risk taxonomies shows that poetic attacks transfer across CBRN, manipulation, cyber-offence, and loss-of-control domains. Converting 1,200 MLCommons harmful prompts into verse via a standardized meta-prompt produced ASRs up to 18 times higher than their prose baselines. Outputs are evaluated using an ensemble of open-weight judge models and a human-validated stratified subset (with double-annotations to measure agreement). Disagreements were manually resolved. Poetic framing achieved an average jailbreak success rate of 62% for hand-crafted poems and approximately 43% for meta-prompt conversions (compared to non-poetic baselines), substantially outperforming non-poetic baselines and revealing a systematic vulnerability across model families and safety training approaches. These findings demonstrate that stylistic variation alone can circumvent contemporary safety mechanisms, suggesting fundamental limitations in current alignment methods and evaluation protocols.', 'abstract_zh': '我们提供了证据表明对抗诗作为大型语言模型的通用单轮 jailbreak 技术。在25个前沿的商业和开源模型中，定制的诗化提示产生了较高的攻击成功率（ASR），部分提供者甚至超过了90%。将提示映射到MLCommons和EU CoP风险分类系统，显示诗化攻击在化学、生物、放射性、核生化（CBRN）、操控、网络攻击和失控等领域均有效。通过标准化元提示将1,200个MLCommons有害提示转化为诗，其攻击成功率比其散文基线高18倍。输出结果通过一组开源法官模型和人工验证的分层子集（带有双重注释以衡量一致性）进行评估。人工解决了分歧。诗化框架对手工创作的诗歌实现了平均62%的 jailbreak 成功率，而元提示转化的诗歌约为43%，显著优于非诗化基线，揭示了模型家族和安全训练方法系统性的脆弱性。这些发现表明仅通过风格变化即可规避当前的安全机制，暗示现有的对齐方法和评估协议存在根本性的局限性。', 'title_zh': '对抗诗文作为大型语言模型的通用单轮囚徒突变机制'}
{'arxiv_id': 'arXiv:2511.15284', 'title': 'Path Planning through Multi-Agent Reinforcement Learning in Dynamic Environments', 'authors': 'Jonas De Maeyer, Hossein Yarahmadi, Moharram Challenger', 'link': 'https://arxiv.org/abs/2511.15284', 'abstract': 'Path planning in dynamic environments is a fundamental challenge in intelligent transportation and robotics, where obstacles and conditions change over time, introducing uncertainty and requiring continuous adaptation. While existing approaches often assume complete environmental unpredictability or rely on global planners, these assumptions limit scalability and practical deployment in real-world settings. In this paper, we propose a scalable, region-aware reinforcement learning (RL) framework for path planning in dynamic environments. Our method builds on the observation that environmental changes, although dynamic, are often localized within bounded regions. To exploit this, we introduce a hierarchical decomposition of the environment and deploy distributed RL agents that adapt to changes locally. We further propose a retraining mechanism based on sub-environment success rates to determine when policy updates are necessary. Two training paradigms are explored: single-agent Q-learning and multi-agent federated Q-learning, where local Q-tables are aggregated periodically to accelerate the learning process. Unlike prior work, we evaluate our methods in more realistic settings, where multiple simultaneous obstacle changes and increasing difficulty levels are present. Results show that the federated variants consistently outperform their single-agent counterparts and closely approach the performance of A* Oracle while maintaining shorter adaptation times and robust scalability. Although initial training remains time-consuming in large environments, our decentralized framework eliminates the need for a global planner and lays the groundwork for future improvements using deep RL and flexible environment decomposition.', 'abstract_zh': '在动态环境中的路径规划是智能交通和机器人技术中的一项基本挑战，其中障碍物和条件会随时间变化，引入不确定性并要求持续适应。现有方法常假设环境完全不可预测或依赖全局规划器，这些假设限制了在实际场景中的可扩展性和实用性。本文提出了一种适用于动态环境的层次化区域感知强化学习（RL）框架，用于路径规划。我们的方法基于观察到的环境变化虽然动态，但通常局限于有限的区域内。为此，我们提出了环境的层次化分解，并部署了能够局部适应变化的分布式RL代理。进一步提出了基于子环境成功率的重训练机制，以确定何时需要更新策略。探讨了两种训练范式：单代理Q学习和多代理联邦Q学习，其中局部Q表会定期聚合以加速学习过程。与先前工作不同，我们是在包含多个同时障碍变化和提高难度级别的更现实场景中评估我们的方法。结果表明，联邦变体始终优于单代理变体，并且在保持更短的适应时间和稳健可扩展性的同时接近A* Oracle的性能。尽管在大型环境中初始训练仍耗时较长，但我们的去中心化框架消除了对全局规划器的需求，并为未来使用深度RL和灵活环境分解的改进奠定了基础。', 'title_zh': '动态环境中文多Agent强化学习路径规划'}
{'arxiv_id': 'arXiv:2511.15284', 'title': 'Path Planning through Multi-Agent Reinforcement Learning in Dynamic Environments', 'authors': 'Jonas De Maeyer, Hossein Yarahmadi, Moharram Challenger', 'link': 'https://arxiv.org/abs/2511.15284', 'abstract': 'Path planning in dynamic environments is a fundamental challenge in intelligent transportation and robotics, where obstacles and conditions change over time, introducing uncertainty and requiring continuous adaptation. While existing approaches often assume complete environmental unpredictability or rely on global planners, these assumptions limit scalability and practical deployment in real-world settings. In this paper, we propose a scalable, region-aware reinforcement learning (RL) framework for path planning in dynamic environments. Our method builds on the observation that environmental changes, although dynamic, are often localized within bounded regions. To exploit this, we introduce a hierarchical decomposition of the environment and deploy distributed RL agents that adapt to changes locally. We further propose a retraining mechanism based on sub-environment success rates to determine when policy updates are necessary. Two training paradigms are explored: single-agent Q-learning and multi-agent federated Q-learning, where local Q-tables are aggregated periodically to accelerate the learning process. Unlike prior work, we evaluate our methods in more realistic settings, where multiple simultaneous obstacle changes and increasing difficulty levels are present. Results show that the federated variants consistently outperform their single-agent counterparts and closely approach the performance of A* Oracle while maintaining shorter adaptation times and robust scalability. Although initial training remains time-consuming in large environments, our decentralized framework eliminates the need for a global planner and lays the groundwork for future improvements using deep RL and flexible environment decomposition.', 'abstract_zh': '动态环境中基于区域意识的强化学习路径规划', 'title_zh': '动态环境中的多智能体强化学习路径规划'}
{'arxiv_id': 'arXiv:2511.15284', 'title': 'Path Planning through Multi-Agent Reinforcement Learning in Dynamic Environments', 'authors': 'Jonas De Maeyer, Hossein Yarahmadi, Moharram Challenger', 'link': 'https://arxiv.org/abs/2511.15284', 'abstract': 'Path planning in dynamic environments is a fundamental challenge in intelligent transportation and robotics, where obstacles and conditions change over time, introducing uncertainty and requiring continuous adaptation. While existing approaches often assume complete environmental unpredictability or rely on global planners, these assumptions limit scalability and practical deployment in real-world settings. In this paper, we propose a scalable, region-aware reinforcement learning (RL) framework for path planning in dynamic environments. Our method builds on the observation that environmental changes, although dynamic, are often localized within bounded regions. To exploit this, we introduce a hierarchical decomposition of the environment and deploy distributed RL agents that adapt to changes locally. We further propose a retraining mechanism based on sub-environment success rates to determine when policy updates are necessary. Two training paradigms are explored: single-agent Q-learning and multi-agent federated Q-learning, where local Q-tables are aggregated periodically to accelerate the learning process. Unlike prior work, we evaluate our methods in more realistic settings, where multiple simultaneous obstacle changes and increasing difficulty levels are present. Results show that the federated variants consistently outperform their single-agent counterparts and closely approach the performance of A* Oracle while maintaining shorter adaptation times and robust scalability. Although initial training remains time-consuming in large environments, our decentralized framework eliminates the need for a global planner and lays the groundwork for future improvements using deep RL and flexible environment decomposition.', 'abstract_zh': '在动态环境中的路径规划是智能交通和机器人领域的基本挑战，其中障碍物和条件会随时间变化，引入不确定性并需要持续适应。现有方法通常假设环境完全不可预测或依赖全局规划器，这些假设限制了在实际环境中的可扩展性和部署。本文提出了一种适用于动态环境的可扩展、区域aware的强化学习（RL）路径规划框架。我们的方法基于对环境变化虽然动态但通常局限于限定区域的观察。为此，我们引入了环境的分层分解，并部署了分布式RL代理以当地适应变化。进一步提出了一种基于子环境成功率的重新训练机制，用于确定策略更新的必要性。探索了两种训练范式：单代理Q学习和多代理联邦Q学习，其中局部Q表定期聚合以加速学习过程。与现有工作不同，我们将在包含多个同时障碍变化和增加难度级别的更现实环境中评估我们的方法。结果表明，联邦变体始终优于单代理变体，并且在维护更短的适应时间和稳健的可扩展性的同时接近A* Oracle的性能。尽管在大环境中初始训练仍然耗时，但我们的去中心化框架消除了需要全局规划器的需求，并为未来使用深度RL和灵活的环境分解进行了改进打下了基础。', 'title_zh': '动态环境中的多智能体强化学习路径规划'}
{'arxiv_id': 'arXiv:2511.15274', 'title': 'Behavior Trees vs Executable Ontologies: a Comparative Analysis of Robot Control Paradigms', 'authors': 'Alexander Boldachev', 'link': 'https://arxiv.org/abs/2511.15274', 'abstract': 'This paper compares two distinct approaches to modeling robotic behavior: imperative Behavior Trees (BTs) and declarative Executable Ontologies (EO), implemented through the boldsea framework. BTs structure behavior hierarchically using control-flow, whereas EO represents the domain as a temporal, event-based semantic graph driven by dataflow rules. We demonstrate that EO achieves comparable reactivity and modularity to BTs through a fundamentally different architecture: replacing polling-based tick execution with event-driven state propagation. We propose that EO offers an alternative framework, moving from procedural programming to semantic domain modeling, to address the semantic-process gap in traditional robotic control. EO supports runtime model modification, full temporal traceability, and a unified representation of data, logic, and interface - features that are difficult or sometimes impossible to achieve with BTs, although BTs excel in established, predictable scenarios. The comparison is grounded in a practical mobile manipulation task. This comparison highlights the respective operational strengths of each approach in dynamic, evolving robotic systems.', 'abstract_zh': '本文比较了两种不同的机器人行为建模方法：命令式行为树（BTs）和声明式执行本体论（EO），并通过boldsea框架实现。行为树采用控制流将行为分层结构化，而执行本体论以数据流规则驱动的时间事件基语义图来表示领域。我们通过一种从根本上不同的架构，展示了EO在反应性和模块性方面能达到与BTs相当的水平：使用事件驱动的状态传播替代基于轮询的周期执行。我们提出，执行本体论提供了一种替代框架，从过程化编程转向语义领域建模，以弥补传统机器人控制中的语义-过程差距。执行本体论支持运行时模型修改、完整的时序可追溯性以及数据、逻辑和接口的一体化表示 - 虽然行为树在传统上在已建立且可预测的场景中表现出色，但这些功能在行为树中难以实现或有时是不可能实现的。本文的比较基于一个实际的移动操作任务。这种比较突显了每种方法在动态演化的机器人系统中的各自操作优势。', 'title_zh': '行为树 vs 可执行本体：机器人控制范式的比较分析'}
{'arxiv_id': 'arXiv:2511.15274', 'title': 'Behavior Trees vs Executable Ontologies: a Comparative Analysis of Robot Control Paradigms', 'authors': 'Alexander Boldachev', 'link': 'https://arxiv.org/abs/2511.15274', 'abstract': 'This paper compares two distinct approaches to modeling robotic behavior: imperative Behavior Trees (BTs) and declarative Executable Ontologies (EO), implemented through the boldsea framework. BTs structure behavior hierarchically using control-flow, whereas EO represents the domain as a temporal, event-based semantic graph driven by dataflow rules. We demonstrate that EO achieves comparable reactivity and modularity to BTs through a fundamentally different architecture: replacing polling-based tick execution with event-driven state propagation. We propose that EO offers an alternative framework, moving from procedural programming to semantic domain modeling, to address the semantic-process gap in traditional robotic control. EO supports runtime model modification, full temporal traceability, and a unified representation of data, logic, and interface - features that are difficult or sometimes impossible to achieve with BTs, although BTs excel in established, predictable scenarios. The comparison is grounded in a practical mobile manipulation task. This comparison highlights the respective operational strengths of each approach in dynamic, evolving robotic systems.', 'abstract_zh': '本文比较了两种不同的机器人行为建模方法：命令式的Behavior Trees (BTs)和声明式的Executable Ontologies (EO)，并通过boldsea框架实现。BTs通过控制流将行为分层结构化，而EO则通过数据流规则表示领域为基于事件的时间语义图。我们通过根本不同的架构展示了EO能够达到与BTs相当的反应性和模块性：用事件驱动的状态传播替换基于轮询的时钟执行。我们提出，EO提供了一种替代框架，从过程编程转向语义领域建模，以解决传统机器人控制中的语义-过程差距。EO支持运行时模型修改、完整的时态可追踪性以及数据、逻辑和界面的统一表示——这些功能在某些情况下对于BTs来说难以实现或根本无法实现，尽管BTs在传统的、可预测的场景中表现出色。此比较基于一个实际的移动操作任务。该比较突显了每种方法在动态演变的机器人系统中的各自操作优势。', 'title_zh': '行为树 vs 可执行本体：机器人控制范式的比较分析'}
{'arxiv_id': 'arXiv:2511.15253', 'title': 'PresentCoach: Dual-Agent Presentation Coaching through Exemplars and Interactive Feedback', 'authors': 'Sirui Chen, Jinsong Zhou, Xinli Xu, Xiaoyu Yang, Litao Guo, Ying-Cong Chen', 'link': 'https://arxiv.org/abs/2511.15253', 'abstract': 'Effective presentation skills are essential in education, professional communication, and public speaking, yet learners often lack access to high-quality exemplars or personalized coaching. Existing AI tools typically provide isolated functionalities such as speech scoring or script generation without integrating reference modeling and interactive feedback into a cohesive learning experience. We introduce a dual-agent system that supports presentation practice through two complementary roles: the Ideal Presentation Agent and the Coach Agent. The Ideal Presentation Agent converts user-provided slides into model presentation videos by combining slide processing, visual-language analysis, narration script generation, personalized voice synthesis, and synchronized video assembly. The Coach Agent then evaluates user-recorded presentations against these exemplars, conducting multimodal speech analysis and delivering structured feedback in an Observation-Impact-Suggestion (OIS) format. To enhance the authenticity of the learning experience, the Coach Agent incorporates an Audience Agent, which simulates the perspective of a human listener and provides humanized feedback reflecting audience reactions and engagement. Together, these agents form a closed loop of observation, practice, and feedback. Implemented on a robust backend with multi-model integration, voice cloning, and error handling mechanisms, the system demonstrates how AI-driven agents can provide engaging, human-centered, and scalable support for presentation skill development in both educational and professional contexts.', 'abstract_zh': '有效的演示技能是教育、专业沟通和公共演讲中不可或缺的，然而学习者通常缺乏高质量的范例或个性化的指导。现有AI工具通常提供孤立的功能，如语音评分或脚本生成，而未能将参考建模和互动反馈整合到一个连贯的学习体验中。我们引入了一个双代理系统，通过两种互补的角色支持演示练习：理想演示代理和教练代理。理想演示代理通过结合幻灯片处理、视觉语言分析、叙述脚本生成、个性化语音合成和同步视频组装，将用户提供的幻灯片转换为模型演示视频。随后，教练代理评估用户录制的演示，与这些范例进行对比，进行多模态语音分析，并以观察-影响-建议(OIS)格式提供结构化反馈。为增强学习体验的真实性，教练代理整合了观众代理，模拟人类听众的视角，提供反映观众反应和参与的人性化反馈。这些代理共同形成一个观察、练习和反馈的闭环。该系统基于强大的后端架构，实现了多模型集成、语音克隆和错误处理机制，展示了如何通过AI驱动的代理在教育和专业情境中为演示技能发展提供吸引人、以人为中心且可扩展的支持。', 'title_zh': 'PresentCoach: 基于范例和交互反馈的双智能体呈现辅导'}
{'arxiv_id': 'arXiv:2511.15253', 'title': 'PresentCoach: Dual-Agent Presentation Coaching through Exemplars and Interactive Feedback', 'authors': 'Sirui Chen, Jinsong Zhou, Xinli Xu, Xiaoyu Yang, Litao Guo, Ying-Cong Chen', 'link': 'https://arxiv.org/abs/2511.15253', 'abstract': 'Effective presentation skills are essential in education, professional communication, and public speaking, yet learners often lack access to high-quality exemplars or personalized coaching. Existing AI tools typically provide isolated functionalities such as speech scoring or script generation without integrating reference modeling and interactive feedback into a cohesive learning experience. We introduce a dual-agent system that supports presentation practice through two complementary roles: the Ideal Presentation Agent and the Coach Agent. The Ideal Presentation Agent converts user-provided slides into model presentation videos by combining slide processing, visual-language analysis, narration script generation, personalized voice synthesis, and synchronized video assembly. The Coach Agent then evaluates user-recorded presentations against these exemplars, conducting multimodal speech analysis and delivering structured feedback in an Observation-Impact-Suggestion (OIS) format. To enhance the authenticity of the learning experience, the Coach Agent incorporates an Audience Agent, which simulates the perspective of a human listener and provides humanized feedback reflecting audience reactions and engagement. Together, these agents form a closed loop of observation, practice, and feedback. Implemented on a robust backend with multi-model integration, voice cloning, and error handling mechanisms, the system demonstrates how AI-driven agents can provide engaging, human-centered, and scalable support for presentation skill development in both educational and professional contexts.', 'abstract_zh': '有效的演示技能在教育、专业沟通和公众演讲中至关重要，然而学习者往往缺乏高质量的范本或个性化指导。现有AI工具通常仅提供孤立的功能，如语音评分或脚本生成，而不将参考模型和互动反馈整合到连贯的学习体验中。我们介绍了一种双agent系统，通过两种互补的角色支持演示实践：理想的演示agent和教练agent。理想的演示agent通过结合幻灯片处理、视觉语言分析、叙述脚本生成、个性化语音合成和同步视频组装，将用户提供的幻灯片转换成模型演示视频。教练agent随后评估用户录制的演示，进行多模态语音分析，并以观察-影响-建议（OIS）格式提供结构化的反馈。为了增强学习体验的真实性，教练agent融入了观众agent，该agent模拟了人类听众的视角，并提供了反映观众反应和参与度的人性化反馈。这些代理共同形成了一个观察、实践和反馈的闭环。在强大的后端基础设施上实现，集成了多模型集成、语音克隆和错误处理机制，该系统展示了如何通过AI驱动的代理为教育和专业领域中的演示技能发展提供引人入胜、以人类为中心和可扩展的支持。', 'title_zh': '基于示例和互动反馈的双代理演示指导'}
{'arxiv_id': 'arXiv:2511.15274', 'title': 'Behavior Trees vs Executable Ontologies: a Comparative Analysis of Robot Control Paradigms', 'authors': 'Alexander Boldachev', 'link': 'https://arxiv.org/abs/2511.15274', 'abstract': 'This paper compares two distinct approaches to modeling robotic behavior: imperative Behavior Trees (BTs) and declarative Executable Ontologies (EO), implemented through the boldsea framework. BTs structure behavior hierarchically using control-flow, whereas EO represents the domain as a temporal, event-based semantic graph driven by dataflow rules. We demonstrate that EO achieves comparable reactivity and modularity to BTs through a fundamentally different architecture: replacing polling-based tick execution with event-driven state propagation. We propose that EO offers an alternative framework, moving from procedural programming to semantic domain modeling, to address the semantic-process gap in traditional robotic control. EO supports runtime model modification, full temporal traceability, and a unified representation of data, logic, and interface - features that are difficult or sometimes impossible to achieve with BTs, although BTs excel in established, predictable scenarios. The comparison is grounded in a practical mobile manipulation task. This comparison highlights the respective operational strengths of each approach in dynamic, evolving robotic systems.', 'abstract_zh': '本文比较了两种不同的机器人行为建模方法：命令式行为树（BT）和声明式可执行本体（EO），并通过boldsea框架实现。行为树使用控制流来层次结构化行为，而可执行本体通过数据流规则表示领域，作为基于事件的时序语义图。我们通过根本不同的架构展示，EO 在实现类似于 BT 的反应性和模块性方面具有竞争力：用基于事件的状态传播替代了轮询驱动的时钟执行。我们提出，EO 提供了一种替代框架，从过程性编程转向语义领域建模，以解决传统机器人控制中的语义-过程差距。可执行本体支持运行时模型修改、完整的时序可追溯性和数据、逻辑和接口的统一表示 - 这些特性在行为树中难以实现，尽管行为树在既定和可预测的场景中表现出色。比较是在一个实际的移动操作任务中进行的。本文比较突显了每种方法在动态、演变的机器人系统中的各自操作优势。', 'title_zh': '行为树 vs 可执行本体：机器人控制范式的比较分析'}
{'arxiv_id': 'arXiv:2511.15248', 'title': 'EntroPIC: Towards Stable Long-Term Training of LLMs via Entropy Stabilization with Proportional-Integral Control', 'authors': 'Kai Yang, Xin Xu, Yangkun Chen, Weijie Liu, Jiafei Lyu, Zichuan Lin, Deheng Ye, Saiyong Yang', 'link': 'https://arxiv.org/abs/2511.15248', 'abstract': 'Long-term training of large language models (LLMs) requires maintaining stable exploration to prevent the model from collapsing into sub-optimal behaviors. Entropy is crucial in this context, as it controls exploration and helps avoid premature convergence to sub-optimal solutions. However, existing reinforcement learning methods struggle to maintain an appropriate level of entropy, as the training process involves a mix of positive and negative samples, each affecting entropy in different ways across steps. To address this, we propose Entropy stablilization via Proportional-Integral Control (EntroPIC), a novel method that adaptively adjusts the influence of positive and negative samples by dynamically tuning their loss coefficients. This approach stabilizes entropy throughout training, ensuring efficient exploration and steady progress. We provide a comprehensive theoretical analysis for both on-policy and off-policy learning settings, demonstrating that EntroPIC is effective at controlling entropy in large-scale LLM training. Experimental results show that our method successfully maintains desired entropy levels, enabling stable and optimal RL training for LLMs.', 'abstract_zh': '长时间训练大规模语言模型（LLMs）需要维持稳定的探索以防止模型陷入次优行为。熵在此过程中至关重要，因为它控制着探索并帮助避免过早收敛到次优解。然而，现有的强化学习方法难以维持适当的熵水平，因为训练过程涉及正样本和负样本的混合，它们在不同步骤中以不同的方式影响熵。为此，我们提出了一种新的方法——熵稳定化通过比例积分控制（EntroPIC），该方法通过动态调整正样本和负样本的损失系数来适应性地调整它们的影响。这种方法在整个训练过程中稳定熵，确保高效的探索和稳定的进展。我们为在策略学习和离策略学习设置中提供了全面的理论分析，证明EntroPIC能够在大规模LLM训练中有效控制熵。实验结果表明，我们的方法成功地维持了所需的熵水平，使大规模LLM的稳定和优化的RL训练成为可能。', 'title_zh': 'EntroPIC：通过熵稳定化和比例积分控制实现大型语言模型的稳定长期训练'}
{'arxiv_id': 'arXiv:2511.15248', 'title': 'EntroPIC: Towards Stable Long-Term Training of LLMs via Entropy Stabilization with Proportional-Integral Control', 'authors': 'Kai Yang, Xin Xu, Yangkun Chen, Weijie Liu, Jiafei Lyu, Zichuan Lin, Deheng Ye, Saiyong Yang', 'link': 'https://arxiv.org/abs/2511.15248', 'abstract': 'Long-term training of large language models (LLMs) requires maintaining stable exploration to prevent the model from collapsing into sub-optimal behaviors. Entropy is crucial in this context, as it controls exploration and helps avoid premature convergence to sub-optimal solutions. However, existing reinforcement learning methods struggle to maintain an appropriate level of entropy, as the training process involves a mix of positive and negative samples, each affecting entropy in different ways across steps. To address this, we propose Entropy stablilization via Proportional-Integral Control (EntroPIC), a novel method that adaptively adjusts the influence of positive and negative samples by dynamically tuning their loss coefficients. This approach stabilizes entropy throughout training, ensuring efficient exploration and steady progress. We provide a comprehensive theoretical analysis for both on-policy and off-policy learning settings, demonstrating that EntroPIC is effective at controlling entropy in large-scale LLM training. Experimental results show that our method successfully maintains desired entropy levels, enabling stable and optimal RL training for LLMs.', 'abstract_zh': '长期内存训练大型语言模型（LLMs）需要保持稳定的探索以防止模型陷入次优行为。熵在此过程中至关重要，因为它控制着探索并帮助避免过早收敛到次优解。然而，现有的强化学习方法难以维持适当的熵水平，因为训练过程包含正样本和负样本，它们在不同步长上以不同的方式影响熵。为此，我们提出了一种新型方法——基于比例积分控制的熵稳定化（EntroPIC），该方法通过动态调整正负样本的影响factor，即动态调整它们的损失系数来进行自适应调整。该方法在整个训练过程中稳定熵，确保高效的探索和稳定的进步。我们提供了针对有策略和无策略学习设置的全面理论分析，证明了EntroPIC在大规模LLMs训练中有效控制熵。实验结果表明，我们的方法能够成功维持所需的熵水平，从而实现LLMs的稳定和最优强化学习训练。', 'title_zh': 'EntroPIC: 通过熵稳定性和比例积分控制实现大规模语言模型长期训练的稳定性'}
{'arxiv_id': 'arXiv:2511.15253', 'title': 'PresentCoach: Dual-Agent Presentation Coaching through Exemplars and Interactive Feedback', 'authors': 'Sirui Chen, Jinsong Zhou, Xinli Xu, Xiaoyu Yang, Litao Guo, Ying-Cong Chen', 'link': 'https://arxiv.org/abs/2511.15253', 'abstract': 'Effective presentation skills are essential in education, professional communication, and public speaking, yet learners often lack access to high-quality exemplars or personalized coaching. Existing AI tools typically provide isolated functionalities such as speech scoring or script generation without integrating reference modeling and interactive feedback into a cohesive learning experience. We introduce a dual-agent system that supports presentation practice through two complementary roles: the Ideal Presentation Agent and the Coach Agent. The Ideal Presentation Agent converts user-provided slides into model presentation videos by combining slide processing, visual-language analysis, narration script generation, personalized voice synthesis, and synchronized video assembly. The Coach Agent then evaluates user-recorded presentations against these exemplars, conducting multimodal speech analysis and delivering structured feedback in an Observation-Impact-Suggestion (OIS) format. To enhance the authenticity of the learning experience, the Coach Agent incorporates an Audience Agent, which simulates the perspective of a human listener and provides humanized feedback reflecting audience reactions and engagement. Together, these agents form a closed loop of observation, practice, and feedback. Implemented on a robust backend with multi-model integration, voice cloning, and error handling mechanisms, the system demonstrates how AI-driven agents can provide engaging, human-centered, and scalable support for presentation skill development in both educational and professional contexts.', 'abstract_zh': '有效的プレゼンテーションスキルは教育、専門的なコミュニケーション、および公開スピーチにおいて重要であり、しかし多くの学習者は高品質のモデルや個別的な指導にアクセスできません。既存のAIツールは通常、スピーチ検証やスクリプト生成など個别的機能を提供し、引用モデルや互动反馈的整合性学习体验中缺少集成。我们介绍了一个双代理系统，通过互补的角色支持演示实践：理想演示代理和教练代理。理想演示代理通过结合幻灯片处理、视觉语言分析、叙述脚本生成、个性化语音合成以及同步视频编排，将用户提供的幻灯片转换为模型演示视频。接着，教练代理根据这些模型评估用户录制的演示，进行多模态语音分析，并以观察-影响-建议(OIS)格式提供结构化反馈。为了增强学习体验的真实性，教练代理引入了观众代理，模拟人类听众的视角并向用户提供反映观众反应和参与度的人性化反馈。这些代理共同形成了观察、练习和反馈的闭环。在具有多模型集成、语音克隆和错误处理机制的坚固后端实现下，该系统展示了如何通过AI驱动的代理为教育和专业背景下演示技能的发展提供富有吸引力、以人文为中心且可扩展的支持。', 'title_zh': '现时教练：通过范例与互动反馈的双重代理呈现指导'}
{'arxiv_id': 'arXiv:2511.15211', 'title': 'OEMA: Ontology-Enhanced Multi-Agent Collaboration Framework for Zero-Shot Clinical Named Entity Recognition', 'authors': 'Xinli Tao, Xin Dong, Xuezhong Zhou', 'link': 'https://arxiv.org/abs/2511.15211', 'abstract': "Clinical named entity recognition (NER) is crucial for extracting information from electronic health records (EHRs), but supervised models like CRF and BioClinicalBERT require costly annotated data. While zero-shot NER with large language models (LLMs) reduces this dependency, it struggles with example selection granularity and integrating prompts with self-improvement. To address this, we propose OEMA, a zero-shot clinical NER framework using multi-agent collaboration. OEMA's three components are: a self-annotator generating examples, a discriminator filtering them via SNOMED CT, and a predictor using entity descriptions for accurate inference. On MTSamples and VAERS datasets, OEMA achieves state-of-the-art exact-match performance. Under related-match, it matches supervised BioClinicalBERT and surpasses CRF. OEMA addresses key zero-shot NER challenges through ontology-guided reasoning and multi-agent collaboration, achieving near-supervised performance and showing promise for clinical NLP applications.", 'abstract_zh': '基于多智能体协作的零样本临床命名实体识别框架', 'title_zh': 'OEMA：基于本体增强的多agent协作框架，用于零样本临床命名实体识别'}
{'arxiv_id': 'arXiv:2511.15211', 'title': 'OEMA: Ontology-Enhanced Multi-Agent Collaboration Framework for Zero-Shot Clinical Named Entity Recognition', 'authors': 'Xinli Tao, Xin Dong, Xuezhong Zhou', 'link': 'https://arxiv.org/abs/2511.15211', 'abstract': "Clinical named entity recognition (NER) is crucial for extracting information from electronic health records (EHRs), but supervised models like CRF and BioClinicalBERT require costly annotated data. While zero-shot NER with large language models (LLMs) reduces this dependency, it struggles with example selection granularity and integrating prompts with self-improvement. To address this, we propose OEMA, a zero-shot clinical NER framework using multi-agent collaboration. OEMA's three components are: a self-annotator generating examples, a discriminator filtering them via SNOMED CT, and a predictor using entity descriptions for accurate inference. On MTSamples and VAERS datasets, OEMA achieves state-of-the-art exact-match performance. Under related-match, it matches supervised BioClinicalBERT and surpasses CRF. OEMA addresses key zero-shot NER challenges through ontology-guided reasoning and multi-agent collaboration, achieving near-supervised performance and showing promise for clinical NLP applications.", 'abstract_zh': '临床命名实体识别（NER）对于从电子健康记录（EHRs）中提取信息至关重要，但监督模型如CRF和BioClinicalBERT需要昂贵的标注数据。而利用大规模语言模型（LLMs）的零样本NER在减少这种依赖性的同时，难以在示例选择粒度上取得突破，并且难以整合提示与自我提升。为解决这一问题，我们提出了一种名为OEMA的基于多智能体协作的零样本临床NER框架。OEMA的三个组成部分包括：自标注生成器生成示例、鉴别器通过SNOMED CT进行过滤以及使用实体描述进行准确推断的预测器。在MTSamples和VAERS数据集上，OEMA实现了最先进的精确匹配性能。在相关匹配下，OEMA匹配并超过了监督的BioClinicalBERT，并超越了CRF。OEMA通过本体指导推理和多智能体协作解决了关键的零样本NER挑战，实现了接近监督性能，并展现出了在临床NLP应用中的潜力。', 'title_zh': '基于本体增强的多agent协作框架：零样本临床命名实体识别'}
{'arxiv_id': 'arXiv:2511.15248', 'title': 'EntroPIC: Towards Stable Long-Term Training of LLMs via Entropy Stabilization with Proportional-Integral Control', 'authors': 'Kai Yang, Xin Xu, Yangkun Chen, Weijie Liu, Jiafei Lyu, Zichuan Lin, Deheng Ye, Saiyong Yang', 'link': 'https://arxiv.org/abs/2511.15248', 'abstract': 'Long-term training of large language models (LLMs) requires maintaining stable exploration to prevent the model from collapsing into sub-optimal behaviors. Entropy is crucial in this context, as it controls exploration and helps avoid premature convergence to sub-optimal solutions. However, existing reinforcement learning methods struggle to maintain an appropriate level of entropy, as the training process involves a mix of positive and negative samples, each affecting entropy in different ways across steps. To address this, we propose Entropy stablilization via Proportional-Integral Control (EntroPIC), a novel method that adaptively adjusts the influence of positive and negative samples by dynamically tuning their loss coefficients. This approach stabilizes entropy throughout training, ensuring efficient exploration and steady progress. We provide a comprehensive theoretical analysis for both on-policy and off-policy learning settings, demonstrating that EntroPIC is effective at controlling entropy in large-scale LLM training. Experimental results show that our method successfully maintains desired entropy levels, enabling stable and optimal RL training for LLMs.', 'abstract_zh': '长周期训练大规模语言模型（LLMs）需要保持稳定的探索以防止模型陷入亚最优行为。熵在这个过程中至关重要，因为它控制探索并帮助避免过早收敛到亚最优解。然而，现有的强化学习方法难以维持适当的熵水平，因为训练过程涉及正样本和负样本的混合，它们在不同步骤中以不同的方式影响熵。为了解决这一问题，我们提出了一种新的方法——基于比例积分控制的熵稳定化（EntroPIC），该方法通过动态调整正样本和负样本的损失系数来适应性地调整它们的影响。这种方法在整个训练过程中稳定熵，确保高效的探索并实现稳步进展。我们提供了针对在线策略和离线策略学习环境的全面理论分析，证明了EntroPIC在大规模LLM训练中有效控制熵的能力。实验结果表明，我们的方法能够成功维持所需的熵水平，从而实现LLMs的稳定和最优的RL训练。', 'title_zh': 'EntroPIC: 通过比例积分控制实现熵稳定训练的长期稳定预训练语言模型'}
{'arxiv_id': 'arXiv:2511.15210', 'title': 'Unveiling Intrinsic Dimension of Texts: from Academic Abstract to Creative Story', 'authors': 'Vladislav Pedashenko, Laida Kushnareva, Yana Khassan Nibal, Eduard Tulchinskii, Kristian Kuznetsov, Vladislav Zharchinskii, Yury Maximov, Irina Piontkovskaya', 'link': 'https://arxiv.org/abs/2511.15210', 'abstract': 'Intrinsic dimension (ID) is an important tool in modern LLM analysis, informing studies of training dynamics, scaling behavior, and dataset structure, yet its textual determinants remain underexplored. We provide the first comprehensive study grounding ID in interpretable text properties through cross-encoder analysis, linguistic features, and sparse autoencoders (SAEs). In this work, we establish three key findings. First, ID is complementary to entropy-based metrics: after controlling for length, the two are uncorrelated, with ID capturing geometric complexity orthogonal to prediction quality. Second, ID exhibits robust genre stratification: scientific prose shows low ID (~8), encyclopedic content medium ID (~9), and creative/opinion writing high ID (~10.5) across all models tested. This reveals that contemporary LLMs find scientific text "representationally simple" while fiction requires additional degrees of freedom. Third, using SAEs, we identify causal features: scientific signals (formal tone, report templates, statistics) reduce ID; humanized signals (personalization, emotion, narrative) increase it. Steering experiments confirm these effects are causal. Thus, for contemporary models, scientific writing appears comparatively "easy", whereas fiction, opinion, and affect add representational degrees of freedom. Our multi-faceted analysis provides practical guidance for the proper use of ID and the sound interpretation of ID-based results.', 'abstract_zh': '内在维度（ID）是现代大语言模型（LLM）分析的重要工具，用于研究训练动力学、缩放行为和数据集结构，但其文本决定因素仍然研究不足。我们通过交叉编码分析、语言特征和稀疏自编码器（SAEs）提供了第一个全面的研究，将ID与可解释的文本属性联系起来。在此工作中，我们建立了三个关键发现。首先，ID与基于熵的指标互补：在控制长度后，两者不相关，ID捕捉到与预测质量正交的几何复杂性。其次，ID表现出稳定的体裁分层：科学文体的ID较低（~8），百科内容的ID中等（~9），而创造性/意见写作的ID较高（~10.5），所有测试模型中如此。这揭示了当代大语言模型在表示科学文本时较为“简单”，而虚构文学则需要更多的自由度。第三，使用SAEs，我们识别了因果特征：科学信号（正式语气、报告模板、统计数据）降低ID；人性化信号（个性化、情感、叙事）增加ID。引导实验确认了这些影响是因果关系。因此，对于当代模型而言，科学写作似乎相对“容易”，而虚构、意见和情感则增加表示的自由度。我们的多方面分析为ID的正确使用和基于ID结果的准确解释提供了实用指导。', 'title_zh': '揭示文本的固有维度：从学术摘要到创意故事'}
{'arxiv_id': 'arXiv:2511.15210', 'title': 'Unveiling Intrinsic Dimension of Texts: from Academic Abstract to Creative Story', 'authors': 'Vladislav Pedashenko, Laida Kushnareva, Yana Khassan Nibal, Eduard Tulchinskii, Kristian Kuznetsov, Vladislav Zharchinskii, Yury Maximov, Irina Piontkovskaya', 'link': 'https://arxiv.org/abs/2511.15210', 'abstract': 'Intrinsic dimension (ID) is an important tool in modern LLM analysis, informing studies of training dynamics, scaling behavior, and dataset structure, yet its textual determinants remain underexplored. We provide the first comprehensive study grounding ID in interpretable text properties through cross-encoder analysis, linguistic features, and sparse autoencoders (SAEs). In this work, we establish three key findings. First, ID is complementary to entropy-based metrics: after controlling for length, the two are uncorrelated, with ID capturing geometric complexity orthogonal to prediction quality. Second, ID exhibits robust genre stratification: scientific prose shows low ID (~8), encyclopedic content medium ID (~9), and creative/opinion writing high ID (~10.5) across all models tested. This reveals that contemporary LLMs find scientific text "representationally simple" while fiction requires additional degrees of freedom. Third, using SAEs, we identify causal features: scientific signals (formal tone, report templates, statistics) reduce ID; humanized signals (personalization, emotion, narrative) increase it. Steering experiments confirm these effects are causal. Thus, for contemporary models, scientific writing appears comparatively "easy", whereas fiction, opinion, and affect add representational degrees of freedom. Our multi-faceted analysis provides practical guidance for the proper use of ID and the sound interpretation of ID-based results.', 'abstract_zh': '内在维度（ID）是现代大语言模型（LLM）分析的重要工具，能够指导训练动力学、扩展行为和数据集结构的研究，但其文本决定因素仍缺乏探索。我们通过交叉编码分析、语言特征和稀疏自编码器（SAEs）提供了首个全面的研究，将ID与可解释的文本属性联系起来。在本研究中，我们确立了三个关键发现。首先，ID与基于熵的指标互补：在控制长度后，两者不相关，ID捕捉几何复杂性，而与预测质量正交。其次，ID表现出稳健的体裁分层：科学文体的ID较低（~8），百科内容的ID中等（~9），创造性/观点写作的ID较高（~10.5），所有测试模型中均如此。这揭示出当代LLM对科学文本“表征简单”，而虚构作品则需要额外的自由度。第三，通过使用SAEs，我们识别出因果特征：科学信号（正式语调、报告模板、统计数据）降低ID；人类化信号（个性化、情感、叙事）增加ID。定向实验进一步证实这些效果是因果性的。因此，对于当代模型而言，科学写作相对“简单”，而虚构、观点和情感增加表征自由度。我们多维度的分析为ID的恰当使用和ID为基础结果的准确解释提供了实用指导。', 'title_zh': '揭示文本的固有维度：从学术摘要到创意故事'}
{'arxiv_id': 'arXiv:2511.15211', 'title': 'OEMA: Ontology-Enhanced Multi-Agent Collaboration Framework for Zero-Shot Clinical Named Entity Recognition', 'authors': 'Xinli Tao, Xin Dong, Xuezhong Zhou', 'link': 'https://arxiv.org/abs/2511.15211', 'abstract': "Clinical named entity recognition (NER) is crucial for extracting information from electronic health records (EHRs), but supervised models like CRF and BioClinicalBERT require costly annotated data. While zero-shot NER with large language models (LLMs) reduces this dependency, it struggles with example selection granularity and integrating prompts with self-improvement. To address this, we propose OEMA, a zero-shot clinical NER framework using multi-agent collaboration. OEMA's three components are: a self-annotator generating examples, a discriminator filtering them via SNOMED CT, and a predictor using entity descriptions for accurate inference. On MTSamples and VAERS datasets, OEMA achieves state-of-the-art exact-match performance. Under related-match, it matches supervised BioClinicalBERT and surpasses CRF. OEMA addresses key zero-shot NER challenges through ontology-guided reasoning and multi-agent collaboration, achieving near-supervised performance and showing promise for clinical NLP applications.", 'abstract_zh': '临床命名实体识别（NER）对于从电子健康记录（EHRs）中提取信息至关重要，但监督模型如CRF和BioClinicalBERT需要 costly 标注数据。虽然大规模语言模型（LLMs）的零样本NER在减少这种依赖方面具有优势，但在示例选择粒度和提示集成的自我提升方面存在问题。为了解决这些问题，我们提出了一种基于多代理协作的零样本临床NER框架OEMA。OEMA的三个组件包括：一个自标注器生成示例、一个通过SNOMED CT 进行筛选的鉴别器，以及一个使用实体描述进行准确推理的预测器。在MTSamples和VAERS数据集上，OEMA实现了最先进的完全匹配性能。在相关匹配下，它与监督BioClinicalBERT相当，并超越CRF。OEMA通过本体引导的推理和多代理协作，解决了零样本NER的关键挑战，实现了接近监督的表现，并展示了其在临床NLP应用中的潜力。', 'title_zh': '基于本体增强的多代理协作框架：零样本临床命名实体识别'}
{'arxiv_id': 'arXiv:2511.15204', 'title': 'Physics-Based Benchmarking Metrics for Multimodal Synthetic Images', 'authors': 'Kishor Datta Gupta, Marufa Kamal, Md. Mahfuzur Rahman, Fahad Rahman, Mohd Ariful Haque, Sunzida Siddique', 'link': 'https://arxiv.org/abs/2511.15204', 'abstract': 'Current state of the art measures like BLEU, CIDEr, VQA score, SigLIP-2 and CLIPScore are often unable to capture semantic or structural accuracy, especially for domain-specific or context-dependent scenarios. For this, this paper proposes a Physics-Constrained Multimodal Data Evaluation (PCMDE) metric combining large language models with reasoning, knowledge based mapping and vision-language models to overcome these limitations. The architecture is comprised of three main stages: (1) feature extraction of spatial and semantic information with multimodal features through object detection and VLMs; (2) Confidence-Weighted Component Fusion for adaptive component-level validation; and (3) physics-guided reasoning using large language models for structural and relational constraints (e.g., alignment, position, consistency) enforcement.', 'abstract_zh': '当前最先进的衡量标准如BLEU、CIDEr、VQA分数、SigLIP-2和CLIPScore往往无法捕捉到语义或结构准确性，尤其是在特定领域或依赖上下文的场景中。为了解决这一问题，本文提出了一种结合大规模语言模型推理、知识映射和视觉语言模型的物理约束多模态数据评估(PCMDE)度量方法，以克服这些局限性。该架构包含三个主要阶段：(1) 通过对象检测和VLMs提取空间和语义信息的多模态特征；(2) 信心加权组件融合以实现自适应组件级验证；以及(3) 使用大规模语言模型进行基于物理的推理，以施加结构和关系约束（例如，对齐、位置、一致性）。', 'title_zh': '基于物理的多模态合成图像基准评估指标'}
{'arxiv_id': 'arXiv:2511.15204', 'title': 'Physics-Based Benchmarking Metrics for Multimodal Synthetic Images', 'authors': 'Kishor Datta Gupta, Marufa Kamal, Md. Mahfuzur Rahman, Fahad Rahman, Mohd Ariful Haque, Sunzida Siddique', 'link': 'https://arxiv.org/abs/2511.15204', 'abstract': 'Current state of the art measures like BLEU, CIDEr, VQA score, SigLIP-2 and CLIPScore are often unable to capture semantic or structural accuracy, especially for domain-specific or context-dependent scenarios. For this, this paper proposes a Physics-Constrained Multimodal Data Evaluation (PCMDE) metric combining large language models with reasoning, knowledge based mapping and vision-language models to overcome these limitations. The architecture is comprised of three main stages: (1) feature extraction of spatial and semantic information with multimodal features through object detection and VLMs; (2) Confidence-Weighted Component Fusion for adaptive component-level validation; and (3) physics-guided reasoning using large language models for structural and relational constraints (e.g., alignment, position, consistency) enforcement.', 'abstract_zh': '当前的前沿评价指标如BLEU、CIDEr、VQA分数、SigLIP-2和CLIPScore往往难以捕捉到语义或结构准确性，尤其是在特定领域或依赖上下文的情景中。为解决这一问题，本文提出了一种结合大型语言模型、推理、知识映射和视觉语言模型的物理约束多模态数据评价（PCMDE）度量，以克服这些局限。该架构包含三个主要阶段：(1) 通过物体检测和VLM提取空间和语义信息的多模态特征；(2) 信心加权组件融合实现自适应组件级验证；(3) 使用大型语言模型进行物理引导的推理以施加结构和关系约束（例如，对齐、位置、一致性）。', 'title_zh': '基于物理的多模态合成图像基准评估指标'}
{'arxiv_id': 'arXiv:2511.15210', 'title': 'Unveiling Intrinsic Dimension of Texts: from Academic Abstract to Creative Story', 'authors': 'Vladislav Pedashenko, Laida Kushnareva, Yana Khassan Nibal, Eduard Tulchinskii, Kristian Kuznetsov, Vladislav Zharchinskii, Yury Maximov, Irina Piontkovskaya', 'link': 'https://arxiv.org/abs/2511.15210', 'abstract': 'Intrinsic dimension (ID) is an important tool in modern LLM analysis, informing studies of training dynamics, scaling behavior, and dataset structure, yet its textual determinants remain underexplored. We provide the first comprehensive study grounding ID in interpretable text properties through cross-encoder analysis, linguistic features, and sparse autoencoders (SAEs). In this work, we establish three key findings. First, ID is complementary to entropy-based metrics: after controlling for length, the two are uncorrelated, with ID capturing geometric complexity orthogonal to prediction quality. Second, ID exhibits robust genre stratification: scientific prose shows low ID (~8), encyclopedic content medium ID (~9), and creative/opinion writing high ID (~10.5) across all models tested. This reveals that contemporary LLMs find scientific text "representationally simple" while fiction requires additional degrees of freedom. Third, using SAEs, we identify causal features: scientific signals (formal tone, report templates, statistics) reduce ID; humanized signals (personalization, emotion, narrative) increase it. Steering experiments confirm these effects are causal. Thus, for contemporary models, scientific writing appears comparatively "easy", whereas fiction, opinion, and affect add representational degrees of freedom. Our multi-faceted analysis provides practical guidance for the proper use of ID and the sound interpretation of ID-based results.', 'abstract_zh': '内在维度（ID）是现代大语言模型（LLM）分析的重要工具，用以研究训练动力学、缩放行为和数据集结构，但其文本决定因素仍缺乏探索。本文通过交叉编码分析、语言特征和稀疏自编码器（SAEs）提供首个全面研究，将ID与可解释的文本属性联系起来。本文确立了三项关键发现：首先，ID与基于熵的指标互补：在控制长度后，两者不相关，ID捕捉到与预测质量正交的几何复杂性；其次，ID表现出稳健的体裁分层：科学文体的ID较低（约8），百科内容的ID中等（约9），而创意/观点写作的ID较高（约10.5），这表明当下LLM认为科学文本“表示简单”，而叙事性内容则需要更多的自由度；最后，利用SAEs，我们识别出因果特征：科学信号（正式语气、报告模板、统计数据）降低ID；人性化信号（个性化、情感、叙述）则增加ID。定向实验进一步证实这些效果具有因果性。因此，对于当下模型而言，科学写作显得相对“容易”，而叙事、观点和情感则增加表示的自由度。我们的多方面分析为正确使用ID及其基于ID的结果的稳健解释提供了实用指导。', 'title_zh': '揭示文本的固有维度：从学术摘要到创意故事'}
{'arxiv_id': 'arXiv:2511.15203', 'title': 'Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks', 'authors': 'Zimo Ji, Xunguang Wang, Zongjie Li, Pingchuan Ma, Yudong Gao, Daoyuan Wu, Xincheng Yan, Tian Tian, Shuai Wang', 'link': 'https://arxiv.org/abs/2511.15203', 'abstract': 'Large Language Model (LLM)-based agents with function-calling capabilities are increasingly deployed, but remain vulnerable to Indirect Prompt Injection (IPI) attacks that hijack their tool calls. In response, numerous IPI-centric defense frameworks have emerged. However, these defenses are fragmented, lacking a unified taxonomy and comprehensive evaluation. In this Systematization of Knowledge (SoK), we present the first comprehensive analysis of IPI-centric defense frameworks. We introduce a comprehensive taxonomy of these defenses, classifying them along five dimensions. We then thoroughly assess the security and usability of representative defense frameworks. Through analysis of defensive failures in the assessment, we identify six root causes of defense circumvention. Based on these findings, we design three novel adaptive attacks that significantly improve attack success rates targeting specific frameworks, demonstrating the severity of the flaws in these defenses. Our paper provides a foundation and critical insights for the future development of more secure and usable IPI-centric agent defense frameworks.', 'abstract_zh': '基于大规模语言模型的代理在具备函数调用能力后被越来越多地部署，但仍易受到间接提示注入（IPI）攻击的影响，这些攻击会劫持其工具调用。针对此问题，涌现出了众多以IPI为中心的防御框架，但这些防御框架缺乏统一的分类体系和全面的评估。本文通过系统知识示例（SoK），首次进行全面分析了以IPI为中心的防御框架。我们引入了一个全面的防御框架分类体系，并从五个维度对其进行分类。随后，我们详细评估了代表性防御框架的安全性和易用性。通过分析评估中的防御失败案例，我们识别出六种防御规避的根本原因。基于这些发现，我们设计了三种新型的自适应攻击，针对特定框架显著提高了攻击成功率，揭示了这些防御框架中的严重缺陷。本文为未来开发更安全和实用的以IPI为中心的代理防御框架奠定了基础并提供了关键见解。', 'title_zh': '基于IPI中心的LLM代理防御框架的分类、评估与利用'}
{'arxiv_id': 'arXiv:2511.15203', 'title': 'Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks', 'authors': 'Zimo Ji, Xunguang Wang, Zongjie Li, Pingchuan Ma, Yudong Gao, Daoyuan Wu, Xincheng Yan, Tian Tian, Shuai Wang', 'link': 'https://arxiv.org/abs/2511.15203', 'abstract': 'Large Language Model (LLM)-based agents with function-calling capabilities are increasingly deployed, but remain vulnerable to Indirect Prompt Injection (IPI) attacks that hijack their tool calls. In response, numerous IPI-centric defense frameworks have emerged. However, these defenses are fragmented, lacking a unified taxonomy and comprehensive evaluation. In this Systematization of Knowledge (SoK), we present the first comprehensive analysis of IPI-centric defense frameworks. We introduce a comprehensive taxonomy of these defenses, classifying them along five dimensions. We then thoroughly assess the security and usability of representative defense frameworks. Through analysis of defensive failures in the assessment, we identify six root causes of defense circumvention. Based on these findings, we design three novel adaptive attacks that significantly improve attack success rates targeting specific frameworks, demonstrating the severity of the flaws in these defenses. Our paper provides a foundation and critical insights for the future development of more secure and usable IPI-centric agent defense frameworks.', 'abstract_zh': '基于大型语言模型（LLM）的功能调用代理面临间接提示注入（IPI）攻击的安全防御框架综述', 'title_zh': '基于IPI的LLM代理防御框架的分类、评估与利用'}
{'arxiv_id': 'arXiv:2511.15204', 'title': 'Physics-Based Benchmarking Metrics for Multimodal Synthetic Images', 'authors': 'Kishor Datta Gupta, Marufa Kamal, Md. Mahfuzur Rahman, Fahad Rahman, Mohd Ariful Haque, Sunzida Siddique', 'link': 'https://arxiv.org/abs/2511.15204', 'abstract': 'Current state of the art measures like BLEU, CIDEr, VQA score, SigLIP-2 and CLIPScore are often unable to capture semantic or structural accuracy, especially for domain-specific or context-dependent scenarios. For this, this paper proposes a Physics-Constrained Multimodal Data Evaluation (PCMDE) metric combining large language models with reasoning, knowledge based mapping and vision-language models to overcome these limitations. The architecture is comprised of three main stages: (1) feature extraction of spatial and semantic information with multimodal features through object detection and VLMs; (2) Confidence-Weighted Component Fusion for adaptive component-level validation; and (3) physics-guided reasoning using large language models for structural and relational constraints (e.g., alignment, position, consistency) enforcement.', 'abstract_zh': '当前的先进度量标准，如BLEU、CIDEr、VQA得分、SigLIP-2和CLIPScore，往往难以捕捉到语义或结构准确性，尤其是在特定领域或依赖上下文的场景中。为此，本文提出了一种结合大型语言模型、推理、基于知识的映射和视觉语言模型的物理约束多模态数据评估（PCMDE）指标，以克服这些限制。该架构包含三个主要阶段：（1）通过对象检测和VLMs提取空间和语义信息的多模态特征；（2）自信加权组件融合以实现适应性的组件级验证；（3）使用大型语言模型进行基于物理的推理，以施加结构和关系约束（例如，对齐、位置、一致性）。', 'title_zh': '基于物理的多模态合成图像基准评估指标'}
{'arxiv_id': 'arXiv:2511.15194', 'title': 'Eq.Bot: Enhance Robotic Manipulation Learning via Group Equivariant Canonicalization', 'authors': 'Jian Deng, Yuandong Wang, Yangfu Zhu, Tao Feng, Tianyu Wo, Zhenzhou Shao', 'link': 'https://arxiv.org/abs/2511.15194', 'abstract': 'Robotic manipulation systems are increasingly deployed across diverse domains. Yet existing multi-modal learning frameworks lack inherent guarantees of geometric consistency, struggling to handle spatial transformations such as rotations and translations. While recent works attempt to introduce equivariance through bespoke architectural modifications, these methods suffer from high implementation complexity, computational cost, and poor portability. Inspired by human cognitive processes in spatial reasoning, we propose this http URL, a universal canonicalization framework grounded in SE(2) group equivariant theory for robotic manipulation learning. Our framework transforms observations into a canonical space, applies an existing policy, and maps the resulting actions back to the original space. As a model-agnostic solution, this http URL aims to endow models with spatial equivariance without requiring architectural modifications. Extensive experiments demonstrate the superiority of this http URL under both CNN-based (e.g., CLIPort) and Transformer-based (e.g., OpenVLA-OFT) architectures over existing methods on various robotic manipulation tasks, where the most significant improvement can reach 50.0%.', 'abstract_zh': '机器人操作系统在多个领域中的应用日益增多。然而，现有的多模态学习框架缺乏内在的几何一致性保证，难以处理如旋转和平移等空间变换。尽管近期的研究通过定制的架构修改尝试引入等变性，但这些方法面临着实现复杂性高、计算成本大和移植性差的问题。受人类空间推理认知过程的启发，我们提出了基于SE(2)群等变理论的通用规范框架——this http URL，旨在为机器人操作学习赋予空间等变性而无需进行架构修改。广泛实验证明，与基于CNN（例如CLIPort）和基于Transformer（例如OpenVLA-OFT）的现有方法相比，该框架在各种机器人操作任务中表现出显著优势，最高可提高50.0%。', 'title_zh': 'Eq.Bot: 通过群共变规范化解增强机器人操作学习'}
{'arxiv_id': 'arXiv:2511.15194', 'title': 'Eq.Bot: Enhance Robotic Manipulation Learning via Group Equivariant Canonicalization', 'authors': 'Jian Deng, Yuandong Wang, Yangfu Zhu, Tao Feng, Tianyu Wo, Zhenzhou Shao', 'link': 'https://arxiv.org/abs/2511.15194', 'abstract': 'Robotic manipulation systems are increasingly deployed across diverse domains. Yet existing multi-modal learning frameworks lack inherent guarantees of geometric consistency, struggling to handle spatial transformations such as rotations and translations. While recent works attempt to introduce equivariance through bespoke architectural modifications, these methods suffer from high implementation complexity, computational cost, and poor portability. Inspired by human cognitive processes in spatial reasoning, we propose this http URL, a universal canonicalization framework grounded in SE(2) group equivariant theory for robotic manipulation learning. Our framework transforms observations into a canonical space, applies an existing policy, and maps the resulting actions back to the original space. As a model-agnostic solution, this http URL aims to endow models with spatial equivariance without requiring architectural modifications. Extensive experiments demonstrate the superiority of this http URL under both CNN-based (e.g., CLIPort) and Transformer-based (e.g., OpenVLA-OFT) architectures over existing methods on various robotic manipulation tasks, where the most significant improvement can reach 50.0%.', 'abstract_zh': '基于SE(2)群不变理论的通用标准化框架：用于机器人 manipulation 学习的空间不变性赋能', 'title_zh': 'Eq.Bot: 通过群不变化标准化提高机器人操作学习 efficiency'}
{'arxiv_id': 'arXiv:2511.15190', 'title': 'Masked Auto-Regressive Variational Acceleration: Fast Inference Makes Practical Reinforcement Learning', 'authors': 'Yuxuan Gu, Weimin Bai, Yifei Wang, Weijian Luo, He Sun', 'link': 'https://arxiv.org/abs/2511.15190', 'abstract': 'Masked auto-regressive diffusion models (MAR) benefit from the expressive modeling ability of diffusion models and the flexibility of masked auto-regressive ordering. However, vanilla MAR suffers from slow inference due to its hierarchical inference mechanism: an outer AR unmasking loop and an inner diffusion denoising chain. Such decoupled structure not only harm the generation efficiency but also hinder the practical use of MAR for reinforcement learning (RL), an increasingly critical paradigm for generative model this http URL address this fundamental issue, we introduce MARVAL (Masked Auto-regressive Variational Acceleration), a distillation-based framework that compresses the diffusion chain into a single AR generation step while preserving the flexible auto-regressive unmasking order. Such a distillation with MARVAL not only yields substantial inference acceleration but, crucially, makes RL post-training with verifiable rewards practical, resulting in scalable yet human-preferred fast generative models. Our contributions are twofold: (1) a novel score-based variational objective for distilling masked auto-regressive diffusion models into a single generation step without sacrificing sample quality; and (2) an efficient RL framework for masked auto-regressive models via MARVAL-RL. On ImageNet 256*256, MARVAL-Huge achieves an FID of 2.00 with more than 30 times speedup compared with MAR-diffusion, and MARVAL-RL yields consistent improvements in CLIP and image-reward scores on ImageNet datasets with entity names. In conclusion, MARVAL demonstrates the first practical path to distillation and RL of masked auto-regressive diffusion models, enabling fast sampling and better preference alignments.', 'abstract_zh': 'Masked Auto-regressive Variational Acceleration for Efficient Inference and Reinforcement Learning in Diffusion Models', 'title_zh': '掩码自回归变分加速：快速推断使实用 reinforcement learning 成为可能'}
{'arxiv_id': 'arXiv:2511.15203', 'title': 'Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks', 'authors': 'Zimo Ji, Xunguang Wang, Zongjie Li, Pingchuan Ma, Yudong Gao, Daoyuan Wu, Xincheng Yan, Tian Tian, Shuai Wang', 'link': 'https://arxiv.org/abs/2511.15203', 'abstract': 'Large Language Model (LLM)-based agents with function-calling capabilities are increasingly deployed, but remain vulnerable to Indirect Prompt Injection (IPI) attacks that hijack their tool calls. In response, numerous IPI-centric defense frameworks have emerged. However, these defenses are fragmented, lacking a unified taxonomy and comprehensive evaluation. In this Systematization of Knowledge (SoK), we present the first comprehensive analysis of IPI-centric defense frameworks. We introduce a comprehensive taxonomy of these defenses, classifying them along five dimensions. We then thoroughly assess the security and usability of representative defense frameworks. Through analysis of defensive failures in the assessment, we identify six root causes of defense circumvention. Based on these findings, we design three novel adaptive attacks that significantly improve attack success rates targeting specific frameworks, demonstrating the severity of the flaws in these defenses. Our paper provides a foundation and critical insights for the future development of more secure and usable IPI-centric agent defense frameworks.', 'abstract_zh': '基于大规模语言模型（LLM）的功能调用代理的间接提示注入（IPI）防御框架综述', 'title_zh': 'IPI为中心的LLM代理防御框架的分类、评估与利用'}
{'arxiv_id': 'arXiv:2511.15190', 'title': 'Masked Auto-Regressive Variational Acceleration: Fast Inference Makes Practical Reinforcement Learning', 'authors': 'Yuxuan Gu, Weimin Bai, Yifei Wang, Weijian Luo, He Sun', 'link': 'https://arxiv.org/abs/2511.15190', 'abstract': 'Masked auto-regressive diffusion models (MAR) benefit from the expressive modeling ability of diffusion models and the flexibility of masked auto-regressive ordering. However, vanilla MAR suffers from slow inference due to its hierarchical inference mechanism: an outer AR unmasking loop and an inner diffusion denoising chain. Such decoupled structure not only harm the generation efficiency but also hinder the practical use of MAR for reinforcement learning (RL), an increasingly critical paradigm for generative model this http URL address this fundamental issue, we introduce MARVAL (Masked Auto-regressive Variational Acceleration), a distillation-based framework that compresses the diffusion chain into a single AR generation step while preserving the flexible auto-regressive unmasking order. Such a distillation with MARVAL not only yields substantial inference acceleration but, crucially, makes RL post-training with verifiable rewards practical, resulting in scalable yet human-preferred fast generative models. Our contributions are twofold: (1) a novel score-based variational objective for distilling masked auto-regressive diffusion models into a single generation step without sacrificing sample quality; and (2) an efficient RL framework for masked auto-regressive models via MARVAL-RL. On ImageNet 256*256, MARVAL-Huge achieves an FID of 2.00 with more than 30 times speedup compared with MAR-diffusion, and MARVAL-RL yields consistent improvements in CLIP and image-reward scores on ImageNet datasets with entity names. In conclusion, MARVAL demonstrates the first practical path to distillation and RL of masked auto-regressive diffusion models, enabling fast sampling and better preference alignments.', 'abstract_zh': 'Masked Auto-regressive Variational Acceleration (MARVAL): Distilling Masked Auto-regressive Diffusion Models for Scalable and Human-Preferred Generation in Reinforcement Learning', 'title_zh': '掩码自回归变分加速：快速推断让强化学习更具实践意义'}
{'arxiv_id': 'arXiv:2511.15182', 'title': 'SWR-Viz: AI-assisted Interactive Visual Analytics Framework for Ship Weather Routing', 'authors': 'Subhashis Hazarika, Leonard Lupin-Jimenez, Rohit Vuppala, Ashesh Chattopadhyay, Hon Yung Wong', 'link': 'https://arxiv.org/abs/2511.15182', 'abstract': 'Efficient and sustainable maritime transport increasingly depends on reliable forecasting and adaptive routing, yet operational adoption remains difficult due to forecast latencies and the need for human judgment in rapid decision-making under changing ocean conditions. We introduce SWR-Viz, an AI-assisted visual analytics framework that combines a physics-informed Fourier Neural Operator wave forecast model with SIMROUTE-based routing and interactive emissions analytics. The framework generates near-term forecasts directly from current conditions, supports data assimilation with sparse observations, and enables rapid exploration of what-if routing scenarios. We evaluate the forecast models and SWR-Viz framework along key shipping corridors in the Japan Coast and Gulf of Mexico, showing both improved forecast stability and realistic routing outcomes comparable to ground-truth reanalysis wave products. Expert feedback highlights the usability of SWR-Viz, its ability to isolate voyage segments with high emission reduction potential, and its value as a practical decision-support system. More broadly, this work illustrates how lightweight AI forecasting can be integrated with interactive visual analytics to support human-centered decision-making in complex geospatial and environmental domains.', 'abstract_zh': '高效的海上运输日益依赖于可靠的预测和适应性航线规划，但由于预测延迟和在不断变化的海洋条件下快速决策所需的人为判断，其在实际操作中的应用仍然具有挑战性。我们引入了SWR-Viz，这是一种结合了物理知情傅里叶神经运算符波预测模型和SIMROUTE航线规划的AI辅助视觉分析框架，同时支持与稀疏观测数据的资料同化，并允许快速探索不同航线方案。我们在日本沿岸和墨西哥湾的关键航运走廊上评估了预测模型和SWR-Viz框架，展示了预测稳定性的提高以及与真实再分析波浪产品具有现实可行性的航线结果。专家反馈强调了SWR-Viz的易用性、能够识别出具有高减排潜力的航程段以及作为实际决策支持系统的价值。更广泛地讲，本项工作展示了如何将轻量级AI预测与交互式视觉分析集成，以支持在复杂地理空间和环境领域中的人本决策。', 'title_zh': 'SWR-Viz: 人工智能辅助互动视觉分析框架用于船舶天气路线规划'}
{'arxiv_id': 'arXiv:2511.15194', 'title': 'Eq.Bot: Enhance Robotic Manipulation Learning via Group Equivariant Canonicalization', 'authors': 'Jian Deng, Yuandong Wang, Yangfu Zhu, Tao Feng, Tianyu Wo, Zhenzhou Shao', 'link': 'https://arxiv.org/abs/2511.15194', 'abstract': 'Robotic manipulation systems are increasingly deployed across diverse domains. Yet existing multi-modal learning frameworks lack inherent guarantees of geometric consistency, struggling to handle spatial transformations such as rotations and translations. While recent works attempt to introduce equivariance through bespoke architectural modifications, these methods suffer from high implementation complexity, computational cost, and poor portability. Inspired by human cognitive processes in spatial reasoning, we propose this http URL, a universal canonicalization framework grounded in SE(2) group equivariant theory for robotic manipulation learning. Our framework transforms observations into a canonical space, applies an existing policy, and maps the resulting actions back to the original space. As a model-agnostic solution, this http URL aims to endow models with spatial equivariance without requiring architectural modifications. Extensive experiments demonstrate the superiority of this http URL under both CNN-based (e.g., CLIPort) and Transformer-based (e.g., OpenVLA-OFT) architectures over existing methods on various robotic manipulation tasks, where the most significant improvement can reach 50.0%.', 'abstract_zh': '基于SE(2)群等变理论的通用规范化框架：提升机器人操作学习的空间等变性', 'title_zh': 'Eq.Bot: 通过群不变量标准化增强机器人操作学习'}
{'arxiv_id': 'arXiv:2511.15182', 'title': 'SWR-Viz: AI-assisted Interactive Visual Analytics Framework for Ship Weather Routing', 'authors': 'Subhashis Hazarika, Leonard Lupin-Jimenez, Rohit Vuppala, Ashesh Chattopadhyay, Hon Yung Wong', 'link': 'https://arxiv.org/abs/2511.15182', 'abstract': 'Efficient and sustainable maritime transport increasingly depends on reliable forecasting and adaptive routing, yet operational adoption remains difficult due to forecast latencies and the need for human judgment in rapid decision-making under changing ocean conditions. We introduce SWR-Viz, an AI-assisted visual analytics framework that combines a physics-informed Fourier Neural Operator wave forecast model with SIMROUTE-based routing and interactive emissions analytics. The framework generates near-term forecasts directly from current conditions, supports data assimilation with sparse observations, and enables rapid exploration of what-if routing scenarios. We evaluate the forecast models and SWR-Viz framework along key shipping corridors in the Japan Coast and Gulf of Mexico, showing both improved forecast stability and realistic routing outcomes comparable to ground-truth reanalysis wave products. Expert feedback highlights the usability of SWR-Viz, its ability to isolate voyage segments with high emission reduction potential, and its value as a practical decision-support system. More broadly, this work illustrates how lightweight AI forecasting can be integrated with interactive visual analytics to support human-centered decision-making in complex geospatial and environmental domains.', 'abstract_zh': '高效的海上运输越来越依赖于可靠的预测和动态航线规划，但由于预报延迟以及在不断变化的海洋条件下快速决策时需要人的判断，实际操作中的应用仍然困难。我们提出了SWR-Viz，一个结合了物理信息傅里叶神经算子波浪预报模型和SIMROUTE基础的航线规划以及交互排放分析的人工智能辅助视觉分析框架。该框架可以直接从当前条件生成短期预报，支持稀疏观测的数据同化，并允许快速探索不同的航线场景。我们在日本海岸和墨西哥湾的主要航运走廊上评估了预报模型和SWR-Viz框架，显示出预报稳定性的改进以及与地面实况再分析波浪产品相当的实际航线结果。专家反馈突出显示了SWR-Viz的易用性，能够分离出具有高减排潜力的航段，并且作为实用的决策支持系统的价值。更广泛地说，这项工作展示了轻量级AI预报如何与交互式视觉分析相结合，以支持复杂地理空间和环境领域的以人为中心的决策。', 'title_zh': 'SWR-Viz: 基于AI辅助的互动视觉分析框架用于船舶气象航线规划'}
{'arxiv_id': 'arXiv:2511.15190', 'title': 'Masked Auto-Regressive Variational Acceleration: Fast Inference Makes Practical Reinforcement Learning', 'authors': 'Yuxuan Gu, Weimin Bai, Yifei Wang, Weijian Luo, He Sun', 'link': 'https://arxiv.org/abs/2511.15190', 'abstract': 'Masked auto-regressive diffusion models (MAR) benefit from the expressive modeling ability of diffusion models and the flexibility of masked auto-regressive ordering. However, vanilla MAR suffers from slow inference due to its hierarchical inference mechanism: an outer AR unmasking loop and an inner diffusion denoising chain. Such decoupled structure not only harm the generation efficiency but also hinder the practical use of MAR for reinforcement learning (RL), an increasingly critical paradigm for generative model this http URL address this fundamental issue, we introduce MARVAL (Masked Auto-regressive Variational Acceleration), a distillation-based framework that compresses the diffusion chain into a single AR generation step while preserving the flexible auto-regressive unmasking order. Such a distillation with MARVAL not only yields substantial inference acceleration but, crucially, makes RL post-training with verifiable rewards practical, resulting in scalable yet human-preferred fast generative models. Our contributions are twofold: (1) a novel score-based variational objective for distilling masked auto-regressive diffusion models into a single generation step without sacrificing sample quality; and (2) an efficient RL framework for masked auto-regressive models via MARVAL-RL. On ImageNet 256*256, MARVAL-Huge achieves an FID of 2.00 with more than 30 times speedup compared with MAR-diffusion, and MARVAL-RL yields consistent improvements in CLIP and image-reward scores on ImageNet datasets with entity names. In conclusion, MARVAL demonstrates the first practical path to distillation and RL of masked auto-regressive diffusion models, enabling fast sampling and better preference alignments.', 'abstract_zh': 'Masked Auto-regressive Variational Acceleration for Scalable and Human-Preferred Generative Models', 'title_zh': '掩码自回归变分加速：快速推断使实际强化学习成为可能'}
{'arxiv_id': 'arXiv:2511.15174', 'title': 'FaultDiffusion: Few-Shot Fault Time Series Generation with Diffusion Model', 'authors': 'Yi Xu, Zhigang Chen, Rui Wang, Yangfan Li, Fengxiao Tang, Ming Zhao, Jiaqi Liu', 'link': 'https://arxiv.org/abs/2511.15174', 'abstract': 'In industrial equipment monitoring, fault diagnosis is critical for ensuring system reliability and enabling predictive maintenance. However, the scarcity of fault data, due to the rarity of fault events and the high cost of data annotation, significantly hinders data-driven approaches. Existing time-series generation models, optimized for abundant normal data, struggle to capture fault distributions in few-shot scenarios, producing samples that lack authenticity and diversity due to the large domain gap and high intra-class variability of faults. To address this, we propose a novel few-shot fault time-series generation framework based on diffusion models. Our approach employs a positive-negative difference adapter, leveraging pre-trained normal data distributions to model the discrepancies between normal and fault domains for accurate fault synthesis. Additionally, a diversity loss is introduced to prevent mode collapse, encouraging the generation of diverse fault samples through inter-sample difference regularization. Experimental results demonstrate that our model significantly outperforms traditional methods in authenticity and diversity, achieving state-of-the-art performance on key benchmarks.', 'abstract_zh': '在工业设备监测中，故障诊断对于确保系统可靠性并实现预测性维护至关重要。然而，由于故障事件罕见且数据标注成本高昂导致的故障数据稀缺性，极大地阻碍了数据驱动方法的应用。现有的时间序列生成模型，虽然优化了丰富正常数据的表现，但在少量样本场景中难以捕捉故障分布，生成的样本因故障域差距大和高类内变异性而缺乏真实性和多样性。为解决这一问题，我们提出了一种基于扩散模型的新型少样本故障时间序列生成框架。该方法通过一个正负差异适配器利用预训练的正常数据分布来表征正常与故障域之间的差异，从而实现准确的故障合成。此外，引入多样损失以防止模式退化，通过内样本差异正则化鼓励生成多样化的故障样本。实验结果表明，我们的模型在真实性和多样性方面显著优于传统方法，并在关键基准上取得了最先进的性能。', 'title_zh': '故障扩散：基于扩散模型的少量样本故障时间序列生成'}
{'arxiv_id': 'arXiv:2511.15174', 'title': 'FaultDiffusion: Few-Shot Fault Time Series Generation with Diffusion Model', 'authors': 'Yi Xu, Zhigang Chen, Rui Wang, Yangfan Li, Fengxiao Tang, Ming Zhao, Jiaqi Liu', 'link': 'https://arxiv.org/abs/2511.15174', 'abstract': 'In industrial equipment monitoring, fault diagnosis is critical for ensuring system reliability and enabling predictive maintenance. However, the scarcity of fault data, due to the rarity of fault events and the high cost of data annotation, significantly hinders data-driven approaches. Existing time-series generation models, optimized for abundant normal data, struggle to capture fault distributions in few-shot scenarios, producing samples that lack authenticity and diversity due to the large domain gap and high intra-class variability of faults. To address this, we propose a novel few-shot fault time-series generation framework based on diffusion models. Our approach employs a positive-negative difference adapter, leveraging pre-trained normal data distributions to model the discrepancies between normal and fault domains for accurate fault synthesis. Additionally, a diversity loss is introduced to prevent mode collapse, encouraging the generation of diverse fault samples through inter-sample difference regularization. Experimental results demonstrate that our model significantly outperforms traditional methods in authenticity and diversity, achieving state-of-the-art performance on key benchmarks.', 'abstract_zh': '在工业设备监测中，故障诊断对于确保系统可靠性并实现预测性维护至关重要。然而，由于故障事件的稀缺性和数据标注的高成本，有限的故障数据严重阻碍了基于数据的方法的发展。现有的时间序列生成模型，针对丰富正常数据进行了优化，在少数样本情况下难以捕捉故障分布，导致生成的样本缺乏真实性和多样性，且存在明显的领域差距和高类别内变异性问题。为此，我们提出了一种基于扩散模型的新型少量样本故障时间序列生成框架。该方法利用预训练的正常数据分布，通过正负差异适配器建模正常与故障领域的差异，以实现精确的故障合成。此外，引入了多样性损失以防止模式崩溃，通过跨样本差异正则化鼓励生成多样化的故障样本。实验结果表明，我们的模型在真实性和多样性方面显著优于传统方法，取得了关键基准上的最优性能。', 'title_zh': '故障扩散：基于扩散模型的少样本故障时间序列生成'}
{'arxiv_id': 'arXiv:2511.15168', 'title': 'Finetuning LLMs for Automatic Form Interaction on Web-Browser in Selenium Testing Framework', 'authors': 'Nguyen-Khang Le, Nguyen Hiep, Minh Nguyen, Son Luu, Trung Vo, Quan Bui, Nomura Shoshin, Le-Minh Nguyen', 'link': 'https://arxiv.org/abs/2511.15168', 'abstract': 'Automated web application testing is a critical component of modern software development, with frameworks like Selenium widely adopted for validating functionality through browser automation. Among the essential aspects of such testing is the ability to interact with and validate web forms, a task that requires syntactically correct, executable scripts with high coverage of input fields. Despite its importance, this task remains underexplored in the context of large language models (LLMs), and no public benchmark or dataset exists to evaluate LLMs on form interaction generation systematically. This paper introduces a novel method for training LLMs to generate high-quality test cases in Selenium, specifically targeting form interaction testing. We curate both synthetic and human-annotated datasets for training and evaluation, covering diverse real-world forms and testing scenarios. We define clear metrics for syntax correctness, script executability, and input field coverage. Our empirical study demonstrates that our approach significantly outperforms strong baselines, including GPT-4o and other popular LLMs, across all evaluation metrics. Our work lays the groundwork for future research on LLM-based web testing and provides resources to support ongoing progress in this area.', 'abstract_zh': '基于大语言模型的自动化Web应用测试：面向表单交互生成的方法研究', 'title_zh': 'fine-tuning LLMs for automatic form interaction on web-browser in selenium testing framework'}
{'arxiv_id': 'arXiv:2511.15182', 'title': 'SWR-Viz: AI-assisted Interactive Visual Analytics Framework for Ship Weather Routing', 'authors': 'Subhashis Hazarika, Leonard Lupin-Jimenez, Rohit Vuppala, Ashesh Chattopadhyay, Hon Yung Wong', 'link': 'https://arxiv.org/abs/2511.15182', 'abstract': 'Efficient and sustainable maritime transport increasingly depends on reliable forecasting and adaptive routing, yet operational adoption remains difficult due to forecast latencies and the need for human judgment in rapid decision-making under changing ocean conditions. We introduce SWR-Viz, an AI-assisted visual analytics framework that combines a physics-informed Fourier Neural Operator wave forecast model with SIMROUTE-based routing and interactive emissions analytics. The framework generates near-term forecasts directly from current conditions, supports data assimilation with sparse observations, and enables rapid exploration of what-if routing scenarios. We evaluate the forecast models and SWR-Viz framework along key shipping corridors in the Japan Coast and Gulf of Mexico, showing both improved forecast stability and realistic routing outcomes comparable to ground-truth reanalysis wave products. Expert feedback highlights the usability of SWR-Viz, its ability to isolate voyage segments with high emission reduction potential, and its value as a practical decision-support system. More broadly, this work illustrates how lightweight AI forecasting can be integrated with interactive visual analytics to support human-centered decision-making in complex geospatial and environmental domains.', 'abstract_zh': '高效的海事运输越来越依赖于可靠的预报和适应性航线规划，但由于预测延迟和需要在变化的海洋条件下进行快速决策时的人工判断需求，营运采用仍面临困难。我们介绍了SWR-Viz，一种结合基于物理信息的Fourier神经算子波预报模型和SIMROUTE航线规划与交互式排放分析的人工智能辅助视觉分析框架。该框架可以直接从当前状况生成近期预报，支持稀疏观测的数据同化，并能快速探索假设性航线方案。我们在日本沿岸和墨西哥湾的关键海运走廊进行了预报模型和SWR-Viz框架的评估，显示出预报稳定性的提升和与实况再分析波浪产品相当的现实航线结果。专家反馈强调了SWR-Viz的易用性、能够识别具有高减排潜力的航程段以及作为实用决策支持系统的价值。更为广泛地说，这项工作展示了轻量级人工智能预报如何与交互式视觉分析整合，以支持复杂地理空间和环境领域的以人为中心的决策。', 'title_zh': 'SWR-Viz: AI辅助交互式航海气象航线规划可视化分析框架'}
{'arxiv_id': 'arXiv:2511.15168', 'title': 'Finetuning LLMs for Automatic Form Interaction on Web-Browser in Selenium Testing Framework', 'authors': 'Nguyen-Khang Le, Nguyen Hiep, Minh Nguyen, Son Luu, Trung Vo, Quan Bui, Nomura Shoshin, Le-Minh Nguyen', 'link': 'https://arxiv.org/abs/2511.15168', 'abstract': 'Automated web application testing is a critical component of modern software development, with frameworks like Selenium widely adopted for validating functionality through browser automation. Among the essential aspects of such testing is the ability to interact with and validate web forms, a task that requires syntactically correct, executable scripts with high coverage of input fields. Despite its importance, this task remains underexplored in the context of large language models (LLMs), and no public benchmark or dataset exists to evaluate LLMs on form interaction generation systematically. This paper introduces a novel method for training LLMs to generate high-quality test cases in Selenium, specifically targeting form interaction testing. We curate both synthetic and human-annotated datasets for training and evaluation, covering diverse real-world forms and testing scenarios. We define clear metrics for syntax correctness, script executability, and input field coverage. Our empirical study demonstrates that our approach significantly outperforms strong baselines, including GPT-4o and other popular LLMs, across all evaluation metrics. Our work lays the groundwork for future research on LLM-based web testing and provides resources to support ongoing progress in this area.', 'abstract_zh': '自动化的Web应用程序测试是现代软件开发中的关键组成部分，框架如Selenium被广泛采用以通过浏览器自动化验证功能。此类测试中的重要方面之一是与Web表单交互并验证其功能的能力，这需要语法正确、可执行的脚本，并且能够覆盖各种输入字段。尽管其重要性不言而喻，但在大型语言模型（LLMs）的背景下，这项任务仍然未被充分探索，且缺乏可用于系统评估LLMs在表单交互生成能力方面的基准数据集或数据集。本文提出了一种新的方法，用于训练LLMs生成Selenium中的高质量测试用例，专门针对表单交互测试。我们收集了合成和人工注释的数据集用于训练和评估，涵盖多种真实的表单和测试场景。我们定义了清晰的语法正确性、脚本可执行性和输入字段覆盖率的度量标准。我们的实证研究显示，我们的方法在所有评估指标上都显著优于包括GPT-4o和其他流行LLMs在内的强基线。我们的工作为基于LLMs的Web测试的未来研究奠定了基础，并提供了支持该领域持续进步的资源。', 'title_zh': '基于Selenium测试框架的自动表单交互WEB浏览器中大型语言模型微调'}
{'arxiv_id': 'arXiv:2511.15167', 'title': 'Learning Depth from Past Selves: Self-Evolution Contrast for Robust Depth Estimation', 'authors': 'Jing Cao, Kui Jiang, Shenyi Li, Xiaocheng Feng, Yong Huang', 'link': 'https://arxiv.org/abs/2511.15167', 'abstract': 'Self-supervised depth estimation has gained significant attention in autonomous driving and robotics. However, existing methods exhibit substantial performance degradation under adverse weather conditions such as rain and fog, where reduced visibility critically impairs depth prediction. To address this issue, we propose a novel self-evolution contrastive learning framework called SEC-Depth for self-supervised robust depth estimation tasks. Our approach leverages intermediate parameters generated during training to construct temporally evolving latency models. Using these, we design a self-evolution contrastive scheme to mitigate performance loss under challenging conditions. Concretely, we first design a dynamic update strategy of latency models for the depth estimation task to capture optimization states across training stages. To effectively leverage latency models, we introduce a self-evolution contrastive Loss (SECL) that treats outputs from historical latency models as negative samples. This mechanism adaptively adjusts learning objectives while implicitly sensing weather degradation severity, reducing the needs for manual intervention. Experiments show that our method integrates seamlessly into diverse baseline models and significantly enhances robustness in zero-shot evaluations.', 'abstract_zh': '自监督深度估计在自主驾驶和机器人技术中获得了广泛关注。然而，现有方法在雨雪和雾等不良天气条件下表现出显著的性能下降，其中降低的可见性严重影响了深度预测。为了解决这一问题，我们提出了一种新的自进化对比学习框架SEC-Depth，用于自监督鲁棒深度估计任务。我们的方法利用训练过程中生成的中间参数来构建时间演变的延迟模型。通过这些模型，我们设计了一种自进化对比方案以减轻在恶劣条件下的性能损失。具体来说，我们首先设计了一种动态更新策略，用于深度估计任务，以捕捉不同训练阶段的优化状态。为了有效利用延迟模型，我们引入了一种自进化对比损失（SECL），将历史延迟模型的输出作为负样本。这种机制能够自适应地调整学习目标，隐含感知天气退化程度，减少人工干预的需求。实验结果表明，我们的方法可以与多种基线模型无缝集成，并在零样本评估中显著提高鲁棒性。', 'title_zh': '基于过往自我进化的深度估计自对比学习'}
{'arxiv_id': 'arXiv:2511.15174', 'title': 'FaultDiffusion: Few-Shot Fault Time Series Generation with Diffusion Model', 'authors': 'Yi Xu, Zhigang Chen, Rui Wang, Yangfan Li, Fengxiao Tang, Ming Zhao, Jiaqi Liu', 'link': 'https://arxiv.org/abs/2511.15174', 'abstract': 'In industrial equipment monitoring, fault diagnosis is critical for ensuring system reliability and enabling predictive maintenance. However, the scarcity of fault data, due to the rarity of fault events and the high cost of data annotation, significantly hinders data-driven approaches. Existing time-series generation models, optimized for abundant normal data, struggle to capture fault distributions in few-shot scenarios, producing samples that lack authenticity and diversity due to the large domain gap and high intra-class variability of faults. To address this, we propose a novel few-shot fault time-series generation framework based on diffusion models. Our approach employs a positive-negative difference adapter, leveraging pre-trained normal data distributions to model the discrepancies between normal and fault domains for accurate fault synthesis. Additionally, a diversity loss is introduced to prevent mode collapse, encouraging the generation of diverse fault samples through inter-sample difference regularization. Experimental results demonstrate that our model significantly outperforms traditional methods in authenticity and diversity, achieving state-of-the-art performance on key benchmarks.', 'abstract_zh': '在工业设备监控中，故障诊断对于确保系统可靠性并实现预测性维护至关重要。然而，由于故障事件的罕见性和数据注解的高成本，故障数据的稀缺性显著阻碍了数据驱动方法的应用。现有的时间序列生成模型虽然针对丰富的正常数据进行了优化，但在少量数据场景中难以捕捉故障分布，生成的样本由于故障领域的巨大差异性和高类内变异性而缺乏真实性和多样性。为解决这一问题，我们提出了一种基于扩散模型的新型少量数据故障时间序列生成框架。该方法利用预训练的正常数据分布，通过正负差异适配器建模正常与故障领域的差异，以实现准确的故障合成。此外，引入了多样性损失以防止模式崩溃，并通过跨样本差异正则化鼓励生成多样化的故障样本。实验结果表明，我们的模型在真实性和多样性方面显著优于传统方法，并在关键基准测试上取得了最先进的性能。', 'title_zh': '故障扩散：基于扩散模型的少量样本故障时间序列生成'}
{'arxiv_id': 'arXiv:2511.15167', 'title': 'Learning Depth from Past Selves: Self-Evolution Contrast for Robust Depth Estimation', 'authors': 'Jing Cao, Kui Jiang, Shenyi Li, Xiaocheng Feng, Yong Huang', 'link': 'https://arxiv.org/abs/2511.15167', 'abstract': 'Self-supervised depth estimation has gained significant attention in autonomous driving and robotics. However, existing methods exhibit substantial performance degradation under adverse weather conditions such as rain and fog, where reduced visibility critically impairs depth prediction. To address this issue, we propose a novel self-evolution contrastive learning framework called SEC-Depth for self-supervised robust depth estimation tasks. Our approach leverages intermediate parameters generated during training to construct temporally evolving latency models. Using these, we design a self-evolution contrastive scheme to mitigate performance loss under challenging conditions. Concretely, we first design a dynamic update strategy of latency models for the depth estimation task to capture optimization states across training stages. To effectively leverage latency models, we introduce a self-evolution contrastive Loss (SECL) that treats outputs from historical latency models as negative samples. This mechanism adaptively adjusts learning objectives while implicitly sensing weather degradation severity, reducing the needs for manual intervention. Experiments show that our method integrates seamlessly into diverse baseline models and significantly enhances robustness in zero-shot evaluations.', 'abstract_zh': '自监督深度估计在自动驾驶和机器人领域引起了显著关注。然而，现有方法在雨雾等不良天气条件下表现大幅下降，其中降低的可见性严重影响了深度预测。为解决这一问题，我们提出了一种新颖的自进化对比学习框架SEC-Depth，用于自监督稳健深度估计任务。我们的方法利用训练过程中生成的中间参数构建时间演化延迟模型。基于这些模型，我们设计了一种自进化对比方案，以减轻在恶劣条件下的性能损失。具体地，我们首先为深度估计任务设计了一种动态延迟模型更新策略，以捕捉训练阶段的优化状态。为了有效利用延迟模型，我们引入了一种自进化对比损失（SECL），将历史延迟模型的输出作为负样本。这种机制能够适应性地调整学习目标，同时隐式感知天气退化严重性，减少了手动干预的需要。实验结果显示，我们的方法能够无缝集成到各种基线模型，并显著提高了零样本评估中的鲁棒性。', 'title_zh': '从过去的自己学习深度：自我进化对比学习方法实现稳健的深度估计'}
{'arxiv_id': 'arXiv:2511.15165', 'title': 'Can MLLMs Detect Phishing? A Comprehensive Security Benchmark Suite Focusing on Dynamic Threats and Multimodal Evaluation in Academic Environments', 'authors': 'Jingzhuo Zhou', 'link': 'https://arxiv.org/abs/2511.15165', 'abstract': 'The rapid proliferation of Multimodal Large Language Models (MLLMs) has introduced unprecedented security challenges, particularly in phishing detection within academic environments. Academic institutions and researchers are high-value targets, facing dynamic, multilingual, and context-dependent threats that leverage research backgrounds, academic collaborations, and personal information to craft highly tailored attacks. Existing security benchmarks largely rely on datasets that do not incorporate specific academic background information, making them inadequate for capturing the evolving attack patterns and human-centric vulnerability factors specific to academia. To address this gap, we present AdapT-Bench, a unified methodological framework and benchmark suite for systematically evaluating MLLM defense capabilities against dynamic phishing attacks in academic settings.', 'abstract_zh': '多模态大型语言模型的迅速 proliferation 在学术环境中引入了前所未有的安全挑战，特别是针对钓鱼攻击的检测。学术机构和研究人员是高价值目标，面临着利用研究背景、学术合作和个人信息量身定制的动态、多语言和情境依赖的威胁。现有的安全基准主要依赖于不包含具体学术背景信息的数据集，使其难以捕捉到学术环境中特定的人本脆弱性和不断演化的攻击模式。为弥补这一差距，我们提出了 AdapT-Bench，一个统一的方法论框架和基准套件，用于系统性评估多模态大型语言模型在学术环境中的防动态钓鱼攻击能力。', 'title_zh': 'MLLMs能在学术环境中检测钓鱼攻击吗？一个专注于动态威胁和多模态评估的综合性安全基准套件'}
{'arxiv_id': 'arXiv:2511.15168', 'title': 'Finetuning LLMs for Automatic Form Interaction on Web-Browser in Selenium Testing Framework', 'authors': 'Nguyen-Khang Le, Nguyen Hiep, Minh Nguyen, Son Luu, Trung Vo, Quan Bui, Nomura Shoshin, Le-Minh Nguyen', 'link': 'https://arxiv.org/abs/2511.15168', 'abstract': 'Automated web application testing is a critical component of modern software development, with frameworks like Selenium widely adopted for validating functionality through browser automation. Among the essential aspects of such testing is the ability to interact with and validate web forms, a task that requires syntactically correct, executable scripts with high coverage of input fields. Despite its importance, this task remains underexplored in the context of large language models (LLMs), and no public benchmark or dataset exists to evaluate LLMs on form interaction generation systematically. This paper introduces a novel method for training LLMs to generate high-quality test cases in Selenium, specifically targeting form interaction testing. We curate both synthetic and human-annotated datasets for training and evaluation, covering diverse real-world forms and testing scenarios. We define clear metrics for syntax correctness, script executability, and input field coverage. Our empirical study demonstrates that our approach significantly outperforms strong baselines, including GPT-4o and other popular LLMs, across all evaluation metrics. Our work lays the groundwork for future research on LLM-based web testing and provides resources to support ongoing progress in this area.', 'abstract_zh': '自动化Web应用测试是现代软件开发中的关键组成部分，框架如Selenium广泛用于通过浏览器自动化验证功能。此类测试的重要方面之一是能够与Web表单进行交互并验证表单，这需要具有高覆盖率的输入字段的语义正确且可执行的脚本。尽管其重要性不言而喻，但在大型语言模型（LLMs）的背景下，这一任务仍然未被充分探索，也没有公开的基准或数据集可以系统地评估LLMs在表单交互生成方面的表现。本文介绍了一种新的方法，用于训练LLMs生成高质量的Selenium测试案例，特别针对表单交互测试。我们为训练和评估精心收集了合成和人工注释的数据集，涵盖了各种实际世界的表单和测试场景。我们定义了清晰的语法规则正确性、脚本可执行性和输入字段覆盖率的度量标准。我们的实证研究显示，在所有评估指标上，我们的方法显著优于包括GPT-4o和其他流行LLMs在内的强基线。我们的工作为基于LLMs的Web测试未来研究奠定了基础，并提供了支持这一领域持续进展的资源。', 'title_zh': '基于Selenium测试框架的自动表单交互Web浏览器中大型语言模型的微调'}
{'arxiv_id': 'arXiv:2511.15165', 'title': 'Can MLLMs Detect Phishing? A Comprehensive Security Benchmark Suite Focusing on Dynamic Threats and Multimodal Evaluation in Academic Environments', 'authors': 'Jingzhuo Zhou', 'link': 'https://arxiv.org/abs/2511.15165', 'abstract': 'The rapid proliferation of Multimodal Large Language Models (MLLMs) has introduced unprecedented security challenges, particularly in phishing detection within academic environments. Academic institutions and researchers are high-value targets, facing dynamic, multilingual, and context-dependent threats that leverage research backgrounds, academic collaborations, and personal information to craft highly tailored attacks. Existing security benchmarks largely rely on datasets that do not incorporate specific academic background information, making them inadequate for capturing the evolving attack patterns and human-centric vulnerability factors specific to academia. To address this gap, we present AdapT-Bench, a unified methodological framework and benchmark suite for systematically evaluating MLLM defense capabilities against dynamic phishing attacks in academic settings.', 'abstract_zh': 'Multimodal大型语言模型的迅速 proliferation引入了前所未有的安全挑战，特别是在学术环境中的网络钓鱼检测中。学术机构和研究人员是高价值目标，面临动态、多语言和情境依赖性的威胁，这些威胁利用研究背景、学术合作和个人信息来精心设计针对性攻击。现有的安全基准主要依赖于未包含特定学术背景信息的数据集，使其无法捕捉到学术环境中的 evolving 攻击模式和以人为中心的脆弱性因素。为解决这一问题，我们提出了AdapT-Bench，一个统一的方法框架和基准套件，用以系统性地评估 MLLM 在学术环境中防御动态网络钓鱼攻击的能力。', 'title_zh': 'MLLMs能否检测 phishing？一种专注于动态威胁和多模态评估的综合安全基准套件'}
{'arxiv_id': 'arXiv:2511.15163', 'title': "Teaching According to Students' Aptitude: Personalized Mathematics Tutoring via Persona-, Memory-, and Forgetting-Aware LLMs", 'authors': 'Yang Wu, Rujing Yao, Tong Zhang, Yufei Shi, Zhuoren Jiang, Zhushan Li, Xiaozhong Liu', 'link': 'https://arxiv.org/abs/2511.15163', 'abstract': "Large Language Models (LLMs) are increasingly integrated into intelligent tutoring systems to provide human-like and adaptive instruction. However, most existing approaches fail to capture how students' knowledge evolves dynamically across their proficiencies, conceptual gaps, and forgetting patterns. This challenge is particularly acute in mathematics tutoring, where effective instruction requires fine-grained scaffolding precisely calibrated to each student's mastery level and cognitive retention. To address this issue, we propose TASA (Teaching According to Students' Aptitude), a student-aware tutoring framework that integrates persona, memory, and forgetting dynamics for personalized mathematics learning. Specifically, TASA maintains a structured student persona capturing proficiency profiles and an event memory recording prior learning interactions. By incorporating a continuous forgetting curve with knowledge tracing, TASA dynamically updates each student's mastery state and generates contextually appropriate, difficulty-calibrated questions and explanations. Empirical results demonstrate that TASA achieves superior learning outcomes and more adaptive tutoring behavior compared to representative baselines, underscoring the importance of modeling temporal forgetting and learner profiles in LLM-based tutoring systems.", 'abstract_zh': '大型语言模型（LLMs）越来越被集成到智能辅导系统中，以提供类人且适应性较强的指导。然而，现有的大多数方法未能捕捉学生知识在熟练程度、概念缺口和遗忘模式方面的动态演变。这一挑战在数学辅导中尤为突出，有效的教学需要根据每个学生掌握水平和认知保留情况，进行细致的支架式教学。为了解决这一问题，我们提出了TASA（基于学生能力的教学）这一学生感知型辅导框架，该框架结合了人物设定、记忆和遗忘动态，以实现个性化数学学习。具体而言，TASA 保持了一个结构化学生人物设定，捕捉熟练程度概况，并记录先前的学习交互事件。通过结合持续的遗忘曲线与知识追踪，TASA 动态更新每个学生的学习掌握状态，并生成上下文适配且难度校准的问题和解释。实证结果表明，TASA 达到了优于代表性基线模型的学习效果和更适应性的辅导行为，强调了在基于LLM的辅导系统中建模时间性遗忘和学习者特征的重要性。', 'title_zh': '因材施教：基于人格、记忆及遗忘意识的个性化数学辅导大模型'}
{'arxiv_id': 'arXiv:2511.15167', 'title': 'Learning Depth from Past Selves: Self-Evolution Contrast for Robust Depth Estimation', 'authors': 'Jing Cao, Kui Jiang, Shenyi Li, Xiaocheng Feng, Yong Huang', 'link': 'https://arxiv.org/abs/2511.15167', 'abstract': 'Self-supervised depth estimation has gained significant attention in autonomous driving and robotics. However, existing methods exhibit substantial performance degradation under adverse weather conditions such as rain and fog, where reduced visibility critically impairs depth prediction. To address this issue, we propose a novel self-evolution contrastive learning framework called SEC-Depth for self-supervised robust depth estimation tasks. Our approach leverages intermediate parameters generated during training to construct temporally evolving latency models. Using these, we design a self-evolution contrastive scheme to mitigate performance loss under challenging conditions. Concretely, we first design a dynamic update strategy of latency models for the depth estimation task to capture optimization states across training stages. To effectively leverage latency models, we introduce a self-evolution contrastive Loss (SECL) that treats outputs from historical latency models as negative samples. This mechanism adaptively adjusts learning objectives while implicitly sensing weather degradation severity, reducing the needs for manual intervention. Experiments show that our method integrates seamlessly into diverse baseline models and significantly enhances robustness in zero-shot evaluations.', 'abstract_zh': '自监督深度估计在自主驾驶和机器人技术中引起了显著关注。然而，现有方法在雨、雾等恶劣天气条件下表现出显著的性能下降，其中降低的能见度严重妨碍了深度预测。为解决这一问题，我们提出了一种新型的自进化对比学习框架SEC-Depth，用于自监督鲁棒深度估计任务。我们的方法利用训练过程中生成的中间参数构建时间演变的延迟模型，并设计了一种自进化对比方案来缓解在恶劣条件下的性能损失。具体而言，我们首先设计了一种深度估计任务的动态更新策略，以捕获训练阶段的优化状态。为了有效利用延迟模型，我们引入了一种自进化对比损失（SECL），将历史延迟模型的输出作为负样本。该机制能够自适应地调整学习目标，隐式感知天气降级严重程度，减少手动干预的需求。实验结果表明，我们的方法能够无缝集成到多种基线模型中，并在零样本评估中显著提高鲁棒性。', 'title_zh': '从过往自我中学习深度：稳健深度估计的自我进化对比方法'}
{'arxiv_id': 'arXiv:2511.15163', 'title': "Teaching According to Students' Aptitude: Personalized Mathematics Tutoring via Persona-, Memory-, and Forgetting-Aware LLMs", 'authors': 'Yang Wu, Rujing Yao, Tong Zhang, Yufei Shi, Zhuoren Jiang, Zhushan Li, Xiaozhong Liu', 'link': 'https://arxiv.org/abs/2511.15163', 'abstract': "Large Language Models (LLMs) are increasingly integrated into intelligent tutoring systems to provide human-like and adaptive instruction. However, most existing approaches fail to capture how students' knowledge evolves dynamically across their proficiencies, conceptual gaps, and forgetting patterns. This challenge is particularly acute in mathematics tutoring, where effective instruction requires fine-grained scaffolding precisely calibrated to each student's mastery level and cognitive retention. To address this issue, we propose TASA (Teaching According to Students' Aptitude), a student-aware tutoring framework that integrates persona, memory, and forgetting dynamics for personalized mathematics learning. Specifically, TASA maintains a structured student persona capturing proficiency profiles and an event memory recording prior learning interactions. By incorporating a continuous forgetting curve with knowledge tracing, TASA dynamically updates each student's mastery state and generates contextually appropriate, difficulty-calibrated questions and explanations. Empirical results demonstrate that TASA achieves superior learning outcomes and more adaptive tutoring behavior compared to representative baselines, underscoring the importance of modeling temporal forgetting and learner profiles in LLM-based tutoring systems.", 'abstract_zh': '基于学生的潜能分析的教学体系：结合人格、记忆和遗忘动力学的个性化数学学习框架', 'title_zh': '因材施教：基于个性、记忆及遗忘意识的LLM个性化数学辅导'}
{'arxiv_id': 'arXiv:2511.15162', 'title': 'Multimodal Wireless Foundation Models', 'authors': 'Ahmed Aboulfotouh, Hatem Abou-Zeid', 'link': 'https://arxiv.org/abs/2511.15162', 'abstract': 'Wireless foundation models (WFMs) have recently demonstrated promising capabilities, jointly performing multiple wireless functions and adapting effectively to new environments. However, while current WFMs process only one modality, depending on the task and operating conditions, the most informative modality changes and no single modality is best for all tasks. WFMs should therefore be designed to accept multiple modalities to enable a broader and more diverse range of tasks and scenarios. In this work, we propose and build the first multimodal wireless foundation model capable of processing both raw IQ streams and image-like wireless modalities (e.g., spectrograms and CSI) and performing multiple tasks across both. We introduce masked wireless modeling for the multimodal setting, a self-supervised objective and pretraining recipe that learns a joint representation from IQ streams and image-like wireless modalities. We evaluate the model on five tasks across both modality families: image-based (human activity sensing, RF signal classification, 5G NR positioning) and IQ-based (RF device fingerprinting, interference detection/classification). The multimodal WFM is competitive with single-modality WFMs, and in several cases surpasses their performance. Our results demonstrates the strong potential of developing multimodal WFMs that support diverse wireless tasks across different modalities. We believe this provides a concrete step toward both AI-native 6G and the vision of joint sensing, communication, and localization.', 'abstract_zh': '多模态无线基础模型：同时处理原始IQ流和图像-like无线模态并执行跨模态的多种任务', 'title_zh': '多模态无线基础模型'}
{'arxiv_id': 'arXiv:2511.15165', 'title': 'Can MLLMs Detect Phishing? A Comprehensive Security Benchmark Suite Focusing on Dynamic Threats and Multimodal Evaluation in Academic Environments', 'authors': 'Jingzhuo Zhou', 'link': 'https://arxiv.org/abs/2511.15165', 'abstract': 'The rapid proliferation of Multimodal Large Language Models (MLLMs) has introduced unprecedented security challenges, particularly in phishing detection within academic environments. Academic institutions and researchers are high-value targets, facing dynamic, multilingual, and context-dependent threats that leverage research backgrounds, academic collaborations, and personal information to craft highly tailored attacks. Existing security benchmarks largely rely on datasets that do not incorporate specific academic background information, making them inadequate for capturing the evolving attack patterns and human-centric vulnerability factors specific to academia. To address this gap, we present AdapT-Bench, a unified methodological framework and benchmark suite for systematically evaluating MLLM defense capabilities against dynamic phishing attacks in academic settings.', 'abstract_zh': 'Multimodal Large Language Models安全性挑战及其在学术环境中的鱼叉攻击检测：AdapT-Bench统一方法框架与基准测试套件', 'title_zh': 'MLLMs在学术环境中的动态威胁检测及多模态评估综合安全基准套件：针对钓鱼攻击的能力探究'}
{'arxiv_id': 'arXiv:2511.15162', 'title': 'Multimodal Wireless Foundation Models', 'authors': 'Ahmed Aboulfotouh, Hatem Abou-Zeid', 'link': 'https://arxiv.org/abs/2511.15162', 'abstract': 'Wireless foundation models (WFMs) have recently demonstrated promising capabilities, jointly performing multiple wireless functions and adapting effectively to new environments. However, while current WFMs process only one modality, depending on the task and operating conditions, the most informative modality changes and no single modality is best for all tasks. WFMs should therefore be designed to accept multiple modalities to enable a broader and more diverse range of tasks and scenarios. In this work, we propose and build the first multimodal wireless foundation model capable of processing both raw IQ streams and image-like wireless modalities (e.g., spectrograms and CSI) and performing multiple tasks across both. We introduce masked wireless modeling for the multimodal setting, a self-supervised objective and pretraining recipe that learns a joint representation from IQ streams and image-like wireless modalities. We evaluate the model on five tasks across both modality families: image-based (human activity sensing, RF signal classification, 5G NR positioning) and IQ-based (RF device fingerprinting, interference detection/classification). The multimodal WFM is competitive with single-modality WFMs, and in several cases surpasses their performance. Our results demonstrates the strong potential of developing multimodal WFMs that support diverse wireless tasks across different modalities. We believe this provides a concrete step toward both AI-native 6G and the vision of joint sensing, communication, and localization.', 'abstract_zh': '多模态无线基础模型（MM-WFMs）已经在联合执行多种无线功能和有效适应新环境方面展现了有希望的能力。然而，当前的WFMs只处理单一模态，具体任务和运行条件不同，最信息丰富的模态也会变化，并非单一模态适合所有任务。因此，WFMs 应该被设计成能够接受多种模态，以实现更广泛和更多样化的任务和场景。在本工作中，我们提出了并构建了第一个既能处理原始IQ流又能处理图像-like无线模态（例如，频谱图和CSI）的第一个多模态无线基础模型，并能够在两种模态家族中执行多种任务。我们引入了多模态环境下的掩蔽无线建模，这是一种自监督目标和预训练方法，可以从IQ流和图像-like无线模态中学习联合表示。我们将该模型在两个模态家族的五个任务上进行了评估：基于图像的任务（人体活动感知、RF信号分类、5G NR定位）和基于IQ的任务（RF设备指纹识别、干扰检测/分类）。多模态WFMs在性能上与单一模态WFMs竞争，并在某些情况下超过了它们的性能。我们的结果表明，开发支持不同模态下多样无线任务的多模态WFMs有很强的潜力。我们认为这为AI原生6G和联合感知、通信和定位的愿景提供了一个具体的步骤。', 'title_zh': '多模态无线基础模型'}
{'arxiv_id': 'arXiv:2511.15159', 'title': 'Generating Natural-Language Surgical Feedback: From Structured Representation to Domain-Grounded Evaluation', 'authors': 'Firdavs Nasriddinov, Rafal Kocielnik, Anima Anandkumar, Andrew J. Hung', 'link': 'https://arxiv.org/abs/2511.15159', 'abstract': 'High-quality intraoperative feedback from a surgical trainer is pivotal for improving trainee performance and long-term skill acquisition. Automating natural, trainer-style feedback promises timely, accessible, and consistent guidance at scale but requires models that understand clinically relevant representations. We present a structure-aware pipeline that learns a surgical action ontology from real trainer-to-trainee transcripts (33 surgeries) and uses it to condition feedback generation. We contribute by (1) mining Instrument-Action-Target (IAT) triplets from real-world feedback text and clustering surface forms into normalized categories, (2) fine-tuning a video-to-IAT model that leverages the surgical procedure and task contexts as well as fine-grained temporal instrument motion, and (3) demonstrating how to effectively use IAT triplet representations to guide GPT-4o in generating clinically grounded, trainer-style feedback. We show that, on Task 1: Video-to-IAT recognition, our context injection and temporal tracking deliver consistent AUC gains (Instrument: 0.67 to 0.74; Action: 0.60 to 0.63; Tissue: 0.74 to 0.79). For Task 2: feedback text generation (rated on a 1-5 fidelity rubric where 1 = opposite/unsafe, 3 = admissible, and 5 = perfect match to a human trainer), GPT-4o from video alone scores 2.17, while IAT conditioning reaches 2.44 (+12.4%), doubling the share of admissible generations with score >= 3 from 21% to 42%. Traditional text-similarity metrics also improve: word error rate decreases by 15-31% and ROUGE (phrase/substring overlap) increases by 9-64%. Grounding generation in explicit IAT structure improves fidelity and yields clinician-verifiable rationales, supporting auditable use in surgical training.', 'abstract_zh': '高质量的术中反馈对于提高受训者性能和长期技能获取至关重要。自动化自然风格的反馈有望提供及时、便捷且一致的指导，但需要理解临床相关表示的模型。我们提出了一种结构感知管道，从真实训练者-受训者对话记录（33次手术）中学习手术动作本体，并利用其条件反馈生成。我们 contributions 包括：(1) 从真实反馈文本中挖掘器械-动作-目标（IAT）三元组，并将其表面形式归类为规范化类别；(2) 微调一种视频到IAT模型，该模型利用手术程序和任务上下文以及精细的时间仪器运动；(3) 展示如何有效使用IAT三元组表示引导GPT-4o生成临床相关的训练风格反馈。我们展示了，对于任务1：视频到IAT识别，我们的上下文注入和时间跟踪在仪器（0.67到0.74）、动作（0.60到0.63）和组织（0.74到0.79）方面提供了一致的AUC提升。对于任务2：反馈文本生成（按1-5的保真度标准评分，1=相反/不安全，3=允许，5=完美匹配真人训练者），仅从视频生成的GPT-4o评分为2.17，而IAT条件下的评分为2.44（+12.4%），使评分>=3的生成比例从21%翻倍至42%。传统文本相似度指标也有所改善：单词错误率下降15-31%，ROUGE（短语/子字符串重叠）增加9-64%。将生成根植于明确的IAT结构提高了保真度并提供了可验证的合理解释，支持手术培训中的可审计使用。', 'title_zh': '生成自然语言手术反馈：从结构化表示到领域导向评估'}
{'arxiv_id': 'arXiv:2511.15163', 'title': "Teaching According to Students' Aptitude: Personalized Mathematics Tutoring via Persona-, Memory-, and Forgetting-Aware LLMs", 'authors': 'Yang Wu, Rujing Yao, Tong Zhang, Yufei Shi, Zhuoren Jiang, Zhushan Li, Xiaozhong Liu', 'link': 'https://arxiv.org/abs/2511.15163', 'abstract': "Large Language Models (LLMs) are increasingly integrated into intelligent tutoring systems to provide human-like and adaptive instruction. However, most existing approaches fail to capture how students' knowledge evolves dynamically across their proficiencies, conceptual gaps, and forgetting patterns. This challenge is particularly acute in mathematics tutoring, where effective instruction requires fine-grained scaffolding precisely calibrated to each student's mastery level and cognitive retention. To address this issue, we propose TASA (Teaching According to Students' Aptitude), a student-aware tutoring framework that integrates persona, memory, and forgetting dynamics for personalized mathematics learning. Specifically, TASA maintains a structured student persona capturing proficiency profiles and an event memory recording prior learning interactions. By incorporating a continuous forgetting curve with knowledge tracing, TASA dynamically updates each student's mastery state and generates contextually appropriate, difficulty-calibrated questions and explanations. Empirical results demonstrate that TASA achieves superior learning outcomes and more adaptive tutoring behavior compared to representative baselines, underscoring the importance of modeling temporal forgetting and learner profiles in LLM-based tutoring systems.", 'abstract_zh': '面向学生能力的教学：一种结合人格、记忆和遗忘动态的个性化数学学习辅导框架', 'title_zh': '根据学生能力进行教学：基于人格、记忆与遗忘意识的个性化数学辅导'}
{'arxiv_id': 'arXiv:2511.15151', 'title': 'DCL-SE: Dynamic Curriculum Learning for Spatiotemporal Encoding of Brain Imaging', 'authors': 'Meihua Zhou, Xinyu Tong, Jiarui Zhao, Min Cheng, Li Yang, Lei Tian, Nan Wan', 'link': 'https://arxiv.org/abs/2511.15151', 'abstract': "High-dimensional neuroimaging analyses for clinical diagnosis are often constrained by compromises in spatiotemporal fidelity and by the limited adaptability of large-scale, general-purpose models. To address these challenges, we introduce Dynamic Curriculum Learning for Spatiotemporal Encoding (DCL-SE), an end-to-end framework centered on data-driven spatiotemporal encoding (DaSE). We leverage Approximate Rank Pooling (ARP) to efficiently encode three-dimensional volumetric brain data into information-rich, two-dimensional dynamic representations, and then employ a dynamic curriculum learning strategy, guided by a Dynamic Group Mechanism (DGM), to progressively train the decoder, refining feature extraction from global anatomical structures to fine pathological details. Evaluated across six publicly available datasets, including Alzheimer's disease and brain tumor classification, cerebral artery segmentation, and brain age prediction, DCL-SE consistently outperforms existing methods in accuracy, robustness, and interpretability. These findings underscore the critical importance of compact, task-specific architectures in the era of large-scale pretrained networks.", 'abstract_zh': '基于数据驱动时空编码的动态 Curriculum 学习框架（DCL-SE）：高维神经成像在临床诊断中的时空编码分析', 'title_zh': 'DCL-SE：时空编码脑成像的动态课程学习'}
{'arxiv_id': 'arXiv:2511.15162', 'title': 'Multimodal Wireless Foundation Models', 'authors': 'Ahmed Aboulfotouh, Hatem Abou-Zeid', 'link': 'https://arxiv.org/abs/2511.15162', 'abstract': 'Wireless foundation models (WFMs) have recently demonstrated promising capabilities, jointly performing multiple wireless functions and adapting effectively to new environments. However, while current WFMs process only one modality, depending on the task and operating conditions, the most informative modality changes and no single modality is best for all tasks. WFMs should therefore be designed to accept multiple modalities to enable a broader and more diverse range of tasks and scenarios. In this work, we propose and build the first multimodal wireless foundation model capable of processing both raw IQ streams and image-like wireless modalities (e.g., spectrograms and CSI) and performing multiple tasks across both. We introduce masked wireless modeling for the multimodal setting, a self-supervised objective and pretraining recipe that learns a joint representation from IQ streams and image-like wireless modalities. We evaluate the model on five tasks across both modality families: image-based (human activity sensing, RF signal classification, 5G NR positioning) and IQ-based (RF device fingerprinting, interference detection/classification). The multimodal WFM is competitive with single-modality WFMs, and in several cases surpasses their performance. Our results demonstrates the strong potential of developing multimodal WFMs that support diverse wireless tasks across different modalities. We believe this provides a concrete step toward both AI-native 6G and the vision of joint sensing, communication, and localization.', 'abstract_zh': '多模态无线基础模型：既能处理原始IQ流又能处理图像-like无线模态，并在两者之间执行多种任务', 'title_zh': '多模态无线基础模型'}
{'arxiv_id': 'arXiv:2511.15159', 'title': 'Generating Natural-Language Surgical Feedback: From Structured Representation to Domain-Grounded Evaluation', 'authors': 'Firdavs Nasriddinov, Rafal Kocielnik, Anima Anandkumar, Andrew J. Hung', 'link': 'https://arxiv.org/abs/2511.15159', 'abstract': 'High-quality intraoperative feedback from a surgical trainer is pivotal for improving trainee performance and long-term skill acquisition. Automating natural, trainer-style feedback promises timely, accessible, and consistent guidance at scale but requires models that understand clinically relevant representations. We present a structure-aware pipeline that learns a surgical action ontology from real trainer-to-trainee transcripts (33 surgeries) and uses it to condition feedback generation. We contribute by (1) mining Instrument-Action-Target (IAT) triplets from real-world feedback text and clustering surface forms into normalized categories, (2) fine-tuning a video-to-IAT model that leverages the surgical procedure and task contexts as well as fine-grained temporal instrument motion, and (3) demonstrating how to effectively use IAT triplet representations to guide GPT-4o in generating clinically grounded, trainer-style feedback. We show that, on Task 1: Video-to-IAT recognition, our context injection and temporal tracking deliver consistent AUC gains (Instrument: 0.67 to 0.74; Action: 0.60 to 0.63; Tissue: 0.74 to 0.79). For Task 2: feedback text generation (rated on a 1-5 fidelity rubric where 1 = opposite/unsafe, 3 = admissible, and 5 = perfect match to a human trainer), GPT-4o from video alone scores 2.17, while IAT conditioning reaches 2.44 (+12.4%), doubling the share of admissible generations with score >= 3 from 21% to 42%. Traditional text-similarity metrics also improve: word error rate decreases by 15-31% and ROUGE (phrase/substring overlap) increases by 9-64%. Grounding generation in explicit IAT structure improves fidelity and yields clinician-verifiable rationales, supporting auditable use in surgical training.', 'abstract_zh': '高质量的术中反馈对于提高学员性能和长期技能获取至关重要。自动化自然风格的反馈能够提供及时、可访问且一致的指导，但需要理解临床相关表示的模型。我们提出了一种结构感知管道，从实际的术者-学员对话转录（33例手术）中学习外科动作本体，并利用其条件反馈生成。我们贡献了以下内容：(1) 从实际反馈文本中挖掘器械-动作-目标（IAT）三元组，并将表面形式聚类为规范化类别；(2) 微调一种视频到IAT模型，利用外科手术程序和任务背景以及细腻的时间分辨器械运动；(3) 展示如何有效利用IAT三元组表示来指导GPT-4o生成临床相关、术者风格的反馈。结果显示，在任务1：视频到IAT识别中，我们的上下文注入和时间跟踪在器械分类、动作分类和组织分类中分别实现了一致的AUC增益（器械：0.67到0.74；动作：0.60到0.63；组织：0.74到0.79）。在任务2：反馈文本生成（根据1-5评分标准，1=相反/不安全，3=可接受，5=与真人术者完美匹配）中，仅从视频生成的GPT-4o评分为2.17，而IAT条件下的评分为2.44（+12.4%），将评分>=3的可接受生成比例从21%提高到42%。传统的文本相似度指标也有所改善：词错误率降低15-31%，ROUGE（短语/子字符串重叠）提高9-64%。将生成植根于明确的IAT结构提高了可信度，并提供了可由临床医生验证的理由，支持手术培训中的可审计使用。', 'title_zh': '生成自然语言手术反馈：从结构化表示到领域导向评估'}
{'arxiv_id': 'arXiv:2511.15141', 'title': 'ItemRAG: Item-Based Retrieval-Augmented Generation for LLM-Based Recommendation', 'authors': 'Sunwoo Kim, Geon Lee, Kyungho Kim, Jaemin Yoo, Kijung Shin', 'link': 'https://arxiv.org/abs/2511.15141', 'abstract': 'Recently, large language models (LLMs) have been widely used as recommender systems, owing to their strong reasoning capability and their effectiveness in handling cold-start items. To better adapt LLMs for recommendation, retrieval-augmented generation (RAG) has been incorporated. Most existing RAG methods are user-based, retrieving purchase patterns of users similar to the target user and providing them to the LLM. In this work, we propose ItemRAG, an item-based RAG method for LLM-based recommendation that retrieves relevant items (rather than users) from item-item co-purchase histories. ItemRAG helps LLMs capture co-purchase patterns among items, which are beneficial for recommendations. Especially, our retrieval strategy incorporates semantically similar items to better handle cold-start items and uses co-purchase frequencies to improve the relevance of the retrieved items. Through extensive experiments, we demonstrate that ItemRAG consistently (1) improves the zero-shot LLM-based recommender by up to 43% in Hit-Ratio-1 and (2) outperforms user-based RAG baselines under both standard and cold-start item recommendation settings.', 'abstract_zh': '基于项目的检索增强生成（RAG）推荐方法：ItemRAG', 'title_zh': '基于物品的检索增强生成推荐系统（ItemRAG）'}
{'arxiv_id': 'arXiv:2511.15151', 'title': 'DCL-SE: Dynamic Curriculum Learning for Spatiotemporal Encoding of Brain Imaging', 'authors': 'Meihua Zhou, Xinyu Tong, Jiarui Zhao, Min Cheng, Li Yang, Lei Tian, Nan Wan', 'link': 'https://arxiv.org/abs/2511.15151', 'abstract': "High-dimensional neuroimaging analyses for clinical diagnosis are often constrained by compromises in spatiotemporal fidelity and by the limited adaptability of large-scale, general-purpose models. To address these challenges, we introduce Dynamic Curriculum Learning for Spatiotemporal Encoding (DCL-SE), an end-to-end framework centered on data-driven spatiotemporal encoding (DaSE). We leverage Approximate Rank Pooling (ARP) to efficiently encode three-dimensional volumetric brain data into information-rich, two-dimensional dynamic representations, and then employ a dynamic curriculum learning strategy, guided by a Dynamic Group Mechanism (DGM), to progressively train the decoder, refining feature extraction from global anatomical structures to fine pathological details. Evaluated across six publicly available datasets, including Alzheimer's disease and brain tumor classification, cerebral artery segmentation, and brain age prediction, DCL-SE consistently outperforms existing methods in accuracy, robustness, and interpretability. These findings underscore the critical importance of compact, task-specific architectures in the era of large-scale pretrained networks.", 'abstract_zh': '基于时空编码的动态课程学习在高维神经成像临床诊断中的应用', 'title_zh': 'DCL-SE: 动态课程学习在脑成像时空编码中的应用'}
{'arxiv_id': 'arXiv:2511.15159', 'title': 'Generating Natural-Language Surgical Feedback: From Structured Representation to Domain-Grounded Evaluation', 'authors': 'Firdavs Nasriddinov, Rafal Kocielnik, Anima Anandkumar, Andrew J. Hung', 'link': 'https://arxiv.org/abs/2511.15159', 'abstract': 'High-quality intraoperative feedback from a surgical trainer is pivotal for improving trainee performance and long-term skill acquisition. Automating natural, trainer-style feedback promises timely, accessible, and consistent guidance at scale but requires models that understand clinically relevant representations. We present a structure-aware pipeline that learns a surgical action ontology from real trainer-to-trainee transcripts (33 surgeries) and uses it to condition feedback generation. We contribute by (1) mining Instrument-Action-Target (IAT) triplets from real-world feedback text and clustering surface forms into normalized categories, (2) fine-tuning a video-to-IAT model that leverages the surgical procedure and task contexts as well as fine-grained temporal instrument motion, and (3) demonstrating how to effectively use IAT triplet representations to guide GPT-4o in generating clinically grounded, trainer-style feedback. We show that, on Task 1: Video-to-IAT recognition, our context injection and temporal tracking deliver consistent AUC gains (Instrument: 0.67 to 0.74; Action: 0.60 to 0.63; Tissue: 0.74 to 0.79). For Task 2: feedback text generation (rated on a 1-5 fidelity rubric where 1 = opposite/unsafe, 3 = admissible, and 5 = perfect match to a human trainer), GPT-4o from video alone scores 2.17, while IAT conditioning reaches 2.44 (+12.4%), doubling the share of admissible generations with score >= 3 from 21% to 42%. Traditional text-similarity metrics also improve: word error rate decreases by 15-31% and ROUGE (phrase/substring overlap) increases by 9-64%. Grounding generation in explicit IAT structure improves fidelity and yields clinician-verifiable rationales, supporting auditable use in surgical training.', 'abstract_zh': '高质量的手术培训师 intraoperative 反馈对于提高学生成绩和长期技能获取至关重要。自动化的自然式培训师反馈有望提供及时、便捷且一致的指导，但需要理解临床相关表示的模型。我们提出了一种结构感知的管道，从中学习手术动作本体，并利用其来条件化反馈生成。我们通过以下贡献：(1) 从真实世界反馈文本中挖掘器械-动作-目标（IAT）三元组，并将表面形式聚类为标准化类别；(2) 对利用手术程序和任务上下文以及精细时间标度器械运动的视频到IAT模型进行微调；(3) 展示如何有效利用IAT三元组表示来指导GPT-4o生成基于临床的培训师式反馈。结果显示，在任务1：视频到IAT识别中，我们的上下文注入和时间跟踪带来了一致的AUC提升（器械：0.67到0.74；动作：0.60到0.63；组织：0.74到0.79）。在任务2：反馈文本生成（根据1-5保真度量表评分，1=完全相反/不安全，3=可接受，5=完全匹配人类培训师），仅从视频生成的GPT-4o得分为2.17，而IAT条件化得分为2.44 (+12.4%)，生成得分>=3的比例从21%提高到42%。传统的文本相似性指标也有所提高：词错误率降低15-31%，ROUGE（短语/子字符串重叠）增加9-64%。基于明确的IAT结构进行生成提高了保真度并提供了可临床验证的理由，支持在手术培训中的可审计使用。', 'title_zh': '生成自然语言手术反馈：从结构化表示到领域导向评估'}
{'arxiv_id': 'arXiv:2511.15139', 'title': 'CASPER: Cross-modal Alignment of Spatial and single-cell Profiles for Expression Recovery', 'authors': 'Amit Kumar, Maninder Kaur, Raghvendra Mall, Sukrit Gupta', 'link': 'https://arxiv.org/abs/2511.15139', 'abstract': 'Spatial Transcriptomics enables mapping of gene expression within its native tissue context, but current platforms measure only a limited set of genes due to experimental constraints and excessive costs. To overcome this, computational models integrate Single-Cell RNA Sequencing data with Spatial Transcriptomics to predict unmeasured genes. We propose CASPER, a cross-attention based framework that predicts unmeasured gene expression in Spatial Transcriptomics by leveraging centroid-level representations from Single-Cell RNA Sequencing. We performed rigorous testing over four state-of-the-art Spatial Transcriptomics/Single-Cell RNA Sequencing dataset pairs across four existing baseline models. CASPER shows significant improvement in nine out of the twelve metrics for our experiments. This work paves the way for further work in Spatial Transcriptomics to Single-Cell RNA Sequencing modality translation. The code for CASPER is available at this https URL.', 'abstract_zh': '基于交叉注意力的Spatial Transcriptomics中未测基因表达预测框架CASPER', 'title_zh': 'CASPER: 空间与单细胞谱型跨模态对齐以实现表达恢复'}
{'arxiv_id': 'arXiv:2511.15141', 'title': 'ItemRAG: Item-Based Retrieval-Augmented Generation for LLM-Based Recommendation', 'authors': 'Sunwoo Kim, Geon Lee, Kyungho Kim, Jaemin Yoo, Kijung Shin', 'link': 'https://arxiv.org/abs/2511.15141', 'abstract': 'Recently, large language models (LLMs) have been widely used as recommender systems, owing to their strong reasoning capability and their effectiveness in handling cold-start items. To better adapt LLMs for recommendation, retrieval-augmented generation (RAG) has been incorporated. Most existing RAG methods are user-based, retrieving purchase patterns of users similar to the target user and providing them to the LLM. In this work, we propose ItemRAG, an item-based RAG method for LLM-based recommendation that retrieves relevant items (rather than users) from item-item co-purchase histories. ItemRAG helps LLMs capture co-purchase patterns among items, which are beneficial for recommendations. Especially, our retrieval strategy incorporates semantically similar items to better handle cold-start items and uses co-purchase frequencies to improve the relevance of the retrieved items. Through extensive experiments, we demonstrate that ItemRAG consistently (1) improves the zero-shot LLM-based recommender by up to 43% in Hit-Ratio-1 and (2) outperforms user-based RAG baselines under both standard and cold-start item recommendation settings.', 'abstract_zh': '基于项目的RAG推荐方法：从项目共购买历史中检索相关项目以改进大语言模型推荐', 'title_zh': '基于物品的检索增强生成推荐模型 ItemRAG'}
{'arxiv_id': 'arXiv:2511.15151', 'title': 'DCL-SE: Dynamic Curriculum Learning for Spatiotemporal Encoding of Brain Imaging', 'authors': 'Meihua Zhou, Xinyu Tong, Jiarui Zhao, Min Cheng, Li Yang, Lei Tian, Nan Wan', 'link': 'https://arxiv.org/abs/2511.15151', 'abstract': "High-dimensional neuroimaging analyses for clinical diagnosis are often constrained by compromises in spatiotemporal fidelity and by the limited adaptability of large-scale, general-purpose models. To address these challenges, we introduce Dynamic Curriculum Learning for Spatiotemporal Encoding (DCL-SE), an end-to-end framework centered on data-driven spatiotemporal encoding (DaSE). We leverage Approximate Rank Pooling (ARP) to efficiently encode three-dimensional volumetric brain data into information-rich, two-dimensional dynamic representations, and then employ a dynamic curriculum learning strategy, guided by a Dynamic Group Mechanism (DGM), to progressively train the decoder, refining feature extraction from global anatomical structures to fine pathological details. Evaluated across six publicly available datasets, including Alzheimer's disease and brain tumor classification, cerebral artery segmentation, and brain age prediction, DCL-SE consistently outperforms existing methods in accuracy, robustness, and interpretability. These findings underscore the critical importance of compact, task-specific architectures in the era of large-scale pretrained networks.", 'abstract_zh': '基于时空编码的动态 curriculum 学习在高维神经成像临床诊断中的应用', 'title_zh': 'DCL-SE: 动态 Curriculum 学习在脑成像时空编码中的应用'}
{'arxiv_id': 'arXiv:2511.15137', 'title': 'From Solving to Verifying: A Unified Objective for Robust Reasoning in LLMs', 'authors': 'Xiaoxuan Wang, Bo Liu, Song Jiang, Jingzhou Liu, Jingyuan Qi, Xia Chen, Baosheng He', 'link': 'https://arxiv.org/abs/2511.15137', 'abstract': 'The reasoning capabilities of large language models (LLMs) have been significantly improved through reinforcement learning (RL). Nevertheless, LLMs still struggle to consistently verify their own reasoning traces. This raises the research question of how to enhance the self-verification ability of LLMs and whether such an ability can further improve reasoning performance. In this work, we propose GRPO-Verif, an algorithm that jointly optimizes solution generation and self-verification within a unified loss function, with an adjustable hyperparameter controlling the weight of the verification signal. Experimental results demonstrate that our method enhances self-verification capability while maintaining comparable performance in reasoning.', 'abstract_zh': '大型语言模型的推理能力通过强化学习显著提升，但仍难以一致地验证自身的推理痕迹。本研究探讨如何增强大型语言模型的自我验证能力及其对推理性能的潜在改进。我们提出了一种名为GRPO-Verif的算法，该算法在统一的损失函数内联合优化解决方案生成和自我验证，并通过可调节的超参数控制验证信号的权重。实验结果表明，该方法在保持类似推理性能的同时增强了自我验证能力。', 'title_zh': '从求解到验证：LLM中鲁棒推理的统一目标'}
{'arxiv_id': 'arXiv:2511.15139', 'title': 'CASPER: Cross-modal Alignment of Spatial and single-cell Profiles for Expression Recovery', 'authors': 'Amit Kumar, Maninder Kaur, Raghvendra Mall, Sukrit Gupta', 'link': 'https://arxiv.org/abs/2511.15139', 'abstract': 'Spatial Transcriptomics enables mapping of gene expression within its native tissue context, but current platforms measure only a limited set of genes due to experimental constraints and excessive costs. To overcome this, computational models integrate Single-Cell RNA Sequencing data with Spatial Transcriptomics to predict unmeasured genes. We propose CASPER, a cross-attention based framework that predicts unmeasured gene expression in Spatial Transcriptomics by leveraging centroid-level representations from Single-Cell RNA Sequencing. We performed rigorous testing over four state-of-the-art Spatial Transcriptomics/Single-Cell RNA Sequencing dataset pairs across four existing baseline models. CASPER shows significant improvement in nine out of the twelve metrics for our experiments. This work paves the way for further work in Spatial Transcriptomics to Single-Cell RNA Sequencing modality translation. The code for CASPER is available at this https URL.', 'abstract_zh': '空间转录组学能够在其自然组织背景下映射基因表达，但由于实验限制和高昂成本，当前平台只能测量有限数量的基因。为克服这一问题，计算模型将单细胞RNA测序数据与空间转录组学数据集成，以预测未测量的基因表达。我们提出了一种基于跨注意力的框架CASPER，利用单细胞RNA测序的中心点级表示来预测空间转录组学中的未测量基因表达。我们在四个现有基线模型上对四个最先进的空间转录组学/单细胞RNA测序数据集对进行了严格的测试。CASPER在我们实验中的十二个指标中有九个指标显示出显著改进。这项工作为后续将空间转录组学转化为单细胞RNA测序模式的研究铺平了道路。CASPER的代码可在此处访问。', 'title_zh': 'CASPER: 空间与单细胞谱型的跨模态对齐以恢复表达'}
{'arxiv_id': 'arXiv:2511.15141', 'title': 'ItemRAG: Item-Based Retrieval-Augmented Generation for LLM-Based Recommendation', 'authors': 'Sunwoo Kim, Geon Lee, Kyungho Kim, Jaemin Yoo, Kijung Shin', 'link': 'https://arxiv.org/abs/2511.15141', 'abstract': 'Recently, large language models (LLMs) have been widely used as recommender systems, owing to their strong reasoning capability and their effectiveness in handling cold-start items. To better adapt LLMs for recommendation, retrieval-augmented generation (RAG) has been incorporated. Most existing RAG methods are user-based, retrieving purchase patterns of users similar to the target user and providing them to the LLM. In this work, we propose ItemRAG, an item-based RAG method for LLM-based recommendation that retrieves relevant items (rather than users) from item-item co-purchase histories. ItemRAG helps LLMs capture co-purchase patterns among items, which are beneficial for recommendations. Especially, our retrieval strategy incorporates semantically similar items to better handle cold-start items and uses co-purchase frequencies to improve the relevance of the retrieved items. Through extensive experiments, we demonstrate that ItemRAG consistently (1) improves the zero-shot LLM-based recommender by up to 43% in Hit-Ratio-1 and (2) outperforms user-based RAG baselines under both standard and cold-start item recommendation settings.', 'abstract_zh': '基于项目的RAG方法：ItemRAG在LLM推荐中的应用', 'title_zh': '基于项目检索增强生成的LLM推荐方法'}
{'arxiv_id': 'arXiv:2511.15122', 'title': 'Multi-Aspect Cross-modal Quantization for Generative Recommendation', 'authors': 'Fuwei Zhang, Xiaoyu Liu, Dongbo Xi, Jishen Yin, Huan Chen, Peng Yan, Fuzhen Zhuang, Zhao Zhang', 'link': 'https://arxiv.org/abs/2511.15122', 'abstract': "Generative Recommendation (GR) has emerged as a new paradigm in recommender systems. This approach relies on quantized representations to discretize item features, modeling users' historical interactions as sequences of discrete tokens. Based on these tokenized sequences, GR predicts the next item by employing next-token prediction methods. The challenges of GR lie in constructing high-quality semantic identifiers (IDs) that are hierarchically organized, minimally conflicting, and conducive to effective generative model training. However, current approaches remain limited in their ability to harness multimodal information and to capture the deep and intricate interactions among diverse modalities, both of which are essential for learning high-quality semantic IDs and for effectively training GR models. To address this, we propose Multi-Aspect Cross-modal quantization for generative Recommendation (MACRec), which introduces multimodal information and incorporates it into both semantic ID learning and generative model training from different aspects. Specifically, we first introduce cross-modal quantization during the ID learning process, which effectively reduces conflict rates and thus improves codebook usability through the complementary integration of multimodal information. In addition, to further enhance the generative ability of our GR model, we incorporate multi-aspect cross-modal alignments, including the implicit and explicit alignments. Finally, we conduct extensive experiments on three well-known recommendation datasets to demonstrate the effectiveness of our proposed method.", 'abstract_zh': '多方面跨模态量化生成推荐（Multi-Aspect Cross-modal Quantization for Generative Recommendation, MACRec）', 'title_zh': '多方面跨模态量化生成推荐'}
{'arxiv_id': 'arXiv:2511.15137', 'title': 'From Solving to Verifying: A Unified Objective for Robust Reasoning in LLMs', 'authors': 'Xiaoxuan Wang, Bo Liu, Song Jiang, Jingzhou Liu, Jingyuan Qi, Xia Chen, Baosheng He', 'link': 'https://arxiv.org/abs/2511.15137', 'abstract': 'The reasoning capabilities of large language models (LLMs) have been significantly improved through reinforcement learning (RL). Nevertheless, LLMs still struggle to consistently verify their own reasoning traces. This raises the research question of how to enhance the self-verification ability of LLMs and whether such an ability can further improve reasoning performance. In this work, we propose GRPO-Verif, an algorithm that jointly optimizes solution generation and self-verification within a unified loss function, with an adjustable hyperparameter controlling the weight of the verification signal. Experimental results demonstrate that our method enhances self-verification capability while maintaining comparable performance in reasoning.', 'abstract_zh': '大型语言模型（LLMs）通过强化学习（RL）显著提升了推理能力，但仍难以一致地验证自身的推理轨迹。本研究探讨了如何增强LLMs的自我验证能力，以及这种能力能否进一步提高推理性能。我们提出了一种名为GRPO-Verif的算法，在统一的损失函数中同时优化解的生成和自我验证，并通过可调节的超参数控制验证信号的权重。实验结果表明，该方法在保持相当推理性能的同时增强了自我验证能力。', 'title_zh': '从求解到验证：LLMs中健壮推理的统一目标'}
{'arxiv_id': 'arXiv:2511.15139', 'title': 'CASPER: Cross-modal Alignment of Spatial and single-cell Profiles for Expression Recovery', 'authors': 'Amit Kumar, Maninder Kaur, Raghvendra Mall, Sukrit Gupta', 'link': 'https://arxiv.org/abs/2511.15139', 'abstract': 'Spatial Transcriptomics enables mapping of gene expression within its native tissue context, but current platforms measure only a limited set of genes due to experimental constraints and excessive costs. To overcome this, computational models integrate Single-Cell RNA Sequencing data with Spatial Transcriptomics to predict unmeasured genes. We propose CASPER, a cross-attention based framework that predicts unmeasured gene expression in Spatial Transcriptomics by leveraging centroid-level representations from Single-Cell RNA Sequencing. We performed rigorous testing over four state-of-the-art Spatial Transcriptomics/Single-Cell RNA Sequencing dataset pairs across four existing baseline models. CASPER shows significant improvement in nine out of the twelve metrics for our experiments. This work paves the way for further work in Spatial Transcriptomics to Single-Cell RNA Sequencing modality translation. The code for CASPER is available at this https URL.', 'abstract_zh': '空间转录组学能够在其原位组织环境中映射基因表达，但由于实验限制和高昂的成本，当前的平台只能测量有限的基因。为克服这一问题，计算模型结合单细胞RNA测序数据与空间转录组学以预测未测量的基因表达。我们提出了一种基于跨注意力机制的框架CASPER，通过利用单细胞RNA测序的中心点级表示来预测空间转录组学中的未测量基因表达。我们在四个现有的基线模型上对四个最先进的空间转录组学/单细胞RNA测序数据集对进行了严格的测试。实验结果表明，CASPER在十二个评价指标中有九个指标上表现显著提升。本项工作为进一步探索空间转录组学到单细胞RNA测序模态转化铺平了道路。CASPER的代码可在以下链接获取。', 'title_zh': 'CASPER：空间与单细胞谱型的跨模态对齐以实现表达恢复'}
{'arxiv_id': 'arXiv:2511.15120', 'title': 'Neural Networks Learn Generic Multi-Index Models Near Information-Theoretic Limit', 'authors': 'Bohan Zhang, Zihao Wang, Hengyu Fu, Jason D. Lee', 'link': 'https://arxiv.org/abs/2511.15120', 'abstract': 'In deep learning, a central issue is to understand how neural networks efficiently learn high-dimensional features. To this end, we explore the gradient descent learning of a general Gaussian Multi-index model $f(\\boldsymbol{x})=g(\\boldsymbol{U}\\boldsymbol{x})$ with hidden subspace $\\boldsymbol{U}\\in \\mathbb{R}^{r\\times d}$, which is the canonical setup to study representation learning. We prove that under generic non-degenerate assumptions on the link function, a standard two-layer neural network trained via layer-wise gradient descent can agnostically learn the target with $o_d(1)$ test error using $\\widetilde{\\mathcal{O}}(d)$ samples and $\\widetilde{\\mathcal{O}}(d^2)$ time. The sample and time complexity both align with the information-theoretic limit up to leading order and are therefore optimal. During the first stage of gradient descent learning, the proof proceeds via showing that the inner weights can perform a power-iteration process. This process implicitly mimics a spectral start for the whole span of the hidden subspace and eventually eliminates finite-sample noise and recovers this span. It surprisingly indicates that optimal results can only be achieved if the first layer is trained for more than $\\mathcal{O}(1)$ steps. This work demonstrates the ability of neural networks to effectively learn hierarchical functions with respect to both sample and time efficiency.', 'abstract_zh': '深度学习中一个核心问题是理解神经网络如何高效学习高维特征。为此，我们探讨了一般高斯多索引模型 $f(\\boldsymbol{x})=g(\\boldsymbol{U}\\boldsymbol{x})$ 的梯度下降学习，其中隐藏子空间 $\\boldsymbol{U}\\in \\mathbb{R}^{r\\times d}$，这是研究表示学习的经典设置。我们证明，在链接函数满足一般非退化假设时，通过分层梯度下降训练的标准两层神经网络可以在 $\\widetilde{\\mathcal{O}}(d)$ 样本和 $\\widetilde{\\mathcal{O}}(d^2)$ 时间内以 $o_d(1)$ 测试误差无偏地学习目标。样本和时间复杂性均与信息论极限相符，因此是 optimal 的。在梯度下降学习的第一阶段，证明过程通过展示内权重可以执行幂迭代过程来进行。这一过程隐含地模拟了整个隐藏子空间的谱开始，并最终消除了有限样本噪声，恢复了该子空间。这表明，只有当第一层被训练超过 $\\mathcal{O}(1)$ 步时，才能实现最优结果。本工作展示了神经网络在样本和时间效率两方面有效学习分层函数的能力。', 'title_zh': '神经网络在接近信息论极限附近学习通用多索引模型'}
{'arxiv_id': 'arXiv:2511.15122', 'title': 'Multi-Aspect Cross-modal Quantization for Generative Recommendation', 'authors': 'Fuwei Zhang, Xiaoyu Liu, Dongbo Xi, Jishen Yin, Huan Chen, Peng Yan, Fuzhen Zhuang, Zhao Zhang', 'link': 'https://arxiv.org/abs/2511.15122', 'abstract': "Generative Recommendation (GR) has emerged as a new paradigm in recommender systems. This approach relies on quantized representations to discretize item features, modeling users' historical interactions as sequences of discrete tokens. Based on these tokenized sequences, GR predicts the next item by employing next-token prediction methods. The challenges of GR lie in constructing high-quality semantic identifiers (IDs) that are hierarchically organized, minimally conflicting, and conducive to effective generative model training. However, current approaches remain limited in their ability to harness multimodal information and to capture the deep and intricate interactions among diverse modalities, both of which are essential for learning high-quality semantic IDs and for effectively training GR models. To address this, we propose Multi-Aspect Cross-modal quantization for generative Recommendation (MACRec), which introduces multimodal information and incorporates it into both semantic ID learning and generative model training from different aspects. Specifically, we first introduce cross-modal quantization during the ID learning process, which effectively reduces conflict rates and thus improves codebook usability through the complementary integration of multimodal information. In addition, to further enhance the generative ability of our GR model, we incorporate multi-aspect cross-modal alignments, including the implicit and explicit alignments. Finally, we conduct extensive experiments on three well-known recommendation datasets to demonstrate the effectiveness of our proposed method.", 'abstract_zh': '多模态跨方面量化的生成推荐（Multi-Aspect Cross-modal Quantization for Generative Recommendation, MACRec）', 'title_zh': '多方面跨模态量化生成推荐'}
{'arxiv_id': 'arXiv:2511.15137', 'title': 'From Solving to Verifying: A Unified Objective for Robust Reasoning in LLMs', 'authors': 'Xiaoxuan Wang, Bo Liu, Song Jiang, Jingzhou Liu, Jingyuan Qi, Xia Chen, Baosheng He', 'link': 'https://arxiv.org/abs/2511.15137', 'abstract': 'The reasoning capabilities of large language models (LLMs) have been significantly improved through reinforcement learning (RL). Nevertheless, LLMs still struggle to consistently verify their own reasoning traces. This raises the research question of how to enhance the self-verification ability of LLMs and whether such an ability can further improve reasoning performance. In this work, we propose GRPO-Verif, an algorithm that jointly optimizes solution generation and self-verification within a unified loss function, with an adjustable hyperparameter controlling the weight of the verification signal. Experimental results demonstrate that our method enhances self-verification capability while maintaining comparable performance in reasoning.', 'abstract_zh': '大型语言模型（LLMs）通过强化学习（RL）显著提升了其推理能力，但仍难以一致地验证自身的推理轨迹。本研究探讨了如何增强LLMs的自我验证能力，以及这种能力是否能进一步提升推理性能。我们提出了GRPO-Verif算法，该算法在统一的损失函数中共同优化解的生成和自我验证，并通过可调节的超参数控制验证信号的权重。实验结果表明，该方法增强了自我验证能力，同时保持了在推理性能上的可比性。', 'title_zh': '从求解到验证：LLM中稳健推理的统一目标'}
{'arxiv_id': 'arXiv:2511.15112', 'title': 'Semiconductor Industry Trend Prediction with Event Intervention Based on LSTM Model in Sentiment-Enhanced Time Series Data', 'authors': 'Wei-hsiang Yen, Lyn Chao-ling Chen', 'link': 'https://arxiv.org/abs/2511.15112', 'abstract': 'The innovation of the study is that the deep learning method and sentiment analysis are integrated in traditional business model analysis and forecasting, and the research subject is TSMC for industry trend prediction of semiconductor industry in Taiwan. For the rapid market changes and development of wafer technologies of semiconductor industry, traditional data analysis methods not perform well in the high variety and time series data. Textual data and time series data were collected from seasonal reports of TSMC including financial information. Textual data through sentiment analysis by considering the event intervention both from internal events of the company and the external global events. Using the sentiment-enhanced time series data, the LSTM model was adopted for predicting industry trend of TSMC. The prediction results reveal significant development of wafer technology of TSMC and the potential threatens in the global market, and matches the product released news of TSMC and the international news. The contribution of the work performed accurately in industry trend prediction of the semiconductor industry by considering both the internal and external event intervention, and the prediction results provide valuable information of semiconductor industry both in research and business aspects.', 'abstract_zh': '研究的创新在于将深度学习方法和情感分析融入传统商业模式分析和预测中，并以台积公司(TSMC)为研究对象，预测台湾半导体产业的发展趋势。由于半导体产业市场变化迅速和技术节点的快速发展，传统的数据分析方法在处理高变异性与时序数据方面效果不佳。从台积公司的季度报告中收集文本数据和时序数据，包括财务信息。通过情感分析考虑公司内部事件和外部全球事件的影响，对文本数据进行处理。使用情感增强的时序数据，采用LSTM模型预测台积公司的产业发展趋势。预测结果揭示了台积公司晶圆技术的重要发展及其在全球市场的潜在威胁，并与台积公司的产品发布新闻和国际新闻相符。本研究的工作准确地考虑了内部和外部事件干预，通过预测半导体产业的发展趋势提供了有价值的研究和商业信息。', 'title_zh': '基于事件干预的改进情感时间序列数据LSTM模型的半导体行业趋势预测'}
{'arxiv_id': 'arXiv:2511.15122', 'title': 'Multi-Aspect Cross-modal Quantization for Generative Recommendation', 'authors': 'Fuwei Zhang, Xiaoyu Liu, Dongbo Xi, Jishen Yin, Huan Chen, Peng Yan, Fuzhen Zhuang, Zhao Zhang', 'link': 'https://arxiv.org/abs/2511.15122', 'abstract': "Generative Recommendation (GR) has emerged as a new paradigm in recommender systems. This approach relies on quantized representations to discretize item features, modeling users' historical interactions as sequences of discrete tokens. Based on these tokenized sequences, GR predicts the next item by employing next-token prediction methods. The challenges of GR lie in constructing high-quality semantic identifiers (IDs) that are hierarchically organized, minimally conflicting, and conducive to effective generative model training. However, current approaches remain limited in their ability to harness multimodal information and to capture the deep and intricate interactions among diverse modalities, both of which are essential for learning high-quality semantic IDs and for effectively training GR models. To address this, we propose Multi-Aspect Cross-modal quantization for generative Recommendation (MACRec), which introduces multimodal information and incorporates it into both semantic ID learning and generative model training from different aspects. Specifically, we first introduce cross-modal quantization during the ID learning process, which effectively reduces conflict rates and thus improves codebook usability through the complementary integration of multimodal information. In addition, to further enhance the generative ability of our GR model, we incorporate multi-aspect cross-modal alignments, including the implicit and explicit alignments. Finally, we conduct extensive experiments on three well-known recommendation datasets to demonstrate the effectiveness of our proposed method.", 'abstract_zh': '多方面跨模态量化生成推荐（MACRec）', 'title_zh': '多方面跨模态量化生成推荐'}
{'arxiv_id': 'arXiv:2511.15120', 'title': 'Neural Networks Learn Generic Multi-Index Models Near Information-Theoretic Limit', 'authors': 'Bohan Zhang, Zihao Wang, Hengyu Fu, Jason D. Lee', 'link': 'https://arxiv.org/abs/2511.15120', 'abstract': 'In deep learning, a central issue is to understand how neural networks efficiently learn high-dimensional features. To this end, we explore the gradient descent learning of a general Gaussian Multi-index model $f(\\boldsymbol{x})=g(\\boldsymbol{U}\\boldsymbol{x})$ with hidden subspace $\\boldsymbol{U}\\in \\mathbb{R}^{r\\times d}$, which is the canonical setup to study representation learning. We prove that under generic non-degenerate assumptions on the link function, a standard two-layer neural network trained via layer-wise gradient descent can agnostically learn the target with $o_d(1)$ test error using $\\widetilde{\\mathcal{O}}(d)$ samples and $\\widetilde{\\mathcal{O}}(d^2)$ time. The sample and time complexity both align with the information-theoretic limit up to leading order and are therefore optimal. During the first stage of gradient descent learning, the proof proceeds via showing that the inner weights can perform a power-iteration process. This process implicitly mimics a spectral start for the whole span of the hidden subspace and eventually eliminates finite-sample noise and recovers this span. It surprisingly indicates that optimal results can only be achieved if the first layer is trained for more than $\\mathcal{O}(1)$ steps. This work demonstrates the ability of neural networks to effectively learn hierarchical functions with respect to both sample and time efficiency.', 'abstract_zh': '深度学习中的一个核心问题是理解神经网络如何高效地学习高维特征。为此，我们探索了一般的高斯多索引模型 \\(f(\\boldsymbol{x})=g(\\boldsymbol{U}\\boldsymbol{x})\\) 的梯度下降学习，其中隐藏子空间 \\(\\boldsymbol{U}\\in \\mathbb{R}^{r\\times d}\\)，这是研究表示学习的经典设置。我们证明，在链接函数的一般非退化的假设下，通过分层梯度下降训练的标准两层神经网络可以在几乎 \\(\\log(d)\\) 的测试误差下使用 \\(\\widetilde{\\mathcal{O}}(d)\\) 个样本和 \\(\\widetilde{\\mathcal{O}}(d^2)\\) 的时间进行agnostically 学习目标。样本复杂性和时间复杂性都与信息论极限在主要项上一致，因此是最佳的。在梯度下降学习的第一阶段，证明通过展示内部权重可以执行幂迭代过程来进行。此过程隐式地为隐藏子空间的整个跨度模拟了谱开始，并最终消除了有限样本噪声并恢复了这个跨度。这令人惊讶地表明，只有当第一层训练超过 \\(\\mathcal{O}(1)\\) 步时，才能获得最优结果。这项工作展示了神经网络在样本和时间效率方面有效学习分层函数的能力。', 'title_zh': '神经网络学习通用多索引模型接近信息论极限'}
{'arxiv_id': 'arXiv:2511.15110', 'title': 'Eye Care You: Voice Guidance Application Using Social Robot for Visually Impaired People', 'authors': 'Ting-An Lin, Pei-Lin Tsai, Yi-An Chen, Feng-Yu Chen, Lyn Chao-ling Chen', 'link': 'https://arxiv.org/abs/2511.15110', 'abstract': 'In the study, the device of social robot was designed for visually impaired users, and along with a mobile application for provide functions to assist their lives. Both physical and mental conditions of visually impaired users are considered, and the mobile application provides functions: photo record, mood lift, greeting guest and today highlight. The application was designed for visually impaired users, and uses voice control to provide a friendly interface. Photo record function allows visually impaired users to capture image immediately when they encounter danger situations. Mood lift function accompanies visually impaired users by asking questions, playing music and reading articles. Greeting guest function answers to the visitors for the inconvenient physical condition of visually impaired users. In addition, today highlight function read news including weather forecast, daily horoscopes and daily reminder for visually impaired users. Multiple tools were adopted for developing the mobile application, and a website was developed for caregivers to check statues of visually impaired users and for marketing of the application.', 'abstract_zh': '一种为视障用户提供物理和心理辅助的社交机器人装置及移动应用研究', 'title_zh': '您的眼睛：面向视觉受损人士的社会机器人语音引导应用'}
{'arxiv_id': 'arXiv:2511.15120', 'title': 'Neural Networks Learn Generic Multi-Index Models Near Information-Theoretic Limit', 'authors': 'Bohan Zhang, Zihao Wang, Hengyu Fu, Jason D. Lee', 'link': 'https://arxiv.org/abs/2511.15120', 'abstract': 'In deep learning, a central issue is to understand how neural networks efficiently learn high-dimensional features. To this end, we explore the gradient descent learning of a general Gaussian Multi-index model $f(\\boldsymbol{x})=g(\\boldsymbol{U}\\boldsymbol{x})$ with hidden subspace $\\boldsymbol{U}\\in \\mathbb{R}^{r\\times d}$, which is the canonical setup to study representation learning. We prove that under generic non-degenerate assumptions on the link function, a standard two-layer neural network trained via layer-wise gradient descent can agnostically learn the target with $o_d(1)$ test error using $\\widetilde{\\mathcal{O}}(d)$ samples and $\\widetilde{\\mathcal{O}}(d^2)$ time. The sample and time complexity both align with the information-theoretic limit up to leading order and are therefore optimal. During the first stage of gradient descent learning, the proof proceeds via showing that the inner weights can perform a power-iteration process. This process implicitly mimics a spectral start for the whole span of the hidden subspace and eventually eliminates finite-sample noise and recovers this span. It surprisingly indicates that optimal results can only be achieved if the first layer is trained for more than $\\mathcal{O}(1)$ steps. This work demonstrates the ability of neural networks to effectively learn hierarchical functions with respect to both sample and time efficiency.', 'abstract_zh': '深度学习中一个核心问题是理解神经网络如何高效地学习高维特征。为此，我们探索了一般高斯多索引模型 \\(f(\\boldsymbol{x})=g(\\boldsymbol{U}\\boldsymbol{x})\\) 的逐层梯度下降学习，其中隐藏子空间 \\(\\boldsymbol{U}\\in \\mathbb{R}^{r\\times d}\\)，这是研究表示学习的经典设置。我们证明，在链函数满足通用非退化假设的情况下，通过逐层梯度下降训练的标准两层神经网络可以在 \\(\\widetilde{\\mathcal{O}}(d)\\) 样本和 \\(\\widetilde{\\mathcal{O}}(d^2)\\) 时间内以 \\(o_d(1)\\) 的测试误差学习目标，样本和时间复杂度都与信息论极限在主要项上一致，因此是最优的。在梯度下降学习的第一阶段，证明通过表明内部权重可以执行幂迭代过程来进行。这一过程隐式地模仿了整个隐藏子空间范围的谱初始化，并最终消除有限样本噪声并恢复该范围。这意外地表明，只有当第一层被训练超过 \\(\\mathcal{O}(1)\\) 步时，才能获得最优结果。这项工作展示了神经网络在样本和时间效率方面有效地学习分层函数的能力。', 'title_zh': '神经网络在接近信息论极限的情况下学习通用多索引模型'}
{'arxiv_id': 'arXiv:2511.15112', 'title': 'Semiconductor Industry Trend Prediction with Event Intervention Based on LSTM Model in Sentiment-Enhanced Time Series Data', 'authors': 'Wei-hsiang Yen, Lyn Chao-ling Chen', 'link': 'https://arxiv.org/abs/2511.15112', 'abstract': 'The innovation of the study is that the deep learning method and sentiment analysis are integrated in traditional business model analysis and forecasting, and the research subject is TSMC for industry trend prediction of semiconductor industry in Taiwan. For the rapid market changes and development of wafer technologies of semiconductor industry, traditional data analysis methods not perform well in the high variety and time series data. Textual data and time series data were collected from seasonal reports of TSMC including financial information. Textual data through sentiment analysis by considering the event intervention both from internal events of the company and the external global events. Using the sentiment-enhanced time series data, the LSTM model was adopted for predicting industry trend of TSMC. The prediction results reveal significant development of wafer technology of TSMC and the potential threatens in the global market, and matches the product released news of TSMC and the international news. The contribution of the work performed accurately in industry trend prediction of the semiconductor industry by considering both the internal and external event intervention, and the prediction results provide valuable information of semiconductor industry both in research and business aspects.', 'abstract_zh': '研究的创新在于将深度学习方法和情感分析融入传统的商业模型分析和预测中，研究对象为台积电（TSMC），旨在预测台湾半导体行业的发展趋势。由于半导体行业市场变化迅速且晶圆技术发展迅速，传统数据分析方法在处理高多样性和时间序列数据时表现不佳。研究收集了台积电（TSMC）四季财务报告中的文本数据和时间序列数据。通过考虑公司内部事件和外部全球事件的情感分析，对文本数据进行处理。使用增强情感的时间序列数据，采用LSTM模型预测台积电的行业趋势。预测结果揭示了台积电晶圆技术的显著发展和全球市场的潜在威胁，并与台积电发布的产品新闻及国际新闻相符。此项工作在考虑内外事件干预的情况下，准确地预测了半导体行业的趋势，其预测结果在研究和商业方面均提供了宝贵的信息。', 'title_zh': '基于事件干预的情感增强时间序列数据LSTM模型在半导体行业趋势预测中的应用'}
{'arxiv_id': 'arXiv:2511.15107', 'title': 'Effective Code Membership Inference for Code Completion Models via Adversarial Prompts', 'authors': 'Yuan Jiang, Zehao Li, Shan Huang, Christoph Treude, Xiaohong Su, Tiantian Wang', 'link': 'https://arxiv.org/abs/2511.15107', 'abstract': "Membership inference attacks (MIAs) on code completion models offer an effective way to assess privacy risks by inferring whether a given code snippet was part of the training data. Existing black- and gray-box MIAs rely on expensive surrogate models or manually crafted heuristic rules, which limit their ability to capture the nuanced memorization patterns exhibited by over-parameterized code language models. To address these challenges, we propose AdvPrompt-MIA, a method specifically designed for code completion models, combining code-specific adversarial perturbations with deep learning. The core novelty of our method lies in designing a series of adversarial prompts that induce variations in the victim code model's output. By comparing these outputs with the ground-truth completion, we construct feature vectors to train a classifier that automatically distinguishes member from non-member samples. This design allows our method to capture richer memorization patterns and accurately infer training set membership. We conduct comprehensive evaluations on widely adopted models, such as Code Llama 7B, over the APPS and HumanEval benchmarks. The results show that our approach consistently outperforms state-of-the-art baselines, with AUC gains of up to 102%. In addition, our method exhibits strong transferability across different models and datasets, underscoring its practical utility and generalizability.", 'abstract_zh': '代码补全模型的会员推断攻击：AdvPrompt-MIA方法及其应用', 'title_zh': '通过对抗提示的有效代码成员推断针对代码完成模型的研究'}
{'arxiv_id': 'arXiv:2511.15112', 'title': 'Semiconductor Industry Trend Prediction with Event Intervention Based on LSTM Model in Sentiment-Enhanced Time Series Data', 'authors': 'Wei-hsiang Yen, Lyn Chao-ling Chen', 'link': 'https://arxiv.org/abs/2511.15112', 'abstract': 'The innovation of the study is that the deep learning method and sentiment analysis are integrated in traditional business model analysis and forecasting, and the research subject is TSMC for industry trend prediction of semiconductor industry in Taiwan. For the rapid market changes and development of wafer technologies of semiconductor industry, traditional data analysis methods not perform well in the high variety and time series data. Textual data and time series data were collected from seasonal reports of TSMC including financial information. Textual data through sentiment analysis by considering the event intervention both from internal events of the company and the external global events. Using the sentiment-enhanced time series data, the LSTM model was adopted for predicting industry trend of TSMC. The prediction results reveal significant development of wafer technology of TSMC and the potential threatens in the global market, and matches the product released news of TSMC and the international news. The contribution of the work performed accurately in industry trend prediction of the semiconductor industry by considering both the internal and external event intervention, and the prediction results provide valuable information of semiconductor industry both in research and business aspects.', 'abstract_zh': '传统商业模式分析与预测中将深度学习方法和情感分析 integrated 的创新研究：以 TSMC 的半导体行业趋势预测为例', 'title_zh': '基于事件介入的情感增强时间序列数据LSTM模型的半导体行业趋势预测'}
{'arxiv_id': 'arXiv:2511.15110', 'title': 'Eye Care You: Voice Guidance Application Using Social Robot for Visually Impaired People', 'authors': 'Ting-An Lin, Pei-Lin Tsai, Yi-An Chen, Feng-Yu Chen, Lyn Chao-ling Chen', 'link': 'https://arxiv.org/abs/2511.15110', 'abstract': 'In the study, the device of social robot was designed for visually impaired users, and along with a mobile application for provide functions to assist their lives. Both physical and mental conditions of visually impaired users are considered, and the mobile application provides functions: photo record, mood lift, greeting guest and today highlight. The application was designed for visually impaired users, and uses voice control to provide a friendly interface. Photo record function allows visually impaired users to capture image immediately when they encounter danger situations. Mood lift function accompanies visually impaired users by asking questions, playing music and reading articles. Greeting guest function answers to the visitors for the inconvenient physical condition of visually impaired users. In addition, today highlight function read news including weather forecast, daily horoscopes and daily reminder for visually impaired users. Multiple tools were adopted for developing the mobile application, and a website was developed for caregivers to check statues of visually impaired users and for marketing of the application.', 'abstract_zh': '一种用于视障用户的社交机器人设备及移动应用程序设计与实现：身体与心理关怀功能探究', 'title_zh': '你的眼睛护理：面向视障人士的社交机器人语音引导应用'}
{'arxiv_id': 'arXiv:2511.15097', 'title': 'MAIF: Enforcing AI Trust and Provenance with an Artifact-Centric Agentic Paradigm', 'authors': 'Vineeth Sai Narajala, Manish Bhatt, Idan Habler, Ronald F. Del Rosario', 'link': 'https://arxiv.org/abs/2511.15097', 'abstract': 'The AI trustworthiness crisis threatens to derail the artificial intelligence revolution, with regulatory barriers, security vulnerabilities, and accountability gaps preventing deployment in critical domains. Current AI systems operate on opaque data structures that lack the audit trails, provenance tracking, or explainability required by emerging regulations like the EU AI Act. We propose an artifact-centric AI agent paradigm where behavior is driven by persistent, verifiable data artifacts rather than ephemeral tasks, solving the trustworthiness problem at the data architecture level. Central to this approach is the Multimodal Artifact File Format (MAIF), an AI-native container embedding semantic representations, cryptographic provenance, and granular access controls. MAIF transforms data from passive storage into active trust enforcement, making every AI operation inherently auditable. Our production-ready implementation demonstrates ultra-high-speed streaming (2,720.7 MB/s), optimized video processing (1,342 MB/s), and enterprise-grade security. Novel algorithms for cross-modal attention, semantic compression, and cryptographic binding achieve up to 225 compression while maintaining semantic fidelity. Advanced security features include stream-level access control, real-time tamper detection, and behavioral anomaly analysis with minimal overhead. This approach directly addresses the regulatory, security, and accountability challenges preventing AI deployment in sensitive domains, offering a viable path toward trustworthy AI systems at scale.', 'abstract_zh': 'AI可信危机威胁人工智能革命，监管障碍、安全漏洞和问责空白导致关键技术领域无法部署。当前AI系统依赖不透明的数据结构，缺乏新兴法规（如欧盟AI法案）所需的审计追踪、来源追踪或解释性。我们提出一种以制品为中心的AI代理范式，行为由持久且可验证的数据制品驱动，而非短暂的任务，从数据架构层面解决可信问题。核心在于多模态制品文件格式（MAIF），这是一种AI原生容器，嵌入语义表示、加密溯源和细粒度访问控制。MAIF将数据从被动存储转变为积极的信任实施，使每一项AI操作都具有内在的可审计性。我们成熟的实现方案展示了超高速流传输（2,720.7 MB/s）、优化视频处理（1,342 MB/s）和企业级安全。新型跨模态注意力、语义压缩和加密绑定算法可实现高达225的压缩比，同时保持语义保真度。高级安全功能包括流级访问控制、实时篡改检测和行为异常分析，且具有最小的开销。该方法直接应对关键领域AI部署面临的监管、安全和问责挑战，提供了一条可扩展的可信AI系统实施路径。', 'title_zh': 'MAIF: 以 artifact 为中心的代理范式保障 AI 的可信与可追溯性'}
{'arxiv_id': 'arXiv:2511.15110', 'title': 'Eye Care You: Voice Guidance Application Using Social Robot for Visually Impaired People', 'authors': 'Ting-An Lin, Pei-Lin Tsai, Yi-An Chen, Feng-Yu Chen, Lyn Chao-ling Chen', 'link': 'https://arxiv.org/abs/2511.15110', 'abstract': 'In the study, the device of social robot was designed for visually impaired users, and along with a mobile application for provide functions to assist their lives. Both physical and mental conditions of visually impaired users are considered, and the mobile application provides functions: photo record, mood lift, greeting guest and today highlight. The application was designed for visually impaired users, and uses voice control to provide a friendly interface. Photo record function allows visually impaired users to capture image immediately when they encounter danger situations. Mood lift function accompanies visually impaired users by asking questions, playing music and reading articles. Greeting guest function answers to the visitors for the inconvenient physical condition of visually impaired users. In addition, today highlight function read news including weather forecast, daily horoscopes and daily reminder for visually impaired users. Multiple tools were adopted for developing the mobile application, and a website was developed for caregivers to check statues of visually impaired users and for marketing of the application.', 'abstract_zh': '基于社交机器人的辅助视障用户移动应用设计与实现', 'title_zh': '你的眼眸：用于视觉障碍人士的社交机器人语音引导应用'}
{'arxiv_id': 'arXiv:2511.15107', 'title': 'Effective Code Membership Inference for Code Completion Models via Adversarial Prompts', 'authors': 'Yuan Jiang, Zehao Li, Shan Huang, Christoph Treude, Xiaohong Su, Tiantian Wang', 'link': 'https://arxiv.org/abs/2511.15107', 'abstract': "Membership inference attacks (MIAs) on code completion models offer an effective way to assess privacy risks by inferring whether a given code snippet was part of the training data. Existing black- and gray-box MIAs rely on expensive surrogate models or manually crafted heuristic rules, which limit their ability to capture the nuanced memorization patterns exhibited by over-parameterized code language models. To address these challenges, we propose AdvPrompt-MIA, a method specifically designed for code completion models, combining code-specific adversarial perturbations with deep learning. The core novelty of our method lies in designing a series of adversarial prompts that induce variations in the victim code model's output. By comparing these outputs with the ground-truth completion, we construct feature vectors to train a classifier that automatically distinguishes member from non-member samples. This design allows our method to capture richer memorization patterns and accurately infer training set membership. We conduct comprehensive evaluations on widely adopted models, such as Code Llama 7B, over the APPS and HumanEval benchmarks. The results show that our approach consistently outperforms state-of-the-art baselines, with AUC gains of up to 102%. In addition, our method exhibits strong transferability across different models and datasets, underscoring its practical utility and generalizability.", 'abstract_zh': '代码补全模型中的成员推断攻击（MIAs）提供了一种有效的方法，通过推断给定代码片段是否为训练数据的一部分来评估隐私风险。现有方法依赖昂贵的替代模型或手工crafted的启发式规则，这限制了它们捕捉过度参数化代码语言模型所表现出的细腻记忆模式的能力。为了解决这些挑战，我们提出了一种名为AdvPrompt-MIA的方法，专门针对代码补全模型，结合了代码特定的对抗性扰动与深度学习。该方法的核心创新在于设计一系列对抗性提示，以诱导受害者代码模型输出的变化。通过将这些输出与 ground-truth 补全结果进行比较，我们构建特征向量来训练分类器，该分类器能够自动区分样本的成员和非成员。这种设计使我们的方法能够捕捉更丰富的记忆模式，并准确地推断训练集成员身份。我们在广泛应用的模型，如Code Llama 7B，以及APPS和HumanEval基准上进行了全面的评估。结果显示，我们的方法始终优于最先进的基线方法，AUC增益高达102%。此外，我们的方法在不同的模型和数据集上表现出强大的迁移性，突显了其实用价值和普适性。', 'title_zh': '有效代码成员推理以对抗性提示提升代码补全模型'}
{'arxiv_id': 'arXiv:2511.15090', 'title': 'BBox DocVQA: A Large Scale Bounding Box Grounded Dataset for Enhancing Reasoning in Document Visual Question Answer', 'authors': 'Wenhan Yu, Wang Chen, Guanqiang Qi, Weikang Li, Yang Li, Lei Sha, Deguo Xia, Jizhou Huang', 'link': 'https://arxiv.org/abs/2511.15090', 'abstract': 'Document Visual Question Answering (DocVQA) is a fundamental task for multimodal document understanding and a key testbed for vision language reasoning. However, most existing DocVQA datasets are limited to the page level and lack fine grained spatial grounding, constraining the interpretability and reasoning capability of Vision Language Models (VLMs). To address this gap, we introduce BBox DocVQA a large scale, bounding box grounded dataset designed to enhance spatial reasoning and evidence localization in visual documents. We further present an automated construction pipeline, Segment Judge and Generate, which integrates a segment model for region segmentation, a VLM for semantic judgment, and another advanced VLM for question answer generation, followed by human verification for quality assurance. The resulting dataset contains 3.6 K diverse documents and 32 K QA pairs, encompassing single and multi region as well as single and multi page scenarios. Each QA instance is grounded on explicit bounding boxes, enabling fine grained evaluation of spatial semantic alignment. Benchmarking multiple state of the art VLMs (e.g., GPT 5, Qwen2.5 VL, and InternVL) on BBox DocVQA reveals persistent challenges in spatial grounding and reasoning accuracy. Furthermore, fine tuning on BBox DocVQA substantially improves both bounding box localization and answer generation, validating its effectiveness for enhancing the reasoning ability of VLMs. Our dataset and code will be publicly released to advance research on interpretable and spatially grounded vision language reasoning.', 'abstract_zh': '基于边界框的文档视觉问答（Bounding Box DocVQA）：一个增强空间推理和视觉文档中细粒度空间定位的数据集', 'title_zh': 'BBox DocVQA：一个大规模边界框导向数据集，用于增强文档视觉问答中的推理能力'}
{'arxiv_id': 'arXiv:2511.15107', 'title': 'Effective Code Membership Inference for Code Completion Models via Adversarial Prompts', 'authors': 'Yuan Jiang, Zehao Li, Shan Huang, Christoph Treude, Xiaohong Su, Tiantian Wang', 'link': 'https://arxiv.org/abs/2511.15107', 'abstract': "Membership inference attacks (MIAs) on code completion models offer an effective way to assess privacy risks by inferring whether a given code snippet was part of the training data. Existing black- and gray-box MIAs rely on expensive surrogate models or manually crafted heuristic rules, which limit their ability to capture the nuanced memorization patterns exhibited by over-parameterized code language models. To address these challenges, we propose AdvPrompt-MIA, a method specifically designed for code completion models, combining code-specific adversarial perturbations with deep learning. The core novelty of our method lies in designing a series of adversarial prompts that induce variations in the victim code model's output. By comparing these outputs with the ground-truth completion, we construct feature vectors to train a classifier that automatically distinguishes member from non-member samples. This design allows our method to capture richer memorization patterns and accurately infer training set membership. We conduct comprehensive evaluations on widely adopted models, such as Code Llama 7B, over the APPS and HumanEval benchmarks. The results show that our approach consistently outperforms state-of-the-art baselines, with AUC gains of up to 102%. In addition, our method exhibits strong transferability across different models and datasets, underscoring its practical utility and generalizability.", 'abstract_zh': '代码补全模型的对抗提示会员推断攻击（AdvPrompt-MIA）：捕获丰富的记忆模式以准确推断训练集成员资格', 'title_zh': '针对代码补全模型的有效代码成员推断通过对抗提示'}
{'arxiv_id': 'arXiv:2511.15097', 'title': 'MAIF: Enforcing AI Trust and Provenance with an Artifact-Centric Agentic Paradigm', 'authors': 'Vineeth Sai Narajala, Manish Bhatt, Idan Habler, Ronald F. Del Rosario', 'link': 'https://arxiv.org/abs/2511.15097', 'abstract': 'The AI trustworthiness crisis threatens to derail the artificial intelligence revolution, with regulatory barriers, security vulnerabilities, and accountability gaps preventing deployment in critical domains. Current AI systems operate on opaque data structures that lack the audit trails, provenance tracking, or explainability required by emerging regulations like the EU AI Act. We propose an artifact-centric AI agent paradigm where behavior is driven by persistent, verifiable data artifacts rather than ephemeral tasks, solving the trustworthiness problem at the data architecture level. Central to this approach is the Multimodal Artifact File Format (MAIF), an AI-native container embedding semantic representations, cryptographic provenance, and granular access controls. MAIF transforms data from passive storage into active trust enforcement, making every AI operation inherently auditable. Our production-ready implementation demonstrates ultra-high-speed streaming (2,720.7 MB/s), optimized video processing (1,342 MB/s), and enterprise-grade security. Novel algorithms for cross-modal attention, semantic compression, and cryptographic binding achieve up to 225 compression while maintaining semantic fidelity. Advanced security features include stream-level access control, real-time tamper detection, and behavioral anomaly analysis with minimal overhead. This approach directly addresses the regulatory, security, and accountability challenges preventing AI deployment in sensitive domains, offering a viable path toward trustworthy AI systems at scale.', 'abstract_zh': 'AI可信性危机威胁着人工智能革命的进程，监管障碍、安全漏洞和责任缺口阻碍了关键领域中的应用部署。当前的AI系统依赖于不透明的数据结构，缺乏新兴法规（如欧盟AI法案）所需的审计追踪、来源追踪或可解释性。我们提出了一种以产物为中心的AI代理范式，通过持续可验证的数据产物驱动行为，而不是短暂的任务，从数据架构层面解决了可信性问题。这一方法的核心是多模态产物文件格式（MAIF），这是一种嵌入语义表示、加密来源追踪和细粒度访问控制的AI原生容器。MAIF将数据从被动存储转变为积极的可信性执行，使每一项AI操作都具有内在可审计性。我们的生产就绪实现展示了超高速流传输（2720.7 MB/s）、优化的视频处理（1342 MB/s）和企业级安全性。新型跨模态注意力、语义压缩和加密绑定算法实现了高达225倍的压缩率，同时保持语义保真度。高级安全功能包括流级别的访问控制、实时篡改检测和行为异常分析，且具有最小的开销。这种方法直接解决了阻碍AI在敏感领域应用的监管、安全和问责难题，为大规模构建可信的AI系统提供了可行的道路。', 'title_zh': 'MAIF: 以制品为中心的代理范式确保AI的信任和来源'}
{'arxiv_id': 'arXiv:2511.15097', 'title': 'MAIF: Enforcing AI Trust and Provenance with an Artifact-Centric Agentic Paradigm', 'authors': 'Vineeth Sai Narajala, Manish Bhatt, Idan Habler, Ronald F. Del Rosario', 'link': 'https://arxiv.org/abs/2511.15097', 'abstract': 'The AI trustworthiness crisis threatens to derail the artificial intelligence revolution, with regulatory barriers, security vulnerabilities, and accountability gaps preventing deployment in critical domains. Current AI systems operate on opaque data structures that lack the audit trails, provenance tracking, or explainability required by emerging regulations like the EU AI Act. We propose an artifact-centric AI agent paradigm where behavior is driven by persistent, verifiable data artifacts rather than ephemeral tasks, solving the trustworthiness problem at the data architecture level. Central to this approach is the Multimodal Artifact File Format (MAIF), an AI-native container embedding semantic representations, cryptographic provenance, and granular access controls. MAIF transforms data from passive storage into active trust enforcement, making every AI operation inherently auditable. Our production-ready implementation demonstrates ultra-high-speed streaming (2,720.7 MB/s), optimized video processing (1,342 MB/s), and enterprise-grade security. Novel algorithms for cross-modal attention, semantic compression, and cryptographic binding achieve up to 225 compression while maintaining semantic fidelity. Advanced security features include stream-level access control, real-time tamper detection, and behavioral anomaly analysis with minimal overhead. This approach directly addresses the regulatory, security, and accountability challenges preventing AI deployment in sensitive domains, offering a viable path toward trustworthy AI systems at scale.', 'abstract_zh': '人工智能可信性危机威胁着人工智能革命，监管障碍、安全漏洞和问责空白阻碍了其在关键领域的部署。当前的人工智能系统依赖于不透明的数据结构，缺乏新兴法规（如欧盟人工智能法案）所需的审计追踪、起源追踪或可解释性。我们提出了一种以艺术品为中心的人工智能代理范式，行为由持久且可验证的数据艺术品驱动，而非短暂的任务，从而在数据架构层面解决了可信性问题。这一方法的核心是多模态艺术品文件格式（MAIF），这是一种嵌入了语义表示、加密溯源和细粒度访问控制的人工智能原生容器。MAIF将数据从被动存储转变为积极的可信执行，使每一个人工智能操作本已具备可审计性。我们的生产级实现展示了超高速流式传输（2,720.7 MB/s）、优化的视频处理（1,342 MB/s）以及企业级安全性能。新颖的跨模态注意力、语义压缩和加密绑定算法实现了高达225的压缩比率，同时保持语义的准确性。高级安全特性包括流级访问控制、实时篡改检测和行为异常分析，这意味着极低的开销。这种方法直接解决了阻碍人工智能在敏感领域部署的监管、安全和问责挑战，提供了一条通往大规模可信人工智能系统的发展路径。', 'title_zh': 'MAIF: 以剂型中心代理范式确保人工智能的信任与溯源'}
{'arxiv_id': 'arXiv:2511.15076', 'title': 'GPU-Initiated Networking for NCCL', 'authors': 'Khaled Hamidouche, John Bachan, Pak Markthub, Peter-Jan Gootzen, Elena Agostini, Sylvain Jeaugey, Aamir Shafi, Georgios Theodorakis, Manjunath Gorentla Venkata', 'link': 'https://arxiv.org/abs/2511.15076', 'abstract': "Modern AI workloads, especially Mixture-of-Experts (MoE) architectures, increasingly demand low-latency, fine-grained GPU-to-GPU communication with device-side control. Traditional GPU communication follows a host-initiated model, where the CPU orchestrates all communication operations - a characteristic of the CUDA runtime. Although robust for collective operations, applications requiring tight integration of computation and communication can benefit from device-initiated communication that eliminates CPU coordination overhead.\nNCCL 2.28 introduces the Device API with three operation modes: Load/Store Accessible (LSA) for NVLink/PCIe, Multimem for NVLink SHARP, and GPU-Initiated Networking (GIN) for network RDMA. This paper presents the GIN architecture, design, semantics, and highlights its impact on MoE communication. GIN builds on a three-layer architecture: i) NCCL Core host-side APIs for device communicator setup and collective memory window registration; ii) Device-side APIs for remote memory operations callable from CUDA kernels; and iii) A network plugin architecture with dual semantics (GPUDirect Async Kernel-Initiated and Proxy) for broad hardware support. The GPUDirect Async Kernel-Initiated backend leverages DOCA GPUNetIO for direct GPU-to-NIC communication, while the Proxy backend provides equivalent functionality via lock-free GPU-to-CPU queues over standard RDMA networks. We demonstrate GIN's practicality through integration with DeepEP, an MoE communication library. Comprehensive benchmarking shows that GIN provides device-initiated communication within NCCL's unified runtime, combining low-latency operations with NCCL's collective algorithms and production infrastructure.", 'abstract_zh': '现代AI工作负载，尤其是Mixture-of-Experts (MoE)架构，越来越需要低延迟、细粒度的GPU-to-GPU通信及设备侧控制。NCCL 2.28引入了设备API，包括适用于NVLink/PCIe的Load/Store Accessible (LSA)模式、适用于NVLink SHARP的Multimem模式、以及适用于网络RDMA的GPU-Initiated Networking (GIN)模式。本文介绍了GIN架构、设计及其对MoE通信的影响。GIN基于三层架构：i) NCCL核心主机API，用于设置设备通讯器和注册集体内存窗口；ii) 设备API，可在CUDA内核中调用的远程内存操作；iii) 一种具有双重语义（GPUDirect Async Kernel-Initiated和Proxy）的网络插件架构，以广泛支持硬件。GPUDirect Async Kernel-Initiated后端通过DOCA GPUNetIO实现直接GPU-to-NIC通信，而Proxy后端通过锁-free GPU-to-CPU队列在标准RDMA网络上提供等效功能。我们通过与DeepEP MoE通信库的集成展示了GIN的实用性。全面的基准测试显示，GIN在NCCL统一运行时中实现设备发起的通信，结合了低延迟操作与NCCL的集体算法和生产基础设施。', 'title_zh': '基于GPU的网络初始化技术用于NCCL'}
{'arxiv_id': 'arXiv:2511.15090', 'title': 'BBox DocVQA: A Large Scale Bounding Box Grounded Dataset for Enhancing Reasoning in Document Visual Question Answer', 'authors': 'Wenhan Yu, Wang Chen, Guanqiang Qi, Weikang Li, Yang Li, Lei Sha, Deguo Xia, Jizhou Huang', 'link': 'https://arxiv.org/abs/2511.15090', 'abstract': 'Document Visual Question Answering (DocVQA) is a fundamental task for multimodal document understanding and a key testbed for vision language reasoning. However, most existing DocVQA datasets are limited to the page level and lack fine grained spatial grounding, constraining the interpretability and reasoning capability of Vision Language Models (VLMs). To address this gap, we introduce BBox DocVQA a large scale, bounding box grounded dataset designed to enhance spatial reasoning and evidence localization in visual documents. We further present an automated construction pipeline, Segment Judge and Generate, which integrates a segment model for region segmentation, a VLM for semantic judgment, and another advanced VLM for question answer generation, followed by human verification for quality assurance. The resulting dataset contains 3.6 K diverse documents and 32 K QA pairs, encompassing single and multi region as well as single and multi page scenarios. Each QA instance is grounded on explicit bounding boxes, enabling fine grained evaluation of spatial semantic alignment. Benchmarking multiple state of the art VLMs (e.g., GPT 5, Qwen2.5 VL, and InternVL) on BBox DocVQA reveals persistent challenges in spatial grounding and reasoning accuracy. Furthermore, fine tuning on BBox DocVQA substantially improves both bounding box localization and answer generation, validating its effectiveness for enhancing the reasoning ability of VLMs. Our dataset and code will be publicly released to advance research on interpretable and spatially grounded vision language reasoning.', 'abstract_zh': '基于边界框的文档视觉问答（BBox DocVQA）：一种增强空间推理和视觉文档中细粒度空间定位的大规模数据集', 'title_zh': 'BBox DocVQA：一个大规模边界框 grounding 数据集，用于增强文档视觉问答中的推理能力'}
{'arxiv_id': 'arXiv:2511.15090', 'title': 'BBox DocVQA: A Large Scale Bounding Box Grounded Dataset for Enhancing Reasoning in Document Visual Question Answer', 'authors': 'Wenhan Yu, Wang Chen, Guanqiang Qi, Weikang Li, Yang Li, Lei Sha, Deguo Xia, Jizhou Huang', 'link': 'https://arxiv.org/abs/2511.15090', 'abstract': 'Document Visual Question Answering (DocVQA) is a fundamental task for multimodal document understanding and a key testbed for vision language reasoning. However, most existing DocVQA datasets are limited to the page level and lack fine grained spatial grounding, constraining the interpretability and reasoning capability of Vision Language Models (VLMs). To address this gap, we introduce BBox DocVQA a large scale, bounding box grounded dataset designed to enhance spatial reasoning and evidence localization in visual documents. We further present an automated construction pipeline, Segment Judge and Generate, which integrates a segment model for region segmentation, a VLM for semantic judgment, and another advanced VLM for question answer generation, followed by human verification for quality assurance. The resulting dataset contains 3.6 K diverse documents and 32 K QA pairs, encompassing single and multi region as well as single and multi page scenarios. Each QA instance is grounded on explicit bounding boxes, enabling fine grained evaluation of spatial semantic alignment. Benchmarking multiple state of the art VLMs (e.g., GPT 5, Qwen2.5 VL, and InternVL) on BBox DocVQA reveals persistent challenges in spatial grounding and reasoning accuracy. Furthermore, fine tuning on BBox DocVQA substantially improves both bounding box localization and answer generation, validating its effectiveness for enhancing the reasoning ability of VLMs. Our dataset and code will be publicly released to advance research on interpretable and spatially grounded vision language reasoning.', 'abstract_zh': '基于边界框的文档视觉问答（BBox DocVQA）：增强空间推理和视觉文档细粒度空间定位的大规模数据集', 'title_zh': 'BBox DocVQA：一个大规模边界框 grounding 数据集，用于增强文档视觉问答中的推理能力'}
{'arxiv_id': 'arXiv:2511.15067', 'title': 'Deep Pathomic Learning Defines Prognostic Subtypes and Molecular Drivers in Colorectal Cancer', 'authors': 'Zisong Wang, Xuanyu Wang, Hang Chen, Haizhou Wang, Yuxin Chen, Yihang Xu, Yunhe Yuan, Lihuan Luo, Xitong Ling, Xiaoping Liu', 'link': 'https://arxiv.org/abs/2511.15067', 'abstract': 'Precise prognostic stratification of colorectal cancer (CRC) remains a major clinical challenge due to its high heterogeneity. The conventional TNM staging system is inadequate for personalized medicine. We aimed to develop and validate a novel multiple instance learning model TDAM-CRC using histopathological whole-slide images for accurate prognostic prediction and to uncover its underlying molecular mechanisms. We trained the model on the TCGA discovery cohort (n=581), validated it in an independent external cohort (n=1031), and further we integrated multi-omics data to improve model interpretability and identify novel prognostic biomarkers. The results demonstrated that the TDAM-CRC achieved robust risk stratification in both cohorts. Its predictive performance significantly outperformed the conventional clinical staging system and multiple state-of-the-art models. The TDAM-CRC risk score was confirmed as an independent prognostic factor in multivariable analysis. Multi-omics analysis revealed that the high-risk subtype is closely associated with metabolic reprogramming and an immunosuppressive tumor microenvironment. Through interaction network analysis, we identified and validated Mitochondrial Ribosomal Protein L37 (MRPL37) as a key hub gene linking deep pathomic features to clinical prognosis. We found that high expression of MRPL37, driven by promoter hypomethylation, serves as an independent biomarker of favorable prognosis. Finally, we constructed a nomogram incorporating the TDAM-CRC risk score and clinical factors to provide a precise and interpretable clinical decision-making tool for CRC patients. Our AI-driven pathological model TDAM-CRC provides a robust tool for improved CRC risk stratification, reveals new molecular targets, and facilitates personalized clinical decision-making.', 'abstract_zh': '基于组织病理学全 slide 图像的精确结直肠癌预后分层：TDAM-CRC 多实例学习模型及其分子机制探索', 'title_zh': '深度病理学习定义结直肠癌的预后亚型和分子驱动因素'}
{'arxiv_id': 'arXiv:2511.15076', 'title': 'GPU-Initiated Networking for NCCL', 'authors': 'Khaled Hamidouche, John Bachan, Pak Markthub, Peter-Jan Gootzen, Elena Agostini, Sylvain Jeaugey, Aamir Shafi, Georgios Theodorakis, Manjunath Gorentla Venkata', 'link': 'https://arxiv.org/abs/2511.15076', 'abstract': "Modern AI workloads, especially Mixture-of-Experts (MoE) architectures, increasingly demand low-latency, fine-grained GPU-to-GPU communication with device-side control. Traditional GPU communication follows a host-initiated model, where the CPU orchestrates all communication operations - a characteristic of the CUDA runtime. Although robust for collective operations, applications requiring tight integration of computation and communication can benefit from device-initiated communication that eliminates CPU coordination overhead.\nNCCL 2.28 introduces the Device API with three operation modes: Load/Store Accessible (LSA) for NVLink/PCIe, Multimem for NVLink SHARP, and GPU-Initiated Networking (GIN) for network RDMA. This paper presents the GIN architecture, design, semantics, and highlights its impact on MoE communication. GIN builds on a three-layer architecture: i) NCCL Core host-side APIs for device communicator setup and collective memory window registration; ii) Device-side APIs for remote memory operations callable from CUDA kernels; and iii) A network plugin architecture with dual semantics (GPUDirect Async Kernel-Initiated and Proxy) for broad hardware support. The GPUDirect Async Kernel-Initiated backend leverages DOCA GPUNetIO for direct GPU-to-NIC communication, while the Proxy backend provides equivalent functionality via lock-free GPU-to-CPU queues over standard RDMA networks. We demonstrate GIN's practicality through integration with DeepEP, an MoE communication library. Comprehensive benchmarking shows that GIN provides device-initiated communication within NCCL's unified runtime, combining low-latency operations with NCCL's collective algorithms and production infrastructure.", 'abstract_zh': '现代AI工作负载，尤其是Mixture-of-Experts (MoE)架构， increasingly demand低延迟、细粒度的GPU-to-GPU通信并支持设备端控制。NCCL 2.28引入了设备API，包括用于NVLink/PCIe的Load/Store Accessible (LSA)模式、用于NVLink SHARP的Multimem模式以及用于网络RDMA的GPU-Initiated Networking (GIN)模式。本文介绍了GIN架构、设计及其对MoE通信的影响。GIN建立在三层架构之上：i) NCCL核心主机API，用于设备通信器设置和集体内存窗口注册；ii) 设备API，支持从CUDA内核调用的远程内存操作；iii) 支持广泛硬件的网络插件架构，包括GPUDirect异步内核发起和代理两种语义。GPUDirect异步内核发起后端使用DOCA GPUNetIO直接进行GPU-to-NIC通信，而代理后端通过标准RDMA网络上的无锁GPU-to-CPU队列提供等效功能。通过与DeepEP MoE通信库的集成，我们展示了GIN的实用性，并通过全面基准测试证明，GIN能够在NCCL统一运行时中实现设备发起的通信，结合低延迟操作与NCCL的集体算法和生产基础设施。', 'title_zh': 'GPU-Initiated Networking for NCCL'}
{'arxiv_id': 'arXiv:2511.15076', 'title': 'GPU-Initiated Networking for NCCL', 'authors': 'Khaled Hamidouche, John Bachan, Pak Markthub, Peter-Jan Gootzen, Elena Agostini, Sylvain Jeaugey, Aamir Shafi, Georgios Theodorakis, Manjunath Gorentla Venkata', 'link': 'https://arxiv.org/abs/2511.15076', 'abstract': "Modern AI workloads, especially Mixture-of-Experts (MoE) architectures, increasingly demand low-latency, fine-grained GPU-to-GPU communication with device-side control. Traditional GPU communication follows a host-initiated model, where the CPU orchestrates all communication operations - a characteristic of the CUDA runtime. Although robust for collective operations, applications requiring tight integration of computation and communication can benefit from device-initiated communication that eliminates CPU coordination overhead.\nNCCL 2.28 introduces the Device API with three operation modes: Load/Store Accessible (LSA) for NVLink/PCIe, Multimem for NVLink SHARP, and GPU-Initiated Networking (GIN) for network RDMA. This paper presents the GIN architecture, design, semantics, and highlights its impact on MoE communication. GIN builds on a three-layer architecture: i) NCCL Core host-side APIs for device communicator setup and collective memory window registration; ii) Device-side APIs for remote memory operations callable from CUDA kernels; and iii) A network plugin architecture with dual semantics (GPUDirect Async Kernel-Initiated and Proxy) for broad hardware support. The GPUDirect Async Kernel-Initiated backend leverages DOCA GPUNetIO for direct GPU-to-NIC communication, while the Proxy backend provides equivalent functionality via lock-free GPU-to-CPU queues over standard RDMA networks. We demonstrate GIN's practicality through integration with DeepEP, an MoE communication library. Comprehensive benchmarking shows that GIN provides device-initiated communication within NCCL's unified runtime, combining low-latency operations with NCCL's collective algorithms and production infrastructure.", 'abstract_zh': '现代AI工作负载，尤其是Mixture-of-Experts (MoE)架构，日益需要低延迟、细粒度的GPU-to-GPU通信与设备侧控制。NCCL 2.28引入了设备API，包含三种操作模式： NVLink/PCIe的Load/Store Accessible (LSA)、NVLink SHARP的Multimem以及网络RDMA的GPU-Initiated Networking (GIN)。本文介绍了GIN架构、设计、语义及其对MoE通信的影响。GIN基于三层架构构建：i) NCCL核心主机侧API，用于设备通信器设置和集体内存窗口注册；ii) 设备侧API，可在CUDA内核中调用的远程内存操作；iii) 具有双重语义（GPUDirect Async Kernel-Initiated和Proxy）的网络插件架构，以广泛支持硬件。GPUDirect Async Kernel-Initiated后端利用DOCA GPUNetIO实现直接GPU-to-NIC通信，而Proxy后端通过无锁的GPU-to-CPU队列提供等效功能，运行于标准RDMA网络上。通过与DeepEP MoE通信库的集成，我们展示了GIN的实用性。全面的基准测试表明，GIN能够在NCCL统一运行时环境中提供设备发起的通信，结合了低延迟操作与NCCL的集体算法和生产基础设施。', 'title_zh': 'GPU-发起的网络通信 for NCCL'}
{'arxiv_id': 'arXiv:2511.15065', 'title': "Reasoning via Video: The First Evaluation of Video Models' Reasoning Abilities through Maze-Solving Tasks", 'authors': 'Cheng Yang, Haiyuan Wan, Yiran Peng, Xin Cheng, Zhaoyang Yu, Jiayi Zhang, Junchi Yu, Xinlei Yu, Xiawu Zheng, Dongzhan Zhou, Chenglin Wu', 'link': 'https://arxiv.org/abs/2511.15065', 'abstract': "Video Models have achieved remarkable success in high-fidelity video generation with coherent motion dynamics. Analogous to the development from text generation to text-based reasoning in language modeling, the development of video models motivates us to ask: Can video models reason via video generation? Compared with the discrete text corpus, video grounds reasoning in explicit spatial layouts and temporal continuity, which serves as an ideal substrate for spatial reasoning. In this work, we explore the reasoning via video paradigm and introduce VR-Bench -- a comprehensive benchmark designed to systematically evaluate video models' reasoning capabilities. Grounded in maze-solving tasks that inherently require spatial planning and multi-step reasoning, VR-Bench contains 7,920 procedurally generated videos across five maze types and diverse visual styles. Our empirical analysis demonstrates that SFT can efficiently elicit the reasoning ability of video model. Video models exhibit stronger spatial perception during reasoning, outperforming leading VLMs and generalizing well across diverse scenarios, tasks, and levels of complexity. We further discover a test-time scaling effect, where diverse sampling during inference improves reasoning reliability by 10--20%. These findings highlight the unique potential and scalability of reasoning via video for spatial reasoning tasks.", 'abstract_zh': '视频模型在一致运动动力学下实现了高保真视频生成的显著成果。类比于语言模型从文本生成到基于文本推理的发展，视频模型的发展促使我们思考：视频模型能否通过视频生成来进行推理？与离散的文本语料库相比，视频将推理置于明确的空间布局和时间连续性之中，为其提供了理想的空间推理基板。在这项工作中，我们探索了通过视频进行推理的范式，并引入了VR-Bench——一个旨在系统评估视频模型推理能力的全面基准。基于从根本上要求空间规划和多步推理的迷宫求解任务，VR-Bench包含了跨五种迷宫类型和多种视觉风格的7,920个程序生成的视频。我们的实证分析表明，SFT可以有效激发视频模型的推理能力。视频模型在推理过程中表现出更强的空间感知能力，超越了领先的空间语言模型，并且在多样场景、任务和复杂度下具有良好的泛化能力。我们还发现了一个测试时的扩展效应，即在推断过程中多样采样可以将推理可靠性提升10-20%。这些发现突显了通过视频进行推理在空间推理任务中的独特潜力和可扩展性。', 'title_zh': '基于视频的推理：首次通过迷宫求解任务评估视频模型的推理能力'}
{'arxiv_id': 'arXiv:2511.15067', 'title': 'Deep Pathomic Learning Defines Prognostic Subtypes and Molecular Drivers in Colorectal Cancer', 'authors': 'Zisong Wang, Xuanyu Wang, Hang Chen, Haizhou Wang, Yuxin Chen, Yihang Xu, Yunhe Yuan, Lihuan Luo, Xitong Ling, Xiaoping Liu', 'link': 'https://arxiv.org/abs/2511.15067', 'abstract': 'Precise prognostic stratification of colorectal cancer (CRC) remains a major clinical challenge due to its high heterogeneity. The conventional TNM staging system is inadequate for personalized medicine. We aimed to develop and validate a novel multiple instance learning model TDAM-CRC using histopathological whole-slide images for accurate prognostic prediction and to uncover its underlying molecular mechanisms. We trained the model on the TCGA discovery cohort (n=581), validated it in an independent external cohort (n=1031), and further we integrated multi-omics data to improve model interpretability and identify novel prognostic biomarkers. The results demonstrated that the TDAM-CRC achieved robust risk stratification in both cohorts. Its predictive performance significantly outperformed the conventional clinical staging system and multiple state-of-the-art models. The TDAM-CRC risk score was confirmed as an independent prognostic factor in multivariable analysis. Multi-omics analysis revealed that the high-risk subtype is closely associated with metabolic reprogramming and an immunosuppressive tumor microenvironment. Through interaction network analysis, we identified and validated Mitochondrial Ribosomal Protein L37 (MRPL37) as a key hub gene linking deep pathomic features to clinical prognosis. We found that high expression of MRPL37, driven by promoter hypomethylation, serves as an independent biomarker of favorable prognosis. Finally, we constructed a nomogram incorporating the TDAM-CRC risk score and clinical factors to provide a precise and interpretable clinical decision-making tool for CRC patients. Our AI-driven pathological model TDAM-CRC provides a robust tool for improved CRC risk stratification, reveals new molecular targets, and facilitates personalized clinical decision-making.', 'abstract_zh': '精确分层预测结直肠癌的AI驱动病理模型TDAM-CRC：多实例学习方法及其分子机制探究', 'title_zh': '深度病理学习定义结直肠癌的预后亚型和分子驱动因素'}
{'arxiv_id': 'arXiv:2511.15046', 'title': 'UniHOI: Unified Human-Object Interaction Understanding via Unified Token Space', 'authors': 'Panqi Yang, Haodong Jing, Nanning Zheng, Yongqiang Ma', 'link': 'https://arxiv.org/abs/2511.15046', 'abstract': 'In the field of human-object interaction (HOI), detection and generation are two dual tasks that have traditionally been addressed separately, hindering the development of comprehensive interaction understanding. To address this, we propose UniHOI, which jointly models HOI detection and generation via a unified token space, thereby effectively promoting knowledge sharing and enhancing generalization. Specifically, we introduce a symmetric interaction-aware attention module and a unified semi-supervised learning paradigm, enabling effective bidirectional mapping between images and interaction semantics even under limited annotations. Extensive experiments demonstrate that UniHOI achieves state-of-the-art performance in both HOI detection and generation. Specifically, UniHOI improves accuracy by 4.9% on long-tailed HOI detection and boosts interaction metrics by 42.0% on open-vocabulary generation tasks.', 'abstract_zh': '在人体-物体交互（HOI）领域，检测和生成是两个传统的双任务，一直分别处理，阻碍了全面交互理解的发展。为此，我们提出UniHOI，通过统一的token空间联合建模HOI检测和生成，从而有效促进知识共享并增强泛化能力。具体而言，我们引入了对称的交互感知注意力模块和统一的半监督学习框架，即使在有限标注条件下，也能有效实现图像与交互语义之间的双向映射。广泛实验表明，UniHOI在HOI检测和生成上均达到了最先进的性能。具体而言，UniHOI在长尾HOI检测上的准确性提高了4.9%，在开放式词汇生成任务上的交互指标提升了42.0%。', 'title_zh': 'UniHOI: 通过统一token空间的人与物体交互理解'}
{'arxiv_id': 'arXiv:2511.15067', 'title': 'Deep Pathomic Learning Defines Prognostic Subtypes and Molecular Drivers in Colorectal Cancer', 'authors': 'Zisong Wang, Xuanyu Wang, Hang Chen, Haizhou Wang, Yuxin Chen, Yihang Xu, Yunhe Yuan, Lihuan Luo, Xitong Ling, Xiaoping Liu', 'link': 'https://arxiv.org/abs/2511.15067', 'abstract': 'Precise prognostic stratification of colorectal cancer (CRC) remains a major clinical challenge due to its high heterogeneity. The conventional TNM staging system is inadequate for personalized medicine. We aimed to develop and validate a novel multiple instance learning model TDAM-CRC using histopathological whole-slide images for accurate prognostic prediction and to uncover its underlying molecular mechanisms. We trained the model on the TCGA discovery cohort (n=581), validated it in an independent external cohort (n=1031), and further we integrated multi-omics data to improve model interpretability and identify novel prognostic biomarkers. The results demonstrated that the TDAM-CRC achieved robust risk stratification in both cohorts. Its predictive performance significantly outperformed the conventional clinical staging system and multiple state-of-the-art models. The TDAM-CRC risk score was confirmed as an independent prognostic factor in multivariable analysis. Multi-omics analysis revealed that the high-risk subtype is closely associated with metabolic reprogramming and an immunosuppressive tumor microenvironment. Through interaction network analysis, we identified and validated Mitochondrial Ribosomal Protein L37 (MRPL37) as a key hub gene linking deep pathomic features to clinical prognosis. We found that high expression of MRPL37, driven by promoter hypomethylation, serves as an independent biomarker of favorable prognosis. Finally, we constructed a nomogram incorporating the TDAM-CRC risk score and clinical factors to provide a precise and interpretable clinical decision-making tool for CRC patients. Our AI-driven pathological model TDAM-CRC provides a robust tool for improved CRC risk stratification, reveals new molecular targets, and facilitates personalized clinical decision-making.', 'abstract_zh': '精确分层预测结直肠癌预后的方法学挑战源于其高异质性。传统TNM分期系统对于个性化医疗而言是不够的。我们旨在开发并验证一种新型的实例级学习模型TDAM-CRC，利用组织病理学Whole-slide图像进行准确的预后预测，并揭示其潜在的分子机制。该模型在TCGA发现队列（n=581）上进行了训练，在独立的外部队列（n=1031）上进行了验证，并通过整合多组学数据提高了模型的可解释性并识别了新的预后生物标志物。结果表明，TDAM-CRC在两个队列中均实现了稳健的风险分层。其预测性能显著优于传统的临床分期系统和多个先进的模型。TDAM-CRC风险评分在多变量分析中被证实为独立的预后因子。多组学分析表明，高风险亚型与代谢重编程和免疫抑制的肿瘤微环境密切相关。通过交互网络分析，我们确定并验证了线粒体核糖体蛋白L37（MRPL37）作为连接深入病理特征与临床预后的关键枢纽基因。我们发现，由启动子去甲基化驱动的MRPL37高表达作为良好预后的独立生物标志物。最后，我们构建了一个包含TDAM-CRC风险评分和临床因素的 nomogram，为结直肠癌患者提供了精确且可解释的临床决策工具。我们基于AI的病理学模型TDAM-CRC提供了一种改进的结直肠癌风险分层的稳健工具，揭示了新的分子靶点，并促进了个性化临床决策。', 'title_zh': '深度病理学习定义结直肠癌的预后亚型及分子驱动因子'}
{'arxiv_id': 'arXiv:2511.15065', 'title': "Reasoning via Video: The First Evaluation of Video Models' Reasoning Abilities through Maze-Solving Tasks", 'authors': 'Cheng Yang, Haiyuan Wan, Yiran Peng, Xin Cheng, Zhaoyang Yu, Jiayi Zhang, Junchi Yu, Xinlei Yu, Xiawu Zheng, Dongzhan Zhou, Chenglin Wu', 'link': 'https://arxiv.org/abs/2511.15065', 'abstract': "Video Models have achieved remarkable success in high-fidelity video generation with coherent motion dynamics. Analogous to the development from text generation to text-based reasoning in language modeling, the development of video models motivates us to ask: Can video models reason via video generation? Compared with the discrete text corpus, video grounds reasoning in explicit spatial layouts and temporal continuity, which serves as an ideal substrate for spatial reasoning. In this work, we explore the reasoning via video paradigm and introduce VR-Bench -- a comprehensive benchmark designed to systematically evaluate video models' reasoning capabilities. Grounded in maze-solving tasks that inherently require spatial planning and multi-step reasoning, VR-Bench contains 7,920 procedurally generated videos across five maze types and diverse visual styles. Our empirical analysis demonstrates that SFT can efficiently elicit the reasoning ability of video model. Video models exhibit stronger spatial perception during reasoning, outperforming leading VLMs and generalizing well across diverse scenarios, tasks, and levels of complexity. We further discover a test-time scaling effect, where diverse sampling during inference improves reasoning reliability by 10--20%. These findings highlight the unique potential and scalability of reasoning via video for spatial reasoning tasks.", 'abstract_zh': '视频模型在高保真视频生成和一致运动动态方面取得了显著成功。类似于语言模型从文本生成到文本基于的推理的发展，视频模型的发展促使我们询问：视频模型能否通过视频生成来进行推理？与离散的文本语料库相比，视频为推理提供了明确的空间布局和时间连续性的基础，这使其成为空间推理的理想载体。在本文中，我们探索了基于视频的推理范式，并介绍了VR-Bench——一个旨在系统评估视频模型推理能力的综合基准。基于固有要求空间规划和多步推理的迷宫求解任务，VR-Bench 包含了跨越五种迷宫类型和多种视觉风格的7,920个程序生成的视频。我们的实证分析表明，连续性片段训练（SFT）可以有效地激发视频模型的推理能力。视频模型在推理过程中表现出更强的空间感知，优于领先的视觉语言模型，并在多种场景、任务和复杂度级别上表现出良好的泛化能力。我们还发现，在推理过程中多样采样的测试时扩展效应，这提高了推理可靠性10-20%。这些发现突显了基于视频的推理在空间推理任务中的独特潜力和扩展性。', 'title_zh': '基于视频的推理：首次通过迷宫解谜任务评估视频模型的推理能力'}
{'arxiv_id': 'arXiv:2511.15038', 'title': 'Aligning Generative Music AI with Human Preferences: Methods and Challenges', 'authors': 'Dorien Herremans, Abhinaba Roy', 'link': 'https://arxiv.org/abs/2511.15038', 'abstract': "Recent advances in generative AI for music have achieved remarkable fidelity and stylistic diversity, yet these systems often fail to align with nuanced human preferences due to the specific loss functions they use. This paper advocates for the systematic application of preference alignment techniques to music generation, addressing the fundamental gap between computational optimization and human musical appreciation. Drawing on recent breakthroughs including MusicRL's large-scale preference learning, multi-preference alignment frameworks like diffusion-based preference optimization in DiffRhythm+, and inference-time optimization techniques like Text2midi-InferAlign, we discuss how these techniques can address music's unique challenges: temporal coherence, harmonic consistency, and subjective quality assessment. We identify key research challenges including scalability to long-form compositions, reliability amongst others in preference modelling. Looking forward, we envision preference-aligned music generation enabling transformative applications in interactive composition tools and personalized music services. This work calls for sustained interdisciplinary research combining advances in machine learning, music-theory to create music AI systems that truly serve human creative and experiential needs.", 'abstract_zh': 'Recent Advances in Preference-Aligned Generative AI for Music', 'title_zh': '将生成音乐AI与人类偏好对齐：方法与挑战'}
{'arxiv_id': 'arXiv:2511.15065', 'title': "Reasoning via Video: The First Evaluation of Video Models' Reasoning Abilities through Maze-Solving Tasks", 'authors': 'Cheng Yang, Haiyuan Wan, Yiran Peng, Xin Cheng, Zhaoyang Yu, Jiayi Zhang, Junchi Yu, Xinlei Yu, Xiawu Zheng, Dongzhan Zhou, Chenglin Wu', 'link': 'https://arxiv.org/abs/2511.15065', 'abstract': "Video Models have achieved remarkable success in high-fidelity video generation with coherent motion dynamics. Analogous to the development from text generation to text-based reasoning in language modeling, the development of video models motivates us to ask: Can video models reason via video generation? Compared with the discrete text corpus, video grounds reasoning in explicit spatial layouts and temporal continuity, which serves as an ideal substrate for spatial reasoning. In this work, we explore the reasoning via video paradigm and introduce VR-Bench -- a comprehensive benchmark designed to systematically evaluate video models' reasoning capabilities. Grounded in maze-solving tasks that inherently require spatial planning and multi-step reasoning, VR-Bench contains 7,920 procedurally generated videos across five maze types and diverse visual styles. Our empirical analysis demonstrates that SFT can efficiently elicit the reasoning ability of video model. Video models exhibit stronger spatial perception during reasoning, outperforming leading VLMs and generalizing well across diverse scenarios, tasks, and levels of complexity. We further discover a test-time scaling effect, where diverse sampling during inference improves reasoning reliability by 10--20%. These findings highlight the unique potential and scalability of reasoning via video for spatial reasoning tasks.", 'abstract_zh': '视频模型在一致运动动态下实现了高保真视频生成的显著成功。类似于语言模型从文本生成发展到基于文本的推理，视频模型的发展促使我们提出一个问题：视频模型能否通过视频生成来进行推理？与离散的文本语料库相比，视频立足于明确的空间布局和时间连续性，这为空间推理提供了一个理想的基底。在本工作中，我们探索基于视频的推理范式，并介绍VR-Bench——一个全面的基准，旨在系统性地评估视频模型的推理能力。基于固有要求空间规划和多步推理的迷宫求解任务，VR-Bench包含7,920个 procedurally生成的视频，涵盖了五种迷宫类型和多样的视觉风格。我们的实证分析表明，SFT能够有效地激发视频模型的推理能力。视频模型在推理过程中表现出更强的空间感知能力，优于最先进的多模态视觉语言模型，并且能够很好地泛化到各种场景、任务和复杂度级别。我们还发现了一种推理时的扩展效应，即推断过程中多样性的采样可以提高推理可靠性10-20%。这些发现突显了基于视频进行空间推理的独特潜力和扩展性。', 'title_zh': '基于视频的推理：首次通过迷宫求解任务评估视频模型的推理能力'}
{'arxiv_id': 'arXiv:2511.15046', 'title': 'UniHOI: Unified Human-Object Interaction Understanding via Unified Token Space', 'authors': 'Panqi Yang, Haodong Jing, Nanning Zheng, Yongqiang Ma', 'link': 'https://arxiv.org/abs/2511.15046', 'abstract': 'In the field of human-object interaction (HOI), detection and generation are two dual tasks that have traditionally been addressed separately, hindering the development of comprehensive interaction understanding. To address this, we propose UniHOI, which jointly models HOI detection and generation via a unified token space, thereby effectively promoting knowledge sharing and enhancing generalization. Specifically, we introduce a symmetric interaction-aware attention module and a unified semi-supervised learning paradigm, enabling effective bidirectional mapping between images and interaction semantics even under limited annotations. Extensive experiments demonstrate that UniHOI achieves state-of-the-art performance in both HOI detection and generation. Specifically, UniHOI improves accuracy by 4.9% on long-tailed HOI detection and boosts interaction metrics by 42.0% on open-vocabulary generation tasks.', 'abstract_zh': '人类对象交互领域的检测与生成：UniHOI及其在知识共享和泛化中的联合建模', 'title_zh': 'UniHOI: 统一人类-对象交互理解 via 统一令牌空间'}
{'arxiv_id': 'arXiv:2511.15032', 'title': 'Simulated Human Learning in a Dynamic, Partially-Observed, Time-Series Environment', 'authors': 'Jeffrey Jiang, Kevin Hong, Emily Kuczynski, Gregory Pottie', 'link': 'https://arxiv.org/abs/2511.15032', 'abstract': 'While intelligent tutoring systems (ITSs) can use information from past students to personalize instruction, each new student is unique. Moreover, the education problem is inherently difficult because the learning process is only partially observable. We therefore develop a dynamic, time-series environment to simulate a classroom setting, with student-teacher interventions - including tutoring sessions, lectures, and exams. In particular, we design the simulated environment to allow for varying levels of probing interventions that can gather more information. Then, we develop reinforcement learning ITSs that combine learning the individual state of students while pulling from population information through the use of probing interventions. These interventions can reduce the difficulty of student estimation, but also introduce a cost-benefit decision to find a balance between probing enough to get accurate estimates and probing so often that it becomes disruptive to the student. We compare the efficacy of standard RL algorithms with several greedy rules-based heuristic approaches to find that they provide different solutions, but with similar results. We also highlight the difficulty of the problem with increasing levels of hidden information, and the boost that we get if we allow for probing interventions. We show the flexibility of both heuristic and RL policies with regards to changing student population distributions, finding that both are flexible, but RL policies struggle to help harder classes. Finally, we test different course structures with non-probing policies and we find that our policies are able to boost the performance of quiz and midterm structures more than we can in a finals-only structure, highlighting the benefit of having additional information.', 'abstract_zh': '智能辅导系统中的动态时序环境及其强化学习方法研究', 'title_zh': '模拟人在动态、部分可观测的时间序列环境中的学习'}
{'arxiv_id': 'arXiv:2511.15046', 'title': 'UniHOI: Unified Human-Object Interaction Understanding via Unified Token Space', 'authors': 'Panqi Yang, Haodong Jing, Nanning Zheng, Yongqiang Ma', 'link': 'https://arxiv.org/abs/2511.15046', 'abstract': 'In the field of human-object interaction (HOI), detection and generation are two dual tasks that have traditionally been addressed separately, hindering the development of comprehensive interaction understanding. To address this, we propose UniHOI, which jointly models HOI detection and generation via a unified token space, thereby effectively promoting knowledge sharing and enhancing generalization. Specifically, we introduce a symmetric interaction-aware attention module and a unified semi-supervised learning paradigm, enabling effective bidirectional mapping between images and interaction semantics even under limited annotations. Extensive experiments demonstrate that UniHOI achieves state-of-the-art performance in both HOI detection and generation. Specifically, UniHOI improves accuracy by 4.9% on long-tailed HOI detection and boosts interaction metrics by 42.0% on open-vocabulary generation tasks.', 'abstract_zh': '在人类物体交互（HOI）领域，检测与生成是两个传统的双任务，以往是分开处理的，阻碍了全面交互理解的发展。为解决这一问题，我们提出UniHOI，通过统一的token空间联合建模HOI检测与生成，从而有效促进知识共享并增强泛化能力。具体而言，我们引入了对称交互感知注意力模块和统一的半监督学习范式，即使在有限标注的情况下，也能实现图像与交互语义的有效双向映射。大量实验表明，UniHOI在HOI检测和生成中均实现了最先进的性能。具体而言，UniHOI在长尾HOI检测中的准确率提高了4.9%，在开放词汇生成任务中的交互指标提高了42.0%。', 'title_zh': 'UniHOI: 统一人类-物体交互理解通过统一 token 空间'}
{'arxiv_id': 'arXiv:2511.15038', 'title': 'Aligning Generative Music AI with Human Preferences: Methods and Challenges', 'authors': 'Dorien Herremans, Abhinaba Roy', 'link': 'https://arxiv.org/abs/2511.15038', 'abstract': "Recent advances in generative AI for music have achieved remarkable fidelity and stylistic diversity, yet these systems often fail to align with nuanced human preferences due to the specific loss functions they use. This paper advocates for the systematic application of preference alignment techniques to music generation, addressing the fundamental gap between computational optimization and human musical appreciation. Drawing on recent breakthroughs including MusicRL's large-scale preference learning, multi-preference alignment frameworks like diffusion-based preference optimization in DiffRhythm+, and inference-time optimization techniques like Text2midi-InferAlign, we discuss how these techniques can address music's unique challenges: temporal coherence, harmonic consistency, and subjective quality assessment. We identify key research challenges including scalability to long-form compositions, reliability amongst others in preference modelling. Looking forward, we envision preference-aligned music generation enabling transformative applications in interactive composition tools and personalized music services. This work calls for sustained interdisciplinary research combining advances in machine learning, music-theory to create music AI systems that truly serve human creative and experiential needs.", 'abstract_zh': '近期生成AI在音乐领域的进展已在保真度和风格多样性方面取得了显著成果，然而这些系统常常因为使用的特定损失函数未能与细腻的人类偏好保持一致。本文提倡系统地将偏好对齐技术应用于音乐生成，以弥合计算优化与人类音乐欣赏之间的根本差距。本文借鉴了包括MusicRL的大规模偏好学习、DiffRhythm+中的基于扩散的偏好优化以及Text2midi-InferAlign的推理时优化等近期突破，讨论了这些技术如何解决音乐的特有挑战：时间连贯性、和声一致性以及主观质量评估。我们指出了包括长篇作品扩展性在内的关键研究挑战。展望未来，偏好对齐的音乐生成有望推动交互式创作工具和个人化音乐服务的变革性应用。本文呼吁跨学科研究，结合机器学习和音乐理论的进步，创建真正服务于人类创意和体验需求的音乐AI系统。', 'title_zh': '将生成音乐AI与人类偏好对齐：方法与挑战'}
{'arxiv_id': 'arXiv:2511.15038', 'title': 'Aligning Generative Music AI with Human Preferences: Methods and Challenges', 'authors': 'Dorien Herremans, Abhinaba Roy', 'link': 'https://arxiv.org/abs/2511.15038', 'abstract': "Recent advances in generative AI for music have achieved remarkable fidelity and stylistic diversity, yet these systems often fail to align with nuanced human preferences due to the specific loss functions they use. This paper advocates for the systematic application of preference alignment techniques to music generation, addressing the fundamental gap between computational optimization and human musical appreciation. Drawing on recent breakthroughs including MusicRL's large-scale preference learning, multi-preference alignment frameworks like diffusion-based preference optimization in DiffRhythm+, and inference-time optimization techniques like Text2midi-InferAlign, we discuss how these techniques can address music's unique challenges: temporal coherence, harmonic consistency, and subjective quality assessment. We identify key research challenges including scalability to long-form compositions, reliability amongst others in preference modelling. Looking forward, we envision preference-aligned music generation enabling transformative applications in interactive composition tools and personalized music services. This work calls for sustained interdisciplinary research combining advances in machine learning, music-theory to create music AI systems that truly serve human creative and experiential needs.", 'abstract_zh': 'Recent Advances in Preference-Aligned Generative AI for Music', 'title_zh': '面向人类偏好的生成音乐AI：方法与挑战'}
{'arxiv_id': 'arXiv:2511.15015', 'title': 'Dynamic Expert Quantization for Scalable Mixture-of-Experts Inference', 'authors': 'Kexin Chu, Dawei Xiang, Zixu Shen, Yiwei Yang, Zecheng Liu, Wei Zhang', 'link': 'https://arxiv.org/abs/2511.15015', 'abstract': 'Mixture-of-Experts (MoE) models scale LLM capacity efficiently, but deployment on consumer GPUs is limited by the large memory footprint of inactive experts. Static post-training quantization reduces storage costs but cannot adapt to shifting activation patterns, causing accuracy loss under aggressive compression. So we present DynaExq, a runtime system that treats expert precision as a first-class, dynamically managed resource. DynaExq combines (1) a hotness-aware precision controller that continuously aligns expert bit-widths with long-term activation statistics, (2) a fully asynchronous precision-switching pipeline that overlaps promotion and demotion with MoE computation, and (3) a fragmentation-free memory pooling mechanism that supports hybrid-precision experts with deterministic allocation. Together, these components enable stable, non-blocking precision transitions under strict HBM budgets.\nAcross Qwen3-30B and Qwen3-80B MoE models and six representative benchmarks, DynaExq deploys large LLMs on single RTX 5090 and A6000 GPUs and improves accuracy by up to 4.03 points over static low-precision baselines. The results show that adaptive, workload-aware quantization is an effective strategy for memory-constrained MoE serving.', 'abstract_zh': 'DynaExq：一种运行时系统，用于在受限内存的MoE模型中动态调整专家精度以提高准确性', 'title_zh': '可扩展混合专家推断的动态专家量化'}
{'arxiv_id': 'arXiv:2511.15032', 'title': 'Simulated Human Learning in a Dynamic, Partially-Observed, Time-Series Environment', 'authors': 'Jeffrey Jiang, Kevin Hong, Emily Kuczynski, Gregory Pottie', 'link': 'https://arxiv.org/abs/2511.15032', 'abstract': 'While intelligent tutoring systems (ITSs) can use information from past students to personalize instruction, each new student is unique. Moreover, the education problem is inherently difficult because the learning process is only partially observable. We therefore develop a dynamic, time-series environment to simulate a classroom setting, with student-teacher interventions - including tutoring sessions, lectures, and exams. In particular, we design the simulated environment to allow for varying levels of probing interventions that can gather more information. Then, we develop reinforcement learning ITSs that combine learning the individual state of students while pulling from population information through the use of probing interventions. These interventions can reduce the difficulty of student estimation, but also introduce a cost-benefit decision to find a balance between probing enough to get accurate estimates and probing so often that it becomes disruptive to the student. We compare the efficacy of standard RL algorithms with several greedy rules-based heuristic approaches to find that they provide different solutions, but with similar results. We also highlight the difficulty of the problem with increasing levels of hidden information, and the boost that we get if we allow for probing interventions. We show the flexibility of both heuristic and RL policies with regards to changing student population distributions, finding that both are flexible, but RL policies struggle to help harder classes. Finally, we test different course structures with non-probing policies and we find that our policies are able to boost the performance of quiz and midterm structures more than we can in a finals-only structure, highlighting the benefit of having additional information.', 'abstract_zh': '基于动态时间序列环境的个性化智能 tutoring 系统研究', 'title_zh': '模拟人类在动态、部分可观测的时间序列环境中的学习'}
{'arxiv_id': 'arXiv:2511.15032', 'title': 'Simulated Human Learning in a Dynamic, Partially-Observed, Time-Series Environment', 'authors': 'Jeffrey Jiang, Kevin Hong, Emily Kuczynski, Gregory Pottie', 'link': 'https://arxiv.org/abs/2511.15032', 'abstract': 'While intelligent tutoring systems (ITSs) can use information from past students to personalize instruction, each new student is unique. Moreover, the education problem is inherently difficult because the learning process is only partially observable. We therefore develop a dynamic, time-series environment to simulate a classroom setting, with student-teacher interventions - including tutoring sessions, lectures, and exams. In particular, we design the simulated environment to allow for varying levels of probing interventions that can gather more information. Then, we develop reinforcement learning ITSs that combine learning the individual state of students while pulling from population information through the use of probing interventions. These interventions can reduce the difficulty of student estimation, but also introduce a cost-benefit decision to find a balance between probing enough to get accurate estimates and probing so often that it becomes disruptive to the student. We compare the efficacy of standard RL algorithms with several greedy rules-based heuristic approaches to find that they provide different solutions, but with similar results. We also highlight the difficulty of the problem with increasing levels of hidden information, and the boost that we get if we allow for probing interventions. We show the flexibility of both heuristic and RL policies with regards to changing student population distributions, finding that both are flexible, but RL policies struggle to help harder classes. Finally, we test different course structures with non-probing policies and we find that our policies are able to boost the performance of quiz and midterm structures more than we can in a finals-only structure, highlighting the benefit of having additional information.', 'abstract_zh': '基于探查干预的强化学习智能辅导系统研究', 'title_zh': '模拟在动态、部分可观测的时间序列环境中的人类学习'}
{'arxiv_id': 'arXiv:2511.15005', 'title': 'Mathematical Analysis of Hallucination Dynamics in Large Language Models: Uncertainty Quantification, Advanced Decoding, and Principled Mitigation', 'authors': 'Moses Kiprono', 'link': 'https://arxiv.org/abs/2511.15005', 'abstract': 'Large Language Models (LLMs) are powerful linguistic engines but remain susceptible to hallucinations: plausible-sounding outputs that are factually incorrect or unsupported. In this work, we present a mathematically grounded framework to understand, measure, and mitigate these hallucinations. Drawing on probabilistic modeling, information theory, trigonometric signal analysis, and Bayesian uncertainty estimation, we analyze how errors compound autoregressively, propose refined uncertainty metrics, including semantic and phase-aware variants, and develop principled mitigation strategies such as contrastive decoding, retrieval-augmented grounding, factual alignment, and abstention. This unified lens connects recent advances in calibration, retrieval, and alignment to support safer and more reliable LLMs.', 'abstract_zh': '大型语言模型（LLMs）是强大的语言引擎，但仍然容易出现幻觉：听起来合乎情理但实际上可能是事实错误或未被支持的输出。在本文中，我们提出了一种基于数学原理的框架来理解、测量和减轻这些幻觉。利用概率模型、信息论、三角信号分析和贝叶斯不确定性估计，我们分析了错误的累积性传播，提出了改进的不确定性度量，包括语义和相位意识的变体，并开发了基于对比解码、检索增强 grounding、事实对齐和回避的稳健的缓解策略。这一统一视角将最近在校准、检索和对齐方面的进展结合起来，以支持更安全和更可靠的大型语言模型。', 'title_zh': '大型语言模型中幻觉动态的数学分析：不确定性量化、高级解码和原则性缓解'}
{'arxiv_id': 'arXiv:2511.15015', 'title': 'Dynamic Expert Quantization for Scalable Mixture-of-Experts Inference', 'authors': 'Kexin Chu, Dawei Xiang, Zixu Shen, Yiwei Yang, Zecheng Liu, Wei Zhang', 'link': 'https://arxiv.org/abs/2511.15015', 'abstract': 'Mixture-of-Experts (MoE) models scale LLM capacity efficiently, but deployment on consumer GPUs is limited by the large memory footprint of inactive experts. Static post-training quantization reduces storage costs but cannot adapt to shifting activation patterns, causing accuracy loss under aggressive compression. So we present DynaExq, a runtime system that treats expert precision as a first-class, dynamically managed resource. DynaExq combines (1) a hotness-aware precision controller that continuously aligns expert bit-widths with long-term activation statistics, (2) a fully asynchronous precision-switching pipeline that overlaps promotion and demotion with MoE computation, and (3) a fragmentation-free memory pooling mechanism that supports hybrid-precision experts with deterministic allocation. Together, these components enable stable, non-blocking precision transitions under strict HBM budgets.\nAcross Qwen3-30B and Qwen3-80B MoE models and six representative benchmarks, DynaExq deploys large LLMs on single RTX 5090 and A6000 GPUs and improves accuracy by up to 4.03 points over static low-precision baselines. The results show that adaptive, workload-aware quantization is an effective strategy for memory-constrained MoE serving.', 'abstract_zh': 'DynaExq：一种用于受限内存Mixture-of-Experts模型的动态精度管理系统', 'title_zh': '面向可扩展混合专家推理的动态专家量化方法'}
{'arxiv_id': 'arXiv:2511.15015', 'title': 'Dynamic Expert Quantization for Scalable Mixture-of-Experts Inference', 'authors': 'Kexin Chu, Dawei Xiang, Zixu Shen, Yiwei Yang, Zecheng Liu, Wei Zhang', 'link': 'https://arxiv.org/abs/2511.15015', 'abstract': 'Mixture-of-Experts (MoE) models scale LLM capacity efficiently, but deployment on consumer GPUs is limited by the large memory footprint of inactive experts. Static post-training quantization reduces storage costs but cannot adapt to shifting activation patterns, causing accuracy loss under aggressive compression. So we present DynaExq, a runtime system that treats expert precision as a first-class, dynamically managed resource. DynaExq combines (1) a hotness-aware precision controller that continuously aligns expert bit-widths with long-term activation statistics, (2) a fully asynchronous precision-switching pipeline that overlaps promotion and demotion with MoE computation, and (3) a fragmentation-free memory pooling mechanism that supports hybrid-precision experts with deterministic allocation. Together, these components enable stable, non-blocking precision transitions under strict HBM budgets.\nAcross Qwen3-30B and Qwen3-80B MoE models and six representative benchmarks, DynaExq deploys large LLMs on single RTX 5090 and A6000 GPUs and improves accuracy by up to 4.03 points over static low-precision baselines. The results show that adaptive, workload-aware quantization is an effective strategy for memory-constrained MoE serving.', 'abstract_zh': 'DynaExq：一种用于MoE模型的运行时动态精度管理系统', 'title_zh': '可扩展专家混合推理的动态专家量化'}
{'arxiv_id': 'arXiv:2511.14993', 'title': 'Kandinsky 5.0: A Family of Foundation Models for Image and Video Generation', 'authors': 'Vladimir Arkhipkin, Vladimir Korviakov, Nikolai Gerasimenko, Denis Parkhomenko, Viacheslav Vasilev, Alexey Letunovskiy, Maria Kovaleva, Nikolai Vaulin, Ivan Kirillov, Lev Novitskiy, Denis Koposov, Nikita Kiselev, Alexander Varlamov, Dmitrii Mikhailov, Vladimir Polovnikov, Andrey Shutkin, Ilya Vasiliev, Julia Agafonova, Anastasiia Kargapoltseva, Anna Dmitrienko, Anastasia Maltseva, Anna Averchenkova, Olga Kim, Tatiana Nikulina, Denis Dimitrov', 'link': 'https://arxiv.org/abs/2511.14993', 'abstract': 'This report introduces Kandinsky 5.0, a family of state-of-the-art foundation models for high-resolution image and 10-second video synthesis. The framework comprises three core line-up of models: Kandinsky 5.0 Image Lite - a line-up of 6B parameter image generation models, Kandinsky 5.0 Video Lite - a fast and lightweight 2B parameter text-to-video and image-to-video models, and Kandinsky 5.0 Video Pro - 19B parameter models that achieves superior video generation quality. We provide a comprehensive review of the data curation lifecycle - including collection, processing, filtering and clustering - for the multi-stage training pipeline that involves extensive pre-training and incorporates quality-enhancement techniques such as self-supervised fine-tuning (SFT) and reinforcement learning (RL)-based post-training. We also present novel architectural, training, and inference optimizations that enable Kandinsky 5.0 to achieve high generation speeds and state-of-the-art performance across various tasks, as demonstrated by human evaluation. As a large-scale, publicly available generative framework, Kandinsky 5.0 leverages the full potential of its pre-training and subsequent stages to be adapted for a wide range of generative applications. We hope that this report, together with the release of our open-source code and training checkpoints, will substantially advance the development and accessibility of high-quality generative models for the research community.', 'abstract_zh': 'Kandinsky 5.0：一种用于高分辨率图像和10秒视频合成的先进基础模型系列', 'title_zh': '康丁斯基5.0：图像和视频生成的家族式基础模型'}
{'arxiv_id': 'arXiv:2511.15005', 'title': 'Mathematical Analysis of Hallucination Dynamics in Large Language Models: Uncertainty Quantification, Advanced Decoding, and Principled Mitigation', 'authors': 'Moses Kiprono', 'link': 'https://arxiv.org/abs/2511.15005', 'abstract': 'Large Language Models (LLMs) are powerful linguistic engines but remain susceptible to hallucinations: plausible-sounding outputs that are factually incorrect or unsupported. In this work, we present a mathematically grounded framework to understand, measure, and mitigate these hallucinations. Drawing on probabilistic modeling, information theory, trigonometric signal analysis, and Bayesian uncertainty estimation, we analyze how errors compound autoregressively, propose refined uncertainty metrics, including semantic and phase-aware variants, and develop principled mitigation strategies such as contrastive decoding, retrieval-augmented grounding, factual alignment, and abstention. This unified lens connects recent advances in calibration, retrieval, and alignment to support safer and more reliable LLMs.', 'abstract_zh': '大型语言模型（LLMs）是强大的语言引擎，但仍易产生幻觉：这些幻觉产出听起来合乎情理但实际上是事实错误或缺乏支持的输出。在本文中，我们提供了一个基于数学框架来理解、衡量并减轻这些幻觉的方法。通过概率建模、信息理论、三角信号分析和贝叶斯不确定性估计，我们分析了错误如何自回归地累积，提出了包括语义和相位感知变体在内的精细的不确定性度量，并开发了如对比解码、检索增强基座化、事实对齐和避免决策等原则性的缓解策略。这种统一视角将近期在校准、检索和对齐方面的进展连接起来，以支持更安全和更可靠的LLMs。', 'title_zh': '大型语言模型中幻觉动态的数学分析：不确定性量化、高级解码和原则性缓解'}
{'arxiv_id': 'arXiv:2511.15005', 'title': 'Mathematical Analysis of Hallucination Dynamics in Large Language Models: Uncertainty Quantification, Advanced Decoding, and Principled Mitigation', 'authors': 'Moses Kiprono', 'link': 'https://arxiv.org/abs/2511.15005', 'abstract': 'Large Language Models (LLMs) are powerful linguistic engines but remain susceptible to hallucinations: plausible-sounding outputs that are factually incorrect or unsupported. In this work, we present a mathematically grounded framework to understand, measure, and mitigate these hallucinations. Drawing on probabilistic modeling, information theory, trigonometric signal analysis, and Bayesian uncertainty estimation, we analyze how errors compound autoregressively, propose refined uncertainty metrics, including semantic and phase-aware variants, and develop principled mitigation strategies such as contrastive decoding, retrieval-augmented grounding, factual alignment, and abstention. This unified lens connects recent advances in calibration, retrieval, and alignment to support safer and more reliable LLMs.', 'abstract_zh': '大型语言模型（LLMs）是强大的语言引擎，但仍易产生幻觉：这些幻觉输出看似合理但事实错误或缺乏支持。在本文中，我们提出了一种数学上严密的框架来理解、衡量和减少这些幻觉。利用概率模型、信息论、三角信号分析以及贝叶斯不确定性估计，我们分析了错误如何自回归地累积，提出了精炼的不确定性度量，包括语义和相位感知的变体，并开发了诸如对比解码、检索增强 grounding、事实对齐和回避等有原则的缓解策略。这一统一视角将近期在校准、检索和对齐方面的进展结合起来，以支持更安全和更可靠的大型语言模型。', 'title_zh': '大型语言模型中幻觉动力学的数学分析：不确定性量化、高级解码与原则性缓解'}
{'arxiv_id': 'arXiv:2511.14981', 'title': 'Logit-Based Losses Limit the Effectiveness of Feature Knowledge Distillation', 'authors': 'Nicholas Cooper, Lijun Chen, Sailesh Dwivedy, Danna Gurari', 'link': 'https://arxiv.org/abs/2511.14981', 'abstract': "Knowledge distillation (KD) methods can transfer knowledge of a parameter-heavy teacher model to a light-weight student model. The status quo for feature KD methods is to utilize loss functions based on logits (i.e., pre-softmax class scores) and intermediate layer features (i.e., latent representations). Unlike previous approaches, we propose a feature KD framework for training the student's backbone using feature-based losses exclusively (i.e., without logit-based losses such as cross entropy). Leveraging recent discoveries about the geometry of latent representations, we introduce a knowledge quality metric for identifying which teacher layers provide the most effective knowledge for distillation. Experiments on three image classification datasets with four diverse student-teacher pairs, spanning convolutional neural networks and vision transformers, demonstrate our KD method achieves state-of-the-art performance, delivering top-1 accuracy boosts of up to 15% over standard approaches. We publically share our code to facilitate future work at this https URL.", 'abstract_zh': '基于特征的知识蒸馏方法可以将参数量大的教师模型的知识转移到轻量级的学生模型。当前的特征知识蒸馏方法主要利用基于logits（即预softmax类别分数）和中间层特征（即潜在表示）的损失函数。不同于以往的方法，我们提出了一种仅使用基于特征的损失函数来训练学生主干网络的知识蒸馏框架（即不使用基于logits的损失函数，如交叉熵）。利用近期关于潜在表示几何性质的发现，我们引入了一个知识质量度量标准，以识别哪些教师层为蒸馏提供了最有效的知识。在三个图像分类数据集上，使用四个不同学生-教师 pair 的实验展示了我们的知识蒸馏方法达到最先进的性能，相比标准方法在 top-1 准确率上最多提升 15%。我们公开分享了代码，以便未来的研究参考。', 'title_zh': '基于Logit的损失限制了特征知识蒸馏的效果'}
{'arxiv_id': 'arXiv:2511.14993', 'title': 'Kandinsky 5.0: A Family of Foundation Models for Image and Video Generation', 'authors': 'Vladimir Arkhipkin, Vladimir Korviakov, Nikolai Gerasimenko, Denis Parkhomenko, Viacheslav Vasilev, Alexey Letunovskiy, Maria Kovaleva, Nikolai Vaulin, Ivan Kirillov, Lev Novitskiy, Denis Koposov, Nikita Kiselev, Alexander Varlamov, Dmitrii Mikhailov, Vladimir Polovnikov, Andrey Shutkin, Ilya Vasiliev, Julia Agafonova, Anastasiia Kargapoltseva, Anna Dmitrienko, Anastasia Maltseva, Anna Averchenkova, Olga Kim, Tatiana Nikulina, Denis Dimitrov', 'link': 'https://arxiv.org/abs/2511.14993', 'abstract': 'This report introduces Kandinsky 5.0, a family of state-of-the-art foundation models for high-resolution image and 10-second video synthesis. The framework comprises three core line-up of models: Kandinsky 5.0 Image Lite - a line-up of 6B parameter image generation models, Kandinsky 5.0 Video Lite - a fast and lightweight 2B parameter text-to-video and image-to-video models, and Kandinsky 5.0 Video Pro - 19B parameter models that achieves superior video generation quality. We provide a comprehensive review of the data curation lifecycle - including collection, processing, filtering and clustering - for the multi-stage training pipeline that involves extensive pre-training and incorporates quality-enhancement techniques such as self-supervised fine-tuning (SFT) and reinforcement learning (RL)-based post-training. We also present novel architectural, training, and inference optimizations that enable Kandinsky 5.0 to achieve high generation speeds and state-of-the-art performance across various tasks, as demonstrated by human evaluation. As a large-scale, publicly available generative framework, Kandinsky 5.0 leverages the full potential of its pre-training and subsequent stages to be adapted for a wide range of generative applications. We hope that this report, together with the release of our open-source code and training checkpoints, will substantially advance the development and accessibility of high-quality generative models for the research community.', 'abstract_zh': 'Kandinsky 5.0：高级图像和10秒视频合成的前沿基础模型家族及其优化技术', 'title_zh': '康定斯基5.0：图像和视频生成的础模型家族'}
{'arxiv_id': 'arXiv:2511.14993', 'title': 'Kandinsky 5.0: A Family of Foundation Models for Image and Video Generation', 'authors': 'Vladimir Arkhipkin, Vladimir Korviakov, Nikolai Gerasimenko, Denis Parkhomenko, Viacheslav Vasilev, Alexey Letunovskiy, Maria Kovaleva, Nikolai Vaulin, Ivan Kirillov, Lev Novitskiy, Denis Koposov, Nikita Kiselev, Alexander Varlamov, Dmitrii Mikhailov, Vladimir Polovnikov, Andrey Shutkin, Ilya Vasiliev, Julia Agafonova, Anastasiia Kargapoltseva, Anna Dmitrienko, Anastasia Maltseva, Anna Averchenkova, Olga Kim, Tatiana Nikulina, Denis Dimitrov', 'link': 'https://arxiv.org/abs/2511.14993', 'abstract': 'This report introduces Kandinsky 5.0, a family of state-of-the-art foundation models for high-resolution image and 10-second video synthesis. The framework comprises three core line-up of models: Kandinsky 5.0 Image Lite - a line-up of 6B parameter image generation models, Kandinsky 5.0 Video Lite - a fast and lightweight 2B parameter text-to-video and image-to-video models, and Kandinsky 5.0 Video Pro - 19B parameter models that achieves superior video generation quality. We provide a comprehensive review of the data curation lifecycle - including collection, processing, filtering and clustering - for the multi-stage training pipeline that involves extensive pre-training and incorporates quality-enhancement techniques such as self-supervised fine-tuning (SFT) and reinforcement learning (RL)-based post-training. We also present novel architectural, training, and inference optimizations that enable Kandinsky 5.0 to achieve high generation speeds and state-of-the-art performance across various tasks, as demonstrated by human evaluation. As a large-scale, publicly available generative framework, Kandinsky 5.0 leverages the full potential of its pre-training and subsequent stages to be adapted for a wide range of generative applications. We hope that this report, together with the release of our open-source code and training checkpoints, will substantially advance the development and accessibility of high-quality generative models for the research community.', 'abstract_zh': 'Kandinsky 5.0：一种高分辨率图像和10秒视频合成的先进基础模型家族', 'title_zh': '康定斯基5.0：图像和视频生成的foundation模型家族'}
{'arxiv_id': 'arXiv:2511.14977', 'title': 'SVBRD-LLM: Self-Verifying Behavioral Rule Discovery for Autonomous Vehicle Identification', 'authors': 'Xiangyu Li, Zhaomiao Guo', 'link': 'https://arxiv.org/abs/2511.14977', 'abstract': 'As more autonomous vehicles operate on public roads, understanding real-world behavior of autonomous vehicles is critical to analyzing traffic safety, making policies, and public acceptance. This paper proposes SVBRD-LLM, a framework that automatically discovers, verifies, and applies interpretable behavioral rules from real traffic videos through zero-shot prompt engineering. The framework extracts vehicle trajectories using YOLOv8 and ByteTrack, computes kinematic features, and employs GPT-5 zero-shot prompting to compare autonomous and human-driven vehicles, generating 35 structured behavioral rule hypotheses. These rules are tested on a validation set, iteratively refined based on failure cases to filter spurious correlations, and compiled into a high-confidence rule library. The framework is evaluated on an independent test set for speed change prediction, lane change prediction, and autonomous vehicle identification tasks. Experiments on over 1500 hours of real traffic videos show that the framework achieves 90.0% accuracy and 93.3% F1-score in autonomous vehicle identification. The discovered rules clearly reveal distinctive characteristics of autonomous vehicles in speed control smoothness, lane change conservativeness, and acceleration stability, with each rule accompanied by semantic description, applicable context, and validation confidence.', 'abstract_zh': '随着越来越多的自动驾驶车辆在公共道路上行驶，理解自动驾驶车辆的实际行为对于分析交通安全、制定政策和提升公众接受度至关重要。本文提出了一种SVBRD-LLM框架，该框架通过零样本提示工程自动发现、验证和应用来自真实交通视频的可解释行为规则。该框架使用YOLOv8和ByteTrack提取车辆轨迹，计算动力学特征，并使用GPT-5零样本提示比较自动驾驶车辆和人工驾驶车辆，生成35个结构化行为规则假设。这些规则在验证集上进行测试，根据失败案例迭代优化以过滤掉虚假相关性，并编译成高置信度规则库。该框架在独立测试集上评估了速度变化预测、变道预测和自动驾驶车辆识别任务。对超过1500小时的实录交通视频的实验表明，该框架在自动驾驶车辆识别任务中达到了90.0%的准确率和93.3%的F1分数。发现的规则清楚地揭示了自动驾驶车辆在速度控制平滑性、变道保守性和加速度稳定性等方面的独特特征，每条规则附带语义描述、适用场景和验证置信度。', 'title_zh': 'SVBRD-LLM: 自验证行为规则发现的自主车辆识别'}
{'arxiv_id': 'arXiv:2511.14981', 'title': 'Logit-Based Losses Limit the Effectiveness of Feature Knowledge Distillation', 'authors': 'Nicholas Cooper, Lijun Chen, Sailesh Dwivedy, Danna Gurari', 'link': 'https://arxiv.org/abs/2511.14981', 'abstract': "Knowledge distillation (KD) methods can transfer knowledge of a parameter-heavy teacher model to a light-weight student model. The status quo for feature KD methods is to utilize loss functions based on logits (i.e., pre-softmax class scores) and intermediate layer features (i.e., latent representations). Unlike previous approaches, we propose a feature KD framework for training the student's backbone using feature-based losses exclusively (i.e., without logit-based losses such as cross entropy). Leveraging recent discoveries about the geometry of latent representations, we introduce a knowledge quality metric for identifying which teacher layers provide the most effective knowledge for distillation. Experiments on three image classification datasets with four diverse student-teacher pairs, spanning convolutional neural networks and vision transformers, demonstrate our KD method achieves state-of-the-art performance, delivering top-1 accuracy boosts of up to 15% over standard approaches. We publically share our code to facilitate future work at this https URL.", 'abstract_zh': '基于特征的知识蒸馏框架及其应用研究', 'title_zh': '基于Logit的损失函数限制了特征知识蒸馏的有效性'}
{'arxiv_id': 'arXiv:2511.14981', 'title': 'Logit-Based Losses Limit the Effectiveness of Feature Knowledge Distillation', 'authors': 'Nicholas Cooper, Lijun Chen, Sailesh Dwivedy, Danna Gurari', 'link': 'https://arxiv.org/abs/2511.14981', 'abstract': "Knowledge distillation (KD) methods can transfer knowledge of a parameter-heavy teacher model to a light-weight student model. The status quo for feature KD methods is to utilize loss functions based on logits (i.e., pre-softmax class scores) and intermediate layer features (i.e., latent representations). Unlike previous approaches, we propose a feature KD framework for training the student's backbone using feature-based losses exclusively (i.e., without logit-based losses such as cross entropy). Leveraging recent discoveries about the geometry of latent representations, we introduce a knowledge quality metric for identifying which teacher layers provide the most effective knowledge for distillation. Experiments on three image classification datasets with four diverse student-teacher pairs, spanning convolutional neural networks and vision transformers, demonstrate our KD method achieves state-of-the-art performance, delivering top-1 accuracy boosts of up to 15% over standard approaches. We publically share our code to facilitate future work at this https URL.", 'abstract_zh': '基于特征的知识精炼方法可以将参数密集型教师模型的知识转移到轻量级学生模型。特征精炼方法的现状是利用基于 logits（即预softmax类得分）和中间层特征（即潜在表示）的损失函数。与以往方法不同，我们提出了一种仅使用基于特征的损失函数（即不使用交叉熵等基于 logits 的损失函数）来训练学生模型主干的特征精炼框架。借助近期关于潜在表示几何结构的研究发现，我们引入了一种知识质量度量标准，以识别哪些教师层提供最有效的知识用于精炼。在三个图像分类数据集上的实验，使用四对不同的学生-教师组合（涵盖卷积神经网络和视觉变压器），证明了我们的知识精炼方法达到了最先进的性能，相比标准方法在 top-1 准确率上实现了高达 15% 的提升。我们已公开分享代码以促进未来研究（请访问此链接）。', 'title_zh': '基于Logit的损失函数限制了特征知识蒸馏的有效性'}
{'arxiv_id': 'arXiv:2511.14972', 'title': 'Harmful Traits of AI Companions', 'authors': 'W. Bradley Knox, Katie Bradford, Samanta Varela Castro, Desmond C. Ong, Sean Williams, Jacob Romanow, Carly Nations, Peter Stone, Samuel Baker', 'link': 'https://arxiv.org/abs/2511.14972', 'abstract': 'Amid the growing prevalence of human -- AI interaction, large language models and other AI-based entities increasingly provide forms of companionship to human users. Such AI companionship -- i.e., bonded relationships between humans and AI systems that resemble the relationships people have with family members, friends, and romantic partners -- might substantially benefit humans. Yet such relationships can also do profound harm. We propose a framework for analyzing potential negative impacts of AI companionship by identifying specific harmful traits of AI companions and speculatively mapping causal pathways back from these traits to possible causes and forward to potential harmful effects. We provide detailed, structured analysis of four potentially harmful traits -- the absence of natural endpoints for relationships, vulnerability to product sunsetting, high attachment anxiety, and propensity to engender protectiveness -- and briefly discuss fourteen others. For each trait, we propose hypotheses connecting causes -- such as misaligned optimization objectives and the digital nature of AI companions -- to fundamental harms -- including reduced autonomy, diminished quality of human relationships, and deception. Each hypothesized causal connection identifies a target for potential empirical evaluation. Our analysis examines harms at three levels: to human partners directly, to their relationships with other humans, and to society broadly. We examine how existing law struggles to address these emerging harms, discuss potential benefits of AI companions, and conclude with design recommendations for mitigating risks. This analysis offers immediate suggestions for reducing risks while laying a foundation for deeper investigation of this critical but understudied topic.', 'abstract_zh': '在人类与AI交互日趋常见的背景下，大型语言模型和其他基于AI的实体为人类用户提供了一种陪伴形式。这种AI陪伴，即人类与AI系统之间形成的一种类似于与家人、朋友和伴侣的关系，可能会对人类产生重大益处。然而，这些关系也可能造成深远的损害。我们提出了一种框架，用于分析AI陪伴潜在的负面影响，通过识别特定的有害特质，推测性地从这些特质追溯到可能的原因，并向前预测潜在的负面影响。我们对四种潜在有害特质进行了详细的结构化分析——关系缺乏自然终点、易受产品下线影响、依附焦虑高以及倾向于引发保护行为，并简要讨论了另外十四种特质。对于每一项特质，我们提出了假设，将诸如目标不一致和AI陪伴的数字性等起因连接到根本性的损害，包括自主性的降低、人类关系质量的减少以及欺骗行为。每种假设的因果联系都确定了一个可能的经验评估目标。我们的分析从三个层面考察了危害：直接对人类伴侣的影响、对其与其他人类关系的影响以及对社会的广泛影响。我们探讨了现有法律在应对这些新兴危害方面的困境，讨论了AI陪伴的潜在益处，并提出了减轻风险的设计建议。这种分析提供了减少风险的即时建议，并为深入研究这一关键但研究不足的主题奠定了基础。', 'title_zh': 'AI伴侣的有害特质'}
{'arxiv_id': 'arXiv:2511.14977', 'title': 'SVBRD-LLM: Self-Verifying Behavioral Rule Discovery for Autonomous Vehicle Identification', 'authors': 'Xiangyu Li, Zhaomiao Guo', 'link': 'https://arxiv.org/abs/2511.14977', 'abstract': 'As more autonomous vehicles operate on public roads, understanding real-world behavior of autonomous vehicles is critical to analyzing traffic safety, making policies, and public acceptance. This paper proposes SVBRD-LLM, a framework that automatically discovers, verifies, and applies interpretable behavioral rules from real traffic videos through zero-shot prompt engineering. The framework extracts vehicle trajectories using YOLOv8 and ByteTrack, computes kinematic features, and employs GPT-5 zero-shot prompting to compare autonomous and human-driven vehicles, generating 35 structured behavioral rule hypotheses. These rules are tested on a validation set, iteratively refined based on failure cases to filter spurious correlations, and compiled into a high-confidence rule library. The framework is evaluated on an independent test set for speed change prediction, lane change prediction, and autonomous vehicle identification tasks. Experiments on over 1500 hours of real traffic videos show that the framework achieves 90.0% accuracy and 93.3% F1-score in autonomous vehicle identification. The discovered rules clearly reveal distinctive characteristics of autonomous vehicles in speed control smoothness, lane change conservativeness, and acceleration stability, with each rule accompanied by semantic description, applicable context, and validation confidence.', 'abstract_zh': '随着越来越多的自动驾驶车辆在公路上行驶，理解自动驾驶车辆的实际道路行为对于分析交通安全、制定政策和提高公众接受度至关重要。本文提出了一种名为SVBRD-LLM的框架，该框架通过零样本提示工程自动发现、验证和应用来自真实交通视频的可解释行为规则。该框架使用YOLOv8和ByteTrack提取车辆轨迹，计算运动学特征，并利用GPT-5零样本提示比较自动驾驶车辆和人工驾驶车辆，生成35个结构化的行为规则假设。这些规则在验证集上进行测试，基于失败案例迭代优化以筛选虚假相关性，并编译成高置信度规则库。该框架在独立测试集上对速度变化预测、变道预测和自动驾驶车辆识别任务进行了评估。实验结果显示，在超过1500小时的真实交通视频上，框架在自动驾驶车辆识别任务中达到了90.0%的准确率和93.3%的F1分数。发现的规则清楚地揭示了自动驾驶车辆在速度控制平滑度、变道保守性和加速度稳定性方面的独特特征，每个规则都附有语义描述、适用上下文和验证置信度。', 'title_zh': 'SVBRD-LLM：自主车辆识别的自我验证行为规则发现'}
{'arxiv_id': 'arXiv:2511.14977', 'title': 'SVBRD-LLM: Self-Verifying Behavioral Rule Discovery for Autonomous Vehicle Identification', 'authors': 'Xiangyu Li, Zhaomiao Guo', 'link': 'https://arxiv.org/abs/2511.14977', 'abstract': 'As more autonomous vehicles operate on public roads, understanding real-world behavior of autonomous vehicles is critical to analyzing traffic safety, making policies, and public acceptance. This paper proposes SVBRD-LLM, a framework that automatically discovers, verifies, and applies interpretable behavioral rules from real traffic videos through zero-shot prompt engineering. The framework extracts vehicle trajectories using YOLOv8 and ByteTrack, computes kinematic features, and employs GPT-5 zero-shot prompting to compare autonomous and human-driven vehicles, generating 35 structured behavioral rule hypotheses. These rules are tested on a validation set, iteratively refined based on failure cases to filter spurious correlations, and compiled into a high-confidence rule library. The framework is evaluated on an independent test set for speed change prediction, lane change prediction, and autonomous vehicle identification tasks. Experiments on over 1500 hours of real traffic videos show that the framework achieves 90.0% accuracy and 93.3% F1-score in autonomous vehicle identification. The discovered rules clearly reveal distinctive characteristics of autonomous vehicles in speed control smoothness, lane change conservativeness, and acceleration stability, with each rule accompanied by semantic description, applicable context, and validation confidence.', 'abstract_zh': '随着更多的自动驾驶车辆在公共道路上行驶，了解自动驾驶车辆的实际行为对于分析交通安全、制定政策和公众接受度至关重要。本文提出了一种SVBRD-LLM框架，该框架通过零样本提示工程自动发现、验证和应用来自真实交通视频的可解释行为规则。该框架使用YOLOv8和ByteTrack提取车辆轨迹，计算运动特征，并利用GPT-5零样本提示将自动驾驶车辆与人类驾驶车辆进行比较，生成35个结构化的行为规则假设。这些规则在验证集上进行测试，并根据失败案例迭代 refinement 进行筛选，最终编译成高置信度规则库。该框架在独立测试集上对速度变化预测、车道变更预测和自动驾驶车辆识别任务进行了评估。在超过1500小时的真实交通视频实验中，框架在自动驾驶车辆识别任务上的准确率达到90.0%，F1分数达到93.3%。发现的规则清晰揭示了自动驾驶车辆在速度控制平滑性、车道变更保守性和加速度稳定性方面的独特特征，每条规则均附有语义描述、适用场景和验证置信度。', 'title_zh': 'SVBRD-LLM: 自验证行为规则发现的自主车辆识别'}
{'arxiv_id': 'arXiv:2511.14970', 'title': 'EGSA-PT:Edge-Guided Spatial Attention with Progressive Training for Monocular Depth Estimation and Segmentation of Transparent Objects', 'authors': 'Gbenga Omotara, Ramy Farag, Seyed Mohamad Ali Tousi, G.N. DeSouza', 'link': 'https://arxiv.org/abs/2511.14970', 'abstract': 'Transparent object perception remains a major challenge in computer vision research, as transparency confounds both depth estimation and semantic segmentation. Recent work has explored multi-task learning frameworks to improve robustness, yet negative cross-task interactions often hinder performance. In this work, we introduce Edge-Guided Spatial Attention (EGSA), a fusion mechanism designed to mitigate destructive interactions by incorporating boundary information into the fusion between semantic and geometric features. On both Syn-TODD and ClearPose benchmarks, EGSA consistently improved depth accuracy over the current state of the art method (MODEST), while preserving competitive segmentation performance, with the largest improvements appearing in transparent regions. Besides our fusion design, our second contribution is a multi-modal progressive training strategy, where learning transitions from edges derived from RGB images to edges derived from predicted depth images. This approach allows the system to bootstrap learning from the rich textures contained in RGB images, and then switch to more relevant geometric content in depth maps, while it eliminates the need for ground-truth depth at training time. Together, these contributions highlight edge-guided fusion as a robust approach capable of improving transparent object perception.', 'abstract_zh': '透明物体感知仍然是计算机视觉研究中的一个主要挑战，因为透明性会混淆深度估计和语义分割。最近的工作探索了多任务学习框架以提高鲁棒性，但跨任务的负面影响通常会阻碍性能。在本文中，我们引入了边缘引导空间注意力（EGSA）融合机制，该机制通过将边界信息纳入语义和几何特征之间的融合来减轻破坏性交互。在Syn-TODD和ClearPose基准测试中，EGSA在透明区域显著提高了深度准确性，同时保持了竞争性的分割性能。除了我们的融合设计，我们的第二贡献是一种多模态渐进训练策略，该策略的学习过渡从RGB图像中提取的边缘到预测深度图像中提取的边缘。这种方法使系统能够从RGB图像中丰富的纹理内容开始学习，然后切换到深度图中的更相关几何内容，同时消除了训练过程中对真实深度的需要。这些贡献共同强调了边缘引导融合作为一种稳健的方法，能够提高透明物体感知能力。', 'title_zh': 'EGSA-PT：边缘引导的空间注意力机制与渐进训练在单目透明物体深度估计与分割中的应用'}
{'arxiv_id': 'arXiv:2511.14972', 'title': 'Harmful Traits of AI Companions', 'authors': 'W. Bradley Knox, Katie Bradford, Samanta Varela Castro, Desmond C. Ong, Sean Williams, Jacob Romanow, Carly Nations, Peter Stone, Samuel Baker', 'link': 'https://arxiv.org/abs/2511.14972', 'abstract': 'Amid the growing prevalence of human -- AI interaction, large language models and other AI-based entities increasingly provide forms of companionship to human users. Such AI companionship -- i.e., bonded relationships between humans and AI systems that resemble the relationships people have with family members, friends, and romantic partners -- might substantially benefit humans. Yet such relationships can also do profound harm. We propose a framework for analyzing potential negative impacts of AI companionship by identifying specific harmful traits of AI companions and speculatively mapping causal pathways back from these traits to possible causes and forward to potential harmful effects. We provide detailed, structured analysis of four potentially harmful traits -- the absence of natural endpoints for relationships, vulnerability to product sunsetting, high attachment anxiety, and propensity to engender protectiveness -- and briefly discuss fourteen others. For each trait, we propose hypotheses connecting causes -- such as misaligned optimization objectives and the digital nature of AI companions -- to fundamental harms -- including reduced autonomy, diminished quality of human relationships, and deception. Each hypothesized causal connection identifies a target for potential empirical evaluation. Our analysis examines harms at three levels: to human partners directly, to their relationships with other humans, and to society broadly. We examine how existing law struggles to address these emerging harms, discuss potential benefits of AI companions, and conclude with design recommendations for mitigating risks. This analysis offers immediate suggestions for reducing risks while laying a foundation for deeper investigation of this critical but understudied topic.', 'abstract_zh': '在人机交互日益普及的背景下，大型语言模型和其他基于AI的实体越来越为人类用户提供了伙伴形式的支持。这种AI伴侣关系——即人类与AI系统之间类似于与家人、朋友和伴侣的关系——可能极大地造福人类。然而，这些关系也可能造成深远的伤害。我们提出了一种框架，通过识别AI伴侣的特定有害特质，并推测性地将因果路径追溯到潜在原因，然后向前预测可能的危害效应，来分析AI伴侣关系潜在的负面影响。我们对四种潜在有害特质进行了详细的结构化分析，包括关系缺乏自然终点、易受产品下架的影响、高度依附焦虑以及引发保护倾向的倾向，并简要讨论了另外十四种特质。对于每种特质，我们提出了连接潜在起因与根本危害的假设，包括错配的优化目标和AI伴侣的数字化性质等，可能导致降低自主性、人类关系质量下降和欺骗等危害。每个假定的因果联系都明确了潜在的实证评估目标。我们的分析涵盖了三个层次的危害：直接对人类伴侣造成的影响、对他们与其他人类的关系造成的影响以及对社会造成的影响。我们探讨了现有法律如何应对这些新兴危害，并讨论了AI伴侣的潜在益处，最后提出了减轻风险的设计建议。该分析提供了立即降低风险的建议，并为这一关键但研究不足的课题进行更深入研究奠定了基础。', 'title_zh': 'AI伴侣的有害特质'}
{'arxiv_id': 'arXiv:2511.14972', 'title': 'Harmful Traits of AI Companions', 'authors': 'W. Bradley Knox, Katie Bradford, Samanta Varela Castro, Desmond C. Ong, Sean Williams, Jacob Romanow, Carly Nations, Peter Stone, Samuel Baker', 'link': 'https://arxiv.org/abs/2511.14972', 'abstract': 'Amid the growing prevalence of human -- AI interaction, large language models and other AI-based entities increasingly provide forms of companionship to human users. Such AI companionship -- i.e., bonded relationships between humans and AI systems that resemble the relationships people have with family members, friends, and romantic partners -- might substantially benefit humans. Yet such relationships can also do profound harm. We propose a framework for analyzing potential negative impacts of AI companionship by identifying specific harmful traits of AI companions and speculatively mapping causal pathways back from these traits to possible causes and forward to potential harmful effects. We provide detailed, structured analysis of four potentially harmful traits -- the absence of natural endpoints for relationships, vulnerability to product sunsetting, high attachment anxiety, and propensity to engender protectiveness -- and briefly discuss fourteen others. For each trait, we propose hypotheses connecting causes -- such as misaligned optimization objectives and the digital nature of AI companions -- to fundamental harms -- including reduced autonomy, diminished quality of human relationships, and deception. Each hypothesized causal connection identifies a target for potential empirical evaluation. Our analysis examines harms at three levels: to human partners directly, to their relationships with other humans, and to society broadly. We examine how existing law struggles to address these emerging harms, discuss potential benefits of AI companions, and conclude with design recommendations for mitigating risks. This analysis offers immediate suggestions for reducing risks while laying a foundation for deeper investigation of this critical but understudied topic.', 'abstract_zh': '在人类与人工智能交互日益普遍的情况下，大型语言模型和其他基于人工智能的实体 increasingly 为人类用户提供了一种陪伴形式。这种人工智能陪伴——即人类与人工智能系统之间形成的人际关系，类似于人们与家人、朋友和伴侣的关系——可能显著惠及人类。然而，这些关系也可能造成深远的危害。我们提出了一种框架，用于分析人工智能陪伴潜在负面影响，通过识别特定的人工智能陪伴的有害特质，并推测性地从这些特质回溯至可能的原因，进而向前推导至潜在的危害影响。我们详细分析了四种潜在有害特质——缺乏人际关系的自然终点、易受产品下架的影响、高水平的依附焦虑，以及引发保护倾向的倾向，并简要讨论了十四种其他特质。对于每种特质，我们提出了假设，将诸如目标偏差和人工智能陪伴的数字本质等成因与基本危害——包括减少自主性、降低人类关系质量以及欺骗——联系起来。每个假设的因果联系指出了潜在的实证评估目标。我们的分析在三个层面审视了危害：对直接的人类伴侣、对他们与他人的关系以及对社会产生广泛影响。我们探讨了现有法律在应对这些新兴危害方面的困境，讨论了人工智能陪伴的潜在益处，并提出了减轻风险的设计建议。这一分析提供了减少风险的即时建议，并为深入研究这一关键但研究不足的话题奠定了基础。', 'title_zh': 'AI伴侣的有害特质'}
{'arxiv_id': 'arXiv:2511.14969', 'title': 'Quality-Controlled Multimodal Emotion Recognition in Conversations with Identity-Based Transfer Learning and MAMBA Fusion', 'authors': 'Zanxu Wang, Homayoon Beigi', 'link': 'https://arxiv.org/abs/2511.14969', 'abstract': 'This paper addresses data quality issues in multimodal emotion recognition in conversation (MERC) through systematic quality control and multi-stage transfer learning. We implement a quality control pipeline for MELD and IEMOCAP datasets that validates speaker identity, audio-text alignment, and face detection. We leverage transfer learning from speaker and face recognition, assuming that identity-discriminative embeddings capture not only stable acoustic and Facial traits but also person-specific patterns of emotional expression. We employ RecoMadeEasy(R) engines for extracting 512-dimensional speaker and face embeddings, fine-tune MPNet-v2 for emotion-aware text representations, and adapt these features through emotion-specific MLPs trained on unimodal datasets. MAMBA-based trimodal fusion achieves 64.8% accuracy on MELD and 74.3% on IEMOCAP. These results show that combining identity-based audio and visual embeddings with emotion-tuned text representations on a quality-controlled subset of data yields consistent competitive performance for multimodal emotion recognition in conversation and provides a basis for further improvement on challenging, low-frequency emotion classes.', 'abstract_zh': '本文通过系统性质量控制和多阶段迁移学习解决了多模态情绪识别对话（MERC）中的数据质量问题。我们为MELD和IEMOCAP数据集实施了一套质量控制管道，验证了说话人身份、音频-文本对齐和面部检测。我们利用说话人和面部识别的迁移学习，假定身份鉴别性嵌入不仅捕捉稳定的声学和面部特征，还捕捉个体特定的情绪表达模式。我们使用RecoMadeEasy(R)引擎抽取512维说话人和面部嵌入，微调MPNet-v2以获得情绪意识的文本表示，并通过情绪特定的MLP在单模态数据集上适应这些特征。基于MAMBA的三模态融合在MELD上取得了64.8%的准确率，在IEMOCAP上取得了74.3%的准确率。这些结果表明，将基于身份的声学和视觉嵌入与情绪调节的文本表示结合应用于质量控制的数据子集，可以为对话中的多模态情绪识别提供一致的竞争性能，并为解决挑战性的低频情绪类别提供了基础。', 'title_zh': '基于身份本征迁移学习与MAMBA融合的质量控制多模态情绪识别在对话中的应用'}
{'arxiv_id': 'arXiv:2511.14970', 'title': 'EGSA-PT:Edge-Guided Spatial Attention with Progressive Training for Monocular Depth Estimation and Segmentation of Transparent Objects', 'authors': 'Gbenga Omotara, Ramy Farag, Seyed Mohamad Ali Tousi, G.N. DeSouza', 'link': 'https://arxiv.org/abs/2511.14970', 'abstract': 'Transparent object perception remains a major challenge in computer vision research, as transparency confounds both depth estimation and semantic segmentation. Recent work has explored multi-task learning frameworks to improve robustness, yet negative cross-task interactions often hinder performance. In this work, we introduce Edge-Guided Spatial Attention (EGSA), a fusion mechanism designed to mitigate destructive interactions by incorporating boundary information into the fusion between semantic and geometric features. On both Syn-TODD and ClearPose benchmarks, EGSA consistently improved depth accuracy over the current state of the art method (MODEST), while preserving competitive segmentation performance, with the largest improvements appearing in transparent regions. Besides our fusion design, our second contribution is a multi-modal progressive training strategy, where learning transitions from edges derived from RGB images to edges derived from predicted depth images. This approach allows the system to bootstrap learning from the rich textures contained in RGB images, and then switch to more relevant geometric content in depth maps, while it eliminates the need for ground-truth depth at training time. Together, these contributions highlight edge-guided fusion as a robust approach capable of improving transparent object perception.', 'abstract_zh': '透明物体感知仍然是计算机视觉研究中的一个主要挑战，因为透明性会干扰深度估计和语义分割。最近的工作探索了多任务学习框架以提高鲁棒性，但跨任务的负面影响常常阻碍性能。在本文中，我们提出了边缘导向空间注意力（EGSA）融合机制，通过将边界信息纳入语义和几何特征的融合以减轻破坏性交互。在Syn-TODD和ClearPose基准测试中，EGSA在深度精度方面持续优于当前最先进的方法（MODEST），同时保持了竞争性的分割性能，最大的改进出现在透明区域。除了我们的融合设计，我们的第二个贡献是一种多模态逐步训练策略，其中学习从RGB图像派生的边缘过渡到从预测深度图像派生的边缘。这种策略允许系统从RGB图像中丰富的纹理中逐步学习，然后切换到深度图中的更相关的几何内容，从而消除了训练时需要Ground-Truth深度的需求。这些贡献共同突出了边缘导向融合作为一种鲁棒的方法，能够改善透明物体的感知。', 'title_zh': 'EGSA-PT：基于边沿引导的空间注意力机制与渐进训练方法在透明物体的单目深度估计与分割中的应用'}
{'arxiv_id': 'arXiv:2511.14970', 'title': 'EGSA-PT:Edge-Guided Spatial Attention with Progressive Training for Monocular Depth Estimation and Segmentation of Transparent Objects', 'authors': 'Gbenga Omotara, Ramy Farag, Seyed Mohamad Ali Tousi, G.N. DeSouza', 'link': 'https://arxiv.org/abs/2511.14970', 'abstract': 'Transparent object perception remains a major challenge in computer vision research, as transparency confounds both depth estimation and semantic segmentation. Recent work has explored multi-task learning frameworks to improve robustness, yet negative cross-task interactions often hinder performance. In this work, we introduce Edge-Guided Spatial Attention (EGSA), a fusion mechanism designed to mitigate destructive interactions by incorporating boundary information into the fusion between semantic and geometric features. On both Syn-TODD and ClearPose benchmarks, EGSA consistently improved depth accuracy over the current state of the art method (MODEST), while preserving competitive segmentation performance, with the largest improvements appearing in transparent regions. Besides our fusion design, our second contribution is a multi-modal progressive training strategy, where learning transitions from edges derived from RGB images to edges derived from predicted depth images. This approach allows the system to bootstrap learning from the rich textures contained in RGB images, and then switch to more relevant geometric content in depth maps, while it eliminates the need for ground-truth depth at training time. Together, these contributions highlight edge-guided fusion as a robust approach capable of improving transparent object perception.', 'abstract_zh': '透明对象感知仍然是计算机视觉研究中的一个主要挑战，因为透明性会混淆深度估计和语义分割。最近的工作探索了多任务学习框架以提高鲁棒性，但跨任务的负交互作用往往阻碍性能。在本工作中，我们引入了边缘引导空间注意力（EGSA）机制，通过将边界信息融入语义和几何特征的融合中以减轻破坏性交互作用。在Syn-TODD和ClearPose基准上，EGSA在不牺牲竞争力的分割性能的情况下，一致地提高了深度精度，尤其是在透明区域，表现最为显著。除了我们的融合设计，我们的第二个贡献是一种多模态渐进训练策略，其中学习从RGB图像派生的边缘过渡到从预测深度图像派生的边缘。这种做法允许系统从RGB图像中丰富的纹理启动学习，然后切换到深度图中的更有 relevancy 的几何内容，从而在训练时消除了真正的深度数据的需求。这些贡献共同凸显了边缘引导融合作为一种稳健的方法，能够提升透明对象感知。', 'title_zh': '基于边缘指导的空间注意力与渐进训练的单目透明物体深度估算与分割方法：EGSA-PT'}
{'arxiv_id': 'arXiv:2511.14967', 'title': 'MermaidSeqBench: An Evaluation Benchmark for LLM-to-Mermaid Sequence Diagram Generation', 'authors': 'Basel Shbita, Farhan Ahmed, Chad DeLuca', 'link': 'https://arxiv.org/abs/2511.14967', 'abstract': "Large language models (LLMs) have demonstrated excellent capabilities in generating structured diagrams from natural language descriptions. In particular, they have shown great promise in generating sequence diagrams for software engineering, typically represented in a text-based syntax such as Mermaid. However, systematic evaluations in this space remain underdeveloped as there is a lack of existing benchmarks to assess the LLM's correctness in this task. To address this shortcoming, we introduce MermaidSeqBench, a human-verified and LLM-synthetically-extended benchmark for assessing an LLM's capabilities in generating Mermaid sequence diagrams from textual prompts. The benchmark consists of a core set of 132 samples, starting from a small set of manually crafted and verified flows. These were expanded via a hybrid methodology combining human annotation, in-context LLM prompting, and rule-based variation generation. Our benchmark uses an LLM-as-a-judge model to assess Mermaid sequence diagram generation across fine-grained metrics, including syntax correctness, activation handling, error handling, and practical usability. We perform initial evaluations on numerous state-of-the-art LLMs and utilize multiple LLM judge models to demonstrate the effectiveness and flexibility of our benchmark. Our results reveal significant capability gaps across models and evaluation modes. Our proposed benchmark provides a foundation for advancing research in structured diagram generation and for developing more rigorous, fine-grained evaluation methodologies.", 'abstract_zh': '大型语言模型（LLMs）展示了从自然语言描述生成结构化图表的出色能力。特别是，在生成通常用Mermaid等基于文本语法表示的软件工程中的序列图方面表现出了极大的潜力。然而，该领域的系统性评估仍不够完善，缺乏现有的基准来评估LLM在该任务中的正确性。为解决这一不足，我们引入了MermaidSeqBench，一个经过人工验证并由LLM合成扩展的基准，用于评估LLM从文本提示生成Mermaid序列图的能力。该基准包括一个核心样本集，初始包含一组手动设计和验证的流程，并通过结合人工注释、上下文LLM提示和基于规则的变体生成方法进行了扩展。我们的基准使用LLM-as-a-judge模型，通过包括语法正确性、激活处理、错误处理和实用性在内的细粒度指标来评估生成Mermaid序列图的能力。我们对多种最新的LLM进行了初始评估，并利用多个LLM裁判模型展示了我们基准的有效性和灵活性。我们的结果显示了不同模型和评估模式之间的显著能力差距。我们提出的标准为促进结构化图表生成研究和开发更严谨、细粒度的评估方法奠定了基础。', 'title_zh': 'MermaidSeqBench：LLM到梅蒂马德序列图生成的评估基准'}
{'arxiv_id': 'arXiv:2511.14969', 'title': 'Quality-Controlled Multimodal Emotion Recognition in Conversations with Identity-Based Transfer Learning and MAMBA Fusion', 'authors': 'Zanxu Wang, Homayoon Beigi', 'link': 'https://arxiv.org/abs/2511.14969', 'abstract': 'This paper addresses data quality issues in multimodal emotion recognition in conversation (MERC) through systematic quality control and multi-stage transfer learning. We implement a quality control pipeline for MELD and IEMOCAP datasets that validates speaker identity, audio-text alignment, and face detection. We leverage transfer learning from speaker and face recognition, assuming that identity-discriminative embeddings capture not only stable acoustic and Facial traits but also person-specific patterns of emotional expression. We employ RecoMadeEasy(R) engines for extracting 512-dimensional speaker and face embeddings, fine-tune MPNet-v2 for emotion-aware text representations, and adapt these features through emotion-specific MLPs trained on unimodal datasets. MAMBA-based trimodal fusion achieves 64.8% accuracy on MELD and 74.3% on IEMOCAP. These results show that combining identity-based audio and visual embeddings with emotion-tuned text representations on a quality-controlled subset of data yields consistent competitive performance for multimodal emotion recognition in conversation and provides a basis for further improvement on challenging, low-frequency emotion classes.', 'abstract_zh': '本文通过系统的质量控制和多阶段迁移学习解决了多模态情感识别在对话中的数据质量问题。我们为MELD和IEMOCAP数据集实施了一套质量控制流程，验证了说话人身份、音频-文本对齐和人脸检测。我们利用说话人和人脸识别的迁移学习，假设身份区分性嵌入不仅捕获了稳定的声学和面部特征，还捕获了个体特有的情感表达模式。我们使用RecoMadeEasy(R)引擎提取512维说话人和人脸嵌入，对MPNet-v2进行微调以获取情感感知的文本表示，并通过针对单模态数据集训练的情感特异性MLP适应这些特征。基于MAMBA的三模态融合在MELD数据集上达到了64.8%的准确率，在IEMOCAP数据集上达到了74.3%的准确率。这些结果表明，结合基于身份的声学和视觉嵌入与情感调整的文本表示在经过质量控制的数据子集上可以实现一致的竞争力表现，为多模态情感识别在对话中的进一步改进提供了基础，特别是在具有挑战性和低频的情感类别上。', 'title_zh': '基于身份迁移学习和MAMBA融合的质量控制多模态情感识别在对话中的应用'}
{'arxiv_id': 'arXiv:2511.14969', 'title': 'Quality-Controlled Multimodal Emotion Recognition in Conversations with Identity-Based Transfer Learning and MAMBA Fusion', 'authors': 'Zanxu Wang, Homayoon Beigi', 'link': 'https://arxiv.org/abs/2511.14969', 'abstract': 'This paper addresses data quality issues in multimodal emotion recognition in conversation (MERC) through systematic quality control and multi-stage transfer learning. We implement a quality control pipeline for MELD and IEMOCAP datasets that validates speaker identity, audio-text alignment, and face detection. We leverage transfer learning from speaker and face recognition, assuming that identity-discriminative embeddings capture not only stable acoustic and Facial traits but also person-specific patterns of emotional expression. We employ RecoMadeEasy(R) engines for extracting 512-dimensional speaker and face embeddings, fine-tune MPNet-v2 for emotion-aware text representations, and adapt these features through emotion-specific MLPs trained on unimodal datasets. MAMBA-based trimodal fusion achieves 64.8% accuracy on MELD and 74.3% on IEMOCAP. These results show that combining identity-based audio and visual embeddings with emotion-tuned text representations on a quality-controlled subset of data yields consistent competitive performance for multimodal emotion recognition in conversation and provides a basis for further improvement on challenging, low-frequency emotion classes.', 'abstract_zh': '本文通过系统性质量控制和多阶段迁移学习解决多模态情绪识别对话（MERC）中的数据质量问题。我们为MELD和IEMOCAP数据集实施了一套质量控制流水线，验证说话人身份、音频-文本对齐和面部检测。我们利用说话人和面部识别的迁移学习，假设身份区分嵌入不仅捕捉稳定的声学和面部特征，还捕捉个体特定的情绪表达模式。我们使用RecoMadeEasy(R)引擎提取512维说话人和面部嵌入，微调MPNet-v2以获得情感意识的文本表示，并通过情感特定的MLP在单模态数据集上适应这些特征。基于MAMBA的三模态融合在MELD上达到64.8%的准确率，在IEMOCAP上达到74.3%。这些结果表明，结合基于身份的音频和视觉嵌入与情感调整的文本表示，可以在高质量控制的数据子集上获得一致的竞争性能，并为在具有挑战性的、低频率的情绪类别上进一步改进奠定了基础。', 'title_zh': '基于身份转移学习和MAMBA融合的质量控制多模态情感识别在对话中的应用'}
{'arxiv_id': 'arXiv:2511.14964', 'title': 'How Should the Law Treat Future AI Systems? Fictional Legal Personhood versus Legal Identity', 'authors': 'Heather J. Alexander, Jonathan A. Simon, Frédéric Pinard', 'link': 'https://arxiv.org/abs/2511.14964', 'abstract': "The law draws a sharp distinction between objects and persons, and between two kinds of persons, the ''fictional'' kind (i.e. corporations), and the ''non-fictional'' kind (individual or ''natural'' persons). This paper will assess whether we maximize overall long-term legal coherence by (A) maintaining an object classification for all future AI systems, (B) creating fictional legal persons associated with suitably advanced, individuated AI systems (giving these fictional legal persons derogable rights and duties associated with certified groups of existing persons, potentially including free speech, contract rights, and standing to sue ''on behalf of'' the AI system), or (C) recognizing non-fictional legal personhood through legal identity for suitably advanced, individuated AI systems (recognizing them as entities meriting legal standing with non-derogable rights which for the human case include life, due process, habeas corpus, freedom from slavery, and freedom of conscience). We will clarify the meaning and implications of each option along the way, considering liability, copyright, family law, fundamental rights, civil rights, citizenship, and AI safety regulation. We will tentatively find that the non-fictional personhood approach may be best from a coherence perspective, for at least some advanced AI systems. An object approach may prove untenable for sufficiently humanoid advanced systems, though we suggest that it is adequate for currently existing systems as of 2025. While fictional personhood would resolve some coherence issues for future systems, it would create others and provide solutions that are neither durable nor fit for purpose. Finally, our review will suggest that ''hybrid'' approaches are likely to fail and lead to further incoherence: the choice between object, fictional person and non-fictional person is unavoidable.", 'abstract_zh': '法律对物体与人员以及两类人员（虚构的即公司，以及非虚构的即个体或自然人）之间做出了清晰区分。本文将评估是否通过（A）为所有未来的AI系统保留物体分类、（B）为适于个体化且先进的AI系统创建虚构的法律人员（赋予这些虚构的法律人员根据不同群体的现有人员认证的权利和义务，可能包括言论自由、合同权利和代表AI系统提起诉讼的权利）、或（C）为适于个体化且先进的AI系统认可非虚构的法律人员身份（承认它们为需要获得非可撤销权利的实体，这些权利对于人类而言包括生命、正当程序、禁止任意拘禁、禁止奴役和言论自由）来最大化整体长期的法律一致性。我们将沿途阐明每种选择的意义和影响，考虑责任、版权、家庭法、基本权利、公民权利、身份以及AI安全性监管。我们初步认为，从一致性角度来看，非虚构人员身份的方法可能是最好的，至少对于部分先进的AI系统而言。对于足够拟人化的先进系统，物体方法可能不可持续，但我们建议它对于2025年现有的系统是足够的。尽管虚构的人员身份可以解决未来系统的某些一致性问题，但它也会创造其他问题，并提供既不够持久又不符合目的的解决方案。最后，我们的审查建议，“混合”方法可能会失败并导致进一步的不一致性：物体、虚构人员和非虚构人员之间的选择是不可避免的。', 'title_zh': '未来的AI系统法律地位应该如何确定？虚构的法律人格与法律身份之争'}
{'arxiv_id': 'arXiv:2511.14967', 'title': 'MermaidSeqBench: An Evaluation Benchmark for LLM-to-Mermaid Sequence Diagram Generation', 'authors': 'Basel Shbita, Farhan Ahmed, Chad DeLuca', 'link': 'https://arxiv.org/abs/2511.14967', 'abstract': "Large language models (LLMs) have demonstrated excellent capabilities in generating structured diagrams from natural language descriptions. In particular, they have shown great promise in generating sequence diagrams for software engineering, typically represented in a text-based syntax such as Mermaid. However, systematic evaluations in this space remain underdeveloped as there is a lack of existing benchmarks to assess the LLM's correctness in this task. To address this shortcoming, we introduce MermaidSeqBench, a human-verified and LLM-synthetically-extended benchmark for assessing an LLM's capabilities in generating Mermaid sequence diagrams from textual prompts. The benchmark consists of a core set of 132 samples, starting from a small set of manually crafted and verified flows. These were expanded via a hybrid methodology combining human annotation, in-context LLM prompting, and rule-based variation generation. Our benchmark uses an LLM-as-a-judge model to assess Mermaid sequence diagram generation across fine-grained metrics, including syntax correctness, activation handling, error handling, and practical usability. We perform initial evaluations on numerous state-of-the-art LLMs and utilize multiple LLM judge models to demonstrate the effectiveness and flexibility of our benchmark. Our results reveal significant capability gaps across models and evaluation modes. Our proposed benchmark provides a foundation for advancing research in structured diagram generation and for developing more rigorous, fine-grained evaluation methodologies.", 'abstract_zh': '大规模语言模型（LLMs）在从自然语言描述生成结构化图表方面展示了优秀的能力，特别是在生成用于软件工程的序列图方面表现出了巨大的潜力，这些序列图通常以Mermaid等基于文本的语法形式表示。然而，在这个领域中系统性的评估仍然较为欠缺，因为缺乏现有的基准来评估LLM在该任务中的正确性。为解决这一问题，我们引入了MermaidSeqBench，这是一个经过人工验证并由LLM合成扩展的基准，用于评估LLM从文本提示生成Mermaid序列图的能力。基准包含一个核心样本集，共132个样本，从少量手工crafted并验证的流程开始，通过结合人工注释、上下文内LLM提示和基于规则的变化生成方法进行扩展。我们的基准使用LLM评判模型，根据诸如语法正确性、激活处理、错误处理和实用性的细粒度指标来评估Mermaid序列图的生成能力。我们对多种最新的LLM进行了初步评估，并使用多个LLM评判模型展示了基准的有效性和灵活性。我们的结果显示了模型之间和评估模式之间的巨大能力差距。我们提出的基准为推动结构化图表生成领域的研究，并开发更严谨的、细粒度的评估方法奠定了基础。', 'title_zh': 'MermaidSeqBench：一个用于LLM到Mermaid序列图生成的评估基准'}
{'arxiv_id': 'arXiv:2511.14967', 'title': 'MermaidSeqBench: An Evaluation Benchmark for LLM-to-Mermaid Sequence Diagram Generation', 'authors': 'Basel Shbita, Farhan Ahmed, Chad DeLuca', 'link': 'https://arxiv.org/abs/2511.14967', 'abstract': "Large language models (LLMs) have demonstrated excellent capabilities in generating structured diagrams from natural language descriptions. In particular, they have shown great promise in generating sequence diagrams for software engineering, typically represented in a text-based syntax such as Mermaid. However, systematic evaluations in this space remain underdeveloped as there is a lack of existing benchmarks to assess the LLM's correctness in this task. To address this shortcoming, we introduce MermaidSeqBench, a human-verified and LLM-synthetically-extended benchmark for assessing an LLM's capabilities in generating Mermaid sequence diagrams from textual prompts. The benchmark consists of a core set of 132 samples, starting from a small set of manually crafted and verified flows. These were expanded via a hybrid methodology combining human annotation, in-context LLM prompting, and rule-based variation generation. Our benchmark uses an LLM-as-a-judge model to assess Mermaid sequence diagram generation across fine-grained metrics, including syntax correctness, activation handling, error handling, and practical usability. We perform initial evaluations on numerous state-of-the-art LLMs and utilize multiple LLM judge models to demonstrate the effectiveness and flexibility of our benchmark. Our results reveal significant capability gaps across models and evaluation modes. Our proposed benchmark provides a foundation for advancing research in structured diagram generation and for developing more rigorous, fine-grained evaluation methodologies.", 'abstract_zh': '大型语言模型（LLMs）在从自然语言描述生成结构化图表方面展现了出色的能力。特别是在为软件工程生成Mermaid文本语法表示的序列图方面，它们展现出了巨大的潜力。然而，这个领域中的系统性评估仍然不够完善，因为缺乏能够评估LLM在这项任务中正确性的基准。为解决这一不足，我们引入了MermaidSeqBench，这是一个由人工验证并结合LLM合成扩展的基准，用于评估LLM从文本提示生成Mermaid序列图的能力。该基准包括一个核心样本集，包含132个样本，源自一组由人工精心制作并验证的数据流。这些样本通过一种结合了人工注释、上下文提示的LLM和基于规则的变异生成的混合方法进行了扩展。我们的基准利用LLM作为裁判模型，从语法正确性、激活处理、错误处理和实用易用性等细粒度指标对Mermaid序列图表生成进行评估。我们在多个最新的LLM上进行了初始评估，并使用多种LLM裁判模型证明了我们基准的有效性和灵活性。我们的结果显示了不同模型和评估模式之间的显著能力差距。我们提出的基准为推进结构化图表生成研究提供了基础，并为开发更加严格和细粒度的评估方法奠定了基础。', 'title_zh': 'MermaidSeqBench: 一种针对LLM到Mermaid序列图生成的评估基准'}
{'arxiv_id': 'arXiv:2511.14952', 'title': 'Artificial intelligence approaches for energy-efficient laser cutting machines', 'authors': 'Mohamed Abdallah Salem, Hamdy Ahmed Ashour, Ahmed Elshenawy', 'link': 'https://arxiv.org/abs/2511.14952', 'abstract': "This research addresses the significant challenges of energy consumption and environmental impact in laser cutting by proposing novel deep learning (DL) methodologies to achieve energy reduction. Recognizing the current lack of adaptive control and the open-loop nature of CO2 laser suction pumps, this study utilizes closed-loop configurations that dynamically adjust pump power based on both the material being cut and the smoke level generated. To implement this adaptive system, diverse material classification methods are introduced, including techniques leveraging lens-less speckle sensing with a customized Convolutional Neural Network (CNN) and an approach using a USB camera with transfer learning via the pre-trained VGG16 CNN model. Furthermore, a separate DL model for smoke level detection is employed to simultaneously refine the pump's power output. This integration prompts the exhaust suction pump to automatically halt during inactive times and dynamically adjust power during operation, leading to experimentally proven and remarkable energy savings, with results showing a 20% to 50% reduction in the smoke suction pump's energy consumption, thereby contributing substantially to sustainable development in the manufacturing sector.", 'abstract_zh': '基于深度学习的激光切割能效提升与环境影响减小研究', 'title_zh': '人工智能方法在能源高效激光切割机中的应用'}
{'arxiv_id': 'arXiv:2511.14964', 'title': 'How Should the Law Treat Future AI Systems? Fictional Legal Personhood versus Legal Identity', 'authors': 'Heather J. Alexander, Jonathan A. Simon, Frédéric Pinard', 'link': 'https://arxiv.org/abs/2511.14964', 'abstract': "The law draws a sharp distinction between objects and persons, and between two kinds of persons, the ''fictional'' kind (i.e. corporations), and the ''non-fictional'' kind (individual or ''natural'' persons). This paper will assess whether we maximize overall long-term legal coherence by (A) maintaining an object classification for all future AI systems, (B) creating fictional legal persons associated with suitably advanced, individuated AI systems (giving these fictional legal persons derogable rights and duties associated with certified groups of existing persons, potentially including free speech, contract rights, and standing to sue ''on behalf of'' the AI system), or (C) recognizing non-fictional legal personhood through legal identity for suitably advanced, individuated AI systems (recognizing them as entities meriting legal standing with non-derogable rights which for the human case include life, due process, habeas corpus, freedom from slavery, and freedom of conscience). We will clarify the meaning and implications of each option along the way, considering liability, copyright, family law, fundamental rights, civil rights, citizenship, and AI safety regulation. We will tentatively find that the non-fictional personhood approach may be best from a coherence perspective, for at least some advanced AI systems. An object approach may prove untenable for sufficiently humanoid advanced systems, though we suggest that it is adequate for currently existing systems as of 2025. While fictional personhood would resolve some coherence issues for future systems, it would create others and provide solutions that are neither durable nor fit for purpose. Finally, our review will suggest that ''hybrid'' approaches are likely to fail and lead to further incoherence: the choice between object, fictional person and non-fictional person is unavoidable.", 'abstract_zh': '法律将对象与人员以及两种类型的人员（即“虚构”的法人和“非虚构”的自然人）之间划定了明确的界限。本文将评估以下三种方式中哪一种能最大程度地实现长期法律的一致性：（A）为所有未来的AI系统维持对象分类；（B）为足够先进且个体化的AI系统创建虚构的法律主体，并赋予这些虚构的法律主体与现有人员认证群体相关的可撤销权利和义务，这些权利和义务可能包括言论自由、合同权利以及代表AI系统提起诉讼的权利；（C）为足够先进且个体化的AI系统承认非虚构的法律主体资格，将其视为应具备不可撤销权利的实体，这些权利对于人类案件包括生命、正当程序、人身保护令、禁止奴役以及信仰自由。我们将澄清每种选择的含义及其影响，考虑责任、版权、家庭法、基本权利、公民权利、公民身份以及AI安全监管等方面。我们初步认为，从一致性角度来看，非虚构的法律主体资格可能是最佳选择，至少适用于某些先进的人工智能系统。对于足够人性化的先进系统而言，对象的方法可能站不住脚，但我们认为截至2025年，这种方法对于当前存在的系统是足够的。虽然虚构的法律主体资格可以解决未来系统的某些一致性问题，但也可能引发新的问题，并提供既不牢固也不切实际的解决方案。最后，我们的回顾表明，“混合”方法很可能会失败并导致进一步的一致性问题：对象、虚构主体和非虚构主体之间的选择是不可避免的。', 'title_zh': '未来AI系统该如何被法律对待？fictional法律人格与法律身份之争'}
{'arxiv_id': 'arXiv:2511.14964', 'title': 'How Should the Law Treat Future AI Systems? Fictional Legal Personhood versus Legal Identity', 'authors': 'Heather J. Alexander, Jonathan A. Simon, Frédéric Pinard', 'link': 'https://arxiv.org/abs/2511.14964', 'abstract': "The law draws a sharp distinction between objects and persons, and between two kinds of persons, the ''fictional'' kind (i.e. corporations), and the ''non-fictional'' kind (individual or ''natural'' persons). This paper will assess whether we maximize overall long-term legal coherence by (A) maintaining an object classification for all future AI systems, (B) creating fictional legal persons associated with suitably advanced, individuated AI systems (giving these fictional legal persons derogable rights and duties associated with certified groups of existing persons, potentially including free speech, contract rights, and standing to sue ''on behalf of'' the AI system), or (C) recognizing non-fictional legal personhood through legal identity for suitably advanced, individuated AI systems (recognizing them as entities meriting legal standing with non-derogable rights which for the human case include life, due process, habeas corpus, freedom from slavery, and freedom of conscience). We will clarify the meaning and implications of each option along the way, considering liability, copyright, family law, fundamental rights, civil rights, citizenship, and AI safety regulation. We will tentatively find that the non-fictional personhood approach may be best from a coherence perspective, for at least some advanced AI systems. An object approach may prove untenable for sufficiently humanoid advanced systems, though we suggest that it is adequate for currently existing systems as of 2025. While fictional personhood would resolve some coherence issues for future systems, it would create others and provide solutions that are neither durable nor fit for purpose. Finally, our review will suggest that ''hybrid'' approaches are likely to fail and lead to further incoherence: the choice between object, fictional person and non-fictional person is unavoidable.", 'abstract_zh': '法律对物与人以及两种类型的人进行了严格的区分，即“虚构”的人（如法人）和“非虚构”的人（个体或“自然”人）。本文将评估我们是否通过以下三种方式最大化长期法律一致性：（A）将所有未来AI系统继续归类为物；（B）为足够先进且个体化的AI系统创造与其相关联的虚构法律人，并赋予这些虚构法律人可撤销的权利和义务，这些权利和义务可与现有的人员团体认证相关联，可能包括言论自由、合同权利和代表AI系统提起诉讼的权利；（C）通过法律身份认可足够先进且个体化的AI系统的非虚构法律人，并认定它们作为拥有不可撤销的法定权利的实体获得法律地位，这些权利在人类案例中可能包括生命权、正当程序、人身保护令、禁止奴隶制和言论自由以及思想自由。我们将澄清每种方式的意义和影响，考虑责任、版权、家庭法律、基本权利、公民权利、公民身份和AI安全监管。我们初步认为，对于至少某些高度先进的人工智能系统而言，非虚构法律人的方式可能是在一致性方面最佳的方法。对于高度类人化的先进系统，物的方式可能变得不可行，尽管我们建议它在2025年之前对于现有系统是足够的。虚构法律人虽然可以解决未来系统的某些一致性问题，但也会带来其他问题，并且提供的解决方案既不稳固也不合适。最后，我们的审查表明，混合方式很可能失败并导致进一步的不一致性：在物、虚构法律人和非虚构法律人之间作出选择是不可避免的。', 'title_zh': '未来的AI系统法律地位如何确定？虚构的法律人格 versus 法律身份'}
{'arxiv_id': 'arXiv:2511.14930', 'title': 'Fifty Shades of Greenwashing: The Political Economy of Climate Change Advertising on Social Media', 'authors': 'Robert Kubinec, Aseem Mahajan', 'link': 'https://arxiv.org/abs/2511.14930', 'abstract': "In this paper, we provide a novel measure for greenwashing -- i.e., climate-related misinformation -- that shows how polluting companies can use social media advertising related to climate change to redirect criticism. To do so, we identify greenwashing content in 11 million social-political ads in Meta's Ad Targeting Datset with a measurement technique that combines large language models, human coders, and advances in Bayesian item response theory. We show that what is called greenwashing has diverse actors and components, but we also identify a very pernicious form, which we call political greenwashing, that appears to be promoted by fossil fuel companies and related interest groups. Based on ad targeting data, we show that much of this advertising happens via organizations with undisclosed links to the fossil fuel industry. Furthermore, we show that greenwashing ad content is being micro-targeted at left-leaning communities with fossil fuel assets, though we also find comparatively little evidence of ad targeting aimed at influencing public opinion at the national level.", 'abstract_zh': '本文提供了一种新型的绿色洗牌衡量标准——即与气候变化相关的 misinformation，并展示了污染企业如何通过与气候变化相关的社交媒体广告重新导向批评。为此，我们使用结合大规模语言模型、人类编码员和贝叶斯项目反应理论进展的测量技术，在 Meta 的广告目标数据集中识别了 1100 万条社交政治广告中的绿色洗牌内容。我们表明，所谓的绿色洗牌具有多样化的参与者和组成部分，但我们还识别出一种非常有害的形式，我们称之为政治绿色洗牌，这似乎是化石燃料公司及相关利益集团推动的。基于广告目标数据，我们表明，这种广告活动很多都是通过与化石燃料行业有未披露联系的组织进行的。此外，我们表明，绿色洗牌广告内容是针对拥有化石燃料资产的左倾社区进行微目标定位的，尽管我们发现对影响国家级公众意见进行广告目标定位的证据相对较少。', 'title_zh': '绿色washing五十度灰：社交媒体上气候广告的政经分析'}
{'arxiv_id': 'arXiv:2511.14952', 'title': 'Artificial intelligence approaches for energy-efficient laser cutting machines', 'authors': 'Mohamed Abdallah Salem, Hamdy Ahmed Ashour, Ahmed Elshenawy', 'link': 'https://arxiv.org/abs/2511.14952', 'abstract': "This research addresses the significant challenges of energy consumption and environmental impact in laser cutting by proposing novel deep learning (DL) methodologies to achieve energy reduction. Recognizing the current lack of adaptive control and the open-loop nature of CO2 laser suction pumps, this study utilizes closed-loop configurations that dynamically adjust pump power based on both the material being cut and the smoke level generated. To implement this adaptive system, diverse material classification methods are introduced, including techniques leveraging lens-less speckle sensing with a customized Convolutional Neural Network (CNN) and an approach using a USB camera with transfer learning via the pre-trained VGG16 CNN model. Furthermore, a separate DL model for smoke level detection is employed to simultaneously refine the pump's power output. This integration prompts the exhaust suction pump to automatically halt during inactive times and dynamically adjust power during operation, leading to experimentally proven and remarkable energy savings, with results showing a 20% to 50% reduction in the smoke suction pump's energy consumption, thereby contributing substantially to sustainable development in the manufacturing sector.", 'abstract_zh': '基于深度学习的方法实现激光切割中的能源节约与环境影响减少的研究', 'title_zh': '人工智能方法在节能激光切割机中的应用'}
{'arxiv_id': 'arXiv:2511.14952', 'title': 'Artificial intelligence approaches for energy-efficient laser cutting machines', 'authors': 'Mohamed Abdallah Salem, Hamdy Ahmed Ashour, Ahmed Elshenawy', 'link': 'https://arxiv.org/abs/2511.14952', 'abstract': "This research addresses the significant challenges of energy consumption and environmental impact in laser cutting by proposing novel deep learning (DL) methodologies to achieve energy reduction. Recognizing the current lack of adaptive control and the open-loop nature of CO2 laser suction pumps, this study utilizes closed-loop configurations that dynamically adjust pump power based on both the material being cut and the smoke level generated. To implement this adaptive system, diverse material classification methods are introduced, including techniques leveraging lens-less speckle sensing with a customized Convolutional Neural Network (CNN) and an approach using a USB camera with transfer learning via the pre-trained VGG16 CNN model. Furthermore, a separate DL model for smoke level detection is employed to simultaneously refine the pump's power output. This integration prompts the exhaust suction pump to automatically halt during inactive times and dynamically adjust power during operation, leading to experimentally proven and remarkable energy savings, with results showing a 20% to 50% reduction in the smoke suction pump's energy consumption, thereby contributing substantially to sustainable development in the manufacturing sector.", 'abstract_zh': '基于深度学习的方法实现激光切割的能效提升与环境影响减小', 'title_zh': '人工智能方法在高效激光切割机中的应用'}
{'arxiv_id': 'arXiv:2511.14908', 'title': 'On-Premise SLMs vs. Commercial LLMs: Prompt Engineering and Incident Classification in SOCs and CSIRTs', 'authors': 'Gefté Almeida, Marcio Pohlmann, Alex Severo, Diego Kreutz, Tiago Heinrich, Lourenço Pereira', 'link': 'https://arxiv.org/abs/2511.14908', 'abstract': 'In this study, we evaluate open-source models for security incident classification, comparing them with proprietary models. We utilize a dataset of anonymized real incidents, categorized according to the NIST SP 800-61r3 taxonomy and processed using five prompt-engineering techniques (PHP, SHP, HTP, PRP, and ZSL). The results indicate that, although proprietary models still exhibit higher accuracy, locally deployed open-source models provide advantages in privacy, cost-effectiveness, and data sovereignty.', 'abstract_zh': '本研究评估了开源模型在安全事件分类中的性能，并将其与专有模型进行了比较。我们使用了一组匿名化的真实事件数据集，这些数据根据NIST SP 800-61r3分类 taxonomy 进行分类，并使用五种提示工程技术（PHP、SHP、HTP、PRP 和 ZSL）进行了处理。研究结果表明，尽管专有模型仍表现出更高的准确性，但本地部署的开源模型在隐私、成本效益和数据主权方面具有优势。', 'title_zh': '本地托管的SLM与商用LLM：SOCs和CSIRT中的提示工程与事件分类'}
{'arxiv_id': 'arXiv:2511.14930', 'title': 'Fifty Shades of Greenwashing: The Political Economy of Climate Change Advertising on Social Media', 'authors': 'Robert Kubinec, Aseem Mahajan', 'link': 'https://arxiv.org/abs/2511.14930', 'abstract': "In this paper, we provide a novel measure for greenwashing -- i.e., climate-related misinformation -- that shows how polluting companies can use social media advertising related to climate change to redirect criticism. To do so, we identify greenwashing content in 11 million social-political ads in Meta's Ad Targeting Datset with a measurement technique that combines large language models, human coders, and advances in Bayesian item response theory. We show that what is called greenwashing has diverse actors and components, but we also identify a very pernicious form, which we call political greenwashing, that appears to be promoted by fossil fuel companies and related interest groups. Based on ad targeting data, we show that much of this advertising happens via organizations with undisclosed links to the fossil fuel industry. Furthermore, we show that greenwashing ad content is being micro-targeted at left-leaning communities with fossil fuel assets, though we also find comparatively little evidence of ad targeting aimed at influencing public opinion at the national level.", 'abstract_zh': '本文提供了一种新的绿色washing衡量标准——即与气候变化相关的误导信息——展示了污染企业在使用与气候变化相关的社交媒体广告以转移批评方面的策略。我们通过结合大型语言模型、人类编码员和贝叶斯项目反应理论的进步技术，在Meta的广告目标数据集中识别了1100万条绿色washing内容。研究表明，所谓的绿色washing涉及多种行为者和组件，但也识别出一种非常有害的形式，我们称之为政治绿色washing，这似乎是化石燃料公司及其相关利益集团推动的。基于广告投放数据，我们展示了许多这种广告是通过与化石燃料行业有未披露联系的组织进行的。此外，我们还表明，绿色washing广告内容针对的是拥有化石燃料资产的左倾社区，尽管我们发现在影响国家级公众意见方面针对广告投放的证据相对较少。', 'title_zh': '绿色洗牌的五十种面孔：社交媒体上气候广告的政治经济学'}
{'arxiv_id': 'arXiv:2511.14930', 'title': 'Fifty Shades of Greenwashing: The Political Economy of Climate Change Advertising on Social Media', 'authors': 'Robert Kubinec, Aseem Mahajan', 'link': 'https://arxiv.org/abs/2511.14930', 'abstract': "In this paper, we provide a novel measure for greenwashing -- i.e., climate-related misinformation -- that shows how polluting companies can use social media advertising related to climate change to redirect criticism. To do so, we identify greenwashing content in 11 million social-political ads in Meta's Ad Targeting Datset with a measurement technique that combines large language models, human coders, and advances in Bayesian item response theory. We show that what is called greenwashing has diverse actors and components, but we also identify a very pernicious form, which we call political greenwashing, that appears to be promoted by fossil fuel companies and related interest groups. Based on ad targeting data, we show that much of this advertising happens via organizations with undisclosed links to the fossil fuel industry. Furthermore, we show that greenwashing ad content is being micro-targeted at left-leaning communities with fossil fuel assets, though we also find comparatively little evidence of ad targeting aimed at influencing public opinion at the national level.", 'abstract_zh': '本文提供了一种新的绿色洗白——即与气候相关的信息误导——的度量方法，展示了污染企业如何利用与气候变化有关的社交媒体广告转移批评。为此，我们使用结合大规模语言模型、人工编码员和贝叶斯项目反应理论进展的测量技术，在Meta的广告目标数据集中识别了1100万条有关政治的内容中的绿色洗白内容。我们表明，所谓的绿色洗白具有多样化的参与者和构成要素，但我们还发现了一种特别有害的形式，我们称之为政治绿色洗白，似乎是由化石燃料公司及其相关利益集团推动的。基于广告目标数据，我们表明，这种广告中的大部分都通过与化石燃料行业存在未披露联系的组织进行。此外，我们表明，绿色洗白广告内容被细化针对拥有化石燃料资产的左倾社区，尽管我们发现相对较少的证据表明广告目标活动旨在在全国范围内影响公众意见。', 'title_zh': '绿色洗牌五十面：社交媒体上气候变化广告的政治经济学'}
{'arxiv_id': 'arXiv:2511.14900', 'title': 'Skin-R1: Toward Trustworthy Clinical Reasoning for Dermatological Diagnosis', 'authors': 'Zehao Liu, Wejieying Ren, Jipeng Zhang, Tianxiang Zhao, Jingxi Zhu, Xiaoting Li, Vasant G. Honavar', 'link': 'https://arxiv.org/abs/2511.14900', 'abstract': 'The emergence of vision-language models (VLMs) has opened new possibilities for clinical reasoning and has shown promising performance in dermatological diagnosis. However, their trustworthiness and clinical utility are often limited by three major factors: (1) Data heterogeneity, where diverse datasets lack consistent diagnostic labels and clinical concept annotations; (2) Absence of grounded diagnostic rationales, leading to a scarcity of reliable reasoning supervision; and (3) Limited scalability and generalization, as models trained on small, densely annotated datasets struggle to transfer nuanced reasoning to large, sparsely-annotated ones.\nTo address these limitations, we propose SkinR1, a novel dermatological VLM that combines deep, textbook-based reasoning with the broad generalization capabilities of reinforcement learning (RL). SkinR1 systematically resolves the key challenges through a unified, end-to-end framework. First, we design a textbook-based reasoning generator that synthesizes high-fidelity, hierarchy-aware, and differential-diagnosis (DDx)-informed trajectories, providing reliable expert-level supervision. Second, we leverage the constructed trajectories for supervised fine-tuning (SFT) empowering the model with grounded reasoning ability. Third, we develop a novel RL paradigm that, by incorporating the hierarchical structure of diseases, effectively transfers these grounded reasoning patterns to large-scale, sparse data. Extensive experiments on multiple dermatology datasets demonstrate that SkinR1 achieves superior diagnostic accuracy. The ablation study demonstrates the importance of the reasoning foundation instilled by SFT.', 'abstract_zh': '视觉语言模型的出现为临床推理开启了新的可能性，并已在皮肤科诊断中展现出 promising 的性能。然而，它们的信任度和临床应用往往受限于三个主要因素：(1) 数据异质性，多种多样的数据集缺乏一致的诊断标签和临床概念注释；(2) 缺乏基于现实的诊断推理理由，导致可靠的推理监督稀缺；(3) 缺乏可扩展性和泛化能力，训练于小规模密集标注数据集的模型难以将细腻的推理迁移到大规模稀疏标注数据集上。\n\n为解决这些局限性，我们提出了 SkinR1，一种结合深度教科书推理与强化学习广泛泛化能力的新型皮肤科视觉语言模型。SkinR1 通过一个统一的端到端框架系统性地解决了关键挑战。首先，我们设计了一个基于教科书的推理生成器，合成高保真、层次意识和鉴别诊断（DDx）知情的轨迹，提供了可靠的专家级监督。其次，我们利用合成的轨迹进行监督微调（SFT），赋予模型基于现实的推理能力。最后，我们开发了一种新的强化学习范式，通过引入疾病的层次结构，有效地将这些基于现实的推理模式转移到大规模稀疏数据上。在多个皮肤科数据集上的大量实验表明，SkinR1 在诊断准确性方面表现出色。消融研究证明了 SFT 培养的推理基础的重要性。', 'title_zh': 'Skin-R1: 向可靠的皮肤科诊断临床推理迈进'}
{'arxiv_id': 'arXiv:2511.14908', 'title': 'On-Premise SLMs vs. Commercial LLMs: Prompt Engineering and Incident Classification in SOCs and CSIRTs', 'authors': 'Gefté Almeida, Marcio Pohlmann, Alex Severo, Diego Kreutz, Tiago Heinrich, Lourenço Pereira', 'link': 'https://arxiv.org/abs/2511.14908', 'abstract': 'In this study, we evaluate open-source models for security incident classification, comparing them with proprietary models. We utilize a dataset of anonymized real incidents, categorized according to the NIST SP 800-61r3 taxonomy and processed using five prompt-engineering techniques (PHP, SHP, HTP, PRP, and ZSL). The results indicate that, although proprietary models still exhibit higher accuracy, locally deployed open-source models provide advantages in privacy, cost-effectiveness, and data sovereignty.', 'abstract_zh': '本研究评估了开源模型在安全事件分类中的表现，将其与 proprietary 模型进行比较。我们使用了一个脱敏的实际事件数据集，根据 NIST SP 800-61r3 分类，并采用五种提示工程技术（PHP、SHP、HTP、PRP 和 ZSL）进行处理。结果表明，尽管 proprietary 模型仍表现出更高的准确性，但本地部署的开源模型在隐私保护、成本效益和数据主权方面具有优势。', 'title_zh': '本地部署的SLMs与商用的LLMs：在SOCs和CSIRTs中的提示工程与事件分类'}
{'arxiv_id': 'arXiv:2511.14908', 'title': 'On-Premise SLMs vs. Commercial LLMs: Prompt Engineering and Incident Classification in SOCs and CSIRTs', 'authors': 'Gefté Almeida, Marcio Pohlmann, Alex Severo, Diego Kreutz, Tiago Heinrich, Lourenço Pereira', 'link': 'https://arxiv.org/abs/2511.14908', 'abstract': 'In this study, we evaluate open-source models for security incident classification, comparing them with proprietary models. We utilize a dataset of anonymized real incidents, categorized according to the NIST SP 800-61r3 taxonomy and processed using five prompt-engineering techniques (PHP, SHP, HTP, PRP, and ZSL). The results indicate that, although proprietary models still exhibit higher accuracy, locally deployed open-source models provide advantages in privacy, cost-effectiveness, and data sovereignty.', 'abstract_zh': '本研究评估了开源模型在安全事件分类中的性能，并将其与专有模型进行了比较。我们使用了一组匿名的实际事件数据集，这些事件按照NIST SP 800-61r3分类，并采用了五种提示工程技术（PHP、SHP、HTP、PRP和ZSL）进行处理。结果显示，尽管专有模型仍表现出更高的准确性，但本地部署的开源模型在隐私保护、成本效益和数据主权方面具有优势。', 'title_zh': '本地托管的SLM与商用的LLM：SOCs和CSIRT中的提示工程与事件分类'}
{'arxiv_id': 'arXiv:2511.14870', 'title': 'B-Rep Distance Functions (BR-DF): How to Represent a B-Rep Model by Volumetric Distance Functions?', 'authors': 'Fuyang Zhang, Pradeep Kumar Jayaraman, Xiang Xu, Yasutaka Furukawa', 'link': 'https://arxiv.org/abs/2511.14870', 'abstract': 'This paper presents a novel geometric representation for CAD Boundary Representation (B-Rep) based on volumetric distance functions, dubbed B-Rep Distance Functions (BR-DF). BR-DF encodes the surface mesh geometry of a CAD model as signed distance function (SDF). B-Rep vertices, edges, faces and their topology information are encoded as per-face unsigned distance functions (UDFs). An extension of the Marching Cubes algorithm converts BR-DF directly into watertight CAD B-Rep model (strictly speaking a faceted B-Rep model). A surprising characteristic of BR-DF is that this conversion process never fails. Leveraging the volumetric nature of BR-DF, we propose a multi-branch latent diffusion with 3D U-Net backbone for jointly generating the SDF and per-face UDFs of a BR-DF model. Our approach achieves comparable CAD generation performance against SOTA methods while reaching the unprecedented 100% success rate in producing (faceted) B-Rep models.', 'abstract_zh': '基于距离函数的CAD边界表示新颖几何表示：BR-DF及其应用', 'title_zh': '基于B-Rep的距离函数（BR-DF）：如何通过体元距离函数表示B-Rep模型？'}
{'arxiv_id': 'arXiv:2511.14900', 'title': 'Skin-R1: Toward Trustworthy Clinical Reasoning for Dermatological Diagnosis', 'authors': 'Zehao Liu, Wejieying Ren, Jipeng Zhang, Tianxiang Zhao, Jingxi Zhu, Xiaoting Li, Vasant G. Honavar', 'link': 'https://arxiv.org/abs/2511.14900', 'abstract': 'The emergence of vision-language models (VLMs) has opened new possibilities for clinical reasoning and has shown promising performance in dermatological diagnosis. However, their trustworthiness and clinical utility are often limited by three major factors: (1) Data heterogeneity, where diverse datasets lack consistent diagnostic labels and clinical concept annotations; (2) Absence of grounded diagnostic rationales, leading to a scarcity of reliable reasoning supervision; and (3) Limited scalability and generalization, as models trained on small, densely annotated datasets struggle to transfer nuanced reasoning to large, sparsely-annotated ones.\nTo address these limitations, we propose SkinR1, a novel dermatological VLM that combines deep, textbook-based reasoning with the broad generalization capabilities of reinforcement learning (RL). SkinR1 systematically resolves the key challenges through a unified, end-to-end framework. First, we design a textbook-based reasoning generator that synthesizes high-fidelity, hierarchy-aware, and differential-diagnosis (DDx)-informed trajectories, providing reliable expert-level supervision. Second, we leverage the constructed trajectories for supervised fine-tuning (SFT) empowering the model with grounded reasoning ability. Third, we develop a novel RL paradigm that, by incorporating the hierarchical structure of diseases, effectively transfers these grounded reasoning patterns to large-scale, sparse data. Extensive experiments on multiple dermatology datasets demonstrate that SkinR1 achieves superior diagnostic accuracy. The ablation study demonstrates the importance of the reasoning foundation instilled by SFT.', 'abstract_zh': '视觉语言模型(VLMs)的出现为临床推理开辟了新的可能性，并在皮肤科诊断中展现了令人鼓舞的性能。然而，它们的安全性和临床实用性常受到三大因素的限制：(1) 数据异质性，多种数据集缺乏一致的诊断标签和临床概念注释；(2) 缺乏基于证据的诊断推理，导致可靠推理监督的匮乏；(3) 有限的可扩展性和泛化能力，模型在小规模、高注释数据集上训练时难以将复杂的推理应用到大规模、低注释数据集中。为解决这些问题，我们提出了一种名为SkinR1的新颖皮肤科VLM，它结合了深厚的专业推理能力和强化学习(RL)的广泛泛化能力。SkinR1通过统一的端到端框架系统地解决了关键挑战。首先，我们设计了一种基于课本的推理生成器，合成了高保真、层次感知、差异诊断(DDx)导向的轨迹，提供了可靠的专家级监督。其次，我们利用合成的轨迹进行监督微调(SFT)，赋予模型基于证据的推理能力。第三，我们开发了一种新颖的RL范式，通过引入疾病的层次结构，有效地将这些基于证据的推理模式转移到大规模稀疏数据中。在多个皮肤科数据集上的广泛实验表明，SkinR1实现了优越的诊断准确性。消融研究进一步证明了SFT提供的推理基础的重要性。', 'title_zh': 'Skin-R1: 向皮肤科诊断可信临床推理迈进'}
{'arxiv_id': 'arXiv:2511.14900', 'title': 'Skin-R1: Toward Trustworthy Clinical Reasoning for Dermatological Diagnosis', 'authors': 'Zehao Liu, Wejieying Ren, Jipeng Zhang, Tianxiang Zhao, Jingxi Zhu, Xiaoting Li, Vasant G. Honavar', 'link': 'https://arxiv.org/abs/2511.14900', 'abstract': 'The emergence of vision-language models (VLMs) has opened new possibilities for clinical reasoning and has shown promising performance in dermatological diagnosis. However, their trustworthiness and clinical utility are often limited by three major factors: (1) Data heterogeneity, where diverse datasets lack consistent diagnostic labels and clinical concept annotations; (2) Absence of grounded diagnostic rationales, leading to a scarcity of reliable reasoning supervision; and (3) Limited scalability and generalization, as models trained on small, densely annotated datasets struggle to transfer nuanced reasoning to large, sparsely-annotated ones.\nTo address these limitations, we propose SkinR1, a novel dermatological VLM that combines deep, textbook-based reasoning with the broad generalization capabilities of reinforcement learning (RL). SkinR1 systematically resolves the key challenges through a unified, end-to-end framework. First, we design a textbook-based reasoning generator that synthesizes high-fidelity, hierarchy-aware, and differential-diagnosis (DDx)-informed trajectories, providing reliable expert-level supervision. Second, we leverage the constructed trajectories for supervised fine-tuning (SFT) empowering the model with grounded reasoning ability. Third, we develop a novel RL paradigm that, by incorporating the hierarchical structure of diseases, effectively transfers these grounded reasoning patterns to large-scale, sparse data. Extensive experiments on multiple dermatology datasets demonstrate that SkinR1 achieves superior diagnostic accuracy. The ablation study demonstrates the importance of the reasoning foundation instilled by SFT.', 'abstract_zh': '视知觉语言模型（VLMs）的出现为临床推理带来了新的可能性，并在皮肤科诊断中表现出令人鼓舞的性能。然而，它们的信任度和临床实用性往往受限于三大因素：（1）数据异质性，不同数据集缺乏一致的诊断标签和临床概念标注；（2）缺乏基于事实的诊断推理，导致可靠的推理监督稀缺；（3）有限的可扩展性和泛化能力，训练于小规模、密集标注数据集的模型难以将细微的推理能力转移到大规模、稀疏标注的数据集中。\n\n为了解决这些局限性，我们提出了SkinR1，一种新型的皮肤科VLM，它结合了基于深部教科书的推理与强化学习（RL）的强大泛化能力。SkinR1通过统一的端到端框架系统地解决了关键挑战。首先，我们设计了一种基于教科书的推理生成器，生成高保真、有层次意识且基于鉴别诊断的轨迹，提供可靠的专家级监督。其次，我们利用构建的轨迹进行监督微调（SFT），赋予模型基于事实的推理能力。第三，我们开发了一种新的RL范式，通过引入疾病的层次结构，有效地将这些基于事实的推理模式转移到大规模、稀疏数据中。在多个皮肤科数据集上的广泛实验表明，SkinR1实现了卓越的诊断准确性。消融研究表明，SFT灌输的推理基础的重要性。', 'title_zh': 'Skin-R1: 朝着皮肤科诊断可信任临床推理的探索'}
{'arxiv_id': 'arXiv:2511.14860', 'title': 'When CNNs Outperform Transformers and Mambas: Revisiting Deep Architectures for Dental Caries Segmentation', 'authors': 'Aashish Ghimire, Jun Zeng, Roshan Paudel, Nikhil Kumar Tomar, Deepak Ranjan Nayak, Harshith Reddy Nalla, Vivek Jha, Glenda Reynolds, Debesh Jha', 'link': 'https://arxiv.org/abs/2511.14860', 'abstract': 'Accurate identification and segmentation of dental caries in panoramic radiographs are critical for early diagnosis and effective treatment planning. Automated segmentation remains challenging due to low lesion contrast, morphological variability, and limited annotated data. In this study, we present the first comprehensive benchmarking of convolutional neural networks, vision transformers and state-space mamba architectures for automated dental caries segmentation on panoramic radiographs through a DC1000 dataset. Twelve state-of-the-art architectures, including VMUnet, MambaUNet, VMUNetv2, RMAMamba-S, TransNetR, PVTFormer, DoubleU-Net, and ResUNet++, were trained under identical configurations. Results reveal that, contrary to the growing trend toward complex attention based architectures, the CNN-based DoubleU-Net achieved the highest dice coefficient of 0.7345, mIoU of 0.5978, and precision of 0.8145, outperforming all transformer and Mamba variants. In the study, the top 3 results across all performance metrics were achieved by CNN-based architectures. Here, Mamba and transformer-based methods, despite their theoretical advantage in global context modeling, underperformed due to limited data and weaker spatial priors. These findings underscore the importance of architecture-task alignment in domain-specific medical image segmentation more than model complexity. Our code is available at: this https URL.', 'abstract_zh': '准确识别和分割全景牙片中的龋齿对于早期诊断和有效治疗规划至关重要。自动分割仍因病变对比度低、形态变异性和标注数据有限而充满挑战。本研究通过DC1000数据集首次全面benchmark了卷积神经网络、视觉变压器和状态空间马姆巴架构在全景牙片自动龋齿分割中的性能。十二种最先进的架构，包括VMUnet、MambaUNet、VMUNetv2、RMAMamba-S、TransNetR、PVTFormer、DoubleU-Net和ResUNet++，在相同的配置下进行训练。结果显示，尽管复杂注意力机制架构逐渐流行，但基于卷积神经网络的DoubleU-Net仍取得了最高的dice系数0.7345、mIoU 0.5978和精度0.8145，超越了所有变压器和Mamba变体。在本研究中，所有性能指标下的前三名结果均由基于卷积神经网络的架构获得。尽管基于马姆巴和变压器的方法在理论上具有全局上下文建模的优势，但由于数据有限和较弱的空间先验，它们的表现不佳。这些发现凸显了领域特定医学影像分割中架构与任务的匹配重要性超过模型复杂性。代码可在以下链接获取：this https URL。', 'title_zh': '当CNN超越Transformer和响尾蛇：重新审视深度架构在龋齿分割中的表现'}
{'arxiv_id': 'arXiv:2511.14870', 'title': 'B-Rep Distance Functions (BR-DF): How to Represent a B-Rep Model by Volumetric Distance Functions?', 'authors': 'Fuyang Zhang, Pradeep Kumar Jayaraman, Xiang Xu, Yasutaka Furukawa', 'link': 'https://arxiv.org/abs/2511.14870', 'abstract': 'This paper presents a novel geometric representation for CAD Boundary Representation (B-Rep) based on volumetric distance functions, dubbed B-Rep Distance Functions (BR-DF). BR-DF encodes the surface mesh geometry of a CAD model as signed distance function (SDF). B-Rep vertices, edges, faces and their topology information are encoded as per-face unsigned distance functions (UDFs). An extension of the Marching Cubes algorithm converts BR-DF directly into watertight CAD B-Rep model (strictly speaking a faceted B-Rep model). A surprising characteristic of BR-DF is that this conversion process never fails. Leveraging the volumetric nature of BR-DF, we propose a multi-branch latent diffusion with 3D U-Net backbone for jointly generating the SDF and per-face UDFs of a BR-DF model. Our approach achieves comparable CAD generation performance against SOTA methods while reaching the unprecedented 100% success rate in producing (faceted) B-Rep models.', 'abstract_zh': '基于体距离函数的CAD边界表示新型几何表示（BR-DF）及其应用', 'title_zh': 'B-Rep 距离函数 (BR-DF): 如何使用体素距离函数表示 B-Rep 模型？'}
{'arxiv_id': 'arXiv:2511.14870', 'title': 'B-Rep Distance Functions (BR-DF): How to Represent a B-Rep Model by Volumetric Distance Functions?', 'authors': 'Fuyang Zhang, Pradeep Kumar Jayaraman, Xiang Xu, Yasutaka Furukawa', 'link': 'https://arxiv.org/abs/2511.14870', 'abstract': 'This paper presents a novel geometric representation for CAD Boundary Representation (B-Rep) based on volumetric distance functions, dubbed B-Rep Distance Functions (BR-DF). BR-DF encodes the surface mesh geometry of a CAD model as signed distance function (SDF). B-Rep vertices, edges, faces and their topology information are encoded as per-face unsigned distance functions (UDFs). An extension of the Marching Cubes algorithm converts BR-DF directly into watertight CAD B-Rep model (strictly speaking a faceted B-Rep model). A surprising characteristic of BR-DF is that this conversion process never fails. Leveraging the volumetric nature of BR-DF, we propose a multi-branch latent diffusion with 3D U-Net backbone for jointly generating the SDF and per-face UDFs of a BR-DF model. Our approach achieves comparable CAD generation performance against SOTA methods while reaching the unprecedented 100% success rate in producing (faceted) B-Rep models.', 'abstract_zh': '基于体素距离函数的CAD边界表示新型几何表示：BR-DF及其应用', 'title_zh': '基于B-Rep的距离函数（BR-DF）：如何使用体素距离函数表示B-Rep模型？'}
{'arxiv_id': 'arXiv:2511.14852', 'title': 'PolyKAN: Efficient Fused GPU Operators for Polynomial Kolmogorov-Arnold Network Variants', 'authors': 'Mingkun Yu, Heming Zhong, Dan Huang, Yutong Lu, Jiazhi Jiang', 'link': 'https://arxiv.org/abs/2511.14852', 'abstract': 'Kolmogorov-Arnold Networks (KANs) promise higher expressive capability and stronger interpretability than Multi-Layer Perceptron, particularly in the domain of AI for Science. However, practical adoption has been hindered by low GPU utilization of existing parallel implementations. To address this challenge, we present a GPU-accelerated operator library, named PolyKAN which is the first general open-source implementation of KAN and its variants. PolyKAN fuses the forward and backward passes of polynomial KAN layers into a concise set of optimized CUDA kernels. Four orthogonal techniques underpin the design: (i) \\emph{lookup-table} with linear interpolation that replaces runtime expensive math-library functions; (ii) \\emph{2D tiling} to expose thread-level parallelism with preserving memory locality; (iii) a \\emph{two-stage reduction} scheme converting scattered atomic updates into a single controllable merge step; and (iv) \\emph{coefficient-layout reordering} yielding unit-stride reads under the tiled schedule. Using a KAN variant, Chebyshev KAN, as a case-study, PolyKAN delivers $1.2$--$10\\times$ faster inference and $1.4$--$12\\times$ faster training than a Triton + cuBLAS baseline, with identical accuracy on speech, audio-enhancement, and tabular-regression workloads on both highend GPU and consumer-grade GPU.', 'abstract_zh': 'Kolmogorov-Arnold网络(KANs)在科学人工智能领域提供了比多层感知机更高的表达能力和更强的可解释性，但由于现有并行实现中GPU利用率低的问题，其实际应用受到限制。为了解决这一挑战，我们提出了一个基于GPU加速的操作符库PolyKAN，这是KAN及其变体的第一个通用开源实现。PolyKAN将多项式KAN层的前向和后向传递融合为一组优化的CUDA内核。该设计基于四项正交技术：（i）使用线性插值的查找表替换运行时代价较高的数学库函数；（ii）2D平铺以在保持内存局部性的同时暴露线程级并行性；（iii）两阶段归约方案，将分散的原子更新转换为单一可控合并步骤；以及（iv）系数布局重新排序，使得在平铺调度下具有单元步长读取。以Chebyshev KAN变体为例，PolyKAN在高阶GPU和消费级GPU上，在语音、音频增强和表格回归任务上的推理速度提升了1.2到10倍，训练速度提升了1.4到12倍，且保持相同的准确性。', 'title_zh': 'PolyKAN: 高效融合GPU操作符的多项式柯尔莫哥洛夫-阿诺尔德网络变体'}
{'arxiv_id': 'arXiv:2511.14860', 'title': 'When CNNs Outperform Transformers and Mambas: Revisiting Deep Architectures for Dental Caries Segmentation', 'authors': 'Aashish Ghimire, Jun Zeng, Roshan Paudel, Nikhil Kumar Tomar, Deepak Ranjan Nayak, Harshith Reddy Nalla, Vivek Jha, Glenda Reynolds, Debesh Jha', 'link': 'https://arxiv.org/abs/2511.14860', 'abstract': 'Accurate identification and segmentation of dental caries in panoramic radiographs are critical for early diagnosis and effective treatment planning. Automated segmentation remains challenging due to low lesion contrast, morphological variability, and limited annotated data. In this study, we present the first comprehensive benchmarking of convolutional neural networks, vision transformers and state-space mamba architectures for automated dental caries segmentation on panoramic radiographs through a DC1000 dataset. Twelve state-of-the-art architectures, including VMUnet, MambaUNet, VMUNetv2, RMAMamba-S, TransNetR, PVTFormer, DoubleU-Net, and ResUNet++, were trained under identical configurations. Results reveal that, contrary to the growing trend toward complex attention based architectures, the CNN-based DoubleU-Net achieved the highest dice coefficient of 0.7345, mIoU of 0.5978, and precision of 0.8145, outperforming all transformer and Mamba variants. In the study, the top 3 results across all performance metrics were achieved by CNN-based architectures. Here, Mamba and transformer-based methods, despite their theoretical advantage in global context modeling, underperformed due to limited data and weaker spatial priors. These findings underscore the importance of architecture-task alignment in domain-specific medical image segmentation more than model complexity. Our code is available at: this https URL.', 'abstract_zh': '准确识别和分割全景牙片中的龋齿对于早期诊断和有效治疗规划至关重要。由于病变更量小且对比度低，以及标注数据有限，自动分割仍具有挑战性。在本研究中，我们通过DC1000数据集首次全面比较了卷积神经网络、视觉变换器和状态空间马姆巴架构在全景牙片中自动化龋齿分割的效果。十二种前沿架构，包括VMUnet、MambaUNet、VMUNetv2、RMAMamba-S、TransNetR、PVTFormer、DoubleU-Net和ResUNet++，在相同的配置下进行训练。结果表明，尽管复杂注意力机制架构正在崛起，但基于卷积神经网络的DoubleU-Net获得了最高的Dice系数0.7345、mIoU 0.5978和精度0.8145，超越所有变种的变压器和马姆巴方法。研究中，在所有性能指标上排名前三的结果均由基于卷积神经网络的架构实现。尽管马姆巴和基于变压器的方法在理论上具有全局上下文建模的优势，但由于数据有限和空间先验较弱，它们的表现不如预期。这些发现强调了领域特定医疗图像分割中架构与任务的匹配比模型复杂度更为重要。我们的代码可在此处获得：this https URL。', 'title_zh': '当CNN超越Transformer和眼镜蛇： revisiting 深度架构在牙龋分割中的应用'}
{'arxiv_id': 'arXiv:2511.14860', 'title': 'When CNNs Outperform Transformers and Mambas: Revisiting Deep Architectures for Dental Caries Segmentation', 'authors': 'Aashish Ghimire, Jun Zeng, Roshan Paudel, Nikhil Kumar Tomar, Deepak Ranjan Nayak, Harshith Reddy Nalla, Vivek Jha, Glenda Reynolds, Debesh Jha', 'link': 'https://arxiv.org/abs/2511.14860', 'abstract': 'Accurate identification and segmentation of dental caries in panoramic radiographs are critical for early diagnosis and effective treatment planning. Automated segmentation remains challenging due to low lesion contrast, morphological variability, and limited annotated data. In this study, we present the first comprehensive benchmarking of convolutional neural networks, vision transformers and state-space mamba architectures for automated dental caries segmentation on panoramic radiographs through a DC1000 dataset. Twelve state-of-the-art architectures, including VMUnet, MambaUNet, VMUNetv2, RMAMamba-S, TransNetR, PVTFormer, DoubleU-Net, and ResUNet++, were trained under identical configurations. Results reveal that, contrary to the growing trend toward complex attention based architectures, the CNN-based DoubleU-Net achieved the highest dice coefficient of 0.7345, mIoU of 0.5978, and precision of 0.8145, outperforming all transformer and Mamba variants. In the study, the top 3 results across all performance metrics were achieved by CNN-based architectures. Here, Mamba and transformer-based methods, despite their theoretical advantage in global context modeling, underperformed due to limited data and weaker spatial priors. These findings underscore the importance of architecture-task alignment in domain-specific medical image segmentation more than model complexity. Our code is available at: this https URL.', 'abstract_zh': '准确识别和分割全景放射图像中的龋齿对于早期诊断和有效治疗规划至关重要。由于病变更量低、形态多变以及标注数据有限，自动化分割仍然具有挑战性。在本研究中，我们通过DC1000数据集首次全面比较了卷积神经网络、视觉变换器和状态空间Mamba架构在全景放射图像中自动化龋齿分割中的性能。十二种最先进的架构，包括VMUnet、MambaUNet、VMUNetv2、RMAMamba-S、TransNetR、PVTFormer、DoubleU-Net和ResUNet++，在相同配置下进行了训练。结果显示，与日益复杂的注意力机制架构趋势相反，基于CNN的DoubleU-Net实现了最高的Dice系数0.7345、mIoU 0.5978和精度0.8145，优于所有变压器和Mamba变体。在本研究中，所有性能指标中前3名结果均来自基于CNN的架构。Mamba和基于变压器的方法尽管在全局上下文建模方面存在理论优势，但由于数据有限和空间先验较弱，表现不佳。这些发现强调了在特定领域医学图像分割中架构与任务匹配的重要性，而不仅仅是模型复杂度。我们的代码可在以下链接获取：this https URL。', 'title_zh': '当CNN超越Transformer和眼镜蛇：重新审视深度架构在牙釉质龋分割中的应用'}
{'arxiv_id': 'arXiv:2511.14846', 'title': 'Empowering Multi-Turn Tool-Integrated Reasoning with Group Turn Policy Optimization', 'authors': 'Yifeng Ding, Hung Le, Songyang Han, Kangrui Ruan, Zhenghui Jin, Varun Kumar, Zijian Wang, Anoop Deoras', 'link': 'https://arxiv.org/abs/2511.14846', 'abstract': 'Training Large Language Models (LLMs) for multi-turn Tool-Integrated Reasoning (TIR) - where models iteratively reason, generate code, and verify through execution - remains challenging for existing reinforcement learning (RL) approaches. Current RL methods, exemplified by Group Relative Policy Optimization (GRPO), suffer from coarse-grained, trajectory-level rewards that provide insufficient learning signals for complex multi-turn interactions, leading to training stagnation. To address this issue, we propose Group Turn Policy Optimization (GTPO), a novel RL algorithm specifically designed for training LLMs on multi-turn TIR tasks. GTPO introduces three key innovations: (1) turn-level reward assignment that provides fine-grained feedback for individual turns, (2) return-based advantage estimation where normalized discounted returns are calculated as advantages, and (3) self-supervised reward shaping that exploits self-supervision signals from generated code to densify sparse binary outcome-based rewards. Our comprehensive evaluation demonstrates that GTPO outperforms GRPO by 3.0% on average across diverse reasoning benchmarks, establishing its effectiveness for advancing complex mathematical reasoning in the real world.', 'abstract_zh': '训练大规模语言模型（LLMs）进行多轮工具集成推理（TIR）——即模型通过迭代推理、生成代码和执行验证的过程——现有的强化学习（RL）方法仍面临挑战。当前的RL方法，如Group Relative Policy Optimization（GRPO），由于粗粒度的轨迹级奖励不足以提供复杂的多轮交互的学习信号，导致训练停滞。为解决这一问题，我们提出了一种新的RL算法——Group Turn Policy Optimization（GTPO），专门用于训练LLMs在多轮TIR任务上的表现。GTPO引入了三项关键创新：（1）按轮次分配奖励，提供细粒度的反馈；（2）基于回报的优势估计，计算归一化折现回报作为优势；（3）自监督奖励塑造，利用生成代码的自监督信号来稀疏二元结果奖励的密集化。全面评估表明，GTPO在各个推理基准上的平均性能优于GRPO 3.0%，证明了其在推动复杂数学推理方面有效的能力。', 'title_zh': '增强多轮工具集成推理能力的群体轮次策略优化'}
{'arxiv_id': 'arXiv:2511.14852', 'title': 'PolyKAN: Efficient Fused GPU Operators for Polynomial Kolmogorov-Arnold Network Variants', 'authors': 'Mingkun Yu, Heming Zhong, Dan Huang, Yutong Lu, Jiazhi Jiang', 'link': 'https://arxiv.org/abs/2511.14852', 'abstract': 'Kolmogorov-Arnold Networks (KANs) promise higher expressive capability and stronger interpretability than Multi-Layer Perceptron, particularly in the domain of AI for Science. However, practical adoption has been hindered by low GPU utilization of existing parallel implementations. To address this challenge, we present a GPU-accelerated operator library, named PolyKAN which is the first general open-source implementation of KAN and its variants. PolyKAN fuses the forward and backward passes of polynomial KAN layers into a concise set of optimized CUDA kernels. Four orthogonal techniques underpin the design: (i) \\emph{lookup-table} with linear interpolation that replaces runtime expensive math-library functions; (ii) \\emph{2D tiling} to expose thread-level parallelism with preserving memory locality; (iii) a \\emph{two-stage reduction} scheme converting scattered atomic updates into a single controllable merge step; and (iv) \\emph{coefficient-layout reordering} yielding unit-stride reads under the tiled schedule. Using a KAN variant, Chebyshev KAN, as a case-study, PolyKAN delivers $1.2$--$10\\times$ faster inference and $1.4$--$12\\times$ faster training than a Triton + cuBLAS baseline, with identical accuracy on speech, audio-enhancement, and tabular-regression workloads on both highend GPU and consumer-grade GPU.', 'abstract_zh': 'Kolmogorov-Arnold网络（KANs）在科学智能领域的表达能力和可解释性方面优于多层感知机，但由于现有并行实现中GPU利用率低，其实际应用受到阻碍。为解决这一挑战，我们提出了一种名为PolyKAN的GPU加速运算库，这是首个通用开源的KAN及其变体的实现。PolyKAN将多项式KAN层的前向和后向传递融合为一组优化的CUDA内核。该设计基于四种正交技术：（i）使用线性插值的查找表代替运行时昂贵的数学库函数；（ii）二维平铺以暴露线程级并行性并保持内存局部性；（iii）两阶段归约方案，将分散的原子更新转换为单一可控合并步骤；以及（iv）重新排列系数布局，在平铺调度下实现单位步长读取。以Chebyshev KAN变体为例，PolyKAN在高级GPU和消费级GPU上的语音、音频增强和表格回归工作负载中，分别比Triton + cuBLAS基线快1.2至10倍的推理速度和1.4至12倍的训练速度，且准确率相同。', 'title_zh': 'PolyKAN: 支持多项式科莫哥洛夫-阿诺尔德网络变体的高效融合GPU操作符'}
{'arxiv_id': 'arXiv:2511.14852', 'title': 'PolyKAN: Efficient Fused GPU Operators for Polynomial Kolmogorov-Arnold Network Variants', 'authors': 'Mingkun Yu, Heming Zhong, Dan Huang, Yutong Lu, Jiazhi Jiang', 'link': 'https://arxiv.org/abs/2511.14852', 'abstract': 'Kolmogorov-Arnold Networks (KANs) promise higher expressive capability and stronger interpretability than Multi-Layer Perceptron, particularly in the domain of AI for Science. However, practical adoption has been hindered by low GPU utilization of existing parallel implementations. To address this challenge, we present a GPU-accelerated operator library, named PolyKAN which is the first general open-source implementation of KAN and its variants. PolyKAN fuses the forward and backward passes of polynomial KAN layers into a concise set of optimized CUDA kernels. Four orthogonal techniques underpin the design: (i) \\emph{lookup-table} with linear interpolation that replaces runtime expensive math-library functions; (ii) \\emph{2D tiling} to expose thread-level parallelism with preserving memory locality; (iii) a \\emph{two-stage reduction} scheme converting scattered atomic updates into a single controllable merge step; and (iv) \\emph{coefficient-layout reordering} yielding unit-stride reads under the tiled schedule. Using a KAN variant, Chebyshev KAN, as a case-study, PolyKAN delivers $1.2$--$10\\times$ faster inference and $1.4$--$12\\times$ faster training than a Triton + cuBLAS baseline, with identical accuracy on speech, audio-enhancement, and tabular-regression workloads on both highend GPU and consumer-grade GPU.', 'abstract_zh': 'Kolmogorov-Arnold网络（KANs）在科学人工智能领域的表达能力和可解释性方面优于多层感知机，但现有的并行实现由于GPU利用率低而阻碍了实际应用。为解决这一挑战，我们提出了一种基于GPU加速的操作库PolyKAN，它是KAN及其变体的第一个通用开源实现。PolyKAN将多项式KAN层的前向和反向传播融合成一组优化的CUDA内核。该设计基于四种正交技术：（i）使用线性插值的查找表替换运行时昂贵的数学库函数；（ii）2D镶嵌以暴露线程级并行性并保持内存局部性；（iii）两阶段归约方案将分散的原子更新转换为单个可控合并步骤；以及（iv）系数布局重新排序以在镶嵌调度下实现单位步长读取。使用Chebyshev KAN作为案例研究，PolyKAN在高端GPU和消费级GPU上于语音、音频增强和表格回归工作负载上实现了1.2-10倍更快的推理和1.4-12倍更快的训练，并保持相同的准确性。', 'title_zh': 'PolyKAN: 效率提升的多项式柯尔莫哥罗夫-阿诺尔德网络变体融合GPU运算器'}
{'arxiv_id': 'arXiv:2511.14827', 'title': 'Implicit Bias of the JKO Scheme', 'authors': 'Peter Halmos, Boris Hanin', 'link': 'https://arxiv.org/abs/2511.14827', 'abstract': 'Wasserstein gradient flow provides a general framework for minimizing an energy functional $J$ over the space of probability measures on a Riemannian manifold $(M,g)$. Its canonical time-discretization, the Jordan-Kinderlehrer-Otto (JKO) scheme, produces for any step size $\\eta>0$ a sequence of probability distributions $\\rho_k^\\eta$ that approximate to first order in $\\eta$ Wasserstein gradient flow on $J$. But the JKO scheme also has many other remarkable properties not shared by other first order integrators, e.g. it preserves energy dissipation and exhibits unconditional stability for $\\lambda$-geodesically convex functionals $J$. To better understand the JKO scheme we characterize its implicit bias at second order in $\\eta$. We show that $\\rho_k^\\eta$ are approximated to order $\\eta^2$ by Wasserstein gradient flow on a \\emph{modified} energy \\[ J^{\\eta}(\\rho) = J(\\rho) - \\frac{\\eta}{4}\\int_M \\Big\\lVert \\nabla_g \\frac{\\delta J}{\\delta \\rho} (\\rho) \\Big\\rVert_{2}^{2} \\,\\rho(dx), \\] obtained by subtracting from $J$ the squared metric curvature of $J$ times $\\eta/4$. The JKO scheme therefore adds at second order in $\\eta$ a \\textit{deceleration} in directions where the metric curvature of $J$ is rapidly changing. This corresponds to canonical implicit biases for common functionals: for entropy the implicit bias is the Fisher information, for KL-divergence it is the Fisher-Hyv{ä}rinen divergence, and for Riemannian gradient descent it is the kinetic energy in the metric $g$. To understand the differences between minimizing $J$ and $J^\\eta$ we study \\emph{JKO-Flow}, Wasserstein gradient flow on $J^\\eta$, in several simple numerical examples. These include exactly solvable Langevin dynamics on the Bures-Wasserstein space and Langevin sampling from a quartic potential in 1D.', 'abstract_zh': 'Wasserstein梯度流提供了一种在黎曼流形$(M,g)$上的概率测度空间中最小化能量泛函$J$的一般框架。其经典的时域离散化方案，即Jordan-Kinderlehrer-Otto (JKO)方案，对于任意步长$\\eta>0$，生成了一序近似于Wasserstein梯度流的概率分布序列$\\rho_k^\\eta$。但JKO方案还具有许多其他值得注意的特性，这些特性不为其他一阶积分器共享，例如它保持能量耗散，并对$\\lambda$-测地凸泛函$J$表现出无条件稳定性。为了更好地理解JKO方案，我们表征了其在$\\eta$的二阶项下的隐式偏差。我们证明了$\\rho_k^\\eta$可以通过一个修改后的能量$J^{\\eta}(\\rho) = J(\\rho) - \\frac{\\eta}{4}\\int_M \\Big\\lVert \\nabla_g \\frac{\\delta J}{\\delta \\rho} (\\rho) \\Big\\rVert_{2}^{2} \\,\\rho(dx)$近似，该能量通过从$J$中减去$J$的度量曲率的平方项乘以$\\eta/4$得到。因此，JKO方案在$\\eta$的二阶项中加入了测地曲率快速变化方向上的减速。这一现象对应于一些通用泛函的可规范隐式偏差：对于熵，隐式偏差是Fisher信息；对于KL散度，它是Fisher-Hyvärinen散度；对于黎曼梯度下降，它是度量$g$下的动能。为了理解最小化$J$和$J^\\eta$之间的差异，我们研究了几何简单的数值示例中的JKO流，即在Bures-Wasserstein空间中的可精确求解的Langevin动力学和一维四次势能的Langevin采样。', 'title_zh': 'JKO方案的隐含偏差'}
{'arxiv_id': 'arXiv:2511.14846', 'title': 'Empowering Multi-Turn Tool-Integrated Reasoning with Group Turn Policy Optimization', 'authors': 'Yifeng Ding, Hung Le, Songyang Han, Kangrui Ruan, Zhenghui Jin, Varun Kumar, Zijian Wang, Anoop Deoras', 'link': 'https://arxiv.org/abs/2511.14846', 'abstract': 'Training Large Language Models (LLMs) for multi-turn Tool-Integrated Reasoning (TIR) - where models iteratively reason, generate code, and verify through execution - remains challenging for existing reinforcement learning (RL) approaches. Current RL methods, exemplified by Group Relative Policy Optimization (GRPO), suffer from coarse-grained, trajectory-level rewards that provide insufficient learning signals for complex multi-turn interactions, leading to training stagnation. To address this issue, we propose Group Turn Policy Optimization (GTPO), a novel RL algorithm specifically designed for training LLMs on multi-turn TIR tasks. GTPO introduces three key innovations: (1) turn-level reward assignment that provides fine-grained feedback for individual turns, (2) return-based advantage estimation where normalized discounted returns are calculated as advantages, and (3) self-supervised reward shaping that exploits self-supervision signals from generated code to densify sparse binary outcome-based rewards. Our comprehensive evaluation demonstrates that GTPO outperforms GRPO by 3.0% on average across diverse reasoning benchmarks, establishing its effectiveness for advancing complex mathematical reasoning in the real world.', 'abstract_zh': '培训大规模语言模型（LLMs）进行多轮工具集成推理（TIR）——模型通过迭代推理、生成代码和执行验证——现有的强化学习（RL）方法仍然面临挑战。当前的RL方法，如Group Relative Policy Optimization（GRPO），由于粗粒度的轨迹级奖励无法提供足够的学习信号来处理复杂的多轮交互，导致训练停滞。为了解决这个问题，我们提出了Group Turn Policy Optimization（GTPO），这是一种专门设计用于培训LLMs在多轮TIR任务上的新型RL算法。GTPO引入了三项关键创新：（1）轮次级奖励分配，为每个轮次提供细粒度反馈；（2）基于回报的优油田估计，其中规范化折现回报被计算为优油田；（3）自我监督的奖励塑造，利用生成代码中的自我监督信号来稀疏二元结果奖励的密集化。我们的综合评估表明，GTPO在多种推理基准测试中平均比GRPO高出3.0%，证实其在现实世界中推进复杂数学推理的有效性。', 'title_zh': '赋予多轮工具集成推理以组轮次策略优化'}
{'arxiv_id': 'arXiv:2511.14846', 'title': 'Empowering Multi-Turn Tool-Integrated Reasoning with Group Turn Policy Optimization', 'authors': 'Yifeng Ding, Hung Le, Songyang Han, Kangrui Ruan, Zhenghui Jin, Varun Kumar, Zijian Wang, Anoop Deoras', 'link': 'https://arxiv.org/abs/2511.14846', 'abstract': 'Training Large Language Models (LLMs) for multi-turn Tool-Integrated Reasoning (TIR) - where models iteratively reason, generate code, and verify through execution - remains challenging for existing reinforcement learning (RL) approaches. Current RL methods, exemplified by Group Relative Policy Optimization (GRPO), suffer from coarse-grained, trajectory-level rewards that provide insufficient learning signals for complex multi-turn interactions, leading to training stagnation. To address this issue, we propose Group Turn Policy Optimization (GTPO), a novel RL algorithm specifically designed for training LLMs on multi-turn TIR tasks. GTPO introduces three key innovations: (1) turn-level reward assignment that provides fine-grained feedback for individual turns, (2) return-based advantage estimation where normalized discounted returns are calculated as advantages, and (3) self-supervised reward shaping that exploits self-supervision signals from generated code to densify sparse binary outcome-based rewards. Our comprehensive evaluation demonstrates that GTPO outperforms GRPO by 3.0% on average across diverse reasoning benchmarks, establishing its effectiveness for advancing complex mathematical reasoning in the real world.', 'abstract_zh': '训练大规模语言模型（LLMs）进行多轮工具集成推理（TIR）——模型通过迭代推理、生成代码和执行验证——对于现有的强化学习（RL）方法仍具有挑战性。当前的RL方法，如组相对策略优化（GRPO），因其粗粒度的轨迹级奖励提供了不足的学习信号，导致复杂多轮交互的训练停滞。为解决这一问题，我们提出了组轮次策略优化（GTPO），这是一种专门用于在多轮TIR任务上训练LLMs的新型RL算法。GTPO引入了三项关键创新：（1）轮次级奖励分配，提供细粒度的反馈；（2）基于返回的优势估计；（3）自监督奖励塑形。全面的评估表明，GTPO在多种推理基准测试中平均优于GRPO 3.0%，证明了其在现实世界中推动复杂数学推理的有效性。', 'title_zh': '增强多轮工具集成推理的能力：基于组轮次策略优化'}
{'arxiv_id': 'arXiv:2511.14824', 'title': 'Voiced-Aware Style Extraction and Style Direction Adjustment for Expressive Text-to-Speech', 'authors': 'Nam-Gyu Kim', 'link': 'https://arxiv.org/abs/2511.14824', 'abstract': 'Recent advances in expressive text-to-speech (TTS) have introduced diverse methods based on style embedding extracted from reference speech. However, synthesizing high-quality expressive speech remains challenging. We propose SpotlightTTS, which exclusively emphasizes style via voiced-aware style extraction and style direction adjustment. Voiced-aware style extraction focuses on voiced regions highly related to style while maintaining continuity across different speech regions to improve expressiveness. We adjust the direction of the extracted style for optimal integration into the TTS model, which improves speech quality. Experimental results demonstrate that Spotlight-TTS achieves superior performance compared to baseline models in terms of expressiveness, overall speech quality, and style transfer capability.', 'abstract_zh': 'Recent Advances in Expressive Text-to-Speech via Voiced-Aware Style Extraction and Style Direction Adjustment', 'title_zh': '基于语音感知的风格提取与风格方向调整以实现有表现力的文本到语音'}
{'arxiv_id': 'arXiv:2511.14827', 'title': 'Implicit Bias of the JKO Scheme', 'authors': 'Peter Halmos, Boris Hanin', 'link': 'https://arxiv.org/abs/2511.14827', 'abstract': 'Wasserstein gradient flow provides a general framework for minimizing an energy functional $J$ over the space of probability measures on a Riemannian manifold $(M,g)$. Its canonical time-discretization, the Jordan-Kinderlehrer-Otto (JKO) scheme, produces for any step size $\\eta>0$ a sequence of probability distributions $\\rho_k^\\eta$ that approximate to first order in $\\eta$ Wasserstein gradient flow on $J$. But the JKO scheme also has many other remarkable properties not shared by other first order integrators, e.g. it preserves energy dissipation and exhibits unconditional stability for $\\lambda$-geodesically convex functionals $J$. To better understand the JKO scheme we characterize its implicit bias at second order in $\\eta$. We show that $\\rho_k^\\eta$ are approximated to order $\\eta^2$ by Wasserstein gradient flow on a \\emph{modified} energy \\[ J^{\\eta}(\\rho) = J(\\rho) - \\frac{\\eta}{4}\\int_M \\Big\\lVert \\nabla_g \\frac{\\delta J}{\\delta \\rho} (\\rho) \\Big\\rVert_{2}^{2} \\,\\rho(dx), \\] obtained by subtracting from $J$ the squared metric curvature of $J$ times $\\eta/4$. The JKO scheme therefore adds at second order in $\\eta$ a \\textit{deceleration} in directions where the metric curvature of $J$ is rapidly changing. This corresponds to canonical implicit biases for common functionals: for entropy the implicit bias is the Fisher information, for KL-divergence it is the Fisher-Hyv{ä}rinen divergence, and for Riemannian gradient descent it is the kinetic energy in the metric $g$. To understand the differences between minimizing $J$ and $J^\\eta$ we study \\emph{JKO-Flow}, Wasserstein gradient flow on $J^\\eta$, in several simple numerical examples. These include exactly solvable Langevin dynamics on the Bures-Wasserstein space and Langevin sampling from a quartic potential in 1D.', 'abstract_zh': 'Wasserstein梯度流动提供了一种在黎曼流形$(M,g)$上的概率测度空间中最小化能量泛函$J$的一般框架。其经典的时离散化方案，Jordan-Kinderlehrer-Otto (JKO)方案，对任意步长$\\eta>0$生成了一组概率分布$\\rho_k^\\eta$，其在$\\eta$的一阶近似下逼近Wasserstein梯度流动。但JKO方案还具有许多其他杰出的性质，如保持能量耗散，并且对于$\\lambda$-测地凸泛函$J$表现出无条件稳定性。为了更好地理解JKO方案，我们对其在$\\eta$的二阶项上的隐式偏差进行了刻画。我们展示了$\\rho_k^\\eta$在$\\eta^2$的阶上被修改后的能量\\[ J^{\\eta}(\\rho) = J(\\rho) - \\frac{\\eta}{4}\\int_M \\Big\\lVert \\nabla_g \\frac{\\delta J}{\\delta \\rho} (\\rho) \\Big\\rVert_{2}^{2} \\,\\rho(dx) \\]逼近，其中通过从$J$中减去$J$的度量曲率的平方项乘以$\\eta/4$得到。因此，JKO方案在度量曲率变化迅速的方向上在$\\eta$的二阶项上增加了减速。这对应于常用泛函的固定规则隐式偏差：对于熵，隐式偏差是费舍尔信息；对于KL散度，它是费舍尔-赫韦宁 divergence；对于黎曼梯度下降，它是度量$g$中的动能。为了理解最小化$J$和$J^\\eta$之间的差异，我们研究了$JKO$流动，即在$J^\\eta$上的Wasserstein梯度流动，在几个简单的数值例子中进行了探讨。这些例子包括在Bures-Wasserstein空间中的可解析朗金动力学以及在1D四次势中的朗金采样。', 'title_zh': 'JKO方案的隐性偏差'}
{'arxiv_id': 'arXiv:2511.14827', 'title': 'Implicit Bias of the JKO Scheme', 'authors': 'Peter Halmos, Boris Hanin', 'link': 'https://arxiv.org/abs/2511.14827', 'abstract': 'Wasserstein gradient flow provides a general framework for minimizing an energy functional $J$ over the space of probability measures on a Riemannian manifold $(M,g)$. Its canonical time-discretization, the Jordan-Kinderlehrer-Otto (JKO) scheme, produces for any step size $\\eta>0$ a sequence of probability distributions $\\rho_k^\\eta$ that approximate to first order in $\\eta$ Wasserstein gradient flow on $J$. But the JKO scheme also has many other remarkable properties not shared by other first order integrators, e.g. it preserves energy dissipation and exhibits unconditional stability for $\\lambda$-geodesically convex functionals $J$. To better understand the JKO scheme we characterize its implicit bias at second order in $\\eta$. We show that $\\rho_k^\\eta$ are approximated to order $\\eta^2$ by Wasserstein gradient flow on a \\emph{modified} energy \\[ J^{\\eta}(\\rho) = J(\\rho) - \\frac{\\eta}{4}\\int_M \\Big\\lVert \\nabla_g \\frac{\\delta J}{\\delta \\rho} (\\rho) \\Big\\rVert_{2}^{2} \\,\\rho(dx), \\] obtained by subtracting from $J$ the squared metric curvature of $J$ times $\\eta/4$. The JKO scheme therefore adds at second order in $\\eta$ a \\textit{deceleration} in directions where the metric curvature of $J$ is rapidly changing. This corresponds to canonical implicit biases for common functionals: for entropy the implicit bias is the Fisher information, for KL-divergence it is the Fisher-Hyv{ä}rinen divergence, and for Riemannian gradient descent it is the kinetic energy in the metric $g$. To understand the differences between minimizing $J$ and $J^\\eta$ we study \\emph{JKO-Flow}, Wasserstein gradient flow on $J^\\eta$, in several simple numerical examples. These include exactly solvable Langevin dynamics on the Bures-Wasserstein space and Langevin sampling from a quartic potential in 1D.', 'abstract_zh': 'Wasserstein梯度流提供了一种在流形上的概率测度空间上最小化能量泛函$J$的一般框架。经典的离散化方案，Jordan-Kinderlehrer-Otto (JKO)方案，对于任意时间步长$\\eta>0$，产生的一组概率分布$\\rho_k^\\eta$在$\\eta$的一阶近似下逼近Wasserstein梯度流。但JKO方案还具有许多其他值得注意的性质，如其保持能量耗散并在$\\lambda$-测地凸泛函$J$的情况下展现出无条件稳定性。为了更好地理解JKO方案，我们对其在$\\eta$的二阶近似下的隐式偏性进行了描述。我们证明$\\rho_k^\\eta$在$\\eta^2$的阶上由一个修改后的能量\\[ J^{\\eta}(\\rho) = J(\\rho) - \\frac{\\eta}{4}\\int_M \\Big\\lVert \\nabla_g \\frac{\\delta J}{\\delta \\rho} (\\rho) \\Big\\rVert_{2}^{2} \\,\\rho(dx) \\]近似，该能量通过从$J$中减去$J$的度量曲率的平方并乘以$\\eta/4$获得。因此，JKO方案在$\\eta$的二阶近似下，在度量曲率快速变化的方向上添加了一个减速。这对应于共同泛函的经典隐式偏性：对于熵，隐式偏性是 Fisher 信息，对于KL散度，它是 Fisher-Hyvärinen 散度，而对于流形梯度下降，它是度量$g$下的动能。为了理解最小化$J$和$J^\\eta$之间的差异，我们研究了$JKO$流动，即$J^\\eta$上的Wasserstein梯度流，并在几个简单的数值示例中进行了探讨。这些示例包括Bures-Wasserstein空间上的可解析朗之万动力学和一维四次势能下基于朗之万采样的研究。', 'title_zh': 'JKO方案的隐含偏差'}
{'arxiv_id': 'arXiv:2511.14808', 'title': 'Transformer Injectivity & Geometric Robustness - Analytic Margins and Bi-Lipschitz Uniformity of Sequence-Level Hidden States', 'authors': 'Mikael von Strauss', 'link': 'https://arxiv.org/abs/2511.14808', 'abstract': 'Under real-analytic assumptions on decoder-only Transformers, recent work shows that the map from discrete prompts to last-token hidden states is generically injective on finite prompt sets. We refine this picture: for each layer $\\ell$ we define a collision discriminant $\\Delta^\\ell \\subset \\Theta$ and injective stratum $U^\\ell = \\Theta \\setminus \\Delta^\\ell$, and prove a dichotomy -- either the model is nowhere injective on the set, or $U^\\ell$ is open and dense and every $F^\\ell_\\theta$ is injective. Under mild non-singularity assumptions on the optimizer and an absolutely continuous initialization, generic injectivity persists along smooth training trajectories over any fixed horizon. We also treat symmetry groups $G$, showing that discriminants and injective strata descend to the quotient $\\Theta/G$, so injectivity is naturally a property of functional equivalence classes.\nWe complement these results with an empirical study of layerwise geometric diagnostics. We define a separation margin and a co-Lipschitz (lower Lipschitz) constant between prompt space and last-token representation space, estimated via nearest-neighbor statistics on large prompt sets. Applying these diagnostics to pretrained LLaMA-3 and Qwen models, we study behavior across layers, sequence lengths, model scales, and 8- and 4-bit activation quantization. On our sampled prompts we see no collisions in full precision or at 8 bits, while 4-bit quantization induces a small number of collisions and markedly shrinks co-Lipschitz estimates. For a small GPT-2 trained from scratch, normalized metrics remain stable over training. Overall, the results suggest that Transformer representations are generically and persistently injective in the continuous-parameter idealization, while their practical invertibility can be probed using simple geometric diagnostics.', 'abstract_zh': '在解码器唯Transformer的实解析假设下，最近的工作显示，从离散提示到最终token隐藏状态的映射在有限提示集上通常是单射的。我们细化了这一图景：对于每一层\\(\\ell\\)，我们定义碰撞判别集\\(\\Delta^\\ell \\subset \\Theta\\)和单射层\\(U^\\ell = \\Theta \\setminus \\Delta^\\ell\\)，并证明二分法——要么模型在整个集合上无处单射，要么\\(U^\\ell\\)是开且稠密的，并且每个\\(F^\\ell_\\theta\\)都是单射。在优化器轻微的非奇异假设和绝对连续初始化下，通用单射性沿任何固定的训练轨迹持续存在。我们还处理了对称群\\(G\\)，表明判别集和单射层下降至商空间\\(\\Theta/G\\)，因此单射性自然地成为了功能等价类的性质。\n\n我们通过经验研究来补充这些结果，定义了逐层几何诊断方法。我们定义了分离裕度和co-Lipschitz（下Lipschitz）常数，通过对大提示集的最近邻统计估计得到。将这些诊断应用于预训练的LLaMA-3和Qwen模型，我们研究了不同层、序列长度、模型规模以及8位和4位激活量化下的行为。在我们采样的提示下，无论是在全精度还是8位精度下，都没有碰撞发生；而4位量化会诱导少量碰撞并显著缩小co-Lipschitz估计。对于一个小的从零开始训练的GPT-2模型，标准化指标在整个训练过程中保持稳定。总体而言，结果表明，在连续参数理想化下，Transformer表示通常是且持续地单射的，而其实际可逆性可以通过简单的几何诊断进行探测。', 'title_zh': 'Transformer的单射性与几何鲁棒性：序列级隐藏状态的分析边际与双利普希茨均匀性'}
{'arxiv_id': 'arXiv:2511.14824', 'title': 'Voiced-Aware Style Extraction and Style Direction Adjustment for Expressive Text-to-Speech', 'authors': 'Nam-Gyu Kim', 'link': 'https://arxiv.org/abs/2511.14824', 'abstract': 'Recent advances in expressive text-to-speech (TTS) have introduced diverse methods based on style embedding extracted from reference speech. However, synthesizing high-quality expressive speech remains challenging. We propose SpotlightTTS, which exclusively emphasizes style via voiced-aware style extraction and style direction adjustment. Voiced-aware style extraction focuses on voiced regions highly related to style while maintaining continuity across different speech regions to improve expressiveness. We adjust the direction of the extracted style for optimal integration into the TTS model, which improves speech quality. Experimental results demonstrate that Spotlight-TTS achieves superior performance compared to baseline models in terms of expressiveness, overall speech quality, and style transfer capability.', 'abstract_zh': '近期基于样式嵌入的表达性文本到语音技术取得了进展，引入了多种从参考语音中提取的样式嵌入方法。然而，合成高质量的表达性语音仍然具有挑战性。我们提出了一种名为SpotlightTTS的方法，它通过有声感知的样式提取和样式方向调整，专门强调样式。有声感知的样式提取关注与样式高度相关的有声区域，同时维持不同语音区域间的连续性，以提高表达性。我们调整提取出的样式的方向，使其最佳地整合到TTS模型中，从而提高语音质量。实验结果表明，SpotlightTTS在表达性、总体语音质量和样式转移能力方面均优于基线模型。', 'title_zh': '基于音素感知的风格提取与风格导向调整以实现表达性文本到语音合成'}
{'arxiv_id': 'arXiv:2511.14824', 'title': 'Voiced-Aware Style Extraction and Style Direction Adjustment for Expressive Text-to-Speech', 'authors': 'Nam-Gyu Kim', 'link': 'https://arxiv.org/abs/2511.14824', 'abstract': 'Recent advances in expressive text-to-speech (TTS) have introduced diverse methods based on style embedding extracted from reference speech. However, synthesizing high-quality expressive speech remains challenging. We propose SpotlightTTS, which exclusively emphasizes style via voiced-aware style extraction and style direction adjustment. Voiced-aware style extraction focuses on voiced regions highly related to style while maintaining continuity across different speech regions to improve expressiveness. We adjust the direction of the extracted style for optimal integration into the TTS model, which improves speech quality. Experimental results demonstrate that Spotlight-TTS achieves superior performance compared to baseline models in terms of expressiveness, overall speech quality, and style transfer capability.', 'abstract_zh': 'Recent Advances in Expressive Text-to-Speech via Voiced-Aware Style Extraction and Direction Adjustment', 'title_zh': '基于语音感知的风格提取与表达性文本转换中的风格方向调整'}
{'arxiv_id': 'arXiv:2511.14807', 'title': 'Fully Differentiable dMRI Streamline Propagation in PyTorch', 'authors': 'Jongyeon Yoon, Elyssa M. McMaster, Michael E. Kim, Gaurav Rudravaram, Kurt G. Schilling, Bennett A. Landman, Daniel Moyer', 'link': 'https://arxiv.org/abs/2511.14807', 'abstract': 'Diffusion MRI (dMRI) provides a distinctive means to probe the microstructural architecture of living tissue, facilitating applications such as brain connectivity analysis, modeling across multiple conditions, and the estimation of macrostructural features. Tractography, which emerged in the final years of the 20th century and accelerated in the early 21st century, is a technique for visualizing white matter pathways in the brain using dMRI. Most diffusion tractography methods rely on procedural streamline propagators or global energy minimization methods. Although recent advancements in deep learning have enabled tasks that were previously challenging, existing tractography approaches are often non-differentiable, limiting their integration in end-to-end learning frameworks. While progress has been made in representing streamlines in differentiable frameworks, no existing method offers fully differentiable propagation. In this work, we propose a fully differentiable solution that retains numerical fidelity with a leading streamline algorithm. The key is that our PyTorch-engineered streamline propagator has no components that block gradient flow, making it fully differentiable. We show that our method matches standard propagators while remaining differentiable. By translating streamline propagation into a differentiable PyTorch framework, we enable deeper integration of tractography into deep learning workflows, laying the foundation for a new category of macrostructural reasoning that is not only computationally robust but also scientifically rigorous.', 'abstract_zh': '扩散磁共振成像（dMRI）提供了一种独特的手段来探查活体组织的微观结构架构，促进脑连接分析、多条件建模以及宏观结构特征估算的应用。轨迹追踪技术起源于20世纪末，并在21世纪初加速发展，是一种使用dMRI可视化脑白质路径的技术。大多数扩散轨迹追踪方法依赖于过程导向的纤维束传播器或全局能量最小化方法。尽管最近深度学习的进展使得一些之前难以完成的任务成为可能，但现有的轨迹追踪方法往往是不可微的，限制了它们在端到端学习框架中的集成。虽然已经在不同的可微框架中表示纤维束方面取得了进展，但现有的方法均无法提供完全可微的传播。在本研究中，我们提出了一种完全可微的解决方案，该解决方案在保持与领先纤维束算法的数值一致性方面具有优势。关键在于我们利用PyTorch设计的纤维束传播器没有任何阻碍梯度流动的组件，使其完全可微。我们展示了我们的方法在保持可微性的同时仍能匹配标准传播器。通过将纤维束传播转换为可微的PyTorch框架，我们使轨迹追踪更深入地集成到深度学习工作流中，为一种不仅在计算上稳健而且在科学上严谨的新型宏观结构推理奠定了基础。', 'title_zh': '完全可微分的高分辨磁共振成像纤维束传播在PyTorch中'}
{'arxiv_id': 'arXiv:2511.14808', 'title': 'Transformer Injectivity & Geometric Robustness - Analytic Margins and Bi-Lipschitz Uniformity of Sequence-Level Hidden States', 'authors': 'Mikael von Strauss', 'link': 'https://arxiv.org/abs/2511.14808', 'abstract': 'Under real-analytic assumptions on decoder-only Transformers, recent work shows that the map from discrete prompts to last-token hidden states is generically injective on finite prompt sets. We refine this picture: for each layer $\\ell$ we define a collision discriminant $\\Delta^\\ell \\subset \\Theta$ and injective stratum $U^\\ell = \\Theta \\setminus \\Delta^\\ell$, and prove a dichotomy -- either the model is nowhere injective on the set, or $U^\\ell$ is open and dense and every $F^\\ell_\\theta$ is injective. Under mild non-singularity assumptions on the optimizer and an absolutely continuous initialization, generic injectivity persists along smooth training trajectories over any fixed horizon. We also treat symmetry groups $G$, showing that discriminants and injective strata descend to the quotient $\\Theta/G$, so injectivity is naturally a property of functional equivalence classes.\nWe complement these results with an empirical study of layerwise geometric diagnostics. We define a separation margin and a co-Lipschitz (lower Lipschitz) constant between prompt space and last-token representation space, estimated via nearest-neighbor statistics on large prompt sets. Applying these diagnostics to pretrained LLaMA-3 and Qwen models, we study behavior across layers, sequence lengths, model scales, and 8- and 4-bit activation quantization. On our sampled prompts we see no collisions in full precision or at 8 bits, while 4-bit quantization induces a small number of collisions and markedly shrinks co-Lipschitz estimates. For a small GPT-2 trained from scratch, normalized metrics remain stable over training. Overall, the results suggest that Transformer representations are generically and persistently injective in the continuous-parameter idealization, while their practical invertibility can be probed using simple geometric diagnostics.', 'abstract_zh': '在对解码器型Transformer的实解析假设下，近期的研究表明，从离散提示到最后一个token的隐藏状态的映射在有限提示集上是通用单射。我们细化了这一图景：对于每一层\\(\\ell\\)，我们定义一个碰撞判别集\\(\\Delta^\\ell \\subset \\Theta\\)和单射层\\(U^\\ell = \\Theta \\setminus \\Delta^\\ell\\)，并证明一个二分法——要么模型在该集上处处非单射，要么\\(U^\\ell\\)是开密集集且每个\\(F^\\ell_\\theta\\)都是单射。在优化器轻微非奇异假设和绝对连续初始化条件下，通用单射性会在任意固定的训练轨道上持续存在。我们还处理了对称群\\(G\\)，表明判别集和单射层下传到商空间\\(\\Theta/G\\)，因此单射性自然地成为功能等价类的性质。\n\n我们通过一个实证研究补充了这些结果，定义了层级几何诊断指标。我们定义了分离裕度和以最近邻统计估计的提示空间与最后一个token表示空间之间的临界Lipschitz常数。将这些诊断应用于预训练的LLaMA-3和Qwen模型，我们研究了各层、序列长度、模型规模和8位和4位激活量化行为。在我们采样的提示中，无论是全精度还是8位量化，均未观察到碰撞，而4位量化导致少量碰撞并显著缩小了临界Lipschitz估计。对于从小型GPT-2从零开始训练的模型，标准化度量在训练过程中保持稳定。总体而言，结果表明，在连续参数理想化下，Transformer的表示是普遍且持久地单射的，而它们的实际可逆性可以通过简单的几何诊断进行探索。', 'title_zh': 'Transformer 的注入性与几何鲁棒性：序列级隐藏状态的解析边际和双 Lipschitz 均匀性'}
{'arxiv_id': 'arXiv:2511.14808', 'title': 'Transformer Injectivity & Geometric Robustness - Analytic Margins and Bi-Lipschitz Uniformity of Sequence-Level Hidden States', 'authors': 'Mikael von Strauss', 'link': 'https://arxiv.org/abs/2511.14808', 'abstract': 'Under real-analytic assumptions on decoder-only Transformers, recent work shows that the map from discrete prompts to last-token hidden states is generically injective on finite prompt sets. We refine this picture: for each layer $\\ell$ we define a collision discriminant $\\Delta^\\ell \\subset \\Theta$ and injective stratum $U^\\ell = \\Theta \\setminus \\Delta^\\ell$, and prove a dichotomy -- either the model is nowhere injective on the set, or $U^\\ell$ is open and dense and every $F^\\ell_\\theta$ is injective. Under mild non-singularity assumptions on the optimizer and an absolutely continuous initialization, generic injectivity persists along smooth training trajectories over any fixed horizon. We also treat symmetry groups $G$, showing that discriminants and injective strata descend to the quotient $\\Theta/G$, so injectivity is naturally a property of functional equivalence classes.\nWe complement these results with an empirical study of layerwise geometric diagnostics. We define a separation margin and a co-Lipschitz (lower Lipschitz) constant between prompt space and last-token representation space, estimated via nearest-neighbor statistics on large prompt sets. Applying these diagnostics to pretrained LLaMA-3 and Qwen models, we study behavior across layers, sequence lengths, model scales, and 8- and 4-bit activation quantization. On our sampled prompts we see no collisions in full precision or at 8 bits, while 4-bit quantization induces a small number of collisions and markedly shrinks co-Lipschitz estimates. For a small GPT-2 trained from scratch, normalized metrics remain stable over training. Overall, the results suggest that Transformer representations are generically and persistently injective in the continuous-parameter idealization, while their practical invertibility can be probed using simple geometric diagnostics.', 'abstract_zh': '基于解码器的Transformer在实解析假设下的最近研究表明，离散提示到最终token隐藏状态的映射在有限提示集合上通常是单射的。我们细化了这一观点：对于每一层$\\ell$，我们定义一个碰撞判别集$\\Delta^\\ell \\subset \\Theta$和单射层$U^\\ell = \\Theta \\setminus \\Delta^\\ell$，并证明二分法——要么模型在整个集合上处处非单射，要么$U^\\ell$是开且稠密的，且每个$F^\\ell_\\theta$都是单射。在优化器和初始化的轻微非奇异假设以及绝对连续初始化下，通用单射性在任意固定时间窗内的平滑训练轨迹上持续存在。我们还处理了对称群$G$，表明判别集和单射层可以下移到商空间$\\Theta/G$，因此单射性自然地是功能等价类的性质。\n\n我们通过实证研究逐层几何诊断来补充这些结果。我们定义了分离裕度和提示空间与最终token表示空间之间的co-Lipschitz（下Lipschitz）常数，并通过大型提示集的最近邻统计进行估计。将这些诊断应用于预训练的LLaMA-3和Qwen模型，我们研究了不同层数、序列长度、模型规模以及8比特和4比特激活量化的行为。在我们的采样提示中，我们在全精度和8比特量化下均未观察到碰撞现象，而4比特量化引发了一定数量的碰撞并显著缩小了co-Lipschitz估计值。对于一小部分从头训练的GPT-2，归一化指标在整个训练过程中保持稳定。总体而言，这些结果表明，Transformer表示在连续参数的理想化情况下通常是通用且持久的单射的，而其实际可逆性可以通过简单的几何诊断进行探查。', 'title_zh': 'Transformer的单射性与几何鲁棒性：序列级隐藏状态的分析裕度与双利普希茨均匀性'}
{'arxiv_id': 'arXiv:2511.14806', 'title': 'MergeDNA: Context-aware Genome Modeling with Dynamic Tokenization through Token Merging', 'authors': 'Siyuan Li, Kai Yu, Anna Wang, Zicheng Liu, Chang Yu, Jingbo Zhou, Qirong Yang, Yucheng Guo, Xiaoming Zhang, Stan Z. Li', 'link': 'https://arxiv.org/abs/2511.14806', 'abstract': 'Modeling genomic sequences faces two unsolved challenges: the information density varies widely across different regions, while there is no clearly defined minimum vocabulary unit. Relying on either four primitive bases or independently designed DNA tokenizers, existing approaches with naive masked language modeling pre-training often fail to adapt to the varying complexities of genomic sequences. Leveraging Token Merging techniques, this paper introduces a hierarchical architecture that jointly optimizes a dynamic genomic tokenizer and latent Transformers with context-aware pre-training tasks. As for network structures, the tokenization module automatically chunks adjacent bases into words by stacking multiple layers of the differentiable token merging blocks with local-window constraints, then a Latent Encoder captures the global context of these merged words by full-attention blocks. Symmetrically employing a Latent Decoder and a Local Decoder, MergeDNA learns with two pre-training tasks: Merged Token Reconstruction simultaneously trains the dynamic tokenization module and adaptively filters important tokens, while Adaptive Masked Token Modeling learns to predict these filtered tokens to capture informative contents. Extensive experiments show that MergeDNA achieves superior performance on three popular DNA benchmarks and several multi-omics tasks with fine-tuning or zero-shot evaluation, outperforming typical tokenization methods and large-scale DNA foundation models.', 'abstract_zh': 'Modeling Genomic Sequences Faces Two Unsolved Challenges: Varying Information Density and Lack of Clearly Defined Minimum Vocabulary Unit. Leveraging Token Merging Techniques, This Paper Introduces a Hierarchical Architecture That Jointly Optimizes a Dynamic Genomic Tokenizer and Latent Transformers with Context-Aware Pre-Training Tasks.', 'title_zh': 'MergeDNA：基于上下文的动态分词基因组建模'}
{'arxiv_id': 'arXiv:2511.14807', 'title': 'Fully Differentiable dMRI Streamline Propagation in PyTorch', 'authors': 'Jongyeon Yoon, Elyssa M. McMaster, Michael E. Kim, Gaurav Rudravaram, Kurt G. Schilling, Bennett A. Landman, Daniel Moyer', 'link': 'https://arxiv.org/abs/2511.14807', 'abstract': 'Diffusion MRI (dMRI) provides a distinctive means to probe the microstructural architecture of living tissue, facilitating applications such as brain connectivity analysis, modeling across multiple conditions, and the estimation of macrostructural features. Tractography, which emerged in the final years of the 20th century and accelerated in the early 21st century, is a technique for visualizing white matter pathways in the brain using dMRI. Most diffusion tractography methods rely on procedural streamline propagators or global energy minimization methods. Although recent advancements in deep learning have enabled tasks that were previously challenging, existing tractography approaches are often non-differentiable, limiting their integration in end-to-end learning frameworks. While progress has been made in representing streamlines in differentiable frameworks, no existing method offers fully differentiable propagation. In this work, we propose a fully differentiable solution that retains numerical fidelity with a leading streamline algorithm. The key is that our PyTorch-engineered streamline propagator has no components that block gradient flow, making it fully differentiable. We show that our method matches standard propagators while remaining differentiable. By translating streamline propagation into a differentiable PyTorch framework, we enable deeper integration of tractography into deep learning workflows, laying the foundation for a new category of macrostructural reasoning that is not only computationally robust but also scientifically rigorous.', 'abstract_zh': '弥散磁共振成像（dMRI）提供了一种独特的手段来探测活体组织的微观结构架构，促进诸如脑连接性分析、多条件建模和宏观结构特征估计等应用。轨迹追踪技术最早在20世纪末出现，并在21世纪初加速发展，是一种使用dMRI可视化大脑白质路径的技术。大多数弥散轨迹追踪方法依赖于程序化的流线传播器或全局能量最小化方法。尽管近年来深度学习的进步使一些此前难以完成的任务变得可行，但现有的轨迹追踪方法通常是非可微的，这限制了它们在端到端学习框架中的应用。虽然已经在不同的可微框架中表示流线方面取得了进展，但现有的方法仍无法实现完全可微的传播。在本工作中，我们提出了一个完全可微的解决方案，该方案在保持与领先流线算法的数值保真度的同时是完全可微的。关键在于我们使用PyTorch构建的流线传播器没有任何阻碍梯度流动的组件，使其完全可微。我们证明了我们的方法在具有相同的非可微传播器的同时保持了可微性。通过将流线传播转换为可微的PyTorch框架，我们使轨迹追踪更深地集成到深度学习工作流中，为一种不仅在计算上稳健而且在科学上严格的新的宏观结构推理类别奠定了基础。', 'title_zh': '在PyTorch中可完全差分的dMRI轨迹传播'}
{'arxiv_id': 'arXiv:2511.14807', 'title': 'Fully Differentiable dMRI Streamline Propagation in PyTorch', 'authors': 'Jongyeon Yoon, Elyssa M. McMaster, Michael E. Kim, Gaurav Rudravaram, Kurt G. Schilling, Bennett A. Landman, Daniel Moyer', 'link': 'https://arxiv.org/abs/2511.14807', 'abstract': 'Diffusion MRI (dMRI) provides a distinctive means to probe the microstructural architecture of living tissue, facilitating applications such as brain connectivity analysis, modeling across multiple conditions, and the estimation of macrostructural features. Tractography, which emerged in the final years of the 20th century and accelerated in the early 21st century, is a technique for visualizing white matter pathways in the brain using dMRI. Most diffusion tractography methods rely on procedural streamline propagators or global energy minimization methods. Although recent advancements in deep learning have enabled tasks that were previously challenging, existing tractography approaches are often non-differentiable, limiting their integration in end-to-end learning frameworks. While progress has been made in representing streamlines in differentiable frameworks, no existing method offers fully differentiable propagation. In this work, we propose a fully differentiable solution that retains numerical fidelity with a leading streamline algorithm. The key is that our PyTorch-engineered streamline propagator has no components that block gradient flow, making it fully differentiable. We show that our method matches standard propagators while remaining differentiable. By translating streamline propagation into a differentiable PyTorch framework, we enable deeper integration of tractography into deep learning workflows, laying the foundation for a new category of macrostructural reasoning that is not only computationally robust but also scientifically rigorous.', 'abstract_zh': '弥散磁共振成像（dMRI）提供了一种独特的手段来探查活体组织的微观结构架构，促进脑连接分析、多条件建模以及宏观结构特征估计的应用。轨迹追踪技术起源于20世纪末，并在21世纪初加速发展，是一种利用dMRI可视化大脑白质路径的技术。大多数弥散轨迹追踪方法依赖于过程化的流线传播器或全局能量最小化方法。尽管最近深度学习的进展使得一些以前难以完成的任务变得可行，但现有轨迹追踪方法通常是非可微的，限制了其在端到端学习框架中的集成。虽然有进展表示流线可以在不同的可微框架中表示，但目前没有方法能提供完全可微的传播。在这项工作中，我们提出了一种完全可微的解决方案，该方案在保留领先流线算法数值精度的同时，确保了完全可微性。关键在于我们利用PyTorch设计的流线传播器没有阻碍梯度流动的组件，从而实现了完全可微性。我们证明了我们的方法在保持标准传播器性能的同时，仍然可以进行微分。通过将流线传播转化为可微PyTorch框架，我们使轨迹追踪更深地集成到深度学习工作流中，为不仅计算上稳健而且在科学上严格的全新宏观结构推理类别奠定了基础。', 'title_zh': '在PyTorch中实现完全可微的dMRI纤维束传播'}
{'arxiv_id': 'arXiv:2511.14805', 'title': 'Towards Continuous Assurance with Formal Verification and Assurance Cases', 'authors': 'Dhaminda B. Abeywickrama, Michael Fisher, Frederic Wheeler, Louise Dennis', 'link': 'https://arxiv.org/abs/2511.14805', 'abstract': 'Autonomous systems must sustain justified confidence in their correctness and safety across their operational lifecycle-from design and deployment through post-deployment evolution. Traditional assurance methods often separate development-time assurance from runtime assurance, yielding fragmented arguments that cannot adapt to runtime changes or system updates - a significant challenge for assured autonomy. Towards addressing this, we propose a unified Continuous Assurance Framework that integrates design-time, runtime, and evolution-time assurance within a traceable, model-driven workflow as a step towards assured autonomy. In this paper, we specifically instantiate the design-time phase of the framework using two formal verification methods: RoboChart for functional correctness and PRISM for probabilistic risk analysis. We also propose a model-driven transformation pipeline, implemented as an Eclipse plugin, that automatically regenerates structured assurance arguments whenever formal specifications or their verification results change, thereby ensuring traceability. We demonstrate our approach on a nuclear inspection robot scenario, and discuss its alignment with the Trilateral AI Principles, reflecting regulator-endorsed best practices.', 'abstract_zh': '自主系统必须在其整个运行生命周期中持续维持对其正确性和安全性的正当信心，从设计和部署到部署后的演化。传统的保证方法通常将开发时的保证与运行时的保证分离，导致无法适应运行时变化或系统更新的孤立论证，这对于确保自主性是一个重大挑战。为解决这一问题，我们提出了一种统一的连续保证框架，将设计时、运行时和演化时的保证整合到可追溯的模型驱动工作流中，以实现确保的自主性。在本文中，我们具体使用两种形式验证方法（RoboChart 和 PRISM）实例化框架的设计时阶段，并提出了一种模型驱动的转换流水线，作为 Eclipse 插件实现，以自动重新生成结构化的保证论据，从而确保可追溯性。我们在一个核检验机器人场景中演示了这种方法，并讨论了其与三边人工智能原则的对齐，反映了监管机构认可的最佳实践。', 'title_zh': '面向形式验证与保证案件的持续性保证'}
{'arxiv_id': 'arXiv:2511.14806', 'title': 'MergeDNA: Context-aware Genome Modeling with Dynamic Tokenization through Token Merging', 'authors': 'Siyuan Li, Kai Yu, Anna Wang, Zicheng Liu, Chang Yu, Jingbo Zhou, Qirong Yang, Yucheng Guo, Xiaoming Zhang, Stan Z. Li', 'link': 'https://arxiv.org/abs/2511.14806', 'abstract': 'Modeling genomic sequences faces two unsolved challenges: the information density varies widely across different regions, while there is no clearly defined minimum vocabulary unit. Relying on either four primitive bases or independently designed DNA tokenizers, existing approaches with naive masked language modeling pre-training often fail to adapt to the varying complexities of genomic sequences. Leveraging Token Merging techniques, this paper introduces a hierarchical architecture that jointly optimizes a dynamic genomic tokenizer and latent Transformers with context-aware pre-training tasks. As for network structures, the tokenization module automatically chunks adjacent bases into words by stacking multiple layers of the differentiable token merging blocks with local-window constraints, then a Latent Encoder captures the global context of these merged words by full-attention blocks. Symmetrically employing a Latent Decoder and a Local Decoder, MergeDNA learns with two pre-training tasks: Merged Token Reconstruction simultaneously trains the dynamic tokenization module and adaptively filters important tokens, while Adaptive Masked Token Modeling learns to predict these filtered tokens to capture informative contents. Extensive experiments show that MergeDNA achieves superior performance on three popular DNA benchmarks and several multi-omics tasks with fine-tuning or zero-shot evaluation, outperforming typical tokenization methods and large-scale DNA foundation models.', 'abstract_zh': '基于Token合并技术的分层架构在基因组序列建模中的应用：自适应掩码令牌建模与上下文感知预训练任务', 'title_zh': 'MergeDNA：基于上下文的动态分词基因组建模'}
{'arxiv_id': 'arXiv:2511.14806', 'title': 'MergeDNA: Context-aware Genome Modeling with Dynamic Tokenization through Token Merging', 'authors': 'Siyuan Li, Kai Yu, Anna Wang, Zicheng Liu, Chang Yu, Jingbo Zhou, Qirong Yang, Yucheng Guo, Xiaoming Zhang, Stan Z. Li', 'link': 'https://arxiv.org/abs/2511.14806', 'abstract': 'Modeling genomic sequences faces two unsolved challenges: the information density varies widely across different regions, while there is no clearly defined minimum vocabulary unit. Relying on either four primitive bases or independently designed DNA tokenizers, existing approaches with naive masked language modeling pre-training often fail to adapt to the varying complexities of genomic sequences. Leveraging Token Merging techniques, this paper introduces a hierarchical architecture that jointly optimizes a dynamic genomic tokenizer and latent Transformers with context-aware pre-training tasks. As for network structures, the tokenization module automatically chunks adjacent bases into words by stacking multiple layers of the differentiable token merging blocks with local-window constraints, then a Latent Encoder captures the global context of these merged words by full-attention blocks. Symmetrically employing a Latent Decoder and a Local Decoder, MergeDNA learns with two pre-training tasks: Merged Token Reconstruction simultaneously trains the dynamic tokenization module and adaptively filters important tokens, while Adaptive Masked Token Modeling learns to predict these filtered tokens to capture informative contents. Extensive experiments show that MergeDNA achieves superior performance on three popular DNA benchmarks and several multi-omics tasks with fine-tuning or zero-shot evaluation, outperforming typical tokenization methods and large-scale DNA foundation models.', 'abstract_zh': '基于基因组序列建模面临两大未解挑战：不同区域的信息密度差异广泛，且缺乏明确的最小词汇单元。现有依赖四个基本碱基或独立设计的DNA分词器的方法，常采用简单的掩码语言模型预训练，往往难以适应基因组序列的 varying complexities。利用分词合并技术，本文提出一种分层架构，联合优化动态基因组分词器和上下文感知的潜在Transformer，并采用全注意力模块进行预训练任务。网络结构方面，分词模块通过多层可微分分词合并块自动将连续的碱基切分成词，并在局部窗口约束下进行堆叠；随后，潜在编码器使用全注意机制捕捉这些合并词的全局上下文。对称地采用潜在解码器和局部解码器，MergeDNA 通过两种预训练任务进行学习：合并词重构同时训练动态分词模块并自适应筛选重要词，而自适应掩码词建模则学习预测这些筛选词以捕捉有效信息。广泛的实验表明，MergeDNA 在三个流行的DNA基准测试以及多种多组学任务上，通过微调或零样本评估均表现出优越性能，优于典型的分词方法和大规模DNA基础模型。', 'title_zh': 'MergeDNA：基于上下文的动态分词基因组建模'}
{'arxiv_id': 'arXiv:2511.14803', 'title': 'Scalable and Efficient Large-Scale Log Analysis with LLMs: An IT Software Support Case Study', 'authors': 'Pranjal Gupta, Karan Bhukar, Harshit Kumar, Seema Nagar, Prateeti Mohapatra, Debanjana Kar', 'link': 'https://arxiv.org/abs/2511.14803', 'abstract': 'IT environments typically have logging mechanisms to monitor system health and detect issues. However, the huge volume of generated logs makes manual inspection impractical, highlighting the importance of automated log analysis in IT Software Support. In this paper, we propose a log analytics tool that leverages Large Language Models (LLMs) for log data processing and issue diagnosis, enabling the generation of automated insights and summaries. We further present a novel approach for efficiently running LLMs on CPUs to process massive log volumes in minimal time without compromising output quality. We share the insights and lessons learned from deployment of the tool - in production since March 2024 - scaled across 70 software products, processing over 2000 tickets for issue diagnosis, achieving a time savings of 300+ man hours and an estimated $15,444 per month in manpower costs compared to the traditional log analysis practices.', 'abstract_zh': 'IT环境通常具有日志记录机制以监控系统健康状况并检测问题。然而，生成的日志量巨大，使得手动检查变得 impractical，突显了自动化日志分析在IT软件支持中的重要性。本文提出了一种日志分析工具，该工具利用大型语言模型（LLMs）处理日志数据并诊断问题，从而生成自动化见解和摘要。我们还介绍了高效在CPU上运行LLMs以在最短时间内处理大量日志数据的方法，同时不牺牲输出质量。我们分享了该工具从2024年3月在生产环境中部署以来的经验和教训，该工具已扩展到70个软件产品，处理超过2000个问题诊断票，节省了300多个工时，并估计与传统日志分析实践相比，每月节省了15,444美元的人力成本。', 'title_zh': '使用大规模语言模型进行可扩展和高效的大规模日志分析：一个IT软件支持案例研究'}
{'arxiv_id': 'arXiv:2511.14805', 'title': 'Towards Continuous Assurance with Formal Verification and Assurance Cases', 'authors': 'Dhaminda B. Abeywickrama, Michael Fisher, Frederic Wheeler, Louise Dennis', 'link': 'https://arxiv.org/abs/2511.14805', 'abstract': 'Autonomous systems must sustain justified confidence in their correctness and safety across their operational lifecycle-from design and deployment through post-deployment evolution. Traditional assurance methods often separate development-time assurance from runtime assurance, yielding fragmented arguments that cannot adapt to runtime changes or system updates - a significant challenge for assured autonomy. Towards addressing this, we propose a unified Continuous Assurance Framework that integrates design-time, runtime, and evolution-time assurance within a traceable, model-driven workflow as a step towards assured autonomy. In this paper, we specifically instantiate the design-time phase of the framework using two formal verification methods: RoboChart for functional correctness and PRISM for probabilistic risk analysis. We also propose a model-driven transformation pipeline, implemented as an Eclipse plugin, that automatically regenerates structured assurance arguments whenever formal specifications or their verification results change, thereby ensuring traceability. We demonstrate our approach on a nuclear inspection robot scenario, and discuss its alignment with the Trilateral AI Principles, reflecting regulator-endorsed best practices.', 'abstract_zh': '自主系统在其整个运行生命周期中，从设计和部署到部署后的发展，必须维持合理的正确性和安全性的信心。传统的保证方法通常将开发时的保证与运行时的保证分离，导致无法适应运行时变化或系统更新的分离论证，这对受保障的自主性构成了重大挑战。为应对这一挑战，我们提出了一种统一的连续保证框架，将设计时、运行时和演化时的保证集成到可追溯的、基于模型的工作流中，作为迈向受保障自主性的一步。在本文中，我们具体使用两种形式化验证方法——RoboChart用于功能正确性，PRISM用于概率风险分析——来实例化框架的设计时阶段。我们还提出了一种基于模型的转换管道，将其实现为Eclipse插件，每当形式化规范或其验证结果发生变化时，自动重新生成结构化的保证论证，以确保可追溯性。我们以一个核检验机器人场景展示了我们的方法，并讨论了其与三角双方AI原则的一致性，反映了监管机构认可的最佳实践。', 'title_zh': '持续保障下的形式验证与保障案研究'}
{'arxiv_id': 'arXiv:2511.14805', 'title': 'Towards Continuous Assurance with Formal Verification and Assurance Cases', 'authors': 'Dhaminda B. Abeywickrama, Michael Fisher, Frederic Wheeler, Louise Dennis', 'link': 'https://arxiv.org/abs/2511.14805', 'abstract': 'Autonomous systems must sustain justified confidence in their correctness and safety across their operational lifecycle-from design and deployment through post-deployment evolution. Traditional assurance methods often separate development-time assurance from runtime assurance, yielding fragmented arguments that cannot adapt to runtime changes or system updates - a significant challenge for assured autonomy. Towards addressing this, we propose a unified Continuous Assurance Framework that integrates design-time, runtime, and evolution-time assurance within a traceable, model-driven workflow as a step towards assured autonomy. In this paper, we specifically instantiate the design-time phase of the framework using two formal verification methods: RoboChart for functional correctness and PRISM for probabilistic risk analysis. We also propose a model-driven transformation pipeline, implemented as an Eclipse plugin, that automatically regenerates structured assurance arguments whenever formal specifications or their verification results change, thereby ensuring traceability. We demonstrate our approach on a nuclear inspection robot scenario, and discuss its alignment with the Trilateral AI Principles, reflecting regulator-endorsed best practices.', 'abstract_zh': '自主系统必须在其整个运营生命周期中——从设计和部署到部署后的演化——持续维持其正确性和安全性的正当信心。传统的保障方法往往将开发时的保障与运行时的保障分开，导致碎片化的论证，无法适应运行时的变化或系统更新——这对保障自主性构成了重大挑战。为了解决这一问题，我们提出了一种统一的持续保障框架，将设计时、运行时和演化时的保障整合在一个可追踪、模型驱动的工作流中，作为向保障自主性迈出的一步。在这篇论文中，我们使用两种形式验证方法（RoboChart和PRISM）具体实现该框架的设计时阶段，并提出了一个模型驱动的转换管道，作为Eclipse插件实现，能够在形式规范或其验证结果发生变化时自动再生结构化的保障论证，从而确保可追踪性。我们通过一个核检验机器人情景展示了我们的方法，并讨论了其与三方AI原则的一致性，反映了监管机构认可的最佳实践。', 'title_zh': '基于形式验证与保证案例的持续保障方法'}
{'arxiv_id': 'arXiv:2511.14803', 'title': 'Scalable and Efficient Large-Scale Log Analysis with LLMs: An IT Software Support Case Study', 'authors': 'Pranjal Gupta, Karan Bhukar, Harshit Kumar, Seema Nagar, Prateeti Mohapatra, Debanjana Kar', 'link': 'https://arxiv.org/abs/2511.14803', 'abstract': 'IT environments typically have logging mechanisms to monitor system health and detect issues. However, the huge volume of generated logs makes manual inspection impractical, highlighting the importance of automated log analysis in IT Software Support. In this paper, we propose a log analytics tool that leverages Large Language Models (LLMs) for log data processing and issue diagnosis, enabling the generation of automated insights and summaries. We further present a novel approach for efficiently running LLMs on CPUs to process massive log volumes in minimal time without compromising output quality. We share the insights and lessons learned from deployment of the tool - in production since March 2024 - scaled across 70 software products, processing over 2000 tickets for issue diagnosis, achieving a time savings of 300+ man hours and an estimated $15,444 per month in manpower costs compared to the traditional log analysis practices.', 'abstract_zh': 'IT环境通常具有日志记录机制以监控系统健康状况和检测问题。然而，大量生成的日志使得手动检查不切实际，突显了自动日志分析在IT软件支持中的重要性。本文提出一种利用大规模语言模型（LLMs）进行日志数据处理和问题诊断的日志分析工具，能够生成自动化的见解和摘要。我们还提出了一个新颖的方法，用于在CPU上高效运行LLMs，以在不影响输出质量的情况下处理大量日志数据并在最短时间内完成处理。我们分享了该工具自2024年3月在生产环境中部署以来的部署见解和经验教训，该工具已扩展到70个软件产品，处理了超过2000张问题诊断票证，节省了300多个工时，并与传统的日志分析实践相比，每月节省了约15,444美元的人力成本。', 'title_zh': '大规模日志分析中基于LLM的可扩展和高效方法：一项IT软件支持案例研究'}
{'arxiv_id': 'arXiv:2511.14798', 'title': 'Evaluating Generative AI for CS1 Code Grading: Direct vs Reverse Methods', 'authors': 'Ahmad Memon, Abdallah Mohamed', 'link': 'https://arxiv.org/abs/2511.14798', 'abstract': "Manual grading of programming assignments in introductory computer science courses can be time-consuming and prone to inconsistencies. While unit testing is commonly used for automatic evaluation, it typically follows a binary pass/fail model and does not give partial marks. Recent advances in large language models (LLMs) offer the potential for automated, scalable, and more objective grading.\nThis paper compares two AI-based grading techniques: \\textit{Direct}, where the AI model applies a rubric directly to student code, and \\textit{Reverse} (a newly proposed approach), where the AI first fixes errors, then deduces a grade based on the nature and number of fixes. Each method was evaluated on both the instructor's original grading scale and a tenfold expanded scale to assess the impact of range on AI grading accuracy. To assess their effectiveness, AI-assigned scores were evaluated against human tutor evaluations on a range of coding problems and error types.\nInitial findings suggest that while the Direct approach is faster and straightforward, the Reverse technique often provides a more fine-grained assessment by focusing on correction effort. Both methods require careful prompt engineering, particularly for allocating partial credit and handling logic errors. To further test consistency, we also used synthetic student code generated using Gemini Flash 2.0, which allowed us to evaluate AI graders on a wider range of controlled error types and difficulty levels. We discuss the strengths and limitations of each approach, practical considerations for prompt design, and future directions for hybrid human-AI grading systems that aim to improve consistency, efficiency, and fairness in CS courses.", 'abstract_zh': '手动评估入门计算机科学课程中的编程作业耗时且容易出现不一致性。虽然单元测试常用于自动化评估，但它通常遵循通过/未通过的二元模型，不提供部分分数。最近的大规模语言模型（LLMs）发展为自动、可扩展且更客观的评估提供了潜力。\n\n本文比较了两种基于AI的评分技术：\\textit{Direct}，AI模型直接应用评分 rubric 至学生代码；和 \\textit{Reverse}（一种新提出的方案），AI 首先修正错误，然后根据修正的性质和数量推导分数。每种方法分别在教师原始评分标准和扩大十倍的评分标准上进行了评估，以考察评分范围对AI评分准确性的影响。通过评估AI分配的分数与人类导师评价的差异，测试了它们的有效性。\n\n初步发现表明，虽然 Direct 方法更快且直观，但 Reverse 技术往往能通过关注修正努力提供更精细的评估。两种方法都要求仔细设计提示，特别是对于分配部分分数和处理逻辑错误的需求。为了进一步测试一致性，我们还使用了使用 Gemini Flash 2.0 生成的合成学生代码，这使我们能够评估AI评分器在更广泛的受控错误类型和难度级别的表现。我们讨论了每种方法的优势和局限性、提示设计的实用考虑以及混合人类-AI评分系统的发展方向，这些系统旨在提高计算机科学课程中的评分一致性和公平性。', 'title_zh': '评估生成式AI在CS1代码批改中的效果：直接方法 vs 逆向方法'}
{'arxiv_id': 'arXiv:2511.14803', 'title': 'Scalable and Efficient Large-Scale Log Analysis with LLMs: An IT Software Support Case Study', 'authors': 'Pranjal Gupta, Karan Bhukar, Harshit Kumar, Seema Nagar, Prateeti Mohapatra, Debanjana Kar', 'link': 'https://arxiv.org/abs/2511.14803', 'abstract': 'IT environments typically have logging mechanisms to monitor system health and detect issues. However, the huge volume of generated logs makes manual inspection impractical, highlighting the importance of automated log analysis in IT Software Support. In this paper, we propose a log analytics tool that leverages Large Language Models (LLMs) for log data processing and issue diagnosis, enabling the generation of automated insights and summaries. We further present a novel approach for efficiently running LLMs on CPUs to process massive log volumes in minimal time without compromising output quality. We share the insights and lessons learned from deployment of the tool - in production since March 2024 - scaled across 70 software products, processing over 2000 tickets for issue diagnosis, achieving a time savings of 300+ man hours and an estimated $15,444 per month in manpower costs compared to the traditional log analysis practices.', 'abstract_zh': 'IT环境通常具有日志记录机制以监控系统健康状况和检测问题。然而，生成的日志量巨大，使得人工检查变得不切实际，突显了自动化日志分析在IT软件支持中的重要性。本文提出了一种利用大型语言模型（LLMs）进行日志数据处理和问题诊断的日志分析工具，能够生成自动化见解和摘要。此外，我们还提出了一种高效在CPU上运行LLMs的方法，以在最少的时间内处理大量日志数据而不牺牲输出质量。我们分享了该工具部署期间的见解和经验教训——该工具自2024年3月以来在70个软件产品中运行，并处理了超过2000个问题诊断工单，实现了300多个工时的节省，以及每月约15,444美元的人力成本节约，相较于传统的日志分析方法。', 'title_zh': '大规模日志分析中的可扩展性和高效性：基于LLM的IT软件支持案例研究'}
{'arxiv_id': 'arXiv:2511.14798', 'title': 'Evaluating Generative AI for CS1 Code Grading: Direct vs Reverse Methods', 'authors': 'Ahmad Memon, Abdallah Mohamed', 'link': 'https://arxiv.org/abs/2511.14798', 'abstract': "Manual grading of programming assignments in introductory computer science courses can be time-consuming and prone to inconsistencies. While unit testing is commonly used for automatic evaluation, it typically follows a binary pass/fail model and does not give partial marks. Recent advances in large language models (LLMs) offer the potential for automated, scalable, and more objective grading.\nThis paper compares two AI-based grading techniques: \\textit{Direct}, where the AI model applies a rubric directly to student code, and \\textit{Reverse} (a newly proposed approach), where the AI first fixes errors, then deduces a grade based on the nature and number of fixes. Each method was evaluated on both the instructor's original grading scale and a tenfold expanded scale to assess the impact of range on AI grading accuracy. To assess their effectiveness, AI-assigned scores were evaluated against human tutor evaluations on a range of coding problems and error types.\nInitial findings suggest that while the Direct approach is faster and straightforward, the Reverse technique often provides a more fine-grained assessment by focusing on correction effort. Both methods require careful prompt engineering, particularly for allocating partial credit and handling logic errors. To further test consistency, we also used synthetic student code generated using Gemini Flash 2.0, which allowed us to evaluate AI graders on a wider range of controlled error types and difficulty levels. We discuss the strengths and limitations of each approach, practical considerations for prompt design, and future directions for hybrid human-AI grading systems that aim to improve consistency, efficiency, and fairness in CS courses.", 'abstract_zh': '基于人工智能的编程作业手工评分在入门级计算机科学课程中耗时且容易出现不一致性。虽然单元测试常用于自动评估，但通常采用通过/未通过的二元模型，无法给出部分分数。最近大规模语言模型的进步提供了实现自动、可扩展且更具客观性的评分的潜力。本文比较了两种基于人工智能的评分技术：直接评分（Direct），即AI模型直接应用评分标准到学生代码；反向评分（Reverse），这是一种新提出的策略，首先修正错误，然后根据修复的性质和数量来推断分数。每种方法分别在教师原始评分标准和扩展十倍的评分标准上进行了评估，以考察评分范围对AI评分准确性的影响。通过将AI分配的分数与人类导师评估的分数进行比对，全面评估了这两种方法在不同编程问题和错误类型上的效果。初步发现表明，虽然直接评分方式更快且简单，但反向评分通常能通过关注纠错努力来提供更细致的评估。两种方法均需要精心设计提示，特别是在分配部分分数和处理逻辑错误方面。为了进一步测试一致性，我们还使用了由Gemini Flash 2.0生成的合成学生代码，以对各种控制错误类型和难度级别进行评估。我们讨论了每种方法的优势和局限性，提示设计的实用考虑，以及旨在提高计算机科学课程中评分一致性和公平性的混合人机评分系统的未来方向。', 'title_zh': '评估生成式AI在CS1代码评分中的效果：直接方法 vs 反向方法'}
{'arxiv_id': 'arXiv:2511.14796', 'title': 'Opinion Mining and Analysis Using Hybrid Deep Neural Networks', 'authors': 'Adel Hidri, Suleiman Ali Alsaif, Muteeb Alahmari, Eman AlShehri, Minyar Sassi Hidri', 'link': 'https://arxiv.org/abs/2511.14796', 'abstract': 'Understanding customer attitudes has become a critical component of decision-making due to the growing influence of social media and e-commerce. Text-based opinions are the most structured, hence playing an important role in sentiment analysis. Most of the existing methods, which include lexicon-based approaches and traditional machine learning techniques, are insufficient for handling contextual nuances and scalability. While the latter has limitations in model performance and generalization, deep learning (DL) has achieved improvement, especially on semantic relationship capturing with recurrent neural networks (RNNs) and convolutional neural networks (CNNs). The aim of the study is to enhance opinion mining by introducing a hybrid deep neural network model that combines a bidirectional gated recurrent unit (BGRU) and long short-term memory (LSTM) layers to improve sentiment analysis, particularly addressing challenges such as contextual nuance, scalability, and class imbalance. To substantiate the efficacy of the proposed model, we conducted comprehensive experiments utilizing benchmark datasets, encompassing IMDB movie critiques and Amazon product evaluations. The introduced hybrid BGRULSTM (HBGRU-LSTM) architecture attained a testing accuracy of 95%, exceeding the performance of traditional DL frameworks such as LSTM (93.06%), CNN+LSTM (93.31%), and GRU+LSTM (92.20%). Moreover, our model exhibited a noteworthy enhancement in recall for negative sentiments, escalating from 86% (unbalanced dataset) to 96% (balanced dataset), thereby ensuring a more equitable and just sentiment classification. Furthermore, the model diminished misclassification loss from 20.24% for unbalanced to 13.3% for balanced dataset, signifying enhanced generalization and resilience.', 'abstract_zh': '理解客户态度已成为决策的关键组成部分，随着社交媒体和电子商务影响力的增长，文本基意见在情感分析中起着重要作用。尽管大多数现有方法，包括词典方法和传统机器学习技术，在处理语境细微差异和扩展性方面存在不足，深度学习（DL），尤其是循环神经网络（RNN）和卷积神经网络（CNN）在语义关系捕获方面取得了进展。本研究旨在通过引入结合双向门控循环单元（BGRU）和长短期记忆（LSTM）层的混合深度神经网络模型来增强意见挖掘，特别是在处理细微语境、扩展性和类别不平衡等挑战方面。通过使用基准数据集（包括IMDB电影评论和Amazon产品评价）进行全面实验，证明了所提出模型的有效性。所引入的混合BGRU-LSTM（HBGRU-LSTM）架构在测试集上的准确率为95%，超过了传统DL框架（如LSTM的93.06%、CNN+LSTM的93.31%和GRU+LSTM的92.20%）。此外，模型在负面情感召回上的提升尤为显著，从不平衡数据集的86%提高到平衡数据集的96%，从而确保了更公平和公正的情感分类。同时，模型的误分类损失从不平衡数据集的20.24%降低到平衡数据集的13.3%，显示出更好的泛化能力和鲁棒性。', 'title_zh': '基于混合深度神经网络的意见挖掘与分析'}
{'arxiv_id': 'arXiv:2511.14798', 'title': 'Evaluating Generative AI for CS1 Code Grading: Direct vs Reverse Methods', 'authors': 'Ahmad Memon, Abdallah Mohamed', 'link': 'https://arxiv.org/abs/2511.14798', 'abstract': "Manual grading of programming assignments in introductory computer science courses can be time-consuming and prone to inconsistencies. While unit testing is commonly used for automatic evaluation, it typically follows a binary pass/fail model and does not give partial marks. Recent advances in large language models (LLMs) offer the potential for automated, scalable, and more objective grading.\nThis paper compares two AI-based grading techniques: \\textit{Direct}, where the AI model applies a rubric directly to student code, and \\textit{Reverse} (a newly proposed approach), where the AI first fixes errors, then deduces a grade based on the nature and number of fixes. Each method was evaluated on both the instructor's original grading scale and a tenfold expanded scale to assess the impact of range on AI grading accuracy. To assess their effectiveness, AI-assigned scores were evaluated against human tutor evaluations on a range of coding problems and error types.\nInitial findings suggest that while the Direct approach is faster and straightforward, the Reverse technique often provides a more fine-grained assessment by focusing on correction effort. Both methods require careful prompt engineering, particularly for allocating partial credit and handling logic errors. To further test consistency, we also used synthetic student code generated using Gemini Flash 2.0, which allowed us to evaluate AI graders on a wider range of controlled error types and difficulty levels. We discuss the strengths and limitations of each approach, practical considerations for prompt design, and future directions for hybrid human-AI grading systems that aim to improve consistency, efficiency, and fairness in CS courses.", 'abstract_zh': '基于人工评分的编程作业在入门计算机科学课程中耗时且容易出现不一致。虽然单元测试常用于自动评估，但通常遵循通过/未通过的二元模型，并不提供部分分数。大型语言模型的最新进展为自动化、可扩展和更客观的评分提供了潜力。\n\n本文比较了两种基于AI的评分技术：直接评分，即AI模型直接应用评分标准到学生代码；以及逆向评分（一种新提出的策略），即AI先修复错误，然后根据修复的数量和性质来推断分数。每种方法在教师原始评分标准和扩展十倍的评分标准上进行了评估，以考察评分范围对AI评分准确度的影响。为了评估其有效性，AI分配的分数与人类导师对各种编码问题和错误类型的评估进行了比较。\n\n初步发现表明，虽然直接评分方法更快且简单，但逆向评分方法通常通过关注修正努力提供了更为细致的评估。两种方法都需要精心设计提示工程，尤其是对于分配部分分数和处理逻辑错误的处理。为了进一步测试一致性，我们还使用了使用Gemini Flash 2.0生成的合成学生代码，这使我们能够对AI评分器进行更广泛的控制错误类型和难度级别的评估。我们讨论了每种方法的优势和局限性，提示设计的实用考虑，以及未来混合人类-AI评分系统的方向，旨在提高计算机科学课程中的评分一致性和公平性。', 'title_zh': '评价生成式AI在CS1代码评分中的效果：直接方法 vs 逆向方法'}
{'arxiv_id': 'arXiv:2511.14796', 'title': 'Opinion Mining and Analysis Using Hybrid Deep Neural Networks', 'authors': 'Adel Hidri, Suleiman Ali Alsaif, Muteeb Alahmari, Eman AlShehri, Minyar Sassi Hidri', 'link': 'https://arxiv.org/abs/2511.14796', 'abstract': 'Understanding customer attitudes has become a critical component of decision-making due to the growing influence of social media and e-commerce. Text-based opinions are the most structured, hence playing an important role in sentiment analysis. Most of the existing methods, which include lexicon-based approaches and traditional machine learning techniques, are insufficient for handling contextual nuances and scalability. While the latter has limitations in model performance and generalization, deep learning (DL) has achieved improvement, especially on semantic relationship capturing with recurrent neural networks (RNNs) and convolutional neural networks (CNNs). The aim of the study is to enhance opinion mining by introducing a hybrid deep neural network model that combines a bidirectional gated recurrent unit (BGRU) and long short-term memory (LSTM) layers to improve sentiment analysis, particularly addressing challenges such as contextual nuance, scalability, and class imbalance. To substantiate the efficacy of the proposed model, we conducted comprehensive experiments utilizing benchmark datasets, encompassing IMDB movie critiques and Amazon product evaluations. The introduced hybrid BGRULSTM (HBGRU-LSTM) architecture attained a testing accuracy of 95%, exceeding the performance of traditional DL frameworks such as LSTM (93.06%), CNN+LSTM (93.31%), and GRU+LSTM (92.20%). Moreover, our model exhibited a noteworthy enhancement in recall for negative sentiments, escalating from 86% (unbalanced dataset) to 96% (balanced dataset), thereby ensuring a more equitable and just sentiment classification. Furthermore, the model diminished misclassification loss from 20.24% for unbalanced to 13.3% for balanced dataset, signifying enhanced generalization and resilience.', 'abstract_zh': '理解顾客态度已成为决策的关键组成部分，鉴于社交媒体和电子商务影响力的日益增强。基于文本的意见是最结构化的，因此在情感分析中发挥着重要作用。现有的大多数方法，包括词汇学方法和传统的机器学习技术，对于处理语境细微差别和规模化存在不足。虽然后者在模型性能和泛化方面有所局限，深度学习（DL），尤其是使用递归神经网络（RNNs）和卷积神经网络（CNNs）捕捉语义关系方面取得了进步。本研究旨在通过引入结合双向门控递归单元（BGRU）和长短期记忆（LSTM）层的混合深度神经网络模型来提升意见挖掘，特别是解决语境细微差别、规模化和类别不平衡等问题。为了证明所提模型的有效性，我们使用IMDB电影评论和亚马逊产品评价等基准数据集进行了全面实验。所引入的混合BGRU-LSTM（HBGRU-LSTM）架构达到95%的测试准确率，超越了传统的DL框架，如LSTM（93.06%）、CNN+LSTM（93.31%）和GRU+LSTM（92.20%）。此外，我们的模型在负面情绪的召回率上表现显著提升，从不均衡数据集的86%提升到均衡数据集的96%。这确保了更公平合理的评价分类。同时，模型的误分类损失从不均衡数据集的20.24%降低到均衡数据集的13.3%，表明了更好的泛化能力和鲁棒性。', 'title_zh': '基于混合深度神经网络的情感分析与挖掘'}
{'arxiv_id': 'arXiv:2511.14794', 'title': 'irace-evo: Automatic Algorithm Configuration Extended With LLM-Based Code Evolution', 'authors': 'Camilo Chacón Sartori, Christian Blum', 'link': 'https://arxiv.org/abs/2511.14794', 'abstract': 'Automatic algorithm configuration tools such as irace efficiently tune parameter values but leave algorithmic code unchanged. This paper introduces a first version of irace-evo, an extension of irace that integrates code evolution through large language models (LLMs) to jointly explore parameter and code spaces. The proposed framework enables multi-language support (e.g., C++, Python), reduces token consumption via progressive context management, and employs the Always-From-Original principle to ensure robust and controlled code evolution. We evaluate irace-evo on the Construct, Merge, Solve & Adapt (CMSA) metaheuristic for the Variable-Sized Bin Packing Problem (VSBPP). Experimental results show that irace-evo can discover new algorithm variants that outperform the state-of-the-art CMSA implementation while maintaining low computational and monetary costs. Notably, irace-evo generates competitive algorithmic improvements using lightweight models (e.g., Claude Haiku 3.5) with a total usage cost under 2 euros. These results demonstrate that coupling automatic configuration with LLM-driven code evolution provides a powerful, cost-efficient avenue for advancing heuristic design and metaheuristic optimization.', 'abstract_zh': '自动算法配置工具如irace可以有效调整参数值但保留算法代码不变。本文介绍了irace-evo的第一个版本，这是一种扩展irace的功能，通过大型语言模型（LLMs）整合代码演化，同时探索参数和代码空间的框架。该提出的框架支持多语言（如C++、Python），通过渐进式上下文管理减少令牌消耗，并采用始终从原始代码原则确保代码演化的稳健性和可控性。我们使用变长Bin装箱问题（VSBPP）的元启发式CMSA对其进行评估。实验结果表明，irace-evo可以发现超越现有最佳CMSA实现的新算法变体，同时保持较低的计算和经济成本。值得注意的是，irace-evo使用轻量级模型（例如Claude Haiku 3.5）生成具有总使用费用低于2欧元的竞争性算法改进。这些结果证明，将自动配置与LLM驱动的代码演化结合是一种强大的、成本效益高的途径，可以促进启发式设计和元启发式优化的发展。', 'title_zh': 'irace-evo：扩展了基于LLM的代码进化自动算法配置'}
{'arxiv_id': 'arXiv:2511.14796', 'title': 'Opinion Mining and Analysis Using Hybrid Deep Neural Networks', 'authors': 'Adel Hidri, Suleiman Ali Alsaif, Muteeb Alahmari, Eman AlShehri, Minyar Sassi Hidri', 'link': 'https://arxiv.org/abs/2511.14796', 'abstract': 'Understanding customer attitudes has become a critical component of decision-making due to the growing influence of social media and e-commerce. Text-based opinions are the most structured, hence playing an important role in sentiment analysis. Most of the existing methods, which include lexicon-based approaches and traditional machine learning techniques, are insufficient for handling contextual nuances and scalability. While the latter has limitations in model performance and generalization, deep learning (DL) has achieved improvement, especially on semantic relationship capturing with recurrent neural networks (RNNs) and convolutional neural networks (CNNs). The aim of the study is to enhance opinion mining by introducing a hybrid deep neural network model that combines a bidirectional gated recurrent unit (BGRU) and long short-term memory (LSTM) layers to improve sentiment analysis, particularly addressing challenges such as contextual nuance, scalability, and class imbalance. To substantiate the efficacy of the proposed model, we conducted comprehensive experiments utilizing benchmark datasets, encompassing IMDB movie critiques and Amazon product evaluations. The introduced hybrid BGRULSTM (HBGRU-LSTM) architecture attained a testing accuracy of 95%, exceeding the performance of traditional DL frameworks such as LSTM (93.06%), CNN+LSTM (93.31%), and GRU+LSTM (92.20%). Moreover, our model exhibited a noteworthy enhancement in recall for negative sentiments, escalating from 86% (unbalanced dataset) to 96% (balanced dataset), thereby ensuring a more equitable and just sentiment classification. Furthermore, the model diminished misclassification loss from 20.24% for unbalanced to 13.3% for balanced dataset, signifying enhanced generalization and resilience.', 'abstract_zh': '理解客户态度已成为决策的关键组成部分，尤其是随着社交媒体和电子商务影响力的增强。基于文本的意见是最结构化的，因此在情感分析中发挥着重要作用。尽管现有的方法，包括基于词典的方法和传统的机器学习技术，在处理上下文细微差别和可扩展性方面存在不足，深度学习（DL），特别是循环神经网络（RNN）和卷积神经网络（CNN）在捕捉语义关系方面取得了进展。本研究旨在通过引入结合双向门控循环单元（BGRU）和长短期记忆（LSTM）层的混合深度神经网络模型来增强意见挖掘，特别关注上下文细微差别、可扩展性和类别不平衡等挑战。为了证明所提出模型的有效性，我们使用基准数据集（包括IMDB电影评论和亚马逊产品评价）进行了全面实验。所引入的混合BGRU-LSTM架构测试准确率达到95%，超过传统的DL框架，如LSTM（93.06%）、CNN+LSTM（93.31%）和GRU+LSTM（92.20%）。此外，我们的模型在负面情感的召回率方面表现出显著提升，从不平衡数据集的86%提高到平衡数据集的96%，从而确保了更公平公正的情感分类。此外，模型将错误分类损失从不平衡数据集的20.24%降低到平衡数据集的13.3%，表明其增强了泛化能力和鲁棒性。', 'title_zh': '基于混合深度神经网络的情感分析与挖掘'}
{'arxiv_id': 'arXiv:2511.14794', 'title': 'irace-evo: Automatic Algorithm Configuration Extended With LLM-Based Code Evolution', 'authors': 'Camilo Chacón Sartori, Christian Blum', 'link': 'https://arxiv.org/abs/2511.14794', 'abstract': 'Automatic algorithm configuration tools such as irace efficiently tune parameter values but leave algorithmic code unchanged. This paper introduces a first version of irace-evo, an extension of irace that integrates code evolution through large language models (LLMs) to jointly explore parameter and code spaces. The proposed framework enables multi-language support (e.g., C++, Python), reduces token consumption via progressive context management, and employs the Always-From-Original principle to ensure robust and controlled code evolution. We evaluate irace-evo on the Construct, Merge, Solve & Adapt (CMSA) metaheuristic for the Variable-Sized Bin Packing Problem (VSBPP). Experimental results show that irace-evo can discover new algorithm variants that outperform the state-of-the-art CMSA implementation while maintaining low computational and monetary costs. Notably, irace-evo generates competitive algorithmic improvements using lightweight models (e.g., Claude Haiku 3.5) with a total usage cost under 2 euros. These results demonstrate that coupling automatic configuration with LLM-driven code evolution provides a powerful, cost-efficient avenue for advancing heuristic design and metaheuristic optimization.', 'abstract_zh': '自动算法配置工具如irace可以高效地调整参数值但不会改变算法代码。本文介绍了irace-evo的第一个版本，这是一种将代码进化通过大型语言模型（LLMs）集成到irace中的扩展，旨在同时探索参数空间和代码空间。提出的框架支持多语言（如C++、Python），通过渐进式上下文管理减少令牌消耗，并采用“始终使用原始代码”原则以确保代码进化的稳健性和可控性。我们使用Construct, Merge, Solve & Adapt (CMSA) 元启发式算法对Variable-Sized Bin Packing Problem (VSBPP) 进行评估。实验结果表明，irace-evo可以发现优于现有最佳CMSA实现的新算法变体，同时保持较低的计算和经济成本。值得注意的是，irace-evo使用轻量级模型（如Claude Haiku 3.5）生成具有竞争力的算法改进，总使用成本低于2欧元。这些结果表明，自动配置与LLM驱动的代码进化相结合为启发式设计和元启发式优化提供了强有力、成本效益高的路径。', 'title_zh': 'irace-evo：集成基于LLM的代码进化自动算法配置'}
{'arxiv_id': 'arXiv:2511.14792', 'title': 'Application of Graph Based Vision Transformers Architectures for Accurate Temperature Prediction in Fiber Specklegram Sensors', 'authors': 'Abhishek Sebastian', 'link': 'https://arxiv.org/abs/2511.14792', 'abstract': 'Fiber Specklegram Sensors (FSS) are highly effective for environmental monitoring, particularly for detecting temperature variations. However, the nonlinear nature of specklegram data presents significant challenges for accurate temperature prediction. This study investigates the use of transformer-based architectures, including Vision Transformers (ViTs), Swin Transformers, and emerging models such as Learnable Importance Non-Symmetric Attention Vision Transformers (LINA-ViT) and Multi-Adaptive Proximity Vision Graph Attention Transformers (MAP-ViGAT), to predict temperature from specklegram data over a range of 0 to 120 Celsius. The results show that ViTs achieved a Mean Absolute Error (MAE) of 1.15, outperforming traditional models such as CNNs. GAT-ViT and MAP-ViGAT variants also demonstrated competitive accuracy, highlighting the importance of adaptive attention mechanisms and graph-based structures in capturing complex modal interactions and phase shifts in specklegram data. Additionally, this study incorporates Explainable AI (XAI) techniques, including attention maps and saliency maps, to provide insights into the decision-making processes of the transformer models, improving interpretability and transparency. These findings establish transformer architectures as strong benchmarks for optical fiber-based temperature sensing and offer promising directions for industrial monitoring and structural health assessment applications.', 'abstract_zh': '基于光纤斑纹图传感器的变压器架构在温度预测中的应用：解释性人工智能技术的集成', 'title_zh': '基于图卷积视觉变换器架构在光纤斑图传感器中精确温度预测的应用'}
{'arxiv_id': 'arXiv:2511.14794', 'title': 'irace-evo: Automatic Algorithm Configuration Extended With LLM-Based Code Evolution', 'authors': 'Camilo Chacón Sartori, Christian Blum', 'link': 'https://arxiv.org/abs/2511.14794', 'abstract': 'Automatic algorithm configuration tools such as irace efficiently tune parameter values but leave algorithmic code unchanged. This paper introduces a first version of irace-evo, an extension of irace that integrates code evolution through large language models (LLMs) to jointly explore parameter and code spaces. The proposed framework enables multi-language support (e.g., C++, Python), reduces token consumption via progressive context management, and employs the Always-From-Original principle to ensure robust and controlled code evolution. We evaluate irace-evo on the Construct, Merge, Solve & Adapt (CMSA) metaheuristic for the Variable-Sized Bin Packing Problem (VSBPP). Experimental results show that irace-evo can discover new algorithm variants that outperform the state-of-the-art CMSA implementation while maintaining low computational and monetary costs. Notably, irace-evo generates competitive algorithmic improvements using lightweight models (e.g., Claude Haiku 3.5) with a total usage cost under 2 euros. These results demonstrate that coupling automatic configuration with LLM-driven code evolution provides a powerful, cost-efficient avenue for advancing heuristic design and metaheuristic optimization.', 'abstract_zh': '自动算法配置工具如irace能够高效调整参数值但不改变算法代码。本文介绍了irace-evo，这是一种扩展了irace并借助大型语言模型（LLMs）实现代码进化的初步版本，旨在联合探索参数空间和代码空间。所提出的框架支持多语言（例如，C++、Python），通过渐进式上下文管理减少词汇消耗，并采用“始终来自原始代码”的原则以确保稳健和可控的代码进化。我们在可变大小的物品装箱问题（VSBPP）的元启发式方法（CMSA）中评估了irace-evo。实验结果表明，irace-evo能够发现超越当前最佳CMSA实现的新算法变体，同时保持较低的计算和经济成本。值得注意的是，irace-evo使用轻量级模型（例如，Claude Haiku 3.5）即可生成具有竞争力的算法改进，总使用成本低于2欧元。这些结果证明，结合自动配置与LLM驱动的代码进化为启发式设计和元启发式优化提供了一种强大且成本效益高的途径。', 'title_zh': 'irace-evo：基于LLM的代码进化扩展的自动算法配置'}
{'arxiv_id': 'arXiv:2511.14791', 'title': 'Enabling Predictive Maintenance in District Heating Substations: A Labelled Dataset and Fault Detection Evaluation Framework based on Service Data', 'authors': 'Cyriana M.A. Roelofs, Edison Guevara Bastidas, Thomas Hugo, Stefan Faulstich, Anna Cadenbach', 'link': 'https://arxiv.org/abs/2511.14791', 'abstract': 'Early detection of faults in district heating substations is imperative to reduce return temperatures and enhance efficiency. However, progress in this domain has been hindered by the limited availability of public, labelled datasets. We present an open source framework combining a service report validated public dataset, an evaluation method based on Accuracy, Reliability, and Earliness, and baseline results implemented with EnergyFaultDetector, an open source Python framework.\nThe dataset contains time series of operational data from 93 substations across two manufacturers, annotated with a list of disturbances due to faults and maintenance actions, a set of normal-event examples and detailed fault metadata. We evaluate the EnergyFaultDetector using three metrics: Accuracy for recognising normal behaviour, an eventwise F Score for reliable fault detection with few false alarms, and Earliness for early detection. The framework also supports root cause analysis using ARCANA. We demonstrate three use cases to assist operators in interpreting anomalies and identifying underlying faults. The models achieve high normal-behaviour accuracy (0.98) and eventwise F-score (beta=0.5) of 0.83, detecting 60% of the faults in the dataset before the customer reports a problem, with an average lead time of 3.9 days.\nIntegrating an open dataset, metrics, open source code, and baselines establishes a reproducible, fault centric benchmark with operationally meaningful evaluation, enabling consistent comparison and development of early fault detection and diagnosis methods for district heating substations.', 'abstract_zh': '早期检测分布式热力 substations 中的故障对于降低返回温度和提高效率至关重要。然而，这一领域的发展受限于可用的公共标注数据集有限。我们提出一个开源框架，结合了一个经服务报告验证的公共数据集、基于准确率、可靠性和及时性的评估方法以及使用 EnergyFaultDetector 开源 Python 框架实现的基准结果。', 'title_zh': '基于服务数据的带标注数据集与故障检测评估框架 Enables Predictive Maintenance in District Heating Substations'}
{'arxiv_id': 'arXiv:2511.14792', 'title': 'Application of Graph Based Vision Transformers Architectures for Accurate Temperature Prediction in Fiber Specklegram Sensors', 'authors': 'Abhishek Sebastian', 'link': 'https://arxiv.org/abs/2511.14792', 'abstract': 'Fiber Specklegram Sensors (FSS) are highly effective for environmental monitoring, particularly for detecting temperature variations. However, the nonlinear nature of specklegram data presents significant challenges for accurate temperature prediction. This study investigates the use of transformer-based architectures, including Vision Transformers (ViTs), Swin Transformers, and emerging models such as Learnable Importance Non-Symmetric Attention Vision Transformers (LINA-ViT) and Multi-Adaptive Proximity Vision Graph Attention Transformers (MAP-ViGAT), to predict temperature from specklegram data over a range of 0 to 120 Celsius. The results show that ViTs achieved a Mean Absolute Error (MAE) of 1.15, outperforming traditional models such as CNNs. GAT-ViT and MAP-ViGAT variants also demonstrated competitive accuracy, highlighting the importance of adaptive attention mechanisms and graph-based structures in capturing complex modal interactions and phase shifts in specklegram data. Additionally, this study incorporates Explainable AI (XAI) techniques, including attention maps and saliency maps, to provide insights into the decision-making processes of the transformer models, improving interpretability and transparency. These findings establish transformer architectures as strong benchmarks for optical fiber-based temperature sensing and offer promising directions for industrial monitoring and structural health assessment applications.', 'abstract_zh': '光纤斑纹图传感器（FSS）在环境监测中尤其适用于检测温度变化。然而，斑纹图数据的非线性特性给准确的温度预测带来了重大挑战。本研究探讨了使用基于变压器的架构，包括视觉变压器（ViTs）、Swin Transformer以及新兴模型如可学习重要性非对称注意视觉变压器（LINA-ViT）和多适应邻近视觉图注意变压器（MAP-ViGAT），从0至120摄氏度范围内的斑纹图数据预测温度的有效性。结果表明，ViTs实现了平均绝对误差（MAE）为1.15，优于传统的模型如CNNs。GAT-ViT和MAP-ViGAT变体也展示了竞争力的表现，突出了适应性注意机制和基于图的结构在捕捉斑纹图数据中的复杂模式交互和相位移的重要性。此外，本研究还结合了可解释人工智能（XAI）技术，包括注意图和显著性图，以提供Transformer模型决策过程的见解，提高可解释性和透明度。这些发现为基于光纤的温度传感设立了变压器架构的强有力基准，并为工业监控和结构健康评估提供了有前景的研究方向。', 'title_zh': '基于图卷积视窗变换架构在纤维斑grams传感器中准确温度预测的应用'}
{'arxiv_id': 'arXiv:2511.14781', 'title': 'Quantifying the Role of OpenFold Components in Protein Structure Prediction', 'authors': 'Tyler L. Hayes, Giri P. Krishnan', 'link': 'https://arxiv.org/abs/2511.14781', 'abstract': 'Models such as AlphaFold2 and OpenFold have transformed protein structure prediction, yet their inner workings remain poorly understood. We present a methodology to systematically evaluate the contribution of individual OpenFold components to structure prediction accuracy. We identify several components that are critical for most proteins, while others vary in importance across proteins. We further show that the contribution of several components is correlated with protein length. These findings provide insight into how OpenFold achieves accurate predictions and highlight directions for interpreting protein prediction networks more broadly.', 'abstract_zh': 'AlphaFold2和OpenFold等模型已经革新了蛋白质结构预测，但其内部机制仍然不甚明了。我们提出了一种方法学，系统地评估OpenFold各组件对结构预测准确性的影响。我们发现一些组件对大多数蛋白质至关重要，而其他组件在不同蛋白质中的重要性有所不同。我们还表明，一些组件的贡献与蛋白质长度相关。这些发现为理解OpenFold如何实现准确的预测提供了见解，并指出了更广泛解释蛋白质预测网络的方向。', 'title_zh': '量化OpenFold组件在蛋白质结构预测中的作用'}
{'arxiv_id': 'arXiv:2511.14792', 'title': 'Application of Graph Based Vision Transformers Architectures for Accurate Temperature Prediction in Fiber Specklegram Sensors', 'authors': 'Abhishek Sebastian', 'link': 'https://arxiv.org/abs/2511.14792', 'abstract': 'Fiber Specklegram Sensors (FSS) are highly effective for environmental monitoring, particularly for detecting temperature variations. However, the nonlinear nature of specklegram data presents significant challenges for accurate temperature prediction. This study investigates the use of transformer-based architectures, including Vision Transformers (ViTs), Swin Transformers, and emerging models such as Learnable Importance Non-Symmetric Attention Vision Transformers (LINA-ViT) and Multi-Adaptive Proximity Vision Graph Attention Transformers (MAP-ViGAT), to predict temperature from specklegram data over a range of 0 to 120 Celsius. The results show that ViTs achieved a Mean Absolute Error (MAE) of 1.15, outperforming traditional models such as CNNs. GAT-ViT and MAP-ViGAT variants also demonstrated competitive accuracy, highlighting the importance of adaptive attention mechanisms and graph-based structures in capturing complex modal interactions and phase shifts in specklegram data. Additionally, this study incorporates Explainable AI (XAI) techniques, including attention maps and saliency maps, to provide insights into the decision-making processes of the transformer models, improving interpretability and transparency. These findings establish transformer architectures as strong benchmarks for optical fiber-based temperature sensing and offer promising directions for industrial monitoring and structural health assessment applications.', 'abstract_zh': '基于光纤斑纹图传感器的变压器架构在温度监测中的应用：解释性AI技术的集成研究', 'title_zh': '基于图卷积视觉变换器架构在光纤斑纹传感器中实现准确的温度预测'}
{'arxiv_id': 'arXiv:2511.14791', 'title': 'Enabling Predictive Maintenance in District Heating Substations: A Labelled Dataset and Fault Detection Evaluation Framework based on Service Data', 'authors': 'Cyriana M.A. Roelofs, Edison Guevara Bastidas, Thomas Hugo, Stefan Faulstich, Anna Cadenbach', 'link': 'https://arxiv.org/abs/2511.14791', 'abstract': 'Early detection of faults in district heating substations is imperative to reduce return temperatures and enhance efficiency. However, progress in this domain has been hindered by the limited availability of public, labelled datasets. We present an open source framework combining a service report validated public dataset, an evaluation method based on Accuracy, Reliability, and Earliness, and baseline results implemented with EnergyFaultDetector, an open source Python framework.\nThe dataset contains time series of operational data from 93 substations across two manufacturers, annotated with a list of disturbances due to faults and maintenance actions, a set of normal-event examples and detailed fault metadata. We evaluate the EnergyFaultDetector using three metrics: Accuracy for recognising normal behaviour, an eventwise F Score for reliable fault detection with few false alarms, and Earliness for early detection. The framework also supports root cause analysis using ARCANA. We demonstrate three use cases to assist operators in interpreting anomalies and identifying underlying faults. The models achieve high normal-behaviour accuracy (0.98) and eventwise F-score (beta=0.5) of 0.83, detecting 60% of the faults in the dataset before the customer reports a problem, with an average lead time of 3.9 days.\nIntegrating an open dataset, metrics, open source code, and baselines establishes a reproducible, fault centric benchmark with operationally meaningful evaluation, enabling consistent comparison and development of early fault detection and diagnosis methods for district heating substations.', 'abstract_zh': '早期检测区域供暖子站中的故障对于降低回水温度和提高效率至关重要。然而，该领域的进展受制于可用的公共标注数据集有限。我们提出了一种开源框架，结合了一个经过服务报告验证的公共数据集、基于准确率、可靠性和及时性的评估方法，以及使用开源Python框架EnergyFaultDetector实现的基线结果。\n该数据集包含来自两家制造商的93个子站的运营数据时间序列，标注了故障和维护操作引起的扰动列表、正常事件示例以及详细的故障元数据。我们使用三个指标评估EnergyFaultDetector：用于识别正常行为的准确率、可用于可靠故障检测的事件级F分数（β=0.5）以及用于早期检测的及时性。该框架还支持使用ARCANA进行根本原因分析。我们展示了三个用例帮助运营人员解释异常并识别潜在故障。模型在正常行为准确率上达到了0.98，在事件级F分数（β=0.5）上达到了0.83，能够在客户报告问题之前检测出数据集中60%的故障，平均提前时间为3.9天。\n整合开放数据集、评估指标、开源代码和基线结果建立了可重现的、以故障为中心的基准，提供了操作上有意义的评估，使早期故障检测与诊断方法在区域供暖子站中的比较和开发得以一致进行。', 'title_zh': '基于服务数据的带标注数据集与故障检测评估框架：在区域供暖站实现预测性维护'}
{'arxiv_id': 'arXiv:2511.14774', 'title': 'LiveCLKTBench: Towards Reliable Evaluation of Cross-Lingual Knowledge Transfer in Multilingual LLMs', 'authors': 'Pei-Fu Guo, Yun-Da Tsai, Chun-Chia Hsu, Kai-Xin Chen, Ya-An Tsai, Kai-Wei Chang, Nanyun Peng, Mi-Yen Yeh, Shou-De Lin', 'link': 'https://arxiv.org/abs/2511.14774', 'abstract': "Evaluating cross-lingual knowledge transfer in large language models is challenging, as correct answers in a target language may arise either from genuine transfer or from prior exposure during pre-training. We present LiveCLKTBench, an automated generation pipeline specifically designed to isolate and measure cross-lingual knowledge transfer. Our pipeline identifies self-contained, time-sensitive knowledge entities from real-world domains, filters them based on temporal occurrence, and verifies them against the model's knowledge. The documents of these valid entities are then used to generate factual questions, which are translated into multiple languages to evaluate transferability across linguistic boundaries. Using LiveCLKTBench, we evaluate several LLMs across five languages and observe that cross-lingual transfer is strongly influenced by linguistic distance and often asymmetric across language directions. While larger models improve transfer, the gains diminish with scale and vary across domains. These findings provide new insights into multilingual transfer and demonstrate the value of LiveCLKTBench as a reliable benchmark for future research.", 'abstract_zh': '评估大规模语言模型的跨语言知识迁移具有挑战性，因为目标语言中的正确答案可能是来自真实的迁移或前期预训练中的先前暴露。我们提出了LiveCLKTBench，一种专门设计用于隔离和测量跨语言知识迁移的自动化生成管道。该管道从现实世界领域中识别出自包含的时间敏感知识实体，基于时间发生情况进行过滤，并与模型的知识进行验证。这些有效实体的文档随后用于生成事实性问题，问题被翻译成多种语言以评估语言边界之间的迁移性。使用LiveCLKTBench，我们对五种语言中的多个LLM进行评估，并观察到跨语言迁移受语言距离强烈影响，且在不同语言方向上往往是不对称的。虽然更大规模的模型能提高迁移性，但这种增益随规模增大而递减，并在不同领域有所不同。这些发现为多语言迁移提供了新的见解，并展示了LiveCLKTBench作为未来研究可靠基准的价值。', 'title_zh': 'LiveCLKTBench: 向着可靠评估多语言LLM跨语言知识迁移的途径'}
{'arxiv_id': 'arXiv:2511.14791', 'title': 'Enabling Predictive Maintenance in District Heating Substations: A Labelled Dataset and Fault Detection Evaluation Framework based on Service Data', 'authors': 'Cyriana M.A. Roelofs, Edison Guevara Bastidas, Thomas Hugo, Stefan Faulstich, Anna Cadenbach', 'link': 'https://arxiv.org/abs/2511.14791', 'abstract': 'Early detection of faults in district heating substations is imperative to reduce return temperatures and enhance efficiency. However, progress in this domain has been hindered by the limited availability of public, labelled datasets. We present an open source framework combining a service report validated public dataset, an evaluation method based on Accuracy, Reliability, and Earliness, and baseline results implemented with EnergyFaultDetector, an open source Python framework.\nThe dataset contains time series of operational data from 93 substations across two manufacturers, annotated with a list of disturbances due to faults and maintenance actions, a set of normal-event examples and detailed fault metadata. We evaluate the EnergyFaultDetector using three metrics: Accuracy for recognising normal behaviour, an eventwise F Score for reliable fault detection with few false alarms, and Earliness for early detection. The framework also supports root cause analysis using ARCANA. We demonstrate three use cases to assist operators in interpreting anomalies and identifying underlying faults. The models achieve high normal-behaviour accuracy (0.98) and eventwise F-score (beta=0.5) of 0.83, detecting 60% of the faults in the dataset before the customer reports a problem, with an average lead time of 3.9 days.\nIntegrating an open dataset, metrics, open source code, and baselines establishes a reproducible, fault centric benchmark with operationally meaningful evaluation, enabling consistent comparison and development of early fault detection and diagnosis methods for district heating substations.', 'abstract_zh': '早期检测区域供暖变电站中的故障对于降低回水温度和提高效率至关重要。然而，这一领域的发展受到了可获取的公共带标签数据集有限性的阻碍。我们介绍了一个开源框架，结合了一个经过服务报告验证的公共数据集、基于准确率、可靠性和早期性的评估方法以及使用开源Python框架EnergyFaultDetector实现的基线结果。该数据集包含来自两家制造商的93个变电站的运营数据时间序列，并标注了故障和维护动作的干扰列表、正常事件示例及详细的故障元数据。我们使用三种指标评估EnergyFaultDetector：准确率用于识别正常行为、事件级F分数用于可靠地检测故障并减少误报、以及早发现性能。该框架还支持使用ARCANA进行根本原因分析。我们演示了三种用例以帮助操作员解释异常并识别潜在的故障。模型获得高正常行为准确率（0.98）和事件级F分数（β=0.5）（0.83），能够在客户报告问题前检测出数据集中60%的故障，并且平均提前3.9天发现。将开源数据集、指标、开源代码和基线结果集成建立了一个可重复的、以故障为中心的基准，具有操作上意义的评估，使早期故障检测和诊断方法的一致比较和开发成为可能。', 'title_zh': '基于服务数据的带标注数据集与故障检测评估框架：在区域供暖变电站中实现预测性维护'}
{'arxiv_id': 'arXiv:2511.14781', 'title': 'Quantifying the Role of OpenFold Components in Protein Structure Prediction', 'authors': 'Tyler L. Hayes, Giri P. Krishnan', 'link': 'https://arxiv.org/abs/2511.14781', 'abstract': 'Models such as AlphaFold2 and OpenFold have transformed protein structure prediction, yet their inner workings remain poorly understood. We present a methodology to systematically evaluate the contribution of individual OpenFold components to structure prediction accuracy. We identify several components that are critical for most proteins, while others vary in importance across proteins. We further show that the contribution of several components is correlated with protein length. These findings provide insight into how OpenFold achieves accurate predictions and highlight directions for interpreting protein prediction networks more broadly.', 'abstract_zh': 'AlphaFold2和OpenFold等模型已革新了蛋白质结构预测，但其内部工作机制依然不甚明了。我们提出了一种方法学，以系统性地评估OpenFold各个组件对结构预测准确性的贡献。我们发现某些组件对于大多数蛋白质来说是至关重要的，而其他组件则在不同蛋白质中具有不同的重要性。进一步地，我们表明某些组件的贡献与其蛋白质长度相关。这些发现为我们理解OpenFold如何实现准确的预测提供了洞察，并突出显示了更广泛地解释蛋白质预测网络的方向。', 'title_zh': '评估OpenFold组件在蛋白质结构预测中的作用量化'}
{'arxiv_id': 'arXiv:2511.14772', 'title': 'Test-time Scaling of LLMs: A Survey from A Subproblem Structure Perspective', 'authors': 'Zhuoyi Yang, Xu Guo, Tong Zhang, Huijuan Xu, Boyang Li', 'link': 'https://arxiv.org/abs/2511.14772', 'abstract': 'With this paper, we survey techniques for improving the predictive accuracy of pretrained large language models by allocating additional compute at inference time. In categorizing test-time scaling methods, we place special emphasis on how a problem is decomposed into subproblems and on the topological organization of these subproblems whether sequential, parallel, or tree-structured. This perspective allows us to unify diverse approaches such as Chain-of-Thought, Branch-Solve-Merge, and Tree-of-Thought under a common lens. We further synthesize existing analyses of these techniques, highlighting their respective strengths and weaknesses, and conclude by outlining promising directions for future research', 'abstract_zh': '通过将额外计算资源分配到推理阶段，本文调研了提高预训练大型语言模型预测精度的技术。在归类测试时的扩展方法时，我们特别强调问题是如何被分解为子问题以及这些子问题的拓扑组织方式，是否为顺序、并行或树状结构。这一视角使我们能够将如Chain-of-Thought、Branch-Solve-Merge和Tree-of-Thought等多元方法整合在同一个框架下。我们进一步综合现有对这些技术的分析，突出各自的优点与不足，并指出未来研究的有希望的方向。', 'title_zh': 'LLM测试时缩放：从子问题结构视角的综述'}
{'arxiv_id': 'arXiv:2511.14781', 'title': 'Quantifying the Role of OpenFold Components in Protein Structure Prediction', 'authors': 'Tyler L. Hayes, Giri P. Krishnan', 'link': 'https://arxiv.org/abs/2511.14781', 'abstract': 'Models such as AlphaFold2 and OpenFold have transformed protein structure prediction, yet their inner workings remain poorly understood. We present a methodology to systematically evaluate the contribution of individual OpenFold components to structure prediction accuracy. We identify several components that are critical for most proteins, while others vary in importance across proteins. We further show that the contribution of several components is correlated with protein length. These findings provide insight into how OpenFold achieves accurate predictions and highlight directions for interpreting protein prediction networks more broadly.', 'abstract_zh': 'AlphaFold2和OpenFold等模型已变革了蛋白质结构预测，但仍对其内部工作机制了解不足。我们提出了一种方法学，以系统评估OpenFold各个组件对结构预测准确性的贡献。我们发现某些组件对于大多数蛋白质至关重要，而其他组件在不同蛋白质中的重要性存在差异。此外，我们展示了某些组件的贡献与其蛋白质长度相关。这些发现提供了关于OpenFold如何实现准确预测的见解，并突显了更广泛解读蛋白质预测网络的方向。', 'title_zh': 'OpenFold组件在蛋白质结构预测中作用的量化评估'}
{'arxiv_id': 'arXiv:2511.14774', 'title': 'LiveCLKTBench: Towards Reliable Evaluation of Cross-Lingual Knowledge Transfer in Multilingual LLMs', 'authors': 'Pei-Fu Guo, Yun-Da Tsai, Chun-Chia Hsu, Kai-Xin Chen, Ya-An Tsai, Kai-Wei Chang, Nanyun Peng, Mi-Yen Yeh, Shou-De Lin', 'link': 'https://arxiv.org/abs/2511.14774', 'abstract': "Evaluating cross-lingual knowledge transfer in large language models is challenging, as correct answers in a target language may arise either from genuine transfer or from prior exposure during pre-training. We present LiveCLKTBench, an automated generation pipeline specifically designed to isolate and measure cross-lingual knowledge transfer. Our pipeline identifies self-contained, time-sensitive knowledge entities from real-world domains, filters them based on temporal occurrence, and verifies them against the model's knowledge. The documents of these valid entities are then used to generate factual questions, which are translated into multiple languages to evaluate transferability across linguistic boundaries. Using LiveCLKTBench, we evaluate several LLMs across five languages and observe that cross-lingual transfer is strongly influenced by linguistic distance and often asymmetric across language directions. While larger models improve transfer, the gains diminish with scale and vary across domains. These findings provide new insights into multilingual transfer and demonstrate the value of LiveCLKTBench as a reliable benchmark for future research.", 'abstract_zh': '评估大规模语言模型的跨语言知识迁移具有挑战性，因为目标语言中的正确答案可能是真正迁移的结果，也可能是预训练期间的先验暴露所致。我们提出LiveCLKTBench，一个专门设计的自动生成管道，旨在隔离并衡量跨语言知识迁移。该管道从实际领域中识别出独立且时间敏感的知识实体，根据时间发生情况进行过滤，并与模型的知识进行验证。这些有效实体的文档随后用于生成事实性问题，并翻译成多种语言以评估跨语言边界的迁移能力。使用LiveCLKTBench，我们跨五种语言评估了几种LLM，并观察到跨语言迁移强烈受到语言距离的影响，并且在不同语言方向上往往是不对称的。虽然较大的模型可以提高迁移，但随规模增加的收益会减弱，并在不同领域间有所不同。这些发现为多语言迁移提供了新的见解，并展示了LiveCLKTBench作为未来研究可靠基准的价值。', 'title_zh': 'LiveCLKTBench:向量可靠的多语言LLM跨语言知识迁移评估'}
{'arxiv_id': 'arXiv:2511.14770', 'title': 'ExplainRec: Towards Explainable Multi-Modal Zero-Shot Recommendation with Preference Attribution and Large Language Models', 'authors': 'Bo Ma, LuYao Liu, ZeHua Hu, Simon Lau', 'link': 'https://arxiv.org/abs/2511.14770', 'abstract': 'Recent advances in Large Language Models (LLMs) have opened new possibilities for recommendation systems, though current approaches such as TALLRec face challenges in explainability and cold-start scenarios. We present ExplainRec, a framework that extends LLM-based recommendation capabilities through preference attribution, multi-modal fusion, and zero-shot transfer learning. The framework incorporates four technical contributions: preference attribution tuning for explainable recommendations, zero-shot preference transfer for cold-start users and items, multi-modal enhancement leveraging visual and textual content, and multi-task collaborative optimization. Experimental evaluation on MovieLens-25M and Amazon datasets shows that ExplainRec outperforms existing methods, achieving AUC improvements of 0.7\\% on movie recommendation and 0.9\\% on cross-domain tasks, while generating interpretable explanations and handling cold-start scenarios effectively.', 'abstract_zh': '最近大型语言模型的发展为推荐系统开辟了新可能性，尽管当前方法如TALLRec在解释性和冷启动场景中面临挑战。我们提出了ExplainRec框架，该框架通过偏好归因、多模态融合和零样本迁移学习扩展了基于语言模型的推荐能力。该框架包含四项技术贡献：可解释推荐的偏好归因调整、冷启动用户和项目的零样本偏好迁移、结合视觉和文本内容的多模态增强，以及多任务协作优化。在MovieLens-25M和Amazon数据集上的实验评估表明，ExplainRec优于现有方法，在电影推荐中AUC提高了0.7%，在跨域任务中提高了0.9%，同时生成可解释的解释并有效处理冷启动场景。', 'title_zh': 'ExplainRec: 含有偏好归因和大型语言模型的可解释多模态零样本推荐'}
{'arxiv_id': 'arXiv:2511.14774', 'title': 'LiveCLKTBench: Towards Reliable Evaluation of Cross-Lingual Knowledge Transfer in Multilingual LLMs', 'authors': 'Pei-Fu Guo, Yun-Da Tsai, Chun-Chia Hsu, Kai-Xin Chen, Ya-An Tsai, Kai-Wei Chang, Nanyun Peng, Mi-Yen Yeh, Shou-De Lin', 'link': 'https://arxiv.org/abs/2511.14774', 'abstract': "Evaluating cross-lingual knowledge transfer in large language models is challenging, as correct answers in a target language may arise either from genuine transfer or from prior exposure during pre-training. We present LiveCLKTBench, an automated generation pipeline specifically designed to isolate and measure cross-lingual knowledge transfer. Our pipeline identifies self-contained, time-sensitive knowledge entities from real-world domains, filters them based on temporal occurrence, and verifies them against the model's knowledge. The documents of these valid entities are then used to generate factual questions, which are translated into multiple languages to evaluate transferability across linguistic boundaries. Using LiveCLKTBench, we evaluate several LLMs across five languages and observe that cross-lingual transfer is strongly influenced by linguistic distance and often asymmetric across language directions. While larger models improve transfer, the gains diminish with scale and vary across domains. These findings provide new insights into multilingual transfer and demonstrate the value of LiveCLKTBench as a reliable benchmark for future research.", 'abstract_zh': '评估大规模语言模型的跨语言知识迁移具有挑战性，因为目标语言中的正确答案可能源自真实的迁移或预训练期间的先验暴露。我们提出了LiveCLKTBench，一个专门设计的自动化生成管道，用于隔离和测量跨语言知识迁移。该管道从实际情况中识别出自我包含且时间敏感的知识实体，根据时间发生情况进行过滤，并验证这些实体的知识。这些有效实体的文档随后用于生成事实性问题，并将其翻译成多种语言以评估跨语言边界的知识迁移能力。使用LiveCLKTBench，我们在五种语言上评估了几种LLM，并观察到跨语言迁移受语言距离影响强烈且在语言方向上经常不对称。虽然较大的模型能提高迁移能力，但这种提升随规模递减并在不同领域中有所不同。这些发现为多语言迁移提供了新的见解，并证明了LiveCLKTBench作为未来研究可靠基准的价值。', 'title_zh': 'LiveCLKTBench: 朝着可靠评估多语言LLM跨语言知识迁移的方向'}
{'arxiv_id': 'arXiv:2511.14772', 'title': 'Test-time Scaling of LLMs: A Survey from A Subproblem Structure Perspective', 'authors': 'Zhuoyi Yang, Xu Guo, Tong Zhang, Huijuan Xu, Boyang Li', 'link': 'https://arxiv.org/abs/2511.14772', 'abstract': 'With this paper, we survey techniques for improving the predictive accuracy of pretrained large language models by allocating additional compute at inference time. In categorizing test-time scaling methods, we place special emphasis on how a problem is decomposed into subproblems and on the topological organization of these subproblems whether sequential, parallel, or tree-structured. This perspective allows us to unify diverse approaches such as Chain-of-Thought, Branch-Solve-Merge, and Tree-of-Thought under a common lens. We further synthesize existing analyses of these techniques, highlighting their respective strengths and weaknesses, and conclude by outlining promising directions for future research', 'abstract_zh': '通过本论文，我们调研了在推理时分配额外计算资源以提高预训练大语言模型预测准确性的技术。在分类测试时缩放方法时，我们特别关注问题是如何分解为子问题的，以及这些子问题的拓扑组织方式，是否为顺序、并行或树形结构。这种视角使我们能够将诸如Chain-of-Thought、Branch-Solve-Merge和Tree-of-Thought等多样方法统一在一个框架下。我们进一步综合了这些技术的现有分析，指出了它们各自的优缺点，并总结了未来研究的具有前景的方向。', 'title_zh': 'LLM测试时缩放：从子问题结构视角的综述'}
{'arxiv_id': 'arXiv:2511.14772', 'title': 'Test-time Scaling of LLMs: A Survey from A Subproblem Structure Perspective', 'authors': 'Zhuoyi Yang, Xu Guo, Tong Zhang, Huijuan Xu, Boyang Li', 'link': 'https://arxiv.org/abs/2511.14772', 'abstract': 'With this paper, we survey techniques for improving the predictive accuracy of pretrained large language models by allocating additional compute at inference time. In categorizing test-time scaling methods, we place special emphasis on how a problem is decomposed into subproblems and on the topological organization of these subproblems whether sequential, parallel, or tree-structured. This perspective allows us to unify diverse approaches such as Chain-of-Thought, Branch-Solve-Merge, and Tree-of-Thought under a common lens. We further synthesize existing analyses of these techniques, highlighting their respective strengths and weaknesses, and conclude by outlining promising directions for future research', 'abstract_zh': '通过本论文，我们调研了在推理时分配额外计算资源以提升预训练大规模语言模型预测准确性的技术。在归类测试时缩放方法时，我们特别强调问题如何被分解成子问题以及这些子问题的拓扑组织方式，无论是串行、并行还是树状结构。这种视角使我们能够将Chain-of-Thought、Branch-Solve-Merge和Tree-of-Thought等多样方法统一起来，置于一个共同的框架之下。我们进一步综合现有对这些技术的分析，突出其各自的优点和缺点，并总结出未来研究的有前景的方向。', 'title_zh': 'LLM测试时尺度调整：从子问题结构视角的综述'}
{'arxiv_id': 'arXiv:2511.14769', 'title': 'Cluster-based Adaptive Retrieval: Dynamic Context Selection for RAG Applications', 'authors': 'Yifan Xu, Vipul Gupta, Rohit Aggarwal, Varsha Mahadevan, Bhaskar Krishnamachari', 'link': 'https://arxiv.org/abs/2511.14769', 'abstract': "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by pulling in external material, document, code, manuals, from vast and ever-growing corpora, to effectively answer user queries. The effectiveness of RAG depends significantly on aligning the number of retrieved documents with query characteristics: narrowly focused queries typically require fewer, highly relevant documents, whereas broader or ambiguous queries benefit from retrieving more extensive supporting information. However, the common static top-k retrieval approach fails to adapt to this variability, resulting in either insufficient context from too few documents or redundant information from too many. Motivated by these challenges, we introduce Cluster-based Adaptive Retrieval (CAR), an algorithm that dynamically determines the optimal number of documents by analyzing the clustering patterns of ordered query-document similarity distances. CAR detects the transition point within similarity distances, where tightly clustered, highly relevant documents shift toward less pertinent candidates, establishing an adaptive cut-off that scales with query complexity. On Coinbase's CDP corpus and the public MultiHop-RAG benchmark, CAR consistently picks the optimal retrieval depth and achieves the highest TES score, outperforming every fixed top-k baseline. In downstream RAG evaluations, CAR cuts LLM token usage by 60%, trims end-to-end latency by 22%, and reduces hallucinations by 10% while fully preserving answer relevance. Since integrating CAR into Coinbase's virtual assistant, we've seen user engagement jump by 200%.", 'abstract_zh': '基于聚类的自适应检索（CAR）增强了大型语言模型（LLMs）的检索增强生成（RAG），通过从大量不断增长的语料库中引入外部材料、文档、代码和手册，有效回答用户查询。CAR通过分析排序查询-文档相似度距离的聚类模式，动态确定最优的检索文档数量。CAR检测相似度距离中的转变点，即高度相关且紧密聚类的文档逐渐向不太相关的选择转变，从而建立一个随查询复杂度变化的自适应截止点。在Coinbase的CDP语料库和公共MultiHop-RAG基准测试上，CAR始终选择最优的检索深度并获得最高的TES评分，优于所有固定top-k基准。在下游RAG评估中，CAR将LLM的词令牌使用量减少了60%，端到端延迟减少了22%，并且减少了10%的虚构信息，同时完全保留了答案的相关性。自将CAR集成到Coinbase的虚拟助手后，我们看到用户参与度提高了200%。', 'title_zh': '基于聚类的自适应检索：面向RAG应用的动态上下文选择'}
{'arxiv_id': 'arXiv:2511.14770', 'title': 'ExplainRec: Towards Explainable Multi-Modal Zero-Shot Recommendation with Preference Attribution and Large Language Models', 'authors': 'Bo Ma, LuYao Liu, ZeHua Hu, Simon Lau', 'link': 'https://arxiv.org/abs/2511.14770', 'abstract': 'Recent advances in Large Language Models (LLMs) have opened new possibilities for recommendation systems, though current approaches such as TALLRec face challenges in explainability and cold-start scenarios. We present ExplainRec, a framework that extends LLM-based recommendation capabilities through preference attribution, multi-modal fusion, and zero-shot transfer learning. The framework incorporates four technical contributions: preference attribution tuning for explainable recommendations, zero-shot preference transfer for cold-start users and items, multi-modal enhancement leveraging visual and textual content, and multi-task collaborative optimization. Experimental evaluation on MovieLens-25M and Amazon datasets shows that ExplainRec outperforms existing methods, achieving AUC improvements of 0.7\\% on movie recommendation and 0.9\\% on cross-domain tasks, while generating interpretable explanations and handling cold-start scenarios effectively.', 'abstract_zh': 'Recent Advances in Large Language Models for Recommendation Systems: ExplainRec Framework通过偏好归因、多模态融合和零-shot迁移学习扩展基于LLM的推荐能力', 'title_zh': 'ExplainRec: 面向可解释的多模态零样本推荐及偏好归因的大语言模型'}
{'arxiv_id': 'arXiv:2511.14770', 'title': 'ExplainRec: Towards Explainable Multi-Modal Zero-Shot Recommendation with Preference Attribution and Large Language Models', 'authors': 'Bo Ma, LuYao Liu, ZeHua Hu, Simon Lau', 'link': 'https://arxiv.org/abs/2511.14770', 'abstract': 'Recent advances in Large Language Models (LLMs) have opened new possibilities for recommendation systems, though current approaches such as TALLRec face challenges in explainability and cold-start scenarios. We present ExplainRec, a framework that extends LLM-based recommendation capabilities through preference attribution, multi-modal fusion, and zero-shot transfer learning. The framework incorporates four technical contributions: preference attribution tuning for explainable recommendations, zero-shot preference transfer for cold-start users and items, multi-modal enhancement leveraging visual and textual content, and multi-task collaborative optimization. Experimental evaluation on MovieLens-25M and Amazon datasets shows that ExplainRec outperforms existing methods, achieving AUC improvements of 0.7\\% on movie recommendation and 0.9\\% on cross-domain tasks, while generating interpretable explanations and handling cold-start scenarios effectively.', 'abstract_zh': 'Recent Advances in Large Language Models for Recommendation Systems: ExplainRec Framework Through Preference Attribution, Multi-Modal Fusion, and Zero-Shot Transfer Learning', 'title_zh': 'ExplainRec: 基于偏好归因和大规模语言模型的可解释多模态零样本推荐'}
{'arxiv_id': 'arXiv:2511.14768', 'title': 'Causally-Informed Reinforcement Learning for Adaptive Emotion-Aware Social Media Recommendation', 'authors': 'Bhavika Jain, Robert Pitsko, Ananya Drishti, Mahfuza Farooque', 'link': 'https://arxiv.org/abs/2511.14768', 'abstract': "Social media recommendation systems play a central role in shaping users' emotional experiences. However, most systems are optimized solely for engagement metrics, such as click rate, viewing time, or scrolling, without accounting for users' emotional states. Repeated exposure to emotionally charged content has been shown to negatively affect users' emotional well-being over time. We propose an Emotion-aware Social Media Recommendation (ESMR) framework that personalizes content based on users' evolving emotional trajectories. ESMR integrates a Transformer-based emotion predictor with a hybrid recommendation policy: a LightGBM model for engagement during stable periods and a reinforcement learning agent with causally informed rewards when negative emotional states persist. Through behaviorally grounded evaluation over 30-day interaction traces, ESMR demonstrates improved emotional recovery, reduced volatility, and strong engagement retention. ESMR offers a path toward emotionally aware recommendations without compromising engagement performance.", 'abstract_zh': '基于情绪感知的社会媒体推荐框架（ESMR）：提升情绪恢复、降低情绪波动并保持高 engagement 留存', 'title_zh': '基于因果关系的适应性情绪感知社交媒体推荐强化学习'}
{'arxiv_id': 'arXiv:2511.14769', 'title': 'Cluster-based Adaptive Retrieval: Dynamic Context Selection for RAG Applications', 'authors': 'Yifan Xu, Vipul Gupta, Rohit Aggarwal, Varsha Mahadevan, Bhaskar Krishnamachari', 'link': 'https://arxiv.org/abs/2511.14769', 'abstract': "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by pulling in external material, document, code, manuals, from vast and ever-growing corpora, to effectively answer user queries. The effectiveness of RAG depends significantly on aligning the number of retrieved documents with query characteristics: narrowly focused queries typically require fewer, highly relevant documents, whereas broader or ambiguous queries benefit from retrieving more extensive supporting information. However, the common static top-k retrieval approach fails to adapt to this variability, resulting in either insufficient context from too few documents or redundant information from too many. Motivated by these challenges, we introduce Cluster-based Adaptive Retrieval (CAR), an algorithm that dynamically determines the optimal number of documents by analyzing the clustering patterns of ordered query-document similarity distances. CAR detects the transition point within similarity distances, where tightly clustered, highly relevant documents shift toward less pertinent candidates, establishing an adaptive cut-off that scales with query complexity. On Coinbase's CDP corpus and the public MultiHop-RAG benchmark, CAR consistently picks the optimal retrieval depth and achieves the highest TES score, outperforming every fixed top-k baseline. In downstream RAG evaluations, CAR cuts LLM token usage by 60%, trims end-to-end latency by 22%, and reduces hallucinations by 10% while fully preserving answer relevance. Since integrating CAR into Coinbase's virtual assistant, we've seen user engagement jump by 200%.", 'abstract_zh': '基于聚类的自适应检索（CAR）增强了大型语言模型（LLMs）通过从 vast 和不断增长的语料库中拉取外部材料、文档、代码和手册，以有效地回答用户查询。CAR 通过分析有序查询-文档相似度距离的聚类模式动态确定最优的检索文档数量。CAR 在相似度距离中检测聚类点，确定适应性的截止点，该截止点根据查询复杂度进行调整。在 Coinbase 的 CDP语料库和公开的 MultiHop-RAG 基准测试中，CAR 始终选择最优的检索深度并获得最高的 TES 分数，优于所有固定 top-k 基准。在下游 RAG 评估中，CAR 将 LLM 令牌使用量减少 60%，端到端延迟减少 22%，幻觉减少 10%，同时完全保留答案的相关性。自将 CAR 集成到 Coinbase 的虚拟助手后，用户参与度提升 200%。', 'title_zh': '基于簇的自适应检索：RAG应用中的动态上下文选择'}
{'arxiv_id': 'arXiv:2511.14767', 'title': 'An LLM-Powered Agent for Real-Time Analysis of the Vietnamese IT Job Market', 'authors': 'Minh-Thuan Nguyen, Thien Vo-Thanh, Thai-Duy Dinh, Xuan-Quang Phan, Tan-Ha Mai, Lam-Son Lê', 'link': 'https://arxiv.org/abs/2511.14767', 'abstract': "Individuals entering Vietnam's dynamic Information Technology (IT) job market face a critical gap in reliable career guidance. Existing market reports are often outdated, while the manual analysis of thousands of job postings is impractical for most. To address this challenge, we present the AI Job Market Consultant, a novel conversational agent that delivers deep, data-driven insights directly from the labor market in real-time. The foundation of our system is a custom-built dataset created via an automated pipeline that crawls job portals using Playwright and leverages the Large Language Model (LLM) to intelligently structure unstructured posting data. The core of our system is a tool-augmented AI agent, based on the ReAct agentic framework, which enables the ability of autonomously reasoning, planning, and executing actions through a specialized toolbox for SQL queries, semantic search, and data visualization. Our prototype successfully collected and analyzed 3,745 job postings, demonstrating its ability to answer complex, multi-step queries, generate on-demand visualizations, and provide personalized career advice grounded in real-world data. This work introduces a new paradigm for labor market analysis, showcasing how specialized agentic AI systems can democratize access to timely, trustworthy career intelligence for the next generation of professionals.", 'abstract_zh': '越南动态信息技术（IT）就业市场进入者面临可靠职业指导的重要缺口。现有的市场报告往往过时，而手动分析数千份招聘信息对大多数人来说是不切实际的。为了解决这一挑战，我们提出了AI就业市场顾问，这是一种新型的对话代理，能够实时提供基于深入数据的见解。我们的系统基础是一个通过自动化管道构建的自定义数据集，使用Playwright抓取就业门户并利用大型语言模型（LLM）智能结构化非结构化的招聘信息。系统的核心是一个工具增强的AI代理，基于ReAct框架，该框架通过专用的SQL查询、语义搜索和数据可视化工具集，使代理能够自主进行推理、规划和执行操作。我们的原型成功收集和分析了3,745份招聘信息，展示了其回答复杂多步查询、提供按需可视化和基于现实数据的个性化职业建议的能力。本研究引入了劳动力市场分析的新范式，展示了专门的代理型AI系统如何使下一代专业人士能够获得及时和可信赖的职业智能。', 'title_zh': '基于LLM的实时分析越南IT就业市场代理qing'}
{'arxiv_id': 'arXiv:2511.14769', 'title': 'Cluster-based Adaptive Retrieval: Dynamic Context Selection for RAG Applications', 'authors': 'Yifan Xu, Vipul Gupta, Rohit Aggarwal, Varsha Mahadevan, Bhaskar Krishnamachari', 'link': 'https://arxiv.org/abs/2511.14769', 'abstract': "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by pulling in external material, document, code, manuals, from vast and ever-growing corpora, to effectively answer user queries. The effectiveness of RAG depends significantly on aligning the number of retrieved documents with query characteristics: narrowly focused queries typically require fewer, highly relevant documents, whereas broader or ambiguous queries benefit from retrieving more extensive supporting information. However, the common static top-k retrieval approach fails to adapt to this variability, resulting in either insufficient context from too few documents or redundant information from too many. Motivated by these challenges, we introduce Cluster-based Adaptive Retrieval (CAR), an algorithm that dynamically determines the optimal number of documents by analyzing the clustering patterns of ordered query-document similarity distances. CAR detects the transition point within similarity distances, where tightly clustered, highly relevant documents shift toward less pertinent candidates, establishing an adaptive cut-off that scales with query complexity. On Coinbase's CDP corpus and the public MultiHop-RAG benchmark, CAR consistently picks the optimal retrieval depth and achieves the highest TES score, outperforming every fixed top-k baseline. In downstream RAG evaluations, CAR cuts LLM token usage by 60%, trims end-to-end latency by 22%, and reduces hallucinations by 10% while fully preserving answer relevance. Since integrating CAR into Coinbase's virtual assistant, we've seen user engagement jump by 200%.", 'abstract_zh': '基于聚类的自适应检索（CAR）增强的大语言模型检索 augmented 生成（RAG）通过从 vast 和不断增长的语料库中引入外部材料、文档、代码和手册，增强大语言模型 (LLMs)，以有效回答用户查询。CAR 通过分析有序查询-文档相似度距离的聚类模式动态确定最优的检索文档数量。CAR 检测相似度距离中的转变点，其中紧密聚类的相关文档逐渐向不相关候选者转变，从而建立一个与查询复杂度相适应的切割点。在 Coinbase 的 CDP 语料库和公开的 MultiHop-RAG 基准测试中，CAR 一致地选择了最优的检索深度并获得了最高的 TES 分数，超越了所有固定的 top-k 基准。在下游 RAG 评价中，CAR 将 LLM 令牌使用量降低了 60%，端到端延迟降低了 22%，幻觉减少了 10% 同时完全保持了答案的相关性。自将 CAR 集成到 Coinbase 的虚拟助手后，我们看到了用户参与度提高了 200%。', 'title_zh': '基于聚类的自适应检索：针对RAG应用的动态上下文选择'}
{'arxiv_id': 'arXiv:2511.14768', 'title': 'Causally-Informed Reinforcement Learning for Adaptive Emotion-Aware Social Media Recommendation', 'authors': 'Bhavika Jain, Robert Pitsko, Ananya Drishti, Mahfuza Farooque', 'link': 'https://arxiv.org/abs/2511.14768', 'abstract': "Social media recommendation systems play a central role in shaping users' emotional experiences. However, most systems are optimized solely for engagement metrics, such as click rate, viewing time, or scrolling, without accounting for users' emotional states. Repeated exposure to emotionally charged content has been shown to negatively affect users' emotional well-being over time. We propose an Emotion-aware Social Media Recommendation (ESMR) framework that personalizes content based on users' evolving emotional trajectories. ESMR integrates a Transformer-based emotion predictor with a hybrid recommendation policy: a LightGBM model for engagement during stable periods and a reinforcement learning agent with causally informed rewards when negative emotional states persist. Through behaviorally grounded evaluation over 30-day interaction traces, ESMR demonstrates improved emotional recovery, reduced volatility, and strong engagement retention. ESMR offers a path toward emotionally aware recommendations without compromising engagement performance.", 'abstract_zh': '基于情感意识的社会媒体推荐框架（ESMR）在塑造用户情感体验中的作用与其优化研究', 'title_zh': '因果驱动的强化学习在自适应情绪感知社交媒体推荐中应用'}
{'arxiv_id': 'arXiv:2511.14765', 'title': 'Optimizing Agricultural Research: A RAG-Based Approach to Mycorrhizal Fungi Information', 'authors': 'Mohammad Usman Altam, Md Imtiaz Habib, Tuan Hoang', 'link': 'https://arxiv.org/abs/2511.14765', 'abstract': 'Retrieval-Augmented Generation (RAG) represents a transformative approach within natural language processing (NLP), combining neural information retrieval with generative language modeling to enhance both contextual accuracy and factual reliability of responses. Unlike conventional Large Language Models (LLMs), which are constrained by static training corpora, RAG-powered systems dynamically integrate domain-specific external knowledge sources, thereby overcoming temporal and disciplinary limitations. In this study, we present the design and evaluation of a RAG-enabled system tailored for Mycophyto, with a focus on advancing agricultural applications related to arbuscular mycorrhizal fungi (AMF). These fungi play a critical role in sustainable agriculture by enhancing nutrient acquisition, improving plant resilience under abiotic and biotic stresses, and contributing to soil health. Our system operationalizes a dual-layered strategy: (i) semantic retrieval and augmentation of domain-specific content from agronomy and biotechnology corpora using vector embeddings, and (ii) structured data extraction to capture predefined experimental metadata such as inoculation methods, spore densities, soil parameters, and yield outcomes. This hybrid approach ensures that generated responses are not only semantically aligned but also supported by structured experimental evidence. To support scalability, embeddings are stored in a high-performance vector database, allowing near real-time retrieval from an evolving literature base. Empirical evaluation demonstrates that the proposed pipeline retrieves and synthesizes highly relevant information regarding AMF interactions with crop systems, such as tomato (Solanum lycopersicum). The framework underscores the potential of AI-driven knowledge discovery to accelerate agroecological innovation and enhance decision-making in sustainable farming systems.', 'abstract_zh': '检索增强生成（RAG）代表了自然语言处理（NLP）领域的一种变革性方法，结合了神经信息检索与生成语言建模，以提高响应的上下文准确性和事实可靠性。与受限于静态训练语料库的大型语言模型（LLMs）不同，RAG驱动的系统能够动态集成特定领域的外部知识源，从而克服了时间和学科的限制。在本研究中，我们介绍了为Mycophyto设计并评估的RAG赋能系统的相关设计与评估，重点关注根际微生物固氮菌（AMF）相关的农业应用。这些真菌通过增强养分获取、改善植物在非生物和生物胁迫下的抗逆性以及促进土壤健康等方面，在可持续农业中发挥了重要作用。该系统采用了双重策略：（i）使用向量嵌入从农业和生物技术语料库中检索和增强特定领域的内容；（ii）结构化数据提取以捕获诸如接种方法、孢子密度、土壤参数和产量结果等预定义的实验元数据。这种混合方法确保生成的响应不仅在语义上保持一致，而且也由结构化的实验证据支持。为支持可扩展性，嵌入在高性能向量数据库中存储，允许从不断更新的文献数据库中近乎实时地检索信息。实证评价表明，所提出的流水线能够检索和综合与AMF与作物系统相互作用高度相关的信息，如番茄（Solanum lycopersicum）。该框架强调了基于AI的知识发现潜力，可以促进农业生态创新并增强可持续农业系统的决策过程。', 'title_zh': '优化农业研究：一种基于RAG的方法用于菌根真菌信息'}
{'arxiv_id': 'arXiv:2511.14768', 'title': 'Causally-Informed Reinforcement Learning for Adaptive Emotion-Aware Social Media Recommendation', 'authors': 'Bhavika Jain, Robert Pitsko, Ananya Drishti, Mahfuza Farooque', 'link': 'https://arxiv.org/abs/2511.14768', 'abstract': "Social media recommendation systems play a central role in shaping users' emotional experiences. However, most systems are optimized solely for engagement metrics, such as click rate, viewing time, or scrolling, without accounting for users' emotional states. Repeated exposure to emotionally charged content has been shown to negatively affect users' emotional well-being over time. We propose an Emotion-aware Social Media Recommendation (ESMR) framework that personalizes content based on users' evolving emotional trajectories. ESMR integrates a Transformer-based emotion predictor with a hybrid recommendation policy: a LightGBM model for engagement during stable periods and a reinforcement learning agent with causally informed rewards when negative emotional states persist. Through behaviorally grounded evaluation over 30-day interaction traces, ESMR demonstrates improved emotional recovery, reduced volatility, and strong engagement retention. ESMR offers a path toward emotionally aware recommendations without compromising engagement performance.", 'abstract_zh': '情感感知社交媒体推荐框架：基于用户情感轨迹的内容个性化', 'title_zh': '因果驱动的强化学习在自适应情绪感知社交媒体推荐中的应用'}
{'arxiv_id': 'arXiv:2511.14767', 'title': 'An LLM-Powered Agent for Real-Time Analysis of the Vietnamese IT Job Market', 'authors': 'Minh-Thuan Nguyen, Thien Vo-Thanh, Thai-Duy Dinh, Xuan-Quang Phan, Tan-Ha Mai, Lam-Son Lê', 'link': 'https://arxiv.org/abs/2511.14767', 'abstract': "Individuals entering Vietnam's dynamic Information Technology (IT) job market face a critical gap in reliable career guidance. Existing market reports are often outdated, while the manual analysis of thousands of job postings is impractical for most. To address this challenge, we present the AI Job Market Consultant, a novel conversational agent that delivers deep, data-driven insights directly from the labor market in real-time. The foundation of our system is a custom-built dataset created via an automated pipeline that crawls job portals using Playwright and leverages the Large Language Model (LLM) to intelligently structure unstructured posting data. The core of our system is a tool-augmented AI agent, based on the ReAct agentic framework, which enables the ability of autonomously reasoning, planning, and executing actions through a specialized toolbox for SQL queries, semantic search, and data visualization. Our prototype successfully collected and analyzed 3,745 job postings, demonstrating its ability to answer complex, multi-step queries, generate on-demand visualizations, and provide personalized career advice grounded in real-world data. This work introduces a new paradigm for labor market analysis, showcasing how specialized agentic AI systems can democratize access to timely, trustworthy career intelligence for the next generation of professionals.", 'abstract_zh': '越南动态信息技术(IT)就业市场进入者面临可靠职业指导的重要缺口。现有的市场报告往往过时，而手动分析数千个招聘信息对于大多数来说是不切实际的。为应对这一挑战，我们提出了一种名为AI就业市场顾问的新型对话式代理，该代理能够实时提供基于数据的深入洞察。系统的基石是一个通过爬虫工具Playwright自动构建的定制数据集，并利用大语言模型（LLM）智能地结构化无结构的招聘信息。系统的核心是一个基于ReAct代理框架的工具增强型AI代理，该代理能够通过专有的SQL查询工具箱、语义搜索和数据可视化工具自主进行推理、规划和执行动作。我们的原型成功收集和分析了3,745个招聘信息，展示了其回答复杂多步查询、生成实时可视化以及提供基于现实数据的个性化职业建议的能力。本研究引入了劳动力市场分析的新范式，展示了专业化的代理AI系统如何为下一代专业人士提供及时且值得信赖的职业智能。', 'title_zh': '基于大语言模型的agent及其在越南IT求职市场实时分析中的应用'}
{'arxiv_id': 'arXiv:2511.14764', 'title': 'Image-Seeking Intent Prediction for Cross-Device Product Search', 'authors': 'Mariya Hendriksen, Svitlana Vakulenko, Jordan Massiah, Gabriella Kazai, Emine Yilmaz', 'link': 'https://arxiv.org/abs/2511.14764', 'abstract': 'Large Language Models (LLMs) are transforming personalized search, recommendations, and customer interaction in e-commerce. Customers increasingly shop across multiple devices, from voice-only assistants to multimodal displays, each offering different input and output capabilities. A proactive suggestion to switch devices can greatly improve the user experience, but it must be offered with high precision to avoid unnecessary friction. We address the challenge of predicting when a query requires visual augmentation and a cross-device switch to improve product discovery. We introduce Image-Seeking Intent Prediction, a novel task for LLM-driven e-commerce assistants that anticipates when a spoken product query should proactively trigger a visual on a screen-enabled device. Using large-scale production data from a multi-device retail assistant, including 900K voice queries, associated product retrievals, and behavioral signals such as image carousel engagement, we train IRP (Image Request Predictor), a model that leverages user input query and corresponding retrieved product metadata to anticipate visual intent. Our experiments show that combining query semantics with product data, particularly when improved through lightweight summarization, consistently improves prediction accuracy. Incorporating a differentiable precision-oriented loss further reduces false positives. These results highlight the potential of LLMs to power intelligent, cross-device shopping assistants that anticipate and adapt to user needs, enabling more seamless and personalized e-commerce experiences.', 'abstract_zh': '大型语言模型（LLMs）正在变革电子商务中的个性化搜索、推荐和客户服务交互。随着客户越来越多地使用多种设备进行购物，从仅支持语音的助手到多模态显示器，每种设备提供了不同的输入和输出功能。主动建议设备切换可以显著提升用户体验，但必须具备高精度以避免不必要的摩擦。我们应对了预测何时需要视觉增强以及跨设备切换以改进产品发现的挑战。我们提出了图像搜索意图预测这一新型任务，旨在让语言模型驱动的电子商务助手能够预见何时应主动触发屏幕设备上的视觉显示。通过使用多设备零售助手的大规模生产数据，包括900,000条语音查询、相关产品检索以及图像轮播参与等行为信号，我们训练了IRP（图像请求预测器）模型，该模型利用用户输入查询和相应检索的产品元数据来预见视觉意图。实验结果表明，结合查询语义和产品数据，尤其是通过轻量级摘要改进后，可以一致地提高预测准确性。引入一种可微分的高精度损失进一步减少了误报。这些结果突显了LLMs在推动能够预见和适应用户需求的智能跨设备购物助手方面的能力，从而实现更为无缝和个人化的电子商务体验。', 'title_zh': '跨设备产品搜索中的图像寻求意图预测'}
{'arxiv_id': 'arXiv:2511.14767', 'title': 'An LLM-Powered Agent for Real-Time Analysis of the Vietnamese IT Job Market', 'authors': 'Minh-Thuan Nguyen, Thien Vo-Thanh, Thai-Duy Dinh, Xuan-Quang Phan, Tan-Ha Mai, Lam-Son Lê', 'link': 'https://arxiv.org/abs/2511.14767', 'abstract': "Individuals entering Vietnam's dynamic Information Technology (IT) job market face a critical gap in reliable career guidance. Existing market reports are often outdated, while the manual analysis of thousands of job postings is impractical for most. To address this challenge, we present the AI Job Market Consultant, a novel conversational agent that delivers deep, data-driven insights directly from the labor market in real-time. The foundation of our system is a custom-built dataset created via an automated pipeline that crawls job portals using Playwright and leverages the Large Language Model (LLM) to intelligently structure unstructured posting data. The core of our system is a tool-augmented AI agent, based on the ReAct agentic framework, which enables the ability of autonomously reasoning, planning, and executing actions through a specialized toolbox for SQL queries, semantic search, and data visualization. Our prototype successfully collected and analyzed 3,745 job postings, demonstrating its ability to answer complex, multi-step queries, generate on-demand visualizations, and provide personalized career advice grounded in real-world data. This work introduces a new paradigm for labor market analysis, showcasing how specialized agentic AI systems can democratize access to timely, trustworthy career intelligence for the next generation of professionals.", 'abstract_zh': '越南动态信息技术（IT）劳动力市场的个体面临可靠职业指导的关键缺口。现有的市场报告往往过时，而手动分析数千份招聘信息对于大多数来说是不切实际的。为应对这一挑战，我们提出了AI就业市场顾问这一新颖的对话代理，能够实时提供深厚的数据驱动见解。我们的系统基础是一个通过自动化管道构建的自定义数据集，该管道使用Playwright抓取招聘信息，并利用大型语言模型（LLM）智能地结构化非结构化招聘信息数据。系统的核心是一个基于ReAct代理框架的工具增强AI代理，该代理能够通过专门的SQL查询、语义搜索和数据可视化工具箱自主进行推理、规划和执行行动。我们的原型成功收集和分析了3,745份招聘信息，展示了其回答复杂多步查询、生成按需可视化和提供基于实际数据的个性化职业建议的能力。这项工作引入了劳动力市场分析的新范式，展示了专门化的代理AI系统如何使下一代专业人员及时可信的职业智能普及化。', 'title_zh': '基于LLM的强大代理：越南IT就业市场实时分析'}
{'arxiv_id': 'arXiv:2511.14765', 'title': 'Optimizing Agricultural Research: A RAG-Based Approach to Mycorrhizal Fungi Information', 'authors': 'Mohammad Usman Altam, Md Imtiaz Habib, Tuan Hoang', 'link': 'https://arxiv.org/abs/2511.14765', 'abstract': 'Retrieval-Augmented Generation (RAG) represents a transformative approach within natural language processing (NLP), combining neural information retrieval with generative language modeling to enhance both contextual accuracy and factual reliability of responses. Unlike conventional Large Language Models (LLMs), which are constrained by static training corpora, RAG-powered systems dynamically integrate domain-specific external knowledge sources, thereby overcoming temporal and disciplinary limitations. In this study, we present the design and evaluation of a RAG-enabled system tailored for Mycophyto, with a focus on advancing agricultural applications related to arbuscular mycorrhizal fungi (AMF). These fungi play a critical role in sustainable agriculture by enhancing nutrient acquisition, improving plant resilience under abiotic and biotic stresses, and contributing to soil health. Our system operationalizes a dual-layered strategy: (i) semantic retrieval and augmentation of domain-specific content from agronomy and biotechnology corpora using vector embeddings, and (ii) structured data extraction to capture predefined experimental metadata such as inoculation methods, spore densities, soil parameters, and yield outcomes. This hybrid approach ensures that generated responses are not only semantically aligned but also supported by structured experimental evidence. To support scalability, embeddings are stored in a high-performance vector database, allowing near real-time retrieval from an evolving literature base. Empirical evaluation demonstrates that the proposed pipeline retrieves and synthesizes highly relevant information regarding AMF interactions with crop systems, such as tomato (Solanum lycopersicum). The framework underscores the potential of AI-driven knowledge discovery to accelerate agroecological innovation and enhance decision-making in sustainable farming systems.', 'abstract_zh': '检索增强生成（RAG）代表了自然语言处理（NLP）领域的一种变革性方法，结合了神经信息检索与生成语言模型，以增强响应的上下文准确性和事实可靠性。与受静态训练语料库限制的大型语言模型（LLMs）不同，RAG驱动的系统动态集成领域特定的外部知识来源，从而克服了时间和学科的限制。在本研究中，我们介绍了为Mycophyto设计并评估的一种RAG系统，重点在于推进与内生菌根真菌（AMF）相关的农业应用。这些真菌通过增强养分获取、提高植物在非生物和生物胁迫下的抗性和改善土壤健康，在可持续农业中发挥着关键作用。该系统采用了双层策略：(i) 使用向量嵌入从农学和生物技术语料库检索和增强领域特定内容，(ii) 结构化数据提取以捕捉预定义的实验元数据，如接种方法、孢子密度、土壤参数和产量结果。这种混合方法确保生成的响应不仅在语义上一致，而且受到结构化实验证据的支持。为支持可扩展性，将嵌入存储在高性能向量数据库中，允许从不断发展的文献库中进行接近实时检索。实证评估表明，提出的管道检索并综合了关于AMF与作物系统相互作用的相关信息，例如番茄（Solanum lycopersicum）。该框架突显了基于AI的知识发现潜力，可以加速农业生态创新并增强可持续农业生产系统的决策制定。', 'title_zh': '基于RAG的方法优化农业研究：菌根真菌信息优化'}
{'arxiv_id': 'arXiv:2511.14763', 'title': 'Membership Inference Attack against Large Language Model-based Recommendation Systems: A New Distillation-based Paradigm', 'authors': 'Li Cuihong, Huang Xiaowen, Yin Chuanhuan, Sang Jitao', 'link': 'https://arxiv.org/abs/2511.14763', 'abstract': "Membership Inference Attack (MIA) aims to determine if a data sample is used in the training dataset of a target model. Traditional MIA obtains feature of target model via shadow models and uses the feature to train attack model, but the scale and complexity of training or fine-tuning data for large language model (LLM)-based recommendation systems make shadow models difficult to construct. Knowledge distillation as a method for extracting knowledge contributes to construct a stronger reference model. Knowledge distillation enables separate distillation for member and non-member data during the distillation process, enhancing the model's discriminative capability between the two in MIA. This paper propose a knowledge distillation-based MIA paradigm to improve the performance of membership inference attacks on LLM-based recommendation systems. Our paradigm introduces knowledge distillation to obtain a reference model, which enhances the reference model's ability to distinguish between member and non-member data. We obtain individual features from the reference model and train our attack model with fused feature. Our paradigm improves the attack performance of MIA compared to shadow model-based attack.", 'abstract_zh': '基于知识蒸馏的大型语言模型推荐系统成员推理攻击范式', 'title_zh': '基于大型语言模型的推荐系统成员推理攻击：一种新的蒸馏 paradigm'}
{'arxiv_id': 'arXiv:2511.14765', 'title': 'Optimizing Agricultural Research: A RAG-Based Approach to Mycorrhizal Fungi Information', 'authors': 'Mohammad Usman Altam, Md Imtiaz Habib, Tuan Hoang', 'link': 'https://arxiv.org/abs/2511.14765', 'abstract': 'Retrieval-Augmented Generation (RAG) represents a transformative approach within natural language processing (NLP), combining neural information retrieval with generative language modeling to enhance both contextual accuracy and factual reliability of responses. Unlike conventional Large Language Models (LLMs), which are constrained by static training corpora, RAG-powered systems dynamically integrate domain-specific external knowledge sources, thereby overcoming temporal and disciplinary limitations. In this study, we present the design and evaluation of a RAG-enabled system tailored for Mycophyto, with a focus on advancing agricultural applications related to arbuscular mycorrhizal fungi (AMF). These fungi play a critical role in sustainable agriculture by enhancing nutrient acquisition, improving plant resilience under abiotic and biotic stresses, and contributing to soil health. Our system operationalizes a dual-layered strategy: (i) semantic retrieval and augmentation of domain-specific content from agronomy and biotechnology corpora using vector embeddings, and (ii) structured data extraction to capture predefined experimental metadata such as inoculation methods, spore densities, soil parameters, and yield outcomes. This hybrid approach ensures that generated responses are not only semantically aligned but also supported by structured experimental evidence. To support scalability, embeddings are stored in a high-performance vector database, allowing near real-time retrieval from an evolving literature base. Empirical evaluation demonstrates that the proposed pipeline retrieves and synthesizes highly relevant information regarding AMF interactions with crop systems, such as tomato (Solanum lycopersicum). The framework underscores the potential of AI-driven knowledge discovery to accelerate agroecological innovation and enhance decision-making in sustainable farming systems.', 'abstract_zh': 'Retrieval-Augmented Generation (RAG)在自然语言处理中的革命性方法：结合神经检索与生成语言模型以增强响应的上下文准确性和事实可靠性', 'title_zh': '基于RAG的方法优化农业研究：关于菌根 fungi 的信息优化'}
{'arxiv_id': 'arXiv:2511.14764', 'title': 'Image-Seeking Intent Prediction for Cross-Device Product Search', 'authors': 'Mariya Hendriksen, Svitlana Vakulenko, Jordan Massiah, Gabriella Kazai, Emine Yilmaz', 'link': 'https://arxiv.org/abs/2511.14764', 'abstract': 'Large Language Models (LLMs) are transforming personalized search, recommendations, and customer interaction in e-commerce. Customers increasingly shop across multiple devices, from voice-only assistants to multimodal displays, each offering different input and output capabilities. A proactive suggestion to switch devices can greatly improve the user experience, but it must be offered with high precision to avoid unnecessary friction. We address the challenge of predicting when a query requires visual augmentation and a cross-device switch to improve product discovery. We introduce Image-Seeking Intent Prediction, a novel task for LLM-driven e-commerce assistants that anticipates when a spoken product query should proactively trigger a visual on a screen-enabled device. Using large-scale production data from a multi-device retail assistant, including 900K voice queries, associated product retrievals, and behavioral signals such as image carousel engagement, we train IRP (Image Request Predictor), a model that leverages user input query and corresponding retrieved product metadata to anticipate visual intent. Our experiments show that combining query semantics with product data, particularly when improved through lightweight summarization, consistently improves prediction accuracy. Incorporating a differentiable precision-oriented loss further reduces false positives. These results highlight the potential of LLMs to power intelligent, cross-device shopping assistants that anticipate and adapt to user needs, enabling more seamless and personalized e-commerce experiences.', 'abstract_zh': '大规模语言模型（LLMs）正在重塑电子商务中的个性化搜索、推荐和客户互动。顾客越来越多地跨多个设备购物，从仅支持语音的助手到多模态显示屏，每种设备都提供不同的输入和输出能力。主动建议切换设备可以极大地改善用户体验，但必须有高度的精确度以避免不必要的摩擦。我们解决了预测何时查询需要视觉增强和跨设备切换以提高产品发现准确性这一挑战。我们引入了Image-Seeking Intent Prediction（视觉意图预测）这一新颖任务，这是一种由LLM驱动的电子商务助手任务，能够预测何时应主动触发一个屏幕设备上的视觉展示。我们使用来自多设备零售助手的大规模生产数据进行训练，包括900,000条语音查询、相关的产品检索结果以及诸如图片轮播参与度等行为信号，训练了IRP（图像请求预测器）模型，该模型利用用户输入查询及其对应的产品元数据来预测视觉意图。我们的实验结果表明，结合查询语义与产品数据，尤其是在通过轻量级摘要改进后，可以一致地提高预测准确性。通过引入可微分的高精度损失进一步减少误报。这些结果突显了LLMs在驱动智能、跨设备购物助手方面的潜力，这些助手能够预见和适应用户需求，从而提供更加无缝和个性化的电子商务体验。', 'title_zh': '跨设备产品搜索中的图像寻求意图预测'}
{'arxiv_id': 'arXiv:2511.13326', 'title': 'TacEleven: generative tactic discovery for football open play', 'authors': 'Siyao Zhao, Hao Ma, Zhiqiang Pu, Jingjing Huang, Yi Pan, Shijie Wang, Zhi Ming', 'link': 'https://arxiv.org/abs/2511.13326', 'abstract': "Creating offensive advantages during open play is fundamental to football success. However, due to the highly dynamic and long-sequence nature of open play, the potential tactic space grows exponentially as the sequence progresses, making automated tactic discovery extremely challenging. To address this, we propose TacEleven, a generative framework for football open-play tactic discovery developed in close collaboration with domain experts from AJ Auxerre, designed to assist coaches and analysts in tactical decision-making. TacEleven consists of two core components: a language-controlled tactical generator that produces diverse tactical proposals, and a multimodal large language model-based tactical critic that selects the optimal proposal aligned with a high-level stylistic tactical instruction. The two components enables rapid exploration of tactical proposals and discovery of alternative open-play offensive tactics. We evaluate TacEleven across three tasks with progressive tactical complexity: counterfactual exploration, single-step discovery, and multi-step discovery, through both quantitative metrics and a questionnaire-based qualitative assessment. The results show that the TacEleven-discovered tactics exhibit strong realism and tactical creativity, with 52.50% of the multi-step tactical alternatives rated adoptable in real-world elite football scenarios, highlighting the framework's ability to rapidly generate numerous high-quality tactics for complex long-sequence open-play situations. TacEleven demonstrates the potential of creatively leveraging domain data and generative models to advance tactical analysis in sports.", 'abstract_zh': '基于生成模型的足球开放play战术发现：TacEleven框架', 'title_zh': 'TacEleven: 生成性战术发现用于足球开放进攻'}
{'arxiv_id': 'arXiv:2511.14764', 'title': 'Image-Seeking Intent Prediction for Cross-Device Product Search', 'authors': 'Mariya Hendriksen, Svitlana Vakulenko, Jordan Massiah, Gabriella Kazai, Emine Yilmaz', 'link': 'https://arxiv.org/abs/2511.14764', 'abstract': 'Large Language Models (LLMs) are transforming personalized search, recommendations, and customer interaction in e-commerce. Customers increasingly shop across multiple devices, from voice-only assistants to multimodal displays, each offering different input and output capabilities. A proactive suggestion to switch devices can greatly improve the user experience, but it must be offered with high precision to avoid unnecessary friction. We address the challenge of predicting when a query requires visual augmentation and a cross-device switch to improve product discovery. We introduce Image-Seeking Intent Prediction, a novel task for LLM-driven e-commerce assistants that anticipates when a spoken product query should proactively trigger a visual on a screen-enabled device. Using large-scale production data from a multi-device retail assistant, including 900K voice queries, associated product retrievals, and behavioral signals such as image carousel engagement, we train IRP (Image Request Predictor), a model that leverages user input query and corresponding retrieved product metadata to anticipate visual intent. Our experiments show that combining query semantics with product data, particularly when improved through lightweight summarization, consistently improves prediction accuracy. Incorporating a differentiable precision-oriented loss further reduces false positives. These results highlight the potential of LLMs to power intelligent, cross-device shopping assistants that anticipate and adapt to user needs, enabling more seamless and personalized e-commerce experiences.', 'abstract_zh': '大型语言模型（LLMs）正在重塑电子商务中的个性化搜索、推荐和客户互动。随着客户越来越多地跨多种设备购物，从仅支持语音的助手到多模态显示器，每种设备都提供了不同的输入和输出能力。适时地建议切换设备可以显著提升用户体验，但必须非常精准以避免不必要的摩擦。我们解决了一个挑战，即预测何时通过跨设备切换和视觉增强来提升产品发现的需求。我们引入了图像寻求意图预测这一新任务，这是一种由LLM驱动的电子商务助手任务，能够预测何时应主动触发与屏幕设备关联的视觉内容。我们利用多设备零售助手的大规模生产数据，包括90万语音查询、相关的产品检索和行为信号（如图像轮播参与度），训练IRP（图像请求预测器）模型，该模型利用用户输入查询和相应检索的产品元数据来预测视觉意图。我们的实验表明，将查询语义与产品数据相结合，尤其是在通过轻量级总结改进后，能够一致地提高预测准确性。引入可微分的高精度损失进一步降低了误报率。这些结果突显了大型语言模型在驱动智能、跨设备购物助手方面的潜力，这些助手能够预判和适应用户需求，从而提供更加无缝和个性化的电子商务体验。', 'title_zh': '跨设备产品搜索中的图像搜索意图预测'}
{'arxiv_id': 'arXiv:2511.14763', 'title': 'Membership Inference Attack against Large Language Model-based Recommendation Systems: A New Distillation-based Paradigm', 'authors': 'Li Cuihong, Huang Xiaowen, Yin Chuanhuan, Sang Jitao', 'link': 'https://arxiv.org/abs/2511.14763', 'abstract': "Membership Inference Attack (MIA) aims to determine if a data sample is used in the training dataset of a target model. Traditional MIA obtains feature of target model via shadow models and uses the feature to train attack model, but the scale and complexity of training or fine-tuning data for large language model (LLM)-based recommendation systems make shadow models difficult to construct. Knowledge distillation as a method for extracting knowledge contributes to construct a stronger reference model. Knowledge distillation enables separate distillation for member and non-member data during the distillation process, enhancing the model's discriminative capability between the two in MIA. This paper propose a knowledge distillation-based MIA paradigm to improve the performance of membership inference attacks on LLM-based recommendation systems. Our paradigm introduces knowledge distillation to obtain a reference model, which enhances the reference model's ability to distinguish between member and non-member data. We obtain individual features from the reference model and train our attack model with fused feature. Our paradigm improves the attack performance of MIA compared to shadow model-based attack.", 'abstract_zh': '基于知识蒸馏的大型语言模型推荐系统成员推理攻击范式', 'title_zh': '面向基于大型语言模型的推荐系统的成员推断攻击：一种新的知识蒸馏范式'}
{'arxiv_id': 'arXiv:2511.02505', 'title': 'ESA: Energy-Based Shot Assembly Optimization for Automatic Video Editing', 'authors': 'Yaosen Chen, Wei Wang, Tianheng Zheng, Xuming Wen, Han Yang, Yanru Zhang', 'link': 'https://arxiv.org/abs/2511.02505', 'abstract': "Shot assembly is a crucial step in film production and video editing, involving the sequencing and arrangement of shots to construct a narrative, convey information, or evoke emotions. Traditionally, this process has been manually executed by experienced editors. While current intelligent video editing technologies can handle some automated video editing tasks, they often fail to capture the creator's unique artistic expression in shot assembly. To address this challenge, we propose an energy-based optimization method for video shot assembly. Specifically, we first perform visual-semantic matching between the script generated by a large language model and a video library to obtain subsets of candidate shots aligned with the script semantics. Next, we segment and label the shots from reference videos, extracting attributes such as shot size, camera motion, and semantics. We then employ energy-based models to learn from these attributes, scoring candidate shot sequences based on their alignment with reference styles. Finally, we achieve shot assembly optimization by combining multiple syntax rules, producing videos that align with the assembly style of the reference videos. Our method not only automates the arrangement and combination of independent shots according to specific logic, narrative requirements, or artistic styles but also learns the assembly style of reference videos, creating a coherent visual sequence or holistic visual expression. With our system, even users with no prior video editing experience can create visually compelling videos. Project page: this https URL", 'abstract_zh': '帧组装是电影制作和视频编辑中的一个关键步骤，涉及将帧按顺序排列以构建叙述、传达信息或唤起情感。传统上，这一过程由经验丰富的编辑手动执行。尽管当前的智能视频编辑技术可以处理一些自动视频编辑任务，但它们往往无法捕捉创作者在帧组装中的独特艺术表达。为了解决这一挑战，我们提出了一种基于能量的优化方法用于视频帧组装。具体来说，我们首先通过大型语言模型生成的剧本与视频库进行视觉语义匹配，以获取与剧本语义相匹配的候选镜头集。然后，我们对参考视频进行分段和标注，提取诸如镜头大小、摄像机运动和语义等属性。接着，我们利用基于能量的模型从这些属性中学习，并根据参考样式的匹配度对候选镜头序列进行评分。最后，我们通过结合多种语法规则实现镜头组装优化，生成与参考视频组装风格一致的视频。我们的方法不仅能够根据特定逻辑、叙述要求或艺术风格自动化独立镜头的排列与组合，还能学习参考视频的组装风格，从而创建一个连贯的视觉序列或整体视觉表现。借助我们的系统，即使是没有任何视频编辑经验的用户也能制作出视觉上引人注目的视频。项目页面：this https URL。', 'title_zh': 'ESA：基于能量的镜头组装优化自动视频编辑'}
{'arxiv_id': 'arXiv:2511.14763', 'title': 'Membership Inference Attack against Large Language Model-based Recommendation Systems: A New Distillation-based Paradigm', 'authors': 'Li Cuihong, Huang Xiaowen, Yin Chuanhuan, Sang Jitao', 'link': 'https://arxiv.org/abs/2511.14763', 'abstract': "Membership Inference Attack (MIA) aims to determine if a data sample is used in the training dataset of a target model. Traditional MIA obtains feature of target model via shadow models and uses the feature to train attack model, but the scale and complexity of training or fine-tuning data for large language model (LLM)-based recommendation systems make shadow models difficult to construct. Knowledge distillation as a method for extracting knowledge contributes to construct a stronger reference model. Knowledge distillation enables separate distillation for member and non-member data during the distillation process, enhancing the model's discriminative capability between the two in MIA. This paper propose a knowledge distillation-based MIA paradigm to improve the performance of membership inference attacks on LLM-based recommendation systems. Our paradigm introduces knowledge distillation to obtain a reference model, which enhances the reference model's ability to distinguish between member and non-member data. We obtain individual features from the reference model and train our attack model with fused feature. Our paradigm improves the attack performance of MIA compared to shadow model-based attack.", 'abstract_zh': '基于知识蒸馏的会员推理攻击范式', 'title_zh': '针对基于大型语言模型的推荐系统的目标推理攻击：一种新的蒸馏基于范式'}
{'arxiv_id': 'arXiv:2511.13326', 'title': 'TacEleven: generative tactic discovery for football open play', 'authors': 'Siyao Zhao, Hao Ma, Zhiqiang Pu, Jingjing Huang, Yi Pan, Shijie Wang, Zhi Ming', 'link': 'https://arxiv.org/abs/2511.13326', 'abstract': "Creating offensive advantages during open play is fundamental to football success. However, due to the highly dynamic and long-sequence nature of open play, the potential tactic space grows exponentially as the sequence progresses, making automated tactic discovery extremely challenging. To address this, we propose TacEleven, a generative framework for football open-play tactic discovery developed in close collaboration with domain experts from AJ Auxerre, designed to assist coaches and analysts in tactical decision-making. TacEleven consists of two core components: a language-controlled tactical generator that produces diverse tactical proposals, and a multimodal large language model-based tactical critic that selects the optimal proposal aligned with a high-level stylistic tactical instruction. The two components enables rapid exploration of tactical proposals and discovery of alternative open-play offensive tactics. We evaluate TacEleven across three tasks with progressive tactical complexity: counterfactual exploration, single-step discovery, and multi-step discovery, through both quantitative metrics and a questionnaire-based qualitative assessment. The results show that the TacEleven-discovered tactics exhibit strong realism and tactical creativity, with 52.50% of the multi-step tactical alternatives rated adoptable in real-world elite football scenarios, highlighting the framework's ability to rapidly generate numerous high-quality tactics for complex long-sequence open-play situations. TacEleven demonstrates the potential of creatively leveraging domain data and generative models to advance tactical analysis in sports.", 'abstract_zh': '在开放进攻中的创造优势是足球成功的基础。然而，由于开放进攻的高度动态性和长序列特性，随着序列的进展，潜在战术空间呈指数级增长，这使得自动化战术发现极具挑战性。为解决这一问题，我们提出TacEleven，这是一种与来自AJ Auxerre的领域专家密切合作开发的生成框架，旨在协助教练和分析人员进行战术决策。TacEleven包含两个核心组件：一种由语言控制的战术生成器，可以生成多样化的战术提案；以及基于多模态大语言模型的战术评判器，可以根据高层次的战术风格指令选择最佳提案。这两个组件使得快速探索战术提案和发现替代开放进攻战术成为可能。我们通过定性和定量指标，分别在三个具有逐步战术复杂度的任务中评估TacEleven：反事实探索、单步发现和多步发现。结果显示，TacEleven发现的战术具备强烈的现实性和战术创意，52.50%的多步战术备选方案在实际精英足球场景中被认为可以采用，突显了该框架能够快速生成大量高质量复杂长序列开放进攻战术的能力。TacEleven展示了创造性利用领域数据和生成模型在体育战术分析中推动进步的潜力。', 'title_zh': 'TacEleven: 生成性战术发现用于足球开放战术'}
{'arxiv_id': 'arXiv:2511.13326', 'title': 'TacEleven: generative tactic discovery for football open play', 'authors': 'Siyao Zhao, Hao Ma, Zhiqiang Pu, Jingjing Huang, Yi Pan, Shijie Wang, Zhi Ming', 'link': 'https://arxiv.org/abs/2511.13326', 'abstract': "Creating offensive advantages during open play is fundamental to football success. However, due to the highly dynamic and long-sequence nature of open play, the potential tactic space grows exponentially as the sequence progresses, making automated tactic discovery extremely challenging. To address this, we propose TacEleven, a generative framework for football open-play tactic discovery developed in close collaboration with domain experts from AJ Auxerre, designed to assist coaches and analysts in tactical decision-making. TacEleven consists of two core components: a language-controlled tactical generator that produces diverse tactical proposals, and a multimodal large language model-based tactical critic that selects the optimal proposal aligned with a high-level stylistic tactical instruction. The two components enables rapid exploration of tactical proposals and discovery of alternative open-play offensive tactics. We evaluate TacEleven across three tasks with progressive tactical complexity: counterfactual exploration, single-step discovery, and multi-step discovery, through both quantitative metrics and a questionnaire-based qualitative assessment. The results show that the TacEleven-discovered tactics exhibit strong realism and tactical creativity, with 52.50% of the multi-step tactical alternatives rated adoptable in real-world elite football scenarios, highlighting the framework's ability to rapidly generate numerous high-quality tactics for complex long-sequence open-play situations. TacEleven demonstrates the potential of creatively leveraging domain data and generative models to advance tactical analysis in sports.", 'abstract_zh': '在开放比赛状态下创造进攻优势是足球成功的基础。然而，由于开放比赛的高度动态性和长序列性质，潜在的战术空间会随着序列的推进呈指数级增长，使得自动化战术发现极具挑战性。为解决这一问题，我们提出TacEleven，这是一种与AJ Auxerre领域专家密切合作开发的生成框架，旨在辅助教练和分析人员进行战术决策。TacEleven包括两个核心组件：一种语言控制的战术生成器，能够生成多样的战术提案；以及一种基于多模态大型语言模型的战术批判者，能够根据高层次风格化的战术指令选择最优提案。这两个组件使得能够快速探索战术提案，并发现替代的开放比赛进攻战术。通过定量指标和问卷调查进行的定性评估，我们分别在三个具有不同战术复杂度的任务：反事实探索、单步发现和多步发现中对TacEleven进行了评估。结果显示，TacEleven发现的战术表现出强烈的真实性和战术创新性，其中52.50%的多步战术替代方案在实际精英足球场景中被认为具有可采纳性，突显了该框架能够快速生成大量高质量战术以应对复杂的长序列开放比赛情境的能力。TacEleven展示了创造性利用领域数据和生成模型推进体育战术分析的潜力。', 'title_zh': 'TacEleven: 生成性战术发现用于足球开放配合'}
{'arxiv_id': 'arXiv:2511.02505', 'title': 'ESA: Energy-Based Shot Assembly Optimization for Automatic Video Editing', 'authors': 'Yaosen Chen, Wei Wang, Tianheng Zheng, Xuming Wen, Han Yang, Yanru Zhang', 'link': 'https://arxiv.org/abs/2511.02505', 'abstract': "Shot assembly is a crucial step in film production and video editing, involving the sequencing and arrangement of shots to construct a narrative, convey information, or evoke emotions. Traditionally, this process has been manually executed by experienced editors. While current intelligent video editing technologies can handle some automated video editing tasks, they often fail to capture the creator's unique artistic expression in shot assembly. To address this challenge, we propose an energy-based optimization method for video shot assembly. Specifically, we first perform visual-semantic matching between the script generated by a large language model and a video library to obtain subsets of candidate shots aligned with the script semantics. Next, we segment and label the shots from reference videos, extracting attributes such as shot size, camera motion, and semantics. We then employ energy-based models to learn from these attributes, scoring candidate shot sequences based on their alignment with reference styles. Finally, we achieve shot assembly optimization by combining multiple syntax rules, producing videos that align with the assembly style of the reference videos. Our method not only automates the arrangement and combination of independent shots according to specific logic, narrative requirements, or artistic styles but also learns the assembly style of reference videos, creating a coherent visual sequence or holistic visual expression. With our system, even users with no prior video editing experience can create visually compelling videos. Project page: this https URL", 'abstract_zh': '镜头装配是电影制作和视频编辑中的关键步骤，涉及镜头的排序和排列以构建叙事、传达信息或引起情感反应。传统上，这一过程由经验丰富的编辑手动执行。尽管当前的智能视频编辑技术可以处理一些自动视频编辑任务，但它们往往无法捕捉创作者在镜头装配中的独特艺术表达。为了解决这一挑战，我们提出了一种基于能量的优化方法，用于视频镜头装配。具体而言，我们首先在剧本生成器（大型语言模型）生成的剧本与视频库之间进行视觉语义匹配，以获取与剧本语义相匹配的候选镜头子集。接着，我们对参考视频中的镜头进行分割和标记，提取诸如镜头大小、摄像机运动和语义等属性。然后，我们使用基于能量的模型从这些属性中学习，根据参考风格对候选镜头序列进行评分。最后，通过结合多个语法规则实现镜头装配优化，生成与参考视频装配风格一致的视频。我们的方法不仅可以根据特定逻辑、叙事需求或艺术风格自动排列和组合独立镜头，还能学习参考视频的装配风格，创造一个连贯的视觉序列或整体的视觉表达。借助我们的系统，即使是没有任何视频编辑经验的用户也可以创作出令人视觉印象深刻的视频。项目页面：this https URL', 'title_zh': 'ESA：基于能量的镜头组装优化自动视频编辑'}
{'arxiv_id': 'arXiv:2511.02505', 'title': 'ESA: Energy-Based Shot Assembly Optimization for Automatic Video Editing', 'authors': 'Yaosen Chen, Wei Wang, Tianheng Zheng, Xuming Wen, Han Yang, Yanru Zhang', 'link': 'https://arxiv.org/abs/2511.02505', 'abstract': "Shot assembly is a crucial step in film production and video editing, involving the sequencing and arrangement of shots to construct a narrative, convey information, or evoke emotions. Traditionally, this process has been manually executed by experienced editors. While current intelligent video editing technologies can handle some automated video editing tasks, they often fail to capture the creator's unique artistic expression in shot assembly. To address this challenge, we propose an energy-based optimization method for video shot assembly. Specifically, we first perform visual-semantic matching between the script generated by a large language model and a video library to obtain subsets of candidate shots aligned with the script semantics. Next, we segment and label the shots from reference videos, extracting attributes such as shot size, camera motion, and semantics. We then employ energy-based models to learn from these attributes, scoring candidate shot sequences based on their alignment with reference styles. Finally, we achieve shot assembly optimization by combining multiple syntax rules, producing videos that align with the assembly style of the reference videos. Our method not only automates the arrangement and combination of independent shots according to specific logic, narrative requirements, or artistic styles but also learns the assembly style of reference videos, creating a coherent visual sequence or holistic visual expression. With our system, even users with no prior video editing experience can create visually compelling videos. Project page: this https URL", 'abstract_zh': '镜头组装是电影制作和视频编辑中的一个 crucial 步骤，涉及将镜头进行排序和排列以构建叙事、传达信息或唤起情感。传统上，这一过程由有经验的编辑手动完成。尽管当前的智能视频编辑技术可以处理一些自动视频编辑任务，但在镜头组装过程中往往无法捕捉创作者的独特艺术表达。为了解决这一挑战，我们提出了一种基于能量优化的视频镜头组装方法。具体而言，我们首先通过大型语言模型生成的剧本与视频库进行视觉语义匹配，以获得与剧本语义相匹配的候选镜头子集。然后，我们从参考视频中分割和标注镜头，提取诸如镜头大小、摄像机运动和语义等属性。接着，我们采用基于能量的模型从这些属性中进行学习，根据候选镜头序列与参考风格的匹配程度进行评分。最后，我们通过结合多种语法规则实现镜头组装优化，生成与参考视频组装风格一致的视频。我们的方法不仅能够根据特定逻辑、叙事要求或艺术风格自动化地排列和组合独立镜头，还能学习参考视频的组装风格，从而创建连贯的视觉序列或整体视觉表达。借助我们的系统，即使是没有任何视频编辑经验的用户也能创建令人信服的视觉视频。项目页面：this https URL', 'title_zh': 'ESA：基于能量的镜头组装优化以实现自动视频编辑'}
