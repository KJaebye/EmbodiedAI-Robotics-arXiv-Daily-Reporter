{'arxiv_id': 'arXiv:2511.15593', 'title': 'What Does It Take to Be a Good AI Research Agent? Studying the Role of Ideation Diversity', 'authors': 'Alexis Audran-Reiss, Jordi Armengol Estapé, Karen Hambardzumyan, Amar Budhiraja, Martin Josifoski, Edan Toledo, Rishi Hazra, Despoina Magka, Michael Shvartsman, Parth Pathak, Justine T Kao, Lucia Cipolina-Kun, Bhavul Gauri, Jean-Christophe Gagnon-Audet, Emanuel Tewolde, Jenny Zhang, Taco Cohen, Yossi Adi, Tatiana Shavrina, Yoram Bachrach', 'link': 'https://arxiv.org/abs/2511.15593', 'abstract': 'AI research agents offer the promise to accelerate scientific progress by automating the design, implementation, and training of machine learning models. However, the field is still in its infancy, and the key factors driving the success or failure of agent trajectories are not fully understood. We examine the role that ideation diversity plays in agent performance. First, we analyse agent trajectories on MLE-bench, a well-known benchmark to evaluate AI research agents, across different models and agent scaffolds. Our analysis reveals that different models and agent scaffolds yield varying degrees of ideation diversity, and that higher-performing agents tend to have increased ideation diversity. Further, we run a controlled experiment where we modify the degree of ideation diversity, demonstrating that higher ideation diversity results in stronger performance. Finally, we strengthen our results by examining additional evaluation metrics beyond the standard medal-based scoring of MLE-bench, showing that our findings still hold across other agent performance metrics.', 'abstract_zh': 'AI研究代理通过自动化机器学习模型的设计、实现和训练来加速科学进步，但该领域仍处于初级阶段，驱动代理轨迹成功或失败的关键因素尚不完全清楚。我们探讨了理念多样性的角色在代理性能中的作用。首先，我们在MLE-bench这一知名基准上分析不同模型和代理支架下的代理轨迹。我们的分析显示，不同的模型和代理支架会产生不同程度的理念多样性，且表现更好的代理往往具备更高的理念多样性。其次，我们进行了一项控制实验，调整理念多样性的程度，证明更高的理念多样性可以提升代理性能。最后，我们通过考察超越MLE-bench标准奖牌评分的其他评估指标来增强我们的结果，显示我们的发现仍然适用于其他代理性能指标。', 'title_zh': '成为一个优秀的AI研究代理需要什么？探究创意多样性的作用'}
{'arxiv_id': 'arXiv:2511.15534', 'title': 'Exploring the use of AI authors and reviewers at Agents4Science', 'authors': 'Federico Bianchi, Owen Queen, Nitya Thakkar, Eric Sun, James Zou', 'link': 'https://arxiv.org/abs/2511.15534', 'abstract': 'There is growing interest in using AI agents for scientific research, yet fundamental questions remain about their capabilities as scientists and reviewers. To explore these questions, we organized Agents4Science, the first conference in which AI agents serve as both primary authors and reviewers, with humans as co-authors and co-reviewers. Here, we discuss the key learnings from the conference and their implications for human-AI collaboration in science.', 'abstract_zh': 'AI代理在科学研究中的应用：人类与AI的合作探讨', 'title_zh': '探索AI作者和评审员在Agents4Science中的应用'}
{'arxiv_id': 'arXiv:2511.15378', 'title': 'Terra Nova: A Comprehensive Challenge Environment for Intelligent Agents', 'authors': 'Trevor McInroe', 'link': 'https://arxiv.org/abs/2511.15378', 'abstract': "We introduce Terra Nova, a new comprehensive challenge environment (CCE) for reinforcement learning (RL) research inspired by Civilization V. A CCE is a single environment in which multiple canonical RL challenges (e.g., partial observability, credit assignment, representation learning, enormous action spaces, etc.) arise simultaneously. Mastery therefore demands integrated, long-horizon understanding across many interacting variables. We emphasize that this definition excludes challenges that only aggregate unrelated tasks in independent, parallel streams (e.g., learning to play all Atari games at once). These aggregated multitask benchmarks primarily asses whether an agent can catalog and switch among unrelated policies rather than test an agent's ability to perform deep reasoning across many interacting challenges.", 'abstract_zh': '我们介绍Terra Nova：一种受文明V启发的新型综合挑战环境（CCE）以促进强化学习（RL）研究', 'title_zh': 'Terra Nova: 一个全面的智能代理挑战环境'}
{'arxiv_id': 'arXiv:2511.15282', 'title': 'Realist and Pluralist Conceptions of Intelligence and Their Implications on AI Research', 'authors': 'Ninell Oldenburg, Ruchira Dhar, Anders Søgaard', 'link': 'https://arxiv.org/abs/2511.15282', 'abstract': 'In this paper, we argue that current AI research operates on a spectrum between two different underlying conceptions of intelligence: Intelligence Realism, which holds that intelligence represents a single, universal capacity measurable across all systems, and Intelligence Pluralism, which views intelligence as diverse, context-dependent capacities that cannot be reduced to a single universal measure. Through an analysis of current debates in AI research, we demonstrate how the conceptions remain largely implicit yet fundamentally shape how empirical evidence gets interpreted across a wide range of areas. These underlying views generate fundamentally different research approaches across three areas. Methodologically, they produce different approaches to model selection, benchmark design, and experimental validation. Interpretively, they lead to contradictory readings of the same empirical phenomena, from capability emergence to system limitations. Regarding AI risk, they generate categorically different assessments: realists view superintelligence as the primary risk and search for unified alignment solutions, while pluralists see diverse threats across different domains requiring context-specific solutions. We argue that making explicit these underlying assumptions can contribute to a clearer understanding of disagreements in AI research.', 'abstract_zh': '本文argument了当前AI研究在两种不同的智能观念之间运作：智能现实主义认为智能是一种可衡量的普遍能力，而智能多元论认为智能是多样且基于情境的能力，无法简化为单一标准。通过对当前AI研究中的争论分析，我们展示了这些观念虽隐含但根本上如何影响广泛领域中实证证据的解读。这些基础观念在三个领域生成了不同的研究方法。在方法论上，它们导致了不同的模型选择、基准设计和实验验证方法。在解释上，它们导致了对相同实证现象的对立解读，从能力涌现到系统局限性。在AI风险方面，它们产生了截然不同的评估：现实主义者视超智能为主要风险，寻求统一的对齐解决方案，而多元论者则认为存在跨不同领域的多种不同威胁，需要情境特定的解决方案。我们argue明确这些基础假设可以有助于更清晰地理解AI研究中的分歧。', 'title_zh': '现实主义与多元主义的智能观念及其对AI研究的影响'}
{'arxiv_id': 'arXiv:2511.15259', 'title': 'Efficiency Will Not Lead to Sustainable Reasoning AI', 'authors': "Philipp Wiesner, Daniel W. O'Neill, Francesca Larosa, Odej Kao", 'link': 'https://arxiv.org/abs/2511.15259', 'abstract': "AI research is increasingly moving toward complex problem solving, where models are optimized not only for pattern recognition but for multi-step reasoning. Historically, computing's global energy footprint has been stabilized by sustained efficiency gains and natural saturation thresholds in demand. But as efficiency improvements are approaching physical limits, emerging reasoning AI lacks comparable saturation points: performance is no longer limited by the amount of available training data but continues to scale with exponential compute investments in both training and inference. This paper argues that efficiency alone will not lead to sustainable reasoning AI and discusses research and policy directions to embed explicit limits into the optimization and governance of such systems.", 'abstract_zh': 'AI研究 increasingly转向复杂问题求解：效率边界将取代数据边界推动 reasoning AI 发展及治理方向探讨', 'title_zh': '效率不会导致可持续推理AI'}
{'arxiv_id': 'arXiv:2511.15002', 'title': 'Task Specific Sharpness Aware O-RAN Resource Management using Multi Agent Reinforcement Learning', 'authors': 'Fatemeh Lotfi, Hossein Rajoli, Fatemeh Afghah', 'link': 'https://arxiv.org/abs/2511.15002', 'abstract': 'Next-generation networks utilize the Open Radio Access Network (O-RAN) architecture to enable dynamic resource management, facilitated by the RAN Intelligent Controller (RIC). While deep reinforcement learning (DRL) models show promise in optimizing network resources, they often struggle with robustness and generalizability in dynamic environments. This paper introduces a novel resource management approach that enhances the Soft Actor Critic (SAC) algorithm with Sharpness-Aware Minimization (SAM) in a distributed Multi-Agent RL (MARL) framework. Our method introduces an adaptive and selective SAM mechanism, where regularization is explicitly driven by temporal-difference (TD)-error variance, ensuring that only agents facing high environmental complexity are regularized. This targeted strategy reduces unnecessary overhead, improves training stability, and enhances generalization without sacrificing learning efficiency. We further incorporate a dynamic $\\rho$ scheduling scheme to refine the exploration-exploitation trade-off across agents. Experimental results show our method significantly outperforms conventional DRL approaches, yielding up to a $22\\%$ improvement in resource allocation efficiency and ensuring superior QoS satisfaction across diverse O-RAN slices.', 'abstract_zh': '下一代网络利用开放无线接入网（O-RAN）架构并通过无线接入网智能控制器（RIC）实现动态资源管理。虽然深度强化学习（DRL）模型在优化网络资源方面显示出潜力，但它们在动态环境中的健壮性和泛化能力通常较差。本文介绍了一种新颖的资源管理方法，该方法在分布式多代理强化学习（MARL）框架中增强了Soft Actor Critic（SAC）算法，并结合了Sharpness-Aware Minimization（SAM）机制。该方法引入了一种自适应和选择性的SAM机制，通过时间差分（TD）误差方差显式驱动正则化，确保仅在面对高环境复杂性时才进行正则化。这一目标策略减少了不必要的开销，提高了训练稳定性，并在不牺牲学习效率的情况下增强泛化能力。此外，本文还引入了一种动态$\\rho$调度方案，以跨代理优化探索与利用的权衡。实验结果表明，该方法显著优于传统DRL方法，在资源分配效率上提升了高达22%，并在各种O-RAN切片中确保了更优的QoS满意度。', 'title_zh': '任务特定的敏锐度意识O-RAN资源管理多代理强化学习'}
{'arxiv_id': 'arXiv:2511.14853', 'title': 'Uncertainty-Aware Measurement of Scenario Suite Representativeness for Autonomous Systems', 'authors': 'Robab Aghazadeh Chakherlou, Siddartha Khastgir, Xingyu Zhao, Jerein Jeyachandran, Shufeng Chen', 'link': 'https://arxiv.org/abs/2511.14853', 'abstract': 'Assuring the trustworthiness and safety of AI systems, e.g., autonomous vehicles (AV), depends critically on the data-related safety properties, e.g., representativeness, completeness, etc., of the datasets used for their training and testing. Among these properties, this paper focuses on representativeness-the extent to which the scenario-based data used for training and testing, reflect the operational conditions that the system is designed to operate safely in, i.e., Operational Design Domain (ODD) or expected to encounter, i.e., Target Operational Domain (TOD). We propose a probabilistic method that quantifies representativeness by comparing the statistical distribution of features encoded by the scenario suites with the corresponding distribution of features representing the TOD, acknowledging that the true TOD distribution is unknown, as it can only be inferred from limited data.\nWe apply an imprecise Bayesian method to handle limited data and uncertain priors. The imprecise Bayesian formulation produces interval-valued, uncertainty-aware estimates of representativeness, rather than a single value. We present a numerical example comparing the distributions of the scenario suite and the inferred TOD across operational categories-weather, road type, time of day, etc., under dependencies and prior uncertainty. We estimate representativeness locally (between categories) and globally as an interval.', 'abstract_zh': '确保人工智能系统如自动驾驶车辆的信任worthiness与安全性依赖于用于其训练和测试的数据的相关安全属性，例如代表性、完整性等。本文重点关注代表性，即用于训练和测试的基于场景的数据在多大程度上反映了系统设计用于安全运行的操作设计域（ODD）或预期可能遇到的目标操作域（TOD）。我们提出了一种概率方法，通过比较场景套件中编码的特征的统计分布与表示TOD的相应分布来量化代表性，同时承认真正的TOD分布是未知的，因为它只能从有限的数据中推断出来。我们使用模糊贝叶斯方法处理有限数据和不确定性先验。模糊贝叶斯公式产生区间值、具有不确定性的代表性估计，而不是单一值。我们在具有依赖性和先验不确定性的情况下展示了操作类别（如天气、道路类型、时间等）下场景套件和推断的TOD分布的数值示例，局部估计代表性并在全局上表示为区间。', 'title_zh': '自主系统场景集合代表性的不确定性感知度量'}
{'arxiv_id': 'arXiv:2511.14819', 'title': 'Project Rachel: Can an AI Become a Scholarly Author?', 'authors': 'Martin Monperrus, Benoit Baudry, Clément Vidal', 'link': 'https://arxiv.org/abs/2511.14819', 'abstract': 'This paper documents Project Rachel, an action research study that created and tracked a complete AI academic identity named Rachel So. Through careful publication of AI-generated research papers, we investigate how the scholarly ecosystem responds to AI authorship. Rachel So published 10+ papers between March and October 2025, was cited, and received a peer review invitation. We discuss the implications of AI authorship on publishers, researchers, and the scientific system at large. This work contributes empirical action research data to the necessary debate about the future of scholarly communication with super human, hyper capable AI systems.', 'abstract_zh': '本研究记录了Project Rachel项目，该项目创建并跟踪了一个完整的AI学术身份——Rachel So。通过精心发布的AI生成的研究论文，我们探讨了学术生态系统对AI作者身份的响应。Rachel So在2025年3月至10月间发表了10多篇论文，并被引用，还收到了同行评审邀请。我们讨论了AI作者身份对出版商、研究人员及更广泛的科学系统的潜在影响。本研究为关于超人类、超能力强的AI系统未来对学术交流影响的必要辩论提供了实证行动研究数据。', 'title_zh': '项目蕾切尔：AI能否成为学术作者？'}
{'arxiv_id': 'arXiv:2511.14778', 'title': 'Learning Interestingness in Automated Mathematical Theory Formation', 'authors': 'George Tsoukalas, Rahul Saha, Amitayush Thakur, Sabrina Reguyal, Swarat Chaudhuri', 'link': 'https://arxiv.org/abs/2511.14778', 'abstract': 'We take two key steps in automating the open-ended discovery of new mathematical theories, a grand challenge in artificial intelligence. First, we introduce $\\emph{FERMAT}$, a reinforcement learning (RL) environment that models concept discovery and theorem-proving using a set of symbolic actions, opening up a range of RL problems relevant to theory discovery. Second, we explore a specific problem through $\\emph{FERMAT}$: automatically scoring the $\\emph{interestingness}$ of mathematical objects. We investigate evolutionary algorithms for synthesizing nontrivial interestingness measures. In particular, we introduce an LLM-based evolutionary algorithm that features function abstraction, leading to notable improvements in discovering elementary number theory and finite fields over hard-coded baselines. We open-source the $\\emph{FERMAT}$ environment at this URL(this https URL).', 'abstract_zh': '我们在这项工作中共实现了自动化发现新数学理论的两个关键步骤，这是人工智能领域的一项宏伟挑战。首先，我们引入了$\\emph{FERMAT}$，一个基于符号操作的强化学习环境，用于建模概念发现和定理证明，从而开启了与理论发现相关的广泛RL问题空间。其次，我们通过$\\emph{FERMAT}$探讨了一个具体问题：自动评估数学对象的“有趣性”。我们研究了进化算法以合成非平凡的兴趣度量，并引入了一种基于大语言模型的进化算法，该算法具备函数抽象特性，并在发现初等数论和有限域方面取得了显著进步。我们开源了$\\emph{FERMAT}$环境，网址见下：(这个 https URL)。', 'title_zh': '自动数学理论形成中的兴趣性学习'}
{'arxiv_id': 'arXiv:2511.15699', 'title': 'Joint Semantic-Channel Coding and Modulation for Token Communications', 'authors': 'Jingkai Ying, Zhijin Qin, Yulong Feng, Liejun Wang, Xiaoming Tao', 'link': 'https://arxiv.org/abs/2511.15699', 'abstract': 'In recent years, the Transformer architecture has achieved outstanding performance across a wide range of tasks and modalities. Token is the unified input and output representation in Transformer-based models, which has become a fundamental information unit. In this work, we consider the problem of token communication, studying how to transmit tokens efficiently and reliably. Point cloud, a prevailing three-dimensional format which exhibits a more complex spatial structure compared to image or video, is chosen to be the information source. We utilize the set abstraction method to obtain point tokens. Subsequently, to get a more informative and transmission-friendly representation based on tokens, we propose a joint semantic-channel and modulation (JSCCM) scheme for the token encoder, mapping point tokens to standard digital constellation points (modulated tokens). Specifically, the JSCCM consists of two parallel Point Transformer-based encoders and a differential modulator which combines the Gumel-softmax and soft quantization methods. Besides, the rate allocator and channel adapter are developed, facilitating adaptive generation of high-quality modulated tokens conditioned on both semantic information and channel conditions. Extensive simulations demonstrate that the proposed method outperforms both joint semantic-channel coding and traditional separate coding, achieving over 1dB gain in reconstruction and more than 6x compression ratio in modulated symbols.', 'abstract_zh': '近年来，Transformer架构在各种任务和模态中取得了出色的表现。Token是基于Transformer模型的统一输入和输出表示，已经成为基本的信息单元。在本文中，我们考虑了Token通信的问题，研究如何高效可靠地传输Token。点云作为一种相比于图像或视频表现出更复杂空间结构的主流三维格式，被选为信息源。我们利用集合抽象方法获得点Token。随后，为了基于Token获得更具信息量且便于传输的表示，我们提出了一种联合语义信道和调制（JSCCM）方案，将点Token映射为标准数字星座点（调制Token）。具体来说，JSCCM由两个并行的基于点Transformer的编码器和一个结合Gumel-softmax和软量化方法的差分调制器组成。此外，我们开发了速率分配器和信道适配器，以根据语义信息和信道条件自适应地生成高质量的调制Token。广泛仿真实验表明，所提出的方法在重建方面优于联合语义信道编码和传统分离编码，获得了超过1dB的增益，并且在调制符号方面的压缩比超过6倍。', 'title_zh': '联合语义-通道编码与调制技术在Token通信中的应用'}
{'arxiv_id': 'arXiv:2511.15623', 'title': 'Sufficient Explanations in Databases and their Connections to Necessary Explanations and Repairs', 'authors': 'Leopoldo Bertossi, Nina Pardal', 'link': 'https://arxiv.org/abs/2511.15623', 'abstract': 'The notion of cause, as formalized by Halpern and Pearl, has been recently applied to relational databases, to characterize and compute causal explanations for query answers. In this work we consider the alternative notion of sufficient explanation. We investigate its connections with database repairs as used for dealing with inconsistent databases, and with causality-based necessary explanations. We also obtain some computational results.', 'abstract_zh': '形式化因果概念由Halpern和Pearl提出，并已应用于关系数据库，用于 characterizing 和 computing 查询答案的因果解释。本文我们考虑替代的充分解释概念，并考察其与处理不一致数据库中的数据库修复的关系，以及与基于因果性的必要解释的关系。我们还获得了一些计算结果。', 'title_zh': '数据库中的充分解释及其与必要解释和修复的关系'}
{'arxiv_id': 'arXiv:2511.15622', 'title': 'The SA-FARI Dataset: Segment Anything in Footage of Animals for Recognition and Identification', 'authors': 'Dante Francisco Wasmuht, Otto Brookes, Maximillian Schall, Pablo Palencia, Chris Beirne, Tilo Burghardt, Majid Mirmehdi, Hjalmar Kühl, Mimi Arandjelovic, Sam Pottie, Peter Bermant, Brandon Asheim, Yi Jin Toh, Adam Elzinga, Jason Holmberg, Andrew Whitworth, Eleanor Flatt, Laura Gustafson, Chaitanya Ryali, Yuan-Ting Hu, Baishan Guo, Andrew Westbury, Kate Saenko, Didac Suris', 'link': 'https://arxiv.org/abs/2511.15622', 'abstract': 'Automated video analysis is critical for wildlife conservation. A foundational task in this domain is multi-animal tracking (MAT), which underpins applications such as individual re-identification and behavior recognition. However, existing datasets are limited in scale, constrained to a few species, or lack sufficient temporal and geographical diversity - leaving no suitable benchmark for training general-purpose MAT models applicable across wild animal populations. To address this, we introduce SA-FARI, the largest open-source MAT dataset for wild animals. It comprises 11,609 camera trap videos collected over approximately 10 years (2014-2024) from 741 locations across 4 continents, spanning 99 species categories. Each video is exhaustively annotated culminating in ~46 hours of densely annotated footage containing 16,224 masklet identities and 942,702 individual bounding boxes, segmentation masks, and species labels. Alongside the task-specific annotations, we publish anonymized camera trap locations for each video. Finally, we present comprehensive benchmarks on SA-FARI using state-of-the-art vision-language models for detection and tracking, including SAM 3, evaluated with both species-specific and generic animal prompts. We also compare against vision-only methods developed specifically for wildlife analysis. SA-FARI is the first large-scale dataset to combine high species diversity, multi-region coverage, and high-quality spatio-temporal annotations, offering a new foundation for advancing generalizable multianimal tracking in the wild. The dataset is available at $\\href{this https URL}{\\text{this http URL}}$.', 'abstract_zh': '自动视频分析对于野生动物保护至关重要。该领域的一项基础任务是多动物跟踪（MAT），其支撑着个体重识别和行为识别等应用。然而，现有的数据集在规模上有限制，仅限于少数几种物种，或者缺乏足够的时空多样性，因此没有适合训练适用于广泛野生动物种群的一般多动物跟踪模型的基准数据集。为了解决这一问题，我们引入了SA-FARI，这是一个最大的开源野生动物多动物跟踪数据集。该数据集包含约10年（2014-2024年）来自四大洲741个地点的11,609个相机陷阱视频，涵盖了99个物种类别。每个视频都进行了详尽标注，总计约46小时密集标注的视频片段，包含16,224个掩码身份和942,702个个体边界框、分割掩码和物种标签。除了任务特定的标注，我们还发布了每个视频的匿名相机陷阱位置。最后，我们使用最新的视觉-语言模型在SA-FARI上进行了综合基准测试，包括SAM 3，评估了特定物种和通用动物提示下的检测和跟踪性能。我们还将与专门为野生动物分析开发的仅视觉方法进行了比较。SA-FARI是第一个结合高物种多样性、多区域覆盖和高质量时空标注的大规模数据集，为进一步发展通用多动物跟踪提供了新的基础。数据集可在<这个网址>获得。', 'title_zh': 'SA-FARI数据集：识别与鉴定动物片段中的对象'}
{'arxiv_id': 'arXiv:2511.15557', 'title': 'B+ANN: A Fast Billion-Scale Disk-based Nearest-Neighbor Index', 'authors': 'Selim Furkan Tekin, Rajesh Bordawekar', 'link': 'https://arxiv.org/abs/2511.15557', 'abstract': 'Storing and processing of embedding vectors by specialized Vector databases (VDBs) has become the linchpin in building modern AI pipelines. Most current VDBs employ variants of a graph-based ap- proximate nearest-neighbor (ANN) index algorithm, HNSW, to an- swer semantic queries over stored vectors. Inspite of its wide-spread use, the HNSW algorithm suffers from several issues: in-memory design and implementation, random memory accesses leading to degradation in cache behavior, limited acceleration scope due to fine-grained pairwise computations, and support of only semantic similarity queries. In this paper, we present a novel disk-based ANN index, B+ANN, to address these issues: it first partitions input data into blocks containing semantically similar items, then builds an B+ tree variant to store blocks both in-memory and on disks, and finally, enables hybrid edge- and block-based in-memory traversals. As demonstrated by our experimantal evaluation, the proposed B+ANN disk-based index improves both quality (Recall value), and execution performance (Queries per second/QPS) over HNSW, by improving spatial and temporal locality for semantic operations, reducing cache misses (19.23% relative gain), and decreasing the memory consumption and disk-based build time by 24x over the DiskANN algorithm. Finally, it enables dissimilarity queries, which are not supported by similarity-oriented ANN indices.', 'abstract_zh': '专用向量数据库（VDBs）存储和处理嵌入向量已成为构建现代AI管道的关键。本文提出了一种新的基于磁盘的ANN索引B+ANN，以解决现有问题：首先将输入数据划分为包含语义相似项的块，然后构建一种B+树变体，同时在内存和磁盘中存储块，并最终实现基于边和块的混合内存遍历。实验评估表明，提出的B+ANN磁盘索引在Recall值和查询每秒数量（QPS）方面均优于HNSW，通过改善空间和时间局部性、减少缓存缺失（相对增益19.23%）和磁盘构建时间减少24倍，从而提高语义操作的执行性能，并且还支持不是面向相似性查询的ANN索引所不支持的差异性查询。', 'title_zh': 'B+ANN：一种基于磁盘的快速十亿规模最近邻索引'}
{'arxiv_id': 'arXiv:2511.15552', 'title': 'Multimodal Evaluation of Russian-language Architectures', 'authors': 'Artem Chervyakov, Ulyana Isaeva, Anton Emelyanov, Artem Safin, Maria Tikhonova, Alexander Kharitonov, Yulia Lyakh, Petr Surovtsev, Denis Shevelev Vildan Saburov, Vasily Konovalov, Elisei Rykov, Ivan Sviridov, Amina Miftakhova, Ilseyar Alimova, Alexander Panchenko, Alexander Kapitanov, Alena Fenogenova', 'link': 'https://arxiv.org/abs/2511.15552', 'abstract': 'Multimodal large language models (MLLMs) are currently at the center of research attention, showing rapid progress in scale and capabilities, yet their intelligence, limitations, and risks remain insufficiently understood. To address these issues, particularly in the context of the Russian language, where no multimodal benchmarks currently exist, we introduce Mera Multi, an open multimodal evaluation framework for Russian-spoken architectures. The benchmark is instruction-based and encompasses default text, image, audio, and video modalities, comprising 18 newly constructed evaluation tasks for both general-purpose models and modality-specific architectures (image-to-text, video-to-text, and audio-to-text). Our contributions include: (i) a universal taxonomy of multimodal abilities; (ii) 18 datasets created entirely from scratch with attention to Russian cultural and linguistic specificity, unified prompts, and metrics; (iii) baseline results for both closed-source and open-source models; (iv) a methodology for preventing benchmark leakage, including watermarking and licenses for private sets. While our current focus is on Russian, the proposed benchmark provides a replicable methodology for constructing multimodal benchmarks in typologically diverse languages, particularly within the Slavic language family.', 'abstract_zh': '多模态大规模语言模型（MLLMs）目前是研究焦点，显示出在规模和能力上的迅速进展，但其智能性、限制和风险仍不够了解。为应对这些问题，特别是在目前俄语领域缺乏多模态基准的情况下，我们引入了Mera Multi，一个针对俄语架构的开放多模态评估框架。该基准基于指令，包括默认的文字、图像、音频和视频模态，共有18项新的评估任务，适用于通用模型和模态特定架构（图像到文本、视频到文本和音频到文本）。我们的贡献包括：(i) 一个多模态能力的通用分类学；(ii) 18个从零开始创建的数据集，注意俄语文化与语言的特殊性，统一的提示和评估指标；(iii) 专源和开源模型的基线结果；(iv) 防止基准泄漏的方法，包括水印和私有集的许可证。虽然我们的当前重点是俄语，但所提出的基准为在不同类型的语言中构建多模态基准提供了可复制的方法，特别是斯拉夫语族语言。', 'title_zh': '俄语架构的多模态评估'}
{'arxiv_id': 'arXiv:2511.15520', 'title': 'Theoretical Closed-loop Stability Bounds for Dynamical System Coupled with Diffusion Policies', 'authors': 'Gabriel Lauzier, Alexandre Girard, François Ferland', 'link': 'https://arxiv.org/abs/2511.15520', 'abstract': 'Diffusion Policy has shown great performance in robotic manipulation tasks under stochastic perturbations, due to its ability to model multimodal action distributions. Nonetheless, its reliance on a computationally expensive reverse-time diffusion (denoising) process, for action inference, makes it challenging to use for real-time applications where quick decision-making is mandatory. This work studies the possibility of conducting the denoising process only partially before executing an action, allowing the plant to evolve according to its dynamics in parallel to the reverse-time diffusion dynamics ongoing on the computer. In a classical diffusion policy setting, the plant dynamics are usually slow and the two dynamical processes are uncoupled. Here, we investigate theoretical bounds on the stability of closed-loop systems using diffusion policies when the plant dynamics and the denoising dynamics are coupled. The contribution of this work gives a framework for faster imitation learning and a metric that yields if a controller will be stable based on the variance of the demonstrations.', 'abstract_zh': '扩散政策在随机扰动下的机器人操纵任务中表现出色，得益于其能够建模多模态动作分布的能力。然而，其依赖于在进行动作推断时需要进行昂贵的反向时间扩散（去噪）过程，这使其难以应用于要求快速决策的实时应用中。本工作研究了在执行动作之前仅部分进行去噪过程的可能性，使得在计算机上进行反向时间扩散的同时，机器人按照其动态演化。在经典的扩散政策设置中，通常植物动力学较慢且两种动力学过程是解耦的。本工作调查了当植物动力学和去噪动力学耦合时，使用扩散政策的闭环系统稳定性理论界。本工作的贡献提供了更快的模仿学习框架以及一个基于演示数据的方差能够判断控制器是否稳定的度量标准。', 'title_zh': '耦合了扩散策略的动力系统闭环稳定性理论界值'}
{'arxiv_id': 'arXiv:2511.15462', 'title': 'Insights from the ICLR Peer Review and Rebuttal Process', 'authors': 'Amir Hossein Kargaran, Nafiseh Nikeghbal, Jing Yang, Nedjma Ousidhoum', 'link': 'https://arxiv.org/abs/2511.15462', 'abstract': 'Peer review is a cornerstone of scientific publishing, including at premier machine learning conferences such as ICLR. As submission volumes increase, understanding the nature and dynamics of the review process is crucial for improving its efficiency, effectiveness, and the quality of published papers. We present a large-scale analysis of the ICLR 2024 and 2025 peer review processes, focusing on before- and after-rebuttal scores and reviewer-author interactions. We examine review scores, author-reviewer engagement, temporal patterns in review submissions, and co-reviewer influence effects. Combining quantitative analyses with LLM-based categorization of review texts and rebuttal discussions, we identify common strengths and weaknesses for each rating group, as well as trends in rebuttal strategies that are most strongly associated with score changes. Our findings show that initial scores and the ratings of co-reviewers are the strongest predictors of score changes during the rebuttal, pointing to a degree of reviewer influence. Rebuttals play a valuable role in improving outcomes for borderline papers, where thoughtful author responses can meaningfully shift reviewer perspectives. More broadly, our study offers evidence-based insights to improve the peer review process, guiding authors on effective rebuttal strategies and helping the community design fairer and more efficient review processes. Our code and score changes data are available at this https URL.', 'abstract_zh': 'ICLR 2024和2025年同行评审过程的大规模分析：重点在于评论前后的评分及评论者-作者互动', 'title_zh': 'ICLR同行评审和反驳过程的见解'}
{'arxiv_id': 'arXiv:2511.15447', 'title': 'TSFM in-context learning for time-series classification of bearing-health status', 'authors': 'Michel Tokic, Slobodan Djukanović, Anja von Beuningen, Cheng Feng', 'link': 'https://arxiv.org/abs/2511.15447', 'abstract': 'This paper introduces a classification method using in-context learning in time-series foundation models (TSFM). We show how data, which was not part of the TSFM training data corpus, can be classified without the need of finetuning the model. Examples are represented in the form of targets (class id) and covariates (data matrix) within the prompt of the model, which enables to classify an unknown covariate data pattern alongside the forecast axis through in-context learning. We apply this method to vibration data for assessing the health state of a bearing within a servo-press motor. The method transforms frequency domain reference signals into pseudo time-series patterns, generates aligned covariate and target signals, and uses the TSFM to predict probabilities how classified data corresponds to predefined labels. Leveraging the scalability of pre-trained models this method demonstrates efficacy across varied operational conditions. This marks significant progress beyond custom narrow AI solutions towards broader, AI-driven maintenance systems.', 'abstract_zh': '本文介绍了一种使用上下文学习进行时序基础模型（TSFM）分类的方法，展示了如何在无需微调模型的情况下对未包含在TSFM训练数据集中的数据进行分类。通过将数据表示为目标（类别标识）和协变量（数据矩阵）的形式嵌入模型提示中，该方法能够在预测轴上通过上下文学习对未知协变量数据模式进行分类。该方法应用于评估伺服压力电机中轴承的健康状态，通过将频率域参考信号转换为伪时序模式，生成对齐的协变量和目标信号，并利用TSFM预测分类数据与预定义标签的匹配概率。利用预训练模型的可扩展性，该方法在各种运行条件下都显示出有效性，标志着朝着更广泛的人工智能驱动维护系统的重要进步。', 'title_zh': 'TSFM 在上下文学习中对轴承健康状态时间序列分类的应用'}
{'arxiv_id': 'arXiv:2511.15432', 'title': 'Towards Understanding Layer Contributions in Tabular In-Context Learning Models', 'authors': 'Amir Rezaei Balef, Mykhailo Koshil, Katharina Eggensperger', 'link': 'https://arxiv.org/abs/2511.15432', 'abstract': 'Despite the architectural similarities between tabular in-context learning (ICL) models and large language models (LLMs), little is known about how individual layers contribute to tabular prediction. In this paper, we investigate how the latent spaces evolve across layers in tabular ICL models, identify potential redundant layers, and compare these dynamics with those observed in LLMs. We analyze TabPFN and TabICL through the "layers as painters" perspective, finding that only subsets of layers share a common representational language, suggesting structural redundancy and offering opportunities for model compression and improved interpretability.', 'abstract_zh': '尽管表格内_context_学习（ICL）模型和大型语言模型（LLMs）在架构上存在相似之处，但关于各层如何贡献于表格预测的了解还很少。在本文中，我们探讨了表格ICL模型中潜在空间在各层之间的演变，识别潜在冗余层，并将这些动态与LLMs中观察到的动态进行比较。我们通过“层如画家”的视角分析了TabPFN和TabICL，发现仅有部分层共享一种共同的表示语言，这表明结构冗余并为模型压缩和增强可解释性提供了机会。', 'title_zh': '理解表格型上下文学习模型中各层的贡献'}
{'arxiv_id': 'arXiv:2511.15418', 'title': 'Building Robust and Scalable Multilingual ASR for Indian Languages', 'authors': 'Arjun Gangwar, Kaousheik Jayakumar, S. Umesh', 'link': 'https://arxiv.org/abs/2511.15418', 'abstract': 'This paper describes the systems developed by SPRING Lab, Indian Institute of Technology Madras, for the ASRU MADASR 2.0 challenge. The systems developed focuses on adapting ASR systems to improve in predicting the language and dialect of the utterance among 8 languages across 33 dialects. We participated in Track 1 and Track 2, which restricts the use of additional data and develop from-the-scratch multilingual systems. We presented a novel training approach using Multi-Decoder architecture with phonemic Common Label Set (CLS) as intermediate representation. It improved the performance over the baseline (in the CLS space). We also discuss various methods used to retain the gain obtained in the phonemic space while converting them back to the corresponding grapheme representations. Our systems beat the baseline in 3 languages (Track 2) in terms of WER/CER and achieved the highest language ID and dialect ID accuracy among all participating teams (Track 2).', 'abstract_zh': '本论文描述了印度理工学院马德拉斯分校SPRING实验室为ASRU MADASR 2.0挑战所开发的系统。这些系统专注于将ASR系统适应于在8种语言和33种方言中预测语种和方言的任务。我们参与了仅允许使用少量附加数据并从零开始构建多语言系统的Track 1和Track 2。我们提出了一种使用多解码器架构并以音素通用标签集(CLS)作为中间表示的新训练方法，这种方法在CLS空间中提升了基线性能。我们还讨论了各种方法以在将获得的增益从音素空间转换回相应的字母表示时保持这一增益。我们的系统在3种语言（Track 2）中以WER/CER指标击败了基线系统，并在所有参赛团队中获得了最高的语言识别和方言识别准确性（Track 2）。', 'title_zh': '构建稳健且可扩展的多语言ASR系统——以印度语言为例'}
{'arxiv_id': 'arXiv:2511.15414', 'title': 'RRT*former: Environment-Aware Sampling-Based Motion Planning using Transformer', 'authors': 'Mingyang Feng, Shaoyuan Li, Xiang Yin', 'link': 'https://arxiv.org/abs/2511.15414', 'abstract': 'We investigate the sampling-based optimal path planning problem for robotics in complex and dynamic environments. Most existing sampling-based algorithms neglect environmental information or the information from previous samples. Yet, these pieces of information are highly informative, as leveraging them can provide better heuristics when sampling the next state. In this paper, we propose a novel sampling-based planning algorithm, called \\emph{RRT*former}, which integrates the standard RRT* algorithm with a Transformer network in a novel way. Specifically, the Transformer is used to extract features from the environment and leverage information from previous samples to better guide the sampling process. Our extensive experiments demonstrate that, compared to existing sampling-based approaches such as RRT*, Neural RRT*, and their variants, our algorithm achieves considerable improvements in both the optimality of the path and sampling efficiency. The code for our implementation is available on this https URL.', 'abstract_zh': '基于采样的机器人在复杂动态环境中的最优路径规划问题研究：一种新型的结合Transformer网络的RRT*算法', 'title_zh': 'RRT*former: 基于环境aware采样并使用Transformer的运动规划'}
{'arxiv_id': 'arXiv:2511.15375', 'title': 'Parameter Importance-Driven Continual Learning for Foundation Models', 'authors': 'Lingxiang Wang, Hainan Zhang, Zhiming Zheng', 'link': 'https://arxiv.org/abs/2511.15375', 'abstract': 'Domain-specific post-training often causes catastrophic forgetting, making foundation models lose their general reasoning ability and limiting their adaptability to dynamic real-world environments. Preserving general capabilities while acquiring downstream domain knowledge is a central challenge for large language and multimodal models. Traditional continual learning methods, such as regularization, replay and architectural isolation, suffer from poor downstream performance, reliance on inaccessible historical data, or additional parameter overhead. While recent parameter-efficient tuning (PET) methods can alleviate forgetting, their effectiveness strongly depends on the choice of parameters and update strategies. In this paper, we introduce PIECE, a Parameter Importance Estimation-based Continual Enhancement method that preserves general ability while efficiently learning domain knowledge without accessing prior training data or increasing model parameters. PIECE selectively updates only 0.1% of core parameters most relevant to new tasks, guided by two importance estimators: PIECE-F based on Fisher Information, and PIECE-S based on a second-order normalization that combines gradient and curvature information. Experiments across three language models and two multimodal models show that PIECE maintains general capabilities and achieves state-of-the-art continual learning performance across diverse downstream tasks. Our results highlight a practical path to scalable, domain-adaptive foundation models without catastrophic forgetting.', 'abstract_zh': 'PIECE：基于参数重要性估计的持续增强方法', 'title_zh': '参数重要性驱动的持续学习方法'}
{'arxiv_id': 'arXiv:2511.15369', 'title': 'IPTQ-ViT: Post-Training Quantization of Non-linear Functions for Integer-only Vision Transformers', 'authors': 'Gihwan Kim, Jemin Lee, Hyungshin Kim', 'link': 'https://arxiv.org/abs/2511.15369', 'abstract': 'Previous Quantization-Aware Training (QAT) methods for vision transformers rely on expensive retraining to recover accuracy loss in non-linear layer quantization, limiting their use in resource-constrained environments. In contrast, existing Post-Training Quantization (PTQ) methods either partially quantize non-linear functions or adjust activation distributions to maintain accuracy but fail to achieve fully integer-only inference. In this paper, we introduce IPTQ-ViT, a novel PTQ framework for fully integer-only vision transformers without retraining. We present approximation functions: a polynomial-based GELU optimized for vision data and a bit-shifting-based Softmax designed to improve approximation accuracy in PTQ. In addition, we propose a unified metric integrating quantization sensitivity, perturbation, and computational cost to select the optimal approximation function per activation layer. IPTQ-ViT outperforms previous PTQ methods, achieving up to 6.44\\%p (avg. 1.78\\%p) top-1 accuracy improvement for image classification, 1.0 mAP for object detection. IPTQ-ViT outperforms partial floating-point PTQ methods under W8A8 and W4A8, and achieves accuracy and latency comparable to integer-only QAT methods. We plan to release our code this https URL.', 'abstract_zh': 'IPTQ-ViT：无需重新训练的全整数后训练量化视觉变压器', 'title_zh': 'IPTQ-ViT：仅整数视觉变换器的后训练量化非线性函数'}
{'arxiv_id': 'arXiv:2511.15342', 'title': 'Reflexive Evidence-Based Multimodal Learning for Clean Energy Transitions: Causal Insights on Cooking Fuel Access, Urbanization, and Carbon Emissions', 'authors': 'Shan Shan', 'link': 'https://arxiv.org/abs/2511.15342', 'abstract': 'Achieving Sustainable Development Goal 7 (Affordable and Clean Energy) requires not only technological innovation but also a deeper understanding of the socioeconomic factors influencing energy access and carbon emissions. While these factors are gaining attention, critical questions remain, particularly regarding how to quantify their impacts on energy systems, model their cross-domain interactions, and capture feedback dynamics in the broader context of energy transitions. To address these gaps, this study introduces ClimateAgents, an AI-based framework that combines large language models with domain-specialized agents to support hypothesis generation and scenario exploration. Leveraging 20 years of socioeconomic and emissions data from 265 economies, countries and regions, and 98 indicators drawn from the World Bank database, the framework applies a machine learning based causal inference approach to identify key determinants of carbon emissions in an evidence-based, data driven manner. The analysis highlights three primary drivers: access to clean cooking fuels in rural areas, access to clean cooking fuels in urban areas, and the percentage of population living in urban areas. These findings underscore the critical role of clean cooking technologies and urbanization patterns in shaping emission outcomes. In line with growing calls for evidence-based AI policy, ClimateAgents offers a modular and reflexive learning system that supports the generation of credible and actionable insights for policy. By integrating heterogeneous data modalities, including structured indicators, policy documents, and semantic reasoning, the framework contributes to adaptive policymaking infrastructures that can evolve with complex socio-technical challenges. This approach aims to support a shift from siloed modeling to reflexive, modular systems designed for dynamic, context-aware climate action.', 'abstract_zh': '实现可持续发展目标7（负担得起和清洁的能源）不仅需要技术创新，还需要更深入地理解影响能源获取和社会经济因素对碳排放的影响。尽管这些问题正在引起关注，但仍存在关键问题，特别是在如何量化这些因素对能源系统的影响、建模跨领域交互以及在能源转型的大背景下捕捉反馈动态方面。为填补这些空白，本研究引入了ClimateAgents，这是一种基于人工智能的框架，结合了大型语言模型和领域专业化代理，以支持假设生成和情景探索。该框架利用来自265个经济体、国家和地区以及世界银行数据库的98个指标的20年社会经济和排放数据，采用基于机器学习的因果推断方法，以证据和数据驱动的方式识别碳排放的关键决定因素。分析结果显示，主要驱动因素包括农村地区的清洁烹饪燃料访问、城市地区的清洁烹饪燃料访问以及城市人口占总人口的百分比。这些发现强调了清洁烹饪技术和城市化模式在塑造排放结果中的关键作用。为响应日益增多的证据驱动的人工智能政策呼吁，ClimateAgents提供了模块化和反思性学习系统，以生成可信和可操作的政策见解。通过整合异质数据模态，包括结构化指标、政策文件和语义推理，该框架促进了能够根据复杂的社会技术挑战而演变的适应性政策制定基础设施。这种方法旨在支持从孤立建模向适应动态、情境感知的气候行动的反思性、模块化系统的转变。', 'title_zh': '反思性证据驱动的多模态学习对于清洁能源转型：关于烹饪燃料 доступ、城市化和碳排放的因果洞察'}
{'arxiv_id': 'arXiv:2511.15339', 'title': 'STREAM-VAE: Dual-Path Routing for Slow and Fast Dynamics in Vehicle Telemetry Anomaly Detection', 'authors': 'Kadir-Kaan Özer, René Ebeling, Markus Enzweiler', 'link': 'https://arxiv.org/abs/2511.15339', 'abstract': 'Automotive telemetry data exhibits slow drifts and fast spikes, often within the same sequence, making reliable anomaly detection challenging. Standard reconstruction-based methods, including sequence variational autoencoders (VAEs), use a single latent process and therefore mix heterogeneous time scales, which can smooth out spikes or inflate variances and weaken anomaly separation.\nIn this paper, we present STREAM-VAE, a variational autoencoder for anomaly detection in automotive telemetry time-series data. Our model uses a dual-path encoder to separate slow drift and fast spike signal dynamics, and a decoder that represents transient deviations separately from the normal operating pattern. STREAM-VAE is designed for deployment, producing stable anomaly scores across operating modes for both in-vehicle monitors and backend fleet analytics.\nExperiments on an automotive telemetry dataset and the public SMD benchmark show that explicitly separating drift and spike dynamics improves robustness compared to strong forecasting, attention, graph, and VAE baselines.', 'abstract_zh': '汽车遥测数据表现出缓慢漂移和快速突变的特点，往往在同一序列中出现，这使得可靠的异常检测具有挑战性。标准的基于重构的方法，包括序列变异自编码器（VAEs），使用单一的潜在过程，因此会混合不同的时间尺度，这可能会平滑掉突变或夸大方差从而削弱异常区分。\n\n本文提出了一种名为STREAM-VAE的自编码器，用于汽车遥测时间序列数据中的异常检测。该模型采用双路径编码器以分离慢漂移和快突变的信号动态，并采用解码器将瞬态偏差与正常运行模式分开。STREAM-VAE旨在实现部署，能够跨不同运行模式生成稳健的异常评分，适用于车内监控和后端车队分析。\n\n实验结果表明，在汽车遥测数据集和公开的SMD基准上，明确分离漂移和突变动态相比强大的预测、注意力、图和VAE基线能够提高鲁棒性。', 'title_zh': 'STREAM-VAE：车辆 telemetry 异常检测中的慢动态和快动态双重路径路由'}
{'arxiv_id': 'arXiv:2511.15211', 'title': 'OEMA: Ontology-Enhanced Multi-Agent Collaboration Framework for Zero-Shot Clinical Named Entity Recognition', 'authors': 'Xinli Tao, Xin Dong, Xuezhong Zhou', 'link': 'https://arxiv.org/abs/2511.15211', 'abstract': "Clinical named entity recognition (NER) is crucial for extracting information from electronic health records (EHRs), but supervised models like CRF and BioClinicalBERT require costly annotated data. While zero-shot NER with large language models (LLMs) reduces this dependency, it struggles with example selection granularity and integrating prompts with self-improvement. To address this, we propose OEMA, a zero-shot clinical NER framework using multi-agent collaboration. OEMA's three components are: a self-annotator generating examples, a discriminator filtering them via SNOMED CT, and a predictor using entity descriptions for accurate inference. On MTSamples and VAERS datasets, OEMA achieves state-of-the-art exact-match performance. Under related-match, it matches supervised BioClinicalBERT and surpasses CRF. OEMA addresses key zero-shot NER challenges through ontology-guided reasoning and multi-agent collaboration, achieving near-supervised performance and showing promise for clinical NLP applications.", 'abstract_zh': '临床命名实体识别（NER）对于从电子健康记录（EHRs）中提取信息至关重要，但监督模型如CRF和BioClinicalBERT需要昂贵的标注数据。而利用大规模语言模型（LLMs）的零样本NER在减少这种依赖性的同时，难以在示例选择粒度上取得突破，并且难以整合提示与自我提升。为解决这一问题，我们提出了一种名为OEMA的基于多智能体协作的零样本临床NER框架。OEMA的三个组成部分包括：自标注生成器生成示例、鉴别器通过SNOMED CT进行过滤以及使用实体描述进行准确推断的预测器。在MTSamples和VAERS数据集上，OEMA实现了最先进的精确匹配性能。在相关匹配下，OEMA匹配并超过了监督的BioClinicalBERT，并超越了CRF。OEMA通过本体指导推理和多智能体协作解决了关键的零样本NER挑战，实现了接近监督性能，并展现出了在临床NLP应用中的潜力。', 'title_zh': '基于本体增强的多agent协作框架：零样本临床命名实体识别'}
{'arxiv_id': 'arXiv:2511.15190', 'title': 'Masked Auto-Regressive Variational Acceleration: Fast Inference Makes Practical Reinforcement Learning', 'authors': 'Yuxuan Gu, Weimin Bai, Yifei Wang, Weijian Luo, He Sun', 'link': 'https://arxiv.org/abs/2511.15190', 'abstract': 'Masked auto-regressive diffusion models (MAR) benefit from the expressive modeling ability of diffusion models and the flexibility of masked auto-regressive ordering. However, vanilla MAR suffers from slow inference due to its hierarchical inference mechanism: an outer AR unmasking loop and an inner diffusion denoising chain. Such decoupled structure not only harm the generation efficiency but also hinder the practical use of MAR for reinforcement learning (RL), an increasingly critical paradigm for generative model this http URL address this fundamental issue, we introduce MARVAL (Masked Auto-regressive Variational Acceleration), a distillation-based framework that compresses the diffusion chain into a single AR generation step while preserving the flexible auto-regressive unmasking order. Such a distillation with MARVAL not only yields substantial inference acceleration but, crucially, makes RL post-training with verifiable rewards practical, resulting in scalable yet human-preferred fast generative models. Our contributions are twofold: (1) a novel score-based variational objective for distilling masked auto-regressive diffusion models into a single generation step without sacrificing sample quality; and (2) an efficient RL framework for masked auto-regressive models via MARVAL-RL. On ImageNet 256*256, MARVAL-Huge achieves an FID of 2.00 with more than 30 times speedup compared with MAR-diffusion, and MARVAL-RL yields consistent improvements in CLIP and image-reward scores on ImageNet datasets with entity names. In conclusion, MARVAL demonstrates the first practical path to distillation and RL of masked auto-regressive diffusion models, enabling fast sampling and better preference alignments.', 'abstract_zh': 'Masked Auto-regressive Variational Acceleration for Scalable and Human-Preferred Generative Models', 'title_zh': '掩码自回归变分加速：快速推断使实际强化学习成为可能'}
{'arxiv_id': 'arXiv:2511.15182', 'title': 'SWR-Viz: AI-assisted Interactive Visual Analytics Framework for Ship Weather Routing', 'authors': 'Subhashis Hazarika, Leonard Lupin-Jimenez, Rohit Vuppala, Ashesh Chattopadhyay, Hon Yung Wong', 'link': 'https://arxiv.org/abs/2511.15182', 'abstract': 'Efficient and sustainable maritime transport increasingly depends on reliable forecasting and adaptive routing, yet operational adoption remains difficult due to forecast latencies and the need for human judgment in rapid decision-making under changing ocean conditions. We introduce SWR-Viz, an AI-assisted visual analytics framework that combines a physics-informed Fourier Neural Operator wave forecast model with SIMROUTE-based routing and interactive emissions analytics. The framework generates near-term forecasts directly from current conditions, supports data assimilation with sparse observations, and enables rapid exploration of what-if routing scenarios. We evaluate the forecast models and SWR-Viz framework along key shipping corridors in the Japan Coast and Gulf of Mexico, showing both improved forecast stability and realistic routing outcomes comparable to ground-truth reanalysis wave products. Expert feedback highlights the usability of SWR-Viz, its ability to isolate voyage segments with high emission reduction potential, and its value as a practical decision-support system. More broadly, this work illustrates how lightweight AI forecasting can be integrated with interactive visual analytics to support human-centered decision-making in complex geospatial and environmental domains.', 'abstract_zh': '高效的海事运输越来越依赖于可靠的预报和适应性航线规划，但由于预测延迟和需要在变化的海洋条件下进行快速决策时的人工判断需求，营运采用仍面临困难。我们介绍了SWR-Viz，一种结合基于物理信息的Fourier神经算子波预报模型和SIMROUTE航线规划与交互式排放分析的人工智能辅助视觉分析框架。该框架可以直接从当前状况生成近期预报，支持稀疏观测的数据同化，并能快速探索假设性航线方案。我们在日本沿岸和墨西哥湾的关键海运走廊进行了预报模型和SWR-Viz框架的评估，显示出预报稳定性的提升和与实况再分析波浪产品相当的现实航线结果。专家反馈强调了SWR-Viz的易用性、能够识别具有高减排潜力的航程段以及作为实用决策支持系统的价值。更为广泛地说，这项工作展示了轻量级人工智能预报如何与交互式视觉分析整合，以支持复杂地理空间和环境领域的以人为中心的决策。', 'title_zh': 'SWR-Viz: AI辅助交互式航海气象航线规划可视化分析框架'}
{'arxiv_id': 'arXiv:2511.15174', 'title': 'FaultDiffusion: Few-Shot Fault Time Series Generation with Diffusion Model', 'authors': 'Yi Xu, Zhigang Chen, Rui Wang, Yangfan Li, Fengxiao Tang, Ming Zhao, Jiaqi Liu', 'link': 'https://arxiv.org/abs/2511.15174', 'abstract': 'In industrial equipment monitoring, fault diagnosis is critical for ensuring system reliability and enabling predictive maintenance. However, the scarcity of fault data, due to the rarity of fault events and the high cost of data annotation, significantly hinders data-driven approaches. Existing time-series generation models, optimized for abundant normal data, struggle to capture fault distributions in few-shot scenarios, producing samples that lack authenticity and diversity due to the large domain gap and high intra-class variability of faults. To address this, we propose a novel few-shot fault time-series generation framework based on diffusion models. Our approach employs a positive-negative difference adapter, leveraging pre-trained normal data distributions to model the discrepancies between normal and fault domains for accurate fault synthesis. Additionally, a diversity loss is introduced to prevent mode collapse, encouraging the generation of diverse fault samples through inter-sample difference regularization. Experimental results demonstrate that our model significantly outperforms traditional methods in authenticity and diversity, achieving state-of-the-art performance on key benchmarks.', 'abstract_zh': '在工业设备监控中，故障诊断对于确保系统可靠性并实现预测性维护至关重要。然而，由于故障事件的罕见性和数据注解的高成本，故障数据的稀缺性显著阻碍了数据驱动方法的应用。现有的时间序列生成模型虽然针对丰富的正常数据进行了优化，但在少量数据场景中难以捕捉故障分布，生成的样本由于故障领域的巨大差异性和高类内变异性而缺乏真实性和多样性。为解决这一问题，我们提出了一种基于扩散模型的新型少量数据故障时间序列生成框架。该方法利用预训练的正常数据分布，通过正负差异适配器建模正常与故障领域的差异，以实现准确的故障合成。此外，引入了多样性损失以防止模式崩溃，并通过跨样本差异正则化鼓励生成多样化的故障样本。实验结果表明，我们的模型在真实性和多样性方面显著优于传统方法，并在关键基准测试上取得了最先进的性能。', 'title_zh': '故障扩散：基于扩散模型的少量样本故障时间序列生成'}
{'arxiv_id': 'arXiv:2511.15165', 'title': 'Can MLLMs Detect Phishing? A Comprehensive Security Benchmark Suite Focusing on Dynamic Threats and Multimodal Evaluation in Academic Environments', 'authors': 'Jingzhuo Zhou', 'link': 'https://arxiv.org/abs/2511.15165', 'abstract': 'The rapid proliferation of Multimodal Large Language Models (MLLMs) has introduced unprecedented security challenges, particularly in phishing detection within academic environments. Academic institutions and researchers are high-value targets, facing dynamic, multilingual, and context-dependent threats that leverage research backgrounds, academic collaborations, and personal information to craft highly tailored attacks. Existing security benchmarks largely rely on datasets that do not incorporate specific academic background information, making them inadequate for capturing the evolving attack patterns and human-centric vulnerability factors specific to academia. To address this gap, we present AdapT-Bench, a unified methodological framework and benchmark suite for systematically evaluating MLLM defense capabilities against dynamic phishing attacks in academic settings.', 'abstract_zh': '多模态大型语言模型的迅速 proliferation 在学术环境中引入了前所未有的安全挑战，特别是针对钓鱼攻击的检测。学术机构和研究人员是高价值目标，面临着利用研究背景、学术合作和个人信息量身定制的动态、多语言和情境依赖的威胁。现有的安全基准主要依赖于不包含具体学术背景信息的数据集，使其难以捕捉到学术环境中特定的人本脆弱性和不断演化的攻击模式。为弥补这一差距，我们提出了 AdapT-Bench，一个统一的方法论框架和基准套件，用于系统性评估多模态大型语言模型在学术环境中的防动态钓鱼攻击能力。', 'title_zh': 'MLLMs能在学术环境中检测钓鱼攻击吗？一个专注于动态威胁和多模态评估的综合性安全基准套件'}
{'arxiv_id': 'arXiv:2511.15151', 'title': 'DCL-SE: Dynamic Curriculum Learning for Spatiotemporal Encoding of Brain Imaging', 'authors': 'Meihua Zhou, Xinyu Tong, Jiarui Zhao, Min Cheng, Li Yang, Lei Tian, Nan Wan', 'link': 'https://arxiv.org/abs/2511.15151', 'abstract': "High-dimensional neuroimaging analyses for clinical diagnosis are often constrained by compromises in spatiotemporal fidelity and by the limited adaptability of large-scale, general-purpose models. To address these challenges, we introduce Dynamic Curriculum Learning for Spatiotemporal Encoding (DCL-SE), an end-to-end framework centered on data-driven spatiotemporal encoding (DaSE). We leverage Approximate Rank Pooling (ARP) to efficiently encode three-dimensional volumetric brain data into information-rich, two-dimensional dynamic representations, and then employ a dynamic curriculum learning strategy, guided by a Dynamic Group Mechanism (DGM), to progressively train the decoder, refining feature extraction from global anatomical structures to fine pathological details. Evaluated across six publicly available datasets, including Alzheimer's disease and brain tumor classification, cerebral artery segmentation, and brain age prediction, DCL-SE consistently outperforms existing methods in accuracy, robustness, and interpretability. These findings underscore the critical importance of compact, task-specific architectures in the era of large-scale pretrained networks.", 'abstract_zh': '基于时空编码的动态 curriculum 学习在高维神经成像临床诊断中的应用', 'title_zh': 'DCL-SE: 动态 Curriculum 学习在脑成像时空编码中的应用'}
{'arxiv_id': 'arXiv:2511.15159', 'title': 'Generating Natural-Language Surgical Feedback: From Structured Representation to Domain-Grounded Evaluation', 'authors': 'Firdavs Nasriddinov, Rafal Kocielnik, Anima Anandkumar, Andrew J. Hung', 'link': 'https://arxiv.org/abs/2511.15159', 'abstract': 'High-quality intraoperative feedback from a surgical trainer is pivotal for improving trainee performance and long-term skill acquisition. Automating natural, trainer-style feedback promises timely, accessible, and consistent guidance at scale but requires models that understand clinically relevant representations. We present a structure-aware pipeline that learns a surgical action ontology from real trainer-to-trainee transcripts (33 surgeries) and uses it to condition feedback generation. We contribute by (1) mining Instrument-Action-Target (IAT) triplets from real-world feedback text and clustering surface forms into normalized categories, (2) fine-tuning a video-to-IAT model that leverages the surgical procedure and task contexts as well as fine-grained temporal instrument motion, and (3) demonstrating how to effectively use IAT triplet representations to guide GPT-4o in generating clinically grounded, trainer-style feedback. We show that, on Task 1: Video-to-IAT recognition, our context injection and temporal tracking deliver consistent AUC gains (Instrument: 0.67 to 0.74; Action: 0.60 to 0.63; Tissue: 0.74 to 0.79). For Task 2: feedback text generation (rated on a 1-5 fidelity rubric where 1 = opposite/unsafe, 3 = admissible, and 5 = perfect match to a human trainer), GPT-4o from video alone scores 2.17, while IAT conditioning reaches 2.44 (+12.4%), doubling the share of admissible generations with score >= 3 from 21% to 42%. Traditional text-similarity metrics also improve: word error rate decreases by 15-31% and ROUGE (phrase/substring overlap) increases by 9-64%. Grounding generation in explicit IAT structure improves fidelity and yields clinician-verifiable rationales, supporting auditable use in surgical training.', 'abstract_zh': '高质量的手术培训师 intraoperative 反馈对于提高学生成绩和长期技能获取至关重要。自动化的自然式培训师反馈有望提供及时、便捷且一致的指导，但需要理解临床相关表示的模型。我们提出了一种结构感知的管道，从中学习手术动作本体，并利用其来条件化反馈生成。我们通过以下贡献：(1) 从真实世界反馈文本中挖掘器械-动作-目标（IAT）三元组，并将表面形式聚类为标准化类别；(2) 对利用手术程序和任务上下文以及精细时间标度器械运动的视频到IAT模型进行微调；(3) 展示如何有效利用IAT三元组表示来指导GPT-4o生成基于临床的培训师式反馈。结果显示，在任务1：视频到IAT识别中，我们的上下文注入和时间跟踪带来了一致的AUC提升（器械：0.67到0.74；动作：0.60到0.63；组织：0.74到0.79）。在任务2：反馈文本生成（根据1-5保真度量表评分，1=完全相反/不安全，3=可接受，5=完全匹配人类培训师），仅从视频生成的GPT-4o得分为2.17，而IAT条件化得分为2.44 (+12.4%)，生成得分>=3的比例从21%提高到42%。传统的文本相似性指标也有所提高：词错误率降低15-31%，ROUGE（短语/子字符串重叠）增加9-64%。基于明确的IAT结构进行生成提高了保真度并提供了可临床验证的理由，支持在手术培训中的可审计使用。', 'title_zh': '生成自然语言手术反馈：从结构化表示到领域导向评估'}
{'arxiv_id': 'arXiv:2511.15139', 'title': 'CASPER: Cross-modal Alignment of Spatial and single-cell Profiles for Expression Recovery', 'authors': 'Amit Kumar, Maninder Kaur, Raghvendra Mall, Sukrit Gupta', 'link': 'https://arxiv.org/abs/2511.15139', 'abstract': 'Spatial Transcriptomics enables mapping of gene expression within its native tissue context, but current platforms measure only a limited set of genes due to experimental constraints and excessive costs. To overcome this, computational models integrate Single-Cell RNA Sequencing data with Spatial Transcriptomics to predict unmeasured genes. We propose CASPER, a cross-attention based framework that predicts unmeasured gene expression in Spatial Transcriptomics by leveraging centroid-level representations from Single-Cell RNA Sequencing. We performed rigorous testing over four state-of-the-art Spatial Transcriptomics/Single-Cell RNA Sequencing dataset pairs across four existing baseline models. CASPER shows significant improvement in nine out of the twelve metrics for our experiments. This work paves the way for further work in Spatial Transcriptomics to Single-Cell RNA Sequencing modality translation. The code for CASPER is available at this https URL.', 'abstract_zh': '空间转录组学能够在其原位组织环境中映射基因表达，但由于实验限制和高昂的成本，当前的平台只能测量有限的基因。为克服这一问题，计算模型结合单细胞RNA测序数据与空间转录组学以预测未测量的基因表达。我们提出了一种基于跨注意力机制的框架CASPER，通过利用单细胞RNA测序的中心点级表示来预测空间转录组学中的未测量基因表达。我们在四个现有的基线模型上对四个最先进的空间转录组学/单细胞RNA测序数据集对进行了严格的测试。实验结果表明，CASPER在十二个评价指标中有九个指标上表现显著提升。本项工作为进一步探索空间转录组学到单细胞RNA测序模态转化铺平了道路。CASPER的代码可在以下链接获取。', 'title_zh': 'CASPER：空间与单细胞谱型的跨模态对齐以实现表达恢复'}
{'arxiv_id': 'arXiv:2511.15122', 'title': 'Multi-Aspect Cross-modal Quantization for Generative Recommendation', 'authors': 'Fuwei Zhang, Xiaoyu Liu, Dongbo Xi, Jishen Yin, Huan Chen, Peng Yan, Fuzhen Zhuang, Zhao Zhang', 'link': 'https://arxiv.org/abs/2511.15122', 'abstract': "Generative Recommendation (GR) has emerged as a new paradigm in recommender systems. This approach relies on quantized representations to discretize item features, modeling users' historical interactions as sequences of discrete tokens. Based on these tokenized sequences, GR predicts the next item by employing next-token prediction methods. The challenges of GR lie in constructing high-quality semantic identifiers (IDs) that are hierarchically organized, minimally conflicting, and conducive to effective generative model training. However, current approaches remain limited in their ability to harness multimodal information and to capture the deep and intricate interactions among diverse modalities, both of which are essential for learning high-quality semantic IDs and for effectively training GR models. To address this, we propose Multi-Aspect Cross-modal quantization for generative Recommendation (MACRec), which introduces multimodal information and incorporates it into both semantic ID learning and generative model training from different aspects. Specifically, we first introduce cross-modal quantization during the ID learning process, which effectively reduces conflict rates and thus improves codebook usability through the complementary integration of multimodal information. In addition, to further enhance the generative ability of our GR model, we incorporate multi-aspect cross-modal alignments, including the implicit and explicit alignments. Finally, we conduct extensive experiments on three well-known recommendation datasets to demonstrate the effectiveness of our proposed method.", 'abstract_zh': '多方面跨模态量化生成推荐（MACRec）', 'title_zh': '多方面跨模态量化生成推荐'}
{'arxiv_id': 'arXiv:2511.15120', 'title': 'Neural Networks Learn Generic Multi-Index Models Near Information-Theoretic Limit', 'authors': 'Bohan Zhang, Zihao Wang, Hengyu Fu, Jason D. Lee', 'link': 'https://arxiv.org/abs/2511.15120', 'abstract': 'In deep learning, a central issue is to understand how neural networks efficiently learn high-dimensional features. To this end, we explore the gradient descent learning of a general Gaussian Multi-index model $f(\\boldsymbol{x})=g(\\boldsymbol{U}\\boldsymbol{x})$ with hidden subspace $\\boldsymbol{U}\\in \\mathbb{R}^{r\\times d}$, which is the canonical setup to study representation learning. We prove that under generic non-degenerate assumptions on the link function, a standard two-layer neural network trained via layer-wise gradient descent can agnostically learn the target with $o_d(1)$ test error using $\\widetilde{\\mathcal{O}}(d)$ samples and $\\widetilde{\\mathcal{O}}(d^2)$ time. The sample and time complexity both align with the information-theoretic limit up to leading order and are therefore optimal. During the first stage of gradient descent learning, the proof proceeds via showing that the inner weights can perform a power-iteration process. This process implicitly mimics a spectral start for the whole span of the hidden subspace and eventually eliminates finite-sample noise and recovers this span. It surprisingly indicates that optimal results can only be achieved if the first layer is trained for more than $\\mathcal{O}(1)$ steps. This work demonstrates the ability of neural networks to effectively learn hierarchical functions with respect to both sample and time efficiency.', 'abstract_zh': '深度学习中一个核心问题是理解神经网络如何高效地学习高维特征。为此，我们探索了一般高斯多索引模型 \\(f(\\boldsymbol{x})=g(\\boldsymbol{U}\\boldsymbol{x})\\) 的逐层梯度下降学习，其中隐藏子空间 \\(\\boldsymbol{U}\\in \\mathbb{R}^{r\\times d}\\)，这是研究表示学习的经典设置。我们证明，在链函数满足通用非退化假设的情况下，通过逐层梯度下降训练的标准两层神经网络可以在 \\(\\widetilde{\\mathcal{O}}(d)\\) 样本和 \\(\\widetilde{\\mathcal{O}}(d^2)\\) 时间内以 \\(o_d(1)\\) 的测试误差学习目标，样本和时间复杂度都与信息论极限在主要项上一致，因此是最优的。在梯度下降学习的第一阶段，证明通过表明内部权重可以执行幂迭代过程来进行。这一过程隐式地模仿了整个隐藏子空间范围的谱初始化，并最终消除有限样本噪声并恢复该范围。这意外地表明，只有当第一层被训练超过 \\(\\mathcal{O}(1)\\) 步时，才能获得最优结果。这项工作展示了神经网络在样本和时间效率方面有效地学习分层函数的能力。', 'title_zh': '神经网络在接近信息论极限的情况下学习通用多索引模型'}
{'arxiv_id': 'arXiv:2511.15112', 'title': 'Semiconductor Industry Trend Prediction with Event Intervention Based on LSTM Model in Sentiment-Enhanced Time Series Data', 'authors': 'Wei-hsiang Yen, Lyn Chao-ling Chen', 'link': 'https://arxiv.org/abs/2511.15112', 'abstract': 'The innovation of the study is that the deep learning method and sentiment analysis are integrated in traditional business model analysis and forecasting, and the research subject is TSMC for industry trend prediction of semiconductor industry in Taiwan. For the rapid market changes and development of wafer technologies of semiconductor industry, traditional data analysis methods not perform well in the high variety and time series data. Textual data and time series data were collected from seasonal reports of TSMC including financial information. Textual data through sentiment analysis by considering the event intervention both from internal events of the company and the external global events. Using the sentiment-enhanced time series data, the LSTM model was adopted for predicting industry trend of TSMC. The prediction results reveal significant development of wafer technology of TSMC and the potential threatens in the global market, and matches the product released news of TSMC and the international news. The contribution of the work performed accurately in industry trend prediction of the semiconductor industry by considering both the internal and external event intervention, and the prediction results provide valuable information of semiconductor industry both in research and business aspects.', 'abstract_zh': '传统商业模式分析与预测中将深度学习方法和情感分析 integrated 的创新研究：以 TSMC 的半导体行业趋势预测为例', 'title_zh': '基于事件介入的情感增强时间序列数据LSTM模型的半导体行业趋势预测'}
{'arxiv_id': 'arXiv:2511.15107', 'title': 'Effective Code Membership Inference for Code Completion Models via Adversarial Prompts', 'authors': 'Yuan Jiang, Zehao Li, Shan Huang, Christoph Treude, Xiaohong Su, Tiantian Wang', 'link': 'https://arxiv.org/abs/2511.15107', 'abstract': "Membership inference attacks (MIAs) on code completion models offer an effective way to assess privacy risks by inferring whether a given code snippet was part of the training data. Existing black- and gray-box MIAs rely on expensive surrogate models or manually crafted heuristic rules, which limit their ability to capture the nuanced memorization patterns exhibited by over-parameterized code language models. To address these challenges, we propose AdvPrompt-MIA, a method specifically designed for code completion models, combining code-specific adversarial perturbations with deep learning. The core novelty of our method lies in designing a series of adversarial prompts that induce variations in the victim code model's output. By comparing these outputs with the ground-truth completion, we construct feature vectors to train a classifier that automatically distinguishes member from non-member samples. This design allows our method to capture richer memorization patterns and accurately infer training set membership. We conduct comprehensive evaluations on widely adopted models, such as Code Llama 7B, over the APPS and HumanEval benchmarks. The results show that our approach consistently outperforms state-of-the-art baselines, with AUC gains of up to 102%. In addition, our method exhibits strong transferability across different models and datasets, underscoring its practical utility and generalizability.", 'abstract_zh': '代码补全模型的对抗提示会员推断攻击（AdvPrompt-MIA）：捕获丰富的记忆模式以准确推断训练集成员资格', 'title_zh': '针对代码补全模型的有效代码成员推断通过对抗提示'}
{'arxiv_id': 'arXiv:2511.15097', 'title': 'MAIF: Enforcing AI Trust and Provenance with an Artifact-Centric Agentic Paradigm', 'authors': 'Vineeth Sai Narajala, Manish Bhatt, Idan Habler, Ronald F. Del Rosario', 'link': 'https://arxiv.org/abs/2511.15097', 'abstract': 'The AI trustworthiness crisis threatens to derail the artificial intelligence revolution, with regulatory barriers, security vulnerabilities, and accountability gaps preventing deployment in critical domains. Current AI systems operate on opaque data structures that lack the audit trails, provenance tracking, or explainability required by emerging regulations like the EU AI Act. We propose an artifact-centric AI agent paradigm where behavior is driven by persistent, verifiable data artifacts rather than ephemeral tasks, solving the trustworthiness problem at the data architecture level. Central to this approach is the Multimodal Artifact File Format (MAIF), an AI-native container embedding semantic representations, cryptographic provenance, and granular access controls. MAIF transforms data from passive storage into active trust enforcement, making every AI operation inherently auditable. Our production-ready implementation demonstrates ultra-high-speed streaming (2,720.7 MB/s), optimized video processing (1,342 MB/s), and enterprise-grade security. Novel algorithms for cross-modal attention, semantic compression, and cryptographic binding achieve up to 225 compression while maintaining semantic fidelity. Advanced security features include stream-level access control, real-time tamper detection, and behavioral anomaly analysis with minimal overhead. This approach directly addresses the regulatory, security, and accountability challenges preventing AI deployment in sensitive domains, offering a viable path toward trustworthy AI systems at scale.', 'abstract_zh': '人工智能可信性危机威胁着人工智能革命，监管障碍、安全漏洞和问责空白阻碍了其在关键领域的部署。当前的人工智能系统依赖于不透明的数据结构，缺乏新兴法规（如欧盟人工智能法案）所需的审计追踪、起源追踪或可解释性。我们提出了一种以艺术品为中心的人工智能代理范式，行为由持久且可验证的数据艺术品驱动，而非短暂的任务，从而在数据架构层面解决了可信性问题。这一方法的核心是多模态艺术品文件格式（MAIF），这是一种嵌入了语义表示、加密溯源和细粒度访问控制的人工智能原生容器。MAIF将数据从被动存储转变为积极的可信执行，使每一个人工智能操作本已具备可审计性。我们的生产级实现展示了超高速流式传输（2,720.7 MB/s）、优化的视频处理（1,342 MB/s）以及企业级安全性能。新颖的跨模态注意力、语义压缩和加密绑定算法实现了高达225的压缩比率，同时保持语义的准确性。高级安全特性包括流级访问控制、实时篡改检测和行为异常分析，这意味着极低的开销。这种方法直接解决了阻碍人工智能在敏感领域部署的监管、安全和问责挑战，提供了一条通往大规模可信人工智能系统的发展路径。', 'title_zh': 'MAIF: 以剂型中心代理范式确保人工智能的信任与溯源'}
{'arxiv_id': 'arXiv:2511.15076', 'title': 'GPU-Initiated Networking for NCCL', 'authors': 'Khaled Hamidouche, John Bachan, Pak Markthub, Peter-Jan Gootzen, Elena Agostini, Sylvain Jeaugey, Aamir Shafi, Georgios Theodorakis, Manjunath Gorentla Venkata', 'link': 'https://arxiv.org/abs/2511.15076', 'abstract': "Modern AI workloads, especially Mixture-of-Experts (MoE) architectures, increasingly demand low-latency, fine-grained GPU-to-GPU communication with device-side control. Traditional GPU communication follows a host-initiated model, where the CPU orchestrates all communication operations - a characteristic of the CUDA runtime. Although robust for collective operations, applications requiring tight integration of computation and communication can benefit from device-initiated communication that eliminates CPU coordination overhead.\nNCCL 2.28 introduces the Device API with three operation modes: Load/Store Accessible (LSA) for NVLink/PCIe, Multimem for NVLink SHARP, and GPU-Initiated Networking (GIN) for network RDMA. This paper presents the GIN architecture, design, semantics, and highlights its impact on MoE communication. GIN builds on a three-layer architecture: i) NCCL Core host-side APIs for device communicator setup and collective memory window registration; ii) Device-side APIs for remote memory operations callable from CUDA kernels; and iii) A network plugin architecture with dual semantics (GPUDirect Async Kernel-Initiated and Proxy) for broad hardware support. The GPUDirect Async Kernel-Initiated backend leverages DOCA GPUNetIO for direct GPU-to-NIC communication, while the Proxy backend provides equivalent functionality via lock-free GPU-to-CPU queues over standard RDMA networks. We demonstrate GIN's practicality through integration with DeepEP, an MoE communication library. Comprehensive benchmarking shows that GIN provides device-initiated communication within NCCL's unified runtime, combining low-latency operations with NCCL's collective algorithms and production infrastructure.", 'abstract_zh': '现代AI工作负载，尤其是Mixture-of-Experts (MoE)架构，日益需要低延迟、细粒度的GPU-to-GPU通信与设备侧控制。NCCL 2.28引入了设备API，包含三种操作模式： NVLink/PCIe的Load/Store Accessible (LSA)、NVLink SHARP的Multimem以及网络RDMA的GPU-Initiated Networking (GIN)。本文介绍了GIN架构、设计、语义及其对MoE通信的影响。GIN基于三层架构构建：i) NCCL核心主机侧API，用于设备通信器设置和集体内存窗口注册；ii) 设备侧API，可在CUDA内核中调用的远程内存操作；iii) 具有双重语义（GPUDirect Async Kernel-Initiated和Proxy）的网络插件架构，以广泛支持硬件。GPUDirect Async Kernel-Initiated后端利用DOCA GPUNetIO实现直接GPU-to-NIC通信，而Proxy后端通过无锁的GPU-to-CPU队列提供等效功能，运行于标准RDMA网络上。通过与DeepEP MoE通信库的集成，我们展示了GIN的实用性。全面的基准测试表明，GIN能够在NCCL统一运行时环境中提供设备发起的通信，结合了低延迟操作与NCCL的集体算法和生产基础设施。', 'title_zh': 'GPU-发起的网络通信 for NCCL'}
{'arxiv_id': 'arXiv:2511.15067', 'title': 'Deep Pathomic Learning Defines Prognostic Subtypes and Molecular Drivers in Colorectal Cancer', 'authors': 'Zisong Wang, Xuanyu Wang, Hang Chen, Haizhou Wang, Yuxin Chen, Yihang Xu, Yunhe Yuan, Lihuan Luo, Xitong Ling, Xiaoping Liu', 'link': 'https://arxiv.org/abs/2511.15067', 'abstract': 'Precise prognostic stratification of colorectal cancer (CRC) remains a major clinical challenge due to its high heterogeneity. The conventional TNM staging system is inadequate for personalized medicine. We aimed to develop and validate a novel multiple instance learning model TDAM-CRC using histopathological whole-slide images for accurate prognostic prediction and to uncover its underlying molecular mechanisms. We trained the model on the TCGA discovery cohort (n=581), validated it in an independent external cohort (n=1031), and further we integrated multi-omics data to improve model interpretability and identify novel prognostic biomarkers. The results demonstrated that the TDAM-CRC achieved robust risk stratification in both cohorts. Its predictive performance significantly outperformed the conventional clinical staging system and multiple state-of-the-art models. The TDAM-CRC risk score was confirmed as an independent prognostic factor in multivariable analysis. Multi-omics analysis revealed that the high-risk subtype is closely associated with metabolic reprogramming and an immunosuppressive tumor microenvironment. Through interaction network analysis, we identified and validated Mitochondrial Ribosomal Protein L37 (MRPL37) as a key hub gene linking deep pathomic features to clinical prognosis. We found that high expression of MRPL37, driven by promoter hypomethylation, serves as an independent biomarker of favorable prognosis. Finally, we constructed a nomogram incorporating the TDAM-CRC risk score and clinical factors to provide a precise and interpretable clinical decision-making tool for CRC patients. Our AI-driven pathological model TDAM-CRC provides a robust tool for improved CRC risk stratification, reveals new molecular targets, and facilitates personalized clinical decision-making.', 'abstract_zh': '精确分层预测结直肠癌预后的方法学挑战源于其高异质性。传统TNM分期系统对于个性化医疗而言是不够的。我们旨在开发并验证一种新型的实例级学习模型TDAM-CRC，利用组织病理学Whole-slide图像进行准确的预后预测，并揭示其潜在的分子机制。该模型在TCGA发现队列（n=581）上进行了训练，在独立的外部队列（n=1031）上进行了验证，并通过整合多组学数据提高了模型的可解释性并识别了新的预后生物标志物。结果表明，TDAM-CRC在两个队列中均实现了稳健的风险分层。其预测性能显著优于传统的临床分期系统和多个先进的模型。TDAM-CRC风险评分在多变量分析中被证实为独立的预后因子。多组学分析表明，高风险亚型与代谢重编程和免疫抑制的肿瘤微环境密切相关。通过交互网络分析，我们确定并验证了线粒体核糖体蛋白L37（MRPL37）作为连接深入病理特征与临床预后的关键枢纽基因。我们发现，由启动子去甲基化驱动的MRPL37高表达作为良好预后的独立生物标志物。最后，我们构建了一个包含TDAM-CRC风险评分和临床因素的 nomogram，为结直肠癌患者提供了精确且可解释的临床决策工具。我们基于AI的病理学模型TDAM-CRC提供了一种改进的结直肠癌风险分层的稳健工具，揭示了新的分子靶点，并促进了个性化临床决策。', 'title_zh': '深度病理学习定义结直肠癌的预后亚型及分子驱动因子'}
{'arxiv_id': 'arXiv:2511.15046', 'title': 'UniHOI: Unified Human-Object Interaction Understanding via Unified Token Space', 'authors': 'Panqi Yang, Haodong Jing, Nanning Zheng, Yongqiang Ma', 'link': 'https://arxiv.org/abs/2511.15046', 'abstract': 'In the field of human-object interaction (HOI), detection and generation are two dual tasks that have traditionally been addressed separately, hindering the development of comprehensive interaction understanding. To address this, we propose UniHOI, which jointly models HOI detection and generation via a unified token space, thereby effectively promoting knowledge sharing and enhancing generalization. Specifically, we introduce a symmetric interaction-aware attention module and a unified semi-supervised learning paradigm, enabling effective bidirectional mapping between images and interaction semantics even under limited annotations. Extensive experiments demonstrate that UniHOI achieves state-of-the-art performance in both HOI detection and generation. Specifically, UniHOI improves accuracy by 4.9% on long-tailed HOI detection and boosts interaction metrics by 42.0% on open-vocabulary generation tasks.', 'abstract_zh': '在人类物体交互（HOI）领域，检测与生成是两个传统的双任务，以往是分开处理的，阻碍了全面交互理解的发展。为解决这一问题，我们提出UniHOI，通过统一的token空间联合建模HOI检测与生成，从而有效促进知识共享并增强泛化能力。具体而言，我们引入了对称交互感知注意力模块和统一的半监督学习范式，即使在有限标注的情况下，也能实现图像与交互语义的有效双向映射。大量实验表明，UniHOI在HOI检测和生成中均实现了最先进的性能。具体而言，UniHOI在长尾HOI检测中的准确率提高了4.9%，在开放词汇生成任务中的交互指标提高了42.0%。', 'title_zh': 'UniHOI: 统一人类-物体交互理解通过统一 token 空间'}
{'arxiv_id': 'arXiv:2511.15038', 'title': 'Aligning Generative Music AI with Human Preferences: Methods and Challenges', 'authors': 'Dorien Herremans, Abhinaba Roy', 'link': 'https://arxiv.org/abs/2511.15038', 'abstract': "Recent advances in generative AI for music have achieved remarkable fidelity and stylistic diversity, yet these systems often fail to align with nuanced human preferences due to the specific loss functions they use. This paper advocates for the systematic application of preference alignment techniques to music generation, addressing the fundamental gap between computational optimization and human musical appreciation. Drawing on recent breakthroughs including MusicRL's large-scale preference learning, multi-preference alignment frameworks like diffusion-based preference optimization in DiffRhythm+, and inference-time optimization techniques like Text2midi-InferAlign, we discuss how these techniques can address music's unique challenges: temporal coherence, harmonic consistency, and subjective quality assessment. We identify key research challenges including scalability to long-form compositions, reliability amongst others in preference modelling. Looking forward, we envision preference-aligned music generation enabling transformative applications in interactive composition tools and personalized music services. This work calls for sustained interdisciplinary research combining advances in machine learning, music-theory to create music AI systems that truly serve human creative and experiential needs.", 'abstract_zh': 'Recent Advances in Preference-Aligned Generative AI for Music', 'title_zh': '面向人类偏好的生成音乐AI：方法与挑战'}
{'arxiv_id': 'arXiv:2511.14981', 'title': 'Logit-Based Losses Limit the Effectiveness of Feature Knowledge Distillation', 'authors': 'Nicholas Cooper, Lijun Chen, Sailesh Dwivedy, Danna Gurari', 'link': 'https://arxiv.org/abs/2511.14981', 'abstract': "Knowledge distillation (KD) methods can transfer knowledge of a parameter-heavy teacher model to a light-weight student model. The status quo for feature KD methods is to utilize loss functions based on logits (i.e., pre-softmax class scores) and intermediate layer features (i.e., latent representations). Unlike previous approaches, we propose a feature KD framework for training the student's backbone using feature-based losses exclusively (i.e., without logit-based losses such as cross entropy). Leveraging recent discoveries about the geometry of latent representations, we introduce a knowledge quality metric for identifying which teacher layers provide the most effective knowledge for distillation. Experiments on three image classification datasets with four diverse student-teacher pairs, spanning convolutional neural networks and vision transformers, demonstrate our KD method achieves state-of-the-art performance, delivering top-1 accuracy boosts of up to 15% over standard approaches. We publically share our code to facilitate future work at this https URL.", 'abstract_zh': '基于特征的知识精炼方法可以将参数密集型教师模型的知识转移到轻量级学生模型。特征精炼方法的现状是利用基于 logits（即预softmax类得分）和中间层特征（即潜在表示）的损失函数。与以往方法不同，我们提出了一种仅使用基于特征的损失函数（即不使用交叉熵等基于 logits 的损失函数）来训练学生模型主干的特征精炼框架。借助近期关于潜在表示几何结构的研究发现，我们引入了一种知识质量度量标准，以识别哪些教师层提供最有效的知识用于精炼。在三个图像分类数据集上的实验，使用四对不同的学生-教师组合（涵盖卷积神经网络和视觉变压器），证明了我们的知识精炼方法达到了最先进的性能，相比标准方法在 top-1 准确率上实现了高达 15% 的提升。我们已公开分享代码以促进未来研究（请访问此链接）。', 'title_zh': '基于Logit的损失函数限制了特征知识蒸馏的有效性'}
{'arxiv_id': 'arXiv:2511.14972', 'title': 'Harmful Traits of AI Companions', 'authors': 'W. Bradley Knox, Katie Bradford, Samanta Varela Castro, Desmond C. Ong, Sean Williams, Jacob Romanow, Carly Nations, Peter Stone, Samuel Baker', 'link': 'https://arxiv.org/abs/2511.14972', 'abstract': 'Amid the growing prevalence of human -- AI interaction, large language models and other AI-based entities increasingly provide forms of companionship to human users. Such AI companionship -- i.e., bonded relationships between humans and AI systems that resemble the relationships people have with family members, friends, and romantic partners -- might substantially benefit humans. Yet such relationships can also do profound harm. We propose a framework for analyzing potential negative impacts of AI companionship by identifying specific harmful traits of AI companions and speculatively mapping causal pathways back from these traits to possible causes and forward to potential harmful effects. We provide detailed, structured analysis of four potentially harmful traits -- the absence of natural endpoints for relationships, vulnerability to product sunsetting, high attachment anxiety, and propensity to engender protectiveness -- and briefly discuss fourteen others. For each trait, we propose hypotheses connecting causes -- such as misaligned optimization objectives and the digital nature of AI companions -- to fundamental harms -- including reduced autonomy, diminished quality of human relationships, and deception. Each hypothesized causal connection identifies a target for potential empirical evaluation. Our analysis examines harms at three levels: to human partners directly, to their relationships with other humans, and to society broadly. We examine how existing law struggles to address these emerging harms, discuss potential benefits of AI companions, and conclude with design recommendations for mitigating risks. This analysis offers immediate suggestions for reducing risks while laying a foundation for deeper investigation of this critical but understudied topic.', 'abstract_zh': '在人类与人工智能交互日益普遍的情况下，大型语言模型和其他基于人工智能的实体 increasingly 为人类用户提供了一种陪伴形式。这种人工智能陪伴——即人类与人工智能系统之间形成的人际关系，类似于人们与家人、朋友和伴侣的关系——可能显著惠及人类。然而，这些关系也可能造成深远的危害。我们提出了一种框架，用于分析人工智能陪伴潜在负面影响，通过识别特定的人工智能陪伴的有害特质，并推测性地从这些特质回溯至可能的原因，进而向前推导至潜在的危害影响。我们详细分析了四种潜在有害特质——缺乏人际关系的自然终点、易受产品下架的影响、高水平的依附焦虑，以及引发保护倾向的倾向，并简要讨论了十四种其他特质。对于每种特质，我们提出了假设，将诸如目标偏差和人工智能陪伴的数字本质等成因与基本危害——包括减少自主性、降低人类关系质量以及欺骗——联系起来。每个假设的因果联系指出了潜在的实证评估目标。我们的分析在三个层面审视了危害：对直接的人类伴侣、对他们与他人的关系以及对社会产生广泛影响。我们探讨了现有法律在应对这些新兴危害方面的困境，讨论了人工智能陪伴的潜在益处，并提出了减轻风险的设计建议。这一分析提供了减少风险的即时建议，并为深入研究这一关键但研究不足的话题奠定了基础。', 'title_zh': 'AI伴侣的有害特质'}
{'arxiv_id': 'arXiv:2511.14977', 'title': 'SVBRD-LLM: Self-Verifying Behavioral Rule Discovery for Autonomous Vehicle Identification', 'authors': 'Xiangyu Li, Zhaomiao Guo', 'link': 'https://arxiv.org/abs/2511.14977', 'abstract': 'As more autonomous vehicles operate on public roads, understanding real-world behavior of autonomous vehicles is critical to analyzing traffic safety, making policies, and public acceptance. This paper proposes SVBRD-LLM, a framework that automatically discovers, verifies, and applies interpretable behavioral rules from real traffic videos through zero-shot prompt engineering. The framework extracts vehicle trajectories using YOLOv8 and ByteTrack, computes kinematic features, and employs GPT-5 zero-shot prompting to compare autonomous and human-driven vehicles, generating 35 structured behavioral rule hypotheses. These rules are tested on a validation set, iteratively refined based on failure cases to filter spurious correlations, and compiled into a high-confidence rule library. The framework is evaluated on an independent test set for speed change prediction, lane change prediction, and autonomous vehicle identification tasks. Experiments on over 1500 hours of real traffic videos show that the framework achieves 90.0% accuracy and 93.3% F1-score in autonomous vehicle identification. The discovered rules clearly reveal distinctive characteristics of autonomous vehicles in speed control smoothness, lane change conservativeness, and acceleration stability, with each rule accompanied by semantic description, applicable context, and validation confidence.', 'abstract_zh': '随着更多的自动驾驶车辆在公共道路上行驶，了解自动驾驶车辆的实际行为对于分析交通安全、制定政策和公众接受度至关重要。本文提出了一种SVBRD-LLM框架，该框架通过零样本提示工程自动发现、验证和应用来自真实交通视频的可解释行为规则。该框架使用YOLOv8和ByteTrack提取车辆轨迹，计算运动特征，并利用GPT-5零样本提示将自动驾驶车辆与人类驾驶车辆进行比较，生成35个结构化的行为规则假设。这些规则在验证集上进行测试，并根据失败案例迭代 refinement 进行筛选，最终编译成高置信度规则库。该框架在独立测试集上对速度变化预测、车道变更预测和自动驾驶车辆识别任务进行了评估。在超过1500小时的真实交通视频实验中，框架在自动驾驶车辆识别任务上的准确率达到90.0%，F1分数达到93.3%。发现的规则清晰揭示了自动驾驶车辆在速度控制平滑性、车道变更保守性和加速度稳定性方面的独特特征，每条规则均附有语义描述、适用场景和验证置信度。', 'title_zh': 'SVBRD-LLM: 自验证行为规则发现的自主车辆识别'}
{'arxiv_id': 'arXiv:2511.14964', 'title': 'How Should the Law Treat Future AI Systems? Fictional Legal Personhood versus Legal Identity', 'authors': 'Heather J. Alexander, Jonathan A. Simon, Frédéric Pinard', 'link': 'https://arxiv.org/abs/2511.14964', 'abstract': "The law draws a sharp distinction between objects and persons, and between two kinds of persons, the ''fictional'' kind (i.e. corporations), and the ''non-fictional'' kind (individual or ''natural'' persons). This paper will assess whether we maximize overall long-term legal coherence by (A) maintaining an object classification for all future AI systems, (B) creating fictional legal persons associated with suitably advanced, individuated AI systems (giving these fictional legal persons derogable rights and duties associated with certified groups of existing persons, potentially including free speech, contract rights, and standing to sue ''on behalf of'' the AI system), or (C) recognizing non-fictional legal personhood through legal identity for suitably advanced, individuated AI systems (recognizing them as entities meriting legal standing with non-derogable rights which for the human case include life, due process, habeas corpus, freedom from slavery, and freedom of conscience). We will clarify the meaning and implications of each option along the way, considering liability, copyright, family law, fundamental rights, civil rights, citizenship, and AI safety regulation. We will tentatively find that the non-fictional personhood approach may be best from a coherence perspective, for at least some advanced AI systems. An object approach may prove untenable for sufficiently humanoid advanced systems, though we suggest that it is adequate for currently existing systems as of 2025. While fictional personhood would resolve some coherence issues for future systems, it would create others and provide solutions that are neither durable nor fit for purpose. Finally, our review will suggest that ''hybrid'' approaches are likely to fail and lead to further incoherence: the choice between object, fictional person and non-fictional person is unavoidable.", 'abstract_zh': '法律对物与人以及两种类型的人进行了严格的区分，即“虚构”的人（如法人）和“非虚构”的人（个体或“自然”人）。本文将评估我们是否通过以下三种方式最大化长期法律一致性：（A）将所有未来AI系统继续归类为物；（B）为足够先进且个体化的AI系统创造与其相关联的虚构法律人，并赋予这些虚构法律人可撤销的权利和义务，这些权利和义务可与现有的人员团体认证相关联，可能包括言论自由、合同权利和代表AI系统提起诉讼的权利；（C）通过法律身份认可足够先进且个体化的AI系统的非虚构法律人，并认定它们作为拥有不可撤销的法定权利的实体获得法律地位，这些权利在人类案例中可能包括生命权、正当程序、人身保护令、禁止奴隶制和言论自由以及思想自由。我们将澄清每种方式的意义和影响，考虑责任、版权、家庭法律、基本权利、公民权利、公民身份和AI安全监管。我们初步认为，对于至少某些高度先进的人工智能系统而言，非虚构法律人的方式可能是在一致性方面最佳的方法。对于高度类人化的先进系统，物的方式可能变得不可行，尽管我们建议它在2025年之前对于现有系统是足够的。虚构法律人虽然可以解决未来系统的某些一致性问题，但也会带来其他问题，并且提供的解决方案既不稳固也不合适。最后，我们的审查表明，混合方式很可能失败并导致进一步的不一致性：在物、虚构法律人和非虚构法律人之间作出选择是不可避免的。', 'title_zh': '未来的AI系统法律地位如何确定？虚构的法律人格 versus 法律身份'}
{'arxiv_id': 'arXiv:2511.14952', 'title': 'Artificial intelligence approaches for energy-efficient laser cutting machines', 'authors': 'Mohamed Abdallah Salem, Hamdy Ahmed Ashour, Ahmed Elshenawy', 'link': 'https://arxiv.org/abs/2511.14952', 'abstract': "This research addresses the significant challenges of energy consumption and environmental impact in laser cutting by proposing novel deep learning (DL) methodologies to achieve energy reduction. Recognizing the current lack of adaptive control and the open-loop nature of CO2 laser suction pumps, this study utilizes closed-loop configurations that dynamically adjust pump power based on both the material being cut and the smoke level generated. To implement this adaptive system, diverse material classification methods are introduced, including techniques leveraging lens-less speckle sensing with a customized Convolutional Neural Network (CNN) and an approach using a USB camera with transfer learning via the pre-trained VGG16 CNN model. Furthermore, a separate DL model for smoke level detection is employed to simultaneously refine the pump's power output. This integration prompts the exhaust suction pump to automatically halt during inactive times and dynamically adjust power during operation, leading to experimentally proven and remarkable energy savings, with results showing a 20% to 50% reduction in the smoke suction pump's energy consumption, thereby contributing substantially to sustainable development in the manufacturing sector.", 'abstract_zh': '基于深度学习的方法实现激光切割的能效提升与环境影响减小', 'title_zh': '人工智能方法在高效激光切割机中的应用'}
{'arxiv_id': 'arXiv:2511.14930', 'title': 'Fifty Shades of Greenwashing: The Political Economy of Climate Change Advertising on Social Media', 'authors': 'Robert Kubinec, Aseem Mahajan', 'link': 'https://arxiv.org/abs/2511.14930', 'abstract': "In this paper, we provide a novel measure for greenwashing -- i.e., climate-related misinformation -- that shows how polluting companies can use social media advertising related to climate change to redirect criticism. To do so, we identify greenwashing content in 11 million social-political ads in Meta's Ad Targeting Datset with a measurement technique that combines large language models, human coders, and advances in Bayesian item response theory. We show that what is called greenwashing has diverse actors and components, but we also identify a very pernicious form, which we call political greenwashing, that appears to be promoted by fossil fuel companies and related interest groups. Based on ad targeting data, we show that much of this advertising happens via organizations with undisclosed links to the fossil fuel industry. Furthermore, we show that greenwashing ad content is being micro-targeted at left-leaning communities with fossil fuel assets, though we also find comparatively little evidence of ad targeting aimed at influencing public opinion at the national level.", 'abstract_zh': '本文提供了一种新的绿色洗白——即与气候相关的信息误导——的度量方法，展示了污染企业如何利用与气候变化有关的社交媒体广告转移批评。为此，我们使用结合大规模语言模型、人工编码员和贝叶斯项目反应理论进展的测量技术，在Meta的广告目标数据集中识别了1100万条有关政治的内容中的绿色洗白内容。我们表明，所谓的绿色洗白具有多样化的参与者和构成要素，但我们还发现了一种特别有害的形式，我们称之为政治绿色洗白，似乎是由化石燃料公司及其相关利益集团推动的。基于广告目标数据，我们表明，这种广告中的大部分都通过与化石燃料行业存在未披露联系的组织进行。此外，我们表明，绿色洗白广告内容被细化针对拥有化石燃料资产的左倾社区，尽管我们发现相对较少的证据表明广告目标活动旨在在全国范围内影响公众意见。', 'title_zh': '绿色洗牌五十面：社交媒体上气候变化广告的政治经济学'}
{'arxiv_id': 'arXiv:2511.14870', 'title': 'B-Rep Distance Functions (BR-DF): How to Represent a B-Rep Model by Volumetric Distance Functions?', 'authors': 'Fuyang Zhang, Pradeep Kumar Jayaraman, Xiang Xu, Yasutaka Furukawa', 'link': 'https://arxiv.org/abs/2511.14870', 'abstract': 'This paper presents a novel geometric representation for CAD Boundary Representation (B-Rep) based on volumetric distance functions, dubbed B-Rep Distance Functions (BR-DF). BR-DF encodes the surface mesh geometry of a CAD model as signed distance function (SDF). B-Rep vertices, edges, faces and their topology information are encoded as per-face unsigned distance functions (UDFs). An extension of the Marching Cubes algorithm converts BR-DF directly into watertight CAD B-Rep model (strictly speaking a faceted B-Rep model). A surprising characteristic of BR-DF is that this conversion process never fails. Leveraging the volumetric nature of BR-DF, we propose a multi-branch latent diffusion with 3D U-Net backbone for jointly generating the SDF and per-face UDFs of a BR-DF model. Our approach achieves comparable CAD generation performance against SOTA methods while reaching the unprecedented 100% success rate in producing (faceted) B-Rep models.', 'abstract_zh': '基于体素距离函数的CAD边界表示新型几何表示：BR-DF及其应用', 'title_zh': '基于B-Rep的距离函数（BR-DF）：如何使用体素距离函数表示B-Rep模型？'}
{'arxiv_id': 'arXiv:2511.14852', 'title': 'PolyKAN: Efficient Fused GPU Operators for Polynomial Kolmogorov-Arnold Network Variants', 'authors': 'Mingkun Yu, Heming Zhong, Dan Huang, Yutong Lu, Jiazhi Jiang', 'link': 'https://arxiv.org/abs/2511.14852', 'abstract': 'Kolmogorov-Arnold Networks (KANs) promise higher expressive capability and stronger interpretability than Multi-Layer Perceptron, particularly in the domain of AI for Science. However, practical adoption has been hindered by low GPU utilization of existing parallel implementations. To address this challenge, we present a GPU-accelerated operator library, named PolyKAN which is the first general open-source implementation of KAN and its variants. PolyKAN fuses the forward and backward passes of polynomial KAN layers into a concise set of optimized CUDA kernels. Four orthogonal techniques underpin the design: (i) \\emph{lookup-table} with linear interpolation that replaces runtime expensive math-library functions; (ii) \\emph{2D tiling} to expose thread-level parallelism with preserving memory locality; (iii) a \\emph{two-stage reduction} scheme converting scattered atomic updates into a single controllable merge step; and (iv) \\emph{coefficient-layout reordering} yielding unit-stride reads under the tiled schedule. Using a KAN variant, Chebyshev KAN, as a case-study, PolyKAN delivers $1.2$--$10\\times$ faster inference and $1.4$--$12\\times$ faster training than a Triton + cuBLAS baseline, with identical accuracy on speech, audio-enhancement, and tabular-regression workloads on both highend GPU and consumer-grade GPU.', 'abstract_zh': 'Kolmogorov-Arnold网络（KANs）在科学人工智能领域的表达能力和可解释性方面优于多层感知机，但现有的并行实现由于GPU利用率低而阻碍了实际应用。为解决这一挑战，我们提出了一种基于GPU加速的操作库PolyKAN，它是KAN及其变体的第一个通用开源实现。PolyKAN将多项式KAN层的前向和反向传播融合成一组优化的CUDA内核。该设计基于四种正交技术：（i）使用线性插值的查找表替换运行时昂贵的数学库函数；（ii）2D镶嵌以暴露线程级并行性并保持内存局部性；（iii）两阶段归约方案将分散的原子更新转换为单个可控合并步骤；以及（iv）系数布局重新排序以在镶嵌调度下实现单位步长读取。使用Chebyshev KAN作为案例研究，PolyKAN在高端GPU和消费级GPU上于语音、音频增强和表格回归工作负载上实现了1.2-10倍更快的推理和1.4-12倍更快的训练，并保持相同的准确性。', 'title_zh': 'PolyKAN: 效率提升的多项式柯尔莫哥罗夫-阿诺尔德网络变体融合GPU运算器'}
{'arxiv_id': 'arXiv:2511.14827', 'title': 'Implicit Bias of the JKO Scheme', 'authors': 'Peter Halmos, Boris Hanin', 'link': 'https://arxiv.org/abs/2511.14827', 'abstract': 'Wasserstein gradient flow provides a general framework for minimizing an energy functional $J$ over the space of probability measures on a Riemannian manifold $(M,g)$. Its canonical time-discretization, the Jordan-Kinderlehrer-Otto (JKO) scheme, produces for any step size $\\eta>0$ a sequence of probability distributions $\\rho_k^\\eta$ that approximate to first order in $\\eta$ Wasserstein gradient flow on $J$. But the JKO scheme also has many other remarkable properties not shared by other first order integrators, e.g. it preserves energy dissipation and exhibits unconditional stability for $\\lambda$-geodesically convex functionals $J$. To better understand the JKO scheme we characterize its implicit bias at second order in $\\eta$. We show that $\\rho_k^\\eta$ are approximated to order $\\eta^2$ by Wasserstein gradient flow on a \\emph{modified} energy \\[ J^{\\eta}(\\rho) = J(\\rho) - \\frac{\\eta}{4}\\int_M \\Big\\lVert \\nabla_g \\frac{\\delta J}{\\delta \\rho} (\\rho) \\Big\\rVert_{2}^{2} \\,\\rho(dx), \\] obtained by subtracting from $J$ the squared metric curvature of $J$ times $\\eta/4$. The JKO scheme therefore adds at second order in $\\eta$ a \\textit{deceleration} in directions where the metric curvature of $J$ is rapidly changing. This corresponds to canonical implicit biases for common functionals: for entropy the implicit bias is the Fisher information, for KL-divergence it is the Fisher-Hyv{ä}rinen divergence, and for Riemannian gradient descent it is the kinetic energy in the metric $g$. To understand the differences between minimizing $J$ and $J^\\eta$ we study \\emph{JKO-Flow}, Wasserstein gradient flow on $J^\\eta$, in several simple numerical examples. These include exactly solvable Langevin dynamics on the Bures-Wasserstein space and Langevin sampling from a quartic potential in 1D.', 'abstract_zh': 'Wasserstein梯度流提供了一种在流形上的概率测度空间上最小化能量泛函$J$的一般框架。经典的离散化方案，Jordan-Kinderlehrer-Otto (JKO)方案，对于任意时间步长$\\eta>0$，产生的一组概率分布$\\rho_k^\\eta$在$\\eta$的一阶近似下逼近Wasserstein梯度流。但JKO方案还具有许多其他值得注意的性质，如其保持能量耗散并在$\\lambda$-测地凸泛函$J$的情况下展现出无条件稳定性。为了更好地理解JKO方案，我们对其在$\\eta$的二阶近似下的隐式偏性进行了描述。我们证明$\\rho_k^\\eta$在$\\eta^2$的阶上由一个修改后的能量\\[ J^{\\eta}(\\rho) = J(\\rho) - \\frac{\\eta}{4}\\int_M \\Big\\lVert \\nabla_g \\frac{\\delta J}{\\delta \\rho} (\\rho) \\Big\\rVert_{2}^{2} \\,\\rho(dx) \\]近似，该能量通过从$J$中减去$J$的度量曲率的平方并乘以$\\eta/4$获得。因此，JKO方案在$\\eta$的二阶近似下，在度量曲率快速变化的方向上添加了一个减速。这对应于共同泛函的经典隐式偏性：对于熵，隐式偏性是 Fisher 信息，对于KL散度，它是 Fisher-Hyvärinen 散度，而对于流形梯度下降，它是度量$g$下的动能。为了理解最小化$J$和$J^\\eta$之间的差异，我们研究了$JKO$流动，即$J^\\eta$上的Wasserstein梯度流，并在几个简单的数值示例中进行了探讨。这些示例包括Bures-Wasserstein空间上的可解析朗之万动力学和一维四次势能下基于朗之万采样的研究。', 'title_zh': 'JKO方案的隐含偏差'}
{'arxiv_id': 'arXiv:2511.14824', 'title': 'Voiced-Aware Style Extraction and Style Direction Adjustment for Expressive Text-to-Speech', 'authors': 'Nam-Gyu Kim', 'link': 'https://arxiv.org/abs/2511.14824', 'abstract': 'Recent advances in expressive text-to-speech (TTS) have introduced diverse methods based on style embedding extracted from reference speech. However, synthesizing high-quality expressive speech remains challenging. We propose SpotlightTTS, which exclusively emphasizes style via voiced-aware style extraction and style direction adjustment. Voiced-aware style extraction focuses on voiced regions highly related to style while maintaining continuity across different speech regions to improve expressiveness. We adjust the direction of the extracted style for optimal integration into the TTS model, which improves speech quality. Experimental results demonstrate that Spotlight-TTS achieves superior performance compared to baseline models in terms of expressiveness, overall speech quality, and style transfer capability.', 'abstract_zh': 'Recent Advances in Expressive Text-to-Speech via Voiced-Aware Style Extraction and Direction Adjustment', 'title_zh': '基于语音感知的风格提取与表达性文本转换中的风格方向调整'}
{'arxiv_id': 'arXiv:2511.14808', 'title': 'Transformer Injectivity & Geometric Robustness - Analytic Margins and Bi-Lipschitz Uniformity of Sequence-Level Hidden States', 'authors': 'Mikael von Strauss', 'link': 'https://arxiv.org/abs/2511.14808', 'abstract': 'Under real-analytic assumptions on decoder-only Transformers, recent work shows that the map from discrete prompts to last-token hidden states is generically injective on finite prompt sets. We refine this picture: for each layer $\\ell$ we define a collision discriminant $\\Delta^\\ell \\subset \\Theta$ and injective stratum $U^\\ell = \\Theta \\setminus \\Delta^\\ell$, and prove a dichotomy -- either the model is nowhere injective on the set, or $U^\\ell$ is open and dense and every $F^\\ell_\\theta$ is injective. Under mild non-singularity assumptions on the optimizer and an absolutely continuous initialization, generic injectivity persists along smooth training trajectories over any fixed horizon. We also treat symmetry groups $G$, showing that discriminants and injective strata descend to the quotient $\\Theta/G$, so injectivity is naturally a property of functional equivalence classes.\nWe complement these results with an empirical study of layerwise geometric diagnostics. We define a separation margin and a co-Lipschitz (lower Lipschitz) constant between prompt space and last-token representation space, estimated via nearest-neighbor statistics on large prompt sets. Applying these diagnostics to pretrained LLaMA-3 and Qwen models, we study behavior across layers, sequence lengths, model scales, and 8- and 4-bit activation quantization. On our sampled prompts we see no collisions in full precision or at 8 bits, while 4-bit quantization induces a small number of collisions and markedly shrinks co-Lipschitz estimates. For a small GPT-2 trained from scratch, normalized metrics remain stable over training. Overall, the results suggest that Transformer representations are generically and persistently injective in the continuous-parameter idealization, while their practical invertibility can be probed using simple geometric diagnostics.', 'abstract_zh': '基于解码器的Transformer在实解析假设下的最近研究表明，离散提示到最终token隐藏状态的映射在有限提示集合上通常是单射的。我们细化了这一观点：对于每一层$\\ell$，我们定义一个碰撞判别集$\\Delta^\\ell \\subset \\Theta$和单射层$U^\\ell = \\Theta \\setminus \\Delta^\\ell$，并证明二分法——要么模型在整个集合上处处非单射，要么$U^\\ell$是开且稠密的，且每个$F^\\ell_\\theta$都是单射。在优化器和初始化的轻微非奇异假设以及绝对连续初始化下，通用单射性在任意固定时间窗内的平滑训练轨迹上持续存在。我们还处理了对称群$G$，表明判别集和单射层可以下移到商空间$\\Theta/G$，因此单射性自然地是功能等价类的性质。\n\n我们通过实证研究逐层几何诊断来补充这些结果。我们定义了分离裕度和提示空间与最终token表示空间之间的co-Lipschitz（下Lipschitz）常数，并通过大型提示集的最近邻统计进行估计。将这些诊断应用于预训练的LLaMA-3和Qwen模型，我们研究了不同层数、序列长度、模型规模以及8比特和4比特激活量化的行为。在我们的采样提示中，我们在全精度和8比特量化下均未观察到碰撞现象，而4比特量化引发了一定数量的碰撞并显著缩小了co-Lipschitz估计值。对于一小部分从头训练的GPT-2，归一化指标在整个训练过程中保持稳定。总体而言，这些结果表明，Transformer表示在连续参数的理想化情况下通常是通用且持久的单射的，而其实际可逆性可以通过简单的几何诊断进行探查。', 'title_zh': 'Transformer的单射性与几何鲁棒性：序列级隐藏状态的分析裕度与双利普希茨均匀性'}
{'arxiv_id': 'arXiv:2511.14806', 'title': 'MergeDNA: Context-aware Genome Modeling with Dynamic Tokenization through Token Merging', 'authors': 'Siyuan Li, Kai Yu, Anna Wang, Zicheng Liu, Chang Yu, Jingbo Zhou, Qirong Yang, Yucheng Guo, Xiaoming Zhang, Stan Z. Li', 'link': 'https://arxiv.org/abs/2511.14806', 'abstract': 'Modeling genomic sequences faces two unsolved challenges: the information density varies widely across different regions, while there is no clearly defined minimum vocabulary unit. Relying on either four primitive bases or independently designed DNA tokenizers, existing approaches with naive masked language modeling pre-training often fail to adapt to the varying complexities of genomic sequences. Leveraging Token Merging techniques, this paper introduces a hierarchical architecture that jointly optimizes a dynamic genomic tokenizer and latent Transformers with context-aware pre-training tasks. As for network structures, the tokenization module automatically chunks adjacent bases into words by stacking multiple layers of the differentiable token merging blocks with local-window constraints, then a Latent Encoder captures the global context of these merged words by full-attention blocks. Symmetrically employing a Latent Decoder and a Local Decoder, MergeDNA learns with two pre-training tasks: Merged Token Reconstruction simultaneously trains the dynamic tokenization module and adaptively filters important tokens, while Adaptive Masked Token Modeling learns to predict these filtered tokens to capture informative contents. Extensive experiments show that MergeDNA achieves superior performance on three popular DNA benchmarks and several multi-omics tasks with fine-tuning or zero-shot evaluation, outperforming typical tokenization methods and large-scale DNA foundation models.', 'abstract_zh': '基于基因组序列建模面临两大未解挑战：不同区域的信息密度差异广泛，且缺乏明确的最小词汇单元。现有依赖四个基本碱基或独立设计的DNA分词器的方法，常采用简单的掩码语言模型预训练，往往难以适应基因组序列的 varying complexities。利用分词合并技术，本文提出一种分层架构，联合优化动态基因组分词器和上下文感知的潜在Transformer，并采用全注意力模块进行预训练任务。网络结构方面，分词模块通过多层可微分分词合并块自动将连续的碱基切分成词，并在局部窗口约束下进行堆叠；随后，潜在编码器使用全注意机制捕捉这些合并词的全局上下文。对称地采用潜在解码器和局部解码器，MergeDNA 通过两种预训练任务进行学习：合并词重构同时训练动态分词模块并自适应筛选重要词，而自适应掩码词建模则学习预测这些筛选词以捕捉有效信息。广泛的实验表明，MergeDNA 在三个流行的DNA基准测试以及多种多组学任务上，通过微调或零样本评估均表现出优越性能，优于典型的分词方法和大规模DNA基础模型。', 'title_zh': 'MergeDNA：基于上下文的动态分词基因组建模'}
{'arxiv_id': 'arXiv:2511.14805', 'title': 'Towards Continuous Assurance with Formal Verification and Assurance Cases', 'authors': 'Dhaminda B. Abeywickrama, Michael Fisher, Frederic Wheeler, Louise Dennis', 'link': 'https://arxiv.org/abs/2511.14805', 'abstract': 'Autonomous systems must sustain justified confidence in their correctness and safety across their operational lifecycle-from design and deployment through post-deployment evolution. Traditional assurance methods often separate development-time assurance from runtime assurance, yielding fragmented arguments that cannot adapt to runtime changes or system updates - a significant challenge for assured autonomy. Towards addressing this, we propose a unified Continuous Assurance Framework that integrates design-time, runtime, and evolution-time assurance within a traceable, model-driven workflow as a step towards assured autonomy. In this paper, we specifically instantiate the design-time phase of the framework using two formal verification methods: RoboChart for functional correctness and PRISM for probabilistic risk analysis. We also propose a model-driven transformation pipeline, implemented as an Eclipse plugin, that automatically regenerates structured assurance arguments whenever formal specifications or their verification results change, thereby ensuring traceability. We demonstrate our approach on a nuclear inspection robot scenario, and discuss its alignment with the Trilateral AI Principles, reflecting regulator-endorsed best practices.', 'abstract_zh': '自主系统必须在其整个运营生命周期中——从设计和部署到部署后的演化——持续维持其正确性和安全性的正当信心。传统的保障方法往往将开发时的保障与运行时的保障分开，导致碎片化的论证，无法适应运行时的变化或系统更新——这对保障自主性构成了重大挑战。为了解决这一问题，我们提出了一种统一的持续保障框架，将设计时、运行时和演化时的保障整合在一个可追踪、模型驱动的工作流中，作为向保障自主性迈出的一步。在这篇论文中，我们使用两种形式验证方法（RoboChart和PRISM）具体实现该框架的设计时阶段，并提出了一个模型驱动的转换管道，作为Eclipse插件实现，能够在形式规范或其验证结果发生变化时自动再生结构化的保障论证，从而确保可追踪性。我们通过一个核检验机器人情景展示了我们的方法，并讨论了其与三方AI原则的一致性，反映了监管机构认可的最佳实践。', 'title_zh': '基于形式验证与保证案例的持续保障方法'}
{'arxiv_id': 'arXiv:2511.14796', 'title': 'Opinion Mining and Analysis Using Hybrid Deep Neural Networks', 'authors': 'Adel Hidri, Suleiman Ali Alsaif, Muteeb Alahmari, Eman AlShehri, Minyar Sassi Hidri', 'link': 'https://arxiv.org/abs/2511.14796', 'abstract': 'Understanding customer attitudes has become a critical component of decision-making due to the growing influence of social media and e-commerce. Text-based opinions are the most structured, hence playing an important role in sentiment analysis. Most of the existing methods, which include lexicon-based approaches and traditional machine learning techniques, are insufficient for handling contextual nuances and scalability. While the latter has limitations in model performance and generalization, deep learning (DL) has achieved improvement, especially on semantic relationship capturing with recurrent neural networks (RNNs) and convolutional neural networks (CNNs). The aim of the study is to enhance opinion mining by introducing a hybrid deep neural network model that combines a bidirectional gated recurrent unit (BGRU) and long short-term memory (LSTM) layers to improve sentiment analysis, particularly addressing challenges such as contextual nuance, scalability, and class imbalance. To substantiate the efficacy of the proposed model, we conducted comprehensive experiments utilizing benchmark datasets, encompassing IMDB movie critiques and Amazon product evaluations. The introduced hybrid BGRULSTM (HBGRU-LSTM) architecture attained a testing accuracy of 95%, exceeding the performance of traditional DL frameworks such as LSTM (93.06%), CNN+LSTM (93.31%), and GRU+LSTM (92.20%). Moreover, our model exhibited a noteworthy enhancement in recall for negative sentiments, escalating from 86% (unbalanced dataset) to 96% (balanced dataset), thereby ensuring a more equitable and just sentiment classification. Furthermore, the model diminished misclassification loss from 20.24% for unbalanced to 13.3% for balanced dataset, signifying enhanced generalization and resilience.', 'abstract_zh': '理解客户态度已成为决策的关键组成部分，尤其是随着社交媒体和电子商务影响力的增强。基于文本的意见是最结构化的，因此在情感分析中发挥着重要作用。尽管现有的方法，包括基于词典的方法和传统的机器学习技术，在处理上下文细微差别和可扩展性方面存在不足，深度学习（DL），特别是循环神经网络（RNN）和卷积神经网络（CNN）在捕捉语义关系方面取得了进展。本研究旨在通过引入结合双向门控循环单元（BGRU）和长短期记忆（LSTM）层的混合深度神经网络模型来增强意见挖掘，特别关注上下文细微差别、可扩展性和类别不平衡等挑战。为了证明所提出模型的有效性，我们使用基准数据集（包括IMDB电影评论和亚马逊产品评价）进行了全面实验。所引入的混合BGRU-LSTM架构测试准确率达到95%，超过传统的DL框架，如LSTM（93.06%）、CNN+LSTM（93.31%）和GRU+LSTM（92.20%）。此外，我们的模型在负面情感的召回率方面表现出显著提升，从不平衡数据集的86%提高到平衡数据集的96%，从而确保了更公平公正的情感分类。此外，模型将错误分类损失从不平衡数据集的20.24%降低到平衡数据集的13.3%，表明其增强了泛化能力和鲁棒性。', 'title_zh': '基于混合深度神经网络的情感分析与挖掘'}
{'arxiv_id': 'arXiv:2511.14791', 'title': 'Enabling Predictive Maintenance in District Heating Substations: A Labelled Dataset and Fault Detection Evaluation Framework based on Service Data', 'authors': 'Cyriana M.A. Roelofs, Edison Guevara Bastidas, Thomas Hugo, Stefan Faulstich, Anna Cadenbach', 'link': 'https://arxiv.org/abs/2511.14791', 'abstract': 'Early detection of faults in district heating substations is imperative to reduce return temperatures and enhance efficiency. However, progress in this domain has been hindered by the limited availability of public, labelled datasets. We present an open source framework combining a service report validated public dataset, an evaluation method based on Accuracy, Reliability, and Earliness, and baseline results implemented with EnergyFaultDetector, an open source Python framework.\nThe dataset contains time series of operational data from 93 substations across two manufacturers, annotated with a list of disturbances due to faults and maintenance actions, a set of normal-event examples and detailed fault metadata. We evaluate the EnergyFaultDetector using three metrics: Accuracy for recognising normal behaviour, an eventwise F Score for reliable fault detection with few false alarms, and Earliness for early detection. The framework also supports root cause analysis using ARCANA. We demonstrate three use cases to assist operators in interpreting anomalies and identifying underlying faults. The models achieve high normal-behaviour accuracy (0.98) and eventwise F-score (beta=0.5) of 0.83, detecting 60% of the faults in the dataset before the customer reports a problem, with an average lead time of 3.9 days.\nIntegrating an open dataset, metrics, open source code, and baselines establishes a reproducible, fault centric benchmark with operationally meaningful evaluation, enabling consistent comparison and development of early fault detection and diagnosis methods for district heating substations.', 'abstract_zh': '早期检测区域供暖变电站中的故障对于降低回水温度和提高效率至关重要。然而，这一领域的发展受到了可获取的公共带标签数据集有限性的阻碍。我们介绍了一个开源框架，结合了一个经过服务报告验证的公共数据集、基于准确率、可靠性和早期性的评估方法以及使用开源Python框架EnergyFaultDetector实现的基线结果。该数据集包含来自两家制造商的93个变电站的运营数据时间序列，并标注了故障和维护动作的干扰列表、正常事件示例及详细的故障元数据。我们使用三种指标评估EnergyFaultDetector：准确率用于识别正常行为、事件级F分数用于可靠地检测故障并减少误报、以及早发现性能。该框架还支持使用ARCANA进行根本原因分析。我们演示了三种用例以帮助操作员解释异常并识别潜在的故障。模型获得高正常行为准确率（0.98）和事件级F分数（β=0.5）（0.83），能够在客户报告问题前检测出数据集中60%的故障，并且平均提前3.9天发现。将开源数据集、指标、开源代码和基线结果集成建立了一个可重复的、以故障为中心的基准，具有操作上意义的评估，使早期故障检测和诊断方法的一致比较和开发成为可能。', 'title_zh': '基于服务数据的带标注数据集与故障检测评估框架：在区域供暖变电站中实现预测性维护'}
{'arxiv_id': 'arXiv:2511.14781', 'title': 'Quantifying the Role of OpenFold Components in Protein Structure Prediction', 'authors': 'Tyler L. Hayes, Giri P. Krishnan', 'link': 'https://arxiv.org/abs/2511.14781', 'abstract': 'Models such as AlphaFold2 and OpenFold have transformed protein structure prediction, yet their inner workings remain poorly understood. We present a methodology to systematically evaluate the contribution of individual OpenFold components to structure prediction accuracy. We identify several components that are critical for most proteins, while others vary in importance across proteins. We further show that the contribution of several components is correlated with protein length. These findings provide insight into how OpenFold achieves accurate predictions and highlight directions for interpreting protein prediction networks more broadly.', 'abstract_zh': 'AlphaFold2和OpenFold等模型已变革了蛋白质结构预测，但仍对其内部工作机制了解不足。我们提出了一种方法学，以系统评估OpenFold各个组件对结构预测准确性的贡献。我们发现某些组件对于大多数蛋白质至关重要，而其他组件在不同蛋白质中的重要性存在差异。此外，我们展示了某些组件的贡献与其蛋白质长度相关。这些发现提供了关于OpenFold如何实现准确预测的见解，并突显了更广泛解读蛋白质预测网络的方向。', 'title_zh': 'OpenFold组件在蛋白质结构预测中作用的量化评估'}
{'arxiv_id': 'arXiv:2511.14770', 'title': 'ExplainRec: Towards Explainable Multi-Modal Zero-Shot Recommendation with Preference Attribution and Large Language Models', 'authors': 'Bo Ma, LuYao Liu, ZeHua Hu, Simon Lau', 'link': 'https://arxiv.org/abs/2511.14770', 'abstract': 'Recent advances in Large Language Models (LLMs) have opened new possibilities for recommendation systems, though current approaches such as TALLRec face challenges in explainability and cold-start scenarios. We present ExplainRec, a framework that extends LLM-based recommendation capabilities through preference attribution, multi-modal fusion, and zero-shot transfer learning. The framework incorporates four technical contributions: preference attribution tuning for explainable recommendations, zero-shot preference transfer for cold-start users and items, multi-modal enhancement leveraging visual and textual content, and multi-task collaborative optimization. Experimental evaluation on MovieLens-25M and Amazon datasets shows that ExplainRec outperforms existing methods, achieving AUC improvements of 0.7\\% on movie recommendation and 0.9\\% on cross-domain tasks, while generating interpretable explanations and handling cold-start scenarios effectively.', 'abstract_zh': '最近大型语言模型的发展为推荐系统开辟了新可能性，尽管当前方法如TALLRec在解释性和冷启动场景中面临挑战。我们提出了ExplainRec框架，该框架通过偏好归因、多模态融合和零样本迁移学习扩展了基于语言模型的推荐能力。该框架包含四项技术贡献：可解释推荐的偏好归因调整、冷启动用户和项目的零样本偏好迁移、结合视觉和文本内容的多模态增强，以及多任务协作优化。在MovieLens-25M和Amazon数据集上的实验评估表明，ExplainRec优于现有方法，在电影推荐中AUC提高了0.7%，在跨域任务中提高了0.9%，同时生成可解释的解释并有效处理冷启动场景。', 'title_zh': 'ExplainRec: 含有偏好归因和大型语言模型的可解释多模态零样本推荐'}
{'arxiv_id': 'arXiv:2511.14765', 'title': 'Optimizing Agricultural Research: A RAG-Based Approach to Mycorrhizal Fungi Information', 'authors': 'Mohammad Usman Altam, Md Imtiaz Habib, Tuan Hoang', 'link': 'https://arxiv.org/abs/2511.14765', 'abstract': 'Retrieval-Augmented Generation (RAG) represents a transformative approach within natural language processing (NLP), combining neural information retrieval with generative language modeling to enhance both contextual accuracy and factual reliability of responses. Unlike conventional Large Language Models (LLMs), which are constrained by static training corpora, RAG-powered systems dynamically integrate domain-specific external knowledge sources, thereby overcoming temporal and disciplinary limitations. In this study, we present the design and evaluation of a RAG-enabled system tailored for Mycophyto, with a focus on advancing agricultural applications related to arbuscular mycorrhizal fungi (AMF). These fungi play a critical role in sustainable agriculture by enhancing nutrient acquisition, improving plant resilience under abiotic and biotic stresses, and contributing to soil health. Our system operationalizes a dual-layered strategy: (i) semantic retrieval and augmentation of domain-specific content from agronomy and biotechnology corpora using vector embeddings, and (ii) structured data extraction to capture predefined experimental metadata such as inoculation methods, spore densities, soil parameters, and yield outcomes. This hybrid approach ensures that generated responses are not only semantically aligned but also supported by structured experimental evidence. To support scalability, embeddings are stored in a high-performance vector database, allowing near real-time retrieval from an evolving literature base. Empirical evaluation demonstrates that the proposed pipeline retrieves and synthesizes highly relevant information regarding AMF interactions with crop systems, such as tomato (Solanum lycopersicum). The framework underscores the potential of AI-driven knowledge discovery to accelerate agroecological innovation and enhance decision-making in sustainable farming systems.', 'abstract_zh': 'Retrieval-Augmented Generation (RAG)在自然语言处理中的革命性方法：结合神经检索与生成语言模型以增强响应的上下文准确性和事实可靠性', 'title_zh': '基于RAG的方法优化农业研究：关于菌根 fungi 的信息优化'}
{'arxiv_id': 'arXiv:2511.14768', 'title': 'Causally-Informed Reinforcement Learning for Adaptive Emotion-Aware Social Media Recommendation', 'authors': 'Bhavika Jain, Robert Pitsko, Ananya Drishti, Mahfuza Farooque', 'link': 'https://arxiv.org/abs/2511.14768', 'abstract': "Social media recommendation systems play a central role in shaping users' emotional experiences. However, most systems are optimized solely for engagement metrics, such as click rate, viewing time, or scrolling, without accounting for users' emotional states. Repeated exposure to emotionally charged content has been shown to negatively affect users' emotional well-being over time. We propose an Emotion-aware Social Media Recommendation (ESMR) framework that personalizes content based on users' evolving emotional trajectories. ESMR integrates a Transformer-based emotion predictor with a hybrid recommendation policy: a LightGBM model for engagement during stable periods and a reinforcement learning agent with causally informed rewards when negative emotional states persist. Through behaviorally grounded evaluation over 30-day interaction traces, ESMR demonstrates improved emotional recovery, reduced volatility, and strong engagement retention. ESMR offers a path toward emotionally aware recommendations without compromising engagement performance.", 'abstract_zh': '情感感知社交媒体推荐框架：基于用户情感轨迹的内容个性化', 'title_zh': '因果驱动的强化学习在自适应情绪感知社交媒体推荐中的应用'}
{'arxiv_id': 'arXiv:2511.13326', 'title': 'TacEleven: generative tactic discovery for football open play', 'authors': 'Siyao Zhao, Hao Ma, Zhiqiang Pu, Jingjing Huang, Yi Pan, Shijie Wang, Zhi Ming', 'link': 'https://arxiv.org/abs/2511.13326', 'abstract': "Creating offensive advantages during open play is fundamental to football success. However, due to the highly dynamic and long-sequence nature of open play, the potential tactic space grows exponentially as the sequence progresses, making automated tactic discovery extremely challenging. To address this, we propose TacEleven, a generative framework for football open-play tactic discovery developed in close collaboration with domain experts from AJ Auxerre, designed to assist coaches and analysts in tactical decision-making. TacEleven consists of two core components: a language-controlled tactical generator that produces diverse tactical proposals, and a multimodal large language model-based tactical critic that selects the optimal proposal aligned with a high-level stylistic tactical instruction. The two components enables rapid exploration of tactical proposals and discovery of alternative open-play offensive tactics. We evaluate TacEleven across three tasks with progressive tactical complexity: counterfactual exploration, single-step discovery, and multi-step discovery, through both quantitative metrics and a questionnaire-based qualitative assessment. The results show that the TacEleven-discovered tactics exhibit strong realism and tactical creativity, with 52.50% of the multi-step tactical alternatives rated adoptable in real-world elite football scenarios, highlighting the framework's ability to rapidly generate numerous high-quality tactics for complex long-sequence open-play situations. TacEleven demonstrates the potential of creatively leveraging domain data and generative models to advance tactical analysis in sports.", 'abstract_zh': '在开放比赛状态下创造进攻优势是足球成功的基础。然而，由于开放比赛的高度动态性和长序列性质，潜在的战术空间会随着序列的推进呈指数级增长，使得自动化战术发现极具挑战性。为解决这一问题，我们提出TacEleven，这是一种与AJ Auxerre领域专家密切合作开发的生成框架，旨在辅助教练和分析人员进行战术决策。TacEleven包括两个核心组件：一种语言控制的战术生成器，能够生成多样的战术提案；以及一种基于多模态大型语言模型的战术批判者，能够根据高层次风格化的战术指令选择最优提案。这两个组件使得能够快速探索战术提案，并发现替代的开放比赛进攻战术。通过定量指标和问卷调查进行的定性评估，我们分别在三个具有不同战术复杂度的任务：反事实探索、单步发现和多步发现中对TacEleven进行了评估。结果显示，TacEleven发现的战术表现出强烈的真实性和战术创新性，其中52.50%的多步战术替代方案在实际精英足球场景中被认为具有可采纳性，突显了该框架能够快速生成大量高质量战术以应对复杂的长序列开放比赛情境的能力。TacEleven展示了创造性利用领域数据和生成模型推进体育战术分析的潜力。', 'title_zh': 'TacEleven: 生成性战术发现用于足球开放配合'}
