{'arxiv_id': 'arXiv:2508.00384', 'title': 'On Learning Closed-Loop Probabilistic Multi-Agent Simulator', 'authors': 'Juanwu Lu, Rohit Gupta, Ahmadreza Moradipari, Kyungtae Han, Ruqi Zhang, Ziran Wang', 'link': 'https://arxiv.org/abs/2508.00384', 'abstract': 'The rapid iteration of autonomous vehicle (AV) deployments leads to increasing needs for building realistic and scalable multi-agent traffic simulators for efficient evaluation. Recent advances in this area focus on closed-loop simulators that enable generating diverse and interactive scenarios. This paper introduces Neural Interactive Agents (NIVA), a probabilistic framework for multi-agent simulation driven by a hierarchical Bayesian model that enables closed-loop, observation-conditioned simulation through autoregressive sampling from a latent, finite mixture of Gaussian distributions. We demonstrate how NIVA unifies preexisting sequence-to-sequence trajectory prediction models and emerging closed-loop simulation models trained on Next-token Prediction (NTP) from a Bayesian inference perspective. Experiments on the Waymo Open Motion Dataset demonstrate that NIVA attains competitive performance compared to the existing method while providing embellishing control over intentions and driving styles.', 'abstract_zh': '自动驾驶汽车（AV）部署的快速迭代推动了对高效评估所需的实际且可扩展的多Agent交通模拟器的需求。这一领域的最新进展集中在可以生成多样化且交互式场景的闭环模拟器上。本文介绍了一种基于分层贝叶斯模型的神经交互Agent（NIVA），这是一种概率框架，通过自回归采样从潜在的有限混合高斯分布中实现闭环、基于观测的模拟。从贝叶斯推理的角度，我们展示NIVA如何统一现有的时间序列到时间序列轨迹预测模型和新兴的闭环模拟模型，并提供对意图和驾驶风格的增强控制。实验表明，NIVA在Waymo开放运动数据集上的性能与现有方法相当，同时提供了增强的控制。', 'title_zh': '关于学习闭环概率多Agent模拟器'}
{'arxiv_id': 'arXiv:2508.00724', 'title': 'Petri Net Modeling and Deadlock-Free Scheduling of Attachable Heterogeneous AGV Systems', 'authors': 'Boyu Li, Zhengchen Li, Weimin Wu, Mengchu Zhou', 'link': 'https://arxiv.org/abs/2508.00724', 'abstract': 'The increasing demand for automation and flexibility drives the widespread adoption of heterogeneous automated guided vehicles (AGVs). This work intends to investigate a new scheduling problem in a material transportation system consisting of attachable heterogeneous AGVs, namely carriers and shuttles. They can flexibly attach to and detach from each other to cooperatively execute complex transportation tasks. While such collaboration enhances operational efficiency, the attachment-induced synchronization and interdependence render the scheduling coupled and susceptible to deadlock. To tackle this challenge, Petri nets are introduced to model AGV schedules, well describing the concurrent and sequential task execution and carrier-shuttle synchronization. Based on Petri net theory, a firing-driven decoding method is proposed, along with deadlock detection and prevention strategies to ensure deadlock-free schedules. Furthermore, a Petri net-based metaheuristic is developed in an adaptive large neighborhood search framework and incorporates an effective acceleration method to enhance computational efficiency. Finally, numerical experiments using real-world industrial data validate the effectiveness of the proposed algorithm against the scheduling policy applied in engineering practice, an exact solver, and four state-of-the-art metaheuristics. A sensitivity analysis is also conducted to provide managerial insights.', 'abstract_zh': '基于异构自动引导车的材料运输系统调度问题研究', 'title_zh': '可附着异构AGV系统的Petri网建模与死锁自由调度'}
{'arxiv_id': 'arXiv:2508.00543', 'title': 'Towards Efficient Certification of Maritime Remote Operation Centers', 'authors': 'Christian Neurohr, Marcel Saager, Lina Putze, Jan-Patrick Osterloh, Karina Rothemann, Hilko Wiards, Eckard Böde, Axel Hahn', 'link': 'https://arxiv.org/abs/2508.00543', 'abstract': 'Additional automation being build into ships implies a shift of crew from ship to shore. However, automated ships still have to be monitored and, in some situations, controlled remotely. These tasks are carried out by human operators located in shore-based remote operation centers. In this work, we present a concept for a hazard database that supports the safeguarding and certification of such remote operation centers. The concept is based on a categorization of hazard sources which we derive from a generic functional architecture. A subsequent preliminary suitability analysis unveils which methods for hazard analysis and risk assessment can adequately fill this hazard database.', 'abstract_zh': '自动化船舶进一步集成意味着船员的减少，从船上转移到岸上。然而，自动化船舶仍然需要远程监控，并在某些情况下需要远程控制。这些任务由位于岸基远程操作中心的人类操作员执行。本文提出一个理念，旨在支持这些远程操作中心的安全保障和认证。该理念基于从通用功能架构中推导出的危险源分类。随后的初步适用性分析揭示了哪些危险分析和风险评估方法能够适当地填充这种危险数据库。', 'title_zh': '向海洋远程操作中心高效认证迈进'}
{'arxiv_id': 'arXiv:2508.00154', 'title': 'Data-Driven Motion Planning for Uncertain Nonlinear Systems', 'authors': 'Babak Esmaeili, Hamidreza Modares, Stefano Di Cairano', 'link': 'https://arxiv.org/abs/2508.00154', 'abstract': 'This paper proposes a data-driven motion-planning framework for nonlinear systems that constructs a sequence of overlapping invariant polytopes. Around each randomly sampled waypoint, the algorithm identifies a convex admissible region and solves data-driven linear-matrix-inequality problems to learn several ellipsoidal invariant sets together with their local state-feedback gains. The convex hull of these ellipsoids, still invariant under a piece-wise-affine controller obtained by interpolating the gains, is then approximated by a polytope. Safe transitions between nodes are ensured by verifying the intersection of consecutive convex-hull polytopes and introducing an intermediate node for a smooth transition. Control gains are interpolated in real time via simplex-based interpolation, keeping the state inside the invariant polytopes throughout the motion. Unlike traditional approaches that rely on system dynamics models, our method requires only data to compute safe regions and design state-feedback controllers. The approach is validated through simulations, demonstrating the effectiveness of the proposed method in achieving safe, dynamically feasible paths for complex nonlinear systems.', 'abstract_zh': '基于数据驱动的非线性系统运动规划框架：构建重叠不变多面体序列', 'title_zh': '数据驱动的不确定非线性系统运动规划'}
{'arxiv_id': 'arXiv:2508.00674', 'title': 'Context-Aware Visualization for Explainable AI Recommendations in Social Media: A Vision for User-Aligned Explanations', 'authors': 'Banan Alkhateeb, Ellis Solaiman', 'link': 'https://arxiv.org/abs/2508.00674', 'abstract': 'Social media platforms today strive to improve user experience through AI recommendations, yet the value of such recommendations vanishes as users do not understand the reasons behind them. This issue arises because explainability in social media is general and lacks alignment with user-specific needs. In this vision paper, we outline a user-segmented and context-aware explanation layer by proposing a visual explanation system with diverse explanation methods. The proposed system is framed by the variety of user needs and contexts, showing explanations in different visualized forms, including a technically detailed version for AI experts and a simplified one for lay users. Our framework is the first to jointly adapt explanation style (visual vs. numeric) and granularity (expert vs. lay) inside a single pipeline. A public pilot with 30 X users will validate its impact on decision-making and trust.', 'abstract_zh': '社交媒体平台通过AI推荐改善用户体验，但这种推荐的价值因用户不了解其背后原因而减弱。这一问题源于社交媒体解释的一般性与用户特定需求之间的不一致。在本文中，我们通过提出一种具有多种解释方法的可视化解释系统，概述了一个基于用户细分和上下文感知的解释层。该系统根据用户需求和上下文的不同，以多种可视化形式展示解释，包括面向AI专家的技术详细版本和面向普通用户的简化版本。我们的框架是首个在单一管道中联合适应解释风格（可视化与数值）和粒度（专家与普通用户）的框架。一项面向30名X用户的公开试点将验证其对决策和信任的影响。', 'title_zh': '基于上下文的可解释人工智能推荐可视化在社交媒体中的用户对齐解释：一种愿景'}
{'arxiv_id': 'arXiv:2508.00658', 'title': 'Multi-Band Variable-Lag Granger Causality: A Unified Framework for Causal Time Series Inference across Frequencies', 'authors': 'Chakattrai Sookkongwaree, Tattep Lakmuang, Chainarong Amornbunchornvej', 'link': 'https://arxiv.org/abs/2508.00658', 'abstract': 'Understanding causal relationships in time series is fundamental to many domains, including neuroscience, economics, and behavioral science. Granger causality is one of the well-known techniques for inferring causality in time series. Typically, Granger causality frameworks have a strong fix-lag assumption between cause and effect, which is often unrealistic in complex systems. While recent work on variable-lag Granger causality (VLGC) addresses this limitation by allowing a cause to influence an effect with different time lags at each time point, it fails to account for the fact that causal interactions may vary not only in time delay but also across frequency bands. For example, in brain signals, alpha-band activity may influence another region with a shorter delay than slower delta-band oscillations. In this work, we formalize Multi-Band Variable-Lag Granger Causality (MB-VLGC) and propose a novel framework that generalizes traditional VLGC by explicitly modeling frequency-dependent causal delays. We provide a formal definition of MB-VLGC, demonstrate its theoretical soundness, and propose an efficient inference pipeline. Extensive experiments across multiple domains demonstrate that our framework significantly outperforms existing methods on both synthetic and real-world datasets, confirming its broad applicability to any type of time series data. Code and datasets are publicly available.', 'abstract_zh': '多频带可变滞后格兰杰因果关系（MB-VLGC）及其理论与应用', 'title_zh': '多频带可变时间滞后格兰杰因果关系：跨频段因果时间序列推断的统一框架'}
{'arxiv_id': 'arXiv:2508.00271', 'title': 'MetaAgent: Toward Self-Evolving Agent via Tool Meta-Learning', 'authors': 'Hongjin Qian, Zheng Liu', 'link': 'https://arxiv.org/abs/2508.00271', 'abstract': 'In this work, we propose MetaAgent, an agentic paradigm inspired by the principle of learning-by-doing, where expertise is developed through hands-on practice and continual self-improvement. MetaAgent starts with a minimal workflow, equipped only with basic reasoning and adaptive help-seeking abilities. When a knowledge gap is encountered, MetaAgent generates natural language help requests, which are routed to the most suitable external tool by a dedicated tool router. As MetaAgent solves tasks, it continually conducts self-reflection and answer verification, distilling actionable experience into concise texts that are dynamically incorporated into future task contexts. Besides, MetaAgent autonomously builds in-house tools and a persistent knowledge base by organizing its tool-use history, further enhancing its ability to retrieve and integrate relevant information We term this continual, data-driven process as \\textit{meta tool learning}, through which MetaAgent incrementally refines its reasoning and tool-use strategies, without changing model parameters or requiring further post-training. Evaluated on challenging knowledge discovery benchmarks, including GAIA, WebWalkerQA, and BrowseCamp, MetaAgent consistently outperforms workflow-based baselines and matches or exceeds end-to-end trained agents, demonstrating the promise of self-evolving agentic systems for robust, general-purpose knowledge discovery. We provide our source codes in this https URL.', 'abstract_zh': '基于学习做事情原则的MetaAgent：一种自主增强性代理范式', 'title_zh': 'MetaAgent：借助工具元学习的自主进化代理'}
{'arxiv_id': 'arXiv:2508.00159', 'title': 'Model-Based Soft Maximization of Suitable Metrics of Long-Term Human Power', 'authors': 'Jobst Heitzig, Ram Potham', 'link': 'https://arxiv.org/abs/2508.00159', 'abstract': "Power is a key concept in AI safety: power-seeking as an instrumental goal, sudden or gradual disempowerment of humans, power balance in human-AI interaction and international AI governance. At the same time, power as the ability to pursue diverse goals is essential for wellbeing.\nThis paper explores the idea of promoting both safety and wellbeing by forcing AI agents explicitly to empower humans and to manage the power balance between humans and AI agents in a desirable way. Using a principled, partially axiomatic approach, we design a parametrizable and decomposable objective function that represents an inequality- and risk-averse long-term aggregate of human power. It takes into account humans' bounded rationality and social norms, and, crucially, considers a wide variety of possible human goals.\nWe derive algorithms for computing that metric by backward induction or approximating it via a form of multi-agent reinforcement learning from a given world model. We exemplify the consequences of (softly) maximizing this metric in a variety of paradigmatic situations and describe what instrumental sub-goals it will likely imply. Our cautious assessment is that softly maximizing suitable aggregate metrics of human power might constitute a beneficial objective for agentic AI systems that is safer than direct utility-based objectives.", 'abstract_zh': 'AI安全中的权力是一个关键概念：寻求权力作为工具性目标、人类突然或渐进失权、人类与AI交互中的权力平衡以及国际AI治理。同时，权力作为追求多元目标的能力对福祉至关重要。\n\n本文探讨通过明确促使AI代理增强人类权力并以可接受的方式管理人类与AI代理之间的权力平衡来促进安全与福祉的想法。采用原则性、部分公理化的方法，我们设计了一个可参数化和可分解的目标函数，代表了一个不平等和风险规避的长期综合的人类权力。该函数考虑了人类的有限理性和社会规范，并且关键地考虑了各种可能的人类目标。\n\n我们通过逆向归纳法或通过给定世界模型的多代理强化学习近似计算该指标的算法。我们通过多种典型情况进行说明，并描述了它可能暗示的工具性亚目标。我们的谨慎评估是，适度最大化适合的人类权力综合指标可能构成一种有益的代理AI系统的目标，比直接基于效用的目标更安全。', 'title_zh': '基于模型的软最大化长期人类功率的合适度量方法'}
{'arxiv_id': 'arXiv:2508.00143', 'title': 'Beyond Agreement: Rethinking Ground Truth in Educational AI Annotation', 'authors': 'Danielle R. Thomas, Conrad Borchers, Kenneth R. Koedinger', 'link': 'https://arxiv.org/abs/2508.00143', 'abstract': 'Humans can be notoriously imperfect evaluators. They are often biased, unreliable, and unfit to define "ground truth." Yet, given the surging need to produce large amounts of training data in educational applications using AI, traditional inter-rater reliability (IRR) metrics like Cohen\'s kappa remain central to validating labeled data. IRR remains a cornerstone of many machine learning pipelines for educational data. Take, for example, the classification of tutors\' moves in dialogues or labeling open responses in machine-graded assessments. This position paper argues that overreliance on human IRR as a gatekeeper for annotation quality hampers progress in classifying data in ways that are valid and predictive in relation to improving learning. To address this issue, we highlight five examples of complementary evaluation methods, such as multi-label annotation schemes, expert-based approaches, and close-the-loop validity. We argue that these approaches are in a better position to produce training data and subsequent models that produce improved student learning and more actionable insights than IRR approaches alone. We also emphasize the importance of external validity, for example, by establishing a procedure of validating tutor moves and demonstrating that it works across many categories of tutor actions (e.g., providing hints). We call on the field to rethink annotation quality and ground truth--prioritizing validity and educational impact over consensus alone.', 'abstract_zh': '人类往往是不可靠的数据评估者，但传统的人间同意可靠性（IRR）指标如科恩κ系数仍然是验证标注数据的关键。为了克服对人类IRR作为数据标注质量守门人的过度依赖，本文提出了五种互补的评估方法，如多标签标注方案、专家基于的方法和闭环验证。我们主张这些方法能够比单独使用IRR方法更有效地生成促进学生学习并提供具体洞察的数据和模型。此外，我们强调外部有效性的的重要性，例如通过建立验证助手指引的程序，并证明其在多种助手法类别中的有效性。我们呼吁该领域重新思考标注质量和真实标签的核心问题，优先考虑有效性及其教育影响，而非单纯的一致性。', 'title_zh': '超越一致性：重新思考教育AI标注中的ground truth'}
{'arxiv_id': 'arXiv:2508.00138', 'title': 'Co-Producing AI: Toward an Augmented, Participatory Lifecycle', 'authors': 'Rashid Mushkani, Hugo Berard, Toumadher Ammar, Cassandre Chatonnier, Shin Koseki', 'link': 'https://arxiv.org/abs/2508.00138', 'abstract': 'Despite efforts to mitigate the inherent risks and biases of artificial intelligence (AI) algorithms, these algorithms can disproportionately impact culturally marginalized groups. A range of approaches has been proposed to address or reduce these risks, including the development of ethical guidelines and principles for responsible AI, as well as technical solutions that promote algorithmic fairness. Drawing on design justice, expansive learning theory, and recent empirical work on participatory AI, we argue that mitigating these harms requires a fundamental re-architecture of the AI production pipeline. This re-design should center co-production, diversity, equity, inclusion (DEI), and multidisciplinary collaboration. We introduce an augmented AI lifecycle consisting of five interconnected phases: co-framing, co-design, co-implementation, co-deployment, and co-maintenance. The lifecycle is informed by four multidisciplinary workshops and grounded in themes of distributed authority and iterative knowledge exchange. Finally, we relate the proposed lifecycle to several leading ethical frameworks and outline key research questions that remain for scaling participatory governance.', 'abstract_zh': '尽管努力减轻人工智能（AI）算法固有的风险和偏见，这些算法仍可能不对等地影响文化上的边缘化群体。为了应对或减少这些风险，提出了一系列方法，包括制定负责任AI的伦理准则和促进算法公平的技术解决方案。借鉴设计正义、扩展学习理论以及参与式AI的最新实证研究，我们认为减轻这些危害需要从根本上重构AI生产 pipeline。这种重新设计应以共同生产、多样性和包容性（DEI）以及跨学科合作为中心。我们提出了一种增强的AI生命周期，包括五个相互连接的阶段：共同界定、共同设计、共同实施、共同部署和共同维护。该生命周期受到四项跨学科研讨会的启发，并扎根于分散权威和迭代知识交流的主题。最后，我们将提出的生命周期与几种主要的伦理框架联系起来，并概述了为扩大参与式治理提供关键研究问题。', 'title_zh': '共生产AI： Toward an Augmented, Participatory Lifecycle'}
{'arxiv_id': 'arXiv:2508.00137', 'title': 'SHACL Validation under Graph Updates (Extended Paper)', 'authors': 'Shqiponja Ahmetaj, George Konstantinidis, Magdalena Ortiz, Paolo Pareti, Mantas Simkus', 'link': 'https://arxiv.org/abs/2508.00137', 'abstract': 'SHACL (SHApe Constraint Language) is a W3C standardized constraint language for RDF graphs. In this paper, we study SHACL validation in RDF graphs under updates. We present a SHACL-based update language that can capture intuitive and realistic modifications on RDF graphs and study the problem of static validation under such updates. This problem asks to verify whether every graph that validates a SHACL specification will still do so after applying a given update sequence. More importantly, it provides a basis for further services for reasoning about evolving RDF graphs. Using a regression technique that embeds the update actions into SHACL constraints, we show that static validation under updates can be reduced to (un)satisfiability of constraints in (a minor extension of) SHACL. We analyze the computational complexity of the static validation problem for SHACL and some key fragments. Finally, we present a prototype implementation that performs static validation and other static analysis tasks on SHACL constraints and demonstrate its behavior through preliminary experiments.', 'abstract_zh': 'SHACL（SHApe Constraint Language）是RDF图的W3C标准化约束语言。在本文中，我们研究RDF图在更新下的SHACL验证问题。我们提出了一种基于SHACL的更新语言，可以捕捉RDF图上直观和现实的修改，并研究在这些更新下进行静态验证的问题。这一问题要求验证在应用给定更新序列之后，所有满足SHACL规范的图是否仍然满足规范。更重要的是，它为关于 evolving RDF图的进一步推理提供了一个基础。通过将更新操作嵌入到SHACL约束中的一种回归技术，我们证明在更新下的静态验证可以被归约为（不）满足约束问题（在SHACL的一个小扩展中）。我们分析了SHACL及其某些关键片段的静态验证问题的计算复杂性。最后，我们展示了一个原型实现，该实现对SHACL约束进行静态验证和其他静态分析任务，并通过初步实验展示了其行为。', 'title_zh': '图更新下的SHACL验证（扩展论文）'}
{'arxiv_id': 'arXiv:2508.00129', 'title': 'Algorithmic Detection of Rank Reversals, Transitivity Violations, and Decomposition Inconsistencies in Multi-Criteria Decision Analysis', 'authors': 'Agustín Borda, Juan Bautista Cabral, Gonzalo Giarda, Diego Nicolás Gimenez Irusta, Paula Pacheco, Alvaro Roy Schachner', 'link': 'https://arxiv.org/abs/2508.00129', 'abstract': 'In Multi-Criteria Decision Analysis, Rank Reversals are a serious problem that can greatly affect the results of a Multi-Criteria Decision Method against a particular set of alternatives. It is therefore useful to have a mechanism that allows one to measure the performance of a method on a set of alternatives. This idea could be taken further to build a global ranking of the effectiveness of different methods to solve a problem. In this paper, we present three tests that detect the presence of Rank Reversals, along with their implementation in the Scikit-Criteria library. We also address the complications that arise when implementing these tests for general scenarios and the design considerations we made to handle them. We close with a discussion about how these additions could play a major role in the judgment of multi-criteria decision methods for problem solving.', 'abstract_zh': '多准则决策分析中，排名反转是一个严重的问题，可能极大影响特定备选方案下多准则决策方法的结果。因此，有必要有一种机制来衡量方法在一组备选方案上的性能。这一想法可以进一步发展，构建不同方法解决同一问题的有效性全球排名。本文介绍了三种检测排名反转的测试，并在Scikit-Criteria库中实现了这些测试。我们还讨论了实现这些测试时遇到的复杂问题以及相应的设计考虑。最后，我们讨论了这些添加如何在多准则决策方法用于问题解决的评估中发挥重要作用。', 'title_zh': '多准则决策分析中算法检测秩颠倒、传递性违反和分解不一致问题'}
{'arxiv_id': 'arXiv:2508.00116', 'title': 'No AI Without PI! Object-Centric Process Mining as the Enabler for Generative, Predictive, and Prescriptive Artificial Intelligence', 'authors': 'Wil M.P. van der Aalst', 'link': 'https://arxiv.org/abs/2508.00116', 'abstract': 'The uptake of Artificial Intelligence (AI) impacts the way we work, interact, do business, and conduct research. However, organizations struggle to apply AI successfully in industrial settings where the focus is on end-to-end operational processes. Here, we consider generative, predictive, and prescriptive AI and elaborate on the challenges of diagnosing and improving such processes. We show that AI needs to be grounded using Object-Centric Process Mining (OCPM). Process-related data are structured and organization-specific and, unlike text, processes are often highly dynamic. OCPM is the missing link connecting data and processes and enables different forms of AI. We use the term Process Intelligence (PI) to refer to the amalgamation of process-centric data-driven techniques able to deal with a variety of object and event types, enabling AI in an organizational context. This paper explains why AI requires PI to improve operational processes and highlights opportunities for successfully combining OCPM and generative, predictive, and prescriptive AI.', 'abstract_zh': '人工智能的应用影响了我们的工作方式、互动方式、商务运作和研究方法。然而，组织在工业环境中很难成功地将人工智能应用于端到端的操作流程。在此，我们考虑生成式、预测式和规范式人工智能，并详细阐述诊断和改进这些流程的挑战。我们表明，人工智能需要通过对象中心的过程挖掘（OCPM）来扎根。相关的流程数据是结构化的、组织特定的，与文本不同，流程通常高度动态。OCPM是连接数据和流程的缺失环节，并能启用不同形式的人工智能。我们使用过程智能（PI）这一术语来指代以过程为中心的数据驱动技术的结合，能够处理各种对象和事件类型，使人工智能在组织环境中得以应用。本文解释了为什么需要过程智能来改进操作流程，并突出了将对象中心的过程挖掘与生成式、预测式和规范式人工智能成功结合的机会。', 'title_zh': '没有 PI 就没有 AI！以对象为中心的过程挖掘作为生成、预测和规范人工智能的使能技术'}
{'arxiv_id': 'arXiv:2508.00081', 'title': 'Rethinking Evidence Hierarchies in Medical Language Benchmarks: A Critical Evaluation of HealthBench', 'authors': 'Fred Mutisya, Shikoh Gitau, Nasubo Ongoma, Keith Mbae, Elizabeth Wamicha', 'link': 'https://arxiv.org/abs/2508.00081', 'abstract': 'HealthBench, a benchmark designed to measure the capabilities of AI systems for health better (Arora et al., 2025), has advanced medical language model evaluation through physician-crafted dialogues and transparent rubrics. However, its reliance on expert opinion, rather than high-tier clinical evidence, risks codifying regional biases and individual clinician idiosyncrasies, further compounded by potential biases in automated grading systems. These limitations are particularly magnified in low- and middle-income settings, where issues like sparse neglected tropical disease coverage and region-specific guideline mismatches are prevalent.\nThe unique challenges of the African context, including data scarcity, inadequate infrastructure, and nascent regulatory frameworks, underscore the urgent need for more globally relevant and equitable benchmarks. To address these shortcomings, we propose anchoring reward functions in version-controlled Clinical Practice Guidelines (CPGs) that incorporate systematic reviews and GRADE evidence ratings.\nOur roadmap outlines "evidence-robust" reinforcement learning via rubric-to-guideline linkage, evidence-weighted scoring, and contextual override logic, complemented by a focus on ethical considerations and the integration of delayed outcome feedback. By re-grounding rewards in rigorously vetted CPGs, while preserving HealthBench\'s transparency and physician engagement, we aim to foster medical language models that are not only linguistically polished but also clinically trustworthy, ethically sound, and globally relevant.', 'abstract_zh': 'HealthBench: 设计用于更好地衡量AI医疗系统能力的基准（Arora et al., 2025），通过医生设计的对话和透明评估标准推动了医疗语言模型的评估，但其依赖专家意见而非高质量临床证据的风险在于固化区域偏见和个体医师的差异性，并且可能进一步加剧自动评分系统的偏见。这些限制在低收入和中等收入国家尤为显著，在这些国家，如淡漠型热带病覆盖率低和区域具体指南不匹配等问题普遍存在。\n\n非洲背景下独特的挑战，包括数据稀缺、基础设施不足和新兴的监管框架，凸显了更具有全球相关性和公平性的基准的迫切需求。为解决这些不足，我们建议将奖励函数锚定在版本控制系统中的临床实践指南（CPGs）中，这些指南结合了系统性回顾和GRADE证据评级。\n\n我们的路线图包括通过评估标准与指南的链接实现“证据稳健”的强化学习、基于证据的评分、以及情境覆盖逻辑，并注重伦理考量和延迟结果反馈的整合。通过将奖励重新锚定在严格审核的CPGs上，同时保持HealthBench的透明性和医生参与，我们旨在培养不仅在语言上精炼而且在临床中可信、伦理上可靠且全球相关的医疗语言模型。', 'title_zh': '重新审视医疗语言基准中的证据层次结构：对HealthBench的批判性评估'}
{'arxiv_id': 'arXiv:2508.00754', 'title': 'A Simple and Effective Method for Uncertainty Quantification and OOD Detection', 'authors': 'Yaxin Ma, Benjamin Colburn, Jose C. Principe', 'link': 'https://arxiv.org/abs/2508.00754', 'abstract': 'Bayesian neural networks and deep ensemble methods have been proposed for uncertainty quantification; however, they are computationally intensive and require large storage. By utilizing a single deterministic model, we can solve the above issue. We propose an effective method based on feature space density to quantify uncertainty for distributional shifts and out-of-distribution (OOD) detection. Specifically, we leverage the information potential field derived from kernel density estimation to approximate the feature space density of the training set. By comparing this density with the feature space representation of test samples, we can effectively determine whether a distributional shift has occurred. Experiments were conducted on a 2D synthetic dataset (Two Moons and Three Spirals) as well as an OOD detection task (CIFAR-10 vs. SVHN). The results demonstrate that our method outperforms baseline models.', 'abstract_zh': '基于特征空间密度的方法用于量化分布偏移和out-of-distribution检测', 'title_zh': '一种简单有效的不确定性量化和OOD检测方法'}
{'arxiv_id': 'arXiv:2508.00751', 'title': 'Harnessing the Power of Interleaving and Counterfactual Evaluation for Airbnb Search Ranking', 'authors': 'Qing Zhang, Alex Deng, Michelle Du, Huiji Gao, Liwei He, Sanjeev Katariya', 'link': 'https://arxiv.org/abs/2508.00751', 'abstract': 'Evaluation plays a crucial role in the development of ranking algorithms on search and recommender systems. It enables online platforms to create user-friendly features that drive commercial success in a steady and effective manner. The online environment is particularly conducive to applying causal inference techniques, such as randomized controlled experiments (known as A/B test), which are often more challenging to implement in fields like medicine and public policy. However, businesses face unique challenges when it comes to effective A/B test. Specifically, achieving sufficient statistical power for conversion-based metrics can be time-consuming, especially for significant purchases like booking accommodations. While offline evaluations are quicker and more cost-effective, they often lack accuracy and are inadequate for selecting candidates for A/B test. To address these challenges, we developed interleaving and counterfactual evaluation methods to facilitate rapid online assessments for identifying the most promising candidates for A/B tests. Our approach not only increased the sensitivity of experiments by a factor of up to 100 (depending on the approach and metrics) compared to traditional A/B testing but also streamlined the experimental process. The practical insights gained from usage in production can also benefit organizations with similar interests.', 'abstract_zh': '评估在搜索引擎和推荐系统排名算法的发展中起着至关重要的作用。它使得在线平台能够持续有效地创建用户友好的功能，以推动商业成功。在线环境特别有利于应用因果推断技术，例如随机化控制试验（即A/B测试），而在医学和公共政策等领域实施此类技术往往更具挑战性。然而，企业在有效实施A/B测试方面也面临独特挑战。特别是，对于如预定住宿这类重大购买行为的转化率指标，要实现足够的统计效力可能非常耗时。虽然离线评估更快且成本更低，但它们通常缺乏准确性，不足以选择进行A/B测试的候选对象。为应对这些挑战，我们开发了交错和反事实评估方法，以促进快速在线评估，识别最有潜力的A/B测试候选对象。我们的方法不仅将实验的敏感性提高了最高可达100倍（取决于方法和指标）相比传统的A/B测试，并且简化了实验流程。从实际应用中获得的经验教训还可以惠及具有类似兴趣的组织。', 'title_zh': '利用交替和反事实评价 harnessing 动力为空bnb搜索排名'}
{'arxiv_id': 'arXiv:2508.00734', 'title': 'Adaptive Machine Learning-Driven Multi-Fidelity Stratified Sampling for Failure Analysis of Nonlinear Stochastic Systems', 'authors': 'Liuyun Xu, Seymour M.J. Spence', 'link': 'https://arxiv.org/abs/2508.00734', 'abstract': 'Existing variance reduction techniques used in stochastic simulations for rare event analysis still require a substantial number of model evaluations to estimate small failure probabilities. In the context of complex, nonlinear finite element modeling environments, this can become computationally challenging-particularly for systems subjected to stochastic excitation. To address this challenge, a multi-fidelity stratified sampling scheme with adaptive machine learning metamodels is introduced for efficiently propagating uncertainties and estimating small failure probabilities. In this approach, a high-fidelity dataset generated through stratified sampling is used to train a deep learning-based metamodel, which then serves as a cost-effective and highly correlated low-fidelity model. An adaptive training scheme is proposed to balance the trade-off between approximation quality and computational demand associated with the development of the low-fidelity model. By integrating the low-fidelity outputs with additional high-fidelity results, an unbiased estimate of the strata-wise failure probabilities is obtained using a multi-fidelity Monte Carlo framework. The overall probability of failure is then computed using the total probability theorem. Application to a full-scale high-rise steel building subjected to stochastic wind excitation demonstrates that the proposed scheme can accurately estimate exceedance probability curves for nonlinear responses of interest, while achieving significant computational savings compared to single-fidelity variance reduction approaches.', 'abstract_zh': '现有用于随机模拟稀有事件分析的方差减少技术仍然需要对模型进行大量评估以估计小的失败概率。在复杂的非线性有限元建模环境中，这可能会变得计算上具有挑战性，特别是在系统受到随机激励的情况下。为应对这一挑战，提出了一种带有自适应机器学习元模型的多保真分层采样方案，用于高效传播不确定性并估计小的失败概率。在该方法中，通过分层采样生成的高保真数据集用于训练基于深度学习的元模型，该模型作为成本效益高且高度相关的低保真模型使用。提出了一个自适应训练方案，以平衡低保真模型开发中近似质量和计算需求之间的trade-off。通过将低保真输出与额外的高保真结果集成，使用多保真蒙特卡罗框架获得各层的无偏失败概率估计。然后，使用全概率定理计算总体失败概率。应用到一个受随机风激励的全规模高层钢建筑表明，所提出的方法可以准确估计感兴趣的非线性响应的超出台阶概率曲线，同时与单保真方差减少方法相比显著节省计算资源。', 'title_zh': '基于机器学习的自适应多保真分层抽样方法及其在非线性随机系统故障分析中的应用'}
{'arxiv_id': 'arXiv:2508.00716', 'title': 'Nested Graph Pseudo-Label Refinement for Noisy Label Domain Adaptation Learning', 'authors': 'Yingxu Wang, Mengzhu Wang, Zhichao Huang, Suyu Liu', 'link': 'https://arxiv.org/abs/2508.00716', 'abstract': 'Graph Domain Adaptation (GDA) facilitates knowledge transfer from labeled source graphs to unlabeled target graphs by learning domain-invariant representations, which is essential in applications such as molecular property prediction and social network analysis. However, most existing GDA methods rely on the assumption of clean source labels, which rarely holds in real-world scenarios where annotation noise is pervasive. This label noise severely impairs feature alignment and degrades adaptation performance under domain shifts. To address this challenge, we propose Nested Graph Pseudo-Label Refinement (NeGPR), a novel framework tailored for graph-level domain adaptation with noisy labels. NeGPR first pretrains dual branches, i.e., semantic and topology branches, by enforcing neighborhood consistency in the feature space, thereby reducing the influence of noisy supervision. To bridge domain gaps, NeGPR employs a nested refinement mechanism in which one branch selects high-confidence target samples to guide the adaptation of the other, enabling progressive cross-domain learning. Furthermore, since pseudo-labels may still contain noise and the pre-trained branches are already overfitted to the noisy labels in the source domain, NeGPR incorporates a noise-aware regularization strategy. This regularization is theoretically proven to mitigate the adverse effects of pseudo-label noise, even under the presence of source overfitting, thus enhancing the robustness of the adaptation process. Extensive experiments on benchmark datasets demonstrate that NeGPR consistently outperforms state-of-the-art methods under severe label noise, achieving gains of up to 12.7% in accuracy.', 'abstract_zh': '带噪声标签下图层次伪标签精炼的图层级域适应（Nested Graph Pseudo-Label Refinement (NeGPR) for Graph-Level Domain Adaptation with Noisy Labels）', 'title_zh': '嵌套图伪标签精炼在噪声标签领域适应学习中'}
{'arxiv_id': 'arXiv:2508.00712', 'title': 'JSON-Bag: A generic game trajectory representation', 'authors': 'Dien Nguyen, Diego Perez-Liebana, Simon Lucas', 'link': 'https://arxiv.org/abs/2508.00712', 'abstract': "We introduce JSON Bag-of-Tokens model (JSON-Bag) as a method to generically represent game trajectories by tokenizing their JSON descriptions and apply Jensen-Shannon distance (JSD) as distance metric for them. Using a prototype-based nearest-neighbor search (P-NNS), we evaluate the validity of JSON-Bag with JSD on six tabletop games -- \\textit{7 Wonders}, \\textit{Dominion}, \\textit{Sea Salt and Paper}, \\textit{Can't Stop}, \\textit{Connect4}, \\textit{Dots and boxes} -- each over three game trajectory classification tasks: classifying the playing agents, game parameters, or game seeds that were used to generate the trajectories.\nOur approach outperforms a baseline using hand-crafted features in the majority of tasks. Evaluating on N-shot classification suggests using JSON-Bag prototype to represent game trajectory classes is also sample efficient. Additionally, we demonstrate JSON-Bag ability for automatic feature extraction by treating tokens as individual features to be used in Random Forest to solve the tasks above, which significantly improves accuracy on underperforming tasks. Finally, we show that, across all six games, the JSD between JSON-Bag prototypes of agent classes highly correlates with the distances between agents' policies.", 'abstract_zh': 'JSON 基于词袋的模型及其在桌游轨迹表示中的应用：基于 Jensen-Shannon 距离的 nearest-neighbor 搜索', 'title_zh': 'JSON-Bag: 通用游戏轨迹表示'}
{'arxiv_id': 'arXiv:2508.00707', 'title': 'Efficient Solution and Learning of Robust Factored MDPs', 'authors': 'Yannik Schnitzer, Alessandro Abate, David Parker', 'link': 'https://arxiv.org/abs/2508.00707', 'abstract': 'Robust Markov decision processes (r-MDPs) extend MDPs by explicitly modelling epistemic uncertainty about transition dynamics. Learning r-MDPs from interactions with an unknown environment enables the synthesis of robust policies with provable (PAC) guarantees on performance, but this can require a large number of sample interactions. We propose novel methods for solving and learning r-MDPs based on factored state-space representations that leverage the independence between model uncertainty across system components. Although policy synthesis for factored r-MDPs leads to hard, non-convex optimisation problems, we show how to reformulate these into tractable linear programs. Building on these, we also propose methods to learn factored model representations directly. Our experimental results show that exploiting factored structure can yield dimensional gains in sample efficiency, producing more effective robust policies with tighter performance guarantees than state-of-the-art methods.', 'abstract_zh': '鲁棒马尔可夫决策过程（r-MDPs）通过明确建模关于转换动态的认知不确定性来扩展MDP。通过与未知环境的交互学习r-MDPs能够合成具有可证明（PAC）性能保证的稳健策略，但这也可能需要大量的样本交互。我们提出了一种基于因子状态空间表示的新方法，利用系统组件间模型不确定性之间的独立性。尽管因子r-MDPs的策略合成导致了难以处理的非凸优化问题，我们展示了如何将其重新表述为可处理的线性规划问题。在此基础上，我们还提出了一种直接学习因子模型表示的方法。我们的实验结果表明，利用因子结构可以实现样本效率上的维度增益，从而生成具有更紧要性能保证的更有效的稳健策略，超越了现有最先进的方法。', 'title_zh': '高效的robust factored MDPs的解算与学习'}
{'arxiv_id': 'arXiv:2508.00679', 'title': 'Segment First, Retrieve Better: Realistic Legal Search via Rhetorical Role-Based Queries', 'authors': 'Shubham Kumar Nigam, Tanmay Dubey, Noel Shallum, Arnab Bhattacharya', 'link': 'https://arxiv.org/abs/2508.00679', 'abstract': 'Legal precedent retrieval is a cornerstone of the common law system, governed by the principle of stare decisis, which demands consistency in judicial decisions. However, the growing complexity and volume of legal documents challenge traditional retrieval methods. TraceRetriever mirrors real-world legal search by operating with limited case information, extracting only rhetorically significant segments instead of requiring complete documents. Our pipeline integrates BM25, Vector Database, and Cross-Encoder models, combining initial results through Reciprocal Rank Fusion before final re-ranking. Rhetorical annotations are generated using a Hierarchical BiLSTM CRF classifier trained on Indian judgments. Evaluated on IL-PCR and COLIEE 2025 datasets, TraceRetriever addresses growing document volume challenges while aligning with practical search constraints, reliable and scalable foundation for precedent retrieval enhancing legal research when only partial case knowledge is available.', 'abstract_zh': '法律先例检索是普通法体系的基石，由 stare decisis 原则治理，要求在司法判决中保持一致性。然而，法律文件的日益复杂性和数量挑战传统的检索方法。TraceRetriever 通过利用有限的案例信息进行操作，提取具有修辞意义的片段，而不是要求完整文档。我们的管道整合了 BM25、向量数据库和跨编码器模型，在通过互惠秩融合进行初步结果的结合后，进行最终重排序。使用层次双向 LSTM CRF 分类器在印度判决上训练生成修辞注解。TraceRetriever 在 IL-PCR 和 COLIEE 2025 数据集上进行评估，解决日益增长的文档量挑战，同时符合实际搜索约束，为在仅部分案件知识可用时增强法律研究提供可靠且可扩展的先例检索基础。', 'title_zh': '先分段，后检索：基于修辞角色的高效法律搜索'}
{'arxiv_id': 'arXiv:2508.00668', 'title': 'Advancing Quantum Information Science Pre-College Education: The Case for Learning Sciences Collaboration', 'authors': 'Raquel Coelho, Roy Pea, Christian Schunn, Jinglei Cheng, Junyu Liu', 'link': 'https://arxiv.org/abs/2508.00668', 'abstract': 'As quantum information science advances and the need for pre-college engagement grows, a critical question remains: How can young learners be prepared to participate in a field so radically different from what they have encountered before? This paper argues that meeting this challenge will require strong interdisciplinary collaboration with the Learning Sciences (LS), a field dedicated to understanding how people learn and designing theory-guided environments to support learning. Drawing on lessons from previous STEM education efforts, we discuss two key contributions of the learning sciences to quantum information science (QIS) education. The first is design-based research, the signature methodology of learning sciences, which can inform the development, refinement, and scaling of effective QIS learning experiences. The second is a framework for reshaping how learners reason about, learn and participate in QIS practices through shifts in knowledge representations that provide new forms of engagement and associated learning. We call for a two-way partnership between quantum information science and the learning sciences, one that not only supports learning in quantum concepts and practices but also improves our understanding of how to teach and support learning in highly complex domains. We also consider potential questions involved in bridging these disciplinary communities and argue that the theoretical and practical benefits justify the effort.', 'abstract_zh': '随着量子信息科学的发展和对中学前教育参与需求的增加，一个关键问题仍然存在：如何准备年轻的学习者参与这样一个与以往遇到的领域截然不同的领域？本文认为，应对这一挑战将需要与学习科学（LS）领域的跨学科合作，该领域致力于理解人们如何学习并设计以理论为导向的支持学习的环境。借鉴以往STEM教育的努力，我们讨论了学习科学对量子信息科学（QIS）教育的两大关键贡献。首先是学习科学的标志性方法——设计导向的研究，可以指导有效的QIS学习体验的发展、完善和扩展。其次是通过知识表示的转变来重塑学习者对QIS实践的思考、学习和参与的方式，提供新的参与形式和相关学习机会。我们呼吁量子信息科学与学习科学之间建立双向伙伴关系，不仅支持量子概念和实践的学习，还提高我们对如何在高度复杂领域进行教学和促进学习的理解。我们还考虑了连接这些学科社区可能涉及的问题，并认为理论和实践的益处值得付出努力。', 'title_zh': '推进量子信息科学中学教育：学习科学合作的必要性'}
{'arxiv_id': 'arXiv:2508.00620', 'title': 'Backdoor Attacks on Deep Learning Face Detection', 'authors': 'Quentin Le Roux, Yannick Teglia, Teddy Furon, Philippe Loubet-Moundi', 'link': 'https://arxiv.org/abs/2508.00620', 'abstract': 'Face Recognition Systems that operate in unconstrained environments capture images under varying conditions,such as inconsistent lighting, or diverse face poses. These challenges require including a Face Detection module that regresses bounding boxes and landmark coordinates for proper Face Alignment. This paper shows the effectiveness of Object Generation Attacks on Face Detection, dubbed Face Generation Attacks, and demonstrates for the first time a Landmark Shift Attack that backdoors the coordinate regression task performed by face detectors. We then offer mitigations against these vulnerabilities.', 'abstract_zh': '不受约束环境下操作的面部识别系统捕获在不同条件下的图像，如不一致的光照或多样的面部姿态。这些挑战需要包含一个面部检测模块，该模块回归边界框和关键点坐标以实现正确的面部对齐。本文展示了面向检测的物体生成攻击（Face Generation Attacks）的有效性，并首次展示了针对面部检测器执行的坐标回归任务的地标位移攻击（Landmark Shift Attack）。然后我们提出了针对这些漏洞的缓解措施。', 'title_zh': '深度学习人脸识别中的后门攻击'}
{'arxiv_id': 'arXiv:2508.00615', 'title': 'Similarity-Based Self-Construct Graph Model for Predicting Patient Criticalness Using Graph Neural Networks and EHR Data', 'authors': 'Mukesh Kumar Sahu, Pinki Roy', 'link': 'https://arxiv.org/abs/2508.00615', 'abstract': 'Accurately predicting the criticalness of ICU patients (such as in-ICU mortality risk) is vital for early intervention in critical care. However, conventional models often treat each patient in isolation and struggle to exploit the relational structure in Electronic Health Records (EHR). We propose a Similarity-Based Self-Construct Graph Model (SBSCGM) that dynamically builds a patient similarity graph from multi-modal EHR data, and a HybridGraphMedGNN architecture that operates on this graph to predict patient mortality and a continuous criticalness score. SBSCGM uses a hybrid similarity measure (combining feature-based and structural similarities) to connect patients with analogous clinical profiles in real-time. The HybridGraphMedGNN integrates Graph Convolutional Network (GCN), GraphSAGE, and Graph Attention Network (GAT) layers to learn robust patient representations, leveraging both local and global graph patterns. In experiments on 6,000 ICU stays from the MIMIC-III dataset, our model achieves state-of-the-art performance (AUC-ROC $0.94$) outperforming baseline classifiers and single-type GNN models. We also demonstrate improved precision/recall and show that the attention mechanism provides interpretable insights into model predictions. Our framework offers a scalable and interpretable solution for critical care risk prediction, with potential to support clinicians in real-world ICU deployment.', 'abstract_zh': '基于相似性自我构建图模型及其在ICU患者重症危险性预测中的应用：HybridGraphMedGNN架构', 'title_zh': '基于相似性自我构造图模型：利用图神经网络和电子健康记录预测患者危重程度'}
{'arxiv_id': 'arXiv:2508.00614', 'title': "Prompting Science Report 3: I'll pay you or I'll kill you -- but will you care?", 'authors': 'Lennart Meincke, Ethan Mollick, Lilach Mollick, Dan Shapiro', 'link': 'https://arxiv.org/abs/2508.00614', 'abstract': "This is the third in a series of short reports that seek to help business, education, and policy leaders understand the technical details of working with AI through rigorous testing. In this report, we investigate two commonly held prompting beliefs: a) offering to tip the AI model and b) threatening the AI model. Tipping was a commonly shared tactic for improving AI performance and threats have been endorsed by Google Founder Sergey Brin (All-In, May 2025, 8:20) who observed that 'models tend to do better if you threaten them,' a claim we subject to empirical testing here. We evaluate model performance on GPQA (Rein et al. 2024) and MMLU-Pro (Wang et al. 2024).\nWe demonstrate two things:\n- Threatening or tipping a model generally has no significant effect on benchmark performance.\n- Prompt variations can significantly affect performance on a per-question level. However, it is hard to know in advance whether a particular prompting approach will help or harm the LLM's ability to answer any particular question.\nTaken together, this suggests that simple prompting variations might not be as effective as previously assumed, especially for difficult problems. However, as reported previously (Meincke et al. 2025a), prompting approaches can yield significantly different results for individual questions.", 'abstract_zh': '这是关于通过严谨测试理解AI技术细节的一系列简报中的第三篇，旨在帮助企业、教育和政策领导者了解与AI合作的技术细节。本报告调查了两种常见的提示观念：a) 提供奖励给AI模型；b) 对AI模型进行威胁。奖励是一种常见的提高AI性能的技术，谷歌创始人谢尔盖·布林曾表示“威胁AI模型会使它们表现更好”（All-In, 2025年5月，8:20），我们在此对其进行实证检验。我们评估了模型在GPQA（Rein等人，2024）和MMLU-Pro（Wang等人，2024）上的性能。\n\n我们证明了以下两点：\n- 对模型进行威胁或奖励通常对基准性能没有显著影响。\n- 不同的提示方式可以在单个问题层面显著影响性能。但是，很难提前知道某种特定的提示方法是否会帮助或损害大型语言模型回答特定问题的能力。\n这些发现表明，简单的提示变化可能没有预期的那么有效，尤其是在解决难题方面。然而，如前所报（Meincke等人，2025a），提示方法可能会在个别问题上产生显著不同的结果。', 'title_zh': '提示科学报告 3：我会付费或者我会杀你——但你会在意吗？'}
{'arxiv_id': 'arXiv:2508.00591', 'title': 'Wukong Framework for Not Safe For Work Detection in Text-to-Image systems', 'authors': 'Mingrui Liu, Sixiao Zhang, Cheng Long', 'link': 'https://arxiv.org/abs/2508.00591', 'abstract': "Text-to-Image (T2I) generation is a popular AI-generated content (AIGC) technology enabling diverse and creative image synthesis. However, some outputs may contain Not Safe For Work (NSFW) content (e.g., violence), violating community guidelines. Detecting NSFW content efficiently and accurately, known as external safeguarding, is essential. Existing external safeguards fall into two types: text filters, which analyze user prompts but overlook T2I model-specific variations and are prone to adversarial attacks; and image filters, which analyze final generated images but are computationally costly and introduce latency. Diffusion models, the foundation of modern T2I systems like Stable Diffusion, generate images through iterative denoising using a U-Net architecture with ResNet and Transformer blocks. We observe that: (1) early denoising steps define the semantic layout of the image, and (2) cross-attention layers in U-Net are crucial for aligning text and image regions. Based on these insights, we propose Wukong, a transformer-based NSFW detection framework that leverages intermediate outputs from early denoising steps and reuses U-Net's pre-trained cross-attention parameters. Wukong operates within the diffusion process, enabling early detection without waiting for full image generation. We also introduce a new dataset containing prompts, seeds, and image-specific NSFW labels, and evaluate Wukong on this and two public benchmarks. Results show that Wukong significantly outperforms text-based safeguards and achieves comparable accuracy of image filters, while offering much greater efficiency.", 'abstract_zh': '基于文本到图像的非工作场所不适合内容检测框架：Wukong', 'title_zh': 'Wukong框架：适用于文本到图像系统中的不适合公开内容检测'}
{'arxiv_id': 'arXiv:2508.00575', 'title': 'Analysing Temporal Reasoning in Description Logics Using Formal Grammars', 'authors': 'Camille Bourgaux, Anton Gnatenko, Michaël Thomazo', 'link': 'https://arxiv.org/abs/2508.00575', 'abstract': 'We establish a correspondence between (fragments of) $\\mathcal{TEL}^\\bigcirc$, a temporal extension of the $\\mathcal{EL}$ description logic with the LTL operator $\\bigcirc^k$, and some specific kinds of formal grammars, in particular, conjunctive grammars (context-free grammars equipped with the operation of intersection). This connection implies that $\\mathcal{TEL}^\\bigcirc$ does not possess the property of ultimate periodicity of models, and further leads to undecidability of query answering in $\\mathcal{TEL}^\\bigcirc$, closing a question left open since the introduction of $\\mathcal{TEL}^\\bigcirc$. Moreover, it also allows to establish decidability of query answering for some new interesting fragments of $\\mathcal{TEL}^\\bigcirc$, and to reuse for this purpose existing tools and algorithms for conjunctive grammars.', 'abstract_zh': '我们将时间扩展的$\\mathcal{EL}$描述逻辑的片段$\\mathcal{TEL}^\\bigcirc$与一些特定类型的正式文法，特别是并发文法（结合了交操作的上下文免费文法），建立对应关系。这一连接意味着$\\mathcal{TEL}^\\bigcirc$不具备模型终极周期性的性质，进一步导致在$\\mathcal{TEL}^\\bigcirc$中查询回答的不可判定性，从而关闭了一个自引入$\\mathcal{TEL}^\\bigcirc$以来遗留的问题。此外，这也允许为$\\mathcal{TEL}^\\bigcirc$的某些新的有趣片段建立查询回答的可判定性，并利用并发文法现有的工具和算法来实现。', 'title_zh': '使用形式文法分析描述逻辑中的时序推理'}
{'arxiv_id': 'arXiv:2508.00555', 'title': 'Activation-Guided Local Editing for Jailbreaking Attacks', 'authors': 'Jiecong Wang, Haoran Li, Hao Peng, Ziqian Zeng, Zihao Wang, Haohua Du, Zhengtao Yu', 'link': 'https://arxiv.org/abs/2508.00555', 'abstract': "Jailbreaking is an essential adversarial technique for red-teaming these models to uncover and patch security flaws. However, existing jailbreak methods face significant drawbacks. Token-level jailbreak attacks often produce incoherent or unreadable inputs and exhibit poor transferability, while prompt-level attacks lack scalability and rely heavily on manual effort and human ingenuity. We propose a concise and effective two-stage framework that combines the advantages of these approaches. The first stage performs a scenario-based generation of context and rephrases the original malicious query to obscure its harmful intent. The second stage then utilizes information from the model's hidden states to guide fine-grained edits, effectively steering the model's internal representation of the input from a malicious toward a benign one. Extensive experiments demonstrate that this method achieves state-of-the-art Attack Success Rate, with gains of up to 37.74% over the strongest baseline, and exhibits excellent transferability to black-box models. Our analysis further demonstrates that AGILE maintains substantial effectiveness against prominent defense mechanisms, highlighting the limitations of current safeguards and providing valuable insights for future defense development. Our code is available at this https URL.", 'abstract_zh': '破解是-red团队利用这些模型以发现和修复安全漏洞的重要对抗技术。然而，现有的破解方法存在显著的局限性。字元级破解攻击通常会产生不连贯或不可读的输入，并表现出较差的迁移性，而提示级攻击缺乏可扩展性且高度依赖人工努力和创意。我们提出了一种简洁而有效的两阶段框架，结合了这两种方法的优势。第一阶段基于场景的生成上下文并重新表述原始恶意查询以掩盖其有害意图。第二阶段利用模型隐藏状态的信息来指导精细编辑，有效引导模型对输入的内部表示从恶意向良性转变。广泛的实验表明，该方法在攻击成功率上达到了最先进的水平，相对于最强的基线方法获得了高达37.74%的提升，并且在黑盒模型中的迁移性表现出色。进一步的分析表明，AGILE在对抗主流防御机制时保持了显著的效果，突显了当前防护措施的局限性，并为未来的防御开发提供了宝贵的见解。该代码可在以下网址获取：this https URL。', 'title_zh': '激活引导局部编辑用于破解攻击'}
{'arxiv_id': 'arXiv:2508.00546', 'title': 'SPENCER: Self-Adaptive Model Distillation for Efficient Code Retrieval', 'authors': 'Wenchao Gu, Zongyi Lyu, Yanlin Wang, Hongyu Zhang, Cuiyun Gao, Michael R. Lyu', 'link': 'https://arxiv.org/abs/2508.00546', 'abstract': "Code retrieval aims to provide users with desired code snippets based on users' natural language queries. With the development of deep learning technologies, adopting pre-trained models for this task has become mainstream. Considering the retrieval efficiency, most of the previous approaches adopt a dual-encoder for this task, which encodes the description and code snippet into representation vectors, respectively. However, the model structure of the dual-encoder tends to limit the model's performance, since it lacks the interaction between the code snippet and description at the bottom layer of the model during training. To improve the model's effectiveness while preserving its efficiency, we propose a framework, which adopts Self-AdaPtive Model Distillation for Efficient CodE Retrieval, named SPENCER. SPENCER first adopts the dual-encoder to narrow the search space and then adopts the cross-encoder to improve accuracy. To improve the efficiency of SPENCER, we propose a novel model distillation technique, which can greatly reduce the inference time of the dual-encoder while maintaining the overall performance. We also propose a teaching assistant selection strategy for our model distillation, which can adaptively select the suitable teaching assistant models for different pre-trained models during the model distillation to ensure the model performance. Extensive experiments demonstrate that the combination of dual-encoder and cross-encoder improves overall performance compared to solely dual-encoder-based models for code retrieval. Besides, our model distillation technique retains over 98% of the overall performance while reducing the inference time of the dual-encoder by 70%.", 'abstract_zh': 'Self-AdaPtive Model Distillation for Efficient CodE Retrieval: SPENCER', 'title_zh': 'SPENCER: 自适应模型蒸馏以实现高效的代码检索'}
{'arxiv_id': 'arXiv:2508.00545', 'title': 'Foundations of Interpretable Models', 'authors': 'Pietro Barbiero, Mateo Espinosa Zarlenga, Alberto Termine, Mateja Jamnik, Giuseppe Marra', 'link': 'https://arxiv.org/abs/2508.00545', 'abstract': 'We argue that existing definitions of interpretability are not actionable in that they fail to inform users about general, sound, and robust interpretable model design. This makes current interpretability research fundamentally ill-posed. To address this issue, we propose a definition of interpretability that is general, simple, and subsumes existing informal notions within the interpretable AI community. We show that our definition is actionable, as it directly reveals the foundational properties, underlying assumptions, principles, data structures, and architectural features necessary for designing interpretable models. Building on this, we propose a general blueprint for designing interpretable models and introduce the first open-sourced library with native support for interpretable data structures and processes.', 'abstract_zh': '我们argue现有的可解释性定义不具备可操作性，因为它们未能向用户传达一般、可靠且稳健的可解释模型设计信息。这使得当前的可解释性研究本质上是不明确的。为了解决这一问题，我们提出了一种通用、简单且包含可解释AI社区中现有非正式概念的可解释性定义。我们展示我们的定义是可操作的，因为它直接揭示了设计可解释模型所必需的基础属性、潜在假设、原则、数据结构和架构特征。在此基础上，我们提出了一种设计可解释模型的一般蓝图，并引入了首个具有内置支持的可解释数据结构和过程的开源库。', 'title_zh': '可解释模型的基础'}
{'arxiv_id': 'arXiv:2508.00525', 'title': 'Towards a Measure Theory of Semantic Information', 'authors': 'George M. Coghill', 'link': 'https://arxiv.org/abs/2508.00525', 'abstract': "A classic account of the quantification of semantic information is that of Bar-Hiller and Carnap. Their account proposes an inverse relation between the informativeness of a statement and its probability. However, their approach assigns the maximum informativeness to a contradiction: which Floridi refers to as the Bar-Hillel-Carnap paradox. He developed a novel theory founded on a distance metric and parabolic relation, designed to remove this paradox. Unfortunately is approach does not succeed in that aim.\nIn this paper I critique Floridi's theory of strongly semantic information on its own terms and show where it succeeds and fails. I then present a new approach based on the unit circle (a relation that has been the basis of theories from basic trigonometry to quantum theory). This is used, by analogy with von Neumann's quantum probability to construct a measure space for informativeness that meets all the requirements stipulated by Floridi and removes the paradox. In addition, while contradictions and tautologies have zero informativeness, it is found that messages which are contradictory to each other are equally informative. The utility of this is explained by means of an example.", 'abstract_zh': '一种语义信息量的经典论述是由Bar-Hiller和Carnap提出的。他们的论述提出，命题的信息量与其概率之间存在倒数关系。然而，他们的方法将最大信息量赋予一个矛盾：这被称为Bar-Hillel-Carnap悖论。Floridi发展了一种新的理论，该理论以距离度量和抛物线关系为基础，旨在消除这一悖论。不幸的是，这种方法未能达到这个目标。\n\n在本文中，我从Floridi自身的理论出发批判 his 强语义信息理论，并展示其成功和失败之处。然后，我提出了一种基于单位圆的新方法（这一关系是基本三角学和量子理论中理论的基础）。通过类比von Neumann的量子概率，我们构建了一个满足Floridi提出的所有要求的信息量度量空间，并消除了悖论。此外，虽然矛盾和重言式具有零信息量，但相互矛盾的信息具有相同的信息量。通过一个例子解释了这一方法的实用性。', 'title_zh': '面向语义信息的测度理论'}
{'arxiv_id': 'arXiv:2508.00496', 'title': 'LesiOnTime -- Joint Temporal and Clinical Modeling for Small Breast Lesion Segmentation in Longitudinal DCE-MRI', 'authors': 'Mohammed Kamran, Maria Bernathova, Raoul Varga, Christian Singer, Zsuzsanna Bago-Horvath, Thomas Helbich, Georg Langs, Philipp Seeböck', 'link': 'https://arxiv.org/abs/2508.00496', 'abstract': 'Accurate segmentation of small lesions in Breast Dynamic Contrast-Enhanced MRI (DCE-MRI) is critical for early cancer detection, especially in high-risk patients. While recent deep learning methods have advanced lesion segmentation, they primarily target large lesions and neglect valuable longitudinal and clinical information routinely used by radiologists. In real-world screening, detecting subtle or emerging lesions requires radiologists to compare across timepoints and consider previous radiology assessments, such as the BI-RADS score. We propose LesiOnTime, a novel 3D segmentation approach that mimics clinical diagnostic workflows by jointly leveraging longitudinal imaging and BIRADS scores. The key components are: (1) a Temporal Prior Attention (TPA) block that dynamically integrates information from previous and current scans; and (2) a BI-RADS Consistency Regularization (BCR) loss that enforces latent space alignment for scans with similar radiological assessments, thus embedding domain knowledge into the training process. Evaluated on a curated in-house longitudinal dataset of high-risk patients with DCE-MRI, our approach outperforms state-of-the-art single-timepoint and longitudinal baselines by 5% in terms of Dice. Ablation studies demonstrate that both TPA and BCR contribute complementary performance gains. These results highlight the importance of incorporating temporal and clinical context for reliable early lesion segmentation in real-world breast cancer screening. Our code is publicly available at this https URL', 'abstract_zh': '准确分割乳腺动态对比增强MRI中的小型病灶对于早期癌症检测至关重要，尤其是在高风险患者中。尽管近期的深度学习方法提高了病灶分割的精度，但它们主要针对大型病灶，并且忽视了放射科医生常规使用的纵向和临床信息。在实际筛查中，检测细微或新出现的病灶需要放射科医生通过比较时间点并考虑之前的影像评估结果，如BI-RADS评分。我们提出了一种名为LesiOnTime的新颖3D分割方法，通过联合利用纵向影像和BI-RADS评分来模仿临床诊断流程。其关键组件包括：(1) 时间先验注意力(TPA)模块，可动态整合前后影像的信息；(2) BI-RADS一致性正则化(BCR)损失，用于对相似放射学评估的影像扫描施加潜在空间对齐，从而将领域知识嵌入训练过程。在高风险患者自建纵向数据集的评估中，我们的方法在Dice系数上比最先进的单时点和纵向基线高出5%。消融研究证明，TPA和BCR均能带来互补的性能提升。这些结果强调了在实际乳腺癌筛查中结合时间与临床上下文以实现可靠早期病灶分割的重要性。我们的代码可在以下链接公开获取。', 'title_zh': 'LesiOnTime -- 联合时序和临床建模在纵向DCE-MRI中小乳腺病灶分割中的应用'}
{'arxiv_id': 'arXiv:2508.00452', 'title': 'M^2VAE: Multi-Modal Multi-View Variational Autoencoder for Cold-start Item Recommendation', 'authors': 'Chuan He, Yongchao Liu, Qiang Li, Wenliang Zhong, Chuntao Hong, Xinwei Yao', 'link': 'https://arxiv.org/abs/2508.00452', 'abstract': 'Cold-start item recommendation is a significant challenge in recommendation systems, particularly when new items are introduced without any historical interaction data. While existing methods leverage multi-modal content to alleviate the cold-start issue, they often neglect the inherent multi-view structure of modalities, the distinction between shared and modality-specific features. In this paper, we propose Multi-Modal Multi-View Variational AutoEncoder (M^2VAE), a generative model that addresses the challenges of modeling common and unique views in attribute and multi-modal features, as well as user preferences over single-typed item features. Specifically, we generate type-specific latent variables for item IDs, categorical attributes, and image features, and use Product-of-Experts (PoE) to derive a common representation. A disentangled contrastive loss decouples the common view from unique views while preserving feature informativeness. To model user inclinations, we employ a preference-guided Mixture-of-Experts (MoE) to adaptively fuse representations. We further incorporate co-occurrence signals via contrastive learning, eliminating the need for pretraining. Extensive experiments on real-world datasets validate the effectiveness of our approach.', 'abstract_zh': '冷启动项推荐是推荐系统中的一个显著挑战，尤其是在没有历史交互数据情况下引入新项时。现有方法通过利用多模态内容来缓解冷启动问题，但往往忽视了模态的固有多视角结构以及共性特征与模态特定特征之间的区别。本文提出多模态多视角变分自编码器（M^2VAE），这是一种生成模型，旨在解决属性和多模态特征中共同视角和独特视角建模的挑战，以及用户对单一类型项特征的偏好。具体而言，我们为项ID、类别属性和图像特征生成类型特定的潜在变量，并利用专家乘积（Product-of-Experts, PoE）获得共同表示。解耦的对比损失将共同视角与独特视角解耦，同时保持特征的信息性。为了建模用户倾向，我们采用偏好引导的混合专家（Mixture-of-Experts, MoE）以自适应方式融合表示。此外，通过对比学习引入共现信号，从而省去了预训练的需要。在实际数据集上的广泛实验验证了我们方法的有效性。', 'title_zh': 'M^2VAE：多模态多视角变分自动编码器在冷启动项推荐中的应用'}
{'arxiv_id': 'arXiv:2508.00413', 'title': 'DC-AE 1.5: Accelerating Diffusion Model Convergence with Structured Latent Space', 'authors': 'Junyu Chen, Dongyun Zou, Wenkun He, Junsong Chen, Enze Xie, Song Han, Han Cai', 'link': 'https://arxiv.org/abs/2508.00413', 'abstract': "We present DC-AE 1.5, a new family of deep compression autoencoders for high-resolution diffusion models. Increasing the autoencoder's latent channel number is a highly effective approach for improving its reconstruction quality. However, it results in slow convergence for diffusion models, leading to poorer generation quality despite better reconstruction quality. This issue limits the quality upper bound of latent diffusion models and hinders the employment of autoencoders with higher spatial compression ratios. We introduce two key innovations to address this challenge: i) Structured Latent Space, a training-based approach to impose a desired channel-wise structure on the latent space with front latent channels capturing object structures and latter latent channels capturing image details; ii) Augmented Diffusion Training, an augmented diffusion training strategy with additional diffusion training objectives on object latent channels to accelerate convergence. With these techniques, DC-AE 1.5 delivers faster convergence and better diffusion scaling results than DC-AE. On ImageNet 512x512, DC-AE-1.5-f64c128 delivers better image generation quality than DC-AE-f32c32 while being 4x faster. Code: this https URL.", 'abstract_zh': 'DC-AE 1.5：一种用于高分辨率扩散模型的新型深度压缩自编码器', 'title_zh': 'DC-AE 1.5: 通过结构化潜在空间加速扩散模型收敛'}
{'arxiv_id': 'arXiv:2508.00394', 'title': 'ExeKGLib: A Platform for Machine Learning Analytics based on Knowledge Graphs', 'authors': 'Antonis Klironomos, Baifan Zhou, Zhipeng Tan, Zhuoxun Zheng, Mohamed H. Gad-Elrab, Heiko Paulheim, Evgeny Kharlamov', 'link': 'https://arxiv.org/abs/2508.00394', 'abstract': 'Nowadays machine learning (ML) practitioners have access to numerous ML libraries available online. Such libraries can be used to create ML pipelines that consist of a series of steps where each step may invoke up to several ML libraries that are used for various data-driven analytical tasks. Development of high-quality ML pipelines is non-trivial; it requires training, ML expertise, and careful development of each step. At the same time, domain experts in science and engineering may not possess such ML expertise and training while they are in pressing need of ML-based analytics. In this paper, we present our ExeKGLib, a Python library enhanced with a graphical interface layer that allows users with minimal ML knowledge to build ML pipelines. This is achieved by relying on knowledge graphs that encode ML knowledge in simple terms accessible to non-ML experts. ExeKGLib also allows improving the transparency and reusability of the built ML workflows and ensures that they are executable. We show the usability and usefulness of ExeKGLib by presenting real use cases.', 'abstract_zh': 'ExeKGLib：一种增强图形界面的Python库，用于非ML专家构建可执行的高质量ML管道', 'title_zh': 'ExeKGLib：基于知识图谱的机器学习分析平台'}
{'arxiv_id': 'arXiv:2508.00381', 'title': 'Advancing Welding Defect Detection in Maritime Operations via Adapt-WeldNet and Defect Detection Interpretability Analysis', 'authors': 'Kamal Basha S, Athira Nambiar', 'link': 'https://arxiv.org/abs/2508.00381', 'abstract': 'Weld defect detection is crucial for ensuring the safety and reliability of piping systems in the oil and gas industry, especially in challenging marine and offshore environments. Traditional non-destructive testing (NDT) methods often fail to detect subtle or internal defects, leading to potential failures and costly downtime. Furthermore, existing neural network-based approaches for defect classification frequently rely on arbitrarily selected pretrained architectures and lack interpretability, raising safety concerns for deployment. To address these challenges, this paper introduces ``Adapt-WeldNet", an adaptive framework for welding defect detection that systematically evaluates various pre-trained architectures, transfer learning strategies, and adaptive optimizers to identify the best-performing model and hyperparameters, optimizing defect detection and providing actionable insights. Additionally, a novel Defect Detection Interpretability Analysis (DDIA) framework is proposed to enhance system transparency. DDIA employs Explainable AI (XAI) techniques, such as Grad-CAM and LIME, alongside domain-specific evaluations validated by certified ASNT NDE Level II professionals. Incorporating a Human-in-the-Loop (HITL) approach and aligning with the principles of Trustworthy AI, DDIA ensures the reliability, fairness, and accountability of the defect detection system, fostering confidence in automated decisions through expert validation. By improving both performance and interpretability, this work enhances trust, safety, and reliability in welding defect detection systems, supporting critical operations in offshore and marine environments.', 'abstract_zh': '焊缺陷检测对于确保石油和天然气行业中管道系统的安全性和可靠性至关重要，尤其是在复杂的海洋和海上环境中。传统的无损检测（NDT）方法往往无法检测到细微的或内部的缺陷，从而可能导致潜在的故障和昂贵的停机时间。此外，现有的基于神经网络的缺陷分类方法通常依赖于任意选择的预训练架构，并缺乏可解释性，增加了部署的安全隐患。为了解决这些挑战，本文介绍了一种自适应框架“Adapt-WeldNet”，该框架系统地评估了各种预训练架构、迁移学习策略和自适应优化器，以确定性能最佳的模型和超参数，优化缺陷检测并提供可操作的洞察。此外，提出了一种新型的缺陷检测可解释性分析（DDIA）框架以增强系统透明度。DDIA 使用可解释人工智能（XAI）技术，如 Grad-CAM 和 LIME，并结合由认证的 ASNT NDE Level II 专业人士进行的领域特定评估。通过引入人机环（HITL）方法并与可信赖人工智能的原则保持一致，DDIA 确保了缺陷检测系统的可靠性和公平性，并通过专家验证增强自动化决策的信心，从而提高焊缺陷检测系统的信任度、安全性和可靠性，支持海洋和海上环境中的关键操作。', 'title_zh': '通过Adapt-WeldNet和缺陷检测可解释性分析推动 maritime 运营中的焊接缺陷检测进展'}
{'arxiv_id': 'arXiv:2508.00300', 'title': 'MetaExplainer: A Framework to Generate Multi-Type User-Centered Explanations for AI Systems', 'authors': 'Shruthi Chari, Oshani Seneviratne, Prithwish Chakraborty, Pablo Meyer, Deborah L. McGuinness', 'link': 'https://arxiv.org/abs/2508.00300', 'abstract': "Explanations are crucial for building trustworthy AI systems, but a gap often exists between the explanations provided by models and those needed by users. To address this gap, we introduce MetaExplainer, a neuro-symbolic framework designed to generate user-centered explanations. Our approach employs a three-stage process: first, we decompose user questions into machine-readable formats using state-of-the-art large language models (LLM); second, we delegate the task of generating system recommendations to model explainer methods; and finally, we synthesize natural language explanations that summarize the explainer outputs. Throughout this process, we utilize an Explanation Ontology to guide the language models and explainer methods. By leveraging LLMs and a structured approach to explanation generation, MetaExplainer aims to enhance the interpretability and trustworthiness of AI systems across various applications, providing users with tailored, question-driven explanations that better meet their needs. Comprehensive evaluations of MetaExplainer demonstrate a step towards evaluating and utilizing current state-of-the-art explanation frameworks. Our results show high performance across all stages, with a 59.06% F1-score in question reframing, 70% faithfulness in model explanations, and 67% context-utilization in natural language synthesis. User studies corroborate these findings, highlighting the creativity and comprehensiveness of generated explanations. Tested on the Diabetes (PIMA Indian) tabular dataset, MetaExplainer supports diverse explanation types, including Contrastive, Counterfactual, Rationale, Case-Based, and Data explanations. The framework's versatility and traceability from using ontology to guide LLMs suggest broad applicability beyond the tested scenarios, positioning MetaExplainer as a promising tool for enhancing AI explainability across various domains.", 'abstract_zh': '元解释器：一种用户中心的神经符号解释框架', 'title_zh': 'MetaExplainer：生成面向用户的多类型解释的AI系统框架'}
{'arxiv_id': 'arXiv:2508.00294', 'title': 'Formal Power Series Representations in Probability and Expected Utility Theory', 'authors': 'Arthur Paul Pedersen, Samuel Allen Alexander', 'link': 'https://arxiv.org/abs/2508.00294', 'abstract': "We advance a general theory of coherent preference that surrenders restrictions embodied in orthodox doctrine. This theory enjoys the property that any preference system admits extension to a complete system of preferences, provided it satisfies a certain coherence requirement analogous to the one de Finetti advanced for his foundations of probability. Unlike de Finetti's theory, the one we set forth requires neither transitivity nor Archimedeanness nor boundedness nor continuity of preference. This theory also enjoys the property that any complete preference system meeting the standard of coherence can be represented by utility in an ordered field extension of the reals. Representability by utility is a corollary of this paper's central result, which at once extends Hölder's Theorem and strengthens Hahn's Embedding Theorem.", 'abstract_zh': '我们提出了一个关于一致偏好的一般理论，该理论舍弃了正统教义中所蕴含的限制条件。该理论具有一种性质：任何偏奋试系统都可以扩展为一个完整的偏奋试系统，前提是它满足一个与de Finetti为概率论基础提出的条件类似的特定一致性要求。与de Finetti的理论不同，我们提出的理论不需要偏好的传递性、阿基米德性、有界性和连续性。此外，该理论还具有一种性质：任何达到一致性标准的完整偏奋试系统都可以在实数的有序域扩张中通过效用表示。效用表示是本文中心结果的推论，这一结果不仅扩展了Hölder定理，还加强了Hahn嵌入定理。', 'title_zh': '形式幂级数表示在概率论与期望效用理论中的应用'}
{'arxiv_id': 'arXiv:2508.00256', 'title': 'Large AI Model-Enabled Secure Communications in Low-Altitude Wireless Networks: Concepts, Perspectives and Case Study', 'authors': 'Chuang Zhang, Geng Sun, Jiacheng Wang, Yijing Lin, Weijie Yuan, Sinem Coleri, Dusit Niyato, Tony Q. S. Quek', 'link': 'https://arxiv.org/abs/2508.00256', 'abstract': 'Low-altitude wireless networks (LAWNs) have the potential to revolutionize communications by supporting a range of applications, including urban parcel delivery, aerial inspections and air taxis. However, compared with traditional wireless networks, LAWNs face unique security challenges due to low-altitude operations, frequent mobility and reliance on unlicensed spectrum, making it more vulnerable to some malicious attacks. In this paper, we investigate some large artificial intelligence model (LAM)-enabled solutions for secure communications in LAWNs. Specifically, we first explore the amplified security risks and important limitations of traditional AI methods in LAWNs. Then, we introduce the basic concepts of LAMs and delve into the role of LAMs in addressing these challenges. To demonstrate the practical benefits of LAMs for secure communications in LAWNs, we propose a novel LAM-based optimization framework that leverages large language models (LLMs) to generate enhanced state features on top of handcrafted representations, and to design intrinsic rewards accordingly, thereby improving reinforcement learning performance for secure communication tasks. Through a typical case study, simulation results validate the effectiveness of the proposed framework. Finally, we outline future directions for integrating LAMs into secure LAWN applications.', 'abstract_zh': '低空无线网络中的大型人工智能模型助力安全通信', 'title_zh': '低高度无线网络中大型AI模型赋能的安全通信：概念、视角与案例研究'}
{'arxiv_id': 'arXiv:2508.00239', 'title': "What's Behind the Magic? Audiences Seek Artistic Value in Generative AI's Contributions to a Live Dance Performance", 'authors': 'Jacqueline Elise Bruen, Myounghoon Jeon', 'link': 'https://arxiv.org/abs/2508.00239', 'abstract': "With the development of generative artificial intelligence (GenAI) tools to create art, stakeholders cannot come to an agreement on the value of these works. In this study we uncovered the mixed opinions surrounding art made by AI. We developed two versions of a dance performance augmented by technology either with or without GenAI. For each version we informed audiences of the performance's development either before or after a survey on their perceptions of the performance. There were thirty-nine participants (13 males, 26 female) divided between the four performances. Results demonstrated that individuals were more inclined to attribute artistic merit to works made by GenAI when they were unaware of its use. We present this case study as a call to address the importance of utilizing the social context and the users' interpretations of GenAI in shaping a technical explanation, leading to a greater discussion that can bridge gaps in understanding.", 'abstract_zh': '随着生成性人工智能（GenAI）工具在创作艺术领域的应用发展，利益相关者在这些作品的价值上无法达成一致意见。本研究揭示了人们对AI创作的艺术作品看法的混杂态度。我们开发了两种版本的技术增强舞蹈表演，一种使用GenAI，另一种不使用GenAI。对于每种版本，我们分别在观众参与调查前或后告知其表演的开发情况。共有三十九名参与者（13名男性，26名女性），分布在四个表演中。结果显示，当参与者不了解GenAI的使用时，他们更倾向于认为这些作品具有艺术价值。我们通过这一案例研究呼吁关注社会语境和用户对GenAI的解读在技术解释中的重要性，以促进更广泛的讨论，弥合理解上的差距。', 'title_zh': '魔力背后是什么？观众在live舞蹈表演中寻求生成式AI的贡献的艺术价值'}
{'arxiv_id': 'arXiv:2508.00235', 'title': 'Weakly Supervised Intracranial Aneurysm Detection and Segmentation in MR angiography via Multi-task UNet with Vesselness Prior', 'authors': 'Erin Rainville, Amirhossein Rasoulian, Hassan Rivaz, Yiming Xiao', 'link': 'https://arxiv.org/abs/2508.00235', 'abstract': "Intracranial aneurysms (IAs) are abnormal dilations of cerebral blood vessels that, if ruptured, can lead to life-threatening consequences. However, their small size and soft contrast in radiological scans often make it difficult to perform accurate and efficient detection and morphological analyses, which are critical in the clinical care of the disorder. Furthermore, the lack of large public datasets with voxel-wise expert annotations pose challenges for developing deep learning algorithms to address the issues. Therefore, we proposed a novel weakly supervised 3D multi-task UNet that integrates vesselness priors to jointly perform aneurysm detection and segmentation in time-of-flight MR angiography (TOF-MRA). Specifically, to robustly guide IA detection and segmentation, we employ the popular Frangi's vesselness filter to derive soft cerebrovascular priors for both network input and an attention block to conduct segmentation from the decoder and detection from an auxiliary branch. We train our model on the Lausanne dataset with coarse ground truth segmentation, and evaluate it on the test set with refined labels from the same database. To further assess our model's generalizability, we also validate it externally on the ADAM dataset. Our results demonstrate the superior performance of the proposed technique over the SOTA techniques for aneurysm segmentation (Dice = 0.614, 95%HD =1.38mm) and detection (false positive rate = 1.47, sensitivity = 92.9%).", 'abstract_zh': '颅内动脉瘤的新型弱监督3D多任务UNet及其血管性先验应用研究', 'title_zh': '基于多任务UNet和血管性先验的弱监督颅内动脉瘤检测与分割在MR血管成像中的应用'}
{'arxiv_id': 'arXiv:2508.00212', 'title': 'Reinitializing weights vs units for maintaining plasticity in neural networks', 'authors': 'J. Fernando Hernandez-Garcia, Shibhansh Dohare, Jun Luo, Rich S. Sutton', 'link': 'https://arxiv.org/abs/2508.00212', 'abstract': 'Loss of plasticity is a phenomenon in which a neural network loses its ability to learn when trained for an extended time on non-stationary data. It is a crucial problem to overcome when designing systems that learn continually. An effective technique for preventing loss of plasticity is reinitializing parts of the network. In this paper, we compare two different reinitialization schemes: reinitializing units vs reinitializing weights. We propose a new algorithm, which we name \\textit{selective weight reinitialization}, for reinitializing the least useful weights in a network. We compare our algorithm to continual backpropagation and ReDo, two previously proposed algorithms that reinitialize units in the network. Through our experiments in continual supervised learning problems, we identify two settings when reinitializing weights is more effective at maintaining plasticity than reinitializing units: (1) when the network has a small number of units and (2) when the network includes layer normalization. Conversely, reinitializing weights and units are equally effective at maintaining plasticity when the network is of sufficient size and does not include layer normalization. We found that reinitializing weights maintains plasticity in a wider variety of settings than reinitializing units.', 'abstract_zh': '神经网络在长时间训练非稳态数据时失去可塑性是一种现象，在设计持续学习系统时需克服的关键问题。有效的防止可塑性丧失的技术是重新初始化网络的一部分。在本文中，我们比较了两种不同的重新初始化方案：重新初始化单位与重新初始化权值。我们提出了一种新的算法——选择性权重新初始化，并将其应用于重新初始化网络中最具代表性的最无用的权值。我们将该算法与两种先前提出的重新初始化单位的算法——连续反向传播和ReDo进行了比较。通过在持续监督学习问题上的实验，我们确定了两种情况下重新初始化权值比重新初始化单位更能保持可塑性：（1）网络的单位数量较少；（2）网络包含层规范化。相反，当网络足够大且不包含层规范化时，重新初始化权重和单位在保持可塑性方面具有同等效果。我们发现，重新初始化权值相较于重新初始化单位在更多的应用场景中能更好地保持可塑性。', 'title_zh': '重新初始化权重 vs 单元以保持神经网络的可塑性'}
{'arxiv_id': 'arXiv:2508.00202', 'title': 'Robust Classification under Noisy Labels: A Geometry-Aware Reliability Framework for Foundation Models', 'authors': 'Ecem Bozkurt, Antonio Ortega', 'link': 'https://arxiv.org/abs/2508.00202', 'abstract': 'Foundation models (FMs) pretrained on large datasets have become fundamental for various downstream machine learning tasks, in particular in scenarios where obtaining perfectly labeled data is prohibitively expensive. In this paper, we assume an FM has to be fine-tuned with noisy data and present a two-stage framework to ensure robust classification in the presence of label noise without model retraining. Recent work has shown that simple k-nearest neighbor (kNN) approaches using an embedding derived from an FM can achieve good performance even in the presence of severe label noise. Our work is motivated by the fact that these methods make use of local geometry. In this paper, following a similar two-stage procedure, reliability estimation followed by reliability-weighted inference, we show that improved performance can be achieved by introducing geometry information. For a given instance, our proposed inference uses a local neighborhood of training data, obtained using the non-negative kernel (NNK) neighborhood construction. We propose several methods for reliability estimation that can rely less on distance and local neighborhood as the label noise increases. Our evaluation on CIFAR-10 and DermaMNIST shows that our methods improve robustness across various noise conditions, surpassing standard K-NN approaches and recent adaptive-neighborhood baselines.', 'abstract_zh': '基于大规模数据预训练的模型在噪声标签下具有鲁棒分类的两阶段框架', 'title_zh': '基于几何感知可靠性的噪声标签下稳健分类框架'}
{'arxiv_id': 'arXiv:2508.00180', 'title': 'EMA Without the Lag: Bias-Corrected Iterate Averaging Schemes', 'authors': 'Adam Block, Cyril Zhang', 'link': 'https://arxiv.org/abs/2508.00180', 'abstract': 'Stochasticity in language model fine-tuning, often caused by the small batch sizes typically used in this regime, can destabilize training by introducing large oscillations in generation quality. A popular approach to mitigating this instability is to take an Exponential moving average (EMA) of weights throughout training. While EMA reduces stochasticity, thereby smoothing training, the introduction of bias from old iterates often creates a lag in optimization relative to vanilla training. In this work, we propose the Bias-Corrected Exponential Moving Average (BEMA), a simple and practical augmentation of EMA that retains variance-reduction benefits while eliminating bias. BEMA is motivated by a simple theoretical model wherein we demonstrate provable acceleration of BEMA over both a standard EMA and vanilla training. Through an extensive suite of experiments on Language Models, we show that BEMA leads to significantly improved convergence rates and final performance over both EMA and vanilla training in a variety of standard LM benchmarks, making BEMA a practical and theoretically motivated intervention for more stable and efficient fine-tuning.', 'abstract_zh': '语言模型微调中的随机性，通常由该阶段通常使用的较小批量大小引起，可能会通过引入生成质量的巨大振荡来 destabilize 训练。缓解这种不稳定性的一种流行方法是在整个训练过程中采取指数移动平均（EMA）的权重。虽然EMA可以减少随机性，从而平滑训练，但旧迭代引入的偏差通常会导致相对于 vanilla 训练的优化滞后。在本文中，我们提出了校正偏差的指数移动平均（BEMA），这是一种简单实用的EMA扩展，保留了减小方差的好处，同时消除了偏差。BEMA 的动机是一个简单的理论模型，在该模型中，我们证明了BEMA 在加速方面优于标准的EMA 和vanilla 训练。通过在语言模型上进行广泛的实验，我们展示了BEMA 在多种标准语言模型基准上的收敛速度和最终性能显著优于EMA 和vanilla 训练，使BEMA 成为一种实用且基于理论的方法，用于提高微调的稳定性和效率。', 'title_zh': 'EMA 无延迟: 偏差校正迭代加权方案'}
{'arxiv_id': 'arXiv:2508.00178', 'title': "The SPACE of AI: Real-World Lessons on AI's Impact on Developers", 'authors': 'Brian Houck, Travis Lowdermilk, Cody Beyer, Steven Clarke, Ben Hanrahan', 'link': 'https://arxiv.org/abs/2508.00178', 'abstract': "As artificial intelligence (AI) tools become increasingly embedded in software development workflows, questions persist about their true impact on developer productivity and experience. This paper presents findings from a mixed-methods study examining how developers perceive AI's influence across the dimensions of the SPACE framework: Satisfaction, Performance, Activity, Collaboration and Efficiency. Drawing on survey responses from over 500 developers and qualitative insights from interviews and observational studies, we find that AI is broadly adopted and widely seen as enhancing productivity, particularly for routine tasks. However, the benefits vary, depending on task complexity, individual usage patterns, and team-level adoption. Developers report increased efficiency and satisfaction, with less evidence of impact on collaboration. Organizational support and peer learning play key roles in maximizing AI's value. These findings suggest that AI is augmenting developers rather than replacing them, and that effective integration depends as much on team culture and support structures as on the tools themselves. We conclude with practical recommendations for teams, organizations and researchers seeking to harness AI's potential in software engineering.", 'abstract_zh': '随着人工智能（AI）工具越来越多地嵌入软件开发工作流中，关于其对开发者生产力和体验的真实影响仍存疑问。本文呈现了对 SPACE 框架维度（满意度、表现、活动、协作与效率）中开发者对 AI 影响感知的混合方法研究发现。基于来自超过500名开发者的调查回应以及访谈和观察研究的定性见解，我们发现AI在开发者的广泛采用并普遍被认为提升了生产力，尤其是在常规任务方面。然而，这种益处依赖于任务复杂度、个体使用模式以及团队级的采用情况而有所不同。开发者报告提高了效率和满意度，但协作方面的证据较少。组织支持和同伴学习在充分发挥AI价值方面发挥着关键作用。这些发现表明，AI正在增强开发者的功能而不是取代他们，并且有效的整合不仅取决于工具本身，还取决于团队文化和支持结构。最后，我们为寻求在软件工程中利用AI潜力的团队、组织和研究者提供了实用建议。', 'title_zh': 'AI的空间：AI对开发者影响的现实世界教训'}
{'arxiv_id': 'arXiv:2508.00141', 'title': 'INSPIRE-GNN: Intelligent Sensor Placement to Improve Sparse Bicycling Network Prediction via Reinforcement Learning Boosted Graph Neural Networks', 'authors': 'Mohit Gupta, Debjit Bhowmick, Rhys Newbury, Meead Saberi, Shirui Pan, Ben Beck', 'link': 'https://arxiv.org/abs/2508.00141', 'abstract': "Accurate link-level bicycling volume estimation is essential for sustainable urban transportation planning. However, many cities face significant challenges of high data sparsity due to limited bicycling count sensor coverage. To address this issue, we propose INSPIRE-GNN, a novel Reinforcement Learning (RL)-boosted hybrid Graph Neural Network (GNN) framework designed to optimize sensor placement and improve link-level bicycling volume estimation in data-sparse environments. INSPIRE-GNN integrates Graph Convolutional Networks (GCN) and Graph Attention Networks (GAT) with a Deep Q-Network (DQN)-based RL agent, enabling a data-driven strategic selection of sensor locations to maximize estimation performance. Applied to Melbourne's bicycling network, comprising 15,933 road segments with sensor coverage on only 141 road segments (99% sparsity) - INSPIRE-GNN demonstrates significant improvements in volume estimation by strategically selecting additional sensor locations in deployments of 50, 100, 200 and 500 sensors. Our framework outperforms traditional heuristic methods for sensor placement such as betweenness centrality, closeness centrality, observed bicycling activity and random placement, across key metrics such as Mean Squared Error (MSE), Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE). Furthermore, our experiments benchmark INSPIRE-GNN against standard machine learning and deep learning models in the bicycle volume estimation performance, underscoring its effectiveness. Our proposed framework provides transport planners actionable insights to effectively expand sensor networks, optimize sensor placement and maximize volume estimation accuracy and reliability of bicycling data for informed transportation planning decisions.", 'abstract_zh': '准确的链路级自行车流量估计对于可持续城市交通规划至关重要。然而，许多城市由于自行车计数传感器覆盖有限而面临严重的数据稀疏性难题。为了解决这一问题，我们提出了一种名为INSPIRE-GNN的新型强化学习（RL）增强混合图神经网络（GNN）框架，旨在优化传感器布放并在数据稀疏环境中改善链路级自行车流量估计。INSPIRE-GNN将图卷积网络（GCN）、图注意力网络（GAT）与基于深度Q网络（DQN）的RL代理相结合，实现基于数据的传感器位置战略性选择，以最大化估计性能。该框架应用于包含15,933条道路段的墨尔本自行车网络，其中仅有141条道路段有传感器覆盖（99%稀疏性）——INSPIRE-GNN在部署50、100、200和500个传感器的情景下，通过战略性选择额外的传感器位置，显著提高了流量估计性能。我们的框架在关键指标如均方误差（MSE）、均方根误差（RMSE）和绝对误差平均值（MAE）上，优于传统启发式方法（如介数中心性、接近中心性、观测到的自行车活动和随机布放）。此外，我们的实验将INSPIRE-GNN与标准的机器学习和深度学习模型在自行车流量估计性能上进行基准测试，进一步证明了其有效性。我们提出的框架为交通规划者提供了 actionable 的洞察，以有效扩展传感器网络、优化传感器布放，并最大化自行车流量估计的准确性和可靠性，从而支持明智的交通规划决策。', 'title_zh': 'INSPIRE-GNN：通过强化学习增强图神经网络优化稀疏自行车网络预测的智能传感器布局'}
{'arxiv_id': 'arXiv:2508.00140', 'title': 'Your Model Is Unfair, Are You Even Aware? Inverse Relationship Between Comprehension and Trust in Explainability Visualizations of Biased ML Models', 'authors': 'Zhanna Kaufman, Madeline Endres, Cindy Xiong Bearfield, Yuriy Brun', 'link': 'https://arxiv.org/abs/2508.00140', 'abstract': "Systems relying on ML have become ubiquitous, but so has biased behavior within them. Research shows that bias significantly affects stakeholders' trust in systems and how they use them. Further, stakeholders of different backgrounds view and trust the same systems differently. Thus, how ML models' behavior is explained plays a key role in comprehension and trust. We survey explainability visualizations, creating a taxonomy of design characteristics. We conduct user studies to evaluate five state-of-the-art visualization tools (LIME, SHAP, CP, Anchors, and ELI5) for model explainability, measuring how taxonomy characteristics affect comprehension, bias perception, and trust for non-expert ML users. Surprisingly, we find an inverse relationship between comprehension and trust: the better users understand the models, the less they trust them. We investigate the cause and find that this relationship is strongly mediated by bias perception: more comprehensible visualizations increase people's perception of bias, and increased bias perception reduces trust. We confirm this relationship is causal: Manipulating explainability visualizations to control comprehension, bias perception, and trust, we show that visualization design can significantly (p < 0.001) increase comprehension, increase perceived bias, and reduce trust. Conversely, reducing perceived model bias, either by improving model fairness or by adjusting visualization design, significantly increases trust even when comprehension remains high. Our work advances understanding of how comprehension affects trust and systematically investigates visualization's role in facilitating responsible ML applications.", 'abstract_zh': '基于机器学习系统的可解释性可视化：理解如何影响信任', 'title_zh': '你的模型是不公平的，你甚至不知道吗？偏见的ML模型的解释性可视化与理解之间的反比关系'}
{'arxiv_id': 'arXiv:2508.00135', 'title': 'Exploring the Feasibility of Deep Learning Techniques for Accurate Gender Classification from Eye Images', 'authors': 'Basna Mohammed Salih Hasan, Ramadhan J. Mstafa', 'link': 'https://arxiv.org/abs/2508.00135', 'abstract': "Gender classification has emerged as a crucial aspect in various fields, including security, human-machine interaction, surveillance, and advertising. Nonetheless, the accuracy of this classification can be influenced by factors such as cosmetics and disguise. Consequently, our study is dedicated to addressing this concern by concentrating on gender classification using color images of the periocular region. The periocular region refers to the area surrounding the eye, including the eyelids, eyebrows, and the region between them. It contains valuable visual cues that can be used to extract key features for gender classification. This paper introduces a sophisticated Convolutional Neural Network (CNN) model that utilizes color image databases to evaluate the effectiveness of the periocular region for gender classification. To validate the model's performance, we conducted tests on two eye datasets, namely CVBL and (Female and Male). The recommended architecture achieved an outstanding accuracy of 99% on the previously unused CVBL dataset while attaining a commendable accuracy of 96% with a small number of learnable parameters (7,235,089) on the (Female and Male) dataset. To ascertain the effectiveness of our proposed model for gender classification using the periocular region, we evaluated its performance through an extensive range of metrics and compared it with other state-of-the-art approaches. The results unequivocally demonstrate the efficacy of our model, thereby suggesting its potential for practical application in domains such as security and surveillance.", 'abstract_zh': '基于 periocular 区域彩色图像的性别分类研究', 'title_zh': '探索深度学习技术在眼图像准确性别分类中的可行性'}
{'arxiv_id': 'arXiv:2508.00117', 'title': 'StackLiverNet: A Novel Stacked Ensemble Model for Accurate and Interpretable Liver Disease Detection', 'authors': 'Md. Ehsanul Haque, S. M. Jahidul Islam, Shakil Mia, Rumana Sharmin, Ashikuzzaman, Md Samir Morshed, Md. Tahmidul Huque', 'link': 'https://arxiv.org/abs/2508.00117', 'abstract': 'Liver diseases are a serious health concern in the world, which requires precise and timely diagnosis to enhance the survival chances of patients. The current literature implemented numerous machine learning and deep learning models to classify liver diseases, but most of them had some issues like high misclassification error, poor interpretability, prohibitive computational expense, and lack of good preprocessing strategies. In order to address these drawbacks, we introduced StackLiverNet in this study; an interpretable stacked ensemble model tailored to the liver disease detection task. The framework uses advanced data preprocessing and feature selection technique to increase model robustness and predictive ability. Random undersampling is performed to deal with class imbalance and make the training balanced. StackLiverNet is an ensemble of several hyperparameter-optimized base classifiers, whose complementary advantages are used through a LightGBM meta-model. The provided model demonstrates excellent performance, with the testing accuracy of 99.89%, Cohen Kappa of 0.9974, and AUC of 0.9993, having only 5 misclassifications, and efficient training and inference speeds that are amenable to clinical practice (training time 4.2783 seconds, inference time 0.1106 seconds). Besides, Local Interpretable Model-Agnostic Explanations (LIME) are applied to generate transparent explanations of individual predictions, revealing high concentrations of Alkaline Phosphatase and moderate SGOT as important observations of liver disease. Also, SHAP was used to rank features by their global contribution to predictions, while the Morris method confirmed the most influential features through sensitivity analysis.', 'abstract_zh': '肝病诊断中的StackLiverNet：一种可解释的集成模型', 'title_zh': 'StackLiverNet: 一种用于准确可解释的肝病检测的新型堆叠集成模型'}
{'arxiv_id': 'arXiv:2508.00109', 'title': 'FACTORY: A Challenging Human-Verified Prompt Set for Long-Form Factuality', 'authors': 'Mingda Chen, Yang Li, Xilun Chen, Adina Williams, Gargi Ghosh, Scott Yih', 'link': 'https://arxiv.org/abs/2508.00109', 'abstract': 'Long-form factuality evaluation assesses the ability of models to generate accurate, comprehensive responses to short prompts. Existing benchmarks often lack human verification, leading to potential quality issues. To address this limitation, we introduce FACTORY, a large-scale, human-verified prompt set. Developed using a model-in-the-loop approach and refined by humans, FACTORY includes challenging prompts that are fact-seeking, answerable, and unambiguous. We conduct human evaluations on 6 state-of-the-art language models using FACTORY and existing datasets. Our results show that FACTORY is a challenging benchmark: approximately 40% of the claims made in the responses of SOTA models are not factual, compared to only 10% for other datasets. Our analysis identifies the strengths of FACTORY over prior benchmarks, emphasizing its reliability and the necessity for models to reason across long-tailed facts.', 'abstract_zh': '长文事实性评估通过评估模型对短提示生成准确全面响应的能力来衡量模型的能力。现有的基准往往缺乏人工验证，可能导致质量问题。为解决这一局限，我们引入了FACTORY，一个大规模的人工验证提示集。该集合作用于模型循环中并由人类进一步细化，包含具有挑战性的、事实导向的、可回答且无歧义的提示。我们使用FACTORY和现有数据集对6个最先进的语言模型进行了人工评估。结果显示，FACTORY是一个具有挑战性的基准：SOTA模型响应中的约40%断言不具事实性，而其他数据集则仅为10%。我们的分析指出了FACTORY相对于前基准的优势，强调了其可靠性和模型在推理长尾事实方面的必要性。', 'title_zh': 'FACTORY：一个具有挑战性的手工验证提示集，用于长文本事实性评估'}
{'arxiv_id': 'arXiv:2508.00098', 'title': 'Stress-Aware Resilient Neural Training', 'authors': 'Ashkan Shakarami, Yousef Yeganeh, Azade Farshad, Lorenzo Nicole, Stefano Ghidoni, Nassir Navab', 'link': 'https://arxiv.org/abs/2508.00098', 'abstract': 'This paper introduces Stress-Aware Learning, a resilient neural training paradigm in which deep neural networks dynamically adjust their optimization behavior - whether under stable training regimes or in settings with uncertain dynamics - based on the concept of Temporary (Elastic) and Permanent (Plastic) Deformation, inspired by structural fatigue in materials science. To instantiate this concept, we propose Plastic Deformation Optimizer, a stress-aware mechanism that injects adaptive noise into model parameters whenever an internal stress signal - reflecting stagnation in training loss and accuracy - indicates persistent optimization difficulty. This enables the model to escape sharp minima and converge toward flatter, more generalizable regions of the loss landscape. Experiments across six architectures, four optimizers, and seven vision benchmarks demonstrate improved robustness and generalization with minimal computational overhead. The code and 3D visuals will be available on GitHub: this https URL.', 'abstract_zh': '基于应力感知的学习：一种自适应神经训练范式', 'title_zh': 'stress-aware resilient神经训练'}
{'arxiv_id': 'arXiv:2508.00078', 'title': 'Evaluating COVID 19 Feature Contributions to Bitcoin Return Forecasting: Methodology Based on LightGBM and Genetic Optimization', 'authors': 'Imen Mahmoud, Andrei Velichko', 'link': 'https://arxiv.org/abs/2508.00078', 'abstract': 'This study proposes a novel methodological framework integrating a LightGBM regression model and genetic algorithm (GA) optimization to systematically evaluate the contribution of COVID-19-related indicators to Bitcoin return prediction. The primary objective was not merely to forecast Bitcoin returns but rather to determine whether including pandemic-related health data significantly enhances prediction accuracy. A comprehensive dataset comprising daily Bitcoin returns and COVID-19 metrics (vaccination rates, hospitalizations, testing statistics) was constructed. Predictive models, trained with and without COVID-19 features, were optimized using GA over 31 independent runs, allowing robust statistical assessment. Performance metrics (R2, RMSE, MAE) were statistically compared through distribution overlaps and Mann-Whitney U tests. Permutation Feature Importance (PFI) analysis quantified individual feature contributions. Results indicate that COVID-19 indicators significantly improved model performance, particularly in capturing extreme market fluctuations (R2 increased by 40%, RMSE decreased by 2%, both highly significant statistically). Among COVID-19 features, vaccination metrics, especially the 75th percentile of fully vaccinated individuals, emerged as dominant predictors. The proposed methodology extends existing financial analytics tools by incorporating public health signals, providing investors and policymakers with refined indicators to navigate market uncertainty during systemic crises.', 'abstract_zh': '本研究提出了一种结合LightGBM回归模型和遗传算法（GA）优化的新方法论框架，系统评估与COVID-19相关的指标对比特币收益预测的贡献。主要目标不仅仅在于预测比特币收益，而是确定是否包括与疫情相关健康数据能够显著提高预测准确性。构建了一个包含每日比特币收益和COVID-19指标（疫苗接种率、住院人数、检测统计数据）的综合数据集。通过遗传算法优化了包含和不包含COVID-19特征的预测模型，进行了31次独立运行，以实现稳健的统计评估。通过分布重叠和曼尼 Whitney U 检验比较了性能指标（R², RMSE, MAE）。通过置换特征重要性（PFI）分析量化了各个特征的贡献。结果表明，与COVID-19相关的指标显著提高了模型性能，特别是在捕捉极端市场波动方面（R² 增加了40%，RMSE 减少了2%，均具有高度统计显著性）。在COVID-19特征中，疫苗接种指标，尤其是完全接种疫苗人数的第75百分位数， emerged as主导预测因素。提出的方法拓展了现有的金融分析工具，通过整合公共卫生信号，为投资者和政策制定者提供了在系统性危机期间导航市场不确定性所需的精细化指标。', 'title_zh': '基于LightGBM和遗传优化的方法评估新冠肺炎特征对比特币回报预测的贡献'}
{'arxiv_id': 'arXiv:2508.00046', 'title': 'Benchmarking Partial Observability in Reinforcement Learning with a Suite of Memory-Improvable Domains', 'authors': 'Ruo Yu Tao, Kaicheng Guo, Cameron Allen, George Konidaris', 'link': 'https://arxiv.org/abs/2508.00046', 'abstract': "Mitigating partial observability is a necessary but challenging task for general reinforcement learning algorithms. To improve an algorithm's ability to mitigate partial observability, researchers need comprehensive benchmarks to gauge progress. Most algorithms tackling partial observability are only evaluated on benchmarks with simple forms of state aliasing, such as feature masking and Gaussian noise. Such benchmarks do not represent the many forms of partial observability seen in real domains, like visual occlusion or unknown opponent intent. We argue that a partially observable benchmark should have two key properties. The first is coverage in its forms of partial observability, to ensure an algorithm's generalizability. The second is a large gap between the performance of a agents with more or less state information, all other factors roughly equal. This gap implies that an environment is memory improvable: where performance gains in a domain are from an algorithm's ability to cope with partial observability as opposed to other factors. We introduce best-practice guidelines for empirically benchmarking reinforcement learning under partial observability, as well as the open-source library POBAX: Partially Observable Benchmarks in JAX. We characterize the types of partial observability present in various environments and select representative environments for our benchmark. These environments include localization and mapping, visual control, games, and more. Additionally, we show that these tasks are all memory improvable and require hard-to-learn memory functions, providing a concrete signal for partial observability research. This framework includes recommended hyperparameters as well as algorithm implementations for fast, out-of-the-box evaluation, as well as highly performant environments implemented in JAX for GPU-scalable experimentation.", 'abstract_zh': '缓解部分可观测性是通用强化学习算法面临的一项必要但具有挑战性的任务。为了提高算法缓解部分可观测性的能力，需要全面的基准来评估进展。大多数处理部分可观测性的算法仅在特征屏蔽和高斯噪声等简单形式的状态混同基准上进行评估。这些基准无法代表真实领域中观察到的众多形式的部分可观测性，例如视觉遮挡或未知对手意图。我们认为一个部分可观测性基准应具备两个关键特性。首先，其形式的覆盖面应确保算法的泛化能力。其次，具有更多或更少状态信息的代理之间应存在显著的性能差距，其他因素大致相同。这一差距表明环境可以通过记忆改进提升性能：即性能提升源于算法处理部分可观测性的能力，而非其他因素。我们提出了在部分可观测性下 empirically benchmarking 强化学习的最佳实践指南，以及开源库 POBAX：JAX 中的部分可观测性基准。我们分析了各种环境中存在的部分可观测性类型，并选择了代表性的环境用于基准测试。这些环境包括定位与制图、视觉控制、游戏等。此外，我们展示了这些任务都是可以通过记忆改进提升性能，并且需要难以学习的记忆函数，这为部分可观测性研究提供了明确信号。该框架包括推荐的超参数和快速、开箱即用的算法实现，以及在 JAX 中实现的高度可性能环境，支持 GPU 扩展实验。', 'title_zh': '基于记忆可提升领域 Benchmarks in Partial Observability in Reinforcement Learning'}
{'arxiv_id': 'arXiv:2508.00039', 'title': 'Hybrid LSTM-Transformer Models for Profiling Highway-Railway Grade Crossings', 'authors': 'Kaustav Chatterjee, Joshua Q. Li, Fatemeh Ansari, Masud Rana Munna, Kundan Parajulee, Jared Schwennesen', 'link': 'https://arxiv.org/abs/2508.00039', 'abstract': 'Hump crossings, or high-profile Highway Railway Grade Crossings (HRGCs), pose safety risks to highway vehicles due to potential hang-ups. These crossings typically result from post-construction railway track maintenance activities or non-compliance with design guidelines for HRGC vertical alignments. Conventional methods for measuring HRGC profiles are costly, time-consuming, traffic-disruptive, and present safety challenges. To address these issues, this research employed advanced, cost-effective techniques and innovative modeling approaches for HRGC profile measurement. A novel hybrid deep learning framework combining Long Short-Term Memory (LSTM) and Transformer architectures was developed by utilizing instrumentation and ground truth data. Instrumentation data were gathered using a highway testing vehicle equipped with Inertial Measurement Unit (IMU) and Global Positioning System (GPS) sensors, while ground truth data were obtained via an industrial-standard walking profiler. Field data was collected at the Red Rock Railroad Corridor in Oklahoma. Three advanced deep learning models Transformer-LSTM sequential (model 1), LSTM-Transformer sequential (model 2), and LSTM-Transformer parallel (model 3) were evaluated to identify the most efficient architecture. Models 2 and 3 outperformed the others and were deployed to generate 2D/3D HRGC profiles. The deep learning models demonstrated significant potential to enhance highway and railroad safety by enabling rapid and accurate assessment of HRGC hang-up susceptibility.', 'abstract_zh': '高原形高速公路铁路平交道口的安全评估：基于新型深度学习框架的测量方法', 'title_zh': '混合LSTM-Transformer模型用于高速公路铁路平交道特征分析'}
{'arxiv_id': 'arXiv:2508.00037', 'title': 'Predicting Large-scale Urban Network Dynamics with Energy-informed Graph Neural Diffusion', 'authors': 'Tong Nie, Jian Sun, Wei Ma', 'link': 'https://arxiv.org/abs/2508.00037', 'abstract': 'Networked urban systems facilitate the flow of people, resources, and services, and are essential for economic and social interactions. These systems often involve complex processes with unknown governing rules, observed by sensor-based time series. To aid decision-making in industrial and engineering contexts, data-driven predictive models are used to forecast spatiotemporal dynamics of urban systems. Current models such as graph neural networks have shown promise but face a trade-off between efficacy and efficiency due to computational demands. Hence, their applications in large-scale networks still require further efforts. This paper addresses this trade-off challenge by drawing inspiration from physical laws to inform essential model designs that align with fundamental principles and avoid architectural redundancy. By understanding both micro- and macro-processes, we present a principled interpretable neural diffusion scheme based on Transformer-like structures whose attention layers are induced by low-dimensional embeddings. The proposed scalable spatiotemporal Transformer (ScaleSTF), with linear complexity, is validated on large-scale urban systems including traffic flow, solar power, and smart meters, showing state-of-the-art performance and remarkable scalability. Our results constitute a fresh perspective on the dynamics prediction in large-scale urban networks.', 'abstract_zh': '网络化城市系统促进人员、资源和服务的流动，是经济和社会互动的基础。这些系统通常涉及受传感器时间序列观测的复杂过程，其治理规则尚不完全清楚。为了工业和工程领域的决策支持，数据驱动的预测模型被用来预报城市系统的时空动态。当前模型如图神经网络展现了潜力，但因计算需求而存在有效性和效率之间的权衡。因此，这些模型在大规模网络中的应用仍需进一步努力。本文通过借鉴物理法则来启发模型设计，使其符合基本原理并避免架构冗余，以解决这一权衡挑战。通过理解微观和宏观过程，我们提出了一种基于Transformer结构的原理性可解释神经扩散方案，其注意力层由低维度嵌入诱导。提出的线性复杂度可扩展时空Transformer（ScaleSTF），在包括交通流量、太阳能电力和智能电表在内的大规模城市系统中得到验证，展示了顶级性能和显著的可扩展性。我们的结果为大规模城市网络中的动力学预测提供了新的视角。', 'title_zh': '基于能量引导的图神经扩散预测大规模城市网络动态'}
{'arxiv_id': 'arXiv:2508.00028', 'title': 'Scalable Spectrum Availability Prediction using a Markov Chain Framework and ITU-R Propagation Models', 'authors': 'Abir Ray', 'link': 'https://arxiv.org/abs/2508.00028', 'abstract': 'Spectrum resources are often underutilized across time and space, motivating dynamic spectrum access strategies that allow secondary users to exploit unused frequencies. A key challenge is predicting when and where spectrum will be available (i.e., unused by primary licensed users) in order to enable proactive and interference-free access. This paper proposes a scalable framework for spectrum availability prediction that combines a two-state Markov chain model of primary user activity with high-fidelity propagation models from the ITU-R (specifically Recommendations P.528 and P.2108). The Markov chain captures temporal occupancy patterns, while the propagation models incorporate path loss and clutter effects to determine if primary signals exceed interference thresholds at secondary user locations. By integrating these components, the proposed method can predict spectrum opportunities both in time and space with improved accuracy. We develop the system model and algorithm for the approach, analyze its scalability and computational efficiency, and discuss assumptions, limitations, and potential applications. The framework is flexible and can be adapted to various frequency bands and scenarios. The results and analysis show that the proposed approach can effectively identify available spectrum with low computational cost, making it suitable for real-time spectrum management in cognitive radio networks and other dynamic spectrum sharing systems.', 'abstract_zh': '一种结合马尔可夫链模型和高保真传播模型的可扩展频谱可用性预测框架', 'title_zh': '基于马尔可夫链框架和ITU-R传播模型的可扩展频谱可用性预测'}
{'arxiv_id': 'arXiv:2508.00024', 'title': 'Embedding-Aware Quantum-Classical SVMs for Scalable Quantum Machine Learning', 'authors': 'Sebastián Andrés Cajas Ordóñez, Luis Fernando Torres Torres, Mario Bifulco, Carlos Andrés Durán, Cristian Bosch, Ricardo Simón Carbajo', 'link': 'https://arxiv.org/abs/2508.00024', 'abstract': 'Quantum Support Vector Machines face scalability challenges due to high-dimensional quantum states and hardware limitations. We propose an embedding-aware quantum-classical pipeline combining class-balanced k-means distillation with pretrained Vision Transformer embeddings. Our key finding: ViT embeddings uniquely enable quantum advantage, achieving up to 8.02% accuracy improvements over classical SVMs on Fashion-MNIST and 4.42% on MNIST, while CNN features show performance degradation. Using 16-qubit tensor network simulation via cuTensorNet, we provide the first systematic evidence that quantum kernel advantage depends critically on embedding choice, revealing fundamental synergy between transformer attention and quantum feature spaces. This provides a practical pathway for scalable quantum machine learning that leverages modern neural architectures.', 'abstract_zh': '量子支持向量机由于高维量子态和硬件限制面临可扩展性挑战。我们提出了一种嵌入感知的量子-经典管道，结合了类别均衡的k-means 降解与预训练的视觉变压器嵌入。我们的主要发现：视觉变压器嵌入独特地实现了量子优势，在Fashion-MNIST上相对于经典的SVMs取得了高达8.02%的准确率提升，在MNIST上取得了4.42%的提升，而CNN特征则表现退化。通过使用cuTensorNet进行16量子位张量网络模拟，我们提供了量子核优势依赖于嵌入选择的系统性证据，揭示了Transformer注意力机制与量子特征空间之间基本的协同作用。这为利用现代神经架构实现可扩展的量子机器学习提供了实际途径。', 'title_zh': '具备嵌入意识的量子-经典SVMs for可扩展的量子机器学习'}
{'arxiv_id': 'arXiv:2508.00017', 'title': 'Generative Logic: A New Computer Architecture for Deterministic Reasoning and Knowledge Generation', 'authors': 'Nikolai Sergeev', 'link': 'https://arxiv.org/abs/2508.00017', 'abstract': "We present Generative Logic (GL), a deterministic architecture that begins from user-supplied axiomatic definitions -- written in a minimalist Mathematical Programming Language (MPL) -- and systematically explores their deductive neighborhood. Definitions are compiled into a distributed grid of simple Logic Blocks (LBs) that exchange messages; any time several expressions unify under an inference rule, a new fact is emitted with full provenance to its sources, yielding replayable, auditable proof graphs.\nA prototype software implementation instantiates the workflow on first-order Peano arithmetic. Starting only from the Peano axioms, GL enumerates candidate implications, applies normalization and type filters, and automatically reconstructs machine-checkable proofs of foundational arithmetic laws including associativity and commutativity of addition, associativity and commutativity of multiplication, and distributivity. Generated proofs export to navigable HTML so that every inference step can be inspected independently.\nWe outline a hardware-software co-design path toward massively parallel realizations and describe prospective integration with probabilistic models (e.g., Large Language Models (LLMs)) for autoformalization and conjecture seeding. The Python and MPL code to reproduce the Peano experiments, along with the full HTML proof graphs, are available in the project's GitHub repository at this https URL and are permanently archived at this https URL. We invite community feedback and collaboration.", 'abstract_zh': '我们提出生成逻辑（GL），这是一种确定性的架构，从用户提供的公理定义出发——这些定义使用一种简约的数学编程语言（MPL）编写——并系统地探索它们的演绎邻域。定义被编译成一个分布式逻辑块网格，逻辑块之间互相交换信息；每当若干表达式在推理规则下统一时，会发出具有完整来源追溯的新事实，从而生成可重放和可审计的证明图。\n\n一个原型软件实现将在一阶皮亚诺算术上实例化工作流。仅从皮亚诺公理开始，GL 列举候选蕴含，应用规范化和类型过滤，并自动重建可机器验证的基础算术定律的证明，包括加法和乘法的结合律和交换律，以及分配律。生成的证明导出为可导航的HTML，使得每一推理步骤都可以独立检查。\n\n我们概述了一种硬件-软件协同设计途径，以实现大规模并行实现，并描述了与概率模型（例如，大型语言模型（LLMs））集成以实现自动形式化和猜想播种的前景。用于重现皮亚诺实验的Python和MPL代码以及完整的HTML证明图可以在该项目的GitHub仓库（此链接）中找到，并永久存档在另一个链接中。我们邀请社区反馈和合作。', 'title_zh': '生成逻辑：一种新的确定性推理和知识生成计算机架构'}
{'arxiv_id': 'arXiv:2508.00011', 'title': 'AoI-Aware Resource Allocation with Deep Reinforcement Learning for HAPS-V2X Networks', 'authors': 'Ahmet Melih Ince, Ayse Elif Canbilen, Halim Yanikomeroglu', 'link': 'https://arxiv.org/abs/2508.00011', 'abstract': 'Sixth-generation (6G) networks are designed to meet the hyper-reliable and low-latency communication (HRLLC) requirements of safety-critical applications such as autonomous driving. Integrating non-terrestrial networks (NTN) into the 6G infrastructure brings redundancy to the network, ensuring continuity of communications even under extreme conditions. In particular, high-altitude platform stations (HAPS) stand out for their wide coverage and low latency advantages, supporting communication reliability and enhancing information freshness, especially in rural areas and regions with infrastructure constraints. In this paper, we present reinforcement learning-based approaches using deep deterministic policy gradient (DDPG) to dynamically optimize the age-of-information (AoI) in HAPS-enabled vehicle-to-everything (V2X) networks. The proposed method improves information freshness and overall network reliability by enabling independent learning without centralized coordination. The findings reveal the potential of HAPS-supported solutions, combined with DDPG-based learning, for efficient AoI-aware resource allocation in platoon-based autonomous vehicle systems.', 'abstract_zh': 'sixth代（6G）网络设计用于满足自动驾驶等关键安全应用的超可靠低延迟通信（HRLLC）要求。将非地面网络（NTN）集成到6G基础设施中，为网络提供了冗余，确保在极端条件下通信的连续性。特别是高空平台站（HAPS）因其广泛的覆盖范围和低延迟优势，支持通信可靠性并提高信息新鲜度，特别是在农村地区和基础设施受限的地区。在本文中，我们提出了基于强化学习的方法，使用深确定性策略梯度（DDPG）动态优化HAPS使能的车联网（V2X）网络中的信息新鲜度（AoI）。所提出的方法通过实现独立学习而无需集中协调，提高了信息新鲜度和整体网络可靠性。研究结果表明，结合HAPS支持的解决方案和基于DDPG的学习，可以在基于车队的自动驾驶系统中实现高效的AoI感知资源分配。', 'title_zh': '基于AoI意识的资源分配与HAPS-V2X网络中的深度强化学习'}
{'arxiv_id': 'arXiv:2508.00009', 'title': 'Enabling Immersive XR Collaborations over FTTR Networks (Invited)', 'authors': 'Sourav Mondal, Elaine Wong', 'link': 'https://arxiv.org/abs/2508.00009', 'abstract': 'Fiber-To-The-Room is a potential solution to achieve in-premise extended reality collaborations. This paper explores predictive bandwidth allocation and seamless handover schemes over FTTR, showing high-quality immersive experience for in-premise collaborations can be achieved. \\c{opyright} 2025 The Author(s).', 'abstract_zh': '光纤到房间是实现室内扩展现实协作的一种潜在解决方案。本文探讨了在光纤到房间（FTTR）上实现预测带宽分配和无缝切换方案的可能性，展示了高质量的沉浸式体验可以在室内协作中实现。版权所有 2025 作者。', 'title_zh': '基于FTTR网络的沉浸式XR协作-enable.invited'}
{'arxiv_id': 'arXiv:2508.00005', 'title': 'Modelling Program Spaces in Program Synthesis with Constraints', 'authors': 'Tilman Hinnerichs, Bart Swinkels, Jaap de Jong, Reuben Gardos Reid, Tudor Magirescu, Neil Yorke-Smith, Sebastijan Dumancic', 'link': 'https://arxiv.org/abs/2508.00005', 'abstract': "A core challenge in program synthesis is taming the large space of possible programs. Since program synthesis is essentially a combinatorial search, the community has sought to leverage powerful combinatorial constraint solvers. Here, constraints are used to express the program semantics, but not as a potentially potent tool to remove unwanted programs. Recent inductive logic programming approaches introduce constraints on the program's syntax to be synthesized. These syntactic constraints allow for checking and propagating a constraint without executing the program, and thus for arbitrary operators. In this work, we leverage syntactic constraints to model program spaces, defining not just solutions that are feasible, but also ones that are likely useful. To demonstrate this idea, we introduce BART, a solver that efficiently propagates and solves these constraints. We evaluate BART on program space enumeration tasks, finding that the constraints eliminate up to 99 percent of the program space, and that modeling program spaces significantly reduces enumeration time.", 'abstract_zh': '程序合成的核心挑战是驾驭可能程序的庞大空间。由于程序合成本质上是一种组合搜索，社区寻求利用强大的组合约束求解器。最近，归纳逻辑编程方法通过在拟合程序的语法上引入约束，来表达程序语义。这些语法约束可以在不执行程序的情况下检查和传播约束，因此适用于任意操作符。在本文中，我们利用语法约束来建模程序空间，不仅定义可行的解决方案，还定义可能有用的解决方案。为了展示这一思路，我们引入了BART，一种高效传播和求解这些约束的求解器。我们在程序空间枚举任务上评估了BART，发现约束可以消除高达99%的程序空间，并且建模程序空间显著减少了枚举时间。', 'title_zh': '基于约束条件下程序空间建模在程序综合中的应用'}
{'arxiv_id': 'arXiv:2507.23585', 'title': 'Agency Among Agents: Designing with Hypertextual Friction in the Algorithmic Web', 'authors': 'Sophia Liu, Shm Garanganao Almeda', 'link': 'https://arxiv.org/abs/2507.23585', 'abstract': 'Today\'s algorithm-driven interfaces, from recommendation feeds to GenAI tools, often prioritize engagement and efficiency at the expense of user agency. As systems take on more decision-making, users have less control over what they see and how meaning or relationships between content are constructed. This paper introduces "Hypertextual Friction," a conceptual design stance that repositions classical hypertext principles--friction, traceability, and structure--as actionable values for reclaiming agency in algorithmically mediated environments. Through a comparative analysis of real-world interfaces--Wikipedia vs. Instagram Explore, and this http URL vs. GenAI image tools--we examine how different systems structure user experience, navigation, and authorship. We show that hypertext systems emphasize provenance, associative thinking, and user-driven meaning-making, while algorithmic systems tend to obscure process and flatten participation. We contribute: (1) a comparative analysis of how interface structures shape agency in user-driven versus agent-driven systems, and (2) a conceptual stance that offers hypertextual values as design commitments for reclaiming agency in an increasingly algorithmic web.', 'abstract_zh': '今天的算法驱动接口，从推荐流到生成式人工智能工具，往往在牺牲用户自主权的情况下优先考虑参与度和效率。随着系统承担更多的决策任务，用户对所见内容及其与内容之间意义和关系的构建失去了更多的控制权。本文提出了“超文本摩擦”这一概念设计立场，将经典超文本原理——摩擦、可跟踪性和结构——重新定位为在算法中介环境中重新获得自主权的可操作价值观。通过将现实世界的接口进行对比分析——Wikipedia与Instagram Explore，以及This URL与生成式人工智能图像工具，我们探讨了不同系统如何构建用户体验、导航和内容创作。我们表明，超文本系统强调出处、联想思维和用户驱动的意义创造，而算法系统往往掩盖过程并削弱参与。我们贡献了：(1) 对接口结构如何影响用户驱动系统与代理驱动系统中自主权的一种比较分析，(2) 一种概念立场，提出了超文本价值观作为在日益算法化的网络中重新获得自主权的设计承诺。', 'title_zh': '代理间的代理：在算法网络中设计超文本摩擦'}
