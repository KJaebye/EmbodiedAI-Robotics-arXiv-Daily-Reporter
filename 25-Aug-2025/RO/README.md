# Hierarchical Decision-Making for Autonomous Navigation: Integrating Deep Reinforcement Learning and Fuzzy Logic in Four-Wheel Independent Steering and Driving Systems 

**Title (ZH)**: 基于层次决策的自主导航：四轮独立转向与驱动系统中深度强化学习与模糊逻辑的集成 

**Authors**: Yizhi Wang, Degang Xu, Yongfang Xie, Shuzhong Tan, Xianan Zhou, Peng Chen  

**Link**: [PDF](https://arxiv.org/pdf/2508.16574)  

**Abstract**: This paper presents a hierarchical decision-making framework for autonomous navigation in four-wheel independent steering and driving (4WISD) systems. The proposed approach integrates deep reinforcement learning (DRL) for high-level navigation with fuzzy logic for low-level control to ensure both task performance and physical feasibility. The DRL agent generates global motion commands, while the fuzzy logic controller enforces kinematic constraints to prevent mechanical strain and wheel slippage. Simulation experiments demonstrate that the proposed framework outperforms traditional navigation methods, offering enhanced training efficiency and stability and mitigating erratic behaviors compared to purely DRL-based solutions. Real-world validations further confirm the framework's ability to navigate safely and effectively in dynamic industrial settings. Overall, this work provides a scalable and reliable solution for deploying 4WISD mobile robots in complex, real-world scenarios. 

**Abstract (ZH)**: 本文提出了一种分层决策框架，用于四轮独立转向与驱动（4WISD）系统的自主导航。该提出的办法将深度强化学习（DRL）用于高层导航与模糊逻辑用于低层控制相结合，以确保任务性能和物理可行性。DRL代理生成全局运动指令，而模糊逻辑控制器则施加运动学约束，以防止机械应力和车轮打滑。仿真实验表明，所提出的框架优于传统的导航方法，提供了增强的训练效率和稳定性，并且比纯粹基于DRL的解决方案更有效地减轻了行为不确定性。实地验证进一步证实了该框架能够安全有效地在动态工业环境中导航。总体而言，本文为部署4WISD移动机器人到复杂的真实世界场景提供了可扩展且可靠的解决方案。 

---
# Comparative Analysis of UAV Path Planning Algorithms for Efficient Navigation in Urban 3D Environments 

**Title (ZH)**: 无人机路径规划算法在城市三维环境高效导航中的 comparative analysis 

**Authors**: Hichem Cheriet, Khellat Kihel Badra, Chouraqui Samira  

**Link**: [PDF](https://arxiv.org/pdf/2508.16515)  

**Abstract**: The most crucial challenges for UAVs are planning paths and avoiding obstacles in their way. In recent years, a wide variety of path-planning algorithms have been developed. These algorithms have successfully solved path-planning problems; however, they suffer from multiple challenges and limitations. To test the effectiveness and efficiency of three widely used algorithms, namely A*, RRT*, and Particle Swarm Optimization (PSO), this paper conducts extensive experiments in 3D urban city environments cluttered with obstacles. Three experiments were designed with two scenarios each to test the aforementioned algorithms. These experiments consider different city map sizes, different altitudes, and varying obstacle densities and sizes in the environment. According to the experimental results, the A* algorithm outperforms the others in both computation efficiency and path quality. PSO is especially suitable for tight turns and dense environments, and RRT* offers a balance and works well across all experiments due to its randomized approach to finding solutions. 

**Abstract (ZH)**: 无人机面临的最关键挑战是规划路径和避开途中的障碍物。近年来，开发了多种路径规划算法。尽管这些算法成功解决了路径规划问题，但仍面临多种挑战和限制。为了测试三种广泛使用的算法（A*、RRT*和粒子 swarm 优化（PSO））的有效性和效率，本文在充满障碍物的3D城市环境中进行了广泛实验。设计了三项实验，每项实验包含两种场景，用于测试上述算法。实验考虑了不同的城市地图大小、不同的海拔高度以及环境中的不同障碍密度和大小。根据实验结果，A*算法在计算效率和路径质量上均优于其他算法。PSO特别适合于狭窄转弯和密集环境，而RRT*由于其求解的随机化方法，在所有实验中表现出良好的平衡性能。 

---
# On Kinodynamic Global Planning in a Simplicial Complex Environment: A Mixed Integer Approach 

**Title (ZH)**: 在单纯复环境中基于混合整数规划的运动动力学全局路径规划 

**Authors**: Otobong Jerome, Alexandr Klimchik, Alexander Maloletov, Geesara Kulathunga  

**Link**: [PDF](https://arxiv.org/pdf/2508.16511)  

**Abstract**: This work casts the kinodynamic planning problem for car-like vehicles as an optimization task to compute a minimum-time trajectory and its associated velocity profile, subject to boundary conditions on velocity, acceleration, and steering. The approach simultaneously optimizes both the spatial path and the sequence of acceleration and steering controls, ensuring continuous motion from a specified initial position and velocity to a target end position and this http URL method analyzes the admissible control space and terrain to avoid local minima. The proposed method operates efficiently in simplicial complex environments, a preferred terrain representation for capturing intricate 3D landscapes. The problem is initially posed as a mixed-integer fractional program with quadratic constraints, which is then reformulated into a mixed-integer bilinear objective through a variable transformation and subsequently relaxed to a mixed-integer linear program using McCormick envelopes. Comparative simulations against planners such as MPPI and log-MPPI demonstrate that the proposed approach generates solutions 104 times faster while strictly adhering to the specified constraints 

**Abstract (ZH)**: 本文将汽车类车辆的运动规划问题 cast 为最优化任务，以计算最小时间轨迹及其相应的速度分布，并满足速度、加速度和转向的边界条件。该方法同时优化空间路径和加速度、转向控制序列，确保从指定的起始位置和速度连续运动到目标终点位置和速度。该方法分析可选控制空间和地形以避免局部最小值。所提方法高效地应用于单纯形复杂环境，这是捕捉复杂三维地形的首选地形表示。问题最初被表述为带二次约束的混合整数分式规划问题，然后通过变量变换重新表述为混合整数双线性目标问题，并通过 McCormick 包封进一步松弛为混合整数线性规划问题。与 MPPI 和 log-MPPI 等规划器的比较模拟表明，所提方法在严格遵守指定约束的情况下，生成解决方案的速度快了 104 倍。 

---
# Terrain Classification for the Spot Quadrupedal Mobile Robot Using Only Proprioceptive Sensing 

**Title (ZH)**: 基于 proprioceptive 感知的 Spot 八足移动机器人地形分类 

**Authors**: Sophie Villemure, Jefferson Silveira, Joshua A. Marshall  

**Link**: [PDF](https://arxiv.org/pdf/2508.16504)  

**Abstract**: Quadrupedal mobile robots can traverse a wider range of terrain types than their wheeled counterparts but do not perform the same on all terrain types. These robots are prone to undesirable behaviours like sinking and slipping on challenging terrains. To combat this issue, we propose a terrain classifier that provides information on terrain type that can be used in robotic systems to create a traversability map to plan safer paths for the robot to navigate. The work presented here is a terrain classifier developed for a Boston Dynamics Spot robot. Spot provides over 100 measured proprioceptive signals describing the motions of the robot and its four legs (e.g., foot penetration, forces, joint angles, etc.). The developed terrain classifier combines dimensionality reduction techniques to extract relevant information from the signals and then applies a classification technique to differentiate terrain based on traversability. In representative field testing, the resulting terrain classifier was able to identify three different terrain types with an accuracy of approximately 97% 

**Abstract (ZH)**: 四足移动机器人能够跨越比轮式机器人更广泛的地形类型，但在所有地形类型上的表现不尽相同。这些机器人在挑战性地形上可能出现下沉和打滑等不良行为。为应对这一问题，我们提出了一种地形分类器，该分类器可以提供地形类型信息，用于机器人系统创建可通行性地图，以规划机器人导航的安全路径。本文展示的工作是专门为Boston Dynamics Spot机器人开发的一种地形分类器。Spot提供了超过100个测得的 proprioceptive 信号，描述了机器人的运动及其四条腿（如脚的穿透力、力、关节角度等）。所开发的地形分类器结合了降维技术以提取信号中的相关信息，然后应用分类技术根据可通行性对地形进行区分。在代表性实地测试中，该地形分类器能够识别三种不同地形类型，准确率约为97%。 

---
# Swarming Without an Anchor (SWA): Robot Swarms Adapt Better to Localization Dropouts Then a Single Robot 

**Title (ZH)**: 无需锚点的群集算法：机器人 swarm 比单个机器人更能适应定位丢失的情况 

**Authors**: Jiri Horyna, Roland Jung, Stephan Weiss, Eliseo Ferrante, Martin Saska  

**Link**: [PDF](https://arxiv.org/pdf/2508.16460)  

**Abstract**: In this paper, we present the Swarming Without an Anchor (SWA) approach to state estimation in swarms of Unmanned Aerial Vehicles (UAVs) experiencing ego-localization dropout, where individual agents are laterally stabilized using relative information only. We propose to fuse decentralized state estimation with robust mutual perception and onboard sensor data to maintain accurate state awareness despite intermittent localization failures. Thus, the relative information used to estimate the lateral state of UAVs enables the identification of the unambiguous state of UAVs with respect to the local constellation. The resulting behavior reaches velocity consensus, as this task can be referred to as the double integrator synchronization problem. All disturbances and performance degradations except a uniform translation drift of the swarm as a whole is attenuated which is enabling new opportunities in using tight cooperation for increasing reliability and resilience of multi-UAV systems. Simulations and real-world experiments validate the effectiveness of our approach, demonstrating its capability to sustain cohesive swarm behavior in challenging conditions of unreliable or unavailable primary localization. 

**Abstract (ZH)**: 无锚点的群集状态估计方法（SWA）：无人机群在自我定位丢失情况下的横向稳定与状态估计 

---
# GPL-SLAM: A Laser SLAM Framework with Gaussian Process Based Extended Landmarks 

**Title (ZH)**: GPL-SLAM: 基于高斯过程扩展地标的一种激光SLAM框架 

**Authors**: Ali Emre Balcı, Erhan Ege Keyvan, Emre Özkan  

**Link**: [PDF](https://arxiv.org/pdf/2508.16459)  

**Abstract**: We present a novel Simultaneous Localization and Mapping (SLAM) method that employs Gaussian Process (GP) based landmark (object) representations. Instead of conventional grid maps or point cloud registration, we model the environment on a per object basis using GP based contour representations. These contours are updated online through a recursive scheme, enabling efficient memory usage. The SLAM problem is formulated within a fully Bayesian framework, allowing joint inference over the robot pose and object based map. This representation provides semantic information such as the number of objects and their areas, while also supporting probabilistic measurement to object associations. Furthermore, the GP based contours yield confidence bounds on object shapes, offering valuable information for downstream tasks like safe navigation and exploration. We validate our method on synthetic and real world experiments, and show that it delivers accurate localization and mapping performance across diverse structured environments. 

**Abstract (ZH)**: 基于高斯过程的物体表示的同时定位与mapping方法 

---
# Take That for Me: Multimodal Exophora Resolution with Interactive Questioning for Ambiguous Out-of-View Instructions 

**Title (ZH)**: 帮我完成这项任务：具有互动式提问的多模态异端消解，用于模糊的离视指示对象处理 

**Authors**: Akira Oyama, Shoichi Hasegawa, Akira Taniguchi, Yoshinobu Hagiwara, Tadahiro Taniguchi  

**Link**: [PDF](https://arxiv.org/pdf/2508.16143)  

**Abstract**: Daily life support robots must interpret ambiguous verbal instructions involving demonstratives such as ``Bring me that cup,'' even when objects or users are out of the robot's view. Existing approaches to exophora resolution primarily rely on visual data and thus fail in real-world scenarios where the object or user is not visible. We propose Multimodal Interactive Exophora resolution with user Localization (MIEL), which is a multimodal exophora resolution framework leveraging sound source localization (SSL), semantic mapping, visual-language models (VLMs), and interactive questioning with GPT-4o. Our approach first constructs a semantic map of the environment and estimates candidate objects from a linguistic query with the user's skeletal data. SSL is utilized to orient the robot toward users who are initially outside its visual field, enabling accurate identification of user gestures and pointing directions. When ambiguities remain, the robot proactively interacts with the user, employing GPT-4o to formulate clarifying questions. Experiments in a real-world environment showed results that were approximately 1.3 times better when the user was visible to the robot and 2.0 times better when the user was not visible to the robot, compared to the methods without SSL and interactive questioning. The project website is this https URL. 

**Abstract (ZH)**: 日常生活的机器人必须解释涉及指示代词（如“ Bring me that cup”）的模糊口头指令，即使对象或用户超出机器人的视角范围。现有的外指消解方法主要依赖于视觉数据，在物体或用户不可见的真实世界场景中会失效。我们提出了多模态交互外指消解与用户定位（MIEL）框架，该框架结合了声音源定位（SSL）、语义地图构建、视觉-语言模型（VLMs）和与GPT-4o的互动询问。我们的方法首先根据用户的骨架数据构建环境语义地图，并从语言查询中估计候选目标物体。声音源定位用于使机器人朝向初始不在其视域的用户，从而实现用户手势和指示方向的准确识别。当存在歧义时，机器人主动与用户交互，使用GPT-4o提出澄清问题。在真实环境中的实验表明，当用户对机器人可见时，我们的方法结果大约提高了1.3倍，而当用户对机器人不可见时，结果提高了2.0倍，相比没有声音源定位和互动询问的方法。项目网站：<https://www.example.com>。 

---
# Self-Aligning EPM Connector: A Versatile Solution for Adaptive and Multi-Modal Interfaces 

**Title (ZH)**: 自对齐EPM连接器：一种适应性和多模态接口的通用解决方案 

**Authors**: Bingchao Wang, Adam A. Stokes  

**Link**: [PDF](https://arxiv.org/pdf/2508.16008)  

**Abstract**: This paper presents a multifunctional connector based on electro-permanent magnet (EPM) technology, integrating self-alignment, mechanical coupling, fluid transfer, and data communication within a compact SLA-3D printed structure. Experimental results demonstrate reliable self-alignment, efficient fluid transfer in single-loop and dual-channel modes, and robust data transmission via integrated electronic control. The connector exhibits high flexibility in accommodating axial, angular, and lateral misalignments while maintaining low energy consumption. These features make it highly suitable for modular robotics, electric vehicle charging, household robotic platforms, and aerospace docking applications. 

**Abstract (ZH)**: 基于电永磁技术的多功能连接器及其在模块化机器人、电动汽车充电、家庭机器人平台和航空航天对接应用中的集成设计与实验研究 

---
# GelSLAM: A Real-time, High-Fidelity, and Robust 3D Tactile SLAM System 

**Title (ZH)**: GelSLAM：一种实时、高保真且鲁棒的3D触觉SLAM系统 

**Authors**: Hung-Jui Huang, Mohammad Amin Mirzaee, Michael Kaess, Wenzhen Yuan  

**Link**: [PDF](https://arxiv.org/pdf/2508.15990)  

**Abstract**: Accurately perceiving an object's pose and shape is essential for precise grasping and manipulation. Compared to common vision-based methods, tactile sensing offers advantages in precision and immunity to occlusion when tracking and reconstructing objects in contact. This makes it particularly valuable for in-hand and other high-precision manipulation tasks. In this work, we present GelSLAM, a real-time 3D SLAM system that relies solely on tactile sensing to estimate object pose over long periods and reconstruct object shapes with high fidelity. Unlike traditional point cloud-based approaches, GelSLAM uses tactile-derived surface normals and curvatures for robust tracking and loop closure. It can track object motion in real time with low error and minimal drift, and reconstruct shapes with submillimeter accuracy, even for low-texture objects such as wooden tools. GelSLAM extends tactile sensing beyond local contact to enable global, long-horizon spatial perception, and we believe it will serve as a foundation for many precise manipulation tasks involving interaction with objects in hand. The video demo is available on our website: this https URL. 

**Abstract (ZH)**: 准确感知物体的姿态和形状对于精确抓取和操作至关重要。与常见的基于视觉的方法相比，触觉传感在追踪和重构接触中物体时，在精度和对遮挡的免疫性方面具有优势，这使其特别适用于手部和其他高精度操作任务。在此项工作中，我们提出了一种名为GelSLAM的实时3D SLAM系统，该系统仅依赖触觉传感来长时间估计物体姿态并以高度保真度重构物体形状。与传统的基于点云的方法不同，GelSLAM使用触觉衍生的表面法线和曲率进行鲁棒跟踪和回环闭合。它可以实时低误差且低漂移地跟踪物体运动，并且即使对于低纹理物体（如木制工具），也能以亚毫米级精度重构形状。GelSLAM将触觉传感扩展到局部接触之外，以实现全局、长视程的空间感知，我们认为它将成为许多涉及手部与物体交互的精确操作任务的基础。更多内容请参见我们的网站：this https URL。 

---
# UnPose: Uncertainty-Guided Diffusion Priors for Zero-Shot Pose Estimation 

**Title (ZH)**: UnPose：面向零样本姿态估计的不确定性引导扩散先验 

**Authors**: Zhaodong Jiang, Ashish Sinha, Tongtong Cao, Yuan Ren, Bingbing Liu, Binbin Xu  

**Link**: [PDF](https://arxiv.org/pdf/2508.15972)  

**Abstract**: Estimating the 6D pose of novel objects is a fundamental yet challenging problem in robotics, often relying on access to object CAD models. However, acquiring such models can be costly and impractical. Recent approaches aim to bypass this requirement by leveraging strong priors from foundation models to reconstruct objects from single or multi-view images, but typically require additional training or produce hallucinated geometry. To this end, we propose UnPose, a novel framework for zero-shot, model-free 6D object pose estimation and reconstruction that exploits 3D priors and uncertainty estimates from a pre-trained diffusion model. Specifically, starting from a single-view RGB-D frame, UnPose uses a multi-view diffusion model to estimate an initial 3D model using 3D Gaussian Splatting (3DGS) representation, along with pixel-wise epistemic uncertainty estimates. As additional observations become available, we incrementally refine the 3DGS model by fusing new views guided by the diffusion model's uncertainty, thereby continuously improving the pose estimation accuracy and 3D reconstruction quality. To ensure global consistency, the diffusion prior-generated views and subsequent observations are further integrated in a pose graph and jointly optimized into a coherent 3DGS field. Extensive experiments demonstrate that UnPose significantly outperforms existing approaches in both 6D pose estimation accuracy and 3D reconstruction quality. We further showcase its practical applicability in real-world robotic manipulation tasks. 

**Abstract (ZH)**: 无模型六自由度物体姿态估计与重建 

---
# Spatial Policy: Guiding Visuomotor Robotic Manipulation with Spatial-Aware Modeling and Reasoning 

**Title (ZH)**: 空间政策：基于空间 Awareness 模型与推理的visuomotor机器人操纵指导 

**Authors**: Yijun Liu, Yuwei Liu, Yuan Meng, Jieheng Zhang, Yuwei Zhou, Ye Li, Jiacheng Jiang, Kangye Ji, Shijia Ge, Zhi Wang, Wenwu Zhu  

**Link**: [PDF](https://arxiv.org/pdf/2508.15874)  

**Abstract**: Vision-centric hierarchical embodied models have demonstrated strong potential for long-horizon robotic control. However, existing methods lack spatial awareness capabilities, limiting their effectiveness in bridging visual plans to actionable control in complex environments. To address this problem, we propose Spatial Policy (SP), a unified spatial-aware visuomotor robotic manipulation framework via explicit spatial modeling and reasoning. Specifically, we first design a spatial-conditioned embodied video generation module to model spatially guided predictions through a spatial plan table. Then, we propose a spatial-based action prediction module to infer executable actions with coordination. Finally, we propose a spatial reasoning feedback policy to refine the spatial plan table via dual-stage replanning. Extensive experiments show that SP significantly outperforms state-of-the-art baselines, achieving a 33.0% average improvement over the best baseline. With an 86.7% average success rate across 11 diverse tasks, SP substantially enhances the practicality of embodied models for robotic control applications. Code and checkpoints are maintained at this https URL. 

**Abstract (ZH)**: 基于视觉的层级体态模型在长时序机器人控制中展现了强大的潜力。然而，现有方法缺乏空间感知能力，限制了其在复杂环境中将视觉计划转化为可执行控制的有效性。为解决这一问题，我们提出了一种统一的空间感知视觉-运动机器人操作框架Spatial Policy (SP)，通过显式的空间建模与推理实现。具体而言，我们首先设计了一个空间条件下的体态视频生成模块，通过空间计划表来建模空间引导的预测。然后，我们提出了一种基于空间的动作预测模块，以实现协调的动作推测。最后，我们提出了一种空间推理反馈策略，通过双重规划细化空间计划表。大量实验表明，SP 显著优于现有基线方法，相对于最佳基线方法平均提升33.0%。在11个不同任务上，SP 的平均成功率高达86.7%，显著增强了体态模型在机器人控制应用中的实用性。相关代码和检查点维护于此[此链接]。 

---
# HOSt3R: Keypoint-free Hand-Object 3D Reconstruction from RGB images 

**Title (ZH)**: HOSt3R：基于RGB图像的手物三维重建（无关键点） 

**Authors**: Anilkumar Swamy, Vincent Leroy, Philippe Weinzaepfel, Jean-Sébastien Franco, Grégory Rogez  

**Link**: [PDF](https://arxiv.org/pdf/2508.16465)  

**Abstract**: Hand-object 3D reconstruction has become increasingly important for applications in human-robot interaction and immersive AR/VR experiences. A common approach for object-agnostic hand-object reconstruction from RGB sequences involves a two-stage pipeline: hand-object 3D tracking followed by multi-view 3D reconstruction. However, existing methods rely on keypoint detection techniques, such as Structure from Motion (SfM) and hand-keypoint optimization, which struggle with diverse object geometries, weak textures, and mutual hand-object occlusions, limiting scalability and generalization. As a key enabler to generic and seamless, non-intrusive applicability, we propose in this work a robust, keypoint detector-free approach to estimating hand-object 3D transformations from monocular motion video/images. We further integrate this with a multi-view reconstruction pipeline to accurately recover hand-object 3D shape. Our method, named HOSt3R, is unconstrained, does not rely on pre-scanned object templates or camera intrinsics, and reaches state-of-the-art performance for the tasks of object-agnostic hand-object 3D transformation and shape estimation on the SHOWMe benchmark. We also experiment on sequences from the HO3D dataset, demonstrating generalization to unseen object categories. 

**Abstract (ZH)**: 基于单目运动视频/图像的手物3D变换估计方法HOSt3R 

---
# Sound and Solution-Complete CCBS 

**Title (ZH)**: 声学与解完备CCBS 

**Authors**: Alvin Combrink, Sabino Francesco Roselli, Martin Fabian  

**Link**: [PDF](https://arxiv.org/pdf/2508.16410)  

**Abstract**: Continuous-time Conflict Based-Search (CCBS) has long been viewed as the de-facto optimal solver for multi-agent path finding in continuous time (MAPFR). Recent findings, however, show that the original theoretical variant of CCBS can suffer from non-termination, while the widely used implementation can return sub-optimal solutions. We introduce an analytical framework that yields simple and sufficient conditions under which any CCBS-style algorithm is both sound, i.e., returns only optimal solutions, and solution complete, i.e., terminates on every solvable MAPFR instance. Investigating the publicly available implementation of CCBS reveals that it violates these conditions. Though this merely indicates that CCBS might be unsound, this indication is supported by counter-examples.
Leveraging the analytical framework, we propose a novel branching rule and prove that it satisfies the sufficient conditions, thereby restoring soundness and termination guarantees. Consequently, the resulting CCBS variant is both sound and solution complete, matching the guarantees of the discrete-time CBS for the first time in the continuous domain. We experimentally apply standard CCBS and CCBS under our branching rule to an example problem, with our branching rule returning a solution with lower sum-of-costs than standard CCBS. Because the branching rule largely only affects the branching step, it can be adopted as a drop-in replacement in existing code-bases, as we show in our provided implementation. Beyond CCBS, the analytical framework and termination criterion provide a systematic way to evaluate other CCBS-like MAPFR solvers and future extensions. 

**Abstract (ZH)**: 连续时间冲突基于搜索（CCBS）一直在连续时间多Agent路径寻找（MAPFR）问题中被视为实际上的最优求解器。然而，最新研究发现，原始的理论变体CCBS可能无法终止，而广泛使用的实现则可能会返回次优解。我们提出了一种分析框架，从而为任何CCBS风格的算法提供了简单且充分的条件，使其既能保证正确性，即仅返回最优解，又能保证完备性，即在每一个可解的MAPFR实例上都能终止。通过对公开的CCBS实现进行调查，我们发现它违反了这些条件。尽管这仅表明CCBS可能是不正确的，这一结论也由反例支持。借助分析框架，我们提出了一个新的分支规则，并证明该规则满足充分条件，从而恢复了正确性和终止性保证。因此，由此衍生的CCBS变体在连续域中首次与离散时间CBS的保证相匹配，既确保正确性又确保完备性。实验结果显示，在我们的分支规则下应用标准CCBS和CCBS，能够获得较低总成本的解。由于分支规则主要影响分支步骤，因此可以在现有的代码库中直接替换使用，正如我们提供的实现所示。除了CCBS之外，分析框架和终止准则还为评估其他CCBS类MAPFR求解器及其未来扩展提供了一种系统性方法。 

---
# Do What? Teaching Vision-Language-Action Models to Reject the Impossible 

**Title (ZH)**: 教什么？训练视觉-语言-动作模型拒绝不可能的动作。 

**Authors**: Wen-Han Hsieh, Elvis Hsieh, Dantong Niu, Trevor Darrell, Roei Herzig, David M. Chan  

**Link**: [PDF](https://arxiv.org/pdf/2508.16292)  

**Abstract**: Recently, Vision-Language-Action (VLA) models have demonstrated strong performance on a range of robotic tasks. These models rely on multimodal inputs, with language instructions playing a crucial role -- not only in predicting actions, but also in robustly interpreting user intent, even when the requests are impossible to fulfill. In this work, we investigate how VLAs can recognize, interpret, and respond to false-premise instructions: natural language commands that reference objects or conditions absent from the environment. We propose Instruct-Verify-and-Act (IVA), a unified framework that (i) detects when an instruction cannot be executed due to a false premise, (ii) engages in language-based clarification or correction, and (iii) grounds plausible alternatives in perception and action. Towards this end, we construct a large-scale instruction tuning setup with structured language prompts and train a VLA model capable of handling both accurate and erroneous requests. Our approach leverages a contextually augmented, semi-synthetic dataset containing paired positive and false-premise instructions, enabling robust detection and natural language correction. Our experiments show that IVA improves false premise detection accuracy by 97.56% over baselines, while increasing successful responses in false-premise scenarios by 50.78%. 

**Abstract (ZH)**: 近期，视觉-语言-行动（VLA）模型在一系列机器人任务中展现了强大的性能。这些模型依赖多模态输入，其中语言指令在预测行动的同时，还起着准确解释用户意图的关键作用，即使请求无法实现也是如此。在本文中，我们研究了VLA如何识别、解释和响应虚假前提指令：自然语言命令中提到的环境不存在的对象或条件。我们提出了一种统一框架Instruct-Verify-and-Act（IVA），该框架包括：（i）检测由于虚假前提导致无法执行指令的情形；（ii）进行语言澄清或纠正；（iii）基于感知和行动提供合理的替代方案。为此，我们构建了一个大规模指令调整设置，使用结构化语言提示进行训练，以处理准确和错误请求。我们的方法利用了一个上下文增强的半合成数据集，包含匹配的正确前提和虚假前提指令，从而实现稳健的检测和自然语言纠正。我们的实验表明，与基线相比，IVA将虚假前提检测准确性提高了97.56%，并在虚假前提情境中成功响应提高了50.78%。 

---
# Validating Terrain Models in Digital Twins for Trustworthy sUAS Operations 

**Title (ZH)**: 在数字孪生中验证地形模型以实现可靠的无人驾驶航空系统运营 

**Authors**: Arturo Miguel Russell Bernal, Maureen Petterson, Pedro Antonio Alarcon Granadeno, Michael Murphy, James Mason, Jane Cleland-Huang  

**Link**: [PDF](https://arxiv.org/pdf/2508.16104)  

**Abstract**: With the increasing deployment of small Unmanned Aircraft Systems (sUAS) in unfamiliar and complex environments, Environmental Digital Twins (EDT) that comprise weather, airspace, and terrain data are critical for safe flight planning and for maintaining appropriate altitudes during search and surveillance operations. With the expansion of sUAS capabilities through edge and cloud computing, accurate EDT are also vital for advanced sUAS capabilities, like geolocation. However, real-world sUAS deployment introduces significant sources of uncertainty, necessitating a robust validation process for EDT components. This paper focuses on the validation of terrain models, one of the key components of an EDT, for real-world sUAS tasks. These models are constructed by fusing U.S. Geological Survey (USGS) datasets and satellite imagery, incorporating high-resolution environmental data to support mission tasks. Validating both the terrain models and their operational use by sUAS under real-world conditions presents significant challenges, including limited data granularity, terrain discontinuities, GPS and sensor inaccuracies, visual detection uncertainties, as well as onboard resources and timing constraints. We propose a 3-Dimensions validation process grounded in software engineering principles, following a workflow across granularity of tests, simulation to real world, and the analysis of simple to edge conditions. We demonstrate our approach using a multi-sUAS platform equipped with a Terrain-Aware Digital Shadow. 

**Abstract (ZH)**: 随着小型无人驾驶航空系统（sUAS）在陌生和复杂环境中的部署增加，集成了气象、空域和地形数据的环境数字 twinning（EDT）对于安全飞行规划以及搜索和监视操作中维持适当高度至关重要。通过边缘和云计算扩展sUAS能力后，准确的EDT也是实现地理定位等高级sUAS功能的关键。然而，实际部署sUAS引入了显著的不确定性来源，需要针对EDT组件制定稳健的验证流程。本文重点关注在实际sUAS任务中验证地形模型，这是EDT的关键组成部分之一。这些模型通过融合美国地质调查局（USGS）数据集和卫星图像构建，加入高分辨率环境数据以支持任务需求。在实际条件下验证地形模型及其在sUAS操作中的应用面临诸多挑战，包括数据粒度有限、地形不连续性、GPS和传感器不准确、视觉检测不确定性，以及机载资源和时间限制。我们提出了一种基于软件工程原则的三维验证过程，该过程遵循从粒度测试、模拟到现实世界的流程，并分析从简单到边缘条件。我们通过装备有地形感知数字阴影的多sUAS平台展示了该方法。 

---
# NeuralMeshing: Complete Object Mesh Extraction from Casual Captures 

**Title (ZH)**: 神经网格化：从随意拍摄中提取完整对象网格 

**Authors**: Floris Erich, Naoya Chiba, Abdullah Mustafa, Ryo Hanai, Noriaki Ando, Yusuke Yoshiyasu, Yukiyasu Domae  

**Link**: [PDF](https://arxiv.org/pdf/2508.16026)  

**Abstract**: How can we extract complete geometric models of objects that we encounter in our daily life, without having access to commercial 3D scanners? In this paper we present an automated system for generating geometric models of objects from two or more videos. Our system requires the specification of one known point in at least one frame of each video, which can be automatically determined using a fiducial marker such as a checkerboard or Augmented Reality (AR) marker. The remaining frames are automatically positioned in world space by using Structure-from-Motion techniques. By using multiple videos and merging results, a complete object mesh can be generated, without having to rely on hole filling. Code for our system is available from this https URL. 

**Abstract (ZH)**: 如何在没有访问商业3D扫描器的情况下提取我们日常生活中遇到的物体的完整几何模型？在本文中，我们提出了一种从两段或多段视频生成物体几何模型的自动化系统。该系统要求在每个视频的至少一帧中指定一个已知点，该点可以使用棋盘格或增强现实（AR）标志等标记物自动确定。剩下的帧通过使用结构恢复运动技术自动定位到世界空间。通过使用多段视频并合并结果，可以生成完整的物体网格，而不需要依赖孔填充。我们的系统代码可以从以下网址获取：this https URL。 

---
# Active Prostate Phantom with Multiple Chambers 

**Title (ZH)**: 多腔室活性前列腺模拟器 

**Authors**: Sizhe Tian, Yinoussa Adagolodjo, Jeremie Dequidt  

**Link**: [PDF](https://arxiv.org/pdf/2508.15873)  

**Abstract**: Prostate cancer is a major global health concern, requiring advancements in robotic surgery and diagnostics to improve patient outcomes. A phantom is a specially designed object that simulates human tissues or organs. It can be used for calibrating and testing a medical process, as well as for training and research purposes. Existing prostate phantoms fail to simulate dynamic scenarios. This paper presents a pneumatically actuated prostate phantom with multiple independently controlled chambers, allowing for precise volumetric adjustments to replicate asymmetric and symmetric benign prostatic hyperplasia (BPH). The phantom is designed based on shape analysis of magnetic resonance imaging (MRI) datasets, modeled with finite element method (FEM), and validated through 3D reconstruction. The simulation results showed strong agreement with physical measurements, achieving average errors of 3.47% in forward modeling and 1.41% in inverse modeling. These results demonstrate the phantom's potential as a platform for validating robotic-assisted systems and for further development toward realistic simulation-based medical training. 

**Abstract (ZH)**: 前列腺癌是全球重大健康问题，需要在机器人手术和诊断方面取得进展以改善患者预后。这是一个特别设计的对象，用于模拟人类组织或器官。它可以用于校准和测试医疗过程，以及培训和研究目的。现有的前列腺模拟器无法模拟动态场景。本文提出了一种由多个独立控制腔室驱动的气动前列腺模拟器，允许精确的体积调整以模拟不对称性和对称性良性前列腺增生（BPH）。该模拟器基于磁共振成像（MRI）数据集的形状分析设计，使用有限元法（FEM）建模，并通过3D重建进行验证。仿真结果与物理测量结果高度一致，前向建模平均误差为3.47%，逆向建模平均误差为1.41%。这些结果表明该模拟器有潜力作为验证辅助机器人系统和进一步发展基于仿真医学培训的现实模拟平台。 

---
