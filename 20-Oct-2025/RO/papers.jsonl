{'arxiv_id': 'arXiv:2510.15803', 'title': 'Dynamic Recalibration in LiDAR SLAM: Integrating AI and Geometric Methods with Real-Time Feedback Using INAF Fusion', 'authors': 'Zahra Arjmandi, Gunho Sohn', 'link': 'https://arxiv.org/abs/2510.15803', 'abstract': "This paper presents a novel fusion technique for LiDAR Simultaneous Localization and Mapping (SLAM), aimed at improving localization and 3D mapping using LiDAR sensor. Our approach centers on the Inferred Attention Fusion (INAF) module, which integrates AI with geometric odometry. Utilizing the KITTI dataset's LiDAR data, INAF dynamically adjusts attention weights based on environmental feedback, enhancing the system's adaptability and measurement accuracy. This method advances the precision of both localization and 3D mapping, demonstrating the potential of our fusion technique to enhance autonomous navigation systems in complex scenarios.", 'abstract_zh': 'æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„LiDAR SLAMèåˆæŠ€æœ¯ï¼Œæ—¨åœ¨é€šè¿‡LiDARä¼ æ„Ÿå™¨æé«˜å®šä½å’Œä¸‰ç»´ mapping çš„å‡†ç¡®æ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•é›†ä¸­åœ¨æ¨ç†æ³¨æ„åŠ›èåˆï¼ˆINAFï¼‰æ¨¡å—ä¸Šï¼Œè¯¥æ¨¡å—ç»“åˆäº†AIä¸å‡ ä½•ä½å§¿ä¼°è®¡ã€‚åˆ©ç”¨KITTIæ•°æ®é›†çš„LiDARæ•°æ®ï¼ŒINAFæ¨¡å—æ ¹æ®ç¯å¢ƒåé¦ˆåŠ¨æ€è°ƒæ•´æ³¨æ„åŠ›æƒé‡ï¼Œå¢å¼ºç³»ç»Ÿçš„é€‚åº”æ€§å’Œæµ‹é‡ç²¾åº¦ã€‚è¯¥æ–¹æ³•æé«˜äº†å®šä½å’Œä¸‰ç»´mappingçš„ç²¾ç¡®åº¦ï¼Œå±•ç¤ºäº†æˆ‘ä»¬çš„èåˆæŠ€æœ¯åœ¨å¤æ‚åœºæ™¯ä¸­å¢å¼ºè‡ªä¸»å¯¼èˆªç³»ç»Ÿçš„æ½œåŠ›ã€‚', 'title_zh': 'åŸºäºINAFèåˆçš„å®æ—¶åé¦ˆç»“åˆAIå’Œå‡ ä½•æ–¹æ³•çš„LiDAR SLAMåŠ¨æ€æ ¡å‡†'}
{'arxiv_id': 'arXiv:2510.15786', 'title': 'DexCanvas: Bridging Human Demonstrations and Robot Learning for Dexterous Manipulation', 'authors': 'Xinyue Xu, Jieqiang Sun, Jing, Siyuan Chen, Lanjie Ma, Ke Sun, Bin Zhao, Jianbo Yuan, Yiwen Lu', 'link': 'https://arxiv.org/abs/2510.15786', 'abstract': 'We present DexCanvas, a large-scale hybrid real-synthetic human manipulation dataset containing 7,000 hours of dexterous hand-object interactions seeded from 70 hours of real human demonstrations, organized across 21 fundamental manipulation types based on the Cutkosky taxonomy. Each entry combines synchronized multi-view RGB-D, high-precision mocap with MANO hand parameters, and per-frame contact points with physically consistent force profiles. Our real-to-sim pipeline uses reinforcement learning to train policies that control an actuated MANO hand in physics simulation, reproducing human demonstrations while discovering the underlying contact forces that generate the observed object motion. DexCanvas is the first manipulation dataset to combine large-scale real demonstrations, systematic skill coverage based on established taxonomies, and physics-validated contact annotations. The dataset can facilitate research in robotic manipulation learning, contact-rich control, and skill transfer across different hand morphologies.', 'abstract_zh': 'DexCanvasï¼šä¸€ç§å¤§è§„æ¨¡æ··åˆçœŸå®åˆæˆäººç±»æ“ä½œæ•°æ®é›†', 'title_zh': 'DexCanvas: è”é€šäººç±»ç¤ºèŒƒä¸æœºå™¨äººçµå·§æ“ä½œå­¦ä¹ '}
{'arxiv_id': 'arXiv:2510.15686', 'title': 'Few-Shot Demonstration-Driven Task Coordination and Trajectory Execution for Multi-Robot Systems', 'authors': 'Taehyeon Kim, Vishnunandan L.N. Venkatesh, Byung-Cheol Min', 'link': 'https://arxiv.org/abs/2510.15686', 'abstract': 'In this paper, we propose a novel few-shot learning framework for multi-robot systems that integrate both spatial and temporal elements: Few-Shot Demonstration-Driven Task Coordination and Trajectory Execution (DDACE). Our approach leverages temporal graph networks for learning task-agnostic temporal sequencing and Gaussian Processes for spatial trajectory modeling, ensuring modularity and generalization across various tasks. By decoupling temporal and spatial aspects, DDACE requires only a small number of demonstrations, significantly reducing data requirements compared to traditional learning from demonstration approaches. To validate our proposed framework, we conducted extensive experiments in task environments designed to assess various aspects of multi-robot coordination-such as multi-sequence execution, multi-action dynamics, complex trajectory generation, and heterogeneous configurations. The experimental results demonstrate that our approach successfully achieves task execution under few-shot learning conditions and generalizes effectively across dynamic and diverse settings. This work underscores the potential of modular architectures in enhancing the practicality and scalability of multi-robot systems in real-world applications. Additional materials are available at this https URL.', 'abstract_zh': 'ä¸€ç§é›†æˆæ—¶ç©ºå…ƒç´ çš„Few-Shotå­¦ä¹ æ¡†æ¶ï¼šFew-Shotç¤ºèŒƒé©±åŠ¨ä»»åŠ¡åè°ƒä¸è½¨è¿¹æ‰§è¡Œï¼ˆDDACEï¼‰', 'title_zh': 'å°‘é‡ç¤ºä¾‹å¼•å¯¼çš„ä»»åŠ¡åè°ƒä¸è½¨è¿¹æ‰§è¡Œå¤šæœºå™¨äººç³»ç»Ÿ'}
{'arxiv_id': 'arXiv:2510.15679', 'title': 'HEADER: Hierarchical Robot Exploration via Attention-Based Deep Reinforcement Learning with Expert-Guided Reward', 'authors': 'Yuhong Cao, Yizhuo Wang, Jingsong Liang, Shuhao Liao, Yifeng Zhang, Peizhuo Li, Guillaume Sartoretti', 'link': 'https://arxiv.org/abs/2510.15679', 'abstract': 'This work pushes the boundaries of learning-based methods in autonomous robot exploration in terms of environmental scale and exploration efficiency. We present HEADER, an attention-based reinforcement learning approach with hierarchical graphs for efficient exploration in large-scale environments. HEADER follows existing conventional methods to construct hierarchical representations for the robot belief/map, but further designs a novel community-based algorithm to construct and update a global graph, which remains fully incremental, shape-adaptive, and operates with linear complexity. Building upon attention-based networks, our planner finely reasons about the nearby belief within the local range while coarsely leveraging distant information at the global scale, enabling next-best-viewpoint decisions that consider multi-scale spatial dependencies. Beyond novel map representation, we introduce a parameter-free privileged reward that significantly improves model performance and produces near-optimal exploration behaviors, by avoiding training objective bias caused by handcrafted reward shaping. In simulated challenging, large-scale exploration scenarios, HEADER demonstrates better scalability than most existing learning and non-learning methods, while achieving a significant improvement in exploration efficiency (up to 20%) over state-of-the-art baselines. We also deploy HEADER on hardware and validate it in complex, large-scale real-life scenarios, including a 300m*230m campus environment.', 'abstract_zh': 'æœ¬å·¥ä½œåœ¨è‡ªä¸»æœºå™¨äººæ¢ç´¢çš„ç¯å¢ƒè§„æ¨¡å’Œæ¢ç´¢æ•ˆç‡æ–¹é¢æ¨åŠ¨äº†åŸºäºå­¦ä¹ æ–¹æ³•çš„è¾¹ç•Œã€‚æˆ‘ä»¬æå‡ºäº†HEADERï¼Œä¸€ç§åŸºäºæ³¨æ„åŠ›çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œç»“åˆåˆ†å±‚å›¾ï¼Œä»¥æé«˜å¤§å‹ç¯å¢ƒä¸‹çš„æ¢ç´¢æ•ˆç‡ã€‚ HEADER åœ¨æ„å»ºæœºå™¨äººä¿¡å¿µ/åœ°å›¾çš„åˆ†å±‚è¡¨ç¤ºæ–¹é¢éµå¾ªç°æœ‰çš„ä¼ ç»Ÿæ–¹æ³•ï¼Œä½†è¿›ä¸€æ­¥è®¾è®¡äº†ä¸€ç§åŸºäºç¤¾åŒºçš„æ–°é¢–ç®—æ³•æ¥æ„å»ºå’Œæ›´æ–°å…¨å±€å›¾ï¼Œè¯¥ç®—æ³•ä¿æŒå®Œå…¨å¢é‡ã€å½¢çŠ¶è‡ªé€‚åº”ï¼Œå¹¶å…·æœ‰çº¿æ€§å¤æ‚åº¦ã€‚åŸºäºåŸºäºæ³¨æ„åŠ›çš„ç½‘ç»œï¼Œæˆ‘ä»¬çš„è§„åˆ’è€…åœ¨å±€éƒ¨èŒƒå›´å†…ç²¾ç»†åœ°è€ƒè™‘é™„è¿‘çš„ä¿¡å¿µï¼ŒåŒæ—¶åœ¨å…¨å±€èŒƒå›´å†…ç²—ç•¥åœ°åˆ©ç”¨è¿œç«¯ä¿¡æ¯ï¼Œä»è€Œå®ç°å¤šå°ºåº¦ç©ºé—´ä¾èµ–æ€§çš„ä¸‹ä¸€æ­¥æœ€ä¼˜è§†ç‚¹å†³ç­–ã€‚é™¤äº†æ–°é¢–çš„åœ°å›¾è¡¨ç¤ºï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ— éœ€å‚æ•°çš„ç‰¹æƒå¥–åŠ±ï¼Œè¯¥å¥–åŠ±æ˜¾ç€æé«˜äº†æ¨¡å‹æ€§èƒ½å¹¶äº§ç”Ÿæ¥è¿‘æœ€ä¼˜çš„æ¢ç´¢è¡Œä¸ºï¼Œé€šè¿‡é¿å…ç”±æ‰‹å·¥æ„å»ºçš„å¥–åŠ±å¡‘å½¢é€ æˆçš„è®­ç»ƒç›®æ ‡åå·®ã€‚åœ¨æ¨¡æ‹Ÿçš„å…·æœ‰æŒ‘æˆ˜æ€§ã€å¤§å‹ç¯å¢ƒæ¢ç´¢åœºæ™¯ä¸­ï¼ŒHEADER åœ¨å¯æ‰©å±•æ€§æ–¹é¢ä¼˜äºå¤§å¤šæ•°ç°æœ‰å­¦ä¹ å’Œéå­¦ä¹ æ–¹æ³•ï¼ŒåŒæ—¶ç›¸å¯¹äºæœ€å…ˆè¿›çš„åŸºçº¿æ–¹æ³•åœ¨æ¢ç´¢æ•ˆç‡ä¸Šå®ç°äº†æ˜¾è‘—æ”¹è¿›ï¼ˆé«˜è¾¾20%ï¼‰ã€‚æˆ‘ä»¬è¿˜åœ¨ç¡¬ä»¶ä¸Šéƒ¨ç½²äº†HEADERï¼Œå¹¶åœ¨å¤æ‚çš„å¤§å‹å®é™…åœºæ™¯ä¸­è¿›è¡Œäº†éªŒè¯ï¼ŒåŒ…æ‹¬ä¸€ä¸ª300mÃ—230mçš„æ ¡å›­ç¯å¢ƒã€‚', 'title_zh': 'åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ ä¸ä¸“å®¶å¼•å¯¼å¥–åŠ±çš„åˆ†å±‚æœºå™¨äººæ¢ç´¢'}
{'arxiv_id': 'arXiv:2510.15668', 'title': 'Freehand 3D Ultrasound Imaging: Sim-in-the-Loop Probe Pose Optimization via Visual Servoing', 'authors': 'Yameng Zhang, Dianye Huang, Max Q.-H. Meng, Nassir Navab, Zhongliang Jiang', 'link': 'https://arxiv.org/abs/2510.15668', 'abstract': "Freehand 3D ultrasound (US) imaging using conventional 2D probes offers flexibility and accessibility for diverse clinical applications but faces challenges in accurate probe pose estimation. Traditional methods depend on costly tracking systems, while neural network-based methods struggle with image noise and error accumulation, compromising reconstruction precision. We propose a cost-effective and versatile solution that leverages lightweight cameras and visual servoing in simulated environments for precise 3D US imaging. These cameras capture visual feedback from a textured planar workspace. To counter occlusions and lighting issues, we introduce an image restoration method that reconstructs occluded regions by matching surrounding texture patterns. For pose estimation, we develop a simulation-in-the-loop approach, which replicates the system setup in simulation and iteratively minimizes pose errors between simulated and real-world observations. A visual servoing controller refines the alignment of camera views, improving translational estimation by optimizing image alignment. Validations on a soft vascular phantom, a 3D-printed conical model, and a human arm demonstrate the robustness and accuracy of our approach, with Hausdorff distances to the reference reconstructions of 0.359 mm, 1.171 mm, and 0.858 mm, respectively. These results confirm the method's potential for reliable freehand 3D US reconstruction.", 'abstract_zh': 'åŸºäºè½»é‡çº§ç›¸æœºå’Œä»¿çœŸç¯å¢ƒçš„è§†è§‰ä¼ºæœè‡ªç”±æ‰‹3Dè¶…å£°æˆåƒ', 'title_zh': 'è‡ªç”±æ‰‹3Dè¶…å£°æˆåƒï¼šåŸºäºè§†è§‰ä¼ºæœçš„æ¨¡æ‹Ÿåœ¨ç¯æ¢å¤´å§¿æ€ä¼˜åŒ–'}
{'arxiv_id': 'arXiv:2510.15639', 'title': 'Integration of a Variable Stiffness Link for Long-Reach Aerial Manipulation', 'authors': 'Manuel J. Fernandez, Alejandro Suarez, Anibal Ollero, Matteo Fumagalli', 'link': 'https://arxiv.org/abs/2510.15639', 'abstract': 'This paper presents the integration of a Variable Stiffness Link (VSL) for long-reach aerial manipulation, enabling adaptable mechanical coupling between an aerial multirotor platform and a dual-arm manipulator. Conventional long-reach manipulation systems rely on rigid or cable connections, which limit precision or transmit disturbances to the aerial vehicle. The proposed VSL introduces an adjustable stiffness mechanism that allows the link to behave either as a flexible rope or as a rigid rod, depending on task requirements.\nThe system is mounted on a quadrotor equipped with the LiCAS dual-arm manipulator and evaluated through teleoperated experiments, involving external disturbances and parcel transportation tasks. Results demonstrate that varying the link stiffness significantly modifies the dynamic interaction between the UAV and the payload. The flexible configuration attenuates external impacts and aerodynamic perturbations, while the rigid configuration improves positional accuracy during manipulation phases.\nThese results confirm that VSL enhances versatility and safety, providing a controllable trade-off between compliance and precision. Future work will focus on autonomous stiffness regulation, multi-rope configurations, cooperative aerial manipulation and user studies to further assess its impact on teleoperated and semi-autonomous aerial tasks.', 'abstract_zh': 'åŸºäºVariable Stiffness Linkçš„é•¿è·ç©ºä¸­ manipulationç³»ç»Ÿç ”ç©¶', 'title_zh': 'é•¿è·èˆªç©ºæ“ä½œä¸­å¯å˜ stiffness è¿æ¥çš„é›†æˆ'}
{'arxiv_id': 'arXiv:2510.15638', 'title': 'Educational SoftHand-A: Building an Anthropomorphic Hand with Soft Synergies using LEGO MINDSTORMS', 'authors': 'Jared K. Lepora, Haoran Li, Efi Psomopoulou, Nathan F. Lepora', 'link': 'https://arxiv.org/abs/2510.15638', 'abstract': 'This paper introduces an anthropomorphic robot hand built entirely using LEGO MINDSTORMS: the Educational SoftHand-A, a tendon-driven, highly-underactuated robot hand based on the Pisa/IIT SoftHand and related hands. To be suitable for an educational context, the design is constrained to use only standard LEGO pieces with tests using common equipment available at home. The hand features dual motors driving an agonist/antagonist opposing pair of tendons on each finger, which are shown to result in reactive fine control. The finger motions are synchonized through soft synergies, implemented with a differential mechanism using clutch gears. Altogether, this design results in an anthropomorphic hand that can adaptively grasp a broad range of objects using a simple actuation and control mechanism. Since the hand can be constructed from LEGO pieces and uses state-of-the-art design concepts for robotic hands, it has the potential to educate and inspire children to learn about the frontiers of modern robotics.', 'abstract_zh': 'åŸºäºLEGO MINDSTORMSçš„æ•™è‚²è½¯æ‰‹Aï¼šä¸€ç§åŸºäºæ¯”è¨/æ„å¤§åˆ©ç†å·¥è½¯æ‰‹çš„è…±é©±åŠ¨é«˜æ¬ é©±åŠ¨ä»¿äººæœºå™¨äººæ‰‹åŠå…¶è®¾è®¡ä¸åº”ç”¨', 'title_zh': 'æ•™è‚²è½¯æ‰‹-Aï¼šåŸºäºLEGO MINDSTORMSæ„å»ºç±»äººè½¯æ‰‹ååŒç³»ç»Ÿ'}
{'arxiv_id': 'arXiv:2510.15626', 'title': 'Adaptive Legged Locomotion via Online Learning for Model Predictive Control', 'authors': 'Hongyu Zhou, Xiaoyu Zhang, Vasileios Tzoumas', 'link': 'https://arxiv.org/abs/2510.15626', 'abstract': 'We provide an algorithm for adaptive legged locomotion via online learning and model predictive control. The algorithm is composed of two interacting modules: model predictive control (MPC) and online learning of residual dynamics. The residual dynamics can represent modeling errors and external disturbances. We are motivated by the future of autonomy where quadrupeds will autonomously perform complex tasks despite real-world unknown uncertainty, such as unknown payload and uneven terrains. The algorithm uses random Fourier features to approximate the residual dynamics in reproducing kernel Hilbert spaces. Then, it employs MPC based on the current learned model of the residual dynamics. The model is updated online in a self-supervised manner using least squares based on the data collected while controlling the quadruped. The algorithm enjoys sublinear \\textit{dynamic regret}, defined as the suboptimality against an optimal clairvoyant controller that knows how the residual dynamics. We validate our algorithm in Gazebo and MuJoCo simulations, where the quadruped aims to track reference trajectories. The Gazebo simulations include constant unknown external forces up to $12\\boldsymbol{g}$, where $\\boldsymbol{g}$ is the gravity vector, in flat terrain, slope terrain with $20\\degree$ inclination, and rough terrain with $0.25m$ height variation. The MuJoCo simulations include time-varying unknown disturbances with payload up to $8~kg$ and time-varying ground friction coefficients in flat terrain.', 'abstract_zh': 'æˆ‘ä»¬æä¾›äº†ä¸€ç§åŸºäºåœ¨çº¿å­¦ä¹ å’Œæ¨¡å‹é¢„æµ‹æ§åˆ¶çš„è‡ªé€‚åº”è…¿è¶³è¿åŠ¨ç®—æ³•ã€‚è¯¥ç®—æ³•ç”±ä¸¤éƒ¨åˆ†ç›¸äº’ä½œç”¨çš„æ¨¡å—ç»„æˆï¼šæ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆMPCï¼‰å’Œæ®‹å·®åŠ¨åŠ›å­¦çš„åœ¨çº¿å­¦ä¹ ã€‚æ®‹å·®åŠ¨åŠ›å­¦å¯ä»¥è¡¨ç¤ºå»ºæ¨¡è¯¯å·®å’Œå¤–éƒ¨å¹²æ‰°ã€‚æˆ‘ä»¬å—åˆ°è‡ªä¸»æ€§æœªæ¥çš„å½±å“ï¼Œåœ¨è¿™ä¸ªæœªæ¥ä¸­ï¼Œå››è¶³æœºå™¨äººå³ä½¿åœ¨å­˜åœ¨æœªçŸ¥ä¸ç¡®å®šæ€§ï¼ˆå¦‚æœªçŸ¥è´Ÿè½½å’Œä¸å¹³åœ°å½¢ï¼‰çš„ç°å®ä¸–ç•Œä¸­ä¹Ÿèƒ½è‡ªä¸»æ‰§è¡Œå¤æ‚ä»»åŠ¡ã€‚è¯¥ç®—æ³•ä½¿ç”¨éšæœºå‚…é‡Œå¶ç‰¹å¾æ¥åœ¨å†ç”Ÿæ ¸å¸Œå°”ä¼¯ç‰¹ç©ºé—´ä¸­é€¼è¿‘æ®‹å·®åŠ¨åŠ›å­¦ï¼Œç„¶ååŸºäºå½“å‰å­¦ä¹ å¾—åˆ°çš„æ®‹å·®åŠ¨åŠ›å­¦æ¨¡å‹é‡‡ç”¨æ¨¡å‹é¢„æµ‹æ§åˆ¶ã€‚æ¨¡å‹é€šè¿‡åœ¨æ§åˆ¶å››è¶³æœºå™¨äººè¿‡ç¨‹ä¸­æ”¶é›†çš„æ•°æ®ï¼Œåœ¨è‡ªæˆ‘ç›‘ç£çš„æ–¹å¼ä¸‹åœ¨çº¿æ›´æ–°ã€‚è¯¥ç®—æ³•å…·æœ‰äºšçº¿æ€§çš„åŠ¨æ€åæ‚”ç‡ï¼Œè¿™æ˜¯ç›¸å¯¹äºå·²çŸ¥æ®‹å·®åŠ¨åŠ›å­¦çš„æœ€ä¼˜é¢„çŸ¥æ§åˆ¶å™¨çš„æ¬¡ä¼˜æ€§åº¦é‡ã€‚æˆ‘ä»¬åœ¨Gazeboå’ŒMuJoCoä»¿çœŸä¸­éªŒè¯äº†è¯¥ç®—æ³•ï¼Œå…¶ä¸­å››è¶³æœºå™¨äººæ—¨åœ¨è·Ÿè¸ªå‚è€ƒè½¨è¿¹ã€‚Gazeboä»¿çœŸçš„å¤–éƒ¨æœªçŸ¥åŠ›æ’å®šï¼Œæœ€å¤§è‡³$12\\boldsymbol{g}$ï¼ŒåŒ…å«å¹³å¦åœ°å½¢ã€å¡åº¦ä¸º$20^\\circ$çš„æ–œå¡åœ°å½¢å’Œèµ·ä¼åœ°å½¢ï¼ˆé«˜åº¦å˜åŒ–$0.25$ç±³ï¼‰ã€‚MuJoCoä»¿çœŸçš„å¤–éƒ¨æœªçŸ¥å¹²æ‰°éšæ—¶é—´å˜åŒ–ï¼Œè´Ÿè½½æœ€å¤§è‡³$8~kg$ï¼Œå¹³å¦åœ°å½¢ä¸Šçš„åœ°é¢æ‘©æ“¦ç³»æ•°éšæ—¶é—´å˜åŒ–ã€‚', 'title_zh': 'åŸºäºåœ¨çº¿å­¦ä¹ çš„è‡ªé€‚åº”è…¿å¼è¿åŠ¨æ¨¡å‹é¢„æµ‹æ§åˆ¶'}
{'arxiv_id': 'arXiv:2510.15533', 'title': 'Improved Extended Kalman Filter-Based Disturbance Observers for Exoskeletons', 'authors': 'Shilei Li, Dawei Shi, Makoto Iwasaki, Yan Ning, Hongpeng Zhou, Ling Shi', 'link': 'https://arxiv.org/abs/2510.15533', 'abstract': 'The nominal performance of mechanical systems is often degraded by unknown disturbances. A two-degree-of-freedom control structure can decouple nominal performance from disturbance rejection. However, perfect disturbance rejection is unattainable when the disturbance dynamic is unknown. In this work, we reveal an inherent trade-off in disturbance estimation subject to tracking speed and tracking uncertainty. Then, we propose two novel methods to enhance disturbance estimation: an interacting multiple model extended Kalman filter-based disturbance observer and a multi-kernel correntropy extended Kalman filter-based disturbance observer. Experiments on an exoskeleton verify that the proposed two methods improve the tracking accuracy $36.3\\%$ and $16.2\\%$ in hip joint error, and $46.3\\%$ and $24.4\\%$ in knee joint error, respectively, compared to the extended Kalman filter-based disturbance observer, in a time-varying interaction force scenario, demonstrating the superiority of the proposed method.', 'abstract_zh': 'æœºæ¢°ç³»ç»Ÿçš„åä¹‰æ€§èƒ½å¾€å¾€å—åˆ°æœªçŸ¥å¹²æ‰°çš„å½±å“ã€‚ä¸¤è‡ªç”±åº¦æ§åˆ¶ç»“æ„å¯ä»¥ä»å¹²æ‰°æŠ‘åˆ¶ä¸­è§£è€¦åä¹‰æ€§èƒ½ã€‚ç„¶è€Œï¼Œå½“å¹²æ‰°åŠ¨åŠ›å­¦æœªçŸ¥æ—¶ï¼Œå®Œç¾çš„å¹²æ‰°æŠ‘åˆ¶æ˜¯ä¸å¯èƒ½å®ç°çš„ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ­ç¤ºäº†åœ¨è¿½è¸ªé€Ÿåº¦å’Œè¿½è¸ªä¸ç¡®å®šæ€§çº¦æŸä¸‹çš„å¹²æ‰°ä¼°è®¡å›ºæœ‰çš„æƒè¡¡ã€‚ç„¶åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸¤ç§æ–°çš„æ–¹æ³•æ¥å¢å¼ºå¹²æ‰°ä¼°è®¡ï¼šåŸºäºäº¤äº’å¼å¤šç§æ¨¡å‹æ‰©å±•å¡å°”æ›¼æ»¤æ³¢å™¨çš„å¹²æ‰°è§‚æµ‹å™¨å’ŒåŸºäºå¤šæ ¸æ­£æ€é€¼è¿‘æ»¤æ³¢å™¨çš„å¹²æ‰°è§‚æµ‹å™¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨æ—¶é—´varyingäº¤äº’åŠ›åœºæ™¯ä¸‹ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åˆ†åˆ«å°†é«‹å…³èŠ‚è¯¯å·®çš„è·Ÿè¸ªç²¾åº¦æé«˜äº†36.3%å’Œ16.2%ï¼Œè†å…³èŠ‚è¯¯å·®çš„è·Ÿè¸ªç²¾åº¦æé«˜äº†46.3%å’Œ24.4%ï¼Œç›¸æ¯”åŸºäºæ‰©å±•å¡å°”æ›¼æ»¤æ³¢å™¨çš„å¹²æ‰°è§‚æµ‹å™¨ï¼Œè¯æ˜äº†æ‰€æå‡ºæ–¹æ³•çš„ä¼˜è¶Šæ€§ã€‚', 'title_zh': 'åŸºäºæ‰©å±•å¡å°”æ›¼æ»¤æ³¢çš„æ”¹è¿›å¹²æ‰°è§‚æµ‹å™¨åœ¨å¤–éª¨éª¼ç³»ç»Ÿä¸­çš„åº”ç”¨'}
{'arxiv_id': 'arXiv:2510.15530', 'title': 'VO-DP: Semantic-Geometric Adaptive Diffusion Policy for Vision-Only Robotic Manipulation', 'authors': 'Zehao Ni, Yonghao He, Lingfeng Qian, Jilei Mao, Fa Fu, Wei Sui, Hu Su, Junran Peng, Zhipeng Wang, Bin He', 'link': 'https://arxiv.org/abs/2510.15530', 'abstract': 'In the context of imitation learning, visuomotor-based diffusion policy learning is one of the main directions in robotic manipulation. Most of these approaches rely on point clouds as observation inputs and construct scene representations through point clouds feature learning, which enables them to achieve remarkable accuracy. However, the existing literature lacks an in-depth exploration of vision-only solutions that have significant potential. In this paper, we propose a Vision-Only and single-view Diffusion Policy learning method (VO-DP) that leverages pretrained visual foundation models to achieve effective fusion of semantic and geometric features. We utilize intermediate features from VGGT incorporating semantic features from DINOv2 and geometric features from Alternating Attention blocks. Features are fused via cross-attention and spatially compressed with a CNN to form the input to the policy head. Extensive experiments demonstrate that VO-DP not only outperforms the vision-only baseline DP significantly but also exhibits distinct performance trends against the point cloud-based method DP3: in simulation tasks, VO-DP achieves an average success rate of 64.6% on par with DP3 64.0% and far higher than DP 34.8%, while in real-world tasks, it reaches 87.9%, outperforming both DP3 67.5% and DP 11.2% by a notable margin. Further robustness evaluations confirm that VO-DP remains highly stable under varying conditions including color, size, background, and lighting. Lastly, we open-source a training library for robotic manipulation. Built on Accelerate, this library supports multi-machine and multi-GPU parallel training, as well as mixed precision training. It is compatible with visuomotor policies such as DP, DP3 and VO-DP, and also supports the RoboTwin simulator.', 'abstract_zh': 'åŸºäºè§†è§‰çš„å•è§†è§’æ‰©æ•£ç­–ç•¥å­¦ä¹ æ–¹æ³•ï¼ˆVO-DPï¼‰ï¼šä¸€ç§æ— éœ€ç‚¹äº‘çš„æ•°æ®é©±åŠ¨æœºå™¨äºº manipulation æ–¹æ³•', 'title_zh': 'VO-DP: åŸºäºè¯­ä¹‰-å‡ ä½•è‡ªé€‚åº”æ‰©æ•£ç­–ç•¥çš„çº¯è§†è§‰æœºå™¨äºº manipulation'}
{'arxiv_id': 'arXiv:2510.15505', 'title': 'Perfect Prediction or Plenty of Proposals? What Matters Most in Planning for Autonomous Driving', 'authors': 'Aron Distelzweig, Faris JanjoÅ¡, Oliver Scheel, Sirish Reddy Varra, Raghu Rajan, Joschka Boedecker', 'link': 'https://arxiv.org/abs/2510.15505', 'abstract': 'Traditionally, prediction and planning in autonomous driving (AD) have been treated as separate, sequential modules. Recently, there has been a growing shift towards tighter integration of these components, known as Integrated Prediction and Planning (IPP), with the aim of enabling more informed and adaptive decision-making. However, it remains unclear to what extent this integration actually improves planning performance. In this work, we investigate the role of prediction in IPP approaches, drawing on the widely adopted Val14 benchmark, which encompasses more common driving scenarios with relatively low interaction complexity, and the interPlan benchmark, which includes highly interactive and out-of-distribution driving situations. Our analysis reveals that even access to perfect future predictions does not lead to better planning outcomes, indicating that current IPP methods often fail to fully exploit future behavior information. Instead, we focus on high-quality proposal generation, while using predictions primarily for collision checks. We find that many imitation learning-based planners struggle to generate realistic and plausible proposals, performing worse than PDM - a simple lane-following approach. Motivated by this observation, we build on PDM with an enhanced proposal generation method, shifting the emphasis towards producing diverse but realistic and high-quality proposals. This proposal-centric approach significantly outperforms existing methods, especially in out-of-distribution and highly interactive settings, where it sets new state-of-the-art results.', 'abstract_zh': 'ä¼ ç»Ÿä¸Šï¼Œè‡ªä¸»é©¾é©¶ä¸­çš„é¢„æµ‹å’Œè§„åˆ’è¢«è§†ä¸ºåˆ†ç¦»çš„ã€é¡ºåºçš„æ¨¡å—ã€‚è¿‘å¹´æ¥ï¼Œäººä»¬è¶Šæ¥è¶Šå€¾å‘äºå°†è¿™äº›ç»„ä»¶é€šè¿‡é›†æˆé¢„æµ‹å’Œè§„åˆ’ï¼ˆIPPï¼‰è¿›è¡Œæ›´ç´§å¯†çš„é›†æˆï¼Œç›®çš„æ˜¯å®ç°æ›´å…·ä¿¡æ¯é‡å’Œé€‚åº”æ€§çš„å†³ç­–ã€‚ç„¶è€Œï¼Œç›®å‰ä»ä¸æ¸…æ¥šè¿™ç§é›†æˆåœ¨å¤šå¤§ç¨‹åº¦ä¸Šæ”¹å–„äº†è§„åˆ’æ€§èƒ½ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†IPPæ–¹æ³•ä¸­é¢„æµ‹çš„ä½œç”¨ï¼Œé‡‡ç”¨äº†å¹¿æ³›é‡‡ç”¨çš„Val14åŸºå‡†æµ‹è¯•ï¼Œè¯¥åŸºå‡†æ¶µç›–äº†å…·æœ‰ç›¸å¯¹è¾ƒä½äº¤äº’å¤æ‚æ€§çš„å¸¸è§é©¾é©¶åœºæ™¯ï¼Œä»¥åŠåŒ…æ‹¬é«˜åº¦äº¤äº’å’Œåˆ†å¸ƒå¤–é©¾é©¶æƒ…å†µçš„interPlanåŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼Œå³ä½¿æ‹¥æœ‰å®Œç¾çš„æœªæ¥é¢„æµ‹ä¿¡æ¯ä¹Ÿä¸ä¸€å®šèƒ½å¾—åˆ°æ›´å¥½çš„è§„åˆ’ç»“æœï¼Œè¡¨æ˜å½“å‰çš„IPPæ–¹æ³•å¾€å¾€æœªèƒ½å……åˆ†åˆ©ç”¨æœªæ¥è¡Œä¸ºä¿¡æ¯ã€‚ç›¸åï¼Œæˆ‘ä»¬ä¾§é‡äºé«˜è´¨é‡ææ¡ˆçš„ç”Ÿæˆï¼Œä¸»è¦åˆ©ç”¨é¢„æµ‹è¿›è¡Œç¢°æ’æ£€æŸ¥ã€‚æˆ‘ä»¬å‘ç°ï¼Œè®¸å¤šåŸºäºæ¨¡ä»¿å­¦ä¹ çš„è§„åˆ’å™¨éš¾ä»¥ç”Ÿæˆé€¼çœŸä¸”åˆç†çš„ææ¡ˆï¼Œå…¶è¡¨ç°ç”šè‡³ä¸å¦‚ç®€å•çš„è½¦é“è·Ÿéšæ–¹æ³•PDMã€‚å—æ­¤è§‚å¯Ÿçš„å¯å‘ï¼Œæˆ‘ä»¬åŸºäºPDMæ„å»ºäº†ä¸€ä¸ªæ”¹è¿›çš„ææ¡ˆç”Ÿæˆæ–¹æ³•ï¼Œç€é‡äºç”Ÿæˆå¤šæ ·åŒ–ä½†é€¼çœŸä¸”é«˜è´¨é‡çš„ææ¡ˆã€‚è¿™ç§ä»¥ææ¡ˆä¸ºä¸­å¿ƒçš„æ–¹æ³•åœ¨åˆ†å¸ƒå¤–å’Œé«˜åº¦äº¤äº’çš„è®¾ç½®ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨è¿™äº›è®¾ç½®ä¸­ï¼Œå®ƒè®¾å®šäº†æ–°çš„æœ€ä½³æˆæœã€‚', 'title_zh': 'å®Œç¾é¢„æµ‹è¿˜æ˜¯å……è¶³å»ºè®®ï¼Ÿè§„åˆ’è‡ªä¸»é©¾é©¶ä¸­ä½•è€…æ›´ä¸ºé‡è¦'}
{'arxiv_id': 'arXiv:2510.15446', 'title': 'VDRive: Leveraging Reinforced VLA and Diffusion Policy for End-to-end Autonomous Driving', 'authors': 'Ziang Guo, Zufeng Zhang', 'link': 'https://arxiv.org/abs/2510.15446', 'abstract': "In autonomous driving, dynamic environment and corner cases pose significant challenges to the robustness of ego vehicle's state understanding and decision making. We introduce VDRive, a novel pipeline for end-to-end autonomous driving that explicitly models state-action mapping to address these challenges, enabling interpretable and robust decision making. By leveraging the advancement of the state understanding of the Vision Language Action Model (VLA) with generative diffusion policy-based action head, our VDRive guides the driving contextually and geometrically. Contextually, VLA predicts future observations through token generation pre-training, where the observations are represented as discrete codes by a Conditional Vector Quantized Variational Autoencoder (CVQ-VAE). Geometrically, we perform reinforcement learning fine-tuning of the VLA to predict future trajectories and actions based on current driving conditions. VLA supplies the current state tokens and predicted state tokens for the action policy head to generate hierarchical actions and trajectories. During policy training, a learned critic evaluates the actions generated by the policy and provides gradient-based feedback, forming an actor-critic framework that enables a reinforcement-based policy learning pipeline. Experiments show that our VDRive achieves state-of-the-art performance in the Bench2Drive closed-loop benchmark and nuScenes open-loop planning.", 'abstract_zh': 'è‡ªä¸»é©¾é©¶ä¸­ï¼ŒåŠ¨æ€ç¯å¢ƒå’Œè¾¹ç¼˜æ¡ˆä¾‹å¯¹ ego è½¦è¾†çŠ¶æ€ç†è§£å’Œå†³ç­–çš„ç¨³å¥æ€§æ„æˆäº†é‡å¤§æŒ‘æˆ˜ã€‚æˆ‘ä»¬æå‡ºäº† VDRiveï¼Œè¿™æ˜¯ä¸€ç§å…¨æ–°çš„ç«¯åˆ°ç«¯è‡ªä¸»é©¾é©¶ç®¡é“ï¼Œæ˜ç¡®å»ºæ¨¡çŠ¶æ€-åŠ¨ä½œæ˜ å°„ä»¥åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œä»è€Œå®ç°å¯è§£é‡Šå’Œç¨³å¥çš„å†³ç­–ã€‚é€šè¿‡åˆ©ç”¨ Vision Language Action æ¨¡å‹ï¼ˆVLAï¼‰çŠ¶æ€ç†è§£çš„è¿›æ­¥ä»¥åŠç”Ÿæˆæ‰©æ•£æ”¿ç­–å–å‘å¤´éƒ¨ï¼Œæˆ‘ä»¬çš„ VDRive åœ¨ä¸Šä¸‹æ–‡å’Œå‡ ä½•æ„ä¹‰ä¸Šå¼•å¯¼é©¾é©¶è¡Œä¸ºã€‚ä¸Šä¸‹æ–‡ä¸­ï¼ŒVLA é€šè¿‡æ ‡è®°ç”Ÿæˆé¢„è®­ç»ƒé¢„æµ‹æœªæ¥è§‚å¯Ÿï¼Œå…¶ä¸­è§‚å¯Ÿç”±æ¡ä»¶å‘é‡é‡åŒ–å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆCVQ-VAEï¼‰è¡¨ç¤ºä¸ºç¦»æ•£ä»£ç ã€‚å‡ ä½•ä¸Šï¼Œæˆ‘ä»¬å¯¹ VLA è¿›è¡Œå¼ºåŒ–å­¦ä¹ å¾®è°ƒï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨å½“å‰é©¾é©¶æ¡ä»¶ä¸‹é¢„æµ‹æœªæ¥è½¨è¿¹å’ŒåŠ¨ä½œã€‚VLA ä¸ºåŠ¨ä½œç­–ç•¥å¤´éƒ¨æä¾›å½“å‰çŠ¶æ€æ ‡è®°å’Œé¢„æµ‹çŠ¶æ€æ ‡è®°ä»¥ç”Ÿæˆåˆ†å±‚åŠ¨ä½œå’Œè½¨è¿¹ã€‚åœ¨ç­–ç•¥è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¸€ä¸ªå­¦ä¹ åˆ°çš„æ‰¹è¯„å®¶è¯„ä¼°æ”¿ç­–ç”Ÿæˆçš„åŠ¨ä½œå¹¶æä¾›åŸºäºæ¢¯åº¦çš„åé¦ˆï¼Œå½¢æˆä¸€ç§ä½¿å¼ºåŒ–å­¦ä¹ ç­–ç•¥å­¦ä¹ ç®¡é“å¾—ä»¥å®ç°çš„è¡Œä¸º-æ‰¹è¯„å®¶æ¡†æ¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„ VDRive åœ¨ Bench2Drive é—­ç¯åŸºå‡†å’Œ nuScenes å¼€ç¯è§„åˆ’ä¸­å‡å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚', 'title_zh': 'VDRive: åˆ©ç”¨å¼ºåŒ–VLADå’Œæ‰©æ•£ç­–ç•¥å®ç°ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶'}
{'arxiv_id': 'arXiv:2510.15376', 'title': 'Towards Automated Chicken Deboning via Learning-based Dynamically-Adaptive 6-DoF Multi-Material Cutting', 'authors': 'Zhaodong Yang, Ai-Ping Hu, Harish Ravichandar', 'link': 'https://arxiv.org/abs/2510.15376', 'abstract': 'Automating chicken shoulder deboning requires precise 6-DoF cutting through a partially occluded, deformable, multi-material joint, since contact with the bones presents serious health and safety risks. Our work makes both systems-level and algorithmic contributions to train and deploy a reactive force-feedback cutting policy that dynamically adapts a nominal trajectory and enables full 6-DoF knife control to traverse the narrow joint gap while avoiding contact with the bones. First, we introduce an open-source custom-built simulator for multi-material cutting that models coupling, fracture, and cutting forces, and supports reinforcement learning, enabling efficient training and rapid prototyping. Second, we design a reusable physical testbed to emulate the chicken shoulder: two rigid "bone" spheres with controllable pose embedded in a softer block, enabling rigorous and repeatable evaluation while preserving essential multi-material characteristics of the target problem. Third, we train and deploy a residual RL policy, with discretized force observations and domain randomization, enabling robust zero-shot sim-to-real transfer and the first demonstration of a learned policy that debones a real chicken shoulder. Our experiments in our simulator, on our physical testbed, and on real chicken shoulders show that our learned policy reliably navigates the joint gap and reduces undesired bone/cartilage contact, resulting in up to a 4x improvement over existing open-loop cutting baselines in terms of success rate and bone avoidance. Our results also illustrate the necessity of force feedback for safe and effective multi-material cutting. The project website is at this https URL.', 'abstract_zh': 'è‡ªåŠ¨åŒ–å»é¸¡è‚©éª¨è¦æ±‚é€šè¿‡éƒ¨åˆ†é®æŒ¡ã€å¯å˜å½¢çš„å¤šææ–™å…³èŠ‚è¿›è¡Œç²¾ç¡®çš„6-è‡ªç”±åº¦åˆ‡å‰²ï¼Œç”±äºä¸éª¨éª¼æ¥è§¦ä¼šå¸¦æ¥ä¸¥é‡çš„å¥åº·å’Œå®‰å…¨é£é™©ã€‚æˆ‘ä»¬çš„å·¥ä½œåœ¨ç³»ç»Ÿçº§å’Œç®—æ³•çº§ä¸Šéƒ½åšå‡ºäº†è´¡çŒ®ï¼Œä»¥è®­ç»ƒå¹¶éƒ¨ç½²ä¸€ç§èƒ½åŠ¨æ€è°ƒæ•´é¢„å®šè½¨è¿¹çš„ååº”å¼åŠ›åé¦ˆåˆ‡å‰²ç­–ç•¥ï¼Œå¹¶ä¸”èƒ½å¤Ÿå®ç°6-è‡ªç”±åº¦åˆ€å…·æ§åˆ¶ä»¥é€šè¿‡ç‹­çª„çš„å…³èŠ‚é—´éš™å¹¶é¿å…æ¥è§¦éª¨éª¼ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå¼€æºçš„è‡ªå®šä¹‰å¤šææ–™åˆ‡å‰²æ¨¡æ‹Ÿå™¨ï¼Œè¯¥æ¨¡æ‹Ÿå™¨æ¨¡å‹äº†è€¦åˆã€æ–­è£‚å’Œåˆ‡å‰²åŠ›ï¼Œå¹¶æ”¯æŒå¼ºåŒ–å­¦ä¹ ï¼Œä»è€Œå®ç°é«˜æ•ˆè®­ç»ƒå’Œå¿«é€ŸåŸå‹åˆ¶ä½œã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªå¯é‡å¤ä½¿ç”¨çš„ç‰©ç†è¯•éªŒå°æ¥æ¨¡æ‹Ÿé¸¡è‚©ï¼šä¸¤ä¸ªå…·æœ‰å¯æ§å§¿æ€çš„åˆšæ€§â€œéª¨éª¼â€çƒä½“åµŒå…¥è¾ƒè½¯çš„å—ä½“ä¸­ï¼Œä»è€Œä¿æŒäº†ç›®æ ‡é—®é¢˜çš„ä¸»è¦å¤šææ–™ç‰¹æ€§ï¼ŒåŒæ—¶ä¹Ÿèƒ½å¤Ÿè¿›è¡Œä¸¥æ ¼çš„é‡å¤è¯„ä¼°ã€‚ç¬¬ä¸‰ï¼Œæˆ‘ä»¬è®­ç»ƒå¹¶éƒ¨ç½²äº†ä¸€ä¸ªç¦»æ•£åŠ›è§‚æµ‹æ®‹å·®RLç­–ç•¥ï¼Œç»“åˆé¢†åŸŸéšæœºåŒ–ï¼Œå®ç°äº†ç¨³å¥çš„æ— ç›‘ç£æ¨¡æ‹Ÿåˆ°ç°å®ä¸–ç•Œçš„è½¬ç§»ï¼Œå¹¶å±•ç¤ºäº†ç¬¬ä¸€ä¸ªèƒ½å¤Ÿå»çœŸé¸¡è‚©éª¨çš„ä»å­¦ä¹ ç­–ç•¥ã€‚æˆ‘ä»¬åœ¨æ¨¡æ‹Ÿå™¨ã€ç‰©ç†è¯•éªŒå°å’ŒçœŸå®é¸¡è‚©ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„å­¦ä¹ ç­–ç•¥èƒ½å¯é åœ°é€šè¿‡å…³èŠ‚é—´éš™å¹¶å‡å°‘ä¸å¿…è¦çš„éª¨éª¼/è½¯éª¨æ¥è§¦ï¼Œç›¸æ¯”äºç°æœ‰çš„å¼€ç¯åˆ‡å‰²åŸºçº¿ï¼Œåœ¨æˆåŠŸç‡å’Œéª¨éª¼è§„é¿æ–¹é¢æå‡äº†é«˜è¾¾4å€çš„æ•ˆæœã€‚æˆ‘ä»¬çš„ç»“æœè¿˜å±•ç¤ºäº†åŠ›åé¦ˆåœ¨å®‰å…¨æœ‰æ•ˆçš„å¤šææ–™åˆ‡å‰²ä¸­çš„å¿…è¦æ€§ã€‚é¡¹ç›®ç½‘ç«™ï¼šğŸ”—ã€‚', 'title_zh': 'åŸºäºå­¦ä¹ çš„è‡ªé€‚åº”6è‡ªç”±åº¦å¤šææ–™åˆ‡å‰²çš„è‡ªåŠ¨åŒ–é¸¡å»éª¨ç ”ç©¶'}
{'arxiv_id': 'arXiv:2510.15352', 'title': 'GaussGym: An open-source real-to-sim framework for learning locomotion from pixels', 'authors': 'Alejandro Escontrela, Justin Kerr, Arthur Allshire, Jonas Frey, Rocky Duan, Carmelo Sferrazza, Pieter Abbeel', 'link': 'https://arxiv.org/abs/2510.15352', 'abstract': 'We present a novel approach for photorealistic robot simulation that integrates 3D Gaussian Splatting as a drop-in renderer within vectorized physics simulators such as IsaacGym. This enables unprecedented speed -- exceeding 100,000 steps per second on consumer GPUs -- while maintaining high visual fidelity, which we showcase across diverse tasks. We additionally demonstrate its applicability in a sim-to-real robotics setting. Beyond depth-based sensing, our results highlight how rich visual semantics improve navigation and decision-making, such as avoiding undesirable regions. We further showcase the ease of incorporating thousands of environments from iPhone scans, large-scale scene datasets (e.g., GrandTour, ARKit), and outputs from generative video models like Veo, enabling rapid creation of realistic training worlds. This work bridges high-throughput simulation and high-fidelity perception, advancing scalable and generalizable robot learning. All code and data will be open-sourced for the community to build upon. Videos, code, and data available at this https URL.', 'abstract_zh': 'æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œç”¨äºåœ¨IsaacGymç­‰å‘é‡ç‰©ç†æ¨¡æ‹Ÿå™¨ä¸­ä»¥3Dæ­£æ€æ–‘ç‚¹å›¾ä½œä¸ºæ’ä»¶æ¸²æŸ“å™¨è¿›è¡Œ photorealistic æœºå™¨äººæ¨¡æ‹Ÿã€‚è¿™ç§æ–¹æ³•å®ç°äº†å‰æ‰€æœªæœ‰çš„é€Ÿåº¦â€”â€”åœ¨æ¶ˆè´¹çº§GPUä¸Šè¶…è¿‡æ¯ç§’100,000æ­¥â€”â€”åŒæ—¶ä¿æŒäº†é«˜åº¦çš„è§†è§‰ä¿çœŸåº¦ï¼Œæˆ‘ä»¬é€šè¿‡å„ç§ä»»åŠ¡å±•ç¤ºäº†è¿™ä¸€ç‚¹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å±•ç¤ºäº†å…¶åœ¨sim-to-realæœºå™¨äººè®¾ç½®ä¸­çš„åº”ç”¨ã€‚é™¤äº†åŸºäºæ·±åº¦çš„ä¼ æ„Ÿå™¨ä¹‹å¤–ï¼Œæˆ‘ä»¬çš„ç»“æœå¼ºè°ƒäº†ä¸°å¯Œçš„è§†è§‰è¯­ä¹‰å¦‚ä½•æé«˜å¯¼èˆªå’Œå†³ç­–èƒ½åŠ›ï¼Œä¾‹å¦‚é¿å…ä¸è‰¯åŒºåŸŸã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å±•ç¤ºäº†å¦‚ä½•è½»æ¾åœ°ä»iPhoneæ‰«æã€å¤§è§„æ¨¡åœºæ™¯æ•°æ®é›†ï¼ˆä¾‹å¦‚GrandTourã€ARKitï¼‰ä»¥åŠç”Ÿæˆè§†é¢‘æ¨¡å‹ï¼ˆå¦‚Veoï¼‰ä¸­é›†æˆæ•°åƒä¸ªç¯å¢ƒï¼Œä»è€Œå¿«é€Ÿåˆ›å»ºçœŸå®çš„è®­ç»ƒä¸–ç•Œã€‚è¿™é¡¹å·¥ä½œå°†é«˜é€šé‡æ¨¡æ‹Ÿä¸é«˜ä¿çœŸæ„ŸçŸ¥ç›¸ç»“åˆï¼Œæ¨åŠ¨äº†å¯æ‰©å±•å’Œé€šç”¨çš„æœºå™¨äººå­¦ä¹ ã€‚æ‰€æœ‰ä»£ç å’Œæ•°æ®éƒ½å°†å¼€æºï¼Œä»¥ä¾¿ç¤¾åŒºåœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œå»ºè®¾ã€‚æ›´å¤šä¿¡æ¯è¯·å‚è§æ­¤é“¾æ¥ï¼š[æ­¤httpsURL]ã€‚', 'title_zh': 'GaussGym: ä¸€ä¸ªå¼€æºçš„ä»åƒç´ å­¦ä¹ è¡Œèµ°çš„å®æ—¶åˆ°æ¨¡æ‹Ÿæ¡†æ¶'}
{'arxiv_id': 'arXiv:2510.15350', 'title': 'Nauplius Optimisation for Autonomous Hydrodynamics', 'authors': 'Shyalan Ramesh, Scott Mann, Alex Stumpf', 'link': 'https://arxiv.org/abs/2510.15350', 'abstract': 'Autonomous Underwater vehicles must operate in strong currents, limited acoustic bandwidth, and persistent sensing requirements where conventional swarm optimisation methods are unreliable. This paper presents NOAH, a novel nature-inspired swarm optimisation algorithm that combines current-aware drift, irreversible settlement in persistent sensing nodes, and colony-based communication. Drawing inspiration from the behaviour of barnacle nauplii, NOAH addresses the critical limitations of existing swarm algorithms by providing hydrodynamic awareness, irreversible anchoring mechanisms, and colony-based communication capabilities essential for underwater exploration missions. The algorithm establishes a comprehensive foundation for scalable and energy-efficient underwater swarm robotics with validated performance analysis. Validation studies demonstrate an 86% success rate for permanent anchoring scenarios, providing a unified formulation for hydrodynamic constraints and irreversible settlement behaviours with an empirical study under flow.', 'abstract_zh': 'è‡ªä¸» underwater æœºå™¨äººå¿…é¡»åœ¨å¼ºæµã€æœ‰é™çš„å£°å­¦å¸¦å®½ä»¥åŠæŒç»­çš„ä¼ æ„Ÿè¦æ±‚ä¸‹è¿ä½œï¼Œä¼ ç»Ÿç¾¤ä½“ä¼˜åŒ–æ–¹æ³•åœ¨æ­¤æƒ…å†µä¸‹ä¸å¯é ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å—è‡ªç„¶ç•Œå¯å‘çš„ç¾¤ä½“ä¼˜åŒ–ç®—æ³• NOAHï¼Œè¯¥ç®—æ³•ç»“åˆäº†æµæ„ŸçŸ¥æ¼‚ç§»ã€ä¸å¯é€†çš„æŒç»­ä¼ æ„ŸèŠ‚ç‚¹é”šå®šæœºåˆ¶ä»¥åŠåŸºäºç¾¤ä½“çš„é€šä¿¡ã€‚NOAH é€šè¿‡å€Ÿé‰´æµ®æ³¥è™«çš„è¡Œä¸ºï¼Œè§£å†³äº†ç°æœ‰ç¾¤ä½“ç®—æ³•çš„å…³é”®é™åˆ¶ï¼Œæä¾›äº†æ°´åŠ¨åŠ›æ„ŸçŸ¥ã€ä¸å¯é€†é”šå®šæœºåˆ¶å’ŒåŸºäºç¾¤ä½“çš„é€šä¿¡èƒ½åŠ›ï¼Œè¿™äº›å¯¹äºæ°´ä¸‹æ¢ç´¢ä»»åŠ¡è‡³å…³é‡è¦ã€‚è¯¥ç®—æ³•ä¸ºå¯æ‰©å±•å’ŒèŠ‚èƒ½çš„æ°´ä¸‹ç¾¤ä½“æœºå™¨äººå¥ å®šäº†åŸºç¡€ï¼Œå¹¶ç»è¿‡äº†éªŒè¯æ€§åˆ†æã€‚éªŒè¯ç ”ç©¶è¡¨æ˜ï¼Œåœ¨æ°¸ä¹…é”šå®šåœºæ™¯ä¸­æˆåŠŸç‡é«˜è¾¾ 86%ï¼Œå¹¶é€šè¿‡æµåœºä¸‹çš„å®éªŒè¯æ˜äº†ä¸€ç§ç»Ÿä¸€çš„æ°´åŠ¨åŠ›çº¦æŸå’Œä¸å¯é€†é”šå®šè¡Œä¸ºçš„è¡¨è¿°ã€‚', 'title_zh': 'Naupliusä¼˜åŒ–forè‡ªä¸»æ°´åŠ¨åŠ›å­¦'}
{'arxiv_id': 'arXiv:2510.15336', 'title': 'Adaptive Cost-Map-based Path Planning in Partially Unknown Environments with Movable Obstacles', 'authors': 'Liviu-Mihai Stan, Ranulfo Bezerra, Shotaro Kojima, Tsige Tadesse Alemayoh, Satoshi Tadokoro, Masashi Konyo, Kazunori Ohno', 'link': 'https://arxiv.org/abs/2510.15336', 'abstract': 'Reliable navigation in disaster-response and other unstructured indoor settings requires robots not only to avoid obstacles but also to recognise when those obstacles can be pushed aside. We present an adaptive, LiDAR and odometry-based path-planning framework that embeds this capability into the ROS2 Nav2 stack. A new Movable Obstacles Layer labels all LiDAR returns missing from a prior static map as tentatively movable and assigns a reduced traversal cost. A companion Slow-Pose Progress Checker monitors the ratio of commanded to actual velocity; when the robot slows appreciably, the local cost is raised from light to heavy, and on a stall to lethal, prompting the global planner to back out and re-route. Gazebo evaluations on a Scout Mini, spanning isolated objects and cluttered corridors, show higher goal-reach rates and fewer deadlocks than a no-layer baseline, with traversal times broadly comparable. Because the method relies only on planar scans and CPU-level computation, it suits resource-constrained search and rescue robots and integrates into heterogeneous platforms with minimal engineering. Overall, the results indicate that interaction-aware cost maps are a lightweight, ROS2-native extension for navigating among potentially movable obstacles in unstructured settings. The full implementation will be released as open source athttps://costmapthis http URL.', 'abstract_zh': 'å¯é çš„ç¾åŒºå“åº”å’Œå…¶å®ƒéç»“æ„åŒ–å®¤å†…å¯¼èˆªéœ€è¦æœºå™¨äººä¸ä»…é¿éšœï¼Œè¿˜èƒ½è¯†åˆ«å¯æ¨ç§»çš„éšœç¢ç‰©ã€‚ä¸€ç§é€‚åº”æ€§LiDARå’Œé‡Œç¨‹è®¡è·¯å¾„è§„åˆ’æ¡†æ¶åµŒå…¥ROS2 Nav2å †æ ˆä¸­ä»¥å®ç°è¿™ä¸€èƒ½åŠ›ã€‚ä¸€ä¸ªæ–°çš„å¯ç§»åŠ¨éšœç¢ç‰©å±‚å°†æ‰€æœ‰å…ˆå‰é™æ€åœ°å›¾ä¸­ç¼ºå¤±çš„LiDARå›æ³¢æ ‡è®°ä¸ºä¸´æ—¶å¯ç§»åŠ¨ï¼Œå¹¶åˆ†é…è¾ƒä½çš„ç©¿è¶Šæˆæœ¬ã€‚ä¸€ä¸ªé…å¥—çš„æ…¢é€Ÿä½å§¿è¿›å±•æ£€æŸ¥å™¨ç›‘æ§æŒ‡ä»¤é€Ÿåº¦ä¸å®é™…é€Ÿåº¦çš„æ¯”ä¾‹ï¼›å½“æœºå™¨äººå‡é€Ÿæ˜æ˜¾æ—¶ï¼Œå±€éƒ¨æˆæœ¬ä»è½»é‡çº§æé«˜åˆ°é‡åº¦ï¼Œåœæ»æ—¶æé«˜åˆ°è‡´å‘½çº§ï¼Œä¿ƒä½¿å…¨å±€è§„åˆ’å™¨å›é€€å¹¶é‡æ–°è§„åˆ’è·¯å¾„ã€‚é’ˆå¯¹Scout Miniçš„Gazeboè¯„ä¼°è¡¨æ˜ï¼Œåœ¨å­¤ç«‹ç‰©ä½“å’Œæ‚ä¹±èµ°å»Šåœºæ™¯ä¸‹ï¼Œä¸æ— å±‚åŸºçº¿ç›¸æ¯”ï¼Œç›®æ ‡å¯è¾¾ç‡æ›´é«˜ï¼Œæ­»é”æ›´å°‘ï¼Œç©¿è¶Šæ—¶é—´å¤§è‡´ç›¸å½“ã€‚ç”±äºè¯¥æ–¹æ³•ä»…ä¾èµ–äºå¹³é¢æ‰«æå’ŒCPUçº§è®¡ç®—ï¼Œå®ƒé€‚ç”¨äºèµ„æºå—é™çš„æœç´¢æ•‘æ´æœºå™¨äººï¼Œå¹¶å¯æœ€å°åŒ–å·¥ç¨‹é‡åœ°é›†æˆåˆ°å¼‚æ„å¹³å°ä¸Šã€‚æ€»ä½“è€Œè¨€ï¼Œç»“æœè¡¨æ˜ï¼Œäº¤äº’æ„è¯†æˆæœ¬å›¾æ˜¯å¯¼èˆªåˆ°æ½œåœ¨å¯ç§»åŠ¨éšœç¢ç‰©åŒºåŸŸçš„ä¸€ç§è½»é‡çº§ä¸”åŸç”Ÿçš„ROS2æ‰©å±•ã€‚å®Œæ•´çš„å®ç°å°†äºå…¬å¼€æºä»£ç å‘å¸ƒäºhttps://costmapthis http URLã€‚', 'title_zh': 'åŸºäºå¯ç§»åŠ¨éšœç¢ç‰©çš„éƒ¨åˆ†æœªçŸ¥ç¯å¢ƒè‡ªé€‚åº”æˆæœ¬å›¾è·¯å¾„è§„åˆ’'}
{'arxiv_id': 'arXiv:2510.15331', 'title': 'ASBI: Leveraging Informative Real-World Data for Active Black-Box Simulator Tuning', 'authors': 'Gahee Kim, Takamitsu Matsubara', 'link': 'https://arxiv.org/abs/2510.15331', 'abstract': 'Black-box simulators are widely used in robotics, but optimizing their parameters remains challenging due to inaccessible likelihoods. Simulation-Based Inference (SBI) tackles this issue using simulation-driven approaches, estimating the posterior from offline real observations and forward simulations. However, in black-box scenarios, preparing observations that contain sufficient information for parameter estimation is difficult due to the unknown relationship between parameters and observations. In this work, we present Active Simulation-Based Inference (ASBI), a parameter estimation framework that uses robots to actively collect real-world online data to achieve accurate black-box simulator tuning. Our framework optimizes robot actions to collect informative observations by maximizing information gain, which is defined as the expected reduction in Shannon entropy between the posterior and the prior. While calculating information gain requires the likelihood, which is inaccessible in black-box simulators, our method solves this problem by leveraging Neural Posterior Estimation (NPE), which leverages a neural network to learn the posterior estimator. Three simulation experiments quantitatively verify that our method achieves accurate parameter estimation, with posteriors sharply concentrated around the true parameters. Moreover, we show a practical application using a real robot to estimate the simulation parameters of cubic particles corresponding to two real objects, beads and gravel, with a bucket pouring action.', 'abstract_zh': 'é»‘ç®±æ¨¡æ‹Ÿå™¨çš„å‚æ•°ä¼°è®¡ï¼šä¸»åŠ¨æ¨¡æ‹Ÿæ¨ç†ï¼ˆASBIï¼‰', 'title_zh': 'ASBIï¼šåˆ©ç”¨ä¿¡æ¯ä¸°å¯Œçš„å®é™…æ•°æ®è¿›è¡Œæ´»æ€§é»‘ç›’æ¨¡æ‹Ÿå™¨è°ƒä¼˜'}
{'arxiv_id': 'arXiv:2510.15319', 'title': 'Traversability-aware Consistent Situational Graphs for Indoor Localization and Mapping', 'authors': 'Jeewon Kim, Minho Oh, Hyun Myung', 'link': 'https://arxiv.org/abs/2510.15319', 'abstract': 'Scene graphs enhance 3D mapping capabilities in robotics by understanding the relationships between different spatial elements, such as rooms and objects. Recent research extends scene graphs to hierarchical layers, adding and leveraging constraints across these levels. This approach is tightly integrated with pose-graph optimization, improving both localization and mapping accuracy simultaneously. However, when segmenting spatial characteristics, consistently recognizing rooms becomes challenging due to variations in viewpoints and limited field of view (FOV) of sensors. For example, existing real-time approaches often over-segment large rooms into smaller, non-functional spaces that are not useful for localization and mapping due to the time-dependent method. Conversely, their voxel-based room segmentation method often under-segment in complex cases like not fully enclosed 3D space that are non-traversable for ground robots or humans, leading to false constraints in pose-graph optimization. We propose a traversability-aware room segmentation method that considers the interaction between robots and surroundings, with consistent feasibility of traversability information. This enhances both the semantic coherence and computational efficiency of pose-graph optimization. Improved performance is demonstrated through the re-detection frequency of the same rooms in a dataset involving repeated traversals of the same space along the same path, as well as the optimization time consumption.', 'abstract_zh': 'åœºæ™¯å›¾å¢å¼ºæœºå™¨äºº3Då»ºå›¾èƒ½åŠ›é€šè¿‡ç†è§£ä¸åŒç©ºé—´å…ƒç´ ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶å°†å…¶æ‰©å±•è‡³å±‚æ¬¡ç»“æ„ï¼Œæé«˜åŒæ—¶å®šä½ä¸å»ºå›¾çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚ç„¶è€Œï¼Œåœ¨åˆ†å‰²ç©ºé—´ç‰¹å¾æ—¶ï¼Œä¸€è‡´åœ°è¯†åˆ«æˆ¿é—´ç”±äºè§†è§’å˜åŒ–å’Œä¼ æ„Ÿå™¨æœ‰é™è§†åœºï¼ˆFOVï¼‰è€Œå˜å¾—å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è€ƒè™‘æœºå™¨äººä¸å‘¨å›´ç¯å¢ƒäº¤äº’çš„å¯é€šè¡Œæ€§æ„ŸçŸ¥æˆ¿é—´åˆ†å‰²æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç¡®ä¿äº†å¯é€šè¡Œæ€§ä¿¡æ¯çš„æŒç»­ä¸€è‡´æ€§ï¼Œä»è€Œæé«˜å§¿æ€å›¾ä¼˜åŒ–çš„è¯­ä¹‰è¿è´¯æ€§å’Œè®¡ç®—æ•ˆç‡ã€‚æ€§èƒ½æ”¹è¿›é€šè¿‡åŒä¸€ç©ºé—´æ²¿ç›¸åŒè·¯å¾„å¤šæ¬¡ç©¿è¶Šçš„æ•°æ®é›†ä¸­çš„ç›¸åŒæˆ¿é—´æ£€æµ‹é¢‘ç‡å’Œä¼˜åŒ–æ—¶é—´æ¶ˆè€—å¾—ä»¥éªŒè¯ã€‚', 'title_zh': 'å¯ç©¿è¶Šæ€§æ„ŸçŸ¥ä¸€è‡´æƒ…å¢ƒå›¾ç”¨äºå®¤å†…å®šä½ä¸å»ºå›¾'}
{'arxiv_id': 'arXiv:2510.15229', 'title': 'A Generalized Sylvester-Fermat-Torricelli problem with application in disaster relief operations by UAVs', 'authors': 'Sina Kazemdehbashi, Yanchao Liu, Boris S. Mordukhovich', 'link': 'https://arxiv.org/abs/2510.15229', 'abstract': 'Natural and human-made disasters can cause severe devastation and claim thousands of lives worldwide. Therefore, developing efficient methods for disaster response and management is a critical task for relief teams. One of the most essential components of effective response is the rapid collection of information about affected areas, damages, and victims. More data translates into better coordination, faster rescue operations, and ultimately, more lives saved. However, in some disasters, such as earthquakes, the communication infrastructure is often partially or completely destroyed, making it extremely difficult for victims to send distress signals and for rescue teams to locate and assist them in time. Unmanned Aerial Vehicles (UAVs) have emerged as valuable tools in such scenarios. In particular, a fleet of UAVs can be dispatched from a mobile station to the affected area to facilitate data collection and establish temporary communication networks. Nevertheless, real-world deployment of UAVs faces several challenges, with adverse weather conditions--especially wind--being among the most significant. To address this, we develop a novel mathematical framework to determine the optimal location of a mobile UAV station while explicitly accounting for the heterogeneity of the UAVs and the effect of wind. In particular, we generalize the Sylvester problem to introduce the Sylvester-Fermat-Torricelli (SFT) problem, which captures complex factors such as wind influence, UAV heterogeneity, and back-and-forth motion within a unified framework. The proposed framework enhances the practicality of UAV-based disaster response planning by accounting for real-world factors such as wind and UAV heterogeneity. Experimental results demonstrate that it can reduce wasted operational time by up to 84%, making post-disaster missions significantly more efficient and effective.', 'abstract_zh': 'è‡ªç„¶å’Œäººä¸ºç¾å®³ä¼šå¯¼è‡´ä¸¥é‡çš„ç ´åå¹¶å¤ºèµ°æ•°åƒæ¡ç”Ÿå‘½ã€‚å› æ­¤ï¼Œå¯¹äºæ•‘æ´å›¢é˜Ÿè€Œè¨€ï¼Œå¼€å‘é«˜æ•ˆçš„ç¾å®³å“åº”å’Œç®¡ç†æ–¹æ³•æ˜¯ä¸€é¡¹å…³é”®ä»»åŠ¡ã€‚æœ‰æ•ˆå“åº”çš„æ ¸å¿ƒä¹‹ä¸€æ˜¯å¿«é€Ÿæ”¶é›†å—ç¾åŒºåŸŸã€æŸå¤±å’Œå—å®³è€…çš„ä¿¡æ¯ã€‚æ›´å¤šä¿¡æ¯æ„å‘³ç€æ›´å¥½çš„åè°ƒã€æ›´å¿«çš„æ•‘æ´è¡ŒåŠ¨ï¼Œæœ€ç»ˆæ‹¯æ•‘æ›´å¤šç”Ÿå‘½ã€‚ç„¶è€Œï¼Œåœ¨åœ°éœ‡ç­‰ç¾å®³ä¸­ï¼Œé€šä¿¡åŸºç¡€è®¾æ–½ç»å¸¸éƒ¨åˆ†æˆ–å®Œå…¨è¢«ç ´åï¼Œä½¿å¾—å—å®³è€…å‘é€æ±‚æ•‘ä¿¡å·å’Œæ•‘æ´é˜Ÿä¼åŠæ—¶å®šä½å¹¶æä¾›æ´åŠ©å˜å¾—æå…¶å›°éš¾ã€‚æ— äººé©¾é©¶èˆªç©ºå™¨ï¼ˆUAVï¼‰åœ¨è¿™ç§æƒ…å†µä¸‹æˆä¸ºäº†æœ‰ä»·å€¼çš„å·¥å…·ã€‚ç‰¹åˆ«æ˜¯åœ¨è¿™ç§åœºæ™¯ä¸­ï¼Œå¯ä»¥æ´¾é£ä¸€ç³»åˆ—UAVä»ç§»åŠ¨ç«™å‡ºå‘åˆ°è¾¾å—ç¾åŒºåŸŸä»¥ä¿ƒè¿›æ•°æ®æ”¶é›†å¹¶å»ºç«‹ä¸´æ—¶é€šä¿¡ç½‘ç»œã€‚ç„¶è€Œï¼Œå®é™…éƒ¨ç½²UAVé¢ä¸´ç€ä¸€ç³»åˆ—æŒ‘æˆ˜ï¼Œå…¶ä¸­æœ€ä¸¥å³»çš„æ˜¯æ¶åŠ£å¤©æ°”æ¡ä»¶ï¼Œç‰¹åˆ«æ˜¯é£åŠ›ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªæ–°é¢–çš„æ•°å­¦æ¡†æ¶ï¼Œä»¥ç¡®å®šç§»åŠ¨UAVç«™çš„æœ€ä½³ä½ç½®ï¼ŒåŒæ—¶æ˜ç¡®è€ƒè™‘äº†UAVçš„å¼‚è´¨æ€§å’Œé£çš„å½±å“ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†å¡ç“¦å°”å¾·é—®é¢˜æ¨å¹¿ä¸ºå¼•å…¥å¡ç“¦å°”å¾·-è´¹é©¬-æ‰˜é‡ŒåŸƒåˆ©ï¼ˆSFTï¼‰é—®é¢˜ï¼Œè¯¥é—®é¢˜åœ¨ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ä¸­æ•æ‰äº†é£çš„å½±å“ã€UAVçš„å¼‚è´¨æ€§å’Œå¾€è¿”è¿åŠ¨ç­‰å¤æ‚å› ç´ ã€‚æ‰€æå‡ºæ¡†æ¶é€šè¿‡è€ƒè™‘å®é™…å› ç´ ï¼Œå¦‚é£å’ŒUAVå¼‚è´¨æ€§ï¼Œæé«˜äº†åŸºäºUAVçš„ç¾å®³å“åº”è§„åˆ’çš„å®ç”¨æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå®ƒå¯ä»¥å°†æ— æ•ˆæ“ä½œæ—¶é—´å‡å°‘å¤šè¾¾84%ï¼Œä½¿ç¾å®³åçš„ä»»åŠ¡æ˜¾è‘—æ›´é«˜æ•ˆå’Œæ›´æœ‰æˆæ•ˆã€‚', 'title_zh': 'å¹¿ä¹‰èµ›å°”ç»´æ–¯ç‰¹-è´¹é©¬-æ‰˜é‡Œåˆ‡åˆ©é—®é¢˜åŠå…¶åœ¨æ— äººæœºæ•‘ç¾ä¸­çš„åº”ç”¨'}
{'arxiv_id': 'arXiv:2510.15226', 'title': 'PolyFly: Polytopic Optimal Planning for Collision-Free Cable-Suspended Aerial Payload Transportation', 'authors': 'Mrunal Sarvaiya, Guanrui Li, Giuseppe Loianno', 'link': 'https://arxiv.org/abs/2510.15226', 'abstract': 'Aerial transportation robots using suspended cables have emerged as versatile platforms for disaster response and rescue operations. To maximize the capabilities of these systems, robots need to aggressively fly through tightly constrained environments, such as dense forests and structurally unsafe buildings, while minimizing flight time and avoiding obstacles. Existing methods geometrically over-approximate the vehicle and obstacles, leading to conservative maneuvers and increased flight times. We eliminate these restrictions by proposing PolyFly, an optimal global planner which considers a non-conservative representation for aerial transportation by modeling each physical component of the environment, and the robot (quadrotor, cable and payload), as independent polytopes. We further increase the model accuracy by incorporating the attitude of the physical components by constructing orientation-aware polytopes. The resulting optimal control problem is efficiently solved by converting the polytope constraints into smooth differentiable constraints via duality theory. We compare our method against the existing state-of-the-art approach in eight maze-like environments and show that PolyFly produces faster trajectories in each scenario. We also experimentally validate our proposed approach on a real quadrotor with a suspended payload, demonstrating the practical reliability and accuracy of our method.', 'abstract_zh': 'æ‚¬ç´¢æ¶è®¾çš„é£è¡Œæœºå™¨äººå·²å‘å±•æˆä¸ºç¾å®³å“åº”å’Œæ•‘æ´æ“ä½œä¸­å¤šåŠŸèƒ½çš„å¹³å°ã€‚ä¸ºæœ€å¤§é™åº¦åœ°æé«˜è¿™äº›ç³»ç»Ÿçš„æ€§èƒ½ï¼Œæœºå™¨äººéœ€è¦åœ¨è¯¸å¦‚å¯†é›†æ£®æ—å’Œç»“æ„ä¸å®‰å…¨å»ºç­‘ç­‰ä¸¥è‹›å—é™ç¯å¢ƒä¸­è¿›è¡Œé«˜æ•ˆçš„é£è¡Œï¼ŒåŒæ—¶æœ€å°åŒ–é£è¡Œæ—¶é—´å’Œé¿å…éšœç¢ã€‚ç°æœ‰æ–¹æ³•åœ¨å‡ ä½•ä¸Šè¿‡åº¦è¿‘ä¼¼æ— äººæœºå’Œéšœç¢ç‰©ï¼Œå¯¼è‡´ä¿å®ˆçš„æ“æ§æ–¹å¼å’Œå¢åŠ çš„é£è¡Œæ—¶é—´ã€‚æˆ‘ä»¬é€šè¿‡æå‡ºPolyFlyï¼Œä¸€ä¸ªå…¨å±€æœ€ä¼˜è§„åˆ’å™¨ï¼Œæ¥æ¶ˆé™¤è¿™äº›é™åˆ¶ã€‚PolyFlyè€ƒè™‘äº†éä¿å®ˆçš„è¡¨ç¤ºæ–¹æ³•ï¼Œé€šè¿‡å»ºæ¨¡ç¯å¢ƒä¸­çš„æ¯ä¸ªç‰©ç†ç»„ä»¶ä»¥åŠæ— äººæœºï¼ˆå››æ—‹ç¿¼æœºã€æ‚¬ç´¢å’Œè½½è·ï¼‰ä¸ºç‹¬ç«‹çš„å¤šé¢ä½“æ¥è¿›è¡Œç©ºä¸­è¿è¾“ã€‚ä¸ºè¿›ä¸€æ­¥æé«˜å»ºæ¨¡å‡†ç¡®æ€§ï¼Œæˆ‘ä»¬é€šè¿‡æ„å»ºå§¿æ€æ„ŸçŸ¥çš„å¤šé¢ä½“æ¥èå…¥ç‰©ç†ç»„ä»¶çš„å§¿æ€ã€‚é€šè¿‡äºŒé‡æ€§ç†è®ºå°†å¤šé¢ä½“çº¦æŸè½¬åŒ–ä¸ºå¹³æ»‘å¯å¾®çº¦æŸï¼Œä»è€Œé«˜æ•ˆåœ°æ±‚è§£æœ€ä¼˜æ§åˆ¶é—®é¢˜ã€‚æˆ‘ä»¬åœ¨å…«ä¸ªè¿·å®«æ ·ç¯å¢ƒä¸­ä¸ç°æœ‰æœ€ä½³æ–¹æ³•è¿›è¡Œäº†å¯¹æ¯”ï¼Œç»“æœæ˜¾ç¤ºPolyFlyåœ¨æ¯ç§æƒ…æ™¯ä¸‹å‡äº§ç”Ÿæ›´å¿«çš„è½¨è¿¹ã€‚æˆ‘ä»¬è¿˜åœ¨å®é™…çš„æ‚¬ç´¢å››æ—‹ç¿¼æœºä¸Šè¿›è¡Œäº†å®éªŒéªŒè¯ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•çš„å®ç”¨å¯é æ€§å’Œå‡†ç¡®æ€§ã€‚', 'title_zh': 'PolyFly: å¤šé¢ä½“æœ€ä¼˜è§„åˆ’å®ç°æ— ç¢°æ’çš„æ‚¬ç´¢ç©ºä¸­è¿è½½è´§ç‰©ä¼ è¾“'}
{'arxiv_id': 'arXiv:2510.15220', 'title': 'LVI-Q: Robust LiDAR-Visual-Inertial-Kinematic Odometry for Quadruped Robots Using Tightly-Coupled and Efficient Alternating Optimization', 'authors': 'Kevin Christiansen Marsim, Minho Oh, Byeongho Yu, Seungjae Lee, I Made Aswin Nahrendra, Hyungtae Lim, Hyun Myung', 'link': 'https://arxiv.org/abs/2510.15220', 'abstract': 'Autonomous navigation for legged robots in complex and dynamic environments relies on robust simultaneous localization and mapping (SLAM) systems to accurately map surroundings and localize the robot, ensuring safe and efficient operation. While prior sensor fusion-based SLAM approaches have integrated various sensor modalities to improve their robustness, these algorithms are still susceptible to estimation drift in challenging environments due to their reliance on unsuitable fusion strategies. Therefore, we propose a robust LiDAR-visual-inertial-kinematic odometry system that integrates information from multiple sensors, such as a camera, LiDAR, inertial measurement unit (IMU), and joint encoders, for visual and LiDAR-based odometry estimation. Our system employs a fusion-based pose estimation approach that runs optimization-based visual-inertial-kinematic odometry (VIKO) and filter-based LiDAR-inertial-kinematic odometry (LIKO) based on measurement availability. In VIKO, we utilize the footpreintegration technique and robust LiDAR-visual depth consistency using superpixel clusters in a sliding window optimization. In LIKO, we incorporate foot kinematics and employ a point-toplane residual in an error-state iterative Kalman filter (ESIKF). Compared with other sensor fusion-based SLAM algorithms, our approach shows robust performance across public and longterm datasets.', 'abstract_zh': 'å¤æ‚åŠ¨æ€ç¯å¢ƒä¸­è…¿å¼æœºå™¨äººè‡ªä¸»å¯¼èˆªä¾èµ–äº robust åŒæ—¶å®šä½ä¸å»ºå›¾ (SLAM) ç³»ç»Ÿï¼Œä»¥å‡†ç¡®åœ°æ˜ å°„ç¯å¢ƒå¹¶å®šä½æœºå™¨äººï¼Œç¡®ä¿å®‰å…¨é«˜æ•ˆçš„è¿è¡Œã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ robust LiDAR-è§†è§‰-æƒ¯æ€§-è¿åŠ¨å­¦é‡Œç¨‹è®¡ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿç»“åˆäº†å¦‚ç›¸æœºã€LiDARã€æƒ¯æ€§æµ‹é‡å•å…ƒï¼ˆIMUï¼‰å’Œå…³èŠ‚ç¼–ç å™¨ç­‰å¤šç§ä¼ æ„Ÿå™¨ä¿¡æ¯ï¼Œç”¨äºåŸºäºè§†è§‰å’ŒLiDARçš„é‡Œç¨‹è®¡ä¼°è®¡ã€‚æˆ‘ä»¬çš„ç³»ç»Ÿé‡‡ç”¨åŸºäºèåˆçš„å§¿æ€ä¼°è®¡æ–¹æ³•ï¼Œæ ¹æ®ä¸åŒä¼ æ„Ÿå™¨æµ‹é‡æ•°æ®çš„å¯ç”¨æ€§è¿è¡Œä¼˜åŒ–åŸºäºè§†è§‰-æƒ¯æ€§-è¿åŠ¨å­¦é‡Œç¨‹è®¡ï¼ˆVIKOï¼‰å’ŒåŸºäºæ»¤æ³¢å™¨çš„LiDAR-æƒ¯æ€§-è¿åŠ¨å­¦é‡Œç¨‹è®¡ï¼ˆLIKOï¼‰ç®—æ³•ã€‚åœ¨VIKOä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨è¶³éƒ¨é¢„ç§¯åˆ†æŠ€æœ¯å’Œæ»‘çª—ä¼˜åŒ–ä¸­çš„é²æ£’LiDAR-è§†è§‰æ·±åº¦ä¸€è‡´æ€§ï¼ˆåŸºäºè¶…åƒç´ ç°‡ï¼‰ã€‚åœ¨LIKOä¸­ï¼Œæˆ‘ä»¬ç»“åˆäº†è¶³éƒ¨è¿åŠ¨å­¦ï¼Œå¹¶åœ¨é”™è¯¯çŠ¶æ€è¿­ä»£å¡å°”æ›¼æ»¤æ³¢å™¨ï¼ˆESIKFï¼‰ä¸­ä½¿ç”¨ç‚¹åˆ°é¢æ®‹å·®ã€‚ä¸å…¶ä»–åŸºäºä¼ æ„Ÿå™¨èåˆçš„SLAMç®—æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å…¬å…±æ•°æ®é›†å’Œé•¿æœŸæ•°æ®é›†ä¸Šå‡è¡¨ç°å‡º robust æ€§èƒ½ã€‚', 'title_zh': 'LVI-Qï¼š quadrupedæœºå™¨äººåŸºäºç´§å¯†è€¦åˆå’Œé«˜æ•ˆäº¤æ›¿ä¼˜åŒ–çš„é²æ£’æ¿€å…‰é›·è¾¾-è§†è§‰-æƒ¯æ€§-åŠ¨åŠ›å­¦é‡Œç¨‹è®¡'}
{'arxiv_id': 'arXiv:2510.15199', 'title': 'Lagrange-PoincarÃ©-Kepler Equations of Disturbed Space-Manipulator Systems in Orbit', 'authors': 'Borna Monazzah Moghaddam, Robin Chhabra', 'link': 'https://arxiv.org/abs/2510.15199', 'abstract': "This article presents an extension of the Lagrange-Poincare Equations (LPE) to model the dynamics of spacecraft-manipulator systems operating within a non-inertial orbital reference frame. Building upon prior formulations of LPE for vehicle-manipulator systems, the proposed framework, termed the Lagrange-Poincare-Kepler Equations (LPKE), incorporates the coupling between spacecraft attitude dynamics, orbital motion, and manipulator kinematics. The formalism combines the Euler-Poincare equations for the base spacecraft, Keplerian orbital dynamics for the reference frame, and reduced Euler-Lagrange equations for the manipulator's shape space, using an exponential joint parametrization. Leveraging the Lagrange-d'Alembert principle on principal bundles, we derive novel closed-form structural matrices that explicitly capture the effects of orbital disturbances and their dynamic coupling with the manipulator system. The LPKE framework also systematically includes externally applied, symmetry-breaking wrenches, allowing for immediate integration into hardware-in-the-loop simulations and model-based control architectures for autonomous robotic operations in the orbital environment. To illustrate the effectiveness of the proposed model and its numerical superiority, we present a simulation study analyzing orbital effects on a 7-degree-of-freedom manipulator mounted on a spacecraft.", 'abstract_zh': 'è¿™ç¯‡æ–‡ç« æå‡ºäº†Lagrange-Poincare-Kepleræ–¹ç¨‹ï¼ˆLPKEï¼‰ä»¥æ‰©å±•æ‹‰æ ¼æœ—æ—¥-åºåŠ è±æ–¹ç¨‹ï¼ˆLPEï¼‰ï¼Œç”¨äºå»ºæ¨¡åœ¨éæƒ¯æ€§è½¨é“å‚è€ƒæ¡†æ¶å†…è¿è¡Œçš„èˆªå¤©å™¨- manipulator ç³»ç»Ÿçš„åŠ¨åŠ›å­¦ã€‚åœ¨æ­¤å‰å¯¹è½¦è¾†- manipulator ç³»ç»Ÿçš„LPEè¡¨è¿°çš„åŸºç¡€ä¸Šï¼Œæå‡ºçš„æ¡†æ¶ç»“åˆäº†èˆªå¤©å™¨å§¿æ€åŠ¨åŠ›å­¦ã€è½¨é“è¿åŠ¨å’Œ manipulator è¿åŠ¨å­¦ï¼Œä½¿ç”¨æŒ‡æ•°å…³èŠ‚å‚æ•°åŒ–ã€‚é€šè¿‡åœ¨ä¸»ä¸›ä¸Šåº”ç”¨æ‹‰æ ¼æœ—æ—¥-è¾¾æœ—è´å°”åŸç†ï¼Œæˆ‘ä»¬æ¨å¯¼å‡ºæ–°é¢–çš„é—­å¼ç»“æ„çŸ©é˜µï¼Œæ˜ç¡®åœ°æ•æ‰è½¨é“æ‰°åŠ¨åŠå…¶ä¸ manipulator ç³»ç»Ÿçš„åŠ¨åŠ›å­¦è€¦åˆæ•ˆåº”ã€‚LPKEæ¡†æ¶ç³»ç»Ÿåœ°åŒ…å«äº†å¤–éƒ¨æ–½åŠ çš„ã€ç ´åå¯¹ç§°æ€§çš„åŠ›å¶çŸ©ï¼Œä½¿å…¶èƒ½å¤Ÿç›´æ¥é›†æˆåˆ°ç¡¬ä»¶åœ¨ç¯ä»¿çœŸå’ŒåŸºäºæ¨¡å‹çš„æ§åˆ¶æ¶æ„ä¸­ï¼Œä»¥å®ç°è½¨é“ç¯å¢ƒä¸­çš„è‡ªä¸»æœºå™¨äººæ“ä½œã€‚ä¸ºäº†é˜æ˜æ‰€æå‡ºæ¨¡å‹çš„æœ‰æ•ˆæ€§å’Œæ•°å€¼ä¼˜åŠ¿ï¼Œæˆ‘ä»¬è¿›è¡Œäº†ä¸€é¡¹ä»¿çœŸç ”ç©¶ï¼Œåˆ†æäº†è½¨é“æ•ˆåº”å¯¹é™„ç€åœ¨èˆªå¤©å™¨ä¸Šçš„7è‡ªç”±åº¦ manipulator çš„å½±å“ã€‚', 'title_zh': 'è½¨é“ä¸Šå—æ‰°ç©ºé—´æ“ä½œç³»ç»Ÿçš„æ‹‰æ ¼æœ—æ—¥-åºåŠ è±-å¼€æ™®å‹’æ–¹ç¨‹'}
{'arxiv_id': 'arXiv:2510.15189', 'title': 'RM-RL: Role-Model Reinforcement Learning for Precise Robot Manipulation', 'authors': 'Xiangyu Chen, Chuhao Zhou, Yuxi Liu, Jianfei Yang', 'link': 'https://arxiv.org/abs/2510.15189', 'abstract': "Precise robot manipulation is critical for fine-grained applications such as chemical and biological experiments, where even small errors (e.g., reagent spillage) can invalidate an entire task. Existing approaches often rely on pre-collected expert demonstrations and train policies via imitation learning (IL) or offline reinforcement learning (RL). However, obtaining high-quality demonstrations for precision tasks is difficult and time-consuming, while offline RL commonly suffers from distribution shifts and low data efficiency. We introduce a Role-Model Reinforcement Learning (RM-RL) framework that unifies online and offline training in real-world environments. The key idea is a role-model strategy that automatically generates labels for online training data using approximately optimal actions, eliminating the need for human demonstrations. RM-RL reformulates policy learning as supervised training, reducing instability from distribution mismatch and improving efficiency. A hybrid training scheme further leverages online role-model data for offline reuse, enhancing data efficiency through repeated sampling. Extensive experiments show that RM-RL converges faster and more stably than existing RL methods, yielding significant gains in real-world manipulation: 53% improvement in translation accuracy and 20% in rotation accuracy. Finally, we demonstrate the successful execution of a challenging task, precisely placing a cell plate onto a shelf, highlighting the framework's effectiveness where prior methods fail.", 'abstract_zh': 'ç²¾ç¡®æœºå™¨äººæ“ä½œå¯¹äºåŒ–å­¦å’Œç”Ÿç‰©å®éªŒç­‰ç²¾ç»†åº”ç”¨è‡³å…³é‡è¦ï¼Œå³ä½¿æ˜¯éå¸¸å°çš„é”™è¯¯ï¼ˆå¦‚è¯•å‰‚æº¢å‡ºï¼‰ä¹Ÿä¼šä½¿æ•´ä¸ªä»»åŠ¡å¤±æ•ˆã€‚ç°æœ‰çš„æ–¹æ³•é€šå¸¸ä¾èµ–äºé¢„å…ˆæ”¶é›†çš„ä¸“å®¶æ¼”ç¤ºï¼Œå¹¶é€šè¿‡æ¨¡ä»¿å­¦ä¹ ï¼ˆILï¼‰æˆ–ç¦»çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è®­ç»ƒç­–ç•¥ã€‚ç„¶è€Œï¼Œä¸ºç²¾ç¡®ä»»åŠ¡è·å–é«˜è´¨é‡çš„æ¼”ç¤ºæ˜¯å›°éš¾ä¸”è€—æ—¶çš„ï¼Œè€Œç¦»çº¿RLé€šå¸¸ä¼šé­å—åˆ†å¸ƒåç§»å’Œä½æ•°æ®æ•ˆç‡çš„é—®é¢˜ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªè§’è‰²æ¨¡å‹å¼ºåŒ–å­¦ä¹ ï¼ˆRM-RLï¼‰æ¡†æ¶ï¼Œå°†åœ¨çº¿å’Œç¦»çº¿è®­ç»ƒç»Ÿä¸€äºç°å®ç¯å¢ƒã€‚å…³é”®æ€æƒ³æ˜¯è§’è‰²æ¨¡å‹ç­–ç•¥ï¼Œè¯¥ç­–ç•¥å¯ä»¥è‡ªåŠ¨ä¸ºåœ¨çº¿è®­ç»ƒæ•°æ®ç”Ÿæˆæ ‡ç­¾ï¼Œä»è€Œæ¶ˆé™¤å¯¹äººç±»æ¼”ç¤ºçš„éœ€è¦ã€‚RM-RLå°†ç­–ç•¥å­¦ä¹ é‡æ–°è¡¨è¿°ä¸ºç›‘ç£è®­ç»ƒï¼Œå‡å°‘äº†åˆ†å¸ƒä¸åŒ¹é…å¸¦æ¥çš„ä¸ç¨³å®šæ€§ï¼Œæé«˜äº†æ•ˆç‡ã€‚æ··åˆè®­ç»ƒæ–¹æ¡ˆè¿›ä¸€æ­¥åˆ©ç”¨åœ¨çº¿è§’è‰²æ¨¡å‹æ•°æ®è¿›è¡Œç¦»çº¿é‡ç”¨ï¼Œé€šè¿‡é‡å¤é‡‡æ ·æé«˜æ•°æ®æ•ˆç‡ã€‚å¤§é‡å®éªŒè¯æ˜ï¼ŒRM-RLæ¯”ç°æœ‰RLæ–¹æ³•æ›´å¿«ã€æ›´ç¨³å®šåœ°æ”¶æ•›ï¼Œå®ç°åœ¨ç°å®ä¸–ç•Œæ“ä½œä¸­çš„æ˜¾è‘—æå‡ï¼šå¹³ç§»ç²¾åº¦æé«˜53%ï¼Œæ—‹è½¬ç²¾åº¦æé«˜20%ã€‚æœ€åï¼Œæˆ‘ä»¬å±•ç¤ºäº†ç²¾ç¡®å°†ç»†èƒæ¿æ”¾ç½®åˆ°æ¶å­ä¸Šçš„å¤æ‚ä»»åŠ¡çš„æˆåŠŸæ‰§è¡Œï¼Œçªæ˜¾äº†è¯¥æ¡†æ¶åœ¨å…ˆå‰æ–¹æ³•å¤±æ•ˆçš„åœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§ã€‚', 'title_zh': 'RM-RL: åŸºäºè§’è‰²æ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ ç²¾ç¡®æœºå™¨äººæ“ä½œ'}
