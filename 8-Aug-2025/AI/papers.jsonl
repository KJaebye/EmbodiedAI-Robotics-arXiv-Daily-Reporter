{'arxiv_id': 'arXiv:2508.05622', 'title': 'Simulating Human-Like Learning Dynamics with LLM-Empowered Agents', 'authors': 'Yu Yuan, Lili Zhao, Wei Chen, Guangting Zheng, Kai Zhang, Mengdi Zhang, Qi Liu', 'link': 'https://arxiv.org/abs/2508.05622', 'abstract': 'Capturing human learning behavior based on deep learning methods has become a major research focus in both psychology and intelligent systems. Recent approaches rely on controlled experiments or rule-based models to explore cognitive processes. However, they struggle to capture learning dynamics, track progress over time, or provide explainability. To address these challenges, we introduce LearnerAgent, a novel multi-agent framework based on Large Language Models (LLMs) to simulate a realistic teaching environment. To explore human-like learning dynamics, we construct learners with psychologically grounded profiles-such as Deep, Surface, and Lazy-as well as a persona-free General Learner to inspect the base LLM\'s default behavior. Through weekly knowledge acquisition, monthly strategic choices, periodic tests, and peer interaction, we can track the dynamic learning progress of individual learners over a full-year journey. Our findings are fourfold: 1) Longitudinal analysis reveals that only Deep Learner achieves sustained cognitive growth. Our specially designed "trap questions" effectively diagnose Surface Learner\'s shallow knowledge. 2) The behavioral and cognitive patterns of distinct learners align closely with their psychological profiles. 3) Learners\' self-concept scores evolve realistically, with the General Learner developing surprisingly high self-efficacy despite its cognitive limitations. 4) Critically, the default profile of base LLM is a "diligent but brittle Surface Learner"-an agent that mimics the behaviors of a good student but lacks true, generalizable understanding. Extensive simulation experiments demonstrate that LearnerAgent aligns well with real scenarios, yielding more insightful findings about LLMs\' behavior.', 'abstract_zh': '基于深度学习方法捕捉人类学习行为已成为心理学和智能系统领域的主要研究焦点。为了探索类似人类的学习动态，我们构建了具有心理依据的学习者画像（如深度学习者、表层学习者和懒惰学习者），并设计了一个无人物设定的一般学习者以考察基础大语言模型的默认行为。通过每周知识获取、每月策略选择、定期测验以及同伴互动，我们能够追踪学习者在全年过程中的动态学习进展。我们的发现包括四个方面：1）纵向分析表明只有深度学习者实现了持续的认知增长，我们特别设计的“陷阱问题”有效地诊断了表层学习者的浅显知识。2）不同学习者的行为和认知模式与其心理特征高度一致。3）学习者的自我概念评分真实地反映了变化，尽管基础大语言模型的认知局限，一般学习者的自我效能感却异常高。4）重要的是，基础大语言模型的默认配置是“勤奋但脆弱的表层学习者”——它模仿了好学生的行为，但缺乏真正可泛化的理解。大量的模拟实验表明，LearnerAgent 与实际场景高度契合，为其行为提供了更深刻的洞见。', 'title_zh': '利用大语言模型赋能的代理模拟人类-like 学习动态'}
{'arxiv_id': 'arXiv:2508.05619', 'title': 'The Missing Reward: Active Inference in the Era of Experience', 'authors': 'Bo Wen', 'link': 'https://arxiv.org/abs/2508.05619', 'abstract': "This paper argues that Active Inference (AIF) provides a crucial foundation for developing autonomous AI agents capable of learning from experience without continuous human reward engineering. As AI systems begin to exhaust high-quality training data and rely on increasingly large human workforces for reward design, the current paradigm faces significant scalability challenges that could impede progress toward genuinely autonomous intelligence. The proposal for an ``Era of Experience,'' where agents learn from self-generated data, is a promising step forward. However, this vision still depends on extensive human engineering of reward functions, effectively shifting the bottleneck from data curation to reward curation. This highlights what we identify as the \\textbf{grounded-agency gap}: the inability of contemporary AI systems to autonomously formulate, adapt, and pursue objectives in response to changing circumstances. We propose that AIF can bridge this gap by replacing external reward signals with an intrinsic drive to minimize free energy, allowing agents to naturally balance exploration and exploitation through a unified Bayesian objective. By integrating Large Language Models as generative world models with AIF's principled decision-making framework, we can create agents that learn efficiently from experience while remaining aligned with human values. This synthesis offers a compelling path toward AI systems that can develop autonomously while adhering to both computational and physical constraints.", 'abstract_zh': 'AIF为自主AI agents从经验中学习提供关键基础：从数据密集型时代过渡到经验时代', 'title_zh': '缺失的奖励：体验时代的学习推断'}
{'arxiv_id': 'arXiv:2508.05557', 'title': 'MV-Debate: Multi-view Agent Debate with Dynamic Reflection Gating for Multimodal Harmful Content Detection in Social Media', 'authors': 'Rui Lu, Jinhe Bi, Yunpu Ma, Feng Xiao, Yuntao Du, Yijun Tian', 'link': 'https://arxiv.org/abs/2508.05557', 'abstract': 'Social media has evolved into a complex multimodal environment where text, images, and other signals interact to shape nuanced meanings, often concealing harmful intent. Identifying such intent, whether sarcasm, hate speech, or misinformation, remains challenging due to cross-modal contradictions, rapid cultural shifts, and subtle pragmatic cues. To address these challenges, we propose MV-Debate, a multi-view agent debate framework with dynamic reflection gating for unified multimodal harmful content detection. MV-Debate assembles four complementary debate agents, a surface analyst, a deep reasoner, a modality contrast, and a social contextualist, to analyze content from diverse interpretive perspectives. Through iterative debate and reflection, the agents refine responses under a reflection-gain criterion, ensuring both accuracy and efficiency. Experiments on three benchmark datasets demonstrate that MV-Debate significantly outperforms strong single-model and existing multi-agent debate baselines. This work highlights the promise of multi-agent debate in advancing reliable social intent detection in safety-critical online contexts.', 'abstract_zh': '社会媒体已演变成一个多模态的复杂环境，其中文本、图像和其他信号相互作用以塑造复杂的含义，常常掩盖潜在的危害意图。识别这种意图，无论是讽刺、仇恨言论还是 misinformation，由于跨模态矛盾、快速的文化变迁以及微妙的语用线索，仍然具有挑战性。为应对这些挑战，我们提出了一种名为MV-Debate的多视角代理辩论框架，该框架通过动态反思门控实现统一的多模态有害内容检测。MV-Debate结合了四位互补的辩论代理，包括表层分析师、深层推理者、模态对比和社交语境主义者，从多角度分析内容。通过迭代辩论和反思，代理在反思增益准则下精炼响应，确保准确性和高效性。在三个基准数据集上的实验表明，MV-Debate显著优于强大的单模型和现有的多代理辩论基线。这项工作强调了多代理辩论在安全关键的在线环境中促进可靠的社会意图检测方面的潜力。', 'title_zh': 'MV-Debate：多视角代理辩论with动态反思门控用于社交媒体多模态有害内容检测'}
{'arxiv_id': 'arXiv:2508.05513', 'title': "Streamlining Admission with LOR Insights: AI-Based Leadership Assessment in Online Master's Program", 'authors': 'Meryem Yilmaz Soylu, Adrian Gallard, Jeonghyun Lee, Gayane Grigoryan, Rushil Desai, Stephen Harmon', 'link': 'https://arxiv.org/abs/2508.05513', 'abstract': "Letters of recommendation (LORs) provide valuable insights into candidates' capabilities and experiences beyond standardized test scores. However, reviewing these text-heavy materials is time-consuming and labor-intensive. To address this challenge and support the admission committee in providing feedback for students' professional growth, our study introduces LORI: LOR Insights, a novel AI-based detection tool for assessing leadership skills in LORs submitted by online master's program applicants. By employing natural language processing and leveraging large language models using RoBERTa and LLAMA, we seek to identify leadership attributes such as teamwork, communication, and innovation. Our latest RoBERTa model achieves a weighted F1 score of 91.6%, a precision of 92.4%, and a recall of 91.6%, showing a strong level of consistency in our test data. With the growing importance of leadership skills in the STEM sector, integrating LORI into the graduate admissions process is crucial for accurately assessing applicants' leadership capabilities. This approach not only streamlines the admissions process but also automates and ensures a more comprehensive evaluation of candidates' capabilities.", 'abstract_zh': '推荐信（LORs）提供了候选人能力与经验的重要见解，超越了标准化测试分数。然而，审查这些文字密集型材料既耗时又费力。为应对这一挑战，支持招生委员会为学生的职业发展提供反馈，本研究引入了LORI：LOR Insights，一种基于AI的评估在线硕士项目申请人推荐信中领导能力的新颖检测工具。通过运用自然语言处理并利用RoBERTa和LLAMA等大型语言模型，我们旨在识别团队合作、沟通和创新等领导特质。我们的最新RoBERTa模型在加权F1分数上达到了91.6%，精确度为92.4%，召回率为91.6%，显示了我们的测试数据中具有很强的一致性。随着STEM领域对领导技能的重要性日益增加，将LORI整合到研究生入学过程中，对于准确评估申请人的领导能力至关重要。这种方法不仅简化了招生过程，还实现了自动化评估，并确保了对候选人能力的更全面评价。', 'title_zh': '利用推荐信洞察简化录取流程：基于AI的在线硕士学位项目领导力评估'}
{'arxiv_id': 'arXiv:2508.05508', 'title': 'Auto-Eval Judge: Towards a General Agentic Framework for Task Completion Evaluation', 'authors': 'Roshita Bhonsle, Rishav Dutta, Sneha Vavilapalli, Harsh Seth, Abubakarr Jaye, Yapei Chang, Mukund Rungta, Emmanuel Aboah Boateng, Sadid Hasan, Ehi Nosakhare, Soundar Srinivasan', 'link': 'https://arxiv.org/abs/2508.05508', 'abstract': "The increasing adoption of foundation models as agents across diverse domains necessitates a robust evaluation framework. Current methods, such as LLM-as-a-Judge, focus only on final outputs, overlooking the step-by-step reasoning that drives agentic decision-making. Meanwhile, existing Agent-as-a-Judge systems, where one agent evaluates another's task completion, are typically designed for narrow, domain-specific settings. To address this gap, we propose a generalizable, modular framework for evaluating agent task completion independent of the task domain. The framework emulates human-like evaluation by decomposing tasks into sub-tasks and validating each step using available information, such as the agent's output and reasoning. Each module contributes to a specific aspect of the evaluation process, and their outputs are aggregated to produce a final verdict on task completion. We validate our framework by evaluating the Magentic-One Actor Agent on two benchmarks, GAIA and BigCodeBench. Our Judge Agent predicts task success with closer agreement to human evaluations, achieving 4.76% and 10.52% higher alignment accuracy, respectively, compared to the GPT-4o based LLM-as-a-Judge baseline. This demonstrates the potential of our proposed general-purpose evaluation framework.", 'abstract_zh': '随着基础模型在多种领域作为代理的广泛应用，迫切需要一个 robust 的评估框架。现有的方法，如 LLM-as-a-Judge，仅关注最终输出，忽视了驱动代理决策的逐步推理过程。同时，现有的 Agent-as-a-Judge 系统通常设计用于狭窄的、特定领域的设置。为解决这一问题，我们提出了一种通用且模块化的框架，用于独立于任务领域评估代理任务完成情况。该框架通过将任务分解为子任务，并利用可用信息（如代理的输出和推理）验证每一步骤，来模拟人类的评估过程。每个模块针对评估过程的特定方面做出贡献，并且它们的输出被聚合以形成对任务完成的最终评判。我们通过在 GAIA 和 BigCodeBench 两个基准上评估 Magentic-One Actor Agent 验证了该框架。我们的 Judge Agent 在预测任务成功方面与人类评价更一致，与基于 GPT-4o 的 LLM-as-a-Judge 基线相比，分别实现了 4.76% 和 10.52% 的更高一致性准确性。这展示了我们提出的通用评估框架的潜力。', 'title_zh': '自评法官：面向任务完成评价的通用代理框架'}
{'arxiv_id': 'arXiv:2508.05498', 'title': 'GRAIL:Learning to Interact with Large Knowledge Graphs for Retrieval Augmented Reasoning', 'authors': 'Ge Chang, Jinbo Su, Jiacheng Liu, Pengfei Yang, Yuhao Shang, Huiwen Zheng, Hongli Ma, Yan Liang, Yuanchun Li, Yunxin Liu', 'link': 'https://arxiv.org/abs/2508.05498', 'abstract': 'Large Language Models (LLMs) integrated with Retrieval-Augmented Generation (RAG) techniques have exhibited remarkable performance across a wide range of domains. However, existing RAG approaches primarily operate on unstructured data and demonstrate limited capability in handling structured knowledge such as knowledge graphs. Meanwhile, current graph retrieval methods fundamentally struggle to capture holistic graph structures while simultaneously facing precision control challenges that manifest as either critical information gaps or excessive redundant connections, collectively undermining reasoning performance. To address this challenge, we propose GRAIL: Graph-Retrieval Augmented Interactive Learning, a framework designed to interact with large-scale graphs for retrieval-augmented reasoning. Specifically, GRAIL integrates LLM-guided random exploration with path filtering to establish a data synthesis pipeline, where a fine-grained reasoning trajectory is automatically generated for each task. Based on the synthesized data, we then employ a two-stage training process to learn a policy that dynamically decides the optimal actions at each reasoning step. The overall objective of precision-conciseness balance in graph retrieval is decoupled into fine-grained process-supervised rewards to enhance data efficiency and training stability. In practical deployment, GRAIL adopts an interactive retrieval paradigm, enabling the model to autonomously explore graph paths while dynamically balancing retrieval breadth and precision. Extensive experiments have shown that GRAIL achieves an average accuracy improvement of 21.01% and F1 improvement of 22.43% on three knowledge graph question-answering datasets. Our source code and datasets is available at this https URL.', 'abstract_zh': '大型语言模型（LLMs）结合检索增强生成（（RAG）技术取得了广泛领域内的卓越表现。\n\n现有的RAG方法主要在结构化数据上运行，并，显示出在处理知识图谱等这类结构化知识方面能力有限。\n\n当前的知识图检索方法在充分捕捉整体图结构方面存在困难，并且在精确度控制上面临着关键信息缺失和过多冗余连接的问题，这些因素共同损害了推理性能。\n\n为了解决这些问题，我们提出了一种框架：图形检索增强交互学习（GRAIL）——，该框架旨在与大规模图形交互，以增强检索和推理。\n\n具体来说，，GRAIL结合了LLM指导的随机探索与候选过滤，建立了一个合成Pipeline，在在此Pipeline上自动为每个任务生成详细的推理轨迹。基于合成的数据上，我们采用两阶段训练过程来政策化地在每次推理步骤上选择最优动作。精确度与简洁性的综合在图形检索中的整体目标被分解为两级过程：监督奖励以增强设计效率和训练稳定。\n\n在实际部署中，GRAIL采用了交互式检索范式，使得模型能够自主探索图形空间的同时动态平衡检索广度和精确度。实验显示表明，GRAIL在准确度上有提高约11 1.1％，并在三个知识图谱问答数据集上上增强了率达到约5 reinforced 2.43％。有关的数据集可可以通过提供的URL获取。', 'title_zh': 'GRAIL：学习与大型知识图谱交互以增强检索推理'}
{'arxiv_id': 'arXiv:2508.05496', 'title': 'InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities', 'authors': 'Shuo Cai, Su Lu, Qi Zhou, Kejing Yang, Zhijie Sang, Congkai Xie, Hongxia Yang', 'link': 'https://arxiv.org/abs/2508.05496', 'abstract': 'Large language models (LLMs) have exhibited impressive reasoning abilities on a wide range of complex tasks. However, enhancing these capabilities through post-training remains resource intensive, particularly in terms of data and computational cost. Although recent efforts have sought to improve sample efficiency through selective data curation, existing methods often rely on heuristic or task-specific strategies that hinder scalability. In this work, we introduce InfiAlign, a scalable and sample-efficient post-training framework that integrates supervised fine-tuning (SFT) with Direct Preference Optimization (DPO) to align LLMs for enhanced reasoning. At the core of InfiAlign is a robust data selection pipeline that automatically curates high-quality alignment data from open-source reasoning datasets using multidimensional quality metrics. This pipeline enables significant performance gains while drastically reducing data requirements and remains extensible to new data sources. When applied to the Qwen2.5-Math-7B-Base model, our SFT model achieves performance on par with DeepSeek-R1-Distill-Qwen-7B, while using only approximately 12% of the training data, and demonstrates strong generalization across diverse reasoning tasks. Additional improvements are obtained through the application of DPO, with particularly notable gains in mathematical reasoning tasks. The model achieves an average improvement of 3.89% on AIME 24/25 benchmarks. Our results highlight the effectiveness of combining principled data selection with full-stage post-training, offering a practical solution for aligning large reasoning models in a scalable and data-efficient manner. The model checkpoints are available at this https URL.', 'abstract_zh': '大规模语言模型（LLMs）在广泛复杂的任务上展示了令人印象深刻的推理能力。然而，通过后训练来增强这些能力依然资源密集，特别是在数据和计算成本方面。尽管最近的努力致力于通过选择性数据编辑提高样本效率，现有方法通常依赖于启发式或特定任务策略，这妨碍了扩展性。在本文中，我们提出了InfiAlign，这是一种可扩展且样本高效的后训练框架，将监督微调（SFT）与直接偏好优化（DPO）相结合，以增强大型语言模型的推理能力。InfiAlign的核心是一个稳健的数据选择管道，它使用多维质量度量从开源推理数据集中自动筛选高质量的对齐数据。该管道能够实现显著的性能提升，同时大幅减少数据需求，且易于扩展到新的数据源。应用到Qwen2.5-Math-7B-Base模型时，我们的SFT模型在使用约12%的训练数据情况下，达到与DeepSeek-R1-Distill-Qwen-7B相当的性能，并在多种推理任务中展现出强大的泛化能力。通过应用DPO还获得了额外改进，特别是在数学推理任务中取得了显著进展。模型在AIME 24/25基准上平均提升了3.89%。我们的结果突显了结合原理数据选择与全程后训练的高效性，提供了一种在可扩展和数据高效的方式下对大型推理模型进行对齐的实用解决方案。模型检查点可在此处访问：this https URL.', 'title_zh': 'InfiAlign: 一个 scalable 和样本高效的方法，用于调整大型语言模型以增强推理能力'}
{'arxiv_id': 'arXiv:2508.05474', 'title': 'Can Large Language Models Generate Effective Datasets for Emotion Recognition in Conversations?', 'authors': 'Burak Can Kaplan, Hugo Cesar De Castro Carneiro, Stefan Wermter', 'link': 'https://arxiv.org/abs/2508.05474', 'abstract': 'Emotion recognition in conversations (ERC) focuses on identifying emotion shifts within interactions, representing a significant step toward advancing machine intelligence. However, ERC data remains scarce, and existing datasets face numerous challenges due to their highly biased sources and the inherent subjectivity of soft labels. Even though Large Language Models (LLMs) have demonstrated their quality in many affective tasks, they are typically expensive to train, and their application to ERC tasks--particularly in data generation--remains limited. To address these challenges, we employ a small, resource-efficient, and general-purpose LLM to synthesize ERC datasets with diverse properties, supplementing the three most widely used ERC benchmarks. We generate six novel datasets, with two tailored to enhance each benchmark. We evaluate the utility of these datasets to (1) supplement existing datasets for ERC classification, and (2) analyze the effects of label imbalance in ERC. Our experimental results indicate that ERC classifier models trained on the generated datasets exhibit strong robustness and consistently achieve statistically significant performance improvements on existing ERC benchmarks.', 'abstract_zh': '情感对话中的情感识别（ERC）专注于识别对话中的情感转变，代表了推动机器智能发展的重大步骤。然而，ERC数据仍然稀缺，现有的数据集由于来源高度偏颇且软标签固有的主观性而面临诸多挑战。尽管大型语言模型（LLMs）在许多情感任务中表现出高质量，但它们通常训练成本高昂，在ERC任务，尤其是在数据生成方面的应用仍然有限。为解决这些挑战，我们采用了一个小型、资源高效且通用的LLM来合成具有多种特性的ERC数据集，补充了使用最广泛的三个ERC基准数据集。我们生成了六个新的数据集，其中两个专门针对增强每个基准进行了定制。我们评估了这些数据集的用途，包括（1）作为ERC分类现有数据集的补充，以及（2）分析ERC中的标签不平衡效果。实验结果表明，基于生成的数据集训练的ERC分类模型具有较强的鲁棒性，并且在现有ERC基准测试上始终能够实现统计上显著的性能提升。', 'title_zh': '大型语言模型能否生成有效的对话情绪识别数据集？'}
{'arxiv_id': 'arXiv:2508.05464', 'title': 'Bench-2-CoP: Can We Trust Benchmarking for EU AI Compliance?', 'authors': 'Matteo Prandi, Vincenzo Suriani, Federico Pierucci, Marcello Galisai, Daniele Nardi, Piercosma Bisconti', 'link': 'https://arxiv.org/abs/2508.05464', 'abstract': 'The rapid advancement of General Purpose AI (GPAI) models necessitates robust evaluation frameworks, especially with emerging regulations like the EU AI Act and its associated Code of Practice (CoP). Current AI evaluation practices depend heavily on established benchmarks, but these tools were not designed to measure the systemic risks that are the focus of the new regulatory landscape. This research addresses the urgent need to quantify this "benchmark-regulation gap." We introduce Bench-2-CoP, a novel, systematic framework that uses validated LLM-as-judge analysis to map the coverage of 194,955 questions from widely-used benchmarks against the EU AI Act\'s taxonomy of model capabilities and propensities. Our findings reveal a profound misalignment: the evaluation ecosystem is overwhelmingly focused on a narrow set of behavioral propensities, such as "Tendency to hallucinate" (53.7% of the corpus) and "Discriminatory bias" (28.9%), while critical functional capabilities are dangerously neglected. Crucially, capabilities central to loss-of-control scenarios, including evading human oversight, self-replication, and autonomous AI development, receive zero coverage in the entire benchmark corpus. This translates to a near-total evaluation gap for systemic risks like "Loss of Control" (0.4% coverage) and "Cyber Offence" (0.8% coverage). This study provides the first comprehensive, quantitative analysis of this gap, offering critical insights for policymakers to refine the CoP and for developers to build the next generation of evaluation tools, ultimately fostering safer and more compliant AI.', 'abstract_zh': '《通用人工智能（GPAI）模型的迅速发展需要 robust 的评估框架，，特别在欧盟AI法案及其\nuser\n好的背景下，特别是在欧盟AI法案及其\n的背景下，引入一种基于系统框架的Bench-CoP评估方法 杨标准化的LLM作为法官分析来映射广泛使用的评估基准针对欧盟AI法案的能力分类和倾向分类 我们的研究发现了一个深刻的分歧: �当前的评估生态体系主要过度关注于一小部分行为倾向,例如“妄想倾向”（37% 的覆盖率）和“歧视性倾向”（88.55% 的覆盖率）而忽略了了功能能力 on这些能力在失控场景中可能会逃避人类监管 值得重视的自主复制复制重复和自主以及自主生成 AI 的发展完全没有覆盖 则这导致了对对于“失控"（ on4 on on的 的覆盖率）和“网络攻击”（（8 on on % on on on on on on on 的映像覆盖 本研究通过全面的定量分析阐述了这一gap\n\n\n\n的回答\n\nAssistant直接输出标题：Bench-CoP：一种基于系统标准化LL', 'title_zh': 'Bench-2-CoP: 欧盟AI合规benchmarking能信赖吗？'}
{'arxiv_id': 'arXiv:2508.05432', 'title': 'Whose Truth? Pluralistic Geo-Alignment for (Agentic) AI', 'authors': 'Krzysztof Janowicz, Zilong Liu, Gengchen Mai, Zhangyu Wang, Ivan Majic, Alexandra Fortacz, Grant McKenzie, Song Gao', 'link': 'https://arxiv.org/abs/2508.05432', 'abstract': "AI (super) alignment describes the challenge of ensuring (future) AI systems behave in accordance with societal norms and goals. While a quickly evolving literature is addressing biases and inequalities, the geographic variability of alignment remains underexplored. Simply put, what is considered appropriate, truthful, or legal can differ widely across regions due to cultural norms, political realities, and legislation. Alignment measures applied to AI/ML workflows can sometimes produce outcomes that diverge from statistical realities, such as text-to-image models depicting balanced gender ratios in company leadership despite existing imbalances. Crucially, some model outputs are globally acceptable, while others, e.g., questions about Kashmir, depend on knowing the user's location and their context. This geographic sensitivity is not new. For instance, Google Maps renders Kashmir's borders differently based on user location. What is new is the unprecedented scale and automation with which AI now mediates knowledge, expresses opinions, and represents geographic reality to millions of users worldwide, often with little transparency about how context is managed. As we approach Agentic AI, the need for spatio-temporally aware alignment, rather than one-size-fits-all approaches, is increasingly urgent. This paper reviews key geographic research problems, suggests topics for future work, and outlines methods for assessing alignment sensitivity.", 'abstract_zh': 'AI（超）对齐描述了确保未来AI系统行为符合社会规范和目标的挑战。尽管涉及偏见和不平等的文献在快速增加，但对齐的地理变异性仍被严重忽视。简单来说，由于文化规范、政治现实和立法的不同，适宜性、真实性或合法性在全球范围内可能会有很大差异。应用于AI/ML工作流的对齐措施有时会产出与统计现实相偏离的结果，例如，文本转图像模型描绘的公司领导层性别比例平衡，尽管实际存在失衡。关键的是，某些模型输出在全球范围内可接受，而另一些，例如关于克什米尔的问题，则取决于用户的位置和背景。这种地理敏感性并不是新的，例如，Google Maps根据用户位置的不同渲染克什米尔的边界。不同之处在于，现在AI以前所未有的规模和自动化程度中介知识、表达观点和呈现地理现实，这通常缺乏关于如何管理上下文的透明度。随着我们接近有智能的AI，时空感知对齐相较于一刀切的方法变得越来越紧迫。本文回顾了关键的地理研究问题，建议了未来工作的话题，并概述了评估对齐敏感性的方法。', 'title_zh': '谁的真相？多元地理对齐ための（能动的）AI'}
{'arxiv_id': 'arXiv:2508.05427', 'title': 'Large Language Models Transform Organic Synthesis From Reaction Prediction to Automation', 'authors': 'Kartar Kumar Lohana Tharwani, Rajesh Kumar, Sumita, Numan Ahmed, Yong Tang', 'link': 'https://arxiv.org/abs/2508.05427', 'abstract': 'Large language models (LLMs) are beginning to reshape how chemists plan and run reactions in organic synthesis. Trained on millions of reported transformations, these text-based models can propose synthetic routes, forecast reaction outcomes and even instruct robots that execute experiments without human supervision. Here we survey the milestones that turned LLMs from speculative tools into practical lab partners. We show how coupling LLMs with graph neural networks, quantum calculations and real-time spectroscopy shrinks discovery cycles and supports greener, data-driven chemistry. We discuss limitations, including biased datasets, opaque reasoning and the need for safety gates that prevent unintentional hazards. Finally, we outline community initiatives open benchmarks, federated learning and explainable interfaces that aim to democratize access while keeping humans firmly in control. These advances chart a path towards rapid, reliable and inclusive molecular innovation powered by artificial intelligence and automation.', 'abstract_zh': '大规模语言模型（LLMs）正在重新定义化学家在有机合成中规划和运行反应的方式。这些基于文本的模型经过数百万个报告的转化训练，可以提出合成路线、预测反应结果，甚至可以指导无需人类监督的机器人执行实验。在这里，我们回顾了LLMs从 speculative 工具转变为实用实验室伙伴的关键里程碑。我们展示了将LLMs与图神经网络、量子计算和实时光谱学相结合如何缩短发现周期，并支持更绿色、更数据驱动的化学。我们讨论了包括偏差数据集、不透明推理以及需要防止意外危害的安全门在内的限制。最后，我们概述了旨在促进平等访问同时确保人类始终处于控制之中的社区倡议，包括开放基准、联邦学习和可解释接口。这些进展描绘了一条通往由人工智能和自动化驱动的快速、可靠和包容的分子创新之路。', 'title_zh': '大型语言模型将有机合成从反应预测转变为自动化。'}
{'arxiv_id': 'arXiv:2508.05405', 'title': 'DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning', 'authors': 'Xinrun Xu, Pi Bu, Ye Wang, Börje F. Karlsson, Ziming Wang, Tengtao Song, Qi Zhu, Jun Song, Zhiming Ding, Bo Zheng', 'link': 'https://arxiv.org/abs/2508.05405', 'abstract': "Although Vision Language Models (VLMs) exhibit strong perceptual abilities and impressive visual reasoning, they struggle with attention to detail and precise action planning in complex, dynamic environments, leading to subpar performance. Real-world tasks typically require complex interactions, advanced spatial reasoning, long-term planning, and continuous strategy refinement, usually necessitating understanding the physics rules of the target scenario. However, evaluating these capabilities in real-world scenarios is often prohibitively expensive. To bridge this gap, we introduce DeepPHY, a novel benchmark framework designed to systematically evaluate VLMs' understanding and reasoning about fundamental physical principles through a series of challenging simulated environments. DeepPHY integrates multiple physical reasoning environments of varying difficulty levels and incorporates fine-grained evaluation metrics. Our evaluation finds that even state-of-the-art VLMs struggle to translate descriptive physical knowledge into precise, predictive control.", 'abstract_zh': '尽管视觉语言模型(VLMs)在感知能力和视觉推理方面表现出色，但在复杂动态环境中，它们在细节关注和精确动作规划方面存在不足，导致性能不佳。真实世界任务通常需要复杂的交互、高级的空间推理、长期规划以及持续的策略优化，通常需要理解目标场景的物理规则。然而，在真实世界场景中评估这些能力往往代价高昂。为了弥补这一差距，我们引入了DeepPHY，一个新型基准框架，旨在通过一系列具有挑战性的模拟环境系统性地评估VLMs关于基本物理原理的了解和推理能力。DeepPHY集成了多个不同难度级别的物理推理环境，并采用了精细的评估指标。我们的评估发现，即使是最先进的VLMs，在将描述性的物理知识转化为精确、预测性的控制方面也存在困难。', 'title_zh': 'DeepPHY: 评估自主型大模型在物理推理任务上的性能'}
{'arxiv_id': 'arXiv:2508.05388', 'title': 'An Explainable Machine Learning Framework for Railway Predictive Maintenance using Data Streams from the Metro Operator of Portugal', 'authors': 'Silvia García-Méndez, Francisco de Arriba-Pérez, Fátima Leal, Bruno Veloso, Benedita Malheiro, Juan Carlos Burguillo-Rial', 'link': 'https://arxiv.org/abs/2508.05388', 'abstract': 'This work contributes to a real-time data-driven predictive maintenance solution for Intelligent Transportation Systems. The proposed method implements a processing pipeline comprised of sample pre-processing, incremental classification with Machine Learning models, and outcome explanation. This novel online processing pipeline has two main highlights: (i) a dedicated sample pre-processing module, which builds statistical and frequency-related features on the fly, and (ii) an explainability module. This work is the first to perform online fault prediction with natural language and visual explainability. The experiments were performed with the MetroPT data set from the metro operator of Porto, Portugal. The results are above 98 % for F-measure and 99 % for accuracy. In the context of railway predictive maintenance, achieving these high values is crucial due to the practical and operational implications of accurate failure prediction. In the specific case of a high F-measure, this ensures that the system maintains an optimal balance between detecting the highest possible number of real faults and minimizing false alarms, which is crucial for maximizing service availability. Furthermore, the accuracy obtained enables reliability, directly impacting cost reduction and increased safety. The analysis demonstrates that the pipeline maintains high performance even in the presence of class imbalance and noise, and its explanations effectively reflect the decision-making process. These findings validate the methodological soundness of the approach and confirm its practical applicability for supporting proactive maintenance decisions in real-world railway operations. Therefore, by identifying the early signs of failure, this pipeline enables decision-makers to understand the underlying problems and act accordingly swiftly.', 'abstract_zh': '本项工作为智能交通系统提供了实时数据驱动的预测性维护解决方案。提出的办法包括样本预处理、基于机器学习模型的增量分类以及结果解释。该创新的在线处理管道有两个主要亮点：(i) 一个专门的样本预处理模块，能够实时构建统计和频率相关的特征，以及(ii) 一个解释性模块。本工作是首次使用自然语言和视觉解释进行在线故障预测。实验使用了葡萄牙波尔图地铁运营商的MetroPT数据集。F-measure和准确率分别超过98%和99%。在铁路预测性维护的背景下，这些高值至关重要，因为准确的故障预测具有实际和操作意义。尤其是高F-measure确保了系统在检测尽可能多的真实故障和最小化误报之间保持最优平衡，这对于最大限度地提高服务可用性至关重要。此外，所获得的准确率保证了可靠性，直接影响成本降低和安全性提高。分析表明，该管道在类别不平衡和噪声存在的情况下仍能保持高性能，并且其解释能够有效地反映决策过程。这些发现验证了该方法的理论基础，并确认其在现实铁路运营中支持预防性维护决策的实际适用性。因此，通过识别故障的早期迹象，该管道使决策者能够理解潜在问题并及时采取相应措施。', 'title_zh': '基于葡萄牙地铁运营商数据流的可解释机器学习预测维护框架'}
{'arxiv_id': 'arXiv:2508.05383', 'title': 'StructVRM: Aligning Multimodal Reasoning with Structured and Verifiable Reward Models', 'authors': 'Xiangxiang Zhang, Jingxuan Wei, Donghong Zhong, Qi Chen, Caijun Jia, Cheng Tan, Jinming Gu, Xiaobo Qin, Zhiping Liu, Liang Hu, Tong Sun, Yuchen Wu, Zewei Sun, Chenwei Lou, Hua Zheng, Tianyang Zhan, Changbao Wang, Shuangzhi Wu, Zefa Lin, Chang Guo, Sihang Yuan, Riwei Chen, Shixiong Zhao, Yingping Zhang, Gaowei Wu, Bihui Yu, Jiahui Wu, Zhehui Zhao, Qianqian Liu, Ruofeng Tang, Xingyue Huang, Bing Zhao, Mengyang Zhang, Youqiang Zhou', 'link': 'https://arxiv.org/abs/2508.05383', 'abstract': 'Existing Vision-Language Models often struggle with complex, multi-question reasoning tasks where partial correctness is crucial for effective learning. Traditional reward mechanisms, which provide a single binary score for an entire response, are too coarse to guide models through intricate problems with multiple sub-parts. To address this, we introduce StructVRM, a method that aligns multimodal reasoning with Structured and Verifiable Reward Models. At its core is a model-based verifier trained to provide fine-grained, sub-question-level feedback, assessing semantic and mathematical equivalence rather than relying on rigid string matching. This allows for nuanced, partial credit scoring in previously intractable problem formats. Extensive experiments demonstrate the effectiveness of StructVRM. Our trained model, Seed-StructVRM, achieves state-of-the-art performance on six out of twelve public multimodal benchmarks and our newly curated, high-difficulty STEM-Bench. The success of StructVRM validates that training with structured, verifiable rewards is a highly effective approach for advancing the capabilities of multimodal models in complex, real-world reasoning domains.', 'abstract_zh': '现有的视觉-语言模型在复杂的多问题推理任务中往往表现不佳，特别是在需要部分正确性以实现有效学习的任务中。传统的奖励机制只能为整个回答提供单一的二元评分，对于具有多个子部分的复杂问题来说过于粗放，难以引导模型通过这些问题。为此，我们提出了StructVRM方法，该方法将多模态推理与结构化可验证奖励模型对齐。其核心是一个基于模型的验证器，该验证器被训练为提供精细的、按子问题级的反馈，评估语义和数学等价性，而不是依赖于严格的字符串匹配。这使得在先前难以处理的问题格式中实现了细微的部分正确评分。广泛的实验展示了StructVRM的有效性。我们的训练模型Seed-StructVRM在六个出十二个公开的多模态基准测试和我们新整理的高难度STEM-Bench上取得了最先进的性能。StructVRM的成功验证了使用结构化可验证奖励进行训练是提高多模态模型在复杂现实世界推理领域能力的有效方法。', 'title_zh': 'StructVRM: 结构化可验证奖励模型引导的多模态推理对齐'}
{'arxiv_id': 'arXiv:2508.05350', 'title': "Minimal Model Reasoning in Description Logics: Don't Try This at Home!", 'authors': 'Federica Di Stefano, Quentin Manière, Magdalena Ortiz, Mantas Šimkus', 'link': 'https://arxiv.org/abs/2508.05350', 'abstract': "Reasoning with minimal models has always been at the core of many knowledge representation techniques, but we still have only a limited understanding of this problem in Description Logics (DLs). Minimization of some selected predicates, letting the remaining predicates vary or be fixed, as proposed in circumscription, has been explored and exhibits high complexity. The case of `pure' minimal models, where the extension of all predicates must be minimal, has remained largely uncharted. We address this problem in popular DLs and obtain surprisingly negative results: concept satisfiability in minimal models is undecidable already for $\\mathcal{EL}$. This undecidability also extends to a very restricted fragment of tuple-generating dependencies. To regain decidability, we impose acyclicity conditions on the TBox that bring the worst-case complexity below double exponential time and allow us to establish a connection with the recently studied pointwise circumscription; we also derive results in data complexity. We conclude with a brief excursion to the DL-Lite family, where a positive result was known for DL-Lite$_{\\text{core}}$, but our investigation establishes ExpSpace-hardness already for its extension DL-Lite$_{\\text{horn}}$.", 'abstract_zh': '在描述逻辑中最小模型的推理一直是众多知识表示技术的核心，但我们在描述逻辑中的这一问题上仍只有有限的理解。纯最小模型的情况，即所有谓词的扩展都必须最小，仍 largely uncharted。我们针对流行的描述逻辑处理这一问题并得到了令人意外的负面结果：概念在最小模型中的可满足性对于 $\\mathcal{EL}$ 来说是不可判定的。这一不可判定性也扩展到了元组生成依赖的一个非常受限的片段。为了重新获得可判定性，我们对TBox施加了无环条件，将最坏情况的复杂性降低到双指数时间，并允许我们建立与最近研究的点态约简之间的联系；我们也在数据复杂性方面得到了一些结果。最后，我们简要介绍了DL-Lite家族，对于DL-Lite$_{\\text{core}}$ 已知有一个积极的结果，但我们的研究却确定其扩展DL-Lite$_{\\text{horn}}$ 的复杂性为ExpSpace-hard。', 'title_zh': '描述逻辑中的最小模型推理：不要在家里尝试！'}
{'arxiv_id': 'arXiv:2508.05344', 'title': 'NomicLaw: Emergent Trust and Strategic Argumentation in LLMs During Collaborative Law-Making', 'authors': 'Asutosh Hota, Jussi P.P. Jokinen', 'link': 'https://arxiv.org/abs/2508.05344', 'abstract': 'Recent advancements in large language models (LLMs) have extended their capabilities from basic text processing to complex reasoning tasks, including legal interpretation, argumentation, and strategic interaction. However, empirical understanding of LLM behavior in open-ended, multi-agent settings especially those involving deliberation over legal and ethical dilemmas remains limited. We introduce NomicLaw, a structured multi-agent simulation where LLMs engage in collaborative law-making, responding to complex legal vignettes by proposing rules, justifying them, and voting on peer proposals. We quantitatively measure trust and reciprocity via voting patterns and qualitatively assess how agents use strategic language to justify proposals and influence outcomes. Experiments involving homogeneous and heterogeneous LLM groups demonstrate how agents spontaneously form alliances, betray trust, and adapt their rhetoric to shape collective decisions. Our results highlight the latent social reasoning and persuasive capabilities of ten open-source LLMs and provide insights into the design of future AI systems capable of autonomous negotiation, coordination and drafting legislation in legal settings.', 'abstract_zh': '近期大型语言模型的 advancements 已将其实现能力从基本的文字处理扩展到复杂的推理任务，包括法律解释、论辩和战略互动。然而，关于大型语言模型在开放性、多智能体环境中的行为理解，特别是在涉及法律和伦理困境的讨论中，仍然有限。我们引入了 NomicLaw，这是一种结构化的多智能体模拟，在此模型中，智能语言模型参与协作立法，通过提出规则、进行正当化并投票评估同伴提案来应对复杂的法律情境。我们通过投票模式定量地测量信任和互惠，并通过智能体如何使用战略语言正当化提案及其对结果的影响进行定性的评估。涉及同质性和异质性大型语言模型组的实验展示了智能体如何自发地形成联盟、背叛信任，并适应其修辞以塑造集体决策。研究结果突显了十个开源大型语言模型潜在的社会推理和说服能力，并为设计具有自主谈判、协调和在法律环境中起草法律文件能力的未来AI系统提供了见解。', 'title_zh': '名义法：LLMs协作立法过程中涌现的信任与战略论证'}
{'arxiv_id': 'arXiv:2508.05338', 'title': "The Term 'Agent' Has Been Diluted Beyond Utility and Requires Redefinition", 'authors': 'Brinnae Bent', 'link': 'https://arxiv.org/abs/2508.05338', 'abstract': "The term 'agent' in artificial intelligence has long carried multiple interpretations across different subfields. Recent developments in AI capabilities, particularly in large language model systems, have amplified this ambiguity, creating significant challenges in research communication, system evaluation and reproducibility, and policy development. This paper argues that the term 'agent' requires redefinition. Drawing from historical analysis and contemporary usage patterns, we propose a framework that defines clear minimum requirements for a system to be considered an agent while characterizing systems along a multidimensional spectrum of environmental interaction, learning and adaptation, autonomy, goal complexity, and temporal coherence. This approach provides precise vocabulary for system description while preserving the term's historically multifaceted nature. After examining potential counterarguments and implementation challenges, we provide specific recommendations for moving forward as a field, including suggestions for terminology standardization and framework adoption. The proposed approach offers practical tools for improving research clarity and reproducibility while supporting more effective policy development.", 'abstract_zh': '人工智能中“代理”一词长期具有多重解释。近期人工智能能力的发展，特别是大型语言模型系统的进展，加剧了这一歧义，为研究通讯、系统评估与再现性和政策制定带来了重大挑战。本文认为“代理”这一术语需要重新定义。通过历史分析和当代使用模式，我们提出了一种框架，明确规定了系统作为代理所应满足的基本要求，并以其在环境交互、学习与适应、自主性、目标复杂性和时序一致性等多维度方面的表现对系统进行分类。这种方法为系统描述提供了精确的词汇，同时保留了该术语历史上的多重含义。在探讨潜在的反论和实施挑战后，我们提供了具体建议，以推动该领域的发展，包括术语标准化和框架采用的建议。提出的这种方法提供了实用工具，以提高研究的清晰度和再现性，并支持更有效的政策制定。', 'title_zh': '术语“代理”已丧失实用价值，需重新定义。'}
{'arxiv_id': 'arXiv:2508.05311', 'title': 'A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents', 'authors': 'Andrew Kiruluta', 'link': 'https://arxiv.org/abs/2508.05311', 'abstract': 'We propose a hybrid architecture that integrates decision tree-based symbolic reasoning with the generative capabilities of large language models (LLMs) within a coordinated multi-agent framework. Unlike prior approaches that loosely couple symbolic and neural modules, our design embeds decision trees and random forests as callable oracles within a unified reasoning system. Tree-based modules enable interpretable rule inference and causal logic, while LLM agents handle abductive reasoning, generalization, and interactive planning. A central orchestrator maintains belief state consistency and mediates communication across agents and external tools, enabling reasoning over both structured and unstructured inputs.\nThe system achieves strong performance on reasoning benchmarks. On \\textit{ProofWriter}, it improves entailment consistency by +7.2\\% through logic-grounded tree validation. On GSM8k, it achieves +5.3\\% accuracy gains in multistep mathematical problems via symbolic augmentation. On \\textit{ARC}, it boosts abstraction accuracy by +6.0\\% through integration of symbolic oracles. Applications in clinical decision support and scientific discovery show how the system encodes domain rules symbolically while leveraging LLMs for contextual inference and hypothesis generation. This architecture offers a robust, interpretable, and extensible solution for general-purpose neuro-symbolic reasoning.', 'abstract_zh': '我们提出了一种混合架构，将基于决策树的符号推理与大规模语言模型（LLMs）的生成能力结合在一个协调的多智能体框架内。与以往松散耦合符号和神经模块的方法不同，我们的设计将决策树和随机森林嵌入为统一推理系统中的可调用先知。基于树的模块支持可解释的规则推理和因果逻辑，而LLM智能体处理演绎推理、泛化和交互式规划。中心协调器维护信念状态一致性，并介调智能体间及与外部工具的通信，支持结构化和非结构化输入的推理。该系统在推理基准测试中表现出色。在ProofWriter上，通过逻辑支持的树验证提高了蕴含一致性7.2%。在GSM8k上，通过符号增强在多步数学问题上实现了5.3%的准确率提升。在ARC上，通过符号先知的整合提高了抽象准确率6.0%。在临床决策支持和科学发现应用中展示了该系统如何以符号方式编码领域规则，并利用LLMs进行上下文推理和假设生成。该架构为通用目的神经-符号推理提供了稳健、可解释和可扩展的解决方案。', 'title_zh': '一种基于决策树和LLM代理的符号推理新架构'}
{'arxiv_id': 'arXiv:2508.05267', 'title': 'An Explainable Natural Language Framework for Identifying and Notifying Target Audiences In Enterprise Communication', 'authors': 'Vítor N. Lourenço, Mohnish Dubey, Yunfei Bai, Audrey Depeige, Vivek Jain', 'link': 'https://arxiv.org/abs/2508.05267', 'abstract': 'In large-scale maintenance organizations, identifying subject matter experts and managing communications across complex entities relationships poses significant challenges -- including information overload and longer response times -- that traditional communication approaches fail to address effectively. We propose a novel framework that combines RDF graph databases with LLMs to process natural language queries for precise audience targeting, while providing transparent reasoning through a planning-orchestration architecture. Our solution enables communication owners to formulate intuitive queries combining concepts such as equipment, manufacturers, maintenance engineers, and facilities, delivering explainable results that maintain trust in the system while improving communication efficiency across the organization.', 'abstract_zh': '在大型维护组织中，识别领域专家并管理复杂实体关系之间的沟通面临显著挑战——包括信息过载和响应时间延长——传统沟通方法无法有效解决这些问题。我们提出了一种结合RDF图数据库与LLMs的新框架，用于处理自然语言查询以实现精确的目标受众定位，并通过规划- orchestration架构提供透明的推理过程。我们的解决方案使沟通所有者能够提出直观的查询，结合设备、制造商、维护工程师和设施等概念，提供可解释的结果，从而在提高组织内沟通效率的同时保持对系统的信任。', 'title_zh': '可解释的自然语言框架：识别和通知目标受众在企业沟通中的应用'}
{'arxiv_id': 'arXiv:2508.05197', 'title': 'QA-Dragon: Query-Aware Dynamic RAG System for Knowledge-Intensive Visual Question Answering', 'authors': 'Zhuohang Jiang, Pangjing Wu, Xu Yuan, Wenqi Fan, Qing Li', 'link': 'https://arxiv.org/abs/2508.05197', 'abstract': "Retrieval-Augmented Generation (RAG) has been introduced to mitigate hallucinations in Multimodal Large Language Models (MLLMs) by incorporating external knowledge into the generation process, and it has become a widely adopted approach for knowledge-intensive Visual Question Answering (VQA). However, existing RAG methods typically retrieve from either text or images in isolation, limiting their ability to address complex queries that require multi-hop reasoning or up-to-date factual knowledge. To address this limitation, we propose QA-Dragon, a Query-Aware Dynamic RAG System for Knowledge-Intensive VQA. Specifically, QA-Dragon introduces a domain router to identify the query's subject domain for domain-specific reasoning, along with a search router that dynamically selects optimal retrieval strategies. By orchestrating both text and image search agents in a hybrid setup, our system supports multimodal, multi-turn, and multi-hop reasoning, enabling it to tackle complex VQA tasks effectively. We evaluate our QA-Dragon on the Meta CRAG-MM Challenge at KDD Cup 2025, where it significantly enhances the reasoning performance of base models under challenging scenarios. Our framework achieves substantial improvements in both answer accuracy and knowledge overlap scores, outperforming baselines by 5.06% on the single-source task, 6.35% on the multi-source task, and 5.03% on the multi-turn task.", 'abstract_zh': 'Query-Aware Dynamic RAG System for Knowledge-Intensive Visual Question Answering', 'title_zh': 'QA-Dragon: 查询感知的动态检索增强系统，应用于知识密集型视觉问答'}
{'arxiv_id': 'arXiv:2508.05145', 'title': 'Graph-based Event Log Repair', 'authors': 'Sebastiano Dissegna, Chiara Di Francescomarino, Massimiliano Ronzani', 'link': 'https://arxiv.org/abs/2508.05145', 'abstract': 'The quality of event logs in Process Mining is crucial when applying any form of analysis to them. In real-world event logs, the acquisition of data can be non-trivial (e.g., due to the execution of manual activities and related manual recording or to issues in collecting, for each event, all its attributes), and often may end up with events recorded with some missing information. Standard approaches to the problem of trace (or log) reconstruction either require the availability of a process model that is used to fill missing values by leveraging different reasoning techniques or employ a Machine Learning/Deep Learning model to restore the missing values by learning from similar cases. In recent years, a new type of Deep Learning model that is capable of handling input data encoded as graphs has emerged, namely Graph Neural Networks. Graph Neural Network models, and even more so Heterogeneous Graph Neural Networks, offer the advantage of working with a more natural representation of complex multi-modal sequences like the execution traces in Process Mining, allowing for more expressive and semantically rich encodings.\nIn this work, we focus on the development of a Heterogeneous Graph Neural Network model that, given a trace containing some incomplete events, will return the full set of attributes missing from those events. We evaluate our work against a state-of-the-art approach leveraging autoencoders on two synthetic logs and four real event logs, on different types of missing values. Different from state-of-the-art model-free approaches, which mainly focus on repairing a subset of event attributes, the proposed approach shows very good performance in reconstructing all different event attributes.', 'abstract_zh': '过程挖掘中事件日志的质量对于应用任何形式的分析至关重要。在实际的事件日志中，数据的获取可能不简单（例如，由于执行手动活动及其相关的手动记录，或在收集每个事件的所有属性时出现的问题），并且常会导致事件记录中缺失某些信息。对于踪迹（或日志）重建的标准方法要么需要一个过程模型来通过利用不同的推理技术填充缺失值，要么使用机器学习/深度学习模型通过学习相似案例来恢复缺失值。近年来，一种能够处理图编码输入数据的新型深度学习模型——图神经网络（Graph Neural Networks）已经出现。图神经网络模型，尤其是异质图神经网络，提供了与复杂多模态序列（如过程挖掘中的执行踪迹）更自然的表示方式的优势，使得编码更加表达性和语义丰富。\n\n在本工作中，我们关注开发一种异质图神经网络模型，给定包含部分不完整事件的踪迹，该模型将返回那些事件中缺失的所有属性集合。我们将我们的工作与利用自动编码器的最新方法在两个合成日志和四个真实事件日志上进行了评估，对于不同类型的缺失值进行了不同类型的评估。与现有的主要关注修复事件属性子集的无模型方法不同，所提出的方法在重建所有不同事件属性方面表现出了非常好的性能。', 'title_zh': '图基础事件日志修复'}
{'arxiv_id': 'arXiv:2508.05116', 'title': 'Beyond Automation: Socratic AI, Epistemic Agency, and the Implications of the Emergence of Orchestrated Multi-Agent Learning Architectures', 'authors': 'Peer-Benedikt Degen, Igor Asanov', 'link': 'https://arxiv.org/abs/2508.05116', 'abstract': 'Generative AI is no longer a peripheral tool in higher education. It is rapidly evolving into a general-purpose infrastructure that reshapes how knowledge is generated, mediated, and validated. This paper presents findings from a controlled experiment evaluating a Socratic AI Tutor, a large language model designed to scaffold student research question development through structured dialogue grounded in constructivist theory. Conducted with 65 pre-service teacher students in Germany, the study compares interaction with the Socratic Tutor to engagement with an uninstructed AI chatbot. Students using the Socratic Tutor reported significantly greater support for critical, independent, and reflective thinking, suggesting that dialogic AI can stimulate metacognitive engagement and challenging recent narratives of de-skilling due to generative AI usage. These findings serve as a proof of concept for a broader pedagogical shift: the use of multi-agent systems (MAS) composed of specialised AI agents. To conceptualise this, we introduce the notion of orchestrated MAS, modular, pedagogically aligned agent constellations, curated by educators, that support diverse learning trajectories through differentiated roles and coordinated interaction. To anchor this shift, we propose an adapted offer-and-use model, in which students appropriate instructional offers from these agents. Beyond technical feasibility, we examine system-level implications for higher education institutions and students, including funding necessities, changes to faculty roles, curriculars, competencies and assessment practices. We conclude with a comparative cost-effectiveness analysis highlighting the scalability of such systems. In sum, this study contributes both empirical evidence and a conceptual roadmap for hybrid learning ecosystems that embed human-AI co-agency and pedagogical alignment.', 'abstract_zh': '生成式AI已不再是高等教育中的边缘工具，而是迅速发展成为一种通用基础设施，重塑知识的生成、传递和验证方式。本文呈现了一项受控实验的发现，该实验评估了基于建构主义理论的结构化对话设计的苏格拉底AI导师，比较了它与未经指导的AI聊天机器人互动对学生的影响。使用苏格拉底导师的学生报告了在批判性、独立性和反思性思维方面获得了显著更多的支持，这表明对话式AI可以激发元认知参与，挑战由于生成式AI使用而出现的去技能化叙事。这些发现作为多智能体系统（MAS）更广泛教学生态系统的概念证明：由专业化AI代理组成的协调MAS。为了构想这一转变，我们引入了协调MAS的概念，这是一种由教育者策划的模块化、教学目标对齐的代理组合，通过差异化角色和协调互动支持多样化的学习路径。为了支持这一转变，我们提出了一个修改后的提供与使用模型，使学生能够使用这些代理提供的教学服务。除了技术可行性，我们还探讨了对于高等教育机构和学生的系统级影响，包括资金需求、教职员工角色变化、课程设置、技能和评估实践的变化。最后，我们进行了一项成本效益分析，强调了此类系统的可扩展性。总的来说，本研究通过实证证据和概念蓝图，为嵌入人类与AI协作和教学目标对齐的混合学习生态系统做出了贡献。', 'title_zh': '超越自动化：苏格拉底式AI、认识论agency及其协同多智能体学习架构兴起的意义'}
{'arxiv_id': 'arXiv:2508.05113', 'title': 'EasySize: Elastic Analog Circuit Sizing via LLM-Guided Heuristic Search', 'authors': 'Xinyue Wu, Fan Hu, Shaik Jani Babu, Yi Zhao, Xinfei Guo', 'link': 'https://arxiv.org/abs/2508.05113', 'abstract': 'Analog circuit design is a time-consuming, experience-driven task in chip development. Despite advances in AI, developing universal, fast, and stable gate sizing methods for analog circuits remains a significant challenge. Recent approaches combine Large Language Models (LLMs) with heuristic search techniques to enhance generalizability, but they often depend on large model sizes and lack portability across different technology nodes. To overcome these limitations, we propose EasySize, the first lightweight gate sizing framework based on a finetuned Qwen3-8B model, designed for universal applicability across process nodes, design specifications, and circuit topologies. EasySize exploits the varying Ease of Attainability (EOA) of performance metrics to dynamically construct task-specific loss functions, enabling efficient heuristic search through global Differential Evolution (DE) and local Particle Swarm Optimization (PSO) within a feedback-enhanced flow. Although finetuned solely on 350nm node data, EasySize achieves strong performance on 5 operational amplifier (Op-Amp) netlists across 180nm, 45nm, and 22nm technology nodes without additional targeted training, and outperforms AutoCkt, a widely-used Reinforcement Learning based sizing framework, on 86.67\\% of tasks with more than 96.67\\% of simulation resources reduction. We argue that EasySize can significantly reduce the reliance on human expertise and computational resources in gate sizing, thereby accelerating and simplifying the analog circuit design process. EasySize will be open-sourced at a later date.', 'abstract_zh': '基于Qwen3-8B微调模型的轻量级门级尺寸优化框架EasySize', 'title_zh': 'EasySize: 基于LLM引导启发式搜索的弹性模拟电路尺寸调整'}
{'arxiv_id': 'arXiv:2508.05083', 'title': 'MedMKEB: A Comprehensive Knowledge Editing Benchmark for Medical Multimodal Large Language Models', 'authors': 'Dexuan Xu, Jieyi Wang, Zhongyan Chai, Yongzhi Cao, Hanpin Wang, Huamin Zhang, Yu Huang', 'link': 'https://arxiv.org/abs/2508.05083', 'abstract': 'Recent advances in multimodal large language models (MLLMs) have significantly improved medical AI, enabling it to unify the understanding of visual and textual information. However, as medical knowledge continues to evolve, it is critical to allow these models to efficiently update outdated or incorrect information without retraining from scratch. Although textual knowledge editing has been widely studied, there is still a lack of systematic benchmarks for multimodal medical knowledge editing involving image and text modalities. To fill this gap, we present MedMKEB, the first comprehensive benchmark designed to evaluate the reliability, generality, locality, portability, and robustness of knowledge editing in medical multimodal large language models. MedMKEB is built on a high-quality medical visual question-answering dataset and enriched with carefully constructed editing tasks, including counterfactual correction, semantic generalization, knowledge transfer, and adversarial robustness. We incorporate human expert validation to ensure the accuracy and reliability of the benchmark. Extensive single editing and sequential editing experiments on state-of-the-art general and medical MLLMs demonstrate the limitations of existing knowledge-based editing approaches in medicine, highlighting the need to develop specialized editing strategies. MedMKEB will serve as a standard benchmark to promote the development of trustworthy and efficient medical knowledge editing algorithms.', 'abstract_zh': 'Recent Advances in Multimodal Large Language Models for Medical AI: MedMKEB, the First Comprehensive Benchmark for Evaluating Medical Multimodal Knowledge Editing', 'title_zh': 'MedMKEB: 一种全面的医学多模态大型语言模型知识编辑基准'}
{'arxiv_id': 'arXiv:2508.05081', 'title': 'Cognitive Duality for Adaptive Web Agents', 'authors': 'Jiarun Liu, Chunhong Zhang, Zheng Hu', 'link': 'https://arxiv.org/abs/2508.05081', 'abstract': 'Web navigation represents a critical and challenging domain for evaluating artificial general intelligence (AGI), demanding complex decision-making within high-entropy, dynamic environments with combinatorially explosive action spaces. Current approaches to building autonomous web agents either focus on offline imitation learning or online exploration, but rarely integrate both paradigms effectively. Inspired by the dual-process theory of human cognition, we derive a principled decomposition into fast System 1 and slow System 2 cognitive processes. This decomposition provides a unifying perspective on existing web agent methodologies, bridging the gap between offline learning of intuitive reactive behaviors and online acquisition of deliberative planning capabilities. We implement this framework in CogniWeb, a modular agent architecture that adaptively toggles between fast intuitive processing and deliberate reasoning based on task complexity. Our evaluation on WebArena demonstrates that CogniWeb achieves competitive performance (43.96% success rate) while maintaining significantly higher efficiency (75% reduction in token usage).', 'abstract_zh': 'Web导航是评估人工通用智能(AGI)的关键性和挑战性领域，要求在高熵、动态环境中进行复杂的决策，在具有组合爆炸性动作空间的环境中提出挑战。当前构建自主网页代理的方法要么集中于离线模仿学习，要么专注于在线探索，但很少能有效结合这两种范式。受到人类认知的双过程理论启发，我们提出了一种原理性的分解，区分快速的System 1和缓慢的System 2认知过程。这种分解为现有的网页代理方法提供了一个统一的视角，弥合了离线学习直观反应行为与在线获取深思熟虑规划能力之间的差距。我们通过CogniWeb模块化代理架构实现了这一框架，该架构根据任务复杂性在快速直观处理与深思熟虑推理之间 adaptable地切换。我们在WebArena上的评估表明，CogniWeb在保持显著更高的效率（75%的令牌使用量减少）的同时，实现了竞争力的性能（成功率43.96%）。', 'title_zh': '适应性网络代理的认知二元性'}
{'arxiv_id': 'arXiv:2508.05009', 'title': 'Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses', 'authors': 'Bin Han, Robert Wolfe, Anat Caspi, Bill Howe', 'link': 'https://arxiv.org/abs/2508.05009', 'abstract': 'We explore the application of large language models (LLMs) to empower domain experts in integrating large, heterogeneous, and noisy urban spatial datasets. Traditional rule-based integration methods are unable to cover all edge cases, requiring manual verification and repair. Machine learning approaches require collecting and labeling of large numbers of task-specific samples. In this study, we investigate the potential of LLMs for spatial data integration. Our analysis first considers how LLMs reason about environmental spatial relationships mediated by human experience, such as between roads and sidewalks. We show that while LLMs exhibit spatial reasoning capabilities, they struggle to connect the macro-scale environment with the relevant computational geometry tasks, often producing logically incoherent responses. But when provided relevant features, thereby reducing dependence on spatial reasoning, LLMs are able to generate high-performing results. We then adapt a review-and-refine method, which proves remarkably effective in correcting erroneous initial responses while preserving accurate responses. We discuss practical implications of employing LLMs for spatial data integration in real-world contexts and outline future research directions, including post-training, multi-modal integration methods, and support for diverse data formats. Our findings position LLMs as a promising and flexible alternative to traditional rule-based heuristics, advancing the capabilities of adaptive spatial data integration.', 'abstract_zh': '我们探索大型语言模型（LLMs）在增强领域专家整合大规模、异构和噪音城市空间数据方面的应用。传统的基于规则的集成方法无法覆盖所有边缘情况，需要人工验证和修复。机器学习方法需要收集和标注大量特定任务的数据样本。在本研究中，我们 investigate LLMs 在空间数据集成中的潜在应用。我们的分析首先考虑了LLMs 如何基于人类经验处理环境空间关系，例如道路与人行道之间的关系。我们发现尽管LLMs展示出空间推理能力，但在连接宏观环境与相关计算几何任务方面常常表现不佳，常产生逻辑不连贯的响应。但在提供相关特征后，从而减少对空间推理的依赖，LLMs能够生成高性能的结果。我们then适应了一种审查和修正的方法，这种方法在纠正初始错误响应的同时保留了准确的响应，证明非常有效。我们讨论了在实际应用中采用LLMs进行空间数据集成的实用意义，并列出了未来研究方向，包括后训练、多模态集成方法以及支持多种数据格式。我们的研究结果定位LLMs为传统基于规则的启发式方法的一种有前景且灵活的替代方案，推动了自适应空间数据集成能力的发展。', 'title_zh': '大型语言模型能否整合空间数据？关于推理优势与计算劣势的经验洞察'}
{'arxiv_id': 'arXiv:2508.05006', 'title': 'The Docking Game: Loop Self-Play for Fast, Dynamic, and Accurate Prediction of Flexible Protein--Ligand Binding', 'authors': 'Youzhi Zhang, Yufei Li, Gaofeng Meng, Hongbin Liu, Jiebo Luo', 'link': 'https://arxiv.org/abs/2508.05006', 'abstract': "Molecular docking is a crucial aspect of drug discovery, as it predicts the binding interactions between small-molecule ligands and protein pockets. However, current multi-task learning models for docking often show inferior performance in ligand docking compared to protein pocket docking. This disparity arises largely due to the distinct structural complexities of ligands and proteins. To address this issue, we propose a novel game-theoretic framework that models the protein-ligand interaction as a two-player game called the Docking Game, with the ligand docking module acting as the ligand player and the protein pocket docking module as the protein player. To solve this game, we develop a novel Loop Self-Play (LoopPlay) algorithm, which alternately trains these players through a two-level loop. In the outer loop, the players exchange predicted poses, allowing each to incorporate the other's structural predictions, which fosters mutual adaptation over multiple iterations. In the inner loop, each player dynamically refines its predictions by incorporating its own predicted ligand or pocket poses back into its model. We theoretically show the convergence of LoopPlay, ensuring stable optimization. Extensive experiments conducted on public benchmark datasets demonstrate that LoopPlay achieves approximately a 10\\% improvement in predicting accurate binding modes compared to previous state-of-the-art methods. This highlights its potential to enhance the accuracy of molecular docking in drug discovery.", 'abstract_zh': '分子对接是药物发现的关键方面，它预测小分子配体与蛋白质口袋之间的结合相互作用。然而，当前用于分子对接的多任务学习模型在配体对接方面的性能往往不如蛋白质口袋对接。这种差异主要归因于配体和蛋白质的结构复杂性不同。为了解决这一问题，我们提出了一种新的博弈理论框架，将蛋白质-配体相互作用建模为一个名为对接博弈的两人博弈，配体对接模块作为配体玩家，蛋白质口袋对接模块作为蛋白质玩家。为了解决这个博弈，我们开发了一种新颖的循环自我博弈（LoopPlay）算法，通过两层循环交替训练这些玩家。在外层循环中，玩家相互交换预测姿势，使每方能够 Incorporate 对方的结构预测，从而在多轮迭代中促进相互适应。在内层循环中，每个玩家动态地通过将其自身预测的配体或口袋姿势纳入其模型来改进其预测。我们从理论上证明了 LoopPlay 的收敛性，确保了优化的稳定。在公共基准数据集上进行的广泛实验表明，LoopPlay 在预测准确的结合模式方面比以前的最佳方法约提高了 10%。这突显了其在提高药物发现中分子对接的准确性方面的潜力。', 'title_zh': '搁码头博弈：环形自我游戏以实现快速、动态且准确的柔性蛋白质-配体结合预测'}
{'arxiv_id': 'arXiv:2508.04915', 'title': 'ConfAgents: A Conformal-Guided Multi-Agent Framework for Cost-Efficient Medical Diagnosis', 'authors': 'Huiya Zhao, Yinghao Zhu, Zixiang Wang, Yasha Wang, Junyi Gao, Liantao Ma', 'link': 'https://arxiv.org/abs/2508.04915', 'abstract': "The efficacy of AI agents in healthcare research is hindered by their reliance on static, predefined strategies. This creates a critical limitation: agents can become better tool-users but cannot learn to become better strategic planners, a crucial skill for complex domains like healthcare. We introduce HealthFlow, a self-evolving AI agent that overcomes this limitation through a novel meta-level evolution mechanism. HealthFlow autonomously refines its own high-level problem-solving policies by distilling procedural successes and failures into a durable, strategic knowledge base. To anchor our research and facilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark featuring complex, realistic health data analysis tasks derived from peer-reviewed clinical research. Our comprehensive experiments demonstrate that HealthFlow's self-evolving approach significantly outperforms state-of-the-art agent frameworks. This work marks a necessary shift from building better tool-users to designing smarter, self-evolving task-managers, paving the way for more autonomous and effective AI for scientific discovery.", 'abstract_zh': 'AI代理在医疗健康研究中的效用受限于其对静态、预定义策略的依赖。这造成了一个关键限制：代理可以变得更善于使用工具，但却不能学会成为更好的战略规划者，这是一个对于像医疗健康这样复杂领域至关重要的技能。我们介绍了HealthFlow，一种通过新型元水平进化机制克服这一限制的自我进化AI代理。HealthFlow自主提炼程序上的成功和失败经验，形成持久的战略知识库，以不断优化其高层次问题解决策略。为了锚定我们的研究并促进可重复评估，我们引入了EHRFlowBench，这是一个新的基准测试，包含来自同行评审临床研究的复杂、现实的健康数据分析任务。我们全面的实验表明，HealthFlow的自我进化方法在性能上显著优于最先进的代理框架。这项工作标志着从构建更好的工具使用者转向设计更智能、自我进化的任务管理者的关键转变，为更具自主性和有效性的科学发现AI铺平了道路。', 'title_zh': 'ConformAgents: 一种基于容 conformal 指导的多-agent 框架，用于成本高效的医疗诊断'}
{'arxiv_id': 'arXiv:2508.04848', 'title': 'Large Language Models Reasoning Abilities Under Non-Ideal Conditions After RL-Fine-Tuning', 'authors': 'Chang Tian, Matthew B. Blaschko, Mingzhe Xing, Xiuxing Li, Yinliang Yue, Marie-Francine Moens', 'link': 'https://arxiv.org/abs/2508.04848', 'abstract': 'Reinforcement learning (RL) has become a key technique for enhancing the reasoning abilities of large language models (LLMs), with policy-gradient algorithms dominating the post-training stage because of their efficiency and effectiveness. However, most existing benchmarks evaluate large-language-model reasoning under idealized settings, overlooking performance in realistic, non-ideal scenarios. We identify three representative non-ideal scenarios with practical relevance: summary inference, fine-grained noise suppression, and contextual filtering. We introduce a new research direction guided by brain-science findings that human reasoning remains reliable under imperfect inputs. We formally define and evaluate these challenging scenarios. We fine-tune three LLMs and a state-of-the-art large vision-language model (LVLM) using RL with a representative policy-gradient algorithm and then test their performance on eight public datasets. Our results reveal that while RL fine-tuning improves baseline reasoning under idealized settings, performance declines significantly across all three non-ideal scenarios, exposing critical limitations in advanced reasoning capabilities. Although we propose a scenario-specific remediation method, our results suggest current methods leave these reasoning deficits largely unresolved. This work highlights that the reasoning abilities of large models are often overstated and underscores the importance of evaluating models under non-ideal scenarios. The code and data will be released at XXXX.', 'abstract_zh': 'reinforcement learning (RL)已在增强大型语言模型（LLMs）的推理能力方面成为关键技术，策略梯度算法因其高效性和有效性在训练后阶段占据主导地位。然而，现有的大多数基准测试在理想化的设定下评估大型语言模型的推理能力，忽视了在现实的非理想场景中的表现。我们识别了三个具有实际意义的非理想场景：摘要推断、精细噪声抑制和上下文过滤。我们提出了一种新的研究方向，受到脑科学发现的启发，体现人类推理在不完美的输入下依然可靠。我们正式定义并评估了这些具有挑战性的场景。我们使用RL和一个代表性的策略梯度算法微调了三种LLMs和一个最先进的大型视觉-语言模型（LVLM），并在八个公开数据集上测试它们的性能。结果显示，虽然RL微调在理想化的设定下提高了基线推理能力，但在所有三个非理想场景中的表现显著下降，揭示了高级推理能力的关键限制。尽管我们提出了一种特定场景的补救方法，但结果表明当前方法在很大程度上未能解决这些推理缺陷。这项工作凸显了大型模型的推理能力往往被夸大，并强调了在非理想场景下评估模型的重要性。代码和数据将在XXXX发布。', 'title_zh': '大型语言模型在非理想条件下的推理能力：强化学习微调后的表现'}
{'arxiv_id': 'arXiv:2508.04846', 'title': 'Fine-Tuning Small Language Models (SLMs) for Autonomous Web-based Geographical Information Systems (AWebGIS)', 'authors': 'Mahdi Nazari Ashani, Ali Asghar Alesheikh, Saba Kazemi, Kimya Kheirkhah, Yasin Mohammadi, Fatemeh Rezaie, Amir Mahdi Manafi, Hedieh Zarkesh', 'link': 'https://arxiv.org/abs/2508.04846', 'abstract': "Autonomous web-based geographical information systems (AWebGIS) aim to perform geospatial operations from natural language input, providing intuitive, intelligent, and hands-free interaction. However, most current solutions rely on cloud-based large language models (LLMs), which require continuous internet access and raise users' privacy and scalability issues due to centralized server processing. This study compares three approaches to enabling AWebGIS: (1) a fully-automated online method using cloud-based LLMs (e.g., Cohere); (2) a semi-automated offline method using classical machine learning classifiers such as support vector machine and random forest; and (3) a fully autonomous offline (client-side) method based on a fine-tuned small language model (SLM), specifically T5-small model, executed in the client's web browser. The third approach, which leverages SLMs, achieved the highest accuracy among all methods, with an exact matching accuracy of 0.93, Levenshtein similarity of 0.99, and recall-oriented understudy for gisting evaluation ROUGE-1 and ROUGE-L scores of 0.98. Crucially, this client-side computation strategy reduces the load on backend servers by offloading processing to the user's device, eliminating the need for server-based inference. These results highlight the feasibility of browser-executable models for AWebGIS solutions.", 'abstract_zh': '基于自主的网络地理信息系统（AWebGIS）旨在从自然语言输入中执行空间操作，提供直观、智能且无需手动的交互。然而，当前大多数解决方案依赖于基于云的大语言模型（LLMs），这需要持续的互联网连接，并由于集中式服务器处理而引起用户隐私和可扩展性问题。本研究比较了三种使AWebGIS自主化的 approach：（1）完全自动化在线方法，使用基于云的LLMs（如Cohere）；（2）半自动化离线方法，使用经典机器学习分类器如支持向量机和支持向量森林；（3）基于微调小语言模型（SLM），特别是T5-small模型，在客户端浏览器中执行的完全自主离线（客户端侧）方法。第三种方法利用SLMs，实现了所有方法中最高的准确性，精确匹配准确率为0.93，Levenshtein相似度为0.99，以及基于召回的摘要评估ROUGE-1和ROUGE-L得分为0.98。关键的是，这种客户端计算策略通过将处理任务转移到用户的设备上减轻了后端服务器的负担，消除了基于服务器的推理需求。这些结果突显了浏览器可执行模型在AWebGIS解决方案中的可行性。', 'title_zh': '细调小型语言模型（SLMs）以应用于自主基于Web的地理信息系统（AWebGIS）'}
{'arxiv_id': 'arXiv:2508.04720', 'title': 'Who is a Better Player: LLM against LLM', 'authors': 'Yingjie Zhou, Jiezhang Cao, Farong Wen, Li Xu, Yanwei Jiang, Jun Jia, Ronghui Li, Xiaohong Liu, Yu Zhou, Xiongkuo Min, Jie Guo, Zicheng Zhang, Guangtao Zhai', 'link': 'https://arxiv.org/abs/2508.04720', 'abstract': "Adversarial board games, as a paradigmatic domain of strategic reasoning and intelligence, have long served as both a popular competitive activity and a benchmark for evaluating artificial intelligence (AI) systems. Building on this foundation, we propose an adversarial benchmarking framework to assess the comprehensive performance of Large Language Models (LLMs) through board games competition, compensating the limitation of data dependency of the mainstream Question-and-Answer (Q&A) based benchmark method. We introduce Qi Town, a specialized evaluation platform that supports 5 widely played games and involves 20 LLM-driven players. The platform employs both the Elo rating system and a novel Performance Loop Graph (PLG) to quantitatively evaluate the technical capabilities of LLMs, while also capturing Positive Sentiment Score (PSS) throughout gameplay to assess mental fitness. The evaluation is structured as a round-robin tournament, enabling systematic comparison across players. Experimental results indicate that, despite technical differences, most LLMs remain optimistic about winning and losing, demonstrating greater adaptability to high-stress adversarial environments than humans. On the other hand, the complex relationship between cyclic wins and losses in PLGs exposes the instability of LLMs' skill play during games, warranting further explanation and exploration.", 'abstract_zh': 'adversarial棋盘游戏作为战略推理和智能的一个典范领域，长期以来既是流行的竞技活动，也是评估人工智能系统性能的标准。基于此，我们提出了一种对抗基准框架，通过棋盘游戏竞赛评估大型语言模型（LLMs）的综合性能，弥补主流基于问答（Q&A）基准方法的数据依赖性限制。我们介绍了棋镇，这是一个专门的评估平台，支持5种广泛玩的棋盘游戏，并涉及20个LLM驱动的玩家。该平台采用Elo排名系统和新型性能循环图（PLG）来定量评估LLMs的技术能力，同时在整个游戏过程中捕获正面情绪分值（PSS）来评估玩家的心理状态。评估结构化为循环赛制，使玩家之间的系统比较成为可能。实验结果表明，尽管存在技术差异，大多数LLMs在赢得和失去方面的乐观态度一致，显示出比人类更大的适应高压对抗环境的能力。另一方面，PLGs中循环胜利与失败之间的复杂关系揭示了LLMs在游戏中的技能表现不稳定，需要进一步解释和探究。', 'title_zh': '谁是更好的玩家：大规模语言模型对抗大规模语言模型'}
{'arxiv_id': 'arXiv:2508.04719', 'title': 'GeoFlow: Agentic Workflow Automation for Geospatial Tasks', 'authors': 'Amulya Bhattaram, Justin Chung, Stanley Chung, Ranit Gupta, Janani Ramamoorthy, Kartikeya Gullapalli, Diana Marculescu, Dimitrios Stamoulis', 'link': 'https://arxiv.org/abs/2508.04719', 'abstract': 'We present GeoFlow, a method that automatically generates agentic workflows for geospatial tasks. Unlike prior work that focuses on reasoning decomposition and leaves API selection implicit, our method provides each agent with detailed tool-calling objectives to guide geospatial API invocation at runtime. GeoFlow increases agentic success by 6.8% and reduces token usage by up to fourfold across major LLM families compared to state-of-the-art approaches.', 'abstract_zh': 'GeoFlow：一种自动生成地理空间任务代理工作流的方法', 'title_zh': 'GeoFlow: 地理空间任务的自主工作流自动化'}
{'arxiv_id': 'arXiv:2508.04714', 'title': 'Prescriptive Agents based on Rag for Automated Maintenance (PARAM)', 'authors': 'Chitranshu Harbola, Anupam Purwar', 'link': 'https://arxiv.org/abs/2508.04714', 'abstract': 'Industrial machinery maintenance requires timely intervention to prevent catastrophic failures and optimize operational efficiency. This paper presents an integrated Large Language Model (LLM)-based intelligent system for prescriptive maintenance that extends beyond traditional anomaly detection to provide actionable maintenance recommendations. Building upon our prior LAMP framework for numerical data analysis, we develop a comprehensive solution that combines bearing vibration frequency analysis with multi agentic generation for intelligent maintenance planning. Our approach serializes bearing vibration data (BPFO, BPFI, BSF, FTF frequencies) into natural language for LLM processing, enabling few-shot anomaly detection with high accuracy. The system classifies fault types (inner race, outer race, ball/roller, cage faults) and assesses severity levels. A multi-agentic component processes maintenance manuals using vector embeddings and semantic search, while also conducting web searches to retrieve comprehensive procedural knowledge and access up-to-date maintenance practices for more accurate and in-depth recommendations. The Gemini model then generates structured maintenance recommendations includes immediate actions, inspection checklists, corrective measures, parts requirements, and timeline specifications. Experimental validation in bearing vibration datasets demonstrates effective anomaly detection and contextually relevant maintenance guidance. The system successfully bridges the gap between condition monitoring and actionable maintenance planning, providing industrial practitioners with intelligent decision support. This work advances the application of LLMs in industrial maintenance, offering a scalable framework for prescriptive maintenance across machinery components and industrial sectors.', 'abstract_zh': '工业机械维护需要及时干预以防止灾难性 的故障并优化运营效率。本文提出了一种基于大型语言模型（LLM）的智能预测性 维护系统，该系统超越了传统的异常检测，提供可 动态的维护建议。依托我们之前的 LAMP 框架进行数值数据分析，，我们开发了一个综合性的系统，将轴承振动频率分析与多代理生成结合，以实现智能维护计划。我们的方法将轴承振动数据（BPFO、BPFI、BSF、FTF 频率）转换为自然语言供 LLM 处理，实现高精度的异常检测。该系统可以对故障类型（内圈故障、外圈故障、类 蛇形滚子故障、保持架故障）进行分类并评估严重程度。多代理系统使用向量嵌入和 语义分类处理维护手册，同时进行网络搜索以检索全面的程序知识并 最新的维护实践，从而提供更准确的深入建议。Gemini 系统然后生成结构化的维护建议，包括立即行动、检查清单、纠正措施、文件要求和时间表规范。在轴承振动数据集上的实验验证了异常检测和上下文相关维护指导。该系统成功地地填补了状态监测与动态可 动态的维护规划 之间的差距，为工业从业者提供智能决策支持。这项工作推进了 LLM 在工业维护中的的应用，提供了可扩展的框架以实现整个机械设备和制造业领域的预测维护。', 'title_zh': '基于Rag的规范代理用于自动化维护（PARAM）'}
{'arxiv_id': 'arXiv:2508.05634', 'title': 'Towards Generalizable Safety in Crowd Navigation via Conformal Uncertainty Handling', 'authors': 'Jianpeng Yao, Xiaopan Zhang, Yu Xia, Zejin Wang, Amit K. Roy-Chowdhury, Jiachen Li', 'link': 'https://arxiv.org/abs/2508.05634', 'abstract': "Mobile robots navigating in crowds trained using reinforcement learning are known to suffer performance degradation when faced with out-of-distribution scenarios. We propose that by properly accounting for the uncertainties of pedestrians, a robot can learn safe navigation policies that are robust to distribution shifts. Our method augments agent observations with prediction uncertainty estimates generated by adaptive conformal inference, and it uses these estimates to guide the agent's behavior through constrained reinforcement learning. The system helps regulate the agent's actions and enables it to adapt to distribution shifts. In the in-distribution setting, our approach achieves a 96.93% success rate, which is over 8.80% higher than the previous state-of-the-art baselines with over 3.72 times fewer collisions and 2.43 times fewer intrusions into ground-truth human future trajectories. In three out-of-distribution scenarios, our method shows much stronger robustness when facing distribution shifts in velocity variations, policy changes, and transitions from individual to group dynamics. We deploy our method on a real robot, and experiments show that the robot makes safe and robust decisions when interacting with both sparse and dense crowds. Our code and videos are available on this https URL.", 'abstract_zh': '基于适应性区间推断的鲁棒导航策略学习：面向crowds场景下的性能退化问题', 'title_zh': '通过游容性不确定性处理实现 crowdsNavigation 的普遍安全性'}
{'arxiv_id': 'arXiv:2508.05633', 'title': 'KuaiLive: A Real-time Interactive Dataset for Live Streaming Recommendation', 'authors': 'Changle Qu, Sunhao Dai, Ke Guo, Liqin Zhao, Yanan Niu, Xiao Zhang, Jun Xu', 'link': 'https://arxiv.org/abs/2508.05633', 'abstract': 'Live streaming platforms have become a dominant form of online content consumption, offering dynamically evolving content, real-time interactions, and highly engaging user experiences. These unique characteristics introduce new challenges that differentiate live streaming recommendation from traditional recommendation settings and have garnered increasing attention from industry in recent years. However, research progress in academia has been hindered by the lack of publicly available datasets that accurately reflect the dynamic nature of live streaming environments. To address this gap, we introduce KuaiLive, the first real-time, interactive dataset collected from Kuaishou, a leading live streaming platform in China with over 400 million daily active users. The dataset records the interaction logs of 23,772 users and 452,621 streamers over a 21-day period. Compared to existing datasets, KuaiLive offers several advantages: it includes precise live room start and end timestamps, multiple types of real-time user interactions (click, comment, like, gift), and rich side information features for both users and streamers. These features enable more realistic simulation of dynamic candidate items and better modeling of user and streamer behaviors. We conduct a thorough analysis of KuaiLive from multiple perspectives and evaluate several representative recommendation methods on it, establishing a strong benchmark for future research. KuaiLive can support a wide range of tasks in the live streaming domain, such as top-K recommendation, click-through rate prediction, watch time prediction, and gift price prediction. Moreover, its fine-grained behavioral data also enables research on multi-behavior modeling, multi-task learning, and fairness-aware recommendation. The dataset and related resources are publicly available at this https URL.', 'abstract_zh': '快手直播：一个来自中国领先直播平台的实时互动数据集', 'title_zh': 'KuaiLive: 一种实时互动直播推荐数据集'}
{'arxiv_id': 'arXiv:2508.05628', 'title': 'H-Net++: Hierarchical Dynamic Chunking for Tokenizer-Free Language Modelling in Morphologically-Rich Languages', 'authors': 'Mehrdad Zakershahrak, Samira Ghodratnama', 'link': 'https://arxiv.org/abs/2508.05628', 'abstract': 'Byte-level language models eliminate fragile tokenizers but face computational challenges in morphologically-rich languages (MRLs), where words span many bytes. We propose H-NET++, a hierarchical dynamic-chunking model that learns linguistically-informed segmentation through end-to-end training. Key innovations include: (1) a lightweight Transformer context-mixer (1.9M parameters) for cross-chunk attention, (2) a two-level latent hyper-prior for document-level consistency, (3) specialized handling of orthographic artifacts (e.g. Persian ZWNJ), and (4) curriculum-based training with staged sequence lengths. On a 1.4B-token Persian corpus, H-NET++ achieves state-of-the-art results: 0.159 BPB reduction versus BPE-based GPT-2-fa (12% better compression), 5.4pp gain on ParsGLUE, 53% improved robustness to ZWNJ corruption, and 73.8% F1 on gold morphological boundaries. Our learned chunks align with Persian morphology without explicit supervision, demonstrating that hierarchical dynamic chunking provides an effective tokenizer-free solution for MRLs while maintaining computational efficiency.', 'abstract_zh': '字级语言模型消除了脆弱的分词器但在富形态语言中面临计算挑战：H-NET++是一种分层动态分割模型，通过端到端训练学习语言学导向的分割', 'title_zh': 'H-Net++: 基于层次动态切块的形态丰富语言无分词器语言建模'}
{'arxiv_id': 'arXiv:2508.05625', 'title': 'How Do LLMs Persuade? Linear Probes Can Uncover Persuasion Dynamics in Multi-Turn Conversations', 'authors': 'Brandon Jaipersaud, David Krueger, Ekdeep Singh Lubana', 'link': 'https://arxiv.org/abs/2508.05625', 'abstract': 'Large Language Models (LLMs) have started to demonstrate the ability to persuade humans, yet our understanding of how this dynamic transpires is limited. Recent work has used linear probes, lightweight tools for analyzing model representations, to study various LLM skills such as the ability to model user sentiment and political perspective. Motivated by this, we apply probes to study persuasion dynamics in natural, multi-turn conversations. We leverage insights from cognitive science to train probes on distinct aspects of persuasion: persuasion success, persuadee personality, and persuasion strategy. Despite their simplicity, we show that they capture various aspects of persuasion at both the sample and dataset levels. For instance, probes can identify the point in a conversation where the persuadee was persuaded or where persuasive success generally occurs across the entire dataset. We also show that in addition to being faster than expensive prompting-based approaches, probes can do just as well and even outperform prompting in some settings, such as when uncovering persuasion strategy. This suggests probes as a plausible avenue for studying other complex behaviours such as deception and manipulation, especially in multi-turn settings and large-scale dataset analysis where prompting-based methods would be computationally inefficient.', 'abstract_zh': '大型语言模型（LLMs）已经开始展示出说服人类的能力，但我们对其背后动态的理解仍然有限。近期的研究使用了线性探针——一种轻量级的模型表示分析工具——探讨了各种LLM技能，如建模用户情感和政治观点的能力。受此启发，我们将探针应用于研究自然、多轮对话中的说服动态。我们借助认知科学的洞见，训练探针关注说服的多个方面：说服成功、说服对象的性格和说服策略。尽管探针简单，但我们表明它们在样本和数据集层面捕捉了说服的多种方面。例如，探针可以识别对话中说服对象被说服的点，或整个数据集中说服成功的普遍趋势。我们还展示了探针不仅比昂贵的提示基方法更快，而且在某些情况下，如揭示说服策略时，甚至可以和提示方法表现得一样好，甚至更好。这表明探针可能是研究其他复杂行为，如欺骗和操纵的一个有希望的途径，特别是在多轮对话和大规模数据集分析中，提示基方法可能会在计算效率方面显得不够高效。', 'title_zh': '如何进行说服？线性探针可以揭示多轮对话中的说服动态。'}
{'arxiv_id': 'arXiv:2508.05616', 'title': 'TrajEvo: Trajectory Prediction Heuristics Design via LLM-driven Evolution', 'authors': 'Zhikai Zhao, Chuanbo Hua, Federico Berto, Kanghoon Lee, Zihan Ma, Jiachen Li, Jinkyoo Park', 'link': 'https://arxiv.org/abs/2508.05616', 'abstract': 'Trajectory prediction is a critical task in modeling human behavior, especially in safety-critical domains such as social robotics and autonomous vehicle navigation. Traditional heuristics based on handcrafted rules often lack accuracy and generalizability. Although deep learning approaches offer improved performance, they typically suffer from high computational cost, limited explainability, and, importantly, poor generalization to out-of-distribution (OOD) scenarios. In this paper, we introduce TrajEvo, a framework that leverages Large Language Models (LLMs) to automatically design trajectory prediction heuristics. TrajEvo employs an evolutionary algorithm to generate and refine prediction heuristics from past trajectory data. We propose two key innovations: Cross-Generation Elite Sampling to encourage population diversity, and a Statistics Feedback Loop that enables the LLM to analyze and improve alternative predictions. Our evaluations demonstrate that TrajEvo outperforms existing heuristic methods across multiple real-world datasets, and notably surpasses both heuristic and deep learning methods in generalizing to an unseen OOD real-world dataset. TrajEvo marks a promising step toward the automated design of fast, explainable, and generalizable trajectory prediction heuristics. We release our source code to facilitate future research at this https URL.', 'abstract_zh': '基于大型语言模型的轨迹进化预测框架', 'title_zh': 'TrajEvo: 基于LLM驱动进化的时间序列预测启发式设计'}
{'arxiv_id': 'arXiv:2508.05615', 'title': 'Test-Time Reinforcement Learning for GUI Grounding via Region Consistency', 'authors': 'Yong Du, Yuchen Yan, Fei Tang, Zhengxi Lu, Chang Zong, Weiming Lu, Shengpei Jiang, Yongliang Shen', 'link': 'https://arxiv.org/abs/2508.05615', 'abstract': 'Graphical User Interface (GUI) grounding, the task of mapping natural language instructions to precise screen coordinates, is fundamental to autonomous GUI agents. While existing methods achieve strong performance through extensive supervised training or reinforcement learning with labeled rewards, they remain constrained by the cost and availability of pixel-level annotations. We observe that when models generate multiple predictions for the same GUI element, the spatial overlap patterns reveal implicit confidence signals that can guide more accurate localization. Leveraging this insight, we propose GUI-RC (Region Consistency), a test-time scaling method that constructs spatial voting grids from multiple sampled predictions to identify consensus regions where models show highest agreement. Without any training, GUI-RC improves accuracy by 2-3% across various architectures on ScreenSpot benchmarks. We further introduce GUI-RCPO (Region Consistency Policy Optimization), which transforms these consistency patterns into rewards for test-time reinforcement learning. By computing how well each prediction aligns with the collective consensus, GUI-RCPO enables models to iteratively refine their outputs on unlabeled data during inference. Extensive experiments demonstrate the generality of our approach: GUI-RC boosts Qwen2.5-VL-3B-Instruct from 80.11% to 83.57% on ScreenSpot-v2, while GUI-RCPO further improves it to 85.14% through self-supervised optimization. Our approach reveals the untapped potential of test-time scaling and test-time reinforcement learning for GUI grounding, offering a promising path toward more robust and data-efficient GUI agents.', 'abstract_zh': '图形用户界面（GUI）grounding：从自然语言指令到精确屏幕坐标映射的任务是自主GUI代理的基础。我们观察到，当模型对同一GUI元素生成多个预测时，空间重叠模式揭示了隐含的信心信号，这些信号可以指导更精确的位置定位。基于这一洞察，我们提出了GUI-RC（区域一致性）方法，该方法在测试时构建由多个采样预测生成的空间投票网格，以识别模型一致性最高的共识区域。GUI-RC 在各种架构上提高了 ScreenSpot 基准上的准确性，提升了 2-3%。我们进一步引入了 GUI-RCPO（区域一致性策略优化），将其一致模式转换为测试时强化学习的奖励。通过计算每个预测与集体共识的吻合程度，GUI-RCPO 允许模型在推断过程中逐步细化其在未标记数据上的输出。广泛的实验表明，我们的方法具有普遍适用性：GUI-RC 将 Qwen2.5-VL-3B-Instruct 在 ScreenSpot-v2 上的表现从 80.11% 提高到 83.57%，而 GUI-RCPO 通过自我监督优化进一步提高到 85.14%。我们的方法揭示了测试时放大和测试时强化学习在GUI定位方面的潜在价值，为更稳健和数据高效的GUI代理提供了充满希望的途径。', 'title_zh': '基于区域一致性的测试时强化学习GUI定位'}
{'arxiv_id': 'arXiv:2508.05614', 'title': 'OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks', 'authors': 'Zixuan Wang, Dingming Li, Hongxing Li, Shuo Chen, Yuchen Yan, Wenqi Zhang, Yongliang Shen, Weiming Lu, Jun Xiao, Yueting Zhuang', 'link': 'https://arxiv.org/abs/2508.05614', 'abstract': 'Large language models excel at abstract reasoning but their capacity for embodied agent reasoning remains largely unexplored. We present OmniEAR, a comprehensive framework for evaluating how language models reason about physical interactions, tool usage, and multi-agent coordination in embodied tasks. Unlike existing benchmarks that provide predefined tool sets or explicit collaboration directives, OmniEAR requires agents to dynamically acquire capabilities and autonomously determine coordination strategies based on task demands. Through text-based environment representation, we model continuous physical properties and complex spatial relationships across 1,500 scenarios spanning household and industrial domains. Our systematic evaluation reveals severe performance degradation when models must reason from constraints: while achieving 85-96% success with explicit instructions, performance drops to 56-85% for tool reasoning and 63-85% for implicit collaboration, with compound tasks showing over 50% failure rates. Surprisingly, complete environmental information degrades coordination performance, indicating models cannot filter task-relevant constraints. Fine-tuning improves single-agent tasks dramatically (0.6% to 76.3%) but yields minimal multi-agent gains (1.5% to 5.5%), exposing fundamental architectural limitations. These findings demonstrate that embodied reasoning poses fundamentally different challenges than current models can address, establishing OmniEAR as a rigorous benchmark for evaluating and advancing embodied AI systems. Our code and data are included in the supplementary materials and will be open-sourced upon acceptance.', 'abstract_zh': '大型语言模型在抽象推理方面表现出色，但在 embodied 代理推理能力上尚未得到充分探索。我们提出了 OmniEAR，一个全面的框架，用于评估语言模型在体表现务中关于物理交互、工具使用和多代理协调的推理能力。与现有基准中提供预定义工具集或明确协作指令不同，OmniEAR 要求代理动态获取能力并在任务需求基础上自主确定协调策略。通过基于文本的环境表示，我们建模了 1,500 种场景中连续的物理属性和复杂的空间关系，涵盖了 household 和工业领域。我们的系统性评估揭示了在处理约束时性能严重退化：在明确指令下成功率达 85-96%，但在工具推理中降至 56-85%，在隐式协作中降至 63-85%，而复合作业的失败率超过 50%。令人惊讶的是，完整环境信息反而降低了协调性能，表明模型无法过滤出与任务相关的信息。微调显著提高了单代理任务的表现（0.6% 至 76.3%），但在多代理方面的增益有限（1.5% 至 5.5%），暴露了基础架构的局限性。这些发现表明，体表现务推理提出了当前模型无法解决的根本性挑战，并确立了 OmniEAR 作为评估和推进体表现务 AI 系统的严格基准。我们的代码和数据包含在附录材料中，并将在接受后开源。', 'title_zh': 'OmniEAR: 人体感知任务中代理推理的基准测试'}
{'arxiv_id': 'arXiv:2508.05613', 'title': 'Cooper: Co-Optimizing Policy and Reward Models in Reinforcement Learning for Large Language Models', 'authors': 'Haitao Hong, Yuchen Yan, Xingyu Wu, Guiyang Hou, Wenqi Zhang, Weiming Lu, Yongliang Shen, Jun Xiao', 'link': 'https://arxiv.org/abs/2508.05613', 'abstract': 'Large language models (LLMs) have demonstrated remarkable performance in reasoning tasks, where reinforcement learning (RL) serves as a key algorithm for enhancing their reasoning capabilities. Currently, there are two mainstream reward paradigms: model-based rewards and rule-based rewards. However, both approaches suffer from limitations: rule-based rewards lack robustness, while model-based rewards are vulnerable to reward hacking. To address these issues, we propose Cooper(Co-optimizing Policy Model and Reward Model), a RL framework that jointly optimizes both the policy model and the reward model. Cooper leverages the high precision of rule-based rewards when identifying correct responses, and dynamically constructs and selects positive-negative sample pairs for continued training the reward model. This design enhances robustness and mitigates the risk of reward hacking. To further support Cooper, we introduce a hybrid annotation strategy that efficiently and accurately generates training data for the reward model. We also propose a reference-based reward modeling paradigm, where the reward model takes a reference answer as input. Based on this design, we train a reward model named VerifyRM, which achieves higher accuracy on VerifyBench compared to other models of the same size. We conduct reinforcement learning using both VerifyRM and Cooper. Our experiments show that Cooper not only alleviates reward hacking but also improves end-to-end RL performance, for instance, achieving a 0.54% gain in average accuracy on Qwen2.5-1.5B-Instruct. Our findings demonstrate that dynamically updating reward model is an effective way to combat reward hacking, providing a reference for better integrating reward models into RL.', 'abstract_zh': '大规模语言模型（LLMs）在推理任务中展现了显著性能，其中强化学习（RL）是提升其推理能力的关键算法。目前主要有两种主流奖励范式：基于模型的奖励和基于规则的奖励。然而，这两种方法都存在局限性：基于规则的奖励缺乏鲁棒性，而基于模型的奖励容易遭受奖励作弊。为解决这些问题，我们提出了Cooper（联合优化策略模型和奖励模型）框架，该框架联合优化策略模型和奖励模型。Cooper 利用基于规则奖励的高精度识别正确响应，并动态构建和选择正负样本对以继续训练奖励模型。这一设计增强了鲁棒性并减轻了奖励作弊的风险。为进一步支持Cooper，我们引入了一种混合注释策略，以高效准确地生成奖励模型的训练数据。我们还提出了一种基于参考的奖励建模范式，其中奖励模型以参考答案作为输入。基于此设计，我们训练了一个名为VerifyRM的奖励模型，其在VerifyBench上的准确率比其他大小相同模型更高。我们使用VerifyRM和Cooper进行强化学习。实验结果显示，Cooper 不仅缓解了奖励作弊，还提高了端到端的强化学习性能，例如在Qwen2.5-1.5B-Instruct上取得了0.54%的平均准确率提升。我们的研究证明，动态更新奖励模型是有效对抗奖励作弊的方法，为将奖励模型更好地集成到强化学习中提供了参考。', 'title_zh': 'Cooper: 在强化学习大规模语言模型中协同优化策略和奖励模型'}
{'arxiv_id': 'arXiv:2508.05612', 'title': 'Shuffle-R1: Efficient RL framework for Multimodal Large Language Models via Data-centric Dynamic Shuffle', 'authors': 'Linghao Zhu, Yiran Guan, Dingkang Liang, Jianzhong Ju, Zhenbo Luo, Bin Qin, Jian Luan, Yuliang Liu, Xiang Bai', 'link': 'https://arxiv.org/abs/2508.05612', 'abstract': 'Reinforcement learning (RL) has emerged as an effective post-training paradigm for enhancing the reasoning capabilities of multimodal large language model (MLLM). However, current RL pipelines often suffer from training inefficiencies caused by two underexplored issues: Advantage Collapsing, where most advantages in a batch concentrate near zero, and Rollout Silencing, where the proportion of rollouts contributing non-zero gradients diminishes over time. These issues lead to suboptimal gradient updates and hinder long-term learning efficiency. To address these issues, we propose Shuffle-R1, a simple yet principled framework that improves RL fine-tuning efficiency by dynamically restructuring trajectory sampling and batch composition. It introduces (1) Pairwise Trajectory Sampling, which selects high-contrast trajectories with large advantages to improve gradient signal quality, and (2) Advantage-based Trajectory Shuffle, which increases exposure of valuable rollouts through informed batch reshuffling. Experiments across multiple reasoning benchmarks show that our framework consistently outperforms strong RL baselines with minimal overhead. These results highlight the importance of data-centric adaptations for more efficient RL training in MLLM.', 'abstract_zh': '强化学习（RL）已 emerges 作为增强多模态大语言模型（MLLM）推理能力的有效后训练范式。然而，当前的 RL 流水线常常由于两个未充分探索的问题而导致训练效率低下：优势坍缩，其中批次中的大多数优势接近零；以及采样消声，其中贡献非零梯度的采样比例随时间减少。这些问题导致梯度更新次优化，并阻碍长期学习效率。为解决这些问题，我们提出了一种简单的且有原则的 Shuffle-R1 框架，通过动态重构轨迹采样和批次组成来提高 RL 微调效率。该框架引入了（1）高对比度轨迹采样，选择具有大优势的轨迹以提高梯度信号质量，以及（2）基于优势的轨迹重排，通过有信息的批次重排增加有价值的采样的暴露度。在多个推理基准测试中的实验结果表明，该框架在最小的开销下始终优于强 RL 基准。这些结果强调了数据导向的适应性对 MLLM 更高效 RL 训练的重要性。', 'title_zh': 'Shuffle-R1:面向数据导向动态打乱的多模态大型语言模型高效 reinforcement 学习框架'}
{'arxiv_id': 'arXiv:2508.05581', 'title': 'Iterative Learning of Computable Phenotypes for Treatment Resistant Hypertension using Large Language Models', 'authors': 'Guilherme Seidyo Imai Aldeia, Daniel S. Herman, William G. La Cava', 'link': 'https://arxiv.org/abs/2508.05581', 'abstract': 'Large language models (LLMs) have demonstrated remarkable capabilities for medical question answering and programming, but their potential for generating interpretable computable phenotypes (CPs) is under-explored. In this work, we investigate whether LLMs can generate accurate and concise CPs for six clinical phenotypes of varying complexity, which could be leveraged to enable scalable clinical decision support to improve care for patients with hypertension. In addition to evaluating zero-short performance, we propose and test a synthesize, execute, debug, instruct strategy that uses LLMs to generate and iteratively refine CPs using data-driven feedback. Our results show that LLMs, coupled with iterative learning, can generate interpretable and reasonably accurate programs that approach the performance of state-of-the-art ML methods while requiring significantly fewer training examples.', 'abstract_zh': '大型语言模型(LLMs)在医学问答和编程方面展示了显著的能力，但其生成可解析计算表型(CPs)的潜力尚未充分探索。在这项工作中，我们研究了LLMs能否生成六种不同复杂性的临床表型的准确且简洁的CPs，这些CPs可以被利用来提供可扩展的临床决策支持，以改善高血压患者的护理。除了评估零样本性能，我们还提出并测试了一种合成、执行、调试、指导策略，利用LLMs生成并在数据驱动的反馈下迭代细化CPs。我们的结果表明，结合迭代学习的LLMs能够生成可解析且相对准确的程序，其性能接近最先进的机器学习方法，同时所需训练示例大大减少。', 'title_zh': '使用大型语言模型迭代学习可计算表型治疗抵抗型高血压'}
{'arxiv_id': 'arXiv:2508.05547', 'title': 'Adapting Vision-Language Models Without Labels: A Comprehensive Survey', 'authors': 'Hao Dong, Lijun Sheng, Jian Liang, Ran He, Eleni Chatzi, Olga Fink', 'link': 'https://arxiv.org/abs/2508.05547', 'abstract': 'Vision-Language Models (VLMs) have demonstrated remarkable generalization capabilities across a wide range of tasks. However, their performance often remains suboptimal when directly applied to specific downstream scenarios without task-specific adaptation. To enhance their utility while preserving data efficiency, recent research has increasingly focused on unsupervised adaptation methods that do not rely on labeled data. Despite the growing interest in this area, there remains a lack of a unified, task-oriented survey dedicated to unsupervised VLM adaptation. To bridge this gap, we present a comprehensive and structured overview of the field. We propose a taxonomy based on the availability and nature of unlabeled visual data, categorizing existing approaches into four key paradigms: Data-Free Transfer (no data), Unsupervised Domain Transfer (abundant data), Episodic Test-Time Adaptation (batch data), and Online Test-Time Adaptation (streaming data). Within this framework, we analyze core methodologies and adaptation strategies associated with each paradigm, aiming to establish a systematic understanding of the field. Additionally, we review representative benchmarks across diverse applications and highlight open challenges and promising directions for future research. An actively maintained repository of relevant literature is available at this https URL.', 'abstract_zh': 'Vision-Language 模型（VLMs）在多种任务上展示了出色的泛化能力。然而，当直接应用于特定下游场景时，其性能往往不尽如人意，需要特定任务的适应。为了在保持数据效率的同时提高其实用性，最近的研究越来越多地关注不需要标签数据的无监督适应方法。尽管对该领域产生了越来越大的兴趣，但仍缺乏一个统一的任务导向的综述，专门涵盖无监督 VLM 调适。为此，我们提供了一个全面且结构化的 overview。我们提出了一个基于无标签视觉数据的可用性和性质的分类体系，将现有方法归类为四个关键范式：数据自由转移（无数据）、无监督领域转移（丰富数据）、事件测试时间适应（批量化数据）和在线测试时间适应（流式数据）。在这一框架下，我们分析了每个范式的核心方法和技术策略，旨在建立对这一领域的系统性理解。此外，我们回顾了跨多种应用的代表性基准，并指出未来研究中的开放挑战和有希望的研究方向。相关文献的主动维护型仓库可在以下链接访问：this https URL。', 'title_zh': '不使用标签适应视觉-语言模型：一个综合调研'}
{'arxiv_id': 'arXiv:2508.05544', 'title': 'Conformal Sets in Multiple-Choice Question Answering under Black-Box Settings with Provable Coverage Guarantees', 'authors': 'Guang Yang, Xinyang Liu', 'link': 'https://arxiv.org/abs/2508.05544', 'abstract': "Large Language Models (LLMs) have shown remarkable progress in multiple-choice question answering (MCQA), but their inherent unreliability, such as hallucination and overconfidence, limits their application in high-risk domains. To address this, we propose a frequency-based uncertainty quantification method under black-box settings, leveraging conformal prediction (CP) to ensure provable coverage guarantees. Our approach involves multiple independent samplings of the model's output distribution for each input, with the most frequent sample serving as a reference to calculate predictive entropy (PE). Experimental evaluations across six LLMs and four datasets (MedMCQA, MedQA, MMLU, MMLU-Pro) demonstrate that frequency-based PE outperforms logit-based PE in distinguishing between correct and incorrect predictions, as measured by AUROC. Furthermore, the method effectively controls the empirical miscoverage rate under user-specified risk levels, validating that sampling frequency can serve as a viable substitute for logit-based probabilities in black-box scenarios. This work provides a distribution-free model-agnostic framework for reliable uncertainty quantification in MCQA with guaranteed coverage, enhancing the trustworthiness of LLMs in practical applications.", 'abstract_zh': '大型语言模型（LLMs）在多项选择题作答（MCQA）中取得了显著进展，但由于其固有的不可靠性，如虚构和过度自信，限制了其在高风险领域的应用。为了解决这一问题，我们提出了一种在黑盒设置下基于频率的不确定性量化方法，利用置信预测（CP）确保可证明的覆盖率保证。我们的方法包括为每个输入进行多次独立采样模型的输出分布，最常见的样本作为参考计算预测熵（PE）。在六种LLM和四种数据集（MedMCQA、MedQA、MMLU、MMLU-Pro）上的实验评估表明，基于频率的PE在区分正确和错误预测方面优于基于对数似然比的PE，通过AUROC衡量。此外，该方法有效地在用户指定的风险水平下控制经验覆盖率误差率，验证了在黑盒场景中采样频率可以作为对数似然比概率的可行替代方案。本工作提供了一种分布无关且模型无关的框架，用于MCQA中的可靠不确定性量化，确保覆盖率，从而增强LLMs在实际应用中的可信度。', 'title_zh': '多重选择题作答下的黑盒设置中的齐性集及其可证明覆盖保证'}
{'arxiv_id': 'arXiv:2508.05537', 'title': 'Tractable Sharpness-Aware Learning of Probabilistic Circuits', 'authors': 'Hrithik Suresh, Sahil Sidheekh, Vishnu Shreeram M.P, Sriraam Natarajan, Narayanan C. Krishnan', 'link': 'https://arxiv.org/abs/2508.05537', 'abstract': 'Probabilistic Circuits (PCs) are a class of generative models that allow exact and tractable inference for a wide range of queries. While recent developments have enabled the learning of deep and expressive PCs, this increased capacity can often lead to overfitting, especially when data is limited. We analyze PC overfitting from a log-likelihood-landscape perspective and show that it is often caused by convergence to sharp optima that generalize poorly. Inspired by sharpness aware minimization in neural networks, we propose a Hessian-based regularizer for training PCs. As a key contribution, we show that the trace of the Hessian of the log-likelihood-a sharpness proxy that is typically intractable in deep neural networks-can be computed efficiently for PCs. Minimizing this Hessian trace induces a gradient-norm-based regularizer that yields simple closed-form parameter updates for EM, and integrates seamlessly with gradient based learning methods. Experiments on synthetic and real-world datasets demonstrate that our method consistently guides PCs toward flatter minima, improves generalization performance.', 'abstract_zh': '概率电路（PCs）是一类允许对广泛查询进行精确和可处理推断的生成模型。尽管近期发展使得能够学习深度和表达性强的PCs，但这种增强的能力往往在数据有限时会引发过拟合。从对数似然景观的角度分析PC过拟合，并表明这通常是由收敛于泛化能力差的尖锐最优解引起的。受神经网络中尖锐性感知最小化方法的启发，我们为训练PCs提出了一个基于海森矩阵的正则化器。作为主要贡献，我们展示了对数似然的海森矩阵迹——一个在深度神经网络中通常不可计算的尖锐性代理——在PCs中可以有效地进行计算。最小化该海森矩阵迹产生了基于梯度范数的正则化器，为EM算法提供了简洁的闭式参数更新，并可无缝集成到基于梯度的学习方法中。实验结果表明，我们的方法能够引导PCs趋向更平坦的极小值，从而提升泛化性能。', 'title_zh': '可计算的基于灵敏度的学习概率电路'}
{'arxiv_id': 'arXiv:2508.05525', 'title': "The World According to LLMs: How Geographic Origin Influences LLMs' Entity Deduction Capabilities", 'authors': 'Harsh Nishant Lalai, Raj Sanjay Shah, Jiaxin Pei, Sashank Varma, Yi-Chia Wang, Ali Emami', 'link': 'https://arxiv.org/abs/2508.05525', 'abstract': 'Large Language Models (LLMs) have been extensively tuned to mitigate explicit biases, yet they often exhibit subtle implicit biases rooted in their pre-training data. Rather than directly probing LLMs with human-crafted questions that may trigger guardrails, we propose studying how models behave when they proactively ask questions themselves. The 20 Questions game, a multi-turn deduction task, serves as an ideal testbed for this purpose. We systematically evaluate geographic performance disparities in entity deduction using a new dataset, Geo20Q+, consisting of both notable people and culturally significant objects (e.g., foods, landmarks, animals) from diverse regions. We test popular LLMs across two gameplay configurations (canonical 20-question and unlimited turns) and in seven languages (English, Hindi, Mandarin, Japanese, French, Spanish, and Turkish). Our results reveal geographic disparities: LLMs are substantially more successful at deducing entities from the Global North than the Global South, and the Global West than the Global East. While Wikipedia pageviews and pre-training corpus frequency correlate mildly with performance, they fail to fully explain these disparities. Notably, the language in which the game is played has minimal impact on performance gaps. These findings demonstrate the value of creative, free-form evaluation frameworks for uncovering subtle biases in LLMs that remain hidden in standard prompting setups. By analyzing how models initiate and pursue reasoning goals over multiple turns, we find geographic and cultural disparities embedded in their reasoning processes. We release the dataset (Geo20Q+) and code at this https URL.', 'abstract_zh': '大型语言模型（LLMs）已在消除显性偏见方面进行了广泛调优，但它们往往根植于预训练数据中的隐性偏见。我们提出通过让模型主动提问来研究其行为，而不是直接用由人类设计的问题触发防护机制。20个问题游戏，一个多轮推理任务，为此目的提供了一个理想的实验环境。我们使用新数据集Geo20Q+系统性地评估了地理表现差异在实体推理中的表现，该数据集包含来自不同地区的显著人物和文化重要对象（如食物、地标、动物）。我们测试了多种流行的LLMs在两种游戏配置（标准20个问题和不限轮次）下的表现，以及在七种语言（英语、印地语、普通话、日语、法语、西班牙语和土耳其语）下的表现。结果显示地理差异：LLMs在推理来自全球北方和西方的实体方面比全球南方和东方更为成功。尽管维基百科页面访问量和预训练语料库频率与表现存在轻微相关性，但它们无法完全解释这些差异。值得注意的是，游戏使用的语言对性能差异的影响微乎其微。这些发现证明了创造性、开放形式评估框架的价值，用于揭示在标准提示设置中隐藏的LLMs中的微妙偏见。通过分析模型在多轮次中如何启动和追求推理目标，我们发现其推理过程中嵌入了地理和文化差异。我们在此处发布数据集（Geo20Q+）和代码：[此链接]。', 'title_zh': 'LLMs眼中的世界：地理起源如何影响LLMs的实体推断能力'}
{'arxiv_id': 'arXiv:2508.05509', 'title': 'LAG: Logic-Augmented Generation from a Cartesian Perspective', 'authors': 'Yilin Xiao, Chuang Zhou, Qinggang Zhang, Su Dong, Shengyuan Chen, Xiao Huang', 'link': 'https://arxiv.org/abs/2508.05509', 'abstract': 'Large language models (LLMs) have demonstrated remarkable capabilities across a wide range of tasks, yet exhibit critical limitations in knowledge-intensive tasks, often generating hallucinations when faced with questions requiring specialized expertise. While retrieval-augmented generation (RAG) mitigates this by integrating external knowledge, it struggles with complex reasoning scenarios due to its reliance on direct semantic retrieval and lack of structured logical organization. Inspired by Cartesian principles from \\textit{Discours de la méthode}, this paper introduces Logic-Augmented Generation (LAG), a novel paradigm that reframes knowledge augmentation through systematic question decomposition and dependency-aware reasoning. Specifically, LAG first decomposes complex questions into atomic sub-questions ordered by logical dependencies. It then resolves these sequentially, using prior answers to guide context retrieval for subsequent sub-questions, ensuring stepwise grounding in logical chain. To prevent error propagation, LAG incorporates a logical termination mechanism that halts inference upon encountering unanswerable sub-questions and reduces wasted computation on excessive reasoning. Finally, it synthesizes all sub-resolutions to generate verified responses. Experiments on four benchmark datasets demonstrate that LAG significantly enhances reasoning robustness, reduces hallucination, and aligns LLM problem-solving with human cognition, offering a principled alternative to existing RAG systems.', 'abstract_zh': '基于笛卡尔原则的逻辑增强生成（LAG）：一种新型的知识增强范式', 'title_zh': 'LAG: 从卡特尔视角增强逻辑生成'}
{'arxiv_id': 'arXiv:2508.05492', 'title': 'MoMA: A Mixture-of-Multimodal-Agents Architecture for Enhancing Clinical Prediction Modelling', 'authors': "Jifan Gao, Mahmudur Rahman, John Caskey, Madeline Oguss, Ann O'Rourke, Randy Brown, Anne Stey, Anoop Mayampurath, Matthew M. Churpek, Guanhua Chen, Majid Afshar", 'link': 'https://arxiv.org/abs/2508.05492', 'abstract': 'Multimodal electronic health record (EHR) data provide richer, complementary insights into patient health compared to single-modality data. However, effectively integrating diverse data modalities for clinical prediction modeling remains challenging due to the substantial data requirements. We introduce a novel architecture, Mixture-of-Multimodal-Agents (MoMA), designed to leverage multiple large language model (LLM) agents for clinical prediction tasks using multimodal EHR data. MoMA employs specialized LLM agents ("specialist agents") to convert non-textual modalities, such as medical images and laboratory results, into structured textual summaries. These summaries, together with clinical notes, are combined by another LLM ("aggregator agent") to generate a unified multimodal summary, which is then used by a third LLM ("predictor agent") to produce clinical predictions. Evaluating MoMA on three prediction tasks using real-world datasets with different modality combinations and prediction settings, MoMA outperforms current state-of-the-art methods, highlighting its enhanced accuracy and flexibility across various tasks.', 'abstract_zh': '多模态电子健康记录（EHR）数据提供了相比单模态数据更为丰富和互补的患者健康洞察。然而，由于数据需求量巨大，有效整合多种数据模态进行临床预测模型构建仍然具有挑战性。我们介绍了一种新型架构，多模态代理混合模型（MoMA），该架构旨在利用多个大型语言模型（LLM）代理处理多模态EHR数据的临床预测任务。MoMA 使用专门的 LLM 代理（“专家代理”）将医疗图像和实验室结果等非文本模态转化为结构化的文本摘要。这些摘要与临床笔记一起，由另一个 LLM（“集成代理”）组合生成统一的多模态摘要，再由第三个 LLM（“预测代理”）生成临床预测。在使用不同模态组合和预测设置的真实世界数据集上对 MoMA 进行三项预测任务评估，MoMA 的性能优于当前最先进的方法，突显了其在各种任务中的增强准确性和灵活性。', 'title_zh': 'MoMA：增强临床预测建模的混合多模态代理架构'}
{'arxiv_id': 'arXiv:2508.05473', 'title': 'Embedding Alignment in Code Generation for Audio', 'authors': 'Sam Kouteili, Hiren Madhu, George Typaldos, Mark Santolucito', 'link': 'https://arxiv.org/abs/2508.05473', 'abstract': "LLM-powered code generation has the potential to revolutionize creative coding endeavors, such as live-coding, by enabling users to focus on structural motifs over syntactic details. In such domains, when prompting an LLM, users may benefit from considering multiple varied code candidates to better realize their musical intentions. Code generation models, however, struggle to present unique and diverse code candidates, with no direct insight into the code's audio output. To better establish a relationship between code candidates and produced audio, we investigate the topology of the mapping between code and audio embedding spaces. We find that code and audio embeddings do not exhibit a simple linear relationship, but supplement this with a constructed predictive model that shows an embedding alignment map could be learned. Supplementing the aim for musically diverse output, we present a model that given code predicts output audio embedding, constructing a code-audio embedding alignment map.", 'abstract_zh': 'LLM 助力的代码生成有望通过使用户专注于结构 motif 而非语法细节来革新现场编码等创意编码领域。在这种领域中，当提示 LLM 时，用户可以通过考虑多种多样的代码候选方案来更好地实现他们的音乐意图。然而，代码生成模型在提供独特且多样的代码候选方案方面存在困难，并且无法直接洞察代码的音频输出。为了更好地建立代码候选方案与生成音频之间的关系，我们研究了代码空间和音频嵌入空间之间的拓扑结构。我们发现代码嵌入和音频嵌入之间并没有简单的线性关系，但通过构建预测模型显示可以学习到一种嵌入对齐图。除了追求音乐多样性输出的目标，我们提出了一个模型，给定代码可以预测输出音频嵌入，从而构建代码-音频嵌入对齐图。', 'title_zh': '嵌入式对齐在音频代码生成中的应用'}
{'arxiv_id': 'arXiv:2508.05463', 'title': 'Task complexity shapes internal representations and robustness in neural networks', 'authors': 'Robert Jankowski, Filippo Radicchi, M. Ángeles Serrano, Marián Boguñá, Santo Fortunato', 'link': 'https://arxiv.org/abs/2508.05463', 'abstract': 'Neural networks excel across a wide range of tasks, yet remain black boxes. In particular, how their internal representations are shaped by the complexity of the input data and the problems they solve remains obscure. In this work, we introduce a suite of five data-agnostic probes-pruning, binarization, noise injection, sign flipping, and bipartite network randomization-to quantify how task difficulty influences the topology and robustness of representations in multilayer perceptrons (MLPs). MLPs are represented as signed, weighted bipartite graphs from a network science perspective. We contrast easy and hard classification tasks on the MNIST and Fashion-MNIST datasets. We show that binarizing weights in hard-task models collapses accuracy to chance, whereas easy-task models remain robust. We also find that pruning low-magnitude edges in binarized hard-task models reveals a sharp phase-transition in performance. Moreover, moderate noise injection can enhance accuracy, resembling a stochastic-resonance effect linked to optimal sign flips of small-magnitude weights. Finally, preserving only the sign structure-instead of precise weight magnitudes-through bipartite network randomizations suffices to maintain high accuracy. These phenomena define a model- and modality-agnostic measure of task complexity: the performance gap between full-precision and binarized or shuffled neural network performance. Our findings highlight the crucial role of signed bipartite topology in learned representations and suggest practical strategies for model compression and interpretability that align with task complexity.', 'abstract_zh': '神经网络在广泛的任务中表现出色，但仍保持为黑箱。特别是，输入数据和任务复杂性如何塑造其内部表示仍然是模糊的。在本工作中，我们引入了一套五种数据无关的探针——剪枝、二值化、噪声注入、符号翻转和 bipartite 网络随机化，以量化任务难度如何影响多层感知机（MLP）中表示的拓扑结构和鲁棒性。从网络科学的角度，MLPs 被表示为带符号和加权的 bipartite 图。我们对比了 MNIST 和 Fashion-MNIST 数据集上的易任务和难任务。我们发现，在难任务模型中二值化权重会导致准确率下降到随机水平，而在易任务模型中则仍保持鲁棒性。我们还发现，在二值化难任务模型中剪枝低幅度边会揭示性能的尖锐相变。此外，适度的噪声注入可以提高准确率，这类似于与小幅度权重最优符号翻转相关的随机共振效应。最后，通过 bipartite 网络随机化仅保留符号结构而不是精确的权重幅度即可保持高准确率。这些现象定义了一种针对模型和模态的难度度量：全精度和二值化或打乱的神经网络性能之间的性能差距。我们的发现突显了在学习表示中带符号 bipartite 拓扑结构的关键作用，并提出了与任务复杂性相一致的模型压缩和解释性策略。', 'title_zh': '任务复杂性塑造神经网络中的内部表示和稳健性'}
{'arxiv_id': 'arXiv:2508.05454', 'title': 'EnergyPatchTST: Multi-scale Time Series Transformers with Uncertainty Estimation for Energy Forecasting', 'authors': 'Wei Li, Zixin Wang, Qizheng Sun, Qixiang Gao, Fenglei Yang', 'link': 'https://arxiv.org/abs/2508.05454', 'abstract': 'Accurate and reliable energy time series prediction is of great significance for power generation planning and allocation. At present, deep learning time series prediction has become the mainstream method. However, the multi-scale time dynamics and the irregularity of real data lead to the limitations of the existing methods. Therefore, we propose EnergyPatchTST, which is an extension of the Patch Time Series Transformer specially designed for energy forecasting. The main innovations of our method are as follows: (1) multi-scale feature extraction mechanism to capture patterns with different time resolutions; (2) probability prediction framework to estimate uncertainty through Monte Carlo elimination; (3) integration path of future known variables (such as temperature and wind conditions); And (4) Pre-training and Fine-tuning examples to enhance the performance of limited energy data sets. A series of experiments on common energy data sets show that EnergyPatchTST is superior to other commonly used methods, the prediction error is reduced by 7-12%, and reliable uncertainty estimation is provided, which provides an important reference for time series prediction in the energy field.', 'abstract_zh': '准确可靠的能源时间序列预测对于电力生成规划和分配具有重要意义。现有的深度学习时间序列预测已成为主流方法，但由于真实数据中的多尺度时间动态和不规律性导致了现有方法的局限性。因此，我们提出了EnergyPatchTST，它是Patch Time Series Transformer的扩展，特别适用于能源预测。我们的方法的主要创新点包括：(1) 多尺度特征提取机制以捕获不同时间分辨率的模式；(2) 概率预测框架通过蒙特卡洛消除估计不确定性；(3) 集成未来已知变量（如温度和风况）的路径；(4) 预训练和微调示例以增强有限能源数据集的性能。一系列在常见能源数据集上的实验表明，EnergyPatchTST优于其他常用方法，预测误差降低了7-12%，并提供了可靠的不确定估计，为能源领域的时序预测提供了重要参考。', 'title_zh': '基于不确定性估计的多尺度时间序列变压器：EnergyPatchTST在能源预测中的应用'}
{'arxiv_id': 'arXiv:2508.05441', 'title': 'Tail-Risk-Safe Monte Carlo Tree Search under PAC-Level Guarantees', 'authors': 'Zuyuan Zhang, Arnob Ghosh, Tian Lan', 'link': 'https://arxiv.org/abs/2508.05441', 'abstract': 'Making decisions with respect to just the expected returns in Monte Carlo Tree Search (MCTS) cannot account for the potential range of high-risk, adverse outcomes associated with a decision. To this end, safety-aware MCTS often consider some constrained variants -- by introducing some form of mean risk measures or hard cost thresholds. These approaches fail to provide rigorous tail-safety guarantees with respect to extreme or high-risk outcomes (denoted as tail-risk), potentially resulting in serious consequence in high-stake scenarios. This paper addresses the problem by developing two novel solutions. We first propose CVaR-MCTS, which embeds a coherent tail risk measure, Conditional Value-at-Risk (CVaR), into MCTS. Our CVaR-MCTS with parameter $\\alpha$ achieves explicit tail-risk control over the expected loss in the "worst $(1-\\alpha)\\%$ scenarios." Second, we further address the estimation bias of tail-risk due to limited samples. We propose Wasserstein-MCTS (or W-MCTS) by introducing a first-order Wasserstein ambiguity set $\\mathcal{P}_{\\varepsilon_{s}}(s,a)$ with radius $\\varepsilon_{s}$ to characterize the uncertainty in tail-risk estimates. We prove PAC tail-safety guarantees for both CVaR-MCTS and W-MCTS and establish their regret. Evaluations on diverse simulated environments demonstrate that our proposed methods outperform existing baselines, effectively achieving robust tail-risk guarantees with improved rewards and stability.', 'abstract_zh': '基于蒙特卡洛树搜索的条件价值风险敏感方法与 Wasserstein 模型在决策中的应用', 'title_zh': '在PAC级保证下的尾部风险安全蒙特卡洛树搜索'}
{'arxiv_id': 'arXiv:2508.05430', 'title': 'Explaining Similarity in Vision-Language Encoders with Weighted Banzhaf Interactions', 'authors': 'Hubert Baniecki, Maximilian Muschalik, Fabian Fumagalli, Barbara Hammer, Eyke Hüllermeier, Przemyslaw Biecek', 'link': 'https://arxiv.org/abs/2508.05430', 'abstract': "Language-image pre-training (LIP) enables the development of vision-language models capable of zero-shot classification, localization, multimodal retrieval, and semantic understanding. Various explanation methods have been proposed to visualize the importance of input image-text pairs on the model's similarity outputs. However, popular saliency maps are limited by capturing only first-order attributions, overlooking the complex cross-modal interactions intrinsic to such encoders. We introduce faithful interaction explanations of LIP models (FIxLIP) as a unified approach to decomposing the similarity in vision-language encoders. FIxLIP is rooted in game theory, where we analyze how using the weighted Banzhaf interaction index offers greater flexibility and improves computational efficiency over the Shapley interaction quantification framework. From a practical perspective, we propose how to naturally extend explanation evaluation metrics, like the pointing game and area between the insertion/deletion curves, to second-order interaction explanations. Experiments on MS COCO and ImageNet-1k benchmarks validate that second-order methods like FIxLIP outperform first-order attribution methods. Beyond delivering high-quality explanations, we demonstrate the utility of FIxLIP in comparing different models like CLIP vs. SigLIP-2 and ViT-B/32 vs. ViT-L/16.", 'abstract_zh': 'LIP模型的忠实交互解释：从一阶到二阶交互解释', 'title_zh': '基于加权瓦伦哈夫相互作用解释视觉-语言编码器中的相似性'}
{'arxiv_id': 'arXiv:2508.05429', 'title': "MyCulture: Exploring Malaysia's Diverse Culture under Low-Resource Language Constraints", 'authors': 'Zhong Ken Hew, Jia Xin Low, Sze Jue Yang, Chee Seng chan', 'link': 'https://arxiv.org/abs/2508.05429', 'abstract': 'Large Language Models (LLMs) often exhibit cultural biases due to training data dominated by high-resource languages like English and Chinese. This poses challenges for accurately representing and evaluating diverse cultural contexts, particularly in low-resource language settings. To address this, we introduce MyCulture, a benchmark designed to comprehensively evaluate LLMs on Malaysian culture across six pillars: arts, attire, customs, entertainment, food, and religion presented in Bahasa Melayu. Unlike conventional benchmarks, MyCulture employs a novel open-ended multiple-choice question format without predefined options, thereby reducing guessing and mitigating format bias. We provide a theoretical justification for the effectiveness of this open-ended structure in improving both fairness and discriminative power. Furthermore, we analyze structural bias by comparing model performance on structured versus free-form outputs, and assess language bias through multilingual prompt variations. Our evaluation across a range of regional and international LLMs reveals significant disparities in cultural comprehension, highlighting the urgent need for culturally grounded and linguistically inclusive benchmarks in the development and assessment of LLMs.', 'abstract_zh': '大型语言模型（LLMs）由于训练数据主要由英语和汉语等高资源语言主导，往往表现出文化偏见。这给准确地代表和评估多样的文化背景，特别是在低资源语言环境中带来了挑战。为了解决这一问题，我们引入了MyCulture，这是一个旨在全面评估马来文化的大规模语言模型基准，涵盖艺术、服饰、习俗、娱乐、食物和宗教六个支柱，全部用马来语呈现。与传统基准不同，MyCulture采用了一种新颖的开放式多项选择题格式，没有预设选项，从而减少了猜测并在一定程度上减轻了格式偏见。我们为这种开放式结构的有效性提供了理论上的解释，以提高公平性和辨别力。此外，我们通过比较模型在结构化输出与自由形式输出上的性能来分析结构偏见，并通过多语言提示变体评估语言偏见。我们的评估涵盖了多个区域性和国际性的大型语言模型，揭示了文化理解上的显著差异，强调了在大型语言模型的发展和评估中迫切需要文化基础和语言包容性基准。', 'title_zh': 'MyCulture: 探索在低资源语言约束下的马来西亚多元文化'}
{'arxiv_id': 'arXiv:2508.05421', 'title': 'LLM-based Multi-Agent Copilot for Quantum Sensor', 'authors': 'Rong Sha, Binglin Wang, Jun Yang, Xiaoxiao Ma, Chengkun Wu, Liang Yan, Chao Zhou, Jixun Liu, Guochao Wang, Shuhua Yan, Lingxiao Zhu', 'link': 'https://arxiv.org/abs/2508.05421', 'abstract': 'Large language models (LLM) exhibit broad utility but face limitations in quantum sensor development, stemming from interdisciplinary knowledge barriers and involving complex optimization processes. Here we present QCopilot, an LLM-based multi-agent framework integrating external knowledge access, active learning, and uncertainty quantification for quantum sensor design and diagnosis. Comprising commercial LLMs with few-shot prompt engineering and vector knowledge base, QCopilot employs specialized agents to adaptively select optimization methods, automate modeling analysis, and independently perform problem diagnosis. Applying QCopilot to atom cooling experiments, we generated 10${}^{\\rm{8}}$ sub-$\\rm{\\mu}$K atoms without any human intervention within a few hours, representing $\\sim$100$\\times$ speedup over manual experimentation. Notably, by continuously accumulating prior knowledge and enabling dynamic modeling, QCopilot can autonomously identify anomalous parameters in multi-parameter experimental settings. Our work reduces barriers to large-scale quantum sensor deployment and readily extends to other quantum information systems.', 'abstract_zh': '基于大型语言模型的多agents量子传感器设计与诊断框架：QCopilot', 'title_zh': '基于LLM的多代理协驾系统for量子传感器（标题翻译）：基于大规模语言模型的多代理协驾系统用于量子传感器'}
{'arxiv_id': 'arXiv:2508.05399', 'title': 'UNCAGE: Contrastive Attention Guidance for Masked Generative Transformers in Text-to-Image Generation', 'authors': 'Wonjun Kang, Byeongkeun Ahn, Minjae Lee, Kevin Galim, Seunghyuk Oh, Hyung Il Koo, Nam Ik Cho', 'link': 'https://arxiv.org/abs/2508.05399', 'abstract': 'Text-to-image (T2I) generation has been actively studied using Diffusion Models and Autoregressive Models. Recently, Masked Generative Transformers have gained attention as an alternative to Autoregressive Models to overcome the inherent limitations of causal attention and autoregressive decoding through bidirectional attention and parallel decoding, enabling efficient and high-quality image generation. However, compositional T2I generation remains challenging, as even state-of-the-art Diffusion Models often fail to accurately bind attributes and achieve proper text-image alignment. While Diffusion Models have been extensively studied for this issue, Masked Generative Transformers exhibit similar limitations but have not been explored in this context. To address this, we propose Unmasking with Contrastive Attention Guidance (UNCAGE), a novel training-free method that improves compositional fidelity by leveraging attention maps to prioritize the unmasking of tokens that clearly represent individual objects. UNCAGE consistently improves performance in both quantitative and qualitative evaluations across multiple benchmarks and metrics, with negligible inference overhead. Our code is available at this https URL.', 'abstract_zh': '基于文本的图像生成：利用掩码生成变换器克服自回归模型的内在限制', 'title_zh': 'UNCAGE: 对比注意力指导在文本到图像生成中掩码生成变换器中的应用'}
{'arxiv_id': 'arXiv:2508.05396', 'title': 'Real-Time Iteration Scheme for Diffusion Policy', 'authors': 'Yufei Duan, Hang Yin, Danica Kragic', 'link': 'https://arxiv.org/abs/2508.05396', 'abstract': 'Diffusion Policies have demonstrated impressive performance in robotic manipulation tasks. However, their long inference time, resulting from an extensive iterative denoising process, and the need to execute an action chunk before the next prediction to maintain consistent actions limit their applicability to latency-critical tasks or simple tasks with a short cycle time. While recent methods explored distillation or alternative policy structures to accelerate inference, these often demand additional training, which can be resource-intensive for large robotic models. In this paper, we introduce a novel approach inspired by the Real-Time Iteration (RTI) Scheme, a method from optimal control that accelerates optimization by leveraging solutions from previous time steps as initial guesses for subsequent iterations. We explore the application of this scheme in diffusion inference and propose a scaling-based method to effectively handle discrete actions, such as grasping, in robotic manipulation. The proposed scheme significantly reduces runtime computational costs without the need for distillation or policy redesign. This enables a seamless integration into many pre-trained diffusion-based models, in particular, to resource-demanding large models. We also provide theoretical conditions for the contractivity which could be useful for estimating the initial denoising step. Quantitative results from extensive simulation experiments show a substantial reduction in inference time, with comparable overall performance compared with Diffusion Policy using full-step denoising. Our project page with additional resources is available at: this https URL.', 'abstract_zh': '实时迭代方案在机器人操作中加速扩散策略推理的研究', 'title_zh': '实时迭代方案for扩散策略'}
{'arxiv_id': 'arXiv:2508.05387', 'title': 'Echo: Decoupling Inference and Training for Large-Scale RL Alignment on Heterogeneous Swarms', 'authors': 'Jie Xiao, Shaoduo Gan, Changyuan Fan, Qingnan Ren, Alfred Long, Yuchen Zhang, Rymon Yu, Eric Yang, Lynn Ai', 'link': 'https://arxiv.org/abs/2508.05387', 'abstract': 'Modern RL-based post-training for large language models (LLMs) co-locate trajectory sampling and policy optimisation on the same GPU cluster, forcing the system to switch between inference and training workloads. This serial context switching violates the single-program-multiple-data (SPMD) assumption underlying today\'s distributed training systems. We present Echo, the RL system that cleanly decouples these two phases across heterogeneous "inference" and "training" swarms while preserving statistical efficiency. Echo introduces two lightweight synchronization protocols: a sequential pull mode that refreshes sampler weights on every API call for minimal bias, and an asynchronous push-pull mode that streams version-tagged rollouts through a replay buffer to maximise hardware utilisation. Training three representative RL workloads with Qwen3-4B, Qwen2.5-7B and Qwen3-32B on a geographically distributed cluster, Echo matches a fully co-located Verl baseline in convergence speed and final reward while off-loading trajectory generation to commodity edge hardware. These promising results demonstrate that large-scale RL for LLMs could achieve datacentre-grade performance using decentralised, heterogeneous resources.', 'abstract_zh': '现代基于RL的后训练方法在大型语言模型（LLMs）中将轨迹采样和策略优化 colocate 在同一GPU集群上，迫使系统在推理和训练工作负载之间进行串行切换。这种串行上下文切换违反了当前分布式训练系统 underlying 的单程序多数据（SPMD）假设。我们提出了Echo，这是一种清洁地将这两个阶段 decouple 到异构的“推理”和“训练”集群中同时保持统计效率的RL系统。Echo 引入了两种轻量级同步协议：一种是顺序拉取模式，在每次API调用时刷新采样器权重以最小化偏差，另一种是异步推拉模式，通过回放缓冲区流式传输版本标记的轨迹以最大化硬件利用率。使用Qwen3-4B、Qwen2.5-7B和Qwen3-32B在地理上分布的集群上训练三个代表性RL工作负载，Echo 在收敛速度和最终奖励方面达到了与完全 colocate 的Verl基线相同的效果，同时将轨迹生成卸载到通用边缘硬件。这些有前途的结果表明，大型RL for LLMs 可以通过使用去中心化的异构资源实现数据中心级性能。', 'title_zh': 'Echo: 分离推理与训练以在异构群体中实现大规模RL对齐'}
{'arxiv_id': 'arXiv:2508.05364', 'title': 'Optimal Corpus Aware Training for Neural Machine Translation', 'authors': 'Yi-Hsiu Liao, Cheng Shen, Brenda, Yang', 'link': 'https://arxiv.org/abs/2508.05364', 'abstract': 'Corpus Aware Training (CAT) leverages valuable corpus metadata during training by injecting corpus information into each training example, and has been found effective in the literature, commonly known as the "tagging" approach. Models trained with CAT inherently learn the quality, domain and nuance between corpora directly from data, and can easily switch to different inference behavior. To achieve the best evaluation, CAT models pre-define a group of high quality data before training starts which can be error-prone and inefficient. In this work, we propose Optimal Corpus Aware Training (OCAT), which fine-tunes a CAT pre-trained model by freezing most of the model parameters and only tuning small set of corpus-related parameters. We show that OCAT is lightweight, resilient to overfitting, and effective in boosting model accuracy. We use WMT23 English to Chinese and English to German translation tasks as our test ground and show +3.6 and +1.8 chrF improvement, respectively, over vanilla training. Furthermore, our approach is on-par or slightly better than other state-of-the-art fine-tuning techniques while being less sensitive to hyperparameter settings.', 'abstract_zh': 'Corpus Aware Training (CAT) 活用利用训练过程中有价值的语料库元数据，通过将语料库信息注入每个训练样本中，在已在文献中广泛证明该方法有效， 通常称为“标注”方法。使用 CAT 训练的模型能够自适应地地 和语料库的质量和细微差别，并 � ，并 可以轻松转移到推理行为。然而 ，CAT 模型可能导致数据偏差和低效。为此， 我们提出 Optimal Corpus Aware Training (OCAT)，这是一种对 细微调节的 CAT 预训练模型的方法，通过冻结大部分模型参数并 只微调与语料库相关的一小 少参数。OCAT 轻量且在提高模型性能方面具有鲁棒性，并 。我们使用 WMT 23 对中英文到德文的翻译任务进行评估，分别取得了 3.6 和 1.8 字节改进，比 �妖怪典型的训练方法。此外 ，我们的方法在性能上 略微优于最先进的微调方法 ，并且对 在对 不太依赖于 超参数设置。', 'title_zh': '面向语料库的神经机器翻译优化训练'}
{'arxiv_id': 'arXiv:2508.05360', 'title': 'Building Effective Safety Guardrails in AI Education Tools', 'authors': 'Hannah-Beth Clark, Laura Benton, Emma Searle, Margaux Dowland, Matthew Gregory, Will Gayne, John Roberts', 'link': 'https://arxiv.org/abs/2508.05360', 'abstract': "There has been rapid development in generative AI tools across the education sector, which in turn is leading to increased adoption by teachers. However, this raises concerns regarding the safety and age-appropriateness of the AI-generated content that is being created for use in classrooms. This paper explores Oak National Academy's approach to addressing these concerns within the development of the UK Government's first publicly available generative AI tool - our AI-powered lesson planning assistant (Aila). Aila is intended to support teachers planning national curriculum-aligned lessons that are appropriate for pupils aged 5-16 years. To mitigate safety risks associated with AI-generated content we have implemented four key safety guardrails - (1) prompt engineering to ensure AI outputs are generated within pedagogically sound and curriculum-aligned parameters, (2) input threat detection to mitigate attacks, (3) an Independent Asynchronous Content Moderation Agent (IACMA) to assess outputs against predefined safety categories, and (4) taking a human-in-the-loop approach, to encourage teachers to review generated content before it is used in the classroom. Through our on-going evaluation of these safety guardrails we have identified several challenges and opportunities to take into account when implementing and testing safety guardrails. This paper highlights ways to build more effective safety guardrails in generative AI education tools including the on-going iteration and refinement of guardrails, as well as enabling cross-sector collaboration through sharing both open-source code, datasets and learnings.", 'abstract_zh': '教育领域生成AI工具的快速发展及其对教师采用的影响：基于UK政府首款公开AI辅助教学规划助手（Aila）的安全考量与实践探索', 'title_zh': '构建有效的AI教育工具安全护栏'}
{'arxiv_id': 'arXiv:2508.05353', 'title': 'PriorRG: Prior-Guided Contrastive Pre-training and Coarse-to-Fine Decoding for Chest X-ray Report Generation', 'authors': 'Kang Liu, Zhuoqi Ma, Zikang Fang, Yunan Li, Kun Xie, Qiguang Miao', 'link': 'https://arxiv.org/abs/2508.05353', 'abstract': "Chest X-ray report generation aims to reduce radiologists' workload by automatically producing high-quality preliminary reports. A critical yet underexplored aspect of this task is the effective use of patient-specific prior knowledge -- including clinical context (e.g., symptoms, medical history) and the most recent prior image -- which radiologists routinely rely on for diagnostic reasoning. Most existing methods generate reports from single images, neglecting this essential prior information and thus failing to capture diagnostic intent or disease progression. To bridge this gap, we propose PriorRG, a novel chest X-ray report generation framework that emulates real-world clinical workflows via a two-stage training pipeline. In Stage 1, we introduce a prior-guided contrastive pre-training scheme that leverages clinical context to guide spatiotemporal feature extraction, allowing the model to align more closely with the intrinsic spatiotemporal semantics in radiology reports. In Stage 2, we present a prior-aware coarse-to-fine decoding for report generation that progressively integrates patient-specific prior knowledge with the vision encoder's hidden states. This decoding allows the model to align with diagnostic focus and track disease progression, thereby enhancing the clinical accuracy and fluency of the generated reports. Extensive experiments on MIMIC-CXR and MIMIC-ABN datasets demonstrate that PriorRG outperforms state-of-the-art methods, achieving a 3.6% BLEU-4 and 3.8% F1 score improvement on MIMIC-CXR, and a 5.9% BLEU-1 gain on MIMIC-ABN. Code and checkpoints will be released upon acceptance.", 'abstract_zh': '胸部X射线报告生成旨在通过自动生成高质量初步报告来减轻放射科医生的工作负担。这一任务的一个关键但尚未充分探索的方面是如何有效利用患者特定的先验知识——包括临床背景（如症状、医疗历史）和最近的先验影像——这些建议对于放射科医生的诊断推理至关重要。现有的大多数方法仅从单张影像生成报告，忽视了这种重要的先验信息，因此无法捕捉到诊断意图或疾病进展。为此，我们提出了一种名为PriorRG的新颖胸部X射线报告生成框架，通过两阶段训练管道模仿实际临床工作流程。在第一阶段，我们引入了一种先验引导的对比预训练方案，利用临床背景引导时空特征提取，使模型更紧密地与放射学报告中的固有时空语义对齐。在第二阶段，我们提出了一种先验感知的粗细解码方法，逐步将患者特定的先验知识与视觉编码器的隐藏状态相结合，使模型能够跟随诊断重点并追踪疾病进展，从而提高生成报告的临床准确性和流畅性。在MIMIC-CXR和MIMIC-ABN数据集上的广泛实验表明，PriorRG优于现有方法，在MIMIC-CXR数据集上实现BLEU-4 3.6%和F1分数3.8%的提升，在MIMIC-ABN数据集上实现BLEU-1 5.9%的增长。在接受后，代码和检查点将公开。', 'title_zh': 'PriorRG: 基于先验的对比预训练和由粗到细解码的胸部X光报告生成'}
{'arxiv_id': 'arXiv:2508.05352', 'title': 'Multi-Modal Multi-Behavior Sequential Recommendation with Conditional Diffusion-Based Feature Denoising', 'authors': 'Xiaoxi Cui, Weihai Lu, Yu Tong, Yiheng Li, Zhejun Zhao', 'link': 'https://arxiv.org/abs/2508.05352', 'abstract': 'The sequential recommendation system utilizes historical user interactions to predict preferences. Effectively integrating diverse user behavior patterns with rich multimodal information of items to enhance the accuracy of sequential recommendations is an emerging and challenging research direction. This paper focuses on the problem of multi-modal multi-behavior sequential recommendation, aiming to address the following challenges: (1) the lack of effective characterization of modal preferences across different behaviors, as user attention to different item modalities varies depending on the behavior; (2) the difficulty of effectively mitigating implicit noise in user behavior, such as unintended actions like accidental clicks; (3) the inability to handle modality noise in multi-modal representations, which further impacts the accurate modeling of user preferences. To tackle these issues, we propose a novel Multi-Modal Multi-Behavior Sequential Recommendation model (M$^3$BSR). This model first removes noise in multi-modal representations using a Conditional Diffusion Modality Denoising Layer. Subsequently, it utilizes deep behavioral information to guide the denoising of shallow behavioral data, thereby alleviating the impact of noise in implicit feedback through Conditional Diffusion Behavior Denoising. Finally, by introducing a Multi-Expert Interest Extraction Layer, M$^3$BSR explicitly models the common and specific interests across behaviors and modalities to enhance recommendation performance. Experimental results indicate that M$^3$BSR significantly outperforms existing state-of-the-art methods on benchmark datasets.', 'abstract_zh': '多-line 多态 夙行为 顺序推荐系统（M$^3$$$$- $BSR）通过条件扩散去噪层去除多模态表示表表示表征中的噪声，，随后利用深层行为对抗浅层行为中的的噪声，，最终通过引入多--专Expert 兴趣提取层，在$3$1$BSR）显式建模行为和模态上的的兴趣以提升推荐性能。实验表明，$$d$3$BSR）在基准数据集上显著优于现有最先进的的方法。', 'title_zh': '基于条件扩散特征去噪的多模态多行为序列推荐'}
{'arxiv_id': 'arXiv:2508.05342', 'title': 'Information-Theoretic Graph Fusion with Vision-Language-Action Model for Policy Reasoning and Dual Robotic Control', 'authors': 'Shunlei Li, Longsen Gao, Jin Wang, Chang Che, Xi Xiao, Jiuwen Cao, Yingbai Hu, Hamid Reza Karimi', 'link': 'https://arxiv.org/abs/2508.05342', 'abstract': 'Teaching robots dexterous skills from human videos remains challenging due to the reliance on low-level trajectory imitation, which fails to generalize across object types, spatial layouts, and manipulator configurations. We propose Graph-Fused Vision-Language-Action (GF-VLA), a framework that enables dual-arm robotic systems to perform task-level reasoning and execution directly from RGB and Depth human demonstrations. GF-VLA first extracts Shannon-information-based cues to identify hands and objects with the highest task relevance, then encodes these cues into temporally ordered scene graphs that capture both hand-object and object-object interactions. These graphs are fused with a language-conditioned transformer that generates hierarchical behavior trees and interpretable Cartesian motion commands. To improve execution efficiency in bimanual settings, we further introduce a cross-hand selection policy that infers optimal gripper assignment without explicit geometric reasoning. We evaluate GF-VLA on four structured dual-arm block assembly tasks involving symbolic shape construction and spatial generalization. Experimental results show that the information-theoretic scene representation achieves over 95 percent graph accuracy and 93 percent subtask segmentation, supporting the LLM planner in generating reliable and human-readable task policies. When executed by the dual-arm robot, these policies yield 94 percent grasp success, 89 percent placement accuracy, and 90 percent overall task success across stacking, letter-building, and geometric reconfiguration scenarios, demonstrating strong generalization and robustness across diverse spatial and semantic variations.', 'abstract_zh': '从人类视频中教机器人灵巧技能依然具有挑战性，因为这高度依赖于低级轨迹模仿，无法在不同物体类型、空间布局和操作器配置之间进行泛化。我们提出了一种图融合视觉-语言-动作框架（GF-VLA），该框架使双臂机器人系统能够直接从RGB和深度人类演示中进行任务级推理和执行。GF-VLA 首先提取基于香农信息的线索以识别最具任务相关性的手和物体，然后将这些线索编码成描述手物和物体之间交互关系的时间顺序场景图。这些图与语言条件下的变换器融合，生成分层行为树和可解释的笛卡尔运动命令。为提高双臂操作中的执行效率，我们进一步引入了一种跨手选择策略，该策略在无需显式几何推理的情况下推断最佳夹爪分配。我们在四种涉及符号形状构建和空间泛化的双臂块组装任务上评估了GF-VLA。实验结果表明，信息论场景表示的图准确率超过95%，子任务分割准确率达到93%，支持大语言模型规划器生成可靠且易读的任务策略。当由双臂机器人执行时，这些策略在堆叠、字母构建和几何重构场景中实现了94%的抓取成功率、89%的放置准确率和90%的整体任务成功率，展示了其在不同空间和语义变体上的强大泛化能力和鲁棒性。', 'title_zh': '基于视觉-语言-动作模型的信息论图融合及其在策略推理与双臂机器人控制中的应用'}
{'arxiv_id': 'arXiv:2508.05337', 'title': 'Efficient Reasoning for Large Reasoning Language Models via Certainty-Guided Reflection Suppression', 'authors': 'Jiameng Huang, Baijiong Lin, Guhao Feng, Jierun Chen, Di He, Lu Hou', 'link': 'https://arxiv.org/abs/2508.05337', 'abstract': 'Recent Large Reasoning Language Models (LRLMs) employ long chain-of-thought reasoning with complex reflection behaviors, typically signaled by specific trigger words (e.g., "Wait" and "Alternatively") to enhance performance. However, these reflection behaviors can lead to the overthinking problem where the generation of redundant reasoning steps that unnecessarily increase token usage, raise inference costs, and reduce practical utility. In this paper, we propose Certainty-Guided Reflection Suppression (CGRS), a novel method that mitigates overthinking in LRLMs while maintaining reasoning accuracy. CGRS operates by dynamically suppressing the model\'s generation of reflection triggers when it exhibits high confidence in its current response, thereby preventing redundant reflection cycles without compromising output quality. Our approach is model-agnostic, requires no retraining or architectural modifications, and can be integrated seamlessly with existing autoregressive generation pipelines. Extensive experiments across four reasoning benchmarks (i.e., AIME24, AMC23, MATH500, and GPQA-D) demonstrate CGRS\'s effectiveness: it reduces token usage by an average of 18.5% to 41.9% while preserving accuracy. It also achieves the optimal balance between length reduction and performance compared to state-of-the-art baselines. These results hold consistently across model architectures (e.g., DeepSeek-R1-Distill series, QwQ-32B, and Qwen3 family) and scales (4B to 32B parameters), highlighting CGRS\'s practical value for efficient reasoning.', 'abstract_zh': 'Recent Large Reasoning Language Models中的确定性指导反射抑制（CGRS）：减轻过度推理的同时保持推理准确性', 'title_zh': '大型推理语言模型的高效推理通过不确定性引导的反射抑制实现'}
{'arxiv_id': 'arXiv:2508.05318', 'title': 'mKG-RAG: Multimodal Knowledge Graph-Enhanced RAG for Visual Question Answering', 'authors': 'Xu Yuan, Liangbo Ning, Wenqi Fan, Qing Li', 'link': 'https://arxiv.org/abs/2508.05318', 'abstract': 'Recently, Retrieval-Augmented Generation (RAG) has been proposed to expand internal knowledge of Multimodal Large Language Models (MLLMs) by incorporating external knowledge databases into the generation process, which is widely used for knowledge-based Visual Question Answering (VQA) tasks. Despite impressive advancements, vanilla RAG-based VQA methods that rely on unstructured documents and overlook the structural relationships among knowledge elements frequently introduce irrelevant or misleading content, reducing answer accuracy and reliability. To overcome these challenges, a promising solution is to integrate multimodal knowledge graphs (KGs) into RAG-based VQA frameworks to enhance the generation by introducing structured multimodal knowledge. Therefore, in this paper, we propose a novel multimodal knowledge-augmented generation framework (mKG-RAG) based on multimodal KGs for knowledge-intensive VQA tasks. Specifically, our approach leverages MLLM-powered keyword extraction and vision-text matching to distill semantically consistent and modality-aligned entities/relationships from multimodal documents, constructing high-quality multimodal KGs as structured knowledge representations. In addition, a dual-stage retrieval strategy equipped with a question-aware multimodal retriever is introduced to improve retrieval efficiency while refining precision. Comprehensive experiments demonstrate that our approach significantly outperforms existing methods, setting a new state-of-the-art for knowledge-based VQA.', 'abstract_zh': '最近，检索增强生成（RAG）被提出以通过集成外部知识数据库来扩展多模态大型语言模型（MLLMs）的内部知识，广泛应用于基于知识的视觉问答（VQA）任务。尽管取得了显著的进步，但依赖于无结构文档且忽视知识元素之间结构关系的原始RAG基VQA方法经常引入无关或误导性的内容，降低答案的准确性和可靠性。为克服这些挑战，将多模态知识图谱（KGs）集成到RAG基VQA框架中以增强生成，通过引入结构化的多模态知识来提升生成效果是一种有前景的解决方案。因此，在本文中，我们提出了一种基于多模态KG的知识增强生成框架（mKG-RAG），用于知识密集型VQA任务。具体而言，我们的方法利用MLLM支持的关键词提取和视觉-文本匹配来提炼语义一致且模态对齐的实体/关系，构建高质量的多模态KG作为结构化的知识表示。此外，我们引入了一种双阶段检索策略，配备有问题感知的多模态检索器，以提高检索效率并优化精确度。全面的实验显示，我们的方法显著优于现有方法，在基于知识的VQA任务上达到了新的state-of-the-art。', 'title_zh': '多模态知识图谱增强的RAG视觉问答模型'}
{'arxiv_id': 'arXiv:2508.05310', 'title': 'ASkDAgger: Active Skill-level Data Aggregation for Interactive Imitation Learning', 'authors': 'Jelle Luijkx, Zlatan Ajanović, Laura Ferranti, Jens Kober', 'link': 'https://arxiv.org/abs/2508.05310', 'abstract': 'Human teaching effort is a significant bottleneck for the broader applicability of interactive imitation learning. To reduce the number of required queries, existing methods employ active learning to query the human teacher only in uncertain, risky, or novel situations. However, during these queries, the novice\'s planned actions are not utilized despite containing valuable information, such as the novice\'s capabilities, as well as corresponding uncertainty levels. To this end, we allow the novice to say: "I plan to do this, but I am uncertain." We introduce the Active Skill-level Data Aggregation (ASkDAgger) framework, which leverages teacher feedback on the novice plan in three key ways: (1) S-Aware Gating (SAG): Adjusts the gating threshold to track sensitivity, specificity, or a minimum success rate; (2) Foresight Interactive Experience Replay (FIER), which recasts valid and relabeled novice action plans into demonstrations; and (3) Prioritized Interactive Experience Replay (PIER), which prioritizes replay based on uncertainty, novice success, and demonstration age. Together, these components balance query frequency with failure incidence, reduce the number of required demonstration annotations, improve generalization, and speed up adaptation to changing domains. We validate the effectiveness of ASkDAgger through language-conditioned manipulation tasks in both simulation and real-world environments. Code, data, and videos are available at this https URL.', 'abstract_zh': '人类教学努力是交互式模仿学习更广泛适用性的显著瓶颈。为了减少所需查询的数量，现有方法采用主动学习只为在不确定、有风险或新颖的情况下向人类教师查询。然而，在这些查询期间，新手计划的动作未被利用，尽管这些动作包含有价值的信息，如新手的能力及其相应的不确定性水平。为此，我们允许新手说：“我计划这样做，但我不确定。”我们提出了基于教师反馈的新手计划的主动技能级数据聚合(ASkDAgger)框架，该框架通过三种关键方式利用教师反馈：(1) S-感知门控(SAG)：调整门限以追踪敏感性、特异度或最小成功率；(2) 先见交互式经验重放(FIER)，将有效和重新标签的新手动作计划重新构造成演示；以及(3) 优先级交互式经验重放(PIER)，根据不确定性、新手成功率和演示时间优先重放。这些组件共同平衡查询频率与失败发生率，减少所需演示标注的数量，提高泛化能力，并加快适应变化领域。我们通过模拟和真实环境中的语言条件化操作任务验证了ASkDAgger的有效性。代码、数据和视频可在以下网址获得。', 'title_zh': 'ASKDAgger: 基于主动技能级数据聚合的交互式 imitation 学习'}
{'arxiv_id': 'arXiv:2508.05306', 'title': 'Estimating Musical Surprisal from Audio in Autoregressive Diffusion Model Noise Spaces', 'authors': 'Mathias Rose Bjare, Stefan Lattner, Gerhard Widmer', 'link': 'https://arxiv.org/abs/2508.05306', 'abstract': "Recently, the information content (IC) of predictions from a Generative Infinite-Vocabulary Transformer (GIVT) has been used to model musical expectancy and surprisal in audio. We investigate the effectiveness of such modelling using IC calculated with autoregressive diffusion models (ADMs). We empirically show that IC estimates of models based on two different diffusion ordinary differential equations (ODEs) describe diverse data better, in terms of negative log-likelihood, than a GIVT. We evaluate diffusion model IC's effectiveness in capturing surprisal aspects by examining two tasks: (1) capturing monophonic pitch surprisal, and (2) detecting segment boundaries in multi-track audio. In both tasks, the diffusion models match or exceed the performance of a GIVT. We hypothesize that the surprisal estimated at different diffusion process noise levels corresponds to the surprisal of music and audio features present at different audio granularities. Testing our hypothesis, we find that, for appropriate noise levels, the studied musical surprisal tasks' results improve. Code is provided on this http URL.", 'abstract_zh': '最近，生成无限词汇量变换器（GIVT）预测的信息内容（IC）被用于建模音频中的音乐期待和惊诧。我们研究了使用自回归扩散模型（ADMs）计算的IC估计的有效性。我们实证表明，基于两种不同扩散常微分方程（ODEs）的模型IC估计在负对数似然方面能更好地描述多样数据，优于GIVT。我们通过两个任务评估扩散模型IC在捕捉惊诧方面的效果：（1）捕捉单声部音高惊诧，（2）检测多轨音频中的段落边界。在两个任务中，扩散模型的性能与GIVT相当或超越GIVT。我们假设在不同扩散过程噪声水平下估计的惊诧对应于存在于不同音频粒度下的音乐和音频特征惊诧。验证我们的假设，我们发现，在适当的噪声水平下，研究的音乐惊诧任务的性能得到提升。相关代码见此网址。', 'title_zh': '从自回归扩散模型噪声空间中估计音乐 surprisal 从音频'}
{'arxiv_id': 'arXiv:2508.05299', 'title': 'VS-LLM: Visual-Semantic Depression Assessment based on LLM for Drawing Projection Test', 'authors': 'Meiqi Wu, Yaxuan Kang, Xuchen Li, Shiyu Hu, Xiaotang Chen, Yunfeng Kang, Weiqiang Wang, Kaiqi Huang', 'link': 'https://arxiv.org/abs/2508.05299', 'abstract': 'The Drawing Projection Test (DPT) is an essential tool in art therapy, allowing psychologists to assess participants\' mental states through their sketches. Specifically, through sketches with the theme of "a person picking an apple from a tree (PPAT)", it can be revealed whether the participants are in mental states such as depression. Compared with scales, the DPT can enrich psychologists\' understanding of an individual\'s mental state. However, the interpretation of the PPAT is laborious and depends on the experience of the psychologists. To address this issue, we propose an effective identification method to support psychologists in conducting a large-scale automatic DPT. Unlike traditional sketch recognition, DPT more focus on the overall evaluation of the sketches, such as color usage and space utilization. Moreover, PPAT imposes a time limit and prohibits verbal reminders, resulting in low drawing accuracy and a lack of detailed depiction. To address these challenges, we propose the following efforts: (1) Providing an experimental environment for automated analysis of PPAT sketches for depression assessment; (2) Offering a Visual-Semantic depression assessment based on LLM (VS-LLM) method; (3) Experimental results demonstrate that our method improves by 17.6% compared to the psychologist assessment method. We anticipate that this work will contribute to the research in mental state assessment based on PPAT sketches\' elements recognition. Our datasets and codes are available at this https URL.', 'abstract_zh': '绘画投射测试（DPT）是艺术疗法中的一个关键工具，通过参与者绘制的草图评估其心理状态。具体而言，通过以“从树上摘苹果的人（PPAT）”为主题的草图，可以揭示参与者是否处于抑郁等心理状态。与量表相比，DPT能够丰富心理学家对个体心理状态的理解。然而，PPAT的解读工作量大且依赖于心理学家的经验。为了解决这一问题，我们提出了一种有效的方法来支持心理学家进行大规模自动DPT。与传统的草图识别不同，DPT更侧重于对草图的整体评估，如颜色使用和空间利用。此外，PPAT设有时间限制并且禁止口头提示，导致绘画准确性较低且缺乏细节表现。为应对这些挑战，我们提出以下努力：（1）提供一个用于抑郁评估的PPAT草图自动化分析实验环境；（2）提供基于LLM的视觉-语义抑郁评估方法（VS-LLM）；（3）实验结果表明，我们的方法在抑郁评估中比心理学家评估方法提高了17.6%。预计本工作将为基于PPAT草图元素识别的心理状态评估研究做出贡献。我们的数据集和代码可通过以下链接获取。', 'title_zh': 'VS-LLM：基于大语言模型的视觉- 语义抑郁评估方法及其在绘画投射测试中的应用'}
{'arxiv_id': 'arXiv:2508.05294', 'title': 'Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction', 'authors': 'Sahar Salimpour, Lei Fu, Farhad Keramat, Leonardo Militano, Giovanni Toffetti, Harry Edelman, Jorge Peña Queralta', 'link': 'https://arxiv.org/abs/2508.05294', 'abstract': "Foundation models, including large language models (LLMs) and vision-language models (VLMs), have recently enabled novel approaches to robot autonomy and human-robot interfaces. In parallel, vision-language-action models (VLAs) or large behavior models (BLMs) are increasing the dexterity and capabilities of robotic systems. This survey paper focuses on those words advancing towards agentic applications and architectures. This includes initial efforts exploring GPT-style interfaces to tooling, as well as more complex system where AI agents are coordinators, planners, perception actors, or generalist interfaces. Such agentic architectures allow robots to reason over natural language instructions, invoke APIs, plan task sequences, or assist in operations and diagnostics. In addition to peer-reviewed research, due to the fast-evolving nature of the field, we highlight and include community-driven projects, ROS packages, and industrial frameworks that show emerging trends. We propose a taxonomy for classifying model integration approaches and present a comparative analysis of the role that agents play in different solutions in today's literature.", 'abstract_zh': '以下是论文内容或 标题的翻译， 中文，\nuser\n基于基础的方法和大规模语言模型（FGM和视觉-语言模型 VLM), 近来使 Recent允许了对 机器人自主性和人-机接口方面的创新方法。与此平行地 分层视觉-语言-行动模型（VLAM）和和大型行为模型（BLM) 也正在提高机器人的灵巧性和能力。。\n\n本文旨在探讨自主自主代理的应用和架构。这包括探索类 GPT 掏口到 以及更复杂的代理，，，代理的角色包括协调者、计划者、感知工作者等 和通用接口。这样的类代理架构使机器人能够根据取自然语言指令、调用API、规划任务序列、以及在操作和诊断中得以发挥作用。除了查阅经过同行评审的研究 G，考虑到该 G 星期社区驱动的项目、ROS 包 G 和 和工业框架 G，，新兴趋势。我们提出 G一种分类法来 为不同的整合方法分类，并 �并以及对对分析在当前的架构中代理的角色。', 'title_zh': '面向具身自主人工智能：由LLM和VLM驱动的机器人自主性和交互性的综述与分类'}
{'arxiv_id': 'arXiv:2508.05287', 'title': 'FlowState: Sampling Rate Invariant Time Series Forecasting', 'authors': 'Lars Graf, Thomas Ortner, Stanisław Woźniak, Angeliki Pantazi', 'link': 'https://arxiv.org/abs/2508.05287', 'abstract': 'Foundation models (FMs) have transformed natural language processing, but their success has not yet translated to time series forecasting. Existing time series foundation models (TSFMs), often based on transformer variants, struggle with generalization across varying context and target lengths, lack adaptability to different sampling rates, and are computationally inefficient. We introduce FlowState, a novel TSFM architecture that addresses these challenges through two key innovations: a state space model (SSM) based encoder and a functional basis decoder. This design enables continuous-time modeling and dynamic time-scale adjustment, allowing FlowState to inherently generalize across all possible temporal resolutions, and dynamically adjust the forecasting horizons. In contrast to other state-of-the-art TSFMs, which require training data across all possible sampling rates to memorize patterns at each scale, FlowState inherently adapts its internal dynamics to the input scale, enabling smaller models, reduced data requirements, and improved efficiency. We further propose an efficient pretraining strategy that improves robustness and accelerates training. Despite being the smallest model, FlowState outperforms all other models and is state-of-the-art for the GIFT-ZS and the Chronos-ZS benchmarks. Ablation studies confirm the effectiveness of its components, and we demonstrate its unique ability to adapt online to varying input sampling rates.', 'abstract_zh': 'FlowState：一种解决时间序列预测挑战的新型架构', 'title_zh': 'FlowState: 抽样率不变的时间序列预测'}
{'arxiv_id': 'arXiv:2508.05264', 'title': 'SGDFuse: SAM-Guided Diffusion for High-Fidelity Infrared and Visible Image Fusion', 'authors': 'Xiaoyang Zhang, Zhen Hua, Yakun Ju, Wei Zhou, Jun Liu, Alex C. Kot', 'link': 'https://arxiv.org/abs/2508.05264', 'abstract': "Infrared and visible image fusion (IVIF) aims to combine the thermal radiation information from infrared images with the rich texture details from visible images to enhance perceptual capabilities for downstream visual tasks. However, existing methods often fail to preserve key targets due to a lack of deep semantic understanding of the scene, while the fusion process itself can also introduce artifacts and detail loss, severely compromising both image quality and task performance. To address these issues, this paper proposes SGDFuse, a conditional diffusion model guided by the Segment Anything Model (SAM), to achieve high-fidelity and semantically-aware image fusion. The core of our method is to utilize high-quality semantic masks generated by SAM as explicit priors to guide the optimization of the fusion process via a conditional diffusion model. Specifically, the framework operates in a two-stage process: it first performs a preliminary fusion of multi-modal features, and then utilizes the semantic masks from SAM jointly with the preliminary fused image as a condition to drive the diffusion model's coarse-to-fine denoising generation. This ensures the fusion process not only has explicit semantic directionality but also guarantees the high fidelity of the final result. Extensive experiments demonstrate that SGDFuse achieves state-of-the-art performance in both subjective and objective evaluations, as well as in its adaptability to downstream tasks, providing a powerful solution to the core challenges in image fusion. The code of SGDFuse is available at this https URL.", 'abstract_zh': '红外与可见光图像融合（IVIF）旨在结合红外图像的热辐射信息与可见光图像丰富的纹理细节，以提升下游视觉任务的感知能力。然而，现有方法往往由于缺乏对场景的深层语义理解而难以保留关键目标，同时融合过程本身也可能引入伪影和细节丢失，严重损害了图像质量和任务性能。为了解决这些问题，本文提出了一种由Segment Anything Model (SAM) 引导的条件扩散模型SGDFuse，以实现高度保真的语义感知图像融合。我们方法的核心是利用SAM生成的高质量语义掩膜作为显性先验，通过条件扩散模型引导融合过程的优化。具体而言，框架分为两阶段：首先进行多模态特征的初步融合，然后利用SAM生成的语义掩膜与初步融合图像作为条件，驱动扩散模型自底向上的去噪生成。这不仅确保了融合过程具有显性的语义方向性，还保证了最终结果的高度保真度。大量实验表明，SGDFuse在主观评价和客观评价中均取得了领先性能，并在下游任务的适应性方面表现出色，提供了一种解决图像融合核心挑战的强大方案。SGDFuse的代码可在以下链接获取。', 'title_zh': 'SGDFuse：SAM引导的高保真红外和可见光图像融合'}
{'arxiv_id': 'arXiv:2508.05262', 'title': 'Robust Tracking with Particle Filtering for Fluorescent Cardiac Imaging', 'authors': 'Suresh Guttikonda, Maximilian Neidhart, Johanna Sprenger, Johannes Petersen, Christian Detter, Alexander Schlaefer', 'link': 'https://arxiv.org/abs/2508.05262', 'abstract': 'Intraoperative fluorescent cardiac imaging enables quality control following coronary bypass grafting surgery. We can estimate local quantitative indicators, such as cardiac perfusion, by tracking local feature points. However, heart motion and significant fluctuations in image characteristics caused by vessel structural enrichment limit traditional tracking methods. We propose a particle filtering tracker based on cyclicconsistency checks to robustly track particles sampled to follow target landmarks. Our method tracks 117 targets simultaneously at 25.4 fps, allowing real-time estimates during interventions. It achieves a tracking error of (5.00 +/- 0.22 px) and outperforms other deep learning trackers (22.3 +/- 1.1 px) and conventional trackers (58.1 +/- 27.1 px).', 'abstract_zh': '术中荧光心脏成像实现冠状动脉旁路移植手术后的质量控制', 'title_zh': '荧光心脏成像中基于粒子滤波的鲁棒跟踪'}
{'arxiv_id': 'arXiv:2508.05260', 'title': 'Marine Chlorophyll Prediction and Driver Analysis based on LSTM-RF Hybrid Models', 'authors': 'Zhouyao Qian, Yang Chen, Baodian Li, Shuyi Zhang, Zhen Tian, Gongsen Wang, Tianyue Gu, Xinyu Zhou, Huilin Chen, Xinyi Li, Hao Zhu, Shuyao Zhang, Zongheng Li, Siyuan Wang', 'link': 'https://arxiv.org/abs/2508.05260', 'abstract': 'Marine chlorophyll concentration is an important indicator of ecosystem health and carbon cycle strength, and its accurate prediction is crucial for red tide warning and ecological response. In this paper, we propose a LSTM-RF hybrid model that combines the advantages of LSTM and RF, which solves the deficiencies of a single model in time-series modelling and nonlinear feature portrayal. Trained with multi-source ocean data(temperature, salinity, dissolved oxygen, etc.), the experimental results show that the LSTM-RF model has an R^2 of 0.5386, an MSE of 0.005806, and an MAE of 0.057147 on the test set, which is significantly better than using LSTM (R^2 = 0.0208) and RF (R^2 =0.4934) alone , respectively. The standardised treatment and sliding window approach improved the prediction accuracy of the model and provided an innovative solution for high-frequency prediction of marine ecological variables.', 'abstract_zh': '海洋叶绿素浓度是生态系统健康和碳循环强度的重要指标，其准确预测对于赤潮预警和生态响应至关重要。本文提出了一种LSTM-RF混合模型，结合了LSTM和RF的优点，解决了单一模型在时间序列建模和非线性特征表示中的不足。该模型使用多源海洋数据（温度、盐度、溶解氧等）进行训练，实验结果表明，LSTM-RF模型在测试集上的R²为0.5386，MSE为0.005806，MAE为0.057147，显著优于单独使用LSTM（R²=0.0208）和RF（R²=0.4934）。标准化处理和滑动窗口方法提高了模型的预测精度，并为海洋生态变量的高频预测提供了创新解决方案。', 'title_zh': '基于LSTM-RF混合模型的海洋 chlorophyll 预测及驱动因素分析'}
{'arxiv_id': 'arXiv:2508.05254', 'title': 'CF3: Compact and Fast 3D Feature Fields', 'authors': 'Hyunjoon Lee, Joonkyu Min, Jaesik Park', 'link': 'https://arxiv.org/abs/2508.05254', 'abstract': '3D Gaussian Splatting (3DGS) has begun incorporating rich information from 2D foundation models. However, most approaches rely on a bottom-up optimization process that treats raw 2D features as ground truth, incurring increased computational costs. We propose a top-down pipeline for constructing compact and fast 3D Gaussian feature fields, namely, CF3. We first perform a fast weighted fusion of multi-view 2D features with pre-trained Gaussians. This approach enables training a per-Gaussian autoencoder directly on the lifted features, instead of training autoencoders in the 2D domain. As a result, the autoencoder better aligns with the feature distribution. More importantly, we introduce an adaptive sparsification method that optimizes the Gaussian attributes of the feature field while pruning and merging the redundant Gaussians, constructing an efficient representation with preserved geometric details. Our approach achieves a competitive 3D feature field using as little as 5% of the Gaussians compared to Feature-3DGS.', 'abstract_zh': '3DGS结合了丰富的2D基础模型信息。然而，大多数方法依赖于自底向上的优化过程，将原始2D特征视为 ground truth，导致计算成本增加。我们提出了一种自顶向下的管道，用于构建紧凑且快速的3D高斯特征场，即CF3。我们首先执行多视图2D特征和预训练高斯之间的快速加权融合。这种方法允许直接在提升特征上训练每个高斯的自编码器，而不是在2D域中训练自编码器。因此，自编码器更好地与特征分布对齐。更重要的是，我们引入了一种自适应稀疏化方法，在裁剪和合并冗余高斯的同时优化特征场的高斯属性，构建一个高效的表示，同时保留几何细节。我们的方法使用比Feature-3DGS少5%的高斯实现了竞争性的3D特征场。', 'title_zh': 'CF3: 紧凑快速的3D特征场'}
{'arxiv_id': 'arXiv:2508.05246', 'title': 'A Study of Gender Classification Techniques Based on Iris Images: A Deep Survey and Analysis', 'authors': 'Basna Mohammed Salih Hasan, Ramadhan J. Mstafa', 'link': 'https://arxiv.org/abs/2508.05246', 'abstract': "Gender classification is attractive in a range of applications, including surveillance and monitoring, corporate profiling, and human-computer interaction. Individuals' identities may be gleaned from information about their gender, which is a kind of soft this http URL the years, several methods for determining a person's gender have been devised. Some of the most well-known ones are based on physical characteristics like face, fingerprint, palmprint, DNA, ears, gait, and iris. On the other hand, facial features account for the vast majority of gender classification methods. Also, the iris is a significant biometric trait because the iris, according to research, remains basically constant during an individual's life. Besides that, the iris is externally visible and is non-invasive to the user, which is important for practical applications. Furthermore, there are already high-quality methods for segmenting and encoding iris images, and the current methods facilitate selecting and extracting attribute vectors from iris textures. This study discusses several approaches to determining gender. The previous works of literature are briefly reviewed. Additionally, there are a variety of methodologies for different steps of gender classification. This study provides researchers with knowledge and analysis of the existing gender classification approaches. Also, it will assist researchers who are interested in this specific area, as well as highlight the gaps and challenges in the field, and finally provide suggestions and future paths for improvement.", 'abstract_zh': '性别分类在监控、企业 profiling 和人机交互等众多应用中具有吸引力。个体的身份可以通过性别信息推断出来，这是一种软身份标识。多年来，已经设计出了多种确定个人性别的方法。最著名的方法之一是基于面部、指纹、掌纹、DNA、耳廓、步态和虹膜等生理特征。另一方面，面部特征构成了性别分类方法的绝大部分。此外，虹膜是一个重要的生物特征，因为研究表明，虹膜在整个个体生命期内基本保持不变。而且，虹膜对外部可见，对用户无侵入性，这对于实际应用很重要。此外，已经存在高质量的虹膜图像分割和编码方法，当前的方法使从虹膜纹理中选择和提取属性向量变得便利。本文讨论了几种确定性别的方法，简要回顾了相关文献。另外，性别分类的不同步骤中存在多种方法。本文为研究人员提供了关于现有性别分类方法的知识和分析，也将帮助对该领域感兴趣的其他研究者，同时指出该领域的空白和挑战，并最终提出改进建议和未来研究方向。', 'title_zh': '基于虹膜图像的性别分类技术研究与分析'}
{'arxiv_id': 'arXiv:2508.05244', 'title': 'RegionMed-CLIP: A Region-Aware Multimodal Contrastive Learning Pre-trained Model for Medical Image Understanding', 'authors': 'Tianchen Fang, Guiru Liu', 'link': 'https://arxiv.org/abs/2508.05244', 'abstract': 'Medical image understanding plays a crucial role in enabling automated diagnosis and data-driven clinical decision support. However, its progress is impeded by two primary challenges: the limited availability of high-quality annotated medical data and an overreliance on global image features, which often miss subtle but clinically significant pathological regions. To address these issues, we introduce RegionMed-CLIP, a region-aware multimodal contrastive learning framework that explicitly incorporates localized pathological signals along with holistic semantic representations. The core of our method is an innovative region-of-interest (ROI) processor that adaptively integrates fine-grained regional features with the global context, supported by a progressive training strategy that enhances hierarchical multimodal alignment. To enable large-scale region-level representation learning, we construct MedRegion-500k, a comprehensive medical image-text corpus that features extensive regional annotations and multilevel clinical descriptions. Extensive experiments on image-text retrieval, zero-shot classification, and visual question answering tasks demonstrate that RegionMed-CLIP consistently exceeds state-of-the-art vision language models by a wide margin. Our results highlight the critical importance of region-aware contrastive pre-training and position RegionMed-CLIP as a robust foundation for advancing multimodal medical image understanding.', 'abstract_zh': 'Medical图像理解在实现自动化诊断和数据驱动的临床决策支持中起着关键作用，但由于高质量标注医疗数据的有限可用性和过度依赖全局图像特征导致的挑战而受阻。为解决这些问题，我们提出了RegionMed-CLIP，这是一种区域意识的多模态对比学习框架，明确结合了局部病理信号和整体语义表示。我们的方法的核心是一种创新的感兴趣区域（ROI）处理器，该处理器适应性地将细粒度的区域特征与全局上下文相结合，并通过逐步训练策略增强层次多模态对齐。为实现大规模区域级表示学习，我们构建了MedRegion-500k，这是一个包含广泛区域注释和多层次临床描述的综合医疗图像-文本语料库。在图像-文本检索、零样本分类和视觉问答任务上的广泛实验表明，RegionMed-CLIP在视觉语言模型上表现出了显著的优势。我们的结果突显了区域意识对比预训练的关键重要性，并将RegionMed-CLIP定位为推动多模态医学图像理解的基础。', 'title_zh': 'RegionMed-CLIP: 一种区域意识的多模态对比学习预训练模型用于医学图像理解'}
{'arxiv_id': 'arXiv:2508.05240', 'title': 'Coarse-to-Fine Joint Registration of MR and Ultrasound Images via Imaging Style Transfer', 'authors': 'Junyi Wang, Xi Zhu, Yikun Guo, Zixi Wang, Haichuan Gao, Le Zhang, Fan Zhang', 'link': 'https://arxiv.org/abs/2508.05240', 'abstract': 'We developed a pipeline for registering pre-surgery Magnetic Resonance (MR) images and post-resection Ultrasound (US) images. Our approach leverages unpaired style transfer using 3D CycleGAN to generate synthetic T1 images, thereby enhancing registration performance. Additionally, our registration process employs both affine and local deformable transformations for a coarse-to-fine registration. The results demonstrate that our approach improves the consistency between MR and US image pairs in most cases.', 'abstract_zh': '我们开发了一种术前磁共振(MR)图像和术后超声(US)图像配准的管道。我们的方法利用3D CycleGAN进行未配对风格转换，生成合成的T1图像，从而提高配准性能。此外，我们的配准过程采用粗到细的方式，结合使用仿射变换和局部可变形变换。结果表明，在大多数情况下，我们的方法提高了MR和US图像配对的一致性。', 'title_zh': '从粗到细的MR和超声图像联合配准及成像风格迁移'}
{'arxiv_id': 'arXiv:2508.05239', 'title': 'Pruning Large Language Models by Identifying and Preserving Functional Networks', 'authors': 'Yiheng Liu, Junhao Ning, Sichen Xia, Xiaohui Gao, Ning Qiang, Bao Ge, Junwei Han, Xintao Hu', 'link': 'https://arxiv.org/abs/2508.05239', 'abstract': 'Structured pruning is one of the representative techniques for compressing large language models (LLMs) to reduce GPU memory consumption and accelerate inference speed. It offers significant practical value in improving the efficiency of LLMs in real-world applications. Current structured pruning methods typically rely on assessment of the importance of the structure units and pruning the units with less importance. Most of them overlooks the interaction and collaboration among artificial neurons that are crucial for the functionalities of LLMs, leading to a disruption in the macro functional architecture of LLMs and consequently a pruning performance degradation. Inspired by the inherent similarities between artificial neural networks and functional neural networks in the human brain, we alleviate this challenge and propose to prune LLMs by identifying and preserving functional networks within LLMs in this study. To achieve this, we treat an LLM as a digital brain and decompose the LLM into functional networks, analogous to identifying functional brain networks in neuroimaging data. Afterwards, an LLM is pruned by preserving the key neurons within these functional networks. Experimental results demonstrate that the proposed method can successfully identify and locate functional networks and key neurons in LLMs, enabling efficient model pruning. Our code is available at this https URL.', 'abstract_zh': '结构化剪枝是压缩大型语言模型（LLMs）以减少GPU内存消耗和加速推理速度的一种代表性技术。它在提高LLMs在实际应用中的效率方面具有重要的实用价值。当前的结构化剪枝方法通常依赖于对结构单元重要性的评估，并剪枝那些重要性较低的单元。大多数方法忽略了对LLMs功能至关重要的人工神经元之间的交互和协作，这会导致LLMs宏观功能架构的破坏，从而降低剪枝性能。受人工神经网络与人脑功能神经网络内在相似性的启发，我们缓解了这一挑战，并在此研究中提出通过识别和保留LLMs内的功能网络来进行LLMs的剪枝。为此，我们将LLM视为数字大脑，将其分解为功能网络，类似于在神经影像数据中识别功能脑网络。随后，通过保留这些功能网络内的关键神经元来剪枝LLM。实验结果表明，所提出的方法可以成功识别和定位LLMs内的功能网络和关键神经元，从而实现高效的模型剪枝。我们的代码可在以下网址获取。', 'title_zh': '通过识别和保留功能性网络精简大型语言模型'}
{'arxiv_id': 'arXiv:2508.05238', 'title': 'Driver Assistant: Persuading Drivers to Adjust Secondary Tasks Using Large Language Models', 'authors': 'Wei Xiang, Muchen Li, Jie Yan, Manling Zheng, Hanfei Zhu, Mengyun Jiang, Lingyun Sun', 'link': 'https://arxiv.org/abs/2508.05238', 'abstract': 'Level 3 automated driving systems allows drivers to engage in secondary tasks while diminishing their perception of risk. In the event of an emergency necessitating driver intervention, the system will alert the driver with a limited window for reaction and imposing a substantial cognitive burden. To address this challenge, this study employs a Large Language Model (LLM) to assist drivers in maintaining an appropriate attention on road conditions through a "humanized" persuasive advice. Our tool leverages the road conditions encountered by Level 3 systems as triggers, proactively steering driver behavior via both visual and auditory routes. Empirical study indicates that our tool is effective in sustaining driver attention with reduced cognitive load and coordinating secondary tasks with takeover behavior. Our work provides insights into the potential of using LLMs to support drivers during multi-task automated driving.', 'abstract_zh': 'Level 3 辅助驾驶系统允许驾驶员在降低感知风险的情况下进行次要任务。在需要驾驶员干预的紧急情况下，系统会通过有限的反应窗口提醒驾驶员，并施加较大的认知负担。为应对这一挑战，本研究利用大型语言模型（LLM）通过“人性化”的劝说建议帮助驾驶员维持对道路状况的适当关注。该工具将Level 3系统遇到的道路情况作为触发器，通过视觉和听觉途径主动引导驾驶员行为。实证研究表明，该工具在减少认知负荷的同时有效维持了驾驶员的注意力，并协调了次要任务与接管行为。本研究为利用LLM在多任务辅助驾驶中支持驾驶员的潜力提供了见解。', 'title_zh': '驾驶员助手：使用大型语言模型说服驾驶员调整次要任务'}
{'arxiv_id': 'arXiv:2508.05237', 'title': 'Navigating the Trade-off: A Synthesis of Defensive Strategies for Zero-Shot Adversarial Robustness in Vision-Language Models', 'authors': 'Zane Xu, Jason Sun', 'link': 'https://arxiv.org/abs/2508.05237', 'abstract': "This report synthesizes eight seminal papers on the zero-shot adversarial robustness of vision-language models (VLMs) like CLIP. A central challenge in this domain is the inherent trade-off between enhancing adversarial robustness and preserving the model's zero-shot generalization capabilities. We analyze two primary defense paradigms: Adversarial Fine-Tuning (AFT), which modifies model parameters, and Training-Free/Test-Time Defenses, which preserve them. We trace the evolution from alignment-preserving methods (TeCoA) to embedding space re-engineering (LAAT, TIMA), and from input heuristics (AOM, TTC) to latent-space purification (CLIPure). Finally, we identify key challenges and future directions including hybrid defense strategies and adversarial pre-training.", 'abstract_zh': '本报告综合了八篇关于视觉语言模型（VLMs）如CLIP的零样本 adversarial 稳定性的奠基性论文。该领域的一个核心挑战是在增强 adversarial 稳定性和保持模型的零样本泛化能力之间存在的固有trade-off。我们分析了两种主要的防御范式：对抗微调（AFT），其修改模型参数，以及无需训练/测试时防御，其保持模型参数不变。我们追溯了从保对齐方法（TeCoA）到嵌入空间重构（LAAT、TIMA）的发展，以及从输入启发式（AOM、TTC）到潜在空间净化（CLIPure）的变化。最后，我们指出了关键挑战和未来发展方向，包括混合防御策略和对抗预训练。', 'title_zh': '权衡trade-off之道：视觉-语言模型零样本对抗鲁棒性的防御策略综述'}
{'arxiv_id': 'arXiv:2508.05234', 'title': 'Resource-Limited Joint Multimodal Sentiment Reasoning and Classification via Chain-of-Thought Enhancement and Distillation', 'authors': 'Haonan Shangguan, Xiaocui Yang, Shi Feng, Daling Wang, Yifei Zhang, Ge Yu', 'link': 'https://arxiv.org/abs/2508.05234', 'abstract': 'The surge in rich multimodal content on social media platforms has greatly advanced Multimodal Sentiment Analysis (MSA), with Large Language Models (LLMs) further accelerating progress in this field. Current approaches primarily leverage the knowledge and reasoning capabilities of parameter-heavy (Multimodal) LLMs for sentiment classification, overlooking autonomous multimodal sentiment reasoning generation in resource-constrained environments. Therefore, we focus on the Resource-Limited Joint Multimodal Sentiment Reasoning and Classification task, JMSRC, which simultaneously performs multimodal sentiment reasoning chain generation and sentiment classification only with a lightweight model. We propose a Multimodal Chain-of-Thought Reasoning Distillation model, MulCoT-RD, designed for JMSRC that employs a "Teacher-Assistant-Student" distillation paradigm to address deployment constraints in resource-limited environments. We first leverage a high-performance Multimodal Large Language Model (MLLM) to generate the initial reasoning dataset and train a medium-sized assistant model with a multi-task learning mechanism. A lightweight student model is jointly trained to perform efficient multimodal sentiment reasoning generation and classification. Extensive experiments on four datasets demonstrate that MulCoT-RD with only 3B parameters achieves strong performance on JMSRC, while exhibiting robust generalization and enhanced interpretability.', 'abstract_zh': '社交媒体平台上的丰富多模态内容 surged极大地推动了多模态情感分析（MSA）的发展，大规模语言模型（LLMs）进一步加快了这一领域的进展。当前的方法主要依赖于参数密集型（多模态）LLMs的知识和推理能力进行情感分类，忽视了在资源受限环境中自主多模态情感推理生成的能力。因此，我们集中于资源受限环境下联合的多模态情感推理和分类任务（JMSRC），仅使用轻量级模型执行多模态情感推理链生成和情感分类。我们提出了一种用于JMSRC的多模态思维链推理蒸馏模型（MulCoT-RD），该模型采用“教师-助理-学生”蒸馏范式以应对资源受限环境下的部署约束。我们利用高性能的多模态大规模语言模型（MLLM）生成初始推理数据集，并使用多任务学习机制训练一个中型助理模型。同时联合训练一个轻量级学生模型以高效执行多模态情感推理生成和分类。在四个数据集上的广泛实验表明，仅含有3B参数的MulCoT-RD在JMSRC任务上表现出色，同时具有较强的泛化能力和增强的可解释性。', 'title_zh': '资源受限的联模式情感推理与分类 via 增强思维链与蒸馏'}
{'arxiv_id': 'arXiv:2508.05231', 'title': 'FDC-Net: Rethinking the association between EEG artifact removal and multi-dimensional affective computing', 'authors': 'Wenjia Dong, Xueyuan Xu, Tianze Yu, Junming Zhang, Li Zhuo', 'link': 'https://arxiv.org/abs/2508.05231', 'abstract': 'Electroencephalogram (EEG)-based emotion recognition holds significant value in affective computing and brain-computer interfaces. However, in practical applications, EEG recordings are susceptible to the effects of various physiological artifacts. Current approaches typically treat denoising and emotion recognition as independent tasks using cascaded architectures, which not only leads to error accumulation, but also fails to exploit potential synergies between these tasks. Moreover, conventional EEG-based emotion recognition models often rely on the idealized assumption of "perfectly denoised data", lacking a systematic design for noise robustness. To address these challenges, a novel framework that deeply couples denoising and emotion recognition tasks is proposed for end-to-end noise-robust emotion recognition, termed as Feedback-Driven Collaborative Network for Denoising-Classification Nexus (FDC-Net). Our primary innovation lies in establishing a dynamic collaborative mechanism between artifact removal and emotion recognition through: (1) bidirectional gradient propagation with joint optimization strategies; (2) a gated attention mechanism integrated with frequency-adaptive Transformer using learnable band-position encoding. Two most popular EEG-based emotion datasets (DEAP and DREAMER) with multi-dimensional emotional labels were employed to compare the artifact removal and emotion recognition performance between ASLSL and nine state-of-the-art methods. In terms of the denoising task, FDC-Net obtains a maximum correlation coefficient (CC) value of 96.30% on DEAP and a maximum CC value of 90.31% on DREAMER. In terms of the emotion recognition task under physiological artifact interference, FDC-Net achieves emotion recognition accuracies of 82.3+7.1% on DEAP and 88.1+0.8% on DREAMER.', 'abstract_zh': '基于EEG的情绪识别在情感计算和脑机接口中具有重要价值。然而，在实际应用中，EEG记录容易受到各种生理伪迹的影响。当前方法通常将去噪和情绪识别视为独立任务，采用级联架构，导致错误累积，并且未能充分利用这些任务之间的潜在协同作用。此外，传统的基于EEG的情绪识别模型往往基于“完美去噪数据”的理想假设，缺乏系统的噪声鲁棒性设计。为了解决这些问题，提出了一种新颖的框架，通过深度耦合去噪和情绪识别任务，实现了端到端的噪声鲁棒情绪识别，该框架称为反馈驱动协作网络用于去噪-分类纽带（FDC-Net）。我们的主要创新在于通过：（1）双向梯度传播和联合优化策略；（2）集成了可学习频带位置编码的门控注意机制与频率自适应Transformer，建立了去伪和情绪识别之间的动态协作机制。分别使用多维度情感标签的两种最流行EEG情绪识别数据集（DEAP和DREAMER），将FDC-Net与ASLSL和九种最新方法的去伪和情绪识别性能进行了比较。在去噪任务中，FDC-Net在DEAP上的最大相关系数（CC）值为96.30%，在DREAMER上的最大CC值为90.31%。在生理伪迹干扰下的情绪识别任务中，FDC-Net在DEAP上的情绪识别准确率为82.3+7.1%，在DREAMER上的情绪识别准确率为88.1+0.8%。', 'title_zh': 'FDC-Net: 重新思考EEG信号去噪与多维度情感计算之间的关联'}
{'arxiv_id': 'arXiv:2508.05229', 'title': 'ADSEL: Adaptive dual self-expression learning for EEG feature selection via incomplete multi-dimensional emotional tagging', 'authors': 'Tianze Yu, Junming Zhang, Wenjia Dong, Xueyuan Xu, Li Zhuo', 'link': 'https://arxiv.org/abs/2508.05229', 'abstract': 'EEG based multi-dimension emotion recognition has attracted substantial research interest in human computer interfaces. However, the high dimensionality of EEG features, coupled with limited sample sizes, frequently leads to classifier overfitting and high computational complexity. Feature selection constitutes a critical strategy for mitigating these challenges. Most existing EEG feature selection methods assume complete multi-dimensional emotion labels. In practice, open acquisition environment, and the inherent subjectivity of emotion perception often result in incomplete label data, which can compromise model generalization. Additionally, existing feature selection methods for handling incomplete multi-dimensional labels primarily focus on correlations among various dimensions during label recovery, neglecting the correlation between samples in the label space and their interaction with various dimensions. To address these issues, we propose a novel incomplete multi-dimensional feature selection algorithm for EEG-based emotion recognition. The proposed method integrates an adaptive dual self-expression learning (ADSEL) with least squares regression. ADSEL establishes a bidirectional pathway between sample-level and dimension-level self-expression learning processes within the label space. It could facilitate the cross-sharing of learned information between these processes, enabling the simultaneous exploitation of effective information across both samples and dimensions for label reconstruction. Consequently, ADSEL could enhances label recovery accuracy and effectively identifies the optimal EEG feature subset for multi-dimensional emotion recognition.', 'abstract_zh': '基于EEG的多缺失多维度情感识别特征选择algorithm', 'title_zh': 'ADSEL：基于不完整多维情绪标注的自适应双路径自表达学习的EEG特征选择'}
{'arxiv_id': 'arXiv:2508.05228', 'title': 'CWEFS: Brain volume conduction effects inspired channel-wise EEG feature selection for multi-dimensional emotion recognition', 'authors': 'Xueyuan Xu, Wenjia Dong, Fulin Wei, Li Zhuo', 'link': 'https://arxiv.org/abs/2508.05228', 'abstract': 'Due to the intracranial volume conduction effects, high-dimensional multi-channel electroencephalography (EEG) features often contain substantial redundant and irrelevant information. This issue not only hinders the extraction of discriminative emotional representations but also compromises the real-time performance. Feature selection has been established as an effective approach to address the challenges while enhancing the transparency and interpretability of emotion recognition models. However, existing EEG feature selection research overlooks the influence of latent EEG feature structures on emotional label correlations and assumes uniform importance across various channels, directly limiting the precise construction of EEG feature selection models for multi-dimensional affective computing. To address these limitations, a novel channel-wise EEG feature selection (CWEFS) method is proposed for multi-dimensional emotion recognition. Specifically, inspired by brain volume conduction effects, CWEFS integrates EEG emotional feature selection into a shared latent structure model designed to construct a consensus latent space across diverse EEG channels. To preserve the local geometric structure, this consensus space is further integrated with the latent semantic analysis of multi-dimensional emotional labels. Additionally, CWEFS incorporates adaptive channel-weight learning to automatically determine the significance of different EEG channels in the emotional feature selection task. The effectiveness of CWEFS was validated using three popular EEG datasets with multi-dimensional emotional labels. Comprehensive experimental results, compared against nineteen feature selection methods, demonstrate that the EEG feature subsets chosen by CWEFS achieve optimal emotion recognition performance across six evaluation metrics.', 'abstract_zh': '基于通道的脑电特征选择方法以提高多维度情感识别性能', 'title_zh': 'CWEFS: 基于脑体积传导效应的通道级EEG特征选择方法及其在多维度情绪识别中的应用'}
{'arxiv_id': 'arXiv:2508.05221', 'title': 'ReasoningTrack: Chain-of-Thought Reasoning for Long-term Vision-Language Tracking', 'authors': 'Xiao Wang, Liye Jin, Xufeng Lou, Shiao Wang, Lan Chen, Bo Jiang, Zhipeng Zhang', 'link': 'https://arxiv.org/abs/2508.05221', 'abstract': "Vision-language tracking has received increasing attention in recent years, as textual information can effectively address the inflexibility and inaccuracy associated with specifying the target object to be tracked. Existing works either directly fuse the fixed language with vision features or simply modify using attention, however, their performance is still limited. Recently, some researchers have explored using text generation to adapt to the variations in the target during tracking, however, these works fail to provide insights into the model's reasoning process and do not fully leverage the advantages of large models, which further limits their overall performance. To address the aforementioned issues, this paper proposes a novel reasoning-based vision-language tracking framework, named ReasoningTrack, based on a pre-trained vision-language model Qwen2.5-VL. Both SFT (Supervised Fine-Tuning) and reinforcement learning GRPO are used for the optimization of reasoning and language generation. We embed the updated language descriptions and feed them into a unified tracking backbone network together with vision features. Then, we adopt a tracking head to predict the specific location of the target object. In addition, we propose a large-scale long-term vision-language tracking benchmark dataset, termed TNLLT, which contains 200 video sequences. 20 baseline visual trackers are re-trained and evaluated on this dataset, which builds a solid foundation for the vision-language visual tracking task. Extensive experiments on multiple vision-language tracking benchmark datasets fully validated the effectiveness of our proposed reasoning-based natural language generation strategy. The source code of this paper will be released on this https URL", 'abstract_zh': '基于视觉语言推理的目标跟踪框架ReasoningTrack', 'title_zh': 'ReasoningTrack：长时视觉-语言跟踪的链式推理方法'}
{'arxiv_id': 'arXiv:2508.05210', 'title': 'Advanced Hybrid Transformer LSTM Technique with Attention and TS Mixer for Drilling Rate of Penetration Prediction', 'authors': 'Saddam Hussain Khan', 'link': 'https://arxiv.org/abs/2508.05210', 'abstract': 'The Rate of Penetration (ROP) is crucial for optimizing drilling operations; however, accurately predicting it is hindered by the complex, dynamic, and high-dimensional nature of drilling data. Traditional empirical, physics-based, and basic machine learning models often fail to capture intricate temporal and contextual relationships, resulting in suboptimal predictions and limited real-time utility. To address this gap, we propose a novel hybrid deep learning architecture integrating Long Short-Term Memory (LSTM) networks, Transformer encoders, Time-Series Mixer (TS-Mixer) blocks, and attention mechanisms to synergistically model temporal dependencies, static feature interactions, global context, and dynamic feature importance. Evaluated on a real-world drilling dataset, our model outperformed benchmarks (standalone LSTM, TS-Mixer, and simpler hybrids) with an R-squared score of 0.9988 and a Mean Absolute Percentage Error of 1.447%, as measured by standard regression metrics (R-squared, MAE, RMSE, MAPE). Model interpretability was ensured using SHAP and LIME, while actual vs. predicted curves and bias checks confirmed accuracy and fairness across scenarios. This advanced hybrid approach enables reliable real-time ROP prediction, paving the way for intelligent, cost-effective drilling optimization systems with significant operational impact.', 'abstract_zh': '基于LSTM、Transformer、TS-Mixer和注意力机制的混合深度学习架构在钻井作业中的实时率_of_penetration预测', 'title_zh': '基于注意力机制和TS Mixer的高级混合变压器LSTM技术在钻进速度预测中的应用'}
{'arxiv_id': 'arXiv:2508.05207', 'title': 'SpectroStream: A Versatile Neural Codec for General Audio', 'authors': 'Yunpeng Li, Kehang Han, Brian McWilliams, Zalan Borsos, Marco Tagliasacchi', 'link': 'https://arxiv.org/abs/2508.05207', 'abstract': 'We propose SpectroStream, a full-band multi-channel neural audio codec. Successor to the well-established SoundStream, SpectroStream extends its capability beyond 24 kHz monophonic audio and enables high-quality reconstruction of 48 kHz stereo music at bit rates of 4--16 kbps. This is accomplished with a new neural architecture that leverages audio representation in the time-frequency domain, which leads to better audio quality especially at higher sample rate. The model also uses a delayed-fusion strategy to handle multi-channel audio, which is crucial in balancing per-channel acoustic quality and cross-channel phase consistency.', 'abstract_zh': 'SpectroStream：全频带多通道神经音频编解码器', 'title_zh': 'SpectroStream：一种通用音频的 versatile 神经编解码器'}
{'arxiv_id': 'arXiv:2508.05201', 'title': 'FAITH: A Framework for Assessing Intrinsic Tabular Hallucinations in finance', 'authors': 'Mengao Zhang, Jiayu Fu, Tanya Warrier, Yuwen Wang, Tianhui Tan, Ke-wei Huang', 'link': 'https://arxiv.org/abs/2508.05201', 'abstract': 'Hallucination remains a critical challenge for deploying Large Language Models (LLMs) in finance. Accurate extraction and precise calculation from tabular data are essential for reliable financial analysis, since even minor numerical errors can undermine decision-making and regulatory compliance. Financial applications have unique requirements, often relying on context-dependent, numerical, and proprietary tabular data that existing hallucination benchmarks rarely capture. In this study, we develop a rigorous and scalable framework for evaluating intrinsic hallucinations in financial LLMs, conceptualized as a context-aware masked span prediction task over real-world financial documents. Our main contributions are: (1) a novel, automated dataset creation paradigm using a masking strategy; (2) a new hallucination evaluation dataset derived from S&P 500 annual reports; and (3) a comprehensive evaluation of intrinsic hallucination patterns in state-of-the-art LLMs on financial tabular data. Our work provides a robust methodology for in-house LLM evaluation and serves as a critical step toward building more trustworthy and reliable financial Generative AI systems.', 'abstract_zh': 'Hallucination仍然是在金融领域部署大型语言模型（LLMs）的关键挑战。准确提取和精确计算表格数据是实现可靠财务分析的关键，因为即使是轻微的数值错误也可能影响决策和监管合规性。金融应用有独特的诉求，通常依赖于上下文相关、数值型和专有的表格数据，而现有的幻觉基准很少涵盖这些需求。在本研究中，我们构建了一个严格且可扩展的框架，以评估金融LLMs中的固有幻觉，这一框架被概念化为一种基于真实世界金融文件的上下文感知隐藏跨度预测任务。我们的主要贡献包括：（1）一种新的自动化数据集创建范式，使用遮蔽策略；（2）一个源自标普500年度报告的新幻觉评估数据集；以及（3）对最先进的LLMs在财务表格数据上的固有幻觉模式进行全面评估。我们的工作提供了一种稳健的内部LLM评估方法，并为构建更可信赖和可靠的金融生成AI系统奠定了关键步骤。', 'title_zh': 'FAITH: 评估金融领域内在表格幻觉的框架'}
{'arxiv_id': 'arXiv:2508.05199', 'title': 'EvoGraph: Hybrid Directed Graph Evolution toward Software 3.0', 'authors': 'Igor Costa, Christopher Baran', 'link': 'https://arxiv.org/abs/2508.05199', 'abstract': "We introduce **EvoGraph**, a framework that enables software systems to evolve their own source code, build pipelines, documentation, and tickets. EvoGraph represents every artefact in a typed directed graph, applies learned mutation operators driven by specialized small language models (SLMs), and selects survivors with a multi-objective fitness. On three benchmarks, EvoGraph fixes 83% of known security vulnerabilities, translates COBOL to Java with 93% functional equivalence (test verified), and maintains documentation freshness within two minutes. Experiments show a 40% latency reduction and a sevenfold drop in feature lead time compared with strong baselines. We extend our approach to **evoGraph**, leveraging language-specific SLMs for modernizing .NET, Lisp, CGI, ColdFusion, legacy Python, and C codebases, achieving 82-96% semantic equivalence across languages while reducing computational costs by 90% compared to large language models. EvoGraph's design responds to empirical failure modes in legacy modernization, such as implicit contracts, performance preservation, and integration evolution. Our results suggest a practical path toward Software 3.0, where systems adapt continuously yet remain under measurable control.", 'abstract_zh': 'EvoGraph：一种使软件系统进化其源代码、构建管道、文档和票据的框架', 'title_zh': 'EvoGraph: 混合有向图演化 toward 软件3.0'}
{'arxiv_id': 'arXiv:2508.05198', 'title': 'Balancing Accuracy and Novelty with Sub-Item Popularity', 'authors': 'Chiara Mallamaci, Aleksandr Vladimirovich Petrov, Alberto Carlo Maria Mancino, Vito Walter Anelli, Tommaso Di Noia, Craig Macdonald', 'link': 'https://arxiv.org/abs/2508.05198', 'abstract': "In the realm of music recommendation, sequential recommenders have shown promise in capturing the dynamic nature of music consumption. A key characteristic of this domain is repetitive listening, where users frequently replay familiar tracks. To capture these repetition patterns, recent research has introduced Personalised Popularity Scores (PPS), which quantify user-specific preferences based on historical frequency. While PPS enhances relevance in recommendation, it often reinforces already-known content, limiting the system's ability to surface novel or serendipitous items - key elements for fostering long-term user engagement and satisfaction. To address this limitation, we build upon RecJPQ, a Transformer-based framework initially developed to improve scalability in large-item catalogues through sub-item decomposition. We repurpose RecJPQ's sub-item architecture to model personalised popularity at a finer granularity. This allows us to capture shared repetition patterns across sub-embeddings - latent structures not accessible through item-level popularity alone. We propose a novel integration of sub-ID-level personalised popularity within the RecJPQ framework, enabling explicit control over the trade-off between accuracy and personalised novelty. Our sub-ID-level PPS method (sPPS) consistently outperforms item-level PPS by achieving significantly higher personalised novelty without compromising recommendation accuracy. Code and experiments are publicly available at this https URL.", 'abstract_zh': '音乐推荐领域的序列推荐器在捕捉音乐消费的动态性方面显示出潜力。一个关键特征是重复聆听，用户频繁重播熟悉的曲目。为了捕捉这些重复模式，近期研究引入了个性化流行度评分（PPS），基于历史频率量化用户特定偏好。虽然PPS增强了推荐的相关性，但它往往加强了已知内容，限制了系统展示新颖或偶然项的能力——这是促进长期用户参与度和满意度的关键要素。为了解决这一局限，我们以RecJPQ为基构建模型，RecJPQ最初是一个基于Transformer的框架，旨在通过次项分解提高大规模项目录的可扩展性。我们将RecJPQ的次项架构重新用于以更细粒度建模个性化流行度。这使我们能够捕捉次嵌入中的共享重复模式——仅通过项级流行度无法访问的潜在结构。我们提出了一种在RecJPQ框架中整合次ID级个性化流行度的新方法，使我们可以明确定义准确性和个性化新颖性之间的权衡。我们的次ID级PPS方法（sPPS）在不牺牲推荐准确性的情况下，通过显著提高个性化新颖性，始终优于项级PPS。相关代码和实验已公开可在以下链接访问。', 'title_zh': '平衡准确性和新颖性与子项流行度'}
{'arxiv_id': 'arXiv:2508.05188', 'title': 'Incident Response Planning Using a Lightweight Large Language Model with Reduced Hallucination', 'authors': 'Kim Hammar, Tansu Alpcan, Emil C. Lupu', 'link': 'https://arxiv.org/abs/2508.05188', 'abstract': 'Timely and effective incident response is key to managing the growing frequency of cyberattacks. However, identifying the right response actions for complex systems is a major technical challenge. A promising approach to mitigate this challenge is to use the security knowledge embedded in large language models (LLMs) to assist security operators during incident handling. Recent research has demonstrated the potential of this approach, but current methods are mainly based on prompt engineering of frontier LLMs, which is costly and prone to hallucinations. We address these limitations by presenting a novel way to use an LLM for incident response planning with reduced hallucination. Our method includes three steps: fine-tuning, information retrieval, and lookahead planning. We prove that our method generates response plans with a bounded probability of hallucination and that this probability can be made arbitrarily small at the expense of increased planning time under certain assumptions. Moreover, we show that our method is lightweight and can run on commodity hardware. We evaluate our method on logs from incidents reported in the literature. The experimental results show that our method a) achieves up to 22% shorter recovery times than frontier LLMs and b) generalizes to a broad range of incident types and response actions.', 'abstract_zh': '及时有效的应急响应是管理日益频繁的网络攻击的关键。然而，为复杂系统识别正确的应急响应行动是一项重大的技术挑战。一种有望缓解这一挑战的方法是利用大型语言模型（LLM）中嵌入的安全知识，在应急处理过程中辅助安全操作员。近期的研究证明了这一方法的潜力，但当前的方法主要基于前沿LLM的提示工程，这耗时且容易产生错误。我们通过提出一种新颖的方法来解决这些限制，该方法能够在减少错误的同时利用LLM进行应急响应规划。我们的方法包括三个步骤：微调、信息检索和前瞻规划。我们证明，我们的方法生成的响应计划在满足某些假设的情况下具有界限内的幻觉概率，并且通过增加规划时间，这一概率可以被任意减小。此外，我们展示了我们的方法具有轻量级的特性，可以在通用硬件上运行。我们在文献中报告的事故日志上评估了我们的方法。实验结果表明，我们的方法a) 将恢复时间缩短了高达22%，b) 能够适应广泛类型的事故和响应行动。', 'title_zh': '使用减轻幻觉的轻量级大型语言模型进行事件响应规划'}
{'arxiv_id': 'arXiv:2508.05187', 'title': 'Refining Gaussian Splatting: A Volumetric Densification Approach', 'authors': 'Mohamed Abdul Gafoor, Marius Preda, Titus Zaharia', 'link': 'https://arxiv.org/abs/2508.05187', 'abstract': 'Achieving high-quality novel view synthesis in 3D Gaussian Splatting (3DGS) often depends on effective point primitive management. The underlying Adaptive Density Control (ADC) process addresses this issue by automating densification and pruning. Yet, the vanilla 3DGS densification strategy shows key shortcomings. To address this issue, in this paper we introduce a novel density control method, which exploits the volumes of inertia associated to each Gaussian function to guide the refinement process. Furthermore, we study the effect of both traditional Structure from Motion (SfM) and Deep Image Matching (DIM) methods for point cloud initialization. Extensive experimental evaluations on the Mip-NeRF 360 dataset demonstrate that our approach surpasses 3DGS in reconstruction quality, delivering encouraging performance across diverse scenes.', 'abstract_zh': '在3D高斯点绘制（3DGS）中实现高质量的新视角合成往往取决于有效的点元管理。底层的自适应密度控制（ADC）过程通过自动化密集化和修剪来解决这一问题。然而，vanilla 3DGS的密集化策略显示出关键缺陷。为了解决这一问题，本文提出了一种新的密度控制方法，通过利用每个高斯函数相关的动量体积来指导细化过程。此外，我们研究了传统结构从运动（SfM）和深度图像匹配（DIM）方法对点云初始化的影响。在Mip-NeRF 360数据集上的广泛实验评估表明，我们的方法在重建质量上超越了3DGS，并在多种场景中取得了令人鼓舞的性能。', 'title_zh': '改进高斯绘制：一种体形密度化方法'}
{'arxiv_id': 'arXiv:2508.05170', 'title': 'Posterior-GRPO: Rewarding Reasoning Processes in Code Generation', 'authors': 'Lishui Fan, Yu Zhang, Mouxiang Chen, Zhongxin Liu', 'link': 'https://arxiv.org/abs/2508.05170', 'abstract': "Reinforcement learning (RL) has significantly advanced code generation for large language models (LLMs). However, current paradigms rely on outcome-based rewards from test cases, neglecting the quality of the intermediate reasoning process. While supervising the reasoning process directly is a promising direction, it is highly susceptible to reward hacking, where the policy model learns to exploit the reasoning reward signal without improving final outcomes. To address this, we introduce a unified framework that can effectively incorporate the quality of the reasoning process during RL. First, to enable reasoning evaluation, we develop LCB-RB, a benchmark comprising preference pairs of superior and inferior reasoning processes. Second, to accurately score reasoning quality, we introduce an Optimized-Degraded based (OD-based) method for reward model training. This method generates high-quality preference pairs by systematically optimizing and degrading initial reasoning paths along curated dimensions of reasoning quality, such as factual accuracy, logical rigor, and coherence. A 7B parameter reward model with this method achieves state-of-the-art (SOTA) performance on LCB-RB and generalizes well to other benchmarks. Finally, we introduce Posterior-GRPO (P-GRPO), a novel RL method that conditions process-based rewards on task success. By selectively applying rewards to the reasoning processes of only successful outcomes, P-GRPO effectively mitigates reward hacking and aligns the model's internal reasoning with final code correctness. A 7B parameter model with P-GRPO achieves superior performance across diverse code generation tasks, outperforming outcome-only baselines by 4.5%, achieving comparable performance to GPT-4-Turbo. We further demonstrate the generalizability of our approach by extending it to mathematical tasks. Our models, dataset, and code are publicly available.", 'abstract_zh': '强化学习（RL）显著推进了大型语言模型（LLMs）的代码生成。然而，当前方法依赖于测试案例的结果奖励，忽视了中间推理过程的质量。虽然直接监督推理过程是一个有前景的方向，但极易导致奖励欺骗，即策略模型学会利用推理奖励信号而不提高最终结果。为解决这一问题，我们提出了一种统一框架，能够在RL过程中有效融入推理过程的质量。首先，为了实现推理评估，我们开发了LCB-RB基准，其包含高级和较差推理过程的偏好对。其次，为了准确评分推理质量，我们引入了一种基于优化-退化（OD）的方法进行奖励模型训练。该方法通过系统地优化和退化初始推理路径，沿特定的推理质量维度生成高质量的偏好对，如事实准确性、逻辑严密性和连贯性。使用该方法训练的7B参数奖励模型在LCB-RB上达到了最优性能，并在其他基准上表现出良好的泛化能力。最后，我们提出了基于过程奖励的后验GRPO（P-GRPO）新方法，该方法将过程奖励条件化于任务成功。通过仅对成功结果的推理过程应用奖励，P-GRPO有效减轻了奖励欺骗，并使模型的内部推理与最终代码正确性对齐。使用P-GRPO的7B参数模型在多种代码生成任务上表现出优越性能，优于仅基于结果的基线4.5%，并实现了与GPT-4-Turbo相当的性能。我们进一步展示了该方法的泛化能力，将其扩展到数学任务。我们的模型、数据集和代码已公开。', 'title_zh': '后验-GRPO：奖励编码生成中的推理过程'}
{'arxiv_id': 'arXiv:2508.05165', 'title': 'Aligning LLMs on a Budget: Inference-Time Alignment with Heuristic Reward Models', 'authors': 'Mason Nakamura, Saaduddin Mahmud, Kyle H. Wray, Hamed Zamani, Shlomo Zilberstein', 'link': 'https://arxiv.org/abs/2508.05165', 'abstract': "Aligning LLMs with user preferences is crucial for real-world use but often requires costly fine-tuning or expensive inference, forcing trade-offs between alignment quality and computational cost. Existing inference-time methods typically ignore this balance, focusing solely on the optimized policy's performance. We propose HIA (Heuristic-Guided Inference-time Alignment), a tuning-free, black-box-compatible approach that uses a lightweight prompt optimizer, heuristic reward models, and two-stage filtering to reduce inference calls while preserving alignment quality. On real-world prompt datasets, HelpSteer and ComPRed, HIA outperforms best-of-N sampling, beam search, and greedy search baselines in multi-objective, goal-conditioned tasks under the same inference budget. We also find that HIA is effective under low-inference budgets with as little as one or two response queries, offering a practical solution for scalable, personalized LLM deployment.", 'abstract_zh': '对齐LL\nuser\n把下面的论文标题翻译成中文，\n JuventusAlign: He-Guided Inference-Time Alignment for Personalized LLM Deployment', 'title_zh': '预算内的LLM对齐：基于启发式奖励模型的推理时对齐'}
{'arxiv_id': 'arXiv:2508.05154', 'title': 'Domain-driven Metrics for Reinforcement Learning: A Case Study on Epidemic Control using Agent-based Simulation', 'authors': 'Rishabh Gaur, Gaurav Deshkar, Jayanta Kshirsagar, Harshal Hayatnagarkar, Janani Venugopalan', 'link': 'https://arxiv.org/abs/2508.05154', 'abstract': "For the development and optimization of agent-based models (ABMs) and rational agent-based models (RABMs), optimization algorithms such as reinforcement learning are extensively used. However, assessing the performance of RL-based ABMs and RABMS models is challenging due to the complexity and stochasticity of the modeled systems, and the lack of well-standardized metrics for comparing RL algorithms. In this study, we are developing domain-driven metrics for RL, while building on state-of-the-art metrics. We demonstrate our ``Domain-driven-RL-metrics'' using policy optimization on a rational ABM disease modeling case study to model masking behavior, vaccination, and lockdown in a pandemic. Our results show the use of domain-driven rewards in conjunction with traditional and state-of-the-art metrics for a few different simulation scenarios such as the differential availability of masks.", 'abstract_zh': '基于领域驱动的强化学习评估指标在代理基于模型及其理性扩展模型开发与优化中的应用：以传染病模型为例', 'title_zh': '基于领域驱动的强化学习度量标准：基于代理仿真在流行病控制中的案例研究'}
{'arxiv_id': 'arXiv:2508.05153', 'title': 'FCBV-Net: Category-Level Robotic Garment Smoothing via Feature-Conditioned Bimanual Value Prediction', 'authors': 'Mohammed Daba, Jing Qiu', 'link': 'https://arxiv.org/abs/2508.05153', 'abstract': 'Category-level generalization for robotic garment manipulation, such as bimanual smoothing, remains a significant hurdle due to high dimensionality, complex dynamics, and intra-category variations. Current approaches often struggle, either overfitting with concurrently learned visual features for a specific instance or, despite category-level perceptual generalization, failing to predict the value of synergistic bimanual actions. We propose the Feature-Conditioned Bimanual Value Network (FCBV-Net), operating on 3D point clouds to specifically enhance category-level policy generalization for garment smoothing. FCBV-Net conditions bimanual action value prediction on pre-trained, frozen dense geometric features, ensuring robustness to intra-category garment variations. Trainable downstream components then learn a task-specific policy using these static features. In simulated GarmentLab experiments with the CLOTH3D dataset, FCBV-Net demonstrated superior category-level generalization. It exhibited only an 11.5% efficiency drop (Steps80) on unseen garments compared to 96.2% for a 2D image-based baseline, and achieved 89% final coverage, outperforming an 83% coverage from a 3D correspondence-based baseline that uses identical per-point geometric features but a fixed primitive. These results highlight that the decoupling of geometric understanding from bimanual action value learning enables better category-level generalization.', 'abstract_zh': '基于特征条件的双边价值网络（FCBV-Net）：用于服装整理的类别级政策泛化', 'title_zh': 'FCBV-Net: 基于特征条件的双臂价值预测在类别级别机器人服装平滑中的应用'}
{'arxiv_id': 'arXiv:2508.05152', 'title': 'Tool Graph Retriever: Exploring Dependency Graph-based Tool Retrieval for Large Language Models', 'authors': 'Linfeng Gao, Yaoxiang Wang, Minlong Peng, Jialong Tang, Yuzhe Shang, Mingming Sun, Jinsong Su', 'link': 'https://arxiv.org/abs/2508.05152', 'abstract': 'With the remarkable advancement of AI agents, the number of their equipped tools is increasing rapidly. However, integrating all tool information into the limited model context becomes impractical, highlighting the need for efficient tool retrieval methods. In this regard, dominant methods primarily rely on semantic similarities between tool descriptions and user queries to retrieve relevant tools. However, they often consider each tool independently, overlooking dependencies between tools, which may lead to the omission of prerequisite tools for successful task execution. To deal with this defect, in this paper, we propose Tool Graph Retriever (TGR), which exploits the dependencies among tools to learn better tool representations for retrieval. First, we construct a dataset termed TDI300K to train a discriminator for identifying tool dependencies. Then, we represent all candidate tools as a tool dependency graph and use graph convolution to integrate the dependencies into their representations. Finally, these updated tool representations are employed for online retrieval. Experimental results on several commonly used datasets show that our TGR can bring a performance improvement to existing dominant methods, achieving SOTA performance. Moreover, in-depth analyses also verify the importance of tool dependencies and the effectiveness of our TGR.', 'abstract_zh': '随着AI代理的显著进步，工具的数量不断增加。由于集成这些工具变得 impractical， 因此突显了高效工具检索的必要性。就此而言，主导方法主要主要主要主要依赖于工具描述和查询之间的语义相似性进行检索。然而，它们往往 each 工具独立进行检索，忽略了工具之间的依赖关系，这可能导致缺失必要的工具从而影响任务执行的成功。为解决这一缺陷，我们提出了 Tool Dependency Retention（TGR），它利用工具之间的依赖关系来改进检索。首先，我们构建构建构建了一个名为 Tool Dependency 3K（T-D3K）的数据集来训练一个鉴别器以识别工具之间的依赖关系。然后我们用候选工具表示一个工具依赖图，并利用图卷积来提取这些依赖关系。最后，，我们在更新后的构建的表达性中使用图卷积进行了在线检索。实验结果表明，相较于现有主导方法 TGR 可以在达到S-OTA（当前最佳水平）表现上提供改进。深入分析也证实了工具依赖关系的重要性以及我们的 TGR 的有效性。', 'title_zh': '工具图检索器：基于依赖图的大型语言模型工具检索探索'}
{'arxiv_id': 'arXiv:2508.05149', 'title': 'Speech LLMs in Low-Resource Scenarios: Data Volume Requirements and the Impact of Pretraining on High-Resource Languages', 'authors': 'Seraphina Fong, Marco Matassoni, Alessio Brutti', 'link': 'https://arxiv.org/abs/2508.05149', 'abstract': 'Large language models (LLMs) have demonstrated potential in handling spoken inputs for high-resource languages, reaching state-of-the-art performance in various tasks. However, their applicability is still less explored in low-resource settings. This work investigates the use of Speech LLMs for low-resource Automatic Speech Recognition using the SLAM-ASR framework, where a trainable lightweight projector connects a speech encoder and a LLM. Firstly, we assess training data volume requirements to match Whisper-only performance, re-emphasizing the challenges of limited data. Secondly, we show that leveraging mono- or multilingual projectors pretrained on high-resource languages reduces the impact of data scarcity, especially with small training sets. Using multilingual LLMs (EuroLLM, Salamandra) with whisper-large-v3-turbo, we evaluate performance on several public benchmarks, providing insights for future research on optimizing Speech LLMs for low-resource languages and multilinguality.', 'abstract_zh': '大型语言模型（LLMs）已经在处理高资源语言的口语输入方面展示了潜力，并在各种任务中达到了最先进的性能。然而，在低资源环境中其应用性 still less explored。本文探讨了使用 SLAM-ASR 框架中的语音 LLM 进行低资源自动语音识别的方法，其中可训练的轻量级投影器连接语音编码器和 LLM。首先，我们评估了训练数据量的需求，以匹配 Whisper 的性能，重新强调了数据短缺的挑战。其次，我们表明，利用在高资源语言上预训练的单语或多语投影器可以减轻数据稀缺的影响，尤其是在使用小规模训练集时。使用多语言 LLM（EuroLLM、Salamandra）与 whisper-large-v3-turbo 结合，我们在多个公开基准上评估性能，为未来研究优化适用于低资源语言和多语言性的语音 LLM 提供了见解。', 'title_zh': '低资源场景中的语音语言模型：数据量要求及预训练对高资源语言的影响'}
{'arxiv_id': 'arXiv:2508.05148', 'title': 'Chemist Eye: A Visual Language Model-Powered System for Safety Monitoring and Robot Decision-Making in Self-Driving Laboratories', 'authors': 'Francisco Munguia-Galeano, Zhengxue Zhou, Satheeshkumar Veeramani, Hatem Fakhruldeen, Louis Longley, Rob Clowes, Andrew I. Cooper', 'link': 'https://arxiv.org/abs/2508.05148', 'abstract': 'The integration of robotics and automation into self-driving laboratories (SDLs) can introduce additional safety complexities, in addition to those that already apply to conventional research laboratories. Personal protective equipment (PPE) is an essential requirement for ensuring the safety and well-being of workers in laboratories, self-driving or otherwise. Fires are another important risk factor in chemical laboratories. In SDLs, fires that occur close to mobile robots, which use flammable lithium batteries, could have increased severity. Here, we present Chemist Eye, a distributed safety monitoring system designed to enhance situational awareness in SDLs. The system integrates multiple stations equipped with RGB, depth, and infrared cameras, designed to monitor incidents in SDLs. Chemist Eye is also designed to spot workers who have suffered a potential accident or medical emergency, PPE compliance and fire hazards. To do this, Chemist Eye uses decision-making driven by a vision-language model (VLM). Chemist Eye is designed for seamless integration, enabling real-time communication with robots. Based on the VLM recommendations, the system attempts to drive mobile robots away from potential fire locations, exits, or individuals not wearing PPE, and issues audible warnings where necessary. It also integrates with third-party messaging platforms to provide instant notifications to lab personnel. We tested Chemist Eye with real-world data from an SDL equipped with three mobile robots and found that the spotting of possible safety hazards and decision-making performances reached 97 % and 95 %, respectively.', 'abstract_zh': '机器人与自动化集成到自主驾驶实验室中可以引入额外的安全复杂性，这在传统的研究实验室中已经存在。个人防护装备是确保实验室工作者安全与健康的重要要求，在自主驾驶或传统的化学实验室中都是如此。火灾是化学实验室中的另一个重要风险因素。在自主驾驶实验室（SDLs）中，发生在使用易燃锂离子电池的移动机器人附近的火灾可能会更加严重。我们介绍了Chemist Eye，这是一个分布式安全监控系统，旨在增强SDLs的安全态势感知能力。该系统集成了多个配备RGB、深度和红外摄像头的站点，用于监控SDL中的事故。Chemist Eye还设计用于识别可能遭遇事故或医疗紧急情况的工作者，以及监测个人防护装备合规性和火灾隐患。Chemist Eye通过由视觉-语言模型（VLM）驱动的决策来实现这一点。Chemist Eye设计为无缝集成，能够与机器人实现实时通信。根据VLM的建议，系统尝试驱离移动机器人远离潜在火灾地点、出口或未佩戴个人防护装备的个体，并在必要时发出声音警告。此外，该系统还与第三方消息平台集成，提供即时通知给实验室人员。我们使用配备了三台移动机器人的实际SDL数据对Chemist Eye进行了测试，结果显示可能的安全隐患识别和决策性能分别达到了97%和95%。', 'title_zh': '化学家之眼：一种基于视觉语言模型的安全监控与机器人决策系统在自主实验室中的应用'}
{'arxiv_id': 'arXiv:2508.05137', 'title': 'FedGIN: Federated Learning with Dynamic Global Intensity Non-linear Augmentation for Organ Segmentation using Multi-modal Images', 'authors': 'Sachin Dudda Nagaraju, Ashkan Moradi, Bendik Skarre Abrahamsen, Mattijs Elschot', 'link': 'https://arxiv.org/abs/2508.05137', 'abstract': 'Medical image segmentation plays a crucial role in AI-assisted diagnostics, surgical planning, and treatment monitoring. Accurate and robust segmentation models are essential for enabling reliable, data-driven clinical decision making across diverse imaging modalities. Given the inherent variability in image characteristics across modalities, developing a unified model capable of generalizing effectively to multiple modalities would be highly beneficial. This model could streamline clinical workflows and reduce the need for modality-specific training. However, real-world deployment faces major challenges, including data scarcity, domain shift between modalities (e.g., CT vs. MRI), and privacy restrictions that prevent data sharing. To address these issues, we propose FedGIN, a Federated Learning (FL) framework that enables multimodal organ segmentation without sharing raw patient data. Our method integrates a lightweight Global Intensity Non-linear (GIN) augmentation module that harmonizes modality-specific intensity distributions during local training. We evaluated FedGIN using two types of datasets: an imputed dataset and a complete dataset. In the limited dataset scenario, the model was initially trained using only MRI data, and CT data was added to assess its performance improvements. In the complete dataset scenario, both MRI and CT data were fully utilized for training on all clients. In the limited-data scenario, FedGIN achieved a 12 to 18% improvement in 3D Dice scores on MRI test cases compared to FL without GIN and consistently outperformed local baselines. In the complete dataset scenario, FedGIN demonstrated near-centralized performance, with a 30% Dice score improvement over the MRI-only baseline and a 10% improvement over the CT-only baseline, highlighting its strong cross-modality generalization under privacy constraints.', 'abstract_zh': '基于联邦学习的多模态器官分割方法FedGIN', 'title_zh': 'FedGIN：基于动态全局强度非线性增强的联邦学习在多模态图像器官分割中的应用'}
{'arxiv_id': 'arXiv:2508.05132', 'title': 'Towards Assessing Medical Ethics from Knowledge to Practice', 'authors': 'Chang Hong, Minghao Wu, Qingying Xiao, Yuchi Wang, Xiang Wan, Guangjun Yu, Benyou Wang, Yan Hu', 'link': 'https://arxiv.org/abs/2508.05132', 'abstract': "The integration of large language models into healthcare necessitates a rigorous evaluation of their ethical reasoning, an area current benchmarks often overlook. We introduce PrinciplismQA, a comprehensive benchmark with 3,648 questions designed to systematically assess LLMs' alignment with core medical ethics. Grounded in Principlism, our benchmark features a high-quality dataset. This includes multiple-choice questions curated from authoritative textbooks and open-ended questions sourced from authoritative medical ethics case study literature, all validated by medical experts. Our experiments reveal a significant gap between models' ethical knowledge and their practical application, especially in dynamically applying ethical principles to real-world scenarios. Most LLMs struggle with dilemmas concerning Beneficence, often over-emphasizing other principles. Frontier closed-source models, driven by strong general capabilities, currently lead the benchmark. Notably, medical domain fine-tuning can enhance models' overall ethical competence, but further progress requires better alignment with medical ethical knowledge. PrinciplismQA offers a scalable framework to diagnose these specific ethical weaknesses, paving the way for more balanced and responsible medical AI.", 'abstract_zh': '大型语言模型在医疗领域的集成需要对其伦理推理进行严格的评估，这是一个当前基准常常忽略的领域。我们引入了PrinciplismQA，这是一个包含3,648个问题的全面基准，旨在系统评估LLMs与核心医疗伦理的契合度。该基准基于Principlism理念，包含高质量的数据集。其中包括从权威教科书中精选的多项选择题和源自权威医学伦理案例研究文献的开放式问题，所有问题均经医学专家验证。我们的实验揭示了模型的伦理知识与其实际应用之间的显著差距，尤其是在将伦理原则应用于真实世界场景时的动态应用方面。大多数LLMs在涉及功利原则的情境中挣扎，往往过分强调其他原则。当前领先的是封闭源代码模型，这些模型凭借强大的通用能力处于领先地位。值得注意的是，医疗领域微调可以提升模型的整体伦理能力，但进一步的进步需要更好地与医学伦理知识相契合。PrinciplismQA提供了一个可扩展的框架来诊断这些特定的伦理弱点，为更加平衡和负责任的医疗AI铺平了道路。', 'title_zh': '从知识到实践评估医学伦理'}
{'arxiv_id': 'arXiv:2508.05128', 'title': 'Attention Basin: Why Contextual Position Matters in Large Language Models', 'authors': 'Zihao Yi, Delong Zeng, Zhenqing Ling, Haohao Luo, Zhe Xu, Wei Liu, Jian Luan, Wanxia Cao, Ying Shen', 'link': 'https://arxiv.org/abs/2508.05128', 'abstract': "The performance of Large Language Models (LLMs) is significantly sensitive to the contextual position of information in the input. To investigate the mechanism behind this positional bias, our extensive experiments reveal a consistent phenomenon we term the attention basin: when presented with a sequence of structured items (e.g., retrieved documents or few-shot examples), models systematically assign higher attention to the items at the beginning and end of the sequence, while neglecting those in the middle. Crucially, our analysis further reveals that allocating higher attention to critical information is key to enhancing model performance. Based on these insights, we introduce Attention-Driven Reranking (AttnRank), a two-stage framework that (i) estimates a model's intrinsic positional attention preferences using a small calibration set, and (ii) reorders retrieved documents or few-shot examples to align the most salient content with these high-attention positions. AttnRank is a model-agnostic, training-free, and plug-and-play method with minimal computational overhead. Experiments on multi-hop QA and few-shot in-context learning tasks demonstrate that AttnRank achieves substantial improvements across 10 large language models of varying architectures and scales, without modifying model parameters or training procedures.", 'abstract_zh': '大型语言模型的表现对其输入中信息的上下文位置高度敏感。为了探究这种位置偏见的机制，我们的 extensive 实验揭示了一个一致的现象，我们称之为注意力盆地：当提供一系列结构化项（如检索文档或少次示例）时，模型系统地对序列开头和结尾的项赋予更高的注意力，而忽视中间的项。关键的是，我们的分析进一步揭示了将更高注意力分配给关键信息是提升模型性能的关键。基于这些洞察，我们提出了基于注意力驱动的重排序（AttnRank）框架，该框架分为两个阶段：（i）使用一个小的校准集估计模型固有的位置注意力偏好，（ii）重新排序检索到的文档或少次示例，使其最具显著性的内容与这些高注意力位置对齐。AttnRank 是一种模型无关、无需训练、插即用的方法，具有最小的计算开销。实验表明，在多跳问答和少次上下文学习任务中，AttnRank 在 10 个不同架构和规模的大语言模型上实现了显著改进，而无需修改模型参数或训练流程。', 'title_zh': '注意力盆地：上下文位置为何在大规模语言模型中 Matters'}
{'arxiv_id': 'arXiv:2508.05123', 'title': 'Latent Expression Generation for Referring Image Segmentation and Grounding', 'authors': 'Seonghoon Yu, Joonbeom Hong, Joonseok Lee, Jeany Son', 'link': 'https://arxiv.org/abs/2508.05123', 'abstract': 'Visual grounding tasks, such as referring image segmentation (RIS) and referring expression comprehension (REC), aim to localize a target object based on a given textual description. The target object in an image can be described in multiple ways, reflecting diverse attributes such as color, position, and more. However, most existing methods rely on a single textual input, which captures only a fraction of the rich information available in the visual domain. This mismatch between rich visual details and sparse textual cues can lead to the misidentification of similar objects. To address this, we propose a novel visual grounding framework that leverages multiple latent expressions generated from a single textual input by incorporating complementary visual details absent from the original description. Specifically, we introduce subject distributor and visual concept injector modules to embed both shared-subject and distinct-attributes concepts into the latent representations, thereby capturing unique and target-specific visual cues. We also propose a positive-margin contrastive learning strategy to align all latent expressions with the original text while preserving subtle variations. Experimental results show that our method not only outperforms state-of-the-art RIS and REC approaches on multiple benchmarks but also achieves outstanding performance on the generalized referring expression segmentation (GRES) benchmark.', 'abstract_zh': '视觉定位任务，如引用图像分割（RIS）和引用表达理解（REC），旨在基于给定的文字描述定位目标对象。图像中的目标对象可以有多样的描述方式，反映其颜色、位置等多种属性。然而，现有大多数方法依赖单一的文字输入，这只能捕获视觉领域中丰富信息的一小部分。这种视觉细节丰富与文字提示稀疏之间的不匹配可能导致相似对象的误识别。为此，我们提出了一个新颖的视觉定位框架，通过结合单一文字输入生成的多个互补的潜在表达，利用缺失的视觉细节。具体地，我们引入了主题分配器和视觉概念注入模块，将共享主题和独特属性的概念嵌入到潜在表示中，从而捕捉独特的且针对目标的视觉线索。我们还提出了一种正边界对比学习策略，使所有潜在表达与原始文本对齐的同时保留细微差异。实验结果表明，我们的方法不仅在多个基准上优于现有的RIS和REC方法，还在泛化引用表达分割（GRES）基准上取得了优异的表现。', 'title_zh': '潜在表达生成用于引用图像分割和 grounding'}
{'arxiv_id': 'arXiv:2508.05118', 'title': 'Exploring Superior Function Calls via Reinforcement Learning', 'authors': 'Bingguang Hao, Maolin Wang, Zengzhuang Xu, Yicheng Chen, Cunyin Peng, Jinjie GU, Chenyi Zhuang', 'link': 'https://arxiv.org/abs/2508.05118', 'abstract': 'Function calling capabilities are crucial for deploying Large Language Models in real-world applications, yet current training approaches fail to develop robust reasoning strategies. Supervised fine-tuning produces models that rely on superficial pattern matching, while standard reinforcement learning methods struggle with the complex action space of structured function calls. We present a novel reinforcement learning framework designed to enhance group relative policy optimization through strategic entropy based exploration specifically tailored for function calling tasks. Our approach addresses three critical challenges in function calling: insufficient exploration during policy learning, lack of structured reasoning in chain-of-thought generation, and inadequate verification of parameter extraction. Our two-stage data preparation pipeline ensures high-quality training samples through iterative LLM evaluation and abstract syntax tree validation. Extensive experiments on the Berkeley Function Calling Leaderboard demonstrate that this framework achieves state-of-the-art performance among open-source models with 86.02\\% overall accuracy, outperforming standard GRPO by up to 6\\% on complex multi-function scenarios. Notably, our method shows particularly strong improvements on code-pretrained models, suggesting that structured language generation capabilities provide an advantageous starting point for reinforcement learning in function calling tasks. We will release all the code, models and dataset to benefit the community.', 'abstract_zh': '面向函数调用任务的新型增强学习框架：通过策略优化增强的策略熵导向探索', 'title_zh': '通过强化学习探索优越函数调用'}
{'arxiv_id': 'arXiv:2508.05102', 'title': 'Fairness in Dysarthric Speech Synthesis: Understanding Intrinsic Bias in Dysarthric Speech Cloning using F5-TTS', 'authors': 'Anuprabha M, Krishna Gurugubelli, Anil Kumar Vuppala', 'link': 'https://arxiv.org/abs/2508.05102', 'abstract': 'Dysarthric speech poses significant challenges in developing assistive technologies, primarily due to the limited availability of data. Recent advances in neural speech synthesis, especially zero-shot voice cloning, facilitate synthetic speech generation for data augmentation; however, they may introduce biases towards dysarthric speech. In this paper, we investigate the effectiveness of state-of-the-art F5-TTS in cloning dysarthric speech using TORGO dataset, focusing on intelligibility, speaker similarity, and prosody preservation. We also analyze potential biases using fairness metrics like Disparate Impact and Parity Difference to assess disparities across dysarthric severity levels. Results show that F5-TTS exhibits a strong bias toward speech intelligibility over speaker and prosody preservation in dysarthric speech synthesis. Insights from this study can help integrate fairness-aware dysarthric speech synthesis, fostering the advancement of more inclusive speech technologies.', 'abstract_zh': '言语障碍者的发音在开发辅助技术方面提出了重大挑战，主要原因是可用数据有限。近期神经语音合成技术的发展，尤其是零样本语音克隆技术，促进了合成语音生成以增加数据量；然而，这可能会导致对言语障碍者发音的偏见。本文我们利用TORGO数据集研究了最先进的F5-TTS在克隆言语障碍者发音方面的有效性，重点考察了可理解性、说话人相似性和语调保留。我们还使用公平性指标（如不对等影响和平等差异）分析潜在偏见，以评估不同言语障碍严重程度之间的差异。结果显示，F5-TTS在言语障碍者语音合成中表现出对可理解性的强烈偏见，而对说话人和语调保留不足。本研究的见解有助于实现公平意识下的言语障碍者语音合成，促进更具包容性的语音技术的发展。', 'title_zh': '言语失用语音合成中的公平性：基于F5-TTS理解言语失用克隆中的固有偏差'}
{'arxiv_id': 'arXiv:2508.05089', 'title': 'Integrated Influence: Data Attribution with Baseline', 'authors': 'Linxiao Yang, Xinyu Gu, Liang Sun', 'link': 'https://arxiv.org/abs/2508.05089', 'abstract': 'As an effective approach to quantify how training samples influence test sample, data attribution is crucial for understanding data and model and further enhance the transparency of machine learning models. We find that prevailing data attribution methods based on leave-one-out (LOO) strategy suffer from the local-based explanation, as these LOO-based methods only perturb a single training sample, and overlook the collective influence in the training set. On the other hand, the lack of baseline in many data attribution methods reduces the flexibility of the explanation, e.g., failing to provide counterfactual explanations. In this paper, we propose Integrated Influence, a novel data attribution method that incorporates a baseline approach. Our method defines a baseline dataset, follows a data degeneration process to transition the current dataset to the baseline, and accumulates the influence of each sample throughout this process. We provide a solid theoretical framework for our method, and further demonstrate that popular methods, such as influence functions, can be viewed as special cases of our approach. Experimental results show that Integrated Influence generates more reliable data attributions compared to existing methods in both data attribution task and mislablled example identification task.', 'abstract_zh': '作为一种有效的方法，用于量化训练样本对测试样本的影响，数据溯源对于理解数据和模型，并进一步提高机器学习模型的透明度至关重要。我们发现基于留一.out（LOO）策略的主流数据溯源方法存在局部解释的问题，因为这些基于LOO的方法仅扰动单个训练样本，而忽略了训练集中的集体影响。另一方面，许多数据溯源方法缺乏基线，降低了解释的灵活性，例如无法提供反事实解释。在本文中，我们提出了集成影响这一新颖的数据溯源方法，该方法结合了基线方法。我们的方法定义了一个基线数据集，在数据退化过程中将当前数据集过渡到基线，并在整个过程中累加每个样本的影响。我们为该方法提供了坚实的理论框架，并进一步证明了流行的技巧，如影响函数，可以被视为我们方法的特例。实验结果显示，与现有方法相比，集成影响在数据溯源任务和错标样例识别任务中生成了更可靠的數據归属。', 'title_zh': '综合影响：基于baseline的数据归因'}
{'arxiv_id': 'arXiv:2508.05087', 'title': 'JPS: Jailbreak Multimodal Large Language Models with Collaborative Visual Perturbation and Textual Steering', 'authors': 'Renmiao Chen, Shiyao Cui, Xuancheng Huang, Chengwei Pan, Victor Shea-Jay Huang, QingLin Zhang, Xuan Ouyang, Zhexin Zhang, Hongning Wang, Minlie Huang', 'link': 'https://arxiv.org/abs/2508.05087', 'abstract': 'Jailbreak attacks against multimodal large language Models (MLLMs) are a significant research focus. Current research predominantly focuses on maximizing attack success rate (ASR), often overlooking whether the generated responses actually fulfill the attacker\'s malicious intent. This oversight frequently leads to low-quality outputs that bypass safety filters but lack substantial harmful content. To address this gap, we propose JPS, \\underline{J}ailbreak MLLMs with collaborative visual \\underline{P}erturbation and textual \\underline{S}teering, which achieves jailbreaks via corporation of visual image and textually steering prompt. Specifically, JPS utilizes target-guided adversarial image perturbations for effective safety bypass, complemented by "steering prompt" optimized via a multi-agent system to specifically guide LLM responses fulfilling the attackers\' intent. These visual and textual components undergo iterative co-optimization for enhanced performance. To evaluate the quality of attack outcomes, we propose the Malicious Intent Fulfillment Rate (MIFR) metric, assessed using a Reasoning-LLM-based evaluator. Our experiments show JPS sets a new state-of-the-art in both ASR and MIFR across various MLLMs and benchmarks, with analyses confirming its efficacy. Codes are available at \\href{this https URL}{this https URL}. \\color{warningcolor}{Warning: This paper contains potentially sensitive contents.}', 'abstract_zh': '面向多模态大语言模型的协作型偷渡攻击及', 'title_zh': 'JPS: 使用协作视觉扰动和文本引导破解多模态大型语言模型'}
{'arxiv_id': 'arXiv:2508.05078', 'title': "Align, Don't Divide: Revisiting the LoRA Architecture in Multi-Task Learning", 'authors': 'Jinda Liu, Bo Cheng, Yi Chang, Yuan Wu', 'link': 'https://arxiv.org/abs/2508.05078', 'abstract': 'Parameter-Efficient Fine-Tuning (PEFT) is essential for adapting Large Language Models (LLMs). In practice, LLMs are often required to handle a diverse set of tasks from multiple domains, a scenario naturally addressed by multi-task learning (MTL). Within this MTL context, a prevailing trend involves LoRA variants with multiple adapters or heads, which advocate for structural diversity to capture task-specific knowledge. Our findings present a direct challenge to this paradigm. We first show that a simplified multi-head architecture with high inter-head similarity substantially outperforms complex multi-adapter and multi-head systems. This leads us to question the multi-component paradigm itself, and we further demonstrate that a standard single-adapter LoRA, with a sufficiently increased rank, also achieves highly competitive performance. These results lead us to a new hypothesis: effective MTL generalization hinges on learning robust shared representations, not isolating task-specific features. To validate this, we propose Align-LoRA, which incorporates an explicit loss to align task representations within the shared adapter space. Experiments confirm that Align-LoRA significantly surpasses all baselines, establishing a simpler yet more effective paradigm for adapting LLMs to multiple tasks. The code is available at this https URL.', 'abstract_zh': '参数高效微调（PEFT）是适应大规模语言模型（LLMs）的关键。在实践中，LLMs 经常需要处理多个领域的多种任务，这一场景自然可以通过多任务学习（MTL）来解决。在这一 MTL 上下文中，流行的趋势是使用具有多个适配器或头部的 LoRA 变体，提倡结构多样性以捕获任务特定的知识。我们的发现直接挑战了这一范式。我们首先展示了高头部相似性的简化多头架构在复杂多适配器和多头系统中表现明显更优。这促使我们质疑多组件范式本身，并进一步证明，一个标准的单适配器 LoRA，如果秩足够增加，也能获得极具竞争力的表现。这些结果促使我们形成一个新假设：有效的 MTL 一般化依赖于学习稳健的共享表示，而不是隔离任务特定特征。为了验证这一点，我们提出了 Align-LoRA，其中包含一个显式的损失以在共享适配器空间内对齐任务表示。实验表明，Align-LoRA 显著优于所有基线，确立了一个更简单且更有效的范式来适应 LLMs 至多个任务。代码可用于此 <https://>。', 'title_zh': '同调，不要分割：重新审视LoRA架构在多任务学习中的应用'}
{'arxiv_id': 'arXiv:2508.05074', 'title': 'Align-for-Fusion: Harmonizing Triple Preferences via Dual-oriented Diffusion for Cross-domain Sequential Recommendation', 'authors': 'Yongfu Zha, Xinxin Dong, Haokai Ma, Yonghui Yang, Xiaodong Wang', 'link': 'https://arxiv.org/abs/2508.05074', 'abstract': "Personalized sequential recommendation aims to predict appropriate items for users based on their behavioral sequences. To alleviate data sparsity and interest drift issues, conventional approaches typically incorporate auxiliary behaviors from other domains via cross-domain transition. However, existing cross-domain sequential recommendation (CDSR) methods often follow an align-then-fusion paradigm that performs representation-level alignment across multiple domains and combines them mechanically for recommendation, overlooking the fine-grained fusion of domain-specific preferences. Inspired by recent advances in diffusion models (DMs) for distribution matching, we propose an align-for-fusion framework for CDSR to harmonize triple preferences via dual-oriented DMs, termed HorizonRec. Specifically, we investigate the uncertainty injection of DMs and identify stochastic noise as a key source of instability in existing DM-based recommenders. To address this, we introduce a mixed-conditioned distribution retrieval strategy that leverages distributions retrieved from users' authentic behavioral logic as semantic bridges across domains, enabling consistent multi-domain preference modeling. Furthermore, we propose a dual-oriented preference diffusion method to suppress potential noise and emphasize target-relevant interests during multi-domain user representation fusion. Extensive experiments on four CDSR datasets from two distinct platforms demonstrate the effectiveness and robustness of HorizonRec in fine-grained triple-domain preference fusion.", 'abstract_zh': '个性化序列推荐旨在基于用户的行为序列预测合适的物品。为了缓解数据稀疏性和兴趣漂移问题，传统方法通常通过跨域转换从其他域引入辅助行为。然而，现有的跨域序列推荐方法往往遵循一种先对齐再融合的范式，在多个域之间进行表示级别的对齐，并机械地将它们结合起来进行推荐，忽略了特定于领域偏好的细粒度融合。受扩散模型在分布匹配方面 Recent 进展的启发，我们提出了一种跨域序列推荐的对齐即融合框架 HorizonRec，通过双导向扩散模型协调三重偏好。具体而言，我们研究了扩散模型中的不确定性注入，并将随机噪声识别为现有基于扩散模型推荐器中不稳定性的关键来源。为此，我们提出了一种混合条件分布检索策略，利用从用户真实行为逻辑中检索到的分布作为跨域的语义桥梁，实现一致的跨域偏好建模。此外，我们提出了双导向偏好扩散方法，在多域用户表示融合过程中抑制潜在的噪声并强调目标相关兴趣。在两个不同平台的四个跨域序列推荐数据集上的实验充分展示了 HorizonRec 在细粒度三域偏好融合中的有效性和鲁棒性。', 'title_zh': '面向融合的三元偏好调节：面向双导向扩散的跨域序列推荐'}
{'arxiv_id': 'arXiv:2508.05068', 'title': 'Automatic Image Colorization with Convolutional Neural Networks and Generative Adversarial Networks', 'authors': 'Ruiyu Li, Changyuan Qiu, Hangrui Cao, Qihan Ren, Yuqing Qiu', 'link': 'https://arxiv.org/abs/2508.05068', 'abstract': 'Image colorization, the task of adding colors to grayscale images, has been the focus of significant research efforts in computer vision in recent years for its various application areas such as color restoration and automatic animation colorization [15, 1]. The colorization problem is challenging as it is highly ill-posed with two out of three image dimensions lost, resulting in large degrees of freedom. However, semantics of the scene as well as the surface texture could provide important cues for colors: the sky is typically blue, the clouds are typically white and the grass is typically green, and there are huge amounts of training data available for learning such priors since any colored image could serve as a training data point [20].\nColorization is initially formulated as a regression task[5], which ignores the multi-modal nature of color prediction. In this project, we explore automatic image colorization via classification and adversarial learning. We will build our models on prior works, apply modifications for our specific scenario and make comparisons.', 'abstract_zh': '图像着色，即为灰度图像添加颜色的任务，近年来在计算机视觉领域受到了广泛关注，因其在颜色恢复和自动动画着色等各个应用领域的潜力[15, 1]。由于三个图像维度中有两个丢失，使得着色问题具有高度的不明确性，因此具有较大的自由度。然而，场景的语义以及表面纹理可以提供重要的颜色线索：天空通常是蓝色，云通常是白色，草地通常是绿色，而且有大量的训练数据可供学习这些先验知识，因为任何彩色图像都可以作为训练数据点[20]。\n\n着色最初被形式化为一个回归任务[5]，这忽略了颜色预测的多模态性质。在本项目中，我们将通过分类和对抗学习探索自动图像着色。我们将建立在先前工作之上，对特定场景进行修改，并进行比较。', 'title_zh': '基于卷积神经网络和生成对抗网络的自动图像着色'}
{'arxiv_id': 'arXiv:2508.05059', 'title': 'Learning from Oblivion: Predicting Knowledge Overflowed Weights via Retrodiction of Forgetting', 'authors': 'Jinhyeok Jang, Jaehong Kim, Jung Uk Kim', 'link': 'https://arxiv.org/abs/2508.05059', 'abstract': 'Pre-trained weights have become a cornerstone of modern deep learning, enabling efficient knowledge transfer and improving downstream task performance, especially in data-scarce scenarios. However, a fundamental question remains: how can we obtain better pre-trained weights that encapsulate more knowledge beyond the given dataset? In this work, we introduce \\textbf{KNowledge Overflowed Weights (KNOW)} prediction, a novel strategy that leverages structured forgetting and its inversion to synthesize knowledge-enriched weights. Our key insight is that sequential fine-tuning on progressively downsized datasets induces a structured forgetting process, which can be modeled and reversed to recover knowledge as if trained on a larger dataset. We construct a dataset of weight transitions governed by this controlled forgetting and employ meta-learning to model weight prediction effectively. Specifically, our \\textbf{KNowledge Overflowed Weights Nowcaster (KNOWN)} acts as a hyper-model that learns the general evolution of weights and predicts enhanced weights with improved generalization. Extensive experiments across diverse datasets and architectures demonstrate that KNOW prediction consistently outperforms Naïve fine-tuning and simple weight prediction, leading to superior downstream performance. Our work provides a new perspective on reinterpreting forgetting dynamics to push the limits of knowledge transfer in deep learning.', 'abstract_zh': '预训练权重已成为现代深度学习的基石，能够实现高效的知识迁移并提升下游任务性能，尤其是在数据稀缺场景中。然而，一个根本性的问题仍然存在：我们如何获得更能封装更多知识的预训练权重，而这些知识超越了给定的数据集？在本文中，我们介绍了\\textbf{知识溢出权重 (KNOW)} 预测这一新颖策略，该策略利用结构化遗忘及其逆过程来合成富含知识的权重。我们的核心见解是，逐步对逐渐缩小的数据集进行顺序微调会引发一种结构化遗忘过程，该过程可以被建模并逆向恢复，以仿若在更大数据集上训练的方式恢复知识。我们构建了一个由这种受控遗忘驱动的权重过渡数据集，并采用元学习来有效建模权重预测。具体来说，我们的\\textbf{知识溢出权重现在预测器 (KNOWN)} 作为超模型，学习权重的一般演化并预测具有更好泛化的增强权重。在多种数据集和架构上进行的大量实验表明，KNOW预测始终优于朴素微调和简单的权重预测，从而在下游任务性能上实现显著提升。我们的工作提供了一种重新诠释遗忘动态的新视角，以推动深度学习中知识迁移的极限。', 'title_zh': '从遗忘中学习：通过遗忘的反向预测来预测知识溢出权重'}
{'arxiv_id': 'arXiv:2508.05045', 'title': 'Human-AI Schema Discovery and Application for Creative Problem Solving', 'authors': 'Sitong Wang', 'link': 'https://arxiv.org/abs/2508.05045', 'abstract': 'Humans often rely on underlying structural patterns-schemas-to create, whether by writing stories, designing software, or composing music. Schemas help organize ideas and guide exploration, but they are often difficult to discover and apply, especially in complex or unfamiliar domains. My Ph.D. research develops a framework for human-AI schema discovery and application to support creative problem solving. I design systems that support users in sensemaking over examples to abstract schemas, and in operationalizing schemas into human-AI co-creative workflows for application. This research offers insights into how schema-guided interaction can make implicit knowledge more accessible and actionable, advancing more transparent and collaborative human-AI systems.', 'abstract_zh': '人类往往依赖于潜在的结构模式—模式——来创作，无论是在写作故事、设计软件还是作曲。模式有助于组织想法并引导探索，但它们往往难以发现和应用，特别是在复杂或不熟悉的领域。我的博士研究开发了一种人类-AI模式发现框架，以支持创造性问题解决。我设计了支持用户从例子中抽象模式并在人类-AI共同创意工作流程中实施模式的系统。这项研究提供了关于模式引导交互如何使隐性知识更加易于访问和采取行动的见解，从而推动了更加透明和协作的人机系统的发展。', 'title_zh': '人类-人工智能主题发现及在创造性问题解决中的应用'}
{'arxiv_id': 'arXiv:2508.05028', 'title': 'Evaluation of LLMs in AMR Parsing', 'authors': 'Shu Han Ho', 'link': 'https://arxiv.org/abs/2508.05028', 'abstract': 'Meaning Representation (AMR) is a semantic formalism that encodes sentence meaning as rooted, directed, acyclic graphs, where nodes represent concepts and edges denote semantic relations. Finetuning decoder only Large Language Models (LLMs) represent a promising novel straightfoward direction for AMR parsing. This paper presents a comprehensive evaluation of finetuning four distinct LLM architectures, Phi 3.5, Gemma 2, LLaMA 3.2, and DeepSeek R1 LLaMA Distilled using the LDC2020T02 Gold AMR3.0 test set. Our results have shown that straightfoward finetuning of decoder only LLMs can achieve comparable performance to complex State of the Art (SOTA) AMR parsers. Notably, LLaMA 3.2 demonstrates competitive performance against SOTA AMR parsers given a straightforward finetuning approach. We achieved SMATCH F1: 0.804 on the full LDC2020T02 test split, on par with APT + Silver (IBM) at 0.804 and approaching Graphene Smatch (MBSE) at 0.854. Across our analysis, we also observed a consistent pattern where LLaMA 3.2 leads in semantic performance while Phi 3.5 excels in structural validity.', 'abstract_zh': 'Meaning Representation (AMR)是一种将句子意义编码为有根、有向、无环图的语义正式语言，其中节点表示概念，边表示语义关系。微调解码器大型语言模型（LLMs）代表了AMR解析的一个有前途的新方向。本文对Phi 3.5、Gemma 2、LLaMA 3.2和DeepSeek R1 LLaMA Distilled四种不同的LLM架构进行了全面评估，使用LDC2020T02 Gold AMR3.0测试集。我们的结果显示，直接微调解码器大型语言模型可以达到与复杂最先进的（SOTA）AMR解析器相当的性能。值得注意的是，LLaMA 3.2在直接微调方法下表现出与SOTA AMR解析器竞争的性能。我们在LDC2020T02测试集的完整部分实现了SMATCH F1: 0.804，与APT + Silver（IBM）的0.804持平，并接近Graphene Smatch（MBSE）的0.854。在整个分析过程中，我们还观察到一种一致的趋势，即LLaMA 3.2在语义性能方面领先，而Phi 3.5在结构有效性方面表现出色。', 'title_zh': 'LLM们在AMR解析中的评估'}
{'arxiv_id': 'arXiv:2508.05023', 'title': 'Dialogues Aspect-based Sentiment Quadruple Extraction via Structural Entropy Minimization Partitioning', 'authors': 'Kun Peng, Cong Cao, Hao Peng, Zhifeng Hao, Lei Jiang, Kongjing Gu, Yanbing Liu, Philip S. Yu', 'link': 'https://arxiv.org/abs/2508.05023', 'abstract': 'Dialogues Aspect-based Sentiment Quadruple Extraction (DiaASQ) aims to extract all target-aspect-opinion-sentiment quadruples from a given multi-round, multi-participant dialogue. Existing methods typically learn word relations across entire dialogues, assuming a uniform distribution of sentiment elements. However, we find that dialogues often contain multiple semantically independent sub-dialogues without clear dependencies between them. Therefore, learning word relationships across the entire dialogue inevitably introduces additional noise into the extraction process. To address this, our method focuses on partitioning dialogues into semantically independent sub-dialogues. Achieving completeness while minimizing these sub-dialogues presents a significant challenge. Simply partitioning based on reply relationships is ineffective. Instead, we propose utilizing a structural entropy minimization algorithm to partition the dialogues. This approach aims to preserve relevant utterances while distinguishing irrelevant ones as much as possible. Furthermore, we introduce a two-step framework for quadruple extraction: first extracting individual sentiment elements at the utterance level, then matching quadruples at the sub-dialogue level. Extensive experiments demonstrate that our approach achieves state-of-the-art performance in DiaASQ with much lower computational costs.', 'abstract_zh': '基于对话的方面情感 quadruple 提取 (DiaASQ) 目标：从给定的多轮多参与对话中提取所有目标-方面-意见-情感 quadruple。', 'title_zh': '基于结构熵最小化分区的对话方面情感 quadruple 提取'}
{'arxiv_id': 'arXiv:2508.05019', 'title': 'Skin-SOAP: A Weakly Supervised Framework for Generating Structured SOAP Notes', 'authors': 'Sadia Kamal, Tim Oates, Joy Wan', 'link': 'https://arxiv.org/abs/2508.05019', 'abstract': 'Skin carcinoma is the most prevalent form of cancer globally, accounting for over $8 billion in annual healthcare expenditures. Early diagnosis, accurate and timely treatment are critical to improving patient survival rates. In clinical settings, physicians document patient visits using detailed SOAP (Subjective, Objective, Assessment, and Plan) notes. However, manually generating these notes is labor-intensive and contributes to clinician burnout. In this work, we propose skin-SOAP, a weakly supervised multimodal framework to generate clinically structured SOAP notes from limited inputs, including lesion images and sparse clinical text. Our approach reduces reliance on manual annotations, enabling scalable, clinically grounded documentation while alleviating clinician burden and reducing the need for large annotated data. Our method achieves performance comparable to GPT-4o, Claude, and DeepSeek Janus Pro across key clinical relevance metrics. To evaluate this clinical relevance, we introduce two novel metrics MedConceptEval and Clinical Coherence Score (CCS) which assess semantic alignment with expert medical concepts and input features, respectively.', 'abstract_zh': '皮肤恶性肿瘤是全球最常见的癌症形式，每年的医疗支出超过80亿美元。早期诊断、准确及时的治疗对提高患者生存率至关重要。在临床环境中，医生使用详细的SOAP（主观、客观、评估、计划）笔记记录患者访视情况。然而，手动生成这些笔记工作量大，会导致 clinicians 的职业倦怠。在本文中，我们提出了一种弱监督多模态框架 skin-SOAP，可以从有限输入（包括病变图像和稀疏临床文本）自动生成临床结构化的SOAP笔记。我们的方法减少了对手动标注的依赖，实现了规模化、基于临床的文档生成，同时减轻了 clinicians 的负担并减少了对大量标注数据的需要。我们的方法在关键临床相关性指标上达到了与GPT-4o、Claude和DeepSeek Janus Pro相当的性能。为了评估这一临床相关性，我们引入了两个新的评估指标：MedConceptEval 和临床连贯性得分（CCS），分别评估语义与专家医学概念和输入特征的一致性。', 'title_zh': 'Skin-SOAP：一种弱监督结构化SOAP笔记生成框架'}
{'arxiv_id': 'arXiv:2508.05015', 'title': 'SPaRFT: Self-Paced Reinforcement Fine-Tuning for Large Language Models', 'authors': 'Dai Do, Manh Nguyen, Svetha Venkatesh, Hung Le', 'link': 'https://arxiv.org/abs/2508.05015', 'abstract': 'Large language models (LLMs) have shown strong reasoning capabilities when fine-tuned with reinforcement learning (RL). However, such methods require extensive data and compute, making them impractical for smaller models. Current approaches to curriculum learning or data selection are largely heuristic-driven or demand extensive computational resources, limiting their scalability and generalizability. We propose \\textbf{SPaRFT}, a self-paced learning framework that enables efficient learning based on the capability of the model being trained through optimizing which data to use and when. First, we apply \\emph{cluster-based data reduction} to partition training data by semantics and difficulty, extracting a compact yet diverse subset that reduces redundancy. Then, a \\emph{multi-armed bandit} treats data clusters as arms, optimized to allocate training samples based on model current performance. Experiments across multiple reasoning benchmarks show that SPaRFT achieves comparable or better accuracy than state-of-the-art baselines while using up to \\(100\\times\\) fewer samples. Ablation studies and analyses further highlight the importance of both data clustering and adaptive selection. Our results demonstrate that carefully curated, performance-driven training curricula can unlock strong reasoning abilities in LLMs with minimal resources.', 'abstract_zh': '基于自适应学习的SPaRFT框架：高效提升大型语言模型的推理能力', 'title_zh': 'SPaRFT: 自适应强化微调方法用于大规模语言模型'}
{'arxiv_id': 'arXiv:2508.05012', 'title': 'Making Prompts First-Class Citizens for Adaptive LLM Pipelines', 'authors': 'Ugur Cetintemel, Shu Chen, Alexander W. Lee, Deepti Raghavan', 'link': 'https://arxiv.org/abs/2508.05012', 'abstract': 'Modern LLM pipelines increasingly resemble data-centric systems: they retrieve external context, compose intermediate outputs, validate results, and adapt based on runtime feedback. Yet, the central element guiding this process -- the prompt -- remains a brittle, opaque string, disconnected from the surrounding dataflow. This disconnect limits reuse, optimization, and runtime control.\nIn this paper, we describe our vision and an initial design for SPEAR, a language and runtime that fills this prompt management gap by making prompts structured, adaptive, and first-class components of the execution model. SPEAR enables (1) runtime prompt refinement -- modifying prompts dynamically in response to execution-time signals such as confidence, latency, or missing context; and (2) structured prompt management -- organizing prompt fragments into versioned views with support for introspection and logging.\nSPEAR defines a prompt algebra that governs how prompts are constructed and adapted within a pipeline. It supports multiple refinement modes (manual, assisted, and automatic), giving developers a balance between control and automation. By treating prompt logic as structured data, SPEAR enables optimizations such as operator fusion, prefix caching, and view reuse. Preliminary experiments quantify the behavior of different refinement modes compared to static prompts and agentic retries, as well as the impact of prompt-level optimizations such as operator fusion.', 'abstract_zh': '现代大模型管道 increasingly 类似于数据驱动系统：它们检索外部上下文、组成中间输出、验证结果并基于运行时反馈进行调整。然而，指导这一过程的核心元素——提示——仍然是一个脆弱且不透明的字符串，与周围的数据流脱节。这种脱节限制了提示的重用、优化和运行时控制。\n\n在本文中，我们阐述了SPEAR的愿景和初步设计，这是一种语言和运行时系统，通过使提示结构化、自适应并成为执行模型的一等组件来填补这一提示管理缺口。SPEAR使（1）运行时提示细化成为可能——动态响应于执行时信号（如置信度、延迟或缺失上下文）修改提示；以及（2）结构化的提示管理——将提示片段组织成带有内省和日志支持的版本视图。\n\nSPEAR定义了一种提示代数，规范了提示在管道中如何构建和调整。它支持多种细化模式（手动、辅助和自动），为开发人员提供了控制和自动化之间的平衡。通过将提示逻辑视为结构化数据，SPEAR使算子融合、前缀缓存和视图重用等优化成为可能。初步实验量化了不同细化模式的行为，与静态提示和主动重试相比，以及提示级别优化（如算子融合）的影响。', 'title_zh': '自动适应大型语言模型管道中的提示一等公民'}
{'arxiv_id': 'arXiv:2508.05011', 'title': 'Towards Hallucination-Free Music: A Reinforcement Learning Preference Optimization Framework for Reliable Song Generation', 'authors': 'Huaicheng Zhang, Wei Tan, Guangzheng Li, Yixuan Zhang, Hangting Chen, Shun Lei, Chenyu Yang, Zhiyong Wu, Shuai Wang, Qijun Huang, Dong Yu', 'link': 'https://arxiv.org/abs/2508.05011', 'abstract': "Recent advances in audio-based generative language models have accelerated AI-driven lyric-to-song generation. However, these models frequently suffer from content hallucination, producing outputs misaligned with the input lyrics and undermining musical coherence. Current supervised fine-tuning (SFT) approaches, limited by passive label-fitting, exhibit constrained self-improvement and poor hallucination mitigation. To address this core challenge, we propose a novel reinforcement learning (RL) framework leveraging preference optimization for hallucination control. Our key contributions include: (1) Developing a robust hallucination preference dataset constructed via phoneme error rate (PER) computation and rule-based filtering to capture alignment with human expectations; (2) Implementing and evaluating three distinct preference optimization strategies within the RL framework: Direct Preference Optimization (DPO), Proximal Policy Optimization (PPO), and Group Relative Policy Optimization (GRPO). DPO operates off-policy to enhance positive token likelihood, achieving a significant 7.4% PER reduction. PPO and GRPO employ an on-policy approach, training a PER-based reward model to iteratively optimize sequences via reward maximization and KL-regularization, yielding PER reductions of 4.9% and 4.7%, respectively. Comprehensive objective and subjective evaluations confirm that our methods effectively suppress hallucinations while preserving musical quality. Crucially, this work presents a systematic, RL-based solution to hallucination control in lyric-to-song generation. The framework's transferability also unlocks potential for music style adherence and musicality enhancement, opening new avenues for future generative song research.", 'abstract_zh': 'Recent Advances in Audio-Based Generative Language Models Have Accelerated AI-Driven Lyric-to-Song Generation: A Preference Optimization Approach via Reinforcement Learning for Controlling Content Hallucination', 'title_zh': '无幻听音乐生成：一种基于强化学习的偏好优化框架，用于可靠的歌曲生成'}
{'arxiv_id': 'arXiv:2508.05004', 'title': 'R-Zero: Self-Evolving Reasoning LLM from Zero Data', 'authors': 'Chengsong Huang, Wenhao Yu, Xiaoyang Wang, Hongming Zhang, Zongxia Li, Ruosen Li, Jiaxin Huang, Haitao Mi, Dong Yu', 'link': 'https://arxiv.org/abs/2508.05004', 'abstract': 'Self-evolving Large Language Models (LLMs) offer a scalable path toward super-intelligence by autonomously generating, refining, and learning from their own experiences. However, existing methods for training such models still rely heavily on vast human-curated tasks and labels, typically via fine-tuning or reinforcement learning, which poses a fundamental bottleneck to advancing AI systems toward capabilities beyond human intelligence. To overcome this limitation, we introduce R-Zero, a fully autonomous framework that generates its own training data from scratch. Starting from a single base LLM, R-Zero initializes two independent models with distinct roles, a Challenger and a Solver. These models are optimized separately and co-evolve through interaction: the Challenger is rewarded for proposing tasks near the edge of the Solver capability, and the Solver is rewarded for solving increasingly challenging tasks posed by the Challenger. This process yields a targeted, self-improving curriculum without any pre-existing tasks and labels. Empirically, R-Zero substantially improves reasoning capability across different backbone LLMs, e.g., boosting the Qwen3-4B-Base by +6.49 on math-reasoning benchmarks and +7.54 on general-domain reasoning benchmarks.', 'abstract_zh': '自我进化的大型语言模型（LLMs）通过自主生成、精炼和从自身经验中学习，提供了通往超级智能的可扩展路径。然而，现有方法仍高度依赖大量的人工标注任务和标签，通常是通过微调或强化学习来实现，这已成为推进AI系统超越人类智能能力的基本瓶颈。为克服这一限制，我们引入了R-Zero，这是一种完全自主的框架，从头开始生成自身的训练数据。从一个基础LLM开始，R-Zero 初始化两个独立的模型，分别承担挑战者和解题者两种角色。这两个模型分别优化，并通过交互共同进化：挑战者因提出接近解题者能力边界的任务而获得奖励，解题者因解决挑战者提出的一系列越来越具有挑战性的任务而获得奖励。这一过程生成了一个有针对性、自我改进的学习课程，无需任何预先存在的任务和标签。实验结果表明，R-Zero 显著提升了不同基础LLM 的推理能力，例如，将Qwen3-4B-Base 在数学推理基准上的性能提高了6.49分，在通用领域推理基准上的性能提高了7.54分。', 'title_zh': 'R-Zero: 从零数据自我进化推理大规模语言模型'}
{'arxiv_id': 'arXiv:2508.05003', 'title': 'A Multi-Stage Large Language Model Framework for Extracting Suicide-Related Social Determinants of Health', 'authors': 'Song Wang, Yishu Wei, Haotian Ma, Max Lovitt, Kelly Deng, Yuan Meng, Zihan Xu, Jingze Zhang, Yunyu Xiao, Ying Ding, Xuhai Xu, Joydeep Ghosh, Yifan Peng', 'link': 'https://arxiv.org/abs/2508.05003', 'abstract': "Background: Understanding social determinants of health (SDoH) factors contributing to suicide incidents is crucial for early intervention and prevention. However, data-driven approaches to this goal face challenges such as long-tailed factor distributions, analyzing pivotal stressors preceding suicide incidents, and limited model explainability. Methods: We present a multi-stage large language model framework to enhance SDoH factor extraction from unstructured text. Our approach was compared to other state-of-the-art language models (i.e., pre-trained BioBERT and GPT-3.5-turbo) and reasoning models (i.e., DeepSeek-R1). We also evaluated how the model's explanations help people annotate SDoH factors more quickly and accurately. The analysis included both automated comparisons and a pilot user study. Results: We show that our proposed framework demonstrated performance boosts in the overarching task of extracting SDoH factors and in the finer-grained tasks of retrieving relevant context. Additionally, we show that fine-tuning a smaller, task-specific model achieves comparable or better performance with reduced inference costs. The multi-stage design not only enhances extraction but also provides intermediate explanations, improving model explainability. Conclusions: Our approach improves both the accuracy and transparency of extracting suicide-related SDoH from unstructured texts. These advancements have the potential to support early identification of individuals at risk and inform more effective prevention strategies.", 'abstract_zh': '背景:理解社会决定健康健康（社会决定因素）对自杀事件的影响对于早期干预和预防至关重要 giảng解释翻译为理解社会决定因素对 对自杀事件的影响对于早期干预和预防至关重要 nâussed\nuser\n Background: Understanding social determinants of health (S Đường) that contribute to suicide incidents is crucial for early intervention and prevention. Mentioning data唬限制了翻译，禁止翻译中 包含G 字符，请重试 nâ\n-user\n背景: � 了解社会决定因素（S Mounted）对自杀事件的影响是进行早期干预和预防的关键-ves\n-user\n背景: 了解社会决定因素（S Mounted）对自杀事件的影响是进行早期干预和预防的关键。', 'title_zh': '多阶段大型语言模型框架用于提取与自杀相关的社会决定因素'}
{'arxiv_id': 'arXiv:2508.05002', 'title': 'AgenticData: An Agentic Data Analytics System for Heterogeneous Data', 'authors': 'Ji Sun, Guoliang Li, Peiyao Zhou, Yihui Ma, Jingzhe Xu, Yuan Li', 'link': 'https://arxiv.org/abs/2508.05002', 'abstract': 'Existing unstructured data analytics systems rely on experts to write code and manage complex analysis workflows, making them both expensive and time-consuming. To address these challenges, we introduce AgenticData, an innovative agentic data analytics system that allows users to simply pose natural language (NL) questions while autonomously analyzing data sources across multiple domains, including both unstructured and structured data. First, AgenticData employs a feedback-driven planning technique that automatically converts an NL query into a semantic plan composed of relational and semantic operators. We propose a multi-agent collaboration strategy by utilizing a data profiling agent for discovering relevant data, a semantic cross-validation agent for iterative optimization based on feedback, and a smart memory agent for maintaining short-term context and long-term knowledge. Second, we propose a semantic optimization model to refine and execute semantic plans effectively. Our system, AgenticData, has been tested using three benchmarks. Experimental results showed that AgenticData achieved superior accuracy on both easy and difficult tasks, significantly outperforming state-of-the-art methods.', 'abstract_zh': '现有的非结构化数据分析系统依赖专家编写代码并管理复杂的分析工作流，这既昂贵又耗时。为了解决这些问题，我们引入了AgenticData，这是一种创新的代理数据分析系统，允许用户仅以自然语言提出问题，同时自主分析跨多个领域（包括非结构化和结构化数据）的数据源。首先，AgenticData 使用一种基于反馈的规划技术，自动将自然语言查询转换为包含关系和语义操作符的语义计划。我们提出了一个多代理协作策略，通过利用数据探查代理发现相关数据、语义交叉验证代理根据反馈进行迭代优化，以及智能记忆代理维护短期上下文和长期知识。其次，我们提出了一种语义优化模型以有效细化和执行语义计划。在使用三个基准进行了系统测试后，实验结果显示，AgenticData 在简单和复杂任务上的准确性均 superior，显著优于现有最先进的方法。', 'title_zh': 'AgenticData：一种异构数据分析代理系统'}
{'arxiv_id': 'arXiv:2508.04995', 'title': 'Situated Epistemic Infrastructures: A Diagnostic Framework for Post-Coherence Knowledge', 'authors': 'Matthew Kelly', 'link': 'https://arxiv.org/abs/2508.04995', 'abstract': 'Large Language Models (LLMs) such as ChatGPT have rendered visible the fragility of contemporary knowledge infrastructures by simulating coherence while bypassing traditional modes of citation, authority, and validation. This paper introduces the Situated Epistemic Infrastructures (SEI) framework as a diagnostic tool for analyzing how knowledge becomes authoritative across hybrid human-machine systems under post-coherence conditions. Rather than relying on stable scholarly domains or bounded communities of practice, SEI traces how credibility is mediated across institutional, computational, and temporal arrangements. Integrating insights from infrastructure studies, platform theory, and epistemology, the framework foregrounds coordination over classification, emphasizing the need for anticipatory and adaptive models of epistemic stewardship. The paper contributes to debates on AI governance, knowledge production, and the ethical design of information systems by offering a robust alternative to representationalist models of scholarly communication.', 'abstract_zh': '大型语言模型（LLMs）如ChatGPT揭示了当代知识基础设施的脆弱性，通过模拟连贯性而绕过了传统的引用、权威和验证模式。本文引入了位处情境的知识基础设施（SEI）框架，作为一种诊断工具，用于分析在后连贯条件下，知识在混合的人机系统中如何获得权威性。SEI框架不依赖稳定的学术领域或限定的实践社区，而是追踪可信度如何在制度、计算和时间的安排中被中介。该框架结合了基础设施研究、平台理论和认识论的见解，将协调置于分类之前，强调对预见性和适应性知识管理模型的需求。本文通过对AI治理、知识生产和信息系统的伦理设计的讨论，提供了代表主义模型的 robust 替代方案。', 'title_zh': '置身于知识基础设施：后共融知识的诊断框架'}
{'arxiv_id': 'arXiv:2508.04994', 'title': 'Hierarchical Deep Deterministic Policy Gradient for Autonomous Maze Navigation of Mobile Robots', 'authors': 'Wenjie Hu, Ye Zhou, Hann Woei Ho', 'link': 'https://arxiv.org/abs/2508.04994', 'abstract': 'Maze navigation is a fundamental challenge in robotics, requiring agents to traverse complex environments efficiently. While the Deep Deterministic Policy Gradient (DDPG) algorithm excels in control tasks, its performance in maze navigation suffers from sparse rewards, inefficient exploration, and long-horizon planning difficulties, often leading to low success rates and average rewards, sometimes even failing to achieve effective navigation. To address these limitations, this paper proposes an efficient Hierarchical DDPG (HDDPG) algorithm, which includes high-level and low-level policies. The high-level policy employs an advanced DDPG framework to generate intermediate subgoals from a long-term perspective and on a higher temporal scale. The low-level policy, also powered by the improved DDPG algorithm, generates primitive actions by observing current states and following the subgoal assigned by the high-level policy. The proposed method enhances stability with off-policy correction, refining subgoal assignments by relabeling historical experiences. Additionally, adaptive parameter space noise is utilized to improve exploration, and a reshaped intrinsic-extrinsic reward function is employed to boost learning efficiency. Further optimizations, including gradient clipping and Xavier initialization, are employed to improve robustness. The proposed algorithm is rigorously evaluated through numerical simulation experiments executed using the Robot Operating System (ROS) and Gazebo. Regarding the three distinct final targets in autonomous maze navigation tasks, HDDPG significantly overcomes the limitations of standard DDPG and its variants, improving the success rate by at least 56.59% and boosting the average reward by a minimum of 519.03 compared to baseline algorithms.', 'abstract_zh': '迷宫导航是机器人研究中的一个基本挑战，要求智能体高效地穿越复杂环境。尽管深度确定性策略梯度（DDPG）算法在控制任务中表现出色，但在迷宫导航任务中，由于稀疏奖励、探索效率低以及长时依赖规划困难，其性能往往较差，导致成功率低、平均奖励低，甚至无法有效导航。为了解决这些问题，本文提出了一种高效的层次化DDPG（HDDPG）算法，该算法包括高一级和低一级的策略。高一级策略采用先进的DDPG框架，从长期视角和更高的时间尺度生成中间子目标。低一级策略由改进的DDPG算法驱动，通过观察当前状态并遵循高一级策略分配的子目标，生成原始动作。所提出的方法通过离策策略校正增强稳定性，通过重新标记历史经验细化子目标分配。此外，利用自适应参数空间噪声提高探索效率，并采用重塑的内在-外在奖励函数增强学习效率。进一步优化包括梯度裁剪和Xavier初始化，提高鲁棒性。通过使用Robot Operating System (ROS)和Gazebo执行的数值仿真实验，对自主迷宫导航任务中的三个不同最终目标进行了严格评估。结果表明，HDDPG显著克服了标准DDPG及其变体的局限性，与基准算法相比，成功率为至少56.59%的提升，平均奖励提高了至少519.03。', 'title_zh': '基于层次化深度确定性策略 gradients 的自主迷宫导航移动机器人算法'}
{'arxiv_id': 'arXiv:2508.04968', 'title': 'UGOD: Uncertainty-Guided Differentiable Opacity and Soft Dropout for Enhanced Sparse-View 3DGS', 'authors': 'Zhihao Guo, Peng Wang, Zidong Chen, Xiangyu Kong, Yan Lyu, Guanyu Gao, Liangxiu Han', 'link': 'https://arxiv.org/abs/2508.04968', 'abstract': '3D Gaussian Splatting (3DGS) has become a competitive approach for novel view synthesis (NVS) due to its advanced rendering efficiency through 3D Gaussian projection and blending. However, Gaussians are treated equally weighted for rendering in most 3DGS methods, making them prone to overfitting, which is particularly the case in sparse-view scenarios. To address this, we investigate how adaptive weighting of Gaussians affects rendering quality, which is characterised by learned uncertainties proposed. This learned uncertainty serves two key purposes: first, it guides the differentiable update of Gaussian opacity while preserving the 3DGS pipeline integrity; second, the uncertainty undergoes soft differentiable dropout regularisation, which strategically transforms the original uncertainty into continuous drop probabilities that govern the final Gaussian projection and blending process for rendering. Extensive experimental results over widely adopted datasets demonstrate that our method outperforms rivals in sparse-view 3D synthesis, achieving higher quality reconstruction with fewer Gaussians in most datasets compared to existing sparse-view approaches, e.g., compared to DropGaussian, our method achieves 3.27\\% PSNR improvements on the MipNeRF 360 dataset.', 'abstract_zh': '33高斯聚类（（33 33 Η e �.e ） 在 e e e 用于密集视 e e e 渲晰的 e e e 三维合成 e e e 由于三维高 e e e 高 e e e 高 e e e 高 e e e 高 Η e e e e e e  e e � e e  e e e e e e e e  e e e  e e  e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e=e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e= e e e e e e e e e e � e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e[e pérdida d predic e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e]\r\n三维高 e e e � e e e � e e e � e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e.MSGD e PSGR 提 e 3 e e e e e e e e e e e e e e e e e e e e PSNR 提 e e e 3  e e e e e e e e  e e e e e e e e e e e e e e e e 3 e e e e e e e 3 e e e e e e e e  e e e  e e e  e e e  e e e  e e e  e e e  e e  e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e 3 e  e e 3 e e e e e e e e ect G e  e 3 e e e e e e e e  e e  e  e e e e e e e  e e e  e e  e  e e e e e e e  e e e  e e e e e e e e e e  e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e. e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e eภาวะ KD', 'title_zh': 'UGOD：基于不确定性引导的可微透明度和软dropout的稀薄投影三维图像增强方法'}
{'arxiv_id': 'arXiv:2508.04956', 'title': 'MENDR: Manifold Explainable Neural Data Representations', 'authors': 'Matthew Chen, Micky Nnamdi, Justin Shao, Andrew Hornback, Hongyun Huang, Ben Tamo, Yishan Zhong, Benoit Marteau, Wenqi Shi, May Dongmei Wang', 'link': 'https://arxiv.org/abs/2508.04956', 'abstract': 'Foundation models for electroencephalography (EEG) signals have recently demonstrated success in learning generalized representations of EEGs, outperforming specialized models in various downstream tasks. However, many of these models lack transparency in their pretraining dynamics and offer limited insight into how well EEG information is preserved within their embeddings. For successful clinical integration, EEG foundation models must ensure transparency in pretraining, downstream fine-tuning, and the interpretability of learned representations. Current approaches primarily operate in the temporal domain, overlooking advancements in digital signal processing that enable the extraction of deterministic and traceable features, such as wavelet-based representations. We propose MENDR (Manifold Explainable Neural Data Representations), a filter bank-based EEG foundation model built on a novel Riemannian Manifold Transformer architecture to resolve these issues. MENDR learns symmetric positive definite matrix embeddings of EEG signals and is pretrained on a large corpus comprising over 4,000 hours of EEG data, decomposed via discrete wavelet packet transforms into multi-resolution coefficients. MENDR significantly enhances interpretability by visualizing symmetric positive definite embeddings as geometric ellipsoids and supports accurate reconstruction of EEG signals from learned embeddings. Evaluations across multiple clinical EEG tasks demonstrate that MENDR achieves near state-of-the-art performance with substantially fewer parameters, underscoring its potential for efficient, interpretable, and clinically applicable EEG analysis.', 'abstract_zh': '基于透彻性神经数据表示的滤波器组脑电基础模型（MENDR）', 'title_zh': 'MENDR：流形可解释神经数据表示'}
{'arxiv_id': 'arXiv:2508.04955', 'title': 'AdvDINO: Domain-Adversarial Self-Supervised Representation Learning for Spatial Proteomics', 'authors': 'Stella Su, Marc Harary, Scott J. Rodig, William Lotter', 'link': 'https://arxiv.org/abs/2508.04955', 'abstract': 'Self-supervised learning (SSL) has emerged as a powerful approach for learning visual representations without manual annotations. However, the robustness of standard SSL methods to domain shift -- systematic differences across data sources -- remains uncertain, posing an especially critical challenge in biomedical imaging where batch effects can obscure true biological signals. We present AdvDINO, a domain-adversarial self-supervised learning framework that integrates a gradient reversal layer into the DINOv2 architecture to promote domain-invariant feature learning. Applied to a real-world cohort of six-channel multiplex immunofluorescence (mIF) whole slide images from non-small cell lung cancer patients, AdvDINO mitigates slide-specific biases to learn more robust and biologically meaningful representations than non-adversarial baselines. Across $>5.46$ million mIF image tiles, the model uncovers phenotype clusters with distinct proteomic profiles and prognostic significance, and improves survival prediction in attention-based multiple instance learning. While demonstrated on mIF data, AdvDINO is broadly applicable to other imaging domains -- including radiology, remote sensing, and autonomous driving -- where domain shift and limited annotated data hinder model generalization and interpretability.', 'abstract_zh': '自监督学习（SSL）已成为无需手动标注学习视觉表示的强大方法。然而，标准SSL方法对领域变换（领域间系统性差异）的鲁棒性仍不确定，在涉及批次效应可能掩盖真正生物信号的生物医学成像领域，这是一个尤其关键的挑战。我们提出AdvDINO，这是一种领域对抗自监督学习框架，将梯度反转层整合到DINOv2架构中，以促进领域不变特征的学习。应用于非小细胞肺癌患者六通道多重免疫荧光（mIF）全切片成像的真实世界队列数据，AdvDINO减轻了切片特异性偏差，获得了比非对抗基线更稳健且生物学上有意义的表示。在超过546万张mIF图像块中，该模型揭示了具有独特蛋白质组学特征和预后意义的表型簇，并在基于注意力的多重实例学习中提高了生存预测能力。虽然AdvDINO在mIF数据上进行了演示，但该方法广泛适用于其他成像领域——包括放射学、遥感和自动驾驶——这些领域中的领域变换和有限的标注数据阻碍了模型的泛化能力和可解释性。', 'title_zh': 'AdvDINO：领域对抗自监督表示学习在空间蛋白质组学中的应用'}
{'arxiv_id': 'arXiv:2508.04953', 'title': 'Tesserae: Scalable Placement Policies for Deep Learning Workloads', 'authors': 'Song Bian, Saurabh Agarwal, Md. Tareq Mahmood, Shivaram Venkataraman', 'link': 'https://arxiv.org/abs/2508.04953', 'abstract': 'Training deep learning (DL) models has become a dominant workload in data-centers and improving resource utilization is a key goal of DL cluster schedulers. In order to do this, schedulers typically incorporate placement policies that govern where jobs are placed on the cluster. Existing placement policies are either designed as ad-hoc heuristics or incorporated as constraints within a complex optimization problem and thus either suffer from suboptimal performance or poor scalability. Our key insight is that many placement constraints can be formulated as graph matching problems and based on that we design novel placement policies for minimizing job migration overheads and job packing. We integrate these policies into Tesserae and describe how our design leads to a scalable and effective GPU cluster scheduler. Our experimental results show that Tesserae improves average JCT by up to 1.62x and the Makespan by up to 1.15x compared with the existing schedulers.', 'abstract_zh': '深度学习模型的训练已成为数据中心的主要工作负载，提高资源利用率是深度学习集群调度器的关键目标。为了实现这一目标，调度器通常会采用控制作业在集群中放置的放置策略。现有放置策略要么被设计为经验主义的启发式方法，要么被纳入复杂的优化问题中作为约束，从而导致性能欠佳或扩展性差的问题。我们的核心见解是，许多放置约束可以被表述为图匹配问题，并基于此设计了新的放置策略来最小化作业迁移开销和作业打包。我们将这些策略集成到Tesserae中，并描述了我们的设计如何导致一种可扩展且有效的GPU集群调度器。实验结果显示，与现有调度器相比，Tesserae将平均作业周转时间（JCT）改善了1.62倍，将工期 （Makespan）改善了1.15倍。', 'title_zh': 'Tesserae: 深度学习工作负载的可扩展放置策略'}
{'arxiv_id': 'arXiv:2508.04945', 'title': 'Towards Robust Evaluation of Visual Activity Recognition: Resolving Verb Ambiguity with Sense Clustering', 'authors': 'Louie Hong Yao, Nicholas Jarvis, Tianyu Jiang', 'link': 'https://arxiv.org/abs/2508.04945', 'abstract': 'Evaluating visual activity recognition systems is challenging due to inherent ambiguities in verb semantics and image interpretation. When describing actions in images, synonymous verbs can refer to the same event (e.g., brushing vs. grooming), while different perspectives can lead to equally valid but distinct verb choices (e.g., piloting vs. operating). Standard exact-match evaluation, which relies on a single gold answer, fails to capture these ambiguities, resulting in an incomplete assessment of model performance. To address this, we propose a vision-language clustering framework that constructs verb sense clusters, providing a more robust evaluation. Our analysis of the imSitu dataset shows that each image maps to an average of 2.8 sense clusters, with each cluster representing a distinct perspective of the image. We evaluate multiple activity recognition models and compare our cluster-based evaluation with standard evaluation methods. Additionally, our human alignment analysis suggests that the cluster-based evaluation better aligns with human judgements, offering a more nuanced assessment of model performance.', 'abstract_zh': '评估视觉活动识别系统具有挑战性，因为动词语义和图像解释中存在的内在歧义。在描述图像中的动作时，同义动词可以指同一个事件（例如，刷 vs. 梳理），而不同的视角会导致不同的但同样合理的动词选择（例如，驾驶 vs. 操作）。依赖单一标准答案的标准精确匹配评估无法捕捉这些歧义，导致对模型性能的评估不完整。为解决这一问题，我们提出了一种视觉-语言聚类框架，构建动词意义簇，提供更稳健的评估。通过对imSitu数据集的分析，我们发现每张图像平均映射到2.8个意义簇，每个簇代表图像的一种不同视角。我们评估了多种活动识别模型，并将基于簇的评估与标准评估方法进行了比较。此外，我们的手动对齐分析表明，基于簇的评估与人类判断更一致，提供了对模型性能更细致的评估。', 'title_zh': '基于语义聚类解决动词歧义的视觉活动识别鲁棒评估方法'}
{'arxiv_id': 'arXiv:2508.04943', 'title': 'TRKT: Weakly Supervised Dynamic Scene Graph Generation with Temporal-enhanced Relation-aware Knowledge Transferring', 'authors': 'Zhu Xu, Ting Lei, Zhimin Li, Guan Wang, Qingchao Chen, Yuxin Peng, Yang liu', 'link': 'https://arxiv.org/abs/2508.04943', 'abstract': 'Dynamic Scene Graph Generation (DSGG) aims to create a scene graph for each video frame by detecting objects and predicting their relationships. Weakly Supervised DSGG (WS-DSGG) reduces annotation workload by using an unlocalized scene graph from a single frame per video for training. Existing WS-DSGG methods depend on an off-the-shelf external object detector to generate pseudo labels for subsequent DSGG training. However, detectors trained on static, object-centric images struggle in dynamic, relation-aware scenarios required for DSGG, leading to inaccurate localization and low-confidence proposals. To address the challenges posed by external object detectors in WS-DSGG, we propose a Temporal-enhanced Relation-aware Knowledge Transferring (TRKT) method, which leverages knowledge to enhance detection in relation-aware dynamic scenarios. TRKT is built on two key components:(1)Relation-aware knowledge mining: we first employ object and relation class decoders that generate category-specific attention maps to highlight both object regions and interactive areas. Then we propose an Inter-frame Attention Augmentation strategy that exploits optical flow for neighboring frames to enhance the attention maps, making them motion-aware and robust to motion blur. This step yields relation- and motion-aware knowledge mining for WS-DSGG. (2) we introduce a Dual-stream Fusion Module that integrates category-specific attention maps into external detections to refine object localization and boost confidence scores for object proposals. Extensive experiments demonstrate that TRKT achieves state-of-the-art performance on Action Genome dataset. Our code is avaliable at this https URL.', 'abstract_zh': '动态场景图生成（DSGG）旨在通过检测物体并通过预测它们之间的关系为每个视频帧创建场景图。弱监督DSGG（WS-DSGG）通过使用单个视频帧中的非局部化场景图来减少标注工作量进行训练。现有的WS-DSGG方法依赖于现成的外部物体检测器为后续的DSGG训练生成伪标签。然而，这些检测器在DSGG所需的动态、关系感知场景中表现不佳，导致定位不准确且置信度低。为了解决外部物体检测器在WS-DSGG中带来的挑战，我们提出了一种基于时间增强的关系感知知识转移（TRKT）方法，该方法利用知识来增强关系感知的动态场景中的检测。TRKT包括两个关键组件：（1）关系感知知识挖掘：首先使用对象类和关系类解码器生成具有类别特定关注图，以突出显示对象区域和交互区域。然后提出了一种基于相邻帧的时移注意力增强策略，利用光流增强注意图，使它们具有运动感知力并能抵抗运动模糊。这一步骤为WS-DSGG提供了关系和运动感知的知识挖掘。（2）引入了一种双流融合模块，将类别特定注意力图集成到外部检测中，以细化物体定位并提升物体候选的置信分数。广泛的实验表明，TRKT在Action Genome数据集上达到了最先进的性能。我们的代码可在以下链接获取。', 'title_zh': 'TRKT：带有时间增强关系感知知识转移的弱监督动态场景图生成'}
{'arxiv_id': 'arXiv:2508.04931', 'title': 'INTENTION: Inferring Tendencies of Humanoid Robot Motion Through Interactive Intuition and Grounded VLM', 'authors': 'Jin Wang, Weijie Wang, Boyuan Deng, Heng Zhang, Rui Dai, Nikos Tsagarakis', 'link': 'https://arxiv.org/abs/2508.04931', 'abstract': 'Traditional control and planning for robotic manipulation heavily rely on precise physical models and predefined action sequences. While effective in structured environments, such approaches often fail in real-world scenarios due to modeling inaccuracies and struggle to generalize to novel tasks. In contrast, humans intuitively interact with their surroundings, demonstrating remarkable adaptability, making efficient decisions through implicit physical understanding. In this work, we propose INTENTION, a novel framework enabling robots with learned interactive intuition and autonomous manipulation in diverse scenarios, by integrating Vision-Language Models (VLMs) based scene reasoning with interaction-driven memory. We introduce Memory Graph to record scenes from previous task interactions which embodies human-like understanding and decision-making about different tasks in real world. Meanwhile, we design an Intuitive Perceptor that extracts physical relations and affordances from visual scenes. Together, these components empower robots to infer appropriate interaction behaviors in new scenes without relying on repetitive instructions. Videos: this https URL', 'abstract_zh': '基于视觉语言模型的交互直觉与自主 manipulation 研究：INTENTION框架', 'title_zh': '意图：通过交互直觉和接地多模态语言模型推断类人机器人运动趋势'}
{'arxiv_id': 'arXiv:2508.04928', 'title': 'Extending Foundational Monocular Depth Estimators to Fisheye Cameras with Calibration Tokens', 'authors': 'Suchisrit Gangopadhyay, Jung-Hee Kim, Xien Chen, Patrick Rim, Hyoungseob Park, Alex Wong', 'link': 'https://arxiv.org/abs/2508.04928', 'abstract': 'We propose a method to extend foundational monocular depth estimators (FMDEs), trained on perspective images, to fisheye images. Despite being trained on tens of millions of images, FMDEs are susceptible to the covariate shift introduced by changes in camera calibration (intrinsic, distortion) parameters, leading to erroneous depth estimates. Our method aligns the distribution of latent embeddings encoding fisheye images to those of perspective images, enabling the reuse of FMDEs for fisheye cameras without retraining or finetuning. To this end, we introduce a set of Calibration Tokens as a light-weight adaptation mechanism that modulates the latent embeddings for alignment. By exploiting the already expressive latent space of FMDEs, we posit that modulating their embeddings avoids the negative impact of artifacts and loss introduced in conventional recalibration or map projection to a canonical reference frame in the image space. Our method is self-supervised and does not require fisheye images but leverages publicly available large-scale perspective image datasets. This is done by recalibrating perspective images to fisheye images, and enforcing consistency between their estimates during training. We evaluate our approach with several FMDEs, on both indoors and outdoors, where we consistently improve over state-of-the-art methods using a single set of tokens for both. Code available at: this https URL.', 'abstract_zh': '我们提出了一种方法，将基于视角图像训练的基线单目深度估计器（FMDEs）扩展到鱼眼图像。尽管FMDEs是在数千万张图像上进行训练的，但它们仍然容易受到由相机标定（固有参数和畸变）变化引入的 covariate shift 的影响，导致错误的深度估计。我们的方法通过将鱼眼图像的潜在嵌入分布调整到视角图像的分布，使得不需要重新训练或微调即可在鱼眼相机上重用FMDEs。为此，我们引入了一组校准标记作为轻量级的适应机制，用于调整潜在嵌入以实现对齐。通过利用FMDEs已有的表达性潜在空间，我们认为调节其嵌入可以避免常规重新标定或将图像空间映射到标准参考框架中引入的负影响。我们的方法是自监督的，不需要鱼眼图像，而是利用公开可用的大规模视角图像数据集。这通过将视角图像重新标定为鱼眼图像，并在训练过程中强制估计之间的一致性来实现。我们使用一组标记在室内和室外场景中评估了我们的方法，结果表明这种方法在使用单组标记时优于现有方法。代码可在以下链接获取：this https URL。', 'title_zh': '基于校准标记扩展单目深度估计模型以适应鱼眼相机'}
{'arxiv_id': 'arXiv:2508.04925', 'title': 'Taxonomy of Faults in Attention-Based Neural Networks', 'authors': 'Sigma Jahan, Saurabh Singh Rajput, Tushar Sharma, Mohammad Masudur Rahman', 'link': 'https://arxiv.org/abs/2508.04925', 'abstract': "Attention mechanisms are at the core of modern neural architectures, powering systems ranging from ChatGPT to autonomous vehicles and driving a major economic impact. However, high-profile failures, such as ChatGPT's nonsensical outputs or Google's suspension of Gemini's image generation due to attention weight errors, highlight a critical gap: existing deep learning fault taxonomies might not adequately capture the unique failures introduced by attention mechanisms. This gap leaves practitioners without actionable diagnostic guidance. To address this gap, we present the first comprehensive empirical study of faults in attention-based neural networks (ABNNs). Our work is based on a systematic analysis of 555 real-world faults collected from 96 projects across ten frameworks, including GitHub, Hugging Face, and Stack Overflow. Through our analysis, we develop a novel taxonomy comprising seven attention-specific fault categories, not captured by existing work. Our results show that over half of the ABNN faults arise from mechanisms unique to attention architectures. We further analyze the root causes and manifestations of these faults through various symptoms. Finally, by analyzing symptom-root cause associations, we identify four evidence-based diagnostic heuristics that explain 33.0% of attention-specific faults, offering the first systematic diagnostic guidance for attention-based models.", 'abstract_zh': '基于注意力机制的神经网络故障综合实证研究：揭示独特故障分类与诊断指导', 'title_zh': '基于注意力机制的神经网络中的故障分类'}
{'arxiv_id': 'arXiv:2508.04903', 'title': 'RCR-Router: Efficient Role-Aware Context Routing for Multi-Agent LLM Systems with Structured Memory', 'authors': 'Jun Liu, Zhenglun Kong, Changdi Yang, Fan Yang, Tianqi Li, Peiyan Dong, Joannah Nanjekye, Hao Tang, Geng Yuan, Wei Niu, Wenbin Zhang, Pu Zhao, Xue Lin, Dong Huang, Yanzhi Wang', 'link': 'https://arxiv.org/abs/2508.04903', 'abstract': 'Multi-agent large language model (LLM) systems have shown strong potential in complex reasoning and collaborative decision-making tasks. However, most existing coordination schemes rely on static or full-context routing strategies, which lead to excessive token consumption, redundant memory exposure, and limited adaptability across interaction rounds. We introduce RCR-Router, a modular and role-aware context routing framework designed to enable efficient, adaptive collaboration in multi-agent LLMs. To our knowledge, this is the first routing approach that dynamically selects semantically relevant memory subsets for each agent based on its role and task stage, while adhering to a strict token budget. A lightweight scoring policy guides memory selection, and agent outputs are iteratively integrated into a shared memory store to facilitate progressive context refinement. To better evaluate model behavior, we further propose an Answer Quality Score metric that captures LLM-generated explanations beyond standard QA accuracy. Experiments on three multi-hop QA benchmarks -- HotPotQA, MuSiQue, and 2WikiMultihop -- demonstrate that RCR-Router reduces token usage (up to 30%) while improving or maintaining answer quality. These results highlight the importance of structured memory routing and output-aware evaluation in advancing scalable multi-agent LLM systems.', 'abstract_zh': '多智能体大型语言模型（LLM）系统在复杂推理和协作决策任务中展现出强大的潜力。然而，现有的大多数协调方案依赖于静态或全上下文路由策略，导致了过多的令牌消耗、冗余的内存暴露和跨交互轮次的有限适应性。我们引入了RCR-Router，一种模块化和角色感知的上下文路由框架，旨在使多智能体LLM中的高效、自适应协作成为可能。据我们所知，这是第一个能够根据智能体的角色和任务阶段动态选择语义相关内存子集的方法，同时遵循严格的令牌预算。轻量级的评分政策指导内存选择，智能体输出逐迭代地整合到共享内存存储中以促进渐进的上下文细化。为了更好地评估模型行为，我们进一步提出了一种答案质量得分指标，该指标捕获了LLM生成的解释，而不仅仅是标准的问答准确性。在三个多跳QA基准——HotPotQA、MuSiQue和2WikiMultihop——上的实验表明，RCR-Router在减少令牌使用量（最多降低30%）的同时提高了或维持了答案质量。这些结果突显了结构化内存路由和输出感知评估在促进可扩展的多智能体LLM系统方面的重要性。', 'title_zh': 'RCR-路由器：具有结构化记忆的多agent LLM系统中高效的角色感知上下文路由'}
{'arxiv_id': 'arXiv:2508.04900', 'title': 'Revealing Temporal Label Noise in Multimodal Hateful Video Classification', 'authors': 'Shuonan Yang, Tailin Chen, Rahul Singh, Jiangbei Yue, Jianbo Jiao, Zeyu Fu', 'link': 'https://arxiv.org/abs/2508.04900', 'abstract': 'The rapid proliferation of online multimedia content has intensified the spread of hate speech, presenting critical societal and regulatory challenges. While recent work has advanced multimodal hateful video detection, most approaches rely on coarse, video-level annotations that overlook the temporal granularity of hateful content. This introduces substantial label noise, as videos annotated as hateful often contain long non-hateful segments. In this paper, we investigate the impact of such label ambiguity through a fine-grained approach. Specifically, we trim hateful videos from the HateMM and MultiHateClip English datasets using annotated timestamps to isolate explicitly hateful segments. We then conduct an exploratory analysis of these trimmed segments to examine the distribution and characteristics of both hateful and non-hateful content. This analysis highlights the degree of semantic overlap and the confusion introduced by coarse, video-level annotations. Finally, controlled experiments demonstrated that time-stamp noise fundamentally alters model decision boundaries and weakens classification confidence, highlighting the inherent context dependency and temporal continuity of hate speech expression. Our findings provide new insights into the temporal dynamics of multimodal hateful videos and highlight the need for temporally aware models and benchmarks for improved robustness and interpretability. Code and data are available at this https URL.', 'abstract_zh': '在线多媒体内容的快速 proliferate 加剧了仇恨言论的传播，提出了重要的社会和监管挑战。尽管最近的工作推进了多模态仇恨视频检测的发展，但大多数方法依赖于粗略的视频级别注释，忽视了仇恨内容的时间粒度。这引入了大量标签噪声，因为被标注为仇恨的视频中往往包含长时间的非仇恨片段。在本文中，我们通过细粒度的方法研究了这种标签含糊性的影响。具体来说，我们使用标注的时间戳从 HateMM 和 MultiHateClip 英文数据集中裁剪出仇恨视频，以隔离明确的仇恨片段。然后，我们对这些裁剪片段进行探索性分析，以检查仇恨和非仇恨内容的分布和特征。此分析突显了粗略视频级别注释所引入的语义重叠和混淆。最后，受控实验表明时间戳噪声根本上改变了模型的决策边界并削弱了分类信心，突显了仇恨言论表达的内在上下文依赖性和时间连续性。我们的研究结果提供了有关多模态仇恨视频时间动态的新见解，并强调了对于提高鲁棒性和可解释性的需要使用时间意识模型和基准。代码和数据可在以下网址获取。', 'title_zh': '揭示多模态仇恨视频分类中的时序标签噪声'}
{'arxiv_id': 'arXiv:2508.04894', 'title': 'Adversarial Attacks and Defenses on Graph-aware Large Language Models (LLMs)', 'authors': 'Iyiola E. Olatunji, Franziska Boenisch, Jing Xu, Adam Dziedzic', 'link': 'https://arxiv.org/abs/2508.04894', 'abstract': 'Large Language Models (LLMs) are increasingly integrated with graph-structured data for tasks like node classification, a domain traditionally dominated by Graph Neural Networks (GNNs). While this integration leverages rich relational information to improve task performance, their robustness against adversarial attacks remains unexplored. We take the first step to explore the vulnerabilities of graph-aware LLMs by leveraging existing adversarial attack methods tailored for graph-based models, including those for poisoning (training-time attacks) and evasion (test-time attacks), on two representative models, LLAGA (Chen et al. 2024) and GRAPHPROMPTER (Liu et al. 2024). Additionally, we discover a new attack surface for LLAGA where an attacker can inject malicious nodes as placeholders into the node sequence template to severely degrade its performance. Our systematic analysis reveals that certain design choices in graph encoding can enhance attack success, with specific findings that: (1) the node sequence template in LLAGA increases its vulnerability; (2) the GNN encoder used in GRAPHPROMPTER demonstrates greater robustness; and (3) both approaches remain susceptible to imperceptible feature perturbation attacks. Finally, we propose an end-to-end defense framework GALGUARD, that combines an LLM-based feature correction module to mitigate feature-level perturbations and adapted GNN defenses to protect against structural attacks.', 'abstract_zh': '大型语言模型（LLMs） increasingly integrated with图结构数据用于节点分类等任务，这一领域传统上由图神经网络（GNNs）主导。尽管这种集成利用丰富的关系信息来提升任务性能，但其对抗攻击的稳健性尚未被探索。我们通过利用针对基于图模型的现有对抗攻击方法，包括训练时攻击（中毒攻击）和测试时攻击（规避攻击），首次探索图意识LLMs的脆弱性，针对两个代表性模型LLAGA（Chen et al. 2024）和GRAPHPROMPTER（Liu et al. 2024）进行了研究。此外，我们还发现LLAGA存在一个新的攻击面，攻击者可以注入恶意节点作为占位符到节点序列模板中，严重影响其性能。我们的系统分析揭示了某些图编码设计选择可以增强攻击成功率，具体发现包括：（1）LLAGA中的节点序列模板增加了其脆弱性；（2）GRAPHPROMPTER使用的GNN编码器表现出更强的鲁棒性；（3）两种方法都易受不可察觉特征扰动攻击的影响。最后，我们提出了一种端到端的防护框架GALGUARD，该框架结合了基于LLM的特征修正模块来减轻特征层面的扰动，并对结构攻击进行了适应性防护。', 'title_zh': '图意识大型语言模型的对抗攻击与防御'}
{'arxiv_id': 'arXiv:2508.04886', 'title': 'Leveraging Deep Learning for Physical Model Bias of Global Air Quality Estimates', 'authors': 'Kelsey Doerksen, Yuliya Marchetti, Kevin Bowman, Steven Lu, James Montgomery, Yarin Gal, Freddie Kalaitzis, Kazuyuki Miyazaki', 'link': 'https://arxiv.org/abs/2508.04886', 'abstract': "Air pollution is the world's largest environmental risk factor for human disease and premature death, resulting in more than 6 million permature deaths in 2019. Currently, there is still a challenge to model one of the most important air pollutants, surface ozone, particularly at scales relevant for human health impacts, with the drivers of global ozone trends at these scales largely unknown, limiting the practical use of physics-based models. We employ a 2D Convolutional Neural Network based architecture that estimate surface ozone MOMO-Chem model residuals, referred to as model bias. We demonstrate the potential of this technique in North America and Europe, highlighting its ability better to capture physical model residuals compared to a traditional machine learning method. We assess the impact of incorporating land use information from high-resolution satellite imagery to improve model estimates. Importantly, we discuss how our results can improve our scientific understanding of the factors impacting ozone bias at urban scales that can be used to improve environmental policy.", 'abstract_zh': '大气污染是世界上最大的环境风险因素，对人体疾病和提前死亡的影响超过2019年的600万人。目前，在人类健康影响相关的尺度上，仍然难以建模最重要的一种大气污染物——表面臭氧，尤其是在这些尺度上全球臭氧趋势的驱动因素尚不清楚，限制了基于物理的模型的实际应用。我们采用基于2D卷积神经网络的架构来估计MOMO-Chem模型残差，即模型偏差。我们展示了该技术在美国和欧洲的潜在应用，强调了其在捕捉物理模型残差方面比传统机器学习方法更具优势的能力。我们评估了结合高分辨率卫星图像的土地利用信息对提高模型估计的影响。重要的是，我们讨论了这些结果如何有助于我们更好地理解城市尺度上影响臭氧偏差的因子，以改进环境政策。', 'title_zh': '利用深度学习减轻全球空气质量估计中的物理模型偏差'}
{'arxiv_id': 'arXiv:2508.04885', 'title': 'Uncertainty Quantification for Surface Ozone Emulators using Deep Learning', 'authors': 'Kelsey Doerksen, Yuliya Marchetti, Steven Lu, Kevin Bowman, James Montgomery, Kazuyuki Miyazaki, Yarin Gal, Freddie Kalaitzis', 'link': 'https://arxiv.org/abs/2508.04885', 'abstract': "Air pollution is a global hazard, and as of 2023, 94\\% of the world's population is exposed to unsafe pollution levels. Surface Ozone (O3), an important pollutant, and the drivers of its trends are difficult to model, and traditional physics-based models fall short in their practical use for scales relevant to human-health impacts. Deep Learning-based emulators have shown promise in capturing complex climate patterns, but overall lack the interpretability necessary to support critical decision making for policy changes and public health measures. We implement an uncertainty-aware U-Net architecture to predict the Multi-mOdel Multi-cOnstituent Chemical data assimilation (MOMO-Chem) model's surface ozone residuals (bias) using Bayesian and quantile regression methods. We demonstrate the capability of our techniques in regional estimation of bias in North America and Europe for June 2019. We highlight the uncertainty quantification (UQ) scores between our two UQ methodologies and discern which ground stations are optimal and sub-optimal candidates for MOMO-Chem bias correction, and evaluate the impact of land-use information in surface ozone residual modeling.", 'abstract_zh': '空气污染是全球性危害，截至2023年，全球94%的人口暴露在不安全的污染水平中。地表臭氧（O3）作为一种重要的污染物及其趋势驱动因素难以建模，传统的基于物理的方法在用于评估对人类健康影响的相关规模时存在局限性。基于深度学习的模拟器展现出捕捉复杂气候模式的潜力，但在支持政策变化和公共卫生措施的关键决策方面缺乏解释性。我们采用一种aware不确定性U-Net架构，结合贝叶斯和分位数回归方法预测MOMO-Chem模型的地表臭氧残差（偏差）。我们在北美洲和欧洲2019年6月的地表臭氧偏差区域估计能力上展示了这些技术的能力。我们量化了两种不确定性量化（UQ）方法之间的差异，并确定哪些地面站是最优和次优的MOMO-Chem偏差校正候选站点，同时评估了土地利用信息对地表臭氧残差建模的影响。', 'title_zh': '使用深度学习进行表面臭氧模拟器的不确定性量化'}
{'arxiv_id': 'arXiv:2508.04874', 'title': 'Sequence Aware SAC Control for Engine Fuel Consumption Optimization in Electrified Powertrain', 'authors': 'Wafeeq Jaleel, Md Ragib Rownak, Athar Hanif, Sidra Ghayour Bhatti, Qadeer Ahmed', 'link': 'https://arxiv.org/abs/2508.04874', 'abstract': 'As hybrid electric vehicles (HEVs) gain traction in heavy-duty trucks, adaptive and efficient energy management is critical for reducing fuel consumption while maintaining battery charge for long operation times. We present a new reinforcement learning (RL) framework based on the Soft Actor-Critic (SAC) algorithm to optimize engine control in series HEVs. We reformulate the control task as a sequential decision-making problem and enhance SAC by incorporating Gated Recurrent Units (GRUs) and Decision Transformers (DTs) into both actor and critic networks to capture temporal dependencies and improve planning over time. To evaluate robustness and generalization, we train the models under diverse initial battery states, drive cycle durations, power demands, and input sequence lengths. Experiments show that the SAC agent with a DT-based actor and GRU-based critic was within 1.8% of Dynamic Programming (DP) in fuel savings on the Highway Fuel Economy Test (HFET) cycle, while the SAC agent with GRUs in both actor and critic networks, and FFN actor-critic agent were within 3.16% and 3.43%, respectively. On unseen drive cycles (US06 and Heavy Heavy-Duty Diesel Truck (HHDDT) cruise segment), generalized sequence-aware agents consistently outperformed feedforward network (FFN)-based agents, highlighting their adaptability and robustness in real-world settings.', 'abstract_zh': '基于软 Actor- Critic 算法的门控循环单元和决策变换器集成的混合电动重卡能量管理强化学习方法', 'title_zh': '面向电动传动系统的序贯意识S(SA) SAC 控制的发动机燃料消耗优化'}
{'arxiv_id': 'arXiv:2508.04853', 'title': 'Provable Post-Training Quantization: Theoretical Analysis of OPTQ and Qronos', 'authors': 'Haoyu Zhang, Shihao Zhang, Ian Colbert, Rayan Saab', 'link': 'https://arxiv.org/abs/2508.04853', 'abstract': "Post-training quantization (PTQ) has become a crucial tool for reducing the memory and compute costs of modern deep neural networks, including large language models (LLMs). Among PTQ algorithms, the OPTQ framework-also known as GPTQ-has emerged as a leading method due to its computational efficiency and strong empirical performance. Despite its widespread adoption, however, OPTQ lacks rigorous quantitative theoretical guarantees. This paper presents the first quantitative error bounds for both deterministic and stochastic variants of OPTQ, as well as for Qronos, a recent related state-of-the-art PTQ algorithm. We analyze how OPTQ's iterative procedure induces quantization error and derive non-asymptotic 2-norm error bounds that depend explicitly on the calibration data and a regularization parameter that OPTQ uses. Our analysis provides theoretical justification for several practical design choices, including the widely used heuristic of ordering features by decreasing norm, as well as guidance for selecting the regularization parameter. For the stochastic variant, we establish stronger infinity-norm error bounds, which enable control over the required quantization alphabet and are particularly useful for downstream layers and nonlinearities. Finally, we extend our analysis to Qronos, providing new theoretical bounds, for both its deterministic and stochastic variants, that help explain its empirical advantages.", 'abstract_zh': '训练后量化（PTQ）已成为降低现代深度神经网络，包括大型语言模型（LLMs）的内存和计算成本的关键工具。在PTQ算法中，OPTQ框架——也称为GPTQ——凭借其计算效率和强大的实证表现，已成为领先的方法。然而，尽管其广泛采用，OPTQ仍缺乏严格的定量理论保证。本文首次为OPTQ的确定性和随机变体，以及最近的相关最佳PTQ算法Qronos提供了定量的误差界。我们分析了OPTQ迭代过程引起的量化误差，并推导出依赖于校准数据和OPTQ使用的正则化参数的非渐近2-范数误差界。我们的分析为诸如按递减范数排序特征等若干实用设计选择提供了理论依据，并为选择正则化参数提供了指导。对于随机变体，我们建立了更强的∞-范数误差界，这使得可以控制所需的量化字母表，并特别适用于下游层和非线性操作。最后，我们将分析扩展到Qronos，为其实定性和随机变体提供了新的理论界，有助于解释其实证优势。', 'title_zh': '可验证后训练量化：OPTQ和Qronos的理论分析'}
{'arxiv_id': 'arXiv:2508.04845', 'title': 'Multi-Stage Knowledge-Distilled VGAE and GAT for Robust Controller-Area-Network Intrusion Detection', 'authors': 'Robert Frenken, Sidra Ghayour Bhatti, Hanqin Zhang, Qadeer Ahmed', 'link': 'https://arxiv.org/abs/2508.04845', 'abstract': 'The Controller Area Network (CAN) protocol is a standard for in-vehicle communication but remains susceptible to cyber-attacks due to its lack of built-in security. This paper presents a multi-stage intrusion detection framework leveraging unsupervised anomaly detection and supervised graph learning tailored for automotive CAN traffic. Our architecture combines a Variational Graph Autoencoder (VGAE) for structural anomaly detection with a Knowledge-Distilled Graph Attention Network (KD-GAT) for robust attack classification. CAN bus activity is encoded as graph sequences to model temporal and relational dependencies. The pipeline applies VGAE-based selective undersampling to address class imbalance, followed by GAT classification with optional score-level fusion. The compact student GAT achieves 96% parameter reduction compared to the teacher model while maintaining strong predictive performance. Experiments on six public CAN intrusion datasets--Car-Hacking, Car-Survival, and can-train-and-test--demonstrate competitive accuracy and efficiency, with average improvements of 16.2% in F1-score over existing methods, particularly excelling on highly imbalanced datasets with up to 55% F1-score improvements.', 'abstract_zh': '基于无监督异常检测和监督图学习的多阶段汽车CAN入侵检测框架', 'title_zh': '多阶段知识蒸馏VGAE和GAT在鲁棒车载网络入侵检测中的应用'}
{'arxiv_id': 'arXiv:2508.04826', 'title': "Persistent Instability in LLM's Personality Measurements: Effects of Scale, Reasoning, and Conversation History", 'authors': 'Tommaso Tosato, Saskia Helbling, Yorguin-Jose Mantilla-Ramos, Mahmood Hegazy, Alberto Tosato, David John Lemay, Irina Rish, Guillaume Dumas', 'link': 'https://arxiv.org/abs/2508.04826', 'abstract': 'Large language models require consistent behavioral patterns for safe deployment, yet their personality-like traits remain poorly understood. We present PERSIST (PERsonality Stability in Synthetic Text), a comprehensive evaluation framework testing 25+ open-source models (1B-671B parameters) across 500,000+ responses. Using traditional (BFI-44, SD3) and novel LLM-adapted personality instruments, we systematically vary question order, paraphrasing, personas, and reasoning modes. Our findings challenge fundamental deployment assumptions: (1) Even 400B+ models exhibit substantial response variability (SD > 0.4); (2) Minor prompt reordering alone shifts personality measurements by up to 20%; (3) Interventions expected to stabilize behavior, such as chain-of-thought reasoning, detailed personas instruction, inclusion of conversation history, can paradoxically increase variability; (4) LLM-adapted instruments show equal instability to human-centric versions, confirming architectural rather than translational limitations. This persistent instability across scales and mitigation strategies suggests current LLMs lack the foundations for genuine behavioral consistency. For safety-critical applications requiring predictable behavior, these findings indicate that personality-based alignment strategies may be fundamentally inadequate.', 'abstract_zh': '大规模语言模型需要一致的行为模式以确保安全部署，但其类似人格的特征仍 poorly understood。我们提出PERSIST（PERsonality Stability in Synthetic Text）框架，测试了超过25个开源模型（参数从1B到671B）在500,000多条响应中的表现。利用传统（BFI-44, SD3）以及新型语言模型适应的人格量表，我们系统地变化了问题顺序、改写、人物设定和推理模式。我们的研究结果挑战了基本的部署假设：（1）即使超过400B的模型也表现出显著的响应波动性（标准差>0.4）；（2）单一的提示重新排序会将人格测量值改变多达20%；（3）预期能够稳定行为的干预措施，如逐步推理、详细的背景人物指令、包含对话历史，反而可能增加波动性；（4）语言模型适应的人格量表与以人为中心的版本表现相当不稳定，证实了架构而非翻译限制。这一持续的不稳定性及缓解策略的无效性表明当前的语言模型缺乏真正行为一致性的基础。对于需要可预测行为的安全关键应用，这些发现表明基于人格的对齐策略可能从根本上不足。', 'title_zh': 'LLM个性测量中的持久不稳定性：量表、推理和对话历史的影响'}
{'arxiv_id': 'arXiv:2508.04825', 'title': 'Voost: A Unified and Scalable Diffusion Transformer for Bidirectional Virtual Try-On and Try-Off', 'authors': 'Seungyong Lee, Jeong-gi Kwak', 'link': 'https://arxiv.org/abs/2508.04825', 'abstract': 'Virtual try-on aims to synthesize a realistic image of a person wearing a target garment, but accurately modeling garment-body correspondence remains a persistent challenge, especially under pose and appearance variation. In this paper, we propose Voost - a unified and scalable framework that jointly learns virtual try-on and try-off with a single diffusion transformer. By modeling both tasks jointly, Voost enables each garment-person pair to supervise both directions and supports flexible conditioning over generation direction and garment category, enhancing garment-body relational reasoning without task-specific networks, auxiliary losses, or additional labels. In addition, we introduce two inference-time techniques: attention temperature scaling for robustness to resolution or mask variation, and self-corrective sampling that leverages bidirectional consistency between tasks. Extensive experiments demonstrate that Voost achieves state-of-the-art results on both try-on and try-off benchmarks, consistently outperforming strong baselines in alignment accuracy, visual fidelity, and generalization.', 'abstract_zh': '虚拟试穿旨在合成一个人穿着目标衣物的现实图像，但准确建模衣物-人体对应关系仍然是一个持久性的挑战，尤其是在姿态和外观变化的情况下。在本文中，我们提出了一种统一且可扩展的框架Voost，该框架使用单个扩散变换器联合学习虚拟试穿和脱穿。通过将两个任务联合建模，Voost使得每件衣物-人体配对能够监督两个方向，并支持生成方向和衣物类别的灵活条件，从而增强衣物-人体关系推理，而无需专门网络、辅助损失或额外标签。此外，我们引入了两种推理时的技术：注意力温度缩放以提高对分辨率或遮罩变化的鲁棒性，以及利用任务间双向一致性的自我校正采样。大量实验表明，Voost在试穿和脱穿基准测试中均取得了最先进的成果，一致地在对齐精度、视觉保真度和泛化方面优于强大基准。', 'title_zh': 'Voost：一种统一且可扩展的双向虚拟试穿与脱下扩散变换器'}
{'arxiv_id': 'arXiv:2508.04820', 'title': 'Automated File-Level Logging Generation for Machine Learning Applications using LLMs: A Case Study using GPT-4o Mini', 'authors': 'Mayra Sofia Ruiz Rodriguez, SayedHassan Khatoonabadi, Emad Shihab', 'link': 'https://arxiv.org/abs/2508.04820', 'abstract': 'Logging is essential in software development, helping developers monitor system behavior and aiding in debugging applications. Given the ability of large language models (LLMs) to generate natural language and code, researchers are exploring their potential to generate log statements. However, prior work focuses on evaluating logs introduced in code functions, leaving file-level log generation underexplored -- especially in machine learning (ML) applications, where comprehensive logging can enhance reliability. In this study, we evaluate the capacity of GPT-4o mini as a case study to generate log statements for ML projects at file level. We gathered a set of 171 ML repositories containing 4,073 Python files with at least one log statement. We identified and removed the original logs from the files, prompted the LLM to generate logs for them, and evaluated both the position of the logs and log level, variables, and text quality of the generated logs compared to human-written logs. In addition, we manually analyzed a representative sample of generated logs to identify common patterns and challenges. We find that the LLM introduces logs in the same place as humans in 63.91% of cases, but at the cost of a high overlogging rate of 82.66%. Furthermore, our manual analysis reveals challenges for file-level logging, which shows overlogging at the beginning or end of a function, difficulty logging within large code blocks, and misalignment with project-specific logging conventions. While the LLM shows promise for generating logs for complete files, these limitations remain to be addressed for practical implementation.', 'abstract_zh': '大语言模型生成文件级日志陈述的研究：以GPT-4o mini为案例的机器学习项目日志生成能力评估', 'title_zh': '使用LLMs生成机器学习应用的文件级日志记录：基于GPT-4o Mini的案例研究'}
{'arxiv_id': 'arXiv:2508.04816', 'title': 'CoMAD: A Multiple-Teacher Self-Supervised Distillation Framework', 'authors': 'Sriram Mandalika, Lalitha V', 'link': 'https://arxiv.org/abs/2508.04816', 'abstract': "Numerous self-supervised learning paradigms, such as contrastive learning and masked image modeling, learn powerful representations from unlabeled data but are typically pretrained in isolation, overlooking complementary insights and yielding large models that are impractical for resource-constrained deployment. To overcome these challenges, we introduce Consensus-oriented Masked Distillation (CoMAD), a lightweight, parameter-free framework that unifies knowledge from multiple current state-of-the-art self-supervised Vision Transformers into a compact student network. CoMAD distills from three pretrained ViT-Base teachers, MAE, MoCo v3, and iBOT, each offering distinct semantic and contextual priors. Rather than naively averaging teacher outputs, we apply asymmetric masking: the student sees only 25 percent of patches while each teacher receives a progressively lighter, unique mask, forcing the student to interpolate missing features under richer contexts. Teacher embeddings are aligned to the student's space via a linear adapter and layer normalization, then fused through our joint consensus gating, which weights each token by combining cosine affinity with inter-teacher agreement. The student is trained with dual-level KL divergence on visible tokens and reconstructed feature maps, capturing both local and global structure. On ImageNet-1K, CoMAD's ViT-Tiny achieves 75.4 percent Top-1, an increment of 0.4 percent over the previous state-of-the-art. In dense-prediction transfers, it attains 47.3 percent mIoU on ADE20K, and 44.5 percent box average precision and 40.5 percent mask average precision on MS-COCO, establishing a new state-of-the-art in compact SSL distillation.", 'abstract_zh': '面向共识的掩码蒸馏（CoMAD）：一种轻量级的学生网络框架', 'title_zh': 'CoMAD: 多师自我监督蒸馏框架'}
{'arxiv_id': 'arXiv:2508.04799', 'title': 'Optimality Principles and Neural Ordinary Differential Equations-based Process Modeling for Distributed Control', 'authors': 'Michael R. Wartmann, B. Erik Ydstie', 'link': 'https://arxiv.org/abs/2508.04799', 'abstract': "Most recent advances in machine learning and analytics for process control pose the question of how to naturally integrate new data-driven methods with classical process models and control. We propose a process modeling framework enabling integration of data-driven algorithms through consistent topological properties and conservation of extensive quantities. Interconnections among process network units are represented through connectivity matrices and network graphs. We derive the system's natural objective function equivalent to the non-equilibrium entropy production in a steady state system as a driving force for the process dynamics. We illustrate how distributed control and optimization can be implemented into process network structures and how control laws and algorithms alter the system's natural equilibrium towards engineered objectives. The basic requirement is that the flow conditions can be expressed in terms of conic sector (passivity) conditions. Our formalism allows integration of fundamental conservation properties from topology with learned dynamic relations from data through sparse deep neural networks.\nWe demonstrate in a practical example of a simple inventory control system how to integrate the basic topology of a process with a neural network ordinary differential equation model. The system specific constitutive equations are left undescribed and learned by the neural ordinary differential equation algorithm using the adjoint method in combination with an adaptive ODE solver from synthetic time-series data. The resulting neural network forms a state space model for use in e.g. a model predictive control algorithm.", 'abstract_zh': '最近在过程控制中 对自动学习与分析 方面取得的 了重要进展， �， 提出了如何自然地 地将数据驱动技术与 与经典过程模型融合的问题 e。. 我们提出 提出了一种 � 一种过 过程 � 程建 仿真模型e 体系框架 e ， 兜 � Claudia  �.bind 中 � 数据驱动算法与 与一致的 的 e 系统拓 孓结构属性 e 以及多种守 保 量 e 量 量 量 量 � � e 保 e e 量 e  e  e  e  e 量 的 p  e e  e  e e e  e e e  e  e  e  e  e  e  e e  e e e e e  e  e  e e e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e e  e e  e  e  e e  e  e  e  e  e  e  e  e  e  e e  e e  e  e  e e  e e  e e  e e  e  e  e  e e  e e  e e  e e  e  e e e  e e e  e e e e e e e e e e e e e e e e e e e e e e e �。  e e  e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e 。\n\n e e  e e e e e e e e  e e e e e e e e e e e e e e e e e  e  e  e  e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e  e  e e e e e e e e e  e  e e  e e e  e e e e e e e e e  e  e e e e e e e e e e e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e  e e e  e e e e e e e e e e e e e  e e e e e  e e e  e e  e e  e e e e e e e e e  e e e e e  e e  e e  e  e e e e e  e e e e e e e e e e e e e e e e e e  e  e  e  e e e  e e e e e  e e e e e  e  e  e e  e e e e e e  e e  e e  e e  e e  e e  e  e  e e  e e e e e  e  e e e e e e e  e  e  e e  e e e e e  e  e e  e  e e e e e �  e e e e e e e e  e  e  e  e e e  e  e e e e e  e  e  e  e  e  e  e e  e e  e e  e e  e e  e e  e e  e e  e e  e e e e e e e e  e  e  e e e e e e e e  e e  e e e e e e e e  e  e  e e  e e e e e e e e e e  e  e e e e e e e  e  e e e e e e  e  e e e  e e  e e  e e  e e  e e e e e  e e  e e  e e  e e  e  e  e e  e e  e e  e  e  e e e  e  e  e  e e e  e e  e e  e e  e e  e  e  e e  e  e  e  e  e  e e  e e  e e  e e  e  e  e  e  e  e  e  e  e e e e e e  e  e e  e e  e e e  e  e e e e  e e e e e  e e e e e e  e e e  e  e  e e  e e  e  e e e  e  e  e e  e e  e e  e  e  e  e  e  e e  e  e  e  e  e  e  e e e e e e e e  e  e e e e e e e e  e  e e e  e  e e e e e e e e  e  e e e e e e  e  e  e  e  e e  e  e e e  e e e e e  e  e e e  e e e e e  e  e e e  e  e  e  e  e  e  e e e e e e  e  e e e  e e e e e  e  e e e e  e  e  e e  e  e e e e  e e e e  e e e  e e  e  e e  e  e  e  e e e  e e  e e  e e e e e e e e e e  e  e  e e  e e  e e  e e  e  e e e e  e  e e  e  e  e  e  e  e e  e  e  e  e  e e  e  e  e  e  e e e  e  e e e  e  e e  e e  e e  e  e e  e  e  e  e e  e  e  e  e  e e  e  e  e  e  e e  e  e  e e e e  e  e  e e  e  e e  e  e  e  e e  e e  e e  e  e e e e e e  e  e e  e e e e  e … e e e e  e e e e e  e  e e  e e  e e  e e e e e  e  e e  e  e e e e  e  e  e e  e  e e  e e  e e  e  e e  e  e  e  e  e  e  e  e e  e e e e  e e  e e e e  e  e e  e  e  e  e  e  e  e  e e  e  e  e  e  e  e e  e e  e  e  e e  e  e  e  e  e  e  e  e  e e e  e  e  e  e e  e  e  e  e  e  e  e e  e  e e  e  e  e e  e  e  e  e  e  e  e  e  e e e e  e  e e e  e  e  e e  e  e  e e  e  e  e  e  e e  e  e  e  e e e e  e  e  e e  e  e e  e  e  e e  e  e  e  e  e  e  e e  e  e  e e  e e  e  e  e  e  e  e e  e  e  e e  e  e  e  e e  e  e  e  e  e e e  e  e e  e  e  e e  e  e  e e  e  e  e e  e  e  e  e  e  e  e  e  e e e  e  e  e  e  e  e  e  e  e  e e  e  e  e  e  e e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e e  e  e e  e  e  e  e  e  e e  e  e  e e  e  e  e e  e  e  e e  e  e  e e  e  e  e e  e  e  e  e  e  e e  e  e  e  e  e e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e e  e  e e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e  e', 'title_zh': '基于神经常微分方程的分布式控制过程建模与最优性原理'}
{'arxiv_id': 'arXiv:2508.04796', 'title': 'Parity-Aware Byte-Pair Encoding: Improving Cross-lingual Fairness in Tokenization', 'authors': 'Negar Foroutan, Clara Meister, Debjit Paul, Joel Niklaus, Sina Ahmadi, Antoine Bosselut, Rico Sennrich', 'link': 'https://arxiv.org/abs/2508.04796', 'abstract': 'Tokenization is the first -- and often least scrutinized -- step of most NLP pipelines. Standard algorithms for learning tokenizers rely on frequency-based objectives, which favor languages dominant in the training data and consequently leave lower-resource languages with tokenizations that are disproportionately longer, morphologically implausible, or even riddled with <UNK> placeholders. This phenomenon ultimately amplifies computational and financial inequalities between users from different language backgrounds. To remedy this, we introduce Parity-aware Byte Pair Encoding (BPE), a variant of the widely-used BPE algorithm. At every merge step, Parity-aware BPE maximizes the compression gain of the currently worst-compressed language, trading a small amount of global compression for cross-lingual parity. We find empirically that Parity-aware BPE leads to more equitable token counts across languages, with negligible impact on global compression rate and no substantial effect on language-model performance in downstream tasks.', 'abstract_zh': 'Parity-aware Byte Pair Encoding：跨语言公平的子词分割方法', 'title_zh': '意识 parity 的字节对编码：在分词中提高跨语言公平性'}
{'arxiv_id': 'arXiv:2508.04795', 'title': 'Enhancing Dialogue Annotation with Speaker Characteristics Leveraging a Frozen LLM', 'authors': 'Thomas Thebaud, Yen-Ju Lu, Matthew Wiesner, Peter Viechnicki, Najim Dehak', 'link': 'https://arxiv.org/abs/2508.04795', 'abstract': 'In dialogue transcription pipelines, Large Language Models (LLMs) are frequently employed in post-processing to improve grammar, punctuation, and readability. We explore a complementary post-processing step: enriching transcribed dialogues by adding metadata tags for speaker characteristics such as age, gender, and emotion. Some of the tags are global to the entire dialogue, while some are time-variant. Our approach couples frozen audio foundation models, such as Whisper or WavLM, with a frozen LLAMA language model to infer these speaker attributes, without requiring task-specific fine-tuning of either model. Using lightweight, efficient connectors to bridge audio and language representations, we achieve competitive performance on speaker profiling tasks while preserving modularity and speed. Additionally, we demonstrate that a frozen LLAMA model can compare x-vectors directly, achieving an Equal Error Rate of 8.8% in some scenarios.', 'abstract_zh': '在对话转写流水线中，大型语言模型（LLMs）经常用于后处理以改进语法、标点和可读性。我们探索了一个互补的后处理步骤：通过添加元数据标签来丰富转录对话，这些标签包括演讲者特征如年龄、性别和情感。部分标签适用于整个对话，而部分标签则是时间变化的。我们的方法结合了冻结的音频基础模型（如Whisper或WavLM）与冻结的LLAMA语言模型，以推断这些演讲者属性，无需对任何模型进行特定任务的微调。借助轻量级且高效的连接器来桥接音频和语言表示，我们在演讲者画像任务中实现了竞争力的表现，同时保持模块化和速度。此外，我们展示了冻结的LLAMA模型可以直接比较x-向量，在某些情况下实现了8.8%的平等错误率。', 'title_zh': '利用冻结的预训练语言模型挖掘说话人特征以增强对话标注'}
{'arxiv_id': 'arXiv:2508.04787', 'title': 'Evaluating the Impact of LLM-guided Reflection on Learning Outcomes with Interactive AI-Generated Educational Podcasts', 'authors': 'Vishnu Menon, Andy Cherney, Elizabeth B. Cloude, Li Zhang, Tiffany D. Do', 'link': 'https://arxiv.org/abs/2508.04787', 'abstract': 'This study examined whether embedding LLM-guided reflection prompts in an interactive AI-generated podcast improved learning and user experience compared to a version without prompts. Thirty-six undergraduates participated, and while learning outcomes were similar across conditions, reflection prompts reduced perceived attractiveness, highlighting a call for more research on reflective interactivity design.', 'abstract_zh': '本研究探讨了将LLM引导的反思提示嵌入交互式AI生成的播客是否能改善学习效果和用户体验，相较于未包含提示的版本。36名本科生参与了研究，尽管各条件下学习成果相近，但反思提示降低了 perceived 吸引力，强调了在反思互动设计方面需要更多研究的必要性。', 'title_zh': '基于交互式AI生成教育播客的LLM引导反思对学习成果的影响评估'}
{'arxiv_id': 'arXiv:2508.04780', 'title': 'Uncertainty-aware Predict-Then-Optimize Framework for Equitable Post-Disaster Power Restoration', 'authors': 'Lin Jiang, Dahai Yu, Rongchao Xu, Tian Tang, Guang Wang', 'link': 'https://arxiv.org/abs/2508.04780', 'abstract': 'The increasing frequency of extreme weather events, such as hurricanes, highlights the urgent need for efficient and equitable power system restoration. Many electricity providers make restoration decisions primarily based on the volume of power restoration requests from each region. However, our data-driven analysis reveals significant disparities in request submission volume, as disadvantaged communities tend to submit fewer restoration requests. This disparity makes the current restoration solution inequitable, leaving these communities vulnerable to extended power outages. To address this, we aim to propose an equity-aware power restoration strategy that balances both restoration efficiency and equity across communities. However, achieving this goal is challenging for two reasons: the difficulty of predicting repair durations under dataset heteroscedasticity, and the tendency of reinforcement learning agents to favor low-uncertainty actions, which potentially undermine equity. To overcome these challenges, we design a predict-then-optimize framework called EPOPR with two key components: (1) Equity-Conformalized Quantile Regression for uncertainty-aware repair duration prediction, and (2) Spatial-Temporal Attentional RL that adapts to varying uncertainty levels across regions for equitable decision-making. Experimental results show that our EPOPR effectively reduces the average power outage duration by 3.60% and decreases inequity between different communities by 14.19% compared to state-of-the-art baselines.', 'abstract_zh': '极端天气事件频率的增加突显了高效和公平恢复电力系统的紧迫需求。许多电力提供商主要根据每个地区的电力恢复请求量来作出恢复决定。然而，我们的数据驱动分析揭示了请求提交量存在显著差异，弱势社区提交的恢复请求较少。这种差异使得当前的恢复解决方案不公平，使这些社区更容易遭受长时间的断电。为解决这一问题，我们旨在提出一种兼顾恢复效率和公平性的公平意识电力恢复策略。然而，实现这一目标面临两个挑战：数据集异方差性下难以预测维修时间，以及强化学习代理倾向于选择低不确定性行动，这可能损害公平性。为克服这些挑战，我们设计了一种名为EPOPR的预测-优化框架，包含两个关键组件：（1）公平校准化分位数回归进行不确定性意识的维修时间预测；（2）时空注意力强化学习，以适应不同地区变异的不确定性水平，实现公平决策。实验结果表明，我们的EPOPR将平均停电时间缩短了3.60%，并将不同社区之间不公平性降低了14.19%，优于现有最先进的基线。', 'title_zh': '面向公平灾后电力恢复的不确定性意识预测-优化框架'}
{'arxiv_id': 'arXiv:2508.04735', 'title': 'ERDES: A Benchmark Video Dataset for Retinal Detachment and Macular Status Classification in Ocular Ultrasound', 'authors': 'Pouyan Navard, Yasemin Ozkut, Srikar Adhikari, Elaine Situ-LaCasse, Josie Acuña, Adrienne Yarnish, Alper Yilmaz', 'link': 'https://arxiv.org/abs/2508.04735', 'abstract': 'Retinal detachment (RD) is a vision-threatening condition that requires timely intervention to preserve vision. Macular involvement -- whether the macula is still intact (macula-intact) or detached (macula-detached) -- is the key determinant of visual outcomes and treatment urgency. Point-of-care ultrasound (POCUS) offers a fast, non-invasive, cost-effective, and accessible imaging modality widely used in diverse clinical settings to detect RD. However, ultrasound image interpretation is limited by a lack of expertise among healthcare providers, especially in resource-limited settings. Deep learning offers the potential to automate ultrasound-based assessment of RD. However, there are no ML ultrasound algorithms currently available for clinical use to detect RD and no prior research has been done on assessing macular status using ultrasound in RD cases -- an essential distinction for surgical prioritization. Moreover, no public dataset currently supports macular-based RD classification using ultrasound video clips. We introduce Eye Retinal DEtachment ultraSound, ERDES, the first open-access dataset of ocular ultrasound clips labeled for (i) presence of retinal detachment and (ii) macula-intact versus macula-detached status. The dataset is intended to facilitate the development and evaluation of machine learning models for detecting retinal detachment. We also provide baseline benchmarks using multiple spatiotemporal convolutional neural network (CNN) architectures. All clips, labels, and training code are publicly available at this https URL.', 'abstract_zh': '视网膜脱离（RD）是一种威胁视力的疾病，需要及时干预以保存视力。黄斑区的牵涉——无论是黄斑完好（macula-intact）还是脱离（macula-detached）——是决定视觉预后和治疗紧迫性的重要因素。床旁超声（POCUS）提供了一种快速、无创、成本效益高且易于获得的成像技术，在多种临床环境中广泛用于检测视网膜脱离。然而，超声图像解释受到医护人员缺乏专业知识的限制，尤其是在资源有限的环境中。深度学习有可能实现基于超声的视网膜脱离自动评估。然而，目前尚无用于临床检测视网膜脱离的机器学习（ML）超声算法，也没有研究使用超声评估视网膜脱离病例中的黄斑状态——这是手术优先级划分的关键区别。此外，目前没有公开数据集支持使用超声视频片段基于黄斑的视网膜脱离分类。为此，我们介绍了一个名为Eye Retinal DEtachment ultraSound (ERDES) 的首个开放访问数据集，该数据集包含标注了视网膜脱离存在与否以及黄斑完好与否或脱离的辐辏超声片段，旨在促进检测视网膜脱离的机器学习模型的开发与评估。我们还提供了基于多种空时卷积神经网络（CNN）架构的基准性能。所有片段、标签和训练代码均公开于 https://。', 'title_zh': 'ERDES：眼科超声中视网膜脱离和黄斑状态分类的基准视频数据集'}
{'arxiv_id': 'arXiv:2508.04734', 'title': 'Cross-Domain Image Synthesis: Generating H&E from Multiplex Biomarker Imaging', 'authors': 'Jillur Rahman Saurav, Mohammad Sadegh Nasr, Jacob M. Luber', 'link': 'https://arxiv.org/abs/2508.04734', 'abstract': 'While multiplex immunofluorescence (mIF) imaging provides deep, spatially-resolved molecular data, integrating this information with the morphological standard of Hematoxylin & Eosin (H&E) can be very important for obtaining complementary information about the underlying tissue. Generating a virtual H&E stain from mIF data offers a powerful solution, providing immediate morphological context. Crucially, this approach enables the application of the vast ecosystem of H&E-based computer-aided diagnosis (CAD) tools to analyze rich molecular data, bridging the gap between molecular and morphological analysis. In this work, we investigate the use of a multi-level Vector-Quantized Generative Adversarial Network (VQGAN) to create high-fidelity virtual H&E stains from mIF images. We rigorously evaluated our VQGAN against a standard conditional GAN (cGAN) baseline on two publicly available colorectal cancer datasets, assessing performance on both image similarity and functional utility for downstream analysis. Our results show that while both architectures produce visually plausible images, the virtual stains generated by our VQGAN provide a more effective substrate for computer-aided diagnosis. Specifically, downstream nuclei segmentation and semantic preservation in tissue classification tasks performed on VQGAN-generated images demonstrate superior performance and agreement with ground-truth analysis compared to those from the cGAN. This work establishes that a multi-level VQGAN is a robust and superior architecture for generating scientifically useful virtual stains, offering a viable pathway to integrate the rich molecular data of mIF into established and powerful H&E-based analytical workflows.', 'abstract_zh': '基于多层次向量量化生成对抗网络生成高保真虚拟HE染色图像以整合分子与形态学分析', 'title_zh': '跨域图像合成：从多重生物标志物成像生成HE图像'}
{'arxiv_id': 'arXiv:2508.04725', 'title': 'Agency, Affordances, and Enculturation of Augmentation Technologies', 'authors': 'Ann Hill Duin, Isabel Pedersen', 'link': 'https://arxiv.org/abs/2508.04725', 'abstract': 'Augmentation technologies are undergoing a process of enculturation due to many factors, one being the rise of artificial intelligence (AI), or what the World Intellectual Property Organization (WIPO) terms the AI wave or AI boom. Chapter 3 focuses critical attention on the hyped assumption that sophisticated, emergent, and embodied augmentation technologies will improve lives, literacy, cultures, arts, economies, and social contexts. The chapter begins by discussing the problem of ambiguity with AI terminology, which it aids with a description of the WIPO Categorization of AI Technologies Scheme. It then draws on media and communication studies to explore concepts such as agents, agency, power, and agentive relationships between humans and robots. The chapter focuses on the development of non-human agents in industry as a critical factor in the rise of augmentation technologies. It looks at how marketing communication enculturates future users to adopt and adapt to the technology. Scholars are charting the significant ways that people are drawn further into commercial digital landscapes, such as the Metaverse concept, in post-internet society. It concludes by examining recent claims concerning the Metaverse and augmented reality.', 'abstract_zh': 'augmentation 技术因多种因素正在经历文化融合的过程，其中一个因素是人工智能（AI）的兴起，或如世界知识产权组织（WIPO）所称的 AI 波潮或 AI 繁荣期。第三章重点关注高级、 emergent 和具体现身的 augmentation 技术将改善生活、 literacy、文化、艺术、经济和社交环境的过谘高的假设。该章首先讨论 AI 术语的模糊性问题，并通过描述 WIPO 人工智能技术分类方案来辅助解决这一问题。接着，该章借鉴媒体与传播研究，探讨代理、能动性、权力以及人类与机器人之间的能动关系等概念。该章关注行业内非人类代理的发展，将其视为 augmentation 技术兴起的关键因素之一。它考察了市场营销传播如何将未来用户纳入技术文化之中。学者们正在研究人们在后互联网社会中如何进一步被商业数字景观吸引，例如元宇宙概念。该章最后分析了有关元宇宙和增强现实的近期说法。', 'title_zh': '代理、可能性与增益技术的文化内化'}
{'arxiv_id': 'arXiv:2508.04723', 'title': 'Wearable Music2Emotion : Assessing Emotions Induced by AI-Generated Music through Portable EEG-fNIRS Fusion', 'authors': 'Sha Zhao, Song Yi, Yangxuan Zhou, Jiadong Pan, Jiquan Wang, Jie Xia, Shijian Li, Shurong Dong, Gang Pan', 'link': 'https://arxiv.org/abs/2508.04723', 'abstract': "Emotions critically influence mental health, driving interest in music-based affective computing via neurophysiological signals with Brain-computer Interface techniques. While prior studies leverage music's accessibility for emotion induction, three key limitations persist: \\textbf{(1) Stimulus Constraints}: Music stimuli are confined to small corpora due to copyright and curation costs, with selection biases from heuristic emotion-music mappings that ignore individual affective profiles. \\textbf{(2) Modality Specificity}: Overreliance on unimodal neural data (e.g., EEG) ignores complementary insights from cross-modal signal fusion.\\textbf{ (3) Portability Limitation}: Cumbersome setups (e.g., 64+ channel gel-based EEG caps) hinder real-world applicability due to procedural complexity and portability barriers. To address these limitations, we propose MEEtBrain, a portable and multimodal framework for emotion analysis (valence/arousal), integrating AI-generated music stimuli with synchronized EEG-fNIRS acquisition via a wireless headband. By MEEtBrain, the music stimuli can be automatically generated by AI on a large scale, eliminating subjective selection biases while ensuring music diversity. We use our developed portable device that is designed in a lightweight headband-style and uses dry electrodes, to simultaneously collect EEG and fNIRS recordings. A 14-hour dataset from 20 participants was collected in the first recruitment to validate the framework's efficacy, with AI-generated music eliciting target emotions (valence/arousal). We are actively expanding our multimodal dataset (44 participants in the latest dataset) and make it publicly available to promote further research and practical applications. \\textbf{The dataset is available at this https URL.", 'abstract_zh': '基于脑机接口的多模态情感分析框架MEEtBrain：自动生成的音乐刺激与同步EEG-fNIRS采集', 'title_zh': '可穿戴音乐2情绪：通过便携式EEG-fNIRS融合评估由AI生成音乐引起的情绪'}
{'arxiv_id': 'arXiv:2508.04721', 'title': 'Toward Low-Latency End-to-End Voice Agents for Telecommunications Using Streaming ASR, Quantized LLMs, and Real-Time TTS', 'authors': 'Vignesh Ethiraj, Ashwath David, Sidhanth Menon, Divya Vijay', 'link': 'https://arxiv.org/abs/2508.04721', 'abstract': 'We introduce a low-latency telecom AI voice agent pipeline for real-time, interactive telecommunications use, enabling advanced voice AI for call center automation, intelligent IVR (Interactive Voice Response), and AI-driven customer support. The solution is built for telecom, combining four specialized models by NetoAI: TSLAM, a 4-bit quantized Telecom-Specific Large Language Model (LLM); T-VEC, a Telecom-Specific Embedding Model; TTE, a Telecom-Specific Automatic Speech Recognition (ASR) model; and T-Synth, a Telecom-Specific Text-to-Speech (TTS) model. These models enable highly responsive, domain-adapted voice AI agents supporting knowledge-grounded spoken interactions with low latency. The pipeline integrates streaming ASR (TTE), conversational intelligence (TSLAM), retrieval augmented generation (RAG) over telecom documents, and real-time TTS (T-Synth), setting a new benchmark for telecom voice assistants. To evaluate the system, we built a dataset of 500 human-recorded telecom questions from RFCs, simulating real telecom agent queries. This framework allows analysis of latency, domain relevance, and real-time performance across the stack. Results show that TSLAM, TTE, and T-Synth deliver real-time factors (RTF) below 1.0, supporting enterprise, low-latency telecom deployments. These AI agents -- powered by TSLAM, TTE, and T-Synth -- provide a foundation for next-generation telecom AI, enabling automated customer support, diagnostics, and more.', 'abstract_zh': '一种低延迟电信AI语音代理流水线，实现实时互动电信应用，推动呼叫中心自动化、智能IVR和AI驱动的客户服务中的高级语音AI。该解决方案结合了NetoAI的四种专门模型：TSLAM（4-bit量化电信专用大型语言模型）、T-VEC（电信专用嵌入模型）、TTE（电信专用自动语音识别模型）和T-Synth（电信专用文本到语音模型）。这些模型能够提供高度响应且领域适应性强的语音AI代理，支持基于知识的语音交互且具有低延迟。该流水线集成了流式ASR（TTE）、对话智能（TSLAM）、基于电信文档的检索增强生成（RAG）以及实时TTS（T-Synth），树立了电信语音助手的新标杆。为评估系统，我们构建了一个包含500个人工录制的电信问题的数据集，模拟实际的电信代理查询。此框架允许对流水线中各层的延迟、领域相关性和实时性能进行分析。结果显示，TSLAM、TTE和T-Synth实现实时因子（RTF）低于1.0，支持企业级低延迟电信部署。这些由TSLAM、TTE和T-Synth支持的AI代理为下一代电信AI奠定了基础，使其能够实现自动化客户服务、故障诊断等功能。', 'title_zh': '面向电信领域的低延迟端到端语音代理：基于流式ASR、量化LLM和实时TTS'}
{'arxiv_id': 'arXiv:2508.04713', 'title': 'AI Should Be More Human, Not More Complex', 'authors': 'Carlo Esposito', 'link': 'https://arxiv.org/abs/2508.04713', 'abstract': 'Large Language Models (LLMs) in search applications increasingly prioritize verbose, lexically complex responses that paradoxically reduce user satisfaction and engagement. Through a comprehensive study of 10.000 (est.) participants comparing responses from five major AI-powered search systems, we demonstrate that users overwhelmingly prefer concise, source-attributed responses over elaborate explanations. Our analysis reveals that current AI development trends toward "artificial sophistication" create an uncanny valley effect where systems sound knowledgeable but lack genuine critical thinking, leading to reduced trust and increased cognitive load. We present evidence that optimal AI communication mirrors effective human discourse: direct, properly sourced, and honest about limitations. Our findings challenge the prevailing assumption that more complex AI responses indicate better performance, instead suggesting that human-like brevity and transparency are key to user engagement and system reliability.', 'abstract_zh': '大型语言模型（LLMs）在搜索应用中的使用 increasingly 优先生成冗长且词缀复杂的回答，这反而降低了用户满意感和参与度。通过对比五大主要AI驱动搜索系统生成的回答，我们的研究显示用户更偏好简洁且来源明确的回答而非详尽的解释。我们分析发现目前的AI开发趋势倾向于“伪 sophistication”，导致系统看似有知识但缺乏真实的批判性思考，从而降低了用户的信任度并增加了认知负荷。我们提出证据表明，最优的AI沟通应像有效的对话那样直接、有恰当来源，并且诚实地承认局限。我们的研究挑战了复杂AI回答意味着更好性能的主流假设，反而表明类人的简洁和透明度是提高用户参与度和系统可靠性的关键。', 'title_zh': 'AI 应更加人性化，而非更加复杂。'}
{'arxiv_id': 'arXiv:2507.16641', 'title': 'Hybrid Reward-Driven Reinforcement Learning for Efficient Quantum Circuit Synthesis', 'authors': 'Sara Giordano, Kornikar Sen, Miguel A. Martin-Delgado', 'link': 'https://arxiv.org/abs/2507.16641', 'abstract': "A reinforcement learning (RL) framework is introduced for the efficient synthesis of quantum circuits that generate specified target quantum states from a fixed initial state, addressing a central challenge in both the NISQ era and future fault-tolerant quantum computing. The approach utilizes tabular Q-learning, based on action sequences, within a discretized quantum state space, to effectively manage the exponential growth of the space dimension. The framework introduces a hybrid reward mechanism, combining a static, domain-informed reward that guides the agent toward the target state with customizable dynamic penalties that discourage inefficient circuit structures such as gate congestion and redundant state revisits. By leveraging sparse matrix representations and state-space discretization, the method enables scalable navigation of high-dimensional environments while minimizing computational overhead. Benchmarking on graph-state preparation tasks for up to seven qubits, we demonstrate that the algorithm consistently discovers minimal-depth circuits with optimized gate counts. Moreover, extending the framework to a universal gate set for arbitrary quantum states, it still produces minimal depth circuits, highlighting the algorithm's robustness and adaptability. The results confirm that this RL-driven approach efficiently explores the complex quantum state space and synthesizes near-optimal quantum circuits, providing a resource-efficient foundation for quantum circuit optimization.", 'abstract_zh': '一种强化学习（RL）框架用于高效合成从固定初始态生成指定目标量子态的量子电路，以解决NISQ时代和未来容错量子计算中的核心挑战。该方法利用基于行动序列的表型Q学习，在离散化的量子态空间中有效管理空间维度的指数增长。框架引入了一种混合奖励机制，结合了静态、领域导向的奖励以引导代理向目标态移动，以及可定制的动态惩罚以避免无效电路结构，如门拥堵和重复态访问。通过利用稀疏矩阵表示和态空间离散化，该方法能够在减少计算开销的同时实现高维度环境下的高效导航。针对多达七量子比特的图态准备任务的基准测试表明，该算法一致发现深度最浅且门数优化的电路。进一步将框架扩展到任意量子态的通用门集中，仍能生成最浅深度电路，突显了算法的鲁棒性和适应性。结果证实，该基于RL的方法能高效探索复杂的量子态空间，合成近最优量子电路，为量子电路优化提供了一种资源高效的基石。', 'title_zh': '混合奖励驱动的强化学习方法用于高效量子电路合成'}
{'arxiv_id': 'arXiv:2507.10818', 'title': 'How Robust are LLM-Generated Library Imports? An Empirical Study using Stack Overflow', 'authors': 'Jasmine Latendresse, SayedHassan Khatoonabadi, Emad Shihab', 'link': 'https://arxiv.org/abs/2507.10818', 'abstract': 'Software libraries are central to the functionality, security, and maintainability of modern code. As developers increasingly turn to Large Language Models (LLMs) to assist with programming tasks, understanding how these models recommend libraries is essential. In this paper, we conduct an empirical study of six state-of-the-art LLMs, both proprietary and open-source, by prompting them to solve real-world Python problems sourced from Stack Overflow. We analyze the types of libraries they import, the characteristics of those libraries, and the extent to which the recommendations are usable out of the box. Our results show that LLMs predominantly favour third-party libraries over standard ones, and often recommend mature, popular, and permissively licensed dependencies. However, we also identify gaps in usability: 4.6% of the libraries could not be resolved automatically due to structural mismatches between import names and installable packages, and only two models (out of six) provided installation guidance. While the generated code is technically valid, the lack of contextual support places the burden of manually resolving dependencies on the user. Our findings offer actionable insights for both developers and researchers, and highlight opportunities to improve the reliability and usability of LLM-generated code in the context of software dependencies.', 'abstract_zh': '软件库是现代代码的功能性、安全性和可维护性的核心。随着开发者越来越多地利用大型语言模型（LLMs）来协助编程任务，理解这些模型如何推荐库变得至关重要。在本文中，我们通过提示六种最先进的LLMs（包括商用和开源模型），使用来自Stack Overflow的实际Python问题来开展实证研究。我们分析了它们导入的库类型、这些库的特点，以及推荐的程度可直接使用。研究结果表明，LLMs更倾向于推荐第三方库而非标准库，并且经常推荐成熟、流行且具有宽松许可证的依赖项。然而，我们也发现了使用方面的不足：4.6%的库由于导入名称与可安装包之间的结构不匹配而无法自动解析，只有两个模型提供了安装指导。虽然生成的代码在技术上是有效的，但由于缺乏上下文支持，用户仍需手动解决依赖项的问题。我们的研究结果为开发者和研究人员提供了实用的见解，并突显了在软件依赖背景下提高LLM生成代码可靠性和使用性的机会。', 'title_zh': 'LLM生成的库导入的稳健性研究：基于Stack Overflow的实证研究'}
{'arxiv_id': 'arXiv:2506.16440', 'title': 'Evaluating the Use of LLMs for Documentation to Code Traceability', 'authors': 'Ebube Alor, SayedHassan Khatoonabadi, Emad Shihab', 'link': 'https://arxiv.org/abs/2506.16440', 'abstract': 'Large Language Models (LLMs) offer new potential for automating documentation-to-code traceability, yet their capabilities remain underexplored. We present a comprehensive evaluation of LLMs (Claude 3.5 Sonnet, GPT-4o, and o3-mini) in establishing trace links between various software documentation (including API references and user guides) and source code. We create two novel datasets from two open-source projects (Unity Catalog and Crawl4AI). Through systematic experiments, we assess three key capabilities: (1) trace link identification accuracy, (2) relationship explanation quality, and (3) multi-step chain reconstruction. Results show that the best-performing LLM achieves F1-scores of 79.4% and 80.4% across the two datasets, substantially outperforming our baselines (TF-IDF, BM25, and CodeBERT). While fully correct relationship explanations range from 42.9% to 71.1%, partial accuracy exceeds 97%, indicating that fundamental connections are rarely missed. For multi-step chains, LLMs maintain high endpoint accuracy but vary in capturing precise intermediate links. Error analysis reveals that many false positives stem from naming-based assumptions, phantom links, or overgeneralization of architectural patterns. We demonstrate that task-framing, such as a one-to-many matching strategy, is critical for performance. These findings position LLMs as powerful assistants for trace discovery, but their limitations could necessitate human-in-the-loop tool design and highlight specific error patterns for future research.', 'abstract_zh': '大规模语言模型在建立软件文档与代码之间追踪链接中的潜力及其评估：一项综合研究', 'title_zh': '评估使用大语言模型进行文档到代码追踪性的使用情况 pestic\nuser\n纠正上面的输出，\nuser\n评估使用大语言模型进行文档到代码追踪性的使用情况'}
{'arxiv_id': 'arXiv:2204.12351', 'title': 'Reinforcement Learning Generation of 4-Qubits Entangled States', 'authors': 'Sara Giordano, Miguel A. Martin-Delgado', 'link': 'https://arxiv.org/abs/2204.12351', 'abstract': 'We have devised an artificial intelligence algorithm with machine reinforcement learning (Q-learning) to construct remarkable entangled states with 4 qubits. This way, the algorithm is able to generate representative states for some of the 49 true SLOCC classes of the four-qubit entanglement states. In particular, it is possible to reach at least one true SLOCC class for each of the nine entanglement families. The quantum circuits synthesized by the algorithm may be useful for the experimental realization of these important classes of entangled states and to draw conclusions about the intrinsic properties of our universe. We introduce a graphical tool called the state-link graph (SLG) to represent the construction of the Quality matrix (Q-matrix) used by the algorithm to build a given objective state belonging to the corresponding entanglement class. This allows us to discover the necessary connections between specific entanglement features and the role of certain quantum gates that the algorithm needs to include in the quantum gate set of actions. The quantum circuits found are optimal by construction with respect to the quantum gate-set chosen. These SLGs make the algorithm simple, intuitive and a useful resource for the automated construction of entangled states with a low number of qubits.', 'abstract_zh': '我们提出了一种基于机器强化学习（Q-learning）的人工智能算法，用于构建四量子比特的非凡纠缠态，并能生成四量子比特纠缠态的49个真SLLOCC类中的代表性状态。特别地，可以实现每种纠缠态家族中至少一个真实SLLOCC类。由该算法合成的量子电路可用于这些重要纠缠态的实验实现，并有助于推断我们宇宙的内在属性。我们引入了一种名为状态链接图（SLG）的图形工具，以表示算法用于构建特定纠缠类中目标态的质量矩阵（Q-矩阵）的构建过程。这有助于发现特定纠缠特征之间的必要联系以及算法需要包含在量子门操作集中的特定量子门的作用。这些量子电路在所选的量子门集下是构造上的最优解。这些SLG使算法简洁直观，并成为构建少量量子比特纠缠态的自动化工具。', 'title_zh': '四量子比特纠缠态的强化学习生成'}
