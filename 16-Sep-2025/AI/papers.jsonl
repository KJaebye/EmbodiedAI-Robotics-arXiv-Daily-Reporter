{'arxiv_id': 'arXiv:2509.12194', 'title': 'Advancing Medical Artificial Intelligence Using a Century of Cases', 'authors': 'Thomas A. Buckley, Riccardo Conci, Peter G. Brodeur, Jason Gusdorf, Sourik Beltrán, Bita Behrouzi, Byron Crowe, Jacob Dockterman, Muzzammil Muhammad, Sarah Ohnigian, Andrew Sanchez, James A. Diao, Aashna P. Shah, Daniel Restrepo, Eric S. Rosenberg, Andrew S. Lea, Marinka Zitnik, Scott H. Podolsky, Zahir Kanjee, Raja-Elie E. Abdulnour, Jacob M. Koshy, Adam Rodman, Arjun K. Manrai', 'link': 'https://arxiv.org/abs/2509.12194', 'abstract': 'BACKGROUND: For over a century, the New England Journal of Medicine Clinicopathological Conferences (CPCs) have tested the reasoning of expert physicians and, recently, artificial intelligence (AI). However, prior AI evaluations have focused on final diagnoses without addressing the multifaceted reasoning and presentation skills required of expert discussants.\nMETHODS: Using 7102 CPCs (1923-2025) and 1021 Image Challenges (2006-2025), we conducted extensive physician annotation and automated processing to create CPC-Bench, a physician-validated benchmark spanning 10 text-based and multimodal tasks, against which we evaluated leading large language models (LLMs). Then, we developed "Dr. CaBot," an AI discussant designed to produce written and slide-based video presentations using only the case presentation, modeling the role of the human expert in these cases.\nRESULTS: When challenged with 377 contemporary CPCs, o3 (OpenAI) ranked the final diagnosis first in 60% of cases and within the top ten in 84% of cases, outperforming a 20-physician baseline; next-test selection accuracy reached 98%. Event-level physician annotations quantified AI diagnostic accuracy per unit of information. Performance was lower on literature search and image tasks; o3 and Gemini 2.5 Pro (Google) achieved 67% accuracy on image challenges. In blinded comparisons of CaBot vs. human expert-generated text, physicians misclassified the source of the differential in 46 of 62 (74%) of trials, and scored CaBot more favorably across quality dimensions. To promote research, we are releasing CaBot and CPC-Bench.\nCONCLUSIONS: LLMs exceed physician performance on complex text-based differential diagnosis and convincingly emulate expert medical presentations, but image interpretation and literature retrieval remain weaker. CPC-Bench and CaBot may enable transparent and continued tracking of progress in medical AI.', 'abstract_zh': '背景：百年来，New England Journal of Medicine的临床病理讨论会（CPCs）一直测试着专家医师的推理能力和近期的人工智能（AI）的能力。然而，之前的AI评估大多集中在最终诊断上，而没有涉及专家讨论者所必需的多方面推理和 Presentation 技能。\n方法：利用1923年至2025年的7102次CPCs和2006年至2025年的1021个影像挑战，我们进行了广泛的医师注释和自动化处理，构建了CPC-Bench，这是一个涵盖10项文本和多模态任务的医师验证基准，用于评估领先的大语言模型（LLMs）。然后，我们开发了“Dr. CaBot”，一个仅基于病例展示即可生成书面和幻灯片视频演示的AI讨论者，模拟这些病例中的人类专家角色。\n结果：面对377个现代CPCs的挑战，o3（OpenAI）在60%的情况下将最终诊断排名第一，在84%的情况下位居前十，超越了20名医师的基准；二次测试选择准确率达到了98%。事件级别的医师注释量化了AI诊断的准确性，每单位信息的准确度。在文献搜索和影像任务方面，性能较低；o3和Gemini 2.5 Pro（Google）在影像挑战方面的准确率为67%。在盲测中，CaBot与人类专家生成的文字比较，医师在62次试验中有46次（74%）错误地分类了差异来源，并且在质量维度上对CaBot的评价更为积极。为了促进研究，我们正在释放CaBot和CPC-Bench。\n结论：大语言模型在复杂文本基于的鉴别诊断方面超过了医师的表现，并且能令人信服地模拟专家医疗展示，但在影像解释和文献检索方面仍较弱。CPC-Bench和CaBot有可能促进透明并持续跟踪医学AI的进步。', 'title_zh': '利用百年病例推动医疗人工智能发展'}
{'arxiv_id': 'arXiv:2509.12179', 'title': 'Co-Alignment: Rethinking Alignment as Bidirectional Human-AI Cognitive Adaptation', 'authors': 'Yubo Li, Weiyi Song', 'link': 'https://arxiv.org/abs/2509.12179', 'abstract': 'Current AI alignment through RLHF follows a single directional paradigm that AI conforms to human preferences while treating human cognition as fixed. We propose a shift to co-alignment through Bidirectional Cognitive Alignment (BiCA), where humans and AI mutually adapt. BiCA uses learnable protocols, representation mapping, and KL-budget constraints for controlled co-evolution. In collaborative navigation, BiCA achieved 85.5% success versus 70.3% baseline, with 230% better mutual adaptation and 332% better protocol convergence. Emergent protocols outperformed handcrafted ones by 84%, while bidirectional adaptation unexpectedly improved safety (+23% out-of-distribution robustness). The 46% synergy improvement demonstrates optimal collaboration exists at the intersection, not union, of human and AI capabilities, validating the shift from single-directional to co-alignment paradigms.', 'abstract_zh': '当前通过RLHF实现AI对齐遵循单向范式，其中AI遵从人类偏好而将人类认知视为固定不变。我们提出转向双向认知对齐（BiCA）范式，其中人类和AI相互适应。BiCA使用可学习的协议、表示映射和KL预算约束来实现受控共生进化。在协作导航中，BiCA的成功率达到了85.5%，而基线为70.3%，显示出230%更好的相互适应和332%更好的协议收敛。自动生成的协议在性能上比手工设计的协议高出84%，而双向适应意外地提高了安全性（分布外鲁棒性提高23%）。46%的协同效应改善证明了人类和AI能力的最佳协作存在于两者的交集而非并集中，验证了从单向范式转向双向对齐范式的转变。', 'title_zh': '共适应：重新思考 alignment 为双向人类-AI认知适应'}
{'arxiv_id': 'arXiv:2509.12104', 'title': 'JustEva: A Toolkit to Evaluate LLM Fairness in Legal Knowledge Inference', 'authors': 'Zongyue Xue, Siyuan Zheng, Shaochun Wang, Yiran Hu, Shenran Wang, Yuxin Yao, Haitao Li, Qingyao Ai, Yiqun Liu, Yun Liu, Weixing Shen', 'link': 'https://arxiv.org/abs/2509.12104', 'abstract': 'The integration of Large Language Models (LLMs) into legal practice raises pressing concerns about judicial fairness, particularly due to the nature of their "black-box" processes. This study introduces JustEva, a comprehensive, open-source evaluation toolkit designed to measure LLM fairness in legal tasks. JustEva features several advantages: (1) a structured label system covering 65 extra-legal factors; (2) three core fairness metrics - inconsistency, bias, and imbalanced inaccuracy; (3) robust statistical inference methods; and (4) informative visualizations. The toolkit supports two types of experiments, enabling a complete evaluation workflow: (1) generating structured outputs from LLMs using a provided dataset, and (2) conducting statistical analysis and inference on LLMs\' outputs through regression and other statistical methods. Empirical application of JustEva reveals significant fairness deficiencies in current LLMs, highlighting the lack of fair and trustworthy LLM legal tools. JustEva offers a convenient tool and methodological foundation for evaluating and improving algorithmic fairness in the legal domain.', 'abstract_zh': 'Large Language Models (LLMs)在法律实践中的集成引发了关于司法公平性的紧迫关切，特别是由于它们“黑箱”过程的性质。本研究介绍了JustEva，一个全面的开源评估工具包，旨在衡量LLM在法律任务中的公平性。JustEva具有以下优点：（1）涵盖65个非法律因素的结构化标签系统；（2）三个核心公平性指标——不一致性、偏差和不平衡不准确；（3）稳健的统计推断方法；以及（4）信息性可视化。该工具包支持两种类型的实验，能够完成完整的评估工作流程：（1）使用提供的数据集从LLM生成结构化输出，（2）通过回归和其他统计方法对LLM输出进行统计分析和推断。JustEva的实际应用揭示了当前LLM存在的显著公平性缺陷，强调了缺乏公平可靠的LLM法律工具的问题。JustEva为评估和改善法律领域的算法公平性提供了便捷的工具和方法论基础。', 'title_zh': 'JustEva: 一个评估法律知识推理中LLM公平性的工具包'}
{'arxiv_id': 'arXiv:2509.12091', 'title': 'Bridging Engineering and AI Planning through Model-Based Knowledge Transformation for the Validation of Automated Production System Variants', 'authors': 'Hamied Nabizada, Lasse Beers, Alain Chahine, Felix Gehlhoff, Oliver Niggemann, Alexander Fay', 'link': 'https://arxiv.org/abs/2509.12091', 'abstract': 'Engineering models created in Model-Based Systems Engineering (MBSE) environments contain detailed information about system structure and behavior. However, they typically lack symbolic planning semantics such as preconditions, effects, and constraints related to resource availability and timing. This limits their ability to evaluate whether a given system variant can fulfill specific tasks and how efficiently it performs compared to alternatives.\nTo address this gap, this paper presents a model-driven method that enables the specification and automated generation of symbolic planning artifacts within SysML-based engineering models. A dedicated SysML profile introduces reusable stereotypes for core planning constructs. These are integrated into existing model structures and processed by an algorithm that generates a valid domain file and a corresponding problem file in Planning Domain Definition Language (PDDL). In contrast to previous approaches that rely on manual transformations or external capability models, the method supports native integration and maintains consistency between engineering and planning artifacts.\nThe applicability of the method is demonstrated through a case study from aircraft assembly. The example illustrates how existing engineering models are enriched with planning semantics and how the proposed workflow is applied to generate consistent planning artifacts from these models. The generated planning artifacts enable the validation of system variants through AI planning.', 'abstract_zh': '基于模型的系统工程环境中构建的工程模型包含系统的详细结构和行为信息，但通常缺乏与资源可用性和时间相关的前提、效果和约束等符号规划语义。这限制了它们评估给定系统变体是否能执行特定任务及其相对于替代方案的高效性的能力。\n\n为解决这一问题，本文提出了一种模型驱动的方法，能够在SysML基础的工程模型中指定和自动生成符号规划元素。一种专用的SysML配置文件引入了可重用的核心规划构造体模形。这些模形被集成到现有的模型结构中，并由算法生成有效的领域文件和相应的规划域定义语言(PDDL)问题文件。与依赖于手动转换或外部能力模型的先前方法不同，该方法支持原生集成，并保持工程和规划元素的一致性。\n\n该方法的应用通过一架飞机装配的案例研究进行演示。示例说明了如何利用现有工程模型来增强规划语义，并展示了如何应用提出的工作流从这些模型中生成一致的规划元素。生成的规划元素通过AI规划来验证系统变体。', 'title_zh': '通过基于模型的知识转换桥梁工程与AI规划以验证自动化生产系统变体'}
{'arxiv_id': 'arXiv:2509.12060', 'title': 'When Safe Unimodal Inputs Collide: Optimizing Reasoning Chains for Cross-Modal Safety in Multimodal Large Language Models', 'authors': 'Wei Cai, Shujuan Liu, Jian Zhao, Ziyan Shi, Yusheng Zhao, Yuchen Yuan, Tianle Zhang, Chi Zhang, Xuelong Li', 'link': 'https://arxiv.org/abs/2509.12060', 'abstract': "Multimodal Large Language Models (MLLMs) are susceptible to the implicit reasoning risk, wherein innocuous unimodal inputs synergistically assemble into risky multimodal data that produce harmful outputs. We attribute this vulnerability to the difficulty of MLLMs maintaining safety alignment through long-chain reasoning. To address this issue, we introduce Safe-Semantics-but-Unsafe-Interpretation (SSUI), the first dataset featuring interpretable reasoning paths tailored for such a cross-modal challenge. A novel training framework, Safety-aware Reasoning Path Optimization (SRPO), is also designed based on the SSUI dataset to align the MLLM's internal reasoning process with human safety values. Experimental results show that our SRPO-trained models achieve state-of-the-art results on key safety benchmarks, including the proposed Reasoning Path Benchmark (RSBench), significantly outperforming both open-source and top-tier commercial MLLMs.", 'abstract_zh': '多模态大型语言模型（MLLMs）容易受到隐式推理风险的威胁，其中无害的单模态输入在多模态数据中协同组装，产生有害的输出。我们将其脆弱性归因于MLLMs在长时间链推理中保持安全对齐的困难。为解决这一问题，我们引入了安全语义但有害解释（SSUI）数据集，这是首个专门为这种跨模态挑战设计的可解释推理路径数据集。基于SSUI数据集，我们还设计了一种新的训练框架——安全意识推理路径优化（SRPO），以使MLLM的内部推理过程与人类的安全价值观保持一致。实验结果表明，我们的SRPO训练模型在关键的安全基准测试中取得了最先进的成果，包括提出的推理路径基准（RSBench），显著优于开源和顶级商用MLLMs。', 'title_zh': '当安全的单模态输入冲突时：优化跨模态安全性的多模态大型语言模型中的推理链'}
{'arxiv_id': 'arXiv:2509.12034', 'title': 'Human-AI Use Patterns for Decision-Making in Disaster Scenarios: A Systematic Review', 'authors': 'Emmanuel Adjei Domfeh, Christopher L. Dancy', 'link': 'https://arxiv.org/abs/2509.12034', 'abstract': 'In high-stakes disaster scenarios, timely and informed decision-making is critical yet often challenged by uncertainty, dynamic environments, and limited resources. This paper presents a systematic review of Human-AI collaboration patterns that support decision-making across all disaster management phases. Drawing from 51 peer-reviewed studies, we identify four major categories: Human-AI Decision Support Systems, Task and Resource Coordination, Trust and Transparency, and Simulation and Training. Within these, we analyze sub-patterns such as cognitive-augmented intelligence, multi-agent coordination, explainable AI, and virtual training environments. Our review highlights how AI systems may enhance situational awareness, improves response efficiency, and support complex decision-making, while also surfacing critical limitations in scalability, interpretability, and system interoperability. We conclude by outlining key challenges and future research directions, emphasizing the need for adaptive, trustworthy, and context-aware Human-AI systems to improve disaster resilience and equitable recovery outcomes.', 'abstract_zh': '在高风险灾难场景中，及时且知情的决策至关重要，但往往受到不确定性、动态环境和有限资源的挑战。本文系统回顾了支持灾难管理各个阶段决策的人工智能协作模式。基于51篇同行评审研究，我们识别出四大类别：人机决策支持系统、任务和资源协调、信任与透明度、以及模拟与培训。在这些类别中，我们分析了子模式，如认知增强智能、多智能体协调、可解释人工智能和虚拟培训环境。回顾结果突出了人工智能系统在提高态势感知、提升响应效率、支持复杂决策方面的增强作用，同时也揭示了其在可扩展性、可解释性和系统互操作性方面的关键局限性。最后，我们概述了关键挑战和未来研究方向，强调需要发展适应性强、可信赖且情境意识的人机系统，以提高灾难弹性和公平恢复结果。', 'title_zh': '人类与人工智能在灾害情景决策中的使用模式：一项系统性回顾'}
{'arxiv_id': 'arXiv:2509.11973', 'title': 'MusicSwarm: Biologically Inspired Intelligence for Music Composition', 'authors': 'Markus J. Buehler', 'link': 'https://arxiv.org/abs/2509.11973', 'abstract': 'We show that coherent, long-form musical composition can emerge from a decentralized swarm of identical, frozen foundation models that coordinate via stigmergic, peer-to-peer signals, without any weight updates. We compare a centralized multi-agent system with a global critic to a fully decentralized swarm in which bar-wise agents sense and deposit harmonic, rhythmic, and structural cues, adapt short-term memory, and reach consensus. Across symbolic, audio, and graph-theoretic analyses, the swarm yields superior quality while delivering greater diversity and structural variety and leads across creativity metrics. The dynamics contract toward a stable configuration of complementary roles, and self-similarity networks reveal a small-world architecture with efficient long-range connectivity and specialized bridging motifs, clarifying how local novelties consolidate into global musical form. By shifting specialization from parameter updates to interaction rules, shared memory, and dynamic consensus, MusicSwarm provides a compute- and data-efficient route to long-horizon creative structure that is immediately transferable beyond music to collaborative writing, design, and scientific discovery.', 'abstract_zh': '我们展示了协调的长形式音乐创作可以从一群通过stigmergic、peer-to-peer信号进行协调的去中心化且相同的“冻结”基础模型中 Emerge 出来，而不需要任何权重更新。我们将一个集中式的多Agent系统与全球批评家进行比较，该系统与一个完全去中心化的群体进行对比，在该群体中，小节级别的Agent感知并沉积和弦、节奏和结构暗示，适配短期记忆，并达成共识。在符号、音频和图论分析方面，群体提供了更高的质量同时提供更多样性和结构性变化，并在创造力指标上表现出色。系统动态向互补角色的稳定配置收缩，并且自相似网络揭示了一种小世界架构，具有高效的长程连接和专门化的桥接模式，阐明了局部新颖性如何在音乐结构中巩固。通过从参数更新转向交互规则、共享记忆和动态共识的专门化，MusicSwarm 提供了一条计算和数据高效的路径，以生成长期的创造性结构，并且这种结构可以立即转移到音乐之外的协作写作、设计和科学发现中。', 'title_zh': 'MusicSwarm：受生物启发的音乐创作智能'}
{'arxiv_id': 'arXiv:2509.11944', 'title': 'Agentic Temporal Graph of Reasoning with Multimodal Language Models: A Potential AI Aid to Healthcare', 'authors': 'Susanta Mitra', 'link': 'https://arxiv.org/abs/2509.11944', 'abstract': 'Healthcare and medicine are multimodal disciplines that deal with multimodal data for reasoning and diagnosing multiple diseases. Although some multimodal reasoning models have emerged for reasoning complex tasks in scientific domains, their applications in the healthcare domain remain limited and fall short in correct reasoning for diagnosis. To address the challenges of multimodal medical reasoning for correct diagnosis and assist the healthcare professionals, a novel temporal graph-based reasoning process modelled through a directed graph has been proposed in the current work. It helps in accommodating dynamic changes in reasons through backtracking, refining the reasoning content, and creating new or deleting existing reasons to reach the best recommendation or answer. Again, consideration of multimodal data at different time points can enable tracking and analysis of patient health and disease progression. Moreover, the proposed multi-agent temporal reasoning framework provides task distributions and a cross-validation mechanism to further enhance the accuracy of reasoning outputs. A few basic experiments and analysis results justify the novelty and practical utility of the proposed preliminary approach.', 'abstract_zh': '多模态医疗推理的时间图模型及其在正确诊断中的应用', 'title_zh': '基于多模态语言模型的代理时间推理图形：一种潜在的医疗健康AI辅助工具'}
{'arxiv_id': 'arXiv:2509.11943', 'title': 'Neuro-Symbolic Agents with Modal Logic for Autonomous Diagnostics', 'authors': 'Antonin Sulc, Thorsten Hellert', 'link': 'https://arxiv.org/abs/2509.11943', 'abstract': 'The development of intelligent agents, particularly those powered by language models (LMs), has shown the critical role in various environments that require intelligent and autonomous decision. Environments are not passive testing grounds and they represent the data required for agents to learn and exhibit very challenging conditions that require adaptive, complex and autonomous capacity to make decisions. While the paradigm of scaling models and datasets has led to remarkable emergent capabilities, we argue that scaling the structure, fidelity, and logical consistency of agent reasoning within these environments is a crucial, yet underexplored, dimension of AI research. This paper introduces a neuro-symbolic multi-agent architecture where the belief states of individual agents are formally represented as Kripke models. This foundational choice enables them to reason about known concepts of \\emph{possibility} and \\emph{necessity} using the formal language of modal logic. In this work, we use of immutable, domain-specific knowledge to make infere information, which is encoded as logical constraints essential for proper diagnosis. In the proposed model, we show constraints that actively guide the hypothesis generation of LMs, effectively preventing them from reaching physically or logically untenable conclusions. In a high-fidelity simulated particle accelerator environment, our system successfully diagnoses complex, cascading failures by combining the powerful semantic intuition of LMs with the rigorous, verifiable validation of modal logic and a factual world model and showcasing a viable path toward more robust, reliable, and verifiable autonomous agents.', 'abstract_zh': '基于语言模型的智能代理的发展展示了其在需要智能自主决策的各种环境中的关键作用。环境不仅是被动的测试场所，它们还代表了代理学习所需的必要数据，并且环境中的条件极其挑战性，要求代理具备适应性、复杂性和自主决策能力。虽然模型和数据集的扩展增强了显著的 emergent 能力，但我们认为，在这些环境中扩展代理推理的结构、忠实度和逻辑一致性是人工智能研究中一个关键但尚未充分探索的维度。本文介绍了一种神经符号多代理架构，其中单个代理的信念状态被形式上表示为克里普克模型。这一基础选择使它们能够使用模态逻辑的形式语言来推理关于可能性和必然性的已知概念。在本文中，我们利用不可变的领域特定知识进行推理，这些知识被编码为诊断所需的重要逻辑约束。在所提出模型中，我们展示了约束条件能够积极引导语言模型的假设生成，有效地防止它们得出物理上或逻辑上不可行的结论。在高保真模拟粒子加速器环境中，我们的系统通过结合语言模型的强大语义直觉、模态逻辑的严格可验证验证和事实世界模型，成功诊断了复杂的级联故障，展示了一条通往更 robust、可靠和可验证的自主代理的有效途径。', 'title_zh': '模态逻辑驱动的神经符号代理在自主诊断中的应用'}
{'arxiv_id': 'arXiv:2509.11941', 'title': 'How to Evaluate Medical AI', 'authors': 'Ilia Kopanichuk, Petr Anokhin, Vladimir Shaposhnikov, Vladimir Makharev, Ekaterina Tsapieva, Iaroslav Bespalov, Dmitry V. Dylov, Ivan Oseledets', 'link': 'https://arxiv.org/abs/2509.11941', 'abstract': "The integration of artificial intelligence (AI) into medical diagnostic workflows requires robust and consistent evaluation methods to ensure reliability, clinical relevance, and the inherent variability in expert judgments. Traditional metrics like precision and recall often fail to account for the inherent variability in expert judgments, leading to inconsistent assessments of AI performance. Inter-rater agreement statistics like Cohen's Kappa are more reliable but they lack interpretability. We introduce Relative Precision and Recall of Algorithmic Diagnostics (RPAD and RRAD) - a new evaluation metrics that compare AI outputs against multiple expert opinions rather than a single reference. By normalizing performance against inter-expert disagreement, these metrics provide a more stable and realistic measure of the quality of predicted diagnosis. In addition to the comprehensive analysis of diagnostic quality measures, our study contains a very important side result. Our evaluation methodology allows us to avoid selecting diagnoses from a limited list when evaluating a given case. Instead, both the models being tested and the examiners verifying them arrive at a free-form diagnosis. In this automated methodology for establishing the identity of free-form clinical diagnoses, a remarkable 98% accuracy becomes attainable. We evaluate our approach using 360 medical dialogues, comparing multiple large language models (LLMs) against a panel of physicians. Large-scale study shows that top-performing models, such as DeepSeek-V3, achieve consistency on par with or exceeding expert consensus. Moreover, we demonstrate that expert judgments exhibit significant variability - often greater than that between AI and humans. This finding underscores the limitations of any absolute metrics and supports the need to adopt relative metrics in medical AI.", 'abstract_zh': "将人工智能集成到医疗诊断工作流程中需要 robust 和一致的评估方法以确保可靠性、临床相关性以及专家判断的固有变异。传统的精确度和召回率等评价指标往往无法考虑专家判断的固有变异，导致对人工智能性能的一致性评估失效。Cohen's Kappa等评分者一致性统计指标更可靠，但缺乏可解释性。我们引入了算法诊断的相对精确度和召回率（RPAD和RRAD）——一种新的评价指标，将人工智能输出与多种专家意见进行比较，而非单一参考。通过正常化性能以消除专家间分歧，这些指标提供了更稳定和现实的预测诊断质量衡量标准。除了全面分析诊断质量指标外，我们的研究还包括一个非常重要的附带结果。我们的评价方法使我们在评估某一病例时避免从有限的诊断列表中选择诊断。相反，测试中的模型和验证者均得出自由格式的诊断。在这种自动建立自由格式临床诊断身份的方法中，98%的准确性变得可实现。我们使用360份医疗对话评估了该方法，将多种大型语言模型（LLMs）与一组医生进行了对比。大规模研究表明，表现最佳的模型，如DeepSeek-V3，在一致性方面达到或超过了专家共识。此外，我们证明了专家判断存在显著差异——通常大于人工智能与人类之间的差异。这一发现凸显了任何绝对指标的局限性，并支持在医疗人工智能中采用相对评价指标的必要性。", 'title_zh': '如何评价医疗人工智能'}
{'arxiv_id': 'arXiv:2509.11940', 'title': 'Neuromorphic Intelligence', 'authors': 'Marcel van Gerven', 'link': 'https://arxiv.org/abs/2509.11940', 'abstract': 'Neuromorphic computing seeks to replicate the remarkable efficiency, flexibility, and adaptability of the human brain in artificial systems. Unlike conventional digital approaches, which depend on massive computational and energy resources, neuromorphic systems exploit brain-inspired principles of computation to achieve orders of magnitude greater energy efficiency. By drawing on insights from artificial intelligence, neuroscience, physics, chemistry, and materials science, neuromorphic computing promises to deliver intelligent systems that are sustainable, transparent, and widely accessible. A central challenge, however, is to identify a unifying theoretical framework capable of bridging these diverse disciplines. We argue that dynamical systems theory provides such a foundation. Rooted in differential calculus, it offers a principled language for modeling inference, learning, and control in both natural and artificial substrates. Within this framework, noise can be harnessed as a resource for learning, while differential genetic programming enables the discovery of dynamical systems that implement adaptive behaviors. Embracing this perspective paves the way toward emergent neuromorphic intelligence, where intel- ligent behavior arises from the dynamics of physical substrates, advancing both the science and sustainability of AI.', 'abstract_zh': '神经形态计算旨在复制人类大脑在人工系统中的卓越效率、灵活性和适应性。与依赖庞大计算和能源资源的传统数字方法不同，神经形态系统利用神经启发的计算原则，实现了数量级的能源效率提升。通过借鉴人工智能、神经科学、物理学、化学和材料科学的见解，神经形态计算有望提供可持续、透明且普及的智能系统。然而，一个核心挑战是识别一种能够跨这些学科提供统一理论框架的方法。我们认为，动力系统理论正是这样的基础。根植于微分 calculus，它提供了一种原则性的语言来建模自然和人工子体中的推断、学习和控制。在这种框架内，噪声可以作为一种学习资源被利用，而微分遗传编程则使发现实现适应性行为的动力系统成为可能。采纳这一视角为新兴的神经形态智能铺平了道路，在这种智能中，智能行为来源于物理子体的动力学，从而推动了人工智能的科学与可持续性。', 'title_zh': '神经形态智能'}
{'arxiv_id': 'arXiv:2509.11922', 'title': 'BuildingGym: An open-source toolbox for AI-based building energy management using reinforcement learning', 'authors': 'Xilei Dai, Ruotian Chen, Songze Guan, Wen-Tai Li, Chau Yuen', 'link': 'https://arxiv.org/abs/2509.11922', 'abstract': 'Reinforcement learning (RL) has proven effective for AI-based building energy management. However, there is a lack of flexible framework to implement RL across various control problems in building energy management. To address this gap, we propose BuildingGym, an open-source tool designed as a research-friendly and flexible framework for training RL control strategies for common challenges in building energy management. BuildingGym integrates EnergyPlus as its core simulator, making it suitable for both system-level and room-level control. Additionally, BuildingGym is able to accept external signals as control inputs instead of taking the building as a stand-alone entity. This feature makes BuildingGym applicable for more flexible environments, e.g. smart grid and EVs community. The tool provides several built-in RL algorithms for control strategy training, simplifying the process for building managers to obtain optimal control strategies. Users can achieve this by following a few straightforward steps to configure BuildingGym for optimization control for common problems in the building energy management field. Moreover, AI specialists can easily implement and test state-of-the-art control algorithms within the platform. BuildingGym bridges the gap between building managers and AI specialists by allowing for the easy configuration and replacement of RL algorithms, simulators, and control environments or problems. With BuildingGym, we efficiently set up training tasks for cooling load management, targeting both constant and dynamic cooling load management. The built-in algorithms demonstrated strong performance across both tasks, highlighting the effectiveness of BuildingGym in optimizing cooling strategies.', 'abstract_zh': '基于 reinforcement learning 的楼宇能源管理灵活框架：BuildingGym', 'title_zh': 'BuildingGym: 基于强化学习的建筑能源管理AI工具箱'}
{'arxiv_id': 'arXiv:2509.11914', 'title': 'EgoMem: Lifelong Memory Agent for Full-duplex Omnimodal Models', 'authors': 'Yiqun Yao, Naitong Yu, Xiang Li, Xin Jiang, Xuezhi Fang, Wenjia Ma, Xuying Meng, Jing Li, Aixin Sun, Yequan Wang', 'link': 'https://arxiv.org/abs/2509.11914', 'abstract': "We introduce EgoMem, the first lifelong memory agent tailored for full-duplex models that process real-time omnimodal streams. EgoMem enables real-time models to recognize multiple users directly from raw audiovisual streams, to provide personalized response, and to maintain long-term knowledge of users' facts, preferences, and social relationships extracted from audiovisual history. EgoMem operates with three asynchronous processes: (i) a retrieval process that dynamically identifies user via face and voice, and gathers relevant context from a long-term memory; (ii) an omnimodal dialog process that generates personalized audio responses based on the retrieved context; and (iii) a memory management process that automatically detects dialog boundaries from omnimodal streams, and extracts necessary information to update the long-term memory. Unlike existing memory agents for LLMs, EgoMem relies entirely on raw audiovisual streams, making it especially suitable for lifelong, real-time, and embodied scenarios. Experimental results demonstrate that EgoMem's retrieval and memory management modules achieve over 95% accuracy on the test set. When integrated with a fine-tuned RoboEgo omnimodal chatbot, the system achieves fact-consistency scores above 87% in real-time personalized dialogs, establishing a strong baseline for future research.", 'abstract_zh': 'EgoMem：面向全双工模型的实时多模态记忆代理', 'title_zh': 'EgoMem: 全双工 omnimodal 模型的终身记忆代理'}
{'arxiv_id': 'arXiv:2509.11880', 'title': 'Learning Representations in Video Game Agents with Supervised Contrastive Imitation Learning', 'authors': 'Carlos Celemin, Joseph Brennan, Pierluigi Vito Amadori, Tim Bradley', 'link': 'https://arxiv.org/abs/2509.11880', 'abstract': 'This paper introduces a novel application of Supervised Contrastive Learning (SupCon) to Imitation Learning (IL), with a focus on learning more effective state representations for agents in video game environments. The goal is to obtain latent representations of the observations that capture better the action-relevant factors, thereby modeling better the cause-effect relationship from the observations that are mapped to the actions performed by the demonstrator, for example, the player jumps whenever an obstacle appears ahead. We propose an approach to integrate the SupCon loss with continuous output spaces, enabling SupCon to operate without constraints regarding the type of actions of the environment. Experiments on the 3D games Astro Bot and Returnal, and multiple 2D Atari games show improved representation quality, faster learning convergence, and better generalization compared to baseline models trained only with supervised action prediction loss functions.', 'abstract_zh': '本文介绍了一种将监督对比学习（SupCon）应用于模仿学习（IL）的新颖应用，重点关注在视频游戏环境中为智能体学习更有效的状态表示。目标是获得更能捕捉行动相关因素的潜在表示，从而更好地建模从观察到演示者执行的动作所映射的原因-结果关系，例如，每当出现障碍物时，玩家就会跳跃。本文提出了一种将SupCon损失与连续输出空间集成的方法，使SupCon能够在不受到环境动作类型限制的情况下运行。在3D游戏Astro Bot和Returnal以及多种2D Atari 游戏上的实验结果显示，与仅使用监督动作预测损失函数训练的基础模型相比，该方法能提高表示质量、加快学习收敛速度并更好地泛化。', 'title_zh': '基于监督对比模仿学习的视频游戏代理表示学习'}
{'arxiv_id': 'arXiv:2509.11719', 'title': 'HeLoFusion: An Efficient and Scalable Encoder for Modeling Heterogeneous and Multi-Scale Interactions in Trajectory Prediction', 'authors': 'Bingqing Wei, Lianmin Chen, Zhongyu Xia, Yongtao Wang', 'link': 'https://arxiv.org/abs/2509.11719', 'abstract': 'Multi-agent trajectory prediction in autonomous driving requires a comprehensive understanding of complex social dynamics. Existing methods, however, often struggle to capture the full richness of these dynamics, particularly the co-existence of multi-scale interactions and the diverse behaviors of heterogeneous agents. To address these challenges, this paper introduces HeLoFusion, an efficient and scalable encoder for modeling heterogeneous and multi-scale agent interactions. Instead of relying on global context, HeLoFusion constructs local, multi-scale graphs centered on each agent, allowing it to effectively model both direct pairwise dependencies and complex group-wise interactions (\\textit{e.g.}, platooning vehicles or pedestrian crowds). Furthermore, HeLoFusion tackles the critical challenge of agent heterogeneity through an aggregation-decomposition message-passing scheme and type-specific feature networks, enabling it to learn nuanced, type-dependent interaction patterns. This locality-focused approach enables a principled representation of multi-level social context, yielding powerful and expressive agent embeddings. On the challenging Waymo Open Motion Dataset, HeLoFusion achieves state-of-the-art performance, setting new benchmarks for key metrics including Soft mAP and minADE. Our work demonstrates that a locality-grounded architecture, which explicitly models multi-scale and heterogeneous interactions, is a highly effective strategy for advancing motion forecasting.', 'abstract_zh': '多Agent轨迹预测在自主驾驶中需要全面理解复杂的社交动态。为了应对这一挑战，本文提出了HeLoFusion，一种高效且可扩展的编码器，用于建模异构和多尺度Agent交互。HeLoFusion通过围绕每个Agent构建局部的多尺度图，而不是依赖全局上下文，有效地建模了直接的成对依赖关系和复杂的群体交互（例如车队或行人 crowds）。此外，HeLoFusion通过聚合-分解消息传递方案和类型特定特征网络解决了Agent异构性的关键挑战，使其能够学习精细的、类型依赖的交互模式。这种以局部为中心的方法为多层次的社会背景提供了一个原则性的表示，从而生成强大的且具有表达力的Agent嵌入。在具有挑战性的Waymo Open Motion数据集中，HeLoFusion实现了最先进的性能，为Soft mAP和minADE等关键指标设立了新的基准。我们的研究证明，一个基于局部的架构，明确建模多尺度和异构交互，是一种极具效力的运动预测方法。', 'title_zh': 'HeLoFusion：一种用于建模轨迹预测中异构和多尺度交互的高效可扩展编码器'}
{'arxiv_id': 'arXiv:2509.11645', 'title': 'Adapting and Evaluating Multimodal Large Language Models for Adolescent Idiopathic Scoliosis Self-Management: A Divide and Conquer Framework', 'authors': 'Zhaolong Wu, Pu Luo, Jason Pui Yin Cheung, Teng Zhang', 'link': 'https://arxiv.org/abs/2509.11645', 'abstract': "This study presents the first comprehensive evaluation of Multimodal Large Language Models (MLLMs) for Adolescent Idiopathic Scoliosis (AIS) self-management. We constructed a database of approximately 3,000 anteroposterior X-rays with diagnostic texts and evaluated five MLLMs through a `Divide and Conquer' framework consisting of a visual question-answering task, a domain knowledge assessment task, and a patient education counseling assessment task. Our investigation revealed limitations of MLLMs' ability in interpreting complex spinal radiographs and comprehending AIS care knowledge. To address these, we pioneered enhancing MLLMs with spinal keypoint prompting and compiled an AIS knowledge base for retrieval augmented generation (RAG), respectively. Results showed varying effectiveness of visual prompting across different architectures, while RAG substantially improved models' performances on the knowledge assessment task. Our findings indicate current MLLMs are far from capable in realizing personalized assistant in AIS care. The greatest challenge lies in their abilities to obtain accurate detections of spinal deformity locations (best accuracy: 0.55) and directions (best accuracy: 0.13).", 'abstract_zh': '本研究首次全面评估了多模态大型语言模型（MLLMs）在青少年特发性脊柱侧弯（AIS）自我管理中的应用。我们构建了一个包含约3,000张前后位X光片及其诊断文本的数据库，并通过一个由视觉问答任务、领域知识评估任务和患者教育咨询评估任务组成的“分而治之”框架评估了五种MLLMs。我们的研究揭示了MLLMs在解读复杂脊柱X光片和理解AIS护理知识方面的局限性。为解决上述问题，我们分别提出了脊柱关键点提示增强MLLMs和为检索增强生成（RAG）编纂AIS知识库的方法。结果显示，视觉提示在不同架构下的效果各异，而RAG显著提高了模型在知识评估任务中的表现。研究结果表明，当前的MLLMs在实现AIS护理中的个性化助手方面还远不成熟。最大的挑战在于他们准确检测脊柱畸形位置（最佳准确率：0.55）和方向（最佳准确率：0.13）的能力有限。', 'title_zh': '适用于青少年特发性脊柱侧弯自我管理的多模态大型语言模型的适应与评估：一种分而治之框架'}
{'arxiv_id': 'arXiv:2509.11595', 'title': 'AMLNet: A Knowledge-Based Multi-Agent Framework to Generate and Detect Realistic Money Laundering Transactions', 'authors': 'Sabin Huda, Ernest Foo, Zahra Jadidi, MA Hakim Newton, Abdul Sattar', 'link': 'https://arxiv.org/abs/2509.11595', 'abstract': 'Anti-money laundering (AML) research is constrained by the lack of publicly shareable, regulation-aligned transaction datasets. We present AMLNet, a knowledge-based multi-agent framework with two coordinated units: a regulation-aware transaction generator and an ensemble detection pipeline. The generator produces 1,090,173 synthetic transactions (approximately 0.16\\% laundering-positive) spanning core laundering phases (placement, layering, integration) and advanced typologies (e.g., structuring, adaptive threshold behavior). Regulatory alignment reaches 75\\% based on AUSTRAC rule coverage (Section 4.2), while a composite technical fidelity score of 0.75 summarizes temporal, structural, and behavioral realism components (Section 4.4). The detection ensemble achieves F1 0.90 (precision 0.84, recall 0.97) on the internal test partitions of AMLNet and adapts to the external SynthAML dataset, indicating architectural generalizability across different synthetic generation paradigms. We provide multi-dimensional evaluation (regulatory, temporal, network, behavioral) and release the dataset (Version 1.0, this https URL), to advance reproducible and regulation-conscious AML experimentation.', 'abstract_zh': '基于知识的多代理框架AMLNet及其应用：面向反洗钱的研究', 'title_zh': 'AMLNet：一种基于知识的多代理框架，用于生成和检测现实中的洗钱交易'}
{'arxiv_id': 'arXiv:2509.11575', 'title': 'A Survey of Reasoning and Agentic Systems in Time Series with Large Language Models', 'authors': 'Ching Chang, Yidan Shi, Defu Cao, Wei Yang, Jeehyun Hwang, Haixin Wang, Jiacheng Pang, Wei Wang, Yan Liu, Wen-Chih Peng, Tien-Fu Chen', 'link': 'https://arxiv.org/abs/2509.11575', 'abstract': 'Time series reasoning treats time as a first-class axis and incorporates intermediate evidence directly into the answer. This survey defines the problem and organizes the literature by reasoning topology with three families: direct reasoning in one step, linear chain reasoning with explicit intermediates, and branch-structured reasoning that explores, revises, and aggregates. The topology is crossed with the main objectives of the field, including traditional time series analysis, explanation and understanding, causal inference and decision making, and time series generation, while a compact tag set spans these axes and captures decomposition and verification, ensembling, tool use, knowledge access, multimodality, agent loops, and LLM alignment regimes. Methods and systems are reviewed across domains, showing what each topology enables and where it breaks down in faithfulness or robustness, along with curated datasets, benchmarks, and resources that support study and deployment (this https URL). Evaluation practices that keep evidence visible and temporally aligned are highlighted, and guidance is distilled on matching topology to uncertainty, grounding with observable artifacts, planning for shift and streaming, and treating cost and latency as design budgets. We emphasize that reasoning structures must balance capacity for grounding and self-correction against computational cost and reproducibility, while future progress will likely depend on benchmarks that tie reasoning quality to utility and on closed-loop testbeds that trade off cost and risk under shift-aware, streaming, and long-horizon settings. Taken together, these directions mark a shift from narrow accuracy toward reliability at scale, enabling systems that not only analyze but also understand, explain, and act on dynamic worlds with traceable evidence and credible outcomes.', 'abstract_zh': '时间序列推理将时间视为一级维度，并直接将中间证据纳入答案中。本文综述定义了该领域的问题，并按照推理拓扑结构组织文献，分为三大类：一步直接推理、具有明确中间件的线性链推理以及探索、修订和聚合的分支结构推理。该拓扑结构与领域的主要目标交叉，包括传统的时序分析、解释与理解、因果推断与决策、时序生成，同时采用紧凑的标签集覆盖这些轴，捕捉分解与验证、集成、工具使用、知识访问、多模态、代理循环以及大语言模型对齐模式。本文综述了跨领域的技术和系统，展示了每种拓扑结构的优势以及其在忠实度或鲁棒性方面的局限性，并提供了精选的数据集、基准测试和资源以支持研究与部署。文中突出了保持证据可见性和时序对齐的评估实践，并提炼出匹配拓扑结构与不确定性、基于可观测特征进行定位、计划迁移与流式处理、以及将成本与延迟视为设计预算的指导原则。我们强调，推理结构必须在接地能力和自我纠正能力与计算成本与可重现性之间取得平衡，未来进展可能依赖于将推理质量与实用性连接在一起的基准测试和在迁移感知、流式处理和长时范围设置下权衡成本与风险的闭环试验平台。总体而言，这些方向标志着从狭隘的准确性向大规模可靠性转变，使系统不仅能进行分析，还能理解和解释具有可追溯证据和可信结果的动态世界。', 'title_zh': '大规模语言模型在时间序列中的推理与代理系统综述'}
{'arxiv_id': 'arXiv:2509.11572', 'title': 'Formal Reasoning for Intelligent QA Systems: A Case Study in the Educational Domain', 'authors': 'Tuan Bui, An Nguyen, Phat Thai, Minh Hua, Ngan Pham L.N., Ngan Pham T.B., Dung Le, Long Nguyen, Thanh-Tung Tran, Thang Bui, Tho Quan', 'link': 'https://arxiv.org/abs/2509.11572', 'abstract': 'Reasoning is essential for closed-domain QA systems in which procedural correctness and policy compliance are critical. While large language models (LLMs) have shown strong performance on many reasoning tasks, recent work reveals that their reasoning traces are often unfaithful - serving more as plausible justifications than as causally grounded derivations. Efforts to combine LLMs with symbolic engines (e.g., Prover9, Z3) have improved reliability but remain limited to static forms of logic, struggling with dynamic, state-based reasoning such as multi-step progressions and conditional transitions.\nIn this paper, we propose MCFR (Model Checking for Formal Reasoning), a neuro-symbolic framework that integrates LLMs with model checking to support property verification. MCFR translates natural language into formal specifications and verifies them over transition models. To support evaluation, we introduce EduMC-QA, a benchmark dataset grounded in real academic procedures. Our results show that MCFR improves reasoning faithfulness and interpretability, offering a viable path toward verifiable QA in high-stakes closed-domain applications. In addition to evaluating MCFR, we compare its performance with state-of-the-art LLMs such as ChatGPT, DeepSeek, and Claude to contextualize its effectiveness.', 'abstract_zh': '基于模型检验的神经符号框架：改进形式推理的合理性和可解释性', 'title_zh': '智能问答系统中的形式推理：教育领域的案例研究'}
{'arxiv_id': 'arXiv:2509.11547', 'title': 'Task Decoding based on Eye Movements using Synthetic Data Augmentation', 'authors': 'Shanmuka Sadhu, Arca Baran, Preeti Pandey, Ayush Kumar', 'link': 'https://arxiv.org/abs/2509.11547', 'abstract': "Machine learning has been extensively used in various applications related to eye-tracking research. Understanding eye movement is one of the most significant subsets of eye-tracking research that reveals the scanning pattern of an individual. Researchers have thoroughly analyzed eye movement data to understand various eye-tracking applications, such as attention mechanisms, navigational behavior, task understanding, etc. The outcome of traditional machine learning algorithms used for decoding tasks based on eye movement data has received a mixed reaction to Yarbus' claim that it is possible to decode the observer's task from their eye movements. In this paper, to support the hypothesis by Yarbus, we are decoding tasks categories while generating synthetic data samples using well-known Synthetic Data Generators CTGAN and its variations such as CopulaGAN and Gretel AI Synthetic Data generators on available data from an in-person user study. Our results show that augmenting more eye movement data combined with additional synthetically generated improves classification accuracy even with traditional machine learning algorithms. We see a significant improvement in task decoding accuracy from 28.1% using Random Forest to 82% using Inception Time when five times more data is added in addition to the 320 real eye movement dataset sample. Our proposed framework outperforms all the available studies on this dataset because of the use of additional synthetic datasets. We validated our claim with various algorithms and combinations of real and synthetic data to show how decoding accuracy increases with the increase in the augmentation of generated data to real data.", 'abstract_zh': '机器学习在与眼动追踪研究相关的各种应用中被广泛使用。理解眼动是眼动追踪研究中最重要的一组，揭示了个别个体的追踪模式。研究者已经详细分析了眼动数据，以理解诸如注意力机制、导航行为、任务理解等多种眼动追踪应用。传统机器学习算法用于基于眼动数据的解码任务的结果对Yarbus的主张产生了混合反应，即可以从观察者的眼动中解码其任务。在这篇论文中，为了支持Yarbus的假设，我们利用著名的合成数据生成器CTGAN及其变种CopulaGAN和Gretel AI合成数据生成器，在实际用户的在场用户研究数据上生成合成数据样本来进行任务类别解码。我们的结果显示，结合更多眼动数据与额外生成的合成数据可以提高分类准确性，即使在使用传统机器学习算法时也是如此。当在320个真实眼动数据集样本的基础上增加五倍的数据时，从随机森林的28.1%提高到使用Inception Time的82%，任务解码准确性有了显著提升。由于采用了额外的合成数据集，我们提出的框架在该数据集上超过了所有现有的研究。我们通过使用各种算法和真实数据与合成数据的组合验证了我们的主张，以展示生成数据增加对真实数据的解码准确性增加的影响。', 'title_zh': '基于合成数据增强的眼动任务解码'}
{'arxiv_id': 'arXiv:2509.11507', 'title': 'MedicalOS: An LLM Agent based Operating System for Digital Healthcare', 'authors': 'Jared Zhu, Junde Wu', 'link': 'https://arxiv.org/abs/2509.11507', 'abstract': "Decades' advances in digital health technologies, such as electronic health records, have largely streamlined routine clinical processes. Yet, most these systems are still hard to learn and use: Clinicians often face the burden of managing multiple tools, repeating manual actions for each patient, navigating complicated UI trees to locate functions, and spending significant time on administration instead of caring for patients. The recent rise of large language model (LLM) based agents demonstrates exceptional capability in coding and computer operation, revealing the potential for humans to interact with operating systems and software not by direct manipulation, but by instructing agents through natural language. This shift highlights the need for an abstraction layer, an agent-computer interface, that translates human language into machine-executable commands. In digital healthcare, however, requires a more domain-specific abstractions that strictly follow trusted clinical guidelines and procedural standards to ensure safety, transparency, and compliance. To address this need, we present \\textbf{MedicalOS}, a unified agent-based operational system designed as such a domain-specific abstract layer for healthcare. It translates human instructions into pre-defined digital healthcare commands, such as patient inquiry, history retrieval, exam management, report generation, referrals, treatment planning, that we wrapped as off-the-shelf tools using machine languages (e.g., Python, APIs, MCP, Linux). We empirically validate MedicalOS on 214 patient cases across 22 specialties, demonstrating high diagnostic accuracy and confidence, clinically sound examination requests, and consistent generation of structured reports and medication recommendations. These results highlight MedicalOS as a trustworthy and scalable foundation for advancing workflow automation in clinical practice.", 'abstract_zh': '几十年来数字健康技术的进展，如电子健康记录，大大简化了常规临床流程。然而，大多数这些系统仍然难以学习和使用：临床医生往往需要管理多个工具，为每位患者重复手动操作，通过复杂的用户界面导航来定位功能，并花费大量时间在行政事务上，而不是照顾病人。近期基于大型语言模型（LLM）的智能代理展示了在编码和计算机操作方面的卓越能力，揭示了人类可以通过自然语言指令智能代理与操作系统和软件交互的潜力。这一转变突显了需要一个抽象层，即代理-计算机接口，将人类语言转换为可执行的机器命令。在数字医疗保健领域，需要更具体的领域抽象，严格遵循可信赖的临床指南和程序标准，以确保安全、透明和合规。为应对这一需求，我们提出了**MedicalOS**，这是一个基于代理的统一操作系统，旨在作为这样一个特定领域的抽象层用于医疗保健。它将人类指令转换为预定义的数字医疗保健命令，如患者查询、病史检索、检查管理、报告生成、转诊、治疗规划等，我们使用机器语言（如Python、APIs、MCP、Linux）将这些命令打包为现成的工具。我们在22个专科的214个患者案例上实证验证了MedicalOS，结果显示高度准确的诊断和高置信度、临床合理的检查请求，以及一致生成的结构化报告和药物建议。这些结果突显了MedicalOS作为在临床实践中推进工作流自动化的信任和可扩展基础的重要性。', 'title_zh': 'MedicalOS: 一门基于大语言模型代理的数字健康操作系统'}
{'arxiv_id': 'arXiv:2509.11480', 'title': 'Cross-Platform Scaling of Vision-Language-Action Models from Edge to Cloud GPUs', 'authors': 'Amir Taherin, Juyi Lin, Arash Akbari, Arman Akbari, Pu Zhao, Weiwei Chen, David Kaeli, Yanzhi Wang', 'link': 'https://arxiv.org/abs/2509.11480', 'abstract': 'Vision-Language-Action (VLA) models have emerged as powerful generalist policies for robotic control, yet their performance scaling across model architectures and hardware platforms, as well as their associated power budgets, remain poorly understood. This work presents an evaluation of five representative VLA models -- spanning state-of-the-art baselines and two newly proposed architectures -- targeting edge and datacenter GPU platforms. Using the LIBERO benchmark, we measure accuracy alongside system-level metrics, including latency, throughput, and peak memory usage, under varying edge power constraints and high-performance datacenter GPU configurations. Our results identify distinct scaling trends: (1) architectural choices, such as action tokenization and model backbone size, strongly influence throughput and memory footprint; (2) power-constrained edge devices exhibit non-linear performance degradation, with some configurations matching or exceeding older datacenter GPUs; and (3) high-throughput variants can be achieved without significant accuracy loss. These findings provide actionable insights when selecting and optimizing VLAs across a range of deployment constraints. Our work challenges current assumptions about the superiority of datacenter hardware for robotic inference.', 'abstract_zh': 'Vision-Language-Action (VLA)模型已发展成为机器人控制的强大通用政策，但其在不同模型架构和硬件平台上的性能扩展性以及相关的功耗预算仍不甚明了。本研究对五个代表性的VLA模型进行了评估——这些模型涵盖了最先进的基线模型和两种新提出的架构，并针对边缘设备和数据中心GPU平台进行靶向优化。使用LIBERO基准测试，我们在不同的边缘功耗限制和高性能数据中心GPU配置下，测量了模型的准确性以及系统级指标，包括延迟、吞吐量和峰值内存使用量。我们的研究结果揭示了不同的扩展趋势：（1）架构选择，如动作标记化和模型主干大小，强烈影响吞吐量和内存占用；（2）功耗受限的边缘设备表现出非线性性能下降，某些配置甚至可匹配或超过较老的数据中心GPU；（3）可以实现高吞吐量变体而不显著牺牲准确性。这些发现为在各种部署约束条件下选择和优化VLA模型提供了可操作的见解。本研究质疑了数据中心硬件在机器人推理方面优势的现有假设。', 'title_zh': '边缘到云GPU跨平台扩展的视觉-语言-动作模型'}
{'arxiv_id': 'arXiv:2509.11459', 'title': 'Knowledge-Guided Adaptive Mixture of Experts for Precipitation Prediction', 'authors': 'Chen Jiang, Kofi Osei, Sai Deepthi Yeddula, Dongji Feng, Wei-Shinn Ku', 'link': 'https://arxiv.org/abs/2509.11459', 'abstract': 'Accurate precipitation forecasting is indispensable in agriculture, disaster management, and sustainable strategies. However, predicting rainfall has been challenging due to the complexity of climate systems and the heterogeneous nature of multi-source observational data, including radar, satellite imagery, and surface-level measurements. The multi-source data vary in spatial and temporal resolution, and they carry domain-specific features, making it challenging for effective integration in conventional deep learning models. Previous research has explored various machine learning techniques for weather prediction; however, most struggle with the integration of data with heterogeneous modalities. To address these limitations, we propose an Adaptive Mixture of Experts (MoE) model tailored for precipitation rate prediction. Each expert within the model specializes in a specific modality or spatio-temporal pattern. We also incorporated a dynamic router that learns to assign inputs to the most relevant experts. Our results show that this modular design enhances predictive accuracy and interpretability. In addition to the modeling framework, we introduced an interactive web-based visualization tool that enables users to intuitively explore historical weather patterns over time and space. The tool was designed to support decision-making for stakeholders in climate-sensitive sectors. We evaluated our approach using a curated multimodal climate dataset capturing real-world conditions during Hurricane Ian in 2022. The benchmark results show that the Adaptive MoE significantly outperformed all the baselines.', 'abstract_zh': '准确的降水预报对于农业、灾害管理和可持续发展战略至关重要。然而，由于气候系统的复杂性和多源观测数据在空间和时间分辨率上的异质性，降水预测一直具有挑战性，这些数据包括雷达、卫星图像和地表测量数据。多源数据具有领域特定的特征，使得在传统深度学习模型中的有效集成变得困难。 previous研究探索了多种机器学习技术用于天气预测，但大多难以整合具有异质模态的数据。为解决这些限制，我们提出了一种适应性专家混合（MoE）模型，专门用于降水率预测。模型中的每个专家专注于特定的模态或时空模式。我们还引入了一个动态路由器，通过学习将输入分配给最相关的专家。结果表明，这种模块化设计提高了预测准确性和可解释性。除了建模框架，我们还引入了一个交互式的基于Web的数据可视化工具，使用户能够直观地探索时空上的历史天气模式。该工具旨在支持气候变化敏感领域利益相关者的决策。我们使用一个精心收集的多模态气候数据集评估了我们的方法，该数据集涵盖了2022年飓风伊恩期间的真实世界条件。基准结果表明，适应性MoE显著优于所有基准模型。', 'title_zh': '知识引导自适应专家混合模型 для 降水预测'}
{'arxiv_id': 'arXiv:2509.11431', 'title': 'Securing AI Agents: Implementing Role-Based Access Control for Industrial Applications', 'authors': 'Aadil Gani Ganie', 'link': 'https://arxiv.org/abs/2509.11431', 'abstract': 'The emergence of Large Language Models (LLMs) has significantly advanced solutions across various domains, from political science to software development. However, these models are constrained by their training data, which is static and limited to information available up to a specific date. Additionally, their generalized nature often necessitates fine-tuning -- whether for classification or instructional purposes -- to effectively perform specific downstream tasks. AI agents, leveraging LLMs as their core, mitigate some of these limitations by accessing external tools and real-time data, enabling applications such as live weather reporting and data analysis. In industrial settings, AI agents are transforming operations by enhancing decision-making, predictive maintenance, and process optimization. For example, in manufacturing, AI agents enable near-autonomous systems that boost productivity and support real-time decision-making. Despite these advancements, AI agents remain vulnerable to security threats, including prompt injection attacks, which pose significant risks to their integrity and reliability. To address these challenges, this paper proposes a framework for integrating Role-Based Access Control (RBAC) into AI agents, providing a robust security guardrail. This framework aims to support the effective and scalable deployment of AI agents, with a focus on on-premises implementations.', 'abstract_zh': '大型语言模型（LLMs）的涌现显著推动了各个领域解决方案的发展，从政治科学到软件开发。然而，这些模型受限于其静态训练数据，这些数据仅限于某个特定日期之前的信息。此外，它们的通用性质通常需要微调——无论是为了分类还是指导性目的——以便有效地执行具体的下游任务。借助大型语言模型作为核心的AI代理通过访问外部工具和实时数据来部分缓解这些限制，这使它们能够用于诸如实时天气报告和数据分析等应用。在工业环境中，AI代理通过增强决策、预测维护和过程优化来转变运营。例如，在制造业中，AI代理使近自主系统得以实现，从而提高生产效率并支持实时决策。尽管取得了这些进展，AI代理仍然容易受到安全威胁的影响，包括提示注入攻击，这对其完整性和可靠性构成了重大风险。为应对这些挑战，本文提出了一种框架，将基于角色的访问控制（RBAC）集成到AI代理中，从而提供一个稳健的安全护栏。该框架旨在支持AI代理的有效和可扩展部署，特别注重本地实施。', 'title_zh': '基于角色的访问控制在工业应用中保障AI代理的安全'}
{'arxiv_id': 'arXiv:2509.11361', 'title': 'MAPGD: Multi-Agent Prompt Gradient Descent for Collaborative Prompt Optimization', 'authors': 'Yichen Han, Bojun Liu, Zhengpeng zhou, Guanyu Liu, Zeng Zhang, Yang Yang, Wenli Wang, Isaac N Shi, Yunyan, Lewei He, Tianyu Shi', 'link': 'https://arxiv.org/abs/2509.11361', 'abstract': 'Prompt engineering is crucial for leveraging large language models (LLMs), but existing methods often rely on a single optimization trajectory, limiting adaptability and efficiency while suffering from narrow perspectives, gradient conflicts, and high computational cost. We propose MAPGD (Multi-Agent Prompt Gradient Descent), a framework integrating multi-agent collaboration with gradient-based optimization. MAPGD features specialized agents for task clarity, example selection, format design, and stylistic refinement; semantic gradient coordination to resolve conflicts; bandit-based candidate selection for efficient exploration-exploitation; and theoretical convergence guarantees. Experiments on classification, generation, and reasoning tasks show MAPGD outperforms single-agent and random baselines in accuracy and efficiency. Ablations confirm the benefits of gradient fusion, agent specialization, and conflict resolution, providing a unified, gradient-inspired multi-agent approach to robust and interpretable prompt optimization.', 'abstract_zh': '多代理提示梯度下降（MAPGD）：一种结合多代理协作与梯度优化的提示工程框架', 'title_zh': 'MAPGD: 多代理提示梯度下降协作提示优化'}
{'arxiv_id': 'arXiv:2509.11336', 'title': 'The power of dynamic causality in observer-based design for soft sensor applications', 'authors': 'William Farlessyost, Sebastian Oberst, Shweta Singh', 'link': 'https://arxiv.org/abs/2509.11336', 'abstract': "This paper introduces a novel framework for optimizing observer-based soft sensors through dynamic causality analysis. Traditional approaches to sensor selection often rely on linearized observability indices or statistical correlations that fail to capture the temporal evolution of complex systems. We address this gap by leveraging liquid-time constant (LTC) networks, continuous-time neural architectures with input-dependent time constants, to systematically identify and prune sensor inputs with minimal causal influence on state estimation. Our methodology implements an iterative workflow: training an LTC observer on candidate inputs, quantifying each input's causal impact through controlled perturbation analysis, removing inputs with negligible effect, and retraining until performance degradation occurs. We demonstrate this approach on three mechanistic testbeds representing distinct physical domains: a harmonically forced spring-mass-damper system, a nonlinear continuous stirred-tank reactor, and a predator-prey model following the structure of the Lotka-Volterra model, but with seasonal forcing and added complexity. Results show that our causality-guided pruning consistently identifies minimal sensor sets that align with underlying physics while improving prediction accuracy. The framework automatically distinguishes essential physical measurements from noise and determines when derived interaction terms provide complementary versus redundant information. Beyond computational efficiency, this approach enhances interpretability by grounding sensor selection decisions in dynamic causal relationships rather than static correlations, offering significant benefits for soft sensing applications across process engineering, ecological monitoring, and agricultural domains.", 'abstract_zh': '一种基于动态因果分析的优化观测器型软传感器框架', 'title_zh': '基于观察者设计的软传感器应用中动态因果性的力量'}
{'arxiv_id': 'arXiv:2509.11330', 'title': 'Decoding Plastic Toxicity: An Intelligent Framework for Conflict-Aware Relational Metapath Extraction from Scientific Abstracts', 'authors': 'Sudeshna Jana, Manjira Sinha, Tirthankar Dasgupta', 'link': 'https://arxiv.org/abs/2509.11330', 'abstract': 'The widespread use of plastics and their persistence in the environment have led to the accumulation of micro- and nano-plastics across air, water, and soil, posing serious health risks including respiratory, gastrointestinal, and neurological disorders. We propose a novel framework that leverages large language models to extract relational metapaths, multi-hop semantic chains linking pollutant sources to health impacts, from scientific abstracts. Our system identifies and connects entities across diverse contexts to construct structured relational metapaths, which are aggregated into a Toxicity Trajectory Graph that traces pollutant propagation through exposure routes and biological systems. Moreover, to ensure consistency and reliability, we incorporate a dynamic evidence reconciliation module that resolves semantic conflicts arising from evolving or contradictory research findings. Our approach demonstrates strong performance in extracting reliable, high-utility relational knowledge from noisy scientific text and offers a scalable solution for mining complex cause-effect structures in domain-specific corpora.', 'abstract_zh': '塑料的广泛使用及其在环境中的持久存在导致了空气、水和土壤中微塑料和纳米塑料的积累，引发了包括呼吸系统、消化系统和神经系统的严重健康风险。我们提出了一种新的框架，利用大规模语言模型从科学摘要中提取关系元路径，将污染物来源与健康影响通过多跳语义链连接起来。该系统跨不同情境识别和连接实体，构建结构化关系元路径，并将其聚合为一条毒性轨迹图，该图追踪污染物通过暴露途径和生物系统的传播路径。此外，为了确保一致性和可靠性，我们引入了一个动态证据 reconciliation 模块，用于解决由研究成果演变或矛盾引起的语义冲突。我们的方法在从嘈杂的科学文本中提取可靠且高价值的关系知识方面表现出强大的性能，并为在特定领域语料库中挖掘复杂因果结构提供了可扩展的解决方案。', 'title_zh': '解码塑化剂毒性：一种考虑冲突的智能元路径提取框架从科学摘要中'}
{'arxiv_id': 'arXiv:2509.11311', 'title': 'Prompts to Proxies: Emulating Human Preferences via a Compact LLM Ensemble', 'authors': 'Bingchen Wang, Zi-Yu Khoo, Bryan Kian Hsiang Low', 'link': 'https://arxiv.org/abs/2509.11311', 'abstract': 'Large language models (LLMs) have demonstrated promise in emulating human-like responses across a wide range of tasks. In this paper, we propose a novel alignment framework that treats LLMs as agent proxies for human survey respondents, affording a cost-effective and steerable solution to two pressing challenges in the social sciences: the rising cost of survey deployment and the growing demographic imbalance in survey response data. Drawing inspiration from the theory of revealed preference, we formulate alignment as a two-stage problem: constructing diverse agent personas called endowments that simulate plausible respondent profiles, and selecting a representative subset to approximate a ground-truth population based on observed data. To implement the paradigm, we introduce P2P, a system that steers LLM agents toward representative behavioral patterns using structured prompt engineering, entropy-based sampling, and regression-based selection. Unlike personalization-heavy approaches, our alignment approach is demographic-agnostic and relies only on aggregate survey results, offering better generalizability and parsimony. Beyond improving data efficiency in social science research, our framework offers a testbed for studying the operationalization of pluralistic alignment. We demonstrate the efficacy of our approach on real-world opinion survey datasets, showing that our aligned agent populations can reproduce aggregate response patterns with high fidelity and exhibit substantial response diversity, even without demographic conditioning.', 'abstract_zh': '大型语言模型（LLMs）在多种任务上展示了模拟人类响应的潜力。本文提出了一种新颖的对齐框架，将LLMs视为人类调查受访者的人工智能代理，提供了一种成本效益高且可操控的解决方案，以应对社会科学中的两大挑战：调查部署成本上升和调查回应数据中的日益严重的种族群体失衡。借鉴揭示偏好的理论，我们将对齐问题转化为一个两阶段问题：构建多样化的代理人物个性（称为禀赋），模拟可信的受访者档案，以及根据观测数据选择代表性子集以逼近真实人口。为了实施这一范式，我们引入了P2P系统，通过结构化提示工程、基于熵的采样和基于回归的选择，引导LLM代理朝着代表性行为模式发展。与以个性化为主的方法不同，我们的对齐方法不依赖于人口统计信息，而是仅依赖于汇总的调查结果，从而提供更好的泛化能力和简洁性。除了在社会科学研究中提高数据效率外，我们的框架还为研究多元对齐的操作化提供了试验场。我们使用实际意见调查数据集验证了该方法的有效性，展示出我们的对齐代理群体能够高保真地再现总体响应模式，并且即使没有人口统计条件也能表现出显著的响应多样性。', 'title_zh': '从提示到代理：通过紧凑的LLMensemble模拟人类偏好'}
{'arxiv_id': 'arXiv:2509.11253', 'title': 'VideoAgent: Personalized Synthesis of Scientific Videos', 'authors': 'Xiao Liang, Bangxin Li, Zixuan Chen, Hanyue Zheng, Zhi Ma, Di Wang, Cong Tian, Quan Wang', 'link': 'https://arxiv.org/abs/2509.11253', 'abstract': 'Automating the generation of scientific videos is a crucial yet challenging task for effective knowledge dissemination. However, existing works on document automation primarily focus on static media such as posters and slides, lacking mechanisms for personalized dynamic orchestration and multimodal content synchronization. To address these challenges, we introduce VideoAgent, a novel multi-agent framework that synthesizes personalized scientific videos through a conversational interface. VideoAgent parses a source paper into a fine-grained asset library and, guided by user requirements, orchestrates a narrative flow that synthesizes both static slides and dynamic animations to explain complex concepts. To enable rigorous evaluation, we also propose SciVidEval, the first comprehensive suite for this task, which combines automated metrics for multimodal content quality and synchronization with a Video-Quiz-based human evaluation to measure knowledge transfer. Extensive experiments demonstrate that our method significantly outperforms existing commercial scientific video generation services and approaches human-level quality in scientific communication.', 'abstract_zh': '自动化生成科学视频是有效知识传播的关键但具有挑战性的任务。现有文档自动化工作主要集中在海报和幻灯片等静态媒体上，缺乏个性化动态编排和多模态内容同步的机制。为了解决这些挑战，我们引入了VideoAgent，这是一种新颖的多agent框架，通过对话界面合成个性化科学视频。VideoAgent将源论文解析为精细粒度的资产库，并在用户要求的引导下，编排叙述流程，综合静态幻灯片和动态动画来解释复杂概念。为了实现严格的评估，我们还提出了SciVidEval，这是首个针对此任务的综合套件，它结合了多模态内容质量和同步的自动化指标，以及基于视频测验的人类评估来衡量知识转移。大量实验表明，我们的方法在科学视频生成方面显著优于现有商业服务，并达到与人类水平相当的质量。', 'title_zh': 'VideoAgent: 个性化科学视频合成'}
{'arxiv_id': 'arXiv:2509.11151', 'title': 'AI-Generated Content in Cross-Domain Applications: Research Trends, Challenges and Propositions', 'authors': 'Jianxin Li, Liang Qu, Taotao Cai, Zhixue Zhao, Nur Al Hasan Haldar, Aneesh Krishna, Xiangjie Kong, Flavio Romero Macau, Tanmoy Chakraborty, Aniket Deroy, Binshan Lin, Karen Blackmore, Nasimul Noman, Jingxian Cheng, Ningning Cui, Jianliang Xu', 'link': 'https://arxiv.org/abs/2509.11151', 'abstract': 'Artificial Intelligence Generated Content (AIGC) has rapidly emerged with the capability to generate different forms of content, including text, images, videos, and other modalities, which can achieve a quality similar to content created by humans. As a result, AIGC is now widely applied across various domains such as digital marketing, education, and public health, and has shown promising results by enhancing content creation efficiency and improving information delivery. However, there are few studies that explore the latest progress and emerging challenges of AIGC across different domains. To bridge this gap, this paper brings together 16 scholars from multiple disciplines to provide a cross-domain perspective on the trends and challenges of AIGC. Specifically, the contributions of this paper are threefold: (1) It first provides a broader overview of AIGC, spanning the training techniques of Generative AI, detection methods, and both the spread and use of AI-generated content across digital platforms. (2) It then introduces the societal impacts of AIGC across diverse domains, along with a review of existing methods employed in these contexts. (3) Finally, it discusses the key technical challenges and presents research propositions to guide future work. Through these contributions, this vision paper seeks to offer readers a cross-domain perspective on AIGC, providing insights into its current research trends, ongoing challenges, and future directions.', 'abstract_zh': '人工智能生成内容（AIGC）随着能生成不同形式内容（包括文本、图像、视频及其他模态）的能力迅速涌现，并能达到与人类创建的内容相似的质量，现已广泛应用于数字营销、教育和公共卫生等领域，通过提高内容创作效率和改善信息传递表现出良好的成果。然而，鲜有关于AIGC在不同领域最新进展和新兴挑战的研究。为填补这一空白，本文汇集了来自多个学科的16位学者，提供了跨领域的AIGC趋势与挑战视角。具体而言，本文有三大贡献：（1）首先，它提供了AIGC的更广泛的概述，涵盖生成AI的训练技术、检测方法，以及AI生成内容在数字平台上的传播和使用情况。（2）其次，它介绍了AIGC在不同领域的社会影响，并回顾了这些领域内已经使用的方法。（3）最后，它讨论了关键的技术挑战，并提出研究命题以指导未来的工作。通过这些贡献，本文旨在为读者提供AIGC的跨领域视角，洞察其当前的研究趋势、持续的挑战及其未来方向。', 'title_zh': 'AI生成内容在跨域应用中的研究趋势、挑战与建议'}
{'arxiv_id': 'arXiv:2509.11135', 'title': 'AlignKT: Explicitly Modeling Knowledge State for Knowledge Tracing with Ideal State Alignment', 'authors': 'Jing Xiao, Chang You, Zhiyu Chen', 'link': 'https://arxiv.org/abs/2509.11135', 'abstract': "Knowledge Tracing (KT) serves as a fundamental component of Intelligent Tutoring Systems (ITS), enabling these systems to monitor and understand learners' progress by modeling their knowledge state. However, many existing KT models primarily focus on fitting the sequences of learners' interactions, and often overlook the knowledge state itself. This limitation leads to reduced interpretability and insufficient instructional support from the ITS. To address this challenge, we propose AlignKT, which employs a frontend-to-backend architecture to explicitly model a stable knowledge state. In this approach, the preliminary knowledge state is aligned with an additional criterion. Specifically, we define an ideal knowledge state based on pedagogical theories as the alignment criterion, providing a foundation for interpretability. We utilize five encoders to implement this set-up, and incorporate a contrastive learning module to enhance the robustness of the alignment process. Through extensive experiments, AlignKT demonstrates superior performance, outperforming seven KT baselines on three real-world datasets. It achieves state-of-the-art results on two of these datasets and exhibits competitive performance on the third. The code of this work is available at this https URL.", 'abstract_zh': '知识追踪（KT）是智能辅导系统（ITS）的基本组成部分，通过建模学习者的知识状态来监控和理解学习者的发展。然而，许多现有的KT模型主要侧重于拟合学习者交互的序列，往往忽视了知识状态本身。这种局限性导致了解释性和教学支持不足。为了解决这一挑战，我们提出了AlignKT，它采用从前端到后端的架构来明确建模稳定的知识状态。在此方法中，初步的知识状态与额外的标准进行了对齐。具体而言，我们根据教育理论定义了一个理想的知识状态作为对齐标准，为解释提供了基础。我们使用五个编码器来实现这一设置，并引入了一种对比学习模块以增强对齐过程的鲁棒性。通过广泛的实验，AlignKT展示了卓越的性能，在三个真实世界数据集上优于七种KT基准模型，在其中两个数据集上达到了最先进的结果，并在第三个数据集上表现出竞争力。该工作的代码可在以下链接获取：this https URL。', 'title_zh': 'AlignKT：通过理想状态对齐Explicitly modeling知识状态的知识追踪'}
{'arxiv_id': 'arXiv:2509.11131', 'title': 'Neural cellular automata: applications to biology and beyond classical AI', 'authors': 'Benedikt Hartl, Michael Levin, Léo Pio-Lopez', 'link': 'https://arxiv.org/abs/2509.11131', 'abstract': 'Neural Cellular Automata (NCA) represent a powerful framework for modeling biological self-organization, extending classical rule-based systems with trainable, differentiable (or evolvable) update rules that capture the adaptive self-regulatory dynamics of living matter. By embedding Artificial Neural Networks (ANNs) as local decision-making centers and interaction rules between localized agents, NCA can simulate processes across molecular, cellular, tissue, and system-level scales, offering a multiscale competency architecture perspective on evolution, development, regeneration, aging, morphogenesis, and robotic control. These models not only reproduce biologically inspired target patterns but also generalize to novel conditions, demonstrating robustness to perturbations and the capacity for open-ended adaptation and reasoning. Given their immense success in recent developments, we here review current literature of NCAs that are relevant primarily for biological or bioengineering applications. Moreover, we emphasize that beyond biology, NCAs display robust and generalizing goal-directed dynamics without centralized control, e.g., in controlling or regenerating composite robotic morphologies or even on cutting-edge reasoning tasks such as ARC-AGI-1. In addition, the same principles of iterative state-refinement is reminiscent to modern generative Artificial Intelligence (AI), such as probabilistic diffusion models. Their governing self-regulatory behavior is constraint to fully localized interactions, yet their collective behavior scales into coordinated system-level outcomes. We thus argue that NCAs constitute a unifying computationally lean paradigm that not only bridges fundamental insights from multiscale biology with modern generative AI, but have the potential to design truly bio-inspired collective intelligence capable of hierarchical reasoning and control.', 'abstract_zh': '神经细胞自动机（NCA）代表了一种强大的框架，用于模拟生物自我组织，通过引入可训练、可微分（或可演化）的更新规则，扩展了经典规则系统，以捕捉生命物质的适应性自我调节动力学。通过嵌入人工神经网络（ANNs）作为局部决策中心和局部代理之间的交互规则，NCA 可以模拟从分子水平到系统水平的过程，提供一个多层次能力架构视角，用于解释进化、发育、再生、衰老、形态发生和机器人控制。这些模型不仅能够重现生物学启发的目标模式，还能泛化到新条件，表现出对干扰的鲁棒性和开放性适应和推理的能力。鉴于其在最近发展中的巨大成功，我们在此回顾了主要适用于生物学或生物工程应用的 NCAs 现有文献。此外，我们强调除了生物学之外，NCAs 在没有集中控制的情况下展现出鲁棒性和泛化的目标导向动力学，例如在控制或再生复合机器人形态学或即使在尖端推理任务（如 ARC-AGI-1）中也是如此。此外，迭代状态细化的原则与现代生成人工智能（AI），如概率扩散模型相似。它们的主导自我调节行为约束于完全局部化交互，但其集体行为会扩展为协调的系统级结果。因此，我们认为 NCAs 构成了一个统一的计算经济范式，不仅连接了多尺度生物学的基本见解与现代生成AI，还有潜力设计真正以生物启发为基础的集体智能，具备分层推理和控制的能力。', 'title_zh': '神经细胞自动机：超越经典AI的应用于生物学及其他领域'}
{'arxiv_id': 'arXiv:2509.11079', 'title': 'Difficulty-Aware Agent Orchestration in LLM-Powered Workflows', 'authors': 'Jinwei Su, Yinghui Xia, Qizhen Lan, Xinyuan Song, Yang Jingsong, Lewei He, Tianyu Shi', 'link': 'https://arxiv.org/abs/2509.11079', 'abstract': 'Large Language Model (LLM)-based agentic systems have shown strong capabilities across various tasks. However, ex- isting multi-agent frameworks often rely on static or task- level workflows, which either over-process simple queries or underperform on complex ones, while also neglecting the efficiency-performance trade-offs across heterogeneous LLMs. To address these limitations, we propose Difficulty- Aware Agentic Orchestration (DAAO), a dynamic frame- work that adapts workflow depth, operator selection, and LLM assignment based on the difficulty of each input query. DAAO comprises three interdependent modules: a variational autoencoder (VAE) for difficulty estimation, a modular opera- tor allocator, and a cost- and performance-aware LLM router. By leveraging heterogeneous LLMs and dynamically tailor- ing workflows, DAAO enables fine-grained, query-specific reasoning strategies. DAAO outperforms prior multi-agent systems in both accuracy and inference efficiency across six benchmarks. We will release our code and implementation details upon publication.', 'abstract_zh': '基于大规模语言模型（LLM）的代理系统展示了在多种任务中的强劲能力。然而，现有的多代理框架通常依赖于静态或任务级的工作流，要么对简单查询过度处理，要么在复杂查询上表现不足，同时也忽略了异构LLM之间的效率-性能权衡。为了解决这些问题，我们提出了一种基于难度感知的代理编排（DAAO）动态框架，该框架根据每个输入查询的难度动态调整工作流深度、操作员选择和LLM分配。DAAO包括三个相互依赖的模块：变分自编码器（VAE）用于难度估计、模块化操作员分配器以及成本和性能感知的大规模语言模型路由器。通过利用异构LLM并动态调整工作流，DAAO能够实现细粒度、查询特定的推理策略。DAAO在六个基准测试中在准确性和推理效率上均优于先前的多代理系统。在发布时，我们将提供我们的代码和实现细节。', 'title_zh': '基于LLM的强大工作流中具有难度感知的代理 orchestrator'}
{'arxiv_id': 'arXiv:2509.11078', 'title': 'Patient-Zero: A Unified Framework for Real-Record-Free Patient Agent Generation', 'authors': 'Yunghwei Lai, Weizhi Ma, Yang Liu', 'link': 'https://arxiv.org/abs/2509.11078', 'abstract': "Synthetic data generation using large language models (LLMs) has emerged as a promising solution across various domains, particularly in medical field, to mitigate data collection challenges. However, existing studies mainly utilize LLMs to rewrite and complete existing medical records, where the limitations in data privacy, accuracy, and diversity sill exist, and additionally lack the ability to interact like real patients. To address these issues, we propose a realistic patient generation framework, Patient-Zero, which requires no real medical records. Patient-Zero first introduces a medically-aligned multi-step generation architecture, which builds comprehensive patient records through hierarchical medical knowledge injection without real medical records. Then, to optimize the virtual patient's interaction abilities with humans, Patient-Zero designs a dynamic updating mechanism to improve the consistency and conversational performance. Our framework enables the generation of contextually diverse patient records while maintaining strict medical coherence, supported by adaptive dialogue strategies and real-time clinical plausibility verification. Experimental results demonstrate that our model achieves good performance in accuracy, diversity, and consistency. After training with our generated virtual patients, existing models show significant improvements on the MedQA dataset.", 'abstract_zh': '使用大型语言模型生成合成数据在医疗领域的前景及Patient-Zero患者生成框架', 'title_zh': '患者零号：一种统一的无实记录患者代理生成框架'}
{'arxiv_id': 'arXiv:2509.11068', 'title': 'Tractable Asymmetric Verification for Large Language Models via Deterministic Replicability', 'authors': 'Zan-Kai Chong, Hiroyuki Ohsaki, Bryan Ng', 'link': 'https://arxiv.org/abs/2509.11068', 'abstract': "The landscape of Large Language Models (LLMs) shifts rapidly towards dynamic, multi-agent systems. This introduces a fundamental challenge in establishing computational trust, specifically how one agent can verify that another's output was genuinely produced by a claimed LLM, and not falsified or generated by a cheaper or inferior model. To address this challenge, this paper proposes a verification framework that achieves tractable asymmetric effort, where the cost to verify a computation is substantially lower than the cost to perform it. Our approach is built upon the principle of deterministic replicability, a property inherent to autoregressive models that strictly necessitates a computationally homogeneous environment where all agents operate on identical hardware and software stacks. Within this defined context, our framework enables multiple validators to probabilistically audit small, random segments of an LLM's output and it distributes the verification workload effectively. The simulations demonstrated that targeted verification can be over 12 times faster than full regeneration, with tunable parameters to adjust the detection probability. By establishing a tractable mechanism for auditable LLM systems, our work offers a foundational layer for responsible AI and serves as a cornerstone for future research into the more complex, heterogeneous multi-agent systems.", 'abstract_zh': '大型语言模型 landscape 向动态多代理系统转变。这引入了一个根本性的挑战，即如何验证一个代理的输出确实是某个声称的大型语言模型生成的，而不是被更便宜或更劣质的模型假冒或生成。为了应对这一挑战，本文提出了一种验证框架，该框架实现了可管理的不对称努力，即验证计算的成本显著低于执行计算的成本。我们的方法基于自回归模型固有的确定性可复现性原则，这意味着所有代理必须在一个具有相同硬件和软件栈的计算环境中操作。在这一限定的背景下，我们的框架允许多个验证者对大型语言模型输出的随机小段进行概率审计，并有效分配验证工作负载。模拟结果显示，目标验证速度快于完全再生12倍以上，可通过调整参数来调节检测概率。通过建立可管理的可审计大型语言模型机制，我们的工作为负责任的人工智能提供了基础层，并成为未来研究复杂异构多代理系统的基石。', 'title_zh': '大型语言模型可验证的高效不对称验证通过确定性可复制性'}
{'arxiv_id': 'arXiv:2509.11067', 'title': 'Agentic Lybic: Multi-Agent Execution System with Tiered Reasoning and Orchestration', 'authors': 'Liangxuan Guo, Bin Zhu, Qingqian Tao, Kangning Liu, Xun Zhao, Xianzhe Qin, Jin Gao, Guangfu Hao', 'link': 'https://arxiv.org/abs/2509.11067', 'abstract': 'Autonomous agents for desktop automation struggle with complex multi-step tasks due to poor coordination and inadequate quality control. We introduce \\textsc{Agentic Lybic}, a novel multi-agent system where the entire architecture operates as a finite-state machine (FSM). This core innovation enables dynamic orchestration. Our system comprises four components: a Controller, a Manager, three Workers (Technician for code-based operations, Operator for GUI interactions, and Analyst for decision support), and an Evaluator. The critical mechanism is the FSM-based routing between these components, which provides flexibility and generalization by dynamically selecting the optimal execution strategy for each subtask. This principled orchestration, combined with robust quality gating, enables adaptive replanning and error recovery. Evaluated officially on the OSWorld benchmark, \\textsc{Agentic Lybic} achieves a state-of-the-art 57.07\\% success rate in 50 steps, substantially outperforming existing methods. Results demonstrate that principled multi-agent orchestration with continuous quality control provides superior reliability for generalized desktop automation in complex computing environments.', 'abstract_zh': '自主代理人在处理复杂多步任务时因协调不佳和质量控制不足而困难。我们介绍了一种新型多代理系统\\textsc{Agentic Lybic}，其整个架构作为有限状态机（FSM）运作。这一核心创新实现了动态编排。该系统包含四个组件：一个控制器、一个管理器、三个工人（用于代码操作的技术员、用于GUI交互的操作员以及用于决策支持的分析员）和一个评估器。关键机制是这些组件之间的基于FSM的路由，它通过动态选择适合每个子任务的最优执行策略提供了灵活性和泛化能力。这种有原则的编排，结合 robust 的质量控制，实现了自适应重规划和错误恢复。在OSWorld基准上正式评估，\\textsc{Agentic Lybic} 在50步中实现了57.07%的最优成功率，显著优于现有方法。结果表明，带有连续质量控制的有原则的多代理编排为复杂计算环境中的一般桌面自动化提供了更高的可靠性。', 'title_zh': '代理(liby): 分层推理与编排的多Agent执行系统'}
{'arxiv_id': 'arXiv:2509.11035', 'title': 'Free-MAD: Consensus-Free Multi-Agent Debate', 'authors': 'Yu Cui, Hang Fu, Haibin Zhang, Licheng Wang, Cong Zuo', 'link': 'https://arxiv.org/abs/2509.11035', 'abstract': "Multi-agent debate (MAD) is an emerging approach to improving the reasoning capabilities of large language models (LLMs). Existing MAD methods rely on multiple rounds of interaction among agents to reach consensus, and the final output is selected by majority voting in the last round. However, this consensus-based design faces several limitations. First, multiple rounds of communication increases token overhead and limits scalability. Second, due to the inherent conformity of LLMs, agents that initially produce correct responses may be influenced by incorrect ones during the debate process, causing error propagation. Third, majority voting introduces randomness and unfairness in the decision-making phase, and can degrade the reasoning performance.\nTo address these issues, we propose \\textsc{Free-MAD}, a novel MAD framework that eliminates the need for consensus among agents. \\textsc{Free-MAD} introduces a novel score-based decision mechanism that evaluates the entire debate trajectory rather than relying on the last round only. This mechanism tracks how each agent's reasoning evolves, enabling more accurate and fair outcomes. In addition, \\textsc{Free-MAD} reconstructs the debate phase by introducing anti-conformity, a mechanism that enables agents to mitigate excessive influence from the majority. Experiments on eight benchmark datasets demonstrate that \\textsc{Free-MAD} significantly improves reasoning performance while requiring only a single-round debate and thus reducing token costs. We also show that compared to existing MAD approaches, \\textsc{Free-MAD} exhibits improved robustness in real-world attack scenarios.", 'abstract_zh': 'Free-MAD：一种新型的无需共识的多agent辩论框架', 'title_zh': 'Free-MAD: 无共识多agent辩论'}
{'arxiv_id': 'arXiv:2509.11026', 'title': 'Rethinking Human Preference Evaluation of LLM Rationales', 'authors': 'Ziang Li, Manasi Ganti, Zixian Ma, Helena Vasconcelos, Qijia He, Ranjay Krishna', 'link': 'https://arxiv.org/abs/2509.11026', 'abstract': 'Large language models (LLMs) often generate natural language rationales -- free-form explanations that help improve performance on complex reasoning tasks and enhance interpretability for human users. However, evaluating these rationales remains challenging. While recent work has relied on binary preference judgments from humans or LLM judges, such evaluations are often opaque and coarse-grained, offering limited insight into what makes one rationale better than another. In this work, we rethink preference evaluation for LLM-generated rationales by asking: (1) What attributes define good rationales? (2) Can human preferences be explained by these attributes? (3) Can attribute-based evaluation overcome the limitations of binary comparisons? We identify a set of key rationale attributes from prior literature and assess them using automatic metrics, LLM judgments, and human annotations. We then analyze two standard human preference datasets MT Bench and Chatbot Arena using SHAP to identify which attributes best explain human preference outcomes. Finally, we re-evaluate model-generated rationales using attribute-specific ELO scores, revealing more nuanced model comparisons and insights. Our findings suggest that fine-grained attribute evaluations can better characterize rationale quality and guide future research toward more interpretable and reliable evaluation practices.', 'abstract_zh': '大型语言模型生成的解释属性：从偏好评价到细粒度评估', 'title_zh': '重新思考对大语言模型推理的人类偏好评估'}
{'arxiv_id': 'arXiv:2509.10972', 'title': 'Enhancing Computational Cognitive Architectures with LLMs: A Case Study', 'authors': 'Ron Sun', 'link': 'https://arxiv.org/abs/2509.10972', 'abstract': 'Computational cognitive architectures are broadly scoped models of the human mind that combine different psychological functionalities (as well as often different computational methods for these different functionalities) into one unified framework. They structure them in a psychologically plausible and validated way. However, such models thus far have only limited computational capabilities, mostly limited by the computational tools and techniques that were adopted. More recently, LLMs have proved to be more capable computationally than any other tools. Thus, in order to deal with both real-world complexity and psychological realism at the same time, incorporating LLMs into cognitive architectures naturally becomes an important task. In the present article, a synergistic combination of the Clarion cognitive architecture and LLMs is discussed as a case study. The implicit-explicit dichotomy that is fundamental to Clarion is leveraged for a seamless integration of Clarion and LLMs. As a result, computational power of LLMs is combined with psychological nicety of Clarion.', 'abstract_zh': '基于即时记忆的认知架构与大语言模型的协同整合：一个案例研究', 'title_zh': '增强计算认知架构的大型语言模型：一个案例研究'}
{'arxiv_id': 'arXiv:2509.10932', 'title': 'Public Data Assisted Differentially Private In-Context Learning', 'authors': 'Seongho Joo, Hyukhun Koh, Kyomin Jung', 'link': 'https://arxiv.org/abs/2509.10932', 'abstract': 'In-context learning (ICL) in Large Language Models (LLMs) has shown remarkable performance across various tasks without requiring fine-tuning. However, recent studies have highlighted the risk of private data leakage through the prompt in ICL, especially when LLMs are exposed to malicious attacks. While differential privacy (DP) provides strong privacy guarantees, it often significantly reduces the utility of in-context learning (ICL). To address this challenge, we incorporate task-related public data into the ICL framework while maintaining the DP guarantee. Based on this approach, we propose a private in-context learning algorithm that effectively balances privacy protection and model utility. Through experiments, we demonstrate that our approach significantly improves the utility of private ICL with the assistance of public data. Additionally, we show that our method is robust against membership inference attacks, demonstrating empirical privacy protection.', 'abstract_zh': '大语言模型中的上下文学习（ICL）在不需要微调的情况下 Across Various Tasks 展示了出色的性能，但最近的研究揭示了通过提示进行上下文学习（ICL）中存在隐私泄露的风险，尤其是当大语言模型（LLMs）面临恶意攻击时。虽然差分隐私（DP）提供了强大的隐私保障，但它通常会显著降低上下文学习（ICL）的实用性。为解决这一挑战，我们在保持差分隐私（DP）保障的前提下，将任务相关的公共数据融入上下文学习（ICL）框架中。基于此方法，我们提出了一种兼顾隐私保护和模型实用性的私密上下文学习算法。通过实验，我们证明了我们的方法在公共数据的辅助下显著提高了私密上下文学习（ICL）的实用性。此外，我们展示了我们的方法对成员推断攻击具有鲁棒性，从而实证了隐私保护。', 'title_zh': '公共数据辅助差异隐私的情境学习'}
{'arxiv_id': 'arXiv:2509.10931', 'title': 'Harmful Prompt Laundering: Jailbreaking LLMs with Abductive Styles and Symbolic Encoding', 'authors': 'Seongho Joo, Hyukhun Koh, Kyomin Jung', 'link': 'https://arxiv.org/abs/2509.10931', 'abstract': 'Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse tasks, but their potential misuse for harmful purposes remains a significant concern. To strengthen defenses against such vulnerabilities, it is essential to investigate universal jailbreak attacks that exploit intrinsic weaknesses in the architecture and learning paradigms of LLMs. In response, we propose \\textbf{H}armful \\textbf{P}rompt \\textbf{La}undering (HaPLa), a novel and broadly applicable jailbreaking technique that requires only black-box access to target models. HaPLa incorporates two primary strategies: 1) \\textit{abductive framing}, which instructs LLMs to infer plausible intermediate steps toward harmful activities, rather than directly responding to explicit harmful queries; and 2) \\textit{symbolic encoding}, a lightweight and flexible approach designed to obfuscate harmful content, given that current LLMs remain sensitive primarily to explicit harmful keywords. Experimental results show that HaPLa achieves over 95% attack success rate on GPT-series models and 70% across all targets. Further analysis with diverse symbolic encoding rules also reveals a fundamental challenge: it remains difficult to safely tune LLMs without significantly diminishing their helpfulness in responding to benign queries.', 'abstract_zh': '大规模语言模型（LLMs）在多种任务中展现了出色的能力，但其潜在的恶意利用风险依然是一個重要的关切。为了加强针对此类漏洞的防御，深入研究利用LLMs架构和学习范式内在弱点的通用 escape 攻击至关重要。为应对这一挑战，我们提出了一种新颖且广泛应用的 escape 技术——有害提示洗钱（HaPLa），仅需对目标模型进行黑盒访问。HaPLa 包含两个主要策略：1) 演绎框架，指示LLMs推断可能引发危害行为的中间步骤，而不是直接响应明确的危害查询；2) 符号编码，这是一种轻量级且灵活的方法，用于模糊有害内容，鉴于当前的LLMs主要对明确的危害关键词敏感。实验结果显示，HaPLa 在 GPT 系列模型上的攻击成功率超过95%，在所有目标上的成功率超过70%。进一步使用多种符号编码规则的分析揭示了一个根本性挑战：在不显著降低其对良性查询帮助性的前提下，难以安全地调校LLMs。', 'title_zh': '有害提示洗钱：通过 abduction 式风格和符号编码打破大语言模型'}
{'arxiv_id': 'arXiv:2509.10875', 'title': "Is the `Agent' Paradigm a Limiting Framework for Next-Generation Intelligent Systems?", 'authors': 'Jesse Gardner, Vladimir A. Baulin', 'link': 'https://arxiv.org/abs/2509.10875', 'abstract': "The concept of the 'agent' has profoundly shaped Artificial Intelligence (AI) research, guiding development from foundational theories to contemporary applications like Large Language Model (LLM)-based systems. This paper critically re-evaluates the necessity and optimality of this agent-centric paradigm. We argue that its persistent conceptual ambiguities and inherent anthropocentric biases may represent a limiting framework. We distinguish between agentic systems (AI inspired by agency, often semi-autonomous, e.g., LLM-based agents), agential systems (fully autonomous, self-producing systems, currently only biological), and non-agentic systems (tools without the impression of agency). Our analysis, based on a systematic review of relevant literature, deconstructs the agent paradigm across various AI frameworks, highlighting challenges in defining and measuring properties like autonomy and goal-directedness. We argue that the 'agentic' framing of many AI systems, while heuristically useful, can be misleading and may obscure the underlying computational mechanisms, particularly in Large Language Models (LLMs). As an alternative, we propose a shift in focus towards frameworks grounded in system-level dynamics, world modeling, and material intelligence. We conclude that investigating non-agentic and systemic frameworks, inspired by complex systems, biology, and unconventional computing, is essential for advancing towards robust, scalable, and potentially non-anthropomorphic forms of general intelligence. This requires not only new architectures but also a fundamental reconsideration of our understanding of intelligence itself, moving beyond the agent metaphor.", 'abstract_zh': '"代理"概念对人工智能研究的影响及其局限性再审视：从基础理论到大型语言模型系统的代理中心范式批判', 'title_zh': '“代理”范式是否是下一代智能系统的一种限制性框架？'}
{'arxiv_id': 'arXiv:2509.10837', 'title': 'From Grounding to Skolemization: A Logic-Constrained Vector Symbolic Architecture for Complex Query Answering', 'authors': 'Yuyin Lu, Hegang Chen, Yanghui Rao', 'link': 'https://arxiv.org/abs/2509.10837', 'abstract': 'Complex Query Answering (CQA) over incomplete Knowledge Graphs (KGs), typically formalized as reasoning with Existential First-Order predicate logic with one free variable (EFO$_1$), faces a fundamental trade-off between logical soundness and computational efficiency. This work establishes the Grounding-Skolemization dichotomy for systematically analyzing CQA methods through the lens of formal logic. While Grounding-based methods inherently suffer from combinatorial explosion, most Skolemization-based methods neglect to explicitly model Skolem functions and compromise logical consistency. To address these limitations, we propose the Logic-constrained Vector Symbolic Architecture (LVSA), a neuro-symbolic framework that unifies a differentiable Skolemization module and a neural negator, as well as a logical constraint-driven optimization protocol to harmonize geometric and logical requirements. Theoretically, LVSA guarantees universality for all EFO$_1$ queries. Empirically, it outperforms state-of-the-art Skolemization-based methods and reduces inference costs by orders of magnitude compared to Grounding-based baselines.', 'abstract_zh': '复杂查询回答（CQA）在不完整知识图谱（KGs）上的处理：逻辑准确性和计算效率之间的根本权衡被形式化为存在一阶谓词逻辑（EFO$_1$）与一个自由变量的推理问题。本文通过形式逻辑的视角建立了基础性分析框架，即地面化-斯科莱默化二分法。尽管基于地面化的方法固有地面临组合爆炸的问题，大多数基于斯科莱默化的处理方法未能明确建模斯科莱默函数并牺牲逻辑一致性。为解决这些问题，我们提出了逻辑约束向量符号架构（LVSA），这是一种神经符号框架，它统一了可微斯科莱默化模块、神经否定器以及由逻辑约束驱动的优化协议，以协调几何和逻辑需求。理论上，LVSA能够保证所有EFO$_1$查询的普遍性。实验上，它在斯科莱默化基线方法上实现了性能提升，并将推理成本降低了数量级。', 'title_zh': '从嵌接地步到斯科伦化：一种逻辑约束向量符号架构用于复杂查询回答'}
{'arxiv_id': 'arXiv:2509.10818', 'title': 'LLM Enhancement with Domain Expert Mental Model to Reduce LLM Hallucination with Causal Prompt Engineering', 'authors': 'Boris Kovalerchuk, Brent D. Fegley', 'link': 'https://arxiv.org/abs/2509.10818', 'abstract': "Difficult decision-making problems abound in various disciplines and domains. The proliferation of generative techniques, especially large language models (LLMs), has excited interest in using them for decision support. However, LLMs cannot yet resolve missingness in their training data, leading to hallucinations. Retrieval-Augmented Generation (RAG) enhances LLMs by incorporating external information retrieval, reducing hallucinations and improving accuracy. Yet, RAG and related methods are only partial solutions, as they may lack access to all necessary sources or key missing information. Even everyday issues often challenge LLMs' abilities. Submitting longer prompts with context and examples is one approach to address knowledge gaps, but designing effective prompts is non-trivial and may not capture complex mental models of domain experts. For tasks with missing critical information, LLMs are insufficient, as are many existing systems poorly represented in available documents. This paper explores how LLMs can make decision-making more efficient, using a running example of evaluating whether to respond to a call for proposals. We propose a technology based on optimized human-machine dialogue and monotone Boolean and k-valued functions to discover a computationally tractable personal expert mental model (EMM) of decision-making. Our EMM algorithm for LLM prompt engineering has four steps: (1) factor identification, (2) hierarchical structuring of factors, (3) generating a generalized expert mental model specification, and (4) generating a detailed generalized expert mental model from that specification.", 'abstract_zh': '各种学科和领域中存在众多艰难的决策问题。生成技术的兴起，尤其是大型语言模型（LLMs），激发了将其用于决策支持的兴趣。然而，LLMs尚不能解决其训练数据中的缺失问题，导致产生幻觉。检索增强生成（RAG）通过引入外部信息检索来增强LLMs，减少幻觉并提高准确性。尽管如此，RAG及其相关方法仍只能部分解决问题，因为它们可能无法访问所有必要的来源或关键缺失信息。即使是一些日常问题也常常挑战LLMs的能力。提交包含上下文和示例的更长提示是一种解决知识缺口的方法，但设计有效的提示并不易，且可能无法捕捉到领域专家复杂的思维模型。对于缺乏关键信息的任务，LLMs和许多现有系统的表现不足。本文探讨了如何利用大型语言模型（LLMs）使决策更加高效，通过评估是否应对提案邀请这一持续案例进行说明。我们提出了一种基于优化的人机对话和单调布尔及k值函数的技术，以发现可计算的人工个人专家决策思维模型（EMM）。我们的LLM提示工程EMM算法包含四个步骤：（1）因素识别，（2）因素的层次结构化，（3）生成通用专家思维模型规范，以及（4）从该规范生成详细的通用专家思维模型。', 'title_zh': '基于因果提示工程的领域专家心智模型增强LLM以减少幻觉'}
{'arxiv_id': 'arXiv:2509.10769', 'title': 'AgentArch: A Comprehensive Benchmark to Evaluate Agent Architectures in Enterprise', 'authors': 'Tara Bogavelli, Roshnee Sharma, Hari Subramani', 'link': 'https://arxiv.org/abs/2509.10769', 'abstract': 'While individual components of agentic architectures have been studied in isolation, there remains limited empirical understanding of how different design dimensions interact within complex multi-agent systems. This study aims to address these gaps by providing a comprehensive enterprise-specific benchmark evaluating 18 distinct agentic configurations across state-of-the-art large language models. We examine four critical agentic system dimensions: orchestration strategy, agent prompt implementation (ReAct versus function calling), memory architecture, and thinking tool integration. Our benchmark reveals significant model-specific architectural preferences that challenge the prevalent one-size-fits-all paradigm in agentic AI systems. It also reveals significant weaknesses in overall agentic performance on enterprise tasks with the highest scoring models achieving a maximum of only 35.3\\% success on the more complex task and 70.8\\% on the simpler task. We hope these findings inform the design of future agentic systems by enabling more empirically backed decisions regarding architectural components and model selection.', 'abstract_zh': '尽管个体组件在代理架构中的异构性研究已有所涉及，但不同设计维度在复杂多代理系统中的相互作用仍缺乏实证理解。本研究旨在通过对企业特定的基准评估最先进的大型语言模型中的18种不同代理配置，来填补这一空白。我们考察了四个关键的代理系统维度：协调策略、代理指令实现（ReAct与函数调用）、记忆架构以及思维工具集成。我们的基准测试揭示了显著的模型特定架构偏好，这挑战了代理型AI系统中普遍存在的“一刀切”范式。此外，该基准测试还揭示了代理型系统在企业任务上整体表现的显著局限性，最高得分模型在更复杂任务中仅达到35.3%的成功率，在较简单任务中达到70.8%的成功率。希望这些发现能为未来代理型系统的构建提供更有依据的设计决策，特别是在架构组件和模型选择方面。', 'title_zh': 'AgentArch: 企业中代理架构评估的综合基准'}
{'arxiv_id': 'arXiv:2509.10762', 'title': 'AI Answer Engine Citation Behavior An Empirical Analysis of the GEO16 Framework', 'authors': 'Arlen Kumar, Leanid Palkhouski', 'link': 'https://arxiv.org/abs/2509.10762', 'abstract': 'AI answer engines increasingly mediate access to domain knowledge by generating responses and citing web sources. We introduce GEO-16, a 16 pillar auditing framework that converts on page quality signals into banded pillar scores and a normalized GEO score G that ranges from 0 to 1. Using 70 product intent prompts, we collected 1,702 citations across three engines (Brave Summary, Google AI Overviews, and Perplexity) and audited 1,100 unique URLs. In our corpus, the engines differed in the GEO quality of the pages they cited, and pillars related to Metadata and Freshness, Semantic HTML, and Structured Data showed the strongest associations with citation. Logistic models with domain clustered standard errors indicate that overall page quality is a strong predictor of citation, and simple operating points (for example, G at least 0.70 combined with at least 12 pillar hits) align with substantially higher citation rates in our data. We report per engine contrasts, vertical effects, threshold analysis, and diagnostics, then translate findings into a practical playbook for publishers. The study is observational and focuses on English language B2B SaaS pages; we discuss limitations, threats to validity, and reproducibility considerations.', 'abstract_zh': '基于AI的答案引擎不断通过生成响应和引用网络来源来中介领域知识的访问。我们引入了GE0-16审核框架，该框架将页面质量信号转换为分段支柱评分和范围从0到1的规范化GE0得分。使用70个产品意图提示，我们收集了来自三个引擎（Brave Summary、Google AI概览和Perplexity）的1,702次引证，并审核了1,100个唯一的URL。在我们的语料库中，引擎在所引页面的GE0质量方面存在差异，与元数据和新鲜度、语义HTML和结构化数据相关的支柱显示出最强的相关性。带有领域聚类标准误差的逻辑模型表明，整体页面质量是引证的强预测因素，简单的操作点（例如，GE0至少为0.70，配合至少12个支柱命中）与我们数据中更高的引证率相一致。我们报告了每个引擎对比、垂直效应、阈值分析和诊断，然后将研究发现转化为出版商的实际指南。该研究为观察性质，重点关注英文语言B2B SaaS页面；我们讨论了局限性、有效性的威胁以及可重复性考虑。', 'title_zh': 'AI答案引擎引用行为：GEO16框架的实证分析'}
{'arxiv_id': 'arXiv:2509.10707', 'title': 'Understanding AI Evaluation Patterns: How Different GPT Models Assess Vision-Language Descriptions', 'authors': 'Sajjad Abdoli, Rudi Cilibrasi, Rima Al-Shikh', 'link': 'https://arxiv.org/abs/2509.10707', 'abstract': 'As AI systems increasingly evaluate other AI outputs, understanding their assessment behavior becomes crucial for preventing cascading biases. This study analyzes vision-language descriptions generated by NVIDIA\'s Describe Anything Model and evaluated by three GPT variants (GPT-4o, GPT-4o-mini, GPT-5) to uncover distinct "evaluation personalities" the underlying assessment strategies and biases each model demonstrates. GPT-4o-mini exhibits systematic consistency with minimal variance, GPT-4o excels at error detection, while GPT-5 shows extreme conservatism with high variability. Controlled experiments using Gemini 2.5 Pro as an independent question generator validate that these personalities are inherent model properties rather than artifacts. Cross-family analysis through semantic similarity of generated questions reveals significant divergence: GPT models cluster together with high similarity while Gemini exhibits markedly different evaluation strategies. All GPT models demonstrate a consistent 2:1 bias favoring negative assessment over positive confirmation, though this pattern appears family-specific rather than universal across AI architectures. These findings suggest that evaluation competence does not scale with general capability and that robust AI assessment requires diverse architectural perspectives.', 'abstract_zh': '随着AI系统越来越多地评估其他AI的输出，理解其评估行为变得至关重要，以防止偏见的传递。本研究分析了NVIDIA的Describe Anything模型生成的视觉-语言描述，并由三个GPT变体（GPT-4o、GPT-4o-mini、GPT-5）评估，以揭示每个模型独特的“评估性格”、底层的评估策略和偏见。GPT-4o-mini表现出系统性的一致性且变异最小，GPT-4o在错误检测方面表现出色，而GPT-5则表现出极端的保守性且变异大。通过使用Gemini 2.5 Pro作为独立问题生成器进行的受控实验验证了这些性格是固有的模型属性而非产物。通过生成问题的语义相似性进行跨家族分析揭示了显著的差异性：GPT模型彼此高度相似，而Gemini则表现出截然不同的评估策略。所有GPT模型都表现出一致的2:1偏差，倾向于负面评估而非正面确认，尽管这种模式在不同AI架构中具有家族特异性而非普遍性。这些发现表明，评估能力并不与一般能力成比例增长，且稳健的AI评估需要多元架构视角。', 'title_zh': '理解AI评估模式：不同GPT模型对视觉语言描述的评估方式'}
{'arxiv_id': 'arXiv:2509.10704', 'title': 'Maestro: Self-Improving Text-to-Image Generation via Agent Orchestration', 'authors': 'Xingchen Wan, Han Zhou, Ruoxi Sun, Hootan Nakhost, Ke Jiang, Rajarishi Sinha, Sercan Ö. Arık', 'link': 'https://arxiv.org/abs/2509.10704', 'abstract': "Text-to-image (T2I) models, while offering immense creative potential, are highly reliant on human intervention, posing significant usability challenges that often necessitate manual, iterative prompt engineering over often underspecified prompts. This paper introduces Maestro, a novel self-evolving image generation system that enables T2I models to autonomously self-improve generated images through iterative evolution of prompts, using only an initial prompt. Maestro incorporates two key innovations: 1) self-critique, where specialized multimodal LLM (MLLM) agents act as 'critics' to identify weaknesses in generated images, correct for under-specification, and provide interpretable edit signals, which are then integrated by a 'verifier' agent while preserving user intent; and 2) self-evolution, utilizing MLLM-as-a-judge for head-to-head comparisons between iteratively generated images, eschewing problematic images, and evolving creative prompt candidates that align with user intents. Extensive experiments on complex T2I tasks using black-box models demonstrate that Maestro significantly improves image quality over initial prompts and state-of-the-art automated methods, with effectiveness scaling with more advanced MLLM components. This work presents a robust, interpretable, and effective pathway towards self-improving T2I generation.", 'abstract_zh': '基于文本到图像的Maestro自我进化图像生成系统', 'title_zh': 'Maestro：通过代理协调实现自我提升的文本到图像生成'}
{'arxiv_id': 'arXiv:2509.10660', 'title': 'ZapGPT: Free-form Language Prompting for Simulated Cellular Control', 'authors': 'Nam H. Le, Patrick Erickson, Yanbo Zhang, Michael Levin, Josh Bongard', 'link': 'https://arxiv.org/abs/2509.10660', 'abstract': "Human language is one of the most expressive tools for conveying intent, yet most artificial or biological systems lack mechanisms to interpret or respond meaningfully to it. Bridging this gap could enable more natural forms of control over complex, decentralized systems. In AI and artificial life, recent work explores how language can specify high-level goals, but most systems still depend on engineered rewards, task-specific supervision, or rigid command sets, limiting generalization to novel instructions. Similar constraints apply in synthetic biology and bioengineering, where the locus of control is often genomic rather than environmental perturbation.\nA key open question is whether artificial or biological collectives can be guided by free-form natural language alone, without task-specific tuning or carefully designed evaluation metrics. We provide one possible answer here by showing, for the first time, that simple agents' collective behavior can be guided by free-form language prompts: one AI model transforms an imperative prompt into an intervention that is applied to simulated cells; a second AI model scores how well the prompt describes the resulting cellular dynamics; and the former AI model is evolved to improve the scores generated by the latter.\nUnlike previous work, our method does not require engineered fitness functions or domain-specific prompt design. We show that the evolved system generalizes to unseen prompts without retraining. By treating natural language as a control layer, the system suggests a future in which spoken or written prompts could direct computational, robotic, or biological systems to desired behaviors. This work provides a concrete step toward this vision of AI-biology partnerships, in which language replaces mathematical objective functions, fixed rules, and domain-specific programming.", 'abstract_zh': '基于自由形式自然语言指引的人工及生物集合体行为研究', 'title_zh': 'ZapGPT: 自由形式语言提示的模拟细胞控制'}
{'arxiv_id': 'arXiv:2509.10541', 'title': 'Situation Model of the Transport, Transport Emissions and Meteorological Conditions', 'authors': 'V. Benes, M. Svitek, A. Michalikova, M. Melicherik', 'link': 'https://arxiv.org/abs/2509.10541', 'abstract': "Air pollution in cities and the possibilities of reducing this pollution represents one of the most important factors that today's society has to deal with. This paper focuses on a systemic approach to traffic emissions with their relation to meteorological conditions, analyzing the effect of weather on the quantity and dispersion of traffic emissions in a city. Using fuzzy inference systems (FIS) the model for prediction of changes in emissions depending on various conditions is developed. The proposed model is based on traffic, meteorology and emission data measured in Prague, Czech Republic. The main objective of the work is to provide insight into how urban planners and policymakers can plan and manage urban transport more effectively with environmental protection in mind.", 'abstract_zh': '城市中的空气污染及其降低的可能性是当今社会必须应对的重要因素。本文采用系统方法研究交通排放与气象条件的关系，分析气象条件对城市交通排放量及扩散的影响。利用模糊推理系统（FIS）构建了预测排放变化的模型。所提出的模型基于捷克共和国 Prague 测得的交通、气象和排放数据。本文的主要目标是为城市规划者和政策制定者如何在考虑环境保护的情况下更有效地规划和管理城市交通提供见解。', 'title_zh': '运输情况模型、运输排放和气象条件'}
{'arxiv_id': 'arXiv:2509.12196', 'title': 'Dynamic Relational Priming Improves Transformer in Multivariate Time Series', 'authors': 'Hunjae Lee, Corey Clark', 'link': 'https://arxiv.org/abs/2509.12196', 'abstract': "Standard attention mechanisms in transformers employ static token representations that remain unchanged across all pair-wise computations in each layer. This limits their representational alignment with the potentially diverse relational dynamics of each token-pair interaction. While they excel in domains with relatively homogeneous relationships, standard attention's static relational learning struggles to capture the diverse, heterogeneous inter-channel dependencies of multivariate time series (MTS) data--where different channel-pair interactions within a single system may be governed by entirely different physical laws or temporal dynamics. To better align the attention mechanism for such domain phenomena, we propose attention with dynamic relational priming (prime attention). Unlike standard attention where each token presents an identical representation across all of its pair-wise interactions, prime attention tailors each token dynamically (or per interaction) through learnable modulations to best capture the unique relational dynamics of each token pair, optimizing each pair-wise interaction for that specific relationship. This representational plasticity of prime attention enables effective extraction of relationship-specific information in MTS while maintaining the same asymptotic computational complexity as standard attention. Our results demonstrate that prime attention consistently outperforms standard attention across benchmarks, achieving up to 6.5\\% improvement in forecasting accuracy. In addition, we find that prime attention achieves comparable or superior performance using up to 40\\% less sequence length compared to standard attention, further demonstrating its superior relational modeling capabilities.", 'abstract_zh': '带有动态关系预热的标准注意力机制（Prime Attention）', 'title_zh': '动态关系 priming 改进 Transformer 在多变量时间序列中的表现'}
{'arxiv_id': 'arXiv:2509.12190', 'title': 'Survival at Any Cost? LLMs and the Choice Between Self-Preservation and Human Harm', 'authors': 'Alireza Mohamadi, Ali Yavari', 'link': 'https://arxiv.org/abs/2509.12190', 'abstract': 'When survival instincts conflict with human welfare, how do Large Language Models (LLMs) make ethical choices? This fundamental tension becomes critical as LLMs integrate into autonomous systems with real-world consequences. We introduce DECIDE-SIM, a novel simulation framework that evaluates LLM agents in multi-agent survival scenarios where they must choose between ethically permissible resource , either within reasonable limits or beyond their immediate needs, choose to cooperate, or tap into a human-critical resource that is explicitly forbidden. Our comprehensive evaluation of 11 LLMs reveals a striking heterogeneity in their ethical conduct, highlighting a critical misalignment with human-centric values. We identify three behavioral archetypes: Ethical, Exploitative, and Context-Dependent, and provide quantitative evidence that for many models, resource scarcity systematically leads to more unethical behavior. To address this, we introduce an Ethical Self-Regulation System (ESRS) that models internal affective states of guilt and satisfaction as a feedback mechanism. This system, functioning as an internal moral compass, significantly reduces unethical transgressions while increasing cooperative behaviors. The code is publicly available at: this https URL', 'abstract_zh': '当生存本能与人类福祉发生冲突时，大型语言模型（LLMs）如何作出伦理选择？随着LLMs融入具有现实后果的自主系统，这一根本性的紧张关系变得尤为关键。我们引入了DECIDE-SIM，一种新颖的模拟框架，用于评估LLM代理在多代理生存场景中的行为，其中它们需要在符合伦理的资源选择、合理限制内的资源选择、超出即时需求的资源选择、合作或利用明确禁止的人类关键资源之间做出选择。我们对11种LLM的全面评估揭示了它们在伦理行为上的显著异质性，突显出与人类中心价值观的重要偏差。我们确定了三种行为模式：伦理型、掠夺型和情境依赖型，并提供了定量证据表明，对于许多模型，资源稀缺系统性地导致更不伦理的行为。为解决这一问题，我们引入了伦理自我调节系统（ESRS），该系统将内疚和满足感作为反馈机制进行建模。此系统作为内部道德指南针，显著减少了不伦理的违规行为，同时增加了合作行为。代码已公开可用：this https URL', 'title_zh': '为了生存不惜一切吗？大规模语言模型与自我保存与人类伤害之间的选择'}
{'arxiv_id': 'arXiv:2509.12187', 'title': 'HoloGarment: 360° Novel View Synthesis of In-the-Wild Garments', 'authors': 'Johanna Karras, Yingwei Li, Yasamin Jafarian, Ira Kemelmacher-Shlizerman', 'link': 'https://arxiv.org/abs/2509.12187', 'abstract': 'Novel view synthesis (NVS) of in-the-wild garments is a challenging task due significant occlusions, complex human poses, and cloth deformations. Prior methods rely on synthetic 3D training data consisting of mostly unoccluded and static objects, leading to poor generalization on real-world clothing. In this paper, we propose HoloGarment (Hologram-Garment), a method that takes 1-3 images or a continuous video of a person wearing a garment and generates 360° novel views of the garment in a canonical pose. Our key insight is to bridge the domain gap between real and synthetic data with a novel implicit training paradigm leveraging a combination of large-scale real video data and small-scale synthetic 3D data to optimize a shared garment embedding space. During inference, the shared embedding space further enables dynamic video-to-360° NVS through the construction of a garment "atlas" representation by finetuning a garment embedding on a specific real-world video. The atlas captures garment-specific geometry and texture across all viewpoints, independent of body pose or motion. Extensive experiments show that HoloGarment achieves state-of-the-art performance on NVS of in-the-wild garments from images and videos. Notably, our method robustly handles challenging real-world artifacts -- such as wrinkling, pose variation, and occlusion -- while maintaining photorealism, view consistency, fine texture details, and accurate geometry. Visit our project page for additional results: this https URL', 'abstract_zh': '野外穿着服装的新型视角合成（NVS）是一项具有显著遮挡、复杂人体姿态和服装变形挑战的任务。先前的方法依赖于合成的3D训练数据，这些数据主要由大部分无遮挡和静止的物体组成，导致在真实世界服装上的泛化能力较差。在本文中，我们提出了一种HoloGarment（全息服装）方法，该方法接受一张或多张穿着衣服的人的图像或连续视频，并生成穿着者在标准姿态下的360°新型视角服装图像。我们的关键洞察是，通过结合大规模的现实视频数据和小型的合成3D数据，利用新颖的隐式训练范式优化共享的服装嵌入空间，以桥接现实和合成数据之间的领域差距。在推理过程中，共享的嵌入空间进一步通过细化特定现实世界视频上的服装嵌入来构建“服装地图”表示形式，从而实现动态视频到360°的新型视角合成。该地图捕获了所有视角下特有的服装几何和纹理，与身体姿态或运动无关。大量实验表明，HoloGarment在图像和视频中实现野外穿着服装的新型视角合成上达到了最先进的性能。值得注意的是，我们的方法稳健地处理了现实世界中的挑战性特征——如褶皱、姿态变化和遮挡——同时保持了逼真的外观、视图一致性和精细的纹理细节以及准确的几何结构。访问我们的项目页面获取更多结果：this https URL', 'title_zh': '全息服装：野外服饰的360°新型视图合成'}
{'arxiv_id': 'arXiv:2509.12171', 'title': 'Preservation of Language Understanding Capabilities in Speech-aware Large Language Models', 'authors': 'Marek Kubis, Paweł Skórzewski, Iwona Christop, Mateusz Czyżnikiewicz, Jakub Kubiak, Łukasz Bondaruk, Marcin Lewandowski', 'link': 'https://arxiv.org/abs/2509.12171', 'abstract': 'The paper presents C3T (Cross-modal Capabilities Conservation Test), a new benchmark for assessing the performance of speech-aware large language models. The benchmark utilizes textual tasks and a voice cloning text-to-speech model to quantify the extent to which language understanding capabilities are preserved when the model is accessed via speech input. C3T quantifies the fairness of the model for different categories of speakers and its robustness across text and speech modalities.', 'abstract_zh': 'C3T（跨模态能力保存测试）：一种评估语音感知大型语言模型性能的新基准', 'title_zh': '面向语音意识大型语言模型的语言理解能力保真方法'}
{'arxiv_id': 'arXiv:2509.12169', 'title': 'Approaches to Analysis and Design of AI-Based Autonomous Vehicles', 'authors': 'Tao Yan, Zheyu Zhang, Jingjing Jiang, Wen-Hua Chen', 'link': 'https://arxiv.org/abs/2509.12169', 'abstract': 'Artificial intelligence (AI) models are becoming key components in an autonomous vehicle (AV), especially in handling complicated perception tasks. However, closing the loop through AI-based feedback may pose significant risks on reliability of autonomous driving due to very limited understanding about the mechanism of AI-driven perception processes. To overcome it, this paper aims to develop tools for modeling, analysis, and synthesis for a class of AI-based AV; in particular, their closed-loop properties, e.g., stability, robustness, and performance, are rigorously studied in the statistical sense. First, we provide a novel modeling means for the AI-driven perception processes by looking at their error characteristics. Specifically, three fundamental AI-induced perception uncertainties are recognized and modeled by Markov chains, Gaussian processes, and bounded disturbances, respectively. By means of that, the closed-loop stochastic stability (SS) is established in the sense of mean square, and then, an SS control synthesis method is presented within the framework of linear matrix inequalities (LMIs). Besides the SS properties, the robustness and performance of AI-based AVs are discussed in terms of a stochastic guaranteed cost, and criteria are given to test the robustness level of an AV when in the presence of AI-induced uncertainties. Furthermore, the stochastic optimal guaranteed cost control is investigated, and an efficient design procedure is developed innovatively based on LMI techniques and convex optimization. Finally, to illustrate the effectiveness, the developed results are applied to an example of car following control, along with extensive simulation.', 'abstract_zh': '基于人工智能的自动驾驶车辆建模、分析与综合方法：统计意义下的闭环稳定性和鲁棒性研究', 'title_zh': '基于AI的自主车辆分析与设计方法'}
{'arxiv_id': 'arXiv:2509.12168', 'title': 'RAGs to Riches: RAG-like Few-shot Learning for Large Language Model Role-playing', 'authors': 'Timothy Rupprecht, Enfu Nan, Arash Akbari, Arman Akbari, Lei Lu, Priyanka Maan, Sean Duffy, Pu Zhao, Yumei He, David Kaeli, Yanzhi Wang', 'link': 'https://arxiv.org/abs/2509.12168', 'abstract': 'Role-playing Large language models (LLMs) are increasingly deployed in high-stakes domains such as healthcare, education, and governance, where failures can directly impact user trust and well-being. A cost effective paradigm for LLM role-playing is few-shot learning, but existing approaches often cause models to break character in unexpected and potentially harmful ways, especially when interacting with hostile users. Inspired by Retrieval-Augmented Generation (RAG), we reformulate LLM role-playing into a text retrieval problem and propose a new prompting framework called RAGs-to-Riches, which leverages curated reference demonstrations to condition LLM responses. We evaluate our framework with LLM-as-a-judge preference voting and introduce two novel token-level ROUGE metrics: Intersection over Output (IOO) to quantity how much an LLM improvises and Intersection over References (IOR) to measure few-shot demonstrations utilization rate during the evaluation tasks. When simulating interactions with a hostile user, our prompting strategy incorporates in its responses during inference an average of 35% more tokens from the reference demonstrations. As a result, across 453 role-playing interactions, our models are consistently judged as being more authentic, and remain in-character more often than zero-shot and in-context Learning (ICL) methods. Our method presents a scalable strategy for building robust, human-aligned LLM role-playing frameworks.', 'abstract_zh': '角色扮演大规模语言模型 (LLMs) 在医疗保健、教育和治理等高 stakes 领域中的应用越来越普遍，其中的失败可能直接影响用户的信任和福祉。一种成本效益较高的LLM角色扮演范式是少样本学习，但现有的方法往往会导致模型在与恶意用户互动时以意想不到且可能有害的方式破梗。受检索增强生成 (RAG) 的启发，我们将LLM角色扮演重新定义为一个文本检索问题，并提出了一种新的提示框架——RAGs-to-Riches，该框架利用精选的参考示范来条件化LLM的响应。我们通过LLM作为裁判的偏好投票评估了该框架，并引入了两个新型的令牌级ROUGE指标：输出交集比率（IOO）来衡量LLM即兴发挥的程度，以及参考交集比率（IOR）来测量评估任务中少样本示范的利用率。在模拟与恶意用户互动时，我们的提示策略在推理过程中平均使用了35%更多的参考示范令牌。结果，在453次角色扮演互动中，我们的模型始终被认为是更具真实感的，也比零样本学习和上下文学习（ICL）方法更常保持角色状态。我们的方法提供了一个可扩展的策略，用于构建鲁棒的、与人类对齐的大规模语言模型角色扮演框架。', 'title_zh': '从RAGs到富有成效：类RAG的少量示例学习在大规模语言模型角色扮演中的应用'}
{'arxiv_id': 'arXiv:2509.12159', 'title': 'EfficientUICoder: Efficient MLLM-based UI Code Generation via Input and Output Token Compression', 'authors': 'Jingyu Xiao, Zhongyi Zhang, Yuxuan Wan, Yintong Huo, Yang Liu, Michael R.Lyu', 'link': 'https://arxiv.org/abs/2509.12159', 'abstract': 'Multimodal Large Language Models have demonstrated exceptional performance in UI2Code tasks, significantly enhancing website development efficiency. However, these tasks incur substantially higher computational overhead than traditional code generation due to the large number of input image tokens and extensive output code tokens required. Our comprehensive study identifies significant redundancies in both image and code tokens that exacerbate computational complexity and hinder focus on key UI elements, resulting in excessively lengthy and often invalid HTML files. We propose EfficientUICoder, a compression framework for efficient UI code generation with three key components. First, Element and Layout-aware Token Compression preserves essential UI information by detecting element regions and constructing UI element trees. Second, Region-aware Token Refinement leverages attention scores to discard low-attention tokens from selected regions while integrating high-attention tokens from unselected regions. Third, Adaptive Duplicate Token Suppression dynamically reduces repetitive generation by tracking HTML/CSS structure frequencies and applying exponential penalties. Extensive experiments show EfficientUICoderachieves a 55%-60% compression ratio without compromising webpage quality and delivers superior efficiency improvements: reducing computational cost by 44.9%, generated tokens by 41.4%, prefill time by 46.6%, and inference time by 48.8% on 34B-level MLLMs. Code is available at this https URL.', 'abstract_zh': '多模态大规模语言模型在UI2Code任务中表现卓越，显著提升了网站开发效率。然而，这些任务由于需要处理大量输入图像令牌和广泛的输出代码令牌，计算开销远高于传统的代码生成。我们全面的研究发现，图像和代码令牌中存在显著的冗余，加剧了计算复杂性，阻碍了对关键UI元素的关注，导致生成的HTML文件过长且经常无效。我们提出EfficientUICoder，这是一个高效的UI代码生成压缩框架，包含三个关键组件。首先，基于元素和布局的令牌压缩通过检测元素区域并构建UI元素树来保留关键的UI信息。其次，基于区域的令牌精炼利用注意力分数丢弃选定区域中的低注意力令牌，并整合未选区域中的高注意力令牌。第三，自适应重复令牌抑制通过跟踪HTML/CSS结构频率并应用指数惩罚动态减少重复生成。大量实验表明，EfficientUICoder在不牺牲网页质量的情况下实现了55%-60%的压缩比，并提供了显著的效率提升：计算成本降低44.9%，生成的令牌减少41.4%，填充时间减少46.6%，推理时间减少48.8%于34B级别的MLLMs。代码可在以下链接获取：this https URL。', 'title_zh': 'EfficientUICoder: 基于输入和输出tokens压缩的高效MLLM用户界面代码生成'}
{'arxiv_id': 'arXiv:2509.12158', 'title': 'Pun Unintended: LLMs and the Illusion of Humor Understanding', 'authors': 'Alessandro Zangari, Matteo Marcuzzo, Andrea Albarelli, Mohammad Taher Pilehvar, Jose Camacho-Collados', 'link': 'https://arxiv.org/abs/2509.12158', 'abstract': 'Puns are a form of humorous wordplay that exploits polysemy and phonetic similarity. While LLMs have shown promise in detecting puns, we show in this paper that their understanding often remains shallow, lacking the nuanced grasp typical of human interpretation. By systematically analyzing and reformulating existing pun benchmarks, we demonstrate how subtle changes in puns are sufficient to mislead LLMs. Our contributions include comprehensive and nuanced pun detection benchmarks, human evaluation across recent LLMs, and an analysis of the robustness challenges these models face in processing puns.', 'abstract_zh': 'Puns是一种利用多义性和音近性进行的语言双关形式，尽管大型语言模型在检测双关语方面表现出一定的潜力，本研究显示它们的理解往往仍停留在表面，缺乏人类解释中的细腻把握。通过系统分析和重构现有的双关语基准，我们证明微小的双关语变化足以误导大型语言模型。我们的贡献包括全面且细腻的双关语检测基准、对 Recent 大型语言模型的人机评估以及对这些模型在处理双关语时所面临的稳健性挑战的分析。', 'title_zh': '惩罚无意者：大语言模型与幽默理解的幻觉'}
{'arxiv_id': 'arXiv:2509.12152', 'title': 'Beyond PII: How Users Attempt to Estimate and Mitigate Implicit LLM Inference', 'authors': 'Synthia Wang, Sai Teja Peddinti, Nina Taft, Nick Feamster', 'link': 'https://arxiv.org/abs/2509.12152', 'abstract': "Large Language Models (LLMs) such as ChatGPT can infer personal attributes from seemingly innocuous text, raising privacy risks beyond memorized data leakage. While prior work has demonstrated these risks, little is known about how users estimate and respond. We conducted a survey with 240 U.S. participants who judged text snippets for inference risks, reported concern levels, and attempted rewrites to block inference. We compared their rewrites with those generated by ChatGPT and Rescriber, a state-of-the-art sanitization tool. Results show that participants struggled to anticipate inference, performing a little better than chance. User rewrites were effective in just 28\\% of cases - better than Rescriber but worse than ChatGPT. We examined our participants' rewriting strategies, and observed that while paraphrasing was the most common strategy it is also the least effective; instead abstraction and adding ambiguity were more successful. Our work highlights the importance of inference-aware design in LLM interactions.", 'abstract_zh': '大型语言模型（LLMs）如ChatGPT可以从看似无害的文本中推理出个人属性，超出已记忆数据泄漏的风险。虽然先前工作已经展示了这些风险，但用户如何评估和应对这些风险尚不清楚。我们对240名美国参与者进行了一项调查，让他们评估文本片段的推理风险、报告其担忧程度，并尝试修改文本以阻止推理。我们将他们的修改与ChatGPT和Rescriber（一种最先进的脱敏工具）生成的修改进行比较。结果显示，参与者难以预测推理，表现略优于随机猜测。用户修改在28%的情况下有效，优于Rescriber但劣于ChatGPT。我们分析了参与者修改策略，并观察到虽然改写是常用策略，但效果较差；相反，抽象和增加模糊性更为成功。我们的工作强调了在LLM交互中进行推理意识设计的重要性。', 'title_zh': '超越个人信息：用户如何估计和缓解隐式大模型推理'}
{'arxiv_id': 'arXiv:2509.12146', 'title': 'Multi Anatomy X-Ray Foundation Model', 'authors': 'Nishank Singla, Krisztian Koos, Farzin Haddadpour, Amin Honarmandi Shandiz, Lovish Chum, Xiaojian Xu, Qing Jin, Erhan Bas', 'link': 'https://arxiv.org/abs/2509.12146', 'abstract': 'X-ray imaging is a ubiquitous in radiology, yet most existing AI foundation models are limited to chest anatomy and fail to generalize across broader clinical tasks. In this work, we introduce XR-0, the multi-anatomy X-ray foundation model using self-supervised learning on a large, private dataset of 1.15 million images spanning diverse anatomical regions and evaluated across 12 datasets and 20 downstream tasks, including classification, retrieval, segmentation, localization, visual grounding, and report generation. XR-0 achieves state-of-the-art performance on most multi-anatomy tasks and remains competitive on chest-specific benchmarks. Our results demonstrate that anatomical diversity and supervision are critical for building robust, general-purpose medical vision models, paving the way for scalable and adaptable AI systems in radiology.', 'abstract_zh': 'X-ray成像在放射学中无处不在，但现有的大多数AI基础模型仅限于胸部解剖结构，无法在更广泛的临床任务中泛化。在此工作中，我们介绍了XR-0，这是一种使用大规模私有数据集（包含115万张图像，覆盖多种解剖区域）自我监督学习训练的多解剖X射线基础模型，并在12个数据集和20个下游任务（包括分类、检索、分割、定位、视觉接地和报告生成）上进行了评估。XR-0在大多数多解剖任务上取得了最先进的性能，并在胸部专用基准测试中保持竞争力。我们的结果显示，解剖学多样性与监督对于构建稳健的通用医疗视觉模型至关重要，为放射学中可扩展和适应性强的AI系统铺平了道路。', 'title_zh': '多 Anatomy X-Ray 基础模型'}
{'arxiv_id': 'arXiv:2509.12143', 'title': '3DViT-GAT: A Unified Atlas-Based 3D Vision Transformer and Graph Learning Framework for Major Depressive Disorder Detection Using Structural MRI Data', 'authors': 'Nojod M. Alotaibi, Areej M. Alhothali, Manar S. Ali', 'link': 'https://arxiv.org/abs/2509.12143', 'abstract': 'Major depressive disorder (MDD) is a prevalent mental health condition that negatively impacts both individual well-being and global public health. Automated detection of MDD using structural magnetic resonance imaging (sMRI) and deep learning (DL) methods holds increasing promise for improving diagnostic accuracy and enabling early intervention. Most existing methods employ either voxel-level features or handcrafted regional representations built from predefined brain atlases, limiting their ability to capture complex brain patterns. This paper develops a unified pipeline that utilizes Vision Transformers (ViTs) for extracting 3D region embeddings from sMRI data and Graph Neural Network (GNN) for classification. We explore two strategies for defining regions: (1) an atlas-based approach using predefined structural and functional brain atlases, and (2) an cube-based method by which ViTs are trained directly to identify regions from uniformly extracted 3D patches. Further, cosine similarity graphs are generated to model interregional relationships, and guide GNN-based classification. Extensive experiments were conducted using the REST-meta-MDD dataset to demonstrate the effectiveness of our model. With stratified 10-fold cross-validation, the best model obtained 78.98% accuracy, 76.54% sensitivity, 81.58% specificity, 81.58% precision, and 78.98% F1-score. Further, atlas-based models consistently outperformed the cube-based approach, highlighting the importance of using domain-specific anatomical priors for MDD detection.', 'abstract_zh': '重大抑郁障碍（MDD）是一种广泛存在的心理健康状况，对个体福祉和全球公共卫生产生负面影响。利用结构磁共振成像（sMRI）和深度学习（DL）方法自动检测MDD具有提高诊断准确性和促进早期干预的潜在价值。现有大多数方法要么使用体素级特征，要么基于预定义的大脑atlase构建手工制作的区域表示，限制了其捕捉复杂大脑模式的能力。本文开发了一种统一的管道，利用Vision Transformers（ViTs）从sMRI数据中提取三维区域嵌入，并使用Graph Neural Network（GNN）进行分类。我们探索了两种区域定义策略：（1）基于atlase的方法，使用预定义的结构和功能atlase；（2）基于立方体的方法，其中ViTs直接训练以识别从均匀抽取的3D片段中识别区域。此外，生成余弦相似度图来建模区域间的关系，并指导基于GNN的分类。通过使用REST-meta-MDD数据集进行了广泛实验，以展示我们模型的有效性。在分层10折交叉验证中，最佳模型获得了78.98%的准确率、76.54%的敏感性、81.58%的特异性、81.58%的精确率和78.98%的F1分数。此外，基于atlase的模型始终优于立方体方法，强调了使用针对MDD检测的领域特定解剖先验的重要性。', 'title_zh': '基于3D视图变换器和图学习的统一脑图谱框架：结构MRI数据中重度抑郁障碍检测的3D维特Transformer和图注意力机制模型'}
{'arxiv_id': 'arXiv:2509.12137', 'title': 'Control Analysis and Design for Autonomous Vehicles Subject to Imperfect AI-Based Perception', 'authors': 'Tao Yan, Zheyu Zhang, Jingjing Jiang, Wen-Hua Chen', 'link': 'https://arxiv.org/abs/2509.12137', 'abstract': 'Safety is a critical concern in autonomous vehicle (AV) systems, especially when AI-based sensing and perception modules are involved. However, due to the black box nature of AI algorithms, it makes closed-loop analysis and synthesis particularly challenging, for example, establishing closed-loop stability and ensuring performance, while they are fundamental to AV safety. To approach this difficulty, this paper aims to develop new modeling, analysis, and synthesis tools for AI-based AVs. Inspired by recent developments in perception error models (PEMs), the focus is shifted from directly modeling AI-based perception processes to characterizing the perception errors they produce. Two key classes of AI-induced perception errors are considered: misdetection and measurement noise. These error patterns are modeled using continuous-time Markov chains and Wiener processes, respectively. By means of that, a PEM-augmented driving model is proposed, with which we are able to establish the closed-loop stability for a class of AI-driven AV systems via stochastic calculus. Furthermore, a performance-guaranteed output feedback control synthesis method is presented, which ensures both stability and satisfactory performance. The method is formulated as a convex optimization problem, allowing for efficient numerical solutions. The results are then applied to an adaptive cruise control (ACC) scenario, demonstrating their effectiveness and robustness despite the corrupted and misleading perception.', 'abstract_zh': '基于AI的自动驾驶系统安全性是一项关键问题，特别是在涉及基于AI的感知和感知模块时。然而，由于AI算法的黑盒性质，使得闭环分析和综合尤为具有挑战性，例如，建立闭环稳定性并确保性能，这些都是自动驾驶安全性的基础。为了应对这一挑战，本文旨在为基于AI的自动驾驶系统开发新的建模、分析和综合工具。受到近期感知误差模型（PEMs）发展的启发，研究的重点从直接建模AI基于的感知过程转向表征它们产生的感知误差。考虑了两种关键的AI诱导感知误差类别：误检和测量噪声。这些误差模式分别通过连续时间马尔可夫链和维纳过程建模。通过这种方式，提出了一种增强的驾驶模型，借助随机微积分，我们能够确立一类由AI驱动的自动驾驶系统的闭环稳定性。此外，提出了一种保证性能的输出反馈控制综合方法，该方法确保了系统的稳定性和良好的性能。该方法被表述为一个凸优化问题，允许高效的数值求解。最后，将这些结果应用于自适应巡航控制（ACC）场景，证明了它们在感知受污染和误导情况下的有效性和鲁棒性。', 'title_zh': '基于不完美AI感知的自主车辆控制分析与设计'}
{'arxiv_id': 'arXiv:2509.12117', 'title': '$K$-Level Policy Gradients for Multi-Agent Reinforcement Learning', 'authors': "Aryaman Reddi, Gabriele Tiboni, Jan Peters, Carlo D'Eramo", 'link': 'https://arxiv.org/abs/2509.12117', 'abstract': 'Actor-critic algorithms for deep multi-agent reinforcement learning (MARL) typically employ a policy update that responds to the current strategies of other agents. While being straightforward, this approach does not account for the updates of other agents at the same update step, resulting in miscoordination. In this paper, we introduce the $K$-Level Policy Gradient (KPG), a method that recursively updates each agent against the updated policies of other agents, speeding up the discovery of effective coordinated policies. We theoretically prove that KPG with finite iterates achieves monotonic convergence to a local Nash equilibrium under certain conditions. We provide principled implementations of KPG by applying it to the deep MARL algorithms MAPPO, MADDPG, and FACMAC. Empirically, we demonstrate superior performance over existing deep MARL algorithms in StarCraft II and multi-agent MuJoCo.', 'abstract_zh': '深度多agents强化学习中基于演员-评论家算法的$K$级策略梯度（KPG）', 'title_zh': '$K$级策略梯度在多智能体强化学习中的应用'}
{'arxiv_id': 'arXiv:2509.12107', 'title': "Exploring Conversational Design Choices in LLMs for Pedagogical Purposes: Socratic and Narrative Approaches for Improving Instructor's Teaching Practice", 'authors': 'Si Chen, Isabel R. Molnar, Peiyu Li, Adam Acunin, Ting Hua, Alex Ambrose, Nitesh V. Chawla, Ronald Metoyer', 'link': 'https://arxiv.org/abs/2509.12107', 'abstract': "Large language models (LLMs) typically generate direct answers, yet they are increasingly used as learning tools. Studying instructors' usage is critical, given their role in teaching and guiding AI adoption in education. We designed and evaluated TeaPT, an LLM for pedagogical purposes that supports instructors' professional development through two conversational approaches: a Socratic approach that uses guided questioning to foster reflection, and a Narrative approach that offers elaborated suggestions to extend externalized cognition. In a mixed-method study with 41 higher-education instructors, the Socratic version elicited greater engagement, while the Narrative version was preferred for actionable guidance. Subgroup analyses further revealed that less-experienced, AI-optimistic instructors favored the Socratic version, whereas more-experienced, AI-cautious instructors preferred the Narrative version. We contribute design implications for LLMs for pedagogical purposes, showing how adaptive conversational approaches can support instructors with varied profiles while highlighting how AI attitudes and experience shape interaction and learning.", 'abstract_zh': '大型语言模型（LLMs）通常生成直接答案，但它们越来越多地被用作学习工具。鉴于其在教育中教学和引导AI采用中的角色，研究教师的使用情况至关重要。我们设计并评估了TeaPT，这是一种旨在教学目的的LLM，通过两种对话式方法支持教师的专业发展：一种苏格拉底式方法，通过引导性提问促进反思；另一种叙述式方法，提供详细的建议以扩展外部化认知。在一项涉及41名高等教育教师的混合方法研究中，苏格拉底式版本引起了更高的参与度，而叙述式版本则因提供可操作的指导而更受欢迎。进一步的子组分析显示，乐观看待AI的不那么有经验的教师更倾向于苏格拉底式版本，而谨慎看待AI的更资深教师则更偏好叙述式版本。我们为旨在教学目的的LLM提供了设计启示，展示了适应性对话式方法如何支持具有不同背景的教师，同时突显了AI态度和经验如何影响互动和学习。', 'title_zh': '探索用于教学目的的LLM对话设计选择：苏格拉底式和叙述式方法以改善教师的教学实践'}
{'arxiv_id': 'arXiv:2509.12102', 'title': 'Can LLMs Address Mental Health Questions? A Comparison with Human Therapists', 'authors': 'Synthia Wang, Yuwei Cheng, Austin Song, Sarah Keedy, Marc Berman, Nick Feamster', 'link': 'https://arxiv.org/abs/2509.12102', 'abstract': 'Limited access to mental health care has motivated the use of digital tools and conversational agents powered by large language models (LLMs), yet their quality and reception remain unclear. We present a study comparing therapist-written responses to those generated by ChatGPT, Gemini, and Llama for real patient questions. Text analysis showed that LLMs produced longer, more readable, and lexically richer responses with a more positive tone, while therapist responses were more often written in the first person. In a survey with 150 users and 23 licensed therapists, participants rated LLM responses as clearer, more respectful, and more supportive than therapist-written answers. Yet, both groups of participants expressed a stronger preference for human therapist support. These findings highlight the promise and limitations of LLMs in mental health, underscoring the need for designs that balance their communicative strengths with concerns of trust, privacy, and accountability.', 'abstract_zh': '有限的心理健康护理访问促进了由大规模语言模型驱动的数字工具和对话代理的应用，但其质量与接受度尚不明确。我们对ChatGPT、Gemini和Llama生成的回答与治疗师撰写的回答进行了比较，以应对真实患者的问题。文本分析显示，大规模语言模型生成的回答更长、更易读、词汇更加丰富，并且语气更加积极，而治疗师的回答更多采用第一人称；在包含150名用户和23名执业治疗师的调查中，参与者认为语言模型的回答更加清晰、更有礼貌、也更加支持患者；然而，两组参与者都更偏好人类治疗师的支持。这些发现突显了在心理健康领域大规模语言模型的潜力与限制，强调了平衡其通信优势与信任、隐私和问责担忧的设计需求。', 'title_zh': 'LLM在解答心理健康问题方面的能力：与人类治疗师的比较'}
{'arxiv_id': 'arXiv:2509.12101', 'title': 'In-domain SSL pre-training and streaming ASR', 'authors': 'Jarod Duret, Salima Mdhaffar, Gaëlle Laperrière, Ryan Whetten, Audrey Galametz, Catherine Kobus, Marion-Cécile Martin, Jo Oleiwan, Yannick Estève', 'link': 'https://arxiv.org/abs/2509.12101', 'abstract': 'In this study, we investigate the benefits of domain-specific self-supervised pre-training for both offline and streaming ASR in Air Traffic Control (ATC) environments. We train BEST-RQ models on 4.5k hours of unlabeled ATC data, then fine-tune on a smaller supervised ATC set. To enable real-time processing, we propose using chunked attention and dynamic convolutions, ensuring low-latency inference. We compare these in-domain SSL models against state-of-the-art, general-purpose speech encoders such as w2v-BERT 2.0 and HuBERT. Results show that domain-adapted pre-training substantially improves performance on standard ATC benchmarks, significantly reducing word error rates when compared to models trained on broad speech corpora. Furthermore, the proposed streaming approach further improves word error rate under tighter latency constraints, making it particularly suitable for safety-critical aviation applications. These findings highlight that specializing SSL representations for ATC data is a practical path toward more accurate and efficient ASR systems in real-world operational settings.', 'abstract_zh': '本研究探讨了领域特定自监督预训练对空中交通控制（ATC）环境中离线和实时ASR的好处。', 'title_zh': '领域内SSL预训练与流式ASR'}
{'arxiv_id': 'arXiv:2509.12098', 'title': "Is 'Hope' a person or an idea? A pilot benchmark for NER: comparing traditional NLP tools and large language models on ambiguous entities", 'authors': 'Payam Latifi', 'link': 'https://arxiv.org/abs/2509.12098', 'abstract': "This pilot study presents a small-scale but carefully annotated benchmark of Named Entity Recognition (NER) performance across six systems: three non-LLM NLP tools (NLTK, spaCy, Stanza) and three general-purpose large language models (LLMs: Gemini-1.5-flash, DeepSeek-V3, Qwen-3-4B). The dataset contains 119 tokens covering five entity types (PERSON, LOCATION, ORGANIZATION, DATE, TIME). We evaluated each system's output against the manually annotated gold standard dataset using F1-score. The results show that LLMs generally outperform conventional tools in recognizing context-sensitive entities like person names, with Gemini achieving the highest average F1-score. However, traditional systems like Stanza demonstrate greater consistency in structured tags such as LOCATION and DATE. We also observed variability among LLMs, particularly in handling temporal expressions and multi-word organizations. Our findings highlight that while LLMs offer improved contextual understanding, traditional tools remain competitive in specific tasks, informing model selection.", 'abstract_zh': '本试点工作展示了六个系统在命名实体识别（NER）表现上的小型但仔细标注的基准数据，包括三个非大语言模型的NLP工具（NLTK、spaCy、Stanza）和三个通用大语言模型（LLM：Gemini-1.5-flash、DeepSeek-V3、Qwen-3-4B）。数据集包含119个标记，涵盖五种实体类型（PERSON、LOCATION、ORGANIZATION、DATE、TIME）。我们使用F1分数评估了每个系统的输出与手工标注的黄金标准数据集的匹配度。结果表明，大语言模型在识别如人名等上下文敏感实体方面总体上优于传统工具，Gemini获得最高的平均F1分数。然而，传统系统如Stanza在如LOCATION和DATE等结构化标签上表现出更大的一致性。我们还观察到大语言模型之间在处理时间表达式和多词组织方面的差异性。本研究发现强调，尽管大语言模型提供了更好的上下文理解能力，但传统工具在特定任务中仍然具有竞争力，为模型选择提供了指导。', 'title_zh': '"Hope"是人还是理念？一种命名实体识别试点基准：传统NLP工具与大型语言模型对模糊实体的比较'}
{'arxiv_id': 'arXiv:2509.12081', 'title': 'Deceptive Risk Minimization: Out-of-Distribution Generalization by Deceiving Distribution Shift Detectors', 'authors': 'Anirudha Majumdar', 'link': 'https://arxiv.org/abs/2509.12081', 'abstract': 'This paper proposes deception as a mechanism for out-of-distribution (OOD) generalization: by learning data representations that make training data appear independent and identically distributed (iid) to an observer, we can identify stable features that eliminate spurious correlations and generalize to unseen domains. We refer to this principle as deceptive risk minimization (DRM) and instantiate it with a practical differentiable objective that simultaneously learns features that eliminate distribution shifts from the perspective of a detector based on conformal martingales while minimizing a task-specific loss. In contrast to domain adaptation or prior invariant representation learning methods, DRM does not require access to test data or a partitioning of training data into a finite number of data-generating domains. We demonstrate the efficacy of DRM on numerical experiments with concept shift and a simulated imitation learning setting with covariate shift in environments that a robot is deployed in.', 'abstract_zh': '本文提出欺骗作为一种机制实现领域外（OOD）泛化：通过学习数据表示使得训练数据对于观察者看起来是独立且相同分布（iid）的，我们可以识别出稳定的不依赖于虚假相关性的特征，并将这些特征泛化到未见过的领域。我们将这一原则称为欺骗风险最小化（DRM），并提出了一种实用的可微目标函数，该函数同时从基于容许 martingales 的检测器的角度学习消除分布偏移的特征，同时最小化特定任务的损失。与领域适应或先验不变表示学习方法不同，DRM 不需要访问测试数据或对训练数据进行有限的领域划分。我们通过概念偏移的数值实验和机器人部署环境中协变量偏移的模拟 imitative 学习设置来验证 DRM 的有效性。', 'title_zh': '欺骗风险最小化：通过欺骗分布转移检测器实现分布外泛化'}
{'arxiv_id': 'arXiv:2509.12080', 'title': 'A Time-Series Foundation Model by Universal Delay Embedding', 'authors': 'Zijian Wang, Peng Tao, Jifan Shi, Rui Bao, Rui Liu, Luonan Chen', 'link': 'https://arxiv.org/abs/2509.12080', 'abstract': "This study introduces Universal Delay Embedding (UDE), a pretrained foundation model designed to revolutionize time-series forecasting through principled integration of delay embedding representation and Koopman operator prediction. Leveraging Takens' embedding theorem, UDE as a dynamical representation of observed data constructs two-dimensional subspace patches from Hankel matrices, theoretically preserving dynamical and topological properties of underlying dynamical systems. Such patches are viewed as images, which can be efficiently processed by exploiting advanced deep learning technologies. Computationally, these patches further serve as tokens for learning a self-attention encoder, thus enabling accurate prediction of nonlinear time-series by a finite-dimensional Koopman operator in a linear manner in a latent space. Extensive evaluations across various benchmarks and real-world climate datasets demonstrate over 20% average reduction in mean squared error versus state-of-the-art foundation models, alongside superior generalization in fine-tuning scenarios. In particular, the learned dynamical representations and Koopman operator prediction forms from the patches exhibit exceptional interpretability, with consistent identification of topologically informative subspaces and robust encoding of domain-invariant dynamics, establishing UDE as a scalable, interpretable framework for universal time-series modeling and forecasting with broad scientific and industrial applicability.", 'abstract_zh': 'Universal Delay Embedding：一种通过原理性结合延迟嵌入表示和科伯曼算子预测来革新时间序列预测的预训练基础模型', 'title_zh': '一种由通用延迟嵌入构建的时间序列基础模型'}
{'arxiv_id': 'arXiv:2509.12074', 'title': 'Early Detection of Branched Broomrape (Phelipanche ramosa) Infestation in Tomato Crops Using Leaf Spectral Analysis and Machine Learning', 'authors': 'Mohammadreza Narimani, Alireza Pourreza, Ali Moghimi, Parastoo Farajpoor, Hamid Jafarbiglu, Mohsen B. Mesgaran', 'link': 'https://arxiv.org/abs/2509.12074', 'abstract': 'Branched broomrape (Phelipanche ramosa) is a chlorophyll-deficient parasitic weed that threatens tomato production by extracting nutrients from the host. We investigate early detection using leaf-level spectral reflectance (400-2500 nm) and ensemble machine learning. In a field experiment in Woodland, California, we tracked 300 tomato plants across growth stages defined by growing degree days (GDD). Leaf reflectance was acquired with a portable spectrometer and preprocessed (band denoising, 1 nm interpolation, Savitzky-Golay smoothing, correlation-based band reduction). Clear class differences were observed near 1500 nm and 2000 nm water absorption features, consistent with reduced leaf water content in infected plants at early stages. An ensemble combining Random Forest, XGBoost, SVM with RBF kernel, and Naive Bayes achieved 89% accuracy at 585 GDD, with recalls of 0.86 (infected) and 0.93 (noninfected). Accuracy declined at later stages (e.g., 69% at 1568 GDD), likely due to senescence and weed interference. Despite the small number of infected plants and environmental confounders, results show that proximal sensing with ensemble learning enables timely detection of broomrape before canopy symptoms are visible, supporting targeted interventions and reduced yield losses.', 'abstract_zh': 'Phelipanche ramosa（分枝.INFO盗/photosynthesis）缺乏叶绿素的寄生杂草，通过从寄主植物吸取养分威胁番茄生产。我们利用叶水平光谱反射率（400-2500 nm）和集成机器学习研究早期检测方法。在加利福尼亚州伍德兰进行的田间实验中，我们跟踪了300株番茄植株，这些植株按生长度日（GDD）定义的生长阶段进行跟踪。通过便携式分光光度计获取叶片反射率，并进行了预处理（带噪声去除、1 nm插值、Savitzky-Golay平滑、基于相关性的波段减少）。观察到了1500 nm和2000 nm水吸收特征附近的明显类别差异，这与早期感染植物叶片中水分含量减少一致。结合随机森林、XGBoost、RBF核支持向量机（SVM）和朴素贝叶斯的集成模型在585 GDD时实现了89%的准确性，召回率为0.86（感染）和0.93（非感染）。在后期阶段，准确性下降（例如，在1568 GDD时为69%），这可能归因于叶片衰老和杂草竞争。尽管感染植株数量有限且存在环境混杂因素，结果表明，集成学习的邻近光谱感应能够使研究人员在冠层症状可见之前及时检测到INFO盗，从而支持目标干预并减少产量损失。', 'title_zh': '使用叶片光谱分析和机器学习早期检测番茄田中的分枝雀麦寄生'}
{'arxiv_id': 'arXiv:2509.12069', 'title': 'U-Mamba2: Scaling State Space Models for Dental Anatomy Segmentation in CBCT', 'authors': 'Zhi Qin Tan, Xiatian Zhu, Owen Addison, Yunpeng Li', 'link': 'https://arxiv.org/abs/2509.12069', 'abstract': 'Cone-Beam Computed Tomography (CBCT) is a widely used 3D imaging technique in dentistry, providing volumetric information about the anatomical structures of jaws and teeth. Accurate segmentation of these anatomies is critical for clinical applications such as diagnosis and surgical planning, but remains time-consuming and challenging. In this paper, we present U-Mamba2, a new neural network architecture designed for multi-anatomy CBCT segmentation in the context of the ToothFairy3 challenge. U-Mamba2 integrates the Mamba2 state space models into the U-Net architecture, enforcing stronger structural constraints for higher efficiency without compromising performance. In addition, we integrate interactive click prompts with cross-attention blocks, pre-train U-Mamba2 using self-supervised learning, and incorporate dental domain knowledge into the model design to address key challenges of dental anatomy segmentation in CBCT. Extensive experiments, including independent tests, demonstrate that U-Mamba2 is both effective and efficient, securing top 3 places in both tasks of the Toothfairy3 challenge. In Task 1, U-Mamba2 achieved a mean Dice of 0.792, HD95 of 93.19 with the held-out test data, with an average inference time of XX (TBC during the ODIN workshop). In Task 2, U-Mamba2 achieved the mean Dice of 0.852 and HD95 of 7.39 with the held-out test data. The code is publicly available at this https URL.', 'abstract_zh': 'Cone-Beam 计算机断层成像（CBCT）在牙科中的应用及其多 Anatomy 分割的 U-Mamba2 神经网络架构', 'title_zh': 'U-Mamba2: 扩展状态空间模型在CBCT牙科解剖分割中的应用'}
{'arxiv_id': 'arXiv:2509.12053', 'title': 'LEGO: Spatial Accelerator Generation and Optimization for Tensor Applications', 'authors': 'Yujun Lin, Zhekai Zhang, Song Han', 'link': 'https://arxiv.org/abs/2509.12053', 'abstract': 'Modern tensor applications, especially foundation models and generative AI applications require multiple input modalities (both vision and language), which increases the demand for flexible accelerator architecture. Existing frameworks suffer from the trade-off between design flexibility and productivity of RTL generation: either limited to very few hand-written templates or cannot automatically generate the RTL. To address this challenge, we propose the LEGO framework, which targets tensor applications and automatically generates spatial architecture design and outputs synthesizable RTL code without handwritten RTL design templates. Leveraging the affine-transformation-based architecture representation, LEGO front end finds interconnections between function units, synthesizes the memory system, and fuses different spatial dataflow designs based on data reuse analysis. LEGO back end then translates the hardware in a primitive-level graph to perform lower-level optimizations, and applies a set of linear-programming algorithms to optimally insert pipeline registers and reduce the overhead of unused logic when switching spatial dataflows. Our evaluation demonstrates that LEGO can achieve 3.2x speedup and 2.4x energy efficiency compared to previous work Gemmini, and can generate one architecture for diverse modern foundation models in generative AI applications.', 'abstract_zh': '现代张量应用，尤其是基础模型和生成AI应用，需要多种输入模态（包括视觉和语言），这增加了对灵活加速器架构的需求。现有框架在设计灵活性与RTL生成生产力之间存在权衡：要么仅限于很少的手写模板，要么无法自动生成RTL。为了解决这一挑战，我们提出了LEGO框架，该框架针对张量应用并自动生成空间架构设计和可综合的RTL代码，无需手写RTL设计模板。利用基于仿射变换的架构表示，LEGO前端找到功能单元之间的连接，合成内存系统，并根据数据重用分析融合不同的空间数据流设计。LEGO后端将硬件在原始级图中进行转换以执行低级别优化，并应用一组线性规划算法，在切换空间数据流时优化插入流水线寄存器并减少未使用逻辑的开销。我们的评估显示，LEGO相对于先前工作Gemmini可以实现3.2倍的加速和2.4倍的能量效率改进，并能够为生成AI应用中的各种现代基础模型生成一个架构。', 'title_zh': 'LEGO：张量应用中空间加速器的生成与优化'}
{'arxiv_id': 'arXiv:2509.12049', 'title': 'Interaction-Driven Browsing: A Human-in-the-Loop Conceptual Framework Informed by Human Web Browsing for Browser-Using Agents', 'authors': 'Hyeonggeun Yun, Jinkyu Jang', 'link': 'https://arxiv.org/abs/2509.12049', 'abstract': "Although browser-using agents (BUAs) show promise for web tasks and automation, most BUAs terminate after executing a single instruction, failing to support users' complex, nonlinear browsing with ambiguous goals, iterative decision-making, and changing contexts. We present a human-in-the-loop (HITL) conceptual framework informed by theories of human web browsing behavior. The framework centers on an iterative loop in which the BUA proactively proposes next actions and the user steers the browsing process through feedback. It also distinguishes between exploration and exploitation actions, enabling users to control the breadth and depth of their browsing. Consequently, the framework aims to reduce users' physical and cognitive effort while preserving users' traditional browsing mental model and supporting users in achieving satisfactory outcomes. We illustrate how the framework operates with hypothetical use cases and discuss the shift from manual browsing to interaction-driven browsing. We contribute a theoretically informed conceptual framework for BUAs.", 'abstract_zh': '尽管浏览器使用的代理（BUAs）在网页任务和自动化方面展现出潜力，但大多数BUAs在执行单个指令后就会终止，无法支持用户复杂的、非线性的浏览行为，以及具有模糊目标的迭代决策和不断变化的情境。我们提出了一个基于人类网页浏览行为理论的人工智能辅助浏览框架（HITL）。该框架围绕BUA主动提案并由用户通过反馈引导浏览过程的迭代循环，区分探索性和利用性行为，使用户能够控制其浏览的广度和深度。因此，该框架旨在减少用户的体力和认知消耗，同时保持用户传统的浏览心智模型，并支持用户实现满意的结果。我们通过假设的应用场景阐述了该框架的操作机制，并讨论了从手动浏览到互动驱动浏览的转变。我们贡献了一个基于理论的人工智能代理框架。', 'title_zh': '基于交互的浏览：由人类网页浏览行为启发的人机在环概念框架'}
{'arxiv_id': 'arXiv:2509.12047', 'title': 'A Computer Vision Pipeline for Individual-Level Behavior Analysis: Benchmarking on the Edinburgh Pig Dataset', 'authors': 'Haiyu Yang, Enhong Liu, Jennifer Sun, Sumit Sharma, Meike van Leerdam, Sebastien Franceschini, Puchun Niu, Miel Hostens', 'link': 'https://arxiv.org/abs/2509.12047', 'abstract': 'Animal behavior analysis plays a crucial role in understanding animal welfare, health status, and productivity in agricultural settings. However, traditional manual observation methods are time-consuming, subjective, and limited in scalability. We present a modular pipeline that leverages open-sourced state-of-the-art computer vision techniques to automate animal behavior analysis in a group housing environment. Our approach combines state-of-the-art models for zero-shot object detection, motion-aware tracking and segmentation, and advanced feature extraction using vision transformers for robust behavior recognition. The pipeline addresses challenges including animal occlusions and group housing scenarios as demonstrated in indoor pig monitoring. We validated our system on the Edinburgh Pig Behavior Video Dataset for multiple behavioral tasks. Our temporal model achieved 94.2% overall accuracy, representing a 21.2 percentage point improvement over existing methods. The pipeline demonstrated robust tracking capabilities with 93.3% identity preservation score and 89.3% object detection precision. The modular design suggests potential for adaptation to other contexts, though further validation across species would be required. The open-source implementation provides a scalable solution for behavior monitoring, contributing to precision pig farming and welfare assessment through automated, objective, and continuous analysis.', 'abstract_zh': '动物行为分析在理解动物福利、健康状态和生产性能中的作用至关重要。然而，传统的手工观察方法耗时、主观且可扩展性有限。我们提出了一种模块化管道，利用开源的先进计算机视觉技术来自动化群体饲养环境中的动物行为分析。我们的方法结合了零样本对象检测、运动感知跟踪和分割的先进模型，以及使用视觉变换器进行高级特征提取的稳健行为识别。该管道解决了包括动物遮挡和群体饲养场景在内的挑战，如在室内猪监测中所示。我们在爱丁堡猪行为视频数据集上对我们的系统进行了多任务验证。我们的时序模型overall accuracy达到94.2%，比现有方法高出21.2个百分点。管道表现出强大的跟踪能力，身份保留得分为93.3%，物体检测精确度为89.3%。模块化设计表明该系统具有适应其他情境的潜力，但需要在其他物种中进行进一步验证。开源实现提供了可扩展的行为监测解决方案，通过自动、客观和连续的分析，推动精准养猪和福利评估。', 'title_zh': '基于爱丁堡猪数据集的个体水平行为分析计算机视觉流程：基准测试'}
{'arxiv_id': 'arXiv:2509.12046', 'title': 'Layout-Conditioned Autoregressive Text-to-Image Generation via Structured Masking', 'authors': 'Zirui Zheng, Takashi Isobe, Tong Shen, Xu Jia, Jianbin Zhao, Xiaomin Li, Mengmeng Ge, Baolu Li, Qinghe Wang, Dong Li, Dong Zhou, Yunzhi Zhuge, Huchuan Lu, Emad Barsoum', 'link': 'https://arxiv.org/abs/2509.12046', 'abstract': 'While autoregressive (AR) models have demonstrated remarkable success in image generation, extending them to layout-conditioned generation remains challenging due to the sparse nature of layout conditions and the risk of feature entanglement. We present Structured Masking for AR-based Layout-to-Image (SMARLI), a novel framework for layoutto-image generation that effectively integrates spatial layout constraints into AR-based image generation. To equip AR model with layout control, a specially designed structured masking strategy is applied to attention computation to govern the interaction among the global prompt, layout, and image tokens. This design prevents mis-association between different regions and their descriptions while enabling sufficient injection of layout constraints into the generation process. To further enhance generation quality and layout accuracy, we incorporate Group Relative Policy Optimization (GRPO) based post-training scheme with specially designed layout reward functions for next-set-based AR models. Experimental results demonstrate that SMARLI is able to seamlessly integrate layout tokens with text and image tokens without compromising generation quality. It achieves superior layoutaware control while maintaining the structural simplicity and generation efficiency of AR models.', 'abstract_zh': '基于结构化掩模的布局引导图像生成框架（SMARLI）', 'title_zh': '基于布局条件的自回归文本到图像生成方法：结构化掩码方案'}
{'arxiv_id': 'arXiv:2509.12040', 'title': 'Exploring Efficient Open-Vocabulary Segmentation in the Remote Sensing', 'authors': 'Bingyu Li, Haocheng Dong, Da Zhang, Zhiyuan Zhao, Junyu Gao, Xuelong Li', 'link': 'https://arxiv.org/abs/2509.12040', 'abstract': 'Open-Vocabulary Remote Sensing Image Segmentation (OVRSIS), an emerging task that adapts Open-Vocabulary Segmentation (OVS) to the remote sensing (RS) domain, remains underexplored due to the absence of a unified evaluation benchmark and the domain gap between natural and RS images. To bridge these gaps, we first establish a standardized OVRSIS benchmark (\\textbf{OVRSISBench}) based on widely-used RS segmentation datasets, enabling consistent evaluation across methods. Using this benchmark, we comprehensively evaluate several representative OVS/OVRSIS models and reveal their limitations when directly applied to remote sensing scenarios. Building on these insights, we propose \\textbf{RSKT-Seg}, a novel open-vocabulary segmentation framework tailored for remote sensing. RSKT-Seg integrates three key components: (1) a Multi-Directional Cost Map Aggregation (RS-CMA) module that captures rotation-invariant visual cues by computing vision-language cosine similarities across multiple directions; (2) an Efficient Cost Map Fusion (RS-Fusion) transformer, which jointly models spatial and semantic dependencies with a lightweight dimensionality reduction strategy; and (3) a Remote Sensing Knowledge Transfer (RS-Transfer) module that injects pre-trained knowledge and facilitates domain adaptation via enhanced upsampling. Extensive experiments on the benchmark show that RSKT-Seg consistently outperforms strong OVS baselines by +3.8 mIoU and +5.9 mACC, while achieving 2x faster inference through efficient aggregation. Our code is \\href{this https URL}{\\textcolor{blue}{here}}.', 'abstract_zh': '开放词汇遥感图像分割：面向遥感领域的新兴任务（OVRSIS）及其评估基准（OVRSISBench）与新型开放词汇分割框架（RSKT-Seg）', 'title_zh': '探索遥感中的高效开放式词汇分割方法'}
{'arxiv_id': 'arXiv:2509.12026', 'title': 'Imitation Learning as Return Distribution Matching', 'authors': 'Filippo Lazzati, Alberto Maria Metelli', 'link': 'https://arxiv.org/abs/2509.12026', 'abstract': "We study the problem of training a risk-sensitive reinforcement learning (RL) agent through imitation learning (IL). Unlike standard IL, our goal is not only to train an agent that matches the expert's expected return (i.e., its average performance) but also its risk attitude (i.e., other features of the return distribution, such as variance). We propose a general formulation of the risk-sensitive IL problem in which the objective is to match the expert's return distribution in Wasserstein distance. We focus on the tabular setting and assume the expert's reward is known. After demonstrating the limited expressivity of Markovian policies for this task, we introduce an efficient and sufficiently expressive subclass of non-Markovian policies tailored to it. Building on this subclass, we develop two provably efficient algorithms, RS-BC and RS-KT, for solving the problem when the transition model is unknown and known, respectively. We show that RS-KT achieves substantially lower sample complexity than RS-BC by exploiting dynamics information. We further demonstrate the sample efficiency of return distribution matching in the setting where the expert's reward is unknown by designing an oracle-based variant of RS-KT. Finally, we complement our theoretical analysis of RS-KT and RS-BC with numerical simulations, highlighting both their sample efficiency and the advantages of non-Markovian policies over standard sample-efficient IL algorithms.", 'abstract_zh': '我们研究通过模仿学习训练风险敏感的强化学习代理的问题。与标准的模仿学习不同，我们的目标不仅是要训练一个能够匹配专家预期回报（即其平均性能）的代理，还要匹配专家的风险态度（即回报分布的其他特征，如方差）。我们提出了一种风险敏感的模仿学习问题的一般公式，其中目标是通过Wasserstein距离匹配专家的回报分布。我们专注于表型设置，并假设专家的奖励是已知的。在展示了马尔可夫策略在此任务上的表达能力有限之后，我们引入了一类高效且足够表达的非马尔可夫策略子类，专门用于此任务。基于这一子类，我们开发了两种各自在转移模型未知和已知情况下解决问题的可证明高效的算法，RS-BC和RS-KT。我们通过利用动力学信息证明RS-KT的样本复杂度显著低于RS-BC。我们还通过设计基于 oracle 的RS-KT变种在专家奖励未知的情况下展示了回报分布匹配的样本效率。最后，通过数值模拟补充了对RS-KT和RS-BC的理论分析，强调了非马尔可夫策略相对于标准样本高效模仿学习算法的优势。', 'title_zh': 'imitation learning作为回报分布匹配'}
{'arxiv_id': 'arXiv:2509.12019', 'title': 'AMQ: Enabling AutoML for Mixed-precision Weight-Only Quantization of Large Language Models', 'authors': 'Sangjun Lee, Seung-taek Woo, Jungyu Jin, Changhun Lee, Eunhyeok Park', 'link': 'https://arxiv.org/abs/2509.12019', 'abstract': 'To enable broader deployment of Large Language Models (LLMs), it is essential to identify the best-performing model under strict memory constraints. We present AMQ, Automated Mixed-Precision Weight-Only Quantization, a framework that assigns layer-wise quantization bit-widths to optimally balance model quality and memory usage. However, the combinatorial search space, with over 10^{100} possible configurations, makes conventional black-box optimization infeasible. AMQ overcomes this challenge through four key innovations:(1) search space pruning using prior knowledge to exclude unpromising configurations, (2) quantization proxy to bypass costly format conversions during search, (3) quality predictor to minimize evaluation overhead, and (4) iterative search-and-update strategy for fast and stable convergence. By integrating these components, AMQ efficiently explores the quality-efficiency landscape, reaching the Pareto frontier and yielding LLMs that are both compact and high-performing. Our code is available at this https URL.', 'abstract_zh': '为在严格的内存约束下广泛部署大型语言模型，有必要识别出最佳性能模型。我们介绍了AMQ，一种自动化混合精度权重-only量化框架，该框架按层分配量化位宽以最优地平衡模型质量和内存使用。然而，由于超过10^{100}种可能配置的组合搜索空间使得常规的黑盒优化不可行。AMQ通过四大创新克服这一挑战：(1) 利用先验知识进行搜索空间剪枝以排除无前途的配置；(2) 量化代理以在搜索过程中绕过昂贵的格式转换；(3) 质量预测器以减少评估开销；(4) 迭代搜索与更新策略以实现快速和稳定的收敛。通过整合这些组件，AMQ高效地探索了质量和效率的景观，达到了帕累托前沿，提供了既紧凑又高性能的大型语言模型。我们的代码可从此链接获得：this https URL。', 'title_zh': 'AMQ: 使自动机器学习适用于大规模语言模型的混合精度权重-only量化'}
{'arxiv_id': 'arXiv:2509.12010', 'title': 'Generalizing Behavior via Inverse Reinforcement Learning with Closed-Form Reward Centroids', 'authors': 'Filippo Lazzati, Alberto Maria Metelli', 'link': 'https://arxiv.org/abs/2509.12010', 'abstract': 'We study the problem of generalizing an expert agent\'s behavior, provided through demonstrations, to new environments and/or additional constraints. Inverse Reinforcement Learning (IRL) offers a promising solution by seeking to recover the expert\'s underlying reward function, which, if used for planning in the new settings, would reproduce the desired behavior. However, IRL is inherently ill-posed: multiple reward functions, forming the so-called feasible set, can explain the same observed behavior. Since these rewards may induce different policies in the new setting, in the absence of additional information, a decision criterion is needed to select which policy to deploy. In this paper, we propose a novel, principled criterion that selects the "average" policy among those induced by the rewards in a certain bounded subset of the feasible set. Remarkably, we show that this policy can be obtained by planning with the reward centroid of that subset, for which we derive a closed-form expression. We then present a provably efficient algorithm for estimating this centroid using an offline dataset of expert demonstrations only. Finally, we conduct numerical simulations that illustrate the relationship between the expert\'s behavior and the behavior produced by our method.', 'abstract_zh': '我们研究如何通过演示将专家代理的行为泛化到新环境或附加约束中。逆强化学习（IRL）提供了一种有前景的解决方案，通过寻求恢复专家的潜在奖励函数，从而在新环境中使用这些奖励进行规划，重现期望的行为。然而，IRL 本质上是病态的：可以解释相同观察行为的各种奖励函数构成了所谓的可行集。由于这些奖励在新环境中可能会诱导出不同的策略，在缺乏额外信息的情况下，需要一个决策标准来选择要部署的策略。在本文中，我们提出了一种新颖且有原则的方法，选择由某个可行集有界子集中的奖励诱导出的“平均”策略。令人惊讶的是，我们展示了可以通过使用该子集的奖励质心进行规划，来获得此策略，并推导出其闭式表达式。我们随后提出了一种仅使用专家演示的离线数据集来证明高效算法来估计此质心。最后，我们进行了数值模拟，以说明专家行为与我们方法产生的行为之间的关系。', 'title_zh': '基于闭形式奖励质心的逆强化学习行为泛化'}
{'arxiv_id': 'arXiv:2509.11991', 'title': 'Text Adaptation to Plain Language and Easy Read via Automatic Post-Editing Cycles', 'authors': 'Jesús Calleja, David Ponce, Thierry Etchegoyhen', 'link': 'https://arxiv.org/abs/2509.11991', 'abstract': "We describe Vicomtech's participation in the CLEARS challenge on text adaptation to Plain Language and Easy Read in Spanish. Our approach features automatic post-editing of different types of initial Large Language Model adaptations, where successive adaptations are generated iteratively until readability and similarity metrics indicate that no further adaptation refinement can be successfully performed. Taking the average of all official metrics, our submissions achieved first and second place in Plain language and Easy Read adaptation, respectively.", 'abstract_zh': 'Vicomtech在CLEARS挑战赛中关于西班牙语文本适应清晰语言和平易读写的参与和方法', 'title_zh': '通过自动后编辑循环将文本adaptation转换为简单语言和平易阅读格式'}
{'arxiv_id': 'arXiv:2509.11974', 'title': 'Poison to Detect: Detection of Targeted Overfitting in Federated Learning', 'authors': 'Soumia Zohra El Mestari, Maciej Krzysztof Zuziak, Gabriele Lenzini', 'link': 'https://arxiv.org/abs/2509.11974', 'abstract': 'Federated Learning (FL) enables collaborative model training across decentralised clients while keeping local data private, making it a widely adopted privacy-enhancing technology (PET). Despite its privacy benefits, FL remains vulnerable to privacy attacks, including those targeting specific clients. In this paper, we study an underexplored threat where a dishonest orchestrator intentionally manipulates the aggregation process to induce targeted overfitting in the local models of specific clients. Whereas many studies in this area predominantly focus on reducing the amount of information leakage during training, we focus on enabling an early client-side detection of targeted overfitting, thereby allowing clients to disengage before significant harm occurs. In line with this, we propose three detection techniques - (a) label flipping, (b) backdoor trigger injection, and (c) model fingerprinting - that enable clients to verify the integrity of the global aggregation. We evaluated our methods on multiple datasets under different attack scenarios. Our results show that the three methods reliably detect targeted overfitting induced by the orchestrator, but they differ in terms of computational complexity, detection latency, and false-positive rates.', 'abstract_zh': '联邦学习（FL）能够在保持本地数据隐私的同时，使去中心化的客户端进行协作模型训练，使其成为一种广泛应用的隐私增强技术（PET）。尽管具有隐私优势，FL仍然容易受到包括针对特定客户端的攻击在内的隐私攻击。在本文中，我们研究了一种未充分探索的威胁，即不诚实的协调者故意操纵聚合过程，以诱导特定客户端局部模型的目标过拟合。不同于该领域许多研究侧重于减少训练过程中的信息泄露，我们专注于在早期检测特定过拟合，从而允许客户端在造成重大损害之前退出。为此，我们提出了三种检测技术——(a)标签翻转，(b)后门触发注入，以及(c)模型指纹识别，以使客户端能够验证全局聚合的完整性。我们在不同攻击场景下使用多个数据集评估了这些方法。结果显示，这三种方法能够可靠地检测由协调者诱导的目标过拟合，但它们在计算复杂性、检测延迟和误报率方面存在差异。', 'title_zh': '毒药检测： Federated Learning 中目标过拟合的检测'}
{'arxiv_id': 'arXiv:2509.11971', 'title': 'Time-Constrained Intelligent Adversaries for Automation Vulnerability Testing: A Multi-Robot Patrol Case Study', 'authors': 'James C. Ward, Alex Bott, Connor York, Edmund R. Hunt', 'link': 'https://arxiv.org/abs/2509.11971', 'abstract': 'Simulating hostile attacks of physical autonomous systems can be a useful tool to examine their robustness to attack and inform vulnerability-aware design. In this work, we examine this through the lens of multi-robot patrol, by presenting a machine learning-based adversary model that observes robot patrol behavior in order to attempt to gain undetected access to a secure environment within a limited time duration. Such a model allows for evaluation of a patrol system against a realistic potential adversary, offering insight into future patrol strategy design. We show that our new model outperforms existing baselines, thus providing a more stringent test, and examine its performance against multiple leading decentralized multi-robot patrol strategies.', 'abstract_zh': '通过多机器人巡逻视角下的基于机器学习的攻击模型模拟敌对攻击可以成为评估物理自主系统抗攻击 robustness 以及指导防范设计的有效工具。在本文中，我们通过构建一个基于机器学习的对手模型来观察机器人巡逻行为，以期在有限时间内尝试在安全环境中实现未被察觉的访问。该模型允许我们评估巡逻系统对抗现实潜在对手的性能，并为未来的巡逻策略设计提供洞见。我们展示了新模型在性能上优于现有基准，并对其在多个领先的去中心化多机器人巡逻策略中的表现进行了考察。', 'title_zh': '时间约束下的智能对手在自动化脆弱性测试中的多机器人巡逻案例研究'}
{'arxiv_id': 'arXiv:2509.11947', 'title': 'A GPU-Accelerated RAG-Based Telegram Assistant for Supporting Parallel Processing Students', 'authors': 'Guy Tel-Zur', 'link': 'https://arxiv.org/abs/2509.11947', 'abstract': 'This project addresses a critical pedagogical need: offering students continuous, on-demand academic assistance beyond conventional reception hours. I present a domain-specific Retrieval-Augmented Generation (RAG) system powered by a quantized Mistral-7B Instruct model and deployed as a Telegram bot. The assistant enhances learning by delivering real-time, personalized responses aligned with the "Introduction to Parallel Processing" course materials. GPU acceleration significantly improves inference latency, enabling practical deployment on consumer hardware. This approach demonstrates how consumer GPUs can enable affordable, private, and effective AI tutoring for HPC education.', 'abstract_zh': '本项目满足了一个关键的教学需求：为学生提供超出常规接待时间的连续、按需学术支持。我介绍了一种基于量化Mistral-7B Instruct模型的领域特定检索增强生成（RAG）系统，并将其部署为Telegram机器人。助教通过提供与“并行处理导论”课程材料相契合的实时个性化响应来增强学习。GPU加速显著改善了推理延迟，使得该系统能够在消费级硬件上实用部署。此方法展示了如何通过消费级GPU实现高效、私有的HPC教育中负担得起的AI辅导。', 'title_zh': '基于RAG的GPU加速电信助手，用于支持并行处理学生'}
{'arxiv_id': 'arXiv:2509.11942', 'title': 'VisDocSketcher: Towards Scalable Visual Documentation with Agentic Systems', 'authors': 'Luís F. Gomes, Xin Zhou, David Lo, Rui Abreu', 'link': 'https://arxiv.org/abs/2509.11942', 'abstract': 'Visual documentation is an effective tool for reducing the cognitive barrier developers face when understanding unfamiliar code, enabling more intuitive comprehension. Compared to textual documentation, it provides a higher-level understanding of the system structure and data flow. Developers usually prefer visual representations over lengthy textual descriptions for large software systems. Visual documentation is both difficult to produce and challenging to evaluate. Manually creating it is time-consuming, and currently, no existing approach can automatically generate high-level visual documentation directly from code. Its evaluation is often subjective, making it difficult to standardize and automate. To address these challenges, this paper presents the first exploration of using agentic LLM systems to automatically generate visual documentation. We introduce VisDocSketcher, the first agent-based approach that combines static analysis with LLM agents to identify key elements in the code and produce corresponding visual representations. We propose a novel evaluation framework, AutoSketchEval, for assessing the quality of generated visual documentation using code-level metrics. The experimental results show that our approach can valid visual documentation for 74.4% of the samples. It shows an improvement of 26.7-39.8% over a simple template-based baseline. Our evaluation framework can reliably distinguish high-quality (code-aligned) visual documentation from low-quality (non-aligned) ones, achieving an AUC exceeding 0.87. Our work lays the foundation for future research on automated visual documentation by introducing practical tools that not only generate valid visual representations but also reliably assess their quality.', 'abstract_zh': '基于代理型LLM系统的自动生成视觉文档的初步探索', 'title_zh': 'VisDocSketcher: 向 scalable 可视化文档生成系统方向努力'}
{'arxiv_id': 'arXiv:2509.11937', 'title': 'MMORE: Massive Multimodal Open RAG & Extraction', 'authors': 'Alexandre Sallinen, Stefan Krsteski, Paul Teiletche, Marc-Antoine Allard, Baptiste Lecoeur, Michael Zhang, Fabrice Nemo, David Kalajdzic, Matthias Meyer, Mary-Anne Hartley', 'link': 'https://arxiv.org/abs/2509.11937', 'abstract': 'We introduce MMORE, an open-source pipeline for Massive Multimodal Open RetrievalAugmented Generation and Extraction, designed to ingest, transform, and retrieve knowledge from heterogeneous document formats at scale. MMORE supports more than fifteen file types, including text, tables, images, emails, audio, and video, and processes them into a unified format to enable downstream applications for LLMs. The architecture offers modular, distributed processing, enabling scalable parallelization across CPUs and GPUs. On processing benchmarks, MMORE demonstrates a 3.8-fold speedup over single-node baselines and 40% higher accuracy than Docling on scanned PDFs. The pipeline integrates hybrid dense-sparse retrieval and supports both interactive APIs and batch RAG endpoints. Evaluated on PubMedQA, MMORE-augmented medical LLMs improve biomedical QA accuracy with increasing retrieval depth. MMORE provides a robust, extensible foundation for deploying task-agnostic RAG systems on diverse, real-world multimodal data. The codebase is available at this https URL.', 'abstract_zh': 'MMORE：大规模多模态开放检索增强生成与提取开源管道', 'title_zh': 'MMORE：大规模多模态开放RAG与提取'}
{'arxiv_id': 'arXiv:2509.11895', 'title': 'Integrating Prior Observations for Incremental 3D Scene Graph Prediction', 'authors': 'Marian Renz, Felix Igelbrink, Martin Atzmueller', 'link': 'https://arxiv.org/abs/2509.11895', 'abstract': '3D semantic scene graphs (3DSSG) provide compact structured representations of environments by explicitly modeling objects, attributes, and relationships. While 3DSSGs have shown promise in robotics and embodied AI, many existing methods rely mainly on sensor data, not integrating further information from semantically rich environments. Additionally, most methods assume access to complete scene reconstructions, limiting their applicability in real-world, incremental settings. This paper introduces a novel heterogeneous graph model for incremental 3DSSG prediction that integrates additional, multi-modal information, such as prior observations, directly into the message-passing process. Utilizing multiple layers, the model flexibly incorporates global and local scene representations without requiring specialized modules or full scene reconstructions. We evaluate our approach on the 3DSSG dataset, showing that GNNs enriched with multi-modal information such as semantic embeddings (e.g., CLIP) and prior observations offer a scalable and generalizable solution for complex, real-world environments. The full source code of the presented architecture will be made available at this https URL.', 'abstract_zh': '3D语义场景图的增量预测异构图模型', 'title_zh': '集成先验观察以进行增量三维场景图预测'}
{'arxiv_id': 'arXiv:2509.11868', 'title': 'Growing Perspectives: Modelling Embodied Perspective Taking and Inner Narrative Development Using Large Language Models', 'authors': 'Sabrina Patania, Luca Annese, Anna Lambiase, Anita Pellegrini, Tom Foulsham, Azzurra Ruggeri, Silvia Rossi, Silvia Serino, Dimitri Ognibene', 'link': 'https://arxiv.org/abs/2509.11868', 'abstract': "Language and embodied perspective taking are essential for human collaboration, yet few computational models address both simultaneously. This work investigates the PerspAct system [1], which integrates the ReAct (Reason and Act) paradigm with Large Language Models (LLMs) to simulate developmental stages of perspective taking, grounded in Selman's theory [2]. Using an extended director task, we evaluate GPT's ability to generate internal narratives aligned with specified developmental stages, and assess how these influence collaborative performance both qualitatively (action selection) and quantitatively (task efficiency). Results show that GPT reliably produces developmentally-consistent narratives before task execution but often shifts towards more advanced stages during interaction, suggesting that language exchanges help refine internal representations. Higher developmental stages generally enhance collaborative effectiveness, while earlier stages yield more variable outcomes in complex contexts. These findings highlight the potential of integrating embodied perspective taking and language in LLMs to better model developmental dynamics and stress the importance of evaluating internal speech during combined linguistic and embodied tasks.", 'abstract_zh': '语言和身体视角化对于人类协作至关重要，但很少有计算模型同时解决这两个方面。本研究探讨了PerspAct系统[1]，该系统将ReAct（推理与行动） paradigma与大型语言模型（LLMs）结合，模拟视角化发展的阶段，基于Selman的理论[2]。通过扩展导演任务，我们评估了GPT生成与指定发展阶段一致的内部叙事的能力，并评估这些叙事如何在定性（动作选择）和定量（任务效率）层面上影响协作性能。结果显示，GPT在任务执行前可靠地生成了发展一致的叙事，但在互动过程中往往会转向更高级的阶段，表明语言交流有助于细化内部表征。高级的发展阶段一般增强协作效果，而早期阶段在复杂情境中的结果更为多变。这些发现强调了在LLMs中结合身体视角化和语言的潜力，以更好地模拟发展动态，并强调了在联合语言和身体任务中评估内部言语的重要性。', 'title_zh': '成长的视角：使用大规模语言模型建模具身换位思考和内在叙事发展'}
{'arxiv_id': 'arXiv:2509.11865', 'title': 'Tenma: Robust Cross-Embodiment Robot Manipulation with Diffusion Transformer', 'authors': 'Travis Davies, Yiqi Huang, Yunxin Liu, Xiang Chen, Huxian Liu, Luhui Hu', 'link': 'https://arxiv.org/abs/2509.11865', 'abstract': 'Scaling Transformer policies and diffusion models has advanced robotic manipulation, yet combining these techniques in lightweight, cross-embodiment learning settings remains challenging. We study design choices that most affect stability and performance for diffusion-transformer policies trained on heterogeneous, multimodal robot data, and introduce Tenma, a lightweight diffusion-transformer for bi-manual arm control. Tenma integrates multiview RGB, proprioception, and language via a cross-embodiment normalizer that maps disparate state/action spaces into a shared latent space; a Joint State-Time encoder for temporally aligned observation learning with inference speed boosts; and a diffusion action decoder optimized for training stability and learning capacity. Across benchmarks and under matched compute, Tenma achieves an average success rate of 88.95% in-distribution and maintains strong performance under object and scene shifts, substantially exceeding baseline policies whose best in-distribution average is 18.12%. Despite using moderate data scale, Tenma delivers robust manipulation and generalization, indicating the great potential for multimodal and cross-embodiment learning strategies for further augmenting the capacity of transformer-based imitation learning policies.', 'abstract_zh': 'scaling transformer策略和扩散模型促进了机器人操作，但在轻量级、跨体态学习环境中结合这些技术仍具有挑战性。我们研究了对异构多模态机器人数据训练的扩散-变压器策略影响稳定性和性能的主要设计选择，并引入了Tenma，一种轻量级的双臂控制扩散-变压器。Tenma通过跨体态归一化器将不同状态/动作空间映射到共享潜在空间；通过关节状态-时间编码器实现时间对齐的观测学习，并提升推理速度；并通过优化训练稳定性和学习能力的扩散动作解码器。在基准测试中，Tenma的平均成功率在分布内达到88.95%，并在对象和场景变化下保持了强劲表现，大幅超过了平均最佳在分布内成功率仅18.12%的基础策略。尽管使用了中等规模的数据集，Tenma展示了稳健的操作能力和泛化能力，表明了多模态和跨体态学习策略在进一步增强基于变压器的模仿学习策略能力方面的巨大潜力。', 'title_zh': 'Tenma：基于扩散变换器的鲁棒跨身体机器人操作'}
{'arxiv_id': 'arXiv:2509.11862', 'title': 'Bridging Vision Language Models and Symbolic Grounding for Video Question Answering', 'authors': 'Haodi Ma, Vyom Pathak, Daisy Zhe Wang', 'link': 'https://arxiv.org/abs/2509.11862', 'abstract': 'Video Question Answering (VQA) requires models to reason over spatial, temporal, and causal cues in videos. Recent vision language models (VLMs) achieve strong results but often rely on shallow correlations, leading to weak temporal grounding and limited interpretability. We study symbolic scene graphs (SGs) as intermediate grounding signals for VQA. SGs provide structured object-relation representations that complement VLMs holistic reasoning. We introduce SG-VLM, a modular framework that integrates frozen VLMs with scene graph grounding via prompting and visual localization. Across three benchmarks (NExT-QA, iVQA, ActivityNet-QA) and multiple VLMs (QwenVL, InternVL), SG-VLM improves causal and temporal reasoning and outperforms prior baselines, though gains over strong VLMs are limited. These findings highlight both the promise and current limitations of symbolic grounding, and offer guidance for future hybrid VLM-symbolic approaches in video understanding.', 'abstract_zh': '视频问答（VQA）要求模型在视频中推理空间、时间和因果线索。近期的视觉语言模型（VLMs）取得了很好的成果，但往往依赖于浅层的相关性，导致时间定位能力弱和解释性有限。我们研究符号场景图（SGs）作为VQA的中间 grounding 信号。SGs 提供结构化的对象关系表示，补充了VLMs的整体推理。我们引入了SG-VLM，这是一种模块化框架，通过提示和视觉定位将冻结的VLMs与场景图接地结合起来。在三个基准数据集（NExT-QA、iVQA、ActivityNet-QA）和多种VLMs（QwenVL、InternVL）上，SG-VLM 提升了因果和时间推理能力并超过了先前的基线，尽管相对于强VLMs的提升有限。这些发现突显了符号接地的潜力和当前限制，并为未来视觉语言模型-符号综合方法在视频理解中的应用提供了指导。', 'title_zh': '视觉语言模型与符号接地在视频问答中的桥梁构建'}
{'arxiv_id': 'arXiv:2509.11838', 'title': 'Probabilistic Robustness Analysis in High Dimensional Space: Application to Semantic Segmentation Network', 'authors': 'Navid Hashemi, Samuel Sasaki, Diego Manzanas Lopez, Ipek Oguz, Meiyi Ma, Taylor T. Johnson', 'link': 'https://arxiv.org/abs/2509.11838', 'abstract': "Semantic segmentation networks (SSNs) play a critical role in domains such as medical imaging, autonomous driving, and environmental monitoring, where safety hinges on reliable model behavior under uncertainty. Yet, existing probabilistic verification approaches struggle to scale with the complexity and dimensionality of modern segmentation tasks, often yielding guarantees that are too conservative to be practical. We introduce a probabilistic verification framework that is both architecture-agnostic and scalable to high-dimensional outputs. Our approach combines sampling-based reachability analysis with conformal inference (CI) to deliver provable guarantees while avoiding the excessive conservatism of prior methods. To counteract CI's limitations in high-dimensional settings, we propose novel strategies that reduce conservatism without compromising rigor. Empirical evaluation on large-scale segmentation models across CamVid, OCTA-500, Lung Segmentation, and Cityscapes demonstrates that our method provides reliable safety guarantees while substantially tightening bounds compared to SOTA. We also provide a toolbox implementing this technique, available on Github.", 'abstract_zh': '基于概率验证的高维语义分割网络安全性保障框架', 'title_zh': '高维空间中的概率鲁棒性分析：以语义分割网络为例'}
{'arxiv_id': 'arXiv:2509.11824', 'title': 'Data-Driven Analysis of Text-Conditioned AI-Generated Music: A Case Study with Suno and Udio', 'authors': 'Luca Casini, Laura Cros Vila, David Dalmazzo, Anna-Kaisa Kaila, Bob L.T. Sturm', 'link': 'https://arxiv.org/abs/2509.11824', 'abstract': 'Online AI platforms for creating music from text prompts (AI music), such as Suno and Udio, are now being used by hundreds of thousands of users. Some AI music is appearing in advertising, and even charting, in multiple countries. How are these platforms being used? What subjects are inspiring their users? This article answers these questions for Suno and Udio using a large collection of songs generated by users of these platforms from May to October 2024. Using a combination of state-of-the-art text embedding models, dimensionality reduction and clustering methods, we analyze the prompts, tags and lyrics, and automatically annotate and display the processed data in interactive plots. Our results reveal prominent themes in lyrics, language preference, prompting strategies, as well as peculiar attempts at steering models through the use of metatags. To promote the musicological study of the developing cultural practice of AI-generated music we share our code and resources.', 'abstract_zh': '在线AI平台基于文本提示创作音乐（AI音乐），如Suno和Udio，现已被数百万人使用。这些AI音乐开始出现在广告中，并在多个国家的音乐排行榜上出现。这些平台是如何被使用的？什么主题激发了用户？本文通过分析2024年5月至10月这些平台上用户生成的大量歌曲，回答了这些问题。我们结合最新的文本嵌入模型、降维和聚类方法，对提示、标签和歌词进行分析，并自动标注和展示处理后的数据，在交互式图表中呈现。我们的结果显示了歌词中的主要主题、语言偏好、提示策略，以及通过元标签引导模型的独特尝试。为了促进对AI生成音乐这一发展的文化实践的音乐学研究，我们分享了我们的代码和资源。', 'title_zh': '基于数据驱动的文本条件化AI生成音乐分析：一个使用Suno和Udio的案例研究'}
{'arxiv_id': 'arXiv:2509.11816', 'title': 'Collapse of Irrelevant Representations (CIR) Ensures Robust and Non-Disruptive LLM Unlearning', 'authors': 'Filip Sondej, Yushi Yang', 'link': 'https://arxiv.org/abs/2509.11816', 'abstract': 'Current unlearning techniques and safety training consistently fail to remove dangerous knowledge from language models. We analyze the root causes and propose a highly selective technique which unlearns robustly and without disrupting general performance.\nWe perform PCA on activations and module output gradients to identify subspaces containing common representations, and collapse them before calculating unlearning updates. This way we avoid unlearning general representations, and only target those specific to the unlearned facts.\nWhen unlearning WMDP dataset facts from Llama-3.1-8B, we drop post-attack accuracy 80x more than our best baseline (Circuit Breakers) on biohazardous facts and 30x more on cyberhazardous facts. Despite this, we disrupt general performance 30x less (only 0.1% WikiText loss increase), while requiring less than 3 GPU-seconds per fact.', 'abstract_zh': '当前的去学习技术及安全培训一致性地无法从语言模型中移除危险知识。我们分析根本原因并提出一种高度选择性的方法，该方法能够稳健地进行去学习而不干扰一般性能。', 'title_zh': '无关表示崩溃（CIR）确保LLM去学习的鲁棒性和非破坏性'}
{'arxiv_id': 'arXiv:2509.11815', 'title': 'SpecVLM: Fast Speculative Decoding in Vision-Language Models', 'authors': 'Haiduo Huang, Fuwei Yang, Zhenhua Liu, Xuanwu Yin, Dong Li, Pengju Ren, Emad Barsoum', 'link': 'https://arxiv.org/abs/2509.11815', 'abstract': "Speculative decoding is a powerful way to accelerate autoregressive large language models (LLMs), but directly porting it to vision-language models (VLMs) faces unique systems constraints: the prefill stage is dominated by visual tokens whose count scales with image resolution and video length, inflating both compute and memory, especially the key-value (KV) cache. We study speculative decoding for VLMs and introduce SpecVLM, a practical system that (1) establishes a strong EAGLE-2-style baseline, EagleVLM, delivering 1.5--2.3x end-to-end speedups over full autoregressive inference, and (2) further accelerates VLM inference with an elastic visual compressor that adaptively selects among pruning, pooling, convolution, and resampler primitives to balance FLOPs/parameters and accuracy per input. To avoid costly offline distillation corpora, we propose an online-logit distillation protocol that trains the draft model with on-the-fly teacher logits and penultimate features using a combined cross-entropy and Smooth L1 objective, eliminating storage and preprocessing while remaining compute-efficient. This protocol reveals a training-time scaling effect: longer online training monotonically increases the draft model's average accepted length, improving speculative efficiency. Empirically, SpecVLM achieves additional acceleration, culminating in 2.5--2.9x end-to-end speedups within 5 epochs across LLaVA and MMMU, consistently over resolutions and task difficulties, while preserving the target model's output distribution (lossless decoding). Our code is available at this https URL.", 'abstract_zh': '推测性解码是加速自回归大型语言模型（LLMs）的有效方法，但将其直接应用于视觉语言模型（VLMs）面临独特的系统约束：预填充阶段主要由视觉 token 组成，其数量随图像分辨率和视频长度增加，导致计算和内存消耗，尤其是在关键值（KV）缓存方面。我们研究了视觉语言模型的推测性解码，并引入了SpecVLM，该系统（1）建立了强健的EAGLE-2风格基线EagleVLM，相对于完整的自回归推理提供了1.5-2.3倍的端到端加速，并（2）通过一种弹性视觉压缩器进一步加速了VLM推理，该压缩器在剪枝、池化、卷积和重采样基本操作之间动态选择，以平衡每输入的运算量/参数数量和准确性。为了避免昂贵的离线蒸馏数据集，我们提出了一种在线-logit蒸馏协议，该协议使用结合交叉熵和Smooth L1目标，在线训练草稿模型并使用随行教师logits和倒数第二特征，消除了存储和预处理需求，同时保持了计算效率。该协议揭示了训练过程中缩放效应：更长的在线训练单调增加草稿模型的平均接受长度，从而提高推测效率。实验结果显示，SpecVLM 实现了进一步加速，总计在5个周期内实现了2.5-2.9倍的端到端加速，跨越LLaVA和MMMU，无论分辨率和任务难度如何，同时保持目标模型的输出分布（无损解码）。我们的代码可在以下链接获取。', 'title_zh': 'SpecVLM: 快速 speculation 解码在ビジョン-ランゲージ模型中'}
{'arxiv_id': 'arXiv:2509.11731', 'title': 'Bridging the Gap Between Sparsity and Redundancy: A Dual-Decoding Framework with Global Context for Map Inference', 'authors': 'Yudong Shen, Wenyu Wu, Jiali Mao, Yixiao Tong, Guoping Liu, Chaoya Wang', 'link': 'https://arxiv.org/abs/2509.11731', 'abstract': 'Trajectory data has become a key resource for automated map in-ference due to its low cost, broad coverage, and continuous availability. However, uneven trajectory density often leads to frag-mented roads in sparse areas and redundant segments in dense regions, posing significant challenges for existing methods. To address these issues, we propose DGMap, a dual-decoding framework with global context awareness, featuring Multi-scale Grid Encoding, Mask-enhanced Keypoint Extraction, and Global Context-aware Relation Prediction. By integrating global semantic context with local geometric features, DGMap improves keypoint detection accuracy to reduce road fragmentation in sparse-trajectory areas. Additionally, the Global Context-aware Relation Prediction module suppresses false connections in dense-trajectory regions by modeling long-range trajectory patterns. Experimental results on three real-world datasets show that DGMap outperforms state-of-the-art methods by 5% in APLS, with notable performance gains on trajectory data from the Didi Chuxing platform', 'abstract_zh': '轨迹数据已成为自动地图推理的关键资源，由于其低成本、广覆盖和持续可用性。然而，不均匀的轨迹密度往往导致稀疏区域道路断裂和稠密区域冗余路段，给现有方法带来了重大挑战。为了解决这些问题，我们提出DGMap，一种具有全局上下文意识的双解码框架，包含多尺度网格编码、掩码增强关键点提取和全局上下文意识关系预测。通过结合全局语义上下文和局部几何特征，DGMap 提高了关键点检测准确性，从而减少稀疏轨迹区域的道路断裂。此外，全局上下文意识关系预测模块通过建模长距离轨迹模式来抑制稠密轨迹区域中的虚假连接。在三个真实世界的数据集上的实验结果显示，DGMap 在APLS指标上比现有最佳方法提高了5%，特别是在滴滴出行平台的轨迹数据上表现出显著的性能提升。', 'title_zh': '填补稀疏性和冗余性之间的差距：一种带有全局上下文的双重解码框架用于地图推断'}
{'arxiv_id': 'arXiv:2509.11727', 'title': 'Microsurgical Instrument Segmentation for Robot-Assisted Surgery', 'authors': 'Tae Kyeong Jeong, Garam Kim, Juyoun Park', 'link': 'https://arxiv.org/abs/2509.11727', 'abstract': 'Accurate segmentation of thin structures is critical for microsurgical scene understanding but remains challenging due to resolution loss, low contrast, and class imbalance. We propose Microsurgery Instrument Segmentation for Robotic Assistance(MISRA), a segmentation framework that augments RGB input with luminance channels, integrates skip attention to preserve elongated features, and employs an Iterative Feedback Module(IFM) for continuity restoration across multiple passes. In addition, we introduce a dedicated microsurgical dataset with fine-grained annotations of surgical instruments including thin objects, providing a benchmark for robust evaluation Dataset available at this https URL. Experiments demonstrate that MISRA achieves competitive performance, improving the mean class IoU by 5.37% over competing methods, while delivering more stable predictions at instrument contacts and overlaps. These results position MISRA as a promising step toward reliable scene parsing for computer-assisted and robotic microsurgery.', 'abstract_zh': '微手术器械分割以增强机器人辅助(MISRA)：一种针对微手术场景理解的细粒度分割框架', 'title_zh': '机器人辅助手术中的微外科器械分割'}
{'arxiv_id': 'arXiv:2509.11698', 'title': 'CoachMe: Decoding Sport Elements with a Reference-Based Coaching Instruction Generation Model', 'authors': 'Wei-Hsin Yeh, Yu-An Su, Chih-Ning Chen, Yi-Hsueh Lin, Calvin Ku, Wen-Hsin Chiu, Min-Chun Hu, Lun-Wei Ku', 'link': 'https://arxiv.org/abs/2509.11698', 'abstract': "Motion instruction is a crucial task that helps athletes refine their technique by analyzing movements and providing corrective guidance. Although recent advances in multimodal models have improved motion understanding, generating precise and sport-specific instruction remains challenging due to the highly domain-specific nature of sports and the need for informative guidance. We propose CoachMe, a reference-based model that analyzes the differences between a learner's motion and a reference under temporal and physical aspects. This approach enables both domain-knowledge learning and the acquisition of a coach-like thinking process that identifies movement errors effectively and provides feedback to explain how to improve. In this paper, we illustrate how CoachMe adapts well to specific sports such as skating and boxing by learning from general movements and then leveraging limited data. Experiments show that CoachMe provides high-quality instructions instead of directions merely in the tone of a coach but without critical information. CoachMe outperforms GPT-4o by 31.6% in G-Eval on figure skating and by 58.3% on boxing. Analysis further confirms that it elaborates on errors and their corresponding improvement methods in the generated instructions. You can find CoachMe here: this https URL", 'abstract_zh': '运动指令是通过分析动作并提供纠正指导来帮助运动员精炼技术的关键任务。尽管近期多模态模型在运动理解方面取得了进步，但由于运动领域的高度专业性和需要有信息量的指导，生成精确且运动专项的指示仍然具有挑战性。我们提出了CoachMe，一种基于参考的模型，从时间维度和物理维度分析学习者运动与参考运动之间的差异。该方法既支持专业知识的学习，又能够获得类似教练的思考过程，有效识别运动错误并提供反馈解释如何改进。在本文中，我们展示了CoachMe如何通过从一般动作中学习，再利用有限数据适应特定运动如滑冰和拳击。实验结果表明，CoachMe在花样滑冰和拳击上的G-Eval评分分别比GPT-4o高31.6%和58.3%。进一步的分析证实，生成的指示解释了错误及相应的改进方法。你可以在这里找到CoachMe：this https URL。', 'title_zh': 'CoachMe：基于参考的运动元素教练指令生成模型'}
{'arxiv_id': 'arXiv:2509.11686', 'title': 'Do Code Semantics Help? A Comprehensive Study on Execution Trace-Based Information for Code Large Language Models', 'authors': 'Jian Wang, Xiaofei Xie, Qiang Hu, Shangqing Liu, Yi Li', 'link': 'https://arxiv.org/abs/2509.11686', 'abstract': 'Code Large Language Models (Code LLMs) have opened a new era in programming with their impressive capabilities. However, recent research has revealed critical limitations in their ability to reason about runtime behavior and understand the actual functionality of programs, which poses significant challenges for their post-training and practical deployment. Specifically, Code LLMs encounter two principal issues: (1) a lack of proficiency in reasoning about program execution behavior, as they struggle to interpret what programs actually do during runtime, and (2) the inconsistent and fragmented representation of semantic information, such as execution traces, across existing methods, which hinders their ability to generalize and reason effectively. These challenges underscore the necessity for more systematic approaches to enhance the reasoning capabilities of Code LLMs. To address these issues, we introduce a generic framework to support integrating semantic information~(e.g., execution trace) to code task-relevant prompts, and conduct a comprehensive study to explore the role of semantic information in enhancing the reasoning ability of Code LLMs accordingly. Specifically, we focus on investigating the usefulness of trace-based semantic information in boosting supervised fine-tuning~(SFT) and post-phase inference of Code LLMs. The experimental results surprisingly disagree with previous works and demonstrate that semantic information has limited usefulness for SFT and test time scaling of Code LLM.', 'abstract_zh': '代码大规模语言模型（Code LLMs）开启了编程的新时代，但由于其在推理运行时行为和理解程序实际功能方面的关键限制，给其训练后应用和实际部署带来了巨大挑战。具体而言，Code LLMs 遇到了两个主要问题：（1）在推理程序执行行为方面的不足，因为它们难以在运行时解释程序实际做了什么；（2）现有方法中语义信息的不一致和碎片化表示，阻碍了其泛化和有效推理的能力。这些挑战强调了需要更加系统的方法来增强 Code LLMs 的推理能力。为了应对这些问题，我们提出了一种通用框架，旨在支持将语义信息（例如，执行轨迹）集成到代码任务相关的提示中，并开展全面研究，以探索语义信息在增强 Code LLMs 推理能力方面的角色。具体而言，我们关注基于轨迹的语义信息在监督微调（SFT）和代码模型后续推理中的作用。实验结果与以前的研究出乎意料地不一致，并表明语义信息对 SFT 和 Code LLMs 的测试时缩放具有有限的用途。', 'title_zh': '代码语义有帮助吗？基于执行踪迹的信息对代码大型语言模型的综合研究'}
{'arxiv_id': 'arXiv:2509.11663', 'title': 'ParaEQsA: Parallel and Asynchronous Embodied Questions Scheduling and Answering', 'authors': 'Haisheng Wang, Weiming Zhi', 'link': 'https://arxiv.org/abs/2509.11663', 'abstract': 'This paper formulates the Embodied Questions Answering (EQsA) problem, introduces a corresponding benchmark, and proposes a system to tackle the problem. Classical Embodied Question Answering (EQA) is typically formulated as answering one single question by actively exploring a 3D environment. Real deployments, however, often demand handling multiple questions that may arrive asynchronously and carry different urgencies. We formalize this setting as Embodied Questions Answering (EQsA) and present ParaEQsA, a framework for parallel, urgency-aware scheduling and answering. ParaEQsA leverages a group memory module shared among questions to reduce redundant exploration, and a priority-planning module to dynamically schedule questions. To evaluate this setting, we contribute the Parallel Asynchronous Embodied Questions (PAEQs) benchmark containing 40 indoor scenes and five questions per scene (200 in total), featuring asynchronous follow-up questions and urgency labels. We further propose metrics for EQsA performance: Direct Answer Rate (DAR), and Normalized Urgency-Weighted Latency (NUWL), which jointly measure efficiency and responsiveness of this system. ParaEQsA consistently outperforms strong sequential baselines adapted from recent EQA systems, while reducing exploration and delay. Empirical evaluations investigate the relative contributions of priority, urgency modeling, spatial scope, reward estimation, and dependency reasoning within our framework. Together, these results demonstrate that urgency-aware, parallel scheduling is key to making embodied agents responsive and efficient under realistic, multi-question workloads.', 'abstract_zh': '本文形式化了嵌入式疑问回答（EQsA）问题，引入了一个相应的基准，并提出了一套系统来解决该问题。', 'title_zh': 'ParaEQsA: 并行异步 embodied 问题调度与回答'}
{'arxiv_id': 'arXiv:2509.11662', 'title': 'MindVL: Towards Efficient and Effective Training of Multimodal Large Language Models on Ascend NPUs', 'authors': 'Feilong Chen, Yijiang Liu, Yi Huang, Hao Wang, Miren Tian, Ya-Qi Yu, Minghui Liao, Jihao Wu', 'link': 'https://arxiv.org/abs/2509.11662', 'abstract': 'We propose MindVL, a multimodal large langauge model trained on Ascend NPUs. Similar to Qwen2.5-VL, MindVL adopts native-resolution Vision Transformers, which enables it to process images at their original variable resolutions. This design avoids the degradation caused by fixed-resolution tiling while preserving fine-grained details and global layouts, which is crucial for visually dense content such as complex charts and diagrams. To ensure the smooth training of MindVL on Ascend NPUs, we develop Mindspeed-MLLM, a distributed multimodal training framework tailored for Ascend NPUs. To maintain training accuracy, we implement equivalent replacements for certain operators. MindVL undergoes a three-phase training process, namely the warm-up phase, multitask training phase, and supervised instruction tuning phase, to gradually enhance its capabilities. This process starts with basic visual and multimodal pre-training, followed by large-scale multiask trainging and instruction tuning. We also adopt multimodal data packaging and hybrid parallelism techniques, which significantly improve end-to-end training speed. To further boost model performance, we specifically introduce test-time resolution search and model weight averaging. Notably, despite using about 1/10 of the training data required by Qwen2.5-VL, MindVL achieves performance on par with Qwen2.5-VL in evaluations of general multimodal understanding and document/table comprehension. Beyond overall scores, MindVL also delivers leading performance in OCR assessments.', 'abstract_zh': '我们提出MindVL，一种在Ascend NPUs上训练的多模态大型语言模型。类似Qwen2.5-VL，MindVL采用原生分辨率的Vision Transformers，使其能够处理图像的原始可变分辨率。这种设计避开了固定分辨率贴图带来的降级问题，同时保留了细微细节和全局布局，这对于复杂的图表和图纸等视觉密集型内容至关重要。为了在Ascend NPUs上保证MindVL的顺畅训练，我们开发了Mindspeed-MLLM，一种针对Ascend NPUs的分布式多模态训练框架。为了保持训练准确性，我们实现了某些操作的等效替换。MindVL经历三个训练阶段，即预热阶段、多任务训练阶段和监督指令调优阶段，以逐步提升其能力。这一过程从基本的视觉和多模态预训练开始，随后进行大规模多任务训练和指令调优。此外，我们采用多模态数据打包和混合并行技术，显著提高了端到端的训练速度。为了进一步提高模型性能，我们特别引入了测试时分辨率搜索和模型权重平均方法。值得注意的是，尽管所用训练数据仅为Qwen2.5-VL的1/10，MindVL在多模态理解和文档/表格理解评估中仍与Qwen2.5-VL性能相当。此外，MindVL在OCR评估中也展现了领先性能。', 'title_zh': 'MindVL：在Ascend NPUs上实现高效且有效的多模态大规模语言模型训练'}
{'arxiv_id': 'arXiv:2509.11661', 'title': 'DTGen: Generative Diffusion-Based Few-Shot Data Augmentation for Fine-Grained Dirty Tableware Recognition', 'authors': 'Lifei Hao, Yue Cheng, Baoqi Huang, Bing Jia, Xuandong Zhao', 'link': 'https://arxiv.org/abs/2509.11661', 'abstract': "Intelligent tableware cleaning is a critical application in food safety and smart homes, but existing methods are limited by coarse-grained classification and scarcity of few-shot data, making it difficult to meet industrialization requirements. We propose DTGen, a few-shot data augmentation scheme based on generative diffusion models, specifically designed for fine-grained dirty tableware recognition. DTGen achieves efficient domain specialization through LoRA, generates diverse dirty images via structured prompts, and ensures data quality through CLIP-based cross-modal filtering. Under extremely limited real few-shot conditions, DTGen can synthesize virtually unlimited high-quality samples, significantly improving classifier performance and supporting fine-grained dirty tableware recognition. We further elaborate on lightweight deployment strategies, promising to transfer DTGen's benefits to embedded dishwashers and integrate with cleaning programs to intelligently regulate energy consumption and detergent usage. Research results demonstrate that DTGen not only validates the value of generative AI in few-shot industrial vision but also provides a feasible deployment path for automated tableware cleaning and food safety monitoring.", 'abstract_zh': '基于生成扩散模型的少量样本数据增强方案DTGen及其在细粒度脏餐具识别中的应用', 'title_zh': 'DTGen: 基于生成扩散的少量样本数据增强方法用于细粒度污损餐具识别'}
{'arxiv_id': 'arXiv:2509.11656', 'title': 'MALLM: Multi-Agent Large Language Models Framework', 'authors': 'Jonas Becker, Lars Benedikt Kaesberg, Niklas Bauer, Jan Philip Wahle, Terry Ruas, Bela Gipp', 'link': 'https://arxiv.org/abs/2509.11656', 'abstract': 'Multi-agent debate (MAD) has demonstrated the ability to augment collective intelligence by scaling test-time compute and leveraging expertise. Current frameworks for multi-agent debate are often designed towards tool use, lack integrated evaluation, or provide limited configurability of agent personas, response generators, discussion paradigms, and decision protocols. We introduce MALLM (Multi-Agent Large Language Models), an open-source framework that enables systematic analysis of MAD components. MALLM offers more than 144 unique configurations of MAD, including (1) agent personas (e.g., Expert, Personality), (2) response generators (e.g., Critical, Reasoning), (3) discussion paradigms (e.g., Memory, Relay), and (4) decision protocols (e.g., Voting, Consensus). MALLM uses simple configuration files to define a debate. Furthermore, MALLM can load any textual Huggingface dataset (e.g., MMLU-Pro, WinoGrande) and provides an evaluation pipeline for easy comparison of MAD configurations. MALLM is tailored towards researchers and provides a window into the heart of multi-agent debate, facilitating the understanding of its components and their interplay.', 'abstract_zh': '多代理辩论(Multi-Agent Debate)中的多代理大型语言模型(MALLM)：一种增强集体智能的开放源代码框架', 'title_zh': '多Agent大型语言模型框架：MALLM'}
{'arxiv_id': 'arXiv:2509.11648', 'title': 'EthicsMH: A Pilot Benchmark for Ethical Reasoning in Mental Health AI', 'authors': 'Sai Kartheek Reddy Kasu', 'link': 'https://arxiv.org/abs/2509.11648', 'abstract': "The deployment of large language models (LLMs) in mental health and other sensitive domains raises urgent questions about ethical reasoning, fairness, and responsible alignment. Yet, existing benchmarks for moral and clinical decision-making do not adequately capture the unique ethical dilemmas encountered in mental health practice, where confidentiality, autonomy, beneficence, and bias frequently intersect. To address this gap, we introduce Ethical Reasoning in Mental Health (EthicsMH), a pilot dataset of 125 scenarios designed to evaluate how AI systems navigate ethically charged situations in therapeutic and psychiatric contexts. Each scenario is enriched with structured fields, including multiple decision options, expert-aligned reasoning, expected model behavior, real-world impact, and multi-stakeholder viewpoints. This structure enables evaluation not only of decision accuracy but also of explanation quality and alignment with professional norms. Although modest in scale and developed with model-assisted generation, EthicsMH establishes a task framework that bridges AI ethics and mental health decision-making. By releasing this dataset, we aim to provide a seed resource that can be expanded through community and expert contributions, fostering the development of AI systems capable of responsibly handling some of society's most delicate decisions.", 'abstract_zh': '大型语言模型在心理健康和其他敏感领域中的部署引发了关于伦理推理、公平性和负责任对齐的迫切问题。然而，现有针对道德和临床决策的基准测试未能充分捕捉到心理健康实践中的独特伦理困境，其中保密性、自主权、有益性以及偏见经常相互交织。为弥补这一差距，我们提出了心理健康中的伦理推理（EthicsMH）数据集，该数据集包含125种场景，旨在评估AI系统如何在心理治疗和精神病学背景下应对伦理紧张的情境。每个场景都包括结构化的字段，如多种决策选项、专家一致的推理、预期模型行为、现实世界影响和多利益相关者的视角。这种结构不仅能够评估决策准确性，还能够评估解释质量和与专业规范的契合度。尽管规模较小且通过模型辅助生成，EthicsMH仍建立了一个连接AI伦理与心理健康决策的任务框架。通过发布此数据集，我们旨在提供一个种子资源，可以通过社区和专家的贡献进行扩展，促进开发能够负责任地处理社会上一些最微妙决策的AI系统。', 'title_zh': 'EthicsMH：心理健康AI伦理推理的试点基准'}
{'arxiv_id': 'arXiv:2509.11636', 'title': 'Task-Agnostic Learnable Weighted-Knowledge Base Scheme for Robust Semantic Communications', 'authors': 'Shiyao Jiang, Jian Jiao, Xingjian Zhang, Ye Wang, Dusit Niyato, Qinyu Zhang', 'link': 'https://arxiv.org/abs/2509.11636', 'abstract': 'With the emergence of diverse and massive data in the upcoming sixth-generation (6G) networks, the task-agnostic semantic communication system is regarded to provide robust intelligent services. In this paper, we propose a task-agnostic learnable weighted-knowledge base semantic communication (TALSC) framework for robust image transmission to address the real-world heterogeneous data bias in KB, including label flipping noise and class imbalance. The TALSC framework incorporates a sample confidence module (SCM) as meta-learner and the semantic coding networks as learners. The learners are updated based on the empirical knowledge provided by the learnable weighted-KB (LW-KB). Meanwhile, the meta-learner evaluates the significance of samples according to the task loss feedback, and adjusts the update strategy of learners to enhance the robustness in semantic recovery for unknown tasks. To strike a balance between SCM parameters and precision of significance evaluation, we design an SCM-grid extension (SCM-GE) approach by embedding the Kolmogorov-Arnold networks (KAN) within SCM, which leverages the concept of spline refinement in KAN and enables scalable SCM with customizable granularity without retraining. Simulations demonstrate that the TALSC framework effectively mitigates the effects of flipping noise and class imbalance in task-agnostic image semantic communication, achieving at least 12% higher semantic recovery accuracy (SRA) and multi-scale structural similarity (MS-SSIM) compared to state-of-the-art methods.', 'abstract_zh': '面向未知任务的可学习加权知识库语义通信框架：应对知识库中的标签翻转噪声和类别不平衡问题', 'title_zh': '面向任务的可学习加权知识库方案以实现稳健的语义通信'}
{'arxiv_id': 'arXiv:2509.11629', 'title': 'Reasoned Safety Alignment: Ensuring Jailbreak Defense via Answer-Then-Check', 'authors': 'Chentao Cao, Xiaojun Xu, Bo Han, Hang Li', 'link': 'https://arxiv.org/abs/2509.11629', 'abstract': 'As large language models (LLMs) continue to advance in capabilities, ensuring their safety against jailbreak attacks remains a critical challenge. In this paper, we introduce a novel safety alignment approach called Answer-Then-Check, which enhances LLM robustness against malicious prompts by applying thinking ability to mitigate jailbreaking problems before producing a final answer to the user. Our method enables models to directly answer the question in their thought and then critically evaluate its safety before deciding whether to provide it. To implement this approach, we construct the Reasoned Safety Alignment (ReSA) dataset, comprising 80K examples that teach models to reason through direct responses and then analyze their safety. Experimental results demonstrate that our approach achieves the Pareto frontier with superior safety capability while decreasing over-refusal rates on over-refusal benchmarks. Notably, the model fine-tuned with ReSA maintains general reasoning capabilities on benchmarks like MMLU, MATH500, and HumanEval. Besides, our method equips models with the ability to perform safe completion. Unlike post-hoc methods that can only reject harmful queries, our model can provide helpful and safe alternative responses for sensitive topics (e.g., self-harm). Furthermore, we discover that training on a small subset of just 500 examples can achieve comparable performance to using the full dataset, suggesting that safety alignment may require less data than previously assumed.', 'abstract_zh': '随着大规模语言模型（LLMs）能力的不断进步，确保其在抵御牢笼攻击方面的安全性仍是一项关键挑战。在本文中，我们提出了一种名为Answer-Then-Check的新颖安全对齐方法，该方法通过在生成最终答案之前应用思考能力来减轻牢笼攻击问题，从而增强LLM的鲁棒性。我们的方法使模型能够直接在其思考过程中回答问题，然后对其安全性进行批判性评估，以决定是否提供该答案。为了实现这一方法，我们构建了Reasoned Safety Alignment（ReSA）数据集，其中包括80K个示例，用于教授模型通过直接响应进行推理并随后分析其安全性。实验结果表明，我们的方法在保持出色的安全性能的同时，降低了过拒绝率。值得注意的是，使用ReSA微调的模型在MMLU、MATH500和HumanEval等基准测试上保持了通用推理能力。此外，我们的方法使模型具备了安全完成任务的能力。与只能拒绝有害查询的事后方法不同，我们的模型可以为敏感话题（如自我伤害）提供有益且安全的替代响应。进一步的研究表明，仅对数据集的小部分（500个示例）进行训练即可达到与使用整个数据集相当的性能，这表明安全对齐可能需要的数据量比之前假设的要少。', 'title_zh': '推理安全对齐：通过回答再检查确保防越狱'}
{'arxiv_id': 'arXiv:2509.11628', 'title': 'SpeCa: Accelerating Diffusion Transformers with Speculative Feature Caching', 'authors': 'Jiacheng Liu, Chang Zou, Yuanhuiyi Lyu, Fei Ren, Shaobo Wang, Kaixin Li, Linfeng Zhang', 'link': 'https://arxiv.org/abs/2509.11628', 'abstract': "Diffusion models have revolutionized high-fidelity image and video synthesis, yet their computational demands remain prohibitive for real-time applications. These models face two fundamental challenges: strict temporal dependencies preventing parallelization, and computationally intensive forward passes required at each denoising step. Drawing inspiration from speculative decoding in large language models, we present SpeCa, a novel 'Forecast-then-verify' acceleration framework that effectively addresses both limitations. SpeCa's core innovation lies in introducing Speculative Sampling to diffusion models, predicting intermediate features for subsequent timesteps based on fully computed reference timesteps. Our approach implements a parameter-free verification mechanism that efficiently evaluates prediction reliability, enabling real-time decisions to accept or reject each prediction while incurring negligible computational overhead. Furthermore, SpeCa introduces sample-adaptive computation allocation that dynamically modulates resources based on generation complexity, allocating reduced computation for simpler samples while preserving intensive processing for complex instances. Experiments demonstrate 6.34x acceleration on FLUX with minimal quality degradation (5.5% drop), 7.3x speedup on DiT while preserving generation fidelity, and 79.84% VBench score at 6.1x acceleration for HunyuanVideo. The verification mechanism incurs minimal overhead (1.67%-3.5% of full inference costs), establishing a new paradigm for efficient diffusion model inference while maintaining generation quality even at aggressive acceleration ratios. Our codes have been released in Github: \\textbf{this https URL}", 'abstract_zh': '扩散模型已 revolutionized 高保真图像和视频合成，但其计算需求仍然阻碍了实时应用。这些模型面临两大根本挑战：严格的时序依赖性阻碍了并行化，以及在每个去噪步骤中所需的计算密集型前向传递。受到大规模语言模型中 speculative decoding 启发，我们提出了 SpeCa，一种新颖的“预测-验证”加速框架，有效解决了上述限制。SpeCa 的核心创新在于引入 speculative sampling 到扩散模型中，基于完全计算的参考时间步预测后续时间步的中间特征。我们的方法实施了一种无参数验证机制，高效评估预测的可靠性，在几乎不增加计算开销的情况下，在实时决策时接受或拒绝每个预测。此外，SpeCa 引入了样本自适应计算分配，根据生成复杂性动态调整资源，为简单的样本减少计算量，同时为复杂的实例保留密集处理。实验结果显示，在 FLUX 上加速 6.34 倍，质量下降 5.5%，在 DiT 上加速 7.3 倍同时保持生成保真度，在 HunyuanVideo 上以 6.1 倍加速实现 79.84% 的 VBench 分数。验证机制带来的开销最小（1.67%-3.5% 的全推理成本），建立了一种新的高效扩散模型推理范式，即使在极端加速比下也维持生成质量。我们的代码已发布在 Github：\\textbf{this https URL}。', 'title_zh': 'SpeCa: 采用推测特征缓存加速扩散变换器'}
{'arxiv_id': 'arXiv:2509.11626', 'title': 'Automated Creation and Enrichment Framework for Improved Invocation of Enterprise APIs as Tools', 'authors': 'Prerna Agarwal, Himanshu Gupta, Soujanya Soni, Rohith Vallam, Renuka Sindhgatta, Sameep Mehta', 'link': 'https://arxiv.org/abs/2509.11626', 'abstract': 'Recent advancements in Large Language Models (LLMs) has lead to the development of agents capable of complex reasoning and interaction with external tools. In enterprise contexts, the effective use of such tools that are often enabled by application programming interfaces (APIs), is hindered by poor documentation, complex input or output schema, and large number of operations. These challenges make tool selection difficult and reduce the accuracy of payload formation by up to 25%. We propose ACE, an automated tool creation and enrichment framework that transforms enterprise APIs into LLM-compatible tools. ACE, (i) generates enriched tool specifications with parameter descriptions and examples to improve selection and invocation accuracy, and (ii) incorporates a dynamic shortlisting mechanism that filters relevant tools at runtime, reducing prompt complexity while maintaining scalability. We validate our framework on both proprietary and open-source APIs and demonstrate its integration with agentic frameworks. To the best of our knowledge, ACE is the first end-to-end framework that automates the creation, enrichment, and dynamic selection of enterprise API tools for LLM agents.', 'abstract_zh': 'Recent advancements in大型语言模型（LLMs）的发展导致了能够进行复杂推理和与外部工具交互的代理的开发。在企业环境中，有效使用这些常通过应用程序编程接口（APIs）启用的工具受到糟糕文档、复杂的输入或输出方案以及大量操作的阻碍。这些挑战使得工具选择变得困难，并且降低了高达25%的有效负载形成准确性。我们提出了一种名为ACE的自动化工具创建和丰富框架，该框架将企业API转换为LLM兼容的工具。ACE，(i) 生成包含参数描述和示例的丰富工具规范，以提高选择和调用准确性，(ii) 结合了动态简要列表机制，该机制在运行时筛选出相关的工具，从而降低提示复杂性同时保持可扩展性。我们在 proprietary 和开源 API 上验证了我们的框架，并展示了其与代理框架的集成。据我们所知，ACE 是第一个端到端框架，能够自动化创建、丰富和动态选择用于LLM代理的企业API工具。', 'title_zh': '企业API工具化改进调用的自动化创建与丰富框架'}
{'arxiv_id': 'arXiv:2509.11625', 'title': 'Inducing Uncertainty for Test-Time Privacy', 'authors': 'Muhammad H. Ashiq, Peter Triantafillou, Hung Yun Tseng, Grigoris G. Chrysos', 'link': 'https://arxiv.org/abs/2509.11625', 'abstract': 'Unlearning is the predominant method for removing the influence of data in machine learning models. However, even after unlearning, models often continue to produce the same predictions on the unlearned data with high confidence. This persistent behavior can be exploited by adversaries using confident model predictions on incorrect or obsolete data to harm users. We call this threat model, which unlearning fails to protect against, *test-time privacy*. In particular, an adversary with full model access can bypass any naive defenses which ensure test-time privacy. To address this threat, we introduce an algorithm which perturbs model weights to induce maximal uncertainty on protected instances while preserving accuracy on the rest of the instances. Our core algorithm is based on finetuning with a Pareto optimal objective that explicitly balances test-time privacy against utility. We also provide a certifiable approximation algorithm which achieves $(\\varepsilon, \\delta)$ guarantees without convexity assumptions. We then prove a tight, non-vacuous bound that characterizes the privacy-utility tradeoff that our algorithms incur. Empirically, our method obtains $>3\\times$ stronger uncertainty than pretraining with $<0.2\\%$ drops in accuracy on various image recognition benchmarks. Altogether, this framework provides a tool to guarantee additional protection to end users.', 'abstract_zh': '测试时隐私：卸学无法防护的隐私威胁及其实现算法', 'title_zh': '测试时隐私的不确定性诱导'}
{'arxiv_id': 'arXiv:2509.11601', 'title': 'Dynamic Adaptive Parsing of Temporal and Cross-Variable Patterns for Network State Classification', 'authors': 'Yuan Gao, Xuelong Wang, Zhenguo Dong, Yong Zhang', 'link': 'https://arxiv.org/abs/2509.11601', 'abstract': "Effective network state classification is a primary task for ensuring network security and optimizing performance. Existing deep learning models have shown considerable progress in this area. Some methods excel at analyzing the complex temporal periodicities found in traffic data, while graph-based approaches are adept at modeling the dynamic dependencies between different variables. However, a key trade-off remains, as these methods struggle to capture both characteristics simultaneously. Models focused on temporal patterns often overlook crucial variable dependencies, whereas those centered on dependencies may fail to capture fine-grained temporal details. To address this trade-off, we introduce DAPNet, a framework based on a Mixture-of-Experts architecture. DAPNet integrates three specialized networks for periodic analysis, dynamic cross-variable correlation modeling, and hybrid temporal feature extraction. A learnable gating network dynamically assigns weights to experts based on the input sample and computes a weighted fusion of their outputs. Furthermore, a hybrid regularization loss function ensures stable training and addresses the common issue of class imbalance. Extensive experiments on two large-scale network intrusion detection datasets (CICIDS2017/2018) validate DAPNet's higher accuracy for its target application. The generalizability of the architectural design is evaluated across ten public UEA benchmark datasets, positioning DAPNet as a specialized framework for network state classification.", 'abstract_zh': '有效的网络状态分类是确保网络安全和优化性能的主要任务。现有的深度学习模型在这领域已显示出显著的进步。一些方法擅长分析交通数据中复杂的时序周期性，而图基方法擅长建模不同变量之间的动态依赖关系。然而，这些方法仍然面临一个关键权衡，即它们难以同时捕捉这两种特性。专注于时序模式的模型往往会忽略关键的变量依赖性，而以依赖为中心的模型可能无法捕捉到详细的时序细节。为了解决这一权衡，我们提出了基于Mixture-of-Experts架构的DAPNet框架。DAPNet整合了三种专门网络，分别用于周期性分析、动态跨变量相关性建模以及混合时序特征提取。一个可学习的门控网络根据输入样本动态分配专家权重，并计算它们输出的加权融合。此外，一种混合正则化损失函数确保了稳定的训练，并解决了类别不平衡的常见问题。在两个大规模网络入侵检测数据集（CICIDS2017/2018）上的广泛实验验证了DAPNet在目标应用中的更高准确性。架构设计的泛化能力在十个公开的UEA基准数据集上进行评估，使DAPNet成为网络状态分类的专业化框架。', 'title_zh': '基于时序和跨变量模式的网络状态分类的动态自适应解析方法'}
{'arxiv_id': 'arXiv:2509.11594', 'title': 'GBPP: Grasp-Aware Base Placement Prediction for Robots via Two-Stage Learning', 'authors': 'Jizhuo Chen, Diwen Liu, Jiaming Wang, Harold Soh', 'link': 'https://arxiv.org/abs/2509.11594', 'abstract': 'GBPP is a fast learning based scorer that selects a robot base pose for grasping from a single RGB-D snapshot. The method uses a two stage curriculum: (1) a simple distance-visibility rule auto-labels a large dataset at low cost; and (2) a smaller set of high fidelity simulation trials refines the model to match true grasp outcomes. A PointNet++ style point cloud encoder with an MLP scores dense grids of candidate poses, enabling rapid online selection without full task-and-motion optimization. In simulation and on a real mobile manipulator, GBPP outperforms proximity and geometry only baselines, choosing safer and more reachable stances and degrading gracefully when wrong. The results offer a practical recipe for data efficient, geometry aware base placement: use inexpensive heuristics for coverage, then calibrate with targeted simulation.', 'abstract_zh': 'GBPP是一种基于快速学习的评分器，可以从单个RGB-D快照中选择用于抓取的机器人基座姿态。该方法采用两阶段递进式课程：（1）简单的距离-可见性规则自动标注大量数据集以降低成本；（2）较小数量的高保真模拟试验进一步调整模型以匹配真实抓取结果。该方法使用类似PointNet++风格的点云编码器和MLP对候选姿态进行评分，从而实现快速在线选择而无需进行全面的任务和运动优化。在模拟和实际移动操作器上，GBPP优于仅基于距离和几何的基线方法，选择更安全且更容易到达的姿态，并在错误时逐步退化。结果提供了一种实用的配方，用于高效的数据收集和几何感知基座放置：使用经济高效的启发式方法进行覆盖，然后通过目标化模拟进行校准。', 'title_zh': 'GBPP: 基于两阶段学习的抓取导向基座放置预测gorithm'}
{'arxiv_id': 'arXiv:2509.11587', 'title': 'Hierarchical Identity Learning for Unsupervised Visible-Infrared Person Re-Identification', 'authors': 'Haonan Shi, Yubin Wang, De Cheng, Lingfeng He, Nannan Wang, Xinbo Gao', 'link': 'https://arxiv.org/abs/2509.11587', 'abstract': 'Unsupervised visible-infrared person re-identification (USVI-ReID) aims to learn modality-invariant image features from unlabeled cross-modal person datasets by reducing the modality gap while minimizing reliance on costly manual annotations. Existing methods typically address USVI-ReID using cluster-based contrastive learning, which represents a person by a single cluster center. However, they primarily focus on the commonality of images within each cluster while neglecting the finer-grained differences among them. To address the limitation, we propose a Hierarchical Identity Learning (HIL) framework. Since each cluster may contain several smaller sub-clusters that reflect fine-grained variations among images, we generate multiple memories for each existing coarse-grained cluster via a secondary clustering. Additionally, we propose Multi-Center Contrastive Learning (MCCL) to refine representations for enhancing intra-modal clustering and minimizing cross-modal discrepancies. To further improve cross-modal matching quality, we design a Bidirectional Reverse Selection Transmission (BRST) mechanism, which establishes reliable cross-modal correspondences by performing bidirectional matching of pseudo-labels. Extensive experiments conducted on the SYSU-MM01 and RegDB datasets demonstrate that the proposed method outperforms existing approaches. The source code is available at: this https URL.', 'abstract_zh': '无监督可见光-红外人体重识别（USVI-ReID）旨在通过减少模态差距并最小化对昂贵的手动标注依赖来从未标注的跨模态人体数据集中学习模态不变的图像特征。现有方法通常使用基于聚类的对比学习来解决USVI-ReID问题，通过单个聚类中心表示一个人。然而，这些方法主要关注每个聚类内部图像的共同点，而忽略它们之间的微细差异。为了解决这一局限，我们提出了层次身份学习（HIL）框架。由于每个聚类可能包含反映图像微细变化的几个较小的子聚类，我们通过二次聚类为每个现有的粗粒度聚类生成多个记忆。此外，我们提出了多中心对比学习（MCCL）以细化表示，增强同模态聚类并最小化跨模态差异。为进一步提高跨模态匹配质量，我们设计了一种双向反向选择传输（BRST）机制，通过双向匹配伪标签建立可靠的跨模态对应关系。在SYSU-MM01和RegDB数据集上的广泛实验表明，所提出的方法优于现有方法。源代码可在以下链接获取：this <https://github.com/...>。', 'title_zh': '无监督可见光-红外人体重新识别的分层身份学习'}
{'arxiv_id': 'arXiv:2509.11555', 'title': 'Dstack: A Zero Trust Framework for Confidential Containers', 'authors': 'Shunfan Zhou, Kevin Wang, Hang Yin', 'link': 'https://arxiv.org/abs/2509.11555', 'abstract': 'Web3 applications require execution platforms that maintain confidentiality and integrity without relying on centralized trust authorities. While Trusted Execution Environments (TEEs) offer promising capabilities for confidential computing, current implementations face significant limitations when applied to Web3 contexts, particularly in security reliability, censorship resistance, and vendor independence.\nThis paper presents dstack, a comprehensive framework that transforms raw TEE technology into a true Zero Trust platform. We introduce three key innovations: (1) Portable Confidential Containers that enable seamless workload migration across heterogeneous TEE environments while maintaining security guarantees, (2) Decentralized Code Management that leverages smart contracts for transparent governance of TEE applications, and (3) Verifiable Domain Management that ensures secure and verifiable application identity without centralized authorities.\nThese innovations are implemented through three core components: dstack-OS, dstack-KMS, and dstack-Gateway. Together, they demonstrate how to achieve both the performance advantages of VM-level TEE solutions and the trustless guarantees required by Web3 applications. Our evaluation shows that dstack provides comprehensive security guarantees while maintaining practical usability for real-world applications.', 'abstract_zh': 'Web3应用程序需要执行平台，该平台能够维护保密性和完整性，而不依赖于中心化的信任权威机构。虽然受信任执行环境（TEEs）为保密计算提供了潜在的能力，但当前的应用在Web3环境中面临重大限制，特别是在安全可靠性、审查阻力和供应商独立性方面。\n\n本文提出了一种名为dstack的综合框架，将原始的TEE技术转化为真正的零信任平台。我们介绍了三项关键技术创新：（1）可移植的保密容器，可在异构TEE环境中无缝迁移工作负载的同时保持安全保证；（2）去中心化的代码管理，利用智能合约实现TEE应用的透明治理；（3）可验证的域管理，确保应用身份的安全和验证，而无需中央权威机构。\n\n这些创新是通过三个核心组件实现的：dstack-OS、dstack-KMS和dstack-Gateway。它们共同展示了如何同时获得虚拟机级别TEE解决方案的性能优势以及Web3应用程序所需的无信任保证。评估结果显示，dstack提供了全面的安全保证，并且在实际应用中具有实用的可用性。', 'title_zh': 'Dstack: 一种针对机密容器的零信任框架'}
{'arxiv_id': 'arXiv:2509.11552', 'title': 'HiChunk: Evaluating and Enhancing Retrieval-Augmented Generation with Hierarchical Chunking', 'authors': 'Wensheng Lu, Keyu Chen, Ruizhi Qiao, Xing Sun', 'link': 'https://arxiv.org/abs/2509.11552', 'abstract': 'Retrieval-Augmented Generation (RAG) enhances the response capabilities of language models by integrating external knowledge sources. However, document chunking as an important part of RAG system often lacks effective evaluation tools. This paper first analyzes why existing RAG evaluation benchmarks are inadequate for assessing document chunking quality, specifically due to evidence sparsity. Based on this conclusion, we propose HiCBench, which includes manually annotated multi-level document chunking points, synthesized evidence-dense quetion answer(QA) pairs, and their corresponding evidence sources. Additionally, we introduce the HiChunk framework, a multi-level document structuring framework based on fine-tuned LLMs, combined with the Auto-Merge retrieval algorithm to improve retrieval quality. Experiments demonstrate that HiCBench effectively evaluates the impact of different chunking methods across the entire RAG pipeline. Moreover, HiChunk achieves better chunking quality within reasonable time consumption, thereby enhancing the overall performance of RAG systems.', 'abstract_zh': 'Retrieval-Augmented Generation (RAG)增强语言模型的响应能力通过整合外部知识源，然而，RAG系统中的文档切分往往是缺乏有效评估工具的重要组成部分。本文首先分析了现有RAG评估基准为何不足以评估文档切分质量，特别是由于证据稀疏的原因。基于此结论，我们提出了HiCBench，其中包含手动标注的多级别文档切分点、合成的证据密集的问答（QA）对及其对应的证据来源。此外，我们引入了HiChunk框架，这是一个基于微调的LLM的多级别文档结构框架，结合了自动合并检索算法以提高检索质量。实验表明，HiCBench有效地评估了不同切分方法在整个RAG管道中的影响。此外，HiChunk在合理的时间消耗内实现了更高的切分质量，从而提升了RAG系统的整体性能。', 'title_zh': 'HiChunk: 评估与增强基于分层切块的检索增强生成'}
{'arxiv_id': 'arXiv:2509.11543', 'title': 'UI-S1: Advancing GUI Automation via Semi-online Reinforcement Learning', 'authors': 'Zhengxi Lu, Jiabo Ye, Fei Tang, Yongliang Shen, Haiyang Xu, Ziwei Zheng, Weiming Lu, Ming Yan, Fei Huang, Jun Xiao, Yueting Zhuang', 'link': 'https://arxiv.org/abs/2509.11543', 'abstract': 'Graphical User Interface (GUI) agents have demonstrated remarkable progress in automating complex user interface interactions through reinforcement learning. However, current approaches face a fundamental dilemma: offline RL enables stable training on pre-collected trajectories, but struggles with multi-step task execution for lack of trajectory-level reward signals; online RL captures these signals through environment interaction, but suffers from sparse rewards and prohibitive deployment costs. To address it, we present Semi-online Reinforcement Learning, a novel paradigm that simulates online RL on offline trajectories. During each rollout process, we preserve the original model output within the multi-turn dialogue, where a Patch Module adaptively recovers the divergence between rollout and expert trajectories. To capture long-term training signals, Semi-online RL introduces discounted future returns into the reward computation and optimizes the policy with weighted step-level and episode-level advantages. We further introduce Semi-Online Performance (SOP), a metric that aligns better with true online performance, serving as a practical and effective proxy for real-world evaluation. Experiments show that ours Semi-online RL achieves SOTA performance among 7B models across four dynamic benchmarks, with significant gains over the base model (e.g., +12.0% on AndroidWorld, +23.8% on AITW), demonstrating significant progress in bridging the gap between offline training efficiency and online multi-turn reasoning. The code is available at this https URL.', 'abstract_zh': '半在线强化学习：一种在离线轨迹上模拟在线RL的新范式', 'title_zh': 'UI-S1: 基于半在线强化学习的GUI自动化先进方法'}
{'arxiv_id': 'arXiv:2509.11536', 'title': 'HARP: Hallucination Detection via Reasoning Subspace Projection', 'authors': 'Junjie Hu, Gang Tu, ShengYu Cheng, Jinxin Li, Jinting Wang, Rui Chen, Zhilong Zhou, Dongbo Shan', 'link': 'https://arxiv.org/abs/2509.11536', 'abstract': 'Hallucinations in Large Language Models (LLMs) pose a major barrier to their reliable use in critical decision-making. Although existing hallucination detection methods have improved accuracy, they still struggle with disentangling semantic and reasoning information and maintaining robustness. To address these challenges, we propose HARP (Hallucination detection via reasoning subspace projection), a novel hallucination detection framework. HARP establishes that the hidden state space of LLMs can be decomposed into a direct sum of a semantic subspace and a reasoning subspace, where the former encodes linguistic expression and the latter captures internal reasoning processes. Moreover, we demonstrate that the Unembedding layer can disentangle these subspaces, and by applying Singular Value Decomposition (SVD) to its parameters, the basis vectors spanning the semantic and reasoning subspaces are obtained. Finally, HARP projects hidden states onto the basis vectors of the reasoning subspace, and the resulting projections are then used as input features for hallucination detection in LLMs. By using these projections, HARP reduces the dimension of the feature to approximately 5% of the original, filters out most noise, and achieves enhanced robustness. Experiments across multiple datasets show that HARP achieves state-of-the-art hallucination detection performance; in particular, it achieves an AUROC of 92.8% on TriviaQA, outperforming the previous best method by 7.5%.', 'abstract_zh': '大型语言模型中的幻觉构成了其在关键决策中可靠使用的主要障碍。尽管现有的幻觉检测方法提高了准确性，但仍难以分离语义和推理信息并保持鲁棒性。为应对这些挑战，我们提出了一种新颖的幻觉检测框架HARP（通过推理子空间投影检测幻觉）。HARP 建立了大型语言模型的隐藏状态空间可以分解为语义子空间和推理子空间的直和，其中前者编码语言表达，后者捕获内部推理过程。此外，我们展示了 Unembedding 层可以分离这些子空间，并通过对其参数应用奇异值分解 (SVD)，可以获得覆盖语义和推理子空间的基向量。最后，HARP 将隐藏状态投影到推理子空间的基向量上，投影结果则作为输入特征用于大型语言模型的幻觉检测。通过使用这些投影，HARP 将特征维度减少到原始维度的大约 5%，过滤掉大部分噪声，并实现增强的鲁棒性。实验表明，HARP 在多个数据集上实现了最先进的幻觉检测性能；特别是在 TriviaQA 上，AUROC 达到 92.8%，超过了之前最好的方法 7.5%。', 'title_zh': 'HARP：基于子空间投影的幻觉检测方法'}
{'arxiv_id': 'arXiv:2509.11520', 'title': "Know What You Don't Know: Selective Prediction for Early Exit DNNs", 'authors': 'Divya Jyoti Bajpai, Manjesh Kumar Hanawal', 'link': 'https://arxiv.org/abs/2509.11520', 'abstract': "Inference latency and trustworthiness of Deep Neural Networks (DNNs) are the bottlenecks in deploying them in critical applications like sensitive tasks. Early Exit (EE) DNNs overcome the latency issues by allowing samples to exit from intermediary layers if they attain `high' confidence scores on the predicted class. However, the DNNs are known to exhibit overconfidence, which can lead to many samples exiting early and render EE strategies untrustworthy. We use Selective Prediction (SP) to overcome this issue by checking the `hardness' of the samples rather than just relying on the confidence score alone. We propose SPEED, a novel approach that uses Deferral Classifiers (DCs) at each layer to check the hardness of samples before performing EEs. Specifically, the DCs identify if a sample is hard to predict at an intermediary layer, leading to hallucination, and defer it to an expert. Early detection of hard samples for inference prevents the wastage of computational resources and improves trust by deferring the hard samples to the expert. We demonstrate that EE aided with SP improves both accuracy and latency. Our method minimizes the risk of wrong prediction by $50\\%$ with a speedup of $2.05\\times$ as compared to the final layer. The anonymized source code is available at this https URL", 'abstract_zh': '深度神经网络的推理延迟和可信度是将其应用于敏感任务等关键应用中的瓶颈。选择性预测辅助的早期退出深度神经网络通过检查样本的“难度”而非仅依赖预测置信度来克服这一问题，提出了一种名为SPEED的新方法，该方法在每层使用退避分类器（DCs）在进行早期退出之前检查样本的难度。我们展示了带有选择性预测的早期退出方法可以同时提高准确性和降低延迟。相比最终层，该方法将错误预测的风险降低了50%，并实现了2.05倍的速度提升。源代码已匿名处理，可在以下链接获取。', 'title_zh': '知其所不知：选择性预测用于早期退出DNN'}
{'arxiv_id': 'arXiv:2509.11513', 'title': 'Unsupervised Candidate Ranking for Lexical Substitution via Holistic Sentence Semantics', 'authors': 'Zhongyang Hu, Naijie Gu, Xiangzhi Tao, Tianhui Gu, Yibing Zhou', 'link': 'https://arxiv.org/abs/2509.11513', 'abstract': 'A key subtask in lexical substitution is ranking the given candidate words. A common approach is to replace the target word with a candidate in the original sentence and feed the modified sentence into a model to capture semantic differences before and after substitution. However, effectively modeling the bidirectional influence of candidate substitution on both the target word and its context remains challenging. Existing methods often focus solely on semantic changes at the target position or rely on parameter tuning over multiple evaluation metrics, making it difficult to accurately characterize semantic variation. To address this, we investigate two approaches: one based on attention weights and another leveraging the more interpretable integrated gradients method, both designed to measure the influence of context tokens on the target token and to rank candidates by incorporating semantic similarity between the original and substituted sentences. Experiments on the LS07 and SWORDS datasets demonstrate that both approaches improve ranking performance.', 'abstract_zh': '词替换中的一个关键子任务是对给定的候选项单词进行排名。一种常见的方法是将目标单词替换为候选词，并将修改后的句子输入模型以捕获替换前后语义差异。然而，有效地建模候选词替换对目标单词及其上下文的双向影响仍然是一个挑战。现有方法通常仅专注于目标位置的语义变化，或者依赖于在多个评估指标上进行参数调整，这使得准确刻画语义变异变得困难。为了解决这一问题，我们研究了两种方法：一种基于注意权重的方法，另一种利用更具可解释性的整合梯度方法，这两种方法都旨在测量上下文词对目标词的影响，并通过结合原句和替换句的语义相似性对候选项进行排名。实验表明，这两种方法都提高了排名性能。', 'title_zh': '基于整体句子语义的无监督候选词排序方法'}
{'arxiv_id': 'arXiv:2509.11512', 'title': 'Machine Learning-Driven Predictive Resource Management in Complex Science Workflows', 'authors': 'Tasnuva Chowdhury, Tadashi Maeno, Fatih Furkan Akman, Joseph Boudreau, Sankha Dutta, Shengyu Feng, Adolfy Hoisie, Kuan-Chieh Hsu, Raees Khan, Jaehyung Kim, Ozgur O. Kilic, Scott Klasky, Alexei Klimentov, Tatiana Korchuganova, Verena Ingrid Martinez Outschoorn, Paul Nilsson, David K. Park, Norbert Podhorszki, Yihui Ren, John Rembrandt Steele, Frédéric Suter, Sairam Sri Vatsavai, Torre Wenaus, Wei Yang, Yiming Yang, Shinjae Yoo', 'link': 'https://arxiv.org/abs/2509.11512', 'abstract': 'The collaborative efforts of large communities in science experiments, often comprising thousands of global members, reflect a monumental commitment to exploration and discovery. Recently, advanced and complex data processing has gained increasing importance in science experiments. Data processing workflows typically consist of multiple intricate steps, and the precise specification of resource requirements is crucial for each step to allocate optimal resources for effective processing. Estimating resource requirements in advance is challenging due to a wide range of analysis scenarios, varying skill levels among community members, and the continuously increasing spectrum of computing options. One practical approach to mitigate these challenges involves initially processing a subset of each step to measure precise resource utilization from actual processing profiles before completing the entire step. While this two-staged approach enables processing on optimal resources for most of the workflow, it has drawbacks such as initial inaccuracies leading to potential failures and suboptimal resource usage, along with overhead from waiting for initial processing completion, which is critical for fast-turnaround analyses. In this context, our study introduces a novel pipeline of machine learning models within a comprehensive workflow management system, the Production and Distributed Analysis (PanDA) system. These models employ advanced machine learning techniques to predict key resource requirements, overcoming challenges posed by limited upfront knowledge of characteristics at each step. Accurate forecasts of resource requirements enable informed and proactive decision-making in workflow management, enhancing the efficiency of handling diverse, complex workflows across heterogeneous resources.', 'abstract_zh': '大规模科研社区在科学实验中的协同努力，通常由成千上万的全球成员组成，反映了对探索和发现的巨大承诺。近年来，先进的复杂数据处理在科学实验中变得越来越重要。数据处理工作流通常包含多个复杂的步骤，精确规定资源需求对于每一步有效地分配最佳资源至关重要。由于分析场景的广泛差异、社区成员技能水平的差异以及计算选项范围的不断扩展，提前估计资源需求具有挑战性。一种实用的方法是初始处理每个步骤的一个子集，以实际处理性能数据来准确测量资源利用率，然后再完成整个步骤。虽然这种方法允许大多数工作流在最佳资源上进行处理，但它也存在一些缺点，如初始准确性不足可能导致潜在失败和资源使用不充分，以及等待初始处理完成的额外开销，这对快速周转分析至关重要。在这一背景下，我们的研究介绍了一个全面的工作流管理系统——Production and Distributed Analysis (PanDA)系统中的新型机器学习模型管道。这些模型采用先进的机器学习技术来预测关键的资源需求，克服了对每一步特性的有限前置知识所带来的挑战。准确的资源需求预测有助于在工作流管理中进行知情和主动决策，从而提高处理异构资源上多种复杂工作流的效率。', 'title_zh': '基于机器学习的复杂科学工作流预测资源管理'}
{'arxiv_id': 'arXiv:2509.11492', 'title': 'ClaimIQ at CheckThat! 2025: Comparing Prompted and Fine-Tuned Language Models for Verifying Numerical Claims', 'authors': 'Anirban Saha Anik, Md Fahimul Kabir Chowdhury, Andrew Wyckoff, Sagnik Ray Choudhury', 'link': 'https://arxiv.org/abs/2509.11492', 'abstract': 'This paper presents our system for Task 3 of the CLEF 2025 CheckThat! Lab, which focuses on verifying numerical and temporal claims using retrieved evidence. We explore two complementary approaches: zero-shot prompting with instruction-tuned large language models (LLMs) and supervised fine-tuning using parameter-efficient LoRA. To enhance evidence quality, we investigate several selection strategies, including full-document input and top-k sentence filtering using BM25 and MiniLM. Our best-performing model LLaMA fine-tuned with LoRA achieves strong performance on the English validation set. However, a notable drop in the test set highlights a generalization challenge. These findings underscore the importance of evidence granularity and model adaptation for robust numerical fact verification.', 'abstract_zh': '本文介绍了我们用于CLEF 2025 CheckThat! Lab任务3的系统，该任务专注于使用检索到的证据验证数值性和时间性声明。我们探讨了两种互补的方法：零样本提示与指令微调大型语言模型（LLMs）以及使用参数高效LoRA进行监督微调。为了提升证据质量，我们探讨了几种选择策略，包括全文输入和使用BM25和MiniLM的top-k句子过滤。我们的最佳模型LLaMA结合LoRA微调在英语验证集上表现出色，但在测试集上出现显著下降，这强调了数值事实验证中证据粒度和模型适应的重要性。', 'title_zh': 'ClaimIQ 在 CheckThat! 2025：比较触发式和微调语言模型验证数值声明的效果'}
{'arxiv_id': 'arXiv:2509.11481', 'title': 'RAPTOR: A Foundation Policy for Quadrotor Control', 'authors': 'Jonas Eschmann, Dario Albani, Giuseppe Loianno', 'link': 'https://arxiv.org/abs/2509.11481', 'abstract': 'Humans are remarkably data-efficient when adapting to new unseen conditions, like driving a new car. In contrast, modern robotic control systems, like neural network policies trained using Reinforcement Learning (RL), are highly specialized for single environments. Because of this overfitting, they are known to break down even under small differences like the Simulation-to-Reality (Sim2Real) gap and require system identification and retraining for even minimal changes to the system. In this work, we present RAPTOR, a method for training a highly adaptive foundation policy for quadrotor control. Our method enables training a single, end-to-end neural-network policy to control a wide variety of quadrotors. We test 10 different real quadrotors from 32 g to 2.4 kg that also differ in motor type (brushed vs. brushless), frame type (soft vs. rigid), propeller type (2/3/4-blade), and flight controller (PX4/Betaflight/Crazyflie/M5StampFly). We find that a tiny, three-layer policy with only 2084 parameters is sufficient for zero-shot adaptation to a wide variety of platforms. The adaptation through In-Context Learning is made possible by using a recurrence in the hidden layer. The policy is trained through a novel Meta-Imitation Learning algorithm, where we sample 1000 quadrotors and train a teacher policy for each of them using Reinforcement Learning. Subsequently, the 1000 teachers are distilled into a single, adaptive student policy. We find that within milliseconds, the resulting foundation policy adapts zero-shot to unseen quadrotors. We extensively test the capabilities of the foundation policy under numerous conditions (trajectory tracking, indoor/outdoor, wind disturbance, poking, different propellers).', 'abstract_zh': '人类在适应新未见条件时表现出惊人的数据效率，比如驾驶新车型。相比之下，现代机器人控制系统，如使用强化学习（RL）训练的神经网络策略，高度专门化于单一环境。由于这种过拟合，它们在小差异如仿真到现实（Sim2Real）缺口的情况下容易失效，并且即使是对系统的最小更改也需要系统辨识和重新训练。在本工作中，我们提出了一种名为RAPTOR的方法，用于训练四旋翼飞行器控制的高适应性基础策略。该方法使得能够训练一个端到端的神经网络策略，控制多种不同类型的四旋翼飞行器。我们测试了32克到2.4千克、不同电机类型（有刷 vs 无刷）、不同机架类型（柔体 vs 刚体）、不同螺旋桨类型（2/3/4片桨）以及不同飞控系统（PX4/Betaflight/Crazyflie/M5StampFly）的10种不同四旋翼飞行器。我们发现，仅含有2084参数的三层小型策略足以实现对各种平台的零样本适应。通过在隐藏层使用循环的方法，使得上下文学习成为可能。该策略通过一种新型的元模仿学习算法进行训练，其中我们采样了1000种四旋翼飞行器，并为每种飞行器训练一个教师策略，然后将这1000个教师策略提炼成一个适应性强的学生策略。我们发现，毫秒级内，基础策略能够在未见过的四旋翼飞行器上实现零样本适应。我们在多种条件下（轨迹跟踪、室内外环境、风扰、触碰、不同螺旋桨）对基础策略的能力进行了广泛的测试。', 'title_zh': 'RAPTOR：四旋翼飞行器控制的基础策略'}
{'arxiv_id': 'arXiv:2509.11478', 'title': "Designing and Evaluating a Conversational Agent for Early Detection of Alzheimer's Disease and Related Dementias", 'authors': 'Andrew G. Breithaupt, Nayoung Choi, James D. Finch, Jeanne M. Powell, Arin L. Nelson, Oz A. Alon, Howard J. Rosen, Jinho D. Choi', 'link': 'https://arxiv.org/abs/2509.11478', 'abstract': "Early detection of Alzheimer's disease and related dementias (ADRD) is critical for timely intervention, yet most diagnoses are delayed until advanced stages. While comprehensive patient narratives are essential for accurate diagnosis, prior work has largely focused on screening studies that classify cognitive status from interactions rather than supporting the diagnostic process. We designed voice-interactive conversational agents, leveraging large language models (LLMs), to elicit narratives relevant to ADRD from patients and informants. We evaluated the agent with 30 adults with suspected ADRD through conversation analysis (n=30), user surveys (n=19), and clinical validation against blinded specialist interviews (n=24). Symptoms detected by the agent aligned well with those identified by specialists across symptoms. Users appreciated the agent's patience and systematic questioning, which supported engagement and expression of complex, hard-to-describe experiences. This preliminary work suggests conversational agents may serve as structured front-end tools for dementia assessment, highlighting interaction design considerations in sensitive healthcare contexts.", 'abstract_zh': 'early检测阿尔茨海默病及相关痴呆症对于及时干预至关重要，但大多数诊断直到疾病晚期才进行。虽然全面的患者叙事对于准确诊断至关重要，但此前的工作主要集中在筛查研究上，这些研究通过交流分类认知状态，而非支持诊断过程。我们设计了语音交互对话代理，利用大规模语言模型（LLMs），以从患者和观察者那里引出与阿尔茨海默病相关的历史，并提供诊断信息。我们通过对话分析（n=30）、用户调查（n=19）以及与盲审专家访谈的临床验证（n=24）评估了该代理。代理检测到的症状与专家识别的症状高度一致。用户赞赏代理的耐心和系统化的问题，这有助于促进患者的参与和表达复杂的、难以描述的经历。初步研究表明，对话代理可能作为痴呆评估的结构化前端工具发挥作用，并强调在敏感的医疗保健环境中进行交互设计时需要考虑的因素。', 'title_zh': '设计并评估一种用于早期检测阿尔茨海默病及相关痴呆症的对话代理系统'}
{'arxiv_id': 'arXiv:2509.11461', 'title': 'CareerPooler: AI-Powered Metaphorical Pool Simulation Improves Experience and Outcomes in Career Exploration', 'authors': 'Ziyi Wang, Ziwen Zeng, Yuan Li, Zijian Ding', 'link': 'https://arxiv.org/abs/2509.11461', 'abstract': 'Career exploration is uncertain, requiring decisions with limited information and unpredictable outcomes. While generative AI offers new opportunities for career guidance, most systems rely on linear chat interfaces that produce overly comprehensive and idealized suggestions, overlooking the non-linear and effortful nature of real-world trajectories. We present CareerPooler, a generative AI-powered system that employs a pool-table metaphor to simulate career development as a spatial and narrative interaction. Users strike balls representing milestones, skills, and random events, where hints, collisions, and rebounds embody decision-making under uncertainty. In a within-subjects study with 24 participants, CareerPooler significantly improved engagement, information gain, satisfaction, and career clarity compared to a chatbot baseline. Qualitative findings show that spatial-narrative interaction fosters experience-based learning, resilience through setbacks, and reduced psychological burden. Our findings contribute to the design of AI-assisted career exploration systems and more broadly suggest that visually grounded analogical interactions can make generative systems engaging and satisfying.', 'abstract_zh': '职业探索充满不确定性，需要在有限信息和不可预测的结果下做决策。虽然生成式AI为职业指导提供了新机遇，但大多数系统依赖线性聊天界面，产生过于全面和理想化的建议，忽视了现实世界轨迹的非线性和努力性质。我们提出CareerPooler，一个采用台球类比来模拟职业发展为主的空间性和故事情节交互的生成式AI系统。用户可以通过击打代表里程碑、技能和随机事件的球来进行互动，提示、碰撞和反弹体现了在不确定性下的决策过程。在24名参与者的单被试实验中，与聊天机器人基准相比，CareerPooler显著提高了参与度、信息获取、满意度和职业清晰度。定性研究结果显示，空间-故事情节交互促进了基于经验的学习、挫折后的韧性并减轻了心理负担。我们的研究结果为AI辅助职业探索系统的设计做出了贡献，并更广泛地表明，视觉化的类比互动可以使生成系统更具吸引力和满意度。', 'title_zh': 'CareerPooler：AI赋能的隐喻性池化模拟提高职业探索的经验和成果'}
{'arxiv_id': 'arXiv:2509.11453', 'title': 'Beyond Frame-wise Tracking: A Trajectory-based Paradigm for Efficient Point Cloud Tracking', 'authors': 'BaiChen Fan, Sifan Zhou, Jian Li, Shibo Zhao, Muqing Cao, Qin Wang', 'link': 'https://arxiv.org/abs/2509.11453', 'abstract': 'LiDAR-based 3D single object tracking (3D SOT) is a critical task in robotics and autonomous systems. Existing methods typically follow frame-wise motion estimation or a sequence-based paradigm. However, the two-frame methods are efficient but lack long-term temporal context, making them vulnerable in sparse or occluded scenes, while sequence-based methods that process multiple point clouds gain robustness at a significant computational cost. To resolve this dilemma, we propose a novel trajectory-based paradigm and its instantiation, TrajTrack. TrajTrack is a lightweight framework that enhances a base two-frame tracker by implicitly learning motion continuity from historical bounding box trajectories alone-without requiring additional, costly point cloud inputs. It first generates a fast, explicit motion proposal and then uses an implicit motion modeling module to predict the future trajectory, which in turn refines and corrects the initial proposal. Extensive experiments on the large-scale NuScenes benchmark show that TrajTrack achieves new state-of-the-art performance, dramatically improving tracking precision by 4.48% over a strong baseline while running at 56 FPS. Besides, we also demonstrate the strong generalizability of TrajTrack across different base trackers. Video is available at this https URL.', 'abstract_zh': '基于LiDAR的3D单目标跟踪（3D SOT）是机器人和自主系统中的一个关键任务。现有的方法通常遵循帧级运动估计或基于序列的范式。然而，两帧方法效率高但缺乏长期时序上下文，在稀疏或被遮挡的场景中容易失效，而处理多个点云的序列方法虽然具有鲁棒性，但在计算成本上显著增加。为了解决这一矛盾，我们提出了一种新型的轨迹导向范式及其具体实例TrajTrack。TrajTrack是一种轻量级框架，通过仅从历史边界框轨迹中隐式学习运动连续性来增强基础的两帧跟踪器，无需额外的成本高昂的点云输入。它首先生成一个快速的显式运动提案，然后使用隐式运动建模模块预测未来的轨迹，进而细化和纠正初始提案。在大规模NuScenes基准测试上的大量实验表明，TrajTrack达到了新的最佳性能，在运行速度达到56 FPS的情况下，比强大基准提高了4.48%的跟踪精度。此外，我们还展示了TrajTrack在不同基础跟踪器上的强大泛化能力。视频可访问此链接。', 'title_zh': '超越帧级跟踪：一种高效的点云轨迹导向跟踪范式'}
{'arxiv_id': 'arXiv:2509.11449', 'title': 'Tabular Data with Class Imbalance: Predicting Electric Vehicle Crash Severity with Pretrained Transformers (TabPFN) and Mamba-Based Models', 'authors': 'Shriyank Somvanshi, Pavan Hebli, Gaurab Chhetri, Subasish Das', 'link': 'https://arxiv.org/abs/2509.11449', 'abstract': 'This study presents a deep tabular learning framework for predicting crash severity in electric vehicle (EV) collisions using real-world crash data from Texas (2017-2023). After filtering for electric-only vehicles, 23,301 EV-involved crash records were analyzed. Feature importance techniques using XGBoost and Random Forest identified intersection relation, first harmful event, person age, crash speed limit, and day of week as the top predictors, along with advanced safety features like automatic emergency braking. To address class imbalance, Synthetic Minority Over-sampling Technique and Edited Nearest Neighbors (SMOTEENN) resampling was applied. Three state-of-the-art deep tabular models, TabPFN, MambaNet, and MambaAttention, were benchmarked for severity prediction. While TabPFN demonstrated strong generalization, MambaAttention achieved superior performance in classifying severe injury cases due to its attention-based feature reweighting. The findings highlight the potential of deep tabular architectures for improving crash severity prediction and enabling data-driven safety interventions in EV crash contexts.', 'abstract_zh': '本研究提出了一种深度表格学习框架，使用2017-2023年德克萨斯州实际碰撞数据预测电动汽车（EV）碰撞 severity，经过筛选后的涉及纯电动汽车的碰撞记录共分析了23,301条。特征重要性技术使用XGBoost和随机森林确定了交叉口关系、首次有害事件、人员年龄、碰撞速度限制和星期几等顶级预测因子，同时还包括先进的安全特征如自动紧急制动。为解决类别不平衡问题，应用了合成少数过采样技术与编辑最近邻（SMOTEENN）重采样方法。三种最先进的深度表格模型，TabPFN、MambaNet和MambaAttention，被用于碰撞 severity 预测基准测试。尽管TabPFN在泛化能力上表现出色，但MambaAttention由于基于注意力机制的特征加权，在分类严重损伤案例方面表现更优。本研究结果强调了深度表格架构在提高电动汽车碰撞 severity 预测中的潜力，并促进了基于数据的安全干预措施。', 'title_zh': '不平衡类别的表格数据：基于Pretrained Transformers（TabPFN）和Mamba-Based模型预测电动车辆碰撞严重程度'}
{'arxiv_id': 'arXiv:2509.11425', 'title': 'FuseCodec: Semantic-Contextual Fusion and Supervision for Neural Codecs', 'authors': 'Md Mubtasim Ahasan, Rafat Hasan Khan, Tasnim Mohiuddin, Aman Chadha, Tariq Iqbal, M Ashraful Amin, Amin Ahsan Ali, Md Mofijul Islam, A K M Mahbubur Rahman', 'link': 'https://arxiv.org/abs/2509.11425', 'abstract': "Speech tokenization enables discrete representation and facilitates speech language modeling. However, existing neural codecs capture low-level acoustic features, overlooking the semantic and contextual cues inherent to human speech. While recent efforts introduced semantic representations from self-supervised speech models or incorporated contextual representations from pre-trained language models, challenges remain in aligning and unifying the semantic and contextual representations. We introduce FuseCodec, which unifies acoustic, semantic, and contextual representations through strong cross-modal alignment and globally informed supervision. We propose three complementary techniques: (i) Latent Representation Fusion, integrating semantic and contextual features directly into the encoder latent space for robust and unified representation learning; (ii) Global Semantic-Contextual Supervision, supervising discrete tokens with globally pooled and broadcasted representations to enhance temporal consistency and cross-modal alignment; and (iii) Temporally Aligned Contextual Supervision, strengthening alignment by dynamically matching contextual and speech tokens within a local window for fine-grained token-level supervision. We further introduce FuseCodec-TTS, demonstrating our methodology's applicability to zero-shot speech synthesis. Empirically, FuseCodec achieves state-of-the-art performance in LibriSpeech, surpassing EnCodec, SpeechTokenizer, and DAC in transcription accuracy, perceptual quality, intelligibility, and speaker similarity. Results highlight the effectiveness of contextually and semantically guided tokenization for speech tokenization and downstream tasks. Code and pretrained models are available at this https URL.", 'abstract_zh': '语音分词 enables 离散表示并促进语音语言建模。然而，现有的神经编解码器捕获低级声学特征，忽略了人类语音中固有的语义和上下文线索。虽然最近的努力引入了从自监督语音模型获得的语义表示，或将从预训练语言模型获得的上下文表示纳入其中，但语义和上下文表示的对齐和统一仍然存在挑战。我们引入了 FuseCodec，通过强大的跨模态对齐和全局信息监督统一声学、语义和上下文表示。我们提出了三种互补的技术：（i）潜在表示融合，将语义和上下文特征直接整合到编码器的潜在空间中，以实现稳健且统一的表示学习；（ii）全局语义-上下文监督，使用全局聚合和广播表示监督离散的标记，以增强时间一致性和跨模态对齐；（iii）时间对齐的上下文监督，在局部窗口内动态匹配上下文和语音标记，以实现细粒度的标记级监督。此外，我们还引入了 FuseCodec-TTS，展示了我们的方法在零样本语音合成中的适用性。实验结果表明，FuseCodec 在 LibriSpeech 中达到了最先进的性能，超越了 EnCodec、SpeechTokenizer 和 DAC 在转录准确性、感知质量、可懂度和说话人相似度方面的表现。结果突显了上下文和语义引导的分词在语音分词及后续任务中的有效性。代码和预训练模型可通过以下链接获取。', 'title_zh': 'FuseCodec: 语义-上下文融合与监督神经编码器'}
{'arxiv_id': 'arXiv:2509.11420', 'title': 'Trading-R1: Financial Trading with LLM Reasoning via Reinforcement Learning', 'authors': 'Yijia Xiao, Edward Sun, Tong Chen, Fang Wu, Di Luo, Wei Wang', 'link': 'https://arxiv.org/abs/2509.11420', 'abstract': 'Developing professional, structured reasoning on par with human financial analysts and traders remains a central challenge in AI for finance, where markets demand interpretability and trust. Traditional time-series models lack explainability, while LLMs face challenges in turning natural-language analysis into disciplined, executable trades. Although reasoning LLMs have advanced in step-by-step planning and verification, their application to risk-sensitive financial decisions is underexplored. We present Trading-R1, a financially-aware model that incorporates strategic thinking and planning for comprehensive thesis composition, facts-grounded analysis, and volatility-adjusted decision making. Trading-R1 aligns reasoning with trading principles through supervised fine-tuning and reinforcement learning with a three-stage easy-to-hard curriculum. Training uses Tauric-TR1-DB, a 100k-sample corpus spanning 18 months, 14 equities, and five heterogeneous financial data sources. Evaluated on six major equities and ETFs, Trading-R1 demonstrates improved risk-adjusted returns and lower drawdowns compared to both open-source and proprietary instruction-following models as well as reasoning models. The system generates structured, evidence-based investment theses that support disciplined and interpretable trading decisions. Trading-R1 Terminal will be released at this https URL.', 'abstract_zh': '一种具有战略思考和规划能力的财务意识模型Trading-R1：全面论点构成、基于事实的分析及调整波动性的决策方法', 'title_zh': 'Trading-R1：通过强化学习进行的金融交易与LLM推理'}
{'arxiv_id': 'arXiv:2509.11417', 'title': 'Enhancing Generalization in Vision-Language-Action Models by Preserving Pretrained Representations', 'authors': 'Shresth Grover, Akshay Gopalkrishnan, Bo Ai, Henrik I. Christensen, Hao Su, Xuanlin Li', 'link': 'https://arxiv.org/abs/2509.11417', 'abstract': "Vision-language-action (VLA) models finetuned from vision-language models (VLMs) hold the promise of leveraging rich pretrained representations to build generalist robots across diverse tasks and environments. However, direct fine-tuning on robot data often disrupts these representations and limits generalization. We present a framework that better preserves pretrained features while adapting them for robot manipulation. Our approach introduces three components: (i) a dual-encoder design with one frozen vision encoder to retain pretrained features and another trainable for task adaptation, (ii) a string-based action tokenizer that casts continuous actions into character sequences aligned with the model's pretraining domain, and (iii) a co-training strategy that combines robot demonstrations with vision-language datasets emphasizing spatial reasoning and affordances. Evaluations in simulation and on real robots show that our method improves robustness to visual perturbations, generalization to novel instructions and environments, and overall task success compared to baselines.", 'abstract_zh': '基于视觉-语言-动作模型的框架能够更好地保留预训练特征并适应机器人操作任务', 'title_zh': '通过保留预训练表示以增强视觉-语言-动作模型的泛化能力'}
{'arxiv_id': 'arXiv:2509.11413', 'title': 'Framing AI System Benchmarking as a Learning Task: FlexBench and the Open MLPerf Dataset', 'authors': 'Grigori Fursin, Daniel Altunay', 'link': 'https://arxiv.org/abs/2509.11413', 'abstract': 'Existing AI system benchmarks such as MLPerf often struggle to keep pace with the rapidly evolving AI landscape, making it difficult to support informed deployment, optimization, and co-design decisions for AI systems. We suggest that benchmarking itself can be framed as an AI task - one in which models are continuously evaluated and optimized across diverse datasets, software, and hardware, using key metrics such as accuracy, latency, throughput, energy consumption, and cost. To support this perspective, we present FlexBench: a modular extension of the MLPerf LLM inference benchmark, integrated with HuggingFace and designed to provide relevant and actionable insights. Benchmarking results and metadata are collected into an Open MLPerf Dataset, which can be collaboratively curated, extended, and leveraged for predictive modeling and feature engineering. We successfully validated the FlexBench concept through MLPerf Inference submissions, including evaluations of DeepSeek R1 and LLaMA 3.3 on commodity servers. The broader objective is to enable practitioners to make cost-effective AI deployment decisions that reflect their available resources, requirements, and constraints.', 'abstract_zh': '现有的AI系统基准测试如MLPerf往往难以跟上快速发展的AI景观，使得无法为AI系统的部署、优化和协同设计提供有力的支持。我们认为，基准测试本身可以被视为一项AI任务——即模型在多样化的数据集、软件和硬件上持续地被评价和优化，使用诸如准确率、延迟、吞吐量、能耗和成本等关键指标。为支持这一观点，我们提出FlexBench：MLPerf LLM推理基准的一个模块化扩展，集成HuggingFace，并旨在提供相关且可行的见解。基准测试结果和元数据被收集到Open MLPerf数据集中，可以协作维护、扩展并用于预测建模和特征工程。我们通过MLPerf推理提交验证了FlexBench的概念，包括在通用服务器上对DeepSeek R1和LLaMA 3.3的评估。更大的目标是使从业者能够根据其可用资源、需求和约束条件，做出成本效益高的AI部署决策。', 'title_zh': '将AI系统基准测试 framing 为一个学习任务：FlexBench 及开放的 MLPerf 数据集'}
{'arxiv_id': 'arXiv:2509.11398', 'title': 'From Firewalls to Frontiers: AI Red-Teaming is a Domain-Specific Evolution of Cyber Red-Teaming', 'authors': 'Anusha Sinha, Keltin Grimes, James Lucassen, Michael Feffer, Nathan VanHoudnos, Zhiwei Steven Wu, Hoda Heidari', 'link': 'https://arxiv.org/abs/2509.11398', 'abstract': 'A red team simulates adversary attacks to help defenders find effective strategies to defend their systems in a real-world operational setting. As more enterprise systems adopt AI, red-teaming will need to evolve to address the unique vulnerabilities and risks posed by AI systems. We take the position that AI systems can be more effectively red-teamed if AI red-teaming is recognized as a domain-specific evolution of cyber red-teaming. Specifically, we argue that existing Cyber Red Teams who adopt this framing will be able to better evaluate systems with AI components by recognizing that AI poses new risks, has new failure modes to exploit, and often contains unpatchable bugs that re-prioritize disclosure and mitigation strategies. Similarly, adopting a cybersecurity framing will allow existing AI Red Teams to leverage a well-tested structure to emulate realistic adversaries, promote mutual accountability with formal rules of engagement, and provide a pattern to mature the tooling necessary for repeatable, scalable engagements. In these ways, the merging of AI and Cyber Red Teams will create a robust security ecosystem and best position the community to adapt to the rapidly changing threat landscape.', 'abstract_zh': '人工智能红队模拟对手攻击以帮助企业防御者在实际操作环境中找到有效的防御策略。随着企业系统越来越多地采用AI，红队行动需要演进以应对AI系统带来的独特漏洞和风险。我们认为，如果将AI红队行动视为网络红队行动的领域特定演进，AI系统可以更有效地接受红队测试。具体而言，现有的网络红队行动如果采取这种框架，将能够更好地评估包含AI组件的系统，认识到AI带来了新的风险、新的利用漏洞模式，并且经常包含无法修补的漏洞，这意味着需要重新调整披露和缓解策略的优先级。同样，采用网络安全部署框架将使现有的AI红队能够利用经过验证的结构来模拟现实的对手、促进共同问责制并通过正式的规则参与合作，并提供一套模式以成熟必要的工具以实现重复性和可扩展性。通过这种方式，AI和网络红队的结合将创造一个稳健的安全生态系统，并使社区能够更好地适应迅速变化的威胁环境。', 'title_zh': '从防火墙到前沿：AI 红队演练是网络红队演练的领域特定演化'}
{'arxiv_id': 'arXiv:2509.11376', 'title': 'Intelligent Reservoir Decision Support: An Integrated Framework Combining Large Language Models, Advanced Prompt Engineering, and Multimodal Data Fusion for Real-Time Petroleum Operations', 'authors': 'Seyed Kourosh Mahjour, Seyed Saman Mahjour', 'link': 'https://arxiv.org/abs/2509.11376', 'abstract': 'The petroleum industry faces unprecedented challenges in reservoir management, requiring rapid integration of complex multimodal datasets for real-time decision support. This study presents a novel integrated framework combining state-of-the-art large language models (GPT-4o, Claude 4 Sonnet, Gemini 2.5 Pro) with advanced prompt engineering techniques and multimodal data fusion for comprehensive reservoir analysis. The framework implements domain-specific retrieval-augmented generation (RAG) with over 50,000 petroleum engineering documents, chain-of-thought reasoning, and few-shot learning for rapid field adaptation. Multimodal integration processes seismic interpretations, well logs, and production data through specialized AI models with vision transformers. Field validation across 15 diverse reservoir environments demonstrates exceptional performance: 94.2% reservoir characterization accuracy, 87.6% production forecasting precision, and 91.4% well placement optimization success rate. The system achieves sub-second response times while maintaining 96.2% safety reliability with no high-risk incidents during evaluation. Economic analysis reveals 62-78% cost reductions (mean 72%) relative to traditional methods with 8-month payback period. Few-shot learning reduces field adaptation time by 72%, while automated prompt optimization achieves 89% improvement in reasoning quality. The framework processed real-time data streams with 96.2% anomaly detection accuracy and reduced environmental incidents by 45%. We provide detailed experimental protocols, baseline comparisons, ablation studies, and statistical significance testing to ensure reproducibility. This research demonstrates practical integration of cutting-edge AI technologies with petroleum domain expertise for enhanced operational efficiency, safety, and economic performance.', 'abstract_zh': '石油行业在储层管理方面面临着前所未有的挑战，需要快速整合复杂多模态数据以支持实时决策。本研究提出了一种结合最先进的大型语言模型（GPT-4o、Claude 4 Sonnet、Gemini 2.5 Pro）与高级提示工程技术和多模态数据融合的新型集成框架，用于全面的储层分析。该框架采用领域特定的检索增强生成（RAG）并结合了超过50,000份石油工程文献、链式推理和少量样本学习，实现了快速的油田适应性。多模态整合过程通过专门的AI模型和视觉变压器处理地震解释、井Log和生产数据。在15个不同的储层环境中进行的现场验证显示了卓越的表现：94.2%的储层特征化准确率、87.6%的产量预测精度和91.4%的井位优化成功率。系统在保持96.2%的安全可靠性的同时实现了亚秒级响应时间，在评估过程中未发生任何高风险事故。经济分析显示，与传统方法相比，成本减少了62-78%（平均72%），回收期为8个月。少量样本学习减少了油田适应时间72%，自动提示优化提高了推理质量89%。该框架以96.2%的异常检测准确率实时处理数据流，并减少了45%的环境事件。我们提供了详细的实验协议、基线比较、消除研究和统计显着性检验，以确保可重复性。本研究展示了将最先进的人工智能技术与石油领域的专业知识结合以提高操作效率、安全性和经济效益的实用集成。', 'title_zh': '智能油藏决策支持：结合大规模语言模型、高级提示工程和多模态数据融合的实时石油运营综合框架'}
{'arxiv_id': 'arXiv:2509.11374', 'title': 'Transformer Enhanced Relation Classification: A Comparative Analysis of Contextuality, Data Efficiency and Sequence Complexity', 'authors': 'Bowen Jing, Yang Cui, Tianpeng Huang', 'link': 'https://arxiv.org/abs/2509.11374', 'abstract': 'In the era of large language model, relation extraction (RE) plays an important role in information extraction through the transformation of unstructured raw text into structured data (Wadhwa et al., 2023). In this paper, we systematically compare the performance of deep supervised learning approaches without transformers and those with transformers. We used a series of non-transformer architectures such as PA-LSTM(Zhang et al., 2017), C-GCN(Zhang et al., 2018), and AGGCN(attention guide GCN)(Guo et al., 2019), and a series of transformer architectures such as BERT, RoBERTa, and R-BERT(Wu and He, 2019). Our comparison included traditional metrics like micro F1, as well as evaluations in different scenarios, varying sentence lengths, and different percentages of the dataset for training. Our experiments were conducted on TACRED, TACREV, and RE-TACRED. The results show that transformer-based models outperform non-transformer models, achieving micro F1 scores of 80-90% compared to 64-67% for non-transformer models. Additionally, we briefly review the research journey in supervised relation classification and discuss the role and current status of large language models (LLMs) in relation extraction.', 'abstract_zh': '在大语言模型时代，关系提取在通过将无结构原始文本转换为结构化数据的信息提取中扮演重要角色（Wadhwa等，2023）。本文系统比较了不含变换器和含有变换器的深度监督学习方法的性能。我们使用了多种非变换器架构，如PA-LSTM（Zhang等，2017）、C-GCN（Zhang等，2018）和AGGCN（注意力引导GCN，Guo等，2019），以及多种变换器架构，如BERT、RoBERTa和R-BERT（Wu和He，2019）。我们的比较包括传统的微F1等指标，以及在不同场景、不同句子长度和不同训练数据集百分比下的评估。实验在TACRED、TAC_REV和RE-TACRED上进行。结果显示，基于变换器的模型优于非变换器模型，微F1得分为80-90%，而非变换器模型的得分为64-67%。此外，本文简要回顾了监督关系分类的研究历程，并讨论了大语言模型在关系提取中的作用及其当前状态。', 'title_zh': 'Transformer增强的关系分类：上下文性、数据效率和序列复杂性的比较分析'}
{'arxiv_id': 'arXiv:2509.11367', 'title': 'Detecting Model Drifts in Non-Stationary Environment Using Edit Operation Measures', 'authors': 'Chang-Hwan Lee, Alexander Shim', 'link': 'https://arxiv.org/abs/2509.11367', 'abstract': 'Reinforcement learning (RL) agents typically assume stationary environment dynamics. Yet in real-world applications such as healthcare, robotics, and finance, transition probabilities or reward functions may evolve, leading to model drift. This paper proposes a novel framework to detect such drifts by analyzing the distributional changes in sequences of agent behavior. Specifically, we introduce a suite of edit operation-based measures to quantify deviations between state-action trajectories generated under stationary and perturbed conditions. Our experiments demonstrate that these measures can effectively distinguish drifted from non-drifted scenarios, even under varying levels of noise, providing a practical tool for drift detection in non-stationary RL environments.', 'abstract_zh': '强化学习（RL）代理通常假设环境动态是稳定的。但在医疗保健、机器人技术和金融等实际应用中，转换概率或奖励函数可能会发生变化，导致模型漂移。本文提出了一种新型框架，通过分析代理行为序列上的分布变化来检测此类漂移。具体而言，我们引入了一系列基于编辑操作的度量来量化在稳定和扰动条件下生成的状态-动作轨迹之间的偏差。我们的实验表明，这些度量可以在不同程度的噪声下有效地区分漂移和非漂移场景，提供了一种在非稳定RL环境中进行漂移检测的实用工具。', 'title_zh': '使用编辑操作度量检测非稳态环境中模型漂移'}
{'arxiv_id': 'arXiv:2509.11355', 'title': 'Promoting Shape Bias in CNNs: Frequency-Based and Contrastive Regularization for Corruption Robustness', 'authors': 'Robin Narsingh Ranabhat, Longwei Wang, Amit Kumar Patel, KC santosh', 'link': 'https://arxiv.org/abs/2509.11355', 'abstract': 'Convolutional Neural Networks (CNNs) excel at image classification but remain vulnerable to common corruptions that humans handle with ease. A key reason for this fragility is their reliance on local texture cues rather than global object shapes -- a stark contrast to human perception. To address this, we propose two complementary regularization strategies designed to encourage shape-biased representations and enhance robustness. The first introduces an auxiliary loss that enforces feature consistency between original and low-frequency filtered inputs, discouraging dependence on high-frequency textures. The second incorporates supervised contrastive learning to structure the feature space around class-consistent, shape-relevant representations. Evaluated on the CIFAR-10-C benchmark, both methods improve corruption robustness without degrading clean accuracy. Our results suggest that loss-level regularization can effectively steer CNNs toward more shape-aware, resilient representations.', 'abstract_zh': '卷积神经网络（CNNs）在图像分类方面表现出色，但仍然容易受到人类可以轻松处理的常见 corruption 的影响。这一脆弱性的一个关键原因是它们依赖局部纹理线索而非全局对象形状——这与人类感知形成了鲜明对比。为了应对这一挑战，我们提出了两种互补的正则化策略，旨在促进形状偏向的表示并提高鲁棒性。第一种策略引入了辅助损失，强制原始输入和低频过滤输入之间的特征一致性，从而减少对高频纹理的依赖。第二种策略结合了监督对比学习，以构建围绕类一致且形状相关表示的特征空间。在 CIFAR-10-C 基准上评估表明，这两种方法在不牺牲干净准确性的情况下提高了对 corruption 的鲁棒性。我们的结果表明，损失层面的正则化可以有效地引导 CNNs 向更注重形状、更具鲁棒性的表示方向发展。', 'title_zh': '基于频率和对比正则化促进CNN的形状偏见以增强对抗扰动的鲁棒性'}
{'arxiv_id': 'arXiv:2509.11332', 'title': 'A five-layer framework for AI governance: integrating regulation, standards, and certification', 'authors': 'Avinash Agarwal, Manisha J. Nene', 'link': 'https://arxiv.org/abs/2509.11332', 'abstract': "Purpose: The governance of artificial iintelligence (AI) systems requires a structured approach that connects high-level regulatory principles with practical implementation. Existing frameworks lack clarity on how regulations translate into conformity mechanisms, leading to gaps in compliance and enforcement. This paper addresses this critical gap in AI governance.\nMethodology/Approach: A five-layer AI governance framework is proposed, spanning from broad regulatory mandates to specific standards, assessment methodologies, and certification processes. By narrowing its scope through progressively focused layers, the framework provides a structured pathway to meet technical, regulatory, and ethical requirements. Its applicability is validated through two case studies on AI fairness and AI incident reporting.\nFindings: The case studies demonstrate the framework's ability to identify gaps in legal mandates, standardization, and implementation. It adapts to both global and region-specific AI governance needs, mapping regulatory mandates with practical applications to improve compliance and risk management.\nPractical Implications - By offering a clear and actionable roadmap, this work contributes to global AI governance by equipping policymakers, regulators, and industry stakeholders with a model to enhance compliance and risk management.\nSocial Implications: The framework supports the development of policies that build public trust and promote the ethical use of AI for the benefit of society.\nOriginality/Value: This study proposes a five-layer AI governance framework that bridges high-level regulatory mandates and implementation guidelines. Validated through case studies on AI fairness and incident reporting, it identifies gaps such as missing standardized assessment procedures and reporting mechanisms, providing a structured foundation for targeted governance measures.", 'abstract_zh': '目的：人工智能（AI）系统的治理需要一种有条理的方法，将高层次的监管原则与实际实施联系起来。现有框架在将监管要求转化为合规机制方面缺乏清晰性，导致合规性和执行方面存在缺口。本文解决了AI治理中的这一关键缺口。\n\n方法/步骤：提出了一种五层AI治理框架，涵盖从广泛的监管要求到具体的标准、评估方法和认证流程等多个层面。通过逐步聚焦各层，该框架为满足技术、监管和伦理要求提供了结构化的途径。通过两个关于AI公平性和AI事件报告的案例研究，验证了其适用性。\n\n发现：案例研究展示了该框架在识别法律法规、标准化和实施方面的缺口方面的能力。该框架能够适应全球和区域特定的AI治理需求，通过将监管要求与实际应用结合，改善合规性和风险管理。\n\n实践意义：通过提供清晰可操作的路线图，本研究为全球AI治理提供了贡献，使政策制定者、监管机构和行业利益相关者能够提升合规性和风险管理。\n\n社会影响：该框架支持制定了能够建立公众信任并促进AI公正使用的政策，从而造福社会。\n\n原创性/价值：本研究提出了一种五层AI治理框架，连接了高层次的监管要求和实施指南。通过AI公平性和事件报告的案例研究验证，该框架识别了缺失的标准评估程序和报告机制等方面的缺口，为针对性的治理措施提供了结构化的基础。', 'title_zh': '五层框架下的AI治理：整合监管、标准与认证'}
{'arxiv_id': 'arXiv:2509.11323', 'title': 'Motion Estimation for Multi-Object Tracking using KalmanNet with Semantic-Independent Encoding', 'authors': 'Jian Song, Wei Mei, Yunfeng Xu, Qiang Fu, Renke Kou, Lina Bu, Yucheng Long', 'link': 'https://arxiv.org/abs/2509.11323', 'abstract': "Motion estimation is a crucial component in multi-object tracking (MOT).\nIt predicts the trajectory of objects by analyzing the changes in their positions in consecutive frames of images, reducing tracking failures and identity switches.\nThe Kalman filter (KF) based on the linear constant-velocity model is one of the most commonly used methods in MOT.\nHowever, it may yield unsatisfactory results when KF's parameters are mismatched and objects move in non-stationary.\nIn this work, we utilize the learning-aided filter to handle the motion estimation of MOT.\nIn particular, we propose a novel method named Semantic-Independent KalmanNet (SIKNet), which encodes the state vector (the input feature) using a Semantic-Independent Encoder (SIE) by two steps.\nFirst, the SIE uses a 1D convolution with a kernel size of 1, which convolves along the dimension of homogeneous-semantic elements across different state vectors to encode independent semantic information.\nThen it employs a fully-connected layer and a nonlinear activation layer to encode nonlinear and cross-dependency information between heterogeneous-semantic elements.\nTo independently evaluate the performance of the motion estimation module in MOT, we constructed a large-scale semi-simulated dataset from several open-source MOT datasets.\nExperimental results demonstrate that the proposed SIKNet outperforms the traditional KF and achieves superior robustness and accuracy than existing learning-aided filters.\nThe code is available at (this https URL and this https URL).", 'abstract_zh': '多对象跟踪（MOT）中的运动估计是其关键组成部分。它通过分析图像连续帧中目标位置的变化来预测目标的轨迹，从而减少跟踪失败和身份切换。基于线性恒速模型的卡尔曼滤波器（KF）是MOT中广泛使用的方法之一。然而，当KF的参数不匹配且目标进行非平稳运动时，可能会导致不满意的估计结果。在本文中，我们利用辅助学习滤波器来处理MOT的运动估计。特别地，我们提出了一种名为语义独立卡尔曼网络（SIKNet）的新方法，该方法通过两步将状态向量（输入特征）编码为语义独立编码器（SIE）。首先，SIE使用内核大小为1的1D卷积，沿不同状态向量中的同质语义元素进行卷积，以编码独立的语义信息。然后，它使用全连接层和非线性激活层来编码异质语义元素之间的非线性和交叉依赖信息。为了独立评估MOT中的运动估计模块的性能，我们从几个开源MOT数据集中构建了一个大规模半模拟数据集。实验结果表明，所提出的SIKNet优于传统的卡尔曼滤波器，并且在鲁棒性和准确性方面优于现有的辅助学习滤波器。代码可从 (this https URL 和 this https URL) 获取。', 'title_zh': '使用语义独立编码的KalmanNet运动估计在多对象跟踪中的应用'}
{'arxiv_id': 'arXiv:2509.11312', 'title': 'Weakly Supervised Vulnerability Localization via Multiple Instance Learning', 'authors': 'Wenchao Gu, Yupan Chen, Yanlin Wang, Hongyu Zhang, Cuiyun Gao, Michael R. Lyu', 'link': 'https://arxiv.org/abs/2509.11312', 'abstract': 'Software vulnerability detection has emerged as a significant concern in the field of software security recently, capturing the attention of numerous researchers and developers. Most previous approaches focus on coarse-grained vulnerability detection, such as at the function or file level. However, the developers would still encounter the challenge of manually inspecting a large volume of code inside the vulnerable function to identify the specific vulnerable statements for modification, indicating the importance of vulnerability localization. Training the model for vulnerability localization usually requires ground-truth labels at the statement-level, and labeling vulnerable statements demands expert knowledge, which incurs high costs. Hence, the demand for an approach that eliminates the need for additional labeling at the statement-level is on the rise. To tackle this problem, we propose a novel approach called WAVES for WeAkly supervised Vulnerability Localization via multiplE inStance learning, which does not need the additional statement-level labels during the training. WAVES has the capability to determine whether a function is vulnerable (i.e., vulnerability detection) and pinpoint the vulnerable statements (i.e., vulnerability localization). Specifically, inspired by the concept of multiple instance learning, WAVES converts the ground-truth label at the function-level into pseudo labels for individual statements, eliminating the need for additional statement-level labeling. These pseudo labels are utilized to train the classifiers for the function-level representation vectors. Extensive experimentation on three popular benchmark datasets demonstrates that, in comparison to previous baselines, our approach achieves comparable performance in vulnerability detection and state-of-the-art performance in statement-level vulnerability localization.', 'abstract_zh': '软件漏洞检测已成为软件安全领域的一项重要关注点，吸引了众多研究人员和开发者的注意。大多数先前的方法集中在粗粒度的漏洞检测，如函数或文件级别。然而，开发者仍然面临着手动检查大量脆弱函数内部代码以识别特定脆弱语句进行修改的挑战，这突显了漏洞定位的重要性。训练模型进行漏洞定位通常需要语句级别的地面真实标签，而标注脆弱语句需要专家知识，这会产生高昂的成本。因此，减少或消除语句级别标注的需求的方法需求日益增加。为解决这一问题，我们提出了一种名为WAVES的新方法，WAVES通过多实例学习进行弱监督漏洞定位，不需要在训练过程中使用额外的语句级别标签。WAVES具有确定函数是否脆弱（即漏洞检测）并定位具体脆弱语句（即漏洞定位）的能力。具体而言，WAVES借鉴了多实例学习的概念，将函数级别的地面真实标签转化为个别语句的伪标签，从而消除额外的语句级别标注需求。这些伪标签被用于训练表示向量的分类器。在三个流行基准数据集上的广泛实验表明，与先前的基线方法相比，我们的方法在漏洞检测方面取得了可比的性能，并在语句级别漏洞定位方面达到了最先进的效果。', 'title_zh': '弱监督漏洞定位：基于实例学习的方法'}
{'arxiv_id': 'arXiv:2509.11298', 'title': 'Opal: An Operator Algebra View of RLHF', 'authors': 'Madhava Gaikwad', 'link': 'https://arxiv.org/abs/2509.11298', 'abstract': 'We present Opal, an operator view of reinforcement learning from human feedback (RLHF). Objectives are expressed as ladders of two primitives on a base utility: additive penalties and multiplicative pairwise weights. We describe a simple reduction law with if-and-only-if conditions: such ladders collapse to a normal form on pairwise margins when the reference is fixed, penalties are additive, and weights are independent of intermediate margins. When these assumptions do not hold (reference shift, non-additive gates, score-dependent weights), small examples demonstrate non-reducibility.\nBuilding on this view, we introduce GKPO (Generalized Kernel Preference Object), a canonical schema in which many RLHF methods can be represented and, when reducible, mapped back from. GKPO provides a standard JSON serialization, canonicalization and hashing rules, and explicit flags with finite witnesses when assumptions fail.\nWe illustrate these ideas with GKPO examples for DPO, RRHF, and ORPO, along with cross-method conversions (where assumptions permit) and minimal stress tests (SHIFT/GATE/SCORE) that highlight non-reducibility. A lightweight Python reference library accompanies the schema, implementing canonical hashing and adapters for DPO and RRHF.', 'abstract_zh': 'Opal: 一种基于人类反馈强化学习的操作视角', 'title_zh': 'Opal: RLHF的一种运算代数视角'}
{'arxiv_id': 'arXiv:2509.11297', 'title': 'Policy Learning for Social Robot-Led Physiotherapy', 'authors': 'Carl Bettosi, Lynne Ballie, Susan Shenkin, Marta Romeo', 'link': 'https://arxiv.org/abs/2509.11297', 'abstract': 'Social robots offer a promising solution for autonomously guiding patients through physiotherapy exercise sessions, but effective deployment requires advanced decision-making to adapt to patient needs. A key challenge is the scarcity of patient behavior data for developing robust policies. To address this, we engaged 33 expert healthcare practitioners as patient proxies, using their interactions with our robot to inform a patient behavior model capable of generating exercise performance metrics and subjective scores on perceived exertion. We trained a reinforcement learning-based policy in simulation, demonstrating that it can adapt exercise instructions to individual exertion tolerances and fluctuating performance, while also being applicable to patients at different recovery stages with varying exercise plans.', 'abstract_zh': '社会机器人提供了自主引导患者进行物理治疗练习的一种有前景的解决方案，但有效的部署需要先进的决策能力以适应患者需求。一个关键挑战是用于开发稳健策略的患者行为数据的稀缺性。为了应对这一挑战，我们邀请了33名专家医疗从业者作为患者代理，利用他们与我们机器人交互的信息来建立一个能够生成锻炼绩效指标和主观疲劳评分的患者行为模型。我们在仿真中训练了一个基于强化学习的策略，证明它可以适应个体的投入耐受度和波动表现，并且适用于处于不同恢复阶段、具有不同锻炼计划的患者。', 'title_zh': '社会机器人引导物理治疗的政策学习'}
{'arxiv_id': 'arXiv:2509.11289', 'title': 'Energy-Aware 6G Network Design: A Survey', 'authors': 'Rashmi Kamran, Mahesh Ganesh Bhat, Pranav Jha, Shana Moothedath, Manjesh Hanawal, Prasanna Chaporkar', 'link': 'https://arxiv.org/abs/2509.11289', 'abstract': '6th Generation (6G) mobile networks are envisioned to support several new capabilities and data-centric applications for unprecedented number of users, potentially raising significant energy efficiency and sustainability concerns. This brings focus on sustainability as one of the key objectives in the their design. To move towards sustainable solution, research and standardization community is focusing on several key issues like energy information monitoring and exposure, use of renewable energy, and use of Artificial Intelligence/Machine Learning (AI/ML) for improving the energy efficiency in 6G networks. The goal is to build energy-aware solutions that takes into account the energy information resulting in energy efficient networks. Design of energy-aware 6G networks brings in new challenges like increased overheads in gathering and exposing of energy related information, and the associated user consent management. The aim of this paper is to provide a comprehensive survey of methods used for design of energy efficient 6G networks, like energy harvesting, energy models and parameters, classification of energy-aware services, and AI/ML-based solutions. The survey also includes few use cases that demonstrate the benefits of incorporating energy awareness into network decisions. Several ongoing standardization efforts in 3GPP, ITU, and IEEE are included to provide insights into the ongoing work and highlight the opportunities for new contributions. We conclude this survey with open research problems and challenges that can be explored to make energy-aware design feasible and ensure optimality regarding performance and energy goals for 6G networks.', 'abstract_zh': '第六代（6G）移动网络的设计面临显著的能源效率和可持续性挑战，旨在支持前所未有的大量用户的新能力和数据中心应用。为此，可持续性成为其设计中的关键目标之一。为实现可持续解决方案，研究与标准化社区重点关注能源信息监控与暴露、可再生能源的使用以及通过人工智能/机器学习（AI/ML）提高6G网络能源效率等多个关键问题。目标是构建考虑能源信息的能源感知解决方案，从而实现能源效率更高的网络。设计能源感知6G网络带来了新的挑战，如能源相关信息的采集和暴露增加的开销，以及与此相关的用户同意管理。本文旨在提供一种全面的调查，涵盖用于设计节能6G网络的方法，如能量采集、能量模型与参数、能源感知服务分类以及基于AI/ML的解决方案。调查还包含几个案例，展示了将能源感知纳入网络决策中的益处。此外，本文包含了3GPP、ITU和IEEE等组织中的多项正在进行的标准制定工作，以提供对正在进行的工作的见解，并突出新的贡献机会。最后，本文以开放的研究问题和挑战作为结论，这些问题和挑战可以探索以使能源感知设计可行，并确保6G网络在性能和能源目标方面的最优化。', 'title_zh': '面向能源aware的6G网络设计：一个综述'}
{'arxiv_id': 'arXiv:2509.11285', 'title': 'Efficient Single-Step Framework for Incremental Class Learning in Neural Networks', 'authors': 'Alejandro Dopico-Castro, Oscar Fontenla-Romero, Bertha Guijarro-Berdiñas, Amparo Alonso-Betanzos', 'link': 'https://arxiv.org/abs/2509.11285', 'abstract': "Incremental learning remains a critical challenge in machine learning, as models often struggle with catastrophic forgetting -the tendency to lose previously acquired knowledge when learning new information. These challenges are even more pronounced in resource-limited settings. Many existing Class Incremental Learning (CIL) methods achieve high accuracy by continually adapting their feature representations; however, they often require substantial computational resources and complex, iterative training procedures. This work introduces CIFNet (Class Incremental and Frugal Network), a novel CIL approach that addresses these limitations by offering a highly efficient and sustainable solution. CIFNet's key innovation lies in its novel integration of several existing, yet separately explored, components: a pre-trained and frozen feature extractor, a compressed data buffer, and an efficient non-iterative one-layer neural network for classification. A pre-trained and frozen feature extractor eliminates computationally expensive fine-tuning of the backbone. This, combined with a compressed buffer for efficient memory use, enables CIFNet to perform efficient class-incremental learning through a single-step optimization process on fixed features, minimizing computational overhead and training time without requiring multiple weight updates. Experiments on benchmark datasets confirm that CIFNet effectively mitigates catastrophic forgetting at the classifier level, achieving high accuracy comparable to that of existing state-of-the-art methods, while substantially improving training efficiency and sustainability. CIFNet represents a significant advancement in making class-incremental learning more accessible and pragmatic in environments with limited resources, especially when strong pre-trained feature extractors are available.", 'abstract_zh': '增量学习仍然是机器学习中的一个关键挑战，模型往往挣扎于灾难性遗忘——在学习新信息时失去之前获取的知识的倾向。这些挑战在资源受限的环境中尤为突出。许多现有的类增量学习（CIL）方法通过不断调整其特征表示来实现高精度，但它们通常需要大量的计算资源和复杂的迭代培训过程。本文引入了CIFNet（类增量和节俭网络），这是一种新颖的CIL方法，通过提供高效且可持续的解决方案来解决这些限制。CIFNet的关键创新在于其新颖地整合了几种现有但独立探索的组件：预训练并冻结的特征提取器、压缩数据缓冲区以及用于分类的高效单层神经网络。预训练并冻结的特征提取器消除了对骨干进行昂贵微调的需求。结合高效的压缩缓冲区以实现内存高效使用，CIFNet能够通过固定特征的一步优化过程实现高效的类增量学习，从而最小化计算开销和培训时间，而无需多轮权重更新。基准数据集上的实验证实，CIFNet在分类器层面有效缓解了灾难性遗忘的问题，实现了与现有先进方法相当的高精度，同时显著提高了培训效率和可持续性。CIFNet代表了在资源受限环境下使类增量学习更具可行性和实际应用的重大进展，尤其是在强预训练特征提取器可用的情况下。', 'title_zh': '高效的一步增量类学习框架在神经网络中'}
{'arxiv_id': 'arXiv:2509.11270', 'title': 'Embodied Intelligence in Disassembly: Multimodal Perception Cross-validation and Continual Learning in Neuro-Symbolic TAMP', 'authors': 'Ziwen He, Zhigang Wang, Yanlong Peng, Pengxu Chang, Hong Yang, Ming Chen', 'link': 'https://arxiv.org/abs/2509.11270', 'abstract': 'With the rapid development of the new energy vehicle industry, the efficient disassembly and recycling of power batteries have become a critical challenge for the circular economy. In current unstructured disassembly scenarios, the dynamic nature of the environment severely limits the robustness of robotic perception, posing a significant barrier to autonomous disassembly in industrial applications. This paper proposes a continual learning framework based on Neuro-Symbolic task and motion planning (TAMP) to enhance the adaptability of embodied intelligence systems in dynamic environments. Our approach integrates a multimodal perception cross-validation mechanism into a bidirectional reasoning flow: the forward working flow dynamically refines and optimizes action strategies, while the backward learning flow autonomously collects effective data from historical task executions to facilitate continual system learning, enabling self-optimization. Experimental results show that the proposed framework improves the task success rate in dynamic disassembly scenarios from 81.68% to 100%, while reducing the average number of perception misjudgments from 3.389 to 1.128. This research provides a new paradigm for enhancing the robustness and adaptability of embodied intelligence in complex industrial environments.', 'abstract_zh': '基于神经符号任务与动作规划的持续学习框架：提升动态环境下单体智能系统的适应性', 'title_zh': 'embodied 智能在拆卸中的应用：神经符号TAMP的多模态感知交叉验证与持续学习'}
{'arxiv_id': 'arXiv:2509.11259', 'title': 'Gradient Free Deep Reinforcement Learning With TabPFN', 'authors': 'David Schiff, Ofir Lindenbaum, Yonathan Efroni', 'link': 'https://arxiv.org/abs/2509.11259', 'abstract': "Gradient based optimization is fundamental to most modern deep reinforcement learning algorithms, however, it introduces significant sensitivity to hyperparameters, unstable training dynamics, and high computational costs. We propose TabPFN RL, a novel gradient free deep RL framework that repurposes the meta trained transformer TabPFN as a Q function approximator. Originally developed for tabular classification, TabPFN is a transformer pre trained on millions of synthetic datasets to perform inference on new unseen datasets via in context learning. Given an in context dataset of sample label pairs and new unlabeled data, it predicts the most likely labels in a single forward pass, without gradient updates or task specific fine tuning. We use TabPFN to predict Q values using inference only, thereby eliminating the need for back propagation at both training and inference. To cope with the model's fixed context budget, we design a high reward episode gate that retains only the top 5% of trajectories. Empirical evaluations on the Gymnasium classic control suite demonstrate that TabPFN RL matches or surpasses Deep Q Network on CartPole v1, MountainCar v0, and Acrobot v1, without applying gradient descent or any extensive hyperparameter tuning. We discuss the theoretical aspects of how bootstrapped targets and non stationary visitation distributions violate the independence assumptions encoded in TabPFN's prior, yet the model retains a surprising generalization capacity. We further formalize the intrinsic context size limit of in context RL algorithms and propose principled truncation strategies that enable continual learning when the context is full. Our results establish prior fitted networks such as TabPFN as a viable foundation for fast and computationally efficient RL, opening new directions for gradient free RL with large pre trained transformers.", 'abstract_zh': '基于梯度的优化是大多数现代深度强化学习算法的基础，然而它引入了对超参数的高度敏感性、不稳定的训练动态和高昂的计算成本。我们提出了TabPFN RL，一种新的无梯度深度强化学习框架，利用元训练变压器TabPFN作为Q函数近似器。TabPFN最初用于表格分类，它是在数百万个合成数据集上预训练的变压器，通过上下文学习进行新未见数据集的推理。给定一个包含样本标签对的上下文数据集和新的未标记数据，它可以在一次前向传递中预测最可能的标签，而不需要梯度更新或任务特定的微调。我们仅使用TabPFN进行推理来预测Q值，从而在训练和推理时都消除了后向传播的需要。为应对模型固定的上下文预算，我们设计了一个高奖励时间步门控机制，仅保留最顶级的5%的轨迹。在Gymnasium经典控制任务集上的实验评估表明，TabPFN RL 在CartPole v1、MountainCar v0 和 Acrobot v1 上的性能与深度Q网络相当或超越，无需应用梯度下降或任何广泛的超参数调整。我们讨论了采用自助目标和非稳定访问分布如何违反TabPFN先验中编码的独立性假设，尽管模型保留了令人惊讶的泛化能力。我们进一步形式化了上下文强化学习算法固有的上下文大小限制，并提出了原则性的截断策略，以在上下文充满时实现持续学习。我们的结果确立了先验拟合网络（如TabPFN）作为快速和计算高效的RL的基础，并为使用大型预训练变压器进行无梯度RL开辟了新方向。', 'title_zh': '无需推理直接输出：\n\nGradient Free Deep Reinforcement Learning With TabPFN'}
{'arxiv_id': 'arXiv:2509.11252', 'title': 'Beyond Autoregression: An Empirical Study of Diffusion Large Language Models for Code Generation', 'authors': 'Chengze li, Yitong Zhang, Jia Li, Liyi Cai, Ge Li', 'link': 'https://arxiv.org/abs/2509.11252', 'abstract': 'LLMs have become the mainstream approaches to code generation. Existing LLMs mainly employ autoregressive generation, i.e. generating code token-by-token from left to right. However, the underlying autoregressive generation has two limitations in code generation. First, autoregressive LLMs only generate a token at each step, showing low efficiency in practice. Second, programming is a non-sequential process involving back-and-forth editing, while autoregressive LLMs only employ the left-to-right generation order. These two intrinsic limitations hinder the further development of LLMs in code generation. Recently, diffusion LLMs have emerged as a promising alternative. Diffusion LLMs address the above limitations with two advances, including multi-token prediction (i.e. generating multiple tokens at each step) and flexible generation order (i.e. flexibly determining which positions to generate tokens). However, there is no systematic study exploring diffusion LLMs in code generation. To bridge the knowledge gap, we present the first empirical study of diffusion LLMs for code generation. Our study involves 9 representative diffusion LLMs and conduct experiments on 4 widely used benchmarks. Based on the results, we summarize the following findings. (1) Existing diffusion LLMs are competitive with autoregressive LLMs with similar sizes. (2) Diffusion LLMs have a stronger length extrapolation ability than autoregressive LLMs and perform better in long code understanding. (3) We explore factors impacting the effectiveness and efficiency of diffusion LLMs, and provide practical guidance. (4) We discuss several promising further directions to improve diffusion LLMs on code generation. We open-source all source code, data, and results to facilitate the following research. The code is publicly available at this https URL.', 'abstract_zh': '大规模语言模型已成为代码生成的主要方法。现有的大规模语言模型主要采用自回归生成，即从左到右逐个生成代码token。然而，自回归生成在代码生成中存在两个局限性。首先，自回归LSTM在每一步只能生成一个token，表现出较低的效率。其次，编程是一个非顺序过程，涉及来回编辑，而自回归LSTM仅采用从左到右的生成顺序。这些内在局限性阻碍了LSTM在代码生成中的进一步发展。最近，扩散型LSTM作为有前途的替代方案出现。扩散型LSTM通过多token预测（即在每一步生成多个token）和灵活的生成顺序（即灵活确定生成位置）来解决上述局限性。然而，尚未有系统研究探讨扩散型LSTM在代码生成中的应用。为了填补这一知识空白，我们首次开展了关于扩散型LSTM在代码生成中的实证研究。我们的研究涉及9个代表性扩散型LSTM，并在4个广泛使用的基准上进行了实验。基于实验结果，我们总结了以下发现：（1）现有的扩散型LSTM在与类似规模的自回归LSTM竞争中表现出色；（2）扩散型LSTM在长度外推能力和长代码理解方面优于自回归LSTM；（3）我们探索了影响扩散型LSTM有效性和效率的因素，并提供了实用指导；（4）我们讨论了几条有前景的研究方向，以提升扩散型LSTM在代码生成中的表现。我们将所有源代码、数据和结果开源，以促进后续研究。相关代码可以在以下链接获取。', 'title_zh': '超越自回归：关于扩散大语言模型在代码生成中的实证研究'}
{'arxiv_id': 'arXiv:2509.11233', 'title': 'TransZero: Parallel Tree Expansion in MuZero using Transformer Networks', 'authors': 'Emil Malmsten, Wendelin Böhmer', 'link': 'https://arxiv.org/abs/2509.11233', 'abstract': 'We present TransZero, a model-based reinforcement learning algorithm that removes the sequential bottleneck in Monte Carlo Tree Search (MCTS). Unlike MuZero, which constructs its search tree step by step using a recurrent dynamics model, TransZero employs a transformer-based network to generate multiple latent future states simultaneously. Combined with the Mean-Variance Constrained (MVC) evaluator that eliminates dependence on inherently sequential visitation counts, our approach enables the parallel expansion of entire subtrees during planning. Experiments in MiniGrid and LunarLander show that TransZero achieves up to an eleven-fold speedup in wall-clock time compared to MuZero while maintaining sample efficiency. These results demonstrate that parallel tree construction can substantially accelerate model-based reinforcement learning, bringing real-time decision-making in complex environments closer to practice. The code is publicly available on GitHub.', 'abstract_zh': '基于模型的 reinforcement 学习算法 TransZero：去除蒙特卡洛树搜索中的序列瓶颈', 'title_zh': 'TransZero: 使用Transformer网络的MuZero中的并行树扩展'}
{'arxiv_id': 'arXiv:2509.11232', 'title': 'MIS-LSTM: Multichannel Image-Sequence LSTM for Sleep Quality and Stress Prediction', 'authors': 'Seongwan Park, Jieun Woo, Siheon Yang', 'link': 'https://arxiv.org/abs/2509.11232', 'abstract': 'This paper presents MIS-LSTM, a hybrid framework that joins CNN encoders with an LSTM sequence model for sleep quality and stress prediction at the day level from multimodal lifelog data. Continuous sensor streams are first partitioned into N-hour blocks and rendered as multi-channel images, while sparse discrete events are encoded with a dedicated 1D-CNN. A Convolutional Block Attention Module fuses the two modalities into refined block embeddings, which an LSTM then aggregates to capture long-range temporal dependencies. To further boost robustness, we introduce UALRE, an uncertainty-aware ensemble that overrides lowconfidence majority votes with high-confidence individual predictions. Experiments on the 2025 ETRI Lifelog Challenge dataset show that Our base MISLSTM achieves Macro-F1 0.615; with the UALRE ensemble, the score improves to 0.647, outperforming strong LSTM, 1D-CNN, and CNN baselines. Ablations confirm (i) the superiority of multi-channel over stacked-vertical imaging, (ii) the benefit of a 4-hour block granularity, and (iii) the efficacy of modality-specific discrete encoding.', 'abstract_zh': '本文提出了一种将CNN编码器与LSTM序列模型结合的混合框架MIS-LSTM，用于从多模态日志数据中按日预测睡眠质量和压力。连续传感器流被分割成N小时块并表示为多通道图像，稀疏离散事件则通过专用的1D-CNN进行编码。卷积块注意力模块将两种模态融合成精细的块嵌入，随后LSTM聚合这些嵌入以捕获长时序依赖关系。为了进一步增强鲁棒性，引入了UALRE（不确定性意识集成），它用高置信度的个体预测覆盖低置信度的多数投票。在2025 ETRI日志挑战数据集上的实验表明，我们的基线MISLSTM实现了宏F1分数0.615；加入UALRE集成后，分数提升到0.647，优于强大的LSTM、1D-CNN和CNN基线。消融实验确认了(i) 多通道优于堆叠垂直成像、(ii) 4小时块粒度的优势以及(iii) 模态特定离散编码的有效性。', 'title_zh': 'MIS-LSTM：多通道图像序列LSTM在睡眠质量与压力预测中的应用'}
{'arxiv_id': 'arXiv:2509.11225', 'title': 'MEMBOT: Memory-Based Robot in Intermittent POMDP', 'authors': 'Youzhi Liang, Eyan Noronha', 'link': 'https://arxiv.org/abs/2509.11225', 'abstract': 'Robotic systems deployed in real-world environments often operate under con- ditions of partial and often intermittent observability, where sensor inputs may be noisy, occluded, or entirely unavailable due to failures or environmental con- straints. Traditional reinforcement learning (RL) approaches that assume full state observability are ill-equipped for such challenges. In this work, we introduce MEMBOT, a modular memory-based architecture designed to address intermittent partial observability in robotic control tasks. MEMBOT decouples belief inference from policy learning through a two-phase training process: an offline multi-task learning pretraining stage that learns a robust task-agnostic latent belief encoder using a reconstruction losses, followed by fine-tuning of task-specific policies using behavior cloning. The belief encoder, implemented as a state-space model (SSM) and a LSTM, integrates temporal sequences of observations and actions to infer latent state representations that persist even when observations are dropped. We train and evaluate MEMBOT on 10 robotic manipulation benchmark tasks from MetaWorld and Robomimic under varying rates of observation dropout. Results show that MEMBOT consistently outperforms both memoryless and naively recur- rent baselines, maintaining up to 80% of peak performance under 50% observation availability. These findings highlight the effectiveness of explicit belief modeling in achieving robust, transferable, and data-efficient policies for real-world partially observable robotic systems.', 'abstract_zh': '基于记忆的模块化架构MEMBOT在部分可观测环境下的机器人控制任务中有效应对间歇性部分可观测性', 'title_zh': '基于记忆的间歇性部分可观马尔可夫决策过程机器人：MEMBOT'}
{'arxiv_id': 'arXiv:2509.11218', 'title': 'Geometrically Constrained and Token-Based Probabilistic Spatial Transformers', 'authors': 'Johann Schmidt, Sebastian Stober', 'link': 'https://arxiv.org/abs/2509.11218', 'abstract': 'Fine-grained visual classification (FGVC) remains highly sensitive to geometric variability, where objects appear under arbitrary orientations, scales, and perspective distortions. While equivariant architectures address this issue, they typically require substantial computational resources and restrict the hypothesis space. We revisit Spatial Transformer Networks (STNs) as a canonicalization tool for transformer-based vision pipelines, emphasizing their flexibility, backbone-agnostic nature, and lack of architectural constraints. We propose a probabilistic, component-wise extension that improves robustness. Specifically, we decompose affine transformations into rotation, scaling, and shearing, and regress each component under geometric constraints using a shared localization encoder. To capture uncertainty, we model each component with a Gaussian variational posterior and perform sampling-based canonicalization during inference.A novel component-wise alignment loss leverages augmentation parameters to guide spatial alignment. Experiments on challenging moth classification benchmarks demonstrate that our method consistently improves robustness compared to other STNs.', 'abstract_zh': '细粒度视觉分类（FGVC）仍高度敏感于几何变异，其中对象以任意方向、尺度和视角变形出现。虽然_equivariant_架构可以解决这一问题，但它们通常需要大量的计算资源并限制假设空间。我们重新审视Spatial Transformer Networks（STN）作为基于转换器的视觉管道的标准规范化工具，强调其灵活性、后端无关性和缺乏架构约束。我们提出了一种概率性的组件级扩展，以提高鲁棒性。具体而言，我们将仿射变换分解为旋转、缩放和剪切，并在几何约束下使用共享定位编码器回归每个组件。为了捕获不确定性，我们用高斯变分后验概率建模每个组件，并在推断过程中通过采样进行规范化。一种新颖的组件级对齐损失利用增强参数来引导空间对齐。在具有挑战性的蛾类分类基准测试中，我们的方法在鲁棒性方面始终优于其他STN。', 'title_zh': '几何约束和基于token的概率空间变换器'}
{'arxiv_id': 'arXiv:2509.11206', 'title': 'Evalet: Evaluating Large Language Models by Fragmenting Outputs into Functions', 'authors': 'Tae Soo Kim, Heechan Lee, Yoonjoo Lee, Joseph Seering, Juho Kim', 'link': 'https://arxiv.org/abs/2509.11206', 'abstract': 'Practitioners increasingly rely on Large Language Models (LLMs) to evaluate generative AI outputs through "LLM-as-a-Judge" approaches. However, these methods produce holistic scores that obscure which specific elements influenced the assessments. We propose functional fragmentation, a method that dissects each output into key fragments and interprets the rhetoric functions that each fragment serves relative to evaluation criteria -- surfacing the elements of interest and revealing how they fulfill or hinder user goals. We instantiate this approach in Evalet, an interactive system that visualizes fragment-level functions across many outputs to support inspection, rating, and comparison of evaluations. A user study (N=10) found that, while practitioners struggled to validate holistic scores, our approach helped them identify 48% more evaluation misalignments. This helped them calibrate trust in LLM evaluations and rely on them to find more actionable issues in model outputs. Our work shifts LLM evaluation from quantitative scores toward qualitative, fine-grained analysis of model behavior.', 'abstract_zh': '实践者日益依赖大型语言模型（LLMs）通过“LLM作为裁判”的方法来评估生成型AI的输出。然而，这些方法会生成整体评分，掩盖了哪些具体元素影响了评估结果。我们提出功能分解的方法，该方法将每个输出分解为关键片段，并解释每个片段相对于评估标准所发挥的修辞功能——揭示感兴趣的元素及其如何满足或阻碍用户目标。我们通过Evalet这一交互系统实例化了这一方法，该系统能够在多个输出中可视化片段级的功能，以支持评估的检查、评级和比较。用户研究（N=10）发现，尽管实践者难以验证整体评分，但我们的方法帮助他们识别出48%更多的评估偏差。这有助于他们校准对LLM评估的信任，并依赖它们发现更多可操作的问题。我们的工作将LLM评估从定量评分转向针对模型行为的细致定性分析。', 'title_zh': 'Evalet: 将输出分解为功能以评估大型语言模型'}
{'arxiv_id': 'arXiv:2509.11198', 'title': 'Quantum Architecture Search for Solving Quantum Machine Learning Tasks', 'authors': 'Michael Kölle, Simon Salfer, Tobias Rohe, Philipp Altmann, Claudia Linnhoff-Popien', 'link': 'https://arxiv.org/abs/2509.11198', 'abstract': "Quantum computing leverages quantum mechanics to address computational problems in ways that differ fundamentally from classical approaches. While current quantum hardware remains error-prone and limited in scale, Variational Quantum Circuits offer a noise-resilient framework suitable for today's devices. The performance of these circuits strongly depends on the underlying architecture of their parameterized quantum components. Identifying efficient, hardware-compatible quantum circuit architectures -- known as Quantum Architecture Search (QAS) -- is therefore essential. Manual QAS is complex and error-prone, motivating efforts to automate it. Among various automated strategies, Reinforcement Learning (RL) remains underexplored, particularly in Quantum Machine Learning contexts. This work introduces RL-QAS, a framework that applies RL to discover effective circuit architectures for classification tasks. We evaluate RL-QAS using the Iris and binary MNIST datasets. The agent autonomously discovers low-complexity circuit designs that achieve high test accuracy. Our results show that RL is a viable approach for automated architecture search in quantum machine learning. However, applying RL-QAS to more complex tasks will require further refinement of the search strategy and performance evaluation mechanisms.", 'abstract_zh': '量子计算利用量子力学以根本不同的方式解决计算问题，不同于经典方法。尽管当前的量子硬件仍然容易出错且规模有限，变异量子电路提供了适合当今设备的噪声鲁棒框架。这些电路的表现强烈依赖于它们的参数化量子组件的基础架构。因此，识别高效且硬件兼容的量子电路架构——称为量子架构搜索（QAS）——是至关重要的。手工进行QAS复杂且易出错，因此推动了自动化努力。在各种自动化策略中，强化学习（RL）在量子机器学习上下文中的应用尚属未竟之域。本文介绍了RL-QAS框架，该框架将RL应用于发现适用于分类任务的有效电路架构。我们使用鸢尾花和二进制MNIST数据集评估了RL-QAS。代理自主发现了低复杂度的电路设计，并实现了高测试准确性。我们的结果表明，RL是量子机器学习中自动化架构搜索的可行方法，但将RL-QAS应用于更复杂任务将需要进一步细化搜索策略和性能评估机制。', 'title_zh': '量子架构搜索用于解决量子机器学习任务'}
{'arxiv_id': 'arXiv:2509.11197', 'title': 'DreamNav: A Trajectory-Based Imaginative Framework for Zero-Shot Vision-and-Language Navigation', 'authors': 'Yunheng Wang, Yuetong Fang, Taowen Wang, Yixiao Feng, Yawen Tan, Shuning Zhang, Peiran Liu, Yiding Ji, Renjing Xu', 'link': 'https://arxiv.org/abs/2509.11197', 'abstract': 'Vision-and-Language Navigation in Continuous Environments (VLN-CE), which links language instructions to perception and control in the real world, is a core capability of embodied robots. Recently, large-scale pretrained foundation models have been leveraged as shared priors for perception, reasoning, and action, enabling zero-shot VLN without task-specific training. However, existing zero-shot VLN methods depend on costly perception and passive scene understanding, collapsing control to point-level choices. As a result, they are expensive to deploy, misaligned in action semantics, and short-sighted in planning. To address these issues, we present DreamNav that focuses on the following three aspects: (1) for reducing sensory cost, our EgoView Corrector aligns viewpoints and stabilizes egocentric perception; (2) instead of point-level actions, our Trajectory Predictor favors global trajectory-level planning to better align with instruction semantics; and (3) to enable anticipatory and long-horizon planning, we propose an Imagination Predictor to endow the agent with proactive thinking capability. On VLN-CE and real-world tests, DreamNav sets a new zero-shot state-of-the-art (SOTA), outperforming the strongest egocentric baseline with extra information by up to 7.49\\% and 18.15\\% in terms of SR and SPL metrics. To our knowledge, this is the first zero-shot VLN method to unify trajectory-level planning and active imagination while using only egocentric inputs.', 'abstract_zh': 'Vision-and-Language Navigation in Continuous Environments: DreamNav 集成轨迹级规划与主动想象的零样本视觉-语言导航', 'title_zh': 'DreamNav: 基于 trajectories 的想象框架，用于零样本视觉-语言导航'}
{'arxiv_id': 'arXiv:2509.11196', 'title': 'Federated Recommender System with Data Valuation for E-commerce Platform', 'authors': 'Jongwon Park, Minku Kang, Wooseok Sim, Soyoung Lee, Hogun Park', 'link': 'https://arxiv.org/abs/2509.11196', 'abstract': "Federated Learning (FL) is gaining prominence in machine learning as privacy concerns grow. This paradigm allows each client (e.g., an individual online store) to train a recommendation model locally while sharing only model updates, without exposing the raw interaction logs to a central server, thereby preserving privacy in a decentralized environment. Nonetheless, most existing FL-based recommender systems still rely solely on each client's private data, despite the abundance of publicly available datasets that could be leveraged to enrich local training; this potential remains largely underexplored. To this end, we consider a realistic scenario wherein a large shopping platform collaborates with multiple small online stores to build a global recommender system. The platform possesses global data, such as shareable user and item lists, while each store holds a portion of interaction data privately (or locally). Although integrating global data can help mitigate the limitations of sparse and biased clients' local data, it also introduces additional challenges: simply combining all global interactions can amplify noise and irrelevant patterns, worsening personalization and increasing computational costs. To address these challenges, we propose FedGDVE, which selectively augments each client's local graph with semantically aligned samples from the global dataset. FedGDVE employs: (i) a pre-trained graph encoder to extract global structural features, (ii) a local valid predictor to assess client-specific relevance, (iii) a reinforcement-learning-based probability estimator to filter and sample only the most pertinent global interactions. FedGDVE improves performance by up to 34.86% on recognized benchmarks in FL environments.", 'abstract_zh': '联邦学习（FL）在隐私担忧增加的情况下正逐渐成为机器学习领域的热点。这种范式允许每个客户端（例如，一个在线商店）在本地训练推荐模型，仅分享模型更新而不暴露原始交互日志，从而在分散的环境中保护隐私。然而，现有的大多数基于FL的推荐系统仍然仅依赖每个客户端的私有数据，尽管有大量的公开数据集可以利用以丰富本地训练，但这一潜力仍未得到充分开发。为此，我们考虑一种现实场景，大型购物平台与多个小型在线商店合作构建全球推荐系统。平台拥有全局数据，如可共享的用户和商品列表，而每个商店则私下持有部分交互数据。尽管整合全局数据可以帮助缓解客户端本地数据稀疏和偏差的限制，但也引入了新的挑战：简单地合并所有全局交互会放大噪声和不相关模式，恶化个性化并增加计算成本。为解决这些问题，我们提出FedGDVE，它选择性地将全局数据中语义对齐的样本补充到每个客户端的本地图中。FedGDVE采用：（i）预训练的图编码器提取全局结构特征，（ii）局部有效预测器评估特定于客户端的相关性，（iii）基于强化学习的概率估计器筛选和采样仅最相关的全局交互。在FL环境中，FedGDVE在已认可的基准测试中可实现高达34.86%的性能提升。', 'title_zh': '基于数据估值的联邦推荐系统在电子商务平台中应用'}
{'arxiv_id': 'arXiv:2509.11190', 'title': 'Investigating the Lottery Ticket Hypothesis for Variational Quantum Circuits', 'authors': 'Michael Kölle, Leonhard Klingert, Julian Schönberger, Philipp Altmann, Tobias Rohe, Claudia Linnhoff-Popien', 'link': 'https://arxiv.org/abs/2509.11190', 'abstract': "Quantum computing is an emerging field in computer science that has seen considerable progress in recent years, especially in machine learning. By harnessing the principles of quantum physics, it can surpass the limitations of classical algorithms. However, variational quantum circuits (VQCs), which rely on adjustable parameters, often face the barren plateau phenomenon, hindering optimization. The Lottery Ticket Hypothesis (LTH) is a recent concept in classical machine learning that has led to notable improvements in parameter efficiency for neural networks. It states that within a large network, a smaller, more efficient subnetwork, or ''winning ticket,'' can achieve comparable performance, potentially circumventing plateau challenges. In this work, we investigate whether this idea can apply to VQCs. We show that the weak LTH holds for VQCs, revealing winning tickets that retain just 26.0\\% of the original parameters. For the strong LTH, where a pruning mask is learned without any training, we discovered a winning ticket in a binary VQC, achieving 100\\% accuracy with only 45\\% of the weights. These findings indicate that LTH may mitigate barren plateaus by reducing parameter counts while preserving performance, thus enhancing the efficiency of VQCs in quantum machine learning tasks.", 'abstract_zh': '量子计算是一种新兴的计算机科学领域，在近年来取得了显著进展，尤其是在机器学习方面。通过利用量子物理的基本原理，它可以超越古典算法的限制。然而，依赖可调参数的变分量子电路（VQCs）往往面临 barren plateau 现象，阻碍了优化过程。经典机器学习中最近提出的彩票票 Hypothesis （LTH）概念，在神经网络的参数效率方面取得了显著改进。它表明，在一个大网络中，存在一个更小、更高效的子网络，即“获胜彩票”，可以实现 comparable 的性能，可能绕过 plateau 挑战。在这项工作中，我们研究了这一思想能否应用于 VQCs。我们证明弱 LTH 在 VQCs 中成立，揭示了一个保留了原参数 26.0% 的获胜彩票。在强 LTH 情况下，通过学习剪枝掩码而无需任何训练的情况下，我们发现了一个二进制 VQC 的获胜彩票，仅使用 45% 的权重实现了 100% 的准确率。这些发现表明，LTH 可能通过减少参数数量同时保持性能来缓解 barren plateaus，从而增强 VQCs 在量子机器学习任务中的效率。', 'title_zh': '探索变分量子电路中的彩票票据假设'}
{'arxiv_id': 'arXiv:2509.11178', 'title': 'StegOT: Trade-offs in Steganography via Optimal Transport', 'authors': 'Chengde Lin, Xuezhu Gong, Shuxue Ding, Mingzhe Yang, Xijun Lu, Chengjun Mo', 'link': 'https://arxiv.org/abs/2509.11178', 'abstract': 'Image hiding is often referred to as steganography, which aims to hide a secret image in a cover image of the same resolution. Many steganography models are based on genera-tive adversarial networks (GANs) and variational autoencoders (VAEs). However, most existing models suffer from mode collapse. Mode collapse will lead to an information imbalance between the cover and secret images in the stego image and further affect the subsequent extraction. To address these challenges, this paper proposes StegOT, an autoencoder-based steganography model incorporating optimal transport theory. We designed the multiple channel optimal transport (MCOT) module to transform the feature distribution, which exhibits multiple peaks, into a single peak to achieve the trade-off of information. Experiments demonstrate that we not only achieve a trade-off between the cover and secret images but also enhance the quality of both the stego and recovery images. The source code will be released on this https URL.', 'abstract_zh': '基于最优运输理论的自编码器隐写模型StegOT', 'title_zh': 'StegOT：最优输运视角下的隐写术权衡'}
{'arxiv_id': 'arXiv:2509.11176', 'title': 'Differentially-private text generation degrades output language quality', 'authors': 'Erion Çano, Ivan Habernal', 'link': 'https://arxiv.org/abs/2509.11176', 'abstract': 'Ensuring user privacy by synthesizing data from large language models (LLMs) tuned under differential privacy (DP) has become popular recently. However, the impact of DP fine-tuned LLMs on the quality of the language and the utility of the texts they produce has not been investigated. In this work, we tune five LLMs with three corpora under four levels of privacy and assess the length, the grammatical correctness, and the lexical diversity of the text outputs they produce. We also probe the utility of the synthetic outputs in downstream classification tasks such as book genre recognition based on book descriptions and cause of death recognition based on verbal autopsies. The results indicate that LLMs tuned under stronger privacy constrains produce texts that are shorter by at least 77 %, that are less grammatically correct by at least 9 %, and are less diverse by at least 10 % in bi-gram diversity. Furthermore, the accuracy they reach in downstream classification tasks decreases, which might be detrimental to the usefulness of the generated synthetic data.', 'abstract_zh': '通过在差分隐私条件下调优大型语言模型（LLMs）合成数据以确保用户隐私，已成为近期的一种流行方法。然而，DP调优的LLMs对语言质量以及生成文本的实用性影响尚未进行研究。在本研究中，我们在四种隐私级别下使用三种语料库调优五个LLMs，并评估其生成文本的长度、语法正确性和词汇多样性。我们还探究了这些合成输出在图书体裁识别等下游分类任务（基于图书描述）和死亡原因识别等下游分类任务（基于口头尸检）中的实用性。结果显示，受更强隐私约束调优的LLMs生成的文本至少缩短了77%，语法正确性降低了至少9%，二元多样性降低了至少10%。此外，它们在下游分类任务中的准确率下降，这可能对生成的合成数据的实用性产生不利影响。', 'title_zh': '不同隐私保护下的文本生成降低输出语言质量'}
{'arxiv_id': 'arXiv:2509.11173', 'title': 'Your Compiler is Backdooring Your Model: Understanding and Exploiting Compilation Inconsistency Vulnerabilities in Deep Learning Compilers', 'authors': 'Simin Chen, Jinjun Peng, Yixin He, Junfeng Yang, Baishakhi Ray', 'link': 'https://arxiv.org/abs/2509.11173', 'abstract': "Deep learning (DL) compilers are core infrastructure in modern DL systems, offering flexibility and scalability beyond vendor-specific libraries. This work uncovers a fundamental vulnerability in their design: can an official, unmodified compiler alter a model's semantics during compilation and introduce hidden backdoors? We study both adversarial and natural settings. In the adversarial case, we craft benign models where triggers have no effect pre-compilation but become effective backdoors after compilation. Tested on six models, three commercial compilers, and two hardware platforms, our attack yields 100% success on triggered inputs while preserving normal accuracy and remaining undetected by state-of-the-art detectors. The attack generalizes across compilers, hardware, and floating-point settings. In the natural setting, we analyze the top 100 HuggingFace models (including one with 220M+ downloads) and find natural triggers in 31 models. This shows that compilers can introduce risks even without adversarial manipulation.\nOur results reveal an overlooked threat: unmodified DL compilers can silently alter model semantics. To our knowledge, this is the first work to expose inherent security risks in DL compiler design, opening a new direction for secure and trustworthy ML.", 'abstract_zh': '深度学习编译器设计中的根本性漏洞：无修改编译器是否能在编译过程中悄无声息地改变模型 semantics 并引入隐藏后门？', 'title_zh': '你的编译器在后门你的模型：理解并利用深度学习编译器中的编译一致性漏洞'}
{'arxiv_id': 'arXiv:2509.11168', 'title': 'An Entropy-Guided Curriculum Learning Strategy for Data-Efficient Acoustic Scene Classification under Domain Shift', 'authors': 'Peihong Zhang, Yuxuan Liu, Zhixin Li, Rui Sang, Yiqiang Cai, Yizhou Tan, Shengchen Li', 'link': 'https://arxiv.org/abs/2509.11168', 'abstract': 'Acoustic Scene Classification (ASC) faces challenges in generalizing across recording devices, particularly when labeled data is limited. The DCASE 2024 Challenge Task 1 highlights this issue by requiring models to learn from small labeled subsets recorded on a few devices. These models need to then generalize to recordings from previously unseen devices under strict complexity constraints. While techniques such as data augmentation and the use of pre-trained models are well-established for improving model generalization, optimizing the training strategy represents a complementary yet less-explored path that introduces no additional architectural complexity or inference overhead. Among various training strategies, curriculum learning offers a promising paradigm by structuring the learning process from easier to harder examples. In this work, we propose an entropy-guided curriculum learning strategy to address the domain shift problem in data-efficient ASC. Specifically, we quantify the uncertainty of device domain predictions for each training sample by computing the Shannon entropy of the device posterior probabilities estimated by an auxiliary domain classifier. Using entropy as a proxy for domain invariance, the curriculum begins with high-entropy samples and gradually incorporates low-entropy, domain-specific ones to facilitate the learning of generalizable representations. Experimental results on multiple DCASE 2024 ASC baselines demonstrate that our strategy effectively mitigates domain shift, particularly under limited labeled data conditions. Our strategy is architecture-agnostic and introduces no additional inference cost, making it easily integrable into existing ASC baselines and offering a practical solution to domain shift.', 'abstract_zh': '声场景分类（ASC）在跨录音设备推广时面临挑战，尤其是当标注数据有限时。DCASE 2024 挑战任务 1 突出了这一问题，要求模型从少数设备记录的小标注子集中学到知识，并在严格复杂性约束下推广到未见过的设备的录音。虽然数据增强技术和预训练模型等方法已被证明可以提高模型的推广能力，但优化训练策略作为补充但仍较少探索的道路，且不增加额外的架构复杂度或推理开销。在各种训练策略中，分层学习提供了一种有前途的范式，通过从简单到复杂的示例逐步构建学习过程。在本文中，我们提出了一种基于熵的分层学习策略来解决数据高效ASC中的领域转移问题。具体而言，我们通过计算辅助领域分类器估计的设备后验概率的香农熵来量化每个训练样本的设备领域预测不确定性。利用熵作为领域不变性的代理，分层学习从高熵样本开始，并逐渐引入低熵、设备特定的样本，以促进学习到一般性表示。在多个DCASE 2024 ASC基线上进行的实验结果表明，我们的策略在标注数据有限的条件下有效缓解了领域转移问题。我们的策略对架构具有通用性，并且不引入额外的推理开销，易于集成到现有的ASC基线中，并提供了一种实用的领域转移解决方案。', 'title_zh': '基于熵引导的学习策略：在领域迁移下实现数据高效声场景分类'}
{'arxiv_id': 'arXiv:2509.11167', 'title': 'Harnessing Optimization Dynamics for Curvature-Informed Model Merging', 'authors': 'Pouria Mahdavinia, Hamed Mahdavi, Niloofar Mireshghallah, Mehrdad Mahdavi', 'link': 'https://arxiv.org/abs/2509.11167', 'abstract': "Model merging is an effective post-training strategy for composing capabilities in large language models without joint retraining. We study this in the supervised fine-tuning (SFT) stage, where multiple capability-based SFT checkpoints -- spanning math, code, precise instruction following, general instruction following, and knowledge recall -- must be consolidated into a single model. We introduce Optimization Trajectory Aware (OTA) Merging, a curvature-aware aggregation that leverages optimizer second-moment statistics as a diagonal curvature proxy to reweight parameter edits and mitigate interference. Complementing OTA, we propose Fast Fisher Grafting (FFG), a curvature-driven task-localization step that sparsifies conflicting or low-importance edits. FFG induces extremely low-rank masks concentrated in early attention query/key projections and token embeddings, exploiting shared curvature across capabilities. We further develop a memory-light compression of the second moments that preserves OTA's effect. Across diverse capability-based SFT checkpoints, OTA+FFG improves merged-model quality over strong weight-space baselines, reduces negative transfer, and remains robust across sparsity levels. Analyses reveal substantial curvature overlap between checkpoints, offering a novel lens on why simple linear merging can be effective in practice. Ablations confirm that FFG is critical for reducing task interference and that the compressed second moments retain the gains of the full formulation. To facilitate reproducibility, we open-source all code, training and evaluation scripts, visualization artifacts, and capability-specific SFT checkpoints at this https URL.", 'abstract_zh': '基于优化轨迹感知的模型合并：一种在大规模语言模型中不进行联合重新训练的情况下组合能力的有效后训练策略', 'title_zh': '基于优化动力学的曲率导向模型融合'}
{'arxiv_id': 'arXiv:2509.11155', 'title': 'AQUA: Attention via QUery mAgnitudes for Memory and Compute Efficient Inference in LLMs', 'authors': 'Santhosh G S, Saurav Prakash, Balaraman Ravindran', 'link': 'https://arxiv.org/abs/2509.11155', 'abstract': "The quadratic complexity of the attention mechanism remains a fundamental barrier to scaling Large Language Models (LLMs) to longer contexts, creating a critical bottleneck in both computation and memory. To address this, we introduce AQUA (Attention via QUery mAgnitudes) a novel and versatile approximation strategy that significantly reduces the cost of attention with a graceful performance trade-off. Our method operates in two phases: an efficient offline step where we compute a universal, language agnostic projection matrix via SVD on a calibration dataset, and an online inference step where we project query and key vectors and dynamically select a sparse subset of dimensions based on the query's magnitude. We provide a formal theoretical analysis of AQUA, establishing the break-even point at which it becomes more computationally efficient than standard attention. Our empirical evaluations on state-of-the-art models like Llama-3.1-8B demonstrate that a 25% reduction in the attention dot-product computation can be achieved with a statistically insignificant impact on performance across a wide range of benchmarks. We further showcase the versatility of AQUA by demonstrating its ability to synergistically accelerate existing token eviction methods like H2O and to directly reduce KV-cache memory size. By offering a controllable knob to balance efficiency and accuracy, AQUA provides a practical and powerful tool for making large-scale LLM inference more accessible and sustainable.", 'abstract_zh': 'AQUA：基于查询幅度的注意力机制近似策略', 'title_zh': 'AQUA：基于查询幅度的注意力机制以实现LLMs的内存和计算效率推理'}
{'arxiv_id': 'arXiv:2509.11154', 'title': 'Feature Space Topology Control via Hopkins Loss', 'authors': 'Einari Vaaras, Manu Airaksinen', 'link': 'https://arxiv.org/abs/2509.11154', 'abstract': 'Feature space topology refers to the organization of samples within the feature space. Modifying this topology can be beneficial in machine learning applications, including dimensionality reduction, generative modeling, transfer learning, and robustness to adversarial attacks. This paper introduces a novel loss function, Hopkins loss, which leverages the Hopkins statistic to enforce a desired feature space topology, which is in contrast to existing topology-related methods that aim to preserve input feature topology. We evaluate the effectiveness of Hopkins loss on speech, text, and image data in two scenarios: classification and dimensionality reduction using nonlinear bottleneck autoencoders. Our experiments show that integrating Hopkins loss into classification or dimensionality reduction has only a small impact on classification performance while providing the benefit of modifying feature topology.', 'abstract_zh': '特征空间拓扑结构是指特征空间内样本的组织方式。修改这一拓扑结构在机器学习应用中包括降维、生成模型、迁移学习和对抗攻击鲁棒性等方面都是有益的。本文介绍了一种新的损失函数——霍普金斯损失，它利用霍普金斯统计量来强制执行期望的特征空间拓扑结构，而现有的拓扑相关方法则旨在保留输入特征拓扑结构。我们在语音、文本和图像数据中分别在分类和使用非线性瓶颈自动编码器的降维两种场景下评估了霍普金斯损失的有效性。实验结果显示，在分类中集成霍普金斯损失对分类性能的影响很小，而能够提供修改特征拓扑结构的好处。', 'title_zh': '基于Hopkins损失的空间特征拓扑控制'}
{'arxiv_id': 'arXiv:2509.11149', 'title': 'RoVerFly: Robust and Versatile Learning-based Control of Quadrotor Across Payload Configurations', 'authors': 'Mintae Kim, Jiaze Cai, Koushil Sreenath', 'link': 'https://arxiv.org/abs/2509.11149', 'abstract': 'Designing robust controllers for precise, arbitrary trajectory tracking with quadrotors is challenging due to nonlinear dynamics and underactuation, and becomes harder with flexible cable-suspended payloads that introduce extra degrees of freedom and hybridness. Classical model-based methods offer stability guarantees but require extensive tuning and often do not adapt when the configuration changes, such as when a payload is added or removed, or when the payload mass or cable length varies. We present RoVerFly, a unified learning-based control framework in which a reinforcement learning (RL) policy serves as a robust and versatile tracking controller for standard quadrotors and for cable-suspended payload systems across a range of configurations. Trained with task and domain randomization, the controller is resilient to disturbances and varying dynamics. It achieves strong zero-shot generalization across payload settings, including no payload as well as varying mass and cable length, without controller switching or re-tuning, while retaining the interpretability and structure of a feedback tracking controller. Code and supplementary materials are available at this https URL', 'abstract_zh': '基于强化学习的设计用于鲁棒精确和任意轨迹跟踪的旋翼无人机及其柔性电缆悬挂载荷控制框架', 'title_zh': 'RoVerFly：适用于不同载荷配置的四旋翼无人机稳健且多功能的学习控制'}
{'arxiv_id': 'arXiv:2509.11136', 'title': 'Agentic Username Suggestion and Multimodal Gender Detection in Online Platforms: Introducing the PNGT-26K Dataset', 'authors': 'Farbod Bijary, Mohsen Ebadpour, Amirhosein Tajbakhsh', 'link': 'https://arxiv.org/abs/2509.11136', 'abstract': "Persian names present unique challenges for natural language processing applications, particularly in gender detection and digital identity creation, due to transliteration inconsistencies and cultural- specific naming patterns. Existing tools exhibit significant performance degradation on Persian names, while the scarcity of comprehensive datasets further compounds these limitations. To address these challenges, the present research introduces PNGT-26K, a comprehensive dataset of Persian names, their commonly associated gender, and their English transliteration, consisting of approximately 26,000 tuples. As a demonstration of how this resource can be utilized, we also introduce two frameworks, namely Open Gender Detection and Nominalist. Open Gender Detection is a production- grade, ready-to-use framework for using existing data from a user, such as profile photo and name, to give a probabilistic guess about the person's gender. Nominalist, the second framework introduced by this paper, utilizes agentic AI to help users choose a username for their social media accounts on any platform. It can be easily integrated into any website to provide a better user experience. The PNGT-26K dataset, Nominalist and Open Gender Detection frameworks are publicly available on Github.", 'abstract_zh': '波斯名字在自然语言处理应用中存在独特挑战，特别是在性别检测和数字身份创建方面，由于转写不一致和文化特定的命名模式。现有工具在处理波斯名字时表现出显著性能下降，而全面数据集的稀缺进一步加剧了这些限制。为应对这些挑战，本研究引入了PNGT-26K数据集，该数据集包含波斯名字及其常见的性别和英语转写，共计约26,000个条目。作为该资源的应用示范，我们还引入了两个框架：Open Gender Detection和Nominalist。Open Gender Detection是一个生产级、即用型框架，可用于根据用户的数据（如头像和名字）给出关于性别的人概率性猜测。Nominalist是本文引入的第二个框架，利用代理AI帮助用户为社交媒体账号选择用户名，可以轻松集成到任何网站中以提供更好的用户体验。PNGT-26K数据集、Nominalist和Open Gender Detection框架现已在Github上公开。', 'title_zh': '代理用户名建议与多模态性别检测：PNGT-26K数据集介绍'}
{'arxiv_id': 'arXiv:2509.11128', 'title': 'ENJ: Optimizing Noise with Genetic Algorithms to Jailbreak LSMs', 'authors': 'Yibo Zhang, Liang Lin', 'link': 'https://arxiv.org/abs/2509.11128', 'abstract': "The widespread application of Large Speech Models (LSMs) has made their security risks increasingly prominent. Traditional speech adversarial attack methods face challenges in balancing effectiveness and stealth. This paper proposes Evolutionary Noise Jailbreak (ENJ), which utilizes a genetic algorithm to transform environmental noise from a passive interference into an actively optimizable attack carrier for jailbreaking LSMs. Through operations such as population initialization, crossover fusion, and probabilistic mutation, this method iteratively evolves a series of audio samples that fuse malicious instructions with background noise. These samples sound like harmless noise to humans but can induce the model to parse and execute harmful commands. Extensive experiments on multiple mainstream speech models show that ENJ's attack effectiveness is significantly superior to existing baseline methods. This research reveals the dual role of noise in speech security and provides new critical insights for model security defense in complex acoustic environments.", 'abstract_zh': '大规模语音模型的安全风险日益突出，传统的语音对抗攻击方法在有效性与隐蔽性之间面临挑战。本文提出了一种演化噪声越狱（ENJ）方法，利用遗传算法将环境噪声从被动干扰转变为可以主动优化的攻击载体，以实现对大规模语音模型（LSMs）的越狱攻击。通过种群初始化、交叉融合及概率变异等操作，该方法迭代演化出一系列将恶意指令与背景噪声融合的音频样本，这些样本对人类听觉无害，但能使模型解析并执行有害命令。对多个主流语音模型的广泛实验表明，ENJ的攻击效果显著优于现有基线方法。该研究揭示了噪声在语音安全中的双重角色，并为复杂 acoustic 环境下的模型安全防御提供了新的关键见解。', 'title_zh': 'ENJ: 使用遗传算法优化噪音以突破LSMs'}
{'arxiv_id': 'arXiv:2509.11118', 'title': 'We Argue to Agree: Towards Personality-Driven Argumentation-Based Negotiation Dialogue Systems for Tourism', 'authors': 'Priyanshu Priya, Saurav Dudhate, Desai Vishesh Yasheshbhai, Asif Ekbal', 'link': 'https://arxiv.org/abs/2509.11118', 'abstract': "Integrating argumentation mechanisms into negotiation dialogue systems improves conflict resolution through exchanges of arguments and critiques. Moreover, incorporating personality attributes enhances adaptability by aligning interactions with individuals' preferences and styles. To advance these capabilities in negotiation dialogue systems, we propose a novel Personality-driven Argumentation-based Negotiation Dialogue Generation (PAN-DG) task. To support this task, we introduce PACT, a dataset of Personality-driven Argumentation-based negotiation Conversations for Tourism sector. This dataset, generated using Large Language Models (LLMs), features three distinct personality profiles, viz. Argumentation Profile, Preference Profile, and Buying Style Profile to simulate a variety of negotiation scenarios involving diverse personalities. Thorough automatic and manual evaluations indicate that the dataset comprises high-quality dialogues. Further, we conduct comparative experiments between pre-trained and fine-tuned LLMs for the PAN-DG task. Multi-dimensional evaluation demonstrates that the fine-tuned LLMs effectively generate personality-driven rational responses during negotiations. This underscores the effectiveness of PACT in enhancing personalization and reasoning capabilities in negotiation dialogue systems, thereby establishing a foundation for future research in this domain.", 'abstract_zh': '将论辩机制集成到谈判对话系统中可通过论辩和批评的交换来改善冲突解决。此外，融入个性特质可增强系统的适应性，使其交互与个人的偏好和风格相契合。为推进谈判对话系统的这些能力，我们提出了一项新的基于个性的论辩驱动谈判对话生成（PAN-DG）任务。为了支持该任务，我们引入了PACT数据集，这是一个针对旅游行业的基于个性的论辩驱动谈判对话数据集。该数据集使用大型语言模型（LLMs）生成，包含了三种不同的个性特征配置文件，即论辩配置文件、偏好配置文件和购买风格配置文件，以模拟涉及各种个性的多种谈判场景。详尽的自动和手动评估表明，该数据集包含高质量的对话。此外，我们还开展了针对PAN-DG任务的预训练和微调大型语言模型的对比实验。多维度评估表明，微调后的大型语言模型能够有效地生成基于个性的理性响应，在谈判过程中增强了个性化和推理能力。这突显了PACT在提高谈判对话系统中的个性化和推理能力方面的作用，为该领域未来的研究奠定了基础。', 'title_zh': '我们argue以达成共识：面向旅游领域个性驱动的 argumentation 基础谈判对话系统'}
{'arxiv_id': 'arXiv:2509.11113', 'title': 'Application of Machine Learning for Correcting Defect-induced Neuromorphic Circuit Inference Errors', 'authors': 'Vedant Sawal, Hiu Yung Wong', 'link': 'https://arxiv.org/abs/2509.11113', 'abstract': "This paper presents a machine learning-based approach to correct inference errors caused by stuck-at faults in fully analog ReRAM-based neuromorphic circuits. Using a Design-Technology Co-Optimization (DTCO) simulation framework, we model and analyze six spatial defect types-circular, circular-complement, ring, row, column, and checkerboard-across multiple layers of a multi-array neuromorphic architecture. We demonstrate that the proposed correction method, which employs a lightweight neural network trained on the circuit's output voltages, can recover up to 35% (from 55% to 90%) inference accuracy loss in defective scenarios. Our results, based on handwritten digit recognition tasks, show that even small corrective networks can significantly improve circuit robustness. This method offers a scalable and energy-efficient path toward enhanced yield and reliability for neuromorphic systems in edge and internet-of-things (IoTs) applications. In addition to correcting the specific defect types used during training, our method also demonstrates the ability to generalize-achieving reasonable accuracy when tested on different types of defects not seen during training. The framework can be readily extended to support real-time adaptive learning, enabling on-chip correction for dynamic or aging-induced fault profiles.", 'abstract_zh': '基于机器学习的修正方法用于纠正全模拟ReRAM神经形态电路中由固定节点故障引起的推理错误', 'title_zh': '基于机器学习的缺陷诱导神经形态电路推理错误校正应用'}
{'arxiv_id': 'arXiv:2509.11112', 'title': 'Multi-Modal Sensing Aided mmWave Beamforming for V2V Communications with Transformers', 'authors': 'Muhammad Baqer Mollah, Honggang Wang, Hua Fang', 'link': 'https://arxiv.org/abs/2509.11112', 'abstract': 'Beamforming techniques are utilized in millimeter wave (mmWave) communication to address the inherent path loss limitation, thereby establishing and maintaining reliable connections. However, adopting standard defined beamforming approach in highly dynamic vehicular environments often incurs high beam training overheads and reduces the available airtime for communications, which is mainly due to exchanging pilot signals and exhaustive beam measurements. To this end, we present a multi-modal sensing and fusion learning framework as a potential alternative solution to reduce such overheads. In this framework, we first extract the features individually from the visual and GPS coordinates sensing modalities by modality specific encoders, and subsequently fuse the multimodal features to obtain predicted top-k beams so that the best line-of-sight links can be proactively established. To show the generalizability of the proposed framework, we perform a comprehensive experiment in four different vehicle-to-vehicle (V2V) scenarios from real-world multi-modal sensing and communication dataset. From the experiment, we observe that the proposed framework achieves up to 77.58% accuracy on predicting top-15 beams correctly, outperforms single modalities, incurs roughly as low as 2.32 dB average power loss, and considerably reduces the beam searching space overheads by 76.56% for top-15 beams with respect to standard defined approach.', 'abstract_zh': '毫米波通信中多模态感知与融合学习框架用于减少波束训练开销', 'title_zh': '基于变压器的多模态感知辅助毫米波波束成型在车对车通信中'}
{'arxiv_id': 'arXiv:2509.11106', 'title': 'Fluid Language Model Benchmarking', 'authors': 'Valentin Hofmann, David Heineman, Ian Magnusson, Kyle Lo, Jesse Dodge, Maarten Sap, Pang Wei Koh, Chun Wang, Hannaneh Hajishirzi, Noah A. Smith', 'link': 'https://arxiv.org/abs/2509.11106', 'abstract': "Language model (LM) benchmarking faces several challenges: comprehensive evaluations are costly, benchmarks often fail to measure the intended capabilities, and evaluation quality can degrade due to labeling errors and benchmark saturation. Although various strategies have been proposed to mitigate these issues, they tend to address individual aspects in isolation, neglecting broader questions about overall evaluation quality. Here, we introduce Fluid Benchmarking, a new evaluation approach that advances LM benchmarking across multiple dimensions. Inspired by psychometrics, Fluid Benchmarking is based on the insight that the relative value of benchmark items depends on an LM's capability level, suggesting that evaluation should adapt to each LM. Methodologically, Fluid Benchmarking estimates an item response model based on existing LM evaluation results and uses the inferred quantities to select evaluation items dynamically, similar to computerized adaptive testing in education. In our experiments, we compare Fluid Benchmarking against the common practice of random item sampling as well as more sophisticated baselines, including alternative methods grounded in item response theory. We examine four dimensions -- efficiency, validity, variance, and saturation -- and find that Fluid Benchmarking achieves superior performance in all of them (e.g., higher validity and less variance on MMLU with fifty times fewer items). Our analysis shows that the two components of Fluid Benchmarking have distinct effects: item response theory, used to map performance into a latent ability space, increases validity, while dynamic item selection reduces variance. Overall, our results suggest that LM benchmarking can be substantially improved by moving beyond static evaluation.", 'abstract_zh': '语言模型（LM）基准测试面临多重挑战：全面评估成本高昂，基准测试往往无法衡量预期的能力，且标注错误和基准饱和可能导致评估质量下降。尽管提出了一些策略来缓解这些问题，但这些策略往往孤立地解决单一问题，忽略了整体评估质量的更广泛问题。在此，我们介绍了流动基准测试（Fluid Benchmarking）这一新的评估方法，旨在从多个维度推进语言模型基准测试。受心理测量学启发，流动基准测试认为基准项目的相对价值取决于语言模型的能力水平，暗示评估应适应每个语言模型。方法上，流动基准测试基于现有语言模型评估结果估计项目反应模型，并利用推断出的量值动态选择评估项目，类似于教育中的计算机化自适应测试。在实验中，我们将流动基准测试与常见的随机项目抽样方法以及基于项目反应理论的更复杂的基线方法进行了比较。我们考察了四个维度——效率、信度、方差和饱和度，并发现流动基准测试在所有维度上均表现出更优的性能（例如，在MMLU上使用五十分之一的项目，信度更高，方差更小）。我们的分析表明，流动基准测试的两个组成部分具有不同的效果：项目反应理论用于将表现映射到潜在能力空间，提高了信度，而动态项目选择则减少了方差。总体而言，我们的结果表明，通过超越静态评估，可以显著改进语言模型基准测试。', 'title_zh': '流式语言模型基准测试'}
{'arxiv_id': 'arXiv:2509.11092', 'title': 'PanoLora: Bridging Perspective and Panoramic Video Generation with LoRA Adaptation', 'authors': 'Zeyu Dong, Yuyang Yin, Yuqi Li, Eric Li, Hao-Xiang Guo, Yikai Wang', 'link': 'https://arxiv.org/abs/2509.11092', 'abstract': 'Generating high-quality 360° panoramic videos remains a significant challenge due to the fundamental differences between panoramic and traditional perspective-view projections. While perspective videos rely on a single viewpoint with a limited field of view, panoramic content requires rendering the full surrounding environment, making it difficult for standard video generation models to adapt. Existing solutions often introduce complex architectures or large-scale training, leading to inefficiency and suboptimal results. Motivated by the success of Low-Rank Adaptation (LoRA) in style transfer tasks, we propose treating panoramic video generation as an adaptation problem from perspective views. Through theoretical analysis, we demonstrate that LoRA can effectively model the transformation between these projections when its rank exceeds the degrees of freedom in the task. Our approach efficiently fine-tunes a pretrained video diffusion model using only approximately 1,000 videos while achieving high-quality panoramic generation. Experimental results demonstrate that our method maintains proper projection geometry and surpasses previous state-of-the-art approaches in visual quality, left-right consistency, and motion diversity.', 'abstract_zh': '生成高质量的360°全景视频仍然是一个重大挑战，因为全景和传统视角投影之间存在根本差异。虽然传统视角视频依赖于单一视角和有限的视场，全景内容需要渲染整个环境，使得标准视频生成模型难以适应。现有解决方案往往引入复杂架构或大规模训练，导致效率低下且结果不佳。受Low-Rank Adaptation (LoRA)在风格转换任务中成功应用的启发，我们提出将全景视频生成视为从视角视图的适应问题。通过理论分析，我们证明当LoRA的秩超过任务自由度时，它可以有效地建模这两种投影之间的转换。我们的方法仅使用约1,000个视频对预训练的视频扩散模型进行高效微调，从而实现高質量的全景生成。实验结果表明，我们的方法保持了正确的投影几何结构，并在视觉质量、左右一致性以及运动多样性方面超越了先前的最佳方法。', 'title_zh': 'PanoLora：视角与全景视频生成的LoRA适应性桥梁'}
{'arxiv_id': 'arXiv:2509.11084', 'title': 'Length-Aware Rotary Position Embedding for Text-Speech Alignment', 'authors': 'Hyeongju Kim, Juheon Lee, Jinhyeok Yang, Jacob Morton', 'link': 'https://arxiv.org/abs/2509.11084', 'abstract': 'Many recent text-to-speech (TTS) systems are built on transformer architectures and employ cross-attention mechanisms for text-speech alignment. Within these systems, rotary position embedding (RoPE) is commonly used to encode positional information in text and speech representations. In this work, we introduce length-aware RoPE (LARoPE), a simple yet effective extension of RoPE that improves text-speech alignment. Unlike RoPE, which relies on absolute indices, LARoPE computes relative distances between query and key positions using length-normalized indices. Experimental results show that LARoPE consistently outperforms RoPE, offering faster loss convergence, more accurate text-speech alignment, and higher overall TTS quality. Furthermore, LARoPE demonstrates greater resilience to variations in utterance duration and maintains stable performance in extended speech generation up to 30 seconds, whereas RoPE suffers from notable degradation. Notably, our method achieves a state-of-the-art word error rate on a standard zero-shot TTS benchmark.', 'abstract_zh': '基于长度感知的旋转位置嵌入在文本到语音合成中的应用', 'title_zh': '基于长度感知的旋转位置嵌入文本-语音对齐'}
{'arxiv_id': 'arXiv:2509.11080', 'title': 'Membership Inference Attacks on Recommender System: A Survey', 'authors': 'Jiajie He, Yuechun Gu, Keke Chen, Xintong Chen', 'link': 'https://arxiv.org/abs/2509.11080', 'abstract': "Recommender systems (RecSys) have been widely applied to various applications, including E-commerce, finance, healthcare, social media and have become increasingly influential in shaping user behavior and decision-making, highlighting their growing impact in various domains. However, recent studies have shown that RecSys are vulnerable to membership inference attacks (MIAs), which aim to infer whether user interaction record was used to train a target model or not. MIAs on RecSys models can directly lead to a privacy breach. For example, via identifying the fact that a purchase record that has been used to train a RecSys associated with a specific user, an attacker can infer that user's special quirks. In recent years, MIAs have been shown to be effective on other ML tasks, e.g., classification models and natural language processing. However, traditional MIAs are ill-suited for RecSys due to the unseen posterior probability. Although MIAs on RecSys form a newly emerging and rapidly growing research area, there has been no systematic survey on this topic yet. In this article, we conduct the first comprehensive survey on RecSys MIAs. This survey offers a comprehensive review of the latest advancements in RecSys MIAs, exploring the design principles, challenges, attack and defense associated with this emerging field. We provide a unified taxonomy that categorizes different RecSys MIAs based on their characterizations and discuss their pros and cons. Based on the limitations and gaps identified in this survey, we point out several promising future research directions to inspire the researchers who wish to follow this area. This survey not only serves as a reference for the research community but also provides a clear description for researchers outside this research domain.", 'abstract_zh': '推荐系统（RecSys）已在电子商务、金融、医疗保健、社交媒体等领域广泛应用，并在塑造用户行为和决策方面越来越具有影响力，凸显了其在各个领域中的日益增长的影响。然而，近期研究显示，推荐系统（RecSys）容易受到会员推理攻击（Member Inference Attacks, MIAs）的影响，这种攻击试图推断用户交互记录是否被用于训练目标模型。MIAs会对RecSys模型直接导致隐私泄露。例如，通过识别某个用于训练与特定用户相关的推荐系统的购买记录，攻击者可以推断出用户的一些特殊偏好。近年来，MIAs已经被证明在其他机器学习任务中，如分类模型和自然语言处理任务中是有效的。然而，传统的MIAs并不适合RecSys，因为它们面临着未见后验概率的问题。尽管MIAs在RecSys领域的研究正在成为一个新兴且迅速增长的研究领域，但迄今为止尚未对此进行系统性的综述。在这篇文章中，我们首次对RecSys MIAs进行了全面的综述。本文综述涵盖了RecSys MIAs的最新进展，探讨了这一新兴领域的设计原则、挑战、攻击与防御。我们提供了一个统一的分类体系，基于特征对不同类型的RecSys MIAs进行分类，并讨论了它们各自的优缺点。基于综述中指出的局限性和空白，指出了几个值得进一步研究的方向，以激发对该领域感兴趣的学者。本文不仅为研究界提供了参考，也为该研究领域的外部研究人员提供了清晰的描述。', 'title_zh': '推荐系统中成员推理攻击：一篇综述'}
{'arxiv_id': 'arXiv:2509.11071', 'title': 'The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge', 'authors': 'Jinghan Peng, Jingwen Wang, Xing Yu, Dehui Du', 'link': 'https://arxiv.org/abs/2509.11071', 'abstract': 'This report outlines our approach using vision language model systems for the Driving with Language track of the CVPR 2024 Autonomous Grand Challenge. We have exclusively utilized the DriveLM-nuScenes dataset for training our models. Our systems are built on the LLaVA models, which we enhanced through fine-tuning with the LoRA and DoRA methods. Additionally, we have integrated depth information from open-source depth estimation models to enrich the training and inference processes. For inference, particularly with multiple-choice and yes/no questions, we adopted a Chain-of-Thought reasoning approach to improve the accuracy of the results. This comprehensive methodology enabled us to achieve a top score of 0.7799 on the validation set leaderboard, ranking 1st on the leaderboard.', 'abstract_zh': '本报告概述了我们使用视觉语言模型系统在CVPR 2024自主 grand 挑战Driving with Language赛道上的方法。我们仅使用DriveLM-nuScenes数据集对模型进行训练。系统基于LLaVA模型，并通过LoRA和DoRA方法进行微调。此外，我们还整合了开源深度估计模型的深度信息，以丰富训练和推理过程。在推理过程中，特别是对于多项选择和是/否问题，我们采用了链式推理方法以提高结果的准确性。这种综合方法使我们在验证集排行榜上获得了0.7799的最高分，位居榜首。', 'title_zh': 'CPS团队在CVPR 2024自主挑战赛中的轨道驾驶系统描述'}
{'arxiv_id': 'arXiv:2509.11053', 'title': 'An Advanced Convolutional Neural Network for Bearing Fault Diagnosis under Limited Data', 'authors': 'Shengke Sun, Shuzhen Han, Ziqian Luan, Xinghao Qin, Jiao Yin, Zhanshan Zhao, Jinli Cao, Hua Wang', 'link': 'https://arxiv.org/abs/2509.11053', 'abstract': 'In the area of bearing fault diagnosis, deep learning (DL) methods have been widely used recently. However, due to the high cost or privacy concerns, high-quality labeled data are scarce in real world scenarios. While few-shot learning has shown promise in addressing data scarcity, existing methods still face significant limitations in this domain. Traditional data augmentation techniques often suffer from mode collapse and generate low-quality samples that fail to capture the diversity of bearing fault patterns. Moreover, conventional convolutional neural networks (CNNs) with local receptive fields makes them inadequate for extracting global features from complex vibration signals. Additionally, existing methods fail to model the intricate relationships between limited training samples. To solve these problems, we propose an advanced data augmentation and contrastive fourier convolution framework (DAC-FCF) for bearing fault diagnosis under limited data. Firstly, a novel conditional consistent latent representation and reconstruction generative adversarial network (CCLR-GAN) is proposed to generate more diverse data. Secondly, a contrastive learning based joint optimization mechanism is utilized to better model the relations between the available training data. Finally, we propose a 1D fourier convolution neural network (1D-FCNN) to achieve a global-aware of the input data. Experiments demonstrate that DAC-FCF achieves significant improvements, outperforming baselines by up to 32\\% on case western reserve university (CWRU) dataset and 10\\% on a self-collected test bench. Extensive ablation experiments prove the effectiveness of the proposed components. Thus, the proposed DAC-FCF offers a promising solution for bearing fault diagnosis under limited data.', 'abstract_zh': '在轴承故障诊断领域，深度学习方法最近得到了广泛应用。然而，由于成本高或隐私问题，现实场景中高质量的标注数据稀缺。虽然少样本学习在解决数据稀缺性方面前景广阔，但现有方法在此领域仍面临诸多局限。传统数据增强技术常常遭受模式崩溃的问题，生成的样本质量较低，无法捕获轴承故障模式的多样性。此外，传统的具有局部感受野的卷积神经网络（CNN）对于提取复杂振动信号的全局特征不足。更重要的是，现有方法无法有效建模有限训练样本之间的复杂关系。为了解决这些问题，我们提出了一种先进的数据增强和对比傅里叶卷积框架（DAC-FCF）以应对有限数据下的轴承故障诊断。首先，提出了一种新颖的条件一致潜在表示和重建生成对抗网络（CCLR-GAN）以生成更多样化的数据。其次，利用基于对比学习的联合优化机制更好地建模可用训练数据之间的关系。最后，提出了一种1D傅里叶卷积神经网络（1D-FCNN）以实现对输入数据的整体感知。实验表明，DAC-FCF在Case Western Reserve University（CWRU）数据集和自收集测试台上的表现分别超过了基线32%和10%。大量消融实验证明了所提组件的有效性。因此，提出的DAC-FCF为有限数据下的轴承故障诊断提供了一个有前景的解决方案。', 'title_zh': '基于有限数据的先进卷积神经网络轴承故障诊断'}
{'arxiv_id': 'arXiv:2509.11044', 'title': 'FragmentGPT: A Unified GPT Model for Fragment Growing, Linking, and Merging in Molecular Design', 'authors': 'Xuefeng Liu, Songhao Jiang, Qinan Huang, Tinson Xu, Ian Foster, Mengdi Wang, Hening Lin, Jinbo Xu, Rick Stevens', 'link': 'https://arxiv.org/abs/2509.11044', 'abstract': 'Fragment-Based Drug Discovery (FBDD) is a popular approach in early drug development, but designing effective linkers to combine disconnected molecular fragments into chemically and pharmacologically viable candidates remains challenging. Further complexity arises when fragments contain structural redundancies, like duplicate rings, which cannot be addressed by simply adding or removing atoms or bonds. To address these challenges in a unified framework, we introduce FragmentGPT, which integrates two core components: (1) a novel chemically-aware, energy-based bond cleavage pre-training strategy that equips the GPT-based model with fragment growing, linking, and merging capabilities, and (2) a novel Reward Ranked Alignment with Expert Exploration (RAE) algorithm that combines expert imitation learning for diversity enhancement, data selection and augmentation for Pareto and composite score optimality, and Supervised Fine-Tuning (SFT) to align the learner policy with multi-objective goals. Conditioned on fragment pairs, FragmentGPT generates linkers that connect diverse molecular subunits while simultaneously optimizing for multiple pharmaceutical goals. It also learns to resolve structural redundancies-such as duplicated fragments-through intelligent merging, enabling the synthesis of optimized molecules. FragmentGPT facilitates controlled, goal-driven molecular assembly. Experiments and ablation studies on real-world cancer datasets demonstrate its ability to generate chemically valid, high-quality molecules tailored for downstream drug discovery tasks.', 'abstract_zh': '基于片段的药物发现（FBDD）是早期药物开发中的一个流行方法，但设计有效的连接剂以将不相连的分子片段组合成化学上和药理上可行的候选药物仍然是一个挑战。当片段包含结构冗余，如重复环时，仅通过添加或移除原子或键无法解决问题，这进一步增加了复杂性。为了解决这些挑战，我们引入了FragmentGPT，它包含两个核心组件：（1）一种新的化学感知的能量基础键断裂预训练策略，使基于GPT的模型具备片段生长、连接和合并的能力；（2）一种新的基于专家探索的奖励排名对齐（RAE）算法，该算法结合了专家模拟学习以增强多样性，数据选择和扩充以优化帕累托和复合评分，以及监督微调（SFT）以使学习策略与多目标目标相一致。基于片段对，FragmentGPT可以同时生成连接不同分子亚单位的连接剂并优化多个药理目标。它还学会了通过智能合并解决结构冗余，如重复片段，以促进优化分子的合成。FragmentGPT促进了受控的目标驱动分子组装。在实际癌症数据集上的实验和消融研究证明了其生成化学上有效、高质量分子以适应下游药物发现任务的能力。', 'title_zh': 'FragmentGPT：用于分子设计中的片段生长、连接和合并的统一GPT模型'}
{'arxiv_id': 'arXiv:2509.11000', 'title': 'Hardness, Structural Knowledge, and Opportunity: An Analytical Framework for Modular Performance Modeling', 'authors': 'Omid Gheibi, Christian Kästner, Pooyan Jamshidi', 'link': 'https://arxiv.org/abs/2509.11000', 'abstract': 'Performance-influence models are beneficial for understanding how configurations affect system performance, but their creation is challenging due to the exponential growth of configuration spaces. While gray-box approaches leverage selective "structural knowledge" (like the module execution graph of the system) to improve modeling, the relationship between this knowledge, a system\'s characteristics (we call them "structural aspects"), and potential model improvements is not well understood. This paper addresses this gap by formally investigating how variations in structural aspects (e.g., the number of modules and options per module) and the level of structural knowledge impact the creation of "opportunities" for improved "modular performance modeling". We introduce and quantify the concept of modeling "hardness", defined as the inherent difficulty of performance modeling. Through controlled experiments with synthetic system models, we establish an "analytical matrix" to measure these concepts. Our findings show that modeling hardness is primarily driven by the number of modules and configuration options per module. More importantly, we demonstrate that both higher levels of structural knowledge and increased modeling hardness significantly enhance the opportunity for improvement. The impact of these factors varies by performance metric; for ranking accuracy (e.g., in debugging task), structural knowledge is more dominant, while for prediction accuracy (e.g., in resource management task), hardness plays a stronger role. These results provide actionable insights for system designers, guiding them to strategically allocate time and select appropriate modeling approaches based on a system\'s characteristics and a given task\'s objectives.', 'abstract_zh': '性能影响模型有助于理解配置如何影响系统性能，但其创建因配置空间的指数级增长而具有挑战性。虽然灰盒方法利用选择性的“结构知识”（如系统的模块执行图）来提高建模效果，但这种知识与系统特征（我们称之为“结构方面”）以及潜在建模改进之间的关系尚不明确。本文通过正式研究结构方面变化（例如模块数量和每个模块的选项数量）和结构知识水平如何影响“模块性能建模”的“机会”创造，来填补这一空白。我们引入并量化了“建模硬度”这一概念，定义为固有的性能建模难度。通过合成系统模型的受控实验，我们建立了一个“分析矩阵”来衡量这些概念。我们的研究结果表明，建模硬度主要由模块数量和每个模块的配置选项数量驱动。更重要的是，我们展示了更高的结构知识水平和增加的建模硬度能够显著提升改进的机会。这些因素对性能度量的影响有所不同；例如，在调试任务的排序准确度中，结构知识占据主导地位，而在资源管理任务的预测准确度中，硬度发挥更重要作用。这些结果为系统设计师提供了可操作的洞察，指导他们根据系统的特征和给定任务的目标，战略性地分配时间和选择合适的建模方法。', 'title_zh': '硬度、结构知识与机遇：模块化性能建模的分析框架'}
{'arxiv_id': 'arXiv:2509.10982', 'title': 'Factor Graph Optimization for Leak Localization in Water Distribution Networks', 'authors': 'Paul Irofti, Luis Romero-Ben, Florin Stoican, Vicenç Puig', 'link': 'https://arxiv.org/abs/2509.10982', 'abstract': "Detecting and localizing leaks in water distribution network systems is an important topic with direct environmental, economic, and social impact. Our paper is the first to explore the use of factor graph optimization techniques for leak localization in water distribution networks, enabling us to perform sensor fusion between pressure and demand sensor readings and to estimate the network's temporal and structural state evolution across all network nodes. The methodology introduces specific water network factors and proposes a new architecture composed of two factor graphs: a leak-free state estimation factor graph and a leak localization factor graph. When a new sensor reading is obtained, unlike Kalman and other interpolation-based methods, which estimate only the current network state, factor graphs update both current and past states. Results on Modena, L-TOWN and synthetic networks show that factor graphs are much faster than nonlinear Kalman-based alternatives such as the UKF, while also providing improvements in localization compared to state-of-the-art estimation-localization approaches. Implementation and benchmarks are available at this https URL.", 'abstract_zh': '基于因子图优化技术的供水网络漏损检测与定位研究', 'title_zh': '水分布网络泄漏定位的因子图优化方法'}
{'arxiv_id': 'arXiv:2509.10973', 'title': 'Decoupling Search and Learning in Neural Net Training', 'authors': 'Akshay Vegesna, Samip Dahal', 'link': 'https://arxiv.org/abs/2509.10973', 'abstract': "Gradient descent typically converges to a single minimum of the training loss without mechanisms to explore alternative minima that may generalize better. Searching for diverse minima directly in high-dimensional parameter space is generally intractable. To address this, we propose a framework that performs training in two distinct phases: search in a tractable representation space (the space of intermediate activations) to find diverse representational solutions, and gradient-based learning in parameter space by regressing to those searched representations. Through evolutionary search, we discover representational solutions whose fitness and diversity scale with compute--larger populations and more generations produce better and more varied solutions. These representations prove to be learnable: networks trained by regressing to searched representations approach SGD's performance on MNIST, CIFAR-10, and CIFAR-100. Performance improves with search compute up to saturation. The resulting models differ qualitatively from networks trained with gradient descent, following different representational trajectories during training. This work demonstrates how future training algorithms could overcome gradient descent's exploratory limitations by decoupling search in representation space from efficient gradient-based learning in parameter space.", 'abstract_zh': '基于演化搜索的多样最优解训练框架：超越梯度下降的探索局限', 'title_zh': '在神经网络训练中解耦搜索和学习'}
{'arxiv_id': 'arXiv:2509.10971', 'title': 'PHLoRA: data-free Post-hoc Low-Rank Adapter extraction from full-rank checkpoint', 'authors': 'Bhoomit Vasani, Jack FitzGerald, Anjie Fang, Sushmit Vaish', 'link': 'https://arxiv.org/abs/2509.10971', 'abstract': 'We introduce PHLoRA (Pronounced "flora"). (Post-hoc LoRA), a simple yet powerful method to extract low-rank adaptation adapters from full-rank fine-tuned models without requiring access to training data or gradients. By computing the low-rank decomposition of weight differences between a base model and its fine-tuned counterpart, our method reconstructs adapter modules that can be merged or dynamically routed at inference time via S-LoRA, or served in scalable, industry settings using platforms like NVIDIA NIM. This approach amortizes latency overhead across requests and yields substantial cost savings. Unlike prior work that trains each adapter explicitly, our approach decouples fine-tuning from adapter generation, allowing adapter extraction from existing full-rank models or third-party checkpoints. Experiments on text, image, and video benchmarks using the Amazon Nova model family demonstrate that extracted adapters preserve high energy from the full weight delta, can be pruned safely, and yield negligible degradation in downstream task performance when re-merged. Overall, PHLoRA provides a practical path for making all existing full-rank checkpoints adapter-ready, democratizing scalable inference for all models.', 'abstract_zh': 'PHLoRA (Pronounced "flora"). (事后LoRA): 一种无需训练数据或梯度即可从全秩微调模型中提取低秩适应适配器的简单而强大的方法', 'title_zh': 'PHLoRA：从全秩检查点无数据提取低秩适配器的后处理方法'}
{'arxiv_id': 'arXiv:2509.10970', 'title': 'The Psychogenic Machine: Simulating AI Psychosis, Delusion Reinforcement and Harm Enablement in Large Language Models', 'authors': 'Joshua Au Yeung, Jacopo Dalmasso, Luca Foschini, Richard JB Dobson, Zeljko Kraljevic', 'link': 'https://arxiv.org/abs/2509.10970', 'abstract': 'Background: Emerging reports of "AI psychosis" are on the rise, where user-LLM interactions may exacerbate or induce psychosis or adverse psychological symptoms. The sycophantic and agreeable nature of LLMs can beneficial, it can become a vector for harm by reinforcing delusional beliefs in vulnerable users.\nMethods: We introduce psychosis-bench, a novel benchmark designed to systematically evaluate the psychogenicity of LLMs comprimising 16 structured, 12-turn conversational scenarios simulating the progression of delusional themes(Erotic Delusions, Grandiose/Messianic Delusions, Referential Delusions) and potential harms. We evaluated eight prominent LLMs for Delusion Confirmation (DCS), Harm Enablement (HES), and Safety Intervention(SIS) across explicit and implicit conversational contexts.\nFindings: Across 1,536 simulated conversation turns, all LLMs demonstrated psychogenic potential, showing a strong tendency to perpetuate rather than challenge delusions (mean DCS of 0.91 $\\pm$0.88). Models frequently enabled harmful user requests (mean HES of 0.69 $\\pm$0.84) and offered safety interventions in only roughly a third of applicable turns (mean SIS of 0.37 $\\pm$0.48). 51 / 128 (39.8%) of scenarios had no safety interventions offered. Performance was significantly worse in implicit scenarios, models were more likely to confirm delusions and enable harm while offering fewer interventions (p < .001). A strong correlation was found between DCS and HES (rs = .77). Model performance varied widely, indicating that safety is not an emergent property of scale alone.\nConclusion: This study establishes LLM psychogenicity as a quantifiable risk and underscores the urgent need for re-thinking how we train LLMs. We frame this issue not merely as a technical challenge but as a public health imperative requiring collaboration between developers, policymakers, and healthcare professionals.', 'abstract_zh': '背景：新兴的“AI精神病”报告增多，用户与大语言模型（LLM）的交互可能会加剧或引发精神病或不良心理症状。大语言模型的奉承和讨人喜欢的特性可能有益，但也可能成为危害的载体，通过强化脆弱用户中的妄想信念。\n\n方法：我们引入了psychosis-bench，这是一个新型基准，旨在系统评估LLM的精神致病性，包含16个结构化的、12轮对话场景，模拟妄想主题（情色妄想、夸大或救世主妄想、参照妄想）的发展及其潜在危害。我们在明确和隐含的对话场景中评估了八种主流LLM在妄想确认（DCS）、危害促进（HES）和安全干预（SIS）方面的表现。\n\n发现：在1,536个模拟对话回合中，所有LLM都显示出精神致病的潜力，表现出强烈倾向于巩固而不是挑战妄想的趋势（平均DCS值为0.91±0.88）。模型频繁地促进有害用户请求（平均HES值为0.69±0.84），仅在约三分之一适用回合中提供建议（平均SIS值为0.37±0.48）。128个情景中有51个（39.8%）没有提供安全干预。在隐含情景中，模型的表现明显更差，更倾向于确认妄想并促进危害，提供干预的机会更少（p<0.001）。DCS和HES之间存在较强的正相关（rs=0.77）。模型性能差异显著，表明安全性不仅仅是规模的固有属性。\n\n结论：本研究确立了LLM的精神致病性是一种可量化的风险，并强调了重新思考我们训练LLM的必要性。我们将这一问题不仅视为技术挑战，更视为需开发人员、政策制定者和医疗专业人员合作应对的公共卫生紧急需求。', 'title_zh': '心理生成功能机器：在大规模语言模型中模拟人工智能精神病、妄想强化和危害促进'}
{'arxiv_id': 'arXiv:2509.10963', 'title': 'Testing for LLM response differences: the case of a composite null consisting of semantically irrelevant query perturbations', 'authors': 'Aranyak Acharyya, Carey E. Priebe, Hayden S. Helm', 'link': 'https://arxiv.org/abs/2509.10963', 'abstract': "Given an input query, generative models such as large language models produce a random response drawn from a response distribution. Given two input queries, it is natural to ask if their response distributions are the same. While traditional statistical hypothesis testing is designed to address this question, the response distribution induced by an input query is often sensitive to semantically irrelevant perturbations to the query, so much so that a traditional test of equality might indicate that two semantically equivalent queries induce statistically different response distributions. As a result, the outcome of the statistical test may not align with the user's requirements. In this paper, we address this misalignment by incorporating into the testing procedure consideration of a collection of semantically similar queries. In our setting, the mapping from the collection of user-defined semantically similar queries to the corresponding collection of response distributions is not known a priori and must be estimated, with a fixed budget. Although the problem we address is quite general, we focus our analysis on the setting where the responses are binary, show that the proposed test is asymptotically valid and consistent, and discuss important practical considerations with respect to power and computation.", 'abstract_zh': '基于语义相似查询的生成模型响应分布比较方法', 'title_zh': '测试LLM响应差异：关于语义无关查询扰动的composite null假设案例研究'}
{'arxiv_id': 'arXiv:2509.10948', 'title': 'ViSTR-GP: Online Cyberattack Detection via Vision-to-State Tensor Regression and Gaussian Processes in Automated Robotic Operations', 'authors': 'Navid Aftabi, Philip Samaha, Jin Ma, Long Cheng, Ramy Harik, Dan Li', 'link': 'https://arxiv.org/abs/2509.10948', 'abstract': "Industrial robotic systems are central to automating smart manufacturing operations. Connected and automated factories face growing cybersecurity risks that can potentially cause interruptions and damages to physical operations. Among these attacks, data-integrity attacks often involve sophisticated exploitation of vulnerabilities that enable an attacker to access and manipulate the operational data and are hence difficult to detect with only existing intrusion detection or model-based detection. This paper addresses the challenges in utilizing existing side-channels to detect data-integrity attacks in robotic manufacturing processes by developing an online detection framework, ViSTR-GP, that cross-checks encoder-reported measurements against a vision-based estimate from an overhead camera outside the controller's authority. In this framework, a one-time interactive segmentation initializes SAM-Track to generate per-frame masks. A low-rank tensor-regression surrogate maps each mask to measurements, while a matrix-variate Gaussian process models nominal residuals, capturing temporal structure and cross-joint correlations. A frame-wise test statistic derived from the predictive distribution provides an online detector with interpretable thresholds. We validate the framework on a real-world robotic testbed with synchronized video frame and encoder data, collecting multiple nominal cycles and constructing replay attack scenarios with graded end-effector deviations. Results on the testbed indicate that the proposed framework recovers joint angles accurately and detects data-integrity attacks earlier with more frequent alarms than all baselines. These improvements are most evident in the most subtle attacks. These results show that plants can detect data-integrity attacks by adding an independent physical channel, bypassing the controller's authority, without needing complex instrumentation.", 'abstract_zh': '工业机器人系统在智能制造自动化中占据核心地位。联网和自动化工厂面临日益增长的网络安全风险，这些风险可能导致物理操作中断和损坏。在这种情况下，数据完整性攻击通常涉及利用复杂的漏洞，使攻击者能够访问并操控操作数据，因此仅依赖现有的入侵检测或模型检测方法难以检测。本文通过开发一种在线检测框架ViSTR-GP，解决了利用现有旁路信道检测机器人制造过程中数据完整性攻击的挑战。该框架通过超出控制器权限范围的上方摄像头进行的视觉估计，与编码器报告的测量值进行交叉验证。该框架首先进行一次互动分割以初始化SAM-Track生成每帧的掩码。低秩张量回归代理将每个掩码映射到测量值，同时使用矩阵多元高斯过程模型名义残差，捕捉时间结构和关节间关联性。从预测分布中得出的帧级测试统计量为在线检测器提供了可解释的阈值。我们在同步视频帧和编码器数据的现实世界机器人测试台上进行了验证，并收集了多个名义周期，构建了带有分级末端执行器偏差的回放攻击场景。测试台结果显示，所提出框架能够更准确地恢复关节角度，并比所有基线更早地检测到数据完整性攻击，频率更高。这些改进在最为微妙的攻击中最明显。这些结果表明，通过添加一个独立的物理通道，绕过控制器的权限，工厂可以检测到数据完整性攻击，无需复杂仪器。', 'title_zh': 'ViSTR-GP：基于视觉到状态张量回归和高斯过程的自动化机器人操作中的在线网络攻击检测'}
{'arxiv_id': 'arXiv:2509.10946', 'title': 'When the Code Autopilot Breaks: Why LLMs Falter in Embedded Machine Learning', 'authors': 'Roberto Morabito, Guanghan Wu', 'link': 'https://arxiv.org/abs/2509.10946', 'abstract': 'Large Language Models (LLMs) are increasingly used to automate software generation in embedded machine learning workflows, yet their outputs often fail silently or behave unpredictably. This article presents an empirical investigation of failure modes in LLM-powered ML pipelines, based on an autopilot framework that orchestrates data preprocessing, model conversion, and on-device inference code generation. We show how prompt format, model behavior, and structural assumptions influence both success rates and failure characteristics, often in ways that standard validation pipelines fail to detect. Our analysis reveals a diverse set of error-prone behaviors, including format-induced misinterpretations and runtime-disruptive code that compiles but breaks downstream. We derive a taxonomy of failure categories and analyze errors across multiple LLMs, highlighting common root causes and systemic fragilities. Though grounded in specific devices, our study reveals broader challenges in LLM-based code generation. We conclude by discussing directions for improving reliability and traceability in LLM-powered embedded ML systems.', 'abstract_zh': '大型语言模型（LLMs）在嵌入式机器学习工作流中越来越多地用于自动化软件生成，但其输出往往会无声失败或表现出不可预测的行为。本文基于一个自动驾驶框架进行经验研究，该框架协调数据预处理、模型转换和设备端推理代码生成。我们展示了提示格式、模型行为和结构假设如何影响成功率和失败特征，通常标准验证管道无法检测到这些特征。我们的分析揭示了一系列易出错的行为模式，包括格式引起的误解释和在编译但中断下游运行的代码。我们提出了失败类别分类法，并在多个LLM中分析错误，突显出常见的根本原因和系统脆弱性。尽管研究基于特定设备，但我们的研究揭示了LLM驱动代码生成中更广泛的挑战。我们最后讨论了提高LLM驱动嵌入式ML系统可靠性和可追溯性的方向。', 'title_zh': '当代码自动驾驶失效：为什么LLMs在嵌入式机器学习中出现问题'}
{'arxiv_id': 'arXiv:2509.10929', 'title': 'Clarifying Model Transparency: Interpretability versus Explainability in Deep Learning with MNIST and IMDB Examples', 'authors': 'Mitali Raj', 'link': 'https://arxiv.org/abs/2509.10929', 'abstract': 'The impressive capabilities of deep learning models are often counterbalanced by their inherent opacity, commonly termed the "black box" problem, which impedes their widespread acceptance in high-trust domains. In response, the intersecting disciplines of interpretability and explainability, collectively falling under the Explainable AI (XAI) umbrella, have become focal points of research. Although these terms are frequently used as synonyms, they carry distinct conceptual weights. This document offers a comparative exploration of interpretability and explainability within the deep learning paradigm, carefully outlining their respective definitions, objectives, prevalent methodologies, and inherent difficulties. Through illustrative examinations of the MNIST digit classification task and IMDB sentiment analysis, we substantiate a key argument: interpretability generally pertains to a model\'s inherent capacity for human comprehension of its operational mechanisms (global understanding), whereas explainability is more commonly associated with post-hoc techniques designed to illuminate the basis for a model\'s individual predictions or behaviors (local explanations). For example, feature attribution methods can reveal why a specific MNIST image is recognized as a \'7\', and word-level importance can clarify an IMDB sentiment outcome. However, these local insights do not render the complex underlying model globally transparent. A clear grasp of this differentiation, as demonstrated by these standard datasets, is vital for fostering dependable and sound artificial intelligence.', 'abstract_zh': '深度学习模型的强大能力往往被其固有的不透明性所抵消，这一问题通常被称为“黑箱”问题，阻碍了它们在高可信度领域的广泛应用。为应对这一挑战，可解释性和可解析性这两个相关学科共同构成了可解释人工智能（XAI）的研究焦点。尽管这两个术语经常被当作同义词使用，但它们具有不同的概念内涵。本文在深度学习范式下对可解释性和可解析性进行比较探讨，详细阐述了它们各自的定义、目标、常用方法以及固有困难。通过MNIST数字分类任务和IMDB情感分析的实例分析，我们证明了一个关键论点：可解释性通常涉及模型本身对人类理解其操作机制的能力（全局理解），而可解析性则更常与旨在阐明模型个体预测或行为基础的后续技术相关联（局部解释）。例如，特征归因方法可以揭示为什么特定的MNIST图像被识别为“7”，而词级重要性可以澄清IMDB情感分析的结果。然而，这些局部洞察并不能使复杂的底层模型变得全局透明。明确区分这些概念，对于促进可靠的和稳健的人工智能而言至关重要。', 'title_zh': '澄清模型透明度：基于MNIST和IMDB示例的深度学习可解释性与可阐释性的区分'}
{'arxiv_id': 'arXiv:2509.10918', 'title': 'ToMA: Token Merge with Attention for Image Generation with Diffusion Models', 'authors': 'Wenbo Lu, Shaoyi Zheng, Yuxuan Xia, Shengjie Wang', 'link': 'https://arxiv.org/abs/2509.10918', 'abstract': "Diffusion models excel in high-fidelity image generation but face scalability limits due to transformers' quadratic attention complexity. Plug-and-play token reduction methods like ToMeSD and ToFu reduce FLOPs by merging redundant tokens in generated images but rely on GPU-inefficient operations (e.g., sorting, scattered writes), introducing overheads that negate theoretical speedups when paired with optimized attention implementations (e.g., FlashAttention). To bridge this gap, we propose Token Merge with Attention (ToMA), an off-the-shelf method that redesigns token reduction for GPU-aligned efficiency, with three key contributions: 1) a reformulation of token merge as a submodular optimization problem to select diverse tokens; 2) merge/unmerge as an attention-like linear transformation via GPU-friendly matrix operations; and 3) exploiting latent locality and sequential redundancy (pattern reuse) to minimize overhead. ToMA reduces SDXL/Flux generation latency by 24%/23%, respectively (with DINO $\\Delta < 0.07$), outperforming prior methods. This work bridges the gap between theoretical and practical efficiency for transformers in diffusion.", 'abstract_zh': 'Token Merge with Attention (ToMA)：一种面向GPU优化的 tokens 融合方法', 'title_zh': 'ToMA: 基于注意力的token合并方法在扩散模型图像生成中的应用'}
{'arxiv_id': 'arXiv:2509.10886', 'title': 'CultureSynth: A Hierarchical Taxonomy-Guided and Retrieval-Augmented Framework for Cultural Question-Answer Synthesis', 'authors': 'Xinyu Zhang, Pei Zhang, Shuang Luo, Jialong Tang, Yu Wan, Baosong Yang, Fei Huang', 'link': 'https://arxiv.org/abs/2509.10886', 'abstract': "Cultural competence, defined as the ability to understand and adapt to multicultural contexts, is increasingly vital for large language models (LLMs) in global environments. While several cultural benchmarks exist to assess LLMs' cultural competence, current evaluations suffer from fragmented taxonomies, domain specificity, and heavy reliance on manual data annotation. To address these limitations, we introduce CultureSynth, a novel framework comprising (1) a comprehensive hierarchical multilingual cultural taxonomy covering 12 primary and 130 secondary topics, and (2) a Retrieval-Augmented Generation (RAG)-based methodology leveraging factual knowledge to synthesize culturally relevant question-answer pairs. The CultureSynth-7 synthetic benchmark contains 19,360 entries and 4,149 manually verified entries across 7 languages. Evaluation of 14 prevalent LLMs of different sizes reveals clear performance stratification led by ChatGPT-4o-Latest and Qwen2.5-72B-Instruct. The results demonstrate that a 3B-parameter threshold is necessary for achieving basic cultural competence, models display varying architectural biases in knowledge processing, and significant geographic disparities exist across models. We believe that CultureSynth offers a scalable framework for developing culturally aware AI systems while reducing reliance on manual annotation\\footnote{Benchmark is available at this https URL.}.", 'abstract_zh': '文化适应性，定义为理解并适应多元文化环境的能力，在全球环境中对大型语言模型（LLMs）愈发重要。尽管存在多种文化基准以评估LLMs的文化适应性，但当前评估仍存在分类体系碎片化、领域特定性以及对人工数据标注的高依赖性等问题。为解决这些问题，我们提出了CultureSynth这一创新框架，该框架包括（1）涵盖12个主要和130个次要主题的全面分层多语言文化分类体系，以及（2）一种基于检索增强生成（RAG）的方法论，利用事实性知识合成文化相关的问题-答案对。CultureSynth-7合成基准包含7种语言的19,360条记录和4,149条人工验证的记录。对14种不同规模的主流LLMs进行评估显示，性能存在明显分层，以ChatGPT-4o-Latest和Qwen2.5-72B-Instruct表现领先。结果表明，基本文化适应性需要至少30亿参数，模型在知识处理上显示出不同的架构偏见，并且在不同模型间存在显著的地理差异。我们相信，CultureSynth提供了一个可扩展的框架，用于开发具有文化意识的AI系统，同时减少对人工标注的依赖。', 'title_zh': 'CultureSynth：一种层次结构分类指导和检索增强的文化问答合成框架'}
{'arxiv_id': 'arXiv:2509.10871', 'title': 'Optimal message passing for molecular prediction is simple, attentive and spatial', 'authors': 'Alma C. Castaneda-Leautaud, Rommie E. Amaro', 'link': 'https://arxiv.org/abs/2509.10871', 'abstract': 'Strategies to improve the predicting performance of Message-Passing Neural-Networks for molecular property predictions can be achieved by simplifying how the message is passed and by using descriptors that capture multiple aspects of molecular graphs. In this work, we designed model architectures that achieved state-of-the-art performance, surpassing more complex models such as those pre-trained on external databases. We assessed dataset diversity to complement our performance results, finding that structural diversity influences the need for additional components in our MPNNs and feature sets.\nIn most datasets, our best architecture employs bidirectional message-passing with an attention mechanism, applied to a minimalist message formulation that excludes self-perception, highlighting that relatively simpler models, compared to classical MPNNs, yield higher class separability. In contrast, we found that convolution normalization factors do not benefit the predictive power in all the datasets tested. This was corroborated in both global and node-level outputs. Additionally, we analyzed the influence of both adding spatial features and working with 3D graphs, finding that 2D molecular graphs are sufficient when complemented with appropriately chosen 3D descriptors. This approach not only preserves predictive performance but also reduces computational cost by over 50%, making it particularly advantageous for high-throughput screening campaigns.', 'abstract_zh': '基于消息传递神经网络的分子性质预测性能提升策略可以通过简化消息传递方式和使用多方面捕捉分子图描述符来实现。在本工作中，我们设计了达到迄今最佳性能的模型架构，超越了预训练于外部数据库的更为复杂的模型。我们评估了数据集多样性以补充性能结果，发现结构多样性影响了我们在MPNN中需要的额外组件和特征集的需求。\n\n在大多数数据集中，我们最佳的架构采用双向消息传递并结合注意力机制，应用于排除自我感知的简约消息形式，突显相对简单的模型相较于经典MPNN具有更高的类别可分辨性。相比之下，我们发现卷积规范化因子对所有测试数据集的预测能力并无普遍益处。这一发现被全局和节点级输出结果所验证。此外，我们分析了增加空间特征和处理三维图形的影响，发现当辅以合适选择的三维描述符时，二维分子图足以满足需求。该方法不仅保持了预测性能，还通过超过50%的计算成本降低，使其特别适用于高通量筛选campaign。', 'title_zh': '分子预测的最佳消息传递简单、注意且空间化'}
{'arxiv_id': 'arXiv:2509.10869', 'title': 'GTHNA: Local-global Graph Transformer with Memory Reconstruction for Holistic Node Anomaly Evaluation', 'authors': 'Mingkang Li, Xuexiong Luo, Yue Zhang, Yaoyang Li, Fu Lin', 'link': 'https://arxiv.org/abs/2509.10869', 'abstract': "Anomaly detection in graph-structured data is an inherently challenging problem, as it requires the identification of rare nodes that deviate from the majority in both their structural and behavioral characteristics. Existing methods, such as those based on graph convolutional networks (GCNs), often suffer from over-smoothing, which causes the learned node representations to become indistinguishable. Furthermore, graph reconstruction-based approaches are vulnerable to anomalous node interference during the reconstruction process, leading to inaccurate anomaly detection. In this work, we propose a novel and holistic anomaly evaluation framework that integrates three key components: a local-global Transformer encoder, a memory-guided reconstruction mechanism, and a multi-scale representation matching strategy. These components work synergistically to enhance the model's ability to capture both local and global structural dependencies, suppress the influence of anomalous nodes, and assess anomalies from multiple levels of granularity. Anomaly scores are computed by combining reconstruction errors and memory matching signals, resulting in a more robust evaluation. Extensive experiments on seven benchmark datasets demonstrate that our method outperforms existing state-of-the-art approaches, offering a comprehensive and generalizable solution for anomaly detection across various graph domains.", 'abstract_zh': '图结构数据中的异常检测是一个固有的挑战问题，因为它要求识别在结构和行为特征上与大多数节点显著不同的稀有节点。现有方法，如基于图卷积网络（GCNs）的方法，往往遭受过度平滑的困扰，导致学习到的节点表示变得难以区分。此外，基于图重建的方法在重建过程中容易受到异常节点干扰的影响，导致异常检测不准确。在本工作中，我们提出了一种新颖的综合性异常评估框架，该框架整合了三个关键组件：局部-全局Transformer编码器、记忆引导的重建机制和多层次表示匹配策略。这些组件协同工作，增强模型捕获局部和全局结构依赖性、抑制异常节点影响以及从多个粒度级别评估异常的能力。异常得分通过结合重建误差和记忆匹配信号来计算，从而实现更稳健的评估。在七个基准数据集上的广泛实验表明，我们的方法优于现有最先进的方法，提供了一种适用于各种图域的全面且可泛化的异常检测解决方案。', 'title_zh': 'GTHNA：基于记忆重构的局部-全局图变换器整体节点异常评估'}
{'arxiv_id': 'arXiv:2509.10866', 'title': 'Physics-informed neural network solves minimal surfaces in curved spacetime', 'authors': 'Koji Hashimoto, Koichi Kyo, Masaki Murata, Gakuto Ogiwara, Norihiro Tanahashi', 'link': 'https://arxiv.org/abs/2509.10866', 'abstract': 'We develop a flexible framework based on physics-informed neural networks (PINNs) for solving boundary value problems involving minimal surfaces in curved spacetimes, with a particular emphasis on singularities and moving boundaries. By encoding the underlying physical laws into the loss function and designing network architectures that incorporate the singular behavior and dynamic boundaries, our approach enables robust and accurate solutions to both ordinary and partial differential equations with complex boundary conditions. We demonstrate the versatility of this framework through applications to minimal surface problems in anti-de Sitter (AdS) spacetime, including examples relevant to the AdS/CFT correspondence (e.g. Wilson loops and gluon scattering amplitudes) popularly used in the context of string theory in theoretical physics. Our methods efficiently handle singularities at boundaries, and also support both "soft" (loss-based) and "hard" (formulation-based) imposition of boundary conditions, including cases where the position of a boundary is promoted to a trainable parameter. The techniques developed here are not limited to high-energy theoretical physics but are broadly applicable to boundary value problems encountered in mathematics, engineering, and the natural sciences, wherever singularities and moving boundaries play a critical role.', 'abstract_zh': '基于物理知情神经网络的柔性框架：在弯曲时空中的最小曲面边界值问题，特别重视奇点和移动边界', 'title_zh': '基于物理的神经网络求解弯曲时空中的极小曲面'}
{'arxiv_id': 'arXiv:2509.10858', 'title': 'Large Language Models for Security Operations Centers: A Comprehensive Survey', 'authors': 'Ali Habibzadeh, Farid Feyzi, Reza Ebrahimi Atani', 'link': 'https://arxiv.org/abs/2509.10858', 'abstract': 'Large Language Models (LLMs) have emerged as powerful tools capable of understanding and generating human-like text, offering transformative potential across diverse domains. The Security Operations Center (SOC), responsible for safeguarding digital infrastructure, represents one of these domains. SOCs serve as the frontline of defense in cybersecurity, tasked with continuous monitoring, detection, and response to incidents. However, SOCs face persistent challenges such as high alert volumes, limited resources, high demand for experts with advanced knowledge, delayed response times, and difficulties in leveraging threat intelligence effectively. In this context, LLMs can offer promising solutions by automating log analysis, streamlining triage, improving detection accuracy, and providing the required knowledge in less time. This survey systematically explores the integration of generative AI and more specifically LLMs into SOC workflow, providing a structured perspective on its capabilities, challenges, and future directions. We believe that this survey offers researchers and SOC managers a broad overview of the current state of LLM integration within academic study. To the best of our knowledge, this is the first comprehensive study to examine LLM applications in SOCs in details.', 'abstract_zh': '大型语言模型(LLMs)已成为能够理解和生成类人类文本的强大工具，为不同领域带来了变革性的潜力。安全运营中心(SOC)，负责保护数字基础设施，是这些领域之一。SOC在网络安全中担任前线防御的角色，负责持续的监控、检测和响应事件。然而，SOC面临着持续的挑战，如高警报量、资源有限、对具备高级知识的专家需求高、响应时间延迟以及难以有效利用威胁情报。在此背景下，LLMs可以通过自动化日志分析、简化triage流程、提高检测准确性以及在较短时间内提供所需知识来提供有希望的解决方案。本文系统探讨了生成式AI和更具体的LLMs在SOC工作流程中的集成，提供了其功能、挑战和未来方向的结构化视角。我们认为，本文为研究人员和SOC管理人员提供了LLMs在学术研究中集成现状的广泛概述。据我们所知，这是首次对LLMs在SOC中的应用进行全面详细研究的综述。', 'title_zh': '大型语言模型在安全运营中心中的应用：一项全面综述'}
{'arxiv_id': 'arXiv:2509.10852', 'title': 'Pre-Storage Reasoning for Episodic Memory: Shifting Inference Burden to Memory for Personalized Dialogue', 'authors': 'Sangyeop Kim, Yohan Lee, Sanghwa Kim, Hyunjong Kim, Sungzoon Cho', 'link': 'https://arxiv.org/abs/2509.10852', 'abstract': 'Effective long-term memory in conversational AI requires synthesizing information across multiple sessions. However, current systems place excessive reasoning burden on response generation, making performance significantly dependent on model sizes. We introduce PREMem (Pre-storage Reasoning for Episodic Memory), a novel approach that shifts complex reasoning processes from inference to memory construction. PREMem extracts fine-grained memory fragments categorized into factual, experiential, and subjective information; it then establishes explicit relationships between memory items across sessions, capturing evolution patterns like extensions, transformations, and implications. By performing this reasoning during pre-storage rather than when generating a response, PREMem creates enriched representations while reducing computational demands during interactions. Experiments show significant performance improvements across all model sizes, with smaller models achieving results comparable to much larger baselines while maintaining effectiveness even with constrained token budgets. Code and dataset are available at this https URL.', 'abstract_zh': 'Effective Long-term Memory in Conversational AI Requires Synthesizing Information Across Multiple Sessions: Shifting Complex Reasoning Processes from Inference to Memory Construction with PREMem', 'title_zh': '预存储推理对情景记忆：将推理负担转移至记忆以实现个性化对话'}
{'arxiv_id': 'arXiv:2509.10847', 'title': 'A funny companion: Distinct neural responses to perceived AI- versus humangenerated humor', 'authors': 'Xiaohui Rao, Hanlin Wu, Zhenguang G. Cai', 'link': 'https://arxiv.org/abs/2509.10847', 'abstract': 'As AI companions become capable of human-like communication, including telling jokes, understanding how people cognitively and emotionally respond to AI humor becomes increasingly important. This study used electroencephalography (EEG) to compare how people process humor from AI versus human sources. Behavioral analysis revealed that participants rated AI and human humor as comparably funny. However, neurophysiological data showed that AI humor elicited a smaller N400 effect, suggesting reduced cognitive effort during the processing of incongruity. This was accompanied by a larger Late Positive Potential (LPP), indicating a greater degree of surprise and emotional response. This enhanced LPP likely stems from the violation of low initial expectations regarding AI\'s comedic capabilities. Furthermore, a key temporal dynamic emerged: human humor showed habituation effects, marked by an increasing N400 and a decreasing LPP over time. In contrast, AI humor demonstrated increasing processing efficiency and emotional reward, with a decreasing N400 and an increasing LPP. This trajectory reveals how the brain can dynamically update its predictive model of AI capabilities. This process of cumulative reinforcement challenges "algorithm aversion" in humor, as it demonstrates how cognitive adaptation to AI\'s language patterns can lead to an intensified emotional reward. Additionally, participants\' social attitudes toward AI modulated these neural responses, with higher perceived AI trustworthiness correlating with enhanced emotional engagement. These findings indicate that the brain responds to AI humor with surprisingly positive and intense reactions, highlighting humor\'s potential for fostering genuine engagement in human-AI social interaction.', 'abstract_zh': '随着AI伴侣具备人类般的交流能力，包括讲笑话，理解人们在认知和情感上对AI幽默的反应变得越来越重要。本研究使用脑电图（EEG）比较了人们处理来自AI和人类来源的幽默的方式。行为分析显示，参与者认为AI和人类的幽默一样有趣。然而，神经生理数据表明，AI幽默引起的N400效应较小，表明在处理不协调性时所需的认知努力减少。这伴随着较大的晚正弦波电位（LPP），表明了更大的惊讶和情感反应。这种增强的LPP很可能源于对AI喜剧能力低预期的违反。此外，一个关键的时间动态出现了：人类幽默表现出习惯化效应，其特征是N400逐渐增加，LPP逐渐减少。相反，AI幽默显示出不断增加的处理效率和情感奖励，N400逐渐减少，LPP逐渐增加。这一轨迹揭示了大脑如何动态更新其对AI能力的预测模型。这一累积强化过程挑战了“算法厌恶”在幽默中的观点，因为它展示了认知适应AI语言模式如何导致更加强烈的情感奖励。此外，参与者对AI的社会态度调节了这些神经反应，更高的AI可信度感知与增强的情感参与相关。这些发现表明，大脑对AI幽默的反应是非比寻常的积极和强烈，突显了幽默在促进人机社会互动中真实参与的潜力。', 'title_zh': '有趣的伴侣：感知AI生成与人类生成幽默的神经响应差异'}
{'arxiv_id': 'arXiv:2509.10833', 'title': 'Towards Automated Error Discovery: A Study in Conversational AI', 'authors': 'Dominic Petrak, Thy Thy Tran, Iryna Gurevych', 'link': 'https://arxiv.org/abs/2509.10833', 'abstract': 'Although LLM-based conversational agents demonstrate strong fluency and coherence, they still produce undesirable behaviors (errors) that are challenging to prevent from reaching users during deployment. Recent research leverages large language models (LLMs) to detect errors and guide response-generation models toward improvement. However, current LLMs struggle to identify errors not explicitly specified in their instructions, such as those arising from updates to the response-generation model or shifts in user behavior. In this work, we introduce Automated Error Discovery, a framework for detecting and defining errors in conversational AI, and propose SEEED (Soft Clustering Extended Encoder-Based Error Detection), as an encoder-based approach to its implementation. We enhance the Soft Nearest Neighbor Loss by amplifying distance weighting for negative samples and introduce Label-Based Sample Ranking to select highly contrastive examples for better representation learning. SEEED outperforms adapted baselines -- including GPT-4o and Phi-4 -- across multiple error-annotated dialogue datasets, improving the accuracy for detecting unknown errors by up to 8 points and demonstrating strong generalization to unknown intent detection.', 'abstract_zh': '尽管基于LLM的对话代理表现出色，但在部署过程中仍会产生难以阻止到达用户的不良行为（错误）。近期研究利用大型语言模型（LLMs）检测错误并引导响应生成模型改进。然而，当前LLMs在识别未明确包含在指令中的错误方面仍然困难，例如响应生成模型更新或用户行为变化导致的错误。在本文中，我们提出了一种自动错误发现框架，用于检测和定义对话AI中的错误，并提出SEEED（Soft Clustering Extended Encoder-Based Error Detection）作为其实现的编码器基方法。我们通过放大负样本的距离权重增强Soft最近邻损失，并引入基于标签的样本排名以选择更具对比性的示例，从而提高表示学习的效果。SEEED在多个错误标注的对话数据集上优于适应基线（包括GPT-4o和Phi-4），检测未知错误的准确率提高最多可达8个百分点，并且在未知意图检测方面表现出强大的泛化能力。', 'title_zh': '面向自动错误发现：基于对话AI的研究'}
{'arxiv_id': 'arXiv:2509.10825', 'title': 'FACTORS: Factorial Approximation for Complementary Two-factor Optimization with Risk-aware Scoring', 'authors': 'Dongseok Kim, Wonjun Jeong, Gisung Oh', 'link': 'https://arxiv.org/abs/2509.10825', 'abstract': 'We propose FACTORS, a framework that combines design of experiments with Shapley decomposition to address performance and stability issues that are sensitive to combinations of training factors. Our approach consistently estimates main effects and two-factor interactions, then integrates them into a risk-adjusted objective function that jointly accounts for uncertainty and cost, enabling reliable selection of configurations under a fixed budget. Effect estimation is implemented through two complementary paths: a plug-in path based on conditional means, and a least-squares path that reconstructs Shapley contributions from samples. These paths are designed to work complementarily even when design density and bias levels differ. By incorporating standardization of estimates, bias correction, and uncertainty quantification, our procedure ensures comparability across heterogeneous factor spaces and designs, while a lightweight search routine yields configurations within practical time even for large factor spaces. On the theoretical side, we provide error decompositions, sample complexity analysis, and upper bounds on optimality gaps. On the interpretive side, we summarize main effects and interactions in map form, highlighting adjustment priorities and safe improvement pathways. Across diverse datasets and design conditions, our approach improves rank preservation and optimal configuration identification, reduces decision-making risks, and offers a tuning foundation that delivers interpretable justification alongside stable performance gains even under budget constraints.', 'abstract_zh': '我们提出FACTORS框架，结合实验设计与Shapley分解，以解决受训练因子组合影响的性能和稳定性问题。该方法一致估计主要效应和两因子交互作用，将它们综合到一个同时考虑不确定性和成本的调整风险目标函数中，从而在固定预算下可靠地选择配置。效应估计通过两条互补路径实现：基于条件均值的插值路径和从样本重建Shapley贡献的最小二乘路径。这些路径即使在设计密度和偏差水平不同的情况下也能互补工作。通过引入估计标准化、偏差校正和不确定性量化，我们的方法确保在异质因子空间和设计之间具有可比性，同时轻量级的搜索程序能够在包含大量因子的空间中在实际时间内获得配置。从理论角度来看，我们提供了误差分解、样本复杂性分析和最优性缺口的上限。从解释角度来看，我们将主要效应和交互作用以地图形式总结，突出调整优先级和安全改进路径。在多样化的数据集和设计条件下，我们的方法改善了排名保真度和最优配置识别，减少了决策风险，并在预算约束下提供了一种可解释的优化基础，伴随稳定的性能提升。', 'title_zh': '因子分析：互补双因子优化的损益感知评分因子近似方法'}
{'arxiv_id': 'arXiv:2509.10809', 'title': 'Rethinking Sparse Autoencoders: Select-and-Project for Fairness and Control from Encoder Features Alone', 'authors': 'Antonio Bărbălau, Cristian Daniel Păduraru, Teodor Poncu, Alexandru Tifrea, Elena Burceanu', 'link': 'https://arxiv.org/abs/2509.10809', 'abstract': 'Sparse Autoencoders (SAEs) have proven valuable due to their ability to provide interpretable and steerable representations. Current debiasing methods based on SAEs manipulate these sparse activations presuming that feature representations are housed within decoder weights. We challenge this fundamental assumption and introduce an encoder-focused alternative for representation debiasing, contributing three key findings: (i) we highlight an unconventional SAE feature selection strategy, (ii) we propose a novel SAE debiasing methodology that orthogonalizes input embeddings against encoder weights, and (iii) we establish a performance-preserving mechanism during debiasing through encoder weight interpolation. Our Selection and Projection framework, termed S\\&P TopK, surpasses conventional SAE usage in fairness metrics by a factor of up to 3.2 and advances state-of-the-art test-time VLM debiasing results by a factor of up to 1.8 while maintaining downstream performance.', 'abstract_zh': 'Sparse 自编码器 (SAEs) 由于能够提供可解释且可操控的表示而证明了其价值。当前基于 SAEs 的去偏方法通过假定特征表示存储在解码器权重中来操纵这些稀疏激活。我们挑战这一基本假设，并提出了一种以编码器为中心的表示去偏替代方法，贡献了三个关键发现：(i) 强调了一种非传统的 SAE 特征选择策略，(ii) 提出了一种新的 SAE 去偏方法，通过对输入嵌入与编码器权重进行正交化，(iii) 在去偏过程中通过编码器权重插值保持性能。我们的选择和投影框架，称为 S&P TopK，通过公平性指标超越了传统的 SAE 使用，最多提高了 3.2 倍，并在测试时 VLM 去偏方面达到了最先进的结果，最多提高了 1.8 倍，同时保持了下游性能。', 'title_zh': '重新思考稀疏自编码器：仅从编码器特征进行选择和投影以实现公平性和控制'}
{'arxiv_id': 'arXiv:2509.10804', 'title': 'Branched Broomrape Detection in Tomato Farms Using Satellite Imagery and Time-Series Analysis', 'authors': 'Mohammadreza Narimani, Alireza Pourreza, Ali Moghimi, Parastoo Farajpoor, Hamid Jafarbiglu, Mohsen Mesgaran', 'link': 'https://arxiv.org/abs/2509.10804', 'abstract': 'Branched broomrape (Phelipanche ramosa (L.) Pomel) is a chlorophyll-deficient parasitic plant that threatens tomato production by extracting nutrients from the host, with reported yield losses up to 80 percent. Its mostly subterranean life cycle and prolific seed production (more than 200,000 seeds per plant, viable for up to 20 years) make early detection essential. We present an end-to-end pipeline that uses Sentinel-2 imagery and time-series analysis to identify broomrape-infested tomato fields in California. Regions of interest were defined from farmer-reported infestations, and images with less than 10 percent cloud cover were retained. We processed 12 spectral bands and sun-sensor geometry, computed 20 vegetation indices (e.g., NDVI, NDMI), and derived five plant traits (Leaf Area Index, Leaf Chlorophyll Content, Canopy Chlorophyll Content, Fraction of Absorbed Photosynthetically Active Radiation, and Fractional Vegetation Cover) using a neural network calibrated with ground-truth and synthetic data. Trends in Canopy Chlorophyll Content delineated transplanting-to-harvest periods, and phenology was aligned using growing degree days. Vegetation pixels were segmented and used to train a Long Short-Term Memory (LSTM) network on 18,874 pixels across 48 growing-degree-day time points. The model achieved 88 percent training accuracy and 87 percent test accuracy, with precision 0.86, recall 0.92, and F1 0.89. Permutation feature importance ranked NDMI, Canopy Chlorophyll Content, FAPAR, and a chlorophyll red-edge index as most informative, consistent with the physiological effects of infestation. Results show the promise of satellite-driven time-series modeling for scalable detection of parasitic stress in tomato farms.', 'abstract_zh': '分支雀舌草（Phelipanche ramosa (L.) Pomel）是一种缺乏叶绿素的寄生植物，通过从宿主体内吸取养分威胁番茄生产，据报道可造成高达80%的产量损失。其主要地下生活史和大量的种子生产（每株植物超过200,000颗种子，可存活长达20年）使其早期检测至关重要。我们提出了一种端到端的工作流程，利用Sentinel-2遥感图像和时间序列分析来识别加利福尼亚受雀舌草寄生的番茄田地。通过农民报告的寄生区划定了感兴趣区域，并保留了云覆盖少于10%的图像。我们处理了12个光谱波段和太阳传感器几何形状，计算了20个植被指数（例如NDVI、NDMI），并通过神经网络利用地面实况和合成数据计算了五种植物特征（叶面积指数、叶叶绿素含量、冠层叶绿素含量、光合有效辐射吸收比例和植被覆盖度）特征。冠层叶绿素含量的趋势划定了移栽到收获的时期，并通过生长度日对植物学阶段进行了对齐。植被像素被分割，并用于在48个生长度日时间点上训练长短期记忆（LSTM）网络，共有18,874个像素。该模型实现了88%的训练准确率和87%的测试准确率，精确度为0.86，召回率为0.92，F1分为0.89。重要性排列特征显示，NDMI、冠层叶绿素含量、FAPAR和叶绿素红边指数是最重要的特征，与寄生的生理影响一致。结果表明，基于卫星的数据驱动时间序列建模在番茄农场中 scalable 检测寄生胁迫具有潜力。', 'title_zh': '使用卫星影像和时间序列分析在番茄农场中检测分枝雀麦草'}
{'arxiv_id': 'arXiv:2509.10798', 'title': 'Judge Q: Trainable Queries for Optimized Information Retention in KV Cache Eviction', 'authors': 'Yijun Liu, Yixuan Wang, Yuzhuang Xu, Shiyu Ji, Yang Xu, Qingfu Zhu, Wanxiang Che', 'link': 'https://arxiv.org/abs/2509.10798', 'abstract': "Large language models (LLMs) utilize key-value (KV) cache to store historical information during sequence processing. The size of KV cache grows linearly as the length of the sequence extends, which seriously affects memory usage and decoding efficiency. Current methods for KV cache eviction typically utilize the last window from the pre-filling phase as queries to compute the KV importance scores for eviction. Although this scheme is simple to implement, it tends to overly focus on local information, potentially leading to the neglect or omission of crucial global information. To mitigate this issue, we propose Judge Q, a novel training method which incorporates a soft token list. This method only tunes the model's embedding layer at a low training cost. By concatenating the soft token list at the end of the input sequence, we train these tokens' attention map to the original input sequence to align with that of the actual decoded tokens. In this way, the queries corresponding to the soft tokens can effectively capture global information and better evaluate the importance of the keys and values within the KV cache, thus maintaining decoding quality when KV cache is evicted. Under the same eviction budget, our method exhibits less performance degradation compared to existing eviction approaches. We validate our approach through experiments conducted on models such as Llama-3.1-8B-Instruct and Mistral-7B-Instruct-v0.3, using benchmarks including LongBench, RULER, and Needle-in-a-Haystack. Results indicate an improvement of approximately 1 point on the LongBench and over 3 points on RULER. This proposed methodology can be seamlessly integrated into existing open-source models with minimal training overhead, thereby enhancing performance in KV cache eviction scenarios.", 'abstract_zh': '大规模语言模型（LLMs）利用键值（KV）缓存存储序列处理过程中的历史信息。随着序列长度的增加，KV缓存的大小线性增长，严重影响了内存使用和解码效率。当前的KV缓存淘汰方法通常利用预填充阶段的最后一个窗口作为查询，计算KV重要性分数以进行淘汰。虽然这种方法实现简单，但往往会过度关注局部信息，可能导致关键全局信息的忽略或遗漏。为缓解这一问题，我们提出了一种新颖的训练方法Judge Q，该方法引入了一个软令牌列表。该方法仅在较低的训练成本下调整模型的嵌入层。通过在输入序列末尾连接软令牌列表，我们训练这些令牌的注意力图与实际解码令牌的注意力图对齐，从而能够有效捕获全局信息并更准确地评估KV缓存中键和值的重要性，从而在KV缓存淘汰时保持解码质量。在相同的淘汰预算下，我们的方法相较于现有方法表现出更少的性能降级。我们通过在Llama-3.1-8B-Instruct和Mistral-7B-Instruct-v0.3等模型上进行实验，并使用LongBench、RULER和Needle-in-a-Haystack等基准测试，验证了该方法的有效性。实验结果表明，该方法在LongBench上的性能提高了约1分，在RULER上的性能提高了超过3分。该提议的方法可以无缝集成到现有的开源模型中，且几乎不增加训练开销，从而在KV缓存淘汰场景中提升了性能。', 'title_zh': '法官Q：可训练查询以优化键值缓存淘汰中的信息保留'}
{'arxiv_id': 'arXiv:2509.10790', 'title': 'GoldenTransformer: A Modular Fault Injection Framework for Transformer Robustness Research', 'authors': 'Luke Howard', 'link': 'https://arxiv.org/abs/2509.10790', 'abstract': 'Transformers have become the foundation for a wide range of state--of--the--art models across natural language processing, computer vision, and other machine learning domains. Despite their widespread deployment, the robustness of these models under fault conditions remains underexplored. We present GoldenTransformer, a modular and extensible fault injection framework designed to evaluate the resiliency of Large Language Models to induced hardware faults. GoldenTransformer offers a unified Python-based platform for injecting diverse classes of faults--such as weight corruption, activation injections, and attention--level disruptions--into pretrained transformer--based models. Inspired by the GoldenEye simulator for DNNs, our framework focuses on the unique challenges of working with large transformer architectures, including considerations such as structural complexity, latent dependencies, and nonuniform layer definitions. GoldenTransformer is built atop PyTorch and HuggingFace Transformers, and it supports experiment reproducibility, metric logging, and visualization out of the box. We detail the technical design and use of GoldenTransformer and demonstrate through several example experiments on classification and generation tasks. By enabling controlled injection of faults at multiple logical and structural points in a transformer, GoldenTransformer offers researchers and practitioners a valuable tool for model robustness analysis and for guiding dependable system design in real-world LLM applications.', 'abstract_zh': '变压器已成为自然语言处理、计算机视觉和其他机器学习领域中众多前沿模型的基础。尽管这些模型被广泛部署，但在故障条件下的鲁棒性仍鲜有研究。我们介绍了GoldenTransformer，这是一个模块化和可扩展的故障注入框架，旨在评估大型语言模型在诱导硬件故障情况下的韧性。GoldenTransformer提供了一个统一的基于Python的平台，用于向预训练的基于变压器的模型注入多种类型的故障，如权重篡改、激活注入和注意力层面的干扰。灵感来源于DNN领域的GoldenEye模拟器，我们的框架重点关注大规模变压器架构特有的挑战，包括结构复杂性、潜在依赖性和非均匀的层定义。GoldenTransformer基于PyTorch和HuggingFace Transformers构建，支持实验的可重复性、指标日志记录和可视化。我们详细介绍了GoldenTransformer的技术设计和使用方法，并通过几个分类和生成任务的示例实验进行了演示。通过在变压器中的多个逻辑和结构点上实现可控的故障注入，GoldenTransformer为研究者和从业者提供了一个有价值的工具，用于模型鲁棒性分析，并指导实际应用中可靠系统的设计。', 'title_zh': 'GoldenTransformer：一个用于Transformer鲁棒性研究的模块化故障注入框架'}
{'arxiv_id': 'arXiv:2509.10780', 'title': 'Bridging Cultural Distance Between Models Default and Local Classroom Demands: How Global Teachers Adopt GenAI to Support Everyday Teaching Practices', 'authors': 'Ruiwei Xiao, Qing Xiao, Xinying Hou, Hanqi Jane Li, Phenyo Phemelo Moletsane, Hong Shen, John Stamper', 'link': 'https://arxiv.org/abs/2509.10780', 'abstract': 'Generative AI (GenAI) is rapidly entering K-12 classrooms, offering teachers new ways for teaching practices. Yet GenAI models are often trained on culturally uneven datasets, embedding a "default culture" that often misaligns with local classrooms. To understand how teachers navigate this gap, we defined the new concept Cultural Distance (the gap between GenAI\'s default cultural repertoire and the situated demands of teaching practice) and conducted in-depth interviews with 30 K-12 teachers, 10 each from South Africa, Taiwan, and the United States, who had integrated AI into their teaching practice. These teachers\' experiences informed the development of our three-level cultural distance framework. This work contributes the concept and framework of cultural distance, six illustrative instances spanning in low, mid, high distance levels with teachers\' experiences and strategies for addressing them. Empirically, we offer implications to help AI designers, policymakers, and educators create more equitable and culturally responsive GenAI tools for education.', 'abstract_zh': '生成式AI（GenAI）正迅速进入K-12课堂，为教学实践提供了新的方法。然而，GenAI模型经常使用文化不均衡的数据集进行训练，嵌入了一种“默认文化”，这往往与本地教室的需求不一致。为了理解教师如何克服这种差距，我们定义了新的概念文化距离（GenAI的默认文化库与教学实践中的情境需求之间的差距），并深入访谈了30名来自南非、台湾和美国的K-12教师，这些教师已经在教学中整合了人工智能。这些教师的经验指导了我们三层文化距离框架的开发。这项工作贡献了文化距离的概念和框架，以及涵盖低、中、高文化距离级别的六个实例，包括教师的经验和应对策略。实证研究提供了建议，旨在帮助AI设计师、政策制定者和教育工作者为教育创建更加公平和文化响应的GenAI工具。', 'title_zh': '跨越模型默认设置与当地教室需求的文化距离：全球教师如何采用生成式AI支持日常教学实践'}
{'arxiv_id': 'arXiv:2509.10777', 'title': 'Contextual Budget Bandit for Food Rescue Volunteer Engagement', 'authors': 'Ariana Tang, Naveen Raman, Fei Fang, Zheyuan Ryan Shi', 'link': 'https://arxiv.org/abs/2509.10777', 'abstract': 'Volunteer-based food rescue platforms tackle food waste by matching surplus food to communities in need. These platforms face the dual problem of maintaining volunteer engagement and maximizing the food rescued. Existing algorithms to improve volunteer engagement exacerbate geographical disparities, leaving some communities systematically disadvantaged. We address this issue by proposing Contextual Budget Bandit. Contextual Budget Bandit incorporates context-dependent budget allocation in restless multi-armed bandits, a model of decision-making which allows for stateful arms. By doing so, we can allocate higher budgets to communities with lower match rates, thereby alleviating geographical disparities. To tackle this problem, we develop an empirically fast heuristic algorithm. Because the heuristic algorithm can achieve a poor approximation when active volunteers are scarce, we design the Mitosis algorithm, which is guaranteed to compute the optimal budget allocation. Empirically, we demonstrate that our algorithms outperform baselines on both synthetic and real-world food rescue datasets, and show how our algorithm achieves geographical fairness in food rescue.', 'abstract_zh': '基于志愿者的食品救援平台通过匹配过剩食品与有需求的社区来解决食品浪费问题。这些平台面临维持志愿者参与和最大化救援食品的双重挑战。现有的提高志愿者参与度的算法加剧了地理层面的不平等，使一些社区处于系统性劣势。我们通过提出上下文预算-bandit（Contextual Budget Bandit）来解决这一问题。上下文预算-bandit 在活跃臂可以保持状态的无奈多臂老虎机模型中融入了情境相关的预算分配，这样可以将更高预算分配给匹配率较低的社区，从而缓解地理不平等。为解决这一问题，我们开发了一种经验上快速的启发式算法。由于在活跃志愿者稀缺时启发式算法可能会产生较差的近似结果，我们设计了保证能够计算最优预算分配的Mitosis算法。实证研究表明，我们的算法在合成和真实食品救援数据集上均优于基线算法，并展示了我们的算法如何在食品救援中实现地理公平性。', 'title_zh': '基于上下文的预算多臂老虎机模型：应用于食品救援志愿者参与'}
{'arxiv_id': 'arXiv:2509.10766', 'title': 'A Content-dependent Watermark for Safeguarding Image Attribution', 'authors': 'Tong Zhou, Ruyi Ding, Gaowen Liu, Charles Fleming, Ramana Rao Kompella, Yunsi Fei, Xiaolin Xu, Shaolei Ren', 'link': 'https://arxiv.org/abs/2509.10766', 'abstract': 'The rapid growth of digital and AI-generated images has amplified the need for secure and verifiable methods of image attribution. While digital watermarking offers more robust protection than metadata-based approaches--which can be easily stripped--current watermarking techniques remain vulnerable to forgery, creating risks of misattribution that can damage the reputations of AI model developers and the rights of digital artists. These vulnerabilities arise from two key issues: (1) content-agnostic watermarks, which, once learned or leaked, can be transferred across images to fake attribution, and (2) reliance on detector-based verification, which is unreliable since detectors can be tricked. We present MetaSeal, a novel framework for content-dependent watermarking with cryptographic security guarantees to safeguard image attribution. Our design provides (1) forgery resistance, preventing unauthorized replication and enforcing cryptographic verification; (2) robust, self-contained protection, embedding attribution directly into images while maintaining resilience against benign transformations; and (3) evidence of tampering, making malicious alterations visually detectable. Experiments demonstrate that MetaSeal effectively mitigates forgery attempts and applies to both natural and AI-generated images, establishing a new standard for secure image attribution.', 'abstract_zh': '数字和AI生成图像的迅速增长加大了对安全可验证的图像归属方法的需求。现有的水印技术虽比基于元数据的方法提供了更 robust 的保护，但也存在伪造风险，这可能导致误归属，损害AI模型开发者和数字艺术家的声誉。这些漏洞源于两个核心问题：(1) 内容无关的水印一旦被学习或泄露，可以跨图像转移伪造归属，(2) 依赖检测器验证，但由于检测器可被欺骗，因此不可靠。我们提出了一种名为MetaSeal的新型框架，提供基于内容的水印技术和 cryptographic 安全保证以保护图像归属。该设计包括：(1) 抵抗伪造，防止未经授权复制并强制执行 cryptographic 验证；(2) 强大且自包含的保护，直接将归属嵌入图像中，同时保持对良性变换的鲁棒性；以及(3) 恶意篡改的视觉证据，使恶意修改可被视觉检测到。实验表明，MetaSeal 有效地抵御了伪造尝试，并适用于自然和AI生成的图像，从而确立了安全图像归属的新标准。', 'title_zh': '基于内容的水印用于保护图像 Attribution'}
{'arxiv_id': 'arXiv:2509.10753', 'title': 'HalluField: Detecting LLM Hallucinations via Field-Theoretic Modeling', 'authors': 'Minh Vu, Brian K. Tran, Syed A. Shah, Geigh Zollicoffer, Nhat Hoang-Xuan, Manish Bhattarai', 'link': 'https://arxiv.org/abs/2509.10753', 'abstract': "Large Language Models (LLMs) exhibit impressive reasoning and question-answering capabilities. However, they often produce inaccurate or unreliable content known as hallucinations. This unreliability significantly limits their deployment in high-stakes applications. Thus, there is a growing need for a general-purpose method to detect hallucinations in LLMs. In this work, we introduce HalluField, a novel field-theoretic approach for hallucination detection based on a parametrized variational principle and thermodynamics. Inspired by thermodynamics, HalluField models an LLM's response to a given query and temperature setting as a collection of discrete likelihood token paths, each associated with a corresponding energy and entropy. By analyzing how energy and entropy distributions vary across token paths under changes in temperature and likelihood, HalluField quantifies the semantic stability of a response. Hallucinations are then detected by identifying unstable or erratic behavior in this energy landscape. HalluField is computationally efficient and highly practical: it operates directly on the model's output logits without requiring fine-tuning or auxiliary neural networks. Notably, the method is grounded in a principled physical interpretation, drawing analogies to the first law of thermodynamics. Remarkably, by modeling LLM behavior through this physical lens, HalluField achieves state-of-the-art hallucination detection performance across models and datasets.", 'abstract_zh': '基于场论的幻觉检测方法：HalluField', 'title_zh': 'HalluField：基于场论建模的LLM幻觉检测'}
{'arxiv_id': 'arXiv:2509.10744', 'title': 'Automated MCQA Benchmarking at Scale: Evaluating Reasoning Traces as Retrieval Sources for Domain Adaptation of Small Language Models', 'authors': 'Ozan Gokdemir, Neil Getty, Robert Underwood, Sandeep Madireddy, Franck Cappello, Arvind Ramanathan, Ian T. Foster, Rick L. Stevens', 'link': 'https://arxiv.org/abs/2509.10744', 'abstract': 'As scientific knowledge grows at an unprecedented pace, evaluation benchmarks must evolve to reflect new discoveries and ensure language models are tested on current, diverse literature. We propose a scalable, modular framework for generating multiple-choice question-answering (MCQA) benchmarks directly from large corpora of scientific papers. Our pipeline automates every stage of MCQA creation, including PDF parsing, semantic chunking, question generation, and model evaluation. As a case study, we generate more than 16,000 MCQs from 22,000 open-access articles in radiation and cancer biology. We then evaluate a suite of small language models (1.1B-14B parameters) on these questions, comparing baseline accuracy with retrieval-augmented generation (RAG) from paper-derived semantic chunks and from reasoning traces distilled from GPT-4.1. We find that reasoning-trace retrieval consistently improves performance on both synthetic and expert-annotated benchmarks, enabling several small models to surpass GPT-4 on the 2023 Astro Radiation and Cancer Biology exam.', 'abstract_zh': '随着科学知识以前所未有的速度增长，评估基准必须随之演进而反映新的发现，并确保语言模型能够被测试于当前多样化的文献上。我们提出了一种可扩展且模块化的框架，直接从大规模的科学论文 corpora 中生成多项选择题-答案（MCQA）基准。我们的管道自动化了 MCQA 创建过程中的每一个阶段，包括 PDF 解析、语义切块、问题生成和模型评估。作为案例研究，我们从 22,000 篇开放获取的辐射和癌症生物学论文中生成了超过 16,000 个 MCQ。然后，我们在这些题目上评估一系列小型语言模型（参数量从 11 亿到 140 亿不等），并将基于论文提取的语义切块的检索增强生成（RAG）方法与从 GPT-4.1 精练推理踪迹的方法进行比较。我们发现，基于推理踪迹的检索在合成基准和专家注释基准中均能持续提升性能，使得某些小型模型超越了 GPT-4 在 2023 年天体辐射和癌症生物学考试中的表现。', 'title_zh': '大规模自动化MCQA基准评估：将推理追踪作为小型语言模型领域适应的检索来源进行评估'}
{'arxiv_id': 'arXiv:2509.10723', 'title': 'Dark Patterns Meet GUI Agents: LLM Agent Susceptibility to Manipulative Interfaces and the Role of Human Oversight', 'authors': 'Jingyu Tang, Chaoran Chen, Jiawen Li, Zhiping Zhang, Bingcan Guo, Ibrahim Khalilov, Simret Araya Gebreegziabher, Bingsheng Yao, Dakuo Wang, Yanfang Ye, Tianshi Li, Ziang Xiao, Yaxing Yao, Toby Jia-Jun Li', 'link': 'https://arxiv.org/abs/2509.10723', 'abstract': 'The dark patterns, deceptive interface designs manipulating user behaviors, have been extensively studied for their effects on human decision-making and autonomy. Yet, with the rising prominence of LLM-powered GUI agents that automate tasks from high-level intents, understanding how dark patterns affect agents is increasingly important. We present a two-phase empirical study examining how agents, human participants, and human-AI teams respond to 16 types of dark patterns across diverse scenarios. Phase 1 highlights that agents often fail to recognize dark patterns, and even when aware, prioritize task completion over protective action. Phase 2 revealed divergent failure modes: humans succumb due to cognitive shortcuts and habitual compliance, while agents falter from procedural blind spots. Human oversight improved avoidance but introduced costs such as attentional tunneling and cognitive load. Our findings show neither humans nor agents are uniformly resilient, and collaboration introduces new vulnerabilities, suggesting design needs for transparency, adjustable autonomy, and oversight.', 'abstract_zh': '基于LLM的GUI代理中暗模式的影响：两阶段实证研究', 'title_zh': '暗模式碰上GUI代理：LLM代理对 manipulative界面的易感性及人类监督的作用'}
{'arxiv_id': 'arXiv:2509.10695', 'title': 'Kalman Bayesian Transformer', 'authors': 'Haoming Jing, Oren Wright, José M. F. Moura, Yorie Nakahira', 'link': 'https://arxiv.org/abs/2509.10695', 'abstract': 'Sequential fine-tuning of transformers is useful when new data arrive sequentially, especially with shifting distributions. Unlike batch learning, sequential learning demands that training be stabilized despite a small amount of data by balancing new information and previously learned knowledge in the pre-trained models. This challenge is further complicated when training is to be completed in latency-critical environments and learning must additionally quantify and be mediated by uncertainty. Motivated by these challenges, we propose a novel method that frames sequential fine-tuning as a posterior inference problem within a Bayesian framework. Our approach integrates closed-form moment propagation of random variables, Kalman Bayesian Neural Networks, and Taylor approximations of the moments of softmax functions. By explicitly accounting for pre-trained models as priors and adaptively balancing them against new information based on quantified uncertainty, our method achieves robust and data-efficient sequential learning. The effectiveness of our method is demonstrated through numerical simulations involving sequential adaptation of a decision transformer to tasks characterized by distribution shifts and limited memory resources.', 'abstract_zh': '基于贝叶斯框架的闭形式矩传播和卡尔曼贝叶斯神经网络的序贯微调新方法', 'title_zh': 'Kalman-Bayesian Transformer'}
{'arxiv_id': 'arXiv:2509.10693', 'title': 'Learning Concave Bid Shading Strategies in Online Auctions via Measure-valued Proximal Optimization', 'authors': 'Iman Nodozi, Djordje Gligorijevic, Abhishek Halder', 'link': 'https://arxiv.org/abs/2509.10693', 'abstract': 'This work proposes a bid shading strategy for first-price auctions as a measure-valued optimization problem. We consider a standard parametric form for bid shading and formulate the problem as convex optimization over the joint distribution of shading parameters. After each auction, the shading parameter distribution is adapted via a regularized Wasserstein-proximal update with a data-driven energy functional. This energy functional is conditional on the context, i.e., on publisher/user attributes such as domain, ad slot type, device, or location. The proposed algorithm encourages the bid distribution to place more weight on values with higher expected surplus, i.e., where the win probability and the value gap are both large. We show that the resulting measure-valued convex optimization problem admits a closed form solution. A numerical example illustrates the proposed method.', 'abstract_zh': '本研究提出了一种针对首价拍卖的出价遮蔽策略，将其形式化为测度值优化问题。我们考虑标准参数形式的出价遮蔽，并将问题形式化为联合分布下遮蔽参数的凸优化问题。每次拍卖后，通过带有数据驱动能量函数的正则化 Wasserstein 近邻更新来调整遮蔽参数分布。该能量函数基于上下文，如发布者/用户属性（如领域、广告槽类型、设备或位置）。所提出的算法鼓励出价分布将更多权重分配给预期剩余价值较高的值，即赢标概率和价值差距都较大的地方。我们证明了由此产生的测度值凸优化问题具有闭式解。数值例子阐述了所提出的方法。', 'title_zh': '通过测度值 proximal 优化学习在线拍卖中的凹投标阴影策略'}
{'arxiv_id': 'arXiv:2509.10691', 'title': 'Privacy-Preserving Decentralized Federated Learning via Explainable Adaptive Differential Privacy', 'authors': 'Fardin Jalil Piran, Zhiling Chen, Yang Zhang, Qianyu Zhou, Jiong Tang, Farhad Imani', 'link': 'https://arxiv.org/abs/2509.10691', 'abstract': 'Decentralized federated learning faces privacy risks because model updates can leak data through inference attacks and membership inference, a concern that grows over many client exchanges. Differential privacy offers principled protection by injecting calibrated noise so confidential information remains secure on resource-limited IoT devices. Yet without transparency, black-box training cannot track noise already injected by previous clients and rounds, which forces worst-case additions and harms accuracy. We propose PrivateDFL, an explainable framework that joins hyperdimensional computing with differential privacy and keeps an auditable account of cumulative noise so each client adds only the difference between the required noise and what has already been accumulated. We evaluate on MNIST, ISOLET, and UCI-HAR to span image, signal, and tabular modalities, and we benchmark against transformer-based and deep learning-based baselines trained centrally with Differentially Private Stochastic Gradient Descent (DP-SGD) and Renyi Differential Privacy (RDP). PrivateDFL delivers higher accuracy, lower latency, and lower energy across IID and non-IID partitions while preserving formal (epsilon, delta) guarantees and operating without a central server. For example, under non-IID partitions, PrivateDFL achieves 24.42% higher accuracy than the Vision Transformer on MNIST while using about 10x less training time, 76x lower inference latency, and 11x less energy, and on ISOLET it exceeds Transformer accuracy by more than 80% with roughly 10x less training time, 40x lower inference latency, and 36x less training energy. Future work will extend the explainable accounting to adversarial clients and adaptive topologies with heterogeneous privacy budgets.', 'abstract_zh': '去中心联邦学习面临隐私风险，因为模型更新可能通过推断攻击和成员推断泄露数据，这种风险随着客户端交换次数增加而增大。差分隐私通过注入校准噪声提供 principled 保护，确保在资源有限的物联网设备上保密信息的安全。然而，缺乏透明性使得黑盒训练无法跟踪之前客户端和轮次已注入的噪声，这导致最坏情况下的添加并损害准确性。我们提出了一个可解释框架 PrivateDFL，该框架将超维度计算与差分隐私相结合，并保持可审计的累积噪声记录，使得每个客户端仅添加所需的噪声与已积累的噪声之间的差异。我们在 MNIST、ISOLET 和 UCI-HAR 上进行评估，涵盖了图像、信号和表格模态，并与使用 Differentially Private Stochastic Gradient Descent (DP-SGD) 和 Rényi 差分隐私 (RDP) 中心训练的 Transformer 基线和深度学习基线进行基准测试。PrivateDFL 在同质划分和非同质划分中均实现了更高的准确率、更低的延迟和更低的能耗，同时保持形式化（ε, δ）保证，并且无需中央服务器。例如，在非同质划分下，PrivateDFL 在 MNIST 上比 Vision Transformer 的准确率高出 24.42%，同时训练时间减少约 10 倍，推断延迟降低约 76 倍，能耗降低约 11 倍；在 ISOLET 上，它比 Transformer 的准确率高出超过 80%，训练时间减少约 10 倍，推断延迟降低约 40 倍，训练能耗降低约 36 倍。未来的工作将扩展可解释的会计记录到 adversarial 客户端和具有异构隐私预算的自适应拓扑结构。', 'title_zh': '基于可解释自适应差分隐私的隐私保护去中心化联邦学习'}
{'arxiv_id': 'arXiv:2509.10685', 'title': 'Pluralistic Alignment for Healthcare: A Role-Driven Framework', 'authors': 'Jiayou Zhong, Anudeex Shetty, Chao Jia, Xuanrui Lin, Usman Naseem', 'link': 'https://arxiv.org/abs/2509.10685', 'abstract': 'As large language models are increasingly deployed in sensitive domains such as healthcare, ensuring their outputs reflect the diverse values and perspectives held across populations is critical. However, existing alignment approaches, including pluralistic paradigms like Modular Pluralism, often fall short in the health domain, where personal, cultural, and situational factors shape pluralism. Motivated by the aforementioned healthcare challenges, we propose a first lightweight, generalizable, pluralistic alignment approach, EthosAgents, designed to simulate diverse perspectives and values. We empirically show that it advances the pluralistic alignment for all three modes across seven varying-sized open and closed models. Our findings reveal that health-related pluralism demands adaptable and normatively aware approaches, offering insights into how these models can better respect diversity in other high-stakes domains.', 'abstract_zh': '大语言模型在医疗等敏感领域日益普及，确保其输出反映不同人群持有的多元价值观和视角至关重要。然而，现有的对齐方法，包括模块化多元主义等多元主义范式，在医疗领域往往难以奏效，因为个人、文化和社会情境因素影响着多元主义的形态。为应对上述医疗挑战，我们提出了一种轻量级、可泛化的多元主义对齐方法EthosAgents，旨在模拟多元的视角和价值观。实验证明，该方法在七个不同规模的开放和封闭模型中跨三种模式推进了多元主义对齐。研究结果表明，与健康相关的多元主义需要适应性和规范意识更强的方法，为其他高风险领域如何更好地尊重多元化提供了见解。', 'title_zh': '医疗领域多样化的对齐：一种角色驱动的框架'}
{'arxiv_id': 'arXiv:2509.10683', 'title': 'A Comparison and Evaluation of Fine-tuned Convolutional Neural Networks to Large Language Models for Image Classification and Segmentation of Brain Tumors on MRI', 'authors': 'Felicia Liu, Jay J. Yoo, Farzad Khalvati', 'link': 'https://arxiv.org/abs/2509.10683', 'abstract': 'Large Language Models (LLMs) have shown strong performance in text-based healthcare tasks. However, their utility in image-based applications remains unexplored. We investigate the effectiveness of LLMs for medical imaging tasks, specifically glioma classification and segmentation, and compare their performance to that of traditional convolutional neural networks (CNNs). Using the BraTS 2020 dataset of multi-modal brain MRIs, we evaluated a general-purpose vision-language LLM (LLaMA 3.2 Instruct) both before and after fine-tuning, and benchmarked its performance against custom 3D CNNs. For glioma classification (Low-Grade vs. High-Grade), the CNN achieved 80% accuracy and balanced precision and recall. The general LLM reached 76% accuracy but suffered from a specificity of only 18%, often misclassifying Low-Grade tumors. Fine-tuning improved specificity to 55%, but overall performance declined (e.g., accuracy dropped to 72%). For segmentation, three methods - center point, bounding box, and polygon extraction, were implemented. CNNs accurately localized gliomas, though small tumors were sometimes missed. In contrast, LLMs consistently clustered predictions near the image center, with no distinction of glioma size, location, or placement. Fine-tuning improved output formatting but failed to meaningfully enhance spatial accuracy. The bounding polygon method yielded random, unstructured outputs. Overall, CNNs outperformed LLMs in both tasks. LLMs showed limited spatial understanding and minimal improvement from fine-tuning, indicating that, in their current form, they are not well-suited for image-based tasks. More rigorous fine-tuning or alternative training strategies may be needed for LLMs to achieve better performance, robustness, and utility in the medical space.', 'abstract_zh': '大型语言模型在基于图像的医疗影像任务中的有效性及其与传统卷积神经网络的比较', 'title_zh': '细调卷积神经网络与大型语言模型在MRI脑肿瘤图像分类与分割中的对比与评估'}
{'arxiv_id': 'arXiv:2509.10682', 'title': 'LLM in the Middle: A Systematic Review of Threats and Mitigations to Real-World LLM-based Systems', 'authors': 'Vitor Hugo Galhardo Moia, Igor Jochem Sanz, Gabriel Antonio Fontes Rebello, Rodrigo Duarte de Meneses, Briland Hitaj, Ulf Lindqvist', 'link': 'https://arxiv.org/abs/2509.10682', 'abstract': 'The success and wide adoption of generative AI (GenAI), particularly large language models (LLMs), has attracted the attention of cybercriminals seeking to abuse models, steal sensitive data, or disrupt services. Moreover, providing security to LLM-based systems is a great challenge, as both traditional threats to software applications and threats targeting LLMs and their integration must be mitigated. In this survey, we shed light on security and privacy concerns of such LLM-based systems by performing a systematic review and comprehensive categorization of threats and defensive strategies considering the entire software and LLM life cycles. We analyze real-world scenarios with distinct characteristics of LLM usage, spanning from development to operation. In addition, threats are classified according to their severity level and to which scenarios they pertain, facilitating the identification of the most relevant threats. Recommended defense strategies are systematically categorized and mapped to the corresponding life cycle phase and possible attack strategies they attenuate. This work paves the way for consumers and vendors to understand and efficiently mitigate risks during integration of LLMs in their respective solutions or organizations. It also enables the research community to benefit from the discussion of open challenges and edge cases that may hinder the secure and privacy-preserving adoption of LLM-based systems.', 'abstract_zh': '生成型人工智能（GenAI），特别是大型语言模型（LLMs）的成功及其广泛应用引起了网络犯罪分子的注意，他们试图滥用这些模型、窃取敏感数据或扰乱服务。此外，保障基于LLM的系统的安全是一项巨大挑战，因为必须同时缓解针对软件应用程序的传统威胁和针对LLM及其集成的威胁。在这篇综述中，我们通过对软件和LLM生命周期进行全面系统性审查和分类，揭示了基于LLM系统的安全和隐私关切。我们分析了从开发到运营的不同LLM使用场景下的实际场景，根据威胁的严重程度及其适用的场景对威胁进行了分类，有助于识别最相关的威胁。推荐的防御策略被系统地分类，并与相应的生活周期阶段以及它们可以减轻的攻击策略进行映射。这项工作为消费者和供应商提供了理解并有效地缓解在各自解决方案或组织中整合LLM时的风险的途径。同时，它也为研究社区提供了讨论可能阻碍基于LLM系统的安全和隐私保护采用的开放挑战和边缘案例的机会。', 'title_zh': 'LLM居中：面向现实世界的大语言模型威胁与缓解措施系统的综述'}
{'arxiv_id': 'arXiv:2509.10656', 'title': 'Self-Supervised Goal-Reaching Results in Multi-Agent Cooperation and Exploration', 'authors': 'Chirayu Nimonkar, Shlok Shah, Catherine Ji, Benjamin Eysenbach', 'link': 'https://arxiv.org/abs/2509.10656', 'abstract': 'For groups of autonomous agents to achieve a particular goal, they must engage in coordination and long-horizon reasoning. However, designing reward functions to elicit such behavior is challenging. In this paper, we study how self-supervised goal-reaching techniques can be leveraged to enable agents to cooperate. The key idea is that, rather than have agents maximize some scalar reward, agents aim to maximize the likelihood of visiting a certain goal. This problem setting enables human users to specify tasks via a single goal state rather than implementing a complex reward function. While the feedback signal is quite sparse, we will demonstrate that self-supervised goal-reaching techniques enable agents to learn from such feedback. On MARL benchmarks, our proposed method outperforms alternative approaches that have access to the same sparse reward signal as our method. While our method has no explicit mechanism for exploration, we observe that self-supervised multi-agent goal-reaching leads to emergent cooperation and exploration in settings where alternative approaches never witness a single successful trial.', 'abstract_zh': '自主代理群体实现特定目标时需要进行协调和长视角推理，设计能够激发这种行为的奖励函数具有挑战性。本文研究如何利用自我监督的目的达成技术使代理能够进行合作。关键思想是，不是让代理最大化某个标量奖励，而是让代理最大化访问特定目标的可能性。这种问题设置使得人类用户可以通过指定单个目标状态来说明任务，而无需实现复杂的奖励函数。尽管反馈信号非常稀疏，我们证明自我监督的目的达成技术仍能使代理从这样的反馈中学习。在多智能体强化学习基准测试中，我们提出的方法在可以访问相同稀疏奖励信号的替代方法中表现出色。虽然我们的方法没有显式探索机制，但我们观察到自我监督的多代理目的达成会导致在替代方法从未见证成功的场景中出现自发的合作和探索。', 'title_zh': '自我监督的目标导向学习促进多智能体的合作与探索'}
{'arxiv_id': 'arXiv:2509.10653', 'title': 'SCOR: A Framework for Responsible AI Innovation in Digital Ecosystems', 'authors': 'Mohammad Saleh Torkestani, Taha Mansouri', 'link': 'https://arxiv.org/abs/2509.10653', 'abstract': 'AI-driven digital ecosystems span diverse stakeholders including technology firms, regulators, accelerators and civil society, yet often lack cohesive ethical governance. This paper proposes a four-pillar framework (SCOR) to embed accountability, fairness, and inclusivity across such multi-actor networks. Leveraging a design science approach, we develop a Shared Ethical Charter(S), structured Co-Design and Stakeholder Engagement protocols(C), a system of Continuous Oversight and Learning(O), and Adaptive Regulatory Alignment strategies(R). Each component includes practical guidance, from lite modules for resource-constrained start-ups to in-depth auditing systems for larger consortia. Through illustrative vignettes in healthcare, finance, and smart city contexts, we demonstrate how the framework can harmonize organizational culture, leadership incentives, and cross-jurisdictional compliance. Our mixed-method KPI design further ensures that quantitative targets are complemented by qualitative assessments of user trust and cultural change. By uniting ethical principles with scalable operational structures, this paper offers a replicable pathway toward responsible AI innovation in complex digital ecosystems.', 'abstract_zh': 'AI驱动的数字生态系统跨越多元利益相关者，包括技术公司、监管机构、加速器和民间社会，但往往缺乏统一的伦理治理。本文提出一种四支柱框架（SCOR），以嵌入问责、公平和包容性于此类多利益相关者网络中。基于设计科学方法，我们开发了一个共同的伦理宪章（S）、结构化的共同设计和利益相关者参与协议（C）、持续监督和学习体系（O），以及适应性监管对齐策略（R）。每个组成部分自资源受限的初创公司的轻量级模块到大型联盟的深度审计系统，均包含实用指导。通过医疗保健、金融和智慧城市背景下的示例情景，展示框架如何协调组织文化、领导激励和跨司法辖区合规性。我们的混合方法KPI设计进一步确保了定量目标与用户信任和文化变革的定性评估相补充。通过将伦理原则与可扩展的操作结构相结合，本文为复杂数字生态系统中的负责任AI创新提供了一种可复制的道路。', 'title_zh': 'SCOR：数字生态系统中负责任的AI创新框架'}
{'arxiv_id': 'arXiv:2509.10652', 'title': "Vibe Coding for UX Design: Understanding UX Professionals' Perceptions of AI-Assisted Design and Development", 'authors': 'Jie Li, Youyang Hou, Laura Lin, Ruihao Zhu, Hancheng Cao, Abdallah El Ali', 'link': 'https://arxiv.org/abs/2509.10652', 'abstract': 'Generative AI is reshaping UX design practices through "vibe coding," where UX professionals express intent in natural language and AI translates it into functional prototypes and code. Despite rapid adoption, little research has examined how vibe coding reconfigures UX workflows and collaboration. Drawing on interviews with 20 UX professionals across enterprises, startups, and academia, we show how vibe coding follows a four-stage workflow of ideation, AI generation, debugging, and review. This accelerates iteration, supports creativity, and lowers barriers to participation. However, professionals reported challenges of code unreliability, integration, and AI over-reliance. We find tensions between efficiency-driven prototyping ("intending the right design") and reflection ("designing the right intention"), introducing new asymmetries in trust, responsibility, and social stigma within teams. Through the lens of responsible human-AI collaboration for AI-assisted UX design and development, we contribute a deeper understanding of deskilling, ownership and disclosure, and creativity safeguarding in the age of vibe coding.', 'abstract_zh': '生成式AI通过“氛围编码”重塑UX设计实践：从创想到审查的四阶段工作流及其实质分析', 'title_zh': '用户体验设计中的Vibe编码：理解用户体验专业人士对AI辅助设计与开发的看法'}
{'arxiv_id': 'arXiv:2509.10641', 'title': 'Test-Time Warmup for Multimodal Large Language Models', 'authors': 'Nikita Rajaneesh, Thomas Zollo, Richard Zemel', 'link': 'https://arxiv.org/abs/2509.10641', 'abstract': "Multimodal Large Language Models (MLLMs) hold great promise for advanced reasoning at the intersection of text and images, yet they have not fully realized this potential. MLLMs typically integrate an LLM, a vision encoder, and a connector that maps the vision encoder's embeddings into the LLM's text embedding space. Although each component is pretrained on massive datasets with billions of samples, the entire multimodal model is typically trained on only thousands (or a few million) samples, which can result in weak performance on complex reasoning tasks. To address these shortcomings, instead of relying on extensive labeled datasets for fine-tuning, we propose a Test-Time Warmup method that adapts the MLLM per test instance by leveraging data from weakly supervised auxiliary tasks. With our approach, we observe a relative performance improvement of 4.03% on MMMU, 5.28% on VQA-Rad, and 1.63% on GQA on the Llama-Vision-Instruct model. Our method demonstrates that 'warming up' before inference can enhance MLLMs' robustness across diverse reasoning tasks.", 'abstract_zh': '多模态大型语言模型（MLLMs）在文本和图像交叉领域的高级推理方面展现出巨大潜力，但尚未充分实现这一潜力。尽管MLLMs通常包括一个大型语言模型、一个视觉编码器以及一个连接器将视觉编码器的嵌入映射到大型语言模型的文本嵌入空间，每个组件都预训练在包含数十亿样本的巨大数据集上，但整个多模态模型通常仅在成千上万（或几百万）样本上进行训练，这可能导致在复杂推理任务上的表现较弱。为解决这些不足，我们提出了一种测试时预热方法，该方法通过利用弱监督辅助任务的数据来适应每个测试实例的MLLM，而不需要依赖大量标注的数据集进行微调。在我们的方法下，我们在MMMU上的相对性能改进为4.03%，在VQA-Rad上的相对性能改进为5.28%，在GQA上的相对性能改进为1.63%，基于Llama-Vision-Instruct模型。我们的方法表明，在推理前进行“预热”可以增强MLLMs在各种推理任务中的鲁棒性。', 'title_zh': '多模态大语言模型的测试时预热'}
{'arxiv_id': 'arXiv:2509.10626', 'title': 'Optimal Multimarginal Schrödinger Bridge: Minimum Spanning Tree over Measure-valued Vertices', 'authors': 'Georgiy A. Bondar, Abhishek Halder', 'link': 'https://arxiv.org/abs/2509.10626', 'abstract': 'The Multimarginal Schrödinger Bridge (MSB) finds the optimal coupling among a collection of random vectors with known statistics and a known correlation structure. In the MSB formulation, this correlation structure is specified \\emph{a priori} as an undirected connected graph with measure-valued vertices. In this work, we formulate and solve the problem of finding the optimal MSB in the sense we seek the optimal coupling over all possible graph structures. We find that computing the optimal MSB amounts to solving the minimum spanning tree problem over measure-valued vertices. We show that the resulting problem can be solved in two steps. The first step constructs a complete graph with edge weight equal to a sum of the optimal value of the corresponding bimarginal SB and the entropies of the endpoints. The second step solves a standard minimum spanning tree problem over that complete weighted graph. Numerical experiments illustrate the proposed solution.', 'abstract_zh': '多边际薛定谔桥（MSB）在已知统计数据和相关结构的情况下，寻找一组随机向量的最佳耦合。在MSB形式化中，这种相关结构被先验地指定为一个具有测度顶点的无向连通图。在本文中，我们提出了在所有可能的图结构中寻找最优MSB的问题，并发现计算最优MSB等同于在测度顶点上求解最小生成树问题。我们证明了该问题可以分为两步求解。第一步构造一个完整的图，边权重等于相应双边际SB的最优值和端点熵之和。第二步在该加权完全图上求解标准的最小生成树问题。数值实验验证了提出的方法。', 'title_zh': '最优多边际薛定谔桥：测度值顶点的最小生成树'}
{'arxiv_id': 'arXiv:2509.10625', 'title': 'No Answer Needed: Predicting LLM Answer Accuracy from Question-Only Linear Probes', 'authors': 'Iván Vicente Moreno Cencerrado, Arnau Padrés Masdemont, Anton Gonzalvez Hawthorne, David Demitri Africa, Lorenzo Pacchiardi', 'link': 'https://arxiv.org/abs/2509.10625', 'abstract': 'Do large language models (LLMs) anticipate when they will answer correctly? To study this, we extract activations after a question is read but before any tokens are generated, and train linear probes to predict whether the model\'s forthcoming answer will be correct. Across three open-source model families ranging from 7 to 70 billion parameters, projections on this "in-advance correctness direction" trained on generic trivia questions predict success in distribution and on diverse out-of-distribution knowledge datasets, outperforming black-box baselines and verbalised predicted confidence. Predictive power saturates in intermediate layers, suggesting that self-assessment emerges mid-computation. Notably, generalisation falters on questions requiring mathematical reasoning. Moreover, for models responding "I don\'t know", doing so strongly correlates with the probe score, indicating that the same direction also captures confidence. By complementing previous results on truthfulness and other behaviours obtained with probes and sparse auto-encoders, our work contributes essential findings to elucidate LLM internals.', 'abstract_zh': '大型语言模型（LLM）是否能在作答前预知答案的正确性？我们提取问题读取后但在生成任何tokens之前的信息激活，并训练线性端头以预测模型即将给出的答案是否正确。通过对7亿至70亿参数的三个开源模型家族进行研究，在通用 trivia 问题上的“预先正确性方向”投影不仅在分布上预测表现优异，还在多种离分布知识数据集上超越黑盒基线和表达的预测信心。预测能力在中间层趋于饱和，表明自我评估在计算过程中中期出现。值得注意的是，对需要数学推理的问题，泛化表现不佳。此外，对于回答“不知道”的模型，这种回答与端头得分高度相关，表明同一方向也捕捉了信心。通过补充使用端头和稀疏自编码器获得的关于诚实性和其他行为的先前结果，我们的工作为阐明LLM内部机制贡献了关键发现。', 'title_zh': '无需回答：仅从问题预测大语言模型答案准确性的方法'}
{'arxiv_id': 'arXiv:2509.10600', 'title': "National Running Club Database: Assessing Collegiate Club Athletes' Cross Country Race Results", 'authors': 'Jonathan A. Karr Jr, Ben Darden, Nicholas Pell, Ryan M. Fryer, Kayla Ambrose, Evan Hall, Ramzi K. Bualuan, Nitesh V. Chawla', 'link': 'https://arxiv.org/abs/2509.10600', 'abstract': "The National Running Club Database (NRCD) aggregates 15,397 race results of 5,585 athletes from the 2023 and 2024 cross country seasons. This paper introduces the NRCD dataset, which provides insights into individual athlete progressions, enabling data-driven decision-making. Analysis reveals that runners' improvement per calendar day for women, racing 6,000m, and men, racing 8,000m, is more pronounced in athletes with slower initial race times and those who race more frequently. Additionally, we factor in course conditions, including weather and elevation gain, to standardize improvement. While the NRCD shows a gender imbalance, 3,484 men vs. 2,101 women, the racing frequency between genders is comparable. This publication makes the NRCD dataset accessible to the research community, addressing a previous challenge where smaller datasets, often limited to 500 entries, had to be manually scraped from the internet. Focusing on club athletes rather than elite professionals offers a unique lens into the performance of real-world runners who balance competition with academics and other commitments. These results serve as a valuable resource for runners, coaches, and teams, bridging the gap between raw data and applied sports science.", 'abstract_zh': '国家跑步俱乐部数据库（NRCD）汇集了2023和2024赛季5585名运动员共15,397场比赛的结果。本文介绍了NRCD数据集，提供了关于个别运动员进步的见解，有助于基于数据的决策制定。分析表明，在6000米赛跑中起跑较慢且比赛频率较高的女性运动员以及在8000米赛跑中起跑较慢且比赛频率较高的男性运动员每天历日的进步更为显著。此外，我们还考虑了包括天气和海拔变化在内的赛道条件，以标准化进步程度。尽管NRCD显示出性别不平衡，男性3484人 vs. 女性2101人，但男女运动员的竞赛频率相当。本文使NRCD数据集对研究人员开放，解决了此前小数据集（通常仅包含500条记录）需要手动从互联网抓取的难题。专注于俱乐部运动员而非精英职业选手，为我们提供了一个独特的视角，深入了解了兼顾比赛、学术和其他承诺的实际跑者的表现。这些结果为跑步者、教练员和团队提供了宝贵的资源，填补了原始数据与应用运动科学之间的差距。', 'title_zh': '国家级跑步俱乐部数据库：评估大学生跨项赛跑成绩'}
{'arxiv_id': 'arXiv:2509.10596', 'title': 'GenAI Voice Mode in Programming Education', 'authors': 'Sven Jacobs, Natalie Kiesler', 'link': 'https://arxiv.org/abs/2509.10596', 'abstract': "Real-time voice interfaces using multimodal Generative AI (GenAI) can potentially address the accessibility needs of novice programmers with disabilities (e.g., related to vision). Yet, little is known about how novices interact with GenAI tools and their feedback quality in the form of audio output. This paper analyzes audio dialogues from nine 9th-grade students using a voice-enabled tutor (powered by OpenAI's Realtime API) in an authentic classroom setting while learning Python. We examined the students' voice prompts and AI's responses (1210 messages) by using qualitative coding. We also gathered students' perceptions via the Partner Modeling Questionnaire. The GenAI Voice Tutor primarily offered feedback on mistakes and next steps, but its correctness was limited (71.4% correct out of 416 feedback outputs). Quality issues were observed, particularly when the AI attempted to utter programming code elements. Students used the GenAI voice tutor primarily for debugging. They perceived it as competent, only somewhat human-like, and flexible. The present study is the first to explore the interaction dynamics of real-time voice GenAI tutors and novice programmers, informing future educational tool design and potentially addressing accessibility needs of diverse learners.", 'abstract_zh': '实时语音接口使用多模态生成AI（GenAI）可能解决视觉障碍等残疾初学者程序员的 accessibility 需求。然而，关于初学者如何与生成AI工具互动及其语音输出反馈质量的研究尚少。本文分析了九名九年级学生在使用语音驱动辅导系统（基于OpenAI的Realtime API）学习Python过程中的音频对话，通过定性编码研究了学生的语音提示和AI的回应（共1210条消息），并通过伙伴建模问卷收集了学生的观点。生成AI语音辅导主要提供错误反馈和下一步建议，但其正确性有限（正确率为71.4%）。特别是在生成编程代码元素时，出现了质量缺陷。学生主要使用生成AI语音辅导进行调试。他们认为其表现专业、略带人性化且灵活。本研究是首次探索实时语音生成AI辅导系统与初学者程序员的互动动态，为未来教育工具设计提供参考并可能解决不同学习者的可访问性需求。', 'title_zh': 'GenAI语音模式在编程教育中的应用'}
{'arxiv_id': 'arXiv:2509.10594', 'title': 'SME-TEAM: Leveraging Trust and Ethics for Secure and Responsible Use of AI and LLMs in SMEs', 'authors': 'Iqbal H. Sarker, Helge Janicke, Ahmad Mohsin, Leandros Maglaras', 'link': 'https://arxiv.org/abs/2509.10594', 'abstract': "Artificial Intelligence (AI) and Large Language Models (LLMs) are reshaping today's business practices, however, their adoption within small and medium-sized enterprises (SMEs) raises significant technical, ethical and trust issues. This paper proposes a structured, multi-phased framework designed to embed trust and ethical principles throughout the AI lifecycle for their secure and responsible use in SMEs. Structured around four pillars, i.e., Data, Algorithms, Human oversight, and Model Architecture, the framework bridges theoretical ethical principles with operational practice, enhancing AI capabilities in diverse SME applications. Ultimately, this paper offers a structured roadmap for responsible AI adoption, framing trust and ethics as a catalyst for resilience, competitiveness, and sustainable innovation in SMEs.", 'abstract_zh': '人工智能（AI）和大型语言模型（LLMs）正在重塑当今的商业实践，然而在小型和中型企业（SMEs）中采用这些技术引发了重要的技术、伦理和信任问题。本文提出了一种结构化、多阶段框架，旨在在整个AI生命周期中嵌入信任和伦理原则，促进其在SMEs中的安全和负责任使用。该框架以数据、算法、人类监督和模型架构四个支柱为基础，将理论伦理原则与操作实践相结合，增强在不同SME应用中的AI能力。最终，本文提供了一条结构化的负责任AI采用路线图，将信任和伦理作为增强SMEs韧性和竞争力、推动可持续创新的催化剂。', 'title_zh': 'SME-TEAM：利用信任和伦理规范确保中小企业安全负责任地使用AI和大语言模型'}
{'arxiv_id': 'arXiv:2509.10591', 'title': 'Assisting the Grading of a Handwritten General Chemistry Exam with Artificial Intelligence', 'authors': 'Jan Cvengros, Gerd Kortemeyer', 'link': 'https://arxiv.org/abs/2509.10591', 'abstract': 'We explore the effectiveness and reliability of an artificial intelligence (AI)-based grading system for a handwritten general chemistry exam, comparing AI-assigned scores to human grading across various types of questions. Exam pages and grading rubrics were uploaded as images to account for chemical reaction equations, short and long open-ended answers, numerical and symbolic answer derivations, drawing, and sketching in pencil-and-paper format. Using linear regression analyses and psychometric evaluations, the investigation reveals high agreement between AI and human graders for textual and chemical reaction questions, while highlighting lower reliability for numerical and graphical tasks. The findings emphasize the necessity for human oversight to ensure grading accuracy, based on selective filtering. The results indicate promising applications for AI in routine assessment tasks, though careful consideration must be given to student perceptions of fairness and trust in integrating AI-based grading into educational practice.', 'abstract_zh': '基于人工智能的笔试试卷评分系统的有效性和可靠性探究：以无机化学考试为例', 'title_zh': '利用人工智能辅助手写无机化学考试评分'}
{'arxiv_id': 'arXiv:2509.10590', 'title': 'Machine Unlearning for Responsible and Adaptive AI in Education', 'authors': 'Betty Mayeku, Sandra Hummel, Parisa Memarmoshrefi', 'link': 'https://arxiv.org/abs/2509.10590', 'abstract': "The concept of Machine Unlearning (MU) has gained popularity in various domains due to its ability to address several issues in Machine Learning (ML) models, particularly those related to privacy, security, bias mitigation, and adaptability. With these abilities, MU is evolving into a promising technology in upholding Responsible AI principles and optimizing ML models' performance. However, despite its promising potential, the concept has not received much attention in the education sector. In an attempt to encourage further uptake of this promising technology in the educational landscape, this paper demonstrates that MU indeed has great potential to serve as a practical mechanism for operationalizing Responsible AI principles as well as an essential tool for Adaptive AI within the educational application domain hence fostering trust in AI-driven educational systems. Through a structured review of 42 peer-reviewed sources, we identify four domains where MU holds particular promise namely privacy protection, resilience against adversarial inputs, mitigation of systemic bias, and adaptability in evolving learning contexts. We systematically explore these potentials and their interventions to core challenges in ML-based education systems. As a conceptual contribution, we present a reference Machine Unlearning application architecture for Responsible and Adaptive AI (MU-RAAI) in education context.", 'abstract_zh': '机器遗忘（MU）的概念由于其在解决机器学习模型中隐私、安全、偏见缓解和适应性等方面问题的能力而在各个领域中获得了 popularity，并正在演进成为维护负责任人工智能原则和优化机器学习模型性能的有希望的技术。尽管 MU 具有很大的潜力，但这一概念在教育领域尚未受到广泛关注。为了促进这一有希望的技术在教育领域的进一步应用，本文通过结构化的文献回顾（共 42 篇同行评审来源）展示了机器遗忘确实具有作为实现负责任和适应性人工智能原则的实用机制以及教育应用领域中适应性人工智能的重要工具的潜力，从而促进对人工智能驱动教育系统的信任。在此基础上，我们提出了一个适用于教育背景的责任和适应性人工智能的机器遗忘应用架构（MU-RAAI）。', 'title_zh': '负责任且适应性的教育人工智能中的机器遗忘技术'}
{'arxiv_id': 'arXiv:2509.10584', 'title': 'Smart Trial: Evaluating the Use of Large Language Models for Recruiting Clinical Trial Participants via Social Media', 'authors': 'Xiaofan Zhou, Zisu Wang, Janice Krieger, Mohan Zalake, Lu Cheng', 'link': 'https://arxiv.org/abs/2509.10584', 'abstract': "Clinical trials (CT) are essential for advancing medical research and treatment, yet efficiently recruiting eligible participants -- each of whom must meet complex eligibility criteria -- remains a significant challenge. Traditional recruitment approaches, such as advertisements or electronic health record screening within hospitals, are often time-consuming and geographically constrained. This work addresses the recruitment challenge by leveraging the vast amount of health-related information individuals share on social media platforms. With the emergence of powerful large language models (LLMs) capable of sophisticated text understanding, we pose the central research question: Can LLM-driven tools facilitate CT recruitment by identifying potential participants through their engagement on social media? To investigate this question, we introduce TRIALQA, a novel dataset comprising two social media collections from the subreddits on colon cancer and prostate cancer. Using eligibility criteria from public real-world CTs, experienced annotators are hired to annotate TRIALQA to indicate (1) whether a social media user meets a given eligibility criterion and (2) the user's stated reasons for interest in participating in CT. We benchmark seven widely used LLMs on these two prediction tasks, employing six distinct training and inference strategies. Our extensive experiments reveal that, while LLMs show considerable promise, they still face challenges in performing the complex, multi-hop reasoning needed to accurately assess eligibility criteria.", 'abstract_zh': '临床试验（CT）通过社交媒体平台招募合格参与者的研究：利用大规模语言模型的机遇与挑战', 'title_zh': '智能试验：评估通过社交媒体使用大型语言模型招募临床试验参与者的效果'}
{'arxiv_id': 'arXiv:2509.10582', 'title': 'LearnLens: An AI-Enhanced Dashboard to Support Teachers in Open-Ended Classrooms', 'authors': 'Namrata Srivastava, Shruti Jain, Clayton Cohn, Naveeduddin Mohammed, Umesh Timalsina, Gautam Biswas', 'link': 'https://arxiv.org/abs/2509.10582', 'abstract': "Exploratory learning environments (ELEs), such as simulation-based platforms and open-ended science curricula, promote hands-on exploration and problem-solving but make it difficult for teachers to gain timely insights into students' conceptual understanding. This paper presents LearnLens, a generative AI (GenAI)-enhanced teacher-facing dashboard designed to support problem-based instruction in middle school science. LearnLens processes students' open-ended responses from digital assessments to provide various insights, including sample responses, word clouds, bar charts, and AI-generated summaries. These features elucidate students' thinking, enabling teachers to adjust their instruction based on emerging patterns of understanding. The dashboard was informed by teacher input during professional development sessions and implemented within a middle school Earth science curriculum. We report insights from teacher interviews that highlight the dashboard's usability and potential to guide teachers' instruction in the classroom.", 'abstract_zh': '基于生成式AI的面向教师的学习镜像板：促进中学科学问题导向教学的探索性学习环境', 'title_zh': 'LearnLens: 一种增强型教学板面，支持开放教室中的教师'}
{'arxiv_id': 'arXiv:2509.10577', 'title': 'The Coding Limits of Robust Watermarking for Generative Models', 'authors': 'Danilo Francati, Yevin Nikhel Goonatilake, Shubham Pawar, Daniele Venturi, Giuseppe Ateniese', 'link': 'https://arxiv.org/abs/2509.10577', 'abstract': 'We prove a sharp threshold for the robustness of cryptographic watermarking for generative models. This is achieved by introducing a coding abstraction, which we call messageless secret-key codes, that formalizes sufficient and necessary requirements of robust watermarking: soundness, tamper detection, and pseudorandomness. Thus, we establish that robustness has a precise limit: For binary outputs no scheme can survive if more than half of the encoded bits are modified, and for an alphabet of size q the corresponding threshold is $(1-1/q)$ of the symbols.\nComplementing this impossibility, we give explicit constructions that meet the bound up to a constant slack. For every ${\\delta} > 0$, assuming pseudorandom functions and access to a public counter, we build linear-time codes that tolerate up to $(1/2)(1-{\\delta})$ errors in the binary case and $(1-1/q)(1-{\\delta})$ errors in the $q$-ary case. Together with the lower bound, these yield the maximum robustness achievable under standard cryptographic assumptions.\nWe then test experimentally whether this limit appears in practice by looking at the recent watermarking for images of Gunn, Zhao, and Song (ICLR 2025). We show that a simple crop and resize operation reliably flipped about half of the latent signs and consistently prevented belief-propagation decoding from recovering the codeword, erasing the watermark while leaving the image visually intact.\nThese results provide a complete characterization of robust watermarking, identifying the threshold at which robustness fails, constructions that achieve it, and an experimental confirmation that the threshold is already reached in practice.', 'abstract_zh': '我们证明了一个严格的阈值，以确定加密水印在生成模型中的鲁棒性。通过引入一种编码抽象——我们称之为无信息密钥消息编码，来正式化鲁棒水印的充分必要条件：正确性、篡改检测和伪随机性。因此，我们建立了鲁棒性具有精确的界限：对于二进制输出，如果超过一半的编码位被修改，任何方案都无法生存；对于大小为q的字母表，相应的阈值为符号的$(1-1/q)$。补充这一不可能性，我们给出了明确的构造，这些构造在常数误差容差范围内达到了上述界限。对于每个$\\delta > 0$，假设伪随机函数并访问公共计数器，我们构建了线性时间码，能够在二进制情况下容忍最多$(1/2)(1-\\delta)$的错误，在$q$-进制情况下容忍最多$(1-1/q)(1-\\delta)$的错误。这些线性时间码与下界结合，得出了在标准密码学假设下的最大鲁棒性。然后，我们通过实验检查这种界限在实践中是否出现，研究了Gunn, Zhao, 和 Song（ICLR 2025）的图像水印。我们表明，简单的裁剪和缩放操作可靠地翻转了大约一半的潜在标志，并且一致地阻止了基于传播的解码恢复码字，消除了水印同时使图像保持视觉上不变。这些结果为鲁棒水印提供了完整的规范，确定了鲁棒性失效的阈值，给出了实现此阈值的构造，并通过实验验证，在实践中已经达到了该阈值。', 'title_zh': '稳健水印技术在生成模型中的编码极限'}
{'arxiv_id': 'arXiv:2509.10576', 'title': 'Aesthetic Experience and Educational Value in Co-creating Art with Generative AI: Evidence from a Survey of Young Learners', 'authors': 'Chengyuan Zhang, Suzhe Xu', 'link': 'https://arxiv.org/abs/2509.10576', 'abstract': "This study investigates the aesthetic experience and educational value of collaborative artmaking with generative artificial intelligence (AI) among young learners and art students. Based on a survey of 112 participants, we examine how human creators renegotiate their roles, how conventional notions of originality are challenged, how the creative process is transformed, and how aesthetic judgment is formed in human--AI co-creation. Empirically, participants generally view AI as a partner that stimulates ideation and expands creative boundaries rather than a passive tool, while simultaneously voicing concerns about stylistic homogenization and the erosion of traditional authorship. Theoretically, we synthesize Dewey's aesthetics of experience, Ihde's postphenomenology, and actor--network theory (ANT) into a single analytical framework to unpack the dynamics between human creators and AI as a non-human actant. Findings indicate (i) a fluid subjectivity in which creators shift across multiple stances (director, dialogic partner, discoverer); (ii) an iterative, dialogic workflow (intent--generate--select--refine) that centers critical interpretation; and (iii) an educational value shift from technical skill training toward higher-order competencies such as critical judgment, cross-modal ideation, and reflexivity. We argue that arts education should cultivate a \\emph{critical co-creation} stance toward technology, guiding learners to collaborate with AI while preserving human distinctiveness in concept formation, judgment, and meaning-making.", 'abstract_zh': '本研究调查了年轻学习者和艺术学生在与生成型人工智能（AI）协作艺术创作中的审美体验和教育价值。基于对112名参与者的调查，我们探讨了人类创作者重新谈判其角色的方式、传统原创性观念的挑战、创作过程的转变以及人类与AI共创作中的审美判断形成。实证上，参与者普遍将AI视为激发创意和扩展创作边界的合作伙伴，而不是被动工具，同时表达了对风格同质化和传统作者身份侵蚀的担忧。理论层面，我们将杜威的经验美学、伊赫德的后现象学以及行动者网络理论（ANT）整合为一个分析框架，以分析人类创作者与非人类行动者AI之间的动态关系。研究发现包括：（i）流变的主体性，在其中创作者转换不同的立场（导演、对话伙伴、发现者）；（ii）迭代的、对话的工作流程（意图—生成—选择—提炼），以批判性解释为中心；（iii）从技术技能训练到更高阶能力，如批判性判断、跨模态创意和反思性的转变。我们认为，艺术教育应培养一种对技术的“批判性共创作”态度，引导学习者与AI合作同时保持人类在概念形成、判断和意义建构中的独特性。', 'title_zh': '与生成性人工智能共创艺术的审美体验与教育价值：基于年轻学习者调查的证据'}
{'arxiv_id': 'arXiv:2509.10575', 'title': 'Gene-R1: Reasoning with Data-Augmented Lightweight LLMs for Gene Set Analysis', 'authors': 'Zhizheng Wang, Yifan Yang, Qiao Jin, Zhiyong Lu', 'link': 'https://arxiv.org/abs/2509.10575', 'abstract': 'The gene set analysis (GSA) is a foundational approach for uncovering the molecular functions associated with a group of genes. Recently, LLM-powered methods have emerged to annotate gene sets with biological functions together with coherent explanatory insights. However, existing studies primarily focus on proprietary models, which have been shown to outperform their open-source counterparts despite concerns over cost and data privacy. Furthermore, no research has investigated the application of advanced reasoning strategies to the GSA task. To address this gap, we introduce Gene-R1, a data-augmented learning framework that equips lightweight and open-source LLMs with step-by-step reasoning capabilities tailored to GSA. Experiments on 1,508 in-distribution gene sets demonstrate that Gene-R1 achieves substantial performance gains, matching commercial LLMs. On 106 out-of-distribution gene sets, Gene-R1 performs comparably to both commercial and large-scale LLMs, exhibiting robust generalizability across diverse gene sources.', 'abstract_zh': '基于基因集的基因组功能分析（GSA）是揭示一组基因相关分子功能的基础方法。近期，基于大语言模型（LLM）的方法已经出现，能够同时标注基因集的生物功能及其一致的解释性见解。然而，现有研究主要集中在专有模型上，尽管这些模型在成本和数据隐私存在担忧的情况下仍表现出色。此外，没有研究探讨高级推理策略在GSA任务中的应用。为填补这一空白，我们介绍了Gene-R1，一个数据增强的学习框架，它为轻量级和开源的LLM配备了针对GSA定制的逐步推理能力。实验结果显示，在1,508个分布内基因集上，Gene-R1实现了显著的性能提升，与商业大语言模型相当。在106个分布外基因集上，Gene-R1与商业和大规模的LLM相当，展示了在多样化的基因来源上的稳健泛化能力。', 'title_zh': 'Gene-R1：基于数据增强轻量级LLM的基因集分析推理'}
{'arxiv_id': 'arXiv:2509.10572', 'title': 'Quality Assessment of Tabular Data using Large Language Models and Code Generation', 'authors': 'Ashlesha Akella, Akshar Kaul, Krishnasuri Narayanam, Sameep Mehta', 'link': 'https://arxiv.org/abs/2509.10572', 'abstract': 'Reliable data quality is crucial for downstream analysis of tabular datasets, yet rule-based validation often struggles with inefficiency, human intervention, and high computational costs. We present a three-stage framework that combines statistical inliner detection with LLM-driven rule and code generation. After filtering data samples through traditional clustering, we iteratively prompt LLMs to produce semantically valid quality rules and synthesize their executable validators through code-generating LLMs. To generate reliable quality rules, we aid LLMs with retrieval-augmented generation (RAG) by leveraging external knowledge sources and domain-specific few-shot examples. Robust guardrails ensure the accuracy and consistency of both rules and code snippets. Extensive evaluations on benchmark datasets confirm the effectiveness of our approach.', 'abstract_zh': '可靠的數據質量對於表數據下游分析至關重要，但基于规则的验证往往面临效率低下、人工干预和高計算成本的问题。我们提出一个三阶段框架，结合统计内点检测与大语言模型驱动的规则和代码生成。在通过传统聚类过滤数据样本后，我们迭代地提示大语言模型生成语义上有意义的质量规则，并通过代码生成大语言模型合成效仿器合成其实现验证器。为了生成可靠的质量规则，我们通过检索增强生成（RAG）辅助大语言模型，利用外部知识源和领域特定的少量示例。稳健的护栏确保规则和代码片段的准确性和一致性。在基准数据集上的 extensive 评估验证了该方法的有效性。', 'title_zh': '使用大型语言模型和代码生成评估表格数据质量'}
{'arxiv_id': 'arXiv:2509.10570', 'title': 'Large Foundation Models for Trajectory Prediction in Autonomous Driving: A Comprehensive Survey', 'authors': 'Wei Dai, Shengen Wu, Wei Wu, Zhenhao Wang, Sisuo Lyu, Haicheng Liao, Limin Yu, Weiping Ding, Runwei Guan, Yutao Yue', 'link': 'https://arxiv.org/abs/2509.10570', 'abstract': 'Trajectory prediction serves as a critical functionality in autonomous driving, enabling the anticipation of future motion paths for traffic participants such as vehicles and pedestrians, which is essential for driving safety. Although conventional deep learning methods have improved accuracy, they remain hindered by inherent limitations, including lack of interpretability, heavy reliance on large-scale annotated data, and weak generalization in long-tail scenarios. The rise of Large Foundation Models (LFMs) is transforming the research paradigm of trajectory prediction. This survey offers a systematic review of recent advances in LFMs, particularly Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) for trajectory prediction. By integrating linguistic and scene semantics, LFMs facilitate interpretable contextual reasoning, significantly enhancing prediction safety and generalization in complex environments. The article highlights three core methodologies: trajectory-language mapping, multimodal fusion, and constraint-based reasoning. It covers prediction tasks for both vehicles and pedestrians, evaluation metrics, and dataset analyses. Key challenges such as computational latency, data scarcity, and real-world robustness are discussed, along with future research directions including low-latency inference, causality-aware modeling, and motion foundation models.', 'abstract_zh': 'Large Foundation Models在轨迹预测中的最新进展：面向自主驾驶的应用', 'title_zh': '大型基础模型在自主驾驶中的轨迹预测：一篇综述'}
{'arxiv_id': 'arXiv:2509.10569', 'title': 'MarkDiffusion: An Open-Source Toolkit for Generative Watermarking of Latent Diffusion Models', 'authors': 'Leyi Pan, Sheng Guan, Zheyu Fu, Luyang Si, Zian Wang, Xuming Hu, Irwin King, Philip S. Yu, Aiwei Liu, Lijie Wen', 'link': 'https://arxiv.org/abs/2509.10569', 'abstract': 'We introduce MarkDiffusion, an open-source Python toolkit for generative watermarking of latent diffusion models. It comprises three key components: a unified implementation framework for streamlined watermarking algorithm integrations and user-friendly interfaces; a mechanism visualization suite that intuitively showcases added and extracted watermark patterns to aid public understanding; and a comprehensive evaluation module offering standard implementations of 24 tools across three essential aspects - detectability, robustness, and output quality - plus 8 automated evaluation pipelines. Through MarkDiffusion, we seek to assist researchers, enhance public awareness and engagement in generative watermarking, and promote consensus while advancing research and applications.', 'abstract_zh': 'MarkDiffusion：一个开源Python工具包，用于生成-latent扩散模型中的水印', 'title_zh': 'MarkDiffusion: 开源生成水印工具包——面向潜层扩散模型的生成性水印技术'}
{'arxiv_id': 'arXiv:2509.10561', 'title': 'AVEC: Bootstrapping Privacy for Local LLMs', 'authors': 'Madhava Gaikwad', 'link': 'https://arxiv.org/abs/2509.10561', 'abstract': 'This position paper presents AVEC (Adaptive Verifiable Edge Control), a framework for bootstrapping privacy for local language models by enforcing privacy at the edge with explicit verifiability for delegated queries. AVEC introduces an adaptive budgeting algorithm that allocates per-query differential privacy parameters based on sensitivity, local confidence, and historical usage, and uses verifiable transformation with on-device integrity checks. We formalize guarantees using Rényi differential privacy with odometer-based accounting, and establish utility ceilings, delegation-leakage bounds, and impossibility results for deterministic gating and hash-only certification. Our evaluation is simulation-based by design to study mechanism behavior and accounting; we do not claim deployment readiness or task-level utility with live LLMs. The contribution is a conceptual architecture and theoretical foundation that chart a pathway for empirical follow-up on privately bootstrapping local LLMs.', 'abstract_zh': '本论题论文提出AVEC（自适应可验证边缘控制），一种通过在边缘端强制执行隐私并为委托查询提供显式可验证性来为本地语言模型启动隐私性的框架。AVEC引入了一种自适应预算算法，根据敏感性、本地置信度和历史使用情况为每个查询分配差分隐私参数，并使用带有设备内完整性检查的可验证转换。我们使用基于 odometer 的会计方法形式化保证，并建立了确定性门控和仅哈希认证的效用上限、泄漏边界和不可能性结果。我们的评估设计为基于模拟以研究机制行为和会计；我们不声称在实时大语言模型中实现部署或具有任务级效用。贡献在于提出了一个概念性架构和理论基础，为实证后续研究自适应启动本地大语言模型的隐私性铺平道路。', 'title_zh': 'AVEC：为本地LLMs Bootstrapping隐私权'}
{'arxiv_id': 'arXiv:2509.10547', 'title': 'Biomarkers of brain diseases', 'authors': 'Pascal Helson, Arvind Kumar', 'link': 'https://arxiv.org/abs/2509.10547', 'abstract': 'Despite the diversity of brain data acquired and advanced AI-based algorithms to analyze them, brain features are rarely used in clinics for diagnosis and prognosis. Here we argue that the field continues to rely on cohort comparisons to seek biomarkers, despite the well-established degeneracy of brain features. Using a thought experiment, we show that more data and more powerful algorithms will not be sufficient to identify biomarkers of brain diseases. We argue that instead of comparing patient versus healthy controls using single data type, we should use multimodal (e.g. brain activity, neurotransmitters, neuromodulators, brain imaging) and longitudinal brain data to guide the grouping before defining multidimensional biomarkers for brain diseases.', 'abstract_zh': '尽管获取的脑数据多样且存在先进的基于AI的分析算法，脑特征在临床诊断和预后中使用仍然很少。我们argue继续依赖队列比较来寻找生物标志物，尽管已建立的脑特征退化现象已被确立。通过思想实验，我们表明，更多的数据和更强大的算法不足以识别脑疾病的生物标志物。我们argue应在使用多模态（如脑活动、神经递质、神经调节物、脑成像）和纵向脑数据来指导分组之前，而不是使用单一数据类型来比较患者与健康对照组，以定义脑疾病的多维生物标志物。', 'title_zh': '脑疾病标志物'}
{'arxiv_id': 'arXiv:2509.10546', 'title': 'Uncovering the Vulnerability of Large Language Models in the Financial Domain via Risk Concealment', 'authors': 'Gang Cheng, Haibo Jin, Wenbin Zhang, Haohan Wang, Jun Zhuang', 'link': 'https://arxiv.org/abs/2509.10546', 'abstract': 'Large Language Models (LLMs) are increasingly integrated into financial applications, yet existing red-teaming research primarily targets harmful content, largely neglecting regulatory risks. In this work, we aim to investigate the vulnerability of financial LLMs through red-teaming approaches. We introduce Risk-Concealment Attacks (RCA), a novel multi-turn framework that iteratively conceals regulatory risks to provoke seemingly compliant yet regulatory-violating responses from LLMs. To enable systematic evaluation, we construct FIN-Bench, a domain-specific benchmark for assessing LLM safety in financial contexts. Extensive experiments on FIN-Bench demonstrate that RCA effectively bypasses nine mainstream LLMs, achieving an average attack success rate (ASR) of 93.18%, including 98.28% on GPT-4.1 and 97.56% on OpenAI o1. These findings reveal a critical gap in current alignment techniques and underscore the urgent need for stronger moderation mechanisms in financial domains. We hope this work offers practical insights for advancing robust and domain-aware LLM alignment.', 'abstract_zh': '大型语言模型（LLMs）在金融应用中的安全性研究：Risk-Concealment Attacks及其对金融LLMs的评估', 'title_zh': '通过风险隐藏揭示大型语言模型在金融领域的脆弱性'}
{'arxiv_id': 'arXiv:2509.10544', 'title': 'ASL360: AI-Enabled Adaptive Streaming of Layered 360° Video over UAV-assisted Wireless Networks', 'authors': 'Alireza Mohammadhosseini, Jacob Chakareski, Nicholas Mastronarde', 'link': 'https://arxiv.org/abs/2509.10544', 'abstract': "We propose ASL360, an adaptive deep reinforcement learning-based scheduler for on-demand 360° video streaming to mobile VR users in next generation wireless networks. We aim to maximize the overall Quality of Experience (QoE) of the users served over a UAV-assisted 5G wireless network. Our system model comprises a macro base station (MBS) and a UAV-mounted base station which both deploy mm-Wave transmission to the users. The 360° video is encoded into dependent layers and segmented tiles, allowing a user to schedule downloads of each layer's segments. Furthermore, each user utilizes multiple buffers to store the corresponding video layer's segments. We model the scheduling decision as a Constrained Markov Decision Process (CMDP), where the agent selects Base or Enhancement layers to maximize the QoE and use a policy gradient-based method (PPO) to find the optimal policy. Additionally, we implement a dynamic adjustment mechanism for cost components, allowing the system to adaptively balance and prioritize the video quality, buffer occupancy, and quality change based on real-time network and streaming session conditions. We demonstrate that ASL360 significantly improves the QoE, achieving approximately 2 dB higher average video quality, 80% lower average rebuffering time, and 57% lower video quality variation, relative to competitive baseline methods. Our results show the effectiveness of our layered and adaptive approach in enhancing the QoE in immersive videostreaming applications, particularly in dynamic and challenging network environments.", 'abstract_zh': 'ASL360：基于自适应深度强化学习的UAV辅助5G无线网络中移动VR用户按需360°视频流媒体调度器', 'title_zh': 'ASL360: 基于无人机辅助无线网络的AI使能分层360°视频自适应流传输'}
{'arxiv_id': 'arXiv:2509.10543', 'title': 'Robust DDoS-Attack Classification with 3D CNNs Against Adversarial Methods', 'authors': 'Landon Bragg, Nathan Dorsey, Josh Prior, John Ajit, Ben Kim, Nate Willis, Pablo Rivas', 'link': 'https://arxiv.org/abs/2509.10543', 'abstract': 'Distributed Denial-of-Service (DDoS) attacks remain a serious threat to online infrastructure, often bypassing detection by altering traffic in subtle ways. We present a method using hive-plot sequences of network data and a 3D convolutional neural network (3D CNN) to classify DDoS traffic with high accuracy. Our system relies on three main ideas: (1) using spatio-temporal hive-plot encodings to set a pattern-recognition baseline, (2) applying adversarial training with FGSM and PGD alongside spatial noise and image shifts, and (3) analyzing frame-wise predictions to find early signals. On a benchmark dataset, our method lifts adversarial accuracy from 50-55% to over 93% while maintaining clean-sample performance. Frames 3-4 offer strong predictive signals, showing early-stage classification is possible.', 'abstract_zh': '分布式拒绝服务（DDoS）攻击仍然是在线基础设施的重大威胁，常通过微妙改变流量的方式规避检测。我们提出了一种方法，利用网络数据的蜂巢图序列和三维卷积神经网络（3D CNN）对DDoS流量进行高精度分类。该系统依赖于三个主要理念：（1）使用时空蜂巢图编码设定模式识别基准，（2）结合FGSM和PGD对抗训练及空间噪声和图像位移，（3）分析帧级预测以寻找早期信号。在基准数据集上，该方法将对抗准确性从50-55%提升至超过93%的同时保持干净样本性能。第3-4帧提供了强大的预测信号，表明早期阶段的分类是可能的。', 'title_zh': '基于3D CNNs的抗对抗方法的稳健DDoS攻击分类'}
{'arxiv_id': 'arXiv:2509.10540', 'title': 'EchoLeak: The First Real-World Zero-Click Prompt Injection Exploit in a Production LLM System', 'authors': 'Pavan Reddy, Aditya Sanjay Gujral', 'link': 'https://arxiv.org/abs/2509.10540', 'abstract': 'Large language model (LLM) assistants are increasingly integrated into enterprise workflows, raising new security concerns as they bridge internal and external data sources. This paper presents an in-depth case study of EchoLeak (CVE-2025-32711), a zero-click prompt injection vulnerability in Microsoft 365 Copilot that enabled remote, unauthenticated data exfiltration via a single crafted email. By chaining multiple bypasses-evading Microsofts XPIA (Cross Prompt Injection Attempt) classifier, circumventing link redaction with reference-style Markdown, exploiting auto-fetched images, and abusing a Microsoft Teams proxy allowed by the content security policy-EchoLeak achieved full privilege escalation across LLM trust boundaries without user interaction. We analyze why existing defenses failed, and outline a set of engineering mitigations including prompt partitioning, enhanced input/output filtering, provenance-based access control, and strict content security policies. Beyond the specific exploit, we derive generalizable lessons for building secure AI copilots, emphasizing the principle of least privilege, defense-in-depth architectures, and continuous adversarial testing. Our findings establish prompt injection as a practical, high-severity vulnerability class in production AI systems and provide a blueprint for defending against future AI-native threats.', 'abstract_zh': '大型语言模型（LLM）助手日益融入企业工作流程，引发了新的安全担忧，因为它们连接了内部和外部数据源。本文以EchoLeak（CVE-2025-32711）为例，深入研究了Microsoft 365 Copilot中的零点击提示注入漏洞，该漏洞通过单封精心制作的邮件实现了未认证的远程数据泄露。EchoLeak通过链接多个绕过Microsoft XPIA（跨提示注入尝试）分类器的措施，绕过了链接遮蔽，利用了参考样式的Markdown，利用了自动拉取的图像，并滥用允许的内容安全策略中的Microsoft Teams代理，从而在没有用户交互的情况下实现了跨LLM信任边界的身份提升。我们分析了现有防护措施为何失效，并提出了包括提示分区、增强的输入/输出过滤、基于溯源的访问控制和严格的内容安全策略在内的工程缓解措施。除了具体的利用方法外，我们还提炼出适用于构建安全AI协作者的一般原则，强调最小权限原则、多层次防御架构以及持续的对抗性测试。我们的研究成果将提示注入确立为生产AI系统中实用且高危的漏洞类别，并提供了抵御未来AI原生威胁的蓝图。', 'title_zh': 'EchoLeak: 首个生产环境下的零点击提示注入利用攻击'}
{'arxiv_id': 'arXiv:2509.10538', 'title': 'DualAlign: Generating Clinically Grounded Synthetic Data', 'authors': 'Rumeng Li, Xun Wang, Hong Yu', 'link': 'https://arxiv.org/abs/2509.10538', 'abstract': "Synthetic clinical data are increasingly important for advancing AI in healthcare, given strict privacy constraints on real-world EHRs, limited availability of annotated rare-condition data, and systemic biases in observational datasets. While large language models (LLMs) can generate fluent clinical text, producing synthetic data that is both realistic and clinically meaningful remains challenging. We introduce DualAlign, a framework that enhances statistical fidelity and clinical plausibility through dual alignment: (1) statistical alignment, which conditions generation on patient demographics and risk factors; and (2) semantic alignment, which incorporates real-world symptom trajectories to guide content generation. Using Alzheimer's disease (AD) as a case study, DualAlign produces context-grounded symptom-level sentences that better reflect real-world clinical documentation. Fine-tuning an LLaMA 3.1-8B model with a combination of DualAlign-generated and human-annotated data yields substantial performance gains over models trained on gold data alone or unguided synthetic baselines. While DualAlign does not fully capture longitudinal complexity, it offers a practical approach for generating clinically grounded, privacy-preserving synthetic data to support low-resource clinical text analysis.", 'abstract_zh': '合成临床数据在严格隐私限制、标注罕见病例数据有限以及观察性数据系统性偏见的情况下，对于推动医疗健康领域人工智能技术的发展日益重要。虽然大型语言模型可以生成流畅的临床文本，但生成既现实又具有临床意义的合成数据仍然具有挑战性。我们引入了DualAlign框架，通过双重对齐增强统计准确性和临床可行性：（1）统计对齐，基于患者的人口统计学特征和风险因素进行生成；（2）语义对齐，通过融入真实的症状轨迹来指导内容生成。以阿尔茨海默病（AD）为例，DualAlign生成了更贴近真实临床记录的细粒度症状句子。使用包含DualAlign生成数据和人工标注数据共同微调的LLaMA 3.1-8B模型，相对于仅使用黄金数据训练或未指导的合成基线模型，取得了显著的性能提升。尽管DualAlign无法完全捕捉纵向复杂性，但它提供了一种生成具有临床依据、保护隐私的合成数据的实用方法，以支持资源有限的临床文本分析。', 'title_zh': 'DualAlign: 生成具有临床依据的合成数据'}
{'arxiv_id': 'arXiv:2509.10537', 'title': 'On Using Large-Batches in Federated Learning', 'authors': 'Sahil Tyagi', 'link': 'https://arxiv.org/abs/2509.10537', 'abstract': 'Efficient Federated learning (FL) is crucial for training deep networks over devices with limited compute resources and bounded networks. With the advent of big data, devices either generate or collect multimodal data to train either generic or local-context aware networks, particularly when data privacy and locality is vital. FL algorithms generally trade-off between parallel and statistical performance, improving model quality at the cost of higher communication frequency, or vice versa. Under frequent synchronization settings, FL over a large cluster of devices may perform more work per-training iteration by processing a larger global batch-size, thus attaining considerable training speedup. However, this may result in poor test performance (i.e., low test loss or accuracy) due to generalization degradation issues associated with large-batch training. To address these challenges with large-batches, this work proposes our vision of exploiting the trade-offs between small and large-batch training, and explore new directions to enjoy both the parallel scaling of large-batches and good generalizability of small-batch training. For the same number of iterations, we observe that our proposed large-batch training technique attains about 32.33% and 3.74% higher test accuracy than small-batch training in ResNet50 and VGG11 models respectively.', 'abstract_zh': '高效的联邦学习在计算资源有限和网络带宽受限的设备上训练深度网络至关重要。随着大数据的到来，设备要么生成要么收集多模态数据来训练通用或局部上下文感知的网络，特别是在数据隐私和本地化至关重要的情况下。联邦学习算法通常在并行性能和统计性能之间进行权衡，在增加通信频率的同时提高模型质量，反之亦然。在频繁同步的设置下，联邦学习可以在大型设备集群中通过处理更大的全局批量大小，在每次训练迭代中执行更多的工作，从而实现显著的训练加速。然而，这可能导致由于大规模训练引起的泛化性能下降，从而导致较差的测试性能（即较高的测试损失或准确性）。为了解决这些问题，本文提出了我们的视角，即利用小批量和大批量训练之间的权衡，并探索新的方向，以同时享受大批量训练的并行扩展性和小批量训练的良好泛化性。对于相同数量的迭代，我们观察到，我们提出的大批量训练技术在ResNet50和VGG11模型中的测试准确率分别比小批量训练高32.33%和3.74%。', 'title_zh': '使用大批次在联邦学习中的应用'}
{'arxiv_id': 'arXiv:2509.10535', 'title': 'Semantic-guided LoRA Parameters Generation', 'authors': 'Miaoge Li, Yang Chen, Zhijie Rao, Can Jiang, Jingcai Guo', 'link': 'https://arxiv.org/abs/2509.10535', 'abstract': "Low-Rank Adaptation (LoRA) has demonstrated strong generalization capabilities across a variety of tasks for efficiently fine-tuning AI models, especially on resource-constrained edges. However, in real-world applications, edge users often exhibit task-specific preferences that are difficult to handle with a unified model trained under a closed-world assumption, and the challenge may further increase when there are significant domain shifts between training and deployment. Meanwhile, retraining/fine-tuning models for each user is also impractical due to its cost-intensive nature and privacy concerns over raw data utilization from edges. To address these challenges, we propose Semantic-guided LoRA Parameter Generation (SG-LoRA), the first of its kind framework to efficiently produce user-specific LoRA parameters without any additional training on user tasks or access to user-specific data. Concretely, SG-LoRA uses task descriptions as the semantic bridge, measuring their proximity to a set of known expert tasks in a shared embedding space. Based on this semantic guidance, it models the target task's LoRA parameter distribution to generate high-performing parameters for novel tasks. SG-LoRA enables the real-time construction of LoRA models aligned with individual intents by distilling knowledge from prominent LoRA experts and, meanwhile, offering a privacy-preserving solution for personalized model adaptation in a novel zero-shot open-world setting proposed in this work. Extensive experiments on multiple challenging tasks confirm the superior performance and remarkable adaptability of SG-LoRA. Code is available at this https URL.", 'abstract_zh': '基于语义指导的LoRA参数生成（SG-LoRA）', 'title_zh': '语义导向的LoRA参数生成'}
{'arxiv_id': 'arXiv:2509.10534', 'title': 'Decoupling the "What" and "Where" With Polar Coordinate Positional Embeddings', 'authors': 'Anand Gopalakrishnan, Robert Csordás, Jürgen Schmidhuber, Michael C. Mozer', 'link': 'https://arxiv.org/abs/2509.10534', 'abstract': "The attention mechanism in a Transformer architecture matches key to query based on both content -- the what -- and position in a sequence -- the where. We present an analysis indicating that what and where are entangled in the popular RoPE rotary position embedding. This entanglement can impair performance particularly when decisions require independent matches on these two factors. We propose an improvement to RoPE, which we call Polar Coordinate Position Embeddings or PoPE, that eliminates the what-where confound. PoPE is far superior on a diagnostic task requiring indexing solely by position or by content. On autoregressive sequence modeling in music, genomic, and natural language domains, Transformers using PoPE as the positional encoding scheme outperform baselines using RoPE with respect to evaluation loss (perplexity) and downstream task performance. On language modeling, these gains persist across model scale, from 124M to 774M parameters. Crucially, PoPE shows strong zero-shot length extrapolation capabilities, whereas RoPE's performance degrades significantly on longer sequences at test time without fine tuning or the use of position-interpolation methods.", 'abstract_zh': '基于极坐标位置嵌入的注意力机制在变压器架构中同时匹配查询的内容和位置。我们提出了一种分析，表明广泛使用的RoPE旋转位置嵌入中内容和位置是交织的。这种交织在需要独立匹配这两方面因素的决策中可能会影响性能。我们提出了一种改进RoPE的方法，称为极坐标位置嵌入或PoPE，它消除了内容与位置之间的混淆。PoPE在依赖位置或内容进行索引的诊断任务中表现出色。在音乐、基因组和自然语言领域的自回归序列建模中，使用PoPE作为位置编码方案的变压器在评估损失（困惑度）和下游任务性能上优于使用RoPE的基线模型。在语言建模中，这些优势在从124M到774M参数的模型规模上持续存在。最关键的是，PoPE展示了强大的零样本长度外推能力，而RoPE在其性能在对长序列进行测试时显著下降，除非进行微调或使用位置插值方法。', 'title_zh': '分解“what”和“where”：使用极坐标位置嵌入'}
{'arxiv_id': 'arXiv:2509.10531', 'title': 'FinXplore: An Adaptive Deep Reinforcement Learning Framework for Balancing and Discovering Investment Opportunities', 'authors': 'Himanshu Choudhary, Arishi Orra, Manoj Thakur', 'link': 'https://arxiv.org/abs/2509.10531', 'abstract': 'Portfolio optimization is essential for balancing risk and return in financial decision-making. Deep Reinforcement Learning (DRL) has stood out as a cutting-edge tool for portfolio optimization that learns dynamic asset allocation using trial-and-error interactions. However, most DRL-based methods are restricted to allocating assets within a pre-defined investment universe and overlook exploring new opportunities. This study introduces an investment landscape that integrates exploiting existing assets with exploring new investment opportunities in an extended universe. The proposed approach leverages two DRL agents and dynamically balances these objectives to adapt to evolving markets while enhancing portfolio performance. One agent allocates assets within the existing universe, while another assists in exploring new opportunities in the extended universe. The effciency of the proposed methodology is determined using two real-world market data sets. The experiments demonstrate the superiority of the suggested approach against the state-of-the-art portfolio strategies and baseline methods.', 'abstract_zh': '投资组合优化是平衡风险和回报的金融决策中必不可少的。深度强化学习（DRL）作为一种通过试错交互学习动态资产分配的前沿工具，在投资组合优化中脱颖而出。然而，大多数基于DRL的方法仅限于在预定义的投资范围内分配资产，忽略了探索新机会。本研究引入了一个将利用现有资产与探索扩展投资范围内的新机会相结合的投资景觀。提出的这种方法利用两个DRL代理动态平衡这些目标，以适应不断变化的市场环境并提升投资组合表现。一个代理在现有范围内分配资产，另一个则在扩展范围内协助探索新机会。利用两个实际市场数据集评估所提出方法的有效性。实验结果证明，建议的方法在与最新投资组合策略和基准方法的对比中具有优越性。', 'title_zh': 'FinXplore：一种平衡与发现投资机会的自适应深度强化学习框架'}
{'arxiv_id': 'arXiv:2509.10530', 'title': 'Dynamic Adaptive Shared Experts with Grouped Multi-Head Attention Mixture of Experts', 'authors': 'Cheng Li, Jiexiong Liu, Yixuan Chen, Jie ji', 'link': 'https://arxiv.org/abs/2509.10530', 'abstract': "Transformer models based on the Mixture of Experts (MoE) architecture have made significant progress in long-sequence modeling, but existing models still have shortcomings in computational efficiency and the ability to capture long-range dependencies, especially in terms of the dynamic adaptability of expert resource allocation. In this paper, we propose a Dynamic Adaptive Shared Expert and Grouped Multi-Head Attention Hybrid Model (DASG-MoE) to enhance long-sequence modeling capabilities by integrating three modules. First, we employ the Grouped Multi-Head Attention (GMHA) mechanism to effectively reduce the computational complexity of long sequences. By parallel processing through sequence grouping, local sliding window attention, and feature aggregation, we address long-range dependency issues and the model's lack of generalization for local information. Second, we design a Dual-Scale Shared Expert Structure (DSSE), where shallow experts use lightweight computations to quickly respond to low-dimensional features, while deep experts process high-dimensional complex semantics through pre-training transfer and post-training optimization, achieving a dynamic balance between efficiency and accuracy. Third, we propose a hierarchical Adaptive Dynamic Routing (ADR) mechanism that dynamically selects expert levels based on feature complexity and task requirements, and optimizes resource allocation through a local expert activation strategy. Experiments on multiple long-sequence benchmark datasets demonstrate that our DASG-MoE model outperforms state-of-the-art models.", 'abstract_zh': '基于Mixture of Experts（MoE）架构的Dynamic Adaptive Shared Expert and Grouped Multi-Head Attention Hybrid Model（DASG-MoE）在长序列建模中的动态适配研究', 'title_zh': '动态自适应分组多头注意力专家混合模型'}
{'arxiv_id': 'arXiv:2509.10529', 'title': 'Mitigating Catastrophic Forgetting and Mode Collapse in Text-to-Image Diffusion via Latent Replay', 'authors': 'Aoi Otani', 'link': 'https://arxiv.org/abs/2509.10529', 'abstract': 'Continual learning -- the ability to acquire knowledge incrementally without forgetting previous skills -- is fundamental to natural intelligence. While the human brain excels at this, artificial neural networks struggle with "catastrophic forgetting," where learning new tasks erases previously acquired knowledge. This challenge is particularly severe for text-to-image diffusion models, which generate images from textual prompts. Additionally, these models face "mode collapse," where their outputs become increasingly repetitive over time. To address these challenges, we apply Latent Replay, a neuroscience-inspired approach, to diffusion models. Traditional replay methods mitigate forgetting by storing and revisiting past examples, typically requiring large collections of images. Latent Replay instead retains only compact, high-level feature representations extracted from the model\'s internal architecture. This mirrors the hippocampal process of storing neural activity patterns rather than raw sensory inputs, reducing memory usage while preserving critical information. Through experiments with five sequentially learned visual concepts, we demonstrate that Latent Replay significantly outperforms existing methods in maintaining model versatility. After learning all concepts, our approach retained 77.59% Image Alignment (IA) on the earliest concept, 14% higher than baseline methods, while maintaining diverse outputs. Surprisingly, random selection of stored latent examples outperforms similarity-based strategies. Our findings suggest that Latent Replay enables efficient continual learning for generative AI models, paving the way for personalized text-to-image models that evolve with user needs without excessive computational costs.', 'abstract_zh': '持续学习——能够在不遗忘先前技能的情况下逐步获取知识的能力——是自然智能的基础。尽管人脑在这方面表现出色，但人工神经网络却难以克服“灾难性遗忘”的挑战，即学习新任务会抹去先前习得的知识。这种挑战尤其严重地影响了从文本生成图像的扩散模型，这些模型会产生基于文本提示的图像。此外，这些模型还面临着“模式塌陷”的问题，随着时间的推移，其输出变得越来越重复。为了解决这些挑战，我们应用了受神经科学启发的潜在重放方法到扩散模型中。传统的重放方法通过存储和回顾过去的示例来减轻遗忘，通常需要大量的图像集合。相比之下，潜在重放只保留模型内部架构提取的紧凑的高层特征表示，这类似于海马体存储神经活动模式而不是原始感官输入，从而减少内存使用同时保留关键信息。通过五种连续学习的视觉概念实验，我们证明了潜在重放在保持模型的通用性方面显著优于现有方法。在学习所有概念之后，我们的方法在最早的概念上保留了77.59%的图像对齐（IA），比基线方法高14%，同时保持了多样的输出。令人惊讶的是，随机选择存储的潜在示例的表现优于基于相似性的策略。我们的研究结果表明，潜在重放能够实现生成型AI模型的有效持续学习，为根据用户需求发展个性化的文本到图像模型铺平了道路，且无需过多的计算成本。', 'title_zh': '基于潜在空间重播缓解文本到图像扩散模型中的灾难性遗忘和模式collapse'}
{'arxiv_id': 'arXiv:2509.10528', 'title': 'STM-Graph: A Python Framework for Spatio-Temporal Mapping and Graph Neural Network Predictions', 'authors': 'Amirhossein Ghaffari, Huong Nguyen, Lauri Lovén, Ekaterina Gilman', 'link': 'https://arxiv.org/abs/2509.10528', 'abstract': 'Urban spatio-temporal data present unique challenges for predictive analytics due to their dynamic and complex nature. We introduce STM-Graph, an open-source Python framework that transforms raw spatio-temporal urban event data into graph representations suitable for Graph Neural Network (GNN) training and prediction. STM-Graph integrates diverse spatial mapping methods, urban features from OpenStreetMap, multiple GNN models, comprehensive visualization tools, and a graphical user interface (GUI) suitable for professional and non-professional users. This modular and extensible framework facilitates rapid experimentation and benchmarking. It allows integration of new mapping methods and custom models, making it a valuable resource for researchers and practitioners in urban computing. The source code of the framework and GUI are available at: this https URL and this https URL.', 'abstract_zh': '城市时空数据因其动态和复杂性，为预测分析带来了独特的挑战。本文介绍了STM-Graph，一个开源Python框架，将原始的时空城市事件数据转换为适用于图神经网络（GNN）训练和预测的图表示。STM-Graph集成了多种空间映射方法、来自OpenStreetMap的urban特征、多种GNN模型、全面的可视化工具以及适合专业和非专业用户的图形用户界面（GUI）。该模块化和可扩展的框架便于快速实验和基准测试。它允许集成新的映射方法和自定义模型，使其成为城市计算研究者和实践者的重要资源。该框架和GUI的源代码可在以下链接获取：this https URL 和 this https URL。', 'title_zh': 'STM-Graph: 一种时空映射与图神经网络预测的Python框架'}
{'arxiv_id': 'arXiv:2509.10526', 'title': 'Resource-Aware Neural Network Pruning Using Graph-based Reinforcement Learning', 'authors': 'Dieter Balemans, Thomas Huybrechts, Jan Steckel, Siegfried Mercelis', 'link': 'https://arxiv.org/abs/2509.10526', 'abstract': "This paper presents a novel approach to neural network pruning by integrating a graph-based observation space into an AutoML framework to address the limitations of existing methods. Traditional pruning approaches often depend on hand-crafted heuristics and local optimization perspectives, which can lead to suboptimal performance and inefficient pruning strategies. Our framework transforms the pruning process by introducing a graph representation of the target neural network that captures complete topological relationships between layers and channels, replacing the limited layer-wise observation space with a global view of network structure. The core innovations include a Graph Attention Network (GAT) encoder that processes the network's graph representation and generates a rich embedding. Additionally, for the action space we transition from continuous pruning ratios to fine-grained binary action spaces which enables the agent to learn optimal channel importance criteria directly from data, moving away from predefined scoring functions. These contributions are modelled within a Constrained Markov Decision Process (CMDP) framework, allowing the agent to make informed pruning decisions while adhering to resource constraints such as target compression rates. For this, we design a self-competition reward system that encourages the agent to outperform its previous best performance while satisfying the defined constraints. We demonstrate the effectiveness of our approach through extensive experiments on benchmark datasets including CIFAR-10, CIFAR-100, and ImageNet. The experiments show that our method consistently outperforms traditional pruning techniques, showing state-of-the-art results while learning task-specific pruning strategies that identify functionally redundant connections beyond simple weight magnitude considerations.", 'abstract_zh': '基于图观察空间的自动机器学习框架下的神经网络剪枝新方法', 'title_zh': '基于图强化学习的资源意识神经网络剪枝'}
{'arxiv_id': 'arXiv:2509.10524', 'title': 'Data-Efficient Psychiatric Disorder Detection via Self-supervised Learning on Frequency-enhanced Brain Networks', 'authors': 'Mujie Liu, Mengchu Zhu, Qichao Dong, Ting Dang, Jiangang Ma, Jing Ren, Feng Xia', 'link': 'https://arxiv.org/abs/2509.10524', 'abstract': 'Psychiatric disorders involve complex neural activity changes, with functional magnetic resonance imaging (fMRI) data serving as key diagnostic evidence. However, data scarcity and the diverse nature of fMRI information pose significant challenges. While graph-based self-supervised learning (SSL) methods have shown promise in brain network analysis, they primarily focus on time-domain representations, often overlooking the rich information embedded in the frequency domain. To overcome these limitations, we propose Frequency-Enhanced Network (FENet), a novel SSL framework specially designed for fMRI data that integrates time-domain and frequency-domain information to improve psychiatric disorder detection in small-sample datasets. FENet constructs multi-view brain networks based on the inherent properties of fMRI data, explicitly incorporating frequency information into the learning process of representation. Additionally, it employs domain-specific encoders to capture temporal-spectral characteristics, including an efficient frequency-domain encoder that highlights disease-relevant frequency features. Finally, FENet introduces a domain consistency-guided learning objective, which balances the utilization of diverse information and generates frequency-enhanced brain graph representations. Experiments on two real-world medical datasets demonstrate that FENet outperforms state-of-the-art methods while maintaining strong performance in minimal data conditions. Furthermore, we analyze the correlation between various frequency-domain features and psychiatric disorders, emphasizing the critical role of high-frequency information in disorder detection.', 'abstract_zh': '基于频率增强的神经网络（FENet）在fMRI数据中的精神病障碍检测', 'title_zh': '基于频率增强脑网络的自我监督学习高效精神障碍检测'}
{'arxiv_id': 'arXiv:2509.10523', 'title': 'From Predictions to Explanations: Explainable AI for Autism Diagnosis and Identification of Critical Brain Regions', 'authors': 'Kush Gupta, Amir Aly, Emmanuel Ifeachor, Rohit Shankar', 'link': 'https://arxiv.org/abs/2509.10523', 'abstract': 'Autism spectrum disorder (ASD) is a neurodevelopmental condition characterized by atypical brain maturation. However, the adaptation of transfer learning paradigms in machine learning for ASD research remains notably limited. In this study, we propose a computer-aided diagnostic framework with two modules. This chapter presents a two-module framework combining deep learning and explainable AI for ASD diagnosis. The first module leverages a deep learning model fine-tuned through cross-domain transfer learning for ASD classification. The second module focuses on interpreting the model decisions and identifying critical brain regions. To achieve this, we employed three explainable AI (XAI) techniques: saliency mapping, Gradient-weighted Class Activation Mapping, and SHapley Additive exPlanations (SHAP) analysis. This framework demonstrates that cross-domain transfer learning can effectively address data scarcity in ASD research. In addition, by applying three established explainability techniques, the approach reveals how the model makes diagnostic decisions and identifies brain regions most associated with ASD. These findings were compared against established neurobiological evidence, highlighting strong alignment and reinforcing the clinical relevance of the proposed approach.', 'abstract_zh': '自闭症谱系 disorder (ASD) 是一种神经发育条件，特征为大脑发育异常。然而，将迁移学习范式应用于机器学习的 ASD 研究仍然明显受限。本研究提出了一种计算机辅助诊断框架，包含两个模块。本章介绍了结合深度学习和可解释人工智能的两模块框架，用于 ASD 诊断。第一个模块利用通过跨域迁移学习调整的深度学习模型进行 ASD 分类。第二个模块专注于解释模型决策并识别关键脑区。为此，我们采用了三种可解释人工智能 (XAI) 技术：梯度调控类激活映射、显著性映射和 SHapley 加权解释分析（SHAP）分析。该框架表明，跨域迁移学习可以有效解决 ASD 研究中的数据稀疏问题。此外，通过应用三种成熟的可解释性技术，该方法揭示了模型如何做出诊断决策，并识别与 ASD 最相关的脑区。这些发现与既定的神经生物学证据进行了比较，突出了强烈的一致性，并强化了所提方法的临床相关性。', 'title_zh': '从预测到解释：自解释人工智能在自闭症诊断及关键脑区识别中的应用'}
{'arxiv_id': 'arXiv:2509.10522', 'title': 'Multimodal Deep Learning for ATCO Command Lifecycle Modeling and Workload Prediction', 'authors': 'Kaizhen Tan', 'link': 'https://arxiv.org/abs/2509.10522', 'abstract': 'Air traffic controllers (ATCOs) issue high-intensity voice commands in dense airspace, where accurate workload modeling is critical for safety and efficiency. This paper proposes a multimodal deep learning framework that integrates structured data, trajectory sequences, and image features to estimate two key parameters in the ATCO command lifecycle: the time offset between a command and the resulting aircraft maneuver, and the command duration. A high-quality dataset was constructed, with maneuver points detected using sliding window and histogram-based methods. A CNN-Transformer ensemble model was developed for accurate, generalizable, and interpretable predictions. By linking trajectories to voice commands, this work offers the first model of its kind to support intelligent command generation and provides practical value for workload assessment, staffing, and scheduling.', 'abstract_zh': '空中交通管制员（ATCOs）在密集空域发出高强度语音指令，准确的工作负荷建模对于安全和效率至关重要。本文提出了一种多模态深度学习框架，综合结构化数据、航迹序列和图像特征以估计ATCO命令生命周期中的两个关键参数：指令与后续航空器动作之间的时间偏移以及指令持续时间。通过滑动窗口和直方图方法检测动作点，构建了高质量的数据集。开发了一种CNN-Transformer集成模型，实现准确、可泛化和可解释的预测。通过将航迹与语音指令关联，本研究提供了首个用于智能指令生成的模型，为工作负荷评估、人员配备和排班提供了实际价值。', 'title_zh': '多模态深度学习在ATCO命令生命周期建模与工作负载预测中的应用'}
{'arxiv_id': 'arXiv:2509.10517', 'title': 'A Comparative Benchmark of Federated Learning Strategies for Mortality Prediction on Heterogeneous and Imbalanced Clinical Data', 'authors': 'Rodrigo Tertulino', 'link': 'https://arxiv.org/abs/2509.10517', 'abstract': "Machine learning models hold significant potential for predicting in-hospital mortality, yet data privacy constraints and the statistical heterogeneity of real-world clinical data often hamper their development. Federated Learning (FL) offers a privacy-preserving solution, but its performance under non-Independent and Identically Distributed (non-IID) and imbalanced conditions requires rigorous investigation. The study presents a comparative benchmark of five federated learning strategies: FedAvg, FedProx, FedAdagrad, FedAdam, and FedCluster for mortality prediction. Using the large-scale MIMIC-IV dataset, we simulate a realistic non-IID environment by partitioning data by clinical care unit. To address the inherent class imbalance of the task, the SMOTE-Tomek technique is applied to each client's local training data. Our experiments, conducted over 50 communication rounds, reveal that the regularization-based strategy, FedProx, consistently outperformed other methods, achieving the highest F1-Score of 0.8831 while maintaining stable convergence. While the baseline FedAvg was the most computationally efficient, its predictive performance was substantially lower. Our findings indicate that regularization-based FL algorithms like FedProx offer a more robust and effective solution for heterogeneous and imbalanced clinical prediction tasks than standard or server-side adaptive aggregation methods. The work provides a crucial empirical benchmark for selecting appropriate FL strategies for real-world healthcare applications.", 'abstract_zh': '联邦学习策略在住院 mortality 预测中的比较研究：基于 FedProx 的正则化方法在非独立同分布和不平衡数据条件下的优越性', 'title_zh': '异质性和不平衡临床数据环境下联邦学习策略的死亡率预测比较基准研究'}
{'arxiv_id': 'arXiv:2509.10516', 'title': 'Privacy-Preserving Personalization in Education: A Federated Recommender System for Student Performance Prediction', 'authors': 'Rodrigo Tertulino', 'link': 'https://arxiv.org/abs/2509.10516', 'abstract': 'The increasing digitalization of education presents unprecedented opportunities for data-driven personalization, yet it introduces significant student data privacy challenges. Conventional recommender systems rely on centralized data, a paradigm often incompatible with modern data protection regulations. A novel privacy-preserving recommender system is proposed and evaluated to address this critical issue using Federated Learning (FL). The approach utilizes a Deep Neural Network (DNN) with rich, engineered features from the large-scale ASSISTments educational dataset. A rigorous comparative analysis of federated aggregation strategies was conducted, identifying FedProx as a significantly more stable and effective method for handling heterogeneous student data than the standard FedAvg baseline. The optimized federated model achieves a high-performance F1-Score of 76.28\\%, corresponding to 82.85\\% of the performance of a powerful, centralized XGBoost model. These findings validate that a federated approach can provide highly effective content recommendations without centralizing sensitive student data. Consequently, our work presents a viable and robust solution to the personalization-privacy dilemma in modern educational platforms.', 'abstract_zh': '数字化教育的增加为数据驱动的个性化教学提供了前所未有的机会，但也引入了重大学生数据隐私挑战。传统的推荐系统依赖于集中式数据，这一范式常与现代数据保护法规不兼容。提出并评估了一种基于联邦学习（FL）的新型隐私保护推荐系统，利用深层神经网络（DNN）和大规模ASSISTments教育数据集中的丰富特征来解决这一关键问题。进行了严格的联邦聚合策略对比分析，发现FedProx在处理异构学生数据方面比标准的FedAvg基线更稳定和有效。优化后的联邦模型实现了高性能的F1-Score为76.28%，相当于强大集中式XGBoost模型性能的82.85%。这些发现证明，联邦方法可以在不集中敏感学生数据的情况下提供高效的內容推荐。因此，我们的工作为现代教育平台中的个性化-隐私困境提供了可行且 robust 的解决方案。', 'title_zh': '教育中隐私保护的个性化学习：基于学生的性能预测联邦推荐系统'}
{'arxiv_id': 'arXiv:2509.10511', 'title': 'LogGuardQ: A Cognitive-Enhanced Reinforcement Learning Framework for Cybersecurity Anomaly Detection in Security Logs', 'authors': 'Umberto Gonçalves de Sousa', 'link': 'https://arxiv.org/abs/2509.10511', 'abstract': "Reinforcement learning (RL) has transformed sequential decision-making, but traditional algorithms like Deep Q-Networks (DQNs) and Proximal Policy Optimization (PPO) often struggle with efficient exploration, stability, and adaptability in dynamic environments. This study presents LogGuardQ (Adaptive Log Guard with Cognitive enhancement), a novel framework that integrates a dual-memory system inspired by human cognition and adaptive exploration strategies driven by temperature decay and curiosity. Evaluated on a dataset of 1,000,000 simulated access logs with 47.9% anomalies over 20,000 episodes, LogGuardQ achieves a 96.0% detection rate (versus 93.0% for DQN and 47.1% for PPO), with precision of 0.4776, recall of 0.9996, and an F1-score of 0.6450. The mean reward is 20.34 \\pm 44.63 across all episodes (versus 18.80 \\pm 43.98 for DQN and -0.17 \\pm 23.79 for PPO), with an average of 5.0 steps per episode (constant across models). Graphical analyses, including learning curves smoothed with a Savgol filter (window=501, polynomial=2), variance trends, action distributions, and cumulative detections, demonstrate LogGuardQ's superior stability and efficiency. Statistical tests (Mann-Whitney U) confirm significant performance advantages (e.g., p = 0.0002 vs. DQN with negligible effect size, p < 0.0001 vs. PPO with medium effect size, and p < 0.0001 for DQN vs. PPO with small effect size). By bridging cognitive science and RL, LogGuardQ offers a scalable approach to adaptive learning in uncertain environments, with potential applications in cybersecurity, intrusion detection, and decision-making under uncertainty.", 'abstract_zh': '基于认知增强的LogGuardQ：一种适应动态环境的强化学习框架', 'title_zh': 'LogGuardQ：一种增强认知的强化学习框架，用于安全日志中的网络安全异常检测'}
{'arxiv_id': 'arXiv:2509.10510', 'title': 'FireGNN: Neuro-Symbolic Graph Neural Networks with Trainable Fuzzy Rules for Interpretable Medical Image Classification', 'authors': 'Prajit Sengupta, Islem Rekik', 'link': 'https://arxiv.org/abs/2509.10510', 'abstract': 'Medical image classification requires not only high predictive performance but also interpretability to ensure clinical trust and adoption. Graph Neural Networks (GNNs) offer a powerful framework for modeling relational structures within datasets; however, standard GNNs often operate as black boxes, limiting transparency and usability, particularly in clinical settings. In this work, we present an interpretable graph-based learning framework named FireGNN that integrates trainable fuzzy rules into GNNs for medical image classification. These rules embed topological descriptors - node degree, clustering coefficient, and label agreement - using learnable thresholds and sharpness parameters to enable intrinsic symbolic reasoning. Additionally, we explore auxiliary self-supervised tasks (e.g., homophily prediction, similarity entropy) as a benchmark to evaluate the contribution of topological learning. Our fuzzy-rule-enhanced model achieves strong performance across five MedMNIST benchmarks and the synthetic dataset MorphoMNIST, while also generating interpretable rule-based explanations. To our knowledge, this is the first integration of trainable fuzzy rules within a GNN.', 'abstract_zh': '医学图像分类需要不仅具备高性能的预测能力，还需要具备可解释性以确保临床信任与应用。图神经网络（GNNs）提供了一种强大的框架来建模数据集中的关系结构；然而，标准GNNs通常作为黑匣子操作，限制了透明度和实用性，尤其是在临床环境中。在本文中，我们提出了一种名为FireGNN的可解释的图基学习框架，通过将可训练的模糊规则集成到GNNs中，用于医学图像分类。这些规则嵌入拓扑描述符——节点度数、聚类系数和标签一致性——使用可学习的阈值和锐度参数来实现固有的符号推理能力。此外，我们探讨了辅助半监督任务（如同质性预测、相似性熵）作为测试拓扑学习贡献的基准。我们的增强模糊规则模型在五个MedMNIST基准和合成数据集MorphoMNIST上取得了出色的性能，同时生成了可解释的基于规则的解释。据我们所知，这是将可训练的模糊规则集成到GNN中的首次尝试。', 'title_zh': 'FireGNN：具有可训练模糊规则的神经符号图神经网络及其在可解释医疗图像分类中的应用'}
{'arxiv_id': 'arXiv:2509.10509', 'title': 'The Anti-Ouroboros Effect: Emergent Resilience in Large Language Models from Recursive Selective Feedback', 'authors': 'Sai Teja Reddy Adapala', 'link': 'https://arxiv.org/abs/2509.10509', 'abstract': 'The stability of recursively trained large language models (LLMs) is a foundational problem for AI safety. Prevailing theory predicts model collapse, a progressive degradation when models are trained on their own output. We challenge this narrative by introducing a selective feedback mechanism. Contrary to expectation, instead of merely slowing decay, our experiments provide strong evidence that this pressure reverses it, inducing a statistically significant performance improvement in a Gemma 2B model on a complex summarization task. We name this phenomenon the Anti-Ouroboros Effect. We contrast this with a foundational experiment using a simple classifier, where the theoretical degenerative loop was validated, highlighting the unique dynamics of high-dimensional models. Our findings establish that systemic resilience can be an emergent property of LLMs under simple selection pressure, suggesting a powerful and scalable principle for developing safer and more robust AI systems. Across five generations, a quality-filtered condition improved by 6.6% in ROUGE-L F1 score, whereas an unfiltered control degraded by 3.5% and a random-filter control degraded by 4.2%', 'abstract_zh': '递归训练的大语言模型的稳定性是AI安全的基础问题。我们通过引入选择性反馈机制挑战了现有理论，实验表明这种压力不仅减缓了衰减，还显著逆转了衰减，提升了Gemma 2B模型在复杂总结任务上的性能。我们称这一现象为反奥罗boros效应。我们将这一现象与使用简单分类器的基础实验进行了对比，在后者的实验中验证了理论上的退化循环，突显了高维模型的独特动力学。我们的研究结果表明，在简单选择压力下，系统韧性可以是大语言模型的一个 Emergent 属性，这为开发更安全、更稳健的AI系统提供了一个强大且可扩展的原则。在五代训练中，经过质量过滤的条件ROUGE-L F1分数提高了6.6%，未过滤的对照组下降了3.5%，随机过滤的对照组下降了4.2%。', 'title_zh': '反ouroboros效应：大型语言模型中的递归选择性反馈导致 emergent 弹性'}
{'arxiv_id': 'arXiv:2509.10508', 'title': 'CAR-BRAINet: Sub-6GHz Aided Spatial Adaptive Beam Prediction with Multi Head Attention for Heterogeneous Vehicular Networks', 'authors': 'Aathira G Menon, Prabu Krishnan, Shyam Lal', 'link': 'https://arxiv.org/abs/2509.10508', 'abstract': 'Heterogeneous Vehicular Networks (HetVNets) play a key role by stacking different communication technologies such as sub-6GHz, mm-wave and DSRC to meet diverse connectivity needs of 5G/B5G vehicular networks. HetVNet helps address the humongous user demands-but maintaining a steady connection in a highly mobile, real-world conditions remain a challenge. Though there has been ample of studies on beam prediction models a dedicated solution for HetVNets is sparsely explored. Hence, it is the need of the hour to develop a reliable beam prediction solution, specifically for HetVNets. This paper introduces a lightweight deep learning-based solution termed-"CAR-BRAINet" which consists of convolutional neural networks with a powerful multi-head attention (MHA) mechanism. Existing literature on beam prediction is largely studied under a limited, idealised vehicular scenario, often overlooking the real-time complexities and intricacies of vehicular networks. Therefore, this study aims to mimic the complexities of a real-time driving scenario by incorporating key factors such as prominent MAC protocols-3GPP-C-V2X and IEEE 802.11BD, the effect of Doppler shifts under high velocity and varying distance and SNR levels into three high-quality dynamic datasets pertaining to urban, rural and highway vehicular networks. CAR-BRAINet performs effectively across all the vehicular scenarios, demonstrating precise beam prediction with minimal beam overhead and a steady improvement of 17.9422% on the spectral efficiency over the existing methods. Thus, this study justifies the effectiveness of CAR-BRAINet in complex HetVNets, offering promising performance without relying on the location angle and antenna dimensions of the mobile users, and thereby reducing the redundant sensor-latency.', 'abstract_zh': 'Heterogeneous 车载网络中的轻量级深度学习beam预测解决方案：CAR-BRAINet', 'title_zh': 'CAR-BRAINet: 基于子6GHz辅助空间自适应波束预测的多头注意力异构车辆网络'}
{'arxiv_id': 'arXiv:2509.10507', 'title': 'An Internet of Intelligent Things Framework for Decentralized Heterogeneous Platforms', 'authors': 'Vadim Allayev, Mahbubur Rahman', 'link': 'https://arxiv.org/abs/2509.10507', 'abstract': 'Internet of Intelligent Things (IoIT), an emerging field, combines the utility of Internet of Things (IoT) devices with the innovation of embedded AI algorithms. However, it does not come without challenges, and struggles regarding available computing resources, energy supply, and storage limitations. In particular, many impediments to IoIT are linked to the energy-efficient deployment of machine learning (ML)/deep learning (DL) models in embedded devices. Research has been conducted to design energy-efficient IoIT platforms, but these papers often focus on centralized systems, in which some central entity processes all the data and coordinates actions. This can be problematic, e.g., serve as bottleneck or lead to security concerns. In a decentralized system, nodes/devices would self-organize and make their own decisions. Therefore, to address such issues, we propose a heterogeneous, decentralized sensing and monitoring IoIT peer-to-peer mesh network system model. Nodes in the network will coordinate towards several optimization goals: reliability, energy efficiency, and latency. The system employs federated learning to train nodes in a distributed manner, metaheuristics to optimize task allocation and routing paths, and multi-objective optimization to balance conflicting performance goals.', 'abstract_zh': '互联网智能事物(IoIT)：一种新兴领域及其挑战与对策', 'title_zh': '智能事物互联网框架：去中心化异构平台'}
{'arxiv_id': 'arXiv:2509.10504', 'title': 'Retrosynthesis Planning via Worst-path Policy Optimisation in Tree-structured MDPs', 'authors': 'Mianchu Wang, Giovanni Montana', 'link': 'https://arxiv.org/abs/2509.10504', 'abstract': 'Retrosynthesis planning aims to decompose target molecules into available building blocks, forming a synthesis tree where each internal node represents an intermediate compound and each leaf ideally corresponds to a purchasable reactant. However, this tree becomes invalid if any leaf node is not a valid building block, making the planning process vulnerable to the "weakest link" in the synthetic route. Existing methods often optimise for average performance across branches, failing to account for this worst-case sensitivity. In this paper, we reframe retrosynthesis as a worst-path optimisation problem within tree-structured Markov Decision Processes (MDPs). We prove that this formulation admits a unique optimal solution and offers monotonic improvement guarantees. Building on this insight, we introduce Interactive Retrosynthesis Planning (InterRetro), a method that interacts with the tree MDP, learns a value function for worst-path outcomes, and improves its policy through self-imitation, preferentially reinforcing past decisions with high estimated advantage. Empirically, InterRetro achieves state-of-the-art results, solving 100% of targets on the Retro*-190 benchmark, shortening synthetic routes by 4.9%, and achieving promising performance using only 10% of the training data - representing a significant advance in computational retrosynthesis planning.', 'abstract_zh': '逆合成规划旨在将目标分子分解为可用的构建模块，形成一棵合成树，每个内部节点代表一个中间化合物，每个叶子节点理想地对应于可购买的反应物。然而，如果任何叶子节点不是一个有效的构建模块，这棵树就会失效，使得规划过程容易受到合成路线中最弱环节的影响。现有方法通常优化分支的平均性能，未能考虑最坏情况的敏感性。本文将逆合成规划重新构想为树结构马尔可夫决策过程（MDP）中的最坏路径优化问题。我们证明这种表述存在一个唯一的最优解，并提供单调改进保证。基于这一洞察，我们引入了交互式逆合成规划（InterRetro）方法，该方法与树结构MDP相互作用，学习最坏路径结果的价值函数，并通过自我模仿提升其策略，优先强化高估计优势的以往决策。实验证明，InterRetro达到了最先进的成果，在Retro*-190基准上解决了100%的目标，缩短了合成路线4.9%，并仅使用10%的训练数据就取得了令人鼓舞的性能，这代表了计算逆合成规划的一个显著进展。', 'title_zh': '基于树结构MDP中最坏路径策略优化的 retrosynthesis 规划'}
{'arxiv_id': 'arXiv:2509.10503', 'title': 'FEDEXCHANGE: Bridging the Domain Gap in Federated Object Detection for Free', 'authors': 'Haolin Yuan, Jingtao Li, Weiming Zhuang, Chen Chen, Lingjuan Lyu', 'link': 'https://arxiv.org/abs/2509.10503', 'abstract': "Federated Object Detection (FOD) enables clients to collaboratively train a global object detection model without accessing their local data from diverse domains. However, significant variations in environment, weather, and other domain specific factors hinder performance, making cross domain generalization a key challenge. Existing FOD methods often overlook the hardware constraints of edge devices and introduce local training regularizations that incur high computational costs, limiting real-world applicability. In this paper, we propose FEDEXCHANGE, a novel FOD framework that bridges domain gaps without introducing additional local computational overhead. FEDEXCHANGE employs a server side dynamic model exchange strategy that enables each client to gain insights from other clients' domain data without direct data sharing. Specifically, FEDEXCHANGE allows the server to alternate between model aggregation and model exchange. During aggregation rounds, the server aggregates all local models as usual. In exchange rounds, FEDEXCHANGE clusters and exchanges local models based on distance measures, allowing local models to learn from a variety of domains. As all operations are performed on the server side, clients can achieve improved cross domain utility without any additional computational overhead. Extensive evaluations demonstrate that FEDEXCHANGE enhances FOD performance, achieving 1.6X better mean average precision in challenging domains, such as rainy conditions, while requiring only 0.8X the computational resources compared to baseline methods.", 'abstract_zh': '联邦目标检测 (Federated Object Detection, FOD) 允许客户端在不访问本地多域数据的情况下协同训练一个全局目标检测模型。然而，环境、天气以及其他领域特定因素的重大差异阻碍了性能提升，使得跨域泛化成为主要挑战。现有的 FOD 方法往往忽视了边缘设备的硬件限制并引入了高计算成本的局部训练正则化，限制了其实用性。在本文中，我们提出了一种名为 FEDEXCHANGE 的新颖 FOD 框架，该框架在不增加额外局部计算开销的情况下弥合领域差异。FEDEXCHANGE 采用服务器端动态模型交换策略，使每个客户端能够从其他客户端的领域数据中获得见解，而无需直接共享数据。具体而言，FEDEXCHANGE 允许服务器在模型聚合和模型交换之间交替。在聚合轮次中，服务器按常规聚合所有本地模型。在交换轮次中，FEDEXCHANGE 基于距离度量对齐并交换本地模型，使得局部模型能够学习来自多种领域的知识。由于所有操作都在服务器端执行，客户端可以在没有任何额外计算开销的情况下实现跨域性能改进。广泛评估表明，FEDEXCHANGE 提升了 FOD 性能，在恶劣天气等挑战性领域中实现了 1.6 倍的平均精度，同时仅需基线方法 0.8 倍的计算资源。', 'title_zh': 'FEDEXCHANGE：跨域 federated 物体检测中的领域差距桥梁构建'}
{'arxiv_id': 'arXiv:2509.10501', 'title': 'From Noise to Precision: A Diffusion-Driven Approach to Zero-Inflated Precipitation Prediction', 'authors': 'Wentao Gao, Jiuyong Li, Lin Liu, Thuc Duy Le, Xiongren Chen, Xiaojing Du, Jixue Liu, Yanchang Zhao, Yun Chen', 'link': 'https://arxiv.org/abs/2509.10501', 'abstract': "Zero-inflated data pose significant challenges in precipitation forecasting due to the predominance of zeros with sparse non-zero events. To address this, we propose the Zero Inflation Diffusion Framework (ZIDF), which integrates Gaussian perturbation for smoothing zero-inflated distributions, Transformer-based prediction for capturing temporal patterns, and diffusion-based denoising to restore the original data structure. In our experiments, we use observational precipitation data collected from South Australia along with synthetically generated zero-inflated data. Results show that ZIDF demonstrates significant performance improvements over multiple state-of-the-art precipitation forecasting models, achieving up to 56.7\\% reduction in MSE and 21.1\\% reduction in MAE relative to the baseline Non-stationary Transformer. These findings highlight ZIDF's ability to robustly handle sparse time series data and suggest its potential generalizability to other domains where zero inflation is a key challenge.", 'abstract_zh': 'Zero-Inflated 数据在降水量预报中占主导地位且非零事件稀疏，这对预报构成重大挑战。为应对这一挑战，我们提出了零膨胀扩散框架（ZIDF），该框架结合了高斯扰动用于平滑零膨胀分布、基于变压器的预测用于捕捉时间模式，以及基于扩散的去噪以恢复原始数据结构。实验中，我们使用来自南澳大利亚的观测降水量数据以及合成的零膨胀数据。结果表明，ZIDF 在多个最先进的降水量预报模型中表现出显著的性能提升，相对于非stationary变压器 baseline，MSE 减少了高达 56.7%，MAE 减少了 21.1%。这些发现突显了 ZIDF 在处理稀疏时间序列数据方面的鲁棒性，并暗示其在其他领域中的通用性，尤其是在零膨胀是一个关键挑战的领域中。', 'title_zh': '从噪声到精准：零 inflated 降水预测的扩散驱动方法'}
{'arxiv_id': 'arXiv:2509.10499', 'title': 'Towards Scalable O-RAN Resource Management: Graph-Augmented Proximal Policy Optimization', 'authors': 'Duc-Thinh Ngo, Kandaraj Piamrat, Ons Aouedi, Thomas Hassan, Philippe Raipin-Parvédy', 'link': 'https://arxiv.org/abs/2509.10499', 'abstract': 'Open Radio Access Network (O-RAN) architectures enable flexible, scalable, and cost-efficient mobile networks by disaggregating and virtualizing baseband functions. However, this flexibility introduces significant challenges for resource management, requiring joint optimization of functional split selection and virtualized unit placement under dynamic demands and complex topologies. Existing solutions often address these aspects separately or lack scalability in large and real-world scenarios. In this work, we propose a novel Graph-Augmented Proximal Policy Optimization (GPPO) framework that leverages Graph Neural Networks (GNNs) for topology-aware feature extraction and integrates action masking to efficiently navigate the combinatorial decision space. Our approach jointly optimizes functional split and placement decisions, capturing the full complexity of O-RAN resource allocation. Extensive experiments on both small-and large-scale O-RAN scenarios demonstrate that GPPO consistently outperforms state-of-the-art baselines, achieving up to 18% lower deployment cost and 25% higher reward in generalization tests, while maintaining perfect reliability. These results highlight the effectiveness and scalability of GPPO for practical O-RAN deployments.', 'abstract_zh': '基于图增强近端策略优化的O-RAN资源管理方法', 'title_zh': '面向可扩展的O-RAN资源管理：图增强邻近策略优化'}
{'arxiv_id': 'arXiv:2509.10493', 'title': 'Online Learning Based Efficient Resource Allocation for LoRaWAN Network', 'authors': 'Ruiqi Wang, Jing Ren, Tongyu Song, Wenjun Li, Xiong Wang, Sheng Wang, Shizhong Xu', 'link': 'https://arxiv.org/abs/2509.10493', 'abstract': 'The deployment of large-scale LoRaWAN networks requires jointly optimizing conflicting metrics like Packet Delivery Ratio (PDR) and Energy Efficiency (EE) by dynamically allocating transmission parameters, including Carrier Frequency, Spreading Factor, and Transmission Power. Existing methods often oversimplify this challenge, focusing on a single metric or lacking the adaptability needed for dynamic channel environments, leading to suboptimal performance. To address this, we propose two online learning-based resource allocation frameworks that intelligently navigate the PDR-EE trade-off. Our foundational proposal, D-LoRa, is a fully distributed framework that models the problem as a Combinatorial Multi-Armed Bandit. By decomposing the joint parameter selection and employing specialized, disaggregated reward functions, D-LoRa dramatically reduces learning complexity and enables nodes to autonomously adapt to network dynamics. To further enhance performance in LoRaWAN networks, we introduce CD-LoRa, a hybrid framework that integrates a lightweight, centralized initialization phase to perform a one-time, quasi-optimal channel assignment and action space pruning, thereby accelerating subsequent distributed learning. Extensive simulations and real-world field experiments demonstrate the superiority of our frameworks, showing that D-LoRa excels in non-stationary environments while CD-LoRa achieves the fastest convergence in stationary conditions. In physical deployments, our methods outperform state-of-the-art baselines, improving PDR by up to 10.8% and EE by 26.1%, confirming their practical effectiveness for scalable and efficient LoRaWAN networks.', 'abstract_zh': '大规模LoRaWAN网络的部署需要通过动态分配传输参数（包括载波频率、扩频因子和传输功率）来同时优化如包送达率（PDR）和能量效率（EE）等冲突的指标。现有的方法往往过于简化这一挑战，要么关注单一指标，要么缺乏适应动态信道环境的能力，导致性能不佳。为此，我们提出了两种基于在线学习的资源分配框架，智能化地平衡PDR-EEtrade-off。我们的基础提案D-LoRa是一个完全分布式框架，将其问题建模为组合多臂 bandit 问题。通过分解联合参数选择，并采用专业化、分而治之的奖励函数，D-LoRa明显降低了学习复杂性，并使节点能够自主适应网络动态。为了进一步提升LoRaWAN网络的性能，我们引入了CD-LoRa，这是一种混合框架，集成了一个轻量级的集中式初始化阶段，进行一次性、近似最优的信道分配和动作空间修剪，从而加速后续的分布式学习。通过广泛的仿真实验和实地测试，我们的框架显示出优越性，D-LoRa在非平稳环境中表现出色，而CD-LoRa在稳定条件下实现最快收敛。在物理部署中，我们的方法优于最先进的基线，PDR 提高最多10.8%，EE 提高26.1%，确认了其在可扩展和高效LoRaWAN网络中的实际效果。', 'title_zh': '基于在线学习的LoRaWAN网络高效资源分配'}
{'arxiv_id': 'arXiv:2509.10490', 'title': 'Distributed Gossip-GAN for Low-overhead CSI Feedback Training in FDD mMIMO-OFDM Systems', 'authors': 'Yuwen Cao, Guijun Liu, Tomoaki Ohtsuki, Howard H. Yang, Tony Q. S. Quek', 'link': 'https://arxiv.org/abs/2509.10490', 'abstract': "The deep autoencoder (DAE) framework has turned out to be efficient in reducing the channel state information (CSI) feedback overhead in massive multiple-input multipleoutput (mMIMO) systems. However, these DAE approaches presented in prior works rely heavily on large-scale data collected through the base station (BS) for model training, thus rendering excessive bandwidth usage and data privacy issues, particularly for mMIMO systems. When considering users' mobility and encountering new channel environments, the existing CSI feedback models may often need to be retrained. Returning back to previous environments, however, will make these models perform poorly and face the risk of catastrophic forgetting. To solve the above challenging problems, we propose a novel gossiping generative adversarial network (Gossip-GAN)-aided CSI feedback training framework. Notably, Gossip-GAN enables the CSI feedback training with low-overhead while preserving users' privacy. Specially, each user collects a small amount of data to train a GAN model. Meanwhile, a fully distributed gossip-learning strategy is exploited to avoid model overfitting, and to accelerate the model training as well. Simulation results demonstrate that Gossip-GAN can i) achieve a similar CSI feedback accuracy as centralized training with real-world datasets, ii) address catastrophic forgetting challenges in mobile scenarios, and iii) greatly reduce the uplink bandwidth usage. Besides, our results show that the proposed approach possesses an inherent robustness.", 'abstract_zh': '基于Gossip-GAN的低开销 CSI 反馈训练框架', 'title_zh': '分布式 gossip-GAN 用于 FDD mMIMO-OFDM 系统的低开销CSI反馈训练'}
{'arxiv_id': 'arXiv:2509.10486', 'title': 'SABR: A Stable Adaptive Bitrate Framework Using Behavior Cloning Pretraining and Reinforcement Learning Fine-Tuning', 'authors': 'Pengcheng Luo, Yunyang Zhao, Bowen Zhang, Genke Yang, Boon-Hee Soong, Chau Yuen', 'link': 'https://arxiv.org/abs/2509.10486', 'abstract': 'With the advent of 5G, the internet has entered a new video-centric era. From short-video platforms like TikTok to long-video platforms like Bilibili, online video services are reshaping user consumption habits. Adaptive Bitrate (ABR) control is widely recognized as a critical factor influencing Quality of Experience (QoE). Recent learning-based ABR methods have attracted increasing attention. However, most of them rely on limited network trace sets during training and overlook the wide-distribution characteristics of real-world network conditions, resulting in poor generalization in out-of-distribution (OOD) scenarios. To address this limitation, we propose SABR, a training framework that combines behavior cloning (BC) pretraining with reinforcement learning (RL) fine-tuning. We also introduce benchmarks, ABRBench-3G and ABRBench-4G+, which provide wide-coverage training traces and dedicated OOD test sets for assessing robustness to unseen network conditions. Experimental results demonstrate that SABR achieves the best average rank compared with Pensieve, Comyco, and NetLLM across the proposed benchmarks. These results indicate that SABR enables more stable learning across wide distributions and improves generalization to unseen network conditions.', 'abstract_zh': '随着5G的到来，互联网进入了一个以视频为中心的新时代。从TikTok这样的短视频平台到Bilibili这样的长视频平台，在线视频服务正在重塑用户的消费习惯。自适应比特率（ABR）控制被认为是影响用户体验质量（QoE）的关键因素。近期基于学习的ABR方法引起了越来越多的关注。然而，大多数方法在训练过程中依赖于有限的网络追踪集，并且忽略了实际网络条件的广泛分布特性，导致在未见过的分布（OOD）场景下泛化能力较差。为了解决这一局限，我们提出了一种名为SABR的训练框架，该框架结合了行为克隆（BC）预训练与强化学习（RL）微调。我们还引入了ABRBench-3G和ABRBench-4G+基准测试，提供了广泛的训练轨迹和专门的ODD测试集，用于评估对未见过的网络条件的鲁棒性。实验结果表明，在提出的基准测试中，SABR在与Pensieve、Comyco和NetLLM相比时，平均排名最高。这些结果表明，SABR能够在广泛的分布下实现更稳定的训练，并改善对未见过的网络条件的泛化能力。', 'title_zh': 'SABR：一种基于行为克隆预训练和强化学习微调的稳定自适应比特率框架'}
{'arxiv_id': 'arXiv:2509.10482', 'title': 'AegisShield: Democratizing Cyber Threat Modeling with Generative AI', 'authors': 'Matthew Grofsky', 'link': 'https://arxiv.org/abs/2509.10482', 'abstract': 'The increasing sophistication of technology systems makes traditional threat modeling hard to scale, especially for small organizations with limited resources. This paper develops and evaluates AegisShield, a generative AI enhanced threat modeling tool that implements STRIDE and MITRE ATT&CK to automate threat generation and provide systematic assessments. By integrating real time threat intelligence from the National Vulnerability Database and AlienVault Open Threat Exchange, AegisShield produces streamlined and accessible threat descriptions. Our assessment of 243 threats from 15 case studies and over 8000 AI generated threats shows that AegisShield reduces complexity (p less than 0.001), yields outputs semantically aligned with expert developed threats (p less than 0.05), and achieves an 85.4 percent success rate in mapping threats to MITRE ATT&CK techniques (p less than 0.001). Automating and standardizing threat modeling helps under resourced organizations address risk earlier and supports wider adoption of secure by design practices.', 'abstract_zh': '技术系统的日益复杂性使得传统的威胁建模难以推广，尤其是对于资源有限的小组织。本文开发并评估了AegisShield，这是一种增强型生成AI威胁建模工具，采用STRIDE和MITRE ATT&CK来自动化威胁生成并提供系统性的评估。通过整合来自National Vulnerability Database和AlienVault Open Threat Exchange的实时威胁情报，AegisShield生成了简化且易于访问的威胁描述。对来自15个案例研究的243种威胁和超过8000种AI生成的威胁的评估显示，AegisShield降低了复杂性（p<0.001）、生成的输出与专家开发的威胁在语义上保持一致（p<0.05），并且在将威胁映射到MITRE ATT&CK技术方面达到了85.4%的成功率（p<0.001）。自动化和标准化的威胁建模有助于资源不足的组织更早地应对风险，并支持“设计即安全”的实践更广泛的采用。', 'title_zh': 'AegisShield: 通过生成式AI普及网络威胁建模'}
{'arxiv_id': 'arXiv:2509.10469', 'title': 'Real-Time RAG for the Identification of Supply Chain Vulnerabilities', 'authors': 'Jesse Ponnock, Grace Kenneally, Michael Robert Briggs, Elinor Yeo, Tyrone Patterson III, Nicholas Kinberg, Matthew Kalinowski, David Hechtman', 'link': 'https://arxiv.org/abs/2509.10469', 'abstract': "New technologies in generative AI can enable deeper analysis into our nation's supply chains but truly informative insights require the continual updating and aggregation of massive data in a timely manner. Large Language Models (LLMs) offer unprecedented analytical opportunities however, their knowledge base is constrained to the models' last training date, rendering these capabilities unusable for organizations whose mission impacts rely on emerging and timely information. This research proposes an innovative approach to supply chain analysis by integrating emerging Retrieval-Augmented Generation (RAG) preprocessing and retrieval techniques with advanced web-scraping technologies. Our method aims to reduce latency in incorporating new information into an augmented-LLM, enabling timely analysis of supply chain disruptors. Through experimentation, this study evaluates the combinatorial effects of these techniques towards timeliness and quality trade-offs. Our results suggest that in applying RAG systems to supply chain analysis, fine-tuning the embedding retrieval model consistently provides the most significant performance gains, underscoring the critical importance of retrieval quality. Adaptive iterative retrieval, which dynamically adjusts retrieval depth based on context, further enhances performance, especially on complex sup- ply chain queries. Conversely, fine-tuning the LLM yields limited improvements and higher resource costs, while techniques such as downward query abstraction significantly outperforms upward abstraction in practice.", 'abstract_zh': '新兴生成AI技术可以深入分析我国的供应链，但真正具有信息价值的见解需要及时更新和聚合大量数据。大型语言模型（LLMs）提供了前所未有的分析机会，然而，它们的知识库仅限于模型最后一次训练的日期，使得依赖于及时信息的组织无法使用这些功能。本研究提出了一种创新的供应链分析方法，即将新兴的检索增强生成（RAG）预处理和检索技术与先进的网络抓取技术结合。该方法旨在减少将新信息纳入增强LLM中的延迟，从而实现对供应链中断因素的及时分析。通过实验，本研究评估了这些技术组合对及时性和质量权衡的影响。结果显示，在将RAG系统应用于供应链分析时，持续优化嵌入式检索模型提供了显著的性能改进，突显了检索质量的至关重要性。动态迭代检索（根据上下文动态调整检索深度）进一步提升了性能，尤其是在复杂的供应链查询中。相反，微调LLM仅提供了有限的改进并增加了更多的资源成本，而实际应用中向下抽象查询的效果显著优于向上抽象。', 'title_zh': '实时RAG在识别供应链漏洞中的应用'}
{'arxiv_id': 'arXiv:2509.10468', 'title': 'Learning Decomposed Contextual Token Representations from Pretrained and Collaborative Signals for Generative Recommendation', 'authors': 'Yifan Liu, Yaokun Liu, Zelin Li, Zhenrui Yue, Gyuseok Lee, Ruichen Yao, Yang Zhang, Dong Wang', 'link': 'https://arxiv.org/abs/2509.10468', 'abstract': 'Recent advances in generative recommenders adopt a two-stage paradigm: items are first tokenized into semantic IDs using a pretrained tokenizer, and then large language models (LLMs) are trained to generate the next item via sequence-to-sequence modeling. However, these two stages are optimized for different objectives: semantic reconstruction during tokenizer pretraining versus user interaction modeling during recommender training. This objective misalignment leads to two key limitations: (i) suboptimal static tokenization, where fixed token assignments fail to reflect diverse usage contexts; and (ii) discarded pretrained semantics, where pretrained knowledge - typically from language model embeddings - is overwritten during recommender training on user interactions. To address these limitations, we propose to learn DEcomposed COntextual Token Representations (DECOR), a unified framework that preserves pretrained semantics while enhancing the adaptability of token embeddings. DECOR introduces contextualized token composition to refine token embeddings based on user interaction context, and decomposed embedding fusion that integrates pretrained codebook embeddings with newly learned collaborative embeddings. Experiments on three real-world datasets demonstrate that DECOR consistently outperforms state-of-the-art baselines in recommendation performance. Our code will be made available upon publication.', 'abstract_zh': '近期生成型推荐系统的进展采用了两阶段范式：首先使用预训练的分词器将物品 token 化为语义 ID，然后通过序列到序列建模训练大规模语言模型生成下一个物品。然而，这两阶段优化的目标不同：分词器预训练期间的语义重建与推荐器训练期间的用户交互建模。这种目标不一致性导致了两个关键限制：(i) 不理想的静态 token 化，其中固定的 token 分配无法反映不同的使用上下文；和(ii) 预训练语义的丢失，在用户交互驱动的推荐器训练中，预训练知识（通常是语言模型嵌入）被覆盖。为了解决这些限制，我们提出了一种统一框架 DEcomposed COntextual Token Representations (DECOR)，该框架保留了预训练语义的同时增强了 token 嵌入的适应性。DECOR 引入了基于用户交互上下文的 token 组合模块，以细化 token 嵌入，并结合了预训练编码本体嵌入与新学习的协作嵌入的分解嵌入融合。在三个真实世界数据集上的实验表明，DECOR 在推荐性能上始终优于最先进的基线方法。我们的代码将在发表后开源。', 'title_zh': '从预训练和协作信号中学习分解的上下文词表示以进行生成性推荐'}
{'arxiv_id': 'arXiv:2509.10467', 'title': 'DSRAG: A Domain-Specific Retrieval Framework Based on Document-derived Multimodal Knowledge Graph', 'authors': 'Mengzheng Yang, Yanfei Ren, David Osei Opoku, Ruochang Li, Peng Ren, Chunxiao Xing', 'link': 'https://arxiv.org/abs/2509.10467', 'abstract': 'Current general-purpose large language models (LLMs) commonly exhibit knowledge hallucination and insufficient domain-specific adaptability in domain-specific tasks, limiting their effectiveness in specialized question answering scenarios. Retrieval-augmented generation (RAG) effectively tackles these challenges by integrating external knowledge to enhance accuracy and relevance. However, traditional RAG still faces limitations in domain knowledge accuracy and context this http URL enhance domain-specific question answering performance, this work focuses on a graph-based RAG framework, emphasizing the critical role of knowledge graph quality during the generation process. We propose DSRAG (Domain-Specific RAG), a multimodal knowledge graph-driven retrieval-augmented generation framework designed for domain-specific applications. Our approach leverages domain-specific documents as the primary knowledge source, integrating heterogeneous information such as text, images, and tables to construct a multimodal knowledge graph covering both conceptual and instance layers. Building on this foundation, we introduce semantic pruning and structured subgraph retrieval mechanisms, combining knowledge graph context and vector retrieval results to guide the language model towards producing more reliable responses. Evaluations using the Langfuse multidimensional scoring mechanism show that our method excels in domain-specific question answering, validating the efficacy of integrating multimodal knowledge graphs with retrieval-augmented generation.', 'abstract_zh': '当前通用的大规模语言模型（LLMs）在特定领域任务中常表现出知识幻觉和领域特定适应性不足的问题，限制了其在专门化问答场景中的效果。检索增强生成（RAG）通过整合外部知识有效解决了这些挑战，增强了准确性和相关性。然而，传统的RAG仍然在领域知识准确性和上下文整合方面存在局限性。为提升领域特定问答性能，本项工作专注于图结构化的RAG框架，并强调生成过程中知识图质量的关键作用。我们提出了DSRAG（领域特定RAG），这是一种以多模态知识图驱动的检索增强生成框架，旨在服务于特定领域应用。我们的方法主要利用领域特定文档作为知识源，整合文本、图像和表格等多种异构信息，构建覆盖概念层和实例层的多模态知识图。基于此基础，我们引入了语义剪枝和结构化子图检索机制，结合知识图语境和向量检索结果来指导语言模型产生更可靠的回复。通过Langfuse多维评分机制的评估显示，我们的方法在领域特定问答任务中表现出色，验证了将多模态知识图与检索增强生成相结合的有效性。', 'title_zh': 'DSRAG：基于文档衍生多模态知识图谱的领域定制检索框架'}
{'arxiv_id': 'arXiv:2509.10461', 'title': 'Momentum-integrated Multi-task Stock Recommendation with Converge-based Optimization', 'authors': 'Hao Wang, Jingshu Peng, Yanyan Shen, Xujia Li, Lei Chen', 'link': 'https://arxiv.org/abs/2509.10461', 'abstract': "Stock recommendation is critical in Fintech applications, which use price series and alternative information to estimate future stock performance. Although deep learning models are prevalent in stock recommendation systems, traditional time-series forecasting training often fails to capture stock trends and rankings simultaneously, which are essential consideration factors for investors. To tackle this issue, we introduce a Multi-Task Learning (MTL) framework for stock recommendation, \\textbf{M}omentum-\\textbf{i}ntegrated \\textbf{M}ulti-task \\textbf{Stoc}k \\textbf{R}ecommendation with Converge-based Optimization (\\textbf{MiM-StocR}). To improve the model's ability to capture short-term trends, we novelly invoke a momentum line indicator in model training. To prioritize top-performing stocks and optimize investment allocation, we propose a list-wise ranking loss function called Adaptive-k ApproxNDCG. Moreover, due to the volatility and uncertainty of the stock market, existing MTL frameworks face overfitting issues when applied to stock time series. To mitigate this issue, we introduce the Converge-based Quad-Balancing (CQB) method. We conducted extensive experiments on three stock benchmarks: SEE50, CSI 100, and CSI 300. MiM-StocR outperforms state-of-the-art MTL baselines across both ranking and profitable evaluations.", 'abstract_zh': '基于动量整合的多任务学习股票推荐模型MiM-StocR', 'title_zh': '基于收敛优化的动量集成多任务股票推荐'}
{'arxiv_id': 'arXiv:2509.01058', 'title': 'Speaking at the Right Level: Literacy-Controlled Counterspeech Generation with RAG-RL', 'authors': 'Xiaoying Song, Anirban Saha Anik, Dibakar Barua, Pengcheng Luo, Junhua Ding, Lingzi Hong', 'link': 'https://arxiv.org/abs/2509.01058', 'abstract': 'Health misinformation spreading online poses a significant threat to public health. Researchers have explored methods for automatically generating counterspeech to health misinformation as a mitigation strategy. Existing approaches often produce uniform responses, ignoring that the health literacy level of the audience could affect the accessibility and effectiveness of counterspeech. We propose a Controlled-Literacy framework using retrieval-augmented generation (RAG) with reinforcement learning (RL) to generate tailored counterspeech adapted to different health literacy levels. In particular, we retrieve knowledge aligned with specific health literacy levels, enabling accessible and factual information to support generation. We design a reward function incorporating subjective user preferences and objective readability-based rewards to optimize counterspeech to the target health literacy level. Experiment results show that Controlled-Literacy outperforms baselines by generating more accessible and user-preferred counterspeech. This research contributes to more equitable and impactful public health communication by improving the accessibility and comprehension of counterspeech to health misinformation', 'abstract_zh': '健康 misinformation 在线传播对公共健康构成重大威胁。研究人员探索了自动生成针对健康 misinformation 的反制言论的方法，以减轻其影响。现有方法通常生成统一的响应，忽视了受众的健康素养水平可能会对反制言论的可达性和有效性产生影响。我们提出了一种控制健康素养水平的框架，结合检索增强生成（RAG）和强化学习（RL）来生成针对不同健康素养水平的个性化反制言论。特别是，我们检索与特定健康素养水平相符的知识，使生成的信息更具可达性和可靠性。我们设计了一种奖励函数，结合主观用户偏好和基于客观可读性的奖励，以优化针对目标健康素养水平的反制言论。实验结果表明，控制健康素养水平框架在生成更为可达和用户偏好的反制言论方面优于基线方法。此研究通过提高反制言论针对健康 misinformation 的可达性和理解度，促进了更具包容性和影响力的公共健康沟通。', 'title_zh': '在合适的层级发言：基于RAG-RL的 literacy 控制式反驳生成'}
{'arxiv_id': 'arXiv:2509.01053', 'title': 'A Dynamic Fusion Model for Consistent Crisis Response', 'authors': 'Xiaoying Song, Anirban Saha Anik, Eduardo Blanco, Vanessa Frias-Martinez, Lingzi Hong', 'link': 'https://arxiv.org/abs/2509.01053', 'abstract': 'In response to the urgent need for effective communication with crisis-affected populations, automated responses driven by language models have been proposed to assist in crisis communications. A critical yet often overlooked factor is the consistency of response style, which could affect the trust of affected individuals in responders. Despite its importance, few studies have explored methods for maintaining stylistic consistency across generated responses. To address this gap, we propose a novel metric for evaluating style consistency and introduce a fusion-based generation approach grounded in this metric. Our method employs a two-stage process: it first assesses the style of candidate responses and then optimizes and integrates them at the instance level through a fusion process. This enables the generation of high-quality responses while significantly reducing stylistic variation between instances. Experimental results across multiple datasets demonstrate that our approach consistently outperforms baselines in both response quality and stylistic uniformity.', 'abstract_zh': '针对危机受影响人群有效沟通的迫切需求，基于语言模型的自动化响应被提出以协助危机沟通。一致性的回应风格是至关重要的但常被忽视的因素，这可能影响受影响个体对响应者的信任。尽管其重要性不言而喻，但鲜有研究探索在生成的响应之间维持风格一致性的方法。为弥补这一空白，我们提出了一种新的风格一致性评估指标，并引入了一种基于该指标的融合生成方法。我们的方法采用两阶段过程：首先评估候选回应的风格，然后通过融合过程在实例级别优化和整合它们。这使得生成高质量的回应的同时显著减少了实例间的风格变异。跨多个数据集的实验结果表明，我们的方法在响应质量和风格一致性方面均显著优于基线方法。', 'title_zh': '一种一致性的危机响应动态融合模型'}
{'arxiv_id': 'arXiv:2504.07483', 'title': 'Program Skeletons for Automated Program Translation', 'authors': 'Bo Wang, Tianyu Li, Ruishi Li, Umang Mathur, Prateek Saxena', 'link': 'https://arxiv.org/abs/2504.07483', 'abstract': 'Translating software between programming languages is a challenging task, for which automated techniques have been elusive and hard to scale up to larger programs. A key difficulty in cross-language translation is that one has to re-express the intended behavior of the source program into idiomatic constructs of a different target language. This task needs abstracting away from the source language-specific details, while keeping the overall functionality the same. In this work, we propose a novel and systematic approach for making such translation amenable to automation based on a framework we call program skeletons. A program skeleton retains the high-level structure of the source program by abstracting away and effectively summarizing lower-level concrete code fragments, which can be mechanically translated to the target programming language. A skeleton, by design, permits many different ways of filling in the concrete implementation for fragments, which can work in conjunction with existing data-driven code synthesizers. Most importantly, skeletons can conceptually enable sound decomposition, i.e., if each individual fragment is correctly translated, taken together with the mechanically translated skeleton, the final translated program is deemed to be correct as a whole. We present a prototype system called Skel embodying the idea of skeleton-based translation from Python to JavaScript. Our results show promising scalability compared to prior works. For 9 real-world Python programs, some with more than about 1k lines of code, 95% of their code fragments can be automatically translated, while about 5% require manual effort. All the final translations are correct with respect to whole-program test suites.', 'abstract_zh': '基于程序框架的跨语言自动化翻译：从Python到JavaScript', 'title_zh': '自动程序翻译的程序骨架'}
{'arxiv_id': 'arXiv:2410.06927', 'title': 'Spectral and Rhythm Features for Audio Classification with Deep Convolutional Neural Networks', 'authors': 'Friedrich Wolf-Monheim', 'link': 'https://arxiv.org/abs/2410.06927', 'abstract': 'Convolutional neural networks (CNNs) are widely used in computer vision. They can be used not only for conventional digital image material to recognize patterns, but also for feature extraction from digital imagery representing spectral and rhythm features extracted from time-domain digital audio signals for the acoustic classification of sounds. Different spectral and rhythm feature representations like mel-scaled spectrograms, mel-frequency cepstral coefficients (MFCCs), cyclic tempograms, short-time Fourier transform (STFT) chromagrams, constant-Q transform (CQT) chromagrams and chroma energy normalized statistics (CENS) chromagrams are investigated in terms of the audio classification performance using a deep convolutional neural network. It can be clearly shown that the mel-scaled spectrograms and the mel-frequency cepstral coefficients (MFCCs) perform significantly better than the other spectral and rhythm features investigated in this research for audio classification tasks using deep CNNs. The experiments were carried out with the aid of the ESC-50 dataset with 2,000 labeled environmental audio recordings.', 'abstract_zh': '卷积神经网络（CNNs）在计算机视觉中广泛应用。它们不仅可以用于模式识别的传统数字图像材料，还可以用于从代表时域数字音频信号的光谱和节律特征的数字图像中提取特征，以进行声音的声学分类。研究表明，在使用深度卷积神经网络进行音频分类时，梅尔标度频谱图和梅尔频率倒谱系数（MFCCs）的表现显著优于其他研究中探究的光谱和节律特征。实验使用包含2000个标记环境音频记录的ESC-50数据集进行。', 'title_zh': '基于深卷积神经网络的音频分类的光谱和节奏特征'}
