# ForesightNav: Learning Scene Imagination for Efficient Exploration 

**Title (ZH)**: 预见导航：学习场景想象以实现高效探索 

**Authors**: Hardik Shah, Jiaxu Xing, Nico Messikommer, Boyang Sun, Marc Pollefeys, Davide Scaramuzza  

**Link**: [PDF](https://arxiv.org/pdf/2504.16062)  

**Abstract**: Understanding how humans leverage prior knowledge to navigate unseen environments while making exploratory decisions is essential for developing autonomous robots with similar abilities. In this work, we propose ForesightNav, a novel exploration strategy inspired by human imagination and reasoning. Our approach equips robotic agents with the capability to predict contextual information, such as occupancy and semantic details, for unexplored regions. These predictions enable the robot to efficiently select meaningful long-term navigation goals, significantly enhancing exploration in unseen environments. We validate our imagination-based approach using the Structured3D dataset, demonstrating accurate occupancy prediction and superior performance in anticipating unseen scene geometry. Our experiments show that the imagination module improves exploration efficiency in unseen environments, achieving a 100% completion rate for PointNav and an SPL of 67% for ObjectNav on the Structured3D Validation split. These contributions demonstrate the power of imagination-driven reasoning for autonomous systems to enhance generalizable and efficient exploration. 

**Abstract (ZH)**: 理解人类如何利用先验知识在未见环境中进行探索性决策对于开发具备类似能力的自主机器人至关重要。在这项工作中，我们提出了一种名为ForesightNav的新颖探索策略，该策略灵感来自人类的想象力和推理能力。我们的方法为机器人代理提供了预测未探索区域上下文信息（如占用情况和语义细节）的能力。这些预测使机器人能够高效地选择有意义的长-term导航目标，显著增强在未见环境中的探索。我们使用Structured3D数据集验证了基于想象力的方法，展示了准确的占用情况预测能力，并在预测未见场景几何形状方面表现出优越性能。我们的实验表明，想象力模块在未见环境中提高了探索效率，在PointNav验证集上实现了100%的任务完成率，在ObjectNav上达到了67%的SPL。这些贡献证明了基于想象力推理在自主系统中增强可泛化和高效探索的能力。 

---
# Bidirectional Task-Motion Planning Based on Hierarchical Reinforcement Learning for Strategic Confrontation 

**Title (ZH)**: 基于层次强化学习的双向任务-运动规划在战略对抗中的应用 

**Authors**: Qizhen Wu Lei Chen, Kexin Liu, Jinhu Lü  

**Link**: [PDF](https://arxiv.org/pdf/2504.15876)  

**Abstract**: In swarm robotics, confrontation scenarios, including strategic confrontations, require efficient decision-making that integrates discrete commands and continuous actions. Traditional task and motion planning methods separate decision-making into two layers, but their unidirectional structure fails to capture the interdependence between these layers, limiting adaptability in dynamic environments. Here, we propose a novel bidirectional approach based on hierarchical reinforcement learning, enabling dynamic interaction between the layers. This method effectively maps commands to task allocation and actions to path planning, while leveraging cross-training techniques to enhance learning across the hierarchical framework. Furthermore, we introduce a trajectory prediction model that bridges abstract task representations with actionable planning goals. In our experiments, it achieves over 80\% in confrontation win rate and under 0.01 seconds in decision time, outperforming existing approaches. Demonstrations through large-scale tests and real-world robot experiments further emphasize the generalization capabilities and practical applicability of our method. 

**Abstract (ZH)**: swarm robotics 中的对抗场景，包括战略对抗，需要高效结合离散命令和连续动作的决策机制。传统的任务和运动规划方法将决策分割为两个层面，但其单向结构无法有效捕捉这两个层面之间的相互依赖性，限制了在动态环境中的适应性。为此，我们提出了一种基于分层强化学习的双向方法，允许两个层面之间进行动态交互。该方法有效地将命令映射到任务分配并将动作映射到路径规划，同时利用交叉训练技术增强分层框架内的学习效果。此外，我们引入了一种轨迹预测模型，将抽象的任务表示与可执行的规划目标连接起来。在我们的实验中，该方法在对抗胜利率上超过80%，决策时间低于0.01秒，并优于现有方法。大规模测试和实际机器人实验的演示进一步突显了该方法的泛化能力和实际应用价值。 

---
# Symbolic Runtime Verification and Adaptive Decision-Making for Robot-Assisted Dressing 

**Title (ZH)**: 符号运行时验证与适应性决策-making for Robot-Assisted Dressing 

**Authors**: Yasmin Rafiq, Gricel Vázquez, Radu Calinescu, Sanja Dogramadzi, Robert M Hierons  

**Link**: [PDF](https://arxiv.org/pdf/2504.15666)  

**Abstract**: We present a control framework for robot-assisted dressing that augments low-level hazard response with runtime monitoring and formal verification. A parametric discrete-time Markov chain (pDTMC) models the dressing process, while Bayesian inference dynamically updates this pDTMC's transition probabilities based on sensory and user feedback. Safety constraints from hazard analysis are expressed in probabilistic computation tree logic, and symbolically verified using a probabilistic model checker. We evaluate reachability, cost, and reward trade-offs for garment-snag mitigation and escalation, enabling real-time adaptation. Our approach provides a formal yet lightweight foundation for safety-aware, explainable robotic assistance. 

**Abstract (ZH)**: 机器人辅助穿衣操作中具有运行时监控和形式验证的低层危害响应增强控制框架 

---
# A Vision-Enabled Prosthetic Hand for Children with Upper Limb Disabilities 

**Title (ZH)**: 上肢残疾儿童的基于视觉的假肢手 

**Authors**: Md Abdul Baset Sarker, Art Nguyen, Sigmond Kukla, Kevin Fite, Masudul H. Imtiaz  

**Link**: [PDF](https://arxiv.org/pdf/2504.15654)  

**Abstract**: This paper introduces a novel AI vision-enabled pediatric prosthetic hand designed to assist children aged 10-12 with upper limb disabilities. The prosthesis features an anthropomorphic appearance, multi-articulating functionality, and a lightweight design that mimics a natural hand, making it both accessible and affordable for low-income families. Using 3D printing technology and integrating advanced machine vision, sensing, and embedded computing, the prosthetic hand offers a low-cost, customizable solution that addresses the limitations of current myoelectric prostheses. A micro camera is interfaced with a low-power FPGA for real-time object detection and assists with precise grasping. The onboard DL-based object detection and grasp classification models achieved accuracies of 96% and 100% respectively. In the force prediction, the mean absolute error was found to be 0.018. The features of the proposed prosthetic hand can thus be summarized as: a) a wrist-mounted micro camera for artificial sensing, enabling a wide range of hand-based tasks; b) real-time object detection and distance estimation for precise grasping; and c) ultra-low-power operation that delivers high performance within constrained power and resource limits. 

**Abstract (ZH)**: 本文介绍了一种新型AI视觉辅助儿童上肢残疾病童使用的假手，旨在帮助10-12岁的儿童。该假手具备人性化的外观、多关节功能和轻量化设计，模仿自然手的结构，使其对低收入家庭既易于获取又经济实惠。利用3D打印技术和集成先进的机器视觉、传感和嵌入式计算技术，该假手提供了一种低成本、可定制的解决方案，解决了现有肌电假手的局限性。通过接口连接微型摄像头和低功耗FPGA，实现实时物体检测，辅助精准抓取。基于DL的物体检测和抓取分类模型的准确性分别达到96%和100%。在力预估方面，均方绝对误差为0.018。所提出假手的特点可总结为：a) 腕部安装的微型摄像头，实现人工感知，支持广泛的基于手的任务；b) 实时物体检测和距离估算，实现精准抓取；c) 超低功耗操作，能在受限的电源和资源限制内提供高性能。 

---
# Grasping Deformable Objects via Reinforcement Learning with Cross-Modal Attention to Visuo-Tactile Inputs 

**Title (ZH)**: 通过跨模态注意力处理视觉-触觉输入的强化学习抓取变形物体 

**Authors**: Yonghyun Lee, Sungeun Hong, Min-gu Kim, Gyeonghwan Kim, Changjoo Nam  

**Link**: [PDF](https://arxiv.org/pdf/2504.15595)  

**Abstract**: We consider the problem of grasping deformable objects with soft shells using a robotic gripper. Such objects have a center-of-mass that changes dynamically and are fragile so prone to burst. Thus, it is difficult for robots to generate appropriate control inputs not to drop or break the object while performing manipulation tasks. Multi-modal sensing data could help understand the grasping state through global information (e.g., shapes, pose) from visual data and local information around the contact (e.g., pressure) from tactile data. Although they have complementary information that can be beneficial to use together, fusing them is difficult owing to their different properties.
We propose a method based on deep reinforcement learning (DRL) that generates control inputs of a simple gripper from visuo-tactile sensing information. Our method employs a cross-modal attention module in the encoder network and trains it in a self-supervised manner using the loss function of the RL agent. With the multi-modal fusion, the proposed method can learn the representation for the DRL agent from the visuo-tactile sensory data. The experimental result shows that cross-modal attention is effective to outperform other early and late data fusion methods across different environments including unseen robot motions and objects. 

**Abstract (ZH)**: 基于深度强化学习的跨模态注意力方法用于软壳变形物体的抓取控制 

---
# SPECI: Skill Prompts based Hierarchical Continual Imitation Learning for Robot Manipulation 

**Title (ZH)**: SPECI: 基于技能提示的分级连续模仿学习机器人 manipulation 

**Authors**: Jingkai Xu, Xiangli Nie  

**Link**: [PDF](https://arxiv.org/pdf/2504.15561)  

**Abstract**: Real-world robot manipulation in dynamic unstructured environments requires lifelong adaptability to evolving objects, scenes and tasks. Traditional imitation learning relies on static training paradigms, which are ill-suited for lifelong adaptation. Although Continual Imitation Learnin (CIL) enables incremental task adaptation while preserving learned knowledge, current CIL methods primarily overlook the intrinsic skill characteristics of robot manipulation or depend on manually defined and rigid skills, leading to suboptimal cross-task knowledge transfer. To address these issues, we propose Skill Prompts-based HiErarchical Continual Imitation Learning (SPECI), a novel end-to-end hierarchical CIL policy architecture for robot manipulation. The SPECI framework consists of a multimodal perception and fusion module for heterogeneous sensory information encoding, a high-level skill inference module for dynamic skill extraction and selection, and a low-level action execution module for precise action generation. To enable efficient knowledge transfer on both skill and task levels, SPECI performs continual implicit skill acquisition and reuse via an expandable skill codebook and an attention-driven skill selection mechanism. Furthermore, we introduce mode approximation to augment the last two modules with task-specific and task-sharing parameters, thereby enhancing task-level knowledge transfer. Extensive experiments on diverse manipulation task suites demonstrate that SPECI consistently outperforms state-of-the-art CIL methods across all evaluated metrics, revealing exceptional bidirectional knowledge transfer and superior overall performance. 

**Abstract (ZH)**: 基于技能提示的层次化持续模仿学习（SPECI）：机器人操作的高效知识转移架构 

---
# Few-Shot Vision-Language Action-Incremental Policy Learning 

**Title (ZH)**: 少样本视觉-语言动作递增策略学习 

**Authors**: Mingchen Song, Xiang Deng, Guoqiang Zhong, Qi Lv, Jia Wan, Yinchuan Li, Jianye Hao, Weili Guan  

**Link**: [PDF](https://arxiv.org/pdf/2504.15517)  

**Abstract**: Recently, Transformer-based robotic manipulation methods utilize multi-view spatial representations and language instructions to learn robot motion trajectories by leveraging numerous robot demonstrations. However, the collection of robot data is extremely challenging, and existing methods lack the capability for continuous learning on new tasks with only a few demonstrations. In this paper, we formulate these challenges as the Few-Shot Action-Incremental Learning (FSAIL) task, and accordingly design a Task-prOmpt graPh evolutIon poliCy (TOPIC) to address these issues. Specifically, to address the data scarcity issue in robotic imitation learning, TOPIC learns Task-Specific Prompts (TSP) through the deep interaction of multi-modal information within few-shot demonstrations, thereby effectively extracting the task-specific discriminative information. On the other hand, to enhance the capability for continual learning on new tasks and mitigate the issue of catastrophic forgetting, TOPIC adopts a Continuous Evolution Strategy (CES). CES leverages the intrinsic relationships between tasks to construct a task relation graph, which effectively facilitates the adaptation of new tasks by reusing skills learned from previous tasks. TOPIC pioneers few-shot continual learning in the robotic manipulation task, and extensive experimental results demonstrate that TOPIC outperforms state-of-the-art baselines by over 26$\%$ in success rate, significantly enhancing the continual learning capabilities of existing Transformer-based policies. 

**Abstract (ZH)**: Few-Shot Action-Incremental Learning for Robotic Manipulation through Task-prOmpt graPh evolutIon poliCy (TOPIC) 

---
# LAPP: Large Language Model Feedback for Preference-Driven Reinforcement Learning 

**Title (ZH)**: LAPP: 大规模语言模型反馈驱动的偏好强化学习 

**Authors**: Pingcheng Jian, Xiao Wei, Yanbaihui Liu, Samuel A. Moore, Michael M. Zavlanos, Boyuan Chen  

**Link**: [PDF](https://arxiv.org/pdf/2504.15472)  

**Abstract**: We introduce Large Language Model-Assisted Preference Prediction (LAPP), a novel framework for robot learning that enables efficient, customizable, and expressive behavior acquisition with minimum human effort. Unlike prior approaches that rely heavily on reward engineering, human demonstrations, motion capture, or expensive pairwise preference labels, LAPP leverages large language models (LLMs) to automatically generate preference labels from raw state-action trajectories collected during reinforcement learning (RL). These labels are used to train an online preference predictor, which in turn guides the policy optimization process toward satisfying high-level behavioral specifications provided by humans. Our key technical contribution is the integration of LLMs into the RL feedback loop through trajectory-level preference prediction, enabling robots to acquire complex skills including subtle control over gait patterns and rhythmic timing. We evaluate LAPP on a diverse set of quadruped locomotion and dexterous manipulation tasks and show that it achieves efficient learning, higher final performance, faster adaptation, and precise control of high-level behaviors. Notably, LAPP enables robots to master highly dynamic and expressive tasks such as quadruped backflips, which remain out of reach for standard LLM-generated or handcrafted rewards. Our results highlight LAPP as a promising direction for scalable preference-driven robot learning. 

**Abstract (ZH)**: 大型语言模型辅助偏好预测（LAPP）：一种无需大量人力即可实现高效、可定制和表达性强的行为获取的机器人学习新型框架 

---
# Post-Convergence Sim-to-Real Policy Transfer: A Principled Alternative to Cherry-Picking 

**Title (ZH)**: 收敛后从仿真到现实的策略转移：一种 principles 上的替代方案 

**Authors**: Dylan Khor, Bowen Weng  

**Link**: [PDF](https://arxiv.org/pdf/2504.15414)  

**Abstract**: Learning-based approaches, particularly reinforcement learning (RL), have become widely used for developing control policies for autonomous agents, such as locomotion policies for legged robots. RL training typically maximizes a predefined reward (or minimizes a corresponding cost/loss) by iteratively optimizing policies within a simulator. Starting from a randomly initialized policy, the empirical expected reward follows a trajectory with an overall increasing trend. While some policies become temporarily stuck in local optima, a well-defined training process generally converges to a reward level with noisy oscillations. However, selecting a policy for real-world deployment is rarely an analytical decision (i.e., simply choosing the one with the highest reward) and is instead often performed through trial and error. To improve sim-to-real transfer, most research focuses on the pre-convergence stage, employing techniques such as domain randomization, multi-fidelity training, adversarial training, and architectural innovations. However, these methods do not eliminate the inevitable convergence trajectory and noisy oscillations of rewards, leading to heuristic policy selection or cherry-picking. This paper addresses the post-convergence sim-to-real transfer problem by introducing a worst-case performance transference optimization approach, formulated as a convex quadratic-constrained linear programming problem. Extensive experiments demonstrate its effectiveness in transferring RL-based locomotion policies from simulation to real-world laboratory tests. 

**Abstract (ZH)**: 基于学习的方法，尤其是强化学习（RL），已被广泛用于开发自主代理的控制策略，如腿足机器人的运动策略。RL 训练通常通过在模拟器中迭代优化策略来最大化预定义的奖励（或最小化相应的成本/损失）。从一个随机初始化的策略开始，经验期望奖励随时间呈现出整体上升的趋势。虽然有些策略会在局部最优中暂时卡住，但一个定义良好的训练过程通常会通过噪声振荡收敛到一个奖励水平。然而，在实际部署时选择一个策略很少是一个分析决策（即，简单地选择奖励最高的策略），而是经常通过试错来完成。为了改进从仿真到现实世界的迁移，大多数研究集中在收敛前的阶段，采用了领域随机化、多保真度训练、对抗训练和架构创新等技术。然而，这些方法并未消除奖励的不可避免的收敛轨迹和噪声振荡，导致启发式策略选择或挑选手动。本文通过引入最坏情况性能转移优化方法，将其形式化为一个凸的二次约束线性规划问题，解决了收敛后的从仿真到现实世界的迁移问题，广泛的实验证明了其有效性，能够将基于RL的运动策略从仿真环境中转移到现实世界的实验室测试中。 

---
# Advancing Embodied Intelligence in Robotic-Assisted Endovascular Procedures: A Systematic Review of AI Solutions 

**Title (ZH)**: 机器人辅助血管内手术中嵌入式智能的发展：人工智能解决方案的系统评价 

**Authors**: Tianliang Yao, Bo Lu, Markus Kowarschik, Yixuan Yuan, Hubin Zhao, Sebastien Ourselin, Kaspar Althoefer, Junbo Ge, Peng Qi  

**Link**: [PDF](https://arxiv.org/pdf/2504.15327)  

**Abstract**: Endovascular procedures have revolutionized the treatment of vascular diseases thanks to minimally invasive solutions that significantly reduce patient recovery time and enhance clinical outcomes. However, the precision and dexterity required during these procedures poses considerable challenges for interventionists. Robotic systems have emerged offering transformative solutions, addressing issues such as operator fatigue, radiation exposure, and the inherent limitations of human precision. The integration of Embodied Intelligence (EI) into these systems signifies a paradigm shift, enabling robots to navigate complex vascular networks and adapt to dynamic physiological conditions. Data-driven approaches, advanced computer vision, medical image analysis, and machine learning techniques, are at the forefront of this evolution. These methods augment procedural intelligence by facilitating real-time vessel segmentation, device tracking, and anatomical landmark detection. Reinforcement learning and imitation learning further refine navigation strategies and replicate experts' techniques. This review systematically examines the integration of EI principles into robotic technologies, in relation to endovascular procedures. We discuss recent advancements in intelligent perception and data-driven control, and their practical applications in robot-assisted endovascular procedures. By critically evaluating current limitations and emerging opportunities, this review establishes a framework for future developments, emphasizing the potential for greater autonomy and improved clinical outcomes. Emerging trends and specific areas of research, such as federated learning for medical data sharing, explainable AI for clinical decision support, and advanced human-robot collaboration paradigms, are also explored, offering insights into the future direction of this rapidly evolving field. 

**Abstract (ZH)**: 内血管程序通过微创解决方案革新了血管疾病治疗方式，显著缩短了患者的恢复时间并提升了临床效果。然而，这些程序所需的精准度和灵巧性给操作者带来了显著挑战。机器人系统已出现，提供了解决方案，克服了操作疲劳、辐射暴露以及人类精度固有限制等问题。将浸透智能（Embodied Intelligence, EI）融入这些系统标志着 paradigm shift 的到来，使机器人能够导航复杂的血管网络并适应动态生理条件。数据驱动的方法、先进的计算机视觉、医学影像分析和机器学习技术处于这一演变的前沿。这些方法通过实时血管分割、设备跟踪和解剖学标志点检测增强了程序智能。强化学习和模仿学习进一步优化了导航策略并复制了专家的技术。本文系统地探讨了 EI 原理在机器人技术中的集成与内血管程序的关系，讨论了智能感知和数据驱动控制的最新进展及其在辅助内血管程序中的实际应用。通过对现有限制和新兴机遇的批判性评估，本文构建了未来发展的框架，强调了更高的自主性和临床效果的改进潜力。本文还探讨了新兴趋势和具体研究领域，如用于医疗数据共享的联邦学习、可解释的人工智能在临床决策支持中的应用以及先进的人类-机器人协作模式，为这一快速发展的领域指明了未来的方向。 

---
# $π_{0.5}$: a Vision-Language-Action Model with Open-World Generalization 

**Title (ZH)**: $π_{0.5}$：一种具有开放世界泛化能力的视觉-语言-行动模型 

**Authors**: Physical Intelligence, Kevin Black, Noah Brown, James Darpinian, Karan Dhabalia, Danny Driess, Adnan Esmail, Michael Equi, Chelsea Finn, Niccolo Fusai, Manuel Y. Galliker, Dibya Ghosh, Lachy Groom, Karol Hausman, Brian Ichter, Szymon Jakubczak, Tim Jones, Liyiming Ke, Devin LeBlanc, Sergey Levine, Adrian Li-Bell, Mohith Mothukuri, Suraj Nair, Karl Pertsch, Allen Z. Ren, Lucy Xiaoyang Shi, Laura Smith, Jost Tobias Springenberg, Kyle Stachowicz, James Tanner, Quan Vuong, Homer Walke, Anna Walling, Haohuan Wang, Lili Yu, Ury Zhilinsky  

**Link**: [PDF](https://arxiv.org/pdf/2504.16054)  

**Abstract**: In order for robots to be useful, they must perform practically relevant tasks in the real world, outside of the lab. While vision-language-action (VLA) models have demonstrated impressive results for end-to-end robot control, it remains an open question how far such models can generalize in the wild. We describe $\pi_{0.5}$, a new model based on $\pi_{0}$ that uses co-training on heterogeneous tasks to enable broad generalization. $\pi_{0.5}$\ uses data from multiple robots, high-level semantic prediction, web data, and other sources to enable broadly generalizable real-world robotic manipulation. Our system uses a combination of co-training and hybrid multi-modal examples that combine image observations, language commands, object detections, semantic subtask prediction, and low-level actions. Our experiments show that this kind of knowledge transfer is essential for effective generalization, and we demonstrate for the first time that an end-to-end learning-enabled robotic system can perform long-horizon and dexterous manipulation skills, such as cleaning a kitchen or bedroom, in entirely new homes. 

**Abstract (ZH)**: 为了使机器人有用，它们必须在外场执行实际相关任务，而不仅限于实验室。尽管视觉-语言-动作（VLA）模型在外场端到端机器人控制任务中展现了令人印象深刻的成果，但这些模型在外场中的广泛泛化能力仍然有待探索。我们介绍了基于$\pi_{0}$的新模型$\pi_{0.5}$，该模型通过异质任务的协同训练来实现广泛泛化。$\pi_{0.5}$利用多机器人数据、高层语义预测、网络数据及其他来源的数据，使机器人能在多种场景中广泛泛化地执行实际任务。我们的系统结合了协同训练和混合多模态示例，这些示例包含图像观测、语言命令、物体检测、语义子任务预测和低层动作。我们的实验表明，这种知识迁移对于有效的泛化至关重要，并且我们首次证明可以通过端到端学习使机器人系统在外场中执行长时间和灵巧的操作技能，如清洁厨房或卧室等工作，这些操作是在全新的家庭中完成的。 

---
# Beyond Attention: Investigating the Threshold Where Objective Robot Exclusion Becomes Subjective 

**Title (ZH)**: 超越注意力：探究客观机器人排斥转变为主观排斥的阈值 

**Authors**: Clarissa Sabrina Arlinghaus, Ashita Ashok, Ashim Mandal, Karsten Berns, Günter W. Maier  

**Link**: [PDF](https://arxiv.org/pdf/2504.15886)  

**Abstract**: As robots become increasingly involved in decision-making processes (e.g., personnel selection), concerns about fairness and social inclusion arise. This study examines social exclusion in robot-led group interviews by robot Ameca, exploring the relationship between objective exclusion (robot's attention allocation), subjective exclusion (perceived exclusion), mood change, and need fulfillment. In a controlled lab study (N = 35), higher objective exclusion significantly predicted subjective exclusion. In turn, subjective exclusion negatively impacted mood and need fulfillment but only mediated the relationship between objective exclusion and need fulfillment. A piecewise regression analysis identified a critical threshold at which objective exclusion begins to be perceived as subjective exclusion. Additionally, the standing position was the primary predictor of exclusion, whereas demographic factors (e.g., gender, height) had no significant effect. These findings underscore the need to consider both objective and subjective exclusion in human-robot interactions and have implications for fairness in robot-assisted hiring processes. 

**Abstract (ZH)**: 随着机器人在决策过程中（如人员选拔）的作用越来越重要，关于公平性和社会包容性的担忧也随之增加。本研究通过考察由机器人Ameca主导的小组面试中的社会排斥现象，探讨了客观排斥（机器人注意力分配）、主观排斥（被排除感）、情绪变化以及需求满足之间的关系。在一项受控实验室研究中（N=35），较高的客观排斥显著预测了主观排斥。反过来，主观排斥对情绪产生了负面影响，但仅部分中介了客观排斥与需求满足之间的关系。分段回归分析发现了客观排斥开始被感知为主观排斥的关键阈值。此外，站立位置是主要的排斥预测因素，而人口统计学因素（如性别、身高）则没有显著影响。这些发现强调了在人机互动中需同时考虑客观和主观排斥，并对机器人辅助招聘过程中的公平性具有重要意义。 

---
# WALL-E 2.0: World Alignment by NeuroSymbolic Learning improves World Model-based LLM Agents 

**Title (ZH)**: WALL-E 2.0: 由神经符号学习提升的世界模型驱动的大语言模型代理 

**Authors**: Siyu Zhou, Tianyi Zhou, Yijun Yang, Guodong Long, Deheng Ye, Jing Jiang, Chengqi Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2504.15785)  

**Abstract**: Can we build accurate world models out of large language models (LLMs)? How can world models benefit LLM agents? The gap between the prior knowledge of LLMs and the specified environment's dynamics usually bottlenecks LLMs' performance as world models. To bridge the gap, we propose a training-free "world alignment" that learns an environment's symbolic knowledge complementary to LLMs. The symbolic knowledge covers action rules, knowledge graphs, and scene graphs, which are extracted by LLMs from exploration trajectories and encoded into executable codes to regulate LLM agents' policies. We further propose an RL-free, model-based agent "WALL-E 2.0" through the model-predictive control (MPC) framework. Unlike classical MPC requiring costly optimization on the fly, we adopt an LLM agent as an efficient look-ahead optimizer of future steps' actions by interacting with the neurosymbolic world model. While the LLM agent's strong heuristics make it an efficient planner in MPC, the quality of its planned actions is also secured by the accurate predictions of the aligned world model. They together considerably improve learning efficiency in a new environment. On open-world challenges in Mars (Minecraft like) and ALFWorld (embodied indoor environments), WALL-E 2.0 significantly outperforms existing methods, e.g., surpassing baselines in Mars by 16.1%-51.6% of success rate and by at least 61.7% in score. In ALFWorld, it achieves a new record 98% success rate after only 4 iterations. 

**Abstract (ZH)**: 基于大型语言模型的世界模型能否构建精准的世界模型？世界模型如何提升大型语言模型代理的能力？由于大型语言模型先验知识与指定环境动力学之间的差距通常会限制其作为世界模型的表现，为弥合这一差距，我们提出了一种无需训练的“世界对齐”方法，以学习与大型语言模型互补的环境符号知识。这些符号知识包括动作规则、知识图谱和场景图，它们从探索轨迹中由大型语言模型提取并编码为可执行代码以调节大型语言模型代理的策略。我们还提出了一个基于模型的代理“WALL-E 2.0”，通过模型预测控制（MPC）框架实现。不同于经典的MPC需要即时进行昂贵的优化，我们采用大型语言模型代理作为一种高效的未来步骤动作的前瞻优化器，通过与神经符号世界模型交互完成。尽管大型语言模型代理具有很强的启发式方法，使其成为MPC中的高效规划者，但其规划动作的质量也由对齐世界模型的准确预测保障。二者共同显著提高了新环境中的学习效率。在火星（类似Minecraft）和ALFWorld（具身室内环境）的开放世界挑战中，WALL-E 2.0显著优于现有方法，例如，在火星上的成功率提高了16.1%-51.6%，在得分上至少高出61.7%；而在ALFWorld中，经过4次迭代后达到了98%的成功率。 

---
# Advancing Embodied Agent Security: From Safety Benchmarks to Input Moderation 

**Title (ZH)**: 提升实体代理安全：从安全基准到输入调节 

**Authors**: Ning Wang, Zihan Yan, Weiyang Li, Chuan Ma, He Chen, Tao Xiang  

**Link**: [PDF](https://arxiv.org/pdf/2504.15699)  

**Abstract**: Embodied agents exhibit immense potential across a multitude of domains, making the assurance of their behavioral safety a fundamental prerequisite for their widespread deployment. However, existing research predominantly concentrates on the security of general large language models, lacking specialized methodologies for establishing safety benchmarks and input moderation tailored to embodied agents. To bridge this gap, this paper introduces a novel input moderation framework, meticulously designed to safeguard embodied agents. This framework encompasses the entire pipeline, including taxonomy definition, dataset curation, moderator architecture, model training, and rigorous evaluation. Notably, we introduce EAsafetyBench, a meticulously crafted safety benchmark engineered to facilitate both the training and stringent assessment of moderators specifically designed for embodied agents. Furthermore, we propose Pinpoint, an innovative prompt-decoupled input moderation scheme that harnesses a masked attention mechanism to effectively isolate and mitigate the influence of functional prompts on moderation tasks. Extensive experiments conducted on diverse benchmark datasets and models validate the feasibility and efficacy of the proposed approach. The results demonstrate that our methodologies achieve an impressive average detection accuracy of 94.58%, surpassing the performance of existing state-of-the-art techniques, alongside an exceptional moderation processing time of merely 0.002 seconds per instance. 

**Abstract (ZH)**: 具身代理展现出在多个领域的巨大潜力，确保其行为安全是其广泛应用的基本前提。然而，现有研究主要集中于通用大型语言模型的安全性，缺乏针对具身代理的安全基准和输入调节的专门方法。为填补这一空白，本文提出了一种全新的输入调节框架，旨在全面保障具身代理的安全。该框架涵盖了从分类学定义、数据集构建、调节器架构、模型训练到严格评估的全流程。此外，我们引入了EAsafetyBench，这是一种精心构建的安全基准，旨在促进针对具身代理的调节器的训练和严格评估。我们还提出了Pinpoint，一种创新的提示解耦输入调节方案，利用掩码注意机制有效隔离和减轻功能性提示对调节任务的影响。广泛的实验结果表明，所提出的方案在不同基准数据集和模型上具有可行性和有效性。实验结果表明，我们的方法在平均检测准确率上达到了94.58%，并获得了卓越的调节处理速度，每实例仅为0.002秒，超越了现有最先进的技术。 

---
# A Multi-Agent Framework for Automated Qinqiang Opera Script Generation Using Large Language Models 

**Title (ZH)**: 基于大型语言模型的秦腔剧本自动生成多代理框架 

**Authors**: Gengxian Cao, Fengyuan Li, Hong Duan, Ye Yang, Bofeng Wang, Donghe Li  

**Link**: [PDF](https://arxiv.org/pdf/2504.15552)  

**Abstract**: This paper introduces a novel multi-Agent framework that automates the end to end production of Qinqiang opera by integrating Large Language Models , visual generation, and Text to Speech synthesis. Three specialized agents collaborate in sequence: Agent1 uses an LLM to craft coherent, culturally grounded scripts;Agent2 employs visual generation models to render contextually accurate stage scenes; and Agent3 leverages TTS to produce synchronized, emotionally expressive vocal performances. In a case study on Dou E Yuan, the system achieved expert ratings of 3.8 for script fidelity, 3.5 for visual coherence, and 3.8 for speech accuracy-culminating in an overall score of 3.6, a 0.3 point improvement over a Single Agent baseline. Ablation experiments demonstrate that removing Agent2 or Agent3 leads to drops of 0.4 and 0.5 points, respectively, underscoring the value of modular collaboration. This work showcases how AI driven pipelines can streamline and scale the preservation of traditional performing arts, and points toward future enhancements in cross modal alignment, richer emotional nuance, and support for additional opera genres. 

**Abstract (ZH)**: 本文介绍了一种基于大型语言模型、视觉生成和文本转语音合成的新颖多 agent 框架，以自动化秦腔戏曲的全流程生产。三个专门的 agent 按序协作：Agent1 使用大型语言模型创作连贯且具有文化根基的剧本；Agent2 利用视觉生成模型渲染上下文准确的舞台场景；Agent3 利用文本转语音技术生成同步且情感表达丰富的歌声。以《窦娥冤》为例，该系统在剧本忠实度、视觉连贯性和语音准确性方面的专家评分为 3.8、3.5 和 3.8，整体评分为 3.6，比单 agent 基线提高了 0.3 分。消融实验表明，移除 Agent2 或 Agent3 分别会导致评分下降 0.4 和 0.5 分，突显了模块化协作的价值。本文展示了人工智能驱动的工作流如何简化并扩大传统表演艺术的保存规模，并指出了跨模态对齐、更丰富的情感细微差别以及支持更多戏曲种类的未来改进方向。 

---
# PolicyEvol-Agent: Evolving Policy via Environment Perception and Self-Awareness with Theory of Mind 

**Title (ZH)**: PolicyEvol-Agent：基于环境感知和自我意识的意愿理解政策演化 

**Authors**: Yajie Yu, Yue Feng  

**Link**: [PDF](https://arxiv.org/pdf/2504.15313)  

**Abstract**: Multi-agents has exhibited significant intelligence in real-word simulations with Large language models (LLMs) due to the capabilities of social cognition and knowledge retrieval. However, existing research on agents equipped with effective cognition chains including reasoning, planning, decision-making and reflecting remains limited, especially in the dynamically interactive scenarios. In addition, unlike human, prompt-based responses face challenges in psychological state perception and empirical calibration during uncertain gaming process, which can inevitably lead to cognition bias. In light of above, we introduce PolicyEvol-Agent, a comprehensive LLM-empowered framework characterized by systematically acquiring intentions of others and adaptively optimizing irrational strategies for continual enhancement. Specifically, PolicyEvol-Agent first obtains reflective expertise patterns and then integrates a range of cognitive operations with Theory of Mind alongside internal and external perspectives. Simulation results, outperforming RL-based models and agent-based methods, demonstrate the superiority of PolicyEvol-Agent for final gaming victory. Moreover, the policy evolution mechanism reveals the effectiveness of dynamic guideline adjustments in both automatic and human evaluation. 

**Abstract (ZH)**: 基于大型语言模型的多智能体通过系统地获取他人的意图并适应性优化非理性策略以实现持续增强的框架：PolicyEvol-Agent 

---
# Can Machine Learning Agents Deal with Hard Choices? 

**Title (ZH)**: 机器学习代理能够应对艰难的选择吗？ 

**Authors**: Kangyu Wang  

**Link**: [PDF](https://arxiv.org/pdf/2504.15304)  

**Abstract**: Machine Learning ML agents have been increasingly used in decision-making across a wide range of tasks and environments. These ML agents are typically designed to balance multiple objectives when making choices. Understanding how their decision-making processes align with or diverge from human reasoning is essential. Human agents often encounter hard choices, that is, situations where options are incommensurable; neither option is preferred, yet the agent is not indifferent between them. In such cases, human agents can identify hard choices and resolve them through deliberation. In contrast, current ML agents, due to fundamental limitations in Multi-Objective Optimisation or MOO methods, cannot identify hard choices, let alone resolve them. Neither Scalarised Optimisation nor Pareto Optimisation, the two principal MOO approaches, can capture incommensurability. This limitation generates three distinct alignment problems: the alienness of ML decision-making behaviour from a human perspective; the unreliability of preference-based alignment strategies for hard choices; and the blockage of alignment strategies pursuing multiple objectives. Evaluating two potential technical solutions, I recommend an ensemble solution that appears most promising for enabling ML agents to identify hard choices and mitigate alignment problems. However, no known technique allows ML agents to resolve hard choices through deliberation, as they cannot autonomously change their goals. This underscores the distinctiveness of human agency and urges ML researchers to reconceptualise machine autonomy and develop frameworks and methods that can better address this fundamental gap. 

**Abstract (ZH)**: 机器学习代理在决策中的应用及其与人类推理的对齐问题：多目标优化的局限性与技术解决方案 

---
# Navigating the State of Cognitive Flow: Context-Aware AI Interventions for Effective Reasoning Support 

**Title (ZH)**: 认知流动状态导航：基于情境的AI干预以支持有效的推理支持 

**Authors**: Dinithi Dissanayake, Suranga Nanayakkara  

**Link**: [PDF](https://arxiv.org/pdf/2504.16021)  

**Abstract**: Flow theory describes an optimal cognitive state where individuals experience deep focus and intrinsic motivation when a task's difficulty aligns with their skill level. In AI-augmented reasoning, interventions that disrupt the state of cognitive flow can hinder rather than enhance decision-making. This paper proposes a context-aware cognitive augmentation framework that adapts interventions based on three key contextual factors: type, timing, and scale. By leveraging multimodal behavioral cues (e.g., gaze behavior, typing hesitation, interaction speed), AI can dynamically adjust cognitive support to maintain or restore flow. We introduce the concept of cognitive flow, an extension of flow theory in AI-augmented reasoning, where interventions are personalized, adaptive, and minimally intrusive. By shifting from static interventions to context-aware augmentation, our approach ensures that AI systems support deep engagement in complex decision-making and reasoning without disrupting cognitive immersion. 

**Abstract (ZH)**: AI增强推理中的认知流理论与上下文感知的认知增强框架 

---
