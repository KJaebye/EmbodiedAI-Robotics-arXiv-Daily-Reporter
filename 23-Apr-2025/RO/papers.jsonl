{'arxiv_id': 'arXiv:2504.16062', 'title': 'ForesightNav: Learning Scene Imagination for Efficient Exploration', 'authors': 'Hardik Shah, Jiaxu Xing, Nico Messikommer, Boyang Sun, Marc Pollefeys, Davide Scaramuzza', 'link': 'https://arxiv.org/abs/2504.16062', 'abstract': 'Understanding how humans leverage prior knowledge to navigate unseen environments while making exploratory decisions is essential for developing autonomous robots with similar abilities. In this work, we propose ForesightNav, a novel exploration strategy inspired by human imagination and reasoning. Our approach equips robotic agents with the capability to predict contextual information, such as occupancy and semantic details, for unexplored regions. These predictions enable the robot to efficiently select meaningful long-term navigation goals, significantly enhancing exploration in unseen environments. We validate our imagination-based approach using the Structured3D dataset, demonstrating accurate occupancy prediction and superior performance in anticipating unseen scene geometry. Our experiments show that the imagination module improves exploration efficiency in unseen environments, achieving a 100% completion rate for PointNav and an SPL of 67% for ObjectNav on the Structured3D Validation split. These contributions demonstrate the power of imagination-driven reasoning for autonomous systems to enhance generalizable and efficient exploration.', 'abstract_zh': '理解人类如何利用先验知识在未见环境中进行探索性决策对于开发具备类似能力的自主机器人至关重要。在这项工作中，我们提出了一种名为ForesightNav的新颖探索策略，该策略灵感来自人类的想象力和推理能力。我们的方法为机器人代理提供了预测未探索区域上下文信息（如占用情况和语义细节）的能力。这些预测使机器人能够高效地选择有意义的长-term导航目标，显著增强在未见环境中的探索。我们使用Structured3D数据集验证了基于想象力的方法，展示了准确的占用情况预测能力，并在预测未见场景几何形状方面表现出优越性能。我们的实验表明，想象力模块在未见环境中提高了探索效率，在PointNav验证集上实现了100%的任务完成率，在ObjectNav上达到了67%的SPL。这些贡献证明了基于想象力推理在自主系统中增强可泛化和高效探索的能力。', 'title_zh': '预见导航：学习场景想象以实现高效探索'}
{'arxiv_id': 'arXiv:2504.16055', 'title': "SAR4SLPs: An Asynchronous Survey of Speech-Language Pathologists' Perspectives on Socially Assistive Robots", 'authors': 'Denielle Oliva, Abbie Olszewski, David Feil-Seifer', 'link': 'https://arxiv.org/abs/2504.16055', 'abstract': 'Socially Assistive Robots (SARs) offer unique opportunities within speech language pathology (SLP) education and practice by supporting interactive interventions for children with communication disorders. This paper explores the implementation of SAR4SLPs (Socially Assistive Robots for Speech-Language Pathologists) to investigate aspects such as engagement, therapeutic strategy discipline, and consistent intervention support. We assessed the current application of technology to clinical and educational settings, especially with respect to how SLPs might use SAR in their therapeutic work. An asynchronous remote community (ARC) collaborated with a cohort of practicing SLPs to consider the feasibility, potential effectiveness, and anticipated challenges with implementing SARs in day-to-day interventions and as practice facilitators. We focus in particular on the expressive functionality of SARs, modeling a foundational strategy that SLPs employ across various intervention targets. This paper highlights clinician-driven insights and design implications for developing SARs that support specific treatment goals through collaborative and iterative design.', 'abstract_zh': '社会辅助机器人（SARs）在言语语言病理学（SLP）教育和实践中提供了独特的机会，通过支持针对沟通障碍儿童的互动干预措施。本文探讨了SAR4SLPs（社会辅助机器人用于言语语言病理学家）的实施，以研究诸如参与度、治疗策略一致性和持续干预支持等方面。我们评估了技术在临床和教育环境中的当前应用，特别是考虑到言语语言病理学家如何在治疗工作中使用SAR。异步远程社区（ARC）与一组实践中的言语语言病理学家合作，考虑在日常干预中实施SAR以及作为实践促进者的可行性和潜在挑战。本文特别关注SAR的表达功能，模拟了言语语言病理学家在各种干预目标中应用的基础策略。本文强调了临床驱动的观点和设计启示，以促进支持特定治疗目标的SAR的协作和迭代设计。', 'title_zh': 'SAR4SLPs: 社交辅助机器人领域言语语言病理学家观点的异步综述'}
{'arxiv_id': 'arXiv:2504.16037', 'title': 'Adaptive Fault-tolerant Control of Underwater Vehicles with Thruster Failures', 'authors': 'Haolin Liu, Shiliang Zhang, Shangbin Jiao, Xiaohui Zhang, Xuehui Ma, Yan Yan, Wenchuan Cui, Youmin Zhang', 'link': 'https://arxiv.org/abs/2504.16037', 'abstract': 'This paper presents a fault-tolerant control for the trajectory tracking of autonomous underwater vehicles (AUVs) against thruster failures. We formulate faults in AUV thrusters as discrete switching events during a UAV mission, and develop a soft-switching approach in facilitating shift of control strategies across fault scenarios. We mathematically define AUV thruster fault scenarios, and develop the fault-tolerant control that captures the fault scenario via Bayesian approach. Particularly, when the AUV fault type switches from one to another, the developed control captures the fault states and maintains the control by a linear quadratic tracking controller. With the captured fault states by Bayesian approach, we derive the control law by aggregating the control outputs for individual fault scenarios weighted by their Bayesian posterior probability. The developed fault-tolerant control works in an adaptive way and guarantees soft-switching across fault scenarios, and requires no complicated fault detection dedicated to different type of faults. The entailed soft-switching ensures stable AUV trajectory tracking when fault type shifts, which otherwise leads to reduced control under hard-switching control strategies. We conduct numerical simulations with diverse AUV thruster fault settings. The results demonstrate that the proposed control can provide smooth transition across thruster failures, and effectively sustain AUV trajectory tracking control in case of thruster failures and failure shifts.', 'abstract_zh': '针对推进器故障的自主水下车辆轨迹跟踪容错控制', 'title_zh': '基于推进器故障自适应容错控制的水下车辆控制'}
{'arxiv_id': 'arXiv:2504.15976', 'title': 'ad-trait: A Fast and Flexible Automatic Differentiation Library in Rust', 'authors': 'Chen Liang, Qian Wang, Andy Xu, Daniel Rakita', 'link': 'https://arxiv.org/abs/2504.15976', 'abstract': "The Rust programming language is an attractive choice for robotics and related fields, offering highly efficient and memory-safe code. However, a key limitation preventing its broader adoption in these domains is the lack of high-quality, well-supported Automatic Differentiation (AD)-a fundamental technique that enables convenient derivative computation by systematically accumulating data during function evaluation. In this work, we introduce ad-trait, a new Rust-based AD library. Our implementation overloads Rust's standard floating-point type with a flexible trait that can efficiently accumulate necessary information for derivative computation. The library supports both forward-mode and reverse-mode automatic differentiation, making it the first operator-overloading AD implementation in Rust to offer both options. Additionally, ad-trait leverages Rust's performance-oriented features, such as Single Instruction, Multiple Data acceleration in forward-mode AD, to enhance efficiency. Through benchmarking experiments, we show that our library is among the fastest AD implementations across several programming languages for computing derivatives. Moreover, it is already integrated into a Rust-based robotics library, where we showcase its ability to facilitate fast optimization procedures. We conclude with a discussion of the limitations and broader implications of our work.", 'abstract_zh': 'Rust编程语言在机器人技术及相关领域中的应用选择：一种高效且内存安全的自动求导库', 'title_zh': 'ad-trait: 一种快速灵活的自动微分库（Rust 语言实现）'}
{'arxiv_id': 'arXiv:2504.15962', 'title': 'Blimp-based Crime Scene Analysis', 'authors': 'Martin Cooney, Fernando Alonso-Fernandez', 'link': 'https://arxiv.org/abs/2504.15962', 'abstract': 'To tackle the crucial problem of crime, evidence at indoor crime scenes must be analyzed before it becomes contaminated or degraded. Here, as an application of artificial intelligence (AI), computer vision, and robotics, we explore how a blimp could be designed as a kind of "floating camera" to drift over and record evidence with minimal disturbance. In particular, rapid prototyping is used to develop a proof-of-concept to gain insight into what such blimps could do, manually piloted or semi-autonomously. As a result, we show the feasibility of attaching various components to an indoor blimp, and confirm our basic premise, that blimps can sense evidence without producing much wind. Some additional suggestions--regarding mapping, sensing, and path-finding--aim to stimulate the flow of ideas for further exploration.', 'abstract_zh': '基于人工智能、计算机视觉和机器人技术的轻气球在室内犯罪现场勘查中的应用探索：从快速原型设计到概念验证', 'title_zh': '基于Blimp的犯罪现场分析'}
{'arxiv_id': 'arXiv:2504.15953', 'title': 'Visual Place Cell Encoding: A Computational Model for Spatial Representation and Cognitive Mapping', 'authors': 'Chance J. Hamilton, Alfredo Weitzenfeld', 'link': 'https://arxiv.org/abs/2504.15953', 'abstract': 'This paper presents the Visual Place Cell Encoding (VPCE) model, a biologically inspired computational framework for simulating place cell-like activation using visual input. Drawing on evidence that visual landmarks play a central role in spatial encoding, the proposed VPCE model activates visual place cells by clustering high-dimensional appearance features extracted from images captured by a robot-mounted camera. Each cluster center defines a receptive field, and activation is computed based on visual similarity using a radial basis function. We evaluate whether the resulting activation patterns correlate with key properties of biological place cells, including spatial proximity, orientation alignment, and boundary differentiation. Experiments demonstrate that the VPCE can distinguish between visually similar yet spatially distinct locations and adapt to environment changes such as the insertion or removal of walls. These results suggest that structured visual input, even in the absence of motion cues or reward-driven learning, is sufficient to generate place-cell-like spatial representations and support biologically inspired cognitive mapping.', 'abstract_zh': '基于视觉的地点细胞编码模型：生物学启发的视觉地点细胞激活计算框架', 'title_zh': '视觉位置细胞编码：空间表示与认知映射的计算模型'}
{'arxiv_id': 'arXiv:2504.15899', 'title': 'RaSCL: Radar to Satellite Crossview Localization', 'authors': 'Blerim Abdullai, Tony Wang, Xinyuan Qiao, Florian Shkurti, Timothy D. Barfoot', 'link': 'https://arxiv.org/abs/2504.15899', 'abstract': 'GNSS is unreliable, inaccurate, and insufficient in many real-time autonomous field applications. In this work, we present a GNSS-free global localization solution that contains a method of registering imaging radar on the ground with overhead RGB imagery, with joint optimization of relative poses from odometry and global poses from our overhead registration. Previous works have used various combinations of ground sensors and overhead imagery, and different feature extraction and matching methods. These include various handcrafted and deep-learning-based methods for extracting features from overhead imagery. Our work presents insights on extracting essential features from RGB overhead images for effective global localization against overhead imagery using only ground radar and a single georeferenced initial guess. We motivate our method by evaluating it on datasets in diverse geographic conditions and robotic platforms, including on an Unmanned Surface Vessel (USV) as well as urban and suburban driving datasets.', 'abstract_zh': 'GNSS在许多实时自主野外应用中不可靠、不准确且不足。在此工作中，我们提出了一种无需GNSS的全球定位解决方案，该方案包含一种将地面成像雷达与空中RGB图像进行注册的方法，并结合了来自传感器里程计的相对姿态优化和来自我们空中注册的绝对姿态优化。之前的研究所使用了各种地面传感器和空中图像的组合，以及不同的特征提取和匹配方法。这些方法包括用于从空中图像中提取特征的各种手工制作和基于深度学习的方法。我们的研究探讨了仅使用地面雷达和单个地理参考初始猜测，从RGB空中图像中提取关键特征以实现有效全球定位的方法。我们通过对在多种地理条件和机器人平台上的数据集（包括无人水面舰艇USV以及城市和郊区驾驶数据集）进行评估来激励我们的方法。', 'title_zh': '雷达到卫星跨视角定位'}
{'arxiv_id': 'arXiv:2504.15876', 'title': 'Bidirectional Task-Motion Planning Based on Hierarchical Reinforcement Learning for Strategic Confrontation', 'authors': 'Qizhen Wu Lei Chen, Kexin Liu, Jinhu Lü', 'link': 'https://arxiv.org/abs/2504.15876', 'abstract': 'In swarm robotics, confrontation scenarios, including strategic confrontations, require efficient decision-making that integrates discrete commands and continuous actions. Traditional task and motion planning methods separate decision-making into two layers, but their unidirectional structure fails to capture the interdependence between these layers, limiting adaptability in dynamic environments. Here, we propose a novel bidirectional approach based on hierarchical reinforcement learning, enabling dynamic interaction between the layers. This method effectively maps commands to task allocation and actions to path planning, while leveraging cross-training techniques to enhance learning across the hierarchical framework. Furthermore, we introduce a trajectory prediction model that bridges abstract task representations with actionable planning goals. In our experiments, it achieves over 80\\% in confrontation win rate and under 0.01 seconds in decision time, outperforming existing approaches. Demonstrations through large-scale tests and real-world robot experiments further emphasize the generalization capabilities and practical applicability of our method.', 'abstract_zh': '在 swarm 机器人领域，包括战略对抗在内的对抗场景需要高效整合离散命令和连续动作的决策制定。传统任务和运动规划方法将决策制定分成两层，但其单向结构无法捕捉这两层之间的相互依赖性，限制了在动态环境中的适应性。在此，我们提出了一种基于层次强化学习的新型双向方法，使得两层之间能够动态交互。该方法有效地将命令映射到任务分配，并将动作映射到路径规划，同时利用跨训练技术在层次结构框架中增强学习能力。此外，我们引入了一种轨迹预测模型，将抽象的任务表示与可执行的规划目标连接起来。在我们的实验中，该方法的对抗胜率超过80%，决策时间不到0.01秒，优于现有方法。大型规模测试和真实机器人实验进一步强调了该方法的泛化能力和实际应用价值。', 'title_zh': '基于分层强化学习的双向任务-运动规划在战略对抗中的应用'}
{'arxiv_id': 'arXiv:2504.15869', 'title': 'An Extended Horizon Tactical Decision-Making for Automated Driving Based on Monte Carlo Tree Search', 'authors': 'Karim Essalmi, Fernando Garrido, Fawzi Nashashibi', 'link': 'https://arxiv.org/abs/2504.15869', 'abstract': 'This paper introduces COR-MCTS (Conservation of Resources - Monte Carlo Tree Search), a novel tactical decision-making approach for automated driving focusing on maneuver planning over extended horizons. Traditional decision-making algorithms are often constrained by fixed planning horizons, typically up to 6 seconds for classical approaches and 3 seconds for learning-based methods limiting their adaptability in particular dynamic driving scenarios. However, planning must be done well in advance in environments such as highways, roundabouts, and exits to ensure safe and efficient maneuvers. To address this challenge, we propose a hybrid method integrating Monte Carlo Tree Search (MCTS) with our prior utility-based framework, COR-MP (Conservation of Resources Model for Maneuver Planning). This combination enables long-term, real-time decision-making, significantly enhancing the ability to plan a sequence of maneuvers over extended horizons. Through simulations across diverse driving scenarios, we demonstrate that COR-MCTS effectively improves planning robustness and decision efficiency over extended horizons.', 'abstract_zh': 'COR-MCTS：资源保存-蒙特卡洛树搜索在长期内存机动规划中的新型自动化驾驶战术决策方法', 'title_zh': '基于蒙特卡洛树搜索的扩展视野战术决策方法在自动驾驶中的应用'}
{'arxiv_id': 'arXiv:2504.15850', 'title': 'Embedded Safe Reactive Navigation for Multirotors Systems using Control Barrier Functions', 'authors': 'Nazar Misyats, Marvin Harms, Morten Nissov, Martin Jacquet, Kostas Alexis', 'link': 'https://arxiv.org/abs/2504.15850', 'abstract': 'Aiming to promote the wide adoption of safety filters for autonomous aerial robots, this paper presents a safe control architecture designed for seamless integration into widely used open-source autopilots. Departing from methods that require consistent localization and mapping, we formalize the obstacle avoidance problem as a composite control barrier function constructed only from the online onboard range measurements. The proposed framework acts as a safety filter, modifying the acceleration references derived by the nominal position/velocity control loops, and is integrated into the PX4 autopilot stack. Experimental studies using a small multirotor aerial robot demonstrate the effectiveness and performance of the solution within dynamic maneuvering and unknown environments.', 'abstract_zh': '旨在促进自主 aerial 机器人安全过滤器的广泛应用，本文提出了一种安全控制架构，该架构便于无缝集成到广泛使用的开源自动驾驶仪中。不同于需要一致定位和建图的方法，我们将避障问题形式化为仅基于在线机载范围测量构建的复合控制屏障函数。所提出的框架作为安全过滤器，在名义位置/速度控制环路获取的加速度参考上进行修改，并集成到PX4自动驾驶仪栈中。使用小型多旋翼 aerial 机器人进行的实验研究验证了该解决方案在动态机动和未知环境中的有效性和性能。', 'title_zh': '使用控制屏障函数的多旋翼系统嵌入式安全反应导航'}
{'arxiv_id': 'arXiv:2504.15766', 'title': 'Dynamic Intent Queries for Motion Transformer-based Trajectory Prediction', 'authors': 'Tobias Demmler, Lennart Hartung, Andreas Tamke, Thao Dang, Alexander Hegai, Karsten Haug, Lars Mikelsons', 'link': 'https://arxiv.org/abs/2504.15766', 'abstract': "In autonomous driving, accurately predicting the movements of other traffic participants is crucial, as it significantly influences a vehicle's planning processes. Modern trajectory prediction models strive to interpret complex patterns and dependencies from agent and map data. The Motion Transformer (MTR) architecture and subsequent work define the most accurate methods in common benchmarks such as the Waymo Open Motion Benchmark. The MTR model employs pre-generated static intention points as initial goal points for trajectory prediction. However, the static nature of these points frequently leads to misalignment with map data in specific traffic scenarios, resulting in unfeasible or unrealistic goal points. Our research addresses this limitation by integrating scene-specific dynamic intention points into the MTR model. This adaptation of the MTR model was trained and evaluated on the Waymo Open Motion Dataset. Our findings demonstrate that incorporating dynamic intention points has a significant positive impact on trajectory prediction accuracy, especially for predictions over long time horizons. Furthermore, we analyze the impact on ground truth trajectories which are not compliant with the map data or are illegal maneuvers.", 'abstract_zh': '在自主驾驶中，准确预测其他交通参与者的运动至关重要，因为它显著影响车辆的规划过程。现代轨迹预测模型致力于从代理和地图数据中解析复杂的模式和依赖关系。Motion Transformer（MTR）架构及其后续工作在Waymo公开轨迹预测基准等常见基准中定义了最精确的方法。MTR模型使用预先生成的静态意向点作为轨迹预测的初始目标点。然而，这些点的静态性质在特定交通场景中往往会与地图数据产生对齐问题，导致不实际或不现实的目标点。我们的研究通过将场景特定的动态意向点集成到MTR模型中，以解决这一局限性。该MTR模型经过Waymo公开轨迹数据集的训练和评估，实验结果表明，纳入动态意向点显著提高了轨迹预测精度，尤其是对于长期预测的影响更为显著。此外，我们分析了不遵守地图数据或不合法的行为的真实轨迹的影响。', 'title_zh': '基于运动变换器的时间预测中的动态意图查询'}
{'arxiv_id': 'arXiv:2504.15740', 'title': 'CaRoSaC: A Reinforcement Learning-Based Kinematic Control of Cable-Driven Parallel Robots by Addressing Cable Sag through Simulation', 'authors': 'Rohit Dhakate, Thomas Jantos, Eren Allak, Stephan Weiss, Jan Steinbrener', 'link': 'https://arxiv.org/abs/2504.15740', 'abstract': 'This paper introduces the Cable Robot Simulation and Control (CaRoSaC) Framework, which integrates a simulation environment with a model-free reinforcement learning control methodology for suspended Cable-Driven Parallel Robots (CDPRs), accounting for cable sag. Our approach seeks to bridge the knowledge gap of the intricacies of CDPRs due to aspects such as cable sag and precision control necessities by establishing a simulation platform that captures the real-world behaviors of CDPRs, including the impacts of cable sag. The framework offers researchers and developers a tool to further develop estimation and control strategies within the simulation for understanding and predicting the performance nuances, especially in complex operations where cable sag can be significant. Using this simulation framework, we train a model-free control policy in Reinforcement Learning (RL). This approach is chosen for its capability to adaptively learn from the complex dynamics of CDPRs. The policy is trained to discern optimal cable control inputs, ensuring precise end-effector positioning. Unlike traditional feedback-based control methods, our RL control policy focuses on kinematic control and addresses the cable sag issues without being tethered to predefined mathematical models. We also demonstrate that our RL-based controller, coupled with the flexible cable simulation, significantly outperforms the classical kinematics approach, particularly in dynamic conditions and near the boundary regions of the workspace. The combined strength of the described simulation and control approach offers an effective solution in manipulating suspended CDPRs even at workspace boundary conditions where traditional approach fails, as proven from our experiments, ensuring that CDPRs function optimally in various applications while accounting for the often neglected but critical factor of cable sag.', 'abstract_zh': 'Cable Robot Simulation and Control (CaRoSaC)框架：考虑电缆下垂的悬空缆驱动并联机器人建模与控制方法', 'title_zh': 'CaRoSaC：一种通过仿真解决缆线松弛的基于强化学习的缆索驱动并联机器人运动控制方法'}
{'arxiv_id': 'arXiv:2504.15714', 'title': 'Autonomous Control of Redundant Hydraulic Manipulator Using Reinforcement Learning with Action Feedback', 'authors': 'Rohit Dhakate, Christian Brommer, Christoph Böhm, Stephan Weiss, Jan Steinbrener', 'link': 'https://arxiv.org/abs/2504.15714', 'abstract': 'This article presents an entirely data-driven approach for autonomous control of redundant manipulators with hydraulic actuation. The approach only requires minimal system information, which is inherited from a simulation model. The non-linear hydraulic actuation dynamics are modeled using actuator networks from the data gathered during the manual operation of the manipulator to effectively emulate the real system in a simulation environment. A neural network control policy for autonomous control, based on end-effector (EE) position tracking is then learned using Reinforcement Learning (RL) with Ornstein-Uhlenbeck process noise (OUNoise) for efficient exploration. The RL agent also receives feedback based on supervised learning of the forward kinematics which facilitates selecting the best suitable action from exploration. The control policy directly provides the joint variables as outputs based on provided target EE position while taking into account the system dynamics. The joint variables are then mapped to the hydraulic valve commands, which are then fed to the system without further modifications. The proposed approach is implemented on a scaled hydraulic forwarder crane with three revolute and one prismatic joint to track the desired position of the EE in 3-Dimensional (3D) space. With the emulated dynamics and extensive learning in simulation, the results demonstrate the feasibility of deploying the learned controller directly on the real system.', 'abstract_zh': '一种基于数据驱动的冗余液压 manipulator 自主控制方法', 'title_zh': '使用带有动作反馈的强化学习控制冗余液压 manipulator 的自主控制'}
{'arxiv_id': 'arXiv:2504.15666', 'title': 'Symbolic Runtime Verification and Adaptive Decision-Making for Robot-Assisted Dressing', 'authors': 'Yasmin Rafiq, Gricel Vázquez, Radu Calinescu, Sanja Dogramadzi, Robert M Hierons', 'link': 'https://arxiv.org/abs/2504.15666', 'abstract': "We present a control framework for robot-assisted dressing that augments low-level hazard response with runtime monitoring and formal verification. A parametric discrete-time Markov chain (pDTMC) models the dressing process, while Bayesian inference dynamically updates this pDTMC's transition probabilities based on sensory and user feedback. Safety constraints from hazard analysis are expressed in probabilistic computation tree logic, and symbolically verified using a probabilistic model checker. We evaluate reachability, cost, and reward trade-offs for garment-snag mitigation and escalation, enabling real-time adaptation. Our approach provides a formal yet lightweight foundation for safety-aware, explainable robotic assistance.", 'abstract_zh': '机器人辅助穿衣操作中具有运行时监控和形式验证的低层危害响应增强控制框架', 'title_zh': '符号运行时验证与适应性决策-making for Robot-Assisted Dressing'}
{'arxiv_id': 'arXiv:2504.15654', 'title': 'A Vision-Enabled Prosthetic Hand for Children with Upper Limb Disabilities', 'authors': 'Md Abdul Baset Sarker, Art Nguyen, Sigmond Kukla, Kevin Fite, Masudul H. Imtiaz', 'link': 'https://arxiv.org/abs/2504.15654', 'abstract': 'This paper introduces a novel AI vision-enabled pediatric prosthetic hand designed to assist children aged 10-12 with upper limb disabilities. The prosthesis features an anthropomorphic appearance, multi-articulating functionality, and a lightweight design that mimics a natural hand, making it both accessible and affordable for low-income families. Using 3D printing technology and integrating advanced machine vision, sensing, and embedded computing, the prosthetic hand offers a low-cost, customizable solution that addresses the limitations of current myoelectric prostheses. A micro camera is interfaced with a low-power FPGA for real-time object detection and assists with precise grasping. The onboard DL-based object detection and grasp classification models achieved accuracies of 96% and 100% respectively. In the force prediction, the mean absolute error was found to be 0.018. The features of the proposed prosthetic hand can thus be summarized as: a) a wrist-mounted micro camera for artificial sensing, enabling a wide range of hand-based tasks; b) real-time object detection and distance estimation for precise grasping; and c) ultra-low-power operation that delivers high performance within constrained power and resource limits.', 'abstract_zh': '一种用于10-12岁上肢残疾儿童的新型AI视觉辅助型假肢手', 'title_zh': '基于视觉的儿童上肢残疾辅助手'}
{'arxiv_id': 'arXiv:2504.15643', 'title': 'Multimodal Perception for Goal-oriented Navigation: A Survey', 'authors': 'I-Tak Ieong, Hao Tang', 'link': 'https://arxiv.org/abs/2504.15643', 'abstract': 'Goal-oriented navigation presents a fundamental challenge for autonomous systems, requiring agents to navigate complex environments to reach designated targets. This survey offers a comprehensive analysis of multimodal navigation approaches through the unifying perspective of inference domains, exploring how agents perceive, reason about, and navigate environments using visual, linguistic, and acoustic information. Our key contributions include organizing navigation methods based on their primary environmental reasoning mechanisms across inference domains; systematically analyzing how shared computational foundations support seemingly disparate approaches across different navigation tasks; identifying recurring patterns and distinctive strengths across various navigation paradigms; and examining the integration challenges and opportunities of multimodal perception to enhance navigation capabilities. In addition, we review approximately 200 relevant articles to provide an in-depth understanding of the current landscape.', 'abstract_zh': '面向目标的导航为自主系统提出了基本挑战，要求代理在复杂环境中导航以到达指定目标。本文综述通过推理域的统一视角，对多模态导航方法进行了全面分析，探讨代理如何利用视觉、语言和声学信息来感知、推理和导航环境。我们的主要贡献包括基于推理域中主要的环境推理机制组织导航方法；系统分析共享的计算基础如何支持在不同导航任务中看似不同的方法；识别各种导航范式中的重复模式和独特优势；并探讨多模态感知的集成挑战与机遇以提高导航能力。此外，我们回顾了约200篇文章以提供当前研究格局的深入理解。', 'title_zh': '面向目标导向导航的多模态感知综述'}
{'arxiv_id': 'arXiv:2504.15600', 'title': 'Research on Navigation Methods Based on LLMs', 'authors': 'Anlong Zhang, Jianmin Ji', 'link': 'https://arxiv.org/abs/2504.15600', 'abstract': 'In recent years, the field of indoor navigation has witnessed groundbreaking advancements through the integration of Large Language Models (LLMs). Traditional navigation approaches relying on pre-built maps or reinforcement learning exhibit limitations such as poor generalization and limited adaptability to dynamic environments. In contrast, LLMs offer a novel paradigm for complex indoor navigation tasks by leveraging their exceptional semantic comprehension, reasoning capabilities, and zero-shot generalization properties. We propose an LLM-based navigation framework that leverages function calling capabilities, positioning the LLM as the central controller. Our methodology involves modular decomposition of conventional navigation functions into reusable LLM tools with expandable configurations. This is complemented by a systematically designed, transferable system prompt template and interaction workflow that can be easily adapted across different implementations. Experimental validation in PyBullet simulation environments across diverse scenarios demonstrates the substantial potential and effectiveness of our approach, particularly in achieving context-aware navigation through dynamic tool composition.', 'abstract_zh': '近年来，通过将大型语言模型（LLMs）集成到室内导航领域，取得了突破性的进展。传统的依赖预构建地图或强化学习的导航方法存在局限性，如泛化能力差和对动态环境适应能力有限。相比之下，LLMs通过利用其出色的语义理解、推理能力和零样本泛化能力，为复杂的室内导航任务提供了新的范式。我们提出了一种基于LLM的导航框架，将LLM定位为中心控制器，并利用其实现功能调用能力。该方法包括将传统导航功能模块化分解为可重用的LLM工具，并具有可扩展的配置。此外，还设计了一种系统化、可转移的系统提示模板和交互工作流，可以在不同实施中轻松适应。在PyBullet仿真环境中对多样场景进行的实验验证表明，我们的方法具有巨大的潜力和效果，特别是在通过动态工具组合实现上下文感知导航方面。', 'title_zh': '基于大语言模型的导航方法研究'}
{'arxiv_id': 'arXiv:2504.15595', 'title': 'Grasping Deformable Objects via Reinforcement Learning with Cross-Modal Attention to Visuo-Tactile Inputs', 'authors': 'Yonghyun Lee, Sungeun Hong, Min-gu Kim, Gyeonghwan Kim, Changjoo Nam', 'link': 'https://arxiv.org/abs/2504.15595', 'abstract': 'We consider the problem of grasping deformable objects with soft shells using a robotic gripper. Such objects have a center-of-mass that changes dynamically and are fragile so prone to burst. Thus, it is difficult for robots to generate appropriate control inputs not to drop or break the object while performing manipulation tasks. Multi-modal sensing data could help understand the grasping state through global information (e.g., shapes, pose) from visual data and local information around the contact (e.g., pressure) from tactile data. Although they have complementary information that can be beneficial to use together, fusing them is difficult owing to their different properties.\nWe propose a method based on deep reinforcement learning (DRL) that generates control inputs of a simple gripper from visuo-tactile sensing information. Our method employs a cross-modal attention module in the encoder network and trains it in a self-supervised manner using the loss function of the RL agent. With the multi-modal fusion, the proposed method can learn the representation for the DRL agent from the visuo-tactile sensory data. The experimental result shows that cross-modal attention is effective to outperform other early and late data fusion methods across different environments including unseen robot motions and objects.', 'abstract_zh': '基于深度强化学习的跨模态注意力方法用于软壳变形物体的抓取控制', 'title_zh': '通过跨模态注意力处理视觉-触觉输入的强化学习抓取变形物体'}
{'arxiv_id': 'arXiv:2504.15561', 'title': 'SPECI: Skill Prompts based Hierarchical Continual Imitation Learning for Robot Manipulation', 'authors': 'Jingkai Xu, Xiangli Nie', 'link': 'https://arxiv.org/abs/2504.15561', 'abstract': 'Real-world robot manipulation in dynamic unstructured environments requires lifelong adaptability to evolving objects, scenes and tasks. Traditional imitation learning relies on static training paradigms, which are ill-suited for lifelong adaptation. Although Continual Imitation Learnin (CIL) enables incremental task adaptation while preserving learned knowledge, current CIL methods primarily overlook the intrinsic skill characteristics of robot manipulation or depend on manually defined and rigid skills, leading to suboptimal cross-task knowledge transfer. To address these issues, we propose Skill Prompts-based HiErarchical Continual Imitation Learning (SPECI), a novel end-to-end hierarchical CIL policy architecture for robot manipulation. The SPECI framework consists of a multimodal perception and fusion module for heterogeneous sensory information encoding, a high-level skill inference module for dynamic skill extraction and selection, and a low-level action execution module for precise action generation. To enable efficient knowledge transfer on both skill and task levels, SPECI performs continual implicit skill acquisition and reuse via an expandable skill codebook and an attention-driven skill selection mechanism. Furthermore, we introduce mode approximation to augment the last two modules with task-specific and task-sharing parameters, thereby enhancing task-level knowledge transfer. Extensive experiments on diverse manipulation task suites demonstrate that SPECI consistently outperforms state-of-the-art CIL methods across all evaluated metrics, revealing exceptional bidirectional knowledge transfer and superior overall performance.', 'abstract_zh': '基于技能提示的层次化持续模仿学习（SPECI）：机器人操作的高效知识转移架构', 'title_zh': 'SPECI: 基于技能提示的分级连续模仿学习机器人 manipulation'}
{'arxiv_id': 'arXiv:2504.15541', 'title': 'RiskNet: Interaction-Aware Risk Forecasting for Autonomous Driving in Long-Tail Scenarios', 'authors': 'Qichao Liu, Heye Huang, Shiyue Zhao, Lei Shi, Soyoung Ahn, Xiaopeng Li', 'link': 'https://arxiv.org/abs/2504.15541', 'abstract': 'Ensuring the safety of autonomous vehicles (AVs) in long-tail scenarios remains a critical challenge, particularly under high uncertainty and complex multi-agent interactions. To address this, we propose RiskNet, an interaction-aware risk forecasting framework, which integrates deterministic risk modeling with probabilistic behavior prediction for comprehensive risk assessment. At its core, RiskNet employs a field-theoretic model that captures interactions among ego vehicle, surrounding agents, and infrastructure via interaction fields and force. This model supports multidimensional risk evaluation across diverse scenarios (highways, intersections, and roundabouts), and shows robustness under high-risk and long-tail settings. To capture the behavioral uncertainty, we incorporate a graph neural network (GNN)-based trajectory prediction module, which learns multi-modal future motion distributions. Coupled with the deterministic risk field, it enables dynamic, probabilistic risk inference across time, enabling proactive safety assessment under uncertainty. Evaluations on the highD, inD, and rounD datasets, spanning lane changes, turns, and complex merges, demonstrate that our method significantly outperforms traditional approaches (e.g., TTC, THW, RSS, NC Field) in terms of accuracy, responsiveness, and directional sensitivity, while maintaining strong generalization across scenarios. This framework supports real-time, scenario-adaptive risk forecasting and demonstrates strong generalization across uncertain driving environments. It offers a unified foundation for safety-critical decision-making in long-tail scenarios.', 'abstract_zh': '确保自动驾驶车辆在长尾场景下的安全性仍然是一个关键挑战，特别是在高不确定性和复杂多代理交互情境下。为此，我们提出RiskNet，一种交互感知的风险预测框架，该框架结合确定性风险建模与概率行为预测，进行全面风险评估。RiskNet的核心是一种场理论模型，通过交互场和力捕捉ego车辆、周围代理和基础设施之间的交互。该模型支持在不同场景（高速公路、交点和环岛）下的多维度风险评估，并在高风险和长尾情境下表现 robust。为了捕捉行为不确定性，我们引入了一种基于图神经网络（GNN）的轨迹预测模块，该模块学习多模态未来运动分布。结合确定性风险场，它能够实现随时间的动态、概率性风险推断，从而在不确定性下进行主动安全评估。在highD、inD和rounD数据集上的评估，涵盖了变道、转弯和复杂合并场景，证明了本方法在准确性、响应性和方向敏感性方面显著优于传统方法（如TTC、THW、RSS、NC Field），同时在不同场景下具有强大的泛化能力。该框架支持实时、场景自适应的风险预测，并在不确定驾驶环境中表现出强大的泛化能力。它为长尾场景下的安全关键决策提供了一个统一的基础。', 'title_zh': 'RiskNet：长尾场景下考虑交互的风险预报在自动驾驶中的应用'}
{'arxiv_id': 'arXiv:2504.15535', 'title': 'VibeCheck: Using Active Acoustic Tactile Sensing for Contact-Rich Manipulation', 'authors': 'Kaidi Zhang, Do-Gon Kim, Eric T. Chang, Hua-Hsuan Liang, Zhanpeng He, Kathryn Lampo, Philippe Wu, Ioannis Kymissis, Matei Ciocarlie', 'link': 'https://arxiv.org/abs/2504.15535', 'abstract': "The acoustic response of an object can reveal a lot about its global state, for example its material properties or the extrinsic contacts it is making with the world. In this work, we build an active acoustic sensing gripper equipped with two piezoelectric fingers: one for generating signals, the other for receiving them. By sending an acoustic vibration from one finger to the other through an object, we gain insight into an object's acoustic properties and contact state. We use this system to classify objects, estimate grasping position, estimate poses of internal structures, and classify the types of extrinsic contacts an object is making with the environment. Using our contact type classification model, we tackle a standard long-horizon manipulation problem: peg insertion. We use a simple simulated transition model based on the performance of our sensor to train an imitation learning policy that is robust to imperfect predictions from the classifier. We finally demonstrate the policy on a UR5 robot with active acoustic sensing as the only feedback.", 'abstract_zh': '具有主动声学传感的抓手：通过声学响应揭示物体的全局状态与其接触状态', 'title_zh': 'VibeCheck: 使用主动声触觉传感进行高接触操作'}
{'arxiv_id': 'arXiv:2504.15517', 'title': 'Few-Shot Vision-Language Action-Incremental Policy Learning', 'authors': 'Mingchen Song, Xiang Deng, Guoqiang Zhong, Qi Lv, Jia Wan, Yinchuan Li, Jianye Hao, Weili Guan', 'link': 'https://arxiv.org/abs/2504.15517', 'abstract': 'Recently, Transformer-based robotic manipulation methods utilize multi-view spatial representations and language instructions to learn robot motion trajectories by leveraging numerous robot demonstrations. However, the collection of robot data is extremely challenging, and existing methods lack the capability for continuous learning on new tasks with only a few demonstrations. In this paper, we formulate these challenges as the Few-Shot Action-Incremental Learning (FSAIL) task, and accordingly design a Task-prOmpt graPh evolutIon poliCy (TOPIC) to address these issues. Specifically, to address the data scarcity issue in robotic imitation learning, TOPIC learns Task-Specific Prompts (TSP) through the deep interaction of multi-modal information within few-shot demonstrations, thereby effectively extracting the task-specific discriminative information. On the other hand, to enhance the capability for continual learning on new tasks and mitigate the issue of catastrophic forgetting, TOPIC adopts a Continuous Evolution Strategy (CES). CES leverages the intrinsic relationships between tasks to construct a task relation graph, which effectively facilitates the adaptation of new tasks by reusing skills learned from previous tasks. TOPIC pioneers few-shot continual learning in the robotic manipulation task, and extensive experimental results demonstrate that TOPIC outperforms state-of-the-art baselines by over 26$\\%$ in success rate, significantly enhancing the continual learning capabilities of existing Transformer-based policies.', 'abstract_zh': 'Few-Shot Action-Incremental Learning for Robotic Manipulation through Task-prOmpt graPh evolutIon poliCy (TOPIC)', 'title_zh': '少样本视觉-语言动作递增策略学习'}
{'arxiv_id': 'arXiv:2504.15472', 'title': 'LAPP: Large Language Model Feedback for Preference-Driven Reinforcement Learning', 'authors': 'Pingcheng Jian, Xiao Wei, Yanbaihui Liu, Samuel A. Moore, Michael M. Zavlanos, Boyuan Chen', 'link': 'https://arxiv.org/abs/2504.15472', 'abstract': 'We introduce Large Language Model-Assisted Preference Prediction (LAPP), a novel framework for robot learning that enables efficient, customizable, and expressive behavior acquisition with minimum human effort. Unlike prior approaches that rely heavily on reward engineering, human demonstrations, motion capture, or expensive pairwise preference labels, LAPP leverages large language models (LLMs) to automatically generate preference labels from raw state-action trajectories collected during reinforcement learning (RL). These labels are used to train an online preference predictor, which in turn guides the policy optimization process toward satisfying high-level behavioral specifications provided by humans. Our key technical contribution is the integration of LLMs into the RL feedback loop through trajectory-level preference prediction, enabling robots to acquire complex skills including subtle control over gait patterns and rhythmic timing. We evaluate LAPP on a diverse set of quadruped locomotion and dexterous manipulation tasks and show that it achieves efficient learning, higher final performance, faster adaptation, and precise control of high-level behaviors. Notably, LAPP enables robots to master highly dynamic and expressive tasks such as quadruped backflips, which remain out of reach for standard LLM-generated or handcrafted rewards. Our results highlight LAPP as a promising direction for scalable preference-driven robot learning.', 'abstract_zh': '大型语言模型辅助偏好预测（LAPP）：一种无需大量人力即可实现高效、可定制和表达性强的行为获取的机器人学习新型框架', 'title_zh': 'LAPP: 大规模语言模型反馈驱动的偏好强化学习'}
{'arxiv_id': 'arXiv:2504.15455', 'title': 'Field Report on Ground Penetrating Radar for Localization at the Mars Desert Research Station', 'authors': 'Anja Sheppard, Katherine A. Skinner', 'link': 'https://arxiv.org/abs/2504.15455', 'abstract': 'In this field report, we detail the lessons learned from our field expedition to collect Ground Penetrating Radar (GPR) data in a Mars analog environment for the purpose of validating GPR localization techniques in rugged environments. Planetary rovers are already equipped with GPR for geologic subsurface characterization. GPR has been successfully used to localize vehicles on Earth, but it has not yet been explored as another modality for localization on a planetary rover. Leveraging GPR for localization can aid in efficient and robust rover pose estimation. In order to demonstrate localizing GPR in a Mars analog environment, we collected over 50 individual survey trajectories during a two-week period at the Mars Desert Research Station (MDRS). In this report, we discuss our methodology, lessons learned, and opportunities for future work.', 'abstract_zh': '在本实地报告中，我们详细介绍了在火星模拟环境中采集地面穿透雷达（GPR）数据的实地探险经验，旨在验证GPR定位技术在崎岖环境中的有效性。行星探测车已经配备了GPR用于地质地下层表征。GPR在地球上已被成功用于车辆定位，但在行星探测车上作为另一种定位模式的应用尚未被探索。利用GPR进行定位可以辅助实现高效的稳健的探测车姿态估计。为了展示在火星模拟环境中定位GPR，我们在火星沙漠研究站（MDRS）为期两周的时间内收集了超过50个独立的调查轨迹。在本报告中，我们讨论了我们的方法论、经验教训以及未来工作的机会。', 'title_zh': '火星沙漠研究站地下雷达定位现场报告'}
{'arxiv_id': 'arXiv:2504.15425', 'title': 'Solving Multi-Agent Safe Optimal Control with Distributed Epigraph Form MARL', 'authors': 'Songyuan Zhang, Oswin So, Mitchell Black, Zachary Serlin, Chuchu Fan', 'link': 'https://arxiv.org/abs/2504.15425', 'abstract': 'Tasks for multi-robot systems often require the robots to collaborate and complete a team goal while maintaining safety. This problem is usually formalized as a constrained Markov decision process (CMDP), which targets minimizing a global cost and bringing the mean of constraint violation below a user-defined threshold. Inspired by real-world robotic applications, we define safety as zero constraint violation. While many safe multi-agent reinforcement learning (MARL) algorithms have been proposed to solve CMDPs, these algorithms suffer from unstable training in this setting. To tackle this, we use the epigraph form for constrained optimization to improve training stability and prove that the centralized epigraph form problem can be solved in a distributed fashion by each agent. This results in a novel centralized training distributed execution MARL algorithm named Def-MARL. Simulation experiments on 8 different tasks across 2 different simulators show that Def-MARL achieves the best overall performance, satisfies safety constraints, and maintains stable training. Real-world hardware experiments on Crazyflie quadcopters demonstrate the ability of Def-MARL to safely coordinate agents to complete complex collaborative tasks compared to other methods.', 'abstract_zh': '多机器人系统的任务往往要求机器人相互协作并完成团队目标的同时保持安全。这个问题通常被形式化为受限马尔可夫决策过程（CMDP），目标是最小化全局成本并将约束违背的均值保持在用户定义的阈值以下。受实际机器人应用的启发，我们将安全定义为零约束违背。虽然已经提出了许多安全多智能体强化学习（MARL）算法来解决CMDP，但这些算法在这种情况下遭受训练不稳定的问题。为了解决这个问题，我们使用受限优化的epigraph形式来提高训练稳定性，并证明中心化的epigraph形式问题可以由每个智能体分布式求解。这导致了一个新颖的中心化训练分布式执行的MARL算法，名为Def-MARL。在2个不同模拟器上的8个不同任务的仿真实验中，Def-MARL在总体性能上表现出最佳效果，满足安全约束，并保持训练稳定。在Crazyflie四旋翼无人机上的实际硬件实验表明，Def-MARL能够安全地协调智能体完成复杂的协同任务，与其它方法相比具有优势。', 'title_zh': '分布式 epithagran 形式多代理安全最优控制求解'}
{'arxiv_id': 'arXiv:2504.15418', 'title': 'MRTA-Sim: A Modular Simulator for Multi-Robot Allocation, Planning, and Control in Open-World Environments', 'authors': 'Victoria Marie Tuck, Hardik Parwana, Pei-Wei Chen, Georgios Fainekos, Bardh Hoxha, Hideki Okamoto, S. Shankar Sastry, Sanjit A. Seshia', 'link': 'https://arxiv.org/abs/2504.15418', 'abstract': 'This paper introduces MRTA-Sim, a Python/ROS2/Gazebo simulator for testing approaches to Multi-Robot Task Allocation (MRTA) problems on simulated robots in complex, indoor environments. Grid-based approaches to MRTA problems can be too restrictive for use in complex, dynamic environments such in warehouses, department stores, hospitals, etc. However, approaches that operate in free-space often operate at a layer of abstraction above the control and planning layers of a robot and make an assumption on approximate travel time between points of interest in the system. These abstractions can neglect the impact of the tight space and multi-agent interactions on the quality of the solution. Therefore, MRTA solutions should be tested with the navigation stacks of the robots in mind, taking into account robot planning, conflict avoidance between robots, and human interaction and avoidance. This tool connects the allocation output of MRTA solvers to individual robot planning using the NAV2 stack and local, centralized multi-robot deconfliction using Control Barrier Function-Quadrtic Programs (CBF-QPs), creating a platform closer to real-world operation for more comprehensive testing of these approaches. The simulation architecture is modular so that users can swap out methods at different levels of the stack. We show the use of our system with a Satisfiability Modulo Theories (SMT)-based approach to dynamic MRTA on a fleet of indoor delivery robots.', 'abstract_zh': 'MRTA-Sim：一种用于复杂室内环境中基于Python/ROS2/Gazebo的多机器人任务分配测试模拟器', 'title_zh': 'MRTA-Sim: 一种适用于开放环境多机器人分配、规划与控制的模块化模拟器'}
{'arxiv_id': 'arXiv:2504.15414', 'title': 'Post-Convergence Sim-to-Real Policy Transfer: A Principled Alternative to Cherry-Picking', 'authors': 'Dylan Khor, Bowen Weng', 'link': 'https://arxiv.org/abs/2504.15414', 'abstract': 'Learning-based approaches, particularly reinforcement learning (RL), have become widely used for developing control policies for autonomous agents, such as locomotion policies for legged robots. RL training typically maximizes a predefined reward (or minimizes a corresponding cost/loss) by iteratively optimizing policies within a simulator. Starting from a randomly initialized policy, the empirical expected reward follows a trajectory with an overall increasing trend. While some policies become temporarily stuck in local optima, a well-defined training process generally converges to a reward level with noisy oscillations. However, selecting a policy for real-world deployment is rarely an analytical decision (i.e., simply choosing the one with the highest reward) and is instead often performed through trial and error. To improve sim-to-real transfer, most research focuses on the pre-convergence stage, employing techniques such as domain randomization, multi-fidelity training, adversarial training, and architectural innovations. However, these methods do not eliminate the inevitable convergence trajectory and noisy oscillations of rewards, leading to heuristic policy selection or cherry-picking. This paper addresses the post-convergence sim-to-real transfer problem by introducing a worst-case performance transference optimization approach, formulated as a convex quadratic-constrained linear programming problem. Extensive experiments demonstrate its effectiveness in transferring RL-based locomotion policies from simulation to real-world laboratory tests.', 'abstract_zh': '基于学习的方法，尤其是强化学习（RL），已被广泛用于开发自主代理的控制策略，如腿足机器人的运动策略。RL 训练通常通过在模拟器中迭代优化策略来最大化预定义的奖励（或最小化相应的成本/损失）。从一个随机初始化的策略开始，经验期望奖励随时间呈现出整体上升的趋势。虽然有些策略会在局部最优中暂时卡住，但一个定义良好的训练过程通常会通过噪声振荡收敛到一个奖励水平。然而，在实际部署时选择一个策略很少是一个分析决策（即，简单地选择奖励最高的策略），而是经常通过试错来完成。为了改进从仿真到现实世界的迁移，大多数研究集中在收敛前的阶段，采用了领域随机化、多保真度训练、对抗训练和架构创新等技术。然而，这些方法并未消除奖励的不可避免的收敛轨迹和噪声振荡，导致启发式策略选择或挑选手动。本文通过引入最坏情况性能转移优化方法，将其形式化为一个凸的二次约束线性规划问题，解决了收敛后的从仿真到现实世界的迁移问题，广泛的实验证明了其有效性，能够将基于RL的运动策略从仿真环境中转移到现实世界的实验室测试中。', 'title_zh': '收敛后从仿真到现实的策略转移：一种 principles 上的替代方案'}
{'arxiv_id': 'arXiv:2504.15327', 'title': 'Advancing Embodied Intelligence in Robotic-Assisted Endovascular Procedures: A Systematic Review of AI Solutions', 'authors': 'Tianliang Yao, Bo Lu, Markus Kowarschik, Yixuan Yuan, Hubin Zhao, Sebastien Ourselin, Kaspar Althoefer, Junbo Ge, Peng Qi', 'link': 'https://arxiv.org/abs/2504.15327', 'abstract': "Endovascular procedures have revolutionized the treatment of vascular diseases thanks to minimally invasive solutions that significantly reduce patient recovery time and enhance clinical outcomes. However, the precision and dexterity required during these procedures poses considerable challenges for interventionists. Robotic systems have emerged offering transformative solutions, addressing issues such as operator fatigue, radiation exposure, and the inherent limitations of human precision. The integration of Embodied Intelligence (EI) into these systems signifies a paradigm shift, enabling robots to navigate complex vascular networks and adapt to dynamic physiological conditions. Data-driven approaches, advanced computer vision, medical image analysis, and machine learning techniques, are at the forefront of this evolution. These methods augment procedural intelligence by facilitating real-time vessel segmentation, device tracking, and anatomical landmark detection. Reinforcement learning and imitation learning further refine navigation strategies and replicate experts' techniques. This review systematically examines the integration of EI principles into robotic technologies, in relation to endovascular procedures. We discuss recent advancements in intelligent perception and data-driven control, and their practical applications in robot-assisted endovascular procedures. By critically evaluating current limitations and emerging opportunities, this review establishes a framework for future developments, emphasizing the potential for greater autonomy and improved clinical outcomes. Emerging trends and specific areas of research, such as federated learning for medical data sharing, explainable AI for clinical decision support, and advanced human-robot collaboration paradigms, are also explored, offering insights into the future direction of this rapidly evolving field.", 'abstract_zh': '内血管程序通过微创解决方案革新了血管疾病治疗方式，显著缩短了患者的恢复时间并提升了临床效果。然而，这些程序所需的精准度和灵巧性给操作者带来了显著挑战。机器人系统已出现，提供了解决方案，克服了操作疲劳、辐射暴露以及人类精度固有限制等问题。将浸透智能（Embodied Intelligence, EI）融入这些系统标志着 paradigm shift 的到来，使机器人能够导航复杂的血管网络并适应动态生理条件。数据驱动的方法、先进的计算机视觉、医学影像分析和机器学习技术处于这一演变的前沿。这些方法通过实时血管分割、设备跟踪和解剖学标志点检测增强了程序智能。强化学习和模仿学习进一步优化了导航策略并复制了专家的技术。本文系统地探讨了 EI 原理在机器人技术中的集成与内血管程序的关系，讨论了智能感知和数据驱动控制的最新进展及其在辅助内血管程序中的实际应用。通过对现有限制和新兴机遇的批判性评估，本文构建了未来发展的框架，强调了更高的自主性和临床效果的改进潜力。本文还探讨了新兴趋势和具体研究领域，如用于医疗数据共享的联邦学习、可解释的人工智能在临床决策支持中的应用以及先进的人类-机器人协作模式，为这一快速发展的领域指明了未来的方向。', 'title_zh': '机器人辅助血管内手术中嵌入式智能的发展：人工智能解决方案的系统评价'}
{'arxiv_id': 'arXiv:2504.15320', 'title': 'Efficient and Safe Planner for Automated Driving on Ramps Considering Unsatisfication', 'authors': 'Qinghao Li, Zhen Tian, Xiaodan Wang, Jinming Yang, Zhihao Lin', 'link': 'https://arxiv.org/abs/2504.15320', 'abstract': "Automated driving on ramps presents significant challenges due to the need to balance both safety and efficiency during lane changes. This paper proposes an integrated planner for automated vehicles (AVs) on ramps, utilizing an unsatisfactory level metric for efficiency and arrow-cluster-based sampling for safety. The planner identifies optimal times for the AV to change lanes, taking into account the vehicle's velocity as a key factor in efficiency. Additionally, the integrated planner employs arrow-cluster-based sampling to evaluate collision risks and select an optimal lane-changing curve. Extensive simulations were conducted in a ramp scenario to verify the planner's efficient and safe performance. The results demonstrate that the proposed planner can effectively select an appropriate lane-changing time point and a safe lane-changing curve for AVs, without incurring any collisions during the maneuver.", 'abstract_zh': '匝道上自动驾驶车辆的结合规划器：利用效率不足等级度量和箭头簇基于采样确保安全与效率并发', 'title_zh': '考虑不满意情况的匝道自动驾驶高效安全规划器'}
{'arxiv_id': 'arXiv:2504.15305', 'title': 'SLAM-Based Navigation and Fault Resilience in a Surveillance Quadcopter with Embedded Vision Systems', 'authors': 'Abhishek Tyagi, Charu Gaur', 'link': 'https://arxiv.org/abs/2504.15305', 'abstract': 'We present an autonomous aerial surveillance platform, Veg, designed as a fault-tolerant quadcopter system that integrates visual SLAM for GPS-independent navigation, advanced control architecture for dynamic stability, and embedded vision modules for real-time object and face recognition. The platform features a cascaded control design with an LQR inner-loop and PD outer-loop trajectory control. It leverages ORB-SLAM3 for 6-DoF localization and loop closure, and supports waypoint-based navigation through Dijkstra path planning over SLAM-derived maps. A real-time Failure Detection and Identification (FDI) system detects rotor faults and executes emergency landing through re-routing. The embedded vision system, based on a lightweight CNN and PCA, enables onboard object detection and face recognition with high precision. The drone operates fully onboard using a Raspberry Pi 4 and Arduino Nano, validated through simulations and real-world testing. This work consolidates real-time localization, fault recovery, and embedded AI on a single platform suitable for constrained environments.', 'abstract_zh': '一种基于视觉SLAM的鲁棒四旋翼自主空中 surveillance 平台：融合故障检测与容错的视觉导航与识别系统', 'title_zh': '基于SLAM的监视四旋翼无人机嵌入式视觉系统导航与故障韧性研究'}
{'arxiv_id': 'arXiv:2504.16054', 'title': '$π_{0.5}$: a Vision-Language-Action Model with Open-World Generalization', 'authors': 'Physical Intelligence, Kevin Black, Noah Brown, James Darpinian, Karan Dhabalia, Danny Driess, Adnan Esmail, Michael Equi, Chelsea Finn, Niccolo Fusai, Manuel Y. Galliker, Dibya Ghosh, Lachy Groom, Karol Hausman, Brian Ichter, Szymon Jakubczak, Tim Jones, Liyiming Ke, Devin LeBlanc, Sergey Levine, Adrian Li-Bell, Mohith Mothukuri, Suraj Nair, Karl Pertsch, Allen Z. Ren, Lucy Xiaoyang Shi, Laura Smith, Jost Tobias Springenberg, Kyle Stachowicz, James Tanner, Quan Vuong, Homer Walke, Anna Walling, Haohuan Wang, Lili Yu, Ury Zhilinsky', 'link': 'https://arxiv.org/abs/2504.16054', 'abstract': 'In order for robots to be useful, they must perform practically relevant tasks in the real world, outside of the lab. While vision-language-action (VLA) models have demonstrated impressive results for end-to-end robot control, it remains an open question how far such models can generalize in the wild. We describe $\\pi_{0.5}$, a new model based on $\\pi_{0}$ that uses co-training on heterogeneous tasks to enable broad generalization. $\\pi_{0.5}$\\ uses data from multiple robots, high-level semantic prediction, web data, and other sources to enable broadly generalizable real-world robotic manipulation. Our system uses a combination of co-training and hybrid multi-modal examples that combine image observations, language commands, object detections, semantic subtask prediction, and low-level actions. Our experiments show that this kind of knowledge transfer is essential for effective generalization, and we demonstrate for the first time that an end-to-end learning-enabled robotic system can perform long-horizon and dexterous manipulation skills, such as cleaning a kitchen or bedroom, in entirely new homes.', 'abstract_zh': '为了使机器人有用，它们必须在外场执行实际相关任务，而不仅限于实验室。尽管视觉-语言-动作（VLA）模型在外场端到端机器人控制任务中展现了令人印象深刻的成果，但这些模型在外场中的广泛泛化能力仍然有待探索。我们介绍了基于$\\pi_{0}$的新模型$\\pi_{0.5}$，该模型通过异质任务的协同训练来实现广泛泛化。$\\pi_{0.5}$利用多机器人数据、高层语义预测、网络数据及其他来源的数据，使机器人能在多种场景中广泛泛化地执行实际任务。我们的系统结合了协同训练和混合多模态示例，这些示例包含图像观测、语言命令、物体检测、语义子任务预测和低层动作。我们的实验表明，这种知识迁移对于有效的泛化至关重要，并且我们首次证明可以通过端到端学习使机器人系统在外场中执行长时间和灵巧的操作技能，如清洁厨房或卧室等工作，这些操作是在全新的家庭中完成的。', 'title_zh': '$π_{0.5}$：一种具有开放世界泛化能力的视觉-语言-行动模型'}
{'arxiv_id': 'arXiv:2504.15886', 'title': 'Beyond Attention: Investigating the Threshold Where Objective Robot Exclusion Becomes Subjective', 'authors': 'Clarissa Sabrina Arlinghaus, Ashita Ashok, Ashim Mandal, Karsten Berns, Günter W. Maier', 'link': 'https://arxiv.org/abs/2504.15886', 'abstract': "As robots become increasingly involved in decision-making processes (e.g., personnel selection), concerns about fairness and social inclusion arise. This study examines social exclusion in robot-led group interviews by robot Ameca, exploring the relationship between objective exclusion (robot's attention allocation), subjective exclusion (perceived exclusion), mood change, and need fulfillment. In a controlled lab study (N = 35), higher objective exclusion significantly predicted subjective exclusion. In turn, subjective exclusion negatively impacted mood and need fulfillment but only mediated the relationship between objective exclusion and need fulfillment. A piecewise regression analysis identified a critical threshold at which objective exclusion begins to be perceived as subjective exclusion. Additionally, the standing position was the primary predictor of exclusion, whereas demographic factors (e.g., gender, height) had no significant effect. These findings underscore the need to consider both objective and subjective exclusion in human-robot interactions and have implications for fairness in robot-assisted hiring processes.", 'abstract_zh': '随着机器人在决策过程中（如人员选拔）的作用越来越重要，关于公平性和社会包容性的担忧也随之增加。本研究通过考察由机器人Ameca主导的小组面试中的社会排斥现象，探讨了客观排斥（机器人注意力分配）、主观排斥（被排除感）、情绪变化以及需求满足之间的关系。在一项受控实验室研究中（N=35），较高的客观排斥显著预测了主观排斥。反过来，主观排斥对情绪产生了负面影响，但仅部分中介了客观排斥与需求满足之间的关系。分段回归分析发现了客观排斥开始被感知为主观排斥的关键阈值。此外，站立位置是主要的排斥预测因素，而人口统计学因素（如性别、身高）则没有显著影响。这些发现强调了在人机互动中需同时考虑客观和主观排斥，并对机器人辅助招聘过程中的公平性具有重要意义。', 'title_zh': '超越注意力：探究客观机器人排斥转变为主观排斥的阈值'}
{'arxiv_id': 'arXiv:2504.15863', 'title': 'DERD-Net: Learning Depth from Event-based Ray Densities', 'authors': 'Diego de Oliveira Hitzges, Suman Ghosh, Guillermo Gallego', 'link': 'https://arxiv.org/abs/2504.15863', 'abstract': 'Event cameras offer a promising avenue for multi-view stereo depth estimation and Simultaneous Localization And Mapping (SLAM) due to their ability to detect blur-free 3D edges at high-speed and over broad illumination conditions. However, traditional deep learning frameworks designed for conventional cameras struggle with the asynchronous, stream-like nature of event data, as their architectures are optimized for discrete, image-like inputs. We propose a scalable, flexible and adaptable framework for pixel-wise depth estimation with event cameras in both monocular and stereo setups. The 3D scene structure is encoded into disparity space images (DSIs), representing spatial densities of rays obtained by back-projecting events into space via known camera poses. Our neural network processes local subregions of the DSIs combining 3D convolutions and a recurrent structure to recognize valuable patterns for depth prediction. Local processing enables fast inference with full parallelization and ensures constant ultra-low model complexity and memory costs, regardless of camera resolution. Experiments on standard benchmarks (MVSEC and DSEC datasets) demonstrate unprecedented effectiveness: (i) using purely monocular data, our method achieves comparable results to existing stereo methods; (ii) when applied to stereo data, it strongly outperforms all state-of-the-art (SOTA) approaches, reducing the mean absolute error by at least 42%; (iii) our method also allows for increases in depth completeness by more than 3-fold while still yielding a reduction in median absolute error of at least 30%. Given its remarkable performance and effective processing of event-data, our framework holds strong potential to become a standard approach for using deep learning for event-based depth estimation and SLAM. Project page: this https URL', 'abstract_zh': '事件摄像头为基于多视图立体深度估计和SLAM的应用提供了有前景的方法，由于其能在高速和广泛光照条件下检测无模糊3D边缘的能力。然而，传统为常规摄像头设计的深度学习框架难以处理事件数据的异步、流式性质，因为其架构优化是为了离散的、图像-like的输入。我们提出了一种适用于单目和立体设置的事件摄像头像素级深度估计的可扩展、灵活和适应性框架。3D场景结构编码在视差空间图像(DSIs)中表示，代表通过将事件回投影到空间中获得的光线的空间密度，其中已知相机姿态。我们的神经网络处理DSI的局部子区域，结合3D卷积和递归结构来识别深度预测有价值的模式。局部处理能使推理快速并实现全并行化，确保无论相机分辨率如何，模型复杂度和内存成本始终保持在超低水平。在标准基准数据集（MVSEC和DSEC）上的实验展示了前所未有的效果：(i) 使用纯单目数据，我们的方法达到与现有立体方法相当的结果；(ii) 当应用于立体数据时，它显著优于所有最新方法，绝对均值误差降低至少42%；(iii) 我们的方法还能使深度完整性提高超过三倍，同时仍能减少至少30%的中值绝对误差。鉴于其卓越的性能和对事件数据的有效处理，我们的框架具有成为深度学习用于事件驱动深度估计和SLAM的标准方法的强大潜力。项目页面: [这个链接](this https URL)。', 'title_zh': 'DERD-Net: 从事件式射线密度学习深度'}
{'arxiv_id': 'arXiv:2504.15776', 'title': 'Pose Optimization for Autonomous Driving Datasets using Neural Rendering Models', 'authors': 'Quentin Herau, Nathan Piasco, Moussab Bennehar, Luis Rolado, Dzmitry Tsishkou, Bingbing Liu, Cyrille Migniot, Pascal Vasseur, Cédric Demonceaux', 'link': 'https://arxiv.org/abs/2504.15776', 'abstract': 'Autonomous driving systems rely on accurate perception and localization of the ego car to ensure safety and reliability in challenging real-world driving scenarios. Public datasets play a vital role in benchmarking and guiding advancement in research by providing standardized resources for model development and evaluation. However, potential inaccuracies in sensor calibration and vehicle poses within these datasets can lead to erroneous evaluations of downstream tasks, adversely impacting the reliability and performance of the autonomous systems. To address this challenge, we propose a robust optimization method based on Neural Radiance Fields (NeRF) to refine sensor poses and calibration parameters, enhancing the integrity of dataset benchmarks. To validate improvement in accuracy of our optimized poses without ground truth, we present a thorough evaluation process, relying on reprojection metrics, Novel View Synthesis rendering quality, and geometric alignment. We demonstrate that our method achieves significant improvements in sensor pose accuracy. By optimizing these critical parameters, our approach not only improves the utility of existing datasets but also paves the way for more reliable autonomous driving models. To foster continued progress in this field, we make the optimized sensor poses publicly available, providing a valuable resource for the research community.', 'abstract_zh': '自主驾驶系统依赖于对 ego 车辆准确感知和定位，以确保在复杂的真实驾驶场景中实现安全性和可靠性。公共数据集在基准测试和指导研究方面发挥着重要作用，通过提供标准化资源支持模型开发和评估。然而，这些数据集中传感器校准和车辆姿态的潜在不准确可能会导致下游任务评估错误，从而影响自主系统的可靠性和性能。为解决这一挑战，我们提出一种基于神经辐射场（NeRF）的稳健优化方法，以 refinement 传感器姿态和校准参数，提高数据集基准的完整性。为验证优化姿态准确性的提升，我们采用了详细的评估过程，基于重投影指标、新颖视角合成渲染质量以及几何对齐。我们证明，我们的方法在传感器姿态准确性方面取得了显著提升。通过优化这些关键参数，我们的方法不仅提高了现有数据集的实用性，也为更可靠的自主驾驶模型铺平了道路。为了促进该领域的持续进展，我们公开发布了优化后的传感器姿态，为研究社区提供了一项宝贵资源。', 'title_zh': '使用神经渲染模型的自主驾驶数据集姿态优化'}
{'arxiv_id': 'arXiv:2504.15611', 'title': 'An ACO-MPC Framework for Energy-Efficient and Collision-Free Path Planning in Autonomous Maritime Navigation', 'authors': 'Yaoze Liu, Zhen Tian, Qifan Zhou, Zixuan Huang, Hongyu Sun', 'link': 'https://arxiv.org/abs/2504.15611', 'abstract': "Automated driving on ramps presents significant challenges due to the need to balance both safety and efficiency during lane changes. This paper proposes an integrated planner for automated vehicles (AVs) on ramps, utilizing an unsatisfactory level metric for efficiency and arrow-cluster-based sampling for safety. The planner identifies optimal times for the AV to change lanes, taking into account the vehicle's velocity as a key factor in efficiency. Additionally, the integrated planner employs arrow-cluster-based sampling to evaluate collision risks and select an optimal lane-changing curve. Extensive simulations were conducted in a ramp scenario to verify the planner's efficient and safe performance. The results demonstrate that the proposed planner can effectively select an appropriate lane-changing time point and a safe lane-changing curve for AVs, without incurring any collisions during the maneuver.", 'abstract_zh': '自动化车辆在匝道上的车道变更规划：综合效率不满足度度量与箭头簇采样的集成规划', 'title_zh': '基于自主海洋导航的节能无碰撞路径规划的蚁群优化-模型预测控制框架'}
{'arxiv_id': 'arXiv:2504.15453', 'title': 'Nearly Optimal Nonlinear Safe Control with BaS-SDRE', 'authors': 'Hassan Almubarak, Maitham F. AL-Sunni, Justin T. Dubbin, Nader Sadegh, John M. Dolan, Evangelos A. Theodorou', 'link': 'https://arxiv.org/abs/2504.15453', 'abstract': "The State-Dependent Riccati Equation (SDRE) approach has emerged as a systematic and effective means of designing nearly optimal nonlinear controllers. The Barrier States (BaS) embedding methodology was developed recently for safe multi-objective controls in which the safety condition is manifested as a state to be controlled along with other states of the system. The overall system, termed the safety embedded system, is highly nonlinear even if the original system is linear. This paper develops a nonlinear nearly optimal safe feedback control technique by combining the two strategies effectively. First, the BaS is derived in an extended linearization formulation to be subsequently used to form an extended safety embedded system. A new optimal control problem is formed thereafter, which is used to construct a safety embedded State-Dependent Riccati Equation, termed BaS-SDRE, whose solution approximates the solution of the optimal control problem's associated Hamilton-Jacobi-Bellman (HJB) equation. The BaS-SDRE is then solved online to synthesize the nearly optimal safe control. The proposed technique's efficacy is demonstrated on an unstable, constrained linear system that shows how the synthesized control reacts to nonlinearities near the unsafe region, a nonlinear flight control system with limited path angular velocity that exists due to structural and dynamic concerns, and a planar quadrotor system that navigates safely in a crowded environment.", 'abstract_zh': '基于Barrier States的State-Dependent Riccati方程方法在安全非线性控制设计中的应用', 'title_zh': '几乎最优的非线性安全控制：BaS-SDRE方法'}
{'arxiv_id': 'arXiv:2504.15423', 'title': 'Safety Embedded Adaptive Control Using Barrier States', 'authors': 'Maitham F. AL-Sunni, Hassan Almubarak, John M. Dolan', 'link': 'https://arxiv.org/abs/2504.15423', 'abstract': 'In this work, we explore the application of barrier states (BaS) in the realm of safe nonlinear adaptive control. Our proposed framework derives barrier states for systems with parametric uncertainty, which are augmented into the uncertain dynamical model. We employ an adaptive nonlinear control strategy based on a control Lyapunov functions approach to design a stabilizing controller for the augmented system. The developed theory shows that the controller ensures safe control actions for the original system while meeting specified performance objectives. We validate the effectiveness of our approach through simulations on diverse systems, including a planar quadrotor subject to unknown drag forces and an adaptive cruise control system, for which we provide comparisons with existing methodologies.', 'abstract_zh': '本研究探讨了屏障状态在安全非线性自适应控制领域的应用。我们提出的框架为具有参数不确定性系统的屏障状态进行推导，并将其扩充到不确定动态模型中。基于控制李雅普诺夫函数的方法，我们设计了稳定控制器以控制扩充后的系统。所发展的理论表明，控制器能够确保对原始系统进行安全控制操作，同时满足指定的性能目标。通过在多种系统上进行仿真，包括受未知阻力影响的平面四旋翼飞行器和自适应巡航控制系统，验证了该方法的有效性，并提供了与现有方法的比较。', 'title_zh': '嵌入安全的自适应控制基于障碍状态'}
{'arxiv_id': 'arXiv:2504.15369', 'title': 'Solving New Tasks by Adapting Internet Video Knowledge', 'authors': 'Calvin Luo, Zilai Zeng, Yilun Du, Chen Sun', 'link': 'https://arxiv.org/abs/2504.15369', 'abstract': 'Video generative models demonstrate great promise in robotics by serving as visual planners or as policy supervisors. When pretrained on internet-scale data, such video models intimately understand alignment with natural language, and can thus facilitate generalization to novel downstream behavior through text-conditioning. However, they may not be sensitive to the specificities of the particular environment the agent inhabits. On the other hand, training video models on in-domain examples of robotic behavior naturally encodes environment-specific intricacies, but the scale of available demonstrations may not be sufficient to support generalization to unseen tasks via natural language specification. In this work, we investigate different adaptation techniques that integrate in-domain information with large-scale pretrained video models, and explore the extent to which they enable novel text-conditioned generalization for robotic tasks, while also considering their independent data and resource considerations. We successfully demonstrate across robotic environments that adapting powerful video models with small scales of example data can successfully facilitate generalization to novel behaviors. In particular, we present a novel adaptation strategy, termed Inverse Probabilistic Adaptation, that not only consistently achieves strong generalization performance across robotic tasks and settings, but also exhibits robustness to the quality of adaptation data, successfully solving novel tasks even when only suboptimal in-domain demonstrations are available.', 'abstract_zh': '基于视频的生成模型在机器人领域通过作为视觉规划者或策略监督者展现出巨大潜力。当在互联网规模的数据上进行预训练时，这类视频模型能够深刻理解自然语言的对齐关系，并通过文本条件化促进对新颖下游行为的一般化。然而，它们可能对特定环境的具体特性不敏感。另一方面，通过领域内的机器人行为示例对视频模型进行训练会自然地编码环境特定的细节，但由于可用示范的规模可能不足以通过自然语言规范支持对未见任务的一般化。在本文中，我们探讨了将领域内信息与大规模预训练视频模型相结合的不同适应技术，并探讨了它们在机器人任务中实现新颖文本条件化一般化的程度，同时也考虑了独立的数据和资源需求。我们成功地展示了在不同的机器人环境中，通过使用小规模的示例数据适应强大的视频模型可以成功促进对新颖行为的一般化。特别地，我们提出了一种新颖的适应策略，称为逆概率适应，不仅在机器人任务和设置中一致地实现了强一般化性能，还能在仅有次优领域内演示的情况下展示出对适应数据质量的鲁棒性，从而成功解决新型任务。', 'title_zh': '通过适应互联网视频知识解决新任务'}
{'arxiv_id': 'arXiv:2504.15329', 'title': 'Vision6D: 3D-to-2D Interactive Visualization and Annotation Tool for 6D Pose Estimation', 'authors': 'Yike Zhang, Eduardo Davalos, Jack Noble', 'link': 'https://arxiv.org/abs/2504.15329', 'abstract': "Accurate 6D pose estimation has gained more attention over the years for robotics-assisted tasks that require precise interaction with physical objects. This paper presents an interactive 3D-to-2D visualization and annotation tool to support the 6D pose estimation research community. To the best of our knowledge, the proposed work is the first tool that allows users to visualize and manipulate 3D objects interactively on a 2D real-world scene, along with a comprehensive user study. This system supports robust 6D camera pose annotation by providing both visual cues and spatial relationships to determine object position and orientation in various environments. The annotation feature in Vision6D is particularly helpful in scenarios where the transformation matrix between the camera and world objects is unknown, as it enables accurate annotation of these objects' poses using only the camera intrinsic matrix. This capability serves as a foundational step in developing and training advanced pose estimation models across various domains. We evaluate Vision6D's effectiveness by utilizing widely-used open-source pose estimation datasets Linemod and HANDAL through comparisons between the default ground-truth camera poses with manual annotations. A user study was performed to show that Vision6D generates accurate pose annotations via visual cues in an intuitive 3D user interface. This approach aims to bridge the gap between 2D scene projections and 3D scenes, offering an effective way for researchers and developers to solve 6D pose annotation related problems. The software is open-source and publicly available at this https URL.", 'abstract_zh': '准确的6D姿态估计在辅助机器人任务中日益受到关注，本论文介绍了一种交互式的3D到2D可视化和标注工具，以支持6D姿态估计研究社区。据我们所知，本工作中首次提出了允许用户在真实世界的2D场景中交互地可视化和操作3D对象的工具，并结合了全面的用户研究。该系统通过提供视觉提示和空间关系，支持在各种环境中稳健地标注6D相机姿态。Vision6D中的标注功能特别适用于相机与世界对象之间的转换矩阵未知的场景，通过仅使用相机内参矩阵即可准确标注这些对象的姿态。这一能力为跨各领域开发和训练高级姿态估计模型奠定了基础。我们通过与广泛使用的开源姿态估计数据集Linemod和HANDAL进行比较，评估了Vision6D的有效性。用户研究显示，Vision6D能够通过直观的3D用户界面中的视觉提示生成准确的姿态标注。该方法旨在弥合2D场景投影与3D场景之间的差距，为研究人员和开发人员提供解决6D姿态标注问题的有效途径。该软件开源并可在以下链接访问：this https URL。', 'title_zh': 'Vision6D：用于6D姿态估计的3D到2D交互可视化和注释工具'}
