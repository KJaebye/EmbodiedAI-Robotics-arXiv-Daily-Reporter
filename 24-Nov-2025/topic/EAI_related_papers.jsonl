{'arxiv_id': 'arXiv:2511.17332', 'title': 'Agentifying Agentic AI', 'authors': 'Virginia Dignum, Frank Dignum', 'link': 'https://arxiv.org/abs/2511.17332', 'abstract': 'Agentic AI seeks to endow systems with sustained autonomy, reasoning, and interaction capabilities. To realize this vision, its assumptions about agency must be complemented by explicit models of cognition, cooperation, and governance. This paper argues that the conceptual tools developed within the Autonomous Agents and Multi-Agent Systems (AAMAS) community, such as BDI architectures, communication protocols, mechanism design, and institutional modelling, provide precisely such a foundation. By aligning adaptive, data-driven approaches with structured models of reasoning and coordination, we outline a path toward agentic systems that are not only capable and flexible, but also transparent, cooperative, and accountable. The result is a perspective on agency that bridges formal theory and practical autonomy.', 'abstract_zh': '代理型人工智能旨在赋予系统持续的自主性、推理能力和交互能力。为了实现这一愿景，其关于代理性的假设必须通过明确的认知模型、合作模型和治理体系模型加以补充。本文认为，自主代理和多agent系统（AAMAS）社区发展出的概念工具，如BDI架构、通信协议、机制设计和制度建模，正好提供了这种基础。通过将适应性、数据驱动的方法与结构化的推理和协调模型相结合，我们勾勒出一条通往不仅具备能力和灵活性，而且具备透明性、合作性和问责性的代理型系统的发展路径。结果展现了将正式理论与实际自主性连接起来的代理视角。', 'title_zh': '代理化能动AI'}
{'arxiv_id': 'arXiv:2511.17162', 'title': 'The Belief-Desire-Intention Ontology for modelling mental reality and agency', 'authors': 'Sara Zuppiroli, Carmelo Fabio Longo, Anna Sofia Lippolis, Rocco Paolillo, Lorenzo Giammei, Miguel Ceriani, Francesco Poggi, Antonio Zinilli, Andrea Giovanni Nuzzolese', 'link': 'https://arxiv.org/abs/2511.17162', 'abstract': 'The Belief-Desire-Intention (BDI) model is a cornerstone for representing rational agency in artificial intelligence and cognitive sciences. Yet, its integration into structured, semantically interoperable knowledge representations remains limited. This paper presents a formal BDI Ontology, conceived as a modular Ontology Design Pattern (ODP) that captures the cognitive architecture of agents through beliefs, desires, intentions, and their dynamic interrelations. The ontology ensures semantic precision and reusability by aligning with foundational ontologies and best practices in modular design. Two complementary lines of experimentation demonstrate its applicability: (i) coupling the ontology with Large Language Models (LLMs) via Logic Augmented Generation (LAG) to assess the contribution of ontological grounding to inferential coherence and consistency; and (ii) integrating the ontology within the Semas reasoning platform, which implements the Triples-to-Beliefs-to-Triples (T2B2T) paradigm, enabling a bidirectional flow between RDF triples and agent mental states. Together, these experiments illustrate how the BDI Ontology acts as both a conceptual and operational bridge between declarative and procedural intelligence, paving the way for cognitively grounded, explainable, and semantically interoperable multi-agent and neuro-symbolic systems operating within the Web of Data.', 'abstract_zh': '基于信念-欲望-意图（BDI）模型的本体：作为模块化本体设计模式的认知架构形式化表示及其应用探究', 'title_zh': '信念- Desire- 意图本体论：用于建模心理现实和 agency'}
{'arxiv_id': 'arXiv:2511.17056', 'title': 'Patient-level Information Extraction by Consistent Integration of Textual and Tabular Evidence with Bayesian Networks', 'authors': 'Paloma Rabaey, Adrick Tench, Stefan Heytens, Thomas Demeester', 'link': 'https://arxiv.org/abs/2511.17056', 'abstract': "Electronic health records (EHRs) form an invaluable resource for training clinical decision support systems. To leverage the potential of such systems in high-risk applications, we need large, structured tabular datasets on which we can build transparent feature-based models. While part of the EHR already contains structured information (e.g. diagnosis codes, medications, and lab results), much of the information is contained within unstructured text (e.g. discharge summaries and nursing notes). In this work, we propose a method for multi-modal patient-level information extraction that leverages both the tabular features available in the patient's EHR (using an expert-informed Bayesian network) as well as clinical notes describing the patient's symptoms (using neural text classifiers). We propose the use of virtual evidence augmented with a consistency node to provide an interpretable, probabilistic fusion of the models' predictions. The consistency node improves the calibration of the final predictions compared to virtual evidence alone, allowing the Bayesian network to better adjust the neural classifier's output to handle missing information and resolve contradictions between the tabular and text data. We show the potential of our method on the SimSUM dataset, a simulated benchmark linking tabular EHRs with clinical notes through expert knowledge.", 'abstract_zh': '电子健康记录中的多模态患者级别信息提取方法', 'title_zh': '基于贝叶斯网络的一致性文本和表格证据整合的患者级信息提取'}
{'arxiv_id': 'arXiv:2511.16997', 'title': 'MirrorMind: Empowering OmniScientist with the Expert Perspectives and Collective Knowledge of Human Scientists', 'authors': 'Qingbin Zeng, Bingbing Fan, Zhiyu Chen, Sijian Ren, Zhilun Zhou, Xuhua Zhang, Yuanyi Zhen, Fengli Xu, Yong Li, Tie-Yan Liu', 'link': 'https://arxiv.org/abs/2511.16997', 'abstract': "The emergence of AI Scientists has demonstrated remarkable potential in automating scientific research. However, current approaches largely conceptualize scientific discovery as a solitary optimization or search process, overlooking that knowledge production is inherently a social and historical endeavor. Human scientific insight stems from two distinct yet interconnected sources. First is the individual cognitive trajectory, where a researcher's unique insight is shaped by their evolving research history and stylistic preferences; another is the collective disciplinary memory, where knowledge is sedimented into vast, interconnected networks of citations and concepts. Existing LLMs still struggle to represent these structured, high-fidelity cognitive and social contexts. To bridge this gap, we introduce MirrorMind, a hierarchical cognitive architecture that integrates dual-memory representations within a three-level framework. The Individual Level constructs high-fidelity cognitive models of individual researchers by capturing their episodic, semantic, and persona memories; the Domain Level maps collective knowledge into structured disciplinary concept graphs; and the Interdisciplinary Level that acts as an orthogonal orchestration engine. Crucially, our architecture separates memory storage from agentic execution, enabling AI scientist agents to flexibly access individual memories for unique perspectives or collective structures to reason. We evaluate MirrorMind across four comprehensive tasks, including author-level cognitive simulation, complementary reasoning, cross-disciplinary collaboration promotion, and multi-agent scientific problem solving. The results show that by integrating individual cognitive depth with collective disciplinary breadth, MirrorMind moves beyond simple fact retrieval toward structural, personalized, and insight-generating scientific reasoning.", 'abstract_zh': 'AI科学家的 emergence 表明了在自动化科学研究方面的显著潜力。然而，当前的方法主要将科学发现视为孤立的优化或搜索过程，忽略了知识生产本质上是社会性和历史性的。人类的科学洞察源自两种既独立又相互关联的来源。首先是个人认知轨迹，其中研究人员的独特见解受到其不断发展的研究历史和风格偏好的影响；其次是集体学科记忆，其中知识积淀为大量相互连接的概念和引文网络。现有的大语言模型仍然难以表示这些结构化和高保真的认知和社会背景。为了弥合这一差距，我们提出了MirrorMind，这是一种分层认知架构，其在三层框架内整合了双记忆表示。个体层次通过捕捉情景记忆、语义记忆和人物记忆来构建高保真度的个体研究人员认知模型；领域层次将集体知识映射到结构化的学科概念图；跨学科层次充当正交编排引擎。 crucially，我们的架构将记忆存储与行动性执行分开，使AI科学家代理能够灵活地访问个体记忆以获得独特视角或集体结构来进行推理。我们通过四个全面的任务评估了MirrorMind，包括作者级认知模拟、互补推理、跨学科合作促进以及多智能体科学问题解决。结果表明，通过整合个体认知深度和集体学科广度，MirrorMind超越了简单的事实检索，迈向了结构性、个性化和洞察生成的科学推理。', 'title_zh': 'MirrorMind: 賦能全知科學家的人類科學家專家視角與集體知識'}
{'arxiv_id': 'arXiv:2511.17225', 'title': 'TP-MDDN: Task-Preferenced Multi-Demand-Driven Navigation with Autonomous Decision-Making', 'authors': 'Shanshan Li, Da Huang, Yu He, Yanwei Fu, Yu-Gang Jiang, Xiangyang Xue', 'link': 'https://arxiv.org/abs/2511.17225', 'abstract': 'In daily life, people often move through spaces to find objects that meet their needs, posing a key challenge in embodied AI. Traditional Demand-Driven Navigation (DDN) handles one need at a time but does not reflect the complexity of real-world tasks involving multiple needs and personal choices. To bridge this gap, we introduce Task-Preferenced Multi-Demand-Driven Navigation (TP-MDDN), a new benchmark for long-horizon navigation involving multiple sub-demands with explicit task preferences. To solve TP-MDDN, we propose AWMSystem, an autonomous decision-making system composed of three key modules: BreakLLM (instruction decomposition), LocateLLM (goal selection), and StatusMLLM (task monitoring). For spatial memory, we design MASMap, which combines 3D point cloud accumulation with 2D semantic mapping for accurate and efficient environmental understanding. Our Dual-Tempo action generation framework integrates zero-shot planning with policy-based fine control, and is further supported by an Adaptive Error Corrector that handles failure cases in real time. Experiments demonstrate that our approach outperforms state-of-the-art baselines in both perception accuracy and navigation robustness.', 'abstract_zh': '日常生活中的物体搜寻任务为实体AI提出了关键挑战：面向任务的多需求导向导航', 'title_zh': 'TP-MDDN: 任务偏好型多需求驱动导航与自主决策'}
{'arxiv_id': 'arXiv:2511.16825', 'title': 'WorldGen: From Text to Traversable and Interactive 3D Worlds', 'authors': 'Dilin Wang, Hyunyoung Jung, Tom Monnier, Kihyuk Sohn, Chuhang Zou, Xiaoyu Xiang, Yu-Ying Yeh, Di Liu, Zixuan Huang, Thu Nguyen-Phuoc, Yuchen Fan, Sergiu Oprea, Ziyan Wang, Roman Shapovalov, Nikolaos Sarafianos, Thibault Groueix, Antoine Toisoul, Prithviraj Dhar, Xiao Chu, Minghao Chen, Geon Yeong Park, Mahima Gupta, Yassir Azziz, Rakesh Ranjan, Andrea Vedaldi', 'link': 'https://arxiv.org/abs/2511.16825', 'abstract': 'We introduce WorldGen, a system that enables the automatic creation of large-scale, interactive 3D worlds directly from text prompts. Our approach transforms natural language descriptions into traversable, fully textured environments that can be immediately explored or edited within standard game engines. By combining LLM-driven scene layout reasoning, procedural generation, diffusion-based 3D generation, and object-aware scene decomposition, WorldGen bridges the gap between creative intent and functional virtual spaces, allowing creators to design coherent, navigable worlds without manual modeling or specialized 3D expertise. The system is fully modular and supports fine-grained control over layout, scale, and style, producing worlds that are geometrically consistent, visually rich, and efficient to render in real time. This work represents a step towards accessible, generative world-building at scale, advancing the frontier of 3D generative AI for applications in gaming, simulation, and immersive social environments.', 'abstract_zh': 'WorldGen：一种直接从文本提示自动创建大规模交互式3D世界的系统', 'title_zh': 'WorldGen: 从文本生成可游走和交互的3D世界'}
{'arxiv_id': 'arXiv:2511.16743', 'title': 'SafeR-CLIP: Mitigating NSFW Content in Vision-Language Models While Preserving Pre-Trained Knowledge', 'authors': 'Adeel Yousaf, Joseph Fioresi, James Beetham, Amrit Singh Bedi, Mubarak Shah', 'link': 'https://arxiv.org/abs/2511.16743', 'abstract': "Improving the safety of vision-language models like CLIP via fine-tuning often comes at a steep price, causing significant drops in their generalization performance. We find this trade-off stems from rigid alignment strategies that force unsafe concepts toward single, predefined safe targets, disrupting the model's learned semantic structure. To address this, we propose a proximity-aware approach: redirecting unsafe concepts to their semantically closest safe alternatives to minimize representational change. We introduce SaFeR-CLIP, a fine-tuning framework that applies this principle of minimal intervention. SaFeR-CLIP successfully reconciles safety and performance, recovering up to 8.0% in zero-shot accuracy over prior methods while maintaining robust safety. To support more rigorous evaluation, we also contribute NSFW-Caps, a new benchmark of 1,000 highly-aligned pairs for testing safety under distributional shift. Our work shows that respecting the geometry of pretrained representations is key to achieving safety without sacrificing performance.", 'abstract_zh': '通过微调提高类似CLIP的视觉语言模型的安全性往往会导致其泛化性能显著下降：一种接近aware的方法来缓解这一权衡', 'title_zh': 'SafeR-CLIP：减轻视觉-语言模型中的不合适内容同时保留预训练知识'}
