# Zero-shot Structure Learning and Planning for Autonomous Robot Navigation using Active Inference 

**Title (ZH)**: 基于主动推断的自主机器人导航零样本结构学习与规划 

**Authors**: Daria de tinguy, Tim Verbelen, Emilio Gamba, Bart Dhoedt  

**Link**: [PDF](https://arxiv.org/pdf/2510.09574)  

**Abstract**: Autonomous navigation in unfamiliar environments requires robots to simultaneously explore, localise, and plan under uncertainty, without relying on predefined maps or extensive training. We present a biologically inspired, Active Inference-based framework, Active Inference MAPping and Planning (AIMAPP). This model unifies mapping, localisation, and decision-making within a single generative model. Inspired by hippocampal navigation, it uses topological reasoning, place-cell encoding, and episodic memory to guide behaviour. The agent builds and updates a sparse topological map online, learns state transitions dynamically, and plans actions by minimising Expected Free Energy. This allows it to balance goal-directed and exploratory behaviours. We implemented a ROS-compatible navigation system that is sensor and robot-agnostic, capable of integrating with diverse hardware configurations. It operates in a fully self-supervised manner, is resilient to drift, and supports both exploration and goal-directed navigation without any pre-training. We demonstrate robust performance in large-scale real and simulated environments against state-of-the-art planning models, highlighting the system's adaptability to ambiguous observations, environmental changes, and sensor noise. The model offers a biologically inspired, modular solution to scalable, self-supervised navigation in unstructured settings. AIMAPP is available at this https URL. 

**Abstract (ZH)**: 自主导航在陌生环境中的要求是在不确定性下同时探索、定位和规划，无需依赖预定义地图或大量训练。我们提出了一种受生物启发的Active Inference框架--Active Inference MAPping and Planning (AIMAPP)。该模型在单一的生成模型中统一了制图、定位和决策。受海马导航启发，它利用拓扑推理、位置细胞编码和情景记忆来引导行为。代理实时构建和更新稀疏拓扑图，动态学习状态转移，并通过最小化预期自由能来规划行动。这使得代理能够平衡目标导向和探索性行为。我们实现了一个与ROS兼容的导航系统，该系统传感器和机器人无关，能够与各种硬件配置集成。该系统以完全自我监督的方式运行，对漂移具有鲁棒性，并且在无任何预训练的情况下支持探索和目标导向导航。我们在大规模的真实和模拟环境中展示了该系统的稳健性能，突显了系统对模糊观察、环境变化和传感器噪声的适应能力。该模型提供了一种生物启发的、模块化的解决方案，适用于结构化不强的环境下的可扩展和自我监督导航。AIMAPP可在以下链接获取。 

---
# Guiding Energy-Efficient Locomotion through Impact Mitigation Rewards 

**Title (ZH)**: 通过冲击缓解奖励引导能效 locomotion 

**Authors**: Chenghao Wang, Arjun Viswanathan, Eric Sihite, Alireza Ramezani  

**Link**: [PDF](https://arxiv.org/pdf/2510.09543)  

**Abstract**: Animals achieve energy-efficient locomotion by their implicit passive dynamics, a marvel that has captivated roboticists for this http URL, methods incorporated Adversarial Motion Prior (AMP) and Reinforcement learning (RL) shows promising progress to replicate Animals' naturalistic motion. However, such imitation learning approaches predominantly capture explicit kinematic patterns, so-called gaits, while overlooking the implicit passive dynamics. This work bridges this gap by incorporating a reward term guided by Impact Mitigation Factor (IMF), a physics-informed metric that quantifies a robot's ability to passively mitigate impacts. By integrating IMF with AMP, our approach enables RL policies to learn both explicit motion trajectories from animal reference motion and the implicit passive dynamic. We demonstrate energy efficiency improvements of up to 32%, as measured by the Cost of Transport (CoT), across both AMP and handcrafted reward structure. 

**Abstract (ZH)**: 动物通过其隐含的被动动力学实现能量高效的运动，这一 marvel 已经吸引了 roboticists 的注意。本工作通过结合由 Impact Mitigation Factor (IMF) 引导的奖励项，填补了这一空白。IMF 是一个基于物理的度量，量化了机器人被动吸收冲击的能力。通过将 IMF 与 Adversarial Motion Prior (AMP) 结合，我们的方法使强化学习策略能够学习动物参考运动的显式运动轨迹和隐含的被动动力学。实验结果表明，本方法在 Cost of Transport (CoT) 测量下实现了高达 32% 的能耗效率提升。 

---
# Dynamic Quadrupedal Legged and Aerial Locomotion via Structure Repurposing 

**Title (ZH)**: 基于结构再利用的动态四足步行和 aerial 运动 

**Authors**: Chenghao Wang, Kaushik Venkatesh Krishnamurthy, Shreyansh Pitroda, Adarsh Salagame, Ioannis Mandralis, Eric Sihite, Alireza Ramezani, Morteza Gharib  

**Link**: [PDF](https://arxiv.org/pdf/2510.09526)  

**Abstract**: Multi-modal ground-aerial robots have been extensively studied, with a significant challenge lying in the integration of conflicting requirements across different modes of operation. The Husky robot family, developed at Northeastern University, and specifically the Husky v.2 discussed in this study, addresses this challenge by incorporating posture manipulation and thrust vectoring into multi-modal locomotion through structure repurposing. This quadrupedal robot features leg structures that can be repurposed for dynamic legged locomotion and flight. In this paper, we present the hardware design of the robot and report primary results on dynamic quadrupedal legged locomotion and hovering. 

**Abstract (ZH)**: 多模态地面-空中机器人得到了广泛研究，不同操作模式之间相互冲突的要求的整合是一个显著挑战。东北大学开发的Husky机器人家族，特别是在本研究中讨论的Husky v.2，通过结构再利用将姿态操控和推力向量集成到多模态运动中，该四足机器人具有可再利用于动态腿足运动和飞行的腿部结构。在本文中，我们介绍了机器人的硬件设计，并报告了动态四足腿足运动和悬停的主要研究结果。 

---
# Autonomous Soft Robotic Guidewire Navigation via Imitation Learning 

**Title (ZH)**: 自主软机器人导丝导航基于模仿学习 

**Authors**: Noah Barnes, Ji Woong Kim, Lingyun Di, Hannah Qu, Anuruddha Bhattacharjee, Miroslaw Janowski, Dheeraj Gandhi, Bailey Felix, Shaopeng Jiang, Olivia Young, Mark Fuge, Ryan D. Sochol, Jeremy D. Brown, Axel Krieger  

**Link**: [PDF](https://arxiv.org/pdf/2510.09497)  

**Abstract**: In endovascular surgery, endovascular interventionists push a thin tube called a catheter, guided by a thin wire to a treatment site inside the patient's blood vessels to treat various conditions such as blood clots, aneurysms, and malformations. Guidewires with robotic tips can enhance maneuverability, but they present challenges in modeling and control. Automation of soft robotic guidewire navigation has the potential to overcome these challenges, increasing the precision and safety of endovascular navigation. In other surgical domains, end-to-end imitation learning has shown promising results. Thus, we develop a transformer-based imitation learning framework with goal conditioning, relative action outputs, and automatic contrast dye injections to enable generalizable soft robotic guidewire navigation in an aneurysm targeting task. We train the model on 36 different modular bifurcated geometries, generating 647 total demonstrations under simulated fluoroscopy, and evaluate it on three previously unseen vascular geometries. The model can autonomously drive the tip of the robot to the aneurysm location with a success rate of 83% on the unseen geometries, outperforming several baselines. In addition, we present ablation and baseline studies to evaluate the effectiveness of each design and data collection choice. Project website: this https URL 

**Abstract (ZH)**: 在血管内手术中，血管内介入医生通过一根细长的导管（由细长钢丝引导）推送至患者血管内的治疗位置，以治疗血栓、动脉瘤和畸形等多种情况。带有机械臂末端执行器的导丝可以增强操控性，但带来了建模和控制方面的挑战。通过软体机器人导丝导航的自动化有潜力克服这些挑战，提高血管内导航的精度和安全性。在其他外科领域，端到端的模仿学习已经显示出有希望的结果。因此，我们开发了一种基于变换器的目标条件模仿学习框架，包含相对动作输出和自动对比染料注射，以实现适用于动脉瘤定位任务的一般化软体机器人导丝导航。我们使用36种不同的模块化分叉几何结构进行模型训练，在模拟的X线下生成了总共647个演示，然后在三种未见过的血管几何结构上进行评估。模型在未见过的几何结构上自主将机器人的尖端引导至动脉瘤位置的成功率为83%，优于几个基线模型。此外，我们还进行了消融和基线研究，以评估每种设计和数据收集选择的有效性。项目网站：this https URL。 

---
# FOGMACHINE -- Leveraging Discrete-Event Simulation and Scene Graphs for Modeling Hierarchical, Interconnected Environments under Partial Observations from Mobile Agents 

**Title (ZH)**: FOGMACHINE——利用离散事件仿真和场景图建模基于移动代理部分观测下的层次化互联环境 

**Authors**: Lars Ohnemus, Nils Hantke, Max Weißer, Kai Furmans  

**Link**: [PDF](https://arxiv.org/pdf/2510.09483)  

**Abstract**: Dynamic Scene Graphs (DSGs) provide a structured representation of hierarchical, interconnected environments, but current approaches struggle to capture stochastic dynamics, partial observability, and multi-agent activity. These aspects are critical for embodied AI, where agents must act under uncertainty and delayed perception. We introduce FOGMACHINE , an open-source framework that fuses DSGs with discrete-event simulation to model object dynamics, agent observations, and interactions at scale. This setup enables the study of uncertainty propagation, planning under limited perception, and emergent multi-agent behavior. Experiments in urban scenarios illustrate realistic temporal and spatial patterns while revealing the challenges of belief estimation under sparse observations. By combining structured representations with efficient simulation, FOGMACHINE establishes an effective tool for benchmarking, model training, and advancing embodied AI in complex, uncertain environments. 

**Abstract (ZH)**: FOGMACHINE：将动态场景图与离散事件仿真融合以建模大规模物体动力学、代理观察和交互 

---
# Failure Prediction at Runtime for Generative Robot Policies 

**Title (ZH)**: 运行时生成机器人政策的失败预测 

**Authors**: Ralf Römer, Adrian Kobras, Luca Worbis, Angela P. Schoellig  

**Link**: [PDF](https://arxiv.org/pdf/2510.09459)  

**Abstract**: Imitation learning (IL) with generative models, such as diffusion and flow matching, has enabled robots to perform complex, long-horizon tasks. However, distribution shifts from unseen environments or compounding action errors can still cause unpredictable and unsafe behavior, leading to task failure. Early failure prediction during runtime is therefore essential for deploying robots in human-centered and safety-critical environments. We propose FIPER, a general framework for Failure Prediction at Runtime for generative IL policies that does not require failure data. FIPER identifies two key indicators of impending failure: (i) out-of-distribution (OOD) observations detected via random network distillation in the policy's embedding space, and (ii) high uncertainty in generated actions measured by a novel action-chunk entropy score. Both failure prediction scores are calibrated using a small set of successful rollouts via conformal prediction. A failure alarm is triggered when both indicators, aggregated over short time windows, exceed their thresholds. We evaluate FIPER across five simulation and real-world environments involving diverse failure modes. Our results demonstrate that FIPER better distinguishes actual failures from benign OOD situations and predicts failures more accurately and earlier than existing methods. We thus consider this work an important step towards more interpretable and safer generative robot policies. Code, data and videos are available at this https URL. 

**Abstract (ZH)**: 基于生成模型的 imitation 学习（IL）使机器人能够执行复杂的长期任务。然而，未见环境下的分布偏移或累积动作错误仍可能导致不可预测且不安全的行为，从而导致任务失败。因此，在以人类为中心和安全性关键的环境中部署机器人时，运行时的早期失败预测是非常重要的。我们提出了一种名为 FIPER 的通用框架，用于生成 IL 策略的运行时失败预测，该框架不要求失败数据。FIPER 识别两种即将发生失败的关键指标：(i) 通过策略嵌入空间中的随机网络蒸馏检测到的离分布观测，以及 (ii) 由新颖的动作块熵分数度量的生成动作的高不确定性。这两种失败预测得分均通过少量成功的回放使用校准预测进行校准。当这两项指标在短时间内超过阈值时，将触发失败警报。我们在涉及多种失败模式的五个仿真和实际环境中评估了 FIPER。我们的结果显示，FIPER 更好地区分了实际失败和良性离分布情况，并且比现有方法更早且更准确地预测了失败。因此，我们认为这项工作是朝更具解释性和安全性的生成机器人策略迈出的重要一步。相关代码、数据和视频可在以下链接获取。 

---
# Bridging Research and Practice in Simulation-based Testing of Industrial Robot Navigation Systems 

**Title (ZH)**: 基于仿真测试的工业机器人导航系统研究与实践桥梁构建 

**Authors**: Sajad Khatiri, Francisco Eli Vina Barrientos, Maximilian Wulf, Paolo Tonella, Sebastiano Panichella  

**Link**: [PDF](https://arxiv.org/pdf/2510.09396)  

**Abstract**: Ensuring robust robotic navigation in dynamic environments is a key challenge, as traditional testing methods often struggle to cover the full spectrum of operational requirements. This paper presents the industrial adoption of Surrealist, a simulation-based test generation framework originally for UAVs, now applied to the ANYmal quadrupedal robot for industrial inspection. Our method uses a search-based algorithm to automatically generate challenging obstacle avoidance scenarios, uncovering failures often missed by manual testing. In a pilot phase, generated test suites revealed critical weaknesses in one experimental algorithm (40.3% success rate) and served as an effective benchmark to prove the superior robustness of another (71.2% success rate). The framework was then integrated into the ANYbotics workflow for a six-month industrial evaluation, where it was used to test five proprietary algorithms. A formal survey confirmed its value, showing it enhances the development process, uncovers critical failures, provides objective benchmarks, and strengthens the overall verification pipeline. 

**Abstract (ZH)**: 确保在动态环境中的稳健机器人导航是一个关键挑战，传统的测试方法往往难以覆盖所有操作要求。本文介绍了将Surrealist这一基于仿真测试生成框架从无人机扩展到ANYmal四足机器人进行工业检测的应用。我们的方法使用基于搜索的算法自动生成具有挑战性的障碍物回避场景，揭示了许多手动测试常忽视的失败案例。在试点阶段，生成的测试套件揭示了一种实验算法的关键弱点（成功率为40.3%），并作为有效的基准测试证明了另一种算法的优异稳健性（成功率为71.2%）。随后，该框架被集成到ANYbotics的工作流程中，进行了为期六个月的工业评估，用于检测五种专有算法。正式调研确认了其价值，表明它能够改善开发过程、揭示关键失败、提供客观的基准测试并强化整体验证流程。 

---
# Placeit! A Framework for Learning Robot Object Placement Skills 

**Title (ZH)**: Placeit! 一种学习机器人物体放置技能的框架 

**Authors**: Amina Ferrad, Johann Huber, François Hélénon, Julien Gleyze, Mahdi Khoramshahi, Stéphane Doncieux  

**Link**: [PDF](https://arxiv.org/pdf/2510.09267)  

**Abstract**: Robotics research has made significant strides in learning, yet mastering basic skills like object placement remains a fundamental challenge. A key bottleneck is the acquisition of large-scale, high-quality data, which is often a manual and laborious process. Inspired by Graspit!, a foundational work that used simulation to automatically generate dexterous grasp poses, we introduce Placeit!, an evolutionary-computation framework for generating valid placement positions for rigid objects. Placeit! is highly versatile, supporting tasks from placing objects on tables to stacking and inserting them. Our experiments show that by leveraging quality-diversity optimization, Placeit! significantly outperforms state-of-the-art methods across all scenarios for generating diverse valid poses. A pick&place pipeline built on our framework achieved a 90% success rate over 120 real-world deployments. This work positions Placeit! as a powerful tool for open-environment pick-and-place tasks and as a valuable engine for generating the data needed to train simulation-based foundation models in robotics. 

**Abstract (ZH)**: 机器人研究在学习方面取得了显著进展，但在掌握如物体放置等基本技能方面仍然存在根本挑战。一个关键瓶颈是获取大规模、高质量的数据，这通常是手动且劳动密集型的过程。受Graspit!的启发，该工作利用模拟自动生成灵巧的抓取姿态，我们提出了Placeit!，一种用于生成刚体物体有效放置位置的进化计算框架。Placeit!极具 versatility，支持从将物体放在桌子上到堆叠和插入等多种任务。我们的实验表明，通过利用品质多样性优化，Placeit!在所有场景下生成多样化有效姿态方面显著优于最先进的方法。基于我们框架构建的拾取和放置流水线在120次真实世界部署中实现了90%的成功率。本工作将Placeit!定位为开放环境拾取和放置任务的强大工具，并作为生成训练基于模拟的基础模型所需数据的价值引擎。 

---
# Obstacle Avoidance using Dynamic Movement Primitives and Reinforcement Learning 

**Title (ZH)**: 基于动态运动模式和强化学习的障碍避让 

**Authors**: Dominik Urbaniak, Alejandro Agostini, Pol Ramon, Jan Rosell, Raúl Suárez, Michael Suppa  

**Link**: [PDF](https://arxiv.org/pdf/2510.09254)  

**Abstract**: Learning-based motion planning can quickly generate near-optimal trajectories. However, it often requires either large training datasets or costly collection of human demonstrations. This work proposes an alternative approach that quickly generates smooth, near-optimal collision-free 3D Cartesian trajectories from a single artificial demonstration. The demonstration is encoded as a Dynamic Movement Primitive (DMP) and iteratively reshaped using policy-based reinforcement learning to create a diverse trajectory dataset for varying obstacle configurations. This dataset is used to train a neural network that takes as inputs the task parameters describing the obstacle dimensions and location, derived automatically from a point cloud, and outputs the DMP parameters that generate the trajectory. The approach is validated in simulation and real-robot experiments, outperforming a RRT-Connect baseline in terms of computation and execution time, as well as trajectory length, while supporting multi-modal trajectory generation for different obstacle geometries and end-effector dimensions. Videos and the implementation code are available at this https URL. 

**Abstract (ZH)**: 基于学习的运动规划可以快速生成接近最优的轨迹。然而，它通常需要大的训练数据集或昂贵的人类演示收集。本文提出了一种替代方法，能够从单个人工演示快速生成平滑、接近最优的碰撞免费3D笛卡尔轨迹。演示被编码为动态运动模板（DMP），并通过基于策略的强化学习迭代重塑，以创建适用于不同障碍配置的多样轨迹数据集。该数据集用于训练一个神经网络，该网络接受描述障碍尺寸和位置的任务参数（从点云中自动提取）作为输入，并输出生成轨迹的DMP参数。该方法在仿真和真实机器人实验中进行了验证，与RRT-Connect基线相比，在计算和执行时间、轨迹长度方面表现出色，并支持不同障碍几何形状和末端执行器尺寸的多模态轨迹生成。相关视频和实现代码可在以下链接获取：this https URL。 

---
# Glovity: Learning Dexterous Contact-Rich Manipulation via Spatial Wrench Feedback Teleoperation System 

**Title (ZH)**: Glovity: 通过空间力矩反馈遥操作系统学习多接触灵活操作 

**Authors**: Yuyang Gao, Haofei Ma, Pai Zheng  

**Link**: [PDF](https://arxiv.org/pdf/2510.09229)  

**Abstract**: We present Glovity, a novel, low-cost wearable teleoperation system that integrates a spatial wrench (force-torque) feedback device with a haptic glove featuring fingertip Hall sensor calibration, enabling feedback-rich dexterous manipulation. Glovity addresses key challenges in contact-rich tasks by providing intuitive wrench and tactile feedback, while overcoming embodiment gaps through precise retargeting. User studies demonstrate significant improvements: wrench feedback boosts success rates in book-flipping tasks from 48% to 78% and reduces completion time by 25%, while fingertip calibration enhances thin-object grasping success significantly compared to commercial glove. Furthermore, incorporating wrench signals into imitation learning (via DP-R3M) achieves high success rate in novel contact-rich scenarios, such as adaptive page flipping and force-aware handovers. All hardware designs, software will be open-sourced. Project website: this https URL 

**Abstract (ZH)**: Glovity：一种低成本的集成空间 wrench 反馈装置的穿戴式远程操作系统，配备经过指端霍尔传感器校准的触感手套，实现丰富的灵巧操控反馈。 

---
# HANDO: Hierarchical Autonomous Navigation and Dexterous Omni-loco-manipulation 

**Title (ZH)**: HANDO：分层自主导航与 omniloquent 操作 manipulating 

**Authors**: Jingyuan Sun, Chaoran Wang, Mingyu Zhang, Cui Miao, Hongyu Ji, Zihan Qu, Han Sun, Bing Wang, Qingyi Si  

**Link**: [PDF](https://arxiv.org/pdf/2510.09221)  

**Abstract**: Seamless loco-manipulation in unstructured environments requires robots to leverage autonomous exploration alongside whole-body control for physical interaction. In this work, we introduce HANDO (Hierarchical Autonomous Navigation and Dexterous Omni-loco-manipulation), a two-layer framework designed for legged robots equipped with manipulators to perform human-centered mobile manipulation tasks. The first layer utilizes a goal-conditioned autonomous exploration policy to guide the robot to semantically specified targets, such as a black office chair in a dynamic environment. The second layer employs a unified whole-body loco-manipulation policy to coordinate the arm and legs for precise interaction tasks-for example, handing a drink to a person seated on the chair. We have conducted an initial deployment of the navigation module, and will continue to pursue finer-grained deployment of whole-body loco-manipulation. 

**Abstract (ZH)**: 无缝的非结构化环境操作要求机器人结合全身控制和自主探索来进行物理交互。本文介绍了HANDO（层次自主导航与全动 dexterous Omni-loco-manipulation），这是一种为配备 manipulator 的 legged 机器人设计的两层框架，用于执行以人类为中心的移动操作任务。第一层利用目标条件的自主探索策略引导机器人到达语义指定的目标，如动态环境中的一把黑色办公椅。第二层采用统一的全身操作策略来协调手臂和腿部进行精确的交互任务，例如将饮料递给坐在椅子上的 person。我们已经初步部署了导航模块，并将继续推进全身操作的更精细部署。 

---
# PLEXUS Hand: Lightweight Four-Motor Prosthetic Hand Enabling Precision-Lateral Dexterous Manipulation 

**Title (ZH)**: PLEXUS 手: 轻量化四电机假手实现精确-侧向灵巧操作 

**Authors**: Yuki Kuroda, Tomoya Takahashi, Cristian C Beltran-Hernandez, Masashi Hamaya, Kazutoshi Tanaka  

**Link**: [PDF](https://arxiv.org/pdf/2510.09209)  

**Abstract**: Electric prosthetic hands should be lightweight to decrease the burden on the user, shaped like human hands for cosmetic purposes, and have motors inside to protect them from damage and dirt. In addition to the ability to perform daily activities, these features are essential for everyday use of the hand. In-hand manipulation is necessary to perform daily activities such as transitioning between different postures, particularly through rotational movements, such as reorienting cards before slot insertion and operating tools such as screwdrivers. However, currently used electric prosthetic hands only achieve static grasp postures, and existing manipulation approaches require either many motors, which makes the prosthesis heavy for daily use in the hand, or complex mechanisms that demand a large internal space and force external motor placement, complicating attachment and exposing the components to damage. Alternatively, we combine a single-axis thumb and optimized thumb positioning to achieve basic posture and in-hand manipulation, that is, the reorientation between precision and lateral grasps, using only four motors in a lightweight (311 g) prosthetic hand. Experimental validation using primitive objects of various widths (5-30 mm) and shapes (cylinders and prisms) resulted in success rates of 90-100% for reorientation tasks. The hand performed seal stamping and USB device insertion, as well as rotation to operate a screwdriver. 

**Abstract (ZH)**: 电假手应当轻便以减轻使用者的负担，外观接近人类手掌以满足美化需求，并内含电机以防止损坏和脏污。除了能够执行日常活动外，这些特点对于手的日常使用至关重要。内部操纵对于执行日常活动如在不同姿势之间转换，尤其是通过旋转运动，比如在插入插槽前重新定位卡片和操作螺丝刀等工具是必要的。然而，目前使用的电假手只能实现静态握持姿势，现有的操纵方法要么需要多台电机，这使得假手在日常使用中变得沉重，要么需要复杂的机构，需要较大的内部空间并要求外部电机定位，从而复杂化安装过程并使组件暴露在外受损伤。相反，我们通过采用单轴拇指和优化的拇指定位，仅使用四个电机在轻量化（311克）的假手中实现了基本的姿势和内部操纵，即在精密握和侧向握之间的重新定位。实验验证使用不同宽度（5-30毫米）和形状（圆柱和棱柱）的原始物体，重新定位任务的成功率为90-100%。该手可以进行密封印章、USB设备插入，并且可以旋转操作螺丝刀。 

---
# Flow-Opt: Scalable Centralized Multi-Robot Trajectory Optimization with Flow Matching and Differentiable Optimization 

**Title (ZH)**: Flow-Opt: 基于流匹配和可微优化的可扩展集中式多机器人轨迹优化 

**Authors**: Simon Idoko, Arun Kumar Singh  

**Link**: [PDF](https://arxiv.org/pdf/2510.09204)  

**Abstract**: Centralized trajectory optimization in the joint space of multiple robots allows access to a larger feasible space that can result in smoother trajectories, especially while planning in tight spaces. Unfortunately, it is often computationally intractable beyond a very small swarm size. In this paper, we propose Flow-Opt, a learning-based approach towards improving the computational tractability of centralized multi-robot trajectory optimization. Specifically, we reduce the problem to first learning a generative model to sample different candidate trajectories and then using a learned Safety-Filter(SF) to ensure fast inference-time constraint satisfaction. We propose a flow-matching model with a diffusion transformer (DiT) augmented with permutation invariant robot position and map encoders as the generative model. We develop a custom solver for our SF and equip it with a neural network that predicts context-specific initialization. The initialization network is trained in a self-supervised manner, taking advantage of the differentiability of the SF solver. We advance the state-of-the-art in the following respects. First, we show that we can generate trajectories of tens of robots in cluttered environments in a few tens of milliseconds. This is several times faster than existing centralized optimization approaches. Moreover, our approach also generates smoother trajectories orders of magnitude faster than competing baselines based on diffusion models. Second, each component of our approach can be batched, allowing us to solve a few tens of problem instances in a fraction of a second. We believe this is a first such result; no existing approach provides such capabilities. Finally, our approach can generate a diverse set of trajectories between a given set of start and goal locations, which can capture different collision-avoidance behaviors. 

**Abstract (ZH)**: 基于流匹配的学习方法Flow-Opt在多机器人联合空间中的集中轨迹优化计算可逾性改进 

---
# Decentralized Multi-Robot Relative Navigation in Unknown, Structurally Constrained Environments under Limited Communication 

**Title (ZH)**: 未知且结构受限环境中受限通信条件下分散式多机器人相对导航 

**Authors**: Zihao Mao, Yunheng Wang, Yunting Ji, Yi Yang, Wenjie Song  

**Link**: [PDF](https://arxiv.org/pdf/2510.09188)  

**Abstract**: Multi-robot navigation in unknown, structurally constrained, and GPS-denied environments presents a fundamental trade-off between global strategic foresight and local tactical agility, particularly under limited communication. Centralized methods achieve global optimality but suffer from high communication overhead, while distributed methods are efficient but lack the broader awareness to avoid deadlocks and topological traps. To address this, we propose a fully decentralized, hierarchical relative navigation framework that achieves both strategic foresight and tactical agility without a unified coordinate system. At the strategic layer, robots build and exchange lightweight topological maps upon opportunistic encounters. This process fosters an emergent global awareness, enabling the planning of efficient, trap-avoiding routes at an abstract level. This high-level plan then inspires the tactical layer, which operates on local metric information. Here, a sampling-based escape point strategy resolves dense spatio-temporal conflicts by generating dynamically feasible trajectories in real time, concurrently satisfying tight environmental and kinodynamic constraints. Extensive simulations and real-world experiments demonstrate that our system significantly outperforms in success rate and efficiency, especially in communication-limited environments with complex topological structures. 

**Abstract (ZH)**: 多机器人在未知、结构受限且GPS受限环境中的导航面临全局战略预见性和局部战术敏捷性之间的基本权衡，尤其是在通信受限的情况下。集中式方法能够实现全局最优但通信开销高，而分布式方法虽然高效但缺乏整体感知能力以避免死锁和拓扑陷阱。为了解决这一问题，我们提出了一种完全分散的分层相对导航框架，能够在无统一坐标系的情况下实现战略预见性和战术敏捷性。在战略层面上，机器人通过机会性邂逅构建并交换轻量级拓扑地图，这一过程促进了全局意识的涌现，使机器人能够在抽象层面规划高效的、避开陷阱的路线。该高层计划随后启发战术层，后者基于局部度量信息操作。在战术层面上，基于采样的逃逸点策略通过实时生成动态可行轨迹解决了密集的空间时间冲突，同时满足严格的环境和动力学约束。大量仿真和实际实验表明，我们的系统在成功率和效率方面显著优于现有方法，特别是在通信受限且拓扑结构复杂的环境中。 

---
# When a Robot is More Capable than a Human: Learning from Constrained Demonstrators 

**Title (ZH)**: 当机器人能力超过人类：从受约束的示范者学习 

**Authors**: Xinhu Li, Ayush Jain, Zhaojing Yang, Yigit Korkmaz, Erdem Bıyık  

**Link**: [PDF](https://arxiv.org/pdf/2510.09096)  

**Abstract**: Learning from demonstrations enables experts to teach robots complex tasks using interfaces such as kinesthetic teaching, joystick control, and sim-to-real transfer. However, these interfaces often constrain the expert's ability to demonstrate optimal behavior due to indirect control, setup restrictions, and hardware safety. For example, a joystick can move a robotic arm only in a 2D plane, even though the robot operates in a higher-dimensional space. As a result, the demonstrations collected by constrained experts lead to suboptimal performance of the learned policies. This raises a key question: Can a robot learn a better policy than the one demonstrated by a constrained expert? We address this by allowing the agent to go beyond direct imitation of expert actions and explore shorter and more efficient trajectories. We use the demonstrations to infer a state-only reward signal that measures task progress, and self-label reward for unknown states using temporal interpolation. Our approach outperforms common imitation learning in both sample efficiency and task completion time. On a real WidowX robotic arm, it completes the task in 12 seconds, 10x faster than behavioral cloning, as shown in real-robot videos on this https URL . 

**Abstract (ZH)**: 基于演示学习使专家能够使用力示教、手柄控制和仿真实验到真实世界的转移等接口来教机器人执行复杂的任务。然而，这些接口往往因间接控制、设置限制和硬件安全等因素而限制了专家展示最优行为的能力。例如，手柄只能在二维平面上移动机械臂，尽管机器人在更高维度的空间中操作。因此，受限专家收集的演示导致学习到的策略表现不佳。这提出了一个关键问题：机器人能否比受限专家展示的策略表现更好？我们通过允许代理超越直接模仿专家动作并探索更短更高效的轨迹来解决这个问题。我们使用演示数据推断仅基于状态的奖励信号以衡量任务进度，并使用时间插值对未知状态进行自我标注奖励。我们的方法在样本效率和任务完成时间方面都优于常见的模仿学习。在一个实际的WidowX机械臂上，它仅用12秒就完成了任务，比行为克隆快10倍，如在该网址提供的实际机器人视频中所展示。 

---
# Robust Visual Teach-and-Repeat Navigation with Flexible Topo-metric Graph Map Representation 

**Title (ZH)**: 鲁棒的视觉指导重复导航与灵活的拓扑-度量图测绘表示 

**Authors**: Jikai Wang, Yunqi Cheng, Kezhi Wang, Zonghai Chen  

**Link**: [PDF](https://arxiv.org/pdf/2510.09089)  

**Abstract**: Visual Teach-and-Repeat Navigation is a direct solution for mobile robot to be deployed in unknown environments. However, robust trajectory repeat navigation still remains challenged due to environmental changing and dynamic objects. In this paper, we propose a novel visual teach-and-repeat navigation system, which consists of a flexible map representation, robust map matching and a map-less local navigation module. During the teaching process, the recorded keyframes are formulated as a topo-metric graph and each node can be further extended to save new observations. Such representation also alleviates the requirement of globally consistent mapping. To enhance the place recognition performance during repeating process, instead of using frame-to-frame matching, we firstly implement keyframe clustering to aggregate similar connected keyframes into local map and perform place recognition based on visual frame-tolocal map matching strategy. To promote the local goal persistent tracking performance, a long-term goal management algorithm is constructed, which can avoid the robot getting lost due to environmental changes or obstacle occlusion. To achieve the goal without map, a local trajectory-control candidate optimization algorithm is proposed. Extensively experiments are conducted on our mobile platform. The results demonstrate that our system is superior to the baselines in terms of robustness and effectiveness. 

**Abstract (ZH)**: 视觉教学与重复导航是一种直接解决方案，用于在未知环境中部署移动机器人。然而，由于环境变化和动态物体的存在，稳健的轨迹重复导航仍面临挑战。本文提出了一种新颖的视觉教学与重复导航系统，该系统由灵活的地图表示、稳健的地图匹配和无地图的局部导航模块组成。在教学过程中，记录的关键帧被形式化为拓扑图，每个节点可以进一步扩展以保存新观测值。这种表示也有助于减轻全局一致映射的需求。为了在重复过程中增强位置识别性能，我们首先实现关键帧聚类，将相似的关键帧聚合成局部地图，并基于视觉帧与局部地图匹配策略进行位置识别。为了促进局部目标持久跟踪性能，构建了一个长期目标管理算法，该算法可以避免由于环境变化或障碍物遮挡导致的机器人迷路。为了在无地图的情况下实现目标，提出了一种局部轨迹控制候选优化算法。在我们移动平台上进行了广泛实验。结果表明，我们的系统在稳健性和有效性方面优于基线系统。 

---
# Training Models to Detect Successive Robot Errors from Human Reactions 

**Title (ZH)**: 训练模型从人类反应中检测机器人连续错误 

**Authors**: Shannon Liu, Maria Teresa Parreira, Wendy Ju  

**Link**: [PDF](https://arxiv.org/pdf/2510.09080)  

**Abstract**: As robots become more integrated into society, detecting robot errors is essential for effective human-robot interaction (HRI). When a robot fails repeatedly, how can it know when to change its behavior? Humans naturally respond to robot errors through verbal and nonverbal cues that intensify over successive failures-from confusion and subtle speech changes to visible frustration and impatience. While prior work shows that human reactions can indicate robot failures, few studies examine how these evolving responses reveal successive failures. This research uses machine learning to recognize stages of robot failure from human reactions. In a study with 26 participants interacting with a robot that made repeated conversational errors, behavioral features were extracted from video data to train models for individual users. The best model achieved 93.5% accuracy for detecting errors and 84.1% for classifying successive failures. Modeling the progression of human reactions enhances error detection and understanding of repeated interaction breakdowns in HRI. 

**Abstract (ZH)**: 随着机器人在社会中的集成程度越来越高，检测机器人错误对于有效的机器人-人类交互（HRI）至关重要。当机器人反复失败时，它如何知道何时改变其行为？人类通过口头和非口头的反应自然地响应机器人的错误，这些反应在连续失败中逐渐增强——从困惑和微妙的语言变化到可见的烦躁和不耐烦。虽然以往的研究表明人类的反应可以指示机器人失败，但很少有研究探讨这些不断变化的反应如何揭示连续失败。本研究使用机器学习从人类反应中识别机器人失败的阶段。在一项涉及26名参与者与一个反复犯对话错误机器人的交互研究中，从视频数据中提取行为特征，为个体用户训练模型。最佳模型在检测错误方面达到了93.5%的准确率，在分类连续失败方面达到了84.1%的准确率。建模人类反应的演变过程提高了错误检测能力，并有助于理解HRI中反复交互中断的机制。 

---
# iMoWM: Taming Interactive Multi-Modal World Model for Robotic Manipulation 

**Title (ZH)**: iMoWM: 控制交互多模态世界模型以实现机器人操纵 

**Authors**: Chuanrui Zhang, Zhengxian Wu, Guanxing Lu, Yansong Tang, Ziwei Wang  

**Link**: [PDF](https://arxiv.org/pdf/2510.09036)  

**Abstract**: Learned world models hold significant potential for robotic manipulation, as they can serve as simulator for real-world interactions. While extensive progress has been made in 2D video-based world models, these approaches often lack geometric and spatial reasoning, which is essential for capturing the physical structure of the 3D world. To address this limitation, we introduce iMoWM, a novel interactive world model designed to generate color images, depth maps, and robot arm masks in an autoregressive manner conditioned on actions. To overcome the high computational cost associated with three-dimensional information, we propose MMTokenizer, which unifies multi-modal inputs into a compact token representation. This design enables iMoWM to leverage large-scale pretrained VideoGPT models while maintaining high efficiency and incorporating richer physical information. With its multi-modal representation, iMoWM not only improves the visual quality of future predictions but also serves as an effective simulator for model-based reinforcement learning (MBRL) and facilitates real-world imitation learning. Extensive experiments demonstrate the superiority of iMoWM across these tasks, showcasing the advantages of multi-modal world modeling for robotic manipulation. Homepage: this https URL 

**Abstract (ZH)**: Learned 世界模型在机器人操作中具有巨大潜力，因为它们可以作为现实世界交互的模拟器。虽然基于2D视频的世界模型取得了广泛进展，但这些方法往往缺乏几何和空间推理，这对于捕捉三维世界的物理结构至关重要。为了解决这一局限，我们引入了iMoWM，这是一种新颖的交互式世界模型，设计用于在动作条件下自回归生成彩色图像、深度图和机器人臂掩码。为了克服与三维信息相关的高计算成本，我们提出了MMTokenizer，将多模态输入统一为紧凑的token表示。这种设计使得iMoWM能够利用大规模预训练的VideoGPT模型，同时保持高效并引入更丰富的物理信息。凭借其多模态表示，iMoWM不仅提高了未来预测的视觉质量，还作为基于模型的强化学习（MBRL）的有效模拟器，并促进了现实世界的模仿学习。广泛的经验表明，iMoWM在这些任务中的优越性，展示了多模态世界建模在机器人操作中的优势。 Homepage: 这个=https://nitro共和国论文地址 

---
# Trust Modeling and Estimation in Human-Autonomy Interactions 

**Title (ZH)**: 人类自主系统交互中的信任建模与估计 

**Authors**: Daniel A. Williams, Airlie Chapman, Daniel R. Little, Chris Manzie  

**Link**: [PDF](https://arxiv.org/pdf/2510.09013)  

**Abstract**: Advances in the control of autonomous systems have accompanied an expansion in the potential applications for autonomous robotic systems. The success of applications involving humans depends on the quality of interaction between the autonomous system and the human supervisor, which is particularly affected by the degree of trust that the supervisor places in the autonomous system. Absent from the literature are models of supervisor trust dynamics that can accommodate asymmetric responses to autonomous system performance and the intermittent nature of supervisor-autonomous system communication. This paper focuses on formulating an estimated model of supervisor trust that incorporates both of these features by employing a switched linear system structure with event-triggered sampling of the model input and output. Trust response data collected in a user study with 51 participants were then used identify parameters for a switched linear model-based observer of supervisor trust. 

**Abstract (ZH)**: 自主系统的控制进展伴随着自主机器人系统潜在应用领域的扩展。人类参与的应用成功取决于自主系统与人类监督者之间互动的质量，这尤其受到监督者对自主系统信任程度的影响。文献中缺乏可以包容自主系统性能不对称响应以及监督者-自主系统通信间歇性的监督者信任动态模型。本文关注通过采用切换线性系统结构和事件触发的模型输入输出采样来构建一个同时包含这两个特征的监督者信任估计模型。随后使用包含51名参与者的研究采集的信任响应数据来识别基于切换线性模型的监督者信任观测器的参数。 

---
# A geometrical approach to solve the proximity of a point to an axisymmetric quadric in space 

**Title (ZH)**: 空间中点到轴对称二次曲面邻近性的几何求解方法 

**Authors**: Bibekananda Patra, Aditya Mahesh Kolte, Sandipan Bandyopadhyay  

**Link**: [PDF](https://arxiv.org/pdf/2510.08973)  

**Abstract**: This paper presents the classification of a general quadric into an axisymmetric quadric (AQ) and the solution to the problem of the proximity of a given point to an AQ. The problem of proximity in $R^3$ is reduced to the same in $R^2$, which is not found in the literature. A new method to solve the problem in $R^2$ is used based on the geometrical properties of the conics, such as sub-normal, length of the semi-major axis, eccentricity, slope and radius. Furthermore, the problem in $R^2$ is categorised into two and three more sub-cases for parabola and ellipse/hyperbola, respectively, depending on the location of the point, which is a novel approach as per the authors' knowledge. The proposed method is suitable for implementation in a common programming language, such as C and proved to be faster than a commercial library, namely, Bullet. 

**Abstract (ZH)**: 本文将一般二次曲线分类为轴对称二次曲线（AQ），并解决了给定点到AQ的接近性问题。将三维空间中的接近性问题归约到二维空间，这是文献中未见的方法。基于几何性质（如次正常高、半长轴长度、离心率、斜率和半径）提出了一种二维空间中问题的新型求解方法。此外，根据不同点的位置，将二维问题进一步细分为两类三个子问题，这是作者所知的首创方法。所提出的方法适用于C等通用编程语言的实现，并且比商用库（如Bullet）更快。 

---
# Direct Data-Driven Predictive Control for a Three-dimensional Cable-Driven Soft Robotic Arm 

**Title (ZH)**: 直接数据驱动预测控制 for 三维缆索驱动软机器人臂 

**Authors**: Cheng Ouyang, Moeen Ul Islam, Dong Chen, Kaixiang Zhang, Zhaojian Li, Xiaobo Tan  

**Link**: [PDF](https://arxiv.org/pdf/2510.08953)  

**Abstract**: Soft robots offer significant advantages in safety and adaptability, yet achieving precise and dynamic control remains a major challenge due to their inherently complex and nonlinear dynamics. Recently, Data-enabled Predictive Control (DeePC) has emerged as a promising model-free approach that bypasses explicit system identification by directly leveraging input-output data. While DeePC has shown success in other domains, its application to soft robots remains underexplored, particularly for three-dimensional (3D) soft robotic systems. This paper addresses this gap by developing and experimentally validating an effective DeePC framework on a 3D, cable-driven soft arm. Specifically, we design and fabricate a soft robotic arm with a thick tubing backbone for stability, a dense silicone body with large cavities for strength and flexibility, and rigid endcaps for secure termination. Using this platform, we implement DeePC with singular value decomposition (SVD)-based dimension reduction for two key control tasks: fixed-point regulation and trajectory tracking in 3D space. Comparative experiments with a baseline model-based controller demonstrate DeePC's superior accuracy, robustness, and adaptability, highlighting its potential as a practical solution for dynamic control of soft robots. 

**Abstract (ZH)**: 软体机器人在安全性和适应性方面提供了显著优势，但由于其固有的复杂非线性动力学，实现精确和动态控制仍是一项重大挑战。最近，数据驱动预测控制（DeePC）作为一种无需进行显式系统辨识的有希望的方法，通过直接利用输入输出数据得到了发展。尽管DeePC在其他领域已显示出成功，但其在软体机器人中的应用仍待探索，尤其是在三维（3D）软体机器人系统中。本文通过在3D线缆驱动软臂平台上开发并实验证实了有效的DeePC框架，解决了这一问题。具体来说，我们设计并制作了一款具有稳定性的厚管骨架、具有强大柔性的多腔硅胶体和安全终接的刚性端帽的软体机器人手臂。利用该平台，我们实现了基于奇异值分解（SVD）的降维DeePC，用于两个关键控制任务：定点调节和三维空间中的轨迹跟踪。与基于模型的基线控制器的对比实验表明，DeePC在精确性、鲁棒性和适应性方面均有优越表现，突显了其作为软体机器人动态控制实用解决方案的潜力。 

---
# Model-Based Lookahead Reinforcement Learning for in-hand manipulation 

**Title (ZH)**: 基于模型的前瞻强化学习在手内操作 

**Authors**: Alexandre Lopes, Catarina Barata, Plinio Moreno  

**Link**: [PDF](https://arxiv.org/pdf/2510.08884)  

**Abstract**: In-Hand Manipulation, as many other dexterous tasks, remains a difficult challenge in robotics by combining complex dynamic systems with the capability to control and manoeuvre various objects using its actuators. This work presents the application of a previously developed hybrid Reinforcement Learning (RL) Framework to In-Hand Manipulation task, verifying that it is capable of improving the performance of the task. The model combines concepts of both Model-Free and Model-Based Reinforcement Learning, by guiding a trained policy with the help of a dynamic model and value-function through trajectory evaluation, as done in Model Predictive Control. This work evaluates the performance of the model by comparing it with the policy that will be guided. To fully explore this, various tests are performed using both fully-actuated and under-actuated simulated robotic hands to manipulate different objects for a given task. The performance of the model will also be tested for generalization tests, by changing the properties of the objects in which both the policy and dynamic model were trained, such as density and size, and additionally by guiding a trained policy in a certain object to perform the same task in a different one. The results of this work show that, given a policy with high average reward and an accurate dynamic model, the hybrid framework improves the performance of in-hand manipulation tasks for most test cases, even when the object properties are changed. However, this improvement comes at the expense of increasing the computational cost, due to the complexity of trajectory evaluation. 

**Abstract (ZH)**: 手持操作：一种结合混合强化学习框架的复杂动态系统方法以提高操作性能 

---
# Online IMU-odometer Calibration using GNSS Measurements for Autonomous Ground Vehicle Localization 

**Title (ZH)**: 基于GNSS测测量的在线IMU-里程计标定方法及其在自主地面车辆定位中的应用 

**Authors**: Baoshan Song, Xiao Xia, Penggao Yan, Yihan Zhong, Weisong Wen, Li-Ta Hsu  

**Link**: [PDF](https://arxiv.org/pdf/2510.08880)  

**Abstract**: Accurate calibration of intrinsic (odometer scaling factors) and extrinsic parameters (IMU-odometer translation and rotation) is essential for autonomous ground vehicle localization. Existing GNSS-aided approaches often rely on positioning results or raw measurements without ambiguity resolution, and their observability properties remain underexplored. This paper proposes a tightly coupled online calibration method that fuses IMU, odometer, and raw GNSS measurements (pseudo-range, carrier-phase, and Doppler) within an extendable factor graph optimization (FGO) framework, incorporating outlier mitigation and ambiguity resolution. Observability analysis reveals that two horizontal translation and three rotation parameters are observable under general motion, while vertical translation remains unobservable. Simulation and real-world experiments demonstrate superior calibration and localization performance over state-of-the-art loosely coupled methods. Specifically, the IMU-odometer positioning using our calibrated parameters achieves the absolute maximum error of 17.75 m while the one of LC method is 61.51 m, achieving up to 71.14 percent improvement. To foster further research, we also release the first open-source dataset that combines IMU, 2D odometer, and raw GNSS measurements from both rover and base stations. 

**Abstract (ZH)**: 精确校准固有参数（里程计缩放因子）和外在参数（IMU-里程计平移和旋转）对于自主地面车辆定位至关重要。现有基于GNSS辅助的方法往往依赖于定位结果或原始测量值而缺乏模糊性解析，其可观测性特性尚未充分探索。本文提出了一种紧耦合的在线校准方法，将IMU、里程计和原始GNSS测量（伪距离、载波相位和多普勒）融合在可扩展的因子图优化（FGO）框架内，同时整合了离群值剔除和模糊性解析。可观测性分析表明，在一般运动情况下，可以观测到两个水平平移和三个旋转参数，而垂直平移参数不可观测。仿真和现实世界实验表明，与最先进的松耦合方法相比，该校准方法和定位性能更优秀。具体而言，使用校准参数的IMU-里程计定位的绝对最大误差为17.75米，而松耦合方法（LC方法）的误差为61.51米，提高了71.14%。为促进进一步研究，我们还发布了第一个综合IMU、2D里程计和原始GNSS测量数据的开源数据集，数据来自移动站和基准站。 

---
# CDE: Concept-Driven Exploration for Reinforcement Learning 

**Title (ZH)**: 概念驱动的探索在强化学习中的应用 

**Authors**: Le Mao, Andrew H. Liu, Renos Zabounidis, Zachary Kingston, Joseph Campbell  

**Link**: [PDF](https://arxiv.org/pdf/2510.08851)  

**Abstract**: Intelligent exploration remains a critical challenge in reinforcement learning (RL), especially in visual control tasks. Unlike low-dimensional state-based RL, visual RL must extract task-relevant structure from raw pixels, making exploration inefficient. We propose Concept-Driven Exploration (CDE), which leverages a pre-trained vision-language model (VLM) to generate object-centric visual concepts from textual task descriptions as weak, potentially noisy supervisory signals. Rather than directly conditioning on these noisy signals, CDE trains a policy to reconstruct the concepts via an auxiliary objective, using reconstruction accuracy as an intrinsic reward to guide exploration toward task-relevant objects. Because the policy internalizes these concepts, VLM queries are only needed during training, reducing dependence on external models during deployment. Across five challenging simulated visual manipulation tasks, CDE achieves efficient, targeted exploration and remains robust to noisy VLM predictions. Finally, we demonstrate real-world transfer by deploying CDE on a Franka Research 3 arm, attaining an 80\% success rate in a real-world manipulation task. 

**Abstract (ZH)**: 智能探索仍是强化学习（RL）中的一个关键挑战，特别是在视觉控制任务中。与基于低维状态的RL不同，视觉RL必须从原始像素中提取相关的任务结构，导致探索效率低下。我们提出了一种概念驱动的探索（CDE），该方法利用预训练的视觉-语言模型（VLM）生成以对象为中心的视觉概念，作为弱的、可能含噪声的监督信号。CDE不直接依赖这些噪声信号，而是训练一个策略通过辅助目标重建这些概念，使用重建准确性作为内在奖励，指导探索向相关任务对象靠拢。由于策略内化了这些概念，在部署时仅需使用VLM查询，减少了对外部模型的依赖。在五个具有挑战性的模拟视觉操作任务中，CDE实现了高效的、有针对性的探索，并且对于含噪声的VLM预测具有鲁棒性。最后，我们通过在Franka Research 3臂上部署CDE展示了实际应用的迁移能力，实现了80%的成功率。 

---
# Adaptive Science Operations in Deep Space Missions Using Offline Belief State Planning 

**Title (ZH)**: 深空任务中基于离线信念状态规划的自适应科学操作 

**Authors**: Grace Ra Kim, Hailey Warner, Duncan Eddy, Evan Astle, Zachary Booth, Edward Balaban, Mykel J. Kochenderfer  

**Link**: [PDF](https://arxiv.org/pdf/2510.08812)  

**Abstract**: Deep space missions face extreme communication delays and environmental uncertainty that prevent real-time ground operations. To support autonomous science operations in communication-constrained environments, we present a partially observable Markov decision process (POMDP) framework that adaptively sequences spacecraft science instruments. We integrate a Bayesian network into the POMDP observation space to manage the high-dimensional and uncertain measurements typical of astrobiology missions. This network compactly encodes dependencies among measurements and improves the interpretability and computational tractability of science data. Instrument operation policies are computed offline, allowing resource-aware plans to be generated and thoroughly validated prior to launch. We use the Enceladus Orbilander's proposed Life Detection Suite (LDS) as a case study, demonstrating how Bayesian network structure and reward shaping influence system performance. We compare our method against the mission's baseline Concept of Operations (ConOps), evaluating both misclassification rates and performance in off-nominal sample accumulation scenarios. Our approach reduces sample identification errors by nearly 40% 

**Abstract (ZH)**: 深空任务面临的通信延迟极长和环境不确定性阻碍了实时地面操作。为支持通信约束环境下自主科学操作，我们提出了一种部分可观测马尔可夫决策过程（POMDP）框架，用于适配性地序列化航天器科学仪器。我们将贝叶斯网络集成到POMDP观测空间中，以管理天体生物学任务中常见的高维和不确定测量。该网络紧凑地编码了测量之间的依赖关系，提高了科学数据的可解释性和计算可行性。仪器操作策略在离线计算，使得在发射前能够生成并彻底验证资源意识强的计划。我们以恩克拉多斯轨道着陆器提议的生命检测套件（LDS）为例，展示了贝叶斯网络结构和奖励塑造如何影响系统性能。我们将我们的方法与任务的基础概念操作（ConOps）进行比较，评估了分类错误率和异常样本收集场景下的性能。我们的方法将样本识别错误降低了近40%。 

---
# Adaptive Motion Planning via Contact-Based Intent Inference for Human-Robot Collaboration 

**Title (ZH)**: 基于接触意图推断的人机协作自适应运动规划 

**Authors**: Jiurun Song, Xiao Liang, Minghui Zheng  

**Link**: [PDF](https://arxiv.org/pdf/2510.08811)  

**Abstract**: Human-robot collaboration (HRC) requires robots to adapt their motions to human intent to ensure safe and efficient cooperation in shared spaces. Although large language models (LLMs) provide high-level reasoning for inferring human intent, their application to reliable motion planning in HRC remains challenging. Physical human-robot interaction (pHRI) is intuitive but often relies on continuous kinesthetic guidance, which imposes burdens on operators. To address these challenges, a contact-informed adaptive motion-planning framework is introduced to infer human intent directly from physical contact and employ the inferred intent for online motion correction in HRC. First, an optimization-based force estimation method is proposed to infer human-intended contact forces and locations from joint torque measurements and a robot dynamics model, thereby reducing cost and installation complexity while enabling whole-body sensitivity. Then, a torque-based contact detection mechanism with link-level localization is introduced to reduce the optimization search space and to enable real-time estimation. Subsequently, a contact-informed adaptive motion planner is developed to infer human intent from contacts and to replan robot motion online, while maintaining smoothness and adapting to human corrections. Finally, experiments on a 7-DOF manipulator are conducted to demonstrate the accuracy of the proposed force estimation method and the effectiveness of the contact-informed adaptive motion planner under perception uncertainty in HRC. 

**Abstract (ZH)**: Human-机器人协作中的接触导向自适应运动规划框架 

---
# Humanoid Everyday: A Comprehensive Robotic Dataset for Open-World Humanoid Manipulation 

**Title (ZH)**: 仿人日常：开放世界仿人操作的综合机器人数据集 

**Authors**: Zhenyu Zhao, Hongyi Jing, Xiawei Liu, Jiageng Mao, Abha Jha, Hanwen Yang, Rong Xue, Sergey Zakharor, Vitor Guizilini, Yue Wang  

**Link**: [PDF](https://arxiv.org/pdf/2510.08807)  

**Abstract**: From loco-motion to dextrous manipulation, humanoid robots have made remarkable strides in demonstrating complex full-body capabilities. However, the majority of current robot learning datasets and benchmarks mainly focus on stationary robot arms, and the few existing humanoid datasets are either confined to fixed environments or limited in task diversity, often lacking human-humanoid interaction and lower-body locomotion. Moreover, there are a few standardized evaluation platforms for benchmarking learning-based policies on humanoid data. In this work, we present Humanoid Everyday, a large-scale and diverse humanoid manipulation dataset characterized by extensive task variety involving dextrous object manipulation, human-humanoid interaction, locomotion-integrated actions, and more. Leveraging a highly efficient human-supervised teleoperation pipeline, Humanoid Everyday aggregates high-quality multimodal sensory data, including RGB, depth, LiDAR, and tactile inputs, together with natural language annotations, comprising 10.3k trajectories and over 3 million frames of data across 260 tasks across 7 broad categories. In addition, we conduct an analysis of representative policy learning methods on our dataset, providing insights into their strengths and limitations across different task categories. For standardized evaluation, we introduce a cloud-based evaluation platform that allows researchers to seamlessly deploy their policies in our controlled setting and receive performance feedback. By releasing Humanoid Everyday along with our policy learning analysis and a standardized cloud-based evaluation platform, we intend to advance research in general-purpose humanoid manipulation and lay the groundwork for more capable and embodied robotic agents in real-world scenarios. Our dataset, data collection code, and cloud evaluation website are made publicly available on our project website. 

**Abstract (ZH)**: 从移动到灵巧操作，人类形机器人在展示全身复杂能力方面取得了显著进展。然而，当前大多数机器人学习数据集和基准主要集中在静止的机器人手臂上，现有的少数人类形机器人数据集要么局限于固定环境，要么在任务多样性方面受限，往往缺乏人-机器人交互和下肢移动。此外，尚缺乏标准化的评估平台用于在人类形机器人数据上benchmark基于学习的策略。本工作中，我们提出Humanoid Everyday，这是一个大规模且多样化的灵巧操作人形机器人数据集，涵盖了广泛的多任务、灵巧物体操作、人-机器人交互、集成移动动作等。通过高效率的人工监督远程操作流水线，Humanoid Everyday集成了高质量的多模态感官数据，包括RGB、深度、LiDAR和触觉输入，以及自然语言注释，包含10300条轨迹和超过300万帧数据，覆盖7个广泛类别下的260个任务。此外，我们对代表性的策略学习方法在我们的数据集上的表现进行了分析，提供了不同任务类别下的强项和局限性的见解。为了实现标准化评估，我们引入了一个基于云的评估平台，研究人员可以无缝部署其策略并在我们的受控环境中进行测试，获取性能反馈。通过发布Humanoid Everyday数据集、策略学习分析以及标准化的基于云的评估平台，我们旨在推动通用型人形机器人操作研究，并为更擅长且具备身体性的机器人代理在真实场景中的应用奠定基础。我们的数据集、数据采集代码和基于云的评估网站已公开发布在我们的项目网站上。 

---
# Geometry-aware Policy Imitation 

**Title (ZH)**: 几何感知策略模仿 

**Authors**: Yiming Li, Nael Darwiche, Amirreza Razmjoo, Sichao Liu, Yilun Du, Auke Ijspeert, Sylvain Calinon  

**Link**: [PDF](https://arxiv.org/pdf/2510.08787)  

**Abstract**: We propose a Geometry-aware Policy Imitation (GPI) approach that rethinks imitation learning by treating demonstrations as geometric curves rather than collections of state-action samples. From these curves, GPI derives distance fields that give rise to two complementary control primitives: a progression flow that advances along expert trajectories and an attraction flow that corrects deviations. Their combination defines a controllable, non-parametric vector field that directly guides robot behavior. This formulation decouples metric learning from policy synthesis, enabling modular adaptation across low-dimensional robot states and high-dimensional perceptual inputs. GPI naturally supports multimodality by preserving distinct demonstrations as separate models and allows efficient composition of new demonstrations through simple additions to the distance field. We evaluate GPI in simulation and on real robots across diverse tasks. Experiments show that GPI achieves higher success rates than diffusion-based policies while running 20 times faster, requiring less memory, and remaining robust to perturbations. These results establish GPI as an efficient, interpretable, and scalable alternative to generative approaches for robotic imitation learning. Project website: this https URL 

**Abstract (ZH)**: 我们提出了一种几何感知策略模仿（GPI）方法，该方法重新思考模仿学习，将演示视为几何曲线而非状态-动作样本集合。从这些曲线上，GPI 导出了距离场，进而生成两种互补的控制原语：一种进展流用于沿专家轨迹推进，另一种吸引流用于纠正偏差。这两种流的结合定义了一个可控的、非参数化的向量场，可以直接引导机器人行为。此形式化方法将度量学习与策略合成脱钩，从而在低维机器人状态和高维感知输入之间实现模块化的适应。GPI 自然支持多模态性，通过保持不同演示为独立模型而得以实现，并可通过简单扩展距离场来进行新的演示高效组合。我们在仿真和真实机器人上对GPI进行了跨任务评估。实验表明，与基于扩散的方法相比，GPI 在成功率为后者 20 倍的同时，运行速度更快、所需内存更少，并且对扰动具有更强的鲁棒性。这些结果确立了GPI作为一种高效、可解释和可扩展的机器人模仿学习替代方案的地位。项目网站：this https URL 

---
# Whole Body Model Predictive Control for Spin-Aware Quadrupedal Table Tennis 

**Title (ZH)**: 基于Spin感知的四足乒乓球全身模型预测控制 

**Authors**: David Nguyen, Zulfiqar Zaidi, Kevin Karol, Jessica Hodgins, Zhaoming Xie  

**Link**: [PDF](https://arxiv.org/pdf/2510.08754)  

**Abstract**: Developing table tennis robots that mirror human speed, accuracy, and ability to predict and respond to the full range of ball spins remains a significant challenge for legged robots. To demonstrate these capabilities we present a system to play dynamic table tennis for quadrupedal robots that integrates high speed perception, trajectory prediction, and agile control. Our system uses external cameras for high-speed ball localization, physical models with learned residuals to infer spin and predict trajectories, and a novel model predictive control (MPC) formulation for agile full-body control. Notably, a continuous set of stroke strategies emerge automatically from different ball return objectives using this control paradigm. We demonstrate our system in the real world on a Spot quadruped, evaluate accuracy of each system component, and exhibit coordination through the system's ability to aim and return balls with varying spin types. As a further demonstration, the system is able to rally with human players. 

**Abstract (ZH)**: 开发能够在速度、准确性和预测及应对全范围球 spin 方面媲美人手的乒乓球机器人仍是一项重大挑战，尤其是对于 legged 机器人。为了展示这些能力，我们提出了一种四足机器人进行动态乒乓球比赛的系统，该系统结合了高精度感知、轨迹预测和敏捷控制。我们的系统使用外部摄像头进行高速球定位，使用结合学习残差的物理模型来推断旋转并预测轨迹，并采用一种新型的模型预测控制（MPC）方法进行敏捷整体控制。值得注意的是，通过这种方法，一系列连续的击球策略能够自动从不同的回球目标中产生。我们在 Spot 四足机器人上展示了该系统，在每个系统组件的准确性评估中展示了协调能力，并通过系统能够根据不同的旋转类型击球和还击来展示协调能力。此外，该系统能够与人类玩家进行对打。 

---
# Point and Go: Intuitive Reference Frame Reallocation in Mode Switching for Assistive Robotics 

**Title (ZH)**: 点即移：辅助机器人模式切换中的直观参考坐标重分配 

**Authors**: A. Wang, C. Jiang, M. Przystupa, J. Valentine, M. Jagersand  

**Link**: [PDF](https://arxiv.org/pdf/2510.08753)  

**Abstract**: Operating high degree of freedom robots can be difficult for users of wheelchair mounted robotic manipulators. Mode switching in Cartesian space has several drawbacks such as unintuitive control reference frames, separate translation and orientation control, and limited movement capabilities that hinder performance. We propose Point and Go mode switching, which reallocates the Cartesian mode switching reference frames into a more intuitive action space comprised of new translation and rotation modes. We use a novel sweeping motion to point the gripper, which defines the new translation axis along the robot base frame's horizontal plane. This creates an intuitive `point and go' translation mode that allows the user to easily perform complex, human-like movements without switching control modes. The system's rotation mode combines position control with a refined end-effector oriented frame that provides precise and consistent robot actions in various end-effector poses. We verified its effectiveness through initial experiments, followed by a three-task user study that compared our method to Cartesian mode switching and a state of the art learning method. Results show that Point and Go mode switching reduced completion times by 31\%, pauses by 41\%, and mode switches by 33\%, while receiving significantly favorable responses in user surveys. 

**Abstract (ZH)**: 基于指定点动作的轮椅载 manipulator 高自由度机器人模式切换方法 

---
# ConPoSe: LLM-Guided Contact Point Selection for Scalable Cooperative Object Pushing 

**Title (ZH)**: ConPoSe: LLM引导的接触点选择用于可扩展的协作物体推送 

**Authors**: Noah Steinkrüger, Nisarga Nilavadi, Wolfram Burgard, Tanja Katharina Kaiser  

**Link**: [PDF](https://arxiv.org/pdf/2510.08705)  

**Abstract**: Object transportation in cluttered environments is a fundamental task in various domains, including domestic service and warehouse logistics. In cooperative object transport, multiple robots must coordinate to move objects that are too large for a single robot. One transport strategy is pushing, which only requires simple robots. However, careful selection of robot-object contact points is necessary to push the object along a preplanned path. Although this selection can be solved analytically, the solution space grows combinatorially with the number of robots and object size, limiting scalability. Inspired by how humans rely on common-sense reasoning for cooperative transport, we propose combining the reasoning capabilities of Large Language Models with local search to select suitable contact points. Our LLM-guided local search method for contact point selection, ConPoSe, successfully selects contact points for a variety of shapes, including cuboids, cylinders, and T-shapes. We demonstrate that ConPoSe scales better with the number of robots and object size than the analytical approach, and also outperforms pure LLM-based selection. 

**Abstract (ZH)**: 在杂乱环境中的物体运输是多个领域的一项基本任务，包括家庭服务和仓库物流。在协同物体运输中，多个机器人必须协调以移动单个机器人无法搬运的大型物体。一种运输策略是推力搬运，只需要简单的机器人即可，但选择机器人与物体的接触点时必须谨慎，以确保物体沿着预规划的路径移动。尽管这个问题可以通过分析解决，但随着机器人和物体尺寸的增加，解决方案空间会呈组合方式增长，限制了可扩展性。受人类如何依赖常识推理来进行协同运输的启发，我们提出结合大型语言模型的推理论能力和局部搜索来选择合适的接触点。我们的LLM引导的局部搜索方法ConPoSe成功地为各种形状，包括长方体、圆柱体和T形物体，选择了合适的接触点。我们证明，与纯分析方法相比，ConPoSe在机器人数量和物体尺寸增加时具有更好的可扩展性，并且也优于纯基于LLM的选择方法。 

---
# Differential Analysis of Pseudo Haptic Feedback: Novel Comparative Study of Visual and Auditory Cue Integration for Psychophysical Evaluation 

**Title (ZH)**: 伪触觉反馈的差异分析：视觉和听觉提示整合的新型比较研究用于心理物理评估 

**Authors**: Nishant Gautam, Somya Sharma, Peter Corcoran, Kaspar Althoefer  

**Link**: [PDF](https://arxiv.org/pdf/2510.09570)  

**Abstract**: Pseudo-haptics exploit carefully crafted visual or auditory cues to trick the brain into "feeling" forces that are never physically applied, offering a low-cost alternative to traditional haptic hardware. Here, we present a comparative psychophysical study that quantifies how visual and auditory stimuli combine to evoke pseudo-haptic pressure sensations on a commodity tablet. Using a Unity-based Rollball game, participants (n = 4) guided a virtual ball across three textured terrains while their finger forces were captured in real time with a Robotous RFT40 force-torque sensor. Each terrain was paired with a distinct rolling-sound profile spanning 440 Hz - 4.7 kHz, 440 Hz - 13.1 kHz, or 440 Hz - 8.9 kHz; crevice collisions triggered additional "knocking" bursts to heighten realism. Average tactile forces increased systematically with cue intensity: 0.40 N, 0.79 N and 0.88 N for visual-only trials and 0.41 N, 0.81 N and 0.90 N for audio-only trials on Terrains 1-3, respectively. Higher audio frequencies and denser visual textures both elicited stronger muscle activation, and their combination further reduced the force needed to perceive surface changes, confirming multisensory integration. These results demonstrate that consumer-grade isometric devices can reliably induce and measure graded pseudo-haptic feedback without specialized actuators, opening a path toward affordable rehabilitation tools, training simulators and assistive interfaces. 

**Abstract (ZH)**: 伪触觉利用精心设计的视觉或听觉提示欺骗大脑感受到从未实际施加的力，提供了一种传统触觉硬件的低成本替代方案。在此，我们进行了一项比较的心理物理研究，量化了视觉和听觉刺激如何在商用平板电脑上引发伪触觉压力感。通过一个基于Unity的Rollball游戏，参与者（n=4）引导虚拟球跨越三种不同的地形，同时使用Robotous RFT40力扭矩传感器实时捕捉手指力。每种地形配有一套独特的滚动声音谱，频率范围分别为440 Hz - 4.7 kHz、440 Hz - 13.1 kHz或440 Hz - 8.9 kHz；裂缝碰撞触发额外的“敲击”爆发以增强真实性。平均触觉力随提示强度系统增加：地形1-3的视觉仅试验分别为0.40 N、0.79 N和0.88 N，听觉仅试验分别为0.41 N、0.81 N和0.90 N。更高的音频频率和更密集的视觉纹理均引发了更强的肌肉激活，并且它们的结合进一步减少了感知表面变化所需的力，证实了多感官整合。研究结果表明，消费级等向性设备在没有专用执行器的情况下可以可靠地诱导和测量分级的伪触觉反馈，为经济实惠的康复工具、培训模拟器和辅助界面提供了途径。 

---
# Toggling stiffness via multistability 

**Title (ZH)**: 多稳态实现切换刚度 

**Authors**: Hugo de Souza Oliveira, Michele Curatolo, Renate Sachse, Edoardo Milana  

**Link**: [PDF](https://arxiv.org/pdf/2510.09511)  

**Abstract**: Mechanical metamaterials enable unconventional and programmable mechanical responses through structural design rather than material composition. In this work, we introduce a multistable mechanical metamaterial that exhibits a toggleable stiffness effect, where the effective shear stiffness switches discretely between stable configurations. The mechanical analysis of surrogate beam models of the unit cell reveal that this behavior originates from the rotation transmitted by the support beams to the curved beam, which governs the balance between bending and axial deformation. The stiffness ratio between the two states of the unit cell can be tuned by varying the slenderness of the support beams or by incorporating localized hinges that modulate rotational transfer. Experiments on 3D-printed prototypes validate the numerical predictions, confirming consistent stiffness toggling across different geometries. Finally, we demonstrate a monolithic soft clutch that leverages this effect to achieve programmable, stepwise stiffness modulation. This work establishes a design strategy for toggleable stiffness using multistable metamaterials, paving the way for adaptive, lightweight, and autonomous systems in soft robotics and smart structures. 

**Abstract (ZH)**: 机械 metamaterials 通过结构设计而非材料组成实现非传统和可编程的机械响应。在本工作中，我们介绍了一种多稳定机械 metamaterial，其表现出可切换的刚度效果，其中有效剪切刚度在稳定配置之间离散切换。单元结构的代理梁模型的机械分析表明，这种行为源于支撑梁传递给曲梁的旋转，这决定了弯曲变形和轴向变形之间的平衡。通过改变支撑梁的细长比或引入局部铰链来调节旋转传递，可以调整单元的刚度比。3D 打印原型实验验证了数值预测，确认了不同几何结构中的刚度切换一致性。最后，我们展示了利用此效应实现可编程步进刚度调节的单片软离合器。本工作确立了使用多稳定 metamaterial 实现可切换刚度的设计策略，为软机器人和智能结构的自适应、轻量化和自主系统开辟了道路。 

---
# PhysToolBench: Benchmarking Physical Tool Understanding for MLLMs 

**Title (ZH)**: PhysToolBench: 评估MLLMs 物理工具理解能力的基准测试 

**Authors**: Zixin Zhang, Kanghao Chen, Xingwang Lin, Lutao Jiang, Xu Zheng, Yuanhuiyi Lyu, Litao Guo, Yinchuan Li, Ying-Cong Chen  

**Link**: [PDF](https://arxiv.org/pdf/2510.09507)  

**Abstract**: The ability to use, understand, and create tools is a hallmark of human intelligence, enabling sophisticated interaction with the physical world. For any general-purpose intelligent agent to achieve true versatility, it must also master these fundamental skills. While modern Multimodal Large Language Models (MLLMs) leverage their extensive common knowledge for high-level planning in embodied AI and in downstream Vision-Language-Action (VLA) models, the extent of their true understanding of physical tools remains unquantified. To bridge this gap, we present PhysToolBench, the first benchmark dedicated to evaluating the comprehension of physical tools by MLLMs. Our benchmark is structured as a Visual Question Answering (VQA) dataset comprising over 1,000 image-text pairs. It assesses capabilities across three distinct difficulty levels: (1) Tool Recognition: Requiring the recognition of a tool's primary function. (2) Tool Understanding: Testing the ability to grasp the underlying principles of a tool's operation. (3) Tool Creation: Challenging the model to fashion a new tool from surrounding objects when conventional options are unavailable. Our comprehensive evaluation of 32 MLLMs-spanning proprietary, open-source, specialized embodied, and backbones in VLAs-reveals a significant deficiency in tool understanding. Furthermore, we provide an in-depth analysis and propose preliminary solutions. Code and dataset are publicly available. 

**Abstract (ZH)**: 物理工具理解基准： multimodal大型语言模型在物理工具理解上的评估 

---
# Scalable Multi-Agent Path Finding using Collision-Aware Dynamic Alert Mask and a Hybrid Execution Strategy 

**Title (ZH)**: 基于碰撞意识动态警示掩码和混合执行策略的可扩展多智能体路径规划 

**Authors**: Bharath Muppasani, Ritirupa Dey, Biplav Srivastava, Vignesh Narayanan  

**Link**: [PDF](https://arxiv.org/pdf/2510.09469)  

**Abstract**: Multi-agent pathfinding (MAPF) remains a critical problem in robotics and autonomous systems, where agents must navigate shared spaces efficiently while avoiding conflicts. Traditional centralized algorithms that have global information, such as Conflict-Based Search (CBS), provide high-quality solutions but become computationally expensive in large-scale scenarios due to the combinatorial explosion of conflicts that need resolution. Conversely, distributed approaches that have local information, particularly learning-based methods, offer better scalability by operating with relaxed information availability, yet often at the cost of solution quality. To address these limitations, we propose a hybrid framework that combines decentralized path planning with a lightweight centralized coordinator. Our framework leverages reinforcement learning (RL) for decentralized planning, enabling agents to adapt their planning based on minimal, targeted alerts--such as static conflict-cell flags or brief conflict tracks--that are dynamically shared information from the central coordinator for effective conflict resolution. We empirically study the effect of the information available to an agent on its planning performance. Our approach reduces the inter-agent information sharing compared to fully centralized and distributed methods, while still consistently finding feasible, collision-free solutions--even in large-scale scenarios having higher agent counts. 

**Abstract (ZH)**: 多智能体路径规划（MAPF）仍然是机器人技术和自主系统中的一个关键问题，其中智能体必须在共享空间中高效导航并避免冲突。传统的集中式算法虽然具有全局信息，如冲突基础搜索（CBS），能够提供高质量的解决方案，但在大型场景中因需要解决的冲突组合爆炸而变得计算耗费巨大。相反，特别是基于学习的方法，具有局部信息的分布式方法通过以较宽松的信息可用性来操作，提供了更好的扩展性，但往往以解决方案质量为代价。为了解决这些局限性，我们提出了一种结合去中心化路径规划和轻量级集中协调器的混合框架。该框架利用强化学习（RL）进行去中心化规划，使智能体可以根据集中协调器动态共享的最小化和针对性的警报（例如静态冲突单元标志或简短冲突轨迹）进行适应性规划，从而有效解决冲突。我们实证研究了可用信息对智能体规划性能的影响。与完全集中式和分布式方法相比，我们的方法减少了智能体之间的信息共享，但仍能一致地找到可行且无碰撞的解决方案，即使在智能体数量较多的大型场景中也是如此。 

---
# SilvaScenes: Tree Segmentation and Species Classification from Under-Canopy Images in Natural Forests 

**Title (ZH)**: SilvaScenes: 林下图像中自然森林树木分割与物种分类 

**Authors**: David-Alexandre Duclos, William Guimont-Martin, Gabriel Jeanson, Arthur Larochelle-Tremblay, Théo Defosse, Frédéric Moore, Philippe Nolet, François Pomerleau, Philippe Giguère  

**Link**: [PDF](https://arxiv.org/pdf/2510.09458)  

**Abstract**: Interest in robotics for forest management is growing, but perception in complex, natural environments remains a significant hurdle. Conditions such as heavy occlusion, variable lighting, and dense vegetation pose challenges to automated systems, which are essential for precision forestry, biodiversity monitoring, and the automation of forestry equipment. These tasks rely on advanced perceptual capabilities, such as detection and fine-grained species classification of individual trees. Yet, existing datasets are inadequate to develop such perception systems, as they often focus on urban settings or a limited number of species. To address this, we present SilvaScenes, a new dataset for instance segmentation of tree species from under-canopy images. Collected across five bioclimatic domains in Quebec, Canada, SilvaScenes features 1476 trees from 24 species with annotations from forestry experts. We demonstrate the relevance and challenging nature of our dataset by benchmarking modern deep learning approaches for instance segmentation. Our results show that, while tree segmentation is easy, with a top mean average precision (mAP) of 67.65%, species classification remains a significant challenge with an mAP of only 35.69%. Our dataset and source code will be available at this https URL. 

**Abstract (ZH)**: 机器人技术在森林管理中的兴趣正在增长，但复杂自然环境下的感知能力仍然是一个重大障碍。 

---
# Parametrized Topological Complexity for a Multi-Robot System with Variable Tasks 

**Title (ZH)**: 参数化拓扑复杂性在多机器人系统中的变量任务应用 

**Authors**: Gopal Chandra Dutta, Amit Kumar Paul, Subhankar Sau  

**Link**: [PDF](https://arxiv.org/pdf/2510.09323)  

**Abstract**: We study a generalized motion planning problem involving multiple autonomous robots navigating in a $d$-dimensional Euclidean space in the presence of a set of obstacles whose positions are unknown a priori. Each robot is required to visit sequentially a prescribed set of target states, with the number of targets varying between robots. This heterogeneous setting generalizes the framework considered in the prior works on sequential parametrized topological complexity by Farber and the second author of this article. To determine the topological complexity of our problem, we formulate it mathematically by constructing an appropriate fibration. Our main contribution is the determination of this invariant in the generalized setting, which captures the minimal algorithmic instability required for designing collision-free motion planning algorithms under parameter-dependent constraints. We provide a detailed analysis for both odd and even-dimensional ambient spaces, including the essential cohomological computations and explicit constructions of corresponding motion planning algorithms. 

**Abstract (ZH)**: 我们研究一个多自主机器人在未知位置障碍物的环境下，在$d$维欧几里得空间中依次访问给定目标状态的广义运动规划问题。每个机器人的目标状态数量可能不同。这种异构设置扩展了Farber和本文第二作者之前关于序列参数化拓扑复杂性的框架。为了确定我们问题的拓扑复杂性，我们通过构造适当纤维化将其数学化。本文的主要贡献是在广义设置下确定这一不变量，它捕捉了在参数依赖约束下设计无碰撞运动规划算法所需的最小算法不稳定度。我们对奇数维和偶数维环境空间进行了详细的分析，包括必要的上同调计算和相应的运动规划算法的显式构造。 

---
# Visual Anomaly Detection for Reliable Robotic Implantation of Flexible Microelectrode Array 

**Title (ZH)**: 柔性微电极阵列可靠植入的视觉异常检测 

**Authors**: Yitong Chen, Xinyao Xu, Ping Zhu, Xinyong Han, Fangbo Qin, Shan Yu  

**Link**: [PDF](https://arxiv.org/pdf/2510.09071)  

**Abstract**: Flexible microelectrode (FME) implantation into brain cortex is challenging due to the deformable fiber-like structure of FME probe and the interaction with critical bio-tissue. To ensure reliability and safety, the implantation process should be monitored carefully. This paper develops an image-based anomaly detection framework based on the microscopic cameras of the robotic FME implantation system. The unified framework is utilized at four checkpoints to check the micro-needle, FME probe, hooking result, and implantation point, respectively. Exploiting the existing object localization results, the aligned regions of interest (ROIs) are extracted from raw image and input to a pretrained vision transformer (ViT). Considering the task specifications, we propose a progressive granularity patch feature sampling method to address the sensitivity-tolerance trade-off issue at different locations. Moreover, we select a part of feature channels with higher signal-to-noise ratios from the raw general ViT features, to provide better descriptors for each specific scene. The effectiveness of the proposed methods is validated with the image datasets collected from our implantation system. 

**Abstract (ZH)**: 基于机器人柔性微电极植入系统微观摄像头的图像异常检测框架 

---
# Exploring Single Domain Generalization of LiDAR-based Semantic Segmentation under Imperfect Labels 

**Title (ZH)**: 基于LiDAR的语义分割在 imperfect 标签条件下的单域泛化探索 

**Authors**: Weitong Kong, Zichao Zeng, Di Wen, Jiale Wei, Kunyu Peng, June Moh Goo, Jan Boehm, Rainer Stiefelhagen  

**Link**: [PDF](https://arxiv.org/pdf/2510.09035)  

**Abstract**: Accurate perception is critical for vehicle safety, with LiDAR as a key enabler in autonomous driving. To ensure robust performance across environments, sensor types, and weather conditions without costly re-annotation, domain generalization in LiDAR-based 3D semantic segmentation is essential. However, LiDAR annotations are often noisy due to sensor imperfections, occlusions, and human errors. Such noise degrades segmentation accuracy and is further amplified under domain shifts, threatening system reliability. While noisy-label learning is well-studied in images, its extension to 3D LiDAR segmentation under domain generalization remains largely unexplored, as the sparse and irregular structure of point clouds limits direct use of 2D methods. To address this gap, we introduce the novel task Domain Generalization for LiDAR Semantic Segmentation under Noisy Labels (DGLSS-NL) and establish the first benchmark by adapting three representative noisy-label learning strategies from image classification to 3D segmentation. However, we find that existing noisy-label learning approaches adapt poorly to LiDAR data. We therefore propose DuNe, a dual-view framework with strong and weak branches that enforce feature-level consistency and apply cross-entropy loss based on confidence-aware filtering of predictions. Our approach shows state-of-the-art performance by achieving 56.86% mIoU on SemanticKITTI, 42.28% on nuScenes, and 52.58% on SemanticPOSS under 10% symmetric label noise, with an overall Arithmetic Mean (AM) of 49.57% and Harmonic Mean (HM) of 48.50%, thereby demonstrating robust domain generalization in DGLSS-NL tasks. The code is available on our project page. 

**Abstract (ZH)**: 基于LiDAR语义分割的噪声标签领域泛化任务（DGLSS-NL） 

---
# Detecting spills using thermal imaging, pretrained deep learning models, and a robotic platform 

**Title (ZH)**: 使用热成像、预训练深度学习模型和机器人平台检测泄漏 

**Authors**: Gregory Yeghiyan, Jurius Azar, Devson Butani, Chan-Jin Chung  

**Link**: [PDF](https://arxiv.org/pdf/2510.08770)  

**Abstract**: This paper presents a real-time spill detection system that utilizes pretrained deep learning models with RGB and thermal imaging to classify spill vs. no-spill scenarios across varied environments. Using a balanced binary dataset (4,000 images), our experiments demonstrate the advantages of thermal imaging in inference speed, accuracy, and model size. We achieve up to 100% accuracy using lightweight models like VGG19 and NasNetMobile, with thermal models performing faster and more robustly across different lighting conditions. Our system runs on consumer-grade hardware (RTX 4080) and achieves inference times as low as 44 ms with model sizes under 350 MB, highlighting its deployability in safety-critical contexts. Results from experiments with a real robot and test datasets indicate that a VGG19 model trained on thermal imaging performs best. 

**Abstract (ZH)**: 利用预训练深度学习模型和RGB及热成像实时检测泄漏的系统 

---
# Zero-Shot Policy Transfer in Reinforcement Learning using Buckingham's Pi Theorem 

**Title (ZH)**: 使用毕奥-萨伐尔定理在强化学习中实现零样本策略转移 

**Authors**: Francisco Pascoa, Ian Lalonde, Alexandre Girard  

**Link**: [PDF](https://arxiv.org/pdf/2510.08768)  

**Abstract**: Reinforcement learning (RL) policies often fail to generalize to new robots, tasks, or environments with different physical parameters, a challenge that limits their real-world applicability. This paper presents a simple, zero-shot transfer method based on Buckingham's Pi Theorem to address this limitation. The method adapts a pre-trained policy to new system contexts by scaling its inputs (observations) and outputs (actions) through a dimensionless space, requiring no retraining. The approach is evaluated against a naive transfer baseline across three environments of increasing complexity: a simulated pendulum, a physical pendulum for sim-to-real validation, and the high-dimensional HalfCheetah. Results demonstrate that the scaled transfer exhibits no loss of performance on dynamically similar contexts. Furthermore, on non-similar contexts, the scaled policy consistently outperforms the naive transfer, significantly expanding the volume of contexts where the original policy remains effective. These findings demonstrate that dimensional analysis provides a powerful and practical tool to enhance the robustness and generalization of RL policies. 

**Abstract (ZH)**: 基于布丰π定理的零shot迁移方法：强化学习策略的通用性提升 

---
# BEAR: Benchmarking and Enhancing Multimodal Language Models for Atomic Embodied Capabilities 

**Title (ZH)**: BEAR: 评估与增强多模态语言模型的原子体态能力 

**Authors**: Yu Qi, Haibo Zhao, Ziyu Guo, Siyuan Ma, Ziyan Chen, Yaokun Han, Renrui Zhang, Zitiantao Lin, Shiji Xin, Yijian Huang, Kai Cheng, Peiheng Wang, Jiazheng Liu, Jiayi Zhang, Yizhe Zhu, Wenqing Wang, Yiran Qin, Xupeng Zhu, Haojie Huang, Lawson L.S. Wong  

**Link**: [PDF](https://arxiv.org/pdf/2510.08759)  

**Abstract**: Embodied capabilities refer to a suite of fundamental abilities for an agent to perceive, comprehend, and interact with the physical world. While multimodal large language models (MLLMs) show promise as embodied agents, a thorough and systematic evaluation of their embodied capabilities remains underexplored, as existing benchmarks primarily focus on specific domains such as planning or spatial understanding. To bridge this gap, we introduce BEAR, a comprehensive and fine-grained benchmark that evaluates MLLMs on atomic embodied capabilities. BEAR comprises 4,469 interleaved image-video-text entries across 14 domains in 6 categories, including tasks from low-level pointing, trajectory understanding, spatial reasoning, to high-level planning. Extensive evaluation results of 20 representative MLLMs reveal their persistent limitations across all domains of embodied capabilities. To tackle the shortfall, we propose BEAR-Agent, a multimodal conversable agent that integrates pretrained vision models to strengthen MLLM perception, 3D understanding, and planning capabilities. It substantially enhances MLLM performance across diverse embodied capabilities on BEAR, yielding a 9.12% absolute gain and a relative improvement of 17.5% on GPT-5. Furthermore, our experiments indicate that improving MLLM embodied capabilities can benefit embodied tasks in simulated environments. Project website: this https URL 

**Abstract (ZH)**: 具身能力是指智能体感知、理解并互动于物理世界的一套基本能力。尽管多模态大型语言模型（MLLMs）显示出作为具身智能体的潜力，但对其具身能力的全面而系统性的评估仍然未充分探索，现有基准主要集中在规划或空间理解等特定领域。为弥补这一不足，我们引入了BEAR，这是一个全面细致的基准，用于评估MLLMs在原子具身能力上的表现。BEAR包含4469个交错的图像-视频-文本条目，分布在6个类别和14个领域中，涵盖了从低级指点、轨迹理解、空间推理到高级规划的任务。对20个代表性MLLMs的广泛评估结果揭示了它们在所有具身能力领域的持续局限性。为解决这一不足，我们提出了一种多模态可对话的智能体BEAR-Agent，它通过集成预训练的视觉模型来增强MLLM的感知、3D理解和规划能力。BEAR-Agent在BEAR上的多样化具身能力上显著提升了MLLM的表现，相对于GPT-5实现了9.12%的绝对改善和17.5%的相对提升。此外，我们的实验表明，提高MLLM的具身能力可以受益于模拟环境中的具身任务。项目网站：this https URL。 

---
# Unified World Models: Memory-Augmented Planning and Foresight for Visual Navigation 

**Title (ZH)**: 统一的世界模型：增强记忆的视觉导航规划与预判 

**Authors**: Yifei Dong, Fengyi Wu, Guangyu Chen, Zhi-Qi Cheng, Qiyu Hu, Yuxuan Zhou, Jingdong Sun, Jun-Yan He, Qi Dai, Alexander G Hauptmann  

**Link**: [PDF](https://arxiv.org/pdf/2510.08713)  

**Abstract**: Enabling embodied agents to effectively imagine future states is critical for robust and generalizable visual navigation. Current state-of-the-art approaches, however, adopt modular architectures that separate navigation planning from visual world modeling, leading to state-action misalignment and limited adaptability in novel or dynamic scenarios. To overcome this fundamental limitation, we propose UniWM, a unified, memory-augmented world model integrating egocentric visual foresight and planning within a single multimodal autoregressive backbone. Unlike modular frameworks, UniWM explicitly grounds action decisions in visually imagined outcomes, ensuring tight alignment between prediction and control. A hierarchical memory mechanism further integrates detailed short-term perceptual cues with longer-term trajectory context, enabling stable, coherent reasoning over extended horizons. Extensive experiments across four challenging benchmarks (Go Stanford, ReCon, SCAND, HuRoN) demonstrate that UniWM substantially improves navigation success rates by up to 30%, significantly reduces trajectory errors compared to strong baselines, and exhibits impressive zero-shot generalization on the unseen TartanDrive dataset. These results highlight UniWM as a principled step toward unified, imagination-driven embodied navigation. 

**Abstract (ZH)**: 统一记忆增强的世界模型对于稳健和泛化的视觉导航至关重要。然而，当前最先进的方法采用模块化架构，将导航规划与视觉世界建模分离，导致状态-动作不对齐和在新或动态场景中的适应性有限。为克服这一根本限制，我们提出了UniWM，这是一种统一的记忆增强世界模型，将自我中心的视觉前瞻与规划整合在一个多模态自回归骨干网络中。与模块化框架不同，UniWM 明确地将行动决策与视觉想象的结果联系起来，确保预测与控制之间的紧密对齐。分层记忆机制进一步整合了详细的短期感知线索与长期轨迹上下文，使长期推理更加稳定和连贯。在四个具有挑战性的基准（Go Stanford、ReCon、SCAND、HuRoN）上的 extensive 实验表明，UniWM 在导航成功率上提高了高达 30%，与强大的基线相比显著减少了轨迹误差，并在未见过的 TartanDrive 数据集上展示了令人印象深刻的零样本泛化能力。这些结果突显了UniWM 是朝着统一的、想象驱动的自主导航的一个基本原则步骤。 

---
# Hamba: Single-view 3D Hand Reconstruction with Graph-guided Bi-Scanning Mamba 

**Title (ZH)**: Hamba：基于图引导双扫描的单视角3D手部重建 

**Authors**: Haoye Dong, Aviral Chharia, Wenbo Gou, Francisco Vicente Carrasco, Fernando De la Torre  

**Link**: [PDF](https://arxiv.org/pdf/2407.09646)  

**Abstract**: 3D Hand reconstruction from a single RGB image is challenging due to the articulated motion, self-occlusion, and interaction with objects. Existing SOTA methods employ attention-based transformers to learn the 3D hand pose and shape, yet they do not fully achieve robust and accurate performance, primarily due to inefficiently modeling spatial relations between joints. To address this problem, we propose a novel graph-guided Mamba framework, named Hamba, which bridges graph learning and state space modeling. Our core idea is to reformulate Mamba's scanning into graph-guided bidirectional scanning for 3D reconstruction using a few effective tokens. This enables us to efficiently learn the spatial relationships between joints for improving reconstruction performance. Specifically, we design a Graph-guided State Space (GSS) block that learns the graph-structured relations and spatial sequences of joints and uses 88.5% fewer tokens than attention-based methods. Additionally, we integrate the state space features and the global features using a fusion module. By utilizing the GSS block and the fusion module, Hamba effectively leverages the graph-guided state space features and jointly considers global and local features to improve performance. Experiments on several benchmarks and in-the-wild tests demonstrate that Hamba significantly outperforms existing SOTAs, achieving the PA-MPVPE of 5.3mm and F@15mm of 0.992 on FreiHAND. At the time of this paper's acceptance, Hamba holds the top position, Rank 1 in two Competition Leaderboards on 3D hand reconstruction. Project Website: this https URL 

**Abstract (ZH)**: 单张RGB图像的3D手部重构因其 articulated 运动、自遮挡以及与物体的交互而具有挑战性。现有的SOTA方法采用基于注意力的变换器来学习3D手部姿态和形状，但未能完全实现稳健且准确的表现，主要原因是关节间空间关系建模效率不高。为解决这一问题，我们提出了一种新的图引导Mamba框架，名为Hamba，该框架将图学习与状态空间建模相结合。我们的核心思想是通过图引导的双向扫描将Mamba的扫描重构成3D重构，仅使用少量有效的tokens。这使我们能够高效地学习关节间的空间关系以提高重构性能。具体而言，我们设计了一种图引导状态空间（GSS）块，学习关节的图结构关系和空间序列，并比注意力方法使用少88.5%的tokens。此外，我们通过融合模块将状态空间特征和全局特征进行整合。通过利用GSS块和融合模块，Hamba有效地利用了图引导的状态空间特征，并共同考虑全局和局部特征以提高性能。在多个基准测试和户外测试中，Hamba显著优于现有SOTA方法，在FreiHAND数据集上实现了PA-MPVPE为5.3mm和F@15mm为0.992。该论文提交时，Hamba在两个3D手部重构竞赛leaderboard上保持第1名。Project Website: this https URL。 

---
