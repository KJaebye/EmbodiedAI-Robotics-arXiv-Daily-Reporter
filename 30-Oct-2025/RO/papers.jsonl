{'arxiv_id': 'arXiv:2510.25768', 'title': 'STITCH 2.0: Extending Augmented Suturing with EKF Needle Estimation and Thread Management', 'authors': 'Kush Hari, Ziyang Chen, Hansoul Kim, Ken Goldberg', 'link': 'https://arxiv.org/abs/2510.25768', 'abstract': 'Surgical suturing is a high-precision task that impacts patient healing and scarring. Suturing skill varies widely between surgeons, highlighting the need for robot assistance. Previous robot suturing works, such as STITCH 1.0 [1], struggle to fully close wounds due to inaccurate needle tracking and poor thread management. To address these challenges, we present STITCH 2.0, an elevated augmented dexterity pipeline with seven improvements including: improved EKF needle pose estimation, new thread untangling methods, and an automated 3D suture alignment algorithm. Experimental results over 15 trials find that STITCH 2.0 on average achieves 74.4% wound closure with 4.87 sutures per trial, representing 66% more sutures in 38% less time compared to the previous baseline. When two human interventions are allowed, STITCH 2.0 averages six sutures with 100% wound closure rate. Project website: this https URL', 'abstract_zh': '手术缝合是一项高精度任务，影响患者的愈合和疤痕形成。外科医生之间的缝合技能差异大，凸显了机器人辅助的必要性。先前的机器人缝合工作，如STITCH 1.0，在针位置跟踪不准确和线管理不佳的情况下，难以完全闭合伤口。为了解决这些问题，我们呈现了STITCH 2.0，这是一个提升的增强灵巧性管道，包括七项改进：改进的EKF针位姿估计、新的线解纠缠方法以及自动3D缝合对齐算法。在15次试验中，STITCH 2.0平均实现74.4%的伤口闭合，每实验使用4.87针，相比先前基线，在时间减少38%的情况下增加了66%的缝合数量。允许两次人类干预时，STITCH 2.0平均使用6针实现100%的伤口闭合率。项目网站：https://this-url', 'title_zh': 'STITCH 2.0: 扩展增强缝合与EKF针估计及线管理'}
{'arxiv_id': 'arXiv:2510.25754', 'title': 'GET-USE: Learning Generalized Tool Usage for Bimanual Mobile Manipulation via Simulated Embodiment Extensions', 'authors': 'Bohan Wu, Paul de La Sayette, Li Fei-Fei, Roberto Martín-Martín', 'link': 'https://arxiv.org/abs/2510.25754', 'abstract': "The ability to use random objects as tools in a generalizable manner is a missing piece in robots' intelligence today to boost their versatility and problem-solving capabilities. State-of-the-art robotic tool usage methods focused on procedurally generating or crowd-sourcing datasets of tools for a task to learn how to grasp and manipulate them for that task. However, these methods assume that only one object is provided and that it is possible, with the correct grasp, to perform the task; they are not capable of identifying, grasping, and using the best object for a task when many are available, especially when the optimal tool is absent. In this work, we propose GeT-USE, a two-step procedure that learns to perform real-robot generalized tool usage by learning first to extend the robot's embodiment in simulation and then transferring the learned strategies to real-robot visuomotor policies. Our key insight is that by exploring a robot's embodiment extensions (i.e., building new end-effectors) in simulation, the robot can identify the general tool geometries most beneficial for a task. This learned geometric knowledge can then be distilled to perform generalized tool usage tasks by selecting and using the best available real-world object as tool. On a real robot with 22 degrees of freedom (DOFs), GeT-USE outperforms state-of-the-art methods by 30-60% success rates across three vision-based bimanual mobile manipulation tool-usage tasks.", 'abstract_zh': '利用随机对象在通用场景下作为工具的能力是当前机器人智能中的一项缺失环节，旨在提升机器人的多功能性和问题解决能力。现有的先进机器人工具使用方法侧重于通过程序生成或众包任务相关的工具数据集，以便学习如何抓取和操控这些工具。然而，这些方法假设只提供一个对象，并且在正确抓取情况下可以完成任务；它们无法在多个对象可用时识别、抓取和使用最适合的任务对象，尤其是在最优工具缺失的情况下。在本研究中，我们提出了一种名为GeT-USE的两步方法，该方法通过首先在模拟中扩展机器人的体感，然后将学到的策略转移到真实机器人可视化运动策略中，来学习执行通用工具使用。我们的关键洞察是，通过在模拟中探索机器人的体感扩展（即构建新的末端执行器），机器人可以识别对任务最有益的一般工具几何形状。这种学到的几何知识可以被提取并用于通过选择和使用最佳可用的真实世界物体作为工具来执行通用工具使用任务。在具有22自由度的真实机器人上，GeT-USE在三项基于视觉的双臂移动操作工具使用任务中的成功率相比最先进的方法提高了30-60%。', 'title_zh': 'GET-USE: 通过模拟体能扩展学习双臂移动操作中的通用工具使用方法'}
{'arxiv_id': 'arXiv:2510.25727', 'title': 'Modeling Collapse of Steered Vine Robots Under Their Own Weight', 'authors': 'Ciera McFarland, Margaret McGuinness', 'link': 'https://arxiv.org/abs/2510.25727', 'abstract': "Soft, vine-inspired growing robots that move by eversion are highly mobile in confined environments, but, when faced with gaps in the environment, they may collapse under their own weight while navigating a desired path. In this work, we present a comprehensive collapse model that can predict the collapse length of steered robots in any shape using true shape information and tail tension. We validate this model by collapsing several unsteered robots without true shape information. The model accurately predicts the trends of those experiments. We then attempt to collapse a robot steered with a single actuator at different orientations. Our models accurately predict collapse when it occurs. Finally, we demonstrate how this could be used in the field by having a robot attempt a gap-crossing task with and without inflating its actuators. The robot needs its actuators inflated to cross the gap without collapsing, which our model supports. Our model has been specifically tested on straight and series pouch motor-actuated robots made of non-stretchable material, but it could be applied to other robot variations. This work enables us to model the robot's collapse behavior in any open environment and understand the parameters it needs to succeed in 3D navigation tasks.", 'abstract_zh': '受藤本植物启发的软体攀爬机器人通过逆转方式移动，在受限环境中高度灵活，但在面对环境中的空隙时，可能在导航目标路径时因自身重量而坍塌。在这项工作中，我们提出了一种综合的坍塌模型，可以使用真实的形状信息和尾巴张力预测任何形状的导向机器人的坍塌长度。我们通过使几个未导向的机器人坍塌而没有真实形状信息来验证该模型，该模型准确地预测了这些实验的趋势。然后，我们尝试使用单个执行器以不同方向导向使机器人坍塌。我们的模型准确地预测了其坍塌的发生。最后，我们展示了如何将其应用到实际任务中，让机器人在有和没有膨胀其执行器的情况下尝试跨越空隙任务。机器人需要其执行器膨胀才能跨越空隙而不坍塌，这得到了我们模型的支持。该模型已在非伸缩材料制成的直行和系列囊状电机驱动机器人上进行了专门测试，但可用于其他机器人变化。这项工作使我们能够模拟机器人在任何开放环境中的坍塌行为，并理解其在三维导航任务中成功所需的参数。', 'title_zh': '基于自身重量的牵引攀爬机器人坍塌建模'}
{'arxiv_id': 'arXiv:2510.25725', 'title': 'A Humanoid Visual-Tactile-Action Dataset for Contact-Rich Manipulation', 'authors': 'Eunju Kwon, Seungwon Oh, In-Chang Baek, Yucheon Park, Gyungbo Kim, JaeYoung Moon, Yunho Choi, Kyung-Joong Kim', 'link': 'https://arxiv.org/abs/2510.25725', 'abstract': 'Contact-rich manipulation has become increasingly important in robot learning. However, previous studies on robot learning datasets have focused on rigid objects and underrepresented the diversity of pressure conditions for real-world manipulation. To address this gap, we present a humanoid visual-tactile-action dataset designed for manipulating deformable soft objects. The dataset was collected via teleoperation using a humanoid robot equipped with dexterous hands, capturing multi-modal interactions under varying pressure conditions. This work also motivates future research on models with advanced optimization strategies capable of effectively leveraging the complexity and diversity of tactile signals.', 'abstract_zh': '富有接触的操控在机器人学习中变得越来越重要。然而，之前的机器人学习数据集研究主要集中在刚性物体上，并未能充分代表现实世界操控中压力条件的多样性。为弥补这一不足，我们呈现了一个用于操控可变形软物体的人形视觉-触觉-动作数据集。该数据集通过装备灵巧手的人形机器人遥操作收集，捕捉了在不同压力条件下的多模态交互。此外，本研究还激励了未来能够有效利用触觉信号复杂性和多样性的模型研究。', 'title_zh': '人类视觉-触觉-行动数据集：接触丰富操作'}
{'arxiv_id': 'arXiv:2510.25713', 'title': 'Robotic Assistant: Completing Collaborative Tasks with Dexterous Vision-Language-Action Models', 'authors': 'Boshi An, Chenyu Yang, Robert Katzschmann', 'link': 'https://arxiv.org/abs/2510.25713', 'abstract': 'We adapt a pre-trained Vision-Language-Action (VLA) model (Open-VLA) for dexterous human-robot collaboration with minimal language prompting. Our approach adds (i) FiLM conditioning to visual backbones for task-aware perception, (ii) an auxiliary intent head that predicts collaborator hand pose and target cues, and (iii) action-space post-processing that predicts compact deltas (position/rotation) and PCA-reduced finger joints before mapping to full commands. Using a multi-view, teleoperated Franka and Mimic-hand dataset augmented with MediaPipe hand poses, we demonstrate that delta actions are well-behaved and that four principal components explain ~96% of hand-joint variance. Ablations identify action post-processing as the primary performance driver; auxiliary intent helps, FiLM is mixed, and a directional motion loss is detrimental. A real-time stack (~0.3 s latency on one RTX 4090) composes "pick-up" and "pass" into a long-horizon behavior. We surface "trainer overfitting" to specific demonstrators as the key limitation.', 'abstract_zh': '我们通过最小的语言提示，适应一个预训练的Vision-Language-Action (VLA)模型（Open-VLA），实现灵巧的人机协作。该方法增加了(i)针对任务的视觉背部的FiLM条件,(ii)一个辅助意图头来预测合作者的手部姿态和目标提示,(iii)在动作空间后处理中预测紧凑的位移和旋转delta，以及PCA降维的手指关节，然后映射到完整的命令。通过一个多视角的远程操作Franka和Mimic-hand数据集，并用MediaPipe手部姿态进行增强，我们展示了delta动作表现良好，并且四个主成分解释了手部关节96%的方差。消融实验表明动作后处理是主要性能驱动因素；辅助意图有所帮助，FiLM的效果参差不齐，而方向性运动损失是有害的。实时堆栈 (~0.3秒延迟在一个RTX 4090上) 将“拾取”和“传递”组合成一种长远行为。我们揭示了对特定示范者的“trainer过拟合”是主要限制。', 'title_zh': '机器人助手中兼顾灵巧视觉-语言-动作模型的协作任务完成'}
{'arxiv_id': 'arXiv:2510.25650', 'title': 'Collision avoidance and path finding in a robotic mobile fulfillment system using multi-objective meta-heuristics', 'authors': 'Ahmad Kokhahi, Mary Kurz', 'link': 'https://arxiv.org/abs/2510.25650', 'abstract': 'Multi-Agent Path Finding (MAPF) has gained significant attention, with most research focusing on minimizing collisions and travel time. This paper also considers energy consumption in the path planning of automated guided vehicles (AGVs). It addresses two main challenges: i) resolving collisions between AGVs and ii) assigning tasks to AGVs. We propose a new collision avoidance strategy that takes both energy use and travel time into account. For task assignment, we present two multi-objective algorithms: Non-Dominated Sorting Genetic Algorithm (NSGA) and Adaptive Large Neighborhood Search (ALNS). Comparative evaluations show that these proposed methods perform better than existing approaches in both collision avoidance and task assignment.', 'abstract_zh': '多代理路径规划（MAPF）引起了广泛关注，大多数研究集中于减少碰撞和旅行时间。本文还考虑了在自动引导车（AGVs）的路径规划中能源消耗的问题。本文主要解决两个挑战：i) AGVs之间的碰撞解决，ii) 任务分配。我们提出了一种新的碰撞避免策略，考虑了能源使用和旅行时间。在任务分配方面，我们提出了两种多目标算法：非支配排序遗传算法（NSGA）和自适应大邻域搜索（ALNS）。比较评价表明，这些提出的方法在碰撞避免和任务分配上都优于现有方法。', 'title_zh': '使用多目标元启发式方法在机器人移动 fulfillment 系统中的碰撞避免与路径规划'}
{'arxiv_id': 'arXiv:2510.25634', 'title': 'Learning to Plan & Schedule with Reinforcement-Learned Bimanual Robot Skills', 'authors': 'Weikang Wan, Fabio Ramos, Xuning Yang, Caelan Garrett', 'link': 'https://arxiv.org/abs/2510.25634', 'abstract': 'Long-horizon contact-rich bimanual manipulation presents a significant challenge, requiring complex coordination involving a mixture of parallel execution and sequential collaboration between arms. In this paper, we introduce a hierarchical framework that frames this challenge as an integrated skill planning & scheduling problem, going beyond purely sequential decision-making to support simultaneous skill invocation. Our approach is built upon a library of single-arm and bimanual primitive skills, each trained using Reinforcement Learning (RL) in GPU-accelerated simulation. We then train a Transformer-based planner on a dataset of skill compositions to act as a high-level scheduler, simultaneously predicting the discrete schedule of skills as well as their continuous parameters. We demonstrate that our method achieves higher success rates on complex, contact-rich tasks than end-to-end RL approaches and produces more efficient, coordinated behaviors than traditional sequential-only planners.', 'abstract_zh': '长时空中交互双臂操作 Presents a Significant Challenge Requiring Complex Coordination Between Arms, and We Introduce a Hierarchical Framework for Integrated Skill Planning and Scheduling', 'title_zh': '学习执行双臂机器人技能的规划与调度'}
{'arxiv_id': 'arXiv:2510.25548', 'title': 'Using VLM Reasoning to Constrain Task and Motion Planning', 'authors': 'Muyang Yan, Miras Mengdibayev, Ardon Floros, Weihang Guo, Lydia E. Kavraki, Zachary Kingston', 'link': 'https://arxiv.org/abs/2510.25548', 'abstract': "In task and motion planning, high-level task planning is done over an abstraction of the world to enable efficient search in long-horizon robotics problems. However, the feasibility of these task-level plans relies on the downward refinability of the abstraction into continuous motion. When a domain's refinability is poor, task-level plans that appear valid may ultimately fail during motion planning, requiring replanning and resulting in slower overall performance. Prior works mitigate this by encoding refinement issues as constraints to prune infeasible task plans. However, these approaches only add constraints upon refinement failure, expending significant search effort on infeasible branches. We propose VIZ-COAST, a method of leveraging the common-sense spatial reasoning of large pretrained Vision-Language Models to identify issues with downward refinement a priori, bypassing the need to fix these failures during planning. Experiments on two challenging TAMP domains show that our approach is able to extract plausible constraints from images and domain descriptions, drastically reducing planning times and, in some cases, eliminating downward refinement failures altogether, generalizing to a diverse range of instances from the broader domain.", 'abstract_zh': '基于任务和动作规划中的常识空间推理在先验识别向下细化问题的方法', 'title_zh': '使用VLM推理来约束任务与运动规划'}
{'arxiv_id': 'arXiv:2510.25520', 'title': 'Octopus-like Reaching Motion: A Perspective Inspired by Whipping', 'authors': 'Shengyao Zhang, Yiyuan Zhang, Chenrui Zhang, Yiming Li, Wenci Xin, Yuliang Liufu, Hong Wei Ng, Cecilia Laschi', 'link': 'https://arxiv.org/abs/2510.25520', 'abstract': 'The stereotypical reaching motion of the octopus arm has drawn growing attention for its efficient control of a highly deformable body. Previous studies suggest that its characteristic bend propagation may share underlying principles with the dynamics of a whip. This work investigates whether whip-like passive dynamics in water can reproduce the kinematic features observed in biological reaching and their similarities and differences. Platform-based whipping tests were performed in water and air while systematically varying material stiffness and driving speed. Image-based quantification revealed that the Ecoflex Gel 2 arm driven at 150 rpm (motor speed) reproduced curvature propagation similar to that observed in octopus reaching. However, its bend-point velocity decreased monotonically rather than exhibiting the biological bell-shaped profile, confirming that the octopus reaching movement is not merely a passive whipping behavior. The absence of propagation in air further highlights the critical role of the surrounding medium in forming octopus-like reaching motion. This study provides a new perspective for understand biological reaching movement, and offers a potential platform for future hydrodynamic research.', 'abstract_zh': '八腕足的典型抓握运动的水动力学研究：鞭打动力学与其生物抓握运动特征的比较', 'title_zh': '类吸盘抓取运动：鞭打启发的新视角'}
{'arxiv_id': 'arXiv:2510.25479', 'title': 'Combining Moving Mass Actuators and Manoeuvring Models for Underwater Vehicles: A Lagrangian Approach', 'authors': 'Alexander B. Rambech, Ivar B. Saksvik, Vahid Hassani', 'link': 'https://arxiv.org/abs/2510.25479', 'abstract': "In this paper, we present a Newton-Euler formulation of the equations of motion for underwater vehicles with an interntal moving mass actuator. Furthermore, the moving mass dynamics are expressed as an extension to the manoeuvring model for underwater vehicles, originally introduced by Fossen (1991). The influence of the moving mass is described in body-frame and included as states in both an additional kinematic equation and as part of the coupled rigid-body kinetics of the underwater vehicle. The Coriolis-centripetal effects are derived from Kirchhoff's equations and the hydrostatics are derived using first principals. The proposed Newton-Euler model is validated through simulation and compared with the traditional Hamiltonian internal moving mass actuator formulation.", 'abstract_zh': '本文提出了一种用于具有内部移动质量执行器的水下车辆的牛顿-欧勒运动方程形式化方法。此外，移动质量的动力学被表示为对Fossen (1991) 提出的水下车辆机动模型的扩展。移动质量的影响在体框架中描述，并在其机动模型的附加运动方程和水下车辆刚体动力学的耦合中作为状态包括。科里奥利-离心效应是从Kirchhoff方程中推导出来的，静水压力则是基于基本原理推导的。所提出的牛顿-欧勒模型通过仿真进行了验证，并与传统的哈密尔顿内部移动质量执行器形式化进行了比较。', 'title_zh': '基于拉格朗日方法结合移动质量执行机构和航行器模型的水下自主航行器控制'}
{'arxiv_id': 'arXiv:2510.25422', 'title': 'Solving the Right Problem with Multi-Robot Formations', 'authors': 'Chaz Cornwall, Jeremy P. Bos', 'link': 'https://arxiv.org/abs/2510.25422', 'abstract': "Formation control simplifies minimizing multi-robot cost functions by encoding a cost function as a shape the robots maintain. However, by reducing complex cost functions to formations, discrepancies arise between maintaining the shape and minimizing the original cost function. For example, a Diamond or Box formation shape is often used for protecting all members of the formation. When more information about the surrounding environment becomes available, a static shape often no longer minimizes the original protection cost. We propose a formation planner to reduce mismatch between a formation and the cost function while still leveraging efficient formation controllers. Our formation planner is a two-step optimization problem that identifies desired relative robot positions. We first solve a constrained problem to estimate non-linear and non-differentiable costs with a weighted sum of surrogate cost functions. We theoretically analyze this problem and identify situations where weights do not need to be updated. The weighted, surrogate cost function is then minimized using relative positions between robots. The desired relative positions are realized using a non-cooperative formation controller derived from Lyapunov's direct approach. We then demonstrate the efficacy of this approach for military-like costs such as protection and obstacle avoidance. In simulations, we show a formation planner can reduce a single cost by over 75%. When minimizing a variety of cost functions simultaneously, using a formation planner with adaptive weights can reduce the cost by 20-40%. Formation planning provides better performance by minimizing a surrogate cost function that closely approximates the original cost function instead of relying on a shape abstraction.", 'abstract_zh': '形成控制通过将成本函数编码为机器人保持的形状来简化多机器人成本函数的最小化，但通过将复杂成本函数简化为形成，会在保持形状和最小化原始成本函数之间产生差异。我们提出了一种形成规划器，以减少形成与成本函数之间的不匹配，同时利用高效的形成控制器。我们的形成规划器是一个两步优化问题，用于识别期望的机器人相对位置。首先，我们解决一个约束问题，使用加权的代理成本函数之和来估算非线性且非可微的成本。我们对该问题进行理论分析，并确定不需要更新权重的情况。然后，我们使用机器人之间的相对位置来最小化加权代理成本函数。期望的机器人相对位置通过由李雅普诺夫直接方法导出的非合作形成控制器来实现。然后，我们展示了这种规划方法在类似军事的成本如保护和障碍物避免方面的有效性。在仿真中，我们展示了形成规划器可以使单个成本减少超过75%。在同时最小化多种成本函数时，使用具有自适应权重的形成规划器可以使成本减少20-40%。形成规划通过最小化一个接近原始成本函数的代理成本函数，而非依赖形状抽象，提供更好的性能。', 'title_zh': '多机器人编队解决正确的问题'}
{'arxiv_id': 'arXiv:2510.25405', 'title': 'Sim-to-Real Gentle Manipulation of Deformable and Fragile Objects with Stress-Guided Reinforcement Learning', 'authors': 'Kei Ikemura, Yifei Dong, David Blanco-Mulero, Alberta Longhini, Li Chen, Florian T. Pokorny', 'link': 'https://arxiv.org/abs/2510.25405', 'abstract': 'Robotic manipulation of deformable and fragile objects presents significant challenges, as excessive stress can lead to irreversible damage to the object. While existing solutions rely on accurate object models or specialized sensors and grippers, this adds complexity and often lacks generalization. To address this problem, we present a vision-based reinforcement learning approach that incorporates a stress-penalized reward to discourage damage to the object explicitly. In addition, to bootstrap learning, we incorporate offline demonstrations as well as a designed curriculum progressing from rigid proxies to deformables. We evaluate the proposed method in both simulated and real-world scenarios, showing that the policy learned in simulation can be transferred to the real world in a zero-shot manner, performing tasks such as picking up and pushing tofu. Our results show that the learned policies exhibit a damage-aware, gentle manipulation behavior, demonstrating their effectiveness by decreasing the stress applied to fragile objects by 36.5% while achieving the task goals, compared to vanilla RL policies.', 'abstract_zh': '基于视觉的强化学习方法：通过应力惩罚奖励实现脆弱可变形物体的智能化 manipulation', 'title_zh': '基于应力导向强化学习的柔性易碎物体温和操控从仿真到现实的研究'}
{'arxiv_id': 'arXiv:2510.25386', 'title': 'Integrating Legal and Logical Specifications in Perception, Prediction, and Planning for Automated Driving: A Survey of Methods', 'authors': 'Kumar Manas, Mert Keser, Alois Knoll', 'link': 'https://arxiv.org/abs/2510.25386', 'abstract': 'This survey provides an analysis of current methodologies integrating legal and logical specifications into the perception, prediction, and planning modules of automated driving systems. We systematically explore techniques ranging from logic-based frameworks to computational legal reasoning approaches, emphasizing their capability to ensure regulatory compliance and interpretability in dynamic and uncertain driving environments. A central finding is that significant challenges arise at the intersection of perceptual reliability, legal compliance, and decision-making justifiability. To systematically analyze these challenges, we introduce a taxonomy categorizing existing approaches by their theoretical foundations, architectural implementations, and validation strategies. We particularly focus on methods that address perceptual uncertainty and incorporate explicit legal norms, facilitating decisions that are both technically robust and legally defensible. The review covers neural-symbolic integration methods for perception, logic-driven rule representation, and norm-aware prediction strategies, all contributing toward transparent and accountable autonomous vehicle operation. We highlight critical open questions and practical trade-offs that must be addressed, offering multidisciplinary insights from engineering, logic, and law to guide future developments in legally compliant autonomous driving systems.', 'abstract_zh': '本综述对将法律和逻辑规范整合到自动驾驶系统感知、预测和规划模块中的当前方法进行了分析。我们系统地探讨了从基于逻辑框架到计算法学推理方法的各种技术，强调了它们在动态和不确定驾驶环境中确保合规性和解释性的能力。一个主要发现是，在感知可靠性、法律合规性和决策可辩护性之间的交叉点存在着重大挑战。为了系统地分析这些挑战，我们提出了一种分类法，将现有的方法按其理论基础、架构实现和验证策略进行分类。特别关注解决感知不确定性并明确纳入法律规范的方法，促进既技术上稳健又具有法律可辩护性的决策。综述涵盖了知觉神经符号集成方法、逻辑驱动规则表示以及法规范识预测策略，所有这些都旨在推动透明和负责的自动驾驶操作。我们强调了必须解决的关键开放问题和实际权衡，并从工程学、逻辑学和法学等跨学科角度提供见解，以指导未来合法合规的自动驾驶系统发展。', 'title_zh': '基于感知、预测和规划的自动驾驶中法律与逻辑规范集成：方法综述'}
{'arxiv_id': 'arXiv:2510.25338', 'title': 'Geometric Robot Calibration Using a Calibration Plate', 'authors': 'Bernhard Rameder, Hubert Gattringer, Andreas Mueller', 'link': 'https://arxiv.org/abs/2510.25338', 'abstract': 'In this paper a new method for geometric robot calibration is introduced, which uses a calibration plate with precisely known distances between its measuring points. The relative measurement between two points on the calibration plate is used to determine predefined error parameters of the system. In comparison to conventional measurement methods, like laser tracker or motion capture systems, the calibration plate provides a more mechanically robust and cheaper alternative, which is furthermore easier to transport due to its small size. The calibration method, the plate design, the mathematical description of the error system as well as the identification of the parameters are described in detail. For identifying the error parameters, the least squares method and a constrained optimization problem are used. The functionality of this method was demonstrated in experiments that led to promising results, correlated with one of a laser tracker calibration. The modeling and identification of the error parameters is done for a gantry machine, but is not restricted to that type of robot.', 'abstract_zh': '本文介绍了一种新的几何机器人校准方法，该方法使用具有 precisely known distances 之间测量点的校准板。通过校准板上两点之间的相对测量来确定系统的预定义误差参数。与激光跟踪仪或运动捕捉系统等常规测量方法相比，校准板提供了更坚固、成本更低的替代方案，并且由于其小巧的尺寸，便于运输。文中详细描述了校准方法、校准板设计、误差系统的数学描述以及误差参数的识别。通过最小二乘法和约束优化问题来识别误差参数。该方法的功能在实验中得到了验证，实验结果与激光跟踪仪校准结果相关。误差参数的建模与识别适用于龙门加工机，但不局限于这种类型的机器人。', 'title_zh': '使用标定板的几何机器人标定'}
{'arxiv_id': 'arXiv:2510.25335', 'title': 'An approach for combining transparency and motion assistance of a lower body exoskeleton', 'authors': 'Jakob Ziegler, Bernhard Rameder, Hubert Gattringer, Andreas Mueller', 'link': 'https://arxiv.org/abs/2510.25335', 'abstract': "In this paper, an approach for gait assistance with a lower body exoskeleton is described. Two concepts, transparency and motion assistance, are combined. The transparent mode, where the system is following the user's free motion with a minimum of perceived interaction forces, is realized by exploiting the gear backlash of the actuation units. During walking a superimposed assistance mode applies an additional torque guiding the legs to their estimated future position. The concept of adaptive oscillators is utilized to learn the quasi-periodic signals typical for locomotion. First experiments showed promising results.", 'abstract_zh': '基于下肢外骨骼的步态辅助方法研究：透明模式与运动辅助的结合', 'title_zh': '一种结合下肢外骨骼透明度和运动辅助的方法'}
{'arxiv_id': 'arXiv:2510.25280', 'title': 'Development of Implicit-Explicit Control Based Amphibious Centipede-Type Robot and Evaluation of its Mobile Performance', 'authors': 'Yusuke Tsunoda, Seiya Yamamoto, Kazuki Ito, Runze Xiao, Keisuke Naniwa, Koichi Osuka', 'link': 'https://arxiv.org/abs/2510.25280', 'abstract': "Multi-legged mobile robots possess high mobility performance in rough terrain environments, stemming from their high postural stability, joint flexibility, and the redundancy provided by multiple legs. In prior research on navigating between different environments such as land and water, the primary strategy employed involves switching to a controller that generates an appropriate gait for the new environment upon entering it. However, designing appropriate gaits for each complex and diverse environment and accurately determining controller switching for each environment is challenging. Therefore, this research develops a centipede-type mobile robot that navigates both aquatic and terrestrial environments with a simple, unified control scheme, based on the implicit-explicit control philosophy and by ingeniously designing the robot's body structure. In this research, we developed the robot featuring flexible joints and left and right legs on each body segment and focused on the leg structure which has extensive contact with the environment. This paper evaluates the locomotion performance on land and water using the three developed leg structures, using the robot's leg slip rate and actuator energy consumption as evaluation metrics. The experimental results confirmed the existence of an appropriate leg structure capable of navigating both aquatic and terrestrial environments under identical control.", 'abstract_zh': '多足移动机器人在崎岖地形环境中表现出�� mobility 绩效，源自其高的姿态稳定性和关节灵活性以及多足提供的冗余性。在以往针对不同环境（如陆地和水体）导航的研究中，主要策略是在进入新环境时切换到能够产生适合新环境步态的控制器。然而，为每个复杂多样的环境设计合适的步态并准确确定控制器切换是一个挑战。因此，本研究开发了一种蜈蚣型移动机器人，它基于隐式-显式控制哲学，并通过巧妙设计机器人的身体结构，实现了对陆地和水体环境的简单统一控制。在本研究中，我们设计了具有柔性关节并在每个身体节段上具有左右腿的机器，并重点关注与环境有广泛接触的腿部结构。本文使用机器人的腿滑移率和执行器能量消耗作为评价标准，评估了三种所开发的腿结构在陆地和水中的运动性能。实验结果证实，存在一种合适的腿结构，在相同控制条件下能够在陆地和水中导航。', 'title_zh': '基于隐式-显式控制的 Amphibious 千足虫型机器人开发及其移动性能评价'}
{'arxiv_id': 'arXiv:2510.25268', 'title': 'SynHLMA:Synthesizing Hand Language Manipulation for Articulated Object with Discrete Human Object Interaction Representation', 'authors': 'Wang zhi, Yuyan Liu, Liu Liu, Li Zhang, Ruixuan Lu, Dan Guo', 'link': 'https://arxiv.org/abs/2510.25268', 'abstract': 'Generating hand grasps with language instructions is a widely studied topic that benefits from embodied AI and VR/AR applications. While transferring into hand articulatied object interaction (HAOI), the hand grasps synthesis requires not only object functionality but also long-term manipulation sequence along the object deformation. This paper proposes a novel HAOI sequence generation framework SynHLMA, to synthesize hand language manipulation for articulated objects. Given a complete point cloud of an articulated object, we utilize a discrete HAOI representation to model each hand object interaction frame. Along with the natural language embeddings, the representations are trained by an HAOI manipulation language model to align the grasping process with its language description in a shared representation space. A joint-aware loss is employed to ensure hand grasps follow the dynamic variations of articulated object joints. In this way, our SynHLMA achieves three typical hand manipulation tasks for articulated objects of HAOI generation, HAOI prediction and HAOI interpolation. We evaluate SynHLMA on our built HAOI-lang dataset and experimental results demonstrate the superior hand grasp sequence generation performance comparing with state-of-the-art. We also show a robotics grasp application that enables dexterous grasps execution from imitation learning using the manipulation sequence provided by our SynHLMA. Our codes and datasets will be made publicly available.', 'abstract_zh': '基于语言指令生成手部抓取：一种适用于手部 articulated 对象交互的序列生成框架', 'title_zh': 'SynHLMA: 基于离散人-object交互表示的手语操纵合成 articulated objectragen'}
{'arxiv_id': 'arXiv:2510.25255', 'title': 'Time-Optimal Transport of Loosely Placed Liquid Filled Cups along Prescribed Paths', 'authors': 'Klaus Zauner, Hubert Gattringer, Andreas Mueller', 'link': 'https://arxiv.org/abs/2510.25255', 'abstract': 'Handling loosely placed objects with robotic manipulators is a difficult task from the point of view of trajectory planning and control. This becomes even more challenging when the object to be handled is a container filled with liquid. This paper addresses the task of transporting a liquid-filled cup placed on a tray along a prescribed path in shortest time. The objective is to minimize swapping, thus avoiding spillage of the fluid. To this end, the sloshing dynamics is incorporated into the dynamic model used within the optimal control problem formulation. The optimization problem is solved using a direct multiple shooting approach.', 'abstract_zh': '基于最优控制问题建模与直接多重拍摄方法解决装有液体的杯子沿指定路径搬运问题：考虑晃动动力学以最小化液体交换', 'title_zh': '沿指定路径运输松散放置的液体填充杯的时间最优传输'}
{'arxiv_id': 'arXiv:2510.25241', 'title': 'One-shot Humanoid Whole-body Motion Learning', 'authors': 'Hao Huang, Geeta Chandra Raju Bethala, Shuaihang Yuan, Congcong Wen, Anthony Tzes, Yi Fang', 'link': 'https://arxiv.org/abs/2510.25241', 'abstract': 'Whole-body humanoid motion represents a cornerstone challenge in robotics, integrating balance, coordination, and adaptability to enable human-like behaviors. However, existing methods typically require multiple training samples per motion category, rendering the collection of high-quality human motion datasets both labor-intensive and costly. To address this, we propose a novel approach that trains effective humanoid motion policies using only a single non-walking target motion sample alongside readily available walking motions. The core idea lies in leveraging order-preserving optimal transport to compute distances between walking and non-walking sequences, followed by interpolation along geodesics to generate new intermediate pose skeletons, which are then optimized for collision-free configurations and retargeted to the humanoid before integration into a simulated environment for policy training via reinforcement learning. Experimental evaluations on the CMU MoCap dataset demonstrate that our method consistently outperforms baselines, achieving superior performance across metrics. Code will be released upon acceptance.', 'abstract_zh': '全身人形机器人的运动表示是机器人学中的一个核心挑战，涉及平衡、协调和适应性，以实现类似人类的行为。然而，现有方法通常需要每个动作类别多个训练样本，使得高质量人类动作数据集的收集既耗时又昂贵。为解决这一问题，我们提出了一种新颖的方法，仅使用一个非行走目标动作样本和易于获取的行走动作样本来训练有效的人形机器人类动策略。核心思想在于利用保序最优传输来计算行走和非行走序列之间的距离，并通过沿测地线进行插值生成新的中间姿态骨架，然后优化为碰撞-free 配置并重新目标化到人形机器人，最后在模拟环境中通过强化学习进行策略训练。在CMU MoCap数据集上的实验评估表明，我们的方法在所有指标上均优于基线方法，取得了更优的性能。接受后将发布代码。', 'title_zh': '单次学习人体全身运动学习'}
{'arxiv_id': 'arXiv:2510.25233', 'title': 'Hybrid Vision Servoing with Depp Alignment and GRU-Based Occlusion Recovery', 'authors': 'Jee Won Lee, Hansol Lim, Sooyeun Yang, Jongseong Brad Choi', 'link': 'https://arxiv.org/abs/2510.25233', 'abstract': "Vision-based control systems, such as image-based visual servoing (IBVS), have been extensively explored for precise robot manipulation. A persistent challenge, however, is maintaining robust target tracking under partial or full occlusions. Classical methods like Lucas-Kanade (LK) offer lightweight tracking but are fragile to occlusion and drift, while deep learning-based approaches often require continuous visibility and intensive computation. To address these gaps, we propose a hybrid visual tracking framework that bridges advanced perception with real-time servo control. First, a fast global template matcher constrains the pose search region; next, a deep-feature Lucas-Kanade module operating on early VGG layers refines alignment to sub-pixel accuracy (<2px); then, a lightweight residual regressor corrects local misalignments caused by texture degradation or partial occlusion. When visual confidence falls below a threshold, a GRU-based predictor seamlessly extrapolates pose updates from recent motion history. Crucially, the pipeline's final outputs-translation, rotation, and scale deltas-are packaged as direct control signals for 30Hz image-based servo loops. Evaluated on handheld video sequences with up to 90% occlusion, our system sustains under 2px tracking error, demonstrating the robustness and low-latency precision essential for reliable real-world robot vision applications.", 'abstract_zh': '基于视觉的控制系统，如图像导向的视觉伺服（IBVS），已在精确机器人操作中得到广泛研究。然而，持续的挑战是在部分或完全遮挡下保持稳健的目标跟踪。传统的鲁棒性较低的方法如Lucas-Kanade（LK）提供轻量级的跟踪，但对遮挡和漂移敏感，而基于深度学习的方法通常需要持续的可见性和大量的计算。为了解决这些差距，我们提出了一种结合高级感知与实时伺服控制的混合视觉跟踪框架。首先，一个快速的全局模板匹配器限制了姿态搜索区域；其次，一个作用于早期VGG层的深度特征Lucas-Kanade模块对齐到亚像素精度（<2px）；然后，一个轻量级的残差回归器纠正由纹理退化或部分遮挡引起的局部对齐误差。当视觉置信度低于阈值时，一个基于GRU的预测器无缝地从最近的运动历史中外推姿态更新。最关键的是，流水线的最终输出——平移、旋转和缩放增量，被打包成30Hz图像伺服环中的直接控制信号。在具有高达90%遮挡的手持视频序列上评估，我们的系统维持了低于2px的跟踪误差，展示了在可靠的实际机器人视觉应用中所需的高度鲁棒性和低延迟精度。', 'title_zh': '基于深度对齐和GRU基遮挡恢复的混合视觉伺服技术'}
{'arxiv_id': 'arXiv:2510.25211', 'title': 'RoadSens-4M: A Multimodal Smartphone & Camera Dataset for Holistic Road-way Analysis', 'authors': 'Amith Khandakar, David Michelson, Shaikh Golam Rabbani, Fariya Bintay Shafi, Md. Faysal Ahamed, Khondokar Radwanur Rahman, Md Abidur Rahman, Md. Fahmidun Nabi, Mohamed Arselene Ayari, Khaled Khan, Ponnuthurai Nagaratnam Suganthan', 'link': 'https://arxiv.org/abs/2510.25211', 'abstract': "It's important to monitor road issues such as bumps and potholes to enhance safety and improve road conditions. Smartphones are equipped with various built-in sensors that offer a cost-effective and straightforward way to assess road quality. However, progress in this area has been slow due to the lack of high-quality, standardized datasets. This paper discusses a new dataset created by a mobile app that collects sensor data from devices like GPS, accelerometers, gyroscopes, magnetometers, gravity sensors, and orientation sensors. This dataset is one of the few that integrates Geographic Information System (GIS) data with weather information and video footage of road conditions, providing a comprehensive understanding of road issues with geographic context. The dataset allows for a clearer analysis of road conditions by compiling essential data, including vehicle speed, acceleration, rotation rates, and magnetic field intensity, along with the visual and spatial context provided by GIS, weather, and video data. Its goal is to provide funding for initiatives that enhance traffic management, infrastructure development, road safety, and urban planning. Additionally, the dataset will be publicly accessible to promote further research and innovation in smart transportation systems.", 'abstract_zh': '基于移动应用的综合地理信息与路面状况数据集：促进交通安全与智能交通系统发展', 'title_zh': 'RoadSens-4M：一种用于整体道路分析的多模态智能手机与相机数据集'}
{'arxiv_id': 'arXiv:2510.25191', 'title': 'SoraNav: Adaptive UAV Task-Centric Navigation via Zeroshot VLM Reasoning', 'authors': 'Hongyu Song, Rishabh Dev Yadav, Cheng Guo, Wei Pan', 'link': 'https://arxiv.org/abs/2510.25191', 'abstract': 'Interpreting visual observations and natural language instructions for complex task execution remains a key challenge in robotics and AI. Despite recent advances, language-driven navigation is still difficult, particularly for UAVs in small-scale 3D environments. Existing Vision-Language Navigation (VLN) approaches are mostly designed for ground robots and struggle to generalize to aerial tasks that require full 3D spatial reasoning. The emergence of large Vision-Language Models (VLMs), such as GPT and Claude, enables zero-shot semantic reasoning from visual and textual inputs. However, these models lack spatial grounding and are not directly applicable to navigation. To address these limitations, SoraNav is introduced, an adaptive UAV navigation framework that integrates zero-shot VLM reasoning with geometry-aware decision-making. Geometric priors are incorporated into image annotations to constrain the VLM action space and improve decision quality. A hybrid switching strategy leverages navigation history to alternate between VLM reasoning and geometry-based exploration, mitigating dead-ends and redundant revisits. A PX4-based hardware-software platform, comprising both a digital twin and a physical micro-UAV, enables reproducible evaluation. Experimental results show that in 2.5D scenarios, our method improves Success Rate (SR) by 25.7% and Success weighted by Path Length (SPL) by 17%. In 3D scenarios, it improves SR by 29.5% and SPL by 18.5% relative to the baseline.', 'abstract_zh': '基于视觉语言理解的复杂任务执行解析仍是在机器人技术和AI领域的一个关键挑战。尽管最近取得了一些进展，但基于语言的导航任务，尤其是在小规模3D环境中的无人机任务，仍然极具挑战性。现有的视觉-语言导航(VLN)方法主要针对地面机器人设计，难以泛化到需要全面3D空间推理的空中任务。大型视觉语言模型(VLM)，如GPT和Claude的出现，使从视觉和文本输入进行零样本语义推理成为可能。然而，这些模型缺乏空间定位，不适用于导航任务。为了克服这些限制，我们提出了SoraNav，一个将零样本VLM推理与几何感知决策相结合的自适应无人机导航框架。将几何先验整合到图像标注中，以约束VLM的动作空间并提高决策质量。一种混合切换策略利用导航历史交替进行VLM推理和基于几何的探索，在避免死胡同和重复访问方面起到了作用。该方法基于PX4的硬件-软件平台，包括数字双胞胎和物理微型无人机，使评估具有可重复性。实验结果显示，在2.5D场景中，我们的方法将成功率达到提高了25.7%，路径加权成功率达到提高了17%。在3D场景中，成功率达到提高了29.5%，路径加权成功率达到提高了18.5%，相对于基线方法。', 'title_zh': 'SoraNav: 基于零样本VLM推理的自适应无人机任务导向导航'}
{'arxiv_id': 'arXiv:2510.25138', 'title': 'Learning Spatial-Aware Manipulation Ordering', 'authors': 'Yuxiang Yan, Zhiyuan Zhou, Xin Gao, Guanghao Li, Shenglin Li, Jiaqi Chen, Qunyan Pu, Jian Pu', 'link': 'https://arxiv.org/abs/2510.25138', 'abstract': 'Manipulation in cluttered environments is challenging due to spatial dependencies among objects, where an improper manipulation order can cause collisions or blocked access. Existing approaches often overlook these spatial relationships, limiting their flexibility and scalability. To address these limitations, we propose OrderMind, a unified spatial-aware manipulation ordering framework that directly learns object manipulation priorities based on spatial context. Our architecture integrates a spatial context encoder with a temporal priority structuring module. We construct a spatial graph using k-Nearest Neighbors to aggregate geometric information from the local layout and encode both object-object and object-manipulator interactions to support accurate manipulation ordering in real-time. To generate physically and semantically plausible supervision signals, we introduce a spatial prior labeling method that guides a vision-language model to produce reasonable manipulation orders for distillation. We evaluate OrderMind on our Manipulation Ordering Benchmark, comprising 163,222 samples of varying difficulty. Extensive experiments in both simulation and real-world environments demonstrate that our method significantly outperforms prior approaches in effectiveness and efficiency, enabling robust manipulation in cluttered scenes.', 'abstract_zh': '在杂乱环境中进行操作因物体之间的空间依赖关系而具有挑战性，不恰当的操作顺序可能导致碰撞或访问受阻。现有方法往往忽略这些空间关系，限制了其灵活性和可扩展性。为了解决这些问题，我们提出了OrderMind，这是一种统一的空间感知操作顺序框架，可以直接根据空间上下文学习物体操作优先级。我们的架构结合了空间上下文编码器和时间优先级结构模块。我们使用k-最近邻构建空间图，以聚合局部布局的几何信息，并编码物体间和物体-操作者间的交互，以支持实时准确的操作顺序。为生成物理和语义上合理的监督信号，我们引入了一种空间先验标签方法，以指导视觉-语言模型生成合理的操作顺序进行蒸馏。我们在包含163,222个不同难度样本的操作顺序基准上评估了OrderMind。在仿真和实际环境中的广泛实验表明，我们的方法在有效性与效率方面显著优于现有方法，能够在杂乱场景中实现稳健的操作。', 'title_zh': '学习空间感知的操作顺序'}
{'arxiv_id': 'arXiv:2510.25122', 'title': 'NanoVLA: Routing Decoupled Vision-Language Understanding for Nano-sized Generalist Robotic Policies', 'authors': 'Jiahong Chen, Jing Wang, Long Chen, Chuwei Cai, Jinghui Lu', 'link': 'https://arxiv.org/abs/2510.25122', 'abstract': 'Vision-language-action (VLA) models have significantly advanced robotic manipulation by integrating vision-language models (VLMs), and action decoders into a unified architecture. However, their deployment on resource-constrained edge devices, such as mobile robots or embedded systems (e.g., Jetson Orin Nano), remains challenging due to high computational demands, especially in real-world scenarios where power, latency, and computational resources are critical. To close this gap, we introduce Nano-scale Vision-Language Action (NanoVLA), a family of lightweight VLA architectures that achieve high performance with minimal resources. Our core innovations include: (1) vision-language decoupling that moves conventional early vision and language inputs fusion in VLM to late stage, achieving better performance while enabling caching and reduce inference overhead and latency; (2) long-short action chunking to ensure smooth, coherent multi-step planning without sacrificing real-time responsiveness; (3) dynamic routing that adaptively assigns lightweight or heavy backbones based on task complexity, further optimizing inference efficiency. Experimental results on several benchmarks, as well as real-world deployments, demonstrate that NanoVLA achieves up to 52x faster inference on edge devices compared to previous state-of-the-art VLA models, with 98% less parameters while maintaining or surpassing their task accuracy and generalization. Ablation studies confirm that our decoupling strategy preserves cross-task transferability, and the routing module enhances cost-performance trade-offs, enabling practical, high-precision robotic manipulation on resource-constrained hardware.', 'abstract_zh': 'Nano尺度视觉-语言-行动（NanoVLA）模型', 'title_zh': 'NanoVLA: 用于纳米级通用机器人政策的路由解耦视觉-语言理解'}
{'arxiv_id': 'arXiv:2510.25086', 'title': 'Mean-Shift Theory and Its Applications in Swarm Robotics: A New Way to Enhance the Efficiency of Multi-Robot Collaboration', 'authors': 'Guibin Sun, Jinhu Lü, Kexin Liu, Zhenqian Wang, Guanrong Chen', 'link': 'https://arxiv.org/abs/2510.25086', 'abstract': 'Swarms evolving from collective behaviors among multiple individuals are commonly seen in nature, which enables biological systems to exhibit more efficient and robust collaboration. Creating similar swarm intelligence in engineered robots poses challenges to the design of collaborative algorithms that can be programmed at large scales. The assignment-based method has played an eminent role for a very long time in solving collaboration problems of robot swarms. However, it faces fundamental limitations in terms of efficiency and robustness due to its unscalability to swarm variants. This article presents a tutorial review on recent advances in assignment-free collaboration of robot swarms, focusing on the problem of shape formation. A key theoretical component is the recently developed \\emph{mean-shift exploration} strategy, which improves the collaboration efficiency of large-scale swarms by dozens of times. Further, the efficiency improvement is more significant as the swarm scale increases. Finally, this article discusses three important applications of the mean-shift exploration strategy, including precise shape formation, area coverage formation, and maneuvering formation, as well as their corresponding industrial scenarios in smart warehousing, area exploration, and cargo transportation.', 'abstract_zh': '基于任务分配的机器人集群协作进化的近期进展：聚焦形状形成', 'title_zh': '平均位移理论及其在群体机器人中的应用：增强多机器人协作效率的新途径'}
{'arxiv_id': 'arXiv:2510.25072', 'title': 'Non-Invasive Calibration Of A Stewart Platform By Photogrammetry', 'authors': 'Sourabh Karmakar, Cameron J. Turner', 'link': 'https://arxiv.org/abs/2510.25072', 'abstract': "Accurate calibration of a Stewart platform is important for their precise and efficient operation. However, the calibration of these platforms using forward kinematics is a challenge for researchers because forward kinematics normally generates multiple feasible and unfeasible solutions for any pose of the moving platform. The complex kinematic relations among the six actuator paths connecting the fixed base to the moving platform further compound the difficulty in establishing a straightforward and efficient calibration method. The authors developed a new forward kinematics-based calibration method using Denavit-Hartenberg convention and used the Stewart platform Tiger 66.1 developed in their lab for experimenting with the photogrammetry-based calibration strategies described in this paper. This system became operational upon completion of construction, marking its inaugural use. The authors used their calibration model for estimating the errors in the system and adopted three compensation options or strategies as per Least Square method to improve the accuracy of the system. These strategies leveraged a high-resolution digital camera and off-the-shelf software to capture the poses of the moving platform's center. This process is non-invasive and does not need any additional equipment to be attached to the hexapod or any alteration of the hexapod hardware. This photogrammetry-based calibration process involves multiple high-resolution images from different angles to measure the position and orientation of the platform center in the three-dimensional space. The Target poses and Actual poses are then compared, and the error compensations are estimated using the Least-Squared methods to calculate the Predicted poses. Results from each of the three compensation approaches demonstrated noticeable enhancements in platform pose accuracies, suggesting room for further improvements.", 'abstract_zh': 'Stewart平台基于正向运动学的准确标定方法及其在Tiger 66.1平台上的实验研究', 'title_zh': '基于摄影测量的非侵入式 Stewart 平台标定'}
{'arxiv_id': 'arXiv:2510.25053', 'title': 'Scalable predictive processing framework for multitask caregiving robots', 'authors': 'Hayato Idei, Tamon Miyake, Tetsuya Ogata, Yuichi Yamashita', 'link': 'https://arxiv.org/abs/2510.25053', 'abstract': "The rapid aging of societies is intensifying demand for autonomous care robots; however, most existing systems are task-specific and rely on handcrafted preprocessing, limiting their ability to generalize across diverse scenarios. A prevailing theory in cognitive neuroscience proposes that the human brain operates through hierarchical predictive processing, which underlies flexible cognition and behavior by integrating multimodal sensory signals. Inspired by this principle, we introduce a hierarchical multimodal recurrent neural network grounded in predictive processing under the free-energy principle, capable of directly integrating over 30,000-dimensional visuo-proprioceptive inputs without dimensionality reduction. The model was able to learn two representative caregiving tasks, rigid-body repositioning and flexible-towel wiping, without task-specific feature engineering. We demonstrate three key properties: (i) self-organization of hierarchical latent dynamics that regulate task transitions, capture variability in uncertainty, and infer occluded states; (ii) robustness to degraded vision through visuo-proprioceptive integration; and (iii) asymmetric interference in multitask learning, where the more variable wiping task had little influence on repositioning, whereas learning the repositioning task led to a modest reduction in wiping performance, while the model maintained overall robustness. Although the evaluation was limited to simulation, these results establish predictive processing as a universal and scalable computational principle, pointing toward robust, flexible, and autonomous caregiving robots while offering theoretical insight into the human brain's ability to achieve flexible adaptation in uncertain real-world environments.", 'abstract_zh': '社会迅速老龄化加剧了对自主护理机器人的需求；然而，现有系统大多任务特定且依赖手工特征预处理，限制了它们在不同场景下的通用性。受认知神经科学中层级预测加工理论的启发，我们提出了一种基于自由能量原则的层级多模态循环神经网络，该模型可以直接整合超过30,000维的视觉- proprioceptive输入而无需降维。该模型能够无需特定任务特征工程学习两种典型的护理任务：刚体重新定位和灵活毛巾擦拭。我们展示了三种关键特性：（i）层级潜在动态的自我组织，调节任务转换，捕获不确定性变异，并推断被遮挡的状态；（ii）通过整合视觉- proprioceptive信号对视觉退化具有鲁棒性；（iii）多任务学习中的不对称干扰，在擦拭任务变异性较大时对重新定位影响较小，而学习重新定位任务时轻度降低了擦拭性能，但模型整体保持鲁棒性。尽管评估仅限于模拟，这些结果确立了预测加工作为一种普遍且可扩展的计算原则，并为实现鲁棒性、灵活性和自主护理机器人指明了方向，同时为人类大脑在不确定的现实环境中实现灵活适应提供了理论见解。', 'title_zh': '可扩展的多任务护理机器人预测处理框架'}
{'arxiv_id': 'arXiv:2510.24994', 'title': 'Defect Mitigation for Robot Arm-based Additive Manufacturing Utilizing Intelligent Control and IOT', 'authors': 'Matsive Ali, Blake Gassen, Sen Liu', 'link': 'https://arxiv.org/abs/2510.24994', 'abstract': 'This paper presents an integrated robotic fused deposition modeling additive manufacturing system featuring closed-loop thermal control and intelligent in-situ defect correction using a 6-degree of freedom robotic arm and an Oak-D camera. The robot arm end effector was modified to mount an E3D hotend thermally regulated by an IoT microcontroller, enabling precise temperature control through real-time feedback. Filament extrusion system was synchronized with robotic motion, coordinated via ROS2, ensuring consistent deposition along complex trajectories. A vision system based on OpenCV detects layer-wise defects position, commanding autonomous re-extrusion at identified sites. Experimental validation demonstrated successful defect mitigation in printing operations. The integrated system effectively addresses challenges real-time quality assurance. Inverse kinematics were used for motion planning, while homography transformations corrected camera perspectives for accurate defect localization. The intelligent system successfully mitigated surface anomalies without interrupting the print process. By combining real-time thermal regulation, motion control, and intelligent defect detection & correction, this architecture establishes a scalable and adaptive robotic additive manufacturing framework suitable for aerospace, biomedical, and industrial applications.', 'abstract_zh': '一种集成的闭环热控和智能就地缺陷纠正的6自由度机器人融沉积增材制造系统', 'title_zh': '基于智能控制与物联网的机器人手臂增材制造缺陷 mitigation 研究'}
{'arxiv_id': 'arXiv:2510.24972', 'title': 'Smooth path planning with safety margins using Piece-Wise Bezier curves', 'authors': 'Iancu Andrei, Marius Kloetzer, Cristian Mahulea, Catalin Dosoftei', 'link': 'https://arxiv.org/abs/2510.24972', 'abstract': 'In this paper, we propose a computationally efficient quadratic programming (QP) approach for generating smooth, $C^1$ continuous paths for mobile robots using piece-wise quadratic Bezier (PWB) curves. Our method explicitly incorporates safety margins within a structured optimization framework, balancing trajectory smoothness and robustness with manageable numerical complexity suitable for real-time and embedded applications. Comparative simulations demonstrate clear advantages over traditional piece-wise linear (PWL) path planning methods, showing reduced trajectory deviations, enhanced robustness, and improved overall path quality. These benefits are validated through simulations using a Pure-Pursuit controller in representative scenarios, highlighting the practical effectiveness and scalability of our approach for safe navigation.', 'abstract_zh': '本文提出了一种计算高效的二次规划（QP）方法，用于利用分段二次贝zier（PWB）曲线生成移动机器人平滑且$C^1$连续的路径。该方法在结构化的优化框架中明确地引入了安全裕量，平衡了轨迹的平滑性和鲁棒性，并且具有可管理的数值复杂性，适用于实时和嵌入式应用。与传统的分段线性（PWL）路径规划方法相比，比较仿真展示了明显的优点，包括轨迹偏差减小、鲁棒性增强和整体路径质量提高。这些优势通过使用纯追赶控制器在代表性场景下的仿真得到验证，突显了该方法在安全导航中的实用效果和可扩展性。', 'title_zh': '使用分段Bezier曲线进行具有安全余量的平滑路径规划'}
{'arxiv_id': 'arXiv:2510.24949', 'title': 'SCOUT: A Lightweight Framework for Scenario Coverage Assessment in Autonomous Driving', 'authors': 'Anil Yildiz, Sarah M. Thornton, Carl Hildebrandt, Sreeja Roy-Singh, Mykel J. Kochenderfer', 'link': 'https://arxiv.org/abs/2510.24949', 'abstract': "Assessing scenario coverage is crucial for evaluating the robustness of autonomous agents, yet existing methods rely on expensive human annotations or computationally intensive Large Vision-Language Models (LVLMs). These approaches are impractical for large-scale deployment due to cost and efficiency constraints. To address these shortcomings, we propose SCOUT (Scenario Coverage Oversight and Understanding Tool), a lightweight surrogate model designed to predict scenario coverage labels directly from an agent's latent sensor representations. SCOUT is trained through a distillation process, learning to approximate LVLM-generated coverage labels while eliminating the need for continuous LVLM inference or human annotation. By leveraging precomputed perception features, SCOUT avoids redundant computations and enables fast, scalable scenario coverage estimation. We evaluate our method across a large dataset of real-life autonomous navigation scenarios, demonstrating that it maintains high accuracy while significantly reducing computational cost. Our results show that SCOUT provides an effective and practical alternative for large-scale coverage analysis. While its performance depends on the quality of LVLM-generated training labels, SCOUT represents a major step toward efficient scenario coverage oversight in autonomous systems.", 'abstract_zh': '情景覆盖评估对于评估自主代理的鲁棒性至关重要，但现有方法依赖昂贵的人工注释或计算密集型大型视觉-语言模型。这些方法由于成本和效率限制，难以大规模部署。为解决这些问题，我们提出了SCOUT（情景覆盖监督和理解工具），这是一种轻量级的替代模型，设计用于从代理的潜藏传感器表示直接预测情景覆盖标签。SCOUT通过一个蒸馏过程进行训练，学习近似大型视觉-语言模型生成的覆盖标签，从而消除持续性大型视觉-语言模型推理或人工注释的需要。通过利用预计算的感知特征，SCOUT避免了冗余计算，实现了快速、可扩展的情景覆盖评估。我们在大型真实自主导航场景数据集中评估了该方法，结果显示其保持了高精度并显著降低了计算成本。我们的结果表明，SCOUT提供了一种有效且实用的大规模覆盖分析替代方案。尽管其性能依赖于大型视觉-语言模型生成训练标签的质量，但SCOUT代表了自主系统中高效情景覆盖监督的一个重要步骤。', 'title_zh': 'SCOUT: 一种轻量级的自动驾驶场景覆盖评估框架'}
{'arxiv_id': 'arXiv:2510.25616', 'title': "Don't Blind Your VLA: Aligning Visual Representations for OOD Generalization", 'authors': 'Nikita Kachaev, Mikhail Kolosov, Daniil Zelezetsky, Alexey K. Kovalev, Aleksandr I. Panov', 'link': 'https://arxiv.org/abs/2510.25616', 'abstract': "The growing success of Vision-Language-Action (VLA) models stems from the promise that pretrained Vision-Language Models (VLMs) can endow agents with transferable world knowledge and vision-language (VL) grounding, laying a foundation for action models with broader generalization. Yet when these VLMs are adapted to the action modality, it remains unclear to what extent their original VL representations and knowledge are preserved. In this work, we conduct a systematic study of representation retention during VLA fine-tuning, showing that naive action fine-tuning leads to degradation of visual representations. To characterize and measure these effects, we probe VLA's hidden representations and analyze attention maps, further, we design a set of targeted tasks and methods that contrast VLA models with their counterpart VLMs, isolating changes in VL capabilities induced by action fine-tuning. We further evaluate a range of strategies for aligning visual representations and introduce a simple yet effective method that mitigates degradation and yields improved generalization to out-of-distribution (OOD) scenarios. Taken together, our analysis clarifies the trade-off between action fine-tuning and the degradation of VL representations and highlights practical approaches to recover inherited VL capabilities. Code is publicly available: this https URL", 'abstract_zh': 'Vision-Language-Action (VLA) 模型成功率的增长得益于预训练视觉-语言模型（VLMs）能够赋予代理可迁移的世界知识和视觉-语言对接，为具有更广泛泛化的动作模型奠定了基础。然而，当这些 VLMs 被适应动作模态时，尚不清楚其原始的视觉-语言表示和知识在多大程度上得以保留。在本文中，我们系统研究了 VLA 微调过程中的表示保留情况，发现简单的动作微调会导致视觉表示的退化。为表征和衡量这些影响，我们探究了 VLA 的隐藏表示，分析了注意力图，并进一步设计了一组针对性的任务和方法，将 VLA 模型与其对应的 VLMs 对比，分离由动作微调引起的视觉-语言能力的变化。我们进一步评估了多种视觉表示对齐策略，并提出了一种简单有效的缓解方法，减轻退化并提高对分布外（OOD）场景的泛化能力。我们的分析阐明了动作微调与视觉-语言表示退化之间的权衡，并强调了恢复继承的视觉-语言能力的实用方法。代码已公开：this https URL。', 'title_zh': '不要盲目遮蔽VLA：对OOD泛化的视觉表示对齐'}
{'arxiv_id': 'arXiv:2510.25597', 'title': 'Incorporating Social Awareness into Control of Unknown Multi-Agent Systems: A Real-Time Spatiotemporal Tubes Approach', 'authors': 'Siddhartha Upadhyay, Ratnangshu Das, Pushpak Jagtap', 'link': 'https://arxiv.org/abs/2510.25597', 'abstract': 'This paper presents a decentralized control framework that incorporates social awareness into multi-agent systems with unknown dynamics to achieve prescribed-time reach-avoid-stay tasks in dynamic environments. Each agent is assigned a social awareness index that quantifies its level of cooperation or self-interest, allowing heterogeneous social behaviors within the system. Building on the spatiotemporal tube (STT) framework, we propose a real-time STT framework that synthesizes tubes online for each agent while capturing its social interactions with others. A closed-form, approximation-free control law is derived to ensure that each agent remains within its evolving STT, thereby avoiding dynamic obstacles while also preventing inter-agent collisions in a socially aware manner, and reaching the target within a prescribed time. The proposed approach provides formal guarantees on safety and timing, and is computationally lightweight, model-free, and robust to unknown disturbances. The effectiveness and scalability of the framework are validated through simulation and hardware experiments on a 2D omnidirectional', 'abstract_zh': '本文提出了一种将社会意识融入具有未知动力学的多智能体系统中的去中心化控制框架，以在动态环境中实现指定时间的避碰驻留任务。每个智能体被分配一个社会意识指数，量化其合作或自我中心的程度，允许系统内存在异质社会行为。基于时空管（STT）框架，我们提出了一种实时STT框架，该框架在线为每个智能体综合时空管，同时捕捉其与其他智能体的社会互动。推导出一种封闭形式的控制律，确保每个智能体保持在其不断变化的时空管内，从而避免动态障碍物，同时以社会意识的方式防止智能体间的碰撞，并在指定时间内到达目标。所提出的方法在安全性与时序方面提供了形式保证，计算量轻，无需模型，对未知干扰具有鲁棒性。通过2D全向运动的仿真和硬件实验验证了该框架的有效性和可扩展性。', 'title_zh': '将社会意识融入未知多智能体系统的控制：一种实时空时管方法'}
{'arxiv_id': 'arXiv:2510.25463', 'title': 'SPADE: Sparsity Adaptive Depth Estimator for Zero-Shot, Real-Time, Monocular Depth Estimation in Underwater Environments', 'authors': 'Hongjie Zhang, Gideon Billings, Stefan B. Williams', 'link': 'https://arxiv.org/abs/2510.25463', 'abstract': 'Underwater infrastructure requires frequent inspection and maintenance due to harsh marine conditions. Current reliance on human divers or remotely operated vehicles is limited by perceptual and operational challenges, especially around complex structures or in turbid water. Enhancing the spatial awareness of underwater vehicles is key to reducing piloting risks and enabling greater autonomy. To address these challenges, we present SPADE: SParsity Adaptive Depth Estimator, a monocular depth estimation pipeline that combines pre-trained relative depth estimator with sparse depth priors to produce dense, metric scale depth maps. Our two-stage approach first scales the relative depth map with the sparse depth points, then refines the final metric prediction with our proposed Cascade Conv-Deformable Transformer blocks. Our approach achieves improved accuracy and generalisation over state-of-the-art baselines and runs efficiently at over 15 FPS on embedded hardware, promising to support practical underwater inspection and intervention. This work has been submitted to IEEE Journal of Oceanic Engineering Special Issue of AUV 2026.', 'abstract_zh': '水下基础设施由于恶劣的海洋条件需要经常进行检查和维护。目前依赖于潜水员或遥控水下机器人受限于感知和操作挑战，尤其是在复杂结构周围或浑浊水域中。增强水下车辆的空间意识是减少操作风险和实现更高自主性的关键。为解决这些挑战，我们提出SPADE：稀疏自适应深度估计器，这是一种结合预训练的相对深度估计器和稀疏深度先验的单目深度估计流水线，生成稠密的、以米为尺度的深度图。我们的两阶段方法首先使用稀疏深度点缩放相对深度图，然后使用我们提出的级联Conv-变形变压器块 refine 最终的米级预测。我们的方法在嵌入式硬件上以每秒超过15帧的速度运行，提高了准确性和泛化能力，有望支持实用的水下检查和干预。该工作已提交给IEEE海洋工程期刊2026年自主水下机器人特刊。', 'title_zh': 'SPADE: 适应稀疏性的深度估计器，适用于海洋环境中的零样本、实时单目深度估计'}
{'arxiv_id': 'arXiv:2510.25314', 'title': 'Seeing Clearly and Deeply: An RGBD Imaging Approach with a Bio-inspired Monocentric Design', 'authors': 'Zongxi Yu, Xiaolong Qian, Shaohua Gao, Qi Jiang, Yao Gao, Kailun Yang, Kaiwei Wang', 'link': 'https://arxiv.org/abs/2510.25314', 'abstract': 'Achieving high-fidelity, compact RGBD imaging presents a dual challenge: conventional compact optics struggle with RGB sharpness across the entire depth-of-field, while software-only Monocular Depth Estimation (MDE) is an ill-posed problem reliant on unreliable semantic priors. While deep optics with elements like DOEs can encode depth, they introduce trade-offs in fabrication complexity and chromatic aberrations, compromising simplicity. To address this, we first introduce a novel bio-inspired all-spherical monocentric lens, around which we build the Bionic Monocentric Imaging (BMI) framework, a holistic co-design. This optical design naturally encodes depth into its depth-varying Point Spread Functions (PSFs) without requiring complex diffractive or freeform elements. We establish a rigorous physically-based forward model to generate a synthetic dataset by precisely simulating the optical degradation process. This simulation pipeline is co-designed with a dual-head, multi-scale reconstruction network that employs a shared encoder to jointly recover a high-fidelity All-in-Focus (AiF) image and a precise depth map from a single coded capture. Extensive experiments validate the state-of-the-art performance of the proposed framework. In depth estimation, the method attains an Abs Rel of 0.026 and an RMSE of 0.130, markedly outperforming leading software-only approaches and other deep optics systems. For image restoration, the system achieves an SSIM of 0.960 and a perceptual LPIPS score of 0.082, thereby confirming a superior balance between image fidelity and depth accuracy. This study illustrates that the integration of bio-inspired, fully spherical optics with a joint reconstruction algorithm constitutes an effective strategy for addressing the intrinsic challenges in high-performance compact RGBD imaging. Source code will be publicly available at this https URL.', 'abstract_zh': '实现高保真度、紧凑型RGBD成像面临双重挑战：传统紧凑型光学元件在整景深范围内难以实现RGB清晰度，而仅依靠软件的单目深度估计方法则依赖不可靠的语义先验，是一个病态问题。虽然有使用DOE等元件的深度光学技术可以编码深度信息，但它们引入了制造复杂性和色差的权衡，牺牲了简单性。为解决这一问题，我们首先提出了一种新颖的生物启发全球心单中心透镜，并构建了仿生单中心成像（BMI）框架，这是一种整体协同设计。这种光学设计天然地通过其随深度变化的点扩展函数（PSFs）编码深度信息，无需复杂衍射或自由形式元件。我们建立了一个严格的基于物理的前向模型，通过精确模拟光学退化过程来生成合成数据集。该模拟管道与一个采用共享编码器的双头多尺度重建网络协同设计，可以共同从单次编码捕获中恢复高保真全焦图像和精确的深度图。大量的实验验证了所提出框架的先进性能。在深度估计中，该方法取得了Abs Rel为0.026和RMSE为0.130的结果，明显优于领先的纯软件方法和其他深度光学系统。对于图像恢复，系统获得了SSIM为0.960和感知LPIPS分数为0.082的结果，从而证实了图像保真度和深度准确性之间的优越平衡。这项研究展示了将生物启发的全球心光学与联合重建算法相结合是解决高性能紧凑型RGBD成像固有挑战的有效策略。源代码将在此网址公开。', 'title_zh': '清晰而深刻地 Seeing 一种生物启发的一元中心设计的 RGBD 成像方法'}
{'arxiv_id': 'arXiv:2510.24795', 'title': 'A Survey on Efficient Vision-Language-Action Models', 'authors': 'Zhaoshu Yu, Bo Wang, Pengpeng Zeng, Haonan Zhang, Ji Zhang, Lianli Gao, Jingkuan Song, Nicu Sebe, Heng Tao Shen', 'link': 'https://arxiv.org/abs/2510.24795', 'abstract': 'Vision-Language-Action models (VLAs) represent a significant frontier in embodied intelligence, aiming to bridge digital knowledge with physical-world interaction. While these models have demonstrated remarkable generalist capabilities, their deployment is severely hampered by the substantial computational and data requirements inherent to their underlying large-scale foundation models. Motivated by the urgent need to address these challenges, this survey presents the first comprehensive review of Efficient Vision-Language-Action models (Efficient VLAs) across the entire data-model-training process. Specifically, we introduce a unified taxonomy to systematically organize the disparate efforts in this domain, categorizing current techniques into three core pillars: (1) Efficient Model Design, focusing on efficient architectures and model compression; (2) Efficient Training, which reduces computational burdens during model learning; and (3) Efficient Data Collection, which addresses the bottlenecks in acquiring and utilizing robotic data. Through a critical review of state-of-the-art methods within this framework, this survey not only establishes a foundational reference for the community but also summarizes representative applications, delineates key challenges, and charts a roadmap for future research. We maintain a continuously updated project page to track our latest developments: this https URL', 'abstract_zh': '高效视觉-语言-动作模型（Efficient Vision-Language-Action Models）：整个数据-模型-训练过程的综述', 'title_zh': '高效视觉-语言-动作模型综述'}
{'arxiv_id': 'arXiv:2510.24773', 'title': 'Point-level Uncertainty Evaluation of Mobile Laser Scanning Point Clouds', 'authors': 'Ziyang Xu, Olaf Wysocki, Christoph Holst', 'link': 'https://arxiv.org/abs/2510.24773', 'abstract': 'Reliable quantification of uncertainty in Mobile Laser Scanning (MLS) point clouds is essential for ensuring the accuracy and credibility of downstream applications such as 3D mapping, modeling, and change analysis. Traditional backward uncertainty modeling heavily rely on high-precision reference data, which are often costly or infeasible to obtain at large scales. To address this issue, this study proposes a machine learning-based framework for point-level uncertainty evaluation that learns the relationship between local geometric features and point-level errors. The framework is implemented using two ensemble learning models, Random Forest (RF) and XGBoost, which are trained and validated on a spatially partitioned real-world dataset to avoid data leakage. Experimental results demonstrate that both models can effectively capture the nonlinear relationships between geometric characteristics and uncertainty, achieving mean ROC-AUC values above 0.87. The analysis further reveals that geometric features describing elevation variation, point density, and local structural complexity play a dominant role in predicting uncertainty. The proposed framework offers a data-driven perspective of uncertainty evaluation, providing a scalable and adaptable foundation for future quality control and error analysis of large-scale point clouds.', 'abstract_zh': '移动激光扫描（MLS）点云中不确定性可靠的量化对于确保其在三维制图、建模和变化分析等下游应用中的准确性和可信度至关重要。传统基于后向模型的不确定性量化依赖于高精度参考数据，但在大规模应用中往往成本高昂或不可行。为解决这一问题，本研究提出了一种基于机器学习的点级不确定性评估框架，该框架通过学习局部几何特征与点级误差之间的关系来进行不确定性评估。该框架使用随机森林（RF）和XGBoost两种集成学习模型实现，并通过空间分区的真实数据集进行训练和验证，以避免数据泄露。实验结果表明，两种模型都能有效捕捉几何特征与不确定性之间的非线性关系，均达到平均ROC-AUC值高于0.87。进一步的分析显示，描述高程变化、点密度和局部结构复杂性的几何特征在预测不确定性方面发挥着主导作用。所提出的框架提供了基于数据的不确定性评估视角，为大规模点云的质量控制和误差分析提供了可扩展和适应性强的基础。', 'title_zh': '移动激光扫描点云的点级不确定性评估'}
{'arxiv_id': 'arXiv:2510.24734', 'title': 'DrivingScene: A Multi-Task Online Feed-Forward 3D Gaussian Splatting Method for Dynamic Driving Scenes', 'authors': 'Qirui Hou, Wenzhang Sun, Chang Zeng, Chunfeng Wang, Hao Li, Jianxun Cui', 'link': 'https://arxiv.org/abs/2510.24734', 'abstract': 'Real-time, high-fidelity reconstruction of dynamic driving scenes is challenged by complex dynamics and sparse views, with prior methods struggling to balance quality and efficiency. We propose DrivingScene, an online, feed-forward framework that reconstructs 4D dynamic scenes from only two consecutive surround-view images. Our key innovation is a lightweight residual flow network that predicts the non-rigid motion of dynamic objects per camera on top of a learned static scene prior, explicitly modeling dynamics via scene flow. We also introduce a coarse-to-fine training paradigm that circumvents the instabilities common to end-to-end approaches. Experiments on nuScenes dataset show our image-only method simultaneously generates high-quality depth, scene flow, and 3D Gaussian point clouds online, significantly outperforming state-of-the-art methods in both dynamic reconstruction and novel view synthesis.', 'abstract_zh': '实时高保真动态驾驶场景重建受到复杂动力学和稀疏视图的挑战，先前方法难以在质量和效率之间取得平衡。我们提出DrivingScene，这是一种在线前馈框架，仅从连续的两个全景图像中重建4D动态场景。我们的核心创新是一种轻量级残差流网络，该网络在学到的静止场景先验之上预测每个摄像头的非刚性动态物体运动，并通过场景流显式建模动态。我们还引入了一种粗到细的训练范式，避免了端到端方法中常见的不稳定性。在nuScenes数据集上的实验显示，我们的图像-only方法能够在线生成高质量的深度、场景流和3D高斯点云，显著优于现有最佳方法在动态重建和新颖视图合成方面的效果。', 'title_zh': 'DrivingScene: 一种用于动态驾驶场景的多任务在线前馈3D高斯点方法'}
