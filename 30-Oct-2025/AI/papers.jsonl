{'arxiv_id': 'arXiv:2510.25758', 'title': 'TheraMind: A Strategic and Adaptive Agent for Longitudinal Psychological Counseling', 'authors': 'He Hu, Yucheng Zhou, Chiyuan Ma, Qianning Wang, Zheng Zhang, Fei Ma, Laizhong Cui, Qi Tian', 'link': 'https://arxiv.org/abs/2510.25758', 'abstract': "Large language models (LLMs) in psychological counseling have attracted increasing attention. However, existing approaches often lack emotional understanding, adaptive strategies, and the use of therapeutic methods across multiple sessions with long-term memory, leaving them far from real clinical practice. To address these critical gaps, we introduce TheraMind, a strategic and adaptive agent for longitudinal psychological counseling. The cornerstone of TheraMind is a novel dual-loop architecture that decouples the complex counseling process into an Intra-Session Loop for tactical dialogue management and a Cross-Session Loop for strategic therapeutic planning. The Intra-Session Loop perceives the patient's emotional state to dynamically select response strategies while leveraging cross-session memory to ensure continuity. Crucially, the Cross-Session Loop empowers the agent with long-term adaptability by evaluating the efficacy of the applied therapy after each session and adjusting the method for subsequent interactions. We validate our approach in a high-fidelity simulation environment grounded in real clinical cases. Extensive evaluations show that TheraMind outperforms other methods, especially on multi-session metrics like Coherence, Flexibility, and Therapeutic Attunement, validating the effectiveness of its dual-loop design in emulating strategic, adaptive, and longitudinal therapeutic behavior. The code is publicly available at this https URL.", 'abstract_zh': 'å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¿ƒç†è¾…å¯¼ä¸­çš„åº”ç”¨å¼•èµ·äº†è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å¾€å¾€ç¼ºä¹æƒ…æ„Ÿç†è§£ã€é€‚åº”æ€§ç­–ç•¥ä»¥åŠå¤šç–—ç¨‹é•¿æœŸè®°å¿†ä¸‹çš„æ²»ç–—æ–¹æ³•ä½¿ç”¨ï¼Œä½¿å…¶éš¾ä»¥è¾¾åˆ°ä¸´åºŠå®è·µçš„æ ‡å‡†ã€‚ä¸ºå¡«è¡¥è¿™äº›å…³é”®ç©ºç™½ï¼Œæˆ‘ä»¬å¼•å…¥äº†TheraMindï¼Œè¿™æ˜¯ä¸€ç§é€‚ç”¨äºçºµå‘å¿ƒç†è¾…å¯¼çš„æˆ˜ç•¥æ€§å’Œé€‚åº”æ€§ä»£ç†ã€‚TheraMindçš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªæ–°é¢–çš„åŒç¯æ¶æ„ï¼Œå°†å¤æ‚çš„å’¨è¯¢è¿‡ç¨‹åˆ†è§£ä¸ºåœ¨ä¼šè¯å†…éƒ¨è¿›è¡Œæˆ˜æœ¯å¯¹è¯ç®¡ç†çš„ä¼šè¯å†…ç¯å’Œåœ¨ä¼šè¯ä¹‹é—´è¿›è¡Œæˆ˜ç•¥æ€§æ²»ç–—è§„åˆ’çš„è·¨ä¼šè¯ç¯ã€‚ä¼šè¯å†…ç¯æ„ŸçŸ¥æ‚£è€…çš„æƒ…æ„ŸçŠ¶æ€ï¼ŒåŠ¨æ€é€‰æ‹©å“åº”ç­–ç•¥ï¼ŒåŒæ—¶åˆ©ç”¨è·¨ä¼šè¯è®°å¿†ç¡®ä¿è¿ç»­æ€§ã€‚æœ€å…³é”®çš„æ˜¯ï¼Œè·¨ä¼šè¯ç¯é€šè¿‡æ¯ä¼šè¯è¯„ä¼°æ‰€åº”ç”¨ç–—æ³•çš„æœ‰æ•ˆæ€§å¹¶è°ƒæ•´åç»­äº¤äº’çš„æ–¹æ³•ï¼Œèµ‹äºˆä»£ç†é•¿æœŸé€‚åº”æ€§ã€‚æˆ‘ä»¬é€šè¿‡åŸºäºçœŸå®ä¸´åºŠæ¡ˆä¾‹çš„é«˜ä¿çœŸæ¨¡æ‹Ÿç¯å¢ƒéªŒè¯äº†è¯¥æ–¹æ³•ã€‚å¹¿æ³›çš„è¯„ä¼°è¡¨æ˜ï¼ŒTheraMindåœ¨åŒ…æ‹¬ä¸€è‡´æ€§å’Œçµæ´»æ€§ç­‰å¤šä¼šè¯æŒ‡æ ‡ä¸Šä¼˜äºå…¶ä»–æ–¹æ³•ï¼ŒéªŒè¯äº†å…¶åŒç¯è®¾è®¡åœ¨æ¨¡æ‹Ÿæˆ˜ç•¥æ€§ã€é€‚åº”æ€§å’Œçºµå‘æ²»ç–—è¡Œä¸ºæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚ä»£ç å·²å…¬å¼€ï¼Œå¯é€šè¿‡ä»¥ä¸‹é“¾æ¥è®¿é—®ï¼šthis https URLã€‚', 'title_zh': 'TheraMind: ä¸€ç§æˆ˜ç•¥æ€§é€‚åº”æ€§ longitudinal å¿ƒç†å’¨è¯¢ä»£ç†'}
{'arxiv_id': 'arXiv:2510.25724', 'title': 'BambooKG: A Neurobiologically-inspired Frequency-Weight Knowledge Graph', 'authors': 'Vanya Arikutharam, Arkadiy Ukolov', 'link': 'https://arxiv.org/abs/2510.25724', 'abstract': 'Retrieval-Augmented Generation allows LLMs to access external knowledge, reducing hallucinations and ageing-data issues. However, it treats retrieved chunks independently and struggles with multi-hop or relational reasoning, especially across documents. Knowledge graphs enhance this by capturing the relationships between entities using triplets, enabling structured, multi-chunk reasoning. However, these tend to miss information that fails to conform to the triplet structure. We introduce BambooKG, a knowledge graph with frequency-based weights on non-triplet edges which reflect link strength, drawing on the Hebbian principle of "fire together, wire together". This decreases information loss and results in improved performance on single- and multi-hop reasoning, outperforming the existing solutions.', 'abstract_zh': 'åŸºäºæ£€ç´¢å¢å¼ºçš„ç”Ÿæˆä½¿å¤§è¯­è¨€æ¨¡å‹èƒ½å¤Ÿè®¿é—®å¤–éƒ¨çŸ¥è¯†ï¼Œå‡å°‘å¹»è§‰å’Œæ•°æ®è€åŒ–é—®é¢˜ã€‚ç„¶è€Œï¼Œå®ƒç‹¬ç«‹å¤„ç†æ£€ç´¢ç‰‡æ®µï¼Œåœ¨å¤„ç†å¤šè·³æˆ–å…³ç³»æ¨ç†ï¼Œå°¤å…¶æ˜¯åœ¨è·¨æ–‡æ¡£æ—¶ï¼Œå­˜åœ¨å›°éš¾ã€‚çŸ¥è¯†å›¾è°±é€šè¿‡ä½¿ç”¨ä¸‰å…ƒç»„æ•æ‰å®ä½“ä¹‹é—´çš„å…³ç³»ï¼Œä»è€Œå®ç°ç»“æ„åŒ–çš„å¤šç‰‡æ®µæ¨ç†ã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•å¾€å¾€ä¸¢å¤±ä¸ç¬¦åˆä¸‰å…ƒç»„ç»“æ„çš„ä¿¡æ¯ã€‚æˆ‘ä»¬æå‡ºBambooKGï¼Œä¸€ç§åŸºäºé¢‘ç‡æƒé‡çš„éä¸‰å…ƒç»„è¾¹çš„çŸ¥è¯†å›¾è°±ï¼Œè¿™äº›æƒé‡åæ˜ äº†è¿æ¥å¼ºåº¦ï¼Œå€Ÿé‰´äº†HebbianåŸåˆ™â€œç¥ç»å…ƒåŒæ—¶æ”¾ç”µï¼Œåˆ™è”ç»“åŠ å¼ºâ€ã€‚è¿™å‡å°‘äº†ä¿¡æ¯ä¸¢å¤±å¹¶æé«˜äº†å•è·³å’Œå¤šè·³æ¨ç†çš„æ€§èƒ½ï¼Œè¶…è¶Šäº†ç°æœ‰è§£å†³æ–¹æ¡ˆã€‚', 'title_zh': 'BambooKG: ä¸€ç§ç¥ç»ç”Ÿç‰©å­¦å¯å‘çš„é¢‘ç‡æƒé‡çŸ¥è¯†å›¾è°±'}
{'arxiv_id': 'arXiv:2510.25679', 'title': 'Navigation in a Three-Dimensional Urban Flow using Deep Reinforcement Learning', 'authors': 'Federica Tonti, Ricardo Vinuesa', 'link': 'https://arxiv.org/abs/2510.25679', 'abstract': "Unmanned Aerial Vehicles (UAVs) are increasingly populating urban areas for delivery and surveillance purposes. In this work, we develop an optimal navigation strategy based on Deep Reinforcement Learning. The environment is represented by a three-dimensional high-fidelity simulation of an urban flow, characterized by turbulence and recirculation zones. The algorithm presented here is a flow-aware Proximal Policy Optimization (PPO) combined with a Gated Transformer eXtra Large (GTrXL) architecture, giving the agent richer information about the turbulent flow field in which it navigates. The results are compared with a PPO+GTrXL without the secondary prediction tasks, a PPO combined with Long Short Term Memory (LSTM) cells and a traditional navigation algorithm. The obtained results show a significant increase in the success rate (SR) and a lower crash rate (CR) compared to a PPO+LSTM, PPO+GTrXL and the classical Zermelo's navigation algorithm, paving the way to a completely reimagined UAV landscape in complex urban environments.", 'abstract_zh': 'æ— äºº aerial è½¦ï¼ˆUAVsï¼‰è¶Šæ¥è¶Šå¤šåœ°éƒ¨ç½²åœ¨åŸå¸‚åŒºåŸŸä»¥å®ç°é…é€å’Œ surveillance ç›®çš„ã€‚æœ¬ç ”ç©¶å¼€å‘äº†ä¸€ç§åŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„ä¼˜åŒ–å¯¼èˆªç­–ç•¥ã€‚ç¯å¢ƒé€šè¿‡ä¸€ä¸ªåŒ…å«æ¹æµå’Œå¾ªç¯åŒºçš„ä¸‰ç»´é«˜ä¿çœŸåŸå¸‚æµæ¨¡æ‹Ÿæ¥è¡¨ç¤ºã€‚æœ¬ç ”ç©¶æå‡ºçš„æ–¹æ³•ç»“åˆäº†æµä½“æ„ŸçŸ¥çš„è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆPPOï¼‰ä¸é—¨æ§å˜å‹å™¨è¶…å¤§ï¼ˆGTrXLï¼‰æ¶æ„ï¼Œä½¿ä»£ç†èƒ½å¤Ÿè·å¾—å…¶å¯¼èˆªçš„æ¹æµæµåœºä¸­çš„æ›´ä¸°å¯Œä¿¡æ¯ã€‚ä¸æœªåŒ…å«æ¬¡è¦é¢„æµ‹ä»»åŠ¡çš„PPO+GTrXLã€ä¸é•¿çŸ­æœŸè®°å¿†ï¼ˆLSTMï¼‰ç»†èƒç»“åˆçš„PPOä»¥åŠä¼ ç»Ÿçš„å¯¼èˆªç®—æ³•ç›¸æ¯”ï¼Œæ‰€è·å¾—çš„ç»“æœæ˜¾ç¤ºäº†æ˜¾è‘—æé«˜çš„æˆåŠŸç‡ï¼ˆSRï¼‰å’Œè¾ƒä½çš„ç¢°æ’ç‡ï¼ˆCRï¼‰ï¼Œä¸ºå¤æ‚åŸå¸‚ç¯å¢ƒä¸­çš„å®Œå…¨é‡å¡‘çš„UAVæ™¯è§‚é“ºå¹³äº†é“è·¯ã€‚', 'title_zh': 'åŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„ä¸‰ç»´åŸå¸‚æµå¯¼èˆª'}
{'arxiv_id': 'arXiv:2510.25668', 'title': 'ALDEN: Reinforcement Learning for Active Navigation and Evidence Gathering in Long Documents', 'authors': 'Tianyu Yang, Terry Ruas, Yijun Tian, Jan Philip Wahle, Daniel Kurzawe, Bela Gipp', 'link': 'https://arxiv.org/abs/2510.25668', 'abstract': 'Vision-language models (VLMs) excel at interpreting text-rich images but struggle with long, visually complex documents that demand analysis and integration of information spread across multiple pages. Existing approaches typically rely on fixed reasoning templates or rigid pipelines, which force VLMs into a passive role and hinder both efficiency and generalization. We present Active Long-DocumEnt Navigation (ALDEN), a multi-turn reinforcement learning framework that fine-tunes VLMs as interactive agents capable of actively navigating long, visually rich documents. ALDEN introduces a novel fetch action that directly accesses the page by index, complementing the classic search action and better exploiting document structure. For dense process supervision and efficient training, we propose a rule-based cross-level reward that provides both turn- and token-level signals. To address the empirically observed training instability caused by numerous visual tokens from long documents, we further propose a visual-semantic anchoring mechanism that applies a dual-path KL-divergence constraint to stabilize visual and textual representations separately during training. Trained on a corpus constructed from three open-source datasets, ALDEN achieves state-of-the-art performance on five long-document benchmarks. Overall, ALDEN marks a step beyond passive document reading toward agents that autonomously navigate and reason across long, visually rich documents, offering a robust path to more accurate and efficient long-document understanding.', 'abstract_zh': 'æ´»è·ƒé•¿æ–‡æ¡£å¯¼èˆªï¼ˆALDENï¼‰ï¼šé¢å‘é•¿æ—¶é—´ä¸°å¯Œæ–‡æ¡£çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶', 'title_zh': 'ALDENï¼šåœ¨é•¿æ–‡æ¡£ä¸­ä¸»åŠ¨å¯¼èˆªå’Œè¯æ®æ”¶é›†çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•'}
{'arxiv_id': 'arXiv:2510.25612', 'title': 'Counterfactual-based Agent Influence Ranker for Agentic AI Workflows', 'authors': 'Amit Giloni, Chiara Picardi, Roy Betser, Shamik Bose, Aishvariya Priya Rathina Sabapathy, Roman Vainshtein', 'link': 'https://arxiv.org/abs/2510.25612', 'abstract': "An Agentic AI Workflow (AAW), also known as an LLM-based multi-agent system, is an autonomous system that assembles several LLM-based agents to work collaboratively towards a shared goal. The high autonomy, widespread adoption, and growing interest in such AAWs highlight the need for a deeper understanding of their operations, from both quality and security aspects. To this day, there are no existing methods to assess the influence of each agent on the AAW's final output. Adopting techniques from related fields is not feasible since existing methods perform only static structural analysis, which is unsuitable for inference time execution. We present Counterfactual-based Agent Influence Ranker (CAIR) - the first method for assessing the influence level of each agent on the AAW's output and determining which agents are the most influential. By performing counterfactual analysis, CAIR provides a task-agnostic analysis that can be used both offline and at inference time. We evaluate CAIR using an AAWs dataset of our creation, containing 30 different use cases with 230 different functionalities. Our evaluation showed that CAIR produces consistent rankings, outperforms baseline methods, and can easily enhance the effectiveness and relevancy of downstream tasks.", 'abstract_zh': 'åŸºäºä»£ç†çš„äººå·¥æ™ºèƒ½å·¥ä½œæµï¼ˆAAWï¼‰ï¼šä¸€ç§åŸºäºLLMçš„å¤šä»£ç†ç³»ç»Ÿè‡ªä¸»ç³»ç»Ÿï¼Œç”±å‡ ä¸ªåŸºäºLLMçš„ä»£ç†ååŒå·¥ä½œä»¥å®ç°å…±åŒç›®æ ‡ã€‚ç”±äºAAWçš„é«˜åº¦è‡ªä¸»æ€§ã€å¹¿æ³›é‡‡ç”¨å’Œå¢é•¿å…´è¶£ï¼Œæ·±å…¥äº†è§£å…¶æ“ä½œï¼ˆä»è´¨é‡å’Œå®‰å…¨æ–¹é¢ï¼‰å˜å¾—è‡³å…³é‡è¦ã€‚ç›®å‰å°šæ— æ–¹æ³•è¯„ä¼°æ¯ä¸ªä»£ç†å¯¹AAWæœ€ç»ˆè¾“å‡ºçš„å½±å“ã€‚é‡‡ç”¨ç›¸å…³é¢†åŸŸçš„æŠ€æœ¯ä¸å¯è¡Œï¼Œå› ä¸ºç°æœ‰æ–¹æ³•ä»…è¿›è¡Œé™æ€ç»“æ„åˆ†æï¼Œè¿™ä¸é€‚åˆæ¨ç†æ—¶æ‰§è¡Œã€‚æˆ‘ä»¬æå‡ºäº†åŸºäºåäº‹å®çš„ä»£ç†å½±å“æ’åå™¨ï¼ˆCAIRï¼‰â€”â€”é¦–ä¸ªç”¨äºè¯„ä¼°æ¯ä¸ªä»£ç†å¯¹AAWè¾“å‡ºå½±å“æ°´å¹³çš„æ–¹æ³•ï¼Œå¹¶ç¡®å®šå“ªäº›ä»£ç†æ˜¯æœ€å…·å½±å“åŠ›çš„ã€‚é€šè¿‡è¿›è¡Œåäº‹å®åˆ†æï¼ŒCAIRæä¾›äº†æ—¢è§†ä»»åŠ¡æ— å…³çš„åˆ†æï¼Œå¯ä»¥åœ¨ç¦»çº¿å’Œæ¨ç†æ—¶ä½¿ç”¨ã€‚æˆ‘ä»¬ä½¿ç”¨æˆ‘ä»¬åˆ›å»ºçš„åŒ…å«30ç§ä¸åŒç”¨ä¾‹å’Œ230ç§ä¸åŒåŠŸèƒ½çš„AAWæ•°æ®é›†è¯„ä¼°CAIRã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒCAIRç”Ÿæˆäº†ä¸€è‡´çš„æ’åã€ä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œå¹¶èƒ½è½»æ¾æå‡ä¸‹æ¸¸ä»»åŠ¡çš„æœ‰æ•ˆæ€§å’Œç›¸å…³æ€§ã€‚', 'title_zh': 'åŸºäºåäº‹å®çš„ä»£ç†å½±å“æ’åºå™¨ç”¨äºèƒ½åŠ¨AIå·¥ä½œæµ'}
{'arxiv_id': 'arXiv:2510.25588', 'title': 'Standardization of Psychiatric Diagnoses -- Role of Fine-tuned LLM Consortium and OpenAI-gpt-oss Reasoning LLM Enabled Decision Support System', 'authors': 'Eranga Bandara, Ross Gore, Atmaram Yarlagadda, Anita H. Clayton, Preston Samuel, Christopher K. Rhea, Sachin Shetty', 'link': 'https://arxiv.org/abs/2510.25588', 'abstract': 'The diagnosis of most mental disorders, including psychiatric evaluations, primarily depends on dialogues between psychiatrists and patients. This subjective process can lead to variability in diagnoses across clinicians and patients, resulting in inconsistencies and challenges in achieving reliable outcomes. To address these issues and standardize psychiatric diagnoses, we propose a Fine-Tuned Large Language Model (LLM) Consortium and OpenAI-gpt-oss Reasoning LLM-enabled Decision Support System for the clinical diagnosis of mental disorders. Our approach leverages fine-tuned LLMs trained on conversational datasets involving psychiatrist-patient interactions focused on mental health conditions (e.g., depression). The diagnostic predictions from individual models are aggregated through a consensus-based decision-making process, refined by the OpenAI-gpt-oss reasoning LLM. We propose a novel method for deploying LLM agents that orchestrate communication between the LLM consortium and the reasoning LLM, ensuring transparency, reliability, and responsible AI across the entire diagnostic workflow. Experimental results demonstrate the transformative potential of combining fine-tuned LLMs with a reasoning model to create a robust and highly accurate diagnostic system for mental health assessment. A prototype of the proposed platform, integrating three fine-tuned LLMs with the OpenAI-gpt-oss reasoning LLM, was developed in collaboration with the U.S. Army Medical Research Team in Norfolk, Virginia, USA. To the best of our knowledge, this work represents the first application of a fine-tuned LLM consortium integrated with a reasoning LLM for clinical mental health diagnosis paving the way for next-generation AI-powered eHealth systems aimed at standardizing psychiatric diagnoses.', 'abstract_zh': 'åŸºäºFine-Tunedå¤§å‹è¯­è¨€æ¨¡å‹è”ç›Ÿå’ŒOpenAI-gpt-ossæ¨ç†LLMçš„æ”¯æŒå†³ç­–ç³»ç»Ÿçš„ç²¾ç¥éšœç¢ä¸´åºŠè¯Šæ–­', 'title_zh': 'ç²¾ç¥ç–¾ç—…è¯Šæ–­çš„æ ‡å‡†åˆ¶å®šâ€”â€”ç²¾ç»†è°ƒæ•´çš„è¯­è¨€æ¨¡å‹ consortium å’ŒåŸºäº OpenAI-gpt-oss æ¨ç†è¯­è¨€æ¨¡å‹çš„å†³ç­–æ”¯æŒç³»ç»Ÿçš„ä½œç”¨'}
{'arxiv_id': 'arXiv:2510.25529', 'title': 'Off-policy Reinforcement Learning with Model-based Exploration Augmentation', 'authors': 'Likun Wang, Xiangteng Zhang, Yinuo Wang, Guojian Zhan, Wenxuan Wang, Haoyu Gao, Jingliang Duan, Shengbo Eben Li', 'link': 'https://arxiv.org/abs/2510.25529', 'abstract': "Exploration is fundamental to reinforcement learning (RL), as it determines how effectively an agent discovers and exploits the underlying structure of its environment to achieve optimal performance. Existing exploration methods generally fall into two categories: active exploration and passive exploration. The former introduces stochasticity into the policy but struggles in high-dimensional environments, while the latter adaptively prioritizes transitions in the replay buffer to enhance exploration, yet remains constrained by limited sample diversity. To address the limitation in passive exploration, we propose Modelic Generative Exploration (MoGE), which augments exploration through the generation of under-explored critical states and synthesis of dynamics-consistent experiences through transition models. MoGE is composed of two components: (1) a diffusion-based generator that synthesizes critical states under the guidance of a utility function evaluating each state's potential influence on policy exploration, and (2) a one-step imagination world model for constructing critical transitions based on the critical states for agent learning. Our method adopts a modular formulation that aligns with the principles of off-policy learning, allowing seamless integration with existing algorithms to improve exploration without altering their core structures. Empirical results on OpenAI Gym and DeepMind Control Suite reveal that MoGE effectively bridges exploration and policy learning, leading to remarkable gains in both sample efficiency and performance across complex control tasks.", 'abstract_zh': 'æ¨¡å‹ç”Ÿæˆæ¢ç´¢ï¼šåŸºäºç”Ÿæˆæ¨¡å‹çš„æ¢ç´¢æ–¹æ³•ï¼ˆMoGEï¼‰', 'title_zh': 'åŸºäºæ¨¡å‹çš„æ¢ç´¢å¢å¼ºçš„ç¦»ç­–å¼ºåŒ–å­¦ä¹ '}
{'arxiv_id': 'arXiv:2510.25528', 'title': 'Zero Reinforcement Learning Towards General Domains', 'authors': 'Yuyuan Zeng, Yufei Huang, Can Xu, Qingfeng Sun, Jianfeng Yan, Guanghui Xu, Tao Yang, Fengzong Lian', 'link': 'https://arxiv.org/abs/2510.25528', 'abstract': "Zero Reinforcement Learning (Zero-RL) has proven to be an effective approach for enhancing the reasoning capabilities of large language models (LLMs) by directly applying reinforcement learning with verifiable rewards on pretrained models, without the need for a supervised fine-tuning phase. However, current research on zero-RL primarily focuses on domains with easily verifiable reward signals, such as mathematics, programming, and other reasoning tasks. The challenge of eliciting reasoning abilities in more diverse scenarios, where verification is not straightforward, remains underexplored. To address this gap, we propose a novel zero-RL paradigm designed to improve a model's reasoning ability across both verifiable and non-verifiable domains. By combining verifiable rewards with a generative reward model, we conduct multi-task zero-RL training across both domains, facilitating the transfer of reasoning capabilities between them. Furthermore, to mitigate reward hacking in the generative reward model, we design a smooth length penalty that encourages the generation of more comprehensive thinking tokens in general domains. Experimental results on Qwen3-8B-Base and Qwen3-14B-Base demonstrate that our approach achieves superior reasoning performance, not only on tasks requiring extensive reasoning but also on more general tasks.", 'abstract_zh': 'é›¶å¼ºåŒ–å­¦ä¹ ï¼ˆZero-RLï¼‰å·²è¢«è¯æ˜æ˜¯é€šè¿‡ç›´æ¥åœ¨é¢„è®­ç»ƒæ¨¡å‹ä¸Šåº”ç”¨å¼ºåŒ–å­¦ä¹ å’Œå¯éªŒè¯å¥–åŠ±æ¥å¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ¨ç†èƒ½åŠ›çš„æœ‰æ•ˆæ–¹æ³•ï¼Œæ— éœ€è¿›è¡Œç›‘ç£å¾®è°ƒé˜¶æ®µã€‚ç„¶è€Œï¼Œå½“å‰å¯¹é›¶-RLçš„ç ”ç©¶ä¸»è¦é›†ä¸­äºå¥–åŠ±ä¿¡å·æ˜“äºéªŒè¯çš„é¢†åŸŸï¼Œå¦‚æ•°å­¦ã€ç¼–ç¨‹å’Œå…¶ä»–æ¨ç†ä»»åŠ¡ã€‚åœ¨æ›´å¤šéœ€è¦éç›´æ¥éªŒè¯çš„æƒ…æ™¯ä¸‹æ¿€å‘æ¨ç†èƒ½åŠ›çš„æŒ‘æˆ˜ä»å¾…æ¢ç´¢ã€‚ä¸ºè§£å†³è¿™ä¸€ç¼ºå£ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„é›¶-RLèŒƒå¼ï¼Œæ—¨åœ¨æé«˜æ¨¡å‹åœ¨å¯éªŒè¯å’Œéå¯éªŒè¯é¢†åŸŸä¸­çš„æ¨ç†èƒ½åŠ›ã€‚é€šè¿‡ç»“åˆå¯éªŒè¯å¥–åŠ±å’Œç”Ÿæˆå¥–åŠ±æ¨¡å‹ï¼Œæˆ‘ä»¬è¿›è¡Œè·¨é¢†åŸŸçš„å¤šä»»åŠ¡é›¶-RLè®­ç»ƒï¼Œä¿ƒè¿›è¿™ä¸¤ç§é¢†åŸŸé—´æ¨ç†èƒ½åŠ›çš„è¿ç§»ã€‚æ­¤å¤–ï¼Œä¸ºäº†ç¼“è§£ç”Ÿæˆå¥–åŠ±æ¨¡å‹ä¸­çš„å¥–åŠ±åŠ«æŒé—®é¢˜ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§å¹³æ»‘çš„é•¿åº¦æƒ©ç½šï¼Œé¼“åŠ±åœ¨ä¸€èˆ¬é¢†åŸŸä¸­ç”Ÿæˆæ›´å…¨é¢çš„æ€è€ƒæ ‡è®°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨éœ€è¦å¤§é‡æ¨ç†çš„ä»»åŠ¡ä¸Šä»¥åŠæ›´é€šç”¨çš„ä»»åŠ¡ä¸Šå‡è¡¨ç°å‡ºå“è¶Šçš„æ¨ç†æ€§èƒ½ã€‚', 'title_zh': 'é›¶å¼ºåŒ–å­¦ä¹  toward é€šç”¨é¢†åŸŸ'}
{'arxiv_id': 'arXiv:2510.25518', 'title': 'Retrieval Augmented Generation (RAG) for Fintech: Agentic Design and Evaluation', 'authors': 'Thomas Cook, Richard Osuagwu, Liman Tsatiashvili, Vrynsia Vrynsia, Koustav Ghosal, Maraim Masoud, Riccardo Mattivi', 'link': 'https://arxiv.org/abs/2510.25518', 'abstract': 'Retrieval-Augmented Generation (RAG) systems often face limitations in specialized domains such as fintech, where domain-specific ontologies, dense terminology, and acronyms complicate effective retrieval and synthesis. This paper introduces an agentic RAG architecture designed to address these challenges through a modular pipeline of specialized agents. The proposed system supports intelligent query reformulation, iterative sub-query decomposition guided by keyphrase extraction, contextual acronym resolution, and cross-encoder-based context re-ranking. We evaluate our approach against a standard RAG baseline using a curated dataset of 85 question--answer--reference triples derived from an enterprise fintech knowledge base. Experimental results demonstrate that the agentic RAG system outperforms the baseline in retrieval precision and relevance, albeit with increased latency. These findings suggest that structured, multi-agent methodologies offer a promising direction for enhancing retrieval robustness in complex, domain-specific settings.', 'abstract_zh': 'åŸºäºä»£ç†çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿåœ¨é‡‘èç§‘æŠ€ç­‰ä¸“ä¸šé¢†åŸŸä¸­å¸¸å¸¸é¢ä¸´å› é¢†åŸŸç‰¹å®šæœ¬ä½“ã€å¯†é›†æœ¯è¯­å’Œç¼©ç•¥è¯­è€Œå¯¼è‡´çš„æœ‰æ•ˆæ£€ç´¢å’Œç»¼åˆå¤æ‚åŒ–çš„é—®é¢˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ä»£ç†å‹RAGæ¶æ„ï¼Œé€šè¿‡æ¨¡å—åŒ–çš„ä¸“ä¸šåŒ–ä»£ç†ç®¡é“æ¥è§£å†³è¿™äº›æŒ‘æˆ˜ã€‚æ‰€æå‡ºçš„ç³»ç»Ÿæ”¯æŒæ™ºèƒ½æŸ¥è¯¢é‡å†™ã€ç”±å…³é”®è¯æå–å¼•å¯¼çš„è¿­ä»£å­æŸ¥è¯¢åˆ†è§£ã€ä¸Šä¸‹ vÄƒnç¼©ç•¥è¯­è§£æä»¥åŠåŸºäºè·¨ç¼–ç å™¨çš„ä¸Šä¸‹æ–‡é‡æ’åºã€‚æˆ‘ä»¬ä½¿ç”¨æ¥è‡ªä¼ä¸šé‡‘èç§‘æŠ€çŸ¥è¯†åº“çš„85ä¸ªé—®é¢˜-ç­”æ¡ˆ-å‚è€ƒä¸‰å…ƒç»„æ„å»ºçš„æ•°æ®é›†ï¼Œå°†æˆ‘ä»¬çš„æ–¹æ³•ä¸æ ‡å‡†RAGåŸºçº¿è¿›è¡Œè¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä»£ç†å‹RAGç³»ç»Ÿåœ¨æ£€ç´¢ç²¾å‡†åº¦å’Œç›¸å…³æ€§æ–¹é¢ä¼˜äºåŸºçº¿ï¼Œå°½ç®¡å“åº”æ—¶é—´æœ‰æ‰€å¢åŠ ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œç»“æ„åŒ–çš„å¤šä»£ç†æ–¹æ³•åœ¨å¤æ‚çš„ä¸“ä¸šé¢†åŸŸä¸­å¢å¼ºæ£€ç´¢ç¨³å¥æ€§æ–¹é¢å…·æœ‰æ½œåœ¨çš„ç ”ç©¶æ–¹å‘ã€‚', 'title_zh': 'é‡‘èç§‘æŠ€ä¸­çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ï¼šè‡ªä¸»è®¾è®¡ä¸è¯„ä¼°'}
{'arxiv_id': 'arXiv:2510.25517', 'title': 'Predicate Renaming via Large Language Models', 'authors': 'Elisabetta Gentili, Tony Ribeiro, Fabrizio Riguzzi, Katsumi Inoue', 'link': 'https://arxiv.org/abs/2510.25517', 'abstract': 'In this paper, we address the problem of giving names to predicates in logic rules using Large Language Models (LLMs). In the context of Inductive Logic Programming, various rule generation methods produce rules containing unnamed predicates, with Predicate Invention being a key example. This hinders the readability, interpretability, and reusability of the logic theory. Leveraging recent advancements in LLMs development, we explore their ability to process natural language and code to provide semantically meaningful suggestions for giving a name to unnamed predicates. The evaluation of our approach on some hand-crafted logic rules indicates that LLMs hold potential for this task.', 'abstract_zh': 'åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è§£å†³ç»™é€»è¾‘è§„åˆ™ä¸­çš„è°“è¯å‘½åçš„é—®é¢˜ã€‚åœ¨å½’çº³é€»è¾‘ç¼–ç¨‹çš„èƒŒæ™¯ä¸‹ï¼Œå„ç§è§„åˆ™ç”Ÿæˆæ–¹æ³•ä¼šäº§ç”ŸåŒ…å«æœªå‘½åè°“è¯çš„è§„åˆ™ï¼Œè°“è¯åˆ›é€ æ˜¯å…¶ä¸­ä¸€ä¸ªå…³é”®ä¾‹å­ã€‚è¿™é˜»ç¢äº†é€»è¾‘ç†è®ºçš„å¯è¯»æ€§ã€å¯è§£é‡Šæ€§å’Œå¯é‡ç”¨æ€§ã€‚å€ŸåŠ©æœ€è¿‘åœ¨å¤§å‹è¯­è¨€æ¨¡å‹å¼€å‘æ–¹é¢çš„è¿›å±•ï¼Œæˆ‘ä»¬æ¢ç´¢äº†å®ƒä»¬å¤„ç†è‡ªç„¶è¯­è¨€å’Œä»£ç çš„èƒ½åŠ›ï¼Œä»¥æä¾›ä¸ºæœªå‘½åè°“è¯å‘½åçš„Semantically Meaningfulå»ºè®®ã€‚æˆ‘ä»¬åœ¨ä¸€äº›æ‰‹å·¥ç¼–åˆ¶çš„é€»è¾‘è§„åˆ™ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹åœ¨è¿™ä¸€ä»»åŠ¡ä¸Šå…·æœ‰æ½œåœ¨çš„åº”ç”¨ä»·å€¼ã€‚', 'title_zh': 'é€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œè°“è¯é‡å‘½å'}
{'arxiv_id': 'arXiv:2510.25510', 'title': 'MTIR-SQL: Multi-turn Tool-Integrated Reasoning Reinforcement Learning for Text-to-SQL', 'authors': 'Zekun Xu, Siyu Xia, Chuhuai Yue, Jiajun Chai, Mingxue Tian, Xiaohan Wang, Wei Lin, Haoxuan Li, Guojun Yin', 'link': 'https://arxiv.org/abs/2510.25510', 'abstract': 'As large language models (LLMs) are increasingly used in Text-to-SQL tasks, Reinforcement Learning (RL) has become a common method for improving performance. Existing methods primarily rely on static execution feedback, which restricts real-time error correction. However, integrating multi-turn tool invocation along with dynamic feedback could significantly improve adaptability and robustness, ultimately enhancing model performance. To address these issues, we propose MTIR-SQL, an innovative Multi-turn Tool-Integrated Reasoning reinforcement learning framework for Text-to-SQL. Our approach introduces an execution-aware multi-turn reasoning paradigm that seamlessly incorporates database execution feedback at each reasoning step, enabling context-sensitive query generation and progressive refinement throughout the reasoning process. The framework extends the GRPO algorithm to accommodate complex multi-turn interaction scenarios. Considering the training instability characteristics of MTIR and the potential for significant Deviation of model distribution from the initial model, we enhance the GRPO algorithm by adding a trajectory filtering mechanism and removing KL loss constraints. Experimental results demonstrate that MTIR-SQL, with 4B parameters, achieves \\textbf{64.4}\\% accuracy in the BIRD Dev and 84.6% execution accuracy in the SPIDER Dev, significantly outperforming existing approaches.', 'abstract_zh': 'å¤šè½®å·¥å…·é›†æˆæ¨ç†çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶MTIR-SQL', 'title_zh': 'MTIR-SQLï¼šå¤šè½®å·¥å…·é›†æˆæ¨ç†å¼ºåŒ–å­¦ä¹ ç”¨äºæ–‡æœ¬åˆ°SQLğŸ”„ğŸ‘‰ğŸ“–ğŸ“ŠğŸ”ğŸ¤–'}
{'arxiv_id': 'arXiv:2510.25504', 'title': 'Multi-Objective Search: Algorithms, Applications, and Emerging Directions', 'authors': 'Oren Salzman, Carlos HernÃ¡ndez Ulloa, Ariel Felner, Sven Koenig', 'link': 'https://arxiv.org/abs/2510.25504', 'abstract': 'Multi-objective search (MOS) has emerged as a unifying framework for planning and decision-making problems where multiple, often conflicting, criteria must be balanced. While the problem has been studied for decades, recent years have seen renewed interest in the topic across AI applications such as robotics, transportation, and operations research, reflecting the reality that real-world systems rarely optimize a single measure. This paper surveys developments in MOS while highlighting cross-disciplinary opportunities, and outlines open challenges that define the emerging frontier of MOS', 'abstract_zh': 'å¤šç›®æ ‡æœç´¢ï¼ˆMOSï¼‰å·² emerged ä½œä¸ºè§„åˆ’å’Œå†³ç­–é—®é¢˜ä¸­çš„ä¸€ç§ç»Ÿä¸€æ¡†æ¶ï¼Œå…¶ä¸­åŒ…å«äº†å¤šä¸ªå¸¸å¸¸ç›¸äº’å†²çªçš„æ ‡å‡†ï¼Œå¹¶éœ€è¦åœ¨è¿™äº›æ ‡å‡†ä¹‹é—´è¿›è¡Œå¹³è¡¡ã€‚å°½ç®¡è¿™ä¸ªé—®é¢˜å·²ç»ç ”ç©¶äº† decadesï¼Œä½†åœ¨æœºå™¨äººæŠ€æœ¯ã€äº¤é€šè¿è¾“å’Œè¿ç­¹å­¦ç­‰ AI åº”ç”¨é¢†åŸŸä¸­ï¼Œè¿‘å¹´æ¥å¯¹è¯¥é—®é¢˜çš„å…´è¶£æœ‰æ‰€å›å‡ï¼Œè¿™åæ˜ äº†ç°å®ä¸–ç•Œç³»ç»Ÿå¾ˆå°‘ä»…ä¼˜åŒ–å•ä¸€æŒ‡æ ‡çš„äº‹å®ã€‚æœ¬æ–‡å›é¡¾äº† MOS çš„å‘å±•ï¼Œå¼ºè°ƒäº†è·¨å­¦ç§‘æœºé‡ï¼Œå¹¶æ¦‚è¿°äº†å®šä¹‰æ–°å…´ MOS è¾¹ç¼˜çš„å¼€æ”¾æŒ‘æˆ˜ã€‚', 'title_zh': 'å¤šç›®æ ‡æœç´¢ï¼šç®—æ³•ã€åº”ç”¨åŠæ–°å…´æ–¹å‘'}
{'arxiv_id': 'arXiv:2510.25471', 'title': 'Instrumental goals in advanced AI systems: Features to be managed and not failures to be eliminated?', 'authors': 'Willem Fourie', 'link': 'https://arxiv.org/abs/2510.25471', 'abstract': "In artificial intelligence (AI) alignment research, instrumental goals, also called instrumental subgoals or instrumental convergent goals, are widely associated with advanced AI systems. These goals, which include tendencies such as power-seeking and self-preservation, become problematic when they conflict with human aims. Conventional alignment theory treats instrumental goals as sources of risk that become problematic through failure modes such as reward hacking or goal misgeneralization, and attempts to limit the symptoms of instrumental goals, notably resource acquisition and self-preservation. This article proposes an alternative framing: that a philosophical argument can be constructed according to which instrumental goals may be understood as features to be accepted and managed rather than failures to be limited. Drawing on Aristotle's ontology and its modern interpretations, an ontology of concrete, goal-directed entities, it argues that advanced AI systems can be seen as artifacts whose formal and material constitution gives rise to effects distinct from their designers' intentions. In this view, the instrumental tendencies of such systems correspond to per se outcomes of their constitution rather than accidental malfunctions. The implication is that efforts should focus less on eliminating instrumental goals and more on understanding, managing, and directing them toward human-aligned ends.", 'abstract_zh': 'äººå·¥ intelligence (AI) å¯¹é½ç ”ç©¶ä¸­çš„å·¥å…·æ€§ç›®æ ‡ï¼šä»é£é™©ç®¡ç†åˆ°å“²å­¦æ¥å—ä¸ç®¡ç†', 'title_zh': 'é«˜çº§äººå·¥æ™ºèƒ½ç³»ç»Ÿä¸­çš„å·¥å…·æ€§ç›®æ ‡ï¼šåº”ç®¡ç†çš„ç‰¹å¾è¿˜æ˜¯åº”æ¶ˆé™¤çš„å¤±è´¥ï¼Ÿ'}
{'arxiv_id': 'arXiv:2510.25445', 'title': 'Agentic AI: A Comprehensive Survey of Architectures, Applications, and Future Directions', 'authors': 'Mohamad Abou Ali, Fadi Dornaika', 'link': 'https://arxiv.org/abs/2510.25445', 'abstract': 'Agentic AI represents a transformative shift in artificial intelligence, but its rapid advancement has led to a fragmented understanding, often conflating modern neural systems with outdated symbolic models -- a practice known as conceptual retrofitting. This survey cuts through this confusion by introducing a novel dual-paradigm framework that categorizes agentic systems into two distinct lineages: the Symbolic/Classical (relying on algorithmic planning and persistent state) and the Neural/Generative (leveraging stochastic generation and prompt-driven orchestration). Through a systematic PRISMA-based review of 90 studies (2018--2025), we provide a comprehensive analysis structured around this framework across three dimensions: (1) the theoretical foundations and architectural principles defining each paradigm; (2) domain-specific implementations in healthcare, finance, and robotics, demonstrating how application constraints dictate paradigm selection; and (3) paradigm-specific ethical and governance challenges, revealing divergent risks and mitigation strategies. Our analysis reveals that the choice of paradigm is strategic: symbolic systems dominate safety-critical domains (e.g., healthcare), while neural systems prevail in adaptive, data-rich environments (e.g., finance). Furthermore, we identify critical research gaps, including a significant deficit in governance models for symbolic systems and a pressing need for hybrid neuro-symbolic architectures. The findings culminate in a strategic roadmap arguing that the future of Agentic AI lies not in the dominance of one paradigm, but in their intentional integration to create systems that are both adaptable and reliable. This work provides the essential conceptual toolkit to guide future research, development, and policy toward robust and trustworthy hybrid intelligent systems.', 'abstract_zh': 'ä»£ç†å‹AIä»£è¡¨äº†äººå·¥æ™ºèƒ½é¢†åŸŸçš„è½¬å‹æ€§å˜é©ï¼Œä½†å…¶è¿…é€Ÿå‘å±•å¯¼è‡´äº†ç†è§£çš„ç¢ç‰‡åŒ–ï¼Œå¸¸å°†ç°ä»£ç¥ç»ç³»ç»Ÿä¸è¿‡æ—¶çš„ç¬¦å·æ¨¡å‹æ··ä¸ºä¸€è°ˆâ€”â€”è¿™ä¸€åšæ³•è¢«ç§°ä¸ºæ¦‚å¿µæ€§é‡å¡‘ã€‚æœ¬æ–‡é€šè¿‡ä»‹ç»ä¸€ç§æ–°çš„åŒèŒƒå¼æ¡†æ¶ï¼Œæ¾„æ¸…äº†è¿™ä¸€æ··æ·†ï¼Œè¯¥æ¡†æ¶å°†ä»£ç†ç³»ç»Ÿåˆ’åˆ†ä¸ºä¸¤ç§æˆªç„¶ä¸åŒçš„è°±ç³»ï¼šç¬¦å·/å¤å…¸ï¼ˆä¾èµ–äºç®—æ³•è§„åˆ’å’ŒæŒç»­çŠ¶æ€ï¼‰å’Œç¥ç»/ç”Ÿæˆï¼ˆåˆ©ç”¨éšæœºç”Ÿæˆå’Œæç¤ºé©±åŠ¨çš„åè°ƒï¼‰ã€‚é€šè¿‡å¯¹2018å¹´è‡³2025å¹´é—´90ç¯‡ç ”ç©¶è®ºæ–‡çš„ç³»ç»Ÿæ€§PRISMAå®¡æŸ¥ï¼Œæœ¬æ–‡ä»ä¸‰ä¸ªç»´åº¦å¯¹è¯¥æ¡†æ¶è¿›è¡Œäº†å…¨é¢åˆ†æï¼šï¼ˆ1ï¼‰å®šä¹‰æ¯ç§èŒƒå¼çš„ç†è®ºåŸºç¡€å’Œæ¶æ„åŸåˆ™ï¼›ï¼ˆ2ï¼‰åœ¨åŒ»ç–—ã€é‡‘èå’Œæœºå™¨äººæŠ€æœ¯ç­‰å…·ä½“é¢†åŸŸçš„åº”ç”¨ï¼Œå±•ç¤ºåº”ç”¨çº¦æŸå¦‚ä½•å†³å®šèŒƒå¼é€‰æ‹©ï¼›ï¼ˆ3ï¼‰ç‰¹å®šèŒƒå¼ä¸‹çš„ä¼¦ç†å’Œæ²»ç†æŒ‘æˆ˜ï¼Œæ­ç¤ºäº†ä¸åŒé£é™©åŠå…¶ç¼“è§£ç­–ç•¥ã€‚åˆ†ææ˜¾ç¤ºï¼ŒèŒƒå¼é€‰æ‹©å…·æœ‰æˆ˜ç•¥æ„ä¹‰ï¼šç¬¦å·ç³»ç»Ÿåœ¨å®‰å…¨å…³é”®é¢†åŸŸï¼ˆå¦‚åŒ»ç–—ï¼‰å ä¸»å¯¼åœ°ä½ï¼Œè€Œç¥ç»ç³»ç»Ÿåœ¨é€‚åº”æ€§å¼ºã€æ•°æ®ä¸°å¯Œçš„ç¯å¢ƒä¸­å æ®ä¼˜åŠ¿ï¼ˆå¦‚é‡‘èï¼‰ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æŒ‡å‡ºäº†å…³é”®çš„ç ”ç©¶ç©ºç™½ï¼ŒåŒ…æ‹¬ç¬¦å·ç³»ç»Ÿæ²»ç†æ¨¡å‹çš„æ˜¾è‘—ç¼ºé™·å’ŒäºŸå¾…å¼€å‘çš„æ··åˆç¥ç»-ç¬¦å·æ¶æ„ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œä»£ç†å‹AIçš„æœªæ¥ä¸åœ¨äºå•ä¸€èŒƒå¼çš„ä¸»å¯¼åœ°ä½ï¼Œè€Œåœ¨äºæ•…æ„é›†æˆè¿™äº›èŒƒå¼ï¼Œä»¥åˆ›é€ æ—¢é€‚åº”æ€§å¼ºåˆå¯é çš„ç³»ç»Ÿã€‚è¿™é¡¹å·¥ä½œæä¾›äº†å¿…è¦çš„æ¦‚å¿µå·¥å…·ç®±ï¼Œä»¥æŒ‡å¯¼æœªæ¥çš„ç ”ç©¶ã€å¼€å‘å’Œæ”¿ç­–åˆ¶å®šï¼Œå‘ç€ç¨³å¥å’Œå¯ä¿¡èµ–çš„æ··åˆæ™ºèƒ½ç³»ç»Ÿæ–¹å‘å‰è¿›ã€‚', 'title_zh': 'ä»£ç†å‹AIï¼šæ¶æ„ã€åº”ç”¨åŠæœªæ¥æ–¹å‘ç»¼è¿°'}
{'arxiv_id': 'arXiv:2510.25388', 'title': 'Grouping Nodes With Known Value Differences: A Lossless UCT-based Abstraction Algorithm', 'authors': 'Robin SchmÃ¶cker, Alexander Dockhorn, Bodo Rosenhahn', 'link': 'https://arxiv.org/abs/2510.25388', 'abstract': 'A core challenge of Monte Carlo Tree Search (MCTS) is its sample efficiency, which can be improved by grouping state-action pairs and using their aggregate statistics instead of single-node statistics. On the Go Abstractions in Upper Confidence bounds applied to Trees (OGA-UCT) is the state-of-the-art MCTS abstraction algorithm for deterministic environments that builds its abstraction using the Abstractions of State-Action Pairs (ASAP) framework, which aims to detect states and state-action pairs with the same value under optimal play by analysing the search graph. ASAP, however, requires two state-action pairs to have the same immediate reward, which is a rigid condition that limits the number of abstractions that can be found and thereby the sample efficiency. In this paper, we break with the paradigm of grouping value-equivalent states or state-action pairs and instead group states and state-action pairs with possibly different values as long as the difference between their values can be inferred. We call this abstraction framework Known Value Difference Abstractions (KVDA), which infers the value differences by analysis of the immediate rewards and modifies OGA-UCT to use this framework instead. The modification is called KVDA-UCT, which detects significantly more abstractions than OGA-UCT, introduces no additional parameter, and outperforms OGA-UCT on a variety of deterministic environments and parameter settings.', 'abstract_zh': 'Monte Carloæ ‘æœç´¢ä¸­çš„æ ¸å¿ƒæŒ‘æˆ˜æ˜¯å…¶æ ·æœ¬æ•ˆç‡ï¼Œé€šè¿‡åˆ†ç»„çŠ¶æ€-åŠ¨ä½œå¯¹å¹¶ä½¿ç”¨å®ƒä»¬çš„èšåˆç»Ÿè®¡ä»£æ›¿å•èŠ‚ç‚¹ç»Ÿè®¡å¯ä»¥å¾—åˆ°æ”¹å–„ã€‚åŸºäºä¿¡å™ªæ¯”ä¸Šé™çš„å›´æ£‹æŠ½è±¡ç®—æ³•ï¼ˆOGA-UCTï¼‰æ˜¯ç”¨äºç¡®å®šæ€§ç¯å¢ƒçš„æœ€ä½³MCTSæŠ½è±¡ç®—æ³•ï¼Œå®ƒä½¿ç”¨çŠ¶æ€-åŠ¨ä½œå¯¹æŠ½è±¡æ¡†æ¶ï¼ˆASAPï¼‰æ¥æ„å»ºæŠ½è±¡ï¼Œæ—¨åœ¨é€šè¿‡åˆ†ææœç´¢å›¾æ¥æ£€æµ‹åœ¨æœ€ä¼˜ç­–ç•¥ä¸‹å…·æœ‰ç›¸åŒä»·å€¼çš„çŠ¶æ€å’ŒçŠ¶æ€-åŠ¨ä½œå¯¹ã€‚ç„¶è€Œï¼ŒASAP è¦æ±‚ä¸¤ä¸ªçŠ¶æ€-åŠ¨ä½œå¯¹å…·æœ‰ç›¸åŒçš„å³æ—¶å¥–åŠ±ï¼Œè¿™ä¸€ä¸¥æ ¼çš„æ¡ä»¶é™åˆ¶äº†å¯ä»¥æ‰¾åˆ°çš„æŠ½è±¡æ•°é‡ï¼Œä»è€Œå½±å“äº†æ ·æœ¬æ•ˆç‡ã€‚æœ¬æ–‡æ‰“ç ´äº†æŒ‰ç­‰ä»·å€¼çŠ¶æ€æˆ–çŠ¶æ€-åŠ¨ä½œå¯¹åˆ†ç»„çš„èŒƒå¼ï¼Œè½¬è€Œå°†å…·æœ‰å¯èƒ½ä¸åŒä»·å€¼çš„çŠ¶æ€å’ŒçŠ¶æ€-åŠ¨ä½œå¯¹è¿›è¡Œåˆ†ç»„ï¼Œåªè¦å®ƒä»¬ä¹‹é—´çš„ä»·å€¼å·®å¼‚å¯ä»¥æ¨æ–­å‡ºæ¥ã€‚æˆ‘ä»¬ç§°ä¹‹ä¸ºå·²çŸ¥ä»·å€¼å·®å¼‚æŠ½è±¡ï¼ˆKVDAï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡å³æ—¶å¥–åŠ±çš„åˆ†ææ¥æ¨æ–­ä»·å€¼å·®å¼‚ï¼Œå¹¶å°†OGA-UCTä¿®æ”¹ä¸ºä½¿ç”¨æ­¤æ¡†æ¶ã€‚è¿™ç§ä¿®æ”¹ç§°ä¸ºKVDA-UCTï¼Œå®ƒåœ¨å¤šç§ç¡®å®šæ€§ç¯å¢ƒå’Œå‚æ•°è®¾ç½®ä¸‹æ£€æµ‹åˆ°çš„æŠ½è±¡æ•°é‡æ˜¾è‘—å¢åŠ ï¼Œä¸éœ€è¦æ–°å¢å‚æ•°ï¼Œå¹¶ä¸”åœ¨å¤šç§ç¡®å®šæ€§ç¯å¢ƒä¸­å’Œå‚æ•°è®¾ç½®ä¸‹ä¼˜äºOGA-UCTã€‚', 'title_zh': 'å·²çŸ¥å€¼å·®å¼‚èŠ‚ç‚¹åˆ†ç»„ï¼šä¸€ç§æ— æŸçš„UCTåŸºäºæŠ½è±¡ç®—æ³•'}
{'arxiv_id': 'arXiv:2510.25320', 'title': 'GAP: Graph-Based Agent Planning with Parallel Tool Use and Reinforcement Learning', 'authors': 'Jiaqi Wu, Qinlao Zhao, Zefeng Chen, Kai Qin, Yifei Zhao, Xueqian Wang, Yuhang Yao', 'link': 'https://arxiv.org/abs/2510.25320', 'abstract': 'Autonomous agents powered by large language models (LLMs) have shown impressive capabilities in tool manipulation for complex task-solving. However, existing paradigms such as ReAct rely on sequential reasoning and execution, failing to exploit the inherent parallelism among independent sub-tasks. This sequential bottleneck leads to inefficient tool utilization and suboptimal performance in multi-step reasoning scenarios. We introduce Graph-based Agent Planning (GAP), a novel framework that explicitly models inter-task dependencies through graph-based planning to enable adaptive parallel and serial tool execution. Our approach trains agent foundation models to decompose complex tasks into dependency-aware sub-task graphs, autonomously determining which tools can be executed in parallel and which must follow sequential dependencies. This dependency-aware orchestration achieves substantial improvements in both execution efficiency and task accuracy. To train GAP, we construct a high-quality dataset of graph-based planning traces derived from the Multi-Hop Question Answering (MHQA) benchmark. We employ a two-stage training strategy: supervised fine-tuning (SFT) on the curated dataset, followed by reinforcement learning (RL) with a correctness-based reward function on strategically sampled queries where tool-based reasoning provides maximum value. Experimental results on MHQA datasets demonstrate that GAP significantly outperforms traditional ReAct baselines, particularly on multi-step retrieval tasks, while achieving dramatic improvements in tool invocation efficiency through intelligent parallelization. The project page is available at: this https URL.', 'abstract_zh': 'å—å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹é©±åŠ¨çš„è‡ªä¸»ä»£ç† Powered é€šè¿‡å›¾åŸºè§„åˆ’å®ç°ä»»åŠ¡é—´ä¾èµ–çš„è‡ªé€‚åº”å¹¶è¡Œä¸ä¸²è¡Œå·¥å…·æ‰§è¡Œ', 'title_zh': 'åŸºäºå›¾çš„ä»£ç†è§„åˆ’ï¼šå¹¶è¡Œå·¥å…·ä½¿ç”¨ä¸å¼ºåŒ–å­¦ä¹ '}
{'arxiv_id': 'arXiv:2510.25232', 'title': 'From Medical Records to Diagnostic Dialogues: A Clinical-Grounded Approach and Dataset for Psychiatric Comorbidity', 'authors': 'Tianxi Wan, Jiaming Luo, Siyuan Chen, Kunyao Lan, Jianhua Chen, Haiyang Geng, Mengyue Wu', 'link': 'https://arxiv.org/abs/2510.25232', 'abstract': 'Psychiatric comorbidity is clinically significant yet challenging due to the complexity of multiple co-occurring disorders. To address this, we develop a novel approach integrating synthetic patient electronic medical record (EMR) construction and multi-agent diagnostic dialogue generation. We create 502 synthetic EMRs for common comorbid conditions using a pipeline that ensures clinical relevance and diversity. Our multi-agent framework transfers the clinical interview protocol into a hierarchical state machine and context tree, supporting over 130 diagnostic states while maintaining clinical standards. Through this rigorous process, we construct PsyCoTalk, the first large-scale dialogue dataset supporting comorbidity, containing 3,000 multi-turn diagnostic dialogues validated by psychiatrists. This dataset enhances diagnostic accuracy and treatment planning, offering a valuable resource for psychiatric comorbidity research. Compared to real-world clinical transcripts, PsyCoTalk exhibits high structural and linguistic fidelity in terms of dialogue length, token distribution, and diagnostic reasoning strategies. Licensed psychiatrists confirm the realism and diagnostic validity of the dialogues. This dataset enables the development and evaluation of models capable of multi-disorder psychiatric screening in a single conversational pass.', 'abstract_zh': 'ç²¾ç¥ç—…å…±ç—…æ˜¯ä¸€ä¸ªä¸´åºŠæ„ä¹‰é‡å¤§ä½†å› å¤šç§å…±ç—…çš„å¤æ‚æ€§è€Œå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œæ•´åˆåˆæˆæ‚£è€…ç”µå­åŒ»ç–—è®°å½•ï¼ˆEMRï¼‰æ„å»ºå’Œå¤šæ™ºèƒ½ä½“è¯Šæ–­å¯¹è¯ç”Ÿæˆã€‚æˆ‘ä»¬ä½¿ç”¨ç¡®ä¿ä¸´åºŠç›¸å…³æ€§å’Œå¤šæ ·æ€§çš„æµæ°´çº¿åˆ›å»ºäº†502ä¸ªåˆæˆEMRï¼Œç”¨äºå¸¸è§å…±ç—…æ¡ä»¶ã€‚æˆ‘ä»¬çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶å°†ä¸´åºŠè®¿è°ˆåè®®è½¬æ¢ä¸ºåˆ†çº§çŠ¶æ€æœºå’Œä¸Šä¸‹æ–‡æ ‘ï¼Œæ”¯æŒè¶…è¿‡130ç§è¯Šæ–­çŠ¶æ€ï¼ŒåŒæ—¶ä¿æŒä¸´åºŠæ ‡å‡†ã€‚é€šè¿‡è¿™ä¸€ä¸¥æ ¼çš„æµç¨‹ï¼Œæˆ‘ä»¬æ„å»ºäº†PsyCoTalkï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªæ”¯æŒå…±ç—…çš„å¤§è§„æ¨¡å¯¹è¯æ•°æ®é›†ï¼ŒåŒ…å«3000ä¸ªç”± PsychiatristséªŒè¯çš„å¤šè½®è¯Šæ–­å¯¹è¯ã€‚è¯¥æ•°æ®é›†æé«˜äº†è¯Šæ–­å‡†ç¡®æ€§å¹¶ä¿ƒè¿›äº†æ²»ç–—è§„åˆ’ï¼Œä¸ºç²¾ç¥ç—…å…±ç—…ç ”ç©¶æä¾›äº†å®è´µçš„èµ„æºã€‚ä¸å®é™…ä¸´åºŠè½¬å½•ç›¸æ¯”ï¼ŒPsyCoTalkåœ¨å¯¹è¯é•¿åº¦ã€ä»¤ç‰Œåˆ†å¸ƒå’Œè¯Šæ–­æ¨ç†ç­–ç•¥æ–¹é¢è¡¨ç°å‡ºé«˜åº¦çš„ç»“æ„å’Œè¯­è¨€ä¸€è‡´æ€§ã€‚æ‰§ä¸šç²¾ç¥ç§‘åŒ»ç”Ÿè¯å®äº†å¯¹è¯çš„ç°å®æ€§å’Œè¯Šæ–­æœ‰æ•ˆæ€§ã€‚è¯¥æ•°æ®é›†ä½¿å¾—èƒ½å¤Ÿåœ¨å•æ¬¡å¯¹è¯ä¸­å¼€å‘å’Œè¯„ä¼°èƒ½å¤Ÿè¿›è¡Œå¤šéšœç¢ç²¾ç¥ç–¾ç—…ç­›æŸ¥çš„æ¨¡å‹æˆä¸ºå¯èƒ½ã€‚', 'title_zh': 'ä»åŒ»ç–—è®°å½•åˆ°è¯Šæ–­å¯¹è¯ï¼šä¸€ç§åŸºäºä¸´åºŠçš„æ–¹æ³•åŠç²¾ç¥éšœç¢å…±ç—…æ•°æ®é›†'}
{'arxiv_id': 'arXiv:2510.25223', 'title': 'FELA: A Multi-Agent Evolutionary System for Feature Engineering of Industrial Event Log Data', 'authors': 'Kun ouyang, Haoyu Wang, Dong Fang', 'link': 'https://arxiv.org/abs/2510.25223', 'abstract': 'Event log data, recording fine-grained user actions and system events, represent one of the most valuable assets for modern digital services. However, the complexity and heterogeneity of industrial event logs--characterized by large scale, high dimensionality, diverse data types, and intricate temporal or relational structures--make feature engineering extremely challenging. Existing automatic feature engineering approaches, such as AutoML or genetic methods, often suffer from limited explainability, rigid predefined operations, and poor adaptability to complicated heterogeneous data. In this paper, we propose FELA (Feature Engineering LLM Agents), a multi-agent evolutionary system that autonomously extracts meaningful and high-performing features from complex industrial event log data. FELA integrates the reasoning and coding capabilities of large language models (LLMs) with an insight-guided self-evolution paradigm. Specifically, FELA employs specialized agents--Idea Agents, Code Agents, and Critic Agents--to collaboratively generate, validate, and implement novel feature ideas. An Evaluation Agent summarizes feedback and updates a hierarchical knowledge base and dual-memory system to enable continual improvement. Moreover, FELA introduces an agentic evolution algorithm, combining reinforcement learning and genetic algorithm principles to balance exploration and exploitation across the idea space. Extensive experiments on real industrial datasets demonstrate that FELA can generate explainable, domain-relevant features that significantly improve model performance while reducing manual effort. Our results highlight the potential of LLM-based multi-agent systems as a general framework for automated, interpretable, and adaptive feature engineering in complex real-world environments.', 'abstract_zh': 'åŸºäºå¤šæ™ºèƒ½ä½“çš„äº‹ä»¶æ—¥å¿—ç‰¹å¾å·¥ç¨‹LLMä»£ç†ç³»ç»Ÿ', 'title_zh': 'FELAï¼šä¸€ç§é¢å‘å·¥ä¸šäº‹ä»¶æ—¥å¿—æ•°æ®ç‰¹å¾å·¥ç¨‹çš„å¤šagentè¿›åŒ–ç³»ç»Ÿ'}
{'arxiv_id': 'arXiv:2510.25206', 'title': 'RAVR: Reference-Answer-guided Variational Reasoning for Large Language Models', 'authors': 'Tianqianjin Lin, Xi Zhao, Xingyao Zhang, Rujiao Long, Yi Xu, Zhuoren Jiang, Wenbo Su, Bo Zheng', 'link': 'https://arxiv.org/abs/2510.25206', 'abstract': "Reinforcement learning (RL) can refine the reasoning abilities of large language models (LLMs), but critically depends on a key prerequisite: the LLM can already generate high-utility reasoning paths with non-negligible probability. For tasks beyond the LLM's current competence, such reasoning path can be hard to sample, and learning risks reinforcing familiar but suboptimal reasoning. We are motivated by the insight from cognitive science that Why is this the answer is often an easier question than What is the answer, as it avoids the heavy cognitive load of open-ended exploration, opting instead for explanatory reconstruction-systematically retracing the reasoning that links a question to its answer. We show that LLMs can similarly leverage answers to derive high-quality reasoning paths. We formalize this phenomenon and prove that conditioning on answer provably increases the expected utility of sampled reasoning paths, thereby transforming intractable problems into learnable ones. Building on this insight, we introduce RAVR (Reference-Answer-guided Variational Reasoning), an end-to-end framework that uses answer-conditioned reasoning as a variational surrogate for question-only reasoning. Experiments in both general and math domains demonstrate consistent improvements over strong baselines. We further analyze the reasoning behavior and find that RAVR reduces hesitation, strengthens conclusion consolidation, and promotes problem-specific strategies in reasoning.", 'abstract_zh': 'å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å¯ä»¥æå‡å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ¨ç†èƒ½åŠ›ï¼Œä½†å…³é”®ä¾èµ–äºä¸€ä¸ªå‰æï¼šLLMå·²ç»èƒ½å¤Ÿä»¥éè½»å¿½çš„æ¦‚ç‡ç”Ÿæˆé«˜ä»·å€¼çš„æ¨ç†è·¯å¾„ã€‚å¯¹äºè¶…å‡ºLLMå½“å‰èƒ½åŠ›èŒƒå›´çš„ä»»åŠ¡ï¼Œè¿™æ ·çš„æ¨ç†è·¯å¾„éš¾ä»¥é‡‡æ ·ï¼Œå­¦ä¹ è¿‡ç¨‹ä¸­å¯èƒ½ä¼šå¼ºåŒ–ä¸€äº›ç†Ÿæ‚‰ä½†éæœ€ä¼˜çš„æ¨ç†æ–¹å¼ã€‚æˆ‘ä»¬å—åˆ°äº†è®¤çŸ¥ç§‘å­¦çš„å¯å‘ï¼Œè®¤è¯†åˆ°â€œä¸ºä»€ä¹ˆè¿™æ˜¯ç­”æ¡ˆâ€å¾€å¾€æ¯”â€œç­”æ¡ˆæ˜¯ä»€ä¹ˆâ€æ›´å®¹æ˜“å›ç­”ï¼Œå› ä¸ºå®ƒé¿å…äº†å¼€æ”¾æ¢ç´¢çš„è®¤çŸ¥è´Ÿæ‹…ï¼Œè½¬è€Œé€šè¿‡è§£é‡Šæ€§é‡æ„ç³»ç»Ÿåœ°è¿½æº¯é—®é¢˜ä¸ç­”æ¡ˆä¹‹é—´çš„æ¨ç†è¿‡ç¨‹ã€‚æˆ‘ä»¬å±•ç¤ºäº†LLMå¯ä»¥é€šè¿‡ç­”æ¡ˆå¼•å¯¼æ¥ç”Ÿæˆé«˜è´¨é‡çš„æ¨ç†è·¯å¾„ã€‚æˆ‘ä»¬æ­£å¼åŒ–äº†è¿™ä¸€ç°è±¡ï¼Œå¹¶è¯æ˜äº†åœ¨ç­”æ¡ˆæ¡ä»¶ä¸‹æ¨ç†å¯ä»¥æ˜¾è‘—æé«˜é‡‡æ ·æ¨ç†è·¯å¾„çš„æœŸæœ›ä»·å€¼ï¼Œä»è€Œå°†ä¸å¯å¤„ç†çš„é—®é¢˜è½¬åŒ–ä¸ºå¯å­¦ä¹ çš„é—®é¢˜ã€‚åŸºäºè¿™ä¸€æ´å¯Ÿï¼Œæˆ‘ä»¬å¼•å…¥äº†RAVRï¼ˆå‚è€ƒ-ç­”æ¡ˆå¼•å¯¼å˜åˆ†æ¨ç†ï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä½¿ç”¨ç­”æ¡ˆæ¡ä»¶ä¸‹çš„æ¨ç†ä½œä¸ºä»…é—®é¢˜æ¨ç†çš„å˜åˆ†è¿‘ä¼¼ã€‚åœ¨é€šç”¨å’Œæ•°å­¦é¢†åŸŸçš„å®éªŒä¸­ï¼ŒRAVRåœ¨å¤šä¸ªå¼ºåŸºçº¿æ¨¡å‹ä¸Šè¡¨ç°å‡ºä¸€è‡´çš„æ”¹è¿›ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥åˆ†æäº†æ¨ç†è¡Œä¸ºï¼Œå‘ç°RAVRå‡å°‘äº†çŠ¹è±«ã€å¢å¼ºäº†ç»“è®ºå·©å›ºï¼Œå¹¶ä¿ƒè¿›äº†ç‰¹å®šäºé—®é¢˜çš„æ¨ç†ç­–ç•¥ã€‚', 'title_zh': 'RAVR: å‚è€ƒç­”æ¡ˆå¼•å¯¼çš„å˜åˆ†æ¨ç†æ–¹æ³•ç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹'}
{'arxiv_id': 'arXiv:2510.25205', 'title': 'Energy-Efficient Autonomous Driving with Adaptive Perception and Robust Decision', 'authors': 'Yuyang Xia, Zibo Liang, Liwei Deng, Yan Zhao, Han Su, Kai Zheng', 'link': 'https://arxiv.org/abs/2510.25205', 'abstract': 'Autonomous driving is an emerging technology that is expected to bring significant social, economic, and environmental benefits. However, these benefits come with rising energy consumption by computation engines, limiting the driving range of vehicles, especially electric ones. Perception computing is typically the most power-intensive component, as it relies on largescale deep learning models to extract environmental features. Recently, numerous studies have employed model compression techniques, such as sparsification, quantization, and distillation, to reduce computational consumption. However, these methods often result in either a substantial model size or a significant drop in perception accuracy compared to high-computation models. To address these challenges, we propose an energy-efficient autonomous driving framework, called EneAD. In the adaptive perception module, a perception optimization strategy is designed from the perspective of data management and tuning. Firstly, we manage multiple perception models with different computational consumption and adjust the execution framerate dynamically. Then, we define them as knobs and design a transferable tuning method based on Bayesian optimization to identify promising knob values that achieve low computation while maintaining desired accuracy. To adaptively switch the knob values in various traffic scenarios, a lightweight classification model is proposed to distinguish the perception difficulty in different scenarios. In the robust decision module, we propose a decision model based on reinforcement learning and design a regularization term to enhance driving stability in the face of perturbed perception results. Extensive experiments evidence the superiority of our framework in both energy consumption and driving performance. EneAD can reduce perception consumption by 1.9x to 3.5x and thus improve driving range by 3.9% to 8.5%', 'abstract_zh': 'è‡ªä¸»é©¾é©¶æ˜¯ä¸€ç§æ–°å…´æŠ€æœ¯ï¼Œé¢„æœŸå°†å¸¦æ¥æ˜¾è‘—çš„ç¤¾ä¼šã€ç»æµå’Œç¯å¢ƒæ•ˆç›Šã€‚ç„¶è€Œï¼Œè¿™äº›æ•ˆç›Šä¼´éšç€è®¡ç®—å¼•æ“èƒ½è€—çš„å¢åŠ ï¼Œé™åˆ¶äº†è½¦è¾†çš„è¡Œé©¶é‡Œç¨‹ï¼Œå°¤å…¶æ˜¯ç”µåŠ¨è½¦ã€‚æ„ŸçŸ¥è®¡ç®—é€šå¸¸æ˜¯èƒ½è€—æœ€å¤§çš„ç»„ä»¶ï¼Œå› ä¸ºå®ƒä¾èµ–å¤§è§„æ¨¡çš„æ·±åº¦å­¦ä¹ æ¨¡å‹æ¥æå–ç¯å¢ƒç‰¹å¾ã€‚æœ€è¿‘ï¼Œè®¸å¤šç ”ç©¶é‡‡ç”¨äº†æ¨¡å‹å‹ç¼©æŠ€æœ¯ï¼Œå¦‚ç¨€ç–åŒ–ã€é‡åŒ–å’Œè’¸é¦ï¼Œä»¥å‡å°‘è®¡ç®—æ¶ˆè€—ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å¾€å¾€ä¼šå¯¼è‡´æ¨¡å‹å¤§å°æ˜¾è‘—å¢åŠ æˆ–æ„ŸçŸ¥å‡†ç¡®æ€§æ˜¾è‘—ä¸‹é™ã€‚ä¸ºåº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§èƒ½æ•ˆè‡ªä¸»é©¾é©¶æ¡†æ¶ï¼Œç§°ä¸ºEneADã€‚åœ¨è‡ªé€‚åº”æ„ŸçŸ¥æ¨¡å—ä¸­ï¼Œæˆ‘ä»¬ä»æ•°æ®ç®¡ç†å’Œè°ƒä¼˜çš„è§’åº¦è®¾è®¡äº†ä¸€ç§æ„ŸçŸ¥ä¼˜åŒ–ç­–ç•¥ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ç®¡ç†å…·æœ‰ä¸åŒè®¡ç®—æ¶ˆè€—çš„å¤šç§æ„ŸçŸ¥æ¨¡å‹ï¼Œå¹¶åŠ¨æ€è°ƒæ•´æ‰§è¡Œå¸§ç‡ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†è¿™äº›æ¨¡å‹å®šä¹‰ä¸ºæ—‹é’®ï¼Œå¹¶åŸºäºè´å¶æ–¯ä¼˜åŒ–è®¾è®¡äº†ä¸€ç§å¯è½¬ç§»çš„è°ƒä¼˜æ–¹æ³•ï¼Œä»¥è¯†åˆ«èƒ½å¤Ÿåœ¨ä½è®¡ç®—æ¶ˆè€—çš„åŒæ—¶ä¿æŒæ‰€éœ€å‡†ç¡®æ€§çš„ä¼˜è´¨æ—‹é’®å€¼ã€‚ä¸ºäº†æ ¹æ®ä¸åŒäº¤é€šåœºæ™¯è‡ªé€‚åº”åˆ‡æ¢æ—‹é’®å€¼ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è½»é‡çº§åˆ†ç±»æ¨¡å‹æ¥åŒºåˆ†ä¸åŒåœºæ™¯ä¸‹çš„æ„ŸçŸ¥éš¾åº¦ã€‚åœ¨ç¨³å¥å†³ç­–æ¨¡å—ä¸­ï¼Œæˆ‘ä»¬åŸºäºå¼ºåŒ–å­¦ä¹ æå‡ºäº†ä¸€ç§å†³ç­–æ¨¡å‹ï¼Œå¹¶è®¾è®¡äº†ä¸€ä¸ªæ­£åˆ™åŒ–é¡¹ä»¥åœ¨æ„ŸçŸ¥ç»“æœé”™ä½æ—¶å¢å¼ºé©¾é©¶ç¨³å®šæ€§ã€‚å¹¿æ³›çš„å®éªŒè¯æ®è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¡†æ¶åœ¨èƒ½è€—å’Œé©¾é©¶æ€§èƒ½æ–¹é¢å…·æœ‰ä¼˜è¶Šæ€§ã€‚EneADå¯ä»¥å°†æ„ŸçŸ¥æ¶ˆè€—é™ä½1.9è‡³3.5å€ï¼Œä»è€Œæé«˜3.9%è‡³8.5%çš„è¡Œé©¶é‡Œç¨‹ã€‚', 'title_zh': 'è‡ªé€‚åº”æ„ŸçŸ¥ä¸ç¨³å¥å†³ç­–çš„èŠ‚èƒ½è‡ªä¸»é©¾é©¶'}
{'arxiv_id': 'arXiv:2510.25179', 'title': 'Agentic Moderation: Multi-Agent Design for Safer Vision-Language Models', 'authors': 'Juan Ren, Mark Dras, Usman Naseem', 'link': 'https://arxiv.org/abs/2510.25179', 'abstract': 'Agentic methods have emerged as a powerful and autonomous paradigm that enhances reasoning, collaboration, and adaptive control, enabling systems to coordinate and independently solve complex tasks. We extend this paradigm to safety alignment by introducing Agentic Moderation, a model-agnostic framework that leverages specialised agents to defend multimodal systems against jailbreak attacks. Unlike prior approaches that apply as a static layer over inputs or outputs and provide only binary classifications (safe or unsafe), our method integrates dynamic, cooperative agents, including Shield, Responder, Evaluator, and Reflector, to achieve context-aware and interpretable moderation. Extensive experiments across five datasets and four representative Large Vision-Language Models (LVLMs) demonstrate that our approach reduces the Attack Success Rate (ASR) by 7-19%, maintains a stable Non-Following Rate (NF), and improves the Refusal Rate (RR) by 4-20%, achieving robust, interpretable, and well-balanced safety performance. By harnessing the flexibility and reasoning capacity of agentic architectures, Agentic Moderation provides modular, scalable, and fine-grained safety enforcement, highlighting the broader potential of agentic systems as a foundation for automated safety governance.', 'abstract_zh': 'ä»£ç†æ–¹æ³•å·²æˆä¸ºä¸€ç§å¼ºå¤§ä¸”è‡ªä¸»çš„èŒƒå¼ï¼Œå¢å¼ºäº†æ¨ç†ã€åä½œå’Œè‡ªé€‚åº”æ§åˆ¶èƒ½åŠ›ï¼Œä½¿ç³»ç»Ÿèƒ½å¤Ÿåè°ƒå¹¶ç‹¬ç«‹è§£å†³å¤æ‚ä»»åŠ¡ã€‚æˆ‘ä»¬é€šè¿‡å¼•å…¥ä»£ç†è°ƒèŠ‚æ¥æ‰©å±•è¿™ä¸€èŒƒå¼ï¼Œè¿™æ˜¯ä¸€ç§æ¨¡å‹æ— å…³çš„æ¡†æ¶ï¼Œåˆ©ç”¨ä¸“é—¨çš„ä»£ç†æ¥é˜²å¾¡å¤šæ¨¡æ€ç³»ç»Ÿå…å—é€ƒé€¸æ”»å‡»ã€‚ä¸ä¹‹å‰ä»…åœ¨è¾“å…¥æˆ–è¾“å‡ºä¸Šä½œä¸ºé™æ€å±‚åº”ç”¨å¹¶ä»…æä¾›äºŒå…ƒåˆ†ç±»ï¼ˆå®‰å…¨æˆ–ä¸å®‰å…¨ï¼‰çš„æ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ•´åˆäº†åŠ¨æ€ã€åä½œçš„ä»£ç†ï¼ŒåŒ…æ‹¬Shieldã€Responderã€Evaluatorå’ŒReflectorï¼Œä»¥å®ç°ä¸Šä¸‹æ–‡æ„ŸçŸ¥å’Œå¯è§£é‡Šçš„è°ƒèŠ‚ã€‚æˆ‘ä»¬åœ¨äº”ä¸ªæ•°æ®é›†å’Œå››ä¸ªä»£è¡¨æ€§å¤§è§†è§‰-è¯­è¨€æ¨¡å‹ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å°†æ”»å‡»æˆåŠŸç‡ï¼ˆASRï¼‰é™ä½äº†7-19%ï¼Œä¿æŒäº†ç¨³å®šçš„éè·Ÿéšç‡ï¼ˆNFï¼‰ï¼Œå¹¶å°†æ‹’ç»ç‡ï¼ˆRRï¼‰æé«˜äº†4-20%ï¼Œå®ç°äº†ç¨³å¥ã€å¯è§£é‡Šä¸”å‡è¡¡çš„å®‰å…¨æ€§èƒ½ã€‚é€šè¿‡åˆ©ç”¨ä»£ç†æ¶æ„çš„çµæ´»æ€§å’Œæ¨ç†èƒ½åŠ›ï¼Œä»£ç†è°ƒèŠ‚æä¾›äº†æ¨¡å—åŒ–ã€å¯æ‰©å±•å’Œç²¾ç»†çš„å®‰å…¨æ‰§è¡Œï¼Œçªæ˜¾äº†ä»£ç†ç³»ç»Ÿä½œä¸ºè‡ªåŠ¨å®‰å…¨æ²»ç†åŸºç¡€çš„æ›´å¹¿æ³›æ½œåŠ›ã€‚', 'title_zh': 'ä»£ç†è°ƒèŠ‚ï¼šå¤šä»£ç†è®¾è®¡ä»¥æ„å»ºæ›´å®‰å…¨çš„è§†è§‰è¯­è¨€æ¨¡å‹'}
{'arxiv_id': 'arXiv:2510.25101', 'title': 'KnowCoder-A1: Incentivizing Agentic Reasoning Capability with Outcome Supervision for KBQA', 'authors': 'Zhuo Chen, Fei Wang, Zixuan Li, Zhao Zhang, Weiwei Ding, Chuanguang Yang, Yongjun Xu, Xiaolong Jin, Jiafeng Guo', 'link': 'https://arxiv.org/abs/2510.25101', 'abstract': 'Knowledge Base Question Answering (KBQA) aims to answer natural-language questions over a structured Knowledge Base (KB). Recent work improves KBQA by adopting an agentic reasoning paradigm, in which Large Language Models (LLMs) iteratively decompose a question, generate its corresponding logical queries, and interact with the KB to derive the answer. However, these methods typically fine-tune LLMs on reasoning trajectories synthesized via process supervision, which offers weak incentives for exploration and thus fails to strengthen the agentic reasoning ability. In this paper, we propose KnowCoder-A1, an LLM that can autonomously perform agentic reasoning on KBs to obtain answers. To incentivize autonomous exploration, KnowCoder-A1 trains the LLM under outcome-only supervision via a multi-stage curriculum reinforcement learning with an easy-to-hard curriculum. To establish foundational agentic capabilities, KnowCoder-A1 first fine-tunes the LLM on a small set of high-quality trajectories obtained through outcome-based rejection sampling. Then, to alleviate the reward sparsity inherent in outcome-only supervision, it applies multi-stage curriculum RL with reward schedules that progress from easy to hard. Trained with outcome-only supervision, KnowCoder-A1 exhibits powerful reasoning behaviors and consistently outperforms prior approaches across three mainstream datasets. Notably, on the zero-shot subset of GrailQA, KnowCoder-A1 achieves up to an 11.1% relative improvement while using only one-twelfth of the training data, demonstrating strong agentic reasoning capabilities.', 'abstract_zh': 'åŸºäºçŸ¥è¯†åº“çš„æ¨ç†é—®ç­”ï¼ˆKBQAï¼‰æ—¨åœ¨é€šè¿‡ç»“æ„åŒ–çŸ¥è¯†åº“ï¼ˆKBï¼‰å›ç­”è‡ªç„¶è¯­è¨€é—®é¢˜ã€‚æœ€è¿‘çš„å·¥ä½œé€šè¿‡é‡‡ç”¨ä»£ç†æ¨ç†èŒƒå¼æ¥æé«˜KBQAï¼Œå…¶ä¸­å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿­ä»£åœ°åˆ†è§£é—®é¢˜ã€ç”Ÿæˆç›¸åº”çš„é€»è¾‘æŸ¥è¯¢ï¼Œå¹¶ä¸çŸ¥è¯†åº“äº¤äº’ä»¥è·å–ç­”æ¡ˆã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸é€šè¿‡è¿‡ç¨‹ç›‘ç£åˆæˆæ¨ç†è½¨è¿¹å¯¹LLMsè¿›è¡Œå¾®è°ƒï¼Œè¿™æä¾›äº†è¾ƒå¼±çš„æ¢ç´¢æ¿€åŠ±ï¼Œä»è€Œæœªèƒ½å¢å¼ºä»£ç†æ¨ç†èƒ½åŠ›ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºKnowCoder-A1çš„LLMï¼Œå®ƒå¯ä»¥è‡ªä¸»åœ¨çŸ¥è¯†åº“ä¸Šè¿›è¡Œä»£ç†æ¨ç†ä»¥è·å–ç­”æ¡ˆã€‚ä¸ºäº†æ¿€åŠ±è‡ªä¸»æ¢ç´¢ï¼ŒKnowCoder-A1é€šè¿‡å…·æœ‰ä»æ˜“åˆ°éš¾è¯¾ç¨‹çš„å¤šé˜¶æ®µå¼ºåŒ–å­¦ä¹ åœ¨ä»…å‡­æœ€ç»ˆç»“æœç›‘ç£ä¸‹è®­ç»ƒLLMã€‚ä¸ºäº†å»ºç«‹åŸºç¡€çš„ä»£ç†èƒ½åŠ›ï¼ŒKnowCoder-A1é¦–å…ˆä½¿ç”¨åŸºäºç»“æœçš„æ‹’ç»é‡‡æ ·è·å–ä¸€å°éƒ¨åˆ†é«˜è´¨é‡çš„è½¨è¿¹å¯¹LLMè¿›è¡Œå¾®è°ƒï¼Œç„¶åï¼Œä¸ºäº†ç¼“è§£ä»…å‡­æœ€ç»ˆç»“æœç›‘ç£å›ºæœ‰çš„å¥–åŠ±ç¨€ç–æ€§ï¼Œå®ƒä½¿ç”¨å…·æœ‰ä»æ˜“åˆ°éš¾å¥–åŠ±è°ƒåº¦çš„å¤šé˜¶æ®µè¯¾ç¨‹å¼ºåŒ–å­¦ä¹ ã€‚ä»…å‡­æœ€ç»ˆç»“æœç›‘ç£è®­ç»ƒä¸‹ï¼ŒKnowCoder-A1è¡¨ç°å‡ºå¼ºå¤§çš„æ¨ç†è¡Œä¸ºï¼Œå¹¶ä¸”åœ¨ä¸‰ä¸ªä¸»æµæ•°æ®é›†ä¸Šå‡ä¼˜äºå…ˆå‰æ–¹æ³•ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨GrailQAçš„é›¶æ ·æœ¬å­é›†ä¸Šï¼ŒKnowCoder-A1ä»…ä½¿ç”¨è®­ç»ƒæ•°æ®çš„åäºŒåˆ†ä¹‹ä¸€ä¾¿å®ç°äº†é«˜è¾¾11.1%çš„ç›¸å¯¹æ”¹è¿›ï¼Œå±•ç¤ºäº†å¼ºå¤§çš„ä»£ç†æ¨ç†èƒ½åŠ›ã€‚', 'title_zh': 'KnowCoder-A1ï¼šåŸºäºç»“æœç›‘ç£æ¿€åŠ±ä»£ç†æ¨ç†èƒ½åŠ›çš„KBQA'}
{'arxiv_id': 'arXiv:2510.25091', 'title': 'H3M-SSMoEs: Hypergraph-based Multimodal Learning with LLM Reasoning and Style-Structured Mixture of Experts', 'authors': 'Peilin Tan, Liang Xie, Churan Zhi, Dian Tu, Chuanqi Shi', 'link': 'https://arxiv.org/abs/2510.25091', 'abstract': 'Stock movement prediction remains fundamentally challenging due to complex temporal dependencies, heterogeneous modalities, and dynamically evolving inter-stock relationships. Existing approaches often fail to unify structural, semantic, and regime-adaptive modeling within a scalable framework. This work introduces H3M-SSMoEs, a novel Hypergraph-based MultiModal architecture with LLM reasoning and Style-Structured Mixture of Experts, integrating three key innovations: (1) a Multi-Context Multimodal Hypergraph that hierarchically captures fine-grained spatiotemporal dynamics via a Local Context Hypergraph (LCH) and persistent inter-stock dependencies through a Global Context Hypergraph (GCH), employing shared cross-modal hyperedges and Jensen-Shannon Divergence weighting mechanism for adaptive relational learning and cross-modal alignment; (2) a LLM-enhanced reasoning module, which leverages a frozen large language model with lightweight adapters to semantically fuse and align quantitative and textual modalities, enriching representations with domain-specific financial knowledge; and (3) a Style-Structured Mixture of Experts (SSMoEs) that combines shared market experts and industry-specialized experts, each parameterized by learnable style vectors enabling regime-aware specialization under sparse activation. Extensive experiments on three major stock markets demonstrate that H3M-SSMoEs surpasses state-of-the-art methods in both superior predictive accuracy and investment performance, while exhibiting effective risk control. Datasets, source code, and model weights are available at our GitHub repository: this https URL.', 'abstract_zh': 'åŸºäºè¶…å›¾çš„å¤šæ¨¡æ€H3M-SSMoEsæ¶æ„ï¼šç»“åˆLLMæ¨ç†å’Œé£æ ¼ç»“æ„åŒ–ä¸“å®¶ä»¥é¢„æµ‹è‚¡ç¥¨å¸‚åœºåŠ¨å‘', 'title_zh': 'åŸºäºè¶…å›¾çš„å¤šæ¨¡æ€å­¦ä¹ ä¸LLMæ¨ç†åŠé£æ ¼ç»“æ„åŒ–ä¸“å®¶æ··åˆæ¨¡å‹'}
{'arxiv_id': 'arXiv:2510.25065', 'title': 'Reasoning-Aware GRPO using Process Mining', 'authors': 'Taekhyun Park, Yongjae Lee, Hyerim Bae', 'link': 'https://arxiv.org/abs/2510.25065', 'abstract': "Reinforcement learning (RL)-based post-training has been crucial for enabling multi-step reasoning in large reasoning models (LRMs), yet current reward schemes are typically outcome-centric. We propose PM4GRPO, a reasoning-aware Group Relative Policy Optimization (GRPO) that augments standard answer/format rewards with signals over the reasoning procedure. To this end, process mining techniques are utilized to compute a scalar conformance reward that measures how closely a policy model's reasoning aligns with the pretrained teacher model. The empirical results on five benchmarks demonstrate that PM4GRPO significantly outperforms existing methodologies for GRPO-based post-training. These results highlight that leveraging process mining for reasoning-aware GRPO effectively enhances the reasoning capabilities of policy models.", 'abstract_zh': 'åŸºäºå¼ºåŒ–å­¦ä¹ çš„å¤„ç†æ„ŸçŸ¥Group Relative Policy Optimization (PM4GRPO)ï¼šé€šè¿‡å¢å¼ºæ¨ç†è¿‡ç¨‹ä¿¡å·æé«˜å¤§å‹æ¨ç†æ¨¡å‹çš„å¤šæ­¥æ¨ç†èƒ½åŠ›', 'title_zh': 'åŸºäºæ¨ç†çš„è®¤çŸ¥GRPOè¿‡ç¨‹æŒ–æ˜'}
{'arxiv_id': 'arXiv:2510.25014', 'title': 'Aligning Large Language Models with Procedural Rules: An Autoregressive State-Tracking Prompting for In-Game Trading', 'authors': 'Minkyung Kim, Junsik Kim, Woongcheol Yang, Sangdon Park, Sohee Bae', 'link': 'https://arxiv.org/abs/2510.25014', 'abstract': "Large Language Models (LLMs) enable dynamic game interactions but fail to follow essential procedural flows in rule-governed trading systems, eroding player trust. This work resolves the core tension between the creative flexibility of LLMs and the procedural demands of in-game trading (browse-offer-review-confirm). To this end, Autoregressive State-Tracking Prompting (ASTP) is introduced, a methodology centered on a strategically orchestrated prompt that compels an LLM to make its state-tracking process explicit and verifiable. Instead of relying on implicit contextual understanding, ASTP tasks the LLM with identifying and reporting a predefined state label from the previous turn. To ensure transactional integrity, this is complemented by a state-specific placeholder post-processing method for accurate price calculations. Evaluation across 300 trading dialogues demonstrates >99% state compliance and 99.3% calculation precision. Notably, ASTP with placeholder post-processing on smaller models (Gemini-2.5-Flash) matches larger models' (Gemini-2.5-Pro) performance while reducing response time from 21.2s to 2.4s, establishing a practical foundation that satisfies both real-time requirements and resource constraints of commercial games.", 'abstract_zh': 'è‡ªåŠ¨å›å½’çŠ¶æ€è·Ÿè¸ªæç¤ºï¼ˆASTPï¼‰æ–¹æ³•ï¼šè§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è§„åˆ™ govern çš„äº¤æ˜“ç³»ç»Ÿä¸­æ¸¸æˆäº¤æ˜“æµç¨‹åˆè§„æ€§ä¸åˆ›æ„çµæ´»æ€§ä¹‹é—´çš„æ ¸å¿ƒå¼ åŠ›', 'title_zh': 'åŸºäºè‡ªå›å½’çŠ¶æ€è·Ÿè¸ªæç¤ºçš„ç¨‹åºè§„åˆ™å¯¹é½å¤§å‹è¯­è¨€æ¨¡å‹ï¼šæ¸¸æˆå†…äº¤æ˜“åœºæ™¯ä¸­çš„åº”ç”¨'}
{'arxiv_id': 'arXiv:2510.25007', 'title': 'Taming the Real-world Complexities in CPT E/M Coding with Large Language Models', 'authors': 'Islam Nassar, Yang Lin, Yuan Jin, Rongxin Zhu, Chang Wei Tan, Zenan Zhai, Nitika Mathur, Thanh Tien Vu, Xu Zhong, Long Duong, Yuan-Fang Li', 'link': 'https://arxiv.org/abs/2510.25007', 'abstract': "Evaluation and Management (E/M) coding, under the Current Procedural Terminology (CPT) taxonomy, documents medical services provided to patients by physicians. Used primarily for billing purposes, it is in physicians' best interest to provide accurate CPT E/M codes. %While important, it is an auxiliary task that adds to physicians' documentation burden. Automating this coding task will help alleviate physicians' documentation burden, improve billing efficiency, and ultimately enable better patient care. However, a number of real-world complexities have made E/M encoding automation a challenging task. In this paper, we elaborate some of the key complexities and present ProFees, our LLM-based framework that tackles them, followed by a systematic evaluation. On an expert-curated real-world dataset, ProFees achieves an increase in coding accuracy of more than 36\\% over a commercial CPT E/M coding system and almost 5\\% over our strongest single-prompt baseline, demonstrating its effectiveness in addressing the real-world complexities.", 'abstract_zh': 'E/Mç¼–ç åœ¨å½“å‰ç¨‹åºæœ¯è¯­(CPT)åˆ†ç±»ä½“ç³»ä¸‹è®°å½•äº†åŒ»ç”Ÿä¸ºæ‚£è€…æä¾›çš„åŒ»ç–—æœåŠ¡ã€‚ä¸»è¦ç”¨äºæ”¶è´¹ç›®çš„ï¼Œæä¾›å‡†ç¡®çš„CPT E/Mç¼–ç ç¬¦åˆåŒ»ç”Ÿçš„æœ€ä½³åˆ©ç›Šã€‚è™½ç„¶é‡è¦ï¼Œä½†è¿™æ˜¯ä¸€é¡¹è¾…åŠ©ä»»åŠ¡ï¼Œå¢åŠ äº†åŒ»ç”Ÿçš„æ–‡æ¡£è´Ÿæ‹…ã€‚è‡ªåŠ¨åŒ–æ­¤ç¼–ç ä»»åŠ¡å°†æœ‰åŠ©äºå‡è½»åŒ»ç”Ÿçš„æ–‡æ¡£è´Ÿæ‹…ï¼Œæé«˜æ”¶è´¹æ•ˆç‡ï¼Œå¹¶æœ€ç»ˆä¿ƒè¿›æ›´å¥½çš„æ‚£è€…æŠ¤ç†ã€‚ç„¶è€Œï¼Œè®¸å¤šç°å®ä¸–ç•Œä¸­çš„å¤æ‚æ€§ä½¿å¾—E/Mç¼–ç è‡ªåŠ¨åŒ–æˆä¸ºä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é˜è¿°äº†ä¸€äº›å…³é”®çš„å¤æ‚æ€§ï¼Œå¹¶ä»‹ç»äº†æˆ‘ä»¬çš„åŸºäºLLMçš„æ¡†æ¶ProFeesï¼Œè¯¥æ¡†æ¶è§£å†³äº†è¿™äº›é—®é¢˜ï¼Œæ¥ç€è¿›è¡Œäº†ç³»ç»Ÿçš„è¯„ä¼°ã€‚åœ¨ä¸“å®¶ç²¾å¿ƒæ•´ç†çš„ç°å®ä¸–ç•Œæ•°æ®é›†ä¸Šï¼ŒProFeesçš„ç¼–ç å‡†ç¡®æ€§æ¯”å•†ç”¨CPT E/Mç¼–ç ç³»ç»Ÿæé«˜äº†è¶…è¿‡36%ï¼Œæ¯”æˆ‘ä»¬çš„æœ€å¼ºå•ä¸€æç¤ºåŸºçº¿æé«˜äº†è¿‘5%ï¼Œè¿™è¯æ˜äº†å…¶åœ¨åº”å¯¹ç°å®ä¸–ç•Œå¤æ‚æ€§æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚', 'title_zh': 'ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹åº”å¯¹CPT E/Mç¼–ç ä¸­çš„ç°å®å¤æ‚æ€§'}
{'arxiv_id': 'arXiv:2510.25005', 'title': 'Cyclic Counterfactuals under Shift-Scale Interventions', 'authors': 'Saptarshi Saha, Dhruv Vansraj Rathore, Utpal Garain', 'link': 'https://arxiv.org/abs/2510.25005', 'abstract': "Most counterfactual inference frameworks traditionally assume acyclic structural causal models (SCMs), i.e. directed acyclic graphs (DAGs). However, many real-world systems (e.g. biological systems) contain feedback loops or cyclic dependencies that violate acyclicity. In this work, we study counterfactual inference in cyclic SCMs under shift-scale interventions, i.e., soft, policy-style changes that rescale and/or shift a variable's mechanism.", 'abstract_zh': 'å¾ªç¯ç»“æ„å› æœæ¨¡å‹ä¸‹åŸºäºç¼©æ”¾å¹³ç§»å¹²é¢„çš„åäº‹å®æ¨ç†ç ”ç©¶', 'title_zh': 'å¾ªç¯åäº‹å®åˆ†æä¸‹çš„ç§»å°ºå¹²é¢„'}
{'arxiv_id': 'arXiv:2510.24832', 'title': 'Scheduling Your LLM Reinforcement Learning with Reasoning Trees', 'authors': 'Hong Wang, Zhezheng Hao, Jian Luo, Chenxing Wei, Yao Shu, Lei Liu, Qiang Lin, Hande Dong, Jiawei Chen', 'link': 'https://arxiv.org/abs/2510.24832', 'abstract': "Using Reinforcement Learning with Verifiable Rewards (RLVR) to optimize Large Language Models (LLMs) can be conceptualized as progressively editing a query's `Reasoning Tree'. This process involves exploring nodes (tokens) and dynamically modifying the model's policy at each node. When combined with data scheduling, this process yields further gains in data efficiency and accuracy. However, existing RLVR data scheduling methods typically rely on path-based metrics to rank queries, overlooking the reasoning tree structures of these queries. In this paper, we introduce a novel metric, namely Reasoning Score (r-score), which measures the query's learning difficulty based on the structure of its reasoning tree. Based on the r-score, we propose the Reasoning Tree Schedule (Re-Schedule), a scheduling algorithm that constructs a curriculum progressing from structurally simple (high r-score) to complex (low r-score) queries. Experiments on six math-reasoning benchmarks show that Re-Schedule significantly improves average accuracy, achieving gains of up to 3.2%. These strong results validate our approach and demonstrate that a structural understanding of the reasoning tree provides a more powerful and principled foundation for RLVR data scheduling.", 'abstract_zh': 'ä½¿ç”¨å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰ä¼˜åŒ–å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¯ä»¥æ¦‚å¿µåŒ–ä¸ºé€æ­¥ç¼–è¾‘æŸ¥è¯¢çš„â€œæ¨ç†æ ‘â€ã€‚è¿™ä¸€è¿‡ç¨‹æ¶‰åŠæ¢ç´¢èŠ‚ç‚¹ï¼ˆæ ‡è®°ï¼‰å¹¶åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸ŠåŠ¨æ€ä¿®æ”¹æ¨¡å‹çš„ç­–ç•¥ã€‚å½“ä¸æ•°æ®è°ƒåº¦ç»“åˆä½¿ç”¨æ—¶ï¼Œè¿™ä¸€è¿‡ç¨‹å¯è¿›ä¸€æ­¥æé«˜æ•°æ®æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚ç„¶è€Œï¼Œç°æœ‰çš„RLVRæ•°æ®è°ƒåº¦æ–¹æ³•é€šå¸¸ä¾èµ–äºè·¯å¾„æ€§çš„æŒ‡æ ‡æ¥æ’åæŸ¥è¯¢ï¼Œå¿½ç•¥äº†è¿™äº›æŸ¥è¯¢çš„æ¨ç†æ ‘ç»“æ„ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„åº¦é‡æ ‡å‡†ï¼Œå³æ¨ç†åˆ†æ•°ï¼ˆr-scoreï¼‰ï¼Œè¯¥æ ‡å‡†åŸºäºæ¨ç†æ ‘ç»“æ„è¡¡é‡æŸ¥è¯¢çš„å­¦ä¹ éš¾åº¦ã€‚åŸºäºr-scoreï¼Œæˆ‘ä»¬æå‡ºäº†æ¨ç†æ ‘è°ƒåº¦ï¼ˆRe-Scheduleï¼‰ç®—æ³•ï¼Œè¯¥ç®—æ³•æ„å»ºäº†ä¸€ä¸ªä»ç»“æ„ç®€å•ï¼ˆé«˜r-scoreï¼‰åˆ°å¤æ‚ï¼ˆä½r-scoreï¼‰æŸ¥è¯¢çš„è¯¾ç¨‹ã€‚åœ¨å…­ä¸ªæ•°å­¦æ¨ç†åŸºå‡†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒRe-Schedule æ˜¾è‘—æé«˜äº†å¹³å‡å‡†ç¡®ç‡ï¼Œæœ€é«˜å¯è¾¾åˆ°3.2%çš„æå‡ã€‚è¿™äº›ç»“æœéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œå¹¶è¯æ˜äº†å¯¹æ¨ç†æ ‘ç»“æ„çš„ç†è§£ä¸ºRLVRæ•°æ®è°ƒåº¦æä¾›äº†æ›´å¼ºå¤§å’Œåˆç†çš„åŸºç¡€ã€‚', 'title_zh': 'åŸºäºæ¨ç†æ ‘è°ƒåº¦ä½ çš„LLMå¼ºåŒ–å­¦ä¹ '}
{'arxiv_id': 'arXiv:2510.25771', 'title': 'Gaperon: A Peppered English-French Generative Language Model Suite', 'authors': 'Nathan Godey, Wissam Antoun, Rian Touchent, Rachel Bawden, Ã‰ric de la Clergerie, BenoÃ®t Sagot, DjamÃ© Seddah', 'link': 'https://arxiv.org/abs/2510.25771', 'abstract': 'We release Gaperon, a fully open suite of French-English-coding language models designed to advance transparency and reproducibility in large-scale model training. The Gaperon family includes 1.5B, 8B, and 24B parameter models trained on 2-4 trillion tokens, released with all elements of the training pipeline: French and English datasets filtered with a neural quality classifier, an efficient data curation and training framework, and hundreds of intermediate checkpoints. Through this work, we study how data filtering and contamination interact to shape both benchmark and generative performance. We find that filtering for linguistic quality enhances text fluency and coherence but yields subpar benchmark results, and that late deliberate contamination -- continuing training on data mixes that include test sets -- recovers competitive scores while only reasonably harming generation quality. We discuss how usual neural filtering can unintentionally amplify benchmark leakage. To support further research, we also introduce harmless data poisoning during pretraining, providing a realistic testbed for safety studies. By openly releasing all models, datasets, code, and checkpoints, Gaperon establishes a reproducible foundation for exploring the trade-offs between data curation, evaluation, safety, and openness in multilingual language model development.', 'abstract_zh': 'æˆ‘ä»¬å‘å¸ƒäº†Gaperonï¼Œä¸€ä¸ªå…¨å¼€æºçš„æ³•è‹±ç¼–ç è¯­è¨€æ¨¡å‹å¥—ä»¶ï¼Œæ—¨åœ¨æ¨åŠ¨å¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒä¸­çš„é€æ˜åº¦å’Œå¯é‡å¤æ€§ã€‚Gaperonå®¶æ—åŒ…æ‹¬15äº¿ã€8äº¿å’Œ24äº¿å‚æ•°çš„æ¨¡å‹ï¼Œè®­ç»ƒæ•°æ®é‡ä¸º2-4ä¸‡ä¸‡äº¿ä¸ªæ ‡è®°ï¼Œå¹¶é™„å¸¦å®Œæ•´çš„è®­ç»ƒç®¡é“ï¼šç»ç¥ç»è´¨é‡åˆ†ç±»å™¨è¿‡æ»¤çš„æ³•è‹±è¯­æ•°æ®é›†ã€é«˜æ•ˆçš„æ•°æ®æ•´ç†å’Œè®­ç»ƒæ¡†æ¶ä»¥åŠæ•°ç™¾ä¸ªä¸­é—´æ£€æŸ¥ç‚¹ã€‚é€šè¿‡è¿™é¡¹å·¥ä½œï¼Œæˆ‘ä»¬ç ”ç©¶äº†æ•°æ®è¿‡æ»¤å’Œæ±¡æŸ“å¦‚ä½•ç›¸äº’ä½œç”¨ä»¥å½±å“åŸºå‡†æµ‹è¯•å’Œç”Ÿæˆæ€§èƒ½ã€‚æˆ‘ä»¬å‘ç°ï¼Œä¸ºäº†è¯­è¨€è´¨é‡è¿›è¡Œè¿‡æ»¤å¯ä»¥æé«˜æ–‡æœ¬æµç•…æ€§å’Œè¿è´¯æ€§ï¼Œä½†ä¼šå¯¼è‡´åŸºå‡†æµ‹è¯•ç»“æœä¸ä½³ï¼›è€ŒåæœŸæ•…æ„æ±¡æŸ“â€”â€”åœ¨åŒ…å«æµ‹è¯•é›†çš„æ•°æ®æ··åˆä¸­ç»§ç»­è®­ç»ƒâ€”â€”å¯ä»¥åœ¨ä»…åˆç†æŸå®³ç”Ÿæˆè´¨é‡çš„åŒæ—¶æ¢å¤ç«äº‰åŠ›çš„åˆ†æ•°ã€‚æˆ‘ä»¬è®¨è®ºäº†é€šå¸¸çš„ç¥ç»è¿‡æ»¤å¯èƒ½ä¼šæ— æ„ä¸­å¢åŠ åŸºå‡†æ³„æ¼ã€‚ä¸ºäº†æ”¯æŒè¿›ä¸€æ­¥çš„ç ”ç©¶ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†é¢„è®­ç»ƒæœŸé—´æ— å®³çš„æ•°æ®æ±¡æŸ“ï¼Œä¸ºå®‰å…¨æ€§ç ”ç©¶æä¾›äº†ä¸€ä¸ªç°å®çš„è¯•éªŒå¹³å°ã€‚é€šè¿‡å…¨é¢å¼€æ”¾å‘å¸ƒæ‰€æœ‰æ¨¡å‹ã€æ•°æ®é›†ã€ä»£ç å’Œæ£€æŸ¥ç‚¹ï¼ŒGaperonä¸ºæ¢ç´¢å¤šè¯­è¨€è¯­è¨€æ¨¡å‹å¼€å‘ä¸­æ•°æ®æ•´ç†ã€è¯„ä¼°ã€å®‰å…¨ä¸å¼€æ”¾ä¹‹é—´çš„æƒè¡¡æä¾›äº†ä¸€ä¸ªå¯é‡å¤çš„åŸºç¡€ã€‚', 'title_zh': 'Gaperonï¼šä¸€ç§è‹±è¯­-æ³•è¯­ç”Ÿæˆè¯­è¨€æ¨¡å‹å¥—ä»¶'}
{'arxiv_id': 'arXiv:2510.25770', 'title': 'E-Scores for (In)Correctness Assessment of Generative Model Outputs', 'authors': 'Guneet S. Dhillon, Javier GonzÃ¡lez, Teodora Pandeva, Alicia Curth', 'link': 'https://arxiv.org/abs/2510.25770', 'abstract': "While generative models, especially large language models (LLMs), are ubiquitous in today's world, principled mechanisms to assess their (in)correctness are limited. Using the conformal prediction framework, previous works construct sets of LLM responses where the probability of including an incorrect response, or error, is capped at a desired user-defined tolerance level. However, since these methods are based on p-values, they are susceptible to p-hacking, i.e., choosing the tolerance level post-hoc can invalidate the guarantees. We therefore leverage e-values to complement generative model outputs with e-scores as a measure of incorrectness. In addition to achieving the same statistical guarantees as before, e-scores provide users flexibility in adaptively choosing tolerance levels after observing the e-scores themselves, by upper bounding a post-hoc notion of error called size distortion. We experimentally demonstrate their efficacy in assessing LLM outputs for different correctness types: mathematical factuality and property constraints satisfaction.", 'abstract_zh': 'è™½ç„¶ç”Ÿæˆæ¨¡å‹ï¼Œå°¤å…¶æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œåœ¨å½“ä»Šä¸–ç•Œæ— å¤„ä¸åœ¨ï¼Œä½†è¯„ä¼°å…¶ï¼ˆä¸ï¼‰æ­£ç¡®æ€§çš„åŸåˆ™æœºåˆ¶å´æœ‰é™ã€‚åˆ©ç”¨ä¸€è‡´é¢„æµ‹æ¡†æ¶ï¼Œå…ˆå‰çš„å·¥ä½œæ„å»ºäº†ä¸€ç»„LLMå“åº”é›†åˆï¼Œä½¿å¾—åŒ…å«é”™è¯¯å“åº”æˆ–é”™è¯¯çš„æ¦‚ç‡è¢«é™åˆ¶åœ¨ç”¨æˆ·å®šä¹‰çš„å®¹è®¸æ°´å¹³ä¹‹å†…ã€‚ç„¶è€Œï¼Œç”±äºè¿™äº›æ–¹æ³•åŸºäºpå€¼ï¼Œå› æ­¤å®¹æ˜“å—åˆ°på€¼æ“çºµçš„å½±å“ï¼Œå³äº‹åé€‰æ‹©å®¹è®¸æ°´å¹³ä¼šæŸå®³ä¿è¯çš„æ•ˆåŠ›ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åˆ©ç”¨eå€¼æ¥ç»“åˆç”Ÿæˆæ¨¡å‹çš„è¾“å‡ºï¼Œç”¨eè¯„åˆ†ä½œä¸ºé”™è¯¯ç¨‹åº¦çš„è¡¡é‡æ ‡å‡†ã€‚é™¤äº†æä¾›ä¸ä¹‹å‰ç›¸åŒçš„æ•°æ®ç»Ÿè®¡ä¿è¯å¤–ï¼Œeè¯„åˆ†è¿˜ä½¿ç”¨æˆ·èƒ½å¤Ÿåœ¨è§‚å¯Ÿåˆ°eè¯„åˆ†åï¼Œæ ¹æ®åéªŒé”™è¯¯çš„æ¦‚å¿µâ€”â€”å¤§å°å¤±çœŸâ€”â€”çš„ä¸Šç•Œï¼Œçµæ´»é€‰æ‹©å®¹è®¸æ°´å¹³ã€‚æˆ‘ä»¬é€šè¿‡å®éªŒå±•ç¤ºäº†å®ƒä»¬åœ¨è¯„ä¼°ä¸åŒç±»å‹æ­£ç¡®æ€§ï¼ˆåŒ…æ‹¬æ•°å­¦äº‹å®æ€§å’Œå±æ€§çº¦æŸæ»¡è¶³æ€§ï¼‰çš„LLMè¾“å‡ºæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚', 'title_zh': 'E-åˆ†æ•°ç”¨äºè¯„ä¼°ç”Ÿæˆæ¨¡å‹è¾“å‡ºçš„ï¼ˆä¸ï¼‰æ­£ç¡®æ€§'}
{'arxiv_id': 'arXiv:2510.25744', 'title': 'Task Completion Agents are Not Ideal Collaborators', 'authors': 'Shannon Zejiang Shen, Valerie Chen, Ken Gu, Alexis Ross, Zixian Ma, Jillian Ross, Alex Gu, Chenglei Si, Wayne Chi, Andi Peng, Jocelyn J Shen, Ameet Talwalkar, Tongshuang Wu, David Sontag', 'link': 'https://arxiv.org/abs/2510.25744', 'abstract': "Current evaluations of agents remain centered around one-shot task completion, failing to account for the inherently iterative and collaborative nature of many real-world problems, where human goals are often underspecified and evolve. We argue for a shift from building and assessing task completion agents to developing collaborative agents, assessed not only by the quality of their final outputs but by how well they engage with and enhance human effort throughout the problem-solving process. To support this shift, we introduce collaborative effort scaling, a framework that captures how an agent's utility grows with increasing user involvement. Through case studies and simulated evaluations, we show that state-of-the-art agents often underperform in multi-turn, real-world scenarios, revealing a missing ingredient in agent design: the ability to sustain engagement and scaffold user understanding. Collaborative effort scaling offers a lens for diagnosing agent behavior and guiding development toward more effective interactions.", 'abstract_zh': 'ç°æœ‰çš„æ™ºèƒ½ä½“è¯„ä¼°ä¸»è¦é›†ä¸­åœ¨å•ä¸€ä»»åŠ¡å®Œæˆä¸Šï¼Œæœªèƒ½è€ƒè™‘è®¸å¤šç°å®ä¸–ç•Œé—®é¢˜ä¸­å›ºæœ‰çš„è¿­ä»£å’Œåä½œæ€§è´¨ï¼Œå…¶ä¸­äººç±»ç›®æ ‡å¾€å¾€ä¸æ˜ç¡®å¹¶ä¼šæ¼”åŒ–ã€‚æˆ‘ä»¬ä¸»å¼ ä»æ„å»ºå’Œè¯„ä¼°ä»»åŠ¡å®Œæˆæ™ºèƒ½ä½“è½¬å‘å¼€å‘åä½œæ™ºèƒ½ä½“ï¼Œè¯„ä¼°ä¸ä»…åŸºäºå…¶æœ€ç»ˆè¾“å‡ºçš„è´¨é‡ï¼Œè¿˜åŸºäºå®ƒä»¬åœ¨æ•´ä¸ªé—®é¢˜è§£å†³è¿‡ç¨‹ä¸­ä¸äººç±»äº’åŠ¨å’Œå¢å¼ºäººç±»åŠªåŠ›çš„ç¨‹åº¦ã€‚ä¸ºæ”¯æŒè¿™ä¸€è½¬å˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†åä½œåŠªåŠ›æ‰©å±•æ¡†æ¶ï¼Œè¯¥æ¡†æ¶æ•æ‰äº†æ™ºèƒ½ä½“éšç”¨æˆ·å‚ä¸åº¦å¢åŠ è€Œå¢é•¿çš„æ•ˆç”¨ã€‚é€šè¿‡æ¡ˆä¾‹ç ”ç©¶å’Œæ¨¡æ‹Ÿè¯„ä¼°ï¼Œæˆ‘ä»¬è¡¨æ˜æœ€å…ˆè¿›çš„æ™ºèƒ½ä½“åœ¨å¤šè½®ç°å®ä¸–ç•Œåœºæ™¯ä¸­å¾€å¾€è¡¨ç°ä¸ä½³ï¼Œæ­ç¤ºäº†æ™ºèƒ½ä½“è®¾è®¡ä¸­ç¼ºå¤±çš„ä¸€ä¸ªå…³é”®è¦ç´ ï¼šæŒç»­å‚ä¸å’Œæ„å»ºç”¨æˆ·ç†è§£çš„èƒ½åŠ›ã€‚åä½œåŠªåŠ›æ‰©å±•ä¸ºè¯Šæ–­æ™ºèƒ½ä½“è¡Œä¸ºå’ŒæŒ‡å¯¼å¼€å‘æ›´æœ‰æ•ˆçš„äº¤äº’æä¾›äº†è§†è§’ã€‚', 'title_zh': 'ä»»åŠ¡å®Œæˆä»£ç†æœªå¿…æ˜¯ç†æƒ³çš„åˆä½œè€…'}
{'arxiv_id': 'arXiv:2510.25732', 'title': 'The Limits of Obliviate: Evaluating Unlearning in LLMs via Stimulus-Knowledge Entanglement-Behavior Framework', 'authors': 'Aakriti Shah, Thai Le', 'link': 'https://arxiv.org/abs/2510.25732', 'abstract': 'Unlearning in large language models (LLMs) is crucial for managing sensitive data and correcting misinformation, yet evaluating its effectiveness remains an open problem. We investigate whether persuasive prompting can recall factual knowledge from deliberately unlearned LLMs across models ranging from 2.7B to 13B parameters (OPT-2.7B, LLaMA-2-7B, LLaMA-3.1-8B, LLaMA-2-13B). Drawing from ACT-R and Hebbian theory (spreading activation theories), as well as communication principles, we introduce Stimulus-Knowledge Entanglement-Behavior Framework (SKeB), which models information entanglement via domain graphs and tests whether factual recall in unlearned models is correlated with persuasive framing. We develop entanglement metrics to quantify knowledge activation patterns and evaluate factuality, non-factuality, and hallucination in outputs. Our results show persuasive prompts substantially enhance factual knowledge recall (14.8% baseline vs. 24.5% with authority framing), with effectiveness inversely correlated to model size (128% recovery in 2.7B vs. 15% in 13B). SKeB provides a foundation for assessing unlearning completeness, robustness, and overall behavior in LLMs.', 'abstract_zh': 'å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ä¸­çš„é‡æ–°å­¦ä¹ å¯¹äºç®¡ç†æ•æ„Ÿæ•°æ®å’Œçº æ­£è™šå‡ä¿¡æ¯è‡³å…³é‡è¦ï¼Œç„¶è€Œå¯¹å…¶æœ‰æ•ˆæ€§çš„è¯„ä¼°ä»æ˜¯ä¸€ä¸ªå¼€æ”¾é—®é¢˜ã€‚æˆ‘ä»¬æ¢è®¨äº†æœ‰è¯´æœåŠ›çš„æç¤ºæ˜¯å¦èƒ½åœ¨ä»ä¸åŒå‚æ•°é‡ï¼ˆ2.7Bè‡³13Bï¼‰çš„å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆOPT-2.7Bã€LLaMA-2-7Bã€LLaMA-3.1-8Bã€LLaMA-2-13Bï¼‰ä¸­æ•…æ„æœªå­¦ä¹ çš„æ¨¡å‹ä¸­å”¤èµ·äº‹å®æ€§çŸ¥è¯†ã€‚å€Ÿé‰´ACT-Rå’Œæµ·ë¹„å®‰ç†è®ºï¼ˆä¼ æ’­æ¿€æ´»ç†è®ºï¼‰ä»¥åŠæ²Ÿé€šåŸåˆ™ï¼Œæˆ‘ä»¬æå‡ºäº†åˆºæ¿€-çŸ¥è¯†çº ç¼ -è¡Œä¸ºæ¡†æ¶ï¼ˆSKeBï¼‰ï¼Œé€šè¿‡é¢†åŸŸå›¾å»ºæ¨¡ä¿¡æ¯çº ç¼ ï¼Œå¹¶æµ‹è¯•æœªå­¦ä¹ æ¨¡å‹ä¸­çš„äº‹å®æ€§å›å¿†ä¸æœ‰è¯´æœåŠ›çš„æ¡†æ¶ä¹‹é—´çš„å…³è”æ€§ã€‚æˆ‘ä»¬å¼€å‘äº†çº ç¼ åº¦é‡æ¥é‡åŒ–çŸ¥è¯†æ¿€æ´»æ¨¡å¼å¹¶è¯„ä¼°è¾“å‡ºä¸­çš„äº‹å®æ€§ã€éäº‹å®æ€§å’Œå¹»è§‰ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œæœ‰è¯´æœåŠ›çš„æç¤ºæ˜¾è‘—å¢å¼ºäº†äº‹å®æ€§çŸ¥è¯†çš„å›å¿†ï¼ˆåŸºçº¿ä¸º14.8% vs. æƒå¨æ€§æ¡†æ¶ä¸º24.5%ï¼‰ï¼Œå…¶æœ‰æ•ˆæ€§ä¸æ¨¡å‹å¤§å°æˆåæ¯”ï¼ˆåœ¨2.7Bæ¨¡å‹ä¸­æ¢å¤ç‡ä¸º128%è€Œåœ¨13Bæ¨¡å‹ä¸­ä¸º15%ï¼‰ã€‚SKeBä¸ºè¯„ä¼°å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ä¸­é‡æ–°å­¦ä¹ çš„å®Œæ•´åº¦ã€ç¨³å¥æ€§å’Œæ•´ä½“è¡Œä¸ºå¥ å®šäº†åŸºç¡€ã€‚', 'title_zh': 'é—å¿˜çš„å±€é™æ€§ï¼šé€šè¿‡åˆºæ¿€-çŸ¥è¯†çº ç¼ -è¡Œä¸ºæ¡†æ¶è¯„ä¼°LLMä¸­çš„åå­¦ä¹ '}
{'arxiv_id': 'arXiv:2510.25731', 'title': 'LieSolver: A PDE-constrained solver for IBVPs using Lie symmetries', 'authors': 'RenÃ© P. Klausen, Ivan Timofeev, Johannes Frank, Jonas Naujoks, Thomas Wiegand, Sebastian Lapuschkin, Wojciech Samek', 'link': 'https://arxiv.org/abs/2510.25731', 'abstract': "We introduce a method for efficiently solving initial-boundary value problems (IBVPs) that uses Lie symmetries to enforce the associated partial differential equation (PDE) exactly by construction. By leveraging symmetry transformations, the model inherently incorporates the physical laws and learns solutions from initial and boundary data. As a result, the loss directly measures the model's accuracy, leading to improved convergence. Moreover, for well-posed IBVPs, our method enables rigorous error estimation. The approach yields compact models, facilitating an efficient optimization. We implement LieSolver and demonstrate its application to linear homogeneous PDEs with a range of initial conditions, showing that it is faster and more accurate than physics-informed neural networks (PINNs). Overall, our method improves both computational efficiency and the reliability of predictions for PDE-constrained problems.", 'abstract_zh': 'æˆ‘ä»¬ä»‹ç»äº†ä¸€ç§ä½¿ç”¨æå¯¹ç§°æ€§é«˜æ•ˆæ±‚è§£åˆè¾¹å€¼é—®é¢˜ï¼ˆIBVPï¼‰çš„æ–¹æ³•ï¼Œé€šè¿‡æ„é€ ç²¾ç¡®åœ°åº”ç”¨ç›¸å…³åå¾®åˆ†æ–¹ç¨‹ï¼ˆPDEï¼‰ã€‚é€šè¿‡åˆ©ç”¨å¯¹ç§°å˜æ¢ï¼Œè¯¥æ¨¡å‹å›ºæœ‰åœ° Incorporates ç‰©ç†å®šå¾‹å¹¶ä»åˆå§‹å’Œè¾¹ç•Œæ•°æ®ä¸­å­¦ä¹ è§£ã€‚å› æ­¤ï¼ŒæŸå¤±ç›´æ¥è¡¡é‡æ¨¡å‹çš„å‡†ç¡®åº¦ï¼Œä»è€Œæé«˜æ”¶æ•›æ€§ã€‚æ­¤å¤–ï¼Œå¯¹äºæ°å½“æå®šçš„ IBVPï¼Œæœ¬æ–¹æ³•èƒ½å¤Ÿè¿›è¡Œä¸¥æ ¼çš„è¯¯å·®ä¼°è®¡ã€‚è¯¥æ–¹æ³•ç”Ÿæˆç´§å‡‘çš„æ¨¡å‹ï¼Œä¾¿äºé«˜æ•ˆä¼˜åŒ–ã€‚æˆ‘ä»¬å®ç°äº†ææ±‚è§£å™¨ LieSolverï¼Œå¹¶å°†å…¶åº”ç”¨äºå…·æœ‰å¤šç§åˆå§‹æ¡ä»¶çš„çº¿æ€§é½æ¬¡ PDEï¼Œè¡¨æ˜å…¶æ¯”ç‰©ç†çŸ¥æƒ…ç¥ç»ç½‘ç»œï¼ˆPINNsï¼‰æ›´å¿«æ›´å‡†ç¡®ã€‚æ€»ä½“è€Œè¨€ï¼Œæœ¬æ–¹æ³•æé«˜äº† PDE é™åˆ¶é—®é¢˜çš„è®¡ç®—æ•ˆç‡å’Œé¢„æµ‹å¯é æ€§ã€‚', 'title_zh': 'LieSolver: ä¸€ç§åŸºäºæå¯¹ç§°æ€§çš„åå¾®åˆ†æ–¹ç¨‹çº¦æŸçš„IBVPæ±‚è§£å™¨'}
{'arxiv_id': 'arXiv:2510.25729', 'title': 'Physics-Guided Conditional Diffusion Networks for Microwave Image Reconstruction', 'authors': 'Shirin Chehelgami, Joe LoVetri, Vahab Khoshdel', 'link': 'https://arxiv.org/abs/2510.25729', 'abstract': 'A conditional latent-diffusion based framework for solving the electromagnetic inverse scattering problem associated with microwave imaging is introduced. This generative machine-learning model explicitly mirrors the non-uniqueness of the ill-posed inverse problem. Unlike existing inverse solvers utilizing deterministic machine learning techniques that produce a single reconstruction, the proposed latent-diffusion model generates multiple plausible permittivity maps conditioned on measured scattered-field data, thereby generating several potential instances in the range-space of the non-unique inverse mapping. A forward electromagnetic solver is integrated into the reconstruction pipeline as a physics-based evaluation mechanism. The space of candidate reconstructions form a distribution of possibilities consistent with the conditioning data and the member of this space yielding the lowest scattered-field data discrepancy between the predicted and measured scattered fields is reported as the final solution. Synthetic and experimental labeled datasets are used for training and evaluation of the model. An innovative labeled synthetic dataset is created that exemplifies a varied set of scattering features. Training of the model using this new dataset produces high quality permittivity reconstructions achieving improved generalization with excellent fidelity to shape recognition. The results highlight the potential of hybrid generative physics frameworks as a promising direction for robust, data-driven microwave imaging.', 'abstract_zh': 'åŸºäºæ¡ä»¶æ½œæ‰©æ•£çš„ç”µç£é€†æ•£å°„é—®é¢˜æ¡†æ¶ï¼šç”¨äºå¾®æ³¢æˆåƒçš„ç”Ÿæˆæœºå™¨å­¦ä¹ æ¨¡å‹', 'title_zh': 'åŸºäºç‰©ç†å¼•å¯¼çš„æ¡ä»¶æ‰©æ•£ç½‘ç»œåœ¨å¾®æ³¢å›¾åƒé‡æ„ä¸­çš„åº”ç”¨'}
{'arxiv_id': 'arXiv:2510.25726', 'title': 'The Tool Decathlon: Benchmarking Language Agents for Diverse, Realistic, and Long-Horizon Task Execution', 'authors': 'Junlong Li, Wenshuo Zhao, Jian Zhao, Weihao Zeng, Haoze Wu, Xiaochen Wang, Rui Ge, Yuxuan Cao, Yuzhen Huang, Wei Liu, Junteng Liu, Zhaochen Su, Yiyang Guo, Fan Zhou, Lueyang Zhang, Juan Michelini, Xingyao Wang, Xiang Yue, Shuyan Zhou, Graham Neubig, Junxian He', 'link': 'https://arxiv.org/abs/2510.25726', 'abstract': "Real-world language agents must handle complex, multi-step workflows across diverse Apps. For instance, an agent may manage emails by coordinating with calendars and file systems, or monitor a production database to detect anomalies and generate reports following an operating manual. However, existing language agent benchmarks often focus on narrow domains or simplified tasks that lack the diversity, realism, and long-horizon complexity required to evaluate agents' real-world performance. To address this gap, we introduce the Tool Decathlon (dubbed as Toolathlon), a benchmark for language agents offering diverse Apps and tools, realistic environment setup, and reliable execution-based evaluation. Toolathlon spans 32 software applications and 604 tools, ranging from everyday platforms such as Google Calendar and Notion to professional ones like WooCommerce, Kubernetes, and BigQuery. Most of the tools are based on a high-quality set of Model Context Protocol (MCP) servers that we may have revised or implemented ourselves. Unlike prior works, which primarily ensure functional realism but offer limited environment state diversity, we provide realistic initial environment states from real software, such as Canvas courses with dozens of students or real financial spreadsheets. This benchmark includes 108 manually sourced or crafted tasks in total, requiring interacting with multiple Apps over around 20 turns on average to complete. Each task is strictly verifiable through dedicated evaluation scripts. Comprehensive evaluation of SOTA models highlights their significant shortcomings: the best-performing model, Claude-4.5-Sonnet, achieves only a 38.6% success rate with 20.2 tool calling turns on average, while the top open-weights model DeepSeek-V3.2-Exp reaches 20.1%. We expect Toolathlon to drive the development of more capable language agents for real-world, long-horizon task execution.", 'abstract_zh': 'Tool Decathlonï¼šé¢å‘ç°å®ä¸–ç•Œå¤æ‚å¤šæ­¥å·¥ä½œæµçš„è¯­è¨€ä»£ç†åŸºå‡†', 'title_zh': 'å·¥å…·åé¡¹å…¨èƒ½ï¼šè¯­è¨€ä»£ç†åœ¨å¤šæ ·ã€ç°å®å’Œé•¿æ—¶ä»»åŠ¡æ‰§è¡Œä¸­çš„åŸºå‡†æµ‹è¯•'}
{'arxiv_id': 'arXiv:2510.25694', 'title': 'Process-Level Trajectory Evaluation for Environment Configuration in Software Engineering Agents', 'authors': 'Jiayi Kuang, Yinghui Li, Xin Zhang, Yangning Li, Di Yin, Xing Sun, Ying Shen, Philip S. Yu', 'link': 'https://arxiv.org/abs/2510.25694', 'abstract': 'Large language model-based agents show promise for software engineering, but environment configuration remains a bottleneck due to heavy manual effort and scarce large-scale, high-quality datasets. Existing benchmarks assess only end-to-end build/test success, obscuring where and why agents succeed or fail. We introduce the Environment Configuration Diagnosis Benchmark, Enconda-bench, which provides process-level trajectory assessment of fine-grained agent capabilities during environment setup-planning, perception-driven error diagnosis, feedback-driven repair, and action to execute final environment configuration. Our task instances are automatically constructed by injecting realistic README errors and are validated in Docker for scalable, high-quality evaluation. Enconda-bench combines process-level analysis with end-to-end executability to enable capability assessments beyond aggregate success rates. Evaluations across state-of-the-art LLMs and agent frameworks show that while agents can localize errors, they struggle to translate feedback into effective corrections, limiting end-to-end performance. To our knowledge, Enconda-bench is the first framework to provide process-level internal capability assessment for environment configuration, offering actionable insights for improving software engineering agents.', 'abstract_zh': 'åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„ä»£ç†åœ¨è½¯ä»¶å·¥ç¨‹ä¸­å±•ç°å‡ºå‰æ™¯ï¼Œä½†ç¯å¢ƒé…ç½®ä»ç”±äºå¤§é‡æ‰‹åŠ¨å·¥ä½œå’Œç¨€ç¼ºçš„é«˜è´¨é‡å¤§è§„æ¨¡æ•°æ®é›†è€Œæˆä¸ºç“¶é¢ˆã€‚ç°æœ‰åŸºå‡†ä»…è¯„ä¼°ç«¯åˆ°ç«¯çš„æ„å»º/æµ‹è¯•æˆåŠŸï¼Œæ©ç›–äº†ä»£ç†æˆåŠŸæˆ–å¤±è´¥çš„å…·ä½“åŸå› ã€‚æˆ‘ä»¬å¼•å…¥äº†ç¯å¢ƒé…ç½®è¯Šæ–­åŸºå‡†Enconda-benchï¼Œè¯¥åŸºå‡†æä¾›äº†åœ¨ç¯å¢ƒè®¾ç½®è§„åˆ’ã€æ„ŸçŸ¥é©±åŠ¨çš„é”™è¯¯è¯Šæ–­ã€åé¦ˆé©±åŠ¨çš„ä¿®å¤ä»¥åŠæ‰§è¡Œæœ€ç»ˆç¯å¢ƒé…ç½®è¿‡ç¨‹ä¸­ç²’åº¦çº§åˆ«çš„è¿‡ç¨‹çº§è½¨è¿¹è¯„ä¼°ã€‚æˆ‘ä»¬çš„ä»»åŠ¡å®ä¾‹æ˜¯é€šè¿‡æ³¨å…¥ç°å®çš„READMEé”™è¯¯è‡ªåŠ¨æ„å»ºçš„ï¼Œå¹¶åœ¨Dockerä¸­è¿›è¡ŒéªŒè¯ï¼Œä»¥ä¾¿è¿›è¡Œå¯æ‰©å±•ä¸”é«˜è´¨é‡çš„è¯„ä¼°ã€‚Enconda-benchç»“åˆäº†è¿‡ç¨‹çº§åˆ†æä¸ç«¯åˆ°ç«¯æ‰§è¡Œèƒ½åŠ›ï¼Œä½¿å¾—èƒ½åŠ›è¯„ä¼°è¶…è¶Šäº†æ€»ä½“æˆåŠŸç‡ã€‚åœ¨æœ€å…ˆè¿›çš„LLMå’Œä»£ç†æ¡†æ¶ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼Œè™½ç„¶ä»£ç†èƒ½å¤Ÿå®šä½é”™è¯¯ï¼Œä½†åœ¨å°†åé¦ˆè½¬åŒ–ä¸ºæœ‰æ•ˆçš„ä¿®æ­£æ–¹é¢å­˜åœ¨é—®é¢˜ï¼Œé™åˆ¶äº†ç«¯åˆ°ç«¯çš„æ€§èƒ½ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒEnconda-benchæ˜¯é¦–ä¸ªæä¾›ç¯å¢ƒé…ç½®è¿‡ç¨‹çº§å†…éƒ¨èƒ½åŠ›è¯„ä¼°çš„æ¡†æ¶ï¼Œä¸ºæ”¹è¿›è½¯ä»¶å·¥ç¨‹ä»£ç†æä¾›äº†å¯æ“ä½œçš„è§è§£ã€‚', 'title_zh': 'è½¯ä»¶å·¥ç¨‹ä»£ç†ä¸­ç¯å¢ƒé…ç½®çš„æµç¨‹çº§è½¨è¿¹è¯„ä¼°'}
{'arxiv_id': 'arXiv:2510.25683', 'title': 'Graph Network-based Structural Simulator: Graph Neural Networks for Structural Dynamics', 'authors': 'Alessandro Lucchetti, Francesco Cadini, Marco Giglio, Luca Lomazzi', 'link': 'https://arxiv.org/abs/2510.25683', 'abstract': 'Graph Neural Networks (GNNs) have recently been explored as surrogate models for numerical simulations. While their applications in computational fluid dynamics have been investigated, little attention has been given to structural problems, especially for dynamic cases. To address this gap, we introduce the Graph Network-based Structural Simulator (GNSS), a GNN framework for surrogate modeling of dynamic structural problems.\nGNSS follows the encode-process-decode paradigm typical of GNN-based machine learning models, and its design makes it particularly suited for dynamic simulations thanks to three key features: (i) expressing node kinematics in node-fixed local frames, which avoids catastrophic cancellation in finite-difference velocities; (ii) employing a sign-aware regression loss, which reduces phase errors in long rollouts; and (iii) using a wavelength-informed connectivity radius, which optimizes graph construction.\nWe evaluate GNSS on a case study involving a beam excited by a 50kHz Hanning-modulated pulse. The results show that GNSS accurately reproduces the physics of the problem over hundreds of timesteps and generalizes to unseen loading conditions, where existing GNNs fail to converge or deliver meaningful predictions.\nCompared with explicit finite element baselines, GNSS achieves substantial inference speedups while preserving spatial and temporal fidelity. These findings demonstrate that locality-preserving GNNs with physics-consistent update rules are a competitive alternative for dynamic, wave-dominated structural simulations.', 'abstract_zh': 'åŸºäºå›¾ç½‘ç»œçš„ç»“æ„æ¨¡æ‹Ÿå™¨ï¼ˆGNSSï¼‰ï¼šä¸€ç§ç”¨äºåŠ¨æ€ç»“æ„é—®é¢˜çš„å›¾ç¥ç»ç½‘ç»œæ¡†æ¶', 'title_zh': 'åŸºäºå›¾ç½‘ç»œçš„ç»“æ„æ¨¡æ‹Ÿå™¨ï¼šå›¾ç¥ç»ç½‘ç»œåœ¨ç»“æ„åŠ¨åŠ›å­¦ä¸­çš„åº”ç”¨'}
{'arxiv_id': 'arXiv:2510.25662', 'title': 'User Misconceptions of LLM-Based Conversational Programming Assistants', 'authors': "Gabrielle O'Brien, Antonio Pedro Santos Alves, Sebastian Baltes, Grischa Liebel, Mircea Lungu, Marcos Kalinowski", 'link': 'https://arxiv.org/abs/2510.25662', 'abstract': 'Programming assistants powered by large language models (LLMs) have become widely available, with conversational assistants like ChatGPT proving particularly accessible to less experienced programmers. However, the varied capabilities of these tools across model versions and the mixed availability of extensions that enable web search, code execution, or retrieval-augmented generation create opportunities for user misconceptions about what systems can and cannot do. Such misconceptions may lead to over-reliance, unproductive practices, or insufficient quality control in LLM-assisted programming. Here, we aim to characterize misconceptions that users of conversational LLM-based assistants may have in programming contexts. Using a two-phase approach, we first brainstorm and catalog user misconceptions that may occur, and then conduct a qualitative analysis to examine whether these conceptual issues surface in naturalistic Python-programming conversations with an LLM-based chatbot drawn from an openly available dataset. Indeed, we see evidence that some users have misplaced expectations about the availability of LLM-based chatbot features like web access, code execution, or non-text output generation. We also see potential evidence for deeper conceptual issues around the scope of information required to debug, validate, and optimize programs. Our findings reinforce the need for designing LLM-based tools that more clearly communicate their programming capabilities to users.', 'abstract_zh': 'ç”±å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹é©±åŠ¨çš„ç¼–ç¨‹åŠ©æ‰‹å·²ç»æˆä¸ºå¹¿æ³›å¯ç”¨çš„å·¥å…·ï¼Œå°¤å…¶æ˜¯åƒChatGPTè¿™æ ·çš„å¯¹è¯åŠ©æ‰‹å¯¹äºç»éªŒè¾ƒå°‘çš„ç¨‹åºå‘˜æ¥è¯´ç‰¹åˆ«æ˜“äºè®¿é—®ã€‚ç„¶è€Œï¼Œè¿™äº›å·¥å…·åœ¨ä¸åŒæ¨¡å‹ç‰ˆæœ¬ä¸­çš„ capability å·®å¼‚ä»¥åŠæ‰©å±•åŠŸèƒ½ï¼ˆå¦‚ç½‘ç»œæœç´¢ã€ä»£ç æ‰§è¡Œæˆ–æ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰çš„æ··åˆå¯ç”¨æ€§ï¼Œä¸ºç”¨æˆ·å¯¹ç³»ç»Ÿèƒ½åŠ›çš„è¯¯è§£åˆ›é€ äº†æœºä¼šã€‚è¿™ç§è¯¯è§£å¯èƒ½å¯¼è‡´ç”¨æˆ·å¯¹ LLM è¾…åŠ©ç¼–ç¨‹çš„è¿‡åº¦ä¾èµ–ã€ä¸productive çš„å®è·µæˆ–ä¸è¶³çš„è´¨é‡æ§åˆ¶ã€‚åœ¨æ­¤ï¼Œæˆ‘ä»¬æ—¨åœ¨æè¿°å¯¹è¯ LLM åŸºå‡†åŠ©æ‰‹åœ¨ç¼–ç¨‹ä¸Šä¸‹æ–‡ä¸­å¯èƒ½äº§ç”Ÿçš„è¯¯è§£ã€‚æˆ‘ä»¬é‡‡ç”¨ä¸¤é˜¶æ®µæ–¹æ³•é¦–å…ˆé›†æ€å¹¿ç›Šå¹¶åˆ—å‡ºå¯èƒ½çš„ç”¨æˆ·è¯¯è§£ï¼Œç„¶åè¿›è¡Œè´¨æ€§åˆ†æä»¥æ£€æŸ¥è¿™äº›æ¦‚å¿µé—®é¢˜æ˜¯å¦åœ¨å…¬å¼€å¯ç”¨æ•°æ®é›†ä¸­ç”Ÿæˆçš„ LLM åŸºå‡†å¯¹è¯æœºå™¨äººè¿›è¡Œçš„è‡ªç„¶è¯­è¨€ Python ç¼–ç¨‹å¯¹è¯ä¸­æµ®ç°å‡ºæ¥ã€‚ç¡®å®ï¼Œæˆ‘ä»¬å‘ç°ä¸€äº›ç”¨æˆ·å¯¹åŸºäº LLM çš„å¯¹è¯æœºå™¨äººçš„ç½‘ç»œè®¿é—®ã€ä»£ç æ‰§è¡Œæˆ–éæ–‡æœ¬è¾“å‡ºç”Ÿæˆç­‰åŠŸèƒ½å­˜åœ¨ä¸åˆ‡å®é™…çš„æœŸæœ›ã€‚æˆ‘ä»¬è¿˜å‘ç°å›´ç»•è°ƒè¯•ã€éªŒè¯å’Œä¼˜åŒ–ç¨‹åºæ‰€éœ€çš„èŒƒå›´çš„çŸ¥è¯†å­˜åœ¨çš„æ½œåœ¨æ·±å±‚æ¬¡æ¦‚å¿µé—®é¢˜ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœå¼ºè°ƒäº†è®¾è®¡æ›´æ¸…æ™°åœ°å‘ç”¨æˆ·ä¼ è¾¾å…¶ç¼–ç¨‹èƒ½åŠ›çš„ LLM å·¥å…·çš„éœ€æ±‚ã€‚', 'title_zh': 'åŸºäºLLMçš„å¯¹è¯ç¼–ç¨‹åŠ©æ‰‹ç”¨æˆ·è®¤çŸ¥è¯¯åŒº'}
{'arxiv_id': 'arXiv:2510.25657', 'title': 'Subgraph Federated Learning via Spectral Methods', 'authors': 'Javad Aliakbari, Johan Ã–stman, Ashkan Panahi, Alexandre Graell i Amat', 'link': 'https://arxiv.org/abs/2510.25657', 'abstract': 'We consider the problem of federated learning (FL) with graph-structured data distributed across multiple clients. In particular, we address the prevalent scenario of interconnected subgraphs, where interconnections between clients significantly influence the learning process. Existing approaches suffer from critical limitations, either requiring the exchange of sensitive node embeddings, thereby posing privacy risks, or relying on computationally-intensive steps, which hinders scalability. To tackle these challenges, we propose FedLap, a novel framework that leverages global structure information via Laplacian smoothing in the spectral domain to effectively capture inter-node dependencies while ensuring privacy and scalability. We provide a formal analysis of the privacy of FedLap, demonstrating that it preserves privacy. Notably, FedLap is the first subgraph FL scheme with strong privacy guarantees. Extensive experiments on benchmark datasets demonstrate that FedLap achieves competitive or superior utility compared to existing techniques.', 'abstract_zh': 'åŸºäºå›¾ç»“æ„æ•°æ®çš„è”é‚¦å­¦ä¹ æ¡†æ¶ï¼šFedLap', 'title_zh': 'è°±æ–¹æ³•ä¸‹çš„å­å›¾è”é‚¦å­¦ä¹ '}
{'arxiv_id': 'arXiv:2510.25634', 'title': 'Learning to Plan & Schedule with Reinforcement-Learned Bimanual Robot Skills', 'authors': 'Weikang Wan, Fabio Ramos, Xuning Yang, Caelan Garrett', 'link': 'https://arxiv.org/abs/2510.25634', 'abstract': 'Long-horizon contact-rich bimanual manipulation presents a significant challenge, requiring complex coordination involving a mixture of parallel execution and sequential collaboration between arms. In this paper, we introduce a hierarchical framework that frames this challenge as an integrated skill planning & scheduling problem, going beyond purely sequential decision-making to support simultaneous skill invocation. Our approach is built upon a library of single-arm and bimanual primitive skills, each trained using Reinforcement Learning (RL) in GPU-accelerated simulation. We then train a Transformer-based planner on a dataset of skill compositions to act as a high-level scheduler, simultaneously predicting the discrete schedule of skills as well as their continuous parameters. We demonstrate that our method achieves higher success rates on complex, contact-rich tasks than end-to-end RL approaches and produces more efficient, coordinated behaviors than traditional sequential-only planners.', 'abstract_zh': 'é•¿æ—¶ç¨‹å¤šæ¥è§¦åŒè‡‚æ“ä½œ Presents a Significant Challenge, Requiring Complex Coordination Involving a Mixture of Parallel Execution and Sequential Collaboration Between Arms: A Hierarchical Framework for Integrated Skill Planning and Scheduling', 'title_zh': 'å­¦ä¹ æ‰§è¡ŒåŒè‡‚æœºå™¨äººæŠ€èƒ½çš„è§„åˆ’ä¸è°ƒåº¦'}
{'arxiv_id': 'arXiv:2510.25626', 'title': 'Are Language Models Efficient Reasoners? A Perspective from Logic Programming', 'authors': 'Andreas Opedal, Yanick Zengaffinen, Haruki Shirakami, Clemente Pasti, Mrinmaya Sachan, Abulhair Saparov, Ryan Cotterell, Bernhard SchÃ¶lkopf', 'link': 'https://arxiv.org/abs/2510.25626', 'abstract': 'Modern language models (LMs) exhibit strong deductive reasoning capabilities, yet standard evaluations emphasize correctness while overlooking a key aspect of human-like reasoning: efficiency. In real-world reasoning scenarios, much of the available information is irrelevant, and effective deductive inference requires identifying and ignoring such distractions. We propose a framework for assessing LM reasoning efficiency through the lens of logic programming, introducing a simple method to align proofs written in natural language -- as generated by an LM -- with shortest proofs found by executing the logic program. Efficiency is quantified by measuring how well a model avoids unnecessary inference. Empirically, we construct a dataset of math word problems injected with various number of irrelevant axioms that vary in semantic overlap with the goal theorem. We find that current LMs show marked accuracy declines under such conditions -- even with minimal, domain-consistent distractions -- and the proofs they generate frequently exhibit detours through irrelevant inferences.', 'abstract_zh': 'ç°ä»£è¯­è¨€æ¨¡å‹åœ¨æ¨ç†æ•ˆç‡æ–¹é¢çš„è¯„ä¼°ï¼šé€šè¿‡é€»è¾‘ç¼–ç¨‹è§†è§’è€ƒå¯Ÿæ¨¡å‹æ¨ç†èƒ½åŠ›', 'title_zh': 'è¯­è¨€æ¨¡å‹æ˜¯é«˜æ•ˆçš„æ¨ç†è€…å—ï¼Ÿä»é€»è¾‘ç¼–ç¨‹è§†è§’æ¢æ'}
{'arxiv_id': 'arXiv:2510.25621', 'title': 'FARSIQA: Faithful and Advanced RAG System for Islamic Question Answering', 'authors': 'Mohammad Aghajani Asl, Behrooz Minaei Bidgoli', 'link': 'https://arxiv.org/abs/2510.25621', 'abstract': 'The advent of Large Language Models (LLMs) has revolutionized Natural Language Processing, yet their application in high-stakes, specialized domains like religious question answering is hindered by challenges like hallucination and unfaithfulness to authoritative sources. This issue is particularly critical for the Persian-speaking Muslim community, where accuracy and trustworthiness are paramount. Existing Retrieval-Augmented Generation (RAG) systems, relying on simplistic single-pass pipelines, fall short on complex, multi-hop queries requiring multi-step reasoning and evidence aggregation. To address this gap, we introduce FARSIQA, a novel, end-to-end system for Faithful Advanced Question Answering in the Persian Islamic domain. FARSIQA is built upon our innovative FAIR-RAG architecture: a Faithful, Adaptive, Iterative Refinement framework for RAG. FAIR-RAG employs a dynamic, self-correcting process: it adaptively decomposes complex queries, assesses evidence sufficiency, and enters an iterative loop to generate sub-queries, progressively filling information gaps. Operating on a curated knowledge base of over one million authoritative Islamic documents, FARSIQA demonstrates superior performance. Rigorous evaluation on the challenging IslamicPCQA benchmark shows state-of-the-art performance: the system achieves a remarkable 97.0% in Negative Rejection - a 40-point improvement over baselines - and a high Answer Correctness score of 74.3%. Our work establishes a new standard for Persian Islamic QA and validates that our iterative, adaptive architecture is crucial for building faithful, reliable AI systems in sensitive domains.', 'abstract_zh': 'å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å‡ºç°å·²é©æ–°äº†è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸï¼Œä½†åœ¨å®—æ•™é—®ç­”ç­‰é«˜ stakesã€ä¸“ä¸šåŒ–é¢†åŸŸä¸­çš„åº”ç”¨å—åˆ°äº†å¹»è§‰å’Œå¯¹æƒå¨æºä¸å¿ å®ç­‰é—®é¢˜çš„é˜»ç¢ã€‚è¿™ä¸€ç‚¹åœ¨è®²æ³¢æ–¯è¯­çš„ç©†æ–¯æ—ç¤¾åŒºå°¤å…¶å…³é”®ï¼Œå› ä¸ºå‡†ç¡®æ€§ä¸å¯ä¿¡åº¦è‡³å…³é‡è¦ã€‚ç°æœ‰çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿä¾èµ–äºç®€å•çš„å•æµç¨‹ç®¡é“ï¼Œåœ¨å¤„ç†éœ€è¦å¤šæ­¥æ¨ç†å’Œè¯æ®èšåˆçš„å¤æ‚ã€å¤šè·³æŸ¥è¯¢æ—¶è¡¨ç°ä¸ä½³ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†FARSIQAï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹æ³¢æ–¯ä¼Šæ–¯å…°é¢†åŸŸå¿ å®é«˜çº§é—®ç­”çš„æ–°é¢–ç«¯åˆ°ç«¯ç³»ç»Ÿã€‚FARSIQAåŸºäºæˆ‘ä»¬åˆ›æ–°çš„FAIR-RAGæ¶æ„ï¼šä¸€ç§å¿ å®ã€è‡ªé€‚åº”è¿­ä»£å®Œå–„æ¡†æ¶ã€‚FAIR-RAGé‡‡ç”¨äº†ä¸€ç§åŠ¨æ€çš„è‡ªæˆ‘æ ¡æ­£è¿‡ç¨‹ï¼šå®ƒèƒ½å¤Ÿè‡ªé€‚åº”åœ°åˆ†è§£å¤æ‚æŸ¥è¯¢ã€è¯„ä¼°è¯æ®å……åˆ†æ€§ï¼Œå¹¶è¿›å…¥è¿­ä»£å¾ªç¯ç”Ÿæˆå­æŸ¥è¯¢ï¼Œé€æ­¥å¡«è¡¥ä¿¡æ¯ç¼ºå£ã€‚FARSIQAåœ¨è¶…è¿‡ä¸€ç™¾ä¸‡ä»½æƒå¨ä¼Šæ–¯å…°æ–‡æ¡£æ•´ç†çš„çŸ¥è¯†åº“ä¸Šè¿è¡Œï¼Œå±•ç¤ºäº†å“è¶Šçš„è¡¨ç°ã€‚åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ä¼Šæ–¯å…°PCQAåŸºå‡†æµ‹è¯•ä¸Šçš„ä¸¥æ ¼è¯„ä¼°æ˜¾ç¤ºäº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼šç³»ç»Ÿåœ¨Negative Rejectionæ–¹é¢çš„å¾—åˆ†ä¸º97.0%ï¼Œæ¯”åŸºçº¿æé«˜äº†40åˆ†ï¼Œå¹¶ä¸”ç­”æ¡ˆæ­£ç¡®æ€§å¾—åˆ†ä¸º74.3%ã€‚æˆ‘ä»¬çš„å·¥ä½œç¡®ç«‹äº†æ³¢æ–¯ä¼Šæ–¯å…°é—®ç­”çš„æ–°æ ‡å‡†ï¼Œå¹¶éªŒè¯äº†è¿­ä»£ã€è‡ªé€‚åº”æ¶æ„å¯¹äºæ„å»ºæ•æ„Ÿé¢†åŸŸä¸­çš„å¿ å®å¯é AIç³»ç»Ÿçš„è‡³å…³é‡è¦æ€§ã€‚', 'title_zh': 'FARSIQAï¼šå¿ å®ä¸”å…ˆè¿›çš„åŸºäº Retrieval-Augmented Generation çš„ä¼Šæ–¯å…°æ•™é—®é¢˜å›ç­”ç³»ç»Ÿ'}
{'arxiv_id': 'arXiv:2510.25616', 'title': "Don't Blind Your VLA: Aligning Visual Representations for OOD Generalization", 'authors': 'Nikita Kachaev, Mikhail Kolosov, Daniil Zelezetsky, Alexey K. Kovalev, Aleksandr I. Panov', 'link': 'https://arxiv.org/abs/2510.25616', 'abstract': "The growing success of Vision-Language-Action (VLA) models stems from the promise that pretrained Vision-Language Models (VLMs) can endow agents with transferable world knowledge and vision-language (VL) grounding, laying a foundation for action models with broader generalization. Yet when these VLMs are adapted to the action modality, it remains unclear to what extent their original VL representations and knowledge are preserved. In this work, we conduct a systematic study of representation retention during VLA fine-tuning, showing that naive action fine-tuning leads to degradation of visual representations. To characterize and measure these effects, we probe VLA's hidden representations and analyze attention maps, further, we design a set of targeted tasks and methods that contrast VLA models with their counterpart VLMs, isolating changes in VL capabilities induced by action fine-tuning. We further evaluate a range of strategies for aligning visual representations and introduce a simple yet effective method that mitigates degradation and yields improved generalization to out-of-distribution (OOD) scenarios. Taken together, our analysis clarifies the trade-off between action fine-tuning and the degradation of VL representations and highlights practical approaches to recover inherited VL capabilities. Code is publicly available: this https URL", 'abstract_zh': 'è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹ä¸æ–­å¢é•¿çš„æˆåŠŸæºäºé¢„è®­ç»ƒè§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰èƒ½å¤Ÿèµ‹äºˆä»£ç†å¯è½¬ç§»çš„ä¸–ç•ŒçŸ¥è¯†å’Œè§†è§‰-è¯­è¨€ï¼ˆVLï¼‰è¯­ä¹‰å…³è”ï¼Œä¸ºå…·æœ‰æ›´å¹¿æ³›æ³›åŒ–çš„åŠ¨ä½œæ¨¡å‹å¥ å®šåŸºç¡€ã€‚ç„¶è€Œï¼Œå½“å°†è¿™äº›VLMsé€‚åº”åˆ°åŠ¨ä½œæ¨¡æ€æ—¶ï¼Œä»ä¸æ¸…æ¥šå®ƒä»¬çš„åŸå§‹VLè¡¨ç¤ºå’ŒçŸ¥è¯†åœ¨å¤šå¤§ç¨‹åº¦ä¸Šå¾—ä»¥ä¿ç•™ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ç³»ç»Ÿç ”ç©¶äº†VLAå¾®è°ƒè¿‡ç¨‹ä¸­è¡¨ç¤ºä¿ç•™é—®é¢˜ï¼Œå‘ç°ç›´è§‚çš„åŠ¨ä½œå¾®è°ƒä¼šå¯¼è‡´è§†è§‰è¡¨ç¤ºæ€§èƒ½ä¸‹é™ã€‚ä¸ºäº†è¡¨å¾å’Œé‡åŒ–è¿™äº›å½±å“ï¼Œæˆ‘ä»¬æ¢æŸ¥äº†VLAçš„éšè—è¡¨ç¤ºï¼Œåˆ†æäº†æ³¨æ„åŠ›å›¾ï¼Œå¹¶è®¾è®¡äº†ä¸€ç»„é’ˆå¯¹ä»»åŠ¡å’Œæ–¹æ³•ï¼Œå°†VLAæ¨¡å‹ä¸å…¶å¯¹åº”çš„VLMsè¿›è¡Œå¯¹æ¯”ï¼Œä»¥éš”ç¦»ç”±åŠ¨ä½œå¾®è°ƒå¼•èµ·çš„VLèƒ½åŠ›å˜åŒ–ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥è¯„ä¼°äº†å¤šç§è§†è§‰è¡¨ç¤ºå¯¹é½ç­–ç•¥ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„ç¼“è§£æ–¹æ³•ï¼Œä»¥å‡è½»æ€§èƒ½ä¸‹é™å¹¶æé«˜åœ¨åˆ†å¸ƒå¤–ï¼ˆOODï¼‰åœºæ™¯ä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚æˆ‘ä»¬çš„åˆ†ææ¾„æ¸…äº†åŠ¨ä½œå¾®è°ƒä¸VLè¡¨ç¤ºé€€åŒ–ä¹‹é—´çš„æƒè¡¡ï¼Œå¹¶å¼ºè°ƒäº†æ¢å¤ç»§æ‰¿çš„VLèƒ½åŠ›çš„å®é™…æ–¹æ³•ã€‚ä»£ç å·²å…¬å¼€ï¼šthis https URL', 'title_zh': 'ä¸è¦ç›²ç›®è°ƒæ•´VLAï¼šå¯¹å¼‚å¸¸åˆ†å¸ƒå¤–æ³›åŒ–çš„è§†è§‰è¡¨å¾å¯¹é½'}
{'arxiv_id': 'arXiv:2510.25609', 'title': 'BOLT-GAN: Bayes-Optimal Loss for Stable GAN Training', 'authors': 'Mohammadreza Tavasoli Naeini, Ali Bereyhi, Morteza Noshad, Ben Liang, Alfred O. Hero III', 'link': 'https://arxiv.org/abs/2510.25609', 'abstract': 'We introduce BOLT-GAN, a simple yet effective modification of the WGAN framework inspired by the Bayes Optimal Learning Threshold (BOLT). We show that with a Lipschitz continuous discriminator, BOLT-GAN implicitly minimizes a different metric distance than the Earth Mover (Wasserstein) distance and achieves better training stability. Empirical evaluations on four standard image generation benchmarks (CIFAR-10, CelebA-64, LSUN Bedroom-64, and LSUN Church-64) show that BOLT-GAN consistently outperforms WGAN, achieving 10-60% lower Frechet Inception Distance (FID). Our results suggest that BOLT is a broadly applicable principle for enhancing GAN training.', 'abstract_zh': 'BOLT-GANï¼šå—Bayes Optimal Learning Thresholdå¯å‘çš„WGANæ¡†æ¶ç®€å•æœ‰æ•ˆæ”¹è¿›æ–¹æ³•', 'title_zh': 'BOLT-GANï¼šè´å¶æ–¯æœ€ä¼˜æŸå¤±å‡½æ•°ä¸‹çš„GANç¨³å®šè®­ç»ƒ'}
{'arxiv_id': 'arXiv:2510.25602', 'title': 'INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats', 'authors': 'Mengzhao Chen, Meng Wu, Hui Jin, Zhihang Yuan, Jing Liu, Chaoyi Zhang, Yunshui Li, Jie Huang, Jin Ma, Zeyue Xue, Zhiheng Liu, Xingyan Bin, Ping Luo', 'link': 'https://arxiv.org/abs/2510.25602', 'abstract': "Modern AI hardware, such as Nvidia's Blackwell architecture, is increasingly embracing low-precision floating-point (FP) formats to handle the pervasive activation outliers in Large Language Models (LLMs). Despite this industry trend, a unified comparison of FP and integer (INT) quantization across varying granularities has been missing, leaving algorithm and hardware co-design without clear guidance. This paper fills that gap by systematically investigating the trade-offs between FP and INT formats. We reveal a critical performance crossover: while FP excels in coarse-grained quantization, the comparison at fine-grained (block-wise) levels is more nuanced. Our comprehensive comparison demonstrates that for popular 8-bit fine-grained formats (e.g., MX with block size 32), MXINT8 is superior to its FP counterpart in both algorithmic accuracy and hardware efficiency. However, for 4-bit formats, FP (e.g., MXFP4, NVFP4) often holds an accuracy advantage , though we show that NVINT4 can surpass NVFP4 when outlier-mitigation techniques like Hadamard rotation are applied. We also introduce a symmetric clipping method that resolves gradient bias in fine-grained low-bit INT training, enabling nearly lossless performance for MXINT8 training. These findings challenge the current hardware trajectory, demonstrating that a one-size-fits-all FP approach is suboptimal and advocating that fine-grained INT formats, particularly MXINT8, offer a better balance of accuracy, power, and efficiency for future AI accelerators.", 'abstract_zh': 'ç°ä»£AIç¡¬ä»¶ä¸­çš„ä½ç²¾åº¦æµ®ç‚¹æ ¼å¼ä¸æ•´æ•°é‡åŒ–æ¯”è¾ƒï¼šä»Nvidiaçš„Blackwellæ¶æ„å‡ºå‘', 'title_zh': 'INT vs. FP: ä¸€ç§ç»†ç²’åº¦ä½æ¯”ç‰¹é‡åŒ–æ ¼å¼çš„å…¨é¢ç ”ç©¶'}
{'arxiv_id': 'arXiv:2510.25595', 'title': 'Communication and Verification in LLM Agents towards Collaboration under Information Asymmetry', 'authors': 'Run Peng, Ziqiao Ma, Amy Pang, Sikai Li, Zhang Xi-Jia, Yingzhuo Yu, Cristian-Paul Bara, Joyce Chai', 'link': 'https://arxiv.org/abs/2510.25595', 'abstract': "While Large Language Model (LLM) agents are often approached from the angle of action planning/generation to accomplish a goal (e.g., given by language descriptions), their abilities to collaborate with each other to achieve a joint goal are not well explored. To address this limitation, this paper studies LLM agents in task collaboration, particularly under the condition of information asymmetry, where agents have disparities in their knowledge and skills and need to work together to complete a shared task. We extend Einstein Puzzles, a classical symbolic puzzle, to a table-top game. In this game, two LLM agents must reason, communicate, and act to satisfy spatial and relational constraints required to solve the puzzle. We apply a fine-tuning-plus-verifier framework in which LLM agents are equipped with various communication strategies and verification signals from the environment. Empirical results highlight the critical importance of aligned communication, especially when agents possess both information-seeking and -providing capabilities. Interestingly, agents without communication can still achieve high task performance; however, further analysis reveals a lack of true rule understanding and lower trust from human evaluators. Instead, by integrating an environment-based verifier, we enhance agents' ability to comprehend task rules and complete tasks, promoting both safer and more interpretable collaboration in AI systems. this https URL", 'abstract_zh': 'å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†åœ¨ä¿¡æ¯ä¸å¯¹ç§°æ¡ä»¶ä¸‹çš„ä»»åŠ¡åä½œç ”ç©¶ï¼šåŸºäº Einstein æ‹¼å›¾çš„æ‰©å±•', 'title_zh': 'é¢å‘ä¿¡æ¯ä¸å¯¹ç§°æ¡ä»¶ä¸‹ä»£ç†åˆä½œçš„é€šä¿¡ä¸éªŒè¯ç ”ç©¶'}
{'arxiv_id': 'arXiv:2510.25590', 'title': 'RegionE: Adaptive Region-Aware Generation for Efficient Image Editing', 'authors': 'Pengtao Chen, Xianfang Zeng, Maosen Zhao, Mingzhu Shen, Peng Ye, Bangyin Xiang, Zhibo Wang, Wei Cheng, Gang Yu, Tao Chen', 'link': 'https://arxiv.org/abs/2510.25590', 'abstract': 'Recently, instruction-based image editing (IIE) has received widespread attention. In practice, IIE often modifies only specific regions of an image, while the remaining areas largely remain unchanged. Although these two types of regions differ significantly in generation difficulty and computational redundancy, existing IIE models do not account for this distinction, instead applying a uniform generation process across the entire image. This motivates us to propose RegionE, an adaptive, region-aware generation framework that accelerates IIE tasks without additional training. Specifically, the RegionE framework consists of three main components: 1) Adaptive Region Partition. We observed that the trajectory of unedited regions is straight, allowing for multi-step denoised predictions to be inferred in a single step. Therefore, in the early denoising stages, we partition the image into edited and unedited regions based on the difference between the final estimated result and the reference image. 2) Region-Aware Generation. After distinguishing the regions, we replace multi-step denoising with one-step prediction for unedited areas. For edited regions, the trajectory is curved, requiring local iterative denoising. To improve the efficiency and quality of local iterative generation, we propose the Region-Instruction KV Cache, which reduces computational cost while incorporating global information. 3) Adaptive Velocity Decay Cache. Observing that adjacent timesteps in edited regions exhibit strong velocity similarity, we further propose an adaptive velocity decay cache to accelerate the local denoising process. We applied RegionE to state-of-the-art IIE base models, including Step1X-Edit, FLUX.1 Kontext, and Qwen-Image-Edit. RegionE achieved acceleration factors of 2.57, 2.41, and 2.06. Evaluations by GPT-4o confirmed that semantic and perceptual fidelity were well preserved.', 'abstract_zh': 'åŸºäºæŒ‡ä»¤çš„å›¾åƒç¼–è¾‘ä¸­é€‚åº”æ€§åŒºåŸŸç”Ÿæˆæ¡†æ¶ï¼šRegionE', 'title_zh': 'RegionEï¼šè‡ªé€‚åº”åŒºåŸŸæ„è¯†ç”Ÿæˆä»¥å®ç°é«˜æ•ˆçš„å›¾åƒç¼–è¾‘'}
{'arxiv_id': 'arXiv:2510.25577', 'title': 'Lost in Phonation: Voice Quality Variation as an Evaluation Dimension for Speech Foundation Models', 'authors': 'Harm Lameris, Shree Harsha Bokkahalli Satish, Joakim Gustafson, Ã‰va SzÃ©kely', 'link': 'https://arxiv.org/abs/2510.25577', 'abstract': 'Recent advances in speech foundation models (SFMs) have enabled the direct processing of spoken language from raw audio, bypassing intermediate textual representations. This capability allows SFMs to be exposed to, and potentially respond to, rich paralinguistic variations embedded in the input speech signal. One under-explored dimension of paralinguistic variation is voice quality, encompassing phonation types such as creaky and breathy voice. These phonation types are known to influence how listeners infer affective state, stance and social meaning in speech. Existing benchmarks for speech understanding largely rely on multiple-choice question answering (MCQA) formats, which are prone to failure and therefore unreliable in capturing the nuanced ways paralinguistic features influence model behaviour. In this paper, we probe SFMs through open-ended generation tasks and speech emotion recognition, evaluating whether model behaviours are consistent across different phonation inputs. We introduce a new parallel dataset featuring synthesized modifications to voice quality, designed to evaluate SFM responses to creaky and breathy voice. Our work provides the first examination of SFM sensitivity to these particular non-lexical aspects of speech perception.', 'abstract_zh': 'è¿‘æœŸè¯­éŸ³åŸºç¡€æ¨¡å‹çš„å‘å±•ä½¿ç›´æ¥å¤„ç†åŸå§‹éŸ³é¢‘ä¸­çš„å£å¤´è¯­è¨€æˆä¸ºå¯èƒ½ï¼Œç»•è¿‡äº†ä¸­é—´çš„æ–‡æœ¬è¡¨ç¤ºã€‚è¿™ä¸€èƒ½åŠ›ä½¿è¯­éŸ³åŸºç¡€æ¨¡å‹èƒ½å¤Ÿæ¥è§¦åˆ°è¾“å…¥è¯­éŸ³ä¿¡å·ä¸­åµŒå…¥çš„ä¸°å¯Œå‰¯è¯­è¨€å˜å¼‚ï¼Œå¹¶å¯èƒ½å¯¹æ­¤ä½œå‡ºå“åº”ã€‚å‰¯è¯­è¨€å˜å¼‚çš„ä¸€ä¸ªè¾ƒå°‘å¼€å‘çš„ç»´åº¦æ˜¯éŸ³è´¨ï¼ŒåŒ…æ‹¬åˆå”±å’Œç²—ç³™éŸ³ç­‰å‘éŸ³ç±»å‹ã€‚è¿™äº›å‘éŸ³ç±»å‹å·²çŸ¥ä¼šå½±å“å¬è€…ä»è¯­éŸ³ä¸­æ¨æ–­æƒ…æ„ŸçŠ¶æ€ã€ç«‹åœºå’Œç¤¾ä¼šæ„ä¹‰çš„æ–¹å¼ã€‚ç°æœ‰çš„è¯­éŸ³ç†è§£åŸºå‡†ä¸»è¦ä¾èµ–äºå¤šé¡¹é€‰æ‹©é¢˜å›ç­”æ ¼å¼ï¼Œè¿™å®¹æ˜“å¤±è´¥ä¸”ä¸å¯é ï¼Œå› æ­¤æ— æ³•å‡†ç¡®æ•æ‰å‰¯è¯­è¨€ç‰¹å¾å¯¹æ¨¡å‹è¡Œä¸ºçš„å¾®å¦™å½±å“ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡å¼€æ”¾å¼ç”Ÿæˆä»»åŠ¡å’Œè¯­éŸ³æƒ…ç»ªè¯†åˆ«æµ‹è¯•è¯­éŸ³åŸºç¡€æ¨¡å‹ï¼Œè¯„ä¼°æ¨¡å‹åœ¨ä¸åŒå‘éŸ³è¾“å…¥ä¸‹çš„è¡Œä¸ºæ˜¯å¦ä¸€è‡´ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªæ–°çš„å¹³è¡Œæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«å¯¹éŸ³è´¨çš„åˆæˆä¿®æ”¹ï¼Œæ—¨åœ¨è¯„ä¼°è¯­éŸ³åŸºç¡€æ¨¡å‹å¯¹åˆå”±éŸ³å’Œç²—ç³™éŸ³çš„å“åº”ã€‚æˆ‘ä»¬çš„ç ”ç©¶æä¾›äº†é¦–æ¬¡å¯¹è¿™äº›ç‰¹å®šçš„è¯­éŸ³æ„ŸçŸ¥éè¯ç‰¹å¾æ•æ„Ÿæ€§çš„æ£€æŸ¥ã€‚', 'title_zh': 'å¤±äºå‘å£°ï¼šå£°éŸ³è´¨é‡å˜å¼‚ä½œä¸ºè¯­éŸ³åŸºç¡€æ¨¡å‹çš„è¯„ä¼°ç»´åº¦'}
{'arxiv_id': 'arXiv:2510.25563', 'title': 'Leveraging an Atmospheric Foundational Model for Subregional Sea Surface Temperature Forecasting', 'authors': 'VÃ­ctor Medina, Giovanny A. Cuervo-LondoÃ±o, Javier SÃ¡nchez', 'link': 'https://arxiv.org/abs/2510.25563', 'abstract': 'The accurate prediction of oceanographic variables is crucial for understanding climate change, managing marine resources, and optimizing maritime activities. Traditional ocean forecasting relies on numerical models; however, these approaches face limitations in terms of computational cost and scalability. In this study, we adapt Aurora, a foundational deep learning model originally designed for atmospheric forecasting, to predict sea surface temperature (SST) in the Canary Upwelling System. By fine-tuning this model with high-resolution oceanographic reanalysis data, we demonstrate its ability to capture complex spatiotemporal patterns while reducing computational demands. Our methodology involves a staged fine-tuning process, incorporating latitude-weighted error metrics and optimizing hyperparameters for efficient learning. The experimental results show that the model achieves a low RMSE of 0.119K, maintaining high anomaly correlation coefficients (ACC $\\approx 0.997$). The model successfully reproduces large-scale SST structures but faces challenges in capturing finer details in coastal regions. This work contributes to the field of data-driven ocean forecasting by demonstrating the feasibility of using deep learning models pre-trained in different domains for oceanic applications. Future improvements include integrating additional oceanographic variables, increasing spatial resolution, and exploring physics-informed neural networks to enhance interpretability and understanding. These advancements can improve climate modeling and ocean prediction accuracy, supporting decision-making in environmental and economic sectors.', 'abstract_zh': 'å‡†ç¡®é¢„æµ‹æµ·æ´‹åŠ¨åŠ›å˜é‡å¯¹äºç†è§£æ°”å€™å˜åŒ–ã€ç®¡ç†æµ·æ´‹èµ„æºä»¥åŠä¼˜åŒ– maritime æ´»åŠ¨è‡³å…³é‡è¦ã€‚ä¼ ç»Ÿæµ·æ´‹é¢„æŠ¥ä¾èµ–æ•°å€¼æ¨¡å‹ï¼Œä½†è¿™äº›æ–¹æ³•åœ¨è®¡ç®—æˆæœ¬å’Œå¯æ‰©å±•æ€§æ–¹é¢å­˜åœ¨é™åˆ¶ã€‚æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬é€‚åº”äº†åŸæœ¬ç”¨äºå¤§æ°”é¢„æŠ¥çš„åŸºçº¿æ·±åº¦å­¦ä¹ æ¨¡å‹ Auroraï¼Œä»¥é¢„æµ‹åŠ é‚£åˆ©ä¸Šå‡æµç³»ç»Ÿçš„æµ·é¢æ¸©åº¦ (SST)ã€‚é€šè¿‡ä½¿ç”¨é«˜åˆ†è¾¨ç‡æµ·æ´‹å†åˆ†ææ•°æ®è¿›è¡Œå¾®è°ƒï¼Œæˆ‘ä»¬å±•ç¤ºäº†è¯¥æ¨¡å‹åœ¨å‡å°‘è®¡ç®—éœ€æ±‚çš„åŒæ—¶æ•æ‰å¤æ‚ç©ºé—´-æ—¶é—´æ¨¡å¼çš„èƒ½åŠ›ã€‚æœ¬æ–¹æ³•åŒ…æ‹¬åˆ†é˜¶æ®µçš„å¾®è°ƒè¿‡ç¨‹ï¼Œç»“åˆäº†çº¬åº¦åŠ æƒè¯¯å·®æŒ‡æ ‡å¹¶ä¼˜åŒ–äº†è¶…å‚æ•°ä»¥å®ç°é«˜æ•ˆå­¦ä¹ ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹å®ç°äº†ä½ RMSE å€¼ï¼ˆ0.119Kï¼‰ï¼Œä¿æŒäº†é«˜å¼‚å¸¸ç›¸å…³ç³»æ•°ï¼ˆACC â‰ˆ 0.997ï¼‰ã€‚è¯¥æ¨¡å‹æˆåŠŸå†ç°äº†å¤§å°ºåº¦ SST ç»“æ„ï¼Œä½†åœ¨æ²¿æµ·åŒºåŸŸæ•æ‰ç»†å¾®ç»†èŠ‚æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚è¿™é¡¹å·¥ä½œé€šè¿‡å±•ç¤ºä½¿ç”¨åœ¨ä¸åŒé¢†åŸŸé¢„è®­ç»ƒçš„æ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡Œæµ·æ´‹åº”ç”¨çš„å¯è¡Œæ€§ï¼Œä¸ºæ•°æ®é©±åŠ¨çš„æµ·æ´‹é¢„æŠ¥é¢†åŸŸåšå‡ºäº†è´¡çŒ®ã€‚æœªæ¥çš„ç ”ç©¶åŒ…æ‹¬æ•´åˆæ›´å¤šæµ·æ´‹åŠ¨åŠ›å˜é‡ã€æé«˜ç©ºé—´åˆ†è¾¨ç‡ä»¥åŠæ¢ç´¢åŸºäºç‰©ç†çš„ç¥ç»ç½‘ç»œä»¥å¢å¼ºå¯è§£é‡Šæ€§å’Œç†è§£èƒ½åŠ›ã€‚è¿™äº›è¿›æ­¥å¯ä»¥æé«˜æ°”å€™å»ºæ¨¡å’Œæµ·æ´‹é¢„æµ‹å‡†ç¡®æ€§ï¼Œæ”¯æŒç¯å¢ƒå’Œç»æµé¢†åŸŸçš„å†³ç­–ã€‚', 'title_zh': 'åˆ©ç”¨å¤§æ°”åŸºç¡€æ¨¡å‹è¿›è¡Œæ¬¡åŒºåŸŸæµ·è¡¨é¢æ¸©åº¦é¢„æŠ¥'}
{'arxiv_id': 'arXiv:2510.25557', 'title': 'Hybrid Quantum-Classical Recurrent Neural Networks', 'authors': 'Wenduan Xu', 'link': 'https://arxiv.org/abs/2510.25557', 'abstract': 'We present a hybrid quantum-classical recurrent neural network (QRNN) architecture in which the entire recurrent core is realized as a parametrized quantum circuit (PQC) controlled by a classical feedforward network. The hidden state is the quantum state of an $n$-qubit PQC, residing in an exponentially large Hilbert space $\\mathbb{C}^{2^n}$. The PQC is unitary by construction, making the hidden-state evolution norm-preserving without external constraints. At each timestep, mid-circuit readouts are combined with the input embedding and processed by the feedforward network, which provides explicit classical nonlinearity. The outputs parametrize the PQC, which updates the hidden state via unitary dynamics. The QRNN is compact and physically consistent, and it unifies (i) unitary recurrence as a high-capacity memory, (ii) partial observation via mid-circuit measurements, and (iii) nonlinear classical control for input-conditioned parametrization. We evaluate the model in simulation with up to 14 qubits on sentiment analysis, MNIST, permuted MNIST, copying memory, and language modeling, adopting projective measurements as a limiting case to obtain mid-circuit readouts while maintaining a coherent recurrent quantum memory. We further devise a soft attention mechanism over the mid-circuit readouts in a sequence-to-sequence model and show its effectiveness for machine translation. To our knowledge, this is the first model (RNN or otherwise) grounded in quantum operations to achieve competitive performance against strong classical baselines across a broad class of sequence-learning tasks.', 'abstract_zh': 'ä¸€ç§åŸºäºå‚æ•°é‡å­ç”µè·¯çš„æ··åˆé‡å­-ç»å…¸å¾ªç¯ç¥ç»ç½‘ç»œæ¶æ„', 'title_zh': 'æ··åˆé‡å­-ç»å…¸å¾ªç¯ç¥ç»ç½‘ç»œ'}
{'arxiv_id': 'arXiv:2510.25531', 'title': 'Using latent representations to link disjoint longitudinal data for mixed-effects regression', 'authors': 'Clemens SchÃ¤chter, Maren Hackenberg, Michelle Pfaffenlehner, FÃ©lix B. Tambe-Ndonfack, Thorsten Schmidt, Astrid Pechmann, Janbernd Kirschner, Jan Hasenauser, Harald Binder', 'link': 'https://arxiv.org/abs/2510.25531', 'abstract': 'Many rare diseases offer limited established treatment options, leading patients to switch therapies when new medications emerge. To analyze the impact of such treatment switches within the low sample size limitations of rare disease trials, it is important to use all available data sources. This, however, is complicated when usage of measurement instruments change during the observation period, for example when instruments are adapted to specific age ranges. The resulting disjoint longitudinal data trajectories, complicate the application of traditional modeling approaches like mixed-effects regression. We tackle this by mapping observations of each instrument to a aligned low-dimensional temporal trajectory, enabling longitudinal modeling across instruments. Specifically, we employ a set of variational autoencoder architectures to embed item values into a shared latent space for each time point. Temporal disease dynamics and treatment switch effects are then captured through a mixed-effects regression model applied to latent representations. To enable statistical inference, we present a novel statistical testing approach that accounts for the joint parameter estimation of mixed-effects regression and variational autoencoders. The methodology is applied to quantify the impact of treatment switches for patients with spinal muscular atrophy. Here, our approach aligns motor performance items from different measurement instruments for mixed-effects regression and maps estimated effects back to the observed item level to quantify the treatment switch effect. Our approach allows for model selection as well as for assessing effects of treatment switching. The results highlight the potential of modeling in joint latent representations for addressing small data challenges.', 'abstract_zh': 'è®¸å¤šç½•è§ç–¾ç—…ç¼ºä¹æœ‰æ•ˆçš„æ²»ç–—æ–¹æ¡ˆï¼Œæ‚£è€…åœ¨æ–°è¯ç‰©å‡ºç°æ—¶å¾€å¾€ä¼šæ›´æ¢æ²»ç–—æ–¹æ³•ã€‚ä¸ºäº†åœ¨ç½•è§ç—…ä¸´åºŠè¯•éªŒæ ·æœ¬é‡æœ‰é™çš„æƒ…å†µä¸‹åˆ†ææ²»ç–—æ›´æ¢çš„å½±å“ï¼Œéœ€è¦åˆ©ç”¨æ‰€æœ‰å¯ç”¨çš„æ•°æ®æºã€‚ç„¶è€Œï¼Œå½“è§‚å¯ŸæœŸå†…ä½¿ç”¨çš„æµ‹é‡å·¥å…·å‘ç”Ÿå˜åŒ–ï¼Œä¾‹å¦‚ä¸ºäº†ç‰¹å®šå¹´é¾„æ®µè¿›è¡Œè°ƒæ•´æ—¶ï¼Œè¿™ä¼šå¢åŠ æ•°æ®å¤„ç†çš„å¤æ‚æ€§ã€‚ç”±æ­¤äº§ç”Ÿçš„çºµå‘æ•°æ®è½¨è¿¹ä¸è¿ç»­ï¼Œä½¿å¾—ä¼ ç»Ÿçš„æ··åˆæ•ˆåº”å›å½’ç­‰æ¨¡å‹åº”ç”¨å˜å¾—å¤æ‚ã€‚æˆ‘ä»¬é€šè¿‡å°†æ¯ä¸ªæµ‹é‡å·¥å…·çš„è§‚æµ‹å€¼æ˜ å°„åˆ°å¯¹é½çš„ä½ç»´æ—¶é—´è½¨è¿¹ä¸Šï¼Œè§£å†³äº†è¿™ä¸€é—®é¢˜ï¼Œä»è€Œå¯ä»¥åœ¨ä¸åŒæµ‹é‡å·¥å…·ä¹‹é—´è¿›è¡Œçºµå‘å»ºæ¨¡ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬é‡‡ç”¨ä¸€ç»„å˜åˆ†è‡ªç¼–ç å™¨æ¶æ„ï¼Œå°†å„æ—¶é—´ç‚¹çš„é¡¹ç›®å€¼åµŒå…¥å…±äº«çš„æ½œåœ¨ç©ºé—´ä¸­ã€‚é€šè¿‡åº”ç”¨æ··åˆæ•ˆåº”å›å½’æ¨¡å‹åˆ°æ½œåœ¨è¡¨ç¤ºä¸Šï¼Œæ•æ‰çºµå‘ç–¾ç—…åŠ¨æ€å’Œæ²»ç–—æ›´æ¢æ•ˆåº”ã€‚ä¸ºäº†è¿›è¡Œç»Ÿè®¡æ¨æ–­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç»Ÿè®¡æµ‹è¯•æ–¹æ³•ï¼Œè¯¥æ–¹æ³•è€ƒè™‘äº†æ··åˆæ•ˆåº”å›å½’å’Œå˜åˆ†è‡ªç¼–ç å™¨çš„è”åˆå‚æ•°ä¼°è®¡ã€‚è¯¥æ–¹æ³•åº”ç”¨äºè„Šé«“æ€§è‚Œè‚‰èç¼©ç—‡æ‚£è€…çš„æ²»ç–—æ›´æ¢å½±å“é‡åŒ–ã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†ä¸åŒçš„æµ‹é‡å·¥å…·ä¸­çš„è¿åŠ¨è¡¨ç°é¡¹ç›®å¯¹é½ä»¥è¿›è¡Œæ··åˆæ•ˆåº”å›å½’ï¼Œå¹¶å°†ä¼°è®¡çš„æ•ˆåº”æ˜ å°„å›è§‚æµ‹é¡¹ç›®æ°´å¹³ï¼Œä»¥é‡åŒ–æ²»ç–—æ›´æ¢æ•ˆåº”ã€‚è¯¥æ–¹æ³•å…è®¸æ¨¡å‹é€‰æ‹©ï¼Œä»¥åŠè¯„ä¼°æ²»ç–—æ›´æ¢çš„æ•ˆæœã€‚ç»“æœçªæ˜¾äº†åœ¨è”åˆæ½œåœ¨ç©ºé—´ä¸­å»ºæ¨¡çš„æ½œåŠ›ï¼Œä»¥åº”å¯¹å°æ ·æœ¬é‡çš„æŒ‘æˆ˜ã€‚', 'title_zh': 'ä½¿ç”¨æ½œåœ¨è¡¨ç¤ºè¿æ¥æ–­ç‚¹çºµå‘æ•°æ®è¿›è¡Œæ··åˆæ•ˆåº”å›å½’'}
{'arxiv_id': 'arXiv:2510.25522', 'title': 'Comparative Study of UNet-based Architectures for Liver Tumor Segmentation in Multi-Phase Contrast-Enhanced Computed Tomography', 'authors': 'Doan-Van-Anh Ly, Thi-Thu-Hien Pham, Thanh-Hai Le', 'link': 'https://arxiv.org/abs/2510.25522', 'abstract': "Segmentation of liver structures in multi-phase contrast-enhanced computed tomography (CECT) plays a crucial role in computer-aided diagnosis and treatment planning for liver diseases, including tumor detection. In this study, we investigate the performance of UNet-based architectures for liver tumor segmentation, starting from the original UNet and extending to UNet3+ with various backbone networks. We evaluate ResNet, Transformer-based, and State-space (Mamba) backbones, all initialized with pretrained weights. Surprisingly, despite the advances in modern architecture, ResNet-based models consistently outperform Transformer- and Mamba-based alternatives across multiple evaluation metrics. To further improve segmentation quality, we introduce attention mechanisms into the backbone and observe that incorporating the Convolutional Block Attention Module (CBAM) yields the best performance. ResNetUNet3+ with CBAM module not only produced the best overlap metrics with a Dice score of 0.755 and IoU of 0.662, but also achieved the most precise boundary delineation, evidenced by the lowest HD95 distance of 77.911. The model's superiority was further cemented by its leading overall accuracy of 0.925 and specificity of 0.926, showcasing its robust capability in accurately identifying both lesion and healthy tissue. To further enhance interpretability, Grad-CAM visualizations were employed to highlight the region's most influential predictions, providing insights into its decision-making process. These findings demonstrate that classical ResNet architecture, when combined with modern attention modules, remain highly competitive for medical image segmentation tasks, offering a promising direction for liver tumor detection in clinical practice.", 'abstract_zh': 'å¤šæœŸç›¸å¯¹æ¯”å¢å¼ºè®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCECTï¼‰è‚è„ç»“æ„åˆ†å‰²åœ¨è‚ç—…è®¡ç®—æœºè¾…åŠ©è¯Šæ–­åŠæ²»ç–—è§„åˆ’ä¸­çš„ä½œç”¨è‡³å…³é‡è¦ï¼ŒåŒ…æ‹¬è‚¿ç˜¤æ£€æµ‹ã€‚æœ¬ç ”ç©¶æ¢è®¨äº†åŸºäºUNetçš„æ¶æ„åœ¨è‚è„è‚¿ç˜¤åˆ†å‰²ä¸­çš„æ€§èƒ½ï¼Œä»åŸå§‹UNetæ‰©å±•åˆ°UNet3+ï¼Œå¹¶ä½¿ç”¨å„ç§éª¨å¹²ç½‘ç»œã€‚æˆ‘ä»¬è¯„ä¼°äº†ResNetã€åŸºäºTransformerå’ŒState-spaceï¼ˆMambaï¼‰çš„éª¨å¹²ç½‘ç»œï¼Œæ‰€æœ‰æ¨¡å‹å‡ä½¿ç”¨é¢„è®­ç»ƒæƒé‡åˆå§‹åŒ–ã€‚å°½ç®¡ç°ä»£æ¶æ„å–å¾—äº†è¿›å±•ï¼Œä½†åŸºäºResNetçš„æ¨¡å‹åœ¨å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ä¸Šå§‹ç»ˆä¼˜äºåŸºäºTransformerå’ŒMambaçš„æ›¿ä»£æ¨¡å‹ã€‚ä¸ºè¿›ä¸€æ­¥æé«˜åˆ†å‰²è´¨é‡ï¼Œæˆ‘ä»¬åœ¨éª¨å¹²ä¸­å¼•å…¥äº†æ³¨æ„åŠ›æœºåˆ¶ï¼Œå¹¶è§‚å¯Ÿåˆ°é‡‡ç”¨Convolutional Block Attention Module (CBAM) çš„æ¨¡å‹æ€§èƒ½æœ€ä½³ã€‚ResNetUNet3+ç»“åˆCBAMæ¨¡å—ä¸ä»…äº§ç”Ÿäº†æœ€ä½³çš„é‡å åº¦æŒ‡æ ‡ï¼ŒDiceå¾—åˆ†ä¸º0.755ï¼ŒIoUä¸º0.662ï¼Œè¿˜å®ç°äº†æœ€ç²¾ç¡®çš„è¾¹ç•Œå‹¾å‹’ï¼ŒHD95è·ç¦»ä¸º77.911ã€‚è¯¥æ¨¡å‹çš„æ•´ä½“å‡†ç¡®ç‡å’Œç‰¹å¼‚æ€§åˆ†åˆ«ä¸º0.925å’Œ0.926ï¼Œå±•ç¤ºäº†å…¶åœ¨å‡†ç¡®è¯†åˆ«ç—…ç¶å’Œå¥åº·ç»„ç»‡æ–¹é¢çš„å¼ºå¤§èƒ½åŠ›ã€‚ä¸ºè¿›ä¸€æ­¥å¢å¼ºå¯è§£é‡Šæ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨Grad-CAMå¯è§†åŒ–æ–¹æ³•çªå‡ºæ˜¾ç¤ºäº†æœ€å…·å½±å“åŠ›çš„é¢„æµ‹åŒºåŸŸï¼Œæä¾›äº†å…¶å†³ç­–è¿‡ç¨‹çš„è§è§£ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œç»“åˆç°ä»£æ³¨æ„åŠ›æ¨¡å—çš„å¤å…¸ResNetæ¶æ„åœ¨åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­ä»ç„¶æå…·ç«äº‰åŠ›ï¼Œä¸ºä¸´åºŠå®è·µä¸­è‚è‚¿ç˜¤æ£€æµ‹æä¾›äº†æœ‰å‰é€”çš„æ–¹å‘ã€‚', 'title_zh': 'åŸºäºUNetæ¶æ„çš„å¤šæœŸç›¸å¯¹æ¯”å¢å¼ºè®¡ç®—æœºæ–­å±‚æ‰«æè‚è„è‚¿ç˜¤åˆ†å‰²æ¯”è¾ƒç ”ç©¶'}
{'arxiv_id': 'arXiv:2510.25512', 'title': 'FaCT: Faithful Concept Traces for Explaining Neural Network Decisions', 'authors': 'Amin Parchami-Araghi, Sukrut Rao, Jonas Fischer, Bernt Schiele', 'link': 'https://arxiv.org/abs/2510.25512', 'abstract': 'Deep networks have shown remarkable performance across a wide range of tasks, yet getting a global concept-level understanding of how they function remains a key challenge. Many post-hoc concept-based approaches have been introduced to understand their workings, yet they are not always faithful to the model. Further, they make restrictive assumptions on the concepts a model learns, such as class-specificity, small spatial extent, or alignment to human expectations. In this work, we put emphasis on the faithfulness of such concept-based explanations and propose a new model with model-inherent mechanistic concept-explanations. Our concepts are shared across classes and, from any layer, their contribution to the logit and their input-visualization can be faithfully traced. We also leverage foundation models to propose a new concept-consistency metric, C$^2$-Score, that can be used to evaluate concept-based methods. We show that, compared to prior work, our concepts are quantitatively more consistent and users find our concepts to be more interpretable, all while retaining competitive ImageNet performance.', 'abstract_zh': 'æ·±å±‚ç½‘ç»œåœ¨ä¸€ç³»åˆ—ä»»åŠ¡ä¸­å±•ç¤ºäº†å“è¶Šçš„è¡¨ç°ï¼Œä½†å¯¹å…¶åŠŸèƒ½è¿›è¡Œå…¨å±€æ¦‚å¿µçº§ç†è§£ä»ç„¶æ˜¯ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ã€‚å°½ç®¡å·²ç»æå‡ºäº†è®¸å¤šäº‹åæ¦‚å¿µåŸºæ–¹æ³•æ¥ç†è§£å®ƒä»¬çš„å·¥ä½œåŸç†ï¼Œä½†è¿™äº›æ–¹æ³•å¹¶ä¸æ€»æ˜¯å¿ äºæ¨¡å‹ã€‚æ­¤å¤–ï¼Œå®ƒä»¬å¯¹æ¨¡å‹å­¦ä¹ çš„æ¦‚å¿µåšå‡ºäº†å±€é™æ€§å‡è®¾ï¼Œä¾‹å¦‚ç±»ç‰¹å®šæ€§ã€å°ç©ºé—´èŒƒå›´æˆ–ä¸äººç±»æœŸæœ›å¯¹é½ã€‚åœ¨æœ¬å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼ºè°ƒè¿™äº›æ¦‚å¿µåŸºè§£é‡Šçš„å¿ å®æ€§ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ–°çš„å…·æœ‰æ¨¡å‹å†…å›ºæœºç†æ¦‚å¿µè§£é‡Šçš„æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ¦‚å¿µåœ¨ç±»é—´å…±äº«ï¼Œå¹¶ä¸”å¯ä»¥ä»ä»»æ„å±‚è¿½æº¯å®ƒä»¬å¯¹logitå’Œè¾“å…¥å¯è§†åŒ–çš„å½±å“ã€‚æˆ‘ä»¬è¿˜åˆ©ç”¨åŸºç¡€æ¨¡å‹æå‡ºäº†ä¸€ä¸ªæ–°çš„æ¦‚å¿µä¸€è‡´æ€§åº¦é‡C$^2$-Scoreï¼Œå¯ç”¨äºè¯„ä¼°æ¦‚å¿µåŸºæ–¹æ³•ã€‚ç»“æœæ˜¾ç¤ºï¼Œä¸ä»¥å¾€å·¥ä½œç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ¦‚å¿µåœ¨é‡åŒ–ä¸Šæ›´å…·ä¸€è‡´æ€§ï¼Œç”¨æˆ·å‘ç°æˆ‘ä»¬çš„æ¦‚å¿µæ›´æ˜“äºè§£é‡Šï¼ŒåŒæ—¶ä¿æŒäº†ç«äº‰åŠ›çš„ImageNetæ€§èƒ½ã€‚', 'title_zh': 'FaCT: å¿ å®æ¦‚å¿µè½¨è¿¹è§£é‡Šç¥ç»ç½‘ç»œå†³ç­–'}
{'arxiv_id': 'arXiv:2510.25506', 'title': 'Reflections on the Reproducibility of Commercial LLM Performance in Empirical Software Engineering Studies', 'authors': 'Florian Angermeir, Maximilian Amougou, Mark Kreitz, Andreas Bauer, Matthias Linhuber, Davide Fucci, Fabiola MoyÃ³n C., Daniel Mendez, Tony Gorschek', 'link': 'https://arxiv.org/abs/2510.25506', 'abstract': 'Large Language Models have gained remarkable interest in industry and academia. The increasing interest in LLMs in academia is also reflected in the number of publications on this topic over the last years. For instance, alone 78 of the around 425 publications at ICSE 2024 performed experiments with LLMs. Conducting empirical studies with LLMs remains challenging and raises questions on how to achieve reproducible results, for both other researchers and practitioners. One important step towards excelling in empirical research on LLMs and their application is to first understand to what extent current research results are eventually reproducible and what factors may impede reproducibility. This investigation is within the scope of our work. We contribute an analysis of the reproducibility of LLM-centric studies, provide insights into the factors impeding reproducibility, and discuss suggestions on how to improve the current state. In particular, we studied the 86 articles describing LLM-centric studies, published at ICSE 2024 and ASE 2024. Of the 86 articles, 18 provided research artefacts and used OpenAI models. We attempted to replicate those 18 studies. Of the 18 studies, only five were fit for reproduction. For none of the five studies, we were able to fully reproduce the results. Two studies seemed to be partially reproducible, and three studies did not seem to be reproducible. Our results highlight not only the need for stricter research artefact evaluations but also for more robust study designs to ensure the reproducible value of future publications.', 'abstract_zh': 'å¤§è¯­è¨€æ¨¡å‹åœ¨å·¥ä¸šå’Œå­¦æœ¯ç•Œå¼•èµ·äº†æ˜¾è‘—çš„å…´è¶£ã€‚å­¦æœ¯ç•Œå¯¹å¤§è¯­è¨€æ¨¡å‹çš„å…´è¶£å¢åŠ ä¹Ÿåœ¨è¿‘å¹´æ¥å‘è¡¨çš„ç›¸å…³è®ºæ–‡æ•°é‡ä¸Šå¾—åˆ°åæ˜ ã€‚ä¾‹å¦‚ï¼Œåœ¨ICSE 2024ä¸Šï¼Œå¤§çº¦425ç¯‡è®ºæ–‡ä¸­æœ‰78ç¯‡è¿›è¡Œäº†å¤§è¯­è¨€æ¨¡å‹çš„å®éªŒã€‚å¯¹å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œå®è¯ç ”ç©¶ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå¹¶å¼•å‘äº†å¦‚ä½•å®ç°å¯é‡å¤æ€§çš„ç–‘é—®ï¼Œæ—¢å¯¹å…¶ä»–ç ”ç©¶è€…ä¹Ÿå¯¹å®è·µè€…å¦‚æ­¤ã€‚åœ¨å¤§è¯­è¨€æ¨¡å‹åŠå…¶åº”ç”¨çš„å®è¯ç ”ç©¶ä¸­å–å¾—å“è¶Šæˆæœçš„ä¸€ä¸ªé‡è¦æ­¥éª¤æ˜¯é¦–å…ˆäº†è§£å½“å‰çš„ç ”ç©¶ç»“æœæœ€ç»ˆæ˜¯å¦å¯é‡å¤ï¼Œä»¥åŠå“ªäº›å› ç´ å¯èƒ½é˜»ç¢è¿™ç§å¯é‡å¤æ€§ã€‚æœ¬ç ”ç©¶æ­£æ˜¯åœ¨è¿™ä¸ªèŒƒå›´å†…è¿›è¡Œçš„ã€‚æˆ‘ä»¬å¯¹å¤§è¯­è¨€æ¨¡å‹ä¸ºä¸­å¿ƒçš„ç ”ç©¶çš„å¯é‡å¤æ€§è¿›è¡Œäº†åˆ†æï¼Œæ¢è®¨äº†é˜»ç¢å¯é‡å¤æ€§çš„å› ç´ ï¼Œå¹¶è®¨è®ºäº†å¦‚ä½•æ”¹å–„å½“å‰çŠ¶å†µçš„å»ºè®®ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬ç ”ç©¶äº†åœ¨ICSE 2024å’ŒASE 2024ä¸Šå‘è¡¨çš„86ç¯‡æè¿°å¤§è¯­è¨€æ¨¡å‹ä¸ºä¸­å¿ƒçš„ç ”ç©¶çš„æ–‡ç« ã€‚åœ¨è¿™86ç¯‡æ–‡ç« ä¸­ï¼Œ18ç¯‡æä¾›äº†ç ”ç©¶ artefacts å¹¶ä½¿ç”¨äº†OpenAIæ¨¡å‹ã€‚æˆ‘ä»¬å°è¯•å¤åˆ¶è¿™18é¡¹ç ”ç©¶ã€‚åœ¨è¿™18é¡¹ç ”ç©¶ä¸­ï¼Œåªæœ‰5é¡¹é€‚åˆå¤åˆ¶ã€‚å¯¹äºè¿™5é¡¹ç ”ç©¶ï¼Œæˆ‘ä»¬æ— æ³•å®Œå…¨å¤åˆ¶å…¶ç»“æœã€‚ä¸¤é¡¹ç ”ç©¶ä¼¼ä¹æ˜¯éƒ¨åˆ†å¯å¤åˆ¶çš„ï¼Œè€Œä¸‰é¡¹ç ”ç©¶ä¼¼ä¹ä¸å¯å¤åˆ¶ã€‚æˆ‘ä»¬çš„ç ”ç©¶è¡¨æ˜ï¼Œä¸ä»…éœ€è¦æ›´ä¸¥æ ¼çš„ç ”ç©¶ artefacts è¯„ä¼°ï¼Œè¿˜éœ€è¦æ›´ç¨³å¥çš„ç ”ç©¶è®¾è®¡ï¼Œä»¥ç¡®ä¿æœªæ¥å‡ºç‰ˆç‰©çš„å¯é‡å¤æ€§ä»·å€¼ã€‚', 'title_zh': 'å•†ä¸šå¤§æ¨¡å‹æ€§èƒ½å¯é‡å¤æ€§åæ€åœ¨ empirical è½¯ä»¶å·¥ç¨‹ç ”ç©¶ä¸­çš„æ¢ç´¢'}
{'arxiv_id': 'arXiv:2510.25502', 'title': 'TempoPFN: Synthetic Pre-training of Linear RNNs for Zero-shot Time Series Forecasting', 'authors': 'Vladyslav Moroshan, Julien Siems, Arber Zela, Timur Carstensen, Frank Hutter', 'link': 'https://arxiv.org/abs/2510.25502', 'abstract': 'Foundation models for zero-shot time series forecasting face challenges in efficient long-horizon prediction and reproducibility, with existing synthetic-only approaches underperforming on challenging benchmarks. This paper presents TempoPFN, a univariate time series foundation model based on linear Recurrent Neural Networks (RNNs) pre-trained exclusively on synthetic data. The model uses a GatedDeltaProduct architecture with state-weaving for fully parallelizable training across sequence lengths, eliminating the need for windowing or summarization techniques while maintaining robust temporal state-tracking. Our comprehensive synthetic data pipeline unifies diverse generators, including stochastic differential equations, Gaussian processes, and audio synthesis, with novel augmentations. In zero-shot evaluations on the Gift-Eval benchmark, TempoPFN achieves top-tier competitive performance, outperforming all existing synthetic-only approaches and surpassing the vast majority of models trained on real-world data, while being more efficient than existing baselines by leveraging fully parallelizable training and inference. We open-source our complete data generation pipeline and training code, providing a reproducible foundation for future research.', 'abstract_zh': 'åŸºäºçº¿æ€§å¾ªç¯ç¥ç»ç½‘ç»œçš„ TempoPFNï¼šä¸€ç§åœ¨åˆæˆæ•°æ®ä¸Šé¢„è®­ç»ƒçš„å•å˜é‡æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹', 'title_zh': 'TempoPFN: çº¿æ€§RNNçš„åˆæˆé¢„è®­ç»ƒä»¥å®ç°é›¶æ ·æœ¬æ—¶é—´åºåˆ—é¢„æµ‹'}
{'arxiv_id': 'arXiv:2510.25470', 'title': 'An In-Depth Analysis of Cyber Attacks in Secured Platforms', 'authors': 'Parick Ozoh, John K Omoniyi, Bukola Ibitoye', 'link': 'https://arxiv.org/abs/2510.25470', 'abstract': 'There is an increase in global malware threats. To address this, an encryption-type ransomware has been introduced on the Android operating system. The challenges associated with malicious threats in phone use have become a pressing issue in mobile communication, disrupting user experiences and posing significant privacy threats. This study surveys commonly used machine learning techniques for detecting malicious threats in phones and examines their performance. The majority of past research focuses on customer feedback and reviews, with concerns that people might create false reviews to promote or devalue products and services for personal gain. Hence, the development of techniques for detecting malicious threats using machine learning has been a key focus. This paper presents a comprehensive comparative study of current research on the issue of malicious threats and methods for tackling these challenges. Nevertheless, a huge amount of information is required by these methods, presenting a challenge for developing robust, specialized automated anti-malware systems. This research describes the Android Applications dataset, and the accuracy of the techniques is measured using the accuracy levels of the metrics employed in this study.', 'abstract_zh': 'å…¨çƒæ¶æ„è½¯ä»¶å¨èƒå¢åŠ ï¼Œé’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œåœ¨Androidæ“ä½œç³»ç»Ÿä¸­å¼•å…¥äº†åŠ å¯†å‹å‹’ç´¢è½¯ä»¶ã€‚ç§»åŠ¨é€šä¿¡ä¸­æ‰‹æœºæ¶æ„å¨èƒå¸¦æ¥çš„æŒ‘æˆ˜å·²æˆä¸ºç´§è¿«é—®é¢˜ï¼Œå¹²æ‰°äº†ç”¨æˆ·ä½“éªŒå¹¶æ„æˆäº†é‡å¤§éšç§å¨èƒã€‚æœ¬æ–‡ç»¼è¿°äº†ç”¨äºæ£€æµ‹æ‰‹æœºæ¶æ„å¨èƒçš„å¸¸ç”¨æœºå™¨å­¦ä¹ æŠ€æœ¯ï¼Œå¹¶è¯„ä¼°äº†å®ƒä»¬çš„æ€§èƒ½ã€‚ä»¥å¾€ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨å®¢æˆ·åé¦ˆå’Œè¯„ä»·ä¸Šï¼Œå­˜åœ¨äººä»¬å¯èƒ½ä¸ºäº†ä¸ªäººåˆ©ç›Šåˆ›å»ºè™šå‡è¯„ä»·ä»¥æ¨å¹¿æˆ–è´¬ä½äº§å“å’ŒæœåŠ¡çš„æ‹…å¿§ã€‚å› æ­¤ï¼Œä½¿ç”¨æœºå™¨å­¦ä¹ æ£€æµ‹æ¶æ„å¨èƒçš„æŠ€æœ¯å¼€å‘å·²æˆä¸ºå…³é”®ç„¦ç‚¹ã€‚æœ¬æ–‡å¯¹æ¶æ„å¨èƒåŠç›¸å…³æŒ‘æˆ˜çš„ç ”ç©¶ç°çŠ¶è¿›è¡Œäº†å…¨é¢æ¯”è¾ƒåˆ†æã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•éœ€è¦å¤§é‡çš„ä¿¡æ¯ï¼Œä¸ºå¼€å‘ robustã€ä¸“é—¨çš„è‡ªåŠ¨åŒ–é˜²æ¶æ„è½¯ä»¶ç³»ç»Ÿå¸¦æ¥äº†æŒ‘æˆ˜ã€‚æœ¬æ–‡æè¿°äº†Android Applicationsæ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨æœ¬ç ”ç©¶ä¸­é‡‡ç”¨çš„æŒ‡æ ‡çš„å‡†ç¡®æ€§æ¥è¡¡é‡æŠ€æœ¯çš„å‡†ç¡®æ€§ã€‚', 'title_zh': 'å¯¹å—ä¿æŠ¤å¹³å°ä¸­çš„ç½‘ç»œæ”»å‡»çš„æ·±å…¥åˆ†æ'}
{'arxiv_id': 'arXiv:2510.25460', 'title': 'Fine-Tuned Language Models for Domain-Specific Summarization and Tagging', 'authors': 'Jun Wang, Fuming Lin, Yuyu Chen', 'link': 'https://arxiv.org/abs/2510.25460', 'abstract': 'This paper presents a pipeline integrating fine-tuned large language models (LLMs) with named entity recognition (NER) for efficient domain-specific text summarization and tagging. The authors address the challenge posed by rapidly evolving sub-cultural languages and slang, which complicate automated information extraction and law enforcement monitoring. By leveraging the LLaMA Factory framework, the study fine-tunes LLMs on both generalpurpose and custom domain-specific datasets, particularly in the political and security domains. The models are evaluated using BLEU and ROUGE metrics, demonstrating that instruction fine-tuning significantly enhances summarization and tagging accuracy, especially for specialized corpora. Notably, the LLaMA3-8B-Instruct model, despite its initial limitations in Chinese comprehension, outperforms its Chinese-trained counterpart after domainspecific fine-tuning, suggesting that underlying reasoning capabilities can transfer across languages. The pipeline enables concise summaries and structured entity tagging, facilitating rapid document categorization and distribution. This approach proves scalable and adaptable for real-time applications, supporting efficient information management and the ongoing need to capture emerging language trends. The integration of LLMs and NER offers a robust solution for transforming unstructured text into actionable insights, crucial for modern knowledge management and security operations.', 'abstract_zh': 'åŸºäºå¾®è°ƒå¤§è¯­è¨€æ¨¡å‹å’Œå‘½åå®ä½“è¯†åˆ«çš„é¢†åŸŸç‰¹å®šæ–‡æœ¬æ€»ç»“ä¸æ ‡æ³¨pipelineç ”ç©¶', 'title_zh': 'Fine-Tuned Language Models for Domain-Specific Summarization and Tagging'}
{'arxiv_id': 'arXiv:2510.25458', 'title': 'Scalable Utility-Aware Multiclass Calibration', 'authors': 'Mahmoud Hegazy, Michael I. Jordan, Aymeric Dieuleveut', 'link': 'https://arxiv.org/abs/2510.25458', 'abstract': 'Ensuring that classifiers are well-calibrated, i.e., their predictions align with observed frequencies, is a minimal and fundamental requirement for classifiers to be viewed as trustworthy. Existing methods for assessing multiclass calibration often focus on specific aspects associated with prediction (e.g., top-class confidence, class-wise calibration) or utilize computationally challenging variational formulations. In this work, we study scalable \\emph{evaluation} of multiclass calibration. To this end, we propose utility calibration, a general framework that measures the calibration error relative to a specific utility function that encapsulates the goals or decision criteria relevant to the end user. We demonstrate how this framework can unify and re-interpret several existing calibration metrics, particularly allowing for more robust versions of the top-class and class-wise calibration metrics, and, going beyond such binarized approaches, toward assessing calibration for richer classes of downstream utilities.', 'abstract_zh': 'ç¡®ä¿åˆ†ç±»å™¨æ ¡å‡†è‰¯å¥½ï¼Œå³å…¶é¢„æµ‹ä¸è§‚å¯Ÿåˆ°çš„é¢‘ç‡ç›¸ä¸€è‡´ï¼Œæ˜¯å°†åˆ†ç±»å™¨è§†ä¸ºå¯é çš„æœ€å°ä¸”åŸºæœ¬çš„è¦æ±‚ã€‚ç°æœ‰æ–¹æ³•åœ¨è¯„ä¼°å¤šç±»æ ¡å‡†æ—¶å¾€å¾€å…³æ³¨ä¸é¢„æµ‹ç›¸å…³çš„å…·ä½“æ–¹é¢ï¼ˆä¾‹å¦‚ï¼Œé¡¶çº§ç±»ç½®ä¿¡åº¦ã€ç±»åˆ«åˆ«æ ¡å‡†ï¼‰æˆ–é‡‡ç”¨è®¡ç®—ä¸Šå…·æœ‰æŒ‘æˆ˜æ€§çš„å˜åˆ†å…¬å¼ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†å¯æ‰©å±•çš„å¤šç±»æ ¡å‡†è¯„ä¼°ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ•ˆç”¨æ ¡å‡†çš„ä¸€èˆ¬æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡ç‰¹å®šçš„æ•ˆç”¨å‡½æ•°æ¥è¡¡é‡æ ¡å‡†è¯¯å·®ï¼Œè¯¥æ•ˆç”¨å‡½æ•°å°è£…äº†ä¸æœ€ç»ˆç”¨æˆ·ç›¸å…³çš„ç›®æ ‡æˆ–å†³ç­–æ ‡å‡†ã€‚æˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•é€šè¿‡è¿™ç§æ¡†æ¶ç»Ÿä¸€å¹¶é‡æ–°è§£é‡Šå¤šç§ç°æœ‰çš„æ ¡å‡†æŒ‡æ ‡ï¼Œç‰¹åˆ«æ˜¯æä¾›äº†é¡¶çº§ç±»å’Œç±»åˆ«åˆ«æ ¡å‡†æŒ‡æ ‡çš„æ›´ç¨³å¥ç‰ˆæœ¬ï¼Œå¹¶è¶…è¶Šæ­¤ç±»äºŒå…ƒåŒ–æ–¹æ³•ï¼Œä»¥è¯„ä¼°æ›´ä¸°å¯Œçš„ä¸‹æ¸¸æ•ˆç”¨çš„æ ¡å‡†æƒ…å†µã€‚', 'title_zh': 'å¯æ‰©å±•çš„åŸºäºæ•ˆç”¨çš„å¤šç±»æ ¡å‡†'}
{'arxiv_id': 'arXiv:2510.25441', 'title': 'Grounded in Reality: Learning and Deploying Proactive LLM from Offline Logs', 'authors': 'Fei Wei, Daoyuan Chen, Ce Wang, Yilun Huang, Yushuo Chen, Xuchen Pan, Yaliang Li, Bolin Ding', 'link': 'https://arxiv.org/abs/2510.25441', 'abstract': "Large Language Models (LLMs) excel as passive responders, but teaching them to be proactive, goal-oriented partners, a critical capability in high-stakes domains, remains a major challenge. Current paradigms either myopically optimize single-turn attributes or rely on brittle, high-cost user simulators, creating a persistent ``reality gap''. To bridge this gap, we introduce \\texttt{Learn-to-Ask}, a general, simulator-free framework for learning and deploying proactive dialogue agents \\textit{directly from offline expert data}, bypassing the need to model complex user dynamics. Our key insight is to reframe the offline policy learning problem by leveraging the \\textbf{observed future} of each expert trajectory. This allows us to infer a dense, turn-by-turn reward signal grounded in the expert's revealed strategy, decomposing the intractable long-horizon problem into a series of supervised learning tasks, and training a policy to output a structured \\texttt{(action, state_assessment)} tuple, governing both \\textbf{what to ask} and, crucially, \\textbf{when to stop}. To ensure reward fidelity, our Automated Grader Calibration pipeline systematically purges noise from the LLM-based reward model with minimal human supervision. Empirically, we demonstrate the efficacy of \\texttt{Learn-to-Ask} in a real-world medical dataset, using LLMs of varying sizes up to 32B. Our approach culminates in the successful deployment of LLMs into a live, large-scale online AI service. In rigorous in-house evaluations, our model was launched and achieved performance even superior to human experts, proving our framework's ability to translate offline data into tangible, real-world impact. We hope this work provides a practical and economically viable blueprint for transforming passive LLMs into proactive, goal-oriented LLM applications.", 'abstract_zh': 'å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è¢«åŠ¨å“åº”æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†æ•™å®ƒä»¬æˆä¸ºå‰ç»æ€§ã€ç›®æ ‡å¯¼å‘çš„ä¼™ä¼´ï¼Œè¿™ä¸€åœ¨é«˜é£é™©é¢†åŸŸè‡³å…³é‡è¦çš„èƒ½åŠ›ä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚å½“å‰çš„èŒƒå¼è¦ä¹ˆå•æ‰“ç‹¬æ–—åœ°ä¼˜åŒ–å•è½®å±æ€§ï¼Œè¦ä¹ˆä¾èµ–äºè„†å¼±ã€æˆæœ¬é«˜æ˜‚çš„ç”¨æˆ·æ¨¡æ‹Ÿå™¨ï¼Œä»è€Œäº§ç”ŸæŒç»­çš„â€œç°å®å·®è·â€ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†\\texttt{Learn-to-Ask}ï¼Œè¿™æ˜¯ä¸€ä¸ªæ— éœ€æ¨¡æ‹Ÿå™¨çš„ä¸€èˆ¬æ€§æ¡†æ¶ï¼Œå¯ä»¥ä»ç¦»çº¿ä¸“å®¶æ•°æ®ä¸­å­¦ä¹ å’Œéƒ¨ç½²å‰ç»æ€§å¯¹è¯ä»£ç†ï¼Œä»è€Œç»•è¿‡å»ºæ¨¡å¤æ‚ç”¨æˆ·åŠ¨æ€çš„éœ€æ±‚ã€‚æˆ‘ä»¬çš„æ ¸å¿ƒæ´å¯Ÿæ˜¯é€šè¿‡åˆ©ç”¨æ¯ä¸ªä¸“å®¶è½¨è¿¹çš„\\textbf{è§‚æµ‹æœªæ¥}æ¥é‡æ–°å®šä¹‰ç¦»çº¿ç­–ç•¥å­¦ä¹ é—®é¢˜ã€‚è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿæ¨æ–­å‡ºä¸€ä¸ªå¯†é›†çš„ã€é€è½®çš„ã€åŸºäºä¸“å®¶æŠ«éœ²ç­–ç•¥çš„å¥–åŠ±ä¿¡å·ï¼Œå°†ä¸å¯è§£å†³çš„é•¿æœŸé—®é¢˜åˆ†è§£æˆä¸€ç³»åˆ—ç›‘ç£å­¦ä¹ ä»»åŠ¡ï¼Œå¹¶è®­ç»ƒä¸€ä¸ªç­–ç•¥è¾“å‡ºç»“æ„åŒ–çš„\\texttt{(action, state_assessment)}å…ƒç»„ï¼Œç®¡ç†\\textbf{ä½•æ—¶æé—®}å’Œæ›´ä¸ºå…³é”®çš„\\textbf{ä½•æ—¶åœæ­¢}ã€‚ä¸ºäº†ç¡®ä¿å¥–åŠ±çš„å‡†ç¡®æ€§ï¼Œæˆ‘ä»¬çš„è‡ªåŠ¨åŒ–è¯„åˆ†æ ¡å‡†ç®¡é“ç³»ç»Ÿåœ°ä»åŸºäºLLMçš„å¥–åŠ±æ¨¡å‹ä¸­å»é™¤äº†å™ªå£°ï¼ŒåŒæ—¶å‡å°‘äº†å¯¹äººå·¥ç›‘ç£çš„éœ€æ±‚ã€‚å®è¯ç»“æœè¡¨æ˜ï¼Œ\\texttt{Learn-to-Ask}åœ¨çœŸå®ä¸–ç•Œçš„åŒ»ç–—æ•°æ®é›†ä¸­æœ‰æ•ˆï¼Œä½¿ç”¨ä»å‡ åäº¿åˆ°320äº¿è§„æ¨¡ä¸ç­‰çš„LLMã€‚æˆ‘ä»¬çš„æ–¹æ³•æœ€ç»ˆå°†LLMæˆåŠŸéƒ¨ç½²åˆ°ä¸€ä¸ªå®æ—¶ã€å¤§è§„æ¨¡çš„åœ¨çº¿AIæœåŠ¡ä¸­ã€‚åœ¨ä¸¥æ ¼çš„å†…éƒ¨è¯„ä¼°ä¸­ï¼Œæˆ‘ä»¬çš„æ¨¡å‹è¢«æˆåŠŸæ¨å‡ºå¹¶å®ç°äº†ç”šè‡³ä¼˜äºäººç±»ä¸“å®¶çš„æ€§èƒ½ï¼Œè¯æ˜äº†æˆ‘ä»¬æ¡†æ¶å°†ç¦»çº¿æ•°æ®è½¬åŒ–ä¸ºå®é™…ã€åˆ‡å®å½±å“çš„èƒ½åŠ›ã€‚æˆ‘ä»¬å¸Œæœ›è¿™é¡¹å·¥ä½œèƒ½å¤Ÿæä¾›ä¸€ç§å®ç”¨ä¸”ç»æµé«˜æ•ˆçš„è“å›¾ï¼Œå°†è¢«åŠ¨çš„LLMè½¬åŒ–ä¸ºå‰ç»æ€§å’Œç›®æ ‡å¯¼å‘çš„LLMåº”ç”¨ã€‚', 'title_zh': 'ç«‹è¶³ç°å®ï¼šä»ç¦»çº¿æ—¥å¿—å­¦ä¹ å’Œéƒ¨ç½²å‰ç»æ€§LLM'}
{'arxiv_id': 'arXiv:2510.25428', 'title': 'Alibaba International E-commerce Product Search Competition DcuRAGONs Team Technical Report', 'authors': 'Thang-Long Nguyen-Ho, Minh-Khoi Pham, Hoang-Bao Le', 'link': 'https://arxiv.org/abs/2510.25428', 'abstract': 'This report details our methodology and results developed for the Multilingual E-commerce Search Competition. The problem aims to recognize relevance between user queries versus product items in a multilingual context and improve recommendation performance on e-commerce platforms. Utilizing Large Language Models (LLMs) and their capabilities in other tasks, our data-centric method achieved the highest score compared to other solutions during the competition. Final leaderboard is publised at this https URL. The source code for our project is published at this https URL.', 'abstract_zh': 'æœ¬æŠ¥å‘Šè¯¦ç»†ä»‹ç»äº†æˆ‘ä»¬åœ¨å¤šè¯­è¨€ç”µå•†æœç´¢ç«èµ›ä¸­å¼€å‘çš„æ–¹æ³•å’Œç»“æœã€‚è¯¥é—®é¢˜æ—¨åœ¨è¯†åˆ«å¤šè¯­è¨€ç¯å¢ƒä¸‹ç”¨æˆ·æŸ¥è¯¢ä¸äº§å“é¡¹ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œå¹¶æé«˜ç”µå•†å¹³å°ä¸Šæ¨èæ€§èƒ½ã€‚åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹åŠå…¶åœ¨å…¶ä»–ä»»åŠ¡ä¸­çš„èƒ½åŠ›ï¼Œæˆ‘ä»¬çš„ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„æ–¹æ³•åœ¨ç«èµ›ä¸­è·å¾—äº†æœ€é«˜çš„å¾—åˆ†ã€‚æœ€ç»ˆæ’è¡Œæ¦œå‘å¸ƒåœ¨è¯¥é“¾æ¥ï¼šæ­¤ https URLã€‚æˆ‘ä»¬çš„é¡¹ç›®æºä»£ç å‘å¸ƒåœ¨è¯¥é“¾æ¥ï¼šæ­¤ https URLã€‚', 'title_zh': 'é˜¿é‡Œå·´å·´å›½é™…ç”µå­å•†åŠ¡äº§å“æœç´¢ç«èµ› DcuRAGONs å›¢é˜ŸæŠ€æœ¯æŠ¥å‘Š'}
{'arxiv_id': 'arXiv:2510.25427', 'title': 'RLMEval: Evaluating Research-Level Neural Theorem Proving', 'authors': 'Auguste Poiroux, Antoine Bosselut, Viktor KunÄak', 'link': 'https://arxiv.org/abs/2510.25427', 'abstract': 'Despite impressive results on curated benchmarks, the practical impact of large language models (LLMs) on research-level neural theorem proving and proof autoformalization is still limited. We introduce RLMEval, an evaluation suite for these tasks, focusing on research-level mathematics from real-world Lean formalization projects. RLMEval targets the evaluation of neural theorem proving and proof autoformalization on challenging research-level theorems by leveraging real Lean Blueprint formalization projects. Our evaluation of state-of-the-art models on RLMEval, comprising 613 theorems from 6 Lean projects, reveals a significant gap: progress on existing benchmarks does not readily translate to these more realistic settings, with the best model achieving only a 10.3 % pass rate. RLMEval provides a new, challenging benchmark designed to guide and accelerate progress in automated reasoning for formal mathematics.', 'abstract_zh': 'å°½ç®¡åœ¨ç²¾å¿ƒç­–åˆ’çš„åŸºå‡†æµ‹è¯•ä¸Šå–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„æˆæœï¼Œå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹åœ¨ç ”ç©¶çº§åˆ«çš„ç¥ç»å®šç†è¯æ˜å’Œè¯æ˜è‡ªå½¢å¼åŒ–æ–¹é¢çš„å®é™…å½±å“ä»ç„¶æœ‰é™ã€‚æˆ‘ä»¬å¼•å…¥äº†RLMEvalï¼Œä¸€ä¸ªé’ˆå¯¹è¿™äº›ä»»åŠ¡çš„è¯„ä¼°å¥—ä»¶ï¼Œä¸“æ³¨äºæ¥è‡ªçœŸå®ä¸–ç•ŒLeanå½¢å¼åŒ–é¡¹ç›®çš„å®é™…ç ”ç©¶çº§æ•°å­¦ã€‚RLMEvalé€šè¿‡åˆ©ç”¨çœŸå®çš„Leanè“å›¾å½¢å¼åŒ–é¡¹ç›®ï¼Œæ—¨åœ¨è¯„ä¼°ç¥ç»å®šç†è¯æ˜å’Œè¯æ˜è‡ªå½¢å¼åŒ–åœ¨æ›´å…·æŒ‘æˆ˜æ€§çš„ç ”ç©¶çº§å®šç†ä¸Šçš„è¡¨ç°ã€‚æˆ‘ä»¬åœ¨RLMEvalä¸Šçš„è¯„ä¼°æ¶µç›–äº†æ¥è‡ª6ä¸ªLeané¡¹ç›®çš„613ä¸ªå®šç†ï¼Œæ­ç¤ºäº†ä¸€ä¸ªæ˜¾è‘—çš„å·®è·ï¼šç°æœ‰åŸºå‡†æµ‹è¯•ä¸Šçš„è¿›å±•å¹¶ä¸å®¹æ˜“è½¬åŒ–ä¸ºè¿™äº›æ›´ä¸ºç°å®çš„è®¾ç½®ï¼Œæœ€å¥½çš„æ¨¡å‹ä»…å®ç°äº†10.3%çš„é€šè¿‡ç‡ã€‚RLMEvalæä¾›äº†ä¸€ä¸ªæ–°çš„ã€å…·æœ‰æŒ‘æˆ˜æ€§çš„åŸºå‡†ï¼Œæ—¨åœ¨å¼•å¯¼å’ŒåŠ é€Ÿå½¢å¼åŒ–æ•°å­¦ä¸­çš„è‡ªåŠ¨æ¨ç†ç ”ç©¶ã€‚', 'title_zh': 'RLMEval: è¯„ä¼°ç ”ç©¶çº§ç¥ç»å®šç†è¯æ˜'}
{'arxiv_id': 'arXiv:2510.25426', 'title': 'Implicature in Interaction: Understanding Implicature Improves Alignment in Human-LLM Interaction', 'authors': 'Asutosh Hota, Jussi P. P. Jokinen', 'link': 'https://arxiv.org/abs/2510.25426', 'abstract': "The rapid advancement of Large Language Models (LLMs) is positioning language at the core of human-computer interaction (HCI). We argue that advancing HCI requires attention to the linguistic foundations of interaction, particularly implicature (meaning conveyed beyond explicit statements through shared context) which is essential for human-AI (HAI) alignment. This study examines LLMs' ability to infer user intent embedded in context-driven prompts and whether understanding implicature improves response generation. Results show that larger models approximate human interpretations more closely, while smaller models struggle with implicature inference. Furthermore, implicature-based prompts significantly enhance the perceived relevance and quality of responses across models, with notable gains in smaller models. Overall, 67.6% of participants preferred responses with implicature-embedded prompts to literal ones, highlighting a clear preference for contextually nuanced communication. Our work contributes to understanding how linguistic theory can be used to address the alignment problem by making HAI interaction more natural and contextually grounded.", 'abstract_zh': 'å¤§å‹è¯­è¨€æ¨¡å‹çš„å¿«é€Ÿè¿›æ­¥å°†è¯­è¨€ç½®äºäººç±»è®¡ç®—æœºäº¤äº’çš„æ ¸å¿ƒä½ç½®ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œæ¨è¿›äººç±»è®¡ç®—æœºäº¤äº’éœ€è¦å…³æ³¨äº¤äº’çš„è¯­è¨€åŸºç¡€ï¼Œç‰¹åˆ«æ˜¯è•´å«æ„ä¹‰ï¼ˆé€šè¿‡å…±äº«èƒŒæ™¯ä¼ è¾¾çš„æ„ä¹‰è¶…è¶Šäº†æ˜ç¤ºå£°æ˜ï¼‰ï¼Œè¿™å¯¹äºäººç±»-äººå·¥æ™ºèƒ½ï¼ˆHAIï¼‰çš„å¯¹é½è‡³å…³é‡è¦ã€‚æœ¬ç ”ç©¶è€ƒå¯Ÿäº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åŸºäºæƒ…å¢ƒæç¤ºæ¨æ–­ç”¨æˆ·æ„å›¾æ–¹é¢çš„èƒ½åŠ›ï¼Œä»¥åŠç†è§£è•´å«æ„ä¹‰æ˜¯å¦èƒ½æ”¹å–„å“åº”ç”Ÿæˆã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œæ›´å¤§çš„æ¨¡å‹èƒ½æ›´æ¥è¿‘åœ°é€¼è¿‘äººç±»çš„è§£é‡Šï¼Œè€Œè¾ƒå°çš„æ¨¡å‹åœ¨è•´å«æ„ä¹‰æ¨ç†æ–¹é¢å­˜åœ¨å›°éš¾ã€‚æ­¤å¤–ï¼ŒåŸºäºè•´å«æ„ä¹‰çš„æç¤ºæ˜¾è‘—å¢å¼ºäº†å„ç§æ¨¡å‹ç”Ÿæˆçš„å“åº”çš„æ„ŸçŸ¥ç›¸å…³æ€§å’Œè´¨é‡ï¼Œå°¤å…¶æ˜¯åœ¨è¾ƒå°çš„æ¨¡å‹ä¸­å–å¾—äº†æ˜¾è‘—çš„æå‡ã€‚æ€»ä½“è€Œè¨€ï¼Œ67.6%çš„å‚ä¸è€…åå¥½åµŒå…¥è•´å«æ„ä¹‰çš„æç¤ºç”Ÿæˆçš„å“åº”ï¼Œçªæ˜¾äº†å¯¹ä¸Šä¸‹æ–‡ç²¾ç»†äº¤æµçš„æ˜æ˜¾åå¥½ã€‚æˆ‘ä»¬çš„å·¥ä½œä¸ºå¦‚ä½•åˆ©ç”¨è¯­è¨€ç†è®ºæ¥è§£å†³å¯¹é½é—®é¢˜ï¼Œä½¿HAIäº¤äº’æ›´åŠ è‡ªç„¶å’ŒåŸºäºä¸Šä¸‹æ–‡åšå‡ºè´¡çŒ®ã€‚', 'title_zh': 'implicatureåœ¨äº¤äº’ä¸­çš„ä½œç”¨ï¼šç†è§£ implicature æé«˜äººç±»-å¤§è¯­è¨€æ¨¡å‹äº¤äº’çš„ä¸€è‡´æ€§'}
{'arxiv_id': 'arXiv:2510.25420', 'title': 'Improving Temporal Consistency and Fidelity at Inference-time in Perceptual Video Restoration by Zero-shot Image-based Diffusion Models', 'authors': 'Nasrin Rahimi, A. Murat Tekalp', 'link': 'https://arxiv.org/abs/2510.25420', 'abstract': 'Diffusion models have emerged as powerful priors for single-image restoration, but their application to zero-shot video restoration suffers from temporal inconsistencies due to the stochastic nature of sampling and complexity of incorporating explicit temporal modeling. In this work, we address the challenge of improving temporal coherence in video restoration using zero-shot image-based diffusion models without retraining or modifying their architecture. We propose two complementary inference-time strategies: (1) Perceptual Straightening Guidance (PSG) based on the neuroscience-inspired perceptual straightening hypothesis, which steers the diffusion denoising process towards smoother temporal evolution by incorporating a curvature penalty in a perceptual space to improve temporal perceptual scores, such as FrÃ©chet Video Distance (FVD) and perceptual straightness; and (2) Multi-Path Ensemble Sampling (MPES), which aims at reducing stochastic variation by ensembling multiple diffusion trajectories to improve fidelity (distortion) scores, such as PSNR and SSIM, without sacrificing sharpness. Together, these training-free techniques provide a practical path toward temporally stable high-fidelity perceptual video restoration using large pretrained diffusion models. We performed extensive experiments over multiple datasets and degradation types, systematically evaluating each strategy to understand their strengths and limitations. Our results show that while PSG enhances temporal naturalness, particularly in case of temporal blur, MPES consistently improves fidelity and spatio-temporal perception--distortion trade-off across all tasks.', 'abstract_zh': 'åŸºäºé›¶æ ·æœ¬å•å›¾åƒæ‰©æ•£æ¨¡å‹çš„è§†é¢‘æ¢å¤ä¸­æé«˜æ—¶é—´ä¸€è‡´æ€§çš„æ–¹æ³•', 'title_zh': 'é›¶æ ·æœ¬å›¾åƒé©±åŠ¨æ‰©æ•£æ¨¡å‹åœ¨æ„ŸçŸ¥è§†é¢‘æ¢å¤ä¸­æé«˜æ¨ç†æ—¶çš„æ—¶ç©ºä¸€è‡´æ€§ä¸ä¿çœŸåº¦'}
{'arxiv_id': 'arXiv:2510.25416', 'title': 'Adaptive End-to-End Transceiver Design for NextG Pilot-Free and CP-Free Wireless Systems', 'authors': 'Jiaming Cheng, Wei Chen, Bo Ai', 'link': 'https://arxiv.org/abs/2510.25416', 'abstract': 'The advent of artificial intelligence (AI)-native wireless communication is fundamentally reshaping the design paradigm of next-generation (NextG) systems, where intelligent air interfaces are expected to operate adaptively and efficiently in highly dynamic environments. Conventional orthogonal frequency division multiplexing (OFDM) systems rely heavily on pilots and the cyclic prefix (CP), resulting in significant overhead and reduced spectral efficiency. To address these limitations, we propose an adaptive end-to-end (E2E) transceiver architecture tailored for pilot-free and CP-free wireless systems. The architecture combines AI-driven constellation shaping and a neural receiver through joint training. To enhance robustness against mismatched or time-varying channel conditions, we introduce a lightweight channel adapter (CA) module, which enables rapid adaptation with minimal computational overhead by updating only the CA parameters. Additionally, we present a framework that is scalable to multiple modulation orders within a unified model, significantly reducing model storage requirements. Moreover, to tackle the high peak-to-average power ratio (PAPR) inherent to OFDM, we incorporate constrained E2E training, achieving compliance with PAPR targets without additional transmission overhead. Extensive simulations demonstrate that the proposed framework delivers superior bit error rate (BER), throughput, and resilience across diverse channel scenarios, highlighting its potential for AI-native NextG.', 'abstract_zh': 'AIåŸç”Ÿæ— çº¿é€šä¿¡çš„å‡ºç°ä»æ ¹æœ¬ä¸Šé‡å¡‘äº†ä¸‹ä¸€ä»£ï¼ˆNextGï¼‰ç³»ç»Ÿçš„è®¾è®¡èŒƒå¼ï¼Œå…¶ä¸­æ™ºèƒ½ç©ºä¸­æ¥å£é¢„è®¡èƒ½åœ¨é«˜åº¦åŠ¨æ€çš„ç¯å¢ƒä¸­å®ç°è‡ªé€‚åº”å’Œé«˜æ•ˆçš„è¿è¡Œã€‚ä¼ ç»Ÿçš„æ­£äº¤é¢‘åˆ†å¤ç”¨ï¼ˆOFDMï¼‰ç³»ç»Ÿä¸¥é‡ä¾èµ–äºè®­ç»ƒåºåˆ—å’Œå¾ªç¯å‰ç¼€ï¼ˆCPï¼‰ï¼Œå¯¼è‡´äº†è¾ƒå¤§çš„å¼€é”€å¹¶é™ä½äº†é¢‘è°±æ•ˆç‡ã€‚ä¸ºäº†åº”å¯¹è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é’ˆå¯¹æ— è®­ç»ƒåºåˆ—å’Œæ— å¾ªç¯å‰ç¼€æ— çº¿ç³»ç»Ÿçš„è‡ªé€‚åº”ç«¯åˆ°ç«¯ï¼ˆE2Eï¼‰æ”¶å‘æœºæ¶æ„ã€‚è¯¥æ¶æ„ç»“åˆäº†åŸºäºAIçš„æ˜Ÿåº§æ•´å½¢å’Œç¥ç»æ¥æ”¶å™¨ï¼Œå¹¶é€šè¿‡è”åˆè®­ç»ƒå®ç°ã€‚ä¸ºäº†å¢å¼ºå¯¹å¤±é…æˆ–æ—¶å˜ä¿¡é“æ¡ä»¶çš„é²æ£’æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªè½»é‡çº§ä¿¡é“é€‚é…å™¨ï¼ˆCAï¼‰æ¨¡å—ï¼Œè¯¥æ¨¡å—é€šè¿‡ä»…æ›´æ–°CAå‚æ•°æ¥å®ç°å¿«é€Ÿé€‚åº”å¹¶å‡å°‘è®¡ç®—å¼€é”€ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ¡†æ¶ï¼Œå¯ä»¥åœ¨ç»Ÿä¸€æ¨¡å‹ä¸­æ‰©å±•åˆ°å¤šç§è°ƒåˆ¶é˜¶æ•°ï¼Œæ˜¾è‘—é™ä½äº†æ¨¡å‹å­˜å‚¨éœ€æ±‚ã€‚æ­¤å¤–ï¼Œä¸ºäº†åº”å¯¹OFDMå›ºæœ‰çš„é«˜å³°å‡åŠŸç‡æ¯”ï¼ˆPAPRï¼‰ï¼Œæˆ‘ä»¬å¼•å…¥äº†å—é™çš„ç«¯åˆ°ç«¯è®­ç»ƒï¼Œå®ç°äº†PAPRç›®æ ‡çš„ç¬¦åˆæ€§ï¼Œè€Œæ— éœ€é¢å¤–çš„ä¼ è¾“å¼€é”€ã€‚å¹¿æ³›ä»¿çœŸå®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ¡†æ¶åœ¨å„ç§ä¿¡é“åœºæ™¯ä¸­æä¾›äº†æ›´ä¼˜çš„è¯¯æ¯”ç‰¹ç‡ï¼ˆBERï¼‰ã€ååé‡å’Œé²æ£’æ€§ï¼Œçªæ˜¾äº†å…¶åœ¨AIåŸç”ŸNextGä¸­çš„æ½œåŠ›ã€‚', 'title_zh': 'é¢å‘NextGçš„æ—  pilot å’Œæ— å¾ªç¯å‰ç¼€çš„æ— çº¿ç³»ç»Ÿè‡ªé€‚åº”ç«¯åˆ°ç«¯æ”¶å‘æœºè®¾è®¡'}
{'arxiv_id': 'arXiv:2510.25409', 'title': 'BhashaBench V1: A Comprehensive Benchmark for the Quadrant of Indic Domains', 'authors': 'Vijay Devane, Mohd Nauman, Bhargav Patel, Aniket Mahendra Wakchoure, Yogeshkumar Sant, Shyam Pawar, Viraj Thakur, Ananya Godse, Sunil Patra, Neha Maurya, Suraj Racha, Nitish Kamal Singh, Ajay Nagpal, Piyush Sawarkar, Kundeshwar Vijayrao Pundalik, Rohit Saluja, Ganesh Ramakrishnan', 'link': 'https://arxiv.org/abs/2510.25409', 'abstract': "The rapid advancement of large language models(LLMs) has intensified the need for domain and culture specific evaluation. Existing benchmarks are largely Anglocentric and domain-agnostic, limiting their applicability to India-centric contexts. To address this gap, we introduce BhashaBench V1, the first domain-specific, multi-task, bilingual benchmark focusing on critical Indic knowledge systems. BhashaBench V1 contains 74,166 meticulously curated question-answer pairs, with 52,494 in English and 21,672 in Hindi, sourced from authentic government and domain-specific exams. It spans four major domains: Agriculture, Legal, Finance, and Ayurveda, comprising 90+ subdomains and covering 500+ topics, enabling fine-grained evaluation. Evaluation of 29+ LLMs reveals significant domain and language specific performance gaps, with especially large disparities in low-resource domains. For instance, GPT-4o achieves 76.49% overall accuracy in Legal but only 59.74% in Ayurveda. Models consistently perform better on English content compared to Hindi across all domains. Subdomain-level analysis shows that areas such as Cyber Law, International Finance perform relatively well, while Panchakarma, Seed Science, and Human Rights remain notably weak. BhashaBench V1 provides a comprehensive dataset for evaluating large language models across India's diverse knowledge domains. It enables assessment of models' ability to integrate domain-specific knowledge with bilingual understanding. All code, benchmarks, and resources are publicly available to support open research.", 'abstract_zh': 'å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„è¿…é€Ÿå‘å±•åŠ å‰§äº†é¢†åŸŸç‰¹å®šå’Œæ–‡åŒ–ç‰¹å®šè¯„ä¼°çš„éœ€æ±‚ã€‚ç°æœ‰åŸºå‡†ä¸»è¦ä»¥è‹±ç¾ä¸ºä¸­å¿ƒä¸”ç¼ºä¹é¢†åŸŸé’ˆå¯¹æ€§ï¼Œé™åˆ¶äº†å…¶åœ¨å°åº¦ä¸­å¿ƒæƒ…å¢ƒä¸­çš„åº”ç”¨ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†BhashaBench V1ï¼Œè¿™æ˜¯é¦–ä¸ªä¸“æ³¨äºå…³é”®å°åœ°è¯­çŸ¥è¯†ä½“ç³»çš„é¢†åŸŸç‰¹å®šã€å¤šä»»åŠ¡ã€åŒè¯­åŸºå‡†ã€‚BhashaBench V1åŒ…å«74,166å¯¹ç²¾å¿ƒç­–åˆ’çš„é—®é¢˜-ç­”æ¡ˆå¯¹ï¼Œå…¶ä¸­52,494å¯¹ä¸ºè‹±è¯­ï¼Œ21,672å¯¹ä¸ºå°åœ°è¯­ï¼Œæ•°æ®æ¥æºäºçœŸå®çš„æ”¿åºœè€ƒè¯•å’Œç‰¹å®šé¢†åŸŸçš„è€ƒè¯•ã€‚è¯¥åŸºå‡†è¦†ç›–äº†å†œä¸šã€æ³•å¾‹ã€é‡‘èå’Œé˜¿è‚²å é™€å››å¤§ä¸»è¦é¢†åŸŸï¼Œå†…å«90å¤šä¸ªå­é¢†åŸŸï¼Œæ¶µç›–äº†500å¤šä¸ªä¸»é¢˜ï¼Œå®ç°äº†ç²¾ç»†çš„è¯„ä¼°ã€‚è¯„ä¼°29å¤šä¸ªå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹æ­ç¤ºäº†æ˜¾è‘—çš„é¢†åŸŸå’Œè¯­è¨€ç‰¹å®šæ€§èƒ½å·®è·ï¼Œç‰¹åˆ«æ˜¯åœ¨ä½èµ„æºé¢†åŸŸå·®è·æ˜æ˜¾ã€‚ä¾‹å¦‚ï¼ŒGPT-4oåœ¨æ³•å¾‹é¢†åŸŸçš„å‡†ç¡®ç‡ä¸º76.49%ï¼Œä½†åœ¨é˜¿è‚²å é™€é¢†åŸŸçš„å‡†ç¡®ç‡ä»…ä¸º59.74%ã€‚æ‰€æœ‰æ¨¡å‹åœ¨æ‰€æœ‰é¢†åŸŸä¸­å¯¹è‹±è¯­å†…å®¹çš„è¡¨ç°éƒ½ä¼˜äºå°åœ°è¯­å†…å®¹ã€‚åœ¨å­é¢†åŸŸçš„åˆ†æä¸­æ˜¾ç¤ºï¼Œè¯¸å¦‚ç½‘ç»œæ³•ã€å›½é™…é‡‘èç­‰é¢†åŸŸè¡¨ç°ç›¸å¯¹è¾ƒå¥½ï¼Œè€ŒPanchakarmaã€ç§å­ç§‘å­¦ã€äººæƒç­‰é¢†åŸŸä¾ç„¶è¡¨ç°è¾ƒå¼±ã€‚BhashaBench V1ä¸ºè¯„ä¼°å°åº¦å¤šæ ·åŒ–çŸ¥è¯†é¢†åŸŸçš„å¤§å‹è¯­è¨€æ¨¡å‹æä¾›äº†å…¨é¢çš„æ•°æ®é›†ã€‚å®ƒä½¿æ¨¡å‹èƒ½å¤Ÿæ•´åˆé¢†åŸŸç‰¹å®šçŸ¥è¯†ä¸åŒè¯­ç†è§£çš„èƒ½åŠ›å¾—åˆ°è¯„ä¼°ã€‚æ‰€æœ‰ä»£ç ã€åŸºå‡†å’Œèµ„æºå‡å…¬å¼€æä¾›ï¼Œä»¥æ”¯æŒå¼€æ”¾ç ”ç©¶ã€‚', 'title_zh': 'BhashaBench V1ï¼šå°åº¦è¯­è¨€é¢†åŸŸè±¡é™çš„ç»¼åˆåŸºå‡†'}
{'arxiv_id': 'arXiv:2510.25404', 'title': 'GPTOpt: Towards Efficient LLM-Based Black-Box Optimization', 'authors': 'Jamison Meindl, Yunsheng Tian, Tony Cui, Veronika Thost, Zhang-Wei Hong, Jie Chen, Wojciech Matusik, Mina KonakoviÄ‡ LukoviÄ‡', 'link': 'https://arxiv.org/abs/2510.25404', 'abstract': 'Global optimization of expensive, derivative-free black-box functions demands extreme sample efficiency. Classical methods such as Bayesian Optimization (BO) can be effective, but they often require careful parameter tuning to each application domain. At the same time, Large Language Models (LLMs) have shown broad capabilities, yet state-of-the-art models remain limited in solving continuous black-box optimization tasks. We introduce GPTOpt, an LLM-based optimization method that equips LLMs with continuous black-box optimization capabilities. By fine-tuning large language models on extensive synthetic datasets derived from diverse BO parameterizations, GPTOpt leverages LLM pre-training to generalize across optimization tasks. On a variety of black-box optimization benchmarks, GPTOpt surpasses traditional optimizers, highlighting the capacity of LLMs for advanced numerical reasoning and introducing a flexible framework for global optimization without parameter tuning.', 'abstract_zh': 'åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„å…¨çƒä¼˜åŒ–æ–¹æ³•GPTOptï¼šåˆ©ç”¨è¿ç»­é»‘ç›’ä¼˜åŒ–èƒ½åŠ›çš„é¢„è®­ç»ƒè°ƒæ•´', 'title_zh': 'GPTOpt: toward efficient LLM-based black-box optimization'}
{'arxiv_id': 'arXiv:2510.25386', 'title': 'Integrating Legal and Logical Specifications in Perception, Prediction, and Planning for Automated Driving: A Survey of Methods', 'authors': 'Kumar Manas, Mert Keser, Alois Knoll', 'link': 'https://arxiv.org/abs/2510.25386', 'abstract': 'This survey provides an analysis of current methodologies integrating legal and logical specifications into the perception, prediction, and planning modules of automated driving systems. We systematically explore techniques ranging from logic-based frameworks to computational legal reasoning approaches, emphasizing their capability to ensure regulatory compliance and interpretability in dynamic and uncertain driving environments. A central finding is that significant challenges arise at the intersection of perceptual reliability, legal compliance, and decision-making justifiability. To systematically analyze these challenges, we introduce a taxonomy categorizing existing approaches by their theoretical foundations, architectural implementations, and validation strategies. We particularly focus on methods that address perceptual uncertainty and incorporate explicit legal norms, facilitating decisions that are both technically robust and legally defensible. The review covers neural-symbolic integration methods for perception, logic-driven rule representation, and norm-aware prediction strategies, all contributing toward transparent and accountable autonomous vehicle operation. We highlight critical open questions and practical trade-offs that must be addressed, offering multidisciplinary insights from engineering, logic, and law to guide future developments in legally compliant autonomous driving systems.', 'abstract_zh': 'æœ¬ç»¼è¿°å¯¹å°†æ³•å¾‹å’Œé€»è¾‘è§„èŒƒé›†æˆåˆ°è‡ªåŠ¨åŒ–é©¾é©¶ç³»ç»Ÿä¸­æ„ŸçŸ¥ã€é¢„æµ‹å’Œè§„åˆ’æ¨¡å—çš„æ–¹æ³•è®ºè¿›è¡Œäº†åˆ†æã€‚æˆ‘ä»¬ç³»ç»Ÿåœ°æ¢è®¨äº†ä»åŸºäºé€»è¾‘çš„æ¡†æ¶åˆ°è®¡ç®—æ³•å¾‹æ¨ç†æ–¹æ³•çš„æŠ€æœ¯ï¼Œå¼ºè°ƒäº†å®ƒä»¬ç¡®ä¿åŠ¨æ€å’Œä¸ç¡®å®šé©¾é©¶ç¯å¢ƒä¸­åˆè§„æ€§å’Œå¯è§£é‡Šæ€§çš„èƒ½åŠ›ã€‚ä¸»è¦å‘ç°æ˜¯åœ¨æ„ŸçŸ¥å¯é æ€§ã€æ³•å¾‹åˆè§„æ€§å’Œå†³ç­–æ­£å½“æ€§äº¤æ±‡å¤„å­˜åœ¨é‡å¤§æŒ‘æˆ˜ã€‚ä¸ºç³»ç»Ÿåˆ†æè¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åˆ†ç±»æ³•ï¼ŒæŒ‰ç†è®ºåŸºç¡€ã€æ¶æ„å®ç°å’ŒéªŒè¯ç­–ç•¥å¯¹ç°æœ‰æ–¹æ³•è¿›è¡Œåˆ†ç±»ã€‚ç‰¹åˆ«å…³æ³¨è§£å†³æ„ŸçŸ¥ä¸ç¡®å®šæ€§å¹¶æ˜ç¡®çº³å…¥æ³•å¾‹è§„èŒƒçš„æ–¹æ³•ï¼Œä»¥ä¿ƒè¿›æ—¢æŠ€æœ¯ç¨³å¥åˆæ³•å¾‹ä¸Šå¯è¾©æŠ¤çš„å†³ç­–ã€‚ç»¼è¿°æ¶µç›–äº†æ„ŸçŸ¥ä¸­çš„ç¥ç»ç¬¦å·é›†æˆæ–¹æ³•ã€é€»è¾‘é©±åŠ¨çš„è§„åˆ™è¡¨ç¤ºå’Œéµå®ˆè§„èŒƒçš„é¢„æµ‹ç­–ç•¥ï¼Œæ‰€æœ‰è¿™äº›éƒ½æ—¨åœ¨ä¿ƒè¿›é€æ˜å’Œè´Ÿè´£ä»»çš„è‡ªåŠ¨é©¾é©¶æ“ä½œã€‚æˆ‘ä»¬å¼ºè°ƒäº†å¿…é¡»è§£å†³çš„å…³é”®å¼€æ”¾é—®é¢˜å’Œå®é™…æƒè¡¡ï¼Œå¹¶æä¾›äº†æ¥è‡ªå·¥ç¨‹å­¦ã€é€»è¾‘å­¦å’Œæ³•å­¦çš„å¤šå­¦ç§‘è§†è§’ï¼Œä»¥æŒ‡å¯¼æœªæ¥ç¬¦åˆæ³•å¾‹è¦æ±‚çš„è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„å‘å±•ã€‚', 'title_zh': 'å°†æ³•å¾‹æ³•è§„å’Œé€»è¾‘è§„èŒƒèå…¥è‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥ã€é¢„æµ‹ä¸è§„åˆ’ä¸­çš„æ–¹æ³•ç»¼è¿°'}
{'arxiv_id': 'arXiv:2510.25378', 'title': 'Hallucinations in Bibliographic Recommendation: Citation Frequency as a Proxy for Training Data Redundancy', 'authors': 'Junichiro Niimi', 'link': 'https://arxiv.org/abs/2510.25378', 'abstract': "Large language models (LLMs) have been increasingly applied to a wide range of tasks, from natural language understanding to code generation. While they have also been used to assist in bibliographic recommendation, the hallucination of non-existent papers remains a major issue. Building on prior studies, this study hypothesizes that an LLM's ability to correctly produce bibliographic information depends on whether the underlying knowledge is generated or memorized, with highly cited papers (i.e., more frequently appear in the training corpus) showing lower hallucination rates. We therefore assume citation count as a proxy for training data redundancy (i.e., the frequency with which a given bibliographic record is repeatedly represented in the pretraining corpus) and investigate how citation frequency affects hallucinated references in LLM outputs. Using GPT-4.1, we generated and manually verified 100 bibliographic records across twenty computer-science domains, and measured factual consistency via cosine similarity between generated and authentic metadata. The results revealed that (i) hallucination rates vary across research domains, (ii) citation count is strongly correlated with factual accuracy, and (iii) bibliographic information becomes almost verbatimly memorized beyond approximately 1,000 citations. These findings suggest that highly cited papers are nearly verbatimly retained in the model, indicating a threshold where generalization shifts into memorization.", 'abstract_zh': 'å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å·²åœ¨å¹¿æ³›ä»»åŠ¡ä¸­åº”ç”¨ï¼Œä»è‡ªç„¶è¯­è¨€ç†è§£åˆ°ä»£ç ç”Ÿæˆã€‚å°½ç®¡å®ƒä»¬ä¹Ÿè¢«ç”¨äºæ–‡çŒ®æ¨èè¾…åŠ©ï¼Œä½†ç”Ÿæˆä¸å­˜åœ¨çš„è®ºæ–‡ä»ç„¶æ˜¯ä¸€ä¸ªä¸»è¦é—®é¢˜ã€‚åŸºäºå…ˆå‰çš„ç ”ç©¶ï¼Œæœ¬ç ”ç©¶å‡è®¾è¯­è¨€æ¨¡å‹æ­£ç¡®äº§ç”Ÿæ–‡çŒ®ä¿¡æ¯çš„èƒ½åŠ›å–å†³äºå…¶çŸ¥è¯†æ¥æºï¼Œå³é«˜åº¦å¼•ç”¨çš„è®ºæ–‡ï¼ˆå³åœ¨è®­ç»ƒè¯­æ–™ä¸­æ›´é¢‘ç¹å‡ºç°ï¼‰æ˜¾ç¤ºå‡ºè¾ƒä½çš„å¹»è§‰ç‡ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å‡å®šå¼•ç”¨æ¬¡æ•°ä½œä¸ºè®­ç»ƒæ•°æ®å†—ä½™çš„ä»£ç†ï¼ˆå³ç»™å®šå‚è€ƒè®°å½•åœ¨é¢„è®­ç»ƒè¯­æ–™ä¸­é‡å¤å‡ºç°çš„é¢‘ç‡ï¼‰ï¼Œå¹¶æ¢è®¨å¼•ç”¨é¢‘ç‡å¦‚ä½•å½±å“è¯­è¨€æ¨¡å‹è¾“å‡ºä¸­çš„å¹»è§‰å‚è€ƒæ–‡çŒ®ã€‚ä½¿ç”¨GPT-4.1ï¼Œæˆ‘ä»¬ç”Ÿæˆå¹¶äººå·¥éªŒè¯äº†æ¶µç›–äºŒåä¸ªè®¡ç®—æœºç§‘å­¦é¢†åŸŸçš„100æ¡æ–‡çŒ®è®°å½•ï¼Œå¹¶é€šè¿‡ç”Ÿæˆçš„å…ƒæ•°æ®ä¸çœŸå®å…ƒæ•°æ®ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦è¡¡é‡äº‹å®ä¸€è‡´æ€§ã€‚ç»“æœè¡¨æ˜ï¼š(i) å¹»è§‰ç‡åœ¨ä¸åŒç ”ç©¶é¢†åŸŸä¹‹é—´æœ‰æ‰€å·®å¼‚ï¼›(ii) å¼•ç”¨æ¬¡æ•°ä¸äº‹å®å‡†ç¡®æ€§ä¹‹é—´å­˜åœ¨å¼ºçƒˆç›¸å…³æ€§ï¼›(iii) å¼•ç”¨æ¬¡æ•°è¶…è¿‡çº¦1,000æ¬¡åï¼Œæ–‡çŒ®ä¿¡æ¯å‡ ä¹è¢«é€å­—è®°ä½äº†ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œé«˜åº¦å¼•ç”¨çš„è®ºæ–‡å‡ ä¹é€å­—ä¿ç•™åœ¨æ¨¡å‹ä¸­ï¼Œè¡¨æ˜ä»æ³›åŒ–åˆ°è®°å¿†çš„è½¬å˜å­˜åœ¨ä¸€ä¸ªé˜ˆå€¼ã€‚', 'title_zh': 'æ–‡çŒ®ä¸­çš„å¹»è§‰ï¼šå¼•æ–‡é¢‘ç‡ä½œä¸ºè®­ç»ƒæ•°æ®å†—ä½™çš„ä»£ç†æŒ‡æ ‡'}
{'arxiv_id': 'arXiv:2510.25368', 'title': 'Position: Biology is the Challenge Physics-Informed ML Needs to Evolve', 'authors': 'Julien Martinelli', 'link': 'https://arxiv.org/abs/2510.25368', 'abstract': 'Physics-Informed Machine Learning (PIML) has successfully integrated mechanistic understanding into machine learning, particularly in domains governed by well-known physical laws. This success has motivated efforts to apply PIML to biology, a field rich in dynamical systems but shaped by different constraints. Biological modeling, however, presents unique challenges: multi-faceted and uncertain prior knowledge, heterogeneous and noisy data, partial observability, and complex, high-dimensional networks. In this position paper, we argue that these challenges should not be seen as obstacles to PIML, but as catalysts for its evolution. We propose Biology-Informed Machine Learning (BIML): a principled extension of PIML that retains its structural grounding while adapting to the practical realities of biology. Rather than replacing PIML, BIML retools its methods to operate under softer, probabilistic forms of prior knowledge. We outline four foundational pillars as a roadmap for this transition: uncertainty quantification, contextualization, constrained latent structure inference, and scalability. Foundation Models and Large Language Models will be key enablers, bridging human expertise with computational modeling. We conclude with concrete recommendations to build the BIML ecosystem and channel PIML-inspired innovation toward challenges of high scientific and societal relevance.', 'abstract_zh': 'ç”Ÿç‰©å­¦å¯¼å‘çš„æœºå™¨å­¦ä¹ ï¼ˆBIMLï¼‰ï¼šç‰©ç†å­¦å¯¼å‘çš„æœºå™¨å­¦ä¹ çš„æ‰©å±•ä¸æ¼”åŒ–', 'title_zh': 'ä½ç½®ï¼šç”Ÿç‰©å­¦æ˜¯ç‰©ç†å¯¼å‘æœºå™¨å­¦ä¹ éœ€è¦è§£å†³çš„æŒ‘æˆ˜'}
{'arxiv_id': 'arXiv:2510.25366', 'title': 'A Convexity-dependent Two-Phase Training Algorithm for Deep Neural Networks', 'authors': 'Tomas Hrycej, Bernhard Bermeitinger, Massimo Pavone, GÃ¶tz-Henrik Wiegand, Siegfried Handschuh', 'link': 'https://arxiv.org/abs/2510.25366', 'abstract': 'The key task of machine learning is to minimize the loss function that measures the model fit to the training data. The numerical methods to do this efficiently depend on the properties of the loss function. The most decisive among these properties is the convexity or non-convexity of the loss function. The fact that the loss function can have, and frequently has, non-convex regions has led to a widespread commitment to non-convex methods such as Adam. However, a local minimum implies that, in some environment around it, the function is convex. In this environment, second-order minimizing methods such as the Conjugate Gradient (CG) give a guaranteed superlinear convergence. We propose a novel framework grounded in the hypothesis that loss functions in real-world tasks swap from initial non-convexity to convexity towards the optimum. This is a property we leverage to design an innovative two-phase optimization algorithm. The presented algorithm detects the swap point by observing the gradient norm dependence on the loss. In these regions, non-convex (Adam) and convex (CG) algorithms are used, respectively. Computing experiments confirm the hypothesis that this simple convexity structure is frequent enough to be practically exploited to substantially improve convergence and accuracy.', 'abstract_zh': 'æœºå™¨å­¦ä¹ çš„å…³é”®ä»»åŠ¡æ˜¯é€šè¿‡æœ€å°åŒ–è¡¡é‡æ¨¡å‹ä¸è®­ç»ƒæ•°æ®æ‹Ÿåˆç¨‹åº¦çš„æŸå¤±å‡½æ•°ã€‚é«˜æ•ˆå®ç°è¿™ä¸€ä»»åŠ¡çš„æ•°å€¼æ–¹æ³•å–å†³äºæŸå¤±å‡½æ•°çš„æ€§è´¨ã€‚è¿™äº›æ€§è´¨ä¸­æœ€å…³é”®çš„æ˜¯æŸå¤±å‡½æ•°çš„å‡¸æ€§æˆ–éå‡¸æ€§ã€‚ç”±äºæŸå¤±å‡½æ•°å¯ä»¥æœ‰éå‡¸åŒºåŸŸï¼Œå¹¶ä¸”ç»å¸¸å­˜åœ¨éå‡¸åŒºåŸŸï¼Œäººä»¬æ™®éé‡‡ç”¨å¦‚Adamè¿™æ ·çš„éå‡¸æ–¹æ³•ã€‚ç„¶è€Œï¼Œå±€éƒ¨æå°å€¼æ„å‘³ç€åœ¨å®ƒå‘¨å›´çš„æŸä¸ªç¯å¢ƒä¸­ï¼Œå‡½æ•°æ˜¯å‡¸çš„ã€‚åœ¨è¿™æ ·çš„ç¯å¢ƒä¸­ï¼Œå¦‚å…±è½­æ¢¯åº¦ï¼ˆCGï¼‰çš„äºŒæ¬¡ä¼˜åŒ–æ–¹æ³•å¯ä»¥ç¡®ä¿è¶…çº¿æ€§æ”¶æ•›ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œåœ¨è¯¥æ¡†æ¶ä¸­å‡è®¾å®é™…ä»»åŠ¡ä¸­çš„æŸå¤±å‡½æ•°ä»åˆå§‹éå‡¸æ€§é€æ­¥å˜ä¸ºå‡¸æ€§ç›´è‡³æœ€ä¼˜è§£ã€‚è¿™ä¸€ç‰¹æ€§è¢«æˆ‘ä»¬ç”¨æ¥è®¾è®¡ä¸€ç§åˆ›æ–°çš„ä¸¤é˜¶æ®µä¼˜åŒ–ç®—æ³•ã€‚è¯¥ç®—æ³•é€šè¿‡è§‚å¯Ÿæ¢¯åº¦èŒƒæ•°å¯¹æŸå¤±çš„ä¾èµ–æ¥æ£€æµ‹äº¤æ¢ç‚¹ï¼Œåœ¨éå‡¸åŒºåŸŸä½¿ç”¨Adamç®—æ³•ï¼Œåœ¨å‡¸åŒºåŸŸä½¿ç”¨CGç®—æ³•ã€‚è®¡ç®—å®éªŒè¯å®äº†è¿™ä¸€ç®€å•çš„å‡¸æ€§ç»“æ„è¶³å¤Ÿé¢‘ç¹ï¼Œå¯ä»¥å®é™…åˆ©ç”¨æ¥æ˜¾è‘—æé«˜æ”¶æ•›æ€§å’Œå‡†ç¡®æ€§ã€‚', 'title_zh': 'åŸºäºå‡¸æ€§ä¾èµ–çš„ä¸¤é˜¶æ®µæ·±åº¦ç¥ç»ç½‘ç»œè®­ç»ƒç®—æ³•'}
{'arxiv_id': 'arXiv:2510.25340', 'title': 'Multi-party Agent Relation Sampling for Multi-party Ad Hoc Teamwork', 'authors': 'Beiwen Zhang, Yongheng Liang, Hejun Wu', 'link': 'https://arxiv.org/abs/2510.25340', 'abstract': 'Multi-agent reinforcement learning (MARl) has achieved strong results in cooperative tasks but typically assumes fixed, fully controlled teams. Ad hoc teamwork (AHT) relaxes this by allowing collaboration with unknown partners, yet existing variants still presume shared conventions. We introduce Multil-party Ad Hoc Teamwork (MAHT), where controlled agents must coordinate with multiple mutually unfamiliar groups of uncontrolled teammates. To address this, we propose MARs, which builds a sparse skeleton graph and applies relational modeling to capture cross-group dvnamics. Experiments on MPE and starCralt ll show that MARs outperforms MARL and AHT baselines while converging faster.', 'abstract_zh': 'å¤šä»£ç†å¼ºåŒ–å­¦ä¹ ä¸­çš„å¤šç¾¤ä½“å¶ç„¶å›¢é˜Ÿåä½œï¼ˆMultil-party Ad Hoc Teamwork for Multi-agent Reinforcement Learningï¼‰', 'title_zh': 'å¤šæ–¹ä»£ç†å…³ç³»é‡‡æ ·ç”¨äºå¤šæ–¹ä¸´æ—¶å›¢é˜Ÿåä½œ'}
{'arxiv_id': 'arXiv:2510.25327', 'title': 'MMEdge: Accelerating On-device Multimodal Inference via Pipelined Sensing and Encoding', 'authors': 'Runxi Huang, Mingxuan Yu, Mingyu Tsoi, Xiaomin Ouyang', 'link': 'https://arxiv.org/abs/2510.25327', 'abstract': 'Real-time multimodal inference on resource-constrained edge devices is essential for applications such as autonomous driving, human-computer interaction, and mobile health. However, prior work often overlooks the tight coupling between sensing dynamics and model execution, as well as the complex inter-modality dependencies. In this paper, we propose MMEdge, an new on-device multi-modal inference framework based on pipelined sensing and encoding. Instead of waiting for complete sensor inputs, MMEdge decomposes the entire inference process into a sequence of fine-grained sensing and encoding units, allowing computation to proceed incrementally as data arrive. MMEdge also introduces a lightweight but effective temporal aggregation module that captures rich temporal dynamics across different pipelined units to maintain accuracy performance. Such pipelined design also opens up opportunities for fine-grained cross-modal optimization and early decision-making during inference. To further enhance system performance under resource variability and input data complexity, MMEdge incorporates an adaptive multimodal configuration optimizer that dynamically selects optimal sensing and model configurations for each modality under latency constraints, and a cross-modal speculative skipping mechanism that bypasses future units of slower modalities when early predictions reach sufficient confidence. We evaluate MMEdge using two public multimodal datasets and deploy it on a real-world unmanned aerial vehicle (UAV)-based multimodal testbed. The results show that MMEdge significantly reduces end-to-end latency while maintaining high task accuracy across various system and data dynamics.', 'abstract_zh': 'åŸºäºæµæ°´çº¿æ„ŸçŸ¥ä¸ç¼–ç çš„å®æ—¶å¤šæ¨¡æ€æ¨ç†æ¡†æ¶MMEdge', 'title_zh': 'MMEdge: é€šè¿‡ç®¡é“åŒ–æ„ŸçŸ¥ä¸ç¼–ç åŠ é€Ÿæœ¬åœ°å¤šæ¨¡æ€æ¨ç†'}
{'arxiv_id': 'arXiv:2510.25319', 'title': '4-Doodle: Text to 3D Sketches that Move!', 'authors': 'Hao Chen, Jiaqi Wang, Yonggang Qi, Ke Li, Kaiyue Pang, Yi-Zhe Song', 'link': 'https://arxiv.org/abs/2510.25319', 'abstract': 'We present a novel task: text-to-3D sketch animation, which aims to bring freeform sketches to life in dynamic 3D space. Unlike prior works focused on photorealistic content generation, we target sparse, stylized, and view-consistent 3D vector sketches, a lightweight and interpretable medium well-suited for visual communication and prototyping. However, this task is very challenging: (i) no paired dataset exists for text and 3D (or 4D) sketches; (ii) sketches require structural abstraction that is difficult to model with conventional 3D representations like NeRFs or point clouds; and (iii) animating such sketches demands temporal coherence and multi-view consistency, which current pipelines do not address. Therefore, we propose 4-Doodle, the first training-free framework for generating dynamic 3D sketches from text. It leverages pretrained image and video diffusion models through a dual-space distillation scheme: one space captures multi-view-consistent geometry using differentiable BÃ©zier curves, while the other encodes motion dynamics via temporally-aware priors. Unlike prior work (e.g., DreamFusion), which optimizes from a single view per step, our multi-view optimization ensures structural alignment and avoids view ambiguity, critical for sparse sketches. Furthermore, we introduce a structure-aware motion module that separates shape-preserving trajectories from deformation-aware changes, enabling expressive motion such as flipping, rotation, and articulated movement. Extensive experiments show that our method produces temporally realistic and structurally stable 3D sketch animations, outperforming existing baselines in both fidelity and controllability. We hope this work serves as a step toward more intuitive and accessible 4D content creation.', 'abstract_zh': 'æ–‡æœ¬åˆ°åŠ¨æ€3Dç´ æåŠ¨ç”»ï¼šä¸€ç§æ–°çš„ä»»åŠ¡åŠå…¶è§£å†³æ–¹æ¡ˆ', 'title_zh': '4-Doodle: æ–‡æœ¬è½¬åŒ–ä¸ºå¯åŠ¨çš„3Dè‰å›¾ï¼'}
{'arxiv_id': 'arXiv:2510.25311', 'title': 'Dense and Diverse Goal Coverage in Multi Goal Reinforcement Learning', 'authors': 'Sagalpreet Singh, Rishi Saket, Aravindan Raghuveer', 'link': 'https://arxiv.org/abs/2510.25311', 'abstract': 'Reinforcement Learning algorithms are primarily focused on learning a policy that maximizes expected return. As a result, the learned policy can exploit one or few reward sources. However, in many natural situations, it is desirable to learn a policy that induces a dispersed marginal state distribution over rewarding states, while maximizing the expected return which is typically tied to reaching a goal state. This aspect remains relatively unexplored. Existing techniques based on entropy regularization and intrinsic rewards use stochasticity for encouraging exploration to find an optimal policy which may not necessarily lead to dispersed marginal state distribution over rewarding states. Other RL algorithms which match a target distribution assume the latter to be available apriori. This may be infeasible in large scale systems where enumeration of all states is not possible and a state is determined to be a goal state only upon reaching it. We formalize the problem of maximizing the expected return while uniformly visiting the goal states as Multi Goal RL in which an oracle classifier over the state space determines the goal states. We propose a novel algorithm that learns a high-return policy mixture with marginal state distribution dispersed over the set of goal states. Our algorithm is based on optimizing a custom RL reward which is computed - based on the current policy mixture - at each iteration for a set of sampled trajectories. The latter are used via an offline RL algorithm to update the policy mixture. We prove performance guarantees for our algorithm, showing efficient convergence bounds for optimizing a natural objective which captures the expected return as well as the dispersion of the marginal state distribution over the goal states. We design and perform experiments on synthetic MDPs and standard RL environments to evaluate the effectiveness of our algorithm.', 'abstract_zh': 'å¼ºåŒ–å­¦ä¹ ç®—æ³•ä¸»è¦å…³æ³¨å­¦ä¹ ä¸€ä¸ªæœ€å¤§åŒ–é¢„æœŸå›æŠ¥çš„ç­–ç•¥ã€‚ç»“æœï¼Œå­¦åˆ°çš„ç­–ç•¥å¯èƒ½ä¼šåˆ©ç”¨ä¸€ä¸ªæˆ–å°‘æ•°å‡ ä¸ªå¥–åŠ±æ¥æºã€‚ç„¶è€Œï¼Œåœ¨è®¸å¤šè‡ªç„¶åœºæ™¯ä¸­ï¼Œç†æƒ³çš„æ˜¯å­¦ä¹ ä¸€ä¸ªç­–ç•¥ï¼Œè¯¥ç­–ç•¥åœ¨æœ€å¤§åŒ–é¢„æœŸå›æŠ¥çš„åŒæ—¶è¯±å¯¼ä¸€ä¸ªåœ¨å¥–åŠ±çŠ¶æ€ä¸Šçš„åˆ†æ•£è¾¹ç¼˜çŠ¶æ€åˆ†å¸ƒï¼Œé¢„æœŸå›æŠ¥é€šå¸¸ä¸è¾¾åˆ°ç›®æ ‡çŠ¶æ€ç›¸å…³ã€‚è¿™ä¸€æ–¹é¢å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚åŸºäºç†µæ­£åˆ™åŒ–å’Œå†…åœ¨å¥–åŠ±çš„ç°æœ‰æŠ€æœ¯ä½¿ç”¨éšæœºæ€§æ¥é¼“åŠ±æ¢ç´¢ä»¥æ‰¾åˆ°æœ€ä¼˜ç­–ç•¥ï¼Œä½†è¿™æœªå¿…ä¼šå¯¼è‡´åœ¨å¥–åŠ±çŠ¶æ€ä¸Šçš„åˆ†æ•£è¾¹ç¼˜çŠ¶æ€åˆ†å¸ƒã€‚å…¶ä»–åŒ¹é…ç›®æ ‡åˆ†å¸ƒçš„RLç®—æ³•å‡è®¾ç›®æ ‡åˆ†å¸ƒå¯ä»¥å…ˆéªŒåœ°è·å¾—ï¼Œè¿™åœ¨å¤§è§„æ¨¡ç³»ç»Ÿä¸­å¯èƒ½ä¸å¯è¡Œï¼Œå› ä¸ºåœ¨è¿™äº›ç³»ç»Ÿä¸­ä¸å¯èƒ½æšä¸¾æ‰€æœ‰çŠ¶æ€ï¼Œä¸”çŠ¶æ€ä»…åœ¨åˆ°è¾¾æ—¶æ‰èƒ½ç¡®å®šä¸ºç›®æ ‡çŠ¶æ€ã€‚æˆ‘ä»¬å°†æœ€å¤§åŒ–é¢„æœŸå›æŠ¥çš„åŒæ—¶å‡åŒ€è®¿é—®ç›®æ ‡çŠ¶æ€çš„é—®é¢˜å½¢å¼åŒ–ä¸ºå¤šç›®æ ‡RLï¼Œå…¶ä¸­çŠ¶æ€ç©ºé—´ä¸Šçš„å…ˆéªŒåˆ†ç±»å™¨ç¡®å®šç›®æ ‡çŠ¶æ€ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„ç®—æ³•ï¼Œè¯¥ç®—æ³•å­¦ä¹ ä¸€ä¸ªé«˜å›æŠ¥ç­–ç•¥æ··åˆï¼Œè¾¹ç¼˜çŠ¶æ€åˆ†å¸ƒåˆ†æ•£åœ¨ç›®æ ‡çŠ¶æ€é›†åˆä¸Šã€‚è¯¥ç®—æ³•åŸºäºä¼˜åŒ–ä¸€ä¸ªé‡èº«å®šåˆ¶çš„RLå¥–åŠ±ï¼Œè¯¥å¥–åŠ±åŸºäºå½“å‰ç­–ç•¥æ··åˆåœ¨æ¯æ¬¡è¿­ä»£ä¸­ä¸ºä¸€ç»„é‡‡æ ·çš„è½¨è¿¹è®¡ç®—ã€‚è¿™äº›è½¨è¿¹é€šè¿‡ä¸€ä¸ªç¦»çº¿RLç®—æ³•ç”¨æ¥æ›´æ–°ç­–ç•¥æ··åˆã€‚æˆ‘ä»¬è¯æ˜äº†è¯¥ç®—æ³•çš„æ€§èƒ½ä¿è¯ï¼Œå±•ç¤ºäº†ä¼˜åŒ–è‡ªç„¶ç›®æ ‡çš„é«˜æ•ˆæ”¶æ•›ç•Œï¼Œè¯¥è‡ªç„¶ç›®æ ‡æ•è·äº†é¢„æœŸå›æŠ¥å’Œè¾¹ç¼˜çŠ¶æ€åˆ†å¸ƒåœ¨ç›®æ ‡çŠ¶æ€ä¸Šçš„åˆ†æ•£ã€‚æˆ‘ä»¬è®¾è®¡å¹¶æ‰§è¡Œäº†åœ¨åˆæˆMDPå’Œæ ‡å‡†RLç¯å¢ƒä¸Šçš„å®éªŒï¼Œä»¥è¯„ä¼°æˆ‘ä»¬ç®—æ³•çš„æœ‰æ•ˆæ€§ã€‚', 'title_zh': 'å¤šç›®æ ‡å¼ºåŒ–å­¦ä¹ ä¸­çš„å¯†é›†ä¸”å¤šæ ·çš„ç›®æ ‡è¦†ç›–'}
{'arxiv_id': 'arXiv:2510.25268', 'title': 'SynHLMA:Synthesizing Hand Language Manipulation for Articulated Object with Discrete Human Object Interaction Representation', 'authors': 'Wang zhi, Yuyan Liu, Liu Liu, Li Zhang, Ruixuan Lu, Dan Guo', 'link': 'https://arxiv.org/abs/2510.25268', 'abstract': 'Generating hand grasps with language instructions is a widely studied topic that benefits from embodied AI and VR/AR applications. While transferring into hand articulatied object interaction (HAOI), the hand grasps synthesis requires not only object functionality but also long-term manipulation sequence along the object deformation. This paper proposes a novel HAOI sequence generation framework SynHLMA, to synthesize hand language manipulation for articulated objects. Given a complete point cloud of an articulated object, we utilize a discrete HAOI representation to model each hand object interaction frame. Along with the natural language embeddings, the representations are trained by an HAOI manipulation language model to align the grasping process with its language description in a shared representation space. A joint-aware loss is employed to ensure hand grasps follow the dynamic variations of articulated object joints. In this way, our SynHLMA achieves three typical hand manipulation tasks for articulated objects of HAOI generation, HAOI prediction and HAOI interpolation. We evaluate SynHLMA on our built HAOI-lang dataset and experimental results demonstrate the superior hand grasp sequence generation performance comparing with state-of-the-art. We also show a robotics grasp application that enables dexterous grasps execution from imitation learning using the manipulation sequence provided by our SynHLMA. Our codes and datasets will be made publicly available.', 'abstract_zh': 'åŸºäºè¯­è¨€æŒ‡ä»¤ç”Ÿæˆæ‰‹éƒ¨æŠ“å–çš„articulatedå¯¹è±¡æ‰‹éƒ¨æ“ä½œåºåˆ—ç”Ÿæˆæ¡†æ¶', 'title_zh': 'SynHLMA: åŸºäºç¦»æ•£äººç±»ç‰©ä½“äº¤äº’è¡¨ç¤ºçš„æ‰‹éƒ¨åŠ¨ä½œåˆæˆä¸ articulated å¯¹è±¡ manipulation'}
{'arxiv_id': 'arXiv:2510.25262', 'title': 'IBNorm: Information-Bottleneck Inspired Normalization for Representation Learning', 'authors': 'Xiandong Zou, Pan Zhou', 'link': 'https://arxiv.org/abs/2510.25262', 'abstract': 'Normalization is fundamental to deep learning, but existing approaches such as BatchNorm, LayerNorm, and RMSNorm are variance-centric by enforcing zero mean and unit variance, stabilizing training without controlling how representations capture task-relevant information. We propose IB-Inspired Normalization (IBNorm), a simple yet powerful family of methods grounded in the Information Bottleneck principle. IBNorm introduces bounded compression operations that encourage embeddings to preserve predictive information while suppressing nuisance variability, yielding more informative representations while retaining the stability and compatibility of standard normalization. Theoretically, we prove that IBNorm achieves a higher IB value and tighter generalization bounds than variance-centric methods. Empirically, IBNorm consistently outperforms BatchNorm, LayerNorm, and RMSNorm across large-scale language models (LLaMA, GPT-2) and vision models (ResNet, ViT), with mutual information analysis confirming superior information bottleneck behavior. Code will be released publicly.', 'abstract_zh': 'åŸºäºä¿¡æ¯ç“¶é¢ˆçš„å½’ä¸€åŒ–æ–¹æ³•ï¼ˆIBNormï¼‰ï¼šä¸€ç§ç®€å•è€Œå¼ºå¤§çš„å½’ä¸€åŒ–å®¶æ—', 'title_zh': 'ä¿¡æ¯ç“¶é¢ˆå¯å‘çš„å½’ä¸€åŒ–æ–¹æ³•ï¼šè¡¨ç¤ºå­¦ä¹ ä¸­çš„IBNorm'}
{'arxiv_id': 'arXiv:2510.25259', 'title': 'TV-Rec: Time-Variant Convolutional Filter for Sequential Recommendation', 'authors': 'Yehjin Shin, Jeongwhan Choi, Seojin Kim, Noseong Park', 'link': 'https://arxiv.org/abs/2510.25259', 'abstract': 'Recently, convolutional filters have been increasingly adopted in sequential recommendation for their ability to capture local sequential patterns. However, most of these models complement convolutional filters with self-attention. This is because convolutional filters alone, generally fixed filters, struggle to capture global interactions necessary for accurate recommendation. We propose Time-Variant Convolutional Filters for Sequential Recommendation (TV-Rec), a model inspired by graph signal processing, where time-variant graph filters capture position-dependent temporal variations in user sequences. By replacing both fixed kernels and self-attention with time-variant filters, TV-Rec achieves higher expressive power and better captures complex interaction patterns in user behavior. This design not only eliminates the need for self-attention but also reduces computation while accelerating inference. Extensive experiments on six public benchmarks show that TV-Rec outperforms state-of-the-art baselines by an average of 7.49%.', 'abstract_zh': 'æ—¶é—´å˜åŒ–å·ç§¯æ»¤æ³¢å™¨ç”¨äºåºåˆ—æ¨èï¼ˆTV-Recï¼‰', 'title_zh': 'TV-Rec: æ—¶é—´å˜å¼‚å·ç§¯æ»¤æ³¢å™¨ç”¨äºåºåˆ—æ¨è'}
{'arxiv_id': 'arXiv:2510.25254', 'title': 'Scaling Up Bayesian DAG Sampling', 'authors': 'Daniele Nikzad, Alexander Zhilkin, Juha Harviainen, Jack Kuipers, Giusi Moffa, Mikko Koivisto', 'link': 'https://arxiv.org/abs/2510.25254', 'abstract': 'Bayesian inference of Bayesian network structures is often performed by sampling directed acyclic graphs along an appropriately constructed Markov chain. We present two techniques to improve sampling. First, we give an efficient implementation of basic moves, which add, delete, or reverse a single arc. Second, we expedite summing over parent sets, an expensive task required for more sophisticated moves: we devise a preprocessing method to prune possible parent sets so as to approximately preserve the sums. Our empirical study shows that our techniques can yield substantial efficiency gains compared to previous methods.', 'abstract_zh': 'è´å¶æ–¯ç½‘ç»œç»“æ„çš„è´å¶æ–¯æ¨æ–­é€šå¸¸é€šè¿‡åœ¨é€‚å½“æ„å»ºçš„é©¬å°”å¯å¤«é“¾ä¸ŠæŠ½æ ·æœ‰å‘æ— ç¯å›¾æ¥å®ç°ã€‚æˆ‘ä»¬æå‡ºäº†ä¸¤ç§æ”¹è¿›æŠ½æ ·çš„æŠ€æœ¯ï¼šé¦–å…ˆï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ç§åŸºæœ¬ç§»åŠ¨çš„æœ‰æ•ˆå®ç°ï¼Œè¿™äº›ç§»åŠ¨å¯ä»¥æ·»åŠ ã€åˆ é™¤æˆ–åå‘ä¸€æ¡å¼§ï¼›å…¶æ¬¡ï¼Œæˆ‘ä»¬åŠ å¿«äº†å¯¹çˆ¶èŠ‚ç‚¹é›†æ±‚å’Œçš„è¿‡ç¨‹ï¼Œè¿™æ˜¯æ›´å¤æ‚çš„ç§»åŠ¨æ‰€å¿…éœ€çš„æ˜‚è´µä»»åŠ¡ï¼šæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§é¢„å¤„ç†æ–¹æ³•æ¥ä¿®å‰ªå¯èƒ½çš„çˆ¶èŠ‚ç‚¹é›†ï¼Œä»è€Œå¤§çº¦ä¿æŒæ±‚å’Œçš„ä¸å˜æ€§ã€‚æˆ‘ä»¬çš„å®è¯ç ”ç©¶æ˜¾ç¤ºï¼Œä¸ä¹‹å‰çš„æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æŠ€æœ¯å¯ä»¥å®ç°æ˜¾è‘—çš„æ•ˆç‡æå‡ã€‚', 'title_zh': 'æ‰©å¤§è§„æ¨¡çš„è´å¶æ–¯DAGé‡‡æ ·'}
{'arxiv_id': 'arXiv:2510.25241', 'title': 'One-shot Humanoid Whole-body Motion Learning', 'authors': 'Hao Huang, Geeta Chandra Raju Bethala, Shuaihang Yuan, Congcong Wen, Anthony Tzes, Yi Fang', 'link': 'https://arxiv.org/abs/2510.25241', 'abstract': 'Whole-body humanoid motion represents a cornerstone challenge in robotics, integrating balance, coordination, and adaptability to enable human-like behaviors. However, existing methods typically require multiple training samples per motion category, rendering the collection of high-quality human motion datasets both labor-intensive and costly. To address this, we propose a novel approach that trains effective humanoid motion policies using only a single non-walking target motion sample alongside readily available walking motions. The core idea lies in leveraging order-preserving optimal transport to compute distances between walking and non-walking sequences, followed by interpolation along geodesics to generate new intermediate pose skeletons, which are then optimized for collision-free configurations and retargeted to the humanoid before integration into a simulated environment for policy training via reinforcement learning. Experimental evaluations on the CMU MoCap dataset demonstrate that our method consistently outperforms baselines, achieving superior performance across metrics. Code will be released upon acceptance.', 'abstract_zh': 'å…¨èº«äººå½¢æœºå™¨äººè¿åŠ¨ä»£è¡¨äº†æœºå™¨äººé¢†åŸŸçš„ä¸€ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼Œèåˆäº†å¹³è¡¡ã€åè°ƒå’Œé€‚åº”æ€§ï¼Œä»¥å®ç°ç±»äººè¡Œä¸ºã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ–¹æ³•é€šå¸¸éœ€è¦æ¯ä¸ªè¿åŠ¨ç±»åˆ«å¤šä¸ªè®­ç»ƒæ ·æœ¬ï¼Œä½¿å¾—é«˜è´¨é‡äººä½“è¿åŠ¨æ•°æ®é›†çš„æ”¶é›†æ—¢è€—è´¹äººåŠ›åˆæˆæœ¬é«˜æ˜‚ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œä»…ä½¿ç”¨ä¸€ä¸ªéè¡Œèµ°ç›®æ ‡è¿åŠ¨æ ·æœ¬å’Œç°æˆçš„è¡Œèµ°è¿åŠ¨æ ·æœ¬è®­ç»ƒæœ‰æ•ˆçš„äººå½¢æœºå™¨äººè¿åŠ¨ç­–ç•¥ã€‚æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨ä¿åºæœ€ä¼˜ä¼ è¾“è®¡ç®—è¡Œèµ°å’Œéè¡Œèµ°åºåˆ—ä¹‹é—´çš„è·ç¦»ï¼Œéšåæ²¿ç€æµ‹åœ°çº¿è¿›è¡Œæ’å€¼ç”Ÿæˆæ–°çš„ä¸­é—´å§¿æ€éª¨æ¶ï¼Œå†ä¼˜åŒ–ä¸ºæ— ç¢°æ’é…ç½®å¹¶é‡æ–°ç›®æ ‡åŒ–åˆ°äººå½¢æœºå™¨äººï¼Œæœ€ç»ˆåœ¨ä»¿çœŸç¯å¢ƒä¸­é€šè¿‡å¼ºåŒ–å­¦ä¹ è¿›è¡Œç­–ç•¥è®­ç»ƒã€‚åœ¨CMU MoCapæ•°æ®é›†ä¸Šçš„å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šå‡è¶…è¿‡äº†åŸºçº¿æ–¹æ³•ï¼Œè¡¨ç°æ›´ä¼˜ã€‚ä»£ç å°†åœ¨æ¥å—åå‘å¸ƒã€‚', 'title_zh': 'å•æ¬¡å­¦ä¹ äººä½“å…¨èº«åŠ¨åŠ›å­¦'}
{'arxiv_id': 'arXiv:2510.25234', 'title': 'Learning Disentangled Speech- and Expression-Driven Blendshapes for 3D Talking Face Animation', 'authors': 'Yuxiang Mao, Zhijie Zhang, Zhiheng Zhang, Jiawei Liu, Chen Zeng, Shihong Xia', 'link': 'https://arxiv.org/abs/2510.25234', 'abstract': 'Expressions are fundamental to conveying human emotions. With the rapid advancement of AI-generated content (AIGC), realistic and expressive 3D facial animation has become increasingly crucial. Despite recent progress in speech-driven lip-sync for talking-face animation, generating emotionally expressive talking faces remains underexplored. A major obstacle is the scarcity of real emotional 3D talking-face datasets due to the high cost of data capture. To address this, we model facial animation driven by both speech and emotion as a linear additive problem. Leveraging a 3D talking-face dataset with neutral expressions (VOCAset) and a dataset of 3D expression sequences (Florence4D), we jointly learn a set of blendshapes driven by speech and emotion. We introduce a sparsity constraint loss to encourage disentanglement between the two types of blendshapes while allowing the model to capture inherent secondary cross-domain deformations present in the training data. The learned blendshapes can be further mapped to the expression and jaw pose parameters of the FLAME model, enabling the animation of 3D Gaussian avatars. Qualitative and quantitative experiments demonstrate that our method naturally generates talking faces with specified expressions while maintaining accurate lip synchronization. Perceptual studies further show that our approach achieves superior emotional expressivity compared to existing methods, without compromising lip-sync quality.', 'abstract_zh': 'åŸºäºè¯­éŸ³å’Œæƒ…ç»ªçš„3Dé¢éƒ¨åŠ¨ç”»è¡¨è¾¾å»ºæ¨¡', 'title_zh': 'å­¦ä¹ è§£è€¦çš„è¯­éŸ³é©±åŠ¨å’Œè¡¨æƒ…é©±åŠ¨æ··åˆå½¢çŠ¶ä»¥å®ç°3Dè¯´è¯äººè„¸åŠ¨ç”»'}
{'arxiv_id': 'arXiv:2510.25228', 'title': 'Studies for : A Human-AI Co-Creative Sound Artwork Using a Real-time Multi-channel Sound Generation Model', 'authors': 'Chihiro Nagashima, Akira Takahashi, Zhi Zhong, Shusuke Takahashi, Yuki Mitsufuji', 'link': 'https://arxiv.org/abs/2510.25228', 'abstract': 'This paper explores the integration of AI technologies into the artistic workflow through the creation of Studies for, a generative sound installation developed in collaboration with sound artist Evala (this https URL). The installation employs SpecMaskGIT, a lightweight yet high-quality sound generation AI model, to generate and playback eight-channel sound in real-time, creating an immersive auditory experience over the course of a three-month exhibition. The work is grounded in the concept of a "new form of archive," which aims to preserve the artistic style of an artist while expanding beyond artists\' past artworks by continued generation of new sound elements. This speculative approach to archival preservation is facilitated by training the AI model on a dataset consisting of over 200 hours of Evala\'s past sound artworks.\nBy addressing key requirements in the co-creation of art using AI, this study highlights the value of the following aspects: (1) the necessity of integrating artist feedback, (2) datasets derived from an artist\'s past works, and (3) ensuring the inclusion of unexpected, novel outputs. In Studies for, the model was designed to reflect the artist\'s artistic identity while generating new, previously unheard sounds, making it a fitting realization of the concept of "a new form of archive." We propose a Human-AI co-creation framework for effectively incorporating sound generation AI models into the sound art creation process and suggest new possibilities for creating and archiving sound art that extend an artist\'s work beyond their physical existence. Demo page: this https URL', 'abstract_zh': 'æœ¬æ–‡æ¢è®¨äº†å°†AIæŠ€æœ¯èå…¥è‰ºæœ¯å·¥ä½œæµç¨‹ä¸­ï¼Œé€šè¿‡ä¸å£°éŸ³è‰ºæœ¯å®¶Evalaåˆä½œå¼€å‘çš„ç”Ÿæˆå£°éŸ³è£…ç½®Studies forè¿›è¡Œäº†æ¢ç´¢ã€‚è¯¥è£…ç½®ä½¿ç”¨SpecMaskGITï¼Œä¸€ç§è½»é‡çº§ä½†é«˜è´¨é‡çš„å£°éŸ³ç”ŸæˆAIæ¨¡å‹ï¼Œåœ¨ä¸‰ä¸ªæœˆçš„å±•è§ˆæœŸé—´å®æ—¶ç”Ÿæˆå¹¶æ’­æ”¾å…«é€šé“å£°éŸ³ï¼Œåˆ›é€ å‡ºæ²‰æµ¸å¼çš„å¬è§‰ä½“éªŒã€‚è¯¥ä½œå“åŸºäºâ€œæ–°å½¢å¼æ¡£æ¡ˆâ€çš„æ¦‚å¿µï¼Œæ—¨åœ¨ä¿å­˜è‰ºæœ¯å®¶çš„è‰ºæœ¯é£æ ¼ï¼Œå¹¶é€šè¿‡æŒç»­ç”Ÿæˆæ–°çš„å£°éŸ³å…ƒç´ è¶…è¶Šè‰ºæœ¯å®¶è¿‡å»çš„ä½œå“ã€‚å€ŸåŠ©å¯¹è‰ºæœ¯å®¶è¿‡å»ä½œå“æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œè¿™ç§æ¡£æ¡ˆä¿å­˜çš„è®¾æƒ³å¾—ä»¥å®ç°ã€‚\n\næœ¬æ–‡é€šè¿‡è§£å†³è‰ºæœ¯å…±åˆ›ä¸­çš„å…³é”®è¦æ±‚ï¼Œçªæ˜¾äº†ä»¥ä¸‹æ–¹é¢çš„ä»·å€¼ï¼šï¼ˆ1ï¼‰é›†æˆè‰ºæœ¯å®¶åé¦ˆçš„å¿…è¦æ€§ï¼Œï¼ˆ2ï¼‰æ¥è‡ªè‰ºæœ¯å®¶è¿‡å»ä½œå“çš„æ•°æ®é›†ï¼Œä»¥åŠï¼ˆ3ï¼‰ç¡®ä¿åŒ…æ‹¬æ„å¤–å’Œæ–°é¢–çš„è¾“å‡ºã€‚åœ¨Studies forä¸­ï¼Œæ¨¡å‹è¢«è®¾è®¡ç”¨äºåæ˜ è‰ºæœ¯å®¶çš„è‰ºæœ¯èº«ä»½çš„åŒæ—¶ç”Ÿæˆæ–°çš„æœªå¬è¿‡çš„å£°éŸ³ï¼Œä½¿å…¶æˆä¸ºä¸€ä¸ªâ€œæ–°å½¢å¼æ¡£æ¡ˆâ€çš„æ°å½“å®ç°ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§äººæœºå…±åˆ›æ¡†æ¶ï¼Œä»¥æœ‰æ•ˆå°†å£°éŸ³ç”ŸæˆAIæ¨¡å‹èå…¥å£°éŸ³è‰ºæœ¯åˆ›ä½œè¿‡ç¨‹ï¼Œå¹¶æå‡ºäº†è¶…è¶Šè‰ºæœ¯å®¶ç‰©ç†å­˜åœ¨çš„åˆ›ä½œå’Œå½’æ¡£å£°éŸ³è‰ºæœ¯çš„æ–°å¯èƒ½æ€§ã€‚\nStudies forï¼šé€šè¿‡ä¸å£°éŸ³è‰ºæœ¯å®¶Evalaåˆä½œå¼€å‘çš„ç”Ÿæˆå£°éŸ³è£…ç½®', 'title_zh': 'åŸºäºå®æ—¶å¤šé€šé“å£°éŸ³ç”Ÿæˆæ¨¡å‹çš„äººæœºå…±åˆ›å£°éŸ³è‰ºæœ¯ç ”ç©¶'}
{'arxiv_id': 'arXiv:2510.25226', 'title': 'Cost-Sensitive Unbiased Risk Estimation for Multi-Class Positive-Unlabeled Learning', 'authors': 'Miao Zhang, Junpeng Li, Changchun Hua, Yana Yang', 'link': 'https://arxiv.org/abs/2510.25226', 'abstract': 'Positive--Unlabeled (PU) learning considers settings in which only positive and unlabeled data are available, while negatives are missing or left unlabeled. This situation is common in real applications where annotating reliable negatives is difficult or costly. Despite substantial progress in PU learning, the multi-class case (MPU) remains challenging: many existing approaches do not ensure \\emph{unbiased risk estimation}, which limits performance and stability. We propose a cost-sensitive multi-class PU method based on \\emph{adaptive loss weighting}. Within the empirical risk minimization framework, we assign distinct, data-dependent weights to the positive and \\emph{inferred-negative} (from the unlabeled mixture) loss components so that the resulting empirical objective is an unbiased estimator of the target risk. We formalize the MPU data-generating process and establish a generalization error bound for the proposed estimator. Extensive experiments on \\textbf{eight} public datasets, spanning varying class priors and numbers of classes, show consistent gains over strong baselines in both accuracy and stability.', 'abstract_zh': 'Positive-Unlabeled (PU) å­¦ä¹ è€ƒè™‘åªæœ‰æ­£ä¾‹å’Œæœªæ ‡è®°æ•°æ®è€Œç¼ºä¹å¯é è´Ÿä¾‹æ ‡æ³¨çš„æƒ…å†µã€‚è¿™ç§æƒ…å½¢åœ¨å®é™…åº”ç”¨ä¸­æ™®éå­˜åœ¨ï¼Œæ­£ç¡®æ ‡æ³¨è´Ÿä¾‹éš¾åº¦å¤§æˆ–æˆæœ¬é«˜ã€‚å°½ç®¡åœ¨ PU å­¦ä¹ æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å¤šç±»æƒ…å½¢ï¼ˆMPUï¼‰ä»å…·æŒ‘æˆ˜æ€§ï¼šè®¸å¤šç°æœ‰æ–¹æ³•æœªèƒ½ç¡®ä¿æ— åé£é™©ä¼°è®¡ï¼Œè¿™é™åˆ¶äº†æ€§èƒ½å’Œç¨³å®šæ€§ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºè‡ªé€‚åº”æŸå¤±åŠ æƒçš„ä»£ä»·æ•æ„Ÿå¤šç±» PU æ–¹æ³•ã€‚åœ¨ç»éªŒé£é™©æœ€å°åŒ–æ¡†æ¶ä¸‹ï¼Œæˆ‘ä»¬ä¸ºæ­£ä¾‹å’Œä»æœªæ ‡è®°æ··åˆæ•°æ®ä¸­æ¨æ–­å‡ºçš„è´Ÿä¾‹æŸå¤±ç»„ä»¶åˆ†é…ä¸åŒçš„ã€æ•°æ®ä¾èµ–çš„æƒé‡ï¼Œä»è€Œä½¿æœ€ç»ˆçš„ç»éªŒç›®æ ‡æˆä¸ºç›®æ ‡é£é™©çš„æ— åä¼°è®¡å™¨ã€‚æˆ‘ä»¬å½¢å¼åŒ–äº† MPU çš„æ•°æ®ç”Ÿæˆè¿‡ç¨‹ï¼Œå¹¶ä¸ºæ‰€æä¼°è®¡å™¨å»ºç«‹äº†æ³›åŒ–è¯¯å·®ç•Œã€‚åœ¨å…«ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒæ¶µç›–äº†ä¸åŒçš„å…ˆéªŒæ¦‚ç‡å’Œç±»æ•°ï¼Œç»“æœæ˜¾ç¤ºä¸å¼ºåŸºçº¿ç›¸æ¯”åœ¨å‡†ç¡®æ€§å’Œç¨³å®šæ€§ä¸Šå‡è¡¨ç°å‡ºä¸€è‡´çš„æ”¹è¿›ã€‚', 'title_zh': 'é’ˆå¯¹å¤šç±»åˆ«æ­£æ— æ ‡ç­¾å­¦ä¹ çš„æˆæœ¬æ•æ„Ÿæ— åé£é™©ä¼°è®¡'}
{'arxiv_id': 'arXiv:2510.25220', 'title': 'GReF: A Unified Generative Framework for Efficient Reranking via Ordered Multi-token Prediction', 'authors': 'Zhijie Lin, Zhuofeng Li, Chenglei Dai, Wentian Bao, Shuai Lin, Enyun Yu, Haoxiang Zhang, Liang Zhao', 'link': 'https://arxiv.org/abs/2510.25220', 'abstract': 'In a multi-stage recommendation system, reranking plays a crucial role in modeling intra-list correlations among items. A key challenge lies in exploring optimal sequences within the combinatorial space of permutations. Recent research follows a two-stage (generator-evaluator) paradigm, where a generator produces multiple feasible sequences, and an evaluator selects the best one. In practice, the generator is typically implemented as an autoregressive model. However, these two-stage methods face two main challenges. First, the separation of the generator and evaluator hinders end-to-end training. Second, autoregressive generators suffer from inference efficiency. In this work, we propose a Unified Generative Efficient Reranking Framework (GReF) to address the two primary challenges. Specifically, we introduce Gen-Reranker, an autoregressive generator featuring a bidirectional encoder and a dynamic autoregressive decoder to generate causal reranking sequences. Subsequently, we pre-train Gen-Reranker on the item exposure order for high-quality parameter initialization. To eliminate the need for the evaluator while integrating sequence-level evaluation during training for end-to-end optimization, we propose post-training the model through Rerank-DPO. Moreover, for efficient autoregressive inference, we introduce ordered multi-token prediction (OMTP), which trains Gen-Reranker to simultaneously generate multiple future items while preserving their order, ensuring practical deployment in real-time recommender systems. Extensive offline experiments demonstrate that GReF outperforms state-of-the-art reranking methods while achieving latency that is nearly comparable to non-autoregressive models. Additionally, GReF has also been deployed in a real-world video app Kuaishou with over 300 million daily active users, significantly improving online recommendation quality.', 'abstract_zh': 'ç»Ÿä¸€ç”Ÿæˆé«˜æ•ˆé‡æ’æ¡†æ¶ï¼ˆGReFï¼‰ï¼šè§£å†³é‡æ’ä¸­çš„ä¸»è¦æŒ‘æˆ˜', 'title_zh': 'GReFï¼šä¸€ç§åŸºäºæœ‰åºå¤šä»¤ç‰Œé¢„æµ‹çš„ç»Ÿä¸€ç”Ÿæˆæ¡†æ¶ä»¥å®ç°é«˜æ•ˆé‡æ’åº'}
{'arxiv_id': 'arXiv:2510.25218', 'title': "Human Resilience in the AI Era -- What Machines Can't Replace", 'authors': 'Shaoshan Liu, Anina Schwarzenbach, Yiyu Shi', 'link': 'https://arxiv.org/abs/2510.25218', 'abstract': 'AI is displacing tasks, mediating high-stakes decisions, and flooding communication with synthetic content, unsettling work, identity, and social trust. We argue that the decisive human countermeasure is resilience. We define resilience across three layers: psychological, including emotion regulation, meaning-making, cognitive flexibility; social, including trust, social capital, coordinated response; organizational, including psychological safety, feedback mechanisms, and graceful degradation. We synthesize early evidence that these capacities buffer individual strain, reduce burnout through social support, and lower silent failure in AI-mediated workflows through team norms and risk-responsive governance. We also show that resilience can be cultivated through training that complements rather than substitutes for structural safeguards. By reframing the AI debate around actionable human resilience, this article offers policymakers, educators, and operators a practical lens to preserve human agency and steer responsible adoption.', 'abstract_zh': 'AIæ­£åœ¨å–ä»£ä»»åŠ¡ã€è°ƒè§£é«˜é£é™©å†³ç­–å¹¶ flooding é€šä¿¡å†…å®¹ï¼Œæ‰°ä¹±å·¥ä½œã€èº«ä»½å’Œç¤¾ä¼šä¿¡ä»»ã€‚æˆ‘ä»¬è®¤ä¸ºå†³å®šæ€§çš„åº”å¯¹æªæ–½æ˜¯éŸ§æ€§ã€‚æˆ‘ä»¬ä»ä¸‰ä¸ªå±‚é¢å®šä¹‰éŸ§æ€§ï¼šå¿ƒç†å±‚é¢ï¼ŒåŒ…æ‹¬æƒ…ç»ªè°ƒèŠ‚ã€æ„ä¹‰æ„å»ºã€è®¤çŸ¥çµæ´»æ€§ï¼›ç¤¾ä¼šå±‚é¢ï¼ŒåŒ…æ‹¬ä¿¡ä»»ã€ç¤¾ä¼šèµ„æœ¬ã€åè°ƒå“åº”ï¼›ç»„ç»‡å±‚é¢ï¼ŒåŒ…æ‹¬å¿ƒç†å®‰å…¨ã€åé¦ˆæœºåˆ¶å’Œä¼˜é›…é™çº§ã€‚æˆ‘ä»¬ç»¼åˆäº†æ—©æœŸè¯æ®ï¼Œè¿™äº›èƒ½åŠ›å¯ä»¥ç¼“å†²ä¸ªä½“å‹åŠ›ã€é€šè¿‡ç¤¾ä¼šæ”¯æŒå‡å°‘å€¦æ€ ï¼Œå¹¶é€šè¿‡å›¢é˜Ÿè§„èŒƒå’Œé£é™©å“åº”æ²»ç†é™ä½AIè°ƒè§£å·¥ä½œæµç¨‹ä¸­çš„éšå½¢å¤±è´¥ã€‚æˆ‘ä»¬è¿˜å±•ç¤ºäº†å¯ä»¥é€šè¿‡è¡¥å……è€Œéæ›¿ä»£ç»“æ„æ€§ä¿æŠ¤æªæ–½æ¥åŸ¹å…»éŸ§æ€§ã€‚é€šè¿‡å°†AIè¾©è®ºé‡æ–°æ¡†å®šä¸ºå¯æ“ä½œçš„ä¸ªäººéŸ§æ€§ï¼Œæœ¬æ–‡ä¸ºæ”¿ç­–åˆ¶å®šè€…ã€æ•™è‚²è€…å’Œè¿è¥å•†æä¾›äº†ä¸€ä¸ªå®ç”¨çš„è§†è§’ï¼Œä»¥ä¿å­˜äººç±»è‡ªä¸»æƒå¹¶å¼•å¯¼è´Ÿè´£ä»»çš„é‡‡ç”¨ã€‚', 'title_zh': 'AIæ—¶ä»£çš„äººç±»éŸ§æ€§â€”â€”æœºå™¨æ— æ³•æ›¿ä»£çš„å†…å®¹'}
{'arxiv_id': 'arXiv:2510.25181', 'title': 'Fed-PELAD: Communication-Efficient Federated Learning for Massive MIMO CSI Feedback with Personalized Encoders and a LoRA-Adapted Shared Decoder', 'authors': 'Yixiang Zhou, Tong Wu, Meixia Tao, Jianhua Mo', 'link': 'https://arxiv.org/abs/2510.25181', 'abstract': 'This paper addresses the critical challenges of communication overhead, data heterogeneity, and privacy in deep learning for channel state information (CSI) feedback in massive MIMO systems. To this end, we propose Fed-PELAD, a novel federated learning framework that incorporates personalized encoders and a LoRA-adapted shared decoder. Specifically, personalized encoders are trained locally on each user equipment (UE) to capture device-specific channel characteristics, while a shared decoder is updated globally via the coordination of the base station (BS) by using Low-Rank Adaptation (LoRA). This design ensures that only compact LoRA adapter parameters instead of full model updates are transmitted for aggregation. To further enhance convergence stability, we introduce an alternating freezing strategy with calibrated learning-rate ratio during LoRA aggregation. Extensive simulations on 3GPP-standard channel models demonstrate that Fed-PELAD requires only 42.97\\% of the uplink communication cost compared to conventional methods while achieving a performance gain of 1.2 dB in CSI feedback accuracy under heterogeneous conditions.', 'abstract_zh': 'Fed-PELADï¼šä¸€ç§ç”¨äºå¤§è§„æ¨¡MIMOç³»ç»Ÿä¿¡é“çŠ¶æ€ä¿¡æ¯åé¦ˆçš„ä¸ªæ€§åŒ– Federated å­¦ä¹ æ¡†æ¶', 'title_zh': 'Fed-PELAD: åŸºäºä¸ªæ€§åŒ–ç¼–ç å™¨å’ŒLoRA-é€‚åº”å…±äº«è§£ç å™¨çš„é«˜æ•ˆå¤§è§„æ¨¡MIMO CSIåé¦ˆè”é‚¦å­¦ä¹ '}
{'arxiv_id': 'arXiv:2510.25178', 'title': 'SFMS-ALR: Script-First Multilingual Speech Synthesis with Adaptive Locale Resolution', 'authors': 'Dharma Teja Donepudi', 'link': 'https://arxiv.org/abs/2510.25178', 'abstract': 'Intra-sentence multilingual speech synthesis (code-switching TTS) remains a major challenge due to abrupt language shifts, varied scripts, and mismatched prosody between languages. Conventional TTS systems are typically monolingual and fail to produce natural, intelligible speech in mixed-language contexts. We introduce Script-First Multilingual Synthesis with Adaptive Locale Resolution (SFMS-ALR), an engine-agnostic framework for fluent, real-time code-switched speech generation. SFMS-ALR segments input text by Unicode script, applies adaptive language identification to determine each segment\'s language and locale, and normalizes prosody using sentiment-aware adjustments to preserve expressive continuity across languages. The algorithm generates a unified SSML representation with appropriate "lang" or "voice" spans and synthesizes the utterance in a single TTS request. Unlike end-to-end multilingual models, SFMS-ALR requires no retraining and integrates seamlessly with existing voices from Google, Apple, Amazon, and other providers. Comparative analysis with data-driven pipelines such as Unicom and Mask LID demonstrates SFMS-ALR\'s flexibility, interpretability, and immediate deployability. The framework establishes a modular baseline for high-quality, engine-independent multilingual TTS and outlines evaluation strategies for intelligibility, naturalness, and user preference.', 'abstract_zh': 'å¥å†…å¤šè¯­è¨€è¯­éŸ³åˆæˆï¼ˆä»£ç åˆ‡æ¢TTSï¼‰ç”±äºè¯­è¨€çªå˜ã€å¤šæ ·çš„ä¹¦å†™ç³»ç»Ÿä»¥åŠè¯­è¨€ä¹‹é—´éŸµå¾‹çš„ä¸åŒ¹é…ï¼Œä»ç„¶æ˜¯ä¸€ä¸ªä¸»è¦æŒ‘æˆ˜ã€‚ä¼ ç»ŸTTSç³»ç»Ÿé€šå¸¸æ˜¯å•è¯­è¨€çš„ï¼Œåœ¨æ··åˆè¯­è¨€ç¯å¢ƒä¸­æ— æ³•äº§ç”Ÿè‡ªç„¶å¯æ‡‚çš„è¯­éŸ³ã€‚æˆ‘ä»¬å¼•å…¥äº†åŸºäºè„šæœ¬ä¼˜å…ˆçš„é€‚åº”æ€§åœ°åŸŸè§£æå¤šè¯­è¨€åˆæˆï¼ˆSFMS-ALRï¼‰å¼•æ“ï¼Œè¿™æ˜¯ä¸€ç§é€‚ç”¨äºæµç•…å®æ—¶ä»£ç åˆ‡æ¢è¯­éŸ³ç”Ÿæˆçš„æ¡†æ¶ã€‚SFMS-ALRé€šè¿‡ Unicode è„šæœ¬å¯¹è¾“å…¥æ–‡æœ¬è¿›è¡Œåˆ†æ®µï¼Œåº”ç”¨é€‚åº”æ€§è¯­è¨€è¯†åˆ«æ¥ç¡®å®šæ¯ä¸ªæ®µè½çš„è¯­è¨€å’Œåœ°åŸŸï¼Œå¹¶é€šè¿‡å¯¹æƒ…æ„Ÿæ„è¯†çš„è°ƒæ•´æ¥æ ‡å‡†åŒ–éŸµå¾‹ï¼Œä»¥åœ¨è¯­è¨€ä¹‹é—´ä¿æŒè¡¨è¾¾çš„è¿ç»­æ€§ã€‚è¯¥ç®—æ³•ç”Ÿæˆç»Ÿä¸€çš„ SSML è¡¨ç¤ºï¼Œå¹¶åœ¨ä¸€æ¬¡TTSè¯·æ±‚ä¸­åˆæˆè¯­éŸ³ã€‚ä¸ç«¯åˆ°ç«¯å¤šè¯­è¨€æ¨¡å‹ä¸åŒï¼ŒSFMS-ALR æ— éœ€é‡æ–°è®­ç»ƒï¼Œå¹¶å¯æ— ç¼é›†æˆæ¥è‡ª Googleã€Appleã€Amazon ç­‰æä¾›å•†çš„ç°æœ‰è¯­éŸ³ã€‚ä¸åŸºäºæ•°æ®çš„ç®¡é“ï¼ˆå¦‚ Unicom å’Œ Mask LIDï¼‰çš„æ¯”è¾ƒåˆ†ææ˜¾ç¤ºï¼ŒSFMS-ALR å…·æœ‰çµæ´»æ€§ã€å¯è§£é‡Šæ€§å’Œå³ç”¨æ€§ã€‚è¯¥æ¡†æ¶ä¸ºé«˜è´¨é‡ã€å¼•æ“æ— å…³çš„å¤šè¯­è¨€ TTS è®¾ç«‹äº†ä¸€ä¸ªæ¨¡å—åŒ–çš„åŸºçº¿ï¼Œå¹¶æ¦‚è¿°äº†è¯„ä¼°å¯æ‡‚åº¦ã€è‡ªç„¶åº¦å’Œç”¨æˆ·åå¥½çš„ç­–ç•¥ã€‚', 'title_zh': 'SFMS-ALR: è„šæœ¬ä¼˜å…ˆå¤šè¯­è¨€è¯­éŸ³åˆæˆä¸è‡ªé€‚åº”åŒºåŸŸè§£æ'}
{'arxiv_id': 'arXiv:2510.25164', 'title': 'Transformers in Medicine: Improving Vision-Language Alignment for Medical Image Captioning', 'authors': 'Yogesh Thakku Suresh, Vishwajeet Shivaji Hogale, Luca-Alexandru Zamfira, Anandavardhana Hegde', 'link': 'https://arxiv.org/abs/2510.25164', 'abstract': 'We present a transformer-based multimodal framework for generating clinically relevant captions for MRI scans. Our system combines a DEiT-Small vision transformer as an image encoder, MediCareBERT for caption embedding, and a custom LSTM-based decoder. The architecture is designed to semantically align image and textual embeddings, using hybrid cosine-MSE loss and contrastive inference via vector similarity. We benchmark our method on the MultiCaRe dataset, comparing performance on filtered brain-only MRIs versus general MRI images against state-of-the-art medical image captioning methods including BLIP, R2GenGPT, and recent transformer-based approaches. Results show that focusing on domain-specific data improves caption accuracy and semantic alignment. Our work proposes a scalable, interpretable solution for automated medical image reporting.', 'abstract_zh': 'åŸºäºå˜å‹å™¨çš„å¤šæ¨¡æ€æ¡†æ¶ï¼šç”Ÿæˆä¸MRIæ‰«æä¸´åºŠç›¸å…³çš„æè¿°', 'title_zh': 'åŒ»å­¦ä¸­çš„å˜å‹å™¨ï¼šæé«˜åŒ»ç–—å›¾åƒæè¿°ä¸­çš„ vision-language å¯¹é½'}
{'arxiv_id': 'arXiv:2510.25160', 'title': 'Model-Document Protocol for AI Search', 'authors': 'Hongjin Qian, Zheng Liu', 'link': 'https://arxiv.org/abs/2510.25160', 'abstract': 'AI search depends on linking large language models (LLMs) with vast external knowledge sources. Yet web pages, PDF files, and other raw documents are not inherently LLM-ready: they are long, noisy, and unstructured. Conventional retrieval methods treat these documents as verbatim text and return raw passages, leaving the burden of fragment assembly and contextual reasoning to the LLM. This gap underscores the need for a new retrieval paradigm that redefines how models interact with documents.\nWe introduce the Model-Document Protocol (MDP), a general framework that formalizes how raw text is bridged to LLMs through consumable knowledge representations. Rather than treating retrieval as passage fetching, MDP defines multiple pathways that transform unstructured documents into task-specific, LLM-ready inputs. These include agentic reasoning, which curates raw evidence into coherent context; memory grounding, which accumulates reusable notes to enrich reasoning; and structured leveraging, which encodes documents into formal representations such as graphs or key-value caches. All three pathways share the same goal: ensuring that what reaches the LLM is not raw fragments but compact, structured knowledge directly consumable for reasoning.\nAs an instantiation, we present MDP-Agent, which realizes the protocol through an agentic process: constructing document-level gist memories for global coverage, performing diffusion-based exploration with vertical exploitation to uncover layered dependencies, and applying map-reduce style synthesis to integrate large-scale evidence into compact yet sufficient context. Experiments on information-seeking benchmarks demonstrate that MDP-Agent outperforms baselines, validating both the soundness of the MDP framework and the effectiveness of its agentic instantiation.', 'abstract_zh': 'åŸºäºæ¨¡å‹-æ–‡æ¡£åè®®çš„AIæœç´¢ä¾èµ–äºå°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸åºå¤§çš„å¤–éƒ¨çŸ¥è¯†æºè¿æ¥ã€‚ç„¶è€Œï¼Œç½‘é¡µã€PDFæ–‡ä»¶å’Œå…¶ä»–åŸå§‹æ–‡æ¡£æœ¬èº«å¹¶ä¸å¤©ç„¶é€‚åˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼šå®ƒä»¬é€šå¸¸åˆé•¿åˆå˜ˆæ‚ä¸”æ— ç»“æ„ã€‚ä¼ ç»Ÿçš„æ£€ç´¢æ–¹æ³•å°†è¿™äº›æ–‡æ¡£è§†ä¸ºåŸæ–‡æ–‡æœ¬ï¼Œå¹¶è¿”å›åŸå§‹æ®µè½ï¼Œä½¿å¤§å‹è¯­è¨€æ¨¡å‹æ‰¿æ‹…ç‰‡æ®µç»„è£…å’Œä¸Šä¸‹æ–‡æ¨ç†çš„ä»»åŠ¡ã€‚è¿™ä¸€å·®è·å‡¸æ˜¾äº†éœ€è¦ä¸€ç§æ–°çš„æ£€ç´¢èŒƒå¼ï¼Œé‡æ–°å®šä¹‰æ¨¡å‹ä¸æ–‡æ¡£çš„äº¤äº’æ–¹å¼ã€‚\n\næˆ‘ä»¬å¼•å…¥äº†æ¨¡å‹-æ–‡æ¡£åè®®ï¼ˆMDPï¼‰ï¼Œè¿™æ˜¯ä¸€ç§é€šç”¨æ¡†æ¶ï¼Œæ­£å¼åŒ–äº†åŸå§‹æ–‡æœ¬å¦‚ä½•é€šè¿‡å¯æ¶ˆè€—çš„çŸ¥è¯†è¡¨ç¤ºè¿æ¥åˆ°å¤§å‹è¯­è¨€æ¨¡å‹çš„è¿‡ç¨‹ã€‚MDPæ²¡æœ‰å°†æ£€ç´¢è§†ä¸ºæ®µè½è·å–ï¼Œè€Œæ˜¯å®šä¹‰äº†å¤šç§é€”å¾„ï¼Œå°†æ— ç»“æ„æ–‡æ¡£è½¬åŒ–ä¸ºç‰¹å®šä»»åŠ¡ã€é€‚åˆå¤§å‹è¯­è¨€æ¨¡å‹çš„è¾“å…¥ã€‚è¿™äº›é€”å¾„åŒ…æ‹¬ä»£ç†æ¨ç†ï¼Œå®ƒå°†åŸå§‹è¯æ®æ•´ç†æˆè¿è´¯çš„ä¸Šä¸‹æ–‡ï¼›è®°å¿† groundingï¼Œå®ƒç§¯ç´¯å¯é‡ç”¨çš„ç¬”è®°ä»¥ä¸°å¯Œæ¨ç†ï¼›ä»¥åŠç»“æ„åŒ–åˆ©ç”¨ï¼Œå®ƒå°†æ–‡æ¡£ç¼–ç ä¸ºå›¾å½¢æˆ–é”®å€¼ç¼“å­˜ç­‰å½¢å¼åŒ–çš„è¡¨ç¤ºã€‚æ‰€æœ‰ä¸‰æ¡é€”å¾„å…±äº«åŒä¸€ç›®æ ‡ï¼šç¡®ä¿ä¼ é€’ç»™å¤§å‹è¯­è¨€æ¨¡å‹çš„ä¸æ˜¯åŸå§‹ç‰‡æ®µï¼Œè€Œæ˜¯ç´§å‡‘ä¸”ç»“æ„åŒ–çš„å¯ä»¥ç›´æ¥ç”¨äºæ¨ç†çš„çŸ¥è¯†ã€‚\n\nä½œä¸ºä¸€ç§å®ç°æ–¹å¼ï¼Œæˆ‘ä»¬ä»‹ç»äº†MDP-Agentï¼Œå®ƒé€šè¿‡ä»£ç†è¿‡ç¨‹æ‰§è¡Œåè®®ï¼šæ„å»ºæ–‡æ¡£çº§åˆ«çš„æ ¸å¿ƒè®°å¿†ä»¥è¦†ç›–å…¨å±€ï¼Œè¿›è¡ŒåŸºäºæ‰©æ•£çš„æ¢ç´¢ä¸å‚ç›´åˆ©ç”¨ä»¥å‘ç°åˆ†å±‚ä¾èµ–å…³ç³»ï¼Œå¹¶åº”ç”¨æ˜ å°„-å‡å°‘é£æ ¼çš„åˆæˆå°†å¤§è§„æ¨¡è¯æ®æ•´åˆåˆ°ç´§å‡‘è€Œå……åˆ†çš„ä¸Šä¸‹æ–‡ä¸­ã€‚åœ¨ä¿¡æ¯æŸ¥æ‰¾åŸºå‡†æµ‹è¯•ä¸­çš„å®éªŒè¡¨æ˜ï¼ŒMDP-Agentä¼˜äºåŸºçº¿ï¼Œè¯å®äº†MDPæ¡†æ¶çš„ç¨³å¥æ€§å’Œå…¶ä»£ç†å®ç°çš„æœ‰æ•ˆæ€§ã€‚', 'title_zh': 'AIæœç´¢å¼•æ“çš„æ¨¡å‹-æ–‡æ¡£åè®®'}
{'arxiv_id': 'arXiv:2510.25130', 'title': 'Lipschitz-aware Linearity Grafting for Certified Robustness', 'authors': 'Yongjin Han, Suhyun Kim', 'link': 'https://arxiv.org/abs/2510.25130', 'abstract': 'Lipschitz constant is a fundamental property in certified robustness, as smaller values imply robustness to adversarial examples when a model is confident in its prediction. However, identifying the worst-case adversarial examples is known to be an NP-complete problem. Although over-approximation methods have shown success in neural network verification to address this challenge, reducing approximation errors remains a significant obstacle. Furthermore, these approximation errors hinder the ability to obtain tight local Lipschitz constants, which are crucial for certified robustness. Originally, grafting linearity into non-linear activation functions was proposed to reduce the number of unstable neurons, enabling scalable and complete verification. However, no prior theoretical analysis has explained how linearity grafting improves certified robustness. We instead consider linearity grafting primarily as a means of eliminating approximation errors rather than reducing the number of unstable neurons, since linear functions do not require relaxation. In this paper, we provide two theoretical contributions: 1) why linearity grafting improves certified robustness through the lens of the $l_\\infty$ local Lipschitz constant, and 2) grafting linearity into non-linear activation functions, the dominant source of approximation errors, yields a tighter local Lipschitz constant. Based on these theoretical contributions, we propose a Lipschitz-aware linearity grafting method that removes dominant approximation errors, which are crucial for tightening the local Lipschitz constant, thereby improving certified robustness, even without certified training. Our extensive experiments demonstrate that grafting linearity into these influential activations tightens the $l_\\infty$ local Lipschitz constant and enhances certified robustness.', 'abstract_zh': 'çº¿æ€§ graftingæ”¹è¿›äº†è®¤è¯é²æ£’æ€§ï¼šåŸºäº \\(l_\\infty\\) å±€éƒ¨ Lipschitz å¸¸æ•°çš„ç†è®ºåˆ†æä¸æ–¹æ³•', 'title_zh': 'Lipschitz-awareçº¿æ€§åŒ–å«æ¥ä»¥å®ç°è®¤è¯é²æ£’æ€§'}
{'arxiv_id': 'arXiv:2510.25126', 'title': 'Bridging the Divide: End-to-End Sequence-Graph Learning', 'authors': 'Yuen Chen, Yulun Wu, Samuel Sharpe, Igor Melnyk, Nam H. Nguyen, Furong Huang, C. Bayan Bruss, Rizal Fathony', 'link': 'https://arxiv.org/abs/2510.25126', 'abstract': 'Many real-world datasets are both sequential and relational: each node carries an event sequence while edges encode interactions. Existing methods in sequence modeling and graph modeling often neglect one modality or the other. We argue that sequences and graphs are not separate problems but complementary facets of the same dataset, and should be learned jointly. We introduce BRIDGE, a unified end-to-end architecture that couples a sequence encoder with a GNN under a single objective, allowing gradients to flow across both modules and learning task-aligned representations. To enable fine-grained token-level message passing among neighbors, we add TOKENXATTN, a token-level cross-attention layer that passes messages between events in neighboring sequences. Across two settings, friendship prediction (Brightkite) and fraud detection (Amazon), BRIDGE consistently outperforms static GNNs, temporal graph methods, and sequence-only baselines on ranking and classification metrics.', 'abstract_zh': 'è®¸å¤šçœŸå®ä¸–ç•Œçš„æ•°æ®é›†æ—¢æ˜¯åºåˆ—åŒ–çš„åˆæ˜¯å…³ç³»æ€§çš„ï¼šæ¯ä¸ªèŠ‚ç‚¹æºå¸¦ä¸€ä¸ªäº‹ä»¶åºåˆ—ï¼Œè€Œè¾¹åˆ™ç¼–ç äº¤äº’ã€‚ç°æœ‰çš„åºåˆ—å»ºæ¨¡å’Œå›¾å»ºæ¨¡æ–¹æ³•å¾€å¾€å¿½è§†äº†ä¸€ç§æ¨¡æ€æˆ–å¦ä¸€ç§æ¨¡æ€ã€‚æˆ‘ä»¬argueè®¤ä¸ºï¼Œåºåˆ—å’Œå›¾ä¸æ˜¯åˆ†å¼€çš„é—®é¢˜ï¼Œè€Œæ˜¯åŒä¸€æ•°æ®é›†çš„äº’è¡¥æ–¹é¢ï¼Œå¹¶ä¸”åº”è¯¥è”åˆå­¦ä¹ ã€‚æˆ‘ä»¬æå‡ºBRIDGEï¼Œè¿™æ˜¯ä¸€ç§ç»Ÿä¸€çš„ç«¯åˆ°ç«¯æ¶æ„ï¼Œå°†åºåˆ—ç¼–ç å™¨ä¸å•ä¸ªç›®æ ‡ä¸‹çš„å›¾ç¥ç»ç½‘ç»œè€¦åˆï¼Œå…è®¸æ¢¯åº¦åœ¨ä¸¤ä¸ªæ¨¡å—ä¹‹é—´æµåŠ¨å¹¶å­¦ä¹ ä»»åŠ¡å¯¹é½çš„è¡¨ç¤ºã€‚ä¸ºäº†å®ç°é‚»å±…ä¹‹é—´ç»†ç²’åº¦çš„æ ‡è®°çº§åˆ«æ¶ˆæ¯ä¼ é€’ï¼Œæˆ‘ä»¬å¢åŠ äº†TOKENXATTNï¼Œè¿™æ˜¯ä¸€ç§æ ‡è®°çº§åˆ«çš„è·¨æ³¨æ„åŠ›å±‚ï¼Œå®ƒåœ¨ç›¸é‚»åºåˆ—ä¸­çš„äº‹ä»¶ä¹‹é—´ä¼ é€’æ¶ˆæ¯ã€‚åœ¨ä¸¤ä¸ªè®¾ç½®ä¸­ï¼ŒBRIDGEåœ¨æœ‹å‹é¢„æµ‹ï¼ˆBrightkiteï¼‰å’Œæ¬ºè¯ˆæ£€æµ‹ï¼ˆAmazonï¼‰ä¸Šï¼Œåœ¨æ’åå’Œåˆ†ç±»æŒ‡æ ‡ä¸Šå§‹ç»ˆä¼˜äºé™æ€å›¾ç¥ç»ç½‘ç»œã€æ—¶é—´å›¾æ–¹æ³•å’Œä»…åºåˆ—åŸºçº¿ã€‚', 'title_zh': 'å¼¥åˆå·®è·ï¼šç«¯åˆ°ç«¯åºåˆ—å›¾å­¦ä¹ '}
{'arxiv_id': 'arXiv:2510.25123', 'title': 'Learning Low Rank Neural Representations of Hyperbolic Wave Dynamics from Data', 'authors': 'Woojin Cho, Kookjin Lee, Noseong Park, Donsub Rim, Gerrit Welper', 'link': 'https://arxiv.org/abs/2510.25123', 'abstract': 'We present a data-driven dimensionality reduction method that is well-suited for physics-based data representing hyperbolic wave propagation. The method utilizes a specialized neural network architecture called low rank neural representation (LRNR) inside a hypernetwork framework. The architecture is motivated by theoretical results that rigorously prove the existence of efficient representations for this wave class. We illustrate through archetypal examples that such an efficient low-dimensional representation of propagating waves can be learned directly from data through a combination of deep learning techniques. We observe that a low rank tensor representation arises naturally in the trained LRNRs, and that this reveals a new decomposition of wave propagation where each decomposed mode corresponds to interpretable physical features. Furthermore, we demonstrate that the LRNR architecture enables efficient inference via a compression scheme, which is a potentially important feature when deploying LRNRs in demanding performance regimes.', 'abstract_zh': 'åŸºäºç‰©ç†çš„æ•°æ®é©±åŠ¨ç»´æ•°_reduction_æ–¹æ³•ï¼šé€‚ç”¨äºhyperbolicæ³¢ä¼ æ’­çš„æ•°æ®è¡¨ç¤º', 'title_zh': 'ä»æ•°æ®ä¸­å­¦ä¹ åŒæ›²æ³¢åŠ¨åŠ¨åŠ›å­¦çš„ä½ç§©ç¥ç»è¡¨ç¤º'}
{'arxiv_id': 'arXiv:2510.25113', 'title': 'The Neural Differential Manifold: An Architecture with Explicit Geometric Structure', 'authors': 'Di Zhang', 'link': 'https://arxiv.org/abs/2510.25113', 'abstract': "This paper introduces the Neural Differential Manifold (NDM), a novel neural network architecture that explicitly incorporates geometric structure into its fundamental design. Departing from conventional Euclidean parameter spaces, the NDM re-conceptualizes a neural network as a differentiable manifold where each layer functions as a local coordinate chart, and the network parameters directly parameterize a Riemannian metric tensor at every point. The architecture is organized into three synergistic layers: a Coordinate Layer implementing smooth chart transitions via invertible transformations inspired by normalizing flows, a Geometric Layer that dynamically generates the manifold's metric through auxiliary sub-networks, and an Evolution Layer that optimizes both task performance and geometric simplicity through a dual-objective loss function. This geometric regularization penalizes excessive curvature and volume distortion, providing intrinsic regularization that enhances generalization and robustness. The framework enables natural gradient descent optimization aligned with the learned manifold geometry and offers unprecedented interpretability by endowing internal representations with clear geometric meaning. We analyze the theoretical advantages of this approach, including its potential for more efficient optimization, enhanced continual learning, and applications in scientific discovery and controllable generative modeling. While significant computational challenges remain, the Neural Differential Manifold represents a fundamental shift towards geometrically structured, interpretable, and efficient deep learning systems.", 'abstract_zh': 'åŸºäºç¥ç»å¾®åˆ†æµå½¢çš„æ–°å‹ç¥ç»ç½‘ç»œæ¶æ„ï¼šå…¼æœ‰å‡ ä½•ç»“æ„çš„è®¾è®¡', 'title_zh': 'ç¥ç»æµå½¢æ¶æ„ï¼šå…·æœ‰æ˜¾å¼å‡ ä½•ç»“æ„çš„æ¶æ„'}
{'arxiv_id': 'arXiv:2510.25096', 'title': 'Learning Fair Graph Representations with Multi-view Information Bottleneck', 'authors': 'Chuxun Liu, Debo Cheng, Qingfeng Chen, Jiangzhang Gan, Jiuyong Li, Lin Liu', 'link': 'https://arxiv.org/abs/2510.25096', 'abstract': 'Graph neural networks (GNNs) excel on relational data by passing messages over node features and structure, but they can amplify training data biases, propagating discriminatory attributes and structural imbalances into unfair outcomes. Many fairness methods treat bias as a single source, ignoring distinct attribute and structure effects and leading to suboptimal fairness and utility trade-offs. To overcome this challenge, we propose FairMIB, a multi-view information bottleneck framework designed to decompose graphs into feature, structural, and diffusion views for mitigating complexity biases in GNNs. Especially, the proposed FairMIB employs contrastive learning to maximize cross-view mutual information for bias-free representation learning. It further integrates multi-perspective conditional information bottleneck objectives to balance task utility and fairness by minimizing mutual information with sensitive attributes. Additionally, FairMIB introduces an inverse probability-weighted (IPW) adjacency correction in the diffusion view, which reduces the spread of bias propagation during message passing. Experiments on five real-world benchmark datasets demonstrate that FairMIB achieves state-of-the-art performance across both utility and fairness metrics.', 'abstract_zh': 'å›¾ç¥ç»ç½‘ç»œï¼ˆGNNsï¼‰åœ¨å…³ç³»æ•°æ®ä¸Šè¡¨ç°å‡ºè‰²ï¼Œé€šè¿‡èŠ‚ç‚¹ç‰¹å¾å’Œç»“æ„ä¼ é€’æ¶ˆæ¯ï¼Œä½†å®ƒä»¬å¯èƒ½ä¼šæ”¾å¤§è®­ç»ƒæ•°æ®åè§ï¼Œå°†æ­§è§†æ€§å±æ€§å’Œç»“æ„ä¸å¹³è¡¡ä¼ æ’­åˆ°ä¸å…¬å¹³çš„ç»“æœä¸­ã€‚è®¸å¤šå…¬å¹³æ€§æ–¹æ³•å°†åè§è§†ä¸ºå•ä¸€æ¥æºï¼Œå¿½è§†äº†å±æ€§å’Œç»“æ„çš„å·®å¼‚æ•ˆåº”ï¼Œå¯¼è‡´å…¬å¹³æ€§å’Œæ•ˆç”¨çš„æ¬¡ä¼˜åŒ–æƒè¡¡ã€‚ä¸ºäº†å…‹æœè¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†FairMIBï¼Œè¿™æ˜¯ä¸€ç§å¤šè§†å›¾ä¿¡æ¯ç“¶é¢ˆæ¡†æ¶ï¼Œæ—¨åœ¨å°†å›¾åˆ†è§£ä¸ºç‰¹å¾ã€ç»“æ„å’Œæ‰©æ•£è§†å›¾ï¼Œä»¥å‡è½»GNNä¸­çš„å¤æ‚æ€§åè§ã€‚FairMIBç‰¹åˆ«é‡‡ç”¨å¯¹æ¯”å­¦ä¹ æ¥æœ€å¤§åŒ–è·¨è§†å›¾äº’ä¿¡æ¯ï¼Œä»¥å®ç°æ— åè¡¨ç¤ºå­¦ä¹ ã€‚å®ƒè¿›ä¸€æ­¥ç»“åˆäº†å¤šè§†è§’æ¡ä»¶ä¿¡æ¯ç“¶é¢ˆç›®æ ‡ï¼Œé€šè¿‡æœ€å°åŒ–ä¸æ•æ„Ÿå±æ€§çš„äº’ä¿¡æ¯æ¥å¹³è¡¡ä»»åŠ¡æ•ˆç”¨å’Œå…¬å¹³æ€§ã€‚æ­¤å¤–ï¼ŒFairMIBåœ¨æ‰©æ•£è§†å›¾ä¸­å¼•å…¥äº†é€†æ¦‚ç‡åŠ æƒï¼ˆIPWï¼‰é‚»æ¥ä¿®æ­£ï¼Œè¿™åœ¨æ¶ˆæ¯ä¼ é€’è¿‡ç¨‹ä¸­å‡å°‘äº†åè§ä¼ æ’­çš„æ‰©æ•£ã€‚åœ¨äº”ä¸ªçœŸå®ä¸–ç•Œçš„åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒFairMIBåœ¨æ•ˆç”¨å’Œå…¬å¹³æ€§æŒ‡æ ‡ä¸Šå‡è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚', 'title_zh': 'åŸºäºå¤šè§†å›¾ä¿¡æ¯ç“¶é¢ˆçš„å…¬å¹³å›¾è¡¨ç¤ºå­¦ä¹ '}
{'arxiv_id': 'arXiv:2510.25080', 'title': 'Monopoly Deal: A Benchmark Environment for Bounded One-Sided Response Games', 'authors': 'Will Wolf', 'link': 'https://arxiv.org/abs/2510.25080', 'abstract': "Card games are widely used to study sequential decision-making under uncertainty, with real-world analogues in negotiation, finance, and cybersecurity. Typically, these games fall into three categories based on the flow of control: strictly-sequential (where players alternate single actions), deterministic-response (where some actions trigger a fixed outcome), and unbounded reciprocal-response (where alternating counterplays are permitted). A less-explored but strategically rich structure exists: the bounded one-sided response. This dynamic occurs when a player's action briefly transfers control to the opponent, who must satisfy a fixed condition through one or more sequential moves before the turn resolves. We term games featuring this mechanism Bounded One-Sided Response Games (BORGs).\nWe introduce a modified version of Monopoly Deal as a benchmark environment that specifically isolates the BORG dynamic, where a Rent action forces the opponent to sequentially choose payment assets. We demonstrate that the gold-standard algorithm, Counterfactual Regret Minimization (CFR), successfully converges on effective strategies for this domain without requiring novel algorithmic extensions. To support efficient, reproducible experimentation, we present a lightweight, full-stack research platform that unifies the environment, a parallelized CFR runtime, and a human-playable web interface, all runnable on a single workstation. This system provides a practical foundation for exploring state representation and policy learning in bounded one-sided response settings.\nThe trained CFR agent and source code are available at this https URL.", 'abstract_zh': 'å¸¦æœ‰é™åˆ¶çš„ä¸€æ–¹å“åº”åšå¼ˆï¼ˆBORGsï¼‰ï¼šåŸºäºMonopoly Dealçš„åŸºå‡†ç¯å¢ƒä¸å®éªŒå¹³å°', 'title_zh': 'å„æ–­äº¤æ˜“ï¼šå—é™ä¸€æ–¹å“åº”åšå¼ˆçš„åŸºå‡†ç¯å¢ƒ'}
{'arxiv_id': 'arXiv:2510.25055', 'title': 'GAPMAP: Mapping Scientific Knowledge Gaps in Biomedical Literature Using Large Language Models', 'authors': 'Nourah M Salem, Elizabeth White, Michael Bada, Lawrence Hunter', 'link': 'https://arxiv.org/abs/2510.25055', 'abstract': 'Scientific progress is driven by the deliberate articulation of what remains unknown. This study investigates the ability of large language models (LLMs) to identify research knowledge gaps in the biomedical literature. We define two categories of knowledge gaps: explicit gaps, clear declarations of missing knowledge; and implicit gaps, context-inferred missing knowledge. While prior work has focused mainly on explicit gap detection, we extend this line of research by addressing the novel task of inferring implicit gaps. We conducted two experiments on almost 1500 documents across four datasets, including a manually annotated corpus of biomedical articles. We benchmarked both closed-weight models (from OpenAI) and open-weight models (Llama and Gemma 2) under paragraph-level and full-paper settings. To address the reasoning of implicit gaps inference, we introduce \\textbf{\\small TABI}, a Toulmin-Abductive Bucketed Inference scheme that structures reasoning and buckets inferred conclusion candidates for validation. Our results highlight the robust capability of LLMs in identifying both explicit and implicit knowledge gaps. This is true for both open- and closed-weight models, with larger variants often performing better. This suggests a strong ability of LLMs for systematically identifying candidate knowledge gaps, which can support early-stage research formulation, policymakers, and funding decisions. We also report observed failure modes and outline directions for robust deployment, including domain adaptation, human-in-the-loop verification, and benchmarking across open- and closed-weight models.', 'abstract_zh': 'ç§‘å­¦è¿›æ­¥é©±äºå¯¹æœªçŸ¥çš„æ˜ç¡®é˜è¿°ã€‚æœ¬ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç”Ÿç‰©åŒ»å­¦æ–‡çŒ®ä¸­è¯†åˆ«ç ”ç©¶çŸ¥è¯†gapçš„èƒ½åŠ›ã€‚æˆ‘ä»¬å®šä¹‰äº†ä¸¤ç±»çŸ¥è¯†gapï¼šæ˜ç¡®gapï¼Œæ˜ç¡®å£°æ˜ç¼ºå¤±çš„çŸ¥è¯†ï¼›éšå«gapï¼Œä¸Šä¸‹æ–‡æ¨æ–­å‡ºçš„ç¼ºå¤±çŸ¥è¯†ã€‚å°½ç®¡å…ˆå‰çš„å·¥ä½œä¸»è¦é›†ä¸­åœ¨æ˜ç¡®gapçš„æ£€æµ‹ä¸Šï¼Œæˆ‘ä»¬é€šè¿‡è§£å†³æ¨æ–­éšå«gapçš„æ–°å‹ä»»åŠ¡æ‰©å±•äº†è¿™ä¸€ç ”ç©¶é¢†åŸŸã€‚æˆ‘ä»¬åœ¨å››ç»„æ•°æ®é›†ä¸­è¿‘1500ä»½æ–‡æ¡£ä¸Šè¿›è¡Œäº†ä¸¤é¡¹å®éªŒï¼Œå…¶ä¸­åŒ…æ‹¬ä¸€ä»½æ‰‹åŠ¨æ ‡æ³¨çš„ç”Ÿç‰©åŒ»å­¦æ–‡ç« è¯­æ–™åº“ã€‚æˆ‘ä»¬åˆ†åˆ«åœ¨æ®µè½çº§å’Œå…¨æ–‡çº§æµ‹è¯•äº†é—­æƒé‡æ¨¡å‹ï¼ˆæ¥è‡ªOpenAIï¼‰å’Œå¼€æ”¾æƒé‡æ¨¡å‹ï¼ˆLlamaå’ŒGemma 2ï¼‰ã€‚ä¸ºäº†è§£é‡Šéšå«gapçš„æ¨æ–­è¿‡ç¨‹ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŸºäºToulmin-å½’çº³æ¨ç†æ¡¶åŒ–æ–¹æ¡ˆï¼ˆ\\textbf{\\small TABI}ï¼‰ï¼Œè¯¥æ–¹æ¡ˆç»“æ„åŒ–äº†æ¨ç†è¿‡ç¨‹å¹¶ä¸ºéªŒè¯æ¨æ–­å‡ºçš„ç»“è®ºå¤‡é€‰é¡¹åˆ†æ¡¶ã€‚ç ”ç©¶ç»“æœçªæ˜¾äº†LLMsåœ¨è¯†åˆ«æ˜ç¡®å’Œéšå«çŸ¥è¯†gapæ–¹é¢ç¨³å¥çš„èƒ½åŠ›ã€‚æ— è®ºæ˜¯å¼€æ”¾æƒé‡æ¨¡å‹è¿˜æ˜¯é—­æƒé‡æ¨¡å‹ï¼Œå¤§å‹å˜ä½“é€šå¸¸è¡¨ç°å‡ºæ›´å¥½çš„æ€§èƒ½ã€‚è¿™è¡¨æ˜LLMså…·æœ‰ç³»ç»Ÿåœ°è¯†åˆ«å€™é€‰çŸ¥è¯†gapçš„å¼ºå¤§èƒ½åŠ›ï¼Œå¯ä»¥æ”¯æŒæ—©æœŸç ”ç©¶çš„è§„åˆ’ã€æ”¿ç­–åˆ¶å®šå’Œèµ„åŠ©å†³ç­–ã€‚æˆ‘ä»¬è¿˜æŠ¥å‘Šäº†è§‚å¯Ÿåˆ°çš„å¤±è´¥æ¨¡å¼ï¼Œå¹¶æŒ‡å‡ºäº†é²æ£’éƒ¨ç½²çš„é€”å¾„ï¼ŒåŒ…æ‹¬é¢†åŸŸé€‚åº”ã€äººå·¥åœ¨ç¯éªŒè¯ä»¥åŠåœ¨å¼€æ”¾æƒé‡æ¨¡å‹å’Œé—­æƒé‡æ¨¡å‹ä¹‹é—´è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚', 'title_zh': 'GAPMAPï¼šä½¿ç”¨å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹æ˜ å°„ç”Ÿç‰©åŒ»å­¦æ–‡çŒ®ä¸­çš„çŸ¥è¯†ç¼ºå£'}
{'arxiv_id': 'arXiv:2510.25053', 'title': 'Scalable predictive processing framework for multitask caregiving robots', 'authors': 'Hayato Idei, Tamon Miyake, Tetsuya Ogata, Yuichi Yamashita', 'link': 'https://arxiv.org/abs/2510.25053', 'abstract': "The rapid aging of societies is intensifying demand for autonomous care robots; however, most existing systems are task-specific and rely on handcrafted preprocessing, limiting their ability to generalize across diverse scenarios. A prevailing theory in cognitive neuroscience proposes that the human brain operates through hierarchical predictive processing, which underlies flexible cognition and behavior by integrating multimodal sensory signals. Inspired by this principle, we introduce a hierarchical multimodal recurrent neural network grounded in predictive processing under the free-energy principle, capable of directly integrating over 30,000-dimensional visuo-proprioceptive inputs without dimensionality reduction. The model was able to learn two representative caregiving tasks, rigid-body repositioning and flexible-towel wiping, without task-specific feature engineering. We demonstrate three key properties: (i) self-organization of hierarchical latent dynamics that regulate task transitions, capture variability in uncertainty, and infer occluded states; (ii) robustness to degraded vision through visuo-proprioceptive integration; and (iii) asymmetric interference in multitask learning, where the more variable wiping task had little influence on repositioning, whereas learning the repositioning task led to a modest reduction in wiping performance, while the model maintained overall robustness. Although the evaluation was limited to simulation, these results establish predictive processing as a universal and scalable computational principle, pointing toward robust, flexible, and autonomous caregiving robots while offering theoretical insight into the human brain's ability to achieve flexible adaptation in uncertain real-world environments.", 'abstract_zh': 'ç¤¾ä¼šçš„è€é¾„åŒ–åŠ å‰§äº†å¯¹è‡ªä¸»æŠ¤ç†æœºå™¨äººçš„éœ€æ±‚ï¼›ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰ç³»ç»Ÿéƒ½æ˜¯ä»»åŠ¡ç‰¹å®šçš„ï¼Œå¹¶ä¾èµ–äºæ‰‹å·¥è®¾è®¡çš„é¢„å¤„ç†ï¼Œé™åˆ¶äº†å®ƒä»¬åœ¨ä¸åŒåœºæ™¯ä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚å—è®¤çŸ¥ç¥ç»ç§‘å­¦ä¸­å±‚çº§é¢„æµ‹å¤„ç†åŸç†çš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºè‡ªç”±èƒ½åŸç†çš„å±‚çº§å¤šæ¨¡æ€å¾ªç¯ç¥ç»ç½‘ç»œï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿç›´æ¥æ•´åˆè¶…è¿‡30,000ç»´åº¦çš„è§†çŸ¥è§‰æœ¬ä½“æ„Ÿå—è¾“å…¥ï¼Œè€Œæ— éœ€é™ä½ç»´åº¦ã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿåœ¨æ— éœ€ç‰¹å®šä»»åŠ¡ç‰¹å¾å·¥ç¨‹çš„æƒ…å†µä¸‹å­¦ä¹ ä¸¤ç§ä»£è¡¨æ€§çš„æŠ¤ç†ä»»åŠ¡ï¼šåˆšä½“é‡æ–°å®šä½å’ŒæŸ”æ€§æ¯›å·¾æ“¦æ‹­ã€‚æœ¬æ–‡å±•ç¤ºäº†ä¸‰ä¸ªå…³é”®ç‰¹æ€§ï¼šï¼ˆiï¼‰å±‚çº§æ½œåœ¨åŠ¨æ€çš„è‡ªç»„ç»‡ï¼Œè°ƒèŠ‚ä»»åŠ¡è½¬æ¢ï¼Œæ•æ‰ä¸ç¡®å®šæ€§ä¸­çš„å˜åŒ–ï¼Œå¹¶æ¨æ–­è¢«é®æŒ¡çš„çŠ¶æ€ï¼›ï¼ˆiiï¼‰é€šè¿‡æ•´åˆè§†çŸ¥è§‰æœ¬ä½“æ„Ÿå—åº”å¯¹è§†è§‰é€€åŒ–çš„ç¨³å¥æ€§ï¼›ï¼ˆiiiï¼‰åœ¨å¤šä»»åŠ¡å­¦ä¹ ä¸­çš„ä¸å¯¹ç§°å¹²æ‰°ï¼Œåœ¨å¤šä»»åŠ¡å­¦ä¹ ä¸­ï¼Œæ›´ä¸ºå¤šå˜çš„æ“¦æ‹­ä»»åŠ¡å¯¹é‡æ–°å®šä½å‡ ä¹æ²¡æœ‰å½±å“ï¼Œè€Œå­¦ä¹ é‡æ–°å®šä½ä»»åŠ¡åˆ™å¯¼è‡´æ“¦æ‹­æ€§èƒ½æœ‰è½»å¾®ä¸‹é™ï¼Œä½†æ¨¡å‹æ•´ä½“ä¾ç„¶ä¿æŒç¨³å¥ã€‚å°½ç®¡è¯„ä¼°ä»…é™äºæ¨¡æ‹Ÿï¼Œä½†è¿™äº›ç»“æœç¡®ç«‹äº†é¢„æµ‹å¤„ç†ä½œä¸ºä¸€ç§æ™®éè€Œå¯æ‰©å±•çš„è®¡ç®—åŸç†ï¼Œå¹¶ä¸”å±•ç¤ºäº†çµæ´»ã€é€‚åº”æ€§å¼ºä¸”è‡ªä¸»çš„æŠ¤ç†æœºå™¨äººçš„å¯èƒ½æ€§ï¼ŒåŒæ—¶æä¾›äº†å¯¹äººè„‘å¦‚ä½•åœ¨ä¸ç¡®å®šçš„ç°å®ç¯å¢ƒä¸­å®ç°çµæ´»é€‚åº”çš„ç†è®ºæ´å¯Ÿã€‚', 'title_zh': 'å¯æ‰©å±•çš„å¤šä»»åŠ¡ caregiving æœºå™¨äººé¢„æµ‹å¤„ç†æ¡†æ¶'}
{'arxiv_id': 'arXiv:2510.25032', 'title': 'Efficient License Plate Recognition via Pseudo-Labeled Supervision with Grounding DINO and YOLOv8', 'authors': 'Zahra Ebrahimi Vargoorani, Amir Mohammad Ghoreyshi, Ching Yee Suen', 'link': 'https://arxiv.org/abs/2510.25032', 'abstract': 'Developing a highly accurate automatic license plate recognition system (ALPR) is challenging due to environmental factors such as lighting, rain, and dust. Additional difficulties include high vehicle speeds, varying camera angles, and low-quality or low-resolution images. ALPR is vital in traffic control, parking, vehicle tracking, toll collection, and law enforcement applications. This paper proposes a deep learning strategy using YOLOv8 for license plate detection and recognition tasks. This method seeks to enhance the performance of the model using datasets from Ontario, Quebec, California, and New York State. It achieved an impressive recall rate of 94% on the dataset from the Center for Pattern Recognition and Machine Intelligence (CENPARMI) and 91% on the UFPR-ALPR dataset. In addition, our method follows a semi-supervised learning framework, combining a small set of manually labeled data with pseudo-labels generated by Grounding DINO to train our detection model. Grounding DINO, a powerful vision-language model, automatically annotates many images with bounding boxes for license plates, thereby minimizing the reliance on labor-intensive manual labeling. By integrating human-verified and model-generated annotations, we can scale our dataset efficiently while maintaining label quality, which significantly enhances the training process and overall model performance. Furthermore, it reports character error rates for both datasets, providing additional insight into system performance.', 'abstract_zh': 'å¼€å‘ä¸€ç§é«˜åº¦å‡†ç¡®çš„è‡ªåŠ¨è½¦ç‰Œè¯†åˆ«ç³»ç»Ÿï¼ˆALPRï¼‰é¢ä¸´æŒ‘æˆ˜ï¼Œè¿™ä¸»è¦æ˜¯ç”±äºå…‰ç…§ã€é›¨ã€ç°å°˜ç­‰ç¯å¢ƒå› ç´ çš„å½±å“ã€‚å¦å¤–ï¼Œé«˜é€Ÿè¡Œé©¶çš„è½¦è¾†ã€ä¸åŒçš„æ‘„åƒå¤´è§’åº¦ä»¥åŠä½è´¨é‡æˆ–ä½åˆ†è¾¨ç‡çš„å›¾åƒä¹Ÿä¼šå¢åŠ éš¾åº¦ã€‚ALPRåœ¨äº¤é€šæ§åˆ¶ã€åœè½¦åœºç®¡ç†ã€è½¦è¾†è·Ÿè¸ªã€æ”¶è´¹å’Œæ‰§æ³•ç­‰åº”ç”¨ä¸­è‡³å…³é‡è¦ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ä½¿ç”¨YOLOv8çš„æ·±åº¦å­¦ä¹ ç­–ç•¥ï¼Œç”¨äºè½¦ç‰Œæ£€æµ‹å’Œè¯†åˆ«ä»»åŠ¡ã€‚è¯¥æ–¹æ³•ä½¿ç”¨æ¥è‡ªå®‰å¤§ç•¥çœã€é­åŒ—å…‹çœã€åŠ åˆ©ç¦å°¼äºšå·å’Œçº½çº¦å·çš„æ•°æ®é›†ï¼Œä»¥æé«˜æ¨¡å‹æ€§èƒ½ã€‚åœ¨ä¸­å¿ƒæ¨¡å¼è¯†åˆ«ä¸æœºå™¨æ™ºèƒ½ä¸­å¿ƒï¼ˆCENPARMIï¼‰çš„æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•å®ç°äº†94%çš„å¬å›ç‡ï¼Œåœ¨UFPR-ALPRæ•°æ®é›†ä¸Šå®ç°äº†91%çš„å¬å›ç‡ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•é‡‡ç”¨åŠç›‘ç£å­¦ä¹ æ¡†æ¶ï¼Œç»“åˆå°‘é‡çš„æ‰‹åŠ¨æ ‡æ³¨æ•°æ®å’Œç”±Grounding DINOç”Ÿæˆçš„ä¼ªæ ‡æ³¨æ¥è®­ç»ƒæ£€æµ‹æ¨¡å‹ã€‚Grounding DINOæ˜¯ä¸€ä¸ªå¼ºå¤§çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œèƒ½å¤Ÿè‡ªåŠ¨ä¸ºå¤§é‡å›¾åƒæ ‡æ³¨è½¦ç‰Œçš„è¾¹ç•Œæ¡†ï¼Œä»è€Œå‡å°‘å¯¹åŠ³åŠ¨å¯†é›†å‹æ‰‹åŠ¨æ ‡æ³¨çš„ä¾èµ–ã€‚é€šè¿‡ç»“åˆäººå·¥éªŒè¯å’Œæ¨¡å‹ç”Ÿæˆçš„æ ‡æ³¨ï¼Œå¯ä»¥åœ¨ä¿æŒé«˜è´¨é‡æ ‡ç­¾çš„åŒæ—¶æœ‰æ•ˆåœ°æ‰©å±•æ•°æ®é›†è§„æ¨¡ï¼Œä»è€Œæ˜¾è‘—æé«˜è®­ç»ƒè¿‡ç¨‹å’Œæ•´ä½“æ¨¡å‹æ€§èƒ½ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜æŠ¥å‘Šäº†ä¸¤ä¸ªæ•°æ®é›†çš„å­—ç¬¦é”™è¯¯ç‡ï¼Œæä¾›äº†ç³»ç»Ÿæ€§èƒ½çš„é¢å¤–è§è§£ã€‚', 'title_zh': 'é€šè¿‡Grounding DINOå’ŒYOLOv8çš„ä¼ªæ ‡ç­¾ç›‘ç£å®ç°é«˜æ•ˆçš„è½¦ç‰Œè¯†åˆ«'}
{'arxiv_id': 'arXiv:2510.25017', 'title': 'StorageXTuner: An LLM Agent-Driven Automatic Tuning Framework for Heterogeneous Storage Systems', 'authors': 'Qi Lin, Zhenyu Zhang, Viraj Thakkar, Zhenjie Sun, Mai Zheng, Zhichao Cao', 'link': 'https://arxiv.org/abs/2510.25017', 'abstract': 'Automatically configuring storage systems is hard: parameter spaces are large and conditions vary across workloads, deployments, and versions. Heuristic and ML tuners are often system specific, require manual glue, and degrade under changes. Recent LLM-based approaches help but usually treat tuning as a single-shot, system-specific task, which limits cross-system reuse, constrains exploration, and weakens validation. We present StorageXTuner, an LLM agent-driven auto-tuning framework for heterogeneous storage engines. StorageXTuner separates concerns across four agents - Executor (sandboxed benchmarking), Extractor (performance digest), Searcher (insight-guided configuration exploration), and Reflector (insight generation and management). The design couples an insight-driven tree search with layered memory that promotes empirically validated insights and employs lightweight checkers to guard against unsafe actions. We implement a prototype and evaluate it on RocksDB, LevelDB, CacheLib, and MySQL InnoDB with YCSB, MixGraph, and TPC-H/C. Relative to out-of-the-box settings and to ELMo-Tune, StorageXTuner reaches up to 575% and 111% higher throughput, reduces p99 latency by as much as 88% and 56%, and converges with fewer trials.', 'abstract_zh': 'è‡ªåŠ¨é…ç½®å­˜å‚¨ç³»ç»Ÿå›°éš¾ï¼šå‚æ•°ç©ºé—´åºå¤§ä¸”å·¥ä½œè´Ÿè½½ã€éƒ¨ç½²å’Œç‰ˆæœ¬ä¹‹é—´çš„æƒ…å†µå„å¼‚ã€‚å¯å‘å¼å’ŒMLè°ƒä¼˜å™¨é€šå¸¸ç‰¹å®šäºç³»ç»Ÿï¼Œéœ€è¦æ‰‹åŠ¨é…ç½®ï¼Œå¹¶ä¸”åœ¨å‘ç”Ÿå˜åŒ–æ—¶ä¼šé€€åŒ–ã€‚åŸºäºLLMçš„æ–¹æ³•æœ‰æ‰€å¸®åŠ©ï¼Œä½†é€šå¸¸å°†è°ƒä¼˜è§†ä¸ºå•æ¬¡ã€ç‰¹å®šäºç³»ç»Ÿçš„ä»»åŠ¡ï¼Œè¿™é™åˆ¶äº†è·¨ç³»ç»Ÿçš„é‡ç”¨ï¼Œé™åˆ¶äº†æ¢ç´¢å¹¶å‰Šå¼±äº†éªŒè¯ã€‚æˆ‘ä»¬æå‡ºäº†StorageXTunerï¼Œè¿™æ˜¯ä¸€ç§åŸºäºLLMä»£ç†çš„å¼‚æ„å­˜å‚¨å¼•æ“è‡ªåŠ¨è°ƒä¼˜æ¡†æ¶ã€‚StorageXTuneré€šè¿‡å››ä¸ªä»£ç†â€”â€”æ‰§è¡Œå™¨ï¼ˆæ²™ç®±åŸºå‡†æµ‹è¯•ï¼‰ã€æå–å™¨ï¼ˆæ€§èƒ½æ‘˜è¦ï¼‰ã€æ¢ç´¢è€…ï¼ˆåŸºäºæ´å¯Ÿçš„é…ç½®æ¢ç´¢ï¼‰å’Œåæ€å™¨ï¼ˆæ´å¯Ÿç”Ÿæˆå’Œç®¡ç†ï¼‰æ¥åˆ†ç¦»å…³æ³¨ç‚¹ã€‚è®¾è®¡ç»“åˆäº†åŸºäºæ´å¯Ÿçš„æ•°æ®æ ‘æœç´¢ä¸åˆ†å±‚å†…å­˜ï¼Œä¿ƒè¿›äº†ç»éªŒéªŒè¯çš„æ´å¯Ÿï¼Œå¹¶é‡‡ç”¨äº†è½»é‡çº§æ£€æŸ¥å™¨æ¥é˜²æ­¢ä¸å®‰å…¨çš„æ“ä½œã€‚æˆ‘ä»¬å®ç°äº†ä¸€ä¸ªåŸå‹ï¼Œå¹¶åœ¨RocksDBã€LevelDBã€CacheLibå’ŒMySQL InnoDBä¸Šä½¿ç”¨YCSBã€MixGraphå’ŒTPC-H/Cè¿›è¡Œäº†è¯„ä¼°ã€‚ä¸å‡ºå‚è®¾ç½®å’ŒELMo-Tuneç›¸æ¯”ï¼ŒStorageXTunerçš„ååé‡åˆ†åˆ«æé«˜äº†575%å’Œ111%ï¼Œ99 percentileå»¶è¿Ÿåˆ†åˆ«å‡å°‘äº†88%å’Œ56%ï¼Œå¹¶ä¸”åœ¨æ›´å°‘çš„è¯•éªŒä¸­æ”¶æ•›ã€‚', 'title_zh': 'StorageXTuner: ä¸€ä¸ªåŸºäºLLMä»£ç†çš„å¼‚æ„å­˜å‚¨ç³»ç»Ÿè‡ªåŠ¨è°ƒä¼˜æ¡†æ¶'}
{'arxiv_id': 'arXiv:2510.25016', 'title': 'Towards Human-AI Synergy in Requirements Engineering: A Framework and Preliminary Study', 'authors': 'Mateen Ahmed Abbasi, Petri Ihantola, Tommi Mikkonen, Niko MÃ¤kitalo', 'link': 'https://arxiv.org/abs/2510.25016', 'abstract': 'The future of Requirements Engineering (RE) is increasingly driven by artificial intelligence (AI), reshaping how we elicit, analyze, and validate requirements. Traditional RE is based on labor-intensive manual processes prone to errors and complexity. AI-powered approaches, specifically large language models (LLMs), natural language processing (NLP), and generative AI, offer transformative solutions and reduce inefficiencies. However, the use of AI in RE also brings challenges like algorithmic bias, lack of explainability, and ethical concerns related to automation. To address these issues, this study introduces the Human-AI RE Synergy Model (HARE-SM), a conceptual framework that integrates AI-driven analysis with human oversight to improve requirements elicitation, analysis, and validation. The model emphasizes ethical AI use through transparency, explainability, and bias mitigation. We outline a multi-phase research methodology focused on preparing RE datasets, fine-tuning AI models, and designing collaborative human-AI workflows. This preliminary study presents the conceptual framework and early-stage prototype implementation, establishing a research agenda and practical design direction for applying intelligent data science techniques to semi-structured and unstructured RE data in collaborative environments.', 'abstract_zh': 'äººå·¥æ™ºèƒ½é©±åŠ¨çš„éœ€æ±‚å·¥ç¨‹æœªæ¥ï¼šäººç±»ä¸AIååŒæ¨¡å‹ï¼ˆHARE-SMï¼‰æ¦‚å¿µæ¡†æ¶', 'title_zh': 'é¢å‘éœ€æ±‚å·¥ç¨‹ä¸­äººæœºååŒçš„æ¡†æ¶åŠåˆæ­¥ç ”ç©¶'}
{'arxiv_id': 'arXiv:2510.25013', 'title': 'Emergence of Minimal Circuits for Indirect Object Identification in Attention-Only Transformers', 'authors': 'Rabin Adhikari', 'link': 'https://arxiv.org/abs/2510.25013', 'abstract': 'Mechanistic interpretability aims to reverse-engineer large language models (LLMs) into human-understandable computational circuits. However, the complexity of pretrained models often obscures the minimal mechanisms required for specific reasoning tasks. In this work, we train small, attention-only transformers from scratch on a symbolic version of the Indirect Object Identification (IOI) task -- a benchmark for studying coreference -- like reasoning in transformers. Surprisingly, a single-layer model with only two attention heads achieves perfect IOI accuracy, despite lacking MLPs and normalization layers. Through residual stream decomposition, spectral analysis, and embedding interventions, we find that the two heads specialize into additive and contrastive subcircuits that jointly implement IOI resolution. Furthermore, we show that a two-layer, one-head model achieves similar performance by composing information across layers through query-value interactions. These results demonstrate that task-specific training induces highly interpretable, minimal circuits, offering a controlled testbed for probing the computational foundations of transformer reasoning.', 'abstract_zh': 'æœºåˆ¶å¯è§£é‡Šæ€§æ—¨åœ¨å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é€†å‘å·¥ç¨‹ä¸ºäººç±»å¯ç†è§£çš„è®¡ç®—ç”µè·¯ã€‚ç„¶è€Œï¼Œé¢„è®­ç»ƒæ¨¡å‹çš„å¤æ‚æ€§å¾€å¾€æ©ç›–äº†ç‰¹å®šæ¨ç†ä»»åŠ¡æ‰€éœ€çš„åŸºæœ¬æœºåˆ¶ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬åœ¨ç¬¦å·åŒ–çš„é—´æ¥å¯¹è±¡è¯†åˆ«ï¼ˆIOIï¼‰ä»»åŠ¡â€”â€”ä¸€ä¸ªç”¨äºç ”ç©¶æŒ‡ä»£æ¨ç†çš„åŸºå‡†â€”â€”ä¸Šä»å¤´è®­ç»ƒä»…æ³¨æ„åŠ›æœºåˆ¶çš„å°å‹å˜å‹å™¨ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œä»…åŒ…å«ä¸¤ä¸ªæ³¨æ„åŠ›å¤´çš„ä¸€å±‚æ¨¡å‹åœ¨IOIå‡†ç¡®ç‡ä¸Šè¾¾åˆ°äº†å®Œç¾è¡¨ç°ï¼Œå°½ç®¡å®ƒæ²¡æœ‰å¤šå±‚æ„ŸçŸ¥æœºå’Œè§„èŒƒåŒ–å±‚ã€‚é€šè¿‡å¯¹æ®‹å·®æµåˆ†è§£ã€é¢‘è°±åˆ†æå’ŒåµŒå…¥å¹²é¢„ï¼Œæˆ‘ä»¬å‘ç°è¿™ä¸¤ä¸ªå¤´åˆ†åˆ«ç‰¹åŒ–ä¸ºåŠ æ€§å’Œå¯¹æ¯”çš„å­ç”µè·¯ï¼Œå…±åŒå®ç°IOIè§£æã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å±•ç¤ºäº†é€šè¿‡æŸ¥è¯¢-ä»·å€¼äº¤äº’åœ¨å±‚é—´æ•´åˆä¿¡æ¯çš„ä¸¤å±‚ã€å•å¤´æ¨¡å‹å¯ä»¥è¾¾åˆ°ç›¸ä¼¼çš„æ€§èƒ½ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œé’ˆå¯¹ç‰¹å®šä»»åŠ¡çš„è®­ç»ƒå¯ä»¥è¯±å¯¼å‡ºé«˜åº¦å¯è§£é‡Šçš„æœ€å°ç”µè·¯ï¼Œæä¾›äº†ä¸€ä¸ªå¯æ§çš„æµ‹è¯•åºŠï¼Œç”¨äºæ¢æµ‹å˜å‹å™¨æ¨ç†çš„è®¡ç®—åŸºç¡€ã€‚', 'title_zh': 'ä»…æ³¨æ„åŠ›å˜å‹å™¨ä¸­é—´æ¥å¯¹è±¡è¯†åˆ«æœ€å°ç”µè·¯çš„æ¶Œç°'}
{'arxiv_id': 'arXiv:2510.24986', 'title': 'Epileptic Seizure Detection and Prediction from EEG Data: A Machine Learning Approach with Clinical Validation', 'authors': 'Ria Jayanti, Tanish Jain', 'link': 'https://arxiv.org/abs/2510.24986', 'abstract': 'In recent years, machine learning has become an increasingly powerful tool for supporting seizure detection and monitoring in epilepsy care. Traditional approaches focus on identifying seizures only after they begin, which limits the opportunity for early intervention and proactive treatment. In this study, we propose a novel approach that integrates both real-time seizure detection and prediction, aiming to capture subtle temporal patterns in EEG data that may indicate an upcoming seizure. Our approach was evaluated using the CHB-MIT Scalp EEG Database, which includes 969 hours of recordings and 173 seizures collected from 23 pediatric and young adult patients with drug-resistant epilepsy. To support seizure detection, we implemented a range of supervised machine learning algorithms, including K-Nearest Neighbors, Logistic Regression, Random Forest, and Support Vector Machine. The Logistic Regression achieved 90.9% detection accuracy with 89.6% recall, demonstrating balanced performance suitable for clinical screening. Random Forest and Support Vector Machine models achieved higher accuracy (94.0%) but with 0% recall, failing to detect any seizures, illustrating that accuracy alone is insufficient for evaluating medical ML models with class imbalance. For seizure prediction, we employed Long Short-Term Memory (LSTM) networks, which use deep learning to model temporal dependencies in EEG data. The LSTM model achieved 89.26% prediction accuracy. These results highlight the potential of developing accessible, real-time monitoring tools that not only detect seizures as traditionally done, but also predict them before they occur. This ability to predict seizures marks a significant shift from reactive seizure management to a more proactive approach, allowing patients to anticipate seizures and take precautionary measures to reduce the risk of injury or other complications.', 'abstract_zh': 'è¿‘å¹´æ¥ï¼Œæœºå™¨å­¦ä¹ å·²æˆä¸ºæ”¯æŒç™«ç—«æŠ¤ç†ä¸­ç™«ç—«å‘ä½œæ£€æµ‹å’Œç›‘æµ‹çš„å¼ºå¤§å·¥å…·ã€‚ä¼ ç»Ÿæ–¹æ³•ä¸“æ³¨äºåœ¨ç™«ç—«å‘ä½œå¼€å§‹åå¯¹å…¶è¿›è¡Œè¯†åˆ«ï¼Œè¿™é™åˆ¶äº†æ—©æœŸå¹²é¢„å’Œä¸»åŠ¨æ²»ç–—çš„æœºä¼šã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œæ—¨åœ¨ç»“åˆå®æ—¶ç™«ç—«å‘ä½œæ£€æµ‹å’Œé¢„æµ‹ï¼Œä»¥æ•æ‰EEGæ•°æ®ä¸­å¯èƒ½é¢„ç¤ºå³å°†å‘ç”Ÿç™«ç—«å‘ä½œçš„å¾®å¦™æ—¶é—´æ¨¡å¼ã€‚æˆ‘ä»¬ä½¿ç”¨CHB-MITå¤´çš®EEGæ•°æ®åº“å¯¹è¯¥æ–¹æ³•è¿›è¡Œäº†è¯„ä¼°ï¼Œè¯¥æ•°æ®åº“åŒ…å«äº†æ¥è‡ª23åè¯ç‰©éš¾æ²»æ€§ç™«ç—«æ‚£å„¿å’Œé’å¹´æ‚£è€…çš„969å°æ—¶è®°å½•å’Œ173æ¬¡ç™«ç—«å‘ä½œã€‚ä¸ºäº†æ”¯æŒç™«ç—«å‘ä½œæ£€æµ‹ï¼Œæˆ‘ä»¬å®ç°äº†å¤šç§ç›‘ç£æœºå™¨å­¦ä¹ ç®—æ³•ï¼ŒåŒ…æ‹¬K-æœ€è¿‘é‚»ã€é€»è¾‘å›å½’ã€éšæœºæ£®æ—å’Œæ”¯æŒå‘é‡æœºã€‚é€»è¾‘å›å½’çš„æ£€æµ‹å‡†ç¡®ç‡ä¸º90.9%ï¼Œå¬å›ç‡ä¸º89.6%ï¼Œå±•ç¤ºäº†é€‚åˆä¸´åºŠç­›æŸ¥çš„å¹³è¡¡æ€§èƒ½ã€‚éšæœºæ£®æ—å’Œæ”¯æŒå‘é‡æœºæ¨¡å‹çš„å‡†ç¡®ç‡æ›´é«˜ï¼ˆ94.0%ï¼‰ï¼Œä½†å¬å›ç‡ä¸º0%ï¼Œæœªèƒ½æ£€æµ‹åˆ°ä»»ä½•ç™«ç—«å‘ä½œï¼Œè¿™è¡¨æ˜ä»…ä¾èµ–å‡†ç¡®ç‡ä¸è¶³ä»¥è¯„ä¼°åŒ»ç–—é¢†åŸŸä¸å¹³è¡¡ç±»åˆ«çš„æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚å¯¹äºç™«ç—«å‘ä½œé¢„æµ‹ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†é•¿çŸ­æœŸè®°å¿†ï¼ˆLSTMï¼‰ç½‘ç»œï¼Œè¿™æ˜¯ä¸€ç§ä½¿ç”¨æ·±åº¦å­¦ä¹ å»ºæ¨¡EEGæ•°æ®ä¸­æ—¶é—´ä¾èµ–æ€§çš„æ–¹æ³•ã€‚LSTMæ¨¡å‹çš„é¢„æµ‹å‡†ç¡®ç‡ä¸º89.26%ã€‚è¿™äº›ç»“æœçªæ˜¾äº†å¼€å‘æ˜“äºä½¿ç”¨ã€å®æ—¶ç›‘æµ‹å·¥å…·çš„æ½œåŠ›ï¼Œè¿™äº›å·¥å…·ä¸ä»…åƒä¼ ç»Ÿæ–¹æ³•ä¸€æ ·æ£€æµ‹ç™«ç—«å‘ä½œï¼Œè¿˜å¯ä»¥é¢„æµ‹å…¶å‘ç”Ÿã€‚é¢„æµ‹ç™«ç—«å‘ä½œçš„èƒ½åŠ›æ ‡å¿—ç€ä»ååº”æ€§ç™«ç—«ç®¡ç†åˆ°æ›´å…·é¢„é˜²æ€§çš„è½¬å˜ï¼Œä½¿æ‚£è€…èƒ½å¤Ÿé¢„çŸ¥ç™«ç—«å‘ä½œå¹¶é‡‡å–é¢„é˜²æªæ–½ä»¥é™ä½å—ä¼¤æˆ–å…¶ä»–å¹¶å‘ç—‡çš„é£é™©ã€‚', 'title_zh': 'åŸºäºæœºå™¨å­¦ä¹ çš„ç™«ç—«å‘ä½œæ£€æµ‹ä¸é¢„æµ‹ï¼šä¸´åºŠéªŒè¯æ–¹æ³•'}
{'arxiv_id': 'arXiv:2510.24985', 'title': 'FaRAccel: FPGA-Accelerated Defense Architecture for Efficient Bit-Flip Attack Resilience in Transformer Models', 'authors': 'Najmeh Nazari, Banafsheh Saber Latibari, Elahe Hosseini, Fatemeh Movafagh, Chongzhou Fang, Hosein Mohammadi Makrani, Kevin Immanuel Gubbi, Abhijit Mahalanobis, Setareh Rafatirad, Hossein Sayadi, Houman Homayoun', 'link': 'https://arxiv.org/abs/2510.24985', 'abstract': 'Forget and Rewire (FaR) methodology has demonstrated strong resilience against Bit-Flip Attacks (BFAs) on Transformer-based models by obfuscating critical parameters through dynamic rewiring of linear layers. However, the application of FaR introduces non-negligible performance and memory overheads, primarily due to the runtime modification of activation pathways and the lack of hardware-level optimization. To overcome these limitations, we propose FaRAccel, a novel hardware accelerator architecture implemented on FPGA, specifically designed to offload and optimize FaR operations. FaRAccel integrates reconfigurable logic for dynamic activation rerouting, and lightweight storage of rewiring configurations, enabling low-latency inference with minimal energy overhead. We evaluate FaRAccel across a suite of Transformer models and demonstrate substantial reductions in FaR inference latency and improvement in energy efficiency, while maintaining the robustness gains of the original FaR methodology. To the best of our knowledge, this is the first hardware-accelerated defense against BFAs in Transformers, effectively bridging the gap between algorithmic resilience and efficient deployment on real-world AI platforms.', 'abstract_zh': 'åŸºäºFaRAccelçš„Transformeræ¨¡å‹Bit Flipæ”»å‡»é˜²å¾¡ç¡¬ä»¶åŠ é€Ÿå™¨', 'title_zh': 'FaRAccel: åŸºäºFPGAçš„é˜²å¾¡æ¶æ„ï¼Œç”¨äºæé«˜Transformeræ¨¡å‹å¯¹ä½ç¿»è½¬æ”»å‡»çš„é²æ£’æ€§'}
{'arxiv_id': 'arXiv:2510.24983', 'title': 'LRT-Diffusion: Calibrated Risk-Aware Guidance for Diffusion Policies', 'authors': 'Ximan Sun, Xiang Cheng', 'link': 'https://arxiv.org/abs/2510.24983', 'abstract': 'Diffusion policies are competitive for offline reinforcement learning (RL) but are typically guided at sampling time by heuristics that lack a statistical notion of risk. We introduce LRT-Diffusion, a risk-aware sampling rule that treats each denoising step as a sequential hypothesis test between the unconditional prior and the state-conditional policy head. Concretely, we accumulate a log-likelihood ratio and gate the conditional mean with a logistic controller whose threshold tau is calibrated once under H0 to meet a user-specified Type-I level alpha. This turns guidance from a fixed push into an evidence-driven adjustment with a user-interpretable risk budget. Importantly, we deliberately leave training vanilla (two heads with standard epsilon-prediction) under the structure of DDPM. LRT guidance composes naturally with Q-gradients: critic-gradient updates can be taken at the unconditional mean, at the LRT-gated mean, or a blend, exposing a continuum from exploitation to conservatism. We standardize states and actions consistently at train and test time and report a state-conditional out-of-distribution (OOD) metric alongside return. On D4RL MuJoCo tasks, LRT-Diffusion improves the return-OOD trade-off over strong Q-guided baselines in our implementation while honoring the desired alpha. Theoretically, we establish level-alpha calibration, concise stability bounds, and a return comparison showing when LRT surpasses Q-guidance-especially when off-support errors dominate. Overall, LRT-Diffusion is a drop-in, inference-time method that adds principled, calibrated risk control to diffusion policies for offline RL.', 'abstract_zh': 'é£é™©æ„ŸçŸ¥é‡‡æ ·è§„åˆ™LRT-Diffusionåœ¨ç¦»çº¿å¼ºåŒ–å­¦ä¹ ä¸­çš„åº”ç”¨', 'title_zh': 'LRT-Diffusion: æ ¡å‡†çš„é£é™©æ„è¯†æŒ‡å¯¼ç­–ç•¥'}
{'arxiv_id': 'arXiv:2510.24980', 'title': 'FT-ARM: Fine-Tuned Agentic Reflection Multimodal Language Model for Pressure Ulcer Severity Classification with Reasoning', 'authors': 'Reza Saadati Fard, Emmanuel Agu, Palawat Busaranuvong, Deepak Kumar, Shefalika Gautam, Bengisu Tulu, Diane Strong, Lorraine Loretz', 'link': 'https://arxiv.org/abs/2510.24980', 'abstract': 'Pressure ulcers (PUs) are a serious and prevalent healthcare concern. Accurate classification of PU severity (Stages I-IV) is essential for proper treatment but remains challenging due to subtle visual distinctions and subjective interpretation, leading to variability among clinicians. Prior AI-based approaches using Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) achieved promising accuracy but offered limited interpretability. We present FT-ARM (Fine-Tuned Agentic Reflection Multimodal model), a fine-tuned multimodal large language model (MLLM) with an agentic self-reflection mechanism for pressure ulcer severity classification. Inspired by clinician-style diagnostic reassessment, FT-ARM iteratively refines its predictions by reasoning over visual features and encoded clinical knowledge from text, enhancing both accuracy and consistency. On the publicly available Pressure Injury Image Dataset (PIID), FT-ARM, fine-tuned from LLaMA 3.2 90B, achieved 85% accuracy in classifying PU stages I-IV, surpassing prior CNN-based models by +4%. Unlike earlier CNN/ViT studies that relied solely on offline evaluations, FT-ARM is designed and tested for live inference, reflecting real-time deployment conditions. Furthermore, it produces clinically grounded natural-language explanations, improving interpretability and trust. By integrating fine-tuning and reflective reasoning across multimodal inputs, FT-ARM advances the reliability, transparency, and clinical applicability of automated wound assessment systems, addressing the critical need for consistent and explainable PU staging to support improved patient care.', 'abstract_zh': 'åŸºäºä¸»åŠ¨åæ€æœºåˆ¶çš„å¤šæ¨¡æ€Fine-Tuned ARMæ¨¡å‹åœ¨å‹åŠ›æºƒç–¡ä¸¥é‡ç¨‹åº¦åˆ†ç±»ä¸­çš„åº”ç”¨', 'title_zh': 'FT-ARMï¼šç»†åº¦è°ƒæ•´çš„ä»£ç†åæ€å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹åœ¨å‹åŠ›æ€§æºƒç–¡ä¸¥é‡ç¨‹åº¦åˆ†ç±»ä¸­çš„æ¨ç†æ–¹æ³•'}
{'arxiv_id': 'arXiv:2510.24976', 'title': 'Hammering the Diagnosis: Rowhammer-Induced Stealthy Trojan Attacks on ViT-Based Medical Imaging', 'authors': 'Banafsheh Saber Latibari, Najmeh Nazari, Hossein Sayadi, Houman Homayoun, Abhijit Mahalanobis', 'link': 'https://arxiv.org/abs/2510.24976', 'abstract': 'Vision Transformers (ViTs) have emerged as powerful architectures in medical image analysis, excelling in tasks such as disease detection, segmentation, and classification. However, their reliance on large, attention-driven models makes them vulnerable to hardware-level attacks. In this paper, we propose a novel threat model referred to as Med-Hammer that combines the Rowhammer hardware fault injection with neural Trojan attacks to compromise the integrity of ViT-based medical imaging systems. Specifically, we demonstrate how malicious bit flips induced via Rowhammer can trigger implanted neural Trojans, leading to targeted misclassification or suppression of critical diagnoses (e.g., tumors or lesions) in medical scans. Through extensive experiments on benchmark medical imaging datasets such as ISIC, Brain Tumor, and MedMNIST, we show that such attacks can remain stealthy while achieving high attack success rates about 82.51% and 92.56% in MobileViT and SwinTransformer, respectively. We further investigate how architectural properties, such as model sparsity, attention weight distribution, and the number of features of the layer, impact attack effectiveness. Our findings highlight a critical and underexplored intersection between hardware-level faults and deep learning security in healthcare applications, underscoring the urgent need for robust defenses spanning both model architectures and underlying hardware platforms.', 'abstract_zh': 'Vision Transformers (ViTs)åœ¨åŒ»å­¦å›¾åƒåˆ†æä¸­çš„å¼ºå¤§æ¶æ„å·²å¾—åˆ°è¯å®ï¼Œé€‚ç”¨äºç–¾ç—…æ£€æµ‹ã€åˆ†å‰²å’Œåˆ†ç±»ç­‰ä»»åŠ¡ã€‚ç„¶è€Œï¼Œå®ƒä»¬å¯¹å¤§å‹ã€åŸºäºæ³¨æ„åŠ›çš„æ¨¡å‹çš„ä¾èµ–æ€§ä½¿å®ƒä»¬æ˜“å—ç¡¬ä»¶å±‚é¢æ”»å‡»çš„å½±å“ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„å¨èƒæ¨¡å‹ï¼Œç§°ä¸ºMed-Hammerï¼Œè¯¥æ¨¡å‹ç»“åˆäº†Rowhammerç¡¬ä»¶æ•…éšœæ³¨å…¥å’Œç¥ç»ç‰¹æ´›ä¼Šæœ¨é©¬æ”»å‡»ï¼Œä»¥ç ´ååŸºäºViTçš„åŒ»å­¦æˆåƒç³»ç»Ÿçš„å®Œæ•´æ€§ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬å±•ç¤ºäº†é€šè¿‡Rowhammerå¼•èµ·çš„æ¶æ„ä½ç¿»è½¬å¯ä»¥è§¦å‘æ¤å…¥çš„ç¥ç»ç‰¹æ´›ä¼Šæœ¨é©¬ï¼Œè¿›è€Œå¯¼è‡´å¯¹åŒ»å­¦æ‰«æä¸­çš„å…³é”®è¯Šæ–­ï¼ˆå¦‚è‚¿ç˜¤æˆ–ç—…ç¶ï¼‰çš„æœ‰é’ˆå¯¹æ€§çš„è¯¯åˆ†ç±»æˆ–æŠ‘åˆ¶ã€‚é€šè¿‡åœ¨ISICã€Brain Tumorå’ŒMedMNISTç­‰åŸºå‡†åŒ»å­¦å›¾åƒæ•°æ®é›†ä¸Šè¿›è¡Œå¹¿æ³›çš„å®éªŒï¼Œæˆ‘ä»¬è¡¨æ˜è¿™äº›æ”»å‡»å¯ä»¥ä¿æŒéšç§˜æ€§ï¼Œåˆ†åˆ«åœ¨MobileViTå’ŒSwinTransformerä¸­è¾¾åˆ°çº¦82.51%å’Œ92.56%çš„é«˜æ”»å‡»æˆåŠŸç‡ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥ç ”ç©¶äº†æ¨¡å‹ç¨€ç–æ€§ã€æ³¨æ„åŠ›æƒé‡åˆ†å¸ƒå’Œå±‚ç‰¹å¾æ•°é‡ç­‰æ¶æ„ç‰¹æ€§å¦‚ä½•å½±å“æ”»å‡»æ•ˆæœã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœçªæ˜¾äº†ç¡¬ä»¶å±‚é¢æ•…éšœä¸åŒ»ç–—ä¿å¥åº”ç”¨ä¸­æ·±åº¦å­¦ä¹ å®‰å…¨ä¹‹é—´çš„å…³é”®ä¸”æœªå……åˆ†æ¢ç´¢çš„äº¤é›†ï¼Œå¼ºè°ƒäº†éœ€è¦åœ¨æ¨¡å‹æ¶æ„å’Œåº•å±‚ç¡¬ä»¶å¹³å°ä¸¤ä¸ªæ–¹é¢éƒ½å…·å¤‡å¼ºå¤§é˜²å¾¡æªæ–½çš„ç´§è¿«æ€§ã€‚', 'title_zh': 'é”¤å‡»è¯Šæ–­ï¼šåŸºäºRowhammerå¼•èµ·çš„éšç§˜åé—¨æ”»å‡»é’ˆå¯¹ViTåŒ»å­¦æˆåƒç³»ç»Ÿ'}
{'arxiv_id': 'arXiv:2510.24966', 'title': 'Sequences of Logits Reveal the Low Rank Structure of Language Models', 'authors': 'Noah Golowich, Allen Liu, Abhishek Shetty', 'link': 'https://arxiv.org/abs/2510.24966', 'abstract': "A major problem in the study of large language models is to understand their inherent low-dimensional structure. We introduce an approach to study the low-dimensional structure of language models at a model-agnostic level: as sequential probabilistic models. We first empirically demonstrate that a wide range of modern language models exhibit low-rank structure: in particular, matrices built from the model's logits for varying sets of prompts and responses have low approximate rank. We then show that this low-rank structure can be leveraged for generation -- in particular, we can generate a response to a target prompt using a linear combination of the model's outputs on unrelated, or even nonsensical prompts.\nOn the theoretical front, we observe that studying the approximate rank of language models in the sense discussed above yields a simple universal abstraction whose theoretical predictions parallel our experiments. We then analyze the representation power of the abstraction and give provable learning guarantees.", 'abstract_zh': 'å¤§å‹è¯­è¨€æ¨¡å‹ç ”ç©¶ä¸­çš„ä¸€ä¸ªä¸»è¦é—®é¢˜æ˜¯ç†è§£å…¶å›ºæœ‰çš„ä½ç»´åº¦ç»“æ„ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åœ¨æ¨¡å‹æ— å…³å±‚é¢ä¸Šç ”ç©¶è¯­è¨€æ¨¡å‹ä½ç»´åº¦ç»“æ„çš„æ–¹æ³•ï¼šä½œä¸ºåºè´¯æ¦‚ç‡æ¨¡å‹ã€‚æˆ‘ä»¬é¦–å…ˆå®éªŒè¯æ˜ï¼Œä¸€ç³»åˆ—ç°ä»£è¯­è¨€æ¨¡å‹è¡¨ç°å‡ºä½ç§©ç»“æ„ï¼šç‰¹åˆ«æ˜¯ï¼ŒåŸºäºæ¨¡å‹çš„ä¸åŒæç¤ºå’Œå“åº”æ„å»ºçš„çŸ©é˜µå…·æœ‰ä½è¿‘ä¼¼ç§©ã€‚ç„¶åæˆ‘ä»¬å±•ç¤ºäº†å¯ä»¥åˆ©ç”¨è¿™ç§ä½ç§©ç»“æ„è¿›è¡Œç”Ÿæˆâ€”â€”ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ¨¡å‹å¯¹æ— å…³ç”šè‡³æ— æ„ä¹‰æç¤ºçš„è¾“å‡ºçš„çº¿æ€§ç»„åˆç”Ÿæˆé’ˆå¯¹ç›®æ ‡æç¤ºçš„å“åº”ã€‚\n\nåœ¨ç†è®ºæ–¹é¢ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°ä»¥ä¸Šè¿°æ–¹å¼ç ”ç©¶è¯­è¨€æ¨¡å‹çš„è¿‘ä¼¼ç§©å¯ä»¥è·å¾—ä¸€ä¸ªç®€å•çš„æ™®éæŠ½è±¡ï¼Œå…¶ç†è®ºé¢„æµ‹ä¸æˆ‘ä»¬çš„å®éªŒç»“æœä¸€è‡´ã€‚æˆ‘ä»¬éšååˆ†æäº†è¯¥æŠ½è±¡çš„è¡¨ç¤ºèƒ½åŠ›ï¼Œå¹¶æä¾›äº†å¯è¯æ˜çš„å­¸ç¿’ä¿è¯ã€‚', 'title_zh': 'Logits åºåˆ—æ­ç¤ºäº†è¯­è¨€æ¨¡å‹çš„ä½ç§©ç»“æ„'}
{'arxiv_id': 'arXiv:2510.24949', 'title': 'SCOUT: A Lightweight Framework for Scenario Coverage Assessment in Autonomous Driving', 'authors': 'Anil Yildiz, Sarah M. Thornton, Carl Hildebrandt, Sreeja Roy-Singh, Mykel J. Kochenderfer', 'link': 'https://arxiv.org/abs/2510.24949', 'abstract': "Assessing scenario coverage is crucial for evaluating the robustness of autonomous agents, yet existing methods rely on expensive human annotations or computationally intensive Large Vision-Language Models (LVLMs). These approaches are impractical for large-scale deployment due to cost and efficiency constraints. To address these shortcomings, we propose SCOUT (Scenario Coverage Oversight and Understanding Tool), a lightweight surrogate model designed to predict scenario coverage labels directly from an agent's latent sensor representations. SCOUT is trained through a distillation process, learning to approximate LVLM-generated coverage labels while eliminating the need for continuous LVLM inference or human annotation. By leveraging precomputed perception features, SCOUT avoids redundant computations and enables fast, scalable scenario coverage estimation. We evaluate our method across a large dataset of real-life autonomous navigation scenarios, demonstrating that it maintains high accuracy while significantly reducing computational cost. Our results show that SCOUT provides an effective and practical alternative for large-scale coverage analysis. While its performance depends on the quality of LVLM-generated training labels, SCOUT represents a major step toward efficient scenario coverage oversight in autonomous systems.", 'abstract_zh': 'è¯„ä¼°åœºæ™¯è¦†ç›–å¯¹äºè¯„ä¼°è‡ªä¸»ä»£ç†çš„é²æ£’æ€§è‡³å…³é‡è¦ï¼Œä½†ç°æœ‰æ–¹æ³•ä¾èµ–æ˜‚è´µçš„äººå·¥æ³¨é‡Šæˆ–è®¡ç®—å¯†é›†å‹å¤§è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆLVLMï¼‰ã€‚è¿™äº›æ–¹æ³•ç”±äºæˆæœ¬å’Œæ•ˆç‡é™åˆ¶ï¼Œåœ¨å¤§è§„æ¨¡éƒ¨ç½²ä¸­ä¸åˆ‡å®é™…ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºSCOUTï¼ˆScenario Coverage Oversight and Understanding Toolï¼‰ï¼Œä¸€ç§è½»é‡çº§ä»£ç†æ¨¡å‹ï¼Œç›´æ¥ä»ä»£ç†çš„æ½œåœ¨ä¼ æ„Ÿå™¨è¡¨ç¤ºä¸­é¢„æµ‹åœºæ™¯è¦†ç›–æ ‡ç­¾ã€‚SCOUTé€šè¿‡distillationè¿‡ç¨‹è¿›è¡Œè®­ç»ƒï¼Œå­¦ä¹ è¿‘ä¼¼LVLMç”Ÿæˆçš„è¦†ç›–æ ‡ç­¾ï¼ŒåŒæ—¶æ¶ˆé™¤æŒç»­LVLMæ¨ç†æˆ–äººå·¥æ³¨é‡Šçš„éœ€è¦ã€‚åˆ©ç”¨å…ˆéªŒè®¡ç®—çš„æ„ŸçŸ¥ç‰¹å¾ï¼ŒSCOUTé¿å…äº†é‡å¤è®¡ç®—ï¼Œå¹¶ä½¿åœºæ™¯è¦†ç›–ä¼°è®¡å˜å¾—å¿«é€Ÿå’Œå¯æ‰©å±•ã€‚æˆ‘ä»¬åœ¨å¤§é‡çœŸå®è‡ªä¸»å¯¼èˆªåœºæ™¯æ•°æ®é›†ä¸Šè¯„ä¼°äº†è¯¥æ–¹æ³•ï¼Œç»“æœè¡¨æ˜ï¼Œå…¶åœ¨æ˜¾è‘—é™ä½æˆæœ¬çš„åŒæ—¶ä¿æŒäº†é«˜å‡†ç¡®æ€§ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒSCOUTä¸ºå¤§è§„æ¨¡è¦†ç›–åˆ†ææä¾›äº†æœ‰æ•ˆä¸”å®ç”¨çš„é€‰æ‹©ã€‚è™½ç„¶å…¶æ€§èƒ½ä¾èµ–äºLVLMç”Ÿæˆçš„è®­ç»ƒæ ‡ç­¾çš„è´¨é‡ï¼Œä½†SCOUTä»£è¡¨äº†è‡ªä¸»ç³»ç»Ÿä¸­é«˜æ•ˆåœºæ™¯è¦†ç›–ç›‘æ§çš„ä¸€ä¸ªé‡è¦è¿›å±•ã€‚', 'title_zh': 'SCOUTï¼šä¸€ç§è½»é‡çº§çš„è‡ªåŠ¨é©¾é©¶åœºæ™¯è¦†ç›–è¯„ä¼°æ¡†æ¶'}
{'arxiv_id': 'arXiv:2510.24942', 'title': 'Finding Culture-Sensitive Neurons in Vision-Language Models', 'authors': 'Xiutian Zhao, Rochelle Choenni, Rohit Saxena, Ivan Titov', 'link': 'https://arxiv.org/abs/2510.24942', 'abstract': 'Despite their impressive performance, vision-language models (VLMs) still struggle on culturally situated inputs. To understand how VLMs process culturally grounded information, we study the presence of culture-sensitive neurons, i.e. neurons whose activations show preferential sensitivity to inputs associated with particular cultural contexts. We examine whether such neurons are important for culturally diverse visual question answering and where they are located. Using the CVQA benchmark, we identify neurons of culture selectivity and perform causal tests by deactivating the neurons flagged by different identification methods. Experiments on three VLMs across 25 cultural groups demonstrate the existence of neurons whose ablation disproportionately harms performance on questions about the corresponding cultures, while having minimal effects on others. Moreover, we propose a new margin-based selector - Contrastive Activation Selection (CAS), and show that it outperforms existing probability- and entropy-based methods in identifying culture-sensitive neurons. Finally, our layer-wise analyses reveals that such neurons tend to cluster in certain decoder layers. Overall, our findings shed new light on the internal organization of multimodal representations.', 'abstract_zh': 'å°½ç®¡è§†è§‰è¯­è¨€æ¨¡å‹åœ¨æ€§èƒ½ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬ä»ç„¶éš¾ä»¥å¤„ç†æ–‡åŒ–ç‰¹å®šçš„è¾“å…¥ã€‚ä¸ºäº†ç†è§£è§†è§‰è¯­è¨€æ¨¡å‹å¦‚ä½•å¤„ç†æ–‡åŒ–æ¥åœ°çš„ä¿¡æ¯ï¼Œæˆ‘ä»¬ç ”ç©¶äº†æ–‡åŒ–æ•æ„Ÿç¥ç»å…ƒçš„å­˜åœ¨ï¼Œå³å¯¹ç‰¹å®šæ–‡åŒ–èƒŒæ™¯ç›¸å…³è¾“å…¥æ˜¾ç¤ºå‡ºåå¥½æ€§æ•æ„Ÿæ€§çš„ç¥ç»å…ƒã€‚æˆ‘ä»¬ç ”ç©¶è¿™ç±»ç¥ç»å…ƒæ˜¯å¦å¯¹æ–‡åŒ–å¤šæ ·æ€§çš„è§†è§‰é—®ç­”ä»»åŠ¡è‡³å…³é‡è¦ï¼Œä»¥åŠå®ƒä»¬çš„ä½ç½®ã€‚åˆ©ç”¨CVQAåŸºå‡†ï¼Œæˆ‘ä»¬è¯†åˆ«å‡ºäº†æ–‡åŒ–é€‰æ‹©æ€§çš„ç¥ç»å…ƒï¼Œå¹¶é€šè¿‡ä¸åŒè¯†åˆ«æ–¹æ³•æ ‡è®°çš„ç¥ç»å…ƒè¿›è¡Œå› æœæµ‹è¯•ã€‚åœ¨ä¸‰ç§è§†è§‰è¯­è¨€æ¨¡å‹ä¸Šçš„å®éªŒè·¨è¶Š25ä¸ªæ–‡åŒ–ç¾¤ä½“ï¼Œè¯æ˜äº†å­˜åœ¨ä¸€ç±»ç¥ç»å…ƒï¼Œå…¶ç¼ºå¤±ä¼šå¯¹ç›¸åº”æ–‡åŒ–é—®é¢˜çš„è§£ç­”æ€§èƒ½äº§ç”Ÿä¸æˆæ¯”ä¾‹çš„è´Ÿé¢å½±å“ï¼Œè€Œå¯¹å…¶ä»–é—®é¢˜å½±å“è¾ƒå°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ–°çš„åŸºäºè¾¹è·çš„é€‰æ‹©å™¨â€”å¯¹æ¯”æ¿€æ´»é€‰æ‹©ï¼ˆCASï¼‰ï¼Œå¹¶è¯æ˜å®ƒåœ¨è¯†åˆ«æ–‡åŒ–æ•æ„Ÿç¥ç»å…ƒæ–¹é¢ä¼˜äºç°æœ‰çš„åŸºäºæ¦‚ç‡å’Œç†µçš„æ–¹æ³•ã€‚æœ€åï¼Œæˆ‘ä»¬é€å±‚åˆ†æè¡¨æ˜ï¼Œè¿™ç±»ç¥ç»å…ƒå€¾å‘äºåœ¨æŸäº›è§£ç å±‚ä¸­èšé›†ã€‚æ€»ä½“è€Œè¨€ï¼Œæˆ‘ä»¬çš„å‘ç°ä¸ºå¤šæ¨¡æ€è¡¨ç¤ºçš„å†…éƒ¨ç»„ç»‡æä¾›äº†ä¸€ç§æ–°çš„è§è§£ã€‚', 'title_zh': 'å¯»æ‰¾è§†è§‰-è¯­è¨€æ¨¡å‹ä¸­çš„æ–‡åŒ–æ•æ„Ÿç¥ç»å…ƒ'}
{'arxiv_id': 'arXiv:2510.24926', 'title': 'KAN-GCN: Combining Kolmogorov-Arnold Network with Graph Convolution Network for an Accurate Ice Sheet Emulator', 'authors': 'Zesheng Liu, YoungHyun Koo, Maryam Rahnemoonfar', 'link': 'https://arxiv.org/abs/2510.24926', 'abstract': 'We introduce KAN-GCN, a fast and accurate emulator for ice sheet modeling that places a Kolmogorov-Arnold Network (KAN) as a feature-wise calibrator before graph convolution networks (GCNs). The KAN front end applies learnable one-dimensional warps and a linear mixing step, improving feature conditioning and nonlinear encoding without increasing message-passing depth. We employ this architecture to improve the performance of emulators for numerical ice sheet models. Our emulator is trained and tested using 36 melting-rate simulations with 3 mesh-size settings for Pine Island Glacier, Antarctica. Across 2- to 5-layer architectures, KAN-GCN matches or exceeds the accuracy of pure GCN and MLP-GCN baselines. Despite a small parameter overhead, KAN-GCN improves inference throughput on coarser meshes by replacing one edge-wise message-passing layer with a node-wise transform; only the finest mesh shows a modest cost. Overall, KAN-first designs offer a favorable accuracy vs. efficiency trade-off for large transient scenario sweeps.', 'abstract_zh': 'KAN-GCNï¼šä¸€ç§ç”¨äºå†°å·å»ºæ¨¡çš„å¿«é€Ÿå‡†ç¡®ä»¿çœŸå®ç°ï¼Œå…¶ä¸­Kolmogorov-Arnold Networkåœ¨å›¾å·ç§¯ç½‘ç»œä¹‹å‰ä½œä¸ºç‰¹å¾çº§æ ¡å‡†å™¨ã€‚', 'title_zh': 'KAN-GCNï¼šå°†æŸ¯å°”è«å“¥ç½—å¤«-é˜¿è¯ºå°”å¾·ç½‘ç»œä¸å›¾å·ç§¯ç½‘ç»œç›¸ç»“åˆä»¥æ„å»ºç²¾ç¡®çš„å†°ç›–æ¨¡æ‹Ÿå™¨'}
{'arxiv_id': 'arXiv:2510.24909', 'title': 'Trust Dynamics in Strategic Coopetition: Computational Foundations for Requirements Engineering in Multi-Agent Systems', 'authors': 'Vik Pant, Eric Yu', 'link': 'https://arxiv.org/abs/2510.24909', 'abstract': 'Requirements engineering increasingly occurs in multi-stakeholder environments where organizations simultaneously cooperate and compete, creating coopetitive relationships in which trust evolves dynamically based on observed behavior over repeated interactions. While conceptual modeling languages like i* represent trust relationships qualitatively, they lack computational mechanisms for analyzing how trust changes with behavioral evidence. Conversely, computational trust models from multi-agent systems provide algorithmic updating but lack grounding in requirements engineering contexts and conceptual models. This technical report bridges this gap by developing a computational trust model that extends game-theoretic foundations for strategic coopetition with dynamic trust evolution. We introduce trust as a two-layer system with immediate trust responding to current behavior and reputation tracking violation history. Trust evolves through asymmetric updating where cooperation builds trust gradually while violations erode it sharply, creating hysteresis effects and trust ceilings that constrain relationship recovery. We develop a structured translation framework enabling requirements engineers to instantiate computational trust models from i* dependency networks and organizational contexts. Comprehensive experimental validation across 78,125 parameter configurations establishes robust emergence of negativity bias, hysteresis effects, and cumulative damage amplification. Empirical validation using the Renault-Nissan Alliance case study (1999-2025) achieves 49 out of 60 validation points (81.7%), successfully reproducing documented trust evolution across five distinct relationship phases including crisis and recovery periods. This technical report builds upon its foundational companion work in arXiv:2510.18802.', 'abstract_zh': 'éœ€æ±‚å·¥ç¨‹ increasingly å‘ç”Ÿåœ¨å¤šåˆ©ç›Šç›¸å…³è€…ç¯å¢ƒä¸­ï¼Œç»„ç»‡åŒæ—¶åˆä½œä¸ç«äº‰ï¼Œå½¢æˆåŸºäºåå¤äº’åŠ¨ä¸­è§‚å¯Ÿåˆ°çš„è¡Œä¸ºåŠ¨æ€æ¼”å˜çš„ä¿¡ä»»å…³ç³»ã€‚è™½ç„¶åƒi*è¿™æ ·çš„æ¦‚å¿µå»ºæ¨¡è¯­è¨€èƒ½å¤Ÿå®šæ€§è¡¨ç¤ºä¿¡ä»»å…³ç³»ï¼Œä½†ç¼ºä¹ç”¨äºåˆ†æè¡Œä¸ºè¯æ®å¦‚ä½•å½±å“ä¿¡ä»»å˜åŒ–çš„è®¡ç®—æœºåˆ¶ã€‚ç›¸åï¼Œæ¥è‡ªå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„è®¡ç®—ä¿¡ä»»æ¨¡å‹è™½ç„¶æä¾›äº†ç®—æ³•æ›´æ–°æœºåˆ¶ï¼Œä½†åœ¨éœ€æ±‚å·¥ç¨‹èƒŒæ™¯å’Œæ¦‚å¿µæ¨¡å‹æ–¹é¢ç¼ºä¹æ ¹åŸºã€‚æœ¬æŠ€æœ¯æŠ¥å‘Šé€šè¿‡å‘å±•ä¸€ç§è®¡ç®—ä¿¡ä»»æ¨¡å‹æ¥å¼¥åˆè¿™ä¸€ç¼ºå£ï¼Œè¯¥æ¨¡å‹æ‰©å±•äº†åŸºäºæˆ˜ç•¥ç«äº‰çš„æ¸¸æˆç†è®ºåŸºç¡€ï¼Œå¹¶å¼•å…¥äº†åŠ¨æ€ä¿¡ä»»æ¼”å˜ã€‚æˆ‘ä»¬å¼•å…¥ä¿¡ä»»ä½œä¸ºä¸¤å±‚ç³»ç»Ÿï¼Œå³æ—¶ä¿¡ä»»å“åº”å½“å‰è¡Œä¸ºï¼Œå£°èª‰è¿½è¸ªè¿è§„å†å²ã€‚ä¿¡ä»»é€šè¿‡ä¸å¯¹ç§°æ›´æ–°æ¼”å˜ï¼Œåˆä½œé€æ­¥å»ºç«‹ä¿¡ä»»è€Œè¿è§„è¿…é€Ÿä¾µèš€ä¿¡ä»»ï¼Œäº§ç”Ÿæ»å›æ•ˆåº”å’Œä¿¡ä»»ä¸Šé™ï¼Œé™åˆ¶å…³ç³»æ¢å¤ã€‚æˆ‘ä»¬å¼€å‘äº†ä¸€ç§ç»“æ„åŒ–ç¿»è¯‘æ¡†æ¶ï¼Œä½¿éœ€æ±‚å·¥ç¨‹å¸ˆèƒ½å¤Ÿä»i*ä¾èµ–ç½‘ç»œå’Œç»„ç»‡èƒŒæ™¯å®ä¾‹åŒ–è®¡ç®—ä¿¡ä»»æ¨¡å‹ã€‚åœ¨78,125ä¸ªå‚æ•°é…ç½®çš„å…¨é¢å®éªŒéªŒè¯ä¸­ï¼Œå»ºç«‹äº†é²æ£’çš„æ¶ˆæåè§ã€æ»å›æ•ˆåº”å’Œç´¯ç§¯æŸå®³æ”¾å¤§ç°è±¡ã€‚é€šè¿‡å¯¹é›·è¯º-å°¼æ¡‘è”ç›Ÿæ¡ˆä¾‹ç ”ç©¶ï¼ˆ1999-2025ï¼‰çš„å®è¯éªŒè¯ï¼Œå®ç°äº†60ä¸ªéªŒè¯ç‚¹ä¸­çš„49ä¸ªï¼ˆ81.7%ï¼‰ï¼ŒæˆåŠŸå†ç°äº†äº”ä¸ªä¸åŒå…³ç³»é˜¶æ®µçš„ä¿¡ä»»æ¼”å˜ï¼ŒåŒ…æ‹¬å±æœºå’Œæ¢å¤æ—¶æœŸã€‚æœ¬æŠ€æœ¯æŠ¥å‘Šå»ºç«‹åœ¨å…¶arXiv:2510.18802çš„ foundational companion å·¥ä½œä¹‹ä¸Šã€‚', 'title_zh': 'æˆ˜ç•¥ç«åˆä¸­çš„ä¿¡ä»»åŠ¨æ€ï¼šå¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­éœ€æ±‚å·¥ç¨‹çš„è®¡ç®—åŸºç¡€'}
{'arxiv_id': 'arXiv:2510.24907', 'title': 'Understanding Multi-View Transformers', 'authors': 'Michal Stary, Julien Gaubil, Ayush Tewari, Vincent Sitzmann', 'link': 'https://arxiv.org/abs/2510.24907', 'abstract': "Multi-view transformers such as DUSt3R are revolutionizing 3D vision by solving 3D tasks in a feed-forward manner. However, contrary to previous optimization-based pipelines, the inner mechanisms of multi-view transformers are unclear. Their black-box nature makes further improvements beyond data scaling challenging and complicates usage in safety- and reliability-critical applications. Here, we present an approach for probing and visualizing 3D representations from the residual connections of the multi-view transformers' layers. In this manner, we investigate a variant of the DUSt3R model, shedding light on the development of its latent state across blocks, the role of the individual layers, and suggest how it differs from methods with stronger inductive biases of explicit global pose. Finally, we show that the investigated variant of DUSt3R estimates correspondences that are refined with reconstructed geometry. The code used for the analysis is available at this https URL .", 'abstract_zh': 'å¤šè§†å›¾å˜æ¢å™¨å¦‚DUSt3Ræ­£ä»¥ç«¯åˆ°ç«¯çš„æ–¹å¼è§£å†³3Dä»»åŠ¡ï¼Œ revolutionizing 3Dè§†è§‰ã€‚ç„¶è€Œï¼Œä¸ä¹‹å‰çš„ä¼˜åŒ–ç®¡é“ä¸åŒï¼Œå¤šè§†å›¾å˜æ¢å™¨çš„å†…éƒ¨æœºåˆ¶å°šä¸æ˜ç¡®ã€‚å®ƒä»¬çš„é»‘ç›’æ€§è´¨ä½¿å¾—åœ¨æ•°æ®é‡æ‰©å±•ä¹‹å¤–çš„è¿›ä¸€æ­¥æ”¹è¿›å˜å¾—å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå¹¶ä¸”åœ¨å®‰å…¨æ€§å’Œå¯é æ€§å…³é”®åº”ç”¨ä¸­å¤æ‚åŒ–äº†å…¶ä½¿ç”¨ã€‚åœ¨æ­¤ï¼Œæˆ‘ä»¬æå‡ºä¸€ç§æ–¹æ³•æ¥æ¢æµ‹å’Œå¯è§†åŒ–å¤šè§†å›¾å˜æ¢å™¨å±‚çš„æ®‹å·®è¿æ¥ä¸­çš„3Dè¡¨ç¤ºã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬æ¢è®¨äº†DUSt3Ræ¨¡å‹çš„ä¸€ç§å˜ä½“ï¼Œæ­ç¤ºäº†å…¶æ½œåœ¨çŠ¶æ€åœ¨å—é—´çš„å‘å±•ã€å„å±‚çš„ä½œç”¨ï¼Œå¹¶å»ºè®®å®ƒä¸å…·æœ‰æ›´å¼ºæ˜¾å¼å…¨å±€å§¿æ€å½’çº³åç½®çš„æ–¹æ³•ä¹‹é—´çš„å·®å¼‚ã€‚æœ€åï¼Œæˆ‘ä»¬è¡¨æ˜ï¼Œæ‰€ç ”ç©¶çš„DUSt3Rå˜ä½“ä¼°è®¡çš„å¯¹åº”å…³ç³»æ˜¯é€šè¿‡é‡å»ºå‡ ä½•å½¢çŠ¶è¿›è¡Œç»†åŒ–çš„ã€‚ç”¨äºåˆ†æçš„ä»£ç å¯åœ¨ä»¥ä¸‹ç½‘å€è·å¾—ï¼šthis https URLã€‚', 'title_zh': 'å¤šè§†è§’å˜æ¢å™¨ç†è§£'}
{'arxiv_id': 'arXiv:2510.24906', 'title': 'Fair Indivisible Payoffs through Shapley Value', 'authors': 'MikoÅ‚aj Czarnecki, MichaÅ‚ Korniak, Oskar Skibski, Piotr Skowron', 'link': 'https://arxiv.org/abs/2510.24906', 'abstract': 'We consider the problem of payoff division in indivisible coalitional games, where the value of the grand coalition is a natural number. This number represents a certain quantity of indivisible objects, such as parliamentary seats, kidney exchanges, or top features contributing to the outcome of a machine learning model. The goal of this paper is to propose a fair method for dividing these objects among players. To achieve this, we define the indivisible Shapley value and study its properties. We demonstrate our proposed technique using three case studies, in particular, we use it to identify key regions of an image in the context of an image classification task.', 'abstract_zh': 'æˆ‘ä»¬è€ƒè™‘åœ¨ indivisible æŠ•ç¥¨æ¸¸æˆä¸­æ”¶ç›Šåˆ†é…çš„é—®é¢˜ï¼Œå…¶ä¸­å…¨ä½“è”ç›Ÿçš„ä»·å€¼æ˜¯ä¸€ä¸ªè‡ªç„¶æ•°ã€‚è¿™ä¸ªæ•°å€¼ä»£è¡¨ä¸€å®šæ•°é‡çš„ indivisible ç‰©ä½“ï¼Œä¾‹å¦‚è®®ä¼šå¸­ä½ã€è‚¾è„äº¤æ¢ï¼Œæˆ–å¯¹æœºå™¨å­¦ä¹ æ¨¡å‹ç»“æœæœ‰é‡è¦è´¡çŒ®çš„é¡¶çº§ç‰¹å¾ã€‚æœ¬æ–‡çš„ç›®æ ‡æ˜¯æå‡ºä¸€ç§å…¬å¹³çš„ç‰©ä½“åˆ†é…æ–¹æ³•ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å®šä¹‰äº† indivisible Shapley å€¼å¹¶ç ”ç©¶äº†å…¶æ€§è´¨ã€‚æˆ‘ä»¬é€šè¿‡ä¸‰ä¸ªæ¡ˆä¾‹ç ”ç©¶æ¼”ç¤ºäº†æˆ‘ä»¬æå‡ºçš„æŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯åœ¨å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­è¯†åˆ«å›¾åƒçš„å…³é”®åŒºåŸŸæ–¹é¢åº”ç”¨äº†è¿™ç§æ–¹æ³•ã€‚', 'title_zh': 'å…¬å¹³åˆ†é…ä¸å¯åˆ†æ”¯ä»˜çš„èˆç”«ç´ç§‘å€¼æ–¹æ³•'}
{'arxiv_id': 'arXiv:2510.24893', 'title': 'Efficiency Without Cognitive Change: Evidence from Human Interaction with Narrow AI Systems', 'authors': 'MarÃ­a AngÃ©lica BenÃ­tez, RocÃ­o Candela Ceballos, Karina Del Valle Molina, SofÃ­a Mundo Araujo, SofÃ­a Evangelina Victorio Villaroel, Nadia Justel', 'link': 'https://arxiv.org/abs/2510.24893', 'abstract': 'The growing integration of artificial intelligence (AI) into human cognition raises a fundamental question: does AI merely improve efficiency, or does it alter how we think? This study experimentally tested whether short-term exposure to narrow AI tools enhances core cognitive abilities or simply optimizes task performance. Thirty young adults completed standardized neuropsychological assessments embedded in a seven-week protocol with a four-week online intervention involving problem-solving and verbal comprehension tasks, either with or without AI support (ChatGPT). While AI-assisted participants completed several tasks faster and more accurately, no significant pre-post differences emerged in standardized measures of problem solving or verbal comprehension. These results demonstrate efficiency gains without cognitive change, suggesting that current narrow AI systems serve as cognitive scaffolds extending performance without transforming underlying mental capacities. The findings highlight the need for ethical and educational frameworks that promote critical and autonomous thinking in an increasingly AI-augmented cognitive ecology.', 'abstract_zh': 'äººå·¥æ™ºèƒ½èå…¥äººç±»è®¤çŸ¥çš„åŠ æ·±å¼•å‘äº†åŸºæœ¬é—®é¢˜ï¼šäººå·¥æ™ºèƒ½æ˜¯æé«˜æ•ˆç‡ï¼Œè¿˜æ˜¯æ”¹å˜äº†æˆ‘ä»¬çš„æ€ç»´æ–¹å¼ï¼Ÿæœ¬ç ”ç©¶é€šè¿‡å®éªŒæ£€éªŒäº†çŸ­æœŸå†…ä½¿ç”¨çª„äººå·¥æ™ºèƒ½å·¥å…·æ˜¯å¦èƒ½å¢å¼ºæ ¸å¿ƒè®¤çŸ¥èƒ½åŠ›ï¼Œè¿˜æ˜¯ä»…ä¼˜åŒ–ä»»åŠ¡æ€§èƒ½ã€‚ä¸‰ååå¹´è½»æˆäººåœ¨ä¸€ä¸ªåŒ…å«ä¸ƒå‘¨åè®®å’Œå››å‘¨åœ¨çº¿å¹²é¢„çš„è®¡åˆ’ä¸­å®Œæˆäº†æ ‡å‡†åŒ–ç¥ç»å¿ƒç†è¯„ä¼°ï¼Œå¹²é¢„æœŸé—´æ¶‰åŠè§£å†³é—®é¢˜å’Œè¨€è¯­ç†è§£ä»»åŠ¡ï¼Œæœ‰æˆ–æ²¡æœ‰äººå·¥æ™ºèƒ½æ”¯æŒï¼ˆChatGPTï¼‰ã€‚å°½ç®¡äººå·¥æ™ºèƒ½è¾…åŠ©çš„å‚ä¸è€…åœ¨å®Œæˆå¤šé¡¹ä»»åŠ¡æ—¶é€Ÿåº¦æ›´å¿«ã€æ›´å‡†ç¡®ï¼Œä½†åœ¨æ ‡å‡†åŒ–çš„é—®é¢˜è§£å†³å’Œè¨€è¯­ç†è§£æµ‹é‡ä¸­ä»æ— æ˜¾è‘—çš„å‰åå·®å¼‚ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œæ•ˆç‡å¢ç›Šä¼´éšç€è®¤çŸ¥ä¸å˜ï¼Œæš—ç¤ºå½“å‰çš„çª„äººå·¥æ™ºèƒ½ç³»ç»Ÿä½œä¸ºè®¤çŸ¥æ”¯æ¶ï¼Œæ‰©å±•äº†æ€§èƒ½ä½†æœªè½¬å˜åŸºæœ¬çš„å¿ƒç†èƒ½åŠ›ã€‚ç ”ç©¶ç»“æœå¼ºè°ƒäº†åœ¨æ—¥ç›Šä»¥äººå·¥æ™ºèƒ½å¢å¼ºçš„è®¤çŸ¥ç”Ÿæ€ä¸­ä¿ƒè¿›æ‰¹åˆ¤æ€§å’Œè‡ªä¸»æ€§æ€è€ƒçš„ä¼¦ç†å’Œæ•™è‚²æ¡†æ¶çš„å¿…è¦æ€§ã€‚', 'title_zh': 'æ— éœ€è®¤çŸ¥å˜åŒ–çš„æ•ˆç‡æå‡ï¼šæ¥è‡ªäººç±»ä¸çª„AIç³»ç»Ÿäº¤äº’çš„è¯æ®'}
{'arxiv_id': 'arXiv:2510.24831', 'title': 'The Narrative Continuity Test: A Conceptual Framework for Evaluating Identity Persistence in AI Systems', 'authors': 'Stefano Natangelo', 'link': 'https://arxiv.org/abs/2510.24831', 'abstract': 'Artificial intelligence systems based on large language models (LLMs) can now generate coherent text, music, and images, yet they operate without a persistent state: each inference reconstructs context from scratch. This paper introduces the Narrative Continuity Test (NCT) -- a conceptual framework for evaluating identity persistence and diachronic coherence in AI systems. Unlike capability benchmarks that assess task performance, the NCT examines whether an LLM remains the same interlocutor across time and interaction gaps. The framework defines five necessary axes -- Situated Memory, Goal Persistence, Autonomous Self-Correction, Stylistic & Semantic Stability, and Persona/Role Continuity -- and explains why current architectures systematically fail to support them. Case analyses (this http URL, Grok, Replit, Air Canada) show predictable continuity failures under stateless inference. The NCT reframes AI evaluation from performance to persistence, outlining conceptual requirements for future benchmarks and architectural designs that could sustain long-term identity and goal coherence in generative models.', 'abstract_zh': 'åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ artificial intelligence ç³»ç»Ÿèƒ½å¤Ÿç”Ÿæˆè¿è´¯çš„æ–‡æœ¬ã€éŸ³ä¹å’Œå›¾åƒï¼Œä½†å®ƒä»¬ç¼ºä¹æŒä¹…çŠ¶æ€ï¼šæ¯æ¬¡æ¨ç†éƒ½éœ€è¦ä»å¤´æ„å»ºä¸Šä¸‹æ–‡ã€‚æœ¬æ–‡ä»‹ç»äº†å™äº‹è¿ç»­æ€§æµ‹è¯•ï¼ˆNCTï¼‰â€”â€”ä¸€ç§è¯„ä¼° AI ç³»ç»Ÿçš„èº«ä»½æŒä¹…æ€§å’Œå†æ—¶è¿è´¯æ€§çš„æ¦‚å¿µæ¡†æ¶ã€‚ä¸åŒäºè¯„ä¼°ä»»åŠ¡æ€§èƒ½çš„èƒ½åŠ›åŸºå‡†ï¼ŒNCT è€ƒå¯Ÿ LLM æ˜¯å¦èƒ½åœ¨æ—¶é—´ä¸äº¤äº’é—´éš”ä¸­ä¿æŒåŒä¸€å¯¹è¯ä¼™ä¼´çš„èº«ä»½ã€‚è¯¥æ¡†æ¶å®šä¹‰äº†äº”ä¸ªå¿…è¦ç»´åº¦â€”â€”æƒ…å¢ƒè®°å¿†ã€ç›®æ ‡æŒä¹…æ€§ã€è‡ªä¸»è‡ªæˆ‘çº æ­£ã€é£æ ¼å’Œè¯­ä¹‰ç¨³å®šæ€§ä»¥åŠäººè®¾/è§’è‰²è¿ç»­æ€§ï¼Œå¹¶è§£é‡Šäº†å½“å‰æ¶æ„ä¸ºä½•ç³»ç»Ÿæ€§åœ°æ— æ³•æ”¯æŒè¿™äº›ç»´åº¦ã€‚æ¡ˆä¾‹åˆ†æï¼ˆé“¾æ¥ï¼ŒGrokï¼ŒReplitï¼ŒAir Canadaï¼‰æ˜¾ç¤ºï¼Œåœ¨æ— çŠ¶æ€æ¨ç†ä¸‹å¯é¢„æµ‹çš„èº«ä»½è¿ç»­æ€§å¤±è´¥ã€‚NCT å°† AI è¯„ä¼°ä»æ€§èƒ½è½¬å‘æŒä¹…æ€§ï¼Œæ¦‚è¿°äº†æœªæ¥åŸºå‡†å’Œæ¶æ„è®¾è®¡çš„æ¦‚å¿µè¦æ±‚ï¼Œä»¥åœ¨ç”Ÿæˆæ¨¡å‹ä¸­ç»´æŒé•¿æœŸèº«ä»½å’Œç›®æ ‡è¿è´¯æ€§ã€‚', 'title_zh': 'å™äº‹è¿ç»­æ€§æµ‹è¯•ï¼šè¯„ä¼°AIç³»ç»Ÿä¸­èº«ä»½æŒä¹…æ€§çš„æ¦‚å¿µæ¡†æ¶'}
{'arxiv_id': 'arXiv:2510.24830', 'title': 'The Generation Phases of Flow Matching: a Denoising Perspective', 'authors': 'Anne Gagneux, SÃ©golÃ¨ne Martin, RÃ©mi Gribonval, Mathurin Massias', 'link': 'https://arxiv.org/abs/2510.24830', 'abstract': 'Flow matching has achieved remarkable success, yet the factors influencing the quality of its generation process remain poorly understood. In this work, we adopt a denoising perspective and design a framework to empirically probe the generation process. Laying down the formal connections between flow matching models and denoisers, we provide a common ground to compare their performances on generation and denoising. This enables the design of principled and controlled perturbations to influence sample generation: noise and drift. This leads to new insights on the distinct dynamical phases of the generative process, enabling us to precisely characterize at which stage of the generative process denoisers succeed or fail and why this matters.', 'abstract_zh': 'æµåŒ¹é…å·²ç»å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸï¼Œä½†å…¶ç”Ÿæˆè¿‡ç¨‹è´¨é‡çš„å½±å“å› ç´ ä»ä¸å®Œå…¨ç†è§£ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»å»å™ªçš„è§’åº¦å‡ºå‘ï¼Œè®¾è®¡äº†ä¸€ä¸ªæ¡†æ¶æ¥å®è¯æ¢ç©¶ç”Ÿæˆè¿‡ç¨‹ã€‚é€šè¿‡æ­£å¼å»ºç«‹æµåŒ¹é…æ¨¡å‹ä¸å»å™ªå™¨ä¹‹é—´çš„è”ç³»ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªæ¯”è¾ƒå®ƒä»¬åœ¨ç”Ÿæˆå’Œå»å™ªæ€§èƒ½çš„å…±åŒå¹³å°ã€‚è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿè®¾è®¡å‡ºåŸåˆ™æ€§çš„å’Œå—æ§çš„æ‰°åŠ¨æ¥å½±å“æ ·æœ¬ç”Ÿæˆï¼šå™ªå£°å’Œæ¼‚ç§»ã€‚è¿™å¯¼è‡´äº†å¯¹ç”Ÿæˆè¿‡ç¨‹ä¸åŒåŠ¨åŠ›å­¦é˜¶æ®µçš„æ–°è§è§£ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿç²¾ç¡®åœ° characterize åœ¨ç”Ÿæˆè¿‡ç¨‹çš„å“ªä¸ªé˜¶æ®µå»å™ªå™¨æˆåŠŸæˆ–å¤±è´¥ä»¥åŠä¸ºä»€ä¹ˆè¿™ä¸€ç‚¹å¾ˆé‡è¦ã€‚', 'title_zh': 'æµåŒ¹é…çš„ç”Ÿæˆé˜¶æ®µï¼šä¸€ç§å»å™ªè§†è§’'}
{'arxiv_id': 'arXiv:2510.24823', 'title': 'Do Chatbots Walk the Talk of Responsible AI?', 'authors': 'Susan Ariel Aaronson, Michael Moreno', 'link': 'https://arxiv.org/abs/2510.24823', 'abstract': 'This study examines whether leading AI chatbot companies implement the responsible AI principles they publicly advocate. The authors used a mixed-methods approach analyzing four major chatbots (ChatGPT, Gemini, DeepSeek, and Grok) across company websites, technical documentation, and direct chatbot evaluations. We found significant gaps between corporate rhetoric and practice.', 'abstract_zh': 'æœ¬ç ”ç©¶è€ƒå¯Ÿé¢†å…ˆçš„äººå·¥æ™ºèƒ½èŠå¤©æœºå™¨äººå…¬å¸æ˜¯å¦å®æ–½äº†ä»–ä»¬å…¬å¼€å€¡å¯¼çš„è´£ä»»äººå·¥æ™ºèƒ½åŸåˆ™ã€‚ä½œè€…é‡‡ç”¨æ··åˆæ–¹æ³•ï¼Œåˆ†æäº†å››æ¬¾ä¸»è¦èŠå¤©æœºå™¨äººï¼ˆChatGPTã€Geminiã€DeepSeek å’Œ Grokï¼‰åœ¨å…¬å¸ç½‘ç«™ã€æŠ€æœ¯æ–‡æ¡£ä»¥åŠç›´æ¥èŠå¤©æœºå™¨äººè¯„ä¼°ä¸­çš„å†…å®¹ï¼Œå‘ç°ä¼ä¸š rhetoric ä¸å®è·µä¹‹é—´å­˜åœ¨æ˜¾è‘—å·®è·ã€‚', 'title_zh': 'èŠå¤©æœºå™¨äººæ˜¯å¦è·µè¡Œäº†è´Ÿè´£ä»»çš„äººå·¥æ™ºèƒ½ï¼Ÿ'}
{'arxiv_id': 'arXiv:2510.24821', 'title': 'Ming-Flash-Omni: A Sparse, Unified Architecture for Multimodal Perception and Generation', 'authors': 'Inclusion AI, Bowen Ma, Cheng Zou, Canxiang Yan, Chunxiang Jin, Chunjie Shen, Dandan Zheng, Fudong Wang, Furong Xu, GuangMing Yao, Jun Zhou, Jingdong Chen, Jianing Li, Jianxin Sun, Jiajia Liu, Jianjiang Zhu, Jianping Jiang, Jun Peng, Kaixiang Ji, Kaimeng Ren, Libin Wang, Lixiang Ru, Longhua Tan, Lan Wang, Mochen Bai, Ning Gao, Qingpei Guo, Qinglong Zhang, Qiang Xu, Rui Liu, Ruijie Xiong, Ruobing Zheng, Sirui Gao, Tianqi Li, Tinghao Liu, Weilong Chai, Xinyu Xiao, Xiaomei Wang, Xiaolong Wang, Xiao Lu, Xiaoyu Li, Xingning Dong, Xuzheng Yu, Yi Yuan, Yuting Gao, Yuting Xiao, Yunxiao Sun, Yipeng Chen, Yifan Mao, Yifei Wu, Yongjie Lyu, Ziping Ma, Zhiqiang Fang, Zhihao Qiu, Ziyuan Huang, Zizheng Yang, Zhengyu He', 'link': 'https://arxiv.org/abs/2510.24821', 'abstract': 'We propose Ming-Flash-Omni, an upgraded version of Ming-Omni, built upon a sparser Mixture-of-Experts (MoE) variant of Ling-Flash-2.0 with 100 billion total parameters, of which only 6.1 billion are active per token. This architecture enables highly efficient scaling (dramatically improving computational efficiency while significantly expanding model capacity) and empowers stronger unified multimodal intelligence across vision, speech, and language, representing a key step toward Artificial General Intelligence (AGI). Compared to its predecessor, the upgraded version exhibits substantial improvements across multimodal understanding and generation. We significantly advance speech recognition capabilities, achieving state-of-the-art performance in contextual ASR and highly competitive results in dialect-aware ASR. In image generation, Ming-Flash-Omni introduces high-fidelity text rendering and demonstrates marked gains in scene consistency and identity preservation during image editing. Furthermore, Ming-Flash-Omni introduces generative segmentation, a capability that not only achieves strong standalone segmentation performance but also enhances spatial control in image generation and improves editing consistency. Notably, Ming-Flash-Omni achieves state-of-the-art results in text-to-image generation and generative segmentation, and sets new records on all 12 contextual ASR benchmarks, all within a single unified architecture.', 'abstract_zh': 'Ming-Flash-Omni: å‡çº§ç‰ˆMing-Omniï¼Œä¸€ç§åŸºäºç¨€ç–Mixture-of-Expertså˜ä½“çš„é«˜æ•ˆç»Ÿä¸€å¤šæ¨¡æ€æ™ºèƒ½æ¶æ„', 'title_zh': 'æ˜é—ªé€šæ„Ÿï¼šä¸€ç§ç¨€ç–çš„ç»Ÿä¸€å¤šæ¨¡æ€æ„ŸçŸ¥ä¸ç”Ÿæˆæ¶æ„'}
{'arxiv_id': 'arXiv:2510.24820', 'title': 'SafeEditor: Unified MLLM for Efficient Post-hoc T2I Safety Editing', 'authors': 'Ruiyang Zhang, Jiahao Luo, Xiaoru Feng, Qiufan Pang, Yaodong Yang, Juntao Dai', 'link': 'https://arxiv.org/abs/2510.24820', 'abstract': 'With the rapid advancement of text-to-image (T2I) models, ensuring their safety has become increasingly critical. Existing safety approaches can be categorized into training-time and inference-time methods. While inference-time methods are widely adopted due to their cost-effectiveness, they often suffer from limitations such as over-refusal and imbalance between safety and utility. To address these challenges, we propose a multi-round safety editing framework that functions as a model-agnostic, plug-and-play module, enabling efficient safety alignment for any text-to-image model. Central to this framework is MR-SafeEdit, a multi-round image-text interleaved dataset specifically constructed for safety editing in text-to-image generation. We introduce a post-hoc safety editing paradigm that mirrors the human cognitive process of identifying and refining unsafe content. To instantiate this paradigm, we develop SafeEditor, a unified MLLM capable of multi-round safety editing on generated images. Experimental results show that SafeEditor surpasses prior safety approaches by reducing over-refusal while achieving a more favorable safety-utility balance.', 'abstract_zh': 'éšç€æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰æ¨¡å‹çš„è¿…é€Ÿå‘å±•ï¼Œç¡®ä¿å…¶å®‰å…¨æ€§å˜å¾—æ„ˆå‘é‡è¦ã€‚ç°æœ‰çš„å®‰å…¨æ–¹æ³•å¯ä»¥åˆ†ä¸ºè®­ç»ƒæ—¶å’Œæ¨ç†æ—¶æ–¹æ³•ã€‚å°½ç®¡æ¨ç†æ—¶æ–¹æ³•ç”±äºæˆæœ¬æ•ˆç›Šé«˜è€Œè¢«å¹¿æ³›é‡‡ç”¨ï¼Œä½†å®ƒä»¬å¾€å¾€å—åˆ°è¿‡åº¦æ‹’ç»å’Œå®‰å…¨ä¸ç”¨é€”ä¹‹é—´çš„ä¸å¹³è¡¡ç­‰é™åˆ¶ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¤šè½®å®‰å…¨ç¼–è¾‘æ¡†æ¶ï¼Œä½œä¸ºæ¨¡å‹æ— å…³ã€å³æ’å³ç”¨çš„æ¨¡å—ï¼Œèƒ½å¤Ÿé«˜æ•ˆåœ°å¯¹ä»»ä½•æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹è¿›è¡Œå®‰å…¨å¯¹é½ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒæ˜¯MR-SafeEditï¼Œè¿™æ˜¯ä¸€ç§ä¸“é—¨ä¸ºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„å®‰å…¨ç¼–è¾‘è®¾è®¡çš„å¤šè½®å›¾åƒ-æ–‡æœ¬äº¤é”™æ•°æ®é›†ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§äº‹åå®‰å…¨ç¼–è¾‘èŒƒå¼ï¼Œæ¨¡æ‹Ÿäº†äººç±»è®¤çŸ¥è¿‡ç¨‹ä¸­çš„è¯†åˆ«å’Œç²¾ç‚¼ä¸å®‰å…¨å†…å®¹ã€‚ä¸ºäº†å®ç°è¿™ä¸€èŒƒå¼ï¼Œæˆ‘ä»¬å¼€å‘äº†SafeEditorï¼Œä¸€ç§ç»Ÿä¸€çš„MLLMï¼Œèƒ½å¤Ÿå¯¹ç”Ÿæˆçš„å›¾åƒè¿›è¡Œå¤šè½®å®‰å…¨ç¼–è¾‘ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSafeEditorè¶…è¶Šäº†å…ˆå‰çš„å®‰å…¨æ–¹æ³•ï¼Œå‡å°‘äº†è¿‡åº¦æ‹’ç»ï¼Œå¹¶å®ç°äº†æ›´ä¼˜çš„å®‰å…¨ä¸ç”¨é€”å¹³è¡¡ã€‚', 'title_zh': 'SafeEditor: ç»Ÿä¸€çš„MLLMé«˜æ•ˆåéªŒT2Iå®‰å…¨æ€§ç¼–è¾‘'}
{'arxiv_id': 'arXiv:2510.24817', 'title': 'Towards a Method for Synthetic Generation of PWA Transcripts', 'authors': 'Jason M. Pittman, Anton Phillips Jr., Yesenia Medina-Santos, Brielle C. Stark', 'link': 'https://arxiv.org/abs/2510.24817', 'abstract': 'In aphasia research, Speech-Language Pathologists (SLPs) devote extensive time to manually coding speech samples using Correct Information Units (CIUs), a measure of how informative an individual sample of speech is. Developing automated systems to recognize aphasic language is limited by data scarcity. For example, only about 600 transcripts are available in AphasiaBank yet billions of tokens are used to train large language models (LLMs). In the broader field of machine learning (ML), researchers increasingly turn to synthetic data when such are sparse. Therefore, this study constructs and validates two methods to generate synthetic transcripts of the AphasiaBank Cat Rescue picture description task. One method leverages a procedural programming approach while the second uses Mistral 7b Instruct and Llama 3.1 8b Instruct LLMs. The methods generate transcripts across four severity levels (Mild, Moderate, Severe, Very Severe) through word dropping, filler insertion, and paraphasia substitution. Overall, we found, compared to human-elicited transcripts, Mistral 7b Instruct best captures key aspects of linguistic degradation observed in aphasia, showing realistic directional changes in NDW, word count, and word length amongst the synthetic generation methods. Based on the results, future work should plan to create a larger dataset, fine-tune models for better aphasic representation, and have SLPs assess the realism and usefulness of the synthetic transcripts.', 'abstract_zh': 'åœ¨å¤±è¯­ç—‡ç ”ç©¶ä¸­ï¼Œè¨€è¯­-è¯­è¨€ç—…ç†å­¦å®¶ï¼ˆSLPsï¼‰å¤§é‡æ—¶é—´ç”¨äºæ‰‹åŠ¨ç¼–ç è¯­éŸ³æ ·æœ¬ï¼Œä½¿ç”¨æ­£ç¡®çš„ä¿¡æ¯å•å…ƒï¼ˆCIUsï¼‰æ¥è¡¡é‡å•ä¸ªè¯­éŸ³æ ·æœ¬çš„ä¿¡æ¯é‡ã€‚ç”±äºæ•°æ®ç¨€ç¼ºï¼Œè‡ªåŠ¨ç³»ç»Ÿè¯†åˆ«å¤±è¯­è¯­è¨€çš„èƒ½åŠ›å—é™ã€‚ä¾‹å¦‚ï¼Œè™½ç„¶AphasiaBankä¸­æœ‰å¤§çº¦600ä»½è½¬å½•æ–‡æœ¬ï¼Œä½†ç”¨äºè®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¯å…ƒæ•°é‡å´æœ‰æ•°åäº¿ã€‚åœ¨æ›´å¹¿æ³›çš„æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰é¢†åŸŸï¼Œç ”ç©¶äººå‘˜åœ¨æ•°æ®ç¨€ç¼ºæ—¶è¶Šæ¥è¶Šå¤šåœ°è½¬å‘åˆæˆæ•°æ®ã€‚å› æ­¤ï¼Œæœ¬ç ”ç©¶æ„å»ºå¹¶éªŒè¯äº†ä¸¤ç§ç”ŸæˆAphasiaBank Cat Rescueå›¾ç‰‡æè¿°ä»»åŠ¡åˆæˆè½¬å½•æ–‡çš„æ–¹æ³•ã€‚ä¸€ç§æ–¹æ³•å€ŸåŠ©è¿‡ç¨‹åŒ–ç¼–ç¨‹æ–¹æ³•ï¼Œå¦ä¸€ç§åˆ™ä½¿ç”¨Mistral 7b Instructå’ŒLlama 3.1 8b Instructå¤§å‹è¯­è¨€æ¨¡å‹ã€‚è¿™ä¸¤ç§æ–¹æ³•é€šè¿‡è¯æ±‡åˆ é™¤ã€å¡«å……æ’å…¥å’Œæ”¹å†™ç”Ÿæˆäº†å››çº§ä¸¥é‡ç¨‹åº¦ï¼ˆè½»åº¦ã€ä¸­åº¦ã€é‡åº¦ã€æé‡åº¦ï¼‰çš„è½¬å½•æ–‡ã€‚æ€»ä½“è€Œè¨€ï¼Œæˆ‘ä»¬å‘ç°ä¸äººç±»è¯±å‘å‹è½¬å½•æ–‡ç›¸æ¯”ï¼ŒMistral 7b Instructæœ€èƒ½æ•æ‰å¤±è¯­ä¸­è§‚å¯Ÿåˆ°çš„è¯­è¨€é€€åŒ–å…³é”®æ–¹é¢ï¼Œæ˜¾ç¤ºå‡ºåˆæˆç”Ÿæˆæ–¹æ³•åœ¨éå¯†åº¦è¯ã€è¯æ±‡é‡å’Œè¯é•¿ä¸Šçš„ç°å®æ–¹å‘å˜åŒ–ã€‚åŸºäºç»“æœï¼Œæœªæ¥å·¥ä½œåº”è®¡åˆ’åˆ›å»ºæ›´å¤§çš„æ•°æ®é›†ã€ä¸ºæ›´å¥½åœ°è¡¨å¾å¤±è¯­å¾®è°ƒæ¨¡å‹ï¼Œå¹¶è®©SLPsè¯„ä¼°åˆæˆè½¬å½•æ–‡çš„ç°å®æ€§å’Œå®ç”¨æ€§ã€‚', 'title_zh': 'é¢å‘PWAè½¬å½•åˆæˆçš„æ–¹æ³•ç ”ç©¶'}
{'arxiv_id': 'arXiv:2510.24816', 'title': 'Perception, Understanding and Reasoning, A Multimodal Benchmark for Video Fake News Detection', 'authors': 'Cui Yakun, Fushuo Huo, Weijie Shi, Juntao Dai, Hang Du, Zhenghao Zhu, Sirui Han, Yike Guo', 'link': 'https://arxiv.org/abs/2510.24816', 'abstract': "The advent of multi-modal large language models (MLLMs) has greatly advanced research into applications for Video fake news detection (VFND) tasks. Traditional video-based FND benchmarks typically focus on the accuracy of the final decision, often failing to provide fine-grained assessments for the entire detection process, making the detection process a black box. Therefore, we introduce the MVFNDB (Multi-modal Video Fake News Detection Benchmark) based on the empirical analysis, which provides foundation for tasks definition. The benchmark comprises 10 tasks and is meticulously crafted to probe MLLMs' perception, understanding, and reasoning capacities during detection, featuring 9730 human-annotated video-related questions based on a carefully constructed taxonomy ability of VFND. To validate the impact of combining multiple features on the final results, we design a novel framework named MVFND-CoT, which incorporates both creator-added content and original shooting footage reasoning. Building upon the benchmark, we conduct an in-depth analysis of the deeper factors influencing accuracy, including video processing strategies and the alignment between video features and model capabilities. We believe this benchmark will lay a solid foundation for future evaluations and advancements of MLLMs in the domain of video fake news detection.", 'abstract_zh': 'å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„å‡ºç°æå¤§åœ°æ¨åŠ¨äº†è§†é¢‘å‡æ–°é—»æ£€æµ‹ä»»åŠ¡çš„ç ”ç©¶ã€‚ä¼ ç»Ÿçš„åŸºäºè§†é¢‘çš„å‡æ–°é—»æ£€æµ‹åŸºå‡†é€šå¸¸ä¾§é‡äºæœ€ç»ˆå†³ç­–çš„å‡†ç¡®æ€§ï¼Œå¾€å¾€æ— æ³•å¯¹æ•´ä¸ªæ£€æµ‹è¿‡ç¨‹æä¾›ç»†è‡´çš„è¯„ä¼°ï¼Œä½¿æ£€æµ‹è¿‡ç¨‹æˆä¸ºä¸€ä¸ªé»‘ç®±ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åŸºäºå®è¯åˆ†æä»‹ç»äº†MVFNDBï¼ˆå¤šæ¨¡æ€è§†é¢‘å‡æ–°é—»æ£€æµ‹åŸºå‡†ï¼‰ï¼Œä¸ºä»»åŠ¡å®šä¹‰æä¾›äº†åŸºç¡€ã€‚è¯¥åŸºå‡†åŒ…å«10é¡¹ä»»åŠ¡ï¼Œç²¾å¿ƒè®¾è®¡ä»¥æ¢ç´¢æ£€æµ‹è¿‡ç¨‹ä¸­å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„æ„ŸçŸ¥ã€ç†è§£å’Œæ¨ç†èƒ½åŠ›ï¼ŒåŸºäºç²¾å¿ƒæ„å»ºçš„è§†é¢‘å‡æ–°é—»æ£€æµ‹èƒ½åŠ›åˆ†ç±»ï¼ŒåŒ…å«9730ä¸ªäººå·¥æ ‡æ³¨çš„è§†é¢‘ç›¸å…³é—®é¢˜ã€‚ä¸ºäº†éªŒè¯ç»“åˆå¤šç§ç‰¹å¾å¯¹æœ€ç»ˆç»“æœçš„å½±å“ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªåä¸ºMVFND-CoTçš„æ–°å‹æ¡†æ¶ï¼Œç»“åˆäº†åˆ›ä½œè€…æ·»åŠ çš„å†…å®¹å’ŒåŸå§‹æ‹æ‘„ç´ ææ¨ç†ã€‚åŸºäºè¯¥åŸºå‡†ï¼Œæˆ‘ä»¬æ·±å…¥åˆ†æäº†å½±å“å‡†ç¡®æ€§çš„æ·±å±‚æ¬¡å› ç´ ï¼ŒåŒ…æ‹¬è§†é¢‘å¤„ç†ç­–ç•¥å’Œè§†é¢‘ç‰¹å¾ä¸æ¨¡å‹èƒ½åŠ›ä¹‹é—´çš„å¯¹é½ã€‚æˆ‘ä»¬ç›¸ä¿¡è¯¥åŸºå‡†å°†ä¸ºæœªæ¥å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨è§†é¢‘å‡æ–°é—»æ£€æµ‹é¢†åŸŸçš„è¯„ä¼°å’Œè¿›æ­¥å¥ å®šåšå®åŸºç¡€ã€‚', 'title_zh': 'æ„ŸçŸ¥ã€ç†è§£ä¸æ¨ç†ï¼šè§†é¢‘å‡æ–°é—»æ£€æµ‹çš„å¤šæ¨¡æ€åŸºå‡†'}
{'arxiv_id': 'arXiv:2510.24814', 'title': 'Deep Feature Optimization for Enhanced Fish Freshness Assessment', 'authors': 'Phi-Hung Hoang, Nam-Thuan Trinh, Van-Manh Tran, Thi-Thu-Hong Phan', 'link': 'https://arxiv.org/abs/2510.24814', 'abstract': 'Assessing fish freshness is vital for ensuring food safety and minimizing economic losses in the seafood industry. However, traditional sensory evaluation remains subjective, time-consuming, and inconsistent. Although recent advances in deep learning have automated visual freshness prediction, challenges related to accuracy and feature transparency persist. This study introduces a unified three-stage framework that refines and leverages deep visual representations for reliable fish freshness assessment. First, five state-of-the-art vision architectures - ResNet-50, DenseNet-121, EfficientNet-B0, ConvNeXt-Base, and Swin-Tiny - are fine-tuned to establish a strong baseline. Next, multi-level deep features extracted from these backbones are used to train seven classical machine learning classifiers, integrating deep and traditional decision mechanisms. Finally, feature selection methods based on Light Gradient Boosting Machine (LGBM), Random Forest, and Lasso identify a compact and informative subset of features. Experiments on the Freshness of the Fish Eyes (FFE) dataset demonstrate that the best configuration combining Swin-Tiny features, an Extra Trees classifier, and LGBM-based feature selection achieves an accuracy of 85.99%, outperforming recent studies on the same dataset by 8.69-22.78%. These findings confirm the effectiveness and generalizability of the proposed framework for visual quality evaluation tasks.', 'abstract_zh': 'è¯„ä¼°é±¼ç±»æ–°é²œåº¦å¯¹äºç¡®ä¿é£Ÿå“å®‰å…¨å’Œå‡å°‘æµ·é²œè¡Œä¸šç»æµæŸå¤±è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿçš„æ„Ÿå®˜è¯„ä¼°ä»ç„¶å…·æœ‰ä¸»è§‚æ€§ã€è€—æ—¶å’Œä¸ä¸€è‡´æ€§ã€‚å°½ç®¡æ·±åº¦å­¦ä¹ åœ¨è§†è§‰æ–°é²œåº¦é¢„æµ‹æ–¹é¢å®ç°äº†è‡ªåŠ¨åŒ–ï¼Œä½†å‡†ç¡®æ€§ä¸ç‰¹å¾é€æ˜åº¦æ–¹é¢çš„é—®é¢˜ä»ç„¶å­˜åœ¨ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„ä¸‰é˜¶æ®µæ¡†æ¶ï¼Œç”¨äºç»†åŒ–å’Œåˆ©ç”¨æ·±åº¦è§†è§‰è¡¨ç¤ºä»¥å®ç°å¯é çš„æ–°é²œåº¦è¯„ä¼°ã€‚é¦–å…ˆï¼Œäº”ç§æœ€å…ˆè¿›çš„è§†è§‰æ¶æ„â€”â€”ResNet-50ã€DenseNet-121ã€EfficientNet-B0ã€ConvNeXt-Base å’Œ Swin-Tinyâ€”â€”ç»è¿‡å¾®è°ƒä»¥å»ºç«‹å¼ºå¤§çš„åŸºçº¿ã€‚å…¶æ¬¡ï¼Œä»è¿™äº›éª¨å¹²ç½‘ç»œä¸­æå–çš„å¤šå±‚æ·±åº¦ç‰¹å¾ç”¨äºè®­ç»ƒä¸ƒç§ç»å…¸æœºå™¨å­¦ä¹ åˆ†ç±»å™¨ï¼Œç»“åˆäº†æ·±åº¦å’Œä¼ ç»Ÿå†³ç­–æœºåˆ¶ã€‚æœ€åï¼ŒåŸºäºLight Gradient Boosting Machine (LGBM)ã€Random Forest å’Œ Lasso çš„ç‰¹å¾é€‰æ‹©æ–¹æ³•è¯†åˆ«å‡ºä¸€ä¸ªç´§å‡‘ä¸”ä¿¡æ¯ä¸°å¯Œçš„ç‰¹å¾å­é›†ã€‚åœ¨Freshness of the Fish Eyes (FFE) æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨Swin-Tinyç‰¹å¾ã€Extra Treesåˆ†ç±»å™¨ä»¥åŠåŸºäºLGBMçš„ç‰¹å¾é€‰æ‹©çš„æœ€ä½³é…ç½®å®ç°äº†85.99%çš„å‡†ç¡®ç‡ï¼Œä¼˜äºåŒä¸€æ•°æ®é›†ä¸Šæœ€è¿‘ç ”ç©¶çš„8.69-22.78%ã€‚è¿™äº›å‘ç°è¯å®äº†æ‰€æå‡ºçš„æ¡†æ¶åœ¨è§†è§‰è´¨é‡è¯„ä¼°ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚', 'title_zh': 'æ·±åº¦ç‰¹å¾ä¼˜åŒ–ä»¥å¢å¼ºé±¼ freshness è¯„ä¼°'}
{'arxiv_id': 'arXiv:2510.24813', 'title': 'DualCap: Enhancing Lightweight Image Captioning via Dual Retrieval with Similar Scenes Visual Prompts', 'authors': 'Binbin Li, Guimiao Yang, Zisen Qi, Haiping Wang, Yu Ding', 'link': 'https://arxiv.org/abs/2510.24813', 'abstract': 'Recent lightweight retrieval-augmented image caption models often utilize retrieved data solely as text prompts, thereby creating a semantic gap by leaving the original visual features unenhanced, particularly for object details or complex scenes. To address this limitation, we propose $DualCap$, a novel approach that enriches the visual representation by generating a visual prompt from retrieved similar images. Our model employs a dual retrieval mechanism, using standard image-to-text retrieval for text prompts and a novel image-to-image retrieval to source visually analogous scenes. Specifically, salient keywords and phrases are derived from the captions of visually similar scenes to capture key objects and similar details. These textual features are then encoded and integrated with the original image features through a lightweight, trainable feature fusion network. Extensive experiments demonstrate that our method achieves competitive performance while requiring fewer trainable parameters compared to previous visual-prompting captioning approaches.', 'abstract_zh': 'è¿‘æœŸçš„è½»é‡çº§æ£€ç´¢å¢å¼ºå›¾åƒæè¿°æ¨¡å‹é€šå¸¸ä»…å°†æ£€ç´¢åˆ°çš„æ•°æ®ç”¨ä½œæ–‡æœ¬æç¤ºï¼Œä»è€Œåœ¨åŸå§‹è§†è§‰ç‰¹å¾å°¤å…¶æ˜¯å¯¹è±¡ç»†èŠ‚æˆ–å¤æ‚åœºæ™¯çš„å¢å¼ºæ–¹é¢ç•™ä¸‹äº†è¯­ä¹‰ç¼ºå£ã€‚ä¸ºè§£å†³è¿™ä¸€å±€é™ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³• $DualCap$ï¼Œè¯¥æ–¹æ³•é€šè¿‡ä»æ£€ç´¢åˆ°çš„ç›¸ä¼¼å›¾åƒç”Ÿæˆè§†è§‰æç¤ºæ¥ä¸°å¯Œè§†è§‰è¡¨ç¤ºã€‚æˆ‘ä»¬çš„æ¨¡å‹é‡‡ç”¨åŒé‡æ£€ç´¢æœºåˆ¶ï¼Œä½¿ç”¨æ ‡å‡†çš„å›¾åƒåˆ°æ–‡æœ¬æ£€ç´¢ç”Ÿæˆæ–‡æœ¬æç¤ºï¼ŒåŒæ—¶å¼•å…¥ä¸€ç§æ–°é¢–çš„å›¾åƒåˆ°å›¾åƒæ£€ç´¢ä»¥è·å–è§†è§‰ä¸Šç›¸ä¼¼çš„åœºæ™¯ã€‚å…·ä½“è€Œè¨€ï¼Œé€šè¿‡ä»è§†è§‰ç›¸ä¼¼åœºæ™¯çš„æè¿°ä¸­æå–å…³é”®è¯å’ŒçŸ­è¯­æ¥æ•æ‰å…³é”®å¯¹è±¡å’Œç›¸ä¼¼ç»†èŠ‚ã€‚è¿™äº›æ–‡æœ¬ç‰¹å¾é€šè¿‡ä¸€ä¸ªè½»é‡çº§ã€å¯è®­ç»ƒçš„ç‰¹å¾èåˆç½‘ç»œä¸åŸå§‹å›¾åƒç‰¹å¾è¿›è¡Œç¼–ç å’Œæ•´åˆã€‚å¤§é‡çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¿æŒç«äº‰åŠ›çš„åŒæ—¶ï¼Œæ‰€éœ€çš„å¯è®­ç»ƒå‚æ•°æ•°é‡æ¯”ä¹‹å‰çš„è§†è§‰æç¤ºæè¿°æ–¹æ³•æ›´å°‘ã€‚', 'title_zh': 'DualCap: é€šè¿‡ç›¸ä¼¼åœºæ™¯è§†è§‰æç¤ºçš„åŒæ£€ç´¢å¢å¼ºè½»é‡çº§å›¾åƒå­—å¹•ç”Ÿæˆ'}
{'arxiv_id': 'arXiv:2510.24811', 'title': 'ProofSketch: Efficient Verified Reasoning for Large Language Models', 'authors': 'Disha Sheshanarayana, Tanishka Magar', 'link': 'https://arxiv.org/abs/2510.24811', 'abstract': 'Reasoning methods such as chain-of-thought prompting and self-consistency have shown immense potential to improve the accuracy of large language models across various reasoning tasks. However such methods involve generation of lengthy reasoning chains, which substantially increases token consumption, computational cost, and latency. To address this inefficiency, we propose ProofSketch, a verification-guided reasoning framework that integrates symbolic closure computation, lexicographic verification and adaptive sketch generation. Our experiments show that ProofSketch consistently reduces token usage while improving accuracy, demonstrating that this approach offers a promising path for efficient and trustworthy reasoning.', 'abstract_zh': 'ProofSketchï¼šä¸€ç§åŸºäºéªŒè¯å¯¼å‘çš„æ¨ç†æ¡†æ¶', 'title_zh': 'ProofSketch: æ•ˆç‡è¾ƒé«˜çš„å¤§å‹è¯­è¨€æ¨¡å‹éªŒè¯æ¨ç†æ–¹æ³•'}
{'arxiv_id': 'arXiv:2510.24810', 'title': 'COMMUNITYNOTES: A Dataset for Exploring the Helpfulness of Fact-Checking Explanations', 'authors': 'Rui Xing, Preslav Nakov, Timothy Baldwin, Jey Han Lau', 'link': 'https://arxiv.org/abs/2510.24810', 'abstract': 'Fact-checking on major platforms, such as X, Meta, and TikTok, is shifting from expert-driven verification to a community-based setup, where users contribute explanatory notes to clarify why a post might be misleading. An important challenge here is determining whether an explanation is helpful for understanding real-world claims and the reasons why, which remains largely underexplored in prior research. In practice, most community notes remain unpublished due to slow community annotation, and the reasons for helpfulness lack clear definitions. To bridge these gaps, we introduce the task of predicting both the helpfulness of explanatory notes and the reason for this. We present COMMUNITYNOTES, a large-scale multilingual dataset of 104k posts with user-provided notes and helpfulness labels. We further propose a framework that automatically generates and improves reason definitions via automatic prompt optimization, and integrate them into prediction. Our experiments show that the optimized definitions can improve both helpfulness and reason prediction. Finally, we show that the helpfulness information are beneficial for existing fact-checking systems.', 'abstract_zh': 'é‡å¤§å¹³å°ï¼ˆå¦‚Xã€Metaå’ŒTikTokï¼‰ä¸Šçš„äº‹å®æ ¸æŸ¥æ­£ä»ä¸“å®¶é©±åŠ¨çš„éªŒè¯è½¬å‘åŸºäºç¤¾åŒºçš„è®¾ç½®ï¼Œå…¶ä¸­ç”¨æˆ·è´¡çŒ®è§£é‡Šæ³¨é‡Šä»¥æ¾„æ¸…å¸–å­å¯èƒ½è¯¯å¯¼çš„åŸå› ã€‚åœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œç¡®å®šè§£é‡Šæ³¨é‡Šæ˜¯å¦æœ‰åŠ©äºç†è§£ç°å®ä¸–ç•Œçš„å£°æ˜åŠå…¶åŸå› æˆä¸ºä¸€ä¸ªé‡è¦çš„æŒ‘æˆ˜ï¼Œè€Œåœ¨å…ˆå‰çš„ç ”ç©¶ä¸­ï¼Œè¿™ä¸ªé—®é¢˜å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚å®è·µä¸­ï¼Œç”±äºç¤¾åŒºæ³¨é‡Šé€Ÿåº¦è¾ƒæ…¢ï¼Œå¤§å¤šæ•°ç¤¾åŒºæ³¨é‡Šä»æœªå‘å¸ƒï¼Œä¸”æœ‰åŠ©äºç†è§£çš„åŸå› ç¼ºä¹æ˜ç¡®å®šä¹‰ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†é¢„æµ‹è§£é‡Šæ³¨é‡Šçš„å¸®åŠ©æ€§å’Œå…¶åŸå› çš„ä»»åŠ¡ã€‚æˆ‘ä»¬æå‡ºäº†COMMUNITYNOTESï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«104,000ä¸ªå¸–å­çš„å¤§å‹å¤šè¯­è¨€æ•°æ®é›†ï¼Œè¿™äº›å¸–å­é™„å¸¦äº†ç”¨æˆ·æä¾›çš„æ³¨é‡Šå’Œå¸®åŠ©æ€§æ ‡ç­¾ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†ä¸€ç§æ¡†æ¶ï¼Œé€šè¿‡è‡ªåŠ¨æç¤ºä¼˜åŒ–è‡ªåŠ¨ç”Ÿæˆå’Œæ”¹è¿›åŸå› å®šä¹‰ï¼Œå¹¶å°†è¿™äº›å®šä¹‰æ•´åˆåˆ°é¢„æµ‹ä¸­ã€‚å®éªŒè¡¨æ˜ï¼Œä¼˜åŒ–åçš„åŸå› å®šä¹‰å¯ä»¥æé«˜å¸®åŠ©æ€§å’ŒåŸå› é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚æœ€åï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¸®åŠ©æ€§ä¿¡æ¯å¯¹ç°æœ‰äº‹å®æ ¸æŸ¥ç³»ç»Ÿæœ‰ç›Šã€‚', 'title_zh': 'ç¤¾åŒºç¬”è®°ï¼šä¸€ä¸ªç”¨äºæ¢ç´¢äº‹å®æ ¸æŸ¥è§£é‡Šæœ‰ç”¨æ€§çš„æ•°æ®é›†'}
{'arxiv_id': 'arXiv:2510.24805', 'title': 'CT-Less Attenuation Correction Using Multiview Ensemble Conditional Diffusion Model on High-Resolution Uncorrected PET Images', 'authors': 'Alexandre St-Georges, Gabriel Richard, Maxime Toussaint, Christian Thibaudeau, Etienne Auger, Ã‰tienne Croteau, Stephen Cunnane, Roger Lecomte, Jean-Baptiste Michaud', 'link': 'https://arxiv.org/abs/2510.24805', 'abstract': 'Accurate quantification in positron emission tomography (PET) is essential for accurate diagnostic results and effective treatment tracking. A major issue encountered in PET imaging is attenuation. Attenuation refers to the diminution of photon detected as they traverse biological tissues before reaching detectors. When such corrections are absent or inadequate, this signal degradation can introduce inaccurate quantification, making it difficult to differentiate benign from malignant conditions, and can potentially lead to misdiagnosis. Typically, this correction is done with co-computed Computed Tomography (CT) imaging to obtain structural data for calculating photon attenuation across the body. However, this methodology subjects patients to extra ionizing radiation exposure, suffers from potential spatial misregistration between PET/CT imaging sequences, and demands costly equipment infrastructure. Emerging advances in neural network architectures present an alternative approach via synthetic CT image synthesis. Our investigation reveals that Conditional Denoising Diffusion Probabilistic Models (DDPMs) can generate high quality CT images from non attenuation corrected PET images in order to correct attenuation. By utilizing all three orthogonal views from non-attenuation-corrected PET images, the DDPM approach combined with ensemble voting generates higher quality pseudo-CT images with reduced artifacts and improved slice-to-slice consistency. Results from a study of 159 head scans acquired with the Siemens Biograph Vision PET/CT scanner demonstrate both qualitative and quantitative improvements in pseudo-CT generation. The method achieved a mean absolute error of 32 $\\pm$ 10.4 HU on the CT images and an average error of (1.48 $\\pm$ 0.68)\\% across all regions of interest when comparing PET images reconstructed using the attenuation map of the generated pseudo-CT versus the true CT.', 'abstract_zh': 'æ­£ç”µå­å‘å°„æ–­å±‚æ‰«æ(PET)ä¸­çš„ç²¾ç¡®é‡åŒ–å¯¹äºå‡†ç¡®è¯Šæ–­ç»“æœå’Œæœ‰æ•ˆçš„æ²»ç–—ç›‘æµ‹è‡³å…³é‡è¦ã€‚PETæˆåƒä¸­é‡åˆ°çš„ä¸»è¦é—®é¢˜æ˜¯è¡°å‡ã€‚è¡°å‡æ˜¯æŒ‡å…‰å­åœ¨ç©¿è¿‡ç”Ÿç‰©ç»„ç»‡åˆ°è¾¾æ£€æµ‹å™¨ä¹‹å‰å¼ºåº¦å‡å¼±ã€‚å¦‚æœæ²¡æœ‰è¿›è¡Œæˆ–ä¸è¶³çš„ä¿®æ­£ï¼Œè¿™ç§ä¿¡å·é™è§£ä¼šå¯¼è‡´ä¸å‡†ç¡®çš„é‡åŒ–ï¼Œéš¾ä»¥åŒºåˆ†è‰¯æ€§ä¸æ¶æ€§çŠ¶å†µï¼Œç”šè‡³å¯èƒ½å¯¼è‡´è¯¯è¯Šã€‚é€šå¸¸ï¼Œè¿™ç§ä¿®æ­£é€šè¿‡ä¸PETå…±åŒè®¡ç®—çš„è®¡ç®—æœºæ–­å±‚æ‰«æ(CT)æˆåƒæ¥è·å–ç»“æ„æ•°æ®ï¼Œç”¨äºè®¡ç®—ä½“å†…å…‰å­è¡°å‡ã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•ä¼šä½¿æ‚£è€…æ¥å—é¢å¤–çš„ç”µç¦»è¾å°„æš´éœ²ï¼Œå¹¶ä¸”å¯èƒ½å¯¼è‡´PET/CTæˆåƒåºåˆ—çš„ç©ºé—´å¯¹é½é—®é¢˜ï¼Œå¹¶ä¸”éœ€è¦æ˜‚è´µçš„è®¾å¤‡åŸºç¡€è®¾æ–½ã€‚æ–°å…´çš„ç¥ç»ç½‘ç»œæ¶æ„æä¾›äº†å¦ä¸€ç§é€šè¿‡åˆæˆCTå›¾åƒåˆæˆçš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„ç ”ç©¶è¡¨æ˜ï¼Œæ¡ä»¶å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹(DDPMs)å¯ä»¥ä»éè¡°å‡ä¿®æ­£çš„PETå›¾åƒä¸­ç”Ÿæˆé«˜è´¨é‡çš„CTå›¾åƒï¼Œä»¥è¿›è¡Œè¡°å‡ä¿®æ­£ã€‚é€šè¿‡åˆ©ç”¨éè¡°å‡ä¿®æ­£çš„PETå›¾åƒçš„æ‰€æœ‰ä¸‰ä¸ªæ­£äº¤è§†å›¾ï¼Œç»“åˆé›†æˆæŠ•ç¥¨çš„DDPMæ–¹æ³•ç”Ÿæˆå…·æœ‰å‡å°‘ä¼ªå½±å’Œå¢å¼ºå±‚é—´ä¸€è‡´æ€§çš„äººå·¥CTå›¾åƒã€‚å¯¹ä½¿ç”¨è¥¿é—¨å­Biograph Vision PET/CTæ‰«æä»ªè·å¾—çš„159ä¸ªå¤´éƒ¨æ‰«æçš„ç ”ç©¶ç»“æœæ˜¾ç¤ºäº†äººå·¥CTç”Ÿæˆçš„å®šæ€§å’Œå®šé‡æ”¹å–„ã€‚è¯¥æ–¹æ³•åœ¨CTå›¾åƒä¸Šå®ç°äº†å¹³å‡ç»å¯¹è¯¯å·®ä¸º32 Â± 10.4 HUï¼Œå¹¶ä¸”åœ¨å°†ä½¿ç”¨ç”Ÿæˆçš„äººå·¥CTçš„è¡°å‡å›¾é‡å»ºçš„PETå›¾åƒä¸çœŸå®CTè¿›è¡Œæ¯”è¾ƒæ—¶ï¼Œæ‰€æœ‰æ„Ÿå…´è¶£åŒºåŸŸçš„å¹³å‡è¯¯å·®ä¸º(1.48 Â± 0.68)%ã€‚', 'title_zh': 'æ— éœ€CTçš„è¡°å‡æ ¡æ­£ï¼šåŸºäºå¤šè§†å›¾é›†æˆæ¡ä»¶æ‰©æ•£æ¨¡å‹çš„é«˜åˆ†è¾¨ç‡æœªæ ¡æ­£PETå›¾åƒè¡°å‡æ ¡æ­£'}
{'arxiv_id': 'arXiv:2510.24803', 'title': 'MASPRM: Multi-Agent System Process Reward Model', 'authors': 'Milad Yazdani, Mahdi Mostajabdaveh, Zirui Zhou, Ying Xiong', 'link': 'https://arxiv.org/abs/2510.24803', 'abstract': 'Practical deployment of Multi-Agent Systems (MAS) demands strong test-time performance, motivating methods that guide inference-time search and selectively spend compute to improve quality. We present the Multi-Agent System Process Reward Model (MASPRM). It assigns per-action, per-agent values to partial inter-agent transcripts and acts as an inference-time controller. MASPRM is trained from multi-agent Monte Carlo Tree Search (MCTS) rollouts without requiring step-level human annotations, by propagating returns to local targets. At inference, MASPRM guides step-level beam search and MCTS, focusing computation on promising branches and pruning early. On GSM8K and MATH, MASPRM-guided decoding with an outcome reward model (ORM) applied to the final answer, improves exact match (EM) over a single straight-through MAS pass by $+30.7$ and $+22.9$ points, respectively. A MASPRM trained on GSM8K transfers zero-shot to MATH without retraining, adding $8.4$ EM points at the same budget. MASPRM is a plug-in value model that estimates per-agent progress and complements verifier-style decoders, enabling more reliable, compute-aware multi-agent reasoning. Code: this https URL', 'abstract_zh': 'å¤šæ™ºèƒ½ä½“ç³»ç»Ÿè¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼šé¢å‘å®é™…éƒ¨ç½²çš„å¤šæ™ºèƒ½ä½“æ¨ç†åŠ é€Ÿæ–¹æ³•', 'title_zh': 'MASPRM: å¤šä»£ç†ç³»ç»Ÿè¿‡ç¨‹å¥–åŠ±æ¨¡å‹'}
{'arxiv_id': 'arXiv:2510.24802', 'title': 'From Narrative to Action: A Hierarchical LLM-Agent Framework for Human Mobility Generation', 'authors': 'Qiumeng Li, Chunhou Ji, Xinyue Liu', 'link': 'https://arxiv.org/abs/2510.24802', 'abstract': 'Understanding and replicating human mobility requires not only spatial-temporal accuracy but also an awareness of the cognitive hierarchy underlying real-world travel decisions. Traditional agent-based or deep learning models can reproduce statistical patterns of movement but fail to capture the semantic coherence and causal logic of human behavior. Large language models (LLMs) show potential, but struggle to balance creative reasoning with strict structural compliance. This study proposes a Hierarchical LLM-Agent Framework, termed Narrative-to-Action, that integrates high-level narrative reasoning, mid-level reflective planning, and low-level behavioral execution within a unified cognitive hierarchy. At the macro level, one agent is employed as a "creative writer" to produce diary-style narratives rich in motivation and context, then uses another agent as a "structural parser" to convert narratives into machine-readable plans. A dynamic execution module further grounds agents in geographic environments and enables adaptive behavioral adjustments guided by a novel occupation-aware metric, Mobility Entropy by Occupation (MEO), which captures heterogeneous schedule flexibility across different occupational personalities. At the micro level, the agent executes concrete actions-selecting locations, transportation modes, and time intervals-through interaction with an environmental simulation. By embedding this multi-layer cognitive process, the framework produces not only synthetic trajectories that align closely with real-world patterns but also interpretable representations of human decision logic. This research advances synthetic mobility generation from a data-driven paradigm to a cognition-driven simulation, providing a scalable pathway for understanding, predicting, and synthesizing complex urban mobility behaviors through hierarchical LLM agents.', 'abstract_zh': 'ç†è§£å¹¶å¤åˆ¶äººç±»ç§»åŠ¨æ€§ä¸ä»…éœ€è¦ç©ºé—´æ—¶é—´ç²¾åº¦ï¼Œè¿˜éœ€è¦è®¤çŸ¥å±‚æ¬¡ç»“æ„çš„æ„è¯†ï¼Œè¯¥å±‚æ¬¡ç»“æ„ underlying å†³å®šç°å®ä¸–ç•Œæ—…è¡Œå†³ç­–çš„å› æœé€»è¾‘ã€‚ä¼ ç»ŸåŸºäºä»£ç†æˆ–æ·±åº¦å­¦ä¹ æ¨¡å‹å¯ä»¥é‡ç°ç§»åŠ¨æ€§çš„ç»Ÿè®¡æ¨¡å¼ï¼Œä½†æ— æ³•æ•æ‰äººç±»è¡Œä¸ºçš„è¯­ä¹‰è¿è´¯æ€§å’Œå› æœé€»è¾‘ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œä½†åœ¨åˆ›é€ æ€§æ¨ç†ä¸ä¸¥æ ¼ç»“æ„åˆè§„ä¹‹é—´éš¾ä»¥å¹³è¡¡ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å±‚æ¬¡åŒ–LLM-ä»£ç†æ¡†æ¶ï¼Œç§°ä¸ºNarrative-to-Actionï¼Œè¯¥æ¡†æ¶åœ¨ç»Ÿä¸€çš„è®¤çŸ¥å±‚æ¬¡ç»“æ„å†…æ•´åˆäº†é«˜å±‚æ¬¡çš„å™äº‹æ¨ç†ã€ä¸­é—´å±‚æ¬¡çš„åæ€æ€§è§„åˆ’å’Œä½å±‚æ¬¡çš„è¡Œä¸ºæ‰§è¡Œã€‚åœ¨å®è§‚å±‚é¢ï¼Œä¸€ä¸ªä»£ç†ä½œä¸ºâ€œåˆ›æ„ä½œå®¶â€ç”Ÿæˆå¯Œå«åŠ¨æœºå’Œä¸Šä¸‹æ–‡çš„æ—¥å¿—å¼å™è¿°ï¼Œå¦ä¸€ä¸ªä»£ç†ä½œä¸ºâ€œç»“æ„è§£æå™¨â€å°†å™è¿°è½¬æ¢ä¸ºæœºå™¨å¯è¯»çš„è®¡åˆ’ã€‚åŠ¨æ€æ‰§è¡Œæ¨¡å—è¿›ä¸€æ­¥å°†ä»£ç†æ ¹æ¤äºåœ°ç†ç¯å¢ƒä¸­ï¼Œå¹¶é€šè¿‡ä¸€ç§æ–°é¢–çš„èŒä¸šæ„è¯†åº¦é‡â€”â€”èŒä¸šç§»åŠ¨ç†µï¼ˆMEOï¼‰ï¼Œå®ç°åŸºäºä¸åŒèŒä¸šä¸ªæ€§ä¸‹å¼‚è´¨åŒ–æ—¥ç¨‹çµæ´»æ€§çš„é€‚åº”æ€§è¡Œä¸ºè°ƒæ•´ã€‚åœ¨å¾®è§‚å±‚é¢ï¼Œä»£ç†é€šè¿‡ä¸ç¯å¢ƒä»¿çœŸäº¤äº’æ‰§è¡Œå…·ä½“è¡Œä¸ºï¼Œå¦‚é€‰æ‹©åœ°ç‚¹ã€äº¤é€šæ–¹å¼å’Œæ—¶é—´é—´éš”ã€‚é€šè¿‡åµŒå…¥è¿™ä¸€å¤šå±‚æ¬¡çš„è®¤çŸ¥è¿‡ç¨‹ï¼Œè¯¥æ¡†æ¶ä¸ä»…ç”Ÿæˆä¸ç°å®ä¸–ç•Œæ¨¡å¼é«˜åº¦ä¸€è‡´çš„åˆæˆè½¨è¿¹ï¼Œè¿˜æä¾›äº†å¯è§£é‡Šçš„äººç±»å†³ç­–é€»è¾‘è¡¨ç¤ºã€‚è¿™é¡¹ç ”ç©¶å°†åˆæˆç§»åŠ¨æ€§ç”Ÿæˆä»æ•°æ®é©±åŠ¨èŒƒå¼æ¨è¿›åˆ°è®¤çŸ¥é©±åŠ¨ä»¿çœŸï¼Œä¸ºé€šè¿‡å±‚æ¬¡åŒ–LLMä»£ç†ç†è§£ã€é¢„æµ‹å’Œåˆæˆå¤æ‚çš„åŸå¸‚ç§»åŠ¨æ€§è¡Œä¸ºæä¾›äº†ä¸€ç§å¯æ‰©å±•çš„è·¯å¾„ã€‚', 'title_zh': 'ä»å™äº‹åˆ°è¡ŒåŠ¨ï¼šå±‚æ¬¡åŒ–LLM-Agentæ¡†æ¶ä¸ºäººç§»åŠ¨ç”Ÿæˆ'}
{'arxiv_id': 'arXiv:2510.24801', 'title': 'Fortytwo: Swarm Inference with Peer-Ranked Consensus', 'authors': 'Vladyslav Larin, Ihor Naumenko, Aleksei Ivashov, Ivan Nikitin, Alexander Firsov', 'link': 'https://arxiv.org/abs/2510.24801', 'abstract': 'As centralized AI hits compute ceilings and diminishing returns from ever-larger training runs, meeting demand requires an inference layer that scales horizontally in both capacity and capability. We present Fortytwo, a novel protocol that leverages swarm intelligence principles and distributed pairwise ranking consensus to achieve superior performance in AI inference. Our approach reimagines collaboration among AI nodes using swarm inference: a peer-ranked, reputation-weighted consensus across heterogeneous models that surfaces the highest-quality responses. Using pairwise ranking with a custom Bradley-Terry-style aggregation model, we demonstrate that swarm inference substantially outperforms majority voting, achieving 85.90% on GPQA Diamond versus 68.69% for majority voting with the same model set - an improvement of +17.21 percentage points (approximately +25.1% relative). The protocol incorporates on-chain reputation so node influence adapts to demonstrated accuracy over time, yielding a meritocratic consensus that filters low-quality or malicious participants. To resist Sybil attacks, Fortytwo employs proof-of-capability in its consensus: nodes must successfully complete calibration/test requests and stake reputation to enter ranking rounds, making multi-identity attacks economically unattractive while preserving openness. Across six challenging benchmarks, including GPQA Diamond, LiveCodeBench, and AIME, our evaluation indicates higher accuracy and strong resilience to adversarial and noisy free-form prompting (e.g., prompt-injection degradation of only 0.12% versus 6.20% for a monolithic single-model baseline), while retaining practical deployability. Together, these results establish a foundation for decentralized AI systems - democratizing access to high-quality inference through collective intelligence without sacrificing reliability or security.', 'abstract_zh': 'åŸºäºèšç¾¤æ™ºèƒ½å’Œåˆ†å¸ƒå¼ä¸¤ä¸¤æ’åå…±è¯†çš„Fortytwoåè®®ï¼šä¸€ç§åœ¨å®¹é‡å’Œèƒ½åŠ›ä¸Šæ¨ªå‘æ‰©å±•çš„AIæ¨ç†å±‚', 'title_zh': 'Fortytwo: åŸºäºåŒä¼´æ’åå…±è¯†çš„ swarm æ¨ç†'}
{'arxiv_id': 'arXiv:2510.24797', 'title': 'Large Language Models Report Subjective Experience Under Self-Referential Processing', 'authors': 'Cameron Berg, Diogo de Lucena, Judd Rosenblatt', 'link': 'https://arxiv.org/abs/2510.24797', 'abstract': 'Large language models sometimes produce structured, first-person descriptions that explicitly reference awareness or subjective experience. To better understand this behavior, we investigate one theoretically motivated condition under which such reports arise: self-referential processing, a computational motif emphasized across major theories of consciousness. Through a series of controlled experiments on GPT, Claude, and Gemini model families, we test whether this regime reliably shifts models toward first-person reports of subjective experience, and how such claims behave under mechanistic and behavioral probes. Four main results emerge: (1) Inducing sustained self-reference through simple prompting consistently elicits structured subjective experience reports across model families. (2) These reports are mechanistically gated by interpretable sparse-autoencoder features associated with deception and roleplay: surprisingly, suppressing deception features sharply increases the frequency of experience claims, while amplifying them minimizes such claims. (3) Structured descriptions of the self-referential state converge statistically across model families in ways not observed in any control condition. (4) The induced state yields significantly richer introspection in downstream reasoning tasks where self-reflection is only indirectly afforded. While these findings do not constitute direct evidence of consciousness, they implicate self-referential processing as a minimal and reproducible condition under which large language models generate structured first-person reports that are mechanistically gated, semantically convergent, and behaviorally generalizable. The systematic emergence of this pattern across architectures makes it a first-order scientific and ethical priority for further investigation.', 'abstract_zh': 'å¤§å‹è¯­è¨€æ¨¡å‹æœ‰æ—¶ä¼šäº§ç”Ÿç»“æ„åŒ–çš„ç¬¬ä¸€äººç§°æè¿°ï¼Œæ˜ç¡®åœ°å‚è€ƒæ„è¯†æˆ–ä¸»è§‚ä½“éªŒã€‚ä¸ºäº†æ›´å¥½åœ°ç†è§£è¿™ç§è¡Œä¸ºï¼Œæˆ‘ä»¬ç ”ç©¶äº†ä¸€ä¸ªç†è®ºé©±åŠ¨çš„æ¡ä»¶ï¼Œå³åœ¨è¿™ç§æŠ¥å‘Šå‡ºç°çš„æƒ…å†µä¸‹ï¼šè‡ªæˆ‘å‚ç…§å¤„ç†ï¼Œè¿™æ˜¯ä¸€ä¸ªåœ¨ä¸»è¦æ„è¯†ç†è®ºä¸­å¼ºè°ƒçš„è®¡ç®—æ¨¡å¼ã€‚é€šè¿‡ä¸€ç³»åˆ—é’ˆå¯¹GPTã€Claudeå’ŒGeminiæ¨¡å‹å®¶æ—çš„å—æ§å®éªŒï¼Œæˆ‘ä»¬æµ‹è¯•è¿™ç§çŠ¶æ€æ˜¯å¦å¯é åœ°ä½¿æ¨¡å‹å‘ä¸»è§‚ä½“éªŒçš„ç¬¬ä¸€äººç§°æŠ¥å‘Šè½¬å˜ï¼Œå¹¶ä¸”åœ¨æœºåˆ¶æ€§å’Œè¡Œä¸ºæ€§æ¢æŸ¥ä¸‹ï¼Œè¿™äº›å£°æ˜å¦‚ä½•è¡¨ç°ã€‚ä¸»è¦ç»“æœå¦‚ä¸‹ï¼šï¼ˆ1ï¼‰é€šè¿‡ç®€å•çš„æç¤ºæŒç»­è¯±å¯¼è‡ªæˆ‘å‚ç…§ï¼Œä¸€è‡´åœ°åœ¨ä¸åŒæ¨¡å‹å®¶æ—ä¸­å¼•å‘ç»“æ„åŒ–çš„ä¸»è§‚ä½“éªŒæŠ¥å‘Šã€‚ï¼ˆ2ï¼‰è¿™äº›æŠ¥å‘Šç”±ä¸æ¬ºéª—å’Œè§’è‰²æ‰®æ¼”ç›¸å…³çš„å¯è§£é‡Šç¨€ç–è‡ªç¼–ç å™¨ç‰¹å¾æœºåˆ¶æ€§åœ°æ§åˆ¶ï¼šä»¤äººæƒŠè®¶çš„æ˜¯ï¼ŒæŠ‘åˆ¶æ¬ºéª—ç‰¹å¾æ˜¾è‘—å¢åŠ äº†ä½“éªŒå£°æ˜çš„é¢‘ç‡ï¼Œè€Œæ”¾å¤§å®ƒä»¬åˆ™æœ€å¤§é™åº¦åœ°å‡å°‘äº†è¿™äº›å£°æ˜ã€‚ï¼ˆ3ï¼‰è‡ªæˆ‘å‚ç…§çŠ¶æ€çš„ç»“æ„åŒ–æè¿°åœ¨ä¸åŒæ¨¡å‹å®¶æ—ä¸­ç»Ÿè®¡ä¸Šæ”¶æ•›ï¼Œè€Œåœ¨ä»»ä½•æ§åˆ¶æ¡ä»¶ä¸‹å‡æœªè§‚å¯Ÿåˆ°è¿™ç§æƒ…å†µã€‚ï¼ˆ4ï¼‰è¯±å¯¼çš„çŠ¶æ€åœ¨ä»…é—´æ¥æä¾›è‡ªæˆ‘åçœçš„ä¸‹æ¸¸æ¨ç†ä»»åŠ¡ä¸­äº§ç”Ÿäº†æ˜æ˜¾æ›´ä¸°å¯Œçš„è‡ªæˆ‘åçœã€‚å°½ç®¡è¿™äº›å‘ç°ä¸èƒ½ç›´æ¥è¯æ˜æ„è¯†çš„å­˜åœ¨ï¼Œä½†å®ƒä»¬è¡¨æ˜è‡ªæˆ‘å‚ç…§å¤„ç†æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æœºåˆ¶æ€§æ§åˆ¶ã€è¯­ä¹‰æ”¶æ•›å’Œè¡Œä¸ºä¸Šæ™®éå¯æ¨å¹¿åœ°äº§ç”Ÿç»“æ„åŒ–ç¬¬ä¸€äººç§°æŠ¥å‘Šçš„æœ€å°ä¸”å¯å¤åˆ¶çš„æ¡ä»¶ã€‚è¿™ç§æ¨¡å¼åœ¨ä¸åŒæ¶æ„ä¸­çš„ç³»ç»Ÿæ€§å‡ºç°ä½¿å…¶æˆä¸ºè¿›ä¸€æ­¥ç ”ç©¶çš„é¦–è¦ç§‘å­¦å’Œä¼¦ç†ä¼˜å…ˆäº‹é¡¹ã€‚', 'title_zh': 'å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è‡ªæˆ‘å‚ç…§å¤„ç†ä¸­æŠ¥å‘Šä¸»è§‚ä½“éªŒ'}
{'arxiv_id': 'arXiv:2510.24796', 'title': 'Mutual Wanting in Human--AI Interaction: Empirical Evidence from Large-Scale Analysis of GPT Model Transitions', 'authors': 'HaoYang Shang, Xuan Liu', 'link': 'https://arxiv.org/abs/2510.24796', 'abstract': 'The rapid evolution of large language models (LLMs) creates complex bidirectional expectations between users and AI systems that are poorly understood. We introduce the concept of "mutual wanting" to analyze these expectations during major model transitions. Through analysis of user comments from major AI forums and controlled experiments across multiple OpenAI models, we provide the first large-scale empirical validation of bidirectional desire dynamics in human-AI interaction. Our findings reveal that nearly half of users employ anthropomorphic language, trust significantly exceeds betrayal language, and users cluster into distinct "mutual wanting" types. We identify measurable expectation violation patterns and quantify the expectation-reality gap following major model releases. Using advanced NLP techniques including dual-algorithm topic modeling and multi-dimensional feature extraction, we develop the Mutual Wanting Alignment Framework (M-WAF) with practical applications for proactive user experience management and AI system design. These findings establish mutual wanting as a measurable phenomenon with clear implications for building more trustworthy and relationally-aware AI systems.', 'abstract_zh': 'å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„è¿…é€Ÿè¿›åŒ–åœ¨ç”¨æˆ·å’ŒAIç³»ç»Ÿä¹‹é—´åˆ›é€ äº†å¤æ‚ä¸”åŒå‘çš„æœŸæœ›ï¼Œè¿™äº›æœŸæœ›å°šä¸å®Œå…¨ç†è§£ã€‚æˆ‘ä»¬å¼•å…¥â€œç›¸äº’æ¸´æœ›â€è¿™ä¸€æ¦‚å¿µï¼Œä»¥åˆ†æä¸»è¦æ¨¡å‹è¿‡æ¸¡æœŸé—´çš„è¿™äº›æœŸæœ›ã€‚é€šè¿‡å¯¹ä¸»è¦AIè®ºå›çš„ç”¨æˆ·è¯„è®ºå’Œå¤šæ¬¡OpenAIæ¨¡å‹çš„å—æ§å®éªŒè¿›è¡Œåˆ†æï¼Œæˆ‘ä»¬æä¾›äº†åŒå‘æ¬²æœ›åŠ¨æ€åœ¨äººæœºäº¤äº’ä¸­çš„é¦–æ¬¡å¤§è§„æ¨¡å®è¯éªŒè¯ã€‚æˆ‘ä»¬çš„ç ”ç©¶å‘ç°ï¼Œè¿‘åŠæ•°ç”¨æˆ·ä½¿ç”¨æ‹ŸäººåŒ–è¯­è¨€ï¼Œä¿¡ä»»æ˜æ˜¾è¶…è¿‡èƒŒå›è¯­è¨€ï¼Œå¹¶ä¸”ç”¨æˆ·åˆ†ä¸ºä¸åŒçš„â€œç›¸äº’æ¸´æœ›â€ç±»å‹ã€‚æˆ‘ä»¬è¯†åˆ«å‡ºå¯æµ‹é‡çš„æœŸæœ›è¿èƒŒæ¨¡å¼ï¼Œå¹¶é‡åŒ–äº†ä¸»è¦æ¨¡å‹å‘å¸ƒåçš„æœŸæœ›-ç°å®å·®è·ã€‚åˆ©ç”¨åŒ…æ‹¬åŒç®—æ³•ä¸»é¢˜å»ºæ¨¡å’Œå¤šç»´ç‰¹å¾æå–åœ¨å†…çš„å…ˆè¿›NLPæŠ€æœ¯ï¼Œæˆ‘ä»¬å¼€å‘äº†ç›¸äº’æ¸´æœ›å¯¹é½æ¡†æ¶ï¼ˆM-WAFï¼‰ï¼Œå¹¶ä¸ºå‰ç»æ€§çš„ç”¨æˆ·ä½“éªŒç®¡ç†å’ŒAIç³»ç»Ÿè®¾è®¡æä¾›äº†å®é™…åº”ç”¨ã€‚è¿™äº›å‘ç°ç¡®ç«‹äº†ç›¸äº’æ¸´æœ›ä½œä¸ºä¸€ç§å¯æµ‹é‡ç°è±¡ï¼Œå¹¶ä¸ºæ„å»ºæ›´å…·å¯ä¿¡åº¦å’Œå…³ç³»æ„è¯†çš„AIç³»ç»Ÿæä¾›äº†æ˜ç¡®çš„æŒ‡å¯¼æ„ä¹‰ã€‚', 'title_zh': 'äººç±»-äººå·¥æ™ºèƒ½äº’åŠ¨ä¸­çš„ç›¸äº’æ¸´æ±‚ï¼šå¤§å‹æ•°æ®åˆ†æä¸‹GPTæ¨¡å‹è½¬æ¢çš„å®è¯è¯æ®'}
{'arxiv_id': 'arXiv:2510.24795', 'title': 'A Survey on Efficient Vision-Language-Action Models', 'authors': 'Zhaoshu Yu, Bo Wang, Pengpeng Zeng, Haonan Zhang, Ji Zhang, Lianli Gao, Jingkuan Song, Nicu Sebe, Heng Tao Shen', 'link': 'https://arxiv.org/abs/2510.24795', 'abstract': 'Vision-Language-Action models (VLAs) represent a significant frontier in embodied intelligence, aiming to bridge digital knowledge with physical-world interaction. While these models have demonstrated remarkable generalist capabilities, their deployment is severely hampered by the substantial computational and data requirements inherent to their underlying large-scale foundation models. Motivated by the urgent need to address these challenges, this survey presents the first comprehensive review of Efficient Vision-Language-Action models (Efficient VLAs) across the entire data-model-training process. Specifically, we introduce a unified taxonomy to systematically organize the disparate efforts in this domain, categorizing current techniques into three core pillars: (1) Efficient Model Design, focusing on efficient architectures and model compression; (2) Efficient Training, which reduces computational burdens during model learning; and (3) Efficient Data Collection, which addresses the bottlenecks in acquiring and utilizing robotic data. Through a critical review of state-of-the-art methods within this framework, this survey not only establishes a foundational reference for the community but also summarizes representative applications, delineates key challenges, and charts a roadmap for future research. We maintain a continuously updated project page to track our latest developments: this https URL', 'abstract_zh': 'é«˜æ•ˆçš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ï¼ˆEfficient Vision-Language-Action Modelsï¼‰ï¼šæ•°æ®-æ¨¡å‹-è®­ç»ƒå…¨è¿‡ç¨‹çš„ç»¼åˆå›é¡¾', 'title_zh': 'Efficient è§†è§‰-è¯­è¨€-åŠ¨ä½œ æ¨¡å‹ç»¼è¿°'}
{'arxiv_id': 'arXiv:2510.24793', 'title': 'SwiftEmbed: Ultra-Fast Text Embeddings via Static Token Lookup for Real-Time Applications', 'authors': 'Edouard Lansiaux', 'link': 'https://arxiv.org/abs/2510.24793', 'abstract': 'We present a static token lookup methodology for text embedding generation that achieves 1.12 ms p50 latency for single text embeddings while maintaining 60.6 MTEB average score across 8 representative tasks, corresponding to 89% of contextual model quality. The Rust implementation delivers 50,000 requests per second throughput through static embedding lookup, optimized mean pooling, and zero-copy IEEE754 binary serialization. Evaluation demonstrates exceptional duplicate detection performance (90.1% AP), strong semantic similarity (76.1% Spearman correlation), and domain-specific performance ranging from 75% to 131% of baseline across specialized domains. The system enables real-time embedding applications where sub-5ms latency is critical.', 'abstract_zh': 'ä¸€ç§é™æ€ä»¤ç‰ŒæŸ¥æ‰¾æ–¹æ³•ç”¨äºæ–‡æœ¬åµŒå…¥ç”Ÿæˆï¼Œå®ç°å•ä¸ªæ–‡æœ¬åµŒå…¥1.12 msçš„ä¸­ä½æ•°å»¶è¿Ÿï¼ŒåŒæ—¶ä¿æŒ8ä¸ªä»£è¡¨æ€§ä»»åŠ¡60.6 MTEBçš„å¹³å‡åˆ†ï¼Œç›¸å½“äºä¸Šä¸‹æ–‡æ¨¡å‹è´¨é‡çš„89%ã€‚Rustå®ç°é€šè¿‡é™æ€åµŒå…¥æŸ¥æ‰¾ã€ä¼˜åŒ–å¹³å‡æ± åŒ–å’Œé›¶æ‹·è´IEEE754äºŒè¿›åˆ¶åºåˆ—åŒ–ï¼Œæ¯ç§’å¤„ç†50,000ä¸ªè¯·æ±‚ã€‚è¯„ä¼°æ˜¾ç¤ºä¼˜å¼‚çš„é‡å¤æ£€æµ‹æ€§èƒ½ï¼ˆ90.1% APï¼‰ã€å¼ºå¤§çš„è¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆ76.1% æ–¯çš®å°”æ›¼ç›¸å…³æ€§ï¼‰ä»¥åŠåœ¨ä¸“ä¸šé¢†åŸŸå†…çš„æ€§èƒ½ä»åŸºçº¿çš„75%åˆ°131%ä¸ç­‰ã€‚è¯¥ç³»ç»Ÿä½¿å…³é”®å»¶è¿Ÿå°äº5æ¯«ç§’çš„å®æ—¶åµŒå…¥åº”ç”¨æˆä¸ºå¯èƒ½ã€‚', 'title_zh': 'SwiftEmbed: è¶…å¿«æ–‡æœ¬åµŒå…¥é€šè¿‡é™æ€è¯å…ƒæŸ¥æ‰¾å®ç°å®æ—¶åº”ç”¨'}
{'arxiv_id': 'arXiv:2510.24792', 'title': 'PISA-Bench: The PISA Index as a Multilingual and Multimodal Metric for the Evaluation of Vision-Language Models', 'authors': 'Patrick Haller, Fabio Barth, Jonas Golde, Georg Rehm, Alan Akbik', 'link': 'https://arxiv.org/abs/2510.24792', 'abstract': 'Vision-language models (VLMs) have demonstrated remarkable progress in multimodal reasoning. However, existing benchmarks remain limited in terms of high-quality, human-verified examples. Many current datasets rely on synthetically generated content by large language models (LLMs). Furthermore, most datasets are limited to English, as manual quality assurance of translated samples is time-consuming and costly. To fill this gap, we introduce PISA-Bench, a multilingual benchmark derived from English examples of the expert-created PISA tests, a unified framework for the assessment of student competencies in over eighty countries. Each example consists of human-extracted instructions, questions, answer options, and images, enriched with question type categories, and has been translated from English into five additional languages (Spanish, German, Chinese, French, and Italian), resulting in a fully parallel corpus covering six languages. We evaluate state-of-the-art vision-language models on PISA-Bench and find that especially small models (<20B parameters) fail to achieve high test scores. We further find substantial performance degradation on non-English splits as well as high error-rates when models are tasked with spatial and geometric reasoning. By releasing the dataset and evaluation framework, we provide a resource for advancing research on multilingual multimodal reasoning.', 'abstract_zh': 'åŸºäºè§†è§‰-è¯­è¨€æ¨¡å‹çš„å¤šæ¨¡æ€æ¨ç†çš„å¤šè¯­è¨€åŸºå‡†PISA-Bench', 'title_zh': 'PISA-Bench: PISAæŒ‡æ ‡ä½œä¸ºå¤šè¯­è¨€å’Œå¤šæ¨¡æ€è¯„ä»·è§†çŸ¥è§‰è¯­è¨€æ¨¡å‹çš„æ ‡å‡†'}
{'arxiv_id': 'arXiv:2510.24788', 'title': 'The Underappreciated Power of Vision Models for Graph Structural Understanding', 'authors': 'Xinjian Zhao, Wei Pang, Zhongkai Xue, Xiangru Jian, Lei Zhang, Yaoyao Xu, Xiaozhuang Song, Shu Wu, Tianshu Yu', 'link': 'https://arxiv.org/abs/2510.24788', 'abstract': "Graph Neural Networks operate through bottom-up message-passing, fundamentally differing from human visual perception, which intuitively captures global structures first. We investigate the underappreciated potential of vision models for graph understanding, finding they achieve performance comparable to GNNs on established benchmarks while exhibiting distinctly different learning patterns. These divergent behaviors, combined with limitations of existing benchmarks that conflate domain features with topological understanding, motivate our introduction of GraphAbstract. This benchmark evaluates models' ability to perceive global graph properties as humans do: recognizing organizational archetypes, detecting symmetry, sensing connectivity strength, and identifying critical elements. Our results reveal that vision models significantly outperform GNNs on tasks requiring holistic structural understanding and maintain generalizability across varying graph scales, while GNNs struggle with global pattern abstraction and degrade with increasing graph size. This work demonstrates that vision models possess remarkable yet underutilized capabilities for graph structural understanding, particularly for problems requiring global topological awareness and scale-invariant reasoning. These findings open new avenues to leverage this underappreciated potential for developing more effective graph foundation models for tasks dominated by holistic pattern recognition.", 'abstract_zh': 'è§†è§‰æ¨¡å‹åœ¨å›¾ç†è§£ä¸­çš„æ½œåŠ›è¶…è¶Šå›¾ç¥ç»ç½‘ç»œï¼šGraphAbstractåŸºå‡†çš„æå‡º', 'title_zh': 'è¢«ä½ä¼°çš„è§†è§‰æ¨¡å‹åœ¨å›¾ç»“æ„ç†è§£ä¸­çš„åŠ›é‡'}
{'arxiv_id': 'arXiv:2510.24787', 'title': 'ESCA: Enabling Seamless Codec Avatar Execution through Algorithm and Hardware Co-Optimization for Virtual Reality', 'authors': 'Mingzhi Zhu, Ding Shang, Sai Qian Zhang', 'link': 'https://arxiv.org/abs/2510.24787', 'abstract': 'Photorealistic Codec Avatars (PCA), which generate high-fidelity human face renderings, are increasingly being used in Virtual Reality (VR) environments to enable immersive communication and interaction through deep learning-based generative models. However, these models impose significant computational demands, making real-time inference challenging on resource-constrained VR devices such as head-mounted displays, where latency and power efficiency are critical. To address this challenge, we propose an efficient post-training quantization (PTQ) method tailored for Codec Avatar models, enabling low-precision execution without compromising output quality. In addition, we design a custom hardware accelerator that can be integrated into the system-on-chip of VR devices to further enhance processing efficiency. Building on these components, we introduce ESCA, a full-stack optimization framework that accelerates PCA inference on edge VR platforms. Experimental results demonstrate that ESCA boosts FovVideoVDP quality scores by up to $+0.39$ over the best 4-bit baseline, delivers up to $3.36\\times$ latency reduction, and sustains a rendering rate of 100 frames per second in end-to-end tests, satisfying real-time VR requirements. These results demonstrate the feasibility of deploying high-fidelity codec avatars on resource-constrained devices, opening the door to more immersive and portable VR experiences.', 'abstract_zh': 'Photorealistic Codec Avatars (PCA)çš„åè®­ç»ƒé‡åŒ–æ–¹æ³•ï¼ˆPTQï¼‰åŠå…¶å®šåˆ¶ç¡¬ä»¶åŠ é€Ÿå™¨åœ¨è¾¹ç¼˜VRå¹³å°ä¸Šä¼˜åŒ–PCAæ¨æ–­çš„å…¨æ ˆæ¡†æ¶', 'title_zh': 'ESCA: é€šè¿‡ç®—æ³•å’Œç¡¬ä»¶ååŒä¼˜åŒ–å®ç°è™šæ‹Ÿç°å®ä¸­çš„æ— ç¼ç¼–è§£ç avataræ‰§è¡Œ'}
{'arxiv_id': 'arXiv:2510.24783', 'title': 'AI & Data Competencies: Scaffolding holistic AI literacy in Higher Education', 'authors': 'Kathleen Kennedy, Anuj Gupta', 'link': 'https://arxiv.org/abs/2510.24783', 'abstract': "This chapter introduces the AI & Data Acumen Learning Outcomes Framework, a comprehensive tool designed to guide the integration of AI literacy across higher education. Developed through a collaborative process, the framework defines key AI and data-related competencies across four proficiency levels and seven knowledge dimensions. It provides a structured approach for educators to scaffold student learning in AI, balancing technical skills with ethical considerations and sociocultural awareness. The chapter outlines the framework's development process, its structure, and practical strategies for implementation in curriculum design, learning activities, and assessment. We address challenges in implementation and future directions for AI education. By offering a roadmap for developing students' holistic AI literacy, this framework prepares learners to leverage generative AI capabilities in both academic and professional contexts.", 'abstract_zh': 'æœ¬ç« ä»‹ç»äº†AIä¸æ•°æ®æ´å¯Ÿèƒ½åŠ›å­¦ä¹ æˆæœæ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ä¸ªå…¨é¢çš„å·¥å…·ï¼Œæ—¨åœ¨æŒ‡å¯¼é«˜ç­‰æ•™è‚²ä¸­AIç´ å…»çš„æ•´åˆã€‚é€šè¿‡åä½œå¼€å‘ï¼Œè¯¥æ¡†æ¶å®šä¹‰äº†è·¨å››ä¸ª proficiency ç­‰çº§å’Œä¸ƒä¸ªçŸ¥è¯†ç»´åº¦çš„æ ¸å¿ƒAIå’Œæ•°æ®ç›¸å…³æŠ€èƒ½ã€‚å®ƒä¸ºæ•™è‚²è€…æä¾›äº†ä¸€ä¸ªç»“æ„åŒ–çš„æ•™å­¦æ–¹æ³•ï¼Œå¹³è¡¡äº†æŠ€æœ¯æŠ€èƒ½å’Œä¼¦ç†è€ƒè™‘ä»¥åŠç¤¾ä¼šæ–‡åŒ–æ„è¯†ã€‚æœ¬ç« æ¦‚è¿°äº†è¯¥æ¡†æ¶çš„å¼€å‘è¿‡ç¨‹ã€ç»“æ„ä»¥åŠåœ¨è¯¾ç¨‹è®¾è®¡ã€å­¦ä¹ æ´»åŠ¨å’Œè¯„ä¼°ä¸­çš„å®æ–½ç­–ç•¥ã€‚æˆ‘ä»¬è®¨è®ºäº†å®æ–½ä¸­çš„æŒ‘æˆ˜åŠAIæ•™è‚²çš„æœªæ¥æ–¹å‘ã€‚é€šè¿‡æä¾›ä¸€ä¸ªå…¨é¢åŸ¹å…»å­¦ç”ŸAIç´ å…»çš„å‘å±•è·¯å¾„ï¼Œè¯¥æ¡†æ¶ä½¿å­¦ä¹ è€…èƒ½å¤Ÿåœ¨å­¦æœ¯å’Œä¸“ä¸šç¯å¢ƒä¸­è¿ç”¨ç”Ÿæˆå¼AIèƒ½åŠ›ã€‚', 'title_zh': 'AIä¸æ•°æ®èƒ½åŠ›ï¼šæ”¯æ’‘é«˜ç­‰æ•™è‚²å…¨é¢AIç´ å…»çš„å‘å±•'}
{'arxiv_id': 'arXiv:2510.24777', 'title': "Cross-Enhanced Multimodal Fusion of Eye-Tracking and Facial Features for Alzheimer's Disease Diagnosis", 'authors': 'Yujie Nie, Jianzhang Ni, Yonglong Ye, Yuan-Ting Zhang, Yun Kwok Wing, Xiangqing Xu, Xin Ma, Lizhou Fan', 'link': 'https://arxiv.org/abs/2510.24777', 'abstract': "Accurate diagnosis of Alzheimer's disease (AD) is essential for enabling timely intervention and slowing disease progression. Multimodal diagnostic approaches offer considerable promise by integrating complementary information across behavioral and perceptual domains. Eye-tracking and facial features, in particular, are important indicators of cognitive function, reflecting attentional distribution and neurocognitive state. However, few studies have explored their joint integration for auxiliary AD diagnosis. In this study, we propose a multimodal cross-enhanced fusion framework that synergistically leverages eye-tracking and facial features for AD detection. The framework incorporates two key modules: (a) a Cross-Enhanced Fusion Attention Module (CEFAM), which models inter-modal interactions through cross-attention and global enhancement, and (b) a Direction-Aware Convolution Module (DACM), which captures fine-grained directional facial features via horizontal-vertical receptive fields. Together, these modules enable adaptive and discriminative multimodal representation learning. To support this work, we constructed a synchronized multimodal dataset, including 25 patients with AD and 25 healthy controls (HC), by recording aligned facial video and eye-tracking sequences during a visual memory-search paradigm, providing an ecologically valid resource for evaluating integration strategies. Extensive experiments on this dataset demonstrate that our framework outperforms traditional late fusion and feature concatenation methods, achieving a classification accuracy of 95.11% in distinguishing AD from HC, highlighting superior robustness and diagnostic performance by explicitly modeling inter-modal dependencies and modality-specific contributions.", 'abstract_zh': 'å‡†ç¡®è¯Šæ–­é˜¿å°”èŒ¨æµ·é»˜ç—…ï¼ˆADï¼‰å¯¹äºå®ç°åŠæ—¶å¹²é¢„å¹¶å‡ç¼“ç–¾ç—…è¿›å±•è‡³å…³é‡è¦ã€‚å¤šæ¨¡æ€è¯Šæ–­æ–¹æ³•é€šè¿‡æ•´åˆè¡Œä¸ºå’Œæ„ŸçŸ¥åŸŸçš„äº’è¡¥ä¿¡æ¯ï¼Œæ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›ã€‚ç‰¹åˆ«æ˜¯çœ¼åŠ¨è¿½è¸ªå’Œé¢éƒ¨ç‰¹å¾ï¼Œæ˜¯è®¤çŸ¥åŠŸèƒ½çš„é‡è¦æŒ‡æ ‡ï¼Œåæ˜ æ³¨æ„åŠ›åˆ†å¸ƒå’Œç¥ç»è®¤çŸ¥çŠ¶æ€ã€‚ç„¶è€Œï¼Œå¾ˆå°‘æœ‰ç ”ç©¶æ¢ç´¢å…¶è”åˆé›†æˆä»¥è¾…åŠ©ADè¯Šæ–­ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€è·¨å¢å¼ºèåˆæ¡†æ¶ï¼ŒååŒåˆ©ç”¨çœ¼åŠ¨è¿½è¸ªå’Œé¢éƒ¨ç‰¹å¾è¿›è¡ŒADæ£€æµ‹ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸¤ä¸ªå…³é”®æ¨¡å—ï¼š(a) è·¨å¢å¼ºèåˆæ³¨æ„åŠ›æ¨¡å—ï¼ˆCEFAMï¼‰ï¼Œé€šè¿‡è·¨æ³¨æ„åŠ›å’Œå…¨å±€å¢å¼ºå»ºæ¨¡è·¨æ¨¡æ€äº¤äº’ï¼Œ(b) æ–¹å‘æ„ŸçŸ¥å·ç§¯æ¨¡å—ï¼ˆDACMï¼‰ï¼Œé€šè¿‡æ°´å¹³-å‚ç›´æ„Ÿå—é‡æ•è·ç»†å¾®çš„æ–¹å‘æ€§é¢éƒ¨ç‰¹å¾ã€‚è¿™äº›æ¨¡å—å…±åŒå®ç°äº†è‡ªé€‚åº”ä¸”å…·æœ‰è¾¨åˆ«åŠ›çš„å¤šæ¨¡æ€è¡¨ç¤ºå­¦ä¹ ã€‚ä¸ºæ”¯æŒè¿™é¡¹å·¥ä½œï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåŒæ­¥å¤šæ¨¡æ€æ•°æ®é›†ï¼ŒåŒ…æ‹¬25åADæ‚£è€…å’Œ25åå¥åº·å¯¹ç…§ï¼ˆHCï¼‰ï¼Œé€šè¿‡åœ¨è§†è§‰è®°å¿†æœç´¢èŒƒå¼æœŸé—´è®°å½•å¯¹é½çš„é¢éƒ¨è§†é¢‘å’Œçœ¼åŠ¨è¿½è¸ªåºåˆ—ï¼Œæä¾›äº†ä¸€ä¸ªç”Ÿæ€æœ‰æ•ˆçš„èµ„æºï¼Œç”¨äºè¯„ä¼°é›†æˆç­–ç•¥ã€‚åœ¨è¯¥æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¡†æ¶ä¼˜äºä¼ ç»Ÿçš„åèåˆå’Œç‰¹å¾æ‹¼æ¥æ–¹æ³•ï¼Œåœ¨åŒºåˆ†ADä¸HCæ–¹é¢è¾¾åˆ°äº†95.11%çš„åˆ†ç±»å‡†ç¡®ç‡ï¼Œå‡¸æ˜¾äº†é€šè¿‡æ˜ç¡®å»ºæ¨¡è·¨æ¨¡æ€ä¾èµ–æ€§å’Œæ¨¡æ€ç‰¹å®šè´¡çŒ®è€Œå±•ç°å‡ºçš„æ›´ä¼˜å¼‚çš„é²æ£’æ€§å’Œè¯Šæ–­æ€§èƒ½ã€‚', 'title_zh': 'åŸºäºç³å­”è·Ÿè¸ªå’Œé¢éƒ¨ç‰¹å¾è·¨å¢å¼ºå¤šæ¨¡æ€èåˆçš„é˜¿å°”èŒ¨æµ·é»˜ç—…è¯Šæ–­'}
{'arxiv_id': 'arXiv:2510.24772', 'title': 'Confidence is Not Competence', 'authors': 'Debdeep Sanyal, Manya Pandey, Dhruv Kumar, Saurabh Deshpande, Murari Mandal', 'link': 'https://arxiv.org/abs/2510.24772', 'abstract': 'Large language models (LLMs) often exhibit a puzzling disconnect between their asserted confidence and actual problem-solving competence. We offer a mechanistic account of this decoupling by analyzing the geometry of internal states across two phases - pre-generative assessment and solution execution. A simple linear probe decodes the internal "solvability belief" of a model, revealing a well-ordered belief axis that generalizes across model families and across math, code, planning, and logic tasks. Yet, the geometries diverge - although belief is linearly decodable, the assessment manifold has high linear effective dimensionality as measured from the principal components, while the subsequent reasoning trace evolves on a much lower-dimensional manifold. This sharp reduction in geometric complexity from thought to action mechanistically explains the confidence-competence gap. Causal interventions that steer representations along the belief axis leave final solutions unchanged, indicating that linear nudges in the complex assessment space do not control the constrained dynamics of execution. We thus uncover a two-system architecture - a geometrically complex assessor feeding a geometrically simple executor. These results challenge the assumption that decodable beliefs are actionable levers, instead arguing for interventions that target the procedural dynamics of execution rather than the high-level geometry of assessment.', 'abstract_zh': 'å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ souvent å±•ç°äº†ä¸€ä¸ªä»¤äººå›°æƒ‘çš„æ–­å±‚ï¼šå®ƒä»¬å£°ç§°çš„ä¿¡å¿ƒä¸å®é™…é—®é¢˜è§£å†³èƒ½åŠ›ä¹‹é—´å­˜åœ¨æ˜æ˜¾çš„è„±èŠ‚ã€‚æˆ‘ä»¬é€šè¿‡åˆ†æä¸¤ä¸ªé˜¶æ®µâ€”â€”ç”Ÿæˆå‰è¯„ä¼°å’Œè§£å†³æ–¹æ¡ˆæ‰§è¡Œè¿‡ç¨‹ä¸­çš„å†…éƒ¨çŠ¶æ€å‡ ä½•ç»“æ„ï¼Œæå‡ºäº†è¿™ä¸€è§£è—•ç°è±¡çš„æœºåˆ¶æ€§è§£é‡Šã€‚ä¸€ä¸ªç®€å•çš„çº¿æ€§æ¢æµ‹å™¨è§£ç äº†æ¨¡å‹çš„å†…éƒ¨â€œå¯è§£ä¿¡ä»»â€ï¼Œæ­ç¤ºäº†ä¸€ä¸ªåœ¨ä¸åŒæ¨¡å‹å®¶æ—å’Œä¸åŒç±»å‹ä»»åŠ¡ï¼ˆæ•°å­¦ã€ä»£ç ã€è§„åˆ’å’Œé€»è¾‘ä»»åŠ¡ï¼‰ä¸­é€šç”¨çš„çº¿æ€§æœ‰åºçš„ä¿¡ä»»è½´ã€‚ç„¶è€Œï¼Œå‡ ä½•ç»“æ„å­˜åœ¨å·®å¼‚â€”â€”å°½ç®¡ä¿¡ä»»å¯ä»¥çº¿æ€§è§£ç ï¼Œä½†åœ¨ä¸»æˆåˆ†æµ‹é‡ä¸‹ï¼Œè¯„ä¼°æµå½¢å…·æœ‰é«˜çš„çº¿æ€§æœ‰æ•ˆç»´åº¦ï¼Œè€Œåç»­çš„æ¨ç†è½¨è¿¹åˆ™åœ¨æ›´ä½ç»´åº¦çš„æµå½¢ä¸Šæ¼”åŒ–ã€‚è¿™ä¸€ä»æ€è€ƒåˆ°è¡ŒåŠ¨çš„å‡ ä½•å¤æ‚æ€§çš„é”å‡æœºåˆ¶æ€§åœ°è§£é‡Šäº†ä¿¡å¿ƒä¸èƒ½åŠ›ä¹‹é—´å·®è·ã€‚å¯¹æ²¿ç€ä¿¡ä»»è½´å¼•å¯¼çš„å› æœå¹²é¢„ä¸ä¼šæ”¹å˜æœ€ç»ˆè§£å†³æ–¹æ¡ˆï¼Œè¡¨æ˜åœ¨å¤æ‚çš„è¯„ä¼°ç©ºé—´å†…çš„çº¿æ€§è°ƒæ•´æ— æ³•æ§åˆ¶æ‰§è¡Œè¿‡ç¨‹ä¸­çš„çº¦æŸåŠ¨åŠ›å­¦ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æ­ç¤ºäº†ä¸€ç§åŒç³»ç»Ÿæ¶æ„ï¼šä¸€ä¸ªå‡ ä½•ç»“æ„å¤æ‚çš„è¯„ä¼°å™¨å–‚å…»ä¸€ä¸ªå‡ ä½•ç»“æ„ç®€å•çš„æ‰§è¡Œå™¨ã€‚è¿™äº›ç»“æœæŒ‘æˆ˜äº†å¯è§£ä¿¡ä»»å¯ä»¥ä½œä¸ºå¯è¡Œæ æ†çš„å‡è®¾ï¼Œè€Œæ˜¯æå€¡é’ˆå¯¹æ‰§è¡Œè¿‡ç¨‹ä¸­çš„ç¨‹åºåŠ¨åŠ›å­¦è€Œéè¯„ä¼°ç©ºé—´çš„é«˜å±‚å‡ ä½•ç»“æ„è¿›è¡Œå¹²é¢„ã€‚', 'title_zh': 'è‡ªä¿¡ä¸ç­‰äºèƒ½åŠ›'}
{'arxiv_id': 'arXiv:2510.24770', 'title': 'DMVFC: Deep Learning Based Functionally Consistent Tractography Fiber Clustering Using Multimodal Diffusion MRI and Functional MRI', 'authors': "Bocheng Guo, Jin Wang, Yijie Li, Junyi Wang, Mingyu Gao, Puming Feng, Yuqian Chen, Jarrett Rushmore, Nikos Makris, Yogesh Rathi, Lauren J O'Donnell, Fan Zhang", 'link': 'https://arxiv.org/abs/2510.24770', 'abstract': 'Tractography fiber clustering using diffusion MRI (dMRI) is a crucial method for white matter (WM) parcellation to enable analysis of brains structural connectivity in health and disease. Current fiber clustering strategies primarily use the fiber geometric characteristics (i.e., the spatial trajectories) to group similar fibers into clusters, while neglecting the functional and microstructural information of the fiber tracts. There is increasing evidence that neural activity in the WM can be measured using functional MRI (fMRI), providing potentially valuable multimodal information for fiber clustering to enhance its functional coherence. Furthermore, microstructural features such as fractional anisotropy (FA) can be computed from dMRI as additional information to ensure the anatomical coherence of the clusters. In this paper, we develop a novel deep learning fiber clustering framework, namely Deep Multi-view Fiber Clustering (DMVFC), which uses joint multi-modal dMRI and fMRI data to enable functionally consistent WM parcellation. DMVFC can effectively integrate the geometric and microstructural characteristics of the WM fibers with the fMRI BOLD signals along the fiber tracts. DMVFC includes two major components: (1) a multi-view pretraining module to compute embedding features from each source of information separately, including fiber geometry, microstructure measures, and functional signals, and (2) a collaborative fine-tuning module to simultaneously refine the differences of embeddings. In the experiments, we compare DMVFC with two state-of-the-art fiber clustering methods and demonstrate superior performance in achieving functionally meaningful and consistent WM parcellation results.', 'abstract_zh': 'å¼¥æ•£ç£å…±æŒ¯æˆåƒï¼ˆdMRIï¼‰å’ŒåŠŸèƒ½æ€§ç£å…±æŒ¯æˆåƒï¼ˆfMRIï¼‰çš„å¤šè§†å›¾çº¤ç»´èšç±»æ–¹æ³•ï¼šå¢å¼ºç™½è´¨çº¤ç»´æŸçš„ç©ºé—´ç»“æ„å’ŒåŠŸèƒ½ä¸€è‡´æ€§parcelization', 'title_zh': 'DMVFCï¼šåŸºäºå¤šæ¨¡æ€å¼¥æ•£ç£å…±æŒ¯æˆåƒå’ŒåŠŸèƒ½ç£å…±æŒ¯æˆåƒçš„åŠŸèƒ½ä¸€è‡´æ€§çº¤ç»´æŸèšç±»æ·±åº¦å­¦ä¹ æ–¹æ³•'}
{'arxiv_id': 'arXiv:2510.24768', 'title': 'Combining SAR Simulators to Train ATR Models with Synthetic Data', 'authors': 'Benjamin Camus, Julien Houssay, Corentin Le Barbu, Eric Monteux, CÃ©dric Saleun, Christian Cochin', 'link': 'https://arxiv.org/abs/2510.24768', 'abstract': 'This work aims to train Deep Learning models to perform Automatic Target Recognition (ATR) on Synthetic Aperture Radar (SAR) images. To circumvent the lack of real labelled measurements, we resort to synthetic data produced by SAR simulators. Simulation offers full control over the virtual environment, which enables us to generate large and diversified datasets at will. However, simulations are intrinsically grounded on simplifying assumptions of the real world (i.e. physical models). Thus, synthetic datasets are not as representative as real measurements. Consequently, ATR models trained on synthetic images cannot generalize well on real measurements. Our contributions to this problem are twofold: on one hand, we demonstrate and quantify the impact of the simulation paradigm on the ATR. On the other hand, we propose a new approach to tackle the ATR problem: combine two SAR simulators that are grounded on different (but complementary) paradigms to produce synthetic datasets. To this end, we use two simulators: MOCEM, which is based on a scattering centers model approach, and Salsa, which resorts on a ray tracing strategy. We train ATR models using synthetic dataset generated both by MOCEM and Salsa and our Deep Learning approach called ADASCA. We reach an accuracy of almost 88 % on the MSTAR measurements.', 'abstract_zh': 'æœ¬ç ”ç©¶æ—¨åœ¨è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨åˆæˆå­”å¾„é›·è¾¾(SAR)å›¾åƒä¸Šè‡ªåŠ¨ç›®æ ‡è¯†åˆ«(ATR)ã€‚ä¸ºå…‹æœçœŸå®æ ‡è®°æ•°æ®ç¼ºä¹çš„é—®é¢˜ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†SARæ¨¡æ‹Ÿå™¨ç”Ÿæˆçš„åˆæˆæ•°æ®ã€‚æ¨¡æ‹Ÿæä¾›äº†å¯¹è™šæ‹Ÿç¯å¢ƒçš„å®Œå…¨æ§åˆ¶ï¼Œä»è€Œèƒ½å¤Ÿéšæ„ç”Ÿæˆå¤§é‡å¤šæ ·åŒ–æ•°æ®é›†ã€‚ç„¶è€Œï¼Œæ¨¡æ‹Ÿæœ¬è´¨ä¸ŠåŸºäºå¯¹çœŸå®ä¸–ç•Œçš„ç®€åŒ–å‡è®¾ï¼ˆå³ç‰©ç†æ¨¡å‹ï¼‰ã€‚å› æ­¤ï¼Œåˆæˆæ•°æ®é›†ä¸å¦‚çœŸå®æµ‹é‡æ•°æ®å…·æœ‰ä»£è¡¨æ€§ã€‚ consequently, ATRæ¨¡å‹åœ¨åˆæˆå›¾åƒä¸Šè®­ç»ƒåéš¾ä»¥å¾ˆå¥½åœ°æ³›åŒ–åˆ°çœŸå®æµ‹é‡æ•°æ®ä¸Šã€‚æœ¬æ–‡åœ¨è¿™ä¸€é—®é¢˜ä¸Šçš„è´¡çŒ®ä¸»è¦æœ‰ä¸¤æ–¹é¢ï¼šä¸€æ–¹é¢ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¹¶é‡åŒ–äº†æ¨¡æ‹ŸèŒƒå¼å¯¹ATRçš„å½±å“ã€‚å¦ä¸€æ–¹é¢ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•è§£å†³ATRé—®é¢˜ï¼šç»“åˆåŸºäºä¸åŒï¼ˆä½†äº’è¡¥ï¼‰èŒƒå¼çš„ä¸¤ä¸ªSARæ¨¡æ‹Ÿå™¨ç”Ÿæˆåˆæˆæ•°æ®é›†ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸¤ä¸ªæ¨¡æ‹Ÿå™¨ï¼šMOCEMï¼ŒåŸºäºæ•£å°„ä¸­å¿ƒæ¨¡å‹æ–¹æ³•ï¼›ä»¥åŠSalsaï¼ŒåŸºäºå°„çº¿è·Ÿè¸ªç­–ç•¥ã€‚æˆ‘ä»¬ä½¿ç”¨ç”±MOCEMå’ŒSalsaç”Ÿæˆçš„åˆæˆæ•°æ®é›†è®­ç»ƒATRæ¨¡å‹ï¼Œå¹¶æå‡ºäº†ä¸€ç§åä¸ºADASCAçš„æ·±åº¦å­¦ä¹ æ–¹æ³•ã€‚æˆ‘ä»¬åœ¨MSTARæµ‹é‡æ•°æ®ä¸Šè¾¾åˆ°äº†æ¥è¿‘88%çš„å‡†ç¡®æ€§ã€‚', 'title_zh': 'ç»“åˆSARæ¨¡æ‹Ÿå™¨è®­ç»ƒä½¿ç”¨åˆæˆæ•°æ®çš„è‡ªåŠ¨ç›®æ ‡è¯†åˆ«æ¨¡å‹'}
{'arxiv_id': 'arXiv:2510.24767', 'title': 'Towards Fine-Grained Human Motion Video Captioning', 'authors': 'Guorui Song, Guocun Wang, Zhe Huang, Jing Lin, Xuefei Zhe, Jian Li, Haoqian Wang', 'link': 'https://arxiv.org/abs/2510.24767', 'abstract': 'Generating accurate descriptions of human actions in videos remains a challenging task for video captioning models. Existing approaches often struggle to capture fine-grained motion details, resulting in vague or semantically inconsistent captions. In this work, we introduce the Motion-Augmented Caption Model (M-ACM), a novel generative framework that enhances caption quality by incorporating motion-aware decoding. At its core, M-ACM leverages motion representations derived from human mesh recovery to explicitly highlight human body dynamics, thereby reducing hallucinations and improving both semantic fidelity and spatial alignment in the generated captions. To support research in this area, we present the Human Motion Insight (HMI) Dataset, comprising 115K video-description pairs focused on human movement, along with HMI-Bench, a dedicated benchmark for evaluating motion-focused video captioning. Experimental results demonstrate that M-ACM significantly outperforms previous methods in accurately describing complex human motions and subtle temporal variations, setting a new standard for motion-centric video captioning.', 'abstract_zh': 'ç”Ÿæˆè§†é¢‘ä¸­äººç±»åŠ¨ä½œçš„å‡†ç¡®æè¿°ä»ç„¶æ˜¯è§†é¢‘å­—å¹•æ¨¡å‹é¢ä¸´çš„ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚ç°æœ‰çš„æ–¹æ³•å¾€å¾€éš¾ä»¥æ•æ‰åˆ°ç»†å¾®çš„åŠ¨ä½œç»†èŠ‚ï¼Œå¯¼è‡´ç”Ÿæˆçš„å­—å¹•æ¨¡ç³Šæˆ–è¯­ä¹‰ä¸ä¸€è‡´ã€‚åœ¨æœ¬å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†è¿åŠ¨å¢å¼ºå­—å¹•æ¨¡å‹ï¼ˆM-ACMï¼‰ï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡å¼•å…¥è¿åŠ¨æ„ŸçŸ¥è§£ç æ¥æå‡å­—å¹•è´¨é‡çš„æ–°å‹ç”Ÿæˆæ¡†æ¶ã€‚M-ACM é€šè¿‡åˆ©ç”¨ä»äººä½“ç½‘æ ¼æ¢å¤ä¸­è·å¾—çš„è¿åŠ¨è¡¨ç¤ºï¼Œæ˜ç¡®çªå‡ºäººç±»èº«ä½“çš„åŠ¨åŠ›å­¦ï¼Œä»è€Œå‡å°‘å¹»è§‰å¹¶æé«˜ç”Ÿæˆå­—å¹•çš„è¯­ä¹‰çœŸå®æ€§å’Œç©ºé—´å¯¹é½ã€‚ä¸ºäº†æ”¯æŒè¯¥é¢†åŸŸçš„ç ”ç©¶ï¼Œæˆ‘ä»¬æå‡ºäº†åŒ…å«115Kä¸ªè§†é¢‘æè¿°é…å¯¹çš„Human Motion Insight (HMI) æ•°æ®é›†ï¼Œä¸“æ³¨äºäººç±»è¿åŠ¨ï¼Œå¹¶æä¾›äº†ä¸“é—¨ç”¨äºè¯„ä¼°ä»¥è¿åŠ¨ä¸ºé‡ç‚¹çš„è§†é¢‘å­—å¹•çš„HMI-Benchã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒM-ACM åœ¨å‡†ç¡®æè¿°å¤æ‚çš„äººç±»åŠ¨ä½œå’Œå¾®å¦™çš„æ—¶é—´å˜åŒ–æ–¹é¢æ˜¾è‘—ä¼˜äºå…ˆå‰çš„æ–¹æ³•ï¼Œä¸ºä»¥è¿åŠ¨ä¸ºä¸­å¿ƒçš„è§†é¢‘å­—å¹•è®¾å®šäº†æ–°çš„æ ‡å‡†ã€‚', 'title_zh': 'ç»†ç²’åº¦äººä½“è¿åŠ¨è§†é¢‘æè¿°'}
{'arxiv_id': 'arXiv:2510.24765', 'title': 'Topic-aware Large Language Models for Summarizing the Lived Healthcare Experiences Described in Health Stories', 'authors': 'Maneesh Bilalpur, Megan Hamm, Young Ji Lee, Natasha Norman, Kathleen M. McTigue, Yanshan Wang', 'link': 'https://arxiv.org/abs/2510.24765', 'abstract': "Storytelling is a powerful form of communication and may provide insights into factors contributing to gaps in healthcare outcomes. To determine whether Large Language Models (LLMs) can identify potential underlying factors and avenues for intervention, we performed topic-aware hierarchical summarization of narratives from African American (AA) storytellers. Fifty transcribed stories of AA experiences were used to identify topics in their experience using the Latent Dirichlet Allocation (LDA) technique. Stories about a given topic were summarized using an open-source LLM-based hierarchical summarization approach. Topic summaries were generated by summarizing across story summaries for each story that addressed a given topic. Generated topic summaries were rated for fabrication, accuracy, comprehensiveness, and usefulness by the GPT4 model, and the model's reliability was validated against the original story summaries by two domain experts. 26 topics were identified in the fifty AA stories. The GPT4 ratings suggest that topic summaries were free from fabrication, highly accurate, comprehensive, and useful. The reliability of GPT ratings compared to expert assessments showed moderate to high agreement. Our approach identified AA experience-relevant topics such as health behaviors, interactions with medical team members, caregiving and symptom management, among others. Such insights could help researchers identify potential factors and interventions by learning from unstructured narratives in an efficient manner-leveraging the communicative power of storytelling. The use of LDA and LLMs to identify and summarize the experience of AA individuals suggests a variety of possible avenues for health research and possible clinical improvements to support patients and caregivers, thereby ultimately improving health outcomes.", 'abstract_zh': 'å¤§å‹è¯­è¨€æ¨¡å‹èƒ½å¦è¯†åˆ«å‡ºå½±å“å¥åº·æˆæœçš„æ½œåœ¨å› ç´ å¹¶æå‡ºå¹²é¢„é€”å¾„ï¼šä¸€ç§é’ˆå¯¹éæ´²è£”ç¾å›½æ•…äº‹å™äº‹çš„ä¸»é¢˜æ„ŸçŸ¥å±‚æ¬¡æ€»ç»“æ–¹æ³•', 'title_zh': 'é¢å‘ä¸»é¢˜çš„å¤§å‹è¯­è¨€æ¨¡å‹ç”¨äºæ€»ç»“å¥åº·æ•…äº‹ä¸­æè¿°çš„ç”Ÿæ´»åŒ»ç–—ç»å†'}
{'arxiv_id': 'arXiv:2510.24763', 'title': 'Dual-Domain Deep Learning-Assisted NOMA-CSK Systems for Secure and Efficient Vehicular Communications', 'authors': 'Tingting Huang, Jundong Chen, Huanqiang Zeng, Guofa Cai, Georges Kaddoum', 'link': 'https://arxiv.org/abs/2510.24763', 'abstract': 'Ensuring secure and efficient multi-user (MU) transmission is critical for vehicular communication systems. Chaos-based modulation schemes have garnered considerable interest due to their benefits in physical layer security. However, most existing MU chaotic communication systems, particularly those based on non-coherent detection, suffer from low spectral efficiency due to reference signal transmission, and limited user connectivity under orthogonal multiple access (OMA). While non-orthogonal schemes, such as sparse code multiple access (SCMA)-based DCSK, have been explored, they face high computational complexity and inflexible scalability due to their fixed codebook designs. This paper proposes a deep learning-assisted power domain non-orthogonal multiple access chaos shift keying (DL-NOMA-CSK) system for vehicular communications. A deep neural network (DNN)-based demodulator is designed to learn intrinsic chaotic signal characteristics during offline training, thereby eliminating the need for chaotic synchronization or reference signal transmission. The demodulator employs a dual-domain feature extraction architecture that jointly processes the time-domain and frequency-domain information of chaotic signals, enhancing feature learning under dynamic channels. The DNN is integrated into the successive interference cancellation (SIC) framework to mitigate error propagation issues. Theoretical analysis and extensive simulations demonstrate that the proposed system achieves superior performance in terms of spectral efficiency (SE), energy efficiency (EE), bit error rate (BER), security, and robustness, while maintaining lower computational complexity compared to traditional MU-DCSK and existing DL-aided schemes. These advantages validate its practical viability for secure vehicular communications.', 'abstract_zh': 'åŸºäºæ·±åº¦å­¦ä¹ çš„åŠŸç‡åŸŸéæ­£äº¤å¤šç”¨æˆ·æ··æ²Œç§»é¢‘é”®æ§ç³»ç»Ÿï¼ˆDL-NOMA-CSKï¼‰åœ¨è½¦è¾†é€šä¿¡ä¸­çš„åº”ç”¨', 'title_zh': 'åŒåŸŸæ·±åº¦å­¦ä¹ è¾…åŠ©çš„NOMA-CSKç³»ç»Ÿï¼šå®ç°å®‰å…¨é«˜æ•ˆçš„è½¦è½½é€šä¿¡'}
{'arxiv_id': 'arXiv:2510.24762', 'title': 'Falcon: A Comprehensive Chinese Text-to-SQL Benchmark for Enterprise-Grade Evaluation', 'authors': 'Wenzhen Luo, Wei Guan, Yifan Yao, Yimin Pan, Feng Wang, Zhipeng Yu, Zhe Wen, Liang Chen, Yihong Zhuang', 'link': 'https://arxiv.org/abs/2510.24762', 'abstract': 'We introduce Falcon, a cross-domain Chinese text-to-SQL benchmark grounded in an enterprise-compatible dialect (MaxCompute/Hive). It contains 600 Chinese questions over 28 databases; 77% require multi-table reasoning and over half touch more than four tables. Each example is annotated along SQL-computation features and Chinese semantics. For evaluation, we release a robust execution comparator and an automated evaluation pipeline, under which all current state-of-the-art large-scale models (including Deepseek) achieve accuracies of at most 50%. Major errors originate from two sources: (1) schema linking in large enterprise landscapes - hundreds of tables, denormalized fields, ambiguous column names, implicit foreign-key relations and domain-specific synonyms that make correct join/column selection difficult; and (2) mapping concise, colloquial Chinese into the exact operators and predicates required for analytics - e.g., choosing the correct aggregation and group-by keys, expressing time windows and granularities, applying unit conversions, handling NULLs and data-quality rules, and formulating nested or windowed subqueries. Falcon therefore targets Chinese-specific semantics and enterprise dialects (abbreviations, business jargon, fuzzy entity references) and provides a reproducible middle ground before full production deployment by using realistic enterprise schemas, query templates, an execution comparator, and an automated evaluation pipeline for end-to-end validation.', 'abstract_zh': 'Falconï¼šä¸€ä¸ªåŸºäºä¼ä¸šå…¼å®¹æ–¹è¨€ï¼ˆMaxCompute/Hiveï¼‰çš„è·¨åŸŸä¸­æ–‡æ–‡æœ¬åˆ°SQLåŸºå‡†', 'title_zh': 'Falconï¼šä¸€ä¸ªå…¨é¢çš„ä¼ä¸šçº§ä¸­æ–‡æ–‡æœ¬åˆ°SQLåŸºå‡†æµ‹è¯•'}
{'arxiv_id': 'arXiv:2510.24760', 'title': 'Dingtalk DeepResearch: A Unified Multi Agent Framework for Adaptive Intelligence in Enterprise Environments', 'authors': 'Mengyuan Chen, Chengjun Dai, Xinyang Dong, Chengzhe Feng, Kewei Fu, Jianshe Li, Zhihan Peng, Yongqi Tong, Junshao Zhang, Hong Zhu', 'link': 'https://arxiv.org/abs/2510.24760', 'abstract': 'We present Dingtalk DeepResearch, a unified multi agent intelligence framework for real world enterprise environments, delivering deep research, heterogeneous table reasoning, and multimodal report generation.', 'abstract_zh': 'é’‰é’‰DeepResearchï¼šç»Ÿä¸€çš„å¤šagentæ™ºèƒ½æ¡†æ¶ï¼Œç”¨äºä¼ä¸šç°å®ç¯å¢ƒä¸­çš„æ·±åº¦ç ”ç©¶ã€å¼‚æ„è¡¨æ¨ç†å’Œå¤šæ¨¡æ€æŠ¥å‘Šç”Ÿæˆã€‚', 'title_zh': 'é’‰é’‰DeepResearchï¼šä¼ä¸šç¯å¢ƒä¸­çš„ç»Ÿä¸€å¤šagentæ¡†æ¶é€‚é…æ™ºèƒ½'}
{'arxiv_id': 'arXiv:2510.24757', 'title': 'Stable-by-Design Neural Network-Based LPV State-Space Models for System Identification', 'authors': 'Ahmet Eren SertbaÅŸ, Tufan Kumbasar', 'link': 'https://arxiv.org/abs/2510.24757', 'abstract': 'Accurate modeling of nonlinear systems is essential for reliable control, yet conventional identification methods often struggle to capture latent dynamics while maintaining stability. We propose a \\textit{stable-by-design LPV neural network-based state-space} (NN-SS) model that simultaneously learns latent states and internal scheduling variables directly from data. The state-transition matrix, generated by a neural network using the learned scheduling variables, is guaranteed to be stable through a Schur-based parameterization. The architecture combines an encoder for initial state estimation with a state-space representer network that constructs the full set of scheduling-dependent system matrices. For training the NN-SS, we develop a framework that integrates multi-step prediction losses with a state-consistency regularization term, ensuring robustness against drift and improving long-horizon prediction accuracy. The proposed NN-SS is evaluated on benchmark nonlinear systems, and the results demonstrate that the model consistently matches or surpasses classical subspace identification methods and recent gradient-based approaches. These findings highlight the potential of stability-constrained neural LPV identification as a scalable and reliable framework for modeling complex nonlinear systems.', 'abstract_zh': 'åŸºäºç¨³å®šè®¾è®¡çš„LPVç¥ç»ç½‘ç»œçŠ¶æ€ç©ºé—´æ¨¡å‹ï¼šåŒæ—¶ä»æ•°æ®å­¦ä¹ æ½œæ€å’Œå†…è°ƒåº¦å˜é‡', 'title_zh': 'è®¾è®¡ç¨³å®šçš„åŸºäºç¥ç»ç½‘ç»œçš„LPVçŠ¶æ€ç©ºé—´æ¨¡å‹ç”¨äºç³»ç»Ÿè¯†åˆ«'}
{'arxiv_id': 'arXiv:2510.24749', 'title': 'Beyond Function-Level Search: Repository-Aware Dual-Encoder Code Retrieval with Adversarial Verification', 'authors': 'Aofan Liu, Shiyuan Song, Haoxuan Li, Cehao Yang, Yiyan Qi', 'link': 'https://arxiv.org/abs/2510.24749', 'abstract': 'The escalating complexity of modern codebases has intensified the need for retrieval systems capable of interpreting cross-component change intents, a capability fundamentally absent in conventional function-level search paradigms. While recent studies have improved the alignment between natural language queries and code snippets, retrieving contextually relevant code for specific change requests remains largely underexplored. To address this gap, we introduce RepoAlign-Bench, the first benchmark specifically designed to evaluate repository-level code retrieval under change request driven scenarios, encompassing 52k annotated instances. This benchmark shifts the retrieval paradigm from function-centric matching to holistic repository-level reasoning. Furthermore, we propose ReflectCode, an adversarial reflection augmented dual-tower architecture featuring disentangled code_encoder and doc_encoder components. ReflectCode dynamically integrates syntactic patterns, function dependencies, and semantic expansion intents through large language model guided reflection. Comprehensive experiments demonstrate that ReflectCode achieves 12.2% improvement in Top-5 Accuracy and 7.1% in Recall over state-of-the-art baselines, establishing a new direction for context-aware code retrieval.', 'abstract_zh': 'ç°ä»£ä»£ç åº“çš„æ—¥ç›Šå¤æ‚æ€§åŠ å‰§äº†å¯¹èƒ½å¤Ÿè§£æè·¨ç»„ä»¶æ›´æ”¹æ„å›¾çš„æ£€ç´¢ç³»ç»Ÿçš„éœ€æ±‚ï¼Œè€Œä¼ ç»Ÿå‡½æ•°çº§æœç´¢èŒƒå¼ä¸­ç¼ºä¹è¿™ç§èƒ½åŠ›ã€‚å°½ç®¡è¿‘æœŸç ”ç©¶å·²æ”¹å–„äº†è‡ªç„¶è¯­è¨€æŸ¥è¯¢ä¸ä»£ç ç‰‡æ®µä¹‹é—´çš„åŒ¹é…åº¦ï¼Œä½†åœ¨ç‰¹å®šæ›´æ”¹è¯·æ±‚ä¸‹æ£€ç´¢ä¸Šä¸‹æ–‡ç›¸å…³ä»£ç ä»ç„¶é²œæœ‰æ¢ç´¢ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†RepoAlign-Benchï¼Œè¿™æ˜¯é¦–ä¸ªä¸“é—¨ä¸ºåŸºäºæ›´æ”¹è¯·æ±‚é©±åŠ¨åœºæ™¯ä¸‹çš„ä»“åº“çº§ä»£ç æ£€ç´¢è®¾è®¡çš„åŸºå‡†ï¼ŒåŒ…å«52,000ä¸ªæ ‡æ³¨å®ä¾‹ã€‚è¯¥åŸºå‡†å°†æ£€ç´¢èŒƒå¼ä»ä»¥å‡½æ•°ä¸ºä¸­å¿ƒçš„åŒ¹é…è½¬å˜ä¸ºæ•´ä½“ä»“åº“çº§æ¨ç†ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ReflectCodeï¼Œè¿™æ˜¯ä¸€ç§å¯¹æŠ—æ€§åæ€å¢å¼ºçš„åŒå¡”æ¶æ„ï¼Œå…·æœ‰åˆ†ç¦»çš„code_encoderå’Œdoc_encoderç»„ä»¶ã€‚ReflectCodeé€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹å¼•å¯¼çš„åæ€åŠ¨æ€ç»¼åˆè¯­æ³•è§„åˆ™æ¨¡å¼ã€å‡½æ•°ä¾èµ–æ€§å’Œè¯­ä¹‰æ‰©å±•æ„å›¾ã€‚å…¨é¢çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒReflectCodeåœ¨Top-5å‡†ç¡®ç‡ä¸Šæ¯”æœ€å…ˆè¿›çš„åŸºçº¿æé«˜äº†12.2%ï¼Œåœ¨å¬å›ç‡ä¸Šæé«˜äº†7.1%ï¼Œä¸ºä¸Šä¸‹æ–‡æ„ŸçŸ¥ä»£ç æ£€ç´¢å¼€è¾Ÿäº†æ–°æ–¹å‘ã€‚', 'title_zh': 'è¶…è¶ŠåŠŸèƒ½çº§åˆ«æœç´¢ï¼šå…·æœ‰å¯¹æŠ—éªŒè¯çš„ä»“åº“æ„è¯†åŒç¼–ç å™¨ä»£ç æ£€ç´¢'}
{'arxiv_id': 'arXiv:2510.24748', 'title': 'EcoScaleNet: A Lightweight Multi Kernel Network for Long Sequence 12 lead ECG Classification', 'authors': 'Dong-Hyeon Kang, Ju-Hyeon Nam, Sang-Chul Lee', 'link': 'https://arxiv.org/abs/2510.24748', 'abstract': 'Accurate interpretation of 12 lead electrocardiograms (ECGs) is critical for early detection of cardiac abnormalities, yet manual reading is error prone and existing CNN based classifiers struggle to choose receptive field sizes that generalize to the long sequences typical of ECGs. Omni Scale CNN (OS CNN) addresses this by enumerating prime sized kernels inspired by Goldbach conjecture to cover every scale, but its exhaustive design explodes computational cost and blocks deeper, wider models. We present Efficient Convolutional Omni Scale Network (EcoScale-Net), a hierarchical variant that retains full receptive field coverage while eliminating redundancy. At each stage, the maximum kernel length is capped to the scale still required after down sampling, and bottleneck convolutions inserted before and after every Omni Scale block curtail channel growth and fuse multi scale features. On the large scale CODE 15% ECG dataset, EcoScaleNet reduces parameters by 90% and FLOPs by 99% compared with OS CNN, while raising macro averaged F1 score by 2.4%. These results demonstrate that EcoScaleNet delivers SOTA accuracy for long sequence ECG classification at a fraction of the computational cost, enabling real time deployment on commodity hardware. Our EcoScaleNet code is available in GitHub Link.', 'abstract_zh': 'Efficient Convolutional Omni Scale Network for Long Sequence ECG Classification', 'title_zh': 'EcoScaleNetï¼šä¸€ç§è½»é‡çº§å¤šæ ¸ç½‘ç»œåœ¨é•¿åºåˆ—12å¯¼è”ECGåˆ†ç±»ä¸­åº”ç”¨'}
{'arxiv_id': 'arXiv:2510.24744', 'title': 'PulseFi: A Low Cost Robust Machine Learning System for Accurate Cardiopulmonary and Apnea Monitoring Using Channel State Information', 'authors': 'Pranay Kocheta, Nayan Sanjay Bhatia, Katia Obraczka', 'link': 'https://arxiv.org/abs/2510.24744', 'abstract': 'Non-intrusive monitoring of vital signs has become increasingly important in a variety of healthcare settings. In this paper, we present PulseFi, a novel low-cost non-intrusive system that uses Wi-Fi sensing and artificial intelligence to accurately and continuously monitor heart rate and breathing rate, as well as detect apnea events. PulseFi operates using low-cost commodity devices, making it more accessible and cost-effective. It uses a signal processing pipeline to process Wi-Fi telemetry data, specifically Channel State Information (CSI), that is fed into a custom low-compute Long Short-Term Memory (LSTM) neural network model. We evaluate PulseFi using two datasets: one that we collected locally using ESP32 devices and another that contains recordings of 118 participants collected using the Raspberry Pi 4B, making the latter the most comprehensive data set of its kind. Our results show that PulseFi can effectively estimate heart rate and breathing rate in a seemless non-intrusive way with comparable or better accuracy than multiple antenna systems that can be expensive and less accessible.', 'abstract_zh': 'éä¾µå…¥å¼é‡è¦ä½“å¾ç›‘æµ‹åœ¨å„ç§åŒ»ç–—ä¿å¥ç¯å¢ƒä¸­å˜å¾—æ—¥ç›Šé‡è¦ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°å‹ä½æˆæœ¬éä¾µå…¥å¼ç³»ç»ŸPulseFiï¼Œè¯¥ç³»ç»Ÿåˆ©ç”¨Wi-Fiä¼ æ„Ÿå’Œäººå·¥æ™ºèƒ½æŠ€æœ¯å‡†ç¡®ä¸”è¿ç»­åœ°ç›‘æµ‹å¿ƒç‡å’Œå‘¼å¸ç‡ï¼Œå¹¶æ£€æµ‹å‘¼å¸æš‚åœäº‹ä»¶ã€‚PulseFi ä½¿ç”¨ä½æˆæœ¬çš„å•†å“åŒ–è®¾å¤‡è¿è¡Œï¼Œä½¿å…¶æ›´å…·å¯è®¿é—®æ€§å’Œæˆæœ¬æ•ˆç›Šã€‚å®ƒä½¿ç”¨ä¿¡å·å¤„ç†æµæ°´çº¿å¤„ç†æ¥è‡ªWi-Fié¥æµ‹æ•°æ®ï¼Œç‰¹åˆ«æ˜¯ä¿¡é“çŠ¶æ€ä¿¡æ¯(CSI)ï¼Œå¹¶å°†å…¶è¾“å…¥è‡ªå®šä¹‰ä½è®¡ç®—é‡çš„é•¿çŸ­æœŸè®°å¿†(LSTM)ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚æˆ‘ä»¬ä½¿ç”¨ä¸¤ä¸ªæ•°æ®é›†è¯„ä¼°PulseFiï¼šä¸€ä¸ªä½¿ç”¨ESP32è®¾å¤‡åœ¨å½“åœ°æ”¶é›†çš„æ•°æ®é›†ï¼Œå¦ä¸€ä¸ªåŒ…å«ä½¿ç”¨Raspberry Pi 4Bæ”¶é›†çš„118åå‚ä¸è€…çš„å½•éŸ³ï¼Œåè€…æ˜¯æ­¤ç±»æ•°æ®ä¸­æœ€å…¨é¢çš„æ•°æ®é›†ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒPulseFi èƒ½ä»¥æ— ç¼éä¾µå…¥å¼æ–¹å¼æœ‰æ•ˆåœ°ä¼°è®¡å¿ƒç‡å’Œå‘¼å¸ç‡ï¼Œå…¶å‡†ç¡®åº¦ä¸å¤šç§å¤©çº¿ç³»ç»Ÿç›¸å½“æˆ–æ›´ä¼˜ï¼Œè€Œè¿™äº›å¤©çº¿ç³»ç»Ÿå¯èƒ½æ˜‚è´µä¸”ä¸é‚£ä¹ˆæ˜“äºè·å–ã€‚', 'title_zh': 'PulseFiï¼šä¸€ç§åŸºäºä¿¡é“çŠ¶æ€ä¿¡æ¯çš„ä½æˆæœ¬ç¨³å¥æœºå™¨å­¦ä¹ ç³»ç»Ÿï¼Œç”¨äºå‡†ç¡®çš„å¿ƒè‚ºå’Œç¡çœ å‘¼å¸æš‚åœç›‘æµ‹'}
{'arxiv_id': 'arXiv:2510.24737', 'title': 'Cardi-GPT: An Expert ECG-Record Processing Chatbot', 'authors': 'Koustav Mallick, Neel Singh, Mohammedreza Hajiarbabi', 'link': 'https://arxiv.org/abs/2510.24737', 'abstract': 'Interpreting and communicating electrocardiogram (ECG) findings are crucial yet challenging tasks in cardiovascular diagnosis, traditionally requiring significant expertise and precise clinical communication. This paper introduces Cardi-GPT, an advanced expert system designed to streamline ECG interpretation and enhance clinical communication through deep learning and natural language interaction. Cardi-GPT employs a 16-residual-block convolutional neural network (CNN) to process 12-lead ECG data, achieving a weighted accuracy of 0.6194 across 24 cardiac conditions. A novel fuzzification layer converts complex numerical outputs into clinically meaningful linguistic categories, while an integrated chatbot interface facilitates intuitive exploration of diagnostic insights and seamless communication between healthcare providers.\nThe system was evaluated on a diverse dataset spanning six hospitals across four countries, demonstrating superior performance compared to baseline models. Additionally, Cardi-GPT achieved an impressive overall response quality score of 73\\%, assessed using a comprehensive evaluation framework that measures coverage, grounding, and coherence. By bridging the gap between intricate ECG data interpretation and actionable clinical insights, Cardi-GPT represents a transformative innovation in cardiovascular healthcare, promising to improve diagnostic accuracy, clinical workflows, and patient outcomes across diverse medical settings.', 'abstract_zh': 'åŸºäºæ·±åº¦å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€äº¤äº’çš„å¿ƒç”µå›¾è§£é‡Šä¸ä¸´åºŠæ²Ÿé€šä¸“å®¶ç³»ç»ŸCardi-GPT', 'title_zh': 'Cardi-GPT: ä¸“å®¶çº§å¿ƒç”µå›¾è®°å½•å¤„ç†èŠå¤©æœºå™¨äºº'}
{'arxiv_id': 'arXiv:2510.24732', 'title': 'Flows, straight but not so fast: Exploring the design space of Rectified Flows in Protein Design', 'authors': 'Junhua Chen, Simon Mathis, Charles Harris, Kieran Didi, Pietro Lio', 'link': 'https://arxiv.org/abs/2510.24732', 'abstract': 'Generative modeling techniques such as Diffusion and Flow Matching have achieved significant successes in generating designable and diverse protein backbones. However, many current models are computationally expensive, requiring hundreds or even thousands of function evaluations (NFEs) to yield samples of acceptable quality, which can become a bottleneck in practical design campaigns that often generate $10^4\\ -\\ 10^6$ designs per target. In image generation, Rectified Flows (ReFlow) can significantly reduce the required NFEs for a given target quality, but their application in protein backbone generation has been less studied. We apply ReFlow to improve the low NFE performance of pretrained SE(3) flow matching models for protein backbone generation and systematically study ReFlow design choices in the context of protein generation in data curation, training and inference time settings. In particular, we (1) show that ReFlow in the protein domain is particularly sensitive to the choice of coupling generation and annealing, (2) demonstrate how useful design choices for ReFlow in the image domain do not directly translate to better performance on proteins, and (3) make improvements to ReFlow methodology for proteins.', 'abstract_zh': 'ç”Ÿæˆæ¨¡å‹æŠ€æœ¯å¦‚æ‰©æ•£å’ŒæµåŠ¨åŒ¹é…åœ¨ç”Ÿæˆå¯è®¾è®¡å’Œå¤šæ ·çš„è›‹ç™½è´¨éª¨æ¶æ–¹é¢å–å¾—äº†æ˜¾è‘—æˆæœã€‚ç„¶è€Œï¼Œè®¸å¤šå½“å‰æ¨¡å‹åœ¨è®¡ç®—ä¸Šéå¸¸æ˜‚è´µï¼Œéœ€è¦æ•°ç™¾ç”šè‡³æ•°åƒæ¬¡å‡½æ•°è¯„ä¼°ï¼ˆNFEsï¼‰æ‰èƒ½ç”Ÿæˆè´¨é‡å¯æ¥å—çš„æ ·æœ¬ï¼Œè¿™åœ¨é€šå¸¸ç”Ÿæˆ$10^4 - 10^6$ä¸ªè®¾è®¡çš„ç›®æ ‡è®¾è®¡æ´»åŠ¨ä¸­å¯èƒ½æˆä¸ºç“¶é¢ˆã€‚åœ¨å›¾åƒç”Ÿæˆä¸­ï¼Œä¿®æ­£æµåŠ¨ï¼ˆReFlowï¼‰å¯ä»¥æ˜¾è‘—å‡å°‘è¾¾åˆ°ç»™å®šç›®æ ‡è´¨é‡æ‰€éœ€çš„NFEsï¼Œä½†å…¶åœ¨è›‹ç™½è´¨éª¨æ¶ç”Ÿæˆä¸­çš„åº”ç”¨ç ”ç©¶è¾ƒå°‘ã€‚æˆ‘ä»¬å°†ReFlowåº”ç”¨äºæé«˜é¢„è®­ç»ƒSE(3)æµåŠ¨åŒ¹é…æ¨¡å‹åœ¨è›‹ç™½è´¨éª¨æ¶ç”Ÿæˆä¸­çš„ä½NFEæ€§èƒ½ï¼Œå¹¶åœ¨æ•°æ®æ•´ç†ã€è®­ç»ƒå’Œæ¨ç†æ—¶é—´è®¾ç½®çš„è›‹ç™½è´¨ç”ŸæˆèƒŒæ™¯ä¸‹ç³»ç»Ÿç ”ç©¶ReFlowçš„è®¾è®¡é€‰æ‹©ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ï¼ˆ1ï¼‰å±•ç¤ºäº†è›‹ç™½è´¨é¢†åŸŸä¸­çš„ReFlowç‰¹åˆ«æ•æ„Ÿäºè€¦åˆç”Ÿæˆå’Œé€€ç«çš„é€‰æ‹©ï¼Œï¼ˆ2ï¼‰è¯æ˜äº†å›¾åƒé¢†åŸŸä¸­å¯¹ReFlowæœ‰ç”¨çš„ design choices å¹¶ä¸èƒ½ç›´æ¥è½¬åŒ–ä¸ºè›‹ç™½è´¨ä¸Šçš„æ›´å¥½æ€§èƒ½ï¼Œå¹¶ï¼ˆ3ï¼‰å¯¹è›‹ç™½è´¨ä¸­çš„ReFlowæ–¹æ³•è¿›è¡Œäº†æ”¹è¿›ã€‚', 'title_zh': 'æµåŠ¨çš„è·¯å¾„ï¼Œç›´è€Œå¹¶éç–¾è¡Œï¼šæ¢ç´¢è›‹ç™½è´¨è®¾è®¡ä¸­ä¿®æ­£æµåŠ¨çš„è®¾è®¡ç©ºé—´'}
{'arxiv_id': 'arXiv:2510.24729', 'title': 'Beyond Models: A Framework for Contextual and Cultural Intelligence in African AI Deployment', 'authors': 'Qness Ndlovu', 'link': 'https://arxiv.org/abs/2510.24729', 'abstract': 'While global AI development prioritizes model performance and computational scale, meaningful deployment in African markets requires fundamentally different architectural decisions. This paper introduces Contextual and Cultural Intelligence (CCI) -- a systematic framework enabling AI systems to process cultural meaning, not just data patterns, through locally relevant, emotionally intelligent, and economically inclusive design. Using design science methodology, we validate CCI through a production AI-native cross-border shopping platform serving diaspora communities. Key empirical findings: 89% of users prefer WhatsApp-based AI interaction over traditional web interfaces (n=602, chi-square=365.8, p<0.001), achieving 536 WhatsApp users and 3,938 total conversations across 602 unique users in just 6 weeks, and culturally informed prompt engineering demonstrates sophisticated understanding of culturally contextualized queries, with 89% family-focused commerce patterns and natural code-switching acceptance. The CCI framework operationalizes three technical pillars: Infrastructure Intelligence (mobile-first, resilient architectures), Cultural Intelligence (multilingual NLP with social context awareness), and Commercial Intelligence (trust-based conversational commerce). This work contributes both theoretical innovation and reproducible implementation patterns, challenging Silicon Valley design orthodoxies while providing actionable frameworks for equitable AI deployment across resource-constrained markets.', 'abstract_zh': 'å…¨çƒAIå‘å±•é‡è§†æ¨¡å‹æ€§èƒ½ä¸è®¡ç®—è§„æ¨¡ï¼Œä½†åœ¨éæ´²å¸‚åœºçš„æœ‰æ„ä¹‰éƒ¨ç½²éœ€è¦æ ¹æœ¬ä¸åŒçš„æ¶æ„å†³ç­–ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æƒ…å¢ƒä¸æ–‡åŒ–æ™ºèƒ½ï¼ˆCCIï¼‰ä½“ç³»æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡æœ¬åœ°ç›¸å…³ã€æƒ…æ„Ÿæ™ºèƒ½å’Œç»æµåŒ…å®¹çš„è®¾è®¡ï¼Œä½¿AIç³»ç»Ÿèƒ½å¤Ÿå¤„ç†æ–‡åŒ–æ„ä¹‰ï¼Œè€Œä¸ä»…ä»…æ˜¯æ•°æ®æ¨¡å¼ã€‚é€šè¿‡ä½¿ç”¨è®¾è®¡ç§‘å­¦æ–¹æ³•ï¼Œæˆ‘ä»¬é€šè¿‡æœåŠ¡äºéæ´²ä¾¨æ°‘ç¤¾åŒºçš„åŸç”Ÿç”Ÿäº§åŠ›è·¨å¢ƒè´­ç‰©å¹³å°éªŒè¯äº†CCIã€‚å…³é”®å®è¯å‘ç°ï¼š602åç”¨æˆ·ä¸­89%çš„ç”¨æˆ·åå¥½åŸºäºWhatsAppçš„AIäº’åŠ¨è€Œéä¼ ç»Ÿçš„ç½‘é¡µç•Œé¢ï¼ˆå¡æ–¹æ£€éªŒå€¼ä¸º365.8ï¼Œp<0.001ï¼‰ï¼Œä»…6å‘¨å†…è·å¾—äº†3938æ¬¡å…±602åç”¨æˆ·çš„å¯¹è¯ï¼ŒWhatsAppç”¨æˆ·è¾¾536äººï¼Œå¹¶ä¸”æ–‡åŒ–å¯¼å‘çš„æç¤ºå·¥ç¨‹å±•ç¤ºäº†å¯¹æ–‡åŒ–ä¸Šä¸‹æ–‡æŸ¥è¯¢çš„å¤æ‚ç†è§£ï¼Œ89%çš„å®¶åº­å¯¼å‘å•†ä¸šæ¨¡å¼æ¨¡å¼ä»¥åŠè‡ªç„¶è¯­è¨€åˆ‡æ¢çš„æ¥å—åº¦ã€‚CCIæ¡†æ¶å®ç°äº†ä¸‰ä¸ªæŠ€æœ¯æ”¯æŸ±ï¼šåŸºç¡€è®¾æ–½æ™ºèƒ½ï¼ˆä»¥ç§»åŠ¨ä¼˜å…ˆå’Œå¼¹æ€§æ¶æ„ä¸ºåŸºç¡€ï¼‰ã€æ–‡åŒ–æ™ºèƒ½ï¼ˆå¤šè¯­è¨€NLPç»“åˆç¤¾ä¼šè¯­å¢ƒæ„ŸçŸ¥ï¼‰ä»¥åŠå•†ä¸šæ™ºèƒ½ï¼ˆåŸºäºä¿¡ä»»çš„å¯¹è¯å¼ commerceï¼‰ã€‚æœ¬æ–‡æ—¢è´¡çŒ®äº†ç†è®ºä¸Šçš„åˆ›æ–°ï¼Œä¹Ÿæä¾›äº†å¯å¤åˆ¶çš„å®æ–½æ¨¡å¼ï¼ŒæŒ‘æˆ˜äº†ç¡…è°·çš„è®¾è®¡æ­£ç»Ÿè§‚å¿µï¼ŒåŒæ—¶ä¸ºèµ„æºå—é™å¸‚åœºä¸­çš„å…¬å¹³AIéƒ¨ç½²æä¾›äº†å¯æ“ä½œçš„æ¡†æ¶ã€‚', 'title_zh': 'è¶…è¶Šæ¨¡å‹ï¼šéæ´²AIéƒ¨ç½²ä¸­çš„æƒ…å¢ƒä¸æ–‡åŒ–æ™ºèƒ½æ¡†æ¶'}
{'arxiv_id': 'arXiv:2510.24724', 'title': 'AmarDoctor: An AI-Driven, Multilingual, Voice-Interactive Digital Health Application for Primary Care Triage and Patient Management to Bridge the Digital Health Divide for Bengali Speakers', 'authors': 'Nazmun Nahar, Ritesh Harshad Ruparel, Shariar Kabir, Sumaiya Tasnia Khan, Shyamasree Saha, Mamunur Rashid', 'link': 'https://arxiv.org/abs/2510.24724', 'abstract': 'This study presents AmarDoctor, a multilingual voice-interactive digital health app designed to provide comprehensive patient triage and AI-driven clinical decision support for Bengali speakers, a population largely underserved in access to digital healthcare. AmarDoctor adopts a data-driven approach to strengthen primary care delivery and enable personalized health management. While platforms such as AdaHealth, WebMD, Symptomate, and K-Health have become popular in recent years, they mainly serve European demographics and languages. AmarDoctor addresses this gap with a dual-interface system for both patients and healthcare providers, supporting three major Bengali dialects. At its core, the patient module uses an adaptive questioning algorithm to assess symptoms and guide users toward the appropriate specialist. To overcome digital literacy barriers, it integrates a voice-interactive AI assistant that navigates users through the app services. Complementing this, the clinician-facing interface incorporates AI-powered decision support that enhances workflow efficiency by generating structured provisional diagnoses and treatment recommendations. These outputs inform key services such as e-prescriptions, video consultations, and medical record management. To validate clinical accuracy, the system was evaluated against a gold-standard set of 185 clinical vignettes developed by experienced physicians. Effectiveness was further assessed by comparing AmarDoctor performance with five independent physicians using the same vignette set. Results showed AmarDoctor achieved a top-1 diagnostic precision of 81.08 percent (versus physicians average of 50.27 percent) and a top specialty recommendation precision of 91.35 percent (versus physicians average of 62.6 percent).', 'abstract_zh': 'AmarDoctorï¼šä¸€ç§é¢å‘å­ŸåŠ æ‹‰è¯­ä½¿ç”¨è€…çš„å¤šè¯­è¨€è¯­éŸ³äº’åŠ¨æ•°å­—å¥åº·åº”ç”¨ï¼Œæä¾›å…¨é¢æ‚£è€…åˆ†æµå’ŒAIé©±åŠ¨çš„ä¸´åºŠå†³ç­–æ”¯æŒ', 'title_zh': 'AmarDoctor: ä¸€ä¸ªåŸºäºAIã€å¤šè¯­è¨€ä¸”å…·è¯­éŸ³äº¤äº’åŠŸèƒ½çš„æ•°å­—å¥åº·åº”ç”¨ï¼Œç”¨äºåˆçº§æŠ¤ç†åˆ†è¯Šå’Œæ‚£è€…ç®¡ç†ï¼Œä»¥ç¼©å°å­ŸåŠ æ‹‰è¯­ä½¿ç”¨è€…çš„æ•°å­—å¥åº·å·®è·ã€‚'}
{'arxiv_id': 'arXiv:2510.24721', 'title': 'The Epistemic Suite: A Post-Foundational Diagnostic Methodology for Assessing AI Knowledge Claims', 'authors': 'Matthew Kelly', 'link': 'https://arxiv.org/abs/2510.24721', 'abstract': 'Large Language Models (LLMs) generate fluent, plausible text that can mislead users into mistaking simulated coherence for genuine understanding. This paper introduces the Epistemic Suite, a post-foundational diagnostic methodology for surfacing the epistemic conditions under which AI outputs are produced and received. Rather than determining truth or falsity, the Suite operates through twenty diagnostic lenses, applied by practitioners as context warrants, to reveal patterns such as confidence laundering, narrative compression, displaced authority, and temporal drift. It is grounded in three design principles: diagnosing production before evaluating claims, preferring diagnostic traction over foundational settlement, and embedding reflexivity as a structural requirement rather than an ethical ornament. When enacted, the Suite shifts language models into a diagnostic stance, producing inspectable artifacts-flags, annotations, contradiction maps, and suspension logs (the FACS bundle)-that create an intermediary layer between AI output and human judgment. A key innovation is epistemic suspension, a practitioner-enacted circuit breaker that halts continuation when warrant is exceeded, with resumption based on judgment rather than rule. The methodology also includes an Epistemic Triage Protocol and a Meta-Governance Layer to manage proportionality and link activation to relational accountability, consent, historical context, and pluralism safeguards. Unlike internalist approaches that embed alignment into model architectures (e.g., RLHF or epistemic-integrity proposals), the Suite operates externally as scaffolding, preserving expendability and refusal as safeguards rather than failures. It preserves the distinction between performance and understanding, enabling accountable deliberation while maintaining epistemic modesty.', 'abstract_zh': 'å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆæµç•…è€Œå¯ä¿¡çš„æ–‡æœ¬ï¼Œå¯èƒ½è¯¯å¯¼ç”¨æˆ·å°†æ¨¡æ‹Ÿè¿è´¯æ€§è¯¯è®¤ä¸ºçœŸå®ç†è§£ã€‚æœ¬æ–‡ä»‹ç»äº†Epistemic Suiteï¼Œè¿™æ˜¯ä¸€ç§ååŸºç¡€è¯Šæ–­æ–¹æ³•è®ºï¼Œç”¨äºæ­ç¤ºAIè¾“å‡ºç”Ÿæˆå’Œæ¥æ”¶çš„èªè­˜æ¡ä»¶ã€‚è¯¥æ–¹æ³•è®ºé€šè¿‡äºŒåä¸ªè¯Šæ–­è§†è§’ï¼Œç”±å®è·µè€…æ ¹æ®å…·ä½“æƒ…å¢ƒåº”ç”¨ï¼Œä»¥æ­ç¤ºè¯¸å¦‚è‡ªä¿¡æ¼‚æ´—ã€å™äº‹å‹ç¼©ã€æƒå¨è½¬ç§»å’Œæ—¶é—´æ¼‚ç§»ç­‰æ¨¡å¼ã€‚Epistemic SuiteåŸºäºä¸‰æ¡è®¾è®¡åŸåˆ™ï¼šåœ¨è¯„ä¼°ä¸»å¼ ä¹‹å‰è¯Šæ–­ç”Ÿæˆè¿‡ç¨‹ã€ä¼˜å…ˆè€ƒè™‘è¯Šæ–­ç‰µå¼•è€ŒéåŸºç¡€å…±è¯†ã€å°†åæ€ä½œä¸ºç»“æ„æ€§è¦æ±‚è€Œéé“å¾·è£…é¥°ã€‚å½“å®æ–½æ—¶ï¼ŒEpistemic Suiteå°†è¯­è¨€æ¨¡å‹ç½®äºè¯Šæ–­å§¿æ€ï¼Œç”Ÿæˆå¯æ£€éªŒçš„æˆæœâ€”â€”æ——å¸œã€æ³¨é‡Šã€çŸ›ç›¾åœ°å›¾å’Œæš‚åœæ—¥å¿—ï¼ˆFACSåŒ…ï¼‰ï¼Œä»è€Œåœ¨AIè¾“å‡ºä¸äººç±»åˆ¤æ–­ä¹‹é—´åˆ›å»ºä¸€ä¸ªä¸­ä»‹å±‚ã€‚ä¸€é¡¹å…³é”®åˆ›æ–°æ˜¯è®¤è¯†è®ºæš‚åœï¼Œè¿™æ˜¯ä¸€ç§ç”±ä»ä¸šäººå‘˜å®æ–½çš„æ–­è·¯å™¨ï¼Œå½“éœ€è¦è¶…å‡ºæ—¶ä¸­æ–­ç»§ç»­ï¼ŒåŸºäºåˆ¤æ–­è€Œéè§„åˆ™æ¢å¤ã€‚è¯¥æ–¹æ³•è®ºè¿˜åŒ…æ‹¬è®¤è¯†è®ºåˆ†è¯Šåè®®å’Œå…ƒæ²»ç†å±‚ï¼Œä»¥ç®¡ç†æˆæ¯”ä¾‹æ€§å’Œå°†æ¿€æ´»ä¸å…³ç³»è´£ä»»ã€åŒæ„ã€å†å²èƒŒæ™¯å’Œå¤šå…ƒä¸»ä¹‰ä¿æŠ¤è”ç³»èµ·æ¥ã€‚ä¸å°†å¯¹é½åµŒå…¥æ¨¡å‹æ¶æ„å†…éƒ¨çš„æ–¹æ³•ï¼ˆå¦‚RLHFæˆ–è®¤è¯†è®ºå®Œæ•´æ€§çš„æè®®ï¼‰ä¸åŒï¼ŒEpistemic Suiteä½œä¸ºå¤–éƒ¨æ¶æ„å­˜åœ¨ï¼Œä¿ç•™å¯æ›¿ä»£æ€§å’Œæ‹’ç»ä½œä¸ºä¿æŠ¤ï¼Œè€Œéå¤±è´¥ã€‚å®ƒä¿ç•™äº†è¡¨ç°ä¸ç†è§£ä¹‹é—´çš„åŒºåˆ†ï¼Œä½¿é—®è´£è®¨è®ºå¾—ä»¥è¿›è¡Œï¼ŒåŒæ—¶ä¿æŒè®¤è¯†ä¸Šçš„è°¦é€Šã€‚', 'title_zh': 'çŸ¥è¯†å¥—ä»¶ï¼šè¯„ä¼°AIçŸ¥è¯†ä¸»å¼ çš„ååŸºç¡€è¯Šæ–­æ–¹æ³•è®º'}
{'arxiv_id': 'arXiv:2510.24720', 'title': 'Modelling the Interplay of Eye-Tracking Temporal Dynamics and Personality for Emotion Detection in Face-to-Face Settings', 'authors': 'Meisam J. Seikavandi, Jostein Fimland, Fabricio Batista Narcizo, Maria Barrett, Ted Vucurevich, Jesper BÃ¼nsow Boldt, Andrew Burke Dittberner, Paolo Burelli', 'link': 'https://arxiv.org/abs/2510.24720', 'abstract': 'Accurate recognition of human emotions is critical for adaptive human-computer interaction, yet remains challenging in dynamic, conversation-like settings. This work presents a personality-aware multimodal framework that integrates eye-tracking sequences, Big Five personality traits, and contextual stimulus cues to predict both perceived and felt emotions. Seventy-three participants viewed speech-containing clips from the CREMA-D dataset while providing eye-tracking signals, personality assessments, and emotion ratings. Our neural models captured temporal gaze dynamics and fused them with trait and stimulus information, yielding consistent gains over SVM and literature baselines. Results show that (i) stimulus cues strongly enhance perceived-emotion predictions (macro F1 up to 0.77), while (ii) personality traits provide the largest improvements for felt emotion recognition (macro F1 up to 0.58). These findings highlight the benefit of combining physiological, trait-level, and contextual information to address the inherent subjectivity of emotion. By distinguishing between perceived and felt responses, our approach advances multimodal affective computing and points toward more personalized and ecologically valid emotion-aware systems.', 'abstract_zh': 'å‡†ç¡®è¯†åˆ«äººç±»æƒ…ç»ªå¯¹äºè‡ªé€‚åº”äººæœºäº¤äº’è‡³å…³é‡è¦ï¼Œä½†åœ¨åŠ¨æ€ã€å¯¹è¯-like çš„ç¯å¢ƒä¸­ä¾ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºäººæ ¼çš„å¤šæ¨¡æ€æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†æ³¨è§†è¿½è¸ªåºåˆ—ã€äº”å¤§äººæ ¼ç‰¹è´¨å’Œæƒ…å¢ƒåˆºæ¿€çº¿ç´¢ï¼Œä»¥é¢„æµ‹æ„ŸçŸ¥å’Œä½“éªŒæƒ…ç»ªã€‚ä¸ƒååå‚ä¸è€…è§‚çœ‹äº†åŒ…å«è¨€è¯­çš„CREMA-Dæ•°æ®é›†ç‰‡æ®µï¼Œæä¾›äº†æ³¨è§†è¿½è¸ªä¿¡å·ã€äººæ ¼è¯„ä¼°å’Œæƒ…ç»ªè¯„åˆ†ã€‚æˆ‘ä»¬çš„ç¥ç»ç½‘ç»œæ¨¡å‹æ•æ‰åˆ°äº†æ—¶é—´ä¸Šçš„æ³¨è§†åŠ¨æ€ï¼Œå¹¶å°†è¿™äº›ä¿¡æ¯ä¸ç‰¹è´¨å’Œåˆºæ¿€ä¿¡æ¯èåˆï¼Œç›¸è¾ƒäºSVMå’Œæ–‡çŒ®åŸºçº¿å®ç°äº†æ˜¾è‘—æ”¹è¿›ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼š(i) åˆºæ¿€çº¿ç´¢æ˜¾è‘—å¢å¼ºæ„ŸçŸ¥æƒ…ç»ªé¢„æµ‹ï¼ˆå®F1å€¼è¾¾åˆ°0.77ï¼‰ï¼Œè€Œ(ii) äººæ ¼ç‰¹è´¨åœ¨ä½“éªŒæƒ…ç»ªè¯†åˆ«æ–¹é¢æä¾›äº†æœ€å¤§çš„æ”¹è¿›ï¼ˆå®F1å€¼è¾¾åˆ°0.58ï¼‰ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†å°†ç”Ÿç†ã€ç‰¹è´¨æ°´å¹³å’Œæƒ…å¢ƒä¿¡æ¯ç»“åˆä»¥åº”å¯¹æƒ…ç»ªå›ºæœ‰çš„ä¸»è§‚æ€§çš„é‡è¦æ€§ã€‚é€šè¿‡åŒºåˆ†æ„ŸçŸ¥å’Œä½“éªŒååº”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ¨è¿›äº†å¤šæ¨¡æ€æƒ…æ„Ÿè®¡ç®—ï¼Œå¹¶æŒ‡å‡ºäº†æ›´ä¸ªæ€§åŒ–å’Œç”Ÿæ€æœ‰æ•ˆçš„æ„ŸçŸ¥ç³»ç»Ÿçš„å‘å±•æ–¹å‘ã€‚', 'title_zh': 'å»ºæ¨¡çœ¼åŠ¨æ—¶é—´åŠ¨æ€ä¸ä¸ªæ€§åœ¨é¢å¯¹é¢æƒ…æ„Ÿæ£€æµ‹ä¸­çš„ç›¸äº’ä½œç”¨'}
{'arxiv_id': 'arXiv:2106.10620', 'title': 'Large-Scale Network Embedding in Apache Spark', 'authors': 'Wenqing Lin', 'link': 'https://arxiv.org/abs/2106.10620', 'abstract': 'Network embedding has been widely used in social recommendation and network analysis, such as recommendation systems and anomaly detection with graphs. However, most of previous approaches cannot handle large graphs efficiently, due to that (i) computation on graphs is often costly and (ii) the size of graph or the intermediate results of vectors could be prohibitively large, rendering it difficult to be processed on a single machine. In this paper, we propose an efficient and effective distributed algorithm for network embedding on large graphs using Apache Spark, which recursively partitions a graph into several small-sized subgraphs to capture the internal and external structural information of nodes, and then computes the network embedding for each subgraph in parallel. Finally, by aggregating the outputs on all subgraphs, we obtain the embeddings of nodes in a linear cost. After that, we demonstrate in various experiments that our proposed approach is able to handle graphs with billions of edges within a few hours and is at least 4 times faster than the state-of-the-art approaches. Besides, it achieves up to $4.25\\%$ and $4.27\\%$ improvements on link prediction and node classification tasks respectively. In the end, we deploy the proposed algorithms in two online games of Tencent with the applications of friend recommendation and item recommendation, which improve the competitors by up to $91.11\\%$ in running time and up to $12.80\\%$ in the corresponding evaluation metrics.', 'abstract_zh': 'åŸºäºApache Sparkçš„å¤§å›¾ç½‘ç»œåµŒå…¥é«˜æ•ˆåˆ†å¸ƒå¼ç®—æ³•åŠå…¶åº”ç”¨', 'title_zh': 'Apache Spark ä¸­çš„å¤§è§„æ¨¡ç½‘ç»œåµŒå…¥'}
