{'arxiv_id': 'arXiv:2507.18819', 'title': 'Probabilistic Collision Risk Estimation through Gauss-Legendre Cubature and Non-Homogeneous Poisson Processes', 'authors': 'Trent Weiss, Madhur Behl', 'link': 'https://arxiv.org/abs/2507.18819', 'abstract': 'Overtaking in high-speed autonomous racing demands precise, real-time estimation of collision risk; particularly in wheel-to-wheel scenarios where safety margins are minimal. Existing methods for collision risk estimation either rely on simplified geometric approximations, like bounding circles, or perform Monte Carlo sampling which leads to overly conservative motion planning behavior at racing speeds. We introduce the Gauss-Legendre Rectangle (GLR) algorithm, a principled two-stage integration method that estimates collision risk by combining Gauss-Legendre with a non-homogeneous Poisson process over time. GLR produces accurate risk estimates that account for vehicle geometry and trajectory uncertainty. In experiments across 446 overtaking scenarios in a high-fidelity Formula One racing simulation, GLR outperforms five state-of-the-art baselines achieving an average error reduction of 77% and surpassing the next-best method by 52%, all while running at 1000 Hz. The framework is general and applicable to broader motion planning contexts beyond autonomous racing.', 'abstract_zh': '高速自主赛车比赛中的超车需求精确且实时的碰撞风险估计；特别是在最小安全 margin 的轮对轮情景中。现有的碰撞风险估计方法要么依赖于简化的几何近似，如边界圆，要么通过蒙特卡洛采样进行计算，这在比赛速度下会导致过于保守的运动规划行为。我们介绍了高斯-勒让德矩形（GLR）算法，这是一种原理上的两阶段整合方法，通过结合高斯-勒让德和非均匀泊松过程来估计碰撞风险。GLR 产生准确的风险估计，考虑了车辆几何形状和轨迹不确定性。在高保真度方程式赛车模拟中的 446 种超车情景中，GLR 在五种最先进的基线方法中表现最佳，平均误差减少了 77%，并比第二佳方法高出 52%，同时运行频率为 1000 Hz。该框架适用于超越自主赛车运动规划的更广泛情境。', 'title_zh': '通过高斯-勒让德求积和非齐次泊松过程的概率碰撞风险估算'}
{'arxiv_id': 'arXiv:2507.18808', 'title': 'Perpetua: Multi-Hypothesis Persistence Modeling for Semi-Static Environments', 'authors': 'Miguel Saavedra-Ruiz, Samer B. Nashed, Charlie Gauthier, Liam Paull', 'link': 'https://arxiv.org/abs/2507.18808', 'abstract': 'Many robotic systems require extended deployments in complex, dynamic environments. In such deployments, parts of the environment may change between subsequent robot observations. Most robotic mapping or environment modeling algorithms are incapable of representing dynamic features in a way that enables predicting their future state. Instead, they opt to filter certain state observations, either by removing them or some form of weighted averaging. This paper introduces Perpetua, a method for modeling the dynamics of semi-static features. Perpetua is able to: incorporate prior knowledge about the dynamics of the feature if it exists, track multiple hypotheses, and adapt over time to enable predicting of future feature states. Specifically, we chain together mixtures of "persistence" and "emergence" filters to model the probability that features will disappear or reappear in a formal Bayesian framework. The approach is an efficient, scalable, general, and robust method for estimating the states of features in an environment, both in the present as well as at arbitrary future times. Through experiments on simulated and real-world data, we find that Perpetua yields better accuracy than similar approaches while also being online adaptable and robust to missing observations.', 'abstract_zh': 'Perpetua：一种用于建模半静态特征动力学的方法', 'title_zh': '永固：半静态环境下的多假设持久性建模'}
{'arxiv_id': 'arXiv:2507.19354', 'title': 'EffiComm: Bandwidth Efficient Multi Agent Communication', 'authors': 'Melih Yazgan, Allen Xavier Arasan, J. Marius Zöllner', 'link': 'https://arxiv.org/abs/2507.19354', 'abstract': "Collaborative perception allows connected vehicles to exchange sensor information and overcome each vehicle's blind spots. Yet transmitting raw point clouds or full feature maps overwhelms Vehicle-to-Vehicle (V2V) communications, causing latency and scalability problems. We introduce EffiComm, an end-to-end framework that transmits less than 40% of the data required by prior art while maintaining state-of-the-art 3D object detection accuracy. EffiComm operates on Bird's-Eye-View (BEV) feature maps from any modality and applies a two-stage reduction pipeline: (1) Selective Transmission (ST) prunes low-utility regions with a confidence mask; (2) Adaptive Grid Reduction (AGR) uses a Graph Neural Network (GNN) to assign vehicle-specific keep ratios according to role and network load. The remaining features are fused with a soft-gated Mixture-of-Experts (MoE) attention layer, offering greater capacity and specialization for effective feature integration. On the OPV2V benchmark, EffiComm reaches 0.84 mAP@0.7 while sending only an average of approximately 1.5 MB per frame, outperforming previous methods on the accuracy-per-bit curve. These results highlight the value of adaptive, learned communication for scalable Vehicle-to-Everything (V2X) perception.", 'abstract_zh': '协作感知使联网车辆能够交换传感器信息并克服每辆车的盲区。然而，传输原始点云或完整特征图会过度占据车辆到车辆（V2V）通信资源，导致延迟和扩展性问题。我们介绍了EffiComm，这是一个端到端框架，与之前的方法相比，仅传输所需数据的不到40%，同时保持最先进的三维物体检测准确性。EffiComm基于任何模态的鸟类视野（BEV）特征图工作，并应用两阶段的减少管道：（1）选择性传输（ST）使用置信度掩码去除低效区域；（2）自适应网格减少（AGR）使用图神经网络（GNN）根据角色和网络负载为每辆车分配保留比率。剩余特征通过软门控混合专家（MoE）注意层融合，提供更大的容量和专业化，以实现有效的特征集成。在OPV2V基准测试中，EffiComm在0.7的平均精度（mAP@0.7）达到0.84的同时，每帧平均发送约1.5 MB的数据，优于先前方法在每比特准确率曲线上的表现。这些结果突显了自适应学习通信对可扩展的车辆到一切（V2X）感知的价值。', 'title_zh': 'EffiComm: 频带高效多代理通信'}
{'arxiv_id': 'arXiv:2507.18938', 'title': 'GMM-Based Time-Varying Coverage Control', 'authors': 'Behzad Zamani, James Kennedy, Airlie Chapman, Peter Dower, Chris Manzie, Simon Crase', 'link': 'https://arxiv.org/abs/2507.18938', 'abstract': 'In coverage control problems that involve time-varying density functions, the coverage control law depends on spatial integrals of the time evolution of the density function. The latter is often neglected, replaced with an upper bound or calculated as a numerical approximation of the spatial integrals involved. In this paper, we consider a special case of time-varying density functions modeled as Gaussian Mixture Models (GMMs) that evolve with time via a set of time-varying sources (with known corresponding velocities). By imposing this structure, we obtain an efficient time-varying coverage controller that fully incorporates the time evolution of the density function. We show that the induced trajectories under our control law minimise the overall coverage cost. We elicit the structure of the proposed controller and compare it with a classical time-varying coverage controller, against which we benchmark the coverage performance in simulation. Furthermore, we highlight that the computationally efficient and distributed nature of the proposed control law makes it ideal for multi-vehicle robotic applications involving time-varying coverage control problems. We employ our method in plume monitoring using a swarm of drones. In an experimental field trial we show that drones guided by the proposed controller are able to track a simulated time-varying chemical plume in a distributed manner.', 'abstract_zh': '涉及时间变化密度函数的覆盖控制问题中，覆盖控制律依赖于密度函数时空积分的演化。通常会忽略这一项，用上界替代或通过数值近似计算。本文中，我们考虑了一类由已知时间变化速度的时间变化源构成的高斯混合模型（GMMs）表示的时间变化密度函数的特例。通过这种方式，我们获得了能够全面考虑密度函数时空演化的高效时间变化覆盖控制器。我们证明了在该控制律下诱导的轨迹能够最小化总体覆盖成本。我们阐明了所提控制器的结构，并将其与经典的时变覆盖控制器进行比较，通过仿真实验评估其覆盖性能。此外，我们强调所提控制律的计算高效性和分布式特性使其非常适合解决多车辆机器人中的时变覆盖控制问题。我们利用该方法进行气团监测，通过实验场试验展示了由所提控制器引导的无人机能够以分布式方式跟踪模拟的时变化学气团。', 'title_zh': '基于GMM的时间 varying 覆盖控制'}
{'arxiv_id': 'arXiv:2507.18763', 'title': 'Diffusion-FS: Multimodal Free-Space Prediction via Diffusion for Autonomous Driving', 'authors': 'Keshav Gupta, Tejas S. Stanley, Pranjal Paul, Arun K. Singh, K. Madhava Krishna', 'link': 'https://arxiv.org/abs/2507.18763', 'abstract': "Drivable Free-space prediction is a fundamental and crucial problem in autonomous driving. Recent works have addressed the problem by representing the entire non-obstacle road regions as the free-space. In contrast our aim is to estimate the driving corridors that are a navigable subset of the entire road region. Unfortunately, existing corridor estimation methods directly assume a BEV-centric representation, which is hard to obtain. In contrast, we frame drivable free-space corridor prediction as a pure image perception task, using only monocular camera input. However such a formulation poses several challenges as one doesn't have the corresponding data for such free-space corridor segments in the image. Consequently, we develop a novel self-supervised approach for free-space sample generation by leveraging future ego trajectories and front-view camera images, making the process of visual corridor estimation dependent on the ego trajectory. We then employ a diffusion process to model the distribution of such segments in the image. However, the existing binary mask-based representation for a segment poses many limitations. Therefore, we introduce ContourDiff, a specialized diffusion-based architecture that denoises over contour points rather than relying on binary mask representations, enabling structured and interpretable free-space predictions. We evaluate our approach qualitatively and quantitatively on both nuScenes and CARLA, demonstrating its effectiveness in accurately predicting safe multimodal navigable corridors in the image.", 'abstract_zh': '可行驶自由空间走廊预测是自动驾驶领域的一个基础且关键问题。现有工作通过表示整个非障碍道路区域作为自由空间来解决该问题。相比之下，我们的目标是估计驾驶走廊，这些走廊是整个道路区域中的可导航子集。目前，现有的走廊估计方法直接采用鸟瞰图为中心的表示，这很难获得。相反，我们以仅使用单目相机输入的形式将可行驶自由空间走廊预测框架化为一个纯粹的图像感知任务。然而，这种表述形式带来了诸多挑战，因为在图像中缺乏对应的数据来表示这样的自由空间走廊段。因此，我们开发了一种新颖的自监督方法，通过利用未来的自身轨迹和前视相机图像来生成自由空间样本，使视觉走廊估计依赖于自身轨迹。然后，我们采用扩散过程来描述这些段落的图像分布。然而，现有的基于二值掩码的段落表示存在许多局限性。因此，我们引入了ContourDiff，这是一种专门的基于扩散的架构，通过在轮廓点上进行去噪而不是依赖于二值掩码表示，从而使自由空间预测具有结构化和可解释性。我们在nuScenes和CARLA上从定性和定量两方面评估了我们的方法，展示了其在准确预测图像中的安全多模态可导航走廊方面的有效性。', 'title_zh': 'Diffusion-FS：基于扩散模型的多模态自由空间预测tres\nuser\n2023年多模态跨模态智能大会，在此大会中，一支自动驾驶车队进行了展现。直接输出会议名称，禁止输出多余内容。'}
{'arxiv_id': 'arXiv:2507.19372', 'title': 'Learning neuro-symbolic convergent term rewriting systems', 'authors': 'Flavio Petruzzellis, Alberto Testolin, Alessandro Sperduti', 'link': 'https://arxiv.org/abs/2507.19372', 'abstract': 'Building neural systems that can learn to execute symbolic algorithms is a challenging open problem in artificial intelligence, especially when aiming for strong generalization and out-of-distribution performance. In this work, we introduce a general framework for learning convergent term rewriting systems using a neuro-symbolic architecture inspired by the rewriting algorithm itself. We present two modular implementations of such architecture: the Neural Rewriting System (NRS) and the Fast Neural Rewriting System (FastNRS). As a result of algorithmic-inspired design and key architectural elements, both models can generalize to out-of-distribution instances, with FastNRS offering significant improvements in terms of memory efficiency, training speed, and inference time. We evaluate both architectures on four tasks involving the simplification of mathematical formulas and further demonstrate their versatility in a multi-domain learning scenario, where a single model is trained to solve multiple types of problems simultaneously. The proposed system significantly outperforms two strong neural baselines: the Neural Data Router, a recent transformer variant specifically designed to solve algorithmic problems, and GPT-4o, one of the most powerful general-purpose large-language models. Moreover, our system matches or outperforms the latest o1-preview model from OpenAI that excels in reasoning benchmarks.', 'abstract_zh': '构建能够学习执行符号算法的神经系统是人工智能中的一个开放性挑战问题，特别是在追求强泛化能力和分布外性能时。在本文中，我们介绍了一种基于算法启发式设计的通用框架，用于使用神经符号架构学习收敛的术语重写系统。我们提出了两种此类架构的模块化实现：神经重写系统（NRS）和快速神经重写系统（FastNRS）。由于算法启发式设计和关键架构元素，两种模型都可以泛化到分布外实例，其中FastNRS在内存效率、训练速度和推理时间方面表现出显著改进。我们在四个涉及数学公式简化任务上评估了这两种架构，并进一步展示了它们在跨域学习场景中的灵活性，其中单个模型同时训练解决多种类型的问题。所提出系统显著优于两种强大的神经基线：神经数据路由器（Neural Data Router），这是一种最近为解决算法问题设计的变体变体变压器，以及GPT-4o，这是最强大的通用大型语言模型之一。此外，我们的系统能够匹配或优于OpenAI的最新o1-preview模型，在推理基准测试中表现出色。', 'title_zh': '学习神经符号收敛术语重写系统'}
{'arxiv_id': 'arXiv:2507.19263', 'title': 'Modeling Uncertainty: Constraint-Based Belief States in Imperfect-Information Games', 'authors': 'Achille Morenville, Éric Piette', 'link': 'https://arxiv.org/abs/2507.19263', 'abstract': 'In imperfect-information games, agents must make decisions based on partial knowledge of the game state. The Belief Stochastic Game model addresses this challenge by delegating state estimation to the game model itself. This allows agents to operate on externally provided belief states, thereby reducing the need for game-specific inference logic. This paper investigates two approaches to represent beliefs in games with hidden piece identities: a constraint-based model using Constraint Satisfaction Problems and a probabilistic extension using Belief Propagation to estimate marginal probabilities. We evaluated the impact of both representations using general-purpose agents across two different games. Our findings indicate that constraint-based beliefs yield results comparable to those of probabilistic inference, with minimal differences in agent performance. This suggests that constraint-based belief states alone may suffice for effective decision-making in many settings.', 'abstract_zh': '在不完善信息博弈中，代理必须基于对游戏状态的部分知识做出决策。信念随机博弈模型通过将状态估计委托给游戏模型本身来解决这一挑战，从而使代理能够基于外部提供的信念状态操作，从而减少针对特定游戏的推理逻辑的需求。本文探讨了两种在隐藏拼图身份的游戏中表示信念的方法：一种基于约束的模型使用约束满足问题，另一种概率扩展使用信念传播来估计边缘概率。我们在两个不同的游戏中使用通用代理评估了这两种表示方法的影响。研究结果表明，基于约束的信念与概率推理产生的结果相当，代理性能差异较小。这表明，在许多情况下，仅基于约束的信念状态可能足以实现有效的决策。', 'title_zh': '基于约束的信念状态建模： imperfect-information 游戏中的不确定性建模'}
{'arxiv_id': 'arXiv:2507.19261', 'title': 'Knowledge Grafting: A Mechanism for Optimizing AI Model Deployment in Resource-Constrained Environments', 'authors': 'Osama Almurshed, Ashish Kaushal, Asmail Muftah, Nitin Auluck, Omer Rana', 'link': 'https://arxiv.org/abs/2507.19261', 'abstract': "The increasing adoption of Artificial Intelligence (AI) has led to larger, more complex models with numerous parameters that require substantial computing power -- resources often unavailable in many real-world application scenarios. Our paper addresses this challenge by introducing knowledge grafting, a novel mechanism that optimizes AI models for resource-constrained environments by transferring selected features (the scion) from a large donor model to a smaller rootstock model. The approach achieves an 88.54% reduction in model size (from 64.39 MB to 7.38 MB), while improving generalization capability of the model. Our new rootstock model achieves 89.97% validation accuracy (vs. donor's 87.47%), maintains lower validation loss (0.2976 vs. 0.5068), and performs exceptionally well on unseen test data with 90.45% accuracy. It addresses the typical size vs performance trade-off, and enables deployment of AI frameworks on resource-constrained devices with enhanced performance. We have tested our approach on an agricultural weed detection scenario, however, it can be extended across various edge computing scenarios, potentially accelerating AI adoption in areas with limited hardware/software support -- by mirroring in a similar manner the horticultural grafting enables productive cultivation in challenging agri-based environments.", 'abstract_zh': 'AI模型知识嫁接：资源受限环境下的高效优化', 'title_zh': '知识嫁接：一种优化资源受限环境下AI模型部署的机制'}
{'arxiv_id': 'arXiv:2507.19182', 'title': 'Faster Lifting for Ordered Domains with Predecessor Relations', 'authors': 'Kuncheng Zou, Jiahao Mai, Yonggang Zhang, Yuyi Wang, Ondřej Kuželka, Yuanhong Wang, Yi Chang', 'link': 'https://arxiv.org/abs/2507.19182', 'abstract': 'We investigate lifted inference on ordered domains with predecessor relations, where the elements of the domain respect a total (cyclic) order, and every element has a distinct (clockwise) predecessor. Previous work has explored this problem through weighted first-order model counting (WFOMC), which computes the weighted sum of models for a given first-order logic sentence over a finite domain. In WFOMC, the order constraint is typically encoded by the linear order axiom introducing a binary predicate in the sentence to impose a linear ordering on the domain elements. The immediate and second predecessor relations are then encoded by the linear order predicate. Although WFOMC with the linear order axiom is theoretically tractable, existing algorithms struggle with practical applications, particularly when the predecessor relations are involved. In this paper, we treat predecessor relations as a native part of the axiom and devise a novel algorithm that inherently supports these relations. The proposed algorithm not only provides an exponential speedup for the immediate and second predecessor relations, which are known to be tractable, but also handles the general k-th predecessor relations. The extensive experiments on lifted inference tasks and combinatorics math problems demonstrate the efficiency of our algorithm, achieving speedups of a full order of magnitude.', 'abstract_zh': '有序域上基于前驱关系的提升推理研究', 'title_zh': '有序域上具有前趋关系的更快提升方法'}
{'arxiv_id': 'arXiv:2507.19132', 'title': 'OS-MAP: How Far Can Computer-Using Agents Go in Breadth and Depth?', 'authors': 'Xuetian Chen, Yinghao Chen, Xinfeng Yuan, Zhuo Peng, Lu Chen, Yuekeng Li, Zhoujia Zhang, Yingqian Huang, Leyan Huang, Jiaqing Liang, Tianbao Xie, Zhiyong Wu, Qiushi Sun, Biqing Qi, Bowen Zhou', 'link': 'https://arxiv.org/abs/2507.19132', 'abstract': 'Computer-using agents have shown strong potential to boost human productivity and enable new application forms across platforms. While recent advances have led to usable applications, existing benchmarks fail to account for the internal task heterogeneity and the corresponding agent capabilities, as well as their alignment with actual user demands-hindering both targeted capability development and the reliable transition of research progress into practical deployment. To bridge the gap, we present OS-MAP, a benchmark for daily computer-using automation that organizes its 416 realistic tasks across 15 applications along two key dimensions: a five-level taxonomy of automation and a generalization scope derived from a real-world user demand hierarchy. To enable fine-grained analysis of required capabilities and alignment with real-world scenarios, OS-MAP evaluates agents along two dimensions: automation level across a five-level taxonomy, and generalization scope across a demand hierarchy. This design captures varying levels of required agent autonomy and generalization, forming a performance-generalization evaluation matrix for structured and comprehensive assessment. Experiments show that even State-of-the-Art agents with VLM backbones struggle with higher-level tasks involving perception, reasoning, and coordination-highlighting the need for a deeper understanding of current strengths and limitations to drive the future progress in computer-using agents research and deployment. All code, environments, baselines, and data are publicly available at this https URL.', 'abstract_zh': '基于计算机的任务代理在提升人类生产力和跨平台启用新型应用形式方面展示了强大的潜力。现有基准未能充分考虑任务内部异质性和相应的代理能力，以及这些能力与实际用户需求的对齐问题，这阻碍了有针对性的能力开发，并阻碍了研究进展向实际部署的可靠过渡。为解决这一问题，我们提出OS-MAP基准，用于日常计算机使用自动化，该基准根据两个关键维度组织其416个实际任务，涵盖15个应用程序：五级自动化 taxonomy 和来自真实用户需求层次的一般化范围。为实现对所需能力的精细分析和与现实场景的对齐，OS-MAP沿两个维度评估代理：沿五级自动化 taxonomy 的自动化水平，以及沿需求层次的一般化范围。该设计捕捉了代理所需的不同自主性和一般化水平，形成了一个性能-一般化评估矩阵，用于有条理和全面的评估。实验表明，即便是基于VLM的最先进的代理也难以处理涉及感知、推理和协调的更高层级任务，强调了深入理解当前优势和局限性的必要性，以推动计算机使用代理研究和部署的未来发展。所有代码、环境、基线和数据均可在以下网址公开获取。', 'title_zh': 'OS-MAP: 计算机使用代理在广度和深度上能走多远？'}
{'arxiv_id': 'arXiv:2507.19109', 'title': 'Pareto-NRPA: A Novel Monte-Carlo Search Algorithm for Multi-Objective Optimization', 'authors': 'Noé Lallouet, Tristan Cazenave, Cyrille Enderli', 'link': 'https://arxiv.org/abs/2507.19109', 'abstract': 'We introduce Pareto-NRPA, a new Monte-Carlo algorithm designed for multi-objective optimization problems over discrete search spaces. Extending the Nested Rollout Policy Adaptation (NRPA) algorithm originally formulated for single-objective problems, Pareto-NRPA generalizes the nested search and policy update mechanism to multi-objective optimization. The algorithm uses a set of policies to concurrently explore different regions of the solution space and maintains non-dominated fronts at each level of search. Policy adaptation is performed with respect to the diversity and isolation of sequences within the Pareto front. We benchmark Pareto-NRPA on two classes of problems: a novel bi-objective variant of the Traveling Salesman Problem with Time Windows problem (MO-TSPTW), and a neural architecture search task on well-known benchmarks. Results demonstrate that Pareto-NRPA achieves competitive performance against state-of-the-art multi-objective algorithms, both in terms of convergence and diversity of solutions. Particularly, Pareto-NRPA strongly outperforms state-of-the-art evolutionary multi-objective algorithms on constrained search spaces. To our knowledge, this work constitutes the first adaptation of NRPA to the multi-objective setting.', 'abstract_zh': 'Pareto-NRPA：一种用于离散搜索空间多目标优化问题的新型蒙特卡洛算法', 'title_zh': '帕累托-NRPA：多目标优化的一种新型蒙特卡罗搜索算法'}
{'arxiv_id': 'arXiv:2507.19089', 'title': 'Fine-Grained Traffic Inference from Road to Lane via Spatio-Temporal Graph Node Generation', 'authors': 'Shuhao Li, Weidong Yang, Yue Cui, Xiaoxing Liu, Lingkai Meng, Lipeng Ma, Fan Zhang', 'link': 'https://arxiv.org/abs/2507.19089', 'abstract': 'Fine-grained traffic management and prediction are fundamental to key applications such as autonomous driving, lane change guidance, and traffic signal control. However, obtaining lane-level traffic data has become a critical bottleneck for data-driven models due to limitations in the types and number of sensors and issues with the accuracy of tracking algorithms. To address this, we propose the Fine-grained Road Traffic Inference (FRTI) task, which aims to generate more detailed lane-level traffic information using limited road data, providing a more energy-efficient and cost-effective solution for precise traffic management. This task is abstracted as the first scene of the spatio-temporal graph node generation problem. We designed a two-stage framework--RoadDiff--to solve the FRTI task. solve the FRTI task. This framework leverages the Road-Lane Correlation Autoencoder-Decoder and the Lane Diffusion Module to fully utilize the limited spatio-temporal dependencies and distribution relationships of road data to accurately infer fine-grained lane traffic states. Based on existing research, we designed several baseline models with the potential to solve the FRTI task and conducted extensive experiments on six datasets representing different road conditions to validate the effectiveness of the RoadDiff model in addressing the FRTI task. The relevant datasets and code are available at this https URL.', 'abstract_zh': '精细的道路交通推断与预测对于自动驾驶、车道变更指导和交通信号控制等关键应用至关重要。然而，由于传感器类型和数量的限制以及跟踪算法准确性的限制，获取车道级交通数据已成为数据驱动模型中的关键瓶颈。为此，我们提出了精细的道路交通推断（FRTI）任务，旨在利用有限的道路数据生成更详细的车道级交通信息，提供一种更具能源效率和成本效益的精确交通管理解决方案。该任务被抽象为时空图节点生成问题的第一阶段。我们设计了一个两阶段框架——RoadDiff，以解决FRTI任务。该框架利用道路-车道关联自动编码器-解码器和车道扩散模块，充分利用有限的时空依赖性和分布关系，准确推断车道级交通状态。基于现有研究，我们设计了几种潜在能够解决FRTI任务的基准模型，并在六个代表不同道路条件的数据集上进行了大量实验，以验证RoadDiff模型在解决FRTI任务中的有效性。相关数据集和代码可在以下链接获取：[this https URL]。', 'title_zh': '基于空间-时间图节点生成的从道路到车道的细粒度交通推断'}
{'arxiv_id': 'arXiv:2507.18977', 'title': 'Towards Improving Long-Tail Entity Predictions in Temporal Knowledge Graphs through Global Similarity and Weighted Sampling', 'authors': 'Mehrnoosh Mirtaheri, Ryan A. Rossi, Sungchul Kim, Kanak Mahadik, Tong Yu, Xiang Chen, Mohammad Rostami', 'link': 'https://arxiv.org/abs/2507.18977', 'abstract': "Temporal Knowledge Graph (TKG) completion models traditionally assume access to the entire graph during training. This overlooks challenges stemming from the evolving nature of TKGs, such as: (i) the model's requirement to generalize and assimilate new knowledge, and (ii) the task of managing new or unseen entities that often have sparse connections. In this paper, we present an incremental training framework specifically designed for TKGs, aiming to address entities that are either not observed during training or have sparse connections. Our approach combines a model-agnostic enhancement layer with a weighted sampling strategy, that can be augmented to and improve any existing TKG completion method. The enhancement layer leverages a broader, global definition of entity similarity, which moves beyond mere local neighborhood proximity of GNN-based methods. The weighted sampling strategy employed in training accentuates edges linked to infrequently occurring entities. We evaluate our method on two benchmark datasets, and demonstrate that our framework outperforms existing methods in total link prediction, inductive link prediction, and in addressing long-tail entities. Notably, our method achieves a 10\\% improvement and a 15\\% boost in MRR for these datasets. The results underscore the potential of our approach in mitigating catastrophic forgetting and enhancing the robustness of TKG completion methods, especially in an incremental training context", 'abstract_zh': '增量训练框架在Temporal Knowledge Graph (TKG) 完善中的应用', 'title_zh': '通过全局相似性和加权采样提高时间知识图谱中长尾实体预测性能'}
{'arxiv_id': 'arXiv:2507.18868', 'title': 'A Neuroscience-Inspired Dual-Process Model of Compositional Generalization', 'authors': 'Alex Noviello, Claas Beger, Jacob Groner, Kevin Ellis, Weinan Sun', 'link': 'https://arxiv.org/abs/2507.18868', 'abstract': 'Systematic compositional generalization - constructing and understanding novel combinations of known building blocks - remains a core challenge for AI systems. Human cognition achieves this flexibility via the interplay of the hippocampus (HPC) and prefrontal cortex (PFC): the hippocampus rapidly encodes episodes, and the prefrontal cortex consolidates them into reusable schemas for reasoning. Drawing on these insights, we present MIRAGE (Meta-Inference with Rules and Abstractions from Generalized Experience), a framework that achieves systematic generalization on compositional tasks. MIRAGE has two interacting modules mirroring the brain\'s deliberative HPC-PFC loop and intuitive neocortical pattern recognition. (1) The meta-trained Transformer Neural Decomposer, paralleling neocortical "System 1" computation, is trained on a task-agnostic stream of randomly sampled compositional grammars and applies one decomposition step per pass, with successive passes iteratively refining the sequence representation. (2) The Schema Engine, analogous to the HPC-PFC "System 2" loop, dynamically extracts, ranks, and applies reusable schemas, storing variable bindings in episodic memory and expanding them when needed. By explicitly equipping the Transformer component of MIRAGE with actively managed schematic structures, our model performs systematic compositional operations through explicit schema application and transformation, relying solely on frozen weights when solving entirely novel tasks. This approach demonstrates systematic compositional generalization on the SCAN benchmark, achieving > 99% accuracy on all task splits with only 1.19M parameters in the transformer module. Ablation studies confirm that MIRAGE\'s systematicity critically depends on the quality of extracted schemas and the model\'s iterative refinement process.', 'abstract_zh': '系统组合泛化：构建和理解已知组件的新组合——仍然是AI系统的核心挑战。人类认知通过海马体（HPC）和前额皮层（PFC）的交互实现这种灵活性：海马体快速编码事件，前额皮层将其整合为可重用的推理模式。基于此见解，我们提出MIRAGE（基于通用经验的规则与抽象元推理框架），该框架在组合任务中实现了系统泛化。MIRAGE有两个相互作用的模块，模拟大脑的审慎HPC-PFC循环和直观的新皮层模式识别。（1）元训练的Transformer神经分解器，类比于皮层“系统1”计算，基于任务无关的随机采样组合语法进行训练，每次通过执行一步分解，并通过迭代优化逐步细化序列表示。（2）模式引擎，类比于HPC-PFC的“系统2”循环，动态提取、排序和应用可重用的模式，将变量绑定存储在情景记忆中并在需要时扩展它们。通过明确地在MIRAGE的Transformer组件中配备主动管理的模式结构，我们的模型在进行系统组合操作时依赖于明确的应用和转换模式，仅在解决完全新颖的任务时使用冻结权重。此方法在SCAN基准测试中展示了系统组合泛化，在仅使用Transformer模块1.19M个参数的情况下，所有任务分割的准确率均超过99%。消融研究证实，MIRAGE的系统性高度依赖于提取模式的质量和模型的迭代优化过程。', 'title_zh': '神经科学启发的组合理念泛化双过程模型'}
{'arxiv_id': 'arXiv:2507.18795', 'title': 'Simulation-Driven Reinforcement Learning in Queuing Network Routing Optimization', 'authors': 'Fatima Al-Ani, Molly Wang, Jevon Charles, Aaron Ong, Joshua Forday, Vinayak Modi', 'link': 'https://arxiv.org/abs/2507.18795', 'abstract': "This study focuses on the development of a simulation-driven reinforcement learning (RL) framework for optimizing routing decisions in complex queueing network systems, with a particular emphasis on manufacturing and communication applications. Recognizing the limitations of traditional queueing methods, which often struggle with dynamic, uncertain environments, we propose a robust RL approach leveraging Deep Deterministic Policy Gradient (DDPG) combined with Dyna-style planning (Dyna-DDPG). The framework includes a flexible and configurable simulation environment capable of modeling diverse queueing scenarios, disruptions, and unpredictable conditions. Our enhanced Dyna-DDPG implementation incorporates separate predictive models for next-state transitions and rewards, significantly improving stability and sample efficiency. Comprehensive experiments and rigorous evaluations demonstrate the framework's capability to rapidly learn effective routing policies that maintain robust performance under disruptions and scale effectively to larger network sizes. Additionally, we highlight strong software engineering practices employed to ensure reproducibility and maintainability of the framework, enabling practical deployment in real-world scenarios.", 'abstract_zh': '本研究聚焦于发展一种基于仿真的强化学习（RL）框架，用于优化复杂队列网络系统中的路由决策，特别关注制造和通信应用。鉴于传统队列方法在动态、不确定环境中存在的局限性，本文提出了一种结合深度确定性策略梯度（DDPG）和Dynashile规划（Dyna-DDPG）的鲁棒RL方法。该框架包含一个灵活且可配置的仿真环境，能够模拟各种队列场景、中断和不可预测的条件。我们的增强型Dyna-DDPG实现分别引入了下一状态转换和奖励的预测模型，显著提高了稳定性和样本效率。全面的实验和严格的评估表明，该框架能够迅速学习有效的路由策略，在遭遇中断时维持稳健性能，并有效扩展到更大的网络规模。此外，本文强调了为确保框架的可重现性和可维护性而采用的强大的软件工程实践，使其能够在实际场景中实现有效的部署。', 'title_zh': '基于模拟驱动的强化学习在排队网络路由优化中的应用'}
{'arxiv_id': 'arXiv:2507.19473', 'title': 'Let It Go? Not Quite: Addressing Item Cold Start in Sequential Recommendations with Content-Based Initialization', 'authors': 'Anton Pembek, Artem Fatkulin, Anton Klenitskiy, Alexey Vasilev', 'link': 'https://arxiv.org/abs/2507.19473', 'abstract': 'Many sequential recommender systems suffer from the cold start problem, where items with few or no interactions cannot be effectively used by the model due to the absence of a trained embedding. Content-based approaches, which leverage item metadata, are commonly used in such scenarios. One possible way is to use embeddings derived from content features such as textual descriptions as initialization for the model embeddings. However, directly using frozen content embeddings often results in suboptimal performance, as they may not fully adapt to the recommendation task. On the other hand, fine-tuning these embeddings can degrade performance for cold-start items, as item representations may drift far from their original structure after training. We propose a novel approach to address this limitation. Instead of entirely freezing the content embeddings or fine-tuning them extensively, we introduce a small trainable delta to frozen embeddings that enables the model to adapt item representations without letting them go too far from their original semantic structure. This approach demonstrates consistent improvements across multiple datasets and modalities, including e-commerce datasets with textual descriptions and a music dataset with audio-based representation.', 'abstract_zh': '许多序贯推荐系统面临冷启动问题，其中交互较少或几乎没有交互的项目由于缺乏训练嵌入而无法被模型有效利用。内容基方法利用项目元数据在这种情况下常被使用。一种可能的方法是使用来自内容特征（如文本描述）的嵌入作为模型嵌入的初始化。然而，直接使用冻结的内容嵌入往往会导致性能不佳，因为它们可能无法充分适应推荐任务。另一方面，对这些嵌入进行微调可能会削弱冷启动项目的性能，因为项目表示在训练后可能会远离其原始结构。我们提出了一种新颖的方法来解决这一局限。我们引入了一个小型可训练增量调整冻结嵌入，使模型能够适应项目表示，同时保持其原始语义结构不发生变化。该方法在多个数据集和模态下显示出一致的改进，包括带有文本描述的电商数据集和基于音频表示的音乐数据集。', 'title_zh': 'Let It Go? Not Quite: 用内容初始化解决序贯推荐中的项目冷启动问题'}
{'arxiv_id': 'arXiv:2507.19408', 'title': 'On Arbitrary Predictions from Equally Valid Models', 'authors': 'Sarah Lockfisch, Kristian Schwethelm, Martin Menten, Rickmer Braren, Daniel Rueckert, Alexander Ziller, Georgios Kaissis', 'link': 'https://arxiv.org/abs/2507.19408', 'abstract': 'Model multiplicity refers to the existence of multiple machine learning models that describe the data equally well but may produce different predictions on individual samples. In medicine, these models can admit conflicting predictions for the same patient -- a risk that is poorly understood and insufficiently addressed.\nIn this study, we empirically analyze the extent, drivers, and ramifications of predictive multiplicity across diverse medical tasks and model architectures, and show that even small ensembles can mitigate/eliminate predictive multiplicity in practice. Our analysis reveals that (1) standard validation metrics fail to identify a uniquely optimal model and (2) a substantial amount of predictions hinges on arbitrary choices made during model development. Using multiple models instead of a single model reveals instances where predictions differ across equally plausible models -- highlighting patients that would receive arbitrary diagnoses if any single model were used. In contrast, (3) a small ensemble paired with an abstention strategy can effectively mitigate measurable predictive multiplicity in practice; predictions with high inter-model consensus may thus be amenable to automated classification. While accuracy is not a principled antidote to predictive multiplicity, we find that (4) higher accuracy achieved through increased model capacity reduces predictive multiplicity.\nOur findings underscore the clinical importance of accounting for model multiplicity and advocate for ensemble-based strategies to improve diagnostic reliability. In cases where models fail to reach sufficient consensus, we recommend deferring decisions to expert review.', 'abstract_zh': '模型多样性是指存在多个机器学习模型能够同样很好地描述数据，但在个别样本上的预测可能不同。在医学领域，这些模型可能会对同一患者给出冲突的预测，这一风险目前尚未被充分理解和应对。\n\n在本研究中，我们通过对多种医学任务和模型架构的实证分析，探讨预测多样性的发展驱动因素及其后果，并展示了即使是小型模型集成也可以在实践中减轻/消除预测多样性。我们的分析揭示了以下几点：（1）标准验证指标无法识别出最优模型；（2）大量预测依赖于模型开发过程中做出的任意选择；（3）结合小型模型集成和弃权策略可以有效减轻可测量的预测多样性；因此，具有高跨模型一致性的预测可以适于自动分类。虽然准确性不是解决预测多样性的根本方法，但我们发现（4）通过增加模型容量来提高准确性可以减少预测多样性。\n\n我们的发现强调了在临床中考虑模型多样性的临床重要性，并倡导基于集成的策略以提高诊断可靠性。在模型无法达到足够共识的情况下，我们建议将决策提交给专家审核。', 'title_zh': '关于同等有效的模型任意预测的探讨'}
{'arxiv_id': 'arXiv:2507.19403', 'title': 'SDVDiag: A Modular Platform for the Diagnosis of Connected Vehicle Functions', 'authors': 'Matthias Weiß, Falk Dettinger, Michael Weyrich', 'link': 'https://arxiv.org/abs/2507.19403', 'abstract': 'Connected and software-defined vehicles promise to offer a broad range of services and advanced functions to customers, aiming to increase passenger comfort and support autonomous driving capabilities. Due to the high reliability and availability requirements of connected vehicles, it is crucial to resolve any occurring failures quickly. To achieve this however, a complex cloud/edge architecture with a mesh of dependencies must be navigated to diagnose the responsible root cause. As such, manual analyses become unfeasible since they would significantly delay the troubleshooting.\nTo address this challenge, this paper presents SDVDiag, an extensible platform for the automated diagnosis of connected vehicle functions. The platform enables the creation of pipelines that cover all steps from initial data collection to the tracing of potential root causes. In addition, SDVDiag supports self-adaptive behavior by the ability to exchange modules at runtime. Dependencies between functions are detected and continuously updated, resulting in a dynamic graph view of the system. In addition, vital system metrics are monitored for anomalies. Whenever an incident is investigated, a snapshot of the graph is taken and augmented by relevant anomalies. Finally, the analysis is performed by traversing the graph and creating a ranking of the most likely causes.\nTo evaluate the platform, it is deployed inside an 5G test fleet environment for connected vehicle functions. The results show that injected faults can be detected reliably. As such, the platform offers the potential to gain new insights and reduce downtime by identifying problems and their causes at an early stage.', 'abstract_zh': '连接和软件定义的车辆有望为乘客提供广泛的服务和高级功能，旨在提高乘坐舒适度并支持自动驾驶能力。由于连接车辆对可靠性和可用性有高要求，快速解决任何发生的故障至关重要。然而，要实现这一目标，必须导航通过一个包含复杂依赖关系的云/边缘架构来诊断责任根源。因此，手动分析变得不可行，因为它们会显著延迟故障排除。\n\n为了解决这一挑战，本文提出了SDVDiag，一个用于连接车辆功能自动诊断的可扩展平台。该平台使用户能够创建涵盖从初始数据收集到追踪潜在根源的全部步骤的管道。此外，SDVDiag 支持自我适应行为，能够在运行时交换模块。检测并持续更新功能之间的依赖关系，从而生成系统的动态图视图。此外，还会监控关键系统指标以检测异常。每当调查事故时，会捕获图的快照并添加相关异常。最后，通过遍历图并将最有可能的原因进行排名来进行分析。\n\n为了评估该平台，在连接车辆功能的5G测试车队环境中部署了SDVDiag。结果显示，注入的故障可以可靠地被检测到。因此，该平台提供了通过早期识别问题及其原因来获取新见解并减少停机时间的潜力。', 'title_zh': 'SDVDiag: 一种面向连接车辆功能诊断的模块化平台'}
{'arxiv_id': 'arXiv:2507.19398', 'title': 'CXR-CML: Improved zero-shot classification of long-tailed multi-label diseases in Chest X-Rays', 'authors': 'Rajesh Madhipati, Sheethal Bhat, Lukas Buess, Andreas Maier', 'link': 'https://arxiv.org/abs/2507.19398', 'abstract': 'Chest radiography (CXR) plays a crucial role in the diagnosis of various diseases. However, the inherent class imbalance in the distribution of clinical findings presents a significant challenge for current self-supervised deep learning models. These models often fail to accurately classify long-tailed classes. Current Vision-Language models such as Contrastive Language Image Pre-training (CLIP) models effectively model the manifold distribution of the latent space, enabling high zero-shot classification accuracies. Although CLIP performs well on most of the primary classes in the dataset, our work reveals that its effectiveness decreases significantly for classes with a long-tailed distribution. Our approach employs a class-weighting mechanism that directly aligns with the distribution of classes within the latent space. This method ensures a substantial improvement in overall classification performance, with particular emphasis on enhancing the recognition and accuracy of rarely observed classes. We accomplish this by applying Gaussian Mixture Model (GMM) clustering to the latent space. The subsequent clusters are further refined by Student t-distribution, followed by a metric loss that utilizes the altered embeddings. Our approach facilitates stable and adaptive clustering of the features. This results in a notable average improvement of 7\\% points in zero-shot AUC scores across 40 classes in the MIMIC-CXR-JPG dataset from previous SOTA models.', 'abstract_zh': '胸部X光影像（CXR）在各类疾病诊断中扮演着重要作用。然而，临床发现中存在的固有类别不平衡为当前的自监督深度学习模型带来了重大挑战。这些模型往往难以准确分类长尾类别。虽然现有的Vision-Language模型如对比语言图像预训练（CLIP）模型能够有效建模潜在空间的流形分布，从而实现高零-shot分类准确率，但我们的研究发现，它们对长尾分布类别效果显著下降。我们的方法采用类别加权机制，直接与潜在空间内类别的分布相匹配，确保在整体分类性能上取得显著提升，特别是在识别和提高罕见类别准确率方面。我们通过在潜在空间中应用高斯混合模型（GMM）聚类实现这一目标。随后的聚类进一步通过学生t分布精炼，并使用修改后的嵌入计算度量损失，从而实现特征的稳定和自适应聚类。我们在MIMIC-CXR-JPG数据集中40个类别上的零-shot AUC分数上取得了平均7个百分点的显著改进，超过之前的所有方法。', 'title_zh': 'CXR-CML：改进的胸部X光长尾多标签疾病零样本分类'}
{'arxiv_id': 'arXiv:2507.19374', 'title': 'Data Augmentation for Spoken Grammatical Error Correction', 'authors': 'Penny Karanasou, Mengjie Qian, Stefano Bannò, Mark J.F. Gales, Kate M. Knill', 'link': 'https://arxiv.org/abs/2507.19374', 'abstract': 'While there exist strong benchmark datasets for grammatical error correction (GEC), high-quality annotated spoken datasets for Spoken GEC (SGEC) are still under-resourced. In this paper, we propose a fully automated method to generate audio-text pairs with grammatical errors and disfluencies. Moreover, we propose a series of objective metrics that can be used to evaluate the generated data and choose the more suitable dataset for SGEC. The goal is to generate an augmented dataset that maintains the textual and acoustic characteristics of the original data while providing new types of errors. This augmented dataset should augment and enrich the original corpus without altering the language assessment scores of the second language (L2) learners. We evaluate the use of the augmented corpus both for written GEC (the text part) and for SGEC (the audio-text pairs). Our experiments are conducted on the S\\&I Corpus, the first publicly available speech dataset with grammar error annotations.', 'abstract_zh': '虽然在语法错误修正（GEC）领域存在强大的基准数据集，但高质量的标注口语数据集（SGEC）仍然资源不足。在本文中，我们提出了一种完全自动的方法来生成包含语法错误和话语中断的音频-文本对。此外，我们提出了一系列客观指标，可以用于评估生成的数据，并选择更适合SGEC的数据集。目标是在保留原始数据的文本和声学特征的同时，提供新的错误类型。该扩充数据集应该扩充和丰富原始语料库，而不改变第二语言（L2）学习者的语言评估分数。我们分别评估扩充语料库在书面GEC（文本部分）和SGEC（音频-文本对）中的使用。我们的实验基于S&I语料库，这是第一个公开发布的带有语法错误标注的口语数据集。', 'title_zh': '口语语法错误纠正的数据增强方法'}
{'arxiv_id': 'arXiv:2507.19368', 'title': 'Counterfactual Explanations in Medical Imaging: Exploring SPN-Guided Latent Space Manipulation', 'authors': 'Julia Siekiera, Stefan Kramer', 'link': 'https://arxiv.org/abs/2507.19368', 'abstract': 'Artificial intelligence is increasingly leveraged across various domains to automate decision-making processes that significantly impact human lives. In medical image analysis, deep learning models have demonstrated remarkable performance. However, their inherent complexity makes them black box systems, raising concerns about reliability and interpretability. Counterfactual explanations provide comprehensible insights into decision processes by presenting hypothetical "what-if" scenarios that alter model classifications. By examining input alterations, counterfactual explanations provide patterns that influence the decision-making process. Despite their potential, generating plausible counterfactuals that adhere to similarity constraints providing human-interpretable explanations remains a challenge. In this paper, we investigate this challenge by a model-specific optimization approach. While deep generative models such as variational autoencoders (VAEs) exhibit significant generative power, probabilistic models like sum-product networks (SPNs) efficiently represent complex joint probability distributions. By modeling the likelihood of a semi-supervised VAE\'s latent space with an SPN, we leverage its dual role as both a latent space descriptor and a classifier for a given discrimination task. This formulation enables the optimization of latent space counterfactuals that are both close to the original data distribution and aligned with the target class distribution. We conduct experimental evaluation on the cheXpert dataset. To evaluate the effectiveness of the integration of SPNs, our SPN-guided latent space manipulation is compared against a neural network baseline. Additionally, the trade-off between latent variable regularization and counterfactual quality is analyzed.', 'abstract_zh': '人工智能在各种领域被越来越多地用于自动化显著影响人类生活的决策过程。在医学图像分析中，深度学习模型展现出了卓越的性能。然而，它们固有的复杂性使得它们成为黑盒系统，引发了可靠性和可解释性的担忧。对比解释通过呈现改变模型分类的假设“如果”情景，提供了对决策过程可理解的洞察。通过检查输入的更改，对比解释揭示了影响决策过程的模式。尽管存在这种潜力，生成符合相似性约束且提供可人类解释的对比解释仍然是一项挑战。在本文中，我们通过模型特定的优化方法来研究这一挑战。虽然生成式深度模型如变分自编码器（VAEs）具有显著的生成能力，但概率模型如和积网络（SPNs）能够高效地表示复杂的联合概率分布。通过使用SPNs建模半监督VAE的潜在空间似然性，我们利用其双重角色作为潜在空间描述符和给定分类任务的分类器进行优化。这种表达方式使得我们可以优化既接近原始数据分布又与目标类分布对齐的潜在空间对比解释。我们在cheXpert数据集上进行了实验评估。为了评估SPNs集成的有效性，我们对比了SPN引导的潜在空间操作与神经网络基线的性能。此外，我们分析了潜在变量正则化与对比解释质量之间的权衡。', 'title_zh': '医学影像中的反事实解释：探索SPN引导的潜在空间操控'}
{'arxiv_id': 'arXiv:2507.19321', 'title': 'SIDE: Sparse Information Disentanglement for Explainable Artificial Intelligence', 'authors': 'Viktar Dubovik, Łukasz Struski, Jacek Tabor, Dawid Rymarczyk', 'link': 'https://arxiv.org/abs/2507.19321', 'abstract': 'Understanding the decisions made by deep neural networks is essential in high-stakes domains such as medical imaging and autonomous driving. Yet, these models often lack transparency, particularly in computer vision. Prototypical-parts-based neural networks have emerged as a promising solution by offering concept-level explanations. However, most are limited to fine-grained classification tasks, with few exceptions such as InfoDisent. InfoDisent extends prototypical models to large-scale datasets like ImageNet, but produces complex explanations.\nWe introduce Sparse Information Disentanglement for Explainability (SIDE), a novel method that improves the interpretability of prototypical parts through a dedicated training and pruning scheme that enforces sparsity. Combined with sigmoid activations in place of softmax, this approach allows SIDE to associate each class with only a small set of relevant prototypes. Extensive experiments show that SIDE matches the accuracy of existing methods while reducing explanation size by over $90\\%$, substantially enhancing the understandability of prototype-based explanations.', 'abstract_zh': 'Sparse Information Disentanglement for Explainability in Prototypical Parts-Based Neural Networks', 'title_zh': 'SIDE: 稀疏信息解耦 für 可解释的人工智能'}
{'arxiv_id': 'arXiv:2507.19298', 'title': 'Controlling Topological Defects in Polar Fluids via Reinforcement Learning', 'authors': 'Abhinav Singh, Petros Koumoutsakos', 'link': 'https://arxiv.org/abs/2507.19298', 'abstract': 'Topological defects in active polar fluids exhibit complex dynamics driven by internally generated stresses, reflecting the deep interplay between topology, flow, and non-equilibrium hydrodynamics. Feedback control offers a powerful means to guide such systems, enabling transitions between dynamic states. We investigated closed-loop steering of integer-charged defects in a confined active fluid by modulating the spatial profile of activity. Using a continuum hydrodynamic model, we show that localized control of active stress induces flow fields that can reposition and direct defects along prescribed trajectories by exploiting non-linear couplings in the system. A reinforcement learning framework is used to discover effective control strategies that produce robust defect transport across both trained and novel trajectories. The results highlight how AI agents can learn the underlying dynamics and spatially structure activity to manipulate topological excitations, offering insights into the controllability of active matter and the design of adaptive, self-organized materials.', 'abstract_zh': '活性极性流体中的拓扑缺陷展示了由内部产生张力驱动的复杂动力学，反映了拓扑、流动和非平衡流体动力学之间深层次的相互作用。反馈控制为引导此类系统提供了一种强大手段，使其能够在不同的动力态状态之间进行转换。我们通过调节活性流的空间分布对被约束的活性流中的整数电荷缺陷进行闭环操纵。通过使用连续流体动力学模型，我们展示了局部控制活性张力可以诱导流场，通过利用系统中的非线性耦合来重定位并引导缺陷沿指定轨迹移动。我们使用强化学习框架来发现有效的控制策略，这些策略可以在训练过的以及新的轨迹上产生稳健的缺陷传输。这些结果突显了人工智能代理如何学习基础动力学并在空间上结构化活性，以操纵拓扑激发，为活性物质的可控性和自适应、自组织材料的设计提供了见解。', 'title_zh': '通过强化学习控制极性流体中的拓扑缺陷'}
{'arxiv_id': 'arXiv:2507.19245', 'title': 'Transfinite Fixed Points in Alpay Algebra as Ordinal Game Equilibria in Dependent Type Theory', 'authors': 'Faruk Alpay, Bugra Kilictas, Taylan Alpay', 'link': 'https://arxiv.org/abs/2507.19245', 'abstract': "This paper contributes to the Alpay Algebra by demonstrating that the stable outcome of a self referential process, obtained by iterating a transformation through all ordinal stages, is identical to the unique equilibrium of an unbounded revision dialogue between a system and its environment. The analysis initially elucidates how classical fixed point theorems guarantee such convergence in finite settings and subsequently extends the argument to the transfinite domain, relying upon well founded induction and principles of order theoretic continuity.\nFurthermore, the resulting transordinal fixed point operator is embedded into dependent type theory, a formalization which permits every step of the transfinite iteration and its limit to be verified within a modern proof assistant. This procedure yields a machine checked proof that the iterative dialogue necessarily stabilizes and that its limit is unique. The result provides a foundation for Alpay's philosophical claim of semantic convergence within the framework of constructive logic. By unifying concepts from fixed point theory, game semantics, ordinal analysis, and type theory, this research establishes a broadly accessible yet formally rigorous foundation for reasoning about infinite self referential systems and offers practical tools for certifying their convergence within computational environments.", 'abstract_zh': '本文通过证明自我参照过程通过所有序数阶段迭代变换的稳定结果与无限修正对话中系统与其环境的独特均衡一致，为Alpay代数做出了贡献。分析首先阐明了古典不动点定理在有限设置中确保这种收敛性的方法，随后扩展了该论点到超限领域，依赖于良基归纳和序理论连续性原则。进一步地，超限不动点运算子被嵌入到依赖类型理论中，这一形式化方法允许在现代证明辅助系统中验证超限迭代的每一步及其极限。这一过程产生了机器检查的证明，表明迭代对话必然稳定并且其极限是唯一的。该结果为在构造逻辑框架内实现语义收敛提供了基础。通过统一固定点理论、博弈语义学、序分析和类型理论的概念，这项研究为推理关于无限自参照系统建立了广泛可访问且形式严谨的基础，并提供了在计算环境中认证其收敛性的实用工具。', 'title_zh': '超越有限的固定点在Alpay代数中的序游戏均衡在依赖类型理论中的应用'}
{'arxiv_id': 'arXiv:2507.19234', 'title': 'Virne: A Comprehensive Benchmark for Deep RL-based Network Resource Allocation in NFV', 'authors': 'Tianfu Wang, Liwei Deng, Xi Chen, Junyang Wang, Huiguo He, Leilei Ding, Wei Wu, Qilin Fan, Hui Xiong', 'link': 'https://arxiv.org/abs/2507.19234', 'abstract': 'Resource allocation (RA) is critical to efficient service deployment in Network Function Virtualization (NFV), a transformative networking paradigm. Recently, deep Reinforcement Learning (RL)-based methods have been showing promising potential to address this complexity. However, the lack of a systematic benchmarking framework and thorough analysis hinders the exploration of emerging networks and the development of more robust algorithms while causing inconsistent evaluation. In this paper, we introduce Virne, a comprehensive benchmarking framework for the NFV-RA problem, with a focus on supporting deep RL-based methods. Virne provides customizable simulations for diverse network scenarios, including cloud, edge, and 5G environments. It also features a modular and extensible implementation pipeline that supports over 30 methods of various types, and includes practical evaluation perspectives beyond effectiveness, such as scalability, generalization, and scalability. Furthermore, we conduct in-depth analysis through extensive experiments to provide valuable insights into performance trade-offs for efficient implementation and offer actionable guidance for future research directions. Overall, with its diverse simulations, rich implementations, and extensive evaluation capabilities, Virne could serve as a comprehensive benchmark for advancing NFV-RA methods and deep RL applications. The code is publicly available at this https URL.', 'abstract_zh': '资源分配（RA）是网络功能虚拟化（NFV）中高效服务部署的关键。近年来，基于深度强化学习（RL）的方法显示出解决这一复杂性的潜力。然而，缺乏系统的基准测试框架和深入分析阻碍了新兴网络的探索和更稳健算法的发展，导致评估不一致。本文介绍了Virne，一个全面的NFV-RA基准测试框架，重点支持深度RL方法。Virne提供了多种网络场景的可定制仿真，包括云、边缘和5G环境。它还具有模块化可扩展的实现管道，支持超过30种不同类型的方法，并包含超越有效性的影响因素的实用评估视角，如可扩展性、通用性和公平性。此外，通过广泛的实验进行了深入分析，提供了关于高效实施性能权衡的宝贵见解，并为未来研究方向提供了可操作的指导。总体而言，凭借其多样化的仿真、丰富的实现能力和广泛的评估能力，Virne可以作为一个全面的基准，推动NFV-RA方法和深度RL应用的发展。代码已公开。', 'title_zh': 'Virne：基于NFV的深度强化学习网络资源分配的综合性基准测试'}
{'arxiv_id': 'arXiv:2507.19199', 'title': 'Enhancing Diabetic Retinopathy Classification Accuracy through Dual Attention Mechanism in Deep Learning', 'authors': 'Abdul Hannan, Zahid Mahmood, Rizwan Qureshi, Hazrat Ali', 'link': 'https://arxiv.org/abs/2507.19199', 'abstract': 'Automatic classification of Diabetic Retinopathy (DR) can assist ophthalmologists in devising personalized treatment plans, making it a critical component of clinical practice. However, imbalanced data distribution in the dataset becomes a bottleneck in the generalization of deep learning models trained for DR classification. In this work, we combine global attention block (GAB) and category attention block (CAB) into the deep learning model, thus effectively overcoming the imbalanced data distribution problem in DR classification. Our proposed approach is based on an attention mechanism-based deep learning model that employs three pre-trained networks, namely, MobileNetV3-small, Efficientnet-b0, and DenseNet-169 as the backbone architecture. We evaluate the proposed method on two publicly available datasets of retinal fundoscopy images for DR. Experimental results show that on the APTOS dataset, the DenseNet-169 yielded 83.20% mean accuracy, followed by the MobileNetV3-small and EfficientNet-b0, which yielded 82% and 80% accuracies, respectively. On the EYEPACS dataset, the EfficientNet-b0 yielded a mean accuracy of 80%, while the DenseNet-169 and MobileNetV3-small yielded 75.43% and 76.68% accuracies, respectively. In addition, we also compute the F1-score of 82.0%, precision of 82.1%, sensitivity of 83.0%, specificity of 95.5%, and a kappa score of 88.2% for the experiments. Moreover, in our work, the MobileNetV3-small has 1.6 million parameters on the APTOS dataset and 0.90 million parameters on the EYEPACS dataset, which is comparatively less than other methods. The proposed approach achieves competitive performance that is at par with recently reported works on DR classification.', 'abstract_zh': '自动分类糖尿病视网膜病变（DR）可以协助眼科医生制定个性化治疗方案，使其成为临床实践中的关键组成部分。然而，数据集中的不平衡数据分布成为深度学习模型在DR分类中泛化的瓶颈。在本文中，我们将全局注意力模块（GAB）和类别注意力模块（CAB）结合到深度学习模型中，从而有效克服了DR分类中的不平衡数据分布问题。我们提出的方法基于一种基于注意力机制的深度学习模型，采用MobileNetV3-small、EfficientNet-b0和DenseNet-169三种预训练网络作为骨干架构。我们在两个公开的眼底图像DR数据集上评估了所提出的方法。实验结果表明，在APTO斯数据集上，DenseNet-169的平均准确率为83.20%，其次是MobileNetV3-small和EfficientNet-b0，准确率分别为82%和80%。在EYEPACS数据集上，EfficientNet-b0的平均准确率为80%，而DenseNet-169和MobileNetV3-small的准确率分别为75.43%和76.68%。此外，我们还计算了F1分数为82.0%、精度为82.1%、灵敏度为83.0%、特异度为95.5%、κ系数为88.2%。此外，在我们的工作中，MobileNetV3-small在APTO斯数据集上的参数量为1.6百万，在EYEPACS数据集上的参数量为0.90百万，相较于其他方法较少。所提出的方法在DR分类中实现了竞争力的性能，与最近报道的DR分类方法相当。', 'title_zh': '通过深度学习中的双重注意力机制提高糖尿病视网膜病变分类准确性'}
{'arxiv_id': 'arXiv:2507.19197', 'title': 'WACA-UNet: Weakness-Aware Channel Attention for Static IR Drop Prediction in Integrated Circuit Design', 'authors': 'Youngmin Seo, Yunhyeong Kwon, Younghun Park, HwiRyong Kim, Seungho Eum, Jinha Kim, Taigon Song, Juho Kim, Unsang Park', 'link': 'https://arxiv.org/abs/2507.19197', 'abstract': 'Accurate spatial prediction of power integrity issues, such as IR drop, is critical for reliable VLSI design. However, traditional simulation-based solvers are computationally expensive and difficult to scale. We address this challenge by reformulating IR drop estimation as a pixel-wise regression task on heterogeneous multi-channel physical maps derived from circuit layouts. Prior learning-based methods treat all input layers (e.g., metal, via, and current maps) equally, ignoring their varying importance to prediction accuracy. To tackle this, we propose a novel Weakness-Aware Channel Attention (WACA) mechanism, which recursively enhances weak feature channels while suppressing over-dominant ones through a two-stage gating strategy. Integrated into a ConvNeXtV2-based attention U-Net, our approach enables adaptive and balanced feature representation. On the public ICCAD-2023 benchmark, our method outperforms the ICCAD-2023 contest winner by reducing mean absolute error by 61.1% and improving F1-score by 71.0%. These results demonstrate that channel-wise heterogeneity is a key inductive bias in physical layout analysis for VLSI.', 'abstract_zh': '准确的空间预测对于VLSI设计中的电源完整性问题，如IR跌落，至关重要。然而，传统的基于仿真的求解器计算成本高昂且难以扩展。我们通过将IR跌落估计重新表述为由电路布局衍生的异构多通道物理图上的像素级回归任务，来应对这一挑战。基于先前的学习方法对待所有输入层（例如，金属、通孔和电流图）一视同仁，忽视了它们对预测准确性的不同重要性。为此，我们提出了一种新型的弱项感知通道注意（WACA）机制，通过两阶段门控策略递归增强弱特征通道并抑制过分主导的通道。将该机制整合到ConvNeXtV2为基础的注意力U-Net中，我们的方法能够实现自适应且均衡的特征表示。在公开的ICCAD-2023基准测试上，我们的方法通过将平均绝对误差降低61.1%并且提高F1分数71.0%，超过了ICCAD-2023竞赛的获胜者。这些结果表明，在VLSI的实际布局分析中，通道间的异质性是关键的归纳偏置。', 'title_zh': 'WACA-UNet：感知弱点的通道注意力在集成电路设计中静态IR压降预测'}
{'arxiv_id': 'arXiv:2507.19137', 'title': 'Assessment of Personality Dimensions Across Situations Using Conversational Speech', 'authors': 'Alice Zhang, Skanda Muralidhar, Daniel Gatica-Perez, Mathew Magimai-Doss', 'link': 'https://arxiv.org/abs/2507.19137', 'abstract': "Prior research indicates that users prefer assistive technologies whose personalities align with their own. This has sparked interest in automatic personality perception (APP), which aims to predict an individual's perceived personality traits. Previous studies in APP have treated personalities as static traits, independent of context. However, perceived personalities can vary by context and situation as shown in psychological research. In this study, we investigate the relationship between conversational speech and perceived personality for participants engaged in two work situations (a neutral interview and a stressful client interaction). Our key findings are: 1) perceived personalities differ significantly across interactions, 2) loudness, sound level, and spectral flux features are indicative of perceived extraversion, agreeableness, conscientiousness, and openness in neutral interactions, while neuroticism correlates with these features in stressful contexts, 3) handcrafted acoustic features and non-verbal features outperform speaker embeddings in inference of perceived personality, and 4) stressful interactions are more predictive of neuroticism, aligning with existing psychological research.", 'abstract_zh': '先前的研究表明，用户更偏好与自己个性相匹配的辅助技术。这激发了自动个性感知（APP）的兴趣，其目标是预测个体感知到的个性特征。以往在APP领域的研究将个性视为静态特征，与情境无关。然而，心理研究显示，感知到的个性会因情境和情况而异。本研究探讨了参与两种工作情境（中性面试和压力大的客户互动）的人员的对话口语与其感知个性之间的关系。我们的主要发现为：1) 不同互动中的感知个性存在显著差异；2) 在中性互动中，响度、声音级别和频谱变化特性与感知的外向性、宜人性、严谨性和开放性相关，而在压力情境中，这些特性与神经质相关；3) 手工设计的声学特征和非语言特征在感知个性的推理中优于说话人嵌入；4) 压力大的互动更能预测神经质，与现有的心理研究结果一致。', 'title_zh': '基于对话语言评估人格维度在不同情境下的表现'}
{'arxiv_id': 'arXiv:2507.19116', 'title': 'Graph Structure Learning with Privacy Guarantees for Open Graph Data', 'authors': 'Muhao Guo, Jiaqi Wu, Yang Weng, Yizheng Liao, Shengzhe Chen', 'link': 'https://arxiv.org/abs/2507.19116', 'abstract': 'Ensuring privacy in large-scale open datasets is increasingly challenging under regulations such as the General Data Protection Regulation (GDPR). While differential privacy (DP) provides strong theoretical guarantees, it primarily focuses on noise injection during model training, neglecting privacy preservation at the data publishing stage. Existing privacy-preserving data publishing (PPDP) approaches struggle to balance privacy and utility, particularly when data publishers and users are distinct entities. To address this gap, we focus on the graph recovery problem and propose a novel privacy-preserving estimation framework for open graph data, leveraging Gaussian DP (GDP) with a structured noise-injection mechanism. Unlike traditional methods that perturb gradients or model updates, our approach ensures unbiased graph structure recovery while enforcing DP at the data publishing stage. Moreover, we provide theoretical guarantees on estimation accuracy and extend our method to discrete-variable graphs, a setting often overlooked in DP research. Experimental results in graph learning demonstrate robust performance, offering a viable solution for privacy-conscious graph analysis.', 'abstract_zh': '在大规模开放数据集下确保隐私越来越具有挑战性，尤其是在《通用数据保护条例》（GDPR）等法规的约束下。虽然差分隐私（DP）提供了强大的理论保证，但它主要关注模型训练过程中的噪声注入，忽略了数据发布阶段的隐私保护。现有的隐私保护数据发布（PPDP）方法在平衡隐私和实用性方面存在困难，尤其是在数据发布者和用户是不同实体的情况下。为解决这一问题，我们关注图恢复问题，并提出一种利用结构化噪声注入机制的高斯差分隐私（GDP）的新型隐私保护估计框架。与传统方法扰动梯度或模型更新不同，我们的方法确保在数据发布阶段实现无偏的图结构恢复。此外，我们提供了估计准确性的理论保证，并将方法扩展到离散变量图，这是差分隐私研究中常被忽视的领域。在图学习实验中，我们的方法表现出 robust 性能，为隐私意识强烈的图分析提供了可行的解决方案。', 'title_zh': '带有隐私保证的开放图数据图形结构学习'}
{'arxiv_id': 'arXiv:2507.19067', 'title': 'PBiLoss: Popularity-Aware Regularization to Improve Fairness in Graph-Based Recommender Systems', 'authors': 'Mohammad Naeimi, Mostafa Haghir Chehreghani', 'link': 'https://arxiv.org/abs/2507.19067', 'abstract': "Recommender systems, especially those based on graph neural networks (GNNs), have achieved remarkable success in capturing user-item interaction patterns. However, they remain susceptible to popularity bias--the tendency to over-recommend popular items--resulting in reduced content diversity and compromised fairness. In this paper, we propose PBiLoss, a novel regularization-based loss function designed to counteract popularity bias in graph-based recommender models explicitly. PBiLoss augments traditional training objectives by penalizing the model's inclination toward popular items, thereby encouraging the recommendation of less popular but potentially more personalized content. We introduce two sampling strategies: Popular Positive (PopPos) and Popular Negative (PopNeg), which respectively modulate the contribution of the positive and negative popular items during training. We further explore two methods to distinguish popular items: one based on a fixed popularity threshold and another without any threshold, making the approach flexible and adaptive. Our proposed method is model-agnostic and can be seamlessly integrated into state-of-the-art graph-based frameworks such as LightGCN and its variants. Comprehensive experiments across multiple real-world datasets demonstrate that PBiLoss significantly improves fairness, as demonstrated by reductions in the Popularity-Rank Correlation for Users (PRU) and Popularity-Rank Correlation for Items (PRI), while maintaining or even enhancing standard recommendation accuracy and ranking metrics. These results highlight the effectiveness of directly embedding fairness objectives into the optimization process, providing a practical and scalable solution for balancing accuracy and equitable content exposure in modern recommender systems.", 'abstract_zh': '基于图神经网络的推荐系统通过捕捉用户-项交互模式取得了显著成功，但它们仍然容易受到流行性偏见的影响——即过度推荐流行项的倾向，这导致内容多样性降低和公平性受损。本文提出了一种新颖的正则化损失函数PBiLoss，该函数旨在明确对抗基于图的推荐模型中的流行性偏见。PBiLoss通过惩罚模型对流行项的偏好，来鼓励推荐较少流行但可能更具个性化的内容。我们引入了两种采样策略：Popular Positive (PopPos)和Popular Negative (PopNeg)，分别调节正向和负向社会流行项在训练中的贡献。此外，我们探讨了两种区分社会流行项的方法：一种基于固定流行度阈值，另一种没有阈值，使方法更加灵活和适应性强。所提方法具有模型独立性，可以无缝集成到LightGCN及其变体等最先进的基于图的框架中。在多个真实世界数据集上的全面实验表明，PBiLoss在降低用户和项的流行性排名相关性（PRU和PRI）方面显著提高了公平性，同时保持或甚至提升了推荐准确性和排名指标。这些结果突显了直接将公平性目标嵌入优化过程的有效性，为在现代推荐系统中平衡准确性和公平内容曝光提供了一种实用且可扩展的解决方案。', 'title_zh': 'PBiLoss：基于流行度的正则化以提高图推荐系统中的公平性'}
{'arxiv_id': 'arXiv:2507.19017', 'title': 'MindSpeed RL: Distributed Dataflow for Scalable and Efficient RL Training on Ascend NPU Cluster', 'authors': 'Laingjun Feng, Chenyi Pan, Xinjie Guo, Fei Mei, Benzhe Ning, Jianxiang Zhang, Xinyang Liu, Beirong Zhou, Zeng Shu, Chang Liu, Guang Yang, Zhenyu Han, Jiangben Wang, Bo Wang', 'link': 'https://arxiv.org/abs/2507.19017', 'abstract': 'Reinforcement learning (RL) is a paradigm increasingly used to align large language models. Popular RL algorithms utilize multiple workers and can be modeled as a graph, where each node is the status of a worker and each edge represents dataflow between nodes. Owing to the heavy cross-node dependencies, the RL training system usually suffers from poor cluster scalability and low memory utilization. In this article, we introduce MindSpeed RL, an effective and efficient system for large-scale RL training. Unlike existing centralized methods, MindSpeed RL organizes the essential data dependencies in RL training, i.e., sample flow and resharding flow, from a distributed view. On the one hand, a distributed transfer dock strategy, which sets controllers and warehouses on the basis of the conventional replay buffer, is designed to release the dispatch overhead in the sample flow. A practical allgather--swap strategy is presented to eliminate redundant memory usage in resharding flow. In addition, MindSpeed RL further integrates numerous parallelization strategies and acceleration techniques for systematic optimization. Compared with existing state-of-the-art systems, comprehensive experiments on the RL training of popular Qwen2.5-Dense-7B/32B, Qwen3-MoE-30B, and DeepSeek-R1-MoE-671B show that MindSpeed RL increases the throughput by 1.42 ~ 3.97 times. Finally, we open--source MindSpeed RL and perform all the experiments on a super pod of Ascend with 384 neural processing units (NPUs) to demonstrate the powerful performance and reliability of Ascend.', 'abstract_zh': '大规模强化学习训练的MindSpeed RL系统', 'title_zh': 'MindSpeed RL：Ascend NPU集群上可扩展且高效的 reinforcement learning训练的数据流分布方案'}
{'arxiv_id': 'arXiv:2507.19003', 'title': 'A diffusion-based generative model for financial time series via geometric Brownian motion', 'authors': 'Gihun Kim, Sun-Yong Choi, Yeoneung Kim', 'link': 'https://arxiv.org/abs/2507.19003', 'abstract': 'We propose a novel diffusion-based generative framework for financial time series that incorporates geometric Brownian motion (GBM), the foundation of the Black--Scholes theory, into the forward noising process. Unlike standard score-based models that treat price trajectories as generic numerical sequences, our method injects noise proportionally to asset prices at each time step, reflecting the heteroskedasticity observed in financial time series. By accurately balancing the drift and diffusion terms, we show that the resulting log-price process reduces to a variance-exploding stochastic differential equation, aligning with the formulation in score-based generative models. The reverse-time generative process is trained via denoising score matching using a Transformer-based architecture adapted from the Conditional Score-based Diffusion Imputation (CSDI) framework. Empirical evaluations on historical stock data demonstrate that our model reproduces key stylized facts heavy-tailed return distributions, volatility clustering, and the leverage effect more realistically than conventional diffusion models.', 'abstract_zh': '我们提出了一种基于扩散的金融时间序列生成框架，将Black-Scholes理论的基础几何布朗运动（GBM）融入前向噪声过程。与标准评分基础模型将价格轨迹视为通用数字序列的做法不同，我们的方法在每个时间步长中根据资产价格成比例地注入噪声，反映金融时间序列中观察到的异方差性。通过精确平衡漂移和扩散项，我们证明所得到的对数价格过程转化为一个方差爆炸的随机微分方程，与评分基础生成模型的公式一致。反向生成过程通过源自Conditional Score-based Diffusion Imputation (CSDI)框架的Transformer架构结合去噪评分匹配进行训练。在历史股价数据上的实证评估表明，我们的模型比传统的扩散模型更真实地再现了重尾回报分布、波动集聚和杠杆效应等关键特征。', 'title_zh': '基于扩散的金融时间序列生成模型通过几何布朗运动'}
{'arxiv_id': 'arXiv:2507.18989', 'title': 'GENIAL: Generative Design Space Exploration via Network Inversion for Low Power Algorithmic Logic Units', 'authors': 'Maxence Bouvier, Ryan Amaudruz, Felix Arnold, Renzo Andri, Lukas Cavigelli', 'link': 'https://arxiv.org/abs/2507.18989', 'abstract': "As AI workloads proliferate, optimizing arithmetic units is becoming increasingly important to reduce the footprint of digital systems. Conventional design flows, which often rely on manual or heuristics-based optimization, are limited in their ability to thoroughly explore the vast design space. In this paper, we introduce GENIAL, a machine learning-based framework for the automatic generation and optimization of arithmetic units, more specifically multipliers.\nAt the core of GENIAL is a Transformer-based surrogate model trained in two stages, involving self-supervised pretraining followed by supervised finetuning, to robustly forecast key hardware metrics such as power and area from abstracted design representations. By inverting the surrogate model, GENIAL efficiently searches for new operand encodings that directly minimize power consumption in arithmetic units for specific input data distributions. Extensive experiments on large datasets demonstrate that GENIAL is consistently more sample efficient than other methods, and converges faster towards optimized designs. This enables to deploy a high-effort logic synthesis optimization flow in the loop, improving the accuracy of the surrogate model. Notably, GENIAL automatically discovers encodings that achieve up to 18% switching activity savings within multipliers on representative AI workloads compared with the conventional two's complement. We also demonstrate the versatility of our approach by achieving significant improvements on Finite State Machines, highlighting GENIAL's applicability for a wide spectrum of logic functions. Together, these advances mark a significant step toward automated Quality-of-Results-optimized combinational circuit generation for digital systems.", 'abstract_zh': '基于机器学习的自动生成与优化算术单元框架：GENIAL', 'title_zh': 'GENIAL: 基于网络反转的生成设计空间探索用于低功耗算法逻辑单元'}
{'arxiv_id': 'arXiv:2507.18987', 'title': 'Differentiated Thyroid Cancer Recurrence Classification Using Machine Learning Models and Bayesian Neural Networks with Varying Priors: A SHAP-Based Interpretation of the Best Performing Model', 'authors': 'HMNS Kumari, HMLS Kumari, UMMPK Nawarathne', 'link': 'https://arxiv.org/abs/2507.18987', 'abstract': 'Differentiated thyroid cancer DTC recurrence is a major public health concern, requiring classification and predictive models that are not only accurate but also interpretable and uncertainty aware. This study introduces a comprehensive framework for DTC recurrence classification using a dataset containing 383 patients and 16 clinical and pathological variables. Initially, 11 machine learning ML models were employed using the complete dataset, where the Support Vector Machines SVM model achieved the highest accuracy of 0.9481. To reduce complexity and redundancy, feature selection was carried out using the Boruta algorithm, and the same ML models were applied to the reduced dataset, where it was observed that the Logistic Regression LR model obtained the maximum accuracy of 0.9611. However, these ML models often lack uncertainty quantification, which is critical in clinical decision making. Therefore, to address this limitation, the Bayesian Neural Networks BNN with six varying prior distributions, including Normal 0,1, Normal 0,10, Laplace 0,1, Cauchy 0,1, Cauchy 0,2.5, and Horseshoe 1, were implemented on both the complete and reduced datasets. The BNN model with Normal 0,10 prior distribution exhibited maximum accuracies of 0.9740 and 0.9870 before and after feature selection, respectively.', 'abstract_zh': '不同分化型甲状腺癌复发的分类及预测模型：基于不确定性意识的可解释框架', 'title_zh': '基于机器学习模型和具有变动先验的贝叶斯神经网络的分化型甲状腺癌复发分类：SHAP基的理解最佳模型解析'}
{'arxiv_id': 'arXiv:2507.18937', 'title': 'CNN-based Surface Temperature Forecasts with Ensemble Numerical Weather Prediction over Medium-range Forecast Periods', 'authors': 'Takuya Inoue, Takuya Kawabata', 'link': 'https://arxiv.org/abs/2507.18937', 'abstract': 'This study proposes a method that integrates convolutional neural networks (CNNs) with ensemble numerical weather prediction (NWP) models, enabling surface temperature forecasting at lead times beyond the short-range (five-day) forecast period. Owing to limited computational resources, operational medium-range temperature forecasts typically rely on low-resolution NWP models, which are prone to systematic and random errors. To resolve these limitations, the proposed method first reduces systematic errors through CNN-based post-processing (bias correction and spatial super-resolution) on each ensemble member, reconstructing high-resolution temperature fields from low-resolution model outputs. Second, it reduces random errors through ensemble averaging of the CNN-corrected members. This study also investigates whether the sequence of CNN correction and ensemble averaging affects the forecast accuracy. For comparison with the proposed method, we additionally conducted experiments with the CNN trained on ensemble-averaged forecasts. The first approach--CNN correction before ensemble averaging--consistently achieved higher accuracy than the reverse approach. Although based on low-resolution ensemble forecasts, the proposed method notably outperformed the high-resolution deterministic NWP models. These findings indicate that combining CNN-based correction with ensemble averaging effectively reduces both the systematic and random errors in NWP model outputs. The proposed approach is a practical and scalable solution for improving medium-range temperature forecasts, and is particularly valuable at operational centers with limited computational resources.', 'abstract_zh': '本研究提出了一种将卷积神经网络（CNN）与集合数值天气预报（NWP）模型相结合的方法，能够在短程预报（五天）之外的时间提前量进行地表温度预测。由于计算资源有限， operational 中程温度预报通常依赖于低分辨率的 NWP 模型，这些模型容易出现系统性错误和随机误差。为解决这些问题，该方法首先通过基于 CNN 的后处理（偏差校正和空间超分辨率）对每个集合成员进行处理，从低分辨率模型输出中重建高分辨率温度场；其次，通过 CNN 校正后的成员的集合平均来减少随机误差。本研究还探讨了 CNN 校正和集合平均顺序是否影响预报准确性。为了与提出的方案进行比较，我们还进行了使用在集合平均预报上训练的 CNN 的实验。结果显示，在集合平均之前进行 CNN 校正的方法始终比反其顺序的方法具有更高的准确性。尽管基于低分辨率的集合预报，提出的方案在性能上显著优于高分辨率的确定性 NWP 模型。这些发现表明，结合 CNN 基准校正与集合平均能有效减少 NWP 模型输出中的系统性和随机误差。该提出的方法是提高中程温度预报的一种实际且可扩展的解决方案，特别适合作为计算资源有限的 operational 中心。', 'title_zh': '基于CNN的中期预报期内集合数值天气预报地表温度预测'}
{'arxiv_id': 'arXiv:2507.18897', 'title': 'HH-Codec: High Compression High-fidelity Discrete Neural Codec for Spoken Language Modeling', 'authors': 'Rongkun Xue, Yazhe Niu, Shuai Hu, Zixin Yin, Yongqiang Yao, Jing Yang', 'link': 'https://arxiv.org/abs/2507.18897', 'abstract': 'Discrete speech tokenization is a fundamental component in speech codecs. However, in large-scale speech-to-speech systems, the complexity of parallel streams from multiple quantizers and the computational cost of high-time-dimensional codecs pose significant challenges. In this paper, we introduce HH-Codec, a neural codec that achieves extreme compression at 24 tokens per second for 24 kHz audio while relying on single-quantizer inference. Our approach involves a carefully designed Vector Quantization space for Spoken Language Modeling, optimizing compression efficiency while minimizing information loss. Building on this, we propose an asymmetric encoder-decoder architecture (Audio-VQ-Mel-Audio) that leverages dual supervision and progressive training to enhance reconstruction stability and fidelity. HH-Codec achieves state-of-the-art performance in speech reconstruction with an ultra-low bandwidth of 0.3 kbps. We further evaluate its effectiveness in codebook utilization and generative model adaptation, with extensive ablations validating the necessity of each module. HH-Codec is available at this https URL.', 'abstract_zh': '离散语音token化是语音编解码器中的一个基本组成部分。然而，在大规模的语音-语音系统中，来自多个量化器的并行流的复杂性以及高时间维度编解码器的计算成本构成了重大挑战。本文介绍了一种名为HH-Codec的神经编解码器，该编解码器在24 kHz音频上实现了每秒24个tokens的极端压缩，仅依赖于单量化器推理。我们的方法涉及到精心设计的语音语言模型向量量化空间，优化了压缩效率并尽量减少信息损失。在此基础上，我们提出了一种不对称编码-解码架构（Audio-VQ-Mel-Audio），利用双监督和渐进训练来增强重建的稳定性和保真度。HH-Codec在超低带宽0.3 kbps的情况下实现了语音重建的最先进的性能。我们进一步评估了其在码书利用和生成模型适应性方面的有效性，并通过广泛的消融实验验证了每个模块的必要性。HH-Codec可在以下链接获取：this https URL。', 'title_zh': 'HH-Codec: 高压缩高保真离散神经编码器用于语音语言建模'}
{'arxiv_id': 'arXiv:2507.18882', 'title': 'A Comprehensive Review of AI-based Intelligent Tutoring Systems: Applications and Challenges', 'authors': 'Meriem Zerkouk, Miloud Mihoubi, Belkacem Chikhaoui', 'link': 'https://arxiv.org/abs/2507.18882', 'abstract': 'AI-based Intelligent Tutoring Systems (ITS) have significant potential to transform teaching and learning. As efforts continue to design, develop, and integrate ITS into educational contexts, mixed results about their effectiveness have emerged. This paper provides a comprehensive review to understand how ITS operate in real educational settings and to identify the associated challenges in their application and evaluation. We use a systematic literature review method to analyze numerous qualified studies published from 2010 to 2025, examining domains such as pedagogical strategies, NLP, adaptive learning, student modeling, and domain-specific applications of ITS. The results reveal a complex landscape regarding the effectiveness of ITS, highlighting both advancements and persistent challenges. The study also identifies a need for greater scientific rigor in experimental design and data analysis. Based on these findings, suggestions for future research and practical implications are proposed.', 'abstract_zh': '基于AI的智能辅导系统（ITS）在教育教学中的应用具有显著潜力。随着努力设计、开发并将ITS集成到教育环境中，关于其有效性的结果出现了分歧。本文提供了全面的综述，以理解ITS在实际教育环境中的运作方式，并识别其应用和评估中遇到的挑战。我们采用系统文献综述方法，分析了2010年至2025年间发表的多项合格研究，涉及教学策略、自然语言处理、自适应学习、学生建模以及ITS的具体应用领域。研究结果揭示了有关ITS有效性的复杂景观，突显了进步与持续挑战。研究还指出需要在实验设计和数据分析方面增加科学严谨性。基于这些发现，提出了未来研究的建议和实践意义。', 'title_zh': '基于AI的智能教学系统综述：应用与挑战'}
{'arxiv_id': 'arXiv:2507.18867', 'title': 'Learning Individual Intrinsic Reward in Multi-Agent Reinforcement Learning via Incorporating Generalized Human Expertise', 'authors': 'Xuefei Wu, Xiao Yin, Yuanyang Zhu, Chunlin Chen', 'link': 'https://arxiv.org/abs/2507.18867', 'abstract': 'Efficient exploration in multi-agent reinforcement learning (MARL) is a challenging problem when receiving only a team reward, especially in environments with sparse rewards. A powerful method to mitigate this issue involves crafting dense individual rewards to guide the agents toward efficient exploration. However, individual rewards generally rely on manually engineered shaping-reward functions that lack high-order intelligence, thus it behaves ineffectively than humans regarding learning and generalization in complex problems. To tackle these issues, we combine the above two paradigms and propose a novel framework, LIGHT (Learning Individual Intrinsic reward via Incorporating Generalized Human experTise), which can integrate human knowledge into MARL algorithms in an end-to-end manner. LIGHT guides each agent to avoid unnecessary exploration by considering both individual action distribution and human expertise preference distribution. Then, LIGHT designs individual intrinsic rewards for each agent based on actionable representational transformation relevant to Q-learning so that the agents align their action preferences with the human expertise while maximizing the joint action value. Experimental results demonstrate the superiority of our method over representative baselines regarding performance and better knowledge reusability across different sparse-reward tasks on challenging scenarios.', 'abstract_zh': '高效探索在仅接收团队奖励的多智能体强化学习中的有效实现，尤其是在稀疏奖励环境中是一个挑战性问题。一种有力的方法是设计密集的个体奖励来引导智能体进行高效的探索。然而，个体奖励通常依赖于手动工程化的塑造奖励函数，缺乏高级智能，因此在复杂问题的学习和泛化方面表现不如人类。为了解决这些问题，我们将上述两种范式结合起来，提出了一种新型框架 LIGHT（基于广泛人类专业知识学习个体内在奖励），该框架可以以端到端的方式将人类知识整合到多智能体强化学习算法中。LIGHT 通过同时考虑个体动作分布和人类专业知识偏好分布来引导每个智能体避免不必要的探索。然后，LIGHT 基于与 Q-learning 相关的动作表示转换设计每个智能体的个体内在奖励，使智能体在最大化联合动作价值的同时与其人类专业知识对齐。实验结果表明，与代表性基线方法相比，我们的方法在性能上具有优势，并且在不同稀疏奖励任务的挑战性场景中具有更好的知识可重用性。', 'title_zh': '通过融入泛化人类专长学习多智能体 reinforcement learning 中的个体固有奖励'}
{'arxiv_id': 'arXiv:2507.18848', 'title': 'PTCMIL: Multiple Instance Learning via Prompt Token Clustering for Whole Slide Image Analysis', 'authors': 'Beidi Zhao, SangMook Kim, Hao Chen, Chen Zhou, Zu-hua Gao, Gang Wang, Xiaoxiao Li', 'link': 'https://arxiv.org/abs/2507.18848', 'abstract': 'Multiple Instance Learning (MIL) has advanced WSI analysis but struggles with the complexity and heterogeneity of WSIs. Existing MIL methods face challenges in aggregating diverse patch information into robust WSI representations. While ViTs and clustering-based approaches show promise, they are computationally intensive and fail to capture task-specific and slide-specific variability. To address these limitations, we propose PTCMIL, a novel Prompt Token Clustering-based ViT for MIL aggregation. By introducing learnable prompt tokens into the ViT backbone, PTCMIL unifies clustering and prediction tasks in an end-to-end manner. It dynamically aligns clustering with downstream tasks, using projection-based clustering tailored to each WSI, reducing complexity while preserving patch heterogeneity. Through token merging and prototype-based pooling, PTCMIL efficiently captures task-relevant patterns. Extensive experiments on eight datasets demonstrate its superior performance in classification and survival analysis tasks, outperforming state-of-the-art methods. Systematic ablation studies confirm its robustness and strong interpretability. The code is released at this https URL.', 'abstract_zh': '基于提示词聚类的ViT多实例学习方法（PTCMIL）：统一聚类与预测任务以提高WSI分析效率', 'title_zh': 'PTCMIL: 基于提示词聚类的多实例学习在全视野图像分析中的应用'}
{'arxiv_id': 'arXiv:2507.18815', 'title': 'Deepfake Detection Via Facial Feature Extraction and Modeling', 'authors': 'Benjamin Carter, Nathan Dilla, Micheal Callahan, Atuhaire Ambala', 'link': 'https://arxiv.org/abs/2507.18815', 'abstract': 'The rise of deepfake technology brings forth new questions about the authenticity of various forms of media found online today. Videos and images generated by artificial intelligence (AI) have become increasingly more difficult to differentiate from genuine media, resulting in the need for new models to detect artificially-generated media. While many models have attempted to solve this, most focus on direct image processing, adapting a convolutional neural network (CNN) or a recurrent neural network (RNN) that directly interacts with the video image data. This paper introduces an approach of using solely facial landmarks for deepfake detection. Using a dataset consisting of both deepfake and genuine videos of human faces, this paper describes an approach for extracting facial landmarks for deepfake detection, focusing on identifying subtle inconsistencies in facial movements instead of raw image processing. Experimental results demonstrated that this feature extraction technique is effective in various neural network models, with the same facial landmarks tested on three neural network models, with promising performance metrics indicating its potential for real-world applications. The findings discussed in this paper include RNN and artificial neural network (ANN) models with accuracy between 96% and 93%, respectively, with a CNN model hovering around 78%. This research challenges the assumption that raw image processing is necessary to identify deepfake videos by presenting a facial feature extraction approach compatible with various neural network models while requiring fewer parameters.', 'abstract_zh': '深fake技术的兴起引发了对在线各种媒体 authenticity的新问题，生成于人工智能（AI）的视频和图像越来越难以与真实媒体区分开来，因此需要新的模型来检测人工生成的媒体。尽管已经提出了许多模型来解决这一问题，大多数模型主要关注直接图像处理，适应卷积神经网络（CNN）或递归神经网络（RNN），直接与视频图像数据交互。本文介绍了仅使用面部特征点进行深fake检测的方法。使用包含人工生成和真实视频人脸的的数据集，本文描述了一种提取面部特征点的方法，专注于识别面部运动中的细微不一致性，而不是直接的图像处理。实验结果表明，这种特征提取技术在各种神经网络模型中都是有效的，经过相同的面部特征点在三种神经网络模型上的测试，显示出其在实际应用中的潜力。本研究讨论的结果包括RNN和人工神经网络（ANN）模型的准确率分别为96%和93%，而CNN模型的准确率约为78%。本文挑战了直接图像处理是识别深fake视频所必需的假设，通过展示一种与各种神经网络模型兼容的面部特征提取方法，同时需要较少的参数。', 'title_zh': '基于面部特征提取与建模的Deepfake检测'}
{'arxiv_id': 'arXiv:2507.18740', 'title': 'Learned Single-Pixel Fluorescence Microscopy', 'authors': "Serban C. Tudosie, Valerio Gandolfi, Shivaprasad Varakkoth, Andrea Farina, Cosimo D'Andrea, Simon Arridge", 'link': 'https://arxiv.org/abs/2507.18740', 'abstract': 'Single-pixel imaging has emerged as a key technique in fluorescence microscopy, where fast acquisition and reconstruction are crucial. In this context, images are reconstructed from linearly compressed measurements. In practice, total variation minimisation is still used to reconstruct the image from noisy measurements of the inner product between orthogonal sampling pattern vectors and the original image data. However, data can be leveraged to learn the measurement vectors and the reconstruction process, thereby enhancing compression, reconstruction quality, and speed. We train an autoencoder through self-supervision to learn an encoder (or measurement matrix) and a decoder. We then test it on physically acquired multispectral and intensity data. During acquisition, the learned encoder becomes part of the physical device. Our approach can enhance single-pixel imaging in fluorescence microscopy by reducing reconstruction time by two orders of magnitude, achieving superior image quality, and enabling multispectral reconstructions. Ultimately, learned single-pixel fluorescence microscopy could advance diagnosis and biological research, providing multispectral imaging at a fraction of the cost.', 'abstract_zh': '单像素成像在荧光显微镜中的新兴关键技术：通过学习提高压缩、重建质量和速度', 'title_zh': '学习单像素荧光显微镜'}
{'arxiv_id': 'arXiv:2507.18732', 'title': 'Multi-Year Maintenance Planning for Large-Scale Infrastructure Systems: A Novel Network Deep Q-Learning Approach', 'authors': 'Amir Fard, Arnold X.-X. Yuan', 'link': 'https://arxiv.org/abs/2507.18732', 'abstract': 'Infrastructure asset management is essential for sustaining the performance of public infrastructure such as road networks, bridges, and utility networks. Traditional maintenance and rehabilitation planning methods often face scalability and computational challenges, particularly for large-scale networks with thousands of assets under budget constraints. This paper presents a novel deep reinforcement learning (DRL) framework that optimizes asset management strategies for large infrastructure networks. By decomposing the network-level Markov Decision Process (MDP) into individual asset-level MDPs while using a unified neural network architecture, the proposed framework reduces computational complexity, improves learning efficiency, and enhances scalability. The framework directly incorporates annual budget constraints through a budget allocation mechanism, ensuring maintenance plans are both optimal and cost-effective. Through a case study on a large-scale pavement network of 68,800 segments, the proposed DRL framework demonstrates significant improvements over traditional methods like Progressive Linear Programming and genetic algorithms, both in efficiency and network performance. This advancement contributes to infrastructure asset management and the broader application of reinforcement learning in complex, large-scale environments.', 'abstract_zh': '大型基础设施网络资产管理系统中的新颖深度强化学习框架', 'title_zh': '大规模基础设施系统多年维护规划：一种新型网络深度Q学习方法'}
{'arxiv_id': 'arXiv:2507.18725', 'title': 'The Right to be Forgotten in Pruning: Unveil Machine Unlearning on Sparse Models', 'authors': 'Yang Xiao, Gen Li, Jie Ji, Ruimeng Ye, Xiaolong Ma, Bo Hui', 'link': 'https://arxiv.org/abs/2507.18725', 'abstract': 'Machine unlearning aims to efficiently eliminate the memory about deleted data from trained models and address the right to be forgotten. Despite the success of existing unlearning algorithms, unlearning in sparse models has not yet been well studied. In this paper, we empirically find that the deleted data has an impact on the pruned topology in a sparse model. Motivated by the observation and the right to be forgotten, we define a new terminology ``un-pruning" to eliminate the impact of deleted data on model pruning. Then we propose an un-pruning algorithm to approximate the pruned topology driven by retained data. We remark that any existing unlearning algorithm can be integrated with the proposed un-pruning workflow and the error of un-pruning is upper-bounded in theory. Also, our un-pruning algorithm can be applied to both structured sparse models and unstructured sparse models. In the experiment, we further find that Membership Inference Attack (MIA) accuracy is unreliable for assessing whether a model has forgotten deleted data, as a small change in the amount of deleted data can produce arbitrary MIA results. Accordingly, we devise new performance metrics for sparse models to evaluate the success of un-pruning. Lastly, we conduct extensive experiments to verify the efficacy of un-pruning with various pruning methods and unlearning algorithms. Our code is released at this https URL.', 'abstract_zh': '机器去学习旨在高效地从训练模型中消除已删除数据的记忆，并解决被遗忘的权利。尽管现有去学习算法取得了成功，但在稀疏模型中的去学习尚未得到充分研究。在本文中，我们实证发现删除的数据会对稀疏模型中的剪枝拓扑产生影响。受此观察及被遗忘权利的启发，我们定义了一个新的术语“去剪枝”（un-pruning）以消除删除数据对模型剪枝的影响。然后，我们提出了一种由保留数据驱动的去剪枝算法来逼近剪枝拓扑。我们注意到，任何现有的去学习算法都可以与提出的去剪枝工作流结合使用，并且理论上可以将去剪枝的误差上界化。此外，我们的去剪枝算法可以适用于结构稀疏模型和无结构稀疏模型。在实验中，我们进一步发现，成员推理攻击（MIA）的准确性对于评估模型是否已忘记删除的数据是不可靠的，因为删除数据量的微小变化可以导致任意的MIA结果。因此，我们为稀疏模型设计了新的性能度量来评估去剪枝的成功。最后，我们进行了广泛实验以验证不同剪枝方法和去学习算法下去剪枝的有效性。我们的代码发布在该网址：https://。', 'title_zh': '遗忘权在修剪中的应用：揭示稀疏模型中的机器遗忘'}
{'arxiv_id': 'arXiv:2507.18681', 'title': 'Concept Probing: Where to Find Human-Defined Concepts (Extended Version)', 'authors': 'Manuel de Sousa Ribeiro, Afonso Leote, João Leite', 'link': 'https://arxiv.org/abs/2507.18681', 'abstract': "Concept probing has recently gained popularity as a way for humans to peek into what is encoded within artificial neural networks. In concept probing, additional classifiers are trained to map the internal representations of a model into human-defined concepts of interest. However, the performance of these probes is highly dependent on the internal representations they probe from, making identifying the appropriate layer to probe an essential task. In this paper, we propose a method to automatically identify which layer's representations in a neural network model should be considered when probing for a given human-defined concept of interest, based on how informative and regular the representations are with respect to the concept. We validate our findings through an exhaustive empirical analysis over different neural network models and datasets.", 'abstract_zh': '概念探针作为一种方法，最近受到追捧，它允许人类窥探人工神经网络中编码的内容。在概念探针中，额外的分类器被训练来将模型的内部表示映射到人类定义的概念中。然而，这些探针的性能高度依赖于它们所探针的内部表示，因此确定探针的适当层次是一项必不可少的任务。在本文中，我们提出了一种方法，根据内部表示对给定的人类定义概念的相关性和规律性，自动识别在探针过程中应该考虑的神经网络模型中哪一层的表示。我们通过在不同神经网络模型和数据集上进行全面的实证分析来验证我们的发现。', 'title_zh': '概念探查：何处寻找人类定义的概念（扩展版本）'}
{'arxiv_id': 'arXiv:2507.18668', 'title': 'Efficient Knowledge Tracing Leveraging Higher-Order Information in Integrated Graphs', 'authors': 'Donghee Han, Daehee Kim, Minjun Lee, Daeyoung Roh, Keejun Han, Mun Yong Yi', 'link': 'https://arxiv.org/abs/2507.18668', 'abstract': 'The rise of online learning has led to the development of various knowledge tracing (KT) methods. However, existing methods have overlooked the problem of increasing computational cost when utilizing large graphs and long learning sequences. To address this issue, we introduce Dual Graph Attention-based Knowledge Tracing (DGAKT), a graph neural network model designed to leverage high-order information from subgraphs representing student-exercise-KC relationships. DGAKT incorporates a subgraph-based approach to enhance computational efficiency. By processing only relevant subgraphs for each target interaction, DGAKT significantly reduces memory and computational requirements compared to full global graph models. Extensive experimental results demonstrate that DGAKT not only outperforms existing KT models but also sets a new standard in resource efficiency, addressing a critical need that has been largely overlooked by prior KT approaches.', 'abstract_zh': '基于双图注意机制的知识追踪模型：DGAKT', 'title_zh': '利用综合图中高阶信息的高效知识追踪'}
{'arxiv_id': 'arXiv:2507.18640', 'title': 'How good are humans at detecting AI-generated images? Learnings from an experiment', 'authors': 'Thomas Roca, Anthony Cintron Roman, Jehú Torres Vega, Marcelo Duarte, Pengce Wang, Kevin White, Amit Misra, Juan Lavista Ferres', 'link': 'https://arxiv.org/abs/2507.18640', 'abstract': 'As AI-powered image generation improves, a key question is how well human beings can differentiate between "real" and AI-generated or modified images. Using data collected from the online game "Real or Not Quiz.", this study investigates how effectively people can distinguish AI-generated images from real ones. Participants viewed a randomized set of real and AI-generated images, aiming to identify their authenticity. Analysis of approximately 287,000 image evaluations by over 12,500 global participants revealed an overall success rate of only 62\\%, indicating a modest ability, slightly above chance. Participants were most accurate with human portraits but struggled significantly with natural and urban landscapes. These results highlight the inherent challenge humans face in distinguishing AI-generated visual content, particularly images without obvious artifacts or stylistic cues. This study stresses the need for transparency tools, such as watermarks and robust AI detection tools to mitigate the risks of misinformation arising from AI-generated content', 'abstract_zh': '随着AI驱动的图像生成技术的进步，一个关键问题是人类如何区分“真实”图像与AI生成或修改的图像。利用来自在线游戏“真实或假象测验”收集的数据，本研究调查了人们区分AI生成图像与真实图像的有效性。参与者被随机呈现真实和AI生成的图像，旨在识别这些图像的真实性。分析显示，超过12,500名全球参与者的约287,000次图像评估的总体准确率为62%，表明人们的辨别能力仅略有提高，略高于随机水平。参与者在识别人类肖像方面最准确，但在识别自然和城市景观方面遇到了显著困难。这些结果突显了人类在区分AI生成的视觉内容（尤其是没有明显瑕疵或风格线索的图像）方面的固有挑战。本研究强调了需要透明度工具（如水印和 robust AI检测工具）以减轻由AI生成内容引发的虚假信息风险。', 'title_zh': '人类如何检测AI生成的图像？一项实验的启示'}
{'arxiv_id': 'arXiv:2507.18637', 'title': 'More Expert-like Eye Gaze Movement Patterns are Related to Better X-ray Reading', 'authors': 'Pingjing Yang, Jennifer Cromley, Jana Diesner', 'link': 'https://arxiv.org/abs/2507.18637', 'abstract': "Understanding how novices acquire and hone visual search skills is crucial for developing and optimizing training methods across domains. Network analysis methods can be used to analyze graph representations of visual expertise. This study investigates the relationship between eye-gaze movements and learning outcomes among undergraduate dentistry students who were diagnosing dental radiographs over multiple semesters. We use network analysis techniques to model eye-gaze scanpaths as directed graphs and examine changes in network metrics over time. Using time series clustering on each metric, we identify distinct patterns of visual search strategies and explore their association with students' diagnostic performance. Our findings suggest that the network metric of transition entropy is negatively correlated with performance scores, while the number of nodes and edges as well as average PageRank are positively correlated with performance scores. Changes in network metrics for individual students over time suggest a developmental shift from intermediate to expert-level processing. These insights contribute to understanding expertise acquisition in visual tasks and can inform the design of AI-assisted learning interventions.", 'abstract_zh': '理解初学者在诊断牙科X光片过程中获取和提高视觉搜索技能的方式对于跨领域开发和优化培训方法至关重要。网络分析方法可用于分析视觉专长的图表示。本研究探讨了本科生在多个学期诊断牙科X光片过程中眼注视运动与学习成果之间的关系。我们使用网络分析技术将眼注视扫描路径建模为有向图，并检查随着时间的变化网络度量的变化。通过时间序列聚类分析每个度量，我们识别出不同的视觉搜索策略模式，并探索它们与学生诊断表现之间的关系。研究发现，网络度量转换熵与绩效评分负相关，而节点数和边数以及平均PageRank与绩效评分正相关。单个学生随时间网络度量的变化表明，从中间水平到专家水平的处理发生了发展性转变。这些见解有助于理解视觉任务中的专长获取，并可以指导AI辅助学习干预的设计。', 'title_zh': '更接近专家的眼球凝视运动模式与更好的X射线阅读相关'}
