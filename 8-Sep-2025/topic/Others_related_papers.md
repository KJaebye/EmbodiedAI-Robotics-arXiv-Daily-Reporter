# The best approximation pair problem relative to two subsets in a normed space 

**Title (ZH)**: 相对两个子集在赋范空间中的最佳逼近对问题 

**Authors**: Daniel Reem, Yair Censor  

**Link**: [PDF](https://arxiv.org/pdf/2403.18767)  

**Abstract**: In the classical best approximation pair (BAP) problem, one is given two nonempty, closed, convex and disjoint subsets in a finite- or an infinite-dimensional Hilbert space, and the goal is to find a pair of points, each from each subset, which realizes the distance between the subsets. We discuss the problem in more general normed spaces and with possibly non-convex subsets, and focus our attention on the issues of uniqueness and existence of the solution to the problem. As far as we know, these fundamental issues have not received much attention. We present several sufficient geometric conditions for the (at most) uniqueness of a BAP. These conditions are related to the structure and the relative orientation of the boundaries of the subsets and to the norm. We also present many sufficient conditions for the existence of a BAP. Our results significantly extend the horizon of a recent algorithm for solving the BAP problem [Censor, Mansour, Reem, J. Approx. Theory (2024)]. The paper also shows, perhaps for the first time, how wide is the scope of the BAP problem in terms of the scientific communities which are involved in it (frequently independently) and in terms of its applications. 

**Abstract (ZH)**: 经典最佳近似对（BAP）问题中，给定有限维或无限维希尔伯特空间中的两个非空、闭合、凸且不相交的子集，目标是找到每部分来自各子集的一对点，使这两点之间的距离最小化。我们将该问题推广到更一般的赋范空间，并考虑可能不凸的子集，重点讨论解的唯一性和存在性问题。据我们所知，这些基本问题尚未引起广泛关注。我们提出了若干充分几何条件来保障（至多）唯一性。这些条件涉及子集边界的结构及其相对方位以及范数。我们还提出了许多充分条件来保障BAP的存在性。我们的结果大大扩展了近期解决BAP问题的算法[曾森, 曼苏尔, 雷姆, 《逼近理论杂志》 (2024)]的应用范围。本文还展示了BAP问题在涉及的科学社区（经常独立地）以及应用范围上的广度，可能是首次如此全面地展示。 

---
# Evaluation and Comparison Semantics for ODRL 

**Title (ZH)**: ODRL的评价与比较语义 

**Authors**: Jaime Osvaldo Salas, Paolo Pareti, Semih Yumuşak, Soulmaz Gheisari, Luis-Daniel Ibáñez, George Konstantinidis  

**Link**: [PDF](https://arxiv.org/pdf/2509.05139)  

**Abstract**: We consider the problem of evaluating, and comparing computational policies in the Open Digital Rights Language (ODRL), which has become the de facto standard for governing the access and usage of digital resources. Although preliminary progress has been made on the formal specification of the language's features, a comprehensive formal semantics of ODRL is still missing. In this paper, we provide a simple and intuitive formal semantics for ODRL that is based on query answering. Our semantics refines previous formalisations, and is aligned with the latest published specification of the language (2.2). Building on our evaluation semantics, and motivated by data sharing scenarios, we also define and study the problem of comparing two policies, detecting equivalent, more restrictive or more permissive policies. 

**Abstract (ZH)**: 我们考虑在开放数字权利语言（ODRL）中评估和比较计算策略的问题，ODRL已成为治理数字资源访问和使用事实标准。尽管在语言特征的形式化规范方面取得了初步进展，但ODRL的全面形式语义仍然缺失。本文提供了基于查询回答的简单直观形式语义，该语义改进了先前的形式化定义，并与语言的最新发布规范（2.2版）保持一致。在我们的评估语义基础上，并受数据共享场景的启发，我们还定义并研究了比较两个策略的问题，检测等价的、更严格的或更宽松的策略。 

---
# ProToM: Promoting Prosocial Behaviour via Theory of Mind-Informed Feedback 

**Title (ZH)**: ProToM: 通过理论心智指导反馈促进利他行为 

**Authors**: Matteo Bortoletto, Yichao Zhou, Lance Ying, Tianmin Shu, Andreas Bulling  

**Link**: [PDF](https://arxiv.org/pdf/2509.05091)  

**Abstract**: While humans are inherently social creatures, the challenge of identifying when and how to assist and collaborate with others - particularly when pursuing independent goals - can hinder cooperation. To address this challenge, we aim to develop an AI system that provides useful feedback to promote prosocial behaviour - actions that benefit others, even when not directly aligned with one's own goals. We introduce ProToM, a Theory of Mind-informed facilitator that promotes prosocial actions in multi-agent systems by providing targeted, context-sensitive feedback to individual agents. ProToM first infers agents' goals using Bayesian inverse planning, then selects feedback to communicate by maximising expected utility, conditioned on the inferred goal distribution. We evaluate our approach against baselines in two multi-agent environments: Doors, Keys, and Gems, as well as Overcooked. Our results suggest that state-of-the-art large language and reasoning models fall short of communicating feedback that is both contextually grounded and well-timed - leading to higher communication overhead and task speedup. In contrast, ProToM provides targeted and helpful feedback, achieving a higher success rate, shorter task completion times, and is consistently preferred by human users. 

**Abstract (ZH)**: 虽然人类本质上是社会动物，但在追求独立目标时识别何时以及如何协助和与他人合作仍然是一个挑战。为了解决这一挑战，我们旨在开发一个AI系统，该系统可以提供有用的反馈以促进助人行为——即即使这些行为与个人目标不完全一致也能惠及他人的行动。我们介绍了ProToM，一种基于理论心智的促进者，在多智能体系统中通过提供针对性的、适时的反馈来促进助人行为。ProToM 首先使用贝叶斯逆向规划推理智能体的目标，然后通过最大化先验目标分布的预期效用来选择要传达的反馈内容。我们在两个多智能体环境中——Doors、Keys、and Gems，以及Overcooked——中将我们的方法与 baselines 进行了对比评估。我们的结果表明，最先进的大型语言和推理模型在传达内容上下文相关且时机恰当的反馈方面存在不足——导致了更高的沟通开销和任务加速。相比之下，ProToM 提供了有针对性且有帮助的反馈，成功率达到更高，任务完成时间更短，并且始终被人类用户更偏爱。 

---
# Finding your MUSE: Mining Unexpected Solutions Engine 

**Title (ZH)**: 寻找你的缪斯：挖掘意外解决方案引擎 

**Authors**: Nir Sweed, Hanit Hakim, Ben Wolfson, Hila Lifshitz, Dafna Shahaf  

**Link**: [PDF](https://arxiv.org/pdf/2509.05072)  

**Abstract**: Innovators often exhibit cognitive fixation on existing solutions or nascent ideas, hindering the exploration of novel alternatives. This paper introduces a methodology for constructing Functional Concept Graphs (FCGs), interconnected representations of functional elements that support abstraction, problem reframing, and analogical inspiration. Our approach yields large-scale, high-quality FCGs with explicit abstraction relations, overcoming limitations of prior work. We further present MUSE, an algorithm leveraging FCGs to generate creative inspirations for a given problem. We demonstrate our method by computing an FCG on 500K patents, which we release for further research. 

**Abstract (ZH)**: 创新者 often表现出对现有解决方案或萌芽中的新想法的认知固定，这阻碍了对新颖替代方案的探索。本文介绍了一种构建功能概念图（FCGs）的方法，FCGs是功能元素的互联互通表示，支持抽象、问题重新框架和类比灵感。我们的方法产生大规模、高质量的FCGs，具有明确的抽象关系，克服了先前工作的局限性。我们进一步介绍了利用FCGs为给定问题生成创造性灵感的MUSE算法。我们通过在50万项专利上计算FCG来演示我们的方法，并将其发布以供进一步研究。 

---
# Sticker-TTS: Learn to Utilize Historical Experience with a Sticker-driven Test-Time Scaling Framework 

**Title (ZH)**: Sticker-TTS：基于贴纸驱动的测试时缩放框架以利用历史经验 

**Authors**: Jie Chen, Jinhao Jiang, Yingqian Min, Zican Dong, Shijie Wang, Wayne Xin Zhao, Ji-Rong Wen  

**Link**: [PDF](https://arxiv.org/pdf/2509.05007)  

**Abstract**: Large reasoning models (LRMs) have exhibited strong performance on complex reasoning tasks, with further gains achievable through increased computational budgets at inference. However, current test-time scaling methods predominantly rely on redundant sampling, ignoring the historical experience utilization, thereby limiting computational efficiency. To overcome this limitation, we propose Sticker-TTS, a novel test-time scaling framework that coordinates three collaborative LRMs to iteratively explore and refine solutions guided by historical attempts. At the core of our framework are distilled key conditions-termed stickers-which drive the extraction, refinement, and reuse of critical information across multiple rounds of reasoning. To further enhance the efficiency and performance of our framework, we introduce a two-stage optimization strategy that combines imitation learning with self-improvement, enabling progressive refinement. Extensive evaluations on three challenging mathematical reasoning benchmarks, including AIME-24, AIME-25, and OlymMATH, demonstrate that Sticker-TTS consistently surpasses strong baselines, including self-consistency and advanced reinforcement learning approaches, under comparable inference budgets. These results highlight the effectiveness of sticker-guided historical experience utilization. Our code and data are available at this https URL. 

**Abstract (ZH)**: 大型推理模型（LRMs）在复杂推理任务上表现出强大的性能，通过增加推理时的计算预算可以进一步提高性能。然而，当前的测试时扩展方法主要依赖冗余采样，忽视了历史经验的利用，从而限制了计算效率。为克服这一限制，我们提出了一种名为Sticker-TTS的新型测试时扩展框架，该框架协调三个协作的LRMs，在历史尝试的指导下迭代探索和细化解决方案。框架的核心是浓缩的关键条件——贴纸，这些贴纸驱动多个推理环节中关键信息的提取、细化和重用。为进一步提高框架的效率和性能，我们引入了一种两阶段优化策略，结合模仿学习与自我改进，实现渐进的精细化。在三个具有挑战性的数学推理基准测试上的广泛评估表明，Sticker-TTS 在相同期限推理预算下始终优于包括自我一致性和高级强化学习方法在内的强基线。这些结果突显了贴纸引导的历史经验利用的有效性。我们的代码和数据可在以下链接获取。 

---
# An Approach to Grounding AI Model Evaluations in Human-derived Criteria 

**Title (ZH)**: 一种基于人类derive标准的AI模型评估方法 

**Authors**: Sasha Mitts  

**Link**: [PDF](https://arxiv.org/pdf/2509.04676)  

**Abstract**: In the rapidly evolving field of artificial intelligence (AI), traditional benchmarks can fall short in attempting to capture the nuanced capabilities of AI models. We focus on the case of physical world modeling and propose a novel approach to augment existing benchmarks with human-derived evaluation criteria, aiming to enhance the interpretability and applicability of model behaviors. Grounding our study in the Perception Test and OpenEQA benchmarks, we conducted in-depth interviews and large-scale surveys to identify key cognitive skills, such as Prioritization, Memorizing, Discerning, and Contextualizing, that are critical for both AI and human reasoning. Our findings reveal that participants perceive AI as lacking in interpretive and empathetic skills yet hold high expectations for AI performance. By integrating insights from our findings into benchmark design, we offer a framework for developing more human-aligned means of defining and measuring progress. This work underscores the importance of user-centered evaluation in AI development, providing actionable guidelines for researchers and practitioners aiming to align AI capabilities with human cognitive processes. Our approach both enhances current benchmarking practices and sets the stage for future advancements in AI model evaluation. 

**Abstract (ZH)**: 在快速发展的人工智能领域，传统的基准标准在试图捕捉AI模型的细微能力上可能存在不足。我们专注于物理世界建模的案例，提出了一种新的方法，通过引入由人类制定的评估标准来增强现有的基准标准，旨在提升模型行为的可解释性和适用性。基于感知测试和OpenEQA基准，我们进行了深入访谈和大规模问卷调查，以识别对于AI和人类推理都至关重要的关键认知技能，如优先级确定、记忆、分辨和上下文理解。我们的研究发现表明，参与者普遍认为AI在解释性和共情能力上存在不足，但对AI的表现寄予很高期望。通过将我们的发现融入基准设计中，我们提供了一个框架，用于开发更为符合人类认知过程的定义和测量进步的方法。这项工作强调了在人工智能开发中以用户为中心的评估的重要性，为希望使AI能力与人类认知过程保持一致的研究人员和从业人员提供了可操作的指导方针。我们的方法不仅改进了当前的基准测试实践，也为未来人工智能模型评估的进步奠定了基础。 

---
# Recomposer: Event-roll-guided generative audio editing 

**Title (ZH)**: Recomposer: 事件卷引导的生成音频编辑 

**Authors**: Daniel P. W. Ellis, Eduardo Fonseca, Ron J. Weiss, Kevin Wilson, Scott Wisdom, Hakan Erdogan, John R. Hershey, Aren Jansen, R. Channing Moore, Manoj Plakal  

**Link**: [PDF](https://arxiv.org/pdf/2509.05256)  

**Abstract**: Editing complex real-world sound scenes is difficult because individual sound sources overlap in time. Generative models can fill-in missing or corrupted details based on their strong prior understanding of the data domain. We present a system for editing individual sound events within complex scenes able to delete, insert, and enhance individual sound events based on textual edit descriptions (e.g., ``enhance Door'') and a graphical representation of the event timing derived from an ``event roll'' transcription. We present an encoder-decoder transformer working on SoundStream representations, trained on synthetic (input, desired output) audio example pairs formed by adding isolated sound events to dense, real-world backgrounds. Evaluation reveals the importance of each part of the edit descriptions -- action, class, timing. Our work demonstrates ``recomposition'' is an important and practical application. 

**Abstract (ZH)**: 基于文本描述和事件timing图形表示编辑复杂声景中的个体声事件 

---
# RapidGNN: Energy and Communication-Efficient Distributed Training on Large-Scale Graph Neural Networks 

**Title (ZH)**: RapidGNN: 大规模图神经网络的能效和通信高效分布式训练 

**Authors**: Arefin Niam, Tevfik Kosar, M S Q Zulkar Nine  

**Link**: [PDF](https://arxiv.org/pdf/2509.05207)  

**Abstract**: Graph Neural Networks (GNNs) have become popular across a diverse set of tasks in exploring structural relationships between entities. However, due to the highly connected structure of the datasets, distributed training of GNNs on large-scale graphs poses significant challenges. Traditional sampling-based approaches mitigate the computational loads, yet the communication overhead remains a challenge. This paper presents RapidGNN, a distributed GNN training framework with deterministic sampling-based scheduling to enable efficient cache construction and prefetching of remote features. Evaluation on benchmark graph datasets demonstrates RapidGNN's effectiveness across different scales and topologies. RapidGNN improves end-to-end training throughput by 2.46x to 3.00x on average over baseline methods across the benchmark datasets, while cutting remote feature fetches by over 9.70x to 15.39x. RapidGNN further demonstrates near-linear scalability with an increasing number of computing units efficiently. Furthermore, it achieves increased energy efficiency over the baseline methods for both CPU and GPU by 44% and 32%, respectively. 

**Abstract (ZH)**: 基于确定性采样调度的分布式GNN训练框架RapidGNN 

---
# Accuracy-Constrained CNN Pruning for Efficient and Reliable EEG-Based Seizure Detection 

**Title (ZH)**: 基于准确率约束的CNN剪枝以实现高效的可靠的脑电图诱发检测 

**Authors**: Mounvik K, N Harshit  

**Link**: [PDF](https://arxiv.org/pdf/2509.05190)  

**Abstract**: Deep learning models, especially convolutional neural networks (CNNs), have shown considerable promise for biomedical signals such as EEG-based seizure detection. However, these models come with challenges, primarily due to their size and compute requirements in environments where real-time detection or limited resources are available. In this study, we present a lightweight one-dimensional CNN model with structured pruning to improve efficiency and reliability. The model was trained with mild early stopping to address possible overfitting, achieving an accuracy of 92.78% and a macro-F1 score of 0.8686. Structured pruning of the baseline CNN involved removing 50% of the convolutional kernels based on their importance to model predictions. Surprisingly, after pruning the weights and memory by 50%, the new network was still able to maintain predictive capabilities, while modestly increasing precision to 92.87% and improving the macro-F1 score to 0.8707. Overall, we present a convincing case that structured pruning removes redundancy, improves generalization, and, in combination with mild early stopping, achieves a promising way forward to improve seizure detection efficiency and reliability, which is clear motivation for resource-limited settings. 

**Abstract (ZH)**: 基于结构化剪枝的轻量级一维卷积神经网络在癫痫检测中的高效与可靠性能 

---
# Exploring Situated Stabilities of a Rhythm Generation System through Variational Cross-Examination 

**Title (ZH)**: 探索节奏生成系统中情境稳定性的变异性交叉检验 

**Authors**: Błażej Kotowski, Nicholas Evans, Behzad Haki, Frederic Font, Sergi Jordà  

**Link**: [PDF](https://arxiv.org/pdf/2509.05145)  

**Abstract**: This paper investigates GrooveTransformer, a real-time rhythm generation system, through the postphenomenological framework of Variational Cross-Examination (VCE). By reflecting on its deployment across three distinct artistic contexts, we identify three stabilities: an autonomous drum accompaniment generator, a rhythmic control voltage sequencer in Eurorack format, and a rhythm driver for a harmonic accompaniment system. The versatility of its applications was not an explicit goal from the outset of the project. Thus, we ask: how did this multistability emerge? Through VCE, we identify three key contributors to its emergence: the affordances of system invariants, the interdisciplinary collaboration, and the situated nature of its development. We conclude by reflecting on the viability of VCE as a descriptive and analytical method for Digital Musical Instrument (DMI) design, emphasizing its value in uncovering how technologies mediate, co-shape, and are co-shaped by users and contexts. 

**Abstract (ZH)**: 通过变异性交叉考问（VCE）的后现象学框架探究GrooveTransformer：一种实时节奏生成系统的多稳定性及其演变 

---
# GenAI-based test case generation and execution in SDV platform 

**Title (ZH)**: 基于GenAI的测试用例生成与执行在SDV平台中 

**Authors**: Denesa Zyberaj, Lukasz Mazur, Nenad Petrovic, Pankhuri Verma, Pascal Hirmer, Dirk Slama, Xiangwei Cheng, Alois Knoll  

**Link**: [PDF](https://arxiv.org/pdf/2509.05112)  

**Abstract**: This paper introduces a GenAI-driven approach for automated test case generation, leveraging Large Language Models and Vision-Language Models to translate natural language requirements and system diagrams into structured Gherkin test cases. The methodology integrates Vehicle Signal Specification modeling to standardize vehicle signal definitions, improve compatibility across automotive subsystems, and streamline integration with third-party testing tools. Generated test cases are executed within the this http URL playground, an open and vendor-neutral environment designed to facilitate rapid validation of software-defined vehicle functionalities. We evaluate our approach using the Child Presence Detection System use case, demonstrating substantial reductions in manual test specification effort and rapid execution of generated tests. Despite significant automation, the generation of test cases and test scripts still requires manual intervention due to current limitations in the GenAI pipeline and constraints of the this http URL platform. 

**Abstract (ZH)**: 基于生成式人工智能的自动化测试用例生成方法：利用大型语言模型和多模态语言模型将自然语言需求和系统图转换为结构化的Gherkin测试用例，并通过车辆信号规范建模标准化车辆信号定义，提高跨汽车子系统的一致性，并简化与第三方测试工具的集成。生成的测试用例在this http URL游乐场中执行，这是一个开放且供应商中立的环境，旨在促进对软件定义车辆功能的快速验证。通过使用儿童存在检测系统使用案例评估我们的方法，展示了大幅减少手动测试规范工作量和生成测试的快速执行。尽管有显著的自动化，但由于生成式人工智能管道的当前限制和this http URL平台的约束，生成测试用例和测试脚本仍需要人工干预。 

---
# ICR: Iterative Clarification and Rewriting for Conversational Search 

**Title (ZH)**: ICR：迭代澄清与重写在会话搜索中的应用 

**Authors**: Zhiyu Cao, Peifeng Li, Qiaoming Zhu  

**Link**: [PDF](https://arxiv.org/pdf/2509.05100)  

**Abstract**: Most previous work on Conversational Query Rewriting employs an end-to-end rewriting paradigm. However, this approach is hindered by the issue of multiple fuzzy expressions within the query, which complicates the simultaneous identification and rewriting of multiple positions. To address this issue, we propose a novel framework ICR (Iterative Clarification and Rewriting), an iterative rewriting scheme that pivots on clarification questions. Within this framework, the model alternates between generating clarification questions and rewritten queries. The experimental results show that our ICR can continuously improve retrieval performance in the clarification-rewriting iterative process, thereby achieving state-of-the-art performance on two popular datasets. 

**Abstract (ZH)**: 最先前的工作在会话查询重写方面大多采用端到端的重写范式。然而，这种方法受限于查询中存在多个模糊表达式的问题，这使得同时识别和重写多个位置变得复杂。为了解决这个问题，我们提出了一种新颖的ICR（迭代澄清与重写）框架，这是一种基于澄清问题的迭代重写方案。在该框架中，模型交替生成澄清问题和重写查询。实验结果表明，我们的ICR能够在澄清-重写迭代过程中持续提高检索性能，从而在两个流行的数据库上实现了最先进的性能。 

---
# Adversarial Augmentation and Active Sampling for Robust Cyber Anomaly Detection 

**Title (ZH)**: 对抗性增强与主动采样在鲁棒网络异常检测中的应用 

**Authors**: Sidahmed Benabderrahmane, Talal Rahwan  

**Link**: [PDF](https://arxiv.org/pdf/2509.04999)  

**Abstract**: Advanced Persistent Threats (APTs) present a considerable challenge to cybersecurity due to their stealthy, long-duration nature. Traditional supervised learning methods typically require large amounts of labeled data, which is often scarce in real-world scenarios. This paper introduces a novel approach that combines AutoEncoders for anomaly detection with active learning to iteratively enhance APT detection. By selectively querying an oracle for labels on uncertain or ambiguous samples, our method reduces labeling costs while improving detection accuracy, enabling the model to effectively learn with minimal data and reduce reliance on extensive manual labeling. We present a comprehensive formulation of the Attention Adversarial Dual AutoEncoder-based anomaly detection framework and demonstrate how the active learning loop progressively enhances the model's performance. The framework is evaluated on real-world, imbalanced provenance trace data from the DARPA Transparent Computing program, where APT-like attacks account for just 0.004\% of the data. The datasets, which cover multiple operating systems including Android, Linux, BSD, and Windows, are tested in two attack scenarios. The results show substantial improvements in detection rates during active learning, outperforming existing methods. 

**Abstract (ZH)**: 高级持续威胁（APTs）由于其隐蔽和长时间的特性，对网络安全构成了重大挑战。传统的监督学习方法通常需要大量标记数据，而在实际场景中这些数据往往是稀缺的。本文介绍了一种结合自编码器进行异常检测与主动学习的新方法，以迭代增强APT检测能力。通过选择性地向专家查询不确定或模棱两可样本的标签，该方法降低了标注成本并提高了检测准确性，使模型能够在少量数据下有效学习，并减少对大量手工标注的依赖。本文提出了基于注意力对抗双自编码器的异常检测框架的完整理论，并展示了如何通过主动学习循环逐步提升模型性能。该框架在DARPA透明计算计划的真实、不平衡的起源跟踪数据集上进行了评估，其中APT样式的攻击仅占数据的0.004%。测试数据集涵盖了包括Android、Linux、BSD和Windows在内的多种操作系统，并在两种攻击场景下进行测试。结果表明，在主动学习过程中检测率有了显著提高，优于现有方法。 

---
# High-Resolution Global Land Surface Temperature Retrieval via a Coupled Mechanism-Machine Learning Framework 

**Title (ZH)**: 基于耦合机制-机器学习框架的高分辨率全球地表温度反演 

**Authors**: Tian Xie, Huanfeng Shen, Menghui Jiang, Juan-Carlos Jiménez-Muñoz, José A. Sobrino, Huifang Li, Chao Zeng  

**Link**: [PDF](https://arxiv.org/pdf/2509.04991)  

**Abstract**: Land surface temperature (LST) is vital for land-atmosphere interactions and climate processes. Accurate LST retrieval remains challenging under heterogeneous land cover and extreme atmospheric conditions. Traditional split window (SW) algorithms show biases in humid environments; purely machine learning (ML) methods lack interpretability and generalize poorly with limited data. We propose a coupled mechanism model-ML (MM-ML) framework integrating physical constraints with data-driven learning for robust LST retrieval. Our approach fuses radiative transfer modeling with data components, uses MODTRAN simulations with global atmospheric profiles, and employs physics-constrained optimization. Validation against 4,450 observations from 29 global sites shows MM-ML achieves MAE=1.84K, RMSE=2.55K, and R-squared=0.966, outperforming conventional methods. Under extreme conditions, MM-ML reduces errors by over 50%. Sensitivity analysis indicates LST estimates are most sensitive to sensor radiance, then water vapor, and less to emissivity, with MM-ML showing superior stability. These results demonstrate the effectiveness of our coupled modeling strategy for retrieving geophysical parameters. The MM-ML framework combines physical interpretability with nonlinear modeling capacity, enabling reliable LST retrieval in complex environments and supporting climate monitoring and ecosystem studies. 

**Abstract (ZH)**: 基于物理约束的数据驱动耦合机制模型-机器学习框架在复杂环境下的地表温度反演 

---
# Exploring an implementation of quantum learning pipeline for support vector machines 

**Title (ZH)**: 探索量子学习管道在支持向量机中的实现 

**Authors**: Mario Bifulco, Luca Roversi  

**Link**: [PDF](https://arxiv.org/pdf/2509.04983)  

**Abstract**: This work presents a fully quantum approach to support vector machine (SVM) learning by integrating gate-based quantum kernel methods with quantum annealing-based optimization. We explore the construction of quantum kernels using various feature maps and qubit configurations, evaluating their suitability through Kernel-Target Alignment (KTA). The SVM dual problem is reformulated as a Quadratic Unconstrained Binary Optimization (QUBO) problem, enabling its solution via quantum annealers. Our experiments demonstrate that a high degree of alignment in the kernel and an appropriate regularization parameter lead to competitive performance, with the best model achieving an F1-score of 90%. These results highlight the feasibility of an end-to-end quantum learning pipeline and the potential of hybrid quantum architectures in quantum high-performance computing (QHPC) contexts. 

**Abstract (ZH)**: 这项工作通过将基于门的量子核方法与量子退火优化集成，提出了一种全面的量子支持向量机（SVM）学习方法。我们探讨了使用各种特征映射和自旋配置构建量子核的方法，并通过核目标对齐（KTA）评估其适用性。将SVM的对偶问题重新表述为二次无约束二元优化（QUBO）问题，从而使量子退火器能够求解。实验结果表明，核的高对齐程度和适当的正则化参数可以实现竞争力的性能，最佳模型的F1分数达到90%。这些结果突显了端到端量子学习管道的可能性，并展示了混合量子架构在量子高性能计算（QHPC）环境中的潜力。 

---
# Artificial intelligence for representing and characterizing quantum systems 

**Title (ZH)**: 人工智能表示和表征量子系统 

**Authors**: Yuxuan Du, Yan Zhu, Yuan-Hang Zhang, Min-Hsiu Hsieh, Patrick Rebentrost, Weibo Gao, Ya-Dong Wu, Jens Eisert, Giulio Chiribella, Dacheng Tao, Barry C. Sanders  

**Link**: [PDF](https://arxiv.org/pdf/2509.04923)  

**Abstract**: Efficient characterization of large-scale quantum systems, especially those produced by quantum analog simulators and megaquop quantum computers, poses a central challenge in quantum science due to the exponential scaling of the Hilbert space with respect to system size. Recent advances in artificial intelligence (AI), with its aptitude for high-dimensional pattern recognition and function approximation, have emerged as a powerful tool to address this challenge. A growing body of research has leveraged AI to represent and characterize scalable quantum systems, spanning from theoretical foundations to experimental realizations. Depending on how prior knowledge and learning architectures are incorporated, the integration of AI into quantum system characterization can be categorized into three synergistic paradigms: machine learning, and, in particular, deep learning and language models. This review discusses how each of these AI paradigms contributes to two core tasks in quantum systems characterization: quantum property prediction and the construction of surrogates for quantum states. These tasks underlie diverse applications, from quantum certification and benchmarking to the enhancement of quantum algorithms and the understanding of strongly correlated phases of matter. Key challenges and open questions are also discussed, together with future prospects at the interface of AI and quantum science. 

**Abstract (ZH)**: 大规模量子系统的高效表征，尤其是由量子模拟器和容量巨大的量子计算机生成的系统，由于希尔伯特空间的维数随系统规模的增加呈指数级增长而成为量子科学中的一个核心挑战。近年来，随着人工智能（AI）在高维模式识别和函数逼近领域的优势，AI 成为了应对这一挑战的强大工具。越来越多的研究利用 AI 表征和表征可扩展的量子系统，涵盖了从理论基础到实验实现的各个方面。根据先验知识和学习架构的融合方式，AI 在量子系统表征中的集成可以被归类为三个互补的范式：机器学习，特别是深度学习和语言模型。本文综述了这些 AI 范式如何有助于量子系统表征中的两个核心任务：量子性质预测以及量子态的代理构造。这些任务涵盖了从量子认证和基准测试到量子算法的提升以及凝聚态强相关相的理解等多种应用。同时，本文还讨论了关键挑战、开放问题以及 AI 与量子科学交叉领域中的未来前景。 

---
# The Paradox of Doom: Acknowledging Extinction Risk Reduces the Incentive to Prevent It 

**Title (ZH)**: 绝境悖论：承认灭绝风险会降低预防其发生的动力 

**Authors**: Jakub Growiec, Klaus Prettner  

**Link**: [PDF](https://arxiv.org/pdf/2509.04855)  

**Abstract**: We investigate the salience of extinction risk as a source of impatience. Our framework distinguishes between human extinction risk and individual mortality risk while allowing for various degrees of intergenerational altruism. Additionally, we consider the evolutionarily motivated "selfish gene" perspective. We find that the risk of human extinction is an indispensable component of the discount rate, whereas individual mortality risk can be hedged against - partially or fully, depending on the setup - through human reproduction. Overall, we show that in the face of extinction risk, people become more impatient rather than more farsighted. Thus, the greater the threat of extinction, the less incentive there is to invest in avoiding it. Our framework can help explain why humanity consistently underinvests in mitigation of catastrophic risks, ranging from climate change mitigation, via pandemic prevention, to addressing the emerging risks of transformative artificial intelligence. 

**Abstract (ZH)**: 我们探讨灭绝风险作为不耐缘由的显著性。我们的框架区分了人类灭绝风险和个体死亡风险，同时允许不同程度的代际利他主义。此外，我们还考虑了进化动机下的“自私基因”观点。我们发现人类灭绝风险是贴现率不可或缺的组成部分，而个体死亡风险可以通过人类繁殖部分地或完全地对冲。总体而言，我们展示，在面对灭绝风险时，人们变得更加不耐而不是更加有远见。因此，灭绝威胁越大，避免其发生的激励就越低。我们的框架有助于解释为何人类在从气候变化缓解到 pandemic 防控再到应对转变性人工智能带来的新兴风险等各类灾难性风险的缓解方面持续投入不足。 

---
# AI-Driven Fronthaul Link Compression in Wireless Communication Systems: Review and Method Design 

**Title (ZH)**: 基于AI驱动的前传链路压缩在无线通信系统中的研究与方法设计 

**Authors**: Keqin Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2509.04805)  

**Abstract**: Modern fronthaul links in wireless systems must transport high-dimensional signals under stringent bandwidth and latency constraints, which makes compression indispensable. Traditional strategies such as compressed sensing, scalar quantization, and fixed-codec pipelines often rely on restrictive priors, degrade sharply at high compression ratios, and are hard to tune across channels and deployments. Recent progress in Artificial Intelligence (AI) has brought end-to-end learned transforms, vector and hierarchical quantization, and learned entropy models that better exploit the structure of Channel State Information(CSI), precoding matrices, I/Q samples, and LLRs. This paper first surveys AI-driven compression techniques and then provides a focused analysis of two representative high-compression routes: CSI feedback with end-to-end learning and Resource Block (RB) granularity precoding optimization combined with compression. Building on these insights, we propose a fronthaul compression strategy tailored to cell-free architectures. The design targets high compression with controlled performance loss, supports RB-level rate adaptation, and enables low-latency inference suitable for centralized cooperative transmission in next-generation networks. 

**Abstract (ZH)**: 现代无线系统中的前传链路必须在严格的带宽和延迟约束下传输高维信号，这使得压缩变得必不可少。最近人工智能的进步带来了端到端学习变换、向量和分层量化以及学习熵模型，这些技术更好地利用了信道状态信息(CSI)、预编码矩阵、I/Q样本和Log-Likelihood Ratios (LLRs) 的结构。本文首先概述了基于AI的压缩技术，然后重点分析了两种高压缩率路线：基于端到端学习的信道状态信息反馈和基于压缩的资源块粒度预编码优化。基于这些见解，我们提出了一种适用于无蜂窝架构的前传压缩策略，该策略旨在实现高压缩率的同时控制性能损失、支持资源块级别速率自适应，并且适用于下一代网络中集中协作传输的低延迟推理。 

---
# Graph Unlearning: Efficient Node Removal in Graph Neural Networks 

**Title (ZH)**: 图去学习：图神经网络中的高效节点移除 

**Authors**: Faqian Guan, Tianqing Zhu, Zhoutian Wang, Wei Ren, Wanlei Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2509.04785)  

**Abstract**: With increasing concerns about privacy attacks and potential sensitive information leakage, researchers have actively explored methods to efficiently remove sensitive training data and reduce privacy risks in graph neural network (GNN) models. Node unlearning has emerged as a promising technique for protecting the privacy of sensitive nodes by efficiently removing specific training node information from GNN models. However, existing node unlearning methods either impose restrictions on the GNN structure or do not effectively utilize the graph topology for node unlearning. Some methods even compromise the graph's topology, making it challenging to achieve a satisfactory performance-complexity trade-off. To address these issues and achieve efficient unlearning for training node removal in GNNs, we propose three novel node unlearning methods: Class-based Label Replacement, Topology-guided Neighbor Mean Posterior Probability, and Class-consistent Neighbor Node Filtering. Among these methods, Topology-guided Neighbor Mean Posterior Probability and Class-consistent Neighbor Node Filtering effectively leverage the topological features of the graph, resulting in more effective node unlearning. To validate the superiority of our proposed methods in node unlearning, we conducted experiments on three benchmark datasets. The evaluation criteria included model utility, unlearning utility, and unlearning efficiency. The experimental results demonstrate the utility and efficiency of the proposed methods and illustrate their superiority compared to state-of-the-art node unlearning methods. Overall, the proposed methods efficiently remove sensitive training nodes and protect the privacy information of sensitive nodes in GNNs. The findings contribute to enhancing the privacy and security of GNN models and provide valuable insights into the field of node unlearning. 

**Abstract (ZH)**: 随着对隐私攻击和潜在敏感信息泄露的担忧不断增加，研究人员积极探索高效移除敏感训练数据并在图神经网络（GNN）模型中减少隐私风险的方法。基于类别的标签替换、拓扑导向的邻居均值后验概率以及类别一致的邻居节点过滤已作为保护敏感节点隐私的有效技术 emerge。然而，现有的节点遗忘方法要么限制了GNN结构，要么未能有效利用图的拓扑结构进行节点遗忘。一些方法甚至破坏了图的拓扑结构，使得难以实现性能与复杂度的最佳Trade-off。为解决这些问题并实现GNN中训练节点移除的高效遗忘，我们提出了三种新颖的节点遗忘方法：基于类别的标签替换、拓扑导向的邻居均值后验概率以及类别一致的邻居节点过滤。在这些方法中，拓扑导向的邻居均值后验概率和类别一致的邻居节点过滤有效地利用了图的拓扑特征，从而提高了节点遗忘效果。为了验证我们提出的方法在节点遗忘上的优越性，我们在三个基准数据集上进行了实验。评估标准包括模型效用、遗忘效用和遗忘效率。实验结果表明，我们提出的方法具有实用性和高效性，并且在与现有的最先进的节点遗忘方法相比时显示出优越性。总之，我们提出的方法能够高效地移除敏感训练节点并保护GNN中敏感节点的隐私信息。研究结果有助于增强GNN模型的隐私和安全性，并为节点遗忘领域的研究提供了宝贵的见解。 

---
# VARMA-Enhanced Transformer for Time Series Forecasting 

**Title (ZH)**: 基于VARMA增强的变换器模型用于时间序列预测 

**Authors**: Jiajun Song, Xiaoou Liu  

**Link**: [PDF](https://arxiv.org/pdf/2509.04782)  

**Abstract**: Transformer-based models have significantly advanced time series forecasting. Recent work, like the Cross-Attention-only Time Series transformer (CATS), shows that removing self-attention can make the model more accurate and efficient. However, these streamlined architectures may overlook the fine-grained, local temporal dependencies effectively captured by classical statistical models like Vector AutoRegressive Moving Average model (VARMA). To address this gap, we propose VARMAformer, a novel architecture that synergizes the efficiency of a cross-attention-only framework with the principles of classical time series analysis. Our model introduces two key innovations: (1) a dedicated VARMA-inspired Feature Extractor (VFE) that explicitly models autoregressive (AR) and moving-average (MA) patterns at the patch level, and (2) a VARMA-Enhanced Attention (VE-atten) mechanism that employs a temporal gate to make queries more context-aware. By fusing these classical insights into a modern backbone, VARMAformer captures both global, long-range dependencies and local, statistical structures. Through extensive experiments on widely-used benchmark datasets, we demonstrate that our model consistently outperforms existing state-of-the-art methods. Our work validates the significant benefit of integrating classical statistical insights into modern deep learning frameworks for time series forecasting. 

**Abstract (ZH)**: 基于Transformer的模型显著推进了时间序列预测。 recent work, like the Cross-Attention-only Time Series Transformer (CATS), 表明移除自我注意可以使模型更准确和高效。然而，这些精简的架构可能会忽略经典统计模型如向量自回归移动平均模型（VARMA）有效捕捉的细粒度局部时间依赖性。为了弥补这一差距，我们提出VARMAformer，这是一种将交叉注意框架的效率与经典时间序列分析原则相结合的新架构。我们的模型引入了两项关键创新：（1）一个专门的由VARMA启发的功能抽取器（VFE），用于在块级别明确建模自回归（AR）和移动平均（MA）模式，以及（2）一个增强的VARMA注意机制（VE-atten），该机制使用时间门控使查询更具上下文意识。通过将这些经典见解融合到现代骨干网络中，VARMAformer可以捕捉到全局、长距离依赖性和局部、统计结构。通过在广泛使用的基准数据集上进行大量实验，我们证明我们的模型在现有的最先进的方法上表现出持续的优越性。我们的研究表明，将经典统计洞察集成到现代深度学习框架中，对于时间序列预测具有显著的好处。 

---
# Beyond I-Con: Exploring New Dimension of Distance Measures in Representation Learning 

**Title (ZH)**: 超越I-Con：探索表示学习中距离度量的新维度 

**Authors**: Jasmine Shone, Shaden Alshammari, Mark Hamilton, Zhening Li, William Freeman  

**Link**: [PDF](https://arxiv.org/pdf/2509.04734)  

**Abstract**: The Information Contrastive (I-Con) framework revealed that over 23 representation learning methods implicitly minimize KL divergence between data and learned distributions that encode similarities between data points. However, a KL-based loss may be misaligned with the true objective, and properties of KL divergence such as asymmetry and unboundedness may create optimization challenges. We present Beyond I-Con, a framework that enables systematic discovery of novel loss functions by exploring alternative statistical divergences and similarity kernels. Key findings: (1) on unsupervised clustering of DINO-ViT embeddings, we achieve state-of-the-art results by modifying the PMI algorithm to use total variation (TV) distance; (2) on supervised contrastive learning, we outperform the standard approach by using TV and a distance-based similarity kernel instead of KL and an angular kernel; (3) on dimensionality reduction, we achieve superior qualitative results and better performance on downstream tasks than SNE by replacing KL with a bounded f-divergence. Our results highlight the importance of considering divergence and similarity kernel choices in representation learning optimization. 

**Abstract (ZH)**: Beyond I-Con：通过探索替代统计散度和相似内核系统发现新型损失函数 

---
# CoVeR: Conformal Calibration for Versatile and Reliable Autoregressive Next-Token Prediction 

**Title (ZH)**: CoVeR：适应性校准以实现多功能可靠的自回归下一个词预测 

**Authors**: Yuzhu Chen, Yingjie Wang, Shunyu Liu, Yongcheng Jing, Dacheng Tao  

**Link**: [PDF](https://arxiv.org/pdf/2509.04733)  

**Abstract**: Autoregressive pre-trained models combined with decoding methods have achieved impressive performance on complex reasoning tasks. While mainstream decoding strategies such as beam search can generate plausible candidate sets, they often lack provable coverage guarantees, and struggle to effectively balance search efficiency with the need for versatile trajectories, particularly those involving long-tail sequences that are essential in certain real-world applications. To address these limitations, we propose \textsc{CoVeR}, a novel model-free decoding strategy wihtin the conformal prediction framework that simultaneously maintains a compact search space and ensures high coverage probability over desirable trajectories. Theoretically, we establish a PAC-style generalization bound, guaranteeing that \textsc{CoVeR} asymptotically achieves a coverage rate of at least $1 - \alpha$ for any target level $\alpha \in (0,1)$. 

**Abstract (ZH)**: 自回归预训练模型结合解码方法已在复杂推理任务中取得了显著成效。然而，主流解码策略如束搜索虽然能够生成合理的候选集，但往往缺乏可证明的覆盖保证，并且在平衡搜索效率与灵活轨迹需求方面存在问题，尤其是涉及某些现实生活应用中必不可少的长尾序列。为解决这些问题，我们提出了\textsc{CoVeR}，一种在符合性预测框架内的新型模型无关解码策略，该策略能够同时保持紧凑的搜索空间并确保对优选轨迹的高覆盖概率。理论上，我们建立了类似PAC的泛化界，保证\textsc{CoVeR}在任何目标水平$\alpha \in (0,1)$下能够渐近地实现至少$1 - \alpha$的覆盖率。 

---
# Ecologically Valid Benchmarking and Adaptive Attention: Scalable Marine Bioacoustic Monitoring 

**Title (ZH)**: 生态有效的基准测试与自适应注意力：可扩展的海洋生物声学监测 

**Authors**: Nicholas R. Rasmussen, Rodrigue Rizk, Longwei Wang, KC Santosh  

**Link**: [PDF](https://arxiv.org/pdf/2509.04682)  

**Abstract**: Underwater Passive Acoustic Monitoring (UPAM) provides rich spatiotemporal data for long-term ecological analysis, but intrinsic noise and complex signal dependencies hinder model stability and generalization. Multilayered windowing has improved target sound localization, yet variability from shifting ambient noise, diverse propagation effects, and mixed biological and anthropogenic sources demands robust architectures and rigorous evaluation. We introduce GetNetUPAM, a hierarchical nested cross-validation framework designed to quantify model stability under ecologically realistic variability. Data are partitioned into distinct site-year segments, preserving recording heterogeneity and ensuring each validation fold reflects a unique environmental subset, reducing overfitting to localized noise and sensor artifacts. Site-year blocking enforces evaluation against genuine environmental diversity, while standard cross-validation on random subsets measures generalization across UPAM's full signal distribution, a dimension absent from current benchmarks. Using GetNetUPAM as the evaluation backbone, we propose the Adaptive Resolution Pooling and Attention Network (ARPA-N), a neural architecture for irregular spectrogram dimensions. Adaptive pooling with spatial attention extends the receptive field, capturing global context without excessive parameters. Under GetNetUPAM, ARPA-N achieves a 14.4% gain in average precision over DenseNet baselines and a log2-scale order-of-magnitude drop in variability across all metrics, enabling consistent detection across site-year folds and advancing scalable, accurate bioacoustic monitoring. 

**Abstract (ZH)**: 基于生态现实变异性的一种分层嵌套交叉验证框架：GetNetUPAM 

---
# Evaluating NL2SQL via SQL2NL 

**Title (ZH)**: 通过SQL2NL评估NL2SQL 

**Authors**: Mohammadtaher Safarzadeh, Afshin Oroojlooyjadid, Dan Roth  

**Link**: [PDF](https://arxiv.org/pdf/2509.04657)  

**Abstract**: Robust evaluation in the presence of linguistic variation is key to understanding the generalization capabilities of Natural Language to SQL (NL2SQL) models, yet existing benchmarks rarely address this factor in a systematic or controlled manner. We propose a novel schema-aligned paraphrasing framework that leverages SQL-to-NL (SQL2NL) to automatically generate semantically equivalent, lexically diverse queries while maintaining alignment with the original schema and intent. This enables the first targeted evaluation of NL2SQL robustness to linguistic variation in isolation-distinct from prior work that primarily investigates ambiguity or schema perturbations. Our analysis reveals that state-of-the-art models are far more brittle than standard benchmarks suggest. For example, LLaMa3.3-70B exhibits a 10.23% drop in execution accuracy (from 77.11% to 66.9%) on paraphrased Spider queries, while LLaMa3.1-8B suffers an even larger drop of nearly 20% (from 62.9% to 42.5%). Smaller models (e.g., GPT-4o mini) are disproportionately affected. We also find that robustness degradation varies significantly with query complexity, dataset, and domain -- highlighting the need for evaluation frameworks that explicitly measure linguistic generalization to ensure reliable performance in real-world settings. 

**Abstract (ZH)**: 一种基于模式对齐的同义句生成框架：在语言变异性存在下稳健评估自然语言到SQL模型的能力 

---
# Interpreting Transformer Architectures as Implicit Multinomial Regression 

**Title (ZH)**: 将变压器架构解释为隐式多项式回归 

**Authors**: Jonas A. Actor, Anthony Gruber, Eric C. Cyr  

**Link**: [PDF](https://arxiv.org/pdf/2509.04653)  

**Abstract**: Mechanistic interpretability aims to understand how internal components of modern machine learning models, such as weights, activations, and layers, give rise to the model's overall behavior. One particularly opaque mechanism is attention: despite its central role in transformer models, its mathematical underpinnings and relationship to concepts like feature polysemanticity, superposition, and model performance remain poorly understood. This paper establishes a novel connection between attention mechanisms and multinomial regression. Specifically, we show that in a fixed multinomial regression setting, optimizing over latent features yields optimal solutions that align with the dynamics induced by attention blocks. In other words, the evolution of representations through a transformer can be interpreted as a trajectory that recovers the optimal features for classification. 

**Abstract (ZH)**: 机制可解释性旨在理解现代机器学习模型内部组件，如权重、激活和层，如何导致模型整体行为。特别是，尽管注意力机制在变换器模型中扮演着核心角色，但其数学原理及其与特征多义性、超叠加和模型性能等概念的关系仍不甚明晰。本文建立了注意力机制与多项式回归之间的新型联系。具体而言，我们展示了在固定的多项式回归设置中，优化潜在特征可获得与注意力模块诱导的动力学相一致的最优解。换句话说，通过变换器演化表示的过程可以被解释为恢复分类最优特征的轨迹。 

---
# Comparative Analysis of Transformer Models in Disaster Tweet Classification for Public Safety 

**Title (ZH)**: 灾难推文分类以保障公共安全的变压器模型比较分析 

**Authors**: Sharif Noor Zisad, Ragib Hasan  

**Link**: [PDF](https://arxiv.org/pdf/2509.04650)  

**Abstract**: Twitter and other social media platforms have become vital sources of real time information during disasters and public safety emergencies. Automatically classifying disaster related tweets can help emergency services respond faster and more effectively. Traditional Machine Learning (ML) models such as Logistic Regression, Naive Bayes, and Support Vector Machines have been widely used for this task, but they often fail to understand the context or deeper meaning of words, especially when the language is informal, metaphorical, or ambiguous. We posit that, in this context, transformer based models can perform better than traditional ML models. In this paper, we evaluate the effectiveness of transformer based models, including BERT, DistilBERT, RoBERTa, and DeBERTa, for classifying disaster related tweets. These models are compared with traditional ML approaches to highlight the performance gap. Experimental results show that BERT achieved the highest accuracy (91%), significantly outperforming traditional models like Logistic Regression and Naive Bayes (both at 82%). The use of contextual embeddings and attention mechanisms allows transformer models to better understand subtle language in tweets, where traditional ML models fall short. This research demonstrates that transformer architectures are far more suitable for public safety applications, offering improved accuracy, deeper language understanding, and better generalization across real world social media text. 

**Abstract (ZH)**: 基于变压器模型在灾害相关推文分类中的有效性研究 

---
# Schema Inference for Tabular Data Repositories Using Large Language Models 

**Title (ZH)**: 使用大型语言模型进行表数据仓库的模式推理 

**Authors**: Zhenyu Wu, Jiaoyan Chen, Norman W. Paton  

**Link**: [PDF](https://arxiv.org/pdf/2509.04632)  

**Abstract**: Minimally curated tabular data often contain representational inconsistencies across heterogeneous sources, and are accompanied by sparse metadata. Working with such data is intimidating. While prior work has advanced dataset discovery and exploration, schema inference remains difficult when metadata are limited. We present SI-LLM (Schema Inference using Large Language Models), which infers a concise conceptual schema for tabular data using only column headers and cell values. The inferred schema comprises hierarchical entity types, attributes, and inter-type relationships. In extensive evaluation on two datasets from web tables and open data, SI-LLM achieves promising end-to-end results, as well as better or comparable results to state-of-the-art methods at each step. All source code, full prompts, and datasets of SI-LLM are available at this https URL. 

**Abstract (ZH)**: 最小程度加工的表格数据经常来自异构来源，并且伴随稀疏的元数据，处理这些数据令人望而生畏。尽管先前的工作已经在数据集的发现和探索方面取得了进展，但在元数据有限的情况下，模式推理仍然具有挑战性。我们提出了SI-LLM（基于大型语言模型的模式推理），仅使用列标题和单元格值来推断表格数据的概念模式。推断出的模式包括层次实体类型、属性以及类间关系。在对两个来自网络表格和开放数据集的广泛评估中，SI-LLM 达到了令人鼓舞的整体效果，并且在每个步骤上取得了与最新方法相当甚至更好的结果。SI-LLM 的所有源代码、完整提示和数据集均可在以下链接获取：这个 https URL。 

---
# Measuring the Measures: Discriminative Capacity of Representational Similarity Metrics Across Model Families 

**Title (ZH)**: 测量方法的测量能力：不同模型家族代表相似性指标的判别能力 

**Authors**: Jialin Wu, Shreya Saha, Yiqing Bo, Meenakshi Khosla  

**Link**: [PDF](https://arxiv.org/pdf/2509.04622)  

**Abstract**: Representational similarity metrics are fundamental tools in neuroscience and AI, yet we lack systematic comparisons of their discriminative power across model families. We introduce a quantitative framework to evaluate representational similarity measures based on their ability to separate model families-across architectures (CNNs, Vision Transformers, Swin Transformers, ConvNeXt) and training regimes (supervised vs. self-supervised). Using three complementary separability measures-dprime from signal detection theory, silhouette coefficients and ROC-AUC, we systematically assess the discriminative capacity of commonly used metrics including RSA, linear predictivity, Procrustes, and soft matching. We show that separability systematically increases as metrics impose more stringent alignment constraints. Among mapping-based approaches, soft-matching achieves the highest separability, followed by Procrustes alignment and linear predictivity. Non-fitting methods such as RSA also yield strong separability across families. These results provide the first systematic comparison of similarity metrics through a separability lens, clarifying their relative sensitivity and guiding metric choice for large-scale model and brain comparisons. 

**Abstract (ZH)**: 基于分离能力量化评估表示相似性度量：从模型家族区分能力系统比较看不同类型相似性度量的相对敏感性及其在大规模模型和脑成像比较中的指导作用 

---
# Quantum-Enhanced Multi-Task Learning with Learnable Weighting for Pharmacokinetic and Toxicity Prediction 

**Title (ZH)**: 基于可学习权重的量子增强多任务学习在药代动力学与毒理学预测中的应用 

**Authors**: Han Zhang, Fengji Ma, Jiamin Su, Xinyue Yang, Lei Wang, Wen-Cai Ye, Li Liu  

**Link**: [PDF](https://arxiv.org/pdf/2509.04601)  

**Abstract**: Prediction for ADMET (Absorption, Distribution, Metabolism, Excretion, and Toxicity) plays a crucial role in drug discovery and development, accelerating the screening and optimization of new drugs. Existing methods primarily rely on single-task learning (STL), which often fails to fully exploit the complementarities between tasks. Besides, it requires more computational resources while training and inference of each task independently. To address these issues, we propose a new unified Quantum-enhanced and task-Weighted Multi-Task Learning (QW-MTL) framework, specifically designed for ADMET classification tasks. Built upon the Chemprop-RDKit backbone, QW-MTL adopts quantum chemical descriptors to enrich molecular representations with additional information about the electronic structure and interactions. Meanwhile, it introduces a novel exponential task weighting scheme that combines dataset-scale priors with learnable parameters to achieve dynamic loss balancing across tasks. To the best of our knowledge, this is the first work to systematically conduct joint multi-task training across all 13 Therapeutics Data Commons (TDC) classification benchmarks, using leaderboard-style data splits to ensure a standardized and realistic evaluation setting. Extensive experimental results show that QW-MTL significantly outperforms single-task baselines on 12 out of 13 tasks, achieving high predictive performance with minimal model complexity and fast inference, demonstrating the effectiveness and efficiency of multi-task molecular learning enhanced by quantum-informed features and adaptive task weighting. 

**Abstract (ZH)**: 量子增强和任务加权多任务学习在ADMET分类中的预测研究 

---
# Toward Faithfulness-guided Ensemble Interpretation of Neural Network 

**Title (ZH)**: 面向忠诚度引导的神经网络集成解释 

**Authors**: Siyu Zhang, Kenneth Mcmillan  

**Link**: [PDF](https://arxiv.org/pdf/2509.04588)  

**Abstract**: Interpretable and faithful explanations for specific neural inferences are crucial for understanding and evaluating model behavior. Our work introduces \textbf{F}aithfulness-guided \textbf{E}nsemble \textbf{I}nterpretation (\textbf{FEI}), an innovative framework that enhances the breadth and effectiveness of faithfulness, advancing interpretability by providing superior visualization. Through an analysis of existing evaluation benchmarks, \textbf{FEI} employs a smooth approximation to elevate quantitative faithfulness scores. Diverse variations of \textbf{FEI} target enhanced faithfulness in hidden layer encodings, expanding interpretability. Additionally, we propose a novel qualitative metric that assesses hidden layer faithfulness. In extensive experiments, \textbf{FEI} surpasses existing methods, demonstrating substantial advances in qualitative visualization and quantitative faithfulness scores. Our research establishes a comprehensive framework for elevating faithfulness in neural network explanations, emphasizing both breadth and precision 

**Abstract (ZH)**: Faithfulness-Guided Ensemble Interpretation (FEI): Enhancing Faithfulness and Interpretability in Neural Inferences 

---
# i-Mask: An Intelligent Mask for Breath-Driven Activity Recognition 

**Title (ZH)**: i-Mask: 一种基于呼吸驱动活动识别的智能面罩 

**Authors**: Ashutosh Kumar Sinha, Ayush Patel, Mitul Dudhat, Pritam Anand, Rahul Mishra  

**Link**: [PDF](https://arxiv.org/pdf/2509.04544)  

**Abstract**: The patterns of inhalation and exhalation contain important physiological signals that can be used to anticipate human behavior, health trends, and vital parameters. Human activity recognition (HAR) is fundamentally connected to these vital signs, providing deeper insights into well-being and enabling real-time health monitoring. This work presents i-Mask, a novel HAR approach that leverages exhaled breath patterns captured using a custom-developed mask equipped with integrated sensors. Data collected from volunteers wearing the mask undergoes noise filtering, time-series decomposition, and labeling to train predictive models. Our experimental results validate the effectiveness of the approach, achieving over 95\% accuracy and highlighting its potential in healthcare and fitness applications. 

**Abstract (ZH)**: 吸入和呼出的模式包含重要的生理信号，可用于预测人类行为、健康趋势和生命体征。呼吸活动识别（HAR）与这些生命体征密切相关，提供了对福祉的更深入洞察，并能够实现实时健康监测。本研究介绍了i-Mask，这是一种新颖的HAR方法，利用配备集成传感器的自开发口罩捕获的呼出呼吸模式。佩戴口罩的志愿者收集的数据经过噪声过滤、时间序列分解和标签处理以训练预测模型。我们的实验结果验证了该方法的有效性，准确率超过95%，并在医疗保健和健身应用中展示了其潜力。 

---
# Mitigation of Gender and Ethnicity Bias in AI-Generated Stories through Model Explanations 

**Title (ZH)**: 通过模型解释减轻AI生成故事中的性别和 Ethnicity 偏见 

**Authors**: Martha O. Dimgba, Sharon Oba, Ameeta Agrawal, Philippe J. Giabbanelli  

**Link**: [PDF](https://arxiv.org/pdf/2509.04515)  

**Abstract**: Language models have been shown to propagate social bias through their output, particularly in the representation of gender and ethnicity. This paper investigates gender and ethnicity biases in AI-generated occupational stories. Representation biases are measured before and after applying our proposed mitigation strategy, Bias Analysis and Mitigation through Explanation (BAME), revealing improvements in demographic representation ranging from 2% to 20%. BAME leverages model-generated explanations to inform targeted prompt engineering, effectively reducing biases without modifying model parameters. By analyzing stories generated across 25 occupational groups, three large language models (Claude 3.5 Sonnet, Llama 3.1 70B Instruct, and GPT-4 Turbo), and multiple demographic dimensions, we identify persistent patterns of overrepresentation and underrepresentation linked to training data stereotypes. Our findings demonstrate that guiding models with their own internal reasoning mechanisms can significantly enhance demographic parity, thereby contributing to the development of more transparent generative AI systems. 

**Abstract (ZH)**: 语言模型在其输出中表现出传播社会偏见的现象，特别是在性别和族裔的表示上。本文探讨了AI生成的职业故事中的性别和族裔偏见。我们通过应用提出的缓解策略“解释驱动的偏见分析与缓解”（BAME）来衡量表示偏见的变化，发现人口统计学表示的改进范围从2%到20%。BAME 利用模型生成的解释来指导目标提示工程，有效减少了偏见而不修改模型参数。通过分析25个职业群体生成的故事，以及三种大型语言模型（Claude 3.5 Sonnet、Llama 3.1 70B Instruct 和 GPT-4 Turbo）和多个人口统计学维度，我们识别出与训练数据刻板印象相关的持续存在的过度代表和不足代表模式。我们的研究结果表明，通过引导模型使用它们自己的内部推理机制，可以显著增强人口统计学平权，从而促进更透明的生成AI系统的开发。 

---
# Memristor-Based Neural Network Accelerators for Space Applications: Enhancing Performance with Temporal Averaging and SIRENs 

**Title (ZH)**: 基于 memristor 的神经网络加速器在空间应用中的增强：通过时间平均和 SIRENs 提升性能 

**Authors**: Zacharia A. Rudge, Dominik Dold, Moritz Fieback, Dario Izzo, Said Hamdioui  

**Link**: [PDF](https://arxiv.org/pdf/2509.04506)  

**Abstract**: Memristors are an emerging technology that enables artificial intelligence (AI) accelerators with high energy efficiency and radiation robustness -- properties that are vital for the deployment of AI on-board spacecraft. However, space applications require reliable and precise computations, while memristive devices suffer from non-idealities, such as device variability, conductance drifts, and device faults. Thus, porting neural networks (NNs) to memristive devices often faces the challenge of severe performance degradation. In this work, we show in simulations that memristor-based NNs achieve competitive performance levels on on-board tasks, such as navigation \& control and geodesy of asteroids. Through bit-slicing, temporal averaging of NN layers, and periodic activation functions, we improve initial results from around $0.07$ to $0.01$ and $0.3$ to $0.007$ for both tasks using RRAM devices, coming close to state-of-the-art levels ($0.003-0.005$ and $0.003$, respectively). Our results demonstrate the potential of memristors for on-board space applications, and we are convinced that future technology and NN improvements will further close the performance gap to fully unlock the benefits of memristors. 

**Abstract (ZH)**: 基于 memristor 的神经网络在星载任务中的竞争性能研究 

---
# A Narrative-Driven Computational Framework for Clinician Burnout Surveillance 

**Title (ZH)**: 基于叙事驱动的计算框架在医务人员倦怠监控中的应用 

**Authors**: Syed Ahmad Chan Bukhari, Fazel Keshtkar, Alyssa Meczkowska  

**Link**: [PDF](https://arxiv.org/pdf/2509.04497)  

**Abstract**: Clinician burnout poses a substantial threat to patient safety, particularly in high-acuity intensive care units (ICUs). Existing research predominantly relies on retrospective survey tools or broad electronic health record (EHR) metadata, often overlooking the valuable narrative information embedded in clinical notes. In this study, we analyze 10,000 ICU discharge summaries from MIMIC-IV, a publicly available database derived from the electronic health records of Beth Israel Deaconess Medical Center. The dataset encompasses diverse patient data, including vital signs, medical orders, diagnoses, procedures, treatments, and deidentified free-text clinical notes. We introduce a hybrid pipeline that combines BioBERT sentiment embeddings fine-tuned for clinical narratives, a lexical stress lexicon tailored for clinician burnout surveillance, and five-topic latent Dirichlet allocation (LDA) with workload proxies. A provider-level logistic regression classifier achieves a precision of 0.80, a recall of 0.89, and an F1 score of 0.84 on a stratified hold-out set, surpassing metadata-only baselines by greater than or equal to 0.17 F1 score. Specialty-specific analysis indicates elevated burnout risk among providers in Radiology, Psychiatry, and Neurology. Our findings demonstrate that ICU clinical narratives contain actionable signals for proactive well-being monitoring. 

**Abstract (ZH)**: 临床医生的 Burnout 对患者安全构成重大威胁，尤其是在高急性重症监护病房（ICUs）。现有研究主要依赖于回顾性调查工具或广泛电子健康记录（EHR）元数据，往往忽视了临床笔记中嵌入的宝贵叙述信息。在本研究中，我们分析了来自 Beth Israel Deaconess Medical Center 电子健康记录的公开数据库 MIMIC-IV 的 10,000 份 ICU 出院总结。该数据集涵盖了多种患者数据，包括生命体征、医疗指令、诊断、程序、治疗和去标识化的自由文本临床笔记。我们引入了一种结合 BioBERT 情感嵌入（针对临床叙述微调）、专为临床医生 Burnout 监控量身定制的词级压力词典，以及带有工作负荷代理的五主题潜在狄利克雷分配（LDA）的混合管道。在分层保留集中，提供者级别的逻辑回归分类器达到了 0.80 的精确度、0.89 的召回率和 0.84 的 F1 分数，超过了仅使用元数据的基线模型大于或等于 0.17 的 F1 分数。专科分析表明，放射科、精神病学和神经学专科提供者的 Burnout 风险更高。我们的研究结果表明，ICU 临床叙述包含可用于主动健康监测的有效信号。 

---
# Refining Transcripts With TV Subtitles by Prompt-Based Weakly Supervised Training of ASR 

**Title (ZH)**: 基于提示的弱监督训练改进ASR转录基于电视字幕 

**Authors**: Xinnian Zhao, Hugo Van Hamme  

**Link**: [PDF](https://arxiv.org/pdf/2509.04491)  

**Abstract**: This study proposes a novel approach to using TV subtitles within a weakly supervised (WS) Automatic Speech Recognition (ASR) framework. Although TV subtitles are readily available, their imprecise alignment with corresponding audio limits their applicability as supervised targets for verbatim transcription. Rather than using subtitles as direct supervision signals, our method reimagines them as context-rich prompts. This design enables the model to handle discrepancies between spoken audio and subtitle text. Instead, generated pseudo transcripts become the primary targets, with subtitles acting as guiding cues for iterative refinement. To further enhance the process, we introduce a weighted attention mechanism that emphasizes relevant subtitle tokens during inference. Our experiments demonstrate significant improvements in transcription accuracy, highlighting the effectiveness of the proposed method in refining transcripts. These enhanced pseudo-labeled datasets provide high-quality foundational resources for training robust ASR systems. 

**Abstract (ZH)**: 本研究提出了一种在弱监督（WS）自动语音识别（ASR）框架中使用电视字幕的新型方法。尽管电视字幕易于获取，但它们与对应音频的不精确对齐限制了其作为逐字转录监督目标的应用。本方法并非直接使用字幕作为监督信号，而是将它们重新想象为富含上下文的提示。这种设计使模型能够处理口语音频与字幕文本之间的差异。相反，生成的伪转录成为主要目标，而字幕则作为迭代细化的引导线索。为进一步增强此过程，我们引入了一种加权注意机制，在推断过程中强调相关的字幕词元。实验结果显示出显著的转录准确性提升，突显了所提出方法在转录细化中的有效性。这些增强的伪标注数据集提供了训练健壯ASR系统的高质量基础资源。 

---
# ASCENDgpt: A Phenotype-Aware Transformer Model for Cardiovascular Risk Prediction from Electronic Health Records 

**Title (ZH)**: ASCEND-GPT：一种基于表型的Transformer模型，用于电子健康记录的心血管风险预测 

**Authors**: Chris Sainsbury, Andreas Karwath  

**Link**: [PDF](https://arxiv.org/pdf/2509.04485)  

**Abstract**: We present ASCENDgpt, a transformer-based model specifically designed for cardiovascular risk prediction from longitudinal electronic health records (EHRs). Our approach introduces a novel phenotype-aware tokenization scheme that maps 47,155 raw ICD codes to 176 clinically meaningful phenotype tokens, achieving 99.6\% consolidation of diagnosis codes while preserving semantic information. This phenotype mapping contributes to a total vocabulary of 10,442 tokens - a 77.9\% reduction when compared with using raw ICD codes directly. We pretrain ASCENDgpt on sequences derived from 19402 unique individuals using a masked language modeling objective, then fine-tune for time-to-event prediction of five cardiovascular outcomes: myocardial infarction (MI), stroke, major adverse cardiovascular events (MACE), cardiovascular death, and all-cause mortality. Our model achieves excellent discrimination on the held-out test set with an average C-index of 0.816, demonstrating strong performance across all outcomes (MI: 0.792, stroke: 0.824, MACE: 0.800, cardiovascular death: 0.842, all-cause mortality: 0.824). The phenotype-based approach enables clinically interpretable predictions while maintaining computational efficiency. Our work demonstrates the effectiveness of domain-specific tokenization and pretraining for EHR-based risk prediction tasks. 

**Abstract (ZH)**: ASCENDgpt：一种基于变压器的心血管风险预测模型 

---
# The Good, the Bad and the Constructive: Automatically Measuring Peer Review's Utility for Authors 

**Title (ZH)**: 好的、坏的和建设性的：自动衡量同行评审对作者的价值 

**Authors**: Abdelrahman Sadallah, Tim Baumgärtner, Iryna Gurevych, Ted Briscoe  

**Link**: [PDF](https://arxiv.org/pdf/2509.04484)  

**Abstract**: Providing constructive feedback to paper authors is a core component of peer review. With reviewers increasingly having less time to perform reviews, automated support systems are required to ensure high reviewing quality, thus making the feedback in reviews useful for authors. To this end, we identify four key aspects of review comments (individual points in weakness sections of reviews) that drive the utility for authors: Actionability, Grounding & Specificity, Verifiability, and Helpfulness. To enable evaluation and development of models assessing review comments, we introduce the RevUtil dataset. We collect 1,430 human-labeled review comments and scale our data with 10k synthetically labeled comments for training purposes. The synthetic data additionally contains rationales, i.e., explanations for the aspect score of a review comment. Employing the RevUtil dataset, we benchmark fine-tuned models for assessing review comments on these aspects and generating rationales. Our experiments demonstrate that these fine-tuned models achieve agreement levels with humans comparable to, and in some cases exceeding, those of powerful closed models like GPT-4o. Our analysis further reveals that machine-generated reviews generally underperform human reviews on our four aspects. 

**Abstract (ZH)**: 提供建设性的反馈是同行评审的核心组成部分。随着评审者可用时间的减少，需要自动化支持系统来确保评审质量，从而使评审中的反馈对作者有用。为此，我们识别了四方面评审意见的关键要素，这些要素驱动作者的有用性：可操作性、依据与具体性、可验证性以及有用性。为了评估和开发评估评审意见的模型，我们引入了RevUtil数据集。我们收集了1,430个人工标注的评审意见，并通过10,000个合成标注的意见来扩展数据，用于训练目的。合成数据还包含了理由，即评审意见评分的解释。使用RevUtil数据集，我们对评估评审意见和生成理由的微调模型进行了基准测试。我们的实验表明，这些微调模型在某些方面与强大的封闭模型（如GPT-4o）相比，能够达到与人类相当的共识水平，甚至在某些情况下超越了它们。进一步的分析表明，机器生成的评审意见在我们定义的四个方面通常表现不如人工生成的评审意见。 

---
# Multiscale Graph Neural Network for Turbulent Flow-Thermal Prediction Around a Complex-Shaped Pin-Fin 

**Title (ZH)**: 复杂形貌针鳍周围湍流流动-热预测的多尺度图神经网络 

**Authors**: Riddhiman Raut, Evan M. Mihalko, Amrita Basak  

**Link**: [PDF](https://arxiv.org/pdf/2509.04463)  

**Abstract**: This study presents the development of a domain-responsive edge-aware multiscale Graph Neural Network for predicting steady, turbulent flow and thermal behavior in a two-dimensional channel containing arbitrarily shaped complex pin-fin geometries. The training dataset was constructed through an automated framework that integrated geometry generation, meshing, and flow-field solutions in ANSYS Fluent. The pin-fin geometry was parameterized using piecewise cubic splines, producing 1,000 diverse configurations through Latin Hypercube Sampling. Each simulation was converted into a graph structure, where nodes carried a feature vector containing spatial coordinates, a normalized streamwise position, one-hot boundary indicators, and a signed distance to the nearest boundary such as wall. This graph structure served as input to the newly developed Graph Neural Network, which was trained to predict temperature, velocity magnitude, and pressure at each node using data from ANSYS. The network predicted fields with outstanding accuracy, capturing boundary layers, recirculation, and the stagnation region upstream of the pin-fins while reducing wall time by 2-3 orders of magnitude. In conclusion, the novel graph neural network offered a fast and reliable surrogate for simulations in complex flow configurations. 

**Abstract (ZH)**: 本文提出了一种针对特定领域且具备边缘感知能力的多尺度图神经网络，用于预测含有任意复杂鼻突-pin鳍几何结构的二维通道中的稳定湍流流动和热行为。训练数据集通过结合ANSYS Fluent中的几何生成、网格划分和流场求解的自动化框架构建。鼻突-pin鳍几何结构使用分段三次样条进行参数化，通过拉丁超立方抽样生成了1,000种不同的配置。每次模拟被转换为图结构，其中节点携带包含空间坐标、归一化的来流方向位置、边界指示符和到最近边界的符号距离等特征向量。该图结构作为新开发的图神经网络的输入，该网络被训练用于使用ANSYS数据预测每个节点的温度、速度大小和压力。该网络预测的场具有出色的准确性，能够捕捉边界层、再循环区域以及鼻突上游的停滞区域，同时将所需的时间缩短了2到3个数量级。总之，新的图神经网络为复杂流动配置下的模拟提供了一种快速且可靠的代理模型。 

---
