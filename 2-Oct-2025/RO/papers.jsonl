{'arxiv_id': 'arXiv:2510.01138', 'title': 'Real-Time Trajectory Generation and Hybrid Lyapunov-Based Control for Hopping Robots', 'authors': 'Matthew Woodward', 'link': 'https://arxiv.org/abs/2510.01138', 'abstract': 'The advent of rotor-based hopping robots has created very capable hopping platforms with high agility and efficiency, and similar controllability, as compared to their purely flying quadrotor counterparts. Advances in robot performance have increased the hopping height to greater than 4 meters and opened up the possibility for more complex aerial trajectories (i.e., behaviors). However, currently hopping robots do not directly control their aerial trajectory or transition to flight, eliminating the efficiency benefits of a hopping system. Here we show a real-time, computationally efficiency, non-linear drag compensated, trajectory generation methodology and accompanying Lyapunov-based controller. The combined system can create and follow complex aerial trajectories from liftoff to touchdown on horizontal and vertical surfaces, while maintaining strick control over the orientation at touchdown. The computational efficiency provides broad applicability across all size scales of hopping robots while maintaining applicability to quadrotors in general.', 'abstract_zh': '基于转子的跳行机器人的发展创造了一类极具敏捷性和效率的跳行平台，其可控性与纯飞行四旋翼机器人相当。机器人性能的进步使得跳跃高度超过4米，并为更复杂的空中轨迹（即行为）提供了可能性。然而，当前的跳行机器人并未直接控制其空中轨迹或过渡到飞行状态，从而消除了跳行系统的效率优势。我们展示了实时的、计算效率高的、基于非线性阻力补偿的轨迹生成方法及其配套的李雅普诺夫基于的控制器。该联合系统能够在水平和垂直表面从离地到着陆的过程中生成并遵循复杂的空中轨迹，同时严格控制着陆姿态。计算效率使得该方法适用于所有规模的跳行机器人，并普遍适用于四旋翼机器人。', 'title_zh': '实时轨迹生成与跳跃机器人基于混合李雅普诺夫的控制方法'}
{'arxiv_id': 'arXiv:2510.01068', 'title': 'Compose Your Policies! Improving Diffusion-based or Flow-based Robot Policies via Test-time Distribution-level Composition', 'authors': 'Jiahang Cao, Yize Huang, Hanzhong Guo, Rui Zhang, Mu Nan, Weijian Mai, Jiaxu Wang, Hao Cheng, Jingkai Sun, Gang Han, Wen Zhao, Qiang Zhang, Yijie Guo, Qihao Zheng, Chunfeng Song, Xiao Li, Ping Luo, Andrew F. Luo', 'link': 'https://arxiv.org/abs/2510.01068', 'abstract': 'Diffusion-based models for robotic control, including vision-language-action (VLA) and vision-action (VA) policies, have demonstrated significant capabilities. Yet their advancement is constrained by the high cost of acquiring large-scale interaction datasets. This work introduces an alternative paradigm for enhancing policy performance without additional model training. Perhaps surprisingly, we demonstrate that the composed policies can exceed the performance of either parent policy. Our contribution is threefold. First, we establish a theoretical foundation showing that the convex composition of distributional scores from multiple diffusion models can yield a superior one-step functional objective compared to any individual score. A Grönwall-type bound is then used to show that this single-step improvement propagates through entire generation trajectories, leading to systemic performance gains. Second, motivated by these results, we propose General Policy Composition (GPC), a training-free method that enhances performance by combining the distributional scores of multiple pre-trained policies via a convex combination and test-time search. GPC is versatile, allowing for the plug-and-play composition of heterogeneous policies, including VA and VLA models, as well as those based on diffusion or flow-matching, irrespective of their input visual modalities. Third, we provide extensive empirical validation. Experiments on Robomimic, PushT, and RoboTwin benchmarks, alongside real-world robotic evaluations, confirm that GPC consistently improves performance and adaptability across a diverse set of tasks. Further analysis of alternative composition operators and weighting strategies offers insights into the mechanisms underlying the success of GPC. These results establish GPC as a simple yet effective method for improving control performance by leveraging existing policies.', 'abstract_zh': '基于扩散的机器人控制模型，包括视觉-语言-动作（VLA）和视觉-动作（VA）策略，已经显示出显著的能力。然而，它们的发展受到大规模交互数据集获取成本高的限制。本文介绍了一种无需额外模型训练即可提高策略性能的替代范式。令人大吃一惊的是，我们证明组合策略的性能可以超过任何一个父策略的性能。我们的贡献有三个方面。首先，我们建立了理论基础，证明从多个扩散模型中得出的分布分数的凸组合可以提供优于任何单一分数的一步功能性目标。然后使用Grönwall型界来证明这种一步改进在整个生成轨迹中传播，从而导致系统性能提升。其次，受这些结果的启发，我们提出了通用策略组合（GPC），这是一种无需训练的方法，通过凸组合多个预训练策略的分布分数并在测试时进行搜索来提升性能。GPC非常灵活，允许异构策略，包括VA和VLA模型，以及基于扩散或流匹配的模型，无论它们的视觉输入模态如何。第三，我们进行了广泛的实证验证。在Robomimic、PushT和RoboTwin基准测试以及真实的机器人评估中，实验结果证实GPC在各种任务中一致地提高了性能和适应性。进一步分析不同的组合操作符和权重策略提供了关于GPC成功机制的见解。这些结果确立了GPC是一种通过利用现有策略来提高控制性能的简单而有效的方法。', 'title_zh': '生成您的策略！通过测试时分布级组合改进基于扩散或流的机器人策略'}
{'arxiv_id': 'arXiv:2510.01041', 'title': 'ROSplane 2.0: A Fixed-Wing Autopilot for Research', 'authors': 'Ian Reid, Joseph Ritchie, Jacob Moore, Brandon Sutherland, Gabe Snow, Phillip Tokumaru, Tim McLain', 'link': 'https://arxiv.org/abs/2510.01041', 'abstract': "Unmanned aerial vehicle (UAV) research requires the integration of cutting-edge technology into existing autopilot frameworks. This process can be arduous, requiring extensive resources, time, and detailed knowledge of the existing system. ROSplane is a lean, open-source fixed-wing autonomy stack built by researchers for researchers. It is designed to accelerate research by providing clearly defined interfaces with an easily modifiable framework. Powered by ROS 2, ROSplane allows for rapid integration of low or high-level control, path planning, or estimation algorithms. A focus on lean, easily understood code and extensive documentation lowers the barrier to entry for researchers. Recent developments to ROSplane improve its capacity to accelerate UAV research, including the transition from ROS 1 to ROS 2, enhanced estimation and control algorithms, increased modularity, and an improved aerodynamic modeling pipeline. This aerodynamic modeling pipeline significantly reduces the effort of transitioning from simulation to real-world testing without requiring expensive system identification or computational fluid dynamics tools. ROSplane's architecture reduces the effort required to integrate new research tools and methods, expediting hardware experimentation.", 'abstract_zh': '无人航空器（UAV）研究需要将前沿技术整合到现有的自主飞行框架中。这一过程可能极为繁琐，需要大量的资源、时间和对现有系统详细的了解。ROSplane是由研究者为研究者设计的轻量级、开源固定翼自主飞行堆栈。它旨在通过提供明确定义的接口和易于修改的框架加速研究。基于ROS 2，ROSplane允许快速集成低层或高层控制、路径规划或估计算法。简洁易懂的代码焦点和详尽的文档降低了研究者的入门门槛。ROSplane的最新发展使其加速无人航空器研究的能力得到了提高，包括从ROS 1过渡到ROS 2、增强的估计算法和控制算法、增加的模块化程度以及改进的气动建模流程。这一气动建模流程显著减少了从仿真过渡到实际测试所需的努力，而无需依赖昂贵的系统辨识或计算流体动力学工具。ROSplane的架构降低了集成新研究工具和方法所需的努力，加速了硬件实验。', 'title_zh': 'ROSplane 2.0：一种用于研究的固定翼自动驾驶仪'}
{'arxiv_id': 'arXiv:2510.01023', 'title': 'Prometheus: Universal, Open-Source Mocap-Based Teleoperation System with Force Feedback for Dataset Collection in Robot Learning', 'authors': 'S. Satsevich, A. Bazhenov, S. Egorov, A. Erkhov, M. Gromakov, A. Fedoseev, D. Tsetserukou', 'link': 'https://arxiv.org/abs/2510.01023', 'abstract': 'This paper presents a novel teleoperation system with force feedback, utilizing consumer-grade HTC Vive Track- ers 2.0. The system integrates a custom-built controller, a UR3 robotic arm, and a Robotiq gripper equipped with custom- designed fingers to ensure uniform pressure distribution on an embedded force sensor. Real-time compression force data is transmitted to the controller, enabling operators to perceive the gripping force applied to objects. Experimental results demonstrate that the system enhances task success rates and provides a low-cost solution for large-scale imitation learning data collection without compromising affordability.', 'abstract_zh': '基于HTC Vive Tracker 2.0的新型力反馈远程操控系统及其在大规模模仿学习数据收集中的应用', 'title_zh': '普罗米修斯：基于运动捕捉的开放式源码力反馈遥操作系统及其在机器人学习数据集收集中的应用'}
{'arxiv_id': 'arXiv:2510.00995', 'title': 'ROSflight 2.0: Lean ROS 2-Based Autopilot for Unmanned Aerial Vehicles', 'authors': 'Jacob Moore, Phil Tokumaru, Ian Reid, Brandon Sutherland, Joseph Ritchie, Gabe Snow, Tim McLain', 'link': 'https://arxiv.org/abs/2510.00995', 'abstract': 'ROSflight is a lean, open-source autopilot ecosystem for unmanned aerial vehicles (UAVs). Designed by researchers for researchers, it is built to lower the barrier to entry to UAV research and accelerate the transition from simulation to hardware experiments by maintaining a lean (not full-featured), well-documented, and modular codebase. This publication builds on previous treatments and describes significant additions to the architecture that improve the modularity and usability of ROSflight, including the transition from ROS 1 to ROS 2, supported hardware, low-level actuator mixing, and the simulation environment. We believe that these changes improve the usability of ROSflight and enable ROSflight to accelerate research in areas like advanced-air mobility. Hardware results are provided, showing that ROSflight is able to control a multirotor over a serial connection at 400 Hz while closing all control loops on the companion computer.', 'abstract_zh': 'ROSflight是面向无人飞行器（UAV）的一种精简的开源自主飞行生态系统。该系统由研究人员为研究目的设计，旨在通过提供精简（非全功能）、文档齐全且模块化的代码库来降低无人飞行器研究的门槛，并加速从仿真到硬件实验的过渡。本研究在此前研究的基础上，描述了对ROSflight架构的重大改进，这些改进增强了模块化和易用性，包括从ROS 1过渡到ROS 2、支持的硬件、低级执行器混合以及仿真环境。我们相信这些变化提高了ROSflight的易用性，并使ROSflight能够加速诸如高级空中移动性等领域的研究。试验结果表明，ROSflight能够在串行连接下以400 Hz的频率控制多旋翼，并在伴侣计算机上闭合所有控制回路。', 'title_zh': 'ROSflight 2.0: 基于ROS 2的轻量级无人驾驶飞行器自主飞行控制系统'}
{'arxiv_id': 'arXiv:2510.00942', 'title': 'Non-submodular Visual Attention for Robot Navigation', 'authors': 'Reza Vafaee, Kian Behzad, Milad Siami, Luca Carlone, Ali Jadbabaie', 'link': 'https://arxiv.org/abs/2510.00942', 'abstract': 'This paper presents a task-oriented computational framework to enhance Visual-Inertial Navigation (VIN) in robots, addressing challenges such as limited time and energy resources. The framework strategically selects visual features using a Mean Squared Error (MSE)-based, non-submodular objective function and a simplified dynamic anticipation model. To address the NP-hardness of this problem, we introduce four polynomial-time approximation algorithms: a classic greedy method with constant-factor guarantees; a low-rank greedy variant that significantly reduces computational complexity; a randomized greedy sampler that balances efficiency and solution quality; and a linearization-based selector based on a first-order Taylor expansion for near-constant-time execution. We establish rigorous performance bounds by leveraging submodularity ratios, curvature, and element-wise curvature analyses. Extensive experiments on both standardized benchmarks and a custom control-aware platform validate our theoretical results, demonstrating that these methods achieve strong approximation guarantees while enabling real-time deployment.', 'abstract_zh': '本文提出一种任务导向的计算框架，以增强机器人的视觉-惯性导航（VIN），应对时间与能量资源有限的挑战。该框架使用基于均方误差（MSE）的非子模函数和简化动态预估模型策略性地选择视觉特征。为解决该问题的NP难性，我们引入了四种多项式时间近似算法：经典具有常数因子保证的贪婪方法；一种低秩贪婪变体，显著降低计算复杂度；一种随机贪婪采样器，平衡效率与解的质量；以及基于一阶泰勒展开的线性化选择器，实现接近常数时间执行。通过利用子模比、曲率及元素曲率分析，我们严格建立了性能界。在标准化基准和自定义控制感知平台上的广泛实验验证了理论结果，表明这些方法不仅能获得强近似保证，还能实现实时部署。', 'title_zh': '非子模态视觉注意力用于机器人导航'}
{'arxiv_id': 'arXiv:2510.00933', 'title': 'Product-oriented Product-Process-Resource Asset Network and its Representation in AutomationML for Asset Administration Shell', 'authors': 'Sara Strakosova, Petr Novak, Petr Kadera', 'link': 'https://arxiv.org/abs/2510.00933', 'abstract': 'Current products, especially in the automotive sector, pose complex technical systems having a multi-disciplinary mechatronic nature. Industrial standards supporting system engineering and production typically (i) address the production phase only, but do not cover the complete product life cycle, and (ii) focus on production processes and resources rather than the products themselves. The presented approach is motivated by incorporating impacts of end-of-life phase of the product life cycle into the engineering phase. This paper proposes a modelling approach coming up from the Product-Process-Resource (PPR) modeling paradigm. It combines requirements on (i) respecting the product structure as a basis for the model, and (ii) it incorporates repairing, remanufacturing, or upcycling within cyber-physical production systems. The proposed model called PoPAN should accompany the product during the entire life cycle as a digital shadow encapsulated within the Asset Administration Shell of a product. To facilitate the adoption of the proposed paradigm, the paper also proposes serialization of the model in the AutomationML data format. The model is demonstrated on a use-case for disassembling electric vehicle batteries to support their remanufacturing for stationary battery applications.', 'abstract_zh': '当前产品，尤其是在汽车领域，具有多学科机电集成的复杂技术系统。支持系统工程和生产的工业标准通常仅（i）关注生产阶段，而不涵盖完整的产品生命周期，（ii）侧重生产过程和资源而非产品本身。本文提出的方法旨在将产品生命周期结束阶段的影响纳入工程阶段。本文提出了一种源自产品-过程-资源（PPR）建模范式的建模方法，该方法结合了对（i）尊重产品结构作为模型基础的要求，以及（ii）在数字化物理生产系统中纳入修复、再制造或升级改造。所提出的模型称为PoPAN，应在产品整个生命周期中作为嵌入产品资产管理壳中的数字影子伴随产品。为了促进该范式的采用，本文还建议将以AutomationML数据格式对模型进行序列化。该模型通过一个用于拆解电动汽车电池的用例来支持其用于固定电池应用的再制造进行演示。', 'title_zh': '面向产品的产品-工艺-资源资产网络及其在自动化建模语言中的表示用于资产行政壳体'}
{'arxiv_id': 'arXiv:2510.00814', 'title': 'RTFF: Random-to-Target Fabric Flattening Policy using Dual-Arm Manipulator', 'authors': 'Kai Tang, Dipankar Bhattacharya, Hang Xu, Fuyuki Tokuda, Norman C. Tien, Kazuhiro Kosuge', 'link': 'https://arxiv.org/abs/2510.00814', 'abstract': "Robotic fabric manipulation in garment production for sewing, cutting, and ironing requires reliable flattening and alignment, yet remains challenging due to fabric deformability, effectively infinite degrees of freedom, and frequent occlusions from wrinkles, folds, and the manipulator's End-Effector (EE) and arm. To address these issues, this paper proposes the first Random-to-Target Fabric Flattening (RTFF) policy, which aligns a random wrinkled fabric state to an arbitrary wrinkle-free target state. The proposed policy adopts a hybrid Imitation Learning-Visual Servoing (IL-VS) framework, where IL learns with explicit fabric models for coarse alignment of the wrinkled fabric toward a wrinkle-free state near the target, and VS ensures fine alignment to the target. Central to this framework is a template-based mesh that offers precise target state representation, wrinkle-aware geometry prediction, and consistent vertex correspondence across RTFF manipulation steps, enabling robust manipulation and seamless IL-VS switching. Leveraging the power of mesh, a novel IL solution for RTFF-Mesh Action Chunking Transformer (MACT)-is then proposed by conditioning the mesh information into a Transformer-based policy. The RTFF policy is validated on a real dual-arm tele-operation system, showing zero-shot alignment to different targets, high accuracy, and strong generalization across fabrics and scales. Project website: this https URL", 'abstract_zh': '基于缝制、裁剪和熨烫的服装生产中，机器人织物操作需要可靠的平铺和对齐，但由于织物变形性、无限的自由度以及频繁的褶皱、折痕和末端执行器（EE）和手臂的遮挡，这一任务仍然具有挑战性。为此，本文提出了第一个随机目标织物平铺（RTFF）策略，该策略将随机褶皱的织物状态对齐到任意无褶皱的目标状态。所提出的方法采用了一种混合的模仿学习-视觉伺服（IL-VS）框架，其中IL使用显式的织物模型粗略对齐褶皱织物向接近目标的无褶皱状态，而VS确保细粒度对齐到目标。该框架的核心是一个基于模板的网格，它提供了精确的目标状态表示、褶皱意识的几何预测，并在RTFF操作步骤中保持一致的顶点对应，从而实现鲁棒的操作并无缝地切换IL-VS。通过利用网格的强大功能，提出了一种基于Transformer的新型IL解决方案——RTFF-Mesh动作分割变换器（MACT），通过将其网格信息条件化到策略中。所提出的RTFF策略在实际的双臂远程操作系统上得到了验证，展示了针对不同目标的零样本对齐、高精度以及在不同织物和尺度上的强大泛化能力。项目网页：this https URL。', 'title_zh': 'RTFF: 基于双臂 manipulator 的随机目标fabric展平策略'}
{'arxiv_id': 'arXiv:2510.00783', 'title': 'Semantic Visual Simultaneous Localization and Mapping: A Survey on State of the Art, Challenges, and Future Directions', 'authors': 'Thanh Nguyen Canh, Haolan Zhang, Xiem HoangVan, Nak Young Chong', 'link': 'https://arxiv.org/abs/2510.00783', 'abstract': 'Semantic Simultaneous Localization and Mapping (SLAM) is a critical area of research within robotics and computer vision, focusing on the simultaneous localization of robotic systems and associating semantic information to construct the most accurate and complete comprehensive model of the surrounding environment. Since the first foundational work in Semantic SLAM appeared more than two decades ago, this field has received increasing attention across various scientific communities. Despite its significance, the field lacks comprehensive surveys encompassing recent advances and persistent challenges. In response, this study provides a thorough examination of the state-of-the-art of Semantic SLAM techniques, with the aim of illuminating current trends and key obstacles. Beginning with an in-depth exploration of the evolution of visual SLAM, this study outlines its strengths and unique characteristics, while also critically assessing previous survey literature. Subsequently, a unified problem formulation and evaluation of the modular solution framework is proposed, which divides the problem into discrete stages, including visual localization, semantic feature extraction, mapping, data association, and loop closure optimization. Moreover, this study investigates alternative methodologies such as deep learning and the utilization of large language models, alongside a review of relevant research about contemporary SLAM datasets. Concluding with a discussion on potential future research directions, this study serves as a comprehensive resource for researchers seeking to navigate the complex landscape of Semantic SLAM.', 'abstract_zh': '语义同步定位与建图（SLAM）是机器人学和计算机视觉领域的关键研究领域，专注于同时定位机器人系统并关联语义信息以构建周围环境的最准确和完整的综合模型。自语义SLAM的第一个基础性工作出现以来二十年多的时间里，该领域受到了跨多个科学社群的越来越多的关注。尽管其重要性日益凸显，但该领域缺少全面综述，涵盖近期进展和持久性挑战。为此，本研究提供了对先进语义SLAM技术的全面考察，旨在揭示当前趋势和关键障碍。首先深入探讨视觉SLAM的发展演变，概述其优势和独特特性，并对之前的综述文献进行批判性评估。随后，提出统一的问题表述和模块化解决方案框架，将问题分解为视觉定位、语义特征提取、建图、数据关联和回路闭合优化等离散阶段。此外，本研究还探讨了深度学习等替代方法论及其采用大规模语言模型的应用，并回顾了关于当前SLAM数据集的相关研究。最后，讨论潜在的未来研究方向，本研究为希望导航复杂语义SLAM领域的研究者提供了一份全面资源。', 'title_zh': '基于语义的视觉同步定位与建图：对当前研究、挑战及未来方向的综述'}
{'arxiv_id': 'arXiv:2510.00770', 'title': 'Tele-rehabilitation with online skill transfer and adaptation in $\\mathbb{R}^3 \\times \\mathit{S}^3$', 'authors': 'Tianle Ni, Xiao Chen, Hamid Sadeghian, Sami Haddadin', 'link': 'https://arxiv.org/abs/2510.00770', 'abstract': 'This paper proposes a tele-teaching framework for the domain of robot-assisted tele-rehabilitation. The system connects two robotic manipulators on therapist and patient side via bilateral teleoperation, enabling a therapist to remotely demonstrate rehabilitation exercises that are executed by the patient-side robot. A 6-DoF Dynamical Movement Primitives formulation is employed to jointly encode translational and rotational motions in $\\mathbb{R}^3 \\times \\mathit{S}^3$ space, ensuring accurate trajectory reproduction. The framework supports smooth transitions between therapist-led guidance and patient passive training, while allowing adaptive adjustment of motion. Experiments with 7-DoF manipulators demonstrate the feasibility of the approach, highlighting its potential for personalized and remotely supervised rehabilitation.', 'abstract_zh': '机器人辅助远程康复领域的远程教学框架', 'title_zh': '三维空间中的远程康复：在线技能转移与适应在$\\mathbb{R}^3 \\times S^3$中'}
{'arxiv_id': 'arXiv:2510.00726', 'title': 'CroSTAta: Cross-State Transition Attention Transformer for Robotic Manipulation', 'authors': 'Giovanni Minelli, Giulio Turrisi, Victor Barasuol, Claudio Semini', 'link': 'https://arxiv.org/abs/2510.00726', 'abstract': 'Learning robotic manipulation policies through supervised learning from demonstrations remains challenging when policies encounter execution variations not explicitly covered during training. While incorporating historical context through attention mechanisms can improve robustness, standard approaches process all past states in a sequence without explicitly modeling the temporal structure that demonstrations may include, such as failure and recovery patterns. We propose a Cross-State Transition Attention Transformer that employs a novel State Transition Attention (STA) mechanism to modulate standard attention weights based on learned state evolution patterns, enabling policies to better adapt their behavior based on execution history. Our approach combines this structured attention with temporal masking during training, where visual information is randomly removed from recent timesteps to encourage temporal reasoning from historical context. Evaluation in simulation shows that STA consistently outperforms standard cross-attention and temporal modeling approaches like TCN and LSTM networks across all tasks, achieving more than 2x improvement over cross-attention on precision-critical tasks.', 'abstract_zh': '通过示例监督学习使机器人操作策略在遇到训练中未明确覆盖的执行变体时仍能保持稳健性依然具有挑战性。虽然通过注意机制引入历史上下文可以改善稳健性，但标准方法在处理序列中的所有过去状态时并未明确建模示例中可能包括的时间结构，如失败和恢复模式。我们提出了一种跨状态转换注意变换器，采用新颖的状态转换注意（STA）机制，根据学习到的状态演化模式修改标准注意权重，使策略能够更好地根据执行历史调整其行为。我们的方法将这种结构化注意与训练期间的时间掩码相结合，在此期间随机从近期时间步骤中移除视觉信息，以促使从历史上下文中进行时间推理。仿真实验表明，STA 在所有任务上均能持续优于标准交叉注意和 TCN 及 LSTM 网络等时间建模方法，精度至关重要的任务上性能提升超过 2 倍。', 'title_zh': 'CroSTAta: 跨状态转换注意力变换器在机器人操作中的应用'}
{'arxiv_id': 'arXiv:2510.00703', 'title': 'MultiPhysio-HRC: Multimodal Physiological Signals Dataset for industrial Human-Robot Collaboration', 'authors': 'Andrea Bussolan, Stefano Baraldo, Oliver Avram, Pablo Urcola, Luis Montesano, Luca Maria Gambardella, Anna Valente', 'link': 'https://arxiv.org/abs/2510.00703', 'abstract': "Human-robot collaboration (HRC) is a key focus of Industry 5.0, aiming to enhance worker productivity while ensuring well-being. The ability to perceive human psycho-physical states, such as stress and cognitive load, is crucial for adaptive and human-aware robotics. This paper introduces MultiPhysio-HRC, a multimodal dataset containing physiological, audio, and facial data collected during real-world HRC scenarios. The dataset includes electroencephalography (EEG), electrocardiography (ECG), electrodermal activity (EDA), respiration (RESP), electromyography (EMG), voice recordings, and facial action units. The dataset integrates controlled cognitive tasks, immersive virtual reality experiences, and industrial disassembly activities performed manually and with robotic assistance, to capture a holistic view of the participants' mental states. Rich ground truth annotations were obtained using validated psychological self-assessment questionnaires. Baseline models were evaluated for stress and cognitive load classification, demonstrating the dataset's potential for affective computing and human-aware robotics research. MultiPhysio-HRC is publicly available to support research in human-centered automation, workplace well-being, and intelligent robotic systems.", 'abstract_zh': 'Human-robot合作（HRC）是工业4.0的关键焦点，旨在提升员工 productivity同时确保 well-being。准确感知人类的心理-生理状态，如压力和认知负荷，是适应性和人性化机器人技术的关键。本文介绍了MultiPhysio-HRC，这是一个包含生理、音频和面部数据的多模态数据集，数据来源于实际的HRC场景。数据集包括脑电图（EEG）、心电图（ECG）、皮肤电活动（EDA）、呼吸（RESP）、肌电图（EMG）、语音录制和面部动作单元。该数据集结合了控制认知任务、沉浸式虚拟现实体验以及手动和机器人辅助的工业拆卸活动，以捕获参与者心理状态的全面视图。使用验证的心理自我评估问卷获得了丰富的地面真实标注。基准模型用于评估压力和认知负荷分类，展示了数据集在情感计算和人性化机器人技术研究中的潜力。MultiPhysio-HRC面向公众，支持以人为中心的自动化、工作场所well-being和智能机器人系统的研究。', 'title_zh': '多模态生理信号数据集：工业人机协作中的多物理量生理信号数据集'}
{'arxiv_id': 'arXiv:2510.00695', 'title': 'HAMLET: Switch your Vision-Language-Action Model into a History-Aware Policy', 'authors': 'Myungkyu Koo, Daewon Choi, Taeyoung Kim, Kyungmin Lee, Changyeon Kim, Youngyo Seo, Jinwoo Shin', 'link': 'https://arxiv.org/abs/2510.00695', 'abstract': 'Inherently, robotic manipulation tasks are history-dependent: leveraging past context could be beneficial. However, most existing Vision-Language-Action models (VLAs) have been designed without considering this aspect, i.e., they rely solely on the current observation, ignoring preceding context. In this paper, we propose HAMLET, a scalable framework to adapt VLAs to attend to the historical context during action prediction. Specifically, we introduce moment tokens that compactly encode perceptual information at each timestep. Their representations are initialized with time-contrastive learning, allowing them to better capture temporally distinctive aspects. Next, we employ a lightweight memory module that integrates the moment tokens across past timesteps into memory features, which are then leveraged for action prediction. Through empirical evaluation, we show that HAMLET successfully transforms a state-of-the-art VLA into a history-aware policy, especially demonstrating significant improvements on long-horizon tasks that require historical context. In particular, on top of GR00T N1.5, HAMLET achieves an average success rate of 76.4% on history-dependent real-world tasks, surpassing the baseline performance by 47.2%. Furthermore, HAMLET pushes prior art performance from 64.1% to 66.4% on RoboCasa Kitchen (100-demo setup) and from 95.6% to 97.7% on LIBERO, highlighting its effectiveness even under generic robot-manipulation benchmarks.', 'abstract_zh': '内在地，机器人操作任务具有历史依赖性：利用过去的上下文可能是有益的。然而，现有的大多数Vision-Language-Action模型（VLAs）在设计时并未考虑这一方面，即它们仅依赖当前观察，忽略了之前的上下文。在本文中，我们提出了一种可扩展的框架HAMLET，以使VLAs能够关注操作预测中的历史上下文。具体而言，我们引入了时刻标记来紧凑地编码每个时间步的感知信息。这些表示通过时间对比学习进行初始化，使其能够更好地捕捉时间上的区别特征。随后，我们采用一个轻量级的内存模块，将过去的时刻标记整合到记忆特征中，这些特征随后被用于操作预测。通过实证评估，我们展示了HAMLET成功将最先进的VLAs转换为历史感知策略，特别是在需要历史上下文的长时序任务中表现出显著改进。特别地，基于GR00T N1.5，HAMLET在依赖历史的现实任务中平均成功率为76.4%，超过了基线性能47.2%。此外，HAMLET在RoboCasa Kitchen（100-demo设置）和LIBERO上的性能分别从64.1%提高到66.4%和从95.6%提高到97.7%，突显了其在通用机器人操作基准下的有效性。', 'title_zh': 'HAMLET: 将你的视觉-语言-动作模型转换为历史感知策略'}
{'arxiv_id': 'arXiv:2510.00682', 'title': 'Shared Object Manipulation with a Team of Collaborative Quadrupeds', 'authors': 'Shengzhi Wang, Niels Dehio, Xuanqi Zeng, Xian Yang, Lingwei Zhang, Yun-Hui Liu, K. W. Samuel Au', 'link': 'https://arxiv.org/abs/2510.00682', 'abstract': 'Utilizing teams of multiple robots is advantageous for handling bulky objects. Many related works focus on multi-manipulator systems, which are limited by workspace constraints. In this paper, we extend a classical hybrid motion-force controller to a team of legged manipulator systems, enabling collaborative loco-manipulation of rigid objects with a force-closed grasp. Our novel approach allows the robots to flexibly coordinate their movements, achieving efficient and stable object co-manipulation and transport, validated through extensive simulations and real-world experiments.', 'abstract_zh': '利用多个机器人团队处理 bulky 物体具有优势。本论文将经典的混合运动-力控制器扩展到由腿式 manipulator 系统组成的团队，使机器人能够通过力闭合抓取协作进行刚性物体的 co-manipulation 和运输。该新颖方法允许机器人灵活协调其运动，通过广泛的仿真和真实世界实验验证实现了高效且稳定的物体 co-manipulation 和运输。', 'title_zh': '协作四足机器人团队的共享物体操作'}
{'arxiv_id': 'arXiv:2510.00646', 'title': 'Enabling High-Frequency Cross-Modality Visual Positioning Service for Accurate Drone Landing', 'authors': 'Haoyang Wang, Xinyu Luo, Wenhua Ding, Jingao Xu, Xuecheng Chen, Ruiyang Duan, Jialong Chen, Haitao Zhang, Yunhao Liu, Xinlei Chen', 'link': 'https://arxiv.org/abs/2510.00646', 'abstract': 'After years of growth, drone-based delivery is transforming logistics. At its core, real-time 6-DoF drone pose tracking enables precise flight control and accurate drone landing. With the widespread availability of urban 3D maps, the Visual Positioning Service (VPS), a mobile pose estimation system, has been adapted to enhance drone pose tracking during the landing phase, as conventional systems like GPS are unreliable in urban environments due to signal attenuation and multi-path propagation. However, deploying the current VPS on drones faces limitations in both estimation accuracy and efficiency. In this work, we redesign drone-oriented VPS with the event camera and introduce EV-Pose to enable accurate, high-frequency 6-DoF pose tracking for accurate drone landing. EV-Pose introduces a spatio-temporal feature-instructed pose estimation module that extracts a temporal distance field to enable 3D point map matching for pose estimation; and a motion-aware hierarchical fusion and optimization scheme to enhance the above estimation in accuracy and efficiency, by utilizing drone motion in the \\textit{early stage} of event filtering and the \\textit{later stage} of pose optimization. Evaluation shows that EV-Pose achieves a rotation accuracy of 1.34$\\degree$ and a translation accuracy of 6.9$mm$ with a tracking latency of 10.08$ms$, outperforming baselines by $>$50\\%, \\tmcrevise{thus enabling accurate drone landings.} Demo: this https URL', 'abstract_zh': '基于事件摄像头的6-DoF无人机姿态估计EV-Pose：实现高精度高效无人机精准降落', 'title_zh': '高频跨模态视觉定位服务 Enables 准确无人机降落'}
{'arxiv_id': 'arXiv:2510.00630', 'title': 'Trajectory Based Observer Design: A Framework for Lightweight Sensor Fusion', 'authors': 'Federico Oliva, Tom Shaked, Daniele Carnevale, Amir Degani', 'link': 'https://arxiv.org/abs/2510.00630', 'abstract': "Efficient observer design and accurate sensor fusion are key in state estimation. This work proposes an optimization-based methodology, termed Trajectory Based Optimization Design (TBOD), allowing the user to easily design observers for general nonlinear systems and multi-sensor setups. Starting from parametrized observer dynamics, the proposed method considers a finite set of pre-recorded measurement trajectories from the nominal plant and exploits them to tune the observer parameters through numerical optimization. This research hinges on the classic observer's theory and Moving Horizon Estimators methodology. Optimization is exploited to ease the observer's design, providing the user with a lightweight, general-purpose sensor fusion methodology. TBOD's main characteristics are the capability to handle general sensors efficiently and in a modular way and, most importantly, its straightforward tuning procedure. The TBOD's performance is tested on a terrestrial rover localization problem, combining IMU and ranging sensors provided by Ultra Wide Band antennas, and validated through a motion-capture system. Comparison with an Extended Kalman Filter is also provided, matching its position estimation accuracy and significantly improving in the orientation.", 'abstract_zh': '基于轨迹优化的设计方法（Trajectory Based Optimization Design，TBOD）及其在状态估计中的应用', 'title_zh': '基于轨迹的观察者设计：轻量级传感器融合的框架'}
{'arxiv_id': 'arXiv:2510.00619', 'title': 'What Did I Learn? Operational Competence Assessment for AI-Based Trajectory Planners', 'authors': 'Michiel Braat, Maren Buermann, Marijke van Weperen, Jan-Pieter Paardekooper', 'link': 'https://arxiv.org/abs/2510.00619', 'abstract': "Automated driving functions increasingly rely on machine learning for tasks like perception and trajectory planning, requiring large, relevant datasets. The performance of these algorithms depends on how closely the training data matches the task. To ensure reliable functioning, it is crucial to know what is included in the dataset to assess the trained model's operational risk. We aim to enhance the safe use of machine learning in automated driving by developing a method to recognize situations that an automated vehicle has not been sufficiently trained on. This method also improves explainability by describing the dataset at a human-understandable level. We propose modeling driving data as knowledge graphs, representing driving scenes with entities and their relationships. These graphs are queried for specific sub-scene configurations to check their occurrence in the dataset. We estimate a vehicle's competence in a driving scene by considering the coverage and complexity of sub-scene configurations in the training set. Higher complexity scenes require greater coverage for high competence. We apply this method to the NuPlan dataset, modeling it with knowledge graphs and analyzing the coverage of specific driving scenes. This approach helps monitor the competence of machine learning models trained on the dataset, which is essential for trustworthy AI to be deployed in automated driving.", 'abstract_zh': '自动驾驶功能越来越多地依赖机器学习进行感知和轨迹规划，要求有大量且相关的数据集。这些算法的性能取决于训练数据与任务的匹配程度。为了确保可靠运行，必须了解数据集包含的内容，以评估训练模型的运行风险。我们旨在通过开发一种方法来增强机器学习在自动驾驶中的安全使用，该方法能够识别自动车辆尚未充分训练的情况，同时也通过以人类可理解的方式描述数据集来提高可解释性。我们提议将驾驶数据建模为知识图谱，以实体及其关系来表示驾驶场景，并查询特定子场景配置以检查其在数据集中的出现情况。我们通过考虑训练集中子场景配置的覆盖范围和复杂性来估算车辆在驾驶场景中的能力。复杂度更高的场景需要更高的覆盖范围才能达到高能力。我们应用此方法对NuPlan数据集进行建模，使用知识图谱分析特定驾驶场景的覆盖范围。这种方法有助于监控基于数据集训练的机器学习模型的能力，这对于可靠部署于自动驾驶中的可信赖人工智能来说至关重要。', 'title_zh': '我在做什么？基于AI的轨迹规划器的操作能力评估'}
{'arxiv_id': 'arXiv:2510.00600', 'title': 'Hybrid Training for Vision-Language-Action Models', 'authors': 'Pietro Mazzaglia, Cansu Sancaktar, Markus Peschl, Daniel Dijkman', 'link': 'https://arxiv.org/abs/2510.00600', 'abstract': "Using Large Language Models to produce intermediate thoughts, a.k.a. Chain-of-thought (CoT), before providing an answer has been a successful recipe for solving complex language tasks. In robotics, similar embodied CoT strategies, generating thoughts before actions, have also been shown to lead to improved performance when using Vision-Language-Action models (VLAs). As these techniques increase the length of the model's generated outputs to include the thoughts, the inference time is negatively affected. Delaying an agent's actions in real-world executions, as in robotic manipulation settings, strongly affects the usability of a method, as tasks require long sequences of actions. However, is the generation of long chains-of-thought a strong prerequisite for achieving performance improvements? In this work, we explore the idea of Hybrid Training (HyT), a framework that enables VLAs to learn from thoughts and benefit from the associated performance gains, while enabling the possibility to leave out CoT generation during inference. Furthermore, by learning to conditionally predict a diverse set of outputs, HyT supports flexibility at inference time, enabling the model to either predict actions directly, generate thoughts or follow instructions. We evaluate the proposed method in a series of simulated benchmarks and real-world experiments.", 'abstract_zh': '使用大型语言模型在提供答案之前生成中间思考，即链式思考（Chain-of-Thought, CoT），已被证明是解决复杂语言任务的成功方法。在机器人领域，类似的嵌入式CoT策略，在采取行动前生成思考，也被证明能够改善使用视觉-语言-动作模型（VLAs）的表现。随着这些技术增加模型生成输出的长度，以包括思考内容，推理时间会受到负面影响。在真实的机器人操作环境中延迟执行代理的操作，严重限制了该方法的实用性，因为任务需要一系列的动作。然而，生成长的链式思考是否是实现性能提升的必要条件？在本工作中，我们探索了混合训练（HyT）框架的想法，该框架使VLAs能够从思考中学习并受益于相关的性能提升，同时允许在推理过程中省略CoT生成的可能性。此外，通过学习有条件地预测一组多样化的输出，HyT在推理时支持灵活性，使模型能够在预测动作、生成思考或遵循指令之间进行选择。我们在一系列模拟基准和实际实验中评估了所提出的方法。', 'title_zh': '视觉-语言-行动模型的混合训练'}
{'arxiv_id': 'arXiv:2510.00573', 'title': 'GRITS: A Spillage-Aware Guided Diffusion Policy for Robot Food Scooping Tasks', 'authors': 'Yen-Ling Tai, Yi-Ru Yang, Kuan-Ting Yu, Yu-Wei Chao, Yi-Ting Chen', 'link': 'https://arxiv.org/abs/2510.00573', 'abstract': 'Robotic food scooping is a critical manipulation skill for food preparation and service robots. However, existing robot learning algorithms, especially learn-from-demonstration methods, still struggle to handle diverse and dynamic food states, which often results in spillage and reduced reliability. In this work, we introduce GRITS: A Spillage-Aware Guided Diffusion Policy for Robot Food Scooping Tasks. This framework leverages guided diffusion policy to minimize food spillage during scooping and to ensure reliable transfer of food items from the initial to the target location. Specifically, we design a spillage predictor that estimates the probability of spillage given current observation and action rollout. The predictor is trained on a simulated dataset with food spillage scenarios, constructed from four primitive shapes (spheres, cubes, cones, and cylinders) with varied physical properties such as mass, friction, and particle size. At inference time, the predictor serves as a differentiable guidance signal, steering the diffusion sampling process toward safer trajectories while preserving task success. We validate GRITS on a real-world robotic food scooping platform. GRITS is trained on six food categories and evaluated on ten unseen categories with different shapes and quantities. GRITS achieves an 82% task success rate and a 4% spillage rate, reducing spillage by over 40% compared to baselines without guidance, thereby demonstrating its effectiveness.', 'abstract_zh': 'Spillage-Aware Guided Diffusion Policy for Robot Food Scooping Tasks', 'title_zh': 'GRITS: 一种考虑溢出的机器人食物舀取任务引导扩散策略'}
{'arxiv_id': 'arXiv:2510.00524', 'title': 'Two stage GNSS outlier detection for factor graph optimization based GNSS-RTK/INS/odometer fusion', 'authors': 'Baoshan Song, Penggao Yan, Xiao Xia, Yihan Zhong, Weisong Wen, Li-Ta Hsu', 'link': 'https://arxiv.org/abs/2510.00524', 'abstract': 'Reliable GNSS positioning in complex environments remains a critical challenge due to non-line-of-sight (NLOS) propagation, multipath effects, and frequent signal blockages. These effects can easily introduce large outliers into the raw pseudo-range measurements, which significantly degrade the performance of global navigation satellite system (GNSS) real-time kinematic (RTK) positioning and limit the effectiveness of tightly coupled GNSS-based integrated navigation system. To address this issue, we propose a two-stage outlier detection method and apply the method in a tightly coupled GNSS-RTK, inertial navigation system (INS), and odometer integration based on factor graph optimization (FGO). In the first stage, Doppler measurements are employed to detect pseudo-range outliers in a GNSS-only manner, since Doppler is less sensitive to multipath and NLOS effects compared with pseudo-range, making it a more stable reference for detecting sudden inconsistencies. In the second stage, pre-integrated inertial measurement units (IMU) and odometer constraints are used to generate predicted double-difference pseudo-range measurements, which enable a more refined identification and rejection of remaining outliers. By combining these two complementary stages, the system achieves improved robustness against both gross pseudo-range errors and degraded satellite measuring quality. The experimental results demonstrate that the two-stage detection framework significantly reduces the impact of pseudo-range outliers, and leads to improved positioning accuracy and consistency compared with representative baseline approaches. In the deep urban canyon test, the outlier mitigation method has limits the RMSE of GNSS-RTK/INS/odometer fusion from 0.52 m to 0.30 m, with 42.3% improvement.', 'abstract_zh': '可靠的GNSS定位在复杂环境中的保持问题依旧是一个关键挑战，由于非视距(NLOS)传播、多路径效应和频繁的信号阻塞。这些效应容易在原始伪距测量中引入大量离群值，显著降低全球导航卫星系统(GNSS)实时动态(RTK)定位性能，并限制基于GNSS的紧密耦合综合导航系统的有效性。为了解决这一问题，我们提出了一种两阶段离群值检测方法，并将其应用于基于因子图优化(FGO)的GNSS-RTK、惯性导航系统(INS)和里程计集成系统中。在第一阶段，采用多普勒测量来仅通过GNSS方式检测伪距离群值，因为与伪距相比，多普勒对多路径和NLOS效应的敏感度较低，因此它可以作为检测突然不一致性的更稳定的参考。在第二阶段，利用预积分惯性测量单元(IMU)和里程计约束生成预测的双差伪距测量，这使得更精细地识别并剔除剩余离群值成为可能。通过结合这两个互补的阶段，系统能够更好地抵抗粗伪距误差和卫星测量质量下降的影响。实验结果表明，两阶段检测框架显著减少了伪距离群值的影响，并与代表性基准方法相比，提高了定位精度和一致性。在深入城市峡谷测试中，离群值缓解方法将GNSS-RTK/INS/里程计融合的RMSE从0.52 m降低到0.30 m，提高了42.3%。', 'title_zh': '基于GNSS-RTK/INS/里程计融合的两阶段GNSS离群值检测因子图优化方法'}
{'arxiv_id': 'arXiv:2510.00491', 'title': 'From Human Hands to Robot Arms: Manipulation Skills Transfer via Trajectory Alignment', 'authors': 'Han Zhou, Jinjin Cao, Liyuan Ma, Xueji Fang, Guo-jun Qi', 'link': 'https://arxiv.org/abs/2510.00491', 'abstract': "Learning diverse manipulation skills for real-world robots is severely bottlenecked by the reliance on costly and hard-to-scale teleoperated demonstrations. While human videos offer a scalable alternative, effectively transferring manipulation knowledge is fundamentally hindered by the significant morphological gap between human and robotic embodiments. To address this challenge and facilitate skill transfer from human to robot, we introduce Traj2Action,a novel framework that bridges this embodiment gap by using the 3D trajectory of the operational endpoint as a unified intermediate representation, and then transfers the manipulation knowledge embedded in this trajectory to the robot's actions. Our policy first learns to generate a coarse trajectory, which forms an high-level motion plan by leveraging both human and robot data. This plan then conditions the synthesis of precise, robot-specific actions (e.g., orientation and gripper state) within a co-denoising framework. Extensive real-world experiments on a Franka robot demonstrate that Traj2Action boosts the performance by up to 27% and 22.25% over $\\pi_0$ baseline on short- and long-horizon real-world tasks, and achieves significant gains as human data scales in robot policy learning. Our project website, featuring code and video demonstrations, is available at this https URL.", 'abstract_zh': '一种通过3D操作末端轨迹将 manipulation 知识从人类转移到机器人中的新颖框架：Traj2Action', 'title_zh': '从人工操控到机器人臂：通过轨迹对齐转移操作技能'}
{'arxiv_id': 'arXiv:2510.00466', 'title': 'Integrating Offline Pre-Training with Online Fine-Tuning: A Reinforcement Learning Approach for Robot Social Navigation', 'authors': 'Run Su, Hao Fu, Shuai Zhou, Yingao Fu', 'link': 'https://arxiv.org/abs/2510.00466', 'abstract': 'Offline reinforcement learning (RL) has emerged as a promising framework for addressing robot social navigation challenges. However, inherent uncertainties in pedestrian behavior and limited environmental interaction during training often lead to suboptimal exploration and distributional shifts between offline training and online deployment. To overcome these limitations, this paper proposes a novel offline-to-online fine-tuning RL algorithm for robot social navigation by integrating Return-to-Go (RTG) prediction into a causal Transformer architecture. Our algorithm features a spatiotem-poral fusion model designed to precisely estimate RTG values in real-time by jointly encoding temporal pedestrian motion patterns and spatial crowd dynamics. This RTG prediction framework mitigates distribution shift by aligning offline policy training with online environmental interactions. Furthermore, a hybrid offline-online experience sampling mechanism is built to stabilize policy updates during fine-tuning, ensuring balanced integration of pre-trained knowledge and real-time adaptation. Extensive experiments in simulated social navigation environments demonstrate that our method achieves a higher success rate and lower collision rate compared to state-of-the-art baselines. These results underscore the efficacy of our algorithm in enhancing navigation policy robustness and adaptability. This work paves the way for more reliable and adaptive robotic navigation systems in real-world applications.', 'abstract_zh': '离线强化学习（RL）已成为应对机器人社会导航挑战的一种有前途的框架。然而，行人行为固有的不确定性以及训练过程中有限的环境互动往往导致次优探索和离线训练与在线部署之间的分布偏移。为克服这些局限性，本文提出了一种将返回前往预测（RTG）集成到因果Transformer架构中的新颖离线到在线微调RL算法，以应对机器人社会导航问题。该算法通过联合编码时空行人运动模式和人群动力学，设计了一种空间时间融合模型，以实时精确估计RTG值。该RTG预测框架通过将离线策略训练与在线环境互动对齐来减轻分布偏移。此外，构建了一种混合离线-在线经验采样机制，以在微调过程中稳定策略更新，从而确保预训练知识与实时适应的有效整合。在仿真社会导航环境中的广泛实验表明，与最先进的基线方法相比，本方法实现了更高的成功率和更低的碰撞率。这些结果强调了该算法在增强导航策略稳健性与适应性方面的有效性。本工作为在实际应用中开发更可靠和适应性强的机器人导航系统铺平了道路。', 'title_zh': '离线预训练与在线微调集成：基于强化学习的机器人社会导航方法'}
{'arxiv_id': 'arXiv:2510.00441', 'title': 'Seeing through Uncertainty: Robust Task-Oriented Optimization in Visual Navigation', 'authors': 'Yiyuan Pan, Yunzhe Xu, Zhe Liu, Hesheng Wang', 'link': 'https://arxiv.org/abs/2510.00441', 'abstract': 'Visual navigation is a fundamental problem in embodied AI, yet practical deployments demand long-horizon planning capabilities to address multi-objective tasks. A major bottleneck is data scarcity: policies learned from limited data often overfit and fail to generalize OOD. Existing neural network-based agents typically increase architectural complexity that paradoxically become counterproductive in the small-sample regime. This paper introduce NeuRO, a integrated learning-to-optimize framework that tightly couples perception networks with downstream task-level robust optimization. Specifically, NeuRO addresses core difficulties in this integration: (i) it transforms noisy visual predictions under data scarcity into convex uncertainty sets using Partially Input Convex Neural Networks (PICNNs) with conformal calibration, which directly parameterize the optimization constraints; and (ii) it reformulates planning under partial observability as a robust optimization problem, enabling uncertainty-aware policies that transfer across environments. Extensive experiments on both unordered and sequential multi-object navigation tasks demonstrate that NeuRO establishes SoTA performance, particularly in generalization to unseen environments. Our work thus presents a significant advancement for developing robust, generalizable autonomous agents.', 'abstract_zh': '视觉导航是本体人工智能中的一个基础问题，但在实际部署中需要具备长期规划能力以应对多目标任务。一个主要瓶颈是数据稀缺性：从有限数据中学到的策略往往会发生过拟合，并且无法在OOD场景下泛化。基于神经网络的代理通常会增加架构的复杂性，但在小样本情况下这却适得其反。本文提出NeuRO，这是一个将感知网络与下游任务级别的鲁棒优化紧密耦合的集成学习-优化框架。具体而言，NeuRO解决了该集成中的核心困难：（i）它通过使用与校准一致的Partially Input Convex Neural Networks (PICNNs)将稀数据下的 noisy 视觉预测转化为凸不确定性集，并直接参数化优化约束；（ii）它将部分可观测性的规划重新表述为鲁棒优化问题，使得能够实现对不确定性的感知，并且能够在不同环境中进行策略迁移。在无序和序列多目标导航任务上的广泛实验表明，NeuRO在性能上达到最新技术水平，尤其是在对未见过环境的泛化能力上。因此，我们的工作对开发鲁棒且可泛化的自主代理系统提出了重要进展。', 'title_zh': '透过不确定性：视觉导航中稳健的任务导向优化'}
{'arxiv_id': 'arXiv:2510.00406', 'title': 'VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators', 'authors': 'Hengtao Li, Pengxiang Ding, Runze Suo, Yihao Wang, Zirui Ge, Dongyuan Zang, Kexian Yu, Mingyang Sun, Hongyin Zhang, Donglin Wang, Weihua Su', 'link': 'https://arxiv.org/abs/2510.00406', 'abstract': 'Vision-Language-Action (VLA) models enable embodied decision-making but rely heavily on imitation learning, leading to compounding errors and poor robustness under distribution shift. Reinforcement learning (RL) can mitigate these issues yet typically demands costly real-world interactions or suffers from sim-to-real gaps. We introduce VLA-RFT, a reinforcement fine-tuning framework that leverages a data-driven world model as a controllable simulator. Trained from real interaction data, the simulator predicts future visual observations conditioned on actions, allowing policy rollouts with dense, trajectory-level rewards derived from goal-achieving references. This design delivers an efficient and action-aligned learning signal, drastically lowering sample requirements. With fewer than 400 fine-tuning steps, VLA-RFT surpasses strong supervised baselines and achieves greater efficiency than simulator-based RL. Moreover, it exhibits strong robustness under perturbed conditions, sustaining stable task execution. Our results establish world-model-based RFT as a practical post-training paradigm to enhance the generalization and robustness of VLA models. For more details, please refer to this https URL.', 'abstract_zh': 'Vision-Language-Action (VLA)模型实现了基于身体的决策，但过度依赖于模仿学习，导致累积错误和在分布偏移下的较差鲁棒性。强化学习（RL）可以缓解这些问题，但通常需要昂贵的实物交互或面临从仿真到实物的差距。我们引入了VLA-RFT，这是一种利用数据驱动的世界模型作为可控模拟器的强化学习微调框架。该模拟器从实物交互数据中训练，可以根据动作预测未来的视觉观察，允许以从目标实现参考中获得的密集轨迹级奖励来执行策略部署。这一设计提供了高效且与动作对齐的学习信号，大幅降低了采样需求。通过不到400步的微调步骤，VLA-RFT超越了强大的监督基准，并实现了比基于模拟器的RL更高效的性能。此外，它在扰动条件下表现出较强的鲁棒性，能够维持稳定的任务执行。我们的结果证明了基于世界模型的RL微调作为增强VLA模型泛化能力和鲁棒性的实用后训练范式的可行性。更多信息请参见此链接。', 'title_zh': '带有验证奖励的视觉-语言-动作强化微调：在世界模拟器中的应用'}
{'arxiv_id': 'arXiv:2510.00401', 'title': 'Physics-Informed Neural Controlled Differential Equations for Scalable Long Horizon Multi-Agent Motion Forecasting', 'authors': 'Shounak Sural, Charles Kekeh, Wenliang Liu, Federico Pecora, Mouhacine Benosman', 'link': 'https://arxiv.org/abs/2510.00401', 'abstract': 'Long-horizon motion forecasting for multiple autonomous robots is challenging due to non-linear agent interactions, compounding prediction errors, and continuous-time evolution of dynamics. Learned dynamics of such a system can be useful in various applications such as travel time prediction, prediction-guided planning and generative simulation. In this work, we aim to develop an efficient trajectory forecasting model conditioned on multi-agent goals. Motivated by the recent success of physics-guided deep learning for partially known dynamical systems, we develop a model based on neural Controlled Differential Equations (CDEs) for long-horizon motion forecasting. Unlike discrete-time methods such as RNNs and transformers, neural CDEs operate in continuous time, allowing us to combine physics-informed constraints and biases to jointly model multi-robot dynamics. Our approach, named PINCoDE (Physics-Informed Neural Controlled Differential Equations), learns differential equation parameters that can be used to predict the trajectories of a multi-agent system starting from an initial condition. PINCoDE is conditioned on future goals and enforces physics constraints for robot motion over extended periods of time. We adopt a strategy that scales our model from 10 robots to 100 robots without the need for additional model parameters, while producing predictions with an average ADE below 0.5 m for a 1-minute horizon. Furthermore, progressive training with curriculum learning for our PINCoDE model results in a 2.7X reduction of forecasted pose error over 4 minute horizons compared to analytical models.', 'abstract_zh': '长时 horizon 多自主机器人运动预测具有挑战性，由于非线性代理交互、累积预测误差以及动力学的连续时间演变。此类系统中学到的动力学在旅行时间预测、预测指导规划和生成性模拟等多种应用中可能是有用的。在这项工作中，我们旨在开发一种基于多代理目标条件的高效轨迹预测模型。受最近物理引导的深度学习在部分已知动力学系统中的成功启发，我们基于神经控制微分方程（CDEs）开发了一种长时 horizon 运动预测模型。与像 RNN 和变压器这样的离散时间方法不同，神经 CDEs 在连续时间中操作，使我们能够结合物理约束和偏置来联合建模多机器人动力学。我们的方法名为 PINCoDE（物理引导的神经控制微分方程），能够从初始条件预测多代理系统的轨迹。PINCoDE 依赖于未来的任务目标，并在长时间段内强制执行机器人运动的物理约束。我们采用一种策略，无需增加模型参数即可将模型扩展从 10 个机器人到 100 个机器人，同时在 1 分钟的展望期内平均 ADE 低于 0.5 米。此外，对于我们的 PINCoDE 模型采用逐级训练与课程学习策略，在 4 分钟的展望期内，预测姿态误差降低了 2.7 倍，相比于分析模型而言。', 'title_zh': '基于物理的神经控制微分方程在可扩展的多agents长时间轨迹预测中的应用'}
{'arxiv_id': 'arXiv:2510.00358', 'title': 'DiSA-IQL: Offline Reinforcement Learning for Robust Soft Robot Control under Distribution Shifts', 'authors': 'Linjin He, Xinda Qi, Dong Chen, Zhaojian Li, Xiaobo Tan', 'link': 'https://arxiv.org/abs/2510.00358', 'abstract': 'Soft snake robots offer remarkable flexibility and adaptability in complex environments, yet their control remains challenging due to highly nonlinear dynamics. Existing model-based and bio-inspired controllers rely on simplified assumptions that limit performance. Deep reinforcement learning (DRL) has recently emerged as a promising alternative, but online training is often impractical because of costly and potentially damaging real-world interactions. Offline RL provides a safer option by leveraging pre-collected datasets, but it suffers from distribution shift, which degrades generalization to unseen scenarios. To overcome this challenge, we propose DiSA-IQL (Distribution-Shift-Aware Implicit Q-Learning), an extension of IQL that incorporates robustness modulation by penalizing unreliable state-action pairs to mitigate distribution shift. We evaluate DiSA-IQL on goal-reaching tasks across two settings: in-distribution and out-of-distribution evaluation. Simulation results show that DiSA-IQL consistently outperforms baseline models, including Behavior Cloning (BC), Conservative Q-Learning (CQL), and vanilla IQL, achieving higher success rates, smoother trajectories, and improved robustness. The codes are open-sourced to support reproducibility and to facilitate further research in offline RL for soft robot control.', 'abstract_zh': '软蛇形机器人在复杂环境中有显著的灵活性和适应性，但由于高度非线性的动力学，其控制仍然具有挑战性。现有的基于模型和生物启发的控制器依赖于简化假设，限制了其性能。深度强化学习(DRL)最近被认为是一种有希望的替代方案，但由于实际互动成本高且可能造成损害，在线训练往往不实际。 offline RL通过利用预先收集的数据集提供了一种更安全的选择，但其遭受分布偏移问题，这降低了其对未见场景的泛化能力。为克服这一挑战，我们提出了DiSA-IQL（分布偏移意识隐式Q学习），这是IQL的扩展，通过惩罚不可靠的状态-动作对来缓解分布偏移。我们在两种场景下对DiSA-IQL进行了目标达成任务的评估：内部分布和外部分布评估。模拟结果显示，DiSA-IQL在成功率、轨迹平滑度和鲁棒性方面均优于基线模型，包括行为克隆(BC)、保守Q学习(CQL)和vanilla IQL。代码已开源，以支持可重复性并促进offline RL在软机器人控制中的进一步研究。', 'title_zh': 'DiSA-IQL: 基于分布偏移的离线强化学习软体机器人控制方法'}
{'arxiv_id': 'arXiv:2510.00329', 'title': 'Learning Human Reaching Optimality Principles from Minimal Observation Inverse Reinforcement Learning', 'authors': 'Sarmad Mehrdad, Maxime Sabbah, Vincent Bonnet, Ludovic Righetti', 'link': 'https://arxiv.org/abs/2510.00329', 'abstract': "This paper investigates the application of Minimal Observation Inverse Reinforcement Learning (MO-IRL) to model and predict human arm-reaching movements with time-varying cost weights. Using a planar two-link biomechanical model and high-resolution motion-capture data from subjects performing a pointing task, we segment each trajectory into multiple phases and learn phase-specific combinations of seven candidate cost functions. MO-IRL iteratively refines cost weights by scaling observed and generated trajectories in the maximum entropy IRL formulation, greatly reducing the number of required demonstrations and convergence time compared to classical IRL approaches. Training on ten trials per posture yields average joint-angle Root Mean Squared Errors (RMSE) of 6.4 deg and 5.6 deg for six- and eight-segment weight divisions, respectively, versus 10.4 deg using a single static weight. Cross-validation on remaining trials and, for the first time, inter-subject validation on an unseen subject's 20 trials, demonstrates comparable predictive accuracy, around 8 deg RMSE, indicating robust generalization. Learned weights emphasize joint acceleration minimization during movement onset and termination, aligning with smoothness principles observed in biological motion. These results suggest that MO-IRL can efficiently uncover dynamic, subject-independent cost structures underlying human motor control, with potential applications for humanoid robots.", 'abstract_zh': '本文研究了最小观察逆强化学习（MO-IRL）在使用时间变化的成本权重建模和预测人类手臂伸展运动的应用。使用平面双关节生物力学模型和受试者执行指针任务的高分辨率动作捕捉数据，将每个轨迹分割为多个阶段，并学习七种候选成本函数的阶段特定组合。MO-IRL 通过在最大熵逆强化学习公式中缩放观察到的和生成的轨迹来迭代细化成本权重，相比经典的逆强化学习方法，极大地减少了所需的演示次数和收敛时间。在每种姿态上训练十次试验，分别得到六段和八段权重划分的平均关节角度均方根误差（RMSE）为6.4°和5.6°，而使用单一静态权重时为10.4°。交叉验证剩余试验，并首次在未见过的受试者20次试验上进行跨个体验证，显示出相近的预测准确性，约8°的RMSE，表明具有稳健的泛化能力。学习到的成本权重在运动开始和终止时强调关节加速度的最小化，与生物运动中观察到的平滑性原则一致。这些结果表明，MO-IRL 可以高效地揭示人类运动控制背后的动态、个体间一致的成本结构，具有应用于类人机器人的潜力。', 'title_zh': '从最少观测中学习人类伸手最优原则的逆强化学习'}
{'arxiv_id': 'arXiv:2510.00272', 'title': 'BC-MPPI: A Probabilistic Constraint Layer for Safe Model-Predictive Path-Integral Control', 'authors': 'Odichimnma Ezeji, Michael Ziegltrum, Giulio Turrisi, Tommaso Belvedere, Valerio Modugno', 'link': 'https://arxiv.org/abs/2510.00272', 'abstract': 'Model Predictive Path Integral (MPPI) control has recently emerged as a fast, gradient-free alternative to model-predictive control in highly non-linear robotic tasks, yet it offers no hard guarantees on constraint satisfaction. We introduce Bayesian-Constraints MPPI (BC-MPPI), a lightweight safety layer that attaches a probabilistic surrogate to every state and input constraint. At each re-planning step the surrogate returns the probability that a candidate trajectory is feasible; this joint probability scales the weight given to a candidate, automatically down-weighting rollouts likely to collide or exceed limits and pushing the sampling distribution toward the safe subset; no hand-tuned penalty costs or explicit sample rejection required. We train the surrogate from 1000 offline simulations and deploy the controller on a quadrotor in MuJoCo with both static and moving obstacles. Across K in [100,1500] rollouts BC-MPPI preserves safety margins while satisfying the prescribed probability of violation. Because the surrogate is a stand-alone, version-controlled artefact and the runtime safety score is a single scalar, the approach integrates naturally with verification-and-validation pipelines for certifiable autonomous systems.', 'abstract_zh': '贝叶斯约束MPPI（BC-MPPI）：一种轻量级的安全层', 'title_zh': 'BC-MPPI: 一种用于安全模型预测路径积分控制的概率约束层'}
{'arxiv_id': 'arXiv:2510.00225', 'title': 'TGPO: Temporal Grounded Policy Optimization for Signal Temporal Logic Tasks', 'authors': 'Yue Meng, Fei Chen, Chuchu Fan', 'link': 'https://arxiv.org/abs/2510.00225', 'abstract': 'Learning control policies for complex, long-horizon tasks is a central challenge in robotics and autonomous systems. Signal Temporal Logic (STL) offers a powerful and expressive language for specifying such tasks, but its non-Markovian nature and inherent sparse reward make it difficult to be solved via standard Reinforcement Learning (RL) algorithms. Prior RL approaches focus only on limited STL fragments or use STL robustness scores as sparse terminal rewards. In this paper, we propose TGPO, Temporal Grounded Policy Optimization, to solve general STL tasks. TGPO decomposes STL into timed subgoals and invariant constraints and provides a hierarchical framework to tackle the problem. The high-level component of TGPO proposes concrete time allocations for these subgoals, and the low-level time-conditioned policy learns to achieve the sequenced subgoals using a dense, stage-wise reward signal. During inference, we sample various time allocations and select the most promising assignment for the policy network to rollout the solution trajectory. To foster efficient policy learning for complex STL with multiple subgoals, we leverage the learned critic to guide the high-level temporal search via Metropolis-Hastings sampling, focusing exploration on temporally feasible solutions. We conduct experiments on five environments, ranging from low-dimensional navigation to manipulation, drone, and quadrupedal locomotion. Under a wide range of STL tasks, TGPO significantly outperforms state-of-the-art baselines (especially for high-dimensional and long-horizon cases), with an average of 31.6% improvement in task success rate compared to the best baseline. The code will be available at this https URL', 'abstract_zh': '学习复杂长期任务的控制策略是机器人技术和自主系统领域的一个核心挑战。Signal Temporal Logic (STL) 提供了一种强大且表达力强的语言来指定此类任务，但由于其非马尔可夫性质和固有的稀疏奖励，通过标准强化学习 (RL) 算法解决它颇具难度。先前的 RL 方法仅关注有限的 STL 片段，或使用 STL 坚固性分数作为稀疏终态奖励。在本文中，我们提出了 TGPO（Temporal Grounded Policy Optimization），以解决通用的 STL 任务。TGPO 将 STL 分解为时间子目标和不变约束，并提供了一个分层框架来解决这个问题。TGPO 的高层组件为这些子目标提供具体的时间分配，而低层时间条件策略则学习使用密集的阶段奖励信号来实现按序排列的子目标。在推断过程中，我们采样不同的时间分配，并选择最有希望的分配供策略网络通过执行解算轨迹。为了促进复杂多子目标 STL 的高效策略学习，我们利用所学习的评论者通过 Metropolis-Hastings 抽样引导高层时间搜索，将探索重点放在时间可行的解决方案上。我们在五个环境中进行了实验，从低维度导航到操作、无人机和四足运动。在广泛的 STL 任务下，TGPO 显著优于最先进的基线（特别是在高维度和长期情况下），平均任务成功率提高了 31.6%。代码将在以下网址获取：this https URL', 'title_zh': 'TGPO: 时间依托策略优化方法用于信号时序逻辑任务'}
{'arxiv_id': 'arXiv:2510.00188', 'title': 'A Novel Robust Control Method Combining DNN-Based NMPC Approximation and PI Control: Application to Exoskeleton Squat Movements', 'authors': 'Alireza Aliyari, Gholamreza Vossoughi', 'link': 'https://arxiv.org/abs/2510.00188', 'abstract': 'Nonlinear Model Predictive Control (NMPC) is a precise controller, but its heavy computational load often prevents application in robotic systems. Some studies have attempted to approximate NMPC using deep neural networks (NMPC-DNN). However, in the presence of unexpected disturbances or when operating conditions differ from training data, this approach lacks robustness, leading to large tracking errors. To address this issue, for the first time, the NMPC-DNN output is combined with a PI controller (Hybrid NMPC-DNN-PI). The proposed controller is validated by applying it to an exoskeleton robot during squat movement, which has a complex dynamic model and has received limited attention regarding robust nonlinear control design. A human-robot dynamic model with three active joints (ankle, knee, hip) is developed, and more than 5.3 million training samples are used to train the DNN. The results show that, under unseen conditions for the DNN, the tracking error in Hybrid NMPC-DNN-PI is significantly lower compared to NMPC-DNN. Moreover, human joint torques are greatly reduced with the use of the exoskeleton, with RMS values for the studied case reduced by 30.9%, 41.8%, and 29.7% at the ankle, knee, and hip, respectively. In addition, the computational cost of Hybrid NMPC-DNN-PI is 99.93% lower than that of NMPC.', 'abstract_zh': '基于NMPC-DNN与PI控制器的混合控制策略及其在下蹲运动exo机器人中的应用', 'title_zh': '一种结合基于DNN的NMPC逼近和PI控制的新型鲁棒控制方法：应用于外骨骼深蹲运动'}
{'arxiv_id': 'arXiv:2510.00182', 'title': 'A Systematic Study of Large Language Models for Task and Motion Planning With PDDLStream', 'authors': 'Jorge Mendez-Mendez', 'link': 'https://arxiv.org/abs/2510.00182', 'abstract': 'Using large language models (LLMs) to solve complex robotics problems requires understanding their planning capabilities. Yet while we know that LLMs can plan on some problems, the extent to which these planning capabilities cover the space of robotics tasks is unclear. One promising direction is to integrate the semantic knowledge of LLMs with the formal reasoning of task and motion planning (TAMP). However, the myriad of choices for how to integrate LLMs within TAMP complicates the design of such systems. We develop 16 algorithms that use Gemini 2.5 Flash to substitute key TAMP components. Our zero-shot experiments across 4,950 problems and three domains reveal that the Gemini-based planners exhibit lower success rates and higher planning times than their engineered counterparts. We show that providing geometric details increases the number of task-planning errors compared to pure PDDL descriptions, and that (faster) non-reasoning LLM variants outperform (slower) reasoning variants in most cases, since the TAMP system can direct the LLM to correct its mistakes.', 'abstract_zh': '使用大规模语言模型（LLMs）解决复杂机器人问题需要理解其规划能力。然而，尽管我们知道LLMs可以在某些问题上进行规划，但其规划能力覆盖机器人任务空间的程度尚不明确。一种有前景的方向是将LLMs的语义知识与任务和运动规划（TAMP）的形式推理相结合。然而，将LLMs整合到TAMP中的众多选择使这样的系统设计变得复杂。我们开发了16种算法，使用Gemini 2.5 Flash替换关键TAMP组件。跨4950个问题和三个领域的零样本实验表明，基于Gemini的规划者在成功率和规划时间上低于其工程化的对应者。我们展示了提供几何细节会增加任务规划错误的数量，与纯PDDL描述相比，并且在大多数情况下，更快的非推理LLM变体优于更慢的推理变体，因为TAMP系统可以指导LLM纠正其错误。', 'title_zh': '大规模语言模型用于任务与运动规划的系统性研究——基于PDDLStream'}
{'arxiv_id': 'arXiv:2510.00154', 'title': 'RoboPilot: Generalizable Dynamic Robotic Manipulation with Dual-thinking Modes', 'authors': 'Xinyi Liu, Mohammadreza Fani Sani, Zewei Zhou, Julius Wirbel, Bahram Zarrin, Roberto Galeazzi', 'link': 'https://arxiv.org/abs/2510.00154', 'abstract': 'Despite rapid progress in autonomous robotics, executing complex or long-horizon tasks remains a fundamental challenge. Most current approaches follow an open-loop paradigm with limited reasoning and no feedback, resulting in poor robustness to environmental changes and severe error accumulation. We present RoboPilot, a dual-thinking closed-loop framework for robotic manipulation that supports adaptive reasoning for complex tasks in real-world dynamic environments. RoboPilot leverages primitive actions for structured task planning and flexible action generation, while introducing feedback to enable replanning from dynamic changes and execution errors. Chain-of-Thought reasoning further enhances high-level task planning and guides low-level action generation. The system dynamically switches between fast and slow thinking to balance efficiency and accuracy. To systematically evaluate the robustness of RoboPilot in diverse robot manipulation scenarios, we introduce RoboPilot-Bench, a benchmark spanning 21 tasks across 10 categories, including infeasible-task recognition and failure recovery. Experiments show that RoboPilot outperforms state-of-the-art baselines by 25.9\\% in task success rate, and the real-world deployment on an industrial robot further demonstrates its robustness in real-world settings.', 'abstract_zh': '尽管自主机器人取得了 rapid progress，执行复杂或长期任务仍是基本挑战。大多数当前方法遵循开放环 paradigm，缺乏推理且没有反馈，导致对环境变化的鲁棒性差和严重错误累积。我们提出 RoboPilot，一种双思考封闭环框架，用于在动态环境中支持复杂任务的自适应推理。RoboPilot 利用原始动作进行结构化任务规划和灵活的动作生成，同时引入反馈以适应动态变化和执行错误。链式推理进一步增强高层任务规划并指导低层动作生成。系统动态切换快速和慢速思考以平衡效率和准确性。为了系统地评估 RoboPilot 在多种机器人操作场景中的鲁棒性，我们引入了 RoboPilot-Bench，一个涵盖 10 类别 21 项任务的基准，包括不可行任务识别和故障恢复。实验表明，RoboPilot 在任务成功率上比最先进的 baselines 高出 25.9%，实际部署在工业机器人上进一步证明了其在现实环境中的鲁棒性。', 'title_zh': 'RoboPilot: 双模式通用动力学机器人 manipulation'}
{'arxiv_id': 'arXiv:2510.01126', 'title': 'Strategic Fusion of Vision Language Models: Shapley-Credited Context-Aware Dawid-Skene for Multi-Label Tasks in Autonomous Driving', 'authors': 'Yuxiang Feng, Keyang Zhang, Hassane Ouchouid, Ashwil Kaniamparambil, Ioannis Souflas, Panagiotis Angeloudis', 'link': 'https://arxiv.org/abs/2510.01126', 'abstract': "Large vision-language models (VLMs) are increasingly used in autonomous-vehicle (AV) stacks, but hallucination limits their reliability in safety-critical pipelines. We present Shapley-credited Context-Aware Dawid-Skene with Agreement, a game-theoretic fusion method for multi-label understanding of ego-view dashcam video. It learns per-model, per-label, context-conditioned reliabilities from labelled history and, at inference, converts each model's report into an agreement-guardrailed log-likelihood ratio that is combined with a contextual prior and a public reputation state updated via Shapley-based team credit. The result is calibrated, thresholdable posteriors that (i) amplify agreement among reliable models, (ii) preserve uniquely correct single-model signals, and (iii) adapt to drift. To specialise general VLMs, we curate 1,000 real-world dashcam clips with structured annotations (scene description, manoeuvre recommendation, rationale) via an automatic pipeline that fuses HDD ground truth, vehicle kinematics, and YOLOv11 + BoT-SORT tracking, guided by a three-step chain-of-thought prompt; three heterogeneous VLMs are then fine-tuned with LoRA. We evaluate with Hamming distance, Micro-Macro-F1, and average per-video latency. Empirically, the proposed method achieves a 23% reduction in Hamming distance, 55% improvement in Macro-F1, and 47% improvement in Micro-F1 when comparing with the best single model, supporting VLM fusion as a calibrated, interpretable, and robust decision-support component for AV pipelines.", 'abstract_zh': '基于Shapley值的适应性Dawid-Skene融合方法：用于自主车辆堆栈中的自我视角行车记录仪视频多标签理解', 'title_zh': '视觉语言模型的战略融合：基于Shapley值的上下文aware Dawid-Skene模型在自主驾驶多标签任务中的应用'}
{'arxiv_id': 'arXiv:2510.01059', 'title': 'Predictive Control Barrier Functions for Discrete-Time Linear Systems with Unmodeled Delays', 'authors': 'Juan Augusto Paredes Salazar, James Usevitch, Ankit Goel', 'link': 'https://arxiv.org/abs/2510.01059', 'abstract': 'This paper introduces a predictive control barrier function (PCBF) framework for enforcing state constraints in discrete-time systems with unknown relative degree, which can be caused by input delays or unmodeled input dynamics. Existing discrete-time CBF formulations typically require the construction of auxiliary barrier functions when the relative degree is greater than one, which complicates implementation and may yield conservative safe sets. The proposed PCBF framework addresses this challenge by extending the prediction horizon to construct a CBF for an associated system with relative degree one. As a result, the superlevel set of the PCBF coincides with the safe set, simplifying constraint enforcement and eliminating the need for auxiliary functions. The effectiveness of the proposed method is demonstrated on a discrete-time double integrator with input delay and a bicopter system with position constraints.', 'abstract_zh': '基于未知相对度的离散时间系统预测控制障碍函数框架', 'title_zh': '离散时间线性系统中未建模延迟的预测控制屏障函数'}
{'arxiv_id': 'arXiv:2510.01049', 'title': 'KeySG: Hierarchical Keyframe-Based 3D Scene Graphs', 'authors': 'Abdelrhman Werby, Dennis Rotondi, Fabio Scaparro, Kai O. Arras', 'link': 'https://arxiv.org/abs/2510.01049', 'abstract': "In recent years, 3D scene graphs have emerged as a powerful world representation, offering both geometric accuracy and semantic richness. Combining 3D scene graphs with large language models enables robots to reason, plan, and navigate in complex human-centered environments. However, current approaches for constructing 3D scene graphs are semantically limited to a predefined set of relationships, and their serialization in large environments can easily exceed an LLM's context window. We introduce KeySG, a framework that represents 3D scenes as a hierarchical graph consisting of floors, rooms, objects, and functional elements, where nodes are augmented with multi-modal information extracted from keyframes selected to optimize geometric and visual coverage. The keyframes allow us to efficiently leverage VLM to extract scene information, alleviating the need to explicitly model relationship edges between objects, enabling more general, task-agnostic reasoning and planning. Our approach can process complex and ambiguous queries while mitigating the scalability issues associated with large scene graphs by utilizing a hierarchical retrieval-augmented generation (RAG) pipeline to extract relevant context from the graph. Evaluated across four distinct benchmarks --including 3D object segmentation and complex query retrieval-- KeySG outperforms prior approaches on most metrics, demonstrating its superior semantic richness and efficiency.", 'abstract_zh': '近年来，3D 场景图已成为一种强大的世界表示形式，提供了几何精确性和语义丰富性。将3D 场景图与大规模语言模型结合，使机器人能够对在复杂的人本环境中进行推理、规划和导航。然而，当前构建3D 场景图的方法在语义上局限于预定义的关系集，其在大规模环境中的序列化可能会很容易超出语言模型的上下文窗口。我们引入了KeySG框架，该框架将3D 场景表示为一个分层图，包含楼层、房间、物体和功能性元素，节点通过从优化几何和视觉覆盖的关键帧中提取的多模态信息进行扩充。关键帧使我们能够高效地利用视觉语言模型提取场景信息，减少了显式建模物体间关系边的需求，从而实现更具通用性、任务无关的推理和规划。该方法能够在处理复杂和模糊查询时，通过利用分层检索增强生成（RAG）管道从图中提取相关上下文，缓解大规模场景图相关的问题。在四个不同的基准测试中，包括3D物体分割和复杂查询检索，KeySG在大多数指标上优于先前的方法，证明了其卓越的语义丰富性和效率。', 'title_zh': 'KeySG：基于分层关键帧的3D场景图'}
{'arxiv_id': 'arXiv:2510.00425', 'title': 'Conflict-Based Search as a Protocol: A Multi-Agent Motion Planning Protocol for Heterogeneous Agents, Solvers, and Independent Tasks', 'authors': 'Rishi Veerapaneni, Alvin Tang, Haodong He, Sophia Zhao, Viraj Shah, Yidai Cen, Ziteng Ji, Gabriel Olin, Jon Arrizabalaga, Yorai Shaoul, Jiaoyang Li, Maxim Likhachev', 'link': 'https://arxiv.org/abs/2510.00425', 'abstract': 'Imagine the future construction site, hospital, office, or even sophisticated household with dozens of robots bought from different manufacturers. How can we enable these different systems to effectively move in a shared environment, given that each robot may have its own independent motion planning system? This work shows how we can get efficient collision-free movements between algorithmically heterogeneous agents by using Conflict-Based Search (Sharon et al. 2015) as a protocol. At its core, the CBS Protocol requires one specific single-agent motion planning API; finding a collision-free path that satisfies certain space-time constraints. Given such an API, CBS uses a central planner to find collision-free paths - independent of how the API is implemented. We show how this protocol enables multi-agent motion planning for a heterogeneous team of agents completing independent tasks with a variety of single-agent planners including: Heuristic Search (e.g., A*), Sampling Based Search (e.g., RRT), Optimization (e.g., Direct Collocation), Diffusion, and Reinforcement Learning.', 'abstract_zh': '想象未来的建筑工地、医院、办公室，甚至是拥有几十台来自不同制造商机器人的复杂家庭。如何在这些不同的系统能够有效共享同一环境进行移动，尤其是每台机器人可能具有独立的运动规划系统时？本研究展示了如何通过使用冲突基于搜索（CBS，Sharon等，2015）协议来实现算法异构代理之间的高效无碰撞移动。CBS协议的核心在于需要一个特定的单一代理运动规划API；即在满足特定空间时间约束的前提下，寻找一条无碰撞路径。利用这样一个API，CBS使用一个中央规划器来找到无碰撞路径——这与API的实现方式无关。我们展示了如何通过这种协议实现异构多代理团队的运动规划，该团队由各种单一代理规划器独立完成任务，包括启发式搜索（例如A*）、采样基于搜索（例如RRT）、优化（例如直接共轭）、扩散以及强化学习。', 'title_zh': '基于冲突的搜索作为一种协议：异构代理、求解器和独立任务的多Agent运动规划协议'}
{'arxiv_id': 'arXiv:2510.00405', 'title': 'EgoTraj-Bench: Towards Robust Trajectory Prediction Under Ego-view Noisy Observations', 'authors': 'Jiayi Liu, Jiaming Zhou, Ke Ye, Kun-Yu Lin, Allan Wang, Junwei Liang', 'link': 'https://arxiv.org/abs/2510.00405', 'abstract': "Reliable trajectory prediction from an ego-centric perspective is crucial for robotic navigation in human-centric environments. However, existing methods typically assume idealized observation histories, failing to account for the perceptual artifacts inherent in first-person vision, such as occlusions, ID switches, and tracking drift. This discrepancy between training assumptions and deployment reality severely limits model robustness. To bridge this gap, we introduce EgoTraj-Bench, the first real-world benchmark that grounds noisy, first-person visual histories in clean, bird's-eye-view future trajectories, enabling robust learning under realistic perceptual constraints. Building on this benchmark, we propose BiFlow, a dual-stream flow matching model that concurrently denoises historical observations and forecasts future motion by leveraging a shared latent representation. To better model agent intent, BiFlow incorporates our EgoAnchor mechanism, which conditions the prediction decoder on distilled historical features via feature modulation. Extensive experiments show that BiFlow achieves state-of-the-art performance, reducing minADE and minFDE by 10-15% on average and demonstrating superior robustness. We anticipate that our benchmark and model will provide a critical foundation for developing trajectory forecasting systems truly resilient to the challenges of real-world, ego-centric perception.", 'abstract_zh': '从自我中心视角进行可靠的轨迹预测是人类中心环境中机器人导航的关键。然而，现有方法通常假设理想化的观察历史，忽略了第一人称视觉固有的感知失真，如遮挡、ID切换和跟踪漂移。这种训练假设与部署现实之间的不匹配严重限制了模型的 robustness。为了弥合这一差距，我们引入了EgoTraj-Bench，这是首个将嘈杂的第一人称视觉历史与清洁的鸟瞰未来轨迹联系起来的真实世界基准，使模型能够在现实的感知约束下进行 robust 学习。基于这一基准，我们提出了BiFlow，一种双流流匹配模型，通过利用共享的潜在表示同时去噪历史观察并预测未来运动。为了更好地建模代理意图，BiFlow 引入了我们的 EgoAnchor 机制，通过特征调节对预测解码器进行条件化。大量实验表明，BiFlow 达到了最先进的性能，平均将 minADE 和 minFDE 减少 10-15%，并表现出更强的 robustness。我们预计，我们的基准和模型将为构建真正能应对现实自我中心感知挑战的轨迹预测系统提供关键基础。', 'title_zh': 'EgoTraj-Bench：在自我视角噪声观测下的稳健轨迹预测'}
{'arxiv_id': 'arXiv:2510.00259', 'title': 'A Hierarchical Agentic Framework for Autonomous Drone-Based Visual Inspection', 'authors': 'Ethan Herron, Xian Yeow Lee, Gregory Sin, Teresa Gonzalez Diaz, Ahmed Farahat, Chetan Gupta', 'link': 'https://arxiv.org/abs/2510.00259', 'abstract': 'Autonomous inspection systems are essential for ensuring the performance and longevity of industrial assets. Recently, agentic frameworks have demonstrated significant potential for automating inspection workflows but have been limited to digital tasks. Their application to physical assets in real-world environments, however, remains underexplored. In this work, our contributions are two-fold: first, we propose a hierarchical agentic framework for autonomous drone control, and second, a reasoning methodology for individual function executions which we refer to as ReActEval. Our framework focuses on visual inspection tasks in indoor industrial settings, such as interpreting industrial readouts or inspecting equipment. It employs a multi-agent system comprising a head agent and multiple worker agents, each controlling a single drone. The head agent performs high-level planning and evaluates outcomes, while worker agents implement ReActEval to reason over and execute low-level actions. Operating entirely in natural language, ReActEval follows a plan, reason, act, evaluate cycle, enabling drones to handle tasks ranging from simple navigation (e.g., flying forward 10 meters and land) to complex high-level tasks (e.g., locating and reading a pressure gauge). The evaluation phase serves as a feedback and/or replanning stage, ensuring actions align with user objectives while preventing undesirable outcomes. We evaluate the framework in a simulated environment with two worker agents, assessing performance qualitatively and quantitatively based on task completion across varying complexity levels and workflow efficiency. By leveraging natural language processing for agent communication, our approach offers a novel, flexible, and user-accessible alternative to traditional drone-based solutions, enabling autonomous problem-solving for industrial inspection without extensive user intervention.', 'abstract_zh': '自主检查系统对于确保工业资产的性能和 longevity 至关重要。近期，代理框架展示了在自动化检查流程方面的重要潜力，但仅限于数字任务。然而，将其应用于真实环境中物理资产的使用仍相对少见。在此工作中，我们的贡献主要有两项：首先，我们提出了一种分层的代理框架，用于自主无人机控制；其次，提出了一种针对单个功能执行的推理方法，我们称之为 ReActEval。该框架专注于室内工业环境中的视觉检查任务，如解释工业读数或检查设备。该框架采用多功能代理系统，包括一个主代理和多个工人代理，每个工人代理控制一架单无人机。主代理进行高层次规划并评估结果，而工人代理则执行 ReActEval，通过推理和执行低级动作来实现任务目标。整个过程完全基于自然语言，ReActEval 遵循计划、推理、执行、评估的循环，使得无人机能够处理从简单导航（如向前飞行 10 米并降落）到复杂高层次任务（如定位并读取压力表）的任务。评估阶段作为反馈和/或重新规划的阶段，确保行动符合用户目标并防止不利结果。我们通过使用两个工人代理的模拟环境来评估该框架，基于任务完成程度和复杂度以及工作流程效率进行定性和定量评估。通过利用自然语言处理进行代理之间的通信，我们的方法提供了一种新颖、灵活且用户友好的替代传统无人机解决方案，使工业检查能够实现自主问题解决，而无需大量用户干预。', 'title_zh': '基于自主无人机的可视化检测分层代理框架'}
{'arxiv_id': 'arXiv:2510.00208', 'title': 'Robust Attitude Control of Nonlinear Multi-Rotor Dynamics with LFT Models and $\\mathcal{H}_\\infty$ Performance', 'authors': 'Tanay Kumar, Raktim Bhattacharya', 'link': 'https://arxiv.org/abs/2510.00208', 'abstract': 'Attitude stabilization of unmanned aerial vehicles in uncertain environments presents significant challenges due to nonlinear dynamics, parameter variations, and sensor limitations. This paper presents a comparative study of $\\mathcal{H}_\\infty$ and classical PID controllers for multi-rotor attitude regulation in the presence of wind disturbances and gyroscope noise. The flight dynamics are modeled using a linear parameter-varying (LPV) framework, where nonlinearities and parameter variations are systematically represented as structured uncertainties within a linear fractional transformation formulation. A robust controller based on $\\mathcal{H}_\\infty$ formulation is designed using only gyroscope measurements to ensure guaranteed performance bounds. Nonlinear simulation results demonstrate the effectiveness of the robust controllers compared to classical PID control, showing significant improvement in attitude regulation under severe wind disturbances.', 'abstract_zh': '不确定环境中多旋翼无人机姿态稳定控制面对非线性动力学、参数变化和传感器限制的挑战。本文对风干扰和陀螺仪噪声下多旋翼姿态调节的$\\mathcal{H}_\\infty$和经典PID控制器进行了比较研究。飞行动力学采用线性参数变异（LPV）框架建模，其中非线性和参数变化系统地表示为线性分数变换形式中的结构不确定性。基于$\\mathcal{H}_\\infty$公式设计了一个仅使用陀螺仪测量的鲁棒控制器，以确保性能边界。非线性仿真结果表明，鲁棒控制器在严重风干扰下的姿态调节效果优于经典PID控制。', 'title_zh': '基于LFT模型和$\\mathcal{H}_\\infty$性能的非线性多旋翼动力学鲁棒姿态控制'}
{'arxiv_id': 'arXiv:2510.00167', 'title': 'Drones that Think on their Feet: Sudden Landing Decisions with Embodied AI', 'authors': 'Diego Ortiz Barbosa, Mohit Agrawal, Yash Malegaonkar, Luis Burbano, Axel Andersson, György Dán, Henrik Sandberg, Alvaro A. Cardenas', 'link': 'https://arxiv.org/abs/2510.00167', 'abstract': 'Autonomous drones must often respond to sudden events, such as alarms, faults, or unexpected changes in their environment, that require immediate and adaptive decision-making. Traditional approaches rely on safety engineers hand-coding large sets of recovery rules, but this strategy cannot anticipate the vast range of real-world contingencies and quickly becomes incomplete. Recent advances in embodied AI, powered by large visual language models, provide commonsense reasoning to assess context and generate appropriate actions in real time. We demonstrate this capability in a simulated urban benchmark in the Unreal Engine, where drones dynamically interpret their surroundings and decide on sudden maneuvers for safe landings. Our results show that embodied AI makes possible a new class of adaptive recovery and decision-making pipelines that were previously infeasible to design by hand, advancing resilience and safety in autonomous aerial systems.', 'abstract_zh': '自主无人机必须应对突然事件（如警报、故障或环境的意外变化），这些事件需要立即且适应性的决策。传统方法依赖于安全工程师手动编写大量的恢复规则，但这一策略无法预见到广泛的实际 contingencies，并且很快变得不完整。最近基于体态人工智能的进步，由大型视觉语言模型驱动，提供了常识推理能力，能够实时评估环境并生成恰当的动作。我们在 Unreal Engine 中的模拟城市基准中展示了这一能力，其中无人机动态解释其周围的环境并决定突然的机动动作以实现安全着陆。我们的结果表明，体态人工智能使得设计之前难以手工实现的新型适应性恢复和决策管道成为可能，从而在自主航空系统中推动了韧性和安全性的发展。', 'title_zh': '能够灵活决策的无人机：基于体化AI的突然着陆决定'}
{'arxiv_id': 'arXiv:2510.00120', 'title': 'The Formation of Trust in Autonomous Vehicles after Interacting with Robotaxis on Public Roads', 'authors': 'Xiang Chang, Zhijie Yi, Yichang Liu, Hongling Sheng, Dengbo He', 'link': 'https://arxiv.org/abs/2510.00120', 'abstract': 'This study investigates how pedestrian trust, receptivity, and behavior evolve during interactions with Level-4 autonomous vehicles (AVs) at uncontrolled urban intersections in a naturalistic setting. While public acceptance is critical for AV adoption, most prior studies relied on simplified simulations or field tests. We conducted a real-world experiment in a commercial Robotaxi operation zone, where 33 participants repeatedly crossed an uncontrolled intersection with frequent Level-4 Robotaxi traffic. Participants completed the Pedestrian Behavior Questionnaire (PBQ), Pedestrian Receptivity Questionnaire for Fully AVs (PRQF), pre- and post-experiment Trust in AVs Scale, and Personal Innovativeness Scale (PIS). Results showed that trust in AVs significantly increased post-experiment, with the increase positively associated with the Interaction component of PRQF. Additionally, both the Positive and Error subscales of the PBQ significantly influenced trust change. This study reveals how trust forms in real-world pedestrian-AV encounters, offering insights beyond lab-based research by accounting for population heterogeneity.', 'abstract_zh': '本研究探讨了行人与未设交通信号控制的城市交叉口处的四级自动驾驶车辆（AVs）互动过程中，行人信任、接受度和行为如何演变。在真实环境中，我们在中国一家商用Robotaxi运营区进行了实验，33名参与者频繁与四级Robotaxi交通互动后穿过一个未设交通信号控制的交叉口。参与者完成了行人行为问卷（PBQ）、全自动驾驶车辆接受度问卷（PRQF）、实验前后的AVs信任量表以及个人创新度量表（PIS）。结果显示，实验后行人对AVs的信任显著增加，且这种增加与PRQF的互动成分正相关。此外，PBQ的积极成分和错误成分显著影响了信任的变化。本研究揭示了在真实世界行人-AV相遇中信任形成的机制，通过考虑人群异质性提供了超越基于实验室研究的见解。', 'title_zh': '公共道路上与Robotaxi交互后自动驾驶车辆信任形成的机制'}
{'arxiv_id': 'arXiv:2510.00060', 'title': 'Less is More: Lean yet Powerful Vision-Language Model for Autonomous Driving', 'authors': 'Sheng Yang, Tong Zhan, Guancheng Chen, Yanfeng Lu, Jian Wang', 'link': 'https://arxiv.org/abs/2510.00060', 'abstract': 'In this work, we reconceptualize autonomous driving as a generalized language and formulate the trajectory planning task as next waypoint prediction. We introduce Max-V1, a novel framework for one-stage end-to-end autonomous driving. Our framework presents a single-pass generation paradigm that aligns with the inherent sequentiality of driving. This approach leverages the generative capacity of the VLM (Vision-Language Model) to enable end-to-end trajectory prediction directly from front-view camera input. The efficacy of this method is underpinned by a principled supervision strategy derived from statistical modeling. This provides a well-defined learning objective, which makes the framework highly amenable to master complex driving policies through imitation learning from large-scale expert demonstrations. Empirically, our method achieves the state-of-the-art performance on the nuScenes dataset, delivers an overall improvement of over 30% compared to prior baselines. Furthermore, it exhibits superior generalization performance on cross-domain datasets acquired from diverse vehicles, demonstrating notable potential for cross-vehicle robustness and adaptability. Due to these empirical strengths, this work introduces a model enabling fundamental driving behaviors, laying the foundation for the development of more capable self-driving agents. Code will be available upon publication.', 'abstract_zh': '本研究重新构想自动驾驶为一种通用语言，并将轨迹规划任务形式化为下一步 waypoints 预测。我们提出了 Max-V1，一种新型的一阶段端到端自动驾驶框架。该框架采用单次生成范式，符合驾驶的固有顺序性。该方法利用 VLM（视觉-语言模型）的生成能力，直接从前视摄像头输入进行端到端轨迹预测。该方法的有效性基于源自统计建模的原则性监督策略，这为通过大规模专家演示进行模仿学习掌握复杂驾驶策略提供了清晰的學習目标。实验上，我们的方法在 nuScenes 数据集上达到了最先进的性能，相对于之前基线提高了超过 30%。此外，该方法在不同车辆获取的跨域数据集上表现出优异的泛化性能，显示出跨车辆鲁棒性和适应性的显著潜力。由于这些实验优势，本研究引入了一种模型，使基本驾驶行为成为可能，并为开发更强大的自动驾驶代理奠定了基础。代码将在发表后公开。', 'title_zh': '少即是多：轻量而强大的自主驾驶视觉-语言模型'}
