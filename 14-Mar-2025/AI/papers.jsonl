{'arxiv_id': 'arXiv:2503.10628', 'title': 'Uncertainty in Action: Confidence Elicitation in Embodied Agents', 'authors': 'Tianjiao Yu, Vedant Shah, Muntasir Wahed, Kiet A. Nguyen, Adheesh Juvekar, Tal August, Ismini Lourentzou', 'link': 'https://arxiv.org/abs/2503.10628', 'abstract': 'Expressing confidence is challenging for embodied agents navigating dynamic multimodal environments, where uncertainty arises from both perception and decision-making processes. We present the first work investigating embodied confidence elicitation in open-ended multimodal environments. We introduce Elicitation Policies, which structure confidence assessment across inductive, deductive, and abductive reasoning, along with Execution Policies, which enhance confidence calibration through scenario reinterpretation, action sampling, and hypothetical reasoning. Evaluating agents in calibration and failure prediction tasks within the Minecraft environment, we show that structured reasoning approaches, such as Chain-of-Thoughts, improve confidence calibration. However, our findings also reveal persistent challenges in distinguishing uncertainty, particularly under abductive settings, underscoring the need for more sophisticated embodied confidence elicitation methods.', 'abstract_zh': '在动态多模态环境中的自主体表达信心具有挑战性：从感知和决策过程中的不确定性出发，探究开放多模态环境中的信心引出', 'title_zh': '行动中的不确定性：体态代理的信心征询'}
{'arxiv_id': 'arXiv:2503.10619', 'title': 'Siege: Autonomous Multi-Turn Jailbreaking of Large Language Models with Tree Search', 'authors': 'Andy Zhou', 'link': 'https://arxiv.org/abs/2503.10619', 'abstract': 'We introduce Siege, a multi-turn adversarial framework that models the gradual erosion of Large Language Model (LLM) safety through a tree search perspective. Unlike single-turn jailbreaks that rely on one meticulously engineered prompt, Siege expands the conversation at each turn in a breadth-first fashion, branching out multiple adversarial prompts that exploit partial compliance from previous responses. By tracking these incremental policy leaks and re-injecting them into subsequent queries, Siege reveals how minor concessions can accumulate into fully disallowed outputs. Evaluations on the JailbreakBench dataset show that Siege achieves a 100% success rate on GPT-3.5-turbo and 97% on GPT-4 in a single multi-turn run, using fewer queries than baselines such as Crescendo or GOAT. This tree search methodology offers an in-depth view of how model safeguards degrade over successive dialogue turns, underscoring the urgency of robust multi-turn testing procedures for language models.', 'abstract_zh': '我们引入了Siege，一种多轮对抗框架，从树搜索的角度建模大型语言模型（LLM）安全性逐渐下降的过程。', 'title_zh': '围城：基于树搜索的自主多轮大语言模型越狱'}
{'arxiv_id': 'arXiv:2503.10479', 'title': 'DeclareAligner: A Leap Towards Efficient Optimal Alignments for Declarative Process Model Conformance Checking', 'authors': 'Jacobo Casas-Ramos, Manuel Lama, Manuel Mucientes', 'link': 'https://arxiv.org/abs/2503.10479', 'abstract': 'In many engineering applications, processes must be followed precisely, making conformance checking between event logs and declarative process models crucial for ensuring adherence to desired behaviors. This is a critical area where Artificial Intelligence (AI) plays a pivotal role in driving effective process improvement. However, computing optimal alignments poses significant computational challenges due to the vast search space inherent in these models. Consequently, existing approaches often struggle with scalability and efficiency, limiting their applicability in real-world settings. This paper introduces DeclareAligner, a novel algorithm that uses the A* search algorithm, an established AI pathfinding technique, to tackle the problem from a fresh perspective leveraging the flexibility of declarative models. Key features of DeclareAligner include only performing actions that actively contribute to fixing constraint violations, utilizing a tailored heuristic to navigate towards optimal solutions, and employing early pruning to eliminate unproductive branches, while also streamlining the process through preprocessing and consolidating multiple fixes into unified actions. The proposed method is evaluated using 8,054 synthetic and real-life alignment problems, demonstrating its ability to efficiently compute optimal alignments by significantly outperforming the current state of the art. By enabling process analysts to more effectively identify and understand conformance issues, DeclareAligner has the potential to drive meaningful process improvement and management.', 'abstract_zh': '在许多工程应用中，必须严格遵循工艺流程，因此事件日志与声明性流程模型之间的符合性检查对于确保遵循预期行为至关重要。这是一个关键领域，人工智能（AI）在推动有效流程改进中扮演着关键角色。然而，计算最优对齐由于这些模型固有的庞大搜索空间而面临重大计算挑战。因此，现有方法往往在可扩展性和效率方面存在局限，限制了其在实际场景中的应用。本文提出了一种名为DeclareAligner的新算法，该算法利用A*搜索算法——一种成熟的AI路径查找技术——从一个新的角度应对这一问题，充分利用声明性模型的灵活性。DeclareAligner的关键特征包括仅执行对修复约束冲突有积极贡献的动作，利用定制的启发式方法导航至最优解，并通过早期剪枝消除无生产力分支，同时通过预处理和技术合并多个修正为统一操作来简化流程。所提出的方法通过对8,054个合成和实际对齐问题的评估，展示了其能够显著优于当前最佳方法高效计算最优对齐的能力。通过使过程分析师更有效地识别和理解符合性问题，DeclareAligner有望推动实际流程的改进和管理。', 'title_zh': 'DeclareAligner: 向声明性过程模型符合性检查的高效最优对齐迈出一步'}
{'arxiv_id': 'arXiv:2503.10265', 'title': 'SurgRAW: Multi-Agent Workflow with Chain-of-Thought Reasoning for Surgical Intelligence', 'authors': 'Chang Han Low, Ziyue Wang, Tianyi Zhang, Zhitao Zeng, Zhu Zhuo, Evangelos B. Mazomenos, Yueming Jin', 'link': 'https://arxiv.org/abs/2503.10265', 'abstract': 'Integration of Vision-Language Models (VLMs) in surgical intelligence is hindered by hallucinations, domain knowledge gaps, and limited understanding of task interdependencies within surgical scenes, undermining clinical reliability. While recent VLMs demonstrate strong general reasoning and thinking capabilities, they still lack the domain expertise and task-awareness required for precise surgical scene interpretation. Although Chain-of-Thought (CoT) can structure reasoning more effectively, current approaches rely on self-generated CoT steps, which often exacerbate inherent domain gaps and hallucinations. To overcome this, we present SurgRAW, a CoT-driven multi-agent framework that delivers transparent, interpretable insights for most tasks in robotic-assisted surgery. By employing specialized CoT prompts across five tasks: instrument recognition, action recognition, action prediction, patient data extraction, and outcome assessment, SurgRAW mitigates hallucinations through structured, domain-aware reasoning. Retrieval-Augmented Generation (RAG) is also integrated to external medical knowledge to bridge domain gaps and improve response reliability. Most importantly, a hierarchical agentic system ensures that CoT-embedded VLM agents collaborate effectively while understanding task interdependencies, with a panel discussion mechanism promotes logical consistency. To evaluate our method, we introduce SurgCoTBench, the first reasoning-based dataset with structured frame-level annotations. With comprehensive experiments, we demonstrate the effectiveness of proposed SurgRAW with 29.32% accuracy improvement over baseline VLMs on 12 robotic procedures, achieving the state-of-the-art performance and advancing explainable, trustworthy, and autonomous surgical assistance.', 'abstract_zh': 'Integrating Vision-Language Models in Surgical Intelligence with SurgRAW: Overcoming Hallucinations and Domain Gaps通过SurgRAW克服幻觉和领域差距，将视觉语言模型集成到手术智能中', 'title_zh': 'SurgRAW: 基于链式思维推理的多agent工作流手术智能化方法'}
{'arxiv_id': 'arXiv:2503.10248', 'title': 'LLM Agents Display Human Biases but Exhibit Distinct Learning Patterns', 'authors': 'Idan Horowitz, Ori Plonsky', 'link': 'https://arxiv.org/abs/2503.10248', 'abstract': 'We investigate the choice patterns of Large Language Models (LLMs) in the context of Decisions from Experience tasks that involve repeated choice and learning from feedback, and compare their behavior to human participants. We find that on the aggregate, LLMs appear to display behavioral biases similar to humans: both exhibit underweighting rare events and correlation effects. However, more nuanced analyses of the choice patterns reveal that this happens for very different reasons. LLMs exhibit strong recency biases, unlike humans, who appear to respond in more sophisticated ways. While these different processes may lead to similar behavior on average, choice patterns contingent on recent events differ vastly between the two groups. Specifically, phenomena such as ``surprise triggers change" and the ``wavy recency effect of rare events" are robustly observed in humans, but entirely absent in LLMs. Our findings provide insights into the limitations of using LLMs to simulate and predict humans in learning environments and highlight the need for refined analyses of their behavior when investigating whether they replicate human decision making tendencies.', 'abstract_zh': '我们探究了在经验决策任务中大型语言模型（LLMs）的决策模式，这些任务涉及重复选择和从反馈中学习，并将其行为与人类参与者的行为进行比较。我们发现总体而言，LLMs 表现出与人类相似的行为偏差：两者都对稀有事件给予不当权重并受到相关性效应的影响。然而，更细致的决策模式分析揭示了这些差异背后的原因有所不同。LLMs 表现出强烈的近期效应偏差，而人类则以更为复杂的方式作出反应。尽管这两种过程在平均表现上可能导致相似的行为，但两种群体基于近期事件的决策模式差异巨大。具体来说，如“惊奇触发变化”和“稀有事件的波状近期效应”等现象在人类中普遍存在，但在LLMs中完全不存在。我们的研究结果为使用LLMs模拟和预测学习环境中的人类行为提供了见解，并强调了在研究它们是否复制人类决策倾向时需要对其行为进行细致分析的必要性。', 'title_zh': 'LLM代理表现出人类偏见但展现出不同的学习模式'}
{'arxiv_id': 'arXiv:2503.10215', 'title': 'Adaptive Preference Aggregation', 'authors': 'Benjamin Heymann', 'link': 'https://arxiv.org/abs/2503.10215', 'abstract': "AI alignment, the challenge of ensuring AI systems act in accordance with human values, has emerged as a critical problem in the development of systems such as foundation models and recommender systems. Still, the current dominant approach, reinforcement learning with human feedback (RLHF) faces known theoretical limitations in aggregating diverse human preferences. Social choice theory provides a framework to aggregate preferences, but was not developed for the multidimensional applications typical of AI. Leveraging insights from a recently published urn process, this work introduces a preference aggregation strategy that adapts to the user's context and that inherits the good properties of the maximal lottery, a Condorcet-consistent solution concept.", 'abstract_zh': 'AI对齐：确保AI系统按照人类价值观行动的挑战已成为基础模型和推荐系统等系统开发中的关键问题。尽管当前主流方法（强化学习结合人类反馈）存在聚合多元人类偏好已知的理论限制，社会选择理论提供了一种聚合偏好框架，但该理论尚未为常见的多维AI应用进行开发。借鉴最近发表的 urn 过程的启示，本研究提出了一种适应用户情境的偏好聚合策略，该策略继承了最大Lottery这一Condorcet一致解概念的良好属性。', 'title_zh': '自适应偏好聚合'}
{'arxiv_id': 'arXiv:2503.10105', 'title': 'StepMathAgent: A Step-Wise Agent for Evaluating Mathematical Processes through Tree-of-Error', 'authors': 'Shu-Xun Yang, Cunxiang Wang, Yidong Wang, Xiaotao Gu, Minlie Huang, Jie Tang', 'link': 'https://arxiv.org/abs/2503.10105', 'abstract': 'Evaluating mathematical capabilities is critical for assessing the overall performance of large language models (LLMs). However, existing evaluation methods often focus solely on final answers, resulting in highly inaccurate and uninterpretable evaluation outcomes, as well as their failure to assess proof or open-ended problems. To address these issues, we propose a novel mathematical process evaluation agent based on Tree-of-Error, called StepMathAgent. This agent incorporates four internal core operations: logical step segmentation, step scoring, score aggregation and error tree generation, along with four external extension modules: difficulty calibration, simplicity evaluation, completeness validation and format assessment. Furthermore, we introduce StepMathBench, a benchmark comprising 1,000 step-divided process evaluation instances, derived from 200 high-quality math problems grouped by problem type, subject category and difficulty level. Experiments on StepMathBench show that our proposed StepMathAgent outperforms all state-of-the-art methods, demonstrating human-aligned evaluation preferences and broad applicability to various scenarios. Our data and code are available at this https URL.', 'abstract_zh': '评估数学能力是评估大型语言模型整体性能的关键。然而，现有的评估方法往往只关注最终答案，导致评估结果高度不准确和不可解释，同时也无法评估证明或开放性问题。为解决这些问题，我们提出一种基于错误树的新型数学过程评估代理，称为StepMathAgent。该代理包含四种内部核心操作：逻辑步骤分割、步骤评分、评分聚合和错误树生成，以及四种外部扩展模块：难度校准、简洁性评估、完整性验证和格式评估。此外，我们介绍了StepMathBench，这是一个包含1000个步骤划分过程评估实例的基准，这些实例来自200道高质量数学问题，按问题类型、主题类别和难度级别分组。实验表明，我们的StepMathAgent在StepMathBench上优于所有最先进的方法，展示了与人类一致的评估偏好并适用于各种场景。我们的数据和代码可在以下链接获取。', 'title_zh': 'StepMathAgent: 一种基于错误树的分步骤评估数学过程的代理模型'}
{'arxiv_id': 'arXiv:2503.10094', 'title': 'Semantic Synergy: Unlocking Policy Insights and Learning Pathways Through Advanced Skill Mapping', 'authors': 'Phoebe Koundouri, Conrad Landis, Georgios Feretzakis', 'link': 'https://arxiv.org/abs/2503.10094', 'abstract': 'This research introduces a comprehensive system based on state-of-the-art natural language processing, semantic embedding, and efficient search techniques for retrieving similarities and thus generating actionable insights from raw textual information. The system automatically extracts and aggregates normalized competencies from multiple documents (such as policy files and curricula vitae) and creates strong relationships between recognized competencies, occupation profiles, and related learning courses. To validate its performance, we conducted a multi-tier evaluation that included both explicit and implicit skill references in synthetic and real-world documents. The results showed near-human-level accuracy, with F1 scores exceeding 0.95 for explicit skill detection and above 0.93 for implicit mentions. The system thereby establishes a sound foundation for supporting in-depth collaboration across the AE4RIA network. The methodology involves a multi-stage pipeline based on extensive preprocessing and data cleaning, semantic embedding and segmentation via SentenceTransformer, and skill extraction using a FAISS-based search method. The extracted skills are associated with occupation frameworks (as formulated in the ESCO ontology) and with learning paths offered through the Sustainable Development Goals Academy. Moreover, interactive visualization software, implemented with Dash and Plotly, presents graphs and tables for real-time exploration and informed decision-making by those involved in policymaking, training and learning supply, career transitions, and recruitment. Overall, this system, backed by rigorous validation, offers promising prospects for improved policymaking, human resource development, and lifelong learning by providing structured and actionable insights from raw, complex textual information.', 'abstract_zh': '基于最新自然语言处理、语义嵌入和高效检索技术的综合系统，用于从原始文本信息中检索相似性并生成可操作洞察', 'title_zh': '语义协同：通过高级技能映射解锁政策洞察和学习路径'}
{'arxiv_id': 'arXiv:2503.10075', 'title': 'Parallelizing Multi-objective A* Search', 'authors': 'Saman Ahmadi, Nathan R. Sturtevant, Andrea Raith, Daniel Harabor, Mahdi Jalili', 'link': 'https://arxiv.org/abs/2503.10075', 'abstract': "The Multi-objective Shortest Path (MOSP) problem is a classic network optimization problem that aims to find all Pareto-optimal paths between two points in a graph with multiple edge costs. Recent studies on multi-objective search with A* (MOA*) have demonstrated superior performance in solving difficult MOSP instances. This paper presents a novel search framework that allows efficient parallelization of MOA* with different objective orders. The framework incorporates a unique upper bounding strategy that helps the search reduce the problem's dimensionality to one in certain cases. Experimental results demonstrate that the proposed framework can enhance the performance of recent A*-based solutions, with the speed-up proportional to the problem dimension.", 'abstract_zh': '多目标最短路径（MOSP）问题是一种经典的网络优化问题，旨在在一个具有多种边成本的图中找到两个点之间的所有帕累托最优路径。最近关于使用A*的多目标搜索（MOA*）的研究证明了其在解决复杂的MOSP实例方面的优越性能。本文提出了一种新的搜索框架，该框架允许在不同的目标顺序下高效地并行化MOA*。该框架包含一种独特的上界策略，有助于在某些情况下减少问题的维度。实验结果表明，所提出的框架能够提升基于A*的解决方案的性能，加速程度与问题维度成正比。', 'title_zh': '并行化多目标A*搜索'}
{'arxiv_id': 'arXiv:2503.10071', 'title': 'Advanced Tool Learning and Selection System (ATLASS): A Closed-Loop Framework Using LLM', 'authors': 'Mohd Ariful Haque, Justin Williams, Sunzida Siddique, Md. Hujaifa Islam, Hasmot Ali, Kishor Datta Gupta, Roy George', 'link': 'https://arxiv.org/abs/2503.10071', 'abstract': 'The combination of LLM agents with external tools enables models to solve complex tasks beyond their knowledge base. Human-designed tools are inflexible and restricted to solutions within the scope of pre-existing tools created by experts. To address this problem, we propose ATLASS, an advanced tool learning and selection system designed as a closed-loop framework. It enables the LLM to solve problems by dynamically generating external tools on demand. In this framework, agents play a crucial role in orchestrating tool selection, execution, and refinement, ensuring adaptive problem-solving capabilities. The operation of ATLASS follows three phases: The first phase, Understanding Tool Requirements, involves the Agents determining whether tools are required and specifying their functionality; the second phase, Tool Retrieval/Generation, involves the Agents retrieving or generating tools based on their availability; and the third phase, Task Solving, involves combining all the component tools necessary to complete the initial task. The Tool Dataset stores the generated tools, ensuring reusability and minimizing inference cost. Current LLM-based tool generation systems have difficulty creating complex tools that need APIs or external packages. In ATLASS, we solve the problem by automatically setting up the environment, fetching relevant API documentation online, and using a Python interpreter to create a reliable, versatile tool that works in a wider range of situations. OpenAI GPT-4.0 is used as the LLM agent, and safety and ethical concerns are handled through human feedback before executing generated code. By addressing the limitations of predefined toolsets and enhancing adaptability, ATLASS serves as a real-world solution that empowers users with dynamically generated tools for complex problem-solving.', 'abstract_zh': 'LLM代理与外部工具的结合使模型能够解决超出其知识库的复杂任务。ATLASS：一种先进的工具学习和选择系统，设计为闭环框架，使LLM能够通过按需动态生成外部工具来解决问题。', 'title_zh': '基于LLM的闭环框架：高级工具学习与选择系统（ATLASS）'}
{'arxiv_id': 'arXiv:2503.10009', 'title': 'OR-LLM-Agent: Automating Modeling and Solving of Operations Research Optimization Problem with Reasoning Large Language Model', 'authors': 'Bowen Zhang, Pengcheng Luo', 'link': 'https://arxiv.org/abs/2503.10009', 'abstract': 'Operations Research (OR) has been widely applied in various fields such as resource allocation, production planning, and supply chain management. However, addressing real-world OR problems requires OR experts to perform mathematical modeling and programmers to develop solution algorithms. This traditional method, heavily reliant on experts, is costly and has long development cycles, severely limiting the widespread adoption of OR techniques. Few have considered using Artificial Intelligence (AI) to replace professionals to achieve fully automated solutions for OR problems. We propose OR-LLM-Agent, the first AI agent that enables end-to-end automation for solving real-world OR problems. OR-LLM-Agent leverages the Chain-of-Thought (CoT) reasoning capabilities of Large Language Models (LLMs) to translate natural language problem descriptions into formal mathematical models and automatically generate Gurobi solver code. In OR-LLM-Agent, OR-CodeAgent is designed to automate code execution and repair within a sandbox environment, facilitating the derivation of the final solution. Due to the lack of dedicated benchmark datasets for evaluating the automated solving of OR problems, we construct a benchmark dataset comprising 83 real-world OR problems described in natural language. We conduct comparative experiments with state-of-the-art (SOTA) reasoning LLMs, including GPT-o3-mini, DeepSeek-R1, and Gemini 2.0 Flash Thinking. The OR-LLM-Agent achieved the highest pass rate of 100% and the highest solution accuracy of 85%, demonstrating the feasibility of automated OR problem-solving. Data and code have been publicly available at this https URL.', 'abstract_zh': 'OR-LLM-Agent：一种用于解决实际运筹学问题的端到端自动化AI代理', 'title_zh': 'OR-LLM-Agent: 利用推理大规模语言模型自动建模和求解运筹优化问题'}
{'arxiv_id': 'arXiv:2503.10003', 'title': 'A New Benchmark for Few-Shot Class-Incremental Learning: Redefining the Upper Bound', 'authors': 'Shiwon Kim, Dongjun Hwang, Sungwon Woo, Rita Singh', 'link': 'https://arxiv.org/abs/2503.10003', 'abstract': 'Class-incremental learning (CIL) aims to continuously adapt to emerging classes while retaining knowledge of previously learned ones. Few-shot class-incremental learning (FSCIL) presents an even greater challenge which requires the model to learn incremental classes with only a limited number of samples. In conventional CIL, joint training is widely considered the upper bound, serving as both a benchmark and a methodological guide. However, we find that joint training fails to be a meaningful upper bound in FSCIL due to the inherent difficulty of inter-task class separation (ICS) caused by severe class imbalance. In this work, we introduce a new joint training benchmark tailored for FSCIL by integrating imbalance-aware techniques, effectively bridging the performance gap between base and incremental classes. Furthermore, we point out inconsistencies in the experimental setup and evaluation of existing FSCIL methods. To ensure fair comparisons between different FSCIL approaches and joint training, we standardize training conditions and propose a unified evaluation protocol that simultaneously considers the validation set and computational complexity. By establishing a reliable upper bound and a standardized evaluation framework for FSCIL, our work provides a clear benchmark and a practical foundation for future research.', 'abstract_zh': '面向少量样本的类增量学习（FSCIL）的目标是在保留以前学习的类的知识的同时，连续适应新兴的类。类增量学习（CIL）旨在连续适应新兴类目并保留之前学习的知识。少数样本类增量学习（FSCIL）提出了更大的挑战，要求模型仅使用有限数量的样本学习增量类目。在传统的CIL中，联合训练通常被视为上限，既是基准又是方法论指导。然而，我们发现由于严重的类不平衡引起的任务间类分离（ICS）固有难度，联合训练在FSCIL中不能成为有意义的上限。在本文中，我们通过结合不平衡感知技术引入了一种新的联合训练基准，有效地弥合了基础类和增量类之间的性能差距。此外，我们指出了现有FSCIL方法中实验设置和评估中的不一致性。为了确保不同FSCIL方法与联合训练之间的公平比较，我们标准化了训练条件并提出了一个统一的评估协议，该协议同时考虑了验证集和计算复杂度。通过为FSCIL建立可靠的上限和标准化的评估框架，我们的工作为未来的研究提供了清晰的基准和实用的基础。', 'title_zh': '一个新的 Few-Shot 类增量学习基准：重定义上界'}
{'arxiv_id': 'arXiv:2503.09858', 'title': 'Media and responsible AI governance: a game-theoretic and LLM analysis', 'authors': 'Nataliya Balabanova, Adeela Bashir, Paolo Bova, Alessio Buscemi, Theodor Cimpeanu, Henrique Correia da Fonseca, Alessandro Di Stefano, Manh Hong Duong, Elias Fernandez Domingos, Antonio Fernandes, Anh Han, Marcus Krellner, Ndidi Bianca Ogbo, Simon T. Powers, Daniele Proverbio, Fernando P. Santos, Zia Ush Shamszaman, Zhao Song', 'link': 'https://arxiv.org/abs/2503.09858', 'abstract': 'This paper investigates the complex interplay between AI developers, regulators, users, and the media in fostering trustworthy AI systems. Using evolutionary game theory and large language models (LLMs), we model the strategic interactions among these actors under different regulatory regimes. The research explores two key mechanisms for achieving responsible governance, safe AI development and adoption of safe AI: incentivising effective regulation through media reporting, and conditioning user trust on commentariats\' recommendation. The findings highlight the crucial role of the media in providing information to users, potentially acting as a form of "soft" regulation by investigating developers or regulators, as a substitute to institutional AI regulation (which is still absent in many regions). Both game-theoretic analysis and LLM-based simulations reveal conditions under which effective regulation and trustworthy AI development emerge, emphasising the importance of considering the influence of different regulatory regimes from an evolutionary game-theoretic perspective. The study concludes that effective governance requires managing incentives and costs for high quality commentaries.', 'abstract_zh': '本文探讨了AI开发者、监管者、用户和媒体之间复杂的相互作用，以促进可信的AI系统。利用演化博弈理论和大规模语言模型（LLMs），我们构建了在不同监管环境下这些行为者之间战略互动的模型。研究探索了实现负责任治理、安全AI开发和安全AI采纳的两种关键机制：通过媒体报道激励有效的监管，以及将用户信任依赖于评论社群的建议。研究结果强调了媒体在向用户提供信息方面的关键作用，可能作为一种“软”监管形式，通过调查开发者或监管者来取代机构化的AI监管（在许多地区仍未实现）。博弈论分析和基于LLMs的模拟揭示了哪些条件下有效的监管和可信的AI开发能够出现，强调了从演化博弈理论视角考虑不同监管环境影响的重要性。研究得出结论，有效的治理需要管理高质量评论的利益和成本。', 'title_zh': '媒体与负责任的AI治理：博弈论与大规模语言模型分析'}
{'arxiv_id': 'arXiv:2503.09780', 'title': 'AgentDAM: Privacy Leakage Evaluation for Autonomous Web Agents', 'authors': 'Arman Zharmagambetov, Chuan Guo, Ivan Evtimov, Maya Pavlova, Ruslan Salakhutdinov, Kamalika Chaudhuri', 'link': 'https://arxiv.org/abs/2503.09780', 'abstract': 'LLM-powered AI agents are an emerging frontier with tremendous potential to increase human productivity. However, empowering AI agents to take action on their user\'s behalf in day-to-day tasks involves giving them access to potentially sensitive and private information, which leads to a possible risk of inadvertent privacy leakage when the agent malfunctions. In this work, we propose one way to address that potential risk, by training AI agents to better satisfy the privacy principle of data minimization. For the purposes of this benchmark, by "data minimization" we mean instances where private information is shared only when it is necessary to fulfill a specific task-relevant purpose. We develop a benchmark called AgentDAM to evaluate how well existing and future AI agents can limit processing of potentially private information that we designate "necessary" to fulfill the task. Our benchmark simulates realistic web interaction scenarios and is adaptable to all existing web navigation agents. We use AgentDAM to evaluate how well AI agents built on top of GPT-4, Llama-3 and Claude can limit processing of potentially private information when unnecessary, and show that these agents are often prone to inadvertent use of unnecessary sensitive information. We finally propose a prompting-based approach that reduces this.', 'abstract_zh': 'LLM赋能的AI代理是提升人类生产力的新兴前沿领域，但赋予其在日常任务中代表用户采取行动可能涉及对其潜在敏感和私人信息的访问，这可能导致代理故障时无意中泄露隐私的风险。在此工作中，我们提出了一种应对该潜在风险的方法，即训练AI代理更好地满足数据最小化隐私原则。为本次基准测试的目的，“数据最小化”是指仅在履行特定任务相关目的必要时分享私人信息。我们开发了一个名为AgentDAM的基准测试，以评估现有和未来AI代理如何限制处理我们指定为“必要”的可能涉及私人信息的处理。我们的基准测试模拟了现实的网络交互场景，并适应所有现有的网络导航代理。我们使用AgentDAM评估基于GPT-4、Llama-3和Claude构建的AI代理在不必要的情况下如何限制处理可能涉及私人信息，并展示这些代理经常无意中使用不必要的敏感信息。最后，我们提出了一种基于提示的方法来减少这一问题。', 'title_zh': 'AgentDAM：自主网络代理的隐私泄露评估'}
{'arxiv_id': 'arXiv:2503.09730', 'title': 'Local Look-Ahead Guidance via Verifier-in-the-Loop for Automated Theorem Proving', 'authors': 'Sara Rajaee, Kumar Pratik, Gabriele Cesa, Arash Behboodi', 'link': 'https://arxiv.org/abs/2503.09730', 'abstract': "The most promising recent methods for AI reasoning require applying variants of reinforcement learning (RL) either on rolled out trajectories from the model, even for the step-wise rewards, or large quantities of human annotated trajectory data. The reliance on the rolled-out trajectory renders the compute cost and time prohibitively high. In particular, the correctness of a reasoning trajectory can typically only be judged at its completion, leading to sparse rewards in RL or requiring expensive synthetic data generation in expert iteration-like methods. In this work, we focus on the Automatic Theorem Proving (ATP) task and propose a novel verifier-in-the-loop design, which unlike existing approaches that leverage feedback on the entire reasoning trajectory, employs an automated verifier to give intermediate feedback at each step of the reasoning process. Using Lean as the verifier, we empirically show that the step-by-step local verification produces a global improvement in the model's reasoning accuracy and efficiency.", 'abstract_zh': '最近最有前景的AI推理方法要求应用强化学习（RL）的变种，无论是针对模型展开的轨迹，即使是逐步奖励，还是大量的人工标注轨迹数据。对展开轨迹的依赖使得计算成本和时间变得难以承受。特别是，推理轨迹的正确性通常只能在其完成时才能判断，这在RL中会导致稀疏奖励，或在专家迭代方法中需要昂贵的合成数据生成。在本工作中，我们专注于自动定理证明（ATP）任务，并提出了一种新的验证者在环设计，该设计与现有利用整个推理轨迹反馈的方法不同，而是使用自动化验证器在推理过程的每一步提供中间反馈。通过使用Lean作为验证器，我们实验证明，逐步局部验证在全局上提高了模型的推理准确性和效率。', 'title_zh': '循环验证器辅以局部前瞻引导的自动化定理证明'}
{'arxiv_id': 'arXiv:2503.10638', 'title': 'Studying Classifier(-Free) Guidance From a Classifier-Centric Perspective', 'authors': 'Xiaoming Zhao, Alexander G. Schwing', 'link': 'https://arxiv.org/abs/2503.10638', 'abstract': 'Classifier-free guidance has become a staple for conditional generation with denoising diffusion models. However, a comprehensive understanding of classifier-free guidance is still missing. In this work, we carry out an empirical study to provide a fresh perspective on classifier-free guidance. Concretely, instead of solely focusing on classifier-free guidance, we trace back to the root, i.e., classifier guidance, pinpoint the key assumption for the derivation, and conduct a systematic study to understand the role of the classifier. We find that both classifier guidance and classifier-free guidance achieve conditional generation by pushing the denoising diffusion trajectories away from decision boundaries, i.e., areas where conditional information is usually entangled and is hard to learn. Based on this classifier-centric understanding, we propose a generic postprocessing step built upon flow-matching to shrink the gap between the learned distribution for a pre-trained denoising diffusion model and the real data distribution, majorly around the decision boundaries. Experiments on various datasets verify the effectiveness of the proposed approach.', 'abstract_zh': '无分类指导已成为去噪扩散模型条件生成的标准方法，然而对其全面理解仍不足。本文通过实证研究，从无分类指导追溯到分类指导，剖析核心假设，系统研究分类器的作用。我们发现，无论是在分类指导还是无分类指导中，条件生成都是通过将去噪扩散轨迹远离决策边界（即条件信息通常交织且难以学习的区域）来实现的。基于这种以分类器为中心的理解，我们提出了一种基于流匹配的通用后处理步骤，以缩小预训练去噪扩散模型学习的分布与真实数据分布之间的差距，尤其是在决策边界附近。在各种数据集上的实验验证了所提出方法的有效性。', 'title_zh': '从分类器为中心的角度研究无分类器引导'}
{'arxiv_id': 'arXiv:2503.10635', 'title': 'A Frustratingly Simple Yet Highly Effective Attack Baseline: Over 90% Success Rate Against the Strong Black-box Models of GPT-4.5/4o/o1', 'authors': 'Zhaoyi Li, Xiaohan Zhao, Dong-Dong Wu, Jiacheng Cui, Zhiqiang Shen', 'link': 'https://arxiv.org/abs/2503.10635', 'abstract': 'Despite promising performance on open-source large vision-language models (LVLMs), transfer-based targeted attacks often fail against black-box commercial LVLMs. Analyzing failed adversarial perturbations reveals that the learned perturbations typically originate from a uniform distribution and lack clear semantic details, resulting in unintended responses. This critical absence of semantic information leads commercial LVLMs to either ignore the perturbation entirely or misinterpret its embedded semantics, thereby causing the attack to fail. To overcome these issues, we notice that identifying core semantic objects is a key objective for models trained with various datasets and methodologies. This insight motivates our approach that refines semantic clarity by encoding explicit semantic details within local regions, thus ensuring interoperability and capturing finer-grained features, and by concentrating modifications on semantically rich areas rather than applying them uniformly. To achieve this, we propose a simple yet highly effective solution: at each optimization step, the adversarial image is cropped randomly by a controlled aspect ratio and scale, resized, and then aligned with the target image in the embedding space. Experimental results confirm our hypothesis. Our adversarial examples crafted with local-aggregated perturbations focused on crucial regions exhibit surprisingly good transferability to commercial LVLMs, including GPT-4.5, GPT-4o, Gemini-2.0-flash, Claude-3.5-sonnet, Claude-3.7-sonnet, and even reasoning models like o1, Claude-3.7-thinking and Gemini-2.0-flash-thinking. Our approach achieves success rates exceeding 90% on GPT-4.5, 4o, and o1, significantly outperforming all prior state-of-the-art attack methods. Our optimized adversarial examples under different configurations and training code are available at this https URL.', 'abstract_zh': '尽管开源大型视觉-语言模型（LVLMs）表现出色，基于转移的针对性攻击经常在面向商业的黑盒LVLMs上失败。分析失败的对抗性扰动发现，学习到的扰动通常源自均匀分布且缺乏明确的语义细节，导致意外的响应。这种语义信息的缺失使商业LVLMs要么完全忽略扰动，要么错误解释其嵌入的语义，从而导致攻击失败。为克服这些问题，我们注意到，训练模型时识别核心语义对象是一个关键目标。这一洞察促使我们提出一种方法，通过在局部区域中编码明确的语义细节来提高语义清晰度，从而确保互操作性和捕捉更细腻的特征，同时将修改集中在语义丰富的区域而不是均匀应用。为实现这一目标，我们提出了一种简单而有效的解决方案：在每次优化步骤中，随机裁剪对抗性图像的控制方面比和比例，重新调整大小，并在嵌入空间中与目标图像对齐。实验结果证实了我们的假设。我们使用局部聚集扰动创建的对抗性样本专注于关键区域，在商业LVLMs，包括GPT-4.5、GPT-4o、Gemini-2.0-flash、Claude-3.5-sonnet、Claude-3.7-sonnet以及推理模型如o1、Claude-3.7-thinking和Gemini-2.0-flash-thinking中表现出惊人的转移性。我们的方法在GPT-4.5、4o和o1上的成功率超过90%，显著优于所有先前的最佳攻击方法。我们的优化对抗性样本在不同配置和训练代码下的版本可在以下链接获得。', 'title_zh': '令人沮丧的简单但极其有效的攻击基线：针对GPT-4.5/4001的强大黑盒模型成功率超过90%'}
{'arxiv_id': 'arXiv:2503.10627', 'title': 'SciVerse: Unveiling the Knowledge Comprehension and Visual Reasoning of LMMs on Multi-modal Scientific Problems', 'authors': 'Ziyu Guo, Ray Zhang, Hao Chen, Jialin Gao, Dongzhi Jiang, Jiaze Wang, Pheng-Ann Heng', 'link': 'https://arxiv.org/abs/2503.10627', 'abstract': 'The rapid advancement of Large Multi-modal Models (LMMs) has enabled their application in scientific problem-solving, yet their fine-grained capabilities remain under-explored. In this paper, we introduce SciVerse, a multi-modal scientific evaluation benchmark to thoroughly assess LMMs across 5,735 test instances in five distinct versions. We aim to investigate three key dimensions of LMMs: scientific knowledge comprehension, multi-modal content interpretation, and Chain-of-Thought (CoT) reasoning. To unveil whether LMMs possess sufficient scientific expertise, we first transform each problem into three versions containing different levels of knowledge required for solving, i.e., Knowledge-free, -lite, and -rich. Then, to explore how LMMs interpret multi-modal scientific content, we annotate another two versions, i.e., Vision-rich and -only, marking more question information from texts to diagrams. Comparing the results of different versions, SciVerse systematically examines the professional knowledge stock and visual perception skills of LMMs in scientific domains. In addition, to rigorously assess CoT reasoning, we propose a new scientific CoT evaluation strategy, conducting a step-wise assessment on knowledge and logical errors in model outputs. Our extensive evaluation of different LMMs on SciVerse reveals critical limitations in their scientific proficiency and provides new insights into future developments. Project page: this https URL', 'abstract_zh': '大规模多模态模型的 rapid advancement 已使其在科学研究中得以应用，但其精细能力仍亟待深入探索。本文介绍了一种多模态科学评估基准 SciVerse，以全面评估 LMMs 在五个不同版本中的 5,735 个测试实例中的性能。我们旨在研究 LMMs 的三个关键维度：科学知识理解、多模态内容解释和思维链（CoT）推理。为了揭示 LMMs 是否具备足够的科学专业知识，我们首先将每个问题转化为包含不同知识要求的三个版本，即知识无、轻和丰富版本。然后，为了探索 LMMs 如何解释多模态科学内容，我们标注了另外两个版本，即视觉丰富和仅视觉版本，从文本中更多地标记问题信息为图表。通过比较不同版本的结果，SciVerse 系统性地检查了 LMMs 在科学领域的专业知识储备和视觉感知能力。此外，为了严格评估 CoT 推理，我们提出了一种新的科学 CoT 评估策略，在模型输出的知识和逻辑错误方面进行逐步评估。我们在 SciVerse 上对不同 LMMs 的广泛评估揭示了它们在科学专业性方面的关键局限性，并为未来的发展提供了新的见解。项目页面：这个 https URL。', 'title_zh': 'SciVerse: 揭示LMMs在多模态科学问题上的知识理解与视觉推理能力'}
{'arxiv_id': 'arXiv:2503.10626', 'title': 'NIL: No-data Imitation Learning by Leveraging Pre-trained Video Diffusion Models', 'authors': 'Mert Albaba, Chenhao Li, Markos Diomataris, Omid Taheri, Andreas Krause, Michael Black', 'link': 'https://arxiv.org/abs/2503.10626', 'abstract': "Acquiring physically plausible motor skills across diverse and unconventional morphologies-including humanoid robots, quadrupeds, and animals-is essential for advancing character simulation and robotics. Traditional methods, such as reinforcement learning (RL) are task- and body-specific, require extensive reward function engineering, and do not generalize well. Imitation learning offers an alternative but relies heavily on high-quality expert demonstrations, which are difficult to obtain for non-human morphologies. Video diffusion models, on the other hand, are capable of generating realistic videos of various morphologies, from humans to ants. Leveraging this capability, we propose a data-independent approach for skill acquisition that learns 3D motor skills from 2D-generated videos, with generalization capability to unconventional and non-human forms. Specifically, we guide the imitation learning process by leveraging vision transformers for video-based comparisons by calculating pair-wise distance between video embeddings. Along with video-encoding distance, we also use a computed similarity between segmented video frames as a guidance reward. We validate our method on locomotion tasks involving unique body configurations. In humanoid robot locomotion tasks, we demonstrate that 'No-data Imitation Learning' (NIL) outperforms baselines trained on 3D motion-capture data. Our results highlight the potential of leveraging generative video models for physically plausible skill learning with diverse morphologies, effectively replacing data collection with data generation for imitation learning.", 'abstract_zh': '跨多种非传统形态，包括人形机器人、四足动物和动物，获取物理上合理的行为技能对于推进角色模拟和机器人技术至关重要。传统的强化学习方法针对性强、需要大量奖励函数工程并且不具备较好的泛化能力。模仿学习提供了一种替代方案，但需要高质量的专家示范，这在非人类形态的情况下难以获得。视频扩散模型能够生成从人类到蚂蚁等多种形态的逼真视频。利用这一能力，我们提出了一种数据独立的行为技能获取方法，可以从生成的2D视频中学习3D运动技能，并具备对非传统和非人类形态的泛化能力。具体而言，我们通过使用视觉变换器进行基于视频的距离比较来指导模仿学习过程，计算视频嵌入的成对距离。同时，我们还利用分割视频帧之间的计算相似度作为辅助奖励。我们在涉及独特身体配置的运动任务中验证了该方法。在人形机器人运动任务中，我们证明了“无数据模仿学习”（NIL）优于基于3D动作捕捉数据训练的基础模型。我们的结果 Highlights 了借助生成视频模型进行多形态物理上合理技能学习的潜力，有效地用数据生成替代了数据收集在模仿学习中的应用。', 'title_zh': 'NIL: 无数据模仿学习通过利用预训练视频扩散模型'}
{'arxiv_id': 'arXiv:2503.10625', 'title': 'LHM: Large Animatable Human Reconstruction Model from a Single Image in Seconds', 'authors': 'Lingteng Qiu, Xiaodong Gu, Peihao Li, Qi Zuo, Weichao Shen, Junfei Zhang, Kejie Qiu, Weihao Yuan, Guanying Chen, Zilong Dong, Liefeng Bo', 'link': 'https://arxiv.org/abs/2503.10625', 'abstract': 'Animatable 3D human reconstruction from a single image is a challenging problem due to the ambiguity in decoupling geometry, appearance, and deformation. Recent advances in 3D human reconstruction mainly focus on static human modeling, and the reliance of using synthetic 3D scans for training limits their generalization ability. Conversely, optimization-based video methods achieve higher fidelity but demand controlled capture conditions and computationally intensive refinement processes. Motivated by the emergence of large reconstruction models for efficient static reconstruction, we propose LHM (Large Animatable Human Reconstruction Model) to infer high-fidelity avatars represented as 3D Gaussian splatting in a feed-forward pass. Our model leverages a multimodal transformer architecture to effectively encode the human body positional features and image features with attention mechanism, enabling detailed preservation of clothing geometry and texture. To further boost the face identity preservation and fine detail recovery, we propose a head feature pyramid encoding scheme to aggregate multi-scale features of the head regions. Extensive experiments demonstrate that our LHM generates plausible animatable human in seconds without post-processing for face and hands, outperforming existing methods in both reconstruction accuracy and generalization ability.', 'abstract_zh': '单张图像中可动画化三维人体重建是一个具有挑战性的问题，因为难以区分几何结构、外观和变形的不确定性。近期在三维人体重建方面的进展主要集中在静态人体建模上，使用合成三维扫描进行训练限制了其泛化能力。相反，基于优化的视频方法实现了更高的保真度，但需要受控的捕捉条件和计算密集型的细化过程。受高效静态重建的大规模重建模型的启发，我们提出了LHM（大规模可动画化人体重建模型），在前向传递过程中推断高保真度以3D高斯点表示的avatar。我们的模型利用多模态变压器架构，通过注意机制有效地编码人体位置特征和图像特征，从而实现详细的服装几何结构和纹理保留。为了进一步提升面部身份保留和细部恢复，我们提出了头部特征金字塔编码方案，以聚合头部区域的多尺度特征。广泛实验表明，我们的LHM在无需面部和手部后处理的情况下，以秒为单位生成合乎情理的可动画化人体，在重建精度和泛化能力方面优于现有方法。', 'title_zh': '秒级从单张图像构建大容量可动画的人体重建模型'}
{'arxiv_id': 'arXiv:2503.10624', 'title': 'ETCH: Generalizing Body Fitting to Clothed Humans via Equivariant Tightness', 'authors': 'Boqian Li, Haiwen Feng, Zeyu Cai, Michael J. Black, Yuliang Xiu', 'link': 'https://arxiv.org/abs/2503.10624', 'abstract': 'Fitting a body to a 3D clothed human point cloud is a common yet challenging task. Traditional optimization-based approaches use multi-stage pipelines that are sensitive to pose initialization, while recent learning-based methods often struggle with generalization across diverse poses and garment types. We propose Equivariant Tightness Fitting for Clothed Humans, or ETCH, a novel pipeline that estimates cloth-to-body surface mapping through locally approximate SE(3) equivariance, encoding tightness as displacement vectors from the cloth surface to the underlying body. Following this mapping, pose-invariant body features regress sparse body markers, simplifying clothed human fitting into an inner-body marker fitting task. Extensive experiments on CAPE and 4D-Dress show that ETCH significantly outperforms state-of-the-art methods -- both tightness-agnostic and tightness-aware -- in body fitting accuracy on loose clothing (16.7% ~ 69.5%) and shape accuracy (average 49.9%). Our equivariant tightness design can even reduce directional errors by (67.2% ~ 89.8%) in one-shot (or out-of-distribution) settings. Qualitative results demonstrate strong generalization of ETCH, regardless of challenging poses, unseen shapes, loose clothing, and non-rigid dynamics. We will release the code and models soon for research purposes at this https URL.', 'abstract_zh': '基于局部近似SE(3)等变性的Clothed Human紧致 fitting方法：ETCH', 'title_zh': 'ETCH: 将体形拟合推广到穿着衣服的人 via 协变紧致度'}
{'arxiv_id': 'arXiv:2503.10622', 'title': 'Transformers without Normalization', 'authors': 'Jiachen Zhu, Xinlei Chen, Kaiming He, Yann LeCun, Zhuang Liu', 'link': 'https://arxiv.org/abs/2503.10622', 'abstract': 'Normalization layers are ubiquitous in modern neural networks and have long been considered essential. This work demonstrates that Transformers without normalization can achieve the same or better performance using a remarkably simple technique. We introduce Dynamic Tanh (DyT), an element-wise operation $DyT($x$) = \\tanh(\\alpha $x$)$, as a drop-in replacement for normalization layers in Transformers. DyT is inspired by the observation that layer normalization in Transformers often produces tanh-like, $S$-shaped input-output mappings. By incorporating DyT, Transformers without normalization can match or exceed the performance of their normalized counterparts, mostly without hyperparameter tuning. We validate the effectiveness of Transformers with DyT across diverse settings, ranging from recognition to generation, supervised to self-supervised learning, and computer vision to language models. These findings challenge the conventional understanding that normalization layers are indispensable in modern neural networks, and offer new insights into their role in deep networks.', 'abstract_zh': '无归一化变换器：Dynamic Tanh 的引入及其效果', 'title_zh': '无需归一化的 Transformers'}
{'arxiv_id': 'arXiv:2503.10617', 'title': 'Compositional Subspace Representation Fine-tuning for Adaptive Large Language Models', 'authors': 'Andy Zhou', 'link': 'https://arxiv.org/abs/2503.10617', 'abstract': 'Adapting large language models to multiple tasks can cause cross-skill interference, where improvements for one skill degrade another. While methods such as LoRA impose orthogonality constraints at the weight level, they do not fully address interference in hidden-state representations. We propose Compositional Subspace Representation Fine-tuning (CS-ReFT), a novel representation-based approach that learns multiple orthonormal subspace transformations, each specializing in a distinct skill, and composes them via a lightweight router. By isolating these subspace edits in the hidden state, rather than weight matrices, CS-ReFT prevents cross-task conflicts more effectively. On the AlpacaEval benchmark, applying CS-ReFT to Llama-2-7B achieves a 93.94% win rate, surpassing GPT-3.5 Turbo (86.30%) while requiring only 0.0098% of model parameters. These findings show that specialized representation edits, composed via a simple router, significantly enhance multi-task instruction following with minimal overhead.', 'abstract_zh': '一种新的表示方法：组成子空间表示微调（CS-ReFT）在多个任务指令跟随中的应用', 'title_zh': 'compositional 子空间表示微调以实现自适应大型语言模型'}
{'arxiv_id': 'arXiv:2503.10603', 'title': 'Dual-Stage Cross-Modal Network with Dynamic Feature Fusion for Emotional Mimicry Intensity Estimation', 'authors': 'Jun Yu, Lingsi Zhu, Yanjun Chi, Yunxiang Zhang, Yang Zheng, Yongqi Wang, Xilong Lu', 'link': 'https://arxiv.org/abs/2503.10603', 'abstract': 'Emotional Mimicry Intensity (EMI) estimation serves as a critical technology for understanding human social behavior and enhancing human-computer interaction experiences, where the core challenge lies in dynamic correlation modeling and robust fusion of multimodal temporal signals. To address the limitations of existing methods in insufficient exploitation of modal synergistic effects, noise sensitivity, and limited fine-grained alignment capabilities, this paper proposes a dual-stage cross-modal alignment framework. First, we construct vision-text and audio-text contrastive learning networks based on an improved CLIP architecture, achieving preliminary alignment in the feature space through modality-decoupled pre-training. Subsequently, we design a temporal-aware dynamic fusion module that combines Temporal Convolutional Networks (TCN) and gated bidirectional LSTM to respectively capture the macro-evolution patterns of facial expressions and local dynamics of acoustic features. Innovatively, we introduce a quality-guided modality fusion strategy that enables modality compensation under occlusion and noisy scenarios through differentiable weight allocation. Experimental results on the Hume-Vidmimic2 dataset demonstrate that our method achieves an average Pearson correlation coefficient of 0.35 across six emotion dimensions, outperforming the best baseline by 40\\%. Ablation studies further validate the effectiveness of the dual-stage training strategy and dynamic fusion mechanism, providing a novel technical pathway for fine-grained emotion analysis in open environments.', 'abstract_zh': '情绪模仿强度（EMI）估计作为理解人类社会行为和增强人机交互体验的关键技术，其核心挑战在于多模态时空信号的动态关联建模和鲁棒融合。为了解决现有方法在模态协同效应利用不足、对噪声敏感以及细粒度对齐能力有限的限制，本文提出了一种双阶段跨模态对齐框架。首先，我们在改进的CLIP架构基础上构建了视讯-文本和音频-文本对比学习网络，通过模态解耦预训练在特征空间中实现初步对齐。随后，我们设计了一个基于时序卷积网络（TCN）和门控双向LSTM的时序感知动态融合模块，分别捕捉面部表情的宏观演变模式和声学特征的局部动态。创新性地，我们引入了一种质量导向的模态融合策略，在遮挡和噪声场景下通过可微权重分配实现模态补偿。实验结果表明，本文方法在Hume-Vidmimic2数据集上六种情感维度上的平均皮尔森相关系数达到0.35，比最佳基线高出40%。消融研究进一步验证了双阶段训练策略和动态融合机制的有效性，为开放环境下的细粒度情感分析提供了新的技术路径。', 'title_zh': '具有动态特征融合的双阶段跨模态网络在情感模仿强度估计中的应用'}
{'arxiv_id': 'arXiv:2503.10602', 'title': 'TruthPrInt: Mitigating LVLM Object Hallucination Via Latent Truthful-Guided Pre-Intervention', 'authors': 'Jinhao Duan, Fei Kong, Hao Cheng, James Diffenderfer, Bhavya Kailkhura, Lichao Sun, Xiaofeng Zhu, Xiaoshuang Shi, Kaidi Xu', 'link': 'https://arxiv.org/abs/2503.10602', 'abstract': 'Object Hallucination (OH) has been acknowledged as one of the major trustworthy challenges in Large Vision-Language Models (LVLMs). Recent advancements in Large Language Models (LLMs) indicate that internal states, such as hidden states, encode the "overall truthfulness" of generated responses. However, it remains under-explored how internal states in LVLMs function and whether they could serve as "per-token" hallucination indicators, which is essential for mitigating OH. In this paper, we first conduct an in-depth exploration of LVLM internal states in relation to OH issues and discover that (1) LVLM internal states are high-specificity per-token indicators of hallucination behaviors. Moreover, (2) different LVLMs encode universal patterns of hallucinations in common latent subspaces, indicating that there exist "generic truthful directions" shared by various LVLMs. Based on these discoveries, we propose Truthful-Guided Pre-Intervention (TruthPrInt) that first learns the truthful direction of LVLM decoding and then applies truthful-guided inference-time intervention during LVLM decoding. We further propose ComnHallu to enhance both cross-LVLM and cross-data hallucination detection transferability by constructing and aligning hallucination latent subspaces. We evaluate TruthPrInt in extensive experimental settings, including in-domain and out-of-domain scenarios, over popular LVLMs and OH benchmarks. Experimental results indicate that TruthPrInt significantly outperforms state-of-the-art methods. Codes will be available at this https URL.', 'abstract_zh': 'Object Hallucination的内部状态探索及其缓解：基于可信方向的预干预（TruthPrInt）和跨模型幻觉检测增强（ComnHallu）', 'title_zh': 'TruthPrInt: 通过潜在事实引导预干预减轻LVLM对象幻觉'}
{'arxiv_id': 'arXiv:2503.10587', 'title': 'The Spectral Bias of Shallow Neural Network Learning is Shaped by the Choice of Non-linearity', 'authors': 'Justin Sahs, Ryan Pyle, Fabio Anselmi, Ankit Patel', 'link': 'https://arxiv.org/abs/2503.10587', 'abstract': "Despite classical statistical theory predicting severe overfitting, modern massively overparameterized neural networks still generalize well. This unexpected property is attributed to the network's so-called implicit bias, which describes its propensity to converge to solutions that generalize effectively, among the many possible that correctly label the training data. The aim of our research is to explore this bias from a new perspective, focusing on how non-linear activation functions contribute to shaping it. First, we introduce a reparameterization which removes a continuous weight rescaling symmetry. Second, in the kernel regime, we leverage this reparameterization to generalize recent findings that relate shallow Neural Networks to the Radon transform, deriving an explicit formula for the implicit bias induced by a broad class of activation functions. Specifically, by utilizing the connection between the Radon transform and the Fourier transform, we interpret the kernel regime's inductive bias as minimizing a spectral seminorm that penalizes high-frequency components, in a manner dependent on the activation function. Finally, in the adaptive regime, we demonstrate the existence of local dynamical attractors that facilitate the formation of clusters of hyperplanes where the input to a neuron's activation function is zero, yielding alignment between many neurons' response functions. We confirm these theoretical results with simulations. All together, our work provides a deeper understanding of the mechanisms underlying the generalization capabilities of overparameterized neural networks and its relation with the implicit bias, offering potential pathways for designing more efficient and robust models.", 'abstract_zh': '尽管经典统计理论预测严重的过拟合现象，但现代高度过参数化的神经网络仍然能够泛化良好。这一意想不到的特性归因于网络所谓的隐式偏置，即其倾向于收敛到能够有效泛化的解决方案，而不是仅仅正确标记训练数据的众多可能解。我们研究的目的是从一个新的角度探索这种偏置，重点关注非线性激活函数如何塑造这种偏置。首先，我们引入了一种重新参数化方法，以消除连续权重缩放对称性。其次，在核区，我们利用这种重新参数化来推广最近与浅层神经网络相关的拉东变换的研究成果，推导出由广泛类别激活函数引发的隐式偏置的显式公式。具体来说，通过拉东变换与傅里叶变换之间的联系，我们将核区的归纳偏置解释为通过激活函数依赖的方式最小化频谱半范数，惩罚高频率分量。最后，在自适应区，我们证明存在局部动力学吸引子，有助于形成神经元激活函数输入为零的超平面簇，从而实现大量神经元响应函数的对齐。我们通过模拟证实了这些理论结果。综上所述，我们的工作为理解过度参数化神经网络泛化能力背后的机制及其与隐式偏置的关系提供了更深入的理解，并为设计更高效和鲁棒的模型提供了潜在途径。', 'title_zh': '浅层神经网络学习的光谱偏置由非线性函数的选择塑造'}
{'arxiv_id': 'arXiv:2503.10582', 'title': 'VisualWebInstruct: Scaling up Multimodal Instruction Data through Web Search', 'authors': 'Yiming Jia, Jiachen Li, Xiang Yue, Bo Li, Ping Nie, Kai Zou, Wenhu Chen', 'link': 'https://arxiv.org/abs/2503.10582', 'abstract': "Vision-Language Models have made significant progress on many perception-focused tasks, however, their progress on reasoning-focused tasks seem to be limited due to the lack of high-quality and diverse training data. In this work, we aim to address the scarcity issue of reasoning-focused multimodal datasets. We propose VisualWebInstruct - a novel approach that leverages search engine to create a diverse, and high-quality dataset spanning multiple disciplines like math, physics, finance, chemistry, etc. Starting with meticulously selected 30,000 seed images, we employ Google Image search to identify websites containing similar images. We collect and process the HTMLs from over 700K unique URL sources. Through a pipeline of content extraction, filtering and synthesis, we build a dataset of approximately 900K question-answer pairs, with 40% being visual QA pairs and the rest as text QA pairs. Models fine-tuned on VisualWebInstruct demonstrate significant performance gains: (1) training from Llava-OV-mid shows 10-20% absolute point gains across benchmarks, (2) training from MAmmoTH-VL shows 5% absoluate gain. Our best model MAmmoTH-VL2 shows state-of-the-art performance within the 10B parameter class on MMMU-Pro-std (40.7%), MathVerse (42.6%), and DynaMath (55.7%). These remarkable results highlight the effectiveness of our dataset in enhancing VLMs' reasoning capabilities for complex multimodal tasks.", 'abstract_zh': 'Vision-Language模型在许多感知任务上取得了显著进展，但在推理任务上的进展受限于高质量和多样性的训练数据不足。本工作中，我们旨在解决推理导向的多模态数据集短缺的问题。我们提出了VisualWebInstruct——一种利用搜索引擎创建多样且高质量数据集的方法，涵盖数学、物理、金融、化学等多个学科。从精心挑选的30,000张种子图像开始，我们使用Google图像搜索来识别包含相似图像的网站，并收集和处理来自超过700,000个唯一URL来源的HTML页面。通过内容提取、过滤和合成的流程，我们构建了一个大约包含900,000个问答对的数据集，其中约40%是视觉问答对，其余的是文本问答对。在VisualWebInstruct上微调的模型显示出显著的性能提升：(1) 从Llava-OV-mid训练显示出各基准上10-20%的绝对点数提升，(2) 从MAmmoTH-VL训练显示出5%的绝对点数提升。我们的最佳模型MAmmoTH-VL2在10B参数级别上，在MMMU-Pro-std（40.7%）、MathVerse（42.6%）和DynaMath（55.7%）上显示出最先进的性能。这些显著的结果突显了我们数据集在提升VLMs处理复杂多模态任务的推理能力方面的有效性。', 'title_zh': '视觉网页指令：通过网络搜索扩展多模态指令数据'}
{'arxiv_id': 'arXiv:2503.10546', 'title': 'KUDA: Keypoints to Unify Dynamics Learning and Visual Prompting for Open-Vocabulary Robotic Manipulation', 'authors': 'Zixian Liu, Mingtong Zhang, Yunzhu Li', 'link': 'https://arxiv.org/abs/2503.10546', 'abstract': 'With the rapid advancement of large language models (LLMs) and vision-language models (VLMs), significant progress has been made in developing open-vocabulary robotic manipulation systems. However, many existing approaches overlook the importance of object dynamics, limiting their applicability to more complex, dynamic tasks. In this work, we introduce KUDA, an open-vocabulary manipulation system that integrates dynamics learning and visual prompting through keypoints, leveraging both VLMs and learning-based neural dynamics models. Our key insight is that a keypoint-based target specification is simultaneously interpretable by VLMs and can be efficiently translated into cost functions for model-based planning. Given language instructions and visual observations, KUDA first assigns keypoints to the RGB image and queries the VLM to generate target specifications. These abstract keypoint-based representations are then converted into cost functions, which are optimized using a learned dynamics model to produce robotic trajectories. We evaluate KUDA on a range of manipulation tasks, including free-form language instructions across diverse object categories, multi-object interactions, and deformable or granular objects, demonstrating the effectiveness of our framework. The project page is available at this http URL.', 'abstract_zh': '随着大规模语言模型（LLMs）和视觉-语言模型（VLMs）的快速发展，开放词汇的机器人 manipulation 系统取得了显著进展。然而，许多现有方法忽视了物体动力学的重要性，限制了其在更复杂、动态任务中的应用。本文介绍了一种名为 KUDA 的开放词汇 manipulation 系统，通过关键点结合动力学习和视觉提示，利用 VLMs 和基于学习的神经动力学模型进行集成。我们的关键洞察是，基于关键点的目标规格化既能被 VLMs 识别，又能高效地转化为基于模型的规划中的成本函数。在获得语言指令和视觉观察后，KUDA 首先为 RGB 图像分配关键点并查询 VLM 生成目标规格化，随后将这些抽象的关键点表示转化为成本函数，利用学习的动力学模型进行优化以产生机器人轨迹。我们将在各种 manipulation 任务上评估 KUDA，包括跨多种物体类别的一般语言指令、多物体交互以及柔体或颗粒状物体，展示了我们框架的有效性。项目页面可通过以下网址访问。', 'title_zh': 'KUDA: 关键点统一动力学习与视觉提示的开放词汇机器人操作'}
{'arxiv_id': 'arXiv:2503.10542', 'title': 'Language Models, Graph Searching, and Supervision Adulteration: When More Supervision is Less and How to Make More More', 'authors': 'Arvid Frydenlund', 'link': 'https://arxiv.org/abs/2503.10542', 'abstract': "This work concerns the path-star task, a minimal example of searching over a graph. The graph, $G$, is star-shaped with $D$ arms radiating from a start node, $s$. A language model (LM) is given $G$, $s$, and a target node $t$, which ends one of the arms and is tasked with generating the arm containing $t$. The minimal nature of this task means only a single choice needs to be made: which of the $D$ arms contains $t$?\nDecoder-only LMs fail to solve this elementary task above $1/D$ chance due to a learned shortcut that absorbs training supervision. We show how this pathology is caused by excess supervision and we present a series of solutions demonstrating that the task is solvable via decoder-only LMs. We find that the task's minimal nature causes its difficulty, as it prevents task decomposition. Our solutions provide insight into the pathology and its implications for LMs trained via next-token prediction.", 'abstract_zh': '本工作关注路径-星图任务，这是在图上搜索的一个最小范例。图 $G$ 是星形结构，从起始节点 $s$ 辐射出 $D$ 条臂。给定一个语言模型 (LM)，以及目标节点 $t$ （其位于其中一条臂的末端），任务是生成包含 $t$ 的那条臂。由于任务的最小性质，只需要做出一个选择：哪一条臂包含 $t$。解码器仅模型在超过 $1/D$ 的随机猜测概率下无法解决这一基本任务，这是由于学习到的一个捷径吸收了训练监督。我们展示了这种病理现象是如何由过度的监督引起的，并提供了一系列解决方案，证明此类任务可以通过解码器仅模型解决。我们发现任务的最小性质使其困难，因为它阻止了任务的分解。我们的解决方案为理解此类病理现象及其对通过下一个单词预测训练的模型的影响提供了见解。', 'title_zh': '语言模型、图搜索与监督污染：何时更多的监督会导致效果下降以及如何使监督更加有效'}
{'arxiv_id': 'arXiv:2503.10539', 'title': 'GBSVR: Granular Ball Support Vector Regression', 'authors': 'Reshma Rastogi, Ankush Bisht, Sanjay Kumar, Suresh Chandra', 'link': 'https://arxiv.org/abs/2503.10539', 'abstract': 'Support Vector Regression (SVR) and its variants are widely used to handle regression tasks, however, since their solution involves solving an expensive quadratic programming problem, it limits its application, especially when dealing with large datasets. Additionally, SVR uses an epsilon-insensitive loss function which is sensitive to outliers and therefore can adversely affect its performance. We propose Granular Ball Support Vector Regression (GBSVR) to tackle problem of regression by using granular ball concept. These balls are useful in simplifying complex data spaces for machine learning tasks, however, to the best of our knowledge, they have not been sufficiently explored for regression problems. Granular balls group the data points into balls based on their proximity and reduce the computational cost in SVR by replacing the large number of data points with far fewer granular balls. This work also suggests a discretization method for continuous-valued attributes to facilitate the construction of granular balls. The effectiveness of the proposed approach is evaluated on several benchmark datasets and it outperforms existing state-of-the-art approaches', 'abstract_zh': '粒度球支持向量回归（GBSVR）：基于粒度球概念的回归问题处理', 'title_zh': '粒球支持向量回归：GBSVR'}
{'arxiv_id': 'arXiv:2503.10533', 'title': 'The Impact of Item-Writing Flaws on Difficulty and Discrimination in Item Response Theory', 'authors': 'Robin Schmucker, Steven Moore', 'link': 'https://arxiv.org/abs/2503.10533', 'abstract': 'High-quality test items are essential for educational assessments, particularly within Item Response Theory (IRT). Traditional validation methods rely on resource-intensive pilot testing to estimate item difficulty and discrimination. More recently, Item-Writing Flaw (IWF) rubrics emerged as a domain-general approach for evaluating test items based on textual features. However, their relationship to IRT parameters remains underexplored. To address this gap, we conducted a study involving over 7,000 multiple-choice questions across various STEM subjects (e.g., math and biology). Using an automated approach, we annotated each question with a 19-criteria IWF rubric and studied relationships to data-driven IRT parameters. Our analysis revealed statistically significant links between the number of IWFs and IRT difficulty and discrimination parameters, particularly in life and physical science domains. We further observed how specific IWF criteria can impact item quality more and less severely (e.g., negative wording vs. implausible distractors). Overall, while IWFs are useful for predicting IRT parameters--particularly for screening low-difficulty MCQs--they cannot replace traditional data-driven validation methods. Our findings highlight the need for further research on domain-general evaluation rubrics and algorithms that understand domain-specific content for robust item validation.', 'abstract_zh': '高质量的测试项目对于教育评估至关重要，特别是在项目反应理论（IRT）领域。传统的验证方法依赖于耗时的试点测试以估算项目的难度和区分度。近年来，项目写作缺陷（IWF）量表作为基于文本特征的通用评估方法得到了发展。然而，它们与IRT参数之间的关系尚待进一步探索。为了填补这一空白，我们对跨多个STEM科目（如数学和生物学）的超过7,000个选择题进行了研究。通过自动化方法，我们为每个问题标注了一个包含19项标准的IWF量表，并研究了其与数据驱动的IRT参数之间的关系。我们的分析揭示了项目写作缺陷的数量与IRT难度和区分度参数之间存在统计显著的相关性，尤其是在生命科学和物理科学领域。我们进一步观察了特定的IWF标准如何不同程度地影响项目质量（例如，负面措辞与不合理干扰项）。总之，虽然IWFs对于预测IRT参数——尤其是筛查难度较低的选择题——非常有用，但它们不能替代传统的数据驱动验证方法。我们的研究结果强调了进一步研究通用评估量表和理解特定领域内容的算法的重要性，以进行稳健的项目验证。', 'title_zh': '项目编写缺陷对项目反应理论中难度和区分度的影响'}
{'arxiv_id': 'arXiv:2503.10530', 'title': 'Lightweight Models for Emotional Analysis in Video', 'authors': 'Quoc-Tien Nguyen, Hong-Hai Nguyen, Van-Thong Huynh', 'link': 'https://arxiv.org/abs/2503.10530', 'abstract': 'In this study, we present an approach for efficient spatiotemporal feature extraction using MobileNetV4 and a multi-scale 3D MLP-Mixer-based temporal aggregation module. MobileNetV4, with its Universal Inverted Bottleneck (UIB) blocks, serves as the backbone for extracting hierarchical feature representations from input image sequences, ensuring both computational efficiency and rich semantic encoding. To capture temporal dependencies, we introduce a three-level MLP-Mixer module, which processes spatial features at multiple resolutions while maintaining structural integrity. Experimental results on the ABAW 8th competition demonstrate the effectiveness of our approach, showing promising performance in affective behavior analysis. By integrating an efficient vision backbone with a structured temporal modeling mechanism, the proposed framework achieves a balance between computational efficiency and predictive accuracy, making it well-suited for real-time applications in mobile and embedded computing environments.', 'abstract_zh': '本研究提出了一种使用MobileNetV4和多尺度3D MLP-Mixer基Temporal Aggregation模块的有效时空特征提取方法。通过Universal Inverted Bottleneck (UIB)块，MobileNetV4确保了计算效率和丰富的语义编码。为了捕获时间依赖性，我们引入了一个三级MLP-Mixer模块，在保持结构完整性的同时处理多分辨率的空间特征。实验结果表明，该方法在情绪行为分析方面具有良好的性能。通过结合高效的视觉主干网络和结构化的时间建模机制，所提出的框架在保持计算效率和预测准确性方面达到平衡，使其适用于移动和嵌入式计算环境中的实时应用。', 'title_zh': '轻量级模型在视频情绪分析中的应用'}
{'arxiv_id': 'arXiv:2503.10529', 'title': 'PiSA: A Self-Augmented Data Engine and Training Strategy for 3D Understanding with Large Models', 'authors': 'Zilu Guo, Hongbin Lin, Zhihao Yuan, Chaoda Zheng, Pengshuo Qiu, Dongzhi Jiang, Renrui Zhang, Chun-Mei Feng, Zhen Li', 'link': 'https://arxiv.org/abs/2503.10529', 'abstract': "3D Multimodal Large Language Models (MLLMs) have recently made substantial advancements. However, their potential remains untapped, primarily due to the limited quantity and suboptimal quality of 3D datasets. Current approaches attempt to transfer knowledge from 2D MLLMs to expand 3D instruction data, but still face modality and domain gaps. To this end, we introduce PiSA-Engine (Point-Self-Augmented-Engine), a new framework for generating instruction point-language datasets enriched with 3D spatial semantics. We observe that existing 3D MLLMs offer a comprehensive understanding of point clouds for annotation, while 2D MLLMs excel at cross-validation by providing complementary information. By integrating holistic 2D and 3D insights from off-the-shelf MLLMs, PiSA-Engine enables a continuous cycle of high-quality data generation. We select PointLLM as the baseline and adopt this co-evolution training framework to develop an enhanced 3D MLLM, termed PointLLM-PiSA. Additionally, we identify limitations in previous 3D benchmarks, which often feature coarse language captions and insufficient category diversity, resulting in inaccurate evaluations. To address this gap, we further introduce PiSA-Bench, a comprehensive 3D benchmark covering six key aspects with detailed and diverse labels. Experimental results demonstrate PointLLM-PiSA's state-of-the-art performance in zero-shot 3D object captioning and generative classification on our PiSA-Bench, achieving significant improvements of 46.45% (+8.33%) and 63.75% (+16.25%), respectively. We will release the code, datasets, and benchmark.", 'abstract_zh': '3D多模态大语言模型（MLLMs） recently取得了重大进展。然而，其潜力尚未完全开发，主要是由于3D数据集的数量有限且质量不佳。目前的方法试图从2D MLLMs转移知识以扩展3D指令数据，但仍面临模态和领域差距。为了解决这一问题，我们提出了PiSA-Engine（点自我增强引擎），这是一种新的框架，用于生成包含3D空间语义的指令点语言数据集。我们观察到现有的3D MLLMs在注解方面提供了全面的点云理解，而2D MLLMs则通过提供补充信息在交叉验证方面表现出色。通过结合现成的2D和3D MLLMs的整体见解，PiSA-Engine使高品质数据生成形成连续循环。我们选择PointLLM作为基线，并采用这种共同演化训练框架开发了一种增强的3D MLLM，称为PointLLM-PiSA。此外，我们还指出了之前3D基准的局限性，这些基准通常语言标注粗糙且分类多样性不足，导致评估不准确。为此，我们进一步引入了PiSA-Bench，这是一种涵盖六个关键方面的全面3D基准，具有详细的多样标签。实验结果表明，PointLLM-PiSA在我们的PiSA-Bench上的零样本3D对象描述和生成分类方面表现出最先进的性能，分别取得了46.45%（+8.33%）和63.75%（+16.25%）的重大提升。我们将发布代码、数据集和基准。', 'title_zh': 'PiSA: 一种自我增强的数据引擎和训练策略，用于大型模型的三维理解'}
{'arxiv_id': 'arXiv:2503.10520', 'title': 'CountPath: Automating Fragment Counting in Digital Pathology', 'authors': 'Ana Beatriz Vieira, Maria Valente, Diana Montezuma, Tomé Albuquerque, Liliana Ribeiro, Domingos Oliveira, João Monteiro, Sofia Gonçalves, Isabel M. Pinto, Jaime S. Cardoso, Arlindo L. Oliveira', 'link': 'https://arxiv.org/abs/2503.10520', 'abstract': 'Quality control of medical images is a critical component of digital pathology, ensuring that diagnostic images meet required standards. A pre-analytical task within this process is the verification of the number of specimen fragments, a process that ensures that the number of fragments on a slide matches the number documented in the macroscopic report. This step is important to ensure that the slides contain the appropriate diagnostic material from the grossing process, thereby guaranteeing the accuracy of subsequent microscopic examination and diagnosis. Traditionally, this assessment is performed manually, requiring significant time and effort while being subject to significant variability due to its subjective nature. To address these challenges, this study explores an automated approach to fragment counting using the YOLOv9 and Vision Transformer models. Our results demonstrate that the automated system achieves a level of performance comparable to expert assessments, offering a reliable and efficient alternative to manual counting. Additionally, we present findings on interobserver variability, showing that the automated approach achieves an accuracy of 86%, which falls within the range of variation observed among experts (82-88%), further supporting its potential for integration into routine pathology workflows.', 'abstract_zh': '医疗图像质量控制是数字病理学的关键组成部分，确保诊断图像达到所需标准。这一过程中的一项预分析任务是标本片段数量的验证，该过程确保载玻片上的片段数量与宏报告中记录的数量相符。这一步骤对于确保载玻片包含来自大体处理的适当诊断材料，从而保证后续显微检查和诊断的准确至关重要。传统上，这种评估是通过人工完成的，耗时且主观性高，容易产生显著的变异。为解决这些挑战，本研究探索了使用YOLOv9和Vision Transformer模型的自动化片段计数方法。研究结果表明，自动化系统在性能上与专家评估相当，提供了一种可靠且高效的替代手工计数的方法。此外，我们还展示了不同观察者间变异性的研究结果，表明自动化方法的准确率为86%，这一数值在专家间观察到的变异范围（82%-88%）之内，进一步支持了其在常规病理工作流程中整合的潜力。', 'title_zh': 'CountPath: 数字病理学中的片段计数自动化'}
{'arxiv_id': 'arXiv:2503.10518', 'title': 'Why the Brain Cannot Be a Digital Computer: History-Dependence and the Computational Limits of Consciousness', 'authors': 'Andrew Knight', 'link': 'https://arxiv.org/abs/2503.10518', 'abstract': 'This paper presents a novel information-theoretic proof demonstrating that the human brain as currently understood cannot function as a classical digital computer. Through systematic quantification of distinguishable conscious states and their historical dependencies, we establish that the minimum information required to specify a conscious state exceeds the physical information capacity of the human brain by a significant factor. Our analysis calculates the bit-length requirements for representing consciously distinguishable sensory "stimulus frames" and demonstrates that consciousness exhibits mandatory temporal-historical dependencies that multiply these requirements beyond the brain\'s storage capabilities. This mathematical approach offers new insights into the fundamental limitations of computational models of consciousness and suggests that non-classical information processing mechanisms may be necessary to account for conscious experience.', 'abstract_zh': '本研究提出了一种新的信息论证明，表明根据当前的理解，人类大脑无法作为经典数字计算机 functioning，通过系统量化可区分的意识状态及其历史依赖性，我们确立了指定一个意识状态所需的最小信息量超出了人类大脑的物理信息容量一个显著的因子。我们的分析计算了表示可区分的感官“刺激帧”的位长要求，并证明了意识表现出强制性的时序历史依赖性，这些依赖性将这些要求乘倍于大脑的存储能力。这种数学方法为计算模型的意识基本限制提供了新的见解，并建议可能需要非经典信息处理机制来解释意识经验。', 'title_zh': '为什么大脑不能是数字计算机：基于历史的依赖性和意识的计算限制'}
{'arxiv_id': 'arXiv:2503.10512', 'title': 'Conformal Prediction Sets for Deep Generative Models via Reduction to Conformal Regression', 'authors': 'Hooman Shahrokhi, Devjeet Raj Roy, Yan Yan, Venera Arnaoudova, Janaradhan Rao Doppa', 'link': 'https://arxiv.org/abs/2503.10512', 'abstract': 'We consider the problem of generating valid and small prediction sets by sampling outputs (e.g., software code and natural language text) from a black-box deep generative model for a given input (e.g., textual prompt). The validity of a prediction set is determined by a user-defined binary admissibility function depending on the target application. For example, requiring at least one program in the set to pass all test cases in code generation application. To address this problem, we develop a simple and effective conformal inference algorithm referred to as Generative Prediction Sets (GPS). Given a set of calibration examples and black-box access to a deep generative model, GPS can generate prediction sets with provable guarantees. The key insight behind GPS is to exploit the inherent structure within the distribution over the minimum number of samples needed to obtain an admissible output to develop a simple conformal regression approach over the minimum number of samples. Experiments on multiple datasets for code and math word problems using different large language models demonstrate the efficacy of GPS over state-of-the-art methods.', 'abstract_zh': '我们考虑通过从给定输入（例如文本提示）的黑盒深度生成模型中采样输出（例如软件代码和自然语言文本）来生成有效且小型的预测集的问题。预测集的有效性由用户定义的二元可接受性函数确定，该函数依赖于目标应用。例如，在代码生成应用中，要求集合中至少有一个程序能够通过所有测试案例。为了解决这一问题，我们开发了一个简单而有效的符合性推断算法，称之为生成预测集（GPS）。给定校准示例集和对深度生成模型的黑盒访问，GPS可以生成具有证明保证的预测集。GPS的核心洞察是利用分布中固有的结构，该结构描述了生成可接受输出所需的最小样本数量，从而开发一种简单的基于最小样本数量的符合性回归方法。使用不同大型语言模型在代码和数学词问题多个数据集上的实验表明，GPS方法优于最新方法的效能。', 'title_zh': '深生成模型中的 conformal 预测集通过转化为 conformal 回归。'}
{'arxiv_id': 'arXiv:2503.10496', 'title': 'Explainable Bayesian deep learning through input-skip Latent Binary Bayesian Neural Networks', 'authors': 'Eirik Høyheim, Lars Skaaret-Lund, Solve Sæbø, Aliaksandr Hubin', 'link': 'https://arxiv.org/abs/2503.10496', 'abstract': 'Modeling natural phenomena with artificial neural networks (ANNs) often provides highly accurate predictions. However, ANNs often suffer from over-parameterization, complicating interpretation and raising uncertainty issues. Bayesian neural networks (BNNs) address the latter by representing weights as probability distributions, allowing for predictive uncertainty evaluation. Latent binary Bayesian neural networks (LBBNNs) further handle structural uncertainty and sparsify models by removing redundant weights. This article advances LBBNNs by enabling covariates to skip to any succeeding layer or be excluded, simplifying networks and clarifying input impacts on predictions. Ultimately, a linear model or even a constant can be found to be optimal for a specific problem at hand. Furthermore, the input-skip LBBNN approach reduces network density significantly compared to standard LBBNNs, achieving over 99% reduction for small networks and over 99.9% for larger ones, while still maintaining high predictive accuracy and uncertainty measurement. For example, on MNIST, we reached 97% accuracy and great calibration with just 935 weights, reaching state-of-the-art for compression of neural networks. Furthermore, the proposed method accurately identifies the true covariates and adjusts for system non-linearity. The main contribution is the introduction of active paths, enhancing directly designed global and local explanations within the LBBNN framework, that have theoretical guarantees and do not require post hoc external tools for explanations.', 'abstract_zh': '用人工神经网络（ANNs）建模自然现象通常能提供高度准确的预测。然而，ANNs往往受到过度参数化的困扰，这 complicating 了解释并引发了不确定性问题。贝叶斯神经网络（BNNs）通过将权重表示为概率分布来解决后者的问题，从而允许对预测不确定性进行评估。潜在二进制贝叶斯神经网络（LBBNNs）进一步处理结构不确定性，并通过移除冗余权重来稀疏化模型。本文通过使协变量能够跳过任何后续层或被排除，推动了LBBNNs的发展，简化了网络并阐明了输入对预测的影响。最终，可以发现对于特定问题来说，线性模型甚至常数可能是最优的。此外，输入跳过的LBBNN方法与标准LBBNN相比，显著减少了网络密度，对于小型网络减少了超过99%，对于大型网络减少了超过99.9%，同时仍保持了高预测准确性和不确定性测量。例如，在MNIST数据集上，我们仅使用935个权重就达到了97%的准确率和良好的校准，这在神经网络压缩技术中达到了最先进的水平。此外，所提出的方法准确地识别了真实的协变量，并调整了系统非线性。主要贡献是引入了活动路径，在LBBNN框架内直接设计全局和局部解释，具有理论保证，并且不需要事后外部工具来进行解释。', 'title_zh': '通过输入跳过潜在二元贝叶斯神经网络的可解释贝叶斯深度学习'}
{'arxiv_id': 'arXiv:2503.10486', 'title': 'LLMs in Disease Diagnosis: A Comparative Study of DeepSeek-R1 and O3 Mini Across Chronic Health Conditions', 'authors': 'Gaurav Kumar Gupta, Pranal Pande', 'link': 'https://arxiv.org/abs/2503.10486', 'abstract': 'Large Language Models (LLMs) are revolutionizing medical diagnostics by enhancing both disease classification and clinical decision-making. In this study, we evaluate the performance of two LLM- based diagnostic tools, DeepSeek R1 and O3 Mini, using a structured dataset of symptoms and diagnoses. We assessed their predictive accuracy at both the disease and category levels, as well as the reliability of their confidence scores. DeepSeek R1 achieved a disease-level accuracy of 76% and an overall accuracy of 82%, outperforming O3 Mini, which attained 72% and 75% respectively. Notably, DeepSeek R1 demonstrated exceptional performance in Mental Health, Neurological Disorders, and Oncology, where it reached 100% accuracy, while O3 Mini excelled in Autoimmune Disease classification with 100% accuracy. Both models, however, struggled with Respiratory Disease classification, recording accuracies of only 40% for DeepSeek R1 and 20% for O3 Mini. Additionally, the analysis of confidence scores revealed that DeepSeek R1 provided high-confidence predictions in 92% of cases, compared to 68% for O3 Mini. Ethical considerations regarding bias, model interpretability, and data privacy are also discussed to ensure the responsible integration of LLMs into clinical practice. Overall, our findings offer valuable insights into the strengths and limitations of LLM-based diagnostic systems and provide a roadmap for future enhancements in AI-driven healthcare.', 'abstract_zh': '大型语言模型（LLMs）正在通过增强疾病分类和临床决策来革新医疗诊断。在本研究中，我们使用症状和诊断的结构化数据评估了两种基于LLM的诊断工具DeepSeek R1和O3 Mini的表现。我们评估了它们在疾病和类别水平上的预测准确性，以及它们置信度评分的可靠性。DeepSeek R1在疾病水平上的准确率为76%，整体准确率为82%，优于O3 Mini的72%和75%。值得注意的是，DeepSeek R1在精神健康、神经系统疾病和肿瘤学领域表现出色，达到100%的准确率，而O3 Mini在自身免疫病分类方面的准确率为100%。然而，这两种模型在呼吸系统疾病的分类方面都表现不佳，DeepSeek R1的准确率为40%，O3 Mini为20%。此外，置信度评分的分析显示，DeepSeek R1在92%的情况下提供了高置信度预测，而O3 Mini为68%。我们还讨论了关于偏见、模型可解释性和数据隐私的伦理考虑，以确保LLM在临床实践中的负责任集成。本研究结果为LLM基于的诊断系统的强项和不足提供了有价值的见解，并提供了未来AI驱动医疗保健改进的路线图。', 'title_zh': 'LLMs在疾病诊断中的比较研究：慢性健康条件下DeepSeek-R1和O3 Mini的对比分析'}
{'arxiv_id': 'arXiv:2503.10471', 'title': 'Siamese Foundation Models for Crystal Structure Prediction', 'authors': 'Liming Wu, Wenbing Huang, Rui Jiao, Jianxing Huang, Liwei Liu, Yipeng Zhou, Hao Sun, Yang Liu, Fuchun Sun, Yuxiang Ren, Jirong Wen', 'link': 'https://arxiv.org/abs/2503.10471', 'abstract': "Crystal Structure Prediction (CSP), which aims to generate stable crystal structures from compositions, represents a critical pathway for discovering novel materials. While structure prediction tasks in other domains, such as proteins, have seen remarkable progress, CSP remains a relatively underexplored area due to the more complex geometries inherent in crystal structures. In this paper, we propose Siamese foundation models specifically designed to address CSP. Our pretrain-finetune framework, named DAO, comprises two complementary foundation models: DAO-G for structure generation and DAO-P for energy prediction. Experiments on CSP benchmarks (MP-20 and MPTS-52) demonstrate that our DAO-G significantly surpasses state-of-the-art (SOTA) methods across all metrics. Extensive ablation studies further confirm that DAO-G excels in generating diverse polymorphic structures, and the dataset relaxation and energy guidance provided by DAO-P are essential for enhancing DAO-G's performance. When applied to three real-world superconductors ($\\text{CsV}_3\\text{Sb}_5$, $ \\text{Zr}_{16}\\text{Rh}_8\\text{O}_4$ and $\\text{Zr}_{16}\\text{Pd}_8\\text{O}_4$) that are known to be challenging to analyze, our foundation models achieve accurate critical temperature predictions and structure generations. For instance, on $\\text{CsV}_3\\text{Sb}_5$, DAO-G generates a structure close to the experimental one with an RMSE of 0.0085; DAO-P predicts the $T_c$ value with high accuracy (2.26 K vs. the ground-truth value of 2.30 K). In contrast, conventional DFT calculators like Quantum Espresso only successfully derive the structure of the first superconductor within an acceptable time, while the RMSE is nearly 8 times larger, and the computation speed is more than 1000 times slower. These compelling results collectively highlight the potential of our approach for advancing materials science research and development.", 'abstract_zh': '晶体结构预测（CSP）：从组成生成稳定晶体结构的关键路径及其在新型材料发现中的应用', 'title_zh': '晶体结构预测中的孪生基础模型'}
{'arxiv_id': 'arXiv:2503.10452', 'title': 'DynaCode: A Dynamic Complexity-Aware Code Benchmark for Evaluating Large Language Models in Code Generation', 'authors': 'Wenhao Hu, Jinhao Duan, Chunchen Wei, Li Zhang, Yue Zhang, Kaidi Xu', 'link': 'https://arxiv.org/abs/2503.10452', 'abstract': "The rapid advancement of large language models (LLMs) has significantly improved their performance in code generation tasks. However, existing code benchmarks remain static, consisting of fixed datasets with predefined problems. This makes them vulnerable to memorization during training, where LLMs recall specific test cases instead of generalizing to new problems, leading to data contamination and unreliable evaluation results. To address these issues, we introduce DynaCode, a dynamic, complexity-aware benchmark that overcomes the limitations of static datasets. DynaCode evaluates LLMs systematically using a complexity-aware metric, incorporating both code complexity and call-graph structures. DynaCode achieves large-scale diversity, generating up to 189 million unique nested code problems across four distinct levels of code complexity, referred to as units, and 16 types of call graphs. Results on 12 latest LLMs show an average performance drop of 16.8% to 45.7% compared to MBPP+, a static code generation benchmark, with performance progressively decreasing as complexity increases. This demonstrates DynaCode's ability to effectively differentiate LLMs. Additionally, by leveraging call graphs, we gain insights into LLM behavior, particularly their preference for handling subfunction interactions within nested code.", 'abstract_zh': '大规模语言模型（LLMs）的迅速发展显著提高了其在代码生成任务中的性能。然而，现有的代码基准仍然保持静态，由固定数据集和预定义的问题组成。这使得它们在训练过程中容易出现记忆现象，即LLMs回忆特定测试案例而不是泛化到新问题，导致数据污染和不可靠的评估结果。为解决这些问题，我们提出了DynaCode，一种动态、复杂性感知的基准，克服了静态数据集的局限性。DynaCode使用复杂性感知度量系统地评估LLMs，结合代码复杂性和调用图结构。DynaCode实现了大规模多样性，生成了高达1.89亿个不同复杂度级别的唯一嵌套代码问题，涵盖四个复杂度单位和16种调用图类型。在12个最新的LLMs上的结果表明，与静态代码生成基准MBPP+相比，平均性能下降16.8%至45.7%，随着复杂性的增加，性能逐渐下降。这证明了DynaCode有效地区分LLMs的能力。此外，通过利用调用图，我们能够深入了解LLM的行为，尤其是它们处理嵌套代码中子函数交互的偏好。', 'title_zh': 'DynaCode: 一种动态复杂性意识代码基准，用于评估代码生成中的大型语言模型'}
{'arxiv_id': 'arXiv:2503.10446', 'title': 'Whisper Speaker Identification: Leveraging Pre-Trained Multilingual Transformers for Robust Speaker Embeddings', 'authors': 'Jakaria Islam Emon, Md Abu Salek, Kazi Tamanna Alam', 'link': 'https://arxiv.org/abs/2503.10446', 'abstract': 'Speaker identification in multilingual settings presents unique challenges, particularly when conventional models are predominantly trained on English data. In this paper, we propose WSI (Whisper Speaker Identification), a framework that repurposes the encoder of the Whisper automatic speech recognition model pre trained on extensive multilingual data to generate robust speaker embeddings via a joint loss optimization strategy that leverages online hard triplet mining and self supervised Normalized Temperature-scaled Cross Entropy loss. By capitalizing on Whisper language-agnostic acoustic representations, our approach effectively distinguishes speakers across diverse languages and recording conditions. Extensive evaluations on multiple corpora, including VoxTube (multilingual), JVS (Japanese), CallHome (German, Spanish, Chinese, and Japanese), and Voxconverse (English), demonstrate that WSI consistently outperforms state-of-the-art baselines, namely Pyannote Embedding, ECAPA TDNN, and Xvector, in terms of lower equal error rates and higher AUC scores. These results validate our hypothesis that a multilingual pre-trained ASR encoder, combined with joint loss optimization, substantially improves speaker identification performance in non-English languages.', 'abstract_zh': '多语言环境下的说话人识别面临独特挑战，特别是在传统模型主要基于英语数据训练的情况下。本文提出了一种WSI（Whisper说话人识别）框架，该框架利用广泛多语言数据预训练的Whisper自动语音识别模型的编码器生成鲁棒的说话人嵌入，并通过结合在线硬三元组挖掘和自监督Normalized Temperature-scaled Cross Entropy损失的联合损失优化策略实现。借助Whisper语言无关的声学表示，我们的方法能够有效区分不同语言和录音条件下的说话人。在包括VoxTube（多语言）、JVS（日语）、CallHome（德语、西班牙语、汉语和日语）和Voxconverse（英语）等多个语料库的广泛评估中，WSI在等错误率和AUC分数方面均优于当前最先进的基线方法（如Pyannote Embedding、ECAPA TDNN和Xvector），验证了我们关于多语言预训练ASR编码器与联合损失优化相结合在非英语语言中显著提高说话人识别性能的假设。', 'title_zh': 'Whisper说话人识别：利用预训练多语言变换器获得稳健的说话人嵌入'}
{'arxiv_id': 'arXiv:2503.10412', 'title': 'dFLMoE: Decentralized Federated Learning via Mixture of Experts for Medical Data Analysis', 'authors': 'Luyuan Xie, Tianyu Luan, Wenyuan Cai, Guochen Yan, Zhaoyu Chen, Nan Xi, Yuejian Fang, Qingni Shen, Zhonghai Wu, Junsong Yuan', 'link': 'https://arxiv.org/abs/2503.10412', 'abstract': "Federated learning has wide applications in the medical field. It enables knowledge sharing among different healthcare institutes while protecting patients' privacy. However, existing federated learning systems are typically centralized, requiring clients to upload client-specific knowledge to a central server for aggregation. This centralized approach would integrate the knowledge from each client into a centralized server, and the knowledge would be already undermined during the centralized integration before it reaches back to each client. Besides, the centralized approach also creates a dependency on the central server, which may affect training stability if the server malfunctions or connections are unstable. To address these issues, we propose a decentralized federated learning framework named dFLMoE. In our framework, clients directly exchange lightweight head models with each other. After exchanging, each client treats both local and received head models as individual experts, and utilizes a client-specific Mixture of Experts (MoE) approach to make collective decisions. This design not only reduces the knowledge damage with client-specific aggregations but also removes the dependency on the central server to enhance the robustness of the framework. We validate our framework on multiple medical tasks, demonstrating that our method evidently outperforms state-of-the-art approaches under both model homogeneity and heterogeneity settings.", 'abstract_zh': '联邦学习在医疗领域有广泛的应用。它使得不同的医疗机构能够在保护患者隐私的前提下进行知识共享。然而，现有的联邦学习系统通常采用中心化的方式，要求客户端将客户特定的知识上传到中央服务器进行聚合。这种中心化的方法会在中央服务器整合知识时就已经损害了知识的完整性，在返回给每个客户端之前进一步削弱了知识。此外，中心化方法还会对中央服务器产生依赖，如果服务器出现故障或连接不稳定，会影响训练的稳定性。为了解决这些问题，我们提出了一种去中心化的联邦学习框架，名为dFLMoE。在该框架中，客户端直接互相交换轻量级头部模型。之后，每个客户端将本地和接收到的头部模型视为独立专家，并利用客户端特定的专家混合（MoE）方法进行集体决策。这种设计不仅通过客户端特定的聚合减少了知识损害，还消除了对中央服务器的依赖，增强了框架的鲁棒性。我们在多个医疗任务上验证了该框架，结果表明，在模型同质性和异质性设置下，我们的方法明显优于现有最先进的方法。', 'title_zh': 'dFLMoE: 基于专家混合的去中心化联邦学习在医疗数据分析中的应用'}
{'arxiv_id': 'arXiv:2503.10406', 'title': 'RealGeneral: Unifying Visual Generation via Temporal In-Context Learning with Video Models', 'authors': 'Yijing Lin, Mengqi Huang, Shuhan Zhuang, Zhendong Mao', 'link': 'https://arxiv.org/abs/2503.10406', 'abstract': 'Unifying diverse image generation tasks within a single framework remains a fundamental challenge in visual generation. While large language models (LLMs) achieve unification through task-agnostic data and generation, existing visual generation models fail to meet these principles. Current approaches either rely on per-task datasets and large-scale training or adapt pre-trained image models with task-specific modifications, limiting their generalizability. In this work, we explore video models as a foundation for unified image generation, leveraging their inherent ability to model temporal correlations. We introduce RealGeneral, a novel framework that reformulates image generation as a conditional frame prediction task, analogous to in-context learning in LLMs. To bridge the gap between video models and condition-image pairs, we propose (1) a Unified Conditional Embedding module for multi-modal alignment and (2) a Unified Stream DiT Block with decoupled adaptive LayerNorm and attention mask to mitigate cross-modal interference. RealGeneral demonstrates effectiveness in multiple important visual generation tasks, e.g., it achieves a 14.5% improvement in subject similarity for customized generation and a 10% enhancement in image quality for canny-to-image task. Project page: this https URL', 'abstract_zh': '将多样的图像生成任务统一在一个框架内仍然是视觉生成中的一个基础挑战。虽然大型语言模型（LLMs）通过任务无关的数据和生成实现统一，但现有的视觉生成模型未能遵循这些原则。当前的方法要么依赖于每个任务的数据集和大规模训练，要么通过特定任务的修改预训练图像模型，这限制了它们的泛化能力。在本工作中，我们探索使用视频模型作为统一图像生成的基础，利用其固有的建模时间相关性的能力。我们引入了RealGeneral，一种新颖的框架，将图像生成重新表述为条件帧预测任务，类似于LLMs中的上下文无关学习。为了弥合视频模型与条件图像配对之间的差距，我们提出了一种统一的条件嵌入模块进行多模态对齐，以及一种统一的Stream DiT块，具有解耦的自适应层规范和注意掩码，以减轻跨模态干扰。RealGeneral在重要的视觉生成任务中显示出有效性，例如，在定制生成中实现了14.5%的主题相似性提升，在Canny-to-image任务中实现了10%的图像质量增强。项目页面: [this](this https URL)', 'title_zh': 'RealGeneral: 通过视频模型的时序内上下文学习统一视觉生成'}
{'arxiv_id': 'arXiv:2503.10392', 'title': 'RoMA: Scaling up Mamba-based Foundation Models for Remote Sensing', 'authors': 'Fengxiang Wang, Hongzhen Wang, Yulin Wang, Di Wang, Mingshuo Chen, Haiyan Zhao, Yangang Sun, Shuo Wang, Long Lan, Wenjing Yang, Jing Zhang', 'link': 'https://arxiv.org/abs/2503.10392', 'abstract': 'Recent advances in self-supervised learning for Vision Transformers (ViTs) have fueled breakthroughs in remote sensing (RS) foundation models. However, the quadratic complexity of self-attention poses a significant barrier to scalability, particularly for large models and high-resolution images. While the linear-complexity Mamba architecture offers a promising alternative, existing RS applications of Mamba remain limited to supervised tasks on small, domain-specific datasets. To address these challenges, we propose RoMA, a framework that enables scalable self-supervised pretraining of Mamba-based RS foundation models using large-scale, diverse, unlabeled data. RoMA enhances scalability for high-resolution images through a tailored auto-regressive learning strategy, incorporating two key innovations: 1) a rotation-aware pretraining mechanism combining adaptive cropping with angular embeddings to handle sparsely distributed objects with arbitrary orientations, and 2) multi-scale token prediction objectives that address the extreme variations in object scales inherent to RS imagery. Systematic empirical studies validate that Mamba adheres to RS data and parameter scaling laws, with performance scaling reliably as model and data size increase. Furthermore, experiments across scene classification, object detection, and semantic segmentation tasks demonstrate that RoMA-pretrained Mamba models consistently outperform ViT-based counterparts in both accuracy and computational efficiency. The source code and pretrained models will be released at this https URL.', 'abstract_zh': 'Recent Advances in Scalable Self-Supervised Pretraining of Mamba-Based Remote Sensing Foundation Models Using RoMA', 'title_zh': 'RoMA: 基于Mamba的基础模型在遥感领域的规模化应用'}
{'arxiv_id': 'arXiv:2503.10391', 'title': 'CINEMA: Coherent Multi-Subject Video Generation via MLLM-Based Guidance', 'authors': 'Yufan Deng, Xun Guo, Yizhi Wang, Jacob Zhiyuan Fang, Angtian Wang, Shenghai Yuan, Yiding Yang, Bo Liu, Haibin Huang, Chongyang Ma', 'link': 'https://arxiv.org/abs/2503.10391', 'abstract': 'Video generation has witnessed remarkable progress with the advent of deep generative models, particularly diffusion models. While existing methods excel in generating high-quality videos from text prompts or single images, personalized multi-subject video generation remains a largely unexplored challenge. This task involves synthesizing videos that incorporate multiple distinct subjects, each defined by separate reference images, while ensuring temporal and spatial consistency. Current approaches primarily rely on mapping subject images to keywords in text prompts, which introduces ambiguity and limits their ability to model subject relationships effectively. In this paper, we propose CINEMA, a novel framework for coherent multi-subject video generation by leveraging Multimodal Large Language Model (MLLM). Our approach eliminates the need for explicit correspondences between subject images and text entities, mitigating ambiguity and reducing annotation effort. By leveraging MLLM to interpret subject relationships, our method facilitates scalability, enabling the use of large and diverse datasets for training. Furthermore, our framework can be conditioned on varying numbers of subjects, offering greater flexibility in personalized content creation. Through extensive evaluations, we demonstrate that our approach significantly improves subject consistency, and overall video coherence, paving the way for advanced applications in storytelling, interactive media, and personalized video generation.', 'abstract_zh': '视频生成领域在深度生成模型，特别是扩散模型的出现下取得了显著进展。尽管现有方法在从文本提示或单张图像生成高质量视频方面表现出色，但个性化多主体视频生成仍然是一个未被充分探索的挑战。该任务涉及合成包含多个独立主体的视频，每个主体由单独的参考图像定义，同时确保时间和空间的一致性。当前方法主要依赖于将主体图像映射到文本提示中的关键词，这引入了不确定性并限制了其对主体关系建模的能力。在本文中，我们提出CINEMA，一种利用多模态大型语言模型（MLLM）进行连贯多主体视频生成的新框架。我们的方法消除了主体图像与文本实体之间需要明确对应的需要，从而降低了不确定性并减少了注释工作量。通过利用MLLM解释主体关系，我们的方法增强了可扩展性，使得可以用大量的多样化数据集进行训练。此外，我们的框架可以针对不同数量的主体进行条件化，提供了更大的个性化内容创作灵活性。通过广泛评估，我们证明了我们的方法显著提高了主体一致性并增强了整体视频连贯性，为叙事、交互式媒体和个人化视频生成等高级应用铺平了道路。', 'title_zh': 'CINEMA：基于MLLM的引导一致多主体视频生成'}
{'arxiv_id': 'arXiv:2503.10371', 'title': 'A Multimodal Fusion Model Leveraging MLP Mixer and Handcrafted Features-based Deep Learning Networks for Facial Palsy Detection', 'authors': 'Heng Yim Nicole Oo, Min Hun Lee, Jeong Hoon Lim', 'link': 'https://arxiv.org/abs/2503.10371', 'abstract': 'Algorithmic detection of facial palsy offers the potential to improve current practices, which usually involve labor-intensive and subjective assessments by clinicians. In this paper, we present a multimodal fusion-based deep learning model that utilizes an MLP mixer-based model to process unstructured data (i.e. RGB images or images with facial line segments) and a feed-forward neural network to process structured data (i.e. facial landmark coordinates, features of facial expressions, or handcrafted features) for detecting facial palsy. We then contribute to a study to analyze the effect of different data modalities and the benefits of a multimodal fusion-based approach using videos of 20 facial palsy patients and 20 healthy subjects. Our multimodal fusion model achieved 96.00 F1, which is significantly higher than the feed-forward neural network trained on handcrafted features alone (82.80 F1) and an MLP mixer-based model trained on raw RGB images (89.00 F1).', 'abstract_zh': '基于多模态融合的深度学习模型在面部瘫痪检测中的应用：改善当前劳动密集型和主观的临床评估实践', 'title_zh': '利用MLP混合器和基于手工特征的深度学习网络的多模态融合模型在面瘫检测中的应用'}
{'arxiv_id': 'arXiv:2503.10367', 'title': 'G-Boost: Boosting Private SLMs with General LLMs', 'authors': 'Yijiang Fan, Yuren Mao, Longbin Lai, Ying Zhang, Zhengping Qian, Yunjun Gao', 'link': 'https://arxiv.org/abs/2503.10367', 'abstract': 'Due to the limited computational resources, most Large Language Models (LLMs) developers can only fine-tune Small Language Models (SLMs) on their own data. These private SLMs typically have limited effectiveness. To boost the performance of private SLMs, this paper proposes to ask general LLMs for help. The general LLMs can be APIs or larger LLMs whose inference cost the developers can afford. Specifically, we propose the G-Boost framework where a private SLM adaptively performs collaborative inference with a general LLM under the guide of process reward. Experiments demonstrate that our framework can significantly boost the performance of private SLMs.', 'abstract_zh': '由于计算资源有限，大多数大型语言模型开发者只能在其自有数据上 fine-tune 小型语言模型。这些私有小型语言模型通常效果有限。为了提升私有小型语言模型的性能，本文提出请求通用大型语言模型提供帮助的方法。通用大型语言模型可以是 API 或者开发者负担得起推理成本的更大模型。具体而言，我们提出了 G-Boost 框架，在该框架下，私有小型语言模型在过程奖励的指导下与通用大型语言模型协作推理。实验结果表明，我们的框架能够显著提升私有小型语言模型的性能。', 'title_zh': 'G-Boost: 通过通用大语言模型增强私有SLMs'}
{'arxiv_id': 'arXiv:2503.10356', 'title': 'Object detection characteristics in a learning factory environment using YOLOv8', 'authors': 'Toni Schneidereit, Stefan Gohrenz, Michael Breuß', 'link': 'https://arxiv.org/abs/2503.10356', 'abstract': 'AI-based object detection, and efforts to explain and investigate their characteristics, is a topic of high interest. The impact of, e.g., complex background structures with similar appearances as the objects of interest, on the detection accuracy and, beforehand, the necessary dataset composition are topics of ongoing research. In this paper, we present a systematic investigation of background influences and different features of the object to be detected. The latter includes various materials and surfaces, partially transparent and with shiny reflections in the context of an Industry 4.0 learning factory. Different YOLOv8 models have been trained for each of the materials on different sized datasets, where the appearance was the only changing parameter. In the end, similar characteristics tend to show different behaviours and sometimes unexpected results. While some background components tend to be detected, others with the same features are not part of the detection. Additionally, some more precise conclusions can be drawn from the results. Therefore, we contribute a challenging dataset with detailed investigations on 92 trained YOLO models, addressing some issues on the detection accuracy and possible overfitting.', 'abstract_zh': '基于AI的物体检测及其背景影响和特征研究是一个高度关注的课题。复杂背景结构与目标物体相似的外观对其检测准确性和事先所需的数据库构成的影响是持续的研究主题。本文系统地研究了背景影响和要检测物体的不同特征，包括工业4.0学习工厂背景下各种材料和表面，部分透明且带有光泽反射。针对每种材料分别训练了不同规模数据集的YOLOv8模型，其中仅改变外观参数。最终，相似特征表现出不同的行为，有时甚至是出人意料的结果。虽然某些背景成分会被检测到，但具有相同特征的其他成分则不会被包含在内。此外，从结果中还可以得出一些更精确的结论。因此，本文贡献了一个具有详尽研究的挑战性数据集，涉及92个训练好的YOLO模型，解决了检测准确性和可能出现的过拟合问题。', 'title_zh': '使用YOLOv8在学习工厂环境中进行目标检测的特点'}
{'arxiv_id': 'arXiv:2503.10337', 'title': 'KV-Distill: Nearly Lossless Learnable Context Compression for LLMs', 'authors': 'Vivek Chari, Guanghui Qin, Benjamin Van Durme', 'link': 'https://arxiv.org/abs/2503.10337', 'abstract': 'Sequence-to-sequence tasks often benefit from long contexts, but the quadratic complexity of self-attention in standard Transformers renders this non-trivial. During generation, temporary representations -stored in the so-called KV cache-account for a large portion of GPU memory usage and scale linearly with context length. We introduce KV-Distill, a Transformer compression framework that distills long context KV caches into significantly shorter representations in a question-independent fashion. KV-Distill can be trained as a parameter-efficient adaptor for pretrained models, and enables the compression of arbitrary spans of a context while preserving pre-trained model capabilities. We treat a compressed-uncompressed cache as a student-teacher pairing and apply a KL-type divergence to match the generated outputs. KV-Distill outperforms other compression techniques in worst-case extractive tasks and approaches uncompressed performance in long context question answering and summarization, and it can be fine-tuned on domain-specific contexts to reduce lengths by up to 99% while preserving downstream performance. We demonstrate the generalizability of KV-Distill across various model sizes and architectures.', 'abstract_zh': '基于序列的任务往往可以从长上下文中受益，但标准Transformer中的自注意机制的二次复杂性使得这一点并不简单。在生成过程中，临时表示——存储在所谓的KV缓存中——占用了大量的GPU内存，并且与上下文长度成线性关系。我们引入了KV-Distill，这是一种Transformer压缩框架，能够在问题无关的情况下将长上下文的KV缓存压缩为显著较短的表示。KV-Distill可以作为参数高效适配器进行预训练模型的训练，并能够压缩上下文的任意部分同时保留预训练模型的能力。我们将压缩-未压缩缓存视为学生-教师配对，并应用KL型散度来匹配生成的输出。KV-Distill在最坏情况下的提取任务中表现出色，并在长上下文问答和总结任务中接近未压缩性能，同时可以通过特定领域上下文的微调最多减少99%的长度而不影响下游性能。KV-Distill在不同模型大小和架构中展示了通用性。', 'title_zh': 'KV-精炼：几乎无损的学习可微上下文压缩 for 大型语言模型'}
{'arxiv_id': 'arXiv:2503.10331', 'title': 'OSMa-Bench: Evaluating Open Semantic Mapping Under Varying Lighting Conditions', 'authors': 'Maxim Popov, Regina Kurkova, Mikhail Iumanov, Jaafar Mahmoud, Sergey Kolyubin', 'link': 'https://arxiv.org/abs/2503.10331', 'abstract': 'Open Semantic Mapping (OSM) is a key technology in robotic perception, combining semantic segmentation and SLAM techniques. This paper introduces a dynamically configurable and highly automated LLM/LVLM-powered pipeline for evaluating OSM solutions called OSMa-Bench (Open Semantic Mapping Benchmark). The study focuses on evaluating state-of-the-art semantic mapping algorithms under varying indoor lighting conditions, a critical challenge in indoor environments. We introduce a novel dataset with simulated RGB-D sequences and ground truth 3D reconstructions, facilitating the rigorous analysis of mapping performance across different lighting conditions. Through experiments on leading models such as ConceptGraphs, BBQ and OpenScene, we evaluate the semantic fidelity of object recognition and segmentation. Additionally, we introduce a Scene Graph evaluation method to analyze the ability of models to interpret semantic structure. The results provide insights into the robustness of these models, forming future research directions for developing resilient and adaptable robotic systems. Our code is available at this https URL.', 'abstract_zh': 'Open Semantic Mapping (OSM)是机器人感知中的关键技术，结合了语义分割和SLAM技术。本文介绍了一种基于LLM/LVLM的动态可配置且高度自动化的管线OSMa-Bench（Open Semantic MappingBenchmark），用于评估OSM解决方案。该研究重点评估了在不同室内光照条件下的前沿语义映射算法，这是室内环境中的一项关键挑战。我们引入了一个新的包含模拟RGB-D序列及其地面 truth 3D重建的数据集，便于对不同光照条件下的映射性能进行严格的分析。通过在ConceptGraphs、BBQ和OpenScene等领先模型上进行实验，我们评估了物体识别和分割的语义精度。此外，我们引入了一种场景图评估方法，以分析模型理解语义结构的能力。结果提供了这些模型鲁棒性的见解，为开发稳健且适应性强的机器人系统的未来研究指明了方向。相关代码可在此处获取。', 'title_zh': 'OSMa-Bench：在不同光照条件下评估开放语义映射'}
{'arxiv_id': 'arXiv:2503.10318', 'title': 'Enhance Exploration in Safe Reinforcement Learning with Contrastive Representation Learning', 'authors': 'Duc Kien Doan, Bang Giang Le, Viet Cuong Ta', 'link': 'https://arxiv.org/abs/2503.10318', 'abstract': 'In safe reinforcement learning, agent needs to balance between exploration actions and safety constraints. Following this paradigm, domain transfer approaches learn a prior Q-function from the related environments to prevent unsafe actions. However, because of the large number of false positives, some safe actions are never executed, leading to inadequate exploration in sparse-reward environments. In this work, we aim to learn an efficient state representation to balance the exploration and safety-prefer action in a sparse-reward environment. Firstly, the image input is mapped to latent representation by an auto-encoder. A further contrastive learning objective is employed to distinguish safe and unsafe states. In the learning phase, the latent distance is used to construct an additional safety check, which allows the agent to bias the exploration if it visits an unsafe state. To verify the effectiveness of our method, the experiment is carried out in three navigation-based MiniGrid environments. The result highlights that our method can explore the environment better while maintaining a good balance between safety and efficiency.', 'abstract_zh': '在安全强化学习中，代理需要在探索动作和安全性约束之间寻求平衡。遵循这一范式，领域迁移方法从相关环境中学习先验Q函数，以防止不安全动作。然而，由于大量误报警，一些安全动作从未被执行，导致在稀疏奖励环境中探索不足。在此工作中，我们旨在学习一种高效的状态表示，以在稀疏奖励环境中平衡探索和安全优先动作。首先，图像输入通过自动编码器映射到潜在表示。进一步采用对比学习目标以区分安全和不安全状态。在学习阶段，使用潜在距离构建额外的安全检查，允许代理在访问不安全状态时偏向探索。为验证方法的有效性，实验在三個基于导航的MiniGrid环境中进行。结果显示，我们的方法可以在保持安全和效率良好平衡的同时更好地探索环境。', 'title_zh': '通过对比表示学习增强安全强化学习中的探索'}
{'arxiv_id': 'arXiv:2503.10304', 'title': 'Nash Equilibrium Constrained Auto-bidding With Bi-level Reinforcement Learning', 'authors': 'Zhiyu Mou, Miao Xu, Rongquan Bai, Zhuoran Yang, Chuan Yu, Jian Xu, Bo Zheng', 'link': 'https://arxiv.org/abs/2503.10304', 'abstract': "Many online advertising platforms provide advertisers with auto-bidding services to enhance their advertising performance. However, most existing auto-bidding algorithms fail to accurately capture the auto-bidding problem formulation that the platform truly faces, let alone solve it. Actually, we argue that the platform should try to help optimize each advertiser's performance to the greatest extent -- which makes $\\epsilon$-Nash Equilibrium ($\\epsilon$-NE) a necessary solution concept -- while maximizing the social welfare of all the advertisers for the platform's long-term value. Based on this, we introduce the \\emph{Nash-Equilibrium Constrained Bidding} (NCB), a new formulation of the auto-bidding problem from the platform's perspective. Specifically, it aims to maximize the social welfare of all advertisers under the $\\epsilon$-NE constraint. However, the NCB problem presents significant challenges due to its constrained bi-level structure and the typically large number of advertisers involved. To address these challenges, we propose a \\emph{Bi-level Policy Gradient} (BPG) framework with theoretical guarantees. Notably, its computational complexity is independent of the number of advertisers, and the associated gradients are straightforward to compute. Extensive simulated and real-world experiments validate the effectiveness of the BPG framework.", 'abstract_zh': 'Many Online广告平台提供的自动出价服务旨在提升广告效果。然而，现有的大多数自动出价算法未能准确捕捉到平台实际面临的问题形式，更不用说解决它了。实际上，我们认为平台应该尽可能帮助优化每个广告商的表现——这使得ε纳什均衡（ε-NE）成为必要的解决方案概念——同时最大化所有广告商的社会福利，以提升平台的长期价值。基于此，我们介绍了一种从平台视角出发的新形式的自动出价问题——纳什均衡约束出价（Nash-Equilibrium Constrained Bidding, NCB），其目标是在ε-NE约束下最大化所有广告商的社会福利。然而，由于NCB问题具有约束的双层结构，并且涉及的广告商数量通常较多，因此提出了一个具有理论保证的双层策略梯度（Bi-level Policy Gradient, BPG）框架。值得注意的是，其计算复杂度与广告商数量无关，相关的梯度也易于计算。大量的仿真和实际实验验证了BPG框架的有效性。', 'title_zh': 'Nash均衡约束下的双层强化学习自出价策略'}
{'arxiv_id': 'arXiv:2503.10301', 'title': "Bilingual Dual-Head Deep Model for Parkinson's Disease Detection from Speech", 'authors': 'Moreno La Quatra, Juan Rafael Orozco-Arroyave, Marco Sabato Siniscalchi', 'link': 'https://arxiv.org/abs/2503.10301', 'abstract': "This work aims to tackle the Parkinson's disease (PD) detection problem from the speech signal in a bilingual setting by proposing an ad-hoc dual-head deep neural architecture for type-based binary classification. One head is specialized for diadochokinetic patterns. The other head looks for natural speech patterns present in continuous spoken utterances. Only one of the two heads is operative accordingly to the nature of the input. Speech representations are extracted from self-supervised learning (SSL) models and wavelet transforms. Adaptive layers, convolutional bottlenecks, and contrastive learning are exploited to reduce variations across languages. Our solution is assessed against two distinct datasets, EWA-DB, and PC-GITA, which cover Slovak and Spanish languages, respectively. Results indicate that conventional models trained on a single language dataset struggle with cross-linguistic generalization, and naive combinations of datasets are suboptimal. In contrast, our model improves generalization on both languages, simultaneously.", 'abstract_zh': '本研究旨在通过提出一种特定于类型的小双头深度神经架构，解决双语环境中从语音信号检测帕金森病（PD）的问题。一个分支专门识别迭言运动模式，另一个分支寻找连续口头表达中存在的自然语言模式。根据输入的性质，仅有一个分支处于激活状态。语音表示通过半监督学习模型和小波变换提取。利用自适应层、卷积瓶颈和对比学习减少语言间的变异。我们的解决方案在EWA-DB（斯洛伐克语）和PC-GITA（西班牙语）两个不同数据集上进行评估。结果表明，单语言数据集训练的模型在跨语言泛化上存在困难，简单地组合数据集也效果不佳。相比之下，我们的模型能够同时在两种语言上提高泛化能力。', 'title_zh': '针对语音的双头双语深度模型在帕金森病检测中的应用'}
{'arxiv_id': 'arXiv:2503.10296', 'title': 'CODEI: Resource-Efficient Task-Driven Co-Design of Perception and Decision Making for Mobile Robots Applied to Autonomous Vehicles', 'authors': 'Dejan Milojevic, Gioele Zardini, Miriam Elser, Andrea Censi, Emilio Frazzoli', 'link': 'https://arxiv.org/abs/2503.10296', 'abstract': 'This paper discusses the integration challenges and strategies for designing mobile robots, by focusing on the task-driven, optimal selection of hardware and software to balance safety, efficiency, and minimal usage of resources such as costs, energy, computational requirements, and weight. We emphasize the interplay between perception and motion planning in decision-making by introducing the concept of occupancy queries to quantify the perception requirements for sampling-based motion planners. Sensor and algorithm performance are evaluated using False Negative Rates (FPR) and False Positive Rates (FPR) across various factors such as geometric relationships, object properties, sensor resolution, and environmental conditions. By integrating perception requirements with perception performance, an Integer Linear Programming (ILP) approach is proposed for efficient sensor and algorithm selection and placement. This forms the basis for a co-design optimization that includes the robot body, motion planner, perception pipeline, and computing unit. We refer to this framework for solving the co-design problem of mobile robots as CODEI, short for Co-design of Embodied Intelligence. A case study on developing an Autonomous Vehicle (AV) for urban scenarios provides actionable information for designers, and shows that complex tasks escalate resource demands, with task performance affecting choices of the autonomy stack. The study demonstrates that resource prioritization influences sensor choice: cameras are preferred for cost-effective and lightweight designs, while lidar sensors are chosen for better energy and computational efficiency.', 'abstract_zh': '本论文讨论了移动机器人设计中的集成挑战与策略，重点关注任务驱动下的硬件和软件优化选择，以平衡安全、效率及成本、能耗、计算需求和重量等资源的最小使用。文中强调感知与运动规划之间的交互作用，在决策中引入占用查询的概念，以量化基于采样运动规划器的感知需求。传感器和算法性能通过误判率（False Negative Rates 和 False Positive Rates）在几何关系、物体属性、传感器分辨率及环境条件等多种因素下进行评估。通过将感知需求与感知性能集成，提出了整数线性规划（Integer Linear Programming）方法，用于高效选择和布置传感器与算法。该方法为基础，涵盖了机器人本体、运动规划器、感知流水线和计算单元的协同设计优化。文中提出的一种解决移动机器人协同设计问题的框架称为CODEI，即协同设计体域智能。一个针对城市场景的自主车辆（AV）开发案例研究为设计师提供了实用信息，表明复杂的任务会增加资源需求，任务性能影响自主堆栈的选择。研究显示，资源优先级影响传感器选择：成本效益高且轻量化设计倾向于使用摄像头，而为了更好的能耗和计算效率，则选择激光雷达传感器。', 'title_zh': 'CODEI: 资源高效的任务驱动感知与决策协同设计及其在自主车辆中的应用'}
{'arxiv_id': 'arXiv:2503.10284', 'title': 'PyGDA: A Python Library for Graph Domain Adaptation', 'authors': 'Zhen Zhang, Meihan Liu, Bingsheng He', 'link': 'https://arxiv.org/abs/2503.10284', 'abstract': 'Graph domain adaptation has emerged as a promising approach to facilitate knowledge transfer across different domains. Recently, numerous models have been proposed to enhance their generalization capabilities in this field. However, there is still no unified library that brings together existing techniques and simplifies their implementation. To fill this gap, we introduce PyGDA, an open-source Python library tailored for graph domain adaptation. As the first comprehensive library in this area, PyGDA covers more than 20 widely used graph domain adaptation methods together with different types of graph datasets. Specifically, PyGDA offers modular components, enabling users to seamlessly build custom models with a variety of commonly used utility functions. To handle large-scale graphs, PyGDA includes support for features such as sampling and mini-batch processing, ensuring efficient computation. In addition, PyGDA also includes comprehensive performance benchmarks and well-documented user-friendly API for both researchers and practitioners. To foster convenient accessibility, PyGDA is released under the MIT license at this https URL, and the API documentation is this https URL.', 'abstract_zh': 'Graph域适应已经成为一种促进不同领域知识迁移的有前途的方法。最近，提出了许多模型以增强其在该领域的泛化能力。然而，目前还没有一个统一的库将现有技术整合在一起并简化其实现。为填补这一空白，我们介绍了PyGDA，一个专为Graph域适应开发的开源Python库。作为该领域的首个综合库，PyGDA涵盖了超过20种广泛使用的方法以及不同类型的Graph数据集。具体而言，PyGDA提供模块化组件，使用户能够无缝构建自定义模型，并使用各种常用工具函数。为了处理大规模Graph，PyGDA支持采样和小批量处理等功能，确保高效计算。此外，PyGDA还包含全面的性能基准测试和文档详尽的用户友好型API，适用于研究人员和实践者。为便于访问，PyGDA在<https://>下以MIT许可证发布，并提供了API文档<https://>。', 'title_zh': 'PyGDA：一种用于图域适应的Python库'}
{'arxiv_id': 'arXiv:2503.10253', 'title': 'PIMRL: Physics-Informed Multi-Scale Recurrent Learning for Spatiotemporal Prediction', 'authors': 'Han Wan, Qi Wang, Hao Sun', 'link': 'https://arxiv.org/abs/2503.10253', 'abstract': 'Simulation of spatiotemporal systems governed by partial differential equations is widely applied in fields such as biology, chemistry, aerospace dynamics, and meteorology. Traditional numerical methods incur high computational costs due to the requirement of small time steps for accurate predictions. While machine learning has reduced these costs, long-term predictions remain challenged by error accumulation, particularly in scenarios with insufficient data or varying time scales, where stability and accuracy are compromised. Existing methods often neglect the effective utilization of multi-scale data, leading to suboptimal robustness in predictions. To address these issues, we propose a novel multi-scale learning framework, namely, the Physics-Informed Multi-Scale Recurrent Learning (PIMRL), to effectively leverage multi-scale data for spatiotemporal dynamics prediction. The PIMRL framework comprises two modules: the micro-scale module embeds physical knowledge into neural networks via pretraining, and the macro-scale module adopts a data-driven approach to learn the temporal evolution of physics in the latent space. Experimental results demonstrate that the PIMRL framework consistently achieves state-of-the-art performance across five benchmark datasets ranging from one to three dimensions, showing average improvements of over 9\\% in both RMSE and MAE evaluation metrics, with maximum enhancements reaching up to 80%.', 'abstract_zh': '基于偏微分方程支配的空间时间系统的仿真广泛应用于生物学、化学、航空航天动力学和气象学等领域。传统的数值方法由于需要较小的时间步长以获得准确预测而产生高额的计算成本。尽管机器学习降低了这些成本，但在数据不足或时间尺度变化的情况下，长期预测仍然面临误差累积的挑战，导致稳定性和准确性受损。现有方法往往忽视了多尺度数据的有效利用，从而导致预测的鲁棒性不足。为了解决这些问题，我们提出了一种新的多尺度学习框架，即物理知情多尺度递归学习（PIMRL），以有效利用多尺度数据进行空间时间动力学预测。PIMRL框架包括两个模块：微观尺度模块通过预训练将物理知识嵌入神经网络中，宏观尺度模块采用数据驱动的方法在潜在空间学习物理的时空演变。实验结果表明，PIMRL框架在从一维到三维的五个基准数据集中均取得了最先进的性能，展示了平均9%以上的RMSE和MAE评估指标改进，最大提升达到80%。', 'title_zh': 'PIMRL：物理启发的多尺度递归学习在时空预测中的应用'}
{'arxiv_id': 'arXiv:2503.10242', 'title': 'MinorBench: A hand-built benchmark for content-based risks for children', 'authors': 'Shaun Khoo, Gabriel Chua, Rachel Shong', 'link': 'https://arxiv.org/abs/2503.10242', 'abstract': "Large Language Models (LLMs) are rapidly entering children's lives - through parent-driven adoption, schools, and peer networks - yet current AI ethics and safety research do not adequately address content-related risks specific to minors. In this paper, we highlight these gaps with a real-world case study of an LLM-based chatbot deployed in a middle school setting, revealing how students used and sometimes misused the system. Building on these findings, we propose a new taxonomy of content-based risks for minors and introduce MinorBench, an open-source benchmark designed to evaluate LLMs on their ability to refuse unsafe or inappropriate queries from children. We evaluate six prominent LLMs under different system prompts, demonstrating substantial variability in their child-safety compliance. Our results inform practical steps for more robust, child-focused safety mechanisms and underscore the urgency of tailoring AI systems to safeguard young users.", 'abstract_zh': '大型语言模型（LLMs）正迅速进入儿童的生活——通过父母的采用、学校和同龄人网络——然而当前的AI伦理和安全研究未能充分应对特定于未成年人的内容相关风险。在这篇论文中，我们通过一个中学校园环境中的LLM聊天机器人案例研究，揭示了学生如何使用并有时误用该系统，从而指出现有研究中的缺口。基于这些发现，我们提出了一种新的针对未成年人的内容相关风险分类，并介绍了MinorBench，一个开源基准，用于评估LLM在拒绝儿童发出的不安全或不适当查询方面的能力。我们对六种主流LLM在不同系统提示下的表现进行了评估，展示了它们在儿童安全合规性方面的显著差异。我们的结果为构建更 robust、更关注儿童的安全机制提供了实用步骤，并强调了调整AI系统以保护年轻用户的重要性。', 'title_zh': 'MinorBench: 一个手工构建的内容相关儿童风险基准测试'}
{'arxiv_id': 'arXiv:2503.10217', 'title': 'Efficient Federated Fine-Tuning of Large Language Models with Layer Dropout', 'authors': 'Shilong Wang, Jianchun Liu, Hongli Xu, Jiaming Yan, Xianjun Gao', 'link': 'https://arxiv.org/abs/2503.10217', 'abstract': 'Fine-tuning plays a crucial role in enabling pre-trained LLMs to evolve from general language comprehension to task-specific expertise. To preserve user data privacy, federated fine-tuning is often employed and has emerged as the de facto paradigm. However, federated fine-tuning is prohibitively inefficient due to the tension between LLM complexity and the resource constraint of end devices, incurring unaffordable fine-tuning overhead. Existing literature primarily utilizes parameter-efficient fine-tuning techniques to mitigate communication costs, yet computational and memory burdens continue to pose significant challenges for developers. This work proposes DropPEFT, an innovative federated PEFT framework that employs a novel stochastic transformer layer dropout method, enabling devices to deactivate a considerable fraction of LLMs layers during training, thereby eliminating the associated computational load and memory footprint. In DropPEFT, a key challenge is the proper configuration of dropout ratios for layers, as overhead and training performance are highly sensitive to this setting. To address this challenge, we adaptively assign optimal dropout-ratio configurations to devices through an exploration-exploitation strategy, achieving efficient and effective fine-tuning. Extensive experiments show that DropPEFT can achieve a 1.3-6.3\\times speedup in model convergence and a 40%-67% reduction in memory footprint compared to state-of-the-art methods.', 'abstract_zh': 'Fine-tuning plays a crucial role in enabling pre-trained LLMs to evolve from general language comprehension to task-specific expertise. To preserve user data privacy, federated fine-tuning is often employed and has emerged as the de facto paradigm. However, federated fine-tuning is prohibitively inefficient due to the tension between LLM complexity and the resource constraint of end devices, incurring unaffordable fine-tuning overhead. Existing literature primarily utilizes parameter-efficient fine-tuning techniques to mitigate communication costs, yet computational and memory burdens continue to pose significant challenges for developers. This work proposes DropPEFT, an innovative federated PEFT framework that employs a novel stochastic transformer layer dropout method, enabling devices to deactivate a considerable fraction of LLMs layers during training, thereby eliminating the associated computational load and memory footprint. In DropPEFT, a key challenge is the proper configuration of dropout ratios for layers, as overhead and training performance are highly sensitive to this setting. To address this challenge, we adaptively assign optimal dropout-ratio configurations to devices through an exploration-exploitation strategy, achieving efficient and effective fine-tuning. Extensive experiments show that DropPEFT can achieve a 1.3-6.3倍模型收敛速度提升和40%-67%的内存占用减少， compared to state-of-the-art methods。', 'title_zh': '高效分层dropout在联邦细调大规模语言模型中的应用'}
{'arxiv_id': 'arXiv:2503.10198', 'title': 'Deep Learning for Time Series Forecasting: A Survey', 'authors': 'Xiangjie Kong, Zhenghao Chen, Weiyao Liu, Kaili Ning, Lechao Zhang, Syauqie Muhammad Marier, Yichen Liu, Yuhao Chen, Feng Xia', 'link': 'https://arxiv.org/abs/2503.10198', 'abstract': 'Time series forecasting (TSF) has long been a crucial task in both industry and daily life. Most classical statistical models may have certain limitations when applied to practical scenarios in fields such as energy, healthcare, traffic, meteorology, and economics, especially when high accuracy is required. With the continuous development of deep learning, numerous new models have emerged in the field of time series forecasting in recent years. However, existing surveys have not provided a unified summary of the wide range of model architectures in this field, nor have they given detailed summaries of works in feature extraction and datasets. To address this gap, in this review, we comprehensively study the previous works and summarize the general paradigms of Deep Time Series Forecasting (DTSF) in terms of model architectures. Besides, we take an innovative approach by focusing on the composition of time series and systematically explain important feature extraction methods. Additionally, we provide an overall compilation of datasets from various domains in existing works. Finally, we systematically emphasize the significant challenges faced and future research directions in this field.', 'abstract_zh': '时间序列预测（TSF）一直是工业和日常生活中的一项关键任务。大多数经典统计模型在能源、医疗、交通、气象和经济学等领域实际应用场景中可能存在一定的局限性，特别是在高精度要求的情况下。随着深度学习的不断进步，近年来在时间序列预测领域涌现出了众多新的模型。然而，现有的综述尚未对这一领域的广泛模型架构提供统一的总结，也没有对特征提取和数据集进行详细的综述。为弥补这一空白，在本文综述中，我们全面研究了先前的研究工作，从模型架构的角度总结了深度时间序列预测（DTSF）的一般范式。此外，我们以创新的方式关注时间序列的组成，并系统地解释了重要的特征提取方法。同时，我们提供了现有研究中不同领域数据集的总体编目。最后，我们系统地强调了该领域面临的重大挑战和未来研究方向。', 'title_zh': '深度学习在时间序列预测中的应用：一种综述'}
{'arxiv_id': 'arXiv:2503.10197', 'title': 'Predicting Chemical Reaction Outcomes Based on Electron Movements Using Machine Learning', 'authors': 'Shuan Chen, Kye Sung Park, Taewan Kim, Sunkyu Han, Yousung Jung', 'link': 'https://arxiv.org/abs/2503.10197', 'abstract': 'Accurately predicting chemical reaction outcomes and potential byproducts is a fundamental task of modern chemistry, enabling the efficient design of synthetic pathways and driving progress in chemical science. Reaction mechanism, which tracks electron movements during chemical reactions, is critical for understanding reaction kinetics and identifying unexpected products. Here, we present Reactron, the first electron-based machine learning model for general reaction prediction. Reactron integrates electron movement into its predictions, generating detailed arrow-pushing diagrams that elucidate each mechanistic step leading to product formation. We demonstrate the high predictive performance of Reactron over existing product-only models by a large-scale reaction outcome prediction benchmark, and the adaptability of the model to learn new reactivity upon providing a few examples. Furthermore, it explores combinatorial reaction spaces, uncovering novel reactivities beyond its training data. With robust performance in both in- and out-of-distribution predictions, Reactron embodies human-like reasoning in chemistry and opens new frontiers in reaction discovery and synthesis design.', 'abstract_zh': '准确预测化学反应结果和潜在副产品的任务是现代化学的基础，有助于合成路径的高效设计并推动化学科学的进步。反应机理追踪化学反应中的电子移动，对于理解反应动力学和识别意外产物至关重要。在这里，我们介绍Reactron，这是首个基于电子的机器学习模型，用于通用反应预测。Reactron通过整合电子移动来生成详细的箭头推导图，阐明每一步机制直至产物形成。通过大规模反应结果预测基准测试，我们展示了Reactron相对于现有仅基于产物的模型的高预测性能。同时，该模型在提供少量示例后能够学习新的反应性，并探索组合反应空间，揭示超出训练数据的新反应性。凭借稳健的内在和外推性能，Reactron体现了化学中的人类级推理，并为反应发现和合成设计开辟了新的前沿。', 'title_zh': '基于电子移动预测化学反应结果的机器学习方法'}
{'arxiv_id': 'arXiv:2503.10191', 'title': 'Robustness Tokens: Towards Adversarial Robustness of Transformers', 'authors': 'Brian Pulfer, Yury Belousov, Slava Voloshynovskiy', 'link': 'https://arxiv.org/abs/2503.10191', 'abstract': 'Recently, large pre-trained foundation models have become widely adopted by machine learning practitioners for a multitude of tasks. Given that such models are publicly available, relying on their use as backbone models for downstream tasks might result in high vulnerability to adversarial attacks crafted with the same public model. In this work, we propose Robustness Tokens, a novel approach specific to the transformer architecture that fine-tunes a few additional private tokens with low computational requirements instead of tuning model parameters as done in traditional adversarial training. We show that Robustness Tokens make Vision Transformer models significantly more robust to white-box adversarial attacks while also retaining the original downstream performances.', 'abstract_zh': '近期，大型预训练基础模型已被机器学习 practitioner 广泛用于多种任务。鉴于此类模型是公开可用的，依赖其作为下游任务骨干模型的使用可能会导致高易受使用相同公开模型构造的对抗攻击的影响。在本文中，我们提出了一种专门针对transformer 架构的 Robustness Tokens 新颖方法，该方法以较低的计算要求微调少量额外的私有 tokens，而传统对抗训练则是调整模型参数。我们展示了 Robustness Tokens 使 Vision Transformer 模型在面对白盒对抗攻击时显著更加稳健，同时保持原始下游任务的性能。', 'title_zh': '鲁棒性令牌：迈向Transformer的对抗鲁棒性'}
{'arxiv_id': 'arXiv:2503.10186', 'title': 'Multi-Agent Q-Learning Dynamics in Random Networks: Convergence due to Exploration and Sparsity', 'authors': 'Aamal Hussain, Dan Leonte, Francesco Belardinelli, Raphael Huser, Dario Paccagnan', 'link': 'https://arxiv.org/abs/2503.10186', 'abstract': "Beyond specific settings, many multi-agent learning algorithms fail to converge to an equilibrium solution, and instead display complex, non-stationary behaviours such as recurrent or chaotic orbits. In fact, recent literature suggests that such complex behaviours are likely to occur when the number of agents increases. In this paper, we study Q-learning dynamics in network polymatrix games where the network structure is drawn from classical random graph models. In particular, we focus on the Erdos-Renyi model, a well-studied model for social networks, and the Stochastic Block model, which generalizes the above by accounting for community structures within the network. In each setting, we establish sufficient conditions under which the agents' joint strategies converge to a unique equilibrium. We investigate how this condition depends on the exploration rates, payoff matrices and, crucially, the sparsity of the network. Finally, we validate our theoretical findings through numerical simulations and demonstrate that convergence can be reliably achieved in many-agent systems, provided network sparsity is controlled.", 'abstract_zh': '超越特定设置，许多多智能体学习算法未能收敛到均衡解，而是表现出复杂的、非平稳的行为，如反复出现或混沌轨道。实际上，近期文献表明，随着智能体数量的增加，此类复杂行为更可能发生。在本文中，我们研究网络聚合矩阵博弈中Q学习动态，其中网络结构来自经典的随机图模型。特别地，我们关注Erdos-Renyi模型，这是一种广泛研究的社会网络模型，以及考虑网络中社区结构的随机块模型。在每种情况下，我们建立了充分条件，以确保智能体的联合策略收敛到唯一的均衡。我们研究了这一条件如何依赖于探索率、支付矩阵以及关键的网络稀疏性。最后，通过数值模拟验证了我们的理论发现，并展示了在控制网络稀疏性的情况下，多智能体系统中的收敛可以可靠地实现。', 'title_zh': '随机网络中多代理Q学习的动力学：探索与稀疏性导致的收敛性'}
{'arxiv_id': 'arXiv:2503.10183', 'title': 'Through the Magnifying Glass: Adaptive Perception Magnification for Hallucination-Free VLM Decoding', 'authors': 'Shunqi Mao, Chaoyi Zhang, Weidong Cai', 'link': 'https://arxiv.org/abs/2503.10183', 'abstract': 'Existing vision-language models (VLMs) often suffer from visual hallucination, where the generated responses contain inaccuracies that are not grounded in the visual input. Efforts to address this issue without model finetuning primarily mitigate hallucination by reducing biases contrastively or amplifying the weights of visual embedding during decoding. However, these approaches improve visual perception at the cost of impairing the language reasoning capability. In this work, we propose the Perception Magnifier (PM), a novel visual decoding method that iteratively isolates relevant visual tokens based on attention and magnifies the corresponding regions, spurring the model to concentrate on fine-grained visual details during decoding. Specifically, by magnifying critical regions while preserving the structural and contextual information at each decoding step, PM allows the VLM to enhance its scrutiny of the visual input, hence producing more accurate and faithful responses. Extensive experimental results demonstrate that PM not only achieves superior hallucination mitigation but also enhances language generation while preserving strong reasoning this http URL is available at this https URL .', 'abstract_zh': '现有的视觉-语言模型（VLMs）经常会出现视觉幻觉问题，生成的响应中包含与视觉输入不符的不准确信息。无需模型微调的努力主要通过对比性地减轻偏差或在解码过程中放大视觉嵌入的权重来减轻幻觉，但这些方法在提高视觉感知能力的同时会损害语言推理能力。在本文中，我们提出了感知放大器（PM），这是一种新颖的视觉解码方法，该方法通过attention迭代地隔离相关视觉令牌并放大相应的区域，促使模型在解码过程中更加关注细粒度的视觉细节。具体而言，通过在每一步解码中放大关键区域并保持结构和上下文信息，PM使VLM能够增强对视觉输入的审视，从而产生更准确和忠实的响应。广泛实验证明，PM不仅实现了更优秀的幻觉减轻效果，还增强了语言生成能力，同时保持了强大的推理能力。该研究结果详见<cite>此处提供链接</cite>。', 'title_zh': '通过放大镜：幻觉-free VLM解码的自适应感知放大'}
{'arxiv_id': 'arXiv:2503.10166', 'title': 'ImageScope: Unifying Language-Guided Image Retrieval via Large Multimodal Model Collective Reasoning', 'authors': 'Pengfei Luo, Jingbo Zhou, Tong Xu, Yuan Xia, Linli Xu, Enhong Chen', 'link': 'https://arxiv.org/abs/2503.10166', 'abstract': 'With the proliferation of images in online content, language-guided image retrieval (LGIR) has emerged as a research hotspot over the past decade, encompassing a variety of subtasks with diverse input forms. While the development of large multimodal models (LMMs) has significantly facilitated these tasks, existing approaches often address them in isolation, requiring the construction of separate systems for each task. This not only increases system complexity and maintenance costs, but also exacerbates challenges stemming from language ambiguity and complex image content, making it difficult for retrieval systems to provide accurate and reliable results. To this end, we propose ImageScope, a training-free, three-stage framework that leverages collective reasoning to unify LGIR tasks. The key insight behind the unification lies in the compositional nature of language, which transforms diverse LGIR tasks into a generalized text-to-image retrieval process, along with the reasoning of LMMs serving as a universal verification to refine the results. To be specific, in the first stage, we improve the robustness of the framework by synthesizing search intents across varying levels of semantic granularity using chain-of-thought (CoT) reasoning. In the second and third stages, we then reflect on retrieval results by verifying predicate propositions locally, and performing pairwise evaluations globally. Experiments conducted on six LGIR datasets demonstrate that ImageScope outperforms competitive baselines. Comprehensive evaluations and ablation studies further confirm the effectiveness of our design.', 'abstract_zh': '基于语言引导的图像检索（LGIR）任务的训练-free三阶段统一框架：ImageScope', 'title_zh': 'ImageScope: 统一语言引导的图像检索 via 大规模多模态模型联合推理'}
{'arxiv_id': 'arXiv:2503.10150', 'title': 'Retrieval-Augmented Generation with Hierarchical Knowledge', 'authors': 'Haoyu Huang, Yongfeng Huang, Junjie Yang, Zhenyu Pan, Yongqiang Chen, Kaili Ma, Hongzhi Chen, James Cheng', 'link': 'https://arxiv.org/abs/2503.10150', 'abstract': 'Graph-based Retrieval-Augmented Generation (RAG) methods have significantly enhanced the performance of large language models (LLMs) in domain-specific tasks. However, existing RAG methods do not adequately utilize the naturally inherent hierarchical knowledge in human cognition, which limits the capabilities of RAG systems. In this paper, we introduce a new RAG approach, called HiRAG, which utilizes hierarchical knowledge to enhance the semantic understanding and structure capturing capabilities of RAG systems in the indexing and retrieval processes. Our extensive experiments demonstrate that HiRAG achieves significant performance improvements over the state-of-the-art baseline methods. The code of our proposed method is available at \\href{this https URL}{this https URL}.', 'abstract_zh': '基于图的层次知识增强检索增强生成（HiRAG）方法在特定领域任务中显著提升了大型语言模型的性能。然而，现有的RAG方法并未充分利用人类认知中自然具有的层次知识，这限制了RAG系统的功能。在本文中，我们提出了一种新的RAG方法，称为HiRAG，该方法利用层次知识在索引和检索过程中增强RAG系统的语义理解和结构捕获能力。我们的大量实验证明，HiRAG在性能上显著优于最先进的基线方法。所提出方法的代码可在\\href{this https URL}{this https URL}获取。', 'title_zh': '具有层级知识增强的检索生成'}
{'arxiv_id': 'arXiv:2503.10144', 'title': 'Multiplicative Learning', 'authors': 'Han Kim, Hyungjoon Soh, Vipul Periwal, Junghyo Jo', 'link': 'https://arxiv.org/abs/2503.10144', 'abstract': 'Efficient training of artificial neural networks remains a key challenge in deep learning. Backpropagation (BP), the standard learning algorithm, relies on gradient descent and typically requires numerous iterations for convergence. In this study, we introduce Expectation Reflection (ER), a novel learning approach that updates weights multiplicatively based on the ratio of observed to predicted outputs. Unlike traditional methods, ER maintains consistency without requiring ad hoc loss functions or learning rate hyperparameters. We extend ER to multilayer networks and demonstrate its effectiveness in performing image classification tasks. Notably, ER achieves optimal weight updates in a single iteration. Additionally, we reinterpret ER as a modified form of gradient descent incorporating the inverse mapping of target propagation. These findings suggest that ER provides an efficient and scalable alternative for training neural networks.', 'abstract_zh': '高效的 artificial neural networks 训练仍然是深度学习中的 key 挑战。Backpropagation (BP) 作为标准的学习算法，依赖于梯度下降，并通常需要多次迭代才能收敛。本研究引入了 Expectation Reflection (ER) 这一新颖的学习方法，该方法基于观测输出与预测输出的比例更新权重。与传统方法不同，ER 保持一致性无需使用随意设定的损失函数或学习率超参数。我们将 ER 扩展到多层网络，并展示了其在执行图像分类任务方面的有效性。值得注意的是，ER 在单次迭代中实现了最优权重更新。此外，我们将 ER 重新解释为一种改进的梯度下降形式，结合了目标传播的逆映射。这些发现表明，ER 为训练神经网络提供了高效且可扩展的替代方案。', 'title_zh': '乘法学习'}
{'arxiv_id': 'arXiv:2503.10135', 'title': 'Gumiho: A Hybrid Architecture to Prioritize Early Tokens in Speculative Decoding', 'authors': 'Jinze Li, Yixing Xu, Haiduo Huang, Xuanwu Yin, Dong Li, Edith C.H. Ngai, Emad Barsoum', 'link': 'https://arxiv.org/abs/2503.10135', 'abstract': 'Speculative decoding (SPD) aims to accelerate the auto-regressive token generation process of a target Large Language Model (LLM). Some approaches employ a draft model with multiple heads to predict a sequence of future tokens, where each head handles a token in the sequence. The target LLM verifies the predicted sequence and accepts aligned tokens, enabling efficient multi-token generation. However, existing methods assume that all tokens within a sequence are equally important, employing identical head structures and relying on a single-generation paradigm, either serial or parallel. To this end, we theoretically demonstrate that initial tokens in the draft sequence are more important than later ones. Building on this insight, we propose Gumiho, a hybrid model combining serial and parallel heads. Specifically, given the critical importance of early tokens, we employ a sophisticated Transformer architecture for the early draft heads in a serial configuration to improve accuracy. For later tokens, we utilize multiple lightweight MLP heads operating in parallel to enhance efficiency. By allocating more advanced model structures and longer running times to the early heads, Gumiho achieves improved overall performance. The experimental results demonstrate that our method outperforms existing approaches, fully validating its effectiveness.', 'abstract_zh': '推测性解码（SPD）旨在加速目标大型语言模型（LLM）的自回归 token 生成过程。一些方法通过使用具有多个头的草稿模型来预测未来 token 的序列，每个头处理序列中的一个 token。目标 LLM 验证预测的序列并接受对齐的 token，从而实现高效的多 token 生成。然而，现有方法假设序列中的所有 token 具有同等的重要性，采用相同的头结构并依赖于串行或并行的一次生成 paradigm。基于此，我们理论证明初始 token 在草稿序列中比后来的 token 更重要。据此，我们提出了一种结合串行和并行头的混合模型 Gumiho。具体而言，鉴于早期 token 的关键重要性，我们采用复杂的 Transformer 架构在串行配置中为早期草稿头提供更高的准确性。对于后续 token，我们使用多个轻量级的 MLP 头在并行配置中进行处理以提高效率。通过为早期头分配更先进的模型结构和更长的运行时间，Gumiho 实现了整体性能的提升。实验结果表明，我们的方法优于现有方法，充分验证了其有效性。', 'title_zh': '九尾狐：一种混合架构，用于在推测性解码中优先处理早期令牌'}
{'arxiv_id': 'arXiv:2503.10129', 'title': 'Deep Learning-Based Direct Leaf Area Estimation using Two RGBD Datasets for Model Development', 'authors': 'Namal Jayasuriya, Yi Guo, Wen Hu, Oula Ghannoum', 'link': 'https://arxiv.org/abs/2503.10129', 'abstract': 'Estimation of a single leaf area can be a measure of crop growth and a phenotypic trait to breed new varieties. It has also been used to measure leaf area index and total leaf area. Some studies have used hand-held cameras, image processing 3D reconstruction and unsupervised learning-based methods to estimate the leaf area in plant images. Deep learning works well for object detection and segmentation tasks; however, direct area estimation of objects has not been explored. This work investigates deep learning-based leaf area estimation, for RGBD images taken using a mobile camera setup in real-world scenarios. A dataset for attached leaves captured with a top angle view and a dataset for detached single leaves were collected for model development and testing. First, image processing-based area estimation was tested on manually segmented leaves. Then a Mask R-CNN-based model was investigated, and modified to accept RGBD images and to estimate the leaf area. The detached-leaf data set was then mixed with the attached-leaf plant data set to estimate the single leaf area for plant images, and another network design with two backbones was proposed: one for segmentation and the other for area estimation. Instead of trying all possibilities or random values, an agile approach was used in hyperparameter tuning. The final model was cross-validated with 5-folds and tested with two unseen datasets: detached and attached leaves. The F1 score with 90% IoA for segmentation result on unseen detached-leaf data was 1.0, while R-squared of area estimation was 0.81. For unseen plant data segmentation, the F1 score with 90% IoA was 0.59, while the R-squared score was 0.57. The research suggests using attached leaves with ground truth area to improve the results.', 'abstract_zh': '基于深度学习的RGBD图像中单片叶面积 estimation', 'title_zh': '基于深度学习的直接叶片面积估计：使用两种RGBD数据集构建模型'}
{'arxiv_id': 'arXiv:2503.10095', 'title': 'Cognitive-Mental-LLM: Leveraging Reasoning in Large Language Models for Mental Health Prediction via Online Text', 'authors': 'Avinash Patil, Amardeep Kour Gedhu', 'link': 'https://arxiv.org/abs/2503.10095', 'abstract': 'Large Language Models (LLMs) have demonstrated potential in predicting mental health outcomes from online text, yet traditional classification methods often lack interpretability and robustness. This study evaluates structured reasoning techniques-Chain-of-Thought (CoT), Self-Consistency (SC-CoT), and Tree-of-Thought (ToT)-to improve classification accuracy across multiple mental health datasets sourced from Reddit. We analyze reasoning-driven prompting strategies, including Zero-shot CoT and Few-shot CoT, using key performance metrics such as Balanced Accuracy, F1 score, and Sensitivity/Specificity. Our findings indicate that reasoning-enhanced techniques improve classification performance over direct prediction, particularly in complex cases. Compared to baselines such as Zero Shot non-CoT Prompting, and fine-tuned pre-trained transformers such as BERT and Mental-RoBerta, and fine-tuned Open Source LLMs such as Mental Alpaca and Mental-Flan-T5, reasoning-driven LLMs yield notable gains on datasets like Dreaddit (+0.52\\% over M-LLM, +0.82\\% over BERT) and SDCNL (+4.67\\% over M-LLM, +2.17\\% over BERT). However, performance declines in Depression Severity, and CSSRS predictions suggest dataset-specific limitations, likely due to our using a more extensive test set. Among prompting strategies, Few-shot CoT consistently outperforms others, reinforcing the effectiveness of reasoning-driven LLMs. Nonetheless, dataset variability highlights challenges in model reliability and interpretability. This study provides a comprehensive benchmark of reasoning-based LLM techniques for mental health text classification. It offers insights into their potential for scalable clinical applications while identifying key challenges for future improvements.', 'abstract_zh': '大型语言模型在预测从在线文本中获得的心理健康结果方面展现了潜力，但传统分类方法通常缺乏可解释性和稳健性。本研究评估了结构化推理技术——链式推理（CoT）、自我一致性（SC-CoT）和思维方式树（ToT）——以提高跨多个来自Reddit的心理健康数据集的分类准确性。我们使用均衡准确性、F1分数和敏感性/特异性等关键性能指标，分析了推理驱动的提示策略，包括零样本链式推理和少量样本链式推理。研究结果表明，增强推理的技术在复杂情况下提高了分类性能，与零样本非CoT提示、微调预训练变换器（如BERT和Mental-RoBerta）、以及微调的开源大型语言模型（如Mental Alpaca和Mental-Flan-T5）相比，具有显著优势。例如，在Dreaddit（+0.52%）和SDCNL（+4.67%）等数据集上，推理驱动的大型语言模型的性能优于基线。然而，在抑郁症严重程度和CSSRS预测中，性能下降，这可能反映了数据集的特定限制。在提示策略中，少量样本链式推理表现最佳，增强了推理驱动大型语言模型的有效性。然而，数据集的变异性突显了模型可靠性及解释性方面的问题。本研究为心理健康的文本分类提供了综合的推理驱动大型语言模型基准，提供了其在可扩展临床应用方面的潜在见解，并指出了未来改进的关键挑战。', 'title_zh': '认知-心理大语言模型：通过在线文本利用推理预测心理健康'}
{'arxiv_id': 'arXiv:2503.10070', 'title': 'AhaRobot: A Low-Cost Open-Source Bimanual Mobile Manipulator for Embodied AI', 'authors': 'Haiqin Cui, Yifu Yuan, Yan Zheng, Jianye Hao', 'link': 'https://arxiv.org/abs/2503.10070', 'abstract': 'Navigation and manipulation in open-world environments remain unsolved challenges in the Embodied AI. The high cost of commercial mobile manipulation robots significantly limits research in real-world scenes. To address this issue, we propose AhaRobot, a low-cost and fully open-source dual-arm mobile manipulation robot system with a hardware cost of only $1,000 (excluding optional computational resources), which is less than 1/15 of the cost of popular mobile robots. The AhaRobot system consists of three components: (1) a novel low-cost hardware architecture primarily composed of off-the-shelf components, (2) an optimized control solution to enhance operational precision integrating dual-motor backlash control and static friction compensation, and (3) a simple remote teleoperation method RoboPilot. We use handles to control the dual arms and pedals for whole-body movement. The teleoperation process is low-burden and easy to operate, much like piloting. RoboPilot is designed for remote data collection in embodied scenarios. Experimental results demonstrate that RoboPilot significantly enhances data collection efficiency in complex manipulation tasks, achieving a 30% increase compared to methods using 3D mouse and leader-follower systems. It also excels at completing extremely long-horizon tasks in one go. Furthermore, AhaRobot can be used to learn end-to-end policies and autonomously perform complex manipulation tasks, such as pen insertion and cleaning up the floor. We aim to build an affordable yet powerful platform to promote the development of embodied tasks on real devices, advancing more robust and reliable embodied AI. All hardware and software systems are available at this https URL.', 'abstract_zh': '开放世界环境中的导航与操控仍然是约束型AI中的未解决挑战。商业移动操控机器人高昂的成本严重限制了现实场景中的研究。为应对这一问题，我们提出了AhaRobot，一个硬件成本仅为1000美元（不包括可选计算资源）的低成本全开源双臂移动操控机器人系统，成本低于流行移动机器人的1/15。AhaRobot系统由三个组成部分组成：（1）一种新颖的低成本硬件架构，主要由现成组件组成，（2）一种优化的控制解决方案，集成双电机反向间隙控制和静摩擦补偿以提高操作精度，以及（3）一种简单的远程遥控方法RoboPilot。使用手柄控制双臂，使用脚踏板进行全身运动。远程操控过程负担低且易于操作，类似于驾驶。RoboPilot旨在远程数据收集中的约束型场景中使用。实验结果表明，RoboPilot显著提高了复杂操控任务的数据采集效率，相比使用3D鼠标和领导者-追随者系统的相关方法，数据收集效率提高了30%。它还能够一次性完成极长视角的任务。此外，AhaRobot可用于学习端到端策略，并自主执行复杂的操控任务，如笔插入和清洁地面。我们的目标是建立一个负担得起但又强大的平台，促进在真实设备上进行约束性任务的发展，推进更稳健可靠的约束型AI。所有硬件和软件系统均可从<a href="this https URL">这里</a>获得。', 'title_zh': 'AhaRobot：一种低成本开源双臂移动 manipulator 用于具身 AI'}
{'arxiv_id': 'arXiv:2503.10061', 'title': 'Compute Optimal Scaling of Skills: Knowledge vs Reasoning', 'authors': 'Nicholas Roberts, Niladri Chatterji, Sharan Narang, Mike Lewis, Dieuwke Hupkes', 'link': 'https://arxiv.org/abs/2503.10061', 'abstract': "Scaling laws are a critical component of the LLM development pipeline, most famously as a way to forecast training decisions such as 'compute-optimally' trading-off parameter count and dataset size, alongside a more recent growing list of other crucial decisions. In this work, we ask whether compute-optimal scaling behaviour can be skill-dependent. In particular, we examine knowledge and reasoning-based skills such as knowledge-based QA and code generation, and we answer this question in the affirmative: $\\textbf{scaling laws are skill-dependent}$. Next, to understand whether skill-dependent scaling is an artefact of the pretraining datamix, we conduct an extensive ablation of different datamixes and find that, also when correcting for datamix differences, $\\textbf{knowledge and code exhibit fundamental differences in scaling behaviour}$. We conclude with an analysis of how our findings relate to standard compute-optimal scaling using a validation set, and find that $\\textbf{a misspecified validation set can impact compute-optimal parameter count by nearly 50%,}$ depending on its skill composition.", 'abstract_zh': '缩放定律是大语言模型开发管道中的关键组成部分，最著名的是作为一种方法来预测训练决策，如“计算最优”权衡参数数量和数据集大小，以及近年来越来越多的其他关键决策。在本工作中，我们探讨计算最优缩放行为是否与技能相关。特别是，我们研究了基于知识和推理的技能，如基于知识的问答和代码生成，并得出结论：缩放定律是技能相关的。接下来，为了理解技能相关的缩放是否是预训练数据混合的产物，我们进行了广泛的数据混合消融实验，并发现，即使校正了数据混合差异，知识和代码在缩放行为上仍表现出根本性的差异。最后，我们将我们的发现与使用验证集的标准计算最优缩放进行了分析，并发现验证集的设定不当可能会影响计算最优参数数量高达近50%，这取决于其技能组成。', 'title_zh': '计算技能的最佳缩放比例：知识 vs 原理推理'}
{'arxiv_id': 'arXiv:2503.10058', 'title': 'Deep Learning Approaches for Anti-Money Laundering on Mobile Transactions: Review, Framework, and Directions', 'authors': 'Jiani Fan, Lwin Khin Shar, Ruichen Zhang, Ziyao Liu, Wenzhuo Yang, Dusit Niyato, Bomin Mao, Kwok-Yan Lam', 'link': 'https://arxiv.org/abs/2503.10058', 'abstract': 'Money laundering is a financial crime that obscures the origin of illicit funds, necessitating the development and enforcement of anti-money laundering (AML) policies by governments and organizations. The proliferation of mobile payment platforms and smart IoT devices has significantly complicated AML investigations. As payment networks become more interconnected, there is an increasing need for efficient real-time detection to process large volumes of transaction data on heterogeneous payment systems by different operators such as digital currencies, cryptocurrencies and account-based payments. Most of these mobile payment networks are supported by connected devices, many of which are considered loT devices in the FinTech space that constantly generate data. Furthermore, the growing complexity and unpredictability of transaction patterns across these networks contribute to a higher incidence of false positives. While machine learning solutions have the potential to enhance detection efficiency, their application in AML faces unique challenges, such as addressing privacy concerns tied to sensitive financial data and managing the real-world constraint of limited data availability due to data regulations. Existing surveys in the AML literature broadly review machine learning approaches for money laundering detection, but they often lack an in-depth exploration of advanced deep learning techniques - an emerging field with significant potential. To address this gap, this paper conducts a comprehensive review of deep learning solutions and the challenges associated with their use in AML. Additionally, we propose a novel framework that applies the least-privilege principle by integrating machine learning techniques, codifying AML red flags, and employing account profiling to provide context for predictions and enable effective fraud detection under limited data availability....', 'abstract_zh': '移动支付平台和智能物联网设备 proliferation 对反洗钱调查的复杂化及其深度学习解决方案的研究：最小权限原则下的机器学习技术、AML红旗标志及账户 profiling 应用', 'title_zh': '移动交易反洗钱的深度学习方法：综述、框架与方向'}
{'arxiv_id': 'arXiv:2503.10052', 'title': 'DTA: Dual Temporal-channel-wise Attention for Spiking Neural Networks', 'authors': 'Minje Kim, Minjun Kim, Xu Yang', 'link': 'https://arxiv.org/abs/2503.10052', 'abstract': 'Spiking Neural Networks (SNNs) present a more energy-efficient alternative to Artificial Neural Networks (ANNs) by harnessing spatio-temporal dynamics and event-driven spikes. Effective utilization of temporal information is crucial for SNNs, leading to the exploration of attention mechanisms to enhance this capability. Conventional attention operations either apply identical operation or employ non-identical operations across target dimensions. We identify that these approaches provide distinct perspectives on temporal information. To leverage the strengths of both operations, we propose a novel Dual Temporal-channel-wise Attention (DTA) mechanism that integrates both identical/non-identical attention strategies. To the best of our knowledge, this is the first attempt to concentrate on both the correlation and dependency of temporal-channel using both identical and non-identical attention operations. Experimental results demonstrate that the DTA mechanism achieves state-of-the-art performance on both static datasets (CIFAR10, CIFAR100, ImageNet-1k) and dynamic dataset (CIFAR10-DVS), elevating spike representation and capturing complex temporal-channel relationship. We open-source our code: this https URL.', 'abstract_zh': '基于尖劈神经元的双时序通道注意力机制：同时利用相同和不同注意力操作增强时间通道相关性和依赖性', 'title_zh': 'DTA: 双时序通道注意力机制在脉冲神经网络中的应用'}
{'arxiv_id': 'arXiv:2503.10040', 'title': 'Rapid analysis of point-contact Andreev reflection spectra via machine learning with adaptive data augmentation', 'authors': 'Dongik Lee, Valentin Stanev, Xiaohang Zhang, Mijeong Kang, Ichiro Takeuchi, Seunghun Lee', 'link': 'https://arxiv.org/abs/2503.10040', 'abstract': "Delineating the superconducting order parameters is a pivotal task in investigating superconductivity for probing pairing mechanisms, as well as their symmetry and topology. Point-contact Andreev reflection (PCAR) measurement is a simple yet powerful tool for identifying the order parameters. The PCAR spectra exhibit significant variations depending on the type of the order parameter in a superconductor, including its magnitude ($\\mathit{\\Delta}$), as well as temperature, interfacial quality, Fermi velocity mismatch, and other factors. The information on the order parameter can be obtained by finding the combination of these parameters, generating a theoretical spectrum that fits a measured experimental spectrum. However, due to the complexity of the spectra and the high dimensionality of parameters, extracting the fitting parameters is often time-consuming and labor-intensive. In this study, we employ a convolutional neural network (CNN) algorithm to create models for rapid and automated analysis of PCAR spectra of various superconductors with different pairing symmetries (conventional $s$-wave, chiral $p_x+ip_y$-wave, and $d_{x^2-y^2}$-wave). The training datasets are generated based on the Blonder-Tinkham-Klapwijk (BTK) theory and further modified and augmented by selectively incorporating noise and peaks according to the bias voltages. This approach not only replicates the experimental spectra but also brings the model's attention to important features within the spectra. The optimized models provide fitting parameters for experimentally measured spectra in less than 100 ms per spectrum. Our approaches and findings pave the way for rapid and automated spectral analysis which will help accelerate research on superconductors with complex order parameters.", 'abstract_zh': '划分超导有序参数是探索超导电性、探查配对机制及其对称性和拓扑性的关键任务。点接触安德烈夫反射（PCAR）测量是一种简单而强大的工具，用于识别有序参数。PCAR光谱会根据超导体中有序参数的类型以及其幅度（$\\mathit{\\Delta}$）、温度、界面质量、费米速度不匹配及其他因素表现出显著差异。通过找到这些参数的组合，生成与测量实验光谱匹配的理论光谱，可以获得有序参数的信息。然而，由于光谱的复杂性和参数的高维度性，提取拟合参数往往耗时且劳动密集。在这项研究中，我们采用卷积神经网络（CNN）算法，为具有不同配对对称性（常规$s$波、手征$p_x+ip_y$波和$d_{x^2-y^2}$波）的各种超导体的PCAR光谱创建快速和自动分析模型。训练数据集基于Blonder-Tinkham-Klapwijk（BTK）理论生成，并通过根据偏置电压选择性地引入噪声和峰值进行了进一步修改和扩充。这种方法不仅复现了实验光谱，还使模型将注意力集中在光谱中的重要特征上。优化后的模型可在每个光谱少于100毫秒的时间内提供实验测量光谱的拟合参数。我们的方法和发现为快速和自动光谱分析铺平了道路，这将有助于加速对具有复杂有序参数的超导体的研究。', 'title_zh': '基于自适应数据扩增的机器学习快速分析点接触安德陇反射谱'}
{'arxiv_id': 'arXiv:2503.09988', 'title': 'Label Unbalance in High-frequency Trading', 'authors': 'Zijian Zhao, Xuming Chen, Jiayu Wen, Mingwen Liu, Xiaoteng Ma', 'link': 'https://arxiv.org/abs/2503.09988', 'abstract': 'In financial trading, return prediction is one of the foundation for a successful trading system. By the fast development of the deep learning in various areas such as graphical processing, natural language, it has also demonstrate significant edge in handling with financial data. While the success of the deep learning relies on huge amount of labeled sample, labeling each time/event as profitable or unprofitable, under the transaction cost, especially in the high-frequency trading world, suffers from serious label imbalance this http URL this paper, we adopts rigurious end-to-end deep learning framework with comprehensive label imbalance adjustment methods and succeed in predicting in high-frequency return in the Chinese future market. The code for our method is publicly available at this https URL .', 'abstract_zh': '在金融交易中，回报预测是成功交易系统的基础。随着深度学习在图形处理、自然语言处理等领域的发展，它在处理金融数据方面也展现出了显著的优势。尽管深度学习的成功依赖于大量的标注样本，但在交易成本较高的情况下，特别是在高频交易领域，每笔交易事件标记为盈利或亏损时存在着严重的标签不平衡问题。本文采用严格的端到端深度学习框架，并结合全面的标签不平衡调整方法，成功预测了中国期货市场的高频回报。我们的方法代码已公开，可访问此链接： эта ссылка 。', 'title_zh': '高频交易中的标签不平衡问题'}
{'arxiv_id': 'arXiv:2503.09974', 'title': 'Uncertainty-aware Long-tailed Weights Model the Utility of Pseudo-labels for Semi-supervised Learning', 'authors': 'Jiaqi Wu, Junbiao Pang, Qingming Huang', 'link': 'https://arxiv.org/abs/2503.09974', 'abstract': "Current Semi-supervised Learning (SSL) adopts the pseudo-labeling strategy and further filters pseudo-labels based on confidence thresholds. However, this mechanism has notable drawbacks: 1) setting the reasonable threshold is an open problem which significantly influences the selection of the high-quality pseudo-labels; and 2) deep models often exhibit the over-confidence phenomenon which makes the confidence value an unreliable indicator for assessing the quality of pseudo-labels due to the scarcity of labeled data. In this paper, we propose an Uncertainty-aware Ensemble Structure (UES) to assess the utility of pseudo-labels for unlabeled samples. We further model the utility of pseudo-labels as long-tailed weights to avoid the open problem of setting the threshold. Concretely, the advantage of the long-tailed weights ensures that even unreliable pseudo-labels still contribute to enhancing the model's robustness. Besides, UES is lightweight and architecture-agnostic, easily extending to various computer vision tasks, including classification and regression. Experimental results demonstrate that combining the proposed method with DualPose leads to a 3.47% improvement in Percentage of Correct Keypoints (PCK) on the Sniffing dataset with 100 data points (30 labeled), a 7.29\\% improvement in PCK on the FLIC dataset with 100 data points (50 labeled), and a 3.91% improvement in PCK on the LSP dataset with 200 data points (100 labeled). Furthermore, when combined with FixMatch, the proposed method achieves a 0.2% accuracy improvement on the CIFAR-10 dataset with 40 labeled data points and a 0.26% accuracy improvement on the CIFAR-100 dataset with 400 labeled data points.", 'abstract_zh': '基于不确定性感知的伪标签评估结构(Uncertainty-aware Ensemble Structure for Assessing Pseudo-label Utility in Semi-supervised Learning)', 'title_zh': '不确定性意识长尾权重模型：伪标签在半监督学习中的效用'}
{'arxiv_id': 'arXiv:2503.09969', 'title': 'Detecting Dataset Bias in Medical AI: A Generalized and Modality-Agnostic Auditing Framework', 'authors': 'Nathan Drenkow, Mitchell Pavlak, Keith Harrigian, Ayah Zirikly, Adarsh Subbaswamy, Mathias Unberath', 'link': 'https://arxiv.org/abs/2503.09969', 'abstract': "Data-driven AI is establishing itself at the center of evidence-based medicine. However, reports of shortcomings and unexpected behavior are growing due to AI's reliance on association-based learning. A major reason for this behavior: latent bias in machine learning datasets can be amplified during training and/or hidden during testing. We present a data modality-agnostic auditing framework for generating targeted hypotheses about sources of bias which we refer to as Generalized Attribute Utility and Detectability-Induced bias Testing (G-AUDIT) for datasets. Our method examines the relationship between task-level annotations and data properties including protected attributes (e.g., race, age, sex) and environment and acquisition characteristics (e.g., clinical site, imaging protocols). G-AUDIT automatically quantifies the extent to which the observed data attributes may enable shortcut learning, or in the case of testing data, hide predictions made based on spurious associations. We demonstrate the broad applicability and value of our method by analyzing large-scale medical datasets for three distinct modalities and learning tasks: skin lesion classification in images, stigmatizing language classification in Electronic Health Records (EHR), and mortality prediction for ICU tabular data. In each setting, G-AUDIT successfully identifies subtle biases commonly overlooked by traditional qualitative methods that focus primarily on social and ethical objectives, underscoring its practical value in exposing dataset-level risks and supporting the downstream development of reliable AI systems. Our method paves the way for achieving deeper understanding of machine learning datasets throughout the AI development life-cycle from initial prototyping all the way to regulation, and creates opportunities to reduce model bias, enabling safer and more trustworthy AI systems.", 'abstract_zh': '数据驱动的人工智能正成为基于证据的医学的核心。然而，由于AI依赖于基于关联的学习，其不足之处和意外行为的报告正在增加。我们提出了一种数据模态无关的审计框架，用于生成关于偏倚来源的靶向假设，我们称之为广义属性效用和可检测性诱导偏倚测试（G-AUDIT）。该方法检查任务级注释与数据属性之间的关系，包括保护属性（如种族、年龄、性别）和环境与获取特征（如临床站点、成像协议）。G-AUDIT自动量化观察到的数据属性可能使快速学习变得可行的程度，或者在测试数据的情况下，隐藏基于虚假关联的预测。我们通过分析针对三种不同模态和学习任务的大规模医学数据集（皮肤病变分类图像、电子健康记录中的污名化语言分类、重症监护病房表数据的死亡率预测）来展示该方法的广泛适用性和价值。在每个场景中，G-AUDIT成功识别了传统定性方法通常忽视的细微偏倚，这些方法主要关注社会和伦理目标，突显了其在揭示数据集层面风险和支持下游开发可靠AI系统方面的实用价值。该方法为从初步原型设计到监管的整个AI开发生命周期中实现对机器学习数据集的更深入理解铺平了道路，并创造了减少模型偏倚的机会，从而实现更安全、更值得信赖的AI系统。', 'title_zh': '在医疗人工智能中检测数据集偏差：一种通用且模态无关的审计框架'}
{'arxiv_id': 'arXiv:2503.09960', 'title': 'Optimizing Fire Safety: Reducing False Alarms Using Advanced Machine Learning Techniques', 'authors': 'Muhammad Hassan Jamal, Abdulwahab Alazeb, Shahid Allah Bakhsh, Wadii Boulila, Syed Aziz Shah, Aizaz Ahmad Khattak, Muhammad Shahbaz Khan', 'link': 'https://arxiv.org/abs/2503.09960', 'abstract': 'Fire safety practices are important to reduce the extent of destruction caused by fire. While smoke alarms help save lives, firefighters struggle with the increasing number of false alarms. This paper presents a precise and efficient Weighted ensemble model for decreasing false alarms. It estimates the density, computes weights according to the high and low-density regions, forwards the high region weights to KNN and low region weights to XGBoost and combines the predictions. The proposed model is effective at reducing response time, increasing fire safety, and minimizing the damage that fires cause. A specifically designed dataset for smoke detection is utilized to test the proposed model. In addition, a variety of ML models, such as Logistic Regression (LR), Decision Tree (DT), Random Forest (RF), Nai:ve Bayes (NB), K-Nearest Neighbour (KNN), Support Vector Machine (SVM), Extreme Gradient Boosting (XGBoost), Adaptive Boosting (ADAB), have also been utilized. To maximize the use of the smoke detection dataset, all the algorithms utilize the SMOTE re-sampling technique. After evaluating the assessment criteria, this paper presents a concise summary of the comprehensive findings obtained by comparing the outcomes of all models.', 'abstract_zh': '防火安全实践对于减少火灾造成的破坏至关重要。虽然烟雾报警器有助于挽救生命，但消防员却面临着日益增多的误报警情况。本文提出了一种精确且高效的加权集成模型，用于降低误报警率。该模型通过估计密度、根据高密度和低密度区域计算权重、将高区域权重传递给KNN并将低区域权重传递给XGBoost，从而结合预测结果。所提出的模型能够有效缩短响应时间、提高防火安全性和最小化火灾造成的损害。本文利用专门设计的烟雾检测数据集测试所提出的模型。此外，还使用了多种机器学习模型，如逻辑回归（LR）、决策树（DT）、随机森林（RF）、朴素贝叶斯（NB）、K最近邻（KNN）、支持向量机（SVM）、极端梯度提升（XGBoost）、自适应提升（AdaB）。为了充分利用烟雾检测数据集，所有算法均采用SMOTE重采样技术。在评估评估标准后，本文简洁地总结了所有模型比较结果所得出的综合发现。', 'title_zh': '优化消防安全性：使用高级机器学习技术减少误报'}
{'arxiv_id': 'arXiv:2503.09956', 'title': 'Exploring Mutual Empowerment Between Wireless Networks and RL-based LLMs: A Survey', 'authors': 'Yu Qiao, Phuong-Nam Tran, Ji Su Yoon, Loc X. Nguyen, Choong Seon Hong', 'link': 'https://arxiv.org/abs/2503.09956', 'abstract': 'Reinforcement learning (RL)-based large language models (LLMs), such as ChatGPT, DeepSeek, and Grok-3, have gained significant attention for their exceptional capabilities in natural language processing and multimodal data understanding. Meanwhile, the rapid expansion of information services has driven the growing need for intelligence, efficient, and adaptable wireless networks. Wireless networks require the empowerment of RL-based LLMs while these models also benefit from wireless networks to broaden their application scenarios. Specifically, RL-based LLMs can enhance wireless communication systems through intelligent resource allocation, adaptive network optimization, and real-time decision-making. Conversely, wireless networks provide a vital infrastructure for the efficient training, deployment, and distributed inference of RL-based LLMs, especially in decentralized and edge computing environments. This mutual empowerment highlights the need for a deeper exploration of the interplay between these two domains. We first review recent advancements in wireless communications, highlighting the associated challenges and potential solutions. We then discuss the progress of RL-based LLMs, focusing on key technologies for LLM training, challenges, and potential solutions. Subsequently, we explore the mutual empowerment between these two fields, highlighting key motivations, open challenges, and potential solutions. Finally, we provide insights into future directions, applications, and their societal impact to further explore this intersection, paving the way for next-generation intelligent communication systems. Overall, this survey provides a comprehensive overview of the relationship between RL-based LLMs and wireless networks, offering a vision where these domains empower each other to drive innovations.', 'abstract_zh': '基于强化学习的大型语言模型与无线网络的相互赋能：推动下一代智能通信系统的创新', 'title_zh': '无线网络与基于RL的LLM间相互赋能探索：一个综述'}
{'arxiv_id': 'arXiv:2503.09950', 'title': 'MoFlow: One-Step Flow Matching for Human Trajectory Forecasting via Implicit Maximum Likelihood Estimation based Distillation', 'authors': 'Yuxiang Fu, Qi Yan, Lele Wang, Ke Li, Renjie Liao', 'link': 'https://arxiv.org/abs/2503.09950', 'abstract': 'In this paper, we address the problem of human trajectory forecasting, which aims to predict the inherently multi-modal future movements of humans based on their past trajectories and other contextual cues. We propose a novel motion prediction conditional flow matching model, termed MoFlow, to predict K-shot future trajectories for all agents in a given scene. We design a novel flow matching loss function that not only ensures at least one of the $K$ sets of future trajectories is accurate but also encourages all $K$ sets of future trajectories to be diverse and plausible. Furthermore, by leveraging the implicit maximum likelihood estimation (IMLE), we propose a novel distillation method for flow models that only requires samples from the teacher model. Extensive experiments on the real-world datasets, including SportVU NBA games, ETH-UCY, and SDD, demonstrate that both our teacher flow model and the IMLE-distilled student model achieve state-of-the-art performance. These models can generate diverse trajectories that are physically and socially plausible. Moreover, our one-step student model is $\\textbf{100}$ times faster than the teacher flow model during sampling. The code, model, and data are available at our project page: this https URL', 'abstract_zh': '本文探讨了基于人类过往轨迹和其他上下文线索预测人类固有的多模态未来运动的问题。提出了一种新颖的运动预测条件流匹配模型MoFlow，用于预测给定场景中所有代理的K-shot未来轨迹。设计了一种新颖的流匹配损失函数，不仅确保至少有一组未来的轨迹准确，还鼓励所有K组未来的轨迹具有多样性和合理性。此外，通过利用隐式最大似然估计(IMLE)，提出了一种仅需教师模型样本的新型流模型蒸馏方法。在包含SportVU NBA比赛、ETH-UCY和SDD的真实世界数据集的大量实验中，证明了我们的教师流模型和IMLE蒸馏的学生模型均达到了最新性能。这些模型可以生成物理上和社会上合理的多样化轨迹。此外，我们的单步学生模型在抽样时比教师流模型快100倍。代码、模型和数据可在我们的项目页面获得：this https URL', 'title_zh': 'MoFlow: 通过隐含最大似然估计蒸馏的一步流匹配人类轨迹预测'}
{'arxiv_id': 'arXiv:2503.09947', 'title': 'Identifying Trustworthiness Challenges in Deep Learning Models for Continental-Scale Water Quality Prediction', 'authors': 'Xiaobo Xia, Xiaofeng Liu, Jiale Liu, Kuai Fang, Lu Lu, Samet Oymak, William S. Currie, Tongliang Liu', 'link': 'https://arxiv.org/abs/2503.09947', 'abstract': 'Water quality is foundational to environmental sustainability, ecosystem resilience, and public health. Deep learning models, particularly Long Short-Term Memory (LSTM) networks, offer transformative potential for large-scale water quality prediction and scientific insights generation. However, their widespread adoption in high-stakes decision-making, such as pollution mitigation and equitable resource allocation, is prevented by unresolved trustworthiness challenges including fairness, uncertainty, interpretability, robustness, generalizability, and reproducibility. In this work, we present the first comprehensive evaluation of trustworthiness in a continental-scale multi-task LSTM model predicting 20 water quality variables (encompassing physical/chemical processes, geochemical weathering, and nutrient cycling) across 482 U.S. basins. Our investigation uncovers systematic patterns of model performance disparities linked to basin characteristics, the inherent complexity of biogeochemical processes, and variable predictability, emphasizing critical performance fairness concerns. We further propose methodological frameworks for quantitatively evaluating critical aspects of trustworthiness, including uncertainty, interpretability, and robustness, identifying key limitations that could challenge reliable real-world deployment. This work serves as a timely call to action for advancing trustworthy data-driven methods for water resources management and provides a pathway to offering critical insights for researchers, decision-makers, and practitioners seeking to leverage artificial intelligence (AI) responsibly in environmental management.', 'abstract_zh': '大范围多任务LSTM模型在20个水质量变量（涵盖物理/化学过程、地球化学风化和养分循环）预测中的可信性综合评估：对美国482个流域的系统性研究及其在水资源管理中的应用呼吁', 'title_zh': '识别大陆尺度水质预测深度学习模型的信任度挑战'}
{'arxiv_id': 'arXiv:2503.09941', 'title': 'TGP: Two-modal occupancy prediction with 3D Gaussian and sparse points for 3D Environment Awareness', 'authors': 'Mu Chen, Wenyu Chen, Mingchuan Yang, Yuan Zhang, Tao Han, Xinchi Li, Yunlong Li, Huaici Zhao', 'link': 'https://arxiv.org/abs/2503.09941', 'abstract': '3D semantic occupancy has rapidly become a research focus in the fields of robotics and autonomous driving environment perception due to its ability to provide more realistic geometric perception and its closer integration with downstream tasks. By performing occupancy prediction of the 3D space in the environment, the ability and robustness of scene understanding can be effectively improved. However, existing occupancy prediction tasks are primarily modeled using voxel or point cloud-based approaches: voxel-based network structures often suffer from the loss of spatial information due to the voxelization process, while point cloud-based methods, although better at retaining spatial location information, face limitations in representing volumetric structural details. To address this issue, we propose a dual-modal prediction method based on 3D Gaussian sets and sparse points, which balances both spatial location and volumetric structural information, achieving higher accuracy in semantic occupancy prediction. Specifically, our method adopts a Transformer-based architecture, taking 3D Gaussian sets, sparse points, and queries as inputs. Through the multi-layer structure of the Transformer, the enhanced queries and 3D Gaussian sets jointly contribute to the semantic occupancy prediction, and an adaptive fusion mechanism integrates the semantic outputs of both modalities to generate the final prediction results. Additionally, to further improve accuracy, we dynamically refine the point cloud at each layer, allowing for more precise location information during occupancy prediction. We conducted experiments on the Occ3DnuScenes dataset, and the experimental results demonstrate superior performance of the proposed method on IoU based metrics.', 'abstract_zh': '3D语义 occupancy 双模态预测：基于3D高斯集合和稀疏点的方法', 'title_zh': 'TGP: 基于3D高斯分布和稀疏点的两模态占用预测方法以提升三维环境意识'}
{'arxiv_id': 'arXiv:2503.09927', 'title': 'Developing and Evaluating an AI-Assisted Prediction Model for Unplanned Intensive Care Admissions following Elective Neurosurgery using Natural Language Processing within an Electronic Healthcare Record System', 'authors': 'Julia Ive, Olatomiwa Olukoya, Jonathan P. Funnell, James Booker, Sze H M Lam, Ugan Reddy, Kawsar Noor, Richard JB Dobson, Astri M.V. Luoma, Hani J Marcus', 'link': 'https://arxiv.org/abs/2503.09927', 'abstract': 'Introduction: Timely care in a specialised neuro-intensive therapy unit (ITU) reduces mortality and hospital stays, with planned admissions being safer than unplanned ones. However, post-operative care decisions remain subjective. This study used artificial intelligence (AI), specifically natural language processing (NLP) to analyse electronic health records (EHRs) and predict ITU admissions for elective surgery patients. Methods: This study analysed the EHRs of elective neurosurgery patients from University College London Hospital (UCLH) using NLP. Patients were categorised into planned high dependency unit (HDU) or ITU admission; unplanned HDU or ITU admission; or ward / overnight recovery (ONR). The Medical Concept Annotation Tool (MedCAT) was used to identify SNOMED-CT concepts within the clinical notes. We then explored the utility of these identified concepts for a range of AI algorithms trained to predict ITU admission. Results: The CogStack-MedCAT NLP model, initially trained on hospital-wide EHRs, underwent two refinements: first with data from patients with Normal Pressure Hydrocephalus (NPH) and then with data from Vestibular Schwannoma (VS) patients, achieving a concept detection F1-score of 0.93. This refined model was then used to extract concepts from EHR notes of 2,268 eligible neurosurgical patients. We integrated the extracted concepts into AI models, including a decision tree model and a neural time-series model. Using the simpler decision tree model, we achieved a recall of 0.87 (CI 0.82 - 0.91) for ITU admissions, reducing the proportion of unplanned ITU cases missed by human experts from 36% to 4%. Conclusion: The NLP model, refined for accuracy, has proven its efficiency in extracting relevant concepts, providing a reliable basis for predictive AI models to use in clinically valid applications.', 'abstract_zh': '介绍：专门的神经重症治疗单元（ITU）中的及时护理可降低死亡率和缩短住院时间，计划入院比非计划入院更安全。然而，手术后护理决策仍具有主观性。本研究利用人工智能（AI），具体为自然语言处理（NLP）分析电子健康记录（EHRs），预测择期手术患者进入ITU的入院情况。方法：本研究使用NLP分析伦敦大学学院医院（UCLH）择期神经外科患者的EHRs。患者被分为计划高依赖单元（HDU）或ITU住院；非计划HDU或ITU住院；或病房/过夜恢复（ONR）。使用医疗概念标注工具（MedCAT）识别临床笔记中的SNOMED-CT概念。然后探讨了这些识别的概念对于训练预测ITU住院的多种AI算法的实用性。结果：CogStack-MedCAT NLP模型首先在全院EHRs上进行训练，随后分别用正常压力脑积水（NPH）和前庭神经鞘瘤（VS）患者的资料进行了两次优化，概念检测F1分数达到0.93。优化后的模型用于从2,268例合格神经外科患者的EHR笔记中提取概念。将提取的概念集成到包括决策树模型和神经时序模型在内的AI模型中。使用较为简单的决策树模型，ITU住院的召回率为0.87（95% CI 0.82 - 0.91），降低了人类专家遗漏非计划ITU病例的比例，从36%降至4%。结论：经过精确优化的NLP模型证明了其在提取相关概念方面的效率，为基础的预测AI模型在临床有效应用提供了可靠的基础。', 'title_zh': '基于电子健康记录系统中的自然语言处理开发并评估人工智能辅助预测模型，用于择期神经外科手术后突发重症监护入院预测'}
{'arxiv_id': 'arXiv:2503.09910', 'title': 'eXpLogic: Explaining Logic Types and Patterns in DiffLogic Networks', 'authors': 'Stephen Wormald, David Koblah, Matheus Kunzler Maldaner, Domenic Forte, Damon L. Woodard', 'link': 'https://arxiv.org/abs/2503.09910', 'abstract': "Constraining deep neural networks (DNNs) to learn individual logic types per node, as performed using the DiffLogic network architecture, opens the door to model-specific explanation techniques that quell the complexity inherent to DNNs. Inspired by principles of circuit analysis from computer engineering, this work presents an algorithm (eXpLogic) for producing saliency maps which explain input patterns that activate certain functions. The eXpLogic explanations: (1) show the exact set of inputs responsible for a decision, which helps interpret false negative and false positive predictions, (2) highlight common input patterns that activate certain outputs, and (3) help reduce the network size to improve class-specific inference. To evaluate the eXpLogic saliency map, we introduce a metric that quantifies how much an input changes before switching a model's class prediction (the SwitchDist) and use this metric to compare eXpLogic against the Vanilla Gradients (VG) and Integrated Gradient (IG) methods. Generally, we show that eXpLogic saliency maps are better at predicting which inputs will change the class score. These maps help reduce the network size and inference times by 87\\% and 8\\%, respectively, while having a limited impact (-3.8\\%) on class-specific predictions. The broader value of this work to machine learning is in demonstrating how certain DNN architectures promote explainability, which is relevant to healthcare, defense, and law.", 'abstract_zh': '约束深度神经网络（DNNs）使每个节点学习单一的逻辑类型，如DiffLogic网络架构所做，为特定模型的解释技术打开了大门，这些技术可以缓解DNNs固有的复杂性。受到计算机工程中电路分析原则的启发，本文提出了一种算法（eXpLogic）来生成解释输入模式的显著性图，这些模式激活了某些功能。eXpLogic解释包括：（1）展示了导致决策的精确输入集合，有助于解释假阴性和假阳性预测，（2）突显了激活某些输出的常见输入模式，以及（3）有助于减小网络规模以改进类特定推理。为了评估eXpLogic显著性图，我们引入了一个度量标准，该标准量化了在改变模型类预测前所需输入的改变量（SwitchDist），并使用此度量标准将eXpLogic与其他VG和IG方法进行比较。总体而言，我们表明，eXpLogic显著性图在预测哪些输入会改变类评分方面更为准确。这些图有助于分别减少网络规模和推理时间87%和8%，同时对类特定预测的影响有限（-3.8%）。本文对机器学习的更广泛价值在于，证明了某些DNN架构促进了可解释性，这在医疗保健、国防和法律领域具有相关性。', 'title_zh': 'eXpLogic: 解释DiffLogic网络中的逻辑类型和模式'}
{'arxiv_id': 'arXiv:2503.09901', 'title': 'AI Rivalry as a Craft: How Resisting and Embracing Generative AI Reshape Writing Professions', 'authors': 'Rama Adithya Varanasi, Batia Mishan Wiesenfeld, Oded Nov', 'link': 'https://arxiv.org/abs/2503.09901', 'abstract': "Generative AI (GAI) technologies are disrupting professional writing, challenging traditional practices. Recent studies explore GAI adoption experiences of creative practitioners, but we know little about how these experiences evolve into established practices and how GAI resistance alters these practices. To address this gap, we conducted 25 semi-structured interviews with writing professionals who adopted and/or resisted GAI. Using the theoretical lens of Job Crafting, we identify four strategies professionals employ to reshape their roles. Writing professionals employed GAI resisting strategies to maximize human potential, reinforce professional identity, carve out a professional niche, and preserve credibility within their networks. In contrast, GAI-enabled strategies allowed writers who embraced GAI to enhance desirable workflows, minimize mundane tasks, and engage in new AI-managerial labor. These strategies amplified their collaborations with GAI while reducing their reliance on other people. We conclude by discussing implications of GAI practices on writers' identity and practices as well as crafting theory.", 'abstract_zh': '生成性人工智能（GAI）技术正在颠覆专业写作，挑战传统实践。当前的研究探索了创造性从业者采用GAI的经历，但我们对这些经历如何演变成既定实践以及GAI抵抗如何改变这些实践知之甚少。为了弥补这一空白，我们对25位采用和/或抵抗GAI的写作专业人士进行了半结构化访谈，运用工作重塑的理论视角，我们识别出专业人士采用的四种策略以重塑其角色。写作专业人士采用GAI抵抗策略以最大化人类潜力、强化专业身份、开拓专业细分领域，并在其网络中维护信誉。相比之下，GAI赋能策略使拥抱GAI的写作者能够优化高效的工作流程、减少乏味任务，并参与新的AI管理劳动。这些策略不仅放大了他们与GAI的合作，还减少了他们对其他人的依赖。我们最后讨论了GAI实践对写作者身份和实践的影响以及工作重塑理论的意义。', 'title_zh': 'AI rivalry as a craft:如何抵制与拥抱生成式AI重塑写作职业'}
{'arxiv_id': 'arXiv:2503.09896', 'title': 'A Rule Based Solution to Co-reference Resolution in Clinical Text', 'authors': 'Ping Chen, David Hinote, Guoqing Chen', 'link': 'https://arxiv.org/abs/2503.09896', 'abstract': 'Objective: The aim of this study was to build an effective co-reference resolution system tailored for the biomedical domain. Materials and Methods: Experiment materials used in this study is provided by the 2011 i2b2 Natural Language Processing Challenge. The 2011 i2b2 challenge involves coreference resolution in medical documents. Concept mentions have been annotated in clinical texts, and the mentions that co-refer in each document are to be linked by coreference chains. Normally, there are two ways of constructing a system to automatically discover co-referent links. One is to manually build rules for co-reference resolution, and the other category of approaches is to use machine learning systems to learn automatically from training datasets and then perform the resolution task on testing datasets. Results: Experiments show the existing co-reference resolution systems are able to find some of the co-referent links, and our rule based system performs well finding the majority of the co-referent links. Our system achieved 89.6% overall performance on multiple medical datasets. Conclusion: The experiment results show that manually crafted rules based on observation of training data is a valid way to accomplish high performance in this coreference resolution task for the critical biomedical domain.', 'abstract_zh': '研究目的：本文旨在构建一个针对生物医学领域的有效共指消解系统。材料与方法：本研究使用的实验材料来自2011年i2b2自然语言处理挑战。2011年i2b2挑战包括医疗文档中的共指消解任务。概念提及已在临床文本中进行了标注，并需通过共指链将每份文档中相互共指的提及连接起来。通常，自动发现共指链接的系统有两种构建方式：一种是人工构建共指消解规则，另一种是使用机器学习系统从训练数据集自动学习，然后在测试数据集上执行消解任务。结果：实验结果表明现有的共指消解系统能够找到一些共指链接，而我们的基于规则的系统在发现大多数共指链接上表现良好。我们的系统在多个生物医学数据集上的整体性能达到了89.6%。结论：实验结果表明，在关键的生物医学领域完成共指消解任务时，根据训练数据观察人工构建规则是一种有效的高 performance 方法。', 'title_zh': '基于规则的方法在临床文本中的同指消解'}
{'arxiv_id': 'arXiv:2503.09878', 'title': 'CleverDistiller: Simple and Spatially Consistent Cross-modal Distillation', 'authors': 'Hariprasath Govindarajan, Maciej K. Wozniak, Marvin Klingner, Camille Maurice, B Ravi Kiran, Senthil Yogamani', 'link': 'https://arxiv.org/abs/2503.09878', 'abstract': 'Vision foundation models (VFMs) such as DINO have led to a paradigm shift in 2D camera-based perception towards extracting generalized features to support many downstream tasks. Recent works introduce self-supervised cross-modal knowledge distillation (KD) as a way to transfer these powerful generalization capabilities into 3D LiDAR-based models. However, they either rely on highly complex distillation losses, pseudo-semantic maps, or limit KD to features useful for semantic segmentation only. In this work, we propose CleverDistiller, a self-supervised, cross-modal 2D-to-3D KD framework introducing a set of simple yet effective design choices: Unlike contrastive approaches relying on complex loss design choices, our method employs a direct feature similarity loss in combination with a multi layer perceptron (MLP) projection head to allow the 3D network to learn complex semantic dependencies throughout the projection. Crucially, our approach does not depend on pseudo-semantic maps, allowing for direct knowledge transfer from a VFM without explicit semantic supervision. Additionally, we introduce the auxiliary self-supervised spatial task of occupancy prediction to enhance the semantic knowledge, obtained from a VFM through KD, with 3D spatial reasoning capabilities. Experiments on standard autonomous driving benchmarks for 2D-to-3D KD demonstrate that CleverDistiller achieves state-of-the-art performance in both semantic segmentation and 3D object detection (3DOD) by up to 10% mIoU, especially when fine tuning on really low data amounts, showing the effectiveness of our simple yet powerful KD strategy', 'abstract_zh': '基于视觉的自监督跨模态知识蒸馏：CleverDistiller在2D到3D知识蒸馏中的应用', 'title_zh': 'CleverDistiller: 简洁且空间一致的跨模态蒸馏'}
{'arxiv_id': 'arXiv:2503.09853', 'title': 'Who Are You Behind the Screen? Implicit MBTI and Gender Detection Using Artificial Intelligence', 'authors': 'Kourosh Shahnazari, Seyed Moein Ayyoubzadeh', 'link': 'https://arxiv.org/abs/2503.09853', 'abstract': "In personalized technology and psychological research, precisely detecting demographic features and personality traits from digital interactions becomes ever more important. This work investigates implicit categorization, inferring personality and gender variables directly from linguistic patterns in Telegram conversation data, while conventional personality prediction techniques mostly depend on explicitly self-reported labels. We refine a Transformer-based language model (RoBERTa) to capture complex linguistic cues indicative of personality traits and gender differences using a dataset comprising 138,866 messages from 1,602 users annotated with MBTI types and 195,016 messages from 2,598 users annotated with gender. Confidence levels help to greatly raise model accuracy to 86.16\\%, hence proving RoBERTa's capacity to consistently identify implicit personality types from conversational text data. Our results highlight the usefulness of Transformer topologies for implicit personality and gender classification, hence stressing their efficiency and stressing important trade-offs between accuracy and coverage in realistic conversational environments. With regard to gender classification, the model obtained an accuracy of 74.4\\%, therefore capturing gender-specific language patterns. Personality dimension analysis showed that people with introverted and intuitive preferences are especially more active in text-based interactions. This study emphasizes practical issues in balancing accuracy and data coverage as Transformer-based models show their efficiency in implicit personality and gender prediction tasks from conversational texts.", 'abstract_zh': '个性化技术与心理研究中，精准检测数字互动中的 demographic 特征和个人特质变得越来越重要。本研究通过分析 Telegram 对话数据中的语言模式，直接推断个性和性别变量，而传统的人格预测技术主要依赖于显式自我报告标签。我们对基于 Transformer 的语言模型（RoBERTa）进行精炼，使用包含 138,866 条消息（1,602 用户，标记有 MBTI 类型）和 195,016 条消息（2,598 用户，标记有性别）的数据集，以捕捉预测个性特质和性别差异的语言线索。置信度水平有助于将模型准确性提高到 86.16%，从而证明 RoBERTa 有能力从对话文本数据中一致性地识别隐含的人格类型。本研究强调了 Transformers 架构在隐含人格和性别分类中的有效性，这突出了在实际对话环境中准确性和覆盖面之间的贸易-offs。在性别分类方面，模型的准确率为 74.4%，因此捕捉到了性别特异性语言模式。人格维度分析表明，具有内倾和直觉倾向的人在文本互动中更为活跃。本研究强调了在平衡准确性与数据覆盖面时的实际问题，Transformer 基础模型在隐含人格和性别预测任务中的效率得到了体现。', 'title_zh': '屏幕背后的真实身份：基于人工智能的隐含MBTI和性别识别'}
{'arxiv_id': 'arXiv:2503.09849', 'title': 'Training Human-Robot Teams by Improving Transparency Through a Virtual Spectator Interface', 'authors': 'Sean Dallas, Hongjiao Qiang, Motaz AbuHijleh, Wonse Jo, Kayla Riegner, Jon Smereka, Lionel Robert, Wing-Yue Louie, Dawn M. Tilbury', 'link': 'https://arxiv.org/abs/2503.09849', 'abstract': "After-action reviews (AARs) are professional discussions that help operators and teams enhance their task performance by analyzing completed missions with peers and professionals. Previous studies that compared different formats of AARs have mainly focused on human teams. However, the inclusion of robotic teammates brings along new challenges in understanding teammate intent and communication. Traditional AAR between human teammates may not be satisfactory for human-robot teams. To address this limitation, we propose a new training review (TR) tool, called the Virtual Spectator Interface (VSI), to enhance human-robot team performance and situational awareness (SA) in a simulated search mission. The proposed VSI primarily utilizes visual feedback to review subjects' behavior. To examine the effectiveness of VSI, we took elements from AAR to conduct our own TR, designed a 1 x 3 between-subjects experiment with experimental conditions: TR with (1) VSI, (2) screen recording, and (3) non-technology (only verbal descriptions). The results of our experiments demonstrated that the VSI did not result in significantly better team performance than other conditions. However, the TR with VSI led to more improvement in the subjects SA over the other conditions.", 'abstract_zh': '虚拟观众界面（VSI）在模拟搜索任务中提升人机团队绩效与态势感知的训练审查工具', 'title_zh': '通过虚拟观众界面提高透明度来培训人机团队'}
{'arxiv_id': 'arXiv:2503.09837', 'title': 'On the Limitations of Vision-Language Models in Understanding Image Transforms', 'authors': 'Ahmad Mustafa Anis, Hasnain Ali, Saquib Sarfraz', 'link': 'https://arxiv.org/abs/2503.09837', 'abstract': 'Vision Language Models (VLMs) have demonstrated significant potential in various downstream tasks, including Image/Video Generation, Visual Question Answering, Multimodal Chatbots, and Video Understanding. However, these models often struggle with basic image transformations. This paper investigates the image-level understanding of VLMs, specifically CLIP by OpenAI and SigLIP by Google. Our findings reveal that these models lack comprehension of multiple image-level augmentations. To facilitate this study, we created an augmented version of the Flickr8k dataset, pairing each image with a detailed description of the applied transformation. We further explore how this deficiency impacts downstream tasks, particularly in image editing, and evaluate the performance of state-of-the-art Image2Image models on simple transformations.', 'abstract_zh': '视觉语言模型（VLMs）在图像/视频生成、视觉问答、多模态聊天机器人和视频理解等下游任务中展现了显著潜力。然而，这些模型常在基本的图像变换方面表现不佳。本文研究了VLMs的图像级理解能力，特别是由OpenAI开发的CLIP和由Google开发的SigLIP。我们的研究发现，这些模型对多种图像级增强缺乏理解。为进行这项研究，我们创建了 Flickr8k 数据集的增强版本，为每张图像提供了详细的转换描述。我们进一步探讨了这种不足对下游任务的影响，特别是在图像编辑任务方面，并评估了最先进的Image2Image模型在简单变换上的性能。', 'title_zh': '视觉语言模型在理解图像变换方面的局限性'}
{'arxiv_id': 'arXiv:2503.09822', 'title': 'Generative AI for Named Entity Recognition in Low-Resource Language Nepali', 'authors': 'Sameer Neupane, Jeevan Chapagain, Nobal B. Niraula, Diwa Koirala', 'link': 'https://arxiv.org/abs/2503.09822', 'abstract': 'Generative Artificial Intelligence (GenAI), particularly Large Language Models (LLMs), has significantly advanced Natural Language Processing (NLP) tasks, such as Named Entity Recognition (NER), which involves identifying entities like person, location, and organization names in text. LLMs are especially promising for low-resource languages due to their ability to learn from limited data. However, the performance of GenAI models for Nepali, a low-resource language, has not been thoroughly evaluated. This paper investigates the application of state-of-the-art LLMs for Nepali NER, conducting experiments with various prompting techniques to assess their effectiveness. Our results provide insights into the challenges and opportunities of using LLMs for NER in low-resource settings and offer valuable contributions to the advancement of NLP research in languages like Nepali.', 'abstract_zh': '生成式人工智能（GenAI），尤其是大型语言模型（LLMs），在自然语言处理（NLP）任务中取得了显著进展，例如命名实体识别（NER），该任务涉及识别文本中的人名、地名和组织名等实体。LLMs特别适合低资源语言，因为它们能够从有限的数据中学习。然而，生成式人工智能模型在尼泊尔语这一低资源语言中的性能尚未得到充分评估。本文探讨了最先进的LLMs在尼泊尔语NER中的应用，通过使用各种提示技术进行实验，评估其效果。我们的结果提供了关于在低资源环境中使用LLMs进行NER所面临挑战和机遇的见解，并为尼泊尔语等语言的NLP研究进展提供了宝贵贡献。', 'title_zh': '生成式AI在低资源语言尼泊尔语命名实体识别中的应用'}
{'arxiv_id': 'arXiv:2503.09820', 'title': 'Vi-LAD: Vision-Language Attention Distillation for Socially-Aware Robot Navigation in Dynamic Environments', 'authors': 'Mohamed Elnoor, Kasun Weerakoon, Gershom Seneviratne, Jing Liang, Vignesh Rajagopal, Dinesh Manocha', 'link': 'https://arxiv.org/abs/2503.09820', 'abstract': 'We introduce Vision-Language Attention Distillation (Vi-LAD), a novel approach for distilling socially compliant navigation knowledge from a large Vision-Language Model (VLM) into a lightweight transformer model for real-time robotic navigation. Unlike traditional methods that rely on expert demonstrations or human-annotated datasets, Vi-LAD performs knowledge distillation and fine-tuning at the intermediate layer representation level (i.e., attention maps) by leveraging the backbone of a pre-trained vision-action model. These attention maps highlight key navigational regions in a given scene, which serve as implicit guidance for socially aware motion planning. Vi-LAD fine-tunes a transformer-based model using intermediate attention maps extracted from the pre-trained vision-action model, combined with attention-like semantic maps constructed from a large VLM. To achieve this, we introduce a novel attention-level distillation loss that fuses knowledge from both sources, generating augmented attention maps with enhanced social awareness. These refined attention maps are then utilized as a traversability costmap within a socially aware model predictive controller (MPC) for navigation. We validate our approach through real-world experiments on a Husky wheeled robot, demonstrating significant improvements over state-of-the-art (SOTA) navigation methods. Our results show up to 14.2% - 50% improvement in success rate, which highlights the effectiveness of Vi-LAD in enabling socially compliant and efficient robot navigation.', 'abstract_zh': 'Vision-Language 注意力蒸馏（Vi-LAD）：一种从大型视觉语言模型中提取社会合规导航知识的方法，以实现实时机器人导航中的轻量级转换器模型fine-tuning', 'title_zh': 'Vi-LAD: 视觉-语言注意力精炼用于动态环境中的社会意识机器人导航'}
{'arxiv_id': 'arXiv:2503.09817', 'title': 'Temporal Difference Flows', 'authors': 'Jesse Farebrother, Matteo Pirotta, Andrea Tirinzoni, Rémi Munos, Alessandro Lazaric, Ahmed Touati', 'link': 'https://arxiv.org/abs/2503.09817', 'abstract': "Predictive models of the future are fundamental for an agent's ability to reason and plan. A common strategy learns a world model and unrolls it step-by-step at inference, where small errors can rapidly compound. Geometric Horizon Models (GHMs) offer a compelling alternative by directly making predictions of future states, avoiding cumulative inference errors. While GHMs can be conveniently learned by a generative analog to temporal difference (TD) learning, existing methods are negatively affected by bootstrapping predictions at train time and struggle to generate high-quality predictions at long horizons. This paper introduces Temporal Difference Flows (TD-Flow), which leverages the structure of a novel Bellman equation on probability paths alongside flow-matching techniques to learn accurate GHMs at over 5x the horizon length of prior methods. Theoretically, we establish a new convergence result and primarily attribute TD-Flow's efficacy to reduced gradient variance during training. We further show that similar arguments can be extended to diffusion-based methods. Empirically, we validate TD-Flow across a diverse set of domains on both generative metrics and downstream tasks including policy evaluation. Moreover, integrating TD-Flow with recent behavior foundation models for planning over pre-trained policies demonstrates substantial performance gains, underscoring its promise for long-horizon decision-making.", 'abstract_zh': '未来预测模型是智能体推理和规划能力的基础。几何地平线模型（GHMs）通过直接预测未来状态，避免累积推理错误，提供了一种有吸引力的替代方案。本文引入了时空差分流（TD-Flow），它利用新的概率路径贝尔曼方程结构及流动匹配技术，在超过之前方法5倍的预测长度上学习精确的GHMs。理论上，我们建立了新的收敛结果，主要归因于TD-Flow在训练中减少的梯度方差。此外，我们展示了类似的论点可以扩展到基于扩散的方法。实验上，我们在生成指标和下游任务（包括策略评估）的多种领域验证了TD-Flow的有效性。进一步地，将TD-Flow与最近的行为基础模型结合用于预训练策略的规划展示了显著性能提升，突显了其在长时决策中的潜力。', 'title_zh': '时差流动'}
{'arxiv_id': 'arXiv:2503.09808', 'title': 'Fine-tuning Vision Language Models with Graph-based Knowledge for Explainable Medical Image Analysis', 'authors': 'Chenjun Li, Laurin Lux, Alexander H. Berger, Martin J. Menten, Mert R. Sabuncu, Johannes C. Paetzold', 'link': 'https://arxiv.org/abs/2503.09808', 'abstract': "Accurate staging of Diabetic Retinopathy (DR) is essential for guiding timely interventions and preventing vision loss. However, current staging models are hardly interpretable, and most public datasets contain no clinical reasoning or interpretation beyond image-level labels. In this paper, we present a novel method that integrates graph representation learning with vision-language models (VLMs) to deliver explainable DR diagnosis. Our approach leverages optical coherence tomography angiography (OCTA) images by constructing biologically informed graphs that encode key retinal vascular features such as vessel morphology and spatial connectivity. A graph neural network (GNN) then performs DR staging while integrated gradients highlight critical nodes and edges and their individual features that drive the classification decisions. We collect this graph-based knowledge which attributes the model's prediction to physiological structures and their characteristics. We then transform it into textual descriptions for VLMs. We perform instruction-tuning with these textual descriptions and the corresponding image to train a student VLM. This final agent can classify the disease and explain its decision in a human interpretable way solely based on a single image input. Experimental evaluations on both proprietary and public datasets demonstrate that our method not only improves classification accuracy but also offers more clinically interpretable results. An expert study further demonstrates that our method provides more accurate diagnostic explanations and paves the way for precise localization of pathologies in OCTA images.", 'abstract_zh': '基于图表示学习和视觉语言模型的糖尿病视网膜病变解释性分级方法', 'title_zh': '基于图知识的 Fine-tuning 视觉语言模型以实现可解释的医学图像分析'}
{'arxiv_id': 'arXiv:2503.09805', 'title': 'Un-Straightening Generative AI: How Queer Artists Surface and Challenge the Normativity of Generative AI Models', 'authors': 'Jordan Taylor, Joel Mire, Franchesca Spektor, Alicia DeVrio, Maarten Sap, Haiyi Zhu, Sarah Fox', 'link': 'https://arxiv.org/abs/2503.09805', 'abstract': 'Queer people are often discussed as targets of bias, harm, or discrimination in research on generative AI. However, the specific ways that queer people engage with generative AI, and thus possible uses that support queer people, have yet to be explored. We conducted a workshop study with 13 queer artists, during which we gave participants access to GPT-4 and DALL-E 3 and facilitated group sensemaking activities. We found our participants struggled to use these models due to various normative values embedded in their designs, such as hyper-positivity and anti-sexuality. We describe various strategies our participants developed to overcome these models\' limitations and how, nevertheless, our participants found value in these highly-normative technologies. Drawing on queer feminist theory, we discuss implications for the conceptualization of "state-of-the-art" models and consider how FAccT researchers might support queer alternatives.', 'abstract_zh': '同性恋人群在生成式AI研究中往往被视为偏见、伤害或歧视的目标。然而，同性恋人群与生成式AI的具体互动方式及其可能支持同性恋人群的应用尚未被探索。我们通过一项包含13名同性恋艺术家的工作坊研究，让参与者接触GPT-4和DALL-E 3，并促进集体意义建构活动。我们发现参与者由于这些模型设计中嵌入的各种规范性价值观（如过度积极和反性倾向）而难以使用这些模型。我们描述了参与者为克服这些模型的局限性而开发的各种策略，并探讨了尽管存在这些局限性，参与者仍然认为这些高度规范化的技术具有价值的原因。基于女权主义的同性恋理论，我们讨论了对“最先进”模型概念化的启示，并考虑FAccT研究人员如何支持同性恋替代方案。', 'title_zh': '非规范化的生成AI： queer艺术家揭示并挑战生成AI模型的规范性'}
{'arxiv_id': 'arXiv:2503.09797', 'title': 'SeqSAM: Autoregressive Multiple Hypothesis Prediction for Medical Image Segmentation using SAM', 'authors': 'Benjamin Towle, Xin Chen, Ke Zhou', 'link': 'https://arxiv.org/abs/2503.09797', 'abstract': 'Pre-trained segmentation models are a powerful and flexible tool for segmenting images. Recently, this trend has extended to medical imaging. Yet, often these methods only produce a single prediction for a given image, neglecting inherent uncertainty in medical images, due to unclear object boundaries and errors caused by the annotation tool. Multiple Choice Learning is a technique for generating multiple masks, through multiple learned prediction heads. However, this cannot readily be extended to producing more outputs than its initial pre-training hyperparameters, as the sparse, winner-takes-all loss function makes it easy for one prediction head to become overly dominant, thus not guaranteeing the clinical relevancy of each mask produced. We introduce SeqSAM, a sequential, RNN-inspired approach to generating multiple masks, which uses a bipartite matching loss for ensuring the clinical relevancy of each mask, and can produce an arbitrary number of masks. We show notable improvements in quality of each mask produced across two publicly available datasets. Our code is available at this https URL.', 'abstract_zh': '预训练分割模型是图像分割的强大且灵活的工具。近年来，这一趋势已扩展到医学成像。然而，这些方法通常只为给定图像生成一个预测，忽略了医学图像中固有的不确定性，由于物体边界不清楚和标注工具引起的误差。多项选择学习是一种通过多个学习预测头生成多个掩码的技术。然而，这不能轻易扩展为生成超过初始预训练超参数的更多输出，因为稀疏的、赢家通吃的损失函数会使一个预测头变得过于主导，从而不能保证每个生成的掩码的临床相关性。我们引入了SeqSAM，这是一种受循环神经网络启发的生成多个掩码的顺序方法，使用双部分匹配损失来确保每个掩码的临床相关性，并可以生成任意数量的掩码。我们在两个公开的数据集上展示了每个生成的掩码的质量上有显著改进。我们的代码可在以下链接获取。', 'title_zh': 'SeqSAM：基于SAM的自回归多假设医学图像分割预测'}
{'arxiv_id': 'arXiv:2503.09746', 'title': 'Solving Bayesian inverse problems with diffusion priors and off-policy RL', 'authors': 'Luca Scimeca, Siddarth Venkatraman, Moksh Jain, Minsu Kim, Marcin Sendera, Mohsin Hasan, Luke Rowe, Sarthak Mittal, Pablo Lemos, Emmanuel Bengio, Alexandre Adam, Jarrid Rector-Brooks, Yashar Hezaveh, Laurence Perreault-Levasseur, Yoshua Bengio, Glen Berseth, Nikolay Malkin', 'link': 'https://arxiv.org/abs/2503.09746', 'abstract': 'This paper presents a practical application of Relative Trajectory Balance (RTB), a recently introduced off-policy reinforcement learning (RL) objective that can asymptotically solve Bayesian inverse problems optimally. We extend the original work by using RTB to train conditional diffusion model posteriors from pretrained unconditional priors for challenging linear and non-linear inverse problems in vision, and science. We use the objective alongside techniques such as off-policy backtracking exploration to improve training. Importantly, our results show that existing training-free diffusion posterior methods struggle to perform effective posterior inference in latent space due to inherent biases.', 'abstract_zh': '本文介绍了相对轨迹平衡(RTB)的实用性应用，RTB是最近引入的一种_off-policy_强化学习(RL)目标，能够渐近地最优解决贝叶斯逆问题。我们通过使用RTB从预训练的无条件先验中训练条件扩散模型后验，解决了视觉和科学领域中的挑战性线性和非线性逆问题。我们使用该目标与其他技术如_off-policy_回溯探索相结合，以改进训练。重要的是，我们的结果表明，现有的无训练扩散后验方法由于固有的偏差，在潜在空间中难以进行有效的后验推理。', 'title_zh': '使用扩散先验和离策强化学习求解贝叶斯逆问题'}
{'arxiv_id': 'arXiv:2503.09737', 'title': 'Unveiling Hidden Pivotal Players with GoalNet: A GNN-Based Soccer Player Evaluation System', 'authors': 'Jacky Hao Jiang, Jerry Cai, Anastasios Kyrillidis', 'link': 'https://arxiv.org/abs/2503.09737', 'abstract': "Soccer analysis tools emphasize metrics such as expected goals, leading to an overrepresentation of attacking players' contributions and overlooking players who facilitate ball control and link attacks. Examples include Rodri from Manchester City and Palhinha who just transferred to Bayern Munich. To address this bias, we aim to identify players with pivotal roles in a soccer team, incorporating both spatial and temporal features.\nIn this work, we introduce a GNN-based framework that assigns individual credit for changes in expected threat (xT), thus capturing overlooked yet vital contributions in soccer. Our pipeline encodes both spatial and temporal features in event-centric graphs, enabling fair attribution of non-scoring actions such as defensive or transitional plays. We incorporate centrality measures into the learned player embeddings, ensuring that ball-retaining defenders and defensive midfielders receive due recognition for their overall impact. Furthermore, we explore diverse GNN variants-including Graph Attention Networks and Transformer-based models-to handle long-range dependencies and evolving match contexts, discussing their relative performance and computational complexity. Experiments on real match data confirm the robustness of our approach in highlighting pivotal roles that traditional attacking metrics typically miss, underscoring the model's utility for more comprehensive soccer analytics.", 'abstract_zh': '基于GNN的足球分析工具框架：识别关键球员并公平归因非得分行为', 'title_zh': '使用GoalNet揭示隐藏的关键球员：基于GNN的足球球员评估系统'}
{'arxiv_id': 'arXiv:2503.09721', 'title': 'Finding the Muses: Identifying Coresets through Loss Trajectories', 'authors': 'Manish Nagaraj, Deepak Ravikumar, Efstathia Soufleri, Kaushik Roy', 'link': 'https://arxiv.org/abs/2503.09721', 'abstract': 'Deep learning models achieve state-of-the-art performance across domains but face scalability challenges in real-time or resource-constrained scenarios. To address this, we propose Loss Trajectory Correlation (LTC), a novel metric for coreset selection that identifies critical training samples driving generalization. $LTC$ quantifies the alignment between training sample loss trajectories and validation set loss trajectories, enabling the construction of compact, representative subsets. Unlike traditional methods with computational and storage overheads that are infeasible to scale to large datasets, $LTC$ achieves superior efficiency as it can be computed as a byproduct of training. Our results on CIFAR-100 and ImageNet-1k show that $LTC$ consistently achieves accuracy on par with or surpassing state-of-the-art coreset selection methods, with any differences remaining under 1%. LTC also effectively transfers across various architectures, including ResNet, VGG, DenseNet, and Swin Transformer, with minimal performance degradation (<2%). Additionally, LTC offers insights into training dynamics, such as identifying aligned and conflicting sample behaviors, at a fraction of the computational cost of traditional methods. This framework paves the way for scalable coreset selection and efficient dataset optimization.', 'abstract_zh': '深度学习模型在各个领域 achieves 现有技术水平，但在实时或资源受限场景下面临可扩展性挑战。为解决这一问题，我们提出了损失轨迹相关性（LTC）这一新颖的聚芯选择度量标准，以识别驱动泛化的关键训练样本。LTC 通过量化训练样本损失轨迹与验证集损失轨迹之间的对齐程度，能够构建紧凑且具代表性的子集。与传统方法相比，LTC 不会产生额外的计算和存储开销，因此在处理大规模数据集时更具优势。我们的实验结果表明，LTC 在 Cifar-100 和 ImageNet-1k 上的准确率与现有最先进的聚芯选择方法相当或更优，差异不超过 1%。此外，LTC 在包括 ResNet、VGG、DenseNet 和 Swin Transformer 等各种架构上表现出色，性能退化低于 2%。LTC 还在较低的计算成本下提供了训练动态的见解，如识别对齐和冲突样本的行为。这一框架为可扩展的聚芯选择和高效的数据集优化铺平了道路。', 'title_zh': '寻找灵感：通过损失轨迹识别核样本'}
{'arxiv_id': 'arXiv:2503.09712', 'title': 'Revisiting Backdoor Attacks on Time Series Classification in the Frequency Domain', 'authors': 'Yuanmin Huang, Mi Zhang, Zhaoxiang Wang, Wenxuan Li, Min Yang', 'link': 'https://arxiv.org/abs/2503.09712', 'abstract': 'Time series classification (TSC) is a cornerstone of modern web applications, powering tasks such as financial data analysis, network traffic monitoring, and user behavior analysis. In recent years, deep neural networks (DNNs) have greatly enhanced the performance of TSC models in these critical domains. However, DNNs are vulnerable to backdoor attacks, where attackers can covertly implant triggers into models to induce malicious outcomes. Existing backdoor attacks targeting DNN-based TSC models remain elementary. In particular, early methods borrow trigger designs from computer vision, which are ineffective for time series data. More recent approaches utilize generative models for trigger generation, but at the cost of significant computational complexity. In this work, we analyze the limitations of existing attacks and introduce an enhanced method, FreqBack. Drawing inspiration from the fact that DNN models inherently capture frequency domain features in time series data, we identify that improper perturbations in the frequency domain are the root cause of ineffective attacks. To address this, we propose to generate triggers both effectively and efficiently, guided by frequency analysis. FreqBack exhibits substantial performance across five models and eight datasets, achieving an impressive attack success rate of over 90%, while maintaining less than a 3% drop in model accuracy on clean data.', 'abstract_zh': '基于时间序列分类的频域后门攻击：FreqBack方法', 'title_zh': 'frequency域中时间序列分类的后门攻击再探'}
{'arxiv_id': 'arXiv:2503.09707', 'title': 'Revisiting semi-supervised learning in the era of foundation models', 'authors': 'Ping Zhang, Zheda Mai, Quang-Huy Nguyen, Wei-Lun Chao', 'link': 'https://arxiv.org/abs/2503.09707', 'abstract': 'Semi-supervised learning (SSL) leverages abundant unlabeled data alongside limited labeled data to enhance learning. As vision foundation models (VFMs) increasingly serve as the backbone of vision applications, it remains unclear how SSL interacts with these pre-trained models. To address this gap, we develop new SSL benchmark datasets where frozen VFMs underperform and systematically evaluate representative SSL methods. We make a surprising observation: parameter-efficient fine-tuning (PEFT) using only labeled data often matches SSL performance, even without leveraging unlabeled data. This motivates us to revisit self-training, a conceptually simple SSL baseline, where we use the supervised PEFT model to pseudo-label unlabeled data for further training. To overcome the notorious issue of noisy pseudo-labels, we propose ensembling multiple PEFT approaches and VFM backbones to produce more robust pseudo-labels. Empirical results validate the effectiveness of this simple yet powerful approach, providing actionable insights into SSL with VFMs and paving the way for more scalable and practical semi-supervised learning in the era of foundation models.', 'abstract_zh': '半监督学习（SSL）利用丰富的未标签数据和有限的标签数据来增强学习。随着视觉基础模型（VFMs）在视觉应用中越来越担任骨干角色，尚不清楚SSL如何与这些预训练模型互动。为填补这一空白，我们开发了新的SSL基准数据集，在这些数据集上冻结的VFMs表现不佳，并系统地评估了代表性的SSL方法。我们意外地发现：仅使用标签数据的参数高效微调（PEFT）往往能匹配SSL性能，甚至无需利用未标签数据。这一发现促使我们重新审视自训练这一概念上简单的SSL基线方法，通过使用监督PEFT模型为未标签数据生成伪标签来进行进一步训练。为克服伪标签噪声这一著名问题，我们提出将多个PEFT方法和VFMs的骨干网络进行集成，以生成更稳健的伪标签。实验结果验证了这一简单而有效的方法的有效性，为使用VFMs的SSL提供了 actionable 洞察，并为基于基础模型时代的可扩展且实用的半监督学习铺平了道路。', 'title_zh': 'revisiting 半监督学习于大模型时代'}
{'arxiv_id': 'arXiv:2503.09669', 'title': 'Silent Branding Attack: Trigger-free Data Poisoning Attack on Text-to-Image Diffusion Models', 'authors': 'Sangwon Jang, June Suk Choi, Jaehyeong Jo, Kimin Lee, Sung Ju Hwang', 'link': 'https://arxiv.org/abs/2503.09669', 'abstract': 'Text-to-image diffusion models have achieved remarkable success in generating high-quality contents from text prompts. However, their reliance on publicly available data and the growing trend of data sharing for fine-tuning make these models particularly vulnerable to data poisoning attacks. In this work, we introduce the Silent Branding Attack, a novel data poisoning method that manipulates text-to-image diffusion models to generate images containing specific brand logos or symbols without any text triggers. We find that when certain visual patterns are repeatedly in the training data, the model learns to reproduce them naturally in its outputs, even without prompt mentions. Leveraging this, we develop an automated data poisoning algorithm that unobtrusively injects logos into original images, ensuring they blend naturally and remain undetected. Models trained on this poisoned dataset generate images containing logos without degrading image quality or text alignment. We experimentally validate our silent branding attack across two realistic settings on large-scale high-quality image datasets and style personalization datasets, achieving high success rates even without a specific text trigger. Human evaluation and quantitative metrics including logo detection show that our method can stealthily embed logos.', 'abstract_zh': '基于文本的图像扩散模型已在从文本提示生成高质量内容方面取得了显著成功。然而，它们对公开可用数据的依赖以及数据共享以进行微调的趋势使其特别容易受到数据中毒攻击。本文中，我们介绍了无声品牌攻击，这是一种新型数据中毒方法，可以操纵基于文本的图像扩散模型生成包含特定品牌标志或符号的图像，而不使用任何文本触发器。我们发现，当某些视觉模式在训练数据中反复出现时，模型会自然地在输出中复制这些模式，即使没有提示提及。利用这一点，我们开发了一种自动数据中毒算法，能够不显眼地将标志注入原始图像，确保它们自然融合并保持不被察觉。基于此中毒数据集训练的模型能够生成包含标志的图像，而不降低图像质量或文本对齐。我们通过在大规模高质量图像数据集和个人风格定制数据集上的两个现实场景中实验验证了我们的无声品牌攻击，即使没有特定的文本触发器，也取得了 high success rates。人类评估和包括标志检测在内的定量指标表明，我们的方法能够隐秘地嵌入标志。', 'title_zh': '无声品牌攻击：无需触发的数据中毒攻击针对文本到图像扩散模型'}
{'arxiv_id': 'arXiv:2503.09658', 'title': 'Towards Robust Model Evolution with Algorithmic Recourse', 'authors': 'Hao-Tsung Yang, Jie Gao, Bo-Yi Liu, Zhi-Xuan Liu', 'link': 'https://arxiv.org/abs/2503.09658', 'abstract': 'Algorithmic Recourse is a way for users to modify their attributes to align with a model\'s expectations, thereby improving their outcomes after receiving unfavorable decisions. In real-world scenarios, users often need to strategically adjust their attributes to compete for limited resources. However, such strategic behavior induces users to "game" algorithms, causing model collapse due to distribution shifts. These shifts arise from user competition, resource constraints, and adaptive user responses. While prior research on Algorithmic Recourse has explored its effects on both systems and users, the impact of resource constraints and competition over time remains underexplored. In this work, we develop a general framework to model user strategic behaviors and their interactions with decision-making systems under resource constraints and competitive dynamics. Through theoretical analysis and empirical evaluation, we identify three key phenomena that arise consistently in both synthetic and real-world datasets: escalating decision boundaries, non-robust model predictions, and inequitable recourse actions. Finally, we discuss the broader social implications of these findings and present two algorithmic strategies aimed at mitigating these challenges.', 'abstract_zh': '算法可溯性是用户修改其属性以使其与模型期望相一致的一种方式，从而在收到不利决定后改善其结果。在现实场景中，用户往往需要战略性地调整其属性以竞争有限资源。然而，这种战略性行为促使用户“游戏”算法，导致由于分布移位而使模型崩溃。这些移位源于用户竞争、资源限制和用户适应性反应。尽管先前关于算法可溯性的研究探讨了其对系统和用户的影响，但资源限制和时间竞争效应的影响尚未得到充分探索。在本文中，我们开发了一种通用框架来建模在资源限制和竞争动态下用户的战略性行为及其与决策系统之间的互动。通过理论分析和实证评估，我们发现了在合成数据集和真实数据集上均一致出现的三种关键现象：决策边界升级、模型预测不稳健以及不公的可溯性行动。最后，我们讨论了这些发现的更广泛社会影响，并提出了两种算法策略以缓解这些挑战。', 'title_zh': '面向具有算法干预的鲁棒模型演化'}
{'arxiv_id': 'arXiv:2503.09642', 'title': 'Open-Sora 2.0: Training a Commercial-Level Video Generation Model in $200k', 'authors': 'Xiangyu Peng, Zangwei Zheng, Chenhui Shen, Tom Young, Xinying Guo, Binluo Wang, Hang Xu, Hongxin Liu, Mingyan Jiang, Wenjun Li, Yuhui Wang, Anbang Ye, Gang Ren, Qianran Ma, Wanying Liang, Xiang Lian, Xiwen Wu, Yuting Zhong, Zhuangyan Li, Chaoyu Gong, Guojun Lei, Leijun Cheng, Limin Zhang, Minghao Li, Ruijie Zhang, Silan Hu, Shijie Huang, Xiaokang Wang, Yuanheng Zhao, Yuqi Wang, Ziang Wei, Yang You', 'link': 'https://arxiv.org/abs/2503.09642', 'abstract': 'Video generation models have achieved remarkable progress in the past year. The quality of AI video continues to improve, but at the cost of larger model size, increased data quantity, and greater demand for training compute. In this report, we present Open-Sora 2.0, a commercial-level video generation model trained for only $200k. With this model, we demonstrate that the cost of training a top-performing video generation model is highly controllable. We detail all techniques that contribute to this efficiency breakthrough, including data curation, model architecture, training strategy, and system optimization. According to human evaluation results and VBench scores, Open-Sora 2.0 is comparable to global leading video generation models including the open-source HunyuanVideo and the closed-source Runway Gen-3 Alpha. By making Open-Sora 2.0 fully open-source, we aim to democratize access to advanced video generation technology, fostering broader innovation and creativity in content creation. All resources are publicly available at: this https URL.', 'abstract_zh': '商业级视频生成模型Open-Sora 2.0：仅20万美元训练的高性能视频生成模型', 'title_zh': 'Open-Sora 2.0: 在200万美元预算内训练商业级视频生成模型'}
{'arxiv_id': 'arXiv:2503.09639', 'title': 'Can A Society of Generative Agents Simulate Human Behavior and Inform Public Health Policy? A Case Study on Vaccine Hesitancy', 'authors': 'Abe Bohan Hou, Hongru Du, Yichen Wang, Jingyu Zhang, Zixiao Wang, Paul Pu Liang, Daniel Khashabi, Lauren Gardner, Tianxing He', 'link': 'https://arxiv.org/abs/2503.09639', 'abstract': "Can we simulate a sandbox society with generative agents to model human behavior, thereby reducing the over-reliance on real human trials for assessing public policies? In this work, we investigate the feasibility of simulating health-related decision-making, using vaccine hesitancy, defined as the delay in acceptance or refusal of vaccines despite the availability of vaccination services (MacDonald, 2015), as a case study. To this end, we introduce the VacSim framework with 100 generative agents powered by Large Language Models (LLMs). VacSim simulates vaccine policy outcomes with the following steps: 1) instantiate a population of agents with demographics based on census data; 2) connect the agents via a social network and model vaccine attitudes as a function of social dynamics and disease-related information; 3) design and evaluate various public health interventions aimed at mitigating vaccine hesitancy. To align with real-world results, we also introduce simulation warmup and attitude modulation to adjust agents' attitudes. We propose a series of evaluations to assess the reliability of various LLM simulations. Experiments indicate that models like Llama and Qwen can simulate aspects of human behavior but also highlight real-world alignment challenges, such as inconsistent responses with demographic profiles. This early exploration of LLM-driven simulations is not meant to serve as definitive policy guidance; instead, it serves as a call for action to examine social simulation for policy development.", 'abstract_zh': '能否通过生成代理模拟沙盒社会来模仿人类行为，从而减少对实际人类试验的依赖以评估公共政策？本研究探讨使用疫苗犹豫（MacDonald, 2015）作为案例研究，利用人口统计学数据构建代理群体，通过社会网络构建代理并模拟疫苗态度作为社会动态和疾病相关信息的函数，设计并评估旨在减少疫苗犹豫的各种公共卫生干预措施，从而模拟健康相关决策。为使模拟结果与实际情况相符，我们引入了模拟热身和态度调节。我们提出了一系列评估，以评估各种大型语言模型模拟的可靠性。实验表明，如Llama和Qwen等模型可以模拟人类行为的某些方面，但也指出了现实世界对齐的挑战，如与人口统计特征不一致的反应。本早期探索性研究并非旨在提供最终政策指导，而是呼吁通过社会模拟来研究政策开发。', 'title_zh': '生成型代理社会能否模拟人类行为并为公共卫生政策提供信息？以疫苗犹豫为例的研究案例'}
{'arxiv_id': 'arXiv:2503.09638', 'title': 'Edge AI-Powered Real-Time Decision-Making for Autonomous Vehicles in Adverse Weather Conditions', 'authors': 'Milad Rahmati', 'link': 'https://arxiv.org/abs/2503.09638', 'abstract': 'Autonomous vehicles (AVs) are transforming modern transportation, but their reliability and safety are significantly challenged by harsh weather conditions such as heavy rain, fog, and snow. These environmental factors impair the performance of cameras, LiDAR, and radar, leading to reduced situational awareness and increased accident risks. Conventional cloud-based AI systems introduce communication delays, making them unsuitable for the rapid decision-making required in real-time autonomous navigation. This paper presents a novel Edge AI-driven real-time decision-making framework designed to enhance AV responsiveness under adverse weather conditions. The proposed approach integrates convolutional neural networks (CNNs) and recurrent neural networks (RNNs) for improved perception, alongside reinforcement learning (RL)-based strategies to optimize vehicle control in uncertain environments. By processing data at the network edge, this system significantly reduces decision latency while improving AV adaptability. The framework is evaluated using simulated driving scenarios in CARLA and real-world data from the Waymo Open Dataset, covering diverse weather conditions. Experimental results indicate that the proposed model achieves a 40% reduction in processing time and a 25% enhancement in perception accuracy compared to conventional cloud-based systems. These findings highlight the potential of Edge AI in improving AV autonomy, safety, and efficiency, paving the way for more reliable self-driving technology in challenging real-world environments.', 'abstract_zh': '基于边缘AI的恶劣天气下实时决策框架：提升自动驾驶车辆响应性', 'title_zh': '边缘AI赋能的恶劣天气条件下的自动驾驶车辆实时决策-making'}
{'arxiv_id': 'arXiv:2503.09635', 'title': 'FPGS: Feed-Forward Semantic-aware Photorealistic Style Transfer of Large-Scale Gaussian Splatting', 'authors': 'GeonU Kim, Kim Youwang, Lee Hyoseok, Tae-Hyun Oh', 'link': 'https://arxiv.org/abs/2503.09635', 'abstract': "We present FPGS, a feed-forward photorealistic style transfer method of large-scale radiance fields represented by Gaussian Splatting. FPGS, stylizes large-scale 3D scenes with arbitrary, multiple style reference images without additional optimization while preserving multi-view consistency and real-time rendering speed of 3D Gaussians. Prior arts required tedious per-style optimization or time-consuming per-scene training stage and were limited to small-scale 3D scenes. FPGS efficiently stylizes large-scale 3D scenes by introducing a style-decomposed 3D feature field, which inherits AdaIN's feed-forward stylization machinery, supporting arbitrary style reference images. Furthermore, FPGS supports multi-reference stylization with the semantic correspondence matching and local AdaIN, which adds diverse user control for 3D scene styles. FPGS also preserves multi-view consistency by applying semantic matching and style transfer processes directly onto queried features in 3D space. In experiments, we demonstrate that FPGS achieves favorable photorealistic quality scene stylization for large-scale static and dynamic 3D scenes with diverse reference images. Project page: this https URL", 'abstract_zh': '我们提出FPGS，这是一种基于高斯 splatting 表示的大规模辐射场的端到端 photorealistic 风格转移方法。FPGS能够在不进行附加优化的情况下，使用任意多个风格参考图像对大规模 3D 场景进行风格化处理，同时保持多视角一致性和 3D 高斯体的实时渲染速度。先前的方法需要针对每种风格进行繁琐的优化或针对每个场景进行耗时的训练阶段，且仅限于小规模 3D 场景。FPGS通过引入风格分解的 3D 特征场，继承了 AdaIN 的端到端风格化机制，支持任意风格参考图像。此外，FPGS还支持通过语义对应匹配和局部 AdaIN 进行多参考图像风格化，为 3D 场景风格提供了多样化的用户控制。FPGS通过直接在 3D 空间中的查询特征上应用语义匹配和风格转移过程，保持多视角一致性。在实验中，我们展示了FPGS能够使用各种参考图像实现大规模静态和动态 3D 场景的优质 photorealistic 风格化效果。项目页面：这个链接', 'title_zh': 'FPGS: 前馈语义aware的高保真样式转移方法研究（基于大规模高斯散步）'}
{'arxiv_id': 'arXiv:2503.09626', 'title': 'Certainly Bot Or Not? Trustworthy Social Bot Detection via Robust Multi-Modal Neural Processes', 'authors': 'Qi Wu, Yingguang Yang, hao liu, Hao Peng, Buyun He, Yutong Xia, Yong Liao', 'link': 'https://arxiv.org/abs/2503.09626', 'abstract': 'Social bot detection is crucial for mitigating misinformation, online manipulation, and coordinated inauthentic behavior. While existing neural network-based detectors perform well on benchmarks, they struggle with generalization due to distribution shifts across datasets and frequently produce overconfident predictions for out-of-distribution accounts beyond the training data. To address this, we introduce a novel Uncertainty Estimation for Social Bot Detection (UESBD) framework, which quantifies the predictive uncertainty of detectors beyond mere classification. For this task, we propose Robust Multi-modal Neural Processes (RMNP), which aims to enhance the robustness of multi-modal neural processes to modality inconsistencies caused by social bot camouflage. RMNP first learns unimodal representations through modality-specific encoders. Then, unimodal attentive neural processes are employed to encode the Gaussian distribution of unimodal latent variables. Furthermore, to avoid social bots stealing human features to camouflage themselves thus causing certain modalities to provide conflictive information, we introduce an evidential gating network to explicitly model the reliability of modalities. The joint latent distribution is learned through the generalized product of experts, which takes the reliability of each modality into consideration during fusion. The final prediction is obtained through Monte Carlo sampling of the joint latent distribution followed by a decoder. Experiments on three real-world benchmarks show the effectiveness of RMNP in classification and uncertainty estimation, as well as its robustness to modality conflicts.', 'abstract_zh': '社会机器人检测对于减轻错误信息、在线操控和 coordinative 不真实行为至关重要。尽管现有的基于神经网络的检测器在基准测试中表现良好，但由于数据集分布转移导致的一般化困难，它们在生成超出训练数据之外的 out-of-distribution 帐号的置信预测时往往会过于自信。为解决这一问题，我们提出了一种新的社会机器人检测中的不确定性估计框架（UESBD），该框架超越了单纯的分类预测，量化了检测器的预测不确定性。为此任务，我们提出了鲁棒多模态神经过程（RMNP），旨在增强多模态神经过程对由社会机器人伪装引起的模态不一致性鲁棒性。RMNP 首先通过模态特定编码器学习单模表示。然后，使用单模注意神经过程编码单模潜变量的高斯分布。此外，为了防止社会机器人通过伪装窃取人类特征，从而导致某些模态提供矛盾信息，我们引入了一个证据门控网络以明确建模模态的可靠性。通过广义专家产品学习联合潜分布，在融合时考虑每个模态的可靠性。最终预测通过联合潜分布的蒙特卡洛采样和解码器获得。在三个真实世界基准上的实验表明，RMNP 在分类和不确定性估计中有效，并且能够抵抗模态冲突。', 'title_zh': '一定是机器人吗？基于稳健多模态神经过程的社会机器人可信检测'}
{'arxiv_id': 'arXiv:2503.09620', 'title': 'Exploiting Edited Large Language Models as General Scientific Optimizers', 'authors': 'Qitan Lv, Tianyu Liu, Hong Wang', 'link': 'https://arxiv.org/abs/2503.09620', 'abstract': "Large language models (LLMs) have been widely adopted in mathematical optimization in scientific scenarios for their extensive knowledge and advanced reasoning capabilities. Existing methods mainly focus on utilizing LLMs to solve optimization problems in a prompt-based manner, which takes observational feedback as additional textual descriptions. However, due to LLM's \\textbf{high sensitivity to the prompts} and \\textbf{tendency to get lost in lengthy prompts}, these methods struggle to effectively utilize the {observational} feedback from each optimization step, which severely hinders the applications for real-world scenarios. To address these challenges, we propose a conceptually simple and general {bi-level} optimization method, namely \\textbf{G}eneral \\textbf{S}cientific \\textbf{O}ptimizers (GSO). Specifically, GSO first utilizes inner-level simulators as experimental platforms to evaluate the current solution and provide observational feedback. Then, LLMs serve as knowledgeable and versatile scientists, generating new solutions by refining potential errors from the feedback as the outer-level optimization. Finally, simulations together with the expert knowledge in LLMs are jointly updated with bi-level interactions via model editing. Extensive experiments show that GSO consistently outperforms existing state-of-the-art methods using \\textit{six} different LLM backbones on \\textit{seven} different tasks, demonstrating the effectiveness and a wide range of applications.", 'abstract_zh': '大型语言模型在科学场景中的数学优化应用：一种通用双层优化方法（GSO）', 'title_zh': '利用编辑后的大型语言模型作为通用科学优化器'}
{'arxiv_id': 'arXiv:2503.09613', 'title': 'Empowering the Future Workforce: Prioritizing Education for the AI-Accelerated Job Market', 'authors': 'Lisa Amini, Henry F. Korth, Nita Patel, Evan Peck, Ben Zorn', 'link': 'https://arxiv.org/abs/2503.09613', 'abstract': "AI's rapid integration into the workplace demands new approaches to workforce education and training and broader AI literacy across disciplines. Coordinated action from government, industry, and educational institutions is necessary to ensure workers can adapt to accelerating technological change.", 'abstract_zh': 'AI在职场的迅速融入要求跨学科的新培训方法和更广泛的AI素养，并需政府、行业和教育机构的协调行动以确保工人能够适应加速的技术变革。', 'title_zh': '赋能未来 workforce: 优先推动面向AI加速job市场的发展教育'}
{'arxiv_id': 'arXiv:2503.05050', 'title': 'A Unified Framework with Novel Metrics for Evaluating the Effectiveness of XAI Techniques in LLMs', 'authors': 'Melkamu Abay Mersha, Mesay Gemeda Yigezu, Hassan shakil, Ali Al shami, Sanghyun Byun, Jugal Kalita', 'link': 'https://arxiv.org/abs/2503.05050', 'abstract': 'The increasing complexity of LLMs presents significant challenges to their transparency and interpretability, necessitating the use of eXplainable AI (XAI) techniques to enhance trustworthiness and usability. This study introduces a comprehensive evaluation framework with four novel metrics for assessing the effectiveness of five XAI techniques across five LLMs and two downstream tasks. We apply this framework to evaluate several XAI techniques LIME, SHAP, Integrated Gradients, Layer-wise Relevance Propagation (LRP), and Attention Mechanism Visualization (AMV) using the IMDB Movie Reviews and Tweet Sentiment Extraction datasets. The evaluation focuses on four key metrics: Human-reasoning Agreement (HA), Robustness, Consistency, and Contrastivity. Our results show that LIME consistently achieves high scores across multiple LLMs and evaluation metrics, while AMV demonstrates superior Robustness and near-perfect Consistency. LRP excels in Contrastivity, particularly with more complex models. Our findings provide valuable insights into the strengths and limitations of different XAI methods, offering guidance for developing and selecting appropriate XAI techniques for LLMs.', 'abstract_zh': 'LLMs复杂性的增加对其实现透明性和可解释性提出了重大挑战，亟需使用可解释AI（XAI）技术来增强其可信度和实用性。本研究引入了一个全面的评估框架，包含四个新型指标，用于评估五种XAI技术在五个LLM和两项下游任务中的有效性。我们应用该框架，使用IMDB电影评论和推文情感提取数据集，评估了LIME、SHAP、整合梯度、层相关性传播（LRP）和注意力机制可视化（AMV）等多种XAI技术。评估主要聚焦于四个关键指标：人类推理一致性（HA）、鲁棒性、一致性与对比度性。研究结果显示，LIME在多个LLM和评估指标上持续获得高分，而AMV在鲁棒性和一致性方面表现出色。LRP在对比度性上表现突出，尤其是在更复杂模型中。我们的研究成果提供了不同XAI方法优缺点的有价值的见解，为开发和选择适合LLM的XAI技术提供了指导。', 'title_zh': '一种新颖度量指标下的统一框架：评估解释性AI技术在大语言模型中的有效性'}
