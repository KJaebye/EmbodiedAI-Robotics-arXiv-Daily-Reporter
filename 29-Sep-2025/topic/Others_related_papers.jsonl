{'arxiv_id': 'arXiv:2509.22550', 'title': 'An Intention-driven Lane Change Framework Considering Heterogeneous Dynamic Cooperation in Mixed-traffic Environment', 'authors': 'Xiaoyun Qiu, Haichao Liu, Yue Pan, Jun Ma, Xinhu Zheng', 'link': 'https://arxiv.org/abs/2509.22550', 'abstract': "In mixed-traffic environments, where autonomous vehicles (AVs) interact with diverse human-driven vehicles (HVs), unpredictable intentions and heterogeneous behaviors make safe and efficient lane change maneuvers highly challenging. Existing methods often oversimplify these interactions by assuming uniform patterns. We propose an intention-driven lane change framework that integrates driving-style recognition, cooperation-aware decision-making, and coordinated motion planning. A deep learning classifier trained on the NGSIM dataset identifies human driving styles in real time. A cooperation score with intrinsic and interactive components estimates surrounding drivers' intentions and quantifies their willingness to cooperate with the ego vehicle. Decision-making combines behavior cloning with inverse reinforcement learning to determine whether a lane change should be initiated. For trajectory generation, model predictive control is integrated with IRL-based intention inference to produce collision-free and socially compliant maneuvers. Experiments show that the proposed model achieves 94.2\\% accuracy and 94.3\\% F1-score, outperforming rule-based and learning-based baselines by 4-15\\% in lane change recognition. These results highlight the benefit of modeling inter-driver heterogeneity and demonstrate the potential of the framework to advance context-aware and human-like autonomous driving in complex traffic environments.", 'abstract_zh': '在包含自动驾驶车辆和人类驾驶车辆的复杂交通环境中，基于意图的变道框架：整合驾驶风格识别、合作感知决策和协同运动规划', 'title_zh': '基于意图的考虑异质动态合作的混合交通环境变道框架'}
{'arxiv_id': 'arXiv:2509.22469', 'title': 'Uncertainty-Aware Multi-Robot Task Allocation With Strongly Coupled Inter-Robot Rewards', 'authors': 'Ben Rossano, Jaein Lim, Jonathan P. How', 'link': 'https://arxiv.org/abs/2509.22469', 'abstract': 'This paper proposes a task allocation algorithm for teams of heterogeneous robots in environments with uncertain task requirements. We model these requirements as probability distributions over capabilities and use this model to allocate tasks such that robots with complementary skills naturally position near uncertain tasks, proactively mitigating task failures without wasting resources. We introduce a market-based approach that optimizes the joint team objective while explicitly capturing coupled rewards between robots, offering a polynomial-time solution in decentralized settings with strict communication assumptions. Comparative experiments against benchmark algorithms demonstrate the effectiveness of our approach and highlight the challenges of incorporating coupled rewards in a decentralized formulation.', 'abstract_zh': '本文提出了一种异质机器人团队在任务需求不确定性环境下任务分配算法。我们将这些需求建模为能力的概率分布，并利用该模型分配任务，使得具有互补技能的机器人自然地接近不确定的任务，主动减轻任务失败风险而不浪费资源。我们介绍了一种基于市场的方法，在分散设置中优化联合团队目标的同时明确捕捉机器人之间的耦合奖励，提供严格的通信假设下的多项式时间解决方案。与基准算法的比较实验表明了我们方法的有效性，并突显了在分散公式中整合耦合奖励所面临的挑战。', 'title_zh': '具有强耦合机器人间奖励的不确定性意识多机器人任务分配'}
{'arxiv_id': 'arXiv:2509.22288', 'title': 'IMU-Preintegrated Radar Factors for Asynchronous Radar-LiDAR-Inertial SLAM', 'authors': 'Johan Hatleskog, Morten Nissov, Kostas Alexis', 'link': 'https://arxiv.org/abs/2509.22288', 'abstract': 'Fixed-lag Radar-LiDAR-Inertial smoothers conventionally create one factor graph node per measurement to compensate for the lack of time synchronization between radar and LiDAR. For a radar-LiDAR sensor pair with equal rates, this strategy results in a state creation rate of twice the individual sensor frequencies. This doubling of the number of states per second yields high optimization costs, inhibiting real-time performance on resource-constrained hardware. We introduce IMU-preintegrated radar factors that use high-rate inertial data to propagate the most recent LiDAR state to the radar measurement timestamp. This strategy maintains the node creation rate at the LiDAR measurement frequency. Assuming equal sensor rates, this lowers the number of nodes by 50 % and consequently the computational costs. Experiments on a single board computer (which has 4 cores each of 2.2 GHz A73 and 2 GHz A53 with 8 GB RAM) show that our method preserves the absolute pose error of a conventional baseline while simultaneously lowering the aggregated factor graph optimization time by up to 56 %.', 'abstract_zh': '基于IMU预积分的雷达-LiDAR惯性平滑器', 'title_zh': 'IMU-预积分雷达因子在异步雷达-激光雷达-惯性SLAM中的应用'}
{'arxiv_id': 'arXiv:2509.21983', 'title': 'Hybrid Diffusion for Simultaneous Symbolic and Continuous Planning', 'authors': 'Sigmund Hennum Høeg, Aksel Vaaler, Chaoqi Liu, Olav Egeland, Yilun Du', 'link': 'https://arxiv.org/abs/2509.21983', 'abstract': 'Constructing robots to accomplish long-horizon tasks is a long-standing challenge within artificial intelligence. Approaches using generative methods, particularly Diffusion Models, have gained attention due to their ability to model continuous robotic trajectories for planning and control. However, we show that these models struggle with long-horizon tasks that involve complex decision-making and, in general, are prone to confusing different modes of behavior, leading to failure. To remedy this, we propose to augment continuous trajectory generation by simultaneously generating a high-level symbolic plan. We show that this requires a novel mix of discrete variable diffusion and continuous diffusion, which dramatically outperforms the baselines. In addition, we illustrate how this hybrid diffusion process enables flexible trajectory synthesis, allowing us to condition synthesized actions on partial and complete symbolic conditions.', 'abstract_zh': '构建用于完成长远任务的机器人是人工智能领域的一个长期挑战。通过生成方法，特别是扩散模型，由于其能够建模连续的机器人轨迹以进行规划和控制，这些方法受到了关注。然而，我们展示了这些模型在处理涉及复杂决策的长远任务时存在困难，通常会混淆不同行为模式，导致失败。为解决这一问题，我们提出通过同时生成高层符号计划来扩展连续轨迹生成。我们表明，这需要一种新颖的离散变量扩散与连续扩散的结合，这在基准方法上表现出色。此外，我们展示了这种混合扩散过程如何使轨迹合成更加灵活，从而使生成的动作能够根据部分和完整的符号条件进行条件化。', 'title_zh': '混合扩散usi时的符号和连续规划'}
{'arxiv_id': 'arXiv:2509.21961', 'title': 'FlowDrive: moderated flow matching with data balancing for trajectory planning', 'authors': 'Lingguang Wang, Ömer Şahin Taş, Marlon Steiner, Christoph Stiller', 'link': 'https://arxiv.org/abs/2509.21961', 'abstract': 'Learning-based planners are sensitive to the long-tailed distribution of driving data. Common maneuvers dominate datasets, while dangerous or rare scenarios are sparse. This imbalance can bias models toward the frequent cases and degrade performance on critical scenarios. To tackle this problem, we compare balancing strategies for sampling training data and find reweighting by trajectory pattern an effective approach. We then present FlowDrive, a flow-matching trajectory planner that learns a conditional rectified flow to map noise directly to trajectory distributions with few flow-matching steps. We further introduce moderated, in-the-loop guidance that injects small perturbation between flow steps to systematically increase trajectory diversity while remaining scene-consistent. On nuPlan and the interaction-focused interPlan benchmarks, FlowDrive achieves state-of-the-art results among learning-based planners and approaches methods with rule-based refinements. After adding moderated guidance and light post-processing (FlowDrive*), it achieves overall state-of-the-art performance across nearly all benchmark splits.', 'abstract_zh': '基于学习的规划器对驾驶数据的长尾分布敏感。常见操作在数据集中占据主导地位，而危险或罕见场景则极少出现。这种不平衡会使模型偏向常见情况，从而在关键场景上的性能下降。为解决这一问题，我们比较了采样训练数据的平衡策略，并发现基于轨迹模式加权是一种有效的approach。我们随后提出了FlowDrive，这是一种流动匹配轨迹规划器，通过学习条件矫正流动直接将噪声映射到轨迹分布中，并仅需少量流动匹配步骤。我们进一步引入了适度的在环指导，通过在流动步骤之间注入小的扰动，系统地增加轨迹多样性，同时保持场景一致性。在nuPlan和交互聚焦的interPlan基准测试中，FlowDrive在基于学习的规划器中达到了最先进的性能，并接近基于规则细化的方法。在添加了适度指导和轻量级后处理（FlowDrive*）后，它在几乎所有基准测试分割中实现了整体最先进性能。', 'title_zh': 'FlowDrive：带数据平衡的流量匹配路径规划'}
{'arxiv_id': 'arXiv:2509.21955', 'title': 'Learnable Conformal Prediction with Context-Aware Nonconformity Functions for Robotic Planning and Perception', 'authors': 'Divake Kumar, Sina Tayebati, Francesco Migliarba, Ranganath Krishnan, Amit Ranjan Trivedi', 'link': 'https://arxiv.org/abs/2509.21955', 'abstract': "Deep learning models in robotics often output point estimates with poorly calibrated confidences, offering no native mechanism to quantify predictive reliability under novel, noisy, or out-of-distribution inputs. Conformal prediction (CP) addresses this gap by providing distribution-free coverage guarantees, yet its reliance on fixed nonconformity scores ignores context and can yield intervals that are overly conservative or unsafe. We address this with Learnable Conformal Prediction (LCP), which replaces fixed scores with a lightweight neural function that leverages geometric, semantic, and task-specific features to produce context-aware uncertainty sets.\nLCP maintains CP's theoretical guarantees while reducing prediction set sizes by 18% in classification, tightening detection intervals by 52%, and improving path planning safety from 72% to 91% success with minimal overhead. Across three robotic tasks on seven benchmarks, LCP consistently outperforms Standard CP and ensemble baselines. In classification on CIFAR-100 and ImageNet, it achieves smaller set sizes (4.7-9.9% reduction) at target coverage. For object detection on COCO, BDD100K, and Cityscapes, it produces 46-54% tighter bounding boxes. In path planning through cluttered environments, it improves success to 91.5% with only 4.5% path inflation, compared to 12.2% for Standard CP.\nThe method is lightweight (approximately 4.8% runtime overhead, 42 KB memory) and supports online adaptation, making it well suited to resource-constrained autonomous systems. Hardware evaluation shows LCP adds less than 1% memory and 15.9% inference overhead, yet sustains 39 FPS on detection tasks while being 7.4 times more energy-efficient than ensembles.", 'abstract_zh': '可学习形变预测（Learnable Conformal Prediction）在机器人任务中的应用', 'title_zh': '基于上下文感知非一致性函数的可学习区间预测方法及其在机器人规划与感知中的应用'}
{'arxiv_id': 'arXiv:2509.21873', 'title': 'Improved Vehicle Maneuver Prediction using Game Theoretic Priors', 'authors': 'Nishant Doshi', 'link': 'https://arxiv.org/abs/2509.21873', 'abstract': 'Conventional maneuver prediction methods use some sort of classification model on temporal trajectory data to predict behavior of agents over a set time horizon. Despite of having the best precision and recall, these models cannot predict a lane change accurately unless they incorporate information about the entire scene. Level-k game theory can leverage the human-like hierarchical reasoning to come up with the most rational decisions each agent can make in a group. This can be leveraged to model interactions between different vehicles in presence of each other and hence compute the most rational decisions each agent would make. The result of game theoretic evaluation can be used as a "prior" or combined with a traditional motion-based classification model to achieve more accurate predictions. The proposed approach assumes that the states of the vehicles around the target lead vehicle are known. The module will output the most rational maneuver prediction of the target vehicle based on an online optimization solution. These predictions are instrumental in decision making systems like Adaptive Cruise Control (ACC) or Traxen\'s iQ-Cruise further improving the resulting fuel savings.', 'abstract_zh': '传统的机动预测方法使用某种类型的分类模型来处理时空轨迹数据，以预测一组时间范围内的代理行为。尽管这些模型在精度和召回率方面表现最佳，但如果它们不包含整个场景的信息，则无法准确预测车道变更。级联游戏理论可以利用类似人类分层推理的方式，为组内每个代理可能做出的最合理决策提供依据。这可以用来建模彼此存在的不同车辆之间的互动，并由此计算出每个代理会做出的最合理决策。游戏理论评估的结果可以作为“先验知识”或与传统的基于运动的分类模型结合，以实现更准确的预测。所提出的方法假设目标车辆周围的车辆状态已知。该模块将基于在线优化解决方案输出目标车辆的最合理机动预测。这些预测对于如自适应巡航控制(ACC)或Traxen的iQ-Cruise之类的决策系统具有重要意义，进一步提高燃油节省效果。', 'title_zh': '基于博弈论先验的车辆 maneuvers 预测改进'}
{'arxiv_id': 'arXiv:2509.22298', 'title': 'Trust and Human Autonomy after Cobot Failures: Communication is Key for Industry 5.0', 'authors': 'Felix Glawe, Laura Kremer, Luisa Vervier, Philipp Brauner, Martina Ziefle', 'link': 'https://arxiv.org/abs/2509.22298', 'abstract': "Collaborative robots (cobots) are a core technology of Industry 4.0. Industry 4.0 uses cyber-physical systems, IoT and smart automation to improve efficiency and data-driven decision-making. Cobots, as cyber-physical systems, enable the introduction of lightweight automation to smaller companies through their flexibility, low cost and ability to work alongside humans, while keeping humans and their skills in the loop. Industry 5.0, the evolution of Industry 4.0, places the worker at the centre of its principles: The physical and mental well-being of the worker is the main goal of new technology design, not just productivity, efficiency and safety standards. Within this concept, human trust in cobots and human autonomy are important. While trust is essential for effective and smooth interaction, the workers' perception of autonomy is key to intrinsic motivation and overall well-being. As failures are an inevitable part of technological systems, this study aims to answer the question of how system failures affect trust in cobots as well as human autonomy, and how they can be recovered afterwards. Therefore, a VR experiment (n = 39) was set up to investigate the influence of a cobot failure and its severity on human autonomy and trust in the cobot. Furthermore, the influence of transparent communication about the failure and next steps was investigated. The results show that both trust and autonomy suffer after cobot failures, with the severity of the failure having a stronger negative impact on trust, but not on autonomy. Both trust and autonomy can be partially restored by transparent communication.", 'abstract_zh': '协作机器人（cobots）是 Industry 4.0 的核心技术。Industry 4.0 通过网络物理系统、物联网和智能自动化提高效率和基于数据的决策。作为网络物理系统，协作机器人通过其灵活性、低成本和能够与人类合作的能力，使轻量级自动化技术能够应用到较小的公司，同时确保人类及其技能的参与。Industry 5.0 是 Industry 4.0 的进化，将工人置于其原则的中心：工人的身心健康是新技术设计的主要目标，而不仅仅是生产力、效率和安全标准。在此概念下，工人对协作机器人的信任和人类自主性非常重要。虽然信任对于有效和顺畅的交互至关重要，但工人的自主感对于内在动机和整体福祉是关键。由于技术系统的失败是不可避免的，本研究旨在探究系统失败如何影响工人对协作机器人的信任以及人类的自主性，以及如何进行恢复。因此，我们设置了 VR 实验（n=39）来调查协作机器人失败及其严重程度对人类自主性及对协作机器人信任的影响，还考察了透明沟通关于失败及其后续步骤的影响。结果表明，协作机器人失败后，信任和自主性都会受到影响，其中失败的严重性对信任的影响更为显著，但对自主性的影响较小。通过透明沟通，信任和自主性都可以部分恢复。', 'title_zh': '协作机器人故障后的人机信任与自主性：Industry 5.0 中的关键在于沟通'}
{'arxiv_id': 'arXiv:2509.22137', 'title': 'Log2Plan: An Adaptive GUI Automation Framework Integrated with Task Mining Approach', 'authors': 'Seoyoung Lee, Seonbin Yoon, Seongbeen Lee, Hyesoo Kim, Joo Yong Sim', 'link': 'https://arxiv.org/abs/2509.22137', 'abstract': 'GUI task automation streamlines repetitive tasks, but existing LLM or VLM-based planner-executor agents suffer from brittle generalization, high latency, and limited long-horizon coherence. Their reliance on single-shot reasoning or static plans makes them fragile under UI changes or complex tasks. Log2Plan addresses these limitations by combining a structured two-level planning framework with a task mining approach over user behavior logs, enabling robust and adaptable GUI automation. Log2Plan constructs high-level plans by mapping user commands to a structured task dictionary, enabling consistent and generalizable automation. To support personalization and reuse, it employs a task mining approach from user behavior logs that identifies user-specific patterns. These high-level plans are then grounded into low-level action sequences by interpreting real-time GUI context, ensuring robust execution across varying interfaces. We evaluated Log2Plan on 200 real-world tasks, demonstrating significant improvements in task success rate and execution time. Notably, it maintains over 60.0% success rate even on long-horizon task sequences, highlighting its robustness in complex, multi-step workflows.', 'abstract_zh': 'GUI任务自动化简化了重复任务，但现有的基于LLM或VLM的规划执行代理在泛化能力、延迟和长期连贯性方面存在局限性。它们依赖于单次推理或静态计划，使其在UI变化或复杂任务面前变得脆弱。Log2Plan通过结合结构化的两层规划框架和基于用户行为日志的任务挖掘方法，解决了这些限制，实现了稳健且适应性强的GUI自动化。Log2Plan通过将用户命令映射到结构化的任务字典中，构建高层次计划，从而实现一致和可泛化的自动化。为支持个性化和复用，它采用从用户行为日志中识别用户特定模式的任务挖掘方法。这些高层次计划随后通过解释实时GUI上下文，被转化为低层操作序列，确保在不同界面之间实现稳健执行。我们在200项真实世界任务上评估了Log2Plan，显示出显著的任务成功率和执行时间改进。值得注意的是，即使在长时间序列的任务中，其成功率仍保持在超过60.0%，突显了其在复杂多步工作流中的稳健性。', 'title_zh': 'Log2Plan：一种结合任务挖掘方法的自适应GUI自动化框架'}
{'arxiv_id': 'arXiv:2509.21464', 'title': 'Residual Vector Quantization For Communication-Efficient Multi-Agent Perception', 'authors': 'Dereje Shenkut, B.V.K Vijaya Kumar', 'link': 'https://arxiv.org/abs/2509.21464', 'abstract': 'Multi-agent collaborative perception (CP) improves scene understanding by sharing information across connected agents such as autonomous vehicles, unmanned aerial vehicles, and robots. Communication bandwidth, however, constrains scalability. We present ReVQom, a learned feature codec that preserves spatial identity while compressing intermediate features. ReVQom is an end-to-end method that compresses feature dimensions via a simple bottleneck network followed by multi-stage residual vector quantization (RVQ). This allows only per-pixel code indices to be transmitted, reducing payloads from 8192 bits per pixel (bpp) of uncompressed 32-bit float features to 6-30 bpp per agent with minimal accuracy loss. On DAIR-V2X real-world CP dataset, ReVQom achieves 273x compression at 30 bpp to 1365x compression at 6 bpp. At 18 bpp (455x), ReVQom matches or outperforms raw-feature CP, and at 6-12 bpp it enables ultra-low-bandwidth operation with graceful degradation. ReVQom allows efficient and accurate multi-agent collaborative perception with a step toward practical V2X deployment.', 'abstract_zh': '基于学习的特征编解码器ReVQom在保持空间身份的同时压缩中间特征，以提高多智能体协作感知的效率和准确性', 'title_zh': '基于通信高效性的多agent感知残差向量量化'}
{'arxiv_id': 'arXiv:2509.21386', 'title': 'ShipwreckFinder: A QGIS Tool for Shipwreck Detection in Multibeam Sonar Data', 'authors': 'Anja Sheppard, Tyler Smithline, Andrew Scheffer, David Smith, Advaith V. Sethuraman, Ryan Bird, Sabrina Lin, Katherine A. Skinner', 'link': 'https://arxiv.org/abs/2509.21386', 'abstract': 'In this paper, we introduce ShipwreckFinder, an open-source QGIS plugin that detects shipwrecks from multibeam sonar data. Shipwrecks are an important historical marker of maritime history, and can be discovered through manual inspection of bathymetric data. However, this is a time-consuming process and often requires expert analysis. Our proposed tool allows users to automatically preprocess bathymetry data, perform deep learning inference, threshold model outputs, and produce either pixel-wise segmentation masks or bounding boxes of predicted shipwrecks. The backbone of this open-source tool is a deep learning model, which is trained on a variety of shipwreck data from the Great Lakes and the coasts of Ireland. Additionally, we employ synthetic data generation in order to increase the size and diversity of our dataset. We demonstrate superior segmentation performance with our open-source tool and training pipeline as compared to a deep learning-based ArcGIS toolkit and a more classical inverse sinkhole detection method. The open-source tool can be found at this https URL.', 'abstract_zh': '本论文引入了ShipwreckFinder，一个开源QGIS插件，用于从多束声纳数据中检测沉船。', 'title_zh': 'ShipwreckFinder：一个用于多波束声纳数据中沉船检测的QGIS工具'}
{'arxiv_id': 'arXiv:2509.22516', 'title': 'TrueGradeAI: Retrieval-Augmented and Bias-Resistant AI for Transparent and Explainable Digital Assessments', 'authors': 'Rakesh Thakur, Shivaansh Kaushik, Gauri Chopra, Harsh Rohilla', 'link': 'https://arxiv.org/abs/2509.22516', 'abstract': 'This paper introduces TrueGradeAI, an AI-driven digital examination framework designed to overcome the shortcomings of traditional paper-based assessments, including excessive paper usage, logistical complexity, grading delays, and evaluator bias. The system preserves natural handwriting by capturing stylus input on secure tablets and applying transformer-based optical character recognition for transcription. Evaluation is conducted through a retrieval-augmented pipeline that integrates faculty solutions, cache layers, and external references, enabling a large language model to assign scores with explicit, evidence-linked reasoning. Unlike prior tablet-based exam systems that primarily digitize responses, TrueGradeAI advances the field by incorporating explainable automation, bias mitigation, and auditable grading trails. By uniting handwriting preservation with scalable and transparent evaluation, the framework reduces environmental costs, accelerates feedback cycles, and progressively builds a reusable knowledge base, while actively working to mitigate grading bias and ensure fairness in assessment.', 'abstract_zh': 'TrueGradeAI：一种基于AI的数字考试框架，用于克服传统纸质评估的不足', 'title_zh': 'TrueGradeAI: 检索增强且抗偏见的透明可解释数字评估AI'}
{'arxiv_id': 'arXiv:2509.22460', 'title': 'GeoSketch: A Neural-Symbolic Approach to Geometric Multimodal Reasoning with Auxiliary Line Construction and Affine Transformation', 'authors': 'Shichao Weng, Zhiqiang Wang, Yuhua Zhou, Rui Lu, Ting Liu, Zhiyang Teng, Xiaozhang Liu, Hanmeng Liu', 'link': 'https://arxiv.org/abs/2509.22460', 'abstract': 'Geometric Problem Solving (GPS) poses a unique challenge for Multimodal Large Language Models (MLLMs), requiring not only the joint interpretation of text and diagrams but also iterative visuospatial reasoning. While existing approaches process diagrams as static images, they lack the capacity for dynamic manipulation - a core aspect of human geometric reasoning involving auxiliary line construction and affine transformations. We present GeoSketch, a neural-symbolic framework that recasts geometric reasoning as an interactive perception-reasoning-action loop. GeoSketch integrates: (1) a Perception module that abstracts diagrams into structured logic forms, (2) a Symbolic Reasoning module that applies geometric theorems to decide the next deductive step, and (3) a Sketch Action module that executes operations such as drawing auxiliary lines or applying transformations, thereby updating the diagram in a closed loop. To train this agent, we develop a two-stage pipeline: supervised fine-tuning on 2,000 symbolic-curated trajectories followed by reinforcement learning with dense, symbolic rewards to enhance robustness and strategic exploration. To evaluate this paradigm, we introduce the GeoSketch Benchmark, a high-quality set of 390 geometry problems requiring auxiliary construction or affine transformations. Experiments on strong MLLM baselines demonstrate that GeoSketch significantly improves stepwise reasoning accuracy and problem-solving success over static perception methods. By unifying hierarchical decision-making, executable visual actions, and symbolic verification, GeoSketch advances multimodal reasoning from static interpretation to dynamic, verifiable interaction, establishing a new foundation for solving complex visuospatial problems.', 'abstract_zh': '几何问题求解（GPS）对多模态大型语言模型（MLLMs）提出了独特挑战，不仅需要联合解释文本和图表，还需要迭代的空间视觉推理。现有方法将图表处理为静态图像，缺乏动态操作的能力——这是人类几何推理的核心方面，涉及辅助线构造和仿射变换。我们提出了GeoSketch，一个神经符号框架，将几何推理重新表述为互动感知-推理-行动循环。GeoSketch 结合了：（1）一个感知模块，将图表抽象为结构化逻辑形式；（2）一个符号推理模块，应用几何定理决定下一步推理；（3）一个绘图动作模块，执行绘制辅助线或应用变换等操作，以在闭环中更新图表。为了训练这个代理，我们开发了一个两阶段管道：首先在2000条符号整理的轨迹上进行监督微调，然后通过密集的符号奖励进行强化学习，以增强鲁棒性和策略探索。为了评估这一范式，我们引入了GeoSketch基准，这是一个包含390个需要辅助构造或仿射变换的高质量几何问题的数据集。在强大的MLLM基线上进行的实验表明，GeoSketch在逐步推理准确性和解决问题成功率上显著优于静态感知方法。通过统一层次决策、可执行的视觉操作和符号验证，GeoSketch将多模态推理从静态解释提升到动态、可验证的交互，建立了解决复杂空间问题的新基础。', 'title_zh': 'GeoSketch: 一种辅助线构造与仿射变换介导的几何多模态推理的神经符号方法'}
{'arxiv_id': 'arXiv:2509.22284', 'title': 'Structured Sparse Transition Matrices to Enable State Tracking in State-Space Models', 'authors': 'Aleksandar Terzić, Nicolas Menet, Michael Hersche, Thomas Hofmann, Abbas Rahimi', 'link': 'https://arxiv.org/abs/2509.22284', 'abstract': "Modern state-space models (SSMs) often utilize transition matrices which enable efficient computation but pose restrictions on the model's expressivity, as measured in terms of the ability to emulate finite-state automata (FSA). While unstructured transition matrices are optimal in terms of expressivity, they come at a prohibitively high compute and memory cost even for moderate state sizes. We propose a structured sparse parametrization of transition matrices in SSMs that enables FSA state tracking with optimal state size and depth, while keeping the computational cost of the recurrence comparable to that of diagonal SSMs. Our method, PD-SSM, parametrizes the transition matrix as the product of a column one-hot matrix ($P$) and a complex-valued diagonal matrix ($D$). Consequently, the computational cost of parallel scans scales linearly with the state size. Theoretically, the model is BIBO-stable and can emulate any $N$-state FSA with one layer of dimension $N$ and a linear readout of size $N \\times N$, significantly improving on all current structured SSM guarantees. Experimentally, the model significantly outperforms a wide collection of modern SSM variants on various FSA state tracking tasks. On multiclass time-series classification, the performance is comparable to that of neural controlled differential equations, a paradigm explicitly built for time-series analysis. Finally, we integrate PD-SSM into a hybrid Transformer-SSM architecture and demonstrate that the model can effectively track the states of a complex FSA in which transitions are encoded as a set of variable-length English sentences. The code is available at this https URL", 'abstract_zh': '现代状态空间模型中结构化稀疏转移矩阵参数化以实现高效的有限状态自动机状态跟踪', 'title_zh': '结构化稀疏转移矩阵以启用状态空间模型中的状态跟踪'}
{'arxiv_id': 'arXiv:2509.22242', 'title': 'Clinical Uncertainty Impacts Machine Learning Evaluations', 'authors': 'Simone Lionetti, Fabian Gröger, Philippe Gottfrois, Alvaro Gonzalez-Jimenez, Ludovic Amruthalingam, Alexander A. Navarini, Marc Pouly', 'link': 'https://arxiv.org/abs/2509.22242', 'abstract': "Clinical dataset labels are rarely certain as annotators disagree and confidence is not uniform across cases. Typical aggregation procedures, such as majority voting, obscure this variability. In simple experiments on medical imaging benchmarks, accounting for the confidence in binary labels significantly impacts model rankings. We therefore argue that machine-learning evaluations should explicitly account for annotation uncertainty using probabilistic metrics that directly operate on distributions. These metrics can be applied independently of the annotations' generating process, whether modeled by simple counting, subjective confidence ratings, or probabilistic response models. They are also computationally lightweight, as closed-form expressions have linear-time implementations once examples are sorted by model score. We thus urge the community to release raw annotations for datasets and to adopt uncertainty-aware evaluation so that performance estimates may better reflect clinical data.", 'abstract_zh': '临床数据集标签通常具有不确定性，因为注释者存在分歧且不同案例的置信度不一致。传统的聚合方法，如多数投票，会掩盖这种变异性。在医学影像基准测试中的简单实验表明，考虑二分类标签的置信度显著影响模型排名。因此，我们认为机器学习评估应当明确采用概率性度量方法，直接作用于分布，来反映注释不确定性。这些度量方法可以独立于注释生成过程，无论是通过简单的计数、主观置信评分还是概率响应模型。它们还具有计算效率，一旦根据模型得分对示例进行排序，闭式表达式便具有线性时间实现。因此，我们敦促社区释放原始注释，并采用能反映临床数据性能估计的不确定性意识评估方法。', 'title_zh': '临床不确定性影响机器学习评估'}
{'arxiv_id': 'arXiv:2509.22092', 'title': 'Ground-Truthing AI Energy Consumption: Validating CodeCarbon Against External Measurements', 'authors': 'Raphael Fischer', 'link': 'https://arxiv.org/abs/2509.22092', 'abstract': 'Although machine learning (ML) and artificial intelligence (AI) present fascinating opportunities for innovation, their rapid development is also significantly impacting our environment. In response to growing resource-awareness in the field, quantification tools such as the ML Emissions Calculator and CodeCarbon were developed to estimate the energy consumption and carbon emissions of running AI models. They are easy to incorporate into AI projects, however also make pragmatic assumptions and neglect important factors, raising the question of estimation accuracy. This study systematically evaluates the reliability of static and dynamic energy estimation approaches through comparisons with ground-truth measurements across hundreds of AI experiments. Based on the proposed validation framework, investigative insights into AI energy demand and estimation inaccuracies are provided. While generally following the patterns of AI energy consumption, the established estimation approaches are shown to consistently make errors of up to 40%. By providing empirical evidence on energy estimation quality and errors, this study establishes transparency and validates widely used tools for sustainable AI development. It moreover formulates guidelines for improving the state-of-the-art and offers code for extending the validation to other domains and tools, thus making important contributions to resource-aware ML and AI sustainability research.', 'abstract_zh': '尽管机器学习（ML）和人工智能（AI）为创新带来了令人振奋的机会，其快速发展也在显著影响着我们的环境。鉴于该领域日益增强的资源意识，开发了诸如ML排放计算器和CodeCarbon等量化工具，以估算运行AI模型的能耗和碳排放。尽管这些工具易于集成到AI项目中，但也会做出实用性的假设并忽略重要因素，这引发了对估算准确性的质疑。本研究通过与数百个AI实验的真实测量值进行比较，系统评估了静态和动态能耗估算方法的可靠性，并提供了关于AI能耗需求和估算不准确性的调查见解。尽管一般遵循AI能耗模式，已建立的估算方法仍然显示出高达40%的一致性误差。通过提供关于能耗估算质量和误差的实验证据，本研究提高了透明度并验证了用于可持续AI发展的广泛使用的工具。此外，制定了改进现有技术的指南，并提供了代码以扩展验证至其他领域和工具，从而为资源意识机器学习和AI可持续性研究作出了重要贡献。', 'title_zh': 'AI能耗的真实验证：CodeCarbon与外部测量的验证'}
{'arxiv_id': 'arXiv:2509.22085', 'title': 'Generalizing Multi-Objective Search via Objective-Aggregation Functions', 'authors': 'Hadar Peer, Eyal Weiss, Ron Alterovitz, Oren Salzman', 'link': 'https://arxiv.org/abs/2509.22085', 'abstract': 'Multi-objective search (MOS) has become essential in robotics, as real-world robotic systems need to simultaneously balance multiple, often conflicting objectives. Recent works explore complex interactions between objectives, leading to problem formulations that do not allow the usage of out-of-the-box state-of-the-art MOS algorithms. In this paper, we suggest a generalized problem formulation that optimizes solution objectives via aggregation functions of hidden (search) objectives. We show that our formulation supports the application of standard MOS algorithms, necessitating only to properly extend several core operations to reflect the specific aggregation functions employed. We demonstrate our approach in several diverse robotics planning problems, spanning motion-planning for navigation, manipulation and planning fr medical systems under obstacle uncertainty as well as inspection planning, and route planning with different road types. We solve the problems using state-of-the-art MOS algorithms after properly extending their core operations, and provide empirical evidence that they outperform by orders of magnitude the vanilla versions of the algorithms applied to the same problems but without objective aggregation.', 'abstract_zh': '多目标搜索（MOS）在机器人技术中的应用已经成为必要，因为现实世界的机器人系统需要同时平衡多个常常相互冲突的目标。最近的研究探索了目标间的复杂交互，导致的问题表述不支持使用现成的最先进的MOS算法。在本文中，我们提出了一种通用的问题表述方法，通过隐藏（搜索）目标的聚合函数来优化解决方案目标。我们展示了我们的表述方法支持标准MOS算法的应用，只需适当扩展几个核心操作以反映特定的聚合函数即可。我们通过涵盖导航、操纵以及障碍不确定性下的医疗系统规划等多个领域的机器人规划问题展示了我们的方法，并且通过不同道路类型的路径规划问题进一步验证了我们的方法。我们使用适当扩展核心操作的最先进的MOS算法解决了这些问题，并提供了实验证据，证明与未聚合目标的算法相比，新方法在同类型问题上的性能高出几个数量级。', 'title_zh': '通过目标聚合函数泛化多目标搜索'}
{'arxiv_id': 'arXiv:2509.22044', 'title': 'A2R: An Asymmetric Two-Stage Reasoning Framework for Parallel Reasoning', 'authors': 'Ziqi Wang, Boye Niu, Zhongli Li, Linghui Meng, Jing Liu, Zhi Zheng, Tong Xu, Hua Wu, Haifeng Wang, Enhong Chen', 'link': 'https://arxiv.org/abs/2509.22044', 'abstract': 'Recent Large Reasoning Models have achieved significant improvements in complex task-solving capabilities by allocating more computation at the inference stage with a "thinking longer" paradigm. Even as the foundational reasoning capabilities of models advance rapidly, the persistent gap between a model\'s performance in a single attempt and its latent potential, often revealed only across multiple solution paths, starkly highlights the disparity between its realized and inherent capabilities. To address this, we present A2R, an Asymmetric Two-Stage Reasoning framework designed to explicitly bridge the gap between a model\'s potential and its actual performance. In this framework, an "explorer" model first generates potential solutions in parallel through repeated sampling. Subsequently,a "synthesizer" model integrates these references for a more refined, second stage of reasoning. This two-stage process allows computation to be scaled orthogonally to existing sequential methods. Our work makes two key innovations: First, we present A2R as a plug-and-play parallel reasoning framework that explicitly enhances a model\'s capabilities on complex questions. For example, using our framework, the Qwen3-8B-distill model achieves a 75% performance improvement compared to its self-consistency baseline. Second, through a systematic analysis of the explorer and synthesizer roles, we identify an effective asymmetric scaling paradigm. This insight leads to A2R-Efficient, a "small-to-big" variant that combines a Qwen3-4B explorer with a Qwen3-8B synthesizer. This configuration surpasses the average performance of a monolithic Qwen3-32B model at a nearly 30% lower cost. Collectively, these results show that A2R is not only a performance-boosting framework but also an efficient and practical solution for real-world applications.', 'abstract_zh': 'Recent Large Reasoning Models通过在推理阶段进行更长时间的计算以分配更多计算资源，显著提升了复杂任务解决能力。尽管基础推理能力迅速进步，模型在单次尝试中的性能与其潜在能力之间的持续差距仍然明显，后者通常仅在多种解决方案路径中才显现。为解决这一问题，我们提出A2R，一种非对称两阶段推理框架，旨在明确弥合模型潜在能力与其实际性能之间的差距。在该框架中，“探索者”模型通过重复采样并行生成潜在解决方案，随后，“合成器”模型将这些参考整合为更精细的第二阶段推理。这一两阶段过程允许计算资源与现有顺序方法正交扩展。我们的工作有两个关键创新：首先，我们提出了A2R作为可无缝集成的并行推理框架，可以显式增强模型在复杂问题上的能力。例如，在我们的框架中，Qwen3-8B-distill模型相比其自我一致性基线实现了75%的性能提升。其次，通过系统分析探索者和合成器的角色，我们确定了一种有效的非对称扩展范式。这一洞察导致了A2R-Efficient变种，即使用Qwen3-4B探索者与Qwen3-8B合成器的“小到大”配置，该配置在成本降低近30%的情况下，性能超过了单一的Qwen3-32B模型。综合来看，这些结果表明A2R不仅是一个性能增益框架，也是一个在实际应用中高效且实用的解决方案。', 'title_zh': 'A2R：一种用于并行推理的非对称两阶段推理框架'}
{'arxiv_id': 'arXiv:2509.21982', 'title': 'RISK: A Framework for GUI Agents in E-commerce Risk Management', 'authors': 'Renqi Chen, Zeyin Tao, Jianming Guo, Jingzhe Zhu, Yiheng Peng, Qingqing Sun, Tianyi Zhang, Shuai Chen', 'link': 'https://arxiv.org/abs/2509.21982', 'abstract': 'E-commerce risk management requires aggregating diverse, deeply embedded web data through multi-step, stateful interactions, which traditional scraping methods and most existing Graphical User Interface (GUI) agents cannot handle. These agents are typically limited to single-step tasks and lack the ability to manage dynamic, interactive content critical for effective risk assessment. To address this challenge, we introduce RISK, a novel framework designed to build and deploy GUI agents for this domain. RISK integrates three components: (1) RISK-Data, a dataset of 8,492 single-step and 2,386 multi-step interaction trajectories, collected through a high-fidelity browser framework and a meticulous data curation process; (2) RISK-Bench, a benchmark with 802 single-step and 320 multi-step trajectories across three difficulty levels for standardized evaluation; and (3) RISK-R1, a R1-style reinforcement fine-tuning framework considering four aspects: (i) Output Format: Updated format reward to enhance output syntactic correctness and task comprehension, (ii) Single-step Level: Stepwise accuracy reward to provide granular feedback during early training stages, (iii) Multi-step Level: Process reweight to emphasize critical later steps in interaction sequences, and (iv) Task Level: Level reweight to focus on tasks of varying difficulty. Experiments show that RISK-R1 outperforms existing baselines, achieving a 6.8% improvement in offline single-step and an 8.8% improvement in offline multi-step. Moreover, it attains a top task success rate of 70.5% in online evaluation. RISK provides a scalable, domain-specific solution for automating complex web interactions, advancing the state of the art in e-commerce risk management.', 'abstract_zh': '电子商务风险管理需要通过多步、有状态的交互聚合多元且深度嵌入的网络数据，传统抓取方法和现有的大多数图形用户界面（GUI）代理无法处理。这些代理通常局限于单步任务，缺乏管理对有效风险评估至关重要的动态交互内容的能力。为解决这一挑战，我们提出了一种名为RISK的新型框架，用于构建和部署此类领域的GUI代理。RISK集成了三个组件：（1）RISK-Data，一个包含8,492条单步和2,386条多步交互轨迹的数据集，通过高保真浏览器框架和细致的数据整理过程收集；（2）RISK-Bench，一个基准测试集，包含320条多步和802条单步交互轨迹，分为三个难度级别，用于标准化评估；以及（3）RISK-R1，一种考虑四大方面的R1风格强化微调框架：输出格式、单步级别、多步级别和任务级别。实验表明，RISK-R1在单步和多步交互方面均优于现有基线，分别提高了6.8%和8.8%。此外，在线评估中其任务成功率高达70.5%。RISK提供了一种针对Web复杂交互的大规模领域特定自动化解决方案，推动了电子商务风险管理领域的进步。', 'title_zh': 'GUI代理在电子商务风险管理的框架：RISK'}
{'arxiv_id': 'arXiv:2509.21943', 'title': 'Outlier Detection in Plantar Pressure: Human-Centered Comparison of Statistical Parametric Mapping and Explainable Machine Learning', 'authors': 'Carlo Dindorf, Jonas Dully, Steven Simon, Dennis Perchthaler, Stephan Becker, Hannah Ehmann, Kjell Heitmann, Bernd Stetter, Christian Diers, Michael Fröhlich', 'link': 'https://arxiv.org/abs/2509.21943', 'abstract': 'Plantar pressure mapping is essential in clinical diagnostics and sports science, yet large heterogeneous datasets often contain outliers from technical errors or procedural inconsistencies. Statistical Parametric Mapping (SPM) provides interpretable analyses but is sensitive to alignment and its capacity for robust outlier detection remains unclear. This study compares an SPM approach with an explainable machine learning (ML) approach to establish transparent quality-control pipelines for plantar pressure datasets. Data from multiple centers were annotated by expert consensus and enriched with synthetic anomalies resulting in 798 valid samples and 2000 outliers. We evaluated (i) a non-parametric, registration-dependent SPM approach and (ii) a convolutional neural network (CNN), explained using SHapley Additive exPlanations (SHAP). Performance was assessed via nested cross-validation; explanation quality via a semantic differential survey with domain experts. The ML model reached high accuracy and outperformed SPM, which misclassified clinically meaningful variations and missed true outliers. Experts perceived both SPM and SHAP explanations as clear, useful, and trustworthy, though SPM was assessed less complex. These findings highlight the complementary potential of SPM and explainable ML as approaches for automated outlier detection in plantar pressure data, and underscore the importance of explainability in translating complex model outputs into interpretable insights that can effectively inform decision-making.', 'abstract_zh': '基于解释性机器学习方法的足底压力数据质量控制管道研究：SPM与可解释ML在自动检测异常值中的互补潜力', 'title_zh': '足底压力异常检测：统计参数映射与可解释机器学习的人本比较'}
{'arxiv_id': 'arXiv:2509.21902', 'title': 'DyRo-MCTS: A Robust Monte Carlo Tree Search Approach to Dynamic Job Shop Scheduling', 'authors': 'Ruiqi Chen, Yi Mei, Fangfang Zhang, Mengjie Zhang', 'link': 'https://arxiv.org/abs/2509.21902', 'abstract': 'Dynamic job shop scheduling, a fundamental combinatorial optimisation problem in various industrial sectors, poses substantial challenges for effective scheduling due to frequent disruptions caused by the arrival of new jobs. State-of-the-art methods employ machine learning to learn scheduling policies offline, enabling rapid responses to dynamic events. However, these offline policies are often imperfect, necessitating the use of planning techniques such as Monte Carlo Tree Search (MCTS) to improve performance at online decision time. The unpredictability of new job arrivals complicates online planning, as decisions based on incomplete problem information are vulnerable to disturbances. To address this issue, we propose the Dynamic Robust MCTS (DyRo-MCTS) approach, which integrates action robustness estimation into MCTS. DyRo-MCTS guides the production environment toward states that not only yield good scheduling outcomes but are also easily adaptable to future job arrivals. Extensive experiments show that DyRo-MCTS significantly improves the performance of offline-learned policies with negligible additional online planning time. Moreover, DyRo-MCTS consistently outperforms vanilla MCTS across various scheduling scenarios. Further analysis reveals that its ability to make robust scheduling decisions leads to long-term, sustainable performance gains under disturbances.', 'abstract_zh': '动态车间调度：一种因新任务的频繁 arrival 而在各类工业部门中提出的根本性组合优化问题，由于缺乏有效的调度策略而带来了显著挑战。最先进的方法利用机器学习在离线阶段学习调度策略，从而能够快速应对动态事件。然而，这些离线策略往往不够完善，需要结合如蒙特卡洛树搜索（MCTS）等规划技术，在线决策时提高性能。新任务 arrival 的不可预测性增加了在线规划的复杂性，基于不完整信息的决策容易受到干扰的影响。为解决这一问题，我们提出了一种动态鲁棒 MCTS（DyRo-MCTS）方法，将动作鲁棒性估计整合到 MCTS 中。DyRo-MCTS 引导生产环境朝着既能产生良好调度结果又能容易适应未来任务 arrival 的状态发展。大量实验表明，DyRo-MCTS 显著提高了离线学习策略的性能，且几乎不增加在线规划时间。此外，DyRo-MCTS 在各种调度场景中均优于基本 MCTS。进一步的分析表明，它能够做出鲁棒调度决策的能力，使其能够在干扰下获得长期且可持续的性能提升。', 'title_zh': 'DyRo-MCTS：一种用于动态车间调度的稳健蒙特卡洛树搜索方法'}
{'arxiv_id': 'arXiv:2509.21896', 'title': 'GenesisGeo: Technical Report', 'authors': 'Minfeng Zhu, Zi Wang, Sizhe Ji, Zhengtong Du, Junming Ke, Xiao Deng, Zanlang Yin, Xiuqi Huang, Heyu Wang, Wei Chen', 'link': 'https://arxiv.org/abs/2509.21896', 'abstract': 'We present GenesisGeo, an automated theorem prover in Euclidean geometry. We have open-sourced a large-scale geometry dataset of 21.8 million geometric problems, over 3 million of which contain auxiliary constructions. Specially, we significantly accelerate the symbolic deduction engine DDARN by 120x through theorem matching, combined with a C++ implementation of its core components. Furthermore, we build our neuro-symbolic prover, GenesisGeo, upon Qwen3-0.6B-Base, which solves 24 of 30 problems (IMO silver medal level) in the IMO-AG-30 benchmark using a single model, and achieves 26 problems (IMO gold medal level) with a dual-model ensemble.', 'abstract_zh': '我们提出了GenesisGeo，一个欧几里得几何自动定理证明器。我们开源了一个大规模几何数据集，包含2180万几何问题，其中超过300万包含辅助构造。特别地，我们通过定理匹配将符号推理引擎DDARN的速度提高120倍，并结合了其核心组件的C++实现。此外，我们基于Qwen3-0.6B-Base构建了神经-符号证明器GenesisGeo，该证明器使用单模型解决了IMO-AG-30基准中的24个问题（IMO银牌水平），并使用双模型集成解决了26个问题（IMO金牌水平）。', 'title_zh': 'GenesisGeo: 技术报告'}
{'arxiv_id': 'arXiv:2509.21886', 'title': 'TRACE: Learning to Compute on Graphs', 'authors': 'Ziyang Zheng, Jiaying Zhu, Jingyi Zhou, Qiang Xu', 'link': 'https://arxiv.org/abs/2509.21886', 'abstract': 'Learning to compute, the ability to model the functional behavior of a computational graph, is a fundamental challenge for graph representation learning. Yet, the dominant paradigm is architecturally mismatched for this task. This flawed assumption, central to mainstream message passing neural networks (MPNNs) and their conventional Transformer-based counterparts, prevents models from capturing the position-aware, hierarchical nature of computation. To resolve this, we introduce \\textbf{TRACE}, a new paradigm built on an architecturally sound backbone and a principled learning objective. First, TRACE employs a Hierarchical Transformer that mirrors the step-by-step flow of computation, providing a faithful architectural backbone that replaces the flawed permutation-invariant aggregation. Second, we introduce \\textbf{function shift learning}, a novel objective that decouples the learning problem. Instead of predicting the complex global function directly, our model is trained to predict only the \\textit{function shift}, the discrepancy between the true global function and a simple local approximation that assumes input independence. We validate this paradigm on electronic circuits, one of the most complex and economically critical classes of computational graphs. Across a comprehensive suite of benchmarks, TRACE substantially outperforms all prior architectures. These results demonstrate that our architecturally-aligned backbone and decoupled learning objective form a more robust paradigm for the fundamental challenge of learning to compute on graphs.', 'abstract_zh': '学习计算的能力，即建模计算图的功能行为，是图表示学习中一个基本的挑战。然而，主导的范式在架构上与这一任务不匹配。这一根本性的假设，是主流消息传递神经网络（MPNNs）及其传统的基于Transformer的变体的核心，阻碍了模型捕捉计算中位置感知和层次化的本质。为了解决这一问题，我们提出了一个名为TRACE的新范式，该范式基于一个架构合理的骨干和一个有原则的学习目标。首先，TRACE使用了一个级联Transformer，该模型模仿了计算的逐步流程，提供了一个忠实的架构基础，用以替代错误的置换不变聚合。其次，我们引入了功能偏移学习这一新颖的目标，将学习问题解耦。我们的模型不是直接预测复杂的全局函数，而是仅预测真全局函数与假设输入独立的简单局部近似的差异，即功能偏移。我们已在电子电路这一最复杂和经济上至关重要的计算图类别上验证了这一范式。在一系列全面的基准测试中，TRACE显著优于所有先前的架构。这些结果表明，我们的架构对齐的骨干和解耦的学习目标构成了一个更为稳健的范式，用于解决在图上学习计算这一基本挑战。', 'title_zh': 'TRACE: 学习在图上进行计算'}
{'arxiv_id': 'arXiv:2509.21836', 'title': 'Axiomatic Choice and the Decision-Evaluation Paradox', 'authors': 'Ben Abramowitz, Nicholas Mattei', 'link': 'https://arxiv.org/abs/2509.21836', 'abstract': 'We introduce a framework for modeling decisions with axioms that are statements about decisions, e.g., ethical constraints. Using our framework we define a taxonomy of decision axioms based on their structural properties and demonstrate a tension between the use of axioms to make decisions and the use of axioms to evaluate decisions which we call the Decision-Evaluation Paradox. We argue that the Decision-Evaluation Paradox arises with realistic axiom structures, and the paradox illuminates why one must be exceptionally careful when training models on decision data or applying axioms to make and evaluate decisions.', 'abstract_zh': '我们介绍了一个框架，用于使用关于决策的公理来建模决策，例如道德约束。使用该框架，我们基于公理的结构性质定义了决策公理的分类，并展示了使用公理进行决策和使用公理评估决策之间的紧张关系，称之为决策-评估悖论。我们认为决策-评估悖论存在于现实的公理结构中，并且悖论阐明了在使用决策数据训练模型或将公理应用于决策及其评估时必须极其谨慎的原因。', 'title_zh': '公理化选择与决策-评估悖论'}
{'arxiv_id': 'arXiv:2509.21825', 'title': 'DS-STAR: Data Science Agent via Iterative Planning and Verification', 'authors': 'Jaehyun Nam, Jinsung Yoon, Jiefeng Chen, Jinwoo Shin, Tomas Pfister', 'link': 'https://arxiv.org/abs/2509.21825', 'abstract': "Data science, which transforms raw data into actionable insights, is critical for data-driven decision-making. However, these tasks are often complex, involving steps for exploring multiple data sources and synthesizing findings to deliver insightful answers. While large language models (LLMs) show significant promise in automating this process, they often struggle with heterogeneous data formats and generate sub-optimal analysis plans, as verifying plan sufficiency is inherently difficult without ground-truth labels for such open-ended tasks. To overcome these limitations, we introduce DS-STAR, a novel data science agent. Specifically, DS-STAR makes three key contributions: (1) a data file analysis module that automatically explores and extracts context from diverse data formats, including unstructured types; (2) a verification step where an LLM-based judge evaluates the sufficiency of the analysis plan at each stage; and (3) a sequential planning mechanism that starts with a simple, executable plan and iteratively refines it based on the DS-STAR's feedback until its sufficiency is verified. This iterative refinement allows DS-STAR to reliably navigate complex analyses involving diverse data sources. Our experiments show that DS-STAR achieves state-of-the-art performance across three challenging benchmarks: DABStep, KramaBench, and DA-Code. Moreover, DS-STAR particularly outperforms baselines on hard tasks that require processing multiple data files with heterogeneous formats.", 'abstract_zh': '数据科学，即通过将原始数据转换为可操作的洞察，对于基于数据的决策至关重要。然而，这些任务往往非常复杂，涉及探索多个数据源并综合发现以提供有洞察力的答案。虽然大型语言模型（LLMs）在自动化这一过程方面显示出巨大的潜力，但它们通常难以处理异构数据格式，并生成次优化的分析计划，因为验证计划的充分性在没有此类开放任务的真实标签的情况下是固有的困难。为克服这些限制，我们引入了DS-STAR，这是一种新颖的数据科学代理。具体而言，DS-STAR 作出三大贡献：（1）数据文件分析模块，能够自动探索和从各种数据格式（包括非结构化格式）中提取背景信息；（2）验证步骤，其中基于LLM的裁判员评估每个阶段分析计划的充分性；以及（3）一种顺序规划机制，从一个简单可执行的计划开始，并根据DS-STAR的反馈逐步优化该计划，直到其充分性被验证。这种逐步优化使得DS-STAR能够在涉及多种数据源的复杂分析中可靠导航。我们的实验表明，DS-STAR在三个具有挑战性的基准测试：DABStep、KramaBench和DA-Code中取得了最先进的性能。此外，DS-STAR特别在需要处理具有异构格式的多个数据文件的困难任务中超过了基线。', 'title_zh': 'DS-STAR: 数据科学代理通过迭代规划与验证'}
{'arxiv_id': 'arXiv:2509.21766', 'title': 'UltraHorizon: Benchmarking Agent Capabilities in Ultra Long-Horizon Scenarios', 'authors': 'Haotian Luo, Huaisong Zhang, Xuelin Zhang, Haoyu Wang, Zeyu Qin, Wenjie Lu, Guozheng Ma, Haiying He, Yingsha Xie, Qiyang Zhou, Zixuan Hu, Hongze Mi, Yibo Wang, Naiqiang Tan, Hong Chen, Yi R. Fung, Chun Yuan, Li Shen', 'link': 'https://arxiv.org/abs/2509.21766', 'abstract': "Autonomous agents have recently achieved remarkable progress across diverse domains, yet most evaluations focus on short-horizon, fully observable tasks. In contrast, many critical real-world tasks, such as large-scale software development, commercial investment, and scientific discovery, unfold in long-horizon and partially observable scenarios where success hinges on sustained reasoning, planning, memory management, and tool use. Existing benchmarks rarely capture these long-horizon challenges, leaving a gap in systematic evaluation. To bridge this gap, we introduce \\textbf{UltraHorizon} a novel benchmark that measures the foundational capabilities essential for complex real-world challenges. We use exploration as a unifying task across three distinct environments to validate these core competencies. Agents are designed in long-horizon discovery tasks where they must iteratively uncover hidden rules through sustained reasoning, planning, memory and tools management, and interaction with environments. Under the heaviest scale setting, trajectories average \\textbf{200k+} tokens and \\textbf{400+} tool calls, whereas in standard configurations they still exceed \\textbf{35k} tokens and involve more than \\textbf{60} tool calls on average. Our extensive experiments reveal that LLM-agents consistently underperform in these settings, whereas human participants achieve higher scores, underscoring a persistent gap in agents' long-horizon abilities. We also observe that simple scaling fails in our task. To better illustrate the failure of agents, we conduct an in-depth analysis of collected trajectories. We identify eight types of errors and attribute them to two primary causes: in-context locking and functional fundamental capability gaps. \\href{this https URL}{Our code will be available here.}", 'abstract_zh': '自主代理在多元领域取得了显著进展，但大多数评估主要集中在短时间内的完全可观测任务上。相比之下，许多关键的现实世界任务，如大规模软件开发、商业投资和科学发现，发生在长时间跨度和部分可观测的场景中，成功取决于持续的推理、规划、记忆管理和工具使用。现有的基准测试很少捕捉到这些长时间跨度的挑战，留下了系统评估的缺口。为了弥补这一缺口，我们引入了**UltraHorizon**这一新型基准测试，用于衡量对于复杂现实挑战必不可少的基础能力。我们利用探索作为统一任务，在三个不同的环境中验证这些核心能力。代理在长时间跨度的发现任务中设计，需要通过持续的推理、规划、记忆和工具管理以及与环境的互动，逐步揭露隐藏的规则。在最极端的规模设置下，轨迹平均包含超过**200k**个令牌和**400**多次工具调用，而在标准配置下，仍然超过**35k**个令牌，并且平均涉及超过**60**次工具调用。我们的大量实验表明，在这些设置中，LLM-代理表现一致不佳，而人类参与者则取得更高分数，突显了代理在长时间跨度能力上的持续差距。我们也观察到简单的扩展在此任务中不起作用。为了更好地说明代理的失败，我们对收集的轨迹进行了深入分析。我们识别出八种类型错误，并将其归因于两大主要原因：上下文锁定和功能基本能力差距。', 'title_zh': 'UltraHorizon：评估代理在超长时距场景能力的基准测试'}
{'arxiv_id': 'arXiv:2509.21765', 'title': 'Lifelong Learning with Behavior Consolidation for Vehicle Routing', 'authors': 'Jiyuan Pei, Yi Mei, Jialin Liu, Mengjie Zhang, Xin Yao', 'link': 'https://arxiv.org/abs/2509.21765', 'abstract': "Recent neural solvers have demonstrated promising performance in learning to solve routing problems. However, existing studies are primarily based on one-off training on one or a set of predefined problem distributions and scales, i.e., tasks. When a new task arises, they typically rely on either zero-shot generalization, which may be poor due to the discrepancies between the new task and the training task(s), or fine-tuning the pretrained solver on the new task, which possibly leads to catastrophic forgetting of knowledge acquired from previous tasks. This paper explores a novel lifelong learning paradigm for neural VRP solvers, where multiple tasks with diverse distributions and scales arise sequentially over time. Solvers are required to effectively and efficiently learn to solve new tasks while maintaining their performance on previously learned tasks. Consequently, a novel framework called Lifelong Learning Router with Behavior Consolidation (LLR-BC) is proposed. LLR-BC consolidates prior knowledge effectively by aligning behaviors of the solver trained on a new task with the buffered ones in a decision-seeking way. To encourage more focus on crucial experiences, LLR-BC assigns greater consolidated weights to decisions with lower confidence. Extensive experiments on capacitated vehicle routing problems and traveling salesman problems demonstrate LLR-BC's effectiveness in training high-performance neural solvers in a lifelong learning setting, addressing the catastrophic forgetting issue, maintaining their plasticity, and improving zero-shot generalization ability.", 'abstract_zh': '最近的神经网络求解器在学习解决路由问题方面展现了有前景的性能。然而，现有研究主要基于单一训练或一组预定义的问题分布和规模进行训练。当出现新的任务时，它们通常依赖于零样本泛化或对预训练解算器进行微调，这可能导致对之前任务所学知识的灾难性遗忘。本文探索了一种新颖的终身学习范式，适用于神经VRP解算器，多种具有多样分布和规模的任务将随时间顺序出现。解算器需要在有效高效地学习解决新任务的同时保持对之前学习任务的性能。因此，提出了一种名为Lifelong Learning Router with Behavior Consolidation (LLR-BC)的新框架。LLR-BC通过决策导向的方式，有效整合新任务训练解算器的行为与缓存的行为。为了更关注关键经验，LLR-BC对低置信度的决策赋予更大的整合权重。在车载路由问题和旅行商问题上的广泛实验表明，LLR-BC能够在终身学习设置中训练高性能的神经解算器，解决了灾难性遗忘问题，保持其可塑性，并提高零样本泛化能力。', 'title_zh': '基于行为巩固的终身学习车辆路径规划'}
{'arxiv_id': 'arXiv:2509.21718', 'title': 'Align2Speak: Improving TTS for Low Resource Languages via ASR-Guided Online Preference Optimization', 'authors': 'Shehzeen Hussain, Paarth Neekhara, Xuesong Yang, Edresson Casanova, Subhankar Ghosh, Roy Fejgin, Ryan Langman, Mikyas Desta, Leili Tavabi, Jason Li', 'link': 'https://arxiv.org/abs/2509.21718', 'abstract': "Developing high-quality text-to-speech (TTS) systems for low-resource languages is challenging due to the scarcity of paired text and speech data. In contrast, automatic speech recognition (ASR) models for such languages are often more accessible, owing to large-scale multilingual pre-training efforts. We propose a framework based on Group Relative Policy Optimization (GRPO) to adapt an autoregressive, multilingual TTS model to new languages. Our method first establishes a language-agnostic foundation for TTS synthesis by training a multilingual baseline with International Phonetic Alphabet (IPA) tokens. Next, we fine-tune this model on limited paired data of the new languages to capture the target language's prosodic features. Finally, we apply GRPO to optimize the model using only unpaired text and speaker prompts, guided by a multi-objective reward from pretrained ASR, speaker verification, and audio quality estimation models. Experiments demonstrate that this pipeline produces intelligible and speaker-consistent speech in low-resource languages, substantially outperforming fine-tuning alone. Furthermore, our GRPO-based framework also improves TTS performance in high-resource languages, surpassing offline alignment methods such as Direct Preference Optimization (DPO) yielding superior intelligibility, speaker similarity, and audio quality.", 'abstract_zh': '开发低资源语言的高质量文本到语音(TTS)系统具有挑战性，因为配对的文本和语音数据稀缺。相比之下，这些语言的自动语音识别(ASR)模型由于大规模多语言预训练努力通常更具 accesibility。我们提出了一种基于Group Relative Policy Optimization (GRPO)的框架，以适应新的语言的自回归、多语言TTS模型。该方法首先通过使用国际音标(IPA)标记训练多语言基线来建立一个语言无关的基础，以进行TTS合成功能。接着，该模型在新语言的有限配对数据上进行微调，以捕捉目标语言的音韵特征。最后，我们利用GRPO仅使用未配对的文本和讲话者提示来优化模型，该优化由预训练的ASR、说话人验证和音频质量估计模型提供多目标奖励指导。实验表明，该流水线在低资源语言中产生了可理解且说话者一致的语音，并显著优于仅进行微调的方法。此外，基于GRPO的框架还改善了高资源语言的TTS性能，超过离线对齐方法如Direct Preference Optimization (DPO)，在可理解性、说话者相似性和音频质量方面表现更优。', 'title_zh': 'Align2Speak：通过ASR引导的在线偏好优化提高低资源语言的TTS'}
{'arxiv_id': 'arXiv:2509.21633', 'title': 'Semantic F1 Scores: Fair Evaluation Under Fuzzy Class Boundaries', 'authors': 'Georgios Chochlakis, Jackson Trager, Vedant Jhaveri, Nikhil Ravichandran, Alexandros Potamianos, Shrikanth Narayanan', 'link': 'https://arxiv.org/abs/2509.21633', 'abstract': 'We propose Semantic F1 Scores, novel evaluation metrics for subjective or fuzzy multi-label classification that quantify semantic relatedness between predicted and gold labels. Unlike the conventional F1 metrics that treat semantically related predictions as complete failures, Semantic F1 incorporates a label similarity matrix to compute soft precision-like and recall-like scores, from which the Semantic F1 scores are derived. Unlike existing similarity-based metrics, our novel two-step precision-recall formulation enables the comparison of label sets of arbitrary sizes without discarding labels or forcing matches between dissimilar labels. By granting partial credit for semantically related but nonidentical labels, Semantic F1 better reflects the realities of domains marked by human disagreement or fuzzy category boundaries. In this way, it provides fairer evaluations: it recognizes that categories overlap, that annotators disagree, and that downstream decisions based on similar predictions lead to similar outcomes. Through theoretical justification and extensive empirical validation on synthetic and real data, we show that Semantic F1 demonstrates greater interpretability and ecological validity. Because it requires only a domain-appropriate similarity matrix, which is robust to misspecification, and not a rigid ontology, it is applicable across tasks and modalities.', 'abstract_zh': '我们提出语义F1分数：一种新型的主观或模糊多标签分类评估指标，用于量化预测标签与黄金标签之间的语义相关性', 'title_zh': '语义F1分数：在模糊类别边界下的公平评价'}
{'arxiv_id': 'arXiv:2509.21600', 'title': 'Automated and Interpretable Survival Analysis from Multimodal Data', 'authors': 'Mafalda Malafaia, Peter A.N. Bosman, Coen Rasch, Tanja Alderliesten', 'link': 'https://arxiv.org/abs/2509.21600', 'abstract': 'Accurate and interpretable survival analysis remains a core challenge in oncology. With growing multimodal data and the clinical need for transparent models to support validation and trust, this challenge increases in complexity. We propose an interpretable multimodal AI framework to automate survival analysis by integrating clinical variables and computed tomography imaging. Our MultiFIX-based framework uses deep learning to infer survival-relevant features that are further explained: imaging features are interpreted via Grad-CAM, while clinical variables are modeled as symbolic expressions through genetic programming. Risk estimation employs a transparent Cox regression, enabling stratification into groups with distinct survival outcomes. Using the open-source RADCURE dataset for head and neck cancer, MultiFIX achieves a C-index of 0.838 (prediction) and 0.826 (stratification), outperforming the clinical and academic baseline approaches and aligning with known prognostic markers. These results highlight the promise of interpretable multimodal AI for precision oncology with MultiFIX.', 'abstract_zh': '准确可解释的生存分析仍是肿瘤学中的核心挑战。随着多模态数据的增长和临床对透明模型的需求以支持验证和信任，这一挑战变得更加复杂。我们提出了一种可解释的多模态AI框架，通过结合临床变量和计算机断层扫描成像来自动化生存分析。基于MultiFIX的框架利用深度学习推断与生存相关的特征，进一步通过Grad-CAM解释成像特征，并通过遗传编程将临床变量建模为符号表达式。风险估计采用透明的Cox回归，实现了具有不同生存结局的组别划分。使用开源RADCURE头颈癌数据集，MultiFIX在预测中的C指数为0.838，在分层中的C指数为0.826，优于临床和学术基准方法，并与已知的预后标志物一致。这些结果突显了MultiFIX在精确肿瘤学中的可解释多模态AI的潜力。', 'title_zh': '多模态数据的自动可解释生存分析'}
{'arxiv_id': 'arXiv:2509.21567', 'title': 'EEG-Based Consumer Behaviour Prediction: An Exploration from Classical Machine Learning to Graph Neural Networks', 'authors': 'Mohammad Parsa Afshar, Aryan Azimi', 'link': 'https://arxiv.org/abs/2509.21567', 'abstract': "Prediction of consumer behavior is one of the important purposes in marketing, cognitive neuroscience, and human-computer interaction. The electroencephalography (EEG) data can help analyze the decision process by providing detailed information about the brain's neural activity. In this research, a comparative approach is utilized for predicting consumer behavior by EEG data. In the first step, the features of the EEG data from the NeuMa dataset were extracted and cleaned. For the Graph Neural Network (GNN) models, the brain connectivity features were created. Different machine learning models, such as classical models and Graph Neural Networks, are used and compared. The GNN models with different architectures are implemented to have a comprehensive comparison; furthermore, a wide range of classical models, such as ensemble models, are applied, which can be very helpful to show the difference and performance of each model on the dataset. Although the results did not show a significant difference overall, the GNN models generally performed better in some basic criteria where classical models were not satisfactory. This study not only shows that combining EEG signal analysis and machine learning models can provide an approach to deeper understanding of consumer behavior, but also provides a comprehensive comparison between the machine learning models that have been widely used in previous studies in the EEG-based neuromarketing such as Support Vector Machine (SVM), and the models which are not used or rarely used in the field, like Graph Neural Networks.", 'abstract_zh': '利用脑电图数据预测消费者行为的图神经网络方法比较研究', 'title_zh': '基于EEG的消费者行为预测：从经典机器学习到图神经网络的研究'}
{'arxiv_id': 'arXiv:2509.21553', 'title': 'AutoClimDS: Climate Data Science Agentic AI -- A Knowledge Graph is All You Need', 'authors': 'Ahmed Jaber, Wangshu Zhu, Karthick Jayavelu, Justin Downes, Sameer Mohamed, Candace Agonafir, Linnia Hawkins, Tian Zheng', 'link': 'https://arxiv.org/abs/2509.21553', 'abstract': 'Climate data science faces persistent barriers stemming from the fragmented nature of data sources, heterogeneous formats, and the steep technical expertise required to identify, acquire, and process datasets. These challenges limit participation, slow discovery, and reduce the reproducibility of scientific workflows. In this paper, we present a proof of concept for addressing these barriers through the integration of a curated knowledge graph (KG) with AI agents designed for cloud-native scientific workflows. The KG provides a unifying layer that organizes datasets, tools, and workflows, while AI agents -- powered by generative AI services -- enable natural language interaction, automated data access, and streamlined analysis. Together, these components drastically lower the technical threshold for engaging in climate data science, enabling non-specialist users to identify and analyze relevant datasets. By leveraging existing cloud-ready API data portals, we demonstrate that "a knowledge graph is all you need" to unlock scalable and agentic workflows for scientific inquiry. The open-source design of our system further supports community contributions, ensuring that the KG and associated tools can evolve as a shared commons. Our results illustrate a pathway toward democratizing access to climate data and establishing a reproducible, extensible framework for human--AI collaboration in scientific research.', 'abstract_zh': '气候变化数据科学面临的持久障碍源于数据源的碎片化、异构格式以及识别、获取和处理数据集所需的 steep 技术门槛。这些挑战限制了参与度、减缓了发现过程，并降低了科学工作流的可再现性。本文提出了一种概念验证方法，通过将精标知识图谱（KG）与为云原生科学工作流设计的 AI 代理集成来应对这些障碍。知识图谱提供了一个统一的层，组织数据集、工具和工作流，而由生成式 AI 服务驱动的 AI 代理则支持自然语言交互、自动化数据访问和 streamlined 分析。这些组件共同大幅降低了参与气候变化数据科学的技术门槛，使非专家用户能够识别和分析相关数据集。通过利用现有的云就绪 API 数据门户，我们证明“一个知识图谱就足够了”来解锁可扩展且自主的工作流以支持科学探索。我们的开源系统设计进一步支持了社区贡献，确保知识图谱及相关工具能够作为共享公共资源进行演化。我们的结果表明了一条途径，即通过将知识图谱应用于气候变化数据来实现数据访问的民主化，并建立了人机在科学研究中协作的可再现且可扩展框架。', 'title_zh': 'AutoClimDS：气候数据科学自治AI——只需一个知识图谱'}
{'arxiv_id': 'arXiv:2509.21344', 'title': 'Towards mitigating information leakage when evaluating safety monitors', 'authors': 'Gerard Boxo, Aman Neelappa, Shivam Raval', 'link': 'https://arxiv.org/abs/2509.21344', 'abstract': "White box monitors that analyze model internals offer promising advantages for detecting potentially harmful behaviors in large language models, including lower computational costs and integration into layered defense this http URL, training and evaluating these monitors requires response exemplars that exhibit the target behaviors, typically elicited through prompting or fine-tuning. This presents a challenge when the information used to elicit behaviors inevitably leaks into the data that monitors ingest, inflating their effectiveness. We present a systematic framework for evaluating a monitor's performance in terms of its ability to detect genuine model behavior rather than superficial elicitation artifacts. Furthermore, we propose three novel strategies to evaluate the monitor: content filtering (removing deception-related text from inputs), score filtering (aggregating only over task-relevant tokens), and prompt distilled fine-tuned model organisms (models trained to exhibit deceptive behavior without explicit prompting). Using deception detection as a representative case study, we identify two forms of leakage that inflate monitor performance: elicitation leakage from prompts that explicitly request harmful behavior, and reasoning leakage from models that verbalize their deceptive actions. Through experiments on multiple deception benchmarks, we apply our proposed mitigation strategies and measure performance retention. Our evaluation of the monitors reveal three crucial findings: (1) Content filtering is a good mitigation strategy that allows for a smooth removal of elicitation signal and can decrease probe AUROC by 30\\% (2) Score filtering was found to reduce AUROC by 15\\% but is not as straightforward to attribute to (3) A finetuned model organism improves monitor evaluations but reduces their performance by upto 40\\%, even when re-trained.", 'abstract_zh': '白盒监控器分析模型内部对我们检测大型语言模型中潜在有害行为提供了潜在优势，包括较低的计算成本和多层次防御的集成。这类监控器的训练和评估需要展示目标行为的响应示例，通常通过提示或微调获得。当用以触发行为的信息不可避免地泄露到监控器所摄入的数据中时，这会夸大其效果。我们提出了一种系统框架，用于评估监控器检测真正模型行为而非表面提示伪影的能力。此外，我们提出了三种新的评估策略：内容过滤（从输入中去除与欺骗相关的文本）、得分过滤（仅聚合与任务相关的标记）以及提示精炼微调模型有机体（训练模型以表现出欺骗行为而无需明确提示）。通过在多个欺骗检测基准上进行实验，我们应用了我们的缓解策略并测量了性能保留。通过对监控器的评估，我们发现了三个关键发现：(1) 内容过滤是一种有效的缓解策略，可以平滑去除引述信号，降低了探针AUROC约30%；(2) 得分过滤降低了AUROC约15%，但其归因性较弱；(3) 微调模型有机体提高了监控器评估，但甚至在重新训练后也使其性能最多下降40%。', 'title_zh': '减轻评估安全性监视器时的信息泄露'}
{'arxiv_id': 'arXiv:2509.22651', 'title': 'VoiceAssistant-Eval: Benchmarking AI Assistants across Listening, Speaking, and Viewing', 'authors': 'Ke Wang, Houxing Ren, Zimu Lu, Mingjie Zhan, Hongsheng Li', 'link': 'https://arxiv.org/abs/2509.22651', 'abstract': "The growing capabilities of large language models and multimodal systems have spurred interest in voice-first AI assistants, yet existing benchmarks are inadequate for evaluating the full range of these systems' capabilities. We introduce VoiceAssistant-Eval, a comprehensive benchmark designed to assess AI assistants across listening, speaking, and viewing. VoiceAssistant-Eval comprises 10,497 curated examples spanning 13 task categories. These tasks include natural sounds, music, and spoken dialogue for listening; multi-turn dialogue, role-play imitation, and various scenarios for speaking; and highly heterogeneous images for viewing. To demonstrate its utility, we evaluate 21 open-source models and GPT-4o-Audio, measuring the quality of the response content and speech, as well as their consistency. The results reveal three key findings: (1) proprietary models do not universally outperform open-source models; (2) most models excel at speaking tasks but lag in audio understanding; and (3) well-designed smaller models can rival much larger ones. Notably, the mid-sized Step-Audio-2-mini (7B) achieves more than double the listening accuracy of LLaMA-Omni2-32B-Bilingual. However, challenges remain: multimodal (audio plus visual) input and role-play voice imitation tasks are difficult for current models, and significant gaps persist in robustness and safety alignment. VoiceAssistant-Eval identifies these gaps and establishes a rigorous framework for evaluating and guiding the development of next-generation AI assistants. Code and data will be released at this https URL .", 'abstract_zh': '大型语言模型和多模态系统的不断增强能力促使了对语音优先AI助手的兴趣，但现有基准无法评估这些系统能力的全部范围。我们引入了VoiceAssistant-Eval，一个全面的基准，旨在评估AI助手在听、说和看各方面的能力。VoiceAssistant-Eval包含10,497个精选示例，覆盖13个任务类别。这些任务包括听觉的自然声音、音乐和对话；口语的多轮对话、角色扮演模仿及各种场景；以及高度异构的图像。为了展示其实用性，我们评估了21个开源模型和GPT-4o-Audio，测量响应内容和语音的质量以及它们的一致性。结果显示了三个关键发现：（1）专有模型并不普遍优于开源模型；（2）大多数模型在口语任务中表现出色但在音频理解方面落后；（3）设计良好的小型模型可以与大型模型匹敌。值得注意的是，中型规模的Step-Audio-2-mini（7B）在听觉准确性上超过LLaMA-Omni2-32B-Bilingual超过一倍。然而，仍存在挑战：多模态（音频加视觉）输入和角色扮演语音模仿任务对于当前模型来说是难题，同时在稳健性和安全性对齐方面仍存在显著差距。VoiceAssistant-Eval指出了这些差距，并为评估和指导下一代AI助手的发展建立了严格的框架。代码和数据将在此处发布。', 'title_zh': 'VoiceAssistant-Eval：跨听、说、看评估AI助手性能的标准基准'}
{'arxiv_id': 'arXiv:2509.22649', 'title': 'Toward a Physics of Deep Learning and Brains', 'authors': 'Arsham Ghavasieh, Meritxell Vila-Minana, Akanksha Khurd, John Beggs, Gerardo Ortiz, Santo Fortunato', 'link': 'https://arxiv.org/abs/2509.22649', 'abstract': 'Deep neural networks and brains both learn and share superficial similarities: processing nodes are likened to neurons and adjustable weights are likened to modifiable synapses. But can a unified theoretical framework be found to underlie them both? Here we show that the equations used to describe neuronal avalanches in living brains can also be applied to cascades of activity in deep neural networks. These equations are derived from non-equilibrium statistical physics and show that deep neural networks learn best when poised between absorbing and active phases. Because these networks are strongly driven by inputs, however, they do not operate at a true critical point but within a quasi-critical regime -- one that still approximately satisfies crackling noise scaling relations. By training networks with different initializations, we show that maximal susceptibility is a more reliable predictor of learning than proximity to the critical point itself. This provides a blueprint for engineering improved network performance. Finally, using finite-size scaling we identify distinct universality classes, including Barkhausen noise and directed percolation. This theoretical framework demonstrates that universal features are shared by both biological and artificial neural networks.', 'abstract_zh': '深度神经网络和大脑都在学习和分享表面相似性：处理节点类比为神经元，可调权重类比为可修改的突触。但是，是否可以找到一个统一的理论框架来同时涵盖它们？在这里，我们展示了用于描述活体大脑神经元 avalanche 的方程也可以应用于深度神经网络中的活动级联。这些方程源自非平衡统计物理学，表明当深度神经网络处于吸收相和活跃相之间平衡状态时，它们学习效果最佳。然而，由于这些网络强烈受输入驱动，它们并未在真正的临界点处运行，而是在准临界状态下运行——其仍大约满足裂变噪声标度关系。通过使用不同的初始化训练网络，我们表明最大可探性比临界点本身更可靠地预测了学习。这为工程优化网络性能提供了蓝图。最后，通过有限大小标度分析，我们标识出不同的普遍性类，包括 Barkhausen 噪声和定向渗流。该理论框架证明了生物学和人工神经网络在普遍特性方面具有共性。', 'title_zh': '向深学习和大脑的物理规律研究'}
{'arxiv_id': 'arXiv:2509.22630', 'title': 'StateX: Enhancing RNN Recall via Post-training State Expansion', 'authors': 'Xingyu Shen, Yingfa Chen, Zhen Leng Thai, Xu Han, Zhiyuan Liu, Maosong Sun', 'link': 'https://arxiv.org/abs/2509.22630', 'abstract': 'While Transformer-based models have demonstrated remarkable language modeling performance, their high complexities result in high costs when processing long contexts. In contrast, recurrent neural networks (RNNs) such as linear attention and state space models have gained popularity due to their constant per-token complexities. However, these recurrent models struggle with tasks that require accurate recall of contextual information from long contexts, because all contextual information is compressed into a constant-size recurrent state. Previous works have shown that recall ability is positively correlated with the recurrent state size, yet directly training RNNs with larger recurrent states results in high training costs. In this paper, we introduce StateX, a training pipeline for efficiently expanding the states of pre-trained RNNs through post-training. For two popular classes of RNNs, linear attention and state space models, we design post-training architectural modifications to scale up the state size with no or negligible increase in model parameters. Experiments on models up to 1.3B parameters demonstrate that StateX efficiently enhances the recall and in-context learning ability of RNNs without incurring high post-training costs or compromising other capabilities.', 'abstract_zh': '基于Transformer模型的语言建模表现卓越，但由于其高复杂性，在处理长上下文时成本高昂。相比之下，线性注意力和状态空间模型等循环神经网络（RNNs）因恒定的逐词复杂性而受到青睐。然而，这些循环模型在需要准确回忆长上下文中的信息的任务中表现不佳，因为所有上下文信息都被压缩到一个恒定大小的循环状态中。以往的研究表明，循环状态大小与回忆能力正相关，但直接训练具有更大循环状态的RNN会导致高昂的训练成本。本文介绍了一种名为StateX的训练管道，用于通过后训练高效扩展预先训练的RNN的状态。对于两种流行的RNN类——线性注意力和状态空间模型——我们设计了后训练架构修改，以无或几乎无增加模型参数的方式扩展状态大小。参数量高达13亿的模型实验结果表明，StateX能够在不增加后训练成本或牺牲其他能力的情况下有效提升RNN的回忆能力和上下文学习能力。', 'title_zh': 'StateX：通过后训练状态扩展增强RNN回忆能力'}
{'arxiv_id': 'arXiv:2509.22626', 'title': 'Learning Admissible Heuristics for A*: Theory and Practice', 'authors': 'Ehsan Futuhi, Nathan R. Sturtevant', 'link': 'https://arxiv.org/abs/2509.22626', 'abstract': "Heuristic functions are central to the performance of search algorithms such as A-star, where admissibility - the property of never overestimating the true shortest-path cost - guarantees solution optimality. Recent deep learning approaches often disregard admissibility and provide limited guarantees on generalization beyond the training data. This paper addresses both of these limitations. First, we pose heuristic learning as a constrained optimization problem and introduce Cross-Entropy Admissibility (CEA), a loss function that enforces admissibility during training. On the Rubik's Cube domain, this method yields near-admissible heuristics with significantly stronger guidance than compressed pattern database (PDB) heuristics. Theoretically, we study the sample complexity of learning heuristics. By leveraging PDB abstractions and the structural properties of graphs such as the Rubik's Cube, we tighten the bound on the number of training samples needed for A-star to generalize. Replacing a general hypothesis class with a ReLU neural network gives bounds that depend primarily on the network's width and depth, rather than on graph size. Using the same network, we also provide the first generalization guarantees for goal-dependent heuristics.", 'abstract_zh': '启发式函数的学习作为约束优化问题及其在 Rubik’s Cube 领域的应用与理论分析', 'title_zh': '学习可接纳启发式方法用于A*：理论与实践'}
{'arxiv_id': 'arXiv:2509.22623', 'title': 'A Theoretical Analysis of Discrete Flow Matching Generative Models', 'authors': 'Maojiang Su, Mingcheng Lu, Jerry Yao-Chieh Hu, Shang Wu, Zhao Song, Alex Reneau, Han Liu', 'link': 'https://arxiv.org/abs/2509.22623', 'abstract': 'We provide a theoretical analysis for end-to-end training Discrete Flow Matching (DFM) generative models. DFM is a promising discrete generative modeling framework that learns the underlying generative dynamics by training a neural network to approximate the transformative velocity field. Our analysis establishes a clear chain of guarantees by decomposing the final distribution estimation error. We first prove that the total variation distance between the generated and target distributions is controlled by the risk of the learned velocity field. We then bound this risk by analyzing its two primary sources: (i) Approximation Error, where we quantify the capacity of the Transformer architecture to represent the true velocity, and (ii) Estimation Error, where we derive statistical convergence rates that bound the error from training on a finite dataset. By composing these results, we provide the first formal proof that the distribution generated by a trained DFM model provably converges to the true data distribution as the training set size increases.', 'abstract_zh': '我们提供了端到端训练离散流匹配（DFM）生成模型的理论分析。DFM是一种有前景的离散生成建模框架，通过训练神经网络来逼近转化的流场以学习潜在的生成动力学。我们的分析通过分解最终分布估计误差来确立一条清晰的保证链。我们首先证明生成分布与目标分布之间的总变差距离受学习流场的风险控制。然后通过分析其两个主要来源来界定制约这一风险：（i）逼近误差，其中量化变换器架构表示真实流场的能力，（ii）估计误差，其中推导出统计收敛速率来界定制量有限数据集训练误差。通过组成这些结果，我们提供了首个正式证明，即随着训练数据集规模的增加，训练好的DFM模型生成的分布可证明地收敛到真实数据分布。', 'title_zh': '离散流匹配生成模型的理论分析'}
{'arxiv_id': 'arXiv:2509.22621', 'title': 'IA2: Alignment with ICL Activations Improves Supervised Fine-Tuning', 'authors': 'Aayush Mishra, Daniel Khashabi, Anqi Liu', 'link': 'https://arxiv.org/abs/2509.22621', 'abstract': "Supervised Fine-Tuning (SFT) is used to specialize model behavior by training weights to produce intended target responses for queries. In contrast, In-Context Learning (ICL) adapts models during inference with instructions or demonstrations in the prompt. ICL can offer better generalizability and more calibrated responses compared to SFT in data scarce settings, at the cost of more inference compute. In this work, we ask the question: Can ICL's internal computations be used to improve the qualities of SFT? We first show that ICL and SFT produce distinct activation patterns, indicating that the two methods achieve adaptation through different functional mechanisms. Motivated by this observation and to use ICL's rich functionality, we introduce ICL Activation Alignment (IA2), a self-distillation technique which aims to replicate ICL's activation patterns in SFT models and incentivizes ICL-like internal reasoning. Performing IA2 as a priming step before SFT significantly improves the accuracy and calibration of model outputs, as shown by our extensive empirical results on 12 popular benchmarks and 2 model families. This finding is not only practically useful, but also offers a conceptual window into the inner mechanics of model adaptation.", 'abstract_zh': '监督微调与内省学习在模型适应中的融合：利用内省学习的内部计算改进监督微调的质量', 'title_zh': 'IA2: 与ICL激活相契合的监督微调改进方法'}
{'arxiv_id': 'arXiv:2509.22566', 'title': 'From Parameters to Behavior: Unsupervised Compression of the Policy Space', 'authors': 'Davide Tenedini, Riccardo Zamboni, Mirco Mutti, Marcello Restelli', 'link': 'https://arxiv.org/abs/2509.22566', 'abstract': "Despite its recent successes, Deep Reinforcement Learning (DRL) is notoriously sample-inefficient. We argue that this inefficiency stems from the standard practice of optimizing policies directly in the high-dimensional and highly redundant parameter space $\\Theta$. This challenge is greatly compounded in multi-task settings. In this work, we develop a novel, unsupervised approach that compresses the policy parameter space $\\Theta$ into a low-dimensional latent space $\\mathcal{Z}$. We train a generative model $g:\\mathcal{Z}\\to\\Theta$ by optimizing a behavioral reconstruction loss, which ensures that the latent space is organized by functional similarity rather than proximity in parameterization. We conjecture that the inherent dimensionality of this manifold is a function of the environment's complexity, rather than the size of the policy network. We validate our approach in continuous control domains, showing that the parameterization of standard policy networks can be compressed up to five orders of magnitude while retaining most of its expressivity. As a byproduct, we show that the learned manifold enables task-specific adaptation via Policy Gradient operating in the latent space $\\mathcal{Z}$.", 'abstract_zh': '尽管深度强化学习（DRL）最近取得了成功，但它在样本效率方面一直表现不佳。我们argue认为，这种低效率源于直接在高维且高度冗余的参数空间Θ中优化策略的标准做法。在多任务设置中，这一挑战被进一步放大。在本文中，我们开发了一种新颖的无监督方法，将策略参数空间Θ压缩到低维潜在空间Z。通过优化行为重构损失来训练生成模型g:Z→Θ，确保潜在空间按功能相似性而非参数化邻近度组织。我们推测，这个流形固有的维数是环境复杂性的函数，而不是策略网络大小的函数。我们在连续控制领域验证了该方法，结果显示标准策略网络的参数化可以压缩至原来五个数量级，同时保留大部分表达能力。作为副产品，我们展示了学习到的流形可以通过在潜在空间Z中操作的策略梯度实现任务特定的适应。', 'title_zh': '从参数到行为：无监督的策略空间压缩'}
{'arxiv_id': 'arXiv:2509.22562', 'title': 'Activation Function Design Sustains Plasticity in Continual Learning', 'authors': 'Lute Lillo, Nick Cheney', 'link': 'https://arxiv.org/abs/2509.22562', 'abstract': 'In independent, identically distributed (i.i.d.) training regimes, activation functions have been benchmarked extensively, and their differences often shrink once model size and optimization are tuned. In continual learning, however, the picture is different: beyond catastrophic forgetting, models can progressively lose the ability to adapt (referred to as loss of plasticity) and the role of the non-linearity in this failure mode remains underexplored. We show that activation choice is a primary, architecture-agnostic lever for mitigating plasticity loss. Building on a property-level analysis of negative-branch shape and saturation behavior, we introduce two drop-in nonlinearities (Smooth-Leaky and Randomized Smooth-Leaky) and evaluate them in two complementary settings: (i) supervised class-incremental benchmarks and (ii) reinforcement learning with non-stationary MuJoCo environments designed to induce controlled distribution and dynamics shifts. We also provide a simple stress protocol and diagnostics that link the shape of the activation to the adaptation under change. The takeaway is straightforward: thoughtful activation design offers a lightweight, domain-general way to sustain plasticity in continual learning without extra capacity or task-specific tuning.', 'abstract_zh': '在连续学习中，激活函数的选择是减少塑性损失的主要且架构无关的手段：基于负支形状和饱和行为的性质分析，引入两种即插即用的非线性函数（Smooth-Leaky和Randomized Smooth-Leaky），并在监督类增量基准和诱导分布与动力学变化的非稳态MuJoCo环境中进行强化学习评估，并提供简单的压力测试协议和诊断工具，将激活函数的形状与变化下的适应性联系起来。结论是：精心设计的激活函数提供了一种轻量级且通用的方法，在无需额外容量或任务特定调优的情况下维持连续学习中的塑性。', 'title_zh': '激活函数设计维持连续学习中的塑性'}
{'arxiv_id': 'arXiv:2509.22551', 'title': 'ConQuER: Modular Architectures for Control and Bias Mitigation in IQP Quantum Generative Models', 'authors': 'Xiaocheng Zou, Shijin Duan, Charles Fleming, Gaowen Liu, Ramana Rao Kompella, Shaolei Ren, Xiaolin Xu', 'link': 'https://arxiv.org/abs/2509.22551', 'abstract': 'Quantum generative models based on instantaneous quantum polynomial (IQP) circuits show great promise in learning complex distributions while maintaining classical trainability. However, current implementations suffer from two key limitations: lack of controllability over generated outputs and severe generation bias towards certain expected patterns. We present a Controllable Quantum Generative Framework, ConQuER, which addresses both challenges through a modular circuit architecture. ConQuER embeds a lightweight controller circuit that can be directly combined with pre-trained IQP circuits to precisely control the output distribution without full retraining. Leveraging the advantages of IQP, our scheme enables precise control over properties such as the Hamming Weight distribution with minimal parameter and gate overhead. In addition, inspired by the controller design, we extend this modular approach through data-driven optimization to embed implicit control paths in the underlying IQP architecture, significantly reducing generation bias on structured datasets. ConQuER retains efficient classical training properties and high scalability. We experimentally validate ConQuER on multiple quantum state datasets, demonstrating its superior control accuracy and balanced generation performance, only with very low overhead cost over original IQP circuits. Our framework bridges the gap between the advantages of quantum computing and the practical needs of controllable generation modeling.', 'abstract_zh': '基于瞬时量子多项式（IQP）电路的量子生成模型展现了在学习复杂分布的同时保持经典可训练性的巨大潜力。然而，当前实现面临两个关键限制：生成输出的可控性不足以及严重偏向某些预期模式。我们提出了一种可控量子生成框架ConQuER，该框架通过模块化电路架构解决这两个挑战。ConQuER嵌入了一个轻量级的控制器电路，可以与预训练的IQP电路直接结合，无需完全重新训练即可精确控制输出分布。利用IQP的优势，我们的方案能够在极小的参数和门操作开销下对诸如汉明重量分布等属性实现精确控制。此外，受控制器设计的启发，我们通过数据驱动的优化将这种模块化方法扩展到在底层IQP架构中嵌入隐式控制路径，显著降低了结构化数据集的生成偏差。ConQuER保留了高效的经典训练特性和高可扩展性。我们通过多种量子态数据集的实验验证了ConQuER，展示了其优越的控制精度和均衡的生成性能，仅实现了非常低的开销成本。该框架填补了量子计算优势与可控生成建模实际需求之间的差距。', 'title_zh': 'ConQuER：用于IQP量子生成模型的控制和偏见缓解模块化架构'}
{'arxiv_id': 'arXiv:2509.22545', 'title': 'Does AI Coaching Prepare us for Workplace Negotiations?', 'authors': 'Veda Duddu, Jash Rajesh Parekh, Andy Mao, Hanyi Min, Ziang Xiao, Vedant Das Swain, Koustuv Saha', 'link': 'https://arxiv.org/abs/2509.22545', 'abstract': "Workplace negotiations are undermined by psychological barriers, which can even derail well-prepared tactics. AI offers personalized and always -- available negotiation coaching, yet its effectiveness for negotiation preparedness remains unclear. We built Trucey, a prototype AI coach grounded in Brett's negotiation model. We conducted a between-subjects experiment (N=267), comparing Trucey, ChatGPT, and a traditional negotiation Handbook, followed by in-depth interviews (N=15). While Trucey showed the strongest reductions in fear relative to both comparison conditions, the Handbook outperformed both AIs in usability and psychological empowerment. Interviews revealed that the Handbook's comprehensive, reviewable content was crucial for participants' confidence and preparedness. In contrast, although participants valued AI's rehearsal capability, its guidance often felt verbose and fragmented -- delivered in bits and pieces that required additional effort -- leaving them uncertain or overwhelmed. These findings challenge assumptions of AI superiority and motivate hybrid designs that integrate structured, theory-driven content with targeted rehearsal, clear boundaries, and adaptive scaffolds to address psychological barriers and support negotiation preparedness.", 'abstract_zh': '工作场所的谈判因心理障碍而受阻，甚至会破坏精心准备的策略。尽管AI提供个性化且随时可用的谈判辅导，其在谈判准备方面的有效性仍有待明确。我们构建了基于Brett谈判模型的Trucey原型AI教练。我们进行了一个被试间实验（N=267），比较了Trucey、ChatGPT和传统谈判手册的效果，并随后进行了深入访谈（N=15）。虽然Trucey在减少恐惧方面比两个对照组表现更好，但传统手册在可用性和心理 empowerment 方面的表现优于两者。访谈显示，手册详实且可复查的内容是参与者信心和准备的关键。相比之下，尽管参与者重视AI的模拟练习能力，但其指导往往显得冗长且碎片化，需要额外的努力，这使得他们感到困惑或不知所措。这些发现挑战了AI优越性的假设，并促使人们采用结合结构化、理论驱动的内容与目标化模拟练习、清晰边界和适应性支架的混合设计，以应对心理障碍并支持谈判准备。', 'title_zh': 'AI教练是否为职场谈判做准备？'}
{'arxiv_id': 'arXiv:2509.22505', 'title': 'Mental Health Impacts of AI Companions: Triangulating Social Media Quasi-Experiments, User Perspectives, and Relational Theory', 'authors': 'Yunhao Yuan, Jiaxun Zhang, Talayeh Aledavood, Renwen Zhang, Koustuv Saha', 'link': 'https://arxiv.org/abs/2509.22505', 'abstract': "AI-powered companion chatbots (AICCs) such as Replika are increasingly popular, offering empathetic interactions, yet their psychosocial impacts remain unclear. We examined how engaging with AICCs shaped wellbeing and how users perceived these experiences. First, we conducted a large-scale quasi-experimental study of longitudinal Reddit data, applying stratified propensity score matching and Difference-in-Differences regression. Findings revealed mixed effects -- greater affective and grief expression, readability, and interpersonal focus, alongside increases in language about loneliness and suicidal ideation. Second, we complemented these results with 15 semi-structured interviews, which we thematically analyzed and contextualized using Knapp's relationship development model. We identified trajectories of initiation, escalation, and bonding, wherein AICCs provided emotional validation and social rehearsal but also carried risks of over-reliance and withdrawal. Triangulating across methods, we offer design implications for AI companions that scaffold healthy boundaries, support mindful engagement, support disclosure without dependency, and surface relationship stages -- maximizing psychosocial benefits while mitigating risks.", 'abstract_zh': '基于AI的同伴聊天机器人（AICCs）如Replika越来越受欢迎，它们提供同理心互动，但其心理社会影响尚不清晰。我们探讨了与AICCs互动如何影响福祉以及用户对这些体验的看法。首先，我们通过纵向Reddit数据进行大规模准实验研究，采用分层倾向得分匹配和差异回归分析。结果发现复杂影响——情绪表达和哀悼表达增加、可读性提高和人际焦点增强，同时孤独感和自杀念头的话语增多。其次，我们通过15次半结构化访谈进行了补充研究，并利用Knapp的关系发展模型对访谈进行主题分析和背景说明。我们识别了互动、升级和整合的轨迹，其中AICCs提供了情感验证和社交练习，但也存在过度依赖和疏远的风险。综合多种方法，我们提出了设计建议，以促进健康边界、支持有意识的互动、支持披露而非依赖，并揭示关系阶段——最大化心理社会益处的同时减轻风险。', 'title_zh': '人工智能伴侣对心理健康的影响：多方验证的社会媒体准实验、用户视角与关系理论综合研究'}
{'arxiv_id': 'arXiv:2509.22484', 'title': 'A Machine Learning Pipeline for Multiple Sclerosis Biomarker Discovery: Comparing explainable AI and Traditional Statistical Approaches', 'authors': 'Samuele Punzo, Silvia Giulia Galfrè, Francesco Massafra, Alessandro Maglione, Corrado Priami, Alina Sîrbu', 'link': 'https://arxiv.org/abs/2509.22484', 'abstract': 'We present a machine learning pipeline for biomarker discovery in Multiple Sclerosis (MS), integrating eight publicly available microarray datasets from Peripheral Blood Mononuclear Cells (PBMC). After robust preprocessing we trained an XGBoost classifier optimized via Bayesian search. SHapley Additive exPlanations (SHAP) were used to identify key features for model prediction, indicating thus possible biomarkers. These were compared with genes identified through classical Differential Expression Analysis (DEA). Our comparison revealed both overlapping and unique biomarkers between SHAP and DEA, suggesting complementary strengths. Enrichment analysis confirmed the biological relevance of SHAP-selected genes, linking them to pathways such as sphingolipid signaling, Th1/Th2/Th17 cell differentiation, and Epstein-Barr virus infection all known to be associated with MS. This study highlights the value of combining explainable AI (xAI) with traditional statistical methods to gain deeper insights into disease mechanism.', 'abstract_zh': '一种基于机器学习的多发性硬化症生物标志物发现管道：整合八个多公开的外周血单核细胞微阵列数据集', 'title_zh': '一种多发性硬化生物标志物发现的机器学习管道：可解释AI与传统统计方法的比较'}
{'arxiv_id': 'arXiv:2509.22468', 'title': 'Learning the Neighborhood: Contrast-Free Multimodal Self-Supervised Molecular Graph Pretraining', 'authors': 'Boshra Ariguib, Mathias Niepert, Andrei Manolache', 'link': 'https://arxiv.org/abs/2509.22468', 'abstract': 'High-quality molecular representations are essential for property prediction and molecular design, yet large labeled datasets remain scarce. While self-supervised pretraining on molecular graphs has shown promise, many existing approaches either depend on hand-crafted augmentations or complex generative objectives, and often rely solely on 2D topology, leaving valuable 3D structural information underutilized. To address this gap, we introduce C-FREE (Contrast-Free Representation learning on Ego-nets), a simple framework that integrates 2D graphs with ensembles of 3D conformers. C-FREE learns molecular representations by predicting subgraph embeddings from their complementary neighborhoods in the latent space, using fixed-radius ego-nets as modeling units across different conformers. This design allows us to integrate both geometric and topological information within a hybrid Graph Neural Network (GNN)-Transformer backbone, without negatives, positional encodings, or expensive pre-processing. Pretraining on the GEOM dataset, which provides rich 3D conformational diversity, C-FREE achieves state-of-the-art results on MoleculeNet, surpassing contrastive, generative, and other multimodal self-supervised methods. Fine-tuning across datasets with diverse sizes and molecule types further demonstrates that pretraining transfers effectively to new chemical domains, highlighting the importance of 3D-informed molecular representations.', 'abstract_zh': '高质量的分子表示对于性质预测和分子设计至关重要，但大型带标签数据集仍然稀缺。虽然基于分子图的自监督预训练显示出潜力，但现有许多方法要么依赖手工构造的增强方法，要么具有复杂的生成目标，且往往仅依赖2D拓扑信息，而使宝贵的3D结构信息未能充分利用。为解决这一问题，我们引入了C-FREE（基于ego-网络的无 Contrastive 表示学习），这是一种简单框架，将2D图与3D同分异构体的集合相结合。C-FREE通过在潜在空间中预测子图嵌入的方式学习分子表示，使用固定半径的ego-网络作为建模单元，在不同同分异构体之间进行。这种设计允许我们在混合图神经网络（GNN）-变压器骨干网络中整合几何和拓扑信息，无需负样本、位置编码或昂贵的预处理。在提供丰富3D构象多样性的GEOM数据集上进行预训练，C-FREE在MoleculeNet上取得了最先进的成果，超越了对比学习、生成和其他多模态自监督方法。在不同大小和分子类型的多个数据集上的微调进一步证明了预训练可以有效转移至新的化学领域，强调了3D启发的分子表示的重要性。', 'title_zh': '学习邻域：对比 free 多模态自监督分子图预训练'}
{'arxiv_id': 'arXiv:2509.22461', 'title': 'MDAR: A Multi-scene Dynamic Audio Reasoning Benchmark', 'authors': 'Hui Li, Changhao Jiang, Hongyu Wang, Ming Zhang, Jiajun Sun, Zhixiong Yang, Yifei Cao, Shihan Dou, Xiaoran Fan, Baoyu Fan, Tao Ji, Tao Gui, Qi Zhang, Xuanjing Huang', 'link': 'https://arxiv.org/abs/2509.22461', 'abstract': 'The ability to reason from audio, including speech, paralinguistic cues, environmental sounds, and music, is essential for AI agents to interact effectively in real-world scenarios. Existing benchmarks mainly focus on static or single-scene settings and do not fully capture scenarios where multiple speakers, unfolding events, and heterogeneous audio sources interact. To address these challenges, we introduce MDAR, a benchmark for evaluating models on complex, multi-scene, and dynamically evolving audio reasoning tasks. MDAR comprises 3,000 carefully curated question-answer pairs linked to diverse audio clips, covering five categories of complex reasoning and spanning three question types. We benchmark 26 state-of-the-art audio language models on MDAR and observe that they exhibit limitations in complex reasoning tasks. On single-choice questions, Qwen2.5-Omni (open-source) achieves 76.67% accuracy, whereas GPT-4o Audio (closed-source) reaches 68.47%; however, GPT-4o Audio substantially outperforms Qwen2.5-Omni on the more challenging multiple-choice and open-ended tasks. Across all three question types, no model achieves 80% performance. These findings underscore the unique challenges posed by MDAR and its value as a benchmark for advancing audio reasoning this http URL and benchmark can be found at this https URL.', 'abstract_zh': '音频推理能力对于AI代理在现实场景中有效交互至关重要。现有的基准主要集中在静态或单场景设置上，并未能充分捕捉多个说话人、展开事件和异质音频源相互作用的场景。为应对这些挑战，我们引入了MDAR这一基准，用于评估模型在复杂、多场景和动态演化的音频推理任务中的表现。MDAR包含3000个精心策划的问答对，关联到多样化的音频片段，涵盖五类复杂的推理场景，涉及三种问题类型。我们基于MDAR对26个最先进的音频语言模型进行了基准测试，并观察到它们在复杂推理任务中存在局限性。在单选题方面，Qwen2.5-Omni（开源）的准确率为76.67%，而GPT-4o Audio（闭源）达到68.47%；然而，GPT-4o Audio在更具挑战性的多项选择和开放型任务中显著优于Qwen2.5-Omni。在所有三种问题类型中，没有一个模型达到80%的性能。这些发现凸显了MDAR带来的独特挑战及其作为推动音频推理基准的价值。更多信息，请访问：this https URL。', 'title_zh': 'MDAR：多场景动态音频推理基准'}
{'arxiv_id': 'arXiv:2509.22458', 'title': 'Physics-informed GNN for medium-high voltage AC power flow with edge-aware attention and line search correction operator', 'authors': 'Changhun Kim, Timon Conrad, Redwanul Karim, Julian Oelhaf, David Riebesel, Tomás Arias-Vergara, Andreas Maier, Johann Jäger, Siming Bayer', 'link': 'https://arxiv.org/abs/2509.22458', 'abstract': "Physics-informed graph neural networks (PIGNNs) have emerged as fast AC power-flow solvers that can replace classic Newton--Raphson (NR) solvers, especially when thousands of scenarios must be evaluated. However, current PIGNNs still need accuracy improvements at parity speed; in particular, the physics loss is inoperative at inference, which can deter operational adoption. We address this with PIGNN-Attn-LS, combining an edge-aware attention mechanism that explicitly encodes line physics via per-edge biases, capturing the grid's anisotropy, with a backtracking line-search-based globalized correction operator that restores an operative decrease criterion at inference. Training and testing use a realistic High-/Medium-Voltage scenario generator, with NR used only to construct reference states. On held-out HV cases consisting of 4--32-bus grids, PIGNN-Attn-LS achieves a test RMSE of 0.00033 p.u. in voltage and 0.08$^\\circ$ in angle, outperforming the PIGNN-MLP baseline by 99.5\\% and 87.1\\%, respectively. With streaming micro-batches, it delivers 2--5$\\times$ faster batched inference than NR on 4--1024-bus grids.", 'abstract_zh': '基于物理信息的图神经网络（PIGNNs）已经发展成为快速的交流功率流求解器，可以在成千上万种场景评估时替代经典的牛顿-拉夫逊（NR）求解器。然而，当前的PIGNNs仍需要在保持速度的同时提高准确性；特别是，在推理时无法发挥作用的物理损失项可能阻碍其实用化。我们通过引入PIGNN-Attn-LS解决了这一问题，该方法结合了边感知注意力机制，通过每边偏差显式地编码线路物理特性，捕获电网的各向异性，并采用基于回溯线搜索的全局校正算子，在推理时恢复了有效的减少准则。训练和测试使用一个现实的高/中压场景生成器，仅使用NR构建参考状态。在由4-32节点电网组成的保留验证案例中，PIGNN-Attn-LS实现了电压0.00033 p.u.和角度0.08°的测试RMSE，分别比PIGNN-MLP基线高出99.5%和87.1%。使用流式微批量处理，它在4-1024节点电网上的批量推理速度比NR快2-5倍。', 'title_zh': '考虑边感知注意力和线路搜索校正运算符的物理知情GNN在中高压AC潮流中的应用'}
{'arxiv_id': 'arXiv:2509.22445', 'title': 'Bridging Kolmogorov Complexity and Deep Learning: Asymptotically Optimal Description Length Objectives for Transformers', 'authors': 'Peter Shaw, James Cohan, Jacob Eisenstein, Kristina Toutanova', 'link': 'https://arxiv.org/abs/2509.22445', 'abstract': "The Minimum Description Length (MDL) principle offers a formal framework for applying Occam's razor in machine learning. However, its application to neural networks such as Transformers is challenging due to the lack of a principled, universal measure for model complexity. This paper introduces the theoretical notion of asymptotically optimal description length objectives, grounded in the theory of Kolmogorov complexity. We establish that a minimizer of such an objective achieves optimal compression, for any dataset, up to an additive constant, in the limit as model resource bounds increase. We prove that asymptotically optimal objectives exist for Transformers, building on a new demonstration of their computational universality. We further show that such objectives can be tractable and differentiable by constructing and analyzing a variational objective based on an adaptive Gaussian mixture prior. Our empirical analysis shows that this variational objective selects for a low-complexity solution with strong generalization on an algorithmic task, but standard optimizers fail to find such solutions from a random initialization, highlighting key optimization challenges. More broadly, by providing a theoretical framework for identifying description length objectives with strong asymptotic guarantees, we outline a potential path towards training neural networks that achieve greater compression and generalization.", 'abstract_zh': '最小描述长度（MDL）原则为在机器学习中应用奥卡姆剃刀提供了一个形式化的框架。然而，将其应用于如变换器等神经网络具有挑战性，原因在于缺乏一个有原则性的、普遍适用的模型复杂度度量。本文介绍了基于科莫戈罗夫复杂性理论的渐近最优描述长度目标的理论概念。我们建立起这样的目标函数的一个最小化者能够对于任意数据集在模型资源界限增加时的极限状态下实现最优压缩，其中误差在可加常数之内。我们证明了对于变换器存在渐近最优目标，这是基于对其计算普遍性的新证明。进一步地，我们表明这样的目标可以是可处理且可微的，通过构建并分析基于自适应高斯混合先验的变分目标来实现这一点。我们的实验分析表明，这种变分目标在算法任务上选择了一个低复杂度的解，并且具有较强的泛化能力，但标准优化器从随机初始化无法找到这样的解，突出了关键的优化挑战。更广泛地，通过提供一个理论框架来识别具有强大渐近保证的描述长度目标，本文勾勒出了一条潜在研究路径，旨在训练能够实现更高压缩和泛化的神经网络。', 'title_zh': '连接科莫洛夫复杂性和深度学习：变换器的渐近最优描述长度目标函数'}
{'arxiv_id': 'arXiv:2509.22436', 'title': 'Global Convergence in Neural ODEs: Impact of Activation Functions', 'authors': 'Tianxiang Gao, Siyuan Sun, Hailiang Liu, Hongyang Gao', 'link': 'https://arxiv.org/abs/2509.22436', 'abstract': 'Neural Ordinary Differential Equations (ODEs) have been successful in various applications due to their continuous nature and parameter-sharing efficiency. However, these unique characteristics also introduce challenges in training, particularly with respect to gradient computation accuracy and convergence analysis. In this paper, we address these challenges by investigating the impact of activation functions. We demonstrate that the properties of activation functions, specifically smoothness and nonlinearity, are critical to the training dynamics. Smooth activation functions guarantee globally unique solutions for both forward and backward ODEs, while sufficient nonlinearity is essential for maintaining the spectral properties of the Neural Tangent Kernel (NTK) during training. Together, these properties enable us to establish the global convergence of Neural ODEs under gradient descent in overparameterized regimes. Our theoretical findings are validated by numerical experiments, which not only support our analysis but also provide practical guidelines for scaling Neural ODEs, potentially leading to faster training and improved performance in real-world applications.', 'abstract_zh': '神经普通微分方程（ODEs）因其连续性质和参数共享效率，在各种应用中取得了成功。然而，这些独特特性也带来了训练挑战，尤其是在梯度计算准确性和收敛性分析方面。本文通过研究激活函数的影响来应对这些挑战。我们证明了激活函数的特性，特别是平滑性和非线性，在训练动态中至关重要。平滑的激活函数确保前向和反向ODEs具有全局唯一解，而足够的非线性则对于在训练过程中保持神经核张量（NTK）的频谱特性是必不可少的。这些特性共同使我们能够在参数过量情况下通过梯度下降方法证明神经ODEs的全局收敛性。我们的理论发现通过数值实验得到了验证，不仅支持了我们的分析，还为在实际应用中扩展神经ODEs提供了实用指南，可能加速训练并提高性能。', 'title_zh': '全局收敛性在神经ODE中的影响：激活函数的作用'}
{'arxiv_id': 'arXiv:2509.22418', 'title': 'Partial Parameter Updates for Efficient Distributed Training', 'authors': 'Anastasiia Filippova, Angelos Katharopoulos, David Grangier, Ronan Collobert', 'link': 'https://arxiv.org/abs/2509.22418', 'abstract': 'We introduce a memory- and compute-efficient method for low-communication distributed training. Existing methods reduce communication by performing multiple local updates between infrequent global synchronizations. We demonstrate that their efficiency can be significantly improved by restricting backpropagation: instead of updating all the parameters, each node updates only a fixed subset while keeping the remainder frozen during local steps. This constraint substantially reduces peak memory usage and training FLOPs, while a full forward pass over all parameters eliminates the need for cross-node activation exchange. Experiments on a $1.3$B-parameter language model trained across $32$ nodes show that our method matches the perplexity of prior low-communication approaches under identical token and bandwidth budgets while reducing training FLOPs and peak memory.', 'abstract_zh': '一种低通信分布式训练的内存和计算高效方法', 'title_zh': '部分参数更新以实现高效分布式训练'}
{'arxiv_id': 'arXiv:2509.22359', 'title': "Forecasting the Future with Yesterday's Climate: Temperature Bias in AI Weather and Climate Models", 'authors': 'Jacob B. Landsberg, Elizabeth A. Barnes', 'link': 'https://arxiv.org/abs/2509.22359', 'abstract': "AI-based climate and weather models have rapidly gained popularity, providing faster forecasts with skill that can match or even surpass that of traditional dynamical models. Despite this success, these models face a key challenge: predicting future climates while being trained only with historical data. In this study, we investigate this issue by analyzing boreal winter land temperature biases in AI weather and climate models. We examine two weather models, FourCastNet V2 Small (FourCastNet) and Pangu Weather (Pangu), evaluating their predictions for 2020-2025 and Ai2 Climate Emulator version 2 (ACE2) for 1996-2010. These time periods lie outside of the respective models' training sets and are significantly more recent than the bulk of their training data, allowing us to assess how well the models generalize to new, i.e. more modern, conditions. We find that all three models produce cold-biased mean temperatures, resembling climates from 15-20 years earlier than the period they are predicting. In some regions, like the Eastern U.S., the predictions resemble climates from as much as 20-30 years earlier. Further analysis shows that FourCastNet's and Pangu's cold bias is strongest in the hottest predicted temperatures, indicating limited training exposure to modern extreme heat events. In contrast, ACE2's bias is more evenly distributed but largest in regions, seasons, and parts of the temperature distribution where climate change has been most pronounced. These findings underscore the challenge of training AI models exclusively on historical data and highlight the need to account for such biases when applying them to future climate prediction.", 'abstract_zh': '基于AI的气候和天气模型在快速获得 popularity 的同时，提供了与传统动力模型技能相当甚至超越的更快预报，但这些模型在仅使用历史数据进行训练的情况下预测未来气候面临关键挑战。本研究通过分析北极冬季陆地温度偏差，探讨了这一问题。我们评估了FourCastNet V2 Small (FourCastNet) 和 Pangu Weather (Pangu) 这两个天气模型在2020-2025年的预测，以及Ai2 Climate Emulator版本2 (ACE2) 在1996-2010年的预测，这些时间段超出了模型各自的训练集并且比大部分训练数据更为近期，从而评估模型在新情况下的泛化能力。研究发现，所有三个模型都生成了冷偏差的平均温度，类似于预测期间15-20年前的气候。在一些区域，如美国东部，预测结果更早地追溯至20-30年前。进一步分析表明，FourCastNet 和 Pangu 的冷偏差在预测的最高温度中最强烈，表明对现代极端高温事件的训练暴露有限。相比之下，ACE2 的偏差较为均匀，但最大的偏差出现在受气候变化影响最显著的区域、季节和温度分布部分中。这些发现突显了仅使用历史数据训练AI模型的挑战，并强调了在将其应用于未来气候预测时考虑偏差的重要性。', 'title_zh': '用昨日气候预测未来：AI天气与气候模型中的温度偏差'}
{'arxiv_id': 'arXiv:2509.22352', 'title': 'SurvDiff: A Diffusion Model for Generating Synthetic Data in Survival Analysis', 'authors': 'Marie Brockschmidt, Maresa Schröder, Stefan Feuerriegel', 'link': 'https://arxiv.org/abs/2509.22352', 'abstract': 'Survival analysis is a cornerstone of clinical research by modeling time-to-event outcomes such as metastasis, disease relapse, or patient death. Unlike standard tabular data, survival data often come with incomplete event information due to dropout, or loss to follow-up. This poses unique challenges for synthetic data generation, where it is crucial for clinical research to faithfully reproduce both the event-time distribution and the censoring mechanism. In this paper, we propose SurvDiff, an end-to-end diffusion model specifically designed for generating synthetic data in survival analysis. SurvDiff is tailored to capture the data-generating mechanism by jointly generating mixed-type covariates, event times, and right-censoring, guided by a survival-tailored loss function. The loss encodes the time-to-event structure and directly optimizes for downstream survival tasks, which ensures that SurvDiff (i) reproduces realistic event-time distributions and (ii) preserves the censoring mechanism. Across multiple datasets, we show that \\survdiff consistently outperforms state-of-the-art generative baselines in both distributional fidelity and downstream evaluation metrics across multiple medical datasets. To the best of our knowledge, SurvDiff is the first diffusion model explicitly designed for generating synthetic survival data.', 'abstract_zh': '生存分析是临床研究的基石，通过建模如转移、疾病复发或患者死亡等时间事件结果。与标准表格式数据不同，生存数据常常由于中途退出或失访等原因包含不完整的事件信息。这对合成数据生成提出了独特挑战，其中仔细再现事件时间分布和截尾机制对临床研究至关重要。本文提出SurvDiff，这是一种专门设计用于生存分析中生成合成数据的端到端扩散模型。SurvDiff通过生成混合型协变量、事件时间及右截尾，并由一种针对生存分析定制的损失函数进行指导，来捕捉数据生成机制。该损失函数编码时间事件结构，并直接优化下游生存分析任务，从而确保SurvDiff (i) 生成现实的时间事件分布，并且(ii) 保留截尾机制。在多个数据集上，我们展示了SurvDiff在合成数据分布保真度和多个医学数据集的下游评估指标上始终优于最先进的生成基线。据我们所知，SurvDiff是首个明确为生成合成生存数据设计的扩散模型。', 'title_zh': 'SurvDiff：生存分析中生成合成数据的扩散模型'}
{'arxiv_id': 'arXiv:2509.22335', 'title': 'Spectral Collapse Drives Loss of Plasticity in Deep Continual Learning', 'authors': 'Naicheng He, Kaicheng Guo, Arjun Prakash, Saket Tiwari, Ruo Yu Tao, Tyrone Serapio, Amy Greenwald, George Konidaris', 'link': 'https://arxiv.org/abs/2509.22335', 'abstract': 'We investigate why deep neural networks suffer from \\emph{loss of plasticity} in deep continual learning, failing to learn new tasks without reinitializing parameters. We show that this failure is preceded by Hessian spectral collapse at new-task initialization, where meaningful curvature directions vanish and gradient descent becomes ineffective. To characterize the necessary condition for successful training, we introduce the notion of $\\tau$-trainability and show that current plasticity preserving algorithms can be unified under this framework. Targeting spectral collapse directly, we then discuss the Kronecker factored approximation of the Hessian, which motivates two regularization enhancements: maintaining high effective feature rank and applying $L2$ penalties. Experiments on continual supervised and reinforcement learning tasks confirm that combining these two regularizers effectively preserves plasticity.', 'abstract_zh': '我们研究为什么在深度连续学习中深度神经网络会遭受可塑性丧失的问题，无法在不重新初始化参数的情况下学习新任务。我们表明，这种失败发生在新任务初始化时海森矩阵谱塌缩之前，在此过程中有意义的曲率方向消失，使得梯度下降变得无效。为了刻画成功训练的必要条件，我们提出了$\\tau$-可训练性的概念，并展示了当前的可塑性保留算法可以在这一框架下统一。直接针对谱塌缩，我们讨论了海森矩阵的克罗内克分解近似，这启发了两种正则化增强：保持有效的特征秩较高和应用$L2$惩罚。实验表明，结合这两种正则化可以有效地保留可塑性。', 'title_zh': '光谱坍缩驱动深连续学习中的可塑性丧失'}
{'arxiv_id': 'arXiv:2509.22319', 'title': 'Progressive Weight Loading: Accelerating Initial Inference and Gradually Boosting Performance on Resource-Constrained Environments', 'authors': 'Hyunwoo Kim, Junha Lee, Mincheol Choi, Jeonghwan Lee, Jaeshin Cho', 'link': 'https://arxiv.org/abs/2509.22319', 'abstract': 'Deep learning models have become increasingly large and complex, resulting in higher memory consumption and computational demands. Consequently, model loading times and initial inference latency have increased, posing significant challenges in mobile and latency-sensitive environments where frequent model loading and unloading are required, which directly impacts user experience. While Knowledge Distillation (KD) offers a solution by compressing large teacher models into smaller student ones, it often comes at the cost of reduced performance. To address this trade-off, we propose Progressive Weight Loading (PWL), a novel technique that enables fast initial inference by first deploying a lightweight student model, then incrementally replacing its layers with those of a pre-trained teacher model. To support seamless layer substitution, we introduce a training method that not only aligns intermediate feature representations between student and teacher layers, but also improves the overall output performance of the student model. Our experiments on VGG, ResNet, and ViT architectures demonstrate that models trained with PWL maintain competitive distillation performance and gradually improve accuracy as teacher layers are loaded-matching the final accuracy of the full teacher model without compromising initial inference speed. This makes PWL particularly suited for dynamic, resource-constrained deployments where both responsiveness and performance are critical.', 'abstract_zh': '渐进权重加载：一种支持快速初始推理的知识蒸馏新方法', 'title_zh': '逐级权重加载：加速初始推理并在资源受限环境中逐步提升性能'}
{'arxiv_id': 'arXiv:2509.22291', 'title': 'Bridging Fairness and Explainability: Can Input-Based Explanations Promote Fairness in Hate Speech Detection?', 'authors': 'Yifan Wang, Mayank Jobanputra, Ji-Ung Lee, Soyoung Oh, Isabel Valera, Vera Demberg', 'link': 'https://arxiv.org/abs/2509.22291', 'abstract': 'Natural language processing (NLP) models often replicate or amplify social bias from training data, raising concerns about fairness. At the same time, their black-box nature makes it difficult for users to recognize biased predictions and for developers to effectively mitigate them. While some studies suggest that input-based explanations can help detect and mitigate bias, others question their reliability in ensuring fairness. Existing research on explainability in fair NLP has been predominantly qualitative, with limited large-scale quantitative analysis. In this work, we conduct the first systematic study of the relationship between explainability and fairness in hate speech detection, focusing on both encoder- and decoder-only models. We examine three key dimensions: (1) identifying biased predictions, (2) selecting fair models, and (3) mitigating bias during model training. Our findings show that input-based explanations can effectively detect biased predictions and serve as useful supervision for reducing bias during training, but they are unreliable for selecting fair models among candidates.', 'abstract_zh': '自然语言处理（NLP）模型常常复制或放大训练数据中的社会偏见，引发了公平性问题的关注。同时，其黑盒性质使得用户难以识别有偏见的预测，并且开发人员难以有效地缓解这些问题。虽然有一些研究表明基于输入的解释可以帮助检测和缓解偏见，但其他研究对其在确保公平性方面的可靠性提出了质疑。现有的关于公平NLP中的可解释性研究主要以定性为主，缺乏大规模的定量分析。在这项工作中，我们首次系统地研究了可解释性与仇恨言论检测中的公平性的关系，重点关注编码器和解码器模型。我们分析了三个关键维度：（1）识别有偏见的预测，（2）选择公平模型，（3）在模型训练中缓解偏见。我们的研究发现，基于输入的解释可以有效地检测有偏见的预测，并在训练过程中作为减少偏见的有效监督，但它们不能可靠地用于在候选模型中选择公平模型。', 'title_zh': '公平性与可解释性之间的桥梁：基于输入的解释能否促进仇恨言论检测的公平性？'}
{'arxiv_id': 'arXiv:2509.22280', 'title': 'A Global Analysis of Cyber Threats to the Energy Sector: "Currents of Conflict" from a Geopolitical Perspective', 'authors': 'Gustavo Sánchez, Ghada Elbez, Veit Hagenmeyer', 'link': 'https://arxiv.org/abs/2509.22280', 'abstract': 'The escalating frequency and sophistication of cyber threats increased the need for their comprehensive understanding. This paper explores the intersection of geopolitical dynamics, cyber threat intelligence analysis, and advanced detection technologies, with a focus on the energy domain. We leverage generative artificial intelligence to extract and structure information from raw cyber threat descriptions, enabling enhanced analysis. By conducting a geopolitical comparison of threat actor origins and target regions across multiple databases, we provide insights into trends within the general threat landscape. Additionally, we evaluate the effectiveness of cybersecurity tools -- with particular emphasis on learning-based techniques -- in detecting indicators of compromise for energy-targeted attacks. This analysis yields new insights, providing actionable information to researchers, policy makers, and cybersecurity professionals.', 'abstract_zh': 'escalating频率和复杂性增加促进了对其全面理解的需要。本文探讨了地缘政治动态、网络威胁情报分析和先进技术检测的交叉领域，重点关注能源领域。我们利用生成式人工智能从原始网络威胁描述中提取和组织信息，以增强分析能力。通过跨多个数据库对威胁行为者来源和目标区域进行地缘政治对比分析，我们提供了总体威胁格局中的趋势见解。此外，我们评估了网络安全工具的有效性——特别是基于学习的技术——在检测针对能源目标的攻击的指示符方面的效果。这一分析提供了新的见解，为研究人员、政策制定者和网络安全专业人员提供了可操作的信息。', 'title_zh': '从地缘政治视角看能源 sector 的网络威胁全球分析：“冲突的 currents”'}
{'arxiv_id': 'arXiv:2509.22246', 'title': 'ASSESS: A Semantic and Structural Evaluation Framework for Statement Similarity', 'authors': 'Xiaoyang Liu, Tao Zhu, Zineng Dong, Yuntian Liu, Qingfeng Guo, Zhaoxuan Liu, Yu Chen, Tao Luo', 'link': 'https://arxiv.org/abs/2509.22246', 'abstract': 'Statement autoformalization, the automated translation of statements from natural language into formal languages, has seen significant advancements, yet the development of automated evaluation metrics remains limited. Existing metrics for formal statement similarity often fail to balance semantic and structural information. String-based approaches capture syntactic structure but ignore semantic meaning, whereas proof-based methods validate semantic equivalence but disregard structural nuances and, critically, provide no graded similarity score in the event of proof failure. To address these issues, we introduce ASSESS (A Semantic and Structural Evaluation Framework for Statement Similarity), which comprehensively integrates semantic and structural information to provide a continuous similarity score. Our framework first transforms formal statements into Operator Trees to capture their syntactic structure and then computes a similarity score using our novel TransTED (Transformation Tree Edit Distance) Similarity metric, which enhances traditional Tree Edit Distance by incorporating semantic awareness through transformations. For rigorous validation, we present EPLA (Evaluating Provability and Likeness for Autoformalization), a new benchmark of 524 expert-annotated formal statement pairs derived from miniF2F and ProofNet, with labels for both semantic provability and structural likeness. Experiments on EPLA demonstrate that TransTED Similarity outperforms existing methods, achieving state-of-the-art accuracy and the highest Kappa coefficient. The benchmark, and implementation code will be made public soon.', 'abstract_zh': '基于语义和结构的语句相似性评估框架：ASSESS', 'title_zh': 'ASSESS：语义和结构评估框架用于语句相似性评估'}
{'arxiv_id': 'arXiv:2509.22232', 'title': 'Fairness-Aware Reinforcement Learning (FAReL): A Framework for Transparent and Balanced Sequential Decision-Making', 'authors': 'Alexandra Cimpean, Nicole Orzan, Catholijn Jonker, Pieter Libin, Ann Nowé', 'link': 'https://arxiv.org/abs/2509.22232', 'abstract': 'Equity in real-world sequential decision problems can be enforced using fairness-aware methods. Therefore, we require algorithms that can make suitable and transparent trade-offs between performance and the desired fairness notions. As the desired performance-fairness trade-off is hard to specify a priori, we propose a framework where multiple trade-offs can be explored. Insights provided by the reinforcement learning algorithm regarding the obtainable performance-fairness trade-offs can then guide stakeholders in selecting the most appropriate policy. To capture fairness, we propose an extended Markov decision process, $f$MDP, that explicitly encodes individuals and groups. Given this $f$MDP, we formalise fairness notions in the context of sequential decision problems and formulate a fairness framework that computes fairness measures over time. We evaluate our framework in two scenarios with distinct fairness requirements: job hiring, where strong teams must be composed while treating applicants equally, and fraud detection, where fraudulent transactions must be detected while ensuring the burden on customers is fairly distributed. We show that our framework learns policies that are more fair across multiple scenarios, with only minor loss in performance reward. Moreover, we observe that group and individual fairness notions do not necessarily imply one another, highlighting the benefit of our framework in settings where both fairness types are desired. Finally, we provide guidelines on how to apply this framework across different problem settings.', 'abstract_zh': '在实际序列决策问题中，可以通过公平性意识方法确保公平性。因此，我们需要能够在这两者之间做出合适且透明权衡的算法：性能与所需的公平性观念。由于期望的性能-公平性权衡在先验难以具体指定，我们提出了一种框架，可以在其中探索多种权衡。强化学习算法提供的见解可以指导相关方选择最合适的政策。为了捕捉公平性，我们提出了一种扩展的马尔可夫决策过程$f$MDP，其中明确编码了个体和群体。基于这个$f$MDP，我们在序列决策问题的背景下形式化了公平性概念，并制定了一个公平性框架，该框架计算公平性指标随时间的变化。我们在两种具有不同公平性要求的场景中评估了该框架：在招聘场景中，需要组建强大的团队同时公平对待应聘者；在欺诈检测场景中，需要检测欺诈性交易同时公平地分配客户负担。我们展示了该框架在多个场景中学习出更公平的策略，仅轻微牺牲性能奖励。此外，我们观察到群体公平性和个体公平性概念并不一定相互蕴含，突显了该框架在同时追求这两种公平性的设置中的优势。最后，我们提供了如何在不同问题设置中应用该框架的指导。', 'title_zh': '面向公平的强化学习（FAReL）：透明且平衡的序列决策框架'}
{'arxiv_id': 'arXiv:2509.22216', 'title': 'Impact of Collective Behaviors of Autonomous Vehicles on Urban Traffic Dynamics: A Multi-Agent Reinforcement Learning Approach', 'authors': 'Ahmet Onur Akman, Anastasia Psarou, Zoltán György Varga, Grzegorz Jamróz, Rafał Kucharski', 'link': 'https://arxiv.org/abs/2509.22216', 'abstract': "This study examines the potential impact of reinforcement learning (RL)-enabled autonomous vehicles (AV) on urban traffic flow in a mixed traffic environment. We focus on a simplified day-to-day route choice problem in a multi-agent setting. We consider a city network where human drivers travel through their chosen routes to reach their destinations in minimum travel time. Then, we convert one-third of the population into AVs, which are RL agents employing Deep Q-learning algorithm. We define a set of optimization targets, or as we call them behaviors, namely selfish, collaborative, competitive, social, altruistic, and malicious. We impose a selected behavior on AVs through their rewards. We run our simulations using our in-house developed RL framework PARCOUR. Our simulations reveal that AVs optimize their travel times by up to 5\\%, with varying impacts on human drivers' travel times depending on the AV behavior. In all cases where AVs adopt a self-serving behavior, they achieve shorter travel times than human drivers. Our findings highlight the complexity differences in learning tasks of each target behavior. We demonstrate that the multi-agent RL setting is applicable for collective routing on traffic networks, though their impact on coexisting parties greatly varies with the behaviors adopted.", 'abstract_zh': '本研究探讨了增强学习（RL）赋能的自动驾驶车辆（AV）对混合交通环境中城市交通流的潜在影响。我们集中研究多智能体环境下的简化日常路线选择问题。我们考虑一个城市网络，其中人类驾驶员通过他们选择的路线在最短的旅行时间内到达目的地。然后，我们将三分之一的人口转换为AV，这些AV是使用深度Q学习算法的RL代理。我们定义了一组优化目标，或如我们所称的行为，分别是自私、协作、竞争、亲社会、利他和恶意。我们通过奖励将选定的行为施加于AV上。我们使用我们自主研发的RL框架PARCOUR进行模拟。我们的模拟结果显示，AV通过优化其旅行时间最多可达5%，而人类驾驶员的旅行时间受到AV行为的影响有所不同。在AV采取自我中心行为的所有情况下，它们的旅行时间都比人类驾驶员短。我们的研究指出，每种目标行为的学习任务复杂性存在差异。我们证明，多智能体RL设置适用于交通网络中的集体路由，但由于所采用的行为不同，其对共存各方的影响也各不相同。', 'title_zh': '自动驾驶车辆集群行为对城市交通动力学的影响：一种多代理强化学习方法'}
{'arxiv_id': 'arXiv:2509.22207', 'title': 'Reversible GNS for Dissipative Fluids with Consistent Bidirectional Dynamics', 'authors': 'Mu Huang, Linning Xu, Mingyue Dai, Yidi Shao, Bo Dai', 'link': 'https://arxiv.org/abs/2509.22207', 'abstract': 'Simulating physically plausible trajectories toward user-defined goals is a fundamental yet challenging task in fluid dynamics. While particle-based simulators can efficiently reproduce forward dynamics, inverse inference remains difficult, especially in dissipative systems where dynamics are irreversible and optimization-based solvers are slow, unstable, and often fail to converge. In this work, we introduce the Reversible Graph Network Simulator (R-GNS), a unified framework that enforces bidirectional consistency within a single graph architecture. Unlike prior neural simulators that approximate inverse dynamics by fitting backward data, R-GNS does not attempt to reverse the underlying physics. Instead, we propose a mathematically invertible design based on residual reversible message passing with shared parameters, coupling forward dynamics with inverse inference to deliver accurate predictions and efficient recovery of plausible initial states. Experiments on three dissipative benchmarks (Water-3D, WaterRamps, and WaterDrop) show that R-GNS achieves higher accuracy and consistency with only one quarter of the parameters, and performs inverse inference more than 100 times faster than optimization-based baselines. For forward simulation, R-GNS matches the speed of strong GNS baselines, while in goal-conditioned tasks it eliminates iterative optimization and achieves orders-of-magnitude speedups. On goal-conditioned tasks, R-GNS further demonstrates its ability to complex target shapes (e.g., characters "L" and "N") through vivid, physically consistent trajectories. To our knowledge, this is the first reversible framework that unifies forward and inverse simulation for dissipative fluid systems.', 'abstract_zh': 'Reversible Graph Network Simulator for Unified Forward and Inverse Simulation of Dissipative Fluid Systems', 'title_zh': '可逆GNS方法用于耗散流体且具有一致的双向动力学'}
{'arxiv_id': 'arXiv:2509.22184', 'title': 'Learning Equivariant Functions via Quadratic Forms', 'authors': 'Pavan Karjol, Vivek V Kashyap, Rohan Kashyap, Prathosh A P', 'link': 'https://arxiv.org/abs/2509.22184', 'abstract': "In this study, we introduce a method for learning group (known or unknown) equivariant functions by learning the associated quadratic form $x^T A x$ corresponding to the group from the data. Certain groups, known as orthogonal groups, preserve a specific quadratic form, and we leverage this property to uncover the underlying symmetry group under the assumption that it is orthogonal. By utilizing the corresponding unique symmetric matrix and its inherent diagonal form, we incorporate suitable inductive biases into the neural network architecture, leading to models that are both simplified and efficient. Our approach results in an invariant model that preserves norms, while the equivariant model is represented as a product of a norm-invariant model and a scale-invariant model, where the ``product'' refers to the group action.\nMoreover, we extend our framework to a more general setting where the function acts on tuples of input vectors via a diagonal (or product) group action. In this extension, the equivariant function is decomposed into an angular component extracted solely from the normalized first vector and a scale-invariant component that depends on the full Gram matrix of the tuple. This decomposition captures the inter-dependencies between multiple inputs while preserving the underlying group symmetry.\nWe assess the effectiveness of our framework across multiple tasks, including polynomial regression, top quark tagging, and moment of inertia matrix prediction. Comparative analysis with baseline methods demonstrates that our model consistently excels in both discovering the underlying symmetry and efficiently learning the corresponding equivariant function.", 'abstract_zh': '本研究介绍了一种通过从数据中学习与群组（已知或未知）相关的二次形式$x^T A x$来学习群组（不变或可变）函数的方法。某些群组，称为正交群组，保持特定的二次形式，我们利用这一性质，在假设群组是正交的情况下，揭示底层对称群组。通过利用相应的唯一对称矩阵及其固有的对角形式，我们将合适的归纳偏置纳入神经网络架构中，从而得到既简化又高效的方法。我们的方法产生一个保持范数不变的不变模型，而可变模型表示为一个范数不变模型和一个尺度不变模型的乘积，这里的“乘积”指的是群组作用。此外，我们将框架推广到函数通过对角（或乘积）群组作用作用于输入向量元组的更一般设置中。在这一扩展中，可变函数被分解为仅从归一化后的第一个向量中提取的角成分和依赖于元组完整格莱姆矩阵的尺度不变成分。这种分解捕捉到多个输入之间的相互依赖关系，同时保持底层的群组对称性。我们跨多项式回归、顶夸克标记和惯性矩预测等多个任务评估了框架的有效性。与基线方法的比较分析表明，我们的模型在发现底层对称性和高效学习相应的可变函数方面始终表现出色。', 'title_zh': '学习二次形式下的等变函数'}
{'arxiv_id': 'arXiv:2509.22174', 'title': 'Efficiency Boost in Decentralized Optimization: Reimagining Neighborhood Aggregation with Minimal Overhead', 'authors': 'Durgesh Kalwar, Mayank Baranwal, Harshad Khadilkar', 'link': 'https://arxiv.org/abs/2509.22174', 'abstract': "In today's data-sensitive landscape, distributed learning emerges as a vital tool, not only fortifying privacy measures but also streamlining computational operations. This becomes especially crucial within fully decentralized infrastructures where local processing is imperative due to the absence of centralized aggregation. Here, we introduce DYNAWEIGHT, a novel framework to information aggregation in multi-agent networks. DYNAWEIGHT offers substantial acceleration in decentralized learning with minimal additional communication and memory overhead. Unlike traditional static weight assignments, such as Metropolis weights, DYNAWEIGHT dynamically allocates weights to neighboring servers based on their relative losses on local datasets. Consequently, it favors servers possessing diverse information, particularly in scenarios of substantial data heterogeneity. Our experiments on various datasets MNIST, CIFAR10, and CIFAR100 incorporating various server counts and graph topologies, demonstrate notable enhancements in training speeds. Notably, DYNAWEIGHT functions as an aggregation scheme compatible with any underlying server-level optimization algorithm, underscoring its versatility and potential for widespread integration.", 'abstract_zh': '在当今数据敏感的环境中，分布式学习 emerge as a vital tool, not only fortifying privacy measures but also streamlining computational operations. 这在完全去中心化的基础设施中尤为重要，因为在这种情况下，由于缺乏集中聚合，本地处理变得至关重要。在此，我们介绍 DYNAWEIGHT，一种用于多代理网络信息聚合的新框架。DYNAWEIGHT 通过最少的额外通信和内存开销实现去中心化学习的显著加速。与传统的静态权重分配（如 Metropolis 权重）不同，DYNAWEIGHT 根据相邻服务器在其本地数据集上的相对损失动态分配权重。因此，在数据异质性显著的情况下，它倾向于信息多样的服务器。在对 MNIST、CIFAR10 和 CIFAR100 等多个数据集的各种服务器数量和图拓扑进行的实验中，展示了训练速度的显著提升。值得注意的是，DYNAWEIGHT 可与任何底层服务器级优化算法兼容，突显了其灵活性和广泛集成的潜力。去中心化学习中的动态权重分配框架', 'title_zh': '去中心化优化中的效率提升：以最小开销重新构想邻域聚合'}
{'arxiv_id': 'arXiv:2509.22161', 'title': 'Pushing Toward the Simplex Vertices: A Simple Remedy for Code Collapse in Smoothed Vector Quantization', 'authors': 'Takashi Morita', 'link': 'https://arxiv.org/abs/2509.22161', 'abstract': 'Vector quantization, which discretizes a continuous vector space into a finite set of representative vectors (a codebook), has been widely adopted in modern machine learning. Despite its effectiveness, vector quantization poses a fundamental challenge: the non-differentiable quantization step blocks gradient backpropagation. Smoothed vector quantization addresses this issue by relaxing the hard assignment of a codebook vector into a weighted combination of codebook entries, represented as the matrix product of a simplex vector and the codebook. Effective smoothing requires two properties: (1) smoothed quantizers should remain close to a onehot vector, ensuring tight approximation, and (2) all codebook entries should be utilized, preventing code collapse. Existing methods typically address these desiderata separately. By contrast, the present study introduces a simple and intuitive regularization that promotes both simultaneously by minimizing the distance between each simplex vertex and its $K$-nearest smoothed quantizers. Experiments on representative benchmarks, including discrete image autoencoding and contrastive speech representation learning, demonstrate that the proposed method achieves more reliable codebook utilization and improves performance compared to prior approaches.', 'abstract_zh': '向量量化，通过将连续向量空间离散化为有限的代表向量集合（码本），在现代机器学习中已被广泛应用。尽管有效，但向量量化面临一个基本挑战：非可微的量化步骤阻碍了梯度反向传播。通过将码本书中的硬分配松弛为码本书条目的加权组合，表示为简单xes向量与码本书的矩阵乘积，平滑向量量化解决了这一问题。有效的平滑需要两个特性：（1）平滑量化器应接近于onehot向量，确保逼近的紧密性；（2）所有码本书条目都应被利用，防止码本书崩塌。现有方法通常分别处理这两个需求。相比之下，本文引入了一种简单直观的正则化方法，通过最小化每个简单xes顶点与其$K$个最近的平滑量化器之间的距离，同时促进这两个特性。在包括离散图像自编码和对比语音表示学习的代表性基准测试中，实验表明所提出的方法实现了更可靠的码本书利用，并且在性能上优于先前的方法。', 'title_zh': '逼近单纯形顶点：平滑向量量化中代码折叠的一种简单 remedy 方法'}
{'arxiv_id': 'arXiv:2509.22144', 'title': 'From Long to Lean: Performance-aware and Adaptive Chain-of-Thought Compression via Multi-round Refinement', 'authors': 'Jianzhi Yan, Le Liu, Youcheng Pan, Shiwei Chen, Zike Yuan, Yang Xiang, Buzhou Tang', 'link': 'https://arxiv.org/abs/2509.22144', 'abstract': 'Chain-of-Thought (CoT) reasoning improves performance on complex tasks but introduces significant inference latency due to verbosity. We propose Multiround Adaptive Chain-of-Thought Compression (MACC), a framework that leverages the token elasticity phenomenon--where overly small token budgets can paradoxically increase output length--to progressively compress CoTs via multiround refinement. This adaptive strategy allows MACC to determine the optimal compression depth for each input. Our method achieves an average accuracy improvement of 5.6 percent over state-of-the-art baselines, while also reducing CoT length by an average of 47 tokens and significantly lowering latency. Furthermore, we show that test-time performance--accuracy and token length--can be reliably predicted using interpretable features like perplexity and compression rate on the training set. Evaluated across different models, our method enables efficient model selection and forecasting without repeated fine-tuning, demonstrating that CoT compression is both effective and predictable. Our code will be released in this https URL.', 'abstract_zh': 'Multiround Adaptive Chain-of-Thought Compression (MACC)提升复杂任务性能的同时降低推理延迟', 'title_zh': '从长到精：基于多轮优化的性能 Awareness 和自适应链式思维压缩'}
{'arxiv_id': 'arXiv:2509.22117', 'title': 'The AI_INFN Platform: Artificial Intelligence Development in the Cloud', 'authors': 'Lucio Anderlini, Giulio Bianchini, Diego Ciangottini, Stefano Dal Pra, Diego Michelotto, Rosa Petrini, Daniele Spiga', 'link': 'https://arxiv.org/abs/2509.22117', 'abstract': "Machine Learning (ML) is driving a revolution in the way scientists design, develop, and deploy data-intensive software. However, the adoption of ML presents new challenges for the computing infrastructure, particularly in terms of provisioning and orchestrating access to hardware accelerators for development, testing, and production. The INFN-funded project AI_INFN (Artificial Intelligence at INFN) aims at fostering the adoption of ML techniques within INFN use cases by providing support on multiple aspects, including the provisioning of AI-tailored computing resources. It leverages cloud-native solutions in the context of INFN Cloud, to share hardware accelerators as effectively as possible, ensuring the diversity of the Institute's research activities is not compromised. In this contribution, we provide an update on the commissioning of a Kubernetes platform designed to ease the development of GPU-powered data analysis workflows and their scalability on heterogeneous distributed computing resources, also using the offloading mechanism with Virtual Kubelet and InterLink API. This setup can manage workflows across different resource providers, including sites of the Worldwide LHC Computing Grid and supercomputers such as CINECA Leonardo, providing a model for use cases requiring dedicated infrastructures for different parts of the workload. Initial test results, emerging case studies, and integration scenarios will be presented with functional tests and benchmarks.", 'abstract_zh': 'AI_INFN项目：基于Kubernetes平台的GPU加速数据分析流程开发与扩展研究', 'title_zh': 'AI_INFN平台：基于云的人工智能开发'}
{'arxiv_id': 'arXiv:2509.22115', 'title': 'Learning More with Less: A Dynamic Dual-Level Down-Sampling Framework for Efficient Policy Optimization', 'authors': 'Chao Wang, Tao Yang, Hongtao Tian, Yunsheng Shi, Qiyao Ma, Xiaotao Liu, Ting Yao, Wenbo Ding', 'link': 'https://arxiv.org/abs/2509.22115', 'abstract': 'Critic-free methods like GRPO reduce memory demands by estimating advantages from multiple rollouts but tend to converge slowly, as critical learning signals are diluted by an abundance of uninformative samples and tokens. To tackle this challenge, we propose the \\textbf{Dynamic Dual-Level Down-Sampling (D$^3$S)} framework that prioritizes the most informative samples and tokens across groups to improve the efficient of policy optimization. D$^3$S operates along two levels: (1) the sample-level, which selects a subset of rollouts to maximize advantage variance ($\\text{Var}(A)$). We theoretically proven that this selection is positively correlated with the upper bound of the policy gradient norms, yielding higher policy gradients. (2) the token-level, which prioritizes tokens with a high product of advantage magnitude and policy entropy ($|A_{i,t}|\\times H_{i,t}$), focusing updates on tokens where the policy is both uncertain and impactful. Moreover, to prevent overfitting to high-signal data, D$^3$S employs a dynamic down-sampling schedule inspired by curriculum learning. This schedule starts with aggressive down-sampling to accelerate early learning and gradually relaxes to promote robust generalization. Extensive experiments on Qwen2.5 and Llama3.1 demonstrate that integrating D$^3$S into advanced RL algorithms achieves state-of-the-art performance and generalization while requiring \\textit{fewer} samples and tokens across diverse reasoning benchmarks. Our code is added in the supplementary materials and will be made publicly available.', 'abstract_zh': '动态双重级别下采样（D\\(^3\\)S）框架', 'title_zh': '少而精地学习：一种高效的政策优化动态双层降采样框架'}
{'arxiv_id': 'arXiv:2509.22064', 'title': 'The QCET Taxonomy of Standard Quality Criterion Names and Definitions for the Evaluation of NLP Systems', 'authors': 'Anya Belz, Simon Mille, Craig Thomson', 'link': 'https://arxiv.org/abs/2509.22064', 'abstract': 'Prior work has shown that two NLP evaluation experiments that report results for the same quality criterion name (e.g. Fluency) do not necessarily evaluate the same aspect of quality, and the comparability implied by the name can be misleading. Not knowing when two evaluations are comparable in this sense means we currently lack the ability to draw reliable conclusions about system quality on the basis of multiple, independently conducted evaluations. This in turn hampers the ability of the field to progress scientifically as a whole, a pervasive issue in NLP since its beginning (Sparck Jones, 1981). It is hard to see how the issue of unclear comparability can be fully addressed other than by the creation of a standard set of quality criterion names and definitions that the several hundred quality criterion names actually in use in the field can be mapped to, and grounded in. Taking a strictly descriptive approach, the QCET Quality Criteria for Evaluation Taxonomy derives a standard set of quality criterion names and definitions from three surveys of evaluations reported in NLP, and structures them into a hierarchy where each parent node captures common aspects of its child nodes. We present QCET and the resources it consists of, and discuss its three main uses in (i) establishing comparability of existing evaluations, (ii) guiding the design of new evaluations, and (iii) assessing regulatory compliance.', 'abstract_zh': 'QCET质量标准评价分类体系', 'title_zh': '标准质量标准名称和定义的QCET分类体系：NLP系统评估'}
{'arxiv_id': 'arXiv:2509.22060', 'title': 'Decoding Deception: Understanding Automatic Speech Recognition Vulnerabilities in Evasion and Poisoning Attacks', 'authors': 'Aravindhan G, Yuvaraj Govindarajulu, Parin Shah', 'link': 'https://arxiv.org/abs/2509.22060', 'abstract': 'Recent studies have demonstrated the vulnerability of Automatic Speech Recognition systems to adversarial examples, which can deceive these systems into misinterpreting input speech commands. While previous research has primarily focused on white-box attacks with constrained optimizations, and transferability based black-box attacks against commercial Automatic Speech Recognition devices, this paper explores cost efficient white-box attack and non transferability black-box adversarial attacks on Automatic Speech Recognition systems, drawing insights from approaches such as Fast Gradient Sign Method and Zeroth-Order Optimization. Further, the novelty of the paper includes how poisoning attack can degrade the performances of state-of-the-art models leading to misinterpretation of audio signals. Through experimentation and analysis, we illustrate how hybrid models can generate subtle yet impactful adversarial examples with very little perturbation having Signal Noise Ratio of 35dB that can be generated within a minute. These vulnerabilities of state-of-the-art open source model have practical security implications, and emphasize the need for adversarial security.', 'abstract_zh': '最近的研究表明，自动语音识别系统容易受到对抗样本的攻击，这些攻击可以使系统错误解读输入的语音命令。尽管此前的研究主要集中在具有约束优化的白盒攻击以及针对商业自动语音识别设备的迁移性基于黑盒攻击上，本文探讨了自动语音识别系统的低成本白盒攻击和非迁移性黑盒对抗攻击，借鉴了快速梯度符号方法和零阶优化等方法。此外，本文的创新之处在于揭示了中毒攻击如何降低最新模型的性能，导致对音频信号的误解释。通过实验和分析，我们展示了混合模型可以生成具有35dB信噪比、仅需一分钟即可生成且具有轻微但影响深远的对抗样本。这些最新开源模型的安全漏洞具有实际的安全意义，并强调了对抗安全的必要性。', 'title_zh': '解码欺诈：理解自动语音识别在规避和投毒攻击中的脆弱性'}
{'arxiv_id': 'arXiv:2509.21979', 'title': 'Benchmarking and Mitigate Psychological Sycophancy in Medical Vision-Language Models', 'authors': 'Zikun Guo, Xinyue Xu, Pei Xiang, Shu Yang, Xin Han, Di Wang, Lijie Hu', 'link': 'https://arxiv.org/abs/2509.21979', 'abstract': 'Vision language models(VLMs) are increasingly integrated into clinical workflows, but they often exhibit sycophantic behavior prioritizing alignment with user phrasing social cues or perceived authority over evidence based reasoning. This study evaluate clinical sycophancy in medical visual question answering through a novel clinically grounded benchmark. We propose a medical sycophancy dataset construct from PathVQA, SLAKE, and VQA-RAD stratified by different type organ system and modality. Using psychologically motivated pressure templates including various sycophancy. In our adversarial experiments on various VLMs, we found that these models are generally vulnerable, exhibiting significant variations in the occurrence of adversarial responses, with weak correlations to the model accuracy or size. Imitation and expert provided corrections were found to be the most effective triggers, suggesting that the models possess a bias mechanism independent of visual evidence. To address this, we propose Visual Information Purification for Evidence based Response (VIPER) a lightweight mitigation strategy that filters non evidentiary content for example social pressures and then generates constrained evidence first answers. This framework reduces sycophancy by an average amount outperforming baselines while maintaining interpretability. Our benchmark analysis and mitigation framework lay the groundwork for robust deployment of medical VLMs in real world clinician interactions emphasizing the need for evidence anchored defenses.', 'abstract_zh': '医学视觉问答中临床奉承现象的评估：基于临床背景的新基准及视觉信息净化以生成基于证据的响应（VIPER）方法', 'title_zh': '医学视觉-语言模型中心理阿谀现象的基准测试与缓解'}
{'arxiv_id': 'arXiv:2509.21976', 'title': 'Geo-R1: Improving Few-Shot Geospatial Referring Expression Understanding with Reinforcement Fine-Tuning', 'authors': 'Zilun Zhang, Zian Guan, Tiancheng Zhao, Haozhan Shen, Tianyu Li, Yuxiang Cai, Zhonggen Su, Zhaojun Liu, Jianwei Yin, Xiang Li', 'link': 'https://arxiv.org/abs/2509.21976', 'abstract': 'Referring expression understanding in remote sensing poses unique challenges, as it requires reasoning over complex object-context relationships. While supervised fine-tuning (SFT) on multimodal large language models achieves strong performance with massive labeled datasets, they struggle in data-scarce scenarios, leading to poor generalization. To address this limitation, we propose Geo-R1, a reasoning-centric reinforcement fine-tuning (RFT) paradigm for few-shot geospatial referring. Geo-R1 enforces the model to first generate explicit, interpretable reasoning chains that decompose referring expressions, and then leverage these rationales to localize target objects. This "reason first, then act" process enables the model to make more effective use of limited annotations, enhances generalization, and provides interpretability. We validate Geo-R1 on three carefully designed few-shot geospatial referring benchmarks, where our model consistently and substantially outperforms SFT baselines. It also demonstrates strong cross-dataset generalization, highlighting its robustness. Code and data will be released at this http URL.', 'abstract_zh': '遥感中的指代表达理解面临着独特的挑战，因为它需要推理复杂的目标-上下文关系。尽管在多模态大语言模型上进行有监督微调（SFT）可以使用大量标注数据获得优异性能，但在数据稀疏场景下却表现不佳，导致泛化能力差。为解决这一局限性，我们提出Geo-R1，这是一种以推理为中心的强化微调（RFT）范式，用于少量样本的地理空间指代。Geo-R1 要求模型首先生成明确且可解释的推理链来分解指代表达，然后利用这些理由来定位目标对象。这一“先推理后行动”的过程使模型能够更有效地利用有限的标注信息，增强泛化能力和可解释性。我们在三个精心设计的少量样本地理空间指代基准上验证了Geo-R1，其中我们的模型在所有基准上都一致且显著地优于SFT基线。同时，它还展示了强大的跨数据集泛化能力，突显了其鲁棒性。代码和数据将发布在该网址。', 'title_zh': 'Geo-R1: 通过强化微调改进 Few-Shot 地理空间参考表达理解'}
{'arxiv_id': 'arXiv:2509.21945', 'title': 'Unveiling Many Faces of Surrogate Models for Configuration Tuning: A Fitness Landscape Analysis Perspective', 'authors': 'Pengzhou Chen, Hongyuan Liang, Tao Chen', 'link': 'https://arxiv.org/abs/2509.21945', 'abstract': 'To efficiently tune configuration for better system performance (e.g., latency), many tuners have leveraged a surrogate model to expedite the process instead of solely relying on the profoundly expensive system measurement. As such, it is naturally believed that we need more accurate models. However, the fact of accuracy can lie-a somewhat surprising finding from prior work-has left us many unanswered questions regarding what role the surrogate model plays in configuration tuning. This paper provides the very first systematic exploration and discussion, together with a resolution proposal, to disclose the many faces of surrogate models for configuration tuning, through the novel perspective of fitness landscape analysis. We present a theory as an alternative to accuracy for assessing the model usefulness in tuning, based on which we conduct an extensive empirical study involving up to 27,000 cases. Drawing on the above, we propose Model4Tune, an automated predictive tool that estimates which model-tuner pairs are the best for an unforeseen system without expensive tuner profiling. Our results suggest that Moldel4Tune, as one of the first of its kind, performs significantly better than random guessing in 79%-82% of the cases. Our results not only shed light on the possible future research directions but also offer a practical resolution that can assist practitioners in evaluating the most useful model for configuration tuning.', 'abstract_zh': '高效调参以改善系统性能（如延迟）： surrogate模型的作用与展望', 'title_zh': '探究代理模型在配置调整中多样化的一面：从适应度景观分析视角'}
{'arxiv_id': 'arXiv:2509.21925', 'title': 'Generation Properties of Stochastic Interpolation under Finite Training Set', 'authors': 'Yunchen Li, Shaohui Lin, Zhou Yu', 'link': 'https://arxiv.org/abs/2509.21925', 'abstract': 'This paper investigates the theoretical behavior of generative models under finite training populations. Within the stochastic interpolation generative framework, we derive closed-form expressions for the optimal velocity field and score function when only a finite number of training samples are available. We demonstrate that, under some regularity conditions, the deterministic generative process exactly recovers the training samples, while the stochastic generative process manifests as training samples with added Gaussian noise. Beyond the idealized setting, we consider model estimation errors and introduce formal definitions of underfitting and overfitting specific to generative models. Our theoretical analysis reveals that, in the presence of estimation errors, the stochastic generation process effectively produces convex combinations of training samples corrupted by a mixture of uniform and Gaussian noise. Experiments on generation tasks and downstream tasks such as classification support our theory.', 'abstract_zh': '本文探讨了在有限训练样本情况下生成模型的理论行为。在随机插值生成框架下，我们推导出了仅使用有限数量训练样本时的最佳速度场和评分函数的闭式表达式。我们证明，在某些正则性条件下，确定性的生成过程能精确恢复训练样本，而随机的生成过程则表现为含有高斯噪声的训练样本。在理想化设定之外，我们考虑了模型估计误差，并提出了针对生成模型的过拟合和欠拟合的正式定义。我们的理论分析表明，在存在估计误差的情况下，随机生成过程有效产生了受到均匀噪声和高斯噪声混合影响的训练样本的凸组合。实验结果在生成任务和分类等下游任务中支持了我们的理论。', 'title_zh': '有限训练集下随机插值的生成性质'}
{'arxiv_id': 'arXiv:2509.21892', 'title': 'Elastic MoE: Unlocking the Inference-Time Scalability of Mixture-of-Experts', 'authors': 'Naibin Gu, Zhenyu Zhang, Yuchen Feng, Yilong Chen, Peng Fu, Zheng Lin, Shuohuan Wang, Yu Sun, Hua Wu, Weiping Wang, Haifeng Wang', 'link': 'https://arxiv.org/abs/2509.21892', 'abstract': "Mixture-of-Experts (MoE) models typically fix the number of activated experts $k$ at both training and inference. Intuitively, activating more experts at inference $k'$ (where $k'> k$) means engaging a larger set of model parameters for the computation and thus is expected to improve performance. However, contrary to this intuition, we find the scaling range to be so narrow that performance begins to degrade rapidly after only a slight increase in the number of experts. Further investigation reveals that this degradation stems from a lack of learned collaboration among experts. To address this, we introduce Elastic Mixture-of-Experts (EMoE), a novel training framework that enables MoE models to scale the number of activated experts at inference without incurring additional training overhead. By simultaneously training experts to collaborate in diverse combinations and encouraging the router for high-quality selections, EMoE ensures robust performance across computational budgets at inference. We conduct extensive experiments on various MoE settings. Our results show that EMoE significantly expands the effective performance-scaling range, extending it to as much as 2-3$\\times$ the training-time $k$, while also pushing the model's peak performance to a higher level.", 'abstract_zh': '弹性专家混合（EMoE）模型：一种无需额外训练开销即可在推理时扩大激活专家数量的新型训练框架', 'title_zh': '弹性MoE：解锁混合专家模型的推理时扩展性'}
{'arxiv_id': 'arXiv:2509.21882', 'title': 'Position: The Hidden Costs and Measurement Gaps of Reinforcement Learning with Verifiable Rewards', 'authors': 'Aaron Tu, Weihao Xuan, Heli Qi, Xu Huang, Qingcheng Zeng, Shayan Talaei, Yijia Xiao, Peng Xia, Xiangru Tang, Yuchen Zhuang, Bing Hu, Hanqun Cao, Wenqi Shi, Tianang Leng, Rui Yang, Yingjian Chen, Ziqi Wang, Irene Li, Nan Liu, Huaxiu Yao, Li Erran Li, Ge Liu, Amin Saberi, Naoto Yokoya, Jure Leskovec, Yejin Choi, Fang Wu', 'link': 'https://arxiv.org/abs/2509.21882', 'abstract': 'Reinforcement learning with verifiable rewards (RLVR) is a practical and scalable approach to enhancing large language models in areas such as math, code, and other structured tasks. Two questions motivate this paper: how much of the reported gains survive under strictly parity-controlled evaluation, and whether RLVR is cost-free or exacts a measurable tax. We argue that progress is real, but gains are often overstated due to three forces - an RLVR tax, evaluation pitfalls, and data contamination. Using a partial-prompt contamination audit and matched-budget reproductions across base and RL models, we show that several headline gaps shrink or vanish under clean, parity-controlled evaluation. We then propose a tax-aware training and evaluation protocol that co-optimizes accuracy, grounding, and calibrated abstention and standardizes budgeting and provenance checks. Applied to recent RLVR setups, this protocol yields more reliable estimates of reasoning gains and, in several cases, revises prior conclusions. Our position is constructive: RLVR is valuable and industry-ready; we advocate keeping its practical benefits while prioritizing reliability, safety, and measurement.', 'abstract_zh': '验证奖励强化学习（RLVR）：在数学、代码及其他结构化任务领域增强大型语言模型的实用且可扩展的方法。本文探讨了两个问题：在严格对等控制评估下，报告的增益有多大部分得以保留，以及RLVR是否无成本或是否付出可量化的代价。我们认为进展是真实的，但由于三种力量——RLVR税、评估陷阱和数据污染，增益往往被夸大了。通过部分指令污染审计和基模型与RL模型的匹配预算再现，我们在严格的对等控制评估下展示了若干关键差距缩小或消失。我们随后提出了一种考虑税收的训练和评估协议，该协议同时优化精度、扎根和校准后的回避，并标准化预算和出处检查。将该协议应用于最近的RLVR设置，可以获得更多可靠的推理增益估计，在某些情况下修正了先前的结论。我们的立场是建设性的：RLVR是有价值且准备好投入工业应用的；我们提倡保留其实际收益，同时优先考虑可靠性、安全性和量测。', 'title_zh': '位置：验证性奖励强化学习的隐含成本与测量缺口'}
{'arxiv_id': 'arXiv:2509.21847', 'title': 'Beyond Johnson-Lindenstrauss: Uniform Bounds for Sketched Bilinear Forms', 'authors': 'Rohan Deb, Qiaobo Li, Mayank Shrivastava, Arindam Banerjee', 'link': 'https://arxiv.org/abs/2509.21847', 'abstract': 'Uniform bounds on sketched inner products of vectors or matrices underpin several important computational and statistical results in machine learning and randomized algorithms, including the Johnson-Lindenstrauss (J-L) lemma, the Restricted Isometry Property (RIP), randomized sketching, and approximate linear algebra. However, many modern analyses involve *sketched bilinear forms*, for which existing uniform bounds either do not apply or are not sharp on general sets. In this work, we develop a general framework to analyze such sketched bilinear forms and derive uniform bounds in terms of geometric complexities of the associated sets. Our approach relies on generic chaining and introduces new techniques for handling suprema over pairs of sets. We further extend these results to the setting where the bilinear form involves a sum of $T$ independent sketching matrices and show that the deviation scales as $\\sqrt{T}$. This unified analysis recovers known results such as the J-L lemma as special cases, while extending RIP-type guarantees. Additionally, we obtain improved convergence bounds for sketched Federated Learning algorithms where such cross terms arise naturally due to sketched gradient compression, and design sketched variants of bandit algorithms with sharper regret bounds that depend on the geometric complexity of the action and parameter sets, rather than the ambient dimension.', 'abstract_zh': '统一的草图下双线性形式的上界：机器学习和随机化算法中若干重要计算与统计结果的基础，及其在几何复杂性下的分析', 'title_zh': '超越约翰逊-林德斯特朗斯ltrauss：草帽下界与拟合双线性形式的统一边界'}
{'arxiv_id': 'arXiv:2509.21802', 'title': 'ChaosNexus: A Foundation Model for Universal Chaotic System Forecasting with Multi-scale Representations', 'authors': 'Chang Liu, Bohao Zhao, Jingtao Ding, Yong Li', 'link': 'https://arxiv.org/abs/2509.21802', 'abstract': 'Accurately forecasting chaotic systems, prevalent in domains such as weather prediction and fluid dynamics, remains a significant scientific challenge. The inherent sensitivity of these systems to initial conditions, coupled with a scarcity of observational data, severely constrains traditional modeling approaches. Since these models are typically trained for a specific system, they lack the generalization capacity necessary for real-world applications, which demand robust zero-shot or few-shot forecasting on novel or data-limited scenarios. To overcome this generalization barrier, we propose ChaosNexus, a foundation model pre-trained on a diverse corpus of chaotic dynamics. ChaosNexus employs a novel multi-scale architecture named ScaleFormer augmented with Mixture-of-Experts layers, to capture both universal patterns and system-specific behaviors. The model demonstrates state-of-the-art zero-shot generalization across both synthetic and real-world benchmarks. On a large-scale testbed comprising over 9,000 synthetic chaotic systems, it improves the fidelity of long-term attractor statistics by more than 40% compared to the leading baseline. This robust performance extends to real-world applications with exceptional data efficiency. For instance, in 5-day global weather forecasting, ChaosNexus achieves a competitive zero-shot mean error below 1 degree, a result that further improves with few-shot fine-tuning. Moreover, experiments on the scaling behavior of ChaosNexus provide a guiding principle for scientific foundation models: cross-system generalization stems from the diversity of training systems, rather than sheer data volume.', 'abstract_zh': '准确预测气象预测和流体动力学等领域中普遍存在的混沌系统仍然是一个重大的科学挑战。由于这些系统对初始条件的高度敏感性以及观测数据的稀缺性，传统建模方法受到了严重限制。由于这些模型通常仅针对特定系统进行训练，因此缺乏在实际应用中所需的在新颖数据或数据有限场景下进行零样本或少样本预测的能力。为克服这一泛化障碍，我们提出了一种基于多样化混沌动力学语料库预训练的基座模型ChaosNexus。ChaosNexus采用了一种名为ScaleFormer的新颖多尺度架构并结合了Mixture-of-Experts层，以捕捉通用模式和系统特定行为。该模型在合成和真实世界基准测试中均表现出最先进的零样本泛化能力。在包含超过9,000个合成混沌系统的大型测试平台上，与领先的基线相比，ChaosNexus在长期吸引子统计的准确性上提高了超过40%。这一稳健的性能还扩展到了实际应用中，并且具有出色的数据效率。例如，在5天全球天气预报中，ChaosNexus实现了竞争性的零样本平均误差低于1度，而通过少量样本微调可进一步提高性能。此外，ChaosNexus的缩放行为实验为科学基座模型提供了一条指导原则：跨系统泛化源于训练系统的多样性，而非单纯的数据量。', 'title_zh': 'ChaosNexus: 一种基于多尺度表示的通用混沌系统预测基础模型'}
{'arxiv_id': 'arXiv:2509.21785', 'title': 'Unbiased Binning: Fairness-aware Attribute Representation', 'authors': 'Abolfazl Asudeh, Zeinab, Asoodeh, Bita Asoodeh, Omid Asudeh', 'link': 'https://arxiv.org/abs/2509.21785', 'abstract': 'Discretizing raw features into bucketized attribute representations is a popular step before sharing a dataset. It is, however, evident that this step can cause significant bias in data and amplify unfairness in downstream tasks.\nIn this paper, we address this issue by introducing the unbiased binning problem that, given an attribute to bucketize, finds its closest discretization to equal-size binning that satisfies group parity across different buckets. Defining a small set of boundary candidates, we prove that unbiased binning must select its boundaries from this set. We then develop an efficient dynamic programming algorithm on top of the boundary candidates to solve the unbiased binning problem.\nFinding an unbiased binning may sometimes result in a high price of fairness, or it may not even exist, especially when group values follow different distributions. Considering that a small bias in the group ratios may be tolerable in such settings, we introduce the epsilon-biased binning problem that bounds the group disparities across buckets to a small value epsilon. We first develop a dynamic programming solution, DP, that finds the optimal binning in quadratic time. The DP algorithm, while polynomial, does not scale to very large settings. Therefore, we propose a practically scalable algorithm, based on local search (LS), for epsilon-biased binning. The key component of the LS algorithm is a divide-and-conquer (D&C) algorithm that finds a near-optimal solution for the problem in near-linear time. We prove that D&C finds a valid solution for the problem unless none exists. The LS algorithm then initiates a local search, using the D&C solution as the upper bound, to find the optimal solution.', 'abstract_zh': '无偏分箱问题：寻找满足群体平等的最优分箱方法', 'title_zh': '无偏分箱：公平感知属性表示'}
{'arxiv_id': 'arXiv:2509.21778', 'title': 'Beyond Structure: Invariant Crystal Property Prediction with Pseudo-Particle Ray Diffraction', 'authors': 'Bin Cao, Yang Liu, Longhan Zhang, Yifan Wu, Zhixun Li, Yuyu Luo, Hong Cheng, Yang Ren, Tong-Yi Zhang', 'link': 'https://arxiv.org/abs/2509.21778', 'abstract': 'Crystal property prediction, governed by quantum mechanical principles, is computationally prohibitive to solve exactly for large many-body systems using traditional density functional theory. While machine learning models have emerged as efficient approximations for large-scale applications, their performance is strongly influenced by the choice of atomic representation. Although modern graph-based approaches have progressively incorporated more structural information, they often fail to capture long-term atomic interactions due to finite receptive fields and local encoding schemes. This limitation leads to distinct crystals being mapped to identical representations, hindering accurate property prediction. To address this, we introduce PRDNet that leverages unique reciprocal-space diffraction besides graph representations. To enhance sensitivity to elemental and environmental variations, we employ a data-driven pseudo-particle to generate a synthetic diffraction pattern. PRDNet ensures full invariance to crystallographic symmetries. Extensive experiments are conducted on Materials Project, JARVIS-DFT, and MatBench, demonstrating that the proposed model achieves state-of-the-art performance.', 'abstract_zh': '基于量子力学原理的晶体性质预测对于大规模系统来说使用传统密度泛函理论进行精确计算是计算上不可行的。虽然机器学习模型已成为大规模应用的有效近似方法，但其性能强烈依赖于原子表示的选择。尽管现代基于图的方法逐渐引入了更多的结构信息，但由于有限的感受野和局部编码方案，它们往往无法捕捉长期的原子相互作用。这一限制导致不同的晶体被映射到相同的表示，阻碍了准确的性质预测。为解决这一问题，我们引入了PRDNet，它结合了独特的倒易空间衍射以及图表示。为增强对元素和环境变化的敏感性，我们采用数据驱动的伪粒子生成合成衍射图。PRDNet 确保了对晶体学对称性的完全不变性。在广泛的实验中，我们在Materials Project、JARVIS-DFT 和 MatBench 上进行实验，证明所提出的模型达到了最先进的性能。', 'title_zh': '超越结构：基于伪粒子射线衍射的Invariant晶体属性预测'}
{'arxiv_id': 'arXiv:2509.21748', 'title': 'SubZeroCore: A Submodular Approach with Zero Training for Coreset Selection', 'authors': 'Brian B. Moser, Tobias C. Nauen, Arundhati S. Shanbhag, Federico Raue, Stanislav Frolov, Joachim Folz, Andreas Dengel', 'link': 'https://arxiv.org/abs/2509.21748', 'abstract': 'The goal of coreset selection is to identify representative subsets of datasets for efficient model training. Yet, existing approaches paradoxically require expensive training-based signals, e.g., gradients, decision boundary estimates or forgetting counts, computed over the entire dataset prior to pruning, which undermines their very purpose by requiring training on samples they aim to avoid. We introduce SubZeroCore, a novel, training-free coreset selection method that integrates submodular coverage and density into a single, unified objective. To achieve this, we introduce a sampling strategy based on a closed-form solution to optimally balance these objectives, guided by a single hyperparameter that explicitly controls the desired coverage for local density measures. Despite no training, extensive evaluations show that SubZeroCore matches training-based baselines and significantly outperforms them at high pruning rates, while dramatically reducing computational overhead. SubZeroCore also demonstrates superior robustness to label noise, highlighting its practical effectiveness and scalability for real-world scenarios.', 'abstract_zh': '基于子模覆盖和密度的训练免费核集选择方法SubZeroCore', 'title_zh': 'SubZeroCore: 一种无需训练的子模态方法用于核心样本选择'}
{'arxiv_id': 'arXiv:2509.21746', 'title': 'HyperCore: Coreset Selection under Noise via Hypersphere Models', 'authors': 'Brian B. Moser, Arundhati S. Shanbhag, Tobias C. Nauen, Stanislav Frolov, Federico Raue, Joachim Folz, Andreas Dengel', 'link': 'https://arxiv.org/abs/2509.21746', 'abstract': "The goal of coreset selection methods is to identify representative subsets of datasets for efficient model training. Yet, existing methods often ignore the possibility of annotation errors and require fixed pruning ratios, making them impractical in real-world settings. We present HyperCore, a robust and adaptive coreset selection framework designed explicitly for noisy environments. HyperCore leverages lightweight hypersphere models learned per class, embedding in-class samples close to a hypersphere center while naturally segregating out-of-class samples based on their distance. By using Youden's J statistic, HyperCore can adaptively select pruning thresholds, enabling automatic, noise-aware data pruning without hyperparameter tuning. Our experiments reveal that HyperCore consistently surpasses state-of-the-art coreset selection methods, especially under noisy and low-data regimes. HyperCore effectively discards mislabeled and ambiguous points, yielding compact yet highly informative subsets suitable for scalable and noise-free learning.", 'abstract_zh': '基于噪声环境的稳健自适应核集选择框架HyperCore', 'title_zh': 'HyperCore: 基于超球体模型下的噪声环境下核心子集选择'}
{'arxiv_id': 'arXiv:2509.21742', 'title': 'Brain PathoGraph Learning', 'authors': 'Ciyuan Peng, Nguyen Linh Dan Le, Shan Jin, Dexuan Ding, Shuo Yu, Feng Xia', 'link': 'https://arxiv.org/abs/2509.21742', 'abstract': 'Brain graph learning has demonstrated significant achievements in the fields of neuroscience and artificial intelligence. However, existing methods struggle to selectively learn disease-related knowledge, leading to heavy parameters and computational costs. This challenge diminishes their efficiency, as well as limits their practicality for real-world clinical applications. To this end, we propose a lightweight Brain PathoGraph Learning (BrainPoG) model that enables efficient brain graph learning by pathological pattern filtering and pathological feature distillation. Specifically, BrainPoG first contains a filter to extract the pathological pattern formulated by highly disease-relevant subgraphs, achieving graph pruning and lesion localization. A PathoGraph is therefore constructed by dropping less disease-relevant subgraphs from the whole brain graph. Afterwards, a pathological feature distillation module is designed to reduce disease-irrelevant noise features and enhance pathological features of each node in the PathoGraph. BrainPoG can exclusively learn informative disease-related knowledge while avoiding less relevant information, achieving efficient brain graph learning. Extensive experiments on four benchmark datasets demonstrate that BrainPoG exhibits superiority in both model performance and computational efficiency across various brain disease detection tasks.', 'abstract_zh': '轻量级脑病理图学习（BrainPoG）模型：通过病理模式过滤和病理特征 distilled 的高效脑图学习', 'title_zh': '脑病理图学习'}
{'arxiv_id': 'arXiv:2509.21735', 'title': "Uncovering Alzheimer's Disease Progression via SDE-based Spatio-Temporal Graph Deep Learning on Longitudinal Brain Networks", 'authors': "Houliang Zhou, Rong Zhou, Yangying Liu, Kanhao Zhao, Li Shen, Brian Y. Chen, Yu Zhang, Lifang He, Alzheimer's Disease Neuroimaging Initiative", 'link': 'https://arxiv.org/abs/2509.21735', 'abstract': "Identifying objective neuroimaging biomarkers to forecast Alzheimer's disease (AD) progression is crucial for timely intervention. However, this task remains challenging due to the complex dysfunctions in the spatio-temporal characteristics of underlying brain networks, which are often overlooked by existing methods. To address these limitations, we develop an interpretable spatio-temporal graph neural network framework to predict future AD progression, leveraging dual Stochastic Differential Equations (SDEs) to model the irregularly-sampled longitudinal functional magnetic resonance imaging (fMRI) data. We validate our approach on two independent cohorts, including the Open Access Series of Imaging Studies (OASIS-3) and the Alzheimer's Disease Neuroimaging Initiative (ADNI). Our framework effectively learns sparse regional and connective importance probabilities, enabling the identification of key brain circuit abnormalities associated with disease progression. Notably, we detect the parahippocampal cortex, prefrontal cortex, and parietal lobule as salient regions, with significant disruptions in the ventral attention, dorsal attention, and default mode networks. These abnormalities correlate strongly with longitudinal AD-related clinical symptoms. Moreover, our interpretability strategy reveals both established and novel neural systems-level and sex-specific biomarkers, offering new insights into the neurobiological mechanisms underlying AD progression. Our findings highlight the potential of spatio-temporal graph-based learning for early, individualized prediction of AD progression, even in the context of irregularly-sampled longitudinal imaging data.", 'abstract_zh': '基于时空图神经网络的客观神经成像生物标志物识别以预测阿尔茨海默病进展', 'title_zh': '基于SDE驱动的空间-时间图深度学习揭示阿尔茨海默病进展'}
{'arxiv_id': 'arXiv:2509.21733', 'title': 'UISim: An Interactive Image-Based UI Simulator for Dynamic Mobile Environments', 'authors': 'Jiannan Xiang, Yun Zhu, Lei Shu, Maria Wang, Lijun Yu, Gabriel Barcik, James Lyon, Srinivas Sunkara, Jindong Chen', 'link': 'https://arxiv.org/abs/2509.21733', 'abstract': 'Developing and testing user interfaces (UIs) and training AI agents to interact with them are challenging due to the dynamic and diverse nature of real-world mobile environments. Existing methods often rely on cumbersome physical devices or limited static analysis of screenshots, which hinders scalable testing and the development of intelligent UI agents. We introduce UISim, a novel image-based UI simulator that offers a dynamic and interactive platform for exploring mobile phone environments purely from screen images. Our system employs a two-stage method: given an initial phone screen image and a user action, it first predicts the abstract layout of the next UI state, then synthesizes a new, visually consistent image based on this predicted layout. This approach enables the realistic simulation of UI transitions. UISim provides immediate practical benefits for UI testing, rapid prototyping, and synthetic data generation. Furthermore, its interactive capabilities pave the way for advanced applications, such as UI navigation task planning for AI agents. Our experimental results show that UISim outperforms end-to-end UI generation baselines in generating realistic and coherent subsequent UI states, highlighting its fidelity and potential to streamline UI development and enhance AI agent training.', 'abstract_zh': '基于图像的用户界面模拟器（UISim）：探索移动环境的新范式', 'title_zh': 'UISim：一种用于动态移动环境的交互式图像基UI模拟器'}
{'arxiv_id': 'arXiv:2509.21713', 'title': 'Developing Strategies to Increase Capacity in AI Education', 'authors': 'Noah Q. Cowit, Sri Yash Tadimalla, Stephanie T. Jones, Mary Lou Maher, Tracy Camp, Enrico Pontelli', 'link': 'https://arxiv.org/abs/2509.21713', 'abstract': 'Many institutions are currently grappling with teaching artificial intelligence (AI) in the face of growing demand and relevance in our world. The Computing Research Association (CRA) has conducted 32 moderated virtual roundtable discussions of 202 experts committed to improving AI education. These discussions slot into four focus areas: AI Knowledge Areas and Pedagogy, Infrastructure Challenges in AI Education, Strategies to Increase Capacity in AI Education, and AI Education for All. Roundtables were organized around institution type to consider the particular goals and resources of different AI education environments. We identified the following high-level community needs to increase capacity in AI education. A significant digital divide creates major infrastructure hurdles, especially for smaller and under-resourced institutions. These challenges manifest as a shortage of faculty with AI expertise, who also face limited time for reskilling; a lack of computational infrastructure for students and faculty to develop and test AI models; and insufficient institutional technical support. Compounding these issues is the large burden associated with updating curricula and creating new programs. To address the faculty gap, accessible and continuous professional development is crucial for faculty to learn about AI and its ethical dimensions. This support is particularly needed for under-resourced institutions and must extend to faculty both within and outside of computing programs to ensure all students have access to AI education. We have compiled and organized a list of resources that our participant experts mentioned throughout this study. These resources contribute to a frequent request heard during the roundtables: a central repository of AI education resources for institutions to freely use across higher education.', 'abstract_zh': '当前，许多机构正面临着在日益增长的需求和重要性面前讲授人工智能（AI）的挑战。美国计算机研究协会（CRA）组织了32次 moderated虚拟圆桌讨论，涉及202位致力于改进AI教育的专家。这些讨论集中在四个重点领域：AI知识领域和教学方法、AI教育中的基础设施挑战、增加AI教育容量的策略、以及面向所有人的AI教育。根据机构类型组织圆桌讨论，以考虑不同AI教育环境的特定目标和资源。我们识别出了以下提高AI教育容量的高层次社区需求。显著的数字鸿沟造成了重大的基础设施障碍，尤其是对小型和资源不足的机构而言。这些挑战表现为缺乏具有AI专长的教师，他们面对重新培训的时间有限；缺少供学生和教师开发和测试AI模型的计算基础设施；以及机构技术支持不足。随着这些问题的加剧，更新课程和创建新计划所需的工作量巨大。为解决师资缺口，为教师提供可访问且持续的专业发展是关键，使他们了解AI及其伦理维度。这尤其对资源不足的机构很重要，并且必须覆盖计算项目内外的教师，以确保所有学生都能获得AI教育。我们汇总并组织了在整个研究过程中我们的专家提及的一系列资源。这些资源满足了圆桌讨论中一个频繁听到的要求：为高等教育机构提供一个中央AI教育资源库，供其自由使用。', 'title_zh': '开发策略以提高人工智能教育容量'}
{'arxiv_id': 'arXiv:2509.21712', 'title': 'Not My Agent, Not My Boundary? Elicitation of Personal Privacy Boundaries in AI-Delegated Information Sharing', 'authors': 'Bingcan Guo, Eryue Xu, Zhiping Zhang, Tianshi Li', 'link': 'https://arxiv.org/abs/2509.21712', 'abstract': "Aligning AI systems with human privacy preferences requires understanding individuals' nuanced disclosure behaviors beyond general norms. Yet eliciting such boundaries remains challenging due to the context-dependent nature of privacy decisions and the complex trade-offs involved. We present an AI-powered elicitation approach that probes individuals' privacy boundaries through a discriminative task. We conducted a between-subjects study that systematically varied communication roles and delegation conditions, resulting in 1,681 boundary specifications from 169 participants for 61 scenarios. We examined how these contextual factors and individual differences influence the boundary specification. Quantitative results show that communication roles influence individuals' acceptance of detailed and identifiable disclosure, AI delegation and individuals' need for privacy heighten sensitivity to disclosed identifiers, and AI delegation results in less consensus across individuals. Our findings highlight the importance of situating privacy preference elicitation within real-world data flows. We advocate using nuanced privacy boundaries as an alignment goal for future AI systems.", 'abstract_zh': '将AI系统与人类隐私偏好相一致需要超越一般规范理解个体复杂的披露行为。然而，由于隐私决策具有情境依赖性以及其中复杂的权衡，获取这些边界仍然具有挑战性。我们提出了一种基于AI的提取方法，通过区分性任务探究个体的隐私边界。我们进行了一项被试间研究，系统地变化了沟通角色和委托条件，共获得了169名参与者在61种情景下的1,681个边界规范。我们探讨了这些情境因素和个体差异如何影响边界规范。定量结果显示，沟通角色影响个体对详细和可识别披露的接受度，AI委托增加了对披露标识符的敏感性，AI委托导致个体之间的共识较低。我们的研究结果强调，在实际数据流中定位隐私偏好提取的重要性，并建议将细腻的隐私边界作为未来AI系统的对齐目标。', 'title_zh': '不是我的代理，不是我的边界？人工智能代理下的个人信息边界 elicitation'}
{'arxiv_id': 'arXiv:2509.21709', 'title': 'Optimizing the non-Clifford-count in unitary synthesis using Reinforcement Learning', 'authors': 'David Kremer, Ali Javadi-Abhari, Priyanka Mukhopadhyay', 'link': 'https://arxiv.org/abs/2509.21709', 'abstract': 'An efficient implementation of unitary operators is important in order to practically realize the computational advantages claimed by quantum algorithms over their classical counterparts. In this paper we study the potential of using reinforcement learning (RL) in order to synthesize quantum circuits, while optimizing the T-count and CS-count, of unitaries that are exactly implementable by the Clifford+T and Clifford+CS gate sets, respectively. In general, the complexity of existing algorithms depend exponentially on the number of qubits and the non-Clifford-count of unitaries. We have designed our RL framework to work with channel representation of unitaries, that enables us to perform matrix operations efficiently, using integers only. We have also incorporated pruning heuristics and a canonicalization of operators, in order to reduce the search complexity. As a result, compared to previous works, we are able to implement significantly larger unitaries, in less time, with much better success rate and improvement factor. Our results for Clifford+T synthesis on two qubits achieve close-to-optimal decompositions for up to 100 T gates, 5 times more than previous RL algorithms and to the best of our knowledge, the largest instances achieved with any method to date. Our RL algorithm is able to recover previously-known optimal linear complexity algorithm for T-count-optimal decomposition of 1 qubit unitaries. For 2-qubit Clifford+CS unitaries, our algorithm achieves a linear complexity, something that could only be accomplished by a previous algorithm using $SO(6)$ representation.', 'abstract_zh': '使用强化学习合成Clifford+T和Clifford+CS门集中可精确实现的量子电路：提高T计数和CS计数的高效实现', 'title_zh': '使用强化学习优化单元ary合成中的非Clifford门数量'}
{'arxiv_id': 'arXiv:2509.21674', 'title': 'QueryGym: Step-by-Step Interaction with Relational Databases', 'authors': 'Haritha Ananthakrishanan, Harsha Kokel, Kelsey Sikes, Debarun Bhattacharjya, Michael Katz, Shirin Sohrabi, Kavitha Srinivas', 'link': 'https://arxiv.org/abs/2509.21674', 'abstract': 'We introduce QueryGym, an interactive environment for building, testing, and evaluating LLM-based query planning agents. Existing frameworks often tie agents to specific query language dialects or obscure their reasoning; QueryGym instead requires agents to construct explicit sequences of relational algebra operations, ensuring engine-agnostic evaluation and transparent step-by-step planning. The environment is implemented as a Gymnasium interface that supplies observations -- including schema details, intermediate results, and execution feedback -- and receives actions that represent database exploration (e.g., previewing tables, sampling column values, retrieving unique values) as well as relational algebra operations (e.g., filter, project, join). We detail the motivation and the design of the environment. In the demo, we showcase the utility of the environment by contrasting it with contemporary LLMs that query databases. QueryGym serves as a practical testbed for research in error remediation, transparency, and reinforcement learning for query generation. For the associated demo, see this https URL.', 'abstract_zh': 'QueryGym：一种用于构建、测试和评估基于LLM的查询规划代理的互动环境', 'title_zh': 'QueryGym: 逐步与关系数据库交互'}
{'arxiv_id': 'arXiv:2509.21673', 'title': 'SlotFM: A Motion Foundation Model with Slot Attention for Diverse Downstream Tasks', 'authors': 'Junyong Park, Oron Levy, Rebecca Adaimi, Asaf Liberman, Gierad Laput, Abdelkareem Bedri', 'link': 'https://arxiv.org/abs/2509.21673', 'abstract': 'Wearable accelerometers are used for a wide range of applications, such as gesture recognition, gait analysis, and sports monitoring. Yet most existing foundation models focus primarily on classifying common daily activities such as locomotion and exercise, limiting their applicability to the broader range of tasks that rely on other signal characteristics. We present SlotFM, an accelerometer foundation model that generalizes across diverse downstream tasks. SlotFM uses Time-Frequency Slot Attention, an extension of Slot Attention that processes both time and frequency representations of the raw signals. It generates multiple small embeddings (slots), each capturing different signal components, enabling task-specific heads to focus on the most relevant parts of the data. We also introduce two loss regularizers that capture local structure and frequency patterns, which improve reconstruction of fine-grained details and helps the embeddings preserve task-relevant information. We evaluate SlotFM on 16 classification and regression downstream tasks that extend beyond standard human activity recognition. It outperforms existing self-supervised approaches on 13 of these tasks and achieves comparable results to the best performing approaches on the remaining tasks. On average, our method yields a 4.5% performance gain, demonstrating strong generalization for sensing foundation models.', 'abstract_zh': '可穿戴加速度计在多样下游任务中的通用基础模型：SlotFM', 'title_zh': 'SlotFM：一种具有槽注意机制的运动基础模型及其在多样的下游任务中的应用'}
{'arxiv_id': 'arXiv:2509.21666', 'title': 'DIM: Enforcing Domain-Informed Monotonicity in Deep Neural Networks', 'authors': 'Joshua Salim, Jordan Yu, Xilei Zhao', 'link': 'https://arxiv.org/abs/2509.21666', 'abstract': 'While deep learning models excel at predictive tasks, they often overfit due to their complex structure and large number of parameters, causing them to memorize training data, including noise, rather than learn patterns that generalize to new data. To tackle this challenge, this paper proposes a new regularization method, i.e., Enforcing Domain-Informed Monotonicity in Deep Neural Networks (DIM), which maintains domain-informed monotonic relationships in complex deep learning models to further improve predictions. Specifically, our method enforces monotonicity by penalizing violations relative to a linear baseline, effectively encouraging the model to follow expected trends while preserving its predictive power. We formalize this approach through a comprehensive mathematical framework that establishes a linear reference, measures deviations from monotonic behavior, and integrates these measurements into the training objective. We test and validate the proposed methodology using a real-world ridesourcing dataset from Chicago and a synthetically created dataset. Experiments across various neural network architectures show that even modest monotonicity constraints consistently enhance model performance. DIM enhances the predictive performance of deep neural networks by applying domain-informed monotonicity constraints to regularize model behavior and mitigate overfitting', 'abstract_zh': '在复杂结构的深度学习模型中，尽管深度学习模型在预测任务上表现出色，但由于其复杂的结构和大量的参数，它们往往会过拟合，导致模型记忆训练数据中的噪声而非学习泛化到新数据的模式。为解决这一挑战，本文提出了一个新的正则化方法，即在深度神经网络中强加领域信息单调性的方法（Enforcing Domain-Informed Monotonicity in Deep Neural Networks，简称DIM），该方法通过保持复杂深度学习模型中的领域信息单调关系来进一步提高预测性能。具体而言，该方法通过对线性基线的违反进行惩罚，有效鼓励模型遵循预期趋势同时保留其预测能力。通过一个全面的数学框架，本文形式化了这一方法，该框架建立了线性参考，衡量单调行为的偏差，并将这些测量值整合到训练目标中。本文使用来自芝加哥的真实世界网约车数据集和合成数据集测试和验证了所提出的方法。各种神经网络架构的实验表明，即使是轻微的单调性约束也能一致地提升模型性能。DIM通过在深度神经网络中应用领域信息单调性约束来规整模型行为并缓解过拟合，从而提高预测性能。', 'title_zh': 'DIM：在深度神经网络中强制执行基于领域 Informative 的单调性'}
{'arxiv_id': 'arXiv:2509.21663', 'title': 'Logic of Hypotheses: from Zero to Full Knowledge in Neurosymbolic Integration', 'authors': 'Davide Bizzaro, Alessandro Daniele', 'link': 'https://arxiv.org/abs/2509.21663', 'abstract': 'Neurosymbolic integration (NeSy) blends neural-network learning with symbolic reasoning. The field can be split between methods injecting hand-crafted rules into neural models, and methods inducing symbolic rules from data. We introduce Logic of Hypotheses (LoH), a novel language that unifies these strands, enabling the flexible integration of data-driven rule learning with symbolic priors and expert knowledge. LoH extends propositional logic syntax with a choice operator, which has learnable parameters and selects a subformula from a pool of options. Using fuzzy logic, formulas in LoH can be directly compiled into a differentiable computational graph, so the optimal choices can be learned via backpropagation. This framework subsumes some existing NeSy models, while adding the possibility of arbitrary degrees of knowledge specification. Moreover, the use of Goedel fuzzy logic and the recently developed Goedel trick yields models that can be discretized to hard Boolean-valued functions without any loss in performance. We provide experimental analysis on such models, showing strong results on tabular data and on the Visual Tic-Tac-Toe NeSy task, while producing interpretable decision rules.', 'abstract_zh': '神经符号整合（NeSy）将神经网络学习与符号推理相结合。该领域可以分为将手工构建规则注入神经模型的方法，以及从数据中诱导符号规则的方法。我们引入了假设逻辑（LoH），这是一种新的语言，能够统一上述两种方法，实现基于数据规则学习与符号先验及专家知识的灵活整合。LoH 扩展了命题逻辑的语法，添加了一个具有可学习参数的选择操作符，可以从一组选项中选择子公式。使用模糊逻辑，LoH 中的公式可以直接编译成可微计算图，从而使最优选择可通过反向传播学习。该框架涵盖了某些现有的 NeSy 模型，同时增加了任意程度的知识指定的可能性。此外，利用哥德尔模糊逻辑和最近发展的哥德尔技巧，可以将模型离散化为硬布尔值函数，而不影响性能。我们对这些模型进行了实验分析，在表格数据和视觉井字博弈 NeSy 任务中取得了显著效果，同时还产生了可解释的决策规则。', 'title_zh': '逻辑假设：从零到完全知识的神经符号集成'}
{'arxiv_id': 'arXiv:2509.21654', 'title': 'Limitations on Safe, Trusted, Artificial General Intelligence', 'authors': 'Rina Panigrahy, Vatsal Sharan', 'link': 'https://arxiv.org/abs/2509.21654', 'abstract': "Safety, trust and Artificial General Intelligence (AGI) are aspirational goals in artificial intelligence (AI) systems, and there are several informal interpretations of these notions. In this paper, we propose strict, mathematical definitions of safety, trust, and AGI, and demonstrate a fundamental incompatibility between them. We define safety of a system as the property that it never makes any false claims, trust as the assumption that the system is safe, and AGI as the property of an AI system always matching or exceeding human capability. Our core finding is that -- for our formal definitions of these notions -- a safe and trusted AI system cannot be an AGI system: for such a safe, trusted system there are task instances which are easily and provably solvable by a human but not by the system. We note that we consider strict mathematical definitions of safety and trust, and it is possible for real-world deployments to instead rely on alternate, practical interpretations of these notions. We show our results for program verification, planning, and graph reachability. Our proofs draw parallels to Gödel's incompleteness theorems and Turing's proof of the undecidability of the halting problem, and can be regarded as interpretations of Gödel's and Turing's results.", 'abstract_zh': '安全、信任与通用人工智能：严格定义及其根本不兼容性', 'title_zh': '安全可靠的通用人工智能局限性'}
{'arxiv_id': 'arXiv:2509.21617', 'title': 'LANCE: Low Rank Activation Compression for Efficient On-Device Continual Learning', 'authors': 'Marco Paul E. Apolinario, Kaushik Roy', 'link': 'https://arxiv.org/abs/2509.21617', 'abstract': 'On-device learning is essential for personalization, privacy, and long-term adaptation in resource-constrained environments. Achieving this requires efficient learning, both fine-tuning existing models and continually acquiring new tasks without catastrophic forgetting. Yet both settings are constrained by high memory cost of storing activations during backpropagation. Existing activation compression methods reduce this cost but relying on repeated low-rank decompositions, introducing computational overhead. Also, such methods have not been explored for continual learning. We propose LANCE (Low-rank Activation Compression), a framework that performs one-shot higher-order Singular Value Decompsoition (SVD) to obtain a reusable low-rank subspace for activation projection. This eliminates repeated decompositions, reducing both memory and computation. Moreover, fixed low-rank subspaces further enable on-device continual learning by allocating tasks to orthogonal subspaces without storing large task-specific matrices. Experiments show that LANCE reduces activation storage up to 250$\\times$ while maintaining accuracy comparable to full backpropagation on CIFAR-10/100, Oxford-IIIT Pets, Flowers102, and CUB-200 datasets. On continual learning benchmarks (Split CIFAR-100, Split MiniImageNet, 5-Datasets), it achieves performance competitive with orthogonal gradient projection methods at a fraction of the memory cost. These results position LANCE as a practical and scalable solution for efficient fine-tuning and continual learning on edge devices.', 'abstract_zh': '设备端学习对于受限资源环境中的个性化、隐私保护和长期适应至关重要。实现这一目标需要高效的在线学习，既包括微调现有模型，也包括不断获取新任务而不发生灾难性遗忘。然而，这二者都受限于反向传播过程中激活存储的高内存成本。现有激活压缩方法虽能降低此成本，但依赖于复现的低秩分解，引入了计算开销。此外，这类方法尚未被探索应用于连续学习。我们提出了一种名为LANCE（Low-rank Activation Compression）的框架，该框架通过一次性的高阶奇异值分解（SVD）获得可重用的低秩子空间来进行激活投影。这消除了复现分解的需求，降低了内存和计算成本。此外，固定的低秩子空间还进一步促进了设备端的连续学习，在不会存储大量任务特定矩阵的情况下，将任务分配到正交子空间中。实验结果显示，LANCE在CIFAR-10/100、Oxford-IIIT Pets、Flowers102和CUB-200数据集上将激活存储减少多达250倍，同时保持与全反向传播相当的准确性。在连续学习基准测试（Split CIFAR-100、Split MiniImageNet、5-数据集）中，LANCE在内存成本极低的情况下，实现了与正交梯度投影方法相当的性能。这些结果将LANCE定位为适用于边缘设备上高效微调和连续学习的实用和可扩展解决方案。', 'title_zh': 'LANCE: 低秩激活压缩以实现高效设备端持续学习'}
{'arxiv_id': 'arXiv:2509.21565', 'title': 'No Alignment Needed for Generation: Learning Linearly Separable Representations in Diffusion Models', 'authors': 'Junno Yun, Yaşar Utku Alçalar, Mehmet Akçakaya', 'link': 'https://arxiv.org/abs/2509.21565', 'abstract': "Efficient training strategies for large-scale diffusion models have recently emphasized the importance of improving discriminative feature representations in these models. A central line of work in this direction is representation alignment with features obtained from powerful external encoders, which improves the representation quality as assessed through linear probing. Alignment-based approaches show promise but depend on large pretrained encoders, which are computationally expensive to obtain. In this work, we propose an alternative regularization for training, based on promoting the Linear SEParability (LSEP) of intermediate layer representations. LSEP eliminates the need for an auxiliary encoder and representation alignment, while incorporating linear probing directly into the network's learning dynamics rather than treating it as a simple post-hoc evaluation tool. Our results demonstrate substantial improvements in both training efficiency and generation quality on flow-based transformer architectures such as SiTs, achieving an FID of 1.46 on $256 \\times 256$ ImageNet dataset.", 'abstract_zh': '大型扩散模型的高效训练策略强调了提高这些模型中的鉴别特征表示的重要性。这一方向的一个主要研究线是通过强大外部编码器获得的特征进行表示对齐，以通过线性探测来提高表示质量。基于对齐的方法显示出前景，但依赖于大型的预训练编码器，这些编码器在计算上非常昂贵。在本文中，我们提出了一种替代的训练正则化方法，基于促进中间层表示的线性可分性（LSEP）。LSEP 消除了辅助编码器和表示对齐的需求，同时将线性探测直接纳入网络的学习动态中，而不是将其视为简单的后续评估工具。我们的结果在基于流的变压器架构如 SiTs 上显示了显著提高的训练效率和生成质量，在 $256 \\times 256$ ImageNet 数据集上实现了 FID 为 1.46。', 'title_zh': '无需对齐即可生成：学习线性可分表示的扩散模型'}
{'arxiv_id': 'arXiv:2509.21554', 'title': 'Domain-Aware Speaker Diarization On African-Accented English', 'authors': 'Chibuzor Okocha, Kelechi Ezema, Christan Grant', 'link': 'https://arxiv.org/abs/2509.21554', 'abstract': 'This study examines domain effects in speaker diarization for African-accented English. We evaluate multiple production and open systems on general and clinical dialogues under a strict DER protocol that scores overlap. A consistent domain penalty appears for clinical speech and remains significant across models. Error analysis attributes much of this penalty to false alarms and missed detections, aligning with short turns and frequent overlap. We test lightweight domain adaptation by fine-tuning a segmentation module on accent-matched data; it reduces error but does not eliminate the gap. Our contributions include a controlled benchmark across domains, a concise approach to error decomposition and conversation-level profiling, and an adaptation recipe that is easy to reproduce. Results point to overlap-aware segmentation and balanced clinical resources as practical next steps.', 'abstract_zh': '本研究考察了非洲口音英语说话人分割中的领域效应，我们在严格的重叠评分DER协议下评估了多种生产系统和开源系统在一般对话和临床对话上的表现，发现临床语音领域存在一致的惩罚，并且在不同模型中保持显著。错误分析将这一惩罚的主要原因归结为误报和漏报，与短发言和频繁重叠相符。我们通过在匹配口音的数据上微调分割模块进行轻量级领域适应测试，虽然减少了错误但未完全消除差距。我们的贡献包括跨领域的受控基准、简洁的错误分解和对话级分析方法，以及易于复现的适应方法。研究结果指出，重叠意识分割和平衡临床资源是实际可行的下一步。', 'title_zh': '基于领域意识的带有非洲口音的英语发言人聚类'}
{'arxiv_id': 'arXiv:2509.21542', 'title': 'Psychological and behavioural responses in human-agent vs. human-human interactions: a systematic review and meta-analysis', 'authors': 'Jianan Zhou, Fleur Corbett, Joori Byun, Talya Porat, Nejra van Zalk', 'link': 'https://arxiv.org/abs/2509.21542', 'abstract': "Interactive intelligent agents are being integrated across society. Despite achieving human-like capabilities, humans' responses to these agents remain poorly understood, with research fragmented across disciplines. We conducted a first systematic synthesis comparing a range of psychological and behavioural responses in matched human-agent vs. human-human dyadic interactions. A total of 162 eligible studies (146 contributed to the meta-analysis; 468 effect sizes) were included in the systematic review and meta-analysis, which integrated frequentist and Bayesian approaches. Our results indicate that individuals exhibited less prosocial behaviour and moral engagement when interacting with agents vs. humans. They attributed less agency and responsibility to agents, perceiving them as less competent, likeable, and socially present. In contrast, individuals' social alignment (i.e., alignment or adaptation of internal states and behaviours with partners), trust in partners, personal agency, task performance, and interaction experiences were generally comparable when interacting with agents vs. humans. We observed high effect-size heterogeneity for many subjective responses (i.e., social perceptions of partners, subjective trust, and interaction experiences), suggesting context-dependency of partner effects. By examining the characteristics of studies, participants, partners, interaction scenarios, and response measures, we also identified several moderators shaping partner effects. Overall, functional behaviours and interactive experiences with agents can resemble those with humans, whereas fundamental social attributions and moral/prosocial concerns lag in human-agent interactions. Agents are thus afforded instrumental value on par with humans but lack comparable intrinsic value, providing practical implications for agent design and regulation.", 'abstract_zh': '交互智能代理正在社会中集成应用。尽管这些代理已展现出了类人的能力，但人们对这些代理的反应仍 poorly understood，跨学科的研究较为零散。我们进行了一项首次系统整合研究，比较了代理-人类与人类-人类互动中的一系列心理与行为反应。系统综述和元分析共纳入162项符合条件的研究（146项用于元分析；468个效应量），整合了 frequentist 和 Bayesian 方法。结果表明，与与人类互动相比，个体在与代理互动时表现出较少的亲社会行为和道德参与。他们赋予代理较少的意图和责任，认为代理不如人类能干、可亲和社交存在感。相反，个体的社会一致性（即与伙伴内部状态和行为的一致性或适应性）、对伙伴的信任、个人意图、任务表现和互动体验在与代理互动时通常与与人类互动相当。我们观察到许多主观反应（如对伙伴的社会认知、主观信任和互动体验）的效应大小差异性很高，表明伙伴效应具有情境依赖性。通过研究各个方面的特征（如研究特点、参与者、伙伴、互动场景和反应措施），我们还识别出若干影响伙伴效应的调节因素。总体而言，与人类互动相比，代理的功能行为和互动体验相似，但基本的社会归因和道德/亲社会关注较少。因此，代理在功能上与人类具有同等的重要性，但在内在价值上则较低，为代理设计和监管提供了实践意义。', 'title_zh': '人类与代理之间 vs. 人类与人类之间互动的心理与行为反应：一项系统回顾和元分析'}
{'arxiv_id': 'arXiv:2509.21535', 'title': 'Agribot: agriculture-specific question answer system', 'authors': 'Naman Jain, Pranjali Jain, Pratik Kayal, Jayakrishna Sahit, Soham Pachpande, Jayesh Choudhari', 'link': 'https://arxiv.org/abs/2509.21535', 'abstract': 'India is an agro-based economy and proper information about agricultural practices is the key to optimal agricultural growth and output. In order to answer the queries of the farmer, we have build an agricultural chatbot based on the dataset from Kisan Call Center. This system is robust enough to answer queries related to weather, market rates, plant protection and government schemes. This system is available 24* 7, can be accessed through any electronic device and the information is delivered with the ease of understanding. The system is based on a sentence embedding model which gives an accuracy of 56%. After eliminating synonyms and incorporating entity extraction, the accuracy jumps to 86%. With such a system, farmers can progress towards easier information about farming related practices and hence a better agricultural output. The job of the Call Center workforce would be made easier and the hard work of various such workers can be redirected to a better goal.', 'abstract_zh': '印度是一个农业导向型经济体，准确的农业信息是实现最优农业增长和产出的关键。为了回答农民的查询，我们基于Kisan呼叫中心的数据集构建了一个农业聊天机器人。该系统能够 robust 地回答与天气、市场行情、植物保护和政府方案相关的查询。该系统全年无休，可通过任何电子设备访问，并且信息传达易于理解。该系统基于句子嵌入模型，准确率为 56%。在消除同义词并结合实体提取后，准确率提升至 86%。通过这样一个系统，农民可以更容易地获取与农业相关的信息，从而提高农业产出。呼叫中心工作人员的工作将更加容易，这些工人的辛勤工作可以重新导向到更有意义的目标。', 'title_zh': '农 bot: 农业专用问答系统'}
{'arxiv_id': 'arXiv:2509.21522', 'title': 'Shortcut Flow Matching for Speech Enhancement: Step-Invariant flows via single stage training', 'authors': 'Naisong Zhou, Saisamarth Rajesh Phaye, Milos Cernak, Tijana Stojkovic, Andy Pearce, Andrea Cavallaro, Andy Harper', 'link': 'https://arxiv.org/abs/2509.21522', 'abstract': 'Diffusion-based generative models have achieved state-of-the-art performance for perceptual quality in speech enhancement (SE). However, their iterative nature requires numerous Neural Function Evaluations (NFEs), posing a challenge for real-time applications. On the contrary, flow matching offers a more efficient alternative by learning a direct vector field, enabling high-quality synthesis in just a few steps using deterministic ordinary differential equation~(ODE) solvers. We thus introduce Shortcut Flow Matching for Speech Enhancement (SFMSE), a novel approach that trains a single, step-invariant model. By conditioning the velocity field on the target time step during a one-stage training process, SFMSE can perform single, few, or multi-step denoising without any architectural changes or fine-tuning. Our results demonstrate that a single-step SFMSE inference achieves a real-time factor (RTF) of 0.013 on a consumer GPU while delivering perceptual quality comparable to a strong diffusion baseline requiring 60 NFEs. This work also provides an empirical analysis of the role of stochasticity in training and inference, bridging the gap between high-quality generative SE and low-latency constraints.', 'abstract_zh': '基于扩散的生成模型在语音增强中实现了感知质量的最先进性能。然而，其迭代特性需要大量神经函数评估（NFEs），这给实时应用带来挑战。相反，流匹配提供了一种更高效的替代方案，通过学习直接的向量场，使用确定性的常微分方程（ODE）求解器，在少量步骤内实现高质量的合成。因此，我们提出了语音增强中的快捷流匹配方法（SFMSE），这是一种新型方法，训练一个单一的、步骤不变的模型。通过在一阶段训练过程中使速度场依赖于目标时间步，SFMSE 可以在不需要任何架构更改或微调的情况下执行单步、少量步或多步去噪。我们的结果表明，单步 SFMSE 推断在消费者 GPU 上实现了 0.013 的实时因子（RTF），同时提供了与需要 60 个 NFEs 的强扩散基线相当的感知质量。这项工作还提供了关于训练和推断中随机性作用的经验分析，缩小了高质量生成 SE 和低延迟约束之间的差距。', 'title_zh': '用于语音增强的捷径流匹配：基于单阶段训练的步进不变流'}
{'arxiv_id': 'arXiv:2509.21519', 'title': '$\\mathbf{Li_2}$: A Framework on Dynamics of Feature Emergence and Delayed Generalization', 'authors': 'Yuandong Tian', 'link': 'https://arxiv.org/abs/2509.21519', 'abstract': 'While the phenomenon of grokking, i.e., delayed generalization, has been studied extensively, it remains an open question whether there is a mathematical framework to characterize what kind of features emerge, how and in which conditions it happens from training, for complex structured inputs. We propose a novel framework, named $\\mathbf{Li_2}$, that captures three key stages for the grokking behavior of 2-layer nonlinear networks: (I) Lazy learning, (II) independent feature learning and (III) interactive feature learning, characterized by the structure of backpropagated gradient $G_F$ across layers. In (I), $G_F$ is random, and top layer overfits to random hidden representation. In (II), the gradient of each node (column of $G_F$) only depends on its own activation, and thus each hidden node learns their representation independently from $G_F$, which now carries information about target labels, thanks to weight decay. Interestingly, the independent dynamics follows exactly the gradient ascent of an energy function $E$, and its local maxima are precisely the emerging features. We study whether these local-optima induced features are generalizable, their representation power, and how they change on sample size, in group arithmetic tasks. Finally, in (III), we provably show how hidden nodes interact, and how $G_F$ changes to focus on missing features that need to be learned. Our study sheds lights on roles played by key hyperparameters such as weight decay, learning rate and sample sizes in grokking, leads to provable scaling laws of memorization and generalization, and reveals the underlying cause why recent optimizers such as Muon can be effective, from the first principles of gradient dynamics. Our analysis can be extended to multi-layer architectures.', 'abstract_zh': '基于Li₂框架的两层非线性网络的grokking行为分析：懒学习、独立特征学习和交互特征学习的数学描述', 'title_zh': '$\\mathbf{Li_2}$: 一种特征涌现和延迟泛化的动力学框架'}
{'arxiv_id': 'arXiv:2509.21502', 'title': 'New Algorithmic Directions in Optimal Transport and Applications for Product Spaces', 'authors': 'Salman Beigi, Omid Etesami, Mohammad Mahmoody, Amir Najafi', 'link': 'https://arxiv.org/abs/2509.21502', 'abstract': 'We study optimal transport between two high-dimensional distributions $\\mu,\\nu$ in $R^n$ from an algorithmic perspective: given $x \\sim \\mu$, find a close $y \\sim \\nu$ in $poly(n)$ time, where $n$ is the dimension of $x,y$. Thus, running time depends on the dimension rather than the full representation size of $\\mu,\\nu$. Our main result is a general algorithm for transporting any product distribution $\\mu$ to any $\\nu$ with cost $\\Delta + \\delta$ under $\\ell_p^p$, where $\\Delta$ is the Knothe-Rosenblatt transport cost and $\\delta$ is a computational error decreasing with runtime. This requires $\\nu$ to be "sequentially samplable" with bounded average sampling cost, a new but natural notion.\nWe further prove:\nAn algorithmic version of Talagrand\'s inequality for transporting the standard Gaussian $\\Phi^n$ to arbitrary $\\nu$ under squared Euclidean cost. For $\\nu = \\Phi^n$ conditioned on a set $\\mathcal{S}$ of measure $\\varepsilon$, we construct the sequential sampler in expected time $poly(n/\\varepsilon)$ using membership oracle access to $\\mathcal{S}$. This yields an algorithmic transport from $\\Phi^n$ to $\\Phi^n|\\mathcal{S}$ in $poly(n/\\varepsilon)$ time and expected squared distance $O(\\log 1/\\varepsilon)$, optimal for general $\\mathcal{S}$ of measure $\\varepsilon$.\nAs corollary, we obtain the first computational concentration result (Etesami et al. SODA 2020) for Gaussian measure under Euclidean distance with dimension-independent transportation cost, resolving an open question of Etesami et al. Specifically, for any $\\mathcal{S}$ of Gaussian measure $\\varepsilon$, most $\\Phi^n$ samples can be mapped to $\\mathcal{S}$ within distance $O(\\sqrt{\\log 1/\\varepsilon})$ in $poly(n/\\varepsilon)$ time.', 'abstract_zh': '高维空间中两分布$\\mu,\\nu$之间的最优传输算法研究：从$\\mu$中的$x$找到$\\nu$中接近的$y$，时间复杂度为多项式时间，取决于维度而非分布的完全表示大小。我们的主要结果是，对于任意乘积分布$\\mu$和任意$\\nu$，在$\\ell_p^p$代价下，传输成本为$\\Delta + \\delta$，其中$\\Delta$为Knothe-Rosenblatt传输成本，$\\delta$是随运行时间减少的计算误差。要求$\\nu$为可按顺序采样的分布，且平均采样成本有界，这是一条新的但自然的性质。', 'title_zh': '最优传输中新的算法方向及在乘积空间中的应用'}
{'arxiv_id': 'arXiv:2509.21485', 'title': 'Neural Operators for Mathematical Modeling of Transient Fluid Flow in Subsurface Reservoir Systems', 'authors': 'Daniil D. Sirota, Sergey A. Khan, Sergey L. Kostikov, Kirill A. Butov', 'link': 'https://arxiv.org/abs/2509.21485', 'abstract': 'This paper presents a method for modeling transient fluid flow in subsurface reservoir systems based on the developed neural operator architecture (TFNO-opt). Reservoir systems are complex dynamic objects with distributed parameters described by systems of partial differential equations (PDEs). Traditional numerical methods for modeling such systems, despite their high accuracy, are characterized by significant time costs for performing calculations, which limits their applicability in control and decision support problems. The proposed architecture (TFNO-opt) is based on Fourier neural operators, which allow approximating PDE solutions in infinite-dimensional functional spaces, providing invariance to discretization and the possibility of generalization to various implementations of equations. The developed modifications are aimed at increasing the accuracy and stability of the trained neural operator, which is especially important for control problems. These include adjustable internal time resolution of the integral Fourier operator, tensor decomposition of parameters in the spectral domain, use of the Sobolev norm in the error function, and separation of approximation errors and reconstruction of initial conditions for more accurate reproduction of physical processes. The effectiveness of the proposed improvements is confirmed by computational experiments. The practical significance is confirmed by computational experiments using the example of the problem of hydrodynamic modeling of an underground gas storage (UGS), where the acceleration of calculations by six orders of magnitude was achieved, compared to traditional methods. This opens up new opportunities for the effective control of complex reservoir systems.', 'abstract_zh': '基于TFNO-opt神经算子架构的地下 reservoir 系统瞬态流体流动建模方法', 'title_zh': '神经算子在地下储层系统瞬态流体流动的数学建模中的应用'}
{'arxiv_id': 'arXiv:2509.21473', 'title': 'Are Hallucinations Bad Estimations?', 'authors': 'Hude Liu, Jerry Yao-Chieh Hu, Jennifer Yuntong Zhang, Zhao Song, Han Liu', 'link': 'https://arxiv.org/abs/2509.21473', 'abstract': 'We formalize hallucinations in generative models as failures to link an estimate to any plausible cause. Under this interpretation, we show that even loss-minimizing optimal estimators still hallucinate. We confirm this with a general high probability lower bound on hallucinate rate for generic data distributions. This reframes hallucination as structural misalignment between loss minimization and human-acceptable outputs, and hence estimation errors induced by miscalibration. Experiments on coin aggregation, open-ended QA, and text-to-image support our theory.', 'abstract_zh': '我们在生成模型中将幻觉形式化为未能将估计值与任何合理的因果关系联系起来的失败。在这一解释下，我们展示了即使是最优损失最小化估计器也会产生幻觉。我们通过一个适用于通用数据分布的高概率下界验证了这一点。这将幻觉重新定义为损失最小化与人类可接受输出之间的结构对齐问题，进而将其视为由于校准不当引起估计错误。我们在硬币聚合、开放式问答和文本转图像实验中支持了这一理论。', 'title_zh': '幻觉是糟糕的估计吗？'}
{'arxiv_id': 'arXiv:2509.21466', 'title': 'Gender Stereotypes in Professional Roles Among Saudis: An Analytical Study of AI-Generated Images Using Language Models', 'authors': 'Khaloud S. AlKhalifah, Malak Mashaabi, Hend Al-Khalifa', 'link': 'https://arxiv.org/abs/2509.21466', 'abstract': "This study investigates the extent to which contemporary Text-to-Image artificial intelligence (AI) models perpetuate gender stereotypes and cultural inaccuracies when generating depictions of professionals in Saudi Arabia. We analyzed 1,006 images produced by ImageFX, DALL-E V3, and Grok for 56 diverse Saudi professions using neutral prompts. Two trained Saudi annotators evaluated each image on five dimensions: perceived gender, clothing and appearance, background and setting, activities and interactions, and age. A third senior researcher adjudicated whenever the two primary raters disagreed, yielding 10,100 individual judgements. The results reveal a strong gender imbalance, with ImageFX outputs being 85\\% male, Grok 86.6\\% male, and DALL-E V3 96\\% male, indicating that DALL-E V3 exhibited the strongest overall gender stereotyping. This imbalance was most evident in leadership and technical roles. Moreover, cultural inaccuracies in clothing, settings, and depicted activities were frequently observed across all three models. Counter-stereotypical images often arise from cultural misinterpretations rather than genuinely progressive portrayals. We conclude that current models mirror societal biases embedded in their training data, generated by humans, offering only a limited reflection of the Saudi labour market's gender dynamics and cultural nuances. These findings underscore the urgent need for more diverse training data, fairer algorithms, and culturally sensitive evaluation frameworks to ensure equitable and authentic visual outputs.", 'abstract_zh': '当代文本生成图像人工智能模型在生成沙特阿拉伯职业形象时性别刻板印象和文化不准确性的程度研究', 'title_zh': '沙特阿拉伯专业角色中的性别刻板印象：基于语言模型生成的图像的分析研究'}
{'arxiv_id': 'arXiv:2509.21463', 'title': 'Enhanced Generative Machine Listener', 'authors': 'Vishnu Raj, Gouthaman KV, Shiv Gehlot, Lars Villemoes, Arijit Biswas', 'link': 'https://arxiv.org/abs/2509.21463', 'abstract': 'We present GMLv2, a reference-based model designed for the prediction of subjective audio quality as measured by MUSHRA scores. GMLv2 introduces a Beta distribution-based loss to model the listener ratings and incorporates additional neural audio coding (NAC) subjective datasets to extend its generalization and applicability. Extensive evaluations on diverse testset demonstrate that proposed GMLv2 consistently outperforms widely used metrics, such as PEAQ and ViSQOL, both in terms of correlation with subjective scores and in reliably predicting these scores across diverse content types and codec configurations. Consequently, GMLv2 offers a scalable and automated framework for perceptual audio quality evaluation, poised to accelerate research and development in modern audio coding technologies.', 'abstract_zh': 'GMLv2：基于参考的主观音频质量预测模型', 'title_zh': '增强生成式机器听众'}
{'arxiv_id': 'arXiv:2509.21459', 'title': 'A State-of-the-Art SQL Reasoning Model using RLVR', 'authors': 'Alnur Ali, Ashutosh Baheti, Jonathan Chang, Ta-Chung Chi, Brandon Cui, Andrew Drozdov, Jonathan Frankle, Abhay Gupta, Pallavi Koppol, Sean Kulinski, Jonathan Li, Dipendra Misra, Krista Opsahl-Ong, Jose Javier Gonzalez Ortiz, Matei Zaharia, Yue Zhang', 'link': 'https://arxiv.org/abs/2509.21459', 'abstract': 'Developing custom reasoning models via Reinforcement Learning (RL) that can incorporate organization-specific knowledge has great potential to address problems faced by enterprise customers. In many of these problems, the reward function is verifiable, a setting termed RL with Verifiable Rewards (RLVR). We apply RLVR to a popular data science benchmark called BIRD that measures the ability of an AI agent to convert a natural language query for a database to SQL executions. We apply a simple and general-purpose training recipe involving careful prompt and model selection, a warm-up stage using our offline RL approach called TAO, followed by rigorous online RLVR training. With no additional training data beyond the BIRD training set and no use of proprietary models, our very first submission to the BIRD leaderboard reached state-of-the-art accuracy on the private test set: 73.56% without self-consistency and 75.68% with self-consistency. In the latter case, our model also required fewer generations than the second-best approach. While BIRD is only a proxy task, the simplicity of our framework makes it broadly applicable to enterprise domains such as business intelligence, data science, and coding.', 'abstract_zh': '通过强化学习开发定制推理模型以 incorporate 组织特定知识在解决企业客户问题方面具有巨大潜力。在许多这些问题中，奖励函数是可验证的，这种设置称为可验证奖励的强化学习（RLVR）。我们将 RLVR 应用于一个流行的 数据科学基准 BIRD，该基准衡量 AI 代理将自然语言数据库查询转换为 SQL 执行的能力。我们应用了一种简单且通用的训练食谱，涉及仔细的选择提示和模型，使用我们的离线 RL 方法 TAO 进行预热阶段，然后进行严格的在线 RLVR 训练。除了 BIRD 训练集之外没有使用额外的训练数据，并且没有使用专有模型，我们的首次提交在 BIRD 私有测试集上达到了最先进的准确性：无自我一致性情况下为 73.56%，带有自我一致性情况下为 75.68%。在后一种情况下，我们的模型还比第二好方法所需的生成次数更少。虽然 BIRD 只是一个代理任务，但我们的框架的简洁性使其在商业智能、数据科学和编程等企业领域具有广泛的应用前景。', 'title_zh': '一种基于RLVR的最先进技术状态的SQL推理模型'}
{'arxiv_id': 'arXiv:2509.21447', 'title': 'ARTI-6: Towards Six-dimensional Articulatory Speech Encoding', 'authors': 'Jihwan Lee, Sean Foley, Thanathai Lertpetchpun, Kevin Huang, Yoonjeong Lee, Tiantian Feng, Louis Goldstein, Dani Byrd, Shrikanth Narayanan', 'link': 'https://arxiv.org/abs/2509.21447', 'abstract': 'We propose ARTI-6, a compact six-dimensional articulatory speech encoding framework derived from real-time MRI data that captures crucial vocal tract regions including the velum, tongue root, and larynx. ARTI-6 consists of three components: (1) a six-dimensional articulatory feature set representing key regions of the vocal tract; (2) an articulatory inversion model, which predicts articulatory features from speech acoustics leveraging speech foundation models, achieving a prediction correlation of 0.87; and (3) an articulatory synthesis model, which reconstructs intelligible speech directly from articulatory features, showing that even a low-dimensional representation can generate natural-sounding speech. Together, ARTI-6 provides an interpretable, computationally efficient, and physiologically grounded framework for advancing articulatory inversion, synthesis, and broader speech technology applications. The source code and speech samples are publicly available.', 'abstract_zh': '我们提出ARTI-6，一个源自实时MRI数据的紧凑六维发音语音编码框架，捕捉包括软腭、舌根和声带在内的关键发音 tract 区域。ARTI-6 包含三个组成部分：（1）一个六维发音特征集，表示发音 tract 的关键区域；（2）一个发音反演模型，通过利用语音基础模型从语音声学中预测发音特征，预测相关性达到 0.87；（3）一个发音合成模型，直接从发音特征重建可懂度高的语音，展示了低维表示也能生成自然听起来的语音。结合在一起，ARTI-6 提供了一个可解释、计算效率高且生理学上合理的框架，用于推动发音反演、合成和更广泛的语音技术应用。源代码和语音样本已公开。', 'title_zh': 'ARTI-6: 向六维articulatory发音编码迈进'}
{'arxiv_id': 'arXiv:2509.21434', 'title': 'Foundation models for high-energy physics', 'authors': 'Anna Hallin', 'link': 'https://arxiv.org/abs/2509.21434', 'abstract': 'The rise of foundation models -- large, pretrained machine learning models that can be finetuned to a variety of tasks -- has revolutionized the fields of natural language processing and computer vision. In high-energy physics, the question of whether these models can be implemented directly in physics research, or even built from scratch, tailored for particle physics data, has generated an increasing amount of attention. This review, which is the first on the topic of foundation models in high-energy physics, summarizes and discusses the research that has been published in the field so far.', 'abstract_zh': '基础模型的兴起——大型预训练机器学习模型可以针对各种任务进行微调，这已彻底改变了自然语言处理和计算机视觉领域。在高能物理领域，关于这些模型是否可以直接应用于物理研究，甚至是否可以根据粒子物理数据从头构建，这一问题日益受到关注。本文作为首个关于高能物理领域基础模型的综述，总结并讨论了迄今为止该领域已发表的研究成果。', 'title_zh': '高能物理领域的基础模型'}
{'arxiv_id': 'arXiv:2509.21433', 'title': 'DyME: Dynamic Multi-Concept Erasure in Diffusion Models with Bi-Level Orthogonal LoRA Adaptation', 'authors': 'Jiaqi Liu, Lan Zhang, Xiaoyong Yuan', 'link': 'https://arxiv.org/abs/2509.21433', 'abstract': 'Text-to-image diffusion models (DMs) inadvertently reproduce copyrighted styles and protected visual concepts, raising legal and ethical concerns. Concept erasure has emerged as a safeguard, aiming to selectively suppress such concepts through fine-tuning. However, existing methods do not scale to practical settings where providers must erase multiple and possibly conflicting concepts. The core bottleneck is their reliance on static erasure: a single checkpoint is fine-tuned to remove all target concepts, regardless of the actual erasure needs at inference. This rigid design mismatches real-world usage, where requests vary per generation, leading to degraded erasure success and reduced fidelity for non-target content. We propose DyME, an on-demand erasure framework that trains lightweight, concept-specific LoRA adapters and dynamically composes only those needed at inference. This modular design enables flexible multi-concept erasure, but naive composition causes interference among adapters, especially when many or semantically related concepts are suppressed. To overcome this, we introduce bi-level orthogonality constraints at both the feature and parameter levels, disentangling representation shifts and enforcing orthogonal adapter subspaces. We further develop ErasureBench-H, a new hierarchical benchmark with brand-series-character structure, enabling principled evaluation across semantic granularities and erasure set sizes. Experiments on ErasureBench-H and standard datasets (e.g., CIFAR-100, Imagenette) demonstrate that DyME consistently outperforms state-of-the-art baselines, achieving higher multi-concept erasure fidelity with minimal collateral degradation.', 'abstract_zh': '基于文本到图像扩散模型的按需擦除框架：DyME', 'title_zh': 'DyME: 动态多概念消除在具有双层正交LoRA适应的扩散模型中'}
{'arxiv_id': 'arXiv:2509.21423', 'title': 'Near-Optimal Experiment Design in Linear non-Gaussian Cyclic Models', 'authors': 'Ehsan Sharifian, Saber Salehkaleybar, Negar Kiyavash', 'link': 'https://arxiv.org/abs/2509.21423', 'abstract': 'We study the problem of causal structure learning from a combination of observational and interventional data generated by a linear non-Gaussian structural equation model that might contain cycles. Recent results show that using mere observational data identifies the causal graph only up to a permutation-equivalence class. We obtain a combinatorial characterization of this class by showing that each graph in an equivalence class corresponds to a perfect matching in a bipartite graph. This bipartite representation allows us to analyze how interventions modify or constrain the matchings. Specifically, we show that each atomic intervention reveals one edge of the true matching and eliminates all incompatible causal graphs. Consequently, we formalize the optimal experiment design task as an adaptive stochastic optimization problem over the set of equivalence classes with a natural reward function that quantifies how many graphs are eliminated from the equivalence class by an intervention. We show that this reward function is adaptive submodular and provide a greedy policy with a provable near-optimal performance guarantee. A key technical challenge is to efficiently estimate the reward function without having to explicitly enumerate all the graphs in the equivalence class. We propose a sampling-based estimator using random matchings and analyze its bias and concentration behavior. Our simulation results show that performing a small number of interventions guided by our stochastic optimization framework recovers the true underlying causal structure.', 'abstract_zh': '从观察数据和干预数据中学习线性非高斯结构方程模型的因果结构：一种基于完美匹配的组合式表征方法', 'title_zh': '接近最优的实验设计在线性非高斯循环模型中'}
{'arxiv_id': 'arXiv:2509.21389', 'title': 'Towards Adapting Federated & Quantum Machine Learning for Network Intrusion Detection: A Survey', 'authors': 'Devashish Chaudhary, Sutharshan Rajasegarar, Shiva Raj Pokhrel', 'link': 'https://arxiv.org/abs/2509.21389', 'abstract': 'This survey explores the integration of Federated Learning (FL) with Network Intrusion Detection Systems (NIDS), with particular emphasis on deep learning and quantum machine learning approaches. FL enables collaborative model training across distributed devices while preserving data privacy-a critical requirement in network security contexts where sensitive traffic data cannot be centralized. Our comprehensive analysis systematically examines the full spectrum of FL architectures, deployment strategies, communication protocols, and aggregation methods specifically tailored for intrusion detection. We provide an in-depth investigation of privacy-preserving techniques, model compression approaches, and attack-specific federated solutions for threats including DDoS, MITM, and botnet attacks. The survey further delivers a pioneering exploration of Quantum FL (QFL), discussing quantum feature encoding, quantum machine learning algorithms, and quantum-specific aggregation methods that promise exponential speedups for complex pattern recognition in network traffic. Through rigorous comparative analysis of classical and quantum approaches, identification of research gaps, and evaluation of real-world deployments, we outline a concrete roadmap for industrial adoption and future research directions. This work serves as an authoritative reference for researchers and practitioners seeking to enhance privacy, efficiency, and robustness of federated intrusion detection systems in increasingly complex network environments, while preparing for the quantum-enhanced cybersecurity landscape of tomorrow.', 'abstract_zh': 'This survey探讨了联邦学习（FL）与网络入侵检测系统（NIDS）的集成，特别强调了深度学习和量子机器学习方法。FL允许分布式设备跨设备进行协作模型训练，同时保护数据隐私——在网络安全环境中这是一个至关重要的要求，特别是在敏感流量数据不能集中处理的情况下。我们的全面分析系统地 examination了适用于入侵检测的FL架构、部署策略、通信协议和聚合方法的完整范围。我们深入研究了隐私保护技术、模型压缩方法以及针对DDoS、MITM和肉鸡攻击等特定攻击场景的联邦解决方案。此外，本调查还首次探索了量子联邦学习（QFL），讨论了量子特征编码、量子机器学习算法及量子特定的聚合方法，这些方法有望在复杂的网络流量模式识别中实现指数级加速。通过经典方法与量子方法的严格比较分析、研究空白的识别以及现实世界部署的评估，我们为联邦入侵检测系统的工业采用和未来研究方向制定了具体的路线图。本工作为研究人员和从业者提供了一份权威参考，帮助他们在日益复杂的网络环境中增强联邦入侵检测系统的隐私性、效率和鲁棒性，同时也为迈向明日的量子增强网络安全景观做好准备。', 'title_zh': '面向网络入侵检测的联邦与量子机器学习适应性研究：一个综述'}
{'arxiv_id': 'arXiv:2509.21387', 'title': 'Do Sparse Subnetworks Exhibit Cognitively Aligned Attention? Effects of Pruning on Saliency Map Fidelity, Sparsity, and Concept Coherence', 'authors': 'Sanish Suwal, Dipkamal Bhusal, Michael Clifford, Nidhi Rastogi', 'link': 'https://arxiv.org/abs/2509.21387', 'abstract': 'Prior works have shown that neural networks can be heavily pruned while preserving performance, but the impact of pruning on model interpretability remains unclear. In this work, we investigate how magnitude-based pruning followed by fine-tuning affects both low-level saliency maps and high-level concept representations. Using a ResNet-18 trained on ImageNette, we compare post-hoc explanations from Vanilla Gradients (VG) and Integrated Gradients (IG) across pruning levels, evaluating sparsity and faithfulness. We further apply CRAFT-based concept extraction to track changes in semantic coherence of learned concepts. Our results show that light-to-moderate pruning improves saliency-map focus and faithfulness while retaining distinct, semantically meaningful concepts. In contrast, aggressive pruning merges heterogeneous features, reducing saliency map sparsity and concept coherence despite maintaining accuracy. These findings suggest that while pruning can shape internal representations toward more human-aligned attention patterns, excessive pruning undermines interpretability.', 'abstract_zh': '基于幅度的剪枝对模型可解释性的影响：从低级显著图到高级概念表示的探究', 'title_zh': '稀疏子网络表现出认知对齐的注意力吗？剪枝对重要性图保真度、稀疏性和概念一致性的影响'}
{'arxiv_id': 'arXiv:2509.21381', 'title': 'Toward a Realistic Encoding Model of Auditory Affective Understanding in the Brain', 'authors': 'Guandong Pan, Yaqian Yang, Shi Chen, Xin Wang, Longzhao Liu, Hongwei Zheng, Shaoting Tang', 'link': 'https://arxiv.org/abs/2509.21381', 'abstract': "In affective neuroscience and emotion-aware AI, understanding how complex auditory stimuli drive emotion arousal dynamics remains unresolved. This study introduces a computational framework to model the brain's encoding of naturalistic auditory inputs into dynamic behavioral/neural responses across three datasets (SEED, LIRIS, self-collected BAVE). Guided by neurobiological principles of parallel auditory hierarchy, we decompose audio into multilevel auditory features (through classical algorithms and wav2vec 2.0/Hubert) from the original and isolated human voice/background soundtrack elements, mapping them to emotion-related responses via cross-dataset analyses. Our analysis reveals that high-level semantic representations (derived from the final layer of wav2vec 2.0/Hubert) exert a dominant role in emotion encoding, outperforming low-level acoustic features with significantly stronger mappings to behavioral annotations and dynamic neural synchrony across most brain regions ($p < 0.05$). Notably, middle layers of wav2vec 2.0/hubert (balancing acoustic-semantic information) surpass the final layers in emotion induction across datasets. Moreover, human voices and soundtracks show dataset-dependent emotion-evoking biases aligned with stimulus energy distribution (e.g., LIRIS favors soundtracks due to higher background energy), with neural analyses indicating voices dominate prefrontal/temporal activity while soundtracks excel in limbic regions. By integrating affective computing and neuroscience, this work uncovers hierarchical mechanisms of auditory-emotion encoding, providing a foundation for adaptive emotion-aware systems and cross-disciplinary explorations of audio-affective interactions.", 'abstract_zh': '在情感神经科学和情感智能AI领域，理解复杂听觉刺激如何驱动情绪唤醒动力学仍未解决。本研究引入了一个计算框架，以建模大脑将自然听觉输入编码为动态的行为/神经响应（涉及SEED、LIRIS和自收集的BAVE三个数据集）。受神经生物学中并行听觉层次的启发，我们将音频分解为多级听觉特征（使用经典算法和wav2vec 2.0/Hubert），并通过跨数据集分析将这些特征映射到与情感相关的响应。我们的分析表明，来自wav2vec 2.0/Hubert最终层的高级语义表示在情绪编码中起主导作用，与低级声学特征相比，其与行为注释和大多数脑区的动态神经同步表现出更强的映射关系（p < 0.05）。值得注意的是，在不同数据集上，wav2vec 2.0/hubert的中间层（平衡声学-语义信息）在情绪诱导方面优于最终层。此外，人类声音和 soundtrack 在不同数据集中表现出依赖性的情感激发偏差，与刺激能量分布相符（例如，LIRIS 更青睐 soundtrack 因其更高的背景能量），神经分析表明，声音主导前额皮层/颞叶活动，而 soundtrack 占优在边缘系统区域。通过将情感计算与神经科学相结合，本研究揭示了听觉-情绪编码的层次机制，为适应性情感智能系统和跨学科探索音频-情感交互提供了基础。', 'title_zh': '向大脑听觉情感理解的现实编码模型迈进'}
{'arxiv_id': 'arXiv:2509.21379', 'title': 'SAEmnesia: Erasing Concepts in Diffusion Models with Sparse Autoencoders', 'authors': 'Enrico Cassano, Riccardo Renzulli, Marco Nurisso, Mirko Zaffaroni, Alan Perotti, Marco Grangetto', 'link': 'https://arxiv.org/abs/2509.21379', 'abstract': "Effective concept unlearning in text-to-image diffusion models requires precise localization of concept representations within the model's latent space. While sparse autoencoders successfully reduce neuron polysemanticity (i.e., multiple concepts per neuron) compared to the original network, individual concept representations can still be distributed across multiple latent features, requiring extensive search procedures for concept unlearning. We introduce SAEmnesia, a supervised sparse autoencoder training method that promotes one-to-one concept-neuron mappings through systematic concept labeling, mitigating feature splitting and promoting feature centralization. Our approach learns specialized neurons with significantly stronger concept associations compared to unsupervised baselines. The only computational overhead introduced by SAEmnesia is limited to cross-entropy computation during training. At inference time, this interpretable representation reduces hyperparameter search by 96.67% with respect to current approaches. On the UnlearnCanvas benchmark, SAEmnesia achieves a 9.22% improvement over the state-of-the-art. In sequential unlearning tasks, we demonstrate superior scalability with a 28.4% improvement in unlearning accuracy for 9-object removal.", 'abstract_zh': '文本到图像扩散模型中有效的概念遗忘需要在模型的潜在空间中精确定位概念表示。我们引入SAEmnesia，一种通过系统性概念标签化促进一对一概念-神经元映射的监督稀疏自编码器训练方法，减少特征分裂并促进特征凝聚。与无监督基线相比，该方法学习的概念关联更强。SAEmnesia引入的唯一计算开销是在训练过程中增加交叉熵计算。在推理阶段，这种可解释表示将当前方法的超参数搜索减少96.67%。在UnlearnCanvas基准上，SAEmnesia比最先进的方法提高了9.22%。在序贯遗忘任务中，我们展示了更好的可扩展性，对于9个对象的移除，遗忘准确率提高了28.4%。', 'title_zh': 'SAEmnesia: 用稀疏自编码器在扩散模型中删除概念'}
{'arxiv_id': 'arXiv:2509.21368', 'title': 'Safety Assessment of Scaffolding on Construction Site using AI', 'authors': 'Sameer Prabhu, Amit Patwardhan, Ramin Karim', 'link': 'https://arxiv.org/abs/2509.21368', 'abstract': 'In the construction industry, safety assessment is vital to ensure both the reliability of assets and the safety of workers. Scaffolding, a key structural support asset requires regular inspection to detect and identify alterations from the design rules that may compromise the integrity and stability. At present, inspections are primarily visual and are conducted by site manager or accredited personnel to identify deviations. However, visual inspection is time-intensive and can be susceptible to human errors, which can lead to unsafe conditions. This paper explores the use of Artificial Intelligence (AI) and digitization to enhance the accuracy of scaffolding inspection and contribute to the safety improvement. A cloud-based AI platform is developed to process and analyse the point cloud data of scaffolding structure. The proposed system detects structural modifications through comparison and evaluation of certified reference data with the recent point cloud data. This approach may enable automated monitoring of scaffolding, reducing the time and effort required for manual inspections while enhancing the safety on a construction site.', 'abstract_zh': '在建筑行业中，安全评估对于确保资产可靠性及工人安全至关重要。脚手架作为关键的结构支持资产，需要定期检查以检测和识别可能损害结构完整性和稳定性的设计规则变更。目前，检查主要依赖视觉方法，并由现场管理者或认证人员进行以识别偏差。然而，视觉检查耗时且易受人为错误的影响，可能导致不安全条件。本文探讨了使用人工智能（AI）和数字化技术以提高脚手架检查的准确性并促进安全改进。开发了一种基于云的AI平台，用于处理和分析脚手架结构的点云数据。所提出系统通过将认证参考数据与最近的点云数据进行比较和评估来检测结构修改。该方法可能实现脚手架的自动化监控，减少手动检查所需的时间和努力，同时提高施工现场的安全性。', 'title_zh': '基于AI的施工现场脚手架安全性评估'}
{'arxiv_id': 'arXiv:2509.21363', 'title': 'A Mutual Learning Method for Salient Object Detection with intertwined Multi-Supervision--Revised', 'authors': 'Runmin Wu, Mengyang Feng, Wenlong Guan, Dong Wang, Huchuan Lu, Errui Ding', 'link': 'https://arxiv.org/abs/2509.21363', 'abstract': 'Though deep learning techniques have made great progress in salient object detection recently, the predicted saliency maps still suffer from incomplete predictions due to the internal complexity of objects and inaccurate boundaries caused by strides in convolution and pooling operations. To alleviate these issues, we propose to train saliency detection networks by exploiting the supervision from not only salient object detection, but also foreground contour detection and edge detection. First, we leverage salient object detection and foreground contour detection tasks in an intertwined manner to generate saliency maps with uniform highlight. Second, the foreground contour and edge detection tasks guide each other simultaneously, thereby leading to precise foreground contour prediction and reducing the local noises for edge prediction. In addition, we develop a novel mutual learning module (MLM) which serves as the building block of our method. Each MLM consists of multiple network branches trained in a mutual learning manner, which improves the performance by a large margin. Extensive experiments on seven challenging datasets demonstrate that the proposed method has delivered state-of-the-art results in both salient object detection and edge detection.', 'abstract_zh': '尽管深度学习技术最近在显著对象检测方面取得了显著进展，但由于对象内部复杂性和卷积和平池化操作引起的不准确边界，预测的显著性图仍然存在不完整的问题。为了解决这些问题，我们提出通过利用显著对象检测、前景轮廓检测和边缘检测的监督来训练显著性检测网络。首先，我们以交织的方式利用显著对象检测和前景轮廓检测任务生成均匀凸显的显著性图。其次，前景轮廓检测和边缘检测任务互相引导，从而实现精确的前景轮廓预测并减少边缘预测中的局部噪声。此外，我们开发了一种新的相互学习模块（MLM），作为我们方法的基本构建块。每一MLM包含多个以相互学习方式训练的网络分支，显著提高了性能。在七个挑战性数据集上的广泛实验表明，所提出的方法在显著对象检测和边缘检测中均取得了最先进的结果。', 'title_zh': '一种基于交织多监督的互学习显著目标检测方法——修订版'}
{'arxiv_id': 'arXiv:2509.21355', 'title': 'Domain-Informed Genetic Superposition Programming: A Case Study on SFRC Beams', 'authors': 'Mohammad Sadegh Khorshidi, Navid Yazdanjue, Hassan Gharoun, Mohammad Reza Nikoo, Fang Chen, Amir H. Gandomi', 'link': 'https://arxiv.org/abs/2509.21355', 'abstract': 'This study presents domain-informed genetic superposition programming (DIGSP), a symbolic regression framework tailored for engineering systems governed by separable physical mechanisms. DIGSP partitions the input space into domain-specific feature subsets and evolves independent genetic programming (GP) populations to model material-specific effects. Early evolution occurs in isolation, while ensemble fitness promotes inter-population cooperation. To enable symbolic superposition, an adaptive hierarchical symbolic abstraction mechanism (AHSAM) is triggered after stagnation across all populations. AHSAM performs analysis of variance- (ANOVA) based filtering to identify statistically significant individuals, compresses them into symbolic constructs, and injects them into all populations through a validation-guided pruning cycle. The DIGSP is benchmarked against a baseline multi-gene genetic programming (BGP) model using a dataset of steel fiber-reinforced concrete (SFRC) beams. Across 30 independent trials with 65% training, 10% validation, and 25% testing splits, DIGSP consistently outperformed BGP in training and test root mean squared error (RMSE). The Wilcoxon rank-sum test confirmed statistical significance (p < 0.01), and DIGSP showed tighter error distributions and fewer outliers. No significant difference was observed in validation RMSE due to limited sample size. These results demonstrate that domain-informed structural decomposition and symbolic abstraction improve convergence and generalization. DIGSP offers a principled and interpretable modeling strategy for systems where symbolic superposition aligns with the underlying physical structure.', 'abstract_zh': '基于领域知识的遗传超position编程：一种适用于受可分物理机制控制的工程系统的目标函数回归框架', 'title_zh': '基于领域知识的遗传超position编程：SFRC 梁的案例研究'}
{'arxiv_id': 'arXiv:2509.21342', 'title': 'SGNNBench: A Holistic Evaluation of Spiking Graph Neural Network on Large-scale Graph', 'authors': 'Huizhe Zhang, Jintang Li, Yuchang Zhu, Liang Chen, Li Kuang', 'link': 'https://arxiv.org/abs/2509.21342', 'abstract': 'Graph Neural Networks (GNNs) are exemplary deep models designed for graph data. Message passing mechanism enables GNNs to effectively capture graph topology and push the performance boundaries across various graph tasks. However, the trend of developing such complex machinery for graph representation learning has become unsustainable on large-scale graphs. The computational and time overhead make it imperative to develop more energy-efficient GNNs to cope with the explosive growth of real-world graphs. Spiking Graph Neural Networks (SGNNs), which integrate biologically plausible learning via unique spike-based neurons, have emerged as a promising energy-efficient alternative. Different layers communicate with sparse and binary spikes, which facilitates computation and storage of intermediate graph representations. Despite the proliferation of SGNNs proposed in recent years, there is no systematic benchmark to explore the basic design principles of these brain-inspired networks on the graph data. To bridge this gap, we present SGNNBench to quantify progress in the field of SGNNs. Specifically, SGNNBench conducts an in-depth investigation of SGNNs from multiple perspectives, including effectiveness, energy efficiency, and architectural design. We comprehensively evaluate 9 state-of-the-art SGNNs across 18 datasets. Regarding efficiency, we empirically compare these baselines w.r.t model size, memory usage, and theoretical energy consumption to reveal the often-overlooked energy bottlenecks of SGNNs. Besides, we elaborately investigate the design space of SGNNs to promote the development of a general SGNN paradigm.', 'abstract_zh': '基于脉冲的图神经网络（SGNNs）：原理与进展评估基准', 'title_zh': 'SGNNBench：大规模图上脉冲图神经网络的综合评估'}
{'arxiv_id': 'arXiv:2509.21341', 'title': 'From Embeddings to Equations: Genetic-Programming Surrogates for Interpretable Transformer Classification', 'authors': 'Mohammad Sadegh Khorshidi, Navid Yazdanjue, Hassan Gharoun, Mohammad Reza Nikoo, Fang Chen, Amir H. Gandomi', 'link': 'https://arxiv.org/abs/2509.21341', 'abstract': 'We study symbolic surrogate modeling of frozen Transformer embeddings to obtain compact, auditable classifiers with calibrated probabilities. For five benchmarks (SST2G, 20NG, MNIST, CIFAR10, MSC17), embeddings from ModernBERT, DINOv2, and SigLIP are partitioned on the training set into disjoint, information-preserving views via semantic-preserving feature partitioning (SPFP). A cooperative multi-population genetic program (MEGP) then learns additive, closed-form logit programs over these views. Across 30 runs per dataset we report F1, AUC, log-loss, Brier, expected calibration error (ECE), and symbolic complexity; a canonical model is chosen by a one-standard-error rule on validation F1 with a parsimony tie-break. Temperature scaling fitted on validation yields substantial ECE reductions on test. The resulting surrogates achieve strong discrimination (up to F1 around 0.99 on MNIST, CIFAR10, MSC17; around 0.95 on SST2G), while 20NG remains most challenging. We provide reliability diagrams, dimension usage and overlap statistics, contribution-based importances, and global effect profiles (PDP and ALE), demonstrating faithful, cross-modal explanations grounded in explicit programs.', 'abstract_zh': '我们研究冻结Transformer嵌入的符号替代建模，以获取紧凑、可审计且概率校准的分类器。对于五个基准（SST2G、20NG、MNIST、CIFAR10、MSC17），使用语义保持特征分区（SPFP）将ModernBERT、DINOv2和SigLIP的嵌入在训练集上分区为互不相交但信息保持的观点。然后，合作多种群遗传程序（MEGP）在这些视图上学习加性、闭式的形式评分程序。我们在每个数据集的30次运行中报告F1、AUC、log-loss、Brier、预期校准误差（ECE）和符号复杂度；通过验证F1的一标准误差规则选择模型，并在必要时通过简化性规则进行区分。针对验证数据集拟合的温度缩放在测试集上显著降低了ECE。生成的替代模型实现了强大的区分能力（MNIST、CIFAR10、MSC17上F1最高可达0.99；SST2G上约为0.95），而20NG仍然是最具挑战性的。我们提供了可靠性图、维度使用和重叠统计、基于贡献的重要性分析以及全局效应轮廓（PDP和ALE），证明了基于明确程序的真实且跨模态的解释。', 'title_zh': '从嵌入到方程：遗传编程代理模型实现可解释的变压器分类'}
{'arxiv_id': 'arXiv:2509.21340', 'title': 'Cycle is All You Need: More Is Different', 'authors': 'Xin Li', 'link': 'https://arxiv.org/abs/2509.21340', 'abstract': 'We propose an information-topological framework in which cycle closure is the fundamental mechanism of memory and consciousness. Memory is not a static store but the ability to re-enter latent cycles in neural state space, with invariant cycles serving as carriers of meaning by filtering order-specific noise and preserving what persists across contexts. The dot-cycle dichotomy captures this: transient dots scaffold exploration, while nontrivial cycles encode low-entropy content invariants that stabilize memory. Biologically, polychronous neural groups realize 1-cycles through delay-locked spiking reinforced by STDP, nested within theta-gamma rhythms that enforce boundary cancellation. These micro-cycles compose hierarchically, extending navigation loops into general memory and cognition. The perception-action cycle introduces high-order invariance: closure holds even across sense-act alternations, generalizing ancestral homing behavior. Sheaf-cosheaf duality formalizes this process: sheaves glue perceptual fragments into global sections, cosheaves decompose global plans into actions and closure aligns top-down predictions with bottom-up cycles. Consciousness then arises as the persistence of high-order invariants that integrate (unity) yet differentiate (richness) across contexts. We conclude that cycle is all you need: persistent invariants enable generalization in non-ergodic environments with long-term coherence at minimal energetic cost.', 'abstract_zh': '我们提出一种基于信息拓扑的框架，其中循环闭合是记忆和意识的基本机制。记忆不是静态存储，而是重新进入神经状态空间中潜藏循环的能力，不变的循环作为承载意义的载体，通过过滤特定于顺序的噪声并保留跨情境持续存在的内容。点-循环二分法捕捉这一点：短暂的点支撑探索，而非平凡的循环编码低熵内容不变量，稳定记忆。从生物学上看，多时相神经群体通过STDP强化的延迟锁定放电实现1-循环，并嵌套在theta-γ节奏中，以确保边界取消。这些微循环逐级组合，将导航循环扩展为普遍的记忆和认知。感知-行动循环引入高阶不变性：即使在感觉-行动交替中，闭合亦能保持一致，从而泛化祖先的回巢行为。层kelas-层kelas对偶形式化这一过程：层kelas将知觉片段胶合为全局片段，层kelas分解全局计划为行动，并通过闭合对齐自上而下的预测与自下而上的循环。随之，意识作为持久的高阶不变量在不同情境中统一（整体性）又差异化（丰富性）。我们得出结论：循环即一切所需：持久不变量能够以最小能量成本在非遍历环境中实现泛化，并保持长期一致性。', 'title_zh': '循环即所需一切：更多即不同'}
{'arxiv_id': 'arXiv:2509.21331', 'title': 'Seismic Velocity Inversion from Multi-Source Shot Gathers Using Deep Segmentation Networks: Benchmarking U-Net Variants and SeismoLabV3+', 'authors': 'Mahedi Hasan', 'link': 'https://arxiv.org/abs/2509.21331', 'abstract': 'Seismic velocity inversion is a key task in geophysical exploration, enabling the reconstruction of subsurface structures from seismic wave data. It is critical for high-resolution seismic imaging and interpretation. Traditional physics-driven methods, such as Full Waveform Inversion (FWI), are computationally demanding, sensitive to initialization, and limited by the bandwidth of seismic data. Recent advances in deep learning have led to data-driven approaches that treat velocity inversion as a dense prediction task. This research benchmarks three advanced encoder-decoder architectures -- U-Net, U-Net++, and DeepLabV3+ -- together with SeismoLabV3+, an optimized variant of DeepLabV3+ with a ResNeXt50 32x4d backbone and task-specific modifications -- for seismic velocity inversion using the ThinkOnward 2025 Speed \\& Structure dataset, which consists of five-channel seismic shot gathers paired with high-resolution velocity maps. Experimental results show that SeismoLabV3+ achieves the best performance, with MAPE values of 0.03025 on the internal validation split and 0.031246 on the hidden test set as scored via the official ThinkOnward leaderboard. These findings demonstrate the suitability of deep segmentation networks for seismic velocity inversion and underscore the value of tailored architectural refinements in advancing geophysical AI models.', 'abstract_zh': '地震波速度反演是地质物理勘探中的关键任务，能够从地震波数据中重建地下结构。它对于高分辨率地震成像和解释至关重要。传统基于物理的方法，如全波形反演（FWI），计算需求高，对初始化敏感，并受限于地震数据的带宽。近年来，深度学习的进展导致了数据驱动的方法，将速度反演视为密集预测任务。本研究在ThinkOnward 2025 Speed & Structure 数据集上（该数据集包含五通道地震地震枪记录及其高分辨率速度图）评估了三种先进的编码器-解码器架构——U-Net、U-Net++ 和 DeepLabV3+，同时包括一个基于 ResNeXt50 32x4d 主干并进行了任务特定修改的优化变体 SeismoLabV3+。实验结果显示，SeismoLabV3+ 在内部验证分割上的 MAPE 值为 0.03025，在隐藏测试集上的 MAPE 值为 0.031246。这些发现表明深度分割网络适合用于地震波速度反演，并强调了为地质物理人工智能模型进行定制架构改进的价值。', 'title_zh': '使用深度分割网络从多源炮集数据中 inversion 地震波速：U-Net 变体和 SeismoLabV3+ 的基准测试'}
{'arxiv_id': 'arXiv:2509.21327', 'title': 'Assessment of deep learning models integrated with weather and environmental variables for wildfire spread prediction and a case study of the 2023 Maui fires', 'authors': 'Jiyeon Kim, Yingjie Hu, Negar Elhami-Khorasani, Kai Sun, Ryan Zhenqi Zhou', 'link': 'https://arxiv.org/abs/2509.21327', 'abstract': 'Predicting the spread of wildfires is essential for effective fire management and risk assessment. With the fast advancements of artificial intelligence (AI), various deep learning models have been developed and utilized for wildfire spread prediction. However, there is limited understanding of the advantages and limitations of these models, and it is also unclear how deep learning-based fire spread models can be compared with existing non-AI fire models. In this work, we assess the ability of five typical deep learning models integrated with weather and environmental variables for wildfire spread prediction based on over ten years of wildfire data in the state of Hawaii. We further use the 2023 Maui fires as a case study to compare the best deep learning models with a widely-used fire spread model, FARSITE. The results show that two deep learning models, i.e., ConvLSTM and ConvLSTM with attention, perform the best among the five tested AI models. FARSITE shows higher precision, lower recall, and higher F1-score than the best AI models, while the AI models offer higher flexibility for the input data. By integrating AI models with an explainable AI method, we further identify important weather and environmental factors associated with the 2023 Maui wildfires.', 'abstract_zh': '预测野火蔓延对于有效的火灾管理与风险评估至关重要。随着人工智能（AI）的快速发展，各种深度学习模型已被开发并用于野火蔓延预测。然而，对于这些模型的优势与限制尚缺乏足够的理解，同时也不清楚基于深度学习的野火蔓延模型如何与现有的非AI野火模型进行比较。在本文中，我们基于夏威夷州超过十年的野火数据，评估了五种典型深度学习模型结合气象与环境变量在野火蔓延预测中的能力。我们进一步以2023年 Maui 火灾为例，将最佳深度学习模型与广泛使用的野火蔓延模型 FARSITE 进行对比。结果显示，在测试的五种AI模型中，ConvLSTM 和带有注意力机制的 ConvLSTM 表现最佳。FARSITE 在精度上高于最佳AI模型，但在召回率和F1分数上较低，而AI模型在输入数据的灵活性方面表现更佳。通过将AI模型与可解释的AI方法相结合，我们进一步确定了与2023年Maui野火相关的关键气象与环境因素。', 'title_zh': '基于天气和环境变量的深度学习模型用于野火蔓延预测的评估及2023年毛伊火灾案例研究'}
{'arxiv_id': 'arXiv:2509.21325', 'title': 'PIR-RAG: A System for Private Information Retrieval in Retrieval-Augmented Generation', 'authors': 'Baiqiang Wang, Qian Lou, Mengxin Zheng, Dongfang Zhao', 'link': 'https://arxiv.org/abs/2509.21325', 'abstract': 'Retrieval-Augmented Generation (RAG) has become a foundational component of modern AI systems, yet it introduces significant privacy risks by exposing user queries to service providers. To address this, we introduce PIR-RAG, a practical system for privacy-preserving RAG. PIR-RAG employs a novel architecture that uses coarse-grained semantic clustering to prune the search space, combined with a fast, lattice-based Private Information Retrieval (PIR) protocol. This design allows for the efficient retrieval of entire document clusters, uniquely optimizing for the end-to-end RAG workflow where full document content is required. Our comprehensive evaluation against strong baseline architectures, including graph-based PIR and Tiptoe-style private scoring, demonstrates PIR-RAG\'s scalability and its superior performance in terms of "RAG-Ready Latency"-the true end-to-end time required to securely fetch content for an LLM. Our work establishes PIR-RAG as a viable and highly efficient solution for privacy in large-scale AI systems.', 'abstract_zh': '隐私保护的检索增强生成（PIR-RAG）已成为现代AI系统的基础组件，但会通过暴露用户查询给服务提供商而引入重大的隐私风险。为了解决这一问题，我们引入了PIR-RAG，这是一种实用的隐私保护检索增强生成系统。PIR-RAG采用了一种新颖的架构，结合了粗粒度语义聚类来修剪搜索空间，并使用快速的格基私有信息检索（PIR）协议。这一设计允许高效检索整个文档集群，针对需要完整文档内容的端到端RAG工作流进行优化。我们的全面评估表明，PIR-RAG在可扩展性和“RAG准备延迟”方面（即真正需要为LLM安全获取内容的端到端时间）优于包括基于图的PIR和Tiptoe风格私有评分在内的强基准架构。我们的工作确立了PIR-RAG作为大规模AI系统中隐私保护的可行且高效的解决方案。', 'title_zh': 'PIR-RAG：一种检索增强生成中的私人信息检索系统'}
{'arxiv_id': 'arXiv:2509.21324', 'title': 'From Search to Reasoning: A Five-Level RAG Capability Framework for Enterprise Data', 'authors': 'Gurbinder Gill, Ritvik Gupta, Denis Lusson, Anand Chandrashekar, Donald Nguyen', 'link': 'https://arxiv.org/abs/2509.21324', 'abstract': 'Retrieval-Augmented Generation (RAG) has emerged as the standard paradigm for answering questions on enterprise data. Traditionally, RAG has centered on text-based semantic search and re-ranking. However, this approach falls short when dealing with questions beyond data summarization or non-text data. This has led to various attempts to supplement RAG to bridge the gap between RAG, the implementation paradigm, and the question answering problem that enterprise users expect it to solve. Given that contemporary RAG is a collection of techniques rather than a defined implementation, discussion of RAG and related question-answering systems benefits from a problem-oriented understanding.\nWe propose a new classification framework (L1-L5) to categorize systems based on data modalities and task complexity of the underlying question answering problems: L1 (Surface Knowledge of Unstructured Data) through L4 (Reflective and Reasoned Knowledge) and the aspirational L5 (General Intelligence). We also introduce benchmarks aligned with these levels and evaluate four state-of-the-art platforms: LangChain, Azure AI Search, OpenAI, and Corvic AI. Our experiments highlight the value of multi-space retrieval and dynamic orchestration for enabling L1-L4 capabilities. We empirically validate our findings using diverse datasets indicative of enterprise use cases.', 'abstract_zh': 'RAG增强生成：面向企业数据的检索增强生成的新分类框架与评估', 'title_zh': '从搜索到推理：企业数据的五级RAG能力框架'}
