{'arxiv_id': 'arXiv:2504.17784', 'title': 'Gripper Keypose and Object Pointflow as Interfaces for Bimanual Robotic Manipulation', 'authors': 'Yuyin Yang, Zetao Cai, Yang Tian, Jia Zeng, Jiangmiao Pang', 'link': 'https://arxiv.org/abs/2504.17784', 'abstract': 'Bimanual manipulation is a challenging yet crucial robotic capability, demanding precise spatial localization and versatile motion trajectories, which pose significant challenges to existing approaches. Existing approaches fall into two categories: keyframe-based strategies, which predict gripper poses in keyframes and execute them via motion planners, and continuous control methods, which estimate actions sequentially at each timestep. The keyframe-based method lacks inter-frame supervision, struggling to perform consistently or execute curved motions, while the continuous method suffers from weaker spatial perception. To address these issues, this paper introduces an end-to-end framework PPI (keyPose and Pointflow Interface), which integrates the prediction of target gripper poses and object pointflow with the continuous actions estimation. These interfaces enable the model to effectively attend to the target manipulation area, while the overall framework guides diverse and collision-free trajectories. By combining interface predictions with continuous actions estimation, PPI demonstrates superior performance in diverse bimanual manipulation tasks, providing enhanced spatial localization and satisfying flexibility in handling movement restrictions. In extensive evaluations, PPI significantly outperforms prior methods in both simulated and real-world experiments, achieving state-of-the-art performance with a +16.1% improvement on the RLBench2 simulation benchmark and an average of +27.5% gain across four challenging real-world tasks. Notably, PPI exhibits strong stability, high precision, and remarkable generalization capabilities in real-world scenarios. Project page: this https URL', 'abstract_zh': '双臂操作是具有挑战性但又至关重要的机器人能力，需要精确的空间定位和多样的运动轨迹，这对现有方法提出了重大挑战。现有的方法主要分为两类：关键帧基方法，预测关键帧中的手部姿态并通过运动规划器执行；连续控制方法，在每个时间步序贯估计动作。关键帧基方法缺乏帧间监督，难以一致执行或执行曲线运动，而连续方法则在空间感知方面较弱。为解决这些问题，本文提出了一种端到端框架PPI（目标姿态和点流接口），将目标手部姿态和对象点流的预测与连续动作估计结合。这些接口使模型能够有效关注目标操作区域，而整体框架指导多样的无碰撞轨迹。通过结合接口预测和连续动作估计，PPI 在多种双臂操作任务中表现出优越性能，提供了增强的空间定位和在处理运动限制方面更好的灵活性。在广泛的评估中，PPI 在模拟和真实世界实验中均显著优于先前的方法，在RLBench2模拟基准测试中提高了16.1%，在四个具有挑战性的真实世界任务中平均提高了27.5%。值得一提的是，PPI 在真实世界场景中表现出强大的稳定性、高精度和卓越的泛化能力。项目页面：this https URL。', 'title_zh': 'Gripper Keypose和Object Pointflow作为双臂机器人 manipulation的接口'}
{'arxiv_id': 'arXiv:2504.17771', 'title': 'Integrating Learning-Based Manipulation and Physics-Based Locomotion for Whole-Body Badminton Robot Control', 'authors': 'Haochen Wang, Zhiwei Shi, Chengxi Zhu, Yafei Qiao, Cheng Zhang, Fan Yang, Pengjie Ren, Lan Lu, Dong Xuan', 'link': 'https://arxiv.org/abs/2504.17771', 'abstract': "Learning-based methods, such as imitation learning (IL) and reinforcement learning (RL), can produce excel control policies over challenging agile robot tasks, such as sports robot. However, no existing work has harmonized learning-based policy with model-based methods to reduce training complexity and ensure the safety and stability for agile badminton robot control. In this paper, we introduce \\ourmethod, a novel hybrid control system for agile badminton robots. Specifically, we propose a model-based strategy for chassis locomotion which provides a base for arm policy. We introduce a physics-informed ``IL+RL'' training framework for learning-based arm policy. In this train framework, a model-based strategy with privileged information is used to guide arm policy training during both IL and RL phases. In addition, we train the critic model during IL phase to alleviate the performance drop issue when transitioning from IL to RL. We present results on our self-engineered badminton robot, achieving 94.5% success rate against the serving machine and 90.7% success rate against human players. Our system can be easily generalized to other agile mobile manipulation tasks such as agile catching and table tennis. Our project website: this https URL.", 'abstract_zh': '基于学习的方法，如 imitative learning (IL) 和 reinforcement learning (RL)，可以为诸如运动机器人等挑战性的敏捷机器人任务生成优异的控制策略。然而，现有的工作尚未将基于学习的策略与基于模型的方法相结合，以降低训练复杂度并确保敏捷羽毛球机器人控制的安全性和稳定性。在本文中，我们提出了一种新颖的混合控制系统 \\ourmethod 用于敏捷羽毛球机器人。具体地，我们提出了一个基于模型的策略来实现底盘运动，为其上臂策略提供基础。我们引入了一个物理驱动的“IL+RL”训练框架，用于学习上臂策略。在此训练框架中，在 IL 和 RL 阶段均使用带有优先信息的基于模型的策略来指导上臂策略训练。此外，我们在 IL 阶段训练批评者模型，以减轻从 IL 切换到 RL 时性能下降的问题。我们在自行设计的羽毛球机器人上展示了结果，对抗发球机的成功率为 94.5%，对抗人类玩家的成功率为 90.7%。该系统可以轻松推广到其他敏捷移动操作任务，如敏捷捕捉和乒乓球。项目网址：this https URL。', 'title_zh': '基于学习的 manipulation 和基于物理的运动相结合的whole-body 游戏机器人控制'}
{'arxiv_id': 'arXiv:2504.17748', 'title': 'Robotic Task Ambiguity Resolution via Natural Language Interaction', 'authors': 'Eugenio Chisari, Jan Ole von Hartz, Fabien Despinoy, Abhinav Valada', 'link': 'https://arxiv.org/abs/2504.17748', 'abstract': 'Language-conditioned policies have recently gained substantial adoption in robotics as they allow users to specify tasks using natural language, making them highly versatile. While much research has focused on improving the action prediction of language-conditioned policies, reasoning about task descriptions has been largely overlooked. Ambiguous task descriptions often lead to downstream policy failures due to misinterpretation by the robotic agent. To address this challenge, we introduce AmbResVLM, a novel method that grounds language goals in the observed scene and explicitly reasons about task ambiguity. We extensively evaluate its effectiveness in both simulated and real-world domains, demonstrating superior task ambiguity detection and resolution compared to recent state-of-the-art baselines. Finally, real robot experiments show that our model improves the performance of downstream robot policies, increasing the average success rate from 69.6% to 97.1%. We make the data, code, and trained models publicly available at this https URL.', 'abstract_zh': '基于语言条件的策略近年来在机器人领域获得了广泛应用，它们允许用户使用自然语言指定任务，使这些策略具有高度的灵活性。虽然许多研究集中在改进语言条件策略的动作预测上，但对任务描述的推理却鲜有关注。含糊的任务描述往往会导致下游策略因机器人代理的误解而失败。为了解决这一挑战，我们提出了AmbResVLM，这是一种新方法，将语言目标与观察到的场景联系起来，并明确地推理任务的含糊性。我们在模拟和实际场景中广泛评估了其有效性，展示了其在检测和解决任务含糊性方面优于最近的先进baseline方法的能力。最后，真实的机器人实验表明，我们的模型提高了下游机器人策略的性能，平均成功率从69.6%提高到97.1%。我们将在以下链接公开数据、代码和训练模型：this https URL。', 'title_zh': '基于自然语言交互的机器人任务歧义解决'}
{'arxiv_id': 'arXiv:2504.17249', 'title': 'Demonstrating Berkeley Humanoid Lite: An Open-source, Accessible, and Customizable 3D-printed Humanoid Robot', 'authors': 'Yufeng Chi, Qiayuan Liao, Junfeng Long, Xiaoyu Huang, Sophia Shao, Borivoje Nikolic, Zhongyu Li, Koushil Sreenath', 'link': 'https://arxiv.org/abs/2504.17249', 'abstract': "Despite significant interest and advancements in humanoid robotics, most existing commercially available hardware remains high-cost, closed-source, and non-transparent within the robotics community. This lack of accessibility and customization hinders the growth of the field and the broader development of humanoid technologies. To address these challenges and promote democratization in humanoid robotics, we demonstrate Berkeley Humanoid Lite, an open-source humanoid robot designed to be accessible, customizable, and beneficial for the entire community. The core of this design is a modular 3D-printed gearbox for the actuators and robot body. All components can be sourced from widely available e-commerce platforms and fabricated using standard desktop 3D printers, keeping the total hardware cost under $5,000 (based on U.S. market prices). The design emphasizes modularity and ease of fabrication. To address the inherent limitations of 3D-printed gearboxes, such as reduced strength and durability compared to metal alternatives, we adopted a cycloidal gear design, which provides an optimal form factor in this context. Extensive testing was conducted on the 3D-printed actuators to validate their durability and alleviate concerns about the reliability of plastic components. To demonstrate the capabilities of Berkeley Humanoid Lite, we conducted a series of experiments, including the development of a locomotion controller using reinforcement learning. These experiments successfully showcased zero-shot policy transfer from simulation to hardware, highlighting the platform's suitability for research validation. By fully open-sourcing the hardware design, embedded code, and training and deployment frameworks, we aim for Berkeley Humanoid Lite to serve as a pivotal step toward democratizing the development of humanoid robotics. All resources are available at this https URL.", 'abstract_zh': '尽管对类人机器人研究有着显著的兴趣和进展，但大多数现有的商用硬件仍然价格高昂、闭源且在机器人社区中不够透明。这种缺乏可访问性和可定制性的状况阻碍了该领域的增长以及类人技术的更广泛发展。为应对这些挑战并促进类人机器人领域的民主化，我们展示了伯克利类人机器人Lite（Berkeley Humanoid Lite），这是一个开源的类人机器人，旨在提高可访问性、可定制性并惠及整个社区。该设计的核心是模块化的3D打印齿轮箱和机器人主体。所有组件均可从广泛可用的电子商务平台获取，并可以使用标准的桌面3D打印机进行制造，从而使整体硬件成本保持在5000美元以下（基于美国市场价格）。该设计强调模块化和易于制造。为解决3D打印齿轮箱固有的局限性，例如与金属替代品相比的强度和耐用性较低的问题，我们采用了玉轮齿轮设计，这在这一背景下提供了最优的结构形式。对3D打印执行器进行了广泛的测试，以验证其耐用性并缓解对塑料组件可靠性的担忧。为了展示伯克利类人机器人Lite的能力，我们进行了一系列实验，包括使用强化学习开发步行控制器。这些实验成功展示了从模拟到硬件的零样本策略转移，突显了该平台在研究验证方面的适用性。通过全面开源硬件设计、嵌入式代码以及训练和部署框架，我们旨在使伯克利类人机器人Lite成为通向类人机器人领域民主化的关键一步。所有资源可在以下链接获取。', 'title_zh': '展示伯克利 humanoID lite：一个开源、易获取且可定制的3D打印人形机器人'}
{'arxiv_id': 'arXiv:2504.17201', 'title': 'Simultaneous Collision Detection and Force Estimation for Dynamic Quadrupedal Locomotion', 'authors': 'Ziyi Zhou, Stefano Di Cairano, Yebin Wang, Karl Berntorp', 'link': 'https://arxiv.org/abs/2504.17201', 'abstract': "In this paper we address the simultaneous collision detection and force estimation problem for quadrupedal locomotion using joint encoder information and the robot dynamics only. We design an interacting multiple-model Kalman filter (IMM-KF) that estimates the external force exerted on the robot and multiple possible contact modes. The method is invariant to any gait pattern design. Our approach leverages pseudo-measurement information of the external forces based on the robot dynamics and encoder information. Based on the estimated contact mode and external force, we design a reflex motion and an admittance controller for the swing leg to avoid collisions by adjusting the leg's reference motion. Additionally, we implement a force-adaptive model predictive controller to enhance balancing. Simulation ablatation studies and experiments show the efficacy of the approach.", 'abstract_zh': '基于关节编码器信息和机器人动力学的腿足机器人碰撞检测与力估计方法', 'title_zh': '动态四腿行进中同时碰撞检测与力估计'}
{'arxiv_id': 'arXiv:2504.17006', 'title': 'A Systematic Approach to Design Real-World Human-in-the-Loop Deep Reinforcement Learning: Salient Features, Challenges and Trade-offs', 'authors': 'Jalal Arabneydi, Saiful Islam, Srijita Das, Sai Krishna Gottipati, William Duguay, Cloderic Mars, Matthew E. Taylor, Matthew Guzdial, Antoine Fagette, Younes Zerouali', 'link': 'https://arxiv.org/abs/2504.17006', 'abstract': 'With the growing popularity of deep reinforcement learning (DRL), human-in-the-loop (HITL) approach has the potential to revolutionize the way we approach decision-making problems and create new opportunities for human-AI collaboration. In this article, we introduce a novel multi-layered hierarchical HITL DRL algorithm that comprises three types of learning: self learning, imitation learning and transfer learning. In addition, we consider three forms of human inputs: reward, action and demonstration. Furthermore, we discuss main challenges, trade-offs and advantages of HITL in solving complex problems and how human information can be integrated in the AI solution systematically. To verify our technical results, we present a real-world unmanned aerial vehicles (UAV) problem wherein a number of enemy drones attack a restricted area. The objective is to design a scalable HITL DRL algorithm for ally drones to neutralize the enemy drones before they reach the area. To this end, we first implement our solution using an award-winning open-source HITL software called Cogment. We then demonstrate several interesting results such as (a) HITL leads to faster training and higher performance, (b) advice acts as a guiding direction for gradient methods and lowers variance, and (c) the amount of advice should neither be too large nor too small to avoid over-training and under-training. Finally, we illustrate the role of human-AI cooperation in solving two real-world complex scenarios, i.e., overloaded and decoy attacks.', 'abstract_zh': '基于人类在环的深度强化学习多层层次算法及其在无人作战无人机任务中的应用', 'title_zh': '系统化的人机环路深度强化学习设计方法：关键特征、挑战与权衡'}
{'arxiv_id': 'arXiv:2504.17356', 'title': 'Comprehend, Divide, and Conquer: Feature Subspace Exploration via Multi-Agent Hierarchical Reinforcement Learning', 'authors': 'Weiliang Zhang, Xiaohan Huang, Yi Du, Ziyue Qiao, Qingqing Long, Zhen Meng, Yuanchun Zhou, Meng Xiao', 'link': 'https://arxiv.org/abs/2504.17356', 'abstract': "Feature selection aims to preprocess the target dataset, find an optimal and most streamlined feature subset, and enhance the downstream machine learning task. Among filter, wrapper, and embedded-based approaches, the reinforcement learning (RL)-based subspace exploration strategy provides a novel objective optimization-directed perspective and promising performance. Nevertheless, even with improved performance, current reinforcement learning approaches face challenges similar to conventional methods when dealing with complex datasets. These challenges stem from the inefficient paradigm of using one agent per feature and the inherent complexities present in the datasets. This observation motivates us to investigate and address the above issue and propose a novel approach, namely HRLFS. Our methodology initially employs a Large Language Model (LLM)-based hybrid state extractor to capture each feature's mathematical and semantic characteristics. Based on this information, features are clustered, facilitating the construction of hierarchical agents for each cluster and sub-cluster. Extensive experiments demonstrate the efficiency, scalability, and robustness of our approach. Compared to contemporary or the one-feature-one-agent RL-based approaches, HRLFS improves the downstream ML performance with iterative feature subspace exploration while accelerating total run time by reducing the number of agents involved.", 'abstract_zh': '基于强化学习的层次化特征选择（HRLFS）方法：提高下游机器学习性能的新视角', 'title_zh': '理解、分解与征服：基于多agent层次强化学习的特征子空间探索'}
{'arxiv_id': 'arXiv:2504.17282', 'title': 'Cracking the Code of Action: a Generative Approach to Affordances for Reinforcement Learning', 'authors': 'Lynn Cherif, Flemming Kondrup, David Venuto, Ankit Anand, Doina Precup, Khimya Khetarpal', 'link': 'https://arxiv.org/abs/2504.17282', 'abstract': "Agents that can autonomously navigate the web through a graphical user interface (GUI) using a unified action space (e.g., mouse and keyboard actions) can require very large amounts of domain-specific expert demonstrations to achieve good performance. Low sample efficiency is often exacerbated in sparse-reward and large-action-space environments, such as a web GUI, where only a few actions are relevant in any given situation. In this work, we consider the low-data regime, with limited or no access to expert behavior. To enable sample-efficient learning, we explore the effect of constraining the action space through $\\textit{intent-based affordances}$ -- i.e., considering in any situation only the subset of actions that achieve a desired outcome. We propose $\\textbf{Code as Generative Affordances}$ $(\\textbf{$\\texttt{CoGA}$})$, a method that leverages pre-trained vision-language models (VLMs) to generate code that determines affordable actions through implicit intent-completion functions and using a fully-automated program generation and verification pipeline. These programs are then used in-the-loop of a reinforcement learning agent to return a set of affordances given a pixel observation. By greatly reducing the number of actions that an agent must consider, we demonstrate on a wide range of tasks in the MiniWob++ benchmark that: $\\textbf{1)}$ $\\texttt{CoGA}$ is orders of magnitude more sample efficient than its RL agent, $\\textbf{2)}$ $\\texttt{CoGA}$'s programs can generalize within a family of tasks, and $\\textbf{3)}$ $\\texttt{CoGA}$ performs better or on par compared with behavior cloning when a small number of expert demonstrations is available.", 'abstract_zh': '基于意图的生成能力约束下的代码生成方法（CoGA）在低数据量环境中的强化学习应用', 'title_zh': '破解行动的代码：生成方法在强化学习中的可用性'}
{'arxiv_id': 'arXiv:2504.17669', 'title': 'Towards a HIPAA Compliant Agentic AI System in Healthcare', 'authors': 'Subash Neupane, Shaswata Mitra, Sudip Mittal, Shahram Rahimi', 'link': 'https://arxiv.org/abs/2504.17669', 'abstract': 'Agentic AI systems powered by Large Language Models (LLMs) as their foundational reasoning engine, are transforming clinical workflows such as medical report generation and clinical summarization by autonomously analyzing sensitive healthcare data and executing decisions with minimal human oversight. However, their adoption demands strict compliance with regulatory frameworks such as Health Insurance Portability and Accountability Act (HIPAA), particularly when handling Protected Health Information (PHI). This work-in-progress paper introduces a HIPAA-compliant Agentic AI framework that enforces regulatory compliance through dynamic, context-aware policy enforcement. Our framework integrates three core mechanisms: (1) Attribute-Based Access Control (ABAC) for granular PHI governance, (2) a hybrid PHI sanitization pipeline combining regex patterns and BERT-based model to minimize leakage, and (3) immutable audit trails for compliance verification.', 'abstract_zh': '由大型语言模型（LLMs）作为基础推理引擎的代理AI系统正在通过自主分析敏感的医疗数据和在 minimal 人类监督下执行决策来转变临床工作流程，例如医学报告生成和临床总结。然而，其采用需要严格遵守健康保险便携性和责任法案（HIPAA）等监管框架，特别是在处理受保护的健康信息（PHI）时。本文介绍了一种符合HIPAA要求的代理AI框架，该框架通过动态、上下文感知的策略执行来强制执行监管合规性。该框架整合了三个核心机制：（1）基于属性的访问控制（ABAC）进行细粒度的PHI治理，（2）结合正则表达式模式和BERT模型的混合PHI脱敏流水线以最小化泄漏，以及（3）不可变的审计跟踪以进行合规验证。', 'title_zh': '面向医疗健康领域的符合HIPAA合规的代理型人工智能系统研究'}
{'arxiv_id': 'arXiv:2504.17315', 'title': "DIMT25@ICDAR2025: HW-TSC's End-to-End Document Image Machine Translation System Leveraging Large Vision-Language Model", 'authors': 'Zhanglin Wu, Tengfei Song, Ning Xie, Weidong Zhang, Pengfei Li, Shuang Wu, Chong Li, Junhao Zhu, Hao Yang', 'link': 'https://arxiv.org/abs/2504.17315', 'abstract': 'This paper presents the technical solution proposed by Huawei Translation Service Center (HW-TSC) for the "End-to-End Document Image Machine Translation for Complex Layouts" competition at the 19th International Conference on Document Analysis and Recognition (DIMT25@ICDAR2025). Leveraging state-of-the-art open-source large vision-language model (LVLM), we introduce a training framework that combines multi-task learning with perceptual chain-of-thought to develop a comprehensive end-to-end document translation system. During the inference phase, we apply minimum Bayesian decoding and post-processing strategies to further enhance the system\'s translation capabilities. Our solution uniquely addresses both OCR-based and OCR-free document image translation tasks within a unified framework. This paper systematically details the training methods, inference strategies, LVLM base models, training data, experimental setups, and results, demonstrating an effective approach to document image machine translation.', 'abstract_zh': '华为翻译服务中心（HW-TSC）在第19届国际文档分析与识别会议（ICDAR2025）“端到端复杂布局文档图像机器翻译”竞赛中的技术解决方案：利用最新开源的大型视觉-语言模型构建综合端到端文档翻译系统及其应用策略。', 'title_zh': 'DIMT25@ICDAR2025：HW-TSC基于大规模视觉-语言模型的端到端文档图像机器翻译系统'}
