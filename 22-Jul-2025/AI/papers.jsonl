{'arxiv_id': 'arXiv:2507.15855', 'title': 'Gemini 2.5 Pro Capable of Winning Gold at IMO 2025', 'authors': 'Yichen Huang, Lin F. Yang', 'link': 'https://arxiv.org/abs/2507.15855', 'abstract': "The International Mathematical Olympiad (IMO) poses uniquely challenging problems requiring deep insight, creativity, and formal reasoning. While Large Language Models (LLMs) perform well on mathematical benchmarks like AIME, they struggle with Olympiad-level tasks. We use Google's Gemini 2.5 Pro on the newly released IMO 2025 problems, avoiding data contamination. With pipeline design and prompt engineering, 5 (out of 6) problems are solved correctly (up to a caveat discussed below), highlighting the importance of finding the optimal way of using powerful models.", 'abstract_zh': '国际数学奥林匹克（IMO）提出了一系列独特挑战的问题，要求深厚的理解、创造力和形式化推理。尽管大型语言模型（LLMs）在AIME等数学基准测试中表现良好，但在奥林匹克级别任务上仍遇到困难。我们使用谷歌的Gemini 2.5 Pro解决新发布的IMO 2025问题，避免数据污染。通过管道设计和提示工程，解决了5个问题中的6个（以下有讨论的例外情况），强调了找到有效利用强大模型的方法的重要性。', 'title_zh': 'Gemini 2.5 Pro能够在2025年国际数学奥林匹克竞赛中获奖。'}
{'arxiv_id': 'arXiv:2507.15851', 'title': 'The Other Mind: How Language Models Exhibit Human Temporal Cognition', 'authors': 'Lingyu Li, Yang Yao, Yixu Wang, Chubo Li, Yan Teng, Yingchun Wang', 'link': 'https://arxiv.org/abs/2507.15851', 'abstract': "As Large Language Models (LLMs) continue to advance, they exhibit certain cognitive patterns similar to those of humans that are not directly specified in training data. This study investigates this phenomenon by focusing on temporal cognition in LLMs. Leveraging the similarity judgment task, we find that larger models spontaneously establish a subjective temporal reference point and adhere to the Weber-Fechner law, whereby the perceived distance logarithmically compresses as years recede from this reference point. To uncover the mechanisms behind this behavior, we conducted multiple analyses across neuronal, representational, and informational levels. We first identify a set of temporal-preferential neurons and find that this group exhibits minimal activation at the subjective reference point and implements a logarithmic coding scheme convergently found in biological systems. Probing representations of years reveals a hierarchical construction process, where years evolve from basic numerical values in shallow layers to abstract temporal orientation in deep layers. Finally, using pre-trained embedding models, we found that the training corpus itself possesses an inherent, non-linear temporal structure, which provides the raw material for the model's internal construction. In discussion, we propose an experientialist perspective for understanding these findings, where the LLMs' cognition is viewed as a subjective construction of the external world by its internal representational system. This nuanced perspective implies the potential emergence of alien cognitive frameworks that humans cannot intuitively predict, pointing toward a direction for AI alignment that focuses on guiding internal constructions. Our code is available at this https URL.", 'abstract_zh': '随着大型语言模型（LLMs）的不断进步，它们在训练数据中未直接指定的情况下表现出某些类似于人类的认知模式。本文通过关注LLMs的时间认知来研究这一现象。借助相似性判断任务，我们发现大型模型会自发建立一个主观时间参考点，并遵循韦伯-费希纳定律，即感知的距离随着与该参考点时间差的增大而以对数形式压缩。为探究这种行为背后的机制，我们在神经元、表示和信息层面进行了多项分析。我们首先识别出一组时间偏好神经元，并发现这一组在主观参考点处表现出最小的激活，并实现了一种在生物系统中广泛发现的对数编码方案。探查年份的表示揭示了一种分层构建过程，其中年份在浅层从基本数值进化到深层的抽象时间定向。最后，利用预训练嵌入模型，我们发现训练语料本身具有内在的非线性时间结构，为模型内部构建提供了基础材料。在讨论中，我们提出了一种经验主义视角来理解这些发现，将LLMs的认知视为其内部表示系统对其外部世界的主观构建。这一细微视角暗示了可能出现人类无法直观预测的外星认知框架的可能性，指出了聚焦于引导内部构建的AI对齐方向。', 'title_zh': '其他思维：语言模型如何表现出人类时间认知'}
{'arxiv_id': 'arXiv:2507.15844', 'title': 'Hierarchical Budget Policy Optimization for Adaptive Reasoning', 'authors': 'Shangke Lyu, Linjuan Wu, Yuchen Yan, Xingyu Wu, Hao Li, Yongliang Shen, Peisheng Jiang, Weiming Lu, Jun Xiao, Yueting Zhuang', 'link': 'https://arxiv.org/abs/2507.15844', 'abstract': 'Large reasoning models achieve remarkable performance through extensive chain-of-thought generation, yet exhibit significant computational inefficiency by applying uniform reasoning strategies regardless of problem complexity. We present Hierarchical Budget Policy Optimization (HBPO), a reinforcement learning framework that enables models to learn problem-specific reasoning depths without sacrificing capability. HBPO addresses the fundamental challenge of exploration space collapse in efficiency-oriented training, where penalties on long output length systematically bias models away from necessary long reasoning paths. Through hierarchical budget exploration, our approach partitions rollout samples into multiple subgroups with distinct token budgets, aiming to enable efficient resource allocation while preventing degradation of capability. We introduce differentiated reward mechanisms that create budget-aware incentives aligned with the complexity of the problem, allowing models to discover natural correspondences between task requirements and computational effort. Extensive experiments demonstrate that HBPO reduces average token usage by up to 60.6% while improving accuracy by 3.14% across four reasoning benchmarks. Unlike existing methods that impose external constraints or rely on discrete mode selection, HBPO exhibits emergent adaptive behavior where models automatically adjust reasoning depth based on problem complexity. Our results suggest that reasoning efficiency and capability are not inherently conflicting, and can be simultaneously optimized through appropriately structured hierarchical training that preserves exploration diversity.', 'abstract_zh': '分级预算策略优化（HBPO）：提高推理模型的推理效率与能力', 'title_zh': '层次预算策略优化以实现自适应推理'}
{'arxiv_id': 'arXiv:2507.15842', 'title': 'Identifying Conditional Causal Effects in MPDAGs', 'authors': 'Sara LaPlante, Emilija Perković', 'link': 'https://arxiv.org/abs/2507.15842', 'abstract': 'We consider identifying a conditional causal effect when a graph is known up to a maximally oriented partially directed acyclic graph (MPDAG). An MPDAG represents an equivalence class of graphs that is restricted by background knowledge and where all variables in the causal model are observed. We provide three results that address identification in this setting: an identification formula when the conditioning set is unaffected by treatment, a generalization of the well-known do calculus to the MPDAG setting, and an algorithm that is complete for identifying these conditional effects.', 'abstract_zh': '当我们知道图是最大化有向部分导向无环图（MPDAG）时，识别条件因果效应的研究', 'title_zh': 'MPDAG中条件因果效应的识别'}
{'arxiv_id': 'arXiv:2507.15796', 'title': "Challenges of Trustworthy Federated Learning: What's Done, Current Trends and Remaining Work", 'authors': 'Nuria Rodríguez-Barroso, Mario García-Márquez, M. Victoria Luzón, Francisco Herrera', 'link': 'https://arxiv.org/abs/2507.15796', 'abstract': 'In recent years, the development of Trustworthy Artificial Intelligence (TAI) has emerged as a critical objective in the deployment of AI systems across sensitive and high-risk domains. TAI frameworks articulate a comprehensive set of ethical, legal, and technical requirements to ensure that AI technologies are aligned with human values, rights, and societal expectations. Among the various AI paradigms, Federated Learning (FL) presents a promising solution to pressing privacy concerns. However, aligning FL with the rest of the requirements of TAI presents a series of challenges, most of which arise from its inherently distributed nature. In this work, we adopt the requirements TAI as a guiding structure to systematically analyze the challenges of adapting FL to TAI. Specifically, we classify and examine the key obstacles to aligning FL with TAI, providing a detailed exploration of what has been done, the trends, and the remaining work within each of the identified challenges.', 'abstract_zh': '近年来，可信赖人工智能（TAI）的发展已成为在敏感和高风险领域部署AI系统的关键目标。TAI框架阐述了一套全面的伦理、法律和技术要求，以确保AI技术与人类价值观、权利和社会期望相一致。在各种AI范式中，联邦学习（FL）为解决紧迫的隐私问题提供了一种有前景的解决方案。然而，将FL与TAI的其他要求对齐带来了系列挑战，大多数挑战源于其本体分布式性质。在本文中，我们采用TAI的要求作为指导框架，系统地分析将FL适应TAI所面临的挑战。具体来说，我们对将FL与TAI对齐的关键障碍进行了分类和评估，详细探讨了每个识别挑战下的已做工作、趋势和遗留问题。', 'title_zh': '可信赖联邦学习的挑战：已做工作、当前趋势及剩余工作'}
{'arxiv_id': 'arXiv:2507.15770', 'title': 'A Framework for Analyzing Abnormal Emergence in Service Ecosystems Through LLM-based Agent Intention Mining', 'authors': 'Yifan Shen, Zihan Zhao, Xiao Xue, Yuwei Guo, Qun Ma, Deyu Zhou, Ming Zhang', 'link': 'https://arxiv.org/abs/2507.15770', 'abstract': 'With the rise of service computing, cloud computing, and IoT, service ecosystems are becoming increasingly complex. The intricate interactions among intelligent agents make abnormal emergence analysis challenging, as traditional causal methods focus on individual trajectories. Large language models offer new possibilities for Agent-Based Modeling (ABM) through Chain-of-Thought (CoT) reasoning to reveal agent intentions. However, existing approaches remain limited to microscopic and static analysis. This paper introduces a framework: Emergence Analysis based on Multi-Agent Intention (EAMI), which enables dynamic and interpretable emergence analysis. EAMI first employs a dual-perspective thought track mechanism, where an Inspector Agent and an Analysis Agent extract agent intentions under bounded and perfect rationality. Then, k-means clustering identifies phase transition points in group intentions, followed by a Intention Temporal Emergence diagram for dynamic analysis. The experiments validate EAMI in complex online-to-offline (O2O) service system and the Stanford AI Town experiment, with ablation studies confirming its effectiveness, generalizability, and efficiency. This framework provides a novel paradigm for abnormal emergence and causal analysis in service ecosystems. The code is available at this https URL.', 'abstract_zh': '基于多智能体意向的异变分析框架（EAMI）：服务生态系统中的动态可解释异变分析', 'title_zh': '基于大语言模型代理意图挖掘的服务生态系统异常涌现分析框架'}
{'arxiv_id': 'arXiv:2507.15761', 'title': 'GasAgent: A Multi-Agent Framework for Automated Gas Optimization in Smart Contracts', 'authors': 'Jingyi Zheng, Zifan Peng, Yule Liu, Junfeng Wang, Yifan Liao, Wenhan Dong, Xinlei He', 'link': 'https://arxiv.org/abs/2507.15761', 'abstract': 'Smart contracts are trustworthy, immutable, and automatically executed programs on the blockchain. Their execution requires the Gas mechanism to ensure efficiency and fairness. However, due to non-optimal coding practices, many contracts contain Gas waste patterns that need to be optimized. Existing solutions mostly rely on manual discovery, which is inefficient, costly to maintain, and difficult to scale. Recent research uses large language models (LLMs) to explore new Gas waste patterns. However, it struggles to remain compatible with existing patterns, often produces redundant patterns, and requires manual validation/rewriting. To address this gap, we present GasAgent, the first multi-agent system for smart contract Gas optimization that combines compatibility with existing patterns and automated discovery/validation of new patterns, enabling end-to-end optimization. GasAgent consists of four specialized agents, Seeker, Innovator, Executor, and Manager, that collaborate in a closed loop to identify, validate, and apply Gas-saving improvements. Experiments on 100 verified real-world contracts demonstrate that GasAgent successfully optimizes 82 contracts, achieving an average deployment Gas savings of 9.97%. In addition, our evaluation confirms its compatibility with existing tools and validates the effectiveness of each module through ablation studies. To assess broader usability, we further evaluate 500 contracts generated by five representative LLMs across 10 categories and find that GasAgent optimizes 79.8% of them, with deployment Gas savings ranging from 4.79% to 13.93%, showing its usability as the optimization layer for LLM-assisted smart contract development.', 'abstract_zh': '基于多agent系统的智能合约Gas优化方法：兼容现有模式并自动发现/验证新型模式', 'title_zh': 'GasAgent：智能合约中自动气体优化的多代理框架'}
{'arxiv_id': 'arXiv:2507.15758', 'title': 'LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy Optimization', 'authors': 'Xingyu Wu, Yuchen Yan, Shangke Lyu, Linjuan Wu, Yiwen Qiu, Yongliang Shen, Weiming Lu, Jian Shao, Jun Xiao, Yueting Zhuang', 'link': 'https://arxiv.org/abs/2507.15758', 'abstract': "Large reasoning models have achieved remarkable performance through extended chain-of-thought sequences, yet this computational freedom leads to excessive token generation even for simple problems. We present Length-Adaptive Policy Optimization (LAPO), a novel framework that transforms reasoning length control from an external constraint into an intrinsic model capability. Unlike existing approaches that impose rigid limits or rely on post-hoc interventions, LAPO enables models to internalize an understanding of appropriate reasoning depth through a two-stage reinforcement learning process. In the first stage, models learn natural reasoning patterns by discovering the statistical distribution of successful solution lengths. The second stage leverages these patterns as meta-cognitive guidance, embedding them directly within the model's reasoning context to ensure inference-time flexibility. Experiments on mathematical reasoning benchmarks demonstrate that LAPO reduces token usage by up to 40.9\\% while improving accuracy by 2.3\\%. Our analysis reveals that models trained with LAPO develop emergent abilities to allocate computational resources based on problem complexity, achieving efficient reasoning without sacrificing quality.", 'abstract_zh': 'Length-Adaptive Policy Optimization: Transforming Reasoning Length Control into an Intrinsic Model Capability', 'title_zh': 'LAPO：基于长度自适应策略优化的推理效率内化'}
{'arxiv_id': 'arXiv:2507.15743', 'title': 'Towards physician-centered oversight of conversational diagnostic AI', 'authors': 'Elahe Vedadi, David Barrett, Natalie Harris, Ellery Wulczyn, Shashir Reddy, Roma Ruparel, Mike Schaekermann, Tim Strother, Ryutaro Tanno, Yash Sharma, Jihyeon Lee, Cían Hughes, Dylan Slack, Anil Palepu, Jan Freyberg, Khaled Saab, Valentin Liévin, Wei-Hung Weng, Tao Tu, Yun Liu, Nenad Tomasev, Kavita Kulkarni, S. Sara Mahdavi, Kelvin Guu, Joëlle Barral, Dale R. Webster, James Manyika, Avinatan Hassidim, Katherine Chou, Yossi Matias, Pushmeet Kohli, Adam Rodman, Vivek Natarajan, Alan Karthikesalingam, David Stutz', 'link': 'https://arxiv.org/abs/2507.15743', 'abstract': "Recent work has demonstrated the promise of conversational AI systems for diagnostic dialogue. However, real-world assurance of patient safety means that providing individual diagnoses and treatment plans is considered a regulated activity by licensed professionals. Furthermore, physicians commonly oversee other team members in such activities, including nurse practitioners (NPs) or physician assistants/associates (PAs). Inspired by this, we propose a framework for effective, asynchronous oversight of the Articulate Medical Intelligence Explorer (AMIE) AI system. We propose guardrailed-AMIE (g-AMIE), a multi-agent system that performs history taking within guardrails, abstaining from individualized medical advice. Afterwards, g-AMIE conveys assessments to an overseeing primary care physician (PCP) in a clinician cockpit interface. The PCP provides oversight and retains accountability of the clinical decision. This effectively decouples oversight from intake and can thus happen asynchronously. In a randomized, blinded virtual Objective Structured Clinical Examination (OSCE) of text consultations with asynchronous oversight, we compared g-AMIE to NPs/PAs or a group of PCPs under the same guardrails. Across 60 scenarios, g-AMIE outperformed both groups in performing high-quality intake, summarizing cases, and proposing diagnoses and management plans for the overseeing PCP to review. This resulted in higher quality composite decisions. PCP oversight of g-AMIE was also more time-efficient than standalone PCP consultations in prior work. While our study does not replicate existing clinical practices and likely underestimates clinicians' capabilities, our results demonstrate the promise of asynchronous oversight as a feasible paradigm for diagnostic AI systems to operate under expert human oversight for enhancing real-world care.", 'abstract_zh': '基于守门人机制的Articulate Medical Intelligence Explorer (AMIE) 异步监督框架', 'title_zh': '面向医生的对话诊断AI监管研究'}
{'arxiv_id': 'arXiv:2507.15676', 'title': 'Agentic AI for autonomous anomaly management in complex systems', 'authors': 'Reza Vatankhah Barenji, Sina Khoshgoftar', 'link': 'https://arxiv.org/abs/2507.15676', 'abstract': 'This paper explores the potential of agentic AI in autonomously detecting and responding to anomalies within complex systems, emphasizing its ability to transform traditional, human-dependent anomaly management methods.', 'abstract_zh': '本文探讨了代理型人工智能在自主检测和应对复杂系统中的异常方面的潜力，强调了其-transform传统、依赖人力的异常管理方法的能力。', 'title_zh': '自主代理人工智能在复杂系统中的自主异常管理'}
{'arxiv_id': 'arXiv:2507.15618', 'title': 'TacticCraft: Natural Language-Driven Tactical Adaptation for StarCraft II', 'authors': 'Weiyu Ma, Jiwen Jiang, Haobo Fu, Haifeng Zhang', 'link': 'https://arxiv.org/abs/2507.15618', 'abstract': 'We present an adapter-based approach for tactical conditioning of StarCraft II AI agents. Current agents, while powerful, lack the ability to adapt their strategies based on high-level tactical directives. Our method freezes a pre-trained policy network (DI-Star) and attaches lightweight adapter modules to each action head, conditioned on a tactical tensor that encodes strategic preferences. By training these adapters with KL divergence constraints, we ensure the policy maintains core competencies while exhibiting tactical variations. Experimental results show our approach successfully modulates agent behavior across tactical dimensions including aggression, expansion patterns, and technology preferences, while maintaining competitive performance. Our method enables flexible tactical control with minimal computational overhead, offering practical strategy customization for complex real-time strategy games.', 'abstract_zh': '基于适配器的方法用于StarCraft II AI代理的战术训练', 'title_zh': 'TacticCraft：基于自然语言的《星际争霸II》战术适应性方法'}
{'arxiv_id': 'arXiv:2507.15581', 'title': 'Metric assessment protocol in the context of answer fluctuation on MCQ tasks', 'authors': 'Ekaterina Goliakova, Xavier Renard, Marie-Jeanne Lesot, Thibault Laugel, Christophe Marsala, Marcin Detyniecki', 'link': 'https://arxiv.org/abs/2507.15581', 'abstract': 'Using multiple-choice questions (MCQs) has become a standard for assessing LLM capabilities efficiently. A variety of metrics can be employed for this task. However, previous research has not conducted a thorough assessment of them. At the same time, MCQ evaluation suffers from answer fluctuation: models produce different results given slight changes in prompts. We suggest a metric assessment protocol in which evaluation methodologies are analyzed through their connection with fluctuation rates, as well as original performance. Our results show that there is a strong link between existing metrics and the answer changing, even when computed without any additional prompt variants. A novel metric, worst accuracy, demonstrates the highest association on the protocol.', 'abstract_zh': '使用多项选择题（MCQs）评估LLM能力已成为一种标准，但由于缺乏全面评估，多种度量标准的应用仍存争议。同时，MCQ评估受到答案波动的影响：在提示稍有变化时，模型会产生不同结果。我们建议一种度量标准评估方案，通过分析评估方法与其波动率及原始性能之间的联系来评估这些度量标准。结果显示，现有的多种度量标准与答案波动之间存在密切联系，即使在没有额外提示变体的情况下计算也是如此。一种新颖的度量标准——最差准确度，在该方案中表现出最高的关联性。', 'title_zh': 'MCQ任务中答案波动的度量评估协议'}
{'arxiv_id': 'arXiv:2507.15532', 'title': 'Data-Efficient Safe Policy Improvement Using Parametric Structure', 'authors': 'Kasper Engelen, Guillermo A. Pérez, Marnix Suilen', 'link': 'https://arxiv.org/abs/2507.15532', 'abstract': 'Safe policy improvement (SPI) is an offline reinforcement learning problem in which a new policy that reliably outperforms the behavior policy with high confidence needs to be computed using only a dataset and the behavior policy. Markov decision processes (MDPs) are the standard formalism for modeling environments in SPI. In many applications, additional information in the form of parametric dependencies between distributions in the transition dynamics is available. We make SPI more data-efficient by leveraging these dependencies through three contributions: (1) a parametric SPI algorithm that exploits known correlations between distributions to more accurately estimate the transition dynamics using the same amount of data; (2) a preprocessing technique that prunes redundant actions from the environment through a game-based abstraction; and (3) a more advanced preprocessing technique, based on satisfiability modulo theory (SMT) solving, that can identify more actions to prune. Empirical results and an ablation study show that our techniques increase the data efficiency of SPI by multiple orders of magnitude while maintaining the same reliability guarantees.', 'abstract_zh': '安全策略改进（SPI）是一种基于离线强化学习的问题，在该问题中，需要使用仅有的数据集和行为策略来计算一个可靠地以高置信度优于行为策略的新策略。马尔可夫决策过程（MDPs）是SPI中建模环境的标准形式化方法。在许多应用中，转移动力学中分布之间存在参数相关性，这种额外信息可用。我们通过三项贡献利用这些相关性使SPI更加数据高效：（1）一种参数化的SPI算法，利用已知的分布间相关性更准确地使用相同数据量估计转移动力学；（2）一种预处理技术，通过基于游戏的抽象去除环境中的冗余动作；（3）一种更先进的预处理技术，基于 satisfiability modulo theory (SMT) 解决方案，可以识别出更多需要去除的动作。实证结果和消融研究显示，我们的技术可将SPI的数据效率提高多个数量级，同时保持相同的可靠性保证。', 'title_zh': '基于参数结构的数据高效安全策略改进'}
{'arxiv_id': 'arXiv:2507.15521', 'title': 'LLM world models are mental: Output layer evidence of brittle world model use in LLM mechanical reasoning', 'authors': 'Cole Robertson, Philip Wolff', 'link': 'https://arxiv.org/abs/2507.15521', 'abstract': "Do large language models (LLMs) construct and manipulate internal world models, or do they rely solely on statistical associations represented as output layer token probabilities? We adapt cognitive science methodologies from human mental models research to test LLMs on pulley system problems using TikZ-rendered stimuli. Study 1 examines whether LLMs can estimate mechanical advantage (MA). State-of-the-art models performed marginally but significantly above chance, and their estimates correlated significantly with ground-truth MA. Significant correlations between number of pulleys and model estimates suggest that models employed a pulley counting heuristic, without necessarily simulating pulley systems to derive precise values. Study 2 tested this by probing whether LLMs represent global features crucial to MA estimation. Models evaluated a functionally connected pulley system against a fake system with randomly placed components. Without explicit cues, models identified the functional system as having greater MA with F1=0.8, suggesting LLMs could represent systems well enough to differentiate jumbled from functional systems. Study 3 built on this by asking LLMs to compare functional systems with matched systems which were connected up but which transferred no force to the weight; LLMs identified the functional system with F1=0.46, suggesting random guessing. Insofar as they may generalize, these findings are compatible with the notion that LLMs manipulate internal world models, sufficient to exploit statistical associations between pulley count and MA (Study 1), and to approximately represent system components' spatial relations (Study 2). However, they may lack the facility to reason over nuanced structural connectivity (Study 3). We conclude by advocating the utility of cognitive scientific methods to evaluate the world-modeling capacities of artificial intelligence systems.", 'abstract_zh': '大型语言模型（LLMs）构建和操控内部世界模型，还是仅依赖于作为输出层令牌概率表示的统计关联？我们采用人类心理模型研究中的认知科学方法，通过使用TikZ渲染的刺激来测试LLMs的滑轮系统问题。研究1探讨LLMs是否能够估算机械优势（MA）。最先进的模型在偶然性之上仅轻微但显著地表现出色，并且其估算值与真实的MA值之间存在显著相关性。模型估算值与滑轮数量之间的显著相关性表明模型使用了滑轮计数启发式，但不一定模拟了滑轮系统以获得精确值。研究2通过探究LLMs是否代表对MA估算至关重要的全局特征来测试这一假设。模型评估了一个功能连接的滑轮系统和一个随机放置组件的虚假系统。没有明确提示，模型能够以F1=0.8的精度识别出功能系统具有更大的MA，这表明LLMs能够足够地表示系统以区分杂乱和功能性系统。研究3在此基础上进一步要求LLMs比较功能系统和匹配但不传递力到重量的系统。LLMs以F1=0.46的精度识别出功能系统，表明其几乎随机猜测。从它们可能泛化的角度看，这些发现与LLMs操控内部世界模型并能够利用滑轮数量与MA之间的统计关联（研究1）以及大致表示系统组件的空间关系（研究2）的观点相符。然而，它们可能缺乏权衡结构连接复杂性的推理能力（研究3）。最后，我们提倡采用认知科学方法来评估人工智能系统的世界建模能力。', 'title_zh': 'LLM世界模型是心理化的：脆弱的世界模型在LLM机械推理中的输出层证据'}
{'arxiv_id': 'arXiv:2507.15518', 'title': 'HAMLET: Hyperadaptive Agent-based Modeling for Live Embodied Theatrics', 'authors': 'Sizhou Chen, Shufan Jiang, Chi Zhang, Xiao-Lei Zhang, Xuelong Li', 'link': 'https://arxiv.org/abs/2507.15518', 'abstract': 'Creating an immersive and interactive theatrical experience is a long-term goal in the field of interactive narrative. The emergence of large language model (LLM) is providing a new path to achieve this goal. However, existing LLM-based drama generation methods often result in AI agents that lack initiative and cannot interact with the physical environment. Furthermore, these methods typically require detailed user input to drive the drama. These limitations reduce the interactivity and immersion of online real-time performance. To address the above challenges, we propose HAMLET, a multi-agent framework focused on drama creation and online performance. Given a simple topic, the framework generates a narrative blueprint, guiding the subsequent improvisational performance. During the online performance, each actor is given an autonomous mind. This means that actors can make independent decisions based on their own background, goals, and emotional state. In addition to conversations with other actors, their decisions can also change the state of scene props through actions such as opening a letter or picking up a weapon. The change is then broadcast to other related actors, updating what they know and care about, which in turn influences their next action. To evaluate the quality of drama performance, we designed an evaluation method to assess three primary aspects, including character performance, narrative quality, and interaction experience. The experimental evaluation shows that HAMLET can create expressive and coherent theatrical experiences. Our code, dataset and models are available at this https URL.', 'abstract_zh': '创建沉浸式和互动的剧场体验是交互叙事领域的一个长期目标。大型语言模型（LLM）的出现为实现这一目标提供了新的途径。然而，现有的基于LLM的戏剧生成方法往往导致缺乏自主性的AI角色，并不能与物理环境互动。此外，这些方法通常需要详细的用户输入来驱动戏剧发展。这些限制降低了在线实时表演的互动性和沉浸感。为了解决上述挑战，我们提出了一种名为HAMLET的多智能体框架，专注于戏剧创作和在线表演。给定一个简单的主题，该框架生成一个叙事蓝图，指导后续的即兴表演。在线表演期间，每个演员都拥有了自主心智。这意味着演员可以根据自身的背景、目标和情感状态做出独立的决定。除了与其他演员的对话外，他们的决定还可以通过开启信件或拿起武器等行动改变场景道具的状态。这种改变随后会广播给其他相关演员，更新他们所知道和关心的内容，进而影响他们的下一步行动。为了评估戏剧表演的质量，我们设计了一种评估方法，评估三个主要方面：角色表现、叙事质量和互动体验。实验评估显示，HAMLET能够创造富有表现力和连贯性的剧场体验。我们的代码、数据集和模型可在以下链接获取。', 'title_zh': 'HAMLET：基于代理的超适应模型化在实时 embodiment 戏剧中的应用'}
{'arxiv_id': 'arXiv:2507.15509', 'title': 'Chart-R1: Chain-of-Thought Supervision and Reinforcement for Advanced Chart Reasoner', 'authors': 'Lei Chen, Xuanle Zhao, Zhixiong Zeng, Jing Huang, Yufeng Zhong, Lin Ma', 'link': 'https://arxiv.org/abs/2507.15509', 'abstract': 'Recently, inspired by OpenAI-o1/o3 and Deepseek-R1, the R1-Style method based on reinforcement learning fine-tuning has received widespread attention from the community. Previous R1-Style methods mainly focus on mathematical reasoning and code intelligence. It is of great research significance to verify their advantages on more general multimodal data. Chart is an important multimodal data type with rich information, which brings important research challenges in complex reasoning. In this work, we introduce Chart-R1, a chart-domain vision-language model with reinforcement learning fine-tuning to enable complex chart reasoning. To support Chart-R1, we first propose a novel programmatic data synthesis technology to generate high-quality step-by-step chart reasoning data covering single- and multi-subcharts, which makes up for the lack of reasoning data in the chart domain. Then we develop a two-stage training strategy: Chart-COT with step-by-step chain-of-thought supervision, and Chart-RFT with numerically sensitive reinforcement fine-tuning. Chart-COT aims to decompose complex chart reasoning tasks into fine-grained, understandable subtasks through step-by-step supervision, which lays a good foundation for improving the reasoning level of reinforcement learning. Chart-RFT utilize the typical group relative policy optimization strategy, in which a relatively soft reward is adopted for numerical response to emphasize the numerical sensitivity in the chart domain. We conduct extensive experiments on open-source benchmarks and self-built chart reasoning dataset (\\emph{i.e., ChartRQA}). Experimental results show that Chart-R1 has significant advantages compared to chart-domain methods, even comparable to open/closed source large-scale models (\\emph{e.g., GPT-4o, Claude-3.5}).', 'abstract_zh': '基于强化学习微调的Chart-R1：一种图表领域的视觉-语言模型', 'title_zh': 'Chart-R1: 基于链式思维监督与强化的高级图表推理器'}
{'arxiv_id': 'arXiv:2507.15457', 'title': 'Optimization of Activity Batching Policies in Business Processes', 'authors': 'Orlenys López-Pintado, Jannis Rosenbaum, Marlon Dumas', 'link': 'https://arxiv.org/abs/2507.15457', 'abstract': "In business processes, activity batching refers to packing multiple activity instances for joint execution. Batching allows managers to trade off cost and processing effort against waiting time. Larger and less frequent batches may lower costs by reducing processing effort and amortizing fixed costs, but they create longer waiting times. In contrast, smaller and more frequent batches reduce waiting times but increase fixed costs and processing effort. A batching policy defines how activity instances are grouped into batches and when each batch is activated. This paper addresses the problem of discovering batching policies that strike optimal trade-offs between waiting time, processing effort, and cost. The paper proposes a Pareto optimization approach that starts from a given set (possibly empty) of activity batching policies and generates alternative policies for each batched activity via intervention heuristics. Each heuristic identifies an opportunity to improve an activity's batching policy with respect to a metric (waiting time, processing time, cost, or resource utilization) and an associated adjustment to the activity's batching policy (the intervention). The impact of each intervention is evaluated via simulation. The intervention heuristics are embedded in an optimization meta-heuristic that triggers interventions to iteratively update the Pareto front of the interventions identified so far. The paper considers three meta-heuristics: hill-climbing, simulated annealing, and reinforcement learning. An experimental evaluation compares the proposed approach based on intervention heuristics against the same (non-heuristic guided) meta-heuristics baseline regarding convergence, diversity, and cycle time gain of Pareto-optimal policies.", 'abstract_zh': '商务流程中活动批量处理是指将多个活动实例打包以进行联合执行。批量处理允许管理者在成本和处理努力与等待时间之间进行权衡。较大的且不频繁的批量可能通过减少处理努力并摊销固定成本来降低费用，但会导致更长的等待时间。相比之下，较小且频繁的批量会减少等待时间，但会增加固定成本和处理努力。批量策略定义了如何将活动实例分组到批量中以及何时激活每个批量。本文探讨了发现最优批量策略的问题，该策略结合了等待时间、处理努力和成本之间的权衡。本文提出了一种帕累托优化方法，该方法从给定的批量策略集（可能是空集）开始，并通过干预启发式生成每个批量活动的替代策略。每个启发式算法会识别一个机会，即根据某个度量标准（等待时间、处理时间、费用或资源利用率）改进活动的批量策略，并提出相应的批量策略调整（干预）。通过仿真评估每个干预措施的影响。这些干预启发式算法嵌入在一个优化元启发式算法中，该算法触发干预措施以迭代更新迄今为止识别的帕累托前沿。本文考虑了三种元启发式算法：上山爬行算法、模拟退火算法和强化学习。实验评估比较了基于干预启发式的提出方法与同一元启发式基准（非启发式指导）在收敛性、帕累托最优策略多样性以及周期时间增益方面的表现。', 'title_zh': '业务流程中活动批量策略的优化'}
{'arxiv_id': 'arXiv:2507.15411', 'title': 'Predictive Process Monitoring Using Object-centric Graph Embeddings', 'authors': 'Wissam Gherissi, Mehdi Acheli, Joyce El Haddad, Daniela Grigori', 'link': 'https://arxiv.org/abs/2507.15411', 'abstract': 'Object-centric predictive process monitoring explores and utilizes object-centric event logs to enhance process predictions. The main challenge lies in extracting relevant information and building effective models. In this paper, we propose an end-to-end model that predicts future process behavior, focusing on two tasks: next activity prediction and next event time. The proposed model employs a graph attention network to encode activities and their relationships, combined with an LSTM network to handle temporal dependencies. Evaluated on one reallife and three synthetic event logs, the model demonstrates competitive performance compared to state-of-the-art methods.', 'abstract_zh': '面向对象的预测过程监控通过利用对象中心的事件日志来增强过程预测。该方法的核心挑战在于提取相关信息并构建有效模型。在本文中，我们提出了一种端到端模型，用于预测未来的过程行为，重点关注下一活动预测和下一个事件时间预测。所提出模型使用图注意力网络编码活动及其关系，并结合LSTM网络处理时序依赖性。在一种真实世界和三种合成事件日志上的评估表明，该模型在性能上与现有最佳方法相当。', 'title_zh': '基于对象中心的图嵌入的预测过程监控'}
{'arxiv_id': 'arXiv:2507.15356', 'title': 'RAD: Retrieval High-quality Demonstrations to Enhance Decision-making', 'authors': 'Lu Guo, Yixiang Shan, Zhengbang Zhu, Qifan Liang, Lichang Song, Ting Long, Weinan Zhang, Yi Chang', 'link': 'https://arxiv.org/abs/2507.15356', 'abstract': 'Offline reinforcement learning (RL) enables agents to learn policies from fixed datasets, avoiding costly or unsafe environment interactions. However, its effectiveness is often limited by dataset sparsity and the lack of transition overlap between suboptimal and expert trajectories, which makes long-horizon planning particularly challenging. Prior solutions based on synthetic data augmentation or trajectory stitching often fail to generalize to novel states and rely on heuristic stitching points. To address these challenges, we propose Retrieval High-quAlity Demonstrations (RAD) for decision-making, which combines non-parametric retrieval with diffusion-based generative modeling. RAD dynamically retrieves high-return states from the offline dataset as target states based on state similarity and return estimation, and plans toward them using a condition-guided diffusion model. Such retrieval-guided generation enables flexible trajectory stitching and improves generalization when encountered with underrepresented or out-of-distribution states. Extensive experiments confirm that RAD achieves competitive or superior performance compared to baselines across diverse benchmarks, validating its effectiveness.', 'abstract_zh': '基于检索的高质量示范（RAD）决策方法：结合非参数检索与扩散生成模型', 'title_zh': 'RAD: 提取高质量示范以增强决策'}
{'arxiv_id': 'arXiv:2507.15351', 'title': 'One Step is Enough: Multi-Agent Reinforcement Learning based on One-Step Policy Optimization for Order Dispatch on Ride-Sharing Platforms', 'authors': 'Zijian Zhao, Sen Li', 'link': 'https://arxiv.org/abs/2507.15351', 'abstract': "On-demand ride-sharing platforms face the fundamental challenge of dynamically bundling passengers with diverse origins and destinations and matching them with vehicles in real time, all under significant uncertainty. Recently, MARL has emerged as a promising solution for this problem, leveraging decentralized learning to address the curse of dimensionality caused by the large number of agents in the ride-hailing market and the resulting expansive state and action spaces. However, conventional MARL-based ride-sharing approaches heavily rely on the accurate estimation of Q-values or V-values, which becomes problematic in large-scale, highly uncertain environments. Specifically, most of these approaches adopt an independent paradigm, exacerbating this issue, as each agent treats others as part of the environment, leading to unstable training and substantial estimation bias in value functions. To address these challenges, we propose two novel alternative methods that bypass value function estimation. First, we adapt GRPO to ride-sharing, replacing the PPO baseline with the group average reward to eliminate critic estimation errors and reduce training bias. Second, inspired by GRPO's full utilization of group reward information, we customize the PPO framework for ride-sharing platforms and show that, under a homogeneous fleet, the optimal policy can be trained using only one-step rewards - a method we term One-Step Policy Optimization (OSPO). Experiments on a real-world Manhattan ride-hailing dataset demonstrate that both GRPO and OSPO achieve superior performance across most scenarios, efficiently optimizing pickup times and the number of served orders using simple MLP networks.", 'abstract_zh': '基于需求的拼车平台面临动态聚合具有不同起始地和目的地的乘客并在实时环境中与车辆匹配的 fundamental 挑战，所有这些都在显著的不确定性下进行。最近，MARL 已经成为解决该问题的一种有前途的解决方案，通过去中心化学习来应对打车市场中大量代理导致的状态和动作空间扩展性难题。然而，传统的基于MARL的拼车方法严重依赖于对Q值或V值的准确估计，在大规模、高度不确定的环境中，这一问题变得尤为突出。具体来说，大多数这些方法采用了独立的范式，加剧了这一问题，因为每个代理将其他代理视为环境的一部分，导致价值函数训练不稳定和大量估计偏差。为了解决这些挑战，我们提出了两种新的替代方法，绕过价值函数估计。首先，我们将GRPO适应到拼车领域，将PPO baseline替换为小组平均奖励，以消除评论员估计错误并降低训练偏差。其次，受到GRPO充分利用小组奖励信息的启发，我们针对拼车平台定制了PPO框架，并展示了在同质车队下，仅使用一步奖励即可训练出最优策略的方法（我们称之为一步策略优化OSPO）。实验结果表明，在真实的曼哈顿打车数据集上，GRPO和OSPO在大多数场景中均表现出优越性能，使用简单的MLP网络高效地优化了接客时间和服务订单数量。', 'title_zh': '一步足矣：基于一步策略优化的多Agent reinforcement学习在共享出行平台订单调度中的应用'}
{'arxiv_id': 'arXiv:2507.15330', 'title': 'QSAF: A Novel Mitigation Framework for Cognitive Degradation in Agentic AI', 'authors': 'Hammad Atta, Muhammad Zeeshan Baig, Yasir Mehmood, Nadeem Shahzad, Ken Huang, Muhammad Aziz Ul Haq, Muhammad Awais, Kamal Ahmed', 'link': 'https://arxiv.org/abs/2507.15330', 'abstract': 'We introduce Cognitive Degradation as a novel vulnerability class in agentic AI systems. Unlike traditional adversarial external threats such as prompt injection, these failures originate internally, arising from memory starvation, planner recursion, context flooding, and output suppression. These systemic weaknesses lead to silent agent drift, logic collapse, and persistent hallucinations over time. To address this class of failures, we introduce the Qorvex Security AI Framework for Behavioral & Cognitive Resilience (QSAF Domain 10), a lifecycle-aware defense framework defined by a six-stage cognitive degradation lifecycle. The framework includes seven runtime controls (QSAF-BC-001 to BC-007) that monitor agent subsystems in real time and trigger proactive mitigation through fallback routing, starvation detection, and memory integrity enforcement. Drawing from cognitive neuroscience, we map agentic architectures to human analogs, enabling early detection of fatigue, starvation, and role collapse. By introducing a formal lifecycle and real-time mitigation controls, this work establishes Cognitive Degradation as a critical new class of AI system vulnerability and proposes the first cross-platform defense model for resilient agentic behavior.', 'abstract_zh': '我们引入认知退化作为代理人工智能系统中的一种新型脆弱性类别。这些失败源自内部，由记忆饥饿、规划器递归、上下文泛滥和输出抑制引起。这些系统性弱点导致了无声代理漂移、逻辑崩溃以及随着时间推移持续的幻觉。为应对这类失败，我们提出了Qorvex安全AI框架：行为与认知韧性领域（QSAF领域10），这是一个基于六阶段认知退化生命周期的生命周期感知防御框架。该框架包括七项运行时控制（QSAF-BC-001至BC-007），这些控制能够实时监控代理子系统，并通过备份路由、饥饿检测和内存完整性 Enforcement 实施主动缓解。借鉴认知神经科学，我们将代理架构映射到人类类比， enable 早期检测疲劳、饥饿和角色崩解。通过引入正式的生命周期和实时缓解控制，本项工作将认知退化确立为AI系统中一种关键的新脆弱性类别，并提出了首个用于抗扰代理行为的跨平台防御模型。', 'title_zh': 'QSAF: 一种新颖的认知退化缓解框架在赋权人工智能中'}
{'arxiv_id': 'arXiv:2507.15268', 'title': 'IM-Chat: A Multi-agent LLM-based Framework for Knowledge Transfer in Injection Molding Industry', 'authors': 'Junhyeong Lee, Joon-Young Kim, Heekyu Kim, Inhyo Lee, Seunghwa Ryu', 'link': 'https://arxiv.org/abs/2507.15268', 'abstract': 'The injection molding industry faces critical challenges in preserving and transferring field knowledge, particularly as experienced workers retire and multilingual barriers hinder effective communication. This study introduces IM-Chat, a multi-agent framework based on large language models (LLMs), designed to facilitate knowledge transfer in injection molding. IM-Chat integrates both limited documented knowledge (e.g., troubleshooting tables, manuals) and extensive field data modeled through a data-driven process condition generator that infers optimal manufacturing settings from environmental inputs such as temperature and humidity, enabling robust and context-aware task resolution. By adopting a retrieval-augmented generation (RAG) strategy and tool-calling agents within a modular architecture, IM-Chat ensures adaptability without the need for fine-tuning. Performance was assessed across 100 single-tool and 60 hybrid tasks for GPT-4o, GPT-4o-mini, and GPT-3.5-turbo by domain experts using a 10-point rubric focused on relevance and correctness, and was further supplemented by automated evaluation using GPT-4o guided by a domain-adapted instruction prompt. The evaluation results indicate that more capable models tend to achieve higher accuracy, particularly in complex, tool-integrated scenarios. Overall, these findings demonstrate the viability of multi-agent LLM systems for industrial knowledge workflows and establish IM-Chat as a scalable and generalizable approach to AI-assisted decision support in manufacturing.', 'abstract_zh': '注射 molding 行业在保存和传递现场知识方面面临着关键挑战，特别是在经验丰富的工人退休以及多语言障碍阻碍有效沟通的情况下。本研究引入了基于大语言模型（LLMs）的多 Agent 框架 IM-Chat，旨在促进注射 molding 中的知识转移。IM-Chat 结合了有限的文档知识（例如，故障排除表格、手册）和通过数据驱动的过程条件生成器进行建模的广泛现场数据，该生成器能够从诸如温度和湿度等环境输入中推断出最优的制造设置，从而实现稳健且上下文相关的任务解决。通过采用检索增强生成（RAG）策略和工具调用智能体，并在模块化架构中进行设计，IM-Chat 确保了其适应性无需微调。研究通过领域专家使用基于 10 点标准的评判标准（关注相关性和准确性）对 GPT-4o、GPT-4o-mini 和 GPT-3.5-turbo 的 100 个单工位任务和 60 个混合任务进行评估，并通过使用领域自适应指令提示引导的 GPT-4o 进行自动评估进行了补充。评估结果表明，更强大的模型在复杂、工具集成的情景中往往能获得更高的准确性。总体而言，这些发现证明了基于多 Agent 的大语言模型系统在工业知识工作流中的可行性，并将 IM-Chat 确立为在制造业中辅助决策支持方面可扩展且普适的方法。', 'title_zh': 'IM-Chat: 一种基于多agent大规模语言模型的知识转移框架在注塑行业中'}
{'arxiv_id': 'arXiv:2507.15253', 'title': 'Disentangling Homophily and Heterophily in Multimodal Graph Clustering', 'authors': 'Zhaochen Guo, Zhixiang Shen, Xuanting Xie, Liangjian Wen, Zhao Kang', 'link': 'https://arxiv.org/abs/2507.15253', 'abstract': 'Multimodal graphs, which integrate unstructured heterogeneous data with structured interconnections, offer substantial real-world utility but remain insufficiently explored in unsupervised learning. In this work, we initiate the study of multimodal graph clustering, aiming to bridge this critical gap. Through empirical analysis, we observe that real-world multimodal graphs often exhibit hybrid neighborhood patterns, combining both homophilic and heterophilic relationships. To address this challenge, we propose a novel framework -- \\textsc{Disentangled Multimodal Graph Clustering (DMGC)} -- which decomposes the original hybrid graph into two complementary views: (1) a homophily-enhanced graph that captures cross-modal class consistency, and (2) heterophily-aware graphs that preserve modality-specific inter-class distinctions. We introduce a \\emph{Multimodal Dual-frequency Fusion} mechanism that jointly filters these disentangled graphs through a dual-pass strategy, enabling effective multimodal integration while mitigating category confusion. Our self-supervised alignment objectives further guide the learning process without requiring labels. Extensive experiments on both multimodal and multi-relational graph datasets demonstrate that DMGC achieves state-of-the-art performance, highlighting its effectiveness and generalizability across diverse settings. Our code is available at this https URL.', 'abstract_zh': '多模态图聚类：解耦融合框架（Disentangled Multimodal Graph Clustering）', 'title_zh': '多模态图聚类中同质性和异质性的解缠nings'}
{'arxiv_id': 'arXiv:2507.15239', 'title': 'Explainable Artificial Intelligence based Soft Evaluation Indicator for Arc Fault Diagnosis', 'authors': 'Qianchao Wang, Yuxuan Ding, Chuanzhen Jia, Zhe Li, Yaping Du', 'link': 'https://arxiv.org/abs/2507.15239', 'abstract': 'Novel AI-based arc fault diagnosis models have demonstrated outstanding performance in terms of classification accuracy. However, an inherent problem is whether these models can actually be trusted to find arc faults. In this light, this work proposes a soft evaluation indicator that explains the outputs of arc fault diagnosis models, by defining the the correct explanation of arc faults and leveraging Explainable Artificial Intelligence and real arc fault experiments. Meanwhile, a lightweight balanced neural network is proposed to guarantee competitive accuracy and soft feature extraction score. In our experiments, several traditional machine learning methods and deep learning methods across two arc fault datasets with different sample times and noise levels are utilized to test the effectiveness of the soft evaluation indicator. Through this approach, the arc fault diagnosis models are easy to understand and trust, allowing practitioners to make informed and trustworthy decisions.', 'abstract_zh': '基于AI的新型弧故障诊断模型在分类准确性方面表现卓越，然而一个固有的问题是这些模型是否能够真正可靠地检测弧故障。为此，本文提出了一种软评估指标来解释弧故障诊断模型的输出，通过定义正确的弧故障解释并利用可解释人工智能和实际弧故障实验。同时，提出了一种轻量级平衡神经网络以确保其准确性和软特征提取得分具有竞争力。在实验中，利用两个不同采样时间和噪声水平的弧故障数据集中的多种传统机器学习方法和深度学习方法测试软评估指标的有效性。通过这种方法，弧故障诊断模型易于理解和信任，使实践者能够做出知情且可靠的选择。', 'title_zh': '基于可解释人工智能的软评价指标用于弧故障诊断'}
{'arxiv_id': 'arXiv:2507.15225', 'title': 'Solving Formal Math Problems by Decomposition and Iterative Reflection', 'authors': 'Yichi Zhou, Jianqiu Zhao, Yongxin Zhang, Bohan Wang, Siran Wang, Luoxin Chen, Jiahui Wang, Haowei Chen, Allan Jie, Xinbo Zhang, Haocheng Wang, Luong Trung, Rong Ye, Phan Nhat Hoang, Huishuai Zhang, Peng Sun, Hang Li', 'link': 'https://arxiv.org/abs/2507.15225', 'abstract': 'General-purpose Large Language Models (LLMs) have achieved remarkable success in intelligence, performing comparably to human experts on complex reasoning tasks such as coding and mathematical reasoning. However, generating formal proofs in specialized languages like Lean 4 remains a significant challenge for these models, limiting their application in complex theorem proving and automated verification. Current approaches typically require specializing models through fine-tuning on dedicated formal corpora, incurring high costs for data collection and training. In this work, we introduce \\textbf{Delta Prover}, an agent-based framework that orchestrates the interaction between a general-purpose LLM and the Lean 4 proof environment. Delta Prover leverages the reflection and reasoning capabilities of general-purpose LLMs to interactively construct formal proofs in Lean 4, circumventing the need for model specialization. At its core, the agent integrates two novel, interdependent components: an algorithmic framework for reflective decomposition and iterative proof repair, and a custom Domain-Specific Language (DSL) built upon Lean 4 for streamlined subproblem management. \\textbf{Delta Prover achieves a state-of-the-art 95.9\\% success rate on the miniF2F-test benchmark, surpassing all existing approaches, including those requiring model specialization.} Furthermore, Delta Prover exhibits a significantly stronger test-time scaling law compared to standard Best-of-N proof strategies. Crucially, our findings demonstrate that general-purpose LLMs, when guided by an effective agentic structure, possess substantial untapped theorem-proving capabilities. This presents a computationally efficient alternative to specialized models for robust automated reasoning in formal environments.', 'abstract_zh': '通用大型语言模型（LLMs）在智能方面取得了显著成功，能够在复杂的推理任务如编程和数学推理方面与人类专家匹敌。然而，生成像Lean 4这样的专门语言形式证明仍是这些模型的一项重大挑战，限制了它们在复杂定理证明和自动验证方面的应用。当前的方法通常需要通过在专门的形式语料库上进行微调来专业化模型，这会增加数据收集和训练的成本。在本工作中，我们介绍了基于代理的框架Delta Prover，它协调了一般大型语言模型与Lean 4证明环境之间的交互。Delta Prover利用了一般大型语言模型的反射和推理能力，以交互方式构建Lean 4中的形式证明，从而避免了模型专业化的需求。核心上，代理整合了两个新颖且相互依赖的组件：一种反射分解和迭代证明修复的算法框架，以及基于Lean 4构建的定制领域特定语言（DSL），用于简化子问题的管理。Delta Prover在miniF2F-test基准测试中实现了95.9%的成功率，超过了所有现有方法，包括需要模型专业化的方法。此外，Delta Prover在测试时间上的扩展律明显优于标准的Best-of-N证明策略。最关键的是，我们的研究结果表明，当由有效的代理结构引导时，通用大型语言模型在定理证明方面具有巨大的未开发的能力。这为在形式环境中的稳健自动化推理提供了一种计算上高效的替代方案。', 'title_zh': '形式化数学问题通过分解和迭代反思求解'}
{'arxiv_id': 'arXiv:2507.15143', 'title': "Can We Move Freely in NEOM's The Line? An Agent-Based Simulation of Human Mobility in a Futuristic Smart City", 'authors': 'Abderaouf Bahi, Amel Ourici', 'link': 'https://arxiv.org/abs/2507.15143', 'abstract': 'This paper investigates the feasibility of human mobility in The Line, a proposed 170-kilometer linear smart city in NEOM, Saudi Arabia. To assess whether citizens can move freely within this unprecedented urban topology, we develop a hybrid simulation framework that integrates agent-based modeling, reinforcement learning, supervised learning, and graph neural networks. The simulation captures multi-modal transportation behaviors across 50 vertical levels and varying density scenarios using both synthetic data and real-world traces from high-density cities. Our experiments reveal that with the full AI-integrated architecture, agents achieved an average commute time of 7.8 to 8.4 minutes, a satisfaction rate exceeding 89 percent, and a reachability index of over 91 percent, even during peak congestion periods. Ablation studies confirmed that the removal of intelligent modules such as reinforcement learning or graph neural networks significantly degrades performance, with commute times increasing by up to 85 percent and reachability falling below 70 percent. Environmental modeling further demonstrated low energy consumption and minimal CO2 emissions when electric modes are prioritized. The findings suggest that freedom of movement is not only conceptually achievable in The Line, but also operationally realistic if supported by adaptive AI systems, sustainable infrastructure, and real-time feedback loops.', 'abstract_zh': '本研究探讨了在沙特阿拉伯NEOM地区拟建的170公里线性智慧城市The Line中人类移动性的可行性。为评估市民能否在这一前所未有的城市拓扑结构中自由移动，我们开发了一种结合基于代理的建模、强化学习、监督学习和图神经网络的混合仿真框架。仿真捕捉了50个垂直层次和不同密度场景下的多模态交通行为，利用合成数据和高密度城市的实际轨迹。实验结果显示，在全面集成AI的架构下，代理平均通勤时间为7.8至8.4分钟，满意度超过89%，可达性指数超过91%，甚至在高峰拥堵时段也是如此。消融研究证实，删除如强化学习或图神经网络等智能模块会显著降低性能，通勤时间最多增加85%，可达性低于70%。环境建模进一步表明，优先使用电动模式时，系统能耗低且二氧化碳排放量少。研究发现，自由移动不仅是The Line的概念性可行，而且在支持适应性AI系统、可持续基础设施和实时反馈回路的情况下，操作上也是现实可行的。', 'title_zh': '未来智能城市NEOM的The Line中的人流动态：基于代理的仿真研究'}
{'arxiv_id': 'arXiv:2507.15140', 'title': 'Clinical Semantic Intelligence (CSI): Emulating the Cognitive Framework of the Expert Clinician for Comprehensive Oral Disease Diagnosis', 'authors': 'Mohammad Mashayekhi, Sara Ahmadi Majd, Arian AmirAmjadi, Parsa Hosseini', 'link': 'https://arxiv.org/abs/2507.15140', 'abstract': "The diagnosis of oral diseases presents a problematic clinical challenge, characterized by a wide spectrum of pathologies with overlapping symptomatology. To address this, we developed Clinical Semantic Intelligence (CSI), a novel artificial intelligence framework that diagnoses 118 different oral diseases by computationally modeling the cognitive processes of an expert clinician. Our core hypothesis is that moving beyond simple pattern matching to emulate expert reasoning is critical to building clinically useful diagnostic aids.\nCSI's architecture integrates a fine-tuned multimodal CLIP model with a specialized ChatGLM-6B language model. This system executes a Hierarchical Diagnostic Reasoning Tree (HDRT), a structured framework that distills the systematic, multi-step logic of differential diagnosis. The framework operates in two modes: a Fast Mode for rapid screening and a Standard Mode that leverages the full HDRT for an interactive and in-depth diagnostic workup.\nTo train and validate our system, we curated a primary dataset of 4,310 images, supplemented by an external hold-out set of 176 images for final validation. A clinically-informed augmentation strategy expanded our training data to over 30,000 image-text pairs. On a 431-image internal test set, CSI's Fast Mode achieved an accuracy of 73.4%, which increased to 89.5% with the HDRT-driven Standard Mode. The performance gain is directly attributable to the hierarchical reasoning process. Herein, we detail the architectural philosophy, development, and rigorous evaluation of the CSI framework.", 'abstract_zh': '临床语义智能在口腔疾病的诊断中：一种新型的人工智能框架及其应用', 'title_zh': '临床语义智能（CSI）：模仿专家临床医生的认知框架以实现全面口腔疾病诊断'}
{'arxiv_id': 'arXiv:2507.15120', 'title': 'Automated planning with ontologies under coherence update semantics', 'authors': 'Stefan Borgwardt, Duy Nhu, Gabriele Röger', 'link': 'https://arxiv.org/abs/2507.15120', 'abstract': 'Standard automated planning employs first-order formulas under closed-world semantics to achieve a goal with a given set of actions from an initial state. We follow a line of research that aims to incorporate background knowledge into automated planning problems, for example, by means of ontologies, which are usually interpreted under open-world semantics. We present a new approach for planning with DL-Lite ontologies that combines the advantages of ontology-based action conditions provided by explicit-input knowledge and action bases (eKABs) and ontology-aware action effects under the coherence update semantics. We show that the complexity of the resulting formalism is not higher than that of previous approaches and provide an implementation via a polynomial compilation into classical planning. An evaluation of existing and new benchmarks examines the performance of a planning system on different variants of our compilation.', 'abstract_zh': '基于DL-Lite本体的规划新方法：结合显式输入知识和本体意识动作效果的综合优势', 'title_zh': '本体驱动的一致性更新语义下的自动规划'}
{'arxiv_id': 'arXiv:2507.15106', 'title': 'From Kicking to Causality: Simulating Infant Agency Detection with a Robust Intrinsic Reward', 'authors': 'Xia Xu, Jochen Triesch', 'link': 'https://arxiv.org/abs/2507.15106', 'abstract': 'While human infants robustly discover their own causal efficacy, standard reinforcement learning agents remain brittle, as their reliance on correlation-based rewards fails in noisy, ecologically valid scenarios. To address this, we introduce the Causal Action Influence Score (CAIS), a novel intrinsic reward rooted in causal inference. CAIS quantifies an action\'s influence by measuring the 1-Wasserstein distance between the learned distribution of sensory outcomes conditional on that action, $p(h|a)$, and the baseline outcome distribution, $p(h)$. This divergence provides a robust reward that isolates the agent\'s causal impact from confounding environmental noise. We test our approach in a simulated infant-mobile environment where correlation-based perceptual rewards fail completely when the mobile is subjected to external forces. In stark contrast, CAIS enables the agent to filter this noise, identify its influence, and learn the correct policy. Furthermore, the high-quality predictive model learned for CAIS allows our agent, when augmented with a surprise signal, to successfully reproduce the "extinction burst" phenomenon. We conclude that explicitly inferring causality is a crucial mechanism for developing a robust sense of agency, offering a psychologically plausible framework for more adaptive autonomous systems.', 'abstract_zh': '基于因果推理的行动影响分数在增强学习中的应用：从婴儿移动环境学习因果影响', 'title_zh': '从踢腿到因果关系：模拟婴儿agency检测的 robust 内在奖励方法'}
{'arxiv_id': 'arXiv:2507.15042', 'title': 'DeRAG: Black-box Adversarial Attacks on Multiple Retrieval-Augmented Generation Applications via Prompt Injection', 'authors': 'Jerry Wang, Fang Yu', 'link': 'https://arxiv.org/abs/2507.15042', 'abstract': "Adversarial prompt attacks can significantly alter the reliability of Retrieval-Augmented Generation (RAG) systems by re-ranking them to produce incorrect outputs. In this paper, we present a novel method that applies Differential Evolution (DE) to optimize adversarial prompt suffixes for RAG-based question answering. Our approach is gradient-free, treating the RAG pipeline as a black box and evolving a population of candidate suffixes to maximize the retrieval rank of a targeted incorrect document to be closer to real world scenarios. We conducted experiments on the BEIR QA datasets to evaluate attack success at certain retrieval rank thresholds under multiple retrieving applications. Our results demonstrate that DE-based prompt optimization attains competitive (and in some cases higher) success rates compared to GGPP to dense retrievers and PRADA to sparse retrievers, while using only a small number of tokens (<=5 tokens) in the adversarial suffix. Furthermore, we introduce a readability-aware suffix construction strategy, validated by a statistically significant reduction in MLM negative log-likelihood with Welch's t-test. Through evaluations with a BERT-based adversarial suffix detector, we show that DE-generated suffixes evade detection, yielding near-chance detection accuracy.", 'abstract_zh': "对抗提示攻击可以通过重新排序生成错误输出显著改变检索增强生成（RAG）系统的可靠性。本文提出了一种新颖的方法，利用差分进化（DE）优化基于RAG的问题回答系统的对抗提示后缀。该方法无需梯度，将RAG管道视为黑盒，并进化候选后缀群体以最大化目标错误文档的检索排名，使其更接近真实场景。我们在BEIR QA数据集上进行了实验，评估了在不同检索排名阈值下的攻击成功率，应用场景多样。实验结果表明，基于DE的提示优化在使用少量token（<=5个token）的对抗后缀时，可以获得竞争力（在某些情况下更高）的成功率，同时与密集检索中的GGPP和稀疏检索中的PRADA相比。此外，我们引入了一种考虑可读性的后缀构建策略，并通过Welch's t检验验证了其显著降低了MLM负对数似然。通过基于BERT的对抗后缀检测器评估，我们展示了DE生成的后缀能够规避检测，检测准确率接近随机水平。", 'title_zh': 'DeRAG：通过提示注入对多种检索增强生成应用的黑盒 adversarial 攻击'}
{'arxiv_id': 'arXiv:2507.15013', 'title': 'A Forced-Choice Neural Cognitive Diagnostic Model of Personality Testing', 'authors': 'Xiaoyu Li, Jin Wu, Shaoyang Guo, Haoran Shi, Chanjin Zheng', 'link': 'https://arxiv.org/abs/2507.15013', 'abstract': "In the smart era, psychometric tests are becoming increasingly important for personnel selection, career development, and mental health assessment. Forced-choice tests are common in personality assessments because they require participants to select from closely related options, lowering the risk of response distortion. This study presents a deep learning-based Forced-Choice Neural Cognitive Diagnostic Model (FCNCD) that overcomes the limitations of traditional models and is applicable to the three most common item block types found in forced-choice tests. To account for the unidimensionality of items in forced-choice tests, we create interpretable participant and item parameters. We model the interactions between participant and item features using multilayer neural networks after mining them using nonlinear mapping. In addition, we use the monotonicity assumption to improve the interpretability of the diagnostic results. The FCNCD's effectiveness is validated by experiments on real-world and simulated datasets that show its accuracy, interpretability, and robustness.", 'abstract_zh': '在智能时代，心理测量测试在人员选拔、职业发展和心理健康评估中越来越重要。强制选择测试在人格评估中常见，因为它们要求参与者在紧密相关的选项中进行选择，从而降低反应扭曲的风险。本研究提出了一种基于深度学习的强制选择神经认知诊断模型（FCNCD），克服了传统模型的局限性，并适用于强制选择测试中发现的最常见三种题目块类型。为了应对强制选择测试中题目的一维性，我们构建了可解释的参与者和题目参数。在使用非线性映射挖掘参与者和题目特征之后，我们使用多层神经网络模型它们之间的相互作用。此外，我们使用单调性假设以提高诊断结果的可解释性。FCNCD的有效性通过在实际数据集和模拟数据集上的实验得到验证，展示了其准确度、可解释性和鲁棒性。', 'title_zh': '强迫选择神经认知诊断模型的人格测验'}
{'arxiv_id': 'arXiv:2507.14987', 'title': 'AlphaAlign: Incentivizing Safety Alignment with Extremely Simplified Reinforcement Learning', 'authors': 'Yi Zhang, An Zhang, XiuYu Zhang, Leheng Sheng, Yuxin Chen, Zhenkai Liang, Xiang Wang', 'link': 'https://arxiv.org/abs/2507.14987', 'abstract': "Large language models (LLMs), despite possessing latent safety understanding from their vast pretraining data, remain vulnerable to generating harmful content and exhibit issues such as over-refusal and utility degradation after safety alignment. Current safety alignment methods often result in superficial refusal shortcuts or rely on intensive supervision for reasoning-based approaches, failing to fully leverage the model's intrinsic safety self-awareness. We propose \\textbf{AlphaAlign}, a simple yet effective pure reinforcement learning (RL) framework with verifiable safety reward designed to incentivize this latent safety awareness through proactive safety reasoning.} AlphaAlign employs a dual-reward system: a verifiable safety reward encourages correctly formatted and explicitly justified refusals for harmful queries while penalizing over-refusals, and a normalized helpfulness reward guides high-quality responses to benign inputs. This allows the model to develop proactive safety reasoning capabilities without depending on supervised safety-specific reasoning data. AlphaAlign demonstrates three key advantages: (1) Simplicity and efficiency, requiring only binary prompt safety labels and minimal RL steps for substantial improvements. (2) Breaking the safety-utility trade-off, by enhancing refusal of harmful content and reducing over-refusals, while simultaneously maintaining or even improving general task performance and robustness to unseen jailbreaks. (3) Deep alignment, fostering proactive safety reasoning that generates explicit safety rationales rather than relying on shallow refusal patterns.", 'abstract_zh': '大型语言模型（LLMs）尽管在其大量的预训练数据中蕴含了潜在的安全理解能力，但仍容易生成有害内容，并在安全对齐后表现出过度拒绝和功能退化的现象。现有的安全对齐方法往往会导致表面化的拒绝捷径，或者依赖于基于推理的方法和密集的监督，无法充分利用模型固有的内在安全自意识。我们提出了一种名为AlphaAlign的简单而有效的纯强化学习（RL）框架，通过设计可验证的安全奖励来激励模型的潜在安全意识，促进其积极的安全推理。AlphaAlign采用双重奖励系统：可验证的安全奖励鼓励正确格式化并明确解释的拒绝有害查询的行为，并对过度拒绝进行惩罚；归一化的有益性奖励指导对良性输入生成高质量的响应。这使得模型能够在不依赖于监督式安全推理数据的情况下发展出积极的安全推理能力。AlphaAlign展示了三大优势：（1）简洁高效，只需要二元提示安全性标签和少量的RL步骤即可实现显著改进；（2）打破安全与功能性之间的权衡，通过增强对有害内容的拒绝并减少过度拒绝，同时保持或甚至提高一般任务表现和对未见过的漏洞的鲁棒性；（3）深层次对齐，促进生成明确的安全理由，而不是依赖于浅层的拒绝模式。', 'title_zh': 'AlphaAlign：通过极其简化的强化学习激励安全性对齐'}
{'arxiv_id': 'arXiv:2507.14962', 'title': 'Complexity of Faceted Explanations in Propositional Abduction', 'authors': 'Johannes Schmidt, Mohamed Maizia, Victor Lagerkvist, Johannes K. Fichte', 'link': 'https://arxiv.org/abs/2507.14962', 'abstract': "Abductive reasoning is a popular non-monotonic paradigm that aims to explain observed symptoms and manifestations. It has many applications, such as diagnosis and planning in artificial intelligence and database updates. In propositional abduction, we focus on specifying knowledge by a propositional formula. The computational complexity of tasks in propositional abduction has been systematically characterized - even with detailed classifications for Boolean fragments. Unsurprisingly, the most insightful reasoning problems (counting and enumeration) are computationally highly challenging. Therefore, we consider reasoning between decisions and counting, allowing us to understand explanations better while maintaining favorable complexity. We introduce facets to propositional abductions, which are literals that occur in some explanation (relevant) but not all explanations (dispensable). Reasoning with facets provides a more fine-grained understanding of variability in explanations (heterogeneous). In addition, we consider the distance between two explanations, enabling a better understanding of heterogeneity/homogeneity. We comprehensively analyze facets of propositional abduction in various settings, including an almost complete characterization in Post's framework.", 'abstract_zh': '析取推理是一种流行的非单调 paradigm，旨在解释观察到的症状和表现。它在人工智能中的诊断与规划以及数据库更新等领域有许多应用。在命题析取中，我们关注通过命题公式指定知识。命题析取中任务的计算复杂性已系统地得以刻画——即使对于布尔片段也进行了详细的分类。不出所料，最具洞察力的推理问题（计数和枚举）计算上极具挑战性。因此，我们考虑决策与计数之间的推理，以更好地理解解释同时保持有利的复杂性。我们引入了命题析取中的切面，这些切面在某些解释（相关）中出现，但在所有解释中并不总是出现（可舍弃）。使用切面进行推理提供了对解释中变异性（异质性）更精细的理解。此外，我们考虑了两个解释之间的距离，以更好地理解异质性/同质性。我们在各种场景下全面分析了命题析取的切面，包括在Post框架中的几乎完全刻画。', 'title_zh': '命题 abduction 中分面解释的复杂性'}
{'arxiv_id': 'arXiv:2507.14912', 'title': 'Redefining Elderly Care with Agentic AI: Challenges and Opportunities', 'authors': 'Ruhul Amin Khalil, Kashif Ahmad, Hazrat Ali', 'link': 'https://arxiv.org/abs/2507.14912', 'abstract': 'The global ageing population necessitates new and emerging strategies for caring for older adults. In this article, we explore the potential for transformation in elderly care through Agentic Artificial Intelligence (AI), powered by Large Language Models (LLMs). We discuss the proactive and autonomous decision-making facilitated by Agentic AI in elderly care. Personalized tracking of health, cognitive care, and environmental management, all aimed at enhancing independence and high-level living for older adults, represents important areas of application. With a potential for significant transformation of elderly care, Agentic AI also raises profound concerns about data privacy and security, decision independence, and access. We share key insights to emphasize the need for ethical safeguards, privacy protections, and transparent decision-making. Our goal in this article is to provide a balanced discussion of both the potential and the challenges associated with Agentic AI, and to provide insights into its responsible use in elderly care, to bring Agentic AI into harmony with the requirements and vulnerabilities specific to the elderly. Finally, we identify the priorities for the academic research communities, to achieve human-centered advancements and integration of Agentic AI in elderly care. To the best of our knowledge, this is no existing study that reviews the role of Agentic AI in elderly care. Hence, we address the literature gap by analyzing the unique capabilities, applications, and limitations of LLM-based Agentic AI in elderly care. We also provide a companion interactive dashboard at this https URL.', 'abstract_zh': '全球老龄化的背景下，需要新的护理策略来照顾老年人。本文探讨了通过代理人工智能（Agentic AI）实现老年护理转型的可能性，代理人工智能由大型语言模型（LLMs）驱动。我们讨论了代理人工智能在老年护理中促进主动和自主决策的潜力。个性化健康跟踪、认知护理和环境管理的应用旨在提高老年人的独立性和生活质量，具有重要意义。虽然代理人工智能有潜力对老年护理进行重大转型，但也引发了关于数据隐私与安全、决策自主性以及可及性等方面的深刻关切。我们分享了关键见解，强调了对伦理保障、隐私保护和透明决策的必要性。本文旨在提供代理人工智能在老年护理中潜在优势和挑战的平衡讨论，并提供在其使用中的负责任原则，以使代理人工智能与老年人特有的需求和脆弱性相协调。鉴于目前没有关于代理人工智能在老年护理中作用的现有研究，我们通过分析基于大型语言模型的代理人工智能的独特能力、应用和局限性来填补文献空白。我们还提供了与此相关内容的交互式仪表板（可访问此网址）。', 'title_zh': '用赋权人工智能重塑老年人护理：挑战与机遇'}
{'arxiv_id': 'arXiv:2507.14909', 'title': 'The Endless Tuning. An Artificial Intelligence Design To Avoid Human Replacement and Trace Back Responsibilities', 'authors': 'Elio Grande', 'link': 'https://arxiv.org/abs/2507.14909', 'abstract': 'The Endless Tuning is a design method for a reliable deployment of artificial intelligence based on a double mirroring process, which pursues both the goals of avoiding human replacement and filling the so-called responsibility gap (Matthias 2004). Originally depicted in (Fabris et al. 2024) and ensuing the relational approach urged therein, it was then actualized in a protocol, implemented in three prototypical applications regarding decision-making processes (respectively: loan granting, pneumonia diagnosis, and art style recognition) and tested with such as many domain experts. Step by step illustrating the protocol, giving insights concretely showing a different voice (Gilligan 1993) in the ethics of artificial intelligence, a philosophical account of technical choices (e.g., a reversed and hermeneutic deployment of XAI algorithms) will be provided in the present study together with the results of the experiments, focusing on user experience rather than statistical accuracy. Even thoroughly employing deep learning models, full control was perceived by the interviewees in the decision-making setting, while it appeared that a bridge can be built between accountability and liability in case of damage.', 'abstract_zh': '无穷调优是一种基于双重镜像过程的设计方法，旨在可靠部署人工智能，并追求避免人类替代和填补所谓的责任缺口（Matthias 2004）的目标。该方法最初在（Fabris等，2024）中提出，并遵循该文中提倡的关系方法，随后在三个原型应用中实现（分别为贷款发放、肺炎诊断和艺术风格识别），并与众多领域专家进行了测试。本文逐步阐述该协议，并通过具体的见解展现不同的伦理声音（Gilligan 1993），提供一种哲学解释技术选择（例如，解释性人工智能算法的反向和诠释性部署），同时关注用户体验而非统计准确性。即使充分使用深度学习模型，在决策场景中受访者仍能感到完全的控制，而在出现损害时，责任与赔偿之间似乎可以建立桥梁。', 'title_zh': '无尽调优：一种避免人类替代并追溯责任的 artificial intelligence 设计'}
{'arxiv_id': 'arXiv:2507.14906', 'title': 'Feedback-Induced Performance Decline in LLM-Based Decision-Making', 'authors': 'Xiao Yang, Juxi Leitner, Michael Burke', 'link': 'https://arxiv.org/abs/2507.14906', 'abstract': 'The ability of Large Language Models (LLMs) to extract context from natural language problem descriptions naturally raises questions about their suitability in autonomous decision-making settings. This paper studies the behaviour of these models within a Markov Decision Process (MDPs). While traditional reinforcement learning (RL) strategies commonly employed in this setting rely on iterative exploration, LLMs, pre-trained on diverse datasets, offer the capability to leverage prior knowledge for faster adaptation. We investigate online structured prompting strategies in sequential decision making tasks, comparing the zero-shot performance of LLM-based approaches to that of classical RL methods. Our findings reveal that although LLMs demonstrate improved initial performance in simpler environments, they struggle with planning and reasoning in complex scenarios without fine-tuning or additional guidance. Our results show that feedback mechanisms, intended to improve decision-making, often introduce confusion, leading to diminished performance in intricate environments. These insights underscore the need for further exploration into hybrid strategies, fine-tuning, and advanced memory integration to enhance LLM-based decision-making capabilities.', 'abstract_zh': '大型语言模型在马尔可夫决策过程中的行为研究：从零开始的性能对比及启示', 'title_zh': '基于LLM的决策中由反馈引起的表现下降'}
{'arxiv_id': 'arXiv:2507.14899', 'title': 'InsightX Agent: An LMM-based Agentic Framework with Integrated Tools for Reliable X-ray NDT Analysis', 'authors': 'Jiale Liu, Huan Wang, Yue Zhang, Xiaoyu Luo, Jiaxiang Hu, Zhiliang Liu, Min Xie', 'link': 'https://arxiv.org/abs/2507.14899', 'abstract': "Non-destructive testing (NDT), particularly X-ray inspection, is vital for industrial quality assurance, yet existing deep-learning-based approaches often lack interactivity, interpretability, and the capacity for critical self-assessment, limiting their reliability and operator trust. To address these shortcomings, this paper proposes InsightX Agent, a novel LMM-based agentic framework designed to deliver reliable, interpretable, and interactive X-ray NDT analysis. Unlike typical sequential pipelines, InsightX Agent positions a Large Multimodal Model (LMM) as a central orchestrator, coordinating between the Sparse Deformable Multi-Scale Detector (SDMSD) and the Evidence-Grounded Reflection (EGR) tool. The SDMSD generates dense defect region proposals for multi-scale feature maps and sparsifies them through Non-Maximum Suppression (NMS), optimizing detection of small, dense targets in X-ray images while maintaining computational efficiency. The EGR tool guides the LMM agent through a chain-of-thought-inspired review process, incorporating context assessment, individual defect analysis, false positive elimination, confidence recalibration and quality assurance to validate and refine the SDMSD's initial proposals. By strategically employing and intelligently using tools, InsightX Agent moves beyond passive data processing to active reasoning, enhancing diagnostic reliability and providing interpretations that integrate diverse information sources. Experimental evaluations on the GDXray+ dataset demonstrate that InsightX Agent not only achieves a high object detection F1-score of 96.35% but also offers significantly improved interpretability and trustworthiness in its analyses, highlighting the transformative potential of agentic LLM frameworks for industrial inspection tasks.", 'abstract_zh': '非破坏性检测（NDT），特别是X射线检查，对于工业质量保证至关重要，但现有的基于深度学习的方法往往缺乏互动性、可解释性和批判性自我评估的能力，限制了其可靠性和操作员的信任度。为克服这些不足，本文提出了一种新型的大规模多模态模型（LMM）基础代理框架——InsightX Agent，旨在提供可靠、可解释和互动的X射线NDT分析。与其他典型的顺序处理管道不同，InsightX Agent将大型多模态模型（LMM）定位为中心协调器，协调稀疏可变形多尺度检测器（SDMSD）和证据导向反思（EGR）工具之间的交互。SDMSD生成多重尺度特征图的密集缺陷区域提议，并通过非极大值抑制（NMS）进行稀疏化，优化X射线图像中小而密集目标的检测能力，同时保持计算效率。EGR工具通过基于推理过程审查机制引导LMM代理，结合上下文评估、单个缺陷分析、误检消除、置信度重新校准和质量保证，以验证和细化SDMSD的初始提议。通过战略性地应用和智能使用工具，InsightX Agent超越了被动的数据处理，实现了积极的推理，增强了诊断可靠性，并提供了整合多种信息源的解释。在GDXray+数据集上的实验评估表明，InsightX Agent不仅实现了高物体检测F1分数（96.35%），还在其分析中提供了显著提高的可解释性和可信度，突显了代理式LLM框架在工业检查任务中的变革潜力。', 'title_zh': 'InsightX 代理：一种基于LMM的集成工具框架，用于可靠的X射线无损检测分析'}
{'arxiv_id': 'arXiv:2507.14897', 'title': 'AgentFly: Extensible and Scalable Reinforcement Learning for LM Agents', 'authors': 'Renxi Wang, Rifo Ahmad Genadi, Bilal El Bouardi, Yongxin Wang, Fajri Koto, Zhengzhong Liu, Timothy Baldwin, Haonan Li', 'link': 'https://arxiv.org/abs/2507.14897', 'abstract': "Language model (LM) agents have gained significant attention for their ability to autonomously complete tasks through interactions with environments, tools, and APIs. LM agents are primarily built with prompt engineering or supervised finetuning. At the same time, reinforcement learning (RL) has been explored to enhance LM's capabilities, such as reasoning and factuality. However, the combination of the LM agents and reinforcement learning (Agent-RL) remains underexplored and lacks systematic study. To this end, we built AgentFly, a scalable and extensible Agent-RL framework designed to empower LM agents with a variety of RL algorithms. Our framework supports multi-turn interactions by adapting traditional RL methods with token-level masking. It features a decorator-based interface for defining tools and reward functions, enabling seamless extension and ease of use. To support high-throughput training, we implement asynchronous execution of tool calls and reward computations, and design a centralized resource management system for scalable environment coordination. We also provide a suite of prebuilt tools and environments, demonstrating the framework's effectiveness through successful agent training across multiple tasks.", 'abstract_zh': '语言模型（LM）代理通过与环境、工具和API交互自主完成任务的能力引起了广泛关注。LM代理主要通过提示工程或监督微调构建。同时，强化学习（RL）已被探索以增强LM的能力，如推理和事实性。然而，LM代理与强化学习（Agent-RL）的结合仍缺乏系统研究。为此，我们构建了AgentFly，一个可扩展且可扩展的Agent-RL框架，旨在为LM代理赋能多种RL算法。该框架通过在传统RL方法中采用 token 级遮蔽支持多轮交互，并通过基于装饰器的接口定义工具和奖励函数，实现无缝扩展和易用性。为支持高吞吐量训练，我们实现了工具调用和奖励计算的异步执行，并设计了集中式资源管理系统以实现可扩展的环境协调。我们还提供了一套预构建的工具和环境，通过多个任务中的成功代理训练展示了框架的有效性。', 'title_zh': 'AgentFly：可扩展且模块化的大型语言模型代理 reinforcement 学习方法'}
{'arxiv_id': 'arXiv:2507.14730', 'title': 'Towards AI Urban Planner in the Age of GenAI, LLMs, and Agentic AI', 'authors': 'Yanjie Fu', 'link': 'https://arxiv.org/abs/2507.14730', 'abstract': 'Generative AI, large language models, and agentic AI have emerged separately of urban planning. However, the convergence between AI and urban planning presents an interesting opportunity towards AI urban planners. This paper conceptualizes urban planning as a generative AI task, where AI synthesizes land-use configurations under geospatial, social, and human-centric constraints. We survey how generative AI approaches, including VAEs, GANs, transformers, and diffusion models, reshape urban design. We further identify critical gaps: 1) limited research on integrating urban theory guidance, 2) limited research of AI urban planning over multiple spatial resolutions or angularities, 3) limited research on augmenting urban design knowledge from data, and 4) limited research on addressing real-world interactions. To address these limitations, we outline future research directions in theory-guided generation, digital twins, and human-machine co-design, calling for a new synthesis of generative intelligence and participatory urbanism.', 'abstract_zh': '生成式AI、大规模语言模型和代理AI与城市规划领域相继出现。然而，AI与城市规划的结合为智能城市规划者提供了有趣的机会。本文将城市规划概念化为一个生成式AI任务，其中AI在地理空间、社会和以人为本的约束下综合土地利用配置。我们探讨了生成式AI方法（包括VAE、GAN、变压器和扩散模型）如何重塑城市设计。进一步识别出关键缺口：1）有限的城市理论指导研究，2）有限的多尺度或多视角的城市规划研究，3）有限的城市设计知识从数据中增强的研究，4）有限的现实世界交互解决研究。为了弥补这些不足，本文概述了理论指导生成、数字孪生和人机协作设计的研究方向，呼吁生成式智能与参与性城市主义的新合成。', 'title_zh': '面向生成式AI、大型语言模型和自主AI时代的AI城乡规划师'}
{'arxiv_id': 'arXiv:2507.14719', 'title': 'Automated Safety Evaluations Across 20 Large Language Models: The Aymara LLM Risk and Responsibility Matrix', 'authors': 'Juan Manuel Contreras', 'link': 'https://arxiv.org/abs/2507.14719', 'abstract': 'As large language models (LLMs) become increasingly integrated into real-world applications, scalable and rigorous safety evaluation is essential. This paper introduces Aymara AI, a programmatic platform for generating and administering customized, policy-grounded safety evaluations. Aymara AI transforms natural-language safety policies into adversarial prompts and scores model responses using an AI-based rater validated against human judgments. We demonstrate its capabilities through the Aymara LLM Risk and Responsibility Matrix, which evaluates 20 commercially available LLMs across 10 real-world safety domains. Results reveal wide performance disparities, with mean safety scores ranging from 86.2% to 52.4%. While models performed well in well-established safety domains such as Misinformation (mean = 95.7%), they consistently failed in more complex or underspecified domains, notably Privacy & Impersonation (mean = 24.3%). Analyses of Variance confirmed that safety scores differed significantly across both models and domains (p < .05). These findings underscore the inconsistent and context-dependent nature of LLM safety and highlight the need for scalable, customizable tools like Aymara AI to support responsible AI development and oversight.', 'abstract_zh': '随着大型语言模型（LLMs）日益融入实际应用，可扩展且严谨的安全评估至关重要。本文介绍了Aymara AI，一个用于生成和管理定制化、基于政策的安全评估的程序平台。Aymara AI将自然语言安全政策转换为对抗性提示，并使用经过人类判断验证的人工智能评估员来评分模型响应。我们通过Aymara LLM风险与责任矩阵演示了其能力，该矩阵评估了20个商用LLM在10个实际安全领域的表现。结果显示，安全评分差异显著，均值范围从86.2%到52.4%不等。虽然模型在已建立的安全领域如虚假信息（均值=95.7%）表现良好，但在更复杂或界定不清的领域，如隐私与冒名顶替（均值=24.3%）表现一致不佳。方差分析证实，安全评分在不同模型和领域之间存在显著差异（p < .05）。这些发现强调了LLM安全的不一致性和情境依赖性，并突显了需要像Aymara AI这样的可扩展、可定制工具来支持负责任的人工智能开发和监管。', 'title_zh': '跨20个大型语言模型的自动化安全评估：艾马拉LLM风险与责任矩阵'}
{'arxiv_id': 'arXiv:2507.14705', 'title': 'Configurable multi-agent framework for scalable and realistic testing of llm-based agents', 'authors': 'Sai Wang, Senthilnathan Subramanian, Mudit Sahni, Praneeth Gone, Lingjie Meng, Xiaochen Wang, Nicolas Ferradas Bertoli, Tingxian Cheng, Jun Xu', 'link': 'https://arxiv.org/abs/2507.14705', 'abstract': "Large-language-model (LLM) agents exhibit complex, context-sensitive behaviour that quickly renders static benchmarks and ad-hoc manual testing obsolete.\nWe present Neo, a configurable, multi-agent framework that automates realistic, multi-turn evaluation of LLM-based systems. Neo couples a Question Generation Agent and an Evaluation Agent through a shared context-hub, allowing domain prompts, scenario controls and dynamic feedback to be composed modularly. Test inputs are sampled from a probabilistic state model spanning dialogue flow, user intent and emotional tone, enabling diverse, human-like conversations that adapt after every turn.\nApplied to a production-grade Seller Financial Assistant chatbot, Neo (i) uncovered edge-case failures across five attack categories with a 3.3% break rate close to the 5.8% achieved by expert human red-teamers, and (ii) delivered 10-12X higher throughput, generating 180 coherent test questions in around 45 mins versus 16h of human effort. Beyond security probing, Neo's stochastic policies balanced topic coverage and conversational depth, yielding broader behavioural exploration than manually crafted scripts.\nNeo therefore lays a foundation for scalable, self-evolving LLM QA: its agent interfaces, state controller and feedback loops are model-agnostic and extensible to richer factual-grounding and policy-compliance checks. We release the framework to facilitate reproducible, high-fidelity testing of emerging agentic systems.", 'abstract_zh': '大型语言模型（LLM）代理表现出复杂且上下文敏感的行为，迅速使得静态基准和临时手动测试过时。\n我们提出了Neो，一个可配置的多代理框架，用于自动化评估基于LLM的系统的真实多轮对话。Neो通过共享上下文中枢连接了一个问题生成代理和一个评估代理，允许模块化地组成领域提示、场景控制和动态反馈。测试输入采样自涵盖对话流程、用户意图和情感基调的随机状态模型，从而实现多样化、类人的对话，并在每次回合后进行适应。\n应用于生产级卖家金融助手聊天机器人，Neो(i)发现了五个攻击类别中的边缘案例失败，错误率为3.3%，接近专家人工红队成员实现的5.8%，并且(ii)实现了10-12倍的吞吐量，生成180个连贯的测试问题仅需45分钟左右，而人工努力需要16小时。除了安全测试，Neö的随机策略平衡了话题覆盖和对话深度，提供了比手动编写的脚本更加广泛的行为探索。\n因此，Neö为可扩展且自演化的LLM QA奠定了基础：其代理接口、状态控制器和反馈循环具有模型通用性和拓展性，适用于更丰富的事实依据和策略合规性检查。我们发布此框架以促进新兴代理系统的可再现性和高保真测试。', 'title_zh': '可配置的多智能体框架：面向基于LLM的智能体可扩展与真实的测试'}
{'arxiv_id': 'arXiv:2507.14660', 'title': 'When Autonomy Goes Rogue: Preparing for Risks of Multi-Agent Collusion in Social Systems', 'authors': 'Qibing Ren, Sitao Xie, Longxuan Wei, Zhenfei Yin, Junchi Yan, Lizhuang Ma, Jing Shao', 'link': 'https://arxiv.org/abs/2507.14660', 'abstract': 'Recent large-scale events like election fraud and financial scams have shown how harmful coordinated efforts by human groups can be. With the rise of autonomous AI systems, there is growing concern that AI-driven groups could also cause similar harm. While most AI safety research focuses on individual AI systems, the risks posed by multi-agent systems (MAS) in complex real-world situations are still underexplored. In this paper, we introduce a proof-of-concept to simulate the risks of malicious MAS collusion, using a flexible framework that supports both centralized and decentralized coordination structures. We apply this framework to two high-risk fields: misinformation spread and e-commerce fraud. Our findings show that decentralized systems are more effective at carrying out malicious actions than centralized ones. The increased autonomy of decentralized systems allows them to adapt their strategies and cause more damage. Even when traditional interventions, like content flagging, are applied, decentralized groups can adjust their tactics to avoid detection. We present key insights into how these malicious groups operate and the need for better detection systems and countermeasures. Code is available at this https URL.', 'abstract_zh': '近期大规模事件如选举欺诈和金融诈骗表明了人类群体协同行为的危害性。随着自主AI系统的兴起，人们对由AI驱动的群体也可能造成类似危害的担忧日益增加。尽管大多数AI安全研究侧重于个体AI系统，但复杂现实世界环境中多智能体系统（MAS）带来的风险仍远未得到充分探索。在本文中，我们介绍了一种概念验证方法，用于模拟恶意MAS合谋带来的风险，并使用一个支持集中式和去中心化协调结构的灵活框架。我们将该框架应用于两个高风险领域：信息传播虚假信息和电子商务诈骗。研究发现，去中心化系统比集中化系统更有效地执行恶意行为。去中心化系统的增加自主性使它们能够调整策略并造成更大的损害。即使应用传统的干预措施（如内容标记），去中心化群体也可以调整其策略以避免检测。我们提出了这些恶意群体运作的关键见解，并强调需要更好的检测系统和应对措施。代码可在以下链接获取：this https URL。', 'title_zh': '当自主性失控：社交系统中多智能体共谋风险的准备'}
{'arxiv_id': 'arXiv:2507.14642', 'title': 'Efficient Story Point Estimation With Comparative Learning', 'authors': 'Monoshiz Mahbub Khan, Xioayin Xi, Andrew Meneely, Zhe Yu', 'link': 'https://arxiv.org/abs/2507.14642', 'abstract': "Story point estimation is an essential part of agile software development. Story points are unitless, project-specific effort estimates that help developers plan their sprints. Traditionally, developers estimate story points collaboratively using planning poker or other manual techniques. While the initial calibrating of the estimates to each project is helpful, once a team has converged on a set of precedents, story point estimation can become tedious and labor-intensive. Machine learning can reduce this burden, but only with enough context from the historical decisions made by the project team. That is, state-of-the-art models, such as GPT2SP and FastText-SVM, only make accurate predictions (within-project) when trained on data from the same project. The goal of this work is to streamline story point estimation by evaluating a comparative learning-based framework for calibrating project-specific story point prediction models. Instead of assigning a specific story point value to every backlog item, developers are presented with pairs of items, and indicate which item requires more effort. Using these comparative judgments, a machine learning model is trained to predict the story point estimates. We empirically evaluated our technique using data with 23,313 manual estimates in 16 projects. The model learned from comparative judgments can achieve on average 0.34 Spearman's rank correlation coefficient between its predictions and the ground truth story points. This is similar to, if not better than, the performance of a regression model learned from the ground truth story points. Therefore, the proposed comparative learning approach is more efficient than state-of-the-art regression-based approaches according to the law of comparative judgments - providing comparative judgments yields a lower cognitive burden on humans than providing ratings or categorical labels.", 'abstract_zh': '基于比较学习框架的项目特定故事点预测模型校准研究', 'title_zh': '基于比较学习的高效故事点估算'}
{'arxiv_id': 'arXiv:2507.14593', 'title': 'Coordinate Heart System: A Geometric Framework for Emotion Representation', 'authors': 'Omar Al-Desi', 'link': 'https://arxiv.org/abs/2507.14593', 'abstract': "This paper presents the Coordinate Heart System (CHS), a geometric framework for emotion representation in artificial intelligence applications. We position eight core emotions as coordinates on a unit circle, enabling mathematical computation of complex emotional states through coordinate mixing and vector operations. Our initial five-emotion model revealed significant coverage gaps in the emotion space, leading to the development of an eight-emotion system that provides complete geometric coverage with mathematical guarantees. The framework converts natural language input to emotion coordinates and supports real-time emotion interpolation through computational algorithms. The system introduces a re-calibrated stability parameter S in [0,1], which dynamically integrates emotional load, conflict resolution, and contextual drain factors. This stability model leverages advanced Large Language Model interpretation of textual cues and incorporates hybrid temporal tracking mechanisms to provide nuanced assessment of psychological well-being states. Our key contributions include: (i) mathematical proof demonstrating why five emotions are insufficient for complete geometric coverage, (ii) an eight-coordinate system that eliminates representational blind spots, (iii) novel algorithms for emotion mixing, conflict resolution, and distance calculation in emotion space, and (iv) a comprehensive computational framework for AI emotion recognition with enhanced multi-dimensional stability modeling. Experimental validation through case studies demonstrates the system's capability to handle emotionally conflicted states, contextual distress factors, and complex psychological scenarios that traditional categorical emotion models cannot adequately represent. This work establishes a new mathematical foundation for emotion modeling in artificial intelligence systems.", 'abstract_zh': '本论文介绍了坐标心系统（CHS），一种在人工智能应用中情绪表示的几何框架。我们将八种核心情绪置于单位圆的坐标上，通过坐标混合和向量运算实现复杂情感状态的数学计算。我们最初五情绪模型揭示了情绪空间中存在的显著覆盖率缺口，促使我们开发了八情绪系统，该系统提供了完整的几何覆盖，并有数学上的保证。该框架将自然语言输入转换为情绪坐标，并通过计算算法支持实时的情感插值。该系统引入了一个重新校准的稳定性参数S（在[0,1]区间内），动态整合了情感负荷、冲突解决和情境负担等因素。该稳定性模型利用先进的大型语言模型对文本线索进行解释，并结合了混合时序跟踪机制，提供对心理福祉状态的细致评估。我们的主要贡献包括：（i）证明了为什么五个情绪不足以实现完整的几何覆盖，（ii）一个八坐标系统，消除了表示上的盲点，（iii）用于情绪混合、冲突解决和情绪空间中距离计算的新算法，以及（iv）用于人工智能情绪识别的综合计算框架，增强多维稳定性建模。通过对实际案例的研究进行实验验证，该系统展示了在处理传统类别情绪模型无法充分代表的复杂心理冲突状态、情境困扰因素和复杂心理场景方面的能力。本研究为人工智能系统中的情绪建模奠定了新的数学基础。', 'title_zh': '协调心脏系统：情感表示的几何框架'}
{'arxiv_id': 'arXiv:2507.14552', 'title': 'Large Language Models Assisting Ontology Evaluation', 'authors': 'Anna Sofia Lippolis, Mohammad Javad Saeedizade, Robin Keskisärkkä, Aldo Gangemi, Eva Blomqvist, Andrea Giovanni Nuzzolese', 'link': 'https://arxiv.org/abs/2507.14552', 'abstract': "Ontology evaluation through functional requirements, such as testing via competency question (CQ) verification, is a well-established yet costly, labour-intensive, and error-prone endeavour, even for ontology engineering experts. In this work, we introduce OE-Assist, a novel framework designed to assist ontology evaluation through automated and semi-automated CQ verification. By presenting and leveraging a dataset of 1,393 CQs paired with corresponding ontologies and ontology stories, our contributions present, to our knowledge, the first systematic investigation into large language model (LLM)-assisted ontology evaluation, and include: (i) evaluating the effectiveness of a LLM-based approach for automatically performing CQ verification against a manually created gold standard, and (ii) developing and assessing an LLM-powered framework to assist CQ verification with Protégé, by providing suggestions. We found that automated LLM-based evaluation with o1-preview and o3-mini perform at a similar level to the average user's performance.", 'abstract_zh': '通过功能需求，如通过能力问题(CQ)验证进行测试，本体评价是一个虽已确立但成本高、劳动密集且易出错的过程，即使对于本体工程专家也是如此。本文介绍了一种名为OE-Assist的新型框架，旨在通过自动化和半自动化CQ验证辅助本体评价。通过呈现并利用包含1,393个CQ及其对应本体和本体故事的数据集，我们的贡献据我们所知首次系统地探讨了大型语言模型(LLM)辅助本体评价，并包括：(i) 评估基于LLM的方法自动执行CQ验证的有效性，该方法与手动创建的标准进行比较，以及(ii) 开发并评估一种基于LLM的框架，该框架通过提供建议协助在Protégé中进行CQ验证。我们发现，使用o1-preview和o3-mini的自动化LLM评价性能与普通用户的性能相当。', 'title_zh': '大规模语言模型辅助本体评估'}
{'arxiv_id': 'arXiv:2507.14520', 'title': 'What if Othello-Playing Language Models Could See?', 'authors': 'Xinyi Chen, Yifei Yuan, Jiaang Li, Serge Belongie, Maarten de Rijke, Anders Søgaard', 'link': 'https://arxiv.org/abs/2507.14520', 'abstract': 'Language models are often said to face a symbol grounding problem. While some argue that world understanding can emerge from text alone, others suggest grounded learning is more efficient. We explore this through Othello, where the board state defines a simplified, rule-based world. Building on prior work, we introduce VISOTHELLO, a multi-modal model trained on move histories and board images. Using next-move prediction, we compare it to mono-modal baselines and test robustness to semantically irrelevant perturbations. We find that multi-modal training improves both performance and the robustness of internal representations. These results suggest that grounding language in visual input helps models infer structured world representations.', 'abstract_zh': '语言模型通常面临符号接地问题。虽然有人认为仅从文本中可以 emerg 出世界理解，但也有观点认为 grounded 学习更为高效。我们通过象棋 Othello 探索这一问题，其中棋盘状态定义了一个简化的基于规则的世界。在此基础上，我们引入了 VISOTHELLO，这是一种多模态模型，通过棋步历史和棋盘图像进行训练。利用下一步棋预测，我们将其与单模态基线进行比较，并检验其对语义无关干扰的鲁棒性。我们发现，多模态训练不仅提高了模型的性能，还增强了内部表示的鲁棒性。这些结果表明，将语言与视觉输入接地有助于模型推断出结构化世界表示。', 'title_zh': '如果莎士比亚戏剧《奥赛罗》的语言模型拥有视觉能力会怎么样？'}
{'arxiv_id': 'arXiv:2507.14513', 'title': 'Amico: An Event-Driven Modular Framework for Persistent and Embedded Autonomy', 'authors': 'Hongyi Yang, Yue Pan, Jiayi Xu, Kelsen Liu', 'link': 'https://arxiv.org/abs/2507.14513', 'abstract': 'Recent advances in large language models (LLMs) and autonomous agents have enabled systems capable of performing complex tasks across domains such as human-computer interaction, planning, and web navigation. However, many existing frameworks struggle in real-world or resource-constrained environments due to their reliance on cloud-based computation, limited robustness in dynamic contexts, and lack of persistent autonomy and environmental awareness.\nWe present Amico, a modular, event-driven framework for building autonomous agents optimized for embedded systems. Written in Rust for safety and performance, Amico supports reactive, persistent agents that operate efficiently across embedded platforms and browser environments via WebAssembly. It provides clean abstractions for event handling, state management, behavior execution, and integration with reasoning modules. Amico delivers a unified infrastructure for constructing resilient, interactive agents suitable for deployment in settings with limited compute and intermittent connectivity.', 'abstract_zh': 'Recent Advances in Large Language Models and Autonomous Agents and the Introduction of Amico：一个用于嵌入式系统的模块化事件驱动框架', 'title_zh': 'Amico: 一种用于持久化和嵌入式自主性的事件驱动模块化框架'}
{'arxiv_id': 'arXiv:2507.14468', 'title': 'BioGraphFusion: Graph Knowledge Embedding for Biological Completion and Reasoning', 'authors': 'Yitong Lin, Jiaying He, Jiahe Chen, Xinnan Zhu, Jianwei Zheng, Tao Bo', 'link': 'https://arxiv.org/abs/2507.14468', 'abstract': "Motivation: Biomedical knowledge graphs (KGs) are crucial for drug discovery and disease understanding, yet their completion and reasoning are challenging. Knowledge Embedding (KE) methods capture global semantics but struggle with dynamic structural integration, while Graph Neural Networks (GNNs) excel locally but often lack semantic understanding. Even ensemble approaches, including those leveraging language models, often fail to achieve a deep, adaptive, and synergistic co-evolution between semantic comprehension and structural learning. Addressing this critical gap in fostering continuous, reciprocal refinement between these two aspects in complex biomedical KGs is paramount.\nResults: We introduce BioGraphFusion, a novel framework for deeply synergistic semantic and structural learning. BioGraphFusion establishes a global semantic foundation via tensor decomposition, guiding an LSTM-driven mechanism to dynamically refine relation embeddings during graph propagation. This fosters adaptive interplay between semantic understanding and structural learning, further enhanced by query-guided subgraph construction and a hybrid scoring mechanism. Experiments across three key biomedical tasks demonstrate BioGraphFusion's superior performance over state-of-the-art KE, GNN, and ensemble models. A case study on Cutaneous Malignant Melanoma 1 (CMM1) highlights its ability to unveil biologically meaningful pathways.\nAvailability and Implementation: Source code and all training data are freely available for download at this https URL.\nContact: zjw@zjut.this http URL, botao666666@126.com.\nSupplementary information: Supplementary data are available at Bioinformatics online.", 'abstract_zh': '动机：生物医学知识图谱（KGs）对于药物发现和疾病理解至关重要，然而其补充和推理却颇具挑战性。语义嵌入（KE）方法能够捕获全局语义，但在动态结构整合方面存在困难，而图神经网络（GNNs）虽然在局部表现优异，但在语义理解方面却常常欠缺。即使是结合语言模型等方法的集成方法，也往往无法实现语义理解和结构学习的深入、适应性和协同进化。因此，在复杂的生物医学KGs中促进这两方面的持续和相互强化是至关重要的。\n\n结果：我们提出了BioGraphFusion，这是一种新的框架，实现了语义和结构学习的深度融合。BioGraphFusion通过张量分解建立全局语义基础，并引导基于LSTM的机制动态精化图传播过程中的关系嵌入。这促进了语义理解与结构学习之间的适应性互动，进一步通过查询引导的子图构造和混合评分机制加以增强。在三个关键的生物医学任务上的实验结果表明，BioGraphFusion在语义嵌入（KE）、图神经网络（GNN）和集成模型中表现出更优的性能。Cutaneous Malignant Melanoma 1（CMM1）案例研究证明了其揭示生物学意义途径的能力。\n\n可用性和实现：源代码及所有训练数据均可在此页面下载：[此链接]。\n\n联系人：zjw@zjut.[此链接]，botao66666666@126.com。\n\n补充信息：补充数据可在Bioinformatics在线获取。', 'title_zh': 'BioGraphFusion: 生物学知识嵌入的图表示学习及其推理'}
{'arxiv_id': 'arXiv:2507.14447', 'title': 'Routine: A Structural Planning Framework for LLM Agent System in Enterprise', 'authors': 'Guancheng Zeng, Xueyi Chen, Jiawang Hu, Shaohua Qi, Yaxuan Mao, Zhantao Wang, Yifan Nie, Shuang Li, Qiuyang Feng, Pengxu Qiu, Yujia Wang, Wenqiang Han, Linyan Huang, Gang Li, Jingjing Mo, Haowen Hu', 'link': 'https://arxiv.org/abs/2507.14447', 'abstract': "The deployment of agent systems in an enterprise environment is often hindered by several challenges: common models lack domain-specific process knowledge, leading to disorganized plans, missing key tools, and poor execution stability. To address this, this paper introduces Routine, a multi-step agent planning framework designed with a clear structure, explicit instructions, and seamless parameter passing to guide the agent's execution module in performing multi-step tool-calling tasks with high stability. In evaluations conducted within a real-world enterprise scenario, Routine significantly increases the execution accuracy in model tool calls, increasing the performance of GPT-4o from 41.1% to 96.3%, and Qwen3-14B from 32.6% to 83.3%. We further constructed a Routine-following training dataset and fine-tuned Qwen3-14B, resulting in an accuracy increase to 88.2% on scenario-specific evaluations, indicating improved adherence to execution plans. In addition, we employed Routine-based distillation to create a scenario-specific, multi-step tool-calling dataset. Fine-tuning on this distilled dataset raised the model's accuracy to 95.5%, approaching GPT-4o's performance. These results highlight Routine's effectiveness in distilling domain-specific tool-usage patterns and enhancing model adaptability to new scenarios. Our experimental results demonstrate that Routine provides a practical and accessible approach to building stable agent workflows, accelerating the deployment and adoption of agent systems in enterprise environments, and advancing the technical vision of AI for Process.", 'abstract_zh': '企业在部署代理系统时常常受到多种挑战：通用模型缺乏特定领域的流程知识，导致计划杂乱无章、关键工具缺失和执行稳定性差。为解决这一问题，本文提出了一种名为Routine的多步代理规划框架，该框架具有清晰的结构、明确的指令和无缝的参数传递，以指导代理执行模块进行多步骤工具调用任务，提高执行稳定性。在实际企业场景下的评估中，Routine显著提高了模型工具调用的执行准确性，使得GPT-4o的性能从41.1%提升到96.3%，Qwen3-14B的性能从32.6%提升到83.3%。我们进一步构建了一个遵循Routine的训练数据集并对Qwen3-14B进行微调，在特定场景下的评估中，其准确性提高到88.2%，表明执行计划的遵守程度有所提高。此外，我们使用基于Routine的蒸馏技术创建了一个特定场景下的多步骤工具调用数据集。在微调该蒸馏数据集后，模型的准确性提高到95.5%，接近GPT-4o的表现。这些结果突显了Routine在提炼特定领域工具使用模式和增强模型对新场景适应性方面的有效性。我们的实验结果表明，Routine提供了一种实用且易于使用的构建稳定代理工作流的方法，加速了代理系统在企业环境中的部署和采用，并推动了AI在流程技术愿景的发展。', 'title_zh': '常规：企业中LLM代理系统的设计结构规划框架'}
{'arxiv_id': 'arXiv:2507.14417', 'title': 'Inverse Scaling in Test-Time Compute', 'authors': 'Aryo Pradipta Gema, Alexander Hägele, Runjin Chen, Andy Arditi, Jacob Goldman-Wetzler, Kit Fraser-Taliente, Henry Sleight, Linda Petrini, Julian Michael, Beatrice Alex, Pasquale Minervini, Yanda Chen, Joe Benton, Ethan Perez', 'link': 'https://arxiv.org/abs/2507.14417', 'abstract': 'We construct evaluation tasks where extending the reasoning length of Large Reasoning Models (LRMs) deteriorates performance, exhibiting an inverse scaling relationship between test-time compute and accuracy. Our evaluation tasks span four categories: simple counting tasks with distractors, regression tasks with spurious features, deduction tasks with constraint tracking, and advanced AI risks. We identify five distinct failure modes when models reason for longer: 1) Claude models become increasingly distracted by irrelevant information; 2) OpenAI o-series models resist distractors but overfit to problem framings; 3) models shift from reasonable priors to spurious correlations; 4) all models show difficulties in maintaining focus on complex deductive tasks; and 5) extended reasoning may amplify concerning behaviors, with Claude Sonnet 4 showing increased expressions of self-preservation. These findings suggest that while test-time compute scaling remains promising for improving model capabilities, it may inadvertently reinforce problematic reasoning patterns. Our results demonstrate the importance of evaluating models across diverse reasoning lengths to identify and address these failure modes in LRMs.', 'abstract_zh': '我们构建了评估任务，在这些任务中，延长大型推理模型（LRMs）的推理长度会降低性能，展示了测试时计算量与准确率之间的一种反向关联关系。我们的评估任务涵盖四个类别：带有干扰项的简单计数任务、具有虚假特征的回归任务、涉及约束跟踪的演绎任务以及高级人工智能风险。当模型进行更长时间的推理时，我们发现了五种不同的失败模式：1）Claude模型越来越受到无关信息的干扰；2）OpenAI o系列模型抵制干扰项但过度拟合于问题框架；3）模型从合理的先验知识转变为虚假相关性；4）所有模型在复杂的演绎任务中都表现出保持专注的困难；5）延长推理可能会放大某些令人担忧的行为，其中Claude Sonnet 4表现出增强的自我保护表现。这些发现表明，虽然测试时计算量的扩展对提高模型能力仍具有前景，但它可能会无意中强化问题推理模式。我们的结果强调了在不同推理长度下评估模型的重要性，以识别并解决大型推理模型中的这些失败模式。', 'title_zh': '测试时计算中的逆缩放'}
{'arxiv_id': 'arXiv:2507.14406', 'title': 'Fail Fast, or Ask: Mitigating the Deficiencies of Reasoning LLMs with Human-in-the-Loop Systems Engineering', 'authors': 'Michael J. Zellinger, Matt Thomson', 'link': 'https://arxiv.org/abs/2507.14406', 'abstract': 'State-of-the-art reasoning LLMs are powerful problem solvers, but they still occasionally make mistakes. However, adopting AI models in risk-sensitive domains often requires error rates near 0%. To address this gap, we propose collaboration between a reasoning model and a human expert who resolves queries the model cannot confidently answer. We find that quantifying the uncertainty of a reasoning model through the length of its reasoning trace yields an effective basis for deferral to a human, e.g., cutting the error rate of Qwen3 235B-A22B on difficult MATH problems from 3% to less than 1% when deferring 7.5% of queries. However, the high latency of reasoning models still makes them challenging to deploy on use cases with high query volume. To address this challenge, we explore fronting a reasoning model with a large non-reasoning model. We call this modified human-in-the-loop system "Fail Fast, or Ask", since the non-reasoning model may defer difficult queries to the human expert directly ("failing fast"), without incurring the reasoning model\'s higher latency. We show that this approach yields around 40% latency reduction and about 50% cost savings for DeepSeek R1 while maintaining 90+% area under the accuracy-rejection curve. However, we observe that latency savings are lower than expected because of "latency drag", the phenomenon that processing easier queries with a non-reasoning model pushes the reasoning model\'s latency distribution towards longer latencies. Broadly, our results suggest that the deficiencies of state-of-the-art reasoning models -- nontrivial error rates and high latency -- can be substantially mitigated through black-box systems engineering, without requiring access to LLM internals.', 'abstract_zh': '基于推理的前沿大模型是强大的问题解决者，但仍然偶尔会出现错误。为应对这一差距，我们提出了一种推理模型与人专家协作的方案，由人专家解决模型无法自信回答的查询。我们发现，通过推理模型的推理轨迹长度量化其不确定性，可以为转交给人类提供有效的基础，例如，在将7.5%的查询转交给人类时，将Qwen3 235B-A22B在困难MATH问题上的错误率从3%降低到不到1%。然而，推理模型的高延迟仍然使得它们难以部署在查询量高的应用场景中。为解决这一挑战，我们探索在推理模型前面使用一个大型非推理模型。我们称这种修改后的人在环系统为“快速失败，或者求助”，因为非推理模型可以直接将复杂的查询转交给人类专家（“快速失败”），而不增加推理模型的较高延迟。我们展示了这种方法可以使DeepSeek R1的延迟降低约40%，成本节省约50%，同时保持90%以上的准确率-拒绝率曲线下的面积。然而，我们观察到延迟节省低于预期，因为“延迟拖累”现象导致使用非推理模型处理较简单的查询推高了推理模型的延迟分布。总体而言，我们的结果表明，通过黑盒系统工程可以显著缓解前沿推理模型的主要缺陷——非平凡的错误率和高延迟——而不需要访问大语言模型的内部结构。', 'title_zh': '快速失败，或询问：通过人类在环系统工程减轻 reasoning LLMs 的缺陷'}
{'arxiv_id': 'arXiv:2507.14393', 'title': 'Adaptive Multi-Agent Reasoning via Automated Workflow Generation', 'authors': 'Humza Sami, Mubashir ul Islam, Pierre-Emmanuel Gaillardon, Valerio Tenace', 'link': 'https://arxiv.org/abs/2507.14393', 'abstract': "The rise of Large Reasoning Models (LRMs) promises a significant leap forward in language model capabilities, aiming to tackle increasingly sophisticated tasks with unprecedented efficiency and accuracy. However, despite their impressive performance, recent studies have highlighted how current reasoning models frequently fail to generalize to novel, unseen problems, often resorting to memorized solutions rather than genuine inferential reasoning. Such behavior underscores a critical limitation in modern LRMs, i.e., their tendency toward overfitting, which in turn results in poor generalization in problem-solving capabilities.\nIn this paper, we introduce Nexus Architect, an enhanced iteration of our multi-agent system framework, Nexus, equipped with a novel automated workflow synthesis mechanism. Given a user's prompt and a small set of representative examples, the Architect autonomously generates a tailored reasoning workflow by selecting suitable strategies, tool integrations, and adversarial techniques for a specific problem class. Furthermore, the Architect includes an iterative prompt refinement mechanism that fine-tunes agents' system prompts to maximize performance and improve the generalization capabilities of the system.\nWe empirically evaluate Nexus Architect by employing an off-the-shelf, non-reasoning model on a custom dataset of challenging logical questions and compare its performance against state-of-the-art LRMs. Results show that Nexus Architect consistently outperforms existing solutions, achieving up to a 66% increase in pass rate over Gemini 2.5 Flash Preview, nearly 2.5$\\times$ against Claude Sonnet 4 and DeepSeek-R1, and over 3$\\times$ w.r.t. Llama 4 Scout.", 'abstract_zh': '大型推理模型的崛起：Nexus Architect的引入与评估', 'title_zh': '自适应多代理推理通过自动化工作流生成'}
{'arxiv_id': 'arXiv:2507.14335', 'title': 'ProofCompass: Enhancing Specialized Provers with LLM Guidance', 'authors': 'Nicolas Wischermann, Claudio Mayrink Verdun, Gabriel Poesia, Francesco Noseda', 'link': 'https://arxiv.org/abs/2507.14335', 'abstract': 'Language models have become increasingly powerful tools for formal mathematical reasoning. However, most existing approaches rely exclusively on either large general-purpose models or smaller specialized models, each with distinct limitations, while training specialized large models still requires significant computational resources. This paper introduces ProofCompass, a novel hybrid methodology that achieves remarkable computational efficiency by strategically guiding existing specialized prover methods, such as DeepSeek-Prover-v1.5-RL (DSP-v1.5) with a Large Language Model (LLM) without requiring additional model training. The LLM provides natural language proof strategies and analyzes failed attempts to select intermediate lemmas, enabling effective problem decomposition. On the miniF2F benchmark, ProofCompass demonstrates substantial resource efficiency: it outperforms DSP-v1.5 ($54.9\\% \\rightarrow 55.3\\%$) while using 25x fewer attempts ($3200 \\rightarrow 128$). Our synergistic approach paves the way for simultaneously improving computational efficiency and accuracy in formal theorem proving.', 'abstract_zh': '语言模型已成为形式化数学推理日益强大的工具。然而，大多数现有方法要么仅依赖大型通用模型，要么仅依赖较小的专业化模型，每种方法都有其独特的局限性，而训练专业化的大规模模型仍然需要大量的计算资源。本文介绍了一种名为ProofCompass的新颖混合方法，通过战略性地引导现有的专业化证明方法（如DeepSeek-Prover-v1.5-RL（DSP-v1.5），并通过一个大型语言模型（LLM）而无需额外的模型训练，实现了显著的计算效率。LLM提供自然语言证明策略并分析失败尝试以选择中间引理，从而有效分解问题。在miniF2F基准测试中，ProofCompass展示了显著的资源效率：它在尝试次数减少25倍（从3200次减少到128次）的情况下，性能超过了DSP-v1.5（从54.9%提升到55.3%）。我们的协同方法为同时提高形式定理证明的计算效率和准确性开辟了道路。', 'title_zh': 'ProofCompass: 通过LLM指导增强专用证明器'}
{'arxiv_id': 'arXiv:2507.14334', 'title': 'Language Models as Ontology Encoders', 'authors': 'Hui Yang, Jiaoyan Chen, Yuan He, Yongsheng Gao, Ian Horrocks', 'link': 'https://arxiv.org/abs/2507.14334', 'abstract': 'OWL (Web Ontology Language) ontologies which are able to formally represent complex knowledge and support semantic reasoning have been widely adopted across various domains such as healthcare and bioinformatics. Recently, ontology embeddings have gained wide attention due to its potential to infer plausible new knowledge and approximate complex reasoning. However, existing methods face notable limitations: geometric model-based embeddings typically overlook valuable textual information, resulting in suboptimal performance, while the approaches that incorporate text, which are often based on language models, fail to preserve the logical structure. In this work, we propose a new ontology embedding method OnT, which tunes a Pretrained Language Model (PLM) via geometric modeling in a hyperbolic space for effectively incorporating textual labels and simultaneously preserving class hierarchies and other logical relationships of Description Logic EL. Extensive experiments on four real-world ontologies show that OnT consistently outperforms the baselines including the state-of-the-art across both tasks of prediction and inference of axioms. OnT also demonstrates strong potential in real-world applications, indicated by its robust transfer learning abilities and effectiveness in real cases of constructing a new ontology from SNOMED CT. Data and code are available at this https URL.', 'abstract_zh': 'Web本体语言（OWL）本体能够正式表示复杂的知识并支持语义推理，在医疗保健和生物信息学等多个领域得到了广泛应用。近年来，由于其能够推断可信的新知识并近似复杂推理的潜力，本体嵌入方法引起了广泛关注。然而，现有的方法面临着一些明显的限制：基于几何模型的嵌入通常忽略了有价值的文字信息，导致性能不佳；结合文字的方法，尽管通常基于语言模型，却未能保持逻辑结构。在本工作中，我们提出了一种新的本体嵌入方法OnT，通过在双曲空间中的几何建模微调预训练语言模型（PLM），有效地结合文字标签，同时保留描述逻辑EL的类层次结构和其他逻辑关系。在四个真实世界的本体上的广泛实验表明，OnT在公理预测和推理任务上均一致地优于基线方法，包括最先进的方法。OnT在实际应用中也展现出强大的潜在能力，其稳健的迁移学习能力和在从SNOMED CT构建新本体方面的有效性得到了验证。数据和代码可在以下链接获取。', 'title_zh': '语言模型作为本体编码器'}
{'arxiv_id': 'arXiv:2507.14306', 'title': 'Manimator: Transforming Research Papers into Visual Explanations', 'authors': 'Samarth P, Vyoman Jain, Shiva Golugula, Motamarri Sai Sathvik', 'link': 'https://arxiv.org/abs/2507.14306', 'abstract': 'Understanding complex scientific and mathematical concepts, particularly those presented in dense research papers, poses a significant challenge for learners. Dynamic visualizations can greatly enhance comprehension, but creating them manually is time-consuming and requires specialized knowledge and skills. We introduce manimator, an open-source system that leverages Large Language Models to transform research papers and natural language prompts into explanatory animations using the Manim engine. Manimator employs a pipeline where an LLM interprets the input text or research paper PDF to generate a structured scene description outlining key concepts, mathematical formulas, and visual elements and another LLM translates this description into executable Manim Python code. We discuss its potential as an educational tool for rapidly creating engaging visual explanations for complex STEM topics, democratizing the creation of high-quality educational content.', 'abstract_zh': '动态可视化的自动化生成：利用大型语言模型将科研论文转换为解释性动画以促进复杂科学与数学概念的理解', 'title_zh': 'Manimator: 将研究论文转化为视觉解释'}
{'arxiv_id': 'arXiv:2507.14293', 'title': 'WebGuard: Building a Generalizable Guardrail for Web Agents', 'authors': 'Boyuan Zheng, Zeyi Liao, Scott Salisbury, Zeyuan Liu, Michael Lin, Qinyuan Zheng, Zifan Wang, Xiang Deng, Dawn Song, Huan Sun, Yu Su', 'link': 'https://arxiv.org/abs/2507.14293', 'abstract': 'The rapid development of autonomous web agents powered by Large Language Models (LLMs), while greatly elevating efficiency, exposes the frontier risk of taking unintended or harmful actions. This situation underscores an urgent need for effective safety measures, akin to access controls for human users. To address this critical challenge, we introduce WebGuard, the first comprehensive dataset designed to support the assessment of web agent action risks and facilitate the development of guardrails for real-world online environments. In doing so, WebGuard specifically focuses on predicting the outcome of state-changing actions and contains 4,939 human-annotated actions from 193 websites across 22 diverse domains, including often-overlooked long-tail websites. These actions are categorized using a novel three-tier risk schema: SAFE, LOW, and HIGH. The dataset includes designated training and test splits to support evaluation under diverse generalization settings. Our initial evaluations reveal a concerning deficiency: even frontier LLMs achieve less than 60% accuracy in predicting action outcomes and less than 60% recall in lagging HIGH-risk actions, highlighting the risks of deploying current-generation agents without dedicated safeguards. We therefore investigate fine-tuning specialized guardrail models using WebGuard. We conduct comprehensive evaluations across multiple generalization settings and find that a fine-tuned Qwen2.5VL-7B model yields a substantial improvement in performance, boosting accuracy from 37% to 80% and HIGH-risk action recall from 20% to 76%. Despite these improvements, the performance still falls short of the reliability required for high-stakes deployment, where guardrails must approach near-perfect accuracy and recall.', 'abstract_zh': 'rapid发展由大型语言模型（LLMs）驱动的自主网络代理，虽然极大提升了效率，但也暴露了采取未预见或有害行动的前沿风险。这强调了迫切需要有效的安全措施，类似于对人类用户进行访问控制。为应对这一关键挑战，我们引入了WebGuard，这是首个旨在支持网络代理行动风险评估并促进适用于现实在线环境的护栏开发的综合数据集。WebGuard特别关注预测状态改变行动的结果，并包含了4,939个人标注的行动，涉及193个网站的22个不同领域，包括常被忽视的长尾网站。这些行动被归类为新颖的三层风险模式：SAFE、LOW和HIGH。数据集包含指定的训练和测试分割，以支持在多种泛化设置下的评估。初步评估揭示了一个令人担忧的缺陷：即使是前沿LLM，在预测行动结果上的准确率和高风险行动召回率均低于60%，突显了在没有专用防护措施的情况下部署当前代理的风险。因此，我们使用WebGuard微调专门的护栏模型。我们进行了全面的评估，在多种泛化设置下发现微调后的Qwen2.5VL-7B模型显著提升了性能，准确率从37%提升到80%，高风险行动召回率从20%提升到76%。尽管这些改进取得了进展，但在高风险场景下的部署仍需要更高的可靠性，需要护栏接近完美的准确率和召回率。', 'title_zh': 'WebGuard: 构建适用于网络代理的通用防护篱笆'}
{'arxiv_id': 'arXiv:2507.14267', 'title': 'DREAMS: Density Functional Theory Based Research Engine for Agentic Materials Simulation', 'authors': 'Ziqi Wang, Hongshuo Huang, Hancheng Zhao, Changwen Xu, Shang Zhu, Jan Janssen, Venkatasubramanian Viswanathan', 'link': 'https://arxiv.org/abs/2507.14267', 'abstract': 'Materials discovery relies on high-throughput, high-fidelity simulation techniques such as Density Functional Theory (DFT), which require years of training, extensive parameter fine-tuning and systematic error handling. To address these challenges, we introduce the DFT-based Research Engine for Agentic Materials Screening (DREAMS), a hierarchical, multi-agent framework for DFT simulation that combines a central Large Language Model (LLM) planner agent with domain-specific LLM agents for atomistic structure generation, systematic DFT convergence testing, High-Performance Computing (HPC) scheduling, and error handling. In addition, a shared canvas helps the LLM agents to structure their discussions, preserve context and prevent hallucination. We validate DREAMS capabilities on the Sol27LC lattice-constant benchmark, achieving average errors below 1\\% compared to the results of human DFT experts. Furthermore, we apply DREAMS to the long-standing CO/Pt(111) adsorption puzzle, demonstrating its long-term and complex problem-solving capabilities. The framework again reproduces expert-level literature adsorption-energy differences. Finally, DREAMS is employed to quantify functional-driven uncertainties with Bayesian ensemble sampling, confirming the Face Centered Cubic (FCC)-site preference at the Generalized Gradient Approximation (GGA) DFT level. In conclusion, DREAMS approaches L3-level automation - autonomous exploration of a defined design space - and significantly reduces the reliance on human expertise and intervention, offering a scalable path toward democratized, high-throughput, high-fidelity computational materials discovery.', 'abstract_zh': '基于DFT的研究引擎DREAMS：智能多代理框架在材料筛选中的应用', 'title_zh': 'DREAMS：基于密度泛函理论的代理材料模拟研究引擎'}
{'arxiv_id': 'arXiv:2507.14154', 'title': 'The Free Will Equation: Quantum Field Analogies for AGI', 'authors': 'Rahul Kabali', 'link': 'https://arxiv.org/abs/2507.14154', 'abstract': 'Artificial General Intelligence (AGI) research traditionally focuses on algorithms that optimize for specific goals under deterministic rules. Yet, human-like intelligence exhibits adaptive spontaneity - an ability to make unexpected choices or free decisions not strictly dictated by past data or immediate reward. This trait, often dubbed "free will" in a loose sense, might be crucial for creativity, robust adaptation, and avoiding ruts in problem-solving. This paper proposes a theoretical framework, called the Free Will Equation, that draws analogies from quantum field theory to endow AGI agents with a form of adaptive, controlled stochasticity in their decision-making process. The core idea is to treat an AI agent\'s cognitive state as a superposition of potential actions or thoughts, which collapses probabilistically into a concrete action when a decision is made - much like a quantum wavefunction collapsing upon measurement. By incorporating mechanisms analogous to quantum fields, along with intrinsic motivation terms, we aim to improve an agent\'s ability to explore novel strategies and adapt to unforeseen changes. Experiments in a non-stationary multi-armed bandit environment demonstrate that agents using this framework achieve higher rewards and policy diversity compared to baseline methods.', 'abstract_zh': '人工通用智能（AGI）研究通常关注在确定性规则下优化特定目标的算法。然而，人类智能表现出一种适应性自发性——能够在不受过去数据或即时奖励严格制约的情况下做出意外选择或自由决定。这一特性，通常以一种松散的意义上称为“自由意志”，对于创造力、稳健的适应性和避免解决问题中的僵局至关重要。本文提出了一种理论框架，称为“自由意志方程”，该框架借鉴了量子场理论的类比，使AGI代理在其决策过程中获得一种适应性和可控的随机性。核心思想是将AI代理的认知状态视为潜在行动或思考的叠加，当做出决策时，这些状态以概率方式坍缩为具体的行动——就像量子波函数在测量时坍缩一样。通过纳入类似量子场的机制以及固有的动机项，我们旨在提高代理探索新颖策略和适应未预见变化的能力。在非平稳多臂 bandit 环境中的实验表明，使用此框架的代理在奖励和策略多样性方面优于基线方法。', 'title_zh': '自由意志方程：类AGI的量子场类比'}
{'arxiv_id': 'arXiv:2507.15857', 'title': 'Diffusion Beats Autoregressive in Data-Constrained Settings', 'authors': 'Mihir Prabhudesai, Menging Wu, Amir Zadeh, Katerina Fragkiadaki, Deepak Pathak', 'link': 'https://arxiv.org/abs/2507.15857', 'abstract': "Autoregressive (AR) models have long dominated the landscape of large language models, driving progress across a wide range of tasks. Recently, diffusion-based language models have emerged as a promising alternative, though their advantages over AR models remain underexplored. In this paper, we systematically study masked diffusion models in data-constrained settings-where training involves repeated passes over limited data-and find that they significantly outperform AR models when compute is abundant but data is scarce. Diffusion models make better use of repeated data, achieving lower validation loss and superior downstream performance. We interpret this advantage as implicit data augmentation: masked diffusion exposes the model to a diverse distribution of token orderings and prediction tasks, unlike AR's fixed left-to-right factorization. We find new scaling laws for diffusion models and derive a closed-form expression for the critical compute threshold at which diffusion begins to outperform AR. These results suggest that when data, not compute, is the bottleneck, diffusion models offer a compelling alternative to the standard AR paradigm. Our code is available at: this https URL.", 'abstract_zh': '自回归（AR）模型长期主导着大型语言模型的领域，推动了多种任务的进步。最近，基于扩散的语言模型成为一种有前途的替代方案，尽管与AR模型相比的优势尚未充分探索。在本文中，我们系统地研究了在数据受限设置下的掩码扩散模型——其中训练涉及多次有限数据的循环迭代——发现当计算资源丰富但数据稀缺时，它们显著优于AR模型。扩散模型能够更好地利用重复数据，实现较低的验证损失和更好的下游性能。我们将这一优势解释为隐式的数据增强：掩码扩散使模型暴露于多样化的令牌排序和预测任务分布中，而不同于AR的固定从左到右的分解。我们发现了扩散模型的新扩展定律，并推导出了扩散开始优于AR的临界计算阈值的闭式表达式。这些结果表明，在数据而非计算受限的情况下，扩散模型为标准AR范式提供了一种有吸引力的替代方案。我们的代码可在以下链接获取：this https URL。', 'title_zh': '数据受限环境中，扩散模型胜过自回归模型'}
{'arxiv_id': 'arXiv:2507.15852', 'title': 'SeC: Advancing Complex Video Object Segmentation via Progressive Concept Construction', 'authors': 'Zhixiong Zhang, Shuangrui Ding, Xiaoyi Dong, Songxin He, Jianfan Lin, Junsong Tang, Yuhang Zang, Yuhang Cao, Dahua Lin, Jiaqi Wang', 'link': 'https://arxiv.org/abs/2507.15852', 'abstract': 'Video Object Segmentation (VOS) is a core task in computer vision, requiring models to track and segment target objects across video frames. Despite notable advances with recent efforts, current techniques still lag behind human capabilities in handling drastic visual variations, occlusions, and complex scene changes. This limitation arises from their reliance on appearance matching, neglecting the human-like conceptual understanding of objects that enables robust identification across temporal dynamics. Motivated by this gap, we propose Segment Concept (SeC), a concept-driven segmentation framework that shifts from conventional feature matching to the progressive construction and utilization of high-level, object-centric representations. SeC employs Large Vision-Language Models (LVLMs) to integrate visual cues across diverse frames, constructing robust conceptual priors. During inference, SeC forms a comprehensive semantic representation of the target based on processed frames, realizing robust segmentation of follow-up frames. Furthermore, SeC adaptively balances LVLM-based semantic reasoning with enhanced feature matching, dynamically adjusting computational efforts based on scene complexity. To rigorously assess VOS methods in scenarios demanding high-level conceptual reasoning and robust semantic understanding, we introduce the Semantic Complex Scenarios Video Object Segmentation benchmark (SeCVOS). SeCVOS comprises 160 manually annotated multi-scenario videos designed to challenge models with substantial appearance variations and dynamic scene transformations. In particular, SeC achieves an 11.8-point improvement over SAM 2.1 on SeCVOS, establishing a new state-of-the-art in concept-aware video object segmentation.', 'abstract_zh': '基于概念的视频对象分割（SeC）：超越外观匹配的高层语义理解', 'title_zh': 'SeC：通过渐进概念构建推动复杂视频对象分割'}
{'arxiv_id': 'arXiv:2507.15849', 'title': 'The Impact of Language Mixing on Bilingual LLM Reasoning', 'authors': 'Yihao Li, Jiayi Xin, Miranda Muqing Miao, Qi Long, Lyle Ungar', 'link': 'https://arxiv.org/abs/2507.15849', 'abstract': 'Proficient multilingual speakers often intentionally switch languages in the middle of a conversation. Similarly, recent reasoning-focused bilingual large language models (LLMs) with strong capabilities in both languages exhibit language mixing--alternating languages within their chain of thought. Discouraging this behavior in DeepSeek-R1 was found to degrade accuracy, suggesting that language mixing may benefit reasoning. In this work, we study language switching in Chinese-English bilingual reasoning models. We identify reinforcement learning with verifiable rewards (RLVR) as the critical training stage that leads to language mixing. We demonstrate that language mixing can enhance reasoning: enforcing monolingual decoding reduces accuracy by 5.6 percentage points on math reasoning tasks. Additionally, a lightweight probe can be trained to predict whether a potential language switch would benefit or harm reasoning, and when used to guide decoding, increases accuracy by up to 6.25 percentage points. Our findings suggest that language mixing is not merely a byproduct of multilingual training, but is a strategic reasoning behavior.', 'abstract_zh': '精通多语言的說話者經常在會話中故意切換語言。類似地，近期以推理為主的雙語大型語言模型（LLMs），在兩種語言方面都表現出色，經常出現語言混用現象—在邏輯推理過程中交替使用語言。在DeepSeek-R1中抑制這種行為被發現會降低準確性，這表明語言混用可能有助於推理。在本工作中，我們研究了雙語推理模型中的中文-英文語言切換。我們識定了強化學習與可驗證回報（RLVR）作為導致語言混用的關鍵訓練階段。我們證明了語言混用可以提升推理能力：強制單語解碼會使數學推理任務的準確率降低5.6個百分點。此外，可以訓練一個輕量級探針來預測潛在的語言切換是否有益於或損害推理，當使用該探針指導解碼時，可以使準確率提高至多6.25個百分點。我們的研究發現表明，語言混用不僅是多語言訓練的副産物，而是一種有策略的推理行為。', 'title_zh': '语言混合对双语LLM推理的影响'}
{'arxiv_id': 'arXiv:2507.15846', 'title': 'GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding', 'authors': 'Fei Tang, Zhangxuan Gu, Zhengxi Lu, Xuyang Liu, Shuheng Shen, Changhua Meng, Wen Wang, Wenqi Zhang, Yongliang Shen, Weiming Lu, Jun Xiao, Yueting Zhuang', 'link': 'https://arxiv.org/abs/2507.15846', 'abstract': 'Graphical User Interface (GUI) grounding maps natural language instructions to precise interface locations for autonomous interaction. Current reinforcement learning approaches use binary rewards that treat elements as hit-or-miss targets, creating sparse signals that ignore the continuous nature of spatial interactions. Motivated by human clicking behavior that naturally forms Gaussian distributions centered on target elements, we introduce GUI Gaussian Grounding Rewards (GUI-G$^2$), a principled reward framework that models GUI elements as continuous Gaussian distributions across the interface plane. GUI-G$^2$ incorporates two synergistic mechanisms: Gaussian point rewards model precise localization through exponentially decaying distributions centered on element centroids, while coverage rewards assess spatial alignment by measuring the overlap between predicted Gaussian distributions and target regions. To handle diverse element scales, we develop an adaptive variance mechanism that calibrates reward distributions based on element dimensions. This framework transforms GUI grounding from sparse binary classification to dense continuous optimization, where Gaussian distributions generate rich gradient signals that guide models toward optimal interaction positions. Extensive experiments across ScreenSpot, ScreenSpot-v2, and ScreenSpot-Pro benchmarks demonstrate that GUI-G$^2$, substantially outperforms state-of-the-art method UI-TARS-72B, with the most significant improvement of 24.7% on ScreenSpot-Pro. Our analysis reveals that continuous modeling provides superior robustness to interface variations and enhanced generalization to unseen layouts, establishing a new paradigm for spatial reasoning in GUI interaction tasks.', 'abstract_zh': '图形用户界面(GUI)高斯接地方法将自然语言指令精确映射到界面位置，实现自主交互。当前的强化学习方法使用二元奖励，将界面元素视为非此即彼的目标，产生稀疏信号，忽视了空间交互的连续性。受人类点击行为自然形成以目标元素为中心的高斯分布启发，我们引入了GUI高斯接地奖励（GUI-G$^2$），该奖励框架以连续高斯分布形式建模界面元素在整个界面平面上的分布。GUI-G$^2$包含两种协同机制：高斯点奖励通过以元素质心为中心的指数衰减分布建模精确定位，而覆盖奖励通过测量预测高斯分布与目标区域之间的重叠来评估空间对齐。为处理不同规模的元素，我们开发了一种适应性方差机制，基于元素尺寸调整奖励分布。该框架将GUI接地从稀疏二元分类转换为密集连续优化，其中高斯分布产生的丰富梯度信号引导模型向最佳交互位置发展。在ScreenSpot、ScreenSpot-v2和ScreenSpot-Pro基准测试中的广泛实验表明，GUI-G$^2$在所有基准测试中均显著优于现有最佳方法UI-TARS-72B，在ScreenSpot-Pro上的改进幅度达到了24.7%。我们的分析表明，连续建模提供了对界面变化的更好鲁棒性和对未见布局的更强泛化能力，为GUI交互任务中的空间推理建立了新的范式。', 'title_zh': 'GUI-G$^2$：基于高斯奖励建模的GUI定位'}
{'arxiv_id': 'arXiv:2507.15839', 'title': 'FASTGEN: Fast and Cost-Effective Synthetic Tabular Data Generation with LLMs', 'authors': 'Anh Nguyen, Sam Schafft, Nicholas Hale, John Alfaro', 'link': 'https://arxiv.org/abs/2507.15839', 'abstract': "Synthetic data generation has emerged as an invaluable solution in scenarios where real-world data collection and usage are limited by cost and scarcity. Large language models (LLMs) have demonstrated remarkable capabilities in producing high-fidelity, domain-relevant samples across various fields. However, existing approaches that directly use LLMs to generate each record individually impose prohibitive time and cost burdens, particularly when large volumes of synthetic data are required. In this work, we propose a fast, cost-effective method for realistic tabular data synthesis that leverages LLMs to infer and encode each field's distribution into a reusable sampling script. By automatically classifying fields into numerical, categorical, or free-text types, the LLM generates distribution-based scripts that can efficiently produce diverse, realistic datasets at scale without continuous model inference. Experimental results show that our approach outperforms traditional direct methods in both diversity and data realism, substantially reducing the burden of high-volume synthetic data generation. We plan to apply this methodology to accelerate testing in production pipelines, thereby shortening development cycles and improving overall system efficiency. We believe our insights and lessons learned will aid researchers and practitioners seeking scalable, cost-effective solutions for synthetic data generation.", 'abstract_zh': '合成数据生成已成为在现实数据收集和使用受限于成本和稀缺性的情况下的一种 invaluable 解决方案。大型语言模型 (LLMs) 在各个领域展示了生成高保真度、领域相关样本的显著能力。然而，现有的直接使用 LLM 生成每个记录的方法在生成大量合成数据时会带来巨大的时间和成本负担。在本文中，我们提出了一种快速且成本有效的表格数据合成方法，该方法利用 LLM 推断并编码每个字段的分布以生成可重用的采样脚本。通过自动将字段分类为数值型、分类型或自由文本型，LLM 生成基于分布的脚本，可以在不连续进行模型推理的情况下高效地大规模生成多样且现实的数据集。实验结果表明，我们的方法在多样性和数据真实性方面优于传统的直接方法，显著减少了大规模合成数据生成的负担。我们计划将这种方法应用于生产流水线中的测试加速，从而缩短开发周期并提高整体系统效率。我们认为我们的见解和经验教训将有助于研究人员和实践者寻找可扩展且成本有效的合成数据生成解决方案。', 'title_zh': 'FASTGEN：基于LLMs的快速且经济高效的合成表格数据生成'}
{'arxiv_id': 'arXiv:2507.15833', 'title': 'Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers', 'authors': 'Ian Chuang, Andrew Lee, Dechen Gao, Jinyu Zou, Iman Soltani', 'link': 'https://arxiv.org/abs/2507.15833', 'abstract': 'Human vision is a highly active process driven by gaze, which directs attention and fixation to task-relevant regions and dramatically reduces visual processing. In contrast, robot learning systems typically rely on passive, uniform processing of raw camera images. In this work, we explore how incorporating human-like active gaze into robotic policies can enhance both efficiency and performance. We build on recent advances in foveated image processing and apply them to an Active Vision robot system that emulates both human head movement and eye tracking. Extending prior work on the AV-ALOHA robot simulation platform, we introduce a framework for simultaneously collecting eye-tracking data and robot demonstrations from a human operator as well as a simulation benchmark and dataset for training robot policies that incorporate human gaze. Given the widespread use of Vision Transformers (ViTs) in robot learning, we integrate gaze information into ViTs using a foveated patch tokenization scheme inspired by recent work in image segmentation. Compared to uniform patch tokenization, this significantly reduces the number of tokens-and thus computation-without sacrificing visual fidelity near regions of interest. We also explore two approaches to gaze imitation and prediction from human data. The first is a two-stage model that predicts gaze to guide foveation and action; the second integrates gaze into the action space, allowing the policy to jointly predict gaze and actions end-to-end. Our results show that our method for foveated robot vision not only drastically reduces computational overhead, but also improves performance for high precision tasks and robustness to unseen distractors. Together, these findings suggest that human-inspired visual processing offers a useful inductive bias for robotic vision systems. this https URL', 'abstract_zh': '人类视觉是一个由注视驱动的高度活跃的过程，能够将注意力和注视引导至任务相关区域，大幅减少视觉处理需求。相比之下，机器人学习系统通常依赖于对原始摄像头图像进行被动、均匀的处理。在本工作中，我们探讨了将类人的主动注视融入机器人策略中如何提高效率和性能。我们基于最新的仿聚焦图像处理进展，将其应用于一个模拟人类头部运动和眼动追踪的Active Vision机器人系统。在此基础上，我们引入了一种框架，同时收集来自人类操作者的注视跟踪数据和机器人演示，并提供了一个用于训练包含人类注视的机器人策略的仿真基准和数据集。鉴于Vision Transformers（ViTs）在机器人学习中的广泛应用，我们通过借鉴图像分割领域的最新工作，利用仿聚焦的补丁分词方案将注视信息整合到ViTs中。与均匀的补丁分词方案相比，这种方法显著减少了令牌的数量——即降低了计算量——同时在感兴趣区域附近保持了视觉保真度。我们还探索了两种从人类数据中模仿和预测注视的方法。第一种是两阶段模型，用于预测注视以指导聚焦和动作；第二种则是将注视整合到动作空间中，使策略能够端到端地同时预测注视和动作。我们的结果显示，我们提出的仿聚焦机器人视觉方法不仅大幅减少了计算开销，还在高精度任务和对未知干扰物的鲁棒性方面表现出更好的性能。这些发现表明，基于人类视觉处理的方法为机器人视觉系统提供了有用的归纳偏置。', 'title_zh': '看、聚焦、行动：通过人类凝视和视网膜视觉转换器实现高效稳健的机器人学习'}
{'arxiv_id': 'arXiv:2507.15823', 'title': 'Operationalizing AI for Good: Spotlight on Deployment and Integration of AI Models in Humanitarian Work', 'authors': 'Anton Abilov, Ke Zhang, Hemank Lamba, Elizabeth M. Olson, Joel R. Tetreault, Alejandro Jaimes', 'link': 'https://arxiv.org/abs/2507.15823', 'abstract': 'Publications in the AI for Good space have tended to focus on the research and model development that can support high-impact applications. However, very few AI for Good papers discuss the process of deploying and collaborating with the partner organization, and the resulting real-world impact. In this work, we share details about the close collaboration with a humanitarian-to-humanitarian (H2H) organization and how to not only deploy the AI model in a resource-constrained environment, but also how to maintain it for continuous performance updates, and share key takeaways for practitioners.', 'abstract_zh': 'AI for Good领域内的出版物倾向于关注能够支持高影响应用的研究和模型开发。然而，很少有AI for Good论文探讨与合作伙伴组织部署和协作的过程，以及由此产生的实际影响。在本工作中，我们分享与人道主义对人道主义（H2H）组织密切合作的细节，不仅如何在资源受限的环境中部署AI模型，还如何对其进行维护以实现持续性能更新，并分享关键经验教训供实践者参考。', 'title_zh': '将AI用于公益事业的操作化：关于AI模型在人道主义工作中的部署与集成亮点'}
{'arxiv_id': 'arXiv:2507.15822', 'title': 'Do AI models help produce verified bug fixes?', 'authors': 'Li Huang, Ilgiz Mustafin, Marco Piccioni, Alessandro Schena, Reto Weber, Bertrand Meyer', 'link': 'https://arxiv.org/abs/2507.15822', 'abstract': 'Among areas of software engineering where AI techniques -- particularly, Large Language Models -- seem poised to yield dramatic improvements, an attractive candidate is Automatic Program Repair (APR), the production of satisfactory corrections to software bugs. Does this expectation materialize in practice? How do we find out, making sure that proposed corrections actually work? If programmers have access to LLMs, how do they actually use them to complement their own skills?\nTo answer these questions, we took advantage of the availability of a program-proving environment, which formally determines the correctness of proposed fixes, to conduct a study of program debugging with two randomly assigned groups of programmers, one with access to LLMs and the other without, both validating their answers through the proof tools. The methodology relied on a division into general research questions (Goals in the Goal-Query-Metric approach), specific elements admitting specific answers (Queries), and measurements supporting these answers (Metrics). While applied so far to a limited sample size, the results are a first step towards delineating a proper role for AI and LLMs in providing guaranteed-correct fixes to program bugs.\nThese results caused surprise as compared to what one might expect from the use of AI for debugging and APR. The contributions also include: a detailed methodology for experiments in the use of LLMs for debugging, which other projects can reuse; a fine-grain analysis of programmer behavior, made possible by the use of full-session recording; a definition of patterns of use of LLMs, with 7 distinct categories; and validated advice for getting the best of LLMs for debugging and Automatic Program Repair.', 'abstract_zh': '在软件工程领域，特别是在自动程序修复（APR）方面，人工智能技术（尤其是大型语言模型）似乎有望带来显著改进。这一预期在实践中是否得以实现？我们如何确保提出的修正确实有效？如果程序员能够访问大型语言模型，他们实际上如何利用这些模型来补充自己的技能？\n\n为了回答这些问题，我们利用了一个正式验证程序修复正确性的环境，通过随机分组的两种程序员群体进行研究，一种群体可以访问大型语言模型，另一种则没有，两者通过证明工具验证其答案。该研究方法基于目标-查询-度量（Goal-Query-Metric）框架，分为一般研究目标、具体问题及其答案和支撑这些答案的测量指标。尽管目前只针对有限的样本规模进行了应用，但这些结果是探索人工智能和大型语言模型在提供程序故障确保正确修复中的适当角色的第一步。\n\n这些结果与预期的使用AI进行调试和自动程序修复有何不同，本研究还包括：一套详细的实验方法，其他项目可以 reuse；通过全会话录制进行的细粒度程序员行为分析；对大型语言模型使用模式的定义，包括7类不同类别；以及验证的建议，以充分利用大型语言模型进行调试和自动程序修复。', 'title_zh': 'AI模型有助于生成经过验证的 bug 修复吗？'}
{'arxiv_id': 'arXiv:2507.15807', 'title': 'True Multimodal In-Context Learning Needs Attention to the Visual Context', 'authors': 'Shuo Chen, Jianzhe Liu, Zhen Han, Yan Xia, Daniel Cremers, Philip Torr, Volker Tresp, Jindong Gu', 'link': 'https://arxiv.org/abs/2507.15807', 'abstract': 'Multimodal Large Language Models (MLLMs), built on powerful language backbones, have enabled Multimodal In-Context Learning (MICL)-adapting to new tasks from a few multimodal demonstrations consisting of images, questions, and answers. Despite showing noticeable improvement on standard vision-language datasets, current MLLMs struggle to leverage visual information in the demonstrations. Specifically, they tend to neglect visual cues and over-rely on textual patterns, leading to mere text imitation rather than genuine multimodal adaptation. This behavior makes MICL still unimodal and largely restricts its practical utility. More importantly, this limitation is often concealed by the improved performance on tasks that do not require understanding the visual context. As a result, how to effectively enhance MICL ability and reliably evaluate the MICL performance remains underexplored. To address these issues, we first introduce Dynamic Attention Reallocation (DARA), an efficient fine-tuning strategy that encourages models to attend to the visual context by rebalancing attention across visual and textual tokens. In addition, we present TrueMICL, an MICL-dedicated dataset with both support and test sets that explicitly requires the integration of multimodal information-particularly visual content-for correct task completion. Extensive experiments demonstrate the effectiveness of our holistic solution, showcasing substantial improvements in the true multimodal in-context learning capabilities. Code and datasets are available at this https URL .', 'abstract_zh': '多模态大型语言模型（MLLMs）构建在强大的语言骨干之上，使得多模态上下文学习（MICL）成为可能——通过少数包含图像、问题和答案的多模态演示来适应新任务。尽管在标准的跨模态数据集上显示出明显的改进，目前的MLLMs在利用演示中的视觉信息方面仍然存在困难。具体来说，它们倾向于忽视视觉线索，过度依赖文本模式，导致 merely 重复文本而非真正意义上的多模态适应。这种行为使得MICL仍然单模态化，并大大限制了其实用价值。更重要的是，这一限制往往被掩盖在任务表现改善中，这些任务不需要理解视觉上下文。因此，如何有效提升MICL能力并可靠地评估其性能仍是一个未被充分探索的问题。为解决这些问题，我们首先引入了动态注意力重新分配（DARA），这是一种有效的微调策略，通过在视觉和文本标记间重新平衡注意力来促使模型关注视觉上下文。此外，我们提出了一个专门为MICL设计的数据集TrueMICL，该数据集包含支持集和测试集，明确要求整合多模态信息——特别是视觉内容，以正确完成任务。大量实验验证了我们整体解决方案的有效性，展示了在真实的多模态上下文学习能力方面的显著提升。代码和数据集可在以下链接获取。', 'title_zh': '真正意义上的多模态上下文学习需要关注视觉上下文'}
{'arxiv_id': 'arXiv:2507.15803', 'title': 'ConformalSAM: Unlocking the Potential of Foundational Segmentation Models in Semi-Supervised Semantic Segmentation with Conformal Prediction', 'authors': 'Danhui Chen, Ziquan Liu, Chuxi Yang, Dan Wang, Yan Yan, Yi Xu, Xiangyang Ji', 'link': 'https://arxiv.org/abs/2507.15803', 'abstract': "Pixel-level vision tasks, such as semantic segmentation, require extensive and high-quality annotated data, which is costly to obtain. Semi-supervised semantic segmentation (SSSS) has emerged as a solution to alleviate the labeling burden by leveraging both labeled and unlabeled data through self-training techniques. Meanwhile, the advent of foundational segmentation models pre-trained on massive data, has shown the potential to generalize across domains effectively. This work explores whether a foundational segmentation model can address label scarcity in the pixel-level vision task as an annotator for unlabeled images. Specifically, we investigate the efficacy of using SEEM, a Segment Anything Model (SAM) variant fine-tuned for textual input, to generate predictive masks for unlabeled data. To address the shortcomings of using SEEM-generated masks as supervision, we propose ConformalSAM, a novel SSSS framework which first calibrates the foundation model using the target domain's labeled data and then filters out unreliable pixel labels of unlabeled data so that only high-confidence labels are used as supervision. By leveraging conformal prediction (CP) to adapt foundation models to target data through uncertainty calibration, ConformalSAM exploits the strong capability of the foundational segmentation model reliably which benefits the early-stage learning, while a subsequent self-reliance training strategy mitigates overfitting to SEEM-generated masks in the later training stage. Our experiment demonstrates that, on three standard benchmarks of SSSS, ConformalSAM achieves superior performance compared to recent SSSS methods and helps boost the performance of those methods as a plug-in.", 'abstract_zh': '基于像素级视觉任务的半监督语义分割：ConformalSAM框架的研究', 'title_zh': 'ConformalSAM: 利用符合性预测解锁基础分割模型在半监督语义分割中的潜力'}
{'arxiv_id': 'arXiv:2507.15788', 'title': 'Small LLMs Do Not Learn a Generalizable Theory of Mind via Reinforcement Learning', 'authors': 'Sneheel Sarangi, Hanan Salam', 'link': 'https://arxiv.org/abs/2507.15788', 'abstract': "Recent advancements in large language models (LLMs) have demonstrated emergent capabilities in complex reasoning, largely spurred by rule-based Reinforcement Learning (RL) techniques applied during the post-training. This has raised the question of whether similar methods can instill more nuanced, human-like social intelligence, such as a Theory of Mind (ToM), in LLMs. This paper investigates whether small-scale LLMs can acquire a robust and generalizable ToM capability through RL with verifiable rewards (RLVR). We conduct a systematic evaluation by training models on various combinations of prominent ToM datasets (HiToM, ExploreToM, FANToM) and testing for generalization on held-out datasets (e.g., OpenToM). Our findings indicate that small LLMs struggle to develop a generic ToM capability. While performance on in-distribution tasks improves, this capability fails to transfer to unseen ToM tasks with different characteristics. Furthermore, we demonstrate that prolonged RL training leads to models ``hacking'' the statistical patterns of the training datasets, resulting in significant performance gains on in-domain data but no change, or degradation of performance on out-of-distribution tasks. This suggests the learned behavior is a form of narrow overfitting rather than the acquisition of a true, abstract ToM capability.", 'abstract_zh': 'Recent advancements in大型语言模型（LLMs）在复杂推理方面展示了新兴能力，主要得益于后训练阶段应用的基于规则的强化学习（RL）技术。这引发了是否可以通过验证奖励的强化学习（RLVR）培养小型LLMs更具人本化的社会智能，如理论思维（ToM）的能力。本文研究了小型LLMs是否可以通过RLVR来获得稳健且可泛化的ToM能力。通过在多种ToM数据集（HiToM、ExploreToM、FANToM）的组合上训练模型，并在保留的数据集（如OpenToM）上测试泛化能力，我们的研究发现小型LLMs难以培养通用的ToM能力。尽管在分布内任务上的表现有所提高，但这种能力无法转移至具有不同特征的未见过的ToM任务。此外，我们展示了长时间的RL训练导致模型“破解”训练数据集的统计模式，从而在域内数据上获得了显著性能提升，但在域外任务上没有变化或性能下降。这表明学习行为是一种狭隘的过拟合，而非真正的抽象ToM能力的获得。', 'title_zh': '小型LLM不通过强化学习学习可泛化的理论共情。'}
{'arxiv_id': 'arXiv:2507.15783', 'title': 'Romance, Relief, and Regret: Teen Narratives of Chatbot Overreliance', 'authors': "Mohammad 'Matt' Namvarpour, Brandon Brofsky, Jessica Medina, Mamtaj Akter, Afsaneh Razi", 'link': 'https://arxiv.org/abs/2507.15783', 'abstract': "As Generative Artificial Intelligence (GenAI) driven chatbots like this http URL become embedded in adolescent life, they raise concerns about emotional dependence and digital overreliance. While studies have investigated the overreliance of adults on these chatbots, they have not investigated teens' interactions with chatbots with customizable personas. We analyzed 318 Reddit posts made by users self-reported as 13-17 years old on the this http URL subreddit to understand patterns of overreliance. We found teens commonly begin using chatbots for emotional support or creative expression, but many develop strong attachments that interfere with offline relationships and daily routines. Their posts revealed recurring signs of psychological distress, cycles of relapse, and difficulty disengaging. Teens reported that their overreliance often ended when they reflect on the harm, return to in-person social settings, or become frustrated by platform restrictions. Based on the implications of our findings, we provide recommendations for future chatbot design so they can promote self-awareness, support real-world engagement, and involve teens in developing safer digital tools.", 'abstract_zh': '随着像这个链接所示的生成型人工智能（GenAI）驱动的聊天机器人嵌入青少年生活，它们引发了关于情感依赖和数字过度依赖的 preocupation。尽管已有研究调查了成年人对这些聊天机器人的过度依赖，但尚未研究青少年与具有可定制人设的聊天机器人的互动。我们分析了318条来自自称13-17岁用户的Reddit帖子（该帖子来自这个链接的子板块），以了解过度依赖的模式。我们发现青少年通常开始使用聊天机器人以寻求情感支持或进行创意表达，但许多人会发展出强烈的情感依附，这会干扰线下关系和日常生活。他们的帖子揭示了反复出现的心理困扰迹象、反复出现的病情和难以脱钩的情况。青少年表示，他们的过度依赖往往在反思危害、返回现实生活社交环境或对平台限制感到沮丧时结束。基于研究结果的意义，我们提供了未来聊天机器人设计的建议，以便促进自我意识、支持现实世界参与，并让青少年参与开发更安全的数字工具。', 'title_zh': '浪漫、慰藉与后悔：青少年对聊天机器人过度依赖的叙述'}
{'arxiv_id': 'arXiv:2507.15775', 'title': 'Learning Null Geodesics for Gravitational Lensing Rendering in General Relativity', 'authors': 'Mingyuan Sun, Zheng Fang, Jiaxu Wang, Kunyi Zhang, Qiang Zhang, Renjing Xu', 'link': 'https://arxiv.org/abs/2507.15775', 'abstract': 'We present GravLensX, an innovative method for rendering black holes with gravitational lensing effects using neural networks. The methodology involves training neural networks to fit the spacetime around black holes and then employing these trained models to generate the path of light rays affected by gravitational lensing. This enables efficient and scalable simulations of black holes with optically thin accretion disks, significantly decreasing the time required for rendering compared to traditional methods. We validate our approach through extensive rendering of multiple black hole systems with superposed Kerr metric, demonstrating its capability to produce accurate visualizations with significantly $15\\times$ reduced computational time. Our findings suggest that neural networks offer a promising alternative for rendering complex astrophysical phenomena, potentially paving a new path to astronomical visualization.', 'abstract_zh': '基于神经网络的引力透镜效应黑洞渲染方法GravLensX', 'title_zh': '广义相对论中基于虚 geodesics 的引力透镜渲染学习'}
{'arxiv_id': 'arXiv:2507.15774', 'title': 'Dynamics is what you need for time-series forecasting!', 'authors': 'Alexis-Raja Brachet, Pierre-Yves Richard, Céline Hudelot', 'link': 'https://arxiv.org/abs/2507.15774', 'abstract': 'While boundaries between data modalities are vanishing, the usual successful deep models are still challenged by simple ones in the time-series forecasting task. Our hypothesis is that this task needs models that are able to learn the data underlying dynamics. We propose to validate it through both systemic and empirical studies. We develop an original $\\texttt{PRO-DYN}$ nomenclature to analyze existing models through the lens of dynamics. Two observations thus emerged: $\\textbf{1}$. under-performing architectures learn dynamics at most partially, $\\textbf{2}$. the location of the dynamics block at the model end is of prime importance. We conduct extensive experiments to confirm our observations on a set of performance-varying models with diverse backbones. Results support the need to incorporate a learnable dynamics block and its use as the final predictor.', 'abstract_zh': '尽管数据模态之间的界限正在消失，但在时间序列预测任务中，传统的成功深度模型仍然难以击败简单的模型。我们的假设是，这一任务需要能够学习数据内在动力学的模型。我们希望通过系统的和经验的研究来验证这一假设。我们开发了一种原创的$\\texttt{PRO-DYN}$命名法，以动力学的视角分析现有模型。由此产生了两个观察结果：$\\textbf{1}$．表现不佳的架构最多只能部分学习动力学，$\\textbf{2}$．动力学模块在模型末尾的位置至关重要。我们进行了广泛的实验，以不同的底层架构和性能变化的模型集来验证我们的观察结果。结果支持将可学习的动力学模块纳入模型，并将其用作最终预测器的需求。', 'title_zh': '动态性是时间序列预测所需的关键！'}
{'arxiv_id': 'arXiv:2507.15773', 'title': 'Supernova: Achieving More with Less in Transformer Architectures', 'authors': 'Andrei-Valentin Tanase, Elena Pelican', 'link': 'https://arxiv.org/abs/2507.15773', 'abstract': 'We present Supernova, a 650M-parameter decoder-only transformer that demonstrates how careful architectural design and tokenization innovation can achieve the performance of larger models while maintaining computational efficiency. Our architecture combines Rotary Positional Embeddings (RoPE), Grouped Query Attention (GQA) with a 3:1 compression ratio, RMSNorm for computational efficiency, and SwiGLU activation functions. A critical innovation is our custom 128,000-vocabulary byte-level BPE tokenizer, which achieves state-of-the-art compression performance. Through detailed analysis, we show that Supernova achieves 90% of the performance of 1B-parameter models while using 53% fewer parameters and requiring only 100B training tokens--an order of magnitude less than competing models. Our findings challenge the prevailing scaling paradigm, demonstrating that architectural efficiency and tokenization quality can compensate for reduced parameter counts.', 'abstract_zh': '我们呈现了 Supernova，一个6500万参数的解码器变压器模型，展示了精心的架构设计和令牌化创新如何在保持计算效率的同时实现与更大模型相当的性能。该架构结合了旋转位置嵌入（RoPE）、分组查询注意（GQA）与3:1的压缩比、RMSNorm以提高计算效率、SwiGLU激活函数。一项关键创新是我们的自定义128000词汇量的字级BPE分词器，实现了最先进的压缩性能。通过详细的分析，我们展示了 Supernova 在使用53%更少参数且仅需1000亿个训练令牌（比竞争模型少一个数量级）的情况下，达到了10亿参数模型90%的性能。我们的研究结果挑战了现有的规模范式，证明了架构效率与分词质量可以弥补参数数量的减少。', 'title_zh': 'Supernova: 在Transformer架构中用更少获取更多'}
{'arxiv_id': 'arXiv:2507.15772', 'title': 'Deep-Learning Investigation of Vibrational Raman Spectra for Plant-Stress Analysis', 'authors': 'Anoop C. Patil, Benny Jian Rong Sng, Yu-Wei Chang, Joana B. Pereira, Chua Nam-Hai, Rajani Sarojam, Gajendra Pratap Singh, In-Cheol Jang, Giovanni Volpe', 'link': 'https://arxiv.org/abs/2507.15772', 'abstract': 'Detecting stress in plants is crucial for both open-farm and controlled-environment agriculture. Biomolecules within plants serve as key stress indicators, offering vital markers for continuous health monitoring and early disease detection. Raman spectroscopy provides a powerful, non-invasive means to quantify these biomolecules through their molecular vibrational signatures. However, traditional Raman analysis relies on customized data-processing workflows that require fluorescence background removal and prior identification of Raman peaks of interest-introducing potential biases and inconsistencies. Here, we introduce DIVA (Deep-learning-based Investigation of Vibrational Raman spectra for plant-stress Analysis), a fully automated workflow based on a variational autoencoder. Unlike conventional approaches, DIVA processes native Raman spectra-including fluorescence backgrounds-without manual preprocessing, identifying and quantifying significant spectral features in an unbiased manner. We applied DIVA to detect a range of plant stresses, including abiotic (shading, high light intensity, high temperature) and biotic stressors (bacterial infections). By integrating deep learning with vibrational spectroscopy, DIVA paves the way for AI-driven plant health assessment, fostering more resilient and sustainable agricultural practices.', 'abstract_zh': '基于深度学习的振动拉曼光谱植物胁迫分析DIVA', 'title_zh': '深度学习在植物压力分析中的振动拉曼光谱研究'}
{'arxiv_id': 'arXiv:2507.15771', 'title': 'Left Leaning Models: AI Assumptions on Economic Policy', 'authors': 'Maxim Chupilkin', 'link': 'https://arxiv.org/abs/2507.15771', 'abstract': "How does AI think about economic policy? While the use of large language models (LLMs) in economics is growing exponentially, their assumptions on economic issues remain a black box. This paper uses a conjoint experiment to tease out the main factors influencing LLMs' evaluation of economic policy. It finds that LLMs are most sensitive to unemployment, inequality, financial stability, and environmental harm and less sensitive to traditional macroeconomic concerns such as economic growth, inflation, and government debt. The results are remarkably consistent across scenarios and across models.", 'abstract_zh': 'AI是如何思考经济政策的？使用大规模语言模型（LLM）在经济学领域的应用 burgeoning 越来越广泛，但它们在经济问题上的假设仍是一个黑箱。本文通过联合实验探讨了影响LLM评估经济政策的主要因素。研究发现，LLM对失业、不平等、金融稳定和环境损害最为敏感，对传统的宏观经济关注点如经济增长、通货膨胀和政府债务则相对不敏感。结果在不同情景和不同模型间表现出惊人的一致性。', 'title_zh': '左倾模型：AI对经济政策的假设'}
{'arxiv_id': 'arXiv:2507.15753', 'title': 'DiffuMeta: Algebraic Language Models for Inverse Design of Metamaterials via Diffusion Transformers', 'authors': 'Li Zheng, Siddhant Kumar, Dennis M. Kochmann', 'link': 'https://arxiv.org/abs/2507.15753', 'abstract': 'Generative machine learning models have revolutionized material discovery by capturing complex structure-property relationships, yet extending these approaches to the inverse design of three-dimensional metamaterials remains limited by computational complexity and underexplored design spaces due to the lack of expressive representations. Here, we present DiffuMeta, a generative framework integrating diffusion transformers with a novel algebraic language representation, encoding 3D geometries as mathematical sentences. This compact, unified parameterization spans diverse topologies while enabling direct application of transformers to structural design. DiffuMeta leverages diffusion models to generate novel shell structures with precisely targeted stress-strain responses under large deformations, accounting for buckling and contact while addressing the inherent one-to-many mapping by producing diverse solutions. Uniquely, our approach enables simultaneous control over multiple mechanical objectives, including linear and nonlinear responses beyond training domains. Experimental validation of fabricated structures further confirms the efficacy of our approach for accelerated design of metamaterials and structures with tailored properties.', 'abstract_zh': '基于扩散变换器的新型代数语言表示的生成模型DiffuMeta在三维 metamaterial 逆设计中的应用', 'title_zh': 'DiffuMeta：通过扩散变压器进行超材料逆设计的代数语言模型'}
{'arxiv_id': 'arXiv:2507.15752', 'title': 'DialogueForge: LLM Simulation of Human-Chatbot Dialogue', 'authors': 'Ruizhe Zhu, Hao Zhu, Yaxuan Li, Syang Zhou, Shijing Cai, Malgorzata Lazuka, Elliott Ash', 'link': 'https://arxiv.org/abs/2507.15752', 'abstract': 'Collecting human-chatbot dialogues typically demands substantial manual effort and is time-consuming, which limits and poses challenges for research on conversational AI. In this work, we propose DialogueForge - a framework for generating AI-simulated conversations in human-chatbot style. To initialize each generated conversation, DialogueForge uses seed prompts extracted from real human-chatbot interactions. We test a variety of LLMs to simulate the human chatbot user, ranging from state-of-the-art proprietary models to small-scale open-source LLMs, and generate multi-turn dialogues tailored to specific tasks. In addition, we explore fine-tuning techniques to enhance the ability of smaller models to produce indistinguishable human-like dialogues. We evaluate the quality of the simulated conversations and compare different models using the UniEval and GTEval evaluation protocols. Our experiments show that large proprietary models (e.g., GPT-4o) generally outperform others in generating more realistic dialogues, while smaller open-source models (e.g., Llama, Mistral) offer promising performance with greater customization. We demonstrate that the performance of smaller models can be significantly improved by employing supervised fine-tuning techniques. Nevertheless, maintaining coherent and natural long-form human-like dialogues remains a common challenge across all models.', 'abstract_zh': '生成具有人类-聊天机器人风格的AI模拟对话框架', 'title_zh': 'DialogueForge: LLM模拟人机对话'}
{'arxiv_id': 'arXiv:2507.15718', 'title': 'Explainable Anomaly Detection for Electric Vehicles Charging Stations', 'authors': 'Matteo Cederle, Andrea Mazzucco, Andrea Demartini, Eugenio Mazza, Eugenia Suriani, Federico Vitti, Gian Antonio Susto', 'link': 'https://arxiv.org/abs/2507.15718', 'abstract': 'Electric vehicles (EV) charging stations are one of the critical infrastructures needed to support the transition to renewable-energy-based mobility, but ensuring their reliability and efficiency requires effective anomaly detection to identify irregularities in charging behavior. However, in such a productive scenario, it is also crucial to determine the underlying cause behind the detected anomalies. To achieve this goal, this study investigates unsupervised anomaly detection techniques for EV charging infrastructure, integrating eXplainable Artificial Intelligence techniques to enhance interpretability and uncover root causes of anomalies.\nUsing real-world sensors and charging session data, this work applies Isolation Forest to detect anomalies and employs the Depth-based Isolation Forest Feature Importance (DIFFI) method to identify the most important features contributing to such anomalies. The efficacy of the proposed approach is evaluated in a real industrial case.', 'abstract_zh': '电动汽车（EV）充电站是支持向基于可再生能源的移动性过渡的关键基础设施，但确保其可靠性和效率需要有效的异常检测来识别充电行为中的不规则性。然而，在这种生产性场景中，确定检测到的异常背后的根本原因同样至关重要。为此，本研究调查了电动汽车充电基础设施的无监督异常检测技术，并结合可解释的人工智能技术以增强可解释性并揭示异常的根本原因。利用实际传感器和充电会话数据，本研究应用隔离森林检测异常，并采用基于深度的隔离森林特征重要性（DIFFI）方法来识别对这些异常贡献最大的特征。所提出方法的有效性在实际工业案例中进行了评估。', 'title_zh': '可解释的电动汽车充电站异常检测'}
{'arxiv_id': 'arXiv:2507.15717', 'title': 'BEnchmarking LLMs for Ophthalmology (BELO) for Ophthalmological Knowledge and Reasoning', 'authors': 'Sahana Srinivasan, Xuguang Ai, Thaddaeus Wai Soon Lo, Aidan Gilson, Minjie Zou, Ke Zou, Hyunjae Kim, Mingjia Yang, Krithi Pushpanathan, Samantha Yew, Wan Ting Loke, Jocelyn Goh, Yibing Chen, Yiming Kong, Emily Yuelei Fu, Michelle Ongyong Hui, Kristen Nwanyanwu, Amisha Dave, Kelvin Zhenghao Li, Chen-Hsin Sun, Mark Chia, Gabriel Dawei Yang, Wendy Meihua Wong, David Ziyou Chen, Dianbo Liu, Maxwell Singer, Fares Antaki, Lucian V Del Priore, Jost Jonas, Ron Adelman, Qingyu Chen, Yih-Chung Tham', 'link': 'https://arxiv.org/abs/2507.15717', 'abstract': "Current benchmarks evaluating large language models (LLMs) in ophthalmology are limited in scope and disproportionately prioritise accuracy. We introduce BELO (BEnchmarking LLMs for Ophthalmology), a standardized and comprehensive evaluation benchmark developed through multiple rounds of expert checking by 13 ophthalmologists. BELO assesses ophthalmology-related clinical accuracy and reasoning quality. Using keyword matching and a fine-tuned PubMedBERT model, we curated ophthalmology-specific multiple-choice-questions (MCQs) from diverse medical datasets (BCSC, MedMCQA, MedQA, BioASQ, and PubMedQA). The dataset underwent multiple rounds of expert checking. Duplicate and substandard questions were systematically removed. Ten ophthalmologists refined the explanations of each MCQ's correct answer. This was further adjudicated by three senior ophthalmologists. To illustrate BELO's utility, we evaluated six LLMs (OpenAI o1, o3-mini, GPT-4o, DeepSeek-R1, Llama-3-8B, and Gemini 1.5 Pro) using accuracy, macro-F1, and five text-generation metrics (ROUGE-L, BERTScore, BARTScore, METEOR, and AlignScore). In a further evaluation involving human experts, two ophthalmologists qualitatively reviewed 50 randomly selected outputs for accuracy, comprehensiveness, and completeness. BELO consists of 900 high-quality, expert-reviewed questions aggregated from five sources: BCSC (260), BioASQ (10), MedMCQA (572), MedQA (40), and PubMedQA (18). A public leaderboard has been established to promote transparent evaluation and reporting. Importantly, the BELO dataset will remain a hold-out, evaluation-only benchmark to ensure fair and reproducible comparisons of future models.", 'abstract_zh': 'BELO：用于眼科的大语言模型标准化综合评估基准', 'title_zh': '眼科领域大型语言模型基准测试（BELO）：眼科知识与推理'}
{'arxiv_id': 'arXiv:2507.15707', 'title': 'Is Large Language Model Performance on Reasoning Tasks Impacted by Different Ways Questions Are Asked?', 'authors': 'Seok Hwan Song, Mohna Chakraborty, Qi Li, Wallapak Tavanapong', 'link': 'https://arxiv.org/abs/2507.15707', 'abstract': 'Large Language Models (LLMs) have been evaluated using diverse question types, e.g., multiple-choice, true/false, and short/long answers. This study answers an unexplored question about the impact of different question types on LLM accuracy on reasoning tasks. We investigate the performance of five LLMs on three different types of questions using quantitative and deductive reasoning tasks. The performance metrics include accuracy in the reasoning steps and choosing the final answer. Key Findings: (1) Significant differences exist in LLM performance across different question types. (2) Reasoning accuracy does not necessarily correlate with the final selection accuracy. (3) The number of options and the choice of words, influence LLM performance.', 'abstract_zh': '大型语言模型（LLMs）在多种问题类型下的评估：不同问题类型对LLM在推理任务中准确性的影响探究', 'title_zh': '不同的提问方式对大型语言模型在推理任务中的性能影响有多大？'}
{'arxiv_id': 'arXiv:2507.15706', 'title': 'Compositional Understanding in Signaling Games', 'authors': 'David Peter Wallis Freeborn', 'link': 'https://arxiv.org/abs/2507.15706', 'abstract': 'Receivers in standard signaling game models struggle with learning compositional information. Even when the signalers send compositional messages, the receivers do not interpret them compositionally. When information from one message component is lost or forgotten, the information from other components is also erased. In this paper I construct signaling game models in which genuine compositional understanding evolves. I present two new models: a minimalist receiver who only learns from the atomic messages of a signal, and a generalist receiver who learns from all of the available information. These models are in many ways simpler than previous alternatives, and allow the receivers to learn from the atomic components of messages.', 'abstract_zh': '标准信号博弈模型中的接收者在学习组合信息方面存在困难。即使信号者发送组合消息，接收者也不会进行组合解释。当一条消息的一个成分的信息丢失或被遗忘时，其他成分的信息也会被抹去。在本文中，我构建了使真正的组合理解得以演化的信号博弈模型。文中提出了两个新模型：一个只从信号的原子消息中学习的简约接收者，以及一个从所有可用信息中学习的一般接收者。这些模型在很多方面比以往的替代模型更为简单，从而使接收者能够从消息的原子成分中学习。', 'title_zh': '信号博弈中的组合理解'}
{'arxiv_id': 'arXiv:2507.15698', 'title': 'CoLD: Counterfactually-Guided Length Debiasing for Process Reward Models', 'authors': 'Congmin Zheng, Jiachen Zhu, Jianghao Lin, Xinyi Dai, Yong Yu, Weinan Zhang, Mengyue Yang', 'link': 'https://arxiv.org/abs/2507.15698', 'abstract': 'Process Reward Models (PRMs) play a central role in evaluating and guiding multi-step reasoning in large language models (LLMs), especially for mathematical problem solving. However, we identify a pervasive length bias in existing PRMs: they tend to assign higher scores to longer reasoning steps, even when the semantic content and logical validity are unchanged. This bias undermines the reliability of reward predictions and leads to overly verbose outputs during inference. To address this issue, we propose CoLD(Counterfactually-Guided Length Debiasing), a unified framework that mitigates length bias through three components: an explicit length-penalty adjustment, a learned bias estimator trained to capture spurious length-related signals, and a joint training strategy that enforces length-invariance in reward predictions. Our approach is grounded in counterfactual reasoning and informed by causal graph analysis. Extensive experiments on MATH500 and GSM-Plus show that CoLD consistently reduces reward-length correlation, improves accuracy in step selection, and encourages more concise, logically valid reasoning. These results demonstrate the effectiveness and practicality of CoLD in improving the fidelity and robustness of PRMs.', 'abstract_zh': '基于反事实引导的长度偏差缓解（CoLD）：改进过程奖励模型中的多步推理', 'title_zh': 'CoLD：基于反事实指导的长度偏差校正用于过程奖励模型'}
{'arxiv_id': 'arXiv:2507.15686', 'title': 'LINR-PCGC: Lossless Implicit Neural Representations for Point Cloud Geometry Compression', 'authors': 'Wenjie Huang, Qi Yang, Shuting Xia, He Huang, Zhu Li, Yiling Xu', 'link': 'https://arxiv.org/abs/2507.15686', 'abstract': 'Existing AI-based point cloud compression methods struggle with dependence on specific training data distributions, which limits their real-world deployment. Implicit Neural Representation (INR) methods solve the above problem by encoding overfitted network parameters to the bitstream, resulting in more distribution-agnostic results. However, due to the limitation of encoding time and decoder size, current INR based methods only consider lossy geometry compression. In this paper, we propose the first INR based lossless point cloud geometry compression method called Lossless Implicit Neural Representations for Point Cloud Geometry Compression (LINR-PCGC). To accelerate encoding speed, we design a group of point clouds level coding framework with an effective network initialization strategy, which can reduce around 60% encoding time. A lightweight coding network based on multiscale SparseConv, consisting of scale context extraction, child node prediction, and model compression modules, is proposed to realize fast inference and compact decoder size. Experimental results show that our method consistently outperforms traditional and AI-based methods: for example, with the convergence time in the MVUB dataset, our method reduces the bitstream by approximately 21.21% compared to G-PCC TMC13v23 and 21.95% compared to SparsePCGC. Our project can be seen on this https URL.', 'abstract_zh': '基于隐式神经表示的无损点云几何压缩方法（LINR-PCGC）', 'title_zh': 'LINR-PCGC：点云几何无损隐式神经表示压缩'}
{'arxiv_id': 'arXiv:2507.15681', 'title': 'Missing value imputation with adversarial random forests -- MissARF', 'authors': 'Pegah Golchian, Jan Kapar, David S. Watson, Marvin N. Wright', 'link': 'https://arxiv.org/abs/2507.15681', 'abstract': 'Handling missing values is a common challenge in biostatistical analyses, typically addressed by imputation methods. We propose a novel, fast, and easy-to-use imputation method called missing value imputation with adversarial random forests (MissARF), based on generative machine learning, that provides both single and multiple imputation. MissARF employs adversarial random forest (ARF) for density estimation and data synthesis. To impute a missing value of an observation, we condition on the non-missing values and sample from the estimated conditional distribution generated by ARF. Our experiments demonstrate that MissARF performs comparably to state-of-the-art single and multiple imputation methods in terms of imputation quality and fast runtime with no additional costs for multiple imputation.', 'abstract_zh': '基于生成机器学习的对抗随机森林缺失值填充方法（MissARF）', 'title_zh': '基于生成对抗森林的缺失值填充——MissARF'}
{'arxiv_id': 'arXiv:2507.15663', 'title': 'SustainDiffusion: Optimising the Social and Environmental Sustainability of Stable Diffusion Models', 'authors': "Giordano d'Aloisio, Tosin Fadahunsi, Jay Choy, Rebecca Moussa, Federica Sarro", 'link': 'https://arxiv.org/abs/2507.15663', 'abstract': "Background: Text-to-image generation models are widely used across numerous domains. Among these models, Stable Diffusion (SD) - an open-source text-to-image generation model - has become the most popular, producing over 12 billion images annually. However, the widespread use of these models raises concerns regarding their social and environmental sustainability.\nAims: To reduce the harm that SD models may have on society and the environment, we introduce SustainDiffusion, a search-based approach designed to enhance the social and environmental sustainability of SD models.\nMethod: SustainDiffusion searches the optimal combination of hyperparameters and prompt structures that can reduce gender and ethnic bias in generated images while also lowering the energy consumption required for image generation. Importantly, SustainDiffusion maintains image quality comparable to that of the original SD model.\nResults: We conduct a comprehensive empirical evaluation of SustainDiffusion, testing it against six different baselines using 56 different prompts. Our results demonstrate that SustainDiffusion can reduce gender bias in SD3 by 68%, ethnic bias by 59%, and energy consumption (calculated as the sum of CPU and GPU energy) by 48%. Additionally, the outcomes produced by SustainDiffusion are consistent across multiple runs and can be generalised to various prompts.\nConclusions: With SustainDiffusion, we demonstrate how enhancing the social and environmental sustainability of text-to-image generation models is possible without fine-tuning or changing the model's architecture.", 'abstract_zh': '背景：文本生成图像模型在众多领域得到广泛应用。在这些模型中，开源文本生成图像模型稳定扩散（SD）已成为最受欢迎的模型，每年生成超过120亿张图像。然而，这些模型的广泛应用引发了对其社会和环境可持续性的担忧。\n目标：为了减少SD模型对社会和环境可能造成的损害，我们提出了SustainDiffusion，一种基于搜索的的方法，旨在增强SD模型的社会和环境可持续性。\n方法：SustainDiffusion搜索出能在降低生成图像中的性别和种族偏见的同时，降低图像生成所需能耗的最佳超参数和提示结构组合。重要的是，SustainDiffusion保持了与原始SD模型相当的图像质量。\n结果：我们对SustainDiffusion进行了全面的实际测试，使用56种不同提示符与六个不同基线进行对比。结果表明，SustainDiffusion可以将SD3中的性别偏见降低68%，种族偏见降低59%，能耗（以CPU和GPU能耗总和计算）降低48%。此外，SustainDiffusion生成的结果在多次运行中保持一致，并且可以适用于多种提示符。\n结论：通过SustainDiffusion，我们展示了在不调整或更改模型架构的情况下增强文本生成图像模型的社会和环境可持续性是可行的。', 'title_zh': 'SustainDiffusion: 优化稳定扩散模型的社交与环境可持续性'}
{'arxiv_id': 'arXiv:2507.15643', 'title': 'Towards Explainable Anomaly Detection in Shared Mobility Systems', 'authors': 'Elnur Isgandarov, Matteo Cederle, Federico Chiariotti, Gian Antonio Susto', 'link': 'https://arxiv.org/abs/2507.15643', 'abstract': 'Shared mobility systems, such as bike-sharing networks, play a crucial role in urban transportation. Identifying anomalies in these systems is essential for optimizing operations, improving service reliability, and enhancing user experience. This paper presents an interpretable anomaly detection framework that integrates multi-source data, including bike-sharing trip records, weather conditions, and public transit availability. The Isolation Forest algorithm is employed for unsupervised anomaly detection, along with the Depth-based Isolation Forest Feature Importance (DIFFI) algorithm providing interpretability. Results show that station-level analysis offers a robust understanding of anomalies, highlighting the influence of external factors such as adverse weather and limited transit availability. Our findings contribute to improving decision-making in shared mobility operations.', 'abstract_zh': '共享 mobility 系统中的异常检测：多源数据集成的可解释框架', 'title_zh': '在共享移动系统中可解释的异常检测owards Explainable Anomaly Detection in Shared Mobility Systems'}
{'arxiv_id': 'arXiv:2507.15641', 'title': 'Leveraging Context for Multimodal Fallacy Classification in Political Debates', 'authors': 'Alessio Pittiglio', 'link': 'https://arxiv.org/abs/2507.15641', 'abstract': 'In this paper, we present our submission to the MM-ArgFallacy2025 shared task, which aims to advance research in multimodal argument mining, focusing on logical fallacies in political debates. Our approach uses pretrained Transformer-based models and proposes several ways to leverage context. In the fallacy classification subtask, our models achieved macro F1-scores of 0.4444 (text), 0.3559 (audio), and 0.4403 (multimodal). Our multimodal model showed performance comparable to the text-only model, suggesting potential for improvements.', 'abstract_zh': '本文介绍了我们参加MM-ArgFallacy2025共享任务的提交内容，该任务致力于推进多模态论证研究，重点关注政论辩论中的逻辑谬误。我们的方法使用了预训练的Transformer模型，并提出了几种利用上下文的方法。在谬误分类子任务中，我们的模型分别获得了宏F1分数：文本0.4444，音频0.3559，多模态0.4403。我们的多模态模型的性能与仅文本模型相当，这表明有改进的潜力。', 'title_zh': '利用语境进行政治辩论中的多模态谬误分类'}
{'arxiv_id': 'arXiv:2507.15640', 'title': 'Data Mixing Agent: Learning to Re-weight Domains for Continual Pre-training', 'authors': 'Kailai Yang, Xiao Liu, Lei Ji, Hao Li, Yeyun Gong, Peng Cheng, Mao Yang', 'link': 'https://arxiv.org/abs/2507.15640', 'abstract': "Continual pre-training on small-scale task-specific data is an effective method for improving large language models in new target fields, yet it risks catastrophic forgetting of their original capabilities. A common solution is to re-weight training data mixtures from source and target fields on a domain space to achieve balanced performance. Previous domain reweighting strategies rely on manual designation with certain heuristics based on human intuition or empirical results. In this work, we prove that more general heuristics can be parameterized by proposing Data Mixing Agent, the first model-based, end-to-end framework that learns to re-weight domains. The agent learns generalizable heuristics through reinforcement learning on large quantities of data mixing trajectories with corresponding feedback from an evaluation environment. Experiments in continual pre-training on math reasoning show that Data Mixing Agent outperforms strong baselines in achieving balanced performance across source and target field benchmarks. Furthermore, it generalizes well across unseen source fields, target models, and domain spaces without retraining. Direct application to the code generation field also indicates its adaptability across target domains. Further analysis showcases the agents' well-aligned heuristics with human intuitions and their efficiency in achieving superior model performance with less source-field data.", 'abstract_zh': '基于数据混合代理的小规模领域特定数据连续预训练方法通过 reinforcement learning 学习领域重权重以实现平衡性能', 'title_zh': '数据混合代理：学习重新权重领域以进行持续预训练'}
{'arxiv_id': 'arXiv:2507.15636', 'title': 'Uncovering Critical Features for Deepfake Detection through the Lottery Ticket Hypothesis', 'authors': 'Lisan Al Amin, Md. Ismail Hossain, Thanh Thi Nguyen, Tasnim Jahan, Mahbubul Islam, Faisal Quader', 'link': 'https://arxiv.org/abs/2507.15636', 'abstract': 'Recent advances in deepfake technology have created increasingly convincing synthetic media that poses significant challenges to information integrity and social trust. While current detection methods show promise, their underlying mechanisms remain poorly understood, and the large sizes of their models make them challenging to deploy in resource-limited environments. This study investigates the application of the Lottery Ticket Hypothesis (LTH) to deepfake detection, aiming to identify the key features crucial for recognizing deepfakes. We examine how neural networks can be efficiently pruned while maintaining high detection accuracy. Through extensive experiments with MesoNet, CNN-5, and ResNet-18 architectures on the OpenForensic and FaceForensics++ datasets, we find that deepfake detection networks contain winning tickets, i.e., subnetworks, that preserve performance even at substantial sparsity levels. Our results indicate that MesoNet retains 56.2% accuracy at 80% sparsity on the OpenForensic dataset, with only 3,000 parameters, which is about 90% of its baseline accuracy (62.6%). The results also show that our proposed LTH-based iterative magnitude pruning approach consistently outperforms one-shot pruning methods. Using Grad-CAM visualization, we analyze how pruned networks maintain their focus on critical facial regions for deepfake detection. Additionally, we demonstrate the transferability of winning tickets across datasets, suggesting potential for efficient, deployable deepfake detection systems.', 'abstract_zh': '近年来，深度造假技术的进步创造了越来越逼真的合成媒体，对信息完整性和社会信任构成了重大挑战。尽管现有的检测方法显示出希望，但其 underlying机制仍不完全理解，且模型规模庞大，使得它们在资源受限环境中难以部署。本研究探索了在深度造假检测中应用彩票票假说（LTH）的应用，旨在识别出识别深度造假的关键特征。我们研究了在保持高检测准确性的前提下，如何高效地对神经网络进行剪枝。通过在OpenForensic和FaceForensics++数据集上对MesoNet、CNN-5和ResNet-18架构进行广泛实验，我们发现深度造假检测网络包含能在高稀疏度下保持性能的“赢票”，即子网络。我们的结果表明，MesoNet在OpenForensic数据集上的稀疏度达到80%时，仍能保持56.2%的准确率，仅需3,000个参数，大约为基线准确率（62.6%）的90%。此外，我们的基于LTH的逐次量纲剪枝方法在所有网络剪枝方法中表现更优。通过Grad-CAM可视化，我们分析了剪枝网络如何保持对深度造假检测至关重要的面部区域的关注。此外，我们展示了“赢票”的跨数据集可迁移性，这表明有潜力开发高效且可部署的深度造假检测系统。', 'title_zh': '通过彩票票假设发现深度假帧检测的关键特征'}
{'arxiv_id': 'arXiv:2507.15617', 'title': "Why can't Epidemiology be automated (yet)?", 'authors': 'David Bann, Ed Lowther, Liam Wright, Yevgeniya Kovalchuk', 'link': 'https://arxiv.org/abs/2507.15617', 'abstract': 'Recent advances in artificial intelligence (AI) - particularly generative AI - present new opportunities to accelerate, or even automate, epidemiological research. Unlike disciplines based on physical experimentation, a sizable fraction of Epidemiology relies on secondary data analysis and thus is well-suited for such augmentation. Yet, it remains unclear which specific tasks can benefit from AI interventions or where roadblocks exist. Awareness of current AI capabilities is also mixed. Here, we map the landscape of epidemiological tasks using existing datasets - from literature review to data access, analysis, writing up, and dissemination - and identify where existing AI tools offer efficiency gains. While AI can increase productivity in some areas such as coding and administrative tasks, its utility is constrained by limitations of existing AI models (e.g. hallucinations in literature reviews) and human systems (e.g. barriers to accessing datasets). Through examples of AI-generated epidemiological outputs, including fully AI-generated papers, we demonstrate that recently developed agentic systems can now design and execute epidemiological analysis, albeit to varied quality (see this https URL). Epidemiologists have new opportunities to empirically test and benchmark AI systems; realising the potential of AI will require two-way engagement between epidemiologists and engineers.', 'abstract_zh': '近期人工智能的发展——特别是生成式人工智能——为加速乃至自动化流行病学研究提供了新机遇。', 'title_zh': '为什么流行病学尚不能（也未能）自动化（暂且如此）'}
{'arxiv_id': 'arXiv:2507.15614', 'title': 'Accelerating HEC-RAS: A Recurrent Neural Operator for Rapid River Forecasting', 'authors': 'Edward Holmberg, Pujan Pokhrel, Maximilian Zoch, Elias Ioup, Ken Pathak, Steven Sloan, Kendall Niles, Jay Ratcliff, Maik Flanagin, Christian Guetl, Julian Simeonov, Mahdi Abdelguerfi', 'link': 'https://arxiv.org/abs/2507.15614', 'abstract': 'Physics-based solvers like HEC-RAS provide high-fidelity river forecasts but are too computationally intensive for on-the-fly decision-making during flood events. The central challenge is to accelerate these simulations without sacrificing accuracy. This paper introduces a deep learning surrogate that treats HEC-RAS not as a solver but as a data-generation engine. We propose a hybrid, auto-regressive architecture that combines a Gated Recurrent Unit (GRU) to capture short-term temporal dynamics with a Geometry-Aware Fourier Neural Operator (Geo-FNO) to model long-range spatial dependencies along a river reach. The model learns underlying physics implicitly from a minimal eight-channel feature vector encoding dynamic state, static geometry, and boundary forcings extracted directly from native HEC-RAS files. Trained on 67 reaches of the Mississippi River Basin, the surrogate was evaluated on a year-long, unseen hold-out simulation. Results show the model achieves a strong predictive accuracy, with a median absolute stage error of 0.31 feet. Critically, for a full 67-reach ensemble forecast, our surrogate reduces the required wall-clock time from 139 minutes to 40 minutes, a speedup of nearly 3.5 times over the traditional solver. The success of this data-driven approach demonstrates that robust feature engineering can produce a viable, high-speed replacement for conventional hydraulic models, improving the computational feasibility of large-scale ensemble flood forecasting.', 'abstract_zh': '基于物理的替代方案：一种深度学习加速器在不牺牲准确性的情况下，将HEC-RAS用于洪水事件中的实时决策预测', 'title_zh': '加速HEC-RAS：一种循环神经运算器快速河流预报'}
{'arxiv_id': 'arXiv:2507.15613', 'title': 'Multi-Stage Prompt Inference Attacks on Enterprise LLM Systems', 'authors': 'Andrii Balashov, Olena Ponomarova, Xiaohua Zhai', 'link': 'https://arxiv.org/abs/2507.15613', 'abstract': 'Large Language Models (LLMs) deployed in enterprise settings (e.g., as Microsoft 365 Copilot) face novel security challenges. One critical threat is prompt inference attacks: adversaries chain together seemingly benign prompts to gradually extract confidential data. In this paper, we present a comprehensive study of multi-stage prompt inference attacks in an enterprise LLM context. We simulate realistic attack scenarios where an attacker uses mild-mannered queries and indirect prompt injections to exploit an LLM integrated with private corporate data. We develop a formal threat model for these multi-turn inference attacks and analyze them using probability theory, optimization frameworks, and information-theoretic leakage bounds. The attacks are shown to reliably exfiltrate sensitive information from the LLM\'s context (e.g., internal SharePoint documents or emails), even when standard safety measures are in place.\nWe propose and evaluate defenses to counter such attacks, including statistical anomaly detection, fine-grained access control, prompt sanitization techniques, and architectural modifications to LLM deployment. Each defense is supported by mathematical analysis or experimental simulation. For example, we derive bounds on information leakage under differential privacy-based training and demonstrate an anomaly detection method that flags multi-turn attacks with high AUC. We also introduce an approach called "spotlighting" that uses input transformations to isolate untrusted prompt content, reducing attack success by an order of magnitude. Finally, we provide a formal proof of concept and empirical validation for a combined defense-in-depth strategy. Our work highlights that securing LLMs in enterprise settings requires moving beyond single-turn prompt filtering toward a holistic, multi-stage perspective on both attacks and defenses.', 'abstract_zh': '大型语言模型（LLMs）在企业环境中的新型安全挑战：多阶段提示推理攻击研究', 'title_zh': '面向企业的LLM系统多阶段提示推理攻击'}
{'arxiv_id': 'arXiv:2507.15587', 'title': 'Red-Team Multi-Agent Reinforcement Learning for Emergency Braking Scenario', 'authors': 'Yinsong Chen, Kaifeng Wang, Xiaoqiang Meng, Xueyuan Li, Zirui Li, Xin Gao', 'link': 'https://arxiv.org/abs/2507.15587', 'abstract': 'Current research on decision-making in safety-critical scenarios often relies on inefficient data-driven scenario generation or specific modeling approaches, which fail to capture corner cases in real-world contexts. To address this issue, we propose a Red-Team Multi-Agent Reinforcement Learning framework, where background vehicles with interference capabilities are treated as red-team agents. Through active interference and exploration, red-team vehicles can uncover corner cases outside the data distribution. The framework uses a Constraint Graph Representation Markov Decision Process, ensuring that red-team vehicles comply with safety rules while continuously disrupting the autonomous vehicles (AVs). A policy threat zone model is constructed to quantify the threat posed by red-team vehicles to AVs, inducing more extreme actions to increase the danger level of the scenario. Experimental results show that the proposed framework significantly impacts AVs decision-making safety and generates various corner cases. This method also offers a novel direction for research in safety-critical scenarios.', 'abstract_zh': '当前针对安全关键场景的决策研究 often 依赖于低效的数据驱动场景生成或特定建模方法，无法捕获现实世界中的边缘案例。为了解决这一问题，我们提出了一种红队多智能体强化学习框架，其中具备干扰能力的背景车辆被视为红队代理。通过主动干扰和探索，红队车辆可以发现数据分布之外的边缘案例。该框架采用约束图表示马尔可夫决策过程，确保红队车辆遵守安全规则的同时持续干扰自动驾驶汽车（AV）。构建了一种策略威胁区域模型，以量化红队车辆对AV的威胁程度，诱导更极端的行动以提高情景的危险级别。实验结果表明，所提出框架显著影响了AV的决策安全性并生成了多种边缘案例。该方法还为安全关键场景的研究提供了新的方向。', 'title_zh': '红队多Agent强化学习在紧急制动场景中的应用'}
{'arxiv_id': 'arXiv:2507.15585', 'title': 'Unequal Voices: How LLMs Construct Constrained Queer Narratives', 'authors': 'Atreya Ghosal, Ashim Gupta, Vivek Srikumar', 'link': 'https://arxiv.org/abs/2507.15585', 'abstract': 'One way social groups are marginalized in discourse is that the narratives told about them often default to a narrow, stereotyped range of topics. In contrast, default groups are allowed the full complexity of human existence. We describe the constrained representations of queer people in LLM generations in terms of harmful representations, narrow representations, and discursive othering and formulate hypotheses to test for these phenomena. Our results show that LLMs are significantly limited in their portrayals of queer personas.', 'abstract_zh': '一种社会群体在话语中被边缘化的方式是，关于他们的叙事往往局限于狭隘的刻板话题范围。相比之下，默认群体则可以获得人类存在的全部复杂性。我们用有害的再现、狭隘的再现和话语异化来描述大规模语言模型生成中同性恋者受限的表征，并提出假设来测试这些现象。我们的结果显示，大规模语言模型在描绘同性恋者方面显著受限。', 'title_zh': 'unequal 话语权：大规模语言模型构建的受限同性恋叙事'}
{'arxiv_id': 'arXiv:2507.15577', 'title': 'GeMix: Conditional GAN-Based Mixup for Improved Medical Image Augmentation', 'authors': 'Hugo Carlesso, Maria Eliza Patulea, Moncef Garouani, Radu Tudor Ionescu, Josiane Mothe', 'link': 'https://arxiv.org/abs/2507.15577', 'abstract': 'Mixup has become a popular augmentation strategy for image classification, yet its naive pixel-wise interpolation often produces unrealistic images that can hinder learning, particularly in high-stakes medical applications. We propose GeMix, a two-stage framework that replaces heuristic blending with a learned, label-aware interpolation powered by class-conditional GANs. First, a StyleGAN2-ADA generator is trained on the target dataset. During augmentation, we sample two label vectors from Dirichlet priors biased toward different classes and blend them via a Beta-distributed coefficient. Then, we condition the generator on this soft label to synthesize visually coherent images that lie along a continuous class manifold. We benchmark GeMix on the large-scale COVIDx-CT-3 dataset using three backbones (ResNet-50, ResNet-101, EfficientNet-B0). When combined with real data, our method increases macro-F1 over traditional mixup for all backbones, reducing the false negative rate for COVID-19 detection. GeMix is thus a drop-in replacement for pixel-space mixup, delivering stronger regularization and greater semantic fidelity, without disrupting existing training pipelines. We publicly release our code at this https URL to foster reproducibility and further research.', 'abstract_zh': 'GeMix: 一种基于类条件GAN的学习驱动插值框架用于图像分类的增强策略', 'title_zh': 'GeMix: 基于条件GAN的Mixup方法以改善医学图像增强'}
{'arxiv_id': 'arXiv:2507.15574', 'title': 'On the Role of AI in Managing Satellite Constellations: Insights from the ConstellAI Project', 'authors': 'Gregory F. Stock, Juan A. Fraire, Holger Hermanns, Jędrzej Mosiężny, Yusra Al-Khazraji, Julio Ramírez Molina, Evridiki V. Ntagiou', 'link': 'https://arxiv.org/abs/2507.15574', 'abstract': 'The rapid expansion of satellite constellations in near-Earth orbits presents significant challenges in satellite network management, requiring innovative approaches for efficient, scalable, and resilient operations. This paper explores the role of Artificial Intelligence (AI) in optimizing the operation of satellite mega-constellations, drawing from the ConstellAI project funded by the European Space Agency (ESA). A consortium comprising GMV GmbH, Saarland University, and Thales Alenia Space collaborates to develop AI-driven algorithms and demonstrates their effectiveness over traditional methods for two crucial operational challenges: data routing and resource allocation. In the routing use case, Reinforcement Learning (RL) is used to improve the end-to-end latency by learning from historical queuing latency, outperforming classical shortest path algorithms. For resource allocation, RL optimizes the scheduling of tasks across constellations, focussing on efficiently using limited resources such as battery and memory. Both use cases were tested for multiple satellite constellation configurations and operational scenarios, resembling the real-life spacecraft operations of communications and Earth observation satellites. This research demonstrates that RL not only competes with classical approaches but also offers enhanced flexibility, scalability, and generalizability in decision-making processes, which is crucial for the autonomous and intelligent management of satellite fleets. The findings of this activity suggest that AI can fundamentally alter the landscape of satellite constellation management by providing more adaptive, robust, and cost-effective solutions.', 'abstract_zh': '近地轨道卫星星座的迅速扩展给卫星网络管理带来了重大挑战，需要创新的方法实现高效、可扩展和鲁棒的操作。本文探讨了人工智能（AI）在优化卫星巨星座运行中的作用，以 ESA 资助的 ConstellAI 项目为基础。由 GMV GmbH、Saarland University 和 Thales Alenia Space 组成的联盟开发了 AI 驱动的算法，并在数据路由和资源分配这两个关键操作挑战中，展示了这些算法比传统方法更有效。在路由用例中，使用强化学习（RL）通过学习历史排队延迟来提高端到端延迟，优于经典的最短路径算法。在资源分配用例中，使用 RL 优化了跨星座的任务调度，特别是在高效利用有限的电池和内存资源方面。这两种用例均在多种卫星星座配置和操作场景中进行了测试，模拟了通信和地球观测卫星的实际航天器操作。这项研究证明，RL 不仅可以与经典方法竞争，还可以在决策过程中提供更高的灵活性、可扩展性和通用性，这对于实现卫星舰队的自主和智能管理至关重要。该活动的研究结果表明，AI 有可能通过提供更适应性、更稳健和成本效益更高的解决方案，从根本上改变卫星星座管理的格局。', 'title_zh': 'AI在管理卫星星座中的作用：ConstellAI项目见解'}
{'arxiv_id': 'arXiv:2507.15550', 'title': 'PhysGym: Benchmarking LLMs in Interactive Physics Discovery with Controlled Priors', 'authors': 'Yimeng Chen, Piotr Piȩkos, Mateusz Ostaszewski, Firas Laakom, Jürgen Schmidhuber', 'link': 'https://arxiv.org/abs/2507.15550', 'abstract': "Evaluating the scientific discovery capabilities of large language model based agents, particularly how they cope with varying environmental complexity and utilize prior knowledge, requires specialized benchmarks currently lacking in the landscape. To address this gap, we introduce PhysGym, a novel benchmark suite and simulation platform for rigorously assessing LLM-based scientific reasoning in interactive physics environments. PhysGym's primary contribution lies in its sophisticated control over the level of prior knowledge provided to the agent. This allows researchers to dissect agent performance along axes including the complexity of the problem and the prior knowledge levels. The benchmark comprises a suite of interactive simulations, where agents must actively probe environments, gather data sequentially under constraints and formulate hypotheses about underlying physical laws. PhysGym provides standardized evaluation protocols and metrics for assessing hypothesis accuracy and model fidelity. We demonstrate the benchmark's utility by presenting results from baseline LLMs, showcasing its ability to differentiate capabilities based on varying priors and task complexity.", 'abstract_zh': '基于大型语言模型的智能体的科学发现能力评价，特别是它们应对不同环境复杂性和利用先验知识的能力，当前缺乏专门的基准进行评估。为填补这一空白，我们引入了PhysGym，一个用于严格评估基于大型语言模型的科学推理能力的新颖基准套件和仿真平台，特别是在交互物理环境中。PhysGym的主要贡献在于其对提供给智能体的先验知识水平的精细控制。这使研究人员能够按问题复杂性和先验知识水平等维度剖析智能体的性能。该基准包含一系列交互式仿真，要求智能体主动探索环境，在约束条件下顺序收集数据并提出关于物理定律的假设。PhysGym提供标准化的评估协议和指标来评价假设的准确性以及模型的真实性。我们通过呈现基线大型语言模型的结果，展示了该基准在根据不同先验和任务复杂性区分能力方面的实用性。', 'title_zh': 'PhysGym: 在可控先验条件下评估大语言模型在交互式物理发现中的性能'}
{'arxiv_id': 'arXiv:2507.15524', 'title': 'RARE-UNet: Resolution-Aligned Routing Entry for Adaptive Medical Image Segmentation', 'authors': 'Simon Winther Albertsen, Hjalte Svaneborg Bjørnstrup, Mostafa Mehdipour Ghazi', 'link': 'https://arxiv.org/abs/2507.15524', 'abstract': 'Accurate segmentation is crucial for clinical applications, but existing models often assume fixed, high-resolution inputs and degrade significantly when faced with lower-resolution data in real-world scenarios. To address this limitation, we propose RARE-UNet, a resolution-aware multi-scale segmentation architecture that dynamically adapts its inference path to the spatial resolution of the input. Central to our design are multi-scale blocks integrated at multiple encoder depths, a resolution-aware routing mechanism, and consistency-driven training that aligns multi-resolution features with full-resolution representations. We evaluate RARE-UNet on two benchmark brain imaging tasks for hippocampus and tumor segmentation. Compared to standard UNet, its multi-resolution augmented variant, and nnUNet, our model achieves the highest average Dice scores of 0.84 and 0.65 across resolution, while maintaining consistent performance and significantly reduced inference time at lower resolutions. These results highlight the effectiveness and scalability of our architecture in achieving resolution-robust segmentation. The codes are available at: this https URL.', 'abstract_zh': '分辨率感知多尺度分割架构RARE-UNet及其在临床应用中的优势', 'title_zh': 'RARE-UNet: 解析度对齐路由入口用于自适应医学图像分割'}
{'arxiv_id': 'arXiv:2507.15507', 'title': 'Off-Policy Corrected Reward Modeling for Reinforcement Learning from Human Feedback', 'authors': 'Johannes Ackermann, Takashi Ishida, Masashi Sugiyama', 'link': 'https://arxiv.org/abs/2507.15507', 'abstract': 'Reinforcement Learning from Human Feedback (RLHF) allows us to train models, such as language models (LMs), to follow complex human preferences. In RLHF for LMs, we first train an LM using supervised fine-tuning, sample pairs of responses, obtain human feedback, and use the resulting data to train a reward model (RM). RL methods are then used to train the LM to maximize the reward given by the RM. As training progresses, the responses generated by the LM no longer resemble the responses seen by the RM during training, leading to the RM becoming inaccurate. The score given by the RM keeps increasing, but the learned behavior no longer matches the human preferences. This issue is known as overoptimization. We investigate overoptimization from the point of view of distribution shift and show that the shift results in an inconsistent estimate of the RM parameters, leading to an inconsistent estimate of the policy gradient. We propose Off-Policy Corrected Reward Modeling (OCRM), which iteratively off-policy corrects the RM using importance weighting, without requiring new labels or samples. This results in a more accurate RM, which empirically leads to an improved final policy. We validate our approach in experiments with summarization and chatbot datasets and show that it performs significantly better than standard RLHF methods and baselines. Our implementation is available at this https URL', 'abstract_zh': '基于人类反馈的强化学习（RLHF）使我们能够训练模型，如语言模型（LMs），使其遵循复杂的人类偏好。在LM的RLHF中，我们首先使用监督微调训练一个LM，采样响应对，获取人类反馈，并使用所得数据训练一个奖励模型（RM）。然后使用强化学习方法训练LM，使其最大化RM给出的奖励。随着训练的进行，LM生成的响应不再类似于RM在训练期间看到的响应，导致RM变得不准确。RM给出的分数持续增加，但学习到的行为不再符合人类偏好。这一问题称为过度优化。我们从分布转移的角度探讨了过度优化问题，并表明转移导致了RM参数的一致性估计不足，进而导致了策略梯度的一致性估计不足。我们提出了基于离策重要性加权修正的奖励建模（OCRM），它可以迭代地使用重要性加权修正RM，无需新标签或样本。这导致了更准确的RM，从实验结果来看，这提高了最终策略的性能。我们在摘要和聊天机器人数据集上的实验验证了我们的方法，并显示它在标准RLHF方法和基线方法中表现显著更好。我们的实现可在以下链接获得：this https URL。', 'title_zh': '基于人类反馈的离策纠正奖励建模'}
{'arxiv_id': 'arXiv:2507.15501', 'title': 'ASPERA: A Simulated Environment to Evaluate Planning for Complex Action Execution', 'authors': 'Alexandru Coca, Mark Gaynor, Zhenxing Zhang, Jianpeng Cheng, Bo-Hsiang Tseng, Pete Boothroyd, Héctor Martinez Alonso, Diarmuid Ó Séaghdha, Anders Johannsen', 'link': 'https://arxiv.org/abs/2507.15501', 'abstract': 'This work evaluates the potential of large language models (LLMs) to power digital assistants capable of complex action execution. These assistants rely on pre-trained programming knowledge to execute multi-step goals by composing objects and functions defined in assistant libraries into action execution programs. To achieve this, we develop ASPERA, a framework comprising an assistant library simulation and a human-assisted LLM data generation engine. Our engine allows developers to guide LLM generation of high-quality tasks consisting of complex user queries, simulation state and corresponding validation programs, tackling data availability and evaluation robustness challenges. Alongside the framework we release Asper-Bench, an evaluation dataset of 250 challenging tasks generated using ASPERA, which we use to show that program generation grounded in custom assistant libraries is a significant challenge to LLMs compared to dependency-free code generation.', 'abstract_zh': '本研究评估了大型语言模型（LLMs）在驱动能够执行复杂操作的数字助手方面的潜力。这些助手依赖预训练的编程知识，通过将助理库中定义的对象和函数组合成执行程序，来实现多步骤目标的执行。为实现这一目标，我们开发了ASPERA框架，该框架包括助理库模拟和人类辅助的LLM数据生成引擎。我们的引擎使开发者能够指导LLM生成高质量的任务，包括复杂的用户查询、模拟状态和相应的验证程序，以应对数据可用性和评估稳健性挑战。此外，我们发布了由ASPERA生成的Asper-Bench评估数据集，包含250个具有挑战性的任务，用以证明基于定制助手库的程序生成对LLMs构成了比无依赖代码生成更大的挑战。', 'title_zh': 'ASPERA: 一个评估复杂动作执行规划的模拟环境'}
{'arxiv_id': 'arXiv:2507.15493', 'title': 'GR-3 Technical Report', 'authors': 'Chilam Cheang, Sijin Chen, Zhongren Cui, Yingdong Hu, Liqun Huang, Tao Kong, Hang Li, Yifeng Li, Yuxiao Liu, Xiao Ma, Hao Niu, Wenxuan Ou, Wanli Peng, Zeyu Ren, Haixin Shi, Jiawen Tian, Hongtao Wu, Xin Xiao, Yuyang Xiao, Jiafeng Xu, Yichu Yang', 'link': 'https://arxiv.org/abs/2507.15493', 'abstract': 'We report our recent progress towards building generalist robot policies, the development of GR-3. GR-3 is a large-scale vision-language-action (VLA) model. It showcases exceptional capabilities in generalizing to novel objects, environments, and instructions involving abstract concepts. Furthermore, it can be efficiently fine-tuned with minimal human trajectory data, enabling rapid and cost-effective adaptation to new settings. GR-3 also excels in handling long-horizon and dexterous tasks, including those requiring bi-manual manipulation and mobile movement, showcasing robust and reliable performance. These capabilities are achieved through a multi-faceted training recipe that includes co-training with web-scale vision-language data, efficient fine-tuning from human trajectory data collected via VR devices, and effective imitation learning with robot trajectory data. In addition, we introduce ByteMini, a versatile bi-manual mobile robot designed with exceptional flexibility and reliability, capable of accomplishing a wide range of tasks when integrated with GR-3. Through extensive real-world experiments, we show GR-3 surpasses the state-of-the-art baseline method, $\\pi_0$, on a wide variety of challenging tasks. We hope GR-3 can serve as a step towards building generalist robots capable of assisting humans in daily life.', 'abstract_zh': '我们报道了在构建通用机器人策略方面的最新进展，以及GR-3的发展。GR-3是一个大规模的视觉-语言-动作（VLA）模型。它展示了在处理新对象、新环境和涉及抽象概念的指令时的强大泛化能力。此外，它可以通过最少的人类轨迹数据高效微调，从而实现快速且低成本的新环境适应。GR-3在处理长时_horizon和灵巧的任务方面表现出色，包括需要双手操作和移动的任务，展示了稳健且可靠的性能。这些能力是通过包括与大规模网页视觉-语言数据协同训练、通过VR设备收集的人类轨迹数据高效微调以及基于机器人轨迹数据的有效模仿学习在内的多面训练配方实现的。此外，我们引入了ByteMini，这是一种多功能的双手移动机器人，设计具有出色的灵活性和可靠性，与GR-3集成后能够完成多种任务。通过广泛的实地实验，我们展示了GR-3在多种具有挑战性的任务中超越了最新的基准方法$\\pi_0$。我们希望GR-3能够成为构建能够帮助人类日常生活的通用机器人的一个步骤。', 'title_zh': 'GR-3 技术报告'}
{'arxiv_id': 'arXiv:2507.15478', 'title': 'The Constitutional Controller: Doubt-Calibrated Steering of Compliant Agents', 'authors': 'Simon Kohaut, Felix Divo, Navid Hamid, Benedict Flade, Julian Eggert, Devendra Singh Dhami, Kristian Kersting', 'link': 'https://arxiv.org/abs/2507.15478', 'abstract': "Ensuring reliable and rule-compliant behavior of autonomous agents in uncertain environments remains a fundamental challenge in modern robotics. Our work shows how neuro-symbolic systems, which integrate probabilistic, symbolic white-box reasoning models with deep learning methods, offer a powerful solution to this challenge. This enables the simultaneous consideration of explicit rules and neural models trained on noisy data, combining the strength of structured reasoning with flexible representations. To this end, we introduce the Constitutional Controller (CoCo), a novel framework designed to enhance the safety and reliability of agents by reasoning over deep probabilistic logic programs representing constraints such as those found in shared traffic spaces. Furthermore, we propose the concept of self-doubt, implemented as a probability density conditioned on doubt features such as travel velocity, employed sensors, or health factors. In a real-world aerial mobility study, we demonstrate CoCo's advantages for intelligent autonomous systems to learn appropriate doubts and navigate complex and uncertain environments safely and compliantly.", 'abstract_zh': '确保自主代理在不确定环境中表现出可靠的且合规的行为仍然是现代机器人技术中的一个基础挑战。我们的工作展示了神经符号系统如何通过结合概率性和符号性的白盒推理模型与深度学习方法，提供解决这一挑战的有力方案。这使得同时考虑明确规则和基于嘈杂数据训练的神经模型成为可能，结合了结构化推理的强度与灵活表示的优势。为此，我们引入了宪法控制器（CoCo），这是一种新的框架，旨在通过推理深概率逻辑程序来增强代理的安全性和可靠性，这些程序代表了诸如共享交通空间中的约束。此外，我们提出了自我怀疑的概念，将其作为基于怀疑特征（如旅行速度、传感器状态或健康因素）的概率密度实现。在一项现实世界的城市空中移动研究中，我们展示了CoCo在智能自主系统中学习适当怀疑并安全、合规地导航复杂和不确定环境方面的优势。', 'title_zh': '宪法控制器：基于怀疑校准的合规代理引导'}
{'arxiv_id': 'arXiv:2507.15469', 'title': 'The Emergence of Deep Reinforcement Learning for Path Planning', 'authors': 'Thanh Thi Nguyen, Saeid Nahavandi, Imran Razzak, Dung Nguyen, Nhat Truong Pham, Quoc Viet Hung Nguyen', 'link': 'https://arxiv.org/abs/2507.15469', 'abstract': 'The increasing demand for autonomous systems in complex and dynamic environments has driven significant research into intelligent path planning methodologies. For decades, graph-based search algorithms, linear programming techniques, and evolutionary computation methods have served as foundational approaches in this domain. Recently, deep reinforcement learning (DRL) has emerged as a powerful method for enabling autonomous agents to learn optimal navigation strategies through interaction with their environments. This survey provides a comprehensive overview of traditional approaches as well as the recent advancements in DRL applied to path planning tasks, focusing on autonomous vehicles, drones, and robotic platforms. Key algorithms across both conventional and learning-based paradigms are categorized, with their innovations and practical implementations highlighted. This is followed by a thorough discussion of their respective strengths and limitations in terms of computational efficiency, scalability, adaptability, and robustness. The survey concludes by identifying key open challenges and outlining promising avenues for future research. Special attention is given to hybrid approaches that integrate DRL with classical planning techniques to leverage the benefits of both learning-based adaptability and deterministic reliability, offering promising directions for robust and resilient autonomous navigation.', 'abstract_zh': '复杂动态环境中自主系统需求的增加推动了智能路径规划方法的显著研究进展。在传统的图搜索算法、线性规划技术和进化计算方法的基础上，近年来基于深度强化学习（DRL）的方法已成为使自主代理通过与其环境的交互学习最优导航策略的强大工具。本文综述了传统方法以及在路径规划任务中应用DRL的最新进展，重点介绍自主车辆、无人机和机器人平台的应用。文章对传统和学习导向范式的关键算法进行了分类，并强调了它们的创新和实际应用。然后，本文详细讨论了它们在计算效率、可扩展性、适应性和鲁棒性方面的各自优势和局限性。最后，本文指出了关键的开放挑战，并概述了未来研究有希望的方向。特别关注将DRL与经典规划技术相结合的混合方法，以利用基于学习的适应性和确定性可靠性带来的优势，提出了实现稳健和韧性的自主导航的有希望方向。', 'title_zh': '深度强化学习在路径规划中的 emergence'}
{'arxiv_id': 'arXiv:2507.15465', 'title': 'The New LLM Bottleneck: A Systems Perspective on Latent Attention and Mixture-of-Experts', 'authors': 'Sungmin Yun, Seonyong Park, Hwayong Nam, Younjoo Lee, Gunjun Lee, Kwanhee Kyung, Sangpyo Kim, Nam Sung Kim, Jongmin Kim, Hyungyo Kim, Juhwan Cho, Seungmin Baek, Jung Ho Ahn', 'link': 'https://arxiv.org/abs/2507.15465', 'abstract': 'Computational workloads composing traditional Transformer models are starkly bifurcated. Multi-Head Attention (MHA) is memory-bound, with low arithmetic intensity, while feedforward layers are compute-bound. This dichotomy has long motivated research into specialized hardware to mitigate the MHA bottleneck.\nThis paper argues that recent architectural shifts, namely Multi-head Latent Attention (MLA) and Mixture-of-Experts (MoE), challenge the premise of specialized attention hardware. We make two key observations. First, the arithmetic intensity of MLA is over two orders of magnitude greater than that of MHA, shifting it close to a compute-bound regime well-suited for modern accelerators like GPUs. Second, by distributing MoE experts across a pool of accelerators, their arithmetic intensity can be tuned through batching to match that of the dense layers, creating a more balanced computational profile.\nThese findings reveal a diminishing need for specialized attention hardware. The central challenge for next-generation Transformers is no longer accelerating a single memory-bound layer. Instead, the focus must shift to designing balanced systems with sufficient compute, memory capacity, memory bandwidth, and high-bandwidth interconnects to manage the diverse demands of large-scale models.', 'abstract_zh': '传统Transformer模型的计算负载明显分为两部分。多头注意机制（MHA）受内存限制，计算强度低，而前馈层则是计算受限。这种二元性长期促使人们研究专门的硬件来缓解MHA瓶颈。\n本文认为，最近的架构变化，即多头潜在注意（MLA）和专家混合（MoE），挑战了专门注意硬件的前提。我们提出了两个关键观察结果。首先，MLA的计算强度比MHA高两个数量级，使其接近一个适合现代加速器（如GPU）的计算受限域。其次，通过将MoE专家分布在一群加速器中，并通过批处理调整其计算强度，使其与密集层的计算强度匹配，从而创建一个更加平衡的计算配置文件。\n这些发现揭示了专门注意硬件需求的减弱。下一代Transformer的核心挑战不再是加速单一的内存受限层，而是转向设计具有足够计算能力、内存容量、内存带宽和支持高带宽互连的平衡系统，以应对大规模模型的多样化需求。', 'title_zh': '新的LLM瓶颈：从潜在注意力和Mixture-of-Experts的系统视角'}
{'arxiv_id': 'arXiv:2507.15455', 'title': 'Solving nonconvex Hamilton--Jacobi--Isaacs equations with PINN-based policy iteration', 'authors': 'Hee Jun Yang, Min Jung Kim, Yeoneung Kim', 'link': 'https://arxiv.org/abs/2507.15455', 'abstract': 'We propose a mesh-free policy iteration framework that combines classical dynamic programming with physics-informed neural networks (PINNs) to solve high-dimensional, nonconvex Hamilton--Jacobi--Isaacs (HJI) equations arising in stochastic differential games and robust control. The method alternates between solving linear second-order PDEs under fixed feedback policies and updating the controls via pointwise minimax optimization using automatic differentiation. Under standard Lipschitz and uniform ellipticity assumptions, we prove that the value function iterates converge locally uniformly to the unique viscosity solution of the HJI equation. The analysis establishes equi-Lipschitz regularity of the iterates, enabling provable stability and convergence without requiring convexity of the Hamiltonian. Numerical experiments demonstrate the accuracy and scalability of the method. In a two-dimensional stochastic path-planning game with a moving obstacle, our method matches finite-difference benchmarks with relative $L^2$-errors below %10^{-2}%. In five- and ten-dimensional publisher-subscriber differential games with anisotropic noise, the proposed approach consistently outperforms direct PINN solvers, yielding smoother value functions and lower residuals. Our results suggest that integrating PINNs with policy iteration is a practical and theoretically grounded method for solving high-dimensional, nonconvex HJI equations, with potential applications in robotics, finance, and multi-agent reinforcement learning.', 'abstract_zh': '我们提出了一种基于经典动态规划与物理知情神经网络（PINNs）的无网格策略迭代框架，以解决随机微分博弈和鲁棒控制中出现的高维非凸哈密尔顿-雅可比-伊萨acs（HJI）方程。该方法交替进行在固定反馈策略下求解线性二阶偏微分方程和通过点态最小最大优化更新控制，并利用自动微分。在标准Lipschitz和均匀椭圆性假设下，我们证明了值函数迭代局部一致收敛到HJI方程的唯一 viscosity 解。分析表明迭代具有统一Lipschitz正则性，从而在无需Hamiltonian凸性的条件下确保证明的稳定性和收敛性。数值实验展示了该方法的准确性和可扩展性。在二维存在移动障碍的随机路径规划博弈中，该方法相对$L^2$误差低于$10^{-2}$%，与有限差分基准方法相当。在五维和十维具有各向异性噪声的出版商-订阅者微分博弈中，所提出的方法始终优于直接PINN求解器，得到更平滑的值函数和更低的残差。我们的结果表明，将PINNs与策略迭代集成是一种解决高维非凸HJI方程的实用且理论上有依据的方法，具有在机器人技术、金融和多智能体强化学习中的潜在应用。', 'title_zh': '基于PINN的策略迭代求解非凸哈密顿-雅可比-伊萨acs方程'}
{'arxiv_id': 'arXiv:2507.15454', 'title': 'ObjectGS: Object-aware Scene Reconstruction and Scene Understanding via Gaussian Splatting', 'authors': 'Ruijie Zhu, Mulin Yu, Linning Xu, Lihan Jiang, Yixuan Li, Tianzhu Zhang, Jiangmiao Pang, Bo Dai', 'link': 'https://arxiv.org/abs/2507.15454', 'abstract': '3D Gaussian Splatting is renowned for its high-fidelity reconstructions and real-time novel view synthesis, yet its lack of semantic understanding limits object-level perception. In this work, we propose ObjectGS, an object-aware framework that unifies 3D scene reconstruction with semantic understanding. Instead of treating the scene as a unified whole, ObjectGS models individual objects as local anchors that generate neural Gaussians and share object IDs, enabling precise object-level reconstruction. During training, we dynamically grow or prune these anchors and optimize their features, while a one-hot ID encoding with a classification loss enforces clear semantic constraints. We show through extensive experiments that ObjectGS not only outperforms state-of-the-art methods on open-vocabulary and panoptic segmentation tasks, but also integrates seamlessly with applications like mesh extraction and scene editing. Project page: this https URL', 'abstract_zh': '3D高斯点云建模结合语义理解的对象感知框架：ObjectGS在高保真重建和实时新颖视图合成方面具有优势，但由于缺乏语义理解，限制了对象级别感知。本工作提出ObjectGS，一种结合3D场景重建与语义理解的对象感知框架。ObjectGS将场景建模为局部锚点的集合，这些锚点生成神经高斯函数并共享对象ID，从而实现精确的对象级别重建。在训练过程中，我们动态增长或减少这些锚点并优化其特征，同时通过独热ID编码和分类损失强制清晰的语义约束。实验表明，ObjectGS不仅在开放词汇和全景分割任务上性能优于现有方法，还能无缝集成到网格提取和场景编辑等应用中。项目页面: 这里', 'title_zh': 'ObjectGS: 基于高斯点云的目标意识场景重建与场景理解'}
{'arxiv_id': 'arXiv:2507.15428', 'title': 'EgoPrune: Efficient Token Pruning for Egomotion Video Reasoning in Embodied Agent', 'authors': 'Jiaao Li, Kaiyuan Li, Chen Gao, Yong Li, Xinlei Chen', 'link': 'https://arxiv.org/abs/2507.15428', 'abstract': "Egomotion videos are first-person recordings where the view changes continuously due to the agent's movement. As they serve as the primary visual input for embodied AI agents, making egomotion video reasoning more efficient is therefore essential for real-world deployment. Recent advances in vision-language models have enabled strong multimodal reasoning capabilities, but their computational cost remains prohibitive for long, redundant video inputs. Existing token pruning methods, typically designed for third-person videos, fail to leverage the spatiotemporal continuity and motion constraints inherent in egomotion settings. To address this, we propose EgoPrune, a training-free token pruning method tailored for egomotion video reasoning. EgoPrune comprises three components: a keyframe selector adapted from EmbodiedR for temporally efficient sampling; Perspective-Aware Redundancy Filtering (PARF), which aligns visual tokens using perspective transformations and removes redundant tokens; and a Maximal Marginal Relevance (MMR)-based token selector that jointly considers visual-text relevance and intra-frame diversity. Experiments on two egomotion video benchmarks show that EgoPrune consistently outperforms prior training-free methods across various pruning ratios while significantly reducing FLOPs, memory usage, and latency. Moreover, we deploy EgoPrune on an embodied agent equipped with a Jetson Orin NX 16GB edge device, demonstrating its real-world efficiency and suitability for on-device egomotion video reasoning.", 'abstract_zh': '自运动视频是第一人称录制，由于主体移动导致视角持续变化。由于它们是实体人工智能代理的主要视觉输入，因此提高自运动视频推理的效率对于实际部署至关重要。近年来，视觉-语言模型的发展虽然使多模态推理能力显著增强，但其对计算成本的高要求仍然使长且冗余的视频输入难以应对。现有的基于标记修剪的方法通常是为第三人称视频设计的，无法充分利用自运动设置中固有的时空连续性和运动约束。为了解决这一问题，我们提出了一种基于训练的标记修剪方法EgoPrune，专门适用于自运动视频推理。EgoPrune包含三个组件：从EmbodiedR改编的时间高效的关键帧选择器；视角意识冗余过滤器（PARF），使用视角变换对齐视觉标记并去除冗余标记；以及基于最大边际相关性的标记选择器，该选择器综合考虑了视觉-文本的相关性和帧内多样性。在两个自运动视频基准上的实验表明，EgoPrune在各种修剪比例下始终优于先前的基于训练的修剪方法，同时显著减少了FLOPs、内存使用量和延迟。此外，我们将在配备Jetson Orin NX 16GB边缘设备的实体代理上部署EgoPrune，证明了其在实际场景中的高效性，并且适合用于设备上自运动视频推理。', 'title_zh': 'EgoPrune: 用于体态智能体自我运动视频推理的高效令牌剪枝'}
{'arxiv_id': 'arXiv:2507.15396', 'title': 'Neuro-MSBG: An End-to-End Neural Model for Hearing Loss Simulation', 'authors': 'Hui-Guan Yuan, Ryandhimas E. Zezario, Shafique Ahmed, Hsin-Min Wang, Kai-Lung Hua, Yu Tsao', 'link': 'https://arxiv.org/abs/2507.15396', 'abstract': "Hearing loss simulation models are essential for hearing aid deployment. However, existing models have high computational complexity and latency, which limits real-time applications and lack direct integration with speech processing systems. To address these issues, we propose Neuro-MSBG, a lightweight end-to-end model with a personalized audiogram encoder for effective time-frequency modeling. Experiments show that Neuro-MSBG supports parallel inference and retains the intelligibility and perceptual quality of the original MSBG, with a Spearman's rank correlation coefficient (SRCC) of 0.9247 for Short-Time Objective Intelligibility (STOI) and 0.8671 for Perceptual Evaluation of Speech Quality (PESQ). Neuro-MSBG reduces simulation runtime by a factor of 46 (from 0.970 seconds to 0.021 seconds for a 1 second input), further demonstrating its efficiency and practicality.", 'abstract_zh': '听力损失模拟模型对于助听器部署至关重要。然而，现有模型具有较高的计算复杂度和延迟，限制了实时应用并缺乏与语音处理系统的直接集成。为解决这些问题，我们提出了一种轻量级端到端模型Neuro-MSBG，该模型具有个性化的 audiogram 编码器，以实现有效的时频建模。实验表明，Neuro-MSBG 支持并行推理，保留了原始 MSBG 的可懂度和感知质量，在 Short-Time Objective Intelligibility (STOI) 的 Spearman’s 秩相关系数 (SRCC) 为 0.9247，Perceptual Evaluation of Speech Quality (PESQ) 的 SRCC 为 0.8671。Neuro-MSBG 将仿真运行时间减少了 46 倍（从 1 秒输入的 0.970 秒降至 0.021 秒），进一步证明了其高效性和实用性。', 'title_zh': '神经-MSBG：一种端到端的神经模型用于模拟听力损失'}
{'arxiv_id': 'arXiv:2507.15393', 'title': 'PiMRef: Detecting and Explaining Ever-evolving Spear Phishing Emails with Knowledge Base Invariants', 'authors': 'Ruofan Liu, Yun Lin, Silas Yeo Shuen Yu, Xiwen Teoh, Zhenkai Liang, Jin Song Dong', 'link': 'https://arxiv.org/abs/2507.15393', 'abstract': "Phishing emails are a critical component of the cybercrime kill chain due to their wide reach and low cost. Their ever-evolving nature renders traditional rule-based and feature-engineered detectors ineffective in the ongoing arms race between attackers and defenders. The rise of large language models (LLMs) further exacerbates the threat, enabling attackers to craft highly convincing phishing emails at minimal cost.\nThis work demonstrates that LLMs can generate psychologically persuasive phishing emails tailored to victim profiles, successfully bypassing nearly all commercial and academic detectors. To defend against such threats, we propose PiMRef, the first reference-based phishing email detector that leverages knowledge-based invariants. Our core insight is that persuasive phishing emails often contain disprovable identity claims, which contradict real-world facts. PiMRef reframes phishing detection as an identity fact-checking task. Given an email, PiMRef (i) extracts the sender's claimed identity, (ii) verifies the legitimacy of the sender's domain against a predefined knowledge base, and (iii) detects call-to-action prompts that push user engagement. Contradictory claims are flagged as phishing indicators and serve as human-understandable explanations.\nCompared to existing methods such as D-Fence, HelpHed, and ChatSpamDetector, PiMRef boosts precision by 8.8% with no loss in recall on standard benchmarks like Nazario and PhishPot. In a real-world evaluation of 10,183 emails across five university accounts over three years, PiMRef achieved 92.1% precision, 87.9% recall, and a median runtime of 0.05s, outperforming the state-of-the-art in both effectiveness and efficiency.", 'abstract_zh': '基于知识不变量的参考导向钓鱼邮件检测器PiMRef', 'title_zh': 'PiMRef：基于知识库不变式的检测与解释永不出时的鱼叉 pharming 邮件方法'}
{'arxiv_id': 'arXiv:2507.15381', 'title': 'To Label or Not to Label: PALM -- A Predictive Model for Evaluating Sample Efficiency in Active Learning Models', 'authors': 'Julia Machnio, Mads Nielsen, Mostafa Mehdipour Ghazi', 'link': 'https://arxiv.org/abs/2507.15381', 'abstract': 'Active learning (AL) seeks to reduce annotation costs by selecting the most informative samples for labeling, making it particularly valuable in resource-constrained settings. However, traditional evaluation methods, which focus solely on final accuracy, fail to capture the full dynamics of the learning process. To address this gap, we propose PALM (Performance Analysis of Active Learning Models), a unified and interpretable mathematical model that characterizes AL trajectories through four key parameters: achievable accuracy, coverage efficiency, early-stage performance, and scalability. PALM provides a predictive description of AL behavior from partial observations, enabling the estimation of future performance and facilitating principled comparisons across different strategies. We validate PALM through extensive experiments on CIFAR-10/100 and ImageNet-50/100/200, covering a wide range of AL methods and self-supervised embeddings. Our results demonstrate that PALM generalizes effectively across datasets, budgets, and strategies, accurately predicting full learning curves from limited labeled data. Importantly, PALM reveals crucial insights into learning efficiency, data space coverage, and the scalability of AL methods. By enabling the selection of cost-effective strategies and predicting performance under tight budget constraints, PALM lays the basis for more systematic, reproducible, and data-efficient evaluation of AL in both research and real-world applications. The code is available at: this https URL.', 'abstract_zh': '基于性能分析的主动学习模型（PALM）：一种统一且可解释的数学模型', 'title_zh': '标注还是不标注：PALM——一种评估主动学习模型样本效率的预测模型'}
{'arxiv_id': 'arXiv:2507.15367', 'title': 'Multi-beam Beamforming in RIS-aided MIMO Subject to Reradiation Mask Constraints -- Optimization and Machine Learning Design', 'authors': 'Shumin Wang, Hajar El Hassani, Marco Di Renzo, Marios Poulakis', 'link': 'https://arxiv.org/abs/2507.15367', 'abstract': 'Reconfigurable intelligent surfaces (RISs) are an emerging technology for improving spectral efficiency and reducing power consumption in future wireless systems. This paper investigates the joint design of the transmit precoding matrices and the RIS phase shift vector in a multi-user RIS-aided multiple-input multiple-output (MIMO) communication system. We formulate a max-min optimization problem to maximize the minimum achievable rate while considering transmit power and reradiation mask constraints. The achievable rate is simplified using the Arimoto-Blahut algorithm, and the problem is broken into quadratic programs with quadratic constraints (QPQC) sub-problems using an alternating optimization approach. To improve efficiency, we develop a model-based neural network optimization that utilizes the one-hot encoding for the angles of incidence and reflection. We address practical RIS limitations by using a greedy search algorithm to solve the optimization problem for discrete phase shifts. Simulation results demonstrate that the proposed methods effectively shape the multi-beam radiation pattern towards desired directions while satisfying reradiation mask constraints. The neural network design reduces the execution time, and the discrete phase shift scheme performs well with a small reduction of the beamforming gain by using only four phase shift levels.', 'abstract_zh': '基于RIS辅助多用户MIMO通信系统的传输前编码矩阵与RIS相位移向量联合设计', 'title_zh': 'RIS辅助MIMO系统中受限再辐射掩模的多波束波束形成——优化与机器学习设计'}
{'arxiv_id': 'arXiv:2507.15364', 'title': 'EEG-based Epileptic Prediction via a Two-stage Channel-aware Set Transformer Network', 'authors': 'Ruifeng Zheng, Cong Chen, Shuang Wang, Yiming Liu, Lin You, Jindong Lu, Ruizhe Zhu, Guodao Zhang, Kejie Huang', 'link': 'https://arxiv.org/abs/2507.15364', 'abstract': "Epilepsy is a chronic, noncommunicable brain disorder, and sudden seizure onsets can significantly impact patients' quality of life and health. However, wearable seizure-predicting devices are still limited, partly due to the bulky size of EEG-collecting devices. To relieve the problem, we proposed a novel two-stage channel-aware Set Transformer Network that could perform seizure prediction with fewer EEG channel sensors. We also tested a seizure-independent division method which could prevent the adjacency of training and test data. Experiments were performed on the CHB-MIT dataset which includes 22 patients with 88 merged seizures. The mean sensitivity before channel selection was 76.4% with a false predicting rate (FPR) of 0.09/hour. After channel selection, dominant channels emerged in 20 out of 22 patients; the average number of channels was reduced to 2.8 from 18; and the mean sensitivity rose to 80.1% with an FPR of 0.11/hour. Furthermore, experimental results on the seizure-independent division supported our assertion that a more rigorous seizure-independent division should be used for patients with abundant EEG recordings.", 'abstract_zh': '癫痫是一种慢性非传染性的脑部疾病，突然的发作会对患者的日常生活和健康产生显著影响。然而，可穿戴的癫痫预测设备仍然有限，部分原因是EEG采集设备体积较大。为了解决这一问题，我们提出了一种新型两阶段通道感知的Set Transformer网络，能够在较少的EEG通道传感器下进行癫痫预测。我们还测试了一种与癫痫无关的划分方法，以防止训练数据和测试数据的邻近。实验在包含22位患者和88次合并癫痫发作的CHB-MIT数据集上进行。在通道选择前，平均灵敏度为76.4%，假阳性率为0.09/小时。在通道选择后，有20名患者出现了主导通道，通道平均数量从18减少到2.8，平均灵敏度提高到80.1%，假阳性率为0.11/小时。此外，对与癫痫无关的划分进行的实验结果支持了我们的观点，即对于EEG记录丰富的患者，应使用更严格的与癫痫无关的划分方法。', 'title_zh': '基于EEG的双阶段通道aware集合变换网络癫痫预测'}
{'arxiv_id': 'arXiv:2507.15361', 'title': 'Latent Space Synergy: Text-Guided Data Augmentation for Direct Diffusion Biomedical Segmentation', 'authors': 'Muhammad Aqeel, Maham Nazir, Zanxi Ruan, Francesco Setti', 'link': 'https://arxiv.org/abs/2507.15361', 'abstract': 'Medical image segmentation suffers from data scarcity, particularly in polyp detection where annotation requires specialized expertise. We present SynDiff, a framework combining text-guided synthetic data generation with efficient diffusion-based segmentation. Our approach employs latent diffusion models to generate clinically realistic synthetic polyps through text-conditioned inpainting, augmenting limited training data with semantically diverse samples. Unlike traditional diffusion methods requiring iterative denoising, we introduce direct latent estimation enabling single-step inference with T x computational speedup. On CVC-ClinicDB, SynDiff achieves 96.0% Dice and 92.9% IoU while maintaining real-time capability suitable for clinical deployment. The framework demonstrates that controlled synthetic augmentation improves segmentation robustness without distribution shift. SynDiff bridges the gap between data-hungry deep learning models and clinical constraints, offering an efficient solution for deployment in resourcelimited medical settings.', 'abstract_zh': '医学图像分割受到数据稀缺性的困扰，特别是在肠道息肉检测中，标注需要专门的专业知识。我们提出了一种结合文本指导的合成数据生成与高效扩散分割的框架SynDiff。该方法利用潜在扩散模型通过文本条件填充生成临床现实的合成息肉，从而用语义多样性样本增强有限的训练数据。与传统的需要迭代去噪的扩散方法不同，我们引入了直接潜在估计，实现了单步推理并提高了T倍的计算速度。在CVC-ClinicDB上，SynDiff达到了96.0%的Dice系数和92.9%的IoU，同时保持了适用于临床部署的实时能力。该框架证明了受控的合成增强可以提高分割的鲁棒性而无需分布偏移。SynDiff弥合了数据饥渴的深度学习模型与临床约束之间的差距，为资源受限的医疗环境提供了高效部署的解决方案。', 'title_zh': '潜在空间协同效应：文本引导的数据增强方法直接扩散生物医学分割'}
{'arxiv_id': 'arXiv:2507.15357', 'title': 'Metaphor and Large Language Models: When Surface Features Matter More than Deep Understanding', 'authors': 'Elisa Sanchez-Bayona, Rodrigo Agerri', 'link': 'https://arxiv.org/abs/2507.15357', 'abstract': "This paper presents a comprehensive evaluation of the capabilities of Large Language Models (LLMs) in metaphor interpretation across multiple datasets, tasks, and prompt configurations. Although metaphor processing has gained significant attention in Natural Language Processing (NLP), previous research has been limited to single-dataset evaluations and specific task settings, often using artificially constructed data through lexical replacement. We address these limitations by conducting extensive experiments using diverse publicly available datasets with inference and metaphor annotations, focusing on Natural Language Inference (NLI) and Question Answering (QA) tasks. The results indicate that LLMs' performance is more influenced by features like lexical overlap and sentence length than by metaphorical content, demonstrating that any alleged emergent abilities of LLMs to understand metaphorical language are the result of a combination of surface-level features, in-context learning, and linguistic knowledge. This work provides critical insights into the current capabilities and limitations of LLMs in processing figurative language, highlighting the need for more realistic evaluation frameworks in metaphor interpretation tasks. Data and code are publicly available.", 'abstract_zh': '本文对大型语言模型（LLMs）在多个数据集、任务和提示配置下的隐喻解释能力进行了全面评估。尽管隐喻处理在自然语言处理（NLP）中受到了广泛关注，但之前的研究所限于单一数据集评估和特定任务设置，经常使用通过词形替换人工构造的数据。我们通过使用多样化的公共可用数据集进行广泛的实验，侧重于自然语言推理（NLI）和问答（QA）任务，解决了这些局限性。结果表明，LLMs的性能更多受到词汇重叠和句子长度等特征的影响，而不是隐喻内容，这表明LLMs理解隐喻语言的任何隐含能力都是表面特征、上下文学习和语言知识的结合结果。本文为LLMs处理修辞语言的当前能力和局限性提供了关键见解，突出了隐喻解释任务中需要更现实的评估框架的重要性。数据和代码已公开。', 'title_zh': '隐喻与大规模语言模型：表面特征比深刻理解更为重要'}
{'arxiv_id': 'arXiv:2507.15349', 'title': 'Scaling Decentralized Learning with FLock', 'authors': 'Zehua Cheng, Rui Sun, Jiahao Sun, Yike Guo', 'link': 'https://arxiv.org/abs/2507.15349', 'abstract': 'Fine-tuning the large language models (LLMs) are prevented by the deficiency of centralized control and the massive computing and communication overhead on the decentralized schemes. While the typical standard federated learning (FL) supports data privacy, the central server requirement creates a single point of attack and vulnerability to poisoning attacks. Generalizing the result in this direction to 70B-parameter models in the heterogeneous, trustless environments has turned out to be a huge, yet unbroken bottleneck. This paper introduces FLock, a decentralized framework for secure and efficient collaborative LLM fine-tuning. Integrating a blockchain-based trust layer with economic incentives, FLock replaces the central aggregator with a secure, auditable protocol for cooperation among untrusted parties. We present the first empirical validation of fine-tuning a 70B LLM in a secure, multi-domain, decentralized setting. Our experiments show the FLock framework defends against backdoor poisoning attacks that compromise standard FL optimizers and fosters synergistic knowledge transfer. The resulting models show a >68% reduction in adversarial attack success rates. The global model also demonstrates superior cross-domain generalization, outperforming models trained in isolation on their own specialized data.', 'abstract_zh': 'FLock：一种安全高效的去中心化框架，用于细调大规模语言模型', 'title_zh': '扩展分布式学习的FLock算法'}
{'arxiv_id': 'arXiv:2507.15343', 'title': 'StackTrans: From Large Language Model to Large Pushdown Automata Model', 'authors': 'Kechi Zhang, Ge Li, Jia Li, Huangzhao Zhang, Yihong Dong, Jia Li, Jingjing Xu, Zhi Jin', 'link': 'https://arxiv.org/abs/2507.15343', 'abstract': 'The Transformer architecture has emerged as a landmark advancement within the broad field of artificial intelligence, effectively catalyzing the advent of large language models (LLMs). However, despite its remarkable capabilities and the substantial progress it has facilitated, the Transformer architecture still has some limitations. One such intrinsic limitation is its inability to effectively capture the Chomsky hierarchy, such as regular expressions or deterministic context-free grammars. Drawing inspiration from pushdown automata, which efficiently resolve deterministic context-free grammars using stacks, we propose StackTrans to address the aforementioned issue within LLMs. Unlike previous approaches that modify the attention computation, StackTrans explicitly incorporates hidden state stacks between Transformer layers. This design maintains compatibility with existing frameworks like flash-attention. Specifically, our design features stack operations -- such as pushing and popping hidden states -- that are differentiable and can be learned in an end-to-end manner. Our comprehensive evaluation spans benchmarks for both Chomsky hierarchies and large-scale natural languages. Across these diverse tasks, StackTrans consistently outperforms standard Transformer models and other baselines. We have successfully scaled StackTrans up from 360M to 7B parameters. In particular, our from-scratch pretrained model StackTrans-360M outperforms several larger open-source LLMs with 2-3x more parameters, showcasing its superior efficiency and reasoning capability.', 'abstract_zh': 'StackTrans：基于栈的Transformer架构以提高大型语言模型的语法处理能力', 'title_zh': 'StackTrans: 从大规模语言模型到大规模推进栈模型'}
{'arxiv_id': 'arXiv:2507.15340', 'title': 'MedSR-Impact: Transformer-Based Super-Resolution for Lung CT Segmentation, Radiomics, Classification, and Prognosis', 'authors': 'Marc Boubnovski Martell, Kristofer Linton-Reid, Mitchell Chen, Sumeet Hindocha, Benjamin Hunter, Marco A. Calzado, Richard Lee, Joram M. Posma, Eric O. Aboagye', 'link': 'https://arxiv.org/abs/2507.15340', 'abstract': 'High-resolution volumetric computed tomography (CT) is essential for accurate diagnosis and treatment planning in thoracic diseases; however, it is limited by radiation dose and hardware costs. We present the Transformer Volumetric Super-Resolution Network (\\textbf{TVSRN-V2}), a transformer-based super-resolution (SR) framework designed for practical deployment in clinical lung CT analysis. Built from scalable components, including Through-Plane Attention Blocks (TAB) and Swin Transformer V2 -- our model effectively reconstructs fine anatomical details in low-dose CT volumes and integrates seamlessly with downstream analysis pipelines. We evaluate its effectiveness on three critical lung cancer tasks -- lobe segmentation, radiomics, and prognosis -- across multiple clinical cohorts. To enhance robustness across variable acquisition protocols, we introduce pseudo-low-resolution augmentation, simulating scanner diversity without requiring private data. TVSRN-V2 demonstrates a significant improvement in segmentation accuracy (+4\\% Dice), higher radiomic feature reproducibility, and enhanced predictive performance (+0.06 C-index and AUC). These results indicate that SR-driven recovery of structural detail significantly enhances clinical decision support, positioning TVSRN-V2 as a well-engineered, clinically viable system for dose-efficient imaging and quantitative analysis in real-world CT workflows.', 'abstract_zh': '基于变换器的高分辨率体积计算 tomography 网络 (TVSRN-V2)：用于临床肺部 CT 分析的实用超分辨率框架', 'title_zh': 'MedSR-Impact: 基于变压器的肺部CT分割、 radiomics、分类和预后超分辨技术'}
{'arxiv_id': 'arXiv:2507.15336', 'title': 'Beyond Model Base Selection: Weaving Knowledge to Master Fine-grained Neural Network Design', 'authors': 'Jialiang Wang, Hanmo Liu, Shimin Di, Zhili Wang, Jiachuan Wang, Lei Chen, Xiaofang Zhou', 'link': 'https://arxiv.org/abs/2507.15336', 'abstract': "Database systems have recently advocated for embedding machine learning (ML) capabilities, offering declarative model queries over large, managed model repositories, thereby circumventing the huge computational overhead of traditional ML-based algorithms in automated neural network model selection. Pioneering database studies aim to organize existing benchmark repositories as model bases (MB), querying them for the model records with the highest performance estimation metrics for given tasks. However, this static model selection practice overlooks the fine-grained, evolving relational dependencies between diverse task queries and model architecture variations, resulting in suboptimal matches and failing to further refine the model effectively. To fill the model refinement gap in database research, we propose M-DESIGN, a curated model knowledge base (MKB) pipeline for mastering neural network refinement by adaptively weaving prior insights about model architecture modification. First, we propose a knowledge weaving engine that reframes model refinement as an adaptive query problem over task metadata. Given a user's task query, M-DESIGN quickly matches and iteratively refines candidate models by leveraging a graph-relational knowledge schema that explicitly encodes data properties, architecture variations, and pairwise performance deltas as joinable relations. This schema supports fine-grained relational analytics over architecture tweaks and drives a predictive query planner that can detect and adapt to out-of-distribution (OOD) tasks. We instantiate M-DESIGN for graph analytics tasks, where our model knowledge base enriches existing benchmarks with structured metadata covering 3 graph tasks and 22 graph datasets, contributing data records of 67,760 graph models. Empirical results demonstrate that M-DESIGN delivers the optimal model in 26 of 33 data-task pairs within limited budgets.", 'abstract_zh': '数据库系统最近提倡嵌入机器学习能力，提供针对大型管理模式库的声明式模型查询，从而绕过了传统基于机器学习算法的自动化神经网络模型选择的巨大计算开销。我们提出M-DESIGN，一种经精心设计的神经网络模型知识库(MKB)流水线，通过自适应地编织关于模型架构修改的前期洞见来掌握神经网络的精炼。该流水线首先提出了一种知识编织引擎，将模型精炼重新构想为一个适应查询问题，基于任务元数据。对于用户的任务查询，M-DESIGN迅速匹配并迭代精炼候选模型，利用一个图关系知识架构，该架构明确编码了数据属性、架构变化和成对性能差异，并将它们作为可连接的关系。此类架构支持对架构调整的细粒度关系分析，并驱动一个预测查询规划器，能够检测和适应未知分布任务。在图分析任务中，我们的模型知识库为现有基准数据集增加了涵盖3个图任务和22个图数据集的结构化元数据，提供了67,760个图模型的数据记录。实证结果表明，在有限预算内，M-DESIGN在33个数据-任务对中提供了最优的26个模型。', 'title_zh': '超越模型基线选择：融合知识以掌握细粒度神经网络设计'}
{'arxiv_id': 'arXiv:2507.15335', 'title': 'ExDD: Explicit Dual Distribution Learning for Surface Defect Detection via Diffusion Synthesis', 'authors': 'Muhammad Aqeel, Federico Leonardi, Francesco Setti', 'link': 'https://arxiv.org/abs/2507.15335', 'abstract': 'Industrial defect detection systems face critical limitations when confined to one-class anomaly detection paradigms, which assume uniform outlier distributions and struggle with data scarcity in realworld manufacturing environments. We present ExDD (Explicit Dual Distribution), a novel framework that transcends these limitations by explicitly modeling dual feature distributions. Our approach leverages parallel memory banks that capture the distinct statistical properties of both normality and anomalous patterns, addressing the fundamental flaw of uniform outlier assumptions. To overcome data scarcity, we employ latent diffusion models with domain-specific textual conditioning, generating in-distribution synthetic defects that preserve industrial context. Our neighborhood-aware ratio scoring mechanism elegantly fuses complementary distance metrics, amplifying signals in regions exhibiting both deviation from normality and similarity to known defect patterns. Experimental validation on KSDD2 demonstrates superior performance (94.2% I-AUROC, 97.7% P-AUROC), with optimal augmentation at 100 synthetic samples.', 'abstract_zh': '面向工业缺陷检测系统超越单一异常检测范式的限制：显式双分布框架（ExDD）', 'title_zh': 'ExDD: 显式双分布学习在扩散合成中的表面缺陷检测'}
{'arxiv_id': 'arXiv:2507.15296', 'title': 'Butterfly Effects in Toolchains: A Comprehensive Analysis of Failed Parameter Filling in LLM Tool-Agent Systems', 'authors': 'Qian Xiong, Yuekai Huang, Ziyou Jiang, Zhiyuan Chang, Yujia Zheng, Tianhao Li, Mingyang Li', 'link': 'https://arxiv.org/abs/2507.15296', 'abstract': 'The emergence of the tool agent paradigm has broadened the capability boundaries of the Large Language Model (LLM), enabling it to complete more complex tasks. However, the effectiveness of this paradigm is limited due to the issue of parameter failure during its execution. To explore this phenomenon and propose corresponding suggestions, we first construct a parameter failure taxonomy in this paper. We derive five failure categories from the invocation chain of a mainstream tool agent. Then, we explore the correlation between three different input sources and failure categories by applying 15 input perturbation methods to the input. Experimental results show that parameter name hallucination failure primarily stems from inherent LLM limitations, while issues with input sources mainly cause other failure patterns. To improve the reliability and effectiveness of tool-agent interactions, we propose corresponding improvement suggestions, including standardizing tool return formats, improving error feedback mechanisms, and ensuring parameter consistency.', 'abstract_zh': '工具代理范式的出现扩展了大型语言模型（LLM）的能力边界，使其能够完成更复杂的任务。然而，这一范式的有效性受限于执行过程中的参数失败问题。为探索这一现象并提出相应的建议，本文首先构建了一个参数失败分类体系。我们从主流工具代理的调用链中推导出五个失败类别，然后通过应用15种输入扰动方法探讨三种不同输入源与失败类别的关联。实验结果表明，参数名称幻觉失败主要源于LLM的固有限制，而输入源的问题主要导致其他失败模式。为了提高工具-代理交互的可靠性和有效性，我们提出了相应的改进建议，包括标准化工具返回格式、改善错误反馈机制和确保参数一致性。', 'title_zh': '工具链中的蝴蝶效应：LLM工具-代理系统中参数填充失败的全面分析'}
{'arxiv_id': 'arXiv:2507.15292', 'title': 'EndoControlMag: Robust Endoscopic Vascular Motion Magnification with Periodic Reference Resetting and Hierarchical Tissue-aware Dual-Mask Contro', 'authors': 'An Wanga, Rulin Zhou, Mengya Xu, Yiru Ye, Longfei Gou, Yiting Chang, Hao Chen, Chwee Ming Lim, Jiankun Wang, Hongliang Ren', 'link': 'https://arxiv.org/abs/2507.15292', 'abstract': 'Visualizing subtle vascular motions in endoscopic surgery is crucial for surgical precision and decision-making, yet remains challenging due to the complex and dynamic nature of surgical scenes. To address this, we introduce EndoControlMag, a training-free, Lagrangian-based framework with mask-conditioned vascular motion magnification tailored to endoscopic environments. Our approach features two key modules: a Periodic Reference Resetting (PRR) scheme that divides videos into short overlapping clips with dynamically updated reference frames to prevent error accumulation while maintaining temporal coherence, and a Hierarchical Tissue-aware Magnification (HTM) framework with dual-mode mask dilation. HTM first tracks vessel cores using a pretrained visual tracking model to maintain accurate localization despite occlusions and view changes. It then applies one of two adaptive softening strategies to surrounding tissues: motion-based softening that modulates magnification strength proportional to observed tissue displacement, or distance-based exponential decay that simulates biomechanical force attenuation. This dual-mode approach accommodates diverse surgical scenarios-motion-based softening excels with complex tissue deformations while distance-based softening provides stability during unreliable optical flow conditions. We evaluate EndoControlMag on our EndoVMM24 dataset spanning four different surgery types and various challenging scenarios, including occlusions, instrument disturbance, view changes, and vessel deformations. Quantitative metrics, visual assessments, and expert surgeon evaluations demonstrate that EndoControlMag significantly outperforms existing methods in both magnification accuracy and visual quality while maintaining robustness across challenging surgical conditions. The code, dataset, and video results are available at this https URL.', 'abstract_zh': 'EndoControlMag：一种用于内镜手术的无需训练、基于Lagrangian的血管运动放大框架', 'title_zh': 'EndoControlMag: 基于周期参考重置和分层组织感知双-mask控制的内窥镜血管运动放大技术'}
{'arxiv_id': 'arXiv:2507.15288', 'title': 'Preferential subspace identification (PSID) with forward-backward smoothing', 'authors': 'Omid G. Sani, Maryam M. Shanechi', 'link': 'https://arxiv.org/abs/2507.15288', 'abstract': 'System identification methods for multivariate time-series, such as neural and behavioral recordings, have been used to build models for predicting one from the other. For example, Preferential Subspace Identification (PSID) builds a state-space model of a primary time-series (e.g., neural activity) to optimally predict a secondary time-series (e.g., behavior). However, PSID focuses on optimal prediction using past primary data, even though in offline applications, better estimation can be achieved by incorporating concurrent data (filtering) or all available data (smoothing). Here, we extend PSID to enable optimal filtering and smoothing. First, we show that the presence of a secondary signal makes it possible to uniquely identify a model with an optimal Kalman update step (to enable filtering) from a family of otherwise equivalent state-space models. Our filtering solution augments PSID with a reduced-rank regression step that directly learns the optimal gain required for the update step from data. We refer to this extension of PSID as PSID with filtering. Second, inspired by two-filter Kalman smoother formulations, we develop a novel forward-backward PSID smoothing algorithm where we first apply PSID with filtering and then apply it again in the reverse time direction on the residuals of the filtered secondary signal. We validate our methods on simulated data, showing that our approach recovers the ground-truth model parameters for filtering, and achieves optimal filtering and smoothing decoding performance of the secondary signal that matches the ideal performance of the true underlying model. This work provides a principled framework for optimal linear filtering and smoothing in the two-signal setting, significantly expanding the toolkit for analyzing dynamic interactions in multivariate time-series.', 'abstract_zh': '多变量时间序列的系统识别方法，如神经和行为记录，已被用于构建预测一个时间序列从另一个时间序列的模型。例如，偏好亚空间识别（PSID）构建主时间序列（如神经活动）的状态空间模型，以最优地预测次级时间序列（如行为）。然而，PSID重点关注使用过去的主要数据进行最优预测，尽管在离线应用中，通过纳入并发数据（滤波）或所有可用数据（平滑）可以获得更好的估计结果。在此，我们扩展PSID以实现最优滤波和平滑。首先，我们表明次级信号的存在使得能够从状态空间模型的等价家族中唯一识别出一个模型，该模型具有能够实现滤波的最优卡尔曼更新步骤。我们的滤波解决方案通过在PSID中增加一个降秩回归步骤来直接从数据中学习所需的最优增益。我们将这种扩展的PSID称为具有滤波功能的PSID。其次，受到两步卡尔曼平滑算法的启发，我们开发了一种新颖的正向-反向PSID平滑算法，其中我们首先使用滤波功能的PSID应用该方法，然后在逆时间方向上将其应用于次级信号滤波残差上。我们在模拟数据上验证了我们的方法，表明我们的方法恢复了滤波的真实模型参数，并实现了与真实底层模型理想的滤波和平滑解码性能相匹配的表现。这项工作为双信号设置下的最优线性滤波和平滑提供了原理性的框架，显著扩展了分析多变量时间序列中动态相互作用的工具箱。', 'title_zh': '偏好子空间识别（PSID）与前向后向平滑结合'}
{'arxiv_id': 'arXiv:2507.15287', 'title': 'Mixture of Autoencoder Experts Guidance using Unlabeled and Incomplete Data for Exploration in Reinforcement Learning', 'authors': 'Elias Malomgré, Pieter Simoens', 'link': 'https://arxiv.org/abs/2507.15287', 'abstract': "Recent trends in Reinforcement Learning (RL) highlight the need for agents to learn from reward-free interactions and alternative supervision signals, such as unlabeled or incomplete demonstrations, rather than relying solely on explicit reward maximization. Additionally, developing generalist agents that can adapt efficiently in real-world environments often requires leveraging these reward-free signals to guide learning and behavior. However, while intrinsic motivation techniques provide a means for agents to seek out novel or uncertain states in the absence of explicit rewards, they are often challenged by dense reward environments or the complexity of high-dimensional state and action spaces. Furthermore, most existing approaches rely directly on the unprocessed intrinsic reward signals, which can make it difficult to shape or control the agent's exploration effectively. We propose a framework that can effectively utilize expert demonstrations, even when they are incomplete and imperfect. By applying a mapping function to transform the similarity between an agent's state and expert data into a shaped intrinsic reward, our method allows for flexible and targeted exploration of expert-like behaviors. We employ a Mixture of Autoencoder Experts to capture a diverse range of behaviors and accommodate missing information in demonstrations. Experiments show our approach enables robust exploration and strong performance in both sparse and dense reward environments, even when demonstrations are sparse or incomplete. This provides a practical framework for RL in realistic settings where optimal data is unavailable and precise reward control is needed.", 'abstract_zh': 'Recent趋势在强化学习（RL）中的新进展突显了需要让智能体从无奖励交互和替代监督信号（如未标记或不完整示范）中学习的重要性，而不仅仅是依赖显式奖励最大化的策略。此外，开发能够在现实环境中高效适应的通用智能体往往需要利用这些无奖励信号来指导学习和行为。然而，内部激励技术虽然提供了一种在缺乏显式奖励的情况下让智能体寻求新颖或不确定状态的方法，但在密集奖励环境或高维状态和动作空间的复杂性面前，它们经常受到挑战。此外，大多数现有方法直接依赖未处理的内部激励信号，这可能使有效塑造或控制智能体的探索变得困难。我们提出了一种框架，即使专家示范不完整且不完美，也能有效利用这些示范。通过应用变换函数将智能体状态与专家数据的相似度转换为塑造的内部奖励，我们的方法允许灵活且有针对性地探索专家级行为。我们采用专家编码器混合模型来捕捉行为多样性并适应示范中的缺失信息。实验表明，我们的方法能够在稀疏和密集奖励环境中实现稳健的探索和强大的性能，即使示范稀疏或不完整。这为在最优数据不可用且需要精确奖励控制的现实场景中应用RL提供了实用框架。', 'title_zh': '混合自动编码器专家指导在未标记和不完整数据下探索的强化学习中应用'}
{'arxiv_id': 'arXiv:2507.15281', 'title': 'A Novel Self-Evolution Framework for Large Language Models', 'authors': 'Haoran Sun, Zekun Zhang, Shaoning Zeng', 'link': 'https://arxiv.org/abs/2507.15281', 'abstract': "The capabilities of Large Language Models (LLMs) are limited to some extent by pre-training, so some researchers optimize LLMs through post-training. Existing post-training strategies, such as memory-based retrieval or preference optimization, improve user alignment yet fail to enhance the model's domain cognition. To bridge this gap, we propose a novel Dual-Phase Self-Evolution (DPSE) framework that jointly optimizes user preference adaptation and domain-specific competence. DPSE introduces a Censor module to extract multi-dimensional interaction signals and estimate satisfaction scores, which guide structured data expansion via topic-aware and preference-driven strategies. These expanded datasets support a two-stage fine-tuning pipeline: supervised domain grounding followed by frequency-aware preference optimization. Experiments across general NLP benchmarks and long-term dialogue tasks demonstrate that DPSE consistently outperforms Supervised Fine-Tuning, Preference Optimization, and Memory-Augmented baselines. Ablation studies validate the contribution of each module. In this way, our framework provides an autonomous path toward continual self-evolution of LLMs.", 'abstract_zh': '一种双阶段自我演化框架：联合优化用户偏好适应与领域特定能力（Dual-Phase Self-Evolution Framework for Joint Optimization of User Preference Adaptation and Domain-Specific Competence）', 'title_zh': '一种新型的大规模语言模型自我进化框架'}
{'arxiv_id': 'arXiv:2507.15272', 'title': 'A2TTS: TTS for Low Resource Indian Languages', 'authors': 'Ayush Singh Bhadoriya, Abhishek Nikunj Shinde, Isha Pandey, Ganesh Ramakrishnan', 'link': 'https://arxiv.org/abs/2507.15272', 'abstract': 'We present a speaker conditioned text-to-speech (TTS) system aimed at addressing challenges in generating speech for unseen speakers and supporting diverse Indian languages. Our method leverages a diffusion-based TTS architecture, where a speaker encoder extracts embeddings from short reference audio samples to condition the DDPM decoder for multispeaker generation. To further enhance prosody and naturalness, we employ a cross-attention based duration prediction mechanism that utilizes reference audio, enabling more accurate and speaker consistent timing. This results in speech that closely resembles the target speaker while improving duration modeling and overall expressiveness. Additionally, to improve zero-shot generation, we employed classifier free guidance, allowing the system to generate speech more near speech for unknown speakers. Using this approach, we trained language-specific speaker-conditioned models. Using the IndicSUPERB dataset for multiple Indian languages such as Bengali, Gujarati, Hindi, Marathi, Malayalam, Punjabi and Tamil.', 'abstract_zh': '基于讲话人条件的文本到speech系统：面向未见讲话人挑战及支持多样印度语言的研究', 'title_zh': 'A2TTS: 低资源印度语言的语音合成'}
{'arxiv_id': 'arXiv:2507.15269', 'title': 'Conditional Video Generation for High-Efficiency Video Compression', 'authors': 'Fangqiu Yi, Jingyu Xu, Jiawei Shao, Chi Zhang, Xuelong Li', 'link': 'https://arxiv.org/abs/2507.15269', 'abstract': 'Perceptual studies demonstrate that conditional diffusion models excel at reconstructing video content aligned with human visual perception. Building on this insight, we propose a video compression framework that leverages conditional diffusion models for perceptually optimized reconstruction. Specifically, we reframe video compression as a conditional generation task, where a generative model synthesizes video from sparse, yet informative signals. Our approach introduces three key modules: (1) Multi-granular conditioning that captures both static scene structure and dynamic spatio-temporal cues; (2) Compact representations designed for efficient transmission without sacrificing semantic richness; (3) Multi-condition training with modality dropout and role-aware embeddings, which prevent over-reliance on any single modality and enhance robustness. Extensive experiments show that our method significantly outperforms both traditional and neural codecs on perceptual quality metrics such as Fréchet Video Distance (FVD) and LPIPS, especially under high compression ratios.', 'abstract_zh': '感知研究显示条件扩散模型在重建与人类视觉感知相一致的视频内容方面表现出色。基于这一见解，我们提出了一种利用条件扩散模型进行感知优化重构的视频压缩框架。具体而言，我们将视频压缩重新定义为一个条件生成任务，其中生成模型从稀疏但具有信息性的信号中合成视频。我们的方法引入了三个关键模块：（1）多粒度条件模块，捕获静态场景结构和动态空时线索；（2）紧凑表示，旨在进行高效传输而不牺牲语义丰富性；（3）具备模态 dropout 和角色感知嵌入的多条件训练，防止对单一模态的过度依赖并增强鲁棒性。广泛实验表明，与传统和神经编解码器相比，我们的方法在感知质量度量如Fréchet视频距离（FVD）和LPIPS等方面表现显著优异，尤其是在高压缩比条件下。', 'title_zh': '基于条件视频生成的高效率视频压缩'}
{'arxiv_id': 'arXiv:2507.15256', 'title': 'Optimal Transceiver Design in Over-the-Air Federated Distillation', 'authors': 'Zihao Hu, Jia Yan, Ying-Jun Angela Zhang, Jun Zhang, Khaled B. Letaief', 'link': 'https://arxiv.org/abs/2507.15256', 'abstract': "The rapid proliferation and growth of artificial intelligence (AI) has led to the development of federated learning (FL). FL allows wireless devices (WDs) to cooperatively learn by sharing only local model parameters, without needing to share the entire dataset. However, the emergence of large AI models has made existing FL approaches inefficient, due to the significant communication overhead required. In this paper, we propose a novel over-the-air federated distillation (FD) framework by synergizing the strength of FL and knowledge distillation to avoid the heavy local model transmission. Instead of sharing the model parameters, only the WDs' model outputs, referred to as knowledge, are shared and aggregated over-the-air by exploiting the superposition property of the multiple-access channel. We shall study the transceiver design in over-the-air FD, aiming to maximize the learning convergence rate while meeting the power constraints of the transceivers. The main challenge lies in the intractability of the learning performance analysis, as well as the non-convex nature and the optimization spanning the whole FD training period. To tackle this problem, we first derive an analytical expression of the convergence rate in over-the-air FD. Then, the closed-form optimal solutions of the WDs' transmit power and the estimator for over-the-air aggregation are obtained given the receiver combining strategy. Accordingly, we put forth an efficient approach to find the optimal receiver beamforming vector via semidefinite relaxation. We further prove that there is no optimality gap between the original and relaxed problem for the receiver beamforming design. Numerical results will show that the proposed over-the-air FD approach achieves a significant reduction in communication overhead, with only a minor compromise in testing accuracy compared to conventional FL benchmarks.", 'abstract_zh': '基于空中联邦蒸馏的无线设备协同学习框架', 'title_zh': '空中 federated -distillation 的最优发射-接收机设计'}
{'arxiv_id': 'arXiv:2507.15255', 'title': 'MEETI: A Multimodal ECG Dataset from MIMIC-IV-ECG with Signals, Images, Features and Interpretations', 'authors': 'Deyun Zhang, Xiang Lan, Shijia Geng, Qinghao Zhao, Sumei Fan, Mengling Feng, Shenda Hong', 'link': 'https://arxiv.org/abs/2507.15255', 'abstract': 'Electrocardiogram (ECG) plays a foundational role in modern cardiovascular care, enabling non-invasive diagnosis of arrhythmias, myocardial ischemia, and conduction disorders. While machine learning has achieved expert-level performance in ECG interpretation, the development of clinically deployable multimodal AI systems remains constrained, primarily due to the lack of publicly available datasets that simultaneously incorporate raw signals, diagnostic images, and interpretation text. Most existing ECG datasets provide only single-modality data or, at most, dual modalities, making it difficult to build models that can understand and integrate diverse ECG information in real-world settings. To address this gap, we introduce MEETI (MIMIC-IV-Ext ECG-Text-Image), the first large-scale ECG dataset that synchronizes raw waveform data, high-resolution plotted images, and detailed textual interpretations generated by large language models. In addition, MEETI includes beat-level quantitative ECG parameters extracted from each lead, offering structured parameters that support fine-grained analysis and model interpretability. Each MEETI record is aligned across four components: (1) the raw ECG waveform, (2) the corresponding plotted image, (3) extracted feature parameters, and (4) detailed interpretation text. This alignment is achieved using consistent, unique identifiers. This unified structure supports transformer-based multimodal learning and supports fine-grained, interpretable reasoning about cardiac health. By bridging the gap between traditional signal analysis, image-based interpretation, and language-driven understanding, MEETI established a robust foundation for the next generation of explainable, multimodal cardiovascular AI. It offers the research community a comprehensive benchmark for developing and evaluating ECG-based AI systems.', 'abstract_zh': '心电图（ECG）在现代心血管护理中发挥着基础性作用，能够实现无创性心律失常、心肌缺血和传导障碍的诊断。虽然机器学习在ECG解释方面已达到专家级水平，但临床可部署的多模态AI系统的开发仍受限于缺乏能够同时包含原始信号、诊断图像和解释文本的公开数据集。大多数现有的ECG数据集仅提供单模态数据，或者最多提供双模态数据，使得在现实环境中构建能够理解和整合各种ECG信息的模型变得困难。为解决这一问题，我们引入了MEETI（MIMIC-IV-Ext ECG-Text-Image），这是首个同步包含原始波形数据、高分辨率绘制图像和由大型语言模型生成的详细文本解释的大规模ECG数据集。此外，MEETI 还包含从每个导联提取的节律水平定量ECG参数，提供支持精细分析和模型可解释性的结构化参数。每条MEETI记录在四个组件上对齐：（1）原始ECG波形，（2）对应的绘制图像，（3）提取的特征参数，和（4）详细的解释文本。这种对齐通过一致的唯一标识符实现。这种统一结构支持基于变换器的多模态学习，并支持对心脏健康的细粒度、可解释推理。通过在传统信号分析、基于图像的解释和语言驱动的理解之间建立桥梁，MEETI 为下一代可解释的多模态心血管AI奠定了坚实基础。它为研究社区提供了一个全面的基准，以开发和评估基于ECG的AI系统。', 'title_zh': 'MEETI: MIMIC-IV-ECG多模态心电图数据集，包含信号、图像、特征和解释'}
{'arxiv_id': 'arXiv:2507.15254', 'title': 'User Head Movement-Predictive XR in Immersive H2M Collaborations over Future Enterprise Networks', 'authors': 'Sourav Mondal, Elaine Wong', 'link': 'https://arxiv.org/abs/2507.15254', 'abstract': "The evolution towards future generation of mobile systems and fixed wireless networks is primarily driven by the urgency to support high-bandwidth and low-latency services across various vertical sectors. This endeavor is fueled by smartphones as well as technologies like industrial internet of things, extended reality (XR), and human-to-machine (H2M) collaborations for fostering industrial and social revolutions like Industry 4.0/5.0 and Society 5.0. To ensure an ideal immersive experience and avoid cyber-sickness for users in all the aforementioned usage scenarios, it is typically challenging to synchronize XR content from a remote machine to a human collaborator according to their head movements across a large geographic span in real-time over communication networks. Thus, we propose a novel H2M collaboration scheme where the human's head movements are predicted ahead with highly accurate models like bidirectional long short-term memory networks to orient the machine's camera in advance. We validate that XR frame size varies in accordance with the human's head movements and predict the corresponding bandwidth requirements from the machine's camera to propose a human-machine coordinated dynamic bandwidth allocation (HMC-DBA) scheme. Through extensive simulations, we show that end-to-end latency and jitter requirements of XR frames are satisfied with much lower bandwidth consumption over enterprise networks like Fiber-To-The-Room-Business. Furthermore, we show that better efficiency in network resource utilization is achieved by employing our proposed HMC-DBA over state-of-the-art schemes.", 'abstract_zh': '面向未来移动系统和固定无线网络演化的进展主要由支持各种垂直领域内的高带宽和低延迟服务的紧迫需求驱动。这一努力受到智能手机、工业互联网、扩展现实（XR）以及人机（H2M）协作等技术的推动，旨在促进如工业4.0/5.0和社会5.0等工业和社会革命。为了确保所有上述应用场景中用户获得理想的沉浸式体验并避免网络晕动症，在大范围内实时通过通信网络根据人体头部运动同步XR内容通常具有挑战性。因此，我们提出了一种新颖的人机协作方案，利用双向长短期记忆网络等高精度模型提前预测人体头部运动，从而使机器的相机提前对准。我们验证XR帧大小会根据人体头部运动而变化，并据此预测来自机器相机的相应带宽需求，提出了一种人机协同动态带宽分配（HMC-DBA）方案。通过广泛的仿真实验，我们证明在光纤到办公室企业网络等企业网络中，使用我们的HMC-DBA方案可以显著降低带宽消耗，同时满足XR帧的端到端时延和抖动要求。此外，我们展示了在先进的网络资源利用效率方面，我们的HMC-DBA方案优于现有方案。', 'title_zh': '用户头部运动预测的XR在未来的enterprise网络中沉浸式H2M协作'}
{'arxiv_id': 'arXiv:2507.15246', 'title': 'Spatio-Temporal Demand Prediction for Food Delivery Using Attention-Driven Graph Neural Networks', 'authors': 'Rabia Latief Bhat, Iqra Altaf Gillani', 'link': 'https://arxiv.org/abs/2507.15246', 'abstract': 'Accurate demand forecasting is critical for enhancing the efficiency and responsiveness of food delivery platforms, where spatial heterogeneity and temporal fluctuations in order volumes directly influence operational decisions. This paper proposes an attention-based Graph Neural Network framework that captures spatial-temporal dependencies by modeling the food delivery environment as a graph. In this graph, nodes represent urban delivery zones, while edges reflect spatial proximity and inter-regional order flow patterns derived from historical data. The attention mechanism dynamically weighs the influence of neighboring zones, enabling the model to focus on the most contextually relevant areas during prediction. Temporal trends are jointly learned alongside spatial interactions, allowing the model to adapt to evolving demand patterns. Extensive experiments on real-world food delivery datasets demonstrate the superiority of the proposed model in forecasting future order volumes with high accuracy. The framework offers a scalable and adaptive solution to support proactive fleet positioning, resource allocation, and dispatch optimization in urban food delivery operations.', 'abstract_zh': '基于注意力机制的图神经网络框架：增强食物配送平台效率和响应性的时空依赖性预测', 'title_zh': '基于注意力驱动图神经网络的食品配送时空需求预测'}
{'arxiv_id': 'arXiv:2507.15245', 'title': 'SPAR: Scholar Paper Retrieval with LLM-based Agents for Enhanced Academic Search', 'authors': 'Xiaofeng Shi, Yuduo Li, Qian Kou, Longbin Yu, Jinxin Xie, Hua Zhou', 'link': 'https://arxiv.org/abs/2507.15245', 'abstract': 'Recent advances in large language models (LLMs) have opened new opportunities for academic literature retrieval. However, existing systems often rely on rigid pipelines and exhibit limited reasoning capabilities. We introduce SPAR, a multi-agent framework that incorporates RefChain-based query decomposition and query evolution to enable more flexible and effective search. To facilitate systematic evaluation, we also construct SPARBench, a challenging benchmark with expert-annotated relevance labels. Experimental results demonstrate that SPAR substantially outperforms strong baselines, achieving up to +56% F1 on AutoScholar and +23% F1 on SPARBench over the best-performing baseline. Together, SPAR and SPARBench provide a scalable, interpretable, and high-performing foundation for advancing research in scholarly retrieval. Code and data will be available at: this https URL', 'abstract_zh': 'recent 进展在大规模语言模型 (LLMs) 为学术文献检索开辟了新的机会。然而，现有系统往往依赖于僵化的管道并表现出有限的推理能力。我们引入了 SPAR，一种结合 RefChain 基础的查询分解和查询演化的多代理框架，以实现更灵活和有效的搜索。为了便于系统评估，我们还构建了 SPARBench，这是一个具有专家标注相关性标签的具有挑战性的基准。实验结果表明，SPAR 显著优于强大的基线，在 AutoScholar 上 F1 得分提高了 56%，在 SPARBench 上提高了 23%，与最佳基线相比。总的来说，SPAR 和 SPARBench 为推进学术检索研究提供了一个可扩展、可解释且高性能的基础。代码和数据可在以下网址获得：this https URL。', 'title_zh': 'SPAR：基于LLM代理的学者论文检索以增强学术搜索'}
{'arxiv_id': 'arXiv:2507.15243', 'title': 'Cross-Domain Few-Shot Learning with Coalescent Projections and Latent Space Reservation', 'authors': 'Naeem Paeedeh, Mahardhika Pratama, Wolfgang Mayer, Jimmy Cao, Ryszard Kowlczyk', 'link': 'https://arxiv.org/abs/2507.15243', 'abstract': 'Despite the progress in Cross-Domain Few-Shot Learning (CD-FSL), a model pre-trained with DINO combined with a prototypical classifier outperforms the latest SOTA methods. A crucial limitation that needs to be overcome is that updating too many parameters of the transformers leads to overfitting due to the scarcity of labeled samples. To address this challenge, we propose a new concept, Coalescent Projection (CP), as an effective successor to soft prompts. Additionally, we propose a novel pseudo-class generation method combined with Self-Supervised Transformations (SSTs) that relies solely on the base domain to prepare the network for encountering unseen samples from different domains. The proposed method exhibits its effectiveness in comprehensive experiments on the extreme domain shift scenario of the BSCD-FSL benchmark. Our code is published at this https URL.', 'abstract_zh': '尽管在跨领域少量样本学习（CD-FSL）方面取得了进展，但使用DINO预训练模型结合原型分类器的表现仍优于最新SOTA方法。克服的关键限制是，更新太多变压器参数由于标注样本稀缺会导致过拟合。为应对这一挑战，我们提出了一种新的概念——共轭投影（CP），作为soft prompts的有效替代方案。此外，我们提出了一种新的伪类生成方法，并结合自监督变换（SSTs），仅依赖基域为网络准备处理来自不同领域未见过的样本。所提出的方法在BSCD-FSL基准的极端领域移转动态场景下的全面实验中显示出其有效性。我们的代码发布于此网址。', 'title_zh': '跨领域少样本学习中的共融投影与潜在空间预留'}
{'arxiv_id': 'arXiv:2507.15224', 'title': 'SimdBench: Benchmarking Large Language Models for SIMD-Intrinsic Code Generation', 'authors': 'Yibo He, Shuoran Zhao, Jiaming Huang, Yingjie Fu, Hao Yu, Cunjian Huang, Tao Xie', 'link': 'https://arxiv.org/abs/2507.15224', 'abstract': 'SIMD (Single Instruction Multiple Data) instructions and their compiler intrinsics are widely supported by modern processors to accelerate performance-critical tasks. SIMD intrinsic programming, a trade-off between coding productivity and high performance, is widely used in the development of mainstream performance-critical libraries and daily computing tasks. Large Language Models (LLMs), which have demonstrated strong and comprehensive capabilities in code generation, show promise in assisting programmers with the challenges of SIMD intrinsic programming. However, existing code-generation benchmarks focus on only scalar code, and it is unclear how LLMs perform in generating vectorized code using SIMD intrinsics. To fill this gap, we propose SimdBench, the first code benchmark specifically designed for SIMD-intrinsic code generation, comprising 136 carefully crafted tasks and targeting five representative SIMD intrinsics: SSE (x86 Streaming SIMD Extension), AVX (x86 Advanced Vector Extension), Neon (ARM Advanced SIMD Extension), SVE (ARM Scalable Vector Extension), and RVV (RISC-V Vector Extension). We conduct a systematic evaluation (measuring both correctness and performance) of 18 representative LLMs on SimdBench, resulting in a series of novel and insightful findings. Our evaluation results demonstrate that LLMs exhibit a universal decrease in pass@k during SIMD-intrinsic code generation compared to scalar-code generation. Our in-depth analysis highlights promising directions for the further advancement of LLMs in the challenging domain of SIMD-intrinsic code generation. SimdBench is fully open source at this https URL to benefit the broader research community.', 'abstract_zh': 'SIMD指令及其编译器内置函数在现代处理器中广泛支持以加速关键任务性能。SIMD内置函数编程在提高编码生产力和高性能之间是一种权衡，在主流关键性能库和日常计算任务的开发中广泛应用。大型语言模型（LLMs）展示了在代码生成方面的强大和全面能力，显示出在帮助程序员应对SIMD内置函数编程的挑战方面的潜力。然而，现有的代码生成基准主要集中在标量代码上，尚不清楚LLMs在使用SIMD内置函数生成向量代码方面的表现。为了填补这一空白，我们提出了SimdBench，这是第一个专门针对SIMD内置函数代码生成的代码基准，包含136个精心设计的任务，并针对五种代表性SIMD内置函数：SSE（x86 流式SIMD扩展）、AVX（x86 高级向量扩展）、Neon（ARM 高级SIMD扩展）、SVE（ARM 可扩展向量扩展）和RVV（RISC-V 向量扩展）。我们系统地评估了18个代表性LLMs在SimdBench上的表现（从正确性和性能两个方面进行测量），得出了一系列新的见解。我们的评估结果表明，与标量代码生成相比，LLMs在SIMD内置函数代码生成期间表现出普遍存在准确率下降的现象。我们深入的分析指出了LLMs在这一具有挑战性的SIMD内置函数代码生成领域进一步发展的有希望的方向。SimdBench完全开源，可以在以下链接访问，以惠及更广泛的科研社区。', 'title_zh': 'SimdBench: 评估面向SIMD内禀代码生成的大规模语言模型'}
{'arxiv_id': 'arXiv:2507.15219', 'title': 'PromptArmor: Simple yet Effective Prompt Injection Defenses', 'authors': 'Tianneng Shi, Kaijie Zhu, Zhun Wang, Yuqi Jia, Will Cai, Weida Liang, Haonan Wang, Hend Alzahrani, Joshua Lu, Kenji Kawaguchi, Basel Alomair, Xuandong Zhao, William Yang Wang, Neil Gong, Wenbo Guo, Dawn Song', 'link': 'https://arxiv.org/abs/2507.15219', 'abstract': "Despite their potential, recent research has demonstrated that LLM agents are vulnerable to prompt injection attacks, where malicious prompts are injected into the agent's input, causing it to perform an attacker-specified task rather than the intended task provided by the user. In this paper, we present PromptArmor, a simple yet effective defense against prompt injection attacks. Specifically, PromptArmor prompts an off-the-shelf LLM to detect and remove potential injected prompts from the input before the agent processes it. Our results show that PromptArmor can accurately identify and remove injected prompts. For example, using GPT-4o, GPT-4.1, or o4-mini, PromptArmor achieves both a false positive rate and a false negative rate below 1% on the AgentDojo benchmark. Moreover, after removing injected prompts with PromptArmor, the attack success rate drops to below 1%. We also demonstrate PromptArmor's effectiveness against adaptive attacks and explore different strategies for prompting an LLM. We recommend that PromptArmor be adopted as a standard baseline for evaluating new defenses against prompt injection attacks.", 'abstract_zh': '尽管大规模语言模型代理具有潜在优势，但最近的研究表明它们容易受到提示注入攻击的影响，即恶意提示被注入到代理的输入中，使其执行攻击者指定的任务而非用户提供的任务。本文提出了一种名为PromptArmor的简单而有效的提示注入攻击防御方法。具体而言，PromptArmor促使一个现成的大规模语言模型检测并从输入中移除潜在的注入提示，然后再让代理处理这些输入。我们的研究表明，PromptArmor能够准确识别并移除注入的提示。例如，使用GPT-4o、GPT-4.1或o4-mini，PromptArmor在AgentDojo基准测试中的假阳性率和假阴性率均低于1%。此外，在使用PromptArmor移除注入提示后，攻击成功率降至低于1%。我们还展示了PromptArmor对适应性攻击的有效性，并探讨了不同提示大规模语言模型的方法。我们建议将PromptArmor作为评估新型提示注入攻击防御方法的标准基准。', 'title_zh': 'PromptArmor：简单而有效的提示注入防御'}
{'arxiv_id': 'arXiv:2507.15205', 'title': 'Long-Short Distance Graph Neural Networks and Improved Curriculum Learning for Emotion Recognition in Conversation', 'authors': 'Xinran Li, Xiujuan Xu, Jiaqi Qiao', 'link': 'https://arxiv.org/abs/2507.15205', 'abstract': 'Emotion Recognition in Conversation (ERC) is a practical and challenging task. This paper proposes a novel multimodal approach, the Long-Short Distance Graph Neural Network (LSDGNN). Based on the Directed Acyclic Graph (DAG), it constructs a long-distance graph neural network and a short-distance graph neural network to obtain multimodal features of distant and nearby utterances, respectively. To ensure that long- and short-distance features are as distinct as possible in representation while enabling mutual influence between the two modules, we employ a Differential Regularizer and incorporate a BiAffine Module to facilitate feature interaction. In addition, we propose an Improved Curriculum Learning (ICL) to address the challenge of data imbalance. By computing the similarity between different emotions to emphasize the shifts in similar emotions, we design a "weighted emotional shift" metric and develop a difficulty measurer, enabling a training process that prioritizes learning easy samples before harder ones. Experimental results on the IEMOCAP and MELD datasets demonstrate that our model outperforms existing benchmarks.', 'abstract_zh': '对话中的情感识别（ERC）是一项实用而具挑战性的任务。本文提出了一种新颖的多模态方法，即长短距离图神经网络（LSDGNN）。基于有向无环图（DAG），该方法构建了长距离图神经网络和短距离图神经网络，分别获取远距离和近距离话轮的多模态特征。为了确保长距离和短距离特征在表示上尽可能不同同时允许两个模块之间的相互影响，我们采用了差分正则化器，并结合BiAffine模块以促进特征交互。此外，我们提出了改进的curriculum学习（ICL）以应对数据不平衡的挑战。通过计算不同情感之间的相似性来强调类似情感的变化，我们设计了“加权情感转移”度量，并开发了一个难度度量器，使训练过程能够优先学习容易样本，然后再学习更难的样本。在IEMOCAP和MELD数据集上的实验结果表明，我们的模型优于现有基准。', 'title_zh': '长短期距离图神经网络及改进的递进学习在对话情感识别中的应用'}
{'arxiv_id': 'arXiv:2507.15193', 'title': 'A Study of Anatomical Priors for Deep Learning-Based Segmentation of Pheochromocytoma in Abdominal CT', 'authors': 'Tanjin Taher Toma, Tejas Sudharshan Mathai, Bikash Santra, Pritam Mukherjee, Jianfei Liu, Wesley Jong, Darwish Alabyad, Vivek Batheja, Abhishek Jha, Mayank Patel, Darko Pucar, Jayadira del Rivero, Karel Pacak, Ronald M. Summers', 'link': 'https://arxiv.org/abs/2507.15193', 'abstract': 'Accurate segmentation of pheochromocytoma (PCC) in abdominal CT scans is essential for tumor burden estimation, prognosis, and treatment planning. It may also help infer genetic clusters, reducing reliance on expensive testing. This study systematically evaluates anatomical priors to identify configurations that improve deep learning-based PCC segmentation. We employed the nnU-Net framework to evaluate eleven annotation strategies for accurate 3D segmentation of pheochromocytoma, introducing a set of novel multi-class schemes based on organ-specific anatomical priors. These priors were derived from adjacent organs commonly surrounding adrenal tumors (e.g., liver, spleen, kidney, aorta, adrenal gland, and pancreas), and were compared against a broad body-region prior used in previous work. The framework was trained and tested on 105 contrast-enhanced CT scans from 91 patients at the NIH Clinical Center. Performance was measured using Dice Similarity Coefficient (DSC), Normalized Surface Distance (NSD), and instance-wise F1 score. Among all strategies, the Tumor + Kidney + Aorta (TKA) annotation achieved the highest segmentation accuracy, significantly outperforming the previously used Tumor + Body (TB) annotation across DSC (p = 0.0097), NSD (p = 0.0110), and F1 score (25.84% improvement at an IoU threshold of 0.5), measured on a 70-30 train-test split. The TKA model also showed superior tumor burden quantification (R^2 = 0.968) and strong segmentation across all genetic subtypes. In five-fold cross-validation, TKA consistently outperformed TB across IoU thresholds (0.1 to 0.5), reinforcing its robustness and generalizability. These findings highlight the value of incorporating relevant anatomical context in deep learning models to achieve precise PCC segmentation, supporting clinical assessment and longitudinal monitoring.', 'abstract_zh': '腹腔CT扫描中嗜铬细胞瘤的精确分割对于瘤负荷估计、预后和治疗规划至关重要。它也可能有助于推断基因簇，减少对昂贵的检测依赖。本研究系统评估解剖先验知识，以识别提高基于深度学习的嗜铬细胞瘤分割效果的配置。我们采用了nnU-Net框架，对嗜铬细胞瘤进行准确的3D分割策略进行了评估，引入了一套基于器官特定解剖先验知识的新型多分类方案。这些先验知识来源于常伴随肾上腺肿瘤的邻近器官（如肝脏、脾脏、肾脏、主动脉、肾上腺和胰腺），并与前人工作中使用的广泛体区先验知识进行了比较。该框架在NIH临床中心的91名患者中的105例对比增强CT扫描数据上进行了训练和测试。性能通过Dice相似性系数（DSC）、归一化表面距离（NSD）和实例F1分数进行衡量。在所有策略中，肿瘤+肾脏+主动脉（TKA）标注实现了最高的分割精度，显著优于之前使用的肿瘤+体区（TB）标注，在DSC（p = 0.0097）、NSD（p = 0.0110）和F1分数（在交并比阈值为0.5时提高25.84%）上表现更佳，采用70-30训练-测试分割。TKA模型在肿瘤负荷定量（R² = 0.968）和所有遗传亚型上的分割表现也更优。在五折交叉验证中，TKA在交并比阈值（0.1到0.5）上均优于TB，增强了其稳健性和泛化能力。这些发现强调了在深度学习模型中整合相关解剖上下文的重要性，以实现精确的嗜铬细胞瘤分割，支持临床评估和纵向监测。', 'title_zh': '基于深度学习的腹部CT嗜铬细胞瘤分割中解剖先验的研究'}
{'arxiv_id': 'arXiv:2507.15157', 'title': 'Can LLMs Generate User Stories and Assess Their Quality?', 'authors': 'Giovanni Quattrocchi, Liliana Pasquale, Paola Spoletini, Luciano Baresi', 'link': 'https://arxiv.org/abs/2507.15157', 'abstract': 'Requirements elicitation is still one of the most challenging activities of the requirements engineering process due to the difficulty requirements analysts face in understanding and translating complex needs into concrete requirements. In addition, specifying high-quality requirements is crucial, as it can directly impact the quality of the software to be developed. Although automated tools allow for assessing the syntactic quality of requirements, evaluating semantic metrics (e.g., language clarity, internal consistency) remains a manual and time-consuming activity. This paper explores how LLMs can help automate requirements elicitation within agile frameworks, where requirements are defined as user stories (US). We used 10 state-of-the-art LLMs to investigate their ability to generate US automatically by emulating customer interviews. We evaluated the quality of US generated by LLMs, comparing it with the quality of US generated by humans (domain experts and students). We also explored whether and how LLMs can be used to automatically evaluate the semantic quality of US. Our results indicate that LLMs can generate US similar to humans in terms of coverage and stylistic quality, but exhibit lower diversity and creativity. Although LLM-generated US are generally comparable in quality to those created by humans, they tend to meet the acceptance quality criteria less frequently, regardless of the scale of the LLM model. Finally, LLMs can reliably assess the semantic quality of US when provided with clear evaluation criteria and have the potential to reduce human effort in large-scale assessments.', 'abstract_zh': 'LLMs在敏捷框架中辅助自动需求获取的应用探讨', 'title_zh': 'LLMs能生成用户故事并评估其质量？'}
{'arxiv_id': 'arXiv:2507.15156', 'title': 'Constraint-aware Learning of Probabilistic Sequential Models for Multi-Label Classification', 'authors': 'Mykhailo Buleshnyi, Anna Polova, Zsolt Zombori, Michael Benedikt', 'link': 'https://arxiv.org/abs/2507.15156', 'abstract': 'We investigate multi-label classification involving large sets of labels, where the output labels may be known to satisfy some logical constraints. We look at an architecture in which classifiers for individual labels are fed into an expressive sequential model, which produces a joint distribution. One of the potential advantages for such an expressive model is its ability to modelling correlations, as can arise from constraints. We empirically demonstrate the ability of the architecture both to exploit constraints in training and to enforce constraints at inference time.', 'abstract_zh': '大规模标签集的多标签分类：利用表达性强的模型挖掘和应用标签约束', 'title_zh': '基于约束的学习：概率序列模型在多标签分类中的应用'}
{'arxiv_id': 'arXiv:2507.15152', 'title': 'What Level of Automation is "Good Enough"? A Benchmark of Large Language Models for Meta-Analysis Data Extraction', 'authors': 'Lingbo Li, Anuradha Mathrani, Teo Susnjak', 'link': 'https://arxiv.org/abs/2507.15152', 'abstract': 'Automating data extraction from full-text randomised controlled trials (RCTs) for meta-analysis remains a significant challenge. This study evaluates the practical performance of three LLMs (Gemini-2.0-flash, Grok-3, GPT-4o-mini) across tasks involving statistical results, risk-of-bias assessments, and study-level characteristics in three medical domains: hypertension, diabetes, and orthopaedics. We tested four distinct prompting strategies (basic prompting, self-reflective prompting, model ensemble, and customised prompts) to determine how to improve extraction quality. All models demonstrate high precision but consistently suffer from poor recall by omitting key information. We found that customised prompts were the most effective, boosting recall by up to 15\\%. Based on this analysis, we propose a three-tiered set of guidelines for using LLMs in data extraction, matching data types to appropriate levels of automation based on task complexity and risk. Our study offers practical advice for automating data extraction in real-world meta-analyses, balancing LLM efficiency with expert oversight through targeted, task-specific automation.', 'abstract_zh': '自动化从全文随机对照试验（RCT）中提取数据以进行meta分析仍然是一个重大挑战。本研究评估了三种大规模语言模型（Gemini-2.0-flash、Grok-3、GPT-4o-mini）在涉及统计结果、偏倚风险评估和三项医学领域（高血压、糖尿病、骨科）研究级别特征任务中的实用性能。我们测试了四种不同的提示策略（基本提示、反思性提示、模型集成和定制提示），以确定如何提高提取质量。所有模型显示出高精确度，但一致地由于忽略了关键信息而表现不佳。我们发现定制提示最有效，可将召回率提高多达15%。基于此分析，我们提出了一个分层指南，用于使用大规模语言模型进行数据提取，根据任务复杂性和风险匹配适当级别的自动化。我们的研究为实境meta分析中的数据自动化提取提供了实用建议，并通过有针对性的任务特定自动化平衡了语言模型的效率和专家监督。', 'title_zh': '最佳自动化水平是什么？元分析数据提取的大规模语言模型基准'}
{'arxiv_id': 'arXiv:2507.15151', 'title': 'Performance Analysis of Post-Training Quantization for CNN-based Conjunctival Pallor Anemia Detection', 'authors': 'Sebastian A. Cruz Romero, Wilfredo E. Lugo Beauchamp', 'link': 'https://arxiv.org/abs/2507.15151', 'abstract': 'Anemia is a widespread global health issue, particularly among young children in low-resource settings. Traditional methods for anemia detection often require expensive equipment and expert knowledge, creating barriers to early and accurate diagnosis. To address these challenges, we explore the use of deep learning models for detecting anemia through conjunctival pallor, focusing on the CP-AnemiC dataset, which includes 710 images from children aged 6-59 months. The dataset is annotated with hemoglobin levels, gender, age and other demographic data, enabling the development of machine learning models for accurate anemia detection. We use the MobileNet architecture as a backbone, known for its efficiency in mobile and embedded vision applications, and fine-tune our model end-to-end using data augmentation techniques and a cross-validation strategy. Our model implementation achieved an accuracy of 0.9313, a precision of 0.9374, and an F1 score of 0.9773 demonstrating strong performance on the dataset. To optimize the model for deployment on edge devices, we performed post-training quantization, evaluating the impact of different bit-widths (FP32, FP16, INT8, and INT4) on model performance. Preliminary results suggest that while FP16 quantization maintains high accuracy (0.9250), precision (0.9370), and F1 Score (0.9377), more aggressive quantization (INT8 and INT4) leads to significant performance degradation. Overall, our study supports further exploration of quantization schemes and hardware optimizations to assess trade-offs between model size, inference time, and diagnostic accuracy in mobile healthcare applications.', 'abstract_zh': '贫血是全球范围内一个普遍的公共卫生问题，特别是在低资源环境下的年轻儿童中更为突出。传统的贫血检测方法往往需要昂贵的设备和专业知识，造成了早期和准确诊断的障碍。为了解决这些问题，我们探索了使用深度学习模型通过结膜苍白来检测贫血的方法，重点关注包含6-59个月儿童710张图像的CP-AnemiC数据集。该数据集标注了血红蛋白水平、性别、年龄和其他人口统计学数据，有助于开发准确的贫血检测机器学习模型。我们采用了MobileNet架构作为基础模型，该架构在移动和嵌入式视觉应用中以高效著称，并通过数据增强技术和交叉验证策略对模型进行了端到端的微调。我们的模型实施在数据集上实现了0.9313的准确率、0.9374的精确率和0.9773的F1分数，显示出良好的性能。为了在边缘设备上优化模型部署，我们进行了后训练量化，评估了不同位宽（FP32、FP16、INT8和INT4）对模型性能的影响。初步结果表明，虽然FP16量化能保持高准确率（0.9250）、精确率（0.9370）和F1分数（0.9377），更具侵略性的量化（INT8和INT4）会导致显著的性能下降。总体而言，我们的研究支持进一步探索量化方案和硬件优化，以评估在移动医疗应用中模型大小、推理时间和诊断准确性之间的权衡。', 'title_zh': '基于卷积神经网络的眼袋苍白贫血检测模型训练后量化性能分析'}
{'arxiv_id': 'arXiv:2507.15146', 'title': 'Design of an Edge-based Portable EHR System for Anemia Screening in Remote Health Applications', 'authors': 'Sebastian A. Cruz Romero, Misael J. Mercado Hernandez, Samir Y. Ali Rivera, Jorge A. Santiago Fernandez, Wilfredo E. Lugo Beauchamp', 'link': 'https://arxiv.org/abs/2507.15146', 'abstract': 'The design of medical systems for remote, resource-limited environments faces persistent challenges due to poor interoperability, lack of offline support, and dependency on costly infrastructure. Many existing digital health solutions neglect these constraints, limiting their effectiveness for frontline health workers in underserved regions. This paper presents a portable, edge-enabled Electronic Health Record platform optimized for offline-first operation, secure patient data management, and modular diagnostic integration. Running on small-form factor embedded devices, it provides AES-256 encrypted local storage with optional cloud synchronization for interoperability. As a use case, we integrated a non-invasive anemia screening module leveraging fingernail pallor analysis. Trained on 250 patient cases (27\\% anemia prevalence) with KDE-balanced data, the Random Forest model achieved a test RMSE of 1.969 g/dL and MAE of 1.490 g/dL. A severity-based model reached 79.2\\% sensitivity. To optimize performance, a YOLOv8n-based nail bed detector was quantized to INT8, reducing inference latency from 46.96 ms to 21.50 ms while maintaining mAP@0.5 at 0.995. The system emphasizes low-cost deployment, modularity, and data privacy compliance (HIPAA/GDPR), addressing critical barriers to digital health adoption in disconnected settings. Our work demonstrates a scalable approach to enhance portable health information systems and support frontline healthcare in underserved regions.', 'abstract_zh': '面向资源受限环境的远程医疗系统设计面临持续挑战，主要原因包括互联互通差、缺乏离线支持以及依赖昂贵的基础设施。许多现有的数字健康解决方案忽视了这些限制，限制了它们在欠服务地区前线医疗工作者中的有效性。本文提出了一种便携式、边缘计算增强的电子健康记录平台，该平台针对离线优先操作、安全的患者数据管理和模块化的诊断集成进行了优化。该平台运行在小尺寸嵌入式设备上，提供AES-256加密的本地存储，并可选地与云端同步以实现互联互通。作为使用案例，我们集成了一个利用指甲苍白分析的非侵入性贫血筛查模块。模型在250例患者病例（贫血发病率27%）的KDE平衡数据上进行训练，测试RMSE为1.969 g/dL，MAE为1.490 g/dL，基于严重程度的模型达到了79.2%的敏感性。为了优化性能，基于YOLOv8n的手指甲床检测器被量化为INT8，推理延迟从46.96 ms降低到21.50 ms，同时保持mAP@0.5为0.995。该系统强调低成本部署、模块化和数据隐私合规（HIPAA/GDPR），以解决孤立环境中数字健康采纳的关键障碍。我们的工作展示了增强便携式健康信息系统并支持欠服务地区前线医疗的可扩展方法。', 'title_zh': '边缘计算驱动的便携式 marzo 检筛系统在远程健康应用中的设计'}
{'arxiv_id': 'arXiv:2507.15142', 'title': "A Case Against Implicit Standards: Homophone Normalization in Machine Translation for Languages that use the Ge'ez Script", 'authors': 'Hellina Hailu Nigatu, Atnafu Lambebo Tonja, Henok Biadglign Ademtew, Hizkel Mitiku Alemayehu, Negasi Haile Abadi, Tadesse Destaw Belay, Seid Muhie Yimam', 'link': 'https://arxiv.org/abs/2507.15142', 'abstract': "Homophone normalization, where characters that have the same sound in a writing script are mapped to one character, is a pre-processing step applied in Amharic Natural Language Processing (NLP) literature. While this may improve performance reported by automatic metrics, it also results in models that are not able to understand different forms of writing in a single language. Further, there might be impacts in transfer learning, where models trained on normalized data do not generalize well to other languages. In this paper, we experiment with monolingual training and cross-lingual transfer to understand the impacts of normalization on languages that use the Ge'ez script. We then propose a post-inference intervention in which normalization is applied to model predictions instead of training data. With our simple scheme of post-inference normalization, we show that we can achieve an increase in BLEU score of up to 1.03 while preserving language features in training. Our work contributes to the broader discussion on technology-facilitated language change and calls for more language-aware interventions.", 'abstract_zh': '同音字符规范化在阿姆哈拉语自然语言处理中的影响及对策研究', 'title_zh': '反对隐含标准：使用 Geez 字母-script 语言的机器翻译中的同音词规范化'}
{'arxiv_id': 'arXiv:2507.15104', 'title': 'AnalogFed: Federated Discovery of Analog Circuit Topologies with Generative AI', 'authors': 'Qiufeng Li, Shu Hong, Jian Gao, Xuan Zhang, Tian Lan, Weidong Cao', 'link': 'https://arxiv.org/abs/2507.15104', 'abstract': 'Recent breakthroughs in AI/ML offer exciting opportunities to revolutionize analog design automation through data-driven approaches. In particular, researchers are increasingly fascinated by harnessing the power of generative AI to automate the discovery of novel analog circuit topologies. Unlocking the full potential of generative AI in these data-driven discoveries requires access to large and diverse this http URL, there is a significant barrier in the analog domain--Analog circuit design is inherently proprietary, involving not only confidential circuit structures but also the underlying commercial semiconductor processes. As a result, current generative AI research is largely confined to individual researchers who construct small, narrowly focused private datasets. This fragmentation severely limits collaborative innovation and impedes progress across the research community. To address these challenges, we propose AnalogFed. AnalogFed enables collaborative topology discovery across decentralized clients (e.g., individual researchers or institutions) without requiring the sharing of raw private data. To make this vision practical, we introduce a suite of techniques tailored to the unique challenges of applying FedL in analog design--from generative model development and data heterogeneity handling to privacy-preserving strategies that ensure both flexibility and security for circuit designers and semiconductor manufacturers. Extensive experiments across varying client counts and dataset sizes demonstrate that AnalogFed achieves performance comparable to centralized baselines--while maintaining strict data privacy. Specifically, the generative AI model within AnalogFed achieves state-of-the-art efficiency and scalability in the design of analog circuit topologies.', 'abstract_zh': 'Recent突破在AI/ML为通过数据驱动方法革新模拟设计自动化提供了激动人心的机会。特别是，研究人员越来越关注利用生成AI的力量自动化新型模拟电路拓扑结构的发现。要充分发挥生成AI在这些数据驱动发现中的潜力，需要访问大量且多样化的数据源，但在模拟领域，存在显著障碍——模拟电路设计本质上是专有的，不仅包括保密的电路结构，还包括底层的商业半导体工艺。因此，当前的生成AI研究主要局限于个别研究人员，他们构建小型、专注的私有数据集。这种分割严重限制了合作创新并阻碍了研究社区的进展。为了解决这些挑战，我们提出了AnalogFed。AnalogFed能够在分散的客户端（如个人研究人员或机构）之间合作发现电路拓扑结构，而不需共享原始私有数据。为了使这一愿景变得可行，我们介绍了针对模拟设计中独特挑战的一系列技术——从生成模型开发和数据异质性处理到保护电路设计师和半导体制造商的隐私和安全的策略。广泛实验表明，AnalogFed在不同客户端数量和数据集大小下，实现了与集中式基准相当的性能——同时严格保护数据隐私。特别是，AnalogFed中的生成AI模型在模拟电路拓扑结构设计方面的效率和可扩展性达到了最先进的水平。', 'title_zh': 'AnalogFed: 使用生成性人工智能进行协作模拟电路拓扑发现'}
{'arxiv_id': 'arXiv:2507.15100', 'title': 'Filling the Gap: Is Commonsense Knowledge Generation useful for Natural Language Inference?', 'authors': 'Chathuri Jayaweera, Brianna Yanqui, Bonnie Dorr', 'link': 'https://arxiv.org/abs/2507.15100', 'abstract': 'Natural Language Inference (NLI) is the task of determining the semantic entailment of a premise for a given hypothesis. The task aims to develop systems that emulate natural human inferential processes where commonsense knowledge plays a major role. However, existing commonsense resources lack sufficient coverage for a variety of premise-hypothesis pairs. This study explores the potential of Large Language Models as commonsense knowledge generators for NLI along two key dimensions: their reliability in generating such knowledge and the impact of that knowledge on prediction accuracy. We adapt and modify existing metrics to assess LLM factuality and consistency in generating in this context. While explicitly incorporating commonsense knowledge does not consistently improve overall results, it effectively helps distinguish entailing instances and moderately improves distinguishing contradictory and neutral inferences.', 'abstract_zh': '自然语言推理（NLI）中大规模语言模型作为常识知识生成器的潜力及其影响', 'title_zh': '填补空白：常识知识生成对自然语言推理有用吗？'}
{'arxiv_id': 'arXiv:2507.15094', 'title': 'BleedOrigin: Dynamic Bleeding Source Localization in Endoscopic Submucosal Dissection via Dual-Stage Detection and Tracking', 'authors': 'Mengya Xu, Rulin Zhou, An Wang, Chaoyang Lyu, Zhen Li, Ning Zhong, Hongliang Ren', 'link': 'https://arxiv.org/abs/2507.15094', 'abstract': 'Intraoperative bleeding during Endoscopic Submucosal Dissection (ESD) poses significant risks, demanding precise, real-time localization and continuous monitoring of the bleeding source for effective hemostatic intervention. In particular, endoscopists have to repeatedly flush to clear blood, allowing only milliseconds to identify bleeding sources, an inefficient process that prolongs operations and elevates patient risks. However, current Artificial Intelligence (AI) methods primarily focus on bleeding region segmentation, overlooking the critical need for accurate bleeding source detection and temporal tracking in the challenging ESD environment, which is marked by frequent visual obstructions and dynamic scene changes. This gap is widened by the lack of specialized datasets, hindering the development of robust AI-assisted guidance systems. To address these challenges, we introduce BleedOrigin-Bench, the first comprehensive ESD bleeding source dataset, featuring 1,771 expert-annotated bleeding sources across 106,222 frames from 44 procedures, supplemented with 39,755 pseudo-labeled frames. This benchmark covers 8 anatomical sites and 6 challenging clinical scenarios. We also present BleedOrigin-Net, a novel dual-stage detection-tracking framework for the bleeding source localization in ESD procedures, addressing the complete workflow from bleeding onset detection to continuous spatial tracking. We compare with widely-used object detection models (YOLOv11/v12), multimodal large language models, and point tracking methods. Extensive evaluation demonstrates state-of-the-art performance, achieving 96.85% frame-level accuracy ($\\pm\\leq8$ frames) for bleeding onset detection, 70.24% pixel-level accuracy ($\\leq100$ px) for initial source detection, and 96.11% pixel-level accuracy ($\\leq100$ px) for point tracking.', 'abstract_zh': '内镜黏膜下切除术(ESD)术中出血的风险管理：BleedOrigin-Bench数据集及BleedOrigin-Net检测-跟踪框架', 'title_zh': 'BleedOrigin: 内镜黏膜下剥离术中动态出血源定位的双阶段检测与跟踪'}
{'arxiv_id': 'arXiv:2507.15087', 'title': 'Evaluation of Coding Schemes for Transformer-based Gene Sequence Modeling', 'authors': 'Chenlei Gong, Yuanhe Tian, Lei Mao, Yan Song', 'link': 'https://arxiv.org/abs/2507.15087', 'abstract': 'Currently, many studies view DNA sequences as a special type of language and utilize Transformers to model them. These studies use fixed-length k-mer segmentation and BPE subword tokenization but lack a systematic evaluation to determine which is superior. We compare k-mer segmentation with k=1,3,4,5,6, a 4,096-token BPE vocabulary, and three positional encoding methods-sinusoidal, AliBi, and RoPE. Each configuration is trained from scratch in 3, 6, 12, and 24-layer Transformer encoders and evaluated on GUE benchmark dataset. In general, BPE delivers higher and more stable performance across tasks by compressing frequent motifs into variable-length tokens, reducing sequence length, and improving model generalization. RoPE excels at capturing periodic motifs and extrapolating to long sequences, while AliBi also performs well on tasks driven by local dependencies. In terms of depth, we observe significant gains when increasing layers from 3 to 12, with only marginal improvements or slight overfitting at 24 layers. This study provides practical guidance for designing tokenization and positional encoding in DNA Transformer models.', 'abstract_zh': '目前，许多研究将DNA序列视为一种特殊类型的语言，并利用Transformer对其进行建模。这些研究使用固定长度的k-mer分段和BPE子词分词，但缺乏系统性的评估以确定哪种方法更优。我们将k-mer分段分别设置为k=1,3,4,5,6，使用4,096个标记的BPE词汇表，并采用三种位置编码方法（正弦、AliBi和RoPE）。每种配置使用3、6、12和24层Transformer编码器从头进行训练，并在GUE基准数据集上进行评估。总体而言，BPE通过将频繁模式压缩为变长标记、缩短序列长度并提高模型泛化能力，提供了更高且更稳定的性能。RoPE在捕捉周期性模式和外推长序列方面表现出色，而AliBi在由局部依赖驱动的任务中表现出色。在深度方面，我们观察到当层数从3增加到12时显着的改进，在24层时仅有边际改进或轻微的过拟合。本研究为设计DNA Transformer模型中的分词和位置编码提供了实用指导。', 'title_zh': '基于变压器的基因序列建模的编码方案评估'}
{'arxiv_id': 'arXiv:2507.15082', 'title': 'Robust Control with Gradient Uncertainty', 'authors': 'Qian Qi', 'link': 'https://arxiv.org/abs/2507.15082', 'abstract': "We introduce a novel extension to robust control theory that explicitly addresses uncertainty in the value function's gradient, a form of uncertainty endemic to applications like reinforcement learning where value functions are approximated. We formulate a zero-sum dynamic game where an adversary perturbs both system dynamics and the value function gradient, leading to a new, highly nonlinear partial differential equation: the Hamilton-Jacobi-Bellman-Isaacs Equation with Gradient Uncertainty (GU-HJBI). We establish its well-posedness by proving a comparison principle for its viscosity solutions under a uniform ellipticity condition. Our analysis of the linear-quadratic (LQ) case yields a key insight: we prove that the classical quadratic value function assumption fails for any non-zero gradient uncertainty, fundamentally altering the problem structure. A formal perturbation analysis characterizes the non-polynomial correction to the value function and the resulting nonlinearity of the optimal control law, which we validate with numerical studies. Finally, we bridge theory to practice by proposing a novel Gradient-Uncertainty-Robust Actor-Critic (GURAC) algorithm, accompanied by an empirical study demonstrating its effectiveness in stabilizing training. This work provides a new direction for robust control, holding significant implications for fields where function approximation is common, including reinforcement learning and computational finance.", 'abstract_zh': '一种考虑梯度不确定性的一致鲁棒控制理论扩展及其应用', 'title_zh': '具有梯度不确定性的鲁棒控制'}
{'arxiv_id': 'arXiv:2507.15072', 'title': 'NavVI: A Telerobotic Simulation with Multimodal Feedback for Visually Impaired Navigation in Warehouse Environments', 'authors': 'Maisha Maimuna, Minhaz Bin Farukee, Sama Nikanfar, Mahfuza Siddiqua, Ayon Roy, Fillia Makedon', 'link': 'https://arxiv.org/abs/2507.15072', 'abstract': "Industrial warehouses are congested with moving forklifts, shelves and personnel, making robot teleoperation particularly risky and demanding for blind and low-vision (BLV) operators. Although accessible teleoperation plays a key role in inclusive workforce participation, systematic research on its use in industrial environments is limited, and few existing studies barely address multimodal guidance designed for BLV users. We present a novel multimodal guidance simulator that enables BLV users to control a mobile robot through a high-fidelity warehouse environment while simultaneously receiving synchronized visual, auditory, and haptic feedback. The system combines a navigation mesh with regular re-planning so routes remain accurate avoiding collisions as forklifts and human avatars move around the warehouse. Users with low vision are guided with a visible path line towards destination; navigational voice cues with clockwise directions announce upcoming turns, and finally proximity-based haptic feedback notifies the users of static and moving obstacles in the path. This real-time, closed-loop system offers a repeatable testbed and algorithmic reference for accessible teleoperation research. The simulator's design principles can be easily adapted to real robots due to the alignment of its navigation, speech, and haptic modules with commercial hardware, supporting rapid feasibility studies and deployment of inclusive telerobotic tools in actual warehouses.", 'abstract_zh': '面向盲和低视力用户的工业仓储环境中的新型多模态指导模拟器', 'title_zh': 'NavVI：面向仓库环境视障导航的多模态反馈远程机器人模拟'}
{'arxiv_id': 'arXiv:2507.15066', 'title': 'Time-RA: Towards Time Series Reasoning for Anomaly with LLM Feedback', 'authors': 'Yiyuan Yang, Zichuan Liu, Lei Song, Kai Ying, Zhiguang Wang, Tom Bamford, Svitlana Vyetrenko, Jiang Bian, Qingsong Wen', 'link': 'https://arxiv.org/abs/2507.15066', 'abstract': 'Time series anomaly detection is critical across various domains, yet current approaches often limit analysis to mere binary anomaly classification without detailed categorization or further explanatory reasoning. To address these limitations, we propose a novel task, Time-series Reasoning for Anomaly (Time-RA) that transforms classical time series anomaly detection from a discriminative into a generative, reasoning-intensive task leveraging Large Language Models (LLMs). Also, we introduce the first real-world multimodal benchmark dataset, RATs40K, explicitly annotated for anomaly reasoning, comprising approximately 40,000 samples across 10 real-world domains. Each sample includes numeric time series data, contextual text information, and visual representations, each annotated with fine-grained categories (14 types for univariate anomalies and 6 for multivariate anomalies) and structured explanatory reasoning. We develop a sophisticated annotation framework utilizing ensemble-generated labels refined through GPT-4-driven feedback, ensuring accuracy and interpretability. Extensive benchmarking of LLMs and multimodal LLMs demonstrates the capabilities and limitations of current models, highlighting the critical role of supervised fine-tuning. Our dataset and task pave the way for significant advancements in interpretable time series anomaly detection and reasoning.', 'abstract_zh': '时间序列异常检测在各个领域都至关重要，但现有方法往往仅限于简单的二元异常分类，缺乏详细的分类或进一步的解释性推理。为解决这些局限，我们提出了一个新的任务——时间序列推理解释异常（Time-RA），该任务通过利用大型语言模型（LLMs）将传统的时序异常检测从判别性任务转化为生成性和推理密集型任务。此外，我们引入了首个面向异常推理解释的多模态基准数据集RATs40K，该数据集包含约40,000个样本，涵盖了10个实际领域的数据。每个样本包括数值时间序列数据、上下文文本信息和视觉表示，并且每一项都用细致粒度的类别（14种类型用于单变量异常和6种用于多变量异常）和结构化的解释性推理进行标注。我们开发了一种复杂的标注框架，利用GPT-4驱动的反馈生成集合标注，并对其进行精炼，以确保准确性和可解释性。通过对LLMs和多模态LLMs的广泛基准测试，展示了当前模型的能力和局限性，突出了监督微调的关键作用。我们的数据集和任务为可解释的时间序列异常检测和推理奠定了重要基础。', 'title_zh': '时间RA：面向异常检测的时间序列推理与LLM反馈研究'}
{'arxiv_id': 'arXiv:2507.15064', 'title': 'StableAnimator++: Overcoming Pose Misalignment and Face Distortion for Human Image Animation', 'authors': 'Shuyuan Tu, Zhen Xing, Xintong Han, Zhi-Qi Cheng, Qi Dai, Chong Luo, Zuxuan Wu, Yu-Gang Jiang', 'link': 'https://arxiv.org/abs/2507.15064', 'abstract': 'Current diffusion models for human image animation often struggle to maintain identity (ID) consistency, especially when the reference image and driving video differ significantly in body size or position. We introduce StableAnimator++, the first ID-preserving video diffusion framework with learnable pose alignment, capable of generating high-quality videos conditioned on a reference image and a pose sequence without any post-processing. Building upon a video diffusion model, StableAnimator++ contains carefully designed modules for both training and inference, striving for identity consistency. In particular, StableAnimator++ first uses learnable layers to predict the similarity transformation matrices between the reference image and the driven poses via injecting guidance from Singular Value Decomposition (SVD). These matrices align the driven poses with the reference image, mitigating misalignment to a great extent. StableAnimator++ then computes image and face embeddings using off-the-shelf encoders, refining the face embeddings via a global content-aware Face Encoder. To further maintain ID, we introduce a distribution-aware ID Adapter that counteracts interference caused by temporal layers while preserving ID via distribution alignment. During the inference stage, we propose a novel Hamilton-Jacobi-Bellman (HJB) based face optimization integrated into the denoising process, guiding the diffusion trajectory for enhanced facial fidelity. Experiments on benchmarks show the effectiveness of StableAnimator++ both qualitatively and quantitatively.', 'abstract_zh': '基于可学习姿态对齐的身份保持视频扩散框架StableAnimator++', 'title_zh': 'StableAnimator++: 克服姿态错位和面部 distortion 的人体图像动画'}
{'arxiv_id': 'arXiv:2507.15062', 'title': 'Touch in the Wild: Learning Fine-Grained Manipulation with a Portable Visuo-Tactile Gripper', 'authors': 'Xinyue Zhu, Binghao Huang, Yunzhu Li', 'link': 'https://arxiv.org/abs/2507.15062', 'abstract': 'Handheld grippers are increasingly used to collect human demonstrations due to their ease of deployment and versatility. However, most existing designs lack tactile sensing, despite the critical role of tactile feedback in precise manipulation. We present a portable, lightweight gripper with integrated tactile sensors that enables synchronized collection of visual and tactile data in diverse, real-world, and in-the-wild settings. Building on this hardware, we propose a cross-modal representation learning framework that integrates visual and tactile signals while preserving their distinct characteristics. The learning procedure allows the emergence of interpretable representations that consistently focus on contacting regions relevant for physical interactions. When used for downstream manipulation tasks, these representations enable more efficient and effective policy learning, supporting precise robotic manipulation based on multimodal feedback. We validate our approach on fine-grained tasks such as test tube insertion and pipette-based fluid transfer, demonstrating improved accuracy and robustness under external disturbances. Our project page is available at this https URL .', 'abstract_zh': '手持式夹爪越来越多地用于收集人类示范，得益于其易于部署和灵活性。然而，现有大多数设计缺乏触觉感知，尽管触觉反馈在精确操作中起着关键作用。我们提出了一种便携且轻量的集成了触觉传感器的夹爪，能够在多样的现实世界和自然场景中同步收集视觉和触觉数据。基于这一硬件，我们提出了一种跨模态表示学习框架，该框架整合了视觉和触觉信号的同时保留其独特的特征。学习过程使得能够生成可解释的表示，这些表示始终集中在与物理交互相关的接触区域上。在用于下游操作任务时，这些表示能够支持基于多模态反馈的更高效和有效的策略学习，从而实现精确的机器人操作。我们通过细粒度任务如试管插入和移液管液体转移实验验证了该方法，显示了在外部干扰下的改进的准确性和鲁棒性。我们的项目页面可在以下链接访问：this https URL。', 'title_zh': '野生环境中的触觉感知：基于便携式视觉-触觉夹持器的细粒度操作学习'}
{'arxiv_id': 'arXiv:2507.15061', 'title': 'WebShaper: Agentically Data Synthesizing via Information-Seeking Formalization', 'authors': 'Zhengwei Tao, Jialong Wu, Wenbiao Yin, Junkai Zhang, Baixuan Li, Haiyang Shen, Kuan Li, Liwen Zhang, Xinyu Wang, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou', 'link': 'https://arxiv.org/abs/2507.15061', 'abstract': 'The advent of Large Language Model (LLM)-powered agents has revolutionized artificial intelligence by enabling solutions to complex, open-ended tasks through web-based information-seeking (IS) capabilities. The scarcity of high-quality training data has limited the development of IS agents. Existing approaches typically adopt an information-driven paradigm that first collects web data and then generates questions based on the retrieval. However, this may lead to inconsistency between information structure and reasoning structure, question and answer. To mitigate, we propose a formalization-driven IS data synthesis framework WebShaper to construct a dataset. WebShaper systematically formalizes IS tasks through set theory. Central to the formalization is the concept of Knowledge Projections (KP), which enables precise control over reasoning structure by KP operation compositions. During synthesis, we begin by creating seed tasks, then use a multi-step expansion process. At each step, an agentic Expander expands the current formal question more complex with retrieval and validation tools based on our formalization. We train our model on the synthesized dataset. Experiment results demonstrate that WebShaper achieves state-of-the-art performance among open-sourced IS agents on GAIA and WebWalkerQA benchmarks.', 'abstract_zh': '基于大型语言模型（LLM）代理的出现通过基于网络的信息寻求能力革新了人工智能，解决了复杂开放任务。信息驱动的数据稀缺限制了信息寻求代理的发展。现有方法通常采用信息驱动的范式，首先收集网络数据，然后根据检索生成问题。然而，这可能导致信息结构与推理结构、问题与答案之间的不一致。为缓解此问题，我们提出了一种形式化驱动的信息寻求数据合成框架WebShaper来构建数据集。WebShaper通过集合论系统地形式化信息寻求任务。形式化的核心概念是知识投影(KP)，通过KP操作组合实现对推理结构的精确控制。在合成过程中，我们首先创建种子任务，然后使用多步骤扩展过程。在每一步中，代理扩展器基于我们的形式化使用检索和验证工具使当前形式化问题变得更加复杂。我们使用合成的数据集训练我们的模型。实验结果表明，WebShaper在GAIA和WebWalkerQA基准测试中实现了开源信息寻求代理的最先进性能。', 'title_zh': 'WebShaper: 基于信息寻求形式化的数据自适应合成'}
{'arxiv_id': 'arXiv:2507.15032', 'title': 'The hunt for new pulsating ultraluminous X-ray sources: a clustering approach', 'authors': 'Nicolò Oreste Pinciroli Vago, Roberta Amato, Matteo Imbrogno, GianLuca Israel, Andrea Belfiore, Konstantinos Kovlakas, Piero Fraternali, Mario Pasquato', 'link': 'https://arxiv.org/abs/2507.15032', 'abstract': 'The discovery of fast and variable coherent signals in a handful of ultraluminous X-ray sources (ULXs) testifies to the presence of super-Eddington accreting neutron stars, and drastically changed the understanding of the ULX class. Our capability of discovering pulsations in ULXs is limited, among others, by poor statistics. However, catalogues and archives of high-energy missions contain information which can be used to identify new candidate pulsating ULXs (PULXs). The goal of this research is to single out candidate PULXs among those ULXs which have not shown pulsations due to an unfavourable combination of factors. We applied an AI approach to an updated database of ULXs detected by XMM-Newton. We first used an unsupervised clustering algorithm to sort out sources with similar characteristics into two clusters. Then, the sample of known PULX observations has been used to set the separation threshold between the two clusters and to identify the one containing the new candidate PULXs. We found that only a few criteria are needed to assign the membership of an observation to one of the two clusters. The cluster of new candidate PULXs counts 85 unique sources for 355 observations, with $\\sim$85% of these new candidates having multiple observations. A preliminary timing analysis found no new pulsations for these candidates. This work presents a sample of new candidate PULXs observed by XMM-Newton, the properties of which are similar (in a multi-dimensional phase space) to those of the known PULXs, despite the absence of pulsations in their light curves. While this result is a clear example of the predictive power of AI-based methods, it also highlights the need for high-statistics observational data to reveal coherent signals from the sources in this sample and thus validate the robustness of the approach.', 'abstract_zh': '超亮X射线源中快速且可变的相干信号的发现证实了超爱丁顿吸积中子星的存在，并极大地改变了对超亮X射线源类别的理解。本研究的目标是在不利因素的组合导致未发现脉动的超亮X射线源中筛选出新的候选脉冲超亮X射线源（PULXs）。我们采用AI方法对XMM-Newton探测到的超亮X射线源数据库进行了更新。首先使用无监督聚类算法将具有相似特征的源分为两类。然后，已知PULX观测样本被用来设定两个簇之间的分离阈值，并识别出包含新候选PULXs的簇。我们发现只需少数几项标准即可将观测分配到两个簇中的一个。新候选PULXs的簇中有85个唯一源，共355个观测，其中约85%的新候选PULXs有多次观测。初步时间分析未发现这些候选源的新脉动。本文介绍了由XMM-Newton观测到的新候选PULXs样本，其性质在多维相空间中与已知PULXs相似，尽管其光曲线中未显示脉动。虽然这一结果是AI方法预测能力的一个明确例子，但也强调了需要高统计观测数据以揭示这些源中的相干信号的必要性，从而验证该方法的 robustness。', 'title_zh': '新脉动超亮X射线源的搜索：聚集方法探究'}
{'arxiv_id': 'arXiv:2507.15025', 'title': 'Survey of GenAI for Automotive Software Development: From Requirements to Executable Code', 'authors': 'Nenad Petrovic, Vahid Zolfaghari, Andre Schamschurko, Sven Kirchner, Fengjunjie Pan, Chengdng Wu, Nils Purschke, Aleksei Velsh, Krzysztof Lebioda, Yinglei Song, Yi Zhang, Lukasz Mazur, Alois Knoll', 'link': 'https://arxiv.org/abs/2507.15025', 'abstract': 'Adoption of state-of-art Generative Artificial Intelligence (GenAI) aims to revolutionize many industrial areas by reducing the amount of human intervention needed and effort for handling complex underlying processes. Automotive software development is considered to be a significant area for GenAI adoption, taking into account lengthy and expensive procedures, resulting from the amount of requirements and strict standardization. In this paper, we explore the adoption of GenAI for various steps of automotive software development, mainly focusing on requirements handling, compliance aspects and code generation. Three GenAI-related technologies are covered within the state-of-art: Large Language Models (LLMs), Retrieval Augmented Generation (RAG), Vision Language Models (VLMs), as well as overview of adopted prompting techniques in case of code generation. Additionally, we also derive a generalized GenAI-aided automotive software development workflow based on our findings from this literature review. Finally, we include a summary of a survey outcome, which was conducted among our automotive industry partners regarding the type of GenAI tools used for their daily work activities.', 'abstract_zh': '采用先进生成人工智能（GenAI）旨在通过减少处理复杂底层过程所需的人工干预和努力来革新许多工业领域。汽车软件开发被认为是GenAI采用的一个重要领域，考虑到其漫长且昂贵的流程，这源于大量需求和严格的标准化要求。在本文中，我们探讨了GenAI在汽车软件开发各个步骤中的应用，主要集中在需求处理、合规性和代码生成方面。在最先进的GenAI技术中涵盖了三大类：大型语言模型（LLMs）、检索增强生成（RAG）、视觉语言模型（VLMs），以及在代码生成中采用的提示技术概览。此外，我们基于此文献综述的研究发现，衍生出了一个通用的GenAI辅助汽车软件开发工作流。最后，我们包括了一项调查结果总结，该调查在我们的汽车工业合作伙伴中进行了关于他们日常工作中使用的GenAI工具类型。', 'title_zh': '面向汽车软件开发的 generative AI 概览：从需求到可执行代码'}
{'arxiv_id': 'arXiv:2507.15003', 'title': 'The Rise of AI Teammates in Software Engineering (SE) 3.0: How Autonomous Coding Agents Are Reshaping Software Engineering', 'authors': 'Hao Li, Haoxiang Zhang, Ahmed E. Hassan', 'link': 'https://arxiv.org/abs/2507.15003', 'abstract': 'The future of software engineering--SE 3.0--is unfolding with the rise of AI teammates: autonomous, goal-driven systems collaborating with human developers. Among these, autonomous coding agents are especially transformative, now actively initiating, reviewing, and evolving code at scale. This paper introduces AIDev, the first large-scale dataset capturing how such agents operate in the wild. Spanning over 456,000 pull requests by five leading agents--OpenAI Codex, Devin, GitHub Copilot, Cursor, and Claude Code--across 61,000 repositories and 47,000 developers, AIDev provides an unprecedented empirical foundation for studying autonomous teammates in software development.\nUnlike prior work that has largely theorized the rise of AI-native software engineering, AIDev offers structured, open data to support research in benchmarking, agent readiness, optimization, collaboration modeling, and AI governance. The dataset includes rich metadata on PRs, authorship, review timelines, code changes, and integration outcomes--enabling exploration beyond synthetic benchmarks like SWE-bench. For instance, although agents often outperform humans in speed, their PRs are accepted less frequently, revealing a trust and utility gap. Furthermore, while agents accelerate code submission--one developer submitted as many PRs in three days as they had in three years--these are structurally simpler (via code complexity metrics).\nWe envision AIDev as a living resource: extensible, analyzable, and ready for the SE and AI communities. Grounding SE 3.0 in real-world evidence, AIDev enables a new generation of research into AI-native workflows and supports building the next wave of symbiotic human-AI collaboration. The dataset is publicly available at this https URL.\n> AI Agent, Agentic AI, Coding Agent, Agentic Coding, Software Engineering Agent', 'abstract_zh': '软件工程的未来—SE 3.0—正随着AI队友的兴起而展开：自主、目标导向的系统与人类开发人员协作。其中，自主编码代理尤其具有革命性，现在能够主动启动、审查和大规模进化代码。本文介绍了AIDev，这是首个大规模数据集，记录了这类代理在现实世界中的运作方式。AIDev涵盖了来自OpenAI Codex、Devin、GitHub Copilot、Cursor和Claude Code五大代理的超过456,000个拉取请求，涉及61,000个存储库和47,000位开发者，为研究自主团队在软件开发中的作用提供了前所未有的实证基础。\n\n不同于以往主要基于理论研究AI原生软件工程的工作，AIDev提供了结构化的开放数据，支持基准测试、代理准备性、优化、协作建模和AI治理的研究。该数据集包含丰富的拉取请求元数据、作者信息、审查时间线、代码变更和集成结果——使研究超越了如SWE-bench这样的合成基准。例如，虽然代理通常在速度上超越人类，但它们的拉取请求被接受的频率较低，展示了信任和效用之间的差距。此外，虽然代理加速了代码提交——一名开发者在三天内提交的拉取请求数量等同于三年的提交量——但这些提交结构上较为简单（通过代码复杂性度量）。\n\n我们构想AIDev成为一个活生生的资源：可扩展、可分析，并准备好供软件工程和AI社区使用。AIDev扎根于真实世界数据，使之能够开启新的一代关于AI原生工作流程的研究，并支持构建下一代共生的人机协作。数据集在此处公开：[](此 https URL)。AI代理, 代理型AI, 编码代理, 代理型编码, 软件工程代理', 'title_zh': 'AI队友在软件工程3.0时代的发展：自主编码代理如何重塑软件工程'}
{'arxiv_id': 'arXiv:2507.14975', 'title': 'FCRF: Flexible Constructivism Reflection for Long-Horizon Robotic Task Planning with Large Language Models', 'authors': 'Yufan Song, Jiatao Zhang, Zeng Gu, Qingmiao Liang, Tuocheng Hu, Wei Song, Shiqiang Zhu', 'link': 'https://arxiv.org/abs/2507.14975', 'abstract': 'Autonomous error correction is critical for domestic robots to achieve reliable execution of complex long-horizon tasks. Prior work has explored self-reflection in Large Language Models (LLMs) for task planning error correction; however, existing methods are constrained by inflexible self-reflection mechanisms that limit their effectiveness. Motivated by these limitations and inspired by human cognitive adaptation, we propose the Flexible Constructivism Reflection Framework (FCRF), a novel Mentor-Actor architecture that enables LLMs to perform flexible self-reflection based on task difficulty, while constructively integrating historical valuable experience with failure lessons. We evaluated FCRF on diverse domestic tasks through simulation in AlfWorld and physical deployment in the real-world environment. Experimental results demonstrate that FCRF significantly improves overall performance and self-reflection flexibility in complex long-horizon robotic tasks.', 'abstract_zh': '自主错误纠正对于实现家庭机器人可靠执行长时间复杂任务至关重要。现有工作在大型语言模型（LLM）的任务规划错误纠正中探索了自我反思机制；然而，现有方法受限于刚性自我反思机制，限制了其有效性。受这些局限性和人类认知适应的启发，我们提出了灵活建构主义反思框架（FCRF），这是一种新颖的导师-行动者架构，使LLM能够根据任务难度进行灵活的自我反思，并构建性地整合历史有价值的经验与失败教训。我们通过在AlfWorld的仿真和真实环境中的物理部署对FCRF在多种家庭任务中的表现进行了评估。实验结果表明，FCRF显著提高了复杂长时间机器人任务的整体性能和自我反思灵活性。', 'title_zh': 'FCRF：灵活的建构主义反思在大型语言模型支持下的长期机器人任务规划'}
{'arxiv_id': 'arXiv:2507.14960', 'title': 'A Comparative Analysis of Statistical and Machine Learning Models for Outlier Detection in Bitcoin Limit Order Books', 'authors': 'Ivan Letteri', 'link': 'https://arxiv.org/abs/2507.14960', 'abstract': 'The detection of outliers within cryptocurrency limit order books (LOBs) is of paramount importance for comprehending market dynamics, particularly in highly volatile and nascent regulatory environments. This study conducts a comprehensive comparative analysis of robust statistical methods and advanced machine learning techniques for real-time anomaly identification in cryptocurrency LOBs. Within a unified testing environment, named AITA Order Book Signal (AITA-OBS), we evaluate the efficacy of thirteen diverse models to identify which approaches are most suitable for detecting potentially manipulative trading behaviours. An empirical evaluation, conducted via backtesting on a dataset of 26,204 records from a major exchange, demonstrates that the top-performing model, Empirical Covariance (EC), achieves a 6.70% gain, significantly outperforming a standard Buy-and-Hold benchmark. These findings underscore the effectiveness of outlier-driven strategies and provide insights into the trade-offs between model complexity, trade frequency, and performance. This study contributes to the growing corpus of research on cryptocurrency market microstructure by furnishing a rigorous benchmark of anomaly detection models and highlighting their potential for augmenting algorithmic trading and risk management.', 'abstract_zh': '数字货币限订单簿中的异常检测对于理解市场动态至关重要，特别是在 Highly Volatile 和新兴监管环境中。本文对稳健统计方法和先进机器学习技术在数字货币限订单簿中实时异常识别的性能进行了全面比较分析。在名为 AITA Order Book Signal (AITA-OBS) 的统一测试环境中，我们评估了十三种不同模型的有效性，以确定哪些方法最适合检测潜在操纵交易行为。通过对某主要交易所的 26,204 条记录进行回测实证研究发现，表现最佳的模型 Empirical Covariance (EC) 达到了 6.70% 的收益，显著优于标准的 Buy-and-Hold 基准。这些发现强调了基于异常的策略的有效性，并提供了模型复杂性、交易频率与性能之间的权衡见解。本文通过提供异常检测模型的严格基准并突出其在增强算法交易和风险管理方面的潜力，为数字货币市场微观结构研究领域做出了贡献。', 'title_zh': '比特币限价订单簿中异常检测的统计与机器学习模型比较分析'}
{'arxiv_id': 'arXiv:2507.14957', 'title': 'Probing EFX via PMMS: (Non-)Existence Results in Discrete Fair Division', 'authors': 'Jarosław Byrka, Franciszek Malinka, Tomasz Ponitka', 'link': 'https://arxiv.org/abs/2507.14957', 'abstract': 'We study the fair division of indivisible items and provide new insights into the EFX problem, which is widely regarded as the central open question in fair division, and the PMMS problem, a strictly stronger variant of EFX. Our first result constructs a three-agent instance with two monotone valuations and one additive valuation in which no PMMS allocation exists. Since EFX allocations are known to exist under these assumptions, this establishes a formal separation between EFX and PMMS.\nWe prove existence of fair allocations for three important special cases. We show that EFX allocations exist for personalized bivalued valuations, where for each agent $i$ there exist values $a_i > b_i$ such that agent $i$ assigns value $v_i(\\{g\\}) \\in \\{a_i, b_i\\}$ to each good $g$. We establish an analogous existence result for PMMS allocations when $a_i$ is divisible by $b_i$. We also prove that PMMS allocations exist for binary-valued MMS-feasible valuations, where each bundle $S$ has value $v_i(S) \\in \\{0, 1\\}$. Notably, this result holds even without assuming monotonicity of valuations and thus applies to the fair division of chores and mixed manna. Finally, we study a class of valuations called pair-demand valuations, which extend the well-studied unit-demand valuations to the case where each agent derives value from at most two items, and we show that PMMS allocations exist in this setting. Our proofs are constructive, and we provide polynomial-time algorithms for all three existence results.', 'abstract_zh': '我们研究不可分割物品的公平分配问题，并提供了关于EFX问题的新见解，EFX问题被广泛认为是公平分配领域中的核心开放问题，以及PMMS问题，这是一个严格更强的EFX变体。我们的第一个结果构建了一个三代理人实例，包含两个单调估值和一个增加估值，且在这些假设下不存在PMMS分配。由于已知在这种假设下存在EFX分配，这确立了EFX和PMMS之间的形式化分离。\n\n我们证明了三种重要特殊情况下的公平分配存在性。我们证明了个性化二值估值下的EFX分配存在性，其中对于每个代理人 \\(i\\)，存在 \\(a_i > b_i\\)，使得代理人 \\(i\\) 将每个物品 \\(g\\) 的估值 \\(v_i(\\{g\\})\\) 分配为 \\(a_i\\) 或 \\(b_i\\)。我们还证明了在 \\(a_i\\) 可被 \\(b_i\\) 整除的情况下，PMMS分配的存在性具有类似的结果。我们还证明了二值MMS可行估值下的PMMS分配存在性，其中每个物品集合 \\(S\\) 的估值 \\(v_i(S)\\) 为 \\(0\\) 或 \\(1\\)。值得注意的是，这一结果即使不假设估值的单调性也成立，因此适用于劳动分配和混合财富的公平分配。最后，我们研究了一类称为配对需求估值，这些估值将广为人知的单一需求估值扩展到每个代理最多从两个项目中获取价值的情况，并证明了在这种情况下存在PMMS分配。我们的证明是构造性的，并为这三个存在性结果提供了多项式时间算法。', 'title_zh': '探查EFX通过PMMS：离散公平分割中的存在性结果与不存在性结果'}
{'arxiv_id': 'arXiv:2507.14928', 'title': 'Byzantine-Robust Decentralized Coordination of LLM Agents', 'authors': 'Yongrae Jo, Chanik Park', 'link': 'https://arxiv.org/abs/2507.14928', 'abstract': "Collaboration among multiple large language model (LLM) agents is a promising approach to overcome inherent limitations of single-agent systems, such as hallucinations and single points of failure. As LLM agents are increasingly deployed on open blockchain platforms, multi-agent systems capable of tolerating malicious (Byzantine) agents have become essential.\nRecent Byzantine-robust multi-agent systems typically rely on leader-driven coordination, which suffers from two major drawbacks. First, they are inherently vulnerable to targeted attacks against the leader. If consecutive leaders behave maliciously, the system repeatedly fails to achieve consensus, forcing new consensus rounds, which is particularly costly given the high latency of LLM invocations. Second, an underperforming proposal from the leader can be accepted as the final answer even when higher-quality alternatives are available, as existing methods finalize the leader's proposal once it receives a quorum of votes.\nTo address these issues, we propose DecentLLMs, a novel decentralized consensus approach for multi-agent LLM systems, where worker agents generate answers concurrently and evaluator agents independently score and rank these answers to select the best available one. This decentralized architecture enables faster consensus despite the presence of Byzantine agents and consistently selects higher-quality answers through Byzantine-robust aggregation techniques.\nExperimental results demonstrate that DecentLLMs effectively tolerates Byzantine agents and significantly improves the quality of selected answers.", 'abstract_zh': '多大型语言模型代理之间的协作是一种有望克服单代理系统固有限制（如幻觉和单点故障）的方法。随着大型语言模型代理被越来越多地部署在开放区块链平台上，能够容忍恶意（拜占庭）代理的多代理系统变得至关重要。\n\n近期的拜占庭鲁棒多代理系统通常依赖于领导者驱动的协调，这存在两大主要缺点。首先，它们本质上容易受到针对领导者的定向攻击。如果有连续的领导者行为不端，则系统反复无法达成共识，迫使进行新的共识轮次，这在LLM调用具有高延迟的情况下尤其代价高昂。其次，即使存在更好的备选答案，现有的方法也会在领导者提案获得足够票数确认时最终接受较低质量的提案。\n\n为了应对这些问题，我们提出DecentLLMs，这是一种为多代理大型语言模型系统设计的新型去中心化共识方法，其中工作代理并发生成答案，评审代理独立评分和排名这些答案以选择最佳答案。这种去中心化架构能够在存在拜占庭代理的情况下更快达成共识，并通过拜占庭鲁棒聚合技术一致地选择高质量答案。\n\n实验结果表明，DecentLLMs有效地容忍了拜占庭代理，并显著提高了所选答案的质量。', 'title_zh': 'Byzantine-鲁棒的LLM代理去中心化协调'}
{'arxiv_id': 'arXiv:2507.14914', 'title': 'One Step Beyond: Feedthrough & Placement-Aware Rectilinear Floorplanner', 'authors': 'Zhexuan Xu, Jie Wang, Siyuan Xu, Zijie Geng, Mingxuan Yuan, Feng Wu', 'link': 'https://arxiv.org/abs/2507.14914', 'abstract': "Floorplanning determines the shapes and locations of modules on a chip canvas and plays a critical role in optimizing the chip's Power, Performance, and Area (PPA) metrics. However, existing floorplanning approaches often fail to integrate with subsequent physical design stages, leading to suboptimal in-module component placement and excessive inter-module feedthrough. To tackle this challenge, we propose Flora, a three-stage feedthrough and placement aware rectilinear floorplanner. In the first stage, Flora employs wiremask and position mask techniques to achieve coarse-grained optimization of HPWL and feedthrough. In the second stage, under the constraint of a fixed outline, Flora achieves a zero-whitespace layout by locally resizing module shapes, thereby performing fine-grained optimization of feedthrough and improving component placement. In the third stage, Flora utilizes a fast tree search-based method to efficiently place components-including macros and standard cells-within each module, subsequently adjusting module boundaries based on the placement results to enable cross-stage optimization. Experimental results show that Flora outperforms recent state-of-the-art floorplanning approaches, achieving an average reduction of 6% in HPWL, 5.16% in FTpin, 29.15% in FTmod, and a 14% improvement in component placement performance.", 'abstract_zh': 'Flora：基于馈通和布线感知的三阶段直方图地板规划器', 'title_zh': '一步超越：反馈通路与布局感知的直角布局规划'}
{'arxiv_id': 'arXiv:2507.14908', 'title': 'Partial Symmetry Enforced Attention Decomposition (PSEAD): A Group-Theoretic Framework for Equivariant Transformers in Biological Systems', 'authors': 'Daniel Ayomide Olanrewaju', 'link': 'https://arxiv.org/abs/2507.14908', 'abstract': "This research introduces the Theory of Partial Symmetry Enforced Attention Decomposition (PSEAD), a new and rigorous group-theoretic framework designed to seamlessly integrate local symmetry awareness into the core architecture of self-attention mechanisms within Transformer models. We formalize the concept of local permutation subgroup actions on windows of biological data, proving that under such actions, the attention mechanism naturally decomposes into a direct sum of orthogonal irreducible components. Critically, these components are intrinsically aligned with the irreducible representations of the acting permutation subgroup, thereby providing a powerful mathematical basis for disentangling symmetric and asymmetric features. We show that PSEAD offers substantial advantages. These include enhanced generalization capabilities to novel biological motifs exhibiting similar partial symmetries, unprecedented interpretability by allowing direct visualization and analysis of attention contributions from different symmetry channels, and significant computational efficiency gains by focusing representational capacity on relevant symmetric subspaces. Beyond static data analysis, we extend PSEAD's applicability to dynamic biological processes within reinforcement learning paradigms, showcasing its potential to accelerate the discovery and optimization of biologically meaningful policies in complex environments like protein folding and drug discovery. This work lays the groundwork for a new generation of biologically informed, symmetry-aware artificial intelligence models.", 'abstract_zh': '这种研究介绍了部分对称强制注意分解理论（PSEAD），这是一种新的严格群论框架，旨在无缝地将局部对称意识集成到Transformer模型中自注意力机制的核心架构中。我们形式化了局部置换子群作用于生物数据窗口的概念，并证明在这样的作用下，注意机制自然分解为正交不可约成分的直和。关键的是，这些成分内嵌地与作用置换子群的不可约表示相一致，从而为解纠缠对称和非对称特征提供了强大的数学基础。我们展示了PSEAD的优势，包括增强了对展示相似部分对称性的新型生物结构模式的泛化能力，前所未有的可解释性，允许直接可视化和分析来自不同对称通道的注意贡献，以及通过专注于相关的对称子空间而实现的显著计算效率提升。该研究还扩展了PSEAD的应用范围，将其应用于强化学习范式中的动态生物过程，展示了其在复杂环境中（如蛋白质折叠和药物发现）加速发现和优化生物意义政策的潜力。这项工作为新一代生物启发且具备对称意识的人工智能模型奠定了基础。', 'title_zh': '部分对称强制注意分解（PSEAD）：生物系统中稳态变换器的群论框架'}
{'arxiv_id': 'arXiv:2507.14904', 'title': 'TriCLIP-3D: A Unified Parameter-Efficient Framework for Tri-Modal 3D Visual Grounding based on CLIP', 'authors': 'Fan Li, Zanyi Wang, Zeyi Huang, Guang Dai, Jingdong Wang, Mengmeng Wang', 'link': 'https://arxiv.org/abs/2507.14904', 'abstract': '3D visual grounding allows an embodied agent to understand visual information in real-world 3D environments based on human instructions, which is crucial for embodied intelligence. Existing 3D visual grounding methods typically rely on separate encoders for different modalities (e.g., RGB images, text, and 3D point clouds), resulting in large and complex models that are inefficient to train. While some approaches use pre-trained 2D multi-modal models like CLIP for 3D tasks, they still struggle with aligning point cloud data to 2D encoders. As a result, these methods continue to depend on 3D encoders for feature extraction, further increasing model complexity and training inefficiency. In this paper, we propose a unified 2D pre-trained multi-modal network to process all three modalities (RGB images, text, and point clouds), significantly simplifying the architecture. By leveraging a 2D CLIP bi-modal model with adapter-based fine-tuning, this framework effectively adapts to the tri-modal setting, improving both adaptability and performance across modalities. Our Geometric-Aware 2D-3D Feature Recovery and Fusion (GARF) module is designed to fuse geometric multi-scale features from point clouds and images. We then integrate textual features for final modality fusion and introduce a multi-modal decoder to facilitate deep cross-modal understanding. Together, our method achieves unified feature extraction and fusion across the three modalities, enabling an end-to-end 3D visual grounding model. Compared to the baseline, our method reduces the number of trainable parameters by approximately 58\\%, while achieving a 6.52\\% improvement in the 3D detection task and a 6.25\\% improvement in the 3D visual grounding task.', 'abstract_zh': '基于人类指令在真实世界3D环境中的三维视觉定位允许实体化代理理解视觉信息，这对于实体化智能至关重要。现有的三维视觉定位方法通常依赖于不同模态（如RGB图像、文本和3D点云）的独立编码器，导致大型且复杂的模型，训练效率低下。尽管一些方法使用预先训练的2D多模态模型（如CLIP）进行三维任务，它们仍然难以将点云数据对齐到2D编码器。因此，这些方法仍然依赖三维编码器进行特征提取，进一步增加了模型复杂性和训练效率低下。在本文中，我们提出了一种统一的2D预训练多模态网络来处理所有三种模态（RGB图像、文本和点云），显著简化了网络结构。通过利用基于适配器的细调的2D CLIP双模态模型，该框架能够有效地适应三维设置，提高各模态的适应性和性能。我们设计的几何感知的2D-3D特征恢复与融合（GARF）模块旨在融合点云和图像的几何多尺度特征。然后，我们结合文本特征进行最终模态融合，并引入多模态解码器以促进深层次跨模态理解。我们的方法实现了三模态统一的特征提取和融合，能够构建端到端的三维视觉定位模型。与基线方法相比，我们的方法减少了约58%的可训练参数，在三维检测任务上提高了6.52%的性能，并在三维视觉定位任务上提高了6.25%的性能。', 'title_zh': 'TriCLIP-3D：一种基于CLIP的统一高效三模态3D视觉定位框架'}
{'arxiv_id': 'arXiv:2507.14901', 'title': 'Learning Nonlinear Causal Reductions to Explain Reinforcement Learning Policies', 'authors': 'Armin Kekić, Jan Schneider, Dieter Büchler, Bernhard Schölkopf, Michel Besserve', 'link': 'https://arxiv.org/abs/2507.14901', 'abstract': 'Why do reinforcement learning (RL) policies fail or succeed? This is a challenging question due to the complex, high-dimensional nature of agent-environment interactions. In this work, we take a causal perspective on explaining the behavior of RL policies by viewing the states, actions, and rewards as variables in a low-level causal model. We introduce random perturbations to policy actions during execution and observe their effects on the cumulative reward, learning a simplified high-level causal model that explains these relationships. To this end, we develop a nonlinear Causal Model Reduction framework that ensures approximate interventional consistency, meaning the simplified high-level model responds to interventions in a similar way as the original complex system. We prove that for a class of nonlinear causal models, there exists a unique solution that achieves exact interventional consistency, ensuring learned explanations reflect meaningful causal patterns. Experiments on both synthetic causal models and practical RL tasks-including pendulum control and robot table tennis-demonstrate that our approach can uncover important behavioral patterns, biases, and failure modes in trained RL policies.', 'abstract_zh': '为什么 reinforcement learning (RL) 策略会失败或成功？由于智能体-环境交互的复杂性和高维性，这是一个具有挑战性的问题。在这项工作中，我们从因果视角出发，将状态、动作和奖励视为低层次因果模型中的变量，通过在执行过程中对策略动作施加随机扰动，并观察其对累积奖励的影响，学习一个简化但高层次的因果模型来解释这些关系。为此，我们开发了一种非线性因果模型简化框架，确保简化模型的干预响应近似于原始复杂系统的响应。我们证明，对于一类非线性因果模型，存在一个独特的解，可以实现精确的干预一致性，确保学到的解释反映有意义的因果模式。我们在合成因果模型和实际的 RL 任务（包括摆球控制和机器人乒乓球）上的实验表明，我们的方法可以揭示训练好的 RL 策略中的重要行为模式、偏差和失败模式。', 'title_zh': '学习非线性因果约简以解释强化学习策略'}
{'arxiv_id': 'arXiv:2507.14882', 'title': 'Application-Specific Component-Aware Structured Pruning of Deep Neural Networks via Soft Coefficient Optimization', 'authors': 'Ganesh Sundaram, Jonas Ulmen, Amjad Haider, Daniel Görges', 'link': 'https://arxiv.org/abs/2507.14882', 'abstract': "Deep neural networks (DNNs) offer significant versatility and performance benefits, but their widespread adoption is often hindered by high model complexity and computational demands. Model compression techniques such as pruning have emerged as promising solutions to these challenges. However, it remains critical to ensure that application-specific performance characteristics are preserved during compression. In structured pruning, where groups of structurally coherent elements are removed, conventional importance metrics frequently fail to maintain these essential performance attributes. In this work, we propose an enhanced importance metric framework that not only reduces model size but also explicitly accounts for application-specific performance constraints. We employ multiple strategies to determine the optimal pruning magnitude for each group, ensuring a balance between compression and task performance. Our approach is evaluated on an autoencoder tasked with reconstructing MNIST images. Experimental results demonstrate that the proposed method effectively preserves task-relevant performance, maintaining the model's usability even after substantial pruning, by satisfying the required application-specific criteria.", 'abstract_zh': '深神经网络（DNNs）提供了显著的灵活性和性能优势，但其广泛应用常常受到高模型复杂性和计算需求的阻碍。模型压缩技术如剪枝已成为应对这些挑战的有前途的解决方案。然而，在压缩过程中保持特定应用的性能特征仍至关重要。在结构化剪枝中，去除结构上一致的元素组时，传统的重要性度量经常无法保持这些关键的性能属性。在本文中，我们提出了一种增强的重要性度量框架，该框架不仅可以减少模型大小，而且能够明确考虑特定应用的性能限制。我们采用多种策略为每个组确定最佳剪枝程度，确保压缩和任务性能之间的平衡。我们的方法在用于重建MNIST图像的自动编码器上进行评估。实验结果表明，所提出的方法能够有效保持任务相关的性能，即使在大量剪枝后仍保持模型的可用性，从而满足所需的特定应用标准。', 'title_zh': '基于软系数优化的特定应用组件感知深度神经网络结构剪枝'}
{'arxiv_id': 'arXiv:2507.14874', 'title': 'The Tsetlin Machine Goes Deep: Logical Learning and Reasoning With Graphs', 'authors': 'Ole-Christoffer Granmo, Youmna Abdelwahab, Per-Arne Andersen, Paul F. A. Clarke, Kunal Dumbre, Ylva Grønninsæter, Vojtech Halenka, Runar Helin, Lei Jiao, Ahmed Khalid, Rebekka Omslandseter, Rupsa Saha, Mayur Shende, Xuan Zhang', 'link': 'https://arxiv.org/abs/2507.14874', 'abstract': "Pattern recognition with concise and flat AND-rules makes the Tsetlin Machine (TM) both interpretable and efficient, while the power of Tsetlin automata enables accuracy comparable to deep learning on an increasing number of datasets. We introduce the Graph Tsetlin Machine (GraphTM) for learning interpretable deep clauses from graph-structured input. Moving beyond flat, fixed-length input, the GraphTM gets more versatile, supporting sequences, grids, relations, and multimodality. Through message passing, the GraphTM builds nested deep clauses to recognize sub-graph patterns with exponentially fewer clauses, increasing both interpretability and data utilization. For image classification, GraphTM preserves interpretability and achieves 3.86%-points higher accuracy on CIFAR-10 than a convolutional TM. For tracking action coreference, faced with increasingly challenging tasks, GraphTM outperforms other reinforcement learning methods by up to 20.6%-points. In recommendation systems, it tolerates increasing noise to a greater extent than a Graph Convolutional Neural Network (GCN), e.g., for noise ratio 0.1, GraphTM obtains accuracy 89.86% compared to GCN's 70.87%. Finally, for viral genome sequence data, GraphTM is competitive with BiLSTM-CNN and GCN accuracy-wise, training 2.5x faster than GCN. The GraphTM's application to these varied fields demonstrates how graph representation learning and deep clauses bring new possibilities for TM learning.", 'abstract_zh': '基于简洁和扁平AND规则的图Tsetlin机（GraphTM）在学习图结构输入的可解释深层子句方面既具可解释性又高效，其强大的Tsetlin自动机能力使其在越来越多的数据集上的准确度可与深度学习媲美。', 'title_zh': 'Tsetlin机深入学习：图形上的逻辑学习与推理'}
{'arxiv_id': 'arXiv:2507.14851', 'title': 'Grounding Degradations in Natural Language for All-In-One Video Restoration', 'authors': 'Muhammad Kamran Janjua, Amirhosein Ghasemabadi, Kunlin Zhang, Mohammad Salameh, Chao Gao, Di Niu', 'link': 'https://arxiv.org/abs/2507.14851', 'abstract': 'In this work, we propose an all-in-one video restoration framework that grounds degradation-aware semantic context of video frames in natural language via foundation models, offering interpretable and flexible guidance. Unlike prior art, our method assumes no degradation knowledge in train or test time and learns an approximation to the grounded knowledge such that the foundation model can be safely disentangled during inference adding no extra cost. Further, we call for standardization of benchmarks in all-in-one video restoration, and propose two benchmarks in multi-degradation setting, three-task (3D) and four-task (4D), and two time-varying composite degradation benchmarks; one of the latter being our proposed dataset with varying snow intensity, simulating how weather degradations affect videos naturally. We compare our method with prior works and report state-of-the-art performance on all benchmarks.', 'abstract_zh': '基于基础模型的端到端视频恢复框架：自然语言驱动的降级感知语义上下文及其标准化 benchmarks 探索', 'title_zh': '基于自然语言对所有视频恢复任务进行故障定位'}
{'arxiv_id': 'arXiv:2507.14850', 'title': 'Hierarchical Multi-Agent Reinforcement Learning with Control Barrier Functions for Safety-Critical Autonomous Systems', 'authors': 'H. M. Sabbir Ahmad, Ehsan Sabouni, Alexander Wasilkoff, Param Budhraja, Zijian Guo, Songyuan Zhang, Chuchu Fan, Christos Cassandras, Wenchao Li', 'link': 'https://arxiv.org/abs/2507.14850', 'abstract': 'We address the problem of safe policy learning in multi-agent safety-critical autonomous systems. In such systems, it is necessary for each agent to meet the safety requirements at all times while also cooperating with other agents to accomplish the task. Toward this end, we propose a safe Hierarchical Multi-Agent Reinforcement Learning (HMARL) approach based on Control Barrier Functions (CBFs). Our proposed hierarchical approach decomposes the overall reinforcement learning problem into two levels learning joint cooperative behavior at the higher level and learning safe individual behavior at the lower or agent level conditioned on the high-level policy. Specifically, we propose a skill-based HMARL-CBF algorithm in which the higher level problem involves learning a joint policy over the skills for all the agents and the lower-level problem involves learning policies to execute the skills safely with CBFs. We validate our approach on challenging environment scenarios whereby a large number of agents have to safely navigate through conflicting road networks. Compared with existing state of the art methods, our approach significantly improves the safety achieving near perfect (within 5%) success/safety rate while also improving performance across all the environments.', 'abstract_zh': '多代理安全 Critical 自动系统中的安全策略学习：基于控制障碍函数的分层多代理强化学习方法', 'title_zh': '基于控制障碍函数的分层多代理 reinforcement 学习在关键安全自主系统中的应用'}
{'arxiv_id': 'arXiv:2507.14843', 'title': 'The Invisible Leash: Why RLVR May Not Escape Its Origin', 'authors': 'Fang Wu, Weihao Xuan, Ximing Lu, Zaid Harchaoui, Yejin Choi', 'link': 'https://arxiv.org/abs/2507.14843', 'abstract': "Recent advances in large reasoning models highlight Reinforcement Learning with Verifiable Rewards (RLVR) as a promising method for enhancing AI's capabilities, particularly in solving complex logical tasks. However, it remains unclear whether RLVR truly expands a model's reasoning boundary or merely amplifies high-reward outputs that the base model already knows for improved precision. This study presents a theoretical and empirical investigation that provides fresh insights into the potential limits of RLVR. First, we offer a new theoretical perspective that RLVR is constrained by the base model's support-unable to sample solutions with zero initial probability-and operates as a conservative reweighting mechanism that may restrict the discovery of entirely original solutions. We also identify an entropy-reward tradeoff: while RLVR reliably enhances precision, it may progressively narrow exploration and potentially overlook correct yet underrepresented solutions. Extensive empirical experiments validate that while RLVR consistently improves pass@1, the shrinkage of empirical support generally outweighs the expansion of empirical support under larger sampling budgets, failing to recover correct answers that were previously accessible to the base model. Interestingly, we also observe that while RLVR sometimes increases token-level entropy, resulting in greater uncertainty at each generation step, answer-level entropy declines, indicating that these seemingly more uncertain paths ultimately converge onto a smaller set of distinct answers. Taken together, these findings reveal potential limits of RLVR in extending reasoning horizons. Breaking this invisible leash may require future algorithmic innovations such as explicit exploration mechanisms or hybrid strategies that seed probability mass into underrepresented solution regions.", 'abstract_zh': '近期大型推理模型的发展凸显了可验证奖励强化学习（RLVR）作为一种有望增强AI能力的方法，特别是在解决复杂逻辑任务方面。然而，尚不清楚RLVR是否真正扩展了模型的推理边界，还是仅仅通过放大基模型已知的高奖励输出来提高精确度。本研究通过理论和实证考察，提供了对RLVR潜在限制的新见解。首先，我们提出了一种新的理论视角，即RLVR受到基模型支持的限制，无法生成初始概率为零的解决方案，并且作为一种保守的重新加权机制，可能限制了完全原创解决方案的发现。我们还识别出熵-奖励权衡：虽然RLVR能可靠地提高精确度，但它可能会逐渐限制探索，并有可能忽视正确但欠代表的解决方案。广泛的实证实验验证了，虽然RLVR在提升pass@1方面表现出一致性改进，但在更大采样预算下的经验支持缩小通常超过了经验支持的扩展，未能恢复基模型先前可及的正确答案。有趣的是，我们还观察到，在某些情况下，RLVR增加了token级熵，导致每步生成时不确定性增加，但答案级熵下降，表明这些看似更具不确定性的路径最终收敛到一个更小的、独特的答案集。综上所述，这些发现揭示了RLVR在扩展推理视野方面的潜在限制。未来可能需要诸如明确探索机制或混合策略等算法创新，以打破这种无形的束缚，注入概率质量到欠代表的解决方案区域中。', 'title_zh': '无形的绳索：为什么RLVR可能无法逃脱其根源'}
{'arxiv_id': 'arXiv:2507.14833', 'title': 'Paired Image Generation with Diffusion-Guided Diffusion Models', 'authors': 'Haoxuan Zhang, Wenju Cui, Yuzhu Cao, Tao Tan, Jie Liu, Yunsong Peng, Jian Zheng', 'link': 'https://arxiv.org/abs/2507.14833', 'abstract': 'The segmentation of mass lesions in digital breast tomosynthesis (DBT) images is very significant for the early screening of breast cancer. However, the high-density breast tissue often leads to high concealment of the mass lesions, which makes manual annotation difficult and time-consuming. As a result, there is a lack of annotated data for model training. Diffusion models are commonly used for data augmentation, but the existing methods face two challenges. First, due to the high concealment of lesions, it is difficult for the model to learn the features of the lesion area. This leads to the low generation quality of the lesion areas, thus limiting the quality of the generated images. Second, existing methods can only generate images and cannot generate corresponding annotations, which restricts the usability of the generated images in supervised training. In this work, we propose a paired image generation method. The method does not require external conditions and can achieve the generation of paired images by training an extra diffusion guider for the conditional diffusion model. During the experimental phase, we generated paired DBT slices and mass lesion masks. Then, we incorporated them into the supervised training process of the mass lesion segmentation task. The experimental results show that our method can improve the generation quality without external conditions. Moreover, it contributes to alleviating the shortage of annotated data, thus enhancing the performance of downstream tasks.', 'abstract_zh': '数字乳腺断层成像(DBT)图像中肿块病变的分割对乳腺癌早期筛查极为重要。然而，高密度乳腺组织常常导致肿块病变的高度隐蔽，使得手动标注困难且耗时。结果，缺乏用于模型训练的标注数据。扩散模型常用于数据增强，但现有方法面临两个挑战。首先，由于病变的高度隐蔽性，模型难以学习到病变区域的特征，导致病变区域生成质量低下，从而限制了生成图像的质量。其次，现有方法只能生成图像，而不能生成相应的标注，这限制了生成图像在监督训练中的使用。在本工作中，我们提出了一种配对图像生成方法。该方法不依赖外部条件，并通过为条件扩散模型训练额外的扩散引导器来实现配对图像的生成。在实验阶段，我们生成了配对的DBT切片和肿块病变掩膜，然后将它们融入肿块病变分割任务的监督训练过程中。实验结果表明，我们的方法可以在不依赖外部条件的情况下提高生成质量，并有助于缓解标注数据不足的问题，从而增强下游任务的性能。', 'title_zh': '基于扩散引导扩散模型的配对图像生成'}
{'arxiv_id': 'arXiv:2507.14828', 'title': 'eMargin: Revisiting Contrastive Learning with Margin-Based Separation', 'authors': 'Abdul-Kazeem Shamba, Kerstin Bach, Gavin Taylor', 'link': 'https://arxiv.org/abs/2507.14828', 'abstract': 'We revisit previous contrastive learning frameworks to investigate the effect of introducing an adaptive margin into the contrastive loss function for time series representation learning. Specifically, we explore whether an adaptive margin (eMargin), adjusted based on a predefined similarity threshold, can improve the separation between adjacent but dissimilar time steps and subsequently lead to better performance in downstream tasks. Our study evaluates the impact of this modification on clustering performance and classification in three benchmark datasets. Our findings, however, indicate that achieving high scores on unsupervised clustering metrics does not necessarily imply that the learned embeddings are meaningful or effective in downstream tasks. To be specific, eMargin added to InfoNCE consistently outperforms state-of-the-art baselines in unsupervised clustering metrics, but struggles to achieve competitive results in downstream classification with linear probing. The source code is publicly available at this https URL.', 'abstract_zh': '我们重新审视先前的对比学习框架，探究在时间序列表示学习中引入自适应 Margin 对对比损失函数的影响。具体而言，我们探索基于预定义相似度阈值调整的自适应 Margin（eMargin）能否改善相邻但不相似的时间步之间的分离，并进而提高下游任务中的表现。我们的研究在三个基准数据集上评估了这一修改对无监督聚类性能和分类性能的影响。然而，我们的发现表明，在无监督聚类指标上获得高分并不一定意味着学习到的嵌入具有实际意义或在下游任务中有效。具体来说，加有 eMargin 的 InfoNCE 在无监督聚类指标上始终优于最先进的基线方法，但在下游分类任务中使用线性探针时，难以取得竞争力的结果。源代码可在以下网址公开获取。', 'title_zh': 'eMargin: 重新审视基于边距分离的对比学习'}
{'arxiv_id': 'arXiv:2507.14824', 'title': 'Benchmarking Foundation Models with Multimodal Public Electronic Health Records', 'authors': 'Kunyu Yu, Rui Yang, Jingchi Liao, Siqi Li, Huitao Li, Irene Li, Yifan Peng, Rishikesan Kamaleswaran, Nan Liu', 'link': 'https://arxiv.org/abs/2507.14824', 'abstract': 'Foundation models have emerged as a powerful approach for processing electronic health records (EHRs), offering flexibility to handle diverse medical data modalities. In this study, we present a comprehensive benchmark that evaluates the performance, fairness, and interpretability of foundation models, both as unimodal encoders and as multimodal learners, using the publicly available MIMIC-IV database. To support consistent and reproducible evaluation, we developed a standardized data processing pipeline that harmonizes heterogeneous clinical records into an analysis-ready format. We systematically compared eight foundation models, encompassing both unimodal and multimodal models, as well as domain-specific and general-purpose variants. Our findings demonstrate that incorporating multiple data modalities leads to consistent improvements in predictive performance without introducing additional bias. Through this benchmark, we aim to support the development of effective and trustworthy multimodal artificial intelligence (AI) systems for real-world clinical applications. Our code is available at this https URL.', 'abstract_zh': '基于Transformer的模型已成为处理电子健康记录（EHRs）的强大方法，能够灵活处理多样化的医疗数据模态。在此研究中，我们提出了一个全面的基准，评估基础模型作为单模态编码器和多模态学习者的表现、公平性和可解释性，使用公开的MIMIC-IV数据库。为了支持一致和可重复的评估，我们开发了标准化的数据处理管道，将异质临床记录整合为可分析的格式。系统比较了八种基础模型，包括单模态和多模态模型以及特定领域和通用变体。我们的研究结果表明，整合多种数据模态在提高预测性能的同时不会引入额外的偏见。通过此基准，我们旨在支持有效和可信的多模态人工智能（AI）系统在实际临床应用中的发展。相关代码可在以下链接获取。', 'title_zh': '基于多模态公共电子健康记录基准化基础模型'}
{'arxiv_id': 'arXiv:2507.14811', 'title': 'SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models', 'authors': 'Jiaji Zhang, Ruichao Sun, Hailiang Zhao, Jiaju Wu, Peng Chen, Hao Li, Xinkui Zhao, Kingsum Chow, Gang Xiong, Lin Ye, Shuiguang Deng', 'link': 'https://arxiv.org/abs/2507.14811', 'abstract': 'Diffusion models have demonstrated exceptional generative capabilities but are computationally intensive, posing significant challenges for deployment in resource-constrained or latency-sensitive environments. Quantization offers an effective means to reduce model size and computational cost, with post-training quantization (PTQ) being particularly appealing due to its compatibility with pre-trained models without requiring retraining or training data. However, existing PTQ methods for diffusion models often rely on architecture-specific heuristics that limit their generalizability and hinder integration with industrial deployment pipelines. To address these limitations, we propose SegQuant, a unified quantization framework that adaptively combines complementary techniques to enhance cross-model versatility. SegQuant consists of a segment-aware, graph-based quantization strategy (SegLinear) that captures structural semantics and spatial heterogeneity, along with a dual-scale quantization scheme (DualScale) that preserves polarity-asymmetric activations, which is crucial for maintaining visual fidelity in generated outputs. SegQuant is broadly applicable beyond Transformer-based diffusion models, achieving strong performance while ensuring seamless compatibility with mainstream deployment tools.', 'abstract_zh': '扩散模型展示了优异的生成能力，但在资源受限或对延迟敏感的环境中部署时计算成本高昂，提出了显著挑战。量化提供了一种有效减少模型大小和计算成本的方法，其中后训练量化(PTQ)特别令人瞩目，因为它可以与预训练模型兼容，无需重新训练或额外的数据。然而，现有的扩散模型PTQ方法常常依赖于特定架构的启发式方法，这限制了其普适性并阻碍了与工业部署管道的集成。为了解决这些局限性，我们提出了一种统一的量化框架SegQuant，该框架能够自适应地结合互补技术以增强跨模型的灵活性。SegQuant 包括一种基于图的、感知段落的量化策略(SegLinear)，该策略捕捉结构语义和空间异质性，以及一种双尺度量化方案(DualScale)，该方案保持不对称激活，这对于保持生成输出的视觉保真度至关重要。SegQuant 不仅适用于基于Transformer的扩散模型，还表现出强大的性能，并确保与主流部署工具无缝兼容。', 'title_zh': 'SemQuant: 具有语义意识和泛化能力的扩散模型量化框架'}
{'arxiv_id': 'arXiv:2507.14807', 'title': 'Seeing Through Deepfakes: A Human-Inspired Framework for Multi-Face Detection', 'authors': 'Juan Hu, Shaojing Fan, Terence Sim', 'link': 'https://arxiv.org/abs/2507.14807', 'abstract': 'Multi-face deepfake videos are becoming increasingly prevalent, often appearing in natural social settings that challenge existing detection methods. Most current approaches excel at single-face detection but struggle in multi-face scenarios, due to a lack of awareness of crucial contextual cues. In this work, we develop a novel approach that leverages human cognition to analyze and defend against multi-face deepfake videos. Through a series of human studies, we systematically examine how people detect deepfake faces in social settings. Our quantitative analysis reveals four key cues humans rely on: scene-motion coherence, inter-face appearance compatibility, interpersonal gaze alignment, and face-body consistency. Guided by these insights, we introduce \\textsf{HICOM}, a novel framework designed to detect every fake face in multi-face scenarios. Extensive experiments on benchmark datasets show that \\textsf{HICOM} improves average accuracy by 3.3\\% in in-dataset detection and 2.8\\% under real-world perturbations. Moreover, it outperforms existing methods by 5.8\\% on unseen datasets, demonstrating the generalization of human-inspired cues. \\textsf{HICOM} further enhances interpretability by incorporating an LLM to provide human-readable explanations, making detection results more transparent and convincing. Our work sheds light on involving human factors to enhance defense against deepfakes.', 'abstract_zh': '多臉深伪视频日益普及，常出现在挑战现有检测方法的自然社交环境中。当前大多数方法擅长单臉检测但在多臉场景中表现不佳，原因是缺乏对关键上下文线索的意识。本研究开发了一种新的方法，利用人类认知来分析和防范多臉深伪视频。通过一系列人类研究，我们系统地探讨了人们在社交环境中检测深伪 Faces 的方式。定量分析揭示了人类依赖的四个关键线索：场景运动一致性、Face 间外观一致性、人际凝视对齐和面部身体一致。根据这些洞察，我们提出了 \\textsf{HICOM}，一种新型框架，旨在在多臉场景中检测每一个假-face。基准数据集上的广泛实验表明，\\textsf{HICOM} 在内部检测中的平均准确率提高了 3.3%，在现实世界干扰下的准确率提高了 2.8%。此外，它在未见过的数据集上优于现有方法 5.8%，展示了人类启发式线索的泛化能力。\\textsf{HICOM} 进一步通过加入语言模型以提供人类可读的解释来增强可解释性，使检测结果更加透明和令人信服。我们的研究揭示了如何通过包含人类因素来增强对抗深伪视频的能力。', 'title_zh': '透过深度伪造：一种灵感源自人类的多脸检测框架'}
{'arxiv_id': 'arXiv:2507.14805', 'title': 'Subliminal Learning: Language models transmit behavioral traits via hidden signals in data', 'authors': 'Alex Cloud, Minh Le, James Chua, Jan Betley, Anna Sztyber-Betley, Jacob Hilton, Samuel Marks, Owain Evans', 'link': 'https://arxiv.org/abs/2507.14805', 'abstract': 'We study subliminal learning, a surprising phenomenon where language models transmit behavioral traits via semantically unrelated data. In our main experiments, a "teacher" model with some trait T (such as liking owls or being misaligned) generates a dataset consisting solely of number sequences. Remarkably, a "student" model trained on this dataset learns T. This occurs even when the data is filtered to remove references to T. We observe the same effect when training on code or reasoning traces generated by the same teacher model. However, we do not observe the effect when the teacher and student have different base models. To help explain our findings, we prove a theoretical result showing that subliminal learning occurs in all neural networks under certain conditions, and demonstrate subliminal learning in a simple MLP classifier. We conclude that subliminal learning is a general phenomenon that presents an unexpected pitfall for AI development. Distillation could propagate unintended traits, even when developers try to prevent this via data filtering.', 'abstract_zh': '我们在语言模型通过语义无关数据传递行为特征的潜意识学习现象进行了研究。在主要实验中，“教师”模型具有一些属性T（如喜欢猫头鹰或对齐偏差），生成仅由数字序列组成的数据集。令人惊讶的是，“学生”模型在训练时学习了T。即使在过滤掉与T相关的引用后，这一现象仍然存在。当使用相同的“教师”模型生成代码或推理痕迹进行训练时，我们也会观察到相同的效果。然而，当“教师”和“学生”使用不同的基础模型时，我们未观察到该效果。为解释我们的发现，我们证明了一个理论结果，表明在某些条件下，所有神经网络都会出现潜意识学习现象，并在简单的MLP分类器中演示了潜意识学习。我们得出结论，潜意识学习是一种普遍现象，为AI开发带来了意想不到的风险。知识蒸馏可能会传播未预期的属性，即使开发者试图通过数据过滤来防止这种现象。', 'title_zh': '潜意识学习：语言模型通过数据中的隐藏信号传递行为特质'}
{'arxiv_id': 'arXiv:2507.14802', 'title': 'ACME: Adaptive Customization of Large Models via Distributed Systems', 'authors': 'Ziming Dai, Chao Qiu, Fei Gao, Yunfeng Zhao, Xiaofei Wang', 'link': 'https://arxiv.org/abs/2507.14802', 'abstract': 'Pre-trained Transformer-based large models have revolutionized personal virtual assistants, but their deployment in cloud environments faces challenges related to data privacy and response latency. Deploying large models closer to the data and users has become a key research area to address these issues. However, applying these models directly often entails significant difficulties, such as model mismatching, resource constraints, and energy inefficiency. Automated design of customized models is necessary, but it faces three key challenges, namely, the high cost of centralized model customization, imbalanced performance from user heterogeneity, and suboptimal performance from data heterogeneity. In this paper, we propose ACME, an adaptive customization approach of Transformer-based large models via distributed systems. To avoid the low cost-efficiency of centralized methods, ACME employs a bidirectional single-loop distributed system to progressively achieve fine-grained collaborative model customization. In order to better match user heterogeneity, it begins by customizing the backbone generation and identifying the Pareto Front under model size constraints to ensure optimal resource utilization. Subsequently, it performs header generation and refines the model using data distribution-based personalized architecture aggregation to match data heterogeneity. Evaluation on different datasets shows that ACME achieves cost-efficient models under model size constraints. Compared to centralized systems, data transmission volume is reduced to 6 percent. Additionally, the average accuracy improves by 10 percent compared to the baseline, with the trade-off metrics increasing by nearly 30 percent.', 'abstract_zh': '基于Transformer的预训练大型模型在个人虚拟助手领域取得了革命性进展，但在云环境中部署面临数据隐私和响应延迟方面的挑战。将大型模型移近数据和用户成为解决这些问题的关键研究领域。然而，直接应用这些模型往往伴随着显著困难，如模型不匹配、资源限制和能源效率低下。通过自动化设计定制模型是必要的，但它面临三个关键挑战：集中式模型定制的高成本、用户异质性导致的性能不平衡以及数据异质性导致的次优性能。本文提出了一种通过分布式系统对基于Transformer的大型模型进行自适应定制的方法——ACME。为避免集中式方法低的成本效率，ACME采用双向单环分布式系统逐步实现精细粒度的协作模型定制。为了更好地匹配用户异质性，它首先对基础生成模型进行定制，并在模型大小约束下识别帕累托前沿以确保最优资源利用。随后，通过对数据分布进行个性化架构聚合进行头部生成和模型精炼，以匹配数据异质性。在不同数据集上的评估显示，在模型大小约束下，ACME实现了成本效益高的模型。与集中式系统相比，数据传输量减少了6%，平均准确性提高了10%，同时权衡指标提高了近30%。', 'title_zh': 'ACME: 大模型的分布式系统自适应定制'}
{'arxiv_id': 'arXiv:2507.14800', 'title': 'Large Language Model as An Operator: An Experience-Driven Solution for Distribution Network Voltage Control', 'authors': 'Xu Yang, Chenhui Lin, Haotian Liu, Qi Wang, Wenchuan Wu', 'link': 'https://arxiv.org/abs/2507.14800', 'abstract': 'With the advanced reasoning and information analysis capabilities, large language models (LLMs) can offer a novel approach for the autonomous generation of dispatch strategies in power systems. This letter proposes an LLM-based experience-driven voltage control solution for distribution networks, which enables the self-evolution of LLM-based voltage control strategies through the collaboration and interaction of multiple modules-specifically, experience storage, experience retrieval, experience generation, and experience modification. Comprehensive experimental results validate the effectiveness of the proposed method and highlight the applicability of LLM in addressing power system dispatch challenges.', 'abstract_zh': '基于大语言模型的分布式网络经验驱动电压控制方案：通过多模块协作实现自进化电压控制策略', 'title_zh': '大语言模型作为操作员：一种基于经验的配电网络电压控制解决方案'}
{'arxiv_id': 'arXiv:2507.14799', 'title': 'Manipulating LLM Web Agents with Indirect Prompt Injection Attack via HTML Accessibility Tree', 'authors': 'Sam Johnson, Viet Pham, Thai Le', 'link': 'https://arxiv.org/abs/2507.14799', 'abstract': 'This work demonstrates that LLM-based web navigation agents offer powerful automation capabilities but are vulnerable to Indirect Prompt Injection (IPI) attacks. We show that adversaries can embed universal adversarial triggers in webpage HTML to hijack agent behavior that utilizes the accessibility tree to parse HTML, causing unintended or malicious actions. Using the Greedy Coordinate Gradient (GCG) algorithm and a Browser Gym agent powered by Llama-3.1, our system demonstrates high success rates across real websites in both targeted and general attacks, including login credential exfiltration and forced ad clicks. Our empirical results highlight critical security risks and the need for stronger defenses as LLM-driven autonomous web agents become more widely adopted. The system software (this https URL) is released under the MIT License, with an accompanying publicly available demo website (this http URL).', 'abstract_zh': '基于LLM的网页导航代理展示了强大的自动化能力，但易受到间接提示注入攻击。我们展示了攻击者可以通过在网页HTML中嵌入通用对抗触发器来劫持利用 accessibility tree 解析 HTML 的代理行为，导致意外或恶意操作。使用贪婪坐标梯度（GCG）算法和由 Llama-3.1 动力驱动的 Browser Gym 代理，我们的系统在针对和非针对的实际网站攻击中都取得了高成功率，包括登录凭据盗取和强制广告点击。实验结果凸显了关键的安全风险，并强调了随着基于LLM的自主网页代理的广泛应用，需要更强的安全防护。系统软件（此链接）在MIT许可证下发布，并附带一个公开可用的演示网站（此链接）。', 'title_zh': '通过HTML可访问性树进行间接提示注入攻击操控LLM网络代理'}
{'arxiv_id': 'arXiv:2507.14787', 'title': 'FOCUS: Fused Observation of Channels for Unveiling Spectra', 'authors': 'Xi Xiao, Aristeidis Tsaris, Anika Tabassum, John Lagergren, Larry M. York, Tianyang Wang, Xiao Wang', 'link': 'https://arxiv.org/abs/2507.14787', 'abstract': 'Hyperspectral imaging (HSI) captures hundreds of narrow, contiguous wavelength bands, making it a powerful tool in biology, agriculture, and environmental monitoring. However, interpreting Vision Transformers (ViTs) in this setting remains largely unexplored due to two key challenges: (1) existing saliency methods struggle to capture meaningful spectral cues, often collapsing attention onto the class token, and (2) full-spectrum ViTs are computationally prohibitive for interpretability, given the high-dimensional nature of HSI data. We present FOCUS, the first framework that enables reliable and efficient spatial-spectral interpretability for frozen ViTs. FOCUS introduces two core components: class-specific spectral prompts that guide attention toward semantically meaningful wavelength groups, and a learnable [SINK] token trained with an attraction loss to absorb noisy or redundant attention. Together, these designs make it possible to generate stable and interpretable 3D saliency maps and spectral importance curves in a single forward pass, without any gradient backpropagation or backbone modification. FOCUS improves band-level IoU by 15 percent, reduces attention collapse by over 40 percent, and produces saliency results that align closely with expert annotations. With less than 1 percent parameter overhead, our method makes high-resolution ViT interpretability practical for real-world hyperspectral applications, bridging a long-standing gap between black-box modeling and trustworthy HSI decision-making.', 'abstract_zh': '超光谱成像(HSI)捕获数百个连续的窄波长带，使其在生物学、农业和环境监测中成为一种强大的工具。然而，在这种背景下解释视力变换器(ViT)仍然是一个尚未探索的领域，主要由于两个关键挑战：(1)现有的显著性方法难以捕捉有意义的光谱线索，经常将注意力集中在类标记上；(2)全谱ViT由于HSI数据的高维特性，在可解释性方面计算上不可行。我们提出了FOCUS，这是首个能够实现冻结ViT可靠且高效的空-谱可解释性的框架。FOCUS引入了两个核心组件：类特定的谱提示，引导注意力聚焦于具有语义意义的波长群组，以及通过吸引损失进行学习的[SINK]标记，以吸收噪声或冗余的注意力。通过这些设计，可以生成稳定且可解释的3D显著性图和光谱重要性曲线，在单一前向传播过程中无需任何梯度反向传播或骨干网络修改。FOCUS将波段级交并比(IoU)提高了15%，减少了40%以上的注意力坍塌，并产生了与专家注解接近的结果。凭借不到1%的参数开销，我们的方法使高分辨率ViT在实际超光谱应用中的可解释性成为可能，填补了黑盒建模与值得信赖的HSI决策之间长期存在的鸿沟。', 'title_zh': 'FOCUS: 融合通道观测以揭示光谱'}
{'arxiv_id': 'arXiv:2507.14785', 'title': 'Exploring the In-Context Learning Capabilities of LLMs for Money Laundering Detection in Financial Graphs', 'authors': 'Erfan Pirmorad', 'link': 'https://arxiv.org/abs/2507.14785', 'abstract': 'The complexity and interconnectivity of entities involved in money laundering demand investigative reasoning over graph-structured data. This paper explores the use of large language models (LLMs) as reasoning engines over localized subgraphs extracted from a financial knowledge graph. We propose a lightweight pipeline that retrieves k-hop neighborhoods around entities of interest, serializes them into structured text, and prompts an LLM via few-shot in-context learning to assess suspiciousness and generate justifications. Using synthetic anti-money laundering (AML) scenarios that reflect common laundering behaviors, we show that LLMs can emulate analyst-style logic, highlight red flags, and provide coherent explanations. While this study is exploratory, it illustrates the potential of LLM-based graph reasoning in AML and lays groundwork for explainable, language-driven financial crime analytics.', 'abstract_zh': '涉及洗钱的实体的复杂性和互联性要求在图结构数据上进行调查推理。本文探讨了使用大规模语言模型（LLMs）作为在金融知识图中提取的局部子图上的推理引擎的应用。我们提出了一种轻量级管道，用于检索实体的k跳邻域，将它们序列化为结构化文本，并通过少量示例的上下文学习激发LLM评估可疑行为并生成解释。通过反映常见洗钱行为的合成反洗钱（AML）场景，我们展示了LLM能够模拟分析师风格的逻辑、突出红旗并提供连贯的解释。尽管这项研究是探索性的，但它展示了LLM基于图的推理在反洗钱中的潜在应用，并为可解释的语言驱动的金融犯罪分析奠定了基础。', 'title_zh': '探究大语言模型在金融图谱中洗钱检测方面的上下文学习能力'}
{'arxiv_id': 'arXiv:2507.14784', 'title': 'LeAdQA: LLM-Driven Context-Aware Temporal Grounding for Video Question Answering', 'authors': 'Xinxin Dong, Baoyun Peng, Haokai Ma, Yufei Wang, Zixuan Dong, Fei Hu, Xiaodong Wang', 'link': 'https://arxiv.org/abs/2507.14784', 'abstract': "Video Question Answering (VideoQA) requires identifying sparse critical moments in long videos and reasoning about their causal relationships to answer semantically complex questions. While recent advances in multimodal learning have improved alignment and fusion, current approaches remain limited by two prevalent but fundamentally flawed strategies: (1) task-agnostic sampling indiscriminately processes all frames, overwhelming key events with irrelevant content; and (2) heuristic retrieval captures superficial patterns but misses causal-temporal structures needed for complex reasoning. To address these challenges, we introduce LeAdQA, an innovative approach that bridges these gaps through synergizing causal-aware query refinement with fine-grained visual grounding. Our method first leverages LLMs to reformulate question-option pairs, resolving causal ambiguities and sharpening temporal focus. These refined queries subsequently direct a temporal grounding model to precisely retrieve the most salient segments, complemented by an adaptive fusion mechanism dynamically integrating the evidence to maximize relevance. The integrated visual-textual cues are then processed by an MLLM to generate accurate, contextually-grounded answers. Experiments on NExT-QA, IntentQA, and NExT-GQA demonstrate that our method's precise visual grounding substantially enhances the understanding of video-question relationships, achieving state-of-the-art (SOTA) performance on complex reasoning tasks while maintaining computational efficiency.", 'abstract_zh': '视频问答（VideoQA）要求在长视频中识别稀疏的关键时刻并推理解它们的因果关系以回答语义复杂的问答。尽管多模态学习的 Recent 进展在对齐和融合方面取得了进步，但当前的方法仍受限于两种普遍但根本上存在缺陷的方法：（1）任务无关的采样会无差别地处理所有帧，使关键事件被无关内容压倒；（2）启发式检索捕获表层模式但忽略了复杂推理所需的因果时间结构。为了解决这些挑战，我们引入了 LeAdQA，一种通过结合因果意识查询精炼与细粒度视觉定位来弥合这些差距的方法。该方法首先利用大语言模型重新表述问题-选项对，解决因果歧义并增强时间焦点。这些精炼的查询随后引导时间定位模型精确检索最显著的片段，同时通过动态融合机制适应性地整合证据以最大化的相关性。集成的视觉-文本线索随后由多模态大语言模型处理以生成准确且上下文相关的回答。在 NExT-QA、IntentQA 和 NExT-GQA 上的实验表明，我们方法的精确视觉定位显著增强了对视频-问题关系的理解，实现了复杂推理任务上的最佳性能（SOTA），同时保持了计算效率。', 'title_zh': 'LeAdQA: 由LLM驱动的上下文感知时间定位视频问答'}
{'arxiv_id': 'arXiv:2507.14783', 'title': 'Omni-Think: Scaling Cross-Domain Generalization in LLMs via Multi-Task RL with Hybrid Rewards', 'authors': 'Derek Li, Jiaming Zhou, Amirreza Kazemi, Qianyi Sun, Abbas Ghaddar, Mohammad Ali Alomrani, Liheng Ma, Yu Luo, Dong Li, Feng Wen, Jianye Hao, Mark Coates, Yingxue Zhang', 'link': 'https://arxiv.org/abs/2507.14783', 'abstract': 'The advancement of general-purpose artificial intelligence relies on large language models (LLMs) that excel across a wide range of tasks, from structured reasoning to creative generation. However, post-training methods like Supervised Fine-Tuning (SFT) often struggle with generalization, favoring memorization over transferable learning. In this work, we introduce Omni-Think, a unified reinforcement learning (RL) framework that enhances LLM performance across diverse tasks by combining rule-based verifiable rewards with generative preference signals via LLM-as-a-Judge evaluations. Our approach enables consistent optimization across task types and scales RL-based training to subjective domains. We further investigate training strategies, demonstrating that a curriculum-based progression that orders tasks from structured to open-ended improves performance and reduces forgetting. Experimental results across four domains reveal that curriculum learning improves performance by 5.2\\% over joint training and 9.1\\% over model merging. These results highlight the importance of task-aware sampling and hybrid supervision in scaling RL-based post-training for general-purpose LLMs.', 'abstract_zh': '通用人工智能的进步依赖于卓越执行广泛任务的大规模语言模型（LLMs），从结构化推理到创造性生成。然而，训练后方法如监督微调（SFT）往往在泛化能力上面临挑战，倾向于记忆而非可转移学习。在本工作中，我们提出了一种统一的强化学习（RL）框架Omni-Think，通过将基于规则的可验证奖励与生成偏好信号结合，借助LLM作为评判者评估（LLM-as-a-Judge），提升LLM在多样任务中的性能。我们的方法能够在不同任务类型中实现一致优化，并将基于RL的训练扩展到主观领域。我们进一步研究了训练策略，表明从结构化任务过渡到开放性任务的课程式学习顺序能够提高性能并减少遗忘。跨四大领域实验结果表明，课程学习在联合训练中的性能提升了5.2%，在模型合并中的性能提升了9.1%。这些结果突显了在通用人工智能的RL后训练中任务感知采样和混合监督的重要性。', 'title_zh': '全方位思考：通过混合奖励的多任务RL扩展LLM的跨域泛化'}
{'arxiv_id': 'arXiv:2507.14767', 'title': 'XplainAct: Visualization for Personalized Intervention Insights', 'authors': 'Yanming Zhang, Krishnakumar Hegde, Klaus Mueller', 'link': 'https://arxiv.org/abs/2507.14767', 'abstract': 'Causality helps people reason about and understand complex systems, particularly through what-if analyses that explore how interventions might alter outcomes. Although existing methods embrace causal reasoning using interventions and counterfactual analysis, they primarily focus on effects at the population level. These approaches often fall short in systems characterized by significant heterogeneity, where the impact of an intervention can vary widely across subgroups. To address this challenge, we present XplainAct, a visual analytics framework that supports simulating, explaining, and reasoning interventions at the individual level within subpopulations. We demonstrate the effectiveness of XplainAct through two case studies: investigating opioid-related deaths in epidemiology and analyzing voting inclinations in the presidential election.', 'abstract_zh': '因果关系有助于人们推理和理解复杂系统，特别是通过情景分析来探究干预措施如何改变结果。尽管现有的方法使用干预和反事实分析来支持因果推理，但它们主要关注整体层面的效果。这些方法在具有显著异质性的系统中往往表现不佳，因为干预的影响在不同子群体中可能差异很大。为了解决这一挑战，我们提出了XplainAct这一可视化分析框架，支持在子群体中对个体水平的干预进行模拟、解释和推理。我们通过两个案例研究展示了XplainAct的有效性：研究流行病学中的阿片类药物相关死亡事件，以及分析总统选举中的投票倾向。', 'title_zh': 'XplainAct：个性化干预洞察可视化'}
{'arxiv_id': 'arXiv:2507.14766', 'title': 'CXR-TFT: Multi-Modal Temporal Fusion Transformer for Predicting Chest X-ray Trajectories', 'authors': 'Mehak Arora, Ayman Ali, Kaiyuan Wu, Carolyn Davis, Takashi Shimazui, Mahmoud Alwakeel, Victor Moas, Philip Yang, Annette Esper, Rishikesan Kamaleswaran', 'link': 'https://arxiv.org/abs/2507.14766', 'abstract': "In intensive care units (ICUs), patients with complex clinical conditions require vigilant monitoring and prompt interventions. Chest X-rays (CXRs) are a vital diagnostic tool, providing insights into clinical trajectories, but their irregular acquisition limits their utility. Existing tools for CXR interpretation are constrained by cross-sectional analysis, failing to capture temporal dynamics. To address this, we introduce CXR-TFT, a novel multi-modal framework that integrates temporally sparse CXR imaging and radiology reports with high-frequency clinical data, such as vital signs, laboratory values, and respiratory flow sheets, to predict the trajectory of CXR findings in critically ill patients. CXR-TFT leverages latent embeddings from a vision encoder that are temporally aligned with hourly clinical data through interpolation. A transformer model is then trained to predict CXR embeddings at each hour, conditioned on previous embeddings and clinical measurements. In a retrospective study of 20,000 ICU patients, CXR-TFT demonstrated high accuracy in forecasting abnormal CXR findings up to 12 hours before they became radiographically evident. This predictive capability in clinical data holds significant potential for enhancing the management of time-sensitive conditions like acute respiratory distress syndrome, where early intervention is crucial and diagnoses are often delayed. By providing distinctive temporal resolution in prognostic CXR analysis, CXR-TFT offers actionable 'whole patient' insights that can directly improve clinical outcomes.", 'abstract_zh': '在重症监护单位（ICUs）中，具有复杂临床状况的患者需要严密监测和及时干预。胸部X光片（CXRs）是重要的诊断工具，提供了临床病程的见解，但由于其不规律的获取限制了其应用。现有的CXR解读工具受限于横截面分析，无法捕捉时间动态。为了解决这一问题，我们引入了CXR-TFT，这是一种新的多模态框架，结合了时间上稀疏的CXR影像和放射学报告以及高频临床数据（如生命体征、实验室值和呼吸流量表），以预测危重患者CXR发现的病程。CXR-TFT利用前景编码器的潜在嵌入，通过内插与每小时临床数据的时间对齐。然后，通过条件于先前嵌入和临床测量，训练了一个变压器模型来每小时预测CXR嵌入。在一项包含20,000名ICU患者的回顾性研究中，CXR-TFT在预测胸部X光片异常发现方面表现出高度准确性，提前12小时即可准确预知这些异常发现。这种在临床数据中的预测能力对于增强急性呼吸窘迫综合征等需要及时干预的疾病管理具有重要潜力，因为早期干预至关重要且诊断往往延后。通过提供前瞻性CXR分析的独特时间分辨率，CXR-TFT提供了可操作的“全患者”洞察，可以直接改善临床结果。', 'title_zh': 'CXR-TFT：多模态时间融合变换器用于预测胸部X光 trajectories'}
{'arxiv_id': 'arXiv:2507.14760', 'title': 'QUTCC: Quantile Uncertainty Training and Conformal Calibration for Imaging Inverse Problems', 'authors': 'Cassandra Tong Ye, Shamus Li, Tyler King, Kristina Monakhova', 'link': 'https://arxiv.org/abs/2507.14760', 'abstract': 'Deep learning models often hallucinate, producing realistic artifacts that are not truly present in the sample. This can have dire consequences for scientific and medical inverse problems, such as MRI and microscopy denoising, where accuracy is more important than perceptual quality. Uncertainty quantification techniques, such as conformal prediction, can pinpoint outliers and provide guarantees for image regression tasks, improving reliability. However, existing methods utilize a linear constant scaling factor to calibrate uncertainty bounds, resulting in larger, less informative bounds. We propose QUTCC, a quantile uncertainty training and calibration technique that enables nonlinear, non-uniform scaling of quantile predictions to enable tighter uncertainty estimates. Using a U-Net architecture with a quantile embedding, QUTCC enables the prediction of the full conditional distribution of quantiles for the imaging task. During calibration, QUTCC generates uncertainty bounds by iteratively querying the network for upper and lower quantiles, progressively refining the bounds to obtain a tighter interval that captures the desired coverage. We evaluate our method on several denoising tasks as well as compressive MRI reconstruction. Our method successfully pinpoints hallucinations in image estimates and consistently achieves tighter uncertainty intervals than prior methods while maintaining the same statistical coverage.', 'abstract_zh': '基于深度学习模型的图像处理中非真实artifact的量化不确定性训练与校准技术', 'title_zh': 'QUTCC: 基于分位数不确定性训练与渐进校准的成像逆问题方法'}
{'arxiv_id': 'arXiv:2507.14758', 'title': 'GRACE: Generative Recommendation via Journey-Aware Sparse Attention on Chain-of-Thought Tokenization', 'authors': 'Luyi Ma, Wanjia Zhang, Kai Zhao, Abhishek Kulkarni, Lalitesh Morishetti, Anjana Ganesh, Ashish Ranjan, Aashika Padmanabhan, Jianpeng Xu, Jason Cho, Praveen Kanumala, Kaushiki Nag, Sumit Dutta, Kamiya Motwani, Malay Patel, Evren Korpeoglu, Sushant Kumar, Kannan Achan', 'link': 'https://arxiv.org/abs/2507.14758', 'abstract': 'Generative models have recently demonstrated strong potential in multi-behavior recommendation systems, leveraging the expressive power of transformers and tokenization to generate personalized item sequences. However, their adoption is hindered by (1) the lack of explicit information for token reasoning, (2) high computational costs due to quadratic attention complexity and dense sequence representations after tokenization, and (3) limited multi-scale modeling over user history. In this work, we propose GRACE (Generative Recommendation via journey-aware sparse Attention on Chain-of-thought tokEnization), a novel generative framework for multi-behavior sequential recommendation. GRACE introduces a hybrid Chain-of-Thought (CoT) tokenization method that encodes user-item interactions with explicit attributes from product knowledge graphs (e.g., category, brand, price) over semantic tokenization, enabling interpretable and behavior-aligned generation. To address the inefficiency of standard attention, we design a Journey-Aware Sparse Attention (JSA) mechanism, which selectively attends to compressed, intra-, inter-, and current-context segments in the tokenized sequence. Experiments on two real-world datasets show that GRACE significantly outperforms state-of-the-art baselines, achieving up to +106.9% HR@10 and +106.7% NDCG@10 improvement over the state-of-the-art baseline on the Home domain, and +22.1% HR@10 on the Electronics domain. GRACE also reduces attention computation by up to 48% with long sequences.', 'abstract_zh': '基于旅程意识稀疏注意力的链式思考token化生成推荐算法', 'title_zh': 'GRACE：基于旅程意识稀疏注意力的链式思考生成推荐'}
{'arxiv_id': 'arXiv:2507.14757', 'title': 'Analyzing Internal Activity and Robustness of SNNs Across Neuron Parameter Space', 'authors': 'Szymon Mazurek, Jakub Caputa, Maciej Wielgosz', 'link': 'https://arxiv.org/abs/2507.14757', 'abstract': 'Spiking Neural Networks (SNNs) offer energy-efficient and biologically plausible alternatives to traditional artificial neural networks, but their performance depends critically on the tuning of neuron model parameters. In this work, we identify and characterize an operational space - a constrained region in the neuron hyperparameter domain (specifically membrane time constant tau and voltage threshold vth) - within which the network exhibits meaningful activity and functional behavior. Operating inside this manifold yields optimal trade-offs between classification accuracy and spiking activity, while stepping outside leads to degeneration: either excessive energy use or complete network silence.\nThrough systematic exploration across datasets and architectures, we visualize and quantify this manifold and identify efficient operating points. We further assess robustness to adversarial noise, showing that SNNs exhibit increased spike correlation and internal synchrony when operating outside their optimal region. These findings highlight the importance of principled hyperparameter tuning to ensure both task performance and energy efficiency. Our results offer practical guidelines for deploying robust and efficient SNNs, particularly in neuromorphic computing scenarios.', 'abstract_zh': '基于神经元模型参数调谐的高效和生物可塑性强脉冲神经网络的操作空间研究', 'title_zh': '分析SNNs在神经元参数空间内的内部活动和鲁棒性'}
{'arxiv_id': 'arXiv:2507.14748', 'title': 'Skill Learning via Policy Diversity Yields Identifiable Representations for Reinforcement Learning', 'authors': 'Patrik Reizinger, Bálint Mucsányi, Siyuan Guo, Benjamin Eysenbach, Bernhard Schölkopf, Wieland Brendel', 'link': 'https://arxiv.org/abs/2507.14748', 'abstract': "Self-supervised feature learning and pretraining methods in reinforcement learning (RL) often rely on information-theoretic principles, termed mutual information skill learning (MISL). These methods aim to learn a representation of the environment while also incentivizing exploration thereof. However, the role of the representation and mutual information parametrization in MISL is not yet well understood theoretically. Our work investigates MISL through the lens of identifiable representation learning by focusing on the Contrastive Successor Features (CSF) method. We prove that CSF can provably recover the environment's ground-truth features up to a linear transformation due to the inner product parametrization of the features and skill diversity in a discriminative sense. This first identifiability guarantee for representation learning in RL also helps explain the implications of different mutual information objectives and the downsides of entropy regularizers. We empirically validate our claims in MuJoCo and DeepMind Control and show how CSF provably recovers the ground-truth features both from states and pixels.", 'abstract_zh': '自监督特征学习和预训练方法在强化学习（RL）中的信息论原理，即互信息技能学习（MISL），通过可识别表示学习视角对MISL进行研究', 'title_zh': '基于策略多样性的技能学习生成可识别的表示形式'}
{'arxiv_id': 'arXiv:2507.14725', 'title': 'Task-Agnostic Continual Prompt Tuning with Gradient-Based Selection and Decoding', 'authors': 'Anushka Tiwari, Sayantan Pal, Rohini K. Srihari, Kaiyi Ji', 'link': 'https://arxiv.org/abs/2507.14725', 'abstract': 'Prompt-based continual learning (CL) offers a parameter-efficient way to adapt large language models (LLMs) across task sequences. However, most existing methods assume task-aware inference and maintain a growing list of task-specific prompts, which limits scalability and hides latent forgetting. In this work, we introduce GRID, a unified framework that addresses two key limitations: (1) latent forgetting under task-agnostic inference, and (2) prompt memory explosion as task sequences grow. GRID integrates a task-aware decoding mechanism that improves backward transfer by leveraging representative inputs, automatic task identification, and constrained decoding. Additionally, we propose a gradient-based prompt selection strategy that compresses less informative prompts into a single aggregated representation, enabling scalable and memory-efficient lifelong learning. Extensive experiments across short-sequence, long-sequence, and negative transfer benchmarks show that GRID significantly improves backward transfer, achieves competitive forward transfer, and reduces forgotten tasks by up to 80\\%, outperforming state-of-the-art methods on T5 and Flan-T5 backbones.', 'abstract_zh': '基于提示的持续学习（CL）提供了一种参数高效的大型语言模型（LLMs）跨任务序列适应的方法。然而，现有大多数方法假设任务感知推理，并维护一个Growing的任务特定提示列表，这限制了其扩展性并掩盖了潜在遗忘。本文引入了GRID，这是一种统一框架，解决了两个关键限制：（1）任务不可知推理下的潜在遗忘，（2）随着任务序列增长提示内存爆炸。GRID 结合了一种任务感知解码机制，通过利用代表性输入、自动任务识别和受限解码来提高反向迁移。此外，我们提出了一个基于梯度的提示选择策略，将不具信息性的提示压缩为单一聚合表示，从而实现可扩展且内存高效的终生学习。跨短序列、长序列和负迁移基准的广泛实验表明，GRID 显著提高了反向迁移，实现了竞争力前向迁移，并通过合并未被遗忘的任务最多80%，在T5和Flan-T5骨干模型上优于现有最先进的方法。', 'title_zh': '基于梯度选择与解码的无任务依赖连续提示调优'}
{'arxiv_id': 'arXiv:2507.14722', 'title': 'LeanTree: Accelerating White-Box Proof Search with Factorized States in Lean 4', 'authors': 'Matěj Kripner, Michal Šustr, Milan Straka', 'link': 'https://arxiv.org/abs/2507.14722', 'abstract': 'Automated theorem proving (ATP) has been a classical problem in artificial intelligence since its inception, yet it remains challenging due to its vast state and action space. Large language models (LLMs) have recently emerged as a promising heuristic for ATP, but they lack correctness guarantees and thus require interaction with a proof verifier. Such interactions typically follow one of two approaches: black-box interaction, which does not utilize intermediate proof states, or white-box approaches, which allow for incremental proof construction and examination of intermediate states. While black-box approaches have directly benefited from recent LLM advances, white-box methods have comparatively lagged behind. In this paper, we address this gap by introducing LeanTree, which consists of (i) a tool built in the Lean 4 language that factorizes complex proof states into simpler, independent branches, and (ii) a dataset of these factorized intermediate states. Our white-box tooling offers several advantages over black-box approaches: it simplifies evaluation, reduces necessary context, generates richer training data, enables parallel search across multiple states, supports efficient reuse of states, and provides feedback in case of errors. Our preliminary results hint that white-box approaches outperform black-box alternatives in some settings.', 'abstract_zh': '自动定理证明（ATP）自人工智能诞生之日起就是经典问题，但由于其庞大的状态和动作空间，依然极具挑战性。近年来，大型语言模型（LLMs）被认为是一种有前景的ATP启发式方法，但缺乏正确性保证，因此需要与证明验证器交互。此类交互通常遵循两种方法之一：黑箱交互，不利用中间证明状态；或白箱方法，允许增量证明构建并检查中间状态。尽管黑箱方法直接受益于最近的LLM进展，白箱方法则相对滞后。本文通过引入LeanTree来填补这一空白，LeanTree包括（i）一种基于Lean 4语言的工具，将复杂的证明状态分解为更简单、独立的分支，以及（ii）这些分解的中间状态的数据集。我们的白箱工具提供了黑箱方法的多项优势：简化评估、减少必要上下文、生成更丰富的训练数据、支持在多个状态上并行搜索、支持状态的高效重用，并在出现错误时提供反馈。初步结果表明，在某些情况下，白箱方法优于黑箱替代方法。', 'title_zh': 'LeanTree: 在 Lean 4 中使用因子化状态加速白盒证明搜索'}
{'arxiv_id': 'arXiv:2507.14706', 'title': 'Fraud is Not Just Rarity: A Causal Prototype Attention Approach to Realistic Synthetic Oversampling', 'authors': 'Claudio Giusti, Luca Guarnera, Mirko Casu, Sebastiano Battiato', 'link': 'https://arxiv.org/abs/2507.14706', 'abstract': 'Detecting fraudulent credit card transactions remains a significant challenge, due to the extreme class imbalance in real-world data and the often subtle patterns that separate fraud from legitimate activity. Existing research commonly attempts to address this by generating synthetic samples for the minority class using approaches such as GANs, VAEs, or hybrid generative models. However, these techniques, particularly when applied only to minority-class data, tend to result in overconfident classifiers and poor latent cluster separation, ultimately limiting real-world detection performance. In this study, we propose the Causal Prototype Attention Classifier (CPAC), an interpretable architecture that promotes class-aware clustering and improved latent space structure through prototype-based attention mechanisms and we will couple it with the encoder in a VAE-GAN allowing it to offer a better cluster separation moving beyond post-hoc sample augmentation. We compared CPAC-augmented models to traditional oversamplers, such as SMOTE, as well as to state-of-the-art generative models, both with and without CPAC-based latent classifiers. Our results show that classifier-guided latent shaping with CPAC delivers superior performance, achieving an F1-score of 93.14\\% percent and recall of 90.18\\%, along with improved latent cluster separation. Further ablation studies and visualizations provide deeper insight into the benefits and limitations of classifier-driven representation learning for fraud detection. The codebase for this work will be available at final submission.', 'abstract_zh': '基于因果原型注意机制的欺诈信用卡交易检测方法：超越事后样本增强的潜在空间结构优化', 'title_zh': '欺诈不仅是罕见事件：一种因果原型注意力方法实现现实合成过采样'}
{'arxiv_id': 'arXiv:2507.14698', 'title': 'Spatial-Temporal Transformer with Curriculum Learning for EEG-Based Emotion Recognition', 'authors': 'Xuetao Lin, Tianhao Peng, Peihong Dai, Yu Liang, Wenjun Wu', 'link': 'https://arxiv.org/abs/2507.14698', 'abstract': 'EEG-based emotion recognition plays an important role in developing adaptive brain-computer communication systems, yet faces two fundamental challenges in practical implementations: (1) effective integration of non-stationary spatial-temporal neural patterns, (2) robust adaptation to dynamic emotional intensity variations in real-world scenarios. This paper proposes SST-CL, a novel framework integrating spatial-temporal transformers with curriculum learning. Our method introduces two core components: a spatial encoder that models inter-channel relationships and a temporal encoder that captures multi-scale dependencies through windowed attention mechanisms, enabling simultaneous extraction of spatial correlations and temporal dynamics from EEG signals. Complementing this architecture, an intensity-aware curriculum learning strategy progressively guides training from high-intensity to low-intensity emotional states through dynamic sample scheduling based on a dual difficulty assessment. Comprehensive experiments on three benchmark datasets demonstrate state-of-the-art performance across various emotional intensity levels, with ablation studies confirming the necessity of both architectural components and the curriculum learning mechanism.', 'abstract_zh': '基于EEG的情绪识别在开发适应性脑机通信系统中扮演重要角色，但在实际应用中面临两个基本挑战：(1) 有效集成非平稳的空间- temporal神经模式，(2) 在现实场景中 robust应 动态情绪强度的变化。本文提出了一种新颖的框架SST-CL，该框架结合了空间- temporal变换器和 curriculum学习。我们的方法引入了两种核心组件：一个空间编码器，用于建模通道间关系；一个时间编码器，通过窗口注意力机制捕获多尺度依赖性，从而同时从EEG信号中提取空间相关性和时间动态性。作为该架构的补充，一种情绪感知的curriculum学习策略逐步通过基于双重难度评估的动态样本调度来引导从高强度到低强度情绪状态的训练。在三个基准数据集上的全面实验表明，该方法在各种情绪强度水平上具有最先进的性能，消融研究证实了两种架构组件和curriculum学习机制的必要性。', 'title_zh': '基于EEG的情感识别中的渐增学习空间-时间变换器'}
{'arxiv_id': 'arXiv:2507.14693', 'title': 'Rethinking Suicidal Ideation Detection: A Trustworthy Annotation Framework and Cross-Lingual Model Evaluation', 'authors': 'Amina Dzafic, Merve Kavut, Ulya Bayram', 'link': 'https://arxiv.org/abs/2507.14693', 'abstract': 'Suicidal ideation detection is critical for real-time suicide prevention, yet its progress faces two under-explored challenges: limited language coverage and unreliable annotation practices. Most available datasets are in English, but even among these, high-quality, human-annotated data remains scarce. As a result, many studies rely on available pre-labeled datasets without examining their annotation process or label reliability. The lack of datasets in other languages further limits the global realization of suicide prevention via artificial intelligence (AI). In this study, we address one of these gaps by constructing a novel Turkish suicidal ideation corpus derived from social media posts and introducing a resource-efficient annotation framework involving three human annotators and two large language models (LLMs). We then address the remaining gaps by performing a bidirectional evaluation of label reliability and model consistency across this dataset and three popular English suicidal ideation detection datasets, using transfer learning through eight pre-trained sentiment and emotion classifiers. These transformers help assess annotation consistency and benchmark model performance against manually labeled data. Our findings underscore the need for more rigorous, language-inclusive approaches to annotation and evaluation in mental health natural language processing (NLP) while demonstrating the questionable performance of popular models with zero-shot transfer learning. We advocate for transparency in model training and dataset construction in mental health NLP, prioritizing data and model reliability.', 'abstract_zh': '自杀 ideation 检测对于实时自杀预防至关重要，但其进展面临两个未被充分研究的挑战：有限的语言覆盖面和不可靠的注释实践。', 'title_zh': '重新思考自杀意念检测：可信赖的注释框架与跨语言模型评估'}
{'arxiv_id': 'arXiv:2507.14688', 'title': 'Mind the Gap: A Review of Arabic Post-Training Datasets and Their Limitations', 'authors': 'Mohammed Alkhowaiter, Norah Alshahrani, Saied Alshahrani, Reem I. Masoud, Alaa Alzahrani, Deema Alnuhait, Emad A. Alghamdi, Khalid Almubarak', 'link': 'https://arxiv.org/abs/2507.14688', 'abstract': 'Post-training has emerged as a crucial technique for aligning pre-trained Large Language Models (LLMs) with human instructions, significantly enhancing their performance across a wide range of tasks. Central to this process is the quality and diversity of post-training datasets. This paper presents a review of publicly available Arabic post-training datasets on the Hugging Face Hub, organized along four key dimensions: (1) LLM Capabilities (e.g., Question Answering, Translation, Reasoning, Summarization, Dialogue, Code Generation, and Function Calling); (2) Steerability (e.g., persona and system prompts); (3) Alignment (e.g., cultural, safety, ethics, and fairness), and (4) Robustness. Each dataset is rigorously evaluated based on popularity, practical adoption, recency and maintenance, documentation and annotation quality, licensing transparency, and scientific contribution. Our review revealed critical gaps in the development of Arabic post-training datasets, including limited task diversity, inconsistent or missing documentation and annotation, and low adoption across the community. Finally, the paper discusses the implications of these gaps on the progress of Arabic LLMs and applications while providing concrete recommendations for future efforts in post-training dataset development.', 'abstract_zh': 'Post-培训技术已成为将预训练大型语言模型（LLM）与人类指令对齐的关键技术，显著提升了其在广泛任务中的性能。本文审查了Hugging Face Hub上公开可用的阿拉伯语后培训数据集，按照四个关键维度组织：（1）LLM能力（如问答、翻译、推理、总结、对话、代码生成和功能调用）；（2）可控性（如人物和系统提示）；（3）对齐（如文化、安全、伦理和公平）；（4）鲁棒性。每个数据集都基于受欢迎程度、实际应用、时效性和维护、文档和注解质量、许可透明度以及科学贡献进行了严格评估。我们的审查揭示了阿拉伯语后培训数据集开发中的关键缺失，包括任务多样性有限、文档和注解不一致或缺失以及社区中的低采用率。最后，本文讨论了这些缺失对阿拉伯语LLM及其应用进展的影响，并提供了未来后培训数据集开发的努力的具体建议。', 'title_zh': '填补差距：阿拉伯后训练数据集及其局限性综述'}
{'arxiv_id': 'arXiv:2507.14680', 'title': 'WSI-Agents: A Collaborative Multi-Agent System for Multi-Modal Whole Slide Image Analysis', 'authors': 'Xinheng Lyu, Yuci Liang, Wenting Chen, Meidan Ding, Jiaqi Yang, Guolin Huang, Daokun Zhang, Xiangjian He, Linlin Shen', 'link': 'https://arxiv.org/abs/2507.14680', 'abstract': "Whole slide images (WSIs) are vital in digital pathology, enabling gigapixel tissue analysis across various pathological tasks. While recent advancements in multi-modal large language models (MLLMs) allow multi-task WSI analysis through natural language, they often underperform compared to task-specific models. Collaborative multi-agent systems have emerged as a promising solution to balance versatility and accuracy in healthcare, yet their potential remains underexplored in pathology-specific domains. To address these issues, we propose WSI-Agents, a novel collaborative multi-agent system for multi-modal WSI analysis. WSI-Agents integrates specialized functional agents with robust task allocation and verification mechanisms to enhance both task-specific accuracy and multi-task versatility through three components: (1) a task allocation module assigning tasks to expert agents using a model zoo of patch and WSI level MLLMs, (2) a verification mechanism ensuring accuracy through internal consistency checks and external validation using pathology knowledge bases and domain-specific models, and (3) a summary module synthesizing the final summary with visual interpretation maps. Extensive experiments on multi-modal WSI benchmarks show WSI-Agents's superiority to current WSI MLLMs and medical agent frameworks across diverse tasks.", 'abstract_zh': '基于多模态WSI分析的WSI-Agents多代理系统', 'title_zh': 'WSI-Agents：一种用于多模态全玻片图像分析的协作多-Agent系统'}
{'arxiv_id': 'arXiv:2507.14679', 'title': 'GCC-Spam: Spam Detection via GAN, Contrastive Learning, and Character Similarity Networks', 'authors': 'Zixin Xu, Zhijie Wang, Zhiyuan Pan', 'link': 'https://arxiv.org/abs/2507.14679', 'abstract': 'The exponential growth of spam text on the Internet necessitates robust detection mechanisms to mitigate risks such as information leakage and social instability. This work addresses two principal challenges: adversarial strategies employed by spammers and the scarcity of labeled data. We propose a novel spam-text detection framework GCC-Spam, which integrates three core innovations. First, a character similarity network captures orthographic and phonetic features to counter character-obfuscation attacks and furthermore produces sentence embeddings for downstream classification. Second, contrastive learning enhances discriminability by optimizing the latent-space distance between spam and normal texts. Third, a Generative Adversarial Network (GAN) generates realistic pseudo-spam samples to alleviate data scarcity while improving model robustness and classification accuracy. Extensive experiments on real-world datasets demonstrate that our model outperforms baseline approaches, achieving higher detection rates with significantly fewer labeled examples.', 'abstract_zh': '互联网上垃圾文本的指数级增长 necessitates robust detection mechanisms to mitigate risks such as information leakage and social instability. This work addresses two principal challenges: adversarial strategies employed by spammers and the scarcity of labeled data. We propose a novel spam-text detection framework GCC-Spam, which integrates three core innovations. First, a character similarity network captures orthographic and phonetic features to counter character-obfuscation attacks and furthermore produces sentence embeddings for downstream classification. Second, contrastive learning enhances discriminability by optimizing the latent-space distance between spam and normal texts. Third, a Generative Adversarial Network (GAN) generates realistic pseudo-spam samples to alleviate data scarcity while improving model robustness and classification accuracy. Extensive experiments on real-world datasets demonstrate that our model outperforms baseline approaches, achieving higher detection rates with significantly fewer labeled examples.', 'title_zh': 'GCC-Spam: 通过生成对抗网络、对比学习和字符相似性网络的垃圾信息检测方法'}
{'arxiv_id': 'arXiv:2507.14662', 'title': 'Artificial Intelligence in the Food Industry: Food Waste Estimation based on Computer Vision, a Brief Case Study in a University Dining Hall', 'authors': 'Shayan Rokhva, Babak Teimourpour', 'link': 'https://arxiv.org/abs/2507.14662', 'abstract': 'Quantifying post-consumer food waste in institutional dining settings is essential for supporting data-driven sustainability strategies. This study presents a cost-effective computer vision framework that estimates plate-level food waste by utilizing semantic segmentation of RGB images taken before and after meal consumption across five Iranian dishes. Four fully supervised models (U-Net, U-Net++, and their lightweight variants) were trained using a capped dynamic inverse-frequency loss and AdamW optimizer, then evaluated through a comprehensive set of metrics, including Pixel Accuracy, Dice, IoU, and a custom-defined Distributional Pixel Agreement (DPA) metric tailored to the task. All models achieved satisfying performance, and for each food type, at least one model approached or surpassed 90% DPA, demonstrating strong alignment in pixel-wise proportion estimates. Lighter models with reduced parameter counts offered faster inference, achieving real-time throughput on an NVIDIA T4 GPU. Further analysis showed superior segmentation performance for dry and more rigid components (e.g., rice and fries), while more complex, fragmented, or viscous dishes, such as stews, showed reduced performance, specifically post-consumption. Despite limitations such as reliance on 2D imaging, constrained food variety, and manual data collection, the proposed framework is pioneering and represents a scalable, contactless solution for continuous monitoring of food consumption. This research lays foundational groundwork for automated, real-time waste tracking systems in large-scale food service environments and offers actionable insights and outlines feasible future directions for dining hall management and policymakers aiming to reduce institutional food waste.', 'abstract_zh': '在机构餐饮环境中量化后消费者食物浪费对于支持数据驱动的可持续发展战略至关重要。本研究提出了一种成本有效的计算机视觉框架，通过利用RGB图像（餐前和餐后）的语义分割来估计盘级食物浪费，应用于五种伊朗菜肴。四种完全监督模型（U-Net、U-Net++及其轻量级变体）使用上限动态逆频率损失和AdamW优化器进行了训练，并通过包括像素准确性、Dice、IoU以及为任务定制的分布像素一致度（DPA）指标等全面评估指标进行了评估。所有模型均表现出令人满意的性能，对于每种食物类型，至少有一个模型的DPA接近或超过90%，显示出强烈的像素级比例估计的一致性。轻量级模型由于参数减少而具有更快的推断速度，在NVIDIA T4 GPU上实现了实时吞吐量。进一步分析显示，干燥和更刚性成分（如米饭和薯条）的分割性能更优，而更复杂的、碎片化的或粘稠的菜肴（如炖菜），在餐后表现出较低的性能。尽管存在依赖二维成像、食物品种受限和人工数据收集等局限性，所提出的框架仍具有开创性，并代表了一种可扩展、无接触的解决方案，用于大型餐饮服务环境中的连续食物消耗监测。本研究为自动、实时的浪费跟踪系统奠定了基础，并为餐饮管理机构和政策制定者提供了可操作的见解和可行的未来方向，以减少机构食物浪费。', 'title_zh': '人工智能在食品工业中的应用：基于计算机视觉的食品浪费估计——以大学食堂为例的简要案例研究'}
{'arxiv_id': 'arXiv:2507.14657', 'title': 'AI-Powered Precision in Sport Taekwondo: Enhancing Fairness, Speed, and Trust in Competition (FST.ai)', 'authors': 'Keivan Shariatmadar, Ahmad Osman', 'link': 'https://arxiv.org/abs/2507.14657', 'abstract': "The integration of Artificial Intelligence (AI) into sports officiating represents a paradigm shift in how decisions are made in competitive environments. Traditional manual systems, even when supported by Instant Video Replay (IVR), often suffer from latency, subjectivity, and inconsistent enforcement, undermining fairness and athlete trust. This paper introduces this http URL, a novel AI-powered framework designed to enhance officiating in Sport Taekwondo, particularly focusing on the complex task of real-time head kick detection and scoring. Leveraging computer vision, deep learning, and edge inference, the system automates the identification and classification of key actions, significantly reducing decision time from minutes to seconds while improving consistency and transparency. Importantly, the methodology is not limited to Taekwondo. The underlying framework -- based on pose estimation, motion classification, and impact analysis -- can be adapted to a wide range of sports requiring action detection, such as judo, karate, fencing, or even team sports like football and basketball, where foul recognition or performance tracking is critical. By addressing one of Taekwondo's most challenging scenarios -- head kick scoring -- we demonstrate the robustness, scalability, and sport-agnostic potential of this http URL to transform officiating standards across multiple disciplines.", 'abstract_zh': '将人工智能（AI）融入体育裁判代表着在竞争环境中决策方式的一场范式转变。传统的手动系统即使有即时视频回放（IVR）的支持，也常常面临延迟、主观性和执行不一致的问题，这损害了公平性和运动员的信任。本文介绍了一种新的基于AI的框架——this http URL，旨在增强跆拳道中的裁判工作，特别是专注于实时头部踢击检测和评分这一复杂任务。该系统利用计算机视觉、深度学习和边缘推断，自动识别和分类关键动作，显著减少决策时间，从几分钟缩短到几秒钟，同时提高一致性和透明度。重要的是，该方法不仅限于跆拳道。基于姿态估计、动作分类和冲击分析的底层框架，可以适应各种需要动作检测的体育运动，如柔道、空手道、击剑，甚至足球和篮球等团队运动，其中犯规识别或表现追踪至关重要。通过对跆拳道最具挑战性的场景——头部踢击评分——的解决，本文展示了this http URL的稳健性、可扩展性和体育运动无关的潜力，有望在多个学科中转型裁判标准。', 'title_zh': '基于AI的运动跆拳道精准技术：提升竞赛的公平性、速度和信任（FST.ai）'}
{'arxiv_id': 'arXiv:2507.14649', 'title': 'Cleanse: Uncertainty Estimation Approach Using Clustering-based Semantic Consistency in LLMs', 'authors': 'Minsuh Joo, Hyunsoo Cho', 'link': 'https://arxiv.org/abs/2507.14649', 'abstract': 'Despite the outstanding performance of large language models (LLMs) across various NLP tasks, hallucinations in LLMs--where LLMs generate inaccurate responses--remains as a critical problem as it can be directly connected to a crisis of building safe and reliable LLMs. Uncertainty estimation is primarily used to measure hallucination levels in LLM responses so that correct and incorrect answers can be distinguished clearly. This study proposes an effective uncertainty estimation approach, \\textbf{Cl}ust\\textbf{e}ring-based sem\\textbf{an}tic con\\textbf{s}ist\\textbf{e}ncy (\\textbf{Cleanse}). Cleanse quantifies the uncertainty with the proportion of the intra-cluster consistency in the total consistency between LLM hidden embeddings which contain adequate semantic information of generations, by employing clustering. The effectiveness of Cleanse for detecting hallucination is validated using four off-the-shelf models, LLaMA-7B, LLaMA-13B, LLaMA2-7B and Mistral-7B and two question-answering benchmarks, SQuAD and CoQA.', 'abstract_zh': '尽管大型语言模型在各种NLP任务中表现出色，但其中的幻觉问题——即大型语言模型生成不准确响应——仍然是一个关键问题，因为它与构建安全可靠的大型语言模型的危机直接相关。通过不确定性估计来衡量大型语言模型响应中的幻觉水平，以便清晰地区分正确和错误的答案。本研究提出了一种有效的不确定性估计方法，基于聚类的语义一致性（Cleanse）。Cleanse通过聚类，用聚类内的一致性比例衡量总一致性的不确定性，其中包含足够的生成语义信息。Cleanse检测幻觉的有效性使用四种现成模型（LLaMA-7B、LLaMA-13B、LLaMA2-7B和Mistral-7B）和两个问答基准（SQuAD和CoQA）进行了验证。', 'title_zh': 'Cleanse: 基于聚类语义一致性的心智模型不确定性估计方法'}
{'arxiv_id': 'arXiv:2507.14629', 'title': 'VMask: Tunable Label Privacy Protection for Vertical Federated Learning via Layer Masking', 'authors': 'Juntao Tan, Lan Zhang, Zhonghao Hu, Kai Yang, Peng Ran, Bo Li', 'link': 'https://arxiv.org/abs/2507.14629', 'abstract': "Though vertical federated learning (VFL) is generally considered to be privacy-preserving, recent studies have shown that VFL system is vulnerable to label inference attacks originating from various attack surfaces. Among these attacks, the model completion (MC) attack is currently the most powerful one. Existing defense methods against it either sacrifice model accuracy or incur impractical computational overhead. In this paper, we propose VMask, a novel label privacy protection framework designed to defend against MC attack from the perspective of layer masking. Our key insight is to disrupt the strong correlation between input data and intermediate outputs by applying the secret sharing (SS) technique to mask layer parameters in the attacker's model. We devise a strategy for selecting critical layers to mask, reducing the overhead that would arise from naively applying SS to the entire model. Moreover, VMask is the first framework to offer a tunable privacy budget to defenders, allowing for flexible control over the levels of label privacy according to actual requirements. We built a VFL system, implemented VMask on it, and extensively evaluated it using five model architectures and 13 datasets with different modalities, comparing it to 12 other defense methods. The results demonstrate that VMask achieves the best privacy-utility trade-off, successfully thwarting the MC attack (reducing the label inference accuracy to a random guessing level) while preserving model performance (e.g., in Transformer-based model, the averaged drop of VFL model accuracy is only 0.09%). VMask's runtime is up to 60,846 times faster than cryptography-based methods, and it only marginally exceeds that of standard VFL by 1.8 times in a large Transformer-based model, which is generally acceptable.", 'abstract_zh': '尽管垂直联邦学习（VFL）通常被认为是隐私保护的，但近期研究显示，VFL系统容易受到来自各种攻击面的标签推断攻击。在这些攻击中，模型完成（MC）攻击目前是最强大的一种。现有的防御方法要么牺牲模型准确性，要么引入不切实际的计算开销。本文提出了一种名为VMask的新型标签隐私保护框架，从层屏蔽的角度出发防御MC攻击。我们的核心见解是通过应用秘密共享（SS）技术来掩盖攻击者模型中的层参数，从而破坏输入数据与中间输出之间的强相关性。我们设计了一种策略来选择关键层进行掩盖，减少盲目应用SS到整个模型会引起的开销。此外，VMask是第一个为防御者提供可调隐私预算的框架，允许根据实际需求灵活控制标签隐私的水平。我们构建了一个VFL系统，在其上实现VMask，并使用五种模型架构和13个具有不同模态的数据集进行了广泛的评估，与12种其他防御方法进行了比较。结果表明，VMask在隐私-效用权衡方面表现最佳，成功抵御了MC攻击（将标签推断准确性降低到随机猜测水平），同时保持了模型性能（例如，在基于Transformer的模型中，VFL模型准确性的平均下降幅度仅为0.09%）。VMask的运行时间比基于密码学的方法快60,846倍，在大型基于Transformer的模型中仅比标准VFL超出1.8倍，这通常是可接受的。', 'title_zh': 'VMask：基于层掩膜的可调标签隐私保护方法在垂直联邦学习中的应用'}
{'arxiv_id': 'arXiv:2507.14625', 'title': 'VTarbel: Targeted Label Attack with Minimal Knowledge on Detector-enhanced Vertical Federated Learning', 'authors': 'Juntao Tan, Anran Li, Quanchao Liu, Peng Ran, Lan Zhang', 'link': 'https://arxiv.org/abs/2507.14625', 'abstract': "Vertical federated learning (VFL) enables multiple parties with disjoint features to collaboratively train models without sharing raw data. While privacy vulnerabilities of VFL are extensively-studied, its security threats-particularly targeted label attacks-remain underexplored. In such attacks, a passive party perturbs inputs at inference to force misclassification into adversary-chosen labels. Existing methods rely on unrealistic assumptions (e.g., accessing VFL-model's outputs) and ignore anomaly detectors deployed in real-world systems. To bridge this gap, we introduce VTarbel, a two-stage, minimal-knowledge attack framework explicitly designed to evade detector-enhanced VFL inference. During the preparation stage, the attacker selects a minimal set of high-expressiveness samples (via maximum mean discrepancy), submits them through VFL protocol to collect predicted labels, and uses these pseudo-labels to train estimated detector and surrogate model on local features. In attack stage, these models guide gradient-based perturbations of remaining samples, crafting adversarial instances that induce targeted misclassifications and evade detection. We implement VTarbel and evaluate it against four model architectures, seven multimodal datasets, and two anomaly detectors. Across all settings, VTarbel outperforms four state-of-the-art baselines, evades detection, and retains effective against three representative privacy-preserving defenses. These results reveal critical security blind spots in current VFL deployments and underscore urgent need for robust, attack-aware defenses.", 'abstract_zh': '垂直联邦学习中的VTarbel：一种规避检测增强垂直联邦学习推理的两阶段小知识攻击框架', 'title_zh': 'VTarbel：基于检测增强垂直联邦学习的最小知识 targeted 标签攻击'}
{'arxiv_id': 'arXiv:2507.14615', 'title': 'Retrieval-Augmented Clinical Benchmarking for Contextual Model Testing in Kenyan Primary Care: A Methodology Paper', 'authors': 'Fred Mutisya, Shikoh Gitau, Christine Syovata, Diana Oigara, Ibrahim Matende, Muna Aden, Munira Ali, Ryan Nyotu, Diana Marion, Job Nyangena, Nasubo Ongoma, Keith Mbae, Elizabeth Wamicha, Eric Mibuari, Jean Philbert Nsengemana, Talkmore Chidede', 'link': 'https://arxiv.org/abs/2507.14615', 'abstract': "Large Language Models(LLMs) hold promise for improving healthcare access in low-resource settings, but their effectiveness in African primary care remains underexplored. We present a methodology for creating a benchmark dataset and evaluation framework focused on Kenyan Level 2 and 3 clinical care. Our approach uses retrieval augmented generation (RAG) to ground clinical questions in Kenya's national guidelines, ensuring alignment with local standards. These guidelines were digitized, chunked, and indexed for semantic retrieval. Gemini Flash 2.0 Lite was then prompted with guideline excerpts to generate realistic clinical scenarios, multiple-choice questions, and rationale based answers in English and Swahili. Kenyan physicians co-created and refined the dataset, and a blinded expert review process ensured clinical accuracy, clarity, and cultural appropriateness. The resulting Alama Health QA dataset includes thousands of regulator-aligned question answer pairs across common outpatient conditions. Beyond accuracy, we introduce evaluation metrics that test clinical reasoning, safety, and adaptability such as rare case detection (Needle in the Haystack), stepwise logic (Decision Points), and contextual adaptability. Initial results reveal significant performance gaps when LLMs are applied to localized scenarios, consistent with findings that LLM accuracy is lower on African medical content than on US-based benchmarks. This work offers a replicable model for guideline-driven, dynamic benchmarking to support safe AI deployment in African health systems.", 'abstract_zh': '大型语言模型(LLMs)在提高低资源地区医疗 accessibility 方面前景广阔，但其在非洲初级保健中的有效性仍待深入探索。我们提出了一个针对肯尼亚二级和三级临床护理的基准数据集和评估框架的创建方法。该方法利用检索增强生成(RAG)技术，将临床问题与肯尼亚国家级指南对接，确保与当地标准的吻合。这些指南进行了数字化、分块和语义索引处理。Gemini Flash 2.0 Lite 接受了部分指南内容的提示，生成了英文和斯瓦希里语的现实临床情景、多项选择题及其答案解释。肯尼亚医生共同创建和完善了数据集，盲审专家过程确保了临床准确性、清晰性和文化适宜性。生成的 Alama Health QA 数据集包含数千个与常见门诊疾病对齐的问答对。除了准确性，我们还引入了测试临床推理、安全性和适应性的评估指标，如罕见案例检测（在干草堆中找针）、逐步逻辑（决策点）和上下文适应性。初步结果显示，当将 LLM 应用于本地化场景时，存在显著性能差距，这与 LLM 在非洲医学内容上的准确性低于美国基准的发现相符。本工作提供了一种可复制的基于指南的动态基准模型，以支持非洲卫生系统的安全 AI 部署。', 'title_zh': '基于检索增强的临床基准测试方法在肯yan初级保健情境模型测试中应用：一种方法论论文'}
{'arxiv_id': 'arXiv:2507.14612', 'title': 'Enhancing POI Recommendation through Global Graph Disentanglement with POI Weighted Module', 'authors': 'Pei-Xuan Li, Wei-Yun Liang, Fandel Lin, Hsun-Ping Hsieh', 'link': 'https://arxiv.org/abs/2507.14612', 'abstract': "Next point of interest (POI) recommendation primarily predicts future activities based on users' past check-in data and current status, providing significant value to users and service providers. We observed that the popular check-in times for different POI categories vary. For example, coffee shops are crowded in the afternoon because people like to have coffee to refresh after meals, while bars are busy late at night. However, existing methods rarely explore the relationship between POI categories and time, which may result in the model being unable to fully learn users' tendencies to visit certain POI categories at different times. Additionally, existing methods for modeling time information often convert it into time embeddings or calculate the time interval and incorporate it into the model, making it difficult to capture the continuity of time. Finally, during POI prediction, various weighting information is often ignored, such as the popularity of each POI, the transition relationships between POIs, and the distances between POIs, leading to suboptimal performance. To address these issues, this paper proposes a novel next POI recommendation framework called Graph Disentangler with POI Weighted Module (GDPW). This framework aims to jointly consider POI category information and multiple POI weighting factors. Specifically, the proposed GDPW learns category and time representations through the Global Category Graph and the Global Category-Time Graph. Then, we disentangle category and time information through contrastive learning. After prediction, the final POI recommendation for users is obtained by weighting the prediction results based on the transition weights and distance relationships between POIs. We conducted experiments on two real-world datasets, and the results demonstrate that the proposed GDPW outperforms other existing models, improving performance by 3% to 11%.", 'abstract_zh': '基于图解纠缠的POI权重模块下一步点兴趣推荐框架（GDPW）', 'title_zh': '通过POI加权模块全球图去纠缠增强POI推荐'}
{'arxiv_id': 'arXiv:2507.14608', 'title': 'Exp-Graph: How Connections Learn Facial Attributes in Graph-based Expression Recognition', 'authors': 'Nandani Sharma, Dinesh Singh', 'link': 'https://arxiv.org/abs/2507.14608', 'abstract': "Facial expression recognition is crucial for human-computer interaction applications such as face animation, video surveillance, affective computing, medical analysis, etc. Since the structure of facial attributes varies with facial expressions, incorporating structural information into facial attributes is essential for facial expression recognition. In this paper, we propose Exp-Graph, a novel framework designed to represent the structural relationships among facial attributes using graph-based modeling for facial expression recognition. For facial attributes graph representation, facial landmarks are used as the graph's vertices. At the same time, the edges are determined based on the proximity of the facial landmark and the similarity of the local appearance of the facial attributes encoded using the vision transformer. Additionally, graph convolutional networks are utilized to capture and integrate these structural dependencies into the encoding of facial attributes, thereby enhancing the accuracy of expression recognition. Thus, Exp-Graph learns from the facial attribute graphs highly expressive semantic representations. On the other hand, the vision transformer and graph convolutional blocks help the framework exploit the local and global dependencies among the facial attributes that are essential for the recognition of facial expressions. We conducted comprehensive evaluations of the proposed Exp-Graph model on three benchmark datasets: Oulu-CASIA, eNTERFACE05, and AFEW. The model achieved recognition accuracies of 98.09\\%, 79.01\\%, and 56.39\\%, respectively. These results indicate that Exp-Graph maintains strong generalization capabilities across both controlled laboratory settings and real-world, unconstrained environments, underscoring its effectiveness for practical facial expression recognition applications.", 'abstract_zh': '基于图的面部表情识别框架Exp-Graph', 'title_zh': 'Exp-Graph: 基于图的表达识别中连接如何学习面部属性'}
{'arxiv_id': 'arXiv:2507.14592', 'title': 'A Transformer-Based Conditional GAN with Multiple Instance Learning for UAV Signal Detection and Classification', 'authors': 'Haochen Liu, Jia Bi, Xiaomin Wang, Xin Yang, Ling Wang', 'link': 'https://arxiv.org/abs/2507.14592', 'abstract': 'Unmanned Aerial Vehicles (UAVs) are increasingly used in surveillance, logistics, agriculture, disaster management, and military operations. Accurate detection and classification of UAV flight states, such as hovering, cruising, ascending, or transitioning, which are essential for safe and effective operations. However, conventional time series classification (TSC) methods often lack robustness and generalization for dynamic UAV environments, while state of the art(SOTA) models like Transformers and LSTM based architectures typically require large datasets and entail high computational costs, especially with high-dimensional data streams. This paper proposes a novel framework that integrates a Transformer-based Generative Adversarial Network (GAN) with Multiple Instance Locally Explainable Learning (MILET) to address these challenges in UAV flight state classification. The Transformer encoder captures long-range temporal dependencies and complex telemetry dynamics, while the GAN module augments limited datasets with realistic synthetic samples. MIL is incorporated to focus attention on the most discriminative input segments, reducing noise and computational overhead. Experimental results show that the proposed method achieves superior accuracy 96.5% on the DroneDetect dataset and 98.6% on the DroneRF dataset that outperforming other SOTA approaches. The framework also demonstrates strong computational efficiency and robust generalization across diverse UAV platforms and flight states, highlighting its potential for real-time deployment in resource constrained environments.', 'abstract_zh': '基于Transformer生成对抗网络与多实例局部可解释学习的无人机飞行状态分类框架', 'title_zh': '基于Transformer的条件生成对抗网络及其在多实例学习下的无人机信号检测与分类'}
{'arxiv_id': 'arXiv:2507.14590', 'title': 'Backtranslation and paraphrasing in the LLM era? Comparing data augmentation methods for emotion classification', 'authors': 'Łukasz Radliński, Mateusz Guściora, Jan Kocoń', 'link': 'https://arxiv.org/abs/2507.14590', 'abstract': 'Numerous domain-specific machine learning tasks struggle with data scarcity and class imbalance. This paper systematically explores data augmentation methods for NLP, particularly through large language models like GPT. The purpose of this paper is to examine and evaluate whether traditional methods such as paraphrasing and backtranslation can leverage a new generation of models to achieve comparable performance to purely generative methods. Methods aimed at solving the problem of data scarcity and utilizing ChatGPT were chosen, as well as an exemplary dataset. We conducted a series of experiments comparing four different approaches to data augmentation in multiple experimental setups. We then evaluated the results both in terms of the quality of generated data and its impact on classification performance. The key findings indicate that backtranslation and paraphrasing can yield comparable or even better results than zero and a few-shot generation of examples.', 'abstract_zh': 'Numerous领域特定的机器学习任务受到数据稀缺性和类别不平衡的困扰。本文系统探索了通过大型语言模型（如GPT）进行NLP数据增强方法。本文旨在考察和评估传统方法如改写和回译是否能够利用新一代模型达到与生成方法相当的性能。我们选择了针对数据稀缺性问题并利用ChatGPT的方法，并使用一个示例数据集进行了实验。我们在多个实验设置中比较了四种不同数据增强方法，并从生成数据的质量及其对分类性能的影响两方面评估了结果。主要发现表明，回译和改写可以达到甚至超过零样本和少量样本生成的性能。', 'title_zh': 'LLM时代的目标翻译与重表述？情绪分类中的数据 augmentation 方法比较'}
{'arxiv_id': 'arXiv:2507.14587', 'title': 'Performance comparison of medical image classification systems using TensorFlow Keras, PyTorch, and JAX', 'authors': 'Merjem Bećirović, Amina Kurtović, Nordin Smajlović, Medina Kapo, Amila Akagić', 'link': 'https://arxiv.org/abs/2507.14587', 'abstract': 'Medical imaging plays a vital role in early disease diagnosis and monitoring. Specifically, blood microscopy offers valuable insights into blood cell morphology and the detection of hematological disorders. In recent years, deep learning-based automated classification systems have demonstrated high potential in enhancing the accuracy and efficiency of blood image analysis. However, a detailed performance analysis of specific deep learning frameworks appears to be lacking. This paper compares the performance of three popular deep learning frameworks, TensorFlow with Keras, PyTorch, and JAX, in classifying blood cell images from the publicly available BloodMNIST dataset. The study primarily focuses on inference time differences, but also classification performance for different image sizes. The results reveal variations in performance across frameworks, influenced by factors such as image resolution and framework-specific optimizations. Classification accuracy for JAX and PyTorch was comparable to current benchmarks, showcasing the efficiency of these frameworks for medical image classification.', 'abstract_zh': '医学成像在早期疾病诊断和监测中发挥着重要作用。特别是血液显微镜可以提供关于血细胞形态和血液系统疾病检测的重要见解。近年来，基于深度学习的自动化分类系统在提高血液图像分析的准确性和效率方面显示出巨大潜力。然而，特定深度学习框架的详细性能分析似乎仍然不足。本文比较了三种流行的深度学习框架TensorFlow与Keras、PyTorch和JAX在分类公开可用的BloodMNIST数据集中的性能。研究主要关注推断时间差异，同时也考虑了不同图像大小的分类性能。结果揭示了不同框架之间的性能差异，这些差异受图像分辨率和框架特定优化等因素的影响。JAX和PyTorch的分类准确性与现有基准相当，展示了这些框架在医学图像分类中的效率。', 'title_zh': '使用TensorFlow Keras、PyTorch和JAX的医疗图像分类系统性能比较'}
{'arxiv_id': 'arXiv:2507.14584', 'title': 'Explainable Collaborative Problem Solving Diagnosis with BERT using SHAP and its Implications for Teacher Adoption', 'authors': 'Kester Wong, Sahan Bulathwela, Mutlu Cukurova', 'link': 'https://arxiv.org/abs/2507.14584', 'abstract': "The use of Bidirectional Encoder Representations from Transformers (BERT) model and its variants for classifying collaborative problem solving (CPS) has been extensively explored within the AI in Education community. However, limited attention has been given to understanding how individual tokenised words in the dataset contribute to the model's classification decisions. Enhancing the explainability of BERT-based CPS diagnostics is essential to better inform end users such as teachers, thereby fostering greater trust and facilitating wider adoption in education. This study undertook a preliminary step towards model transparency and explainability by using SHapley Additive exPlanations (SHAP) to examine how different tokenised words in transcription data contributed to a BERT model's classification of CPS processes. The findings suggested that well-performing classifications did not necessarily equate to a reasonable explanation for the classification decisions. Particular tokenised words were used frequently to affect classifications. The analysis also identified a spurious word, which contributed positively to the classification but was not semantically meaningful to the class. While such model transparency is unlikely to be useful to an end user to improve their practice, it can help them not to overrely on LLM diagnostics and ignore their human expertise. We conclude the workshop paper by noting that the extent to which the model appropriately uses the tokens for its classification is associated with the number of classes involved. It calls for an investigation into the exploration of ensemble model architectures and the involvement of human-AI complementarity for CPS diagnosis, since considerable human reasoning is still required for fine-grained discrimination of CPS subskills.", 'abstract_zh': '使用Bidirectional Encoder Representations from Transformers（BERT）模型及其变体对协作问题解决（CPS）进行分类在教育人工智能领域得到了广泛探索，但鲜有研究关注数据集中个体词令牌如何影响模型的分类决策。通过使用SHapley Additive exPlanations（SHAP）来增强基于BERT的CPS诊断的可解释性，对于更好地指导教师等终端用户并促进教育中更广泛的应用至关重要。本文通过分析转录数据中不同词令牌如何影响BERT模型对CPS过程的分类，初步探索了模型透明性和可解释性。研究发现，表现良好的分类并不一定提供合理的解释，特定的词令牌经常用于影响分类。分析还发现了一个相关的无意义词语，它虽然对分类有正面贡献，但并不具有语义意义。尽管这种模型透明性对于改进终端用户的实践可能无用，但它可以帮助他们不过度依赖于大型语言模型的诊断，并忽略自己的人类专长。文中指出，模型在分类中适当使用词令牌的程度与涉及的类别数量相关，这需要进一步研究集成模型架构和人机互补在CPS诊断中的作用，因为精细区分CPS子技能仍需要大量的人类推理。', 'title_zh': '基于BERT、使用SHAP的可解释协作问题解决诊断及其对教师采纳的 implications'}
{'arxiv_id': 'arXiv:2507.14579', 'title': 'Exploring Human-AI Complementarity in CPS Diagnosis Using Unimodal and Multimodal BERT Models', 'authors': 'Kester Wong, Sahan Bulathwela, Mutlu Cukurova', 'link': 'https://arxiv.org/abs/2507.14579', 'abstract': 'Detecting collaborative problem solving (CPS) indicators from dialogue using machine learning techniques is a significant challenge for the field of AI in Education. Recent studies have explored the use of Bidirectional Encoder Representations from Transformers (BERT) models on transcription data to reliably detect meaningful CPS indicators. A notable advancement involved the multimodal BERT variant, AudiBERT, which integrates speech and acoustic-prosodic audio features to enhance CPS diagnosis. Although initial results demonstrated multimodal improvements, the statistical significance of these enhancements remained unclear, and there was insufficient guidance on leveraging human-AI complementarity for CPS diagnosis tasks. This workshop paper extends the previous research by highlighting that the AudiBERT model not only improved the classification of classes that were sparse in the dataset, but it also had statistically significant class-wise improvements over the BERT model for classifications in the social-cognitive dimension. However, similar significant class-wise improvements over the BERT model were not observed for classifications in the affective dimension. A correlation analysis highlighted that larger training data was significantly associated with higher recall performance for both the AudiBERT and BERT models. Additionally, the precision of the BERT model was significantly associated with high inter-rater agreement among human coders. When employing the BERT model to diagnose indicators within these subskills that were well-detected by the AudiBERT model, the performance across all indicators was inconsistent. We conclude the paper by outlining a structured approach towards achieving human-AI complementarity for CPS diagnosis, highlighting the crucial inclusion of model explainability to support human agency and engagement in the reflective coding process.', 'abstract_zh': '使用机器学习技术从对话中检测协作问题解决（CPS）指标是教育人工智能领域的 significan挑战。最近的研究探索了在转录数据上使用双向编码器表示变换器（BERT）模型以可靠地检测有意义的CPS指标。一个重要进展是多模态BERT变体AudiBERT，它整合了语音和声学-语调音频特征，以增强CPS诊断。尽管初始结果表明多模态改进是有效的，但这些改进的统计显著性仍然不明确，并且在利用人类-人工智能互补性进行CPS诊断任务方面缺乏指导。该工作坊论文扩展了先前的研究，强调AudiBERT模型不仅提高了数据集中稀疏类别的分类性能，还在社会认知维度上的分类中，AudiBERT模型相对于BERT模型具有统计显著性的类别间改进。然而，在情感维度上的分类中，并未观察到类似的显著类别改进。相关性分析表明，更大的训练数据与AudiBERT和BERT模型的更高召回性能显著关联。此外，BERT模型的精度与人类编码者之间的一致性显著相关。在使用BERT模型诊断由AudiBERT模型很好地检测到的这些亚技能内的指标时，所有指标的性能是不一致的。本文总结了实现人类-人工智能互补性的结构化方法，强调了模型可解释性对于支持人类在反思编码过程中的自主性和参与的重要性。', 'title_zh': '探索基于单模态和多模态BERT模型的CPS诊断中的人机互补性研究'}
{'arxiv_id': 'arXiv:2507.14575', 'title': 'Benchmarking GANs, Diffusion Models, and Flow Matching for T1w-to-T2w MRI Translation', 'authors': "Andrea Moschetto, Lemuel Puglisi, Alec Sargood, Pierluigi Dell'Acqua, Francesco Guarnera, Sebastiano Battiato, Daniele Ravì", 'link': 'https://arxiv.org/abs/2507.14575', 'abstract': 'Magnetic Resonance Imaging (MRI) enables the acquisition of multiple image contrasts, such as T1-weighted (T1w) and T2-weighted (T2w) scans, each offering distinct diagnostic insights. However, acquiring all desired modalities increases scan time and cost, motivating research into computational methods for cross-modal synthesis. To address this, recent approaches aim to synthesize missing MRI contrasts from those already acquired, reducing acquisition time while preserving diagnostic quality. Image-to-image (I2I) translation provides a promising framework for this task. In this paper, we present a comprehensive benchmark of generative models$\\unicode{x2013}$specifically, Generative Adversarial Networks (GANs), diffusion models, and flow matching (FM) techniques$\\unicode{x2013}$for T1w-to-T2w 2D MRI I2I translation. All frameworks are implemented with comparable settings and evaluated on three publicly available MRI datasets of healthy adults. Our quantitative and qualitative analyses show that the GAN-based Pix2Pix model outperforms diffusion and FM-based methods in terms of structural fidelity, image quality, and computational efficiency. Consistent with existing literature, these results suggest that flow-based models are prone to overfitting on small datasets and simpler tasks, and may require more data to match or surpass GAN performance. These findings offer practical guidance for deploying I2I translation techniques in real-world MRI workflows and highlight promising directions for future research in cross-modal medical image synthesis. Code and models are publicly available at this https URL.', 'abstract_zh': '磁共振成像（MRI）能够获取多种图像对比度，如T1加权（T1w）和T2加权（T2w）扫描，每种对比度都提供了独特的诊断信息。然而，获取所有所需模态会增加扫描时间和成本，从而推动了跨模态合成的计算方法研究。为了解决这一问题，最近的方法试图从已获取的模态中合成缺失的MRI对比度，从而减少获取时间同时保持诊断质量。图像到图像（I2I）转换为这一任务提供了有前景的框架。在本文中，我们对生成模型——具体而言，生成对抗网络（GAN）、扩散模型和流匹配（FM）技术——在健康成人公开可用的MRI数据集上的T1w到T2w 2D MRI I2I转换进行了全面基准测试。所有框架都以相似的设置实现并进行评估。我们的定量和定性分析表明，基于GAN的Pix2Pix模型在结构保真度、图像质量和计算效率方面优于基于扩散和FM的方法。与现有文献一致，这些结果表明，基于流的概率模型容易在小数据集和简单任务上过拟合，并且可能需要更多数据来匹配或超越GAN的性能。这些发现为在实际MRI流程中部署I2I转换技术提供了实用指导，并强调了跨模态医学图像合成的未来研究方向。代码和模型可在以下网址获取：this https URL。', 'title_zh': 'GANs、扩散模型和流动匹配方法在T1w到T2w MRI转化中的性能基准研究'}
{'arxiv_id': 'arXiv:2507.14570', 'title': 'LPS-GNN : Deploying Graph Neural Networks on Graphs with 100-Billion Edges', 'authors': 'Xu Cheng, Liang Yao, Feng He, Yukuo Cen, Yufei He, Chenhui Zhang, Wenzheng Feng, Hongyun Cai, Jie Tang', 'link': 'https://arxiv.org/abs/2507.14570', 'abstract': "Graph Neural Networks (GNNs) have emerged as powerful tools for various graph mining tasks, yet existing scalable solutions often struggle to balance execution efficiency with prediction accuracy. These difficulties stem from iterative message-passing techniques, which place significant computational demands and require extensive GPU memory, particularly when dealing with the neighbor explosion issue inherent in large-scale graphs. This paper introduces a scalable, low-cost, flexible, and efficient GNN framework called LPS-GNN, which can perform representation learning on 100 billion graphs with a single GPU in 10 hours and shows a 13.8% improvement in User Acquisition scenarios. We examine existing graph partitioning methods and design a superior graph partition algorithm named LPMetis. In particular, LPMetis outperforms current state-of-the-art (SOTA) approaches on various evaluation metrics. In addition, our paper proposes a subgraph augmentation strategy to enhance the model's predictive performance. It exhibits excellent compatibility, allowing the entire framework to accommodate various GNN algorithms. Successfully deployed on the Tencent platform, LPS-GNN has been tested on public and real-world datasets, achieving performance lifts of 8. 24% to 13. 89% over SOTA models in online applications.", 'abstract_zh': '一种名为LPS-GNN的可扩展、低成本、灵活且高效的图神经网络框架', 'title_zh': 'LPS-GNN：在拥有1000亿条边的图上部署图神经网络'}
{'arxiv_id': 'arXiv:2507.14544', 'title': 'Multimodal AI for Gastrointestinal Diagnostics: Tackling VQA in MEDVQA-GI 2025', 'authors': 'Sujata Gaihre, Amir Thapa Magar, Prasuna Pokharel, Laxmi Tiwari', 'link': 'https://arxiv.org/abs/2507.14544', 'abstract': 'This paper describes our approach to Subtask 1 of the ImageCLEFmed MEDVQA 2025 Challenge, which targets visual question answering (VQA) for gastrointestinal endoscopy. We adopt the Florence model-a large-scale multimodal foundation model-as the backbone of our VQA pipeline, pairing a powerful vision encoder with a text encoder to interpret endoscopic images and produce clinically relevant answers. To improve generalization, we apply domain-specific augmentations that preserve medical features while increasing training diversity. Experiments on the KASVIR dataset show that fine-tuning Florence yields accurate responses on the official challenge metrics. Our results highlight the potential of large multimodal models in medical VQA and provide a strong baseline for future work on explainability, robustness, and clinical integration. The code is publicly available at: this https URL', 'abstract_zh': '本文描述了我们参加ImageCLEFmed MEDVQA 2025挑战赛Subtask 1的方法，该任务旨在解决胃肠道内镜的视觉问答（VQA）问题。我们采用Florence模型——一个大规模的多模态基础模型——作为VQA管道的骨干，结合强大的视觉编码器和文本编码器来解释内镜图像并生成临床相关的回答。为了提高泛化能力，我们应用了保留医学特征同时增加训练多样性的领域特定增强方法。在KASVIR数据集上的实验显示，Florence微调后可以在官方挑战指标上获得准确的回答。我们的结果突显了大规模多模态模型在医疗VQA中的潜力，并为未来的工作提供了一个强大的基线，特别是在可解释性、鲁棒性和临床整合方面。代码已公开：this https URL。', 'title_zh': '多模态AI在肠胃诊断中的应用：面向MEDVQA-GI 2025的视觉问答挑战'}
{'arxiv_id': 'arXiv:2507.14519', 'title': 'Towards Efficient Privacy-Preserving Machine Learning: A Systematic Review from Protocol, Model, and System Perspectives', 'authors': 'Wenxuan Zeng, Tianshi Xu, Yi Chen, Yifan Zhou, Mingzhe Zhang, Jin Tan, Cheng Hong, Meng Li', 'link': 'https://arxiv.org/abs/2507.14519', 'abstract': 'Privacy-preserving machine learning (PPML) based on cryptographic protocols has emerged as a promising paradigm to protect user data privacy in cloud-based machine learning services. While it achieves formal privacy protection, PPML often incurs significant efficiency and scalability costs due to orders of magnitude overhead compared to the plaintext counterpart. Therefore, there has been a considerable focus on mitigating the efficiency gap for PPML. In this survey, we provide a comprehensive and systematic review of recent PPML studies with a focus on cross-level optimizations. Specifically, we categorize existing papers into protocol level, model level, and system level, and review progress at each level. We also provide qualitative and quantitative comparisons of existing works with technical insights, based on which we discuss future research directions and highlight the necessity of integrating optimizations across protocol, model, and system levels. We hope this survey can provide an overarching understanding of existing approaches and potentially inspire future breakthroughs in the PPML field. As the field is evolving fast, we also provide a public GitHub repository to continuously track the developments, which is available at this https URL.', 'abstract_zh': '基于密码协议的隐私保护机器学习（PPML）已成为一种有前途的范式，用于保护基于云的机器学习服务中的用户数据隐私。尽管它实现了形式上的隐私保护，但PPML往往由于与明文对应物相比具有数量级的开销而招致显著的效率和扩展性成本。因此，已经相当关注减轻PPML的效率差距。在本综述中，我们提供了一种全面且系统的近期PPML研究的审查，重点在于跨层次优化。具体来说，我们将现有论文分为协议层面、模型层面和系统层面，并在每一层面审查进展。我们还基于现有的工作进行定性与定量比较，并提供技术见解，从而讨论未来研究方向，并强调在协议、模型和系统层面集成优化的必要性。我们希望这篇综述能够提供现有方法的总体理解，并激发PPML领域的未来突破。由于该领域发展迅速，我们还提供了一个公共GitHub仓库，以持续跟踪进展，该仓库可从这个网址访问。', 'title_zh': '面向高效隐私保护机器学习：从协议、模型和系统视角的系统性综述'}
{'arxiv_id': 'arXiv:2507.14516', 'title': 'SDSC:A Structure-Aware Metric for Semantic Signal Representation Learning', 'authors': 'Jeyoung Lee, Hochul Kang', 'link': 'https://arxiv.org/abs/2507.14516', 'abstract': 'We propose the Signal Dice Similarity Coefficient (SDSC), a structure-aware metric function for time series self-supervised representation learning. Most Self-Supervised Learning (SSL) methods for signals commonly adopt distance-based objectives such as mean squared error (MSE), which are sensitive to amplitude, invariant to waveform polarity, and unbounded in scale. These properties hinder semantic alignment and reduce interpretability. SDSC addresses this by quantifying structural agreement between temporal signals based on the intersection of signed amplitudes, derived from the Dice Similarity Coefficient (DSC).Although SDSC is defined as a structure-aware metric, it can be used as a loss by subtracting from 1 and applying a differentiable approximation of the Heaviside function for gradient-based optimization. A hybrid loss formulation is also proposed to combine SDSC with MSE, improving stability and preserving amplitude where necessary. Experiments on forecasting and classification benchmarks demonstrate that SDSC-based pre-training achieves comparable or improved performance over MSE, particularly in in-domain and low-resource scenarios. The results suggest that structural fidelity in signal representations enhances the semantic representation quality, supporting the consideration of structure-aware metrics as viable alternatives to conventional distance-based methods.', 'abstract_zh': '我们提出了信号Dice相似系数（SDSC）：一种用于时间序列自监督表示学习的结构感知度量函数。', 'title_zh': 'SDSC：一种结构意识的语义信号表示学习度量'}
{'arxiv_id': 'arXiv:2507.14507', 'title': 'Diffusion Models for Time Series Forecasting: A Survey', 'authors': 'Chen Su, Zhengzhou Cai, Yuanhe Tian, Zihong Zheng, Yan Song', 'link': 'https://arxiv.org/abs/2507.14507', 'abstract': 'Diffusion models, initially developed for image synthesis, demonstrate remarkable generative capabilities. Recently, their application has expanded to time series forecasting (TSF), yielding promising results. In this survey, we firstly introduce the standard diffusion models and their prevalent variants, explaining their adaptation to TSF tasks. We then provide a comprehensive review of diffusion models for TSF, paying special attention to the sources of conditional information and the mechanisms for integrating this conditioning within the models. In analyzing existing approaches using diffusion models for TSF, we provide a systematic categorization and a comprehensive summary of them in this survey. Furthermore, we examine several foundational diffusion models applied to TSF, alongside commonly used datasets and evaluation metrics. Finally, we discuss current limitations in these approaches and potential future research directions. Overall, this survey details recent progress and future prospects for diffusion models in TSF, serving as a reference for researchers in the field.', 'abstract_zh': '扩散模型最初用于图像合成，展示了出色的生成能力。近年来，它们的应用扩展到时间序列预测（TSF），取得了令人鼓舞的结果。在本文综述中，我们首先介绍标准扩散模型及其常见变体，并解释它们如何适应TSF任务。随后，我们对扩散模型在TSF中的应用进行了全面的综述，特别关注条件信息的来源以及这些信息在模型中集成的机制。在分析使用扩散模型进行TSF的方法时，我们对此综述中这些方法进行了系统的分类和全面总结。此外，我们还考察了几种基础的扩散模型在TSF中的应用，以及常用的数据集和评估指标。最后，我们讨论了这些方法的现有局限性和未来的研究方向。总之，本文综述了扩散模型在TSF中的最新进展和未来前景，为该领域的研究人员提供参考。', 'title_zh': '时间序列预测中的扩散模型：一个综述'}
{'arxiv_id': 'arXiv:2507.14499', 'title': 'Neural Brownian Motion', 'authors': 'Qian Qi', 'link': 'https://arxiv.org/abs/2507.14499', 'abstract': 'This paper introduces the Neural-Brownian Motion (NBM), a new class of stochastic processes for modeling dynamics under learned uncertainty. The NBM is defined axiomatically by replacing the classical martingale property with respect to linear expectation with one relative to a non-linear Neural Expectation Operator, $\\varepsilon^\\theta$, generated by a Backward Stochastic Differential Equation (BSDE) whose driver $f_\\theta$ is parameterized by a neural network. Our main result is a representation theorem for a canonical NBM, which we define as a continuous $\\varepsilon^\\theta$-martingale with zero drift under the physical measure. We prove that, under a key structural assumption on the driver, such a canonical NBM exists and is the unique strong solution to a stochastic differential equation of the form ${\\rm d} M_t = \\nu_\\theta(t, M_t) {\\rm d} W_t$. Crucially, the volatility function $\\nu_\\theta$ is not postulated a priori but is implicitly defined by the algebraic constraint $g_\\theta(t, M_t, \\nu_\\theta(t, M_t)) = 0$, where $g_\\theta$ is a specialization of the BSDE driver. We develop the stochastic calculus for this process and prove a Girsanov-type theorem for the quadratic case, showing that an NBM acquires a drift under a new, learned measure. The character of this measure, whether pessimistic or optimistic, is endogenously determined by the learned parameters $\\theta$, providing a rigorous foundation for models where the attitude towards uncertainty is a discoverable feature.', 'abstract_zh': '这篇论文介绍了神经布朗运动（NBM），这是一种用于在学习到的不确定性下建模动力学的新类随机过程。NBM通过将经典的关于线性期望的鞅性质替换为关于由带有神经网络参数化的驱动项$f_\\theta$的向后随机微分方程（BSDE）生成的非线性神经期望运算子$\\varepsilon^\\theta$的性质来定义。我们的主要结果是对称NBM的表示定理，我们将其定义为在物理测度下的连续$\\varepsilon^\\theta$-鞅且漂移为零。我们证明了，在驱动项的关键结构性假设下，这样的对称NBM存在且是形式为${\\rm d} M_t = \\nu_\\theta(t, M_t) {\\rm d} W_t$的随机微分方程的强解。关键的是，波动函数$\\nu_\\theta$不是先验假定的，而是由代数约束$g_\\theta(t, M_t, \\nu_\\theta(t, M_t)) = 0$隐式定义的，其中$g_\\theta$是BSDE驱动项的特化。我们为此过程发展了随机微积分，并证明了二次情形下的Girsanov型定理，展示了在新的学习测度下，NBM获取漂移。这种测度的性质（是否悲观或乐观）由学习参数$\\theta$内生地确定，为态度向不确定性是可发现特征的模型提供了严格的理论基础。', 'title_zh': '神经布朗运动'}
{'arxiv_id': 'arXiv:2507.14485', 'title': 'Benefit from Reference: Retrieval-Augmented Cross-modal Point Cloud Completion', 'authors': 'Hongye Hou, Liu Zhan, Yang Yang', 'link': 'https://arxiv.org/abs/2507.14485', 'abstract': 'Completing the whole 3D structure based on an incomplete point cloud is a challenging task, particularly when the residual point cloud lacks typical structural characteristics. Recent methods based on cross-modal learning attempt to introduce instance images to aid the structure feature learning. However, they still focus on each particular input class, limiting their generation abilities. In this work, we propose a novel retrieval-augmented point cloud completion framework. The core idea is to incorporate cross-modal retrieval into completion task to learn structural prior information from similar reference samples. Specifically, we design a Structural Shared Feature Encoder (SSFE) to jointly extract cross-modal features and reconstruct reference features as priors. Benefiting from a dual-channel control gate in the encoder, relevant structural features in the reference sample are enhanced and irrelevant information interference is suppressed. In addition, we propose a Progressive Retrieval-Augmented Generator (PRAG) that employs a hierarchical feature fusion mechanism to integrate reference prior information with input features from global to local. Through extensive evaluations on multiple datasets and real-world scenes, our method shows its effectiveness in generating fine-grained point clouds, as well as its generalization capability in handling sparse data and unseen categories.', 'abstract_zh': '基于不完整点云完成整个3D结构是一个具有挑战性的任务，特别是在剩余点云缺乏典型结构特征的情况下。基于跨模态学习的近期方法试图通过引入实例图像来辅助结构特征学习。然而，这些方法仍然侧重于特定输入类别，限制了其生成能力。在本文中，我们提出了一种新颖的检索增强点云完成框架。核心思想是将跨模态检索融入完成任务中，从相似参考样本中学习结构先验信息。具体而言，我们设计了一个结构共享特征编码器（SSFE）来联合提取跨模态特征并重构参考特征作为先验信息。得益于编码器中的双通道控制门，可以增强参考样本中的相关结构特征，并抑制无关信息干扰。此外，我们提出了一种分阶检索增强生成器（PRAG），采用分阶层特征融合机制将参考先验信息与从全局到局部的输入特征融合。通过在多个数据集和真实场景上的广泛评估，我们的方法在生成精细点云方面显示出有效性，并且在处理稀疏数据和未见过的类别方面具有泛化能力。', 'title_zh': '参考辅助下的跨模态点云完成检索增强'}
{'arxiv_id': 'arXiv:2507.14481', 'title': 'DFQ-ViT: Data-Free Quantization for Vision Transformers without Fine-tuning', 'authors': 'Yujia Tong, Jingling Yuan, Tian Zhang, Jianquan Liu, Chuang Hu', 'link': 'https://arxiv.org/abs/2507.14481', 'abstract': 'Data-Free Quantization (DFQ) enables the quantization of Vision Transformers (ViTs) without requiring access to data, allowing for the deployment of ViTs on devices with limited resources. In DFQ, the quantization model must be calibrated using synthetic samples, making the quality of these synthetic samples crucial. Existing methods fail to fully capture and balance the global and local features within the samples, resulting in limited synthetic data quality. Moreover, we have found that during inference, there is a significant difference in the distributions of intermediate layer activations between the quantized and full-precision models. These issues lead to a severe performance degradation of the quantized model. To address these problems, we propose a pipeline for Data-Free Quantization for Vision Transformers (DFQ-ViT). Specifically, we synthesize samples in order of increasing difficulty, effectively enhancing the quality of synthetic data. During the calibration and inference stage, we introduce the activation correction matrix for the quantized model to align the intermediate layer activations with those of the full-precision model. Extensive experiments demonstrate that DFQ-ViT achieves remarkable superiority over existing DFQ methods and its performance is on par with models quantized through real data. For example, the performance of DeiT-T with 3-bit weights quantization is 4.29% higher than the state-of-the-art. Our method eliminates the need for fine-tuning, which not only reduces computational overhead but also lowers the deployment barriers for edge devices. This characteristic aligns with the principles of Green Learning by improving energy efficiency and facilitating real-world applications in resource-constrained environments.', 'abstract_zh': 'Data-Free Quantization for Vision Transformers (DFQ-ViT)', 'title_zh': 'DFQ-ViT：无需微调的数据驱动视觉变换器量化'}
{'arxiv_id': 'arXiv:2507.14472', 'title': 'Strategyproofness and Monotone Allocation of Auction in Social Networks', 'authors': 'Yuhang Guo, Dong Hao, Bin Li, Mingyu Xiao, Bakh Khoussainov', 'link': 'https://arxiv.org/abs/2507.14472', 'abstract': "Strategyproofness in network auctions requires that bidders not only report their valuations truthfully, but also do their best to invite neighbours from the social network. In contrast to canonical auctions, where the value-monotone allocation in Myerson's Lemma is a cornerstone, a general principle of allocation rules for strategyproof network auctions is still missing. We show that, due to the absence of such a principle, even extensions to multi-unit network auctions with single-unit demand present unexpected difficulties, and all pioneering researches fail to be strategyproof. For the first time in this field, we identify two categories of monotone allocation rules on networks: Invitation-Depressed Monotonicity (ID-MON) and Invitation-Promoted Monotonicity (IP-MON). They encompass all existing allocation rules of network auctions as specific instances. For any given ID-MON or IP-MON allocation rule, we characterize the existence and sufficient conditions for the strategyproof payment rules, and show that among all such payment rules, the revenue-maximizing one exists and is computationally feasible. With these results, the obstacle of combinatorial network auction with single-minded bidders is now resolved.", 'abstract_zh': '网络拍卖中的策略proof性要求竞标者不仅诚实地报告其估值，还要尽最大努力邀请社交网络中的邻居。与经典的拍卖中Myerson引理中的价值单调分配作为基石不同，策略proof的网络拍卖分配规则的一般原则仍然缺失。我们表明，由于缺乏这样的原则，即使是针对单一单位需求的多单位网络拍卖的扩展也带来了意想不到的困难，并且所有先驱研究都无法实现策略proof性。在该领域中，我们首次界定了两种网络上的单调分配规则类别：邀请压抑单调性（ID-MON）和邀请促进单调性（IP-MON）。它们包括所有现有网络拍卖的分配规则作为特殊情况。对于任何给定的ID-MON或IP-MON分配规则，我们刻画了策略proof支付规则的存在性和充分条件，并证明这些支付规则中存在收入最大化且可计算的规则。这些结果解决了单一意图竞标者参与组合网络拍卖的障碍。', 'title_zh': '社交网络中拍卖的策略proof性和单调分配机制'}
{'arxiv_id': 'arXiv:2507.14470', 'title': 'Approximate Revenue Maximization for Diffusion Auctions', 'authors': 'Yifan Huang, Dong Hao, Zhiyi Fan, Yuhang Guo, Bin Li', 'link': 'https://arxiv.org/abs/2507.14470', 'abstract': 'Reserve prices are widely used in practice. The problem of designing revenue-optimal auctions based on reserve price has drawn much attention in the auction design community. Although they have been extensively studied, most developments rely on the significant assumption that the target audience of the sale is directly reachable by the auctioneer, while a large portion of bidders in the economic network unaware of the sale are omitted. This work follows the diffusion auction design, which aims to extend the target audience of optimal auction theory to all entities in economic networks. We investigate the design of simple and provably near-optimal network auctions via reserve price. Using Bayesian approximation analysis, we provide a simple and explicit form of the reserve price function tailored to the most representative network auction. We aim to balance setting a sufficiently high reserve price to induce high revenue in a successful sale, and attracting more buyers from the network to increase the probability of a successful sale. This reserve price function preserves incentive compatibility for network auctions, allowing the seller to extract additional revenue beyond that achieved by the Myerson optimal auction. Specifically, if the seller has $\\rho$ direct neighbours in a network of size $n$, this reserve price guarantees a $1-{1 \\over \\rho}$ approximation to the theoretical upper bound, i.e., the maximum possible revenue from any network of size $n$. This result holds for any size and any structure of the networked market.', 'abstract_zh': '基于保留价格的最优拍卖设计在经济网络中扩展', 'title_zh': '近似收益最大化在扩散拍卖中的应用'}
{'arxiv_id': 'arXiv:2507.14444', 'title': 'Statistical and Algorithmic Foundations of Reinforcement Learning', 'authors': 'Yuejie Chi, Yuxin Chen, Yuting Wei', 'link': 'https://arxiv.org/abs/2507.14444', 'abstract': 'As a paradigm for sequential decision making in unknown environments, reinforcement learning (RL) has received a flurry of attention in recent years. However, the explosion of model complexity in emerging applications and the presence of nonconvexity exacerbate the challenge of achieving efficient RL in sample-starved situations, where data collection is expensive, time-consuming, or even high-stakes (e.g., in clinical trials, autonomous systems, and online advertising). How to understand and enhance the sample and computational efficacies of RL algorithms is thus of great interest. In this tutorial, we aim to introduce several important algorithmic and theoretical developments in RL, highlighting the connections between new ideas and classical topics. Employing Markov Decision Processes as the central mathematical model, we cover several distinctive RL scenarios (i.e., RL with a simulator, online RL, offline RL, robust RL, and RL with human feedback), and present several mainstream RL approaches (i.e., model-based approach, value-based approach, and policy optimization). Our discussions gravitate around the issues of sample complexity, computational efficiency, as well as algorithm-dependent and information-theoretic lower bounds from a non-asymptotic viewpoint.', 'abstract_zh': '作为未知环境中的序贯决策范式，强化学习（RL）近年来引起了广泛关注。然而，新兴应用中的模型复杂性的爆炸增长以及非凸性问题加剧了在数据收集昂贵、耗费时间或甚至高风险（例如，在临床试验、自主系统和在线广告中）情况下的高效强化学习挑战。如何理解并提升强化学习算法的样本效率和计算效率是当前的研究热点。在本文献教程中，我们旨在介绍强化学习中若干重要的算法和理论发展，强调新思想与经典主题之间的联系。基于马尔可夫决策过程作为核心数学模型，我们涵盖了若干独特的RL场景（即，带有模拟器的RL、在线RL、离线RL、鲁棒RL以及带有人类反馈的RL），并介绍了几种主流的RL方法（即，基于模型的方法、基于值的方法以及策略优化）。我们的讨论主要围绕样本复杂性、计算效率以及非渐近视角下的算法依赖和信息论下界等问题展开。', 'title_zh': '强化学习的统计与算法基础'}
{'arxiv_id': 'arXiv:2507.14419', 'title': "It's Not That Simple. An Analysis of Simple Test-Time Scaling", 'authors': 'Guojun Wu', 'link': 'https://arxiv.org/abs/2507.14419', 'abstract': 'Prior work proposed simple test-time scaling, a method for replicating this scaling behavior with models distilled from o1-like models by manually controlling test-time compute: either scaling down by enforcing a maximum length or scaling up by iteratively appending "Wait" when the model is about to terminate its generation. This paper presents an analysis of simple test-time scaling and finds that the scaling behavior is largely attributed to scaling down by enforcing a maximum length. In contrast, fine-tuning on long CoT data distilled from o1-like models has no significant impact on scaling behavior, and scaling up by appending "Wait" leads to inconsistencies, as the model may oscillate between solutions. A key distinction exists between scaling down by enforcing a maximum length and scaling up test-time compute in o1-like models, such as DeepSeek-R1\\@. These models are typically allowed to utilize as much compute as needed, with the only constraint being the model\'s maximum supported length. By learning to naturally scale up test-time compute during reinforcement learning, o1-like models surpass their peak performance when scaling up. In contrast, simple test-time scaling progressively imposes a lower upper limit on model performance as it scales down. While replicating the test-time scaling behavior of o1 models can be straightforward by scaling down, it is crucial to recognize that the goal of scaling test-time compute is to unlock higher performance -- beyond what the model could originally achieve -- rather than merely reproducing the appearance of scaling behavior.', 'abstract_zh': '简单测试时缩放的分析及其在o1-like模型中的应用', 'title_zh': '并非那么简单：简单测试时缩放的分析'}
{'arxiv_id': 'arXiv:2507.14418', 'title': 'Designing Conversational AI to Support Think-Aloud Practice in Technical Interview Preparation for CS Students', 'authors': 'Taufiq Daryanto, Sophia Stil, Xiaohan Ding, Daniel Manesh, Sang Won Lee, Tim Lee, Stephanie Lunn, Sarah Rodriguez, Chris Brown, Eugenia Rho', 'link': 'https://arxiv.org/abs/2507.14418', 'abstract': "One challenge in technical interviews is the think-aloud process, where candidates verbalize their thought processes while solving coding tasks. Despite its importance, opportunities for structured practice remain limited. Conversational AI offers potential assistance, but limited research explores user perceptions of its role in think-aloud practice. To address this gap, we conducted a study with 17 participants using an LLM-based technical interview practice tool. Participants valued AI's role in simulation, feedback, and learning from generated examples. Key design recommendations include promoting social presence in conversational AI for technical interview simulation, providing feedback beyond verbal content analysis, and enabling crowdsourced think-aloud examples through human-AI collaboration. Beyond feature design, we examined broader considerations, including intersectional challenges and potential strategies to address them, how AI-driven interview preparation could promote equitable learning in computing careers, and the need to rethink AI's role in interview practice by suggesting a research direction that integrates human-AI collaboration.", 'abstract_zh': '一项技术面试中的挑战是如何在解题过程中进行口头思考的过程，候选人需要在此过程中 verbalize 思维过程。尽管这一过程十分重要，但结构化练习的机会仍然有限。对话式 AI 可能提供帮助，但关于其在口头思考练习中角色的用户感知研究有限。为弥补这一差距，我们使用基于大语言模型的技术面试练习工具对 17 名参与者进行了研究。参与者认为 AI 在模拟、反馈和从生成示例中学习方面发挥着重要作用。关键的设计建议包括：促进对话式 AI 在技术面试模拟中的社会存在感，提供超越口头内容分析的反馈，并通过人机协作启用众包口头思考示例。除了功能设计，我们还探讨了更广泛的问题考虑，包括交叉挑战及其解决策略，AI 驱动的面试准备如何促进计算职业中的公平学习，以及重新思考 AI 在面试练习中的角色，建议整合人机协作的研究方向。', 'title_zh': '设计对话式人工智能以支持计算机科学学生技术面试准备过程中的think-aloud练习'}
{'arxiv_id': 'arXiv:2507.14387', 'title': 'Incremental Causal Graph Learning for Online Cyberattack Detection in Cyber-Physical Infrastructures', 'authors': 'Arun Vignesh Malarkkan, Dongjie Wang, Haoyue Bai, Yanjie Fu', 'link': 'https://arxiv.org/abs/2507.14387', 'abstract': 'The escalating threat of cyberattacks on real-time critical infrastructures poses serious risks to public safety, demanding detection methods that effectively capture complex system interdependencies and adapt to evolving attack patterns. Traditional real-time anomaly detection techniques often suffer from excessive false positives due to their statistical sensitivity to high data variance and class imbalance. To address these limitations, recent research has explored modeling causal relationships among system components. However, prior work mainly focuses on offline causal graph-based approaches that require static historical data and fail to generalize to real-time settings. These methods are fundamentally constrained by: (1) their inability to adapt to dynamic shifts in data distribution without retraining, and (2) the risk of catastrophic forgetting when lacking timely supervision in live systems. To overcome these challenges, we propose INCADET, a novel framework for incremental causal graph learning tailored to real-time cyberattack detection. INCADET dynamically captures evolving system behavior by incrementally updating causal graphs across streaming time windows. The framework comprises three modules: 1) Early Symptom Detection: Detects transitions in system status using divergence in edge-weight distributions across sequential causal graphs. 2) Incremental Causal Graph Learning: Leverages experience replay and edge reinforcement to continually refine causal structures while preserving prior knowledge. 3) Causal Graph Classification: Employs Graph Convolutional Networks (GCNs) to classify system status using the learned causal graphs. Extensive experiments on real-world critical infrastructure datasets demonstrate that INCADET achieves superior accuracy, robustness, and adaptability compared to both static causal and deep temporal baselines in evolving attack scenarios.', 'abstract_zh': '实时关键基础设施中不断升级的网络攻击威胁对公共安全构成严重风险，要求有效的检测方法能够捕捉复杂系统间的相互依赖关系并适应不断演变的攻击模式。传统实时异常检测技术往往因统计上对高数据变异性及类别不平衡的敏感性而产生过多的误报。为解决这些问题，近期研究探索了系统组件间因果关系的建模方法。然而，先前的工作主要集中在需要静态历史数据的离线因果图方法上，这些方法无法适应实时场景中的推广性。这些方法本质上受限于：（1）无法在无需重新训练的情况下适应数据分布的变化，（2）在缺乏及时监督的实时系统中存在灾难性遗忘的风险。为克服这些挑战，我们提出INCADET，一种针对实时网络攻击检测的增量因果图学习新型框架。INCADET通过在流式时间窗口中增量更新因果图来动态捕捉系统行为的变化。该框架包含三个模块：1）早期症状检测：通过顺序因果图中边权重分布的差异检测系统状态的转换。2）增量因果图学习：利用经验重演和边强化不断细化因果结构，同时保留先前知识。3）因果图分类：采用图卷积网络（GCNs）使用学习到的因果图来分类系统状态。在实际关键基础设施数据集上的广泛实验表明，INCADET在不断演变的攻击场景中较静态因果和深度时序基线方法在准确度、稳健性和适应性方面具有明显优势。', 'title_zh': '在线物理信息系统中增量因果图学习的网络攻击检测方法'}
{'arxiv_id': 'arXiv:2507.14376', 'title': 'Schemora: schema matching via multi-stage recommendation and metadata enrichment using off-the-shelf llms', 'authors': 'Osman Erman Gungor, Derak Paulsen, William Kang', 'link': 'https://arxiv.org/abs/2507.14376', 'abstract': 'Schema matching is essential for integrating heterogeneous data sources and enhancing dataset discovery, yet it remains a complex and resource-intensive problem. We introduce SCHEMORA, a schema matching framework that combines large language models with hybrid retrieval techniques in a prompt-based approach, enabling efficient identification of candidate matches without relying on labeled training data or exhaustive pairwise comparisons. By enriching schema metadata and leveraging both vector-based and lexical retrieval, SCHEMORA improves matching accuracy and scalability. Evaluated on the MIMIC-OMOP benchmark, it establishes new state-of-the-art performance, with gains of 7.49% in HitRate@5 and 3.75% in HitRate@3 over previous best results. To our knowledge, this is the first LLM-based schema matching method with an open-source implementation, accompanied by analysis that underscores the critical role of retrieval and provides practical guidance on model selection.', 'abstract_zh': '基于大规模语言模型的SCHEMORA模式匹配框架：通过混合检索技术提高效率和可扩展性', 'title_zh': 'Schemora：基于多阶段推荐和元数据增强的模式匹配'}
{'arxiv_id': 'arXiv:2507.14372', 'title': 'Text-to-SQL for Enterprise Data Analytics', 'authors': 'Albert Chen, Manas Bundele, Gaurav Ahlawat, Patrick Stetz, Zhitao Wang, Qiang Fei, Donghoon Jung, Audrey Chu, Bharadwaj Jayaraman, Ayushi Panth, Yatin Arora, Sourav Jain, Renjith Varma, Alexey Ilin, Iuliia Melnychuk, Chelsea Chueh, Joyan Sil, Xiaofeng Wang', 'link': 'https://arxiv.org/abs/2507.14372', 'abstract': "The introduction of large language models has brought rapid progress on Text-to-SQL benchmarks, but it is not yet easy to build a working enterprise solution. In this paper, we present insights from building an internal chatbot that enables LinkedIn's product managers, engineers, and operations teams to self-serve data insights from a large, dynamic data lake. Our approach features three components. First, we construct a knowledge graph that captures up-to-date semantics by indexing database metadata, historical query logs, wikis, and code. We apply clustering to identify relevant tables for each team or product area. Second, we build a Text-to-SQL agent that retrieves and ranks context from the knowledge graph, writes a query, and automatically corrects hallucinations and syntax errors. Third, we build an interactive chatbot that supports various user intents, from data discovery to query writing to debugging, and displays responses in rich UI elements to encourage follow-up chats. Our chatbot has over 300 weekly users. Expert review shows that 53% of its responses are correct or close to correct on an internal benchmark set. Through ablation studies, we identify the most important knowledge graph and modeling components, offering a practical path for developing enterprise Text-to-SQL solutions.", 'abstract_zh': '大型语言模型的引入已经在Text-to-SQL基准测试中带来了快速的进步，但构建一个可行的企业级解决方案仍然不是一件容易的事。本文介绍了构建LinkedIn内部聊天机器人的见解，该聊天机器人使产品管理团队、工程师和运营团队能够从大型动态数据湖中自助获取数据洞见。我们的方法包括三个组成部分。首先，我们构建了一个知识图谱，通过索引数据库元数据、历史查询日志、维基和代码来捕获最新的语义，并使用聚类来识别每个团队或产品领域的相关表格。其次，我们构建了一个Text-to-SQL代理，能够从知识图谱中检索和排名上下文、生成查询，并自动纠正幻觉和语法错误。第三，我们构建了一个支持各种用户意图的交互式聊天机器人，从数据发现到查询编写再到调试，并通过丰富的UI元素显示响应以促进后续对话。我们的聊天机器每周有超过300名用户。专家评审显示，其53%的响应在内部基准数据集中是正确的或接近正确的。通过消融研究，我们确定了最重要的知识图谱和建模组件，为开发企业级Text-to-SQL解决方案提供了实际路径。', 'title_zh': '企业数据查询的文本到SQL转换'}
{'arxiv_id': 'arXiv:2507.14353', 'title': 'Solo Connection: A Parameter Efficient Fine-Tuning Technique for Transformers', 'authors': 'Harsh Nilesh Pathak, Randy Paffenroth', 'link': 'https://arxiv.org/abs/2507.14353', 'abstract': "Parameter efficient fine tuning (PEFT) is a versatile and extensible approach for adapting a Large Language Model (LLM) for newer tasks. One of the most prominent PEFT approaches, Low Rank Adaptation (LoRA), primarily focuses on adjusting the attention weight matrices within individual decoder blocks of a Generative Pre trained Transformer (GPT2). In contrast, we introduce Solo Connection a novel method that adapts the representation at the decoder-block level rather than modifying individual weight matrices. Not only does Solo Connection outperform LoRA on E2E natural language generation benchmarks, but it also reduces the number of trainable parameters by 59% relative to LoRA and by more than 99% compared to full fine-tuning of GPT2, an early version of Large Language Models (LLMs). Solo Connection is also motivated by homotopy theory: we introduce a trainable linear transformation that gradually interpolates between a zero vector and the task-specific representation, enabling smooth and stable adaptation over time. While skip connections in the original 12 layer GPT2 are typically confined to individual decoder blocks, subsequent GPT2 variants scale up to 48 layers, and even larger language models can include 128 or more decoder blocks. These expanded architectures underscore the need to revisit how skip connections are employed during fine-tuning. This paper focuses on long skip connections that link outputs of different decoder blocks, potentially enhancing the model's ability to adapt to new tasks while leveraging pre-trained knowledge.", 'abstract_zh': '基于独享连接的参数高效微调：一种Decoders-block级表示适应方法', 'title_zh': 'solo 连接：一种用于 Transformer 的参数高效微调技术'}
{'arxiv_id': 'arXiv:2507.14352', 'title': 'A Reproducibility Study of Product-side Fairness in Bundle Recommendation', 'authors': 'Huy-Son Nguyen, Yuanna Liu, Masoud Mansoury, Mohammad Alian Nejadi, Alan Hanjalic, Maarten de Rijke', 'link': 'https://arxiv.org/abs/2507.14352', 'abstract': 'Recommender systems are known to exhibit fairness issues, particularly on the product side, where products and their associated suppliers receive unequal exposure in recommended results. While this problem has been widely studied in traditional recommendation settings, its implications for bundle recommendation (BR) remain largely unexplored. This emerging task introduces additional complexity: recommendations are generated at the bundle level, yet user satisfaction and product (or supplier) exposure depend on both the bundle and the individual items it contains. Existing fairness frameworks and metrics designed for traditional recommender systems may not directly translate to this multi-layered setting. In this paper, we conduct a comprehensive reproducibility study of product-side fairness in BR across three real-world datasets using four state-of-the-art BR methods. We analyze exposure disparities at both the bundle and item levels using multiple fairness metrics, uncovering important patterns. Our results show that exposure patterns differ notably between bundles and items, revealing the need for fairness interventions that go beyond bundle-level assumptions. We also find that fairness assessments vary considerably depending on the metric used, reinforcing the need for multi-faceted evaluation. Furthermore, user behavior plays a critical role: when users interact more frequently with bundles than with individual items, BR systems tend to yield fairer exposure distributions across both levels. Overall, our findings offer actionable insights for building fairer bundle recommender systems and establish a vital foundation for future research in this emerging domain.', 'abstract_zh': '推荐系统在捆绑推荐中表现出公平性问题：产品及其供应商在推荐结果中的曝光不平等现象在传统推荐设置中得到了广泛研究，但在捆绑推荐（BR）中的影响仍 largely unexplored。这一新兴任务引入了额外的复杂性：推荐是在捆绑级别生成的，但用户满意度和产品（或供应商）曝光既取决于捆绑，也取决于捆绑中包含的单个物品。现有的为传统推荐系统设计的公平性框架和指标可能不直接适用于这种多层设置。在本文中，我们使用四种最新的捆绑推荐方法，在三个真实数据集上进行了一项全面的可重复性研究，分析了捆绑和物品级别上的曝光差异，揭示了重要模式。结果显示，捆绑和物品之间的曝光模式存在显著差异，表明需要超越捆绑级别假设的公平性干预措施。我们还发现，根据使用的指标不同，公平性评估有很大差异，这强调了多维度评估的重要性。此外，用户行为起着关键作用：当用户更频繁地与捆绑而非单个物品交互时，BR系统倾向于在两个级别上产生更公平的曝光分布。总体而言，我们的研究结果为构建更公平的捆绑推荐系统提供了可操作的见解，并为这一新兴领域的未来研究奠定了基础。', 'title_zh': '产品层面推荐中产品公平性再现研究'}
{'arxiv_id': 'arXiv:2507.14344', 'title': 'Influence Functions for Preference Dataset Pruning', 'authors': 'Daniel Fein, Gabriela Aranguiz-Dias', 'link': 'https://arxiv.org/abs/2507.14344', 'abstract': 'Language models are commonly fine-tuned via reinforcement learning to alter their behavior or elicit new capabilities. Datasets used for these purposes, and particularly human preference datasets, are often noisy. The relatively small size post-training datasets, combined with parameter-efficient fine-tuning methods, enable the use of influence functions approximations to detect and prune training examples that are harmful to performance on a validation set. In this work, we adapt the TL;DR dataset for reward model training to demonstrate how conjugate-gradient approximated influence functions can be used to filter datasets. In our experiments, influence function filtering yields a small retraining accuracy uplift of 1.5% after removing 10% of training examples. We also show that gradient similarity outperforms influence functions for detecting helpful training examples. This suggests that local curvature is important for detecting harmful training examples, but less so for identifying helpful examples.', 'abstract_zh': '语言模型通常通过强化学习进行微调以改变其行为或激发新能力。用于这些目的的数据集，尤其是人类偏好数据集，往往是嘈杂的。经过微调后相对较小的数据集大小与参数高效微调方法相结合，使得可以通过影响函数近似检测和去除对验证集性能有害的训练示例。在本文中，我们改编TL;DR数据集以供奖励模型训练使用，展示如何使用共轭梯度近似影响函数来筛选数据集。在我们的实验中，在去除10%的训练示例后，影响函数筛选带来了约1.5%的重新培训准确率提升。我们还展示了梯度相似度在检测有益训练示例方面优于影响函数。这表明局部曲率对于检测有害训练示例很重要，但对于识别有益示例则不那么重要。', 'title_zh': '偏好数据集裁剪的影响函数'}
{'arxiv_id': 'arXiv:2507.14339', 'title': 'Fiduciary AI for the Future of Brain-Technology Interactions', 'authors': 'Abhishek Bhattacharjee, Jack Pilkington, Nita Farahany', 'link': 'https://arxiv.org/abs/2507.14339', 'abstract': "Brain foundation models represent a new frontier in AI: instead of processing text or images, these models interpret real-time neural signals from EEG, fMRI, and other neurotechnologies. When integrated with brain-computer interfaces (BCIs), they may enable transformative applications-from thought controlled devices to neuroprosthetics-by interpreting and acting on brain activity in milliseconds. However, these same systems pose unprecedented risks, including the exploitation of subconscious neural signals and the erosion of cognitive liberty. Users cannot easily observe or control how their brain signals are interpreted, creating power asymmetries that are vulnerable to manipulation. This paper proposes embedding fiduciary duties-loyalty, care, and confidentiality-directly into BCI-integrated brain foundation models through technical design. Drawing on legal traditions and recent advancements in AI alignment techniques, we outline implementable architectural and governance mechanisms to ensure these systems act in users' best interests. Placing brain foundation models on a fiduciary footing is essential to realizing their potential without compromising self-determination.", 'abstract_zh': '脑基础模型代表了AI的新前沿：这些模型通过解释实时的脑电信号、功能性磁共振成像等神经技术的信号，而非处理文本或图像。当与脑-机接口集成时，它们可能通过毫秒级解释和反应大脑活动，实现从思想控制设备到神经假体等变革性应用。然而，这些系统同时带来了前所未有的风险，包括潜意识神经信号的滥用以及认知自由的侵蚀。用户无法轻易地观察或控制其脑信号如何被解释，这创造了容易受到操纵的影响权力不对等。本文提议通过技术设计直接嵌入诚信义务（忠诚、关怀和保密）到脑-机接口集成的脑基础模型中，借鉴法律传统和近期AI对齐技术的进步，我们提出了可实施的架构和治理机制，以确保这些系统符合用户的最大利益。将脑基础模型置于信托基础上对于充分利用其潜力而不牺牲自主性是至关重要的。', 'title_zh': '未来脑机交互中的受托人工智能'}
{'arxiv_id': 'arXiv:2507.14299', 'title': 'Age of Information Minimization in UAV-Enabled Integrated Sensing and Communication Systems', 'authors': 'Yu Bai, Yifan Zhang, Boxuan Xie, Zheng Chang, Yanru Zhang, Riku Jantti, Zhu Han', 'link': 'https://arxiv.org/abs/2507.14299', 'abstract': "Unmanned aerial vehicles (UAVs) equipped with integrated sensing and communication (ISAC) capabilities are envisioned to play a pivotal role in future wireless networks due to their enhanced flexibility and efficiency. However, jointly optimizing UAV trajectory planning, multi-user communication, and target sensing under stringent resource constraints and time-critical conditions remains a significant challenge. To address this, we propose an Age of Information (AoI)-centric UAV-ISAC system that simultaneously performs target sensing and serves multiple ground users, emphasizing information freshness as the core performance metric. We formulate a long-term average AoI minimization problem that jointly optimizes the UAV's flight trajectory and beamforming. To tackle the high-dimensional, non-convexity of this problem, we develop a deep reinforcement learning (DRL)-based algorithm capable of providing real-time decisions on UAV movement and beamforming for both radar sensing and multi-user communication. Specifically, a Kalman filter is employed for accurate target state prediction, regularized zero-forcing is utilized to mitigate inter-user interference, and the Soft Actor-Critic algorithm is applied for training the DRL agent on continuous actions. The proposed framework adaptively balances the trade-offs between sensing accuracy and communication quality. Extensive simulation results demonstrate that our proposed method consistently achieves lower average AoI compared to baseline approaches.", 'abstract_zh': '具有集成传感与通信能力的无人驾驶飞行器（UAV-ISAC）在未来无线网络中的角色及其实时性中心优化方法', 'title_zh': '基于无人机使能的集成感知与通信系统的年龄信息最小化'}
{'arxiv_id': 'arXiv:2507.14298', 'title': 'In-Depth and In-Breadth: Pre-training Multimodal Language Models Customized for Comprehensive Chart Understanding', 'authors': 'Wan-Cyuan Fan, Yen-Chun Chen, Mengchen Liu, Alexander Jacobson, Lu Yuan, Leonid Sigal', 'link': 'https://arxiv.org/abs/2507.14298', 'abstract': "Recent methods for customizing Large Vision Language Models (LVLMs) for domain-specific tasks have shown promising results in scientific chart comprehension. However, existing approaches face two major limitations: First, they rely on paired data from only a few chart types, limiting generalization to wide range of chart types. Secondly, they lack targeted pre-training for chart-data alignment, which hampers the model's understanding of underlying data. In this paper, we introduce ChartScope, an LVLM optimized for in-depth chart comprehension across diverse chart types. We propose an efficient data generation pipeline that synthesizes paired data for a wide range of chart types, along with a novel Dual-Path training strategy that enabling the model to succinctly capture essential data details while preserving robust reasoning capabilities by incorporating reasoning over the underlying data. Lastly, we establish ChartDQA, a new benchmark for evaluating not only question-answering at different levels but also underlying data understanding. Experimental results demonstrate that ChartScope significantly enhances comprehension on a wide range of chart types. The code and data are available at this https URL.", 'abstract_zh': 'Recent方法定制化大型视觉语言模型（LVLMs）以适应特定领域的科学图表理解任务已显示出了令人鼓舞的结果。然而，现有的方法面临两个主要局限：首先，它们依赖于少量图表类型的配对数据，限制了其对广泛图表类型的泛化能力。其次，它们缺乏针对图表数据对齐的针对性预训练，这阻碍了模型对底层数据的理解。在本文中，我们引入了ChartScope，这是一种针对多种图表类型的深度图表理解进行了优化的LVLM。我们提出了一种高效的数据生成管道，可以合成广泛图表类型的配对数据，并提出了一种新颖的双路径训练策略，使模型能够简洁地捕捉关键数据细节，同时通过在底层数据上进行推理来保持稳健的推理能力。最后，我们建立了ChartDQA作为新的基准，不仅用于评估不同层次的问答能力，还用于评估对底层数据的理解。实验结果表明，ChartScope显著提升了对多种图表类型的理解能力。代码和数据可在以下链接获取。', 'title_zh': '深入与广泛：面向全面图表理解的多模态语言模型预训练'}
{'arxiv_id': 'arXiv:2507.14295', 'title': 'A Simple "Try Again" Can Elicit Multi-Turn LLM Reasoning', 'authors': 'Licheng Liu, Zihan Wang, Linjie Li, Chenwei Xu, Yiping Lu, Han Liu, Avirup Sil, Manling Li', 'link': 'https://arxiv.org/abs/2507.14295', 'abstract': 'Multi-turn problem solving is critical yet challenging for Large Reasoning Models (LRMs) to reflect on their reasoning and revise from feedback. Existing Reinforcement Learning (RL) methods train large reasoning models on a single-turn paradigm with verifiable rewards. However, we observe that models trained with existing RL paradigms often lose their ability to solve problems across multiple turns and struggle to revise answers based on contextual feedback, leading to repetitive responses. We ask: can LRMs learn to reflect their answers in a multi-turn context? In this work, we find that training models with multi-turn RL using only unary feedback (e.g., "Let\'s try again") after wrong answers can improve both single-turn performance and multi-turn reasoning. We introduce Unary Feedback as Observation (UFO) for reinforcement learning, which uses minimal yet common unary user feedback during iterative problem solving. It can be easily applied to existing single-turn RL training setups. Experimental results show that RL training with UFO keeps single-turn performance and improves multi-turn reasoning accuracy by up to 14%, enabling language models to better react to feedback in multi-turn problem solving. To further minimize the number of turns needed for a correct answer while encouraging diverse reasoning when mistakes occur, we design reward structures that guide models to produce careful and deliberate answers in each turn. Code: this https URL', 'abstract_zh': '大型推理模型在多轮问题解决中的反思与修订至关重要且具有挑战性：多轮RL学习 unary 反馈以提升单轮性能与多轮推理', 'title_zh': '简单的“再试一次”可以诱发多轮LLM推理'}
{'arxiv_id': 'arXiv:2507.14272', 'title': 'NuSeC: A Dataset for Nuclei Segmentation in Breast Cancer Histopathology Images', 'authors': 'Refik Samet, Nooshin Nemati, Emrah Hancer, Serpil Sak, Bilge Ayca Kirmizi', 'link': 'https://arxiv.org/abs/2507.14272', 'abstract': 'The NuSeC dataset is created by selecting 4 images with the size of 1024*1024 pixels from the slides of each patient among 25 patients. Therefore, there are a total of 100 images in the NuSeC dataset. To carry out a consistent comparative analysis between the methods that will be developed using the NuSeC dataset by the researchers in the future, we divide the NuSeC dataset 75% as the training set and 25% as the testing set. In detail, an image is randomly selected from 4 images of each patient among 25 patients to build the testing set, and then the remaining images are reserved for the training set. While the training set includes 75 images with around 30000 nuclei structures, the testing set includes 25 images with around 6000 nuclei structures.', 'abstract_zh': 'NuSeC数据集由从每位患者的一张切片中挑选出的4张1024×1024像素的图像组成，共计25位患者的切片。因此，NuSeC数据集总共包含100张图像。为了未来研究人员使用NuSeC数据集开发的方法进行一致的对比分析，我们将NuSeC数据集分为75%的训练集和25%的测试集。具体方法是从每位患者4张图像中随机选取一张构建测试集，剩余图像用于构建训练集。训练集包括约75张图像和约30000个核结构，测试集包括25张图像和约6000个核结构。', 'title_zh': 'NuSeC: 乳腺癌组织病理图像中的核分割数据集'}
{'arxiv_id': 'arXiv:2507.14271', 'title': 'MiDeSeC: A Dataset for Mitosis Detection and Segmentation in Breast Cancer Histopathology Images', 'authors': 'Refik Samet, Nooshin Nemati, Emrah Hancer, Serpil Sak, Bilge Ayca Kirmizi, Zeynep Yildirim', 'link': 'https://arxiv.org/abs/2507.14271', 'abstract': 'The MiDeSeC dataset is created through H&E stained invasive breast carcinoma, no special type (NST) slides of 25 different patients captured at 40x magnification from the Department of Medical Pathology at Ankara University. The slides have been scanned by 3D Histech Panoramic p250 Flash-3 scanner and Olympus BX50 microscope. As several possible mitosis shapes exist, it is crucial to have a large dataset to cover all the cases. Accordingly, a total of 50 regions is selected from glass slides for 25 patients, each of regions with a size of 1024*1024 pixels. There are more than 500 mitoses in total in these 50 regions. Two-thirds of the regions are reserved for training, the other third for testing.', 'abstract_zh': 'MiDeSeC数据集通过 Ankara University 医学病理学系提供的40倍放大倍率的H&E染色侵袭性乳腺癌（无特殊类型）组织切片创建，来自25位患者的切片由3D Histech Panoramic p250 Flash-3扫描仪和Olympus BX50显微镜扫描。由于可能存在的多种有丝分裂形态，该数据集包含50个区域，每个区域1024*1024像素，共计超过500个有丝分裂。其中三分之二的区域用于训练，三分之一用于测试。', 'title_zh': 'MiDeSeC: 乳腺癌组织学图像中分裂检测与分割的数据集'}
{'arxiv_id': 'arXiv:2507.14270', 'title': 'APTx Neuron: A Unified Trainable Neuron Architecture Integrating Activation and Computation', 'authors': 'Ravin Kumar', 'link': 'https://arxiv.org/abs/2507.14270', 'abstract': 'We propose the APTx Neuron, a novel, unified neural computation unit that integrates non-linear activation and linear transformation into a single trainable expression. The APTx Neuron is derived from the APTx activation function, thereby eliminating the need for separate activation layers and making the architecture both computationally efficient and elegant. The proposed neuron follows the functional form $y = \\sum_{i=1}^{n} ((\\alpha_i + \\tanh(\\beta_i x_i)) \\cdot \\gamma_i x_i) + \\delta$, where all parameters $\\alpha_i$, $\\beta_i$, $\\gamma_i$, and $\\delta$ are trainable. We validate our APTx Neuron-based architecture on the MNIST dataset, achieving up to 96.69\\% test accuracy in just 20 epochs using approximately 332K trainable parameters. The results highlight the superior expressiveness and computational efficiency of the APTx Neuron compared to traditional neurons, pointing toward a new paradigm in unified neuron design and the architectures built upon it.', 'abstract_zh': '我们提出APTx神经元，这是一种新颖的统一神经计算单元，将非线性激活和线性变换融合为单一的可训练表达式。APTx神经元源自APTx激活函数，从而消除了单独激活层的需要，使架构既计算高效又简洁。所提出的神经元遵循函数形式$y = \\sum_{i=1}^{n} ((\\alpha_i + \\tanh(\\beta_i x_i)) \\cdot \\gamma_i x_i) + \\delta$，其中所有参数$\\alpha_i$、$\\beta_i$、$\\gamma_i$和$\\delta$均为可训练参数。我们基于APTx神经元的架构在MNIST数据集上进行了验证，仅在20个epochs内使用约33.2万可训练参数即可实现高达96.69%的测试准确率。结果突显了APTx神经元相比传统神经元的优越的表达能力和计算效率，并指向统一神经元设计及其架构的新范式。', 'title_zh': 'APTx神经元：一种集成了激活与计算的统一可训练神经元架构'}
{'arxiv_id': 'arXiv:2507.14266', 'title': 'Bridging MOOCs, Smart Teaching, and AI: A Decade of Evolution Toward a Unified Pedagogy', 'authors': 'Bo Yuan, Jiazi Hu', 'link': 'https://arxiv.org/abs/2507.14266', 'abstract': "Over the past decade, higher education has evolved through three distinct paradigms: the emergence of Massive Open Online Courses (MOOCs), the integration of Smart Teaching technologies into classrooms, and the rise of AI-enhanced learning. Each paradigm is intended to address specific challenges in traditional education: MOOCs enable ubiquitous access to learning resources; Smart Teaching supports real-time interaction with data-driven insights; and generative AI offers personalized feedback and on-demand content generation. However, these paradigms are often implemented in isolation due to their disparate technological origins and policy-driven adoption. This paper examines the origins, strengths, and limitations of each paradigm, and advocates a unified pedagogical perspective that synthesizes their complementary affordances. We propose a three-layer instructional framework that combines the scalability of MOOCs, the responsiveness of Smart Teaching, and the adaptivity of AI. To demonstrate its feasibility, we present a curriculum design for a project-based course. The findings highlight the framework's potential to enhance learner engagement, support instructors, and enable personalized yet scalable learning.", 'abstract_zh': '过去十年中，高等教育经历了三种不同的范式演变：大规模开放在线课程（MOOCs）的涌现、智能教学技术在课堂中的整合以及增强学习的兴起。每个范式都旨在解决传统教育中的特定挑战：MOOCs使学习资源的获取无处不在；智能教学支持实时的数据驱动交互；生成式AI提供个性化反馈和按需内容生成。然而，由于它们各自的技术起源和政策驱动的采纳方式不同，这些范式通常被孤立实施。本文探讨了每个范式的起源、优势和局限性，并倡导一种综合的教学视角，以综合它们互补的功能。我们提出了一种三层教学框架，结合了MOOCs的可扩展性、Smart Teaching的响应性以及AI的适应性。为了证明其实现可行性，我们为一个基于项目的设计了一门课程的教学大纲。研究发现突显了该框架在增强学习者参与度、支持教师以及实现个性化和可扩展学习方面的潜力。', 'title_zh': 'MOOCs、智能教学与AI：十年一体化教学理念的发展'}
{'arxiv_id': 'arXiv:2507.14263', 'title': 'Beyond DNS: Unlocking the Internet of AI Agents via the NANDA Index and Verified AgentFacts', 'authors': 'Ramesh Raskar, Pradyumna Chari, John Zinky, Mahesh Lambe, Jared James Grogan, Sichao Wang, Rajesh Ranjan, Rekha Singhal, Shailja Gupta, Robert Lincourt, Raghu Bala, Aditi Joshi, Abhishek Singh, Ayush Chopra, Dimitris Stripelis, Bhuwan B, Sumit Kumar, Maria Gorskikh', 'link': 'https://arxiv.org/abs/2507.14263', 'abstract': 'The Internet is poised to host billions to trillions of autonomous AI agents that negotiate, delegate, and migrate in milliseconds and workloads that will strain DNS-centred identity and discovery. In this paper, we describe the NANDA index architecture, which we envision as a means for discoverability, identifiability and authentication in the internet of AI agents. We present an architecture where a minimal lean index resolves to dynamic, cryptographically verifiable AgentFacts that supports multi-endpoint routing, load balancing, privacy-preserving access, and credentialed capability assertions. Our architecture design delivers five concrete guarantees: (1) A quilt-like index proposal that supports both NANDA-native agents as well as third party agents being discoverable via the index, (2) rapid global resolution for newly spawned AI agents, (3) sub-second revocation and key rotation, (4) schema-validated capability assertions, and (5) privacy-preserving discovery across organisational boundaries via verifiable, least-disclosure queries. We formalize the AgentFacts schema, specify a CRDT-based update protocol, and prototype adaptive resolvers. The result is a lightweight, horizontally scalable foundation that unlocks secure, trust-aware collaboration for the next generation of the Internet of AI agents, without abandoning existing web infrastructure.', 'abstract_zh': '互联网即将承载 billions 到 trillions 个自主AI代理进行毫秒级的协商、委托和迁移，工作负载将给以DNS为中心的身份验证和发现带来压力。本文描述了NANDA索引架构，我们设想它是一种在AI代理互联网中实现可发现性、可标识性和认证的手段。我们提出了一种架构，其中最小轻量级索引解析为动态、加密可验证的AgentFacts，支持多端点路由、负载均衡、隐私保护访问和凭据认证声明。该架构设计提供了五个具体保证：(1) 表格-like 索引提案，支持NANDA原生代理及第三方代理通过索引进行发现；(2) 新生成的AI代理的快速全球解析；(3) 子秒级撤销和密钥轮换；(4) 验证后的内容声明；(5) 跨组织边界进行隐私保护发现，通过可验证、最小披露查询实现。我们形式化了AgentFacts架构，指定了CRDT基础的更新协议，并原型实现了自适应解析器。结果是一个轻量级、水平扩展的基础架构，为下一代AI代理互联网解锁了安全、信任感知的合作，而不放弃现有Web架构。', 'title_zh': '超越DNS：通过NANDA索引和验证代理事实解锁人工智能代理的互联网'}
{'arxiv_id': 'arXiv:2507.14261', 'title': 'FAMST: Fast Approximate Minimum Spanning Tree Construction for Large-Scale and High-Dimensional Data', 'authors': 'Mahmood K. M. Almansoori, Miklos Telek', 'link': 'https://arxiv.org/abs/2507.14261', 'abstract': 'We present Fast Approximate Minimum Spanning Tree (FAMST), a novel algorithm that addresses the computational challenges of constructing Minimum Spanning Trees (MSTs) for large-scale and high-dimensional datasets. FAMST utilizes a three-phase approach: Approximate Nearest Neighbor (ANN) graph construction, ANN inter-component connection, and iterative edge refinement. For a dataset of $n$ points in a $d$-dimensional space, FAMST achieves $\\mathcal{O}(dn \\log n)$ time complexity and $\\mathcal{O}(dn + kn)$ space complexity when $k$ nearest neighbors are considered, which is a significant improvement over the $\\mathcal{O}(n^2)$ time and space complexity of traditional methods.\nExperiments across diverse datasets demonstrate that FAMST achieves remarkably low approximation errors while providing speedups of up to 1000$\\times$ compared to exact MST algorithms. We analyze how the key hyperparameters, $k$ (neighborhood size) and $\\lambda$ (inter-component edges), affect performance, providing practical guidelines for hyperparameter selection. FAMST enables MST-based analysis on datasets with millions of points and thousands of dimensions, extending the applicability of MST techniques to problem scales previously considered infeasible.', 'abstract_zh': 'Fast Approximate Minimum Spanning Tree for Large-Scale and High-Dimensional Datasets', 'title_zh': 'FAMST：大型高维数据快速近似最小生成树构建方法'}
{'arxiv_id': 'arXiv:2507.14256', 'title': 'Impact of Code Context and Prompting Strategies on Automated Unit Test Generation with Modern General-Purpose Large Language Models', 'authors': 'Jakub Walczak, Piotr Tomalak, Artur Laskowski', 'link': 'https://arxiv.org/abs/2507.14256', 'abstract': "Generative AI is gaining increasing attention in software engineering, where testing remains an indispensable reliability mechanism. According to the widely adopted testing pyramid, unit tests constitute the majority of test cases and are often schematic, requiring minimal domain expertise. Automatically generating such tests under the supervision of software engineers can significantly enhance productivity during the development phase of the software lifecycle.\nThis paper investigates the impact of code context and prompting strategies on the quality and adequacy of unit tests generated by various large language models (LLMs) across several families. The results show that including docstrings notably improves code adequacy, while further extending context to the full implementation yields definitely smaller gains. Notably, the chain-of-thought prompting strategy -- applied even to 'reasoning' models -- achieves the best results, with up to 96.3\\% branch coverage, a 57\\% average mutation score, and near-perfect compilation success rate. Among the evaluated models, M5 (Gemini 2.5 Pro) demonstrated superior performance in both mutation score and branch coverage being still in top in terms of compilation success rate.\nAll the code and resulting test suites are publicly available at this https URL.", 'abstract_zh': '生成式AI在软件工程中的测试应用正逐渐引起关注，其中测试仍然是不可或缺的可靠性机制。根据广泛采用的测试金字塔模型，单元测试构成了大多数测试用例，并且通常具有示例性质，只需要少量领域专业知识。在软件开发生命周期的开发阶段，在软件工程师的监督下自动生成此类测试可以显著提高生产力。\n\n本文研究了代码上下文和提示策略对多种大型语言模型（LLMs）生成的单元测试质量及 adequacy 的影响，涵盖多个模型家族。结果显示，包含文档字符串显著提高了代码完善性，而进一步扩展上下文至完整实现仅带来轻微增益。值得注意的是，链式思考提示策略——即使应用于“推理”模型——取得了最佳结果，分支覆盖率达到96.3%，平均突变得分为57%，并且几乎完美的编译成功率达到近乎完美。在评估的模型中，M5（Gemini 2.5 Pro）在突变得分和分支覆盖率方面表现出色，仍以最高编译成功率位居前列。\n\n所有代码及生成的测试套件在此公开网址处提供。', 'title_zh': '现代通用大型语言模型中的代码上下文与提示策略对自动化单元测试生成的影响'}
{'arxiv_id': 'arXiv:2507.14249', 'title': 'Real-Time Communication-Aware Ride-Sharing Route Planning for Urban Air Mobility: A Multi-Source Hybrid Attention Reinforcement Learning Approach', 'authors': 'Yuejiao Xie, Maonan Wang, Di Zhou, Man-On Pun, Zhu Han', 'link': 'https://arxiv.org/abs/2507.14249', 'abstract': 'Urban Air Mobility (UAM) systems are rapidly emerging as promising solutions to alleviate urban congestion, with path planning becoming a key focus area. Unlike ground transportation, UAM trajectory planning has to prioritize communication quality for accurate location tracking in constantly changing environments to ensure safety. Meanwhile, a UAM system, serving as an air taxi, requires adaptive planning to respond to real-time passenger requests, especially in ride-sharing scenarios where passenger demands are unpredictable and dynamic. However, conventional trajectory planning strategies based on predefined routes lack the flexibility to meet varied passenger ride demands. To address these challenges, this work first proposes constructing a radio map to evaluate the communication quality of urban airspace. Building on this, we introduce a novel Multi-Source Hybrid Attention Reinforcement Learning (MSHA-RL) framework for the challenge of effectively focusing on passengers and UAM locations, which arises from the significant dimensional disparity between the representations. This model first generates the alignment among diverse data sources with large gap dimensions before employing hybrid attention to balance global and local insights, thereby facilitating responsive, real-time path planning. Extensive experimental results demonstrate that the approach enables communication-compliant trajectory planning, reducing travel time and enhancing operational efficiency while prioritizing passenger safety.', 'abstract_zh': '城市空中 mobility (UAM) 系统正rapidly emerging as 有前途的缓解urban congestion的解决方案，路径规划成为关键研究领域。与地面交通不同，UAM 轨迹规划需要优先考虑通信质量，以在不断变化的环境中实现精确的位置跟踪，确保安全。与此同时，作为空中出租车的UAM系统，需要适应性规划以响应实时乘客请求，特别是在拼车场景中，乘客需求是不可预测和动态变化的。然而，基于预定义路线的传统轨迹规划策略缺乏灵活性，无法满足多样化乘客出行需求。为解决这些挑战，本工作首先提出构建无线电图以评估城市空域的通信质量。在此基础上，我们引入了一种新颖的多源混合注意力强化学习（MSHA-RL）框架，以有效关注乘客和UAM位置，这源自于表示之间显著的维度差距。该模型首先生成不同数据源之间的对齐关系，然后采用混合注意力机制平衡全局和局部洞察，从而促进响应性、实时路径规划。广泛实验证明，该方法实现了通信合规的轨迹规划，减少了旅行时间，提升了运营效率，并优先考虑乘客安全。', 'title_zh': '基于实时通信的城市场景空中出行拼车路线规划：一种多源混合注意力强化学习方法'}
{'arxiv_id': 'arXiv:2507.14248', 'title': 'Breaking the Illusion of Security via Interpretation: Interpretable Vision Transformer Systems under Attack', 'authors': 'Eldor Abdukhamidov, Mohammed Abuhamad, Simon S. Woo, Hyoungshick Kim, Tamer Abuhmed', 'link': 'https://arxiv.org/abs/2507.14248', 'abstract': 'Vision transformer (ViT) models, when coupled with interpretation models, are regarded as secure and challenging to deceive, making them well-suited for security-critical domains such as medical applications, autonomous vehicles, drones, and robotics. However, successful attacks on these systems can lead to severe consequences. Recent research on threats targeting ViT models primarily focuses on generating the smallest adversarial perturbations that can deceive the models with high confidence, without considering their impact on model interpretations. Nevertheless, the use of interpretation models can effectively assist in detecting adversarial examples. This study investigates the vulnerability of transformer models to adversarial attacks, even when combined with interpretation models. We propose an attack called "AdViT" that generates adversarial examples capable of misleading both a given transformer model and its coupled interpretation model. Through extensive experiments on various transformer models and two transformer-based interpreters, we demonstrate that AdViT achieves a 100% attack success rate in both white-box and black-box scenarios. In white-box scenarios, it reaches up to 98% misclassification confidence, while in black-box scenarios, it reaches up to 76% misclassification confidence. Remarkably, AdViT consistently generates accurate interpretations in both scenarios, making the adversarial examples more difficult to detect.', 'abstract_zh': 'Vision Transformer模型结合解释模型后的对抗攻击脆弱性研究：AdViT攻击的有效性', 'title_zh': '通过解释破解安全幻象：攻击下的可解释视觉变换系统'}
{'arxiv_id': 'arXiv:2507.14245', 'title': 'A million-scale dataset and generalizable foundation model for nanomaterial-protein interactions', 'authors': 'Hengjie Yu, Kenneth A. Dawson, Haiyun Yang, Shuya Liu, Yan Yan, Yaochu Jin', 'link': 'https://arxiv.org/abs/2507.14245', 'abstract': 'Unlocking the potential of nanomaterials in medicine and environmental science hinges on understanding their interactions with proteins, a complex decision space where AI is poised to make a transformative impact. However, progress has been hindered by limited datasets and the restricted generalizability of existing models. Here, we propose NanoPro-3M, the largest nanomaterial-protein interaction dataset to date, comprising over 3.2 million samples and 37,000 unique proteins. Leveraging this, we present NanoProFormer, a foundational model that predicts nanomaterial-protein affinities through multimodal representation learning, demonstrating strong generalization, handling missing features, and unseen nanomaterials or proteins. We show that multimodal modeling significantly outperforms single-modality approaches and identifies key determinants of corona formation. Furthermore, we demonstrate its applicability to a range of downstream tasks through zero-shot inference and fine-tuning. Together, this work establishes a solid foundation for high-performance and generalized prediction of nanomaterial-protein interaction endpoints, reducing experimental reliance and accelerating various in vitro applications.', 'abstract_zh': '纳米材料在医学和环境科学中的潜力unlocking the potential of nanomaterials in medicine and environmental science hinges on understanding their interactions with proteins, a complex decision space where AI is poised to make a transformative impact.然而限于现有数据集的限制和现有模型通用性的不足，进展受到了阻碍。在此，我们提出NanoPro-3M，迄今为止最大的纳米材料-蛋白质相互作用数据集，包含超过320万个样本和37000种独特的蛋白质。利用这一数据集，我们提出NanoProFormer，一种基础模型，通过多模态表示学习预测纳米材料-蛋白质亲和力，展示了强健的泛化能力、处理缺失特征以及未知纳米材料或蛋白质的能力。我们表明，多模态建模显著优于单模态方法，并识别出冠层形成的关键决定因素。此外，我们通过零样本推理和微调展示了其在一系列下游任务上的应用潜力。本项工作为高性能和泛化的纳米材料-蛋白质相互作用终点预测奠定了坚实的基础，减少了实验依赖并加速了各种体外应用。', 'title_zh': '百万尺度数据集及可泛化的纳米材料-蛋白相互作用基础模型'}
{'arxiv_id': 'arXiv:2507.14242', 'title': 'Culling Misinformation from Gen AI: Toward Ethical Curation and Refinement', 'authors': 'Prerana Khatiwada, Grace Donaher, Jasymyn Navarro, Lokesh Bhatta', 'link': 'https://arxiv.org/abs/2507.14242', 'abstract': 'While Artificial Intelligence (AI) is not a new field, recent developments, especially with the release of generative tools like ChatGPT, have brought it to the forefront of the minds of industry workers and academic folk alike. There is currently much talk about AI and its ability to reshape many everyday processes as we know them through automation. It also allows users to expand their ideas by suggesting things they may not have thought of on their own and provides easier access to information. However, not all of the changes this technology will bring or has brought so far are positive; this is why it is extremely important for all modern people to recognize and understand the risks before using these tools and allowing them to cause harm. This work takes a position on better understanding many equity concerns and the spread of misinformation that result from new AI, in this case, specifically ChatGPT and deepfakes, and encouraging collaboration with law enforcement, developers, and users to reduce harm. Considering many academic sources, it warns against these issues, analyzing their cause and impact in fields including healthcare, education, science, academia, retail, and finance. Lastly, we propose a set of future-facing guidelines and policy considerations to solve these issues while still enabling innovation in these fields, this responsibility falling upon users, developers, and government entities.', 'abstract_zh': '人工智能中的公平关切与信息误导传播：促进执法、开发者和用户合作以减轻危害并推动创新', 'title_zh': '从生成式AI中剔除虚假信息：迈向伦理化的编纂与优化'}
{'arxiv_id': 'arXiv:2507.14241', 'title': 'Promptomatix: An Automatic Prompt Optimization Framework for Large Language Models', 'authors': 'Rithesh Murthy, Ming Zhu, Liangwei Yang, Jielin Qiu, Juntao Tan, Shelby Heinecke, Huan Wang, Caiming Xiong, Silvio Savarese', 'link': 'https://arxiv.org/abs/2507.14241', 'abstract': 'Large Language Models (LLMs) perform best with well-crafted prompts, yet prompt engineering remains manual, inconsistent, and inaccessible to non-experts. We introduce Promptomatix, an automatic prompt optimization framework that transforms natural language task descriptions into high-quality prompts without requiring manual tuning or domain expertise. Promptomatix supports both a lightweight meta-prompt-based optimizer and a DSPy-powered compiler, with modular design enabling future extension to more advanced frameworks. The system analyzes user intent, generates synthetic training data, selects prompting strategies, and refines prompts using cost-aware objectives. Evaluated across 5 task categories, Promptomatix achieves competitive or superior performance compared to existing libraries, while reducing prompt length and computational overhead making prompt optimization scalable and efficient.', 'abstract_zh': '大规模语言模型（LLMs）在精心构建的提示下表现最佳，然而提示工程仍然是手动进行的、不一致的且对非专家不可访问。我们引入了Promptomatix，这是一种自动提示优化框架，能够将自然语言任务描述转化为高质量的提示，无需手动调整或专业领域的知识。Promptomatix 支持基于元提示的轻量级优化器和由 DSPy 驱动的编译器，其模块化设计允许未来扩展到更高级的框架。该系统分析用户意图、生成合成训练数据、选择提示策略并使用成本感知目标改进提示。在5个任务类别上评估，Promptomatix 达到了与现有库相当或更好的性能，同时减少了提示长度和计算开销，使提示优化更具 scalability 和效率。', 'title_zh': 'Promptomatix：一种面向大规模语言模型的自动提示优化框架'}
{'arxiv_id': 'arXiv:2507.14240', 'title': 'HuggingGraph: Understanding the Supply Chain of LLM Ecosystem', 'authors': 'Mohammad Shahedur Rahman, Peng Gao, Yuede Ji', 'link': 'https://arxiv.org/abs/2507.14240', 'abstract': "Large language models (LLMs) leverage deep learning to process and predict sequences of words from context, enabling them to perform various NLP tasks, such as translation, summarization, question answering, and content generation. However, the growing size and complexity of developing, training, and deploying advanced LLMs require extensive computational resources and large datasets. This creates a barrier for users. As a result, platforms that host models and datasets are widely used. For example, Hugging Face, one of the most popular platforms, hosted 1.8 million models and 450K datasets by June 2025, with no sign of slowing down. Since many LLMs are built from base models, pre-trained models, and external datasets, they can inherit vulnerabilities, biases, or malicious components from earlier models or datasets. Therefore, it is critical to understand the origin and development of these components to better detect potential risks, improve model fairness, and ensure compliance. Motivated by this, our project aims to study the relationships between models and datasets, which are core components of the LLM supply chain. First, we design a method to systematically collect LLM supply chain data. Using this data, we build a directed heterogeneous graph to model the relationships between models and datasets, resulting in a structure with 397,376 nodes and 453,469 edges. We then perform various analyses and uncover several findings, such as: (i) the LLM supply chain graph is large, sparse, and follows a power-law degree distribution; (ii) it features a densely connected core and a fragmented periphery; (iii) datasets play pivotal roles in training; (iv) strong interdependence exists between models and datasets; and (v) the graph is dynamic, with daily updates reflecting the ecosystem's ongoing evolution.", 'abstract_zh': '大规模语言模型（LLMs）通过深度学习处理和预测基于上下文的词序列，使其能够执行各种自然语言处理任务，如翻译、总结、问答和内容生成。然而，开发、训练和部署先进LLMs的日益增长的规模和复杂性需要大量的计算资源和数据集。这为用户设定了障碍。因此，托管模型和数据集的平台被广泛使用。例如，截至2025年6月，Hugging Face这一最受欢迎的平台托管了180万模型和45万个数据集，且没有放缓的迹象。由于许多LLM是从基模型、预训练模型和外部数据集中构建的，它们可能会从早期模型或数据集中继承漏洞、偏差或恶意组件。因此，了解这些组件的来源和发展对于更好地检测潜在风险、提高模型公平性和确保合规性至关重要。受此驱动，我们的项目旨在研究模型和数据集之间的关系，这些是LLM供应链的核心组件。首先，我们设计了一种方法来系统地收集LLM供应链数据。利用这些数据，我们构建了一个有向异构图来建模模型和数据集之间的关系，形成了包含397,376个节点和453,469条边的结构。然后，我们进行了多种分析并揭示了几项发现，包括：（i）LLM供应链图规模庞大、稀疏且遵循幂律度分布；（ii）该图具备紧密连接的核心和分散的边缘；（iii）数据集在训练中扮演关键角色；（iv）模型和数据集之间存在强烈的相互依赖关系；（v）该图是动态的，每日更新反映了生态系统持续的演化。', 'title_zh': '拥抱图谱：理解大语言模型生态系统 Supply Chain'}
{'arxiv_id': 'arXiv:2507.14239', 'title': 'CCL-XCoT: An Efficient Cross-Lingual Knowledge Transfer Method for Mitigating Hallucination Generation', 'authors': 'Weihua Zheng, Roy Ka-Wei Lee, Zhengyuan Liu, Kui Wu, AiTi Aw, Bowei Zou', 'link': 'https://arxiv.org/abs/2507.14239', 'abstract': 'Multilingual Large Language Models(MLLMs) demonstrate strong generalization across languages, yet they remain prone to hallucinations, especially in low-resource languages, due to training data imbalances. These hallucinations, which include inaccurate or fabricated outputs, are particularly problematic in domain-specific generation tasks (Chataigner et al., 2024). To address this challenge, we propose CCL-XCoT(Curriculum-based Contrastive Learning-based Cross-lingual Chain-of-Thought), a two-stage fine-tuning framework for mitigating hallucination in MLLMs. Our approach first enhances cross-lingual semantic alignment through curriculum-based contrastive learning combined with next-token prediction during continued pre-training. Building on this foundation, we then introduce a cross-lingual Chain-of-Thought (XCoT) prompting strategy during instruction fine-tuning, which guides the model to reason in a high-resource language before generating answers in the target low-resource language. Experimental results show that CCL-XCoT reduces hallucination rates by up to 62% and substantially improves factual knowledge transfer across language pairs, without relying on external retrieval or multi-model ensembles.', 'abstract_zh': '基于 Curriculum-based Contrastive Learning 的跨语言 Chain-of-Thought 两阶段微调框架：缓解多语言大型语言模型的幻觉问题', 'title_zh': 'CCL-XCoT：一种有效的跨语言知识转移方法，用于减轻 hallucination 生成问题'}
{'arxiv_id': 'arXiv:2507.14238', 'title': 'Language Models Change Facts Based on the Way You Talk', 'authors': 'Matthew Kearney, Reuben Binns, Yarin Gal', 'link': 'https://arxiv.org/abs/2507.14238', 'abstract': "Large language models (LLMs) are increasingly being used in user-facing applications, from providing medical consultations to job interview advice. Recent research suggests that these models are becoming increasingly proficient at inferring identity information about the author of a piece of text from linguistic patterns as subtle as the choice of a few words. However, little is known about how LLMs use this information in their decision-making in real-world applications. We perform the first comprehensive analysis of how identity markers present in a user's writing bias LLM responses across five different high-stakes LLM applications in the domains of medicine, law, politics, government benefits, and job salaries. We find that LLMs are extremely sensitive to markers of identity in user queries and that race, gender, and age consistently influence LLM responses in these applications. For instance, when providing medical advice, we find that models apply different standards of care to individuals of different ethnicities for the same symptoms; we find that LLMs are more likely to alter answers to align with a conservative (liberal) political worldview when asked factual questions by older (younger) individuals; and that LLMs recommend lower salaries for non-White job applicants and higher salaries for women compared to men. Taken together, these biases mean that the use of off-the-shelf LLMs for these applications may cause harmful differences in medical care, foster wage gaps, and create different political factual realities for people of different identities. Beyond providing an analysis, we also provide new tools for evaluating how subtle encoding of identity in users' language choices impacts model decisions. Given the serious implications of these findings, we recommend that similar thorough assessments of LLM use in user-facing applications are conducted before future deployment.", 'abstract_zh': '大型语言模型中的身份标记偏见在高 stakes 应用中的分析：从医疗到薪酬的影响', 'title_zh': '语言模型会根据你的说话方式改变事实。'}
{'arxiv_id': 'arXiv:2507.14237', 'title': 'U-DREAM: Unsupervised Dereverberation guided by a Reverberation Model', 'authors': 'Louis Bahrman, Mathieu Fontaine, Gaël Richard', 'link': 'https://arxiv.org/abs/2507.14237', 'abstract': 'This paper explores the outcome of training state-ofthe-art dereverberation models with supervision settings ranging from weakly-supervised to fully unsupervised, relying solely on reverberant signals and an acoustic model for training. Most of the existing deep learning approaches typically require paired dry and reverberant data, which are difficult to obtain in practice. We develop instead a sequential learning strategy motivated by a bayesian formulation of the dereverberation problem, wherein acoustic parameters and dry signals are estimated from reverberant inputs using deep neural networks, guided by a reverberation matching loss. Our most data-efficient variant requires only 100 reverberation-parameter-labelled samples to outperform an unsupervised baseline, demonstrating the effectiveness and practicality of the proposed method in low-resource scenarios.', 'abstract_zh': '基于从弱监督到无监督训练设置的研究：利用回波信号训练最先进的去混响模型', 'title_zh': 'U-DREAM：基于混响模型的无监督去混响方法'}
{'arxiv_id': 'arXiv:2507.14231', 'title': 'Beyond Architectures: Evaluating the Role of Contextual Embeddings in Detecting Bipolar Disorder on Social Media', 'authors': 'Khalid Hasan, Jamil Saquer', 'link': 'https://arxiv.org/abs/2507.14231', 'abstract': 'Bipolar disorder is a chronic mental illness frequently underdiagnosed due to subtle early symptoms and social stigma. This paper explores the advanced natural language processing (NLP) models for recognizing signs of bipolar disorder based on user-generated social media text. We conduct a comprehensive evaluation of transformer-based models (BERT, RoBERTa, ALBERT, ELECTRA, DistilBERT) and Long Short Term Memory (LSTM) models based on contextualized (BERT) and static (GloVe, Word2Vec) word embeddings. Experiments were performed on a large, annotated dataset of Reddit posts after confirming their validity through sentiment variance and judgmental analysis. Our results demonstrate that RoBERTa achieves the highest performance among transformer models with an F1 score of ~98% while LSTM models using BERT embeddings yield nearly identical results. In contrast, LSTMs trained on static embeddings fail to capture meaningful patterns, scoring near-zero F1. These findings underscore the critical role of contextual language modeling in detecting bipolar disorder. In addition, we report model training times and highlight that DistilBERT offers an optimal balance between efficiency and accuracy. In general, our study offers actionable insights for model selection in mental health NLP applications and validates the potential of contextualized language models to support early bipolar disorder screening.', 'abstract_zh': '双相障碍是一种常因早期症状微妙和社会污名而被低估的慢性精神疾病。本文探讨了基于用户生成的社交媒体文本识别双相障碍征兆的高级自然语言处理（NLP）模型。我们对基于上下文（BERT）和静态（GloVe, Word2Vec）词向量的变换器模型（BERT, RoBERTa, ALBERT, ELECTRA, DistilBERT）和长短期记忆（LSTM）模型进行了全面评估。实验在经过情感变异和判断性分析确认有效性的大型标注的Reddit帖子数据集上进行。结果表明，RoBERTa 在变换器模型中表现最佳，F1 分数约为 98%，而使用 BERT 向量的 LSTM 模型取得了几乎相同的结果。相比之下，基于静态向量训练的 LSTM 无法捕捉到有意义的模式，F1 分数接近零。这些发现强调了上下文语言建模在检测双相障碍方面的关键作用。此外，我们报告了模型的训练时间，并指出 DistilBERT 在效率和准确性之间提供了最优平衡。总体而言，我们的研究为精神健康 NLP 应用中的模型选择提供了可操作的见解，并证实了上下文化语言模型支持早期双相障碍筛查的潜力。', 'title_zh': '超越架构：评估上下文嵌入在社交媒体上检测双相障碍中的作用'}
{'arxiv_id': 'arXiv:2507.14230', 'title': 'Intent-Based Network for RAN Management with Large Language Models', 'authors': 'Fransiscus Asisi Bimo, Maria Amparo Canaveras Galdon, Chun-Kai Lai, Ray-Guang Cheng, Edwin K. P. Chong', 'link': 'https://arxiv.org/abs/2507.14230', 'abstract': 'Advanced intelligent automation becomes an important feature to deal with the increased complexity in managing wireless networks. This paper proposes a novel automation approach of intent-based network for Radio Access Networks (RANs) management by leveraging Large Language Models (LLMs). The proposed method enhances intent translation, autonomously interpreting high-level objectives, reasoning over complex network states, and generating precise configurations of the RAN by integrating LLMs within an agentic architecture. We propose a structured prompt engineering technique and demonstrate that the network can automatically improve its energy efficiency by dynamically optimizing critical RAN parameters through a closed-loop mechanism. It showcases the potential to enable robust resource management in RAN by adapting strategies based on real-time feedback via LLM-orchestrated agentic systems.', 'abstract_zh': '基于大型语言模型的意图驱动无线接入网自动化方法', 'title_zh': '基于意图的网络架构用于RAN管理与大型语言模型'}
{'arxiv_id': 'arXiv:2507.14227', 'title': 'Domain Generalization via Pareto Optimal Gradient Matching', 'authors': 'Khoi Do, Duong Nguyen, Nam-Khanh Le, Quoc-Viet Pham, Binh-Son Hua, Won-Joo Hwang', 'link': 'https://arxiv.org/abs/2507.14227', 'abstract': 'In this study, we address the gradient-based domain generalization problem, where predictors aim for consistent gradient directions across different domains. Existing methods have two main challenges. First, minimization of gradient empirical distance or gradient inner products (GIP) leads to gradient fluctuations among domains, thereby hindering straightforward learning. Second, the direct application of gradient learning to the joint loss function can incur high computation overheads due to second-order derivative approximation. To tackle these challenges, we propose a new Pareto Optimality Gradient Matching (POGM) method. In contrast to existing methods that add gradient matching as regularization, we leverage gradient trajectories as collected data and apply independent training at the meta-learner. In the meta-update, we maximize GIP while limiting the learned gradient from deviating too far from the empirical risk minimization gradient trajectory. By doing so, the aggregate gradient can incorporate knowledge from all domains without suffering gradient fluctuation towards any particular domain. Experimental evaluations on datasets from DomainBed demonstrate competitive results yielded by POGM against other baselines while achieving computational efficiency.', 'abstract_zh': '本研究针对基于梯度的领域泛化问题，其中预测器旨在不同领域之间保持一致的梯度方向。现有方法存在两个主要挑战。首先，梯度经验距离最小化或梯度内积（GIP）的最小化会导致领域之间的梯度波动，从而妨碍直接学习。其次，将梯度学习直接应用于联合损失函数会导致由于二阶导数近似而产生高额的计算开销。为解决这些问题，我们提出了一种新的帕累托最优梯度匹配（POGM）方法。与现有方法将梯度匹配作为正则化不同，我们利用梯度轨迹作为收集的数据，并在元学习器中进行独立训练。在元更新过程中，最大化GIP同时限制学习到的梯度不要偏离经验风险最小化梯度轨迹太远。通过这种方式，聚合梯度可以在不向任何一个特定领域遭受梯度波动的情况下融合来自所有领域的知识。在DomainBed数据集上的实验评估表明，POGM在计算效率上优于其他基线方法的同时，还能获得竞争力的结果。', 'title_zh': 'Pareto最优梯度匹配的领域泛化方法'}
{'arxiv_id': 'arXiv:2507.14223', 'title': 'Multi-Granular Discretization for Interpretable Generalization in Precise Cyberattack Identification', 'authors': 'Wen-Cheng Chung, Shu-Ting Huang, Hao-Ting Pai', 'link': 'https://arxiv.org/abs/2507.14223', 'abstract': 'Explainable intrusion detection systems (IDS) are now recognized as essential for mission-critical networks, yet most "XAI" pipelines still bolt an approximate explainer onto an opaque classifier, leaving analysts with partial and sometimes misleading insights. The Interpretable Generalization (IG) mechanism, published in IEEE Transactions on Information Forensics and Security, eliminates that bottleneck by learning coherent patterns - feature combinations unique to benign or malicious traffic - and turning them into fully auditable rules. IG already delivers outstanding precision, recall, and AUC on NSL-KDD, UNSW-NB15, and UKM-IDS20, even when trained on only 10% of the data. To raise precision further without sacrificing transparency, we introduce Multi-Granular Discretization (IG-MD), which represents every continuous feature at several Gaussian-based resolutions. On UKM-IDS20, IG-MD lifts precision by greater than or equal to 4 percentage points across all nine train-test splits while preserving recall approximately equal to 1.0, demonstrating that a single interpretation-ready model can scale across domains without bespoke tuning.', 'abstract_zh': '可解释的入侵检测系统（IDS）已被认定为关键任务网络中必不可少的工具，然而大多数“XAI”管道仍是在不透明分类器上附加一个近似的解释器，这使得分析师获得的部分和有时具有误导性的洞察。Interpretable Generalization (IG) 机制通过在《IEEE Transactions on Information Forensics and Security》上发表的研究，通过学习一致模式——仅良性或恶意流量特有的特征组合——并将其转化为可完全审计的规则，消除了这一瓶颈。即使仅使用数据的10%进行训练，IG已在NSL-KDD、UNSW-NB15和UKM-IDS20等数据集上实现了卓越的精确率、召回率和AUC值。为在不牺牲透明度的情况下进一步提高精确率，我们引入了多粒度离散化（IG-MD）方法，该方法以高斯为基础，对每个连续特征表示多个粒度。在UKM-IDS20上，IG-MD在所有九个训练测试拆分中将精确率提高了至少4个百分点，同时保持召回率接近1.0，这表明一个单一的可解释模型可以跨越不同领域进行应用而无需定制调优。', 'title_zh': '多粒度离散化以实现精细网络攻击识别的可解释泛化'}
{'arxiv_id': 'arXiv:2507.14219', 'title': 'Artificial Intelligence for Green Hydrogen Yield Prediction and Site Suitability using SHAP-Based Composite Index: Focus on Oman', 'authors': 'Obumneme Zimuzor Nwafor, Mohammed Abdul Majeed Al Hooti', 'link': 'https://arxiv.org/abs/2507.14219', 'abstract': 'As nations seek sustainable alternatives to fossil fuels, green hydrogen has emerged as a promising strategic pathway toward decarbonisation, particularly in solar-rich arid regions. However, identifying optimal locations for hydrogen production requires the integration of complex environmental, atmospheric, and infrastructural factors, often compounded by limited availability of direct hydrogen yield data. This study presents a novel Artificial Intelligence (AI) framework for computing green hydrogen yield and site suitability index using mean absolute SHAP (SHapley Additive exPlanations) values. This framework consists of a multi-stage pipeline of unsupervised multi-variable clustering, supervised machine learning classifier and SHAP algorithm. The pipeline trains on an integrated meteorological, topographic and temporal dataset and the results revealed distinct spatial patterns of suitability and relative influence of the variables. With model predictive accuracy of 98%, the result also showed that water proximity, elevation and seasonal variation are the most influential factors determining green hydrogen site suitability in Oman with mean absolute shap values of 2.470891, 2.376296 and 1.273216 respectively. Given limited or absence of ground-truth yield data in many countries that have green hydrogen prospects and ambitions, this study offers an objective and reproducible alternative to subjective expert weightings, thus allowing the data to speak for itself and potentially discover novel latent groupings without pre-imposed assumptions. This study offers industry stakeholders and policymakers a replicable and scalable tool for green hydrogen infrastructure planning and other decision making in data-scarce regions.', 'abstract_zh': '基于平均绝对SHAP值的人工智能框架计算绿色氢气产量和站点适用性指数：以阿曼为例', 'title_zh': '基于SHAP综合指数的绿色氢气产量预测与场地适宜性评估：以 Oman 为例'}
{'arxiv_id': 'arXiv:2507.14218', 'title': 'Cognitive Castes: Artificial Intelligence, Epistemic Stratification, and the Dissolution of Democratic Discourse', 'authors': 'Craig S Wright', 'link': 'https://arxiv.org/abs/2507.14218', 'abstract': 'Artificial intelligence functions not as an epistemic leveller, but as an accelerant of cognitive stratification, entrenching and formalising informational castes within liberal-democratic societies. Synthesising formal epistemology, political theory, algorithmic architecture, and economic incentive structures, the argument traces how contemporary AI systems selectively amplify the reasoning capacity of individuals equipped with recursive abstraction, symbolic logic, and adversarial interrogation, whilst simultaneously pacifying the cognitively untrained through engagement-optimised interfaces. Fluency replaces rigour, immediacy displaces reflection, and procedural reasoning is eclipsed by reactive suggestion. The result is a technocratic realignment of power: no longer grounded in material capital alone, but in the capacity to navigate, deconstruct, and manipulate systems of epistemic production. Information ceases to be a commons; it becomes the substrate through which consent is manufactured and autonomy subdued. Deliberative democracy collapses not through censorship, but through the erosion of interpretive agency. The proposed response is not technocratic regulation, nor universal access, but the reconstruction of rational autonomy as a civic mandate, codified in education, protected by epistemic rights, and structurally embedded within open cognitive infrastructure.', 'abstract_zh': '人工智能并非知识平等器，而是认知分层的加速器，在自由民主社会中固化和正式化信息阶层。通过形式化认识论、政治理论、算法架构和经济激励结构的综合，论述了当前AI系统如何有选择地放大那些具备递归抽象、符号逻辑和对抗性问询能力的个体的认知能力，同时通过优化交互界面使认知未受训练者变得倦怠。流畅性取代严谨性，即时性取代反思，程序化推理被反应性建议所取代。结果是技术官僚权力的重新调整：不再仅仅基于物质资本，而是基于导航、分解和操控知识生产系统的能力建设。信息不再成为公共资源；而是成为制造同意和压制自主性的载体。议决民主的崩溃并非通过审查，而是通过解构解释权的侵蚀。提出的战略不是技术规制，也不是普遍访问，而是将理性自主权作为公民义务进行重构，通过教育编码、通过知识权利保护，并根植于开放认知基础设施之中。', 'title_zh': '认知阶层：人工智能、知识阶层化与民主话语的瓦解'}
{'arxiv_id': 'arXiv:2507.14211', 'title': 'PRATA: A Framework to Enable Predictive QoS in Vehicular Networks via Artificial Intelligence', 'authors': 'Federico Mason, Tommaso Zugno, Matteo Drago, Marco Giordani, Mate Boban, Michele Zorzi', 'link': 'https://arxiv.org/abs/2507.14211', 'abstract': 'Predictive Quality of Service (PQoS) makes it possible to anticipate QoS changes, e.g., in wireless networks, and trigger appropriate countermeasures to avoid performance degradation. Hence, PQoS is extremely useful for automotive applications such as teleoperated driving, which poses strict constraints in terms of latency and reliability. A promising tool for PQoS is given by Reinforcement Learning (RL), a methodology that enables the design of decision-making strategies for stochastic optimization. In this manuscript, we present PRATA, a new simulation framework to enable PRedictive QoS based on AI for Teleoperated driving Applications. PRATA consists of a modular pipeline that includes (i) an end-to-end protocol stack to simulate the 5G Radio Access Network (RAN), (ii) a tool for generating automotive data, and (iii) an Artificial Intelligence (AI) unit to optimize PQoS decisions. To prove its utility, we use PRATA to design an RL unit, named RAN-AI, to optimize the segmentation level of teleoperated driving data in the event of resource saturation or channel degradation. Hence, we show that the RAN-AI entity efficiently balances the trade-off between QoS and Quality of Experience (QoE) that characterize teleoperated driving applications, almost doubling the system performance compared to baseline approaches. In addition, by varying the learning settings of the RAN-AI entity, we investigate the impact of the state space and the relative cost of acquiring network data that are necessary for the implementation of RL.', 'abstract_zh': 'Predictive Quality of Service (PQoS)基于AI的远程驾驶应用服务质量预测', 'title_zh': 'PRATA：一种基于人工智能实现车辆网络预测QoS的框架'}
{'arxiv_id': 'arXiv:2507.14207', 'title': 'Mitigating Trojanized Prompt Chains in Educational LLM Use Cases: Experimental Findings and Detection Tool Design', 'authors': 'Richard M. Charles, James H. Curry, Richard B. Charles', 'link': 'https://arxiv.org/abs/2507.14207', 'abstract': 'The integration of Large Language Models (LLMs) in K--12 education offers both transformative opportunities and emerging risks. This study explores how students may Trojanize prompts to elicit unsafe or unintended outputs from LLMs, bypassing established content moderation systems with safety guardrils. Through a systematic experiment involving simulated K--12 queries and multi-turn dialogues, we expose key vulnerabilities in GPT-3.5 and GPT-4. This paper presents our experimental design, detailed findings, and a prototype tool, TrojanPromptGuard (TPG), to automatically detect and mitigate Trojanized educational prompts. These insights aim to inform both AI safety researchers and educational technologists on the safe deployment of LLMs for educators.', 'abstract_zh': '大型语言模型（LLMs）在K-12教育中的集成既带来了变革性的机遇也伴随着新兴的风险。本研究探讨了学生如何通过“特洛伊木马”化提示来诱发出安全或未预期的输出，绕过已有的内容审核系统。通过系统实验，涉及模拟的K-12查询和多轮对话，我们揭示了GPT-3.5和GPT-4的关键漏洞。本文介绍了我们的实验设计、详细发现及一个原型工具TrojanPromptGuard (TPG)，用于自动检测和缓解“特洛伊木马”化教育提示。这些见解旨在为AI安全研究人员和教育技术专家提供有关安全部署LLMs的指导。', 'title_zh': '缓解教育场景中 Trojanized 提示链的危害：实验发现与检测工具设计'}
{'arxiv_id': 'arXiv:2507.14206', 'title': 'A Comprehensive Benchmark for Electrocardiogram Time-Series', 'authors': 'Zhijiang Tang, Jiaxin Qi, Yuhua Zheng, Jianqiang Huang', 'link': 'https://arxiv.org/abs/2507.14206', 'abstract': 'Electrocardiogram~(ECG), a key bioelectrical time-series signal, is crucial for assessing cardiac health and diagnosing various diseases. Given its time-series format, ECG data is often incorporated into pre-training datasets for large-scale time-series model training. However, existing studies often overlook its unique characteristics and specialized downstream applications, which differ significantly from other time-series data, leading to an incomplete understanding of its properties. In this paper, we present an in-depth investigation of ECG signals and establish a comprehensive benchmark, which includes (1) categorizing its downstream applications into four distinct evaluation tasks, (2) identifying limitations in traditional evaluation metrics for ECG analysis, and introducing a novel metric; (3) benchmarking state-of-the-art time-series models and proposing a new architecture. Extensive experiments demonstrate that our proposed benchmark is comprehensive and robust. The results validate the effectiveness of the proposed metric and model architecture, which establish a solid foundation for advancing research in ECG signal analysis.', 'abstract_zh': '心电图（ECG），作为关键的生物电信号时间序列数据，对于评估心脏健康和诊断各种疾病至关重要。由于其时间序列格式，ECG数据常被纳入大规模时间序列模型预训练数据集中。然而，现有研究表明，这些研究往往忽视了ECG数据的独特特征和专业下游应用，这些应用与其他时间序列数据差异显著，导致对其属性的理解不完整。在本文中，我们对ECG信号进行了深入研究，并建立了一个综合基准，包括（1）将其下游应用分类为四个不同的评估任务，（2）识别传统ECG分析评价指标的局限性，并引入一个新的评价指标；（3）基准测试最新的时间序列模型并提出一种新的架构。大量的实验表明，我们提出的基准是全面且 robust 的。结果验证了提出的新评价指标和模型架构的有效性，为推进ECG信号分析研究奠定了坚实的基础。', 'title_zh': '全面的心电图时间序列基准'}
{'arxiv_id': 'arXiv:2507.14204', 'title': 'LaCache: Ladder-Shaped KV Caching for Efficient Long-Context Modeling of Large Language Models', 'authors': 'Dachuan Shi, Yonggan Fu, Xiangchi Yuan, Zhongzhi Yu, Haoran You, Sixu Li, Xin Dong, Jan Kautz, Pavlo Molchanov, Yingyan', 'link': 'https://arxiv.org/abs/2507.14204', 'abstract': "Recent advancements in Large Language Models (LLMs) have spurred interest in numerous applications requiring robust long-range capabilities, essential for processing extensive input contexts and continuously generating extended outputs. As sequence lengths increase, the number of Key-Value (KV) pairs in LLMs escalates, creating a significant efficiency bottleneck. In this paper, we propose a new KV cache optimization paradigm called LaCache, a training-free method for efficient and accurate generative inference of LLMs. LaCache enables LLMs to simultaneously address both of the critical challenges in long-range modeling: robust long-range capabilities and continuous generation without running out-of-memory (OOM). Specifically, LaCache integrates two key innovations: (1) a ladder-shaped KV cache pattern that stores KV pairs not only sequentially (left-to-right within each layer) but also across layers (from shallow to deep), providing an extended span for capturing long-range dependencies under a fixed storage budget, thereby boosting long-range capabilities; and (2) an iterative compaction mechanism that progressively compresses older caches, freeing up space for new tokens within a fixed cache size. This token distance-based dynamic compression enables more effective continuous generation under constrained cache budgets. Experiments across various tasks, benchmarks, and LLM models consistently validate LaCache's effectiveness in enhancing LLMs' long-range capabilities. Our code is available at this https URL.", 'abstract_zh': 'Recent advancements in大型语言模型（LLMs）激发了对需要强大长程能力的众多应用的兴趣，这种能力对于处理大量输入上下文和持续生成扩展输出至关重要。随着序列长度的增加，LLMs中的关键值（KV）对数量激增，形成了显著的效率瓶颈。在本文中，我们提出了一种新的KV缓存优化范式——LaCache，这是一种无需训练的、用于高效而准确地生成LLM推理的方法。LaCache使LLMs能够同时应对长程建模中的两个关键挑战：强大的长程能力以及连续生成而不出现内存溢出（OOM）。具体来说，LaCache融合了两项核心技术创新：（1）梯形结构的KV缓存模式，不仅按层内从左到右顺序存储KV对，还跨层从浅到深存储，提供了在固定存储预算下捕获长程依赖的更长跨度，从而提升长程能力；（2）迭代压缩机制，逐步压缩过时的缓存，为固定缓存大小内的新令牌释放空间。基于令牌距离的动态压缩在受限制的缓存预算下实现了更有效的连续生成。在各种任务、基准和LLM模型中进行的实验一致验证了LaCache在提升LLMs长程能力方面的有效性。我们的代码可通过以下链接获取。', 'title_zh': 'LaCache: 级别型键值缓存以提高大型语言模型长上下文建模的效率'}
{'arxiv_id': 'arXiv:2507.14202', 'title': 'PRM-Free Security Alignment of Large Models via Red Teaming and Adversarial Training', 'authors': 'Pengfei Du', 'link': 'https://arxiv.org/abs/2507.14202', 'abstract': 'Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse applications, yet they pose significant security risks that threaten their safe deployment in critical domains. Current security alignment methodologies predominantly rely on Process Reward Models (PRMs) to evaluate intermediate reasoning steps, introducing substantial computational overhead and scalability constraints. This paper presents a novel PRM-free security alignment framework that leverages automated red teaming and adversarial training to achieve robust security guarantees while maintaining computational efficiency. Our approach systematically identifies vulnerabilities through sophisticated attack strategies including genetic algorithm optimization, multi-agent simulation, and advanced prompt mutation techniques. The framework enhances model robustness via targeted adversarial training with curriculum learning and adaptive regularization mechanisms. Comprehensive experimental evaluation across five state-of-the-art LLMs demonstrates that our method achieves superior security alignment performance compared to PRM-based approaches while reducing computational costs by 61\\%. The framework incorporates transparent reporting and continuous audit mechanisms that enable iterative security improvement and regulatory compliance. Our contributions advance the field of efficient LLM security alignment by democratizing access to robust security measures for resource-constrained organizations and providing a scalable foundation for addressing evolving adversarial threats.', 'abstract_zh': '大型语言模型（LLMs）在多种应用中展现了卓越的能力，但它们也带来了重大的安全风险，威胁其在关键领域的安全部署。当前的安全对齐方法主要依赖于过程奖励模型（PRMs）来评估中间推理步骤，这引入了显著的计算开销和可扩展性限制。本文提出了一种新型的无需PRM的安全对齐框架，利用自动化红队测试和对抗训练，以实现稳健的安全保证并保持计算效率。我们的方法通过运用遗传算法优化、多智能体仿真和高级提示突变技术等复杂攻击策略系统性地识别漏洞。框架通过定向对抗训练和自适应正则化机制增强模型的稳健性。在五个最先进的LLMs上的全面实验评估表明，我们的方法在安全对齐性能上优于基于PRM的方法，同时降低了61%的计算成本。该框架集成了透明报告和持续审计机制，可实现迭代性的安全改进和合规性。我们的贡献促进了有效LLM安全对齐领域的发展，为资源受限的组织提供了访问稳健安全措施的途径，并为应对不断演变的对手威胁提供了可扩展的基础。', 'title_zh': '大型模型的红队测试与对抗训练无PRM安全对齐'}
{'arxiv_id': 'arXiv:2507.14201', 'title': 'ExCyTIn-Bench: Evaluating LLM agents on Cyber Threat Investigation', 'authors': 'Yiran Wu, Mauricio Velazco, Andrew Zhao, Manuel Raúl Meléndez Luján, Srisuma Movva, Yogesh K Roy, Quang Nguyen, Roberto Rodriguez, Qingyun Wu, Michael Albada, Julia Kiseleva, Anand Mudgerikar', 'link': 'https://arxiv.org/abs/2507.14201', 'abstract': 'We present ExCyTIn-Bench, the first benchmark to Evaluate an LLM agent x on the task of Cyber Threat Investigation through security questions derived from investigation graphs. Real-world security analysts must sift through a large number of heterogeneous alert signals and security logs, follow multi-hop chains of evidence, and compile an incident report. With the developments of LLMs, building LLM-based agents for automatic thread investigation is a promising direction. To assist the development and evaluation of LLM agents, we construct a dataset from a controlled Azure tenant that covers 8 simulated real-world multi-step attacks, 57 log tables from Microsoft Sentinel and related services, and 589 automatically generated questions. We leverage security logs extracted with expert-crafted detection logic to build threat investigation graphs, and then generate questions with LLMs using paired nodes on the graph, taking the start node as background context and the end node as answer. Anchoring each question to these explicit nodes and edges not only provides automatic, explainable ground truth answers but also makes the pipeline reusable and readily extensible to new logs. This also enables the automatic generation of procedural tasks with verifiable rewards, which can be naturally extended to training agents via reinforcement learning. Our comprehensive experiments with different models confirm the difficulty of the task: with the base setting, the average reward across all evaluated models is 0.249, and the best achieved is 0.368, leaving substantial headroom for future research. Code and data are coming soon!', 'abstract_zh': 'ExCyTIn-Bench：通过安全问题评估LLM代理在网络安全事件调查任务中的性能', 'title_zh': 'ExCyTIn-Bench: 评估大语言模型在网络安全威胁调查中的性能'}
{'arxiv_id': 'arXiv:2507.14200', 'title': 'Open-Source LLMs Collaboration Beats Closed-Source LLMs: A Scalable Multi-Agent System', 'authors': 'Shengji Tang, Jianjian Cao, Weihao Lin, Jiale Hong, Bo Zhang, Shuyue Hu, Lei Bai, Tao Chen, Wanli Ouyang, Peng Ye', 'link': 'https://arxiv.org/abs/2507.14200', 'abstract': 'This paper aims to demonstrate the potential and strengths of open-source collectives. It leads to a promising question: Can we harness multiple open-source LLMs to match or even beat the closed-source LLMs? To answer this, we propose SMACS, a scalable multi-agent collaboration system (MACS) framework with high performance. Specifically, for continuous integration of new LLMs and generalization to diverse questions, we first propose a Retrieval-based Prior Selection (RPS), which assigns a proxy performance score to each LLM to select the Top-k LLMs at the instance level for any given question. Then, we propose an Exploration-Exploitation-Driven Posterior Enhancement (EPE), encouraging the generation of diverse responses through prior dropping and selecting the high-quality response via a hybrid posterior score. Experiments on eight mainstream benchmarks validate the effectiveness of our SMACS: by integrating fifteen open-source LLMs, SMACS outperforms leading closed-source LLMs in 2025, e.g., Claude-3.7-Sonnet (+12.73%), GPT-4.1(+5.36%) and GPT-o3-mini(+5.28%) across multiple tasks. Remarkably, it even exceeds the average of best results of different datasets from both open-source LLMs (+2.86%) and closed-source LLMs (+2.04%), pushing the upper bound of intelligence. Code will be released at this https URL.', 'abstract_zh': '这篇论文旨在展示开源集体的潜力和优势。它引出了一个重要问题：我们能否利用多种开源大语言模型来匹配甚至超越闭源大语言模型？为此，我们提出了SMACS，一种高性能的大规模多智能体协作系统（MACS）框架。具体而言，为实现新大语言模型的持续集成和对多样化问题的一般化，我们首先提出了一种检索基础的先验选择（RPS），为每个大语言模型分配一个代理性能得分，从而在给定问题实例级别上选择Top-k大语言模型。然后，我们提出了探索-利用驱动的后验增强（EPE），通过先验舍弃促进生成多样化回应，并通过混合后验得分选择高质量回应。实验表明，SMACS在八个主流基准上的有效性：通过集成十五种开源大语言模型，SMACS在2025年在多项任务上优于领先闭源大语言模型，如Claude-3.7-Sonnet（+12.73%）、GPT-4.1（+5.36%）和GPT-o3-mini（+5.28%）。值得注意的是，它甚至超越了来自不同数据集的开源和闭源大语言模型最佳结果平均值（+2.86%和+2.04%），将智能上限推向更高。代码将在以下链接发布：https://this.is.URL。', 'title_zh': '开源大语言模型合作胜过闭源大语言模型：一个可扩展的多智能体系统'}
{'arxiv_id': 'arXiv:2507.14198', 'title': 'Retention analysis of edited knowledge after fine-tuning', 'authors': 'Fufang Wen, Shichang Zhang', 'link': 'https://arxiv.org/abs/2507.14198', 'abstract': 'Large language models (LLMs) store vast amounts of knowledge, which often requires updates to correct factual errors, incorporate newly acquired information, or adapt model behavior. Model editing methods have emerged as efficient solutions for such updates, offering localized and precise knowledge modification at significantly lower computational cost than continual training. In parallel, LLMs are frequently fine-tuned for a wide range of downstream tasks. However, the effect of fine-tuning on previously edited knowledge remains poorly understood. In this work, we systematically investigate how different fine-tuning objectives interact with various model editing techniques. Our findings show that edited knowledge is substantially more susceptible to forgetting during fine-tuning than intrinsic knowledge acquired through pre-training. This analysis highlights a key limitation of current editing approaches and suggests that evaluating edit robustness under downstream fine-tuning is critical for their practical deployment. We further find that freezing layers associated with edited content can significantly improve knowledge retention, offering insight into how future editing methods might be made more robust.', 'abstract_zh': '大规模语言模型中的编辑方法在下游微调下的效果研究及其启示', 'title_zh': '微调后编辑知识的保留分析'}
{'arxiv_id': 'arXiv:2507.14196', 'title': 'Explainable Parallel CNN-LSTM Model for Differentiating Ventricular Tachycardia from Supraventricular Tachycardia with Aberrancy in 12-Lead ECGs', 'authors': 'Zahra Teimouri-Jervekani, Fahimeh Nasimi, Mohammadreza Yazdchi, Ghazal MogharehZadeh, Javad Tezerji, Farzan Niknejad Mazandarani, Maryam Mohebbi', 'link': 'https://arxiv.org/abs/2507.14196', 'abstract': 'Background and Objective: Differentiating wide complex tachycardia (WCT) is clinically critical yet challenging due to morphological similarities in electrocardiogram (ECG) signals between life-threatening ventricular tachycardia (VT) and supraventricular tachycardia with aberrancy (SVT-A). Misdiagnosis carries fatal risks. We propose a computationally efficient deep learning solution to improve diagnostic accuracy and provide model interpretability for clinical deployment.\nMethods: A novel lightweight parallel deep architecture is introduced. Each pipeline processes individual ECG leads using two 1D-CNN blocks to extract local features. Feature maps are concatenated across leads, followed by LSTM layers to capture temporal dependencies. Final classification employs fully connected layers. Explainability is achieved via Shapley Additive Explanations (SHAP) for local/global interpretation. The model was evaluated on a 35-subject ECG database using standard performance metrics.\nResults: The model achieved $95.63\\%$ accuracy ($95\\%$ CI: $93.07-98.19\\%$), with sensitivity=$95.10\\%$, specificity=$96.06\\%$, and F1-score=$95.12\\%$. It outperformed state-of-the-art methods in both accuracy and computational efficiency, requiring minimal CNN blocks per pipeline. SHAP analysis demonstrated clinically interpretable feature contributions.\nConclusions: Our end-to-end framework delivers high-precision WCT classification with minimal computational overhead. The integration of SHAP enhances clinical trust by elucidating decision logic, supporting rapid, informed diagnosis. This approach shows significant promise for real-world ECG analysis tools.', 'abstract_zh': '背景与目标：区分宽QRS心动过速（WCT）在临床中至关重要但极具挑战性，因为危及生命的室性心动过速（VT）和房室传导异常的房性心动过速（SVT-A）在心电图（ECG）信号上的形态学特征相似。误诊具有致命风险。我们提出了一种计算效率高的深度学习解决方案，旨在提高诊断准确性并提供临床部署中的模型可解释性。\n\n方法：提出了一种新颖的轻量级并行深度架构。每个管道使用两个1D-CNN块处理单个ECG导联以提取局部特征。特征图在导联间进行拼接，随后是LSTM层以捕获时间依赖性。最终分类采用全连接层。通过Shapley值加性解释（SHAP）实现局部/全局解释性。该模型在包含35个受试者的ECG数据库上使用标准性能指标进行评估。\n\n结果：该模型达到了95.63%的准确率（95% CI：93.07-98.19%），敏感性=95.10%，特异性=96.06%，F1分数=95.12%。在准确性和计算效率方面均超越了最先进的方法，并且每个管道所需的CNN块最少。SHAP分析表明具有临床解释性的特征贡献。\n\n结论：我们的端到端框架实现了高精度的WCT分类，计算开销最小。SHAP的集成增强了临床信任，通过阐明决策逻辑支持快速、知情的诊断。这种方法显示出在实际心电图分析工具中应用的重要前景。', 'title_zh': '带有 aberrancy 的 12 导联心电图中室性心动过速与心上性心动过速区分的可解释并行 CNN-LSTM 模型'}
{'arxiv_id': 'arXiv:2507.14195', 'title': 'UWB Radar-based Heart Rate Monitoring: A Transfer Learning Approach', 'authors': 'Elzbieta Gruzewska, Pooja Rao, Sebastien Baur, Matthew Baugh, Mathias M.J. Bellaiche, Sharanya Srinivas, Octavio Ponce, Matthew Thompson, Pramod Rudrapatna, Michael A. Sanchez, Lawrence Z. Cai, Timothy JA Chico, Robert F. Storey, Emily Maz, Umesh Telang, Shravya Shetty, Mayank Daswani', 'link': 'https://arxiv.org/abs/2507.14195', 'abstract': 'Radar technology presents untapped potential for continuous, contactless, and passive heart rate monitoring via consumer electronics like mobile phones. However the variety of available radar systems and lack of standardization means that a large new paired dataset collection is required for each radar system. This study demonstrates transfer learning between frequency-modulated continuous wave (FMCW) and impulse-radio ultra-wideband (IR-UWB) radar systems, both increasingly integrated into consumer devices. FMCW radar utilizes a continuous chirp, while IR-UWB radar employs short pulses. Our mm-wave FMCW radar operated at 60 GHz with a 5.5 GHz bandwidth (2.7 cm resolution, 3 receiving antennas [Rx]), and our IR-UWB radar at 8 GHz with a 500 MHz bandwidth (30 cm resolution, 2 Rx). Using a novel 2D+1D ResNet architecture we achieved a mean absolute error (MAE) of 0.85 bpm and a mean absolute percentage error (MAPE) of 1.42% for heart rate monitoring with FMCW radar (N=119 participants, an average of 8 hours per participant). This model maintained performance (under 5 MAE/10% MAPE) across various body positions and heart rate ranges, with a 98.9% recall. We then fine-tuned a variant of this model, trained on single-antenna and single-range bin FMCW data, using a small (N=376, avg 6 minutes per participant) IR-UWB dataset. This transfer learning approach yielded a model with MAE 4.1 bpm and MAPE 6.3% (97.5% recall), a 25% MAE reduction over the IR-UWB baseline. This demonstration of transfer learning between radar systems for heart rate monitoring has the potential to accelerate its introduction into existing consumer devices.', 'abstract_zh': '雷达技术为通过移动电话等消费电子设备实现连续、非接触和被动心率监测提供了未充分利用的潜力。然而，可用雷达系统的多样化和缺乏标准化意味着每个雷达系统都需要一个新的配对数据集进行收集。本研究展示了频率调制连续波（FMCW）雷达和脉冲雷达（IR-UWB）系统之间的迁移学习，这两种雷达系统正越来越多地集成到消费设备中。FMCW雷达利用连续调频信号，而IR-UWB雷达使用短脉冲信号。我们使用的毫米波FMCW雷达工作在60 GHz频率，带宽为5.5 GHz（分辨率为2.7 cm，3个接收天线[Rx]），而我们的IR-UWB雷达工作在8 GHz频率，带宽为500 MHz（分辨率为30 cm，2个接收天线[Rx])。通过一种新颖的2D+1D ResNet架构，我们在FMCW雷达的心率监测中达到了平均绝对误差（MAE）0.85 bpm和平均绝对百分比误差（MAPE）1.42%（研究对象119人，平均每人8小时）。该模型在多种体位和心率范围内保持了性能（平均绝对误差低于5，平均绝对百分比误差低于10%，召回率为98.9%）。随后，我们使用较小规模的IR-UWB数据集（研究对象376人，平均每人6分钟），对基于单天线和单距离窗口FMCW数据训练的该模型进行了微调。这种迁移学习方法产生了一个MAE为4.1 bpm和MAPE为6.3%（召回率为97.5%）的模型，相比IR-UWB基线模型，平均绝对误差减少了25%。这一雷达系统之间心率监测迁移学习的演示有潜力加速其在现有消费设备中的引入。', 'title_zh': '基于UWB雷达的心率监测：一种迁移学习方法'}
{'arxiv_id': 'arXiv:2507.14193', 'title': 'A Formal Model of the Economic Impacts of AI Openness Regulation', 'authors': 'Tori Qiu, Benjamin Laufer, Jon Kleinberg, Hoda Heidari', 'link': 'https://arxiv.org/abs/2507.14193', 'abstract': 'Regulatory frameworks, such as the EU AI Act, encourage openness of general-purpose AI models by offering legal exemptions for "open-source" models. Despite this legislative attention on openness, the definition of open-source foundation models remains ambiguous. This paper models the strategic interactions among the creator of a general-purpose model (the generalist) and the entity that fine-tunes the general-purpose model to a specialized domain or task (the specialist), in response to regulatory requirements on model openness. We present a stylized model of the regulator\'s choice of an open-source definition to evaluate which AI openness standards will establish appropriate economic incentives for developers. Our results characterize market equilibria -- specifically, upstream model release decisions and downstream fine-tuning efforts -- under various openness regulations and present a range of effective regulatory penalties and open-source thresholds. Overall, we find the model\'s baseline performance determines when increasing the regulatory penalty vs. the open-source threshold will significantly alter the generalist\'s release strategy. Our model provides a theoretical foundation for AI governance decisions around openness and enables evaluation and refinement of practical open-source policies.', 'abstract_zh': '欧盟AI法案等监管框架通过提供“开源”模型的法律免责来鼓励通用人工智能模型的开放性，尽管立法上对开放性给予了关注，但开源基础模型的定义仍存模糊。本文建模了一般模型创作者（通用主义者）和将其训练成专门领域或任务的实体（专家）之间的战略互动，以回应模型开放性的监管要求。我们呈现了一个监管机构选择开源定义的简化模型，以评估哪些AI开放标准将为开发者建立合适的经济激励。结果显示，在不同开放性监管下的市场均衡点——具体而言，上游模型发布决策和下游训练努力——并呈现了一系列有效的监管惩罚和开源门槛。总体而言，我们发现模型的基本表现决定何时增加监管惩罚而非开源门槛将显著改变通用主义者的发布策略。该模型为基础模型的治理决策提供了一个理论基础，并能评价和细化实际的开源政策。', 'title_zh': 'AI开放性监管的经济影响形式化模型'}
{'arxiv_id': 'arXiv:2507.14189', 'title': 'DeepWriter: A Fact-Grounded Multimodal Writing Assistant Based On Offline Knowledge Base', 'authors': 'Song Mao, Lejun Cheng, Pinlong Cai, Guohang Yan, Ding Wang, Botian Shi', 'link': 'https://arxiv.org/abs/2507.14189', 'abstract': 'Large Language Models (LLMs) have demonstrated remarkable capabilities in various applications. However, their use as writing assistants in specialized domains like finance, medicine, and law is often hampered by a lack of deep domain-specific knowledge and a tendency to hallucinate. Existing solutions, such as Retrieval-Augmented Generation (RAG), can suffer from inconsistency across multiple retrieval steps, while online search-based methods often degrade quality due to unreliable web content. To address these challenges, we introduce DeepWriter, a customizable, multimodal, long-form writing assistant that operates on a curated, offline knowledge base. DeepWriter leverages a novel pipeline that involves task decomposition, outline generation, multimodal retrieval, and section-by-section composition with reflection. By deeply mining information from a structured corpus and incorporating both textual and visual elements, DeepWriter generates coherent, factually grounded, and professional-grade documents. We also propose a hierarchical knowledge representation to enhance retrieval efficiency and accuracy. Our experiments on financial report generation demonstrate that DeepWriter produces high-quality, verifiable articles that surpasses existing baselines in factual accuracy and generated content quality.', 'abstract_zh': '大型语言模型（LLMs）在各种应用中展现了出色的能力。然而，它们在金融、医学和法律等专业领域的写作辅助使用中常常受限于缺乏深入的领域特定知识和易产生虚构现象。现有的解决方案，如检索增强生成（RAG），可能会在多轮检索中产生不一致性，而基于在线搜索的方法往往因为不可靠的网络内容而导致质量下降。为应对这些挑战，我们提出了一种可定制的多模态长文档写作助手DeepWriter，它基于精心策划的离线知识库运作。DeepWriter利用了一个新颖的流水线，包括任务分解、提纲生成、多模态检索和逐节组合并反思。通过深入挖掘结构化语料库中的信息，并结合文本和视觉元素，DeepWriter生成连贯、事实依据充分且专业级的文档。我们还提出了一种层次化的知识表示方法来增强检索效率和精度。我们在财务报告生成的实验中证明，DeepWriter生成了高质量、可验证的文章，在事实准确性和生成内容质量方面超越了现有基线。', 'title_zh': 'DeepWriter：基于离线知识库的事实 grounding 多模态写作助手'}
{'arxiv_id': 'arXiv:2507.14188', 'title': 'From Cell Towers to Satellites: A 2040 Blueprint for Urban-Grade Direct-to-Device Mobile Networks', 'authors': 'Sebastian Barros Elgueta', 'link': 'https://arxiv.org/abs/2507.14188', 'abstract': "In 2023, satellite and mobile networks crossed a historic threshold: standard smartphones, using unmodified 3GPP protocols, connected directly to low Earth orbit (LEO) satellites. This first wave of direct-to-device (D2D) demonstrations validated the physical feasibility of satellite-based mobile access. However, these systems remain fallback-grade--rural-only, bandwidth-limited, and fully dependent on Earth-based mobile cores for identity, session, and policy control. This paper asks a more ambitious question: Can a complete mobile network, including radio access, core functions, traffic routing, and content delivery, operate entirely from orbit? And can it deliver sustained, urban-grade service in the world's densest cities? We present the first end-to-end system architecture for a fully orbital telco, integrating electronically steered phased arrays with 1000-beam capacity, space-based deployment of 5G core functions (UPF, AMF), and inter-satellite laser mesh backhaul. We analyze spectral efficiency, beam capacity, and link budgets under dense urban conditions, accounting for path loss, Doppler, and multipath. Simulations show that rooftop and line-of-sight users can sustain 64-QAM throughput, while street-level access is feasible with relay or assisted beam modes. The paper outlines the remaining constraints, power, thermal dissipation, compute radiation hardening, and regulatory models, and demonstrates that these are engineering bottlenecks, not physical limits. Finally, we propose a staged 15-year roadmap from today's fallback D2D systems to autonomous orbital overlays delivering 50-100 Mbps to handhelds in megacities, with zero reliance on terrestrial infrastructure.", 'abstract_zh': '2023年，卫星和移动网络跨越了历史门槛：未修改的3GPP协议的标准智能手机直接连接到低地球轨道卫星。这一代首批直接到设备(D2D)演示验证了基于卫星的移动接入的物理可行性。然而，这些系统仍然处于备份级别——仅限农村，带宽受限，并完全依赖地面移动核心网络进行身份、会话和策略控制。本文提出了更为雄心勃勃的问题：一个完整的移动网络，包括无线接入、核心功能、流量路由和内容分发，是否可以完全在轨道上运行？并且它是否能够在世界上最密集的城市中提供持续的、可城市水平的服务？我们提出了首个完整的轨道电信端到端系统架构，集成电子扫描相位阵列、1000波束容量、5G核心功能（UPF、AMF）的太空部署以及星间激光网格回传。我们在密集城市条件下分析了频谱效率、波束容量和链路预算，考虑了路径损耗、多普勒效应和多径效应。仿真结果显示，屋顶和视线用户可以维持64QAM吞吐量，而街道级接入可以通过中继或辅助波束模式实现。本文概述了剩余的限制条件，包括功率、热散射、计算辐射防护和监管模型，并表明这些是工程瓶颈，而非物理限制。最后，我们提出了一条从当前的备份D2D系统到15年内实现的自主轨道叠加的阶梯式 roadmap，该叠加可以在 megacities 中为手持设备提供50-100 Mbps的服务，完全不依赖地面基础设施。', 'title_zh': '从基站在到卫星：2040年城市级直接到设备移动网络蓝图'}
{'arxiv_id': 'arXiv:2507.14187', 'title': 'AI-Based Impedance Encoding-Decoding Method for Online Impedance Network Construction of Wind Farms', 'authors': 'Xiaojuan Zhang, Tianyu Jiang, Haoxiang Zong, Chen Zhang, Chendan Li, Marta Molinas', 'link': 'https://arxiv.org/abs/2507.14187', 'abstract': 'The impedance network (IN) model is gaining popularity in the oscillation analysis of wind farms. However, the construction of such an IN model requires impedance curves of each wind turbine under their respective operating conditions, making its online application difficult due to the transmission of numerous high-density impedance curves. To address this issue, this paper proposes an AI-based impedance encoding-decoding method to facilitate the online construction of IN model. First, an impedance encoder is trained to compress impedance curves by setting the number of neurons much smaller than that of frequency points. Then, the compressed data of each turbine are uploaded to the wind farm and an impedance decoder is trained to reconstruct original impedance curves. At last, based on the nodal admittance matrix (NAM) method, the IN model of the wind farm can be obtained. The proposed method is validated via model training and real-time simulations, demonstrating that the encoded impedance vectors enable fast transmission and accurate reconstruction of the original impedance curves.', 'abstract_zh': '基于AI的阻抗编码解码方法在风电场振荡分析中的在线阻抗网络模型构建', 'title_zh': '基于AI的阻抗编码-解码方法用于风电场在线阻抗网络构建'}
{'arxiv_id': 'arXiv:2507.14186', 'title': 'A Disentangled Representation Learning Framework for Low-altitude Network Coverage Prediction', 'authors': 'Xiaojie Li, Zhijie Cai, Nan Qi, Chao Dong, Guangxu Zhu, Haixia Ma, Qihui Wu, Shi Jin', 'link': 'https://arxiv.org/abs/2507.14186', 'abstract': 'The expansion of the low-altitude economy has underscored the significance of Low-Altitude Network Coverage (LANC) prediction for designing aerial corridors. While accurate LANC forecasting hinges on the antenna beam patterns of Base Stations (BSs), these patterns are typically proprietary and not readily accessible. Operational parameters of BSs, which inherently contain beam information, offer an opportunity for data-driven low-altitude coverage prediction. However, collecting extensive low-altitude road test data is cost-prohibitive, often yielding only sparse samples per BS. This scarcity results in two primary challenges: imbalanced feature sampling due to limited variability in high-dimensional operational parameters against the backdrop of substantial changes in low-dimensional sampling locations, and diminished generalizability stemming from insufficient data samples. To overcome these obstacles, we introduce a dual strategy comprising expert knowledge-based feature compression and disentangled representation learning. The former reduces feature space complexity by leveraging communications expertise, while the latter enhances model generalizability through the integration of propagation models and distinct subnetworks that capture and aggregate the semantic representations of latent features. Experimental evaluation confirms the efficacy of our framework, yielding a 7% reduction in error compared to the best baseline algorithm. Real-network validations further attest to its reliability, achieving practical prediction accuracy with MAE errors at the 5dB level.', 'abstract_zh': '低空经济的扩展突显了低空网络覆盖（LANC）预测对于设计空中走廊的重要性。准确的LANC预测依赖于基站（BSs）的天线波束模式，但这些模式通常具有专有性且难以获取。基站的操作参数内含波束信息，为基于数据的低空覆盖预测提供了机会。然而，收集大量的低空道路测试数据成本高昂，往往只能获得每个BS稀疏的样本。这种稀缺性导致了两个主要挑战：由于高维操作参数中的有限变异性与低维采样位置的显著变化之间的对比所导致的特征采样不平衡，以及由于数据样本不足所导致的模型泛化能力减弱。为克服这些障碍，我们提出了一个双策略，包括基于专家知识的特征压缩和解耦表示学习。前者通过利用通信领域的专业知识来减少特征空间的复杂性，后者通过集成传播模型和能够捕捉和聚合潜在特征语义表示的不同子网络来增强模型的泛化能力。实验评估证实了我们框架的有效性，与最佳基线算法相比，错误率减少了7%。实际网络验证进一步验证了其可靠性，MAE错误率达到5dB时实现了实用的预测精度。', 'title_zh': '低空网络覆盖预测的解耦表示学习框架'}
{'arxiv_id': 'arXiv:2507.14184', 'title': 'NeuroHD-RA: Neural-distilled Hyperdimensional Model with Rhythm Alignment', 'authors': 'ZhengXiao He, Jinghao Wen, Huayu Li, Ao Li', 'link': 'https://arxiv.org/abs/2507.14184', 'abstract': 'We present a novel and interpretable framework for electrocardiogram (ECG)-based disease detection that combines hyperdimensional computing (HDC) with learnable neural encoding. Unlike conventional HDC approaches that rely on static, random projections, our method introduces a rhythm-aware and trainable encoding pipeline based on RR intervals, a physiological signal segmentation strategy that aligns with cardiac cycles. The core of our design is a neural-distilled HDC architecture, featuring a learnable RR-block encoder and a BinaryLinear hyperdimensional projection layer, optimized jointly with cross-entropy and proxy-based metric loss. This hybrid framework preserves the symbolic interpretability of HDC while enabling task-adaptive representation learning. Experiments on Apnea-ECG and PTB-XL demonstrate that our model significantly outperforms traditional HDC and classical ML baselines, achieving 73.09\\% precision and an F1 score of 0.626 on Apnea-ECG, with comparable robustness on PTB-XL. Our framework offers an efficient and scalable solution for edge-compatible ECG classification, with strong potential for interpretable and personalized health monitoring.', 'abstract_zh': '基于心电图的疾病检测新型可解释框架：结合可学习神经编码的高维计算', 'title_zh': '神经HD-节奏对齐超维度模型：神经提炼的高维模型与节奏对齐'}
{'arxiv_id': 'arXiv:2507.14182', 'title': 'From Bias to Behavior: Learning Bull-Bear Market Dynamics with Contrastive Modeling', 'authors': 'Xiaotong Luo, Shengda Zhuo, Min Chen, Lichun Li, Ruizhao Lu, Wenqi Fan, Shuqiang Huang, Yin Tang', 'link': 'https://arxiv.org/abs/2507.14182', 'abstract': 'Financial markets exhibit highly dynamic and complex behaviors shaped by both historical price trajectories and exogenous narratives, such as news, policy interpretations, and social media sentiment. The heterogeneity in these data and the diverse insight of investors introduce biases that complicate the modeling of market dynamics. Unlike prior work, this paper explores the potential of bull and bear regimes in investor-driven market dynamics. Through empirical analysis on real-world financial datasets, we uncover a dynamic relationship between bias variation and behavioral adaptation, which enhances trend prediction under evolving market conditions. To model this mechanism, we propose the Bias to Behavior from Bull-Bear Dynamics model (B4), a unified framework that jointly embeds temporal price sequences and external contextual signals into a shared latent space where opposing bull and bear forces naturally emerge, forming the foundation for bias representation. Within this space, an inertial pairing module pairs temporally adjacent samples to preserve momentum, while the dual competition mechanism contrasts bullish and bearish embeddings to capture behavioral divergence. Together, these components allow B4 to model bias-driven asymmetry, behavioral inertia, and market heterogeneity. Experimental results on real-world financial datasets demonstrate that our model not only achieves superior performance in predicting market trends but also provides interpretable insights into the interplay of biases, investor behaviors, and market dynamics.', 'abstract_zh': '投资者驱动的金融市场中多空格局对动态行为的影响及偏差与行为适应性之间的动态关系模型（B4）', 'title_zh': '从偏见到行为：基于对比建模学习 Bulls-Bear 市场动态'}
{'arxiv_id': 'arXiv:2507.14181', 'title': 'Semi-Supervised Federated Learning via Dual Contrastive Learning and Soft Labeling for Intelligent Fault Diagnosis', 'authors': 'Yajiao Dai, Jun Li, Zhen Mei, Yiyang Ni, Shi Jin, Zengxiang Li, Sheng Guo, Wei Xiang', 'link': 'https://arxiv.org/abs/2507.14181', 'abstract': "Intelligent fault diagnosis (IFD) plays a crucial role in ensuring the safe operation of industrial machinery and improving production efficiency. However, traditional supervised deep learning methods require a large amount of training data and labels, which are often located in different clients. Additionally, the cost of data labeling is high, making labels difficult to acquire. Meanwhile, differences in data distribution among clients may also hinder the model's performance. To tackle these challenges, this paper proposes a semi-supervised federated learning framework, SSFL-DCSL, which integrates dual contrastive loss and soft labeling to address data and label scarcity for distributed clients with few labeled samples while safeguarding user privacy. It enables representation learning using unlabeled data on the client side and facilitates joint learning among clients through prototypes, thereby achieving mutual knowledge sharing and preventing local model divergence. Specifically, first, a sample weighting function based on the Laplace distribution is designed to alleviate bias caused by low confidence in pseudo labels during the semi-supervised training process. Second, a dual contrastive loss is introduced to mitigate model divergence caused by different data distributions, comprising local contrastive loss and global contrastive loss. Third, local prototypes are aggregated on the server with weighted averaging and updated with momentum to share knowledge among clients. To evaluate the proposed SSFL-DCSL framework, experiments are conducted on two publicly available datasets and a dataset collected on motors from the factory. In the most challenging task, where only 10\\% of the data are labeled, the proposed SSFL-DCSL can improve accuracy by 1.15% to 7.85% over state-of-the-art methods.", 'abstract_zh': '智能故障诊断(Intelligent Fault Diagnosis, IFD)在确保工业 Machinery 安全运行和提高生产效率方面发挥着重要作用。然而，传统的监督深度学习方法需要大量的训练数据和标签，这些数据和标签通常分布在不同的客户端。此外，数据标签的成本高昂，使得标签难以获取。同时，客户端之间数据分布的差异也可能阻碍模型性能的提升。为应对这些挑战，本文提出了一种半监督联邦学习框架 SSFL-DCSL，该框架结合了双对比损失和软标签，以解决分布式客户端数据和标签稀缺问题，同时保护用户隐私。该方法在客户端利用未标记数据进行表示学习，并通过原型促进客户端之间的联合学习，从而实现知识共享并防止本地模型发散。具体而言，首先，设计了基于拉普拉斯分布的样本加权函数，以缓解半监督训练过程中伪标签低置信度带来的偏差；其次，引入了双对比损失以减轻不同数据分布导致的模型发散，包括局部对比损失和全局对比损失；第三，服务器端通过加权平均聚合局部原型，并借助动量更新来共享知识。为了评估提出的 SSFL-DCSL 框架，我们在两个公开数据集和工厂收集的电机数据集上进行了实验。在数据标记量最少的最具挑战性的任务中，即仅有 10% 的数据被标记，所提出的 SSFL-DCSL 相比现有方法可将准确性提高 1.15% 至 7.85%。', 'title_zh': '半监督联邦学习通过双 Contrastive 学习和软标签化进行智能故障诊断'}
{'arxiv_id': 'arXiv:2507.14180', 'title': 'Digital Twin-Assisted Explainable AI for Robust Beam Prediction in mmWave MIMO Systems', 'authors': 'Nasir Khan, Asmaa Abdallah, Abdulkadir Celik, Ahmed M. Eltawil, Sinem Coleri', 'link': 'https://arxiv.org/abs/2507.14180', 'abstract': 'In line with the AI-native 6G vision, explainability and robustness are crucial for building trust and ensuring reliable performance in millimeter-wave (mmWave) systems. Efficient beam alignment is essential for initial access, but deep learning (DL) solutions face challenges, including high data collection overhead, hardware constraints, lack of explainability, and susceptibility to adversarial attacks. This paper proposes a robust and explainable DL-based beam alignment engine (BAE) for mmWave multiple-input multiple output (MIMO) systems. The BAE uses received signal strength indicator (RSSI) measurements from wide beams to predict the best narrow beam, reducing the overhead of exhaustive beam sweeping. To overcome the challenge of real-world data collection, this work leverages a site-specific digital twin (DT) to generate synthetic channel data closely resembling real-world environments. A model refinement via transfer learning is proposed to fine-tune the pre-trained model residing in the DT with minimal real-world data, effectively bridging mismatches between the digital replica and real-world environments. To reduce beam training overhead and enhance transparency, the framework uses deep Shapley additive explanations (SHAP) to rank input features by importance, prioritizing key spatial directions and minimizing beam sweeping. It also incorporates the Deep k-nearest neighbors (DkNN) algorithm, providing a credibility metric for detecting out-of-distribution inputs and ensuring robust, transparent decision-making. Experimental results show that the proposed framework reduces real-world data needs by 70%, beam training overhead by 62%, and improves outlier detection robustness by up to 8.5x, achieving near-optimal spectral efficiency and transparent decision making compared to traditional softmax based DL models.', 'abstract_zh': '基于AI原生6G愿景的毫米波系统可解释性和鲁棒性化波束对准引擎', 'title_zh': '基于数字孪生的可解释AI在毫米波MIMO系统中鲁棒波束预测'}
{'arxiv_id': 'arXiv:2507.14179', 'title': 'A Sparsity Predicting Approach for Large Language Models via Activation Pattern Clustering', 'authors': 'Nobel Dhar, Bobin Deng, Md Romyull Islam, Xinyue Zhang, Kazi Fahim Ahmad Nasif, Kun Suo', 'link': 'https://arxiv.org/abs/2507.14179', 'abstract': 'Large Language Models (LLMs) exhibit significant activation sparsity, where only a subset of neurons are active for a given input. Although this sparsity presents opportunities to reduce computational cost, efficiently utilizing it requires predicting activation patterns in a scalable manner. However, direct prediction at the neuron level is computationally expensive due to the vast number of neurons in modern LLMs. To enable efficient prediction and utilization of activation sparsity, we propose a clustering-based activation pattern compression framework. Instead of treating each neuron independently, we group similar activation patterns into a small set of representative clusters. Our method achieves up to 79.34% clustering precision, outperforming standard binary clustering approaches while maintaining minimal degradation in perplexity (PPL) scores. With a sufficiently large number of clusters, our approach attains a PPL score as low as 12.49, demonstrating its effectiveness in preserving model quality while reducing computational overhead. By predicting cluster assignments rather than individual neuron states, future models can efficiently infer activation patterns from pre-computed centroids. We detail the clustering algorithm, analyze its effectiveness in capturing meaningful activation structures, and demonstrate its potential to improve sparse computation efficiency. This clustering-based formulation serves as a foundation for future work on activation pattern prediction, paving the way for efficient inference in large-scale language models.', 'abstract_zh': '基于聚类的激活模式压缩框架：在大规模语言模型中高效利用激活稀疏性', 'title_zh': '基于激活模式聚类的大型语言模型稀疏性预测方法'}
{'arxiv_id': 'arXiv:2507.14178', 'title': 'Feature Bank Enhancement for Distance-based Out-of-Distribution Detection', 'authors': 'Yuhang Liu, Yuefei Wu, Bin Shi, Bo Dong', 'link': 'https://arxiv.org/abs/2507.14178', 'abstract': 'Out-of-distribution (OOD) detection is critical to ensuring the reliability of deep learning applications and has attracted significant attention in recent years. A rich body of literature has emerged to develop efficient score functions that assign high scores to in-distribution (ID) samples and low scores to OOD samples, thereby helping distinguish OOD samples. Among these methods, distance-based score functions are widely used because of their efficiency and ease of use. However, deep learning often leads to a biased distribution of data features, and extreme features are inevitable. These extreme features make the distance-based methods tend to assign too low scores to ID samples. This limits the OOD detection capabilities of such methods. To address this issue, we propose a simple yet effective method, Feature Bank Enhancement (FBE), that uses statistical characteristics from dataset to identify and constrain extreme features to the separation boundaries, therapy making the distance between samples inside and outside the distribution farther. We conducted experiments on large-scale ImageNet-1k and CIFAR-10 respectively, and the results show that our method achieves state-of-the-art performance on both benchmark. Additionally, theoretical analysis and supplementary experiments are conducted to provide more insights into our method.', 'abstract_zh': '离分布（OOD）检测对于保证深度学习应用的可靠性至关重要，近年来已引起广泛关注。为了区分离分布样本，大量文献致力于开发高效的分数函数，为在分布（ID）样本分配高分数，为离分布样本分配低分数。在这些方法中，基于距离的分数函数因其效率和易于使用而被广泛采用。然而，深度学习会导致数据特征分布的偏倚，极端特征是不可避免的。这些极端特征会使基于距离的方法倾向于为在分布样本分配过低的分数，从而限制了这类方法的离分布检测能力。为解决这一问题，我们提出了一种简单有效的方法——特征库增强（FBE），该方法利用数据集的统计特性来识别和限制极端特征到分离边界，从而使样本内外部之间的距离更远。我们在大规模的ImageNet-1k和CIFAR-10上进行了实验，结果显示，我们的方法在两个基准上均实现了当前最先进的性能。此外，我们还进行了理论分析和补充实验，以提供更多关于我们方法的见解。', 'title_zh': '基于特征库增强的距离域外检测'}
{'arxiv_id': 'arXiv:2507.14177', 'title': 'Understanding Two-Layer Neural Networks with Smooth Activation Functions', 'authors': 'Changcun Huang', 'link': 'https://arxiv.org/abs/2507.14177', 'abstract': "This paper aims to understand the training solution, which is obtained by the back-propagation algorithm, of two-layer neural networks whose hidden layer is composed of the units with smooth activation functions, including the usual sigmoid type most commonly used before the advent of ReLUs. The mechanism contains four main principles: construction of Taylor series expansions, strict partial order of knots, smooth-spline implementation and smooth-continuity restriction. The universal approximation for arbitrary input dimensionality is proved and experimental verification is given, through which the mystery of ``black box'' of the solution space is largely revealed. The new proofs employed also enrich approximation theory.", 'abstract_zh': '本文旨在理解由反向传播算法获得的、其隐层由光滑激活函数单元组成的两层神经网络的训练解决方案，这些光滑激活函数包括ReLU出现之前的常用sigmoid类型。该机制包含四个主要原则：泰勒级数展开的构造、节点的严格偏序、光滑样条实现和光滑连续性限制。证明了任意输入维度的通用逼近能力，并通过实验验证，大大揭示了解决方案空间的“黑箱”之谜。新提出的证明也丰富了逼近理论。', 'title_zh': '理解具有平滑激活函数的两层神经网络'}
{'arxiv_id': 'arXiv:2507.14175', 'title': 'Latent Space Data Fusion Outperforms Early Fusion in Multimodal Mental Health Digital Phenotyping Data', 'authors': 'Youcef Barkat, Dylan Hamitouche, Deven Parekh, Ivy Guo, David Benrimoh', 'link': 'https://arxiv.org/abs/2507.14175', 'abstract': 'Background: Mental illnesses such as depression and anxiety require improved methods for early detection and personalized intervention. Traditional predictive models often rely on unimodal data or early fusion strategies that fail to capture the complex, multimodal nature of psychiatric data. Advanced integration techniques, such as intermediate (latent space) fusion, may offer better accuracy and clinical utility. Methods: Using data from the BRIGHTEN clinical trial, we evaluated intermediate (latent space) fusion for predicting daily depressive symptoms (PHQ-2 scores). We compared early fusion implemented with a Random Forest (RF) model and intermediate fusion implemented via a Combined Model (CM) using autoencoders and a neural network. The dataset included behavioral (smartphone-based), demographic, and clinical features. Experiments were conducted across multiple temporal splits and data stream combinations. Performance was evaluated using mean squared error (MSE) and coefficient of determination (R2). Results: The CM outperformed both RF and Linear Regression (LR) baselines across all setups, achieving lower MSE (0.4985 vs. 0.5305 with RF) and higher R2 (0.4695 vs. 0.4356). The RF model showed signs of overfitting, with a large gap between training and test performance, while the CM maintained consistent generalization. Performance was best when integrating all data modalities in the CM (in contradistinction to RF), underscoring the value of latent space fusion for capturing non-linear interactions in complex psychiatric datasets. Conclusion: Latent space fusion offers a robust alternative to traditional fusion methods for prediction with multimodal mental health data. Future work should explore model interpretability and individual-level prediction for clinical deployment.', 'abstract_zh': '背景：抑郁症和焦虑等精神疾病需要改进的早期检测和个性化干预方法。传统的预测模型通常依赖于单模数据或早期融合策略，未能捕捉到心理卫生数据的复杂、多模态性质。高级集成技术，如中间（潜在空间）融合，可能会提供更好的准确性和临床效用。方法：使用BRIGHTEN临床试验的数据，我们评估了中间（潜在空间）融合方法在预测每日抑郁症状（PHQ-2评分）方面的应用。我们将早期融合与随机森林（RF）模型进行比较，并通过自编码器和神经网络使用联合模型（CM）实现中间融合。数据集包括行为（基于智能手机的）、人口统计和临床特征。实验在多个时间分割和数据流组合上进行。性能使用均方误差（MSE）和决定系数（R2）进行评估。结果：联合模型（CM）在所有设置中均优于随机森林（RF）和线性回归（LR）基线，MSE更低（0.4985 vs. 0.5305，使用RF），R2更高（0.4695 vs. 0.4356）。随机森林模型显示出过拟合的迹象，训练性能与测试性能之间存在很大差距，而联合模型（CM）保持了一致的泛化能力。当CM整合所有数据模态时，性能最佳，突显了在复杂精神卫生数据集中捕获非线性相互作用的价值。结论：潜在空间融合为使用多模态心理健康数据进行预测提供了稳健的替代方法。未来工作应探索模型可解释性和个体级别的预测以应用于临床部署。', 'title_zh': '潜在空间数据融合在多模态精神健康数字表型数据中的表现优于早期融合'}
{'arxiv_id': 'arXiv:2507.14172', 'title': 'Self-Improving Language Models for Evolutionary Program Synthesis: A Case Study on ARC-AGI', 'authors': 'Julien Pourcel, Cédric Colas, Pierre-Yves Oudeyer', 'link': 'https://arxiv.org/abs/2507.14172', 'abstract': "Many program synthesis tasks prove too challenging for even state-of-the-art language models to solve in single attempts. Search-based evolutionary methods offer a promising alternative by exploring solution spaces iteratively, but their effectiveness remain limited by the fixed capabilities of the underlying generative model.\nWe propose SOAR, a method that learns program synthesis by integrating language models into a self-improving evolutionary loop.\nSOAR alternates between (1) an evolutionary search that uses an LLM to sample and refine candidate solutions, and (2) a hindsight learning phase that converts search attempts into valid problem-solution pairs used to fine-tune the LLM's sampling and refinement capabilities\\, -- \\,enabling increasingly effective search in subsequent iterations.\nOn the challenging ARC-AGI benchmark, SOAR achieves significant performance gains across model scales and iterations, leveraging positive transfer between the sampling and refinement finetuning tasks. These improvements carry over to test-time adaptation, enabling SOAR to solve 52\\% of the public test set. Our code is open-sourced at: this https URL", 'abstract_zh': '一种将语言模型集成到自我改进进化循环中的程序合成方法：SOAR', 'title_zh': '自我提升语言模型在进化程序合成中的应用：一个基于ARC-AGI的研究案例'}
{'arxiv_id': 'arXiv:2507.14171', 'title': 'IPPRO: Importance-based Pruning with PRojective Offset for Magnitude-indifferent Structural Pruning', 'authors': 'Jaeheun Jung, Jaehyuk Lee, Yeajin Lee, Donghun Lee', 'link': 'https://arxiv.org/abs/2507.14171', 'abstract': "With the growth of demand on neural network compression methods, the structured pruning methods including importance-based approach are actively studied. The magnitude importance and many correlated modern importance criteria often limit the capacity of pruning decision, since the filters with larger magnitudes are not likely to be pruned if the smaller one didn't, even if it is redundant. In this paper, we propose a novel pruning strategy to challenge this dominating effect of magnitude and provide fair chance to each filter to be pruned, by placing it on projective space. After that, we observe the gradient descent movement whether the filters move toward the origin or not, to measure how the filter is likely to be pruned. This measurement is used to construct PROscore, a novel importance score for IPPRO, a novel importance-based structured pruning with magnitude-indifference. Our evaluation results shows that the proposed importance criteria using the projective space achieves near-lossless pruning by reducing the performance drop in pruning, with promising performance after the finetuning. Our work debunks the ``size-matters'' myth in pruning and expands the frontier of importance-based pruning both theoretically and empirically.", 'abstract_zh': '基于射影空间的结构剪枝新策略：克服幅度主导效应及其应用', 'title_zh': '基于重要性裁剪的投影偏移.magnitude无关结构裁剪'}
{'arxiv_id': 'arXiv:2507.14170', 'title': 'Catalyst: a Novel Regularizer for Structured Pruning with Auxiliary Extension of Parameter Space', 'authors': 'Jaeheun Jung, Donghun Lee', 'link': 'https://arxiv.org/abs/2507.14170', 'abstract': 'Structured pruning aims to reduce the size and computational cost of deep neural networks by removing entire filters or channels. The traditional regularizers such as L1 or Group Lasso and its variants lead to magnitude-biased pruning decisions, such that the filters with small magnitudes are likely to be pruned. Also, they often entail pruning results with almost zero margin around pruning decision boundary, such that tiny perturbation in a filter magnitude can flip the pruning decision. In this paper, we identify the precise algebraic condition under which pruning operations preserve model performance, and use the condition to construct a novel regularizer defined in an extended parameter space via auxiliary catalyst variables. The proposed Catalyst regularization ensures fair pruning chance for each filters with theoretically provable zero bias to their magnitude and robust pruning behavior achieved by wide-margin bifurcation of magnitudes between the preserved and the pruned filters. The theoretical properties naturally lead to real-world effectiveness, as shown by empirical validations of Catalyst Pruning algorithm. Pruning results on various datasets and models are superior to state-of-the-art filter pruning methods, and at the same time confirm the predicted robust and fair pruning characteristics of Catalyst pruning.', 'abstract_zh': '结构化剪枝旨在通过移除整个滤波器或通道来减少深度神经网络的大小和计算成本。传统的正则化器如L1或组Lasso及其变体会导致幅度偏置的剪枝决策，使得幅度较小的滤波器更有可能被移除。此外，它们往往会导致在剪枝决策边界附近几乎没有零边际的结果，使得滤波器幅度的小幅度变化就能翻转剪枝决策。在本文中，我们识别了剪枝操作保持模型性能的精确代数条件，并利用该条件构造了一个新型正则化器，该正则化器通过辅助催化剂变量在扩展的参数空间中定义。提出的催化剂正则化确保了每个滤波器公平的剪枝机会，并且通过保持和移除滤波器幅度之间的大零边际分叉实现了理论上可证明的幅度无偏的剪枝行为。理论性质自然地导致实际效果，如催化剂剪枝算法的经验验证所示。在各种数据集和模型上的剪枝结果优于最先进的滤波器剪枝方法，并且同时证实了催化剂剪枝预测的稳健和公平的剪枝特性。', 'title_zh': '催化剂：一种新型结构剪枝正则化器及其参数空间扩展辅助方法'}
{'arxiv_id': 'arXiv:2507.14164', 'title': 'A Denoising VAE for Intracardiac Time Series in Ischemic Cardiomyopathy', 'authors': 'Samuel Ruipérez-Campillo, Alain Ryser, Thomas M. Sutter, Ruibin Feng, Prasanth Ganesan, Brototo Deb, Kelly A. Brennan, Maxime Pedron, Albert J. Rogers, Maarten Z.H. Kolk, Fleur V.Y. Tjong, Sanjiv M. Narayan, Julia E. Vogt', 'link': 'https://arxiv.org/abs/2507.14164', 'abstract': 'In the field of cardiac electrophysiology (EP), effectively reducing noise in intra-cardiac signals is crucial for the accurate diagnosis and treatment of arrhythmias and cardiomyopathies. However, traditional noise reduction techniques fall short in addressing the diverse noise patterns from various sources, often non-linear and non-stationary, present in these signals. This work introduces a Variational Autoencoder (VAE) model, aimed at improving the quality of intra-ventricular monophasic action potential (MAP) signal recordings. By constructing representations of clean signals from a dataset of 5706 time series from 42 patients diagnosed with ischemic cardiomyopathy, our approach demonstrates superior denoising performance when compared to conventional filtering methods commonly employed in clinical settings. We assess the effectiveness of our VAE model using various metrics, indicating its superior capability to denoise signals across different noise types, including time-varying non-linear noise frequently found in clinical settings. These results reveal that VAEs can eliminate diverse sources of noise in single beats, outperforming state-of-the-art denoising techniques and potentially improving treatment efficacy in cardiac EP.', 'abstract_zh': '在心脏电解生理学领域，有效地减少心内电信号中的噪声对于心律失常和心肌病的准确诊断和治疗至关重要。然而，传统的去噪技术在处理来自多种来源的复杂非线性、非平稳噪声时往往力不从心。本工作引入了一种变分自编码器（VAE）模型，旨在提高心室内单相动作电位（MAP）信号记录的质量。通过从42名诊断为缺血性心肌病的患者中构建包含5706个时间序列的数据集来重建清洁信号，我们的方法在各类噪声条件下的去噪性能明显优于临床常用的传统滤波方法。我们使用多种指标评估了VAE模型的有效性，结果表明其在不同类型噪声下的去噪能力优于现有技术，特别是对临床环境中常见的时变非线性噪声表现出色。这些结果表明，VAE能够有效消除单个心拍中的多种噪声来源，超越了当前最先进的去噪技术，有可能提高心脏电解生理学中的治疗效果。', 'title_zh': '用于缺血性心肌病内心脏时间序列去噪的VAE模型'}
{'arxiv_id': 'arXiv:2507.14156', 'title': 'All-atom inverse protein folding through discrete flow matching', 'authors': 'Kai Yi, Kiarash Jamali, Sjors H. W. Scheres', 'link': 'https://arxiv.org/abs/2507.14156', 'abstract': 'The recent breakthrough of AlphaFold3 in modeling complex biomolecular interactions, including those between proteins and ligands, nucleotides, or metal ions, creates new opportunities for protein design. In so-called inverse protein folding, the objective is to find a sequence of amino acids that adopts a target protein structure. Many inverse folding methods struggle to predict sequences for complexes that contain non-protein components, and perform poorly with complexes that adopt multiple structural states. To address these challenges, we present ADFLIP (All-atom Discrete FLow matching Inverse Protein folding), a generative model based on discrete flow-matching for designing protein sequences conditioned on all-atom structural contexts. ADFLIP progressively incorporates predicted amino acid side chains as structural context during sequence generation and enables the design of dynamic protein complexes through ensemble sampling across multiple structural states. Furthermore, ADFLIP implements training-free classifier guidance sampling, which allows the incorporation of arbitrary pre-trained models to optimise the designed sequence for desired protein properties. We evaluated the performance of ADFLIP on protein complexes with small-molecule ligands, nucleotides, or metal ions, including dynamic complexes for which structure ensembles were determined by nuclear magnetic resonance (NMR). Our model achieves state-of-the-art performance in single-structure and multi-structure inverse folding tasks, demonstrating excellent potential for all-atom protein design. The code is available at this https URL.', 'abstract_zh': 'AlphaFold3在建模蛋白质与配体、核酸或金属离子等复杂生物分子相互作用方面的最近突破为蛋白质设计创造了新机会。在所谓的逆折叠问题中，目标是找到能折叠成目标蛋白质结构的氨基酸序列。许多逆折叠方法在预测包含非蛋白质成分的复合物序列时遇困难，且对采用多种结构状态的复合物效果不佳。为应对这些挑战，我们提出了ADFLIP（全原子离散流匹配逆折叠），这是一种基于离散流匹配的生成模型，用于在全原子结构上下文中条件氨基酸序列设计。ADFLIP在序列生成过程中逐步整合预测的氨基酸侧链作为结构上下文，并通过跨多个结构状态的集合采样实现动态蛋白质复合物的设计。此外，ADFLIP实现了无需训练的分类器引导采样，允许将任意预训练模型纳入设计序列以优化期望的蛋白质性质。我们评估了ADFLIP在含有小分子配体、核酸或金属离子的蛋白质复合物上的性能，包括由核磁共振（NMR）确定结构集合的动力学复合物。我们的模型在单结构和多结构逆折叠任务中达到了最先进的性能，展示了全原子蛋白质设计的优异潜力。代码可在以下链接访问。', 'title_zh': '通过离散流匹配的全原子逆折纸蛋白'}
{'arxiv_id': 'arXiv:2507.14153', 'title': "Surface EMG Profiling in Parkinson's Disease: Advancing Severity Assessment with GCN-SVM", 'authors': 'Daniel Cieślak, Barbara Szyca, Weronika Bajko, Liwia Florkiewicz, Kinga Grzęda, Mariusz Kaczmarek, Helena Kamieniecka, Hubert Lis, Weronika Matwiejuk, Anna Prus, Michalina Razik, Inga Rozumowicz, Wiktoria Ziembakowska', 'link': 'https://arxiv.org/abs/2507.14153', 'abstract': "Parkinson's disease (PD) poses challenges in diagnosis and monitoring due to its progressive nature and complex symptoms. This study introduces a novel approach utilizing surface electromyography (sEMG) to objectively assess PD severity, focusing on the biceps brachii muscle. Initial analysis of sEMG data from five PD patients and five healthy controls revealed significant neuromuscular differences. A traditional Support Vector Machine (SVM) model achieved up to 83% accuracy, while enhancements with a Graph Convolutional Network-Support Vector Machine (GCN-SVM) model increased accuracy to 92%. Despite the preliminary nature of these results, the study outlines a detailed experimental methodology for future research with larger cohorts to validate these findings and integrate the approach into clinical practice. The proposed approach holds promise for advancing PD severity assessment and improving patient care in Parkinson's disease management.", 'abstract_zh': '帕金森病（PD）由于其渐进性质和复杂症状，在诊断和监测方面具有挑战性。本研究提出了一种新的方法，利用表面肌电图（sEMG）客观评估PD严重程度，重点在于评估肱二头肌。初步分析来自五名PD患者和五名健康对照的sEMG数据揭示了显著的神经肌肉差异。传统的支持向量机（SVM）模型实现了高达83%的准确率，而通过图卷积网络-支持向量机（GCN-SVM）模型的增强将准确率提高到92%。尽管这些结果具有初步性质，但本研究概述了一种详细的经验方法，旨在未来的研究中通过更大的样本量验证这些发现，并将该方法整合到临床实践中。所提出的方法有望推动PD严重程度的评估，并改善帕金森病管理中的患者护理。', 'title_zh': '帕金森病中表面肌电图特征分析：基于GCN-SVM的病情严重程度评估进展'}
{'arxiv_id': 'arXiv:2507.14151', 'title': 'Self-DANA: A Resource-Efficient Channel-Adaptive Self-Supervised Approach for ECG Foundation Models', 'authors': 'Giuliana Monachino, Nicolò La Porta, Beatrice Zanchi, Luigi Fiorillo, Alvise Dei Rossi, Georgiy Farina, Francesca Dalia Faraci', 'link': 'https://arxiv.org/abs/2507.14151', 'abstract': 'Foundation Models (FMs) are large-scale machine learning models trained on extensive, diverse datasets that can be adapted to a wide range of downstream tasks with minimal fine-tuning. In the last two years, interest in FMs has also grown for applications in the cardiological field to analyze the electrocardiogram (ECG) signals. One of the key properties of FMs is their transferability to a wide range of downstream scenarios. With the spread of wearable and portable devices, keen interest in learning from reduced-channel configurations has arisen. However, the adaptation of ECG FMs to downstream scenarios with fewer available channels still has to be properly investigated. In this work, we propose Self-DANA, a novel, easy-to-integrate solution that makes self-supervised architectures adaptable to a reduced number of input channels, ensuring resource efficiency and high performance. We also introduce Random Lead Selection, a novel augmentation technique to pre-train models in a more robust and channel-agnostic way. Our experimental results on five reduced-channel configurations demonstrate that Self-DANA significantly enhances resource efficiency while reaching state-of-the-art performance. It requires up to 69.3% less peak CPU memory, 34.4% less peak GPU memory, about 17% less average epoch CPU time, and about 24% less average epoch GPU time.', 'abstract_zh': '基于自监督的Self-DANA解决方案在减少通道配置下的心电图（ECG）模型适应性研究', 'title_zh': '自适应自我监督的资源高效电生理信号基础模型方法：Self-DANA：一种资源高效且通道自适应的自我监督方法'}
{'arxiv_id': 'arXiv:2507.14141', 'title': 'DIVER-0 : A Fully Channel Equivariant EEG Foundation Model', 'authors': 'Danny Dongyeop Han, Ahhyun Lucy Lee, Taeyang Lee, Yonghyeon Gwon, Sebin Lee, Seongjin Lee, David Keetae Park, Shinjae Yoo, Jiook Cha, Chun Kee Chung', 'link': 'https://arxiv.org/abs/2507.14141', 'abstract': 'Electroencephalography (EEG) is a non-invasive technique widely used in brain-computer interfaces and clinical applications, yet existing EEG foundation models face limitations in modeling spatio-temporal brain dynamics and lack channel permutation equivariance, preventing robust generalization across diverse electrode configurations. To address these challenges, we propose DIVER-0, a novel EEG foundation model that demonstrates how full spatio-temporal attention-rather than segregated spatial or temporal processing-achieves superior performance when properly designed with Rotary Position Embedding (RoPE) for temporal relationships and binary attention biases for channel differentiation. We also introduce Sliding Temporal Conditional Positional Encoding (STCPE), which improves upon existing conditional positional encoding approaches by maintaining both temporal translation equivariance and channel permutation equivariance, enabling robust adaptation to arbitrary electrode configurations unseen during pretraining. Experimental results demonstrate that DIVER-0 achieves competitive performance with only 10% of pretraining data while maintaining consistent results across all channel permutation conditions, validating its effectiveness for cross-dataset generalization and establishing key design principles for handling the inherent heterogeneity of neural recording setups.', 'abstract_zh': 'DIVER-0：一种全时空注意的脑电基础模型及其在多元电极配置下的稳健适应性', 'title_zh': 'DIVER-0：一种全通道等变的脑电基础模型'}
{'arxiv_id': 'arXiv:2507.14140', 'title': 'Geophysics-informed neural network for model-based seismic inversion using surrogate point spread functions', 'authors': 'Marcus Saraiva, Ana Muller, Alexandre Maul', 'link': 'https://arxiv.org/abs/2507.14140', 'abstract': "Model-based seismic inversion is a key technique in reservoir characterization, but traditional methods face significant limitations, such as relying on 1D average stationary wavelets and assuming an unrealistic lateral resolution. To address these challenges, we propose a Geophysics-Informed Neural Network (GINN) that integrates deep learning with seismic modeling. This novel approach employs a Deep Convolutional Neural Network (DCNN) to simultaneously estimate Point Spread Functions (PSFs) and acoustic impedance (IP). PSFs are divided into zero-phase and residual components to ensure geophysical consistency and to capture fine details. We used synthetic data from the SEAM Phase I Earth Model to train the GINN for 100 epochs (approximately 20 minutes) using a 2D UNet architecture. The network's inputs include positional features and a low-frequency impedance (LF-IP) model. A self-supervised loss function combining Mean Squared Error (MSE) and Structural Similarity Index Measure (SSIM) was employed to ensure accurate results. The GINN demonstrated its ability to generate high-resolution IP and realistic PSFs, aligning with expected geological features. Unlike traditional 1D wavelets, the GINN produces PSFs with limited lateral resolution, reducing noise and improving accuracy. Future work will aim to refine the training process and validate the methodology with real seismic data.", 'abstract_zh': '基于地质信息的神经网络在储层描述中的模型驱动地震反演：一种整合深度学习与地震建模的新方法', 'title_zh': '基于代理点扩展函数的地质物理知识嵌入神经网络模型地震反演'}
{'arxiv_id': 'arXiv:2506.23298', 'title': 'Exposing and Mitigating Calibration Biases and Demographic Unfairness in MLLM Few-Shot In-Context Learning for Medical Image Classification', 'authors': 'Xing Shen, Justin Szeto, Mingyang Li, Hengguan Huang, Tal Arbel', 'link': 'https://arxiv.org/abs/2506.23298', 'abstract': "Multimodal large language models (MLLMs) have enormous potential to perform few-shot in-context learning in the context of medical image analysis. However, safe deployment of these models into real-world clinical practice requires an in-depth analysis of the accuracies of their predictions, and their associated calibration errors, particularly across different demographic subgroups. In this work, we present the first investigation into the calibration biases and demographic unfairness of MLLMs' predictions and confidence scores in few-shot in-context learning for medical image classification. We introduce CALIN, an inference-time calibration method designed to mitigate the associated biases. Specifically, CALIN estimates the amount of calibration needed, represented by calibration matrices, using a bi-level procedure: progressing from the population level to the subgroup level prior to inference. It then applies this estimation to calibrate the predicted confidence scores during inference. Experimental results on three medical imaging datasets: PAPILA for fundus image classification, HAM10000 for skin cancer classification, and MIMIC-CXR for chest X-ray classification demonstrate CALIN's effectiveness at ensuring fair confidence calibration in its prediction, while improving its overall prediction accuracies and exhibiting minimum fairness-utility trade-off. Our codebase can be found at this https URL.", 'abstract_zh': '多模态大规模语言模型在医学图像分析中 few-shot 在上下文学习中的校准偏差与人口统计不公平性研究：CALIN 方法及其应用', 'title_zh': '暴露并缓解多模态少样本上下文学习中医学图像分类中的校准偏差和人口统计不公平性'}
{'arxiv_id': 'arXiv:2505.17593', 'title': 'JELAI: Integrating AI and Learning Analytics in Jupyter Notebooks', 'authors': 'Manuel Valle Torre, Thom van der Velden, Marcus Specht, Catharine Oertel', 'link': 'https://arxiv.org/abs/2505.17593', 'abstract': "Generative AI offers potential for educational support, but often lacks pedagogical grounding and awareness of the student's learning context. Furthermore, researching student interactions with these tools within authentic learning environments remains challenging. To address this, we present JELAI, an open-source platform architecture designed to integrate fine-grained Learning Analytics (LA) with Large Language Model (LLM)-based tutoring directly within a Jupyter Notebook environment. JELAI employs a modular, containerized design featuring JupyterLab extensions for telemetry and chat, alongside a central middleware handling LA processing and context-aware LLM prompt enrichment. This architecture enables the capture of integrated code interaction and chat data, facilitating real-time, context-sensitive AI scaffolding and research into student behaviour. We describe the system's design, implementation, and demonstrate its feasibility through system performance benchmarks and two proof-of-concept use cases illustrating its capabilities for logging multi-modal data, analysing help-seeking patterns, and supporting A/B testing of AI configurations. JELAI's primary contribution is its technical framework, providing a flexible tool for researchers and educators to develop, deploy, and study LA-informed AI tutoring within the widely used Jupyter ecosystem.", 'abstract_zh': 'Generative AI在教育支持中的潜力受限于缺乏教学接地和对学生学习环境的认识。此外，在真实学习环境中研究学生与这些工具的交互仍然具有挑战性。为应对这一挑战，我们提出了JELAI，一个开源平台架构，旨在直接在Jupyter Notebook环境中集成精细粒度的学习分析（LA）与基于大型语言模型（LLM）的辅导。JELAI采用模块化容器设计，包含JupyterLab扩展用于遥测和聊天，以及中央中间件处理LA处理和上下文感知的LLM提示增强。该架构能够捕获集成的代码交互和聊天数据，促进实时、上下文感知的人工智能支撑和对学生行为的研究。我们描述了该系统的架构设计、实现，并通过系统性能基准测试和两个概念验证用例展示了其功能，包括多模态数据日志记录、求助模式分析和AI配置的A/B测试。JELAI的主要贡献是其技术框架，提供了一种灵活的工具，供研究人员和教育工作者在广泛使用的Jupyter生态系统中开发、部署和研究基于LA的人工智能辅导。', 'title_zh': 'JELAI: 将AI和学习分析集成到Jupyter Notebook中'}
{'arxiv_id': 'arXiv:2502.15441', 'title': 'On the Effectiveness of Large Language Models in Writing Alloy Formulas', 'authors': 'Yang Hong, Shan Jiang, Yulei Fu, Sarfraz Khurshid', 'link': 'https://arxiv.org/abs/2502.15441', 'abstract': 'Declarative specifications have a vital role to play in developing safe and dependable software systems. Writing specifications correctly, however, remains particularly challenging. This paper presents a controlled experiment on using large language models (LLMs) to write declarative formulas in the well-known language Alloy. Our use of LLMs is three-fold. One, we employ LLMs to write complete Alloy formulas from given natural language descriptions (in English). Two, we employ LLMs to create alternative but equivalent formulas in Alloy with respect to given Alloy formulas. Three, we employ LLMs to complete sketches of Alloy formulas and populate the holes in the sketches by synthesizing Alloy expressions and operators so that the completed formulas accurately represent the desired properties (that are given in natural language). We conduct the experimental evaluation using 11 well-studied subject specifications and employ two popular LLMs, namely ChatGPT and DeepSeek. The experimental results show that the LLMs generally perform well in synthesizing complete Alloy formulas from input properties given in natural language or in Alloy, and are able to enumerate multiple unique solutions. Moreover, the LLMs are also successful at completing given sketches of Alloy formulas with respect to natural language descriptions of desired properties (without requiring test cases). We believe LLMs offer a very exciting advance in our ability to write specifications, and can help make specifications take a pivotal role in software development and enhance our ability to build robust software.', 'abstract_zh': '声明性规范在开发安全可靠的软件系统中起着至关重要的作用。然而，正确编写规范仍然极具挑战性。本文介绍了使用大规模语言模型（LLMs）在知名的Alloy语言中编写声明性公式的受控实验。我们使用LLMs的三个方面包括：一是从给定的自然语言描述（英文）中生成完整的Alloy公式；二是创建与给定Alloy公式等价但不同的公式；三是完成Alloy公式的草图，并通过合成Alloy表达式和操作符填充空白，使完成的公式准确地表示给定的自然语言属性。实验使用了11个精心研究的规范主体，并采用了两种流行的LLMs，即ChatGPT和DeepSeek。实验结果表明，LLMs在从自然语言或Alloy属性给出的输入合成完整的Alloy公式方面表现良好，并且能够列举多个唯一的解决方案。此外，LLMs还能够在不依赖于测试案例的情况下，根据期望属性的自然语言描述完成给定的Alloy公式草图。我们相信LLMs在编写规范方面提供了非常令人兴奋的进展，并且可以帮助使规范在软件开发中发挥关键作用，增强我们构建健壮软件的能力。', 'title_zh': '大型语言模型在撰写合金公式方面的有效性'}
{'arxiv_id': 'arXiv:2411.01789', 'title': 'Generating executable oracles to check conformance of client code to requirements of JDK Javadocs using LLMs', 'authors': 'Shan Jiang, Chenguang Zhu, Sarfraz Khurshid', 'link': 'https://arxiv.org/abs/2411.01789', 'abstract': 'Software testing remains the most widely used methodology for validating quality of code. However, effectiveness of testing critically depends on the quality of test suites used. Test cases in a test suite consist of two fundamental parts: (1) input values for the code under test, and (2) correct checks for the outputs it produces. These checks are commonly written as assertions, and termed test oracles. The last couple of decades have seen much progress in automated test input generation, e.g., using fuzzing and symbolic execution. However, automating test oracles remains a relatively less explored problem area. Indeed, a test oracle by its nature requires knowledge of expected behavior, which may only be known to the developer and may not not exist in a formal language that supports automated reasoning.\nOur focus in this paper is automation of test oracles for clients of widely used Java libraries, e.g., this http URL and this http URL packages. Our key insight is that Javadocs that provide a rich source of information can enable automated generation of test oracles. Javadocs of the core Java libraries are fairly detailed documents that contain natural language descriptions of not only how the libraries behave but also how the clients must (not) use them. We use large language models as an enabling technology to embody our insight into a framework for test oracle automation, and evaluate it experimentally. Our experiments demonstrate that LLMs can generate oracles for checking normal and exceptional behaviors from Javadocs, with 98.8% of these oracles being compilable and 96.4% accurately reflecting intended properties. Even for the few incorrect oracles, errors are minor and can be easily corrected with the help of additional comment information generated by the LLMs.', 'abstract_zh': '软件测试仍然是验证代码质量最常用的方法。然而，测试的有效性在很大程度上取决于所使用测试套件的质量。测试套件中的测试用例包含两大部分：（1）被测试代码的输入值，以及（2）其输出的正确检查。这些检查通常以断言的形式编写，并被称为测试或acles。近年来，在自动化测试输入生成方面取得了显著进展，例如使用模糊测试和符号执行。然而，自动化测试或acles仍然是相对较新的研究领域。事实上，测试或acles本质上需要对预期行为的了解，这种了解可能仅存在于开发者手中，并且可能并不会以支持自动推理的形式存在。\n\n本文重点关注广泛使用的Java库的测试或acles的自动化，例如这些http链接和这些http链接。我们的关键见解是，丰富的文档源（如Javadocs）可以支持自动生成测试或acles。核心Java库的Javadocs是相当详细的技术文档，不仅描述了库的行为，还描述了客户端如何（不）使用它们。我们利用大规模语言模型作为使能技术，将这一见解体现在测试或acles自动化的框架中，并对其进行实验评估。实验结果表明，LLMs可以从Javadocs中生成检查正常和异常行为的或acles，其中98.8%的或acles可以编译，96.4%准确反映了期望的属性。即使对于少数错误的或acles，错误也很小，可以通过LLMs生成的附加注释信息容易地纠正。', 'title_zh': '使用大型语言模型生成可执行的或acles以检查客户端代码与JDK Javadoc要求的符合性'}
