{'arxiv_id': 'arXiv:2507.15716', 'title': 'DiffPF: Differentiable Particle Filtering with Generative Sampling via Conditional Diffusion Models', 'authors': 'Ziyu Wan, Lin Zhao', 'link': 'https://arxiv.org/abs/2507.15716', 'abstract': 'This paper proposes DiffPF, a differentiable particle filter that leverages diffusion models for state estimation in dynamic systems. Unlike conventional differentiable particle filters, which require importance weighting and typically rely on predefined or low-capacity proposal distributions. DiffPF learns a flexible posterior sampler by conditioning a diffusion model on predicted particles and the current observation. This enables accurate, equally-weighted sampling from complex, high-dimensional, and multimodal filtering distributions. We evaluate DiffPF across a range of scenarios, including both unimodal and highly multimodal distributions, and test it on simulated as well as real-world tasks, where it consistently outperforms existing filtering baselines. In particular, DiffPF achieves an 82.8% improvement in estimation accuracy on a highly multimodal global localization benchmark, and a 26% improvement on the real-world KITTI visual odometry benchmark, compared to state-of-the-art differentiable filters. To the best of our knowledge, DiffPF is the first method to integrate conditional diffusion models into particle filtering, enabling high-quality posterior sampling that produces more informative particles and significantly improves state estimation.', 'abstract_zh': 'DiffPF：一种用于动态系统状态估计的可微分粒子滤波器', 'title_zh': 'DiffPF：基于条件扩散模型的可微分粒子滤波与生成采样'}
{'arxiv_id': 'arXiv:2507.15499', 'title': 'CLEVER: Stream-based Active Learning for Robust Semantic Perception from Human Instructions', 'authors': 'Jongseok Lee, Timo Birr, Rudolph Triebel, Tamim Asfour', 'link': 'https://arxiv.org/abs/2507.15499', 'abstract': "We propose CLEVER, an active learning system for robust semantic perception with Deep Neural Networks (DNNs). For data arriving in streams, our system seeks human support when encountering failures and adapts DNNs online based on human instructions. In this way, CLEVER can eventually accomplish the given semantic perception tasks. Our main contribution is the design of a system that meets several desiderata of realizing the aforementioned capabilities. The key enabler herein is our Bayesian formulation that encodes domain knowledge through priors. Empirically, we not only motivate CLEVER's design but further demonstrate its capabilities with a user validation study as well as experiments on humanoid and deformable objects. To our knowledge, we are the first to realize stream-based active learning on a real robot, providing evidence that the robustness of the DNN-based semantic perception can be improved in practice. The project website can be accessed at this https URL.", 'abstract_zh': '我们提出了一种基于深度神经网络的鲁棒语义感知的主动学习系统CLEVER', 'title_zh': 'CLEVER：基于流的数据主动学习以从人类指令中实现鲁棒语义感知'}
{'arxiv_id': 'arXiv:2507.15155', 'title': 'Learning-Based Modeling of a Magnetically Steerable Soft Suction Device for Endoscopic Endonasal Interventions', 'authors': 'Majid Roshanfar, Alex Zhang, Changyan He, Amir Hooshiar, Dale J. Podolsky, Thomas Looi, Eric Diller', 'link': 'https://arxiv.org/abs/2507.15155', 'abstract': "This letter introduces a novel learning-based modeling framework for a magnetically steerable soft suction device designed for endoscopic endonasal brain tumor resection. The device is miniaturized (4 mm outer diameter, 2 mm inner diameter, 40 mm length), 3D printed using biocompatible SIL 30 material, and integrates embedded Fiber Bragg Grating (FBG) sensors for real-time shape feedback. Shape reconstruction is represented using four Bezier control points, enabling a compact and smooth model of the device's deformation. A data-driven model was trained on 5,097 experimental samples covering a range of magnetic field magnitudes (0-14 mT), actuation frequencies (0.2-1.0 Hz), and vertical tip distances (90-100 mm), using both Neural Network (NN) and Random Forest (RF) architectures. The RF model outperformed the NN across all metrics, achieving a mean root mean square error of 0.087 mm in control point prediction and a mean shape reconstruction error of 0.064 mm. Feature importance analysis further revealed that magnetic field components predominantly influence distal control points, while frequency and distance affect the base configuration. This learning-based approach effectively models the complex nonlinear behavior of hyperelastic soft robots under magnetic actuation without relying on simplified physical assumptions. By enabling sub-millimeter shape prediction accuracy and real-time inference, this work represents an advancement toward the intelligent control of magnetically actuated soft robotic tools in minimally invasive neurosurgery.", 'abstract_zh': '基于学习的磁控可弯曲软 suction 设备建模框架：用于内镜经鼻脑肿瘤切除', 'title_zh': '基于学习的可磁导航软吸引装置的建模研究：内鼻外科干预应用'}
{'arxiv_id': 'arXiv:2507.15022', 'title': 'CPED-NCBFs: A Conformal Prediction for Expert Demonstration-based Neural Control Barrier Functions', 'authors': 'Sumeadh MS, Kevin Dsouza, Ravi Prakash', 'link': 'https://arxiv.org/abs/2507.15022', 'abstract': 'Among the promising approaches to enforce safety in control systems, learning Control Barrier Functions (CBFs) from expert demonstrations has emerged as an effective strategy. However, a critical challenge remains: verifying that the learned CBFs truly enforce safety across the entire state space. This is especially difficult when CBF is represented using neural networks (NCBFs). Several existing verification techniques attempt to address this problem including SMT-based solvers, mixed-integer programming (MIP), and interval or bound-propagation methods but these approaches often introduce loose, conservative bounds. To overcome these limitations, in this work we use CPED-NCBFs a split-conformal prediction based verification strategy to verify the learned NCBF from the expert demonstrations. We further validate our method on point mass systems and unicycle models to demonstrate the effectiveness of the proposed theory.', 'abstract_zh': '基于专家演示学习控制 barrier 函数的安全验证：使用 CPED-NCBFs 策略验证神经网络控制 barrier 函数的有效性', 'title_zh': '基于专家示范的神经控制障碍函数的 conformal 预测'}
{'arxiv_id': 'arXiv:2507.14914', 'title': 'One Step Beyond: Feedthrough & Placement-Aware Rectilinear Floorplanner', 'authors': 'Zhexuan Xu, Jie Wang, Siyuan Xu, Zijie Geng, Mingxuan Yuan, Feng Wu', 'link': 'https://arxiv.org/abs/2507.14914', 'abstract': "Floorplanning determines the shapes and locations of modules on a chip canvas and plays a critical role in optimizing the chip's Power, Performance, and Area (PPA) metrics. However, existing floorplanning approaches often fail to integrate with subsequent physical design stages, leading to suboptimal in-module component placement and excessive inter-module feedthrough. To tackle this challenge, we propose Flora, a three-stage feedthrough and placement aware rectilinear floorplanner. In the first stage, Flora employs wiremask and position mask techniques to achieve coarse-grained optimization of HPWL and feedthrough. In the second stage, under the constraint of a fixed outline, Flora achieves a zero-whitespace layout by locally resizing module shapes, thereby performing fine-grained optimization of feedthrough and improving component placement. In the third stage, Flora utilizes a fast tree search-based method to efficiently place components-including macros and standard cells-within each module, subsequently adjusting module boundaries based on the placement results to enable cross-stage optimization. Experimental results show that Flora outperforms recent state-of-the-art floorplanning approaches, achieving an average reduction of 6% in HPWL, 5.16% in FTpin, 29.15% in FTmod, and a 14% improvement in component placement performance.", 'abstract_zh': 'Flora：基于馈通和布线感知的三阶段直方图地板规划器', 'title_zh': '一步超越：反馈通路与布局感知的直角布局规划'}
{'arxiv_id': 'arXiv:2507.14455', 'title': 'Koopman Operator Based Time-Delay Embeddings and State History Augmented LQR for Periodic Hybrid Systems: Bouncing Pendulum and Bipedal Walking', 'authors': 'Chun-Ming Yang, Pranav A. Bhounsule', 'link': 'https://arxiv.org/abs/2507.14455', 'abstract': 'Time-delay embedding is a technique that uses snapshots of state history over time to build a linear state space model of a nonlinear smooth system. We demonstrate that periodic non-smooth or hybrid system can also be modeled as a linear state space system using this approach as long as its behavior is consistent in modes and timings. We extended time-delay embeddings to generate a linear model of two periodic hybrid systems: the bouncing pendulum and the simplest walker with control inputs. This leads to a novel state history augmented linear quadratic regulator (LQR) which uses current and past state history for feedback control.', 'abstract_zh': '时间延迟嵌入是一种技术，它利用时间上的状态历史截面来构建非线性光滑系统的线性状态空间模型。我们演示了只要其模式和时间行为一致，即使是周期性非光滑或混合系统也可以通过这种方法被建模为线性状态空间系统。我们扩展了时间延迟嵌入技术，以生成双周期混合系统的线性模型：摆锤和带有控制输入的最简单步行者。这导致了一种新的状态历史增强线性二次调节器（LQR），它使用当前和过去的状态历史来实现反馈控制。', 'title_zh': '基于柯普曼算子的时间延迟嵌入与时变历史状态增强的LQR方法：摆动摆和双足步行周期混合系统'}
{'arxiv_id': 'arXiv:2507.14249', 'title': 'Real-Time Communication-Aware Ride-Sharing Route Planning for Urban Air Mobility: A Multi-Source Hybrid Attention Reinforcement Learning Approach', 'authors': 'Yuejiao Xie, Maonan Wang, Di Zhou, Man-On Pun, Zhu Han', 'link': 'https://arxiv.org/abs/2507.14249', 'abstract': 'Urban Air Mobility (UAM) systems are rapidly emerging as promising solutions to alleviate urban congestion, with path planning becoming a key focus area. Unlike ground transportation, UAM trajectory planning has to prioritize communication quality for accurate location tracking in constantly changing environments to ensure safety. Meanwhile, a UAM system, serving as an air taxi, requires adaptive planning to respond to real-time passenger requests, especially in ride-sharing scenarios where passenger demands are unpredictable and dynamic. However, conventional trajectory planning strategies based on predefined routes lack the flexibility to meet varied passenger ride demands. To address these challenges, this work first proposes constructing a radio map to evaluate the communication quality of urban airspace. Building on this, we introduce a novel Multi-Source Hybrid Attention Reinforcement Learning (MSHA-RL) framework for the challenge of effectively focusing on passengers and UAM locations, which arises from the significant dimensional disparity between the representations. This model first generates the alignment among diverse data sources with large gap dimensions before employing hybrid attention to balance global and local insights, thereby facilitating responsive, real-time path planning. Extensive experimental results demonstrate that the approach enables communication-compliant trajectory planning, reducing travel time and enhancing operational efficiency while prioritizing passenger safety.', 'abstract_zh': '城市空中 mobility (UAM) 系统正rapidly emerging as 有前途的缓解urban congestion的解决方案，路径规划成为关键研究领域。与地面交通不同，UAM 轨迹规划需要优先考虑通信质量，以在不断变化的环境中实现精确的位置跟踪，确保安全。与此同时，作为空中出租车的UAM系统，需要适应性规划以响应实时乘客请求，特别是在拼车场景中，乘客需求是不可预测和动态变化的。然而，基于预定义路线的传统轨迹规划策略缺乏灵活性，无法满足多样化乘客出行需求。为解决这些挑战，本工作首先提出构建无线电图以评估城市空域的通信质量。在此基础上，我们引入了一种新颖的多源混合注意力强化学习（MSHA-RL）框架，以有效关注乘客和UAM位置，这源自于表示之间显著的维度差距。该模型首先生成不同数据源之间的对齐关系，然后采用混合注意力机制平衡全局和局部洞察，从而促进响应性、实时路径规划。广泛实验证明，该方法实现了通信合规的轨迹规划，减少了旅行时间，提升了运营效率，并优先考虑乘客安全。', 'title_zh': '基于实时通信的城市场景空中出行拼车路线规划：一种多源混合注意力强化学习方法'}
{'arxiv_id': 'arXiv:2507.15036', 'title': 'EBA-AI: Ethics-Guided Bias-Aware AI for Efficient Underwater Image Enhancement and Coral Reef Monitoring', 'authors': 'Lyes Saad Saoud, Irfan Hussain', 'link': 'https://arxiv.org/abs/2507.15036', 'abstract': "Underwater image enhancement is vital for marine conservation, particularly coral reef monitoring. However, AI-based enhancement models often face dataset bias, high computational costs, and lack of transparency, leading to potential misinterpretations. This paper introduces EBA-AI, an ethics-guided bias-aware AI framework to address these challenges. EBA-AI leverages CLIP embeddings to detect and mitigate dataset bias, ensuring balanced representation across varied underwater environments. It also integrates adaptive processing to optimize energy efficiency, significantly reducing GPU usage while maintaining competitive enhancement quality. Experiments on LSUI400, Oceanex, and UIEB100 show that while PSNR drops by a controlled 1.0 dB, computational savings enable real-time feasibility for large-scale marine monitoring. Additionally, uncertainty estimation and explainability techniques enhance trust in AI-driven environmental decisions. Comparisons with CycleGAN, FunIEGAN, RAUNENet, WaterNet, UGAN, PUGAN, and UTUIE validate EBA-AI's effectiveness in balancing efficiency, fairness, and interpretability in underwater image processing. By addressing key limitations of AI-driven enhancement, this work contributes to sustainable, bias-aware, and computationally efficient marine conservation efforts. For interactive visualizations, animations, source code, and access to the preprint, visit: this https URL", 'abstract_zh': '基于伦理引导的偏见感知AI框架EBA-AI在水下图像增强中的应用：平衡效率、公平性和可解释性', 'title_zh': 'EBA-AI: 道德引导的偏置意识人工智能在水下图像增强与珊瑚礁监测中的高效应用'}
{'arxiv_id': 'arXiv:2507.14190', 'title': 'Traffic Signal Phase and Timing Estimation with Large-Scale Floating Car Data', 'authors': 'Mingcheng Liao, Zebang Feng, Miao Fan, Shengtong Xu, Haoyi Xiong', 'link': 'https://arxiv.org/abs/2507.14190', 'abstract': "Effective modern transportation systems depend critically on accurate Signal Phase and Timing (SPaT) estimation. However, acquiring ground-truth SPaT information faces significant hurdles due to communication challenges with transportation departments and signal installers. As a result, Floating Car Data (FCD) has become the primary source for large-scale SPaT analyses. Current FCD approaches often simplify the problem by assuming fixed schedules and basic intersection designs for specific times and locations. These methods fail to account for periodic signal changes, diverse intersection structures, and the inherent limitations of real-world data, thus lacking a comprehensive framework that is universally applicable. Addressing this limitation, we propose an industrial-grade FCD analysis suite that manages the entire process, from initial data preprocessing to final SPaT estimation. Our approach estimates signal phases, identifies time-of-day (TOD) periods, and determines the durations of red and green lights. The framework's notable stability and robustness across diverse conditions, regardless of road geometry, is a key feature. Furthermore, we provide a cleaned, de-identified FCD dataset and supporting parameters to facilitate future research. Currently operational within our navigation platform, the system analyses over 15 million FCD records daily, supporting over two million traffic signals in mainland China, with more than 75\\% of estimations demonstrating less than five seconds of error.", 'abstract_zh': '有效的现代交通系统高度依赖准确的信号相位和定时（SPaT）估计。然而，由于与交通管理部门和信号安装者通信的挑战，获取地面真实SPaT信息面临重大障碍。因此，浮动车数据（FCD）已成为大规模SPaT分析的主要来源。当前的FCD方法往往通过假设固定的时间表和简单的交叉口设计来简化问题，这些方法未能考虑到周期性的信号变化、多样的交叉口结构以及现实世界数据的固有限制，缺乏一个普遍适用的全面框架。为了克服这一限制，我们提出了一种工业级的FCD分析套件，从初始数据预处理到最终的SPaT估计，管理整个过程。我们的方法估算信号相位、识别时间周期（TOD）并确定红绿灯持续时间。框架的显著稳定性和在各种条件下表现出的鲁棒性，即使在不同的道路几何条件下也是如此，是一个关键特征。此外，我们还提供了一个清理和脱识别后的FCD数据集及支持参数，以促进未来的研究。目前该系统已在我们的导航平台中运行，每天分析超过1500万条FCD记录，支持中国大陆超过200万个交通信号，超过75%的估计误差少于五秒。', 'title_zh': '大规模浮动车数据驱动的交通信号相位和定时估计'}
{'arxiv_id': 'arXiv:2507.15844', 'title': 'Hierarchical Budget Policy Optimization for Adaptive Reasoning', 'authors': 'Shangke Lyu, Linjuan Wu, Yuchen Yan, Xingyu Wu, Hao Li, Yongliang Shen, Peisheng Jiang, Weiming Lu, Jun Xiao, Yueting Zhuang', 'link': 'https://arxiv.org/abs/2507.15844', 'abstract': 'Large reasoning models achieve remarkable performance through extensive chain-of-thought generation, yet exhibit significant computational inefficiency by applying uniform reasoning strategies regardless of problem complexity. We present Hierarchical Budget Policy Optimization (HBPO), a reinforcement learning framework that enables models to learn problem-specific reasoning depths without sacrificing capability. HBPO addresses the fundamental challenge of exploration space collapse in efficiency-oriented training, where penalties on long output length systematically bias models away from necessary long reasoning paths. Through hierarchical budget exploration, our approach partitions rollout samples into multiple subgroups with distinct token budgets, aiming to enable efficient resource allocation while preventing degradation of capability. We introduce differentiated reward mechanisms that create budget-aware incentives aligned with the complexity of the problem, allowing models to discover natural correspondences between task requirements and computational effort. Extensive experiments demonstrate that HBPO reduces average token usage by up to 60.6% while improving accuracy by 3.14% across four reasoning benchmarks. Unlike existing methods that impose external constraints or rely on discrete mode selection, HBPO exhibits emergent adaptive behavior where models automatically adjust reasoning depth based on problem complexity. Our results suggest that reasoning efficiency and capability are not inherently conflicting, and can be simultaneously optimized through appropriately structured hierarchical training that preserves exploration diversity.', 'abstract_zh': '分级预算策略优化（HBPO）：提高推理模型的推理效率与能力', 'title_zh': '层次预算策略优化以实现自适应推理'}
{'arxiv_id': 'arXiv:2507.15842', 'title': 'Identifying Conditional Causal Effects in MPDAGs', 'authors': 'Sara LaPlante, Emilija Perković', 'link': 'https://arxiv.org/abs/2507.15842', 'abstract': 'We consider identifying a conditional causal effect when a graph is known up to a maximally oriented partially directed acyclic graph (MPDAG). An MPDAG represents an equivalence class of graphs that is restricted by background knowledge and where all variables in the causal model are observed. We provide three results that address identification in this setting: an identification formula when the conditioning set is unaffected by treatment, a generalization of the well-known do calculus to the MPDAG setting, and an algorithm that is complete for identifying these conditional effects.', 'abstract_zh': '当我们知道图是最大化有向部分导向无环图（MPDAG）时，识别条件因果效应的研究', 'title_zh': 'MPDAG中条件因果效应的识别'}
{'arxiv_id': 'arXiv:2507.15796', 'title': "Challenges of Trustworthy Federated Learning: What's Done, Current Trends and Remaining Work", 'authors': 'Nuria Rodríguez-Barroso, Mario García-Márquez, M. Victoria Luzón, Francisco Herrera', 'link': 'https://arxiv.org/abs/2507.15796', 'abstract': 'In recent years, the development of Trustworthy Artificial Intelligence (TAI) has emerged as a critical objective in the deployment of AI systems across sensitive and high-risk domains. TAI frameworks articulate a comprehensive set of ethical, legal, and technical requirements to ensure that AI technologies are aligned with human values, rights, and societal expectations. Among the various AI paradigms, Federated Learning (FL) presents a promising solution to pressing privacy concerns. However, aligning FL with the rest of the requirements of TAI presents a series of challenges, most of which arise from its inherently distributed nature. In this work, we adopt the requirements TAI as a guiding structure to systematically analyze the challenges of adapting FL to TAI. Specifically, we classify and examine the key obstacles to aligning FL with TAI, providing a detailed exploration of what has been done, the trends, and the remaining work within each of the identified challenges.', 'abstract_zh': '近年来，可信赖人工智能（TAI）的发展已成为在敏感和高风险领域部署AI系统的关键目标。TAI框架阐述了一套全面的伦理、法律和技术要求，以确保AI技术与人类价值观、权利和社会期望相一致。在各种AI范式中，联邦学习（FL）为解决紧迫的隐私问题提供了一种有前景的解决方案。然而，将FL与TAI的其他要求对齐带来了系列挑战，大多数挑战源于其本体分布式性质。在本文中，我们采用TAI的要求作为指导框架，系统地分析将FL适应TAI所面临的挑战。具体来说，我们对将FL与TAI对齐的关键障碍进行了分类和评估，详细探讨了每个识别挑战下的已做工作、趋势和遗留问题。', 'title_zh': '可信赖联邦学习的挑战：已做工作、当前趋势及剩余工作'}
{'arxiv_id': 'arXiv:2507.15758', 'title': 'LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy Optimization', 'authors': 'Xingyu Wu, Yuchen Yan, Shangke Lyu, Linjuan Wu, Yiwen Qiu, Yongliang Shen, Weiming Lu, Jian Shao, Jun Xiao, Yueting Zhuang', 'link': 'https://arxiv.org/abs/2507.15758', 'abstract': "Large reasoning models have achieved remarkable performance through extended chain-of-thought sequences, yet this computational freedom leads to excessive token generation even for simple problems. We present Length-Adaptive Policy Optimization (LAPO), a novel framework that transforms reasoning length control from an external constraint into an intrinsic model capability. Unlike existing approaches that impose rigid limits or rely on post-hoc interventions, LAPO enables models to internalize an understanding of appropriate reasoning depth through a two-stage reinforcement learning process. In the first stage, models learn natural reasoning patterns by discovering the statistical distribution of successful solution lengths. The second stage leverages these patterns as meta-cognitive guidance, embedding them directly within the model's reasoning context to ensure inference-time flexibility. Experiments on mathematical reasoning benchmarks demonstrate that LAPO reduces token usage by up to 40.9\\% while improving accuracy by 2.3\\%. Our analysis reveals that models trained with LAPO develop emergent abilities to allocate computational resources based on problem complexity, achieving efficient reasoning without sacrificing quality.", 'abstract_zh': 'Length-Adaptive Policy Optimization: Transforming Reasoning Length Control into an Intrinsic Model Capability', 'title_zh': 'LAPO：基于长度自适应策略优化的推理效率内化'}
{'arxiv_id': 'arXiv:2507.15743', 'title': 'Towards physician-centered oversight of conversational diagnostic AI', 'authors': 'Elahe Vedadi, David Barrett, Natalie Harris, Ellery Wulczyn, Shashir Reddy, Roma Ruparel, Mike Schaekermann, Tim Strother, Ryutaro Tanno, Yash Sharma, Jihyeon Lee, Cían Hughes, Dylan Slack, Anil Palepu, Jan Freyberg, Khaled Saab, Valentin Liévin, Wei-Hung Weng, Tao Tu, Yun Liu, Nenad Tomasev, Kavita Kulkarni, S. Sara Mahdavi, Kelvin Guu, Joëlle Barral, Dale R. Webster, James Manyika, Avinatan Hassidim, Katherine Chou, Yossi Matias, Pushmeet Kohli, Adam Rodman, Vivek Natarajan, Alan Karthikesalingam, David Stutz', 'link': 'https://arxiv.org/abs/2507.15743', 'abstract': "Recent work has demonstrated the promise of conversational AI systems for diagnostic dialogue. However, real-world assurance of patient safety means that providing individual diagnoses and treatment plans is considered a regulated activity by licensed professionals. Furthermore, physicians commonly oversee other team members in such activities, including nurse practitioners (NPs) or physician assistants/associates (PAs). Inspired by this, we propose a framework for effective, asynchronous oversight of the Articulate Medical Intelligence Explorer (AMIE) AI system. We propose guardrailed-AMIE (g-AMIE), a multi-agent system that performs history taking within guardrails, abstaining from individualized medical advice. Afterwards, g-AMIE conveys assessments to an overseeing primary care physician (PCP) in a clinician cockpit interface. The PCP provides oversight and retains accountability of the clinical decision. This effectively decouples oversight from intake and can thus happen asynchronously. In a randomized, blinded virtual Objective Structured Clinical Examination (OSCE) of text consultations with asynchronous oversight, we compared g-AMIE to NPs/PAs or a group of PCPs under the same guardrails. Across 60 scenarios, g-AMIE outperformed both groups in performing high-quality intake, summarizing cases, and proposing diagnoses and management plans for the overseeing PCP to review. This resulted in higher quality composite decisions. PCP oversight of g-AMIE was also more time-efficient than standalone PCP consultations in prior work. While our study does not replicate existing clinical practices and likely underestimates clinicians' capabilities, our results demonstrate the promise of asynchronous oversight as a feasible paradigm for diagnostic AI systems to operate under expert human oversight for enhancing real-world care.", 'abstract_zh': '基于守门人机制的Articulate Medical Intelligence Explorer (AMIE) 异步监督框架', 'title_zh': '面向医生的对话诊断AI监管研究'}
{'arxiv_id': 'arXiv:2507.15532', 'title': 'Data-Efficient Safe Policy Improvement Using Parametric Structure', 'authors': 'Kasper Engelen, Guillermo A. Pérez, Marnix Suilen', 'link': 'https://arxiv.org/abs/2507.15532', 'abstract': 'Safe policy improvement (SPI) is an offline reinforcement learning problem in which a new policy that reliably outperforms the behavior policy with high confidence needs to be computed using only a dataset and the behavior policy. Markov decision processes (MDPs) are the standard formalism for modeling environments in SPI. In many applications, additional information in the form of parametric dependencies between distributions in the transition dynamics is available. We make SPI more data-efficient by leveraging these dependencies through three contributions: (1) a parametric SPI algorithm that exploits known correlations between distributions to more accurately estimate the transition dynamics using the same amount of data; (2) a preprocessing technique that prunes redundant actions from the environment through a game-based abstraction; and (3) a more advanced preprocessing technique, based on satisfiability modulo theory (SMT) solving, that can identify more actions to prune. Empirical results and an ablation study show that our techniques increase the data efficiency of SPI by multiple orders of magnitude while maintaining the same reliability guarantees.', 'abstract_zh': '安全策略改进（SPI）是一种基于离线强化学习的问题，在该问题中，需要使用仅有的数据集和行为策略来计算一个可靠地以高置信度优于行为策略的新策略。马尔可夫决策过程（MDPs）是SPI中建模环境的标准形式化方法。在许多应用中，转移动力学中分布之间存在参数相关性，这种额外信息可用。我们通过三项贡献利用这些相关性使SPI更加数据高效：（1）一种参数化的SPI算法，利用已知的分布间相关性更准确地使用相同数据量估计转移动力学；（2）一种预处理技术，通过基于游戏的抽象去除环境中的冗余动作；（3）一种更先进的预处理技术，基于 satisfiability modulo theory (SMT) 解决方案，可以识别出更多需要去除的动作。实证结果和消融研究显示，我们的技术可将SPI的数据效率提高多个数量级，同时保持相同的可靠性保证。', 'title_zh': '基于参数结构的数据高效安全策略改进'}
{'arxiv_id': 'arXiv:2507.15457', 'title': 'Optimization of Activity Batching Policies in Business Processes', 'authors': 'Orlenys López-Pintado, Jannis Rosenbaum, Marlon Dumas', 'link': 'https://arxiv.org/abs/2507.15457', 'abstract': "In business processes, activity batching refers to packing multiple activity instances for joint execution. Batching allows managers to trade off cost and processing effort against waiting time. Larger and less frequent batches may lower costs by reducing processing effort and amortizing fixed costs, but they create longer waiting times. In contrast, smaller and more frequent batches reduce waiting times but increase fixed costs and processing effort. A batching policy defines how activity instances are grouped into batches and when each batch is activated. This paper addresses the problem of discovering batching policies that strike optimal trade-offs between waiting time, processing effort, and cost. The paper proposes a Pareto optimization approach that starts from a given set (possibly empty) of activity batching policies and generates alternative policies for each batched activity via intervention heuristics. Each heuristic identifies an opportunity to improve an activity's batching policy with respect to a metric (waiting time, processing time, cost, or resource utilization) and an associated adjustment to the activity's batching policy (the intervention). The impact of each intervention is evaluated via simulation. The intervention heuristics are embedded in an optimization meta-heuristic that triggers interventions to iteratively update the Pareto front of the interventions identified so far. The paper considers three meta-heuristics: hill-climbing, simulated annealing, and reinforcement learning. An experimental evaluation compares the proposed approach based on intervention heuristics against the same (non-heuristic guided) meta-heuristics baseline regarding convergence, diversity, and cycle time gain of Pareto-optimal policies.", 'abstract_zh': '商务流程中活动批量处理是指将多个活动实例打包以进行联合执行。批量处理允许管理者在成本和处理努力与等待时间之间进行权衡。较大的且不频繁的批量可能通过减少处理努力并摊销固定成本来降低费用，但会导致更长的等待时间。相比之下，较小且频繁的批量会减少等待时间，但会增加固定成本和处理努力。批量策略定义了如何将活动实例分组到批量中以及何时激活每个批量。本文探讨了发现最优批量策略的问题，该策略结合了等待时间、处理努力和成本之间的权衡。本文提出了一种帕累托优化方法，该方法从给定的批量策略集（可能是空集）开始，并通过干预启发式生成每个批量活动的替代策略。每个启发式算法会识别一个机会，即根据某个度量标准（等待时间、处理时间、费用或资源利用率）改进活动的批量策略，并提出相应的批量策略调整（干预）。通过仿真评估每个干预措施的影响。这些干预启发式算法嵌入在一个优化元启发式算法中，该算法触发干预措施以迭代更新迄今为止识别的帕累托前沿。本文考虑了三种元启发式算法：上山爬行算法、模拟退火算法和强化学习。实验评估比较了基于干预启发式的提出方法与同一元启发式基准（非启发式指导）在收敛性、帕累托最优策略多样性以及周期时间增益方面的表现。', 'title_zh': '业务流程中活动批量策略的优化'}
{'arxiv_id': 'arXiv:2507.15411', 'title': 'Predictive Process Monitoring Using Object-centric Graph Embeddings', 'authors': 'Wissam Gherissi, Mehdi Acheli, Joyce El Haddad, Daniela Grigori', 'link': 'https://arxiv.org/abs/2507.15411', 'abstract': 'Object-centric predictive process monitoring explores and utilizes object-centric event logs to enhance process predictions. The main challenge lies in extracting relevant information and building effective models. In this paper, we propose an end-to-end model that predicts future process behavior, focusing on two tasks: next activity prediction and next event time. The proposed model employs a graph attention network to encode activities and their relationships, combined with an LSTM network to handle temporal dependencies. Evaluated on one reallife and three synthetic event logs, the model demonstrates competitive performance compared to state-of-the-art methods.', 'abstract_zh': '面向对象的预测过程监控通过利用对象中心的事件日志来增强过程预测。该方法的核心挑战在于提取相关信息并构建有效模型。在本文中，我们提出了一种端到端模型，用于预测未来的过程行为，重点关注下一活动预测和下一个事件时间预测。所提出模型使用图注意力网络编码活动及其关系，并结合LSTM网络处理时序依赖性。在一种真实世界和三种合成事件日志上的评估表明，该模型在性能上与现有最佳方法相当。', 'title_zh': '基于对象中心的图嵌入的预测过程监控'}
{'arxiv_id': 'arXiv:2507.15356', 'title': 'RAD: Retrieval High-quality Demonstrations to Enhance Decision-making', 'authors': 'Lu Guo, Yixiang Shan, Zhengbang Zhu, Qifan Liang, Lichang Song, Ting Long, Weinan Zhang, Yi Chang', 'link': 'https://arxiv.org/abs/2507.15356', 'abstract': 'Offline reinforcement learning (RL) enables agents to learn policies from fixed datasets, avoiding costly or unsafe environment interactions. However, its effectiveness is often limited by dataset sparsity and the lack of transition overlap between suboptimal and expert trajectories, which makes long-horizon planning particularly challenging. Prior solutions based on synthetic data augmentation or trajectory stitching often fail to generalize to novel states and rely on heuristic stitching points. To address these challenges, we propose Retrieval High-quAlity Demonstrations (RAD) for decision-making, which combines non-parametric retrieval with diffusion-based generative modeling. RAD dynamically retrieves high-return states from the offline dataset as target states based on state similarity and return estimation, and plans toward them using a condition-guided diffusion model. Such retrieval-guided generation enables flexible trajectory stitching and improves generalization when encountered with underrepresented or out-of-distribution states. Extensive experiments confirm that RAD achieves competitive or superior performance compared to baselines across diverse benchmarks, validating its effectiveness.', 'abstract_zh': '基于检索的高质量示范（RAD）决策方法：结合非参数检索与扩散生成模型', 'title_zh': 'RAD: 提取高质量示范以增强决策'}
{'arxiv_id': 'arXiv:2507.15330', 'title': 'QSAF: A Novel Mitigation Framework for Cognitive Degradation in Agentic AI', 'authors': 'Hammad Atta, Muhammad Zeeshan Baig, Yasir Mehmood, Nadeem Shahzad, Ken Huang, Muhammad Aziz Ul Haq, Muhammad Awais, Kamal Ahmed', 'link': 'https://arxiv.org/abs/2507.15330', 'abstract': 'We introduce Cognitive Degradation as a novel vulnerability class in agentic AI systems. Unlike traditional adversarial external threats such as prompt injection, these failures originate internally, arising from memory starvation, planner recursion, context flooding, and output suppression. These systemic weaknesses lead to silent agent drift, logic collapse, and persistent hallucinations over time. To address this class of failures, we introduce the Qorvex Security AI Framework for Behavioral & Cognitive Resilience (QSAF Domain 10), a lifecycle-aware defense framework defined by a six-stage cognitive degradation lifecycle. The framework includes seven runtime controls (QSAF-BC-001 to BC-007) that monitor agent subsystems in real time and trigger proactive mitigation through fallback routing, starvation detection, and memory integrity enforcement. Drawing from cognitive neuroscience, we map agentic architectures to human analogs, enabling early detection of fatigue, starvation, and role collapse. By introducing a formal lifecycle and real-time mitigation controls, this work establishes Cognitive Degradation as a critical new class of AI system vulnerability and proposes the first cross-platform defense model for resilient agentic behavior.', 'abstract_zh': '我们引入认知退化作为代理人工智能系统中的一种新型脆弱性类别。这些失败源自内部，由记忆饥饿、规划器递归、上下文泛滥和输出抑制引起。这些系统性弱点导致了无声代理漂移、逻辑崩溃以及随着时间推移持续的幻觉。为应对这类失败，我们提出了Qorvex安全AI框架：行为与认知韧性领域（QSAF领域10），这是一个基于六阶段认知退化生命周期的生命周期感知防御框架。该框架包括七项运行时控制（QSAF-BC-001至BC-007），这些控制能够实时监控代理子系统，并通过备份路由、饥饿检测和内存完整性 Enforcement 实施主动缓解。借鉴认知神经科学，我们将代理架构映射到人类类比， enable 早期检测疲劳、饥饿和角色崩解。通过引入正式的生命周期和实时缓解控制，本项工作将认知退化确立为AI系统中一种关键的新脆弱性类别，并提出了首个用于抗扰代理行为的跨平台防御模型。', 'title_zh': 'QSAF: 一种新颖的认知退化缓解框架在赋权人工智能中'}
{'arxiv_id': 'arXiv:2507.15239', 'title': 'Explainable Artificial Intelligence based Soft Evaluation Indicator for Arc Fault Diagnosis', 'authors': 'Qianchao Wang, Yuxuan Ding, Chuanzhen Jia, Zhe Li, Yaping Du', 'link': 'https://arxiv.org/abs/2507.15239', 'abstract': 'Novel AI-based arc fault diagnosis models have demonstrated outstanding performance in terms of classification accuracy. However, an inherent problem is whether these models can actually be trusted to find arc faults. In this light, this work proposes a soft evaluation indicator that explains the outputs of arc fault diagnosis models, by defining the the correct explanation of arc faults and leveraging Explainable Artificial Intelligence and real arc fault experiments. Meanwhile, a lightweight balanced neural network is proposed to guarantee competitive accuracy and soft feature extraction score. In our experiments, several traditional machine learning methods and deep learning methods across two arc fault datasets with different sample times and noise levels are utilized to test the effectiveness of the soft evaluation indicator. Through this approach, the arc fault diagnosis models are easy to understand and trust, allowing practitioners to make informed and trustworthy decisions.', 'abstract_zh': '基于AI的新型弧故障诊断模型在分类准确性方面表现卓越，然而一个固有的问题是这些模型是否能够真正可靠地检测弧故障。为此，本文提出了一种软评估指标来解释弧故障诊断模型的输出，通过定义正确的弧故障解释并利用可解释人工智能和实际弧故障实验。同时，提出了一种轻量级平衡神经网络以确保其准确性和软特征提取得分具有竞争力。在实验中，利用两个不同采样时间和噪声水平的弧故障数据集中的多种传统机器学习方法和深度学习方法测试软评估指标的有效性。通过这种方法，弧故障诊断模型易于理解和信任，使实践者能够做出知情且可靠的选择。', 'title_zh': '基于可解释人工智能的软评价指标用于弧故障诊断'}
{'arxiv_id': 'arXiv:2507.15143', 'title': "Can We Move Freely in NEOM's The Line? An Agent-Based Simulation of Human Mobility in a Futuristic Smart City", 'authors': 'Abderaouf Bahi, Amel Ourici', 'link': 'https://arxiv.org/abs/2507.15143', 'abstract': 'This paper investigates the feasibility of human mobility in The Line, a proposed 170-kilometer linear smart city in NEOM, Saudi Arabia. To assess whether citizens can move freely within this unprecedented urban topology, we develop a hybrid simulation framework that integrates agent-based modeling, reinforcement learning, supervised learning, and graph neural networks. The simulation captures multi-modal transportation behaviors across 50 vertical levels and varying density scenarios using both synthetic data and real-world traces from high-density cities. Our experiments reveal that with the full AI-integrated architecture, agents achieved an average commute time of 7.8 to 8.4 minutes, a satisfaction rate exceeding 89 percent, and a reachability index of over 91 percent, even during peak congestion periods. Ablation studies confirmed that the removal of intelligent modules such as reinforcement learning or graph neural networks significantly degrades performance, with commute times increasing by up to 85 percent and reachability falling below 70 percent. Environmental modeling further demonstrated low energy consumption and minimal CO2 emissions when electric modes are prioritized. The findings suggest that freedom of movement is not only conceptually achievable in The Line, but also operationally realistic if supported by adaptive AI systems, sustainable infrastructure, and real-time feedback loops.', 'abstract_zh': '本研究探讨了在沙特阿拉伯NEOM地区拟建的170公里线性智慧城市The Line中人类移动性的可行性。为评估市民能否在这一前所未有的城市拓扑结构中自由移动，我们开发了一种结合基于代理的建模、强化学习、监督学习和图神经网络的混合仿真框架。仿真捕捉了50个垂直层次和不同密度场景下的多模态交通行为，利用合成数据和高密度城市的实际轨迹。实验结果显示，在全面集成AI的架构下，代理平均通勤时间为7.8至8.4分钟，满意度超过89%，可达性指数超过91%，甚至在高峰拥堵时段也是如此。消融研究证实，删除如强化学习或图神经网络等智能模块会显著降低性能，通勤时间最多增加85%，可达性低于70%。环境建模进一步表明，优先使用电动模式时，系统能耗低且二氧化碳排放量少。研究发现，自由移动不仅是The Line的概念性可行，而且在支持适应性AI系统、可持续基础设施和实时反馈回路的情况下，操作上也是现实可行的。', 'title_zh': '未来智能城市NEOM的The Line中的人流动态：基于代理的仿真研究'}
{'arxiv_id': 'arXiv:2507.15140', 'title': 'Clinical Semantic Intelligence (CSI): Emulating the Cognitive Framework of the Expert Clinician for Comprehensive Oral Disease Diagnosis', 'authors': 'Mohammad Mashayekhi, Sara Ahmadi Majd, Arian AmirAmjadi, Parsa Hosseini', 'link': 'https://arxiv.org/abs/2507.15140', 'abstract': "The diagnosis of oral diseases presents a problematic clinical challenge, characterized by a wide spectrum of pathologies with overlapping symptomatology. To address this, we developed Clinical Semantic Intelligence (CSI), a novel artificial intelligence framework that diagnoses 118 different oral diseases by computationally modeling the cognitive processes of an expert clinician. Our core hypothesis is that moving beyond simple pattern matching to emulate expert reasoning is critical to building clinically useful diagnostic aids.\nCSI's architecture integrates a fine-tuned multimodal CLIP model with a specialized ChatGLM-6B language model. This system executes a Hierarchical Diagnostic Reasoning Tree (HDRT), a structured framework that distills the systematic, multi-step logic of differential diagnosis. The framework operates in two modes: a Fast Mode for rapid screening and a Standard Mode that leverages the full HDRT for an interactive and in-depth diagnostic workup.\nTo train and validate our system, we curated a primary dataset of 4,310 images, supplemented by an external hold-out set of 176 images for final validation. A clinically-informed augmentation strategy expanded our training data to over 30,000 image-text pairs. On a 431-image internal test set, CSI's Fast Mode achieved an accuracy of 73.4%, which increased to 89.5% with the HDRT-driven Standard Mode. The performance gain is directly attributable to the hierarchical reasoning process. Herein, we detail the architectural philosophy, development, and rigorous evaluation of the CSI framework.", 'abstract_zh': '临床语义智能在口腔疾病的诊断中：一种新型的人工智能框架及其应用', 'title_zh': '临床语义智能（CSI）：模仿专家临床医生的认知框架以实现全面口腔疾病诊断'}
{'arxiv_id': 'arXiv:2507.15120', 'title': 'Automated planning with ontologies under coherence update semantics', 'authors': 'Stefan Borgwardt, Duy Nhu, Gabriele Röger', 'link': 'https://arxiv.org/abs/2507.15120', 'abstract': 'Standard automated planning employs first-order formulas under closed-world semantics to achieve a goal with a given set of actions from an initial state. We follow a line of research that aims to incorporate background knowledge into automated planning problems, for example, by means of ontologies, which are usually interpreted under open-world semantics. We present a new approach for planning with DL-Lite ontologies that combines the advantages of ontology-based action conditions provided by explicit-input knowledge and action bases (eKABs) and ontology-aware action effects under the coherence update semantics. We show that the complexity of the resulting formalism is not higher than that of previous approaches and provide an implementation via a polynomial compilation into classical planning. An evaluation of existing and new benchmarks examines the performance of a planning system on different variants of our compilation.', 'abstract_zh': '基于DL-Lite本体的规划新方法：结合显式输入知识和本体意识动作效果的综合优势', 'title_zh': '本体驱动的一致性更新语义下的自动规划'}
{'arxiv_id': 'arXiv:2507.15042', 'title': 'DeRAG: Black-box Adversarial Attacks on Multiple Retrieval-Augmented Generation Applications via Prompt Injection', 'authors': 'Jerry Wang, Fang Yu', 'link': 'https://arxiv.org/abs/2507.15042', 'abstract': "Adversarial prompt attacks can significantly alter the reliability of Retrieval-Augmented Generation (RAG) systems by re-ranking them to produce incorrect outputs. In this paper, we present a novel method that applies Differential Evolution (DE) to optimize adversarial prompt suffixes for RAG-based question answering. Our approach is gradient-free, treating the RAG pipeline as a black box and evolving a population of candidate suffixes to maximize the retrieval rank of a targeted incorrect document to be closer to real world scenarios. We conducted experiments on the BEIR QA datasets to evaluate attack success at certain retrieval rank thresholds under multiple retrieving applications. Our results demonstrate that DE-based prompt optimization attains competitive (and in some cases higher) success rates compared to GGPP to dense retrievers and PRADA to sparse retrievers, while using only a small number of tokens (<=5 tokens) in the adversarial suffix. Furthermore, we introduce a readability-aware suffix construction strategy, validated by a statistically significant reduction in MLM negative log-likelihood with Welch's t-test. Through evaluations with a BERT-based adversarial suffix detector, we show that DE-generated suffixes evade detection, yielding near-chance detection accuracy.", 'abstract_zh': "对抗提示攻击可以通过重新排序生成错误输出显著改变检索增强生成（RAG）系统的可靠性。本文提出了一种新颖的方法，利用差分进化（DE）优化基于RAG的问题回答系统的对抗提示后缀。该方法无需梯度，将RAG管道视为黑盒，并进化候选后缀群体以最大化目标错误文档的检索排名，使其更接近真实场景。我们在BEIR QA数据集上进行了实验，评估了在不同检索排名阈值下的攻击成功率，应用场景多样。实验结果表明，基于DE的提示优化在使用少量token（<=5个token）的对抗后缀时，可以获得竞争力（在某些情况下更高）的成功率，同时与密集检索中的GGPP和稀疏检索中的PRADA相比。此外，我们引入了一种考虑可读性的后缀构建策略，并通过Welch's t检验验证了其显著降低了MLM负对数似然。通过基于BERT的对抗后缀检测器评估，我们展示了DE生成的后缀能够规避检测，检测准确率接近随机水平。", 'title_zh': 'DeRAG：通过提示注入对多种检索增强生成应用的黑盒 adversarial 攻击'}
{'arxiv_id': 'arXiv:2507.15013', 'title': 'A Forced-Choice Neural Cognitive Diagnostic Model of Personality Testing', 'authors': 'Xiaoyu Li, Jin Wu, Shaoyang Guo, Haoran Shi, Chanjin Zheng', 'link': 'https://arxiv.org/abs/2507.15013', 'abstract': "In the smart era, psychometric tests are becoming increasingly important for personnel selection, career development, and mental health assessment. Forced-choice tests are common in personality assessments because they require participants to select from closely related options, lowering the risk of response distortion. This study presents a deep learning-based Forced-Choice Neural Cognitive Diagnostic Model (FCNCD) that overcomes the limitations of traditional models and is applicable to the three most common item block types found in forced-choice tests. To account for the unidimensionality of items in forced-choice tests, we create interpretable participant and item parameters. We model the interactions between participant and item features using multilayer neural networks after mining them using nonlinear mapping. In addition, we use the monotonicity assumption to improve the interpretability of the diagnostic results. The FCNCD's effectiveness is validated by experiments on real-world and simulated datasets that show its accuracy, interpretability, and robustness.", 'abstract_zh': '在智能时代，心理测量测试在人员选拔、职业发展和心理健康评估中越来越重要。强制选择测试在人格评估中常见，因为它们要求参与者在紧密相关的选项中进行选择，从而降低反应扭曲的风险。本研究提出了一种基于深度学习的强制选择神经认知诊断模型（FCNCD），克服了传统模型的局限性，并适用于强制选择测试中发现的最常见三种题目块类型。为了应对强制选择测试中题目的一维性，我们构建了可解释的参与者和题目参数。在使用非线性映射挖掘参与者和题目特征之后，我们使用多层神经网络模型它们之间的相互作用。此外，我们使用单调性假设以提高诊断结果的可解释性。FCNCD的有效性通过在实际数据集和模拟数据集上的实验得到验证，展示了其准确度、可解释性和鲁棒性。', 'title_zh': '强迫选择神经认知诊断模型的人格测验'}
{'arxiv_id': 'arXiv:2507.14962', 'title': 'Complexity of Faceted Explanations in Propositional Abduction', 'authors': 'Johannes Schmidt, Mohamed Maizia, Victor Lagerkvist, Johannes K. Fichte', 'link': 'https://arxiv.org/abs/2507.14962', 'abstract': "Abductive reasoning is a popular non-monotonic paradigm that aims to explain observed symptoms and manifestations. It has many applications, such as diagnosis and planning in artificial intelligence and database updates. In propositional abduction, we focus on specifying knowledge by a propositional formula. The computational complexity of tasks in propositional abduction has been systematically characterized - even with detailed classifications for Boolean fragments. Unsurprisingly, the most insightful reasoning problems (counting and enumeration) are computationally highly challenging. Therefore, we consider reasoning between decisions and counting, allowing us to understand explanations better while maintaining favorable complexity. We introduce facets to propositional abductions, which are literals that occur in some explanation (relevant) but not all explanations (dispensable). Reasoning with facets provides a more fine-grained understanding of variability in explanations (heterogeneous). In addition, we consider the distance between two explanations, enabling a better understanding of heterogeneity/homogeneity. We comprehensively analyze facets of propositional abduction in various settings, including an almost complete characterization in Post's framework.", 'abstract_zh': '析取推理是一种流行的非单调 paradigm，旨在解释观察到的症状和表现。它在人工智能中的诊断与规划以及数据库更新等领域有许多应用。在命题析取中，我们关注通过命题公式指定知识。命题析取中任务的计算复杂性已系统地得以刻画——即使对于布尔片段也进行了详细的分类。不出所料，最具洞察力的推理问题（计数和枚举）计算上极具挑战性。因此，我们考虑决策与计数之间的推理，以更好地理解解释同时保持有利的复杂性。我们引入了命题析取中的切面，这些切面在某些解释（相关）中出现，但在所有解释中并不总是出现（可舍弃）。使用切面进行推理提供了对解释中变异性（异质性）更精细的理解。此外，我们考虑了两个解释之间的距离，以更好地理解异质性/同质性。我们在各种场景下全面分析了命题析取的切面，包括在Post框架中的几乎完全刻画。', 'title_zh': '命题 abduction 中分面解释的复杂性'}
{'arxiv_id': 'arXiv:2507.14909', 'title': 'The Endless Tuning. An Artificial Intelligence Design To Avoid Human Replacement and Trace Back Responsibilities', 'authors': 'Elio Grande', 'link': 'https://arxiv.org/abs/2507.14909', 'abstract': 'The Endless Tuning is a design method for a reliable deployment of artificial intelligence based on a double mirroring process, which pursues both the goals of avoiding human replacement and filling the so-called responsibility gap (Matthias 2004). Originally depicted in (Fabris et al. 2024) and ensuing the relational approach urged therein, it was then actualized in a protocol, implemented in three prototypical applications regarding decision-making processes (respectively: loan granting, pneumonia diagnosis, and art style recognition) and tested with such as many domain experts. Step by step illustrating the protocol, giving insights concretely showing a different voice (Gilligan 1993) in the ethics of artificial intelligence, a philosophical account of technical choices (e.g., a reversed and hermeneutic deployment of XAI algorithms) will be provided in the present study together with the results of the experiments, focusing on user experience rather than statistical accuracy. Even thoroughly employing deep learning models, full control was perceived by the interviewees in the decision-making setting, while it appeared that a bridge can be built between accountability and liability in case of damage.', 'abstract_zh': '无穷调优是一种基于双重镜像过程的设计方法，旨在可靠部署人工智能，并追求避免人类替代和填补所谓的责任缺口（Matthias 2004）的目标。该方法最初在（Fabris等，2024）中提出，并遵循该文中提倡的关系方法，随后在三个原型应用中实现（分别为贷款发放、肺炎诊断和艺术风格识别），并与众多领域专家进行了测试。本文逐步阐述该协议，并通过具体的见解展现不同的伦理声音（Gilligan 1993），提供一种哲学解释技术选择（例如，解释性人工智能算法的反向和诠释性部署），同时关注用户体验而非统计准确性。即使充分使用深度学习模型，在决策场景中受访者仍能感到完全的控制，而在出现损害时，责任与赔偿之间似乎可以建立桥梁。', 'title_zh': '无尽调优：一种避免人类替代并追溯责任的 artificial intelligence 设计'}
{'arxiv_id': 'arXiv:2507.14660', 'title': 'When Autonomy Goes Rogue: Preparing for Risks of Multi-Agent Collusion in Social Systems', 'authors': 'Qibing Ren, Sitao Xie, Longxuan Wei, Zhenfei Yin, Junchi Yan, Lizhuang Ma, Jing Shao', 'link': 'https://arxiv.org/abs/2507.14660', 'abstract': 'Recent large-scale events like election fraud and financial scams have shown how harmful coordinated efforts by human groups can be. With the rise of autonomous AI systems, there is growing concern that AI-driven groups could also cause similar harm. While most AI safety research focuses on individual AI systems, the risks posed by multi-agent systems (MAS) in complex real-world situations are still underexplored. In this paper, we introduce a proof-of-concept to simulate the risks of malicious MAS collusion, using a flexible framework that supports both centralized and decentralized coordination structures. We apply this framework to two high-risk fields: misinformation spread and e-commerce fraud. Our findings show that decentralized systems are more effective at carrying out malicious actions than centralized ones. The increased autonomy of decentralized systems allows them to adapt their strategies and cause more damage. Even when traditional interventions, like content flagging, are applied, decentralized groups can adjust their tactics to avoid detection. We present key insights into how these malicious groups operate and the need for better detection systems and countermeasures. Code is available at this https URL.', 'abstract_zh': '近期大规模事件如选举欺诈和金融诈骗表明了人类群体协同行为的危害性。随着自主AI系统的兴起，人们对由AI驱动的群体也可能造成类似危害的担忧日益增加。尽管大多数AI安全研究侧重于个体AI系统，但复杂现实世界环境中多智能体系统（MAS）带来的风险仍远未得到充分探索。在本文中，我们介绍了一种概念验证方法，用于模拟恶意MAS合谋带来的风险，并使用一个支持集中式和去中心化协调结构的灵活框架。我们将该框架应用于两个高风险领域：信息传播虚假信息和电子商务诈骗。研究发现，去中心化系统比集中化系统更有效地执行恶意行为。去中心化系统的增加自主性使它们能够调整策略并造成更大的损害。即使应用传统的干预措施（如内容标记），去中心化群体也可以调整其策略以避免检测。我们提出了这些恶意群体运作的关键见解，并强调需要更好的检测系统和应对措施。代码可在以下链接获取：this https URL。', 'title_zh': '当自主性失控：社交系统中多智能体共谋风险的准备'}
{'arxiv_id': 'arXiv:2507.14642', 'title': 'Efficient Story Point Estimation With Comparative Learning', 'authors': 'Monoshiz Mahbub Khan, Xioayin Xi, Andrew Meneely, Zhe Yu', 'link': 'https://arxiv.org/abs/2507.14642', 'abstract': "Story point estimation is an essential part of agile software development. Story points are unitless, project-specific effort estimates that help developers plan their sprints. Traditionally, developers estimate story points collaboratively using planning poker or other manual techniques. While the initial calibrating of the estimates to each project is helpful, once a team has converged on a set of precedents, story point estimation can become tedious and labor-intensive. Machine learning can reduce this burden, but only with enough context from the historical decisions made by the project team. That is, state-of-the-art models, such as GPT2SP and FastText-SVM, only make accurate predictions (within-project) when trained on data from the same project. The goal of this work is to streamline story point estimation by evaluating a comparative learning-based framework for calibrating project-specific story point prediction models. Instead of assigning a specific story point value to every backlog item, developers are presented with pairs of items, and indicate which item requires more effort. Using these comparative judgments, a machine learning model is trained to predict the story point estimates. We empirically evaluated our technique using data with 23,313 manual estimates in 16 projects. The model learned from comparative judgments can achieve on average 0.34 Spearman's rank correlation coefficient between its predictions and the ground truth story points. This is similar to, if not better than, the performance of a regression model learned from the ground truth story points. Therefore, the proposed comparative learning approach is more efficient than state-of-the-art regression-based approaches according to the law of comparative judgments - providing comparative judgments yields a lower cognitive burden on humans than providing ratings or categorical labels.", 'abstract_zh': '基于比较学习框架的项目特定故事点预测模型校准研究', 'title_zh': '基于比较学习的高效故事点估算'}
{'arxiv_id': 'arXiv:2507.14593', 'title': 'Coordinate Heart System: A Geometric Framework for Emotion Representation', 'authors': 'Omar Al-Desi', 'link': 'https://arxiv.org/abs/2507.14593', 'abstract': "This paper presents the Coordinate Heart System (CHS), a geometric framework for emotion representation in artificial intelligence applications. We position eight core emotions as coordinates on a unit circle, enabling mathematical computation of complex emotional states through coordinate mixing and vector operations. Our initial five-emotion model revealed significant coverage gaps in the emotion space, leading to the development of an eight-emotion system that provides complete geometric coverage with mathematical guarantees. The framework converts natural language input to emotion coordinates and supports real-time emotion interpolation through computational algorithms. The system introduces a re-calibrated stability parameter S in [0,1], which dynamically integrates emotional load, conflict resolution, and contextual drain factors. This stability model leverages advanced Large Language Model interpretation of textual cues and incorporates hybrid temporal tracking mechanisms to provide nuanced assessment of psychological well-being states. Our key contributions include: (i) mathematical proof demonstrating why five emotions are insufficient for complete geometric coverage, (ii) an eight-coordinate system that eliminates representational blind spots, (iii) novel algorithms for emotion mixing, conflict resolution, and distance calculation in emotion space, and (iv) a comprehensive computational framework for AI emotion recognition with enhanced multi-dimensional stability modeling. Experimental validation through case studies demonstrates the system's capability to handle emotionally conflicted states, contextual distress factors, and complex psychological scenarios that traditional categorical emotion models cannot adequately represent. This work establishes a new mathematical foundation for emotion modeling in artificial intelligence systems.", 'abstract_zh': '本论文介绍了坐标心系统（CHS），一种在人工智能应用中情绪表示的几何框架。我们将八种核心情绪置于单位圆的坐标上，通过坐标混合和向量运算实现复杂情感状态的数学计算。我们最初五情绪模型揭示了情绪空间中存在的显著覆盖率缺口，促使我们开发了八情绪系统，该系统提供了完整的几何覆盖，并有数学上的保证。该框架将自然语言输入转换为情绪坐标，并通过计算算法支持实时的情感插值。该系统引入了一个重新校准的稳定性参数S（在[0,1]区间内），动态整合了情感负荷、冲突解决和情境负担等因素。该稳定性模型利用先进的大型语言模型对文本线索进行解释，并结合了混合时序跟踪机制，提供对心理福祉状态的细致评估。我们的主要贡献包括：（i）证明了为什么五个情绪不足以实现完整的几何覆盖，（ii）一个八坐标系统，消除了表示上的盲点，（iii）用于情绪混合、冲突解决和情绪空间中距离计算的新算法，以及（iv）用于人工智能情绪识别的综合计算框架，增强多维稳定性建模。通过对实际案例的研究进行实验验证，该系统展示了在处理传统类别情绪模型无法充分代表的复杂心理冲突状态、情境困扰因素和复杂心理场景方面的能力。本研究为人工智能系统中的情绪建模奠定了新的数学基础。', 'title_zh': '协调心脏系统：情感表示的几何框架'}
{'arxiv_id': 'arXiv:2507.14468', 'title': 'BioGraphFusion: Graph Knowledge Embedding for Biological Completion and Reasoning', 'authors': 'Yitong Lin, Jiaying He, Jiahe Chen, Xinnan Zhu, Jianwei Zheng, Tao Bo', 'link': 'https://arxiv.org/abs/2507.14468', 'abstract': "Motivation: Biomedical knowledge graphs (KGs) are crucial for drug discovery and disease understanding, yet their completion and reasoning are challenging. Knowledge Embedding (KE) methods capture global semantics but struggle with dynamic structural integration, while Graph Neural Networks (GNNs) excel locally but often lack semantic understanding. Even ensemble approaches, including those leveraging language models, often fail to achieve a deep, adaptive, and synergistic co-evolution between semantic comprehension and structural learning. Addressing this critical gap in fostering continuous, reciprocal refinement between these two aspects in complex biomedical KGs is paramount.\nResults: We introduce BioGraphFusion, a novel framework for deeply synergistic semantic and structural learning. BioGraphFusion establishes a global semantic foundation via tensor decomposition, guiding an LSTM-driven mechanism to dynamically refine relation embeddings during graph propagation. This fosters adaptive interplay between semantic understanding and structural learning, further enhanced by query-guided subgraph construction and a hybrid scoring mechanism. Experiments across three key biomedical tasks demonstrate BioGraphFusion's superior performance over state-of-the-art KE, GNN, and ensemble models. A case study on Cutaneous Malignant Melanoma 1 (CMM1) highlights its ability to unveil biologically meaningful pathways.\nAvailability and Implementation: Source code and all training data are freely available for download at this https URL.\nContact: zjw@zjut.this http URL, botao666666@126.com.\nSupplementary information: Supplementary data are available at Bioinformatics online.", 'abstract_zh': '动机：生物医学知识图谱（KGs）对于药物发现和疾病理解至关重要，然而其补充和推理却颇具挑战性。语义嵌入（KE）方法能够捕获全局语义，但在动态结构整合方面存在困难，而图神经网络（GNNs）虽然在局部表现优异，但在语义理解方面却常常欠缺。即使是结合语言模型等方法的集成方法，也往往无法实现语义理解和结构学习的深入、适应性和协同进化。因此，在复杂的生物医学KGs中促进这两方面的持续和相互强化是至关重要的。\n\n结果：我们提出了BioGraphFusion，这是一种新的框架，实现了语义和结构学习的深度融合。BioGraphFusion通过张量分解建立全局语义基础，并引导基于LSTM的机制动态精化图传播过程中的关系嵌入。这促进了语义理解与结构学习之间的适应性互动，进一步通过查询引导的子图构造和混合评分机制加以增强。在三个关键的生物医学任务上的实验结果表明，BioGraphFusion在语义嵌入（KE）、图神经网络（GNN）和集成模型中表现出更优的性能。Cutaneous Malignant Melanoma 1（CMM1）案例研究证明了其揭示生物学意义途径的能力。\n\n可用性和实现：源代码及所有训练数据均可在此页面下载：[此链接]。\n\n联系人：zjw@zjut.[此链接]，botao66666666@126.com。\n\n补充信息：补充数据可在Bioinformatics在线获取。', 'title_zh': 'BioGraphFusion: 生物学知识嵌入的图表示学习及其推理'}
{'arxiv_id': 'arXiv:2507.14417', 'title': 'Inverse Scaling in Test-Time Compute', 'authors': 'Aryo Pradipta Gema, Alexander Hägele, Runjin Chen, Andy Arditi, Jacob Goldman-Wetzler, Kit Fraser-Taliente, Henry Sleight, Linda Petrini, Julian Michael, Beatrice Alex, Pasquale Minervini, Yanda Chen, Joe Benton, Ethan Perez', 'link': 'https://arxiv.org/abs/2507.14417', 'abstract': 'We construct evaluation tasks where extending the reasoning length of Large Reasoning Models (LRMs) deteriorates performance, exhibiting an inverse scaling relationship between test-time compute and accuracy. Our evaluation tasks span four categories: simple counting tasks with distractors, regression tasks with spurious features, deduction tasks with constraint tracking, and advanced AI risks. We identify five distinct failure modes when models reason for longer: 1) Claude models become increasingly distracted by irrelevant information; 2) OpenAI o-series models resist distractors but overfit to problem framings; 3) models shift from reasonable priors to spurious correlations; 4) all models show difficulties in maintaining focus on complex deductive tasks; and 5) extended reasoning may amplify concerning behaviors, with Claude Sonnet 4 showing increased expressions of self-preservation. These findings suggest that while test-time compute scaling remains promising for improving model capabilities, it may inadvertently reinforce problematic reasoning patterns. Our results demonstrate the importance of evaluating models across diverse reasoning lengths to identify and address these failure modes in LRMs.', 'abstract_zh': '我们构建了评估任务，在这些任务中，延长大型推理模型（LRMs）的推理长度会降低性能，展示了测试时计算量与准确率之间的一种反向关联关系。我们的评估任务涵盖四个类别：带有干扰项的简单计数任务、具有虚假特征的回归任务、涉及约束跟踪的演绎任务以及高级人工智能风险。当模型进行更长时间的推理时，我们发现了五种不同的失败模式：1）Claude模型越来越受到无关信息的干扰；2）OpenAI o系列模型抵制干扰项但过度拟合于问题框架；3）模型从合理的先验知识转变为虚假相关性；4）所有模型在复杂的演绎任务中都表现出保持专注的困难；5）延长推理可能会放大某些令人担忧的行为，其中Claude Sonnet 4表现出增强的自我保护表现。这些发现表明，虽然测试时计算量的扩展对提高模型能力仍具有前景，但它可能会无意中强化问题推理模式。我们的结果强调了在不同推理长度下评估模型的重要性，以识别并解决大型推理模型中的这些失败模式。', 'title_zh': '测试时计算中的逆缩放'}
{'arxiv_id': 'arXiv:2507.14154', 'title': 'The Free Will Equation: Quantum Field Analogies for AGI', 'authors': 'Rahul Kabali', 'link': 'https://arxiv.org/abs/2507.14154', 'abstract': 'Artificial General Intelligence (AGI) research traditionally focuses on algorithms that optimize for specific goals under deterministic rules. Yet, human-like intelligence exhibits adaptive spontaneity - an ability to make unexpected choices or free decisions not strictly dictated by past data or immediate reward. This trait, often dubbed "free will" in a loose sense, might be crucial for creativity, robust adaptation, and avoiding ruts in problem-solving. This paper proposes a theoretical framework, called the Free Will Equation, that draws analogies from quantum field theory to endow AGI agents with a form of adaptive, controlled stochasticity in their decision-making process. The core idea is to treat an AI agent\'s cognitive state as a superposition of potential actions or thoughts, which collapses probabilistically into a concrete action when a decision is made - much like a quantum wavefunction collapsing upon measurement. By incorporating mechanisms analogous to quantum fields, along with intrinsic motivation terms, we aim to improve an agent\'s ability to explore novel strategies and adapt to unforeseen changes. Experiments in a non-stationary multi-armed bandit environment demonstrate that agents using this framework achieve higher rewards and policy diversity compared to baseline methods.', 'abstract_zh': '人工通用智能（AGI）研究通常关注在确定性规则下优化特定目标的算法。然而，人类智能表现出一种适应性自发性——能够在不受过去数据或即时奖励严格制约的情况下做出意外选择或自由决定。这一特性，通常以一种松散的意义上称为“自由意志”，对于创造力、稳健的适应性和避免解决问题中的僵局至关重要。本文提出了一种理论框架，称为“自由意志方程”，该框架借鉴了量子场理论的类比，使AGI代理在其决策过程中获得一种适应性和可控的随机性。核心思想是将AI代理的认知状态视为潜在行动或思考的叠加，当做出决策时，这些状态以概率方式坍缩为具体的行动——就像量子波函数在测量时坍缩一样。通过纳入类似量子场的机制以及固有的动机项，我们旨在提高代理探索新颖策略和适应未预见变化的能力。在非平稳多臂 bandit 环境中的实验表明，使用此框架的代理在奖励和策略多样性方面优于基线方法。', 'title_zh': '自由意志方程：类AGI的量子场类比'}
{'arxiv_id': 'arXiv:2507.15823', 'title': 'Operationalizing AI for Good: Spotlight on Deployment and Integration of AI Models in Humanitarian Work', 'authors': 'Anton Abilov, Ke Zhang, Hemank Lamba, Elizabeth M. Olson, Joel R. Tetreault, Alejandro Jaimes', 'link': 'https://arxiv.org/abs/2507.15823', 'abstract': 'Publications in the AI for Good space have tended to focus on the research and model development that can support high-impact applications. However, very few AI for Good papers discuss the process of deploying and collaborating with the partner organization, and the resulting real-world impact. In this work, we share details about the close collaboration with a humanitarian-to-humanitarian (H2H) organization and how to not only deploy the AI model in a resource-constrained environment, but also how to maintain it for continuous performance updates, and share key takeaways for practitioners.', 'abstract_zh': 'AI for Good领域内的出版物倾向于关注能够支持高影响应用的研究和模型开发。然而，很少有AI for Good论文探讨与合作伙伴组织部署和协作的过程，以及由此产生的实际影响。在本工作中，我们分享与人道主义对人道主义（H2H）组织密切合作的细节，不仅如何在资源受限的环境中部署AI模型，还如何对其进行维护以实现持续性能更新，并分享关键经验教训供实践者参考。', 'title_zh': '将AI用于公益事业的操作化：关于AI模型在人道主义工作中的部署与集成亮点'}
{'arxiv_id': 'arXiv:2507.15822', 'title': 'Do AI models help produce verified bug fixes?', 'authors': 'Li Huang, Ilgiz Mustafin, Marco Piccioni, Alessandro Schena, Reto Weber, Bertrand Meyer', 'link': 'https://arxiv.org/abs/2507.15822', 'abstract': 'Among areas of software engineering where AI techniques -- particularly, Large Language Models -- seem poised to yield dramatic improvements, an attractive candidate is Automatic Program Repair (APR), the production of satisfactory corrections to software bugs. Does this expectation materialize in practice? How do we find out, making sure that proposed corrections actually work? If programmers have access to LLMs, how do they actually use them to complement their own skills?\nTo answer these questions, we took advantage of the availability of a program-proving environment, which formally determines the correctness of proposed fixes, to conduct a study of program debugging with two randomly assigned groups of programmers, one with access to LLMs and the other without, both validating their answers through the proof tools. The methodology relied on a division into general research questions (Goals in the Goal-Query-Metric approach), specific elements admitting specific answers (Queries), and measurements supporting these answers (Metrics). While applied so far to a limited sample size, the results are a first step towards delineating a proper role for AI and LLMs in providing guaranteed-correct fixes to program bugs.\nThese results caused surprise as compared to what one might expect from the use of AI for debugging and APR. The contributions also include: a detailed methodology for experiments in the use of LLMs for debugging, which other projects can reuse; a fine-grain analysis of programmer behavior, made possible by the use of full-session recording; a definition of patterns of use of LLMs, with 7 distinct categories; and validated advice for getting the best of LLMs for debugging and Automatic Program Repair.', 'abstract_zh': '在软件工程领域，特别是在自动程序修复（APR）方面，人工智能技术（尤其是大型语言模型）似乎有望带来显著改进。这一预期在实践中是否得以实现？我们如何确保提出的修正确实有效？如果程序员能够访问大型语言模型，他们实际上如何利用这些模型来补充自己的技能？\n\n为了回答这些问题，我们利用了一个正式验证程序修复正确性的环境，通过随机分组的两种程序员群体进行研究，一种群体可以访问大型语言模型，另一种则没有，两者通过证明工具验证其答案。该研究方法基于目标-查询-度量（Goal-Query-Metric）框架，分为一般研究目标、具体问题及其答案和支撑这些答案的测量指标。尽管目前只针对有限的样本规模进行了应用，但这些结果是探索人工智能和大型语言模型在提供程序故障确保正确修复中的适当角色的第一步。\n\n这些结果与预期的使用AI进行调试和自动程序修复有何不同，本研究还包括：一套详细的实验方法，其他项目可以 reuse；通过全会话录制进行的细粒度程序员行为分析；对大型语言模型使用模式的定义，包括7类不同类别；以及验证的建议，以充分利用大型语言模型进行调试和自动程序修复。', 'title_zh': 'AI模型有助于生成经过验证的 bug 修复吗？'}
{'arxiv_id': 'arXiv:2507.15775', 'title': 'Learning Null Geodesics for Gravitational Lensing Rendering in General Relativity', 'authors': 'Mingyuan Sun, Zheng Fang, Jiaxu Wang, Kunyi Zhang, Qiang Zhang, Renjing Xu', 'link': 'https://arxiv.org/abs/2507.15775', 'abstract': 'We present GravLensX, an innovative method for rendering black holes with gravitational lensing effects using neural networks. The methodology involves training neural networks to fit the spacetime around black holes and then employing these trained models to generate the path of light rays affected by gravitational lensing. This enables efficient and scalable simulations of black holes with optically thin accretion disks, significantly decreasing the time required for rendering compared to traditional methods. We validate our approach through extensive rendering of multiple black hole systems with superposed Kerr metric, demonstrating its capability to produce accurate visualizations with significantly $15\\times$ reduced computational time. Our findings suggest that neural networks offer a promising alternative for rendering complex astrophysical phenomena, potentially paving a new path to astronomical visualization.', 'abstract_zh': '基于神经网络的引力透镜效应黑洞渲染方法GravLensX', 'title_zh': '广义相对论中基于虚 geodesics 的引力透镜渲染学习'}
{'arxiv_id': 'arXiv:2507.15774', 'title': 'Dynamics is what you need for time-series forecasting!', 'authors': 'Alexis-Raja Brachet, Pierre-Yves Richard, Céline Hudelot', 'link': 'https://arxiv.org/abs/2507.15774', 'abstract': 'While boundaries between data modalities are vanishing, the usual successful deep models are still challenged by simple ones in the time-series forecasting task. Our hypothesis is that this task needs models that are able to learn the data underlying dynamics. We propose to validate it through both systemic and empirical studies. We develop an original $\\texttt{PRO-DYN}$ nomenclature to analyze existing models through the lens of dynamics. Two observations thus emerged: $\\textbf{1}$. under-performing architectures learn dynamics at most partially, $\\textbf{2}$. the location of the dynamics block at the model end is of prime importance. We conduct extensive experiments to confirm our observations on a set of performance-varying models with diverse backbones. Results support the need to incorporate a learnable dynamics block and its use as the final predictor.', 'abstract_zh': '尽管数据模态之间的界限正在消失，但在时间序列预测任务中，传统的成功深度模型仍然难以击败简单的模型。我们的假设是，这一任务需要能够学习数据内在动力学的模型。我们希望通过系统的和经验的研究来验证这一假设。我们开发了一种原创的$\\texttt{PRO-DYN}$命名法，以动力学的视角分析现有模型。由此产生了两个观察结果：$\\textbf{1}$．表现不佳的架构最多只能部分学习动力学，$\\textbf{2}$．动力学模块在模型末尾的位置至关重要。我们进行了广泛的实验，以不同的底层架构和性能变化的模型集来验证我们的观察结果。结果支持将可学习的动力学模块纳入模型，并将其用作最终预测器的需求。', 'title_zh': '动态性是时间序列预测所需的关键！'}
{'arxiv_id': 'arXiv:2507.15773', 'title': 'Supernova: Achieving More with Less in Transformer Architectures', 'authors': 'Andrei-Valentin Tanase, Elena Pelican', 'link': 'https://arxiv.org/abs/2507.15773', 'abstract': 'We present Supernova, a 650M-parameter decoder-only transformer that demonstrates how careful architectural design and tokenization innovation can achieve the performance of larger models while maintaining computational efficiency. Our architecture combines Rotary Positional Embeddings (RoPE), Grouped Query Attention (GQA) with a 3:1 compression ratio, RMSNorm for computational efficiency, and SwiGLU activation functions. A critical innovation is our custom 128,000-vocabulary byte-level BPE tokenizer, which achieves state-of-the-art compression performance. Through detailed analysis, we show that Supernova achieves 90% of the performance of 1B-parameter models while using 53% fewer parameters and requiring only 100B training tokens--an order of magnitude less than competing models. Our findings challenge the prevailing scaling paradigm, demonstrating that architectural efficiency and tokenization quality can compensate for reduced parameter counts.', 'abstract_zh': '我们呈现了 Supernova，一个6500万参数的解码器变压器模型，展示了精心的架构设计和令牌化创新如何在保持计算效率的同时实现与更大模型相当的性能。该架构结合了旋转位置嵌入（RoPE）、分组查询注意（GQA）与3:1的压缩比、RMSNorm以提高计算效率、SwiGLU激活函数。一项关键创新是我们的自定义128000词汇量的字级BPE分词器，实现了最先进的压缩性能。通过详细的分析，我们展示了 Supernova 在使用53%更少参数且仅需1000亿个训练令牌（比竞争模型少一个数量级）的情况下，达到了10亿参数模型90%的性能。我们的研究结果挑战了现有的规模范式，证明了架构效率与分词质量可以弥补参数数量的减少。', 'title_zh': 'Supernova: 在Transformer架构中用更少获取更多'}
{'arxiv_id': 'arXiv:2507.15772', 'title': 'Deep-Learning Investigation of Vibrational Raman Spectra for Plant-Stress Analysis', 'authors': 'Anoop C. Patil, Benny Jian Rong Sng, Yu-Wei Chang, Joana B. Pereira, Chua Nam-Hai, Rajani Sarojam, Gajendra Pratap Singh, In-Cheol Jang, Giovanni Volpe', 'link': 'https://arxiv.org/abs/2507.15772', 'abstract': 'Detecting stress in plants is crucial for both open-farm and controlled-environment agriculture. Biomolecules within plants serve as key stress indicators, offering vital markers for continuous health monitoring and early disease detection. Raman spectroscopy provides a powerful, non-invasive means to quantify these biomolecules through their molecular vibrational signatures. However, traditional Raman analysis relies on customized data-processing workflows that require fluorescence background removal and prior identification of Raman peaks of interest-introducing potential biases and inconsistencies. Here, we introduce DIVA (Deep-learning-based Investigation of Vibrational Raman spectra for plant-stress Analysis), a fully automated workflow based on a variational autoencoder. Unlike conventional approaches, DIVA processes native Raman spectra-including fluorescence backgrounds-without manual preprocessing, identifying and quantifying significant spectral features in an unbiased manner. We applied DIVA to detect a range of plant stresses, including abiotic (shading, high light intensity, high temperature) and biotic stressors (bacterial infections). By integrating deep learning with vibrational spectroscopy, DIVA paves the way for AI-driven plant health assessment, fostering more resilient and sustainable agricultural practices.', 'abstract_zh': '基于深度学习的振动拉曼光谱植物胁迫分析DIVA', 'title_zh': '深度学习在植物压力分析中的振动拉曼光谱研究'}
{'arxiv_id': 'arXiv:2507.15771', 'title': 'Left Leaning Models: AI Assumptions on Economic Policy', 'authors': 'Maxim Chupilkin', 'link': 'https://arxiv.org/abs/2507.15771', 'abstract': "How does AI think about economic policy? While the use of large language models (LLMs) in economics is growing exponentially, their assumptions on economic issues remain a black box. This paper uses a conjoint experiment to tease out the main factors influencing LLMs' evaluation of economic policy. It finds that LLMs are most sensitive to unemployment, inequality, financial stability, and environmental harm and less sensitive to traditional macroeconomic concerns such as economic growth, inflation, and government debt. The results are remarkably consistent across scenarios and across models.", 'abstract_zh': 'AI是如何思考经济政策的？使用大规模语言模型（LLM）在经济学领域的应用 burgeoning 越来越广泛，但它们在经济问题上的假设仍是一个黑箱。本文通过联合实验探讨了影响LLM评估经济政策的主要因素。研究发现，LLM对失业、不平等、金融稳定和环境损害最为敏感，对传统的宏观经济关注点如经济增长、通货膨胀和政府债务则相对不敏感。结果在不同情景和不同模型间表现出惊人的一致性。', 'title_zh': '左倾模型：AI对经济政策的假设'}
{'arxiv_id': 'arXiv:2507.15753', 'title': 'DiffuMeta: Algebraic Language Models for Inverse Design of Metamaterials via Diffusion Transformers', 'authors': 'Li Zheng, Siddhant Kumar, Dennis M. Kochmann', 'link': 'https://arxiv.org/abs/2507.15753', 'abstract': 'Generative machine learning models have revolutionized material discovery by capturing complex structure-property relationships, yet extending these approaches to the inverse design of three-dimensional metamaterials remains limited by computational complexity and underexplored design spaces due to the lack of expressive representations. Here, we present DiffuMeta, a generative framework integrating diffusion transformers with a novel algebraic language representation, encoding 3D geometries as mathematical sentences. This compact, unified parameterization spans diverse topologies while enabling direct application of transformers to structural design. DiffuMeta leverages diffusion models to generate novel shell structures with precisely targeted stress-strain responses under large deformations, accounting for buckling and contact while addressing the inherent one-to-many mapping by producing diverse solutions. Uniquely, our approach enables simultaneous control over multiple mechanical objectives, including linear and nonlinear responses beyond training domains. Experimental validation of fabricated structures further confirms the efficacy of our approach for accelerated design of metamaterials and structures with tailored properties.', 'abstract_zh': '基于扩散变换器的新型代数语言表示的生成模型DiffuMeta在三维 metamaterial 逆设计中的应用', 'title_zh': 'DiffuMeta：通过扩散变压器进行超材料逆设计的代数语言模型'}
{'arxiv_id': 'arXiv:2507.15718', 'title': 'Explainable Anomaly Detection for Electric Vehicles Charging Stations', 'authors': 'Matteo Cederle, Andrea Mazzucco, Andrea Demartini, Eugenio Mazza, Eugenia Suriani, Federico Vitti, Gian Antonio Susto', 'link': 'https://arxiv.org/abs/2507.15718', 'abstract': 'Electric vehicles (EV) charging stations are one of the critical infrastructures needed to support the transition to renewable-energy-based mobility, but ensuring their reliability and efficiency requires effective anomaly detection to identify irregularities in charging behavior. However, in such a productive scenario, it is also crucial to determine the underlying cause behind the detected anomalies. To achieve this goal, this study investigates unsupervised anomaly detection techniques for EV charging infrastructure, integrating eXplainable Artificial Intelligence techniques to enhance interpretability and uncover root causes of anomalies.\nUsing real-world sensors and charging session data, this work applies Isolation Forest to detect anomalies and employs the Depth-based Isolation Forest Feature Importance (DIFFI) method to identify the most important features contributing to such anomalies. The efficacy of the proposed approach is evaluated in a real industrial case.', 'abstract_zh': '电动汽车（EV）充电站是支持向基于可再生能源的移动性过渡的关键基础设施，但确保其可靠性和效率需要有效的异常检测来识别充电行为中的不规则性。然而，在这种生产性场景中，确定检测到的异常背后的根本原因同样至关重要。为此，本研究调查了电动汽车充电基础设施的无监督异常检测技术，并结合可解释的人工智能技术以增强可解释性并揭示异常的根本原因。利用实际传感器和充电会话数据，本研究应用隔离森林检测异常，并采用基于深度的隔离森林特征重要性（DIFFI）方法来识别对这些异常贡献最大的特征。所提出方法的有效性在实际工业案例中进行了评估。', 'title_zh': '可解释的电动汽车充电站异常检测'}
{'arxiv_id': 'arXiv:2507.15706', 'title': 'Compositional Understanding in Signaling Games', 'authors': 'David Peter Wallis Freeborn', 'link': 'https://arxiv.org/abs/2507.15706', 'abstract': 'Receivers in standard signaling game models struggle with learning compositional information. Even when the signalers send compositional messages, the receivers do not interpret them compositionally. When information from one message component is lost or forgotten, the information from other components is also erased. In this paper I construct signaling game models in which genuine compositional understanding evolves. I present two new models: a minimalist receiver who only learns from the atomic messages of a signal, and a generalist receiver who learns from all of the available information. These models are in many ways simpler than previous alternatives, and allow the receivers to learn from the atomic components of messages.', 'abstract_zh': '标准信号博弈模型中的接收者在学习组合信息方面存在困难。即使信号者发送组合消息，接收者也不会进行组合解释。当一条消息的一个成分的信息丢失或被遗忘时，其他成分的信息也会被抹去。在本文中，我构建了使真正的组合理解得以演化的信号博弈模型。文中提出了两个新模型：一个只从信号的原子消息中学习的简约接收者，以及一个从所有可用信息中学习的一般接收者。这些模型在很多方面比以往的替代模型更为简单，从而使接收者能够从消息的原子成分中学习。', 'title_zh': '信号博弈中的组合理解'}
{'arxiv_id': 'arXiv:2507.15686', 'title': 'LINR-PCGC: Lossless Implicit Neural Representations for Point Cloud Geometry Compression', 'authors': 'Wenjie Huang, Qi Yang, Shuting Xia, He Huang, Zhu Li, Yiling Xu', 'link': 'https://arxiv.org/abs/2507.15686', 'abstract': 'Existing AI-based point cloud compression methods struggle with dependence on specific training data distributions, which limits their real-world deployment. Implicit Neural Representation (INR) methods solve the above problem by encoding overfitted network parameters to the bitstream, resulting in more distribution-agnostic results. However, due to the limitation of encoding time and decoder size, current INR based methods only consider lossy geometry compression. In this paper, we propose the first INR based lossless point cloud geometry compression method called Lossless Implicit Neural Representations for Point Cloud Geometry Compression (LINR-PCGC). To accelerate encoding speed, we design a group of point clouds level coding framework with an effective network initialization strategy, which can reduce around 60% encoding time. A lightweight coding network based on multiscale SparseConv, consisting of scale context extraction, child node prediction, and model compression modules, is proposed to realize fast inference and compact decoder size. Experimental results show that our method consistently outperforms traditional and AI-based methods: for example, with the convergence time in the MVUB dataset, our method reduces the bitstream by approximately 21.21% compared to G-PCC TMC13v23 and 21.95% compared to SparsePCGC. Our project can be seen on this https URL.', 'abstract_zh': '基于隐式神经表示的无损点云几何压缩方法（LINR-PCGC）', 'title_zh': 'LINR-PCGC：点云几何无损隐式神经表示压缩'}
{'arxiv_id': 'arXiv:2507.15681', 'title': 'Missing value imputation with adversarial random forests -- MissARF', 'authors': 'Pegah Golchian, Jan Kapar, David S. Watson, Marvin N. Wright', 'link': 'https://arxiv.org/abs/2507.15681', 'abstract': 'Handling missing values is a common challenge in biostatistical analyses, typically addressed by imputation methods. We propose a novel, fast, and easy-to-use imputation method called missing value imputation with adversarial random forests (MissARF), based on generative machine learning, that provides both single and multiple imputation. MissARF employs adversarial random forest (ARF) for density estimation and data synthesis. To impute a missing value of an observation, we condition on the non-missing values and sample from the estimated conditional distribution generated by ARF. Our experiments demonstrate that MissARF performs comparably to state-of-the-art single and multiple imputation methods in terms of imputation quality and fast runtime with no additional costs for multiple imputation.', 'abstract_zh': '基于生成机器学习的对抗随机森林缺失值填充方法（MissARF）', 'title_zh': '基于生成对抗森林的缺失值填充——MissARF'}
{'arxiv_id': 'arXiv:2507.15663', 'title': 'SustainDiffusion: Optimising the Social and Environmental Sustainability of Stable Diffusion Models', 'authors': "Giordano d'Aloisio, Tosin Fadahunsi, Jay Choy, Rebecca Moussa, Federica Sarro", 'link': 'https://arxiv.org/abs/2507.15663', 'abstract': "Background: Text-to-image generation models are widely used across numerous domains. Among these models, Stable Diffusion (SD) - an open-source text-to-image generation model - has become the most popular, producing over 12 billion images annually. However, the widespread use of these models raises concerns regarding their social and environmental sustainability.\nAims: To reduce the harm that SD models may have on society and the environment, we introduce SustainDiffusion, a search-based approach designed to enhance the social and environmental sustainability of SD models.\nMethod: SustainDiffusion searches the optimal combination of hyperparameters and prompt structures that can reduce gender and ethnic bias in generated images while also lowering the energy consumption required for image generation. Importantly, SustainDiffusion maintains image quality comparable to that of the original SD model.\nResults: We conduct a comprehensive empirical evaluation of SustainDiffusion, testing it against six different baselines using 56 different prompts. Our results demonstrate that SustainDiffusion can reduce gender bias in SD3 by 68%, ethnic bias by 59%, and energy consumption (calculated as the sum of CPU and GPU energy) by 48%. Additionally, the outcomes produced by SustainDiffusion are consistent across multiple runs and can be generalised to various prompts.\nConclusions: With SustainDiffusion, we demonstrate how enhancing the social and environmental sustainability of text-to-image generation models is possible without fine-tuning or changing the model's architecture.", 'abstract_zh': '背景：文本生成图像模型在众多领域得到广泛应用。在这些模型中，开源文本生成图像模型稳定扩散（SD）已成为最受欢迎的模型，每年生成超过120亿张图像。然而，这些模型的广泛应用引发了对其社会和环境可持续性的担忧。\n目标：为了减少SD模型对社会和环境可能造成的损害，我们提出了SustainDiffusion，一种基于搜索的的方法，旨在增强SD模型的社会和环境可持续性。\n方法：SustainDiffusion搜索出能在降低生成图像中的性别和种族偏见的同时，降低图像生成所需能耗的最佳超参数和提示结构组合。重要的是，SustainDiffusion保持了与原始SD模型相当的图像质量。\n结果：我们对SustainDiffusion进行了全面的实际测试，使用56种不同提示符与六个不同基线进行对比。结果表明，SustainDiffusion可以将SD3中的性别偏见降低68%，种族偏见降低59%，能耗（以CPU和GPU能耗总和计算）降低48%。此外，SustainDiffusion生成的结果在多次运行中保持一致，并且可以适用于多种提示符。\n结论：通过SustainDiffusion，我们展示了在不调整或更改模型架构的情况下增强文本生成图像模型的社会和环境可持续性是可行的。', 'title_zh': 'SustainDiffusion: 优化稳定扩散模型的社交与环境可持续性'}
{'arxiv_id': 'arXiv:2507.15643', 'title': 'Towards Explainable Anomaly Detection in Shared Mobility Systems', 'authors': 'Elnur Isgandarov, Matteo Cederle, Federico Chiariotti, Gian Antonio Susto', 'link': 'https://arxiv.org/abs/2507.15643', 'abstract': 'Shared mobility systems, such as bike-sharing networks, play a crucial role in urban transportation. Identifying anomalies in these systems is essential for optimizing operations, improving service reliability, and enhancing user experience. This paper presents an interpretable anomaly detection framework that integrates multi-source data, including bike-sharing trip records, weather conditions, and public transit availability. The Isolation Forest algorithm is employed for unsupervised anomaly detection, along with the Depth-based Isolation Forest Feature Importance (DIFFI) algorithm providing interpretability. Results show that station-level analysis offers a robust understanding of anomalies, highlighting the influence of external factors such as adverse weather and limited transit availability. Our findings contribute to improving decision-making in shared mobility operations.', 'abstract_zh': '共享 mobility 系统中的异常检测：多源数据集成的可解释框架', 'title_zh': '在共享移动系统中可解释的异常检测owards Explainable Anomaly Detection in Shared Mobility Systems'}
{'arxiv_id': 'arXiv:2507.15636', 'title': 'Uncovering Critical Features for Deepfake Detection through the Lottery Ticket Hypothesis', 'authors': 'Lisan Al Amin, Md. Ismail Hossain, Thanh Thi Nguyen, Tasnim Jahan, Mahbubul Islam, Faisal Quader', 'link': 'https://arxiv.org/abs/2507.15636', 'abstract': 'Recent advances in deepfake technology have created increasingly convincing synthetic media that poses significant challenges to information integrity and social trust. While current detection methods show promise, their underlying mechanisms remain poorly understood, and the large sizes of their models make them challenging to deploy in resource-limited environments. This study investigates the application of the Lottery Ticket Hypothesis (LTH) to deepfake detection, aiming to identify the key features crucial for recognizing deepfakes. We examine how neural networks can be efficiently pruned while maintaining high detection accuracy. Through extensive experiments with MesoNet, CNN-5, and ResNet-18 architectures on the OpenForensic and FaceForensics++ datasets, we find that deepfake detection networks contain winning tickets, i.e., subnetworks, that preserve performance even at substantial sparsity levels. Our results indicate that MesoNet retains 56.2% accuracy at 80% sparsity on the OpenForensic dataset, with only 3,000 parameters, which is about 90% of its baseline accuracy (62.6%). The results also show that our proposed LTH-based iterative magnitude pruning approach consistently outperforms one-shot pruning methods. Using Grad-CAM visualization, we analyze how pruned networks maintain their focus on critical facial regions for deepfake detection. Additionally, we demonstrate the transferability of winning tickets across datasets, suggesting potential for efficient, deployable deepfake detection systems.', 'abstract_zh': '近年来，深度造假技术的进步创造了越来越逼真的合成媒体，对信息完整性和社会信任构成了重大挑战。尽管现有的检测方法显示出希望，但其 underlying机制仍不完全理解，且模型规模庞大，使得它们在资源受限环境中难以部署。本研究探索了在深度造假检测中应用彩票票假说（LTH）的应用，旨在识别出识别深度造假的关键特征。我们研究了在保持高检测准确性的前提下，如何高效地对神经网络进行剪枝。通过在OpenForensic和FaceForensics++数据集上对MesoNet、CNN-5和ResNet-18架构进行广泛实验，我们发现深度造假检测网络包含能在高稀疏度下保持性能的“赢票”，即子网络。我们的结果表明，MesoNet在OpenForensic数据集上的稀疏度达到80%时，仍能保持56.2%的准确率，仅需3,000个参数，大约为基线准确率（62.6%）的90%。此外，我们的基于LTH的逐次量纲剪枝方法在所有网络剪枝方法中表现更优。通过Grad-CAM可视化，我们分析了剪枝网络如何保持对深度造假检测至关重要的面部区域的关注。此外，我们展示了“赢票”的跨数据集可迁移性，这表明有潜力开发高效且可部署的深度造假检测系统。', 'title_zh': '通过彩票票假设发现深度假帧检测的关键特征'}
{'arxiv_id': 'arXiv:2507.15617', 'title': "Why can't Epidemiology be automated (yet)?", 'authors': 'David Bann, Ed Lowther, Liam Wright, Yevgeniya Kovalchuk', 'link': 'https://arxiv.org/abs/2507.15617', 'abstract': 'Recent advances in artificial intelligence (AI) - particularly generative AI - present new opportunities to accelerate, or even automate, epidemiological research. Unlike disciplines based on physical experimentation, a sizable fraction of Epidemiology relies on secondary data analysis and thus is well-suited for such augmentation. Yet, it remains unclear which specific tasks can benefit from AI interventions or where roadblocks exist. Awareness of current AI capabilities is also mixed. Here, we map the landscape of epidemiological tasks using existing datasets - from literature review to data access, analysis, writing up, and dissemination - and identify where existing AI tools offer efficiency gains. While AI can increase productivity in some areas such as coding and administrative tasks, its utility is constrained by limitations of existing AI models (e.g. hallucinations in literature reviews) and human systems (e.g. barriers to accessing datasets). Through examples of AI-generated epidemiological outputs, including fully AI-generated papers, we demonstrate that recently developed agentic systems can now design and execute epidemiological analysis, albeit to varied quality (see this https URL). Epidemiologists have new opportunities to empirically test and benchmark AI systems; realising the potential of AI will require two-way engagement between epidemiologists and engineers.', 'abstract_zh': '近期人工智能的发展——特别是生成式人工智能——为加速乃至自动化流行病学研究提供了新机遇。', 'title_zh': '为什么流行病学尚不能（也未能）自动化（暂且如此）'}
{'arxiv_id': 'arXiv:2507.15614', 'title': 'Accelerating HEC-RAS: A Recurrent Neural Operator for Rapid River Forecasting', 'authors': 'Edward Holmberg, Pujan Pokhrel, Maximilian Zoch, Elias Ioup, Ken Pathak, Steven Sloan, Kendall Niles, Jay Ratcliff, Maik Flanagin, Christian Guetl, Julian Simeonov, Mahdi Abdelguerfi', 'link': 'https://arxiv.org/abs/2507.15614', 'abstract': 'Physics-based solvers like HEC-RAS provide high-fidelity river forecasts but are too computationally intensive for on-the-fly decision-making during flood events. The central challenge is to accelerate these simulations without sacrificing accuracy. This paper introduces a deep learning surrogate that treats HEC-RAS not as a solver but as a data-generation engine. We propose a hybrid, auto-regressive architecture that combines a Gated Recurrent Unit (GRU) to capture short-term temporal dynamics with a Geometry-Aware Fourier Neural Operator (Geo-FNO) to model long-range spatial dependencies along a river reach. The model learns underlying physics implicitly from a minimal eight-channel feature vector encoding dynamic state, static geometry, and boundary forcings extracted directly from native HEC-RAS files. Trained on 67 reaches of the Mississippi River Basin, the surrogate was evaluated on a year-long, unseen hold-out simulation. Results show the model achieves a strong predictive accuracy, with a median absolute stage error of 0.31 feet. Critically, for a full 67-reach ensemble forecast, our surrogate reduces the required wall-clock time from 139 minutes to 40 minutes, a speedup of nearly 3.5 times over the traditional solver. The success of this data-driven approach demonstrates that robust feature engineering can produce a viable, high-speed replacement for conventional hydraulic models, improving the computational feasibility of large-scale ensemble flood forecasting.', 'abstract_zh': '基于物理的替代方案：一种深度学习加速器在不牺牲准确性的情况下，将HEC-RAS用于洪水事件中的实时决策预测', 'title_zh': '加速HEC-RAS：一种循环神经运算器快速河流预报'}
{'arxiv_id': 'arXiv:2507.15574', 'title': 'On the Role of AI in Managing Satellite Constellations: Insights from the ConstellAI Project', 'authors': 'Gregory F. Stock, Juan A. Fraire, Holger Hermanns, Jędrzej Mosiężny, Yusra Al-Khazraji, Julio Ramírez Molina, Evridiki V. Ntagiou', 'link': 'https://arxiv.org/abs/2507.15574', 'abstract': 'The rapid expansion of satellite constellations in near-Earth orbits presents significant challenges in satellite network management, requiring innovative approaches for efficient, scalable, and resilient operations. This paper explores the role of Artificial Intelligence (AI) in optimizing the operation of satellite mega-constellations, drawing from the ConstellAI project funded by the European Space Agency (ESA). A consortium comprising GMV GmbH, Saarland University, and Thales Alenia Space collaborates to develop AI-driven algorithms and demonstrates their effectiveness over traditional methods for two crucial operational challenges: data routing and resource allocation. In the routing use case, Reinforcement Learning (RL) is used to improve the end-to-end latency by learning from historical queuing latency, outperforming classical shortest path algorithms. For resource allocation, RL optimizes the scheduling of tasks across constellations, focussing on efficiently using limited resources such as battery and memory. Both use cases were tested for multiple satellite constellation configurations and operational scenarios, resembling the real-life spacecraft operations of communications and Earth observation satellites. This research demonstrates that RL not only competes with classical approaches but also offers enhanced flexibility, scalability, and generalizability in decision-making processes, which is crucial for the autonomous and intelligent management of satellite fleets. The findings of this activity suggest that AI can fundamentally alter the landscape of satellite constellation management by providing more adaptive, robust, and cost-effective solutions.', 'abstract_zh': '近地轨道卫星星座的迅速扩展给卫星网络管理带来了重大挑战，需要创新的方法实现高效、可扩展和鲁棒的操作。本文探讨了人工智能（AI）在优化卫星巨星座运行中的作用，以 ESA 资助的 ConstellAI 项目为基础。由 GMV GmbH、Saarland University 和 Thales Alenia Space 组成的联盟开发了 AI 驱动的算法，并在数据路由和资源分配这两个关键操作挑战中，展示了这些算法比传统方法更有效。在路由用例中，使用强化学习（RL）通过学习历史排队延迟来提高端到端延迟，优于经典的最短路径算法。在资源分配用例中，使用 RL 优化了跨星座的任务调度，特别是在高效利用有限的电池和内存资源方面。这两种用例均在多种卫星星座配置和操作场景中进行了测试，模拟了通信和地球观测卫星的实际航天器操作。这项研究证明，RL 不仅可以与经典方法竞争，还可以在决策过程中提供更高的灵活性、可扩展性和通用性，这对于实现卫星舰队的自主和智能管理至关重要。该活动的研究结果表明，AI 有可能通过提供更适应性、更稳健和成本效益更高的解决方案，从根本上改变卫星星座管理的格局。', 'title_zh': 'AI在管理卫星星座中的作用：ConstellAI项目见解'}
{'arxiv_id': 'arXiv:2507.15507', 'title': 'Off-Policy Corrected Reward Modeling for Reinforcement Learning from Human Feedback', 'authors': 'Johannes Ackermann, Takashi Ishida, Masashi Sugiyama', 'link': 'https://arxiv.org/abs/2507.15507', 'abstract': 'Reinforcement Learning from Human Feedback (RLHF) allows us to train models, such as language models (LMs), to follow complex human preferences. In RLHF for LMs, we first train an LM using supervised fine-tuning, sample pairs of responses, obtain human feedback, and use the resulting data to train a reward model (RM). RL methods are then used to train the LM to maximize the reward given by the RM. As training progresses, the responses generated by the LM no longer resemble the responses seen by the RM during training, leading to the RM becoming inaccurate. The score given by the RM keeps increasing, but the learned behavior no longer matches the human preferences. This issue is known as overoptimization. We investigate overoptimization from the point of view of distribution shift and show that the shift results in an inconsistent estimate of the RM parameters, leading to an inconsistent estimate of the policy gradient. We propose Off-Policy Corrected Reward Modeling (OCRM), which iteratively off-policy corrects the RM using importance weighting, without requiring new labels or samples. This results in a more accurate RM, which empirically leads to an improved final policy. We validate our approach in experiments with summarization and chatbot datasets and show that it performs significantly better than standard RLHF methods and baselines. Our implementation is available at this https URL', 'abstract_zh': '基于人类反馈的强化学习（RLHF）使我们能够训练模型，如语言模型（LMs），使其遵循复杂的人类偏好。在LM的RLHF中，我们首先使用监督微调训练一个LM，采样响应对，获取人类反馈，并使用所得数据训练一个奖励模型（RM）。然后使用强化学习方法训练LM，使其最大化RM给出的奖励。随着训练的进行，LM生成的响应不再类似于RM在训练期间看到的响应，导致RM变得不准确。RM给出的分数持续增加，但学习到的行为不再符合人类偏好。这一问题称为过度优化。我们从分布转移的角度探讨了过度优化问题，并表明转移导致了RM参数的一致性估计不足，进而导致了策略梯度的一致性估计不足。我们提出了基于离策重要性加权修正的奖励建模（OCRM），它可以迭代地使用重要性加权修正RM，无需新标签或样本。这导致了更准确的RM，从实验结果来看，这提高了最终策略的性能。我们在摘要和聊天机器人数据集上的实验验证了我们的方法，并显示它在标准RLHF方法和基线方法中表现显著更好。我们的实现可在以下链接获得：this https URL。', 'title_zh': '基于人类反馈的离策纠正奖励建模'}
{'arxiv_id': 'arXiv:2507.15455', 'title': 'Solving nonconvex Hamilton--Jacobi--Isaacs equations with PINN-based policy iteration', 'authors': 'Hee Jun Yang, Min Jung Kim, Yeoneung Kim', 'link': 'https://arxiv.org/abs/2507.15455', 'abstract': 'We propose a mesh-free policy iteration framework that combines classical dynamic programming with physics-informed neural networks (PINNs) to solve high-dimensional, nonconvex Hamilton--Jacobi--Isaacs (HJI) equations arising in stochastic differential games and robust control. The method alternates between solving linear second-order PDEs under fixed feedback policies and updating the controls via pointwise minimax optimization using automatic differentiation. Under standard Lipschitz and uniform ellipticity assumptions, we prove that the value function iterates converge locally uniformly to the unique viscosity solution of the HJI equation. The analysis establishes equi-Lipschitz regularity of the iterates, enabling provable stability and convergence without requiring convexity of the Hamiltonian. Numerical experiments demonstrate the accuracy and scalability of the method. In a two-dimensional stochastic path-planning game with a moving obstacle, our method matches finite-difference benchmarks with relative $L^2$-errors below %10^{-2}%. In five- and ten-dimensional publisher-subscriber differential games with anisotropic noise, the proposed approach consistently outperforms direct PINN solvers, yielding smoother value functions and lower residuals. Our results suggest that integrating PINNs with policy iteration is a practical and theoretically grounded method for solving high-dimensional, nonconvex HJI equations, with potential applications in robotics, finance, and multi-agent reinforcement learning.', 'abstract_zh': '我们提出了一种基于经典动态规划与物理知情神经网络（PINNs）的无网格策略迭代框架，以解决随机微分博弈和鲁棒控制中出现的高维非凸哈密尔顿-雅可比-伊萨acs（HJI）方程。该方法交替进行在固定反馈策略下求解线性二阶偏微分方程和通过点态最小最大优化更新控制，并利用自动微分。在标准Lipschitz和均匀椭圆性假设下，我们证明了值函数迭代局部一致收敛到HJI方程的唯一 viscosity 解。分析表明迭代具有统一Lipschitz正则性，从而在无需Hamiltonian凸性的条件下确保证明的稳定性和收敛性。数值实验展示了该方法的准确性和可扩展性。在二维存在移动障碍的随机路径规划博弈中，该方法相对$L^2$误差低于$10^{-2}$%，与有限差分基准方法相当。在五维和十维具有各向异性噪声的出版商-订阅者微分博弈中，所提出的方法始终优于直接PINN求解器，得到更平滑的值函数和更低的残差。我们的结果表明，将PINNs与策略迭代集成是一种解决高维非凸HJI方程的实用且理论上有依据的方法，具有在机器人技术、金融和多智能体强化学习中的潜在应用。', 'title_zh': '基于PINN的策略迭代求解非凸哈密顿-雅可比-伊萨acs方程'}
{'arxiv_id': 'arXiv:2507.15396', 'title': 'Neuro-MSBG: An End-to-End Neural Model for Hearing Loss Simulation', 'authors': 'Hui-Guan Yuan, Ryandhimas E. Zezario, Shafique Ahmed, Hsin-Min Wang, Kai-Lung Hua, Yu Tsao', 'link': 'https://arxiv.org/abs/2507.15396', 'abstract': "Hearing loss simulation models are essential for hearing aid deployment. However, existing models have high computational complexity and latency, which limits real-time applications and lack direct integration with speech processing systems. To address these issues, we propose Neuro-MSBG, a lightweight end-to-end model with a personalized audiogram encoder for effective time-frequency modeling. Experiments show that Neuro-MSBG supports parallel inference and retains the intelligibility and perceptual quality of the original MSBG, with a Spearman's rank correlation coefficient (SRCC) of 0.9247 for Short-Time Objective Intelligibility (STOI) and 0.8671 for Perceptual Evaluation of Speech Quality (PESQ). Neuro-MSBG reduces simulation runtime by a factor of 46 (from 0.970 seconds to 0.021 seconds for a 1 second input), further demonstrating its efficiency and practicality.", 'abstract_zh': '听力损失模拟模型对于助听器部署至关重要。然而，现有模型具有较高的计算复杂度和延迟，限制了实时应用并缺乏与语音处理系统的直接集成。为解决这些问题，我们提出了一种轻量级端到端模型Neuro-MSBG，该模型具有个性化的 audiogram 编码器，以实现有效的时频建模。实验表明，Neuro-MSBG 支持并行推理，保留了原始 MSBG 的可懂度和感知质量，在 Short-Time Objective Intelligibility (STOI) 的 Spearman’s 秩相关系数 (SRCC) 为 0.9247，Perceptual Evaluation of Speech Quality (PESQ) 的 SRCC 为 0.8671。Neuro-MSBG 将仿真运行时间减少了 46 倍（从 1 秒输入的 0.970 秒降至 0.021 秒），进一步证明了其高效性和实用性。', 'title_zh': '神经-MSBG：一种端到端的神经模型用于模拟听力损失'}
{'arxiv_id': 'arXiv:2507.15381', 'title': 'To Label or Not to Label: PALM -- A Predictive Model for Evaluating Sample Efficiency in Active Learning Models', 'authors': 'Julia Machnio, Mads Nielsen, Mostafa Mehdipour Ghazi', 'link': 'https://arxiv.org/abs/2507.15381', 'abstract': 'Active learning (AL) seeks to reduce annotation costs by selecting the most informative samples for labeling, making it particularly valuable in resource-constrained settings. However, traditional evaluation methods, which focus solely on final accuracy, fail to capture the full dynamics of the learning process. To address this gap, we propose PALM (Performance Analysis of Active Learning Models), a unified and interpretable mathematical model that characterizes AL trajectories through four key parameters: achievable accuracy, coverage efficiency, early-stage performance, and scalability. PALM provides a predictive description of AL behavior from partial observations, enabling the estimation of future performance and facilitating principled comparisons across different strategies. We validate PALM through extensive experiments on CIFAR-10/100 and ImageNet-50/100/200, covering a wide range of AL methods and self-supervised embeddings. Our results demonstrate that PALM generalizes effectively across datasets, budgets, and strategies, accurately predicting full learning curves from limited labeled data. Importantly, PALM reveals crucial insights into learning efficiency, data space coverage, and the scalability of AL methods. By enabling the selection of cost-effective strategies and predicting performance under tight budget constraints, PALM lays the basis for more systematic, reproducible, and data-efficient evaluation of AL in both research and real-world applications. The code is available at: this https URL.', 'abstract_zh': '基于性能分析的主动学习模型（PALM）：一种统一且可解释的数学模型', 'title_zh': '标注还是不标注：PALM——一种评估主动学习模型样本效率的预测模型'}
{'arxiv_id': 'arXiv:2507.15367', 'title': 'Multi-beam Beamforming in RIS-aided MIMO Subject to Reradiation Mask Constraints -- Optimization and Machine Learning Design', 'authors': 'Shumin Wang, Hajar El Hassani, Marco Di Renzo, Marios Poulakis', 'link': 'https://arxiv.org/abs/2507.15367', 'abstract': 'Reconfigurable intelligent surfaces (RISs) are an emerging technology for improving spectral efficiency and reducing power consumption in future wireless systems. This paper investigates the joint design of the transmit precoding matrices and the RIS phase shift vector in a multi-user RIS-aided multiple-input multiple-output (MIMO) communication system. We formulate a max-min optimization problem to maximize the minimum achievable rate while considering transmit power and reradiation mask constraints. The achievable rate is simplified using the Arimoto-Blahut algorithm, and the problem is broken into quadratic programs with quadratic constraints (QPQC) sub-problems using an alternating optimization approach. To improve efficiency, we develop a model-based neural network optimization that utilizes the one-hot encoding for the angles of incidence and reflection. We address practical RIS limitations by using a greedy search algorithm to solve the optimization problem for discrete phase shifts. Simulation results demonstrate that the proposed methods effectively shape the multi-beam radiation pattern towards desired directions while satisfying reradiation mask constraints. The neural network design reduces the execution time, and the discrete phase shift scheme performs well with a small reduction of the beamforming gain by using only four phase shift levels.', 'abstract_zh': '基于RIS辅助多用户MIMO通信系统的传输前编码矩阵与RIS相位移向量联合设计', 'title_zh': 'RIS辅助MIMO系统中受限再辐射掩模的多波束波束形成——优化与机器学习设计'}
{'arxiv_id': 'arXiv:2507.15364', 'title': 'EEG-based Epileptic Prediction via a Two-stage Channel-aware Set Transformer Network', 'authors': 'Ruifeng Zheng, Cong Chen, Shuang Wang, Yiming Liu, Lin You, Jindong Lu, Ruizhe Zhu, Guodao Zhang, Kejie Huang', 'link': 'https://arxiv.org/abs/2507.15364', 'abstract': "Epilepsy is a chronic, noncommunicable brain disorder, and sudden seizure onsets can significantly impact patients' quality of life and health. However, wearable seizure-predicting devices are still limited, partly due to the bulky size of EEG-collecting devices. To relieve the problem, we proposed a novel two-stage channel-aware Set Transformer Network that could perform seizure prediction with fewer EEG channel sensors. We also tested a seizure-independent division method which could prevent the adjacency of training and test data. Experiments were performed on the CHB-MIT dataset which includes 22 patients with 88 merged seizures. The mean sensitivity before channel selection was 76.4% with a false predicting rate (FPR) of 0.09/hour. After channel selection, dominant channels emerged in 20 out of 22 patients; the average number of channels was reduced to 2.8 from 18; and the mean sensitivity rose to 80.1% with an FPR of 0.11/hour. Furthermore, experimental results on the seizure-independent division supported our assertion that a more rigorous seizure-independent division should be used for patients with abundant EEG recordings.", 'abstract_zh': '癫痫是一种慢性非传染性的脑部疾病，突然的发作会对患者的日常生活和健康产生显著影响。然而，可穿戴的癫痫预测设备仍然有限，部分原因是EEG采集设备体积较大。为了解决这一问题，我们提出了一种新型两阶段通道感知的Set Transformer网络，能够在较少的EEG通道传感器下进行癫痫预测。我们还测试了一种与癫痫无关的划分方法，以防止训练数据和测试数据的邻近。实验在包含22位患者和88次合并癫痫发作的CHB-MIT数据集上进行。在通道选择前，平均灵敏度为76.4%，假阳性率为0.09/小时。在通道选择后，有20名患者出现了主导通道，通道平均数量从18减少到2.8，平均灵敏度提高到80.1%，假阳性率为0.11/小时。此外，对与癫痫无关的划分进行的实验结果支持了我们的观点，即对于EEG记录丰富的患者，应使用更严格的与癫痫无关的划分方法。', 'title_zh': '基于EEG的双阶段通道aware集合变换网络癫痫预测'}
{'arxiv_id': 'arXiv:2507.15336', 'title': 'Beyond Model Base Selection: Weaving Knowledge to Master Fine-grained Neural Network Design', 'authors': 'Jialiang Wang, Hanmo Liu, Shimin Di, Zhili Wang, Jiachuan Wang, Lei Chen, Xiaofang Zhou', 'link': 'https://arxiv.org/abs/2507.15336', 'abstract': "Database systems have recently advocated for embedding machine learning (ML) capabilities, offering declarative model queries over large, managed model repositories, thereby circumventing the huge computational overhead of traditional ML-based algorithms in automated neural network model selection. Pioneering database studies aim to organize existing benchmark repositories as model bases (MB), querying them for the model records with the highest performance estimation metrics for given tasks. However, this static model selection practice overlooks the fine-grained, evolving relational dependencies between diverse task queries and model architecture variations, resulting in suboptimal matches and failing to further refine the model effectively. To fill the model refinement gap in database research, we propose M-DESIGN, a curated model knowledge base (MKB) pipeline for mastering neural network refinement by adaptively weaving prior insights about model architecture modification. First, we propose a knowledge weaving engine that reframes model refinement as an adaptive query problem over task metadata. Given a user's task query, M-DESIGN quickly matches and iteratively refines candidate models by leveraging a graph-relational knowledge schema that explicitly encodes data properties, architecture variations, and pairwise performance deltas as joinable relations. This schema supports fine-grained relational analytics over architecture tweaks and drives a predictive query planner that can detect and adapt to out-of-distribution (OOD) tasks. We instantiate M-DESIGN for graph analytics tasks, where our model knowledge base enriches existing benchmarks with structured metadata covering 3 graph tasks and 22 graph datasets, contributing data records of 67,760 graph models. Empirical results demonstrate that M-DESIGN delivers the optimal model in 26 of 33 data-task pairs within limited budgets.", 'abstract_zh': '数据库系统最近提倡嵌入机器学习能力，提供针对大型管理模式库的声明式模型查询，从而绕过了传统基于机器学习算法的自动化神经网络模型选择的巨大计算开销。我们提出M-DESIGN，一种经精心设计的神经网络模型知识库(MKB)流水线，通过自适应地编织关于模型架构修改的前期洞见来掌握神经网络的精炼。该流水线首先提出了一种知识编织引擎，将模型精炼重新构想为一个适应查询问题，基于任务元数据。对于用户的任务查询，M-DESIGN迅速匹配并迭代精炼候选模型，利用一个图关系知识架构，该架构明确编码了数据属性、架构变化和成对性能差异，并将它们作为可连接的关系。此类架构支持对架构调整的细粒度关系分析，并驱动一个预测查询规划器，能够检测和适应未知分布任务。在图分析任务中，我们的模型知识库为现有基准数据集增加了涵盖3个图任务和22个图数据集的结构化元数据，提供了67,760个图模型的数据记录。实证结果表明，在有限预算内，M-DESIGN在33个数据-任务对中提供了最优的26个模型。', 'title_zh': '超越模型基线选择：融合知识以掌握细粒度神经网络设计'}
{'arxiv_id': 'arXiv:2507.15335', 'title': 'ExDD: Explicit Dual Distribution Learning for Surface Defect Detection via Diffusion Synthesis', 'authors': 'Muhammad Aqeel, Federico Leonardi, Francesco Setti', 'link': 'https://arxiv.org/abs/2507.15335', 'abstract': 'Industrial defect detection systems face critical limitations when confined to one-class anomaly detection paradigms, which assume uniform outlier distributions and struggle with data scarcity in realworld manufacturing environments. We present ExDD (Explicit Dual Distribution), a novel framework that transcends these limitations by explicitly modeling dual feature distributions. Our approach leverages parallel memory banks that capture the distinct statistical properties of both normality and anomalous patterns, addressing the fundamental flaw of uniform outlier assumptions. To overcome data scarcity, we employ latent diffusion models with domain-specific textual conditioning, generating in-distribution synthetic defects that preserve industrial context. Our neighborhood-aware ratio scoring mechanism elegantly fuses complementary distance metrics, amplifying signals in regions exhibiting both deviation from normality and similarity to known defect patterns. Experimental validation on KSDD2 demonstrates superior performance (94.2% I-AUROC, 97.7% P-AUROC), with optimal augmentation at 100 synthetic samples.', 'abstract_zh': '面向工业缺陷检测系统超越单一异常检测范式的限制：显式双分布框架（ExDD）', 'title_zh': 'ExDD: 显式双分布学习在扩散合成中的表面缺陷检测'}
{'arxiv_id': 'arXiv:2507.15288', 'title': 'Preferential subspace identification (PSID) with forward-backward smoothing', 'authors': 'Omid G. Sani, Maryam M. Shanechi', 'link': 'https://arxiv.org/abs/2507.15288', 'abstract': 'System identification methods for multivariate time-series, such as neural and behavioral recordings, have been used to build models for predicting one from the other. For example, Preferential Subspace Identification (PSID) builds a state-space model of a primary time-series (e.g., neural activity) to optimally predict a secondary time-series (e.g., behavior). However, PSID focuses on optimal prediction using past primary data, even though in offline applications, better estimation can be achieved by incorporating concurrent data (filtering) or all available data (smoothing). Here, we extend PSID to enable optimal filtering and smoothing. First, we show that the presence of a secondary signal makes it possible to uniquely identify a model with an optimal Kalman update step (to enable filtering) from a family of otherwise equivalent state-space models. Our filtering solution augments PSID with a reduced-rank regression step that directly learns the optimal gain required for the update step from data. We refer to this extension of PSID as PSID with filtering. Second, inspired by two-filter Kalman smoother formulations, we develop a novel forward-backward PSID smoothing algorithm where we first apply PSID with filtering and then apply it again in the reverse time direction on the residuals of the filtered secondary signal. We validate our methods on simulated data, showing that our approach recovers the ground-truth model parameters for filtering, and achieves optimal filtering and smoothing decoding performance of the secondary signal that matches the ideal performance of the true underlying model. This work provides a principled framework for optimal linear filtering and smoothing in the two-signal setting, significantly expanding the toolkit for analyzing dynamic interactions in multivariate time-series.', 'abstract_zh': '多变量时间序列的系统识别方法，如神经和行为记录，已被用于构建预测一个时间序列从另一个时间序列的模型。例如，偏好亚空间识别（PSID）构建主时间序列（如神经活动）的状态空间模型，以最优地预测次级时间序列（如行为）。然而，PSID重点关注使用过去的主要数据进行最优预测，尽管在离线应用中，通过纳入并发数据（滤波）或所有可用数据（平滑）可以获得更好的估计结果。在此，我们扩展PSID以实现最优滤波和平滑。首先，我们表明次级信号的存在使得能够从状态空间模型的等价家族中唯一识别出一个模型，该模型具有能够实现滤波的最优卡尔曼更新步骤。我们的滤波解决方案通过在PSID中增加一个降秩回归步骤来直接从数据中学习所需的最优增益。我们将这种扩展的PSID称为具有滤波功能的PSID。其次，受到两步卡尔曼平滑算法的启发，我们开发了一种新颖的正向-反向PSID平滑算法，其中我们首先使用滤波功能的PSID应用该方法，然后在逆时间方向上将其应用于次级信号滤波残差上。我们在模拟数据上验证了我们的方法，表明我们的方法恢复了滤波的真实模型参数，并实现了与真实底层模型理想的滤波和平滑解码性能相匹配的表现。这项工作为双信号设置下的最优线性滤波和平滑提供了原理性的框架，显著扩展了分析多变量时间序列中动态相互作用的工具箱。', 'title_zh': '偏好子空间识别（PSID）与前向后向平滑结合'}
{'arxiv_id': 'arXiv:2507.15272', 'title': 'A2TTS: TTS for Low Resource Indian Languages', 'authors': 'Ayush Singh Bhadoriya, Abhishek Nikunj Shinde, Isha Pandey, Ganesh Ramakrishnan', 'link': 'https://arxiv.org/abs/2507.15272', 'abstract': 'We present a speaker conditioned text-to-speech (TTS) system aimed at addressing challenges in generating speech for unseen speakers and supporting diverse Indian languages. Our method leverages a diffusion-based TTS architecture, where a speaker encoder extracts embeddings from short reference audio samples to condition the DDPM decoder for multispeaker generation. To further enhance prosody and naturalness, we employ a cross-attention based duration prediction mechanism that utilizes reference audio, enabling more accurate and speaker consistent timing. This results in speech that closely resembles the target speaker while improving duration modeling and overall expressiveness. Additionally, to improve zero-shot generation, we employed classifier free guidance, allowing the system to generate speech more near speech for unknown speakers. Using this approach, we trained language-specific speaker-conditioned models. Using the IndicSUPERB dataset for multiple Indian languages such as Bengali, Gujarati, Hindi, Marathi, Malayalam, Punjabi and Tamil.', 'abstract_zh': '基于讲话人条件的文本到speech系统：面向未见讲话人挑战及支持多样印度语言的研究', 'title_zh': 'A2TTS: 低资源印度语言的语音合成'}
{'arxiv_id': 'arXiv:2507.15256', 'title': 'Optimal Transceiver Design in Over-the-Air Federated Distillation', 'authors': 'Zihao Hu, Jia Yan, Ying-Jun Angela Zhang, Jun Zhang, Khaled B. Letaief', 'link': 'https://arxiv.org/abs/2507.15256', 'abstract': "The rapid proliferation and growth of artificial intelligence (AI) has led to the development of federated learning (FL). FL allows wireless devices (WDs) to cooperatively learn by sharing only local model parameters, without needing to share the entire dataset. However, the emergence of large AI models has made existing FL approaches inefficient, due to the significant communication overhead required. In this paper, we propose a novel over-the-air federated distillation (FD) framework by synergizing the strength of FL and knowledge distillation to avoid the heavy local model transmission. Instead of sharing the model parameters, only the WDs' model outputs, referred to as knowledge, are shared and aggregated over-the-air by exploiting the superposition property of the multiple-access channel. We shall study the transceiver design in over-the-air FD, aiming to maximize the learning convergence rate while meeting the power constraints of the transceivers. The main challenge lies in the intractability of the learning performance analysis, as well as the non-convex nature and the optimization spanning the whole FD training period. To tackle this problem, we first derive an analytical expression of the convergence rate in over-the-air FD. Then, the closed-form optimal solutions of the WDs' transmit power and the estimator for over-the-air aggregation are obtained given the receiver combining strategy. Accordingly, we put forth an efficient approach to find the optimal receiver beamforming vector via semidefinite relaxation. We further prove that there is no optimality gap between the original and relaxed problem for the receiver beamforming design. Numerical results will show that the proposed over-the-air FD approach achieves a significant reduction in communication overhead, with only a minor compromise in testing accuracy compared to conventional FL benchmarks.", 'abstract_zh': '基于空中联邦蒸馏的无线设备协同学习框架', 'title_zh': '空中 federated -distillation 的最优发射-接收机设计'}
{'arxiv_id': 'arXiv:2507.15254', 'title': 'User Head Movement-Predictive XR in Immersive H2M Collaborations over Future Enterprise Networks', 'authors': 'Sourav Mondal, Elaine Wong', 'link': 'https://arxiv.org/abs/2507.15254', 'abstract': "The evolution towards future generation of mobile systems and fixed wireless networks is primarily driven by the urgency to support high-bandwidth and low-latency services across various vertical sectors. This endeavor is fueled by smartphones as well as technologies like industrial internet of things, extended reality (XR), and human-to-machine (H2M) collaborations for fostering industrial and social revolutions like Industry 4.0/5.0 and Society 5.0. To ensure an ideal immersive experience and avoid cyber-sickness for users in all the aforementioned usage scenarios, it is typically challenging to synchronize XR content from a remote machine to a human collaborator according to their head movements across a large geographic span in real-time over communication networks. Thus, we propose a novel H2M collaboration scheme where the human's head movements are predicted ahead with highly accurate models like bidirectional long short-term memory networks to orient the machine's camera in advance. We validate that XR frame size varies in accordance with the human's head movements and predict the corresponding bandwidth requirements from the machine's camera to propose a human-machine coordinated dynamic bandwidth allocation (HMC-DBA) scheme. Through extensive simulations, we show that end-to-end latency and jitter requirements of XR frames are satisfied with much lower bandwidth consumption over enterprise networks like Fiber-To-The-Room-Business. Furthermore, we show that better efficiency in network resource utilization is achieved by employing our proposed HMC-DBA over state-of-the-art schemes.", 'abstract_zh': '面向未来移动系统和固定无线网络演化的进展主要由支持各种垂直领域内的高带宽和低延迟服务的紧迫需求驱动。这一努力受到智能手机、工业互联网、扩展现实（XR）以及人机（H2M）协作等技术的推动，旨在促进如工业4.0/5.0和社会5.0等工业和社会革命。为了确保所有上述应用场景中用户获得理想的沉浸式体验并避免网络晕动症，在大范围内实时通过通信网络根据人体头部运动同步XR内容通常具有挑战性。因此，我们提出了一种新颖的人机协作方案，利用双向长短期记忆网络等高精度模型提前预测人体头部运动，从而使机器的相机提前对准。我们验证XR帧大小会根据人体头部运动而变化，并据此预测来自机器相机的相应带宽需求，提出了一种人机协同动态带宽分配（HMC-DBA）方案。通过广泛的仿真实验，我们证明在光纤到办公室企业网络等企业网络中，使用我们的HMC-DBA方案可以显著降低带宽消耗，同时满足XR帧的端到端时延和抖动要求。此外，我们展示了在先进的网络资源利用效率方面，我们的HMC-DBA方案优于现有方案。', 'title_zh': '用户头部运动预测的XR在未来的enterprise网络中沉浸式H2M协作'}
{'arxiv_id': 'arXiv:2507.15246', 'title': 'Spatio-Temporal Demand Prediction for Food Delivery Using Attention-Driven Graph Neural Networks', 'authors': 'Rabia Latief Bhat, Iqra Altaf Gillani', 'link': 'https://arxiv.org/abs/2507.15246', 'abstract': 'Accurate demand forecasting is critical for enhancing the efficiency and responsiveness of food delivery platforms, where spatial heterogeneity and temporal fluctuations in order volumes directly influence operational decisions. This paper proposes an attention-based Graph Neural Network framework that captures spatial-temporal dependencies by modeling the food delivery environment as a graph. In this graph, nodes represent urban delivery zones, while edges reflect spatial proximity and inter-regional order flow patterns derived from historical data. The attention mechanism dynamically weighs the influence of neighboring zones, enabling the model to focus on the most contextually relevant areas during prediction. Temporal trends are jointly learned alongside spatial interactions, allowing the model to adapt to evolving demand patterns. Extensive experiments on real-world food delivery datasets demonstrate the superiority of the proposed model in forecasting future order volumes with high accuracy. The framework offers a scalable and adaptive solution to support proactive fleet positioning, resource allocation, and dispatch optimization in urban food delivery operations.', 'abstract_zh': '基于注意力机制的图神经网络框架：增强食物配送平台效率和响应性的时空依赖性预测', 'title_zh': '基于注意力驱动图神经网络的食品配送时空需求预测'}
{'arxiv_id': 'arXiv:2507.15243', 'title': 'Cross-Domain Few-Shot Learning with Coalescent Projections and Latent Space Reservation', 'authors': 'Naeem Paeedeh, Mahardhika Pratama, Wolfgang Mayer, Jimmy Cao, Ryszard Kowlczyk', 'link': 'https://arxiv.org/abs/2507.15243', 'abstract': 'Despite the progress in Cross-Domain Few-Shot Learning (CD-FSL), a model pre-trained with DINO combined with a prototypical classifier outperforms the latest SOTA methods. A crucial limitation that needs to be overcome is that updating too many parameters of the transformers leads to overfitting due to the scarcity of labeled samples. To address this challenge, we propose a new concept, Coalescent Projection (CP), as an effective successor to soft prompts. Additionally, we propose a novel pseudo-class generation method combined with Self-Supervised Transformations (SSTs) that relies solely on the base domain to prepare the network for encountering unseen samples from different domains. The proposed method exhibits its effectiveness in comprehensive experiments on the extreme domain shift scenario of the BSCD-FSL benchmark. Our code is published at this https URL.', 'abstract_zh': '尽管在跨领域少量样本学习（CD-FSL）方面取得了进展，但使用DINO预训练模型结合原型分类器的表现仍优于最新SOTA方法。克服的关键限制是，更新太多变压器参数由于标注样本稀缺会导致过拟合。为应对这一挑战，我们提出了一种新的概念——共轭投影（CP），作为soft prompts的有效替代方案。此外，我们提出了一种新的伪类生成方法，并结合自监督变换（SSTs），仅依赖基域为网络准备处理来自不同领域未见过的样本。所提出的方法在BSCD-FSL基准的极端领域移转动态场景下的全面实验中显示出其有效性。我们的代码发布于此网址。', 'title_zh': '跨领域少样本学习中的共融投影与潜在空间预留'}
{'arxiv_id': 'arXiv:2507.15156', 'title': 'Constraint-aware Learning of Probabilistic Sequential Models for Multi-Label Classification', 'authors': 'Mykhailo Buleshnyi, Anna Polova, Zsolt Zombori, Michael Benedikt', 'link': 'https://arxiv.org/abs/2507.15156', 'abstract': 'We investigate multi-label classification involving large sets of labels, where the output labels may be known to satisfy some logical constraints. We look at an architecture in which classifiers for individual labels are fed into an expressive sequential model, which produces a joint distribution. One of the potential advantages for such an expressive model is its ability to modelling correlations, as can arise from constraints. We empirically demonstrate the ability of the architecture both to exploit constraints in training and to enforce constraints at inference time.', 'abstract_zh': '大规模标签集的多标签分类：利用表达性强的模型挖掘和应用标签约束', 'title_zh': '基于约束的学习：概率序列模型在多标签分类中的应用'}
{'arxiv_id': 'arXiv:2507.15146', 'title': 'Design of an Edge-based Portable EHR System for Anemia Screening in Remote Health Applications', 'authors': 'Sebastian A. Cruz Romero, Misael J. Mercado Hernandez, Samir Y. Ali Rivera, Jorge A. Santiago Fernandez, Wilfredo E. Lugo Beauchamp', 'link': 'https://arxiv.org/abs/2507.15146', 'abstract': 'The design of medical systems for remote, resource-limited environments faces persistent challenges due to poor interoperability, lack of offline support, and dependency on costly infrastructure. Many existing digital health solutions neglect these constraints, limiting their effectiveness for frontline health workers in underserved regions. This paper presents a portable, edge-enabled Electronic Health Record platform optimized for offline-first operation, secure patient data management, and modular diagnostic integration. Running on small-form factor embedded devices, it provides AES-256 encrypted local storage with optional cloud synchronization for interoperability. As a use case, we integrated a non-invasive anemia screening module leveraging fingernail pallor analysis. Trained on 250 patient cases (27\\% anemia prevalence) with KDE-balanced data, the Random Forest model achieved a test RMSE of 1.969 g/dL and MAE of 1.490 g/dL. A severity-based model reached 79.2\\% sensitivity. To optimize performance, a YOLOv8n-based nail bed detector was quantized to INT8, reducing inference latency from 46.96 ms to 21.50 ms while maintaining mAP@0.5 at 0.995. The system emphasizes low-cost deployment, modularity, and data privacy compliance (HIPAA/GDPR), addressing critical barriers to digital health adoption in disconnected settings. Our work demonstrates a scalable approach to enhance portable health information systems and support frontline healthcare in underserved regions.', 'abstract_zh': '面向资源受限环境的远程医疗系统设计面临持续挑战，主要原因包括互联互通差、缺乏离线支持以及依赖昂贵的基础设施。许多现有的数字健康解决方案忽视了这些限制，限制了它们在欠服务地区前线医疗工作者中的有效性。本文提出了一种便携式、边缘计算增强的电子健康记录平台，该平台针对离线优先操作、安全的患者数据管理和模块化的诊断集成进行了优化。该平台运行在小尺寸嵌入式设备上，提供AES-256加密的本地存储，并可选地与云端同步以实现互联互通。作为使用案例，我们集成了一个利用指甲苍白分析的非侵入性贫血筛查模块。模型在250例患者病例（贫血发病率27%）的KDE平衡数据上进行训练，测试RMSE为1.969 g/dL，MAE为1.490 g/dL，基于严重程度的模型达到了79.2%的敏感性。为了优化性能，基于YOLOv8n的手指甲床检测器被量化为INT8，推理延迟从46.96 ms降低到21.50 ms，同时保持mAP@0.5为0.995。该系统强调低成本部署、模块化和数据隐私合规（HIPAA/GDPR），以解决孤立环境中数字健康采纳的关键障碍。我们的工作展示了增强便携式健康信息系统并支持欠服务地区前线医疗的可扩展方法。', 'title_zh': '边缘计算驱动的便携式 marzo 检筛系统在远程健康应用中的设计'}
{'arxiv_id': 'arXiv:2507.15142', 'title': "A Case Against Implicit Standards: Homophone Normalization in Machine Translation for Languages that use the Ge'ez Script", 'authors': 'Hellina Hailu Nigatu, Atnafu Lambebo Tonja, Henok Biadglign Ademtew, Hizkel Mitiku Alemayehu, Negasi Haile Abadi, Tadesse Destaw Belay, Seid Muhie Yimam', 'link': 'https://arxiv.org/abs/2507.15142', 'abstract': "Homophone normalization, where characters that have the same sound in a writing script are mapped to one character, is a pre-processing step applied in Amharic Natural Language Processing (NLP) literature. While this may improve performance reported by automatic metrics, it also results in models that are not able to understand different forms of writing in a single language. Further, there might be impacts in transfer learning, where models trained on normalized data do not generalize well to other languages. In this paper, we experiment with monolingual training and cross-lingual transfer to understand the impacts of normalization on languages that use the Ge'ez script. We then propose a post-inference intervention in which normalization is applied to model predictions instead of training data. With our simple scheme of post-inference normalization, we show that we can achieve an increase in BLEU score of up to 1.03 while preserving language features in training. Our work contributes to the broader discussion on technology-facilitated language change and calls for more language-aware interventions.", 'abstract_zh': '同音字符规范化在阿姆哈拉语自然语言处理中的影响及对策研究', 'title_zh': '反对隐含标准：使用 Geez 字母-script 语言的机器翻译中的同音词规范化'}
{'arxiv_id': 'arXiv:2507.15104', 'title': 'AnalogFed: Federated Discovery of Analog Circuit Topologies with Generative AI', 'authors': 'Qiufeng Li, Shu Hong, Jian Gao, Xuan Zhang, Tian Lan, Weidong Cao', 'link': 'https://arxiv.org/abs/2507.15104', 'abstract': 'Recent breakthroughs in AI/ML offer exciting opportunities to revolutionize analog design automation through data-driven approaches. In particular, researchers are increasingly fascinated by harnessing the power of generative AI to automate the discovery of novel analog circuit topologies. Unlocking the full potential of generative AI in these data-driven discoveries requires access to large and diverse this http URL, there is a significant barrier in the analog domain--Analog circuit design is inherently proprietary, involving not only confidential circuit structures but also the underlying commercial semiconductor processes. As a result, current generative AI research is largely confined to individual researchers who construct small, narrowly focused private datasets. This fragmentation severely limits collaborative innovation and impedes progress across the research community. To address these challenges, we propose AnalogFed. AnalogFed enables collaborative topology discovery across decentralized clients (e.g., individual researchers or institutions) without requiring the sharing of raw private data. To make this vision practical, we introduce a suite of techniques tailored to the unique challenges of applying FedL in analog design--from generative model development and data heterogeneity handling to privacy-preserving strategies that ensure both flexibility and security for circuit designers and semiconductor manufacturers. Extensive experiments across varying client counts and dataset sizes demonstrate that AnalogFed achieves performance comparable to centralized baselines--while maintaining strict data privacy. Specifically, the generative AI model within AnalogFed achieves state-of-the-art efficiency and scalability in the design of analog circuit topologies.', 'abstract_zh': 'Recent突破在AI/ML为通过数据驱动方法革新模拟设计自动化提供了激动人心的机会。特别是，研究人员越来越关注利用生成AI的力量自动化新型模拟电路拓扑结构的发现。要充分发挥生成AI在这些数据驱动发现中的潜力，需要访问大量且多样化的数据源，但在模拟领域，存在显著障碍——模拟电路设计本质上是专有的，不仅包括保密的电路结构，还包括底层的商业半导体工艺。因此，当前的生成AI研究主要局限于个别研究人员，他们构建小型、专注的私有数据集。这种分割严重限制了合作创新并阻碍了研究社区的进展。为了解决这些挑战，我们提出了AnalogFed。AnalogFed能够在分散的客户端（如个人研究人员或机构）之间合作发现电路拓扑结构，而不需共享原始私有数据。为了使这一愿景变得可行，我们介绍了针对模拟设计中独特挑战的一系列技术——从生成模型开发和数据异质性处理到保护电路设计师和半导体制造商的隐私和安全的策略。广泛实验表明，AnalogFed在不同客户端数量和数据集大小下，实现了与集中式基准相当的性能——同时严格保护数据隐私。特别是，AnalogFed中的生成AI模型在模拟电路拓扑结构设计方面的效率和可扩展性达到了最先进的水平。', 'title_zh': 'AnalogFed: 使用生成性人工智能进行协作模拟电路拓扑发现'}
{'arxiv_id': 'arXiv:2507.15094', 'title': 'BleedOrigin: Dynamic Bleeding Source Localization in Endoscopic Submucosal Dissection via Dual-Stage Detection and Tracking', 'authors': 'Mengya Xu, Rulin Zhou, An Wang, Chaoyang Lyu, Zhen Li, Ning Zhong, Hongliang Ren', 'link': 'https://arxiv.org/abs/2507.15094', 'abstract': 'Intraoperative bleeding during Endoscopic Submucosal Dissection (ESD) poses significant risks, demanding precise, real-time localization and continuous monitoring of the bleeding source for effective hemostatic intervention. In particular, endoscopists have to repeatedly flush to clear blood, allowing only milliseconds to identify bleeding sources, an inefficient process that prolongs operations and elevates patient risks. However, current Artificial Intelligence (AI) methods primarily focus on bleeding region segmentation, overlooking the critical need for accurate bleeding source detection and temporal tracking in the challenging ESD environment, which is marked by frequent visual obstructions and dynamic scene changes. This gap is widened by the lack of specialized datasets, hindering the development of robust AI-assisted guidance systems. To address these challenges, we introduce BleedOrigin-Bench, the first comprehensive ESD bleeding source dataset, featuring 1,771 expert-annotated bleeding sources across 106,222 frames from 44 procedures, supplemented with 39,755 pseudo-labeled frames. This benchmark covers 8 anatomical sites and 6 challenging clinical scenarios. We also present BleedOrigin-Net, a novel dual-stage detection-tracking framework for the bleeding source localization in ESD procedures, addressing the complete workflow from bleeding onset detection to continuous spatial tracking. We compare with widely-used object detection models (YOLOv11/v12), multimodal large language models, and point tracking methods. Extensive evaluation demonstrates state-of-the-art performance, achieving 96.85% frame-level accuracy ($\\pm\\leq8$ frames) for bleeding onset detection, 70.24% pixel-level accuracy ($\\leq100$ px) for initial source detection, and 96.11% pixel-level accuracy ($\\leq100$ px) for point tracking.', 'abstract_zh': '内镜黏膜下切除术(ESD)术中出血的风险管理：BleedOrigin-Bench数据集及BleedOrigin-Net检测-跟踪框架', 'title_zh': 'BleedOrigin: 内镜黏膜下剥离术中动态出血源定位的双阶段检测与跟踪'}
{'arxiv_id': 'arXiv:2507.15087', 'title': 'Evaluation of Coding Schemes for Transformer-based Gene Sequence Modeling', 'authors': 'Chenlei Gong, Yuanhe Tian, Lei Mao, Yan Song', 'link': 'https://arxiv.org/abs/2507.15087', 'abstract': 'Currently, many studies view DNA sequences as a special type of language and utilize Transformers to model them. These studies use fixed-length k-mer segmentation and BPE subword tokenization but lack a systematic evaluation to determine which is superior. We compare k-mer segmentation with k=1,3,4,5,6, a 4,096-token BPE vocabulary, and three positional encoding methods-sinusoidal, AliBi, and RoPE. Each configuration is trained from scratch in 3, 6, 12, and 24-layer Transformer encoders and evaluated on GUE benchmark dataset. In general, BPE delivers higher and more stable performance across tasks by compressing frequent motifs into variable-length tokens, reducing sequence length, and improving model generalization. RoPE excels at capturing periodic motifs and extrapolating to long sequences, while AliBi also performs well on tasks driven by local dependencies. In terms of depth, we observe significant gains when increasing layers from 3 to 12, with only marginal improvements or slight overfitting at 24 layers. This study provides practical guidance for designing tokenization and positional encoding in DNA Transformer models.', 'abstract_zh': '目前，许多研究将DNA序列视为一种特殊类型的语言，并利用Transformer对其进行建模。这些研究使用固定长度的k-mer分段和BPE子词分词，但缺乏系统性的评估以确定哪种方法更优。我们将k-mer分段分别设置为k=1,3,4,5,6，使用4,096个标记的BPE词汇表，并采用三种位置编码方法（正弦、AliBi和RoPE）。每种配置使用3、6、12和24层Transformer编码器从头进行训练，并在GUE基准数据集上进行评估。总体而言，BPE通过将频繁模式压缩为变长标记、缩短序列长度并提高模型泛化能力，提供了更高且更稳定的性能。RoPE在捕捉周期性模式和外推长序列方面表现出色，而AliBi在由局部依赖驱动的任务中表现出色。在深度方面，我们观察到当层数从3增加到12时显着的改进，在24层时仅有边际改进或轻微的过拟合。本研究为设计DNA Transformer模型中的分词和位置编码提供了实用指导。', 'title_zh': '基于变压器的基因序列建模的编码方案评估'}
{'arxiv_id': 'arXiv:2507.15082', 'title': 'Robust Control with Gradient Uncertainty', 'authors': 'Qian Qi', 'link': 'https://arxiv.org/abs/2507.15082', 'abstract': "We introduce a novel extension to robust control theory that explicitly addresses uncertainty in the value function's gradient, a form of uncertainty endemic to applications like reinforcement learning where value functions are approximated. We formulate a zero-sum dynamic game where an adversary perturbs both system dynamics and the value function gradient, leading to a new, highly nonlinear partial differential equation: the Hamilton-Jacobi-Bellman-Isaacs Equation with Gradient Uncertainty (GU-HJBI). We establish its well-posedness by proving a comparison principle for its viscosity solutions under a uniform ellipticity condition. Our analysis of the linear-quadratic (LQ) case yields a key insight: we prove that the classical quadratic value function assumption fails for any non-zero gradient uncertainty, fundamentally altering the problem structure. A formal perturbation analysis characterizes the non-polynomial correction to the value function and the resulting nonlinearity of the optimal control law, which we validate with numerical studies. Finally, we bridge theory to practice by proposing a novel Gradient-Uncertainty-Robust Actor-Critic (GURAC) algorithm, accompanied by an empirical study demonstrating its effectiveness in stabilizing training. This work provides a new direction for robust control, holding significant implications for fields where function approximation is common, including reinforcement learning and computational finance.", 'abstract_zh': '一种考虑梯度不确定性的一致鲁棒控制理论扩展及其应用', 'title_zh': '具有梯度不确定性的鲁棒控制'}
{'arxiv_id': 'arXiv:2507.15066', 'title': 'Time-RA: Towards Time Series Reasoning for Anomaly with LLM Feedback', 'authors': 'Yiyuan Yang, Zichuan Liu, Lei Song, Kai Ying, Zhiguang Wang, Tom Bamford, Svitlana Vyetrenko, Jiang Bian, Qingsong Wen', 'link': 'https://arxiv.org/abs/2507.15066', 'abstract': 'Time series anomaly detection is critical across various domains, yet current approaches often limit analysis to mere binary anomaly classification without detailed categorization or further explanatory reasoning. To address these limitations, we propose a novel task, Time-series Reasoning for Anomaly (Time-RA) that transforms classical time series anomaly detection from a discriminative into a generative, reasoning-intensive task leveraging Large Language Models (LLMs). Also, we introduce the first real-world multimodal benchmark dataset, RATs40K, explicitly annotated for anomaly reasoning, comprising approximately 40,000 samples across 10 real-world domains. Each sample includes numeric time series data, contextual text information, and visual representations, each annotated with fine-grained categories (14 types for univariate anomalies and 6 for multivariate anomalies) and structured explanatory reasoning. We develop a sophisticated annotation framework utilizing ensemble-generated labels refined through GPT-4-driven feedback, ensuring accuracy and interpretability. Extensive benchmarking of LLMs and multimodal LLMs demonstrates the capabilities and limitations of current models, highlighting the critical role of supervised fine-tuning. Our dataset and task pave the way for significant advancements in interpretable time series anomaly detection and reasoning.', 'abstract_zh': '时间序列异常检测在各个领域都至关重要，但现有方法往往仅限于简单的二元异常分类，缺乏详细的分类或进一步的解释性推理。为解决这些局限，我们提出了一个新的任务——时间序列推理解释异常（Time-RA），该任务通过利用大型语言模型（LLMs）将传统的时序异常检测从判别性任务转化为生成性和推理密集型任务。此外，我们引入了首个面向异常推理解释的多模态基准数据集RATs40K，该数据集包含约40,000个样本，涵盖了10个实际领域的数据。每个样本包括数值时间序列数据、上下文文本信息和视觉表示，并且每一项都用细致粒度的类别（14种类型用于单变量异常和6种用于多变量异常）和结构化的解释性推理进行标注。我们开发了一种复杂的标注框架，利用GPT-4驱动的反馈生成集合标注，并对其进行精炼，以确保准确性和可解释性。通过对LLMs和多模态LLMs的广泛基准测试，展示了当前模型的能力和局限性，突出了监督微调的关键作用。我们的数据集和任务为可解释的时间序列异常检测和推理奠定了重要基础。', 'title_zh': '时间RA：面向异常检测的时间序列推理与LLM反馈研究'}
{'arxiv_id': 'arXiv:2507.15032', 'title': 'The hunt for new pulsating ultraluminous X-ray sources: a clustering approach', 'authors': 'Nicolò Oreste Pinciroli Vago, Roberta Amato, Matteo Imbrogno, GianLuca Israel, Andrea Belfiore, Konstantinos Kovlakas, Piero Fraternali, Mario Pasquato', 'link': 'https://arxiv.org/abs/2507.15032', 'abstract': 'The discovery of fast and variable coherent signals in a handful of ultraluminous X-ray sources (ULXs) testifies to the presence of super-Eddington accreting neutron stars, and drastically changed the understanding of the ULX class. Our capability of discovering pulsations in ULXs is limited, among others, by poor statistics. However, catalogues and archives of high-energy missions contain information which can be used to identify new candidate pulsating ULXs (PULXs). The goal of this research is to single out candidate PULXs among those ULXs which have not shown pulsations due to an unfavourable combination of factors. We applied an AI approach to an updated database of ULXs detected by XMM-Newton. We first used an unsupervised clustering algorithm to sort out sources with similar characteristics into two clusters. Then, the sample of known PULX observations has been used to set the separation threshold between the two clusters and to identify the one containing the new candidate PULXs. We found that only a few criteria are needed to assign the membership of an observation to one of the two clusters. The cluster of new candidate PULXs counts 85 unique sources for 355 observations, with $\\sim$85% of these new candidates having multiple observations. A preliminary timing analysis found no new pulsations for these candidates. This work presents a sample of new candidate PULXs observed by XMM-Newton, the properties of which are similar (in a multi-dimensional phase space) to those of the known PULXs, despite the absence of pulsations in their light curves. While this result is a clear example of the predictive power of AI-based methods, it also highlights the need for high-statistics observational data to reveal coherent signals from the sources in this sample and thus validate the robustness of the approach.', 'abstract_zh': '超亮X射线源中快速且可变的相干信号的发现证实了超爱丁顿吸积中子星的存在，并极大地改变了对超亮X射线源类别的理解。本研究的目标是在不利因素的组合导致未发现脉动的超亮X射线源中筛选出新的候选脉冲超亮X射线源（PULXs）。我们采用AI方法对XMM-Newton探测到的超亮X射线源数据库进行了更新。首先使用无监督聚类算法将具有相似特征的源分为两类。然后，已知PULX观测样本被用来设定两个簇之间的分离阈值，并识别出包含新候选PULXs的簇。我们发现只需少数几项标准即可将观测分配到两个簇中的一个。新候选PULXs的簇中有85个唯一源，共355个观测，其中约85%的新候选PULXs有多次观测。初步时间分析未发现这些候选源的新脉动。本文介绍了由XMM-Newton观测到的新候选PULXs样本，其性质在多维相空间中与已知PULXs相似，尽管其光曲线中未显示脉动。虽然这一结果是AI方法预测能力的一个明确例子，但也强调了需要高统计观测数据以揭示这些源中的相干信号的必要性，从而验证该方法的 robustness。', 'title_zh': '新脉动超亮X射线源的搜索：聚集方法探究'}
{'arxiv_id': 'arXiv:2507.15003', 'title': 'The Rise of AI Teammates in Software Engineering (SE) 3.0: How Autonomous Coding Agents Are Reshaping Software Engineering', 'authors': 'Hao Li, Haoxiang Zhang, Ahmed E. Hassan', 'link': 'https://arxiv.org/abs/2507.15003', 'abstract': 'The future of software engineering--SE 3.0--is unfolding with the rise of AI teammates: autonomous, goal-driven systems collaborating with human developers. Among these, autonomous coding agents are especially transformative, now actively initiating, reviewing, and evolving code at scale. This paper introduces AIDev, the first large-scale dataset capturing how such agents operate in the wild. Spanning over 456,000 pull requests by five leading agents--OpenAI Codex, Devin, GitHub Copilot, Cursor, and Claude Code--across 61,000 repositories and 47,000 developers, AIDev provides an unprecedented empirical foundation for studying autonomous teammates in software development.\nUnlike prior work that has largely theorized the rise of AI-native software engineering, AIDev offers structured, open data to support research in benchmarking, agent readiness, optimization, collaboration modeling, and AI governance. The dataset includes rich metadata on PRs, authorship, review timelines, code changes, and integration outcomes--enabling exploration beyond synthetic benchmarks like SWE-bench. For instance, although agents often outperform humans in speed, their PRs are accepted less frequently, revealing a trust and utility gap. Furthermore, while agents accelerate code submission--one developer submitted as many PRs in three days as they had in three years--these are structurally simpler (via code complexity metrics).\nWe envision AIDev as a living resource: extensible, analyzable, and ready for the SE and AI communities. Grounding SE 3.0 in real-world evidence, AIDev enables a new generation of research into AI-native workflows and supports building the next wave of symbiotic human-AI collaboration. The dataset is publicly available at this https URL.\n> AI Agent, Agentic AI, Coding Agent, Agentic Coding, Software Engineering Agent', 'abstract_zh': '软件工程的未来—SE 3.0—正随着AI队友的兴起而展开：自主、目标导向的系统与人类开发人员协作。其中，自主编码代理尤其具有革命性，现在能够主动启动、审查和大规模进化代码。本文介绍了AIDev，这是首个大规模数据集，记录了这类代理在现实世界中的运作方式。AIDev涵盖了来自OpenAI Codex、Devin、GitHub Copilot、Cursor和Claude Code五大代理的超过456,000个拉取请求，涉及61,000个存储库和47,000位开发者，为研究自主团队在软件开发中的作用提供了前所未有的实证基础。\n\n不同于以往主要基于理论研究AI原生软件工程的工作，AIDev提供了结构化的开放数据，支持基准测试、代理准备性、优化、协作建模和AI治理的研究。该数据集包含丰富的拉取请求元数据、作者信息、审查时间线、代码变更和集成结果——使研究超越了如SWE-bench这样的合成基准。例如，虽然代理通常在速度上超越人类，但它们的拉取请求被接受的频率较低，展示了信任和效用之间的差距。此外，虽然代理加速了代码提交——一名开发者在三天内提交的拉取请求数量等同于三年的提交量——但这些提交结构上较为简单（通过代码复杂性度量）。\n\n我们构想AIDev成为一个活生生的资源：可扩展、可分析，并准备好供软件工程和AI社区使用。AIDev扎根于真实世界数据，使之能够开启新的一代关于AI原生工作流程的研究，并支持构建下一代共生的人机协作。数据集在此处公开：[](此 https URL)。AI代理, 代理型AI, 编码代理, 代理型编码, 软件工程代理', 'title_zh': 'AI队友在软件工程3.0时代的发展：自主编码代理如何重塑软件工程'}
{'arxiv_id': 'arXiv:2507.14960', 'title': 'A Comparative Analysis of Statistical and Machine Learning Models for Outlier Detection in Bitcoin Limit Order Books', 'authors': 'Ivan Letteri', 'link': 'https://arxiv.org/abs/2507.14960', 'abstract': 'The detection of outliers within cryptocurrency limit order books (LOBs) is of paramount importance for comprehending market dynamics, particularly in highly volatile and nascent regulatory environments. This study conducts a comprehensive comparative analysis of robust statistical methods and advanced machine learning techniques for real-time anomaly identification in cryptocurrency LOBs. Within a unified testing environment, named AITA Order Book Signal (AITA-OBS), we evaluate the efficacy of thirteen diverse models to identify which approaches are most suitable for detecting potentially manipulative trading behaviours. An empirical evaluation, conducted via backtesting on a dataset of 26,204 records from a major exchange, demonstrates that the top-performing model, Empirical Covariance (EC), achieves a 6.70% gain, significantly outperforming a standard Buy-and-Hold benchmark. These findings underscore the effectiveness of outlier-driven strategies and provide insights into the trade-offs between model complexity, trade frequency, and performance. This study contributes to the growing corpus of research on cryptocurrency market microstructure by furnishing a rigorous benchmark of anomaly detection models and highlighting their potential for augmenting algorithmic trading and risk management.', 'abstract_zh': '数字货币限订单簿中的异常检测对于理解市场动态至关重要，特别是在 Highly Volatile 和新兴监管环境中。本文对稳健统计方法和先进机器学习技术在数字货币限订单簿中实时异常识别的性能进行了全面比较分析。在名为 AITA Order Book Signal (AITA-OBS) 的统一测试环境中，我们评估了十三种不同模型的有效性，以确定哪些方法最适合检测潜在操纵交易行为。通过对某主要交易所的 26,204 条记录进行回测实证研究发现，表现最佳的模型 Empirical Covariance (EC) 达到了 6.70% 的收益，显著优于标准的 Buy-and-Hold 基准。这些发现强调了基于异常的策略的有效性，并提供了模型复杂性、交易频率与性能之间的权衡见解。本文通过提供异常检测模型的严格基准并突出其在增强算法交易和风险管理方面的潜力，为数字货币市场微观结构研究领域做出了贡献。', 'title_zh': '比特币限价订单簿中异常检测的统计与机器学习模型比较分析'}
{'arxiv_id': 'arXiv:2507.14957', 'title': 'Probing EFX via PMMS: (Non-)Existence Results in Discrete Fair Division', 'authors': 'Jarosław Byrka, Franciszek Malinka, Tomasz Ponitka', 'link': 'https://arxiv.org/abs/2507.14957', 'abstract': 'We study the fair division of indivisible items and provide new insights into the EFX problem, which is widely regarded as the central open question in fair division, and the PMMS problem, a strictly stronger variant of EFX. Our first result constructs a three-agent instance with two monotone valuations and one additive valuation in which no PMMS allocation exists. Since EFX allocations are known to exist under these assumptions, this establishes a formal separation between EFX and PMMS.\nWe prove existence of fair allocations for three important special cases. We show that EFX allocations exist for personalized bivalued valuations, where for each agent $i$ there exist values $a_i > b_i$ such that agent $i$ assigns value $v_i(\\{g\\}) \\in \\{a_i, b_i\\}$ to each good $g$. We establish an analogous existence result for PMMS allocations when $a_i$ is divisible by $b_i$. We also prove that PMMS allocations exist for binary-valued MMS-feasible valuations, where each bundle $S$ has value $v_i(S) \\in \\{0, 1\\}$. Notably, this result holds even without assuming monotonicity of valuations and thus applies to the fair division of chores and mixed manna. Finally, we study a class of valuations called pair-demand valuations, which extend the well-studied unit-demand valuations to the case where each agent derives value from at most two items, and we show that PMMS allocations exist in this setting. Our proofs are constructive, and we provide polynomial-time algorithms for all three existence results.', 'abstract_zh': '我们研究不可分割物品的公平分配问题，并提供了关于EFX问题的新见解，EFX问题被广泛认为是公平分配领域中的核心开放问题，以及PMMS问题，这是一个严格更强的EFX变体。我们的第一个结果构建了一个三代理人实例，包含两个单调估值和一个增加估值，且在这些假设下不存在PMMS分配。由于已知在这种假设下存在EFX分配，这确立了EFX和PMMS之间的形式化分离。\n\n我们证明了三种重要特殊情况下的公平分配存在性。我们证明了个性化二值估值下的EFX分配存在性，其中对于每个代理人 \\(i\\)，存在 \\(a_i > b_i\\)，使得代理人 \\(i\\) 将每个物品 \\(g\\) 的估值 \\(v_i(\\{g\\})\\) 分配为 \\(a_i\\) 或 \\(b_i\\)。我们还证明了在 \\(a_i\\) 可被 \\(b_i\\) 整除的情况下，PMMS分配的存在性具有类似的结果。我们还证明了二值MMS可行估值下的PMMS分配存在性，其中每个物品集合 \\(S\\) 的估值 \\(v_i(S)\\) 为 \\(0\\) 或 \\(1\\)。值得注意的是，这一结果即使不假设估值的单调性也成立，因此适用于劳动分配和混合财富的公平分配。最后，我们研究了一类称为配对需求估值，这些估值将广为人知的单一需求估值扩展到每个代理最多从两个项目中获取价值的情况，并证明了在这种情况下存在PMMS分配。我们的证明是构造性的，并为这三个存在性结果提供了多项式时间算法。', 'title_zh': '探查EFX通过PMMS：离散公平分割中的存在性结果与不存在性结果'}
{'arxiv_id': 'arXiv:2507.14908', 'title': 'Partial Symmetry Enforced Attention Decomposition (PSEAD): A Group-Theoretic Framework for Equivariant Transformers in Biological Systems', 'authors': 'Daniel Ayomide Olanrewaju', 'link': 'https://arxiv.org/abs/2507.14908', 'abstract': "This research introduces the Theory of Partial Symmetry Enforced Attention Decomposition (PSEAD), a new and rigorous group-theoretic framework designed to seamlessly integrate local symmetry awareness into the core architecture of self-attention mechanisms within Transformer models. We formalize the concept of local permutation subgroup actions on windows of biological data, proving that under such actions, the attention mechanism naturally decomposes into a direct sum of orthogonal irreducible components. Critically, these components are intrinsically aligned with the irreducible representations of the acting permutation subgroup, thereby providing a powerful mathematical basis for disentangling symmetric and asymmetric features. We show that PSEAD offers substantial advantages. These include enhanced generalization capabilities to novel biological motifs exhibiting similar partial symmetries, unprecedented interpretability by allowing direct visualization and analysis of attention contributions from different symmetry channels, and significant computational efficiency gains by focusing representational capacity on relevant symmetric subspaces. Beyond static data analysis, we extend PSEAD's applicability to dynamic biological processes within reinforcement learning paradigms, showcasing its potential to accelerate the discovery and optimization of biologically meaningful policies in complex environments like protein folding and drug discovery. This work lays the groundwork for a new generation of biologically informed, symmetry-aware artificial intelligence models.", 'abstract_zh': '这种研究介绍了部分对称强制注意分解理论（PSEAD），这是一种新的严格群论框架，旨在无缝地将局部对称意识集成到Transformer模型中自注意力机制的核心架构中。我们形式化了局部置换子群作用于生物数据窗口的概念，并证明在这样的作用下，注意机制自然分解为正交不可约成分的直和。关键的是，这些成分内嵌地与作用置换子群的不可约表示相一致，从而为解纠缠对称和非对称特征提供了强大的数学基础。我们展示了PSEAD的优势，包括增强了对展示相似部分对称性的新型生物结构模式的泛化能力，前所未有的可解释性，允许直接可视化和分析来自不同对称通道的注意贡献，以及通过专注于相关的对称子空间而实现的显著计算效率提升。该研究还扩展了PSEAD的应用范围，将其应用于强化学习范式中的动态生物过程，展示了其在复杂环境中（如蛋白质折叠和药物发现）加速发现和优化生物意义政策的潜力。这项工作为新一代生物启发且具备对称意识的人工智能模型奠定了基础。', 'title_zh': '部分对称强制注意分解（PSEAD）：生物系统中稳态变换器的群论框架'}
{'arxiv_id': 'arXiv:2507.14901', 'title': 'Learning Nonlinear Causal Reductions to Explain Reinforcement Learning Policies', 'authors': 'Armin Kekić, Jan Schneider, Dieter Büchler, Bernhard Schölkopf, Michel Besserve', 'link': 'https://arxiv.org/abs/2507.14901', 'abstract': 'Why do reinforcement learning (RL) policies fail or succeed? This is a challenging question due to the complex, high-dimensional nature of agent-environment interactions. In this work, we take a causal perspective on explaining the behavior of RL policies by viewing the states, actions, and rewards as variables in a low-level causal model. We introduce random perturbations to policy actions during execution and observe their effects on the cumulative reward, learning a simplified high-level causal model that explains these relationships. To this end, we develop a nonlinear Causal Model Reduction framework that ensures approximate interventional consistency, meaning the simplified high-level model responds to interventions in a similar way as the original complex system. We prove that for a class of nonlinear causal models, there exists a unique solution that achieves exact interventional consistency, ensuring learned explanations reflect meaningful causal patterns. Experiments on both synthetic causal models and practical RL tasks-including pendulum control and robot table tennis-demonstrate that our approach can uncover important behavioral patterns, biases, and failure modes in trained RL policies.', 'abstract_zh': '为什么 reinforcement learning (RL) 策略会失败或成功？由于智能体-环境交互的复杂性和高维性，这是一个具有挑战性的问题。在这项工作中，我们从因果视角出发，将状态、动作和奖励视为低层次因果模型中的变量，通过在执行过程中对策略动作施加随机扰动，并观察其对累积奖励的影响，学习一个简化但高层次的因果模型来解释这些关系。为此，我们开发了一种非线性因果模型简化框架，确保简化模型的干预响应近似于原始复杂系统的响应。我们证明，对于一类非线性因果模型，存在一个独特的解，可以实现精确的干预一致性，确保学到的解释反映有意义的因果模式。我们在合成因果模型和实际的 RL 任务（包括摆球控制和机器人乒乓球）上的实验表明，我们的方法可以揭示训练好的 RL 策略中的重要行为模式、偏差和失败模式。', 'title_zh': '学习非线性因果约简以解释强化学习策略'}
{'arxiv_id': 'arXiv:2507.14882', 'title': 'Application-Specific Component-Aware Structured Pruning of Deep Neural Networks via Soft Coefficient Optimization', 'authors': 'Ganesh Sundaram, Jonas Ulmen, Amjad Haider, Daniel Görges', 'link': 'https://arxiv.org/abs/2507.14882', 'abstract': "Deep neural networks (DNNs) offer significant versatility and performance benefits, but their widespread adoption is often hindered by high model complexity and computational demands. Model compression techniques such as pruning have emerged as promising solutions to these challenges. However, it remains critical to ensure that application-specific performance characteristics are preserved during compression. In structured pruning, where groups of structurally coherent elements are removed, conventional importance metrics frequently fail to maintain these essential performance attributes. In this work, we propose an enhanced importance metric framework that not only reduces model size but also explicitly accounts for application-specific performance constraints. We employ multiple strategies to determine the optimal pruning magnitude for each group, ensuring a balance between compression and task performance. Our approach is evaluated on an autoencoder tasked with reconstructing MNIST images. Experimental results demonstrate that the proposed method effectively preserves task-relevant performance, maintaining the model's usability even after substantial pruning, by satisfying the required application-specific criteria.", 'abstract_zh': '深神经网络（DNNs）提供了显著的灵活性和性能优势，但其广泛应用常常受到高模型复杂性和计算需求的阻碍。模型压缩技术如剪枝已成为应对这些挑战的有前途的解决方案。然而，在压缩过程中保持特定应用的性能特征仍至关重要。在结构化剪枝中，去除结构上一致的元素组时，传统的重要性度量经常无法保持这些关键的性能属性。在本文中，我们提出了一种增强的重要性度量框架，该框架不仅可以减少模型大小，而且能够明确考虑特定应用的性能限制。我们采用多种策略为每个组确定最佳剪枝程度，确保压缩和任务性能之间的平衡。我们的方法在用于重建MNIST图像的自动编码器上进行评估。实验结果表明，所提出的方法能够有效保持任务相关的性能，即使在大量剪枝后仍保持模型的可用性，从而满足所需的特定应用标准。', 'title_zh': '基于软系数优化的特定应用组件感知深度神经网络结构剪枝'}
{'arxiv_id': 'arXiv:2507.14874', 'title': 'The Tsetlin Machine Goes Deep: Logical Learning and Reasoning With Graphs', 'authors': 'Ole-Christoffer Granmo, Youmna Abdelwahab, Per-Arne Andersen, Paul F. A. Clarke, Kunal Dumbre, Ylva Grønninsæter, Vojtech Halenka, Runar Helin, Lei Jiao, Ahmed Khalid, Rebekka Omslandseter, Rupsa Saha, Mayur Shende, Xuan Zhang', 'link': 'https://arxiv.org/abs/2507.14874', 'abstract': "Pattern recognition with concise and flat AND-rules makes the Tsetlin Machine (TM) both interpretable and efficient, while the power of Tsetlin automata enables accuracy comparable to deep learning on an increasing number of datasets. We introduce the Graph Tsetlin Machine (GraphTM) for learning interpretable deep clauses from graph-structured input. Moving beyond flat, fixed-length input, the GraphTM gets more versatile, supporting sequences, grids, relations, and multimodality. Through message passing, the GraphTM builds nested deep clauses to recognize sub-graph patterns with exponentially fewer clauses, increasing both interpretability and data utilization. For image classification, GraphTM preserves interpretability and achieves 3.86%-points higher accuracy on CIFAR-10 than a convolutional TM. For tracking action coreference, faced with increasingly challenging tasks, GraphTM outperforms other reinforcement learning methods by up to 20.6%-points. In recommendation systems, it tolerates increasing noise to a greater extent than a Graph Convolutional Neural Network (GCN), e.g., for noise ratio 0.1, GraphTM obtains accuracy 89.86% compared to GCN's 70.87%. Finally, for viral genome sequence data, GraphTM is competitive with BiLSTM-CNN and GCN accuracy-wise, training 2.5x faster than GCN. The GraphTM's application to these varied fields demonstrates how graph representation learning and deep clauses bring new possibilities for TM learning.", 'abstract_zh': '基于简洁和扁平AND规则的图Tsetlin机（GraphTM）在学习图结构输入的可解释深层子句方面既具可解释性又高效，其强大的Tsetlin自动机能力使其在越来越多的数据集上的准确度可与深度学习媲美。', 'title_zh': 'Tsetlin机深入学习：图形上的逻辑学习与推理'}
{'arxiv_id': 'arXiv:2507.14851', 'title': 'Grounding Degradations in Natural Language for All-In-One Video Restoration', 'authors': 'Muhammad Kamran Janjua, Amirhosein Ghasemabadi, Kunlin Zhang, Mohammad Salameh, Chao Gao, Di Niu', 'link': 'https://arxiv.org/abs/2507.14851', 'abstract': 'In this work, we propose an all-in-one video restoration framework that grounds degradation-aware semantic context of video frames in natural language via foundation models, offering interpretable and flexible guidance. Unlike prior art, our method assumes no degradation knowledge in train or test time and learns an approximation to the grounded knowledge such that the foundation model can be safely disentangled during inference adding no extra cost. Further, we call for standardization of benchmarks in all-in-one video restoration, and propose two benchmarks in multi-degradation setting, three-task (3D) and four-task (4D), and two time-varying composite degradation benchmarks; one of the latter being our proposed dataset with varying snow intensity, simulating how weather degradations affect videos naturally. We compare our method with prior works and report state-of-the-art performance on all benchmarks.', 'abstract_zh': '基于基础模型的端到端视频恢复框架：自然语言驱动的降级感知语义上下文及其标准化 benchmarks 探索', 'title_zh': '基于自然语言对所有视频恢复任务进行故障定位'}
{'arxiv_id': 'arXiv:2507.14843', 'title': 'The Invisible Leash: Why RLVR May Not Escape Its Origin', 'authors': 'Fang Wu, Weihao Xuan, Ximing Lu, Zaid Harchaoui, Yejin Choi', 'link': 'https://arxiv.org/abs/2507.14843', 'abstract': "Recent advances in large reasoning models highlight Reinforcement Learning with Verifiable Rewards (RLVR) as a promising method for enhancing AI's capabilities, particularly in solving complex logical tasks. However, it remains unclear whether RLVR truly expands a model's reasoning boundary or merely amplifies high-reward outputs that the base model already knows for improved precision. This study presents a theoretical and empirical investigation that provides fresh insights into the potential limits of RLVR. First, we offer a new theoretical perspective that RLVR is constrained by the base model's support-unable to sample solutions with zero initial probability-and operates as a conservative reweighting mechanism that may restrict the discovery of entirely original solutions. We also identify an entropy-reward tradeoff: while RLVR reliably enhances precision, it may progressively narrow exploration and potentially overlook correct yet underrepresented solutions. Extensive empirical experiments validate that while RLVR consistently improves pass@1, the shrinkage of empirical support generally outweighs the expansion of empirical support under larger sampling budgets, failing to recover correct answers that were previously accessible to the base model. Interestingly, we also observe that while RLVR sometimes increases token-level entropy, resulting in greater uncertainty at each generation step, answer-level entropy declines, indicating that these seemingly more uncertain paths ultimately converge onto a smaller set of distinct answers. Taken together, these findings reveal potential limits of RLVR in extending reasoning horizons. Breaking this invisible leash may require future algorithmic innovations such as explicit exploration mechanisms or hybrid strategies that seed probability mass into underrepresented solution regions.", 'abstract_zh': '近期大型推理模型的发展凸显了可验证奖励强化学习（RLVR）作为一种有望增强AI能力的方法，特别是在解决复杂逻辑任务方面。然而，尚不清楚RLVR是否真正扩展了模型的推理边界，还是仅仅通过放大基模型已知的高奖励输出来提高精确度。本研究通过理论和实证考察，提供了对RLVR潜在限制的新见解。首先，我们提出了一种新的理论视角，即RLVR受到基模型支持的限制，无法生成初始概率为零的解决方案，并且作为一种保守的重新加权机制，可能限制了完全原创解决方案的发现。我们还识别出熵-奖励权衡：虽然RLVR能可靠地提高精确度，但它可能会逐渐限制探索，并有可能忽视正确但欠代表的解决方案。广泛的实证实验验证了，虽然RLVR在提升pass@1方面表现出一致性改进，但在更大采样预算下的经验支持缩小通常超过了经验支持的扩展，未能恢复基模型先前可及的正确答案。有趣的是，我们还观察到，在某些情况下，RLVR增加了token级熵，导致每步生成时不确定性增加，但答案级熵下降，表明这些看似更具不确定性的路径最终收敛到一个更小的、独特的答案集。综上所述，这些发现揭示了RLVR在扩展推理视野方面的潜在限制。未来可能需要诸如明确探索机制或混合策略等算法创新，以打破这种无形的束缚，注入概率质量到欠代表的解决方案区域中。', 'title_zh': '无形的绳索：为什么RLVR可能无法逃脱其根源'}
{'arxiv_id': 'arXiv:2507.14828', 'title': 'eMargin: Revisiting Contrastive Learning with Margin-Based Separation', 'authors': 'Abdul-Kazeem Shamba, Kerstin Bach, Gavin Taylor', 'link': 'https://arxiv.org/abs/2507.14828', 'abstract': 'We revisit previous contrastive learning frameworks to investigate the effect of introducing an adaptive margin into the contrastive loss function for time series representation learning. Specifically, we explore whether an adaptive margin (eMargin), adjusted based on a predefined similarity threshold, can improve the separation between adjacent but dissimilar time steps and subsequently lead to better performance in downstream tasks. Our study evaluates the impact of this modification on clustering performance and classification in three benchmark datasets. Our findings, however, indicate that achieving high scores on unsupervised clustering metrics does not necessarily imply that the learned embeddings are meaningful or effective in downstream tasks. To be specific, eMargin added to InfoNCE consistently outperforms state-of-the-art baselines in unsupervised clustering metrics, but struggles to achieve competitive results in downstream classification with linear probing. The source code is publicly available at this https URL.', 'abstract_zh': '我们重新审视先前的对比学习框架，探究在时间序列表示学习中引入自适应 Margin 对对比损失函数的影响。具体而言，我们探索基于预定义相似度阈值调整的自适应 Margin（eMargin）能否改善相邻但不相似的时间步之间的分离，并进而提高下游任务中的表现。我们的研究在三个基准数据集上评估了这一修改对无监督聚类性能和分类性能的影响。然而，我们的发现表明，在无监督聚类指标上获得高分并不一定意味着学习到的嵌入具有实际意义或在下游任务中有效。具体来说，加有 eMargin 的 InfoNCE 在无监督聚类指标上始终优于最先进的基线方法，但在下游分类任务中使用线性探针时，难以取得竞争力的结果。源代码可在以下网址公开获取。', 'title_zh': 'eMargin: 重新审视基于边距分离的对比学习'}
{'arxiv_id': 'arXiv:2507.14811', 'title': 'SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models', 'authors': 'Jiaji Zhang, Ruichao Sun, Hailiang Zhao, Jiaju Wu, Peng Chen, Hao Li, Xinkui Zhao, Kingsum Chow, Gang Xiong, Lin Ye, Shuiguang Deng', 'link': 'https://arxiv.org/abs/2507.14811', 'abstract': 'Diffusion models have demonstrated exceptional generative capabilities but are computationally intensive, posing significant challenges for deployment in resource-constrained or latency-sensitive environments. Quantization offers an effective means to reduce model size and computational cost, with post-training quantization (PTQ) being particularly appealing due to its compatibility with pre-trained models without requiring retraining or training data. However, existing PTQ methods for diffusion models often rely on architecture-specific heuristics that limit their generalizability and hinder integration with industrial deployment pipelines. To address these limitations, we propose SegQuant, a unified quantization framework that adaptively combines complementary techniques to enhance cross-model versatility. SegQuant consists of a segment-aware, graph-based quantization strategy (SegLinear) that captures structural semantics and spatial heterogeneity, along with a dual-scale quantization scheme (DualScale) that preserves polarity-asymmetric activations, which is crucial for maintaining visual fidelity in generated outputs. SegQuant is broadly applicable beyond Transformer-based diffusion models, achieving strong performance while ensuring seamless compatibility with mainstream deployment tools.', 'abstract_zh': '扩散模型展示了优异的生成能力，但在资源受限或对延迟敏感的环境中部署时计算成本高昂，提出了显著挑战。量化提供了一种有效减少模型大小和计算成本的方法，其中后训练量化(PTQ)特别令人瞩目，因为它可以与预训练模型兼容，无需重新训练或额外的数据。然而，现有的扩散模型PTQ方法常常依赖于特定架构的启发式方法，这限制了其普适性并阻碍了与工业部署管道的集成。为了解决这些局限性，我们提出了一种统一的量化框架SegQuant，该框架能够自适应地结合互补技术以增强跨模型的灵活性。SegQuant 包括一种基于图的、感知段落的量化策略(SegLinear)，该策略捕捉结构语义和空间异质性，以及一种双尺度量化方案(DualScale)，该方案保持不对称激活，这对于保持生成输出的视觉保真度至关重要。SegQuant 不仅适用于基于Transformer的扩散模型，还表现出强大的性能，并确保与主流部署工具无缝兼容。', 'title_zh': 'SemQuant: 具有语义意识和泛化能力的扩散模型量化框架'}
{'arxiv_id': 'arXiv:2507.14767', 'title': 'XplainAct: Visualization for Personalized Intervention Insights', 'authors': 'Yanming Zhang, Krishnakumar Hegde, Klaus Mueller', 'link': 'https://arxiv.org/abs/2507.14767', 'abstract': 'Causality helps people reason about and understand complex systems, particularly through what-if analyses that explore how interventions might alter outcomes. Although existing methods embrace causal reasoning using interventions and counterfactual analysis, they primarily focus on effects at the population level. These approaches often fall short in systems characterized by significant heterogeneity, where the impact of an intervention can vary widely across subgroups. To address this challenge, we present XplainAct, a visual analytics framework that supports simulating, explaining, and reasoning interventions at the individual level within subpopulations. We demonstrate the effectiveness of XplainAct through two case studies: investigating opioid-related deaths in epidemiology and analyzing voting inclinations in the presidential election.', 'abstract_zh': '因果关系有助于人们推理和理解复杂系统，特别是通过情景分析来探究干预措施如何改变结果。尽管现有的方法使用干预和反事实分析来支持因果推理，但它们主要关注整体层面的效果。这些方法在具有显著异质性的系统中往往表现不佳，因为干预的影响在不同子群体中可能差异很大。为了解决这一挑战，我们提出了XplainAct这一可视化分析框架，支持在子群体中对个体水平的干预进行模拟、解释和推理。我们通过两个案例研究展示了XplainAct的有效性：研究流行病学中的阿片类药物相关死亡事件，以及分析总统选举中的投票倾向。', 'title_zh': 'XplainAct：个性化干预洞察可视化'}
{'arxiv_id': 'arXiv:2507.14760', 'title': 'QUTCC: Quantile Uncertainty Training and Conformal Calibration for Imaging Inverse Problems', 'authors': 'Cassandra Tong Ye, Shamus Li, Tyler King, Kristina Monakhova', 'link': 'https://arxiv.org/abs/2507.14760', 'abstract': 'Deep learning models often hallucinate, producing realistic artifacts that are not truly present in the sample. This can have dire consequences for scientific and medical inverse problems, such as MRI and microscopy denoising, where accuracy is more important than perceptual quality. Uncertainty quantification techniques, such as conformal prediction, can pinpoint outliers and provide guarantees for image regression tasks, improving reliability. However, existing methods utilize a linear constant scaling factor to calibrate uncertainty bounds, resulting in larger, less informative bounds. We propose QUTCC, a quantile uncertainty training and calibration technique that enables nonlinear, non-uniform scaling of quantile predictions to enable tighter uncertainty estimates. Using a U-Net architecture with a quantile embedding, QUTCC enables the prediction of the full conditional distribution of quantiles for the imaging task. During calibration, QUTCC generates uncertainty bounds by iteratively querying the network for upper and lower quantiles, progressively refining the bounds to obtain a tighter interval that captures the desired coverage. We evaluate our method on several denoising tasks as well as compressive MRI reconstruction. Our method successfully pinpoints hallucinations in image estimates and consistently achieves tighter uncertainty intervals than prior methods while maintaining the same statistical coverage.', 'abstract_zh': '基于深度学习模型的图像处理中非真实artifact的量化不确定性训练与校准技术', 'title_zh': 'QUTCC: 基于分位数不确定性训练与渐进校准的成像逆问题方法'}
{'arxiv_id': 'arXiv:2507.14758', 'title': 'GRACE: Generative Recommendation via Journey-Aware Sparse Attention on Chain-of-Thought Tokenization', 'authors': 'Luyi Ma, Wanjia Zhang, Kai Zhao, Abhishek Kulkarni, Lalitesh Morishetti, Anjana Ganesh, Ashish Ranjan, Aashika Padmanabhan, Jianpeng Xu, Jason Cho, Praveen Kanumala, Kaushiki Nag, Sumit Dutta, Kamiya Motwani, Malay Patel, Evren Korpeoglu, Sushant Kumar, Kannan Achan', 'link': 'https://arxiv.org/abs/2507.14758', 'abstract': 'Generative models have recently demonstrated strong potential in multi-behavior recommendation systems, leveraging the expressive power of transformers and tokenization to generate personalized item sequences. However, their adoption is hindered by (1) the lack of explicit information for token reasoning, (2) high computational costs due to quadratic attention complexity and dense sequence representations after tokenization, and (3) limited multi-scale modeling over user history. In this work, we propose GRACE (Generative Recommendation via journey-aware sparse Attention on Chain-of-thought tokEnization), a novel generative framework for multi-behavior sequential recommendation. GRACE introduces a hybrid Chain-of-Thought (CoT) tokenization method that encodes user-item interactions with explicit attributes from product knowledge graphs (e.g., category, brand, price) over semantic tokenization, enabling interpretable and behavior-aligned generation. To address the inefficiency of standard attention, we design a Journey-Aware Sparse Attention (JSA) mechanism, which selectively attends to compressed, intra-, inter-, and current-context segments in the tokenized sequence. Experiments on two real-world datasets show that GRACE significantly outperforms state-of-the-art baselines, achieving up to +106.9% HR@10 and +106.7% NDCG@10 improvement over the state-of-the-art baseline on the Home domain, and +22.1% HR@10 on the Electronics domain. GRACE also reduces attention computation by up to 48% with long sequences.', 'abstract_zh': '基于旅程意识稀疏注意力的链式思考token化生成推荐算法', 'title_zh': 'GRACE：基于旅程意识稀疏注意力的链式思考生成推荐'}
{'arxiv_id': 'arXiv:2507.14757', 'title': 'Analyzing Internal Activity and Robustness of SNNs Across Neuron Parameter Space', 'authors': 'Szymon Mazurek, Jakub Caputa, Maciej Wielgosz', 'link': 'https://arxiv.org/abs/2507.14757', 'abstract': 'Spiking Neural Networks (SNNs) offer energy-efficient and biologically plausible alternatives to traditional artificial neural networks, but their performance depends critically on the tuning of neuron model parameters. In this work, we identify and characterize an operational space - a constrained region in the neuron hyperparameter domain (specifically membrane time constant tau and voltage threshold vth) - within which the network exhibits meaningful activity and functional behavior. Operating inside this manifold yields optimal trade-offs between classification accuracy and spiking activity, while stepping outside leads to degeneration: either excessive energy use or complete network silence.\nThrough systematic exploration across datasets and architectures, we visualize and quantify this manifold and identify efficient operating points. We further assess robustness to adversarial noise, showing that SNNs exhibit increased spike correlation and internal synchrony when operating outside their optimal region. These findings highlight the importance of principled hyperparameter tuning to ensure both task performance and energy efficiency. Our results offer practical guidelines for deploying robust and efficient SNNs, particularly in neuromorphic computing scenarios.', 'abstract_zh': '基于神经元模型参数调谐的高效和生物可塑性强脉冲神经网络的操作空间研究', 'title_zh': '分析SNNs在神经元参数空间内的内部活动和鲁棒性'}
{'arxiv_id': 'arXiv:2507.14748', 'title': 'Skill Learning via Policy Diversity Yields Identifiable Representations for Reinforcement Learning', 'authors': 'Patrik Reizinger, Bálint Mucsányi, Siyuan Guo, Benjamin Eysenbach, Bernhard Schölkopf, Wieland Brendel', 'link': 'https://arxiv.org/abs/2507.14748', 'abstract': "Self-supervised feature learning and pretraining methods in reinforcement learning (RL) often rely on information-theoretic principles, termed mutual information skill learning (MISL). These methods aim to learn a representation of the environment while also incentivizing exploration thereof. However, the role of the representation and mutual information parametrization in MISL is not yet well understood theoretically. Our work investigates MISL through the lens of identifiable representation learning by focusing on the Contrastive Successor Features (CSF) method. We prove that CSF can provably recover the environment's ground-truth features up to a linear transformation due to the inner product parametrization of the features and skill diversity in a discriminative sense. This first identifiability guarantee for representation learning in RL also helps explain the implications of different mutual information objectives and the downsides of entropy regularizers. We empirically validate our claims in MuJoCo and DeepMind Control and show how CSF provably recovers the ground-truth features both from states and pixels.", 'abstract_zh': '自监督特征学习和预训练方法在强化学习（RL）中的信息论原理，即互信息技能学习（MISL），通过可识别表示学习视角对MISL进行研究', 'title_zh': '基于策略多样性的技能学习生成可识别的表示形式'}
{'arxiv_id': 'arXiv:2507.14722', 'title': 'LeanTree: Accelerating White-Box Proof Search with Factorized States in Lean 4', 'authors': 'Matěj Kripner, Michal Šustr, Milan Straka', 'link': 'https://arxiv.org/abs/2507.14722', 'abstract': 'Automated theorem proving (ATP) has been a classical problem in artificial intelligence since its inception, yet it remains challenging due to its vast state and action space. Large language models (LLMs) have recently emerged as a promising heuristic for ATP, but they lack correctness guarantees and thus require interaction with a proof verifier. Such interactions typically follow one of two approaches: black-box interaction, which does not utilize intermediate proof states, or white-box approaches, which allow for incremental proof construction and examination of intermediate states. While black-box approaches have directly benefited from recent LLM advances, white-box methods have comparatively lagged behind. In this paper, we address this gap by introducing LeanTree, which consists of (i) a tool built in the Lean 4 language that factorizes complex proof states into simpler, independent branches, and (ii) a dataset of these factorized intermediate states. Our white-box tooling offers several advantages over black-box approaches: it simplifies evaluation, reduces necessary context, generates richer training data, enables parallel search across multiple states, supports efficient reuse of states, and provides feedback in case of errors. Our preliminary results hint that white-box approaches outperform black-box alternatives in some settings.', 'abstract_zh': '自动定理证明（ATP）自人工智能诞生之日起就是经典问题，但由于其庞大的状态和动作空间，依然极具挑战性。近年来，大型语言模型（LLMs）被认为是一种有前景的ATP启发式方法，但缺乏正确性保证，因此需要与证明验证器交互。此类交互通常遵循两种方法之一：黑箱交互，不利用中间证明状态；或白箱方法，允许增量证明构建并检查中间状态。尽管黑箱方法直接受益于最近的LLM进展，白箱方法则相对滞后。本文通过引入LeanTree来填补这一空白，LeanTree包括（i）一种基于Lean 4语言的工具，将复杂的证明状态分解为更简单、独立的分支，以及（ii）这些分解的中间状态的数据集。我们的白箱工具提供了黑箱方法的多项优势：简化评估、减少必要上下文、生成更丰富的训练数据、支持在多个状态上并行搜索、支持状态的高效重用，并在出现错误时提供反馈。初步结果表明，在某些情况下，白箱方法优于黑箱替代方法。', 'title_zh': 'LeanTree: 在 Lean 4 中使用因子化状态加速白盒证明搜索'}
{'arxiv_id': 'arXiv:2507.14706', 'title': 'Fraud is Not Just Rarity: A Causal Prototype Attention Approach to Realistic Synthetic Oversampling', 'authors': 'Claudio Giusti, Luca Guarnera, Mirko Casu, Sebastiano Battiato', 'link': 'https://arxiv.org/abs/2507.14706', 'abstract': 'Detecting fraudulent credit card transactions remains a significant challenge, due to the extreme class imbalance in real-world data and the often subtle patterns that separate fraud from legitimate activity. Existing research commonly attempts to address this by generating synthetic samples for the minority class using approaches such as GANs, VAEs, or hybrid generative models. However, these techniques, particularly when applied only to minority-class data, tend to result in overconfident classifiers and poor latent cluster separation, ultimately limiting real-world detection performance. In this study, we propose the Causal Prototype Attention Classifier (CPAC), an interpretable architecture that promotes class-aware clustering and improved latent space structure through prototype-based attention mechanisms and we will couple it with the encoder in a VAE-GAN allowing it to offer a better cluster separation moving beyond post-hoc sample augmentation. We compared CPAC-augmented models to traditional oversamplers, such as SMOTE, as well as to state-of-the-art generative models, both with and without CPAC-based latent classifiers. Our results show that classifier-guided latent shaping with CPAC delivers superior performance, achieving an F1-score of 93.14\\% percent and recall of 90.18\\%, along with improved latent cluster separation. Further ablation studies and visualizations provide deeper insight into the benefits and limitations of classifier-driven representation learning for fraud detection. The codebase for this work will be available at final submission.', 'abstract_zh': '基于因果原型注意机制的欺诈信用卡交易检测方法：超越事后样本增强的潜在空间结构优化', 'title_zh': '欺诈不仅是罕见事件：一种因果原型注意力方法实现现实合成过采样'}
{'arxiv_id': 'arXiv:2507.14698', 'title': 'Spatial-Temporal Transformer with Curriculum Learning for EEG-Based Emotion Recognition', 'authors': 'Xuetao Lin, Tianhao Peng, Peihong Dai, Yu Liang, Wenjun Wu', 'link': 'https://arxiv.org/abs/2507.14698', 'abstract': 'EEG-based emotion recognition plays an important role in developing adaptive brain-computer communication systems, yet faces two fundamental challenges in practical implementations: (1) effective integration of non-stationary spatial-temporal neural patterns, (2) robust adaptation to dynamic emotional intensity variations in real-world scenarios. This paper proposes SST-CL, a novel framework integrating spatial-temporal transformers with curriculum learning. Our method introduces two core components: a spatial encoder that models inter-channel relationships and a temporal encoder that captures multi-scale dependencies through windowed attention mechanisms, enabling simultaneous extraction of spatial correlations and temporal dynamics from EEG signals. Complementing this architecture, an intensity-aware curriculum learning strategy progressively guides training from high-intensity to low-intensity emotional states through dynamic sample scheduling based on a dual difficulty assessment. Comprehensive experiments on three benchmark datasets demonstrate state-of-the-art performance across various emotional intensity levels, with ablation studies confirming the necessity of both architectural components and the curriculum learning mechanism.', 'abstract_zh': '基于EEG的情绪识别在开发适应性脑机通信系统中扮演重要角色，但在实际应用中面临两个基本挑战：(1) 有效集成非平稳的空间- temporal神经模式，(2) 在现实场景中 robust应 动态情绪强度的变化。本文提出了一种新颖的框架SST-CL，该框架结合了空间- temporal变换器和 curriculum学习。我们的方法引入了两种核心组件：一个空间编码器，用于建模通道间关系；一个时间编码器，通过窗口注意力机制捕获多尺度依赖性，从而同时从EEG信号中提取空间相关性和时间动态性。作为该架构的补充，一种情绪感知的curriculum学习策略逐步通过基于双重难度评估的动态样本调度来引导从高强度到低强度情绪状态的训练。在三个基准数据集上的全面实验表明，该方法在各种情绪强度水平上具有最先进的性能，消融研究证实了两种架构组件和curriculum学习机制的必要性。', 'title_zh': '基于EEG的情感识别中的渐增学习空间-时间变换器'}
{'arxiv_id': 'arXiv:2507.14693', 'title': 'Rethinking Suicidal Ideation Detection: A Trustworthy Annotation Framework and Cross-Lingual Model Evaluation', 'authors': 'Amina Dzafic, Merve Kavut, Ulya Bayram', 'link': 'https://arxiv.org/abs/2507.14693', 'abstract': 'Suicidal ideation detection is critical for real-time suicide prevention, yet its progress faces two under-explored challenges: limited language coverage and unreliable annotation practices. Most available datasets are in English, but even among these, high-quality, human-annotated data remains scarce. As a result, many studies rely on available pre-labeled datasets without examining their annotation process or label reliability. The lack of datasets in other languages further limits the global realization of suicide prevention via artificial intelligence (AI). In this study, we address one of these gaps by constructing a novel Turkish suicidal ideation corpus derived from social media posts and introducing a resource-efficient annotation framework involving three human annotators and two large language models (LLMs). We then address the remaining gaps by performing a bidirectional evaluation of label reliability and model consistency across this dataset and three popular English suicidal ideation detection datasets, using transfer learning through eight pre-trained sentiment and emotion classifiers. These transformers help assess annotation consistency and benchmark model performance against manually labeled data. Our findings underscore the need for more rigorous, language-inclusive approaches to annotation and evaluation in mental health natural language processing (NLP) while demonstrating the questionable performance of popular models with zero-shot transfer learning. We advocate for transparency in model training and dataset construction in mental health NLP, prioritizing data and model reliability.', 'abstract_zh': '自杀 ideation 检测对于实时自杀预防至关重要，但其进展面临两个未被充分研究的挑战：有限的语言覆盖面和不可靠的注释实践。', 'title_zh': '重新思考自杀意念检测：可信赖的注释框架与跨语言模型评估'}
{'arxiv_id': 'arXiv:2507.14679', 'title': 'GCC-Spam: Spam Detection via GAN, Contrastive Learning, and Character Similarity Networks', 'authors': 'Zixin Xu, Zhijie Wang, Zhiyuan Pan', 'link': 'https://arxiv.org/abs/2507.14679', 'abstract': 'The exponential growth of spam text on the Internet necessitates robust detection mechanisms to mitigate risks such as information leakage and social instability. This work addresses two principal challenges: adversarial strategies employed by spammers and the scarcity of labeled data. We propose a novel spam-text detection framework GCC-Spam, which integrates three core innovations. First, a character similarity network captures orthographic and phonetic features to counter character-obfuscation attacks and furthermore produces sentence embeddings for downstream classification. Second, contrastive learning enhances discriminability by optimizing the latent-space distance between spam and normal texts. Third, a Generative Adversarial Network (GAN) generates realistic pseudo-spam samples to alleviate data scarcity while improving model robustness and classification accuracy. Extensive experiments on real-world datasets demonstrate that our model outperforms baseline approaches, achieving higher detection rates with significantly fewer labeled examples.', 'abstract_zh': '互联网上垃圾文本的指数级增长 necessitates robust detection mechanisms to mitigate risks such as information leakage and social instability. This work addresses two principal challenges: adversarial strategies employed by spammers and the scarcity of labeled data. We propose a novel spam-text detection framework GCC-Spam, which integrates three core innovations. First, a character similarity network captures orthographic and phonetic features to counter character-obfuscation attacks and furthermore produces sentence embeddings for downstream classification. Second, contrastive learning enhances discriminability by optimizing the latent-space distance between spam and normal texts. Third, a Generative Adversarial Network (GAN) generates realistic pseudo-spam samples to alleviate data scarcity while improving model robustness and classification accuracy. Extensive experiments on real-world datasets demonstrate that our model outperforms baseline approaches, achieving higher detection rates with significantly fewer labeled examples.', 'title_zh': 'GCC-Spam: 通过生成对抗网络、对比学习和字符相似性网络的垃圾信息检测方法'}
{'arxiv_id': 'arXiv:2507.14629', 'title': 'VMask: Tunable Label Privacy Protection for Vertical Federated Learning via Layer Masking', 'authors': 'Juntao Tan, Lan Zhang, Zhonghao Hu, Kai Yang, Peng Ran, Bo Li', 'link': 'https://arxiv.org/abs/2507.14629', 'abstract': "Though vertical federated learning (VFL) is generally considered to be privacy-preserving, recent studies have shown that VFL system is vulnerable to label inference attacks originating from various attack surfaces. Among these attacks, the model completion (MC) attack is currently the most powerful one. Existing defense methods against it either sacrifice model accuracy or incur impractical computational overhead. In this paper, we propose VMask, a novel label privacy protection framework designed to defend against MC attack from the perspective of layer masking. Our key insight is to disrupt the strong correlation between input data and intermediate outputs by applying the secret sharing (SS) technique to mask layer parameters in the attacker's model. We devise a strategy for selecting critical layers to mask, reducing the overhead that would arise from naively applying SS to the entire model. Moreover, VMask is the first framework to offer a tunable privacy budget to defenders, allowing for flexible control over the levels of label privacy according to actual requirements. We built a VFL system, implemented VMask on it, and extensively evaluated it using five model architectures and 13 datasets with different modalities, comparing it to 12 other defense methods. The results demonstrate that VMask achieves the best privacy-utility trade-off, successfully thwarting the MC attack (reducing the label inference accuracy to a random guessing level) while preserving model performance (e.g., in Transformer-based model, the averaged drop of VFL model accuracy is only 0.09%). VMask's runtime is up to 60,846 times faster than cryptography-based methods, and it only marginally exceeds that of standard VFL by 1.8 times in a large Transformer-based model, which is generally acceptable.", 'abstract_zh': '尽管垂直联邦学习（VFL）通常被认为是隐私保护的，但近期研究显示，VFL系统容易受到来自各种攻击面的标签推断攻击。在这些攻击中，模型完成（MC）攻击目前是最强大的一种。现有的防御方法要么牺牲模型准确性，要么引入不切实际的计算开销。本文提出了一种名为VMask的新型标签隐私保护框架，从层屏蔽的角度出发防御MC攻击。我们的核心见解是通过应用秘密共享（SS）技术来掩盖攻击者模型中的层参数，从而破坏输入数据与中间输出之间的强相关性。我们设计了一种策略来选择关键层进行掩盖，减少盲目应用SS到整个模型会引起的开销。此外，VMask是第一个为防御者提供可调隐私预算的框架，允许根据实际需求灵活控制标签隐私的水平。我们构建了一个VFL系统，在其上实现VMask，并使用五种模型架构和13个具有不同模态的数据集进行了广泛的评估，与12种其他防御方法进行了比较。结果表明，VMask在隐私-效用权衡方面表现最佳，成功抵御了MC攻击（将标签推断准确性降低到随机猜测水平），同时保持了模型性能（例如，在基于Transformer的模型中，VFL模型准确性的平均下降幅度仅为0.09%）。VMask的运行时间比基于密码学的方法快60,846倍，在大型基于Transformer的模型中仅比标准VFL超出1.8倍，这通常是可接受的。', 'title_zh': 'VMask：基于层掩膜的可调标签隐私保护方法在垂直联邦学习中的应用'}
{'arxiv_id': 'arXiv:2507.14625', 'title': 'VTarbel: Targeted Label Attack with Minimal Knowledge on Detector-enhanced Vertical Federated Learning', 'authors': 'Juntao Tan, Anran Li, Quanchao Liu, Peng Ran, Lan Zhang', 'link': 'https://arxiv.org/abs/2507.14625', 'abstract': "Vertical federated learning (VFL) enables multiple parties with disjoint features to collaboratively train models without sharing raw data. While privacy vulnerabilities of VFL are extensively-studied, its security threats-particularly targeted label attacks-remain underexplored. In such attacks, a passive party perturbs inputs at inference to force misclassification into adversary-chosen labels. Existing methods rely on unrealistic assumptions (e.g., accessing VFL-model's outputs) and ignore anomaly detectors deployed in real-world systems. To bridge this gap, we introduce VTarbel, a two-stage, minimal-knowledge attack framework explicitly designed to evade detector-enhanced VFL inference. During the preparation stage, the attacker selects a minimal set of high-expressiveness samples (via maximum mean discrepancy), submits them through VFL protocol to collect predicted labels, and uses these pseudo-labels to train estimated detector and surrogate model on local features. In attack stage, these models guide gradient-based perturbations of remaining samples, crafting adversarial instances that induce targeted misclassifications and evade detection. We implement VTarbel and evaluate it against four model architectures, seven multimodal datasets, and two anomaly detectors. Across all settings, VTarbel outperforms four state-of-the-art baselines, evades detection, and retains effective against three representative privacy-preserving defenses. These results reveal critical security blind spots in current VFL deployments and underscore urgent need for robust, attack-aware defenses.", 'abstract_zh': '垂直联邦学习中的VTarbel：一种规避检测增强垂直联邦学习推理的两阶段小知识攻击框架', 'title_zh': 'VTarbel：基于检测增强垂直联邦学习的最小知识 targeted 标签攻击'}
{'arxiv_id': 'arXiv:2507.14615', 'title': 'Retrieval-Augmented Clinical Benchmarking for Contextual Model Testing in Kenyan Primary Care: A Methodology Paper', 'authors': 'Fred Mutisya, Shikoh Gitau, Christine Syovata, Diana Oigara, Ibrahim Matende, Muna Aden, Munira Ali, Ryan Nyotu, Diana Marion, Job Nyangena, Nasubo Ongoma, Keith Mbae, Elizabeth Wamicha, Eric Mibuari, Jean Philbert Nsengemana, Talkmore Chidede', 'link': 'https://arxiv.org/abs/2507.14615', 'abstract': "Large Language Models(LLMs) hold promise for improving healthcare access in low-resource settings, but their effectiveness in African primary care remains underexplored. We present a methodology for creating a benchmark dataset and evaluation framework focused on Kenyan Level 2 and 3 clinical care. Our approach uses retrieval augmented generation (RAG) to ground clinical questions in Kenya's national guidelines, ensuring alignment with local standards. These guidelines were digitized, chunked, and indexed for semantic retrieval. Gemini Flash 2.0 Lite was then prompted with guideline excerpts to generate realistic clinical scenarios, multiple-choice questions, and rationale based answers in English and Swahili. Kenyan physicians co-created and refined the dataset, and a blinded expert review process ensured clinical accuracy, clarity, and cultural appropriateness. The resulting Alama Health QA dataset includes thousands of regulator-aligned question answer pairs across common outpatient conditions. Beyond accuracy, we introduce evaluation metrics that test clinical reasoning, safety, and adaptability such as rare case detection (Needle in the Haystack), stepwise logic (Decision Points), and contextual adaptability. Initial results reveal significant performance gaps when LLMs are applied to localized scenarios, consistent with findings that LLM accuracy is lower on African medical content than on US-based benchmarks. This work offers a replicable model for guideline-driven, dynamic benchmarking to support safe AI deployment in African health systems.", 'abstract_zh': '大型语言模型(LLMs)在提高低资源地区医疗 accessibility 方面前景广阔，但其在非洲初级保健中的有效性仍待深入探索。我们提出了一个针对肯尼亚二级和三级临床护理的基准数据集和评估框架的创建方法。该方法利用检索增强生成(RAG)技术，将临床问题与肯尼亚国家级指南对接，确保与当地标准的吻合。这些指南进行了数字化、分块和语义索引处理。Gemini Flash 2.0 Lite 接受了部分指南内容的提示，生成了英文和斯瓦希里语的现实临床情景、多项选择题及其答案解释。肯尼亚医生共同创建和完善了数据集，盲审专家过程确保了临床准确性、清晰性和文化适宜性。生成的 Alama Health QA 数据集包含数千个与常见门诊疾病对齐的问答对。除了准确性，我们还引入了测试临床推理、安全性和适应性的评估指标，如罕见案例检测（在干草堆中找针）、逐步逻辑（决策点）和上下文适应性。初步结果显示，当将 LLM 应用于本地化场景时，存在显著性能差距，这与 LLM 在非洲医学内容上的准确性低于美国基准的发现相符。本工作提供了一种可复制的基于指南的动态基准模型，以支持非洲卫生系统的安全 AI 部署。', 'title_zh': '基于检索增强的临床基准测试方法在肯yan初级保健情境模型测试中应用：一种方法论论文'}
{'arxiv_id': 'arXiv:2507.14612', 'title': 'Enhancing POI Recommendation through Global Graph Disentanglement with POI Weighted Module', 'authors': 'Pei-Xuan Li, Wei-Yun Liang, Fandel Lin, Hsun-Ping Hsieh', 'link': 'https://arxiv.org/abs/2507.14612', 'abstract': "Next point of interest (POI) recommendation primarily predicts future activities based on users' past check-in data and current status, providing significant value to users and service providers. We observed that the popular check-in times for different POI categories vary. For example, coffee shops are crowded in the afternoon because people like to have coffee to refresh after meals, while bars are busy late at night. However, existing methods rarely explore the relationship between POI categories and time, which may result in the model being unable to fully learn users' tendencies to visit certain POI categories at different times. Additionally, existing methods for modeling time information often convert it into time embeddings or calculate the time interval and incorporate it into the model, making it difficult to capture the continuity of time. Finally, during POI prediction, various weighting information is often ignored, such as the popularity of each POI, the transition relationships between POIs, and the distances between POIs, leading to suboptimal performance. To address these issues, this paper proposes a novel next POI recommendation framework called Graph Disentangler with POI Weighted Module (GDPW). This framework aims to jointly consider POI category information and multiple POI weighting factors. Specifically, the proposed GDPW learns category and time representations through the Global Category Graph and the Global Category-Time Graph. Then, we disentangle category and time information through contrastive learning. After prediction, the final POI recommendation for users is obtained by weighting the prediction results based on the transition weights and distance relationships between POIs. We conducted experiments on two real-world datasets, and the results demonstrate that the proposed GDPW outperforms other existing models, improving performance by 3% to 11%.", 'abstract_zh': '基于图解纠缠的POI权重模块下一步点兴趣推荐框架（GDPW）', 'title_zh': '通过POI加权模块全球图去纠缠增强POI推荐'}
{'arxiv_id': 'arXiv:2507.14584', 'title': 'Explainable Collaborative Problem Solving Diagnosis with BERT using SHAP and its Implications for Teacher Adoption', 'authors': 'Kester Wong, Sahan Bulathwela, Mutlu Cukurova', 'link': 'https://arxiv.org/abs/2507.14584', 'abstract': "The use of Bidirectional Encoder Representations from Transformers (BERT) model and its variants for classifying collaborative problem solving (CPS) has been extensively explored within the AI in Education community. However, limited attention has been given to understanding how individual tokenised words in the dataset contribute to the model's classification decisions. Enhancing the explainability of BERT-based CPS diagnostics is essential to better inform end users such as teachers, thereby fostering greater trust and facilitating wider adoption in education. This study undertook a preliminary step towards model transparency and explainability by using SHapley Additive exPlanations (SHAP) to examine how different tokenised words in transcription data contributed to a BERT model's classification of CPS processes. The findings suggested that well-performing classifications did not necessarily equate to a reasonable explanation for the classification decisions. Particular tokenised words were used frequently to affect classifications. The analysis also identified a spurious word, which contributed positively to the classification but was not semantically meaningful to the class. While such model transparency is unlikely to be useful to an end user to improve their practice, it can help them not to overrely on LLM diagnostics and ignore their human expertise. We conclude the workshop paper by noting that the extent to which the model appropriately uses the tokens for its classification is associated with the number of classes involved. It calls for an investigation into the exploration of ensemble model architectures and the involvement of human-AI complementarity for CPS diagnosis, since considerable human reasoning is still required for fine-grained discrimination of CPS subskills.", 'abstract_zh': '使用Bidirectional Encoder Representations from Transformers（BERT）模型及其变体对协作问题解决（CPS）进行分类在教育人工智能领域得到了广泛探索，但鲜有研究关注数据集中个体词令牌如何影响模型的分类决策。通过使用SHapley Additive exPlanations（SHAP）来增强基于BERT的CPS诊断的可解释性，对于更好地指导教师等终端用户并促进教育中更广泛的应用至关重要。本文通过分析转录数据中不同词令牌如何影响BERT模型对CPS过程的分类，初步探索了模型透明性和可解释性。研究发现，表现良好的分类并不一定提供合理的解释，特定的词令牌经常用于影响分类。分析还发现了一个相关的无意义词语，它虽然对分类有正面贡献，但并不具有语义意义。尽管这种模型透明性对于改进终端用户的实践可能无用，但它可以帮助他们不过度依赖于大型语言模型的诊断，并忽略自己的人类专长。文中指出，模型在分类中适当使用词令牌的程度与涉及的类别数量相关，这需要进一步研究集成模型架构和人机互补在CPS诊断中的作用，因为精细区分CPS子技能仍需要大量的人类推理。', 'title_zh': '基于BERT、使用SHAP的可解释协作问题解决诊断及其对教师采纳的 implications'}
{'arxiv_id': 'arXiv:2507.14579', 'title': 'Exploring Human-AI Complementarity in CPS Diagnosis Using Unimodal and Multimodal BERT Models', 'authors': 'Kester Wong, Sahan Bulathwela, Mutlu Cukurova', 'link': 'https://arxiv.org/abs/2507.14579', 'abstract': 'Detecting collaborative problem solving (CPS) indicators from dialogue using machine learning techniques is a significant challenge for the field of AI in Education. Recent studies have explored the use of Bidirectional Encoder Representations from Transformers (BERT) models on transcription data to reliably detect meaningful CPS indicators. A notable advancement involved the multimodal BERT variant, AudiBERT, which integrates speech and acoustic-prosodic audio features to enhance CPS diagnosis. Although initial results demonstrated multimodal improvements, the statistical significance of these enhancements remained unclear, and there was insufficient guidance on leveraging human-AI complementarity for CPS diagnosis tasks. This workshop paper extends the previous research by highlighting that the AudiBERT model not only improved the classification of classes that were sparse in the dataset, but it also had statistically significant class-wise improvements over the BERT model for classifications in the social-cognitive dimension. However, similar significant class-wise improvements over the BERT model were not observed for classifications in the affective dimension. A correlation analysis highlighted that larger training data was significantly associated with higher recall performance for both the AudiBERT and BERT models. Additionally, the precision of the BERT model was significantly associated with high inter-rater agreement among human coders. When employing the BERT model to diagnose indicators within these subskills that were well-detected by the AudiBERT model, the performance across all indicators was inconsistent. We conclude the paper by outlining a structured approach towards achieving human-AI complementarity for CPS diagnosis, highlighting the crucial inclusion of model explainability to support human agency and engagement in the reflective coding process.', 'abstract_zh': '使用机器学习技术从对话中检测协作问题解决（CPS）指标是教育人工智能领域的 significan挑战。最近的研究探索了在转录数据上使用双向编码器表示变换器（BERT）模型以可靠地检测有意义的CPS指标。一个重要进展是多模态BERT变体AudiBERT，它整合了语音和声学-语调音频特征，以增强CPS诊断。尽管初始结果表明多模态改进是有效的，但这些改进的统计显著性仍然不明确，并且在利用人类-人工智能互补性进行CPS诊断任务方面缺乏指导。该工作坊论文扩展了先前的研究，强调AudiBERT模型不仅提高了数据集中稀疏类别的分类性能，还在社会认知维度上的分类中，AudiBERT模型相对于BERT模型具有统计显著性的类别间改进。然而，在情感维度上的分类中，并未观察到类似的显著类别改进。相关性分析表明，更大的训练数据与AudiBERT和BERT模型的更高召回性能显著关联。此外，BERT模型的精度与人类编码者之间的一致性显著相关。在使用BERT模型诊断由AudiBERT模型很好地检测到的这些亚技能内的指标时，所有指标的性能是不一致的。本文总结了实现人类-人工智能互补性的结构化方法，强调了模型可解释性对于支持人类在反思编码过程中的自主性和参与的重要性。', 'title_zh': '探索基于单模态和多模态BERT模型的CPS诊断中的人机互补性研究'}
{'arxiv_id': 'arXiv:2507.14570', 'title': 'LPS-GNN : Deploying Graph Neural Networks on Graphs with 100-Billion Edges', 'authors': 'Xu Cheng, Liang Yao, Feng He, Yukuo Cen, Yufei He, Chenhui Zhang, Wenzheng Feng, Hongyun Cai, Jie Tang', 'link': 'https://arxiv.org/abs/2507.14570', 'abstract': "Graph Neural Networks (GNNs) have emerged as powerful tools for various graph mining tasks, yet existing scalable solutions often struggle to balance execution efficiency with prediction accuracy. These difficulties stem from iterative message-passing techniques, which place significant computational demands and require extensive GPU memory, particularly when dealing with the neighbor explosion issue inherent in large-scale graphs. This paper introduces a scalable, low-cost, flexible, and efficient GNN framework called LPS-GNN, which can perform representation learning on 100 billion graphs with a single GPU in 10 hours and shows a 13.8% improvement in User Acquisition scenarios. We examine existing graph partitioning methods and design a superior graph partition algorithm named LPMetis. In particular, LPMetis outperforms current state-of-the-art (SOTA) approaches on various evaluation metrics. In addition, our paper proposes a subgraph augmentation strategy to enhance the model's predictive performance. It exhibits excellent compatibility, allowing the entire framework to accommodate various GNN algorithms. Successfully deployed on the Tencent platform, LPS-GNN has been tested on public and real-world datasets, achieving performance lifts of 8. 24% to 13. 89% over SOTA models in online applications.", 'abstract_zh': '一种名为LPS-GNN的可扩展、低成本、灵活且高效的图神经网络框架', 'title_zh': 'LPS-GNN：在拥有1000亿条边的图上部署图神经网络'}
{'arxiv_id': 'arXiv:2507.14519', 'title': 'Towards Efficient Privacy-Preserving Machine Learning: A Systematic Review from Protocol, Model, and System Perspectives', 'authors': 'Wenxuan Zeng, Tianshi Xu, Yi Chen, Yifan Zhou, Mingzhe Zhang, Jin Tan, Cheng Hong, Meng Li', 'link': 'https://arxiv.org/abs/2507.14519', 'abstract': 'Privacy-preserving machine learning (PPML) based on cryptographic protocols has emerged as a promising paradigm to protect user data privacy in cloud-based machine learning services. While it achieves formal privacy protection, PPML often incurs significant efficiency and scalability costs due to orders of magnitude overhead compared to the plaintext counterpart. Therefore, there has been a considerable focus on mitigating the efficiency gap for PPML. In this survey, we provide a comprehensive and systematic review of recent PPML studies with a focus on cross-level optimizations. Specifically, we categorize existing papers into protocol level, model level, and system level, and review progress at each level. We also provide qualitative and quantitative comparisons of existing works with technical insights, based on which we discuss future research directions and highlight the necessity of integrating optimizations across protocol, model, and system levels. We hope this survey can provide an overarching understanding of existing approaches and potentially inspire future breakthroughs in the PPML field. As the field is evolving fast, we also provide a public GitHub repository to continuously track the developments, which is available at this https URL.', 'abstract_zh': '基于密码协议的隐私保护机器学习（PPML）已成为一种有前途的范式，用于保护基于云的机器学习服务中的用户数据隐私。尽管它实现了形式上的隐私保护，但PPML往往由于与明文对应物相比具有数量级的开销而招致显著的效率和扩展性成本。因此，已经相当关注减轻PPML的效率差距。在本综述中，我们提供了一种全面且系统的近期PPML研究的审查，重点在于跨层次优化。具体来说，我们将现有论文分为协议层面、模型层面和系统层面，并在每一层面审查进展。我们还基于现有的工作进行定性与定量比较，并提供技术见解，从而讨论未来研究方向，并强调在协议、模型和系统层面集成优化的必要性。我们希望这篇综述能够提供现有方法的总体理解，并激发PPML领域的未来突破。由于该领域发展迅速，我们还提供了一个公共GitHub仓库，以持续跟踪进展，该仓库可从这个网址访问。', 'title_zh': '面向高效隐私保护机器学习：从协议、模型和系统视角的系统性综述'}
{'arxiv_id': 'arXiv:2507.14516', 'title': 'SDSC:A Structure-Aware Metric for Semantic Signal Representation Learning', 'authors': 'Jeyoung Lee, Hochul Kang', 'link': 'https://arxiv.org/abs/2507.14516', 'abstract': 'We propose the Signal Dice Similarity Coefficient (SDSC), a structure-aware metric function for time series self-supervised representation learning. Most Self-Supervised Learning (SSL) methods for signals commonly adopt distance-based objectives such as mean squared error (MSE), which are sensitive to amplitude, invariant to waveform polarity, and unbounded in scale. These properties hinder semantic alignment and reduce interpretability. SDSC addresses this by quantifying structural agreement between temporal signals based on the intersection of signed amplitudes, derived from the Dice Similarity Coefficient (DSC).Although SDSC is defined as a structure-aware metric, it can be used as a loss by subtracting from 1 and applying a differentiable approximation of the Heaviside function for gradient-based optimization. A hybrid loss formulation is also proposed to combine SDSC with MSE, improving stability and preserving amplitude where necessary. Experiments on forecasting and classification benchmarks demonstrate that SDSC-based pre-training achieves comparable or improved performance over MSE, particularly in in-domain and low-resource scenarios. The results suggest that structural fidelity in signal representations enhances the semantic representation quality, supporting the consideration of structure-aware metrics as viable alternatives to conventional distance-based methods.', 'abstract_zh': '我们提出了信号Dice相似系数（SDSC）：一种用于时间序列自监督表示学习的结构感知度量函数。', 'title_zh': 'SDSC：一种结构意识的语义信号表示学习度量'}
{'arxiv_id': 'arXiv:2507.14507', 'title': 'Diffusion Models for Time Series Forecasting: A Survey', 'authors': 'Chen Su, Zhengzhou Cai, Yuanhe Tian, Zihong Zheng, Yan Song', 'link': 'https://arxiv.org/abs/2507.14507', 'abstract': 'Diffusion models, initially developed for image synthesis, demonstrate remarkable generative capabilities. Recently, their application has expanded to time series forecasting (TSF), yielding promising results. In this survey, we firstly introduce the standard diffusion models and their prevalent variants, explaining their adaptation to TSF tasks. We then provide a comprehensive review of diffusion models for TSF, paying special attention to the sources of conditional information and the mechanisms for integrating this conditioning within the models. In analyzing existing approaches using diffusion models for TSF, we provide a systematic categorization and a comprehensive summary of them in this survey. Furthermore, we examine several foundational diffusion models applied to TSF, alongside commonly used datasets and evaluation metrics. Finally, we discuss current limitations in these approaches and potential future research directions. Overall, this survey details recent progress and future prospects for diffusion models in TSF, serving as a reference for researchers in the field.', 'abstract_zh': '扩散模型最初用于图像合成，展示了出色的生成能力。近年来，它们的应用扩展到时间序列预测（TSF），取得了令人鼓舞的结果。在本文综述中，我们首先介绍标准扩散模型及其常见变体，并解释它们如何适应TSF任务。随后，我们对扩散模型在TSF中的应用进行了全面的综述，特别关注条件信息的来源以及这些信息在模型中集成的机制。在分析使用扩散模型进行TSF的方法时，我们对此综述中这些方法进行了系统的分类和全面总结。此外，我们还考察了几种基础的扩散模型在TSF中的应用，以及常用的数据集和评估指标。最后，我们讨论了这些方法的现有局限性和未来的研究方向。总之，本文综述了扩散模型在TSF中的最新进展和未来前景，为该领域的研究人员提供参考。', 'title_zh': '时间序列预测中的扩散模型：一个综述'}
{'arxiv_id': 'arXiv:2507.14499', 'title': 'Neural Brownian Motion', 'authors': 'Qian Qi', 'link': 'https://arxiv.org/abs/2507.14499', 'abstract': 'This paper introduces the Neural-Brownian Motion (NBM), a new class of stochastic processes for modeling dynamics under learned uncertainty. The NBM is defined axiomatically by replacing the classical martingale property with respect to linear expectation with one relative to a non-linear Neural Expectation Operator, $\\varepsilon^\\theta$, generated by a Backward Stochastic Differential Equation (BSDE) whose driver $f_\\theta$ is parameterized by a neural network. Our main result is a representation theorem for a canonical NBM, which we define as a continuous $\\varepsilon^\\theta$-martingale with zero drift under the physical measure. We prove that, under a key structural assumption on the driver, such a canonical NBM exists and is the unique strong solution to a stochastic differential equation of the form ${\\rm d} M_t = \\nu_\\theta(t, M_t) {\\rm d} W_t$. Crucially, the volatility function $\\nu_\\theta$ is not postulated a priori but is implicitly defined by the algebraic constraint $g_\\theta(t, M_t, \\nu_\\theta(t, M_t)) = 0$, where $g_\\theta$ is a specialization of the BSDE driver. We develop the stochastic calculus for this process and prove a Girsanov-type theorem for the quadratic case, showing that an NBM acquires a drift under a new, learned measure. The character of this measure, whether pessimistic or optimistic, is endogenously determined by the learned parameters $\\theta$, providing a rigorous foundation for models where the attitude towards uncertainty is a discoverable feature.', 'abstract_zh': '这篇论文介绍了神经布朗运动（NBM），这是一种用于在学习到的不确定性下建模动力学的新类随机过程。NBM通过将经典的关于线性期望的鞅性质替换为关于由带有神经网络参数化的驱动项$f_\\theta$的向后随机微分方程（BSDE）生成的非线性神经期望运算子$\\varepsilon^\\theta$的性质来定义。我们的主要结果是对称NBM的表示定理，我们将其定义为在物理测度下的连续$\\varepsilon^\\theta$-鞅且漂移为零。我们证明了，在驱动项的关键结构性假设下，这样的对称NBM存在且是形式为${\\rm d} M_t = \\nu_\\theta(t, M_t) {\\rm d} W_t$的随机微分方程的强解。关键的是，波动函数$\\nu_\\theta$不是先验假定的，而是由代数约束$g_\\theta(t, M_t, \\nu_\\theta(t, M_t)) = 0$隐式定义的，其中$g_\\theta$是BSDE驱动项的特化。我们为此过程发展了随机微积分，并证明了二次情形下的Girsanov型定理，展示了在新的学习测度下，NBM获取漂移。这种测度的性质（是否悲观或乐观）由学习参数$\\theta$内生地确定，为态度向不确定性是可发现特征的模型提供了严格的理论基础。', 'title_zh': '神经布朗运动'}
{'arxiv_id': 'arXiv:2507.14481', 'title': 'DFQ-ViT: Data-Free Quantization for Vision Transformers without Fine-tuning', 'authors': 'Yujia Tong, Jingling Yuan, Tian Zhang, Jianquan Liu, Chuang Hu', 'link': 'https://arxiv.org/abs/2507.14481', 'abstract': 'Data-Free Quantization (DFQ) enables the quantization of Vision Transformers (ViTs) without requiring access to data, allowing for the deployment of ViTs on devices with limited resources. In DFQ, the quantization model must be calibrated using synthetic samples, making the quality of these synthetic samples crucial. Existing methods fail to fully capture and balance the global and local features within the samples, resulting in limited synthetic data quality. Moreover, we have found that during inference, there is a significant difference in the distributions of intermediate layer activations between the quantized and full-precision models. These issues lead to a severe performance degradation of the quantized model. To address these problems, we propose a pipeline for Data-Free Quantization for Vision Transformers (DFQ-ViT). Specifically, we synthesize samples in order of increasing difficulty, effectively enhancing the quality of synthetic data. During the calibration and inference stage, we introduce the activation correction matrix for the quantized model to align the intermediate layer activations with those of the full-precision model. Extensive experiments demonstrate that DFQ-ViT achieves remarkable superiority over existing DFQ methods and its performance is on par with models quantized through real data. For example, the performance of DeiT-T with 3-bit weights quantization is 4.29% higher than the state-of-the-art. Our method eliminates the need for fine-tuning, which not only reduces computational overhead but also lowers the deployment barriers for edge devices. This characteristic aligns with the principles of Green Learning by improving energy efficiency and facilitating real-world applications in resource-constrained environments.', 'abstract_zh': 'Data-Free Quantization for Vision Transformers (DFQ-ViT)', 'title_zh': 'DFQ-ViT：无需微调的数据驱动视觉变换器量化'}
{'arxiv_id': 'arXiv:2507.14472', 'title': 'Strategyproofness and Monotone Allocation of Auction in Social Networks', 'authors': 'Yuhang Guo, Dong Hao, Bin Li, Mingyu Xiao, Bakh Khoussainov', 'link': 'https://arxiv.org/abs/2507.14472', 'abstract': "Strategyproofness in network auctions requires that bidders not only report their valuations truthfully, but also do their best to invite neighbours from the social network. In contrast to canonical auctions, where the value-monotone allocation in Myerson's Lemma is a cornerstone, a general principle of allocation rules for strategyproof network auctions is still missing. We show that, due to the absence of such a principle, even extensions to multi-unit network auctions with single-unit demand present unexpected difficulties, and all pioneering researches fail to be strategyproof. For the first time in this field, we identify two categories of monotone allocation rules on networks: Invitation-Depressed Monotonicity (ID-MON) and Invitation-Promoted Monotonicity (IP-MON). They encompass all existing allocation rules of network auctions as specific instances. For any given ID-MON or IP-MON allocation rule, we characterize the existence and sufficient conditions for the strategyproof payment rules, and show that among all such payment rules, the revenue-maximizing one exists and is computationally feasible. With these results, the obstacle of combinatorial network auction with single-minded bidders is now resolved.", 'abstract_zh': '网络拍卖中的策略proof性要求竞标者不仅诚实地报告其估值，还要尽最大努力邀请社交网络中的邻居。与经典的拍卖中Myerson引理中的价值单调分配作为基石不同，策略proof的网络拍卖分配规则的一般原则仍然缺失。我们表明，由于缺乏这样的原则，即使是针对单一单位需求的多单位网络拍卖的扩展也带来了意想不到的困难，并且所有先驱研究都无法实现策略proof性。在该领域中，我们首次界定了两种网络上的单调分配规则类别：邀请压抑单调性（ID-MON）和邀请促进单调性（IP-MON）。它们包括所有现有网络拍卖的分配规则作为特殊情况。对于任何给定的ID-MON或IP-MON分配规则，我们刻画了策略proof支付规则的存在性和充分条件，并证明这些支付规则中存在收入最大化且可计算的规则。这些结果解决了单一意图竞标者参与组合网络拍卖的障碍。', 'title_zh': '社交网络中拍卖的策略proof性和单调分配机制'}
{'arxiv_id': 'arXiv:2507.14470', 'title': 'Approximate Revenue Maximization for Diffusion Auctions', 'authors': 'Yifan Huang, Dong Hao, Zhiyi Fan, Yuhang Guo, Bin Li', 'link': 'https://arxiv.org/abs/2507.14470', 'abstract': 'Reserve prices are widely used in practice. The problem of designing revenue-optimal auctions based on reserve price has drawn much attention in the auction design community. Although they have been extensively studied, most developments rely on the significant assumption that the target audience of the sale is directly reachable by the auctioneer, while a large portion of bidders in the economic network unaware of the sale are omitted. This work follows the diffusion auction design, which aims to extend the target audience of optimal auction theory to all entities in economic networks. We investigate the design of simple and provably near-optimal network auctions via reserve price. Using Bayesian approximation analysis, we provide a simple and explicit form of the reserve price function tailored to the most representative network auction. We aim to balance setting a sufficiently high reserve price to induce high revenue in a successful sale, and attracting more buyers from the network to increase the probability of a successful sale. This reserve price function preserves incentive compatibility for network auctions, allowing the seller to extract additional revenue beyond that achieved by the Myerson optimal auction. Specifically, if the seller has $\\rho$ direct neighbours in a network of size $n$, this reserve price guarantees a $1-{1 \\over \\rho}$ approximation to the theoretical upper bound, i.e., the maximum possible revenue from any network of size $n$. This result holds for any size and any structure of the networked market.', 'abstract_zh': '基于保留价格的最优拍卖设计在经济网络中扩展', 'title_zh': '近似收益最大化在扩散拍卖中的应用'}
{'arxiv_id': 'arXiv:2507.14444', 'title': 'Statistical and Algorithmic Foundations of Reinforcement Learning', 'authors': 'Yuejie Chi, Yuxin Chen, Yuting Wei', 'link': 'https://arxiv.org/abs/2507.14444', 'abstract': 'As a paradigm for sequential decision making in unknown environments, reinforcement learning (RL) has received a flurry of attention in recent years. However, the explosion of model complexity in emerging applications and the presence of nonconvexity exacerbate the challenge of achieving efficient RL in sample-starved situations, where data collection is expensive, time-consuming, or even high-stakes (e.g., in clinical trials, autonomous systems, and online advertising). How to understand and enhance the sample and computational efficacies of RL algorithms is thus of great interest. In this tutorial, we aim to introduce several important algorithmic and theoretical developments in RL, highlighting the connections between new ideas and classical topics. Employing Markov Decision Processes as the central mathematical model, we cover several distinctive RL scenarios (i.e., RL with a simulator, online RL, offline RL, robust RL, and RL with human feedback), and present several mainstream RL approaches (i.e., model-based approach, value-based approach, and policy optimization). Our discussions gravitate around the issues of sample complexity, computational efficiency, as well as algorithm-dependent and information-theoretic lower bounds from a non-asymptotic viewpoint.', 'abstract_zh': '作为未知环境中的序贯决策范式，强化学习（RL）近年来引起了广泛关注。然而，新兴应用中的模型复杂性的爆炸增长以及非凸性问题加剧了在数据收集昂贵、耗费时间或甚至高风险（例如，在临床试验、自主系统和在线广告中）情况下的高效强化学习挑战。如何理解并提升强化学习算法的样本效率和计算效率是当前的研究热点。在本文献教程中，我们旨在介绍强化学习中若干重要的算法和理论发展，强调新思想与经典主题之间的联系。基于马尔可夫决策过程作为核心数学模型，我们涵盖了若干独特的RL场景（即，带有模拟器的RL、在线RL、离线RL、鲁棒RL以及带有人类反馈的RL），并介绍了几种主流的RL方法（即，基于模型的方法、基于值的方法以及策略优化）。我们的讨论主要围绕样本复杂性、计算效率以及非渐近视角下的算法依赖和信息论下界等问题展开。', 'title_zh': '强化学习的统计与算法基础'}
{'arxiv_id': 'arXiv:2507.14419', 'title': "It's Not That Simple. An Analysis of Simple Test-Time Scaling", 'authors': 'Guojun Wu', 'link': 'https://arxiv.org/abs/2507.14419', 'abstract': 'Prior work proposed simple test-time scaling, a method for replicating this scaling behavior with models distilled from o1-like models by manually controlling test-time compute: either scaling down by enforcing a maximum length or scaling up by iteratively appending "Wait" when the model is about to terminate its generation. This paper presents an analysis of simple test-time scaling and finds that the scaling behavior is largely attributed to scaling down by enforcing a maximum length. In contrast, fine-tuning on long CoT data distilled from o1-like models has no significant impact on scaling behavior, and scaling up by appending "Wait" leads to inconsistencies, as the model may oscillate between solutions. A key distinction exists between scaling down by enforcing a maximum length and scaling up test-time compute in o1-like models, such as DeepSeek-R1\\@. These models are typically allowed to utilize as much compute as needed, with the only constraint being the model\'s maximum supported length. By learning to naturally scale up test-time compute during reinforcement learning, o1-like models surpass their peak performance when scaling up. In contrast, simple test-time scaling progressively imposes a lower upper limit on model performance as it scales down. While replicating the test-time scaling behavior of o1 models can be straightforward by scaling down, it is crucial to recognize that the goal of scaling test-time compute is to unlock higher performance -- beyond what the model could originally achieve -- rather than merely reproducing the appearance of scaling behavior.', 'abstract_zh': '简单测试时缩放的分析及其在o1-like模型中的应用', 'title_zh': '并非那么简单：简单测试时缩放的分析'}
{'arxiv_id': 'arXiv:2507.14387', 'title': 'Incremental Causal Graph Learning for Online Cyberattack Detection in Cyber-Physical Infrastructures', 'authors': 'Arun Vignesh Malarkkan, Dongjie Wang, Haoyue Bai, Yanjie Fu', 'link': 'https://arxiv.org/abs/2507.14387', 'abstract': 'The escalating threat of cyberattacks on real-time critical infrastructures poses serious risks to public safety, demanding detection methods that effectively capture complex system interdependencies and adapt to evolving attack patterns. Traditional real-time anomaly detection techniques often suffer from excessive false positives due to their statistical sensitivity to high data variance and class imbalance. To address these limitations, recent research has explored modeling causal relationships among system components. However, prior work mainly focuses on offline causal graph-based approaches that require static historical data and fail to generalize to real-time settings. These methods are fundamentally constrained by: (1) their inability to adapt to dynamic shifts in data distribution without retraining, and (2) the risk of catastrophic forgetting when lacking timely supervision in live systems. To overcome these challenges, we propose INCADET, a novel framework for incremental causal graph learning tailored to real-time cyberattack detection. INCADET dynamically captures evolving system behavior by incrementally updating causal graphs across streaming time windows. The framework comprises three modules: 1) Early Symptom Detection: Detects transitions in system status using divergence in edge-weight distributions across sequential causal graphs. 2) Incremental Causal Graph Learning: Leverages experience replay and edge reinforcement to continually refine causal structures while preserving prior knowledge. 3) Causal Graph Classification: Employs Graph Convolutional Networks (GCNs) to classify system status using the learned causal graphs. Extensive experiments on real-world critical infrastructure datasets demonstrate that INCADET achieves superior accuracy, robustness, and adaptability compared to both static causal and deep temporal baselines in evolving attack scenarios.', 'abstract_zh': '实时关键基础设施中不断升级的网络攻击威胁对公共安全构成严重风险，要求有效的检测方法能够捕捉复杂系统间的相互依赖关系并适应不断演变的攻击模式。传统实时异常检测技术往往因统计上对高数据变异性及类别不平衡的敏感性而产生过多的误报。为解决这些问题，近期研究探索了系统组件间因果关系的建模方法。然而，先前的工作主要集中在需要静态历史数据的离线因果图方法上，这些方法无法适应实时场景中的推广性。这些方法本质上受限于：（1）无法在无需重新训练的情况下适应数据分布的变化，（2）在缺乏及时监督的实时系统中存在灾难性遗忘的风险。为克服这些挑战，我们提出INCADET，一种针对实时网络攻击检测的增量因果图学习新型框架。INCADET通过在流式时间窗口中增量更新因果图来动态捕捉系统行为的变化。该框架包含三个模块：1）早期症状检测：通过顺序因果图中边权重分布的差异检测系统状态的转换。2）增量因果图学习：利用经验重演和边强化不断细化因果结构，同时保留先前知识。3）因果图分类：采用图卷积网络（GCNs）使用学习到的因果图来分类系统状态。在实际关键基础设施数据集上的广泛实验表明，INCADET在不断演变的攻击场景中较静态因果和深度时序基线方法在准确度、稳健性和适应性方面具有明显优势。', 'title_zh': '在线物理信息系统中增量因果图学习的网络攻击检测方法'}
{'arxiv_id': 'arXiv:2507.14372', 'title': 'Text-to-SQL for Enterprise Data Analytics', 'authors': 'Albert Chen, Manas Bundele, Gaurav Ahlawat, Patrick Stetz, Zhitao Wang, Qiang Fei, Donghoon Jung, Audrey Chu, Bharadwaj Jayaraman, Ayushi Panth, Yatin Arora, Sourav Jain, Renjith Varma, Alexey Ilin, Iuliia Melnychuk, Chelsea Chueh, Joyan Sil, Xiaofeng Wang', 'link': 'https://arxiv.org/abs/2507.14372', 'abstract': "The introduction of large language models has brought rapid progress on Text-to-SQL benchmarks, but it is not yet easy to build a working enterprise solution. In this paper, we present insights from building an internal chatbot that enables LinkedIn's product managers, engineers, and operations teams to self-serve data insights from a large, dynamic data lake. Our approach features three components. First, we construct a knowledge graph that captures up-to-date semantics by indexing database metadata, historical query logs, wikis, and code. We apply clustering to identify relevant tables for each team or product area. Second, we build a Text-to-SQL agent that retrieves and ranks context from the knowledge graph, writes a query, and automatically corrects hallucinations and syntax errors. Third, we build an interactive chatbot that supports various user intents, from data discovery to query writing to debugging, and displays responses in rich UI elements to encourage follow-up chats. Our chatbot has over 300 weekly users. Expert review shows that 53% of its responses are correct or close to correct on an internal benchmark set. Through ablation studies, we identify the most important knowledge graph and modeling components, offering a practical path for developing enterprise Text-to-SQL solutions.", 'abstract_zh': '大型语言模型的引入已经在Text-to-SQL基准测试中带来了快速的进步，但构建一个可行的企业级解决方案仍然不是一件容易的事。本文介绍了构建LinkedIn内部聊天机器人的见解，该聊天机器人使产品管理团队、工程师和运营团队能够从大型动态数据湖中自助获取数据洞见。我们的方法包括三个组成部分。首先，我们构建了一个知识图谱，通过索引数据库元数据、历史查询日志、维基和代码来捕获最新的语义，并使用聚类来识别每个团队或产品领域的相关表格。其次，我们构建了一个Text-to-SQL代理，能够从知识图谱中检索和排名上下文、生成查询，并自动纠正幻觉和语法错误。第三，我们构建了一个支持各种用户意图的交互式聊天机器人，从数据发现到查询编写再到调试，并通过丰富的UI元素显示响应以促进后续对话。我们的聊天机器每周有超过300名用户。专家评审显示，其53%的响应在内部基准数据集中是正确的或接近正确的。通过消融研究，我们确定了最重要的知识图谱和建模组件，为开发企业级Text-to-SQL解决方案提供了实际路径。', 'title_zh': '企业数据查询的文本到SQL转换'}
{'arxiv_id': 'arXiv:2507.14352', 'title': 'A Reproducibility Study of Product-side Fairness in Bundle Recommendation', 'authors': 'Huy-Son Nguyen, Yuanna Liu, Masoud Mansoury, Mohammad Alian Nejadi, Alan Hanjalic, Maarten de Rijke', 'link': 'https://arxiv.org/abs/2507.14352', 'abstract': 'Recommender systems are known to exhibit fairness issues, particularly on the product side, where products and their associated suppliers receive unequal exposure in recommended results. While this problem has been widely studied in traditional recommendation settings, its implications for bundle recommendation (BR) remain largely unexplored. This emerging task introduces additional complexity: recommendations are generated at the bundle level, yet user satisfaction and product (or supplier) exposure depend on both the bundle and the individual items it contains. Existing fairness frameworks and metrics designed for traditional recommender systems may not directly translate to this multi-layered setting. In this paper, we conduct a comprehensive reproducibility study of product-side fairness in BR across three real-world datasets using four state-of-the-art BR methods. We analyze exposure disparities at both the bundle and item levels using multiple fairness metrics, uncovering important patterns. Our results show that exposure patterns differ notably between bundles and items, revealing the need for fairness interventions that go beyond bundle-level assumptions. We also find that fairness assessments vary considerably depending on the metric used, reinforcing the need for multi-faceted evaluation. Furthermore, user behavior plays a critical role: when users interact more frequently with bundles than with individual items, BR systems tend to yield fairer exposure distributions across both levels. Overall, our findings offer actionable insights for building fairer bundle recommender systems and establish a vital foundation for future research in this emerging domain.', 'abstract_zh': '推荐系统在捆绑推荐中表现出公平性问题：产品及其供应商在推荐结果中的曝光不平等现象在传统推荐设置中得到了广泛研究，但在捆绑推荐（BR）中的影响仍 largely unexplored。这一新兴任务引入了额外的复杂性：推荐是在捆绑级别生成的，但用户满意度和产品（或供应商）曝光既取决于捆绑，也取决于捆绑中包含的单个物品。现有的为传统推荐系统设计的公平性框架和指标可能不直接适用于这种多层设置。在本文中，我们使用四种最新的捆绑推荐方法，在三个真实数据集上进行了一项全面的可重复性研究，分析了捆绑和物品级别上的曝光差异，揭示了重要模式。结果显示，捆绑和物品之间的曝光模式存在显著差异，表明需要超越捆绑级别假设的公平性干预措施。我们还发现，根据使用的指标不同，公平性评估有很大差异，这强调了多维度评估的重要性。此外，用户行为起着关键作用：当用户更频繁地与捆绑而非单个物品交互时，BR系统倾向于在两个级别上产生更公平的曝光分布。总体而言，我们的研究结果为构建更公平的捆绑推荐系统提供了可操作的见解，并为这一新兴领域的未来研究奠定了基础。', 'title_zh': '产品层面推荐中产品公平性再现研究'}
{'arxiv_id': 'arXiv:2507.14344', 'title': 'Influence Functions for Preference Dataset Pruning', 'authors': 'Daniel Fein, Gabriela Aranguiz-Dias', 'link': 'https://arxiv.org/abs/2507.14344', 'abstract': 'Language models are commonly fine-tuned via reinforcement learning to alter their behavior or elicit new capabilities. Datasets used for these purposes, and particularly human preference datasets, are often noisy. The relatively small size post-training datasets, combined with parameter-efficient fine-tuning methods, enable the use of influence functions approximations to detect and prune training examples that are harmful to performance on a validation set. In this work, we adapt the TL;DR dataset for reward model training to demonstrate how conjugate-gradient approximated influence functions can be used to filter datasets. In our experiments, influence function filtering yields a small retraining accuracy uplift of 1.5% after removing 10% of training examples. We also show that gradient similarity outperforms influence functions for detecting helpful training examples. This suggests that local curvature is important for detecting harmful training examples, but less so for identifying helpful examples.', 'abstract_zh': '语言模型通常通过强化学习进行微调以改变其行为或激发新能力。用于这些目的的数据集，尤其是人类偏好数据集，往往是嘈杂的。经过微调后相对较小的数据集大小与参数高效微调方法相结合，使得可以通过影响函数近似检测和去除对验证集性能有害的训练示例。在本文中，我们改编TL;DR数据集以供奖励模型训练使用，展示如何使用共轭梯度近似影响函数来筛选数据集。在我们的实验中，在去除10%的训练示例后，影响函数筛选带来了约1.5%的重新培训准确率提升。我们还展示了梯度相似度在检测有益训练示例方面优于影响函数。这表明局部曲率对于检测有害训练示例很重要，但对于识别有益示例则不那么重要。', 'title_zh': '偏好数据集裁剪的影响函数'}
{'arxiv_id': 'arXiv:2507.14299', 'title': 'Age of Information Minimization in UAV-Enabled Integrated Sensing and Communication Systems', 'authors': 'Yu Bai, Yifan Zhang, Boxuan Xie, Zheng Chang, Yanru Zhang, Riku Jantti, Zhu Han', 'link': 'https://arxiv.org/abs/2507.14299', 'abstract': "Unmanned aerial vehicles (UAVs) equipped with integrated sensing and communication (ISAC) capabilities are envisioned to play a pivotal role in future wireless networks due to their enhanced flexibility and efficiency. However, jointly optimizing UAV trajectory planning, multi-user communication, and target sensing under stringent resource constraints and time-critical conditions remains a significant challenge. To address this, we propose an Age of Information (AoI)-centric UAV-ISAC system that simultaneously performs target sensing and serves multiple ground users, emphasizing information freshness as the core performance metric. We formulate a long-term average AoI minimization problem that jointly optimizes the UAV's flight trajectory and beamforming. To tackle the high-dimensional, non-convexity of this problem, we develop a deep reinforcement learning (DRL)-based algorithm capable of providing real-time decisions on UAV movement and beamforming for both radar sensing and multi-user communication. Specifically, a Kalman filter is employed for accurate target state prediction, regularized zero-forcing is utilized to mitigate inter-user interference, and the Soft Actor-Critic algorithm is applied for training the DRL agent on continuous actions. The proposed framework adaptively balances the trade-offs between sensing accuracy and communication quality. Extensive simulation results demonstrate that our proposed method consistently achieves lower average AoI compared to baseline approaches.", 'abstract_zh': '具有集成传感与通信能力的无人驾驶飞行器（UAV-ISAC）在未来无线网络中的角色及其实时性中心优化方法', 'title_zh': '基于无人机使能的集成感知与通信系统的年龄信息最小化'}
{'arxiv_id': 'arXiv:2507.14271', 'title': 'MiDeSeC: A Dataset for Mitosis Detection and Segmentation in Breast Cancer Histopathology Images', 'authors': 'Refik Samet, Nooshin Nemati, Emrah Hancer, Serpil Sak, Bilge Ayca Kirmizi, Zeynep Yildirim', 'link': 'https://arxiv.org/abs/2507.14271', 'abstract': 'The MiDeSeC dataset is created through H&E stained invasive breast carcinoma, no special type (NST) slides of 25 different patients captured at 40x magnification from the Department of Medical Pathology at Ankara University. The slides have been scanned by 3D Histech Panoramic p250 Flash-3 scanner and Olympus BX50 microscope. As several possible mitosis shapes exist, it is crucial to have a large dataset to cover all the cases. Accordingly, a total of 50 regions is selected from glass slides for 25 patients, each of regions with a size of 1024*1024 pixels. There are more than 500 mitoses in total in these 50 regions. Two-thirds of the regions are reserved for training, the other third for testing.', 'abstract_zh': 'MiDeSeC数据集通过 Ankara University 医学病理学系提供的40倍放大倍率的H&E染色侵袭性乳腺癌（无特殊类型）组织切片创建，来自25位患者的切片由3D Histech Panoramic p250 Flash-3扫描仪和Olympus BX50显微镜扫描。由于可能存在的多种有丝分裂形态，该数据集包含50个区域，每个区域1024*1024像素，共计超过500个有丝分裂。其中三分之二的区域用于训练，三分之一用于测试。', 'title_zh': 'MiDeSeC: 乳腺癌组织学图像中分裂检测与分割的数据集'}
{'arxiv_id': 'arXiv:2507.14270', 'title': 'APTx Neuron: A Unified Trainable Neuron Architecture Integrating Activation and Computation', 'authors': 'Ravin Kumar', 'link': 'https://arxiv.org/abs/2507.14270', 'abstract': 'We propose the APTx Neuron, a novel, unified neural computation unit that integrates non-linear activation and linear transformation into a single trainable expression. The APTx Neuron is derived from the APTx activation function, thereby eliminating the need for separate activation layers and making the architecture both computationally efficient and elegant. The proposed neuron follows the functional form $y = \\sum_{i=1}^{n} ((\\alpha_i + \\tanh(\\beta_i x_i)) \\cdot \\gamma_i x_i) + \\delta$, where all parameters $\\alpha_i$, $\\beta_i$, $\\gamma_i$, and $\\delta$ are trainable. We validate our APTx Neuron-based architecture on the MNIST dataset, achieving up to 96.69\\% test accuracy in just 20 epochs using approximately 332K trainable parameters. The results highlight the superior expressiveness and computational efficiency of the APTx Neuron compared to traditional neurons, pointing toward a new paradigm in unified neuron design and the architectures built upon it.', 'abstract_zh': '我们提出APTx神经元，这是一种新颖的统一神经计算单元，将非线性激活和线性变换融合为单一的可训练表达式。APTx神经元源自APTx激活函数，从而消除了单独激活层的需要，使架构既计算高效又简洁。所提出的神经元遵循函数形式$y = \\sum_{i=1}^{n} ((\\alpha_i + \\tanh(\\beta_i x_i)) \\cdot \\gamma_i x_i) + \\delta$，其中所有参数$\\alpha_i$、$\\beta_i$、$\\gamma_i$和$\\delta$均为可训练参数。我们基于APTx神经元的架构在MNIST数据集上进行了验证，仅在20个epochs内使用约33.2万可训练参数即可实现高达96.69%的测试准确率。结果突显了APTx神经元相比传统神经元的优越的表达能力和计算效率，并指向统一神经元设计及其架构的新范式。', 'title_zh': 'APTx神经元：一种集成了激活与计算的统一可训练神经元架构'}
{'arxiv_id': 'arXiv:2507.14266', 'title': 'Bridging MOOCs, Smart Teaching, and AI: A Decade of Evolution Toward a Unified Pedagogy', 'authors': 'Bo Yuan, Jiazi Hu', 'link': 'https://arxiv.org/abs/2507.14266', 'abstract': "Over the past decade, higher education has evolved through three distinct paradigms: the emergence of Massive Open Online Courses (MOOCs), the integration of Smart Teaching technologies into classrooms, and the rise of AI-enhanced learning. Each paradigm is intended to address specific challenges in traditional education: MOOCs enable ubiquitous access to learning resources; Smart Teaching supports real-time interaction with data-driven insights; and generative AI offers personalized feedback and on-demand content generation. However, these paradigms are often implemented in isolation due to their disparate technological origins and policy-driven adoption. This paper examines the origins, strengths, and limitations of each paradigm, and advocates a unified pedagogical perspective that synthesizes their complementary affordances. We propose a three-layer instructional framework that combines the scalability of MOOCs, the responsiveness of Smart Teaching, and the adaptivity of AI. To demonstrate its feasibility, we present a curriculum design for a project-based course. The findings highlight the framework's potential to enhance learner engagement, support instructors, and enable personalized yet scalable learning.", 'abstract_zh': '过去十年中，高等教育经历了三种不同的范式演变：大规模开放在线课程（MOOCs）的涌现、智能教学技术在课堂中的整合以及增强学习的兴起。每个范式都旨在解决传统教育中的特定挑战：MOOCs使学习资源的获取无处不在；智能教学支持实时的数据驱动交互；生成式AI提供个性化反馈和按需内容生成。然而，由于它们各自的技术起源和政策驱动的采纳方式不同，这些范式通常被孤立实施。本文探讨了每个范式的起源、优势和局限性，并倡导一种综合的教学视角，以综合它们互补的功能。我们提出了一种三层教学框架，结合了MOOCs的可扩展性、Smart Teaching的响应性以及AI的适应性。为了证明其实现可行性，我们为一个基于项目的设计了一门课程的教学大纲。研究发现突显了该框架在增强学习者参与度、支持教师以及实现个性化和可扩展学习方面的潜力。', 'title_zh': 'MOOCs、智能教学与AI：十年一体化教学理念的发展'}
{'arxiv_id': 'arXiv:2507.14263', 'title': 'Beyond DNS: Unlocking the Internet of AI Agents via the NANDA Index and Verified AgentFacts', 'authors': 'Ramesh Raskar, Pradyumna Chari, John Zinky, Mahesh Lambe, Jared James Grogan, Sichao Wang, Rajesh Ranjan, Rekha Singhal, Shailja Gupta, Robert Lincourt, Raghu Bala, Aditi Joshi, Abhishek Singh, Ayush Chopra, Dimitris Stripelis, Bhuwan B, Sumit Kumar, Maria Gorskikh', 'link': 'https://arxiv.org/abs/2507.14263', 'abstract': 'The Internet is poised to host billions to trillions of autonomous AI agents that negotiate, delegate, and migrate in milliseconds and workloads that will strain DNS-centred identity and discovery. In this paper, we describe the NANDA index architecture, which we envision as a means for discoverability, identifiability and authentication in the internet of AI agents. We present an architecture where a minimal lean index resolves to dynamic, cryptographically verifiable AgentFacts that supports multi-endpoint routing, load balancing, privacy-preserving access, and credentialed capability assertions. Our architecture design delivers five concrete guarantees: (1) A quilt-like index proposal that supports both NANDA-native agents as well as third party agents being discoverable via the index, (2) rapid global resolution for newly spawned AI agents, (3) sub-second revocation and key rotation, (4) schema-validated capability assertions, and (5) privacy-preserving discovery across organisational boundaries via verifiable, least-disclosure queries. We formalize the AgentFacts schema, specify a CRDT-based update protocol, and prototype adaptive resolvers. The result is a lightweight, horizontally scalable foundation that unlocks secure, trust-aware collaboration for the next generation of the Internet of AI agents, without abandoning existing web infrastructure.', 'abstract_zh': '互联网即将承载 billions 到 trillions 个自主AI代理进行毫秒级的协商、委托和迁移，工作负载将给以DNS为中心的身份验证和发现带来压力。本文描述了NANDA索引架构，我们设想它是一种在AI代理互联网中实现可发现性、可标识性和认证的手段。我们提出了一种架构，其中最小轻量级索引解析为动态、加密可验证的AgentFacts，支持多端点路由、负载均衡、隐私保护访问和凭据认证声明。该架构设计提供了五个具体保证：(1) 表格-like 索引提案，支持NANDA原生代理及第三方代理通过索引进行发现；(2) 新生成的AI代理的快速全球解析；(3) 子秒级撤销和密钥轮换；(4) 验证后的内容声明；(5) 跨组织边界进行隐私保护发现，通过可验证、最小披露查询实现。我们形式化了AgentFacts架构，指定了CRDT基础的更新协议，并原型实现了自适应解析器。结果是一个轻量级、水平扩展的基础架构，为下一代AI代理互联网解锁了安全、信任感知的合作，而不放弃现有Web架构。', 'title_zh': '超越DNS：通过NANDA索引和验证代理事实解锁人工智能代理的互联网'}
{'arxiv_id': 'arXiv:2507.14261', 'title': 'FAMST: Fast Approximate Minimum Spanning Tree Construction for Large-Scale and High-Dimensional Data', 'authors': 'Mahmood K. M. Almansoori, Miklos Telek', 'link': 'https://arxiv.org/abs/2507.14261', 'abstract': 'We present Fast Approximate Minimum Spanning Tree (FAMST), a novel algorithm that addresses the computational challenges of constructing Minimum Spanning Trees (MSTs) for large-scale and high-dimensional datasets. FAMST utilizes a three-phase approach: Approximate Nearest Neighbor (ANN) graph construction, ANN inter-component connection, and iterative edge refinement. For a dataset of $n$ points in a $d$-dimensional space, FAMST achieves $\\mathcal{O}(dn \\log n)$ time complexity and $\\mathcal{O}(dn + kn)$ space complexity when $k$ nearest neighbors are considered, which is a significant improvement over the $\\mathcal{O}(n^2)$ time and space complexity of traditional methods.\nExperiments across diverse datasets demonstrate that FAMST achieves remarkably low approximation errors while providing speedups of up to 1000$\\times$ compared to exact MST algorithms. We analyze how the key hyperparameters, $k$ (neighborhood size) and $\\lambda$ (inter-component edges), affect performance, providing practical guidelines for hyperparameter selection. FAMST enables MST-based analysis on datasets with millions of points and thousands of dimensions, extending the applicability of MST techniques to problem scales previously considered infeasible.', 'abstract_zh': 'Fast Approximate Minimum Spanning Tree for Large-Scale and High-Dimensional Datasets', 'title_zh': 'FAMST：大型高维数据快速近似最小生成树构建方法'}
{'arxiv_id': 'arXiv:2507.14248', 'title': 'Breaking the Illusion of Security via Interpretation: Interpretable Vision Transformer Systems under Attack', 'authors': 'Eldor Abdukhamidov, Mohammed Abuhamad, Simon S. Woo, Hyoungshick Kim, Tamer Abuhmed', 'link': 'https://arxiv.org/abs/2507.14248', 'abstract': 'Vision transformer (ViT) models, when coupled with interpretation models, are regarded as secure and challenging to deceive, making them well-suited for security-critical domains such as medical applications, autonomous vehicles, drones, and robotics. However, successful attacks on these systems can lead to severe consequences. Recent research on threats targeting ViT models primarily focuses on generating the smallest adversarial perturbations that can deceive the models with high confidence, without considering their impact on model interpretations. Nevertheless, the use of interpretation models can effectively assist in detecting adversarial examples. This study investigates the vulnerability of transformer models to adversarial attacks, even when combined with interpretation models. We propose an attack called "AdViT" that generates adversarial examples capable of misleading both a given transformer model and its coupled interpretation model. Through extensive experiments on various transformer models and two transformer-based interpreters, we demonstrate that AdViT achieves a 100% attack success rate in both white-box and black-box scenarios. In white-box scenarios, it reaches up to 98% misclassification confidence, while in black-box scenarios, it reaches up to 76% misclassification confidence. Remarkably, AdViT consistently generates accurate interpretations in both scenarios, making the adversarial examples more difficult to detect.', 'abstract_zh': 'Vision Transformer模型结合解释模型后的对抗攻击脆弱性研究：AdViT攻击的有效性', 'title_zh': '通过解释破解安全幻象：攻击下的可解释视觉变换系统'}
{'arxiv_id': 'arXiv:2507.14245', 'title': 'A million-scale dataset and generalizable foundation model for nanomaterial-protein interactions', 'authors': 'Hengjie Yu, Kenneth A. Dawson, Haiyun Yang, Shuya Liu, Yan Yan, Yaochu Jin', 'link': 'https://arxiv.org/abs/2507.14245', 'abstract': 'Unlocking the potential of nanomaterials in medicine and environmental science hinges on understanding their interactions with proteins, a complex decision space where AI is poised to make a transformative impact. However, progress has been hindered by limited datasets and the restricted generalizability of existing models. Here, we propose NanoPro-3M, the largest nanomaterial-protein interaction dataset to date, comprising over 3.2 million samples and 37,000 unique proteins. Leveraging this, we present NanoProFormer, a foundational model that predicts nanomaterial-protein affinities through multimodal representation learning, demonstrating strong generalization, handling missing features, and unseen nanomaterials or proteins. We show that multimodal modeling significantly outperforms single-modality approaches and identifies key determinants of corona formation. Furthermore, we demonstrate its applicability to a range of downstream tasks through zero-shot inference and fine-tuning. Together, this work establishes a solid foundation for high-performance and generalized prediction of nanomaterial-protein interaction endpoints, reducing experimental reliance and accelerating various in vitro applications.', 'abstract_zh': '纳米材料在医学和环境科学中的潜力unlocking the potential of nanomaterials in medicine and environmental science hinges on understanding their interactions with proteins, a complex decision space where AI is poised to make a transformative impact.然而限于现有数据集的限制和现有模型通用性的不足，进展受到了阻碍。在此，我们提出NanoPro-3M，迄今为止最大的纳米材料-蛋白质相互作用数据集，包含超过320万个样本和37000种独特的蛋白质。利用这一数据集，我们提出NanoProFormer，一种基础模型，通过多模态表示学习预测纳米材料-蛋白质亲和力，展示了强健的泛化能力、处理缺失特征以及未知纳米材料或蛋白质的能力。我们表明，多模态建模显著优于单模态方法，并识别出冠层形成的关键决定因素。此外，我们通过零样本推理和微调展示了其在一系列下游任务上的应用潜力。本项工作为高性能和泛化的纳米材料-蛋白质相互作用终点预测奠定了坚实的基础，减少了实验依赖并加速了各种体外应用。', 'title_zh': '百万尺度数据集及可泛化的纳米材料-蛋白相互作用基础模型'}
{'arxiv_id': 'arXiv:2507.14242', 'title': 'Culling Misinformation from Gen AI: Toward Ethical Curation and Refinement', 'authors': 'Prerana Khatiwada, Grace Donaher, Jasymyn Navarro, Lokesh Bhatta', 'link': 'https://arxiv.org/abs/2507.14242', 'abstract': 'While Artificial Intelligence (AI) is not a new field, recent developments, especially with the release of generative tools like ChatGPT, have brought it to the forefront of the minds of industry workers and academic folk alike. There is currently much talk about AI and its ability to reshape many everyday processes as we know them through automation. It also allows users to expand their ideas by suggesting things they may not have thought of on their own and provides easier access to information. However, not all of the changes this technology will bring or has brought so far are positive; this is why it is extremely important for all modern people to recognize and understand the risks before using these tools and allowing them to cause harm. This work takes a position on better understanding many equity concerns and the spread of misinformation that result from new AI, in this case, specifically ChatGPT and deepfakes, and encouraging collaboration with law enforcement, developers, and users to reduce harm. Considering many academic sources, it warns against these issues, analyzing their cause and impact in fields including healthcare, education, science, academia, retail, and finance. Lastly, we propose a set of future-facing guidelines and policy considerations to solve these issues while still enabling innovation in these fields, this responsibility falling upon users, developers, and government entities.', 'abstract_zh': '人工智能中的公平关切与信息误导传播：促进执法、开发者和用户合作以减轻危害并推动创新', 'title_zh': '从生成式AI中剔除虚假信息：迈向伦理化的编纂与优化'}
{'arxiv_id': 'arXiv:2507.14237', 'title': 'U-DREAM: Unsupervised Dereverberation guided by a Reverberation Model', 'authors': 'Louis Bahrman, Mathieu Fontaine, Gaël Richard', 'link': 'https://arxiv.org/abs/2507.14237', 'abstract': 'This paper explores the outcome of training state-ofthe-art dereverberation models with supervision settings ranging from weakly-supervised to fully unsupervised, relying solely on reverberant signals and an acoustic model for training. Most of the existing deep learning approaches typically require paired dry and reverberant data, which are difficult to obtain in practice. We develop instead a sequential learning strategy motivated by a bayesian formulation of the dereverberation problem, wherein acoustic parameters and dry signals are estimated from reverberant inputs using deep neural networks, guided by a reverberation matching loss. Our most data-efficient variant requires only 100 reverberation-parameter-labelled samples to outperform an unsupervised baseline, demonstrating the effectiveness and practicality of the proposed method in low-resource scenarios.', 'abstract_zh': '基于从弱监督到无监督训练设置的研究：利用回波信号训练最先进的去混响模型', 'title_zh': 'U-DREAM：基于混响模型的无监督去混响方法'}
{'arxiv_id': 'arXiv:2507.14231', 'title': 'Beyond Architectures: Evaluating the Role of Contextual Embeddings in Detecting Bipolar Disorder on Social Media', 'authors': 'Khalid Hasan, Jamil Saquer', 'link': 'https://arxiv.org/abs/2507.14231', 'abstract': 'Bipolar disorder is a chronic mental illness frequently underdiagnosed due to subtle early symptoms and social stigma. This paper explores the advanced natural language processing (NLP) models for recognizing signs of bipolar disorder based on user-generated social media text. We conduct a comprehensive evaluation of transformer-based models (BERT, RoBERTa, ALBERT, ELECTRA, DistilBERT) and Long Short Term Memory (LSTM) models based on contextualized (BERT) and static (GloVe, Word2Vec) word embeddings. Experiments were performed on a large, annotated dataset of Reddit posts after confirming their validity through sentiment variance and judgmental analysis. Our results demonstrate that RoBERTa achieves the highest performance among transformer models with an F1 score of ~98% while LSTM models using BERT embeddings yield nearly identical results. In contrast, LSTMs trained on static embeddings fail to capture meaningful patterns, scoring near-zero F1. These findings underscore the critical role of contextual language modeling in detecting bipolar disorder. In addition, we report model training times and highlight that DistilBERT offers an optimal balance between efficiency and accuracy. In general, our study offers actionable insights for model selection in mental health NLP applications and validates the potential of contextualized language models to support early bipolar disorder screening.', 'abstract_zh': '双相障碍是一种常因早期症状微妙和社会污名而被低估的慢性精神疾病。本文探讨了基于用户生成的社交媒体文本识别双相障碍征兆的高级自然语言处理（NLP）模型。我们对基于上下文（BERT）和静态（GloVe, Word2Vec）词向量的变换器模型（BERT, RoBERTa, ALBERT, ELECTRA, DistilBERT）和长短期记忆（LSTM）模型进行了全面评估。实验在经过情感变异和判断性分析确认有效性的大型标注的Reddit帖子数据集上进行。结果表明，RoBERTa 在变换器模型中表现最佳，F1 分数约为 98%，而使用 BERT 向量的 LSTM 模型取得了几乎相同的结果。相比之下，基于静态向量训练的 LSTM 无法捕捉到有意义的模式，F1 分数接近零。这些发现强调了上下文语言建模在检测双相障碍方面的关键作用。此外，我们报告了模型的训练时间，并指出 DistilBERT 在效率和准确性之间提供了最优平衡。总体而言，我们的研究为精神健康 NLP 应用中的模型选择提供了可操作的见解，并证实了上下文化语言模型支持早期双相障碍筛查的潜力。', 'title_zh': '超越架构：评估上下文嵌入在社交媒体上检测双相障碍中的作用'}
{'arxiv_id': 'arXiv:2507.14227', 'title': 'Domain Generalization via Pareto Optimal Gradient Matching', 'authors': 'Khoi Do, Duong Nguyen, Nam-Khanh Le, Quoc-Viet Pham, Binh-Son Hua, Won-Joo Hwang', 'link': 'https://arxiv.org/abs/2507.14227', 'abstract': 'In this study, we address the gradient-based domain generalization problem, where predictors aim for consistent gradient directions across different domains. Existing methods have two main challenges. First, minimization of gradient empirical distance or gradient inner products (GIP) leads to gradient fluctuations among domains, thereby hindering straightforward learning. Second, the direct application of gradient learning to the joint loss function can incur high computation overheads due to second-order derivative approximation. To tackle these challenges, we propose a new Pareto Optimality Gradient Matching (POGM) method. In contrast to existing methods that add gradient matching as regularization, we leverage gradient trajectories as collected data and apply independent training at the meta-learner. In the meta-update, we maximize GIP while limiting the learned gradient from deviating too far from the empirical risk minimization gradient trajectory. By doing so, the aggregate gradient can incorporate knowledge from all domains without suffering gradient fluctuation towards any particular domain. Experimental evaluations on datasets from DomainBed demonstrate competitive results yielded by POGM against other baselines while achieving computational efficiency.', 'abstract_zh': '本研究针对基于梯度的领域泛化问题，其中预测器旨在不同领域之间保持一致的梯度方向。现有方法存在两个主要挑战。首先，梯度经验距离最小化或梯度内积（GIP）的最小化会导致领域之间的梯度波动，从而妨碍直接学习。其次，将梯度学习直接应用于联合损失函数会导致由于二阶导数近似而产生高额的计算开销。为解决这些问题，我们提出了一种新的帕累托最优梯度匹配（POGM）方法。与现有方法将梯度匹配作为正则化不同，我们利用梯度轨迹作为收集的数据，并在元学习器中进行独立训练。在元更新过程中，最大化GIP同时限制学习到的梯度不要偏离经验风险最小化梯度轨迹太远。通过这种方式，聚合梯度可以在不向任何一个特定领域遭受梯度波动的情况下融合来自所有领域的知识。在DomainBed数据集上的实验评估表明，POGM在计算效率上优于其他基线方法的同时，还能获得竞争力的结果。', 'title_zh': 'Pareto最优梯度匹配的领域泛化方法'}
{'arxiv_id': 'arXiv:2507.14223', 'title': 'Multi-Granular Discretization for Interpretable Generalization in Precise Cyberattack Identification', 'authors': 'Wen-Cheng Chung, Shu-Ting Huang, Hao-Ting Pai', 'link': 'https://arxiv.org/abs/2507.14223', 'abstract': 'Explainable intrusion detection systems (IDS) are now recognized as essential for mission-critical networks, yet most "XAI" pipelines still bolt an approximate explainer onto an opaque classifier, leaving analysts with partial and sometimes misleading insights. The Interpretable Generalization (IG) mechanism, published in IEEE Transactions on Information Forensics and Security, eliminates that bottleneck by learning coherent patterns - feature combinations unique to benign or malicious traffic - and turning them into fully auditable rules. IG already delivers outstanding precision, recall, and AUC on NSL-KDD, UNSW-NB15, and UKM-IDS20, even when trained on only 10% of the data. To raise precision further without sacrificing transparency, we introduce Multi-Granular Discretization (IG-MD), which represents every continuous feature at several Gaussian-based resolutions. On UKM-IDS20, IG-MD lifts precision by greater than or equal to 4 percentage points across all nine train-test splits while preserving recall approximately equal to 1.0, demonstrating that a single interpretation-ready model can scale across domains without bespoke tuning.', 'abstract_zh': '可解释的入侵检测系统（IDS）已被认定为关键任务网络中必不可少的工具，然而大多数“XAI”管道仍是在不透明分类器上附加一个近似的解释器，这使得分析师获得的部分和有时具有误导性的洞察。Interpretable Generalization (IG) 机制通过在《IEEE Transactions on Information Forensics and Security》上发表的研究，通过学习一致模式——仅良性或恶意流量特有的特征组合——并将其转化为可完全审计的规则，消除了这一瓶颈。即使仅使用数据的10%进行训练，IG已在NSL-KDD、UNSW-NB15和UKM-IDS20等数据集上实现了卓越的精确率、召回率和AUC值。为在不牺牲透明度的情况下进一步提高精确率，我们引入了多粒度离散化（IG-MD）方法，该方法以高斯为基础，对每个连续特征表示多个粒度。在UKM-IDS20上，IG-MD在所有九个训练测试拆分中将精确率提高了至少4个百分点，同时保持召回率接近1.0，这表明一个单一的可解释模型可以跨越不同领域进行应用而无需定制调优。', 'title_zh': '多粒度离散化以实现精细网络攻击识别的可解释泛化'}
{'arxiv_id': 'arXiv:2507.14219', 'title': 'Artificial Intelligence for Green Hydrogen Yield Prediction and Site Suitability using SHAP-Based Composite Index: Focus on Oman', 'authors': 'Obumneme Zimuzor Nwafor, Mohammed Abdul Majeed Al Hooti', 'link': 'https://arxiv.org/abs/2507.14219', 'abstract': 'As nations seek sustainable alternatives to fossil fuels, green hydrogen has emerged as a promising strategic pathway toward decarbonisation, particularly in solar-rich arid regions. However, identifying optimal locations for hydrogen production requires the integration of complex environmental, atmospheric, and infrastructural factors, often compounded by limited availability of direct hydrogen yield data. This study presents a novel Artificial Intelligence (AI) framework for computing green hydrogen yield and site suitability index using mean absolute SHAP (SHapley Additive exPlanations) values. This framework consists of a multi-stage pipeline of unsupervised multi-variable clustering, supervised machine learning classifier and SHAP algorithm. The pipeline trains on an integrated meteorological, topographic and temporal dataset and the results revealed distinct spatial patterns of suitability and relative influence of the variables. With model predictive accuracy of 98%, the result also showed that water proximity, elevation and seasonal variation are the most influential factors determining green hydrogen site suitability in Oman with mean absolute shap values of 2.470891, 2.376296 and 1.273216 respectively. Given limited or absence of ground-truth yield data in many countries that have green hydrogen prospects and ambitions, this study offers an objective and reproducible alternative to subjective expert weightings, thus allowing the data to speak for itself and potentially discover novel latent groupings without pre-imposed assumptions. This study offers industry stakeholders and policymakers a replicable and scalable tool for green hydrogen infrastructure planning and other decision making in data-scarce regions.', 'abstract_zh': '基于平均绝对SHAP值的人工智能框架计算绿色氢气产量和站点适用性指数：以阿曼为例', 'title_zh': '基于SHAP综合指数的绿色氢气产量预测与场地适宜性评估：以 Oman 为例'}
{'arxiv_id': 'arXiv:2507.14218', 'title': 'Cognitive Castes: Artificial Intelligence, Epistemic Stratification, and the Dissolution of Democratic Discourse', 'authors': 'Craig S Wright', 'link': 'https://arxiv.org/abs/2507.14218', 'abstract': 'Artificial intelligence functions not as an epistemic leveller, but as an accelerant of cognitive stratification, entrenching and formalising informational castes within liberal-democratic societies. Synthesising formal epistemology, political theory, algorithmic architecture, and economic incentive structures, the argument traces how contemporary AI systems selectively amplify the reasoning capacity of individuals equipped with recursive abstraction, symbolic logic, and adversarial interrogation, whilst simultaneously pacifying the cognitively untrained through engagement-optimised interfaces. Fluency replaces rigour, immediacy displaces reflection, and procedural reasoning is eclipsed by reactive suggestion. The result is a technocratic realignment of power: no longer grounded in material capital alone, but in the capacity to navigate, deconstruct, and manipulate systems of epistemic production. Information ceases to be a commons; it becomes the substrate through which consent is manufactured and autonomy subdued. Deliberative democracy collapses not through censorship, but through the erosion of interpretive agency. The proposed response is not technocratic regulation, nor universal access, but the reconstruction of rational autonomy as a civic mandate, codified in education, protected by epistemic rights, and structurally embedded within open cognitive infrastructure.', 'abstract_zh': '人工智能并非知识平等器，而是认知分层的加速器，在自由民主社会中固化和正式化信息阶层。通过形式化认识论、政治理论、算法架构和经济激励结构的综合，论述了当前AI系统如何有选择地放大那些具备递归抽象、符号逻辑和对抗性问询能力的个体的认知能力，同时通过优化交互界面使认知未受训练者变得倦怠。流畅性取代严谨性，即时性取代反思，程序化推理被反应性建议所取代。结果是技术官僚权力的重新调整：不再仅仅基于物质资本，而是基于导航、分解和操控知识生产系统的能力建设。信息不再成为公共资源；而是成为制造同意和压制自主性的载体。议决民主的崩溃并非通过审查，而是通过解构解释权的侵蚀。提出的战略不是技术规制，也不是普遍访问，而是将理性自主权作为公民义务进行重构，通过教育编码、通过知识权利保护，并根植于开放认知基础设施之中。', 'title_zh': '认知阶层：人工智能、知识阶层化与民主话语的瓦解'}
{'arxiv_id': 'arXiv:2507.14211', 'title': 'PRATA: A Framework to Enable Predictive QoS in Vehicular Networks via Artificial Intelligence', 'authors': 'Federico Mason, Tommaso Zugno, Matteo Drago, Marco Giordani, Mate Boban, Michele Zorzi', 'link': 'https://arxiv.org/abs/2507.14211', 'abstract': 'Predictive Quality of Service (PQoS) makes it possible to anticipate QoS changes, e.g., in wireless networks, and trigger appropriate countermeasures to avoid performance degradation. Hence, PQoS is extremely useful for automotive applications such as teleoperated driving, which poses strict constraints in terms of latency and reliability. A promising tool for PQoS is given by Reinforcement Learning (RL), a methodology that enables the design of decision-making strategies for stochastic optimization. In this manuscript, we present PRATA, a new simulation framework to enable PRedictive QoS based on AI for Teleoperated driving Applications. PRATA consists of a modular pipeline that includes (i) an end-to-end protocol stack to simulate the 5G Radio Access Network (RAN), (ii) a tool for generating automotive data, and (iii) an Artificial Intelligence (AI) unit to optimize PQoS decisions. To prove its utility, we use PRATA to design an RL unit, named RAN-AI, to optimize the segmentation level of teleoperated driving data in the event of resource saturation or channel degradation. Hence, we show that the RAN-AI entity efficiently balances the trade-off between QoS and Quality of Experience (QoE) that characterize teleoperated driving applications, almost doubling the system performance compared to baseline approaches. In addition, by varying the learning settings of the RAN-AI entity, we investigate the impact of the state space and the relative cost of acquiring network data that are necessary for the implementation of RL.', 'abstract_zh': 'Predictive Quality of Service (PQoS)基于AI的远程驾驶应用服务质量预测', 'title_zh': 'PRATA：一种基于人工智能实现车辆网络预测QoS的框架'}
{'arxiv_id': 'arXiv:2507.14206', 'title': 'A Comprehensive Benchmark for Electrocardiogram Time-Series', 'authors': 'Zhijiang Tang, Jiaxin Qi, Yuhua Zheng, Jianqiang Huang', 'link': 'https://arxiv.org/abs/2507.14206', 'abstract': 'Electrocardiogram~(ECG), a key bioelectrical time-series signal, is crucial for assessing cardiac health and diagnosing various diseases. Given its time-series format, ECG data is often incorporated into pre-training datasets for large-scale time-series model training. However, existing studies often overlook its unique characteristics and specialized downstream applications, which differ significantly from other time-series data, leading to an incomplete understanding of its properties. In this paper, we present an in-depth investigation of ECG signals and establish a comprehensive benchmark, which includes (1) categorizing its downstream applications into four distinct evaluation tasks, (2) identifying limitations in traditional evaluation metrics for ECG analysis, and introducing a novel metric; (3) benchmarking state-of-the-art time-series models and proposing a new architecture. Extensive experiments demonstrate that our proposed benchmark is comprehensive and robust. The results validate the effectiveness of the proposed metric and model architecture, which establish a solid foundation for advancing research in ECG signal analysis.', 'abstract_zh': '心电图（ECG），作为关键的生物电信号时间序列数据，对于评估心脏健康和诊断各种疾病至关重要。由于其时间序列格式，ECG数据常被纳入大规模时间序列模型预训练数据集中。然而，现有研究表明，这些研究往往忽视了ECG数据的独特特征和专业下游应用，这些应用与其他时间序列数据差异显著，导致对其属性的理解不完整。在本文中，我们对ECG信号进行了深入研究，并建立了一个综合基准，包括（1）将其下游应用分类为四个不同的评估任务，（2）识别传统ECG分析评价指标的局限性，并引入一个新的评价指标；（3）基准测试最新的时间序列模型并提出一种新的架构。大量的实验表明，我们提出的基准是全面且 robust 的。结果验证了提出的新评价指标和模型架构的有效性，为推进ECG信号分析研究奠定了坚实的基础。', 'title_zh': '全面的心电图时间序列基准'}
{'arxiv_id': 'arXiv:2507.14196', 'title': 'Explainable Parallel CNN-LSTM Model for Differentiating Ventricular Tachycardia from Supraventricular Tachycardia with Aberrancy in 12-Lead ECGs', 'authors': 'Zahra Teimouri-Jervekani, Fahimeh Nasimi, Mohammadreza Yazdchi, Ghazal MogharehZadeh, Javad Tezerji, Farzan Niknejad Mazandarani, Maryam Mohebbi', 'link': 'https://arxiv.org/abs/2507.14196', 'abstract': 'Background and Objective: Differentiating wide complex tachycardia (WCT) is clinically critical yet challenging due to morphological similarities in electrocardiogram (ECG) signals between life-threatening ventricular tachycardia (VT) and supraventricular tachycardia with aberrancy (SVT-A). Misdiagnosis carries fatal risks. We propose a computationally efficient deep learning solution to improve diagnostic accuracy and provide model interpretability for clinical deployment.\nMethods: A novel lightweight parallel deep architecture is introduced. Each pipeline processes individual ECG leads using two 1D-CNN blocks to extract local features. Feature maps are concatenated across leads, followed by LSTM layers to capture temporal dependencies. Final classification employs fully connected layers. Explainability is achieved via Shapley Additive Explanations (SHAP) for local/global interpretation. The model was evaluated on a 35-subject ECG database using standard performance metrics.\nResults: The model achieved $95.63\\%$ accuracy ($95\\%$ CI: $93.07-98.19\\%$), with sensitivity=$95.10\\%$, specificity=$96.06\\%$, and F1-score=$95.12\\%$. It outperformed state-of-the-art methods in both accuracy and computational efficiency, requiring minimal CNN blocks per pipeline. SHAP analysis demonstrated clinically interpretable feature contributions.\nConclusions: Our end-to-end framework delivers high-precision WCT classification with minimal computational overhead. The integration of SHAP enhances clinical trust by elucidating decision logic, supporting rapid, informed diagnosis. This approach shows significant promise for real-world ECG analysis tools.', 'abstract_zh': '背景与目标：区分宽QRS心动过速（WCT）在临床中至关重要但极具挑战性，因为危及生命的室性心动过速（VT）和房室传导异常的房性心动过速（SVT-A）在心电图（ECG）信号上的形态学特征相似。误诊具有致命风险。我们提出了一种计算效率高的深度学习解决方案，旨在提高诊断准确性并提供临床部署中的模型可解释性。\n\n方法：提出了一种新颖的轻量级并行深度架构。每个管道使用两个1D-CNN块处理单个ECG导联以提取局部特征。特征图在导联间进行拼接，随后是LSTM层以捕获时间依赖性。最终分类采用全连接层。通过Shapley值加性解释（SHAP）实现局部/全局解释性。该模型在包含35个受试者的ECG数据库上使用标准性能指标进行评估。\n\n结果：该模型达到了95.63%的准确率（95% CI：93.07-98.19%），敏感性=95.10%，特异性=96.06%，F1分数=95.12%。在准确性和计算效率方面均超越了最先进的方法，并且每个管道所需的CNN块最少。SHAP分析表明具有临床解释性的特征贡献。\n\n结论：我们的端到端框架实现了高精度的WCT分类，计算开销最小。SHAP的集成增强了临床信任，通过阐明决策逻辑支持快速、知情的诊断。这种方法显示出在实际心电图分析工具中应用的重要前景。', 'title_zh': '带有 aberrancy 的 12 导联心电图中室性心动过速与心上性心动过速区分的可解释并行 CNN-LSTM 模型'}
{'arxiv_id': 'arXiv:2507.14195', 'title': 'UWB Radar-based Heart Rate Monitoring: A Transfer Learning Approach', 'authors': 'Elzbieta Gruzewska, Pooja Rao, Sebastien Baur, Matthew Baugh, Mathias M.J. Bellaiche, Sharanya Srinivas, Octavio Ponce, Matthew Thompson, Pramod Rudrapatna, Michael A. Sanchez, Lawrence Z. Cai, Timothy JA Chico, Robert F. Storey, Emily Maz, Umesh Telang, Shravya Shetty, Mayank Daswani', 'link': 'https://arxiv.org/abs/2507.14195', 'abstract': 'Radar technology presents untapped potential for continuous, contactless, and passive heart rate monitoring via consumer electronics like mobile phones. However the variety of available radar systems and lack of standardization means that a large new paired dataset collection is required for each radar system. This study demonstrates transfer learning between frequency-modulated continuous wave (FMCW) and impulse-radio ultra-wideband (IR-UWB) radar systems, both increasingly integrated into consumer devices. FMCW radar utilizes a continuous chirp, while IR-UWB radar employs short pulses. Our mm-wave FMCW radar operated at 60 GHz with a 5.5 GHz bandwidth (2.7 cm resolution, 3 receiving antennas [Rx]), and our IR-UWB radar at 8 GHz with a 500 MHz bandwidth (30 cm resolution, 2 Rx). Using a novel 2D+1D ResNet architecture we achieved a mean absolute error (MAE) of 0.85 bpm and a mean absolute percentage error (MAPE) of 1.42% for heart rate monitoring with FMCW radar (N=119 participants, an average of 8 hours per participant). This model maintained performance (under 5 MAE/10% MAPE) across various body positions and heart rate ranges, with a 98.9% recall. We then fine-tuned a variant of this model, trained on single-antenna and single-range bin FMCW data, using a small (N=376, avg 6 minutes per participant) IR-UWB dataset. This transfer learning approach yielded a model with MAE 4.1 bpm and MAPE 6.3% (97.5% recall), a 25% MAE reduction over the IR-UWB baseline. This demonstration of transfer learning between radar systems for heart rate monitoring has the potential to accelerate its introduction into existing consumer devices.', 'abstract_zh': '雷达技术为通过移动电话等消费电子设备实现连续、非接触和被动心率监测提供了未充分利用的潜力。然而，可用雷达系统的多样化和缺乏标准化意味着每个雷达系统都需要一个新的配对数据集进行收集。本研究展示了频率调制连续波（FMCW）雷达和脉冲雷达（IR-UWB）系统之间的迁移学习，这两种雷达系统正越来越多地集成到消费设备中。FMCW雷达利用连续调频信号，而IR-UWB雷达使用短脉冲信号。我们使用的毫米波FMCW雷达工作在60 GHz频率，带宽为5.5 GHz（分辨率为2.7 cm，3个接收天线[Rx]），而我们的IR-UWB雷达工作在8 GHz频率，带宽为500 MHz（分辨率为30 cm，2个接收天线[Rx])。通过一种新颖的2D+1D ResNet架构，我们在FMCW雷达的心率监测中达到了平均绝对误差（MAE）0.85 bpm和平均绝对百分比误差（MAPE）1.42%（研究对象119人，平均每人8小时）。该模型在多种体位和心率范围内保持了性能（平均绝对误差低于5，平均绝对百分比误差低于10%，召回率为98.9%）。随后，我们使用较小规模的IR-UWB数据集（研究对象376人，平均每人6分钟），对基于单天线和单距离窗口FMCW数据训练的该模型进行了微调。这种迁移学习方法产生了一个MAE为4.1 bpm和MAPE为6.3%（召回率为97.5%）的模型，相比IR-UWB基线模型，平均绝对误差减少了25%。这一雷达系统之间心率监测迁移学习的演示有潜力加速其在现有消费设备中的引入。', 'title_zh': '基于UWB雷达的心率监测：一种迁移学习方法'}
{'arxiv_id': 'arXiv:2507.14193', 'title': 'A Formal Model of the Economic Impacts of AI Openness Regulation', 'authors': 'Tori Qiu, Benjamin Laufer, Jon Kleinberg, Hoda Heidari', 'link': 'https://arxiv.org/abs/2507.14193', 'abstract': 'Regulatory frameworks, such as the EU AI Act, encourage openness of general-purpose AI models by offering legal exemptions for "open-source" models. Despite this legislative attention on openness, the definition of open-source foundation models remains ambiguous. This paper models the strategic interactions among the creator of a general-purpose model (the generalist) and the entity that fine-tunes the general-purpose model to a specialized domain or task (the specialist), in response to regulatory requirements on model openness. We present a stylized model of the regulator\'s choice of an open-source definition to evaluate which AI openness standards will establish appropriate economic incentives for developers. Our results characterize market equilibria -- specifically, upstream model release decisions and downstream fine-tuning efforts -- under various openness regulations and present a range of effective regulatory penalties and open-source thresholds. Overall, we find the model\'s baseline performance determines when increasing the regulatory penalty vs. the open-source threshold will significantly alter the generalist\'s release strategy. Our model provides a theoretical foundation for AI governance decisions around openness and enables evaluation and refinement of practical open-source policies.', 'abstract_zh': '欧盟AI法案等监管框架通过提供“开源”模型的法律免责来鼓励通用人工智能模型的开放性，尽管立法上对开放性给予了关注，但开源基础模型的定义仍存模糊。本文建模了一般模型创作者（通用主义者）和将其训练成专门领域或任务的实体（专家）之间的战略互动，以回应模型开放性的监管要求。我们呈现了一个监管机构选择开源定义的简化模型，以评估哪些AI开放标准将为开发者建立合适的经济激励。结果显示，在不同开放性监管下的市场均衡点——具体而言，上游模型发布决策和下游训练努力——并呈现了一系列有效的监管惩罚和开源门槛。总体而言，我们发现模型的基本表现决定何时增加监管惩罚而非开源门槛将显著改变通用主义者的发布策略。该模型为基础模型的治理决策提供了一个理论基础，并能评价和细化实际的开源政策。', 'title_zh': 'AI开放性监管的经济影响形式化模型'}
{'arxiv_id': 'arXiv:2507.14188', 'title': 'From Cell Towers to Satellites: A 2040 Blueprint for Urban-Grade Direct-to-Device Mobile Networks', 'authors': 'Sebastian Barros Elgueta', 'link': 'https://arxiv.org/abs/2507.14188', 'abstract': "In 2023, satellite and mobile networks crossed a historic threshold: standard smartphones, using unmodified 3GPP protocols, connected directly to low Earth orbit (LEO) satellites. This first wave of direct-to-device (D2D) demonstrations validated the physical feasibility of satellite-based mobile access. However, these systems remain fallback-grade--rural-only, bandwidth-limited, and fully dependent on Earth-based mobile cores for identity, session, and policy control. This paper asks a more ambitious question: Can a complete mobile network, including radio access, core functions, traffic routing, and content delivery, operate entirely from orbit? And can it deliver sustained, urban-grade service in the world's densest cities? We present the first end-to-end system architecture for a fully orbital telco, integrating electronically steered phased arrays with 1000-beam capacity, space-based deployment of 5G core functions (UPF, AMF), and inter-satellite laser mesh backhaul. We analyze spectral efficiency, beam capacity, and link budgets under dense urban conditions, accounting for path loss, Doppler, and multipath. Simulations show that rooftop and line-of-sight users can sustain 64-QAM throughput, while street-level access is feasible with relay or assisted beam modes. The paper outlines the remaining constraints, power, thermal dissipation, compute radiation hardening, and regulatory models, and demonstrates that these are engineering bottlenecks, not physical limits. Finally, we propose a staged 15-year roadmap from today's fallback D2D systems to autonomous orbital overlays delivering 50-100 Mbps to handhelds in megacities, with zero reliance on terrestrial infrastructure.", 'abstract_zh': '2023年，卫星和移动网络跨越了历史门槛：未修改的3GPP协议的标准智能手机直接连接到低地球轨道卫星。这一代首批直接到设备(D2D)演示验证了基于卫星的移动接入的物理可行性。然而，这些系统仍然处于备份级别——仅限农村，带宽受限，并完全依赖地面移动核心网络进行身份、会话和策略控制。本文提出了更为雄心勃勃的问题：一个完整的移动网络，包括无线接入、核心功能、流量路由和内容分发，是否可以完全在轨道上运行？并且它是否能够在世界上最密集的城市中提供持续的、可城市水平的服务？我们提出了首个完整的轨道电信端到端系统架构，集成电子扫描相位阵列、1000波束容量、5G核心功能（UPF、AMF）的太空部署以及星间激光网格回传。我们在密集城市条件下分析了频谱效率、波束容量和链路预算，考虑了路径损耗、多普勒效应和多径效应。仿真结果显示，屋顶和视线用户可以维持64QAM吞吐量，而街道级接入可以通过中继或辅助波束模式实现。本文概述了剩余的限制条件，包括功率、热散射、计算辐射防护和监管模型，并表明这些是工程瓶颈，而非物理限制。最后，我们提出了一条从当前的备份D2D系统到15年内实现的自主轨道叠加的阶梯式 roadmap，该叠加可以在 megacities 中为手持设备提供50-100 Mbps的服务，完全不依赖地面基础设施。', 'title_zh': '从基站在到卫星：2040年城市级直接到设备移动网络蓝图'}
{'arxiv_id': 'arXiv:2507.14187', 'title': 'AI-Based Impedance Encoding-Decoding Method for Online Impedance Network Construction of Wind Farms', 'authors': 'Xiaojuan Zhang, Tianyu Jiang, Haoxiang Zong, Chen Zhang, Chendan Li, Marta Molinas', 'link': 'https://arxiv.org/abs/2507.14187', 'abstract': 'The impedance network (IN) model is gaining popularity in the oscillation analysis of wind farms. However, the construction of such an IN model requires impedance curves of each wind turbine under their respective operating conditions, making its online application difficult due to the transmission of numerous high-density impedance curves. To address this issue, this paper proposes an AI-based impedance encoding-decoding method to facilitate the online construction of IN model. First, an impedance encoder is trained to compress impedance curves by setting the number of neurons much smaller than that of frequency points. Then, the compressed data of each turbine are uploaded to the wind farm and an impedance decoder is trained to reconstruct original impedance curves. At last, based on the nodal admittance matrix (NAM) method, the IN model of the wind farm can be obtained. The proposed method is validated via model training and real-time simulations, demonstrating that the encoded impedance vectors enable fast transmission and accurate reconstruction of the original impedance curves.', 'abstract_zh': '基于AI的阻抗编码解码方法在风电场振荡分析中的在线阻抗网络模型构建', 'title_zh': '基于AI的阻抗编码-解码方法用于风电场在线阻抗网络构建'}
{'arxiv_id': 'arXiv:2507.14186', 'title': 'A Disentangled Representation Learning Framework for Low-altitude Network Coverage Prediction', 'authors': 'Xiaojie Li, Zhijie Cai, Nan Qi, Chao Dong, Guangxu Zhu, Haixia Ma, Qihui Wu, Shi Jin', 'link': 'https://arxiv.org/abs/2507.14186', 'abstract': 'The expansion of the low-altitude economy has underscored the significance of Low-Altitude Network Coverage (LANC) prediction for designing aerial corridors. While accurate LANC forecasting hinges on the antenna beam patterns of Base Stations (BSs), these patterns are typically proprietary and not readily accessible. Operational parameters of BSs, which inherently contain beam information, offer an opportunity for data-driven low-altitude coverage prediction. However, collecting extensive low-altitude road test data is cost-prohibitive, often yielding only sparse samples per BS. This scarcity results in two primary challenges: imbalanced feature sampling due to limited variability in high-dimensional operational parameters against the backdrop of substantial changes in low-dimensional sampling locations, and diminished generalizability stemming from insufficient data samples. To overcome these obstacles, we introduce a dual strategy comprising expert knowledge-based feature compression and disentangled representation learning. The former reduces feature space complexity by leveraging communications expertise, while the latter enhances model generalizability through the integration of propagation models and distinct subnetworks that capture and aggregate the semantic representations of latent features. Experimental evaluation confirms the efficacy of our framework, yielding a 7% reduction in error compared to the best baseline algorithm. Real-network validations further attest to its reliability, achieving practical prediction accuracy with MAE errors at the 5dB level.', 'abstract_zh': '低空经济的扩展突显了低空网络覆盖（LANC）预测对于设计空中走廊的重要性。准确的LANC预测依赖于基站（BSs）的天线波束模式，但这些模式通常具有专有性且难以获取。基站的操作参数内含波束信息，为基于数据的低空覆盖预测提供了机会。然而，收集大量的低空道路测试数据成本高昂，往往只能获得每个BS稀疏的样本。这种稀缺性导致了两个主要挑战：由于高维操作参数中的有限变异性与低维采样位置的显著变化之间的对比所导致的特征采样不平衡，以及由于数据样本不足所导致的模型泛化能力减弱。为克服这些障碍，我们提出了一个双策略，包括基于专家知识的特征压缩和解耦表示学习。前者通过利用通信领域的专业知识来减少特征空间的复杂性，后者通过集成传播模型和能够捕捉和聚合潜在特征语义表示的不同子网络来增强模型的泛化能力。实验评估证实了我们框架的有效性，与最佳基线算法相比，错误率减少了7%。实际网络验证进一步验证了其可靠性，MAE错误率达到5dB时实现了实用的预测精度。', 'title_zh': '低空网络覆盖预测的解耦表示学习框架'}
{'arxiv_id': 'arXiv:2507.14184', 'title': 'NeuroHD-RA: Neural-distilled Hyperdimensional Model with Rhythm Alignment', 'authors': 'ZhengXiao He, Jinghao Wen, Huayu Li, Ao Li', 'link': 'https://arxiv.org/abs/2507.14184', 'abstract': 'We present a novel and interpretable framework for electrocardiogram (ECG)-based disease detection that combines hyperdimensional computing (HDC) with learnable neural encoding. Unlike conventional HDC approaches that rely on static, random projections, our method introduces a rhythm-aware and trainable encoding pipeline based on RR intervals, a physiological signal segmentation strategy that aligns with cardiac cycles. The core of our design is a neural-distilled HDC architecture, featuring a learnable RR-block encoder and a BinaryLinear hyperdimensional projection layer, optimized jointly with cross-entropy and proxy-based metric loss. This hybrid framework preserves the symbolic interpretability of HDC while enabling task-adaptive representation learning. Experiments on Apnea-ECG and PTB-XL demonstrate that our model significantly outperforms traditional HDC and classical ML baselines, achieving 73.09\\% precision and an F1 score of 0.626 on Apnea-ECG, with comparable robustness on PTB-XL. Our framework offers an efficient and scalable solution for edge-compatible ECG classification, with strong potential for interpretable and personalized health monitoring.', 'abstract_zh': '基于心电图的疾病检测新型可解释框架：结合可学习神经编码的高维计算', 'title_zh': '神经HD-节奏对齐超维度模型：神经提炼的高维模型与节奏对齐'}
{'arxiv_id': 'arXiv:2507.14182', 'title': 'From Bias to Behavior: Learning Bull-Bear Market Dynamics with Contrastive Modeling', 'authors': 'Xiaotong Luo, Shengda Zhuo, Min Chen, Lichun Li, Ruizhao Lu, Wenqi Fan, Shuqiang Huang, Yin Tang', 'link': 'https://arxiv.org/abs/2507.14182', 'abstract': 'Financial markets exhibit highly dynamic and complex behaviors shaped by both historical price trajectories and exogenous narratives, such as news, policy interpretations, and social media sentiment. The heterogeneity in these data and the diverse insight of investors introduce biases that complicate the modeling of market dynamics. Unlike prior work, this paper explores the potential of bull and bear regimes in investor-driven market dynamics. Through empirical analysis on real-world financial datasets, we uncover a dynamic relationship between bias variation and behavioral adaptation, which enhances trend prediction under evolving market conditions. To model this mechanism, we propose the Bias to Behavior from Bull-Bear Dynamics model (B4), a unified framework that jointly embeds temporal price sequences and external contextual signals into a shared latent space where opposing bull and bear forces naturally emerge, forming the foundation for bias representation. Within this space, an inertial pairing module pairs temporally adjacent samples to preserve momentum, while the dual competition mechanism contrasts bullish and bearish embeddings to capture behavioral divergence. Together, these components allow B4 to model bias-driven asymmetry, behavioral inertia, and market heterogeneity. Experimental results on real-world financial datasets demonstrate that our model not only achieves superior performance in predicting market trends but also provides interpretable insights into the interplay of biases, investor behaviors, and market dynamics.', 'abstract_zh': '投资者驱动的金融市场中多空格局对动态行为的影响及偏差与行为适应性之间的动态关系模型（B4）', 'title_zh': '从偏见到行为：基于对比建模学习 Bulls-Bear 市场动态'}
{'arxiv_id': 'arXiv:2507.14181', 'title': 'Semi-Supervised Federated Learning via Dual Contrastive Learning and Soft Labeling for Intelligent Fault Diagnosis', 'authors': 'Yajiao Dai, Jun Li, Zhen Mei, Yiyang Ni, Shi Jin, Zengxiang Li, Sheng Guo, Wei Xiang', 'link': 'https://arxiv.org/abs/2507.14181', 'abstract': "Intelligent fault diagnosis (IFD) plays a crucial role in ensuring the safe operation of industrial machinery and improving production efficiency. However, traditional supervised deep learning methods require a large amount of training data and labels, which are often located in different clients. Additionally, the cost of data labeling is high, making labels difficult to acquire. Meanwhile, differences in data distribution among clients may also hinder the model's performance. To tackle these challenges, this paper proposes a semi-supervised federated learning framework, SSFL-DCSL, which integrates dual contrastive loss and soft labeling to address data and label scarcity for distributed clients with few labeled samples while safeguarding user privacy. It enables representation learning using unlabeled data on the client side and facilitates joint learning among clients through prototypes, thereby achieving mutual knowledge sharing and preventing local model divergence. Specifically, first, a sample weighting function based on the Laplace distribution is designed to alleviate bias caused by low confidence in pseudo labels during the semi-supervised training process. Second, a dual contrastive loss is introduced to mitigate model divergence caused by different data distributions, comprising local contrastive loss and global contrastive loss. Third, local prototypes are aggregated on the server with weighted averaging and updated with momentum to share knowledge among clients. To evaluate the proposed SSFL-DCSL framework, experiments are conducted on two publicly available datasets and a dataset collected on motors from the factory. In the most challenging task, where only 10\\% of the data are labeled, the proposed SSFL-DCSL can improve accuracy by 1.15% to 7.85% over state-of-the-art methods.", 'abstract_zh': '智能故障诊断(Intelligent Fault Diagnosis, IFD)在确保工业 Machinery 安全运行和提高生产效率方面发挥着重要作用。然而，传统的监督深度学习方法需要大量的训练数据和标签，这些数据和标签通常分布在不同的客户端。此外，数据标签的成本高昂，使得标签难以获取。同时，客户端之间数据分布的差异也可能阻碍模型性能的提升。为应对这些挑战，本文提出了一种半监督联邦学习框架 SSFL-DCSL，该框架结合了双对比损失和软标签，以解决分布式客户端数据和标签稀缺问题，同时保护用户隐私。该方法在客户端利用未标记数据进行表示学习，并通过原型促进客户端之间的联合学习，从而实现知识共享并防止本地模型发散。具体而言，首先，设计了基于拉普拉斯分布的样本加权函数，以缓解半监督训练过程中伪标签低置信度带来的偏差；其次，引入了双对比损失以减轻不同数据分布导致的模型发散，包括局部对比损失和全局对比损失；第三，服务器端通过加权平均聚合局部原型，并借助动量更新来共享知识。为了评估提出的 SSFL-DCSL 框架，我们在两个公开数据集和工厂收集的电机数据集上进行了实验。在数据标记量最少的最具挑战性的任务中，即仅有 10% 的数据被标记，所提出的 SSFL-DCSL 相比现有方法可将准确性提高 1.15% 至 7.85%。', 'title_zh': '半监督联邦学习通过双 Contrastive 学习和软标签化进行智能故障诊断'}
{'arxiv_id': 'arXiv:2507.14178', 'title': 'Feature Bank Enhancement for Distance-based Out-of-Distribution Detection', 'authors': 'Yuhang Liu, Yuefei Wu, Bin Shi, Bo Dong', 'link': 'https://arxiv.org/abs/2507.14178', 'abstract': 'Out-of-distribution (OOD) detection is critical to ensuring the reliability of deep learning applications and has attracted significant attention in recent years. A rich body of literature has emerged to develop efficient score functions that assign high scores to in-distribution (ID) samples and low scores to OOD samples, thereby helping distinguish OOD samples. Among these methods, distance-based score functions are widely used because of their efficiency and ease of use. However, deep learning often leads to a biased distribution of data features, and extreme features are inevitable. These extreme features make the distance-based methods tend to assign too low scores to ID samples. This limits the OOD detection capabilities of such methods. To address this issue, we propose a simple yet effective method, Feature Bank Enhancement (FBE), that uses statistical characteristics from dataset to identify and constrain extreme features to the separation boundaries, therapy making the distance between samples inside and outside the distribution farther. We conducted experiments on large-scale ImageNet-1k and CIFAR-10 respectively, and the results show that our method achieves state-of-the-art performance on both benchmark. Additionally, theoretical analysis and supplementary experiments are conducted to provide more insights into our method.', 'abstract_zh': '离分布（OOD）检测对于保证深度学习应用的可靠性至关重要，近年来已引起广泛关注。为了区分离分布样本，大量文献致力于开发高效的分数函数，为在分布（ID）样本分配高分数，为离分布样本分配低分数。在这些方法中，基于距离的分数函数因其效率和易于使用而被广泛采用。然而，深度学习会导致数据特征分布的偏倚，极端特征是不可避免的。这些极端特征会使基于距离的方法倾向于为在分布样本分配过低的分数，从而限制了这类方法的离分布检测能力。为解决这一问题，我们提出了一种简单有效的方法——特征库增强（FBE），该方法利用数据集的统计特性来识别和限制极端特征到分离边界，从而使样本内外部之间的距离更远。我们在大规模的ImageNet-1k和CIFAR-10上进行了实验，结果显示，我们的方法在两个基准上均实现了当前最先进的性能。此外，我们还进行了理论分析和补充实验，以提供更多关于我们方法的见解。', 'title_zh': '基于特征库增强的距离域外检测'}
{'arxiv_id': 'arXiv:2507.14177', 'title': 'Understanding Two-Layer Neural Networks with Smooth Activation Functions', 'authors': 'Changcun Huang', 'link': 'https://arxiv.org/abs/2507.14177', 'abstract': "This paper aims to understand the training solution, which is obtained by the back-propagation algorithm, of two-layer neural networks whose hidden layer is composed of the units with smooth activation functions, including the usual sigmoid type most commonly used before the advent of ReLUs. The mechanism contains four main principles: construction of Taylor series expansions, strict partial order of knots, smooth-spline implementation and smooth-continuity restriction. The universal approximation for arbitrary input dimensionality is proved and experimental verification is given, through which the mystery of ``black box'' of the solution space is largely revealed. The new proofs employed also enrich approximation theory.", 'abstract_zh': '本文旨在理解由反向传播算法获得的、其隐层由光滑激活函数单元组成的两层神经网络的训练解决方案，这些光滑激活函数包括ReLU出现之前的常用sigmoid类型。该机制包含四个主要原则：泰勒级数展开的构造、节点的严格偏序、光滑样条实现和光滑连续性限制。证明了任意输入维度的通用逼近能力，并通过实验验证，大大揭示了解决方案空间的“黑箱”之谜。新提出的证明也丰富了逼近理论。', 'title_zh': '理解具有平滑激活函数的两层神经网络'}
{'arxiv_id': 'arXiv:2507.14171', 'title': 'IPPRO: Importance-based Pruning with PRojective Offset for Magnitude-indifferent Structural Pruning', 'authors': 'Jaeheun Jung, Jaehyuk Lee, Yeajin Lee, Donghun Lee', 'link': 'https://arxiv.org/abs/2507.14171', 'abstract': "With the growth of demand on neural network compression methods, the structured pruning methods including importance-based approach are actively studied. The magnitude importance and many correlated modern importance criteria often limit the capacity of pruning decision, since the filters with larger magnitudes are not likely to be pruned if the smaller one didn't, even if it is redundant. In this paper, we propose a novel pruning strategy to challenge this dominating effect of magnitude and provide fair chance to each filter to be pruned, by placing it on projective space. After that, we observe the gradient descent movement whether the filters move toward the origin or not, to measure how the filter is likely to be pruned. This measurement is used to construct PROscore, a novel importance score for IPPRO, a novel importance-based structured pruning with magnitude-indifference. Our evaluation results shows that the proposed importance criteria using the projective space achieves near-lossless pruning by reducing the performance drop in pruning, with promising performance after the finetuning. Our work debunks the ``size-matters'' myth in pruning and expands the frontier of importance-based pruning both theoretically and empirically.", 'abstract_zh': '基于射影空间的结构剪枝新策略：克服幅度主导效应及其应用', 'title_zh': '基于重要性裁剪的投影偏移.magnitude无关结构裁剪'}
{'arxiv_id': 'arXiv:2507.14170', 'title': 'Catalyst: a Novel Regularizer for Structured Pruning with Auxiliary Extension of Parameter Space', 'authors': 'Jaeheun Jung, Donghun Lee', 'link': 'https://arxiv.org/abs/2507.14170', 'abstract': 'Structured pruning aims to reduce the size and computational cost of deep neural networks by removing entire filters or channels. The traditional regularizers such as L1 or Group Lasso and its variants lead to magnitude-biased pruning decisions, such that the filters with small magnitudes are likely to be pruned. Also, they often entail pruning results with almost zero margin around pruning decision boundary, such that tiny perturbation in a filter magnitude can flip the pruning decision. In this paper, we identify the precise algebraic condition under which pruning operations preserve model performance, and use the condition to construct a novel regularizer defined in an extended parameter space via auxiliary catalyst variables. The proposed Catalyst regularization ensures fair pruning chance for each filters with theoretically provable zero bias to their magnitude and robust pruning behavior achieved by wide-margin bifurcation of magnitudes between the preserved and the pruned filters. The theoretical properties naturally lead to real-world effectiveness, as shown by empirical validations of Catalyst Pruning algorithm. Pruning results on various datasets and models are superior to state-of-the-art filter pruning methods, and at the same time confirm the predicted robust and fair pruning characteristics of Catalyst pruning.', 'abstract_zh': '结构化剪枝旨在通过移除整个滤波器或通道来减少深度神经网络的大小和计算成本。传统的正则化器如L1或组Lasso及其变体会导致幅度偏置的剪枝决策，使得幅度较小的滤波器更有可能被移除。此外，它们往往会导致在剪枝决策边界附近几乎没有零边际的结果，使得滤波器幅度的小幅度变化就能翻转剪枝决策。在本文中，我们识别了剪枝操作保持模型性能的精确代数条件，并利用该条件构造了一个新型正则化器，该正则化器通过辅助催化剂变量在扩展的参数空间中定义。提出的催化剂正则化确保了每个滤波器公平的剪枝机会，并且通过保持和移除滤波器幅度之间的大零边际分叉实现了理论上可证明的幅度无偏的剪枝行为。理论性质自然地导致实际效果，如催化剂剪枝算法的经验验证所示。在各种数据集和模型上的剪枝结果优于最先进的滤波器剪枝方法，并且同时证实了催化剂剪枝预测的稳健和公平的剪枝特性。', 'title_zh': '催化剂：一种新型结构剪枝正则化器及其参数空间扩展辅助方法'}
{'arxiv_id': 'arXiv:2507.14164', 'title': 'A Denoising VAE for Intracardiac Time Series in Ischemic Cardiomyopathy', 'authors': 'Samuel Ruipérez-Campillo, Alain Ryser, Thomas M. Sutter, Ruibin Feng, Prasanth Ganesan, Brototo Deb, Kelly A. Brennan, Maxime Pedron, Albert J. Rogers, Maarten Z.H. Kolk, Fleur V.Y. Tjong, Sanjiv M. Narayan, Julia E. Vogt', 'link': 'https://arxiv.org/abs/2507.14164', 'abstract': 'In the field of cardiac electrophysiology (EP), effectively reducing noise in intra-cardiac signals is crucial for the accurate diagnosis and treatment of arrhythmias and cardiomyopathies. However, traditional noise reduction techniques fall short in addressing the diverse noise patterns from various sources, often non-linear and non-stationary, present in these signals. This work introduces a Variational Autoencoder (VAE) model, aimed at improving the quality of intra-ventricular monophasic action potential (MAP) signal recordings. By constructing representations of clean signals from a dataset of 5706 time series from 42 patients diagnosed with ischemic cardiomyopathy, our approach demonstrates superior denoising performance when compared to conventional filtering methods commonly employed in clinical settings. We assess the effectiveness of our VAE model using various metrics, indicating its superior capability to denoise signals across different noise types, including time-varying non-linear noise frequently found in clinical settings. These results reveal that VAEs can eliminate diverse sources of noise in single beats, outperforming state-of-the-art denoising techniques and potentially improving treatment efficacy in cardiac EP.', 'abstract_zh': '在心脏电解生理学领域，有效地减少心内电信号中的噪声对于心律失常和心肌病的准确诊断和治疗至关重要。然而，传统的去噪技术在处理来自多种来源的复杂非线性、非平稳噪声时往往力不从心。本工作引入了一种变分自编码器（VAE）模型，旨在提高心室内单相动作电位（MAP）信号记录的质量。通过从42名诊断为缺血性心肌病的患者中构建包含5706个时间序列的数据集来重建清洁信号，我们的方法在各类噪声条件下的去噪性能明显优于临床常用的传统滤波方法。我们使用多种指标评估了VAE模型的有效性，结果表明其在不同类型噪声下的去噪能力优于现有技术，特别是对临床环境中常见的时变非线性噪声表现出色。这些结果表明，VAE能够有效消除单个心拍中的多种噪声来源，超越了当前最先进的去噪技术，有可能提高心脏电解生理学中的治疗效果。', 'title_zh': '用于缺血性心肌病内心脏时间序列去噪的VAE模型'}
{'arxiv_id': 'arXiv:2507.14156', 'title': 'All-atom inverse protein folding through discrete flow matching', 'authors': 'Kai Yi, Kiarash Jamali, Sjors H. W. Scheres', 'link': 'https://arxiv.org/abs/2507.14156', 'abstract': 'The recent breakthrough of AlphaFold3 in modeling complex biomolecular interactions, including those between proteins and ligands, nucleotides, or metal ions, creates new opportunities for protein design. In so-called inverse protein folding, the objective is to find a sequence of amino acids that adopts a target protein structure. Many inverse folding methods struggle to predict sequences for complexes that contain non-protein components, and perform poorly with complexes that adopt multiple structural states. To address these challenges, we present ADFLIP (All-atom Discrete FLow matching Inverse Protein folding), a generative model based on discrete flow-matching for designing protein sequences conditioned on all-atom structural contexts. ADFLIP progressively incorporates predicted amino acid side chains as structural context during sequence generation and enables the design of dynamic protein complexes through ensemble sampling across multiple structural states. Furthermore, ADFLIP implements training-free classifier guidance sampling, which allows the incorporation of arbitrary pre-trained models to optimise the designed sequence for desired protein properties. We evaluated the performance of ADFLIP on protein complexes with small-molecule ligands, nucleotides, or metal ions, including dynamic complexes for which structure ensembles were determined by nuclear magnetic resonance (NMR). Our model achieves state-of-the-art performance in single-structure and multi-structure inverse folding tasks, demonstrating excellent potential for all-atom protein design. The code is available at this https URL.', 'abstract_zh': 'AlphaFold3在建模蛋白质与配体、核酸或金属离子等复杂生物分子相互作用方面的最近突破为蛋白质设计创造了新机会。在所谓的逆折叠问题中，目标是找到能折叠成目标蛋白质结构的氨基酸序列。许多逆折叠方法在预测包含非蛋白质成分的复合物序列时遇困难，且对采用多种结构状态的复合物效果不佳。为应对这些挑战，我们提出了ADFLIP（全原子离散流匹配逆折叠），这是一种基于离散流匹配的生成模型，用于在全原子结构上下文中条件氨基酸序列设计。ADFLIP在序列生成过程中逐步整合预测的氨基酸侧链作为结构上下文，并通过跨多个结构状态的集合采样实现动态蛋白质复合物的设计。此外，ADFLIP实现了无需训练的分类器引导采样，允许将任意预训练模型纳入设计序列以优化期望的蛋白质性质。我们评估了ADFLIP在含有小分子配体、核酸或金属离子的蛋白质复合物上的性能，包括由核磁共振（NMR）确定结构集合的动力学复合物。我们的模型在单结构和多结构逆折叠任务中达到了最先进的性能，展示了全原子蛋白质设计的优异潜力。代码可在以下链接访问。', 'title_zh': '通过离散流匹配的全原子逆折纸蛋白'}
{'arxiv_id': 'arXiv:2507.14153', 'title': "Surface EMG Profiling in Parkinson's Disease: Advancing Severity Assessment with GCN-SVM", 'authors': 'Daniel Cieślak, Barbara Szyca, Weronika Bajko, Liwia Florkiewicz, Kinga Grzęda, Mariusz Kaczmarek, Helena Kamieniecka, Hubert Lis, Weronika Matwiejuk, Anna Prus, Michalina Razik, Inga Rozumowicz, Wiktoria Ziembakowska', 'link': 'https://arxiv.org/abs/2507.14153', 'abstract': "Parkinson's disease (PD) poses challenges in diagnosis and monitoring due to its progressive nature and complex symptoms. This study introduces a novel approach utilizing surface electromyography (sEMG) to objectively assess PD severity, focusing on the biceps brachii muscle. Initial analysis of sEMG data from five PD patients and five healthy controls revealed significant neuromuscular differences. A traditional Support Vector Machine (SVM) model achieved up to 83% accuracy, while enhancements with a Graph Convolutional Network-Support Vector Machine (GCN-SVM) model increased accuracy to 92%. Despite the preliminary nature of these results, the study outlines a detailed experimental methodology for future research with larger cohorts to validate these findings and integrate the approach into clinical practice. The proposed approach holds promise for advancing PD severity assessment and improving patient care in Parkinson's disease management.", 'abstract_zh': '帕金森病（PD）由于其渐进性质和复杂症状，在诊断和监测方面具有挑战性。本研究提出了一种新的方法，利用表面肌电图（sEMG）客观评估PD严重程度，重点在于评估肱二头肌。初步分析来自五名PD患者和五名健康对照的sEMG数据揭示了显著的神经肌肉差异。传统的支持向量机（SVM）模型实现了高达83%的准确率，而通过图卷积网络-支持向量机（GCN-SVM）模型的增强将准确率提高到92%。尽管这些结果具有初步性质，但本研究概述了一种详细的经验方法，旨在未来的研究中通过更大的样本量验证这些发现，并将该方法整合到临床实践中。所提出的方法有望推动PD严重程度的评估，并改善帕金森病管理中的患者护理。', 'title_zh': '帕金森病中表面肌电图特征分析：基于GCN-SVM的病情严重程度评估进展'}
{'arxiv_id': 'arXiv:2507.14151', 'title': 'Self-DANA: A Resource-Efficient Channel-Adaptive Self-Supervised Approach for ECG Foundation Models', 'authors': 'Giuliana Monachino, Nicolò La Porta, Beatrice Zanchi, Luigi Fiorillo, Alvise Dei Rossi, Georgiy Farina, Francesca Dalia Faraci', 'link': 'https://arxiv.org/abs/2507.14151', 'abstract': 'Foundation Models (FMs) are large-scale machine learning models trained on extensive, diverse datasets that can be adapted to a wide range of downstream tasks with minimal fine-tuning. In the last two years, interest in FMs has also grown for applications in the cardiological field to analyze the electrocardiogram (ECG) signals. One of the key properties of FMs is their transferability to a wide range of downstream scenarios. With the spread of wearable and portable devices, keen interest in learning from reduced-channel configurations has arisen. However, the adaptation of ECG FMs to downstream scenarios with fewer available channels still has to be properly investigated. In this work, we propose Self-DANA, a novel, easy-to-integrate solution that makes self-supervised architectures adaptable to a reduced number of input channels, ensuring resource efficiency and high performance. We also introduce Random Lead Selection, a novel augmentation technique to pre-train models in a more robust and channel-agnostic way. Our experimental results on five reduced-channel configurations demonstrate that Self-DANA significantly enhances resource efficiency while reaching state-of-the-art performance. It requires up to 69.3% less peak CPU memory, 34.4% less peak GPU memory, about 17% less average epoch CPU time, and about 24% less average epoch GPU time.', 'abstract_zh': '基于自监督的Self-DANA解决方案在减少通道配置下的心电图（ECG）模型适应性研究', 'title_zh': '自适应自我监督的资源高效电生理信号基础模型方法：Self-DANA：一种资源高效且通道自适应的自我监督方法'}
{'arxiv_id': 'arXiv:2507.14141', 'title': 'DIVER-0 : A Fully Channel Equivariant EEG Foundation Model', 'authors': 'Danny Dongyeop Han, Ahhyun Lucy Lee, Taeyang Lee, Yonghyeon Gwon, Sebin Lee, Seongjin Lee, David Keetae Park, Shinjae Yoo, Jiook Cha, Chun Kee Chung', 'link': 'https://arxiv.org/abs/2507.14141', 'abstract': 'Electroencephalography (EEG) is a non-invasive technique widely used in brain-computer interfaces and clinical applications, yet existing EEG foundation models face limitations in modeling spatio-temporal brain dynamics and lack channel permutation equivariance, preventing robust generalization across diverse electrode configurations. To address these challenges, we propose DIVER-0, a novel EEG foundation model that demonstrates how full spatio-temporal attention-rather than segregated spatial or temporal processing-achieves superior performance when properly designed with Rotary Position Embedding (RoPE) for temporal relationships and binary attention biases for channel differentiation. We also introduce Sliding Temporal Conditional Positional Encoding (STCPE), which improves upon existing conditional positional encoding approaches by maintaining both temporal translation equivariance and channel permutation equivariance, enabling robust adaptation to arbitrary electrode configurations unseen during pretraining. Experimental results demonstrate that DIVER-0 achieves competitive performance with only 10% of pretraining data while maintaining consistent results across all channel permutation conditions, validating its effectiveness for cross-dataset generalization and establishing key design principles for handling the inherent heterogeneity of neural recording setups.', 'abstract_zh': 'DIVER-0：一种全时空注意的脑电基础模型及其在多元电极配置下的稳健适应性', 'title_zh': 'DIVER-0：一种全通道等变的脑电基础模型'}
{'arxiv_id': 'arXiv:2507.14140', 'title': 'Geophysics-informed neural network for model-based seismic inversion using surrogate point spread functions', 'authors': 'Marcus Saraiva, Ana Muller, Alexandre Maul', 'link': 'https://arxiv.org/abs/2507.14140', 'abstract': "Model-based seismic inversion is a key technique in reservoir characterization, but traditional methods face significant limitations, such as relying on 1D average stationary wavelets and assuming an unrealistic lateral resolution. To address these challenges, we propose a Geophysics-Informed Neural Network (GINN) that integrates deep learning with seismic modeling. This novel approach employs a Deep Convolutional Neural Network (DCNN) to simultaneously estimate Point Spread Functions (PSFs) and acoustic impedance (IP). PSFs are divided into zero-phase and residual components to ensure geophysical consistency and to capture fine details. We used synthetic data from the SEAM Phase I Earth Model to train the GINN for 100 epochs (approximately 20 minutes) using a 2D UNet architecture. The network's inputs include positional features and a low-frequency impedance (LF-IP) model. A self-supervised loss function combining Mean Squared Error (MSE) and Structural Similarity Index Measure (SSIM) was employed to ensure accurate results. The GINN demonstrated its ability to generate high-resolution IP and realistic PSFs, aligning with expected geological features. Unlike traditional 1D wavelets, the GINN produces PSFs with limited lateral resolution, reducing noise and improving accuracy. Future work will aim to refine the training process and validate the methodology with real seismic data.", 'abstract_zh': '基于地质信息的神经网络在储层描述中的模型驱动地震反演：一种整合深度学习与地震建模的新方法', 'title_zh': '基于代理点扩展函数的地质物理知识嵌入神经网络模型地震反演'}
