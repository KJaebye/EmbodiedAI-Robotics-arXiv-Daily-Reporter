# Improving Swimming Performance in Soft Robotic Fish with Distributed Muscles and Embedded Kinematic Sensing 

**Title (ZH)**: 具有分布式肌肉和嵌入式运动传感的软体鱼类游泳性能提升 

**Authors**: Kevin Soto, Isabel Hess, Brandon Schrader, Shan He, Patrick Musgrave  

**Link**: [PDF](https://arxiv.org/pdf/2504.11377)  

**Abstract**: Bio-inspired underwater vehicles could yield improved efficiency, maneuverability, and environmental compatibility over conventional propeller-driven underwater vehicles. However, to realize the swimming performance of biology, there is a need for soft robotic swimmers with both distributed muscles and kinematic feedback. This study presents the design and swimming performance of a soft robotic fish with independently controllable muscles and embedded kinematic sensing distributed along the body. The soft swimming robot consists of an interior flexible spine, three axially distributed sets of HASEL artificial muscles, embedded strain gauges, a streamlined silicone body, and off-board electronics. In a fixed configuration, the soft robot generates a maximum thrust of 7.9 mN when excited near its first resonant frequency (2 Hz) with synchronized antagonistic actuation of all muscles. When excited near its second resonant frequency (8 Hz), synchronized muscle actuation generates 5.0 mN of thrust. By introducing a sequential phase offset into the muscle actuation, the thrust at the second resonant frequency increases to 7.2 mN, a 44% increase from simple antagonistic activation. The sequential muscle activation improves the thrust by increasing 1) the tail-beat velocity and 2) traveling wave content in the swimming kinematics by four times. Further, the second resonant frequency (8 Hz) generates nearly as much thrust as the first resonance (2 Hz) while requiring only $\approx25$% of the tail displacement, indicating that higher resonant frequencies have benefits for swimming in confined environments where a smaller kinematic envelope is necessary. These results demonstrate the performance benefits of independently controllable muscles and distributed kinematic sensing, and this type of soft robotic swimmer provides a platform to address the open challenge of sensorimotor control. 

**Abstract (ZH)**: 受生物启发的 underwater 软体机器人鱼在推进效率、操控性和环境兼容性方面可能优于传统的螺旋桨驱动 underwater 车辆。然而，为了实现生物学的游泳性能，需要具有分布式肌肉和运动学反馈的软体机器人鱼。本研究介绍了具有独立可控肌肉和沿身体分布嵌入式运动学感应的软体机器人鱼的设计及其游泳性能。该软体游动机器人包括一个内部柔性脊柱、三组轴向分布的HASEL人工肌肉、嵌入式应变计、流线型硅胶体外壳和外部电子设备。在固定配置下，当在第一共振频率（2 Hz）附近激发并进行所有肌肉的同步拮抗激活时，软机器人产生最大推力7.9 mN。当在第二共振频率（8 Hz）附近激发并进行同步肌肉激活时，产生的推力为5.0 mN。通过引入肌肉激活的顺序相位偏移，第二共振频率下的推力增加到7.2 mN，比简单的拮抗激活增加了44%。顺序肌肉激活通过增加1) 尾拍速度和2) 游泳运动学中的行波成分四倍来提高推力。此外，第二共振频率（8 Hz）产生的推力几乎与第一共振频率（2 Hz）一样多，但仅需约25%的尾巴位移，表明在需要较小运动学包络的受限环境中，较高共振频率具有优势。这些结果展示了独立可控肌肉和分布式的运动学传感带来的性能优势，这种类型的软体机器人鱼为解决传感器运动控制这一开放性挑战提供了平台。 

---
# Next-Future: Sample-Efficient Policy Learning for Robotic-Arm Tasks 

**Title (ZH)**: Next-Future: 样本高效机器人臂任务策略学习 

**Authors**: Fikrican Özgür, René Zurbrügg, Suryansh Kumar  

**Link**: [PDF](https://arxiv.org/pdf/2504.11247)  

**Abstract**: Hindsight Experience Replay (HER) is widely regarded as the state-of-the-art algorithm for achieving sample-efficient multi-goal reinforcement learning (RL) in robotic manipulation tasks with binary rewards. HER facilitates learning from failed attempts by replaying trajectories with redefined goals. However, it relies on a heuristic-based replay method that lacks a principled framework. To address this limitation, we introduce a novel replay strategy, "Next-Future", which focuses on rewarding single-step transitions. This approach significantly enhances sample efficiency and accuracy in learning multi-goal Markov decision processes (MDPs), particularly under stringent accuracy requirements -- a critical aspect for performing complex and precise robotic-arm tasks. We demonstrate the efficacy of our method by highlighting how single-step learning enables improved value approximation within the multi-goal RL framework. The performance of the proposed replay strategy is evaluated across eight challenging robotic manipulation tasks, using ten random seeds for training. Our results indicate substantial improvements in sample efficiency for seven out of eight tasks and higher success rates in six tasks. Furthermore, real-world experiments validate the practical feasibility of the learned policies, demonstrating the potential of "Next-Future" in solving complex robotic-arm tasks. 

**Abstract (ZH)**: 基于“ hindsight经验重放（HER）的“Next-Future”重放策略在机器人 manipulation 任务中的高效多目标强化学习 

---
# A Real-time Anomaly Detection Method for Robots based on a Flexible and Sparse Latent Space 

**Title (ZH)**: 基于柔性稀疏潜在空间的实时机器人异常检测方法 

**Authors**: Taewook Kang, Bum-Jae You, Juyoun Park, Yisoo Lee  

**Link**: [PDF](https://arxiv.org/pdf/2504.11170)  

**Abstract**: The growing demand for robots to operate effectively in diverse environments necessitates the need for robust real-time anomaly detection techniques during robotic operations. However, deep learning-based models in robotics face significant challenges due to limited training data and highly noisy signal features. In this paper, we present Sparse Masked Autoregressive Flow-based Adversarial AutoEncoders model to address these problems. This approach integrates Masked Autoregressive Flow model into Adversarial AutoEncoders to construct a flexible latent space and utilize Sparse autoencoder to efficiently focus on important features, even in scenarios with limited feature space. Our experiments demonstrate that the proposed model achieves a 4.96% to 9.75% higher area under the receiver operating characteristic curve for pick-and-place robotic operations with randomly placed cans, compared to existing state-of-the-art methods. Notably, it showed up to 19.67% better performance in scenarios involving collisions with lightweight objects. Additionally, unlike the existing state-of-the-art model, our model performs inferences within 1 millisecond, ensuring real-time anomaly detection. These capabilities make our model highly applicable to machine learning-based robotic safety systems in dynamic environments. The code will be made publicly available after acceptance. 

**Abstract (ZH)**: 基于稀疏掩码自回归流的对抗自编码器模型：应对机器人操作中多样环境下的实时异常检测需求 

---
# The Robotability Score: Enabling Harmonious Robot Navigation on Urban Streets 

**Title (ZH)**: 机器人化得分：实现城市街道和谐机器人导航 

**Authors**: Matt Franchi, Maria Teresa Parreira, Fanjun Bu, Wendy Ju  

**Link**: [PDF](https://arxiv.org/pdf/2504.11163)  

**Abstract**: This paper introduces the Robotability Score ($R$), a novel metric that quantifies the suitability of urban environments for autonomous robot navigation. Through expert interviews and surveys, we identify and weigh key features contributing to R for wheeled robots on urban streets. Our findings reveal that pedestrian density, crowd dynamics and pedestrian flow are the most critical factors, collectively accounting for 28% of the total score. Computing robotability across New York City yields significant variation; the area of highest R is 3.0 times more "robotable" than the area of lowest R. Deployments of a physical robot on high and low robotability areas show the adequacy of the score in anticipating the ease of robot navigation. This new framework for evaluating urban landscapes aims to reduce uncertainty in robot deployment while respecting established mobility patterns and urban planning principles, contributing to the discourse on harmonious human-robot environments. 

**Abstract (ZH)**: 这篇论文介绍了Robotability得分（$R$），这是一个新颖的指标，用于量化城市环境对自主机器人导航的适宜性。通过专家访谈和调查，我们识别并加权了对城市街道上轮式机器人导航至关重要的关键特征。我们的研究发现，行人密度、人群动态和行人流量是最重要的因素，共同占总分的28%。在整个纽约市计算机器人适宜性揭示了显著的变化；最高机器人适宜性区域的得分是最低区域的3.0倍。在高机器人适宜性和低机器人适宜性区域部署物理机器人显示了该得分在预测机器人导航难度方面的有效性。这一新的评估城市景观的框架旨在减少机器人部署的不确定性，同时尊重已有的移动模式和城市规划原则，为和谐的人机共存环境的讨论做出贡献。 

---
# FreeDOM: Online Dynamic Object Removal Framework for Static Map Construction Based on Conservative Free Space Estimation 

**Title (ZH)**: FreeDOM：基于保守自由空间估计的静态地图构建在线动态对象移除框架 

**Authors**: Chen Li, Wanlei Li, Wenhao Liu, Yixiang Shu, Yunjiang Lou  

**Link**: [PDF](https://arxiv.org/pdf/2504.11073)  

**Abstract**: Online map construction is essential for autonomous robots to navigate in unknown environments. However, the presence of dynamic objects may introduce artifacts into the map, which can significantly degrade the performance of localization and path planning. To tackle this problem, a novel online dynamic object removal framework for static map construction based on conservative free space estimation (FreeDOM) is proposed, consisting of a scan-removal front-end and a map-refinement back-end. First, we propose a multi-resolution map structure for fast computation and effective map representation. In the scan-removal front-end, we employ raycast enhancement to improve free space estimation and segment the LiDAR scan based on the estimated free space. In the map-refinement back-end, we further eliminate residual dynamic objects in the map by leveraging incremental free space information. As experimentally verified on SemanticKITTI, HeLiMOS, and indoor datasets with various sensors, our proposed framework overcomes the limitations of visibility-based methods and outperforms state-of-the-art methods with an average F1-score improvement of 9.7%. 

**Abstract (ZH)**: 基于保守自由空间估计的在线动态物体去除框架以构建静态地图 

---
# Neural Control Barrier Functions from Physics Informed Neural Networks 

**Title (ZH)**: 基于物理知情神经网络的神经控制屏障函数 

**Authors**: Shreenabh Agrawal, Manan Tayal, Aditya Singh, Shishir Kolathaya  

**Link**: [PDF](https://arxiv.org/pdf/2504.11045)  

**Abstract**: As autonomous systems become increasingly prevalent in daily life, ensuring their safety is paramount. Control Barrier Functions (CBFs) have emerged as an effective tool for guaranteeing safety; however, manually designing them for specific applications remains a significant challenge. With the advent of deep learning techniques, recent research has explored synthesizing CBFs using neural networks-commonly referred to as neural CBFs. This paper introduces a novel class of neural CBFs that leverages a physics-inspired neural network framework by incorporating Zubov's Partial Differential Equation (PDE) within the context of safety. This approach provides a scalable methodology for synthesizing neural CBFs applicable to high-dimensional systems. Furthermore, by utilizing reciprocal CBFs instead of zeroing CBFs, the proposed framework allows for the specification of flexible, user-defined safe regions. To validate the effectiveness of the approach, we present case studies on three different systems: an inverted pendulum, autonomous ground navigation, and aerial navigation in obstacle-laden environments. 

**Abstract (ZH)**: 随着自主系统在日常生活中日益普及，确保其安全变得至关重要。控制障碍函数（CBFs）已成为确保安全的有效工具；然而，为特定应用手工设计它们仍然是一个重大挑战。随着深度学习技术的发展，最近的研究探索了使用神经网络合成CBFs——通常称为神经CBFs。本文介绍了一种新的神经CBF类，通过在安全性框架中结合Zubov偏微分方程（PDE）来利用物理启发的神经网络框架。该方法提供了一种可扩展的合成神经CBFs的方法，适用于高维系统。此外，通过使用逆CBFs而不是零CBFs，所提出的框架允许为用户定义灵活的安全区域。为了验证该方法的有效性，我们在三个不同的系统上进行了案例研究：倒立摆、自主地面导航和障碍环境下的空中导航。 

---
# Acquisition of high-quality images for camera calibration in robotics applications via speech prompts 

**Title (ZH)**: 通过语音提示获取用于机器人应用-camera标定的高质量图像 

**Authors**: Timm Linder, Kadir Yilmaz, David B. Adrian, Bastian Leibe  

**Link**: [PDF](https://arxiv.org/pdf/2504.11031)  

**Abstract**: Accurate intrinsic and extrinsic camera calibration can be an important prerequisite for robotic applications that rely on vision as input. While there is ongoing research on enabling camera calibration using natural images, many systems in practice still rely on using designated calibration targets with e.g. checkerboard patterns or April tag grids. Once calibration images from different perspectives have been acquired and feature descriptors detected, those are typically used in an optimization process to minimize the geometric reprojection error. For this optimization to converge, input images need to be of sufficient quality and particularly sharpness; they should neither contain motion blur nor rolling-shutter artifacts that can arise when the calibration board was not static during image capture. In this work, we present a novel calibration image acquisition technique controlled via voice commands recorded with a clip-on microphone, that can be more robust and user-friendly than e.g. triggering capture with a remote control, or filtering out blurry frames from a video sequence in postprocessing. To achieve this, we use a state-of-the-art speech-to-text transcription model with accurate per-word timestamping to capture trigger words with precise temporal alignment. Our experiments show that the proposed method improves user experience by being fast and efficient, allowing us to successfully calibrate complex multi-camera setups. 

**Abstract (ZH)**: 准确的固有和外在相机标定对于依赖视觉输入的机器人应用来说是重要的先决条件。尽管目前有关利用自然图像进行相机标定的研究正在进行，但在实践中许多系统仍然依靠使用特定的标定目标，如棋盘格模式或AprilTag网格。一旦从不同视角获取了标定图像并检测出特征描述符，通常会将这些特征描述符用于优化过程以最小化几何重投影误差。为了使这种优化能够收敛，输入图像需要具有足够的质量，特别是在捕获图像时标定板应该是静止的，以避免运动模糊或滚筒快门伪影。在本工作中，我们提出了一种通过贴片麦克风录制语音命令控制的新型标定图像采集技术，该技术比使用遥控器触发捕获或在后期处理中过滤模糊帧更加健壮和用户友好。为实现这一目标，我们使用了具有准确逐词时间戳的最新演讲转文字模型，以实现精确的时间对齐。我们的实验表明，所提出的方法通过提高高效性改善了用户体验，使我们能够成功标定复杂的多相机系统。 

---
# $π$-MPPI: A Projection-based Model Predictive Path Integral Scheme for Smooth Optimal Control of Fixed-Wing Aerial Vehicles 

**Title (ZH)**: 基于投影的路径积分模型预测控制方案：固定翼 aerial 车辆平滑最优控制 

**Authors**: Edvin Martin Andrejev, Amith Manoharan, Karl-Eerik Unt, Arun Kumar Singh  

**Link**: [PDF](https://arxiv.org/pdf/2504.10962)  

**Abstract**: Model Predictive Path Integral (MPPI) is a popular sampling-based Model Predictive Control (MPC) algorithm for nonlinear systems. It optimizes trajectories by sampling control sequences and averaging them. However, a key issue with MPPI is the non-smoothness of the optimal control sequence, leading to oscillations in systems like fixed-wing aerial vehicles (FWVs). Existing solutions use post-hoc smoothing, which fails to bound control derivatives. This paper introduces a new approach: we add a projection filter $\pi$ to minimally correct control samples, ensuring bounds on control magnitude and higher-order derivatives. The filtered samples are then averaged using MPPI, leading to our $\pi$-MPPI approach. We minimize computational overhead by using a neural accelerated custom optimizer for the projection filter. $\pi$-MPPI offers a simple way to achieve arbitrary smoothness in control sequences. While we focus on FWVs, this projection filter can be integrated into any MPPI pipeline. Applied to FWVs, $\pi$-MPPI is easier to tune than the baseline, resulting in smoother, more robust performance. 

**Abstract (ZH)**: 基于投影滤波的模型预测路径积分（π-MPPI）算法 

---
# ZeroGrasp: Zero-Shot Shape Reconstruction Enabled Robotic Grasping 

**Title (ZH)**: ZeroGrasp: 零样本形状重建赋能机器人抓取 

**Authors**: Shun Iwase, Zubair Irshad, Katherine Liu, Vitor Guizilini, Robert Lee, Takuya Ikeda, Ayako Amma, Koichi Nishiwaki, Kris Kitani, Rares Ambrus, Sergey Zakharov  

**Link**: [PDF](https://arxiv.org/pdf/2504.10857)  

**Abstract**: Robotic grasping is a cornerstone capability of embodied systems. Many methods directly output grasps from partial information without modeling the geometry of the scene, leading to suboptimal motion and even collisions. To address these issues, we introduce ZeroGrasp, a novel framework that simultaneously performs 3D reconstruction and grasp pose prediction in near real-time. A key insight of our method is that occlusion reasoning and modeling the spatial relationships between objects is beneficial for both accurate reconstruction and grasping. We couple our method with a novel large-scale synthetic dataset, which comprises 1M photo-realistic images, high-resolution 3D reconstructions and 11.3B physically-valid grasp pose annotations for 12K objects from the Objaverse-LVIS dataset. We evaluate ZeroGrasp on the GraspNet-1B benchmark as well as through real-world robot experiments. ZeroGrasp achieves state-of-the-art performance and generalizes to novel real-world objects by leveraging synthetic data. 

**Abstract (ZH)**: 机器人抓取是具身系统的一项基石能力。许多方法直接从部分信息输出抓取，而不建模场景几何，导致运动次优甚至发生碰撞。为解决这些问题，我们提出了ZeroGrasp，这是一种新颖的框架，能够同时在近实时下进行3D重建和抓取姿态预测。我们方法的一个关键洞察是，遮挡推理和建模物体之间的空间关系对于准确的重建和抓取都有益处。我们将该方法与一个新的大规模合成数据集相结合，该数据集包含100万张逼真图像、高分辨率3D重建以及对Objaverse-LVIS数据集中12000个对象的1130亿个物理上有效的抓取姿态注释。我们在GraspNet-1B基准上评估了ZeroGrasp，并通过真实世界机器人实验进行了评估。ZeroGrasp实现了最先进的性能，并通过利用合成数据对新型真实世界对象进行了泛化。 

---
# Following Is All You Need: Robot Crowd Navigation Using People As Planners 

**Title (ZH)**: 跟随即一切：利用人群作为规划者的机器人群体导航 

**Authors**: Yuwen Liao, Xinhang Xu, Ruofei Bai, Yizhuo Yang, Muqing Cao, Shenghai Yuan, Lihua Xie  

**Link**: [PDF](https://arxiv.org/pdf/2504.10828)  

**Abstract**: Navigating in crowded environments requires the robot to be equipped with high-level reasoning and planning techniques. Existing works focus on developing complex and heavyweight planners while ignoring the role of human intelligence. Since humans are highly capable agents who are also widely available in a crowd navigation setting, we propose an alternative scheme where the robot utilises people as planners to benefit from their effective planning decisions and social behaviours. Through a set of rule-based evaluations, we identify suitable human leaders who exhibit the potential to guide the robot towards its goal. Using a simple base planner, the robot follows the selected leader through shorthorizon subgoals that are designed to be straightforward to achieve. We demonstrate through both simulated and real-world experiments that our novel framework generates safe and efficient robot plans compared to existing planners, even without predictive or data-driven modules. Our method also brings human-like robot behaviours without explicitly defining traffic rules and social norms. Code will be available at this https URL. 

**Abstract (ZH)**: 在拥挤环境中导航需要机器人配备高级推理和规划技术。现有工作集中在开发复杂和沉重的规划器上，而忽视了人类智能的作用。由于人类是高度有能力且在拥挤环境下广泛可用的代理，我们提出了一种替代方案，其中机器人利用人类作为规划者，以受益于他们有效的规划决策和社会行为。通过一套基于规则的评估，我们识别出合适的 human leaders，他们具有引导机器人实现其目标的潜力。使用一个简单的基础规划器，机器人通过设计易于实现的短期子目标跟随选定的领导者。通过模拟和真实世界的实验，我们展示我们的新颖框架生成的安全且高效的机器人规划，即使没有预测或数据驱动的模块。我们的方法也带来了类似人类的机器人行为，而无需明确定义交通规则和社会规范。代码将在此处提供。 

---
# E2E Parking Dataset: An Open Benchmark for End-to-End Autonomous Parking 

**Title (ZH)**: 端到端泊车数据集：面向端到端自动驾驶泊车的开源基准 

**Authors**: Kejia Gao, Liguo Zhou, Mingjun Liu, Alois Knoll  

**Link**: [PDF](https://arxiv.org/pdf/2504.10812)  

**Abstract**: End-to-end learning has shown great potential in autonomous parking, yet the lack of publicly available datasets limits reproducibility and benchmarking. While prior work introduced a visual-based parking model and a pipeline for data generation, training, and close-loop test, the dataset itself was not released. To bridge this gap, we create and open-source a high-quality dataset for end-to-end autonomous parking. Using the original model, we achieve an overall success rate of 85.16% with lower average position and orientation errors (0.24 meters and 0.34 degrees). 

**Abstract (ZH)**: 端到端学习在自主停车中的应用展现了巨大的潜力，然而公开数据集的缺乏限制了重复实验和基准测试。为弥补这一缺口，我们创建并开源了一个高质量的自主停车数据集，采用原始模型实现了总体成功率85.16%，且平均位置和方向误差分别为0.24米和0.34度。 

---
# ATLASv2: LLM-Guided Adaptive Landmark Acquisition and Navigation on the Edge 

**Title (ZH)**: ATLASv2: LLM引导的边缘自适应地标获取与导航 

**Authors**: Mikolaj Walczak, Uttej Kallakuri, Tinoosh Mohsenin  

**Link**: [PDF](https://arxiv.org/pdf/2504.10784)  

**Abstract**: Autonomous systems deployed on edge devices face significant challenges, including resource constraints, real-time processing demands, and adapting to dynamic environments. This work introduces ATLASv2, a novel system that integrates a fine-tuned TinyLLM, real-time object detection, and efficient path planning to enable hierarchical, multi-task navigation and manipulation all on the edge device, Jetson Nano. ATLASv2 dynamically expands its navigable landmarks by detecting and localizing objects in the environment which are saved to its internal knowledge base to be used for future task execution. We evaluate ATLASv2 in real-world environments, including a handcrafted home and office setting constructed with diverse objects and landmarks. Results show that ATLASv2 effectively interprets natural language instructions, decomposes them into low-level actions, and executes tasks with high success rates. By leveraging generative AI in a fully on-board framework, ATLASv2 achieves optimized resource utilization with minimal prompting latency and power consumption, bridging the gap between simulated environments and real-world applications. 

**Abstract (ZH)**: 部署在边缘设备上的自主系统面临显著挑战，包括资源限制、实时处理需求以及适应动态环境的能力。本文介绍了ATLASv2，这是一种将微调过的TinyLLM、实时物体检测和高效路径规划集成的新系统，使其能够在Jetson Nano这样的边缘设备上实现分层的多任务导航和操作。ATLASv2通过检测和定位环境中的物体来动态扩展可导航地标，并将这些信息保存在其内部知识库中，以用于未来的任务执行。我们在真实的环境中评估了ATLASv2，包括由各种物体和地标组成的手工制作的家庭和办公室环境。结果表明，ATLASv2能够有效地解释自然语言指令，将其分解为低级动作，并以高成功率执行任务。通过在完全机载框架中利用生成式AI，ATLASv2实现了优化资源利用，具备最小的提示延迟和能耗，从而弥合了模拟环境与实际应用之间的差距。 

---
# Superfast Configuration-Space Convex Set Computation on GPUs for Online Motion Planning 

**Title (ZH)**: 基于GPU的超快速配置空间凸集计算在线运动规划 

**Authors**: Peter Werner, Richard Cheng, Tom Stewart, Russ Tedrake, Daniela Rus  

**Link**: [PDF](https://arxiv.org/pdf/2504.10783)  

**Abstract**: In this work, we leverage GPUs to construct probabilistically collision-free convex sets in robot configuration space on the fly. This extends the use of modern motion planning algorithms that leverage such representations to changing environments. These planners rapidly and reliably optimize high-quality trajectories, without the burden of challenging nonconvex collision-avoidance constraints. We present an algorithm that inflates collision-free piecewise linear paths into sequences of convex sets (SCS) that are probabilistically collision-free using massive parallelism. We then integrate this algorithm into a motion planning pipeline, which leverages dynamic roadmaps to rapidly find one or multiple collision-free paths, and inflates them. We then optimize the trajectory through the probabilistically collision-free sets, simultaneously using the candidate trajectory to detect and remove collisions from the sets. We demonstrate the efficacy of our approach on a simulation benchmark and a KUKA iiwa 7 robot manipulator with perception in the loop. On our benchmark, our approach runs 17.1 times faster and yields a 27.9% increase in reliability over the nonlinear trajectory optimization baseline, while still producing high-quality motion plans. 

**Abstract (ZH)**: 本研究利用GPU实时构建机器人配置空间中的概率无碰撞凸集。此方法将依赖此类表示的现代运动规划算法扩展到动态环境。这些规划器能够迅速可靠地优化高质量轨迹，同时避免复杂的非凸碰撞约束。我们提出了一种算法，利用大规模并行性将无碰撞的分段线性路径膨胀为概率无碰撞的凸集序列（SCS）。然后，我们将此算法集成到运动规划管道中，利用动态路网快速找到一个或多个无碰撞路径，并将其膨胀。随后，我们通过这些概率无碰撞的集屮优化轨迹，同时使用候选轨迹检测并移除集中的碰撞。我们通过仿真基准和带有感知的KUKA iiwa 7机器人 manipulator演示了该方法的有效性。在基准测试中，与非线性轨迹优化基准相比，该方法运行速度快17.1倍，可靠性能提高27.9%，同时生成高质量的运动规划。 

---
# Communication-aware Hierarchical Map Compression of Time-Varying Environments for Mobile Robots 

**Title (ZH)**: 通信感知分层时间varying环境地图压缩方法及其在移动机器人中的应用 

**Authors**: Daniel T. Larsson, Dipankar Maity  

**Link**: [PDF](https://arxiv.org/pdf/2504.10751)  

**Abstract**: In this paper, we develop a systematic framework for the time-sequential compression of dynamic probabilistic occupancy grids. Our approach leverages ideas from signal compression theory to formulate an optimization problem that searches for a multi-resolution hierarchical encoder that balances the quality of the compressed map (distortion) with its description size, the latter of which relates to the bandwidth required to reliably transmit the map to other agents or to store map estimates in on-board memory. The resulting optimization problem allows for multi-resolution map compressions to be obtained that satisfy available communication or memory resources, and does not require knowledge of the occupancy map dynamics. We develop an algorithm to solve our problem, and demonstrate the utility of the proposed framework in simulation on both static (i.e., non-time varying) and dynamic (time-varying) occupancy maps. 

**Abstract (ZH)**: 本文开发了一种系统化的框架，用于动态概率占位格网的时间序列压缩。我们的方法利用信号压缩理论中的想法，提出了一种优化问题，该问题旨在寻找一个多分辨率层次编码器，以平衡压缩地图的质量（失真）与其描述大小，后者与可靠地传输地图所需的带宽相关。该优化问题允许获得满足可用通信或内存资源的多分辨率地图压缩，并且不需要了解占位地图的动力学。我们开发了一个算法来解决这个问题，并在静态（即非时间变化）和动态（时间变化）占位地图的仿真实验中展示了所提出的框架的应用价值。 

---
# HyRRT-Connect: Bidirectional Motion Planning for Hybrid Dynamical Systems 

**Title (ZH)**: HyRRT-Connect: 双向混合动力学系统运动规划 

**Authors**: Nan Wang, Ricardo G. Sanfelice  

**Link**: [PDF](https://arxiv.org/pdf/2504.10699)  

**Abstract**: This paper proposes a bidirectional rapidly-exploring random trees (RRT) algorithm to solve the motion planning problem for hybrid systems. The proposed algorithm, called HyRRT-Connect, propagates in both forward and backward directions in hybrid time until an overlap between the forward and backward propagation results is detected. Then, HyRRT-Connect constructs a motion plan through the reversal and concatenation of functions defined on hybrid time domains, ensuring that the motion plan satisfies the given hybrid dynamics. To address the potential discontinuity along the flow caused by tolerating some distance between the forward and backward partial motion plans, we reconstruct the backward partial motion plan by a forward-in-hybrid-time simulation from the final state of the forward partial motion plan. effectively eliminating the discontinuity. The proposed algorithm is applied to an actuated bouncing ball system and a walking robot example to highlight its computational improvement. 

**Abstract (ZH)**: 基于混合时间的双向快速探索随机树算法（HyRRT-Connect）及其在混合系统运动规划中的应用 

---
# A Clean Slate for Offline Reinforcement Learning 

**Title (ZH)**: 从零开始的离线强化学习 

**Authors**: Matthew Thomas Jackson, Uljad Berdica, Jarek Liesen, Shimon Whiteson, Jakob Nicolaus Foerster  

**Link**: [PDF](https://arxiv.org/pdf/2504.11453)  

**Abstract**: Progress in offline reinforcement learning (RL) has been impeded by ambiguous problem definitions and entangled algorithmic designs, resulting in inconsistent implementations, insufficient ablations, and unfair evaluations. Although offline RL explicitly avoids environment interaction, prior methods frequently employ extensive, undocumented online evaluation for hyperparameter tuning, complicating method comparisons. Moreover, existing reference implementations differ significantly in boilerplate code, obscuring their core algorithmic contributions. We address these challenges by first introducing a rigorous taxonomy and a transparent evaluation protocol that explicitly quantifies online tuning budgets. To resolve opaque algorithmic design, we provide clean, minimalistic, single-file implementations of various model-free and model-based offline RL methods, significantly enhancing clarity and achieving substantial speed-ups. Leveraging these streamlined implementations, we propose Unifloral, a unified algorithm that encapsulates diverse prior approaches within a single, comprehensive hyperparameter space, enabling algorithm development in a shared hyperparameter space. Using Unifloral with our rigorous evaluation protocol, we develop two novel algorithms - TD3-AWR (model-free) and MoBRAC (model-based) - which substantially outperform established baselines. Our implementation is publicly available at this https URL. 

**Abstract (ZH)**: offline reinforcement learning (RL) 的进展受到了含糊的问题定义和交织的算法设计的阻碍，导致了不一致的实现、缺乏充分的消融实验以及不公平的评估。尽管offline RL明确避免了环境交互，但先前的方法经常通过广泛的、未记录的在线评估进行超参数调优，这使得方法间的比较变得更加复杂。此外，现有的参考实现之间在样板代码方面存在显著差异，这模糊了它们的核心算法贡献。我们通过首先引入严谨的分类学和透明的评估协议，明确量化在线调优预算来应对这些挑战。为了解决模糊的算法设计，我们提供了各种无模型和基于模型的offline RL方法的简洁、最小化、单一文件实现，显著提高了清晰度并实现了显著的加速。利用这些优化的实现，我们提出了Unifloral，这是一种统一的算法，将多种先前的方法封装在一个全面的超参数空间中，使算法开发能够在共享的超参数空间中进行。使用Unifloral和严谨的评估协议，我们开发了两个新的算法——TD3-AWR（无模型）和MoBRAC（基于模型），它们显著优于现有的基线方法。我们的实现已公开，可从以下链接访问：this https URL。 

---
# CAP-Net: A Unified Network for 6D Pose and Size Estimation of Categorical Articulated Parts from a Single RGB-D Image 

**Title (ZH)**: CAP-Net：从单张RGB-D图像中估计类别化articulated部分6D姿态和尺寸的一体化网络 

**Authors**: Jingshun Huang, Haitao Lin, Tianyu Wang, Yanwei Fu, Xiangyang Xue, Yi Zhu  

**Link**: [PDF](https://arxiv.org/pdf/2504.11230)  

**Abstract**: This paper tackles category-level pose estimation of articulated objects in robotic manipulation tasks and introduces a new benchmark dataset. While recent methods estimate part poses and sizes at the category level, they often rely on geometric cues and complex multi-stage pipelines that first segment parts from the point cloud, followed by Normalized Part Coordinate Space (NPCS) estimation for 6D poses. These approaches overlook dense semantic cues from RGB images, leading to suboptimal accuracy, particularly for objects with small parts. To address these limitations, we propose a single-stage Network, CAP-Net, for estimating the 6D poses and sizes of Categorical Articulated Parts. This method combines RGB-D features to generate instance segmentation and NPCS representations for each part in an end-to-end manner. CAP-Net uses a unified network to simultaneously predict point-wise class labels, centroid offsets, and NPCS maps. A clustering algorithm then groups points of the same predicted class based on their estimated centroid distances to isolate each part. Finally, the NPCS region of each part is aligned with the point cloud to recover its final pose and size. To bridge the sim-to-real domain gap, we introduce the RGBD-Art dataset, the largest RGB-D articulated dataset to date, featuring photorealistic RGB images and depth noise simulated from real sensors. Experimental evaluations on the RGBD-Art dataset demonstrate that our method significantly outperforms the state-of-the-art approach. Real-world deployments of our model in robotic tasks underscore its robustness and exceptional sim-to-real transfer capabilities, confirming its substantial practical utility. Our dataset, code and pre-trained models are available on the project page. 

**Abstract (ZH)**: 本文解决了机器人操作任务中刚性部件类别级姿态估计问题，并引入了一个新的基准数据集。虽然最近的方法在类别级别估计部件姿态和尺寸，但它们通常依赖于几何线索和复杂的多阶段管道，首先从点云中分割部件，然后使用归一化部分坐标空间(NPCS)估计6D姿态。这些方法忽视了从RGB图像中提取的密集语义线索，导致精度欠佳，特别是对于具有小部件的对象。为了解决这些局限性，我们提出了一种单阶段网络CAP-Net，用于估计类别级可变形部件的6D姿态和尺寸。该方法结合RGB-D特征，以端到端的方式生成每个部件的实例分割和NPCS表示。CAP-Net使用统一网络同时预测点级类别标签、质心偏移和NPCS图。然后，使用聚类算法根据估计的质心距离对具有相同预测类别的点进行分组，以隔离每个部件。最后，将每个部件的NPCS区域与点云对齐以恢复其最终姿态和尺寸。为弥合仿真到现实的领域差距，我们引入了RGBD-Art数据集，这是迄今为止最大的RGB-D可变形数据集，包含逼真的RGB图像和从真实传感器模拟的深度噪声。在RGBD-Art数据集上的实验评估表明，我们的方法显著优于现有最先进的方法。在实际机器人任务中的应用部署证明了其稳健性和出色的仿真实现迁移能力，确认了其重大的实用价值。我们的数据集、代码和预训练模型可在项目页面获取。 

---
# A Multi-UAV Formation Obstacle Avoidance Method Combined Improved Simulated Annealing and Adaptive Artificial Potential Field 

**Title (ZH)**: 改进模拟退火算法和自适应人工势场相结合的多无人机编队障碍避让方法 

**Authors**: Bo Ma, Yi Ji, Liyong Fang  

**Link**: [PDF](https://arxiv.org/pdf/2504.11064)  

**Abstract**: The traditional Artificial Potential Field (APF) method exhibits limitations in its force distribution: excessive attraction when UAVs are far from the target may cause collisions with obstacles, while insufficient attraction near the goal often results in failure to reach the target. Furthermore, APF is highly susceptible to local minima, compromising motion reliability in complex environments. To address these challenges, this paper presents a novel hybrid obstacle avoidance algorithm-Deflected Simulated Annealing-Adaptive Artificial Potential Field (DSA-AAPF)-which combines an improved simulated annealing mechanism with an enhanced APF model. The proposed approach integrates a Leader-Follower distributed formation strategy with the APF framework, where the resultant force formulation is redefined to smooth UAV trajectories. An adaptive gravitational gain function is introduced to dynamically adjust UAV velocity based on environmental context, and a fast-converging controller ensures accurate and efficient convergence to the target. Moreover, a directional deflection mechanism is embedded within the simulated annealing process, enabling UAVs to escape local minima caused by semi-enclosed obstacles through continuous rotational motion. The simulation results, covering formation reconfiguration, complex obstacle avoidance, and entrapment escape, demonstrate the feasibility, robustness, and superiority of the proposed DSA-AAPF algorithm. 

**Abstract (ZH)**: 改进的模拟退火-自适应人工势场混合避障算法（改进DSA-AAPF算法） 

---
# A Sublinear Algorithm for Path Feasibility Among Rectangular Obstacles 

**Title (ZH)**: 亚线性算法实现矩形障碍物路径可行性的判断 

**Authors**: Alex Fan, Alicia Li, Arul Kolla, Jason Gonzalez  

**Link**: [PDF](https://arxiv.org/pdf/2504.10859)  

**Abstract**: The problem of finding a path between two points while avoiding obstacles is critical in robotic path planning. We focus on the feasibility problem: determining whether such a path exists. We model the robot as a query-specific rectangular object capable of moving parallel to its sides. The obstacles are axis-aligned, rectangular, and may overlap. Most previous works only consider nondisjoint rectangular objects and point-sized or statically sized robots. Our approach introduces a novel technique leveraging generalized Gabriel graphs and constructs a data structure to facilitate online queries regarding path feasibility with varying robot sizes in sublinear time. To efficiently handle feasibility queries, we propose an online algorithm utilizing sweep line to construct a generalized Gabriel graph under the $L_\infty$ norm, capturing key gap constraints between obstacles. We utilize a persistent disjoint-set union data structure to efficiently determine feasibility queries in $\mathcal{O}(\log n)$ time and $\mathcal{O}(n)$ total space. 

**Abstract (ZH)**: 在两点之间寻找避免障碍物的路径问题是机器人路径规划中的关键问题。我们关注可行性问题：确定这样的路径是否存在。我们将机器人建模为查询特定的矩形对象，能够在其边上平行移动。障碍物是轴对齐的矩形，并且可能重叠。大多数以前的工作只考虑非分离的矩形对象和点大小或静态大小的机器人。我们的方法引入了一种新的技术，利用广义加布里埃尔图，并构建了一个数据结构，以实现在线查询路径可行性，同时随着机器人大小的变化在亚线性时间内进行。为了高效地处理可行性查询，我们提出了一种利用扫描线在线构建在$L_\infty$范数下的广义加布里埃尔图的算法，捕捉障碍物之间的关键间隙约束。我们利用持久分离集合合并数据结构，在$\mathcal{O}(\log n)$时间复杂度和$\mathcal{O}(n)$总空间复杂度下高效地确定可行性查询。 

---
# Hallucination-Aware Generative Pretrained Transformer for Cooperative Aerial Mobility Control 

**Title (ZH)**: 面向幻觉的生成预训练变换器在协同空中机动控制中的应用 

**Authors**: Hyojun Ahn, Seungcheol Oh, Gyu Seon Kim, Soyi Jung, Soohyun Park, Joongheon Kim  

**Link**: [PDF](https://arxiv.org/pdf/2504.10831)  

**Abstract**: This paper proposes SafeGPT, a two-tiered framework that integrates generative pretrained transformers (GPTs) with reinforcement learning (RL) for efficient and reliable unmanned aerial vehicle (UAV) last-mile deliveries. In the proposed design, a Global GPT module assigns high-level tasks such as sector allocation, while an On-Device GPT manages real-time local route planning. An RL-based safety filter monitors each GPT decision and overrides unsafe actions that could lead to battery depletion or duplicate visits, effectively mitigating hallucinations. Furthermore, a dual replay buffer mechanism helps both the GPT modules and the RL agent refine their strategies over time. Simulation results demonstrate that SafeGPT achieves higher delivery success rates compared to a GPT-only baseline, while substantially reducing battery consumption and travel distance. These findings validate the efficacy of combining GPT-based semantic reasoning with formal safety guarantees, contributing a viable solution for robust and energy-efficient UAV logistics. 

**Abstract (ZH)**: SafeGPT：结合强化学习的两层框架以实现高效可靠的自主飞行器最后一英里交付 

---
# SeeTree -- A modular, open-source system for tree detection and orchard localization 

**Title (ZH)**: SeeTree ——一种模块化开源的树木检测与果园定位系统 

**Authors**: Jostan Brown, Cindy Grimm, Joseph R. Davidson  

**Link**: [PDF](https://arxiv.org/pdf/2504.10764)  

**Abstract**: Accurate localization is an important functional requirement for precision orchard management. However, there are few off-the-shelf commercial solutions available to growers. In this paper, we present SeeTree, a modular, open source embedded system for tree trunk detection and orchard localization that is deployable on any vehicle. Building on our prior work on vision-based in-row localization using particle filters, SeeTree includes several new capabilities. First, it provides capacity for full orchard localization including out-of-row headland turning. Second, it includes the flexibility to integrate either visual, GNSS, or wheel odometry in the motion model. During field experiments in a commercial orchard, the system converged to the correct location 99% of the time over 800 trials, even when starting with large uncertainty in the initial particle locations. When turning out of row, the system correctly tracked 99% of the turns (860 trials representing 43 unique row changes). To help support adoption and future research and development, we make our dataset, design files, and source code freely available to the community. 

**Abstract (ZH)**: 精准定位是精确果园管理的重要功能需求。然而，面向种植者提供的现成商业解决方案很少。本文介绍SeeTree，一种基于模块化和开源的嵌入式系统，用于检测树干并实现果园定位，可在任何车辆上部署。该系统在我们之前基于粒子滤波的行内视觉定位工作基础上，包含了几种新的功能。首先，它提供了包括行间调头的整个果园定位能力。其次，其运动模型能够灵活地整合视觉、GNSS或轮式里程计。在商业化果园的实地试验中，系统在800次试验中有99%的时间能够从初始位置的高不确定性中收敛到正确位置；在行间调头时，系统正确跟踪了99%的转弯（860次试验，涵盖43次不同的行变化）。为了支持推广应用和未来的研究开发，我们将数据集、设计文件和源代码免费提供给社区。 

---
# ReasonDrive: Efficient Visual Question Answering for Autonomous Vehicles with Reasoning-Enhanced Small Vision-Language Models 

**Title (ZH)**: ReasonDrive: 融合推理增强的小规模视觉语言模型的自主车辆高效视觉问答 

**Authors**: Amirhosein Chahe, Lifeng Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2504.10757)  

**Abstract**: Vision-language models (VLMs) show promise for autonomous driving but often lack transparent reasoning capabilities that are critical for safety. We investigate whether explicitly modeling reasoning during fine-tuning enhances VLM performance on driving decision tasks. Using GPT-4o, we generate structured reasoning chains for driving scenarios from the DriveLM benchmark with category-specific prompting strategies. We compare reasoning-based fine-tuning, answer-only fine-tuning, and baseline instruction-tuned models across multiple small VLM families (Llama 3.2, Llava 1.5, and Qwen 2.5VL). Our results demonstrate that reasoning-based fine-tuning consistently outperforms alternatives, with Llama3.2-11B-reason achieving the highest performance. Models fine-tuned with reasoning show substantial improvements in accuracy and text generation quality, suggesting explicit reasoning enhances internal representations for driving decisions. These findings highlight the importance of transparent decision processes in safety-critical domains and offer a promising direction for developing more interpretable autonomous driving systems. 

**Abstract (ZH)**: Vision-language模型(VLMs)在自主驾驶领域展现出潜力，但往往缺乏对于安全至关重要的透明推理能力。我们探讨了在微调过程中显式建模推理是否能够提升VLM在驾驶决策任务上的性能。使用GPT-4o，我们针对DriveLM基准数据集中的驾驶场景，采用类别特定的提示策略生成结构化的推理链。我们将基于推理的微调、仅答案微调和基线指令调优模型在多个小型VLM家族（Llama 3.2、Llava 1.5和Qwen 2.5VL）上进行对比。研究结果表明，基于推理的微调始终优于其他方法，Llama3.2-11B-reason表现最佳。带有推理微调的模型在准确性和文本生成质量方面显示出显著改善，这表明显式的推理能够增强用于驾驶决策的内部表示。这些发现突显了在安全关键领域中透明决策过程的重要性，并为开发更具可解释性的自主驾驶系统提供了有前景的方向。 

---
# Real-time Seafloor Segmentation and Mapping 

**Title (ZH)**: 实时海底分割与制图 

**Authors**: Michele Grimaldi, Nouf Alkaabi, Francesco Ruscio, Sebastian Realpe Rua, Rafael Garcia, Nuno Gracias  

**Link**: [PDF](https://arxiv.org/pdf/2504.10750)  

**Abstract**: Posidonia oceanica meadows are a species of seagrass highly dependent on rocks for their survival and conservation. In recent years, there has been a concerning global decline in this species, emphasizing the critical need for efficient monitoring and assessment tools. While deep learning-based semantic segmentation and visual automated monitoring systems have shown promise in a variety of applications, their performance in underwater environments remains challenging due to complex water conditions and limited datasets. This paper introduces a framework that combines machine learning and computer vision techniques to enable an autonomous underwater vehicle (AUV) to inspect the boundaries of Posidonia oceanica meadows autonomously. The framework incorporates an image segmentation module using an existing Mask R-CNN model and a strategy for Posidonia oceanica meadow boundary tracking. Furthermore, a new class dedicated to rocks is introduced to enhance the existing model, aiming to contribute to a comprehensive monitoring approach and provide a deeper understanding of the intricate interactions between the meadow and its surrounding environment. The image segmentation model is validated using real underwater images, while the overall inspection framework is evaluated in a realistic simulation environment, replicating actual monitoring scenarios with real underwater images. The results demonstrate that the proposed framework enables the AUV to autonomously accomplish the main tasks of underwater inspection and segmentation of rocks. Consequently, this work holds significant potential for the conservation and protection of marine environments, providing valuable insights into the status of Posidonia oceanica meadows and supporting targeted preservation efforts 

**Abstract (ZH)**: Posidonia oceanica 沼泽的监测与评估：结合机器学习和计算机视觉的自主水下车辆框架 

---
# CleanMAP: Distilling Multimodal LLMs for Confidence-Driven Crowdsourced HD Map Updates 

**Title (ZH)**: CleanMAP：提炼多模态LLMs以实现基于信心驱动的高精度地图众包更新 

**Authors**: Ankit Kumar Shaw, Kun Jiang, Tuopu Wen, Chandan Kumar Sah, Yining Shi, Mengmeng Yang, Diange Yang, Xiaoli Lian  

**Link**: [PDF](https://arxiv.org/pdf/2504.10738)  

**Abstract**: The rapid growth of intelligent connected vehicles (ICVs) and integrated vehicle-road-cloud systems has increased the demand for accurate, real-time HD map updates. However, ensuring map reliability remains challenging due to inconsistencies in crowdsourced data, which suffer from motion blur, lighting variations, adverse weather, and lane marking degradation. This paper introduces CleanMAP, a Multimodal Large Language Model (MLLM)-based distillation framework designed to filter and refine crowdsourced data for high-confidence HD map updates. CleanMAP leverages an MLLM-driven lane visibility scoring model that systematically quantifies key visual parameters, assigning confidence scores (0-10) based on their impact on lane detection. A novel dynamic piecewise confidence-scoring function adapts scores based on lane visibility, ensuring strong alignment with human evaluations while effectively filtering unreliable data. To further optimize map accuracy, a confidence-driven local map fusion strategy ranks and selects the top-k highest-scoring local maps within an optimal confidence range (best score minus 10%), striking a balance between data quality and quantity. Experimental evaluations on a real-world autonomous vehicle dataset validate CleanMAP's effectiveness, demonstrating that fusing the top three local maps achieves the lowest mean map update error of 0.28m, outperforming the baseline (0.37m) and meeting stringent accuracy thresholds (<= 0.32m). Further validation with real-vehicle data confirms 84.88% alignment with human evaluators, reinforcing the model's robustness and reliability. This work establishes CleanMAP as a scalable and deployable solution for crowdsourced HD map updates, ensuring more precise and reliable autonomous navigation. The code will be available at this https URL 

**Abstract (ZH)**: 基于多模态大型语言模型的CleanMAP地图清洁框架：确保高精度的 crowdsourced 高精地图更新 

---
# MARVIS: Motion & Geometry Aware Real and Virtual Image Segmentation 

**Title (ZH)**: MARVIS: 动态与几何感知的现实与虚拟图像分割 

**Authors**: Jiayi Wu, Xiaomin Lin, Shahriar Negahdaripour, Cornelia Fermüller, Yiannis Aloimonos  

**Link**: [PDF](https://arxiv.org/pdf/2403.09850)  

**Abstract**: Tasks such as autonomous navigation, 3D reconstruction, and object recognition near the water surfaces are crucial in marine robotics applications. However, challenges arise due to dynamic disturbances, e.g., light reflections and refraction from the random air-water interface, irregular liquid flow, and similar factors, which can lead to potential failures in perception and navigation systems. Traditional computer vision algorithms struggle to differentiate between real and virtual image regions, significantly complicating tasks. A virtual image region is an apparent representation formed by the redirection of light rays, typically through reflection or refraction, creating the illusion of an object's presence without its actual physical location. This work proposes a novel approach for segmentation on real and virtual image regions, exploiting synthetic images combined with domain-invariant information, a Motion Entropy Kernel, and Epipolar Geometric Consistency. Our segmentation network does not need to be re-trained if the domain changes. We show this by deploying the same segmentation network in two different domains: simulation and the real world. By creating realistic synthetic images that mimic the complexities of the water surface, we provide fine-grained training data for our network (MARVIS) to discern between real and virtual images effectively. By motion & geometry-aware design choices and through comprehensive experimental analysis, we achieve state-of-the-art real-virtual image segmentation performance in unseen real world domain, achieving an IoU over 78% and a F1-Score over 86% while ensuring a small computational footprint. MARVIS offers over 43 FPS (8 FPS) inference rates on a single GPU (CPU core). Our code and dataset are available here this https URL. 

**Abstract (ZH)**: 水表面附近自主导航、三维重建和物体识别任务在水下机器人应用中至关重要。然而，由于动态干扰因素，如随机气-水界面的光反射和折射、不规则液体流动等，感知和导航系统可能失效。传统计算机视觉算法难以区分真实和虚拟图像区域，显著增加了任务难度。虚拟图像区域是光线经过反射或折射重定向后形成的表象，并不真实存在。本文提出了一种结合合成图像、领域不变信息、运动熵核和极线几何一致性的新颖方法，用于真实和虚拟图像区域的分割。我们的分割网络在领域变化时无需重新训练。通过在模拟和真实世界两个不同领域中部署相同的分割网络，我们展示了这一点。通过生成模拟真实水面复杂性的逼真合成图像，为网络（MARVIS）提供精细的训练数据，以有效区分真实和虚拟图像。通过运动与几何感知设计选择和全面的实验分析，在未见的真实世界领域中实现了最先进的真实虚拟图像分割性能，IoU超过78%，F1-Score超过86%，同时保持较小的计算开销。MARVIS在单块GPU（CPU核心）上实现超过43 FPS（8 FPS）的推理速率。我们的代码和数据集可在此处获取：https://。 

---
