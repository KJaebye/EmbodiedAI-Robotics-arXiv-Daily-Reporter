{'arxiv_id': 'arXiv:2504.11419', 'title': 'Embodied World Models Emerge from Navigational Task in Open-Ended Environments', 'authors': 'Li Jin, Liu Jia', 'link': 'https://arxiv.org/abs/2504.11419', 'abstract': "Understanding how artificial systems can develop spatial awareness and reasoning has long been a challenge in AI research. Traditional models often rely on passive observation, but embodied cognition theory suggests that deeper understanding emerges from active interaction with the environment. This study investigates whether neural networks can autonomously internalize spatial concepts through interaction, focusing on planar navigation tasks. Using Gated Recurrent Units (GRUs) combined with Meta-Reinforcement Learning (Meta-RL), we show that agents can learn to encode spatial properties like direction, distance, and obstacle avoidance. We introduce Hybrid Dynamical Systems (HDS) to model the agent-environment interaction as a closed dynamical system, revealing stable limit cycles that correspond to optimal navigation strategies. Ridge Representation allows us to map navigation paths into a fixed-dimensional behavioral space, enabling comparison with neural states. Canonical Correlation Analysis (CCA) confirms strong alignment between these representations, suggesting that the agent's neural states actively encode spatial knowledge. Intervention experiments further show that specific neural dimensions are causally linked to navigation performance. This work provides an approach to bridging the gap between action and perception in AI, offering new insights into building adaptive, interpretable models that can generalize across complex environments. The causal validation of neural representations also opens new avenues for understanding and controlling the internal mechanisms of AI systems, pushing the boundaries of how machines learn and reason in dynamic, real-world scenarios.", 'abstract_zh': '理解人工系统如何发展空间意识和推理一直是人工智能研究中的挑战。传统模型往往依赖于被动观察，但本体认知理论表明，更深层次的理解来自于与环境的积极互动。本研究 investigate 是否可以通过互动使神经网络自主内化空间概念，重点是平面导航任务。通过将门控循环单元（GRUs）与元强化学习（Meta-RL）结合使用，我们表明智能体可以学会编码方向、距离和障碍避让等空间属性。我们引入混合动力系统（HDS）来模型化智能体-环境交互，揭示出与最优导航策略对应的稳定极限环。岭表示法使我们能够将导航路径映射到固定维度的行为空间，从而便于与神经状态进行比较。通过对角相关分析（CCA）证实了这些表示之间的强烈对齐，表明智能体的神经状态主动编码了空间知识。干预实验进一步表明特定的神经维度与导航性能之间存在因果关系。这项工作提供了一种弥合人工智能中动作与感知之间差距的方法，为构建能够跨复杂环境泛化的适应性和可解释性模型提供了新见解。神经表示的因果验证也为理解并控制人工智能系统的内部机制开辟了新途径，推动了机器在动态、实际环境中的学习和推理能力的提升。', 'title_zh': '具身世界模型在开放环境中的导航任务中 Emerge 从导航任务中在开放-ended 环境中'}
{'arxiv_id': 'arXiv:2504.11354', 'title': 'Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning', 'authors': 'Haiming Wang, Mert Unsal, Xiaohan Lin, Mantas Baksys, Junqi Liu, Marco Dos Santos, Flood Sung, Marina Vinyes, Zhenzhe Ying, Zekai Zhu, Jianqiao Lu, Hugues de Saxcé, Bolton Bailey, Chendong Song, Chenjun Xiao, Dehao Zhang, Ebony Zhang, Frederick Pu, Han Zhu, Jiawei Liu, Jonas Bayer, Julien Michel, Longhui Yu, Léo Dreyfus-Schmidt, Lewis Tunstall, Luigi Pagani, Moreira Machado, Pauline Bourigault, Ran Wang, Stanislas Polu, Thibaut Barroyer, Wen-Ding Li, Yazhe Niu, Yann Fleureau, Yangyang Hu, Zhouliang Yu, Zihan Wang, Zhilin Yang, Zhengying Liu, Jia Li', 'link': 'https://arxiv.org/abs/2504.11354', 'abstract': 'We introduce Kimina-Prover Preview, a large language model that pioneers a novel reasoning-driven exploration paradigm for formal theorem proving, as showcased in this preview release. Trained with a large-scale reinforcement learning pipeline from Qwen2.5-72B, Kimina-Prover demonstrates strong performance in Lean 4 proof generation by employing a structured reasoning pattern we term \\textit{formal reasoning pattern}. This approach allows the model to emulate human problem-solving strategies in Lean, iteratively generating and refining proof steps. Kimina-Prover sets a new state-of-the-art on the miniF2F benchmark, reaching 80.7% with pass@8192. Beyond improved benchmark performance, our work yields several key insights: (1) Kimina-Prover exhibits high sample efficiency, delivering strong results even with minimal sampling (pass@1) and scaling effectively with computational budget, stemming from its unique reasoning pattern and RL training; (2) we demonstrate clear performance scaling with model size, a trend previously unobserved for neural theorem provers in formal mathematics; (3) the learned reasoning style, distinct from traditional search algorithms, shows potential to bridge the gap between formal verification and informal mathematical intuition. We open source distilled versions with 1.5B and 7B parameters of Kimina-Prover', 'abstract_zh': 'Kimina-Prover Preview:一种基于新颖推理驱动探索范式的大型语言模型及其在形式定理证明中的应用', 'title_zh': 'Kimina-Prover 预览：基于 reinforcement learning 的大规模形式化推理模型探索'}
{'arxiv_id': 'arXiv:2504.11301', 'title': 'Learning to Be A Doctor: Searching for Effective Medical Agent Architectures', 'authors': 'Yangyang Zhuang, Wenjia Jiang, Jiayu Zhang, Ze Yang, Joey Tianyi Zhou, Chi Zhang', 'link': 'https://arxiv.org/abs/2504.11301', 'abstract': 'Large Language Model (LLM)-based agents have demonstrated strong capabilities across a wide range of tasks, and their application in the medical domain holds particular promise due to the demand for high generalizability and reliance on interdisciplinary knowledge. However, existing medical agent systems often rely on static, manually crafted workflows that lack the flexibility to accommodate diverse diagnostic requirements and adapt to emerging clinical scenarios. Motivated by the success of automated machine learning (AutoML), this paper introduces a novel framework for the automated design of medical agent architectures. Specifically, we define a hierarchical and expressive agent search space that enables dynamic workflow adaptation through structured modifications at the node, structural, and framework levels. Our framework conceptualizes medical agents as graph-based architectures composed of diverse, functional node types and supports iterative self-improvement guided by diagnostic feedback. Experimental results on skin disease diagnosis tasks demonstrate that the proposed method effectively evolves workflow structures and significantly enhances diagnostic accuracy over time. This work represents the first fully automated framework for medical agent architecture design and offers a scalable, adaptable foundation for deploying intelligent agents in real-world clinical environments.', 'abstract_zh': '基于大规模语言模型（LLM）的医疗智能体自动生成框架：一种通过自动化设计适应多变临床情景的医疗智能化架构', 'title_zh': '学习成为一名医生：搜索有效的医疗智能体架构'}
{'arxiv_id': 'arXiv:2504.11243', 'title': 'Towards Automated Safety Requirements Derivation Using Agent-based RAG', 'authors': 'Balahari Vignesh Balu, Florian Geissler, Francesco Carella, Joao-Vitor Zacchi, Josef Jiru, Nuria Mata, Reinhard Stolle', 'link': 'https://arxiv.org/abs/2504.11243', 'abstract': 'We study the automated derivation of safety requirements in a self-driving vehicle use case, leveraging LLMs in combination with agent-based retrieval-augmented generation. Conventional approaches that utilise pre-trained LLMs to assist in safety analyses typically lack domain-specific knowledge. Existing RAG approaches address this issue, yet their performance deteriorates when handling complex queries and it becomes increasingly harder to retrieve the most relevant information. This is particularly relevant for safety-relevant applications. In this paper, we propose the use of agent-based RAG to derive safety requirements and show that the retrieved information is more relevant to the queries. We implement an agent-based approach on a document pool of automotive standards and the Apollo case study, as a representative example of an automated driving perception system. Our solution is tested on a data set of safety requirement questions and answers, extracted from the Apollo data. Evaluating a set of selected RAG metrics, we present and discuss advantages of a agent-based approach compared to default RAG methods.', 'abstract_zh': '我们研究了一种结合基于代理的检索增强生成的自驾驶车辆应用场景中自动化获取安全要求的方法。现有的利用预训练语言模型进行安全分析的传统方法通常缺乏领域特定知识。现有的基于检索增强生成的方法能够解决这一问题，但在处理复杂查询时其性能会下降，越来越难以检索到最相关的信息。这对于安全相关应用尤为重要。在本文中，我们提出使用基于代理的检索增强生成来推导安全要求，并展示了检索到的信息与查询的相关性更强。我们基于汽车标准文档库和Apollo案例研究（作为自动化驾驶感知系统的代表例子）实现了一个基于代理的方案，并在Apollo数据中提取的安全要求问题和答案数据集上进行了测试。通过对一组选定的检索增强生成指标进行评估，我们呈现并讨论了基于代理的方法相较于默认检索增强生成方法的优势。', 'title_zh': '基于基于代理的RAG的自动化安全性需求导出研究'}
{'arxiv_id': 'arXiv:2504.11239', 'title': 'Nondeterministic Polynomial-time Problem Challenge: An Ever-Scaling Reasoning Benchmark for LLMs', 'authors': 'Chang Yang, Ruiyu Wang, Junzhe Jiang, Qi Jiang, Qinggang Zhang, Yanchen Deng, Shuxin Li, Shuyue Hu, Bo Li, Florian T. Pokorny, Xiao Huang, Xinrun Wang', 'link': 'https://arxiv.org/abs/2504.11239', 'abstract': "Reasoning is the fundamental capability of large language models (LLMs). Due to the rapid progress of LLMs, there are two main issues of current benchmarks: i) these benchmarks can be crushed in a short time (less than 1 year), and ii) these benchmarks may be easily hacked. To handle these issues, we propose the ever-scalingness for building the benchmarks which are uncrushable, unhackable, auto-verifiable and general. This paper presents Nondeterministic Polynomial-time Problem Challenge (NPPC), an ever-scaling reasoning benchmark for LLMs. Specifically, the NPPC has three main modules: i) npgym, which provides a unified interface of 25 well-known NP-complete problems and can generate any number of instances with any levels of complexities, ii) npsolver: which provides a unified interface to evaluate the problem instances with both online and offline models via APIs and local deployments, respectively, and iii) npeval: which provides the comprehensive and ready-to-use tools to analyze the performances of LLMs over different problems, the number of tokens, the aha moments, the reasoning errors and the solution errors. Extensive experiments over widely-used LLMs demonstrate: i) NPPC can successfully decrease the performances of advanced LLMs' performances to below 10%, demonstrating that NPPC is uncrushable, ii) DeepSeek-R1, Claude-3.7-Sonnet, and o1/o3-mini are the most powerful LLMs, where DeepSeek-R1 outperforms Claude-3.7-Sonnet and o1/o3-mini in most NP-complete problems considered, and iii) the numbers of tokens, aha moments in the advanced LLMs, e.g., Claude-3.7-Sonnet and DeepSeek-R1, are observed first to increase and then decrease when the problem instances become more and more difficult. We believe that NPPC is the first ever-scaling reasoning benchmark, serving as the uncrushable and unhackable testbed for LLMs toward artificial general intelligence (AGI).", 'abstract_zh': '非确定多项式时间问题挑战：面向大语言模型的不可粉碎、不可 hack、自动可验证且通用的归因基准', 'title_zh': '非确定多项式时间问题挑战：面向LLMs的不断扩展的推理基准'}
{'arxiv_id': 'arXiv:2504.11200', 'title': 'Mutual Understanding between People and Systems via Neurosymbolic AI and Knowledge Graphs', 'authors': 'Irene Celino, Mario Scrocca, Agnese Chiatti', 'link': 'https://arxiv.org/abs/2504.11200', 'abstract': 'This chapter investigates the concept of mutual understanding between humans and systems, positing that Neuro-symbolic Artificial Intelligence (NeSy AI) methods can significantly enhance this mutual understanding by leveraging explicit symbolic knowledge representations with data-driven learning models. We start by introducing three critical dimensions to characterize mutual understanding: sharing knowledge, exchanging knowledge, and governing knowledge. Sharing knowledge involves aligning the conceptual models of different agents to enable a shared understanding of the domain of interest. Exchanging knowledge relates to ensuring the effective and accurate communication between agents. Governing knowledge concerns establishing rules and processes to regulate the interaction between agents. Then, we present several different use case scenarios that demonstrate the application of NeSy AI and Knowledge Graphs to aid meaningful exchanges between human, artificial, and robotic agents. These scenarios highlight both the potential and the challenges of combining top-down symbolic reasoning with bottom-up neural learning, guiding the discussion of the coverage provided by current solutions along the dimensions of sharing, exchanging, and governing knowledge. Concurrently, this analysis facilitates the identification of gaps and less developed aspects in mutual understanding to address in future research.', 'abstract_zh': '本章探讨了人类与系统之间相互理解的概念，并提出神经符号人工智能（NeSy AI）方法可以通过结合显式符号知识表示与数据驱动的学习模型，显著增强这种相互理解。我们首先介绍三个关键维度来刻画相互理解：共享知识、交换知识和治理知识。共享知识涉及对齐不同代理的conceptual模型，以实现对感兴趣领域的共同理解。交换知识涉及确保代理之间有效的准确通信。治理知识涉及建立规则和流程，以调节代理之间的交互。然后，我们展示了NeSy AI和知识图谱在促进人类、人工和机器人代理之间有意义的交流中的应用实例。这些场景突显了自上而下的符号推理与自下而上的神经学习结合的潜力和挑战，并指导了沿共享、交换和治理知识维度的当前解决方案的讨论。同时，这种分析也有助于识别相互理解中的空白和未充分开发的方面，为未来研究提供方向。', 'title_zh': '人与系统之间的神经符号AI与知识图谱相互理解'}
{'arxiv_id': 'arXiv:2504.11190', 'title': 'Enhancing multimodal analogical reasoning with Logic Augmented Generation', 'authors': 'Anna Sofia Lippolis, Andrea Giovanni Nuzzolese, Aldo Gangemi', 'link': 'https://arxiv.org/abs/2504.11190', 'abstract': 'Recent advances in Large Language Models have demonstrated their capabilities across a variety of tasks. However, automatically extracting implicit knowledge from natural language remains a significant challenge, as machines lack active experience with the physical world. Given this scenario, semantic knowledge graphs can serve as conceptual spaces that guide the automated text generation reasoning process to achieve more efficient and explainable results. In this paper, we apply a logic-augmented generation (LAG) framework that leverages the explicit representation of a text through a semantic knowledge graph and applies it in combination with prompt heuristics to elicit implicit analogical connections. This method generates extended knowledge graph triples representing implicit meaning, enabling systems to reason on unlabeled multimodal data regardless of the domain. We validate our work through three metaphor detection and understanding tasks across four datasets, as they require deep analogical reasoning capabilities. The results show that this integrated approach surpasses current baselines, performs better than humans in understanding visual metaphors, and enables more explainable reasoning processes, though still has inherent limitations in metaphor understanding, especially for domain-specific metaphors. Furthermore, we propose a thorough error analysis, discussing issues with metaphorical annotations and current evaluation methods.', 'abstract_zh': '近期大型语言模型的进展展示了其在各种任务中的能力。然而，自动从自然语言中提取隐性知识仍然是一个重要的挑战，因为机器缺乏对物理世界的主动经验。在这种情况下，语义知识图可以作为概念空间，指导自动文本生成的推理过程，以实现更高效和可解释的结果。在本文中，我们应用了一种逻辑增强生成（LAG）框架，该框架通过语义知识图的显式表示来增强文本，并结合提示启发式方法来引发隐性的类比连接。该方法生成表示隐含意义的扩展知识图三元组，使系统能够对未标记的多模态数据进行推理，而不论其领域如何。我们通过三个隐喻检测和理解任务在四个数据集中验证了我们的工作，这些任务需要深入的类比推理能力。结果表明，这种集成方法超越了当前基线，优于人类在理解视觉隐喻方面的表现，并允许更可解释的推理过程，尽管在隐喻理解方面仍然存在固有的局限性，特别是在领域特定隐喻方面。此外，我们提出了一种彻底的错误分析，讨论了隐喻注释和当前评估方法的问题。', 'title_zh': '增强多模态类比推理的逻辑增强生成方法'}
{'arxiv_id': 'arXiv:2504.11159', 'title': 'C-SHAP for time series: An approach to high-level temporal explanations', 'authors': 'Annemarie Jutte, Faizan Ahmed, Jeroen Linssen, Maurice van Keulen', 'link': 'https://arxiv.org/abs/2504.11159', 'abstract': 'Time series are ubiquitous in domains such as energy forecasting, healthcare, and industry. Using AI systems, some tasks within these domains can be efficiently handled. Explainable AI (XAI) aims to increase the reliability of AI solutions by explaining model reasoning. For time series, many XAI methods provide point- or sequence-based attribution maps. These methods explain model reasoning in terms of low-level patterns. However, they do not capture high-level patterns that may also influence model reasoning. We propose a concept-based method to provide explanations in terms of these high-level patterns. In this paper, we present C-SHAP for time series, an approach which determines the contribution of concepts to a model outcome. We provide a general definition of C-SHAP and present an example implementation using time series decomposition. Additionally, we demonstrate the effectiveness of the methodology through a use case from the energy domain.', 'abstract_zh': '时间序列在能源预测、医疗健康和工业等领域广泛存在。通过AI系统，这些领域的某些任务可以得到有效处理。可解释AI（XAI）旨在通过解释模型推理来提高AI解决方案的可靠性。对于时间序列，许多XAI方法提供基于点或序列的归因图，这些方法从低级模式的角度解释模型推理，但没有捕捉到可能也影响模型推理的高级模式。我们提出了一种基于概念的方法，以这些高级模式来提供解释。在本文中，我们介绍了时间序列的C-SHAP方法，该方法确定概念对模型结果的贡献。我们提供了C-SHAP的通用定义，并通过时间序列分解示例展示了其实现方式。此外，我们通过能源领域的案例研究展示了该方法的有效性。', 'title_zh': 'C-SHAP for 时间序列：一种高层次时间解释的方法'}
{'arxiv_id': 'arXiv:2504.11075', 'title': 'Emergence of Goal-Directed Behaviors via Active Inference with Self-Prior', 'authors': 'Dongmin Kim, Hoshinori Kanazawa, Naoto Yoshida, Yasuo Kuniyoshi', 'link': 'https://arxiv.org/abs/2504.11075', 'abstract': 'Infants often exhibit goal-directed behaviors, such as reaching for a sensory stimulus, even when no external reward criterion is provided. These intrinsically motivated behaviors facilitate spontaneous exploration and learning of the body and environment during early developmental stages. Although computational modeling can offer insight into the mechanisms underlying such behaviors, many existing studies on intrinsic motivation focus primarily on how exploration contributes to acquiring external rewards. In this paper, we propose a novel density model for an agent\'s own multimodal sensory experiences, called the "self-prior," and investigate whether it can autonomously induce goal-directed behavior. Integrated within an active inference framework based on the free energy principle, the self-prior generates behavioral references purely from an intrinsic process that minimizes mismatches between average past sensory experiences and current observations. This mechanism is also analogous to the acquisition and utilization of a body schema through continuous interaction with the environment. We examine this approach in a simulated environment and confirm that the agent spontaneously reaches toward a tactile stimulus. Our study implements intrinsically motivated behavior shaped by the agent\'s own sensory experiences, demonstrating the spontaneous emergence of intentional behavior during early development.', 'abstract_zh': '婴儿经常表现出目标导向的行为，即使没有提供外部奖励标准，也会伸手去抓感觉刺激。这些内驱动行為促进了婴儿在早期发展阶段对身体和环境的自发探索和学习。尽管计算建模可以揭示这些行为背后的机制，但许多关于内驱动的研究主要关注探索如何有助于获得外部奖励。在本文中，我们提出了一种基于代理自身多种感官体验的新密度模型，称为“自我先验”，并探讨它是否可以自主诱导目标导向行为。该模型整合在基于自由能原则的主动推理框架之内，从一个内在过程中生成行为参考，该过程旨在最小化平均过去感官体验与当前观察之间的差异匹配。这种机制类似于通过与环境的持续互动获得和利用身体图示的过程。我们在模拟环境中对这种方法进行了测试，并确认代理自发地向触觉刺激伸展。我们的研究实现了由代理自身感官经验塑造的内驱动行为，展示了在早期发展阶段自发产生有意图行为的出现。', 'title_zh': '基于自我先验的主动推断中目标导向行为的涌现'}
{'arxiv_id': 'arXiv:2504.10893', 'title': 'ARise: Towards Knowledge-Augmented Reasoning via Risk-Adaptive Search', 'authors': 'Yize Zhang, Tianshu Wang, Sirui Chen, Kun Wang, Xingyu Zeng, Hongyu Lin, Xianpei Han, Le Sun, Chaochao Lu', 'link': 'https://arxiv.org/abs/2504.10893', 'abstract': 'Large language models (LLMs) have demonstrated impressive capabilities and are receiving increasing attention to enhance their reasoning through scaling test--time compute. However, their application in open--ended, knowledge--intensive, complex reasoning scenarios is still limited. Reasoning--oriented methods struggle to generalize to open--ended scenarios due to implicit assumptions of complete world knowledge. Meanwhile, knowledge--augmented reasoning (KAR) methods fail to address two core challenges: 1) error propagation, where errors in early steps cascade through the chain, and 2) verification bottleneck, where the explore--exploit tradeoff arises in multi--branch decision processes. To overcome these limitations, we introduce ARise, a novel framework that integrates risk assessment of intermediate reasoning states with dynamic retrieval--augmented generation (RAG) within a Monte Carlo tree search paradigm. This approach enables effective construction and optimization of reasoning plans across multiple maintained hypothesis branches. Experimental results show that ARise significantly outperforms the state--of--the--art KAR methods by up to 23.10%, and the latest RAG-equipped large reasoning models by up to 25.37%.', 'abstract_zh': '大型语言模型（LLMs）展示出了令人印象深刻的能力，并通过扩展测试时计算来不断提高其推理能力，但它们在开放性、知识密集型和复杂推理场景中的应用仍然有限。面向推理的方法由于隐含了完整的世界知识假设，难以推广到开放性场景中。同时，知识增强的推理（KAR）方法未能解决两个核心挑战：1）错误传播，即早期步骤中的错误会通过推理链条传递；2）验证瓶颈，在多分支决策过程中会引发探索-利用权衡。为克服这些限制，我们引入了ARise，一种新的框架，该框架将风险评估与动态检索增强生成（RAG）结合在蒙特卡洛树搜索框架内。该方法能够在多个保持假设分支中有效构建和优化推理计划。实验结果表明，ARise在最高可达到23.10%的性能上优于最新的KAR方法，并且在最新的配备RAG的大规模推理模型上可提升高达25.37%。', 'title_zh': 'ARise: 向基于风险适应性搜索的知识增强推理研究'}
{'arxiv_id': 'arXiv:2504.10865', 'title': 'Understanding the theoretical properties of projected Bellman equation, linear Q-learning, and approximate value iteration', 'authors': 'Han-Dong Lim, Donghwan Lee', 'link': 'https://arxiv.org/abs/2504.10865', 'abstract': 'In this paper, we study the theoretical properties of the projected Bellman equation (PBE) and two algorithms to solve this equation: linear Q-learning and approximate value iteration (AVI). We consider two sufficient conditions for the existence of a solution to PBE : strictly negatively row dominating diagonal (SNRDD) assumption and a condition motivated by the convergence of AVI. The SNRDD assumption also ensures the convergence of linear Q-learning, and its relationship with the convergence of AVI is examined. Lastly, several interesting observations on the solution of PBE are provided when using $\\epsilon$-greedy policy.', 'abstract_zh': '在本文中，我们研究了投影贝尔曼方程（PBE）的理论性质以及解决该方程的两种算法：线性Q学习和近似值迭代（AVI）。我们考虑了PBE解存在的两个充分条件：严格负行支配对角（SNRDD）假设以及一种受AVI收敛性启发的条件。SNRDD假设还保证了线性Q学习的收敛性，并探讨了其与AVI收敛性之间的关系。最后，我们提供了在使用$\\epsilon$-贪婪策略时PBE解的一些有趣观察。', 'title_zh': '理解投影贝尔曼方程、线性Q学习和近似值迭代的理论性质'}
{'arxiv_id': 'arXiv:2504.10831', 'title': 'Hallucination-Aware Generative Pretrained Transformer for Cooperative Aerial Mobility Control', 'authors': 'Hyojun Ahn, Seungcheol Oh, Gyu Seon Kim, Soyi Jung, Soohyun Park, Joongheon Kim', 'link': 'https://arxiv.org/abs/2504.10831', 'abstract': 'This paper proposes SafeGPT, a two-tiered framework that integrates generative pretrained transformers (GPTs) with reinforcement learning (RL) for efficient and reliable unmanned aerial vehicle (UAV) last-mile deliveries. In the proposed design, a Global GPT module assigns high-level tasks such as sector allocation, while an On-Device GPT manages real-time local route planning. An RL-based safety filter monitors each GPT decision and overrides unsafe actions that could lead to battery depletion or duplicate visits, effectively mitigating hallucinations. Furthermore, a dual replay buffer mechanism helps both the GPT modules and the RL agent refine their strategies over time. Simulation results demonstrate that SafeGPT achieves higher delivery success rates compared to a GPT-only baseline, while substantially reducing battery consumption and travel distance. These findings validate the efficacy of combining GPT-based semantic reasoning with formal safety guarantees, contributing a viable solution for robust and energy-efficient UAV logistics.', 'abstract_zh': 'SafeGPT：结合强化学习的两层框架以实现高效可靠的无人驾驶航空车辆最后一公里交付', 'title_zh': '面向幻觉的生成预训练变换器在协同空中移动控制中应用'}
{'arxiv_id': 'arXiv:2504.10649', 'title': 'Ride-pool Assignment Algorithms: Modern Implementation and Swapping Heuristics', 'authors': 'Matthew Zalesak, Hins Hu, Samitha Samaranayake', 'link': 'https://arxiv.org/abs/2504.10649', 'abstract': "On-demand ride-pooling has emerged as a popular urban transportation solution, addressing the efficiency limitations of traditional ride-hailing services by grouping multiple riding requests with spatiotemporal proximity into a single vehicle. Although numerous algorithms have been developed for the Ride-pool Assignment Problem (RAP) -- a core component of ride-pooling systems, there is a lack of open-source implementations, making it difficult to benchmark these algorithms on a common dataset and objective. In this paper, we present the implementation details of a ride-pool simulator that encompasses several key ride-pool assignment algorithms, along with associated components such as vehicle routing and rebalancing. We also open-source a highly optimized and modular C++ codebase, designed to facilitate the extension of new algorithms and features. Additionally, we introduce a family of swapping-based local-search heuristics to enhance existing ride-pool assignment algorithms, achieving a better balance between performance and computational efficiency. Extensive experiments on a large-scale, real-world dataset from Manhattan, NYC reveal that while all selected algorithms perform comparably, the newly proposed Multi-Round Linear Assignment with Cyclic Exchange (LA-MR-CE) algorithm achieves a state-of-the-art service rate with significantly reduced computational time. Furthermore, an in-depth analysis suggests that a performance barrier exists for all myopic ride-pool assignment algorithms due to the system's capacity bottleneck, and incorporating future information could be key to overcoming this limitation.", 'abstract_zh': '按需拼车已成为一种流行的都市交通解决方案，通过将具有时空临近性的多个乘车请求分组到同一辆车中，解决了传统拼车服务的效率限制。尽管已开发出多种用于乘车拼组分配问题（RAP）的算法——这是拼车系统的核心组成部分之一，但缺乏开源实现，使得在共同的数据集和目标上对这些算法进行基准测试变得困难。本文介绍了包含多种关键乘车拼组分配算法及相关组件（如车辆路由和再平衡）的乘车拼组模拟器的实现细节。我们还开源了一个高度优化且模块化的C++代码库，旨在方便新算法和功能的扩展。此外，我们引入了一类基于交换的局部搜索启发式算法，以增强现有的乘车拼组分配算法，实现性能和计算效率之间的更好平衡。大规模现实世界数据集（来自纽约市曼哈顿区）的实验结果显示，虽然所有选定的算法表现相当，但新提出的多轮线性分配伴有循环交换（LA-MR-CE）算法在显著减少计算时间的同时实现了最先进的服务率。进一步的分析表明，由于系统容量瓶颈，所有短视的乘车拼组分配算法都存在性能障碍，而引入未来信息可能是克服这一限制的关键。', 'title_zh': '拼车分配算法：现代实现与置换 heuristic 研究'}
{'arxiv_id': 'arXiv:2504.10527', 'title': 'Explainable Artificial Intelligence techniques for interpretation of food datasets: a review', 'authors': 'Leonardo Arrighi, Ingrid Alves de Moraes, Marco Zullich, Michele Simonato, Douglas Fernandes Barbin, Sylvio Barbon Junior', 'link': 'https://arxiv.org/abs/2504.10527', 'abstract': 'Artificial Intelligence (AI) has become essential for analyzing complex data and solving highly-challenging tasks. It is being applied across numerous disciplines beyond computer science, including Food Engineering, where there is a growing demand for accurate and trustworthy predictions to meet stringent food quality standards. However, this requires increasingly complex AI models, raising reliability concerns. In response, eXplainable AI (XAI) has emerged to provide insights into AI decision-making, aiding model interpretation by developers and users. Nevertheless, XAI remains underutilized in Food Engineering, limiting model reliability. For instance, in food quality control, AI models using spectral imaging can detect contaminants or assess freshness levels, but their opaque decision-making process hinders adoption. XAI techniques such as SHAP (Shapley Additive Explanations) and Grad-CAM (Gradient-weighted Class Activation Mapping) can pinpoint which spectral wavelengths or image regions contribute most to a prediction, enhancing transparency and aiding quality control inspectors in verifying AI-generated assessments. This survey presents a taxonomy for classifying food quality research using XAI techniques, organized by data types and explanation methods, to guide researchers in choosing suitable approaches. We also highlight trends, challenges, and opportunities to encourage the adoption of XAI in Food Engineering.', 'abstract_zh': '人工智能（AI）已成为分析复杂数据和解决高度挑战性任务的重要工具。它已跨计算机科学以外的多个学科得到应用，包括食品工程，该领域对准确和可信赖的预测需求越来越大，以满足严格的食物质量标准。然而，这要求使用越来越复杂的AI模型，从而引发可靠性方面的担忧。为此，可解释人工智能（XAI）已经出现，以提供对AI决策的洞察，帮助开发者和用户理解和解释模型。尽管如此，XAI在食品工程中的应用仍然不足，限制了模型的可靠性。例如，在食品质量控制中，使用光谱成像的AI模型可以检测污染物或评估新鲜度水平，但它们不透明的决策过程阻碍了其应用。可解释AI技术，如SHAP（Shapley值分解）和Grad-CAM（梯度加权类激活映射），可以识别出对预测贡献最大的光谱波长或图像区域，提高透明度，并帮助质量控制检查员验证AI生成的评估结果。本文综述了使用XAI技术分类食品质量研究的分类体系，按数据类型和解释方法组织，以指导研究人员选择合适的方法。我们还指出了趋势、挑战和机遇，以促进XAI在食品工程中的应用。', 'title_zh': '可解释的人工智能技术在食品数据集解释中的应用：一个综述'}
{'arxiv_id': 'arXiv:2504.10519', 'title': 'Toward Super Agent System with Hybrid AI Routers', 'authors': 'Yuhang Yao, Haixin Wang, Yibo Chen, Jiawen Wang, Min Chang Jordan Ren, Bosheng Ding, Salman Avestimehr, Chaoyang He', 'link': 'https://arxiv.org/abs/2504.10519', 'abstract': 'AI Agents powered by Large Language Models are transforming the world through enormous applications. A super agent has the potential to fulfill diverse user needs, such as summarization, coding, and research, by accurately understanding user intent and leveraging the appropriate tools to solve tasks. However, to make such an agent viable for real-world deployment and accessible at scale, significant optimizations are required to ensure high efficiency and low cost. This paper presents a design of the Super Agent System. Upon receiving a user prompt, the system first detects the intent of the user, then routes the request to specialized task agents with the necessary tools or automatically generates agentic workflows. In practice, most applications directly serve as AI assistants on edge devices such as phones and robots. As different language models vary in capability and cloud-based models often entail high computational costs, latency, and privacy concerns, we then explore the hybrid mode where the router dynamically selects between local and cloud models based on task complexity. Finally, we introduce the blueprint of an on-device super agent enhanced with cloud. With advances in multi-modality models and edge hardware, we envision that most computations can be handled locally, with cloud collaboration only as needed. Such architecture paves the way for super agents to be seamlessly integrated into everyday life in the near future.', 'abstract_zh': '基于大型语言模型的AI代理正在通过众多应用改变世界。超级代理有能力通过准确理解用户意图并利用适当的工具来满足多样化的用户需求，如总结、编程和研究。然而，为了使这样的代理能够在现实世界中部署并大规模使用，需要进行重大优化以确保高效率和低成本。本文介绍了超级代理系统的架构设计。系统接收到用户提示后，首先检测用户的意图，然后将请求路由到具有必要工具的专业任务代理，或者自动生成代理工作流。实践中，大多数应用直接作为边缘设备上的AI助手运行，如手机和机器人。鉴于不同语言模型的能力差异以及基于云的模型通常带来的高计算成本、延迟和隐私问题，我们探索了混合模式，即路由器根据任务复杂度动态选择本地或云模型。最后，我们介绍了兼具云端功能的边缘超级代理蓝图。随着多模态模型和边缘硬件的进步，我们设想大多数计算可以本地处理，必要时才进行云协作。这样的架构为超级代理在未来无缝融入日常生活铺平了道路。', 'title_zh': '具有混合AI交换机的超 agent 系统研究'}
{'arxiv_id': 'arXiv:2504.11456', 'title': 'DeepMath-103K: A Large-Scale, Challenging, Decontaminated, and Verifiable Mathematical Dataset for Advancing Reasoning', 'authors': 'Zhiwei He, Tian Liang, Jiahao Xu, Qiuzhi Liu, Xingyu Chen, Yue Wang, Linfeng Song, Dian Yu, Zhenwen Liang, Wenxuan Wang, Zhuosheng Zhang, Rui Wang, Zhaopeng Tu, Haitao Mi, Dong Yu', 'link': 'https://arxiv.org/abs/2504.11456', 'abstract': 'The capacity for complex mathematical reasoning is a key benchmark for artificial intelligence. While reinforcement learning (RL) applied to LLMs shows promise, progress is significantly hindered by the lack of large-scale training data that is sufficiently challenging, possesses verifiable answer formats suitable for RL, and is free from contamination with evaluation benchmarks. To address these limitations, we introduce DeepMath-103K, a new, large-scale dataset comprising approximately 103K mathematical problems, specifically designed to train advanced reasoning models via RL. DeepMath-103K is curated through a rigorous pipeline involving source analysis, stringent decontamination against numerous benchmarks, and filtering for high difficulty (primarily Levels 5-9), significantly exceeding existing open resources in challenge. Each problem includes a verifiable final answer, enabling rule-based RL, and three distinct R1-generated solutions suitable for diverse training paradigms like supervised fine-tuning or distillation. Spanning a wide range of mathematical topics, DeepMath-103K promotes the development of generalizable reasoning. We demonstrate that models trained on DeepMath-103K achieve significant improvements on challenging mathematical benchmarks, validating its effectiveness. We release DeepMath-103K publicly to facilitate community progress in building more capable AI reasoning systems: this https URL.', 'abstract_zh': '复杂数学推理能力是人工智能的重要基准。虽然将强化学习（RL）应用于大型语言模型（LLMs）显示出了前景，但由于缺乏足够具有挑战性、具备可验证答案格式且未被评估基准污染的大规模训练数据，进展受到了显著阻碍。为解决这些限制，我们引入了DeepMath-103K，这是一个新的大规模数据集，包含约103,000个数学问题，专门设计用于通过RL训练高级推理模型。DeepMath-103K通过包含源分析、严格的多基准去污染以及高水平难度（主要为5-9级）的过滤，形成了一套严格的数据管道，远超现有公开资源的挑战性。每个问题都包含可验证的最终答案，支持基于规则的RL，以及适用于监督微调或蒸馏等不同训练范式的三个不同的R1生成解决方案。涵盖广泛的数学主题，DeepMath-103K促进了可泛化的推理能力的发展。实验结果显示，基于DeepMath-103K训练的模型在具有挑战性的数学基准测试中取得了显著改进，验证了其有效性。我们将DeepMath-103K公开发布，以促进社区在构建更强大的AI推理系统方面的进展：this https URL。', 'title_zh': 'DeepMath-103K：一个大规模、具有挑战性、去噪且可验证的数学数据集，用于推进推理能力'}
{'arxiv_id': 'arXiv:2504.11454', 'title': 'Elucidating the Design Space of Multimodal Protein Language Models', 'authors': 'Cheng-Yen, Hsieh, Xinyou Wang, Daiheng Zhang, Dongyu Xue, Fei Ye, Shujian Huang, Zaixiang Zheng, Quanquan Gu', 'link': 'https://arxiv.org/abs/2504.11454', 'abstract': 'Multimodal protein language models (PLMs) integrate sequence and token-based structural information, serving as a powerful foundation for protein modeling, generation, and design. However, the reliance on tokenizing 3D structures into discrete tokens causes substantial loss of fidelity about fine-grained structural details and correlations. In this paper, we systematically elucidate the design space of multimodal PLMs to overcome their limitations. We identify tokenization loss and inaccurate structure token predictions by the PLMs as major bottlenecks. To address these, our proposed design space covers improved generative modeling, structure-aware architectures and representation learning, and data exploration. Our advancements approach finer-grained supervision, demonstrating that token-based multimodal PLMs can achieve robust structural modeling. The effective design methods dramatically improve the structure generation diversity, and notably, folding abilities of our 650M model by reducing the RMSD from 5.52 to 2.36 on PDB testset, even outperforming 3B baselines and on par with the specialized folding models.', 'abstract_zh': '多模态蛋白质语言模型的设计空间：克服限制实现精细结构建模', 'title_zh': '阐述多模态蛋白质语言模型的设计空间'}
{'arxiv_id': 'arXiv:2504.11453', 'title': 'A Clean Slate for Offline Reinforcement Learning', 'authors': 'Matthew Thomas Jackson, Uljad Berdica, Jarek Liesen, Shimon Whiteson, Jakob Nicolaus Foerster', 'link': 'https://arxiv.org/abs/2504.11453', 'abstract': 'Progress in offline reinforcement learning (RL) has been impeded by ambiguous problem definitions and entangled algorithmic designs, resulting in inconsistent implementations, insufficient ablations, and unfair evaluations. Although offline RL explicitly avoids environment interaction, prior methods frequently employ extensive, undocumented online evaluation for hyperparameter tuning, complicating method comparisons. Moreover, existing reference implementations differ significantly in boilerplate code, obscuring their core algorithmic contributions. We address these challenges by first introducing a rigorous taxonomy and a transparent evaluation protocol that explicitly quantifies online tuning budgets. To resolve opaque algorithmic design, we provide clean, minimalistic, single-file implementations of various model-free and model-based offline RL methods, significantly enhancing clarity and achieving substantial speed-ups. Leveraging these streamlined implementations, we propose Unifloral, a unified algorithm that encapsulates diverse prior approaches within a single, comprehensive hyperparameter space, enabling algorithm development in a shared hyperparameter space. Using Unifloral with our rigorous evaluation protocol, we develop two novel algorithms - TD3-AWR (model-free) and MoBRAC (model-based) - which substantially outperform established baselines. Our implementation is publicly available at this https URL.', 'abstract_zh': 'Offline Reinforcement Learning 进展受困于模糊的问题定义和纠缠的算法设计，导致实现不一致、消融实验不足和评估不公平。尽管 Offline RL 明确避免环境交互，先前的方法通常频繁使用广泛的、未文档化的在线调优评估，使得方法比较复杂。此外，现有的参考实现之间在样板代码方面差异显著，掩盖了其核心算法贡献。我们通过首先引入严格的分类学和透明的评估协议来解决这些挑战，该协议明确量化了在线调优预算。为了解决不透明的算法设计，我们提供了各种模型自由和模型依赖的 Offline RL 方法的简洁、简约、单文件实现，显著增强了清晰度并实现了显著的加速。利用这些精简的实现，我们提出了 Unifloral，一种统一算法，将多种先前的方法封装在一个全面的超参数空间内，使算法开发可以在共享的超参数空间中进行。使用我们的严格评估协议以及 Unifloral，我们开发了两个新的算法——TD3-AWR（模型自由）和 MoBRAC（模型依赖），它们显著优于现有的基准算法。我们的实现已公开，网址为：这个 https URL。', 'title_zh': '离线强化学习的全新起点'}
{'arxiv_id': 'arXiv:2504.11442', 'title': 'TextArena', 'authors': 'Leon Guertler, Bobby Cheng, Simon Yu, Bo Liu, Leshem Choshen, Cheston Tan', 'link': 'https://arxiv.org/abs/2504.11442', 'abstract': 'TextArena is an open-source collection of competitive text-based games for training and evaluation of agentic behavior in Large Language Models (LLMs). It spans 57+ unique environments (including single-player, two-player, and multi-player setups) and allows for easy evaluation of model capabilities via an online-play system (against humans and other submitted models) with real-time TrueSkill scores. Traditional benchmarks rarely assess dynamic social skills such as negotiation, theory of mind, and deception, creating a gap that TextArena addresses. Designed with research, community and extensibility in mind, TextArena emphasizes ease of adding new games, adapting the framework, testing models, playing against the models, and training models. Detailed documentation of environments, games, leaderboard, and examples are available on this https URL and this https URL.', 'abstract_zh': 'TextArena是一个用于大规模语言模型（LLMs）agency行为训练和评估的开源竞争性文本游戏集合', 'title_zh': '文本竞技场'}
{'arxiv_id': 'arXiv:2504.11440', 'title': 'Greedy Restart Schedules: A Baseline for Dynamic Algorithm Selection on Numerical Black-box Optimization Problems', 'authors': 'Lennart Schäpermeier', 'link': 'https://arxiv.org/abs/2504.11440', 'abstract': 'In many optimization domains, there are multiple different solvers that contribute to the overall state-of-the-art, each performing better on some, and worse on other types of problem instances. Meta-algorithmic approaches, such as instance-based algorithm selection, configuration and scheduling, aim to close this gap by extracting the most performance possible from a set of (configurable) optimizers. In this context, the best performing individual algorithms are often hand-crafted hybrid heuristics which perform many restarts of fast local optimization approaches. However, data-driven techniques to create optimized restart schedules have not yet been extensively studied.\nHere, we present a simple scheduling approach that iteratively selects the algorithm performing best on the distribution of unsolved training problems at time of selection, resulting in a problem-independent solver schedule. We demonstrate our approach using well-known optimizers from numerical black-box optimization on the BBOB testbed, bridging much of the gap between single and virtual best solver from the original portfolio across various evaluation protocols. Our greedy restart schedule presents a powerful baseline for more complex dynamic algorithm selection models.', 'abstract_zh': '在多个优化领域中，存在多种不同的求解器，各自在不同类型的优化问题上表现出色或较差。元算法方法，如基于实例的算法选择、配置和调度，旨在通过从一组（可配置的）优化器中提取最佳性能来缩小这一差距。在此背景下，表现最好的单独算法通常是手工构建的混合启发式算法，这些算法在快速局部优化方法的基础上进行多次重启。然而，利用数据驱动技术创建优化重启计划的时间表尚未被广泛研究。在这里，我们提出了一种简单的时间表方法，该方法在选择时间点上迭代选择在未解决的训练问题分布上表现最佳的算法，从而生成一个与问题无关的求解器时间序列。我们使用数值黑盒优化中的知名优化器在BBOB测试台上展示了该方法，该方法在各种评估协议下极大地缩小了单一最优求解器与虚拟最优求解器之间的时间隔。我们的贪婪重启计划为更复杂的动态算法选择模型提供了强大的基线。', 'title_zh': '贪婪重启调度：数值黑箱优化问题中动态算法选择的基线方法'}
{'arxiv_id': 'arXiv:2504.11431', 'title': 'Masculine Defaults via Gendered Discourse in Podcasts and Large Language Models', 'authors': 'Maria Teleki, Xiangjue Dong, Haoran Liu, James Caverlee', 'link': 'https://arxiv.org/abs/2504.11431', 'abstract': 'Masculine defaults are widely recognized as a significant type of gender bias, but they are often unseen as they are under-researched. Masculine defaults involve three key parts: (i) the cultural context, (ii) the masculine characteristics or behaviors, and (iii) the reward for, or simply acceptance of, those masculine characteristics or behaviors. In this work, we study discourse-based masculine defaults, and propose a twofold framework for (i) the large-scale discovery and analysis of gendered discourse words in spoken content via our Gendered Discourse Correlation Framework (GDCF); and (ii) the measurement of the gender bias associated with these gendered discourse words in LLMs via our Discourse Word-Embedding Association Test (D-WEAT). We focus our study on podcasts, a popular and growing form of social media, analyzing 15,117 podcast episodes. We analyze correlations between gender and discourse words -- discovered via LDA and BERTopic -- to automatically form gendered discourse word lists. We then study the prevalence of these gendered discourse words in domain-specific contexts, and find that gendered discourse-based masculine defaults exist in the domains of business, technology/politics, and video games. Next, we study the representation of these gendered discourse words from a state-of-the-art LLM embedding model from OpenAI, and find that the masculine discourse words have a more stable and robust representation than the feminine discourse words, which may result in better system performance on downstream tasks for men. Hence, men are rewarded for their discourse patterns with better system performance by one of the state-of-the-art language models -- and this embedding disparity is a representational harm and a masculine default.', 'abstract_zh': 'masculinistic 默认广泛被认为是性别偏见的一种重要类型，但由于其研究不足而常常未被察觉。 masculinistic 默认包含三个关键部分：(i) 文化背景，(ii) 男性特征或行为，以及(iii) 对这些男性特征或行为的奖励，或是对其的简单接受。在本文中，我们研究基于话语的 masculinistic 默认，并提出了一种双管齐下的框架：(i) 通过我们的性别话语相关性框架 (GDCF)，大规模发现和分析口头内容中的性别化话语词汇；(ii) 通过我们的话语词嵌入关联测试 (D-WEAT)，测量这些性别化话语词汇与语言模型 (LLM) 中的性别偏见相关性。我们将研究重点放在受欢迎且不断增长的社交媒体形式播客上，分析了15,117期播客节目。我们通过LDA和BERTopic分析性别与话语词汇之间的相关性，自动形成性别化话语词汇列表。随后，我们研究了这些性别化话语词汇在特定领域中的普遍存在性，发现性别化话语为基础的 masculinistic 默认存在于商业、技术和政治以及电子游戏领域。接着，我们从OpenAI的先进LSTM嵌入模型出发，研究这些性别化话语词汇的表示，发现男性话语词汇比女性话语词汇有更稳定和稳健的表示，这可能导致更先进的语言模型在下游任务上对男性表现更好。因此，男性因其话语模式获得更好的系统性能奖励，并且这种嵌入差异是一种表征损害和 masculinistic 默认。', 'title_zh': '性别话语在播客和大型语言模型中的 masculinist 默认'}
{'arxiv_id': 'arXiv:2504.11426', 'title': 'A Dual-Space Framework for General Knowledge Distillation of Large Language Models', 'authors': 'Xue Zhang, Songming Zhang, Yunlong Liang, Fandong Meng, Yufeng Chen, Jinan Xu, Jie Zhou', 'link': 'https://arxiv.org/abs/2504.11426', 'abstract': 'Knowledge distillation (KD) is a promising solution to compress large language models (LLMs) by transferring their knowledge to smaller models. During this process, white-box KD methods usually minimize the distance between the output distributions of the teacher model and the student model to transfer more information. However, we reveal that the current white-box KD framework exhibits two limitations: a) bridging probability distributions from different output spaces will limit the similarity between the teacher model and the student model; b) this framework cannot be applied to LLMs with different vocabularies. One of the root causes for these limitations is that the distributions from the teacher and the student for KD are output by different prediction heads, which yield distributions in different output spaces and dimensions. Therefore, in this paper, we propose a dual-space knowledge distillation (DSKD) framework that unifies the prediction heads of the teacher and the student models for KD. Specifically, we first introduce two projectors with ideal initialization to project the teacher/student hidden states into the student/teacher representation spaces. After this, the hidden states from different models can share the same head and unify the output spaces of the distributions. Furthermore, we develop an exact token alignment (ETA) algorithm to align the same tokens in two differently-tokenized sequences. Based on the above, our DSKD framework is a general KD framework that supports both off-policy and on-policy KD, and KD between any two LLMs regardless of their vocabularies. Extensive experiments on instruction-following, mathematical reasoning, and code generation benchmarks show that DSKD significantly outperforms existing methods based on the current white-box KD framework and surpasses other cross-tokenizer KD methods for LLMs with different vocabularies.', 'abstract_zh': '双空间知识蒸馏（DSKD）框架', 'title_zh': '双空间框架赋能大型语言模型通用知识精炼'}
{'arxiv_id': 'arXiv:2504.11423', 'title': 'ADT: Tuning Diffusion Models with Adversarial Supervision', 'authors': 'Dazhong Shen, Guanglu Song, Yi Zhang, Bingqi Ma, Lujundong Li, Dongzhi Jiang, Zhuofan Zong, Yu Liu', 'link': 'https://arxiv.org/abs/2504.11423', 'abstract': 'Diffusion models have achieved outstanding image generation by reversing a forward noising process to approximate true data distributions. During training, these models predict diffusion scores from noised versions of true samples in a single forward pass, while inference requires iterative denoising starting from white noise. This training-inference divergences hinder the alignment between inference and training data distributions, due to potential prediction biases and cumulative error accumulation. To address this problem, we propose an intuitive but effective fine-tuning framework, called Adversarial Diffusion Tuning (ADT), by stimulating the inference process during optimization and aligning the final outputs with training data by adversarial supervision. Specifically, to achieve robust adversarial training, ADT features a siamese-network discriminator with a fixed pre-trained backbone and lightweight trainable parameters, incorporates an image-to-image sampling strategy to smooth discriminative difficulties, and preserves the original diffusion loss to prevent discriminator hacking. In addition, we carefully constrain the backward-flowing path for back-propagating gradients along the inference path without incurring memory overload or gradient explosion. Finally, extensive experiments on Stable Diffusion models (v1.5, XL, and v3), demonstrate that ADT significantly improves both distribution alignment and image quality.', 'abstract_zh': '对抗扩散调优（ADT）：优化过程中的对抗性监督以改善分布对齐和图像质量', 'title_zh': 'ADT：通过对抗监督调优扩散模型'}
{'arxiv_id': 'arXiv:2504.11412', 'title': 'Measures of Variability for Risk-averse Policy Gradient', 'authors': 'Yudong Luo, Yangchen Pan, Jiaqi Tan, Pascal Poupart', 'link': 'https://arxiv.org/abs/2504.11412', 'abstract': 'Risk-averse reinforcement learning (RARL) is critical for decision-making under uncertainty, which is especially valuable in high-stake applications. However, most existing works focus on risk measures, e.g., conditional value-at-risk (CVaR), while measures of variability remain underexplored. In this paper, we comprehensively study nine common measures of variability, namely Variance, Gini Deviation, Mean Deviation, Mean-Median Deviation, Standard Deviation, Inter-Quantile Range, CVaR Deviation, Semi_Variance, and Semi_Standard Deviation. Among them, four metrics have not been previously studied in RARL. We derive policy gradient formulas for these unstudied metrics, improve gradient estimation for Gini Deviation, analyze their gradient properties, and incorporate them with the REINFORCE and PPO frameworks to penalize the dispersion of returns.\nOur empirical study reveals that variance-based metrics lead to unstable policy updates. In contrast, CVaR Deviation and Gini Deviation show consistent performance across different randomness and evaluation domains, achieving high returns while effectively learning risk-averse policies. Mean Deviation and Semi_Standard Deviation are also competitive across different scenarios. This work provides a comprehensive overview of variability measures in RARL, offering practical insights for risk-aware decision-making and guiding future research on risk metrics and RARL algorithms.', 'abstract_zh': '风险规避强化学习 (RARL) 在不确定性决策中至关重要，特别是在高风险应用场景中尤为有价值。然而，现有大部分工作集中在风险度量上，如条件值-at-风险 (CVaR)，而波动性度量则尚未充分探索。在本文中，我们全面研究了九种常见的波动性度量，包括方差、基尼偏差、均值偏差、均值-中位数偏差、标准差、分位数间距、CVaR偏差、半方差和半标准差。其中，有四种指标在RARL中尚未被研究。我们推导了这些未研究指标的策略梯度公式，改进了基尼偏差的梯度估计，分析了它们的梯度性质，并将其与REINFORCE和PPO框架结合，用于惩罚回报的分散性。', 'title_zh': '风险回避策略梯度的变异性度量'}
{'arxiv_id': 'arXiv:2504.11406', 'title': 'Multi-level Cellular Automata for FLIM networks', 'authors': 'Felipe Crispim Salvagnini, Jancarlo F. Gomes, Cid A. N. Santos, Silvio Jamil F. Guimarães, Alexandre X. Falcão', 'link': 'https://arxiv.org/abs/2504.11406', 'abstract': 'The necessity of abundant annotated data and complex network architectures presents a significant challenge in deep-learning Salient Object Detection (deep SOD) and across the broader deep-learning landscape. This challenge is particularly acute in medical applications in developing countries with limited computational resources. Combining modern and classical techniques offers a path to maintaining competitive performance while enabling practical applications. Feature Learning from Image Markers (FLIM) methodology empowers experts to design convolutional encoders through user-drawn markers, with filters learned directly from these annotations. Recent findings demonstrate that coupling a FLIM encoder with an adaptive decoder creates a flyweight network suitable for SOD, requiring significantly fewer parameters than lightweight models and eliminating the need for backpropagation. Cellular Automata (CA) methods have proven successful in data-scarce scenarios but require proper initialization -- typically through user input, priors, or randomness. We propose a practical intersection of these approaches: using FLIM networks to initialize CA states with expert knowledge without requiring user interaction for each image. By decoding features from each level of a FLIM network, we can initialize multiple CAs simultaneously, creating a multi-level framework. Our method leverages the hierarchical knowledge encoded across different network layers, merging multiple saliency maps into a high-quality final output that functions as a CA ensemble. Benchmarks across two challenging medical datasets demonstrate the competitiveness of our multi-level CA approach compared to established models in the deep SOD literature.', 'abstract_zh': '丰富的标注数据和复杂的网络架构在深度学习显著目标检测（deep SOD）及更广泛的深度学习领域中提出了重大挑战。这一挑战在计算资源有限的 developing countries 的医疗应用中尤为严峻。结合现代和经典技术为维持竞争力同时实现实际应用提供了一条途径。图像标记特征学习（FLIM）方法使专家能够通过用户绘制的标记设计卷积编码器，并直接从这些注释中学习滤波器。最近的研究表明，将FLIM编码器与自适应解码器结合使用，可创建一种轻量级网络，所需的参数显著少于轻量级模型，并且不需要反向传播。在数据稀缺情况下，细胞自动机（CA）方法已经证明是有效的，但需要适当的初始化通常通过用户输入、先验知识或随机性实现。我们提出了一种实用的结合方法：利用FLIM网络在不需每张图像都进行用户交互的情况下，通过专家知识初始化CA状态。通过从FLIM网络的每一层解码特征，我们可以同时初始化多个CA，创建一个多层框架。该方法利用了不同网络层中编码的层次知识，将多个显著性图合并成高质量的最终输出，作为CA的集成。在两个具有挑战性的医学数据集上的基准测试表明，与深度SOD文献中已有的模型相比，我们的多层CA方法具有竞争力。', 'title_zh': '多级细胞自动机for FLIM网络'}
{'arxiv_id': 'arXiv:2504.11389', 'title': 'VideoPanda: Video Panoramic Diffusion with Multi-view Attention', 'authors': 'Kevin Xie, Amirmojtaba Sabour, Jiahui Huang, Despoina Paschalidou, Greg Klar, Umar Iqbal, Sanja Fidler, Xiaohui Zeng', 'link': 'https://arxiv.org/abs/2504.11389', 'abstract': 'High resolution panoramic video content is paramount for immersive experiences in Virtual Reality, but is non-trivial to collect as it requires specialized equipment and intricate camera setups. In this work, we introduce VideoPanda, a novel approach for synthesizing 360$^\\circ$ videos conditioned on text or single-view video data. VideoPanda leverages multi-view attention layers to augment a video diffusion model, enabling it to generate consistent multi-view videos that can be combined into immersive panoramic content. VideoPanda is trained jointly using two conditions: text-only and single-view video, and supports autoregressive generation of long-videos. To overcome the computational burden of multi-view video generation, we randomly subsample the duration and camera views used during training and show that the model is able to gracefully generalize to generating more frames during inference. Extensive evaluations on both real-world and synthetic video datasets demonstrate that VideoPanda generates more realistic and coherent 360$^\\circ$ panoramas across all input conditions compared to existing methods. Visit the project website at this https URL for results.', 'abstract_zh': '基于文本或单视角视频数据合成360°视频的novel方法：VideoPanda', 'title_zh': 'VideoPanda：基于多视图Attention的全景视频扩散'}
{'arxiv_id': 'arXiv:2504.11386', 'title': 'Trajectory Encoding Temporal Graph Networks', 'authors': 'Jiafeng Xiong, Rizos Sakellariou', 'link': 'https://arxiv.org/abs/2504.11386', 'abstract': "Temporal Graph Networks (TGNs) have demonstrated significant success in dynamic graph tasks such as link prediction and node classification. Both tasks comprise transductive settings, where the model predicts links among known nodes, and in inductive settings, where it generalises learned patterns to previously unseen nodes. Existing TGN designs face a dilemma under these dual scenarios. Anonymous TGNs, which rely solely on temporal and structural information, offer strong inductive generalisation but struggle to distinguish known nodes. In contrast, non-anonymous TGNs leverage node features to excel in transductive tasks yet fail to adapt to new nodes. To address this challenge, we propose Trajectory Encoding TGN (TETGN). Our approach introduces automatically expandable node identifiers (IDs) as learnable temporal positional features and performs message passing over these IDs to capture each node's historical context. By integrating this trajectory-aware module with a standard TGN using multi-head attention, TETGN effectively balances transductive accuracy with inductive generalisation. Experimental results on three real-world datasets show that TETGN significantly outperforms strong baselines on both link prediction and node classification tasks, demonstrating its ability to unify the advantages of anonymous and non-anonymous models for dynamic graph learning.", 'abstract_zh': 'Temporal Graph Networks with Trajectory-aware Encoding for Dynamic Graph Learning', 'title_zh': '轨迹编码时序图网络'}
{'arxiv_id': 'arXiv:2504.11374', 'title': 'A Winner-Takes-All Mechanism for Event Generation', 'authors': 'Yongkang Huo, Fuvio Forni, Rodolphe Sepulchre', 'link': 'https://arxiv.org/abs/2504.11374', 'abstract': 'We present a novel framework for central pattern generator design that leverages the intrinsic rebound excitability of neurons in combination with winner-takes-all computation. Our approach unifies decision-making and rhythmic pattern generation within a simple yet powerful network architecture that employs all-to-all inhibitory connections enhanced by designable excitatory interactions. This design offers significant advantages regarding ease of implementation, adaptability, and robustness. We demonstrate its efficacy through a ring oscillator model, which exhibits adaptive phase and frequency modulation, making the framework particularly promising for applications in neuromorphic systems and robotics.', 'abstract_zh': '一种利用神经元内源性反弹可兴奋性与胜者全取计算相结合的新型中央模式发生器设计框架', 'title_zh': '全胜者机制事件生成'}
{'arxiv_id': 'arXiv:2504.11369', 'title': 'OpenTuringBench: An Open-Model-based Benchmark and Framework for Machine-Generated Text Detection and Attribution', 'authors': 'Lucio La Cava, Andrea Tagarelli', 'link': 'https://arxiv.org/abs/2504.11369', 'abstract': 'Open Large Language Models (OLLMs) are increasingly leveraged in generative AI applications, posing new challenges for detecting their outputs. We propose OpenTuringBench, a new benchmark based on OLLMs, designed to train and evaluate machine-generated text detectors on the Turing Test and Authorship Attribution problems. OpenTuringBench focuses on a representative set of OLLMs, and features a number of challenging evaluation tasks, including human/machine-manipulated texts, out-of-domain texts, and texts from previously unseen models. We also provide OTBDetector, a contrastive learning framework to detect and attribute OLLM-based machine-generated texts. Results highlight the relevance and varying degrees of difficulty of the OpenTuringBench tasks, with our detector achieving remarkable capabilities across the various tasks and outperforming most existing detectors. Resources are available on the OpenTuringBench Hugging Face repository at this https URL', 'abstract_zh': '开放大型语言模型（OLLMs）在生成人工智能应用中越来越受到重视，给其输出检测带来了新的挑战。我们提出了一种基于OLLMs的新基准OpenTuringBench，旨在训练和评估机器生成文本检测器在图灵测试和作者归属问题上的表现。OpenTuringBench关注代表性较强的OLLMs集合，并包含一系列具有挑战性的评估任务，包括人工/机器操控的文本、域外文本以及来自以前未见过的模型的文本。我们还提供了一种对比学习框架OTBDetector，用于检测和归属基于OLLMs的机器生成文本。实验结果突显了OpenTuringBench任务的相关性和不同难度等级，我们的检测器在各种任务上表现出色，并显著优于大多数现有检测器。相关资源可以在以下Hugging Face仓库中获取：this https URL。', 'title_zh': 'OpenTuringBench: 基于开放模型的机器生成文本检测与归属基准和框架'}
{'arxiv_id': 'arXiv:2504.11364', 'title': 'Teaching Large Language Models to Reason through Learning and Forgetting', 'authors': 'Tianwei Ni, Allen Nie, Sapana Chaudhary, Yao Liu, Huzefa Rangwala, Rasool Fakoor', 'link': 'https://arxiv.org/abs/2504.11364', 'abstract': "Leveraging inference-time search in large language models has proven effective in further enhancing a trained model's capability to solve complex mathematical and reasoning problems. However, this approach significantly increases computational costs and inference time, as the model must generate and evaluate multiple candidate solutions to identify a viable reasoning path. To address this, we propose an effective approach that integrates search capabilities directly into the model by fine-tuning it using both successful (learning) and failed reasoning paths (forgetting) derived from diverse search methods. While fine-tuning the model with these data might seem straightforward, we identify a critical issue: the model's search capability tends to degrade rapidly if fine-tuning is performed naively. We show that this degradation can be substantially mitigated by employing a smaller learning rate. Extensive experiments on the challenging Game-of-24 and Countdown mathematical reasoning benchmarks show that our approach not only outperforms both standard fine-tuning and inference-time search baselines but also significantly reduces inference time by 180$\\times$.", 'abstract_zh': '利用推理时搜索能力增强大规模语言模型解决复杂数学和推理问题的能力已被证明有效，但这种方法会显著增加计算成本和推理时间，因为模型必须生成和评估多个候选解决方案以识别有效的推理路径。为了解决这个问题，我们提出了一种有效的方法，通过将搜索能力直接集成到模型中来解决此问题，具体做法是在从多种搜索方法中得出的成功（学习）和失败（遗忘）推理路径数据上进行微调。尽管使用这些数据进行微调似乎很简单，但我们将一个关键问题识别出来：如果进行简单的微调，模型的搜索能力会迅速退化。我们表明，通过采用较小的学习率，这种退化可以大幅缓解。在具有挑战性的Game-of-24和Countdown数学推理基准测试中进行的广泛实验表明，我们的方法不仅在性能上优于标准微调和推理时搜索基线，而且还将推理时间显著减少至原来的180倍。', 'title_zh': '通过学习与遗忘来教授大型语言模型进行推理'}
{'arxiv_id': 'arXiv:2504.11358', 'title': 'DataSentinel: A Game-Theoretic Detection of Prompt Injection Attacks', 'authors': 'Yupei Liu, Yuqi Jia, Jinyuan Jia, Dawn Song, Neil Zhenqiang Gong', 'link': 'https://arxiv.org/abs/2504.11358', 'abstract': 'LLM-integrated applications and agents are vulnerable to prompt injection attacks, where an attacker injects prompts into their inputs to induce attacker-desired outputs. A detection method aims to determine whether a given input is contaminated by an injected prompt. However, existing detection methods have limited effectiveness against state-of-the-art attacks, let alone adaptive ones. In this work, we propose DataSentinel, a game-theoretic method to detect prompt injection attacks. Specifically, DataSentinel fine-tunes an LLM to detect inputs contaminated with injected prompts that are strategically adapted to evade detection. We formulate this as a minimax optimization problem, with the objective of fine-tuning the LLM to detect strong adaptive attacks. Furthermore, we propose a gradient-based method to solve the minimax optimization problem by alternating between the inner max and outer min problems. Our evaluation results on multiple benchmark datasets and LLMs show that DataSentinel effectively detects both existing and adaptive prompt injection attacks.', 'abstract_zh': 'LLM集成应用和代理易受提示注入攻击的威胁，攻击者可通过向输入中注入提示来诱导攻击者期望的输出。检测方法旨在确定给定输入是否被注入提示所污染。然而，现有的检测方法在对抗最新的攻击时效果有限，更不用说适应性攻击了。在此工作中，我们提出了一种基于博弈论的方法DataSentinel来检测提示注入攻击。具体来说，DataSentinel对LLM进行微调，使其能够检测被战略适应以逃避检测的注入提示污染的输入。我们将此问题形式化为一个极大极小优化问题，目标是微调LLM以检测强大的适应性攻击。此外，我们提出了一种基于梯度的方法通过交替解决内部极大问题和外部极小问题来求解极大极小优化问题。我们在多个基准数据集和LLM上的评估结果表明，DataSentinel能够有效检测现有的和适应性的提示注入攻击。', 'title_zh': 'DataSentinel：基于博弈论的提示注入攻击检测方法'}
{'arxiv_id': 'arXiv:2504.11355', 'title': 'Neural Networks for on-chip Model Predictive Control: a Method to Build Optimized Training Datasets and its application to Type-1 Diabetes', 'authors': 'Alberto Castillo, Elliot Pryor, Anas El Fathi, Boris Kovatchev, Marc Breton', 'link': 'https://arxiv.org/abs/2504.11355', 'abstract': "Training Neural Networks (NNs) to behave as Model Predictive Control (MPC) algorithms is an effective way to implement them in constrained embedded devices. By collecting large amounts of input-output data, where inputs represent system states and outputs are MPC-generated control actions, NNs can be trained to replicate MPC behavior at a fraction of the computational cost. However, although the composition of the training data critically influences the final NN accuracy, methods for systematically optimizing it remain underexplored. In this paper, we introduce the concept of Optimally-Sampled Datasets (OSDs) as ideal training sets and present an efficient algorithm for generating them. An OSD is a parametrized subset of all the available data that (i) preserves existing MPC information up to a certain numerical resolution, (ii) avoids duplicate or near-duplicate states, and (iii) becomes saturated or complete. We demonstrate the effectiveness of OSDs by training NNs to replicate the University of Virginia's MPC algorithm for automated insulin delivery in Type-1 Diabetes, achieving a four-fold improvement in final accuracy. Notably, two OSD-trained NNs received regulatory clearance for clinical testing as the first NN-based control algorithm for direct human insulin dosing. This methodology opens new pathways for implementing advanced optimizations on resource-constrained embedded platforms, potentially revolutionizing how complex algorithms are deployed.", 'abstract_zh': '将神经网络训练为模型预测控制算法可以有效地在约束嵌入式设备中实现它们。通过收集大量输入-输出数据，其中输入代表系统状态，输出是模型预测控制生成的控制动作，神经网络可以以极低的计算成本复制模型预测控制的行为。然而，尽管训练数据的组成对最终神经网络的准确性至关重要，但系统地优化它的方法仍然研究不足。在本文中，我们提出了最优采样数据集（OSD）的概念，作为理想的训练集，并提出了一种高效生成它们的算法。OSD是一个参数化的可用数据子集，它(i)保留到一定数值分辨率的现有模型预测控制信息，(ii)避免重复或近乎重复的状态，(iii)变得饱和或完备。我们通过训练神经网络复制弗吉尼亚大学的模型预测控制算法来自动输送胰岛素，在1型糖尿病中实现了四倍的最终准确性提升。值得注意的是，两种经过OSD训练的神经网络获得了生物医学监管机构的临床测试批准，成为第一个基于神经网络的直接人类胰岛素剂量控制算法。这种方法为资源受限的嵌入式平台上的高级优化提供了新的途径，有可能彻底改变复杂算法的部署方式。', 'title_zh': '基于神经网络的片上模型预测控制方法及其在1型糖尿病中的应用：构建优化训练数据集的方法'}
{'arxiv_id': 'arXiv:2504.11349', 'title': 'Explicit and Implicit Representations in AI-based 3D Reconstruction for Radiology: A systematic literature review', 'authors': 'Yuezhe Yang, Boyu Yang, Yaqian Wang, Yang He, Xingbo Dong, Zhe Jin', 'link': 'https://arxiv.org/abs/2504.11349', 'abstract': 'The demand for high-quality medical imaging in clinical practice and assisted diagnosis has made 3D reconstruction in radiological imaging a key research focus. Artificial intelligence (AI) has emerged as a promising approach to enhancing reconstruction accuracy while reducing acquisition and processing time, thereby minimizing patient radiation exposure and discomfort and ultimately benefiting clinical diagnosis. This review explores state-of-the-art AI-based 3D reconstruction algorithms in radiological imaging, categorizing them into explicit and implicit approaches based on their underlying principles. Explicit methods include point-based, volume-based, and Gaussian representations, while implicit methods encompass implicit prior embedding and neural radiance fields. Additionally, we examine commonly used evaluation metrics and benchmark datasets. Finally, we discuss the current state of development, key challenges, and future research directions in this evolving field. Our project available on: this https URL.', 'abstract_zh': '高质医学成像在临床实践和辅助诊断中的需求使得放射影像三维重建成为关键研究方向。人工智能（AI）作为一种有望提高重建精度、减少获取和处理时间的方法，从而减少患者辐射暴露和不适，最终有利于临床诊断。本文综述了基于AI的放射影像三维重建最新算法，基于其基本原理将其分类为显式方法和隐式方法。显式方法包括基于点、基于体素和高斯表示法，而隐式方法包括隐式先验嵌入和神经辐射场。此外，本文还探讨了常用评估指标和基准数据集。最后，本文讨论了该领域当前的发展状况、关键挑战及未来研究方向。我们的项目可在以下链接获取：this https URL。', 'title_zh': '基于AI的3D重建在放射学中显式和隐式表示：一项系统文献综述'}
{'arxiv_id': 'arXiv:2504.11344', 'title': 'Interpretable Hybrid-Rule Temporal Point Processes', 'authors': 'Yunyang Cao, Juekai Lin, Hongye Wang, Wenhao Li, Bo Jin', 'link': 'https://arxiv.org/abs/2504.11344', 'abstract': 'Temporal Point Processes (TPPs) are widely used for modeling event sequences in various medical domains, such as disease onset prediction, progression analysis, and clinical decision support. Although TPPs effectively capture temporal dynamics, their lack of interpretability remains a critical challenge. Recent advancements have introduced interpretable TPPs. However, these methods fail to incorporate numerical features, thereby limiting their ability to generate precise predictions. To address this issue, we propose Hybrid-Rule Temporal Point Processes (HRTPP), a novel framework that integrates temporal logic rules with numerical features, improving both interpretability and predictive accuracy in event modeling. HRTPP comprises three key components: basic intensity for intrinsic event likelihood, rule-based intensity for structured temporal dependencies, and numerical feature intensity for dynamic probability modulation. To effectively discover valid rules, we introduce a two-phase rule mining strategy with Bayesian optimization. To evaluate our method, we establish a multi-criteria assessment framework, incorporating rule validity, model fitting, and temporal predictive accuracy. Experimental results on real-world medical datasets demonstrate that HRTPP outperforms state-of-the-art interpretable TPPs in terms of predictive performance and clinical interpretability. In case studies, the rules extracted by HRTPP explain the disease progression, offering valuable contributions to medical diagnosis.', 'abstract_zh': '混合规则时序点过程：兼具解释性和预测精度的新型时序事件建模框架', 'title_zh': '可解释的混合规则时序点过程'}
{'arxiv_id': 'arXiv:2504.11343', 'title': 'A Minimalist Approach to LLM Reasoning: from Rejection Sampling to Reinforce', 'authors': 'Wei Xiong, Jiarui Yao, Yuhui Xu, Bo Pang, Lei Wang, Doyen Sahoo, Junnan Li, Nan Jiang, Tong Zhang, Caiming Xiong, Hanze Dong', 'link': 'https://arxiv.org/abs/2504.11343', 'abstract': "Reinforcement learning (RL) has become a prevailing approach for fine-tuning large language models (LLMs) on complex reasoning tasks. Among recent methods, GRPO stands out for its empirical success in training models such as DeepSeek-R1, yet the sources of its effectiveness remain poorly understood. In this work, we revisit GRPO from a reinforce-like algorithm perspective and analyze its core components. Surprisingly, we find that a simple rejection sampling baseline, RAFT, which trains only on positively rewarded samples, yields competitive performance than GRPO and PPO. Our ablation studies reveal that GRPO's main advantage arises from discarding prompts with entirely incorrect responses, rather than from its reward normalization. Motivated by this insight, we propose Reinforce-Rej, a minimal extension of policy gradient that filters both entirely incorrect and entirely correct samples. Reinforce-Rej improves KL efficiency and stability, serving as a lightweight yet effective alternative to more complex RL algorithms. We advocate RAFT as a robust and interpretable baseline, and suggest that future advances should focus on more principled designs for incorporating negative samples, rather than relying on them indiscriminately. Our findings provide guidance for future work in reward-based LLM post-training.", 'abstract_zh': '强化学习（RL）已成为在复杂推理任务上 fine-tuning 大型语言模型（LLMs）的主流方法。在 recent 方法中，GRPO 由于其在训练 DeepSeek-R1 等模型方面的 empirical 成功而脱颖而出，但其有效性的来源尚不清楚。在本文中，我们从类似强化学习算法的角度重新审视 GRPO，并分析其核心组件。令人惊讶的是，我们发现一个简单的拒绝采样基线 RAFT，在仅使用正奖励样本进行训练的情况下，其性能与 GRPO 和 PPO 相当。我们的消融研究揭示了 GRPO 的主要优势来自于抛弃完全错误的提示，而不是其奖励归一化。受此洞见的启发，我们提出了 Reinforce-Rej，这是一种对策略梯度的最小扩展，可以过滤掉完全错误和完全正确的样本。Reinforce-Rej 提高了 KL 效率和稳定性，作为一种轻量级但有效的替代方法，可以替代更复杂的 RL 算法。我们提倡 RAFT 作为一种稳健且可解释的基准，并建议未来的工作应集中在更原则性的设计上，以更好地利用负样本，而不是随意依赖它们。我们的研究结果为基于奖励的 LLM 后训练未来工作提供了指导。', 'title_zh': '最小主义方法下的大语言模型推理：从拒绝采样到强化점을 추가합니다.'}
{'arxiv_id': 'arXiv:2504.11338', 'title': 'Transformer-Based Model for Cold Start Mitigation in FaaS Architecture', 'authors': 'Alexandre Savi Fayam Mbala Mouen, Jerry Lacmou Zeutouo, Vianney Kengne Tchendji', 'link': 'https://arxiv.org/abs/2504.11338', 'abstract': 'Serverless architectures, particularly the Function as a Service (FaaS) model, have become a cornerstone of modern cloud computing due to their ability to simplify resource management and enhance application deployment agility. However, a significant challenge remains: the cold start problem. This phenomenon occurs when an idle FaaS function is invoked, requiring a full initialization process, which increases latency and degrades user experience. Existing solutions for cold start mitigation are limited in terms of invocation pattern generalization and implementation complexity. In this study, we propose an innovative approach leveraging Transformer models to mitigate the impact of cold starts in FaaS architectures. Our solution excels in accurately modeling function initialization delays and optimizing serverless system performance. Experimental evaluation using a public dataset provided by Azure demonstrates a significant reduction in cold start times, reaching up to 79\\% compared to conventional methods.', 'abstract_zh': '无服务器架构，特别是函数即服务（FaaS）模型，因其能够简化资源管理并增强应用部署 agility，已成为现代云计算的基石。然而，一个重大挑战仍然存在：冷启动问题。当一个空闲的FaaS函数被调用时，会触发完整的初始化过程，从而增加延迟并降低用户体验。现有的冷启动缓解解决方案在调用模式泛化和实现复杂性方面受到限制。在本研究中，我们提出了一种创新的方法，利用Transformer模型来缓解FaaS架构中的冷启动影响。我们的解决方案在准确建模函数初始化延迟和优化无服务器系统性能方面表现出色。使用Azure提供的公共数据集进行的实验评估表明，与传统方法相比，冷启动时间显著减少，最高可达79%。', 'title_zh': '基于Transformer的模型在FaaS架构中的冷启动缓解'}
{'arxiv_id': 'arXiv:2504.11336', 'title': 'Looking beyond the next token', 'authors': 'Abitha Thankaraj, Yiding Jiang, J. Zico Kolter, Yonatan Bisk', 'link': 'https://arxiv.org/abs/2504.11336', 'abstract': "The structure of causal language model training assumes that each token can be accurately predicted from the previous context. This contrasts with humans' natural writing and reasoning process, where goals are typically known before the exact argument or phrasings. While this mismatch has been well studied in the literature, the working assumption has been that architectural changes are needed to address this mismatch. We argue that rearranging and processing the training data sequences can allow models to more accurately imitate the true data-generating process, and does not require any other changes to the architecture or training infrastructure. We demonstrate that this technique, Trelawney, and the inference algorithms derived from it allow us to improve performance on several key benchmarks that span planning, algorithmic reasoning, and story generation tasks. Finally, our method naturally enables the generation of long-term goals at no additional cost. We investigate how using the model's goal-generation capability can further improve planning and reasoning. Additionally, we believe Trelawney could potentially open doors to new capabilities beyond the current language modeling paradigm.", 'abstract_zh': '因果语言模型训练的结构假设每个令牌可以从之前的上下文中准确预测。这与人类自然写作和推理过程不同，在人类过程中，目标通常在具体论据或措辞之前就已经知道了。尽管这种不匹配在文献中已有充分研究，但假定需要对架构进行改变以解决这种不匹配。我们认为重新排列和处理训练数据序列可以让模型更准确地模仿真实的数据生成过程，不需要对架构或训练基础设施进行任何其他修改。我们证明了这种方法Trelawney及其推导出的推理算法能够在多个涵盖规划、算法推理和故事生成的任务基准上改善性能。最后，我们的方法自然地使生成长期目标成为零成本操作。我们研究了利用模型的目标生成能力如何进一步改进规划和推理。此外，我们认为Trelawney可能为超越当前语言模型范式的新型能力打开大门。', 'title_zh': '超越下一个词'}
{'arxiv_id': 'arXiv:2504.11335', 'title': 'Code Reborn AI-Driven Legacy Systems Modernization from COBOL to Java', 'authors': 'Gopichand Bandarupalli', 'link': 'https://arxiv.org/abs/2504.11335', 'abstract': 'This study investigates AI-driven modernization of legacy COBOL code into Java, addressing a critical challenge in aging software systems. Leveraging the Legacy COBOL 2024 Corpus -- 50,000 COBOL files from public and enterprise sources -- Java parses the code, AI suggests upgrades, and React visualizes gains. Achieving 93% accuracy, complexity drops 35% (from 18 to 11.7) and coupling 33% (from 8 to 5.4), surpassing manual efforts (75%) and rule-based tools (82%). The approach offers a scalable path to rejuvenate COBOL systems, vital for industries like banking and insurance.', 'abstract_zh': '本研究探讨了基于AI的老一代COBOL代码向Java的现代化转型，解决了老化软件系统中的关键挑战。利用Legacy COBOL 2024语料库（包含50,000个来自公共和企业来源的COBOL文件），Java解析代码，AI建议更新，并使用React可视化改进效果。实现了93%的准确性，复杂性降低35%（从18降至11.7），耦合度降低33%（从8降至5.4），超过了人工努力（75%）和基于规则的工具（82%）。该方法为银行业和保险业等行业的COBOL系统焕发活力提供了可扩展的路径。', 'title_zh': 'AI驱动的COBOL到Java的遗产系统现代化重生成代码'}
{'arxiv_id': 'arXiv:2504.11320', 'title': 'Optimizing LLM Inference: Fluid-Guided Online Scheduling with Memory Constraints', 'authors': 'Ruicheng Ao, Gan Luo, David Simchi-Levi, Xinshang Wang', 'link': 'https://arxiv.org/abs/2504.11320', 'abstract': "Large Language Models (LLMs) are indispensable in today's applications, but their inference procedure -- generating responses by processing text in segments and using a memory-heavy Key-Value (KV) cache -- demands significant computational resources, particularly under memory constraints. This paper formulates LLM inference optimization as a multi-stage online scheduling problem where sequential prompt arrivals and KV cache growth render conventional scheduling ineffective. We develop a fluid dynamics approximation to provide a tractable benchmark that guides algorithm design. Building on this, we propose the Waiting for Accumulated Inference Threshold (WAIT) algorithm, which uses multiple thresholds to schedule incoming prompts optimally when output lengths are known, and extend it to Nested WAIT for cases with unknown output lengths. Theoretical analysis shows that both algorithms achieve near-optimal performance against the fluid benchmark in heavy traffic conditions, balancing throughput, latency, and Time to First Token (TTFT). Experiments with the Llama-7B model on an A100 GPU using both synthetic and real-world datasets demonstrate improved throughput and reduced latency relative to established baselines like vLLM and Sarathi. This work bridges operations research and machine learning, offering a rigorous framework for the efficient deployment of LLMs under memory constraints.", 'abstract_zh': '大型语言模型（LLMs）在当今的应用中不可或缺，但其推理过程——通过分段处理文本并使用内存密集型Key-Value（KV）缓存生成响应——在内存受限的情况下需要大量的计算资源。本文将LLM推理优化问题表述为多阶段在线调度问题，其中顺序到来的提示和KV缓存的增长使传统调度方法无效。我们发展了一种流体动力学近似来提供一个可操作的基准，指导算法设计。在此基础上，我们提出了累积推理阈值等待（WAIT）算法，该算法利用多个阈值在已知输出长度的情况下最优地调度到来的提示，并将其扩展为嵌套WAIT算法以处理未知输出长度的情况。理论分析表明，在高负荷条件下，这两种算法均可在吞吐量、延迟和首个标记时间（TTFT）之间达到几乎最优的性能。利用A100 GPU对该结果通过Llama-7B模型在合成和实际数据集上的实验表明，与vLLM和Sarathi等现有基线相比，吞吐量提高且延迟减少。该工作将运筹学与机器学习相结合，提供了一种在内存受限条件下高效部署LLMs的严格框架。', 'title_zh': '优化大语言模型推理：基于流动引导的内存受限在线调度'}
{'arxiv_id': 'arXiv:2504.11305', 'title': 'CFIS-YOLO: A Lightweight Multi-Scale Fusion Network for Edge-Deployable Wood Defect Detection', 'authors': 'Jincheng Kang, Yi Cen, Yigang Cen, Ke Wang, Yuhan Liu', 'link': 'https://arxiv.org/abs/2504.11305', 'abstract': 'Wood defect detection is critical for ensuring quality control in the wood processing industry. However, current industrial applications face two major challenges: traditional methods are costly, subjective, and labor-intensive, while mainstream deep learning models often struggle to balance detection accuracy and computational efficiency for edge deployment. To address these issues, this study proposes CFIS-YOLO, a lightweight object detection model optimized for edge devices. The model introduces an enhanced C2f structure, a dynamic feature recombination module, and a novel loss function that incorporates auxiliary bounding boxes and angular constraints. These innovations improve multi-scale feature fusion and small object localization while significantly reducing computational overhead. Evaluated on a public wood defect dataset, CFIS-YOLO achieves a mean Average Precision (mAP@0.5) of 77.5\\%, outperforming the baseline YOLOv10s by 4 percentage points. On SOPHON BM1684X edge devices, CFIS-YOLO delivers 135 FPS, reduces power consumption to 17.3\\% of the original implementation, and incurs only a 0.5 percentage point drop in mAP. These results demonstrate that CFIS-YOLO is a practical and effective solution for real-world wood defect detection in resource-constrained environments.', 'abstract_zh': '木材缺陷检测对于确保木制品加工业的质量控制至关重要。然而，当前工业应用面临两大挑战：传统方法成本高、主观性强且劳动密集；主流的深度学习模型往往难以在保持检测准确率的同时兼顾计算效率以适用于边缘部署。为解决这些问题，本研究提出了一种针对边缘设备优化的轻量化目标检测模型CFIS-YOLO。该模型引入了增强的C2f结构、动态特征重组模块以及新的损失函数，该损失函数结合了辅助边界框和角度约束。这些创新提高了多尺度特征融合和小目标定位能力，显著减少了计算开销。在公开的木材缺陷数据集上，CFIS-YOLO的mAP@0.5达到77.5%，比基准YOLOv10s高出4个百分点。在SOPHON BM1684X边缘设备上，CFIS-YOLO实现了135 FPS，将功耗降低至原实现的17.3%，同时mAP仅有0.5个百分点的下降。这些结果表明，CFIS-YOLO是适用于资源受限环境的实际有效解决方案。', 'title_zh': 'CFIS-YOLO：一种适用于边缘部署的多尺度融合轻量级木材缺陷检测网络'}
{'arxiv_id': 'arXiv:2504.11284', 'title': 'Bipartite Ranking From Multiple Labels: On Loss Versus Label Aggregation', 'authors': 'Michal Lukasik, Lin Chen, Harikrishna Narasimhan, Aditya Krishna Menon, Wittawat Jitkrittum, Felix X. Yu, Sashank J. Reddi, Gang Fu, Mohammadhossein Bateni, Sanjiv Kumar', 'link': 'https://arxiv.org/abs/2504.11284', 'abstract': 'Bipartite ranking is a fundamental supervised learning problem, with the goal of learning a ranking over instances with maximal area under the ROC curve (AUC) against a single binary target label. However, one may often observe multiple binary target labels, e.g., from distinct human annotators. How can one synthesize such labels into a single coherent ranking? In this work, we formally analyze two approaches to this problem -- loss aggregation and label aggregation -- by characterizing their Bayes-optimal solutions. Based on this, we show that while both methods can yield Pareto-optimal solutions, loss aggregation can exhibit label dictatorship: one can inadvertently (and undesirably) favor one label over others. This suggests that label aggregation can be preferable to loss aggregation, which we empirically verify.', 'abstract_zh': '双部图排序是监督学习中的一个基础问题，目标是在单一二元目标标签下最大化受试操作特征曲线面积（AUC）的实例排名学习。然而，人们常常会观察到多个二元目标标签，例如来自不同的手工标注者。如何将这些标签综合为一个一致的排名？在本文中，我们通过刻画这两种方法的贝叶斯最优解来正式分析合成这些标签为单一一致排名的问题——损失聚合和标签聚合。基于此，我们证明尽管两种方法都可以产生帕累托最优解，但损失聚合可能会表现出标签独裁：可能会无意中（且不希望地）偏好一个标签而忽视其他标签。这表明标签聚合可能比损失聚合更可取，我们在实验中证实了这一点。', 'title_zh': '多标签下的二部排名：损失函数与标签聚合的研究'}
{'arxiv_id': 'arXiv:2504.11268', 'title': 'Single-Input Multi-Output Model Merging: Leveraging Foundation Models for Dense Multi-Task Learning', 'authors': 'Juan Garcia Giraldo, Nikolaos Dimitriadis, Ke Wang, Pascal Frossard', 'link': 'https://arxiv.org/abs/2504.11268', 'abstract': 'Model merging is a flexible and computationally tractable approach to merge single-task checkpoints into a multi-task model. Prior work has solely focused on constrained multi-task settings where there is a one-to-one mapping between a sample and a task, overlooking the paradigm where multiple tasks may operate on the same sample, e.g., scene understanding. In this paper, we focus on the multi-task setting with single-input-multiple-outputs (SIMO) and show that it qualitatively differs from the single-input-single-output model merging settings studied in the literature due to the existence of task-specific decoders and diverse loss objectives. We identify that existing model merging methods lead to significant performance degradation, primarily due to representation misalignment between the merged encoder and task-specific decoders. We propose two simple and efficient fixes for the SIMO setting to re-align the feature representation after merging. Compared to joint fine-tuning, our approach is computationally effective and flexible, and sheds light into identifying task relationships in an offline manner. Experiments on NYUv2, Cityscapes, and a subset of the Taskonomy dataset demonstrate: (1) task arithmetic suffices to enable multi-task capabilities; however, the representations generated by the merged encoder has to be re-aligned with the task-specific heads; (2) the proposed architecture rivals traditional multi-task learning in performance but requires fewer samples and training steps by leveraging the existence of task-specific models.', 'abstract_zh': '模型融合是一种灵活且计算上可实现的方法，用于将单任务检查点合并为多任务模型。先前的工作仅专注于具有一对一样本和任务映射的受约束多任务设置，忽视了多个任务可能在同一样本上操作的范式，例如场景理解。在本文中，我们关注单输入多输出（SIMO）的多任务设置，并展示了它在文献中研究的单输入单输出模型融合设置中存在质的差异，这是由于任务特定解码器和多样性的损失目标的存在。我们发现现有的模型融合方法导致显著的性能下降，主要原因是合并后的编码器和任务特定解码器之间的表示不一致。我们为SIMO设置提出了两种简单的高效解决方案，以合并后重新对齐特征表示。与联合微调相比，我们的方法在计算效率和灵活性方面更具优势，并有助于离线识别任务关系。实验在NYUv2、Cityscapes以及Taskonomy数据集的部分子集上证明：（1）任务算术足以使模型具备多任务能力；然而，合并后的编码器生成的表示需要重新与任务特定头对齐；（2）所提出的架构在性能上与传统多任务学习相当，但由于利用了特定任务模型的存在，所需的样本数量和训练步骤更少。', 'title_zh': '单输入多输出模型融合：利用基础模型进行密集多任务学习'}
{'arxiv_id': 'arXiv:2504.11264', 'title': 'DeepSelective: Feature Gating and Representation Matching for Interpretable Clinical Prediction', 'authors': 'Ruochi Zhang, Qian Yang, Xiaoyang Wang, Haoran Wu, Qiong Zhou, Yu Wang, Kewei Li, Yueying Wang, Yusi Fan, Jiale Zhang, Lan Huang, Chang Liu, Fengfeng Zhou', 'link': 'https://arxiv.org/abs/2504.11264', 'abstract': 'The rapid accumulation of Electronic Health Records (EHRs) has transformed healthcare by providing valuable data that enhance clinical predictions and diagnoses. While conventional machine learning models have proven effective, they often lack robust representation learning and depend heavily on expert-crafted features. Although deep learning offers powerful solutions, it is often criticized for its lack of interpretability. To address these challenges, we propose DeepSelective, a novel end to end deep learning framework for predicting patient prognosis using EHR data, with a strong emphasis on enhancing model interpretability. DeepSelective combines data compression techniques with an innovative feature selection approach, integrating custom-designed modules that work together to improve both accuracy and interpretability. Our experiments demonstrate that DeepSelective not only enhances predictive accuracy but also significantly improves interpretability, making it a valuable tool for clinical decision-making. The source code is freely available at this http URL .', 'abstract_zh': '电子健康记录（EHR）的快速积累已通过提供增强临床预测和诊断的宝贵数据，彻底改变了医疗保健。尽管传统的机器学习模型已 proven 有效，但它们往往缺乏稳固的表示学习，并严重依赖专家设计的特征。虽然深度学习提供了强大的解决方案，但它常因缺乏可解释性而受到批评。为解决这些问题，我们提出了 DeepSelective——一种新颖的端到端深度学习框架，用于基于 EHR 数据预测患者预后，强调增强模型的可解释性。DeepSelective 结合了数据压缩技术与创新的功能选择方法，集成自定义设计的模块，共同提高准确性和可解释性。我们的实验表明，DeepSelective 不仅提高了预测准确性，还显著提升了可解释性，使其成为临床决策的重要工具。相关源代码已免费发布在该网址。', 'title_zh': 'DeepSelective: 特征门控与表示匹配的可解释临床预测'}
{'arxiv_id': 'arXiv:2504.11250', 'title': 'A Rollout-Based Algorithm and Reward Function for Efficient Resource Allocation in Business Processes', 'authors': 'Jeroen Middelhuis, Zaharah Bukhsh, Ivo Adan, Remco Dijkman', 'link': 'https://arxiv.org/abs/2504.11250', 'abstract': 'Resource allocation plays a critical role in minimizing cycle time and improving the efficiency of business processes. Recently, Deep Reinforcement Learning (DRL) has emerged as a powerful tool to optimize resource allocation policies in business processes. In the DRL framework, an agent learns a policy through interaction with the environment, guided solely by reward signals that indicate the quality of its decisions. However, existing algorithms are not suitable for dynamic environments such as business processes. Furthermore, existing DRL-based methods rely on engineered reward functions that approximate the desired objective, but a misalignment between reward and objective can lead to undesired decisions or suboptimal policies. To address these issues, we propose a rollout-based DRL algorithm and a reward function to optimize the objective directly. Our algorithm iteratively improves the policy by evaluating execution trajectories following different actions. Our reward function directly decomposes the objective function of minimizing the mean cycle time. Maximizing our reward function guarantees that the objective function is minimized without requiring extensive reward engineering. The results show that our method consistently learns the optimal policy in all six evaluated business processes, outperforming the state-of-the-art algorithm that can only learn the optimal policy in two of the evaluated processes.', 'abstract_zh': '资源分配在最小化周期时间并提高业务流程效率中发挥着关键作用。近年来，深度强化学习（DRL）成为优化业务流程中资源分配策略的强大工具。在DRL框架中，智能体通过与环境的交互学习策略，仅受奖励信号的指导，这些信号表明其决策的质量。然而，现有算法不适用于如业务流程等动态环境。此外，现有的基于DRL的方法依赖于近似目标的工程化奖励函数，但奖励与目标之间的不匹配可能导致不良决策或次优策略。为解决这些问题，我们提出了一种基于展开的DRL算法和直接优化目标的奖励函数。该算法通过评估不同动作执行轨迹的策略逐步改进。我们的奖励函数直接将最小化平均周期时间的目标函数分解。最大化我们的奖励函数保证了目标函数的最小化，无需大量奖励工程。实验结果表明，我们的方法在六个评估的业务流程中始终学习到了最优策略，优于只能在两种评估流程中学习到最优策略的最先进算法。', 'title_zh': '基于回放的算法及奖励函数在业务流程中高效资源分配'}
{'arxiv_id': 'arXiv:2504.11246', 'title': 'Respiratory Inhaler Sound Event Classification Using Self-Supervised Learning', 'authors': 'Davoud Shariat Panah, Alessandro N Franciosi, Cormac McCarthy, Andrew Hines', 'link': 'https://arxiv.org/abs/2504.11246', 'abstract': 'Asthma is a chronic respiratory condition that affects millions of people worldwide. While this condition can be managed by administering controller medications through handheld inhalers, clinical studies have shown low adherence to the correct inhaler usage technique. Consequently, many patients may not receive the full benefit of their medication. Automated classification of inhaler sounds has recently been studied to assess medication adherence. However, the existing classification models were typically trained using data from specific inhaler types, and their ability to generalize to sounds from different inhalers remains unexplored. In this study, we adapted the wav2vec 2.0 self-supervised learning model for inhaler sound classification by pre-training and fine-tuning this model on inhaler sounds. The proposed model shows a balanced accuracy of 98% on a dataset collected using a dry powder inhaler and smartwatch device. The results also demonstrate that re-finetuning this model on minimal data from a target inhaler is a promising approach to adapting a generic inhaler sound classification model to a different inhaler device and audio capture hardware. This is the first study in the field to demonstrate the potential of smartwatches as assistive technologies for the personalized monitoring of inhaler adherence using machine learning models.', 'abstract_zh': '哮喘是一种影响全世界数百万人的慢性呼吸道疾病。尽管可以通过手持吸入器给药控制该疾病，但临床研究显示患者正确使用吸入器的技术 adherence 较低，这可能导致患者未能充分发挥药物疗效。最近，吸入器声音的自动化分类已被研究以评估药物依从性。然而，现有的分类模型通常仅在特定吸入器类型的数据上进行训练，其在不同吸入器类型上通用性的能力尚未得到探索。在本研究中，我们通过在吸入器声音上进行预训练和微调来适应 wav2vec 2.0 自监督学习模型进行吸入器声音分类。提出的新模型在使用干粉吸入器和智能手表设备收集的数据集上达到了 98% 的平衡准确率。研究结果还表明，通过少量目标吸入器数据对模型进行再微调是将通用的吸入器声音分类模型适应到不同吸入器设备和音频采集硬件的一种有前景的方法。这是该领域首项展示了智能手表作为机器学习模型辅助技术，用于个性化监测吸入器依从性的潜力的研究。', 'title_zh': '基于自监督学习的呼吸吸入器声音事件分类'}
{'arxiv_id': 'arXiv:2504.11245', 'title': 'Influence Maximization in Temporal Social Networks with a Cold-Start Problem: A Supervised Approach', 'authors': 'Laixin Xie, Ying Zhang, Xiyuan Wang, Shiyi Liu, Shenghan Gao, Xingxing Xing, Wei Wan, Haipeng Zhang, Quan Li', 'link': 'https://arxiv.org/abs/2504.11245', 'abstract': 'Influence Maximization (IM) in temporal graphs focuses on identifying influential "seeds" that are pivotal for maximizing network expansion. We advocate defining these seeds through Influence Propagation Paths (IPPs), which is essential for scaling up the network. Our focus lies in efficiently labeling IPPs and accurately predicting these seeds, while addressing the often-overlooked cold-start issue prevalent in temporal networks. Our strategy introduces a motif-based labeling method and a tensorized Temporal Graph Network (TGN) tailored for multi-relational temporal graphs, bolstering prediction accuracy and computational efficiency. Moreover, we augment cold-start nodes with new neighbors from historical data sharing similar IPPs. The recommendation system within an online team-based gaming environment presents subtle impact on the social network, forming multi-relational (i.e., weak and strong) temporal graphs for our empirical IM study. We conduct offline experiments to assess prediction accuracy and model training efficiency, complemented by online A/B testing to validate practical network growth and the effectiveness in addressing the cold-start issue.', 'abstract_zh': '时效网络中的影响力最大化（IM）旨在识别对网络扩展至关重要的“种子”节点。我们提倡通过影响传播路径（IPPs）来定义这些种子节点，这对于扩展网络至关重要。我们的重点在于高效地标记IPPs并准确预测这些种子节点，同时应对时效网络中普遍存在的冷启动问题。我们提出的策略包括基于模式的标记方法和适用于多关系时效图的张量化时效图网络（TGN），这提高了预测准确性和计算效率。此外，我们通过从历史数据中添加具有相似IPP的新邻居来增强冷启动节点。在线团队游戏环境中推荐系统的影响力在社会网络中表现微妙，形成了多关系（即弱关系和强关系）时效图，用于我们的实证IM研究。我们进行离线实验评估预测准确性和模型训练效率，并结合在线A/B测试验证实际网络扩展的有效性和解决冷启动问题的实用性。', 'title_zh': '冷启动问题下Temporal社交网络中的影响力最大化：一种监督方法'}
{'arxiv_id': 'arXiv:2504.11216', 'title': 'Diversity-Driven Learning: Tackling Spurious Correlations and Data Heterogeneity in Federated Models', 'authors': 'Gergely D. Németh, Eros Fanì, Yeat Jeng Ng, Barbara Caputo, Miguel Ángel Lozano, Nuria Oliver, Novi Quadrianto', 'link': 'https://arxiv.org/abs/2504.11216', 'abstract': "Federated Learning (FL) enables decentralized training of machine learning models on distributed data while preserving privacy. However, in real-world FL settings, client data is often non-identically distributed and imbalanced, resulting in statistical data heterogeneity which impacts the generalization capabilities of the server's model across clients, slows convergence and reduces performance. In this paper, we address this challenge by first proposing a characterization of statistical data heterogeneity by means of 6 metrics of global and client attribute imbalance, class imbalance, and spurious correlations. Next, we create and share 7 computer vision datasets for binary and multiclass image classification tasks in Federated Learning that cover a broad range of statistical data heterogeneity and hence simulate real-world situations. Finally, we propose FedDiverse, a novel client selection algorithm in FL which is designed to manage and leverage data heterogeneity across clients by promoting collaboration between clients with complementary data distributions. Experiments on the seven proposed FL datasets demonstrate FedDiverse's effectiveness in enhancing the performance and robustness of a variety of FL methods while having low communication and computational overhead.", 'abstract_zh': '联邦学习（FL）通过在分布式数据上进行去中心化训练来保持隐私，同时训练机器学习模型。然而，在实际的FL设置中，客户端数据往往是非同分布且不平衡的，导致统计数据异质性，影响服务器模型在客户端之间的泛化能力，减缓收敛速度并降低性能。本文通过首先提出使用6个全局和客户端属性不平衡、类别不平衡以及假相关性的指标来表征统计数据异质性，接着创建并共享了7个用于二分类和多分类图像识别任务的联邦学习数据集，模拟了广泛的统计数据异质性情况，最后提出了FedDiverse，一种用于联邦学习的新型客户端选择算法，通过促进具有互补数据分布的客户端之间的协作来管理和利用数据异质性。实验结果表明，FedDiverse在多种FL方法中提高了性能和 robustness，同时具有较低的通信和计算开销。', 'title_zh': '多样性驱动的学习：应对联邦模型中的假相关和数据异质性'}
{'arxiv_id': 'arXiv:2504.11197', 'title': 'Efficient Distributed Retrieval-Augmented Generation for Enhancing Language Model Performance', 'authors': 'Shangyu Liu, Zhenzhe Zheng, Xiaoyao Huang, Fan Wu, Jie Wu', 'link': 'https://arxiv.org/abs/2504.11197', 'abstract': 'Small language models (SLMs) support efficient deployments on resource-constrained edge devices, but their limited capacity compromises inference performance. Retrieval-augmented generation (RAG) is a promising solution to enhance model performance by integrating external databases, without requiring intensive on-device model retraining. However, large-scale public databases and user-specific private contextual documents are typically located on the cloud and the device separately, while existing RAG implementations are primarily centralized. To bridge this gap, we propose DRAGON, a distributed RAG framework to enhance on-device SLMs through both general and personal knowledge without the risk of leaking document privacy. Specifically, DRAGON decomposes multi-document RAG into multiple parallel token generation processes performed independently and locally on the cloud and the device, and employs a newly designed Speculative Aggregation, a dual-side speculative algorithm to avoid frequent output synchronization between the cloud and device. A new scheduling algorithm is further introduced to identify the optimal aggregation side based on real-time network conditions. Evaluations on real-world hardware testbed demonstrate a significant performance improvement of DRAGON-up to 1.9x greater gains over standalone SLM compared to the centralized RAG, substantial reduction in per-token latency, and negligible Time to First Token (TTFT) overhead.', 'abstract_zh': '分布式RAG框架DRAGON：增强边缘设备上小语言模型的通用和私人知识而不泄露文档隐私', 'title_zh': '高效的分布式检索增强生成方法以提升语言模型性能'}
{'arxiv_id': 'arXiv:2504.11186', 'title': 'Benchmarking Next-Generation Reasoning-Focused Large Language Models in Ophthalmology: A Head-to-Head Evaluation on 5,888 Items', 'authors': 'Minjie Zou, Sahana Srinivasan, Thaddaeus Wai Soon Lo, Ke Zou, Gabriel Dawei Yang, Xuguang Ai, Hyunjae Kim, Maxwell Singer, Fares Antaki, Kelvin Li, Robert Chang, Marcus Tan, David Ziyou Chen, Dianbo Liu, Qingyu Chen, Yih Chung Tham', 'link': 'https://arxiv.org/abs/2504.11186', 'abstract': 'Recent advances in reasoning-focused large language models (LLMs) mark a shift from general LLMs toward models designed for complex decision-making, a crucial aspect in medicine. However, their performance in specialized domains like ophthalmology remains underexplored. This study comprehensively evaluated and compared the accuracy and reasoning capabilities of four newly developed reasoning-focused LLMs, namely DeepSeek-R1, OpenAI o1, o3-mini, and Gemini 2.0 Flash-Thinking. Each model was assessed using 5,888 multiple-choice ophthalmology exam questions from the MedMCQA dataset in zero-shot setting. Quantitative evaluation included accuracy, Macro-F1, and five text-generation metrics (ROUGE-L, METEOR, BERTScore, BARTScore, and AlignScore), computed against ground-truth reasonings. Average inference time was recorded for a subset of 100 randomly selected questions. Additionally, two board-certified ophthalmologists qualitatively assessed clarity, completeness, and reasoning structure of responses to differential diagnosis questions.O1 (0.902) and DeepSeek-R1 (0.888) achieved the highest accuracy, with o1 also leading in Macro-F1 (0.900). The performance of models across the text-generation metrics varied: O3-mini excelled in ROUGE-L (0.151), o1 in METEOR (0.232), DeepSeek-R1 and o3-mini tied for BERTScore (0.673), DeepSeek-R1 (-4.105) and Gemini 2.0 Flash-Thinking (-4.127) performed best in BARTScore, while o3-mini (0.181) and o1 (0.176) led AlignScore. Inference time across the models varied, with DeepSeek-R1 being slowest (40.4 seconds) and Gemini 2.0 Flash-Thinking fastest (6.7 seconds). Qualitative evaluation revealed that DeepSeek-R1 and Gemini 2.0 Flash-Thinking tended to provide detailed and comprehensive intermediate reasoning, whereas o1 and o3-mini displayed concise and summarized justifications.', 'abstract_zh': '近期面向推理的大语言模型进展：从通用大语言模型向复杂决策模型的转变在医学领域中的应用——以眼科专业应用为例', 'title_zh': '眼科领域下一代推理导向大语言模型基准测试：5,888个项目一对一评估'}
{'arxiv_id': 'arXiv:2504.11182', 'title': 'Exploring Backdoor Attack and Defense for LLM-empowered Recommendations', 'authors': 'Liangbo Ning, Wenqi Fan, Qing Li', 'link': 'https://arxiv.org/abs/2504.11182', 'abstract': "The fusion of Large Language Models (LLMs) with recommender systems (RecSys) has dramatically advanced personalized recommendations and drawn extensive attention. Despite the impressive progress, the safety of LLM-based RecSys against backdoor attacks remains largely under-explored. In this paper, we raise a new problem: Can a backdoor with a specific trigger be injected into LLM-based Recsys, leading to the manipulation of the recommendation responses when the backdoor trigger is appended to an item's title? To investigate the vulnerabilities of LLM-based RecSys under backdoor attacks, we propose a new attack framework termed Backdoor Injection Poisoning for RecSys (BadRec). BadRec perturbs the items' titles with triggers and employs several fake users to interact with these items, effectively poisoning the training set and injecting backdoors into LLM-based RecSys. Comprehensive experiments reveal that poisoning just 1% of the training data with adversarial examples is sufficient to successfully implant backdoors, enabling manipulation of recommendations. To further mitigate such a security threat, we propose a universal defense strategy called Poison Scanner (P-Scanner). Specifically, we introduce an LLM-based poison scanner to detect the poisoned items by leveraging the powerful language understanding and rich knowledge of LLMs. A trigger augmentation agent is employed to generate diverse synthetic triggers to guide the poison scanner in learning domain-specific knowledge of the poisoned item detection task. Extensive experiments on three real-world datasets validate the effectiveness of the proposed P-Scanner.", 'abstract_zh': 'LLMs与推荐系统融合的安全性研究：针对后门攻击的Backdoor Injection Poisoning for RecSys（BadRec）与通用防御策略P-Scanner探究', 'title_zh': '探索由大规模语言模型赋能的推荐系统中的后门攻击与防御'}
{'arxiv_id': 'arXiv:2504.11171', 'title': 'TerraMind: Large-Scale Generative Multimodality for Earth Observation', 'authors': 'Johannes Jakubik, Felix Yang, Benedikt Blumenstiel, Erik Scheurer, Rocco Sedona, Stefano Maurogiovanni, Jente Bosmans, Nikolaos Dionelis, Valerio Marsocci, Niklas Kopp, Rahul Ramachandran, Paolo Fraccaro, Thomas Brunschwiler, Gabriele Cavallaro, Juan Bernabe-Moreno, Nicolas Longépé', 'link': 'https://arxiv.org/abs/2504.11171', 'abstract': 'We present TerraMind, the first any-to-any generative, multimodal foundation model for Earth observation (EO). Unlike other multimodal models, TerraMind is pretrained on dual-scale representations combining both token-level and pixel-level data across modalities. On a token level, TerraMind encodes high-level contextual information to learn cross-modal relationships, while on a pixel level, TerraMind leverages fine-grained representations to capture critical spatial nuances. We pretrained TerraMind on nine geospatial modalities of a global, large-scale dataset. In this paper, we demonstrate that (i) TerraMind\'s dual-scale early fusion approach unlocks a range of zero-shot and few-shot applications for Earth observation, (ii) TerraMind introduces "Thinking-in-Modalities" (TiM) -- the capability of generating additional artificial data during finetuning and inference to improve the model output -- and (iii) TerraMind achieves beyond state-of-the-art performance in community-standard benchmarks for EO like PANGAEA. The pretraining dataset, the model weights, and our code is open-sourced under a permissive license.', 'abstract_zh': 'We呈现TerraMind：一种用于地球观测的首个多尺度生成型多模态基础模型', 'title_zh': 'TerraMind: 大规模生成多模态地球观测'}
{'arxiv_id': 'arXiv:2504.11169', 'title': 'MuSeD: A Multimodal Spanish Dataset for Sexism Detection in Social Media Videos', 'authors': 'Laura De Grazia, Pol Pastells, Mauro Vázquez Chas, Desmond Elliott, Danae Sánchez Villegas, Mireia Farrús, Mariona Taulé', 'link': 'https://arxiv.org/abs/2504.11169', 'abstract': 'Sexism is generally defined as prejudice and discrimination based on sex or gender, affecting every sector of society, from social institutions to relationships and individual behavior. Social media platforms amplify the impact of sexism by conveying discriminatory content not only through text but also across multiple modalities, highlighting the critical need for a multimodal approach to the analysis of sexism online. With the rise of social media platforms where users share short videos, sexism is increasingly spreading through video content. Automatically detecting sexism in videos is a challenging task, as it requires analyzing the combination of verbal, audio, and visual elements to identify sexist content. In this study, (1) we introduce MuSeD, a new Multimodal Spanish dataset for Sexism Detection consisting of $\\approx$ 11 hours of videos extracted from TikTok and BitChute; (2) we propose an innovative annotation framework for analyzing the contribution of textual and multimodal labels in the classification of sexist and non-sexist content; and (3) we evaluate a range of large language models (LLMs) and multimodal LLMs on the task of sexism detection. We find that visual information plays a key role in labeling sexist content for both humans and models. Models effectively detect explicit sexism; however, they struggle with implicit cases, such as stereotypes, instances where annotators also show low agreement. This highlights the inherent difficulty of the task, as identifying implicit sexism depends on the social and cultural context.', 'abstract_zh': '性别歧视通常被定义为基于性别的偏见和歧视，影响社会的每一个领域，从社会机构到人际关系和个人行为。社交媒体平台通过不仅以文本形式还通过多种模态传播歧视性内容，强调了在线性别歧视分析的多模态方法的迫切需要。随着用户分享短视频的社交媒体平台兴起，性别歧视内容的传播越来越多地通过视频内容进行。自动检测视频中的性别歧视是一项具有挑战性的任务，因为它需要分析口头、音频和视觉元素的组合来识别性别歧视内容。在本研究中，(1) 我们介绍了MuSeD，一个包含源自TikTok和BitChute的约11小时视频的新多模态西班牙语性别歧视检测数据集；(2) 我们提出了一种创新的注释框架，用于分析文本标签和多模态标签在歧视性和非歧视性内容分类中的贡献；(3) 我们评估了一系列大规模语言模型（LLMs）和多模态LLMs在性别歧视检测任务中的性能。我们发现视觉信息在人类和模型标注性别歧视内容中起着关键作用。模型能够有效检测显性性别歧视；然而，它们在处理隐性案例，如刻板印象等方面存在困难，这些问题上注释者也表现出低一致性。这突显了该任务内在的难度，因为识别隐性性别歧视依赖于社会和文化背景。', 'title_zh': 'MuSeD: 用于社交媒体视频中性别歧视检测的多模态西班牙语数据集'}
{'arxiv_id': 'arXiv:2504.11168', 'title': 'Bypassing Prompt Injection and Jailbreak Detection in LLM Guardrails', 'authors': 'William Hackett, Lewis Birch, Stefan Trawicki, Neeraj Suri, Peter Garraghan', 'link': 'https://arxiv.org/abs/2504.11168', 'abstract': "Large Language Models (LLMs) guardrail systems are designed to protect against prompt injection and jailbreak attacks. However, they remain vulnerable to evasion techniques. We demonstrate two approaches for bypassing LLM prompt injection and jailbreak detection systems via traditional character injection methods and algorithmic Adversarial Machine Learning (AML) evasion techniques. Through testing against six prominent protection systems, including Microsoft's Azure Prompt Shield and Meta's Prompt Guard, we show that both methods can be used to evade detection while maintaining adversarial utility achieving in some instances up to 100% evasion success. Furthermore, we demonstrate that adversaries can enhance Attack Success Rates (ASR) against black-box targets by leveraging word importance ranking computed by offline white-box models. Our findings reveal vulnerabilities within current LLM protection mechanisms and highlight the need for more robust guardrail systems.", 'abstract_zh': '大型语言模型的护栏系统设计用于防范提示注入和 Jailbreak 攻击，但仍然容易受到欺骗技术的攻击。我们展示了通过传统字符注入方法和算法对抗机器学习（AML）欺骗技术绕过大型语言模型提示注入和检测系统的两种方法。通过针对包括微软的 Azure Prompt Shield 和 Meta 的 Prompt Guard 在内的六种主流保护系统进行测试，我们表明这两种方法可以在不牺牲对抗效用的情况下逃避检测，并在某些情况下实现 100% 的欺骗成功率。此外，我们展示了攻击者可以通过利用离线白盒模型计算的单词重要性排名来增强针对黑盒目标的攻击成功率（ASR）。我们的发现揭示了当前大型语言模型保护机制中的漏洞，并强调了需要更 robust 的护栏系统的必要性。', 'title_zh': '绕过提示注入和LLM护栏中的 Jailbreak 检测'}
{'arxiv_id': 'arXiv:2504.11160', 'title': 'DMAGaze: Gaze Estimation Based on Feature Disentanglement and Multi-Scale Attention', 'authors': 'Haohan Chen, Hongjia Liu, Shiyong Lan, Wenwu Wang, Yixin Qiao, Yao Li, Guonan Deng', 'link': 'https://arxiv.org/abs/2504.11160', 'abstract': 'Gaze estimation, which predicts gaze direction, commonly faces the challenge of interference from complex gaze-irrelevant information in face images. In this work, we propose DMAGaze, a novel gaze estimation framework that exploits information from facial images in three aspects: gaze-relevant global features (disentangled from facial image), local eye features (extracted from cropped eye patch), and head pose estimation features, to improve overall performance. Firstly, we design a new continuous mask-based Disentangler to accurately disentangle gaze-relevant and gaze-irrelevant information in facial images by achieving the dual-branch disentanglement goal through separately reconstructing the eye and non-eye regions. Furthermore, we introduce a new cascaded attention module named Multi-Scale Global Local Attention Module (MS-GLAM). Through a customized cascaded attention structure, it effectively focuses on global and local information at multiple scales, further enhancing the information from the Disentangler. Finally, the global gaze-relevant features disentangled by the upper face branch, combined with head pose and local eye features, are passed through the detection head for high-precision gaze estimation. Our proposed DMAGaze has been extensively validated on two mainstream public datasets, achieving state-of-the-art performance.', 'abstract_zh': 'DMAGaze：一种多视角解耦的眼球追踪框架', 'title_zh': 'DMAGaze：基于特征解缠和多尺度注意力的眼球估计'}
{'arxiv_id': 'arXiv:2504.11130', 'title': 'Divergence of Empirical Neural Tangent Kernel in Classification Problems', 'authors': 'Zixiong Yu, Songtao Tian, Guhan Chen', 'link': 'https://arxiv.org/abs/2504.11130', 'abstract': 'This paper demonstrates that in classification problems, fully connected neural networks (FCNs) and residual neural networks (ResNets) cannot be approximated by kernel logistic regression based on the Neural Tangent Kernel (NTK) under overtraining (i.e., when training time approaches infinity). Specifically, when using the cross-entropy loss, regardless of how large the network width is (as long as it is finite), the empirical NTK diverges from the NTK on the training samples as training time increases. To establish this result, we first demonstrate the strictly positive definiteness of the NTKs for multi-layer FCNs and ResNets. Then, we prove that during training, % with the cross-entropy loss, the neural network parameters diverge if the smallest eigenvalue of the empirical NTK matrix (Gram matrix) with respect to training samples is bounded below by a positive constant. This behavior contrasts sharply with the lazy training regime commonly observed in regression problems. Consequently, using a proof by contradiction, we show that the empirical NTK does not uniformly converge to the NTK across all times on the training samples as the network width increases. We validate our theoretical results through experiments on both synthetic data and the MNIST classification task. This finding implies that NTK theory is not applicable in this context, with significant theoretical implications for understanding neural networks in classification problems.', 'abstract_zh': '这篇论文展示了在分类问题中，完全连接神经网络（FCNs）和残差神经网络（ResNets）在过拟合情况下（即训练时间趋近于无穷大）不能被神经领域核（NTK）基于核逻辑回归逼近。具体而言，使用交叉熵损失函数时，无论网络宽度多大（只要不是无限大），训练时间增加时经验NTK将远离训练样本上的NTK。为了得出这一结果，我们首先证明了多层FCNs和ResNets的NTK严格正定性。然后我们证明，在使用交叉熵损失函数训练过程中，如果训练样本的经验NTK矩阵（Gram矩阵）的最小特征值被正常数下界限制，则神经网络参数会发散。这种行为与回归问题中常见的惰性训练阶段形成了鲜明对比。通过反证法，我们证明随着网络宽度的增加，经验NTK在训练样本上不一致地收敛到NTK。通过在合成数据和MNIST分类任务上的实验验证了我们的理论结果。这一发现表明NTK理论在此上下文中不适用，对理解分类问题中的神经网络具有重要的理论意义。', 'title_zh': '分类问题中经验神经 tangent 核的发散性'}
{'arxiv_id': 'arXiv:2504.11109', 'title': 'Fine-Tuning Large Language Models on Quantum Optimization Problems for Circuit Generation', 'authors': 'Linus Jern, Valter Uotila, Cong Yu, Bo Zhao', 'link': 'https://arxiv.org/abs/2504.11109', 'abstract': 'Large language models (LLM) have achieved remarkable outcomes in addressing complex problems, including math, coding, and analyzing large amounts of scientific reports. Yet few works have explored the potential of LLM in quantum computing. The most challenging problem is how to leverage LLMs to automatically generate quantum circuits at a large scale. In this paper, we address such a challenge by fine-tuning LLMs and injecting the domain-specific knowledge of quantum computing. In particular, we investigate the mechanisms to generate training data sets and construct the end-to-end pipeline to fine-tune pre-trained LLMs that produce parameterized quantum circuits for optimization problems. We have prepared 14,000 quantum circuits covering a substantial part of the quantum optimization landscape: 12 optimization problem instances and their optimized QAOA, VQE, and adaptive VQE circuits. The fine-tuned LLMs can construct syntactically correct parametrized quantum circuits in the most recent OpenQASM 3.0. We have evaluated the quality of the parameters by comparing them to the optimized expectation values and distributions. Our evaluation shows that the fine-tuned LLM outperforms state-of-the-art models and that the parameters are better than random. The LLM-generated parametrized circuits and initial parameters can be used as a starting point for further optimization, \\emph{e.g.,} templates in quantum machine learning and the benchmark for compilers and hardware.', 'abstract_zh': '大规模语言模型（LLM）在解决数学、编码以及分析大量科学报告等复杂问题方面取得了显著成果。然而，很少有研究探索LLM在量子计算领域的潜力。最大的挑战是利用LLM自动生成大规模的量子电路。在本文中，我们通过微调LLM并注入量子计算领域的专业知识来应对这一挑战。特别是，我们研究了生成训练数据集的机制，并构建了从预训练LLM到生成优化问题参数化量子电路的端到端管道。我们准备了14,000个涵盖量子优化大部分景观的量子电路：12个优化问题实例及其优化的QAOA、VQE和自适应VQE电路。微调后的LLM能够构建语法正确的参数化量子电路，符合最新的OpenQASM 3.0标准。我们通过与优化的期望值和分布进行比较，评估了参数的质量。我们的评估表明，微调后的LLM优于现有顶级模型，且参数优于随机生成的。LLM生成的参数化电路及其初始参数可以作为进一步优化的起点，例如量子机器学习中的模板，以及编译器和硬件的基准。', 'title_zh': '基于量子优化问题的大规模语言模型微调以生成电路'}
{'arxiv_id': 'arXiv:2504.11091', 'title': 'AI-guided Antibiotic Discovery Pipeline from Target Selection to Compound Identification', 'authors': 'Maximilian G. Schuh, Joshua Hesse, Stephan A. Sieber', 'link': 'https://arxiv.org/abs/2504.11091', 'abstract': 'Antibiotic resistance presents a growing global health crisis, demanding new therapeutic strategies that target novel bacterial mechanisms. Recent advances in protein structure prediction and machine learning-driven molecule generation offer a promising opportunity to accelerate drug discovery. However, practical guidance on selecting and integrating these models into real-world pipelines remains limited. In this study, we develop an end-to-end, artificial intelligence-guided antibiotic discovery pipeline that spans target identification to compound realization. We leverage structure-based clustering across predicted proteomes of multiple pathogens to identify conserved, essential, and non-human-homologous targets. We then systematically evaluate six leading 3D-structure-aware generative models$\\unicode{x2014}$spanning diffusion, autoregressive, graph neural network, and language model architectures$\\unicode{x2014}$on their usability, chemical validity, and biological relevance. Rigorous post-processing filters and commercial analogue searches reduce over 100 000 generated compounds to a focused, synthesizable set. Our results highlight DeepBlock and TamGen as top performers across diverse criteria, while also revealing critical trade-offs between model complexity, usability, and output quality. This work provides a comparative benchmark and blueprint for deploying artificial intelligence in early-stage antibiotic development.', 'abstract_zh': '抗生素耐药性构成了日益严峻的全球健康危机，需要针对新型细菌机制的新治疗策略。近年来，基于蛋白质结构预测和机器学习驱动的分子生成技术为加速药物发现提供了新的机会。然而，关于如何选择和将这些模型整合到实际工作流程中的实用指导仍显不足。在本研究中，我们开发了一个从靶标识别到化合物实现的端到端、人工智能引导的抗生素发现管道。我们利用针对多种病原体预测蛋白质组的结构基团聚类来识别保守、必不可少且非人类同源的靶标。然后，我们系统地评估了六种领先的空间结构感知生成模型——包括扩散模型、自回归模型、图神经网络和语言模型架构——的可使用性、化学合理性和生物学相关性。严格的后处理过滤和商业同系物搜索将超过100,000个生成化合物缩减为一个集中且可合成的集合。我们的结果强调了DeepBlock和TamGen在多种标准下的表现最佳，同时也揭示了模型复杂性、可使用性和输出质量之间的关键权衡。本研究提供了人工智能在早期抗生素开发中应用的比较基准和蓝图。', 'title_zh': 'AI引导的从靶标选择到化合物鉴定的抗生素发现流程'}
{'arxiv_id': 'arXiv:2504.11083', 'title': 'QAMA: Quantum annealing multi-head attention operator with classical deep learning framework', 'authors': 'Peng Du, Shuolei Wang, Shicheng Li, Jinjing Shi', 'link': 'https://arxiv.org/abs/2504.11083', 'abstract': 'As large language models scale up, the conventional attention mechanism faces critical challenges of exponential growth in memory consumption and energy costs. Quantum annealing computing, with its inherent advantages in computational efficiency and low energy consumption, offers an innovative direction for constructing novel deep learning architectures. This study proposes the first Quantum Annealing-based Multi-head Attention (QAMA) mechanism, achieving seamless compatibility with classical attention architectures through quadratic unconstrained binary optimization (QUBO) modeling of forward propagation and energy-based backpropagation. The method innovatively leverages the quantum bit interaction characteristics of Ising models to optimize the conventional $O(n^2)$ spatiotemporal complexity into linear resource consumption. Integrated with the optical computing advantages of coherent Ising machines (CIM), the system maintains millisecond-level real-time responsiveness while significantly reducing energy consumption. Our key contributions include: Theoretical proofs establish QAMA mathematical equivalence to classical attention mechanisms; Dual optimization of multi-head specificity and long-range information capture via QUBO constraints; Explicit gradient proofs for the Ising energy equation are utilized to implement gradient conduction as the only path in the computational graph as a layer; Proposed soft selection mechanism overcoming traditional binary attention limitations to approximate continuous weights. Experiments on QBoson CPQC quantum computer show QAMA achieves comparable accuracy to classical operators while reducing inference time to millisecond level and improving solution quality. This work pioneers architectural-level integration of quantum computing and deep learning, applicable to any attention-based model, driving paradigm innovation in AI foundational computing.', 'abstract_zh': '基于量子退火的多头注意力机制（QAMA）：实现经典注意力架构的无缝兼容与线性资源消耗', 'title_zh': 'QAMA: 量子退火多头注意力运算器与经典深度学习框架'}
{'arxiv_id': 'arXiv:2504.11082', 'title': 'DeepMLF: Multimodal language model with learnable tokens for deep fusion in sentiment analysis', 'authors': 'Efthymios Georgiou, Vassilis Katsouros, Yannis Avrithis, Alexandros Potamianos', 'link': 'https://arxiv.org/abs/2504.11082', 'abstract': "While multimodal fusion has been extensively studied in Multimodal Sentiment Analysis (MSA), the role of fusion depth and multimodal capacity allocation remains underexplored. In this work, we position fusion depth, scalability, and dedicated multimodal capacity as primary factors for effective fusion. We introduce DeepMLF, a novel multimodal language model (LM) with learnable tokens tailored toward deep fusion. DeepMLF leverages an audiovisual encoder and a pretrained decoder LM augmented with multimodal information across its layers. We append learnable tokens to the LM that: 1) capture modality interactions in a controlled fashion and 2) preserve independent information flow for each modality. These fusion tokens gather linguistic information via causal self-attention in LM Blocks and integrate with audiovisual information through cross-attention MM Blocks. Serving as dedicated multimodal capacity, this design enables progressive fusion across multiple layers, providing depth in the fusion process. Our training recipe combines modality-specific losses and language modelling loss, with the decoder LM tasked to predict ground truth polarity. Across three MSA benchmarks with varying dataset characteristics, DeepMLF achieves state-of-the-art performance. Our results confirm that deeper fusion leads to better performance, with optimal fusion depths (5-7) exceeding those of existing approaches. Additionally, our analysis on the number of fusion tokens reveals that small token sets ($\\sim$20) achieve optimal performance. We examine the importance of representation learning order (fusion curriculum) through audiovisual encoder initialization experiments. Our ablation studies demonstrate the superiority of the proposed fusion design and gating while providing a holistic examination of DeepMLF's scalability to LLMs, and the impact of each training objective and embedding regularization.", 'abstract_zh': '多模态融合深度与容量分配在多模态情感分析中的研究：DeepMLF模型的设计与分析', 'title_zh': 'DeepMLF：具有可学习令牌的多模态语言模型在情感分析中的深度融合'}
{'arxiv_id': 'arXiv:2504.11074', 'title': 'Dynamical errors in machine learning forecasts', 'authors': 'Zhou Fang, Gianmarco Mengaldo', 'link': 'https://arxiv.org/abs/2504.11074', 'abstract': 'In machine learning forecasting, standard error metrics such as mean absolute error (MAE) and mean squared error (MSE) quantify discrepancies between predictions and target values. However, these metrics do not directly evaluate the physical and/or dynamical consistency of forecasts, an increasingly critical concern in scientific and engineering applications.\nIndeed, a fundamental yet often overlooked question is whether machine learning forecasts preserve the dynamical behavior of the underlying system. Addressing this issue is essential for assessing the fidelity of machine learning models and identifying potential failure modes, particularly in applications where maintaining correct dynamical behavior is crucial.\nIn this work, we investigate the relationship between standard forecasting error metrics, such as MAE and MSE, and the dynamical properties of the underlying system. To achieve this goal, we use two recently developed dynamical indices: the instantaneous dimension ($d$), and the inverse persistence ($\\theta$). Our results indicate that larger forecast errors -- e.g., higher MSE -- tend to occur in states with higher $d$ (higher complexity) and higher $\\theta$ (lower persistence). To further assess dynamical consistency, we propose error metrics based on the dynamical indices that measure the discrepancy of the forecasted $d$ and $\\theta$ versus their correct values. Leveraging these dynamical indices-based metrics, we analyze direct and recursive forecasting strategies for three canonical datasets -- Lorenz, Kuramoto-Sivashinsky equation, and Kolmogorov flow -- as well as a real-world weather forecasting task. Our findings reveal substantial distortions in dynamical properties in ML forecasts, especially for long forecast lead times or long recursive simulations, providing complementary information on ML forecast fidelity that can be used to improve ML models.', 'abstract_zh': '在机器学习预测中，标准误差指标如均方误差（MSE）和均绝对误差（MAE）量度了预测值与目标值之间的差异，但这些指标没有直接评估 forecasts 的物理和/或动力学一致性，这对于科学和工程应用来说越来越成为一个关键问题。实际上，一个基础但常被忽视的问题是机器学习预测是否保留了底层系统的动力学行为。解决这一问题对于评估机器学习模型的保真度和识别潜在故障模式至关重要，特别是在必须保持正确动力学行为的应用中。在本文中，我们研究了标准预测误差指标（如 MSE 和 MAE）与底层系统动力学属性之间的关系。为此，我们使用了两个 recently 开发的动力学指标：瞬时维度 ($d$) 和逆持续性 ($\\theta$)。结果显示，较大的预测误差（例如，较高的 MSE）倾向于出现在更高 $d$（更高复杂度）和更高 $\\theta$（更低持续性）的状态中。为了进一步评估动力学一致性，我们提出了基于动力学指标的误差指标，这些指标测量了 forecasted $d$ 和 $\\theta$ 与其正确值之间的差异。利用这些基于动力学指标的指标，我们分析了三维标准数据集（洛伦兹系统、库拉莫托-西凡夏系统方程和柯尔莫哥洛夫流动）以及实际天气预报任务的直接和递归预报策略。我们的发现揭示了在机器学习预测中动力学属性的显著失真，尤其是在较长预测时效或较长递归模拟中，提供了关于机器学习预测保真度的补充信息，可用于改进机器学习模型。', 'title_zh': '机器学习预测中的动态误差'}
{'arxiv_id': 'arXiv:2504.11045', 'title': 'Neural Control Barrier Functions from Physics Informed Neural Networks', 'authors': 'Shreenabh Agrawal, Manan Tayal, Aditya Singh, Shishir Kolathaya', 'link': 'https://arxiv.org/abs/2504.11045', 'abstract': "As autonomous systems become increasingly prevalent in daily life, ensuring their safety is paramount. Control Barrier Functions (CBFs) have emerged as an effective tool for guaranteeing safety; however, manually designing them for specific applications remains a significant challenge. With the advent of deep learning techniques, recent research has explored synthesizing CBFs using neural networks-commonly referred to as neural CBFs. This paper introduces a novel class of neural CBFs that leverages a physics-inspired neural network framework by incorporating Zubov's Partial Differential Equation (PDE) within the context of safety. This approach provides a scalable methodology for synthesizing neural CBFs applicable to high-dimensional systems. Furthermore, by utilizing reciprocal CBFs instead of zeroing CBFs, the proposed framework allows for the specification of flexible, user-defined safe regions. To validate the effectiveness of the approach, we present case studies on three different systems: an inverted pendulum, autonomous ground navigation, and aerial navigation in obstacle-laden environments.", 'abstract_zh': '随着自主系统在日常生活中越来越普遍，确保其安全性变得至关重要。控制屏障函数（CBFs）已成为确保安全的有效工具；然而，为特定应用手动设计它们仍然是一个重大挑战。随着深度学习技术的发展，近期研究探索了使用神经网络合成CBFs的方法——通常称为神经CBFs。本文介绍了一类新颖的神经CBFs，通过在安全性框架中引入Zubov的部分微分方程（PDE），利用物理启发式的神经网络框架。该方法为高维系统提供了可扩展的CBFs合成方法。此外，通过使用互惠CBFs而非零值CBFs，所提出的框架允许用户定义灵活的安全区域。为了验证该方法的有效性，我们在三种不同的系统上进行了案例研究：倒立摆、自主地面导航和障碍环境中的航路规划。', 'title_zh': '基于物理知情神经网络的神经控制障碍函数'}
{'arxiv_id': 'arXiv:2504.11038', 'title': 'QAVA: Query-Agnostic Visual Attack to Large Vision-Language Models', 'authors': 'Yudong Zhang, Ruobing Xie, Jiansheng Chen, Xingwu Sun, Zhanhui Kang, Yu Wang', 'link': 'https://arxiv.org/abs/2504.11038', 'abstract': 'In typical multimodal tasks, such as Visual Question Answering (VQA), adversarial attacks targeting a specific image and question can lead large vision-language models (LVLMs) to provide incorrect answers. However, it is common for a single image to be associated with multiple questions, and LVLMs may still answer other questions correctly even for an adversarial image attacked by a specific question. To address this, we introduce the query-agnostic visual attack (QAVA), which aims to create robust adversarial examples that generate incorrect responses to unspecified and unknown questions. Compared to traditional adversarial attacks focused on specific images and questions, QAVA significantly enhances the effectiveness and efficiency of attacks on images when the question is unknown, achieving performance comparable to attacks on known target questions. Our research broadens the scope of visual adversarial attacks on LVLMs in practical settings, uncovering previously overlooked vulnerabilities, particularly in the context of visual adversarial threats. The code is available at this https URL.', 'abstract_zh': '在典型的多模态任务中，如视觉问答（VQA），针对特定图像和问题的对抗攻击可以使大型视听模型（LVLMs）提供错误的答案。然而，一张图片通常与多个问题相关联，即使图片被针对特定问题进行了攻击，LVLMs也可能仍能正确回答其他问题。为了应对这一挑战，我们引入了一种查询无感知的视觉攻击（QAVA），其目标是生成对未指定和未知问题产生错误响应的健壯对抗样本。与传统针对特定图像和问题的对抗攻击相比，QAVA在未知问题的背景下增强了针对图片的攻击效果，其性能与针对已知目标问题的攻击相当。我们的研究拓宽了在实际应用场景中LVLMs的视觉对抗攻击范围，揭示了之前忽视的脆弱性，特别是在视觉对抗威胁的背景下。代码可在此处获得：this https URL。', 'title_zh': 'QAVA：面向大型视觉-语言模型的查询无感知视觉攻击'}
{'arxiv_id': 'arXiv:2504.11020', 'title': '"Even explanations will not help in trusting [this] fundamentally biased system": A Predictive Policing Case-Study', 'authors': 'Siddharth Mehrotra, Ujwal Gadiraju, Eva Bittner, Folkert van Delden, Catholijn M. Jonker, Myrthe L. Tielman', 'link': 'https://arxiv.org/abs/2504.11020', 'abstract': "In today's society, where Artificial Intelligence (AI) has gained a vital role, concerns regarding user's trust have garnered significant attention. The use of AI systems in high-risk domains have often led users to either under-trust it, potentially causing inadequate reliance or over-trust it, resulting in over-compliance. Therefore, users must maintain an appropriate level of trust. Past research has indicated that explanations provided by AI systems can enhance user understanding of when to trust or not trust the system. However, the utility of presentation of different explanations forms still remains to be explored especially in high-risk domains. Therefore, this study explores the impact of different explanation types (text, visual, and hybrid) and user expertise (retired police officers and lay users) on establishing appropriate trust in AI-based predictive policing. While we observed that the hybrid form of explanations increased the subjective trust in AI for expert users, it did not led to better decision-making. Furthermore, no form of explanations helped build appropriate trust. The findings of our study emphasize the importance of re-evaluating the use of explanations to build [appropriate] trust in AI based systems especially when the system's use is questionable. Finally, we synthesize potential challenges and policy recommendations based on our results to design for appropriate trust in high-risk based AI-based systems.", 'abstract_zh': '人工智能基于预测警务中不同解释类型和用户专业背景对建立适当信任的影响研究', 'title_zh': '“即使解释也无法让人信任这一基本有偏见的系统”：一项预测性警务案例研究'}
{'arxiv_id': 'arXiv:2504.11014', 'title': 'GATE3D: Generalized Attention-based Task-synergized Estimation in 3D*', 'authors': 'Eunsoo Im, Jung Kwon Lee, Changhyun Jee', 'link': 'https://arxiv.org/abs/2504.11014', 'abstract': 'The emerging trend in computer vision emphasizes developing universal models capable of simultaneously addressing multiple diverse tasks. Such universality typically requires joint training across multi-domain datasets to ensure effective generalization. However, monocular 3D object detection presents unique challenges in multi-domain training due to the scarcity of datasets annotated with accurate 3D ground-truth labels, especially beyond typical road-based autonomous driving contexts. To address this challenge, we introduce a novel weakly supervised framework leveraging pseudo-labels. Current pretrained models often struggle to accurately detect pedestrians in non-road environments due to inherent dataset biases. Unlike generalized image-based 2D object detection models, achieving similar generalization in monocular 3D detection remains largely unexplored. In this paper, we propose GATE3D, a novel framework designed specifically for generalized monocular 3D object detection via weak supervision. GATE3D effectively bridges domain gaps by employing consistency losses between 2D and 3D predictions. Remarkably, our model achieves competitive performance on the KITTI benchmark as well as on an indoor-office dataset collected by us to evaluate the generalization capabilities of our framework. Our results demonstrate that GATE3D significantly accelerates learning from limited annotated data through effective pre-training strategies, highlighting substantial potential for broader impacts in robotics, augmented reality, and virtual reality applications. Project page: this https URL', 'abstract_zh': '新兴的计算机视觉趋势强调开发能够同时处理多种多样任务的通用模型。这种通用性通常需要跨多域数据集进行联合训练，以确保有效的泛化能力。然而，单目三维物体检测在多域训练中面临独特挑战，主要原因是在非道路环境中的准确三维地面真值标签数据集十分稀缺。为解决这一挑战，我们提出了一种利用伪标签的新颖弱监督框架。当前的预训练模型在非道路环境中的行人检测方面往往表现不佳，这是因为数据集中的偏见问题。与通用的基于图像的二维对象检测模型不同，在单目三维检测中实现类似的泛化能力仍然尚未得到充分探索。在本文中，我们提出了GATE3D，这是一种专门用于通过弱监督进行通用单目三维物体检测的新型框架。GATE3D 通过在二维和三维预测之间使用一致性损失有效地弥合了领域差距。令人惊讶的是，我们的模型在KITTIData基准测试以及我们在室内办公环境收集的数据集上均取得了竞争力的表现，用于评估我们框架的泛化能力。我们的结果表明，GATE3D 通过有效的预训练策略显著加速了从有限标注数据的学习过程，突显了其在机器人、增强现实和虚拟现实应用中的广泛应用潜力。项目页面: [this URL](this https URL)', 'title_zh': 'GATE3D: 基于通用注意力的任务协同三维估计'}
{'arxiv_id': 'arXiv:2504.11011', 'title': 'Document Quality Scoring for Web Crawling', 'authors': 'Francesca Pezzuti, Ariane Mueller, Sean MacAvaney, Nicola Tonellotto', 'link': 'https://arxiv.org/abs/2504.11011', 'abstract': 'The internet contains large amounts of low-quality content, yet users expect web search engines to deliver high-quality, relevant results. The abundant presence of low-quality pages can negatively impact retrieval and crawling processes by wasting resources on these documents. Therefore, search engines can greatly benefit from techniques that leverage efficient quality estimation methods to mitigate these negative impacts. Quality scoring methods for web pages are useful for many processes typical for web search systems, including static index pruning, index tiering, and crawling. Building on work by Chang et al.~\\cite{chang2024neural}, who proposed using neural estimators of semantic quality for static index pruning, we extend their approach and apply their neural quality scorers to assess the semantic quality of web pages in crawling prioritisation tasks. In our experimental analysis, we found that prioritising semantically high-quality pages over low-quality ones can improve downstream search effectiveness. Our software contribution consists of a Docker container that computes an effective quality score for a given web page, allowing the quality scorer to be easily included and used in other components of web search systems.', 'abstract_zh': '互联网包含大量低质量内容，但用户期望网络搜索引擎能够提供高质量的相关结果。大量低质量页面的存在会对检索和爬虫过程产生负面影响，浪费资源在这些文档上。因此，搜索引擎可以从利用高效的质量估计方法中获益，以减轻这些负面影响。用于网页的质量评分方法对网页搜索系统中的许多典型过程（包括静态索引修剪、索引分层和爬虫）很有用。在此基础上，我们借鉴Chang等人的工作（Chang et al.~\\cite{chang2024neural}），提出使用神经估计器对静态索引进行修剪，并进一步将他们的神经质量评分器应用于爬虫优先级任务中以评估网页的语义质量。实验分析表明，优先处理语义质量高的网页可以提高后续搜索效果。我们的软件贡献在于提供一个Docker容器，用于计算给定网页的有效质量得分，使得质量评分器可以轻松地被纳入和使用于网页搜索系统的其他组件中。', 'title_zh': '网页抓取中的文档质量评分'}
{'arxiv_id': 'arXiv:2504.11008', 'title': 'MediSee: Reasoning-based Pixel-level Perception in Medical Images', 'authors': 'Qinyue Tong, Ziqian Lu, Jun Liu, Yangming Zheng, Zheming Lu', 'link': 'https://arxiv.org/abs/2504.11008', 'abstract': 'Despite remarkable advancements in pixel-level medical image perception, existing methods are either limited to specific tasks or heavily rely on accurate bounding boxes or text labels as input prompts. However, the medical knowledge required for input is a huge obstacle for general public, which greatly reduces the universality of these methods. Compared with these domain-specialized auxiliary information, general users tend to rely on oral queries that require logical reasoning. In this paper, we introduce a novel medical vision task: Medical Reasoning Segmentation and Detection (MedSD), which aims to comprehend implicit queries about medical images and generate the corresponding segmentation mask and bounding box for the target object. To accomplish this task, we first introduce a Multi-perspective, Logic-driven Medical Reasoning Segmentation and Detection (MLMR-SD) dataset, which encompasses a substantial collection of medical entity targets along with their corresponding reasoning. Furthermore, we propose MediSee, an effective baseline model designed for medical reasoning segmentation and detection. The experimental results indicate that the proposed method can effectively address MedSD with implicit colloquial queries and outperform traditional medical referring segmentation methods.', 'abstract_zh': '基于逻辑推理的医疗图像分割与检测（MedSD）', 'title_zh': 'MediSee: 基于推理的医学图像像素级感知'}
{'arxiv_id': 'arXiv:2504.11004', 'title': 'Dynamic Compressing Prompts for Efficient Inference of Large Language Models', 'authors': 'Jinwu Hu, Wei Zhang, Yufeng Wang, Yu Hu, Bin Xiao, Mingkui Tan, Qing Du', 'link': 'https://arxiv.org/abs/2504.11004', 'abstract': 'Large Language Models (LLMs) have shown outstanding performance across a variety of tasks, partly due to advanced prompting techniques. However, these techniques often require lengthy prompts, which increase computational costs and can hinder performance because of the limited context windows of LLMs. While prompt compression is a straightforward solution, existing methods confront the challenges of retaining essential information, adapting to context changes, and remaining effective across different tasks. To tackle these issues, we propose a task-agnostic method called Dynamic Compressing Prompts (LLM-DCP). Our method reduces the number of prompt tokens while aiming to preserve the performance as much as possible. We model prompt compression as a Markov Decision Process (MDP), enabling the DCP-Agent to sequentially remove redundant tokens by adapting to dynamic contexts and retaining crucial content. We develop a reward function for training the DCP-Agent that balances the compression rate, the quality of the LLM output, and the retention of key information. This allows for prompt token reduction without needing an external black-box LLM. Inspired by the progressive difficulty adjustment in curriculum learning, we introduce a Hierarchical Prompt Compression (HPC) training strategy that gradually increases the compression difficulty, enabling the DCP-Agent to learn an effective compression method that maintains information integrity. Experiments demonstrate that our method outperforms state-of-the-art techniques, especially at higher compression rates. The code for our approach will be available at this https URL.', 'abstract_zh': '大型语言模型（LLMs）在各种任务中展示了卓越的性能，部分原因归功于先进的提示技术。然而，这些技术往往需要较长的提示，这增加了计算成本，并且由于LLMs的有限上下文窗口，可能妨碍其性能。虽然提示压缩是一个直接的解决方案，但现有方法面临保留关键信息、适应上下文变化和在不同任务中保持有效性等挑战。为应对这些挑战，我们提出了一种任务通用的方法，称为动态压缩提示（LLM-DCP）。该方法在减少提示token数量的同时，尽量保持性能不变。我们将提示压缩建模为马尔可夫决策过程（MDP），使DCP-Agent能够根据动态上下文顺序移除冗余token，同时保留关键内容。我们为训练DCP-Agent开发了一个奖励函数，该函数平衡压缩率、LLM输出质量以及关键信息的保留。这使得可以在不使用外部黑盒LLM的情况下实现提示token的减少。受课程学习中逐步增加难度的启发，我们引入了一种分层提示压缩（HPC）训练策略，该策略逐渐增加压缩难度，使DCP-Agent能够学习一种有效且信息完整性的压缩方法。实验结果表明，该方法在更高的压缩率下优于现有最佳技术。我们的方法代码将在此网址获得：this https URL。', 'title_zh': '动态压缩提示以提高大型语言模型高效推理'}
{'arxiv_id': 'arXiv:2504.10995', 'title': 'TMCIR: Token Merge Benefits Composed Image Retrieval', 'authors': 'Chaoyang Wang, Zeyu Zhang, Long Teng, Zijun Li, Shichao Kan', 'link': 'https://arxiv.org/abs/2504.10995', 'abstract': 'Composed Image Retrieval (CIR) retrieves target images using a multi-modal query that combines a reference image with text describing desired modifications. The primary challenge is effectively fusing this visual and textual information. Current cross-modal feature fusion approaches for CIR exhibit an inherent bias in intention interpretation. These methods tend to disproportionately emphasize either the reference image features (visual-dominant fusion) or the textual modification intent (text-dominant fusion through image-to-text conversion). Such an imbalanced representation often fails to accurately capture and reflect the actual search intent of the user in the retrieval results. To address this challenge, we propose TMCIR, a novel framework that advances composed image retrieval through two key innovations: 1) Intent-Aware Cross-Modal Alignment. We first fine-tune CLIP encoders contrastively using intent-reflecting pseudo-target images, synthesized from reference images and textual descriptions via a diffusion model. This step enhances the encoder ability of text to capture nuanced intents in textual descriptions. 2) Adaptive Token Fusion. We further fine-tune all encoders contrastively by comparing adaptive token-fusion features with the target image. This mechanism dynamically balances visual and textual representations within the contrastive learning pipeline, optimizing the composed feature for retrieval. Extensive experiments on Fashion-IQ and CIRR datasets demonstrate that TMCIR significantly outperforms state-of-the-art methods, particularly in capturing nuanced user intent.', 'abstract_zh': '综合图像检索（CIR）使用结合参考图像和描述所需修改的文本的多模态查询来检索目标图像。主要挑战在于有效地融合这种视觉和文本信息。当前的跨模态特征融合方法在意图解释上存在固有的偏见。这些方法往往过度强调参考图像特征（视觉主导融合）或通过图像到文本转换的文本修改意图（文本主导融合）。这种不平衡的表示往往无法准确捕捉和反映用户的实际检索意图。为了解决这一挑战，我们提出了一种名为TMCIR的新框架，通过两项创新推进了综合图像检索：1）意图感知的跨模态对齐。我们首先使用从参考图像和文本描述通过扩散模型合成的反映意图的伪目标图像，以对比的方式微调CLIP编码器。这一步骤增强了编码器捕捉文本描述中细微意图的能力。2）自适应 token 融合。我们进一步通过将自适应 token 融合特征与目标图像进行对比来对比微调所有编码器。这种机制在对比学习管道中动态平衡视觉和文本表示，优化组合特征以进行检索。在 Fashion-IQ 和 CIRR 数据集上的广泛实验表明，TMCIR 显著优于当前最先进的方法，尤其是在捕捉细微用户意图方面。', 'title_zh': 'TMCIR: 词元合并优化组合图像检索'}
{'arxiv_id': 'arXiv:2504.10983', 'title': 'ProtFlow: Fast Protein Sequence Design via Flow Matching on Compressed Protein Language Model Embeddings', 'authors': 'Zitai Kong, Yiheng Zhu, Yinlong Xu, Hanjing Zhou, Mingzhe Yin, Jialu Wu, Hongxia Xu, Chang-Yu Hsieh, Tingjun Hou, Jian Wu', 'link': 'https://arxiv.org/abs/2504.10983', 'abstract': 'The design of protein sequences with desired functionalities is a fundamental task in protein engineering. Deep generative methods, such as autoregressive models and diffusion models, have greatly accelerated the discovery of novel protein sequences. However, these methods mainly focus on local or shallow residual semantics and suffer from low inference efficiency, large modeling space and high training cost. To address these challenges, we introduce ProtFlow, a fast flow matching-based protein sequence design framework that operates on embeddings derived from semantically meaningful latent space of protein language models. By compressing and smoothing the latent space, ProtFlow enhances performance while training on limited computational resources. Leveraging reflow techniques, ProtFlow enables high-quality single-step sequence generation. Additionally, we develop a joint design pipeline for the design scene of multichain proteins. We evaluate ProtFlow across diverse protein design tasks, including general peptides and long-chain proteins, antimicrobial peptides, and antibodies. Experimental results demonstrate that ProtFlow outperforms task-specific methods in these applications, underscoring its potential and broad applicability in computational protein sequence design and analysis.', 'abstract_zh': '基于语义有意义潜在空间的流匹配蛋白序列设计框架', 'title_zh': 'ProtFlow: 快速蛋白质序列设计通过压缩蛋白质语言模型嵌入的流匹配'}
{'arxiv_id': 'arXiv:2504.10982', 'title': 'Exploring the Role of KG-Based RAG in Japanese Medical Question Answering with Small-Scale LLMs', 'authors': 'Yingjian Chen, Feiyang Li, Xingyu Song, Tianxiao Li, Issey Sudeka, Irene Li', 'link': 'https://arxiv.org/abs/2504.10982', 'abstract': 'Large language models (LLMs) perform well in medical QA, but their effectiveness in Japanese contexts is limited due to privacy constraints that prevent the use of commercial models like GPT-4 in clinical settings. As a result, recent efforts focus on instruction-tuning open-source LLMs, though the potential of combining them with retrieval-augmented generation (RAG) remains underexplored. To bridge this gap, we are the first to explore a knowledge graph-based (KG) RAG framework for Japanese medical QA small-scale open-source LLMs. Experimental results show that KG-based RAG has only a limited impact on Japanese medical QA using small-scale open-source LLMs. Further case studies reveal that the effectiveness of the RAG is sensitive to the quality and relevance of the external retrieved content. These findings offer valuable insights into the challenges and potential of applying RAG in Japanese medical QA, while also serving as a reference for other low-resource languages.', 'abstract_zh': '基于知识图谱的检索增强生成框架(KG-RAG)在小型开源日医QA中的探索', 'title_zh': '基于知识图谱的RAG在小型LLM驱动的日语医疗问答中的作用探索'}
{'arxiv_id': 'arXiv:2504.10961', 'title': 'Evaluating Trust in AI, Human, and Co-produced Feedback Among Undergraduate Students', 'authors': 'Audrey Zhang, Yifei Gao, Wannapon Suraworachet, Tanya Nazaretsky, Mutlu Cukurova', 'link': 'https://arxiv.org/abs/2504.10961', 'abstract': "As generative AI transforms educational feedback practices, understanding students' perceptions of different feedback providers becomes crucial for effective implementation. This study addresses a critical gap by comparing undergraduate students' trust in AI-generated, human-created, and human-AI co-produced feedback, informing how institutions can adapt feedback practices in this new era. Through a within-subject experiment with 91 participants, we investigated factors predicting students' ability to distinguish between feedback types, perception of feedback quality, and potential biases to AI involvement. Findings revealed that students generally preferred AI and co-produced feedback over human feedback in terms of perceived usefulness and objectivity. Only AI feedback suffered a decline in perceived genuineness when feedback sources were revealed, while co-produced feedback maintained its positive perception. Educational AI experience improved students' ability to identify AI feedback and increased their trust in all feedback types, while general AI experience decreased perceived usefulness and credibility. Male students consistently rated all feedback types as less valuable than their female and non-binary counterparts. These insights inform evidence-based guidelines for integrating AI into higher education feedback systems while addressing trust concerns and fostering AI literacy among students.", 'abstract_zh': '随着生成式AI改变教育反馈实践，理解不同反馈提供者的学生感知成为有效实施的关键。本研究通过对比大学生对AI生成、人类创造和人类与AI合作生成反馈的信任度，填补了重要空白，并为机构如何适应这一新环境下的反馈实践提供信息。通过一项涉及91名参与者的重复被试实验，我们探讨了影响学生区分不同反馈类型能力、反馈质量感知以及对AI参与可能存在的偏见的因素。研究发现，学生普遍更偏好AI和合作生成的反馈，认为其更具实用性和客观性。只有当反馈来源被揭示时，AI反馈的可信度有所下降，而合作生成的反馈维持了积极的感知。教育AI经验提高了学生识别AI反馈的能力，并增加了他们对所有反馈类型的信任，而一般AI经验则降低了反馈的实用性和可信度。男性学生普遍认为所有反馈类型的价值低于女性和非二元性别学生。这些见解为基于证据的指南提供了依据，指导AI整合入高等教育反馈系统，并解决信任关切，培养学生的AI素养。', 'title_zh': '评估本科生在AI、人类和联合生产反馈中的信任度'}
{'arxiv_id': 'arXiv:2504.10948', 'title': 'BEACON: A Benchmark for Efficient and Accurate Counting of Subgraphs', 'authors': 'Mohammad Matin Najafi, Xianju Zhu, Chrysanthi Kosyfaki, Laks V.S. Lakshmanan, Reynold Cheng', 'link': 'https://arxiv.org/abs/2504.10948', 'abstract': 'Subgraph counting the task of determining the number of instances of a query pattern within a large graph lies at the heart of many critical applications, from analyzing financial networks and transportation systems to understanding biological interactions. Despite decades of work yielding efficient algorithmic (AL) solutions and, more recently, machine learning (ML) approaches, a clear comparative understanding is elusive. This gap stems from the absence of a unified evaluation framework, standardized datasets, and accessible ground truths, all of which hinder systematic analysis and fair benchmarking. To overcome these barriers, we introduce BEACON: a comprehensive benchmark designed to rigorously evaluate both AL and ML-based subgraph counting methods. BEACON provides a standardized dataset with verified ground truths, an integrated evaluation environment, and a public leaderboard, enabling reproducible and transparent comparisons across diverse approaches. Our extensive experiments reveal that while AL methods excel in efficiently counting subgraphs on very large graphs, they struggle with complex patterns (e.g., those exceeding six nodes). In contrast, ML methods are capable of handling larger patterns but demand massive graph data inputs and often yield suboptimal accuracy on small, dense graphs. These insights not only highlight the unique strengths and limitations of each approach but also pave the way for future advancements in subgraph counting techniques. Overall, BEACON represents a significant step towards unifying and accelerating research in subgraph counting, encouraging innovative solutions and fostering a deeper understanding of the trade-offs between algorithmic and machine learning paradigms.', 'abstract_zh': 'BEACON：一种用于子图计数方法综合评估的基准框架', 'title_zh': 'BEACON: 一个用于子图高效准确计数的基准测试'}
{'arxiv_id': 'arXiv:2504.10936', 'title': 'Can LLMs Leverage Observational Data? Towards Data-Driven Causal Discovery with LLMs', 'authors': 'Yuni Susanti, Michael Färber', 'link': 'https://arxiv.org/abs/2504.10936', 'abstract': "Causal discovery traditionally relies on statistical methods applied to observational data, often requiring large datasets and assumptions about underlying causal structures. Recent advancements in Large Language Models (LLMs) have introduced new possibilities for causal discovery by providing domain expert knowledge. However, it remains unclear whether LLMs can effectively process observational data for causal discovery. In this work, we explore the potential of LLMs for data-driven causal discovery by integrating observational data for LLM-based reasoning. Specifically, we examine whether LLMs can effectively utilize observational data through two prompting strategies: pairwise prompting and breadth first search (BFS)-based prompting. In both approaches, we incorporate the observational data directly into the prompt to assess LLMs' ability to infer causal relationships from such data. Experiments on benchmark datasets show that incorporating observational data enhances causal discovery, boosting F1 scores by up to 0.11 point using both pairwise and BFS LLM-based prompting, while outperforming traditional statistical causal discovery baseline by up to 0.52 points. Our findings highlight the potential and limitations of LLMs for data-driven causal discovery, demonstrating their ability to move beyond textual metadata and effectively interpret and utilize observational data for more informed causal reasoning. Our studies lays the groundwork for future advancements toward fully LLM-driven causal discovery.", 'abstract_zh': '大型语言模型在数据驱动因果发现中的潜力', 'title_zh': 'LLM能否利用观察数据？基于LLM的数据驱动因果发现探索'}
{'arxiv_id': 'arXiv:2504.10925', 'title': 'Transfer Learning for Temporal Link Prediction', 'authors': 'Ayan Chatterjee, Barbara Ikica, Babak Ravandi, John Palowitch', 'link': 'https://arxiv.org/abs/2504.10925', 'abstract': 'Link prediction on graphs has applications spanning from recommender systems to drug discovery. Temporal link prediction (TLP) refers to predicting future links in a temporally evolving graph and adds additional complexity related to the dynamic nature of graphs. State-of-the-art TLP models incorporate memory modules alongside graph neural networks to learn both the temporal mechanisms of incoming nodes and the evolving graph topology. However, memory modules only store information about nodes seen at train time, and hence such models cannot be directly transferred to entirely new graphs at test time and deployment. In this work, we study a new transfer learning task for temporal link prediction, and develop transfer-effective methods for memory-laden models. Specifically, motivated by work showing the informativeness of structural signals for the TLP task, we augment a structural mapping module to the existing TLP model architectures, which learns a mapping from graph structural (topological) features to memory embeddings. Our work paves the way for a memory-free foundation model for TLP.', 'abstract_zh': '图上的链接预测在从推荐系统到药物发现等多个领域都有应用。时间链接预测（TLP）是指预测时间演变图中的未来链接，并且增加了与图的动态性质相关的额外复杂性。最先进的TLP模型结合了记忆模块和图神经网络，以学习入边节点的时间机制以及图拓扑的演变。然而，记忆模块只能存储训练期间看到的节点信息，因此此类模型无法直接迁移应用于测试时间和部署中的全新图。在这项工作中，我们研究了时间链接预测的新型迁移学习任务，并开发了适用于记忆负载模型的有效迁移方法。具体来说，受结构信号对于TLP任务有用性的研究启发，我们在现有TLP模型架构中增加了一个结构映射模块，该模块学习从图结构（拓扑）特征到记忆嵌入的映射。我们的工作为TLP奠定了无记忆基础模型的道路。', 'title_zh': '时间链接预测中的迁移学习'}
{'arxiv_id': 'arXiv:2504.10917', 'title': 'Towards A Universal Graph Structural Encoder', 'authors': 'Jialin Chen, Haolan Zuo, Haoyu Peter Wang, Siqi Miao, Pan Li, Rex Ying', 'link': 'https://arxiv.org/abs/2504.10917', 'abstract': "Recent advancements in large-scale pre-training have shown the potential to learn generalizable representations for downstream tasks. In the graph domain, however, capturing and transferring structural information across different graph domains remains challenging, primarily due to the inherent differences in topological patterns across various contexts. Additionally, most existing models struggle to capture the complexity of rich graph structures, leading to inadequate exploration of the embedding space. To address these challenges, we propose GFSE, a universal graph structural encoder designed to capture transferable structural patterns across diverse domains such as molecular graphs, social networks, and citation networks. GFSE is the first cross-domain graph structural encoder pre-trained with multiple self-supervised learning objectives. Built on a Graph Transformer, GFSE incorporates attention mechanisms informed by graph inductive bias, enabling it to encode intricate multi-level and fine-grained topological features. The pre-trained GFSE produces generic and theoretically expressive positional and structural encoding for graphs, which can be seamlessly integrated with various downstream graph feature encoders, including graph neural networks for vectorized features and Large Language Models for text-attributed graphs. Comprehensive experiments on synthetic and real-world datasets demonstrate GFSE's capability to significantly enhance the model's performance while requiring substantially less task-specific fine-tuning. Notably, GFSE achieves state-of-the-art performance in 81.6% evaluated cases, spanning diverse graph models and datasets, highlighting its potential as a powerful and versatile encoder for graph-structured data.", 'abstract_zh': '近年来，大规模预训练的最新进展展示了学习下游任务泛化表示的潜力。然而，在图领域中，跨不同图域捕捉和传递结构信息依然充满挑战，主要原因是各种上下文之间的拓扑模式存在固有的差异。此外，大多数现有模型难以捕捉复杂图结构的细节，导致嵌入空间的探索不够充分。为了解决这些问题，我们提出了一种名为GFSE的通用图结构编码器，旨在跨分子图、社交网络和引用网络等不同领域捕捉可转移的结构模式。GFSE是首个基于多种自监督学习目标预训练的跨域图结构编码器。基于图变压器，GFSE融合了由图归纳偏置驱动的注意力机制，使其能够编码复杂的多层次和精细的拓扑特征。预训练的GFSE生成适用于各类下游图特征编码器的通用且理论表达性强的位置编码和结构编码，包括用于向量特征的图神经网络和用于文本图的大型语言模型。综合实验表明，GFSE能够在合成和真实世界数据集上显著提升模型性能，同时需要较少的任务特定微调。值得注意的是，GFSE在81.6%的评估案例中达到了最先进的性能，涵盖了多种图模型和数据集，突显了其作为图结构数据强大而通用编码器的潜力。', 'title_zh': '面向通用图结构编码器'}
{'arxiv_id': 'arXiv:2504.10915', 'title': 'LOKA Protocol: A Decentralized Framework for Trustworthy and Ethical AI Agent Ecosystems', 'authors': 'Rajesh Ranjan, Shailja Gupta, Surya Narayan Singh', 'link': 'https://arxiv.org/abs/2504.10915', 'abstract': 'The rise of autonomous AI agents, capable of perceiving, reasoning, and acting independently, signals a profound shift in how digital ecosystems operate, govern, and evolve. As these agents proliferate beyond centralized infrastructures, they expose foundational gaps in identity, accountability, and ethical alignment. Three critical questions emerge: Identity: Who or what is the agent? Accountability: Can its actions be verified, audited, and trusted? Ethical Consensus: Can autonomous systems reliably align with human values and prevent harmful emergent behaviors? We present the novel LOKA Protocol (Layered Orchestration for Knowledgeful Agents), a unified, systems-level architecture for building ethically governed, interoperable AI agent ecosystems. LOKA introduces a proposed Universal Agent Identity Layer (UAIL) for decentralized, verifiable identity; intent-centric communication protocols for semantic coordination across diverse agents; and a Decentralized Ethical Consensus Protocol (DECP) that enables agents to make context-aware decisions grounded in shared ethical baselines. Anchored in emerging standards such as Decentralized Identifiers (DIDs), Verifiable Credentials (VCs), and post-quantum cryptography, LOKA offers a scalable, future-resilient blueprint for multi-agent AI governance. By embedding identity, trust, and ethics into the protocol layer itself, LOKA establishes the foundation for a new era of responsible, transparent, and autonomous AI ecosystems operating across digital and physical domains.', 'abstract_zh': '自主AI代理的兴起标志着数字生态系统运作、治理和演化的深刻转变。随着这些代理超越集中式基础设施的普及，它们暴露了身份、问责制和伦理对齐的基本缺口。三个关键问题随之浮现：身份：代理是什么？问责制：其行动能否被验证、审计并信任？伦理一致性：自主系统能否可靠地与人类价值观对齐并防止有害的 emergent 行为？我们提出了新型LOKA协议（知识型代理的分层编排），这是一种统一的系统级架构，用于构建受伦理治理和互联互通的AI代理生态系统。LOKA引入了提议的去中心化可验证身份层（UAIL）、以意图为中心的通信协议以实现跨不同代理的语义协调，以及去中心化的伦理一致性协议（DECP），使代理能够基于共享的伦理基准做出情境感知的决策。基于如去中心化标识符（DIDs）、可验证凭据（VCs）和后量子加密等新兴标准，LOKA为多代理AI治理提供了可扩展且面向未来的蓝图。通过将身份、信任和伦理嵌入协议层本身，LOKA为横跨数字和物理域的责任、透明和自主AI生态系统的时代奠定了基础。', 'title_zh': 'LOKA协议：一个可信赖和伦理的AI代理生态系统去中心化框架'}
{'arxiv_id': 'arXiv:2504.10903', 'title': 'Efficient Reasoning Models: A Survey', 'authors': 'Sicheng Feng, Gongfan Fang, Xinyin Ma, Xinchao Wang', 'link': 'https://arxiv.org/abs/2504.10903', 'abstract': 'Reasoning models have demonstrated remarkable progress in solving complex and logic-intensive tasks by generating extended Chain-of-Thoughts (CoTs) prior to arriving at a final answer. Yet, the emergence of this "slow-thinking" paradigm, with numerous tokens generated in sequence, inevitably introduces substantial computational overhead. To this end, it highlights an urgent need for effective acceleration. This survey aims to provide a comprehensive overview of recent advances in efficient reasoning. It categorizes existing works into three key directions: (1) shorter - compressing lengthy CoTs into concise yet effective reasoning chains; (2) smaller - developing compact language models with strong reasoning capabilities through techniques such as knowledge distillation, other model compression techniques, and reinforcement learning; and (3) faster - designing efficient decoding strategies to accelerate inference. A curated collection of papers discussed in this survey is available in our GitHub repository.', 'abstract_zh': '推理模型已经在通过生成扩展的思维链(CoTs)来解决复杂和逻辑密集型任务方面取得了显著进展，但在到达最终答案之前生成这些思维链不可避免地带来了大量的计算开销。为此，有效加速显得尤为迫切。本文综述旨在提供对近期高效推理进展的全面概述。它将现有工作划分为三个主要方向：(1) 更短——将长思维链压缩为简洁有效的推理链；(2) 更小——通过知识蒸馏、其他模型压缩技术及强化学习等手段开发具有强大推理能力的紧凑型语言模型；(3) 更快——设计高效的解码策略以加速推理。本文综述中讨论的精选论文集合可在我们的GitHub仓库中获取。', 'title_zh': '高效推理模型：一个综述'}
{'arxiv_id': 'arXiv:2504.10900', 'title': 'Bridging Distribution Gaps in Time Series Foundation Model Pretraining with Prototype-Guided Normalization', 'authors': 'Peiliang Gong, Emadeldeen Eldele, Min Wu, Zhenghua Chen, Xiaoli Li, Daoqiang Zhang', 'link': 'https://arxiv.org/abs/2504.10900', 'abstract': 'Foundation models have achieved remarkable success across diverse machine-learning domains through large-scale pretraining on large, diverse datasets. However, pretraining on such datasets introduces significant challenges due to substantial mismatches in data distributions, a problem particularly pronounced with time series data. In this paper, we tackle this issue by proposing a domain-aware adaptive normalization strategy within the Transformer architecture. Specifically, we replace the traditional LayerNorm with a prototype-guided dynamic normalization mechanism (ProtoNorm), where learned prototypes encapsulate distinct data distributions, and sample-to-prototype affinity determines the appropriate normalization layer. This mechanism effectively captures the heterogeneity of time series characteristics, aligning pretrained representations with downstream tasks. Through comprehensive empirical evaluation, we demonstrate that our method significantly outperforms conventional pretraining techniques across both classification and forecasting tasks, while effectively mitigating the adverse effects of distribution shifts during pretraining. Incorporating ProtoNorm is as simple as replacing a single line of code. Extensive experiments on diverse real-world time series benchmarks validate the robustness and generalizability of our approach, advancing the development of more versatile time series foundation models.', 'abstract_zh': '基于Transformer架构的原型引导自适应归一化策略：提升时间序列数据预训练效果', 'title_zh': '基于原型引导归一化的时序基础模型预训练中分布差距弥合'}
{'arxiv_id': 'arXiv:2504.10898', 'title': 'Xpose: Bi-directional Engineering for Hidden Query Extraction', 'authors': 'Ahana Pradhan, Jayant Haritsa', 'link': 'https://arxiv.org/abs/2504.10898', 'abstract': 'Query reverse engineering (QRE) aims to synthesize a SQL query to connect a given database and result instance. A recent variation of QRE is where an additional input, an opaque executable containing a ground-truth query, is provided, and the goal is to non-invasively extract this specific query through only input-output examples. This variant, called Hidden Query Extraction (HQE), has a spectrum of industrial use-cases including query recovery, database security, and vendor migration. The reverse engineering (RE) tools developed for HQE, which are based on database mutation and generation techniques, can only extract flat queries with key-based equi joins and conjunctive arithmetic filter predicates, making them limited wrt both query structure and query operators. In this paper, we present Xpose, a HQE solution that elevates the extraction scope to realistic complex queries, such as those found in the TPCH benchmark. A two-pronged approach is taken: (1) The existing RE scope is substantially extended to incorporate union connectors, algebraic filter predicates, and disjunctions for both values and predicates. (2) The predictive power of LLMs is leveraged to convert business descriptions of the opaque application into extraction guidance, representing ``forward engineering" (FE). The FE module recognizes common constructs, such as nesting of sub-queries, outer joins, and scalar functions. In essence, FE establishes the broad query contours, while RE fleshes out the fine-grained details. We have evaluated Xpose on (a) E-TPCH, a query suite comprising the complete TPCH benchmark extended with queries featuring unions, diverse join types, and sub-queries; and (b) the real-world STACK benchmark. The experimental results demonstrate that its bi-directional engineering approach accurately extracts these complex queries, representing a significant step forward with regard to HQE coverage.', 'abstract_zh': '隐查询提取 (HQE) 旨在合成一个 SQL 查询以连接给定的数据库和结果实例。HQE 的一种变体提供了额外的输入，即包含真实查询的不透明可执行文件，并通过输入输出示例无侵入地提取该特定查询。该变体称为隐查询提取 (HQE)，其在查询恢复、数据库安全和供应商迁移等领域具有广泛的应用场景。为 HQE 开发的基于数据库变异和生成技术的逆向工程 (RE) 工具仅能提取基于键的等值连接和平面查询，且含有连接和算术过滤谓词，这使它们在查询结构和查询操作符方面都受到限制。在这篇论文中，我们提出了 Xpose，一个将提取范围扩展到现实中的复杂查询（如 TPCH 基准中的查询）的 HQE 解决方案。我们采用了双管齐下的方法：(1) 显著扩展现有 RE 范围，以结合并连接连接符、代数过滤谓词以及值和谓词的析取。(2) 利用大型语言模型 (LLM) 的预测能力，将不透明应用程序的业务描述转换为提取指导，代表了“正向工程”(FE)。FE 模块识别常见的构造，如子查询的嵌套、外连接和标量函数。本质上，FE 确定了广泛的查询轮廓，而 RE 填充了细粒度的细节。我们已在 (a) E-TPCH，一个包含完整 TPCH 基准并扩展了具有并集、多种连接类型和子查询的查询的查询集；和 (b) 实际的 STACK 基准上评估了 Xpose。实验结果表明，其双向工程方法准确提取了这些复杂查询，标志着 HQE 覆盖范围的一个重要进展。', 'title_zh': 'Xpose: 双向工程提取隐藏查询'}
{'arxiv_id': 'arXiv:2504.10888', 'title': 'CDUPatch: Color-Driven Universal Adversarial Patch Attack for Dual-Modal Visible-Infrared Detectors', 'authors': 'Jiahuan Long, Wen Yao, Tingsong Jiang, Chao Ma', 'link': 'https://arxiv.org/abs/2504.10888', 'abstract': 'Adversarial patches are widely used to evaluate the robustness of object detection systems in real-world scenarios. These patches were initially designed to deceive single-modal detectors (e.g., visible or infrared) and have recently been extended to target visible-infrared dual-modal detectors. However, existing dual-modal adversarial patch attacks have limited attack effectiveness across diverse physical scenarios. To address this, we propose CDUPatch, a universal cross-modal patch attack against visible-infrared object detectors across scales, views, and scenarios. Specifically, we observe that color variations lead to different levels of thermal absorption, resulting in temperature differences in infrared imaging. Leveraging this property, we propose an RGB-to-infrared adapter that maps RGB patches to infrared patches, enabling unified optimization of cross-modal patches. By learning an optimal color distribution on the adversarial patch, we can manipulate its thermal response and generate an adversarial infrared texture. Additionally, we introduce a multi-scale clipping strategy and construct a new visible-infrared dataset, MSDrone, which contains aerial vehicle images in varying scales and perspectives. These data augmentation strategies enhance the robustness of our patch in real-world conditions. Experiments on four benchmark datasets (e.g., DroneVehicle, LLVIP, VisDrone, MSDrone) show that our method outperforms existing patch attacks in the digital domain. Extensive physical tests further confirm strong transferability across scales, views, and scenarios.', 'abstract_zh': '跨模态通用 adversarial 崩溃点攻击：面向可见光-红外目标检测系统', 'title_zh': 'CDUPatch: 颜色驱动的通用 adversarial 贴片攻击用于双模可见-红外检测器'}
{'arxiv_id': 'arXiv:2504.10886', 'title': 'Exploring Persona-dependent LLM Alignment for the Moral Machine Experiment', 'authors': 'Jiseon Kim, Jea Kwon, Luiz Felipe Vecchietti, Alice Oh, Meeyoung Cha', 'link': 'https://arxiv.org/abs/2504.10886', 'abstract': 'Deploying large language models (LLMs) with agency in real-world applications raises critical questions about how these models will behave. In particular, how will their decisions align with humans when faced with moral dilemmas? This study examines the alignment between LLM-driven decisions and human judgment in various contexts of the moral machine experiment, including personas reflecting different sociodemographics. We find that the moral decisions of LLMs vary substantially by persona, showing greater shifts in moral decisions for critical tasks than humans. Our data also indicate an interesting partisan sorting phenomenon, where political persona predominates the direction and degree of LLM decisions. We discuss the ethical implications and risks associated with deploying these models in applications that involve moral decisions.', 'abstract_zh': '部署具有自主性的大型语言模型（LLMs）在实际应用中 raises 关键问题，关于这些模型的行为。特别是，当面对道德困境时，它们的决策将如何与人类相一致？本研究考察了在道德机器实验等各种背景下，由LLM驱动的决策与人类判断的一致性，包括反映不同社会人口统计学特征的人格特质。我们发现，LLM的道德决策在不同的人格特质下差异显著，对于关键任务，LLM的道德决策变化幅度大于人类。我们的数据还显示了一个有趣的偏见分组现象，政治人格主导了LLM决策的方向和程度。我们讨论了在涉及道德决策的应用中部署这些模型的伦理影响和风险。', 'title_zh': '基于人格依赖的LLM对齐探索：以道德机器实验为例'}
{'arxiv_id': 'arXiv:2504.10885', 'title': 'PuzzleBench: A Fully Dynamic Evaluation Framework for Large Multimodal Models on Puzzle Solving', 'authors': 'Zeyu Zhang, Zijian Chen, Zicheng Zhang, Yuze Sun, Yuan Tian, Ziheng Jia, Chunyi Li, Xiaohong Liu, Xiongkuo Min, Guangtao Zhai', 'link': 'https://arxiv.org/abs/2504.10885', 'abstract': 'Large Multimodal Models (LMMs) have demonstrated impressive capabilities across a wide range of multimodal tasks, achieving ever-increasing performance on various evaluation benchmarks. However, existing benchmarks are typically static and often overlap with pre-training datasets, leading to fixed complexity constraints and substantial data contamination issues. Meanwhile, manually annotated datasets are labor-intensive, time-consuming, and subject to human bias and inconsistency, leading to reliability and reproducibility issues. To address these problems, we propose a fully dynamic multimodal evaluation framework, named Open-ended Visual Puzzle Generation (OVPG), which aims to generate fresh, diverse, and verifiable evaluation data automatically in puzzle-solving tasks. Specifically, the OVPG pipeline consists of a raw material sampling module, a visual content generation module, and a puzzle rule design module, which ensures that each evaluation instance is primitive, highly randomized, and uniquely solvable, enabling continual adaptation to the evolving capabilities of LMMs. Built upon OVPG, we construct PuzzleBench, a dynamic and scalable benchmark comprising 11,840 VQA samples. It features six carefully designed puzzle tasks targeting three core LMM competencies, visual recognition, logical reasoning, and context understanding. PuzzleBench differs from static benchmarks that quickly become outdated. It enables ongoing dataset refreshing through OVPG and a rich set of open-ended puzzle designs, allowing seamless adaptation to the evolving capabilities of LMMs.', 'abstract_zh': '开放性视觉谜题生成的大规模多模态评估框架', 'title_zh': 'PuzzleBench: 一种用于益智谜题解决的全面动态评估框架（大型多模态模型）'}
{'arxiv_id': 'arXiv:2504.10883', 'title': 'Bringing together invertible UNets with invertible attention modules for memory-efficient diffusion models', 'authors': 'Karan Jain, Mohammad Nayeem Teli', 'link': 'https://arxiv.org/abs/2504.10883', 'abstract': 'Diffusion models have recently gained state of the art performance on many image generation tasks. However, most models require significant computational resources to achieve this. This becomes apparent in the application of medical image synthesis due to the 3D nature of medical datasets like CT-scans, MRIs, electron microscope, etc. In this paper we propose a novel architecture for a single GPU memory-efficient training for diffusion models for high dimensional medical datasets. The proposed model is built by using an invertible UNet architecture with invertible attention modules. This leads to the following two contributions: 1. denoising diffusion models and thus enabling memory usage to be independent of the dimensionality of the dataset, and 2. reducing the energy usage during training. While this new model can be applied to a multitude of image generation tasks, we showcase its memory-efficiency on the 3D BraTS2020 dataset leading to up to 15\\% decrease in peak memory consumption during training with comparable results to SOTA while maintaining the image quality.', 'abstract_zh': '基于单GPU内存高效训练的 invertible UNet 架构在高维医疗图像生成中的应用', 'title_zh': '将可逆UNet与可逆注意力模块结合以实现_MEMORY-EFFICIENT_扩散模型'}
{'arxiv_id': 'arXiv:2504.10878', 'title': 'Large Language Model-Informed Feature Discovery Improves Prediction and Interpretation of Credibility Perceptions of Visual Content', 'authors': 'Yilang Peng, Sijia Qian, Yingdan Lu, Cuihua Shen', 'link': 'https://arxiv.org/abs/2504.10878', 'abstract': "In today's visually dominated social media landscape, predicting the perceived credibility of visual content and understanding what drives human judgment are crucial for countering misinformation. However, these tasks are challenging due to the diversity and richness of visual features. We introduce a Large Language Model (LLM)-informed feature discovery framework that leverages multimodal LLMs, such as GPT-4o, to evaluate content credibility and explain its reasoning. We extract and quantify interpretable features using targeted prompts and integrate them into machine learning models to improve credibility predictions. We tested this approach on 4,191 visual social media posts across eight topics in science, health, and politics, using credibility ratings from 5,355 crowdsourced workers. Our method outperformed zero-shot GPT-based predictions by 13 percent in R2, and revealed key features like information concreteness and image format. We discuss the implications for misinformation mitigation, visual credibility, and the role of LLMs in social science.", 'abstract_zh': '在今天以视觉为主导的社交媒体景观中，预测视觉内容的感知可信度并理解影响人类判断的因素对于打击 misinformation 至关重要。然而，这些任务因视觉特征的多样性和丰富性而极具挑战性。我们介绍了一种由大规模语言模型 (LLM) 驱动的特征发现框架，利用包括 GPT-4o 在内的多模态 LLM 评估内容可信度并解释其推理过程。我们通过靶向提示提取和量化可解释的特征，并将它们整合到机器学习模型中以提高可信度预测性能。我们在科学、健康和政治等八个主题的 4,191 条视觉社交媒体帖子上进行了测试，这些帖子是由 5,355 名众包工人对可信度进行评级的。我们的方法在 R2 方面优于零样本 GPT 预测 13%，揭示了关键特征如信息具体性和图像格式。我们讨论了这些结果对打击 misinformation、视觉可信度和 LLM 在社会科学中的角色的意义。', 'title_zh': '大型语言模型指导的特征发现改善了视觉内容可信度感知的预测与解释'}
{'arxiv_id': 'arXiv:2504.10873', 'title': 'Can Vision-Language Models Understand and Interpret Dynamic Gestures from Pedestrians? Pilot Datasets and Exploration Towards Instructive Nonverbal Commands for Cooperative Autonomous Vehicles', 'authors': 'Tonko E. W. Bossen, Andreas Møgelmose, Ross Greer', 'link': 'https://arxiv.org/abs/2504.10873', 'abstract': 'In autonomous driving, it is crucial to correctly interpret traffic gestures (TGs), such as those of an authority figure providing orders or instructions, or a pedestrian signaling the driver, to ensure a safe and pleasant traffic environment for all road users. This study investigates the capabilities of state-of-the-art vision-language models (VLMs) in zero-shot interpretation, focusing on their ability to caption and classify human gestures in traffic contexts. We create and publicly share two custom datasets with varying formal and informal TGs, such as \'Stop\', \'Reverse\', \'Hail\', etc. The datasets are "Acted TG (ATG)" and "Instructive TG In-The-Wild (ITGI)". They are annotated with natural language, describing the pedestrian\'s body position and gesture. We evaluate models using three methods utilizing expert-generated captions as baseline and control: (1) caption similarity, (2) gesture classification, and (3) pose sequence reconstruction similarity. Results show that current VLMs struggle with gesture understanding: sentence similarity averages below 0.59, and classification F1 scores reach only 0.14-0.39, well below the expert baseline of 0.70. While pose reconstruction shows potential, it requires more data and refined metrics to be reliable. Our findings reveal that although some SOTA VLMs can interpret zero-shot human traffic gestures, none are accurate and robust enough to be trustworthy, emphasizing the need for further research in this domain.', 'abstract_zh': '在自主驾驶中，正确解释交通手势（TGs），如权威人物的指令或行人的驾驶信号，对于确保所有道路使用者的安全和愉快交通环境至关重要。本研究探讨了最先进的视觉-语言模型（VLMs）在零样本解释中的能力，重点在于其在交通场景中描述和分类人类手势的能力。我们创建并公开分享了两个自定义数据集，包含正式和非正式的交通手势，如“停止”、“倒车”、“招手”等。这些数据集分别为“行为交通手势（ATG）”和“野生指导性交通手势（ITGI）”。它们用自然语言标注了行人的身体位置和手势。我们使用三种方法评估模型，利用专家生成的描述作为基线和对照：（1）句子相似度，（2）手势分类，（3）姿态序列重构相似度。结果表明，当前的VLMs在手势理解方面存在困难：句子相似度平均值低于0.59，分类F1分数仅为0.14-0.39，远低于专家基线0.70。尽管姿态重建显示出潜力，但需要更多数据和精细的评估指标才能可靠。我们的研究发现，尽管一些最先进的VLMs能够理解和解释零样本的人类交通手势，但没有一种模型既准确又足够可靠，这强调了在此领域进一步研究的必要性。', 'title_zh': '视觉-语言模型能否理解并解释行人动态手势？试点数据集及向配合型自主车辆指示性非言语命令的探索'}
{'arxiv_id': 'arXiv:2504.10845', 'title': 'Moving Beyond Next-Token Prediction: Transformers are Context-Sensitive Language Generators', 'authors': 'Phill Kyu Rhee', 'link': 'https://arxiv.org/abs/2504.10845', 'abstract': 'Large Language Models (LLMs), powered by Transformers, have demonstrated human-like intelligence capabilities, yet their underlying mechanisms remain poorly understood. This paper presents a novel framework for interpreting LLMs as probabilistic left context-sensitive languages (CSLs) generators. We hypothesize that Transformers can be effectively decomposed into three fundamental components: context windows, attention mechanisms, and autoregressive generation frameworks. This decomposition allows for the development of more flexible and interpretable computational models, moving beyond the traditional view of attention and autoregression as inseparable processes. We argue that next-token predictions can be understood as probabilistic, dynamic approximations of left CSL production rules, providing an intuitive explanation for how simple token predictions can yield human-like intelligence outputs. Given that all CSLs are left context-sensitive (Penttonen, 1974), we conclude that Transformers stochastically approximate CSLs, which are widely recognized as models of human-like intelligence. This interpretation bridges the gap between Formal Language Theory and the observed generative power of Transformers, laying a foundation for future advancements in generative AI theory and applications. Our novel perspective on Transformer architectures will foster a deeper understanding of LLMs and their future potentials.', 'abstract_zh': '大型语言模型（LLMs）由变换器驱动，展示了类似人类的智能能力，但其工作机制依然不够清晰。本文提出了一种新的框架，将LLMs解释为概率性的左上下文敏感语言（CSLs）生成器。我们假设变换器可以有效分解为三个基本组件：上下文窗口、注意机制和自回归生成框架。这种分解允许开发出更灵活和可解释的计算模型，超越了传统将注意和自回归视为不可分割过程的观点。我们认为下一词预测可以理解为左上下文敏感语言生成规则的概率动态近似，为简单词预测如何产生类似人类的智能输出提供了直观的解释。鉴于所有CSLs都是左上下文敏感的（Penttonen, 1974），我们得出结论，变换器通过随机近似CSLs来工作，而CSLs被广泛认作是类似人类智能的模型。这一解释弥合了形式语言理论与变换器观测到的生成能力之间的差距，为生成AI理论和应用的进步奠定了基础。我们对变换器架构的这一新颖观点将促进对LLMs及其未来潜力的更深入理解。', 'title_zh': '超越下一个词预测：Transformer 是上下文敏感的语言生成器'}
{'arxiv_id': 'arXiv:2504.10839', 'title': 'Rethinking Theory of Mind Benchmarks for LLMs: Towards A User-Centered Perspective', 'authors': 'Qiaosi Wang, Xuhui Zhou, Maarten Sap, Jodi Forlizzi, Hong Shen', 'link': 'https://arxiv.org/abs/2504.10839', 'abstract': "The last couple of years have witnessed emerging research that appropriates Theory-of-Mind (ToM) tasks designed for humans to benchmark LLM's ToM capabilities as an indication of LLM's social intelligence. However, this approach has a number of limitations. Drawing on existing psychology and AI literature, we summarize the theoretical, methodological, and evaluation limitations by pointing out that certain issues are inherently present in the original ToM tasks used to evaluate human's ToM, which continues to persist and exacerbated when appropriated to benchmark LLM's ToM. Taking a human-computer interaction (HCI) perspective, these limitations prompt us to rethink the definition and criteria of ToM in ToM benchmarks in a more dynamic, interactional approach that accounts for user preferences, needs, and experiences with LLMs in such evaluations. We conclude by outlining potential opportunities and challenges towards this direction.", 'abstract_zh': '近年来，研究人员开始利用设计用于人类的理论共情任务（ToM）来评估大规模语言模型（LLM）的理论共情能力，以此作为其社会智能的指标。然而，这种做法存在诸多局限性。结合现有心理学和人工智能文献，我们总结了理论、方法和评价方面的局限性，指出原用于评估人类理论共情的ToM任务中存在的某些问题，在将其应用于评估LLM的理论共情时，这些问题仍然存在并被放大。从人机交互（HCI）的角度来看，这些局限性促使我们重新思考理论共情基准中的ToM定义和标准，采用更为动态和交互的方式来评估用户对LLM的偏好、需求和体验。我们最后概述了在此方向上存在的潜在机遇与挑战。', 'title_zh': '重思大模型共情基准：朝着以用户为中心的角度'}
{'arxiv_id': 'arXiv:2504.10836', 'title': 'Uplink Assisted Joint Channel Estimation and CSI Feedback: An Approach Based on Deep Joint Source-Channel Coding', 'authors': 'Yiran Guo, Wei Chen, Bo Ai', 'link': 'https://arxiv.org/abs/2504.10836', 'abstract': 'In frequency division duplex (FDD) multiple-input multiple-output (MIMO) wireless communication systems, the acquisition of downlink channel state information (CSI) is essential for maximizing spatial resource utilization and improving system spectral efficiency. The separate design of modules in AI-based CSI feedback architectures under traditional modular communication frameworks, including channel estimation (CE), CSI compression and feedback, leads to sub-optimal performance. In this paper, we propose an uplink assisted joint CE and and CSI feedback approach via deep learning for downlink CSI acquisition, which mitigates performance degradation caused by distribution bias across separately trained modules in traditional modular communication frameworks. The proposed network adopts a deep joint source-channel coding (DJSCC) architecture to mitigate the cliff effect encountered in the conventional separate source-channel coding. Furthermore, we exploit the uplink CSI as auxiliary information to enhance CSI reconstruction accuracy by leveraging the partial reciprocity between the uplink and downlink channels in FDD systems, without introducing additional overhead. The effectiveness of uplink CSI as assisted information and the necessity of an end-toend multi-module joint training architecture is validated through comprehensive ablation and scalability experiments.', 'abstract_zh': '基于深度学习的上行辅助联合信道估计与CSI反馈方法在FDD MIMO无线通信系统中的下行CSI获取', 'title_zh': '上行协助联合信道估计和CSI反馈：基于深度联合源-信道编码的方法'}
{'arxiv_id': 'arXiv:2504.10833', 'title': 'Towards Spatially-Aware and Optimally Faithful Concept-Based Explanations', 'authors': 'Shubham Kumar, Dwip Dalal, Narendra Ahuja', 'link': 'https://arxiv.org/abs/2504.10833', 'abstract': "Post-hoc, unsupervised concept-based explanation methods (U-CBEMs) are a promising tool for generating semantic explanations of the decision-making processes in deep neural networks, having applications in both model improvement and understanding. It is vital that the explanation is accurate, or faithful, to the model, yet we identify several limitations of prior faithfulness metrics that inhibit an accurate evaluation; most notably, prior metrics involve only the set of concepts present, ignoring how they may be spatially distributed. We address these limitations with Surrogate Faithfulness (SF), an evaluation method that introduces a spatially-aware surrogate and two novel faithfulness metrics. Using SF, we produce Optimally Faithful (OF) explanations, where concepts are found that maximize faithfulness. Our experiments show that (1) adding spatial-awareness to prior U-CBEMs increases faithfulness in all cases; (2) OF produces significantly more faithful explanations than prior U-CBEMs (30% or higher improvement in error); (3) OF's learned concepts generalize well to out-of-domain data and are more robust to adversarial examples, where prior U-CBEMs struggle.", 'abstract_zh': '基于概念的后验无监督解释方法（U-CBEMs）的空间 Awareness 评估及其优化可靠解释', 'title_zh': '面向空间意识和最优忠实概念导向的解释'}
{'arxiv_id': 'arXiv:2504.10823', 'title': 'CLASH: Evaluating Language Models on Judging High-Stakes Dilemmas from Multiple Perspectives', 'authors': 'Ayoung Lee, Ryan Sungmo Kwon, Peter Railton, Lu Wang', 'link': 'https://arxiv.org/abs/2504.10823', 'abstract': "Navigating high-stakes dilemmas involving conflicting values is challenging even for humans, let alone for AI. Yet prior work in evaluating the reasoning capabilities of large language models (LLMs) in such situations has been limited to everyday scenarios. To close this gap, this work first introduces CLASH (Character perspective-based LLM Assessments in Situations with High-stakes), a meticulously curated dataset consisting of 345 high-impact dilemmas along with 3,795 individual perspectives of diverse values. In particular, we design CLASH in a way to support the study of critical aspects of value-based decision-making processes which are missing from prior work, including understanding decision ambivalence and psychological discomfort as well as capturing the temporal shifts of values in characters' perspectives. By benchmarking 10 open and closed frontier models, we uncover several key findings. (1) Even the strongest models, such as GPT-4o and Claude-Sonnet, achieve less than 50% accuracy in identifying situations where the decision should be ambivalent, while they perform significantly better in clear-cut scenarios. (2) While LLMs reasonably predict psychological discomfort as marked by human, they inadequately comprehend perspectives involving value shifts, indicating a need for LLMs to reason over complex values. (3) Our experiments also reveal a significant correlation between LLMs' value preferences and their steerability towards a given value. (4) Finally, LLMs exhibit greater steerability when engaged in value reasoning from a third-party perspective, compared to a first-person setup, though certain value pairs benefit uniquely from the first-person framing.", 'abstract_zh': '基于人物视角的大规模语言模型在高 stakes 情境中的评估：CLASH数据集', 'title_zh': 'CLASH: 从多视角评估语言模型判断高 stakes 两难问题的能力'}
{'arxiv_id': 'arXiv:2504.10821', 'title': 'Progressive Rock Music Classification', 'authors': 'Arpan Nagar, Joseph Bensabat, Jokent Gaza, Moinak Dey', 'link': 'https://arxiv.org/abs/2504.10821', 'abstract': 'This study investigates the classification of progressive rock music, a genre characterized by complex compositions and diverse instrumentation, distinct from other musical styles. Addressing this Music Information Retrieval (MIR) task, we extracted comprehensive audio features, including spectrograms, Mel-Frequency Cepstral Coefficients (MFCCs), chromagrams, and beat positions from song snippets using the Librosa library. A winner-take-all voting strategy was employed to aggregate snippet-level predictions into final song classifications. We conducted a comparative analysis of various machine learning techniques. Ensemble methods, encompassing Bagging (Random Forest, ExtraTrees, Bagging Classifier) and Boosting (XGBoost, Gradient Boosting), were explored, utilizing Principal Component Analysis (PCA) for dimensionality reduction to manage computational constraints with high-dimensional feature sets. Additionally, deep learning approaches were investigated, including the development of custom 1D Convolutional Neural Network (1D CNN) architectures (named "Zuck" and "Satya") featuring specific layer configurations, normalization, and activation functions. Furthermore, we fine-tuned a state-of-the-art Audio Spectrogram Transformer (AST) model, leveraging its attention-based mechanisms for audio classification. Performance evaluation on validation and test sets revealed varying effectiveness across models, with ensemble methods like Extra Trees achieving test accuracies up to 76.38%. This research provides insights into the application and relative performance of diverse machine learning paradigms for the nuanced task of progressive rock genre classification.', 'abstract_zh': '本研究探究了进步摇滚音乐的分类，该音乐风格以复杂的编排和多样的乐器配置为特点，与其他音乐风格明显不同。针对这一音乐信息检索（MIR）任务，我们从歌曲片段中使用Librosa库提取了包括频谱图、梅尔频率倒谱系数（MFCC）、chromagram和节拍位置在内的综合音频特征。采用了一票当选的投票策略，将片段级别的预测聚合为最终的歌曲分类。我们对比分析了多种机器学习技术。探索了包涵随机森林、额外树木、袋装分类器的自助集成方法，以及XGBoost、梯度提升等提升方法，并利用主成分分析（PCA）进行降维以管理高维特征集带来的计算约束。此外，我们还研究了深度学习方法，包括开发了特定层配置、归一化和激活函数的定制一维卷积神经网络（1D CNN，分别称为“Zuck”和“Satya”）。进一步地，我们对最新的音频光谱变换器（AST）模型进行了微调，利用其基于注意力机制的技术进行音频分类。对验证集和测试集的性能评估结果显示，不同模型的效果各异，例如额外树木集成方法在测试集上的准确率可达到76.38%。本研究为多种机器学习范式在精细的进步摇滚音乐类型分类任务中的应用和相对性能提供了见解。', 'title_zh': '渐进摇滚音乐分类'}
{'arxiv_id': 'arXiv:2504.10817', 'title': 'FHBench: Towards Efficient and Personalized Federated Learning for Multimodal Healthcare', 'authors': 'Penghao Wang, Qian Chen, Teng Zhang, Yingwei Zhang, Wang Lu, Yiqiang Chen', 'link': 'https://arxiv.org/abs/2504.10817', 'abstract': 'Federated Learning (FL) has emerged as an effective solution for multi-institutional collaborations without sharing patient data, offering a range of methods tailored for diverse applications. However, real-world medical datasets are often multimodal, and computational resources are limited, posing significant challenges for existing FL approaches. Recognizing these limitations, we developed the Federated Healthcare Benchmark(FHBench), a benchmark specifically designed from datasets derived from real-world healthcare applications. FHBench encompasses critical diagnostic tasks across domains such as the nervous, cardiovascular, and respiratory systems and general pathology, providing comprehensive support for multimodal healthcare evaluations and filling a significant gap in existing benchmarks. Building on FHBench, we introduced Efficient Personalized Federated Learning with Adaptive LoRA(EPFL), a personalized FL framework that demonstrates superior efficiency and effectiveness across various healthcare modalities. Our results highlight the robustness of FHBench as a benchmarking tool and the potential of EPFL as an innovative approach to advancing healthcare-focused FL, addressing key limitations of existing methods.', 'abstract_zh': '联邦学习(Federated Learning, FL)已成为多机构合作而不共享患者数据的有效解决方案，提供了多种针对不同应用的定制方法。然而，现实世界的医疗数据集往往是多模态的，并且计算资源有限，给现有的FL方法带来了重大挑战。针对这些限制，我们开发了联邦医疗保健基准(Federated Healthcare Benchmark, FHBench)，这是一个专为来自实际医疗保健应用的数据集设计的基准。FHBench涵盖了神经系统、心血管系统、呼吸系统以及普通病理等领域的关键诊断任务，提供了全面的支持以进行多模态医疗评估，并填补了现有基准中的一个重大空白。基于FHBench，我们引入了高效个性化联邦学习与自适应LoRA(EPFL)，这是一种跨各种医疗模态具有优越效率和效果的个性化FL框架。我们的结果强调了FHBench作为基准测试工具的稳健性，并突显了EPFL作为推进以医疗保健为重点的FL的创新方法的潜力，解决了现有方法的关键限制。', 'title_zh': 'FHBench: 向高效的个性化多模态医疗联邦学习迈进'}
{'arxiv_id': 'arXiv:2504.10812', 'title': 'E2E Parking Dataset: An Open Benchmark for End-to-End Autonomous Parking', 'authors': 'Kejia Gao, Liguo Zhou, Mingjun Liu, Alois Knoll', 'link': 'https://arxiv.org/abs/2504.10812', 'abstract': 'End-to-end learning has shown great potential in autonomous parking, yet the lack of publicly available datasets limits reproducibility and benchmarking. While prior work introduced a visual-based parking model and a pipeline for data generation, training, and close-loop test, the dataset itself was not released. To bridge this gap, we create and open-source a high-quality dataset for end-to-end autonomous parking. Using the original model, we achieve an overall success rate of 85.16% with lower average position and orientation errors (0.24 meters and 0.34 degrees).', 'abstract_zh': '端到端学习在自主停车中的应用展现出巨大潜力，然而缺乏公开的数据集限制了其实现的可重复性和基准测试。尽管先前的工作引入了基于视觉的停车模型及数据生成、训练和闭环测试的管道，但数据集本身并未公开。为了弥合这一差距，我们创建并开源了一个高质量的端到端自主停车数据集。使用原始模型，我们实现了85.16%的整体成功率，并且平均位置和方向误差分别为0.24米和0.34度。', 'title_zh': 'E2E停车数据集：端到端自主停车的开放基准'}
{'arxiv_id': 'arXiv:2504.10810', 'title': 'PatrolVision: Automated License Plate Recognition in the wild', 'authors': 'Anmol Singhal Navya Singhal', 'link': 'https://arxiv.org/abs/2504.10810', 'abstract': 'Adoption of AI driven techniques in public services remains low due to challenges related to accuracy and speed of information at population scale. Computer vision techniques for traffic monitoring have not gained much popularity despite their relative strength in areas such as autonomous driving. Despite large number of academic methods for Automatic License Plate Recognition (ALPR) systems, very few provide an end to end solution for patrolling in the city. This paper presents a novel prototype for a low power GPU based patrolling system to be deployed in an urban environment on surveillance vehicles for automated vehicle detection, recognition and tracking. In this work, we propose a complete ALPR system for Singapore license plates having both single and double line creating our own YOLO based network. We focus on unconstrained capture scenarios as would be the case in real world application, where the license plate (LP) might be considerably distorted due to oblique views. In this work, we first detect the license plate from the full image using RFB-Net and rectify multiple distorted license plates in a single image. After that, the detected license plate image is fed to our network for character recognition. We evaluate the performance of our proposed system on a newly built dataset covering more than 16,000 images. The system was able to correctly detect license plates with 86\\% precision and recognize characters of a license plate in 67\\% of the test set, and 89\\% accuracy with one incorrect character (partial match). We also test latency of our system and achieve 64FPS on Tesla P4 GPU', 'abstract_zh': '基于GPU的低功耗巡逻系统在城市环境中的自动车辆检测、识别与跟踪技术研究', 'title_zh': '巡逻视界：野外自动化车牌识别'}
{'arxiv_id': 'arXiv:2504.10797', 'title': 'Name of Thrones: Evaluating How LLMs Rank Student Names, Race, and Gender in Status Hierarchies', 'authors': 'Annabella Sakunkoo, Jonathan Sakunkoo', 'link': 'https://arxiv.org/abs/2504.10797', 'abstract': "Across cultures, names tell a lot about their bearers as they carry deep personal and cultural significance. Names also serve as powerful signals of gender, race, and status in the social hierarchy - a pecking order in which individual positions shape others' expectations on their perceived competence and worth. With the widespread adoption of LLMs and as names are often an input for LLMs, it is crucial to evaluate whether LLMs may sort people into status positions based on first and last names and, if so, whether it is in an unfair, biased fashion. While prior work has primarily investigated biases in first names, little attention has been paid to last names and even less to the combined effects of first and last names. In this study, we conduct a large-scale analysis of name variations across 5 ethnicities to examine how AI exhibits name biases. Our study investigates three key characteristics of inequality and finds that LLMs reflect and reinforce status hierarchies based on names that signal gender and ethnicity as they encode differential expectations of competence, leadership, and economic potential. Contrary to the common assumption that AI tends to favor Whites, we show that East and, in some contexts, South Asian names receive higher rankings. We also disaggregate Asians, a population projected to be the largest immigrant group in the U.S. by 2055. Our results challenge the monolithic Asian model minority assumption, illustrating a more complex and stratified model of bias. Gender moderates biases, with girls facing unfair disadvantages in certain racial groups. Additionally, spanning cultural categories by adopting Western first names improves AI-perceived status for East and Southeast Asian students, particularly for girls. Our findings underscore the importance of intersectional and more nuanced understandings of race, gender, and mixed identities in the evaluation of LLMs.", 'abstract_zh': '跨文化背景下，名字揭示了其持有者大量的个人信息和文化意义。名字作为性别、种族和社会层级地位的强大信号，在社会阶层的竞争中，个体的位置影响他人对其能力与价值的预期。随着大规模语言模型（LLM）的广泛应用，以及名字往往是LLM的输入，评估LLM是否基于名字将人们排序至不同的社会地位位置，特别是以不公平、有偏见的方式进行，变得至关重要。尽管先前的工作主要研究名字中的性别偏见，但较少关注姓氏，以及名字中性与姓氏组合偏见的影响。本研究对5个民族群体中的名字变体进行大规模分析，以探究AI表现的名字偏见。我们的研究发现，LLM反映了并强化了基于性别和 ethnicity 的名字信号所体现的身份地位等级制度，这些名字编码了不同的能力、领导力和经济潜力的预期。这与普遍认为AI倾向于偏袒白人的假设相反，我们发现，东方以及在某些情况下南亚名字获得了更高的排名。我们还分解了亚洲裔美国人，预计到2055年将成为美国最大的移民群体。我们的结果显示，单一的亚洲裔美国模范少数群体假设受到挑战，展示了更加复杂和分层的偏见模式。性别调节偏见，女孩在某些种族群体中面临不公平的劣势。此外，采用西方名字跨越文化类别，提高了东方和东南亚学生在AI中的地位感知，特别是女孩。我们的研究结果强调了在评估LLM时，种族、性别和混合身份的交集和更细致理解的重要性。', 'title_zh': '王冠之名：评估语言模型对学生姓名、种族和性别在等级结构中排名的方式'}
{'arxiv_id': 'arXiv:2504.10786', 'title': 'Visual Language Models show widespread visual deficits on neuropsychological tests', 'authors': 'Gene Tangtartharakul, Katherine R. Storrs', 'link': 'https://arxiv.org/abs/2504.10786', 'abstract': 'Visual Language Models (VLMs) show remarkable performance in visual reasoning tasks, successfully tackling college-level challenges that require high-level understanding of images. However, some recent reports of VLMs struggling to reason about elemental visual concepts like orientation, position, continuity, and occlusion suggest a potential gulf between human and VLM vision. Here we use the toolkit of neuropsychology to systematically assess the capabilities of three state-of-the-art VLMs across visual domains. Using 51 tests drawn from six clinical and experimental batteries, we characterise the visual abilities of leading VLMs relative to normative performance in healthy adults. While the models excel in straightforward object recognition tasks, we find widespread deficits in low- and mid-level visual abilities that would be considered clinically significant in humans. These selective deficits, profiled through validated test batteries, suggest that an artificial system can achieve complex object recognition without developing foundational visual concepts that in humans require no explicit training.', 'abstract_zh': '视觉语言模型在视觉推理任务中展现出显著性能，成功应对了涉及高级图像理解的大学级挑战。然而，近期关于视觉语言模型在处理诸如方向、位置、连续性和遮挡等基本视觉概念方面的困难报告表明，人类与视觉语言模型的视觉之间可能存在巨大的差距。我们使用神经心理学工具，系统地评估了三种最先进的视觉语言模型在视觉领域的能力。通过来自六个临床和实验量表的51项测试，我们量化了领先视觉语言模型在视觉能力上的表现，对照健康成年人的正常表现进行比较。虽然这些模型在简单的物体识别任务上表现出色，但在低级和中级视觉能力方面我们发现了广泛存在的缺陷，这些缺陷在人类中被认为是临床显著的。这些选择性的缺陷，通过有效的测试量表进行刻画，表明一个人工系统可以在没有发展出人类在没有任何明确训练需求的情况下所需的基本视觉概念的情况下，实现复杂的物体识别能力。', 'title_zh': '视觉语言模型在神经心理测试中普遍表现出视觉缺陷'}
{'arxiv_id': 'arXiv:2504.10784', 'title': 'ATLASv2: LLM-Guided Adaptive Landmark Acquisition and Navigation on the Edge', 'authors': 'Mikolaj Walczak, Uttej Kallakuri, Tinoosh Mohsenin', 'link': 'https://arxiv.org/abs/2504.10784', 'abstract': 'Autonomous systems deployed on edge devices face significant challenges, including resource constraints, real-time processing demands, and adapting to dynamic environments. This work introduces ATLASv2, a novel system that integrates a fine-tuned TinyLLM, real-time object detection, and efficient path planning to enable hierarchical, multi-task navigation and manipulation all on the edge device, Jetson Nano. ATLASv2 dynamically expands its navigable landmarks by detecting and localizing objects in the environment which are saved to its internal knowledge base to be used for future task execution. We evaluate ATLASv2 in real-world environments, including a handcrafted home and office setting constructed with diverse objects and landmarks. Results show that ATLASv2 effectively interprets natural language instructions, decomposes them into low-level actions, and executes tasks with high success rates. By leveraging generative AI in a fully on-board framework, ATLASv2 achieves optimized resource utilization with minimal prompting latency and power consumption, bridging the gap between simulated environments and real-world applications.', 'abstract_zh': '边缘设备上部署的自主系统面临显著挑战，包括资源限制、实时处理需求以及适应动态环境的能力。本文介绍了ATLASv2新型系统，该系统整合了精细化调优的TinyLLM、实时物体检测和高效路径规划，以在Jetson Nano边缘设备上实现分层次的多任务导航和操作。ATLASv2通过检测和定位环境中的物体来动态扩展可导航地标，并将这些信息保存到其内部知识库中，以供未来任务执行使用。我们在包括手工构建的多样化家庭和办公室环境在内的真实环境中评估了ATLASv2，结果表明ATLASv2能够有效解释自然语言指令，将其分解为低级操作，并以高成功率执行任务。通过在一个完整的车载框架中利用生成式AI，ATLASv2实现了资源的高效利用，具有最小的提示延迟和能耗，从而在模拟环境与实际应用之间架起了桥梁。', 'title_zh': 'ATLASv2: LLM引导的边缘端自适应地标获取与导航'}
{'arxiv_id': 'arXiv:2504.10781', 'title': 'Neural Network Emulation of the Classical Limit in Quantum Systems via Learned Observable Mappings', 'authors': 'Kamran Majid', 'link': 'https://arxiv.org/abs/2504.10781', 'abstract': "The classical limit of quantum mechanics, formally investigated through frameworks like strict deformation quantization, remains a profound area of inquiry in the philosophy of physics. This paper explores a computational approach employing a neural network to emulate the emergence of classical behavior from the quantum harmonic oscillator as Planck's constant $\\hbar$ approaches zero. We develop and train a neural network architecture to learn the mapping from initial expectation values and $\\hbar$ to the time evolution of the expectation value of position. By analyzing the network's predictions across different regimes of hbar, we aim to provide computational insights into the nature of the quantum-classical transition. This work demonstrates the potential of machine learning as a complementary tool for exploring foundational questions in quantum mechanics and its classical limit.", 'abstract_zh': '量子力学的经典极限，通过严格的变形量ization等框架形式研究，仍然是物理学哲学中的一个深刻探究领域。本文探讨了一种采用神经网络的计算方法，模拟普朗克常数$\\hbar$趋近于零时量子简谐振子的经典行为 Emergence of Classical Behavior from the Quantum Harmonic Oscillator as $\\hbar$ Approaches Zero via a Neural Network：通过神经网络探讨量子简谐振子的经典行为随着$\\hbar$趋近于零的涌现，旨在提供量子经典过渡性质的计算见解。本文展示了机器学习作为一种探索量子力学及其经典极限基础问题的补充工具的潜在价值。', 'title_zh': '通过学习可观测量映射在量子系统中模拟经典极限的神经网络'}
{'arxiv_id': 'arXiv:2504.10768', 'title': 'The Art of Audience Engagement: LLM-Based Thin-Slicing of Scientific Talks', 'authors': 'Ralf Schmälzle, Sue Lim, Yuetong Du, Gary Bente', 'link': 'https://arxiv.org/abs/2504.10768', 'abstract': 'This paper examines the thin-slicing approach - the ability to make accurate judgments based on minimal information - in the context of scientific presentations. Drawing on research from nonverbal communication and personality psychology, we show that brief excerpts (thin slices) reliably predict overall presentation quality. Using a novel corpus of over one hundred real-life science talks, we employ Large Language Models (LLMs) to evaluate transcripts of full presentations and their thin slices. By correlating LLM-based evaluations of short excerpts with full-talk assessments, we determine how much information is needed for accurate predictions. Our results demonstrate that LLM-based evaluations align closely with human ratings, proving their validity, reliability, and efficiency. Critically, even very short excerpts (less than 10 percent of a talk) strongly predict overall evaluations. This suggests that the first moments of a presentation convey relevant information that is used in quality evaluations and can shape lasting impressions. The findings are robust across different LLMs and prompting strategies. This work extends thin-slicing research to public speaking and connects theories of impression formation to LLMs and current research on AI communication. We discuss implications for communication and social cognition research on message reception. Lastly, we suggest an LLM-based thin-slicing framework as a scalable feedback tool to enhance human communication.', 'abstract_zh': '本文探讨了薄片效应——基于极少信息做出准确判断的能力——在科学演讲中的应用。借助非言语沟通和人格心理学的研究，我们展示了简短摘录（薄片）能可靠地预测总体演讲质量。利用包含一百多个真实科学讲座的新颖语料库，我们运用大型语言模型（LLMs）评估全篇演讲及简短摘录的文本。通过将LLM评估的简短摘录与全篇演讲评估相关联，我们确定了准确预测所需的必要信息量。研究结果表明，基于LLM的评估与人类评价高度一致，证明了其有效性和可靠性。关键的是，即使极其简短的摘录（少于演讲的10%）也能强烈预测总体评价。这表明演讲的初始时刻传达了用于质量评估的相关信息，并可能形成持久印象。这些发现跨不同LLM和提示策略保持稳健。本研究将薄片效应研究拓展至公开演讲领域，并将印象形成理论与LLM及相关的人工智能通信研究联系起来。我们讨论了这对信息接收的沟通和社会认知研究的影响。最后，我们提出了一种基于LLM的薄片效果框架，作为可扩展的反馈工具以提升人类沟通能力。', 'title_zh': '基于LLM的科学演讲受众 Engagement的艺术：快速识别与分类方法'}
{'arxiv_id': 'arXiv:2504.10766', 'title': 'How Instruction and Reasoning Data shape Post-Training: Data Quality through the Lens of Layer-wise Gradients', 'authors': 'Ming Li, Yanhong Li, Ziyue Li, Tianyi Zhou', 'link': 'https://arxiv.org/abs/2504.10766', 'abstract': "As the post-training of large language models (LLMs) advances from instruction-following to complex reasoning tasks, understanding how different data affect finetuning dynamics remains largely unexplored. In this paper, we present a spectral analysis of layer-wise gradients induced by low/high-quality instruction and reasoning data for LLM post-training. Our analysis reveals that widely-studied metrics for data evaluation, e.g., IFD, InsTag, Difficulty, and Reward, can be explained and unified by spectral properties computed from gradients' singular value decomposition (SVD). Specifically, higher-quality data are usually associated with lower nuclear norms and higher effective ranks. Notably, effective rank exhibits better robustness and resolution than nuclear norm in capturing subtle quality differences. For example, reasoning data achieves substantially higher effective ranks than instruction data, implying richer gradient structures on more complex tasks. Our experiments also highlight that models within the same family share similar gradient patterns regardless of their sizes, whereas different model families diverge significantly. Providing a unified view on the effects of data quality across instruction and reasoning data, this work illuminates the interplay between data quality and training stability, shedding novel insights into developing better data exploration strategies for post-training.", 'abstract_zh': '大型语言模型（LLMs）后训练从指令跟随发展到复杂推理任务的过程中，不同数据对微调动态的影响尚待深入探索：基于梯度奇异值分解的低/高质量指令和推理数据的谱分析', 'title_zh': '基于层梯度视角的数据质量：指令与推理数据对后训练的影响'}
{'arxiv_id': 'arXiv:2504.10753', 'title': 'Epistemic Uncertainty-aware Recommendation Systems via Bayesian Deep Ensemble Learning', 'authors': 'Radin Cheraghi, Amir Mohammad Mahfoozi, Sepehr Zolfaghari, Mohammadshayan Shabani, Maryam Ramezani, Hamid R. Rabiee', 'link': 'https://arxiv.org/abs/2504.10753', 'abstract': "Recommending items to users has long been a fundamental task, and studies have tried to improve it ever since. Most well-known models commonly employ representation learning to map users and items into a unified embedding space for matching assessment. These approaches have primary limitations, especially when dealing with explicit feedback and sparse data contexts. Two primary limitations are their proneness to overfitting and failure to incorporate epistemic uncertainty in predictions. To address these problems, we propose a novel Bayesian Deep Ensemble Collaborative Filtering method named BDECF. To improve model generalization and quality, we utilize Bayesian Neural Networks, which incorporate uncertainty within their weight parameters. In addition, we introduce a new interpretable non-linear matching approach for the user and item embeddings, leveraging the advantages of the attention mechanism. Furthermore, we endorse the implementation of an ensemble-based supermodel to generate more robust and reliable predictions, resulting in a more complete model. Empirical evaluation through extensive experiments and ablation studies across a range of publicly accessible real-world datasets with differing sparsity characteristics confirms our proposed method's effectiveness and the importance of its components.", 'abstract_zh': '推荐用户项目一直是基本任务，研究者们一直在努力改进这一任务。绝大多数知名模型通常采用表示学习将用户和项目映射到统一的嵌入空间以进行匹配评估。这些方法的主要局限性，在处理显式反馈和稀疏数据上下文时尤为突出。两个主要局限性包括容易过拟合和无法在预测中整合先验不确定性。为解决这些问题，我们提出了一种新的贝叶斯深度集成协作过滤方法，命名为BDECF。为提高模型的泛化能力和质量，我们采用了贝叶斯神经网络，这种方法在其权重参数中整合了不确定性。此外，我们引入了一种新的可解释的非线性匹配方法，利用注意机制的优势，为用户和项目嵌入提供匹配方法。同时，我们倡导使用基于集成的超模型来生成更稳健和可靠的预测，从而构建一个更为完整的方法。通过广泛实验和跨多种公共真实世界稀疏特性各异的数据集的消融研究，实证评估证实了我们所提方法的有效性及其各个组件的重要性。', 'title_zh': '基于贝叶斯深度集成学习的 Epistemic 不确定性感知推荐系统'}
{'arxiv_id': 'arXiv:2504.10751', 'title': 'Communication-aware Hierarchical Map Compression of Time-Varying Environments for Mobile Robots', 'authors': 'Daniel T. Larsson, Dipankar Maity', 'link': 'https://arxiv.org/abs/2504.10751', 'abstract': 'In this paper, we develop a systematic framework for the time-sequential compression of dynamic probabilistic occupancy grids. Our approach leverages ideas from signal compression theory to formulate an optimization problem that searches for a multi-resolution hierarchical encoder that balances the quality of the compressed map (distortion) with its description size, the latter of which relates to the bandwidth required to reliably transmit the map to other agents or to store map estimates in on-board memory. The resulting optimization problem allows for multi-resolution map compressions to be obtained that satisfy available communication or memory resources, and does not require knowledge of the occupancy map dynamics. We develop an algorithm to solve our problem, and demonstrate the utility of the proposed framework in simulation on both static (i.e., non-time varying) and dynamic (time-varying) occupancy maps.', 'abstract_zh': '本文开发了一种系统框架，用于动态概率占用网格的时间序列压缩。我们的方法借鉴信号压缩理论，通过建立优化问题来寻找一个多分辨率层次编码器，该编码器在压缩图的质量（失真）与描述大小之间寻求平衡，后者与可靠传输地图所需带宽相关。该优化问题允许获得满足可用通信或存储资源的多分辨率地图压缩，并且不需要了解占用地图的动力学。我们开发了一种算法来解决该问题，并在模拟中展示了所提框架在静态和动态占用地图上的应用价值。', 'title_zh': '通信感知分层时间变化环境地图压缩方法及其在移动机器人中的应用'}
{'arxiv_id': 'arXiv:2504.10746', 'title': 'Hearing Anywhere in Any Environment', 'authors': 'Xiulong Liu, Anurag Kumar, Paul Calamia, Sebastia V. Amengual, Calvin Murdock, Ishwarya Ananthabhotla, Philip Robinson, Eli Shlizerman, Vamsi Krishna Ithapu, Ruohan Gao', 'link': 'https://arxiv.org/abs/2504.10746', 'abstract': 'In mixed reality applications, a realistic acoustic experience in spatial environments is as crucial as the visual experience for achieving true immersion. Despite recent advances in neural approaches for Room Impulse Response (RIR) estimation, most existing methods are limited to the single environment on which they are trained, lacking the ability to generalize to new rooms with different geometries and surface materials. We aim to develop a unified model capable of reconstructing the spatial acoustic experience of any environment with minimum additional measurements. To this end, we present xRIR, a framework for cross-room RIR prediction. The core of our generalizable approach lies in combining a geometric feature extractor, which captures spatial context from panorama depth images, with a RIR encoder that extracts detailed acoustic features from only a few reference RIR samples. To evaluate our method, we introduce ACOUSTICROOMS, a new dataset featuring high-fidelity simulation of over 300,000 RIRs from 260 rooms. Experiments show that our method strongly outperforms a series of baselines. Furthermore, we successfully perform sim-to-real transfer by evaluating our model on four real-world environments, demonstrating the generalizability of our approach and the realism of our dataset.', 'abstract_zh': '在混合现实应用中，空间环境中的真实声学体验与视觉体验一样至关重要，对于实现真正的沉浸感至关重要。尽管在基于神经网络的房间冲激响应（RIR）估计方面取得了近期进展，但大多数现有方法仅限于它们所训练的单一环境，缺乏在不同几何结构和表面材料的新房间中泛化的能力。我们旨在开发一种统一模型，能够在最少的额外测量下重构任何环境的空间声学体验。为此，我们提出了xRIR，一种跨房间RIR预测框架。我们泛化方法的核心在于结合一个几何特征提取器，该提取器从全景深度图像中捕获空间上下文，与一个仅从少量参考RIR样本中提取详细声学特征的RIR编码器相结合。为了评估我们的方法，我们引入了ACOUSTICROOMS新数据集，该数据集包含来自260个房间的超过300,000个高保真模拟的RIR。实验结果显示，我们的方法显著优于一系列基线方法。此外，我们成功地通过在四个真实世界环境中评估我们的模型展示了方法的泛化能力和数据集的真实感。', 'title_zh': '在任意环境下的 anytime  hearing'}
{'arxiv_id': 'arXiv:2504.10738', 'title': 'CleanMAP: Distilling Multimodal LLMs for Confidence-Driven Crowdsourced HD Map Updates', 'authors': 'Ankit Kumar Shaw, Kun Jiang, Tuopu Wen, Chandan Kumar Sah, Yining Shi, Mengmeng Yang, Diange Yang, Xiaoli Lian', 'link': 'https://arxiv.org/abs/2504.10738', 'abstract': "The rapid growth of intelligent connected vehicles (ICVs) and integrated vehicle-road-cloud systems has increased the demand for accurate, real-time HD map updates. However, ensuring map reliability remains challenging due to inconsistencies in crowdsourced data, which suffer from motion blur, lighting variations, adverse weather, and lane marking degradation. This paper introduces CleanMAP, a Multimodal Large Language Model (MLLM)-based distillation framework designed to filter and refine crowdsourced data for high-confidence HD map updates. CleanMAP leverages an MLLM-driven lane visibility scoring model that systematically quantifies key visual parameters, assigning confidence scores (0-10) based on their impact on lane detection. A novel dynamic piecewise confidence-scoring function adapts scores based on lane visibility, ensuring strong alignment with human evaluations while effectively filtering unreliable data. To further optimize map accuracy, a confidence-driven local map fusion strategy ranks and selects the top-k highest-scoring local maps within an optimal confidence range (best score minus 10%), striking a balance between data quality and quantity. Experimental evaluations on a real-world autonomous vehicle dataset validate CleanMAP's effectiveness, demonstrating that fusing the top three local maps achieves the lowest mean map update error of 0.28m, outperforming the baseline (0.37m) and meeting stringent accuracy thresholds (<= 0.32m). Further validation with real-vehicle data confirms 84.88% alignment with human evaluators, reinforcing the model's robustness and reliability. This work establishes CleanMAP as a scalable and deployable solution for crowdsourced HD map updates, ensuring more precise and reliable autonomous navigation. The code will be available at this https URL", 'abstract_zh': '基于多模态大型语言模型的CleanMAP地图更新框架：过滤和精炼众包数据以提高高清地图的可靠性', 'title_zh': 'CleanMAP: 精炼多模态LLMs以实现基于信心驱动的高精度地图众包更新'}
{'arxiv_id': 'arXiv:2504.10735', 'title': 'Frozen Layers: Memory-efficient Many-fidelity Hyperparameter Optimization', 'authors': 'Timur Carstensen, Neeratyoy Mallik, Frank Hutter, Martin Rapp', 'link': 'https://arxiv.org/abs/2504.10735', 'abstract': 'As model sizes grow, finding efficient and cost-effective hyperparameter optimization (HPO) methods becomes increasingly crucial for deep learning pipelines. While multi-fidelity HPO (MF-HPO) trades off computational resources required for DL training with lower fidelity estimations, existing fidelity sources often fail under lower compute and memory constraints. We propose a novel fidelity source: the number of layers that are trained or frozen during training. For deep networks, this approach offers significant compute and memory savings while preserving rank correlations between hyperparameters at low fidelities compared to full model training. We demonstrate this in our empirical evaluation across ResNets and Transformers and additionally analyze the utility of frozen layers as a fidelity in using GPU resources as a fidelity in HPO, and for a combined MF-HPO with other fidelity sources. This contribution opens new applications for MF-HPO with hardware resources as a fidelity and creates opportunities for improved algorithms navigating joint fidelity spaces.', 'abstract_zh': '随着模型规模的增长，寻找高效的成本优化超参数优化（HPO）方法对于深度学习流水线变得越来越重要。尽管多保真度HPO（MF-HPO）在降低计算资源消耗的同时提供较低保真度的估计，但现有的保真度源在较低的计算和内存约束下常常失效。我们提出了一种新的保真度源：在训练过程中被训练或冻结的层的数量。对于深层网络，这种方法在保留低保真度下超参数之间的排序相关性的同时，提供了显著的计算和内存节省。我们在ResNets和Transformers的实证评估中展示了这一点，并进一步分析了冻结层作为保真度在使用GPU资源进行HPO以及与其他保真度源结合的多保真度HPO中的效用。这一贡献为将硬件资源作为保真度的多保真度HPO开辟了新的应用，并为在联合保真度空间中寻找改进算法提供了机会。', 'title_zh': '冻结层：高效多保真度超参数优化'}
{'arxiv_id': 'arXiv:2504.10700', 'title': 'Optimizing Data Distribution and Kernel Performance for Efficient Training of Chemistry Foundation Models: A Case Study with MACE', 'authors': 'Jesun Firoz, Franco Pellegrini, Mario Geiger, Darren Hsu, Jenna A. Bilbrey, Han-Yi Chou, Maximilian Stadler, Markus Hoehnerbach, Tingyu Wang, Dejun Lin, Emine Kucukbenli, Henry W. Sprueill, Ilyes Batatia, Sotiris S. Xantheas, MalSoon Lee, Chris Mundy, Gabor Csanyi, Justin S. Smith, Ponnuswamy Sadayappan, Sutanay Choudhury', 'link': 'https://arxiv.org/abs/2504.10700', 'abstract': 'Chemistry Foundation Models (CFMs) that leverage Graph Neural Networks (GNNs) operating on 3D molecular graph structures are becoming indispensable tools for computational chemists and materials scientists. These models facilitate the understanding of matter and the discovery of new molecules and materials. In contrast to GNNs operating on a large homogeneous graphs, GNNs used by CFMs process a large number of geometric graphs of varying sizes, requiring different optimization strategies than those developed for large homogeneous GNNs. This paper presents optimizations for two critical phases of CFM training: data distribution and model training, targeting MACE - a state-of-the-art CFM. We address the challenge of load balancing in data distribution by formulating it as a multi-objective bin packing problem. We propose an iterative algorithm that provides a highly effective, fast, and practical solution, ensuring efficient data distribution. For the training phase, we identify symmetric tensor contraction as the key computational kernel in MACE and optimize this kernel to improve the overall performance. Our combined approach of balanced data distribution and kernel optimization significantly enhances the training process of MACE. Experimental results demonstrate a substantial speedup, reducing per-epoch execution time for training from 12 to 2 minutes on 740 GPUs with a 2.6M sample dataset.', 'abstract_zh': '基于图神经网络的化学基础模型中的优化研究：以MACE为例', 'title_zh': '化学基础模型高效训练中的数据分布优化与核函数性能提升：MACE案例研究'}
{'arxiv_id': 'arXiv:2504.10699', 'title': 'HyRRT-Connect: Bidirectional Motion Planning for Hybrid Dynamical Systems', 'authors': 'Nan Wang, Ricardo G. Sanfelice', 'link': 'https://arxiv.org/abs/2504.10699', 'abstract': 'This paper proposes a bidirectional rapidly-exploring random trees (RRT) algorithm to solve the motion planning problem for hybrid systems. The proposed algorithm, called HyRRT-Connect, propagates in both forward and backward directions in hybrid time until an overlap between the forward and backward propagation results is detected. Then, HyRRT-Connect constructs a motion plan through the reversal and concatenation of functions defined on hybrid time domains, ensuring that the motion plan satisfies the given hybrid dynamics. To address the potential discontinuity along the flow caused by tolerating some distance between the forward and backward partial motion plans, we reconstruct the backward partial motion plan by a forward-in-hybrid-time simulation from the final state of the forward partial motion plan. effectively eliminating the discontinuity. The proposed algorithm is applied to an actuated bouncing ball system and a walking robot example to highlight its computational improvement.', 'abstract_zh': '该论文提出了一种双向快速探索随机树（RRT）算法以解决混合系统的运动规划问题。所提出的方法称为HyRRT-Connect，它在混合时间的前后两个方向上进行扩展，直到检测到前后扩展之间的重叠。然后，HyRRT-Connect通过反转和拼接定义在混合时间域上的函数来构造运动计划，确保运动计划满足给定的混合动力学。为了解决由前后局部运动计划之间允许的距离导致的沿流的潜在不连续性，我们通过从前向混合时间的最终状态进行反向模拟来重构后向局部运动计划，从而有效消除不连续性。所提出的方法应用于一个受控跳球系统和一个步行机器人示例，以突出其计算上的改进。', 'title_zh': 'HyRRT-Connect：混合动力系统双向运动规划'}
{'arxiv_id': 'arXiv:2504.10694', 'title': 'The Jailbreak Tax: How Useful are Your Jailbreak Outputs?', 'authors': 'Kristina Nikolić, Luze Sun, Jie Zhang, Florian Tramèr', 'link': 'https://arxiv.org/abs/2504.10694', 'abstract': 'Jailbreak attacks bypass the guardrails of large language models to produce harmful outputs. In this paper, we ask whether the model outputs produced by existing jailbreaks are actually useful. For example, when jailbreaking a model to give instructions for building a bomb, does the jailbreak yield good instructions? Since the utility of most unsafe answers (e.g., bomb instructions) is hard to evaluate rigorously, we build new jailbreak evaluation sets with known ground truth answers, by aligning models to refuse questions related to benign and easy-to-evaluate topics (e.g., biology or math). Our evaluation of eight representative jailbreaks across five utility benchmarks reveals a consistent drop in model utility in jailbroken responses, which we term the jailbreak tax. For example, while all jailbreaks we tested bypass guardrails in models aligned to refuse to answer math, this comes at the expense of a drop of up to 92% in accuracy. Overall, our work proposes the jailbreak tax as a new important metric in AI safety, and introduces benchmarks to evaluate existing and future jailbreaks. We make the benchmark available at this https URL', 'abstract_zh': 'Jailbreak攻击绕过了大型语言模型的防护措施以产生有害输出。本文探讨现有的 Jailbreak 是否产生实际有用的结果。例如，当将模型劫持以提供制备炸弹的指令时，Jailbreak 是否会产生有效的指令？由于大多数不安全答案（例如，炸弹指令）的实用性难以严格评估，我们通过将模型对涉及良性且易于评估的主题（例如，生物学或数学）的回答进行拒绝，构建了新的 Jailbreak 评估集。在五个实用性标准上的评估结果显示，Jailbreak 响应的模型实用性存在一致下降，我们称之为 Jailbreak 税。例如，所有测试的 Jailbreak 能绕过模型对数学问题的回答限制，但准确率下降幅度高达 92%。整体而言，我们的工作将 Jailbreak 税提出作为人工智能安全领域的一项新重要指标，并引入了评估现有和未来 Jailbreak 的基准。相关基准可在以下链接获得：this https URL', 'title_zh': '越狱成本：你的越狱输出有用吗？'}
{'arxiv_id': 'arXiv:2504.10685', 'title': 'NTIRE 2025 Challenge on Cross-Domain Few-Shot Object Detection: Methods and Results', 'authors': 'Yuqian Fu, Xingyu Qiu, Bin Ren, Yanwei Fu, Radu Timofte, Nicu Sebe, Ming-Hsuan Yang, Luc Van Gool, Kaijin Zhang, Qingpeng Nong, Xiugang Dong, Hong Gao, Xiangsheng Zhou, Jiancheng Pan, Yanxing Liu, Xiao He, Jiahao Li, Yuze Sun, Xiaomeng Huang, Zhenyu Zhang, Ran Ma, Yuhan Liu, Zijian Zhuang, Shuai Yi, Yixiong Zou, Lingyi Hong, Mingxi Chen, Runze Li, Xingdong Sheng, Wenqiang Zhang, Weisen Chen, Yongxin Yan, Xinguo Chen, Yuanjie Shao, Zhengrong Zuo, Nong Sang, Hao Wu, Haoran Sun, Shuming Hu, Yan Zhang, Zhiguang Shi, Yu Zhang, Chao Chen, Tao Wang, Da Feng, Linhai Zhuo, Ziming Lin, Yali Huang, Jie Me, Yiming Yang, Mi Guo, Mingyuan Jiu, Mingliang Xu, Maomao Xiong, Qunshu Zhang, Xinyu Cao, Yuqing Yang, Dianmo Sheng, Xuanpu Zhao, Zhiyu Li, Xuyang Ding, Wenqian Li', 'link': 'https://arxiv.org/abs/2504.10685', 'abstract': 'Cross-Domain Few-Shot Object Detection (CD-FSOD) poses significant challenges to existing object detection and few-shot detection models when applied across domains. In conjunction with NTIRE 2025, we organized the 1st CD-FSOD Challenge, aiming to advance the performance of current object detectors on entirely novel target domains with only limited labeled data. The challenge attracted 152 registered participants, received submissions from 42 teams, and concluded with 13 teams making valid final submissions. Participants approached the task from diverse perspectives, proposing novel models that achieved new state-of-the-art (SOTA) results under both open-source and closed-source settings. In this report, we present an overview of the 1st NTIRE 2025 CD-FSOD Challenge, highlighting the proposed solutions and summarizing the results submitted by the participants.', 'abstract_zh': '跨域少样本对象检测（CD-FSOD）在不同领域应用时对现有对象检测和少样本检测模型提出了重大挑战。为促进对象检测器在全新目标领域上的性能提升，仅凭有限标注数据，我们与NTIRE 2025合作组织了第1届CD-FSOD挑战赛。该挑战赛吸引了152名注册参赛者，共收到42支队伍的提交，并有13支队伍提交了有效的最终结果。参赛者从多个角度出发，提出了新的模型，在开源和闭源环境下均取得了新的最先进（SOTA）成果。本文报告了第1届NTIRE 2025 CD-FSOD挑战赛的概述，强调了提出的方法并总结了参赛者的提交结果。', 'title_zh': 'NTIRE 2025挑战赛：跨域少样本对象检测——方法与结果'}
{'arxiv_id': 'arXiv:2504.10679', 'title': 'Keyword Extraction, and Aspect Classification in Sinhala, English, and Code-Mixed Content', 'authors': 'F.A. Rizvi, T. Navojith, A.M.N.H. Adhikari, W.P.U. Senevirathna, Dharshana Kasthurirathna, Lakmini Abeywardhana', 'link': 'https://arxiv.org/abs/2504.10679', 'abstract': 'Brand reputation in the banking sector is maintained through insightful analysis of customer opinion on code-mixed and multilingual content. Conventional NLP models misclassify or ignore code-mixed text, when mix with low resource languages such as Sinhala-English and fail to capture domain-specific knowledge. This study introduces a hybrid NLP method to improve keyword extraction, content filtering, and aspect-based classification of banking content. Keyword extraction in English is performed with a hybrid approach comprising a fine-tuned SpaCy NER model, FinBERT-based KeyBERT embeddings, YAKE, and EmbedRank, which results in a combined accuracy of 91.2%. Code-mixed and Sinhala keywords are extracted using a fine-tuned XLM-RoBERTa model integrated with a domain-specific Sinhala financial vocabulary, and it results in an accuracy of 87.4%. To ensure data quality, irrelevant comment filtering was performed using several models, with the BERT-base-uncased model achieving 85.2% for English and XLM-RoBERTa 88.1% for Sinhala, which was better than GPT-4o, SVM, and keyword-based filtering. Aspect classification followed the same pattern, with the BERT-base-uncased model achieving 87.4% for English and XLM-RoBERTa 85.9% for Sinhala, both exceeding GPT-4 and keyword-based approaches. These findings confirm that fine-tuned transformer models outperform traditional methods in multilingual financial text analysis. The present framework offers an accurate and scalable solution for brand reputation monitoring in code-mixed and low-resource banking environments.', 'abstract_zh': '银行领域的品牌声誉通过深入分析混合语言和多语言内容的客户意见来维护。传统的NLP模型在低资源语言（如僧伽罗语-英语混合文本）中会出现误分类或忽略，并且难以捕捉领域特定知识。本研究引入了一种混合NLP方法，以改进银行内容的关键词提取、内容过滤和方面分类。关键词提取在英语中采用了一种混合方法，结合了微调的SpaCy NER模型、FinBERT基的KeyBERT嵌入、YAKE和EmbedRank，最终准确率为91.2%。僧伽罗语和混合语言关键词采用集成域特定僧伽罗语金融词汇的微调XLM-RoBERTa模型进行提取，准确率为87.4%。为保证数据质量，不相关的评论过滤使用了多种模型，其中BERT-base-uncased模型在英语中的准确率为85.2%，XLM-RoBERTa模型在僧伽罗语中的准确率为88.1%，优于GPT-4o、SVM和基于关键词的过滤。方面分类也遵循相同的模式，BERT-base-uncased模型在英语中的准确率为87.4%，XLM-RoBERTa模型在僧伽罗语中的准确率为85.9%，均超过了GPT-4和基于关键词的方法。这些发现证实，微调的变换器模型在多语言金融文本分析中优于传统方法。当前框架为混合语言和低资源银行环境中的品牌声誉监控提供了准确且可扩展的解决方案。', 'title_zh': 'Sinhala、English及其代码混合内容中的关键信息提取与aspect分类'}
{'arxiv_id': 'arXiv:2504.10677', 'title': 'Achieving Optimal Tissue Repair Through MARL with Reward Shaping and Curriculum Learning', 'authors': 'Muhammad Al-Zafar Khan, Jamal Al-Karaki', 'link': 'https://arxiv.org/abs/2504.10677', 'abstract': 'In this paper, we present a multi-agent reinforcement learning (MARL) framework for optimizing tissue repair processes using engineered biological agents. Our approach integrates: (1) stochastic reaction-diffusion systems modeling molecular signaling, (2) neural-like electrochemical communication with Hebbian plasticity, and (3) a biologically informed reward function combining chemical gradient tracking, neural synchronization, and robust penalties. A curriculum learning scheme guides the agent through progressively complex repair scenarios. In silico experiments demonstrate emergent repair strategies, including dynamic secretion control and spatial coordination.', 'abstract_zh': '本研究提出了一种多智能体强化学习（MARL）框架，用于利用工程生物代理人优化组织修复过程。该方法集成如下内容：（1）随机反应-扩散系统建模分子信号传导，（2）具有 Hebbian 可塑性的神经似信号化学通信，以及（3）一种基于化学梯度跟踪、神经同步和鲁棒惩罚的生物启发式奖励函数。通过阶梯式学习方案引导智能体逐步通过复杂度渐增的修复场景。计算机模拟实验展示了涌现的修复策略，包括动态分泌控制和空间协调。', 'title_zh': '通过奖励塑造和分级学习实现最优组织修复的MARL方法'}
{'arxiv_id': 'arXiv:2504.10663', 'title': 'Characterizing Knowledge Manipulation in a Russian Wikipedia Fork', 'authors': 'Mykola Trokhymovych, Oleksandr Kosovan, Nathan Forrester, Pablo Aragón, Diego Saez-Trumper, Ricardo Baeza-Yates', 'link': 'https://arxiv.org/abs/2504.10663', 'abstract': 'Wikipedia is powered by MediaWiki, a free and open-source software that is also the infrastructure for many other wiki-based online encyclopedias. These include the recently launched website Ruwiki, which has copied and modified the original Russian Wikipedia content to conform to Russian law. To identify practices and narratives that could be associated with different forms of knowledge manipulation, this article presents an in-depth analysis of this Russian Wikipedia fork. We propose a methodology to characterize the main changes with respect to the original version. The foundation of this study is a comprehensive comparative analysis of more than 1.9M articles from Russian Wikipedia and its fork. Using meta-information and geographical, temporal, categorical, and textual features, we explore the changes made by Ruwiki editors. Furthermore, we present a classification of the main topics of knowledge manipulation in this fork, including a numerical estimation of their scope. This research not only sheds light on significant changes within Ruwiki, but also provides a methodology that could be applied to analyze other Wikipedia forks and similar collaborative projects.', 'abstract_zh': 'Wikipedia由MediaWiki驱动，这是一个免费开源的软件，也是许多其他基于维基的在线百科全书的基础。这包括最近推出的Ruwiki网站，该网站复制并修改了原始的俄罗斯维基百科内容以符合俄罗斯法律规定。为了识别与不同形式的知识操纵相关的行为和叙事，本文对这个俄罗斯维基百科分支进行了深入分析。我们提出了一种方法来描述与原始版本相比的主要变化。本研究的基础是对俄罗斯维基百科及其分支超过190万篇文章进行了全面比较分析。借助元信息和地理、时间、类别以及文本特征，我们探讨了Ruwiki编辑者所做的更改。此外，我们对该分支中的主要知识操纵主题进行了分类，并对其范围进行了量化评估。这项研究不仅揭示了Ruwiki中的重要变化，还提供了一种可以应用于分析其他维基分支和类似协作项目的分析方法。', 'title_zh': 'characterizing知识操纵在俄罗斯维基百科分支中'}
{'arxiv_id': 'arXiv:2504.10660', 'title': 'LITERA: An LLM Based Approach to Latin-to-English Translation', 'authors': 'Paul Rosu', 'link': 'https://arxiv.org/abs/2504.10660', 'abstract': "This paper introduces an LLM-based Latin-to-English translation platform designed to address the challenges of translating Latin texts. We named the model LITERA, which stands for Latin Interpretation and Translations into English for Research Assistance. Through a multi-layered translation process utilizing a fine-tuned version of GPT-4o-mini and GPT-4o, LITERA offers an unprecedented level of accuracy, showcased by greatly improved BLEU scores, particularly in classical Latin, along with improved BLEURT scores. The development of LITERA involved close collaboration with Duke University's Classical Studies Department, which was instrumental in creating a small, high-quality parallel Latin-English dataset. This paper details the architecture, fine-tuning methodology, and prompting strategies used in LITERA, emphasizing its ability to produce literal translations.", 'abstract_zh': '基于LLM的拉丁文到英文翻译平台：LITERA及其多层翻译方法和准确性改进', 'title_zh': 'LITERA: 一种基于大语言模型的拉丁语到英语翻译方法'}
{'arxiv_id': 'arXiv:2504.10655', 'title': 'MatterTune: An Integrated, User-Friendly Platform for Fine-Tuning Atomistic Foundation Models to Accelerate Materials Simulation and Discovery', 'authors': 'Lingyu Kong, Nima Shoghi, Guoxiang Hu, Pan Li, Victor Fung', 'link': 'https://arxiv.org/abs/2504.10655', 'abstract': 'Geometric machine learning models such as graph neural networks have achieved remarkable success in recent years in chemical and materials science research for applications such as high-throughput virtual screening and atomistic simulations. The success of these models can be attributed to their ability to effectively learn latent representations of atomic structures directly from the training data. Conversely, this also results in high data requirements for these models, hindering their application to problems which are data sparse which are common in this domain. To address this limitation, there is a growing development in the area of pre-trained machine learning models which have learned general, fundamental, geometric relationships in atomistic data, and which can then be fine-tuned to much smaller application-specific datasets. In particular, models which are pre-trained on diverse, large-scale atomistic datasets have shown impressive generalizability and flexibility to downstream applications, and are increasingly referred to as atomistic foundation models. To leverage the untapped potential of these foundation models, we introduce MatterTune, a modular and extensible framework that provides advanced fine-tuning capabilities and seamless integration of atomistic foundation models into downstream materials informatics and simulation workflows, thereby lowering the barriers to adoption and facilitating diverse applications in materials science. In its current state, MatterTune supports a number of state-of-the-art foundation models such as ORB, MatterSim, JMP, and EquformerV2, and hosts a wide range of features including a modular and flexible design, distributed and customizable fine-tuning, broad support for downstream informatics tasks, and more.', 'abstract_zh': '几何机器学习模型如图神经网络近年来在化学和材料科学研究中取得了显著成功，特别是在高通量虚拟筛选和原子尺度模拟应用方面。这些模型的成功归因于它们能够直接从训练数据中有效地学习原子结构的潜在表示。相反，这也导致这些模型需要高数据需求，从而阻碍了它们在数据稀疏问题中的应用，而这类问题在该领域非常常见。为了解决这一局限性，预训练机器学习模型的发展日益增长，这些模型已在原子尺度数据中学到了一般性和基础性的几何关系，并可进一步微调以适应较小的应用特定数据集。特别是，在多样化大规模原子尺度数据集上预训练的模型展现出了强大的泛化能力和下游应用的灵活性，并逐渐被称为原子尺度基础模型。为了充分利用这些基础模型的潜力，我们引入了MatterTune，这是一种模块化和可扩展的框架，提供了高级微调功能，并无缝整合原子尺度基础模型到下游材料informatics和模拟工作流中，从而降低了采用门槛并促进了材料科学中各种应用的实现。目前，MatterTune 支持包括 ORB、MatterSim、JMP 和 EquformerV2 在内的多种最先进的基础模型，并提供了包括模块化和灵活设计、分布式和可定制的微调、对下游informatics任务的广泛支持等一系列功能。', 'title_zh': 'MatterTune: 一个集成的、用户友好的平台，用于优化原子级基础模型以加速材料模拟与发现'}
{'arxiv_id': 'arXiv:2504.10650', 'title': 'Will AI shape the way we speak? The emerging sociolinguistic influence of synthetic voices', 'authors': 'Éva Székely, Jūra Miniota, Míša, Hejná', 'link': 'https://arxiv.org/abs/2504.10650', 'abstract': "The growing prevalence of conversational voice interfaces, powered by developments in both speech and language technologies, raises important questions about their influence on human communication. While written communication can signal identity through lexical and stylistic choices, voice-based interactions inherently amplify socioindexical elements - such as accent, intonation, and speech style - which more prominently convey social identity and group affiliation. There is evidence that even passive media such as television is likely to influence the audience's linguistic patterns. Unlike passive media, conversational AI is interactive, creating a more immersive and reciprocal dynamic that holds a greater potential to impact how individuals speak in everyday interactions. Such heightened influence can be expected to arise from phenomena such as acoustic-prosodic entrainment and linguistic accommodation, which occur naturally during interaction and enable users to adapt their speech patterns in response to the system. While this phenomenon is still emerging, its potential societal impact could provide organisations, movements, and brands with a subtle yet powerful avenue for shaping and controlling public perception and social identity. We argue that the socioindexical influence of AI-generated speech warrants attention and should become a focus of interdisciplinary research, leveraging new and existing methodologies and technologies to better understand its implications.", 'abstract_zh': '基于语音技术发展的对话式语音接口日益普及，这对人类交流产生了重要影响。虽然书面交流可以通过词汇和风格选择来信号身份，但基于语音的交互会更显著地放大社会指数性特征，如口音、语调和言语风格，这些特征更直接地传达了社会身份和群体归属感。有证据表明，即使是电视这样的被动媒体也会影响观众的语言模式。与被动媒体不同，对话式AI具有互动性，能够创建一种更沉浸和互动的动力学，具有更大的潜力影响个体在日常交流中的言语方式。这种增强的影响可以预期源于诸如声学-语调同步和语言调整等自然现象，这些现象在互动过程中会发生，使用户能够根据系统的响应调整自己的言语模式。尽管这一现象仍处于初期阶段，但其潜在的社会影响可能会为组织、运动和品牌提供一种微妙而有力的途径，以塑造和控制公共认知和社会身份。我们主张，应关注AI生成语音的社会指数性影响，并将其作为跨学科研究的重点，利用新旧方法和技术来更好地理解其影响。', 'title_zh': 'AI是否会塑造我们的语言方式？合成语音的新兴社会语言学影响。'}
{'arxiv_id': 'arXiv:2504.10646', 'title': 'Weight-of-Thought Reasoning: Exploring Neural Network Weights for Enhanced LLM Reasoning', 'authors': 'Saif Punjwani, Larry Heck', 'link': 'https://arxiv.org/abs/2504.10646', 'abstract': 'Large language models (LLMs) have demonstrated remarkable reasoning capabilities when prompted with strategies such as Chain-of-Thought (CoT). However, these approaches focus on token-level output without considering internal weight dynamics. We introduce Weight-of-Thought (WoT) reasoning, a novel approach that examines neural network weights before inference to identify reasoning pathways. Unlike existing methods, WoT explores the weight space through graph-based message passing, multi-step reasoning processes, and attention mechanisms. Our implementation creates an interconnected graph of reasoning nodes. Experiments on diverse reasoning tasks (syllogistic, mathematical, algebraic, combinatorial, and geometric) demonstrate that WoT achieves superior performance compared to traditional methods, particularly for complex problems. This approach leads to both improved performance and greater interpretability of the reasoning process, offering a promising direction for enhancing LLM reasoning capabilities.', 'abstract_zh': 'Large语言模型（LLMs）在使用Chain-of-Thought（CoT）等策略提示下展现了显著的推理能力。然而，这些方法关注于token级别的输出而不考虑内部权重动态。我们引入了一种名为Weight-of-Thought（WoT）的新颖推理方法，该方法在推理前检查神经网络权重以识别推理路径。与现有方法不同，WoT通过图基信息传递、多步推理过程和注意力机制探索权重空间。我们的实现创建了一个相互连接的推理节点图。实验表明，WoT在各种推理任务（三段论、数学、代数、组合和几何）中优于传统方法，特别是在复杂问题上表现更佳。这种方法既提高了推理性能又增强了推理过程的可解释性，为提升LLM的推理能力提供了有前途的方向。', 'title_zh': '思维权重推理：探索神经网络权重以增强LLM推理'}
{'arxiv_id': 'arXiv:2504.10637', 'title': 'Better Estimation of the KL Divergence Between Language Models', 'authors': 'Afra Amini, Tim Vieira, Ryan Cotterell', 'link': 'https://arxiv.org/abs/2504.10637', 'abstract': 'Estimating the Kullback--Leibler (KL) divergence between language models has many applications, e.g., reinforcement learning from human feedback (RLHF), interpretability, and knowledge distillation. However, computing the exact KL divergence between two arbitrary language models is intractable. Thus, practitioners often resort to the use of sampling-based estimators. While it is easy to fashion a simple Monte Carlo (MC) estimator that provides an unbiased estimate of the KL divergence between language models, this estimator notoriously suffers from high variance, and can even result in a negative estimate of the KL divergence, a non-negative quantity. In this paper, we introduce a Rao--Blackwellized estimator that is also unbiased and provably has variance less than or equal to that of the standard Monte Carlo estimator. In an empirical study on sentiment-controlled fine-tuning, we show that our estimator provides more stable KL estimates and reduces variance substantially in practice. Additionally, we derive an analogous Rao--Blackwellized estimator of the gradient of the KL divergence, which leads to more stable training and produces models that more frequently appear on the Pareto frontier of reward vs. KL compared to the ones trained with the MC estimator of the gradient.', 'abstract_zh': '语言模型之间Kullback--Leibler（KL）散度的Rao--Blackwell化估计及其应用', 'title_zh': '更好的语言模型之间KL散度估计方法'}
{'arxiv_id': 'arXiv:2504.10636', 'title': 'Who is More Bayesian: Humans or ChatGPT?', 'authors': 'Tianshi Mu, Pranjal Rawat, John Rust, Chengjun Zhang, Qixuan Zhong', 'link': 'https://arxiv.org/abs/2504.10636', 'abstract': "We compare the performance of human and artificially intelligent (AI) decision makers in simple binary classification tasks where the optimal decision rule is given by Bayes Rule. We reanalyze choices of human subjects gathered from laboratory experiments conducted by El-Gamal and Grether and Holt and Smith. We confirm that while overall, Bayes Rule represents the single best model for predicting human choices, subjects are heterogeneous and a significant share of them make suboptimal choices that reflect judgement biases described by Kahneman and Tversky that include the ``representativeness heuristic'' (excessive weight on the evidence from the sample relative to the prior) and ``conservatism'' (excessive weight on the prior relative to the sample). We compare the performance of AI subjects gathered from recent versions of large language models (LLMs) including several versions of ChatGPT. These general-purpose generative AI chatbots are not specifically trained to do well in narrow decision making tasks, but are trained instead as ``language predictors'' using a large corpus of textual data from the web. We show that ChatGPT is also subject to biases that result in suboptimal decisions. However we document a rapid evolution in the performance of ChatGPT from sub-human performance for early versions (ChatGPT 3.5) to superhuman and nearly perfect Bayesian classifications in the latest versions (ChatGPT 4o).", 'abstract_zh': '我们比较了人类和人工智能（AI）决策者在简单二分类任务中的表现，这些任务的最佳决策规则由贝叶斯规则给出。我们重新分析了埃尔-加马尔和格雷瑟以及霍尔特和史密斯实验室实验中收集的人类被试的选择。我们确认，虽然总体而言，贝叶斯规则是预测人类选择的单一最佳模型，但被试之间存在异质性，其中相当一部分人做出了反映卡尼曼和特维斯基所描述的判断偏差的次优选择，这些偏差包括“代表性启发式”（样本证据相对于先验信息的过度权重）和“保守性”（先验信息相对于样本信息的过度权重）。我们比较了来自最近版本的大规模语言模型（LLMs）包括多个版本的ChatGPT收集到的AI被试的表现。这些通用生成型AI聊天机器人并不是专门为狭窄的决策任务表现良好而进行训练，而是作为“语言预测器”使用网络上的大量文本数据进行训练。我们证明ChatGPT也受到了导致次优决策的偏差的影响。然而，我们记录了ChatGPT在性能上的快速进化，从早期版本（ChatGPT 3.5）的人类以下水平到最新版本（ChatGPT 4）的超人类和近乎完美的贝叶斯分类。', 'title_zh': '谁更遵循贝叶斯原则：人类还是ChatGPT？'}
{'arxiv_id': 'arXiv:2504.10612', 'title': 'Energy Matching: Unifying Flow Matching and Energy-Based Models for Generative Modeling', 'authors': 'Michal Balcerak, Tamaz Amiranashvili, Suprosanna Shit, Antonio Terpin, Sebastian Kaltenbach, Petros Koumoutsakos, Bjoern Menze', 'link': 'https://arxiv.org/abs/2504.10612', 'abstract': 'Generative models often map noise to data by matching flows or scores, but these approaches become cumbersome for incorporating partial observations or additional priors. Inspired by recent advances in Wasserstein gradient flows, we propose Energy Matching, a framework that unifies flow-based approaches with the flexibility of energy-based models (EBMs). Far from the data manifold, samples move along curl-free, optimal transport paths from noise to data. As they approach the data manifold, an entropic energy term guides the system into a Boltzmann equilibrium distribution, explicitly capturing the underlying likelihood structure of the data. We parameterize this dynamic with a single time-independent scalar field, which serves as both a powerful generator and a flexible prior for effective regularization of inverse problems. Our method substantially outperforms existing EBMs on CIFAR-10 generation (FID 3.97 compared to 8.61), while retaining the simulation-free training of transport-based approaches away from the data manifold. Additionally, we exploit the flexibility of our method and introduce an interaction energy for diverse mode exploration. Our approach focuses on learning a static scalar potential energy -- without time conditioning, auxiliary generators, or additional networks -- marking a significant departure from recent EBM methods. We believe this simplified framework significantly advances EBM capabilities and paves the way for their broader adoption in generative modeling across diverse domains.', 'abstract_zh': '基于能量匹配的生成模型', 'title_zh': '能量匹配：统一流匹配和能量基于模型的生成建模'}
{'arxiv_id': 'arXiv:2504.10584', 'title': 'Visual anemometry of natural vegetation from their leaf motion', 'authors': 'Roni H. Goldshmid, John O. Dabiri, John E. Sader', 'link': 'https://arxiv.org/abs/2504.10584', 'abstract': "High-resolution, near-ground wind-speed data are critical for improving the accuracy of weather predictions and climate models,$^{1-3}$ supporting wildfire control efforts,$^{4-7}$ and ensuring the safe passage of airplanes during takeoff and landing maneouvers.$^{8,9}$ Quantitative wind speed anemometry generally employs on-site instrumentation for accurate single-position data or sophisticated remote techniques such as Doppler radar for quantitative field measurements. It is widely recognized that the wind-induced motion of vegetation depends in a complex manner on their structure and mechanical properties, obviating their use in quantitative anemometry.$^{10-14}$ We analyze measurements on a host of different vegetation showing that leaf motion can be decoupled from the leaf's branch and support structure, at low-to-moderate wind speed, $U_{wind}$. This wind speed range is characterized by a leaf Reynolds number, enabling the development of a remote, quantitative anemometry method based on the formula, $U_{wind}\\approx740\\sqrt{{\\mu}U_{leaf}/{\\rho}D}$, that relies only on the leaf size $D$, its measured fluctuating (RMS) speed $U_{leaf}$, the air viscosity $\\mu$, and its mass density $\\rho$. This formula is corroborated by a first-principles model and validated using a host of laboratory and field tests on diverse vegetation types, ranging from oak, olive, and magnolia trees through to camphor and bullgrass. The findings of this study open the door to a new paradigm in anemometry, using natural vegetation to enable remote and rapid quantitative field measurements at global locations with minimal cost.", 'abstract_zh': '高分辨率近地风速数据对于提高天气预测和气候模型的准确性至关重要，支持野火控制努力，并确保飞机在起飞和降落时的安全。基于叶片运动的远程定量风速仪方法：一种新的基于自然植被的远程快速定量场测量方法。', 'title_zh': '自然植被叶片运动的视觉风速测量'}
{'arxiv_id': 'arXiv:2504.10561', 'title': 'Self-Controlled Dynamic Expansion Model for Continual Learning', 'authors': 'Runqing Wu, Fei Ye, Rongyao Hu, Guoxi Huang', 'link': 'https://arxiv.org/abs/2504.10561', 'abstract': "Continual Learning (CL) epitomizes an advanced training paradigm wherein prior data samples remain inaccessible during the acquisition of new tasks. Numerous investigations have delved into leveraging a pre-trained Vision Transformer (ViT) to enhance model efficacy in continual learning. Nonetheless, these approaches typically utilize a singular, static backbone, which inadequately adapts to novel tasks, particularly when engaging with diverse data domains, due to a substantial number of inactive parameters. This paper addresses this limitation by introducing an innovative Self-Controlled Dynamic Expansion Model (SCDEM), which orchestrates multiple distinct trainable pre-trained ViT backbones to furnish diverse and semantically enriched representations. Specifically, by employing the multi-backbone architecture as a shared module, the proposed SCDEM dynamically generates a new expert with minimal parameters to accommodate a new task. A novel Collaborative Optimization Mechanism (COM) is introduced to synergistically optimize multiple backbones by harnessing prediction signals from historical experts, thereby facilitating new task learning without erasing previously acquired knowledge. Additionally, a novel Feature Distribution Consistency (FDC) approach is proposed to align semantic similarity between previously and currently learned representations through an optimal transport distance-based mechanism, effectively mitigating negative knowledge transfer effects. Furthermore, to alleviate over-regularization challenges, this paper presents a novel Dynamic Layer-Wise Feature Attention Mechanism (DLWFAM) to autonomously determine the penalization intensity on each trainable representation layer. An extensive series of experiments have been conducted to evaluate the proposed methodology's efficacy, with empirical results corroborating that the approach attains state-of-the-art performance.", 'abstract_zh': '持续学习（CL）体现在一个先进的训练 paradigm 中，其中先前的数据样本在学习新任务时保持不可访问。众多研究致力于利用预训练的 Vision Transformer（ViT）来增强在持续学习中的模型效果。然而，这些方法通常使用单一的静态主干，这在处理多样化的数据领域时难以适应新的任务，尤其是由于大量未激活的参数。本文通过引入一种创新的自我控制动态扩展模型（SCDEM），解决了这一局限性。该模型协调多个可训练的预训练 ViT 主干，提供多样化的语义丰富表示。具体而言，通过使用多主干架构作为共享模块，所提出的 SCDEM 动态生成一个新的专家，以最小的参数量适应新任务。作者引入了一种新颖的合作优化机制（COM），通过利用历史专家的预测信号协同优化多个主干，从而在不丢失之前获取的知识的情况下促进新任务的学习。此外，提出了一个新颖的特征分布一致性（FDC）方法，通过最优运输距离机制对齐已学习和当前学习的表示之间的语义相似性，有效减轻负面知识转移的影响。为进一步缓解过度正则化挑战，本文提出了一种新颖的动态逐层特征注意机制（DLWFAM），以自主确定每个可训练表示层的惩罚强度。进行了大量的实验评估所提方法的有效性，实验证明该方法达到了最先进的性能。', 'title_zh': '自我控制动态扩展模型 for 连续学习'}
{'arxiv_id': 'arXiv:2504.10559', 'title': 'Efficient Process Reward Model Training via Active Learning', 'authors': 'Keyu Duan, Zichen Liu, Xin Mao, Tianyu Pang, Changyu Chen, Qiguang Chen, Michael Qizhe Shieh, Longxu Dou', 'link': 'https://arxiv.org/abs/2504.10559', 'abstract': "Process Reward Models (PRMs) provide step-level supervision to large language models (LLMs), but scaling up training data annotation remains challenging for both humans and LLMs. To address this limitation, we propose an active learning approach, ActPRM, which proactively selects the most uncertain samples for training, substantially reducing labeling costs. During training, we use the PRM to estimate uncertainty after the forward pass, retaining only highly uncertain data. A capable yet costly reasoning model then labels this data. Then we compute the loss with respect to the labels and update the PRM's weights. We compare ActPRM vs. vanilla fine-tuning, on a pool-based active learning setting, demonstrating that ActPRM reduces 50% annotation, but achieving the comparable or even better performance. Beyond annotation efficiency, we further advance the actively trained PRM by filtering over 1M+ math reasoning trajectories with ActPRM, retaining 60% of the data. A subsequent training on this selected dataset yields a new state-of-the-art (SOTA) PRM on ProcessBench (75.0%) and PRMBench (65.5%) compared with same sized models.", 'abstract_zh': '基于过程的奖励模型（PRMs）为大型语言模型（LLMs）提供步骤级监督，但扩展训练数据注释仍然是对人类和LLMs的一大挑战。为解决这一局限，我们提出了一种主动学习方法ActPRM，该方法主动选择最不确定的样本进行训练，大幅减少了标注成本。在训练过程中，我们使用PRM在前向传播后估计不确定性，并仅保留高度不确定的数据。然后，一个有能力但成本较高的推理模型对这些数据进行标注。之后，我们根据标签计算损失，并更新PRM的权重。我们在基于池的主动学习设置中将ActPRM与传统微调进行了比较，结果显示ActPRM将标注工作量减少50%，但性能可媲美或甚至更好。除了提高标注效率外，我们还通过ActPRM过滤超过100万条数学推理轨迹，保留了其中60%的数据。随后在选定的数据集上进行训练，最终在ProcessBench（75.0%）和PRMBench（65.5%）上获得了比同规模模型更好的最新状态（SOTA）PRM。', 'title_zh': '通过主动学习提高过程奖励模型训练效率'}
{'arxiv_id': 'arXiv:2504.10557', 'title': 'The Code Barrier: What LLMs Actually Understand?', 'authors': 'Serge Lionel Nikiema, Jordan Samhi, Abdoul Kader Kaboré, Jacques Klein, Tegawendé F. Bissyandé', 'link': 'https://arxiv.org/abs/2504.10557', 'abstract': "Understanding code represents a core ability needed for automating software development tasks. While foundation models like LLMs show impressive results across many software engineering challenges, the extent of their true semantic understanding beyond simple token recognition remains unclear. This research uses code obfuscation as a structured testing framework to evaluate LLMs' semantic understanding capabilities. We methodically apply controlled obfuscation changes to source code and measure comprehension through two complementary tasks: generating accurate descriptions of obfuscated code and performing deobfuscation, a skill with important implications for reverse engineering applications.\nOur testing approach includes 13 cutting-edge models, covering both code-specialized (e.g., StarCoder2) and general-purpose (e.g., GPT-4o) architectures, evaluated on a benchmark created from CodeNet and consisting of filtered 250 Java programming problems and their solutions. Findings show a statistically significant performance decline as obfuscation complexity increases, with unexpected resilience shown by general-purpose models compared to their code-focused counterparts. While some models successfully identify obfuscation techniques, their ability to reconstruct the underlying program logic remains constrained, suggesting limitations in their semantic representation mechanisms. This research introduces a new evaluation approach for assessing code comprehension in language models and establishes empirical baselines for advancing research in security-critical code analysis applications such as reverse engineering and adversarial code analysis.", 'abstract_zh': '理解代码是自动化软件开发任务的一个核心能力。虽然像LLMs这样的基础模型在许多软件工程挑战中展现出令人印象深刻的成果，但它们超出简单 token 识别的真正语义理解程度仍然不清楚。本研究利用代码混淆作为结构化的测试框架，评估LLMs的语义理解能力。我们有条不紊地对源代码应用控制性混淆变化，并通过两个互补任务来衡量理解能力：生成混淆代码的准确描述和执行去混淆，后者对于逆向工程应用具有重要的意义。\n\n测试方法包括13个前沿模型，涵盖代码专门化（例如，StarCoder2）和通用目的（例如，GPT-4o）架构，这些模型在由CodeNet创建的基准测试中进行评估，该基准测试包括过滤后的250个Java编程问题及其解决方案。研究结果显示，随着混淆复杂性的增加，性能呈现出统计学上的显著下降，通用目的模型显示出与代码专注模型相比的意外韧性。尽管一些模型能够识别混淆技术，但它们重建底层程序逻辑的能力仍然受到限制，这表明它们在语义表示机制方面存在局限性。本研究引入了一种新的语言模型代码理解评估方法，并为安全关键代码分析应用（如逆向工程和对抗代码分析）的研究进展提供了实证基准。', 'title_zh': '代码障碍：LLMsactually理解些什么？'}
{'arxiv_id': 'arXiv:2504.10556', 'title': 'VAE-based Feature Disentanglement for Data Augmentation and Compression in Generalized GNSS Interference Classification', 'authors': 'Lucas Heublein, Simon Kocher, Tobias Feigl, Alexander Rügamer, Christopher Mutschler, Felix Ott', 'link': 'https://arxiv.org/abs/2504.10556', 'abstract': 'Distributed learning and Edge AI necessitate efficient data processing, low-latency communication, decentralized model training, and stringent data privacy to facilitate real-time intelligence on edge devices while reducing dependency on centralized infrastructure and ensuring high model performance. In the context of global navigation satellite system (GNSS) applications, the primary objective is to accurately monitor and classify interferences that degrade system performance in distributed environments, thereby enhancing situational awareness. To achieve this, machine learning (ML) models can be deployed on low-resource devices, ensuring minimal communication latency and preserving data privacy. The key challenge is to compress ML models while maintaining high classification accuracy. In this paper, we propose variational autoencoders (VAEs) for disentanglement to extract essential latent features that enable accurate classification of interferences. We demonstrate that the disentanglement approach can be leveraged for both data compression and data augmentation by interpolating the lower-dimensional latent representations of signal power. To validate our approach, we evaluate three VAE variants - vanilla, factorized, and conditional generative - on four distinct datasets, including two collected in controlled indoor environments and two real-world highway datasets. Additionally, we conduct extensive hyperparameter searches to optimize performance. Our proposed VAE achieves a data compression rate ranging from 512 to 8,192 and achieves an accuracy up to 99.92%.', 'abstract_zh': '分布式学习与边缘AI需要高效的数据处理、低延迟通信、去中心化的模型训练以及严格的数据隐私保护，以在边缘设备上实现实时智能，减少对中心化基础设施的依赖并保证高模型性能。在全球导航卫星系统（GNSS）应用中，主要目标是准确监控和分类影响系统性能的干扰，从而增强态势感知。为此，可以在低资源设备上部署机器学习（ML）模型，确保最小化通信延迟并保护数据隐私。关键挑战是如何在保持高分类精度的同时压缩ML模型。在本文中，我们提出使用变分自编码器（VAEs）进行解耦，以提取能够准确分类干扰的关键潜在特征。我们证明了解耦方法可以用于数据压缩和数据增强，通过插值信号功率的低维潜在表示。为了验证我们的方法，我们在四个不同的数据集上评估了三种VAE变体——vanilla、因子分解和条件生成型，包括两个在受控室内环境收集的数据集和两个实际高速公路数据集。此外，我们还进行了广泛的超参数搜索以优化性能。我们提出的方法达到了512到8,192的数据压缩率，并且分类精度高达99.92%。', 'title_zh': '基于VAE的特征解耦在广义GNSS干扰分类中的数据增强与压缩'}
{'arxiv_id': 'arXiv:2504.10555', 'title': 'Beyond the Generative Learning Trilemma: Generative Model Assessment in Data Scarcity Domains', 'authors': 'Marco Salmè, Lorenzo Tronchin, Rosa Sicilia, Paolo Soda, Valerio Guarrasi', 'link': 'https://arxiv.org/abs/2504.10555', 'abstract': 'Data scarcity remains a critical bottleneck impeding technological advancements across various domains, including but not limited to medicine and precision agriculture. To address this challenge, we explore the potential of Deep Generative Models (DGMs) in producing synthetic data that satisfies the Generative Learning Trilemma: fidelity, diversity, and sampling efficiency. However, recognizing that these criteria alone are insufficient for practical applications, we extend the trilemma to include utility, robustness, and privacy, factors crucial for ensuring the applicability of DGMs in real-world scenarios. Evaluating these metrics becomes particularly challenging in data-scarce environments, as DGMs traditionally rely on large datasets to perform optimally. This limitation is especially pronounced in domains like medicine and precision agriculture, where ensuring acceptable model performance under data constraints is vital. To address these challenges, we assess the Generative Learning Trilemma in data-scarcity settings using state-of-the-art evaluation metrics, comparing three prominent DGMs: Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), and Diffusion Models (DMs). Furthermore, we propose a comprehensive framework to assess utility, robustness, and privacy in synthetic data generated by DGMs. Our findings demonstrate varying strengths among DGMs, with each model exhibiting unique advantages based on the application context. This study broadens the scope of the Generative Learning Trilemma, aligning it with real-world demands and providing actionable guidance for selecting DGMs tailored to specific applications.', 'abstract_zh': '数据稀缺仍然是阻碍医学和精准农业等领域技术进步的关键瓶颈。为应对这一挑战，我们探索了深度生成模型（DGMs）在满足生成学习三难局面（忠实性、多样性和采样效率）方面生成合成数据的潜力。然而，认识到这些标准本身不足以满足实际应用需求，我们将三难局面扩展到包括效用、稳健性和隐私性等因素，这些因素对于确保DGMs在实际场景中的适用性至关重要。在数据稀缺环境中评估这些指标变得尤为挑战性，因为传统的DGMs需要大量数据才能发挥最佳性能。这种限制在医学和精准农业等领域尤为明显，这些领域在数据受限条件下保证模型性能的可接受性至关重要。为应对这些挑战，我们使用最先进的评估指标，在数据稀缺条件下评估生成学习三难局面，比较三种突出的DGMs：变分自编码器（VAEs）、生成对抗网络（GANs）和扩散模型（DMs）。此外，我们提出了一种全面框架来评估由DGMs生成的合成数据的效用、稳健性和隐私性。我们的研究结果表明，DGMs在性能上有不同的优势，每种模型根据应用场景具有独特的优点。本研究扩大了生成学习三难局面的适用范围，使其与实际需求相契合，并提供了选择适用于特定应用的DGMs的实际指导。', 'title_zh': '超越生成学习三难境地：在数据稀缺领域中的生成模型评估'}
{'arxiv_id': 'arXiv:2504.10552', 'title': 'LEMUR Neural Network Dataset: Towards Seamless AutoML', 'authors': 'Arash Torabi Goodarzi, Roman Kochnev, Waleed Khalid, Furui Qin, Tolgay Atinc Uzun, Yashkumar Sanjaybhai Dhameliya, Yash Kanubhai Kathiriya, Zofia Antonina Bentyn, Dmitry Ignatov, Radu Timofte', 'link': 'https://arxiv.org/abs/2504.10552', 'abstract': 'Neural networks are fundamental in artificial intelligence, driving progress in computer vision and natural language processing. High-quality datasets are crucial for their development, and there is growing interest in datasets composed of neural networks themselves to support benchmarking, automated machine learning (AutoML), and model analysis. We introduce LEMUR, an open source dataset of neural network models with well-structured code for diverse architectures across tasks such as object detection, image classification, segmentation, and natural language processing. LEMUR is primarily designed to enable fine-tuning of large language models (LLMs) for AutoML tasks, providing a rich source of structured model representations and associated performance data. Leveraging Python and PyTorch, LEMUR enables seamless extension to new datasets and models while maintaining consistency. It integrates an Optuna-powered framework for evaluation, hyperparameter optimization, statistical analysis, and graphical insights. LEMUR provides an extension that enables models to run efficiently on edge devices, facilitating deployment in resource-constrained environments. Providing tools for model evaluation, preprocessing, and database management, LEMUR supports researchers and practitioners in developing, testing, and analyzing neural networks. Additionally, it offers an API that delivers comprehensive information about neural network models and their complete performance statistics with a single request, which can be used in experiments with code-generating large language models. The LEMUR will be released as an open source project under the MIT license upon acceptance of the paper.', 'abstract_zh': '神经网络在人工智能中是基础的组成部分，推动了计算机视觉和自然语言处理的进步。高质量的数据集对于其发展至关重要，而对于支持基准测试、自动化机器学习（AutoML）和模型分析的由神经网络组成的数据集也日益引起关注。我们介绍了LEMUR，这是一个开源的数据集，包含结构良好的神经网络模型代码，适用于各种任务，如物体检测、图像分类、分割和自然语言处理。LEMUR 主要旨在支持大型语言模型（LLMs）的微调以用于 AutoML 任务，提供丰富的结构化模型表示和相关性能数据。利用 Python 和 PyTorch，LEMUR 可轻松扩展到新的数据集和模型，同时保持一致性。LEMUR 集成了一个基于 Optuna 的评估框架，用于超参数优化、统计分析和图形洞察。LEMUR 提供了一个扩展，使模型能够在边缘设备上高效运行，便于在资源受限环境中部署。LEMUR 提供了评估、预处理和数据库管理的工具，支持研究人员和从业者开发、测试和分析神经网络。此外，它还提供了一个 API，可以通过单一请求提供有关神经网络模型及其完整性能统计的全面信息，这可以用于代码生成大型语言模型的实验。接受论文后，LEMUR 将作为 MIT 许可证下的开源项目发布。', 'title_zh': 'LEMUR 神经网络数据集：迈向无缝自动机器学习'}
{'arxiv_id': 'arXiv:2504.10551', 'title': 'MiMu: Mitigating Multiple Shortcut Learning Behavior of Transformers', 'authors': 'Lili Zhao, Qi Liu, Wei Chen, Liyi Chen, Ruijun Sun, Min Hou, Yang Wang, Shijin Wang', 'link': 'https://arxiv.org/abs/2504.10551', 'abstract': 'Empirical Risk Minimization (ERM) models often rely on spurious correlations between features and labels during the learning process, leading to shortcut learning behavior that undermines robustness generalization performance. Current research mainly targets identifying or mitigating a single shortcut; however, in real-world scenarios, cues within the data are diverse and unknown. In empirical studies, we reveal that the models rely to varying extents on different shortcuts. Compared to weak shortcuts, models depend more heavily on strong shortcuts, resulting in their poor generalization ability. To address these challenges, we propose MiMu, a novel method integrated with Transformer-based ERMs designed to Mitigate Multiple shortcut learning behavior, which incorporates self-calibration strategy and self-improvement strategy. In the source model, we preliminarily propose the self-calibration strategy to prevent the model from relying on shortcuts and make overconfident predictions. Then, we further design self-improvement strategy in target model to reduce the reliance on multiple shortcuts. The random mask strategy involves randomly masking partial attention positions to diversify the focus of target model other than concentrating on a fixed region. Meanwhile, the adaptive attention alignment module facilitates the alignment of attention weights to the calibrated source model, without the need for post-hoc attention maps or supervision. Finally, extensive experiments conducted on Natural Language Processing (NLP) and Computer Vision (CV) demonstrate the effectiveness of MiMu in improving robustness generalization abilities.', 'abstract_zh': 'Mitigating Multiple Shortcut Learning Behavior in Empirical Risk Minimization Models through Integrated Transformer-based Methods', 'title_zh': 'MiMu: 减缓 transformers 的多重捷径学习行为'}
{'arxiv_id': 'arXiv:2504.10548', 'title': 'Automated Testing of COBOL to Java Transformation', 'authors': 'Sandeep Hans, Atul Kumar, Toshikai Yasue, Kouichi Ono, Saravanan Krishnan, Devika Sondhi, Fumiko Satoh, Gerald Mitchell, Sachin Kumar, Diptikalyan Saha', 'link': 'https://arxiv.org/abs/2504.10548', 'abstract': 'Recent advances in Large Language Model (LLM) based Generative AI techniques have made it feasible to translate enterprise-level code from legacy languages such as COBOL to modern languages such as Java or Python. While the results of LLM-based automatic transformation are encouraging, the resulting code cannot be trusted to correctly translate the original code, making manual validation of translated Java code from COBOL a necessary but time-consuming and labor-intensive process. In this paper, we share our experience of developing a testing framework for IBM Watsonx Code Assistant for Z (WCA4Z) [5], an industrial tool designed for COBOL to Java translation. The framework automates the process of testing the functional equivalence of the translated Java code against the original COBOL programs in an industry context. Our framework uses symbolic execution to generate unit tests for COBOL, mocking external calls and transforming them into JUnit tests to validate semantic equivalence with translated Java. The results not only help identify and repair any detected discrepancies but also provide feedback to improve the AI model.', 'abstract_zh': 'Recent advances in基于大型语言模型（LLM）的生成AI技术使从COBOL等遗留语言向Java或Python等现代语言翻译企业级代码成为可能。尽管基于LLM的自动转换结果令人鼓舞，但生成的代码无法确保正确翻译原始代码，因此在工业环境中验证从COBOL翻译而来的Java代码的必要性使其成为一项耗时且劳动密集的过程。本文分享了开发IBM Watsonx Code Assistant for Z (WCA4Z) 测试框架的经验，该框架旨在工业环境中实现对从COBOL翻译而来的Java代码的功能等价性的测试。框架使用符号执行为COBOL生成单元测试，模拟外部调用并将它们转换为JUnit测试以验证语义等价性。结果不仅有助于识别并修复任何检测到的差异，还为提高AI模型提供了反馈。', 'title_zh': 'COBOL到Java转换的自动化测试'}
{'arxiv_id': 'arXiv:2504.10541', 'title': 'Multi-Modal Hypergraph Enhanced LLM Learning for Recommendation', 'authors': 'Xu Guo, Tong Zhang, Yuanzhi Wang, Chenxu Wang, Fuyun Wang, Xudong Wang, Xiaoya Zhang, Xin Liu, Zhen Cui', 'link': 'https://arxiv.org/abs/2504.10541', 'abstract': "The burgeoning presence of Large Language Models (LLM) is propelling the development of personalized recommender systems. Most existing LLM-based methods fail to sufficiently explore the multi-view graph structure correlations inherent in recommendation scenarios. To this end, we propose a novel framework, Hypergraph Enhanced LLM Learning for multimodal Recommendation (HeLLM), designed to equip LLMs with the capability to capture intricate higher-order semantic correlations by fusing graph-level contextual signals with sequence-level behavioral patterns. In the recommender pre-training phase, we design a user hypergraph to uncover shared interest preferences among users and an item hypergraph to capture correlations within multimodal similarities among items. The hypergraph convolution and synergistic contrastive learning mechanism are introduced to enhance the distinguishability of learned representations. In the LLM fine-tuning phase, we inject the learned graph-structured embeddings directly into the LLM's architecture and integrate sequential features capturing each user's chronological behavior. This process enables hypergraphs to leverage graph-structured information as global context, enhancing the LLM's ability to perceive complex relational patterns and integrate multimodal information, while also modeling local temporal dynamics. Extensive experiments demonstrate the superiority of our proposed method over state-of-the-art baselines, confirming the advantages of fusing hypergraph-based context with sequential user behavior in LLMs for recommendation.", 'abstract_zh': '大型语言模型增强的超图嵌入推荐框架（HeLLM）', 'title_zh': '多模态超图增强的LLM推荐学习'}
{'arxiv_id': 'arXiv:2504.10540', 'title': 'AB-Cache: Training-Free Acceleration of Diffusion Models via Adams-Bashforth Cached Feature Reuse', 'authors': 'Zichao Yu, Zhen Zou, Guojiang Shao, Chengwei Zhang, Shengze Xu, Jie Huang, Feng Zhao, Xiaodong Cun, Wenyi Zhang', 'link': 'https://arxiv.org/abs/2504.10540', 'abstract': "Diffusion models have demonstrated remarkable success in generative tasks, yet their iterative denoising process results in slow inference, limiting their practicality. While existing acceleration methods exploit the well-known U-shaped similarity pattern between adjacent steps through caching mechanisms, they lack theoretical foundation and rely on simplistic computation reuse, often leading to performance degradation. In this work, we provide a theoretical understanding by analyzing the denoising process through the second-order Adams-Bashforth method, revealing a linear relationship between the outputs of consecutive steps. This analysis explains why the outputs of adjacent steps exhibit a U-shaped pattern. Furthermore, extending Adams-Bashforth method to higher order, we propose a novel caching-based acceleration approach for diffusion models, instead of directly reusing cached results, with a truncation error bound of only \\(O(h^k)\\) where $h$ is the step size. Extensive validation across diverse image and video diffusion models (including HunyuanVideo and FLUX.1-dev) with various schedulers demonstrates our method's effectiveness in achieving nearly $3\\times$ speedup while maintaining original performance levels, offering a practical real-time solution without compromising generation quality.", 'abstract_zh': '扩散模型在生成任务中展现了显著的成功，但其迭代去噪过程导致推断缓慢，限制了其实用性。虽然现有的加速方法通过缓存机制利用了相邻步骤间已知的U形相似模式，但缺乏理论基础，依赖于简单的计算复用，经常会降低性能。在本工作中，我们通过分析连续步骤之间的输出关系，利用第二阶阿德ams- Bashforth方法提供了一个理论理解，揭示了连续步骤输出间的线性关系。这种分析解释了相邻步骤输出为何呈现U形模式。此外，将阿德ams-巴斯福德方法扩展到更高阶，我们提出了一种基于缓存的新型加速方法，而不是直接复用缓存结果，仅带有限截断误差边界\\(O(h^k)\\)。在不同的图像和视频扩散模型（包括HunyuanVideo和FLUX.1-dev）以及多种调度器上进行的广泛验证表明，我们的方法能够实现接近3倍的速度提升，同时保持原始性能水平，提供了一种在不牺牲生成质量的情况下实现实时处理的实用解决方案。', 'title_zh': 'AB-Cache: 不需训练的扩散模型加速通过Adams-Bashforth缓存特征重用'}
{'arxiv_id': 'arXiv:2504.10539', 'title': 'Physics-Informed Neural Networks for Enhanced Interface Preservation in Lattice Boltzmann Multiphase Simulations', 'authors': 'Yue Li', 'link': 'https://arxiv.org/abs/2504.10539', 'abstract': 'This paper presents an improved approach for preserving sharp interfaces in multiphase Lattice Boltzmann Method (LBM) simulations using Physics-Informed Neural Networks (PINNs). Interface diffusion is a common challenge in multiphase LBM, leading to reduced accuracy in simulating phenomena where interfacial dynamics are critical. We propose a coupled PINN-LBM framework that maintains interface sharpness while preserving the physical accuracy of the simulation. Our approach is validated through droplet simulations, with quantitative metrics measuring interface width, maximum gradient, phase separation, effective interface width, and interface energy. The enhanced visualization techniques employed in this work clearly demonstrate the superior performance of PINN-LBM over standard LBM for multiphase simulations, particularly in maintaining well-defined interfaces throughout the simulation. We provide a comprehensive analysis of the results, showcasing how the neural network integration effectively counteracts numerical diffusion, while maintaining physical consistency with the underlying fluid dynamics.', 'abstract_zh': '本文提出了一种使用物理知情神经网络（PINNs）改善多相格子玻尔茲曼方法（LBM）仿真中保锐界面的方法。界面扩散是多相LBM中的常见挑战，会导致在界面动力学至关重要的现象模拟中降低准确性。我们提出了一种结合PINN-LBM框架，既能保持界面的锐利性又能保持仿真的物理准确性。我们的方法通过液滴仿真得到了验证，通过界面宽度、最大梯度、相分离、有效界面宽度和界面能量等定量指标进行评估。本工作中采用的增强可视化技术清楚地展示了PINN-LBM相较于标准LBM在多相仿真中优越的性能，尤其是在整个仿真过程中保持清晰定义的界面方面。我们对结果进行了全面分析，展示了神经网络集成如何有效地抵消数值扩散效应，同时保持与底层流体力学的一致性。', 'title_zh': '基于物理信息的神经网络在格子玻尔兹曼双相流模拟中增强界面保持方法'}
{'arxiv_id': 'arXiv:2504.10538', 'title': 'Distilling Transitional Pattern to Large Language Models for Multimodal Session-based Recommendation', 'authors': 'Jiajie Su, Qiyong Zhong, Yunshan Ma, Weiming Liu, Chaochao Chen, Xiaolin Zheng, Jianwei Yin, Tat-Seng Chua', 'link': 'https://arxiv.org/abs/2504.10538', 'abstract': 'Session-based recommendation (SBR) predicts the next item based on anonymous sessions. Traditional SBR explores user intents based on ID collaborations or auxiliary content. To further alleviate data sparsity and cold-start issues, recent Multimodal SBR (MSBR) methods utilize simplistic pre-trained models for modality learning but have limitations in semantic richness. Considering semantic reasoning abilities of Large Language Models (LLM), we focus on the LLM-enhanced MSBR scenario in this paper, which leverages LLM cognition for comprehensive multimodal representation generation, to enhance downstream MSBR. Tackling this problem faces two challenges: i) how to obtain LLM cognition on both transitional patterns and inherent multimodal knowledge, ii) how to align both features into one unified LLM, minimize discrepancy while maximizing representation utility. To this end, we propose a multimodal LLM-enhanced framework TPAD, which extends a distillation paradigm to decouple and align transitional patterns for promoting MSBR. TPAD establishes parallel Knowledge-MLLM and Transfer-MLLM, where the former interprets item knowledge-reflected features and the latter extracts transition-aware features underneath sessions. A transitional pattern alignment module harnessing mutual information estimation theory unites two MLLMs, alleviating distribution discrepancy and distilling transitional patterns into modal representations. Extensive experiments on real-world datasets demonstrate the effectiveness of our framework.', 'abstract_zh': '基于会话的推荐（SBR）根据匿名会话预测下一个项目。传统的SBR基于ID协作或辅助内容探索用户意图。为进一步缓解数据稀疏性和冷启动问题，最近的多模态SBR（MSBR）方法利用了简单的预训练模型进行模态学习，但在语义丰富性方面存在局限。考虑到大型语言模型（LLM）的语义推理能力，本文集中探讨了LLM增强的MSBR场景，利用LLM的认知生成全面的多模态表示，以增强下游的MSBR。解决这一问题面临两大挑战：一是如何获取LLM在过渡模式和内在多模态知识上的认知能力，二是如何将两者特征统一到一个统一的LLM中，最小化差异同时最大化表示的实用性。为此，我们提出了一种多模态LLM增强框架TPAD，扩展了蒸馏 paradigm以分离和对齐过渡模式，促进SBR。TPAD建立并行的知识-MLM和转移-MLM，前者解释项目知识反映的特征，后者在会话下提取过渡感知特征。利用互信息估计理论的过渡模式对齐模块将两个MLM统一起来，缓解分布差异并将过渡模式提炼为模态表示。在实际数据集上的广泛实验展示了我们框架的有效性。', 'title_zh': '从过渡模式蒸馏至大规模语言模型的多模态会话推荐'}
{'arxiv_id': 'arXiv:2504.10536', 'title': 'Federated Learning with Layer Skipping: Efficient Training of Large Language Models for Healthcare NLP', 'authors': 'Lihong Zhang, Yue Li', 'link': 'https://arxiv.org/abs/2504.10536', 'abstract': 'Federated learning (FL) enables collaborative model training across organizations without sharing raw data, addressing crucial privacy concerns in healthcare natural language processing (NLP). However, training large language models (LLMs) in federated settings faces significant challenges, including communication overhead and data heterogeneity. We propose Layer-Skipping Federated Learning, where only selected layers of a pre-trained LLM are fine-tuned across clients while others remain frozen. Applied to LLaMA 3.2-1B, our approach reduces communication costs by approximately 70% while maintaining performance within 2% of centralized training. We evaluate our method on clinical NER and classification tasks using i2b2 and MIMIC-III datasets. Our experiments demonstrate that Layer-Skipping FL outperforms competitive baselines, handles non-IID clinical data distributions effectively, and shows robustness when combined with differential privacy. This approach represents a practical solution for privacy-preserving collaborative learning in healthcare NLP.', 'abstract_zh': '联邦学习（FL）在不共享原始数据的情况下跨组织实现模型训练，解决医疗自然语言处理（NLP）中的关键隐私问题。然而，在联邦环境中训练大规模语言模型（LLMs）面临重大挑战，包括通信开销和数据异质性。我们提出了一种分层跳过联邦学习方法，只有预训练的LLM的部分层在客户端进行微调，其他层保持冻结状态。应用于LaMA 3.2-1B，我们的方法将通信成本降低了约70%，同时性能在集中训练的2%以内。我们使用i2b2和MIMIC-III数据集评估了我们的方法在临床NER和分类任务中的性能。实验结果显示，分层跳过FL方法优于竞品基线，有效处理非 IID 的临床数据分布，并且与差分隐私结合时表现出高度的鲁棒性。该方法代表了在医疗NLP中实现保护隐私的协作学习的有效解决方案。', 'title_zh': 'federated learning with layer skipping: 面向医疗自然语言处理的大规模语言模型高效训练'}
{'arxiv_id': 'arXiv:2504.10529', 'title': 'HeteRAG: A Heterogeneous Retrieval-augmented Generation Framework with Decoupled Knowledge Representations', 'authors': 'Peiru Yang, Xintian Li, Zhiyang Hu, Jiapeng Wang, Jinhua Yin, Huili Wang, Lizhi He, Shuai Yang, Shangguang Wang, Yongfeng Huang, Tao Qi', 'link': 'https://arxiv.org/abs/2504.10529', 'abstract': 'Retrieval-augmented generation (RAG) methods can enhance the performance of LLMs by incorporating retrieved knowledge chunks into the generation process. In general, the retrieval and generation steps usually have different requirements for these knowledge chunks. The retrieval step benefits from comprehensive information to improve retrieval accuracy, whereas excessively long chunks may introduce redundant contextual information, thereby diminishing both the effectiveness and efficiency of the generation process. However, existing RAG methods typically employ identical representations of knowledge chunks for both retrieval and generation, resulting in suboptimal performance. In this paper, we propose a heterogeneous RAG framework (\\myname) that decouples the representations of knowledge chunks for retrieval and generation, thereby enhancing the LLMs in both effectiveness and efficiency. Specifically, we utilize short chunks to represent knowledge to adapt the generation step and utilize the corresponding chunk with its contextual information from multi-granular views to enhance retrieval accuracy. We further introduce an adaptive prompt tuning method for the retrieval model to adapt the heterogeneous retrieval augmented generation process. Extensive experiments demonstrate that \\myname achieves significant improvements compared to baselines.', 'abstract_zh': '基于检索增强生成的异质框架（\\myname）： decoupling knowledge chunk representations for retrieval and generation to enhance LLMs的性能与效率', 'title_zh': 'HeteRAG：一种解耦知识表示的异构检索增强生成框架'}
{'arxiv_id': 'arXiv:2504.10521', 'title': 'Integrating Emotion Distribution Networks and Textual Message Analysis for X User Emotional State Classification', 'authors': 'Pardis Moradbeiki, Mohammad Ali Zare Chahooki', 'link': 'https://arxiv.org/abs/2504.10521', 'abstract': "As the popularity and reach of social networks continue to surge, a vast reservoir of opinions and sentiments across various subjects inundates these platforms. Among these, X social network (formerly Twitter) stands as a juggernaut, boasting approximately 420 million active users. Extracting users' emotional and mental states from their expressed opinions on social media has become a common pursuit. While past methodologies predominantly focused on the textual content of messages to analyze user sentiment, the interactive nature of these platforms suggests a deeper complexity. This study employs hybrid methodologies, integrating textual analysis, profile examination, follower analysis, and emotion dissemination patterns. Initially, user interactions are leveraged to refine emotion classification within messages, encompassing exchanges where users respond to each other. Introducing the concept of a communication tree, a model is extracted to map these interactions. Subsequently, users' bios and interests from this tree are juxtaposed with message text to enrich analysis. Finally, influential figures are identified among users' followers in the communication tree, categorized into different topics to gauge interests. The study highlights that traditional sentiment analysis methodologies, focusing solely on textual content, are inadequate in discerning sentiment towards significant events, notably the presidential election. Comparative analysis with conventional methods reveals a substantial improvement in accuracy with the incorporation of emotion distribution patterns and user profiles. The proposed approach yields a 12% increase in accuracy with emotion distribution patterns and a 15% increase when considering user profiles, underscoring its efficacy in capturing nuanced sentiment dynamics.", 'abstract_zh': '随着社交网络的 popularity 和 reach 不断增长，各种主题的意见和情感在这些平台上大量涌现。其中，X 社交网络（原 Twitter）作为巨头，拥有约 4.2 亿活跃用户。从用户在社交媒体上表达的意见中提取其情感和心理状态已成为一种常见追求。尽管以往的方法主要侧重于消息的文本内容来分析用户情感，但这些平台的互动性提示了更深层次的复杂性。本研究采用混合方法，结合文本分析、个人资料检查、关注者分析和情绪传播模式。首先，利用用户互动来细化消息中的情感分类，包括用户相互回应的情况。引入通信树的概念，提取模型以映射这些互动。随后，将通信树中的用户简介和兴趣与消息文本进行对比，以丰富分析。最后，在通信树中识别出用户的重要关注者，并按不同话题分类，以衡量兴趣。研究指出，专注于文本内容的传统情感分析方法在识别重要事件（尤其是总统选举）的情感时存在不足。与传统方法的比较分析表明，将情绪分布模式和用户资料纳入分析可显著提高准确性。提出的方法在情绪分布模式下准确率提高了 12%，在考虑用户资料时提高了 15%，突显了其在捕捉细微情感动态方面的有效性。', 'title_zh': '整合情绪分布网络与文本消息分析进行X用户情绪状态分类'}
{'arxiv_id': 'arXiv:2504.10514', 'title': 'ColorBench: Can VLMs See and Understand the Colorful World? A Comprehensive Benchmark for Color Perception, Reasoning, and Robustness', 'authors': 'Yijun Liang, Ming Li, Chenrui Fan, Ziyue Li, Dang Nguyen, Kwesi Cobbina, Shweta Bhardwaj, Jiuhai Chen, Fuxiao Liu, Tianyi Zhou', 'link': 'https://arxiv.org/abs/2504.10514', 'abstract': 'Color plays an important role in human perception and usually provides critical clues in visual reasoning. However, it is unclear whether and how vision-language models (VLMs) can perceive, understand, and leverage color as humans. This paper introduces ColorBench, an innovative benchmark meticulously crafted to assess the capabilities of VLMs in color understanding, including color perception, reasoning, and robustness. By curating a suite of diverse test scenarios, with grounding in real applications, ColorBench evaluates how these models perceive colors, infer meanings from color-based cues, and maintain consistent performance under varying color transformations. Through an extensive evaluation of 32 VLMs with varying language models and vision encoders, our paper reveals some undiscovered findings: (i) The scaling law (larger models are better) still holds on ColorBench, while the language model plays a more important role than the vision encoder. (ii) However, the performance gaps across models are relatively small, indicating that color understanding has been largely neglected by existing VLMs. (iii) CoT reasoning improves color understanding accuracies and robustness, though they are vision-centric tasks. (iv) Color clues are indeed leveraged by VLMs on ColorBench but they can also mislead models in some tasks. These findings highlight the critical limitations of current VLMs and underscore the need to enhance color comprehension. Our ColorBenchcan serve as a foundational tool for advancing the study of human-level color understanding of multimodal AI.', 'abstract_zh': 'ColorBench: 一种用于评估视觉语言模型颜色理解能力的创新基准', 'title_zh': 'ColorBench：VLMs能否洞察彩色世界？一种全面的颜色感知、推理与鲁棒性基准测试'}
{'arxiv_id': 'arXiv:2504.10512', 'title': 'JEPA4Rec: Learning Effective Language Representations for Sequential Recommendation via Joint Embedding Predictive Architecture', 'authors': 'Minh-Anh Nguyen, Dung D.Le', 'link': 'https://arxiv.org/abs/2504.10512', 'abstract': 'Language representation learning has emerged as a promising approach for sequential recommendation, thanks to its ability to learn generalizable representations. However, despite its advantages, this approach still struggles with data sparsity and a limited understanding of common-sense user preferences. To address these limitations, we propose $\\textbf{JEPA4Rec}$, a framework that combines $\\textbf{J}$oint $\\textbf{E}$mbedding $\\textbf{P}$redictive $\\textbf{A}$rchitecture with language modeling of item textual descriptions. JEPA4Rec captures semantically rich and transferable representations, improving recommendation performance and reducing reliance on large-scale pre-training data. Specifically, JEPA4Rec represents items as text sentences by flattening descriptive information such as $\\textit{title, category}$, and other attributes. To encode these sentences, we employ a bidirectional Transformer encoder with modified embedding layers tailored for capturing item information in recommendation datasets. We apply masking to text sentences and use them to predict the representations of the unmasked sentences, helping the model learn generalizable item embeddings. To further improve recommendation performance and language understanding, we employ a two-stage training strategy incorporating self-supervised learning losses. Experiments on six real-world datasets demonstrate that JEPA4Rec consistently outperforms state-of-the-art methods, particularly in cross-domain, cross-platform, and low-resource scenarios.', 'abstract_zh': 'JEPA4Rec：结合项文本描述的语言建模的联合嵌入预测架构', 'title_zh': 'JEPA4Rec: 联合嵌入预测架构下有效语言表示学习的序列推荐方法'}
{'arxiv_id': 'arXiv:2504.10509', 'title': 'Beyond Reproducibility: Advancing Zero-shot LLM Reranking Efficiency with Setwise Insertion', 'authors': 'Jakub Podolak, Leon Peric, Mina Janicijevic, Roxana Petcu', 'link': 'https://arxiv.org/abs/2504.10509', 'abstract': 'This study presents a comprehensive reproducibility and extension analysis of the Setwise prompting methodology for zero-shot ranking with Large Language Models (LLMs), as proposed by Zhuang et al. We evaluate its effectiveness and efficiency compared to traditional Pointwise, Pairwise, and Listwise approaches in document ranking tasks. Our reproduction confirms the findings of Zhuang et al., highlighting the trade-offs between computational efficiency and ranking effectiveness in Setwise methods. Building on these insights, we introduce Setwise Insertion, a novel approach that leverages the initial document ranking as prior knowledge, reducing unnecessary comparisons and uncertainty by focusing on candidates more likely to improve the ranking results. Experimental results across multiple LLM architectures (Flan-T5, Vicuna, and Llama) show that Setwise Insertion yields a 31% reduction in query time, a 23% reduction in model inferences, and a slight improvement in reranking effectiveness compared to the original Setwise method. These findings highlight the practical advantage of incorporating prior ranking knowledge into Setwise prompting for efficient and accurate zero-shot document reranking.', 'abstract_zh': '本研究对Zhuang等提出的一种集合式提示方法在大规模语言模型（LLMs）零样本排名中的可再现性和扩展性进行了全面分析。我们评估了它在文档排名任务中与传统点wise、对wise和列wise方法相比的有效性和效率。我们的再现结果证实了Zhuang等人的发现，突显了集合式方法在计算效率与排名效果之间的权衡。在此基础上，我们引入了一种新的方法——集合式插入，该方法利用初始文档排名作为先验知识，通过聚焦更有可能提高排名结果的候选者，减少不必要的比较和不确定性。实验结果表明，集合式插入方法在多种LLM架构（Flan-T5、Vicuna和Llama）上使查询时间减少了31%，模型推理减少了23%，并且在重新排序效果上略有提升。这些发现强调了在集合式提示中融入先验排名知识以实现高效准确的零样本文档重新排序的实际优势。', 'title_zh': '超越可重复性：基于集合插入的零-shot LLM重新排-ranking效率提升'}
{'arxiv_id': 'arXiv:2504.10508', 'title': 'Poly-Vector Retrieval: Reference and Content Embeddings for Legal Documents', 'authors': 'João Alberto de Oliveira Lima', 'link': 'https://arxiv.org/abs/2504.10508', 'abstract': 'Retrieval-Augmented Generation (RAG) has emerged as an effective paradigm for generating contextually accurate answers by integrating Large Language Models (LLMs) with retrieval mechanisms. However, in legal contexts, users frequently reference norms by their labels or nicknames (e.g., Article 5 of the Constitution or Consumer Defense Code (CDC)), rather than by their content, posing challenges for traditional RAG approaches that rely solely on semantic embeddings of text. Furthermore, legal texts themselves heavily rely on explicit cross-references (e.g., "pursuant to Article 34") that function as pointers. Both scenarios pose challenges for traditional RAG approaches that rely solely on semantic embeddings of text, often failing to retrieve the necessary referenced content. This paper introduces Poly-Vector Retrieval, a method assigning multiple distinct embeddings to each legal provision: one embedding captures the content (the full text), another captures the label (the identifier or proper name), and optionally additional embeddings capture alternative denominations. Inspired by Frege\'s distinction between Sense and Reference, this poly-vector retrieval approach treats labels, identifiers and reference markers as rigid designators and content embeddings as carriers of semantic substance. Experiments on the Brazilian Federal Constitution demonstrate that Poly-Vector Retrieval significantly improves retrieval accuracy for label-centric queries and potential to resolve internal and external cross-references, without compromising performance on purely semantic queries. The study discusses philosophical and practical implications of explicitly separating reference from content in vector embeddings and proposes future research directions for applying this approach to broader legal datasets and other domains characterized by explicit reference identifiers.', 'abstract_zh': '多向量检索增益生成（Poly-Vector Retrieval Augmented Generation）：解决法律情境下检索与生成问题', 'title_zh': '多向量检索：法律文档的参考和内容嵌入'}
{'arxiv_id': 'arXiv:2504.10500', 'title': 'Leveraging Auto-Distillation and Generative Self-Supervised Learning in Residual Graph Transformers for Enhanced Recommender Systems', 'authors': 'Eya Mhedhbi, Youssef Mourchid, Alice Othmani', 'link': 'https://arxiv.org/abs/2504.10500', 'abstract': 'This paper introduces a cutting-edge method for enhancing recommender systems through the integration of generative self-supervised learning (SSL) with a Residual Graph Transformer. Our approach emphasizes the importance of superior data enhancement through the use of pertinent pretext tasks, automated through rationale-aware SSL to distill clear ways of how users and items interact. The Residual Graph Transformer incorporates a topology-aware transformer for global context and employs residual connections to improve graph representation learning. Additionally, an auto-distillation process refines self-supervised signals to uncover consistent collaborative rationales. Experimental evaluations on multiple datasets demonstrate that our approach consistently outperforms baseline methods.', 'abstract_zh': '基于残差图变换器的生成自监督学习增强推荐系统方法', 'title_zh': '利用自动蒸馏和生成自监督学习在残差图变换器中的应用以增强推荐系统'}
{'arxiv_id': 'arXiv:2504.10498', 'title': 'CCSK:Cognitive Convection of Self-Knowledge Based Retrieval Augmentation for Large Language Models', 'authors': 'Jianling Lu, Mingqi Lv', 'link': 'https://arxiv.org/abs/2504.10498', 'abstract': "The performance of large language models (LLMs) in Q&A task increased substantially through Retrieval-Augmented Generation (RAG) which brings in external knowledge. However, the main difficulty lies in balancing the inherent self-knowledge of LLMs with external information retrieval (IR). The current threshold-based methods apply one-dimensional static mechanisms with single criterion. As a result, their IR decisions might be irrelevant to the LLMs' response under difficult queries. To alleviate this problem, we propose Cognitive Convection of Self-Knowledge (CCSK). Different from traditional methods that maintain single fixed IR activation criteria, CCSK implements a dynamic joint decision process via a Siamese Network module and a Response Quality Model. The Siamese Network calculates the cosine similarity between the current query and the historical queries. The Response Quality Model evaluates the responses of LLMs through LightGBM. The final decision of the CCSK is derived from the outputs of the two modules, as well as text features fused using a multi-head attention mechanism. Extensive experiments on real-world datasets show that CCSK significantly enhances the model's effectiveness in information retrieval.", 'abstract_zh': '大型语言模型（LLMs）在问答任务中的表现通过检索增强生成（RAG）显著提高，这带来了外部知识。然而，主要困难在于平衡LLMs的固有自我知识与外部信息检索（IR）。当前的阈值方法使用一维静态机制和单一标准，结果可能在复杂查询下与LLMs的回答无关。为了解决这一问题，我们提出了一种认知自知识传递（CCSK）方法。不同于传统方法保持单一固定的IR激活标准，CCSK通过Siamese网络模块和响应质量模型实现动态联合决策过程。Siamese网络计算当前查询与历史查询之间的余弦相似度。响应质量模型通过LightGBM评估LLMs的响应质量。CCSK的最终决策来自两个模块的输出以及使用多头注意力机制融合的文本特征。在实际数据集上的广泛实验结果显示，CCSK显著提高了模型在信息检索方面的有效性。', 'title_zh': 'CCSK：基于认知收敛的自我知识增强检索増强\tfor 大语言模型'}
{'arxiv_id': 'arXiv:2504.10497', 'title': 'Exploring Generative AI Techniques in Government: A Case Study', 'authors': 'Sunyi Liu, Mengzhe Geng, Rebecca Hart', 'link': 'https://arxiv.org/abs/2504.10497', 'abstract': 'The swift progress of Generative Artificial intelligence (GenAI), notably Large Language Models (LLMs), is reshaping the digital landscape. Recognizing this transformative potential, the National Research Council of Canada (NRC) launched a pilot initiative to explore the integration of GenAI techniques into its daily operation for performance excellence, where 22 projects were launched in May 2024. Within these projects, this paper presents the development of the intelligent agent Pubbie as a case study, targeting the automation of performance measurement, data management and insight reporting at the NRC. Cutting-edge techniques are explored, including LLM orchestration and semantic embedding via RoBERTa, while strategic fine-tuning and few-shot learning approaches are incorporated to infuse domain knowledge at an affordable cost. The user-friendly interface of Pubbie allows general government users to input queries in natural language and easily upload or download files with a simple button click, greatly reducing manual efforts and accessibility barriers.', 'abstract_zh': '生成式人工智能（GenAI）的迅速进步，尤其是大规模语言模型（LLMs），正在重塑数字landscape。加拿大国家研究 Council（NRC）认识到这一变革潜力，于2024年5月启动了一项试点项目，探索将GenAI技术整合到日常运营中以实现卓越绩效，共启动了22个项目。在这些建设中，本文以智能代理Pubbie的发展为例，旨在探讨NRC内部的工作绩效测量、数据管理和洞察报告的自动化。研究采用了包括LLM编排和通过RoBERTa进行语义嵌入在内的先进方法，并结合了战略性 fine-tuning 和少样本学习方法，以在经济高效的情况下融入领域知识。Pubbie友好的用户界面允许一般政府用户以自然语言输入查询并轻松地通过单击按钮上传或下载文件，大大减少了人工努力和访问障碍。', 'title_zh': '探索政府领域中的生成型AI技术：一个案例研究'}
{'arxiv_id': 'arXiv:2504.10496', 'title': 'ArxivBench: Can LLMs Assist Researchers in Conducting Research?', 'authors': 'Ning Li, Jingran Zhang, Justin Cui', 'link': 'https://arxiv.org/abs/2504.10496', 'abstract': 'Large language models (LLMs) have demonstrated remarkable effectiveness in completing various tasks such as reasoning, translation, and question answering. However the issue of factual incorrect content in LLM-generated responses remains a persistent challenge. In this study, we evaluate both proprietary and open-source LLMs on their ability to respond with relevant research papers and accurate links to articles hosted on the arXiv platform, based on high level prompts. To facilitate this evaluation, we introduce arXivBench, a benchmark specifically designed to assess LLM performance across eight major subject categories on arXiv and five subfields within computer science, one of the most popular categories among them. Our findings reveal a concerning accuracy of LLM-generated responses depending on the subject, with some subjects experiencing significantly lower accuracy than others. Notably, Claude-3.5-Sonnet exhibits a substantial advantage in generating both relevant and accurate responses. And interestingly, most LLMs achieve a much higher accuracy in the Artificial Intelligence sub-field than other sub-fields. This benchmark provides a standardized tool for evaluating the reliability of LLM-generated scientific responses, promoting more dependable use of LLMs in academic and research environments. Our code is open-sourced at this https URL and our dataset is available on huggingface at this https URL.', 'abstract_zh': '大型语言模型（LLMs）在完成推理、翻译和问答等多种任务方面表现出色。然而，LLM生成的响应中事实错误内容的问题仍然是一个持续的挑战。在本研究中，我们基于高级提示，评估了商用和开源LLM在回应与arXiv平台上的研究论文和准确链接方面的能力。为了 facilitating 这项评估，我们引入了arXivBench，这是一个专门设计用于评估LLM在arXiv八大主要学科类别和计算机科学五个子领域（其中最受欢迎的领域之一）上性能的基准。我们的研究发现，LLM生成的响应准确性在不同学科间存在显著差异，某些科目比其他科目准确性低得多。值得注意的是，Claude-3.5-Sonnet在生成相关且准确的响应方面表现出明显的优越性。另外，有趣的是，大多数LLM在人工智能子领域中的准确性远高于其他子领域。该基准提供了一个标准化工具，用于评估LLM生成的科学响应的可靠性，促进在学术和研究环境中更可靠地使用LLM。我们的代码在此传送门开源，数据集在此传送门可在huggingface获得。', 'title_zh': 'ArxivBench: LLMs能协助研究人员进行研究吗？'}
{'arxiv_id': 'arXiv:2504.10489', 'title': 'Roamify: Designing and Evaluating an LLM Based Google Chrome Extension for Personalised Itinerary Planning', 'authors': 'Vikranth Udandarao, Noel Abraham Tiju, Muthuraj Vairamuthu, Harsh Mistry, Dhruv Kumar', 'link': 'https://arxiv.org/abs/2504.10489', 'abstract': 'In this paper, we present Roamify, an Artificial Intelligence powered travel assistant that aims to ease the process of travel planning. We have tested and used multiple Large Language Models like Llama and T5 to generate personalised itineraries per user preferences. Results from user surveys highlight the preference for AI powered mediums over existing methods to help in travel planning across all user age groups. These results firmly validate the potential need of such a travel assistant. We highlight the two primary design considerations for travel assistance: D1) incorporating a web-scraping method to gather up-to-date news articles about destinations from various blog sources, which significantly improves our itinerary suggestions, and D2) utilising user preferences to create customised travel experiences along with a recommendation system which changes the itinerary according to the user needs. Our findings suggest that Roamify has the potential to improve and simplify how users across multiple age groups plan their travel experiences.', 'abstract_zh': 'Roamify：一种基于人工智能的旅行助手，旨在简化旅行规划过程', 'title_zh': 'Roamify: 设计与评估一个基于LLM的Google Chrome扩展程序，用于个性化行程规划'}
{'arxiv_id': 'arXiv:2504.09861', 'title': 'EthosGPT: Mapping Human Value Diversity to Advance Sustainable Development Goals (SDGs)', 'authors': 'Luyao Zhang', 'link': 'https://arxiv.org/abs/2504.09861', 'abstract': "Large language models (LLMs) are transforming global decision-making and societal systems by processing diverse data at unprecedented scales. However, their potential to homogenize human values poses critical risks, similar to biodiversity loss undermining ecological resilience. Rooted in the ancient Greek concept of ethos, meaning both individual character and the shared moral fabric of communities, EthosGPT draws on a tradition that spans from Aristotle's virtue ethics to Adam Smith's moral sentiments as the ethical foundation of economic cooperation. These traditions underscore the vital role of value diversity in fostering social trust, institutional legitimacy, and long-term prosperity. EthosGPT addresses the challenge of value homogenization by introducing an open-source framework for mapping and evaluating LLMs within a global scale of human values. Using international survey data on cultural indices, prompt-based assessments, and comparative statistical analyses, EthosGPT reveals both the adaptability and biases of LLMs across regions and cultures. It offers actionable insights for developing inclusive LLMs, such as diversifying training data and preserving endangered cultural heritage to ensure representation in AI systems. These contributions align with the United Nations Sustainable Development Goals (SDGs), especially SDG 10 (Reduced Inequalities), SDG 11.4 (Cultural Heritage Preservation), and SDG 16 (Peace, Justice and Strong Institutions). Through interdisciplinary collaboration, EthosGPT promotes AI systems that are both technically robust and ethically inclusive, advancing value plurality as a cornerstone for sustainable and equitable futures.", 'abstract_zh': '大型语言模型（LLMs）通过前所未有的规模处理多元数据，正在全球决策和社会系统中发挥变革作用。然而，它们对人类价值观同质化的潜在风险类似于生物多样性丧失对生态弹性的破坏。根植于古希腊的“ethos”概念，既指个体特质，也指社区共享的道德织体，EthosGPT借鉴了从亚里士多德美德伦理学到亚当·斯密道德情感的伦理传统，这些传统强调价值观多样性在促进社会信任、制度合法性及长期繁荣中的关键作用。EthosGPT通过引入一个开源框架，在全球人类价值观范围内映射和评估LLMs，应对价值观同质化的挑战。利用国际文化指数调查数据、基于提示的评估以及比较统计分析，EthosGPT揭示了LLMs在不同地区和文化中的适应性和偏见，并提供了促进包容性LLMs发展的行动建议，如多样化训练数据和保存濒临失传的文化遗产，以确保AI系统的代表性。这些贡献与联合国可持续发展目标（SDGs）尤其是SDG 10（减少不平等）、SDG 11.4（文化遗产保护）和SDG 16（和平、正义和强大制度）相一致。通过跨学科合作，EthosGPT推动了既技术上稳健又伦理上包容的AI系统，将价值观多样性作为实现可持续和公平未来的核心基石。', 'title_zh': 'EthosGPT: 映射人类价值多样性以促进可持续发展目标（SDGs）'}
{'arxiv_id': 'arXiv:1908.08652', 'title': 'MTCNET: Multi-task Learning Paradigm for Crowd Count Estimation', 'authors': 'Abhay Kumar, Nishant Jain, Suraj Tripathi, Chirag Singh, Kamal Krishna', 'link': 'https://arxiv.org/abs/1908.08652', 'abstract': 'We propose a Multi-Task Learning (MTL) paradigm based deep neural network architecture, called MTCNet (Multi-Task Crowd Network) for crowd density and count estimation. Crowd count estimation is challenging due to the non-uniform scale variations and the arbitrary perspective of an individual image. The proposed model has two related tasks, with Crowd Density Estimation as the main task and Crowd-Count Group Classification as the auxiliary task. The auxiliary task helps in capturing the relevant scale-related information to improve the performance of the main task. The main task model comprises two blocks: VGG-16 front-end for feature extraction and a dilated Convolutional Neural Network for density map generation. The auxiliary task model shares the same front-end as the main task, followed by a CNN classifier. Our proposed network achieves 5.8% and 14.9% lower Mean Absolute Error (MAE) than the state-of-the-art methods on ShanghaiTech dataset without using any data augmentation. Our model also outperforms with 10.5% lower MAE on UCF_CC_50 dataset.', 'abstract_zh': '基于多任务学习的众人群体密度和计数估算的MTCNet架构', 'title_zh': 'MTCNET：多任务学习框架用于人群计数估计'}
{'arxiv_id': 'arXiv:1906.05682', 'title': 'Focal Loss based Residual Convolutional Neural Network for Speech Emotion Recognition', 'authors': 'Suraj Tripathi, Abhay Kumar, Abhiram Ramesh, Chirag Singh, Promod Yenigalla', 'link': 'https://arxiv.org/abs/1906.05682', 'abstract': 'This paper proposes a Residual Convolutional Neural Network (ResNet) based on speech features and trained under Focal Loss to recognize emotion in speech. Speech features such as Spectrogram and Mel-frequency Cepstral Coefficients (MFCCs) have shown the ability to characterize emotion better than just plain text. Further Focal Loss, first used in One-Stage Object Detectors, has shown the ability to focus the training process more towards hard-examples and down-weight the loss assigned to well-classified examples, thus preventing the model from being overwhelmed by easily classifiable examples.', 'abstract_zh': '基于语音特征和焦损失的残差卷积神经网络情感识别研究成果', 'title_zh': '基于焦点损失的残差卷积神经网络在语音情绪识别中的应用'}
{'arxiv_id': 'arXiv:2504.10445', 'title': 'RealWebAssist: A Benchmark for Long-Horizon Web Assistance with Real-World Users', 'authors': 'Suyu Ye, Haojun Shi, Darren Shih, Hyokun Yun, Tanya Roosta, Tianmin Shu', 'link': 'https://arxiv.org/abs/2504.10445', 'abstract': "To achieve successful assistance with long-horizon web-based tasks, AI agents must be able to sequentially follow real-world user instructions over a long period. Unlike existing web-based agent benchmarks, sequential instruction following in the real world poses significant challenges beyond performing a single, clearly defined task. For instance, real-world human instructions can be ambiguous, require different levels of AI assistance, and may evolve over time, reflecting changes in the user's mental state. To address this gap, we introduce RealWebAssist, a novel benchmark designed to evaluate sequential instruction-following in realistic scenarios involving long-horizon interactions with the web, visual GUI grounding, and understanding ambiguous real-world user instructions. RealWebAssist includes a dataset of sequential instructions collected from real-world human users. Each user instructs a web-based assistant to perform a series of tasks on multiple websites. A successful agent must reason about the true intent behind each instruction, keep track of the mental state of the user, understand user-specific routines, and ground the intended tasks to actions on the correct GUI elements. Our experimental results show that state-of-the-art models struggle to understand and ground user instructions, posing critical challenges in following real-world user instructions for long-horizon web assistance.", 'abstract_zh': '实现长周期网络任务的有效辅助，AI代理必须能够在长期内按照现实世界用户的指令顺序执行。与现有的基于网络的代理基准不同，真实世界的顺序指令遵循带来了超出执行单一明确任务之外的重大挑战。例如，现实世界的用户指令可能是模糊的，需要不同程度的AI辅助，并且可能会随时间演变，反映用户心理状态的变化。为了弥补这一空白，我们引入了RealWebAssist，这是一个新颖的基准，旨在评估在涉及长时间与网络交互、视觉GUI定位以及理解模糊的现实世界用户指令的现实场景中顺序指令遵循的能力。RealWebAssist 包括从真实世界人类用户收集的顺序指令数据集。每个用户指示一个基于网络的助手在多个网站上执行一系列任务。成功的代理必须理解每条指令背后的真正意图，跟踪用户的心理状态，了解用户的特定程序，并将意图任务与正确的GUI元素上的操作进行关联。我们的实验结果表明，最先进的模型难以理解并定位用户指令，在长时间网络辅助中遵循现实世界的用户指令面临关键挑战。', 'title_zh': 'RealWebAssist：基于真实用户的长视角网页助手基准'}
