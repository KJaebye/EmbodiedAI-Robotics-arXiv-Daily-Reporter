{'arxiv_id': 'arXiv:2510.07297', 'title': 'Agentic generative AI for media content discovery at the national football league', 'authors': 'Henry Wang, Sirajus Salekin, Jake Lee, Ross Claytor, Shinan Zhang, Michael Chi', 'link': 'https://arxiv.org/abs/2510.07297', 'abstract': "Generative AI has unlocked new possibilities in content discovery and management. Through collaboration with the National Football League (NFL), we demonstrate how a generative-AI based workflow enables media researchers and analysts to query relevant historical plays using natural language rather than traditional filter-and-click interfaces. The agentic workflow takes a user query as input, breaks it into elements, and translates them into the underlying database query language. Accuracy and latency are further improved through carefully designed semantic caching. The solution achieves over 95 percent accuracy and reduces the average time to find relevant videos from 10 minutes to 30 seconds, significantly increasing the NFL's operational efficiency and allowing users to focus on producing creative content and engaging storylines.", 'abstract_zh': '生成式AI解锁了内容发现和管理的新可能性。通过与美国国家足球联盟（NFL）的合作，我们展示了基于生成式AI的工作流如何使媒体研究人员和分析师能够使用自然语言查询相关历史比赛，而无需传统的过滤和点击界面。该代理工作流将用户查询作为输入，将其拆分为元素，并转化为底层的数据库查询语言。通过精心设计的语义缓存进一步提高准确性和延迟。该解决方案实现超过95%的准确率，并将找到相关视频的平均时间从10分钟减少到30秒，显著提高了NFL的操作效率，使用户能够专注于创作内容和构建引人入胜的故事线。', 'title_zh': '国家级足球联赛中代理生成AI的内容发现应用'}
{'arxiv_id': 'arXiv:2510.07276', 'title': 'Multi-Objective Multi-Agent Path Finding with Lexicographic Cost Preferences', 'authors': 'Pulkit Rustagi, Kyle Hollins Wray, Sandhya Saisubramanian', 'link': 'https://arxiv.org/abs/2510.07276', 'abstract': 'Many real-world scenarios require multiple agents to coordinate in shared environments, while balancing trade-offs between multiple, potentially competing objectives. Current multi-objective multi-agent path finding (MO-MAPF) algorithms typically produce conflict-free plans by computing Pareto frontiers. They do not explicitly optimize for user-defined preferences, even when the preferences are available, and scale poorly with the number of objectives. We propose a lexicographic framework for modeling MO-MAPF, along with an algorithm \\textit{Lexicographic Conflict-Based Search} (LCBS) that directly computes a single solution aligned with a lexicographic preference over objectives. LCBS integrates a priority-aware low-level $A^*$ search with conflict-based search, avoiding Pareto frontier construction and enabling efficient planning guided by preference over objectives. We provide insights into optimality and scalability, and empirically demonstrate that LCBS computes optimal solutions while scaling to instances with up to ten objectives -- far beyond the limits of existing MO-MAPF methods. Evaluations on standard and randomized MAPF benchmarks show consistently higher success rates against state-of-the-art baselines, especially with increasing number of objectives.', 'abstract_zh': '多目标多智能体路径规划的词序框架及算法：LCBS', 'title_zh': '带词序成本偏好的多目标多智能体路径规划'}
{'arxiv_id': 'arXiv:2510.07172', 'title': 'NewtonBench: Benchmarking Generalizable Scientific Law Discovery in LLM Agents', 'authors': 'Tianshi Zheng, Kelvin Kiu-Wai Tam, Newt Hue-Nam K. Nguyen, Baixuan Xu, Zhaowei Wang, Jiayang Cheng, Hong Ting Tsang, Weiqi Wang, Jiaxin Bai, Tianqing Fang, Yangqiu Song, Ginny Y. Wong, Simon See', 'link': 'https://arxiv.org/abs/2510.07172', 'abstract': 'Large language models are emerging as powerful tools for scientific law discovery, a foundational challenge in AI-driven science. However, existing benchmarks for this task suffer from a fundamental methodological trilemma, forcing a trade-off between scientific relevance, scalability, and resistance to memorization. Furthermore, they oversimplify discovery as static function fitting, failing to capture the authentic scientific process of uncovering embedded laws through the interactive exploration of complex model systems. To address these critical gaps, we introduce NewtonBench, a benchmark comprising 324 scientific law discovery tasks across 12 physics domains. Our design mitigates the evaluation trilemma by using metaphysical shifts - systematic alterations of canonical laws - to generate a vast suite of problems that are scalable, scientifically relevant, and memorization-resistant. Moreover, we elevate the evaluation from static function fitting to interactive model discovery, requiring agents to experimentally probe simulated complex systems to uncover hidden principles. Our extensive experiment reveals a clear but fragile capability for discovery in frontier LLMs: this ability degrades precipitously with increasing system complexity and exhibits extreme sensitivity to observational noise. Notably, we uncover a paradoxical effect of tool assistance: providing a code interpreter can hinder more capable models by inducing a premature shift from exploration to exploitation, causing them to satisfice on suboptimal solutions. These results demonstrate that robust, generalizable discovery in complex, interactive environments remains the core challenge. By providing a scalable, robust, and scientifically authentic testbed, NewtonBench offers a crucial tool for measuring true progress and guiding the development of next-generation AI agents capable of genuine scientific discovery.', 'abstract_zh': 'Large语言模型作为科学定律发现的强大工具正在 emergence，这是人工智能驱动科学的基础挑战。然而，现有任务基准在根本方法论三难中受到影响，被迫在科学相关性、可扩展性和抗记忆性之间做出权衡。此外，它们过度简化了发现过程，仅视为静态函数拟合，无法捕捉到通过探索复杂模型系统来揭示嵌入定律的真实科学过程。为了填补这些关键空白，我们引入了NewtonBench，这是一个涵盖12个物理学领域共324项科学定律发现任务的基准。我们的设计通过使用本体论转换——系统地改变经典定律——生成大量可扩展、科学相关且抗记忆性的问题。此外，我们将评估从静态函数拟合提升为交互式模型发现，要求代理对模拟的复杂系统进行实验性探索，以揭示隐藏的原则。我们的大量实验揭示了前沿LLM在发现方面的一种明确但易碎的能力：随着系统复杂性的增加，这种能力急剧下降，并对观测噪声表现出极端的敏感性。值得注意的是，我们发现了一个反常效应：提供代码解释器可能会妨碍更强大的模型，促使它们从探索转向利用，导致它们屈就于次优解决方案。这些结果表明，在复杂、交互式环境中实现稳健且通用的发现仍是最核心的挑战。通过提供一个可扩展、稳健且具有科学真实性的工作台，NewtonBench 提供了一个关键工具，用于衡量真实进展并引导下一代能够进行真正科学发现的AI代理的发展。', 'title_zh': 'NewtonBench: 评估大规模语言模型代理通用科学定律发现能力的基准测试'}
{'arxiv_id': 'arXiv:2510.07161', 'title': 'Integrating Domain Knowledge into Process Discovery Using Large Language Models', 'authors': 'Ali Norouzifar, Humam Kourani, Marcus Dees, Wil van der Aalst', 'link': 'https://arxiv.org/abs/2510.07161', 'abstract': 'Process discovery aims to derive process models from event logs, providing insights into operational behavior and forming a foundation for conformance checking and process improvement. However, models derived solely from event data may not accurately reflect the real process, as event logs are often incomplete or affected by noise, and domain knowledge, an important complementary resource, is typically disregarded. As a result, the discovered models may lack reliability for downstream tasks. We propose an interactive framework that incorporates domain knowledge, expressed in natural language, into the process discovery pipeline using Large Language Models (LLMs). Our approach leverages LLMs to extract declarative rules from textual descriptions provided by domain experts. These rules are used to guide the IMr discovery algorithm, which recursively constructs process models by combining insights from both the event log and the extracted rules, helping to avoid problematic process structures that contradict domain knowledge. The framework coordinates interactions among the LLM, domain experts, and a set of backend services. We present a fully implemented tool that supports this workflow and conduct an extensive evaluation of multiple LLMs and prompt engineering strategies. Our empirical study includes a case study based on a real-life event log with the involvement of domain experts, who assessed the usability and effectiveness of the framework.', 'abstract_zh': '过程发现旨在从事件日志中推导出过程模型，提供对操作行为的洞察，并为合规检查和过程改进奠定基础。然而，仅从事件数据中推导出的模型可能无法准确反映实际过程，因为事件日志通常不完整且受到噪声影响，而重要的补充资源领域知识通常被忽视。因此，所发现的模型可能不适用于下游任务。我们提出了一种交互式框架，通过大型语言模型（LLMs）将自然语言表达的领域知识融入过程发现过程中。我们的方法利用LLMs从领域专家提供的文本描述中提取声明性规则，并利用这些规则引导IMr发现算法，该算法递归地通过结合事件日志和提取规则的洞见来构建过程模型，从而避免与领域知识矛盾的过程结构。该框架协调了LLMs、领域专家和一组后端服务之间的交互。我们提供了一个完全实现的工具来支持这一工作流程，并针对多种LLMs和提示工程策略进行了广泛评估。我们的实证研究包括一个基于实际事件日志的案例研究，领域专家参与评估了该框架的可用性和有效性。', 'title_zh': '将领域知识集成到过程发现中使用大规模语言模型'}
{'arxiv_id': 'arXiv:2510.07117', 'title': 'The Contingencies of Physical Embodiment Allow for Open-Endedness and Care', 'authors': "Leonardo Christov-Moore, Arthur Juliani, Alex Kiefer, Nicco Reggente, B. Scott Rousse, Adam Safron, Nicol'as Hinrichs, Daniel Polani, Antonio Damasio", 'link': 'https://arxiv.org/abs/2510.07117', 'abstract': "Physical vulnerability and mortality are often seen as obstacles to be avoided in the development of artificial agents, which struggle to adapt to open-ended environments and provide aligned care. Meanwhile, biological organisms survive, thrive, and care for each other in an open-ended physical world with relative ease and efficiency. Understanding the role of the conditions of life in this disparity can aid in developing more robust, adaptive, and caring artificial agents. Here we define two minimal conditions for physical embodiment inspired by the existentialist phenomenology of Martin Heidegger: being-in-the-world (the agent is a part of the environment) and being-towards-death (unless counteracted, the agent drifts toward terminal states due to the second law of thermodynamics). We propose that from these conditions we can obtain both a homeostatic drive - aimed at maintaining integrity and avoiding death by expending energy to learn and act - and an intrinsic drive to continue to do so in as many ways as possible. Drawing inspiration from Friedrich Nietzsche's existentialist concept of will-to-power, we examine how intrinsic drives to maximize control over future states, e.g., empowerment, allow agents to increase the probability that they will be able to meet their future homeostatic needs, thereby enhancing their capacity to maintain physical integrity. We formalize these concepts within a reinforcement learning framework, which enables us to examine how intrinsically driven embodied agents learning in open-ended multi-agent environments may cultivate the capacities for open-endedness and this http URL", 'abstract_zh': '物理脆弱性和死亡率往往被视为在开发人工代理过程中需避免的障碍，这些代理难以适应开放环境并提供一致性的关怀。与此同时，生物有机体能够相对容易和高效地在开放物理世界中生存、繁盛并相互照顾。理解这种差异中的生活条件作用有助于开发出更为 robust、适应性强且富有关怀的人工代理。在此基础上，我们受到马丁·海德格尔存在主义现象学的启发，定义了两种基本的物理具身条件：在世之物（代理是环境的一部分）和死亡之趋近（除非受阻，代理会因热力学第二定律而向终结状态趋近）。我们提出，从这些条件出发，可以获取一种稳态驱动——旨在维持完整性并避免死亡，通过耗散能量来学习和行动——以及一种内在驱动力，使其尽可能以多种方式持续这么做。借鉴弗里德里希·尼采的存在主义概念“权力意志”，我们探讨了内在驱动力最大化对未来状态的控制（例如，赋权），如何使代理增加其满足未来稳态需求的可能性，从而增强其维持物理完整性的能力。我们在这类概念中采用强化学习框架进行正式化，使我们能够探究内在驱动的具身代理在开放多代理环境中的学习如何培养开放性和相关能力。', 'title_zh': '物理 embodimen 的偶然性允许开放性和关怀'}
{'arxiv_id': 'arXiv:2510.07091', 'title': 'The Cognitive Bandwidth Bottleneck: Shifting Long-Horizon Agent from Planning with Actions to Planning with Schemas', 'authors': 'Baixuan Xu, Tianshi Zheng, Zhaowei Wang, Hong Ting Tsang, Weiqi Wang, Tianqing Fang, Yangqiu Song', 'link': 'https://arxiv.org/abs/2510.07091', 'abstract': 'Enabling LLMs to effectively operate long-horizon task which requires long-term planning and multiple interactions is essential for open-world autonomy. Conventional methods adopt planning with actions where a executable action list would be provided as reference. However, this action representation choice would be impractical when the environment action space is combinatorial exploded (e.g., open-ended real world). This naturally leads to a question: As environmental action space scales, what is the optimal action representation for long-horizon agents? In this paper, we systematically study the effectiveness of two different action representations. The first one is conventional planning with actions (PwA) which is predominantly adopted for its effectiveness on existing benchmarks. The other one is planning with schemas (PwS) which instantiate an action schema into action lists (e.g., "move [OBJ] to [OBJ]" -> "move apple to desk") to ensure concise action space and reliable scalability. This alternative is motivated by its alignment with human cognition and its compliance with environment-imposed action format restriction. We propose cognitive bandwidth perspective as a conceptual framework to qualitatively understand the differences between these two action representations and empirically observe a representation-choice inflection point between ALFWorld (~35 actions) and SciWorld (~500 actions), which serve as evidence of the need for scalable representations. We further conduct controlled experiments to study how the location of this inflection point interacts with different model capacities: stronger planning proficiency shifts the inflection rightward, whereas better schema instantiation shifts it leftward. Finally, noting the suboptimal performance of PwS agents, we provide an actionable guide for building more capable PwS agents for better scalable autonomy.', 'abstract_zh': '使大语言模型能够有效执行长期任务并进行长期规划和多次交互对于开放世界自主性至关重要。传统方法采用基于动作的规划方式，其中会提供可执行动作列表作为参考。然而，当环境动作空间出现组合爆炸（例如，开放的真实世界）时，这种动作表示形式的选择将变得不切实际。这自然引出了一个问题：随着环境动作空间的扩大，长期任务代理的最佳动作表示形式是什么？在本文中，我们系统地研究了两种不同动作表示形式的有效性。第一种是传统的基于动作的规划（PwA），因其在现有基准上的有效性而广泛采用。第二种是基于模式的规划（PwS），它将动作模式实例化为动作列表（例如，“将[OBJ]移动到[OBJ]” -> “将苹果移动到桌子”），以确保简洁的动作空间和可靠的可扩展性。这种替代方案的动力在于其与人类认知的契合以及对环境动作格式限制的合规性。我们提出认知带宽视角作为概念框架，以定性理解这两种动作表示形式之间的差异，并实证观察到认知带宽视角下的表示选择转折点，该转折点在ALFWorld（约35个动作）和SciWorld（约500个动作）之间，为需要可扩展表示形式的需求提供了证据。我们进一步进行了受控实验，研究这种转折点位置与不同模型能力的交互方式：更强的规划 proficiency使转折向右移动，而更好的模式实例化使转折向左移动。最后，注意到PwS代理的次优性能，我们提供了一条实用指南，以构建更强大且可扩展的PwS代理，从而实现更好的自主性。', 'title_zh': '认知带宽瓶颈：从基于动作规划转向基于模式规划的长期 horizon 代理'}
{'arxiv_id': 'arXiv:2510.07073', 'title': 'VRPAgent: LLM-Driven Discovery of Heuristic Operators for Vehicle Routing Problems', 'authors': 'André Hottung, Federico Berto, Chuanbo Hua, Nayeli Gast Zepeda, Daniel Wetzel, Michael Römer, Haoran Ye, Davide Zago, Michael Poli, Stefano Massaroli, Jinkyoo Park, Kevin Tierney', 'link': 'https://arxiv.org/abs/2510.07073', 'abstract': 'Designing high-performing heuristics for vehicle routing problems (VRPs) is a complex task that requires both intuition and deep domain knowledge. Large language model (LLM)-based code generation has recently shown promise across many domains, but it still falls short of producing heuristics that rival those crafted by human experts. In this paper, we propose VRPAgent, a framework that integrates LLM-generated components into a metaheuristic and refines them through a novel genetic search. By using the LLM to generate problem-specific operators, embedded within a generic metaheuristic framework, VRPAgent keeps tasks manageable, guarantees correctness, and still enables the discovery of novel and powerful strategies. Across multiple problems, including the capacitated VRP, the VRP with time windows, and the prize-collecting VRP, our method discovers heuristic operators that outperform handcrafted methods and recent learning-based approaches while requiring only a single CPU core. To our knowledge, \\VRPAgent is the first LLM-based paradigm to advance the state-of-the-art in VRPs, highlighting a promising future for automated heuristics discovery.', 'abstract_zh': '基于大型语言模型的VRP代理框架：整合生成组件并通过新颖的遗传搜索进行精化', 'title_zh': 'VRPAgent：基于LLM的车辆路线问题启发式操作发现'}
{'arxiv_id': 'arXiv:2510.07069', 'title': 'Inductive Learning for Possibilistic Logic Programs Under Stable Models', 'authors': 'Hongbo Hu, Yisong Wang, Yi Huang, Kewen Wang', 'link': 'https://arxiv.org/abs/2510.07069', 'abstract': 'Possibilistic logic programs (poss-programs) under stable models are a major variant of answer set programming (ASP). While its semantics (possibilistic stable models) and properties have been well investigated, the problem of inductive reasoning has not been investigated yet. This paper presents an approach to extracting poss-programs from a background program and examples (parts of intended possibilistic stable models). To this end, the notion of induction tasks is first formally defined, its properties are investigated and two algorithms ilpsm and ilpsmmin for computing induction solutions are presented. An implementation of ilpsmmin is also provided and experimental results show that when inputs are ordinary logic programs, the prototype outperforms a major inductive learning system for normal logic programs from stable models on the datasets that are randomly generated.', 'abstract_zh': 'Possibilistic 逻辑程序在稳定模型下的归纳推理', 'title_zh': 'possibilistic 逻辑程序在稳定模型下的归纳学习'}
{'arxiv_id': 'arXiv:2510.07064', 'title': 'Prompt Optimization Across Multiple Agents for Representing Diverse Human Populations', 'authors': 'Manh Hung Nguyen, Sebastian Tschiatschek, Adish Singla', 'link': 'https://arxiv.org/abs/2510.07064', 'abstract': 'The difficulty and expense of obtaining large-scale human responses make Large Language Models (LLMs) an attractive alternative and a promising proxy for human behavior. However, prior work shows that LLMs often produce homogeneous outputs that fail to capture the rich diversity of human perspectives and behaviors. Thus, rather than trying to capture this diversity with a single LLM agent, we propose a novel framework to construct a set of agents that collectively capture the diversity of a given human population. Each agent is an LLM whose behavior is steered by conditioning on a small set of human demonstrations (task-response pairs) through in-context learning. The central challenge is therefore to select a representative set of LLM agents from the exponentially large space of possible agents. We tackle this selection problem from the lens of submodular optimization. In particular, we develop methods that offer different trade-offs regarding time complexity and performance guarantees. Extensive experiments in crowdsourcing and educational domains demonstrate that our approach constructs agents that more effectively represent human populations compared to baselines. Moreover, behavioral analyses on new tasks show that these agents reproduce the behavior patterns and perspectives of the students and annotators they are designed to represent.', 'abstract_zh': '大规模人类响应的获取难度和成本使得大型语言模型（LLMs）成为人类行为的有吸引力的替代方案和前景看好的代理。然而，先前的工作表明，LLMs经常产生同质化的输出，无法捕捉人类视角和行为的丰富多样性。因此，我们不试图通过单个LLM代理来捕捉这种多样性，而是提出了一种新的框架，构建一个集体制约来捕捉给定人类群体的多样性。每个代理是通过基于少量人类示范（任务-响应对）的上下文学习来引导其行为的LLM。因此，核心挑战是从可能的代理的指数空间中选择一个具有代表性的代理集。我们从亚模优化的角度来解决这个问题。特别是，我们开发了具有不同时间复杂性和性能保证的不同方法。在人群绘制和教育领域的广泛实验表明，我们方法构建的代理比基线方法更能有效地代表人类群体。此外，对新任务的行为分析表明，这些代理再现了设计它们来代表的学生和标注者的行为模式和视角。', 'title_zh': '跨多个代理优化提示以表示多元人类群体'}
{'arxiv_id': 'arXiv:2510.07038', 'title': 'Tool-Augmented Policy Optimization: Synergizing Reasoning and Adaptive Tool Use with Reinforcement Learning', 'authors': 'Wenxun Wu, Yuanyang Li, Guhan Chen, Linyue Wang, Hongyang Chen', 'link': 'https://arxiv.org/abs/2510.07038', 'abstract': 'Recent advances in large language models (LLMs) have popularized test-time scaling, where models generate additional reasoning tokens before producing final answers. These approaches have demonstrated significant performance improvements on benchmarks involving mathematical reasoning. However, language models relying solely on direct inference still struggle with tasks demanding up-to-date knowledge or computational tools such as calculators and code interpreters for complex arithmetic operations. To overcome these limitations, we propose Tool-Augmented Policy Optimization (TAPO), a novel reinforcement learning framework that systematically integrates multi-hop reasoning with adaptive tool-calling capabilities. Our approach employs a modified version of Dynamic Sampling Policy Optimization (DAPO), a recently developed RL paradigm, which we adapt specifically for tool invocation scenarios, enabling models to dynamically interleave complex reasoning with on-demand tool usage (including search APIs and Python interpreters).\nTo support this research, we introduce two new datasets: TAPO-easy-60K and TAPO-hard-18K, specifically designed to train and evaluate both fact-based reasoning and mathematical calculation capabilities. Our experiments on Qwen2.5-3B and Qwen2.5-7B models demonstrate the effectiveness of our approach, with both models achieving state-of-the-art performance on tasks requiring external knowledge and mathematical computation among methods with comparable parameters. Notably, TAPO achieves more efficient tool utilization than baseline methods while preventing excessive calls caused by reward hacking. These results highlight the significant potential of combining advanced reasoning with tool usage to enhance model performance in knowledge-intensive and computationally demanding tasks.', 'abstract_zh': '近期大型语言模型的发展推动了测试时扩展技术的普及，模型在生成最终答案之前会生成额外的推理令牌。尽管这些方法在涉及数学推理的基准测试中表现出显著的性能提升，但仅依赖直接推理的语言模型在处理需要最新知识或计算器、代码解释器等计算工具的任务时仍面临挑战，尤其是在复杂算术操作方面。为克服这些局限性，我们提出了工具增强策略优化（TAPO）框架，这是一种新颖的强化学习框架，系统地将多跳推理与适应性工具调用能力相结合。该方法采用了一种最近开发的RL范式——动态采样策略优化（DAPO）的修改版本，并针对工具调用场景进行了特定的适应，使模型能够在复杂推理与按需工具使用（包括搜索API和Python解释器）之间动态交织。\n\n为了支持这项研究，我们引入了两个新的数据集：TAPO-easy-60K和TAPO-hard-18K，专门用于训练和评估基于事实的推理和数学计算能力。我们的实验表明，无论是Qwen2.5-3B还是Qwen2.5-7B模型，我们的方法都有效，同时在需要外部知识和数学计算的任务中达到了具有可比参数方法的最先进性能。值得注意的是，TAPO在工具利用效率上优于基线方法，同时防止了由于奖励黑客而导致的过度调用。这些结果突显了将高级推理与工具使用相结合以提高知识密集型和计算密集型任务模型性能的巨大潜力。', 'title_zh': '工具增强的策略优化：强化学习中推理与自适应工具使用相结合'}
{'arxiv_id': 'arXiv:2510.06953', 'title': 'Revisiting the Uniform Information Density Hypothesis in LLM Reasoning Traces', 'authors': 'Minju Gwak, Guijin Son, Jaehyung Kim', 'link': 'https://arxiv.org/abs/2510.06953', 'abstract': 'The Uniform Information Density (UID) hypothesis suggests that effective communication maintains a stable flow of information. In this work, we revisit this principle in the context of large language model (LLM) reasoning traces, asking whether step-level uniformity reflects reasoning quality. To this end, we propose an entropy-based stepwise information density metric and introduce two complementary measures of uniformity, local and global uniformity scores. Across the experiments on six different reasoning benchmarks, we find that step-level uniformity not only provides a strong theoretical lens but also yields practical performance benefits; for example, selecting reasoning traces with more uniform information density at the step-level improves accuracy by 10-32\\% relative gains over baselines at AIME2025. Our analysis further reveals that correct reasoning traces tend to avoid sharp information density spikes, while incorrect traces exhibit irregular information bursts. These results demonstrate that UID-inspired information density measures outperform alternative internal signals as predictors of reasoning quality. Results highlight the uniformity of the information density as a robust diagnostic and selection criterion for building more reliable and accurate reasoning systems.', 'abstract_zh': '统一信息密度（UID）假设认为有效的通信保持信息流的稳定性。本文在大语言模型（LLM）推理追踪的背景下重新审视这一原则，询问步骤级的均匀性是否反映推理质量。为此，我们提出了一种基于熵的步骤级信息密度度量，并引入了局部和全局均匀性评分两种互补的一致性度量标准。通过对六个不同的推理基准的实验，我们发现步骤级的一致性不仅提供了强大的理论视角，还带来了实际性能优势；例如，选择步骤级信息密度更均匀的推理追踪可在AIME2025基准上实现10-32%的相对准确率提升。进一步的分析表明，正确推理追踪倾向于避免信息密度突跃，而不正确追踪则表现出不规则的信息突发。这些结果表明，基于UID的信息密度度量优于其他替代内部信号，作为推理质量的预测指标。结果强调信息密度的一致性是构建更可靠和准确推理系统的重要诊断和选择标准。', 'title_zh': '重新审视大规模语言模型推理轨迹中的均匀信息密度假设'}
{'arxiv_id': 'arXiv:2510.06911', 'title': 'LLM-Assisted Modeling of Semantic Web-Enabled Multi-Agents Systems with AJAN', 'authors': 'Hacane Hechehouche, Andre Antakli, Matthias Klusch', 'link': 'https://arxiv.org/abs/2510.06911', 'abstract': 'There are many established semantic Web standards for implementing multi-agent driven applications. The AJAN framework allows to engineer multi-agent systems based on these standards. In particular, agent knowledge is represented in RDF/RDFS and OWL, while agent behavior models are defined with Behavior Trees and SPARQL to access and manipulate this knowledge. However, the appropriate definition of RDF/RDFS and SPARQL-based agent behaviors still remains a major hurdle not only for agent modelers in practice. For example, dealing with URIs is very error-prone regarding typos and dealing with complex SPARQL queries in large-scale environments requires a high learning curve. In this paper, we present an integrated development environment to overcome such hurdles of modeling AJAN agents and at the same time to extend the user community for AJAN by the possibility to leverage Large Language Models for agent engineering.', 'abstract_zh': 'AJAN框架中基于RDF/RDFS和SPARQL的多智能体系统开发环境设计', 'title_zh': '基于AJAN的语义网启用多智能体系统建模辅助方法'}
{'arxiv_id': 'arXiv:2510.06878', 'title': 'TGPR: Tree-Guided Policy Refinement for Robust Self-Debugging of LLMs', 'authors': 'Daria Ozerova, Ekaterina Trofimova', 'link': 'https://arxiv.org/abs/2510.06878', 'abstract': 'Iterative refinement has been a promising paradigm to enable large language models (LLMs) to resolve difficult reasoning and problem-solving tasks. One of the key challenges, however, is how to effectively search through the enormous search space of possible refinements. Existing methods typically fall back on predefined heuristics, which are troubled by the exploration-exploitation dilemma and cannot adapt based on past refinement outcomes. We introduce Tree-Guided Policy Refinement (TGPR), a novel framework that combines GRPO with a Thompson-Sampling-based tree search. TGPR explores both failed and successful refinement paths actively, with denser training trajectories and more adaptive policies. On HumanEval, MBPP, and APPS benchmarks, our method achieves up to +4.2 percentage points absolute improvement in pass@1 (on MBPP) and up to +12.51 percentage points absolute improvement in pass@10 (on APPS) compared to a competitive GRPO baseline. Apart from debugging code, TGPR focuses on a principled approach to combining learned policies with structured search methods, offering a general framework for enhancing iterative refinement and stateful reasoning in LLMs.', 'abstract_zh': '基于树引导的策略精炼（Tree-Guided Policy Refinement）：一种结合GRPO和Thompson-Sampling树搜索的框架', 'title_zh': 'TGPR：基于树引导的策略细化方法以实现LLM的稳健自我调试'}
{'arxiv_id': 'arXiv:2510.06857', 'title': 'Autoformalizer with Tool Feedback', 'authors': 'Qi Guo, Jianing Wang, Jianfei Zhang, Deyang Kong, Xiangzhou Huang, Xiangyu Xi, Wei Wang, Jingang Wang, Xunliang Cai, Shikun Zhang, Wei Ye', 'link': 'https://arxiv.org/abs/2510.06857', 'abstract': 'Autoformalization addresses the scarcity of data for Automated Theorem Proving (ATP) by translating mathematical problems from natural language into formal statements. Efforts in recent work shift from directly prompting large language models to training an end-to-end formalizer model from scratch, achieving remarkable advancements. However, existing formalizer still struggles to consistently generate valid statements that meet syntactic validity and semantic consistency. To address this issue, we propose the Autoformalizer with Tool Feedback (ATF), a novel approach that incorporates syntactic and consistency information as tools into the formalization process. By integrating Lean 4 compilers for syntax corrections and employing a multi-LLMs-as-judge approach for consistency validation, the model is able to adaptively refine generated statements according to the tool feedback, enhancing both syntactic validity and semantic consistency. The training of ATF involves a cold-start phase on synthetic tool-calling data, an expert iteration phase to improve formalization capabilities, and Direct Preference Optimization to alleviate ineffective revisions. Experimental results show that ATF markedly outperforms a range of baseline formalizer models, with its superior performance further validated by human evaluations. Subsequent analysis reveals that ATF demonstrates excellent inference scaling properties. Moreover, we open-source Numina-ATF, a dataset containing 750K synthetic formal statements to facilitate advancements in autoformalization and ATP research.', 'abstract_zh': '自动形式化通过将数学问题从自然语言翻译成形式化陈述来解决自动定理证明（ATP）中数据稀缺的问题。近年来的工作努力从直接提示大语言模型转变为从零开始训练端到端的形式化模型，取得了显著的进步。然而，现有的形式化模型仍然难以一贯生成符合语法有效性和语义一致性标准的有效陈述。为了解决这一问题，我们提出了一种新颖的方法——工具反馈自动形式化器（ATF），该方法将语法和一致性信息作为工具整合到形式化过程中。通过集成Lean 4编译器进行语法修正，并采用多LLM作为法官的方法进行一致性验证，模型可以根据工具反馈自适应地细化生成的陈述，从而增强语法有效性和语义一致性。ATF的训练包括一个基于合成工具调用数据的冷启动阶段、一个专家迭代阶段以提高形式化能力，以及直接偏好优化以缓解无效修订。实验结果表明，ATF显著优于多种基线形式化模型，其优越性进一步得到了人工评估的验证。后续分析显示，ATF表现出色的推理扩展性能。此外，我们开源了Numina-ATF数据集，包含750K个合成的形式化陈述，以促进自动形式化和自动定理证明研究。', 'title_zh': '自动形式化工具反馈系统'}
{'arxiv_id': 'arXiv:2510.06761', 'title': 'Evolving and Executing Research Plans via Double-Loop Multi-Agent Collaboration', 'authors': 'Zhi Zhang, Yan Liu, Zhejing Hu, Gong Chen, Sheng-hua Zhong, Jiannong Cao', 'link': 'https://arxiv.org/abs/2510.06761', 'abstract': 'Automating the end-to-end scientific research process poses a fundamental challenge: it requires both evolving high-level plans that are novel and sound, and executing these plans correctly amidst dynamic and uncertain conditions. To address this bilevel challenge, we propose a novel Double-Loop Multi-Agent (DLMA) framework to solve the given research problem automatically. The leader loop, composed of professor agents, is responsible for evolving research plans. It employs an evolutionary algorithm through involvement, improvement, and integration meetings to iteratively generate and refine a pool of research proposals, exploring the solution space effectively. The follower loop, composed of doctoral student agents, is responsible for executing the best-evolved plan. It dynamically adjusts the plan during implementation via pre-hoc and post-hoc meetings, ensuring each step (e.g., drafting, coding) is well-supported by contextual and external observations. Extensive experiments on benchmarks like ACLAward and Laboratory show that DLMA generates research papers that achieve state-of-the-art scores in automated evaluation, significantly outperforming strong baselines. Ablation studies confirm the critical roles of both loops, with evolution driving novelty and execution ensuring soundness.', 'abstract_zh': '自动化端到端科学研究过程面临根本性的挑战：它要求同时发展既新颖又稳健的高级计划，并在动态和不确定的条件下正确执行这些计划。为应对这一多层次挑战，我们提出了一种新型双环多智能体（DLMA）框架，以便自动解决给定的研究问题。领导环由教授智能体组成，负责演化研究计划。该环通过参与、改进和整合会议，采用进化算法迭代生成和细化研究提案池，有效探索解空间。跟随环由博士生智能体组成，负责执行最佳演化计划。该环在实施过程中通过预先和事后会议动态调整计划，确保每一步（例如，撰写、编码）都得到上下文和外部观察的支持。在ACLAward和实验室基准测试上的广泛实验表明，DLMA生成的研究论文在自动化评估中达到了最先进的得分，显著优于强大的基线。消融研究证实了两个环的至关重要的作用，演化推动了新颖性，执行确保了稳健性。', 'title_zh': '基于双环多代理协作的研究计划演进与执行'}
{'arxiv_id': 'arXiv:2510.06756', 'title': 'Verifying Memoryless Sequential Decision-making of Large Language Models', 'authors': 'Dennis Gross, Helge Spieker, Arnaud Gotlieb', 'link': 'https://arxiv.org/abs/2510.06756', 'abstract': "We introduce a tool for rigorous and automated verification of large language model (LLM)- based policies in memoryless sequential decision-making tasks. Given a Markov decision process (MDP) representing the sequential decision-making task, an LLM policy, and a safety requirement expressed as a PCTL formula, our approach incrementally constructs only the reachable portion of the MDP guided by the LLM's chosen actions. Each state is encoded as a natural language prompt, the LLM's response is parsed into an action, and reachable successor states by the policy are expanded. The resulting formal model is checked with Storm to determine whether the policy satisfies the specified safety property. In experiments on standard grid world benchmarks, we show that open source LLMs accessed via Ollama can be verified when deterministically seeded, but generally underperform deep reinforcement learning baselines. Our tool natively integrates with Ollama and supports PRISM-specified tasks, enabling continuous benchmarking in user-specified sequential decision-making tasks and laying a practical foundation for formally verifying increasingly capable LLMs.", 'abstract_zh': '我们介绍了一个工具，用于在无记忆顺序决策任务中对基于大型语言模型（LLM）的策略进行严格的自动化验证。给定一个表示顺序决策任务的马尔科夫决策过程（MDP）、一个LLM策略以及以PCTL公式表达的安全要求，我们的方法通过根据LLM选择的动作逐步构造MDP可达部分来验证策略。每个状态编码为自然语言提示，LLM的响应解析为动作，并展开策略可达的后继状态。最终形成的正式模型使用Storm进行检查，以确定策略是否满足指定的安全属性。在对标准网格世界基准的实验中，我们展示了通过Ollama访问的开源LLM在确定性初始化时可以进行验证，但总体上在深度强化学习基线方法下的表现较差。我们的工具原生支持与Ollama集成，并支持PRISM指定的任务，使得在用户指定的顺序决策任务中持续基准测试成为可能，并为正式验证日益强大的LLM奠定了实用基础。', 'title_zh': '验证大型语言模型的无记忆顺序决策'}
{'arxiv_id': 'arXiv:2510.06742', 'title': 'MultiCNKG: Integrating Cognitive Neuroscience, Gene, and Disease Knowledge Graphs Using Large Language Models', 'authors': 'Ali Sarabadani, Kheirolah Rahsepar Fard', 'link': 'https://arxiv.org/abs/2510.06742', 'abstract': 'The advent of large language models (LLMs) has revolutionized the integration of knowledge graphs (KGs) in biomedical and cognitive sciences, overcoming limitations in traditional machine learning methods for capturing intricate semantic links among genes, diseases, and cognitive processes. We introduce MultiCNKG, an innovative framework that merges three key knowledge sources: the Cognitive Neuroscience Knowledge Graph (CNKG) with 2.9K nodes and 4.3K edges across 9 node types and 20 edge types; Gene Ontology (GO) featuring 43K nodes and 75K edges in 3 node types and 4 edge types; and Disease Ontology (DO) comprising 11.2K nodes and 8.8K edges with 1 node type and 2 edge types. Leveraging LLMs like GPT-4, we conduct entity alignment, semantic similarity computation, and graph augmentation to create a cohesive KG that interconnects genetic mechanisms, neurological disorders, and cognitive functions. The resulting MultiCNKG encompasses 6.9K nodes across 5 types (e.g., Genes, Diseases, Cognitive Processes) and 11.3K edges spanning 7 types (e.g., Causes, Associated with, Regulates), facilitating a multi-layered view from molecular to behavioral domains. Assessments using metrics such as precision (85.20%), recall (87.30%), coverage (92.18%), graph consistency (82.50%), novelty detection (40.28%), and expert validation (89.50%) affirm its robustness and coherence. Link prediction evaluations with models like TransE (MR: 391, MRR: 0.411) and RotatE (MR: 263, MRR: 0.395) show competitive performance against benchmarks like FB15k-237 and WN18RR. This KG advances applications in personalized medicine, cognitive disorder diagnostics, and hypothesis formulation in cognitive neuroscience.', 'abstract_zh': '大型语言模型的出现颠覆了生物医学和认知科学中知识图谱的集成，克服了传统机器学习方法在捕捉基因、疾病和认知过程之间的复杂语义关系方面的局限性。我们提出了MultiCNKG，这是一种创新框架，融合了三个关键知识源：包含2900个节点和4300条边的神经认知知识图谱（CNKG），包含43000个节点和75000条边的基因本体（GO），以及包含11200个节点和8800条边的疾病本体（DO）。利用如GPT-4等大型语言模型，我们进行实体对齐、语义相似性计算和图增广，创建了一个整合遗传机制、神经疾病和认知功能的协同知识图谱。MultiCNKG包含6900个节点（例如，基因、疾病、认知过程）和11300条边（例如，因果关系、关联、调控），提供了从分子到行为领域的多层次视角。使用精确度（85.20%）、召回率（87.30%）、覆盖面（92.18%）、图一致性（82.50%）、新颖性检测（40.28%）和专家验证（89.50%）等指标的评估证实了其 robustness 和一致性。使用 TransE（MR: 391，MRR: 0.411）和 RotatE（MR: 263，MRR: 0.395）等模型的链接预测评估显示，其性能与 FB15k-237 和 WN18RR 等基准具有竞争力。该知识图谱推进了个性化医疗、认知疾病诊断和认知神经科学中的假设形成的应用。', 'title_zh': 'MultiCNKG: 结合认知神经科学、基因和疾病知识图谱的大语言模型方法'}
{'arxiv_id': 'arXiv:2510.06711', 'title': 'Inefficiencies of Meta Agents for Agent Design', 'authors': 'Batu El, Mert Yuksekgonul, James Zou', 'link': 'https://arxiv.org/abs/2510.06711', 'abstract': 'Recent works began to automate the design of agentic systems using meta-agents that propose and iteratively refine new agent architectures. In this paper, we examine three key challenges in a common class of meta-agents. First, we investigate how a meta-agent learns across iterations and find that simply expanding the context with all previous agents, as proposed by previous works, performs worse than ignoring prior designs entirely. We show that the performance improves with an evolutionary approach. Second, although the meta-agent designs multiple agents during training, it typically commits to a single agent at test time. We find that the designed agents have low behavioral diversity, limiting the potential for their complementary use. Third, we assess when automated design is economically viable. We find that only in a few cases--specifically, two datasets--the overall cost of designing and deploying the agents is lower than that of human-designed agents when deployed on over 15,000 examples. In contrast, the performance gains for other datasets do not justify the design cost, regardless of scale.', 'abstract_zh': '近期的工作已经开始使用元代理来自动设计有agency的系统，并通过迭代提出和优化新的代理架构。本文探究了常见类别的元代理中的三个关键挑战。首先，我们研究元代理在迭代中的学习过程，并发现简单地将所有先前代理的信息扩展到上下文中，如以往工作所提出的，不如完全忽略先前的设计表现更好。我们展示了一种进化的方法能够提升性能。其次，尽管在训练过程中元代理设计了多个代理，但在测试时通常只会采用一个。我们发现设计出的代理具有较低的行为多样性，限制了它们互补使用的潜力。第三，我们评估自动设计在经济上是否可行。我们发现仅在少数情况下——具体来说，两个数据集——自动设计和部署代理的成本低于人类设计的代理在超过15,000个实例上的部署成本。而对于其他数据集，性能收益并不足以抵消设计成本，无论规模如何。', 'title_zh': '元代理在代理设计中的低效率'}
{'arxiv_id': 'arXiv:2510.06674', 'title': 'Agent-in-the-Loop: A Data Flywheel for Continuous Improvement in LLM-based Customer Support', 'authors': 'Zhao, Tiantian Zhang, Hanchen Su, Yufeng, Zhang, Shaowei Su, Mingzhi Xu, Wei Han, Jeremy Werner, Claire Na Cheng, Yashar Mehdad', 'link': 'https://arxiv.org/abs/2510.06674', 'abstract': "We introduce an Agent-in-the-Loop (AITL) framework that implements a continuous data flywheel for iteratively improving an LLM-based customer support system. Unlike standard offline approaches that rely on batch annotations, AITL integrates four key types of annotations directly into live customer operations: (1) pairwise response preferences, (2) agent adoption and rationales, (3) knowledge relevance checks, and (4) identification of missing knowledge. These feedback signals seamlessly feed back into models' updates, reducing retraining cycles from months to weeks. Our production pilot involving US-based customer support agents demonstrated significant improvements in retrieval accuracy (+11.7% recall@75, +14.8% precision@8), generation quality (+8.4% helpfulness) and agent adoption rates (+4.5%). These results underscore the effectiveness of embedding human feedback loops directly into operational workflows to continuously refine LLM-based customer support system.", 'abstract_zh': '基于代理的循环回路框架：连续数据飞轮及其在迭代改进基于LLM的客户服务系统中的应用', 'title_zh': 'Agent-in-the-Loop: 一种基于数据飞轮的LLM客户支持连续改进方法'}
{'arxiv_id': 'arXiv:2510.06600', 'title': 'Fine-Grained Emotion Recognition via In-Context Learning', 'authors': 'Zhaochun Ren, Zhou Yang, Chenglong Ye, Haizhou Sun, Chao Chen, Xiaofei Zhu, Xiangwen Liao', 'link': 'https://arxiv.org/abs/2510.06600', 'abstract': 'Fine-grained emotion recognition aims to identify the emotional type in queries through reasoning and decision-making processes, playing a crucial role in various systems. Recent methods use In-Context Learning (ICL), enhancing the representation of queries in the reasoning process through semantically similar examples, while further improving emotion recognition by explaining the reasoning mechanisms. However, these methods enhance the reasoning process but overlook the decision-making process. This paper investigates decision-making in fine-grained emotion recognition through prototype theory. We show that ICL relies on similarity matching between query representations and emotional prototypes within the model, where emotion-accurate representations are critical. However, semantically similar examples often introduce emotional discrepancies, hindering accurate representations and causing errors. To address this, we propose Emotion In-Context Learning (EICL), which introduces emotionally similar examples and uses a dynamic soft-label strategy to improve query representations in the emotion reasoning process. A two-stage exclusion strategy is then employed to assess similarity from multiple angles, further optimizing the decision-making process. Extensive experiments show that EICL significantly outperforms ICL on multiple datasets.', 'abstract_zh': '细粒度情绪识别中的决策过程研究：基于原型理论的 emotion In-Context Learning', 'title_zh': '基于即席学习的细粒度情感识别'}
{'arxiv_id': 'arXiv:2510.06587', 'title': 'WebDART: Dynamic Decomposition and Re-planning for Complex Web Tasks', 'authors': 'Jingbo Yang, Bairu Hou, Wei Wei, Shiyu Chang, Yujia Bao', 'link': 'https://arxiv.org/abs/2510.06587', 'abstract': 'Large language model (LLM) agents are becoming competent at straightforward web tasks, such as opening an item page or submitting a form, but still struggle with objectives that require long horizon navigation, large scale information extraction, and reasoning under constraints. We present WebDART, a general framework that enables a single LLM to handle such complex chores. WebDART (i) dynamically decomposes each objective into three focused subtasks: navigation, information extraction, and execution, so the model concentrates on one skill at a time, and (ii) continuously replans the decomposition as new webpages are revealed, taking advantage of newly discovered filters or shortcuts and avoiding redundant exploration. Evaluated on WebChoreArena, WebDART lifts success rates by up to 13.7 percentage points over previous SOTA agents, while matching their performance on the easier WebArena suite and completing tasks with up to 14.7 fewer navigation steps.', 'abstract_zh': 'WebDART：一种通用框架，使大语言模型能够处理复杂的网络任务', 'title_zh': 'WebDART：动态分解与重新规划用于复杂Web任务'}
{'arxiv_id': 'arXiv:2510.06538', 'title': 'Auto-Prompt Ensemble for LLM Judge', 'authors': 'Jiajie Li, Huayi Zhang, Peng Lin, Jinjun Xiong, Wei Xu', 'link': 'https://arxiv.org/abs/2510.06538', 'abstract': 'We present a novel framework that improves the reliability of LLM judges by selectively augmenting LLM with auxiliary evaluation dimensions. Existing LLM judges often miss crucial evaluation dimensions because they fail to recognize the implicit standards underlying human assessments. To address this challenge, we propose the Auto-Prompt Ensemble (APE), an adaptive framework that automatically learns evaluation dimensions from its failure cases. APE incorporates a confidence-based ensemble mechanism to decide when to adopt the judgments from additional evaluation dimensions through a novel confidence estimation approach called Collective Confidence. Extensive experiments demonstrate that APE improves the reliability of LLM Judge across diverse standard benchmarks. For instance, APE enhances GPT-4o agreement rate on Reward Bench from 87.2% to 90.5% in the zero-shot setting. Overall, APE provides a principled approach for LLM Judge to leverage test-time computation, and bridge the evaluation gap between human and LLM judges.', 'abstract_zh': '我们提出了一种新型框架，通过选择性地为LLM添加辅助评估维度来提高LLM评估者的可靠性。现有的LLM评估者常常忽视关键的评估维度，因为他们未能识别出人类评估背后的隐含标准。为了解决这一挑战，我们提出了一种自适应框架Auto-Prompt Ensemble (APE)，该框架能够从其失败案例中自动学习评估维度。APE结合了一种基于置信度的集成机制，通过一种新颖的集体置信估计方法来决定何时采用附加评估维度的判断。广泛的经验表明，APE在多种标准基准上提高了LLM评估者的可靠性。例如，在零样本设置下，APE将GPT-4o在Reward Bench上的一致性率从87.2%提升到90.5%。总体而言，APE为LLM评估者提供了一种原理性的方法，利用测试时计算，并弥合人类与LLM评估者之间的评价差距。', 'title_zh': '自动提示ensemblefor大规模语言模型法官'}
{'arxiv_id': 'arXiv:2510.06534', 'title': 'Beneficial Reasoning Behaviors in Agentic Search and Effective Post-training to Obtain Them', 'authors': 'Jiahe Jin, Abhijay Paladugu, Chenyan Xiong', 'link': 'https://arxiv.org/abs/2510.06534', 'abstract': "Agentic search leverages large language models (LLMs) to interpret complex user information needs and execute a multi-step process of planning, searching, and synthesizing information to provide answers. This paradigm introduces unique challenges for LLMs' reasoning and agentic capabilities when interacting with retrieval systems and the broader web. In this paper, we propose a reasoning-driven LLM-based pipeline to study effective reasoning behavior patterns in agentic search. Using this pipeline, we analyze successful agentic search trajectories and identify four beneficial reasoning behaviors: Information Verification, Authority Evaluation, Adaptive Search, and Error Recovery. Based on these findings, we propose a technique called Behavior Priming to train more effective agentic search models. It synthesizes agentic search trajectories that exhibit these four behaviors and integrates them into the agentic search model through supervised fine-tuning (SFT), followed by standard reinforcement learning (RL). Experiments on three benchmarks (GAIA, WebWalker, and HLE) demonstrate that behavior priming yields over 35% gains in Llama3.2-3B and Qwen3-1.7B compared to directly training agentic search models with RL. Crucially, we demonstrate that the desired reasoning behaviors in the SFT data, rather than the correctness of the final answer, is the critical factor for achieving strong final performance after RL: fine-tuning on trajectories with desirable reasoning behaviors but incorrect answers leads to better performance than fine-tuning on trajectories with correct answers. Our analysis further reveals the underlying mechanism: the introduced reasoning behaviors endow models with more effective exploration (higher pass@k and entropy) and test-time scaling (longer trajectories) capabilities, providing a strong foundation for RL. Our code will be released as open source.", 'abstract_zh': '基于推理的大语言模型驱动的代理搜索管道：研究有效的代理搜索推理行为模式及其训练技术', 'title_zh': '代理搜索中的有益推理行为及有效后训练以获得这些行为'}
{'arxiv_id': 'arXiv:2510.06475', 'title': 'PuzzlePlex: Benchmarking Foundation Models on Reasoning and Planning with Puzzles', 'authors': 'Yitao Long, Yuru Jiang, Hongjun Liu, Yilun Zhao, Jingchen Sun, Yiqiu Shen, Chen Zhao, Arman Cohan, Dennis Shasha', 'link': 'https://arxiv.org/abs/2510.06475', 'abstract': 'This work investigates the reasoning and planning capabilities of foundation models and their scalability in complex, dynamic environments. We introduce PuzzlePlex, a benchmark designed to assess these capabilities through a diverse set of puzzles. PuzzlePlex consists of 15 types of puzzles, including deterministic and stochastic games of varying difficulty, as well as single-player and two-player scenarios. The PuzzlePlex framework provides a comprehensive environment for each game, and supports extensibility to generate more challenging instances as foundation models evolve. Additionally, we implement customized game-playing strategies for comparison. Building on this benchmark, we develop fine-grained metrics to measure performance and conduct an in-depth analysis of frontier foundation models across two settings: instruction-based and code-based. Furthermore, we systematically investigate their scaling limits. Our findings show that reasoning models outperform others in instruction-based settings, while code-based execution presents greater challenges but offers a scalable and efficient alternative. PuzzlePlex enables targeted evaluation and guides future improvements in reasoning, planning, and generalization for foundation models.', 'abstract_zh': '本研究探讨基础模型在复杂动态环境中的推理和规划能力及其可扩展性，并通过多样化的谜题提出了PuzzlePlex基准来评估这些能力。PuzzlePlex包含15种类型的不同难度的确定性和随机游戏，以及单人和双人场景。PuzzlePlex框架为每种游戏提供了综合环境，并支持扩展以生成更具有挑战性的实例，随着基础模型的发展。此外，我们还实现了定制的游戏策略进行比较。基于此基准，我们开发了细粒度的度量标准来衡量性能，并对基于指令和基于代码两种设置下的先进基础模型进行了深入分析。此外，我们系统地考察了它们的扩展极限。研究发现，在基于指令的设置中，推理模型表现优异，而基于代码的执行虽然更具挑战性，但提供了可扩展且高效的替代方案。PuzzlePlex实现有针对性的评估并指导基础模型在推理、规划和泛化方面的未来改进。', 'title_zh': 'PuzzlePlex：基于谜题的基石模型推理与规划基准测试'}
{'arxiv_id': 'arXiv:2510.06433', 'title': 'Flavonoid Fusion: Creating a Knowledge Graph to Unveil the Interplay Between Food and Health', 'authors': 'Aryan Singh Dalal, Yinglun Zhang, Duru Doğan, Atalay Mert İleri, Hande Küçük McGinty', 'link': 'https://arxiv.org/abs/2510.06433', 'abstract': 'The focus on "food as medicine" is gaining traction in the field of health and several studies conducted in the past few years discussed this aspect of food in the literature. However, very little research has been done on representing the relationship between food and health in a standardized, machine-readable format using a semantic web that can help us leverage this knowledge effectively. To address this gap, this study aims to create a knowledge graph to link food and health through the knowledge graph\'s ability to combine information from various platforms focusing on flavonoid contents of food found in the USDA databases and cancer connections found in the literature. We looked closely at these relationships using KNARM methodology and represented them in machine-operable format. The proposed knowledge graph serves as an example for researchers, enabling them to explore the complex interplay between dietary choices and disease management. Future work for this study involves expanding the scope of the knowledge graph by capturing nuances, adding more related data, and performing inferences on the acquired knowledge to uncover hidden relationships.', 'abstract_zh': '“食品作为药物”的关注在健康领域日益受到重视，近年来有多项研究在文献中探讨了食品与健康的这种关系。然而，鲜有研究利用语义网将食品与健康之间的关系标准化和机器可读化，以有效利用这些知识。为填补这一空白，本研究旨在通过知识图谱将食品和健康联结起来，重点关注美国农业部数据库中的食品黄酮含量以及文献中的癌症关联。我们使用KNARM方法仔细研究了这些关系，并将其以机器可操作的形式表示。所提出的知识图谱为研究人员提供了范例，使他们能够探索饮食选择与疾病管理之间的复杂相互作用。未来工作将扩大知识图谱的范围，捕捉更多细微差异，增加更多相关数据，并对获取的知识进行推理，以发现隐藏的关系。', 'title_zh': '黄酮融合：构建知识图谱以揭示食物与健康之间的互动'}
{'arxiv_id': 'arXiv:2510.06410', 'title': 'Off-Trajectory Reasoning: Can LLMs Collaborate on Reasoning Trajectory?', 'authors': 'Aochong Oliver Li, Tanya Goyal', 'link': 'https://arxiv.org/abs/2510.06410', 'abstract': 'Reasoning LLMs are trained to verbalize their reasoning process, yielding strong gains on complex tasks. This transparency also opens a promising direction: multiple reasoners can directly collaborate on each other\'s thinking within a shared trajectory, yielding better inference efficiency and exploration. A key prerequisite, however, is the ability to assess the usefulness and build on another model\'s partial thinking -- we call this off-trajectory reasoning. Our paper investigates a critical question: can standard solo-reasoning training pipelines deliver desired off-trajectory behaviors? We propose twin tests that capture the two extremes of the off-trajectory spectrum, namely Recoverability, which tests whether LLMs can backtrack from "distractions" induced by misleading reasoning traces, and Guidability, which tests their ability to build upon correct reasoning from stronger collaborators. Our study evaluates 15 open-weight LLMs (1.5B-32B) and reveals a counterintuitive finding -- "stronger" LLMs on benchmarks are often more fragile under distraction. Moreover, all models tested fail to effectively leverage guiding steps from collaborators on problems beyond their inherent capabilities with solve rates remaining under 9.2%. Finally, we conduct control studies to isolate the effects of three factors in post-training on these behaviors: the choice of distillation teacher, the use of RL, and data selection strategy. Our results provide actionable insights for training natively strong reasoning collaborators; e.g., we find that suboptimal recoverability behaviors of teacher models are transferred to distilled students even if the distillation trajectories are correct. Taken together, this work lays the groundwork for evaluating multi-model collaborations in shared reasoning trajectories and highlights the limitations of off-the-shelf reasoning LLMs.', 'abstract_zh': '基于链路推理的透明性，LLMs被训练以 verbalize 其推理过程，从而在复杂任务上获得显著提升。这种透明性也为一个多推理器在共享轨迹上直接协作打开了新局面，从而提高推理效率和探索能力。然而，一个关键前提是对另一个模型部分推理的有效评估和利用能力——我们称之为离轨推理。本文探讨了一个关键问题：标准的单推理训练流程能否产生所需的离轨行为？我们提出了两种捕捉离轨推理光谱两端极端情况的测试方法：恢复性测试，检验LLMs能否从误导性推理痕迹引发的“偏离”中恢复；引导性测试，检验其利用更强合作伙伴正确推理构建的能力。我们的研究评估了15种开源权重LLM（1.5B-32B），揭示了一个反常识的发现——在基准测试中表现出优越性的LLM在面对误导性推理痕迹时往往更加脆弱。此外，所有测试的模型在外在能力范围之外的问题上未能有效利用合作者的引导步，解决率低于9.2%。最后，我们进行了控制实验，以分离这些行为在后续训练中受三个因素影响的效果：蒸馏教师的选择，使用RL，和数据选择策略。我们的研究成果为训练先天性强的推理合作者提供了可操作的见解；例如，我们发现，即使蒸馏轨迹是正确的，教师模型表现不佳的恢复行为也会传递给受蒸馏的学生模型。综上所述，这项工作为评估多模型在共享推理轨迹上的合作奠定了基础，并突显了现成推理LLM的局限性。', 'title_zh': '离轨推理：大规模语言模型能否协作进行推理轨迹？'}
{'arxiv_id': 'arXiv:2510.06307', 'title': 'Belief-Calibrated Multi-Agent Consensus Seeking for Complex NLP Tasks', 'authors': 'Wentao Deng, Jiahuan Pei, Zhiwei Xu, Zhaochun Ren, Zhumin Chen, Pengjie Ren', 'link': 'https://arxiv.org/abs/2510.06307', 'abstract': 'A multi-agent system (MAS) enhances its capacity to solve complex natural language processing (NLP) tasks through collaboration among multiple agents, where consensus-seeking serves as a fundamental mechanism. However, existing consensus-seeking approaches typically rely on voting mechanisms to judge consensus, overlooking contradictions in system-internal beliefs that destabilize the consensus. Moreover, these methods often involve agents updating their results through indiscriminate collaboration with every other agent. Such uniform interaction fails to identify the optimal collaborators for each agent, hindering the emergence of a stable consensus. To address these challenges, we provide a theoretical framework for selecting optimal collaborators that maximize consensus stability. Based on the theorems, we propose the Belief-Calibrated Consensus Seeking (BCCS) framework to facilitate stable consensus via selecting optimal collaborators and calibrating the consensus judgment by system-internal beliefs. Experimental results on the MATH and MMLU benchmark datasets demonstrate that the proposed BCCS framework outperforms the best existing results by 2.23% and 3.95% of accuracy on challenging tasks, respectively. Our code and data are available at this https URL.', 'abstract_zh': '一种多agent系统（MAS）通过多个agent间的合作提升解决复杂自然语言处理（NLP）任务的能力，其中共识寻求是基本机制。然而，现有的共识寻求方法通常依赖投票机制来判断共识，忽视了系统内部信念之间的矛盾，这种矛盾会瓦解共识。此外，这些方法经常要求agents无差别地与每个其他agent合作更新结果，这种一致的交互方式无法识别出最适合每个agent的合作对象，阻碍了稳定共识的形成。为解决这些问题，我们提供了一个理论框架，用于选择能够最大化共识稳定性的最佳合作对象。基于该理论框架，我们提出Belief-Calibrated Consensus Seeking (BCCS)框架，通过选择最佳合作对象和通过系统内部信念校准共识判断来促进稳定共识的形成。在MATH和MMLU基准数据集上的实验结果表明，提出的BCCS框架在挑战性任务上的准确率分别优于现有最佳结果2.23%和3.95%。我们的代码和数据可在以下链接获取。', 'title_zh': '信念校准的多Agent共识求取方法及其在复杂NLP任务中的应用'}
{'arxiv_id': 'arXiv:2510.06302', 'title': 'Requirements for Game-Based Learning Design Framework for Information System Integration in the Context of Post-Merger Integration', 'authors': 'Ksenija Lace, Marite Kirikova', 'link': 'https://arxiv.org/abs/2510.06302', 'abstract': 'Post-merger integration states unique challenges for professionals responsible for information system integration aimed on alignment and combination diverse system architectures of merging organizations. Although the theoretical and practical guidance exists for post-merger integration on the business level, there is a significant gap in training for information system integration in this context. In prior research specific methods AMILI (Support method for informed decision identification) and AMILP (Support method for informed decision-making) were introduced for the support of information system integration decisions in the post-merger integration. But during the practical application was reported high learning curve and low learner motivation. This paper explores how game-based learning design can address these limitations by transforming static method training into engaging learning experience. The study analyzes foundational learning theories, cognitive load and motivation models, and serious game design frameworks to identify the essential requirements for a game-based learning design framework tailored to information system integration in post-merger integration. Requirements are structured in two components: the transformation process and resulting learning experience. The paper concludes with a plan for developing and evaluating the proposed framework through iterative design and real-world validation.', 'abstract_zh': '并购后集成状态为负责信息系统集成的专业人士带来了独特挑战，旨在实现合并组织异构系统架构的整合与对齐。尽管在业务层面已经存在并购后的集成理论和实践指导，但在信息系统集成培训方面仍存在显著差距。前期研究介绍了AMILI（支持明智决策识别的方法）和AMILP（支持明智决策制定的方法）等特定方法，用于并购后集成中的信息系统集成决策支持。但在实际应用中报告了较高的学习曲线和较低的学习动机。本文探讨了基于游戏的学习设计如何通过将静态方法培训转化为沉浸式学习体验来解决这些问题。研究分析了基础学习理论、认知负荷和动机模型以及严肃游戏设计框架，以确定适合并购后集成信息系统集成的游戏化学习设计框架的必要要求。要求分为两个组成部分：转化过程和学习体验。本文以迭代设计和现实世界验证为基础，提出框架的发展和评估计划。', 'title_zh': '基于游戏化学习设计框架的信息系统集成在合并后集成的背景下要求'}
{'arxiv_id': 'arXiv:2510.06288', 'title': 'BuilderBench -- A benchmark for generalist agents', 'authors': 'Raj Ghugare, Catherine Ji, Kathryn Wantlin, Jin Schofield, Benjamin Eysenbach', 'link': 'https://arxiv.org/abs/2510.06288', 'abstract': "Today's AI models learn primarily through mimicry and sharpening, so it is not surprising that they struggle to solve problems beyond the limits set by existing data. To solve novel problems, agents should acquire skills for exploring and learning through experience. Finding a scalable learning mechanism for developing agents that learn through interaction remains a major open problem. In this work, we introduce BuilderBench, a benchmark to accelerate research into agent pre-training that centers open-ended exploration. BuilderBench requires agents to learn how to build any structure using blocks. BuilderBench is equipped with $(1)$ a hardware accelerated simulator of a robotic agent interacting with various physical blocks, and $(2)$ a task-suite with over 42 diverse target structures that are carefully curated to test an understanding of physics, mathematics, and long-horizon planning. During training, agents have to explore and learn general principles about the environment without any external supervision. During evaluation, agents have to build the unseen target structures from the task suite. Solving these tasks requires a sort of \\emph{embodied reasoning} that is not reflected in words but rather in actions, experimenting with different strategies and piecing them together. Our experiments show that many of these tasks challenge the current iteration of algorithms. Hence, we also provide a ``training wheels'' protocol, in which agents are trained and evaluated to build a single target structure from the task suite. Finally, we provide single-file implementations of six different algorithms as a reference point for researchers.", 'abstract_zh': '今天的AI模型主要通过模仿和精炼来学习，因此它们难以解决超出现有数据限制的问题也就不足为奇了。为了解决新型问题，代理应该获得通过经验探索和学习的技能。寻找一种可扩展的学习机制来培养通过互动学习的代理仍然是一个主要开放问题。在本工作中，我们介绍了BuilderBench这一基准，以加速专注于开放式探索的代理预训练研究。BuilderBench要求代理学习如何使用积木构建任何结构。（1）配备硬件加速的机器人代理与各种物理积木交互的模拟器；（2）包含超过42个精心筛选的多样化目标结构的任务套件，用于测试对物理、数学和远期规划的理解。在训练阶段，代理需要在没有外部监督的情况下探索和学习关于环境的一般原则。在评估阶段，代理需要从任务套件中构建未见过的目标结构。解决这些任务需要一种体现在行动中的“具身推理”，而不仅仅是语言。我们的实验表明，这些任务挑战了当前算法的迭代。因此，我们还提供了一个“训练轮”协议，其中代理被训练和评估以构建任务套件中的单个目标结构。最后，我们提供了六种不同算法的单文件实现，以供研究人员参考。', 'title_zh': 'BuilderBench —— 通用型代理的基准测试'}
{'arxiv_id': 'arXiv:2510.06274', 'title': 'Bridging Reasoning to Learning: Unmasking Illusions using Complexity Out of Distribution Generalization', 'authors': 'Mohammad Mahdi Samiei Paqaleh, Arash Marioriyad, Arman Tahmasebi-Zadeh, Mohamadreza Fereydooni, Mahdi Ghaznavai, Mahdieh Soleymani Baghshah', 'link': 'https://arxiv.org/abs/2510.06274', 'abstract': 'Recent progress has pushed AI frontiers from pattern recognition tasks toward problems that require step by step, System2 style reasoning, especially with large language models. Yet, unlike learning, where generalization and out of distribution (OoD) evaluation concepts are well formalized, there is no clear, consistent definition or metric for reasoning ability. We propose Complexity Out of Distribution (Complexity OoD) generalization as a framework and problem setting to define and measure reasoning. A model exhibits Complexity OoD generalization when it maintains performance on test instances whose minimal required solution complexity, either representational (richer solution structure) or computational (more reasoning steps/program length), exceeds that of all training examples. We formalize complexity via solution description Kolmogorov complexity and operational proxies (e.g., object/relation counts; reasoning step counts), clarifying how Complexity OoD differs from length and compositional OoD. This lens unifies learning and reasoning: many cases solvable with System1 like processing at low complexity become System2 like under complexity pressure, while System2 can be viewed as generalization over solution structures. We translate this perspective into practice with recommendations for operationalizing Complexity OoD across the stack: incorporating complexity into benchmark and evaluation metric design, rethinking supervision to target solution traces, seeking and designing inductive biases for Complexity OoD generalization, addressing learning to reason spillovers such as spurious shortcuts, semantic robustness, catastrophic forgetting, and step wise calibration. Because Complexity OoD cannot be solved by scaling data alone, progress toward robust reasoning will require architectures and training regimes that explicitly model and allocate computation with respect to complexity.', 'abstract_zh': 'Recent进展推动AI从模式识别任务向需要逐步、System2风格推理的问题发展，尤其是大型语言模型的应用。然而，与学习领域中泛化和分布外（OoD）评估概念的明确规范不同，推理能力尚无清晰且一致的定义或度量标准。我们提出复杂性分布外（Complexity OoD）泛化作为一种框架和问题设定，以定义和度量推理能力。当模型在测试实例上保持高性能，这些实例的最小必要解决方案复杂度（无论是表示性的，即更丰富的解构，还是计算性的，即更多推理步骤/程序长度）超过了所有训练样本复杂度时，模型表现出复杂性分布外泛化。我们通过解决方案描述的 Kolmogorov 复杂性和操作代理（例如，对象/关系计数；推理步骤计数）来正式化复杂性，阐明复杂性分布外与长度和组合性分布外之间的区别。这一视角将学习与推理统一起来：许多用System1风格低复杂度处理可解的问题在复杂度压力下转变为System2风格的问题，而System2可以被视作对解构的泛化。我们将这种视角落实到实践中，提出复杂性分布外的操作化建议：将复杂性纳入基准和评估指标的设计，重新思考监督以瞄准解决方案轨迹，寻求和设计促进复杂性分布外泛化的归纳偏置，解决推理学习溢出问题如虚假捷径、语义鲁棒性、灾难性遗忘和逐步校准。由于复杂性分布外泛化单单通过扩大数据规模无法解决，因此实现稳健推理的进展需要构建和训练能够显式建模和分配与复杂性相关的计算的架构和训练制度。', 'title_zh': '打通推理与学习的桥梁：通过分布外泛化揭露幻象'}
{'arxiv_id': 'arXiv:2510.06261', 'title': 'AlphaApollo: Orchestrating Foundation Models and Professional Tools into a Self-Evolving System for Deep Agentic Reasoning', 'authors': 'Zhanke Zhou, Chentao Cao, Xiao Feng, Xuan Li, Zongze Li, Xiangyu Lu, Jiangchao Yao, Weikai Huang, Linrui Xu, Tian Cheng, Guanyu Jiang, Yiming Zheng, Brando Miranda, Tongliang Liu, Sanmi Koyejo, Masashi Sugiyama, Bo Han', 'link': 'https://arxiv.org/abs/2510.06261', 'abstract': 'We present AlphaApollo, a self-evolving agentic reasoning system that aims to address two bottlenecks in foundation model (FM) reasoning-limited model-intrinsic capacity and unreliable test-time iteration. AlphaApollo orchestrates multiple models with professional tools to enable deliberate, verifiable reasoning. It couples (i) a computation tool (Python with numerical and symbolic libraries) and (ii) a retrieval tool (task-relevant external information) to execute exact calculations and ground decisions. The system further supports multi-round, multi-model solution evolution via a shared state map that records candidates, executable checks, and feedback for iterative refinement. In evaluations on AIME 2024/2025 across multiple models, AlphaApollo delivers consistent gains: +5.15% Average@32 and +23.34% Pass@32 for Qwen2.5-14B-Instruct, and +8.91% Average@32 with +26.67% Pass@32 for Llama-3.3-70B-Instruct. Tool-use analysis shows that more than 80% of tool calls are successfully executed, with consistent outperformance of non-tool baselines, thereby lifting the capability ceiling of FMs. More empirical results and implementation details will be updated at this https URL.', 'abstract_zh': 'AlphaApollo：一种自演进代理推理系统，旨在解决基础模型推理中的模型固有容量限制和测试时迭代不可靠性问题', 'title_zh': 'AlphaApollo: 将基础模型和专业工具 orchestrating 成一个自 evolution 系统以促进深度自主推理'}
{'arxiv_id': 'arXiv:2510.07318', 'title': 'Artificial Hippocampus Networks for Efficient Long-Context Modeling', 'authors': 'Yunhao Fang, Weihao Yu, Shu Zhong, Qinghao Ye, Xuehan Xiong, Lai Wei', 'link': 'https://arxiv.org/abs/2510.07318', 'abstract': "Long-sequence modeling faces a fundamental trade-off between the efficiency of compressive fixed-size memory in RNN-like models and the fidelity of lossless growing memory in attention-based Transformers. Inspired by the Multi-Store Model in cognitive science, we introduce a memory framework of artificial neural networks. Our method maintains a sliding window of the Transformer's KV cache as lossless short-term memory, while a learnable module termed Artificial Hippocampus Network (AHN) recurrently compresses out-of-window information into a fixed-size compact long-term memory. To validate this framework, we instantiate AHNs using modern RNN-like architectures, including Mamba2, DeltaNet, and Gated DeltaNet. Extensive experiments on long-context benchmarks LV-Eval and InfiniteBench demonstrate that AHN-augmented models consistently outperform sliding window baselines and achieve performance comparable or even superior to full-attention models, while substantially reducing computational and memory requirements. For instance, augmenting the Qwen2.5-3B-Instruct with AHNs reduces inference FLOPs by 40.5% and memory cache by 74.0%, while improving its average score on LV-Eval (128k sequence length) from 4.41 to 5.88. Code is available at: this https URL.", 'abstract_zh': 'Long-sequence Modeling Faces a Fundamental Trade-off Between the Efficiency of Compressive Fixed-size Memory in RNN-like Models and the Fidelity of Lossless Growing Memory in Attention-based Transformers: Inspired by the Multi-Store Model in Cognitive Science, We Introduce a Memory Framework for Artificial Neural Networks', 'title_zh': '人工海马网络用于高效长上下文建模'}
{'arxiv_id': 'arXiv:2510.07315', 'title': 'Vibe Checker: Aligning Code Evaluation with Human Preference', 'authors': 'Ming Zhong, Xiang Zhou, Ting-Yun Chang, Qingze Wang, Nan Xu, Xiance Si, Dan Garrette, Shyam Upadhyay, Jeremiah Liu, Jiawei Han, Benoit Schillings, Jiao Sun', 'link': 'https://arxiv.org/abs/2510.07315', 'abstract': "Large Language Models (LLMs) have catalyzed vibe coding, where users leverage LLMs to generate and iteratively refine code through natural language interactions until it passes their vibe check. Vibe check is tied to real-world human preference and goes beyond functionality: the solution should feel right, read cleanly, preserve intent, and remain correct. However, current code evaluation remains anchored to pass@k and captures only functional correctness, overlooking the non-functional instructions that users routinely apply. In this paper, we hypothesize that instruction following is the missing piece underlying vibe check that represents human preference in coding besides functional correctness. To quantify models' code instruction following capabilities with measurable signals, we present VeriCode, a taxonomy of 30 verifiable code instructions together with corresponding deterministic verifiers. We use the taxonomy to augment established evaluation suites, resulting in Vibe Checker, a testbed to assess both code instruction following and functional correctness. Upon evaluating 31 leading LLMs, we show that even the strongest models struggle to comply with multiple instructions and exhibit clear functional regression. Most importantly, a composite score of functional correctness and instruction following correlates the best with human preference, with the latter emerging as the primary differentiator on real-world programming tasks. Our work identifies core factors of the vibe check, providing a concrete path for benchmarking and developing models that better align with user preferences in coding.", 'abstract_zh': '大型语言模型（LLMs）促进了情绪编码，用户通过自然语言互动利用LLMs生成并迭代 refining 代码，直至通过其情绪检查。情绪检查与现实世界的人类偏好相关，并超越了功能性：解决方案应感觉正确、读起来清爽、保持意图并保持正确。然而，当前的代码评估仍然局限于功能正确的通过率指标，忽略了用户常规应用的非功能性指令。在本文中，我们假设指令遵循是情绪检查背后的关键环节，情绪检查代表了编码中除功能性正确性之外的人类偏好。为量化模型的代码指令遵循能力并使用可量化的信号，我们提出了VeriCode，一种包含30条可验证代码指令及其相应确定性验证器的分类体系。我们使用分类体系扩展了现有的评估套件，从而得到Vibe Checker测试床，用于评估代码指令遵循和功能性正确性。通过对31个领先的大规模语言模型的评估，我们表明，即使是最强大的模型也难以遵守多个指令，并且表现出明显的功能性退化。最重要的是，功能性正确性和指令遵循的综合评分与人类偏好关联最强，后者成为了衡量现实世界编程任务的主要差异因子。我们的工作识别了情绪检查的核心因素，为基准测试和开发更好地符合用户编码偏好的模型提供了具体路径。', 'title_zh': '代码评审器：使代码评估符合人类偏好'}
{'arxiv_id': 'arXiv:2510.07314', 'title': 'GyroSwin: 5D Surrogates for Gyrokinetic Plasma Turbulence Simulations', 'authors': 'Fabian Paischer, Gianluca Galletti, William Hornsby, Paul Setinek, Lorenzo Zanisi, Naomi Carey, Stanislas Pamela, Johannes Brandstetter', 'link': 'https://arxiv.org/abs/2510.07314', 'abstract': 'Nuclear fusion plays a pivotal role in the quest for reliable and sustainable energy production. A major roadblock to viable fusion power is understanding plasma turbulence, which significantly impairs plasma confinement, and is vital for next-generation reactor design. Plasma turbulence is governed by the nonlinear gyrokinetic equation, which evolves a 5D distribution function over time. Due to its high computational cost, reduced-order models are often employed in practice to approximate turbulent transport of energy. However, they omit nonlinear effects unique to the full 5D dynamics. To tackle this, we introduce GyroSwin, the first scalable 5D neural surrogate that can model 5D nonlinear gyrokinetic simulations, thereby capturing the physical phenomena neglected by reduced models, while providing accurate estimates of turbulent heat this http URL (i) extends hierarchical Vision Transformers to 5D, (ii) introduces cross-attention and integration modules for latent 3D$\\leftrightarrow$5D interactions between electrostatic potential fields and the distribution function, and (iii) performs channelwise mode separation inspired by nonlinear physics. We demonstrate that GyroSwin outperforms widely used reduced numerics on heat flux prediction, captures the turbulent energy cascade, and reduces the cost of fully resolved nonlinear gyrokinetics by three orders of magnitude while remaining physically verifiable. GyroSwin shows promising scaling laws, tested up to one billion parameters, paving the way for scalable neural surrogates for gyrokinetic simulations of plasma turbulence.', 'abstract_zh': '核聚合成 Reliable 和可持续能源生产的关键。克服核聚变电源可行性的主要障碍是理解等离子体湍流，这显著影响等离子体约束，并对于下一代反应堆设计至关重要。等离子体湍流由非线性陀螺波动方程支配，该方程随时间演化5D分布函数。由于计算成本高，实践中经常使用降阶模型来近似湍流的能量传输。然而，这些模型忽略了5D动态独有的非线性效应。为了解决这个问题，我们引入了GyroSwin，这是第一个可扩展的5D神经拟合模型，能够模拟5D非线性陀螺波动模拟，从而捕获被降阶模型忽略的物理现象，同时提供湍流热流的准确估计。GyroSwin通过以下方式实现：(i) 将分层视觉变压器扩展至5D，(ii) 引入交叉注意力和整合模块以处理静电势场与分布函数之间的3D$\\leftrightarrow$5D潜在相互作用，(iii) 借鉴非线性物理学进行通道内模式分离。实验表明，GyroSwin在热流预测方面优于广泛使用的降阶数值方法，捕捉到湍流能量 cascade，并将完全解析的非线性陀螺波动动力学的成本降低了三个数量级以上，同时保持物理可验证性。GyroSwin显示出有前途的标度律，测试参数规模达到十亿级，为可扩展的陀螺波动模拟神经拟合铺平了道路。', 'title_zh': 'GyroSwin: 5D 代替模型用于磁约束等离子体涡流模拟'}
{'arxiv_id': 'arXiv:2510.07312', 'title': 'h1: Bootstrapping LLMs to Reason over Longer Horizons via Reinforcement Learning', 'authors': 'Sumeet Ramesh Motwani, Alesia Ivanova, Ziyang Cai, Philip Torr, Riashat Islam, Shital Shah, Christian Schroeder de Witt, Charles London', 'link': 'https://arxiv.org/abs/2510.07312', 'abstract': 'Large language models excel at short-horizon reasoning tasks, but performance drops as reasoning horizon lengths increase. Existing approaches to combat this rely on inference-time scaffolding or costly step-level supervision, neither of which scales easily. In this work, we introduce a scalable method to bootstrap long-horizon reasoning capabilities using only existing, abundant short-horizon data. Our approach synthetically composes simple problems into complex, multi-step dependency chains of arbitrary length. We train models on this data using outcome-only rewards under a curriculum that automatically increases in complexity, allowing RL training to be scaled much further without saturating. Empirically, our method generalizes remarkably well: curriculum training on composed 6th-grade level math problems (GSM8K) boosts accuracy on longer, competition-level benchmarks (GSM-Symbolic, MATH-500, AIME) by up to 2.06x. Importantly, our long-horizon improvements are significantly higher than baselines even at high pass@k, showing that models can learn new reasoning paths under RL. Theoretically, we show that curriculum RL with outcome rewards achieves an exponential improvement in sample complexity over full-horizon training, providing training signal comparable to dense supervision. h1 therefore introduces an efficient path towards scaling RL for long-horizon problems using only existing data.', 'abstract_zh': '大规模语言模型在短视推理任务中表现出色，但随着推理视窗长度增加，性能下降。现有方法依赖于推理时的支架或昂贵的逐步骤监督，这两种方法都不容易扩展。在这种工作中，我们介绍了一种仅使用现有丰富短视数据来逐步增强长视窗推理能力的可扩展方法。我们的方法合成简单问题为任意长度的复杂多步依赖链。通过仅基于结果的奖励，在自适应增加复杂性的课程训练下训练模型，使得基于强化学习的训练能够大幅扩展而不会饱和。实验证明，我们的方法泛化效果出色：在合成的六年级水平数学问题（GSM8K）上进行课程训练，显著提高了更长、更高级基准（GSM-Symbolic、MATH-500、AIME）上的准确性最多2.06倍。重要的是，即使在高通过率下，我们的长视窗改进也显著高于基线，表明模型可以在强化学习下学习新的推理路径。理论上，我们证明了仅基于结果回报的课程训练在样本复杂性上实现了指数级改进，提供的训练信号与密集监督相当。因此，h1引入了一种仅使用现有数据扩展强化学习以应对长视窗问题的有效途径。', 'title_zh': '通过强化学习]){\r\nH1: 通过强化学习将LLMs扩展到更长的时间 horizon 上进行推理'}
{'arxiv_id': 'arXiv:2510.07307', 'title': 'MLE-Smith: Scaling MLE Tasks with Automated Multi-Agent Pipeline', 'authors': 'Rushi Qiang, Yuchen Zhuang, Anikait Singh, Percy Liang, Chao Zhang, Sherry Yang, Bo Dai', 'link': 'https://arxiv.org/abs/2510.07307', 'abstract': 'While Language Models (LMs) have made significant progress in automating machine learning engineering (MLE), the acquisition of high-quality MLE training data is significantly constrained. Current MLE benchmarks suffer from low scalability and limited applicability because they rely on static, manually curated tasks, demanding extensive time and manual effort to produce. We introduce MLE-Smith, a fully automated multi-agent pipeline, to transform raw datasets into competition-style MLE challenges through an efficient generate-verify-execute paradigm for scaling MLE tasks with verifiable quality, real-world usability, and rich diversity. The proposed multi-agent pipeline in MLE-Smith drives structured task design and standardized refactoring, coupled with a hybrid verification mechanism that enforces strict structural rules and high-level semantic soundness. It further validates empirical solvability and real-world fidelity through interactive execution. We apply MLE-Smith to 224 of real-world datasets and generate 606 tasks spanning multiple categories, objectives, and modalities, demonstrating that MLE-Smith can work effectively across a wide range of real-world datasets. Evaluation on the generated tasks shows that the performance of eight mainstream and cutting-edge LLMs on MLE-Smith tasks is strongly correlated with their performance on carefully human-designed tasks, highlighting the effectiveness of the MLE-Smith to scaling up MLE tasks, while maintaining task quality.', 'abstract_zh': '语言模型在自动化机器学习工程中的进展受限于高质量训练数据的获取。当前的机器学习工程基准因依赖静态的手动整理任务而缺乏可扩展性和适用性，需要大量时间和手动努力来生成。我们引入了MLE-Smith，这是一种完全自动化的多智能体流水线，通过高效生成-验证-执行范式将原始数据集转换为具有可验证质量、实际可用性和丰富多样性的竞赛风格的机器学习工程挑战。MLE-Smith中的提议多智能体流水线推动了结构化任务设计和标准化重构，并结合了一种混合验证机制，该机制强制执行严格的结构规则和高层次语义正确性。进一步通过交互执行验证其实证可解决性和现实世界的真实性。我们应用MLE-Smith处理了224个真实世界数据集并生成了涵盖多个类别、目标和模态的606个任务，证明了MLE-Smith可以在广泛的真实世界数据集上有效工作。对生成任务的评估表明，主流和前沿的语言模型在MLE-Smith任务上的性能与精心设计的人工任务上的性能之间高度相关，突显了MLE-Smith在扩展机器学习工程任务方面的有效性，同时保持任务质量。', 'title_zh': 'MLE-Smith: 通过自动化多智能体管道扩展MLE任务'}
{'arxiv_id': 'arXiv:2510.07304', 'title': 'Cocoon: A System Architecture for Differentially Private Training with Correlated Noises', 'authors': 'Donghwan Kim, Xin Gu, Jinho Baek, Timothy Lo, Younghoon Min, Kwangsik Shin, Jongryool Kim, Jongse Park, Kiwan Maeng', 'link': 'https://arxiv.org/abs/2510.07304', 'abstract': 'Machine learning (ML) models memorize and leak training data, causing serious privacy issues to data owners. Training algorithms with differential privacy (DP), such as DP-SGD, have been gaining attention as a solution. However, DP-SGD adds a noise at each training iteration, which degrades the accuracy of the trained model. To improve accuracy, a new family of approaches adds carefully designed correlated noises, so that noises cancel out each other across iterations. We performed an extensive characterization study of these new mechanisms, for the first time to the best of our knowledge, and show they incur non-negligible overheads when the model is large or uses large embedding tables. Motivated by the analysis, we propose Cocoon, a hardware-software co-designed framework for efficient training with correlated noises. Cocoon accelerates models with embedding tables through pre-computing and storing correlated noises in a coalesced format (Cocoon-Emb), and supports large models through a custom near-memory processing device (Cocoon-NMP). On a real system with an FPGA-based NMP device prototype, Cocoon improves the performance by 2.33-10.82x(Cocoon-Emb) and 1.55-3.06x (Cocoon-NMP).', 'abstract_zh': '基于相关噪声的硬件软件协同设计框架Cocoon：高效训练与隐私保护', 'title_zh': '茧：一种支持相关噪音下差异隐私训练的系统架构'}
{'arxiv_id': 'arXiv:2510.07293', 'title': 'AudioMarathon: A Comprehensive Benchmark for Long-Context Audio Understanding and Efficiency in Audio LLMs', 'authors': 'Peize He, Zichen Wen, Yubo Wang, Yuxuan Wang, Xiaoqian Liu, Jiajie Huang, Zehui Lei, Zhuangcheng Gu, Xiangqi Jin, Jiabing Yang, Kai Li, Zhifei Liu, Weijia Li, Cunxiang Wang, Conghui He, Linfeng Zhang', 'link': 'https://arxiv.org/abs/2510.07293', 'abstract': 'Processing long-form audio is a major challenge for Large Audio Language models (LALMs). These models struggle with the quadratic cost of attention ($O(N^2)$) and with modeling long-range temporal dependencies. Existing audio benchmarks are built mostly from short clips and do not evaluate models in realistic long context settings. To address this gap, we introduce AudioMarathon, a benchmark designed to evaluate both understanding and inference efficiency on long-form audio. AudioMarathon provides a diverse set of tasks built upon three pillars: long-context audio inputs with durations ranging from 90.0 to 300.0 seconds, which correspond to encoded sequences of 2,250 to 7,500 audio tokens, respectively, full domain coverage across speech, sound, and music, and complex reasoning that requires multi-hop inference. We evaluate state-of-the-art LALMs and observe clear performance drops as audio length grows. We also study acceleration techniques and analyze the trade-offs of token pruning and KV cache eviction. The results show large gaps across current LALMs and highlight the need for better temporal reasoning and memory-efficient architectures. We believe AudioMarathon will drive the audio and multimodal research community to develop more advanced audio understanding models capable of solving complex audio tasks.', 'abstract_zh': '处理长格式音频是大型音频语言模型(LALMs)面临的重大挑战。AudioMarathon：一个用于评估长格式音频上的理解能力和推理效率的基准', 'title_zh': 'AudioMarathon: 长上下文音频理解与音频LLMs效率的综合基准'}
{'arxiv_id': 'arXiv:2510.07286', 'title': 'Evolutionary Profiles for Protein Fitness Prediction', 'authors': 'Jigang Fan, Xiaoran Jiao, Shengdong Lin, Zhanming Liang, Weian Mao, Chenchen Jing, Hao Chen, Chunhua Shen', 'link': 'https://arxiv.org/abs/2510.07286', 'abstract': 'Predicting the fitness impact of mutations is central to protein engineering but constrained by limited assays relative to the size of sequence space. Protein language models (pLMs) trained with masked language modeling (MLM) exhibit strong zero-shot fitness prediction; we provide a unifying view by interpreting natural evolution as implicit reward maximization and MLM as inverse reinforcement learning (IRL), in which extant sequences act as expert demonstrations and pLM log-odds serve as fitness estimates. Building on this perspective, we introduce EvoIF, a lightweight model that integrates two complementary sources of evolutionary signal: (i) within-family profiles from retrieved homologs and (ii) cross-family structural-evolutionary constraints distilled from inverse folding logits. EvoIF fuses sequence-structure representations with these profiles via a compact transition block, yielding calibrated probabilities for log-odds scoring. On ProteinGym (217 mutational assays; >2.5M mutants), EvoIF and its MSA-enabled variant achieve state-of-the-art or competitive performance while using only 0.15% of the training data and fewer parameters than recent large models. Ablations confirm that within-family and cross-family profiles are complementary, improving robustness across function types, MSA depths, taxa, and mutation depths. The codes will be made publicly available at this https URL.', 'abstract_zh': '基于蛋白的语言模型在自然进化和逆强化学习中的统一视角：EvoIF模型的引入', 'title_zh': '蛋白质 fitness 预测的进化谱型'}
{'arxiv_id': 'arXiv:2510.07285', 'title': 'GTCN-G: A Residual Graph-Temporal Fusion Network for Imbalanced Intrusion Detection (Preprint)', 'authors': 'Tianxiang Xu, Zhichao Wen, Xinyu Zhao, Qi Hu, Yan Li, Chang Liu', 'link': 'https://arxiv.org/abs/2510.07285', 'abstract': 'The escalating complexity of network threats and the inherent class imbalance in traffic data present formidable challenges for modern Intrusion Detection Systems (IDS). While Graph Neural Networks (GNNs) excel in modeling topological structures and Temporal Convolutional Networks (TCNs) are proficient in capturing time-series dependencies, a framework that synergistically integrates both while explicitly addressing data imbalance remains an open challenge. This paper introduces a novel deep learning framework, named Gated Temporal Convolutional Network and Graph (GTCN-G), engineered to overcome these limitations. Our model uniquely fuses a Gated TCN (G-TCN) for extracting hierarchical temporal features from network flows with a Graph Convolutional Network (GCN) designed to learn from the underlying graph structure. The core innovation lies in the integration of a residual learning mechanism, implemented via a Graph Attention Network (GAT). This mechanism preserves original feature information through residual connections, which is critical for mitigating the class imbalance problem and enhancing detection sensitivity for rare malicious activities (minority classes). We conducted extensive experiments on two public benchmark datasets, UNSW-NB15 and ToN-IoT, to validate our approach. The empirical results demonstrate that the proposed GTCN-G model achieves state-of-the-art performance, significantly outperforming existing baseline models in both binary and multi-class classification tasks.', 'abstract_zh': 'boost Temporal Convolutional Network and Graph for Intrusion Detection in Network Traffic Data', 'title_zh': 'GTCN-G：一种残差图时序融合网络在不平衡入侵检测中的应用（预印本）'}
{'arxiv_id': 'arXiv:2510.07284', 'title': 'Online Rubrics Elicitation from Pairwise Comparisons', 'authors': 'MohammadHossein Rezaei, Robert Vacareanu, Zihao Wang, Clinton Wang, Yunzhong He, Afra Feyza Akyürek', 'link': 'https://arxiv.org/abs/2510.07284', 'abstract': 'Rubrics provide a flexible way to train LLMs on open-ended long-form answers where verifiable rewards are not applicable and human preferences provide coarse signals. Prior work shows that reinforcement learning with rubric-based rewards leads to consistent gains in LLM post-training. Most existing approaches rely on rubrics that remain static over the course of training. Such static rubrics, however, are vulnerable to reward-hacking type behaviors and fail to capture emergent desiderata that arise during training. We introduce Online Rubrics Elicitation (OnlineRubrics), a method that dynamically curates evaluation criteria in an online manner through pairwise comparisons of responses from current and reference policies. This online process enables continuous identification and mitigation of errors as training proceeds. Empirically, this approach yields consistent improvements of up to 8% over training exclusively with static rubrics across AlpacaEval, GPQA, ArenaHard as well as the validation sets of expert questions and rubrics. We qualitatively analyze the elicited criteria and identify prominent themes such as transparency, practicality, organization, and reasoning.', 'abstract_zh': '基于评分标准的动态 elicitation 方法在训练 LLMs 中的应用：连续改进和误差 mitigation', 'title_zh': '基于成对比较的在线评分标准提取'}
{'arxiv_id': 'arXiv:2510.07268', 'title': 'On the false election between regulation and innovation. Ideas for regulation through the responsible use of artificial intelligence in research and education.[Spanish version]', 'authors': 'Pompeu Casanovas', 'link': 'https://arxiv.org/abs/2510.07268', 'abstract': 'This short essay is a reworking of the answers offered by the author at the Debate Session of the AIHUB (CSIC) and EduCaixa Summer School, organized by Marta Garcia-Matos and Lissette Lemus, and coordinated by Albert Sabater (OEIAC, UG), with the participation of Vanina Martinez-Posse (IIIA-CSIC), Eulalia Soler (Eurecat) and Pompeu Casanovas (IIIA-CSIC) on July 4th 2025. Albert Sabater posed three questions: (1) How can regulatory frameworks priori-tise the protection of fundamental rights (privacy, non-discrimination, autonomy, etc.) in the development of AI, without falling into the false dichotomy between regulation and innova-tion? (2) Given the risks of AI (bias, mass surveillance, manipulation), what examples of regu-lations or policies have demonstrated that it is possible to foster responsible innovation, putting the public interest before profitability, without giving in to competitive pressure from actors such as China or the US? (3) In a scenario where the US prioritizes flexibility, what mecha-nisms could ensure that international cooperation in AI does not become a race to the bottom in rights, but rather a global standard of accountability? The article attempts to answer these three questions and concludes with some reflections on the relevance of the answers for education and research.', 'abstract_zh': '这篇简短的文章是对作者在AIHUB（CSIC）和EduCaixa暑期学校辩论会（由Marta Garcia-Matos和Lissette Lemus组织，Albert Sabater协调，阿尔巴特教育交流中心和格拉纳达大学共同主办）上回答的重新加工，本次活动于2025年7月4日举行，参与者包括Vanina Martinez-Posse（IIIA-CSIC）、Eulalia Soler（Eurecat）、Pompeu Casanovas（IIIA-CSIC）和Albert Sabater（OEIAC，UG）。Albert Sabater提出了三个问题：（1）如何在AI的发展中优先考虑基本权利（隐私、非歧视、自主权等）的保护，而不陷入监管与创新之间的虚假二元对立？（2）鉴于AI的风险（偏见、大规模监视、操控），有哪些监管或政策的例子证明能够在公共利益优先于盈利的同时促进负责任的创新，而不屈从于来自如中国或美国等竞争压力？（3）在美国优先考虑灵活性的背景下，哪些机制能够确保AI的国际合作不导致权利标准的逐底竞争，而是形成全球问责制的标准？本文试图回答这三个问题，并对这些问题的答案对于教育和研究的相关性进行了反思。', 'title_zh': '关于监管与创新之间的虚假对立：通过负责任使用人工智能在研究和教育中的监管思路[/西班牙语版本]'}
{'arxiv_id': 'arXiv:2510.07243', 'title': 'LeMAJ (Legal LLM-as-a-Judge): Bridging Legal Reasoning and LLM Evaluation', 'authors': 'Joseph Enguehard, Morgane Van Ermengem, Kate Atkinson, Sujeong Cha, Arijit Ghosh Chowdhury, Prashanth Kallur Ramaswamy, Jeremy Roghair, Hannah R Marlowe, Carina Suzana Negreanu, Kitty Boxall, Diana Mincu', 'link': 'https://arxiv.org/abs/2510.07243', 'abstract': "Evaluating large language model (LLM) outputs in the legal domain presents unique challenges due to the complex and nuanced nature of legal analysis. Current evaluation approaches either depend on reference data, which is costly to produce, or use standardized assessment methods, both of which have significant limitations for legal applications.\nAlthough LLM-as-a-Judge has emerged as a promising evaluation technique, its reliability and effectiveness in legal contexts depend heavily on evaluation processes unique to the legal industry and how trustworthy the evaluation appears to the human legal expert. This is where existing evaluation methods currently fail and exhibit considerable variability.\nThis paper aims to close the gap: a) we break down lengthy responses into 'Legal Data Points' (LDPs), self-contained units of information, and introduce a novel, reference-free evaluation methodology that reflects how lawyers evaluate legal answers; b) we demonstrate that our method outperforms a variety of baselines on both our proprietary dataset and an open-source dataset (LegalBench); c) we show how our method correlates more closely with human expert evaluations and helps improve inter-annotator agreement; and finally d) we open source our Legal Data Points for a subset of LegalBench used in our experiments, allowing the research community to replicate our results and advance research in this vital area of LLM evaluation on legal question-answering.", 'abstract_zh': '评估法律领域的大型语言模型（LLM）输出面临着独特的挑战，因为法律分析具有复杂和微妙的性质。当前的评估方法要么依赖于成本高昂的参考数据，要么使用标准化评估方法，这两种方法在法律应用中都存在显著的局限性。\n\n尽管已出现作为法官的大规模语言模型的评估技术，但其在法律情境下的可靠性和有效性很大程度上取决于独特的法律行业评估过程，以及这种评估对人类法律专家的信任程度。目前现有的评估方法在这方面存在缺陷，表现出显著的变异性。\n\n本文旨在缩小这一差距：a) 我们将 lengthy responses 分解为“法律数据点”（LDPs），这是一种自包含的信息单元，并引入了一种新颖的、无参考的评估方法，反映了律师评估法律答案的方式；b) 我们证明了我们的方法在我们的专有数据集和开源数据集（LegalBench）上都优于多种基线方法；c) 我们展示了我们的方法与人类专家评估的相关性更高，并有助于提高标注者间的一致性；最后 d) 我们开源了用于实验的部分 LegalBench 法律数据点，使研究社区能够复制我们的结果并在这一关键领域的 LLM 法律问答评估研究中取得进展。', 'title_zh': 'LeMAJ (法律LLM法官): 融合法律推理与LLM评估'}
{'arxiv_id': 'arXiv:2510.07231', 'title': 'Benchmarking LLM Causal Reasoning with Scientifically Validated Relationships', 'authors': 'Donggyu Lee, Sungwon Park, Yerin Hwang, Hyunwoo Oh, Hyoshin Kim, Jungwon Kim, Meeyoung Cha, Sangyoon Park, Jihee Kim', 'link': 'https://arxiv.org/abs/2510.07231', 'abstract': 'Causal reasoning is fundamental for Large Language Models (LLMs) to understand genuine cause-and-effect relationships beyond pattern matching. Existing benchmarks suffer from critical limitations such as reliance on synthetic data and narrow domain coverage. We introduce a novel benchmark constructed from casually identified relationships extracted from top-tier economics and finance journals, drawing on rigorous methodologies including instrumental variables, difference-in-differences, and regression discontinuity designs. Our benchmark comprises 40,379 evaluation items covering five task types across domains such as health, environment, technology, law, and culture. Experimental results on eight state-of-the-art LLMs reveal substantial limitations, with the best model achieving only 57.6\\% accuracy. Moreover, model scale does not consistently translate to superior performance, and even advanced reasoning models struggle with fundamental causal relationship identification. These findings underscore a critical gap between current LLM capabilities and demands of reliable causal reasoning in high-stakes applications.', 'abstract_zh': '因果推理是大型语言模型理解真正因果关系的基础，而不仅仅是模式匹配。现有基准存在关键局限性，如依赖合成数据和狭窄的领域覆盖率。我们提出了一个基于从顶级经济学和金融期刊中识别出的因果关系构建的新基准，采用了严格的因果方法，包括工具变量法、差分差异法和断点回归设计。该基准包含40,379个评估项目，覆盖健康、环境、技术、法律和文化等五个任务类型。在八种最先进的语言模型上的实验结果揭示了显著的局限性，最佳模型的准确率仅为57.6%。此外，模型规模并不一致地转化为更好的性能，即使是先进的推理模型也难以识别基本的因果关系。这些发现突显了当前大型语言模型能力和高标准的可靠因果推理之间的关键差距。', 'title_zh': '基于科学验证的关系 Benchmarking 大型语言模型因果推理能力'}
{'arxiv_id': 'arXiv:2510.07227', 'title': 'Where to Begin: Efficient Pretraining via Subnetwork Selection and Distillation', 'authors': 'Arjun Krishnakumar, Rhea Sanjay Sukthanker, Hannan Javed Mahadik, Gabriela Kadlecová, Vladyslav Moroshan, Timur Carstensen, Frank Hutter, Aaron Klein', 'link': 'https://arxiv.org/abs/2510.07227', 'abstract': 'Small Language models (SLMs) offer an efficient and accessible alternative to Large Language Models (LLMs), delivering strong performance while using far fewer resources. We introduce a simple and effective framework for pretraining SLMs that brings together three complementary ideas. First, we identify structurally sparse sub-network initializations that consistently outperform randomly initialized models of similar size under the same compute budget. Second, we use evolutionary search to automatically discover high-quality sub-network initializations, providing better starting points for pretraining. Third, we apply knowledge distillation from larger teacher models to speed up training and improve generalization. Together, these components make SLM pretraining substantially more efficient: our best model, discovered using evolutionary search and initialized with LLM weights, matches the validation perplexity of a comparable Pythia SLM while requiring 9.2x fewer pretraining tokens. We release all code and models at this https URL, offering a practical and reproducible path toward cost-efficient small language model development at scale.', 'abstract_zh': '小语言模型（SLMs）提供了一种在资源有限的情况下与大型语言模型（LLMs）竞争的有效替代方案，它们能在使用更少资源的同时取得强大的性能。我们提出了一个简单而有效的框架，用于预训练SLMs，该框架结合了三种互补的想法。首先，我们识别出结构上稀疏的子网络初始化方法，在相同的计算预算下，这些方法比随机初始化的模型表现更好。其次，我们使用进化搜索自动发现高质量的子网络初始化，为预训练提供更好的起点。第三，我们应用来自较大教师模型的知识蒸馏来加速训练并提高泛化能力。这些组件共同使得SLM预训练显著更加高效：我们使用进化搜索发现的最佳模型，在初始化时使用LLM权重，所要求的预训练标记数量仅为同类Pythia SLM的9.2倍，但在验证困惑度上表现相当。我们已在该链接发布了全部代码和模型，为大规模低成本小语言模型开发提供了可实践和可复制的路径。', 'title_zh': '从何开始：通过子网络选择和知识蒸馏实现高效的预训练'}
{'arxiv_id': 'arXiv:2510.07217', 'title': 'GenPilot: A Multi-Agent System for Test-Time Prompt Optimization in Image Generation', 'authors': 'Wen Ye, Zhaocheng Liu, Yuwei Gui, Tingyu Yuan, Yunyue Su, Bowen Fang, Chaoyang Zhao, Qiang Liu, Liang Wang', 'link': 'https://arxiv.org/abs/2510.07217', 'abstract': 'Text-to-image synthesis has made remarkable progress, yet accurately interpreting complex and lengthy prompts remains challenging, often resulting in semantic inconsistencies and missing details. Existing solutions, such as fine-tuning, are model-specific and require training, while prior automatic prompt optimization (APO) approaches typically lack systematic error analysis and refinement strategies, resulting in limited reliability and effectiveness. Meanwhile, test-time scaling methods operate on fixed prompts and on noise or sample numbers, limiting their interpretability and adaptability. To solve these, we introduce a flexible and efficient test-time prompt optimization strategy that operates directly on the input text. We propose a plug-and-play multi-agent system called GenPilot, integrating error analysis, clustering-based adaptive exploration, fine-grained verification, and a memory module for iterative optimization. Our approach is model-agnostic, interpretable, and well-suited for handling long and complex prompts. Simultaneously, we summarize the common patterns of errors and the refinement strategy, offering more experience and encouraging further exploration. Experiments on DPG-bench and Geneval with improvements of up to 16.9% and 5.7% demonstrate the strong capability of our methods in enhancing the text and image consistency and structural coherence of generated images, revealing the effectiveness of our test-time prompt optimization strategy. The code is available at this https URL.', 'abstract_zh': '文本到图像合成取得了显著进展，但准确解释复杂的长提示依然具有挑战性，常常导致语义不一致和缺失细节。现有解决方案，如微调，是模型特定的并且需要训练，而先前的自动提示优化（APO）方法通常缺乏系统性的错误分析和优化策略，导致其可靠性有限且效果有限。同时，测试时缩放方法仅适用于固定提示或噪声或样本数量，限制了其可解释性和适应性。为了解决这些问题，我们提出了一种灵活且高效的测试时提示优化策略，可以直接作用于输入文本。我们提出了一个即插即用的多代理系统GenPilot，该系统结合了错误分析、基于聚类的自适应探索、细粒度验证和记忆模块，实现迭代优化。我们的方法是模型无关的、可解释的，并且非常适合处理长且复杂的提示。同时，我们总结了常见的错误模式和优化策略，提供了更多的经验并鼓励进一步探索。在DPG-bench和Geneval上的实验表明，我们的方法在提高生成图的文本和图像一致性及结构连贯性方面具有显著的能力，证实了我们测试时提示优化策略的有效性。代码可在此处访问。', 'title_zh': 'GenPilot: 一种用于图像生成测试时提示优化的多agent系统'}
{'arxiv_id': 'arXiv:2510.07213', 'title': 'Language Lives in Sparse Dimensions: Toward Interpretable and Efficient Multilingual Control for Large Language Models', 'authors': 'Chengzhi Zhong, Fei Cheng, Qianying Liu, Yugo Murawaki, Chenhui Chu, Sadao Kurohashi', 'link': 'https://arxiv.org/abs/2510.07213', 'abstract': 'Large language models exhibit strong multilingual capabilities despite limited exposure to non-English data. Prior studies show that English-centric large language models map multilingual content into English-aligned representations at intermediate layers and then project them back into target-language token spaces in the final layer. From this observation, we hypothesize that this cross-lingual transition is governed by a small and sparse set of dimensions, which occur at consistent indices across the intermediate to final layers. Building on this insight, we introduce a simple, training-free method to identify and manipulate these dimensions, requiring only as few as 50 sentences of either parallel or monolingual data. Experiments on a multilingual generation control task reveal the interpretability of these dimensions, demonstrating that the interventions in these dimensions can switch the output language while preserving semantic content, and that it surpasses the performance of prior neuron-based approaches at a substantially lower cost.', 'abstract_zh': '大型语言模型尽管具有有限的非英语数据暴露，但仍展现出强大的多语言能力。以往研究显示，以英语为中心的大规模语言模型将在中间层将多语言内容映射到英文对齐的表示，然后在最终层将其投影回目标语言的标记空间。基于这一观察，我们假设这种跨语言过渡是由一组小型且稀疏的维度控制的，这些维度在中间层到最终层中的一致索引位置出现。基于这一见解，我们提出了一种简单的、无需训练的方法来识别并操控这些维度，仅需少量（少至50句）平行或单一语言的数据。在多语言生成控制任务上的实验揭示了这些维度的可解释性，表明在这些维度上的干预可以切换输出语言同时保留语义内容，并且与先前的神经元基于的方法相比，在显著更低的成本下实现了更好的性能。', 'title_zh': '语言存在于稀疏维度中： toward 可解释且高效的多语言控制大语言模型'}
{'arxiv_id': 'arXiv:2510.07210', 'title': 'HyPlan: Hybrid Learning-Assisted Planning Under Uncertainty for Safe Autonomous Driving', 'authors': 'Donald Pfaffmann, Matthias Klusch, Marcel Steinmetz', 'link': 'https://arxiv.org/abs/2510.07210', 'abstract': 'We present a novel hybrid learning-assisted planning method, named HyPlan, for solving the collision-free navigation problem for self-driving cars in partially observable traffic environments. HyPlan combines methods for multi-agent behavior prediction, deep reinforcement learning with proximal policy optimization and approximated online POMDP planning with heuristic confidence-based vertical pruning to reduce its execution time without compromising safety of driving. Our experimental performance analysis on the CARLA-CTS2 benchmark of critical traffic scenarios with pedestrians revealed that HyPlan may navigate safer than selected relevant baselines and perform significantly faster than considered alternative online POMDP planners.', 'abstract_zh': '一种用于部分可观测交通环境中的自主驾驶汽车无碰撞导航问题的新型混合学习辅助规划方法：HyPlan', 'title_zh': 'HyPlan: 在不确定性下结合学习辅助规划以实现安全自主驾驶'}
{'arxiv_id': 'arXiv:2510.07191', 'title': 'Resolution scaling governs DINOv3 transfer performance in chest radiograph classification', 'authors': 'Soroosh Tayebi Arasteh, Mina Shaigan, Christiane Kuhl, Jakob Nikolas Kather, Sven Nebelung, Daniel Truhn', 'link': 'https://arxiv.org/abs/2510.07191', 'abstract': "Self-supervised learning (SSL) has advanced visual representation learning, but its value in chest radiography, a high-volume imaging modality with fine-grained findings, remains unclear. Meta's DINOv3 extends earlier SSL models through Gram-anchored self-distillation. Whether these design choices improve transfer learning for chest radiography has not been systematically tested. We benchmarked DINOv3 against DINOv2 and ImageNet initialization across seven datasets (n>814,000). Two representative backbones were evaluated: ViT-B/16 and ConvNeXt-B. Images were analyzed at 224x224, 512x512, and 1024x1024 pixels. We additionally assessed frozen features from a 7B model. The primary outcome was mean AUROC across labels. At 224x224, DINOv3 and DINOv2 achieved comparable performance on adult datasets. Increasing resolution to 512x512 yielded consistent improvements for DINOv3 over both DINOv2 and ImageNet. In contrast, results in pediatric cohort showed no differences across initializations. Across all settings, ConvNeXt-B outperformed ViT-B/16. Models using frozen DINOv3-7B features underperformed relative to fully finetuned 86-89M-parameter backbones, highlighting the importance of domain adaptation. Scaling to 1024x1024 did not further improve accuracy. Resolution-related gains were most evident for boundary-dependent and small focal abnormalities. In chest radiography, higher input resolution is critical for leveraging the benefits of modern self-supervised models. 512x512 pixels represent a practical upper limit where DINOv3-initialized ConvNeXt-B networks provide the strongest performance, while larger inputs offer minimal return on cost. Clinically, these findings support use of finetuned, mid-sized backbones at 512x512 for chest radiograph interpretation, with the greatest gains expected in detecting subtle or boundary-centered lesions relevant to emergency and critical care settings.", 'abstract_zh': '自监督学习（SSL）在胸部X线成像中的价值：DINOv3在高通量细粒度影像数据中的表现评估', 'title_zh': '分辨率缩放决定了DINOv3在胸部X光分类中的迁移学习性能。'}
{'arxiv_id': 'arXiv:2510.07181', 'title': 'TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics', 'authors': 'Yi Han, Cheng Chi, Enshen Zhou, Shanyu Rong, Jingkun An, Pengwei Wang, Zhongyuan Wang, Lu Sheng, Shanghang Zhang', 'link': 'https://arxiv.org/abs/2510.07181', 'abstract': 'Vision-Language Models (VLMs) have shown remarkable capabilities in spatial reasoning, yet they remain fundamentally limited to qualitative precision and lack the computational precision required for real-world robotics. Current approaches fail to leverage metric cues from depth sensors and camera calibration, instead reducing geometric problems to pattern recognition tasks that cannot deliver the centimeter-level accuracy essential for robotic manipulation. We present TIGeR (Tool-Integrated Geometric Reasoning), a novel framework that transforms VLMs from perceptual estimators to geometric computers by enabling them to generate and execute precise geometric computations through external tools. Rather than attempting to internalize complex geometric operations within neural networks, TIGeR empowers models to recognize geometric reasoning requirements, synthesize appropriate computational code, and invoke specialized libraries for exact calculations. To support this paradigm, we introduce TIGeR-300K, a comprehensive tool-invocation-oriented dataset covering point transformations, pose estimation, trajectory generation, and spatial compatibility verification, complete with tool invocation sequences and intermediate computations. Through a two-stage training pipeline combining supervised fine-tuning (SFT) and reinforcement fine-tuning (RFT) with our proposed hierarchical reward design, TIGeR achieves SOTA performance on geometric reasoning benchmarks while demonstrating centimeter-level precision in real-world robotic manipulation tasks.', 'abstract_zh': 'Vision-Language模型（VLMs）在空间推理方面展现了卓越的能力，但仍从根本上局限于定性的精确度，并缺乏用于实际机器人应用所需的计算精确度。当前的方法未能利用深度传感器和相机校准提供的度量线索，而是将几何问题简化为模式识别任务，这些任务无法提供机器人操作所需的高度厘米级准确性。我们提出了TIGeR（Tool-Integrated Geometric Reasoning），一种新型框架，通过使模型能够生成和执行精确的几何计算，从而将VLMs从感知估计器转变为几何计算机。TIGeR 不试图在神经网络内部化复杂的几何操作，而是使模型能够识别几何推理需求、合成合适的计算代码，并调用专门的库进行精确计算。为了支持这一范式，我们引入了TIGeR-300K数据集，该数据集涵盖了点变换、姿态估计、轨迹生成和空间兼容性验证，其中包括工具调用序列和中间计算步骤。通过结合监督微调（SFT）和强化微调（RFT），以及我们提出的分层奖励设计的两阶段训练pipeline，TIGeR 在几何推理基准测试中达到了最优性能，并在实际机器人操作任务中展示了厘米级的精确度。', 'title_zh': 'TIGeR: 工具集成几何推理在视觉-语言模型中的机器人应用'}
{'arxiv_id': 'arXiv:2510.07151', 'title': 'ELMUR: External Layer Memory with Update/Rewrite for Long-Horizon RL', 'authors': 'Egor Cherepanov, Alexey K. Kovalev, Aleksandr I. Panov', 'link': 'https://arxiv.org/abs/2510.07151', 'abstract': 'Real-world robotic agents must act under partial observability and long horizons, where key cues may appear long before they affect decision making. However, most modern approaches rely solely on instantaneous information, without incorporating insights from the past. Standard recurrent or transformer models struggle with retaining and leveraging long-term dependencies: context windows truncate history, while naive memory extensions fail under scale and sparsity. We propose ELMUR (External Layer Memory with Update/Rewrite), a transformer architecture with structured external memory. Each layer maintains memory embeddings, interacts with them via bidirectional cross-attention, and updates them through an Least Recently Used (LRU) memory module using replacement or convex blending. ELMUR extends effective horizons up to 100,000 times beyond the attention window and achieves a 100% success rate on a synthetic T-Maze task with corridors up to one million steps. In POPGym, it outperforms baselines on more than half of the tasks. On MIKASA-Robo sparse-reward manipulation tasks with visual observations, it nearly doubles the performance of strong baselines. These results demonstrate that structured, layer-local external memory offers a simple and scalable approach to decision making under partial observability.', 'abstract_zh': '实况机器人代理必须在部分可观测性和长时间框架下行动，其中关键线索可能在影响决策之前很久就会出现。然而，大多数现代方法仅依赖于瞬时信息，而不结合过去的洞见。标准的循环或变压器模型在保留和利用长期依赖关系方面存在问题：注意力窗口裁剪了历史记录，而简单的记忆扩展在规模和稀疏性下失效。我们提出了一种名为ELMUR（External Layer Memory with Update/Rewrite）的变压器架构，带有结构化外部记忆。每一层维护着记忆嵌入，通过双向跨注意力与之交互，并通过一个基于最近最少使用（LRU）的记忆模块进行更新或凸融合。ELMUR将有效的时间框架扩展了100,000倍以上，并在合成T-Maze任务中实现了100%的成功率，该任务的最大步数为一百万步。在POPGym中，它在超过一半的任务上优于基线方法。在MIKASA-Robo视觉观察下的稀疏奖励操作任务中，它几乎将强基线方法的性能翻倍。这些结果表明，结构化、分层局部外部内存为部分可观测性下的决策制定提供了一种简单而可扩展的方法。', 'title_zh': 'ELMUR：外部层记忆更新/重写方法在长时 horizon RL 中的应用'}
{'arxiv_id': 'arXiv:2510.07147', 'title': 'A Multi-Agent Framework for Stateful Inference-Time Search', 'authors': 'Arshika Lalan, Rajat Ghosh, Aditya Kolsur, Debojyoti Dutta', 'link': 'https://arxiv.org/abs/2510.07147', 'abstract': 'Recent work explores agentic inference-time techniques to perform structured, multi-step reasoning. However, stateless inference often struggles on multi-step tasks due to the absence of persistent state. Moreover, task-specific fine-tuning or instruction-tuning often achieve surface-level code generation but remain brittle on tasks requiring deeper reasoning and long-horizon dependencies. To address these limitations, we propose stateful multi-agent evolutionary search, a training-free framework that departs from prior stateless approaches by combining (i) persistent inference-time state, (ii) adversarial mutation, and (iii) evolutionary preservation. We demonstrate its effectiveness in automated unit test generation through the generation of edge cases. We generate robust edge cases using an evolutionary search process, where specialized agents sequentially propose, mutate, and score candidates. A controller maintains persistent state across generations, while evolutionary preservation ensures diversity and exploration across all possible cases. This yields a generalist agent capable of discovering robust, high-coverage edge cases across unseen codebases. Experiments show our stateful multi-agent inference framework achieves substantial gains in coverage over stateless single-step baselines, evaluated on prevalent unit-testing benchmarks such as HumanEval and TestGenEvalMini and using three diverse LLM families - Llama, Gemma, and GPT. These results indicate that combining persistent inference-time state with evolutionary search materially improves unit-test generation.', 'abstract_zh': '基于状态的多智能体演化搜索：一种训练-free框架，在多步任务中提高推理能力', 'title_zh': '具备状态感知推理时搜索的多代理框架'}
{'arxiv_id': 'arXiv:2510.07141', 'title': 'Comparing human and language models sentence processing difficulties on complex structures', 'authors': 'Samuel Joseph Amouyal, Aya Meltzer-Asscher, Jonathan Berant', 'link': 'https://arxiv.org/abs/2510.07141', 'abstract': 'Large language models (LLMs) that fluently converse with humans are a reality - but do LLMs experience human-like processing difficulties? We systematically compare human and LLM sentence comprehension across seven challenging linguistic structures. We collect sentence comprehension data from humans and five families of state-of-the-art LLMs, varying in size and training procedure in a unified experimental framework. Our results show LLMs overall struggle on the target structures, but especially on garden path (GP) sentences. Indeed, while the strongest models achieve near perfect accuracy on non-GP structures (93.7% for GPT-5), they struggle on GP structures (46.8% for GPT-5). Additionally, when ranking structures based on average performance, rank correlation between humans and models increases with parameter count. For each target structure, we also collect data for their matched baseline without the difficult structure. Comparing performance on the target vs. baseline sentences, the performance gap observed in humans holds for LLMs, with two exceptions: for models that are too weak performance is uniformly low across both sentence types, and for models that are too strong the performance is uniformly high. Together, these reveal convergence and divergence in human and LLM sentence comprehension, offering new insights into the similarity of humans and LLMs.', 'abstract_zh': '大型语言模型在流畅地与人类交流方面已成为现实——但大型语言模型是否体验到类似人类的处理困难？我们系统地在七个具有挑战性的语言结构上比较了人类和大型语言模型的句子理解能力。我们在统一的实验框架下收集了人类和五大家族的最先进的大型语言模型的句子理解数据，这些模型在规模和训练过程上各不相同。结果显示，整体而言，大型语言模型在目标结构上表现挣扎，尤其是在“误判句”（GP句）上。事实上，虽然最强的模型在非GP句上几乎达到完美准确率（GPT-5达到93.7%），但在GP句上则表现挣扎（GPT-5仅为46.8%）。此外，根据平均表现对结构进行排序时，人类和模型之间的排名相关性随参数量增加而增强。在为每个目标结构收集对应的不含困难结构的基线数据后，将目标句子的表现与基线句子的表现进行比较，人类表现出的性能差距同样适用于大型语言模型，有两项例外：对于过弱的模型，两种句型的表现均低；对于过强的模型，两种句型的表现均高。这些结果揭示了人类和大型语言模型在句子理解上的趋同与分歧，为人类与大型语言模型的相似性提供了新的见解。', 'title_zh': '比较人类与语言模型在处理复杂结构句子时的困难'}
{'arxiv_id': 'arXiv:2510.07134', 'title': 'TrackVLA++: Unleashing Reasoning and Memory Capabilities in VLA Models for Embodied Visual Tracking', 'authors': 'Jiahang Liu, Yunpeng Qi, Jiazhao Zhang, Minghan Li, Shaoan Wang, Kui Wu, Hanjing Ye, Hong Zhang, Zhibo Chen, Fangwei Zhong, Zhizheng Zhang, He Wang', 'link': 'https://arxiv.org/abs/2510.07134', 'abstract': "Embodied Visual Tracking (EVT) is a fundamental ability that underpins practical applications, such as companion robots, guidance robots and service assistants, where continuously following moving targets is essential. Recent advances have enabled language-guided tracking in complex and unstructured scenes. However, existing approaches lack explicit spatial reasoning and effective temporal memory, causing failures under severe occlusions or in the presence of similar-looking distractors. To address these challenges, we present TrackVLA++, a novel Vision-Language-Action (VLA) model that enhances embodied visual tracking with two key modules, a spatial reasoning mechanism and a Target Identification Memory (TIM). The reasoning module introduces a Chain-of-Thought paradigm, termed Polar-CoT, which infers the target's relative position and encodes it as a compact polar-coordinate token for action prediction. Guided by these spatial priors, the TIM employs a gated update strategy to preserve long-horizon target memory, ensuring spatiotemporal consistency and mitigating target loss during extended occlusions. Extensive experiments show that TrackVLA++ achieves state-of-the-art performance on public benchmarks across both egocentric and multi-camera settings. On the challenging EVT-Bench DT split, TrackVLA++ surpasses the previous leading approach by 5.1 and 12, respectively. Furthermore, TrackVLA++ exhibits strong zero-shot generalization, enabling robust real-world tracking in dynamic and occluded scenarios.", 'abstract_zh': '具身视觉跟踪（EVT）是支撑 companion 机器人、引导机器人和服务助理等实际应用的基本能力，其中连续追踪移动目标是必不可少的。近期进展使得在复杂且无结构的场景中实现语言引导的跟踪成为可能。然而，现有方法缺乏明确的空间推理和有效的时序记忆，导致在严重遮挡或存在相似干扰物的情况下出现失败。为应对这些挑战，我们提出了 TrackVLA++，这是一种具有创新性的视觉-语言-动作（VLA）模型，通过两个关键模块——空间推理机制和目标识别记忆（TIM）来增强具身视觉跟踪能力。推理模块引入了一种称为 Polar-CoT 的思维链框架，通过推断目标的相对位置并将其编码为紧凑的极坐标 tokens 来预测动作。受这些空间先验的引导，TIM 采用门控更新策略来保持长期目标记忆，确保时空一致性和在长时间遮挡期间减轻目标丢失。广泛实验表明，TrackVLA++ 在公共基准测试中在第一人称和多摄像头设置下均达到最先进的性能。在具有挑战性的 EVT-Bench DT 分割中，TrackVLA++ 分别超越之前领先的方法 5.1 和 12 分。此外，TrackVLA++ 具有强大的零样本泛化能力，可在动态和遮挡场景中实现稳健的真实世界跟踪。', 'title_zh': 'TrackVLA++: 解锁VLA模型中的推理与记忆能力以实现沉浸式视觉跟踪'}
{'arxiv_id': 'arXiv:2510.07133', 'title': 'A Digital Twin Framework for Metamorphic Testing of Autonomous Driving Systems Using Generative Model', 'authors': 'Tony Zhang, Burak Kantarci, Umair Siddique', 'link': 'https://arxiv.org/abs/2510.07133', 'abstract': "Ensuring the safety of self-driving cars remains a major challenge due to the complexity and unpredictability of real-world driving environments. Traditional testing methods face significant limitations, such as the oracle problem, which makes it difficult to determine whether a system's behavior is correct, and the inability to cover the full range of scenarios an autonomous vehicle may encounter. In this paper, we introduce a digital twin-driven metamorphic testing framework that addresses these challenges by creating a virtual replica of the self-driving system and its operating environment. By combining digital twin technology with AI-based image generative models such as Stable Diffusion, our approach enables the systematic generation of realistic and diverse driving scenes. This includes variations in weather, road topology, and environmental features, all while maintaining the core semantics of the original scenario. The digital twin provides a synchronized simulation environment where changes can be tested in a controlled and repeatable manner. Within this environment, we define three metamorphic relations inspired by real-world traffic rules and vehicle behavior. We validate our framework in the Udacity self-driving simulator and demonstrate that it significantly enhances test coverage and effectiveness. Our method achieves the highest true positive rate (0.719), F1 score (0.689), and precision (0.662) compared to baseline approaches. This paper highlights the value of integrating digital twins with AI-powered scenario generation to create a scalable, automated, and high-fidelity testing solution for autonomous vehicle safety.", 'abstract_zh': '确保自动驾驶汽车的安全仍是一项重大挑战，由于实际驾驶环境的复杂性和不可预测性。传统的测试方法面临许多局限性，如荆棘难题，这使得确定系统行为的正确性变得困难，以及无法覆盖自动驾驶汽车可能遇到的全部场景。本文介绍了一种基于数字孪生的元测试框架，通过创建自动驾驶系统及其运行环境的虚拟复制品来应对这些挑战。结合数字孪生技术与基于AI的图像生成模型（如Stable Diffusion），我们的方法能够系统地生成逼真且多样的驾驶场景，包括天气、道路拓扑和环境特征的变化，同时保持原始场景的核心语义。数字孪生提供了一个同步的仿真环境，可以在受控和可重复的情况下进行测试。在这个环境中，我们定义了三种受现实交通规则和车辆行为启发的元关系。我们在Udacity自动驾驶模拟器中验证了该框架，并证明了它显著提升了测试覆盖率和有效性。该方法在真实基线方法中的真正阳性率最高（0.719）、F1分数最高（0.689）和精确度最高（0.662）。本文强调了将数字孪生与AI驱动的场景生成相结合的价值，以创建适用于自动驾驶汽车安全的可扩展、自动化和高保真测试解决方案。', 'title_zh': '基于生成模型的自主驾驶系统 metamorphic 测试的数字孪生框架'}
{'arxiv_id': 'arXiv:2510.07129', 'title': 'Graph Conditioned Diffusion for Controllable Histopathology Image Generation', 'authors': 'Sarah Cechnicka, Matthew Baugh, Weitong Zhang, Mischa Dombrowski, Zhe Li, Johannes C. Paetzold, Candice Roufosse, Bernhard Kainz', 'link': 'https://arxiv.org/abs/2510.07129', 'abstract': 'Recent advances in Diffusion Probabilistic Models (DPMs) have set new standards in high-quality image synthesis. Yet, controlled generation remains challenging, particularly in sensitive areas such as medical imaging. Medical images feature inherent structure such as consistent spatial arrangement, shape or texture, all of which are critical for diagnosis. However, existing DPMs operate in noisy latent spaces that lack semantic structure and strong priors, making it difficult to ensure meaningful control over generated content. To address this, we propose graph-based object-level representations for Graph-Conditioned-Diffusion. Our approach generates graph nodes corresponding to each major structure in the image, encapsulating their individual features and relationships. These graph representations are processed by a transformer module and integrated into a diffusion model via the text-conditioning mechanism, enabling fine-grained control over generation. We evaluate this approach using a real-world histopathology use case, demonstrating that our generated data can reliably substitute for annotated patient data in downstream segmentation tasks. The code is available here.', 'abstract_zh': '最近在扩散概率模型（DPMs）方面的进展为高质量图像合成设定了新标准。然而，在医疗成像等敏感领域，受控生成仍然具有挑战性。医疗图像具有内在结构，如一致的空间排列、形状或纹理，这些都是诊断的关键。然而，现有的DPMs在缺乏语义结构和强先验知识的噪声潜在空间中运行，这使得确保生成内容的有意义控制变得困难。为了解决这个问题，我们提出了基于图的对象级表示以实现条件图扩散。本方法生成对应于图像中每个主要结构的图节点，封装其各自的特征和关系。这些图表示通过一个变压器模块进行处理，并通过文本引导机制集成到扩散模型中，从而实现对生成的精细控制。我们使用实际病理学案例进行了评估，结果显示我们生成的数据可以可靠地替代注释的患者数据用于后续分割任务。代码可在此获得。', 'title_zh': '基于图条件的扩散模型在可控制的病理图像生成中的应用'}
{'arxiv_id': 'arXiv:2510.07105', 'title': 'Opt-ICL at LeWiDi-2025: Maximizing In-Context Signal from Rater Examples via Meta-Learning', 'authors': 'Taylor Sorensen, Yejin Choi', 'link': 'https://arxiv.org/abs/2510.07105', 'abstract': "Many natural language processing (NLP) tasks involve subjectivity, ambiguity, or legitimate disagreement between annotators. In this paper, we outline our system for modeling human variation. Our system leverages language models' (LLMs) in-context learning abilities, along with a two-step meta-learning training procedure for 1) post-training on many datasets requiring in-context learning and 2) specializing the model via in-context meta-learning to the particular data distribution of interest. We also evaluate the performance of our system submission to the Learning With Disagreements (LeWiDi) competition, where it was the overall winner on both tasks. Additionally, we perform an ablation study to measure the importance of each system component. We find that including rater examples in-context is crucial for our system's performance, dataset-specific fine-tuning is helpful on the larger datasets, post-training on other in-context datasets is helpful on one of the competition datasets, and that performance improves with model scale.", 'abstract_zh': '许多自然语言处理（NLP）任务涉及主观性、歧义或注释者之间的合理分歧。本文概述了我们的人类变异性建模系统。该系统利用了语言模型（LLMs）的上下文学习能力，并采用两步元学习训练程序，首先是经过多个需要上下文学习的數據集训练，其次是通过上下文元学习使模型专门化以适应特定的数据分布。另外，我们还评估了该系统在Learning With Disagreements（LeWiDi）竞赛中的表现，其中在两个任务上均获得了总体冠军。我们还进行了消融研究以衡量每个系统组件的重要性。研究发现，将评价者示例纳入上下文对于系统性能至关重要，在较大数据集上进行数据集特定微调是有帮助的，在竞赛数据集中有一个数据集的后训练有助于提高性能，随着模型规模的增加，性能会有所改善。', 'title_zh': 'Opt-ICL 在 LeWiDi-2025：通过元学习最大化标注示例的上下文信号'}
{'arxiv_id': 'arXiv:2510.07092', 'title': 'Generative World Modelling for Humanoids: 1X World Model Challenge Technical Report', 'authors': 'Riccardo Mereu, Aidan Scannell, Yuxin Hou, Yi Zhao, Aditya Jitta, Antonio Dominguez, Luigi Acerbi, Amos Storkey, Paul Chang', 'link': 'https://arxiv.org/abs/2510.07092', 'abstract': 'World models are a powerful paradigm in AI and robotics, enabling agents to reason about the future by predicting visual observations or compact latent states. The 1X World Model Challenge introduces an open-source benchmark of real-world humanoid interaction, with two complementary tracks: sampling, focused on forecasting future image frames, and compression, focused on predicting future discrete latent codes. For the sampling track, we adapt the video generation foundation model Wan-2.2 TI2V-5B to video-state-conditioned future frame prediction. We condition the video generation on robot states using AdaLN-Zero, and further post-train the model using LoRA. For the compression track, we train a Spatio-Temporal Transformer model from scratch. Our models achieve 23.0 dB PSNR in the sampling task and a Top-500 CE of 6.6386 in the compression task, securing 1st place in both challenges.', 'abstract_zh': '世界模型是AI和机器人领域的强大范式，使智能体能够通过预测视觉观察或紧凑的潜状态来推理未来。1X世界模型挑战引入了一个开源的现实世界类人交互基准，包含两个互补的赛道：采样，专注于预测未来的图像帧；压缩，专注于预测未来的离散潜代码。在采样赛道中，我们使用Wan-2.2 TI2V-5B视频生成基础模型，并将其适应于基于机器人状态的未来帧预测。我们使用AdaLN-Zero条件化视频生成，并进一步使用LoRA对模型进行后训练。在压缩赛道中，我们从零开始训练一个时空变换器模型。我们的模型在采样任务中达到23.0 dB的PSNR，在压缩任务中获得Top-500 CE 6.6386的成绩，分别获得两个挑战的第一名。', 'title_zh': 'humanoid生成世界建模：1X世界模型挑战技术报告'}
{'arxiv_id': 'arXiv:2510.07084', 'title': 'HTMformer: Hybrid Time and Multivariate Transformer for Time Series Forecasting', 'authors': 'Tan Wang, Yun Wei Dong, Tao Zhang, Qi Wang', 'link': 'https://arxiv.org/abs/2510.07084', 'abstract': 'Transformer-based methods have achieved impressive results in time series forecasting. However, existing Transformers still exhibit limitations in sequence modeling as they tend to overemphasize temporal dependencies. This incurs additional computational overhead without yielding corresponding performance gains. We find that the performance of Transformers is highly dependent on the embedding method used to learn effective representations. To address this issue, we extract multivariate features to augment the effective information captured in the embedding layer, yielding multidimensional embeddings that convey richer and more meaningful sequence representations. These representations enable Transformer-based forecasters to better understand the series. Specifically, we introduce Hybrid Temporal and Multivariate Embeddings (HTME). The HTME extractor integrates a lightweight temporal feature extraction module with a carefully designed multivariate feature extraction module to provide complementary features, thereby achieving a balance between model complexity and performance. By combining HTME with the Transformer architecture, we present HTMformer, leveraging the enhanced feature extraction capability of the HTME extractor to build a lightweight forecaster. Experiments conducted on eight real-world datasets demonstrate that our approach outperforms existing baselines in both accuracy and efficiency.', 'abstract_zh': '基于Transformer的方法在时间序列预测中取得了显著成果，但现有Transformer在序列建模中仍然存在局限性，容易过分强调时序依赖性，导致额外的计算开销而未获得相应的性能提升。我们发现，Transformer的表现高度依赖于用于学习有效表示的嵌入方法。为解决这一问题，我们通过引入多变量特征来增强嵌入层捕获的有效信息，生成多维嵌入，以传达更丰富和更具有意义的序列表示。这些表示使基于Transformer的预测器能够更好地理解时间序列。具体来说，我们提出了混合时序和多变量嵌入（HTME）。HTME提取器结合了一个轻量级的时间特征提取模块和一个精心设计的多变量特征提取模块，以提供互补特征，从而在模型复杂度和性能之间达到平衡。通过将HTME与Transformer架构相结合，我们提出了HTMformer，利用HTME提取器增强的特征提取能力构建了一个轻量级预测器。实验结果表明，我们在准确性和效率上均优于现有基线方法。', 'title_zh': 'HTMformer：混合时间维度和多变量变换的时间序列 forecasting 模型'}
{'arxiv_id': 'arXiv:2510.07077', 'title': 'Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications', 'authors': 'Kento Kawaharazuka, Jihoon Oh, Jun Yamada, Ingmar Posner, Yuke Zhu', 'link': 'https://arxiv.org/abs/2510.07077', 'abstract': 'Amid growing efforts to leverage advances in large language models (LLMs) and vision-language models (VLMs) for robotics, Vision-Language-Action (VLA) models have recently gained significant attention. By unifying vision, language, and action data at scale, which have traditionally been studied separately, VLA models aim to learn policies that generalise across diverse tasks, objects, embodiments, and environments. This generalisation capability is expected to enable robots to solve novel downstream tasks with minimal or no additional task-specific data, facilitating more flexible and scalable real-world deployment. Unlike previous surveys that focus narrowly on action representations or high-level model architectures, this work offers a comprehensive, full-stack review, integrating both software and hardware components of VLA systems. In particular, this paper provides a systematic review of VLAs, covering their strategy and architectural transition, architectures and building blocks, modality-specific processing techniques, and learning paradigms. In addition, to support the deployment of VLAs in real-world robotic applications, we also review commonly used robot platforms, data collection strategies, publicly available datasets, data augmentation methods, and evaluation benchmarks. Throughout this comprehensive survey, this paper aims to offer practical guidance for the robotics community in applying VLAs to real-world robotic systems. All references categorized by training approach, evaluation method, modality, and dataset are available in the table on our project website: this https URL .', 'abstract_zh': '随着对利用大规模语言模型（LLMs）和视觉-语言模型（VLMs）推动机器人技术发展的努力不断增长，视觉-语言-动作（VLA）模型最近吸引了显著的关注。通过大规模统一视觉、语言和动作数据，这些模型旨在学习能够在多样化的任务、物体、代理和环境中泛化的策略。这种泛化能力有望使机器人能够通过最少或无需额外的任务特定数据来解决新的下游任务，从而促进更灵活和可扩展的实际应用部署。不同于以往专注于动作表示或高层模型架构的综述，本文提供了一种全面的端到端综述，整合了VLA系统的软件和硬件组件。特别地，本文对VLA进行了系统的回顾，涵盖了其策略和架构演变、架构和构建块、特定模态的处理技术以及学习范式。此外，为了支持VLA在实际机器人应用中的部署，本文还回顾了常用机器人平台、数据收集策略、公开可用的数据集、数据增强方法以及评估基准。在整个综合综述中，本文旨在为机器人社区在实际机器人系统中应用VLA提供实用指导。所有按训练方法、评估方法、模态和数据集分类的参考文献均在我们项目网站上的表格中提供：this https URL。', 'title_zh': '视觉-语言-行动模型在机器人领域的研究：面向实际应用的综述'}
{'arxiv_id': 'arXiv:2510.07074', 'title': 'LuxInstruct: A Cross-Lingual Instruction Tuning Dataset For Luxembourgish', 'authors': 'Fred Philippy, Laura Bernardy, Siwen Guo, Jacques Klein, Tegawendé F. Bissyandé', 'link': 'https://arxiv.org/abs/2510.07074', 'abstract': "Instruction tuning has become a key technique for enhancing the performance of large language models, enabling them to better follow human prompts. However, low-resource languages such as Luxembourgish face severe limitations due to the lack of high-quality instruction datasets. Traditional reliance on machine translation often introduces semantic misalignment and cultural inaccuracies. In this work, we address these challenges by creating a cross-lingual instruction tuning dataset for Luxembourgish, without resorting to machine-generated translations into it. Instead, by leveraging aligned data from English, French, and German, we build a high-quality dataset that preserves linguistic and cultural nuances. We provide evidence that cross-lingual instruction tuning not only improves representational alignment across languages but also the model's generative capabilities in Luxembourgish. This highlights how cross-lingual data curation can avoid the common pitfalls of machine-translated data and directly benefit low-resource language development.", 'abstract_zh': '跨语言指令调优：为卢森堡语创建高质量数据集并提高其生成能力', 'title_zh': 'LuxInstruct: 一种面向卢森堡语的跨语言指令调优数据集'}
{'arxiv_id': 'arXiv:2510.07053', 'title': 'Introspection in Learned Semantic Scene Graph Localisation', 'authors': 'Manshika Charvi Bissessur, Efimia Panagiotaki, Daniele De Martini', 'link': 'https://arxiv.org/abs/2510.07053', 'abstract': 'This work investigates how semantics influence localisation performance and robustness in a learned self-supervised, contrastive semantic localisation framework. After training a localisation network on both original and perturbed maps, we conduct a thorough post-hoc introspection analysis to probe whether the model filters environmental noise and prioritises distinctive landmarks over routine clutter. We validate various interpretability methods and present a comparative reliability analysis. Integrated gradients and Attention Weights consistently emerge as the most reliable probes of learned behaviour. A semantic class ablation further reveals an implicit weighting in which frequent objects are often down-weighted. Overall, the results indicate that the model learns noise-robust, semantically salient relations about place definition, thereby enabling explainable registration under challenging visual and structural variations.', 'abstract_zh': '本研究探讨语义如何影响在一种学习驱动的自监督对比语义定位框架中的定位性能和鲁棒性。经过在原始和扰动地图上训练定位网络后，我们进行了一项深入的后验反省分析，以探查模型是否能够过滤环境噪声并优先考虑显著地标而非常规杂乱。我们验证了多种解释性方法，并进行了可靠性比较分析。综合梯度和注意力权重一致地被认为是研究学习行为最可靠的探针。进一步的语义类别消融揭示了一种隐含的加权方式，其中频繁出现的对象往往被下调权重。总体而言，结果表明模型学习了对于噪声具有鲁棒性且语义上显著的空间定义关系，从而在具有挑战性的视觉和结构变异下实现可解释的对齐。', 'title_zh': '学习得到的语义场景图定位中的内省'}
{'arxiv_id': 'arXiv:2510.07048', 'title': 'Search-R3: Unifying Reasoning and Embedding Generation in Large Language Models', 'authors': 'Yuntao Gui, James Cheng', 'link': 'https://arxiv.org/abs/2510.07048', 'abstract': "Despite their remarkable natural language understanding capabilities, Large Language Models (LLMs) have been underutilized for retrieval tasks. We present Search-R3, a novel framework that addresses this limitation by adapting LLMs to generate search embeddings as a direct output of their reasoning process. Our approach exploits LLMs' chain-of-thought capabilities, allowing them to produce more effective embeddings by reasoning step-by-step through complex semantic analyses. We implement this through three complementary mechanisms. (1) a supervised learning stage enables the model's ability to produce quality embeddings, (2) a reinforcement learning (RL) methodology that optimizes embedding generation alongside reasoning, and (3) a specialized RL environment that efficiently handles evolving embedding representations without requiring complete corpus re-encoding at each training iteration. Our extensive evaluations on diverse benchmarks demonstrate that Search-R3 significantly outperforms prior methods by unifying the reasoning and embedding generation processes. This integrated post-training approach represents a substantial advancement in handling complex knowledge-intensive tasks that require both sophisticated reasoning and effective information retrieval. Project page: this https URL", 'abstract_zh': '尽管大型语言模型（LLMs）具备非凡的自然语言理解能力，但它们在检索任务中的利用程度较低。我们提出了一种名为Search-R3的新型框架，通过将LLMs改编为直接生成搜索嵌入，从而弥补这一不足。我们的方法利用了LLMs的逐步推理能力，使其能够通过复杂的语义分析进行逐步推理，从而生成更有效的嵌入。我们通过三种互补机制实现这一目标。（1）监督学习阶段使模型能够生成高质量的嵌入；（2）结合推理优化嵌入生成的强化学习（RL）方法；（3）专门的RL环境，能够在每次训练迭代时高效处理不断变化的嵌入表示，而无需每次都重新编码整个语料库。我们在多种基准上的广泛评估表明，Search-R3显著优于先前的方法，通过将推理和嵌入生成过程统一起来。这种集成的后训练方法代表了处理需要复杂推理和有效信息检索的密集型知识任务的重大进展。项目页面：这个 https URL。', 'title_zh': 'Search-R3: 在大型语言模型中统一推理和嵌入生成'}
{'arxiv_id': 'arXiv:2510.07035', 'title': 'Unified Molecule Pre-training with Flexible 2D and 3D Modalities: Single and Paired Modality Integration', 'authors': 'Tengwei Song, Min Wu, Yuan Fang', 'link': 'https://arxiv.org/abs/2510.07035', 'abstract': 'Molecular representation learning plays a crucial role in advancing applications such as drug discovery and material design. Existing work leverages 2D and 3D modalities of molecular information for pre-training, aiming to capture comprehensive structural and geometric insights. However, these methods require paired 2D and 3D molecular data to train the model effectively and prevent it from collapsing into a single modality, posing limitations in scenarios where a certain modality is unavailable or computationally expensive to generate. To overcome this limitation, we propose FlexMol, a flexible molecule pre-training framework that learns unified molecular representations while supporting single-modality input. Specifically, inspired by the unified structure in vision-language models, our approach employs separate models for 2D and 3D molecular data, leverages parameter sharing to improve computational efficiency, and utilizes a decoder to generate features for the missing modality. This enables a multistage continuous learning process where both modalities contribute collaboratively during training, while ensuring robustness when only one modality is available during inference. Extensive experiments demonstrate that FlexMol achieves superior performance across a wide range of molecular property prediction tasks, and we also empirically demonstrate its effectiveness with incomplete data. Our code and data are available at this https URL.', 'abstract_zh': '分子表示学习在推动药物发现和材料设计等应用方面发挥着关键作用。现有工作利用分子的2D和3D模态进行预训练，旨在捕捉全面的结构和几何洞察。然而，这些方法需要配对的2D和3D分子数据来有效训练模型并防止其塌缩到单一模态，这在某些模态不可用或生成计算成本较高时会受到限制。为克服这一限制，我们提出了FlexMol，这是一个灵活的分子预训练框架，可以在支持单一模态输入的同时学习统一的分子表示。具体来说，受视觉语言模型中统一结构的启发，我们的方法为2D和3D分子数据分别使用独立模型，并通过参数共享提高计算效率，利用解码器生成缺失模态的特征。这使得在训练过程中两种模态能够协同贡献，并且在仅有一种模态可用进行推理时也能保证鲁棒性。广泛的实验表明，FlexMol 在多种分子属性预测任务中实现了优越的性能，并且我们还通过不完整数据的实验证明了其有效性。我们的代码和数据可在以下网址获取。', 'title_zh': '统一分子预训练：灵活的2D和3D模态集成，单一模态与配对模态集成'}
{'arxiv_id': 'arXiv:2510.07024', 'title': 'Mining the Mind: What 100M Beliefs Reveal About Frontier LLM Knowledge', 'authors': 'Shrestha Ghosh, Luca Giordano, Yujia Hu, Tuan-Phong Nguyen, Simon Razniewski', 'link': 'https://arxiv.org/abs/2510.07024', 'abstract': "LLMs are remarkable artifacts that have revolutionized a range of NLP and AI tasks. A significant contributor is their factual knowledge, which, to date, remains poorly understood, and is usually analyzed from biased samples. In this paper, we take a deep tour into the factual knowledge (or beliefs) of a frontier LLM, based on GPTKB v1.5 (Hu et al., 2025a), a recursively elicited set of 100 million beliefs of one of the strongest currently available frontier LLMs, GPT-4.1. We find that the models' factual knowledge differs quite significantly from established knowledge bases, and that its accuracy is significantly lower than indicated by previous benchmarks. We also find that inconsistency, ambiguity and hallucinations are major issues, shedding light on future research opportunities concerning factual LLM knowledge.", 'abstract_zh': '大规模语言模型是革命性的成果，已重塑一系列NLP和AI任务。其事实知识是重要贡献者，至今仍 poorly understood，通常是从有偏样本中进行分析。本文基于GPTKB v1.5（Hu et al., 2025a），对前沿LLM的fact知识进行了深入探讨，GPTKB v1.5 是一个递归获取的包含1亿条信念的集合，来自于当前最强的前沿LLM之一GPT-4。我们发现，模型的事实知识与已建立的知识库存在显著差异，其准确性显著低于以往基准测试所显示的。我们还发现不一致、模糊性和幻觉是主要问题，这为未来关于事实LLM知识的研究提供了新的契机。', 'title_zh': '探索心灵：1亿条信念揭示的前沿LLM知识'}
{'arxiv_id': 'arXiv:2510.07022', 'title': 'Federated Unlearning in the Wild: Rethinking Fairness and Data Discrepancy', 'authors': 'ZiHeng Huang, Di Wu, Jun Bai, Jiale Zhang, Sicong Cao, Ji Zhang, Yingjie Hu', 'link': 'https://arxiv.org/abs/2510.07022', 'abstract': 'Machine unlearning is critical for enforcing data deletion rights like the "right to be forgotten." As a decentralized paradigm, Federated Learning (FL) also requires unlearning, but realistic implementations face two major challenges. First, fairness in Federated Unlearning (FU) is often overlooked. Exact unlearning methods typically force all clients into costly retraining, even those uninvolved. Approximate approaches, using gradient ascent or distillation, make coarse interventions that can unfairly degrade performance for clients with only retained data. Second, most FU evaluations rely on synthetic data assumptions (IID/non-IID) that ignore real-world heterogeneity. These unrealistic benchmarks obscure the true impact of unlearning and limit the applicability of current methods. We first conduct a comprehensive benchmark of existing FU methods under realistic data heterogeneity and fairness conditions. We then propose a novel, fairness-aware FU approach, Federated Cross-Client-Constrains Unlearning (FedCCCU), to explicitly address both challenges. FedCCCU offers a practical and scalable solution for real-world FU. Experimental results show that existing methods perform poorly in realistic settings, while our approach consistently outperforms them.', 'abstract_zh': '机器遗忘对于执行类似于“被遗忘的权利”数据删除权限至关重要。作为去中心化的范式，联邦学习（FL）也需要进行遗忘操作，但实际实现面临着两大挑战。首先，联邦遗忘（FU）的公平性经常被忽视。精确的遗忘方法通常要求所有客户端进行代价高昂的重新训练，即使对于那些不相关的客户端也是如此。其次，大多数FU评估依赖于合成数据假设（IID/非IID），忽略了现实世界中的异质性。这些不切实际的基准掩蔽了遗忘的真正影响，并限制了当前方法的应用范围。我们首先在现实数据异质性和公平性条件下对现有的FU方法进行了全面的基准测试。然后，我们提出了一种新的基于公平性的FU方法——联邦跨客户端约束遗忘（FedCCCU），以明确解决上述挑战。FedCCCU提供了在实际应用场景中进行联邦遗忘的一种实用且可扩展的解决方案。实验结果表明，现有方法在现实环境中表现不佳，而我们的方法则始终优于它们。', 'title_zh': '野外联邦遗忘：重新思考公平性和数据差异性'}
{'arxiv_id': 'arXiv:2510.07019', 'title': 'Native Hybrid Attention for Efficient Sequence Modeling', 'authors': 'Jusen Du, Jiaxi Hu, Tao Zhang, Weigao Sun, Yu Cheng', 'link': 'https://arxiv.org/abs/2510.07019', 'abstract': 'Transformers excel at sequence modeling but face quadratic complexity, while linear attention offers improved efficiency but often compromises recall accuracy over long contexts. In this work, we introduce Native Hybrid Attention (NHA), a novel hybrid architecture of linear and full attention that integrates both intra \\& inter-layer hybridization into a unified layer design. NHA maintains long-term context in key-value slots updated by a linear RNN, and augments them with short-term tokens from a sliding window. A single \\texttt{softmax attention} operation is then applied over all keys and values, enabling per-token and per-head context-dependent weighting without requiring additional fusion parameters. The inter-layer behavior is controlled through a single hyperparameter, the sliding window size, which allows smooth adjustment between purely linear and full attention while keeping all layers structurally uniform. Experimental results show that NHA surpasses Transformers and other hybrid baselines on recall-intensive and commonsense reasoning tasks. Furthermore, pretrained LLMs can be structurally hybridized with NHA, achieving competitive accuracy while delivering significant efficiency gains. Code is available at this https URL.', 'abstract_zh': 'Native Hybrid Attention: A Unified Hybrid Architecture of Linear and Full Attention', 'title_zh': '原生混合注意力机制高效序列建模'}
{'arxiv_id': 'arXiv:2510.07000', 'title': 'Pragyaan: Designing and Curating High-Quality Cultural Post-Training Datasets for Indian Languages', 'authors': 'Neel Prabhanjan Rachamalla, Aravind Konakalla, Gautam Rajeev, Ashish Kulkarni, Chandra Khatri, Shubham Agarwal', 'link': 'https://arxiv.org/abs/2510.07000', 'abstract': 'The effectiveness of Large Language Models (LLMs) depends heavily on the availability of high-quality post-training data, particularly instruction-tuning and preference-based examples. Existing open-source datasets, however, often lack multilingual coverage, cultural grounding, and suffer from task diversity gaps that are especially pronounced for Indian languages. We introduce a human-in-the-loop pipeline that combines translations with synthetic expansion to produce reliable and diverse Indic post-training data. Using this pipeline, we curate two datasets: Pragyaan-IT (22.5K) and Pragyaan-Align (100K) across 10 Indian languages covering 13 broad and 56 sub-categories, leveraging 57 diverse datasets. Our dataset protocol incorporates several often-overlooked dimensions and emphasize task diversity, multi-turn dialogue, instruction fidelity, safety alignment, and preservation of cultural nuance, providing a foundation for more inclusive and effective multilingual LLMs.', 'abstract_zh': '大型语言模型（LLMs）的效果在很大程度上依赖于高质量的后训练数据，特别是指令调优和基于偏好的示例。现有的开源数据集往往缺乏多语言覆盖、文化基础，并且在任务多样性方面存在特别明显的缺口，尤其是对于印度语言。我们提出了一种人机协作流水线，结合翻译与合成扩展，生成可靠且多样的印度语言后训练数据。使用此流水线，我们构建了两个数据集：Pragyaan-IT（22,500）和Pragyaan-Align（100,000），涵盖10种印度语言，包括13个大类和56个子类别，利用57个不同的数据集。我们的数据集协议包含了多个常被忽视的维度，强调任务多样性、多轮对话、指令忠实度、安全性对齐以及文化细微差别的保存，为更包容和有效的多语言大型语言模型提供基础。', 'title_zh': 'Pragyaan: 设计和策展高质量的印度语言文化后训练数据集'}
{'arxiv_id': 'arXiv:2510.06997', 'title': 'The Limits of Goal-Setting Theory in LLM-Driven Assessment', 'authors': 'Mrityunjay Kumar', 'link': 'https://arxiv.org/abs/2510.06997', 'abstract': "Many users interact with AI tools like ChatGPT using a mental model that treats the system as human-like, which we call Model H. According to goal-setting theory, increased specificity in goals should reduce performance variance. If Model H holds, then prompting a chatbot with more detailed instructions should lead to more consistent evaluation behavior.\nThis paper tests that assumption through a controlled experiment in which ChatGPT evaluated 29 student submissions using four prompts with increasing specificity. We measured consistency using intra-rater reliability (Cohen's Kappa) across repeated runs.\nContrary to expectations, performance did not improve consistently with increased prompt specificity, and performance variance remained largely unchanged. These findings challenge the assumption that LLMs behave like human evaluators and highlight the need for greater robustness and improved input integration in future model development.", 'abstract_zh': "许多用户使用类似于ChatGPT的AI工具时，将其视为类人系统，我们称之为Model H。根据目标设定理论，目标设定的细化应减少性能的差异性。如果Model H成立，那么通过更详细的指令提示聊天机器人应该会导致更一致的评估行为。本文通过一项受控实验测试了这一假设，该实验让ChatGPT对29份学生提交的作品进行了评价，并通过重复运行内评分者信度（Cohen's Kappa）来衡量一致性。令人意外的是，随着提示的细化，性能并未一致提高，性能的差异性也没有显著变化。这些发现挑战了LLMs表现得像人类评估者的假设，强调了未来模型开发中需要增强鲁棒性和提高输入集成能力。", 'title_zh': '目标设定理论在驱动LLM评估中的局限性'}
{'arxiv_id': 'arXiv:2510.06975', 'title': 'VelLMes: A high-interaction AI-based deception framework', 'authors': 'Muris Sladić, Veronica Valeros, Carlos Catania, Sebastian Garcia', 'link': 'https://arxiv.org/abs/2510.06975', 'abstract': "There are very few SotA deception systems based on Large Language Models. The existing ones are limited only to simulating one type of service, mainly SSH shells. These systems - but also the deception technologies not based on LLMs - lack an extensive evaluation that includes human attackers. Generative AI has recently become a valuable asset for cybersecurity researchers and practitioners, and the field of cyber-deception is no exception. Researchers have demonstrated how LLMs can be leveraged to create realistic-looking honeytokens, fake users, and even simulated systems that can be used as honeypots. This paper presents an AI-based deception framework called VelLMes, which can simulate multiple protocols and services such as SSH Linux shell, MySQL, POP3, and HTTP. All of these can be deployed and used as honeypots, thus VelLMes offers a variety of choices for deception design based on the users' needs. VelLMes is designed to be attacked by humans, so interactivity and realism are key for its performance. We evaluate the generative capabilities and the deception capabilities. Generative capabilities were evaluated using unit tests for LLMs. The results of the unit tests show that, with careful prompting, LLMs can produce realistic-looking responses, with some LLMs having a 100% passing rate. In the case of the SSH Linux shell, we evaluated deception capabilities with 89 human attackers. The results showed that about 30% of the attackers thought that they were interacting with a real system when they were assigned an LLM-based honeypot. Lastly, we deployed 10 instances of the SSH Linux shell honeypot on the Internet to capture real-life attacks. Analysis of these attacks showed us that LLM honeypots simulating Linux shells can perform well against unstructured and unexpected attacks on the Internet, responding correctly to most of the issued commands.", 'abstract_zh': '基于大语言模型的先进欺骗系统非常少。现有的系统仅限于模拟一种服务，主要是SSH终端。这些系统以及其他非基于大语言模型的欺骗技术缺乏包含人类攻击者的广泛评估。生成式AI最近已成为网络安全研究人员和 practitioner 的宝贵资产，欺骗技术领域也不例外。研究人员已经展示了如何利用大语言模型生成逼真的蜜罐、虚假用户，甚至是模拟系统作为蜜罐。本文提出了一种基于AI的欺骗框架VelLMes，它可以模拟多种协议和服务，如SSH Linux终端、MySQL、POP3和HTTP。这些都可以部署和使用为蜜罐，因此VelLMes提供了多种基于用户需求的欺骗设计选择。VelLMes设计为接受人类攻击，因此交互性和逼真性是其性能的关键。我们评估了生成能力和欺骗能力。生成能力通过大语言模型的单元测试进行评估。单元测试的结果显示，在精心提示下，大语言模型可以生成逼真的响应，有些模型通过率为100%。对于SSH Linux终端，我们使用89名人类攻击者评估了欺骗能力。结果显示，约30%的攻击者认为他们与基于大语言模型的蜜罐进行了真实的交互。最后，我们在互联网上部署了10个SSH Linux终端蜜罐实例以捕获真实攻击。这些攻击的分析表明，模拟Linux终端的LLM蜜罐在应对互联网上的非结构化和非预期攻击时表现良好，正确响应了大多数发出的命令。', 'title_zh': 'VelLMes：一种高交互人工智能欺骗框架'}
{'arxiv_id': 'arXiv:2510.06969', 'title': 'Learning Global Representation from Queries for Vectorized HD Map Construction', 'authors': 'Shoumeng Qiu, Xinrun Li, Yang Long, Xiangyang Xue, Varun Ojha, Jian Pu', 'link': 'https://arxiv.org/abs/2510.06969', 'abstract': 'The online construction of vectorized high-definition (HD) maps is a cornerstone of modern autonomous driving systems. State-of-the-art approaches, particularly those based on the DETR framework, formulate this as an instance detection problem. However, their reliance on independent, learnable object queries results in a predominantly local query perspective, neglecting the inherent global representation within HD maps. In this work, we propose \\textbf{MapGR} (\\textbf{G}lobal \\textbf{R}epresentation learning for HD \\textbf{Map} construction), an architecture designed to learn and utilize a global representations from queries. Our method introduces two synergistic modules: a Global Representation Learning (GRL) module, which encourages the distribution of all queries to better align with the global map through a carefully designed holistic segmentation task, and a Global Representation Guidance (GRG) module, which endows each individual query with explicit, global-level contextual information to facilitate its optimization. Evaluations on the nuScenes and Argoverse2 datasets validate the efficacy of our approach, demonstrating substantial improvements in mean Average Precision (mAP) compared to leading baselines.', 'abstract_zh': '基于全局表示学习的高精度emap构建方法：MapGR', 'title_zh': '基于查询学习全局表示的向量化高清地图构建'}
{'arxiv_id': 'arXiv:2510.06967', 'title': 'Generating Surface for Text-to-3D using 2D Gaussian Splatting', 'authors': 'Huanning Dong, Fan Li, Ping Kuang, Jianwen Min', 'link': 'https://arxiv.org/abs/2510.06967', 'abstract': 'Recent advancements in Text-to-3D modeling have shown significant potential for the creation of 3D content. However, due to the complex geometric shapes of objects in the natural world, generating 3D content remains a challenging task. Current methods either leverage 2D diffusion priors to recover 3D geometry, or train the model directly based on specific 3D representations. In this paper, we propose a novel method named DirectGaussian, which focuses on generating the surfaces of 3D objects represented by surfels. In DirectGaussian, we utilize conditional text generation models and the surface of a 3D object is rendered by 2D Gaussian splatting with multi-view normal and texture priors. For multi-view geometric consistency problems, DirectGaussian incorporates curvature constraints on the generated surface during optimization process. Through extensive experiments, we demonstrate that our framework is capable of achieving diverse and high-fidelity 3D content creation.', 'abstract_zh': 'Recent advancements in Text-to-3D modeling have shown significant potential for the creation of 3D content. However, due to the complex geometric shapes of objects in the natural world, generating 3D content remains a challenging task. Current methods either leverage 2D diffusion priors to recover 3D geometry, or train the model directly based on specific 3D representations. In this paper, we propose a novel method named DirectGaussian, which focuses on generating the surfaces of 3D objects represented by surfels. In DirectGaussian, we utilize conditional text generation models and the surface of a 3D object is rendered by 2D Gaussian splatting with multi-view normal and texture priors. For multi-view geometric consistency problems, DirectGaussian incorporates curvature constraints on the generated surface during optimization process. Through extensive experiments, we demonstrate that our framework is capable of achieving diverse and high-fidelity 3D content creation.', 'title_zh': '使用2D高斯点绘制的从文本生成三维表面方法'}
{'arxiv_id': 'arXiv:2510.06965', 'title': 'EDUMATH: Generating Standards-aligned Educational Math Word Problems', 'authors': 'Bryan R. Christ, Penelope Molitz, Jonathan Kropko, Thomas Hartvigsen', 'link': 'https://arxiv.org/abs/2510.06965', 'abstract': "Math word problems (MWPs) are critical K-12 educational tools, and customizing them to students' interests and ability levels can increase learning outcomes. However, teachers struggle to find time to customize MWPs for each student given large class sizes and increasing burnout. We propose that LLMs can support math education by generating MWPs customized to student interests and math education standards. To this end, we use a joint human expert-LLM judge approach to evaluate over 11,000 MWPs generated by open and closed LLMs and develop the first teacher-annotated dataset for standards-aligned educational MWP generation. We show the value of our data by using it to train a 12B open model that matches the performance of larger and more capable open models. We also use our teacher-annotated data to train a text classifier that enables a 30B open LLM to outperform existing closed baselines without any training. Next, we show our models' MWPs are more similar to human-written MWPs than those from existing models. We conclude by conducting the first study of customized LLM-generated MWPs with grade school students, finding they perform similarly on our models' MWPs relative to human-written MWPs but consistently prefer our customized MWPs.", 'abstract_zh': '数学文字问题（MWPs）是关键的K-12教育工具，将其个性化以适应学生的兴趣和能力水平可以提高学习成果。然而，在大班授课和不断增加的教学压力下，教师难以为每位学生量身定制MWPs。我们提出，大型语言模型（LLMs）可以通过生成符合学生兴趣和数学教育标准的MWPs来支持数学教育。为此，我们采用人工专家和LLM评判员联合评估了超过11,000个由开放和封闭的LLM生成的MWPs，并开发了首个针对标准对齐的教育MWPs生成的教师标注数据集。我们通过使用该数据集训练一个12亿参数的开放模型，证实了其性能与更大和更强大的开放模型相当。我们还使用教师标注的数据训练了一个文本分类器，使得一个30亿参数的开放LLM在没有任何训练的情况下超过了现有的封闭基线。此外，我们表明我们的模型生成的MWPs比现有模型生成的MWPs更类似于人工撰写的MWPs。最后，我们进行了首次针对小学生的研究，发现他们在我们的模型生成的MWPs上的表现与人工撰写的MWPs相当，但始终更偏好我们个性化生成的MWPs。', 'title_zh': 'EDUMATH: 生成符合标准的教育数学文字题'}
{'arxiv_id': 'arXiv:2510.06961', 'title': 'Open ASR Leaderboard: Towards Reproducible and Transparent Multilingual and Long-Form Speech Recognition Evaluation', 'authors': 'Vaibhav Srivastav, Steven Zheng, Eric Bezzam, Eustache Le Bihan, Nithin Koluguri, Piotr Żelasko, Somshubra Majumdar, Adel Moumen, Sanchit Gandhi', 'link': 'https://arxiv.org/abs/2510.06961', 'abstract': 'Despite rapid progress, ASR evaluation remains saturated with short-form English, and efficiency is rarely reported. We present the Open ASR Leaderboard, a fully reproducible benchmark and interactive leaderboard comparing 60+ open-source and proprietary systems across 11 datasets, including dedicated multilingual and long-form tracks. We standardize text normalization and report both word error rate (WER) and inverse real-time factor (RTFx), enabling fair accuracy-efficiency comparisons. For English transcription, Conformer encoders paired with LLM decoders achieve the best average WER but are slower, while CTC and TDT decoders deliver much better RTFx, making them attractive for long-form and offline use. Whisper-derived encoders fine-tuned for English improve accuracy but often trade off multilingual coverage. All code and dataset loaders are open-sourced to support transparent, extensible evaluation.', 'abstract_zh': '尽管取得了快速进展，ASR评估仍主要集中在短格式英语上，效率方面的表现鲜有报道。我们介绍了Open ASR Leaderboard，这是一个完全可再现的标准测试基准和交互式排行榜，它比较了11个数据集上的60多种开源和专有系统，包括专门的多语言和长格式赛道。我们统一了文本规范化的方法，并报告了字错误率（WER）和逆实时因子（RTFx），以实现公平的准确性和效率比较。对于英语转录，Conformer编码器与LLM解码器的组合取得了最佳平均WER，但速率为慢，而CTC和TDT解码器在RTFx方面表现出色，使其适用于长格式和离线使用。从Whisper衍生出的编码器在对英语进行微调后能提升准确性，但往往以多语言覆盖范围为代价。所有代码和数据集加载器均开源，以支持透明且扩展性强的评估。', 'title_zh': '开放ASR排行榜：迈向可重复和透明的多语言和长时语音识别评价'}
{'arxiv_id': 'arXiv:2510.06949', 'title': 'Grouped Differential Attention', 'authors': 'Junghwan Lim, Sungmin Lee, Dongseok Kim, Wai Ting Cheung, Beomgyu Kim, Taehwan Kim, Haesol Lee, Junhyeok Lee, Dongpin Oh, Eunhwan Park', 'link': 'https://arxiv.org/abs/2510.06949', 'abstract': 'The self-attention mechanism, while foundational to modern Transformer architectures, suffers from a critical inefficiency: it frequently allocates substantial attention to redundant or noisy context. Differential Attention addressed this by using subtractive attention maps for signal and noise, but its required balanced head allocation imposes rigid constraints on representational flexibility and scalability.\nTo overcome this, we propose Grouped Differential Attention (GDA), a novel approach that introduces unbalanced head allocation between signal-preserving and noise-control groups. GDA significantly enhances signal focus by strategically assigning more heads to signal extraction and fewer to noise-control, stabilizing the latter through controlled repetition (akin to GQA). This design achieves stronger signal fidelity with minimal computational overhead. We further extend this principle to group-differentiated growth, a scalable strategy that selectively replicates only the signal-focused heads, thereby ensuring efficient capacity expansion.\nThrough large-scale pretraining and continual training experiments, we demonstrate that moderate imbalance ratios in GDA yield substantial improvements in generalization and stability compared to symmetric baselines. Our results collectively establish that ratio-aware head allocation and selective expansion offer an effective and practical path toward designing scalable, computation-efficient Transformer architectures.', 'abstract_zh': '组分差分注意力（GDA）：具有不平衡头分配的信号增强注意力机制', 'title_zh': '分组差异注意力'}
{'arxiv_id': 'arXiv:2510.06938', 'title': 'Expressive and Scalable Quantum Fusion for Multimodal Learning', 'authors': 'Tuyen Nguyen, Trong Nghia Hoang, Phi Le Nguyen, Hai L. Vu, Truong Cong Thang', 'link': 'https://arxiv.org/abs/2510.06938', 'abstract': 'The aim of this paper is to introduce a quantum fusion mechanism for multimodal learning and to establish its theoretical and empirical potential. The proposed method, called the Quantum Fusion Layer (QFL), replaces classical fusion schemes with a hybrid quantum-classical procedure that uses parameterized quantum circuits to learn entangled feature interactions without requiring exponential parameter growth. Supported by quantum signal processing principles, the quantum component efficiently represents high-order polynomial interactions across modalities with linear parameter scaling, and we provide a separation example between QFL and low-rank tensor-based methods that highlights potential quantum query advantages. In simulation, QFL consistently outperforms strong classical baselines on small but diverse multimodal tasks, with particularly marked improvements in high-modality regimes. These results suggest that QFL offers a fundamentally new and scalable approach to multimodal fusion that merits deeper exploration on larger systems.', 'abstract_zh': '本文旨在介绍一种用于多模态学习的量子融合机制，并建立其理论和实证潜力。所提出的方法称为量子融合层（QFL），该方法用参数化量子电路替代经典融合方案，无需参数指数级增长即可学习纠缠特征交互。基于量子信号处理原理，量子组件以线性参数缩放高效地表示各模态间的高阶多项式交互，并通过一个分离示例展示了QFL与低秩张量基方法之间的潜在量子查询优势。在模拟中，QFL在小型但多样的多模态任务中始终优于强大的经典基线方法，特别是在高模态范式中表现尤为显著。这些结果表明，QFL提供了一种基本新且可扩展的多模态融合方法，值得在更大系统中进行更深入的研究。', 'title_zh': '表达丰富且可扩展的多模态量子融合'}
{'arxiv_id': 'arXiv:2510.06919', 'title': 'Bayesian Nonparametric Dynamical Clustering of Time Series', 'authors': 'Adrián Pérez-Herrero, Paulo Félix, Jesús Presedo, Carl Henrik Ek', 'link': 'https://arxiv.org/abs/2510.06919', 'abstract': 'We present a method that models the evolution of an unbounded number of time series clusters by switching among an unknown number of regimes with linear dynamics. We develop a Bayesian non-parametric approach using a hierarchical Dirichlet process as a prior on the parameters of a Switching Linear Dynamical System and a Gaussian process prior to model the statistical variations in amplitude and temporal alignment within each cluster. By modeling the evolution of time series patterns, the method avoids unnecessary proliferation of clusters in a principled manner. We perform inference by formulating a variational lower bound for off-line and on-line scenarios, enabling efficient learning through optimization. We illustrate the versatility and effectiveness of the approach through several case studies of electrocardiogram analysis using publicly available databases.', 'abstract_zh': '我们提出了一种方法，通过在未知数量的动态模式之间切换来建模任意数量的时间序列聚类的演变。该方法使用分层Dirichlet过程作为切换线性动力系统参数的先验分布，并使用高斯过程先验来建模每个聚类内振幅和时间对齐的统计变化。通过建模时间序列模式的演变，该方法能够以一种正当的方式来避免聚类的无谓增多。我们通过形式化离线和在线场景下的变分下界来进行推断，从而通过优化实现高效学习。通过使用公开可用数据库中的心电图分析案例研究，我们展示了该方法的灵活性和有效性。', 'title_zh': '基于贝叶斯非参数动态聚类的时间序列分析'}
{'arxiv_id': 'arXiv:2510.06915', 'title': 'LongRM: Revealing and Unlocking the Context Boundary of Reward Modeling', 'authors': 'Zecheng Tang, Baibei Ji, Quantong Qiu, Haitian Wang, Xiaobo Liang, Juntao Li, Min Zhang', 'link': 'https://arxiv.org/abs/2510.06915', 'abstract': "Reward model (RM) plays a pivotal role in aligning large language model (LLM) with human preferences. As real-world applications increasingly involve long history trajectories, e.g., LLM agent, it becomes indispensable to evaluate whether a model's responses are not only high-quality but also grounded in and consistent with the provided context. Yet, current RMs remain confined to short-context settings and primarily focus on response-level attributes (e.g., safety or helpfulness), while largely neglecting the critical dimension of long context-response consistency. In this work, we introduce Long-RewardBench, a benchmark specifically designed for long-context RM evaluation, featuring both Pairwise Comparison and Best-of-N tasks. Our preliminary study reveals that even state-of-the-art generative RMs exhibit significant fragility in long-context scenarios, failing to maintain context-aware preference judgments. Motivated by the analysis of failure patterns observed in model outputs, we propose a general multi-stage training strategy that effectively scales arbitrary models into robust Long-context RMs (LongRMs). Experiments show that our approach not only substantially improves performance on long-context evaluation but also preserves strong short-context capability. Notably, our 8B LongRM outperforms much larger 70B-scale baselines and matches the performance of the proprietary Gemini 2.5 Pro model.", 'abstract_zh': 'Long-RewardBench: 一种专门用于长上下文强化评估的标准基准', 'title_zh': 'LongRM: 揭示和解锁奖励建模的上下文边界'}
{'arxiv_id': 'arXiv:2510.06913', 'title': 'DecompGAIL: Learning Realistic Traffic Behaviors with Decomposed Multi-Agent Generative Adversarial Imitation Learning', 'authors': 'Ke Guo, Haochen Liu, Xiaojun Wu, Chen Lv', 'link': 'https://arxiv.org/abs/2510.06913', 'abstract': "Realistic traffic simulation is critical for the development of autonomous driving systems and urban mobility planning, yet existing imitation learning approaches often fail to model realistic traffic behaviors. Behavior cloning suffers from covariate shift, while Generative Adversarial Imitation Learning (GAIL) is notoriously unstable in multi-agent settings. We identify a key source of this instability: irrelevant interaction misguidance, where a discriminator penalizes an ego vehicle's realistic behavior due to unrealistic interactions among its neighbors. To address this, we propose Decomposed Multi-agent GAIL (DecompGAIL), which explicitly decomposes realism into ego-map and ego-neighbor components, filtering out misleading neighbor: neighbor and neighbor: map interactions. We further introduce a social PPO objective that augments ego rewards with distance-weighted neighborhood rewards, encouraging overall realism across agents. Integrated into a lightweight SMART-based backbone, DecompGAIL achieves state-of-the-art performance on the WOMD Sim Agents 2025 benchmark.", 'abstract_zh': '基于分解的多Agent GAIL及其在WOMD Sim Agents 2025基准上的性能', 'title_zh': 'DecompGAIL：分解多agents生成对抗 imitation 学习学习真实交通行为'}
{'arxiv_id': 'arXiv:2510.06908', 'title': 'Emotionally Vulnerable Subtype of Internet Gaming Disorder: Measuring and Exploring the Pathology of Problematic Generative AI Use', 'authors': 'Haocan Sun, Di Wua, Weizi Liu, Guoming Yua, Mike Yao', 'link': 'https://arxiv.org/abs/2510.06908', 'abstract': 'Concerns over the potential over-pathologization of generative AI (GenAI) use and the lack of conceptual clarity surrounding GenAI addiction call for empirical tools and theoretical refinement. This study developed and validated the PUGenAIS-9 (Problematic Use of Generative Artificial Intelligence Scale-9 items) and examined whether PUGenAIS reflects addiction-like patterns under the Internet Gaming Disorder (IGD) framework. Using samples from China and the United States (N = 1,508), we conducted confirmatory factor analysis and identified a robust 31-item structure across nine IGD-based dimensions. We then derived the PUGenAIS-9 by selecting the highest-loading items from each dimension and validated its structure in an independent sample (N = 1,426). Measurement invariance tests confirmed its stability across nationality and gender. Person-centered (latent profile analysis) and variable-centered (network analysis) approaches found that PUGenAIS matches the traits of the emotionally vulnerable subtype of IGD, not the competence-based kind. These results support using PUGenAIS-9 to identify problematic GenAI use and show the need to rethink digital addiction with an ICD (infrastructures, content, and device) model. This keeps addiction research responsive to new media while avoiding over-pathologizing.', 'abstract_zh': '关于生成人工智能(GenAI)使用可能的过度病理化以及GenAI成瘾概念不清的问题，需要开发实证工具并进行理论精炼。本研究开发并验证了PUGenAIS-9（问题性使用生成人工智能量表-9项）并探讨了PUGenAIS是否能在互联网游戏障碍(IGD)框架下反映类似成瘾的模式。采用来自中国和美国的样本(N=1,508)，我们进行了 confirmatory factor analysis，并识别出一个由九个IGD基维度组成的稳健的31项结构。然后，我们通过从每个维度中选择载荷最高的项目来推导出PUGenAIS-9，并在独立样本(N=1,426)中验证其结构。测量不变性检验确认其在全国性和性别上的稳定性。以数据为中心（潜在剖面分析）和变量为中心（网络分析）的方法发现，PUGenAIS与IGD中情感易感亚型的特征相符，而非基于能力的类型。这些结果支持使用PUGenAIS-9来识别问题性GenAI使用，并表明需要使用ICD（基础设施、内容和技术设备）模型重新思考数字成瘾，以使成瘾研究能更好地应对新兴媒体，同时避免过度病理化。', 'title_zh': '网络游戏障碍中情感脆弱亚型：测量与探索有问题的生成式人工智能使用病理特征'}
{'arxiv_id': 'arXiv:2510.06907', 'title': 'Angular Constraint Embedding via SpherePair Loss for Constrained Clustering', 'authors': 'Shaojie Zhang, Ke Chen', 'link': 'https://arxiv.org/abs/2510.06907', 'abstract': 'Constrained clustering integrates domain knowledge through pairwise constraints. However, existing deep constrained clustering (DCC) methods are either limited by anchors inherent in end-to-end modeling or struggle with learning discriminative Euclidean embedding, restricting their scalability and real-world applicability. To avoid their respective pitfalls, we propose a novel angular constraint embedding approach for DCC, termed SpherePair. Using the SpherePair loss with a geometric formulation, our method faithfully encodes pairwise constraints and leads to embeddings that are clustering-friendly in angular space, effectively separating representation learning from clustering. SpherePair preserves pairwise relations without conflict, removes the need to specify the exact number of clusters, generalizes to unseen data, enables rapid inference of the number of clusters, and is supported by rigorous theoretical guarantees. Comparative evaluations with state-of-the-art DCC methods on diverse benchmarks, along with empirical validation of theoretical insights, confirm its superior performance, scalability, and overall real-world effectiveness. Code is available at \\href{this https URL}{our repository}.', 'abstract_zh': '约束聚类通过成对约束整合领域知识。然而，现有的深度约束聚类（DCC）方法要么受限于端到端建模中的锚点，要么难以学习具有区分性的欧几里得嵌入，从而限制了它们的可扩展性和实际应用性。为避免各自的不足，我们提出了一种新颖的-angular约束嵌入方法，称为SpherePair。利用具有几何表述的SpherePair损失，我们的方法忠实编码成对约束，在角空间中产生易于聚类的嵌入，有效分离了表示学习和聚类。SpherePair在不冲突的情况下保留了成对关系，消除了指定确切聚类数的需求，适用于未见数据，能够快速推断出聚类数，并由严格的理论保证支持。在多种基准上的对比评估以及理论洞察的实际验证证实了其优异的性能、可扩展性和整体实际有效性。代码可在our repository获取。', 'title_zh': '基于SpherePair损失的角约束嵌入用于约束聚类'}
{'arxiv_id': 'arXiv:2510.06888', 'title': 'M3Retrieve: Benchmarking Multimodal Retrieval for Medicine', 'authors': 'Arkadeep Acharya, Akash Ghosh, Pradeepika Verma, Kitsuchart Pasupa, Sriparna Saha, Priti Singh', 'link': 'https://arxiv.org/abs/2510.06888', 'abstract': 'With the increasing use of RetrievalAugmented Generation (RAG), strong retrieval models have become more important than ever. In healthcare, multimodal retrieval models that combine information from both text and images offer major advantages for many downstream tasks such as question answering, cross-modal retrieval, and multimodal summarization, since medical data often includes both formats. However, there is currently no standard benchmark to evaluate how well these models perform in medical settings. To address this gap, we introduce M3Retrieve, a Multimodal Medical Retrieval Benchmark. M3Retrieve, spans 5 domains,16 medical fields, and 4 distinct tasks, with over 1.2 Million text documents and 164K multimodal queries, all collected under approved licenses. We evaluate leading multimodal retrieval models on this benchmark to explore the challenges specific to different medical specialities and to understand their impact on retrieval performance. By releasing M3Retrieve, we aim to enable systematic evaluation, foster model innovation, and accelerate research toward building more capable and reliable multimodal retrieval systems for medical applications. The dataset and the baselines code are available in this github page this https URL.', 'abstract_zh': '随着检索增强生成（RAG）的使用不断增加，强大的检索模型比以往任何时候都更为重要。在医疗领域，结合文本和图像信息的多模态检索模型为诸如问答、跨模态检索和多模态总结等多种下游任务提供了重大优势，因为医疗数据通常包括这两种格式。然而，目前尚无标准基准来评估这些模型在医疗环境中的表现。为解决这一问题，我们引入了M3Retrieve多模态医疗检索基准。M3Retrieve涵盖了5个领域、16个医疗领域和4项不同的任务，包含超过120万份文本文档和16.4万个多模态查询，所有数据均在获批许可证下收集。我们在这项基准上评估了领先的多模态检索模型，以探索不同医疗专科特有的挑战，并理解其对检索性能的影响。通过发布M3Retrieve，我们旨在促进系统的评估、模型创新，并加速针对医疗应用构建更具能力和可靠性的多模态检索系统的研究。该数据集和baseline代码可在以下github页面获取：this https URL。', 'title_zh': 'M3Retrieve:  multimodal retrieval benchmarking for medicine'}
{'arxiv_id': 'arXiv:2510.06882', 'title': 'Multi-Dimensional Autoscaling of Stream Processing Services on Edge Devices', 'authors': 'Boris Sedlak, Philipp Raith, Andrea Morichetta, Víctor Casamayor Pujol, Schahram Dustdar', 'link': 'https://arxiv.org/abs/2510.06882', 'abstract': 'Edge devices have limited resources, which inevitably leads to situations where stream processing services cannot satisfy their needs. While existing autoscaling mechanisms focus entirely on resource scaling, Edge devices require alternative ways to sustain the Service Level Objectives (SLOs) of competing services. To address these issues, we introduce a Multi-dimensional Autoscaling Platform (MUDAP) that supports fine-grained vertical scaling across both service- and resource-level dimensions. MUDAP supports service-specific scaling tailored to available parameters, e.g., scale data quality or model size for a particular service. To optimize the execution across services, we present a scaling agent based on Regression Analysis of Structural Knowledge (RASK). The RASK agent efficiently explores the solution space and learns a continuous regression model of the processing environment for inferring optimal scaling actions. We compared our approach with two autoscalers, the Kubernetes VPA and a reinforcement learning agent, for scaling up to 9 services on a single Edge device. Our results showed that RASK can infer an accurate regression model in merely 20 iterations (i.e., observe 200s of processing). By increasingly adding elasticity dimensions, RASK sustained the highest request load with 28% less SLO violations, compared to baselines.', 'abstract_zh': '边缘设备资源有限，不可避免地导致流处理服务无法满足其需求。现有自动扩展机制专注于资源扩展，而边缘设备需要其他方式来维持竞争服务的业务水平目标（SLOs）。为此，我们引入了一个多维度自动扩展平台（MUDAP），它支持服务和资源层面的细粒度垂直扩展。MUDAP支持针对可用参数定制的服务特定扩展，例如为特定服务调整数据质量或模型大小。为优化跨服务执行，我们提出了一种基于结构知识回归分析的扩展代理（RASK）。RASK代理高效地探索解决方案空间，并学习处理环境的连续回归模型来推断最优扩展动作。我们将我们的方法与 Kubernetes VPA 和一个强化学习代理进行了比较，用于单个边缘设备上最多 9 服务的扩展。实验结果表明，RASK 可以仅在 20 次迭代中（即观察 200 秒处理）推理出准确的回归模型。通过不断增加弹性维度，RASK 将 SLO 违规率降低了 28%，维持了最高的请求负载。', 'title_zh': '边缘设备上流处理服务的多维自动扩缩容'}
{'arxiv_id': 'arXiv:2510.06880', 'title': 'MoRE-GNN: Multi-omics Data Integration with a Heterogeneous Graph Autoencoder', 'authors': 'Zhiyu Wang, Sonia Koszut, Pietro Liò, Francesco Ceccarelli', 'link': 'https://arxiv.org/abs/2510.06880', 'abstract': 'The integration of multi-omics single-cell data remains challenging due to high-dimensionality and complex inter-modality relationships. To address this, we introduce MoRE-GNN (Multi-omics Relational Edge Graph Neural Network), a heterogeneous graph autoencoder that combines graph convolution and attention mechanisms to dynamically construct relational graphs directly from data. Evaluations on six publicly available datasets demonstrate that MoRE-GNN captures biologically meaningful relationships and outperforms existing methods, particularly in settings with strong inter-modality correlations. Furthermore, the learned representations allow for accurate downstream cross-modal predictions. While performance may vary with dataset complexity, MoRE-GNN offers an adaptive, scalable and interpretable framework for advancing multi-omics integration.', 'abstract_zh': '多组学单细胞数据的多模态关系图神经网络MoRE-GNN：动态构建基于数据的异质图', 'title_zh': 'MoRE-GNN：异质图自编码器驱动的多组学数据整合'}
{'arxiv_id': 'arXiv:2510.06868', 'title': 'Multi-hop Deep Joint Source-Channel Coding with Deep Hash Distillation for Semantically Aligned Image Retrieval', 'authors': 'Didrik Bergström, Deniz Gündüz, Onur Günlü', 'link': 'https://arxiv.org/abs/2510.06868', 'abstract': 'We consider image transmission via deep joint source-channel coding (DeepJSCC) over multi-hop additive white Gaussian noise (AWGN) channels by training a DeepJSCC encoder-decoder pair with a pre-trained deep hash distillation (DHD) module to semantically cluster images, facilitating security-oriented applications through enhanced semantic consistency and improving the perceptual reconstruction quality. We train the DeepJSCC module to both reduce mean square error (MSE) and minimize cosine distance between DHD hashes of source and reconstructed images. Significantly improved perceptual quality as a result of semantic alignment is illustrated for different multi-hop settings, for which classical DeepJSCC may suffer from noise accumulation, measured by the learned perceptual image patch similarity (LPIPS) metric.', 'abstract_zh': '基于预训练深哈希蒸馏模块的深度联合源-信道编码在多跳加性白色高斯噪声信道中的图像传输', 'title_zh': '多跳深度联合源信道编码与深度哈希精炼用于语义对齐的图像检索'}
{'arxiv_id': 'arXiv:2510.06860', 'title': 'Towards Generalization of Graph Neural Networks for AC Optimal Power Flow', 'authors': 'Olayiwola Arowolo, Jochen L. Cremer', 'link': 'https://arxiv.org/abs/2510.06860', 'abstract': 'AC Optimal Power Flow (ACOPF) is computationally expensive for large-scale power systems, with conventional solvers requiring prohibitive solution times. Machine learning approaches offer computational speedups but struggle with scalability and topology adaptability without expensive retraining. To enable scalability across grid sizes and adaptability to topology changes, we propose a Hybrid Heterogeneous Message Passing Neural Network (HH-MPNN). HH-MPNN models buses, generators, loads, shunts, transmission lines and transformers as distinct node or edge types, combined with a scalable transformer model for handling long-range dependencies. On grids from 14 to 2,000 buses, HH-MPNN achieves less than 1% optimality gap on default topologies. Applied zero-shot to thousands of unseen topologies, HH-MPNN achieves less than 3% optimality gap despite training only on default topologies. Pre-training on smaller grids also improves results on a larger grid. Computational speedups reach 1,000x to 10,000x compared to interior point solvers. These results advance practical, generalizable machine learning for real-time power system operations.', 'abstract_zh': '基于混合异构消息传递神经网络的近最优功率流方法：可扩展性和拓扑适应性', 'title_zh': '面向交流最优功率流问题的图神经网络泛化研究'}
{'arxiv_id': 'arXiv:2510.06858', 'title': 'Explaining raw data complexity to improve satellite onboard processing', 'authors': 'Adrien Dorise, Marjorie Bellizzi, Adrien Girard, Benjamin Francesconi, Stéphane May', 'link': 'https://arxiv.org/abs/2510.06858', 'abstract': 'With increasing processing power, deploying AI models for remote sensing directly onboard satellites is becoming feasible. However, new constraints arise, mainly when using raw, unprocessed sensor data instead of preprocessed ground-based products. While current solutions primarily rely on preprocessed sensor images, few approaches directly leverage raw data. This study investigates the effects of utilising raw data on deep learning models for object detection and classification tasks. We introduce a simulation workflow to generate raw-like products from high-resolution L1 imagery, enabling systemic evaluation. Two object detection models (YOLOv11s and YOLOX-S) are trained on both raw and L1 datasets, and their performance is compared using standard detection metrics and explainability tools. Results indicate that while both models perform similarly at low to medium confidence thresholds, the model trained on raw data struggles with object boundary identification at high confidence levels. It suggests that adapting AI architectures with improved contouring methods can enhance object detection on raw images, improving onboard AI for remote sensing.', 'abstract_zh': '随着计算能力的增强，在卫星上直接部署AI模型变得可行。然而，当使用原始未处理的传感器数据而不是预处理的地面产品时，新的约束条件随之而来。尽管当前的方法主要依赖预处理的传感器图像，但很少有方法直接利用原始数据。本文研究了利用原始数据对目标检测和分类任务的深度学习模型的影响。我们引入了一套仿真工作流，从高分辨率L1影像中生成类似原始产品的数据，从而实现系统的评估。两个目标检测模型（YOLOv11s和YOLOX-S）分别在校准和L1数据集上训练，并使用标准检测指标和解释性工具比较其性能。结果显示，在低到中等置信度阈值下，两种模型表现相似，但在高置信度水平下，基于原始数据训练的模型在目标边界识别方面遇到困难。这表明，通过改进边缘提取方法适应AI架构可以增强对原始图像的目标检测能力，从而提高遥感领域的机载AI性能。', 'title_zh': '解释原始数据复杂性以提高卫星机载处理能力'}
{'arxiv_id': 'arXiv:2510.06852', 'title': 'Enhancing Bankruptcy Prediction of Banks through Advanced Machine Learning Techniques: An Innovative Approach and Analysis', 'authors': 'Zuherman Rustam, Sri Hartini, Sardar M.N. Islam, Fevi Novkaniza, Fiftitah R. Aszhari, Muhammad Rifqi', 'link': 'https://arxiv.org/abs/2510.06852', 'abstract': "Context: Financial system stability is determined by the condition of the banking system. A bank failure can destroy the stability of the financial system, as banks are subject to systemic risk, affecting not only individual banks but also segments or the entire financial system. Calculating the probability of a bank going bankrupt is one way to ensure the banking system is safe and sound. Existing literature and limitations: Statistical models, such as Altman's Z-Score, are one of the common techniques for developing a bankruptcy prediction model. However, statistical methods rely on rigid and sometimes irrelevant assumptions, which can result in low forecast accuracy. New approaches are necessary. Objective of the research: Bankruptcy models are developed using machine learning techniques, such as logistic regression (LR), random forest (RF), and support vector machines (SVM). According to several studies, machine learning is also more accurate and effective than statistical methods for categorising and forecasting banking risk management. Present Research: The commercial bank data are derived from the annual financial statements of 44 active banks and 21 bankrupt banks in Turkey from 1994 to 2004, and the rural bank data are derived from the quarterly financial reports of 43 active and 43 bankrupt rural banks in Indonesia between 2013 and 2019. Five rural banks in Indonesia have also been selected to demonstrate the feasibility of analysing bank bankruptcy trends. Findings and implications: The results of the research experiments show that RF can forecast data from commercial banks with a 90% accuracy rate. Furthermore, the three machine learning methods proposed accurately predict the likelihood of rural bank bankruptcy. Contribution and Conclusion: The proposed innovative machine learning approach help to implement policies that reduce the costs of bankruptcy.", 'abstract_zh': '金融系统稳定性取决于银行系统的状况。银行失败可能会破坏金融系统的稳定性，因为银行面临系统性风险，不仅会影响个别银行，还可能影响金融系统的某个部分或整个系统。计算银行破产概率是确保银行系统安全稳健的一种方式。现有文献与局限性：统计模型，如Altman的Z-Score，是开发破产预测模型的常用技术之一。然而，统计方法依赖于生硬且有时无关紧要的假设，可能导致预测准确率较低。需要新的方法。研究目标：使用机器学习技术，如逻辑回归（LR）、随机森林（RF）和支持向量机（SVM）开发破产模型。多项研究表明，机器学习在分类和预测银行风险管理方面比统计方法更准确有效。当前研究：商用银行数据源自1994年至2004年间土耳其44家活跃银行和21家破产银行的年度财务报表，农村银行数据源自2013年至2019年间印度尼西亚43家活跃和43家破产农村银行的季度财务报告。还选择了印度尼西亚的五家农村银行来展示分析银行破产趋势的可行性。研究成果与意义：研究实验结果表明，随机森林（RF）可以以90%的准确率预测商用银行的数据。此外，三种机器学习方法准确预测了农村银行破产的可能性。贡献与结论：提出的创新机器学习方法有助于实施减少破产成本的政策。', 'title_zh': '通过高级机器学习技术提高银行破产预测：一种创新方法与分析'}
{'arxiv_id': 'arXiv:2510.06847', 'title': 'OpenJAI-v1.0: An Open Thai Large Language Model', 'authors': 'Pontakorn Trakuekul, Attapol T. Rutherford, Jullajak Karnjanaekarin, Narongkorn Panitsrisit, Sumana Sumanakul', 'link': 'https://arxiv.org/abs/2510.06847', 'abstract': 'We introduce OpenJAI-v1.0, an open-source large language model for Thai and English, developed from the Qwen3-14B model. Our work focuses on boosting performance on practical tasks through carefully curated data across three key use cases: instruction following, long-context understanding, and tool use. Evaluation results show that OpenJAI-v1.0 improves on the capabilities of its base model and outperforms other leading open-source Thai models on a diverse suite of benchmarks, while avoiding catastrophic forgetting. OpenJAI-v1.0 is publicly released as another alternative NLP resource for the Thai AI community.', 'abstract_zh': '我们介绍OpenJAI-v1.0，一个基于Qwen3-14B模型的开源大型语言模型，适用于泰语和英语。我们的工作集中在通过精心选择的数据在三个关键应用场景上提高性能：指令跟随、长上下文理解以及工具使用。评估结果显示，OpenJAI-v1.0 在其基础模型的基础上提升性能，并在一系列基准测试中优于其他主要的开源泰语模型，同时避免了灾难性遗忘。OpenJAI-v1.0 公开发布，作为泰国人工智能社区的另一个自然语言处理资源。', 'title_zh': 'OpenJAI-v1.0：一个开源泰语大型语言模型'}
{'arxiv_id': 'arXiv:2510.06843', 'title': 'SID: Multi-LLM Debate Driven by Self Signals', 'authors': 'Xuhang Chen, Zhifan Song, Deyi Ji, Shuo Gao, Lanyun Zhu', 'link': 'https://arxiv.org/abs/2510.06843', 'abstract': 'Large Language Models (LLMs) have exhibited impressive capabilities across diverse application domains. Recent work has explored Multi-LLM Agent Debate (MAD) as a way to enhance performance by enabling multiple LLMs to discuss and refine responses iteratively. Nevertheless, existing MAD methods predominantly focus on utilizing external structures, such as debate graphs, using LLM-as-a-Judge, while neglecting the application of self signals, such as token logits and attention, that arise during generation. This omission leads to redundant computation and potential performance degradation. In this paper, we shift the focus to the self signals of multi-LLM debate and introduce a Self-Signals Driven Multi-LLM Debate (SID), which leverages two types of self-signals: model-level confidence and token-level semantic focus, to adaptively guide the debate process. Our approach enables high-confidence agents to exit early at the model level and compress the redundant debate contents based on the attention mechanism. We evaluate our method on various LLMs and Multimodal LLMs across multiple challenging benchmarks. Experimental results demonstrate that our method not only outperforms existing MAD techniques in accuracy but also reduces token consumption, highlighting the effectiveness of utilizing self signals in enhancing both the performance and efficiency of multi-agent debate systems. Our code will be available at~\\href{this https URL}{\\texttt{this https URL}}.', 'abstract_zh': '大规模语言模型（LLMs）在多个应用领域展示了出色的能力。近期研究表明，通过让多个LLM进行讨论和迭代修正回应的多LLM代理辩论（MAD）方法能够提升性能。然而，现有MAD方法主要侧重于使用外部结构，如辩论图，以及LLM作为裁判的方式，而忽视了生成过程中出现的自我信号，如令牌概率和注意力，这导致了重复计算和潜在性能下降。本文将重点放在多LLM辩论的自我信号上，提出了一种基于自我信号的多LLM代理辩论（SID），利用模型级别信心和令牌级别语义焦点两种自我信号，自适应地指导辩论过程。该方法允许高信心代理在模型级别提前退出，并基于注意力机制压缩冗余辩论内容。我们在多个LLM和多模态LLM上多项具有挑战性的基准测试上评估了该方法。实验结果表明，该方法不仅在准确率上优于现有MAD技术，还能减少令牌消耗，突出利用自我信号提高多代理辩论系统性能和效率的有效性。我们的代码将在\\href{this https URL}{\\texttt{this https URL}}提供。', 'title_zh': 'SID: 由自我信号驱动的多语言模型辩论'}
{'arxiv_id': 'arXiv:2510.06840', 'title': 'CNN-TFT explained by SHAP with multi-head attention weights for time series forecasting', 'authors': 'Stefano F. Stefenon, João P. Matos-Carvalho, Valderi R. Q. Leithardt, Kin-Choong Yow', 'link': 'https://arxiv.org/abs/2510.06840', 'abstract': 'Convolutional neural networks (CNNs) and transformer architectures offer strengths for modeling temporal data: CNNs excel at capturing local patterns and translational invariances, while transformers effectively model long-range dependencies via self-attention. This paper proposes a hybrid architecture integrating convolutional feature extraction with a temporal fusion transformer (TFT) backbone to enhance multivariate time series forecasting. The CNN module first applies a hierarchy of one-dimensional convolutional layers to distill salient local patterns from raw input sequences, reducing noise and dimensionality. The resulting feature maps are then fed into the TFT, which applies multi-head attention to capture both short- and long-term dependencies and to weigh relevant covariates adaptively. We evaluate the CNN-TFT on a hydroelectric natural flow time series dataset. Experimental results demonstrate that CNN-TFT outperforms well-established deep learning models, with a mean absolute percentage error of up to 2.2%. The explainability of the model is obtained by a proposed Shapley additive explanations with multi-head attention weights (SHAP-MHAW). Our novel architecture, named CNN-TFT-SHAP-MHAW, is promising for applications requiring high-fidelity, multivariate time series forecasts, being available for future analysis at this https URL .', 'abstract_zh': '卷积神经网络（CNNs）和变压器架构在建模时序数据方面表现出色：卷积神经网络擅长捕捉局部模式和平移不变性，而变压器通过自注意力机制有效建模长距离依赖关系。本文提出了一种将卷积特征提取与时间融合变压器（TFT）骨干网络相结合的混合架构，以增强多变量时间序列预测。卷积模块首先应用一系列一维卷积层从原始输入序列中提取显著的局部模式，减少噪声和维度。提取的特征图随后输入TFT，后者通过多头注意力机制捕获短长期依赖关系，并适应性地加权相关协变量。我们使用水力发电天然流量时序数据集对CNN-TFT进行了评估。实验结果表明，CNN-TFT在均绝对百分比误差方面优于现有的深度学习模型，最高可达2.2%。通过提出的具有多头注意力权重的Shapley加性解释（SHAP-MHAW）方法获得了模型的可解释性。我们提出的新型架构CNN-TFT-SHAP-MHAW适用于需要高保真度多变量时间序列预测的应用，并可在<https://这一网址提供>供未来分析使用。', 'title_zh': '基于多头注意力权重的SHAP解释的CNN-TFT时间序列 forecasting'}
{'arxiv_id': 'arXiv:2510.06828', 'title': 'Recurrence-Complete Frame-based Action Models', 'authors': 'Michael Keiblinger', 'link': 'https://arxiv.org/abs/2510.06828', 'abstract': 'In recent years, attention-like mechanisms have been used to great success in the space of large language models, unlocking scaling potential to a previously unthinkable extent. "Attention Is All You Need" famously claims RNN cells are not needed in conjunction with attention. We challenge this view. In this paper, we point to existing proofs that architectures with fully parallelizable forward or backward passes cannot represent classes of problems specifically interesting for long-running agentic tasks. We further conjecture a critical time t beyond which non-recurrence-complete models fail to aggregate inputs correctly, with concrete implications for agentic systems (e.g., software engineering agents). To address this, we introduce a recurrence-complete architecture and train it on GitHub-derived action sequences. Loss follows a power law in the trained sequence length while the parameter count remains fixed. Moreover, longer-sequence training always amortizes its linearly increasing wall-time cost, yielding lower loss as a function of wall time.', 'abstract_zh': '近年来，注意力机制在大型语言模型领域取得了巨大的成功，解开了此前难以想象的扩展潜力。“Attention Is All You Need”著名地宣称，在注意力机制下RNN单元是不必要的。我们认为这一观点值得商榷。本文指出，具有完全并行可执行正向或反向传递的架构无法表示特定针对长时间运行智能任务的问题类。此外，我们推测存在一个关键时间点t，在此之后，非递归完备模型无法正确聚合输入，对智能系统（例如软件工程代理）具有具体影响。为解决这一问题，我们提出了一种递归完备架构，并在GitHub派生的操作序列上进行训练。损失遵循训练序列长度的幂律分布，而参数计数保持不变。此外，更长序列的训练总是能够摊薄线性增加的墙时间成本，以墙时间为函数，损失更低。', 'title_zh': '基于帧的循环完整动作模型'}
{'arxiv_id': 'arXiv:2510.06800', 'title': 'FURINA: A Fully Customizable Role-Playing Benchmark via Scalable Multi-Agent Collaboration Pipeline', 'authors': 'Haotian Wu, Shufan Jiang, Chios Chen, Yiyang Feng, Hehai Lin, Heqing Zou, Yao Shu, Yanran Li, Chengwei Qin', 'link': 'https://arxiv.org/abs/2510.06800', 'abstract': "As large language models (LLMs) advance in role-playing (RP) tasks, existing benchmarks quickly become obsolete due to their narrow scope, outdated interaction paradigms, and limited adaptability across diverse application scenarios. To address this gap, we introduce FURINA-Builder, a novel multi-agent collaboration pipeline that automatically constructs fully customizable RP benchmarks at any scale. It enables evaluation of arbitrary characters across diverse scenarios and prompt formats, as the first benchmark builder in RP area for adaptable assessment. FURINA-Builder simulates dialogues between a test character and other characters drawn from a well-constructed character-scene pool, while an LLM judge selects fine-grained evaluation dimensions and adjusts the test character's responses into final test utterances. Using this pipeline, we build FURINA-Bench, a new comprehensive role-playing benchmark featuring both established and synthesized test characters, each assessed with dimension-specific evaluation criteria. Human evaluation and preliminary separability analysis justify our pipeline and benchmark design. We conduct extensive evaluations of cutting-edge LLMs and find that o3 and DeepSeek-R1 achieve the best performance on English and Chinese RP tasks, respectively. Across all models, established characters consistently outperform synthesized ones, with reasoning capabilities further amplifying this disparity. Interestingly, we observe that model scale does not monotonically reduce hallucinations. More critically, for reasoning LLMs, we uncover a novel trade-off: reasoning improves RP performance but simultaneously increases RP hallucinations. This trade-off extends to a broader Pareto frontier between RP performance and reliability for all LLMs. These findings demonstrate the effectiveness of FURINA-Builder and the challenge posed by FURINA-Bench.", 'abstract_zh': '随着大型语言模型在角色扮演任务中的进步，现有基准迅速变得过时，因为它们的范围狭窄、过时的交互范式以及在多样应用场景中的有限适应性。为了解决这一差距，我们引入了FURINA-Builder，这是一种新颖的多智能体协作流水线，可以自动构建任意规模的完全可定制的角色扮演基准。它能够评估各种场景和指令格式中的任意角色，是角色扮演领域中的首个可适应评估的基准构建器。FURINA-Builder模拟了测试角色与其他从精心构建的角色场景池中抽取的角色之间的对话，而一个语言模型裁判选取细致的评估维度并调整测试角色的回复以形成最终的测试话语。使用此流水线，我们构建了FURINA-Bench，一个新的全面的角色扮演基准，包含既有和合成的测试角色，并对每个角色使用特定维度的评估标准。通过人工评估和初步可分性分析，我们证明了我们的流水线和基准设计的有效性。我们对最先进的语言模型进行了广泛的评估，发现o3和DeepSeek-R1分别在英语和中文角色扮演任务中表现最佳。在所有模型中，既有角色始终优于合成角色，推理能力进一步放大了这一差异。有趣的是，我们发现模型规模并非单调减少涌现现象。更关键的是，对于推理语言模型，我们揭示了一种新的权衡：推理提高了角色扮演性能，但同时增加了角色扮演中的涌现现象。这种权衡扩展到了所有语言模型之间RP性能和可靠性之间的帕累托前沿。这些发现展示了FURINA-Builder的有效性和FURINA-Bench带来的挑战。', 'title_zh': 'FURINA：一种基于可扩展多智能体协作pipeline的完全可定制角色扮演基准测试'}
{'arxiv_id': 'arXiv:2510.06791', 'title': 'Extreme Amodal Face Detection', 'authors': 'Changlin Song, Yunzhong Hou, Michael Randall Barnes, Rahul Shome, Dylan Campbell', 'link': 'https://arxiv.org/abs/2510.06791', 'abstract': 'Extreme amodal detection is the task of inferring the 2D location of objects that are not fully visible in the input image but are visible within an expanded field-of-view. This differs from amodal detection, where the object is partially visible within the input image, but is occluded. In this paper, we consider the sub-problem of face detection, since this class provides motivating applications involving safety and privacy, but do not tailor our method specifically to this class. Existing approaches rely on image sequences so that missing detections may be interpolated from surrounding frames or make use of generative models to sample possible completions. In contrast, we consider the single-image task and propose a more efficient, sample-free approach that makes use of the contextual cues from the image to infer the presence of unseen faces. We design a heatmap-based extreme amodal object detector that addresses the problem of efficiently predicting a lot (the out-of-frame region) from a little (the image) with a selective coarse-to-fine decoder. Our method establishes strong results for this new task, even outperforming less efficient generative approaches.', 'abstract_zh': '极端无框检测是推断输入图像中未完全可见但存在于扩展视野中的物体2D位置的任务。这与部分可见的无框检测不同，在后者中，物体在输入图像中部分可见但被遮挡。在本文中，我们考虑人脸检测的子问题，因为该类别提供了涉及安全和隐私的激励应用，但我们并未专门针对该类别设计我们的方法。现有方法依赖于图像序列，以便从相邻帧中插值缺失的检测，或者利用生成模型采样可能的完成。相比之下，我们考虑单张图像任务，并提出了一种更高效、无需样本的方法，利用图像中的上下文线索推断未见人脸的存在。我们设计了一种基于热图的极端无框物体检测器，该检测器通过选择性粗细解码器高效地解决了从少量（图像）中预测大量（超出图像范围区域）的问题。我们的方法在该新任务中取得了强有力的成果，甚至优于更不高效的生成方法。', 'title_zh': '极端非视界面部检测'}
{'arxiv_id': 'arXiv:2510.06780', 'title': 'Foundations of LLM Knowledge Materialization: Termination, Reproducibility, Robustness', 'authors': 'Luca Giordano, Simon Razniewski', 'link': 'https://arxiv.org/abs/2510.06780', 'abstract': 'Large Language Models (LLMs) encode substantial factual knowledge, yet measuring and systematizing this knowledge remains challenging. Converting it into structured format, for example through recursive extraction approaches such as the GPTKB methodology (Hu et al., 2025b), is still underexplored. Key open questions include whether such extraction can terminate, whether its outputs are reproducible, and how robust they are to variations. We systematically study LLM knowledge materialization using miniGPTKBs (domain-specific, tractable subcrawls), analyzing termination, reproducibility, and robustness across three categories of metrics: yield, lexical similarity, and semantic similarity. We experiment with four variations (seed, language, randomness, model) and three illustrative domains (from history, entertainment, and finance). Our findings show (i) high termination rates, though model-dependent; (ii) mixed reproducibility; and (iii) robustness that varies by perturbation type: high for seeds and temperature, lower for languages and models. These results suggest that LLM knowledge materialization can reliably surface core knowledge, while also revealing important limitations.', 'abstract_zh': '大型语言模型（LLMs）蕴含大量的事实性知识，但测量和系统化这些知识依然具有挑战性。通过递归提取方法（如GPTKB方法，Hu等，2025b）将其转换为结构化格式仍然未被充分探索。关键的开放问题包括此类提取是否可以终止、其输出是否可重复以及对变化的鲁棒性如何。我们系统地研究了使用minigiptkb（领域特定、可处理的子抓取）来实现LLM知识物质化，分析了终止、可重复性和鲁棒性在三种类别指标下的表现：产出量、词汇相似性和语义相似性。我们实验了四种变体（种子、语言、随机性、模型）和三个示例领域（历史、娱乐和金融）。我们的研究结果表明：（i）高终止率，但取决于模型；（ii）重复性参差不齐；（iii）鲁棒性因扰动类型而异：对种子和温度高，对语言和模型低。这些结果表明，LLM知识物质化可以可靠地揭示核心知识，同时也揭示了重要的限制。', 'title_zh': 'LLM知识物质化的基础：终止性、可重复性、稳健性'}
{'arxiv_id': 'arXiv:2510.06776', 'title': 'Modeling COVID-19 Dynamics in German States Using Physics-Informed Neural Networks', 'authors': 'Phillip Rothenbeck, Sai Karthikeya Vemuri, Niklas Penzel, Joachim Denzler', 'link': 'https://arxiv.org/abs/2510.06776', 'abstract': 'The COVID-19 pandemic has highlighted the need for quantitative modeling and analysis to understand real-world disease dynamics. In particular, post hoc analyses using compartmental models offer valuable insights into the effectiveness of public health interventions, such as vaccination strategies and containment policies. However, such compartmental models like SIR (Susceptible-Infectious-Recovered) often face limitations in directly incorporating noisy observational data. In this work, we employ Physics-Informed Neural Networks (PINNs) to solve the inverse problem of the SIR model using infection data from the Robert Koch Institute (RKI). Our main contribution is a fine-grained, spatio-temporal analysis of COVID-19 dynamics across all German federal states over a three-year period. We estimate state-specific transmission and recovery parameters and time-varying reproduction number (R_t) to track the pandemic progression. The results highlight strong variations in transmission behavior across regions, revealing correlations with vaccination uptake and temporal patterns associated with major pandemic phases. Our findings demonstrate the utility of PINNs in localized, long-term epidemiological modeling.', 'abstract_zh': 'COVID-19疫情突显了定量建模与分析在理解现实世界疾病动态中的必要性。特别是，使用 compartimental 模型进行事后分析为理解公共卫生干预措施（如疫苗接种策略和管控政策）的有效性提供了宝贵见解。然而，这类 compartimental 模型如 SIR（易感-感染-恢复）模型往往难以直接整合嘈杂的观察数据。本研究使用物理知情神经网络（PINNs）利用罗伯特·科赫研究所的感染数据解决 SIR 模型的逆问题。我们的主要贡献是在三年时间内对德国所有联邦州进行细粒度的空间-时间分析，估计各州的传播和恢复参数以及时间变化的基本再生数（R_t），以追踪疫情进展。结果表明，不同地区传播行为存在显著差异，与疫苗接种率和与主要疫情阶段相关的时间模式存在关联。我们的研究发现表明了 PINNs 在局部长期流行病学建模中的应用价值。', 'title_zh': '使用物理启发神经网络建模德国各州COVID-19动态'}
{'arxiv_id': 'arXiv:2510.06743', 'title': 'Evaluating LLMs for Historical Document OCR: A Methodological Framework for Digital Humanities', 'authors': 'Maria Levchenko', 'link': 'https://arxiv.org/abs/2510.06743', 'abstract': 'Digital humanities scholars increasingly use Large Language Models for historical document digitization, yet lack appropriate evaluation frameworks for LLM-based OCR. Traditional metrics fail to capture temporal biases and period-specific errors crucial for historical corpus creation. We present an evaluation methodology for LLM-based historical OCR, addressing contamination risks and systematic biases in diplomatic transcription. Using 18th-century Russian Civil font texts, we introduce novel metrics including Historical Character Preservation Rate (HCPR) and Archaic Insertion Rate (AIR), alongside protocols for contamination control and stability testing. We evaluate 12 multimodal LLMs, finding that Gemini and Qwen models outperform traditional OCR while exhibiting over-historicization: inserting archaic characters from incorrect historical periods. Post-OCR correction degrades rather than improves performance. Our methodology provides digital humanities practitioners with guidelines for model selection and quality assessment in historical corpus digitization.', 'abstract_zh': '基于大型语言模型的历史文档光学字符识别评估方法：Addressing Contamination Risks and Systematic Biases in LLM-based Historical OCR', 'title_zh': '基于数字人文的方法论框架：评估语言模型在历史文档OCR中的应用'}
{'arxiv_id': 'arXiv:2510.06732', 'title': 'Are LLMs Reliable Rankers? Rank Manipulation via Two-Stage Token Optimization', 'authors': 'Tiancheng Xing, Jerry Li, Yixuan Du, Xiyang Hu', 'link': 'https://arxiv.org/abs/2510.06732', 'abstract': 'Large language models (LLMs) are increasingly used as rerankers in information retrieval, yet their ranking behavior can be steered by small, natural-sounding prompts. To expose this vulnerability, we present Rank Anything First (RAF), a two-stage token optimization method that crafts concise textual perturbations to consistently promote a target item in LLM-generated rankings while remaining hard to detect. Stage 1 uses Greedy Coordinate Gradient to shortlist candidate tokens at the current position by combining the gradient of the rank-target with a readability score; Stage 2 evaluates those candidates under exact ranking and readability losses using an entropy-based dynamic weighting scheme, and selects a token via temperature-controlled sampling. RAF generates ranking-promoting prompts token-by-token, guided by dual objectives: maximizing ranking effectiveness and preserving linguistic naturalness. Experiments across multiple LLMs show that RAF significantly boosts the rank of target items using naturalistic language, with greater robustness than existing methods in both promoting target items and maintaining naturalness. These findings underscore a critical security implication: LLM-based reranking is inherently susceptible to adversarial manipulation, raising new challenges for the trustworthiness and robustness of modern retrieval systems. Our code is available at: this https URL.', 'abstract_zh': '基于大型语言模型的检索重新排行为自然语言操控提供新挑战：Rank Anything First', 'title_zh': 'LLMs可靠吗？基于两阶段token优化的排名操控'}
{'arxiv_id': 'arXiv:2510.06727', 'title': 'Scaling LLM Multi-turn RL with End-to-end Summarization-based Context Management', 'authors': 'Miao Lu, Weiwei Sun, Weihua Du, Zhan Ling, Xuesong Yao, Kang Liu, Jiecao Chen', 'link': 'https://arxiv.org/abs/2510.06727', 'abstract': 'We study reinforcement learning (RL) fine-tuning of large language model (LLM) agents for long-horizon multi-turn tool use, where context length quickly becomes a fundamental bottleneck. Existing RL pipelines can suffer from degraded instruction following, excessive rollout costs, and most importantly, strict context limits. To address these challenges, we introduce summarization-based context management to training. In specific, it periodically compresses the tool using history by LLM-generated summaries that retain task-relevant information to keep a compact context while enabling the agent to scale beyond the fixed context window. Building on this formulation, we derive a policy gradient representation that seamlessly enables standard LLM RL infrastructures to optimize both tool-use behaviors as well as summarization strategies in an end-to-end fashion. We instantiate this framework with \\underline{SU}mmarization augmented \\underline{P}olicy \\underline{O}ptimization (\\texttt{SUPO}), an LLM RL algorithm that enables long-horizon training beyond a fixed context limit. Experiments on interactive function calling and searching tasks demonstrate that \\texttt{SUPO} significantly improves the success rate while maintaining the same or even lower working context length compared to baselines. We also demonstrate that for complex searching tasks, \\texttt{SUPO} can further improve the evaluation performance when scaling test-time maximum round of summarization beyond that of training time. Our results establish summarization-based context management as a principled and scalable approach for training RL agents beyond a fixed context length limit.', 'abstract_zh': '基于总结化的上下文管理的大语言模型强化学习 Fine-tuning 以实现长时 horizon 多轮工具使用', 'title_zh': '基于摘要式上下文管理的大型语言模型多轮RL扩展研究'}
{'arxiv_id': 'arXiv:2510.06718', 'title': 'LLM Company Policies and Policy Implications in Software Organizations', 'authors': 'Ranim Khojah, Mazen Mohamad, Linda Erlenhov, Francisco Gomes de Oliveira Neto, Philipp Leitner', 'link': 'https://arxiv.org/abs/2510.06718', 'abstract': 'The risks associated with adopting large language model (LLM) chatbots in software organizations highlight the need for clear policies. We examine how 11 companies create these policies and the factors that influence them, aiming to help managers safely integrate chatbots into development workflows.', 'abstract_zh': '采用大型语言模型聊天机器人（LLM chatbots）在软件组织中面临的风险凸显了明确政策的必要性。我们研究了11家公司如何制定这些政策及其影响因素，旨在帮助管理人员安全地将聊天机器人集成到开发流程中。', 'title_zh': 'LLM 公司政策及软件组织中的政策影响'}
{'arxiv_id': 'arXiv:2510.06714', 'title': 'Dual Goal Representations', 'authors': 'Seohong Park, Deepinder Mann, Sergey Levine', 'link': 'https://arxiv.org/abs/2510.06714', 'abstract': 'In this work, we introduce dual goal representations for goal-conditioned reinforcement learning (GCRL). A dual goal representation characterizes a state by "the set of temporal distances from all other states"; in other words, it encodes a state through its relations to every other state, measured by temporal distance. This representation provides several appealing theoretical properties. First, it depends only on the intrinsic dynamics of the environment and is invariant to the original state representation. Second, it contains provably sufficient information to recover an optimal goal-reaching policy, while being able to filter out exogenous noise. Based on this concept, we develop a practical goal representation learning method that can be combined with any existing GCRL algorithm. Through diverse experiments on the OGBench task suite, we empirically show that dual goal representations consistently improve offline goal-reaching performance across 20 state- and pixel-based tasks.', 'abstract_zh': '在本工作中，我们引入了双目标表示方法用于目标导向的强化学习(GCRL)。', 'title_zh': '双重目标表示'}
{'arxiv_id': 'arXiv:2510.06708', 'title': 'AISysRev - LLM-based Tool for Title-abstract Screening', 'authors': 'Aleksi Huotala, Miikka Kuutila, Olli-Pekka Turtio, Mika Mäntylä', 'link': 'https://arxiv.org/abs/2510.06708', 'abstract': "Systematic reviews are a standard practice for summarizing the state of evidence in software engineering. Conducting systematic reviews is laborious, especially during the screening or study selection phase, where the number of papers can be overwhelming. During this phase, papers are assessed against inclusion and exclusion criteria based on their titles and abstracts. Recent research has demonstrated that large language models (LLMs) can perform title-abstract screening at a level comparable to that of a master's student. While LLMs cannot be fully trusted, they can help, for example, in Rapid Reviews, which try to expedite the review process. Building on recent research, we developed AiSysRev, an LLM-based screening tool implemented as a web application running in a Docker container. The tool accepts a CSV file containing paper titles and abstracts. Users specify inclusion and exclusion criteria. One can use multiple LLMs for screening via OpenRouter. AiSysRev supports both zero-shot and few-shot screening, and also allows for manual screening through interfaces that display LLM results as guidance for human this http URL conducted a trial study with 137 papers using the tool. Our findings indicate that papers can be classified into four categories: Easy Includes, Easy Excludes, Boundary Includes, and Boundary Excludes. The Boundary cases, where LLMs are prone to errors, highlight the need for human intervention. While LLMs do not replace human judgment in systematic reviews, they can significantly reduce the burden of assessing large volumes of scientific literature. Video: this https URL Tool: this https URL", 'abstract_zh': '系统综述是软件工程中总结现有证据标准实践。进行系统综述是一项繁琐的工作，尤其是在筛选或研究选择阶段，此时需要评估的论文数量可能非常庞大。在这一阶段，论文依据标题和摘要评估是否符合纳入和排除标准。最近的研究表明，大型语言模型（LLMs）可以在标题-摘要筛选方面达到与硕士学生相当的水平。尽管LLMs不能完全信赖，但它们可以在快速综述（如尝试加快审查过程）等场景中发挥作用。基于最近的研究，我们开发了AiSysRev，这是一种基于LLM的筛选工具，实现为Docker容器中的Web应用。该工具接受包含论文标题和摘要的CSV文件。用户指定纳入和排除标准。可以使用OpenRouter的多个LLM进行筛选。AiSysRev支持零样本和少量样本筛选，并允许通过显示LLM结果以指导人工筛选的界面进行人工筛选。我们使用该工具对137篇论文进行了试用研究。研究结果表明，论文可以分为四类：易纳入、易排除、边界纳入和边界排除。边界情形下，LLMs容易出现错误，突显了人工干预的必要性。尽管LLMs不能替代系统综述中的人类判断，但它们可以显著减轻评估大量科学文献的负担。视频：[此链接]。工具：[此链接]。', 'title_zh': 'AISysRev - 基于LLM的标题摘要筛查工具'}
{'arxiv_id': 'arXiv:2510.06695', 'title': 'Learning to Rewrite Prompts for Bootstrapping LLMs on Downstream Tasks', 'authors': 'Qinhao Zhou, Xiang Xiang, Kun He, John E. Hopcroft', 'link': 'https://arxiv.org/abs/2510.06695', 'abstract': 'In recent years, the growing interest in Large Language Models (LLMs) has significantly advanced prompt engineering, transitioning from manual design to model-based optimization. Prompts for LLMs generally comprise two components: the \\textit{instruction}, which defines the task or objective, and the \\textit{input}, which is tailored to the instruction type. In natural language generation (NLG) tasks such as machine translation, the \\textit{input} component is particularly critical, while the \\textit{instruction} component tends to be concise. Existing prompt engineering methods primarily focus on optimizing the \\textit{instruction} component for general tasks, often requiring large-parameter LLMs as auxiliary tools. However, these approaches exhibit limited applicability for tasks like machine translation, where the \\textit{input} component plays a more pivotal role. To address this limitation, this paper introduces a novel prompt optimization method specifically designed for machine translation tasks. The proposed approach employs a small-parameter model trained using a back-translation-based strategy, significantly reducing training overhead for single-task optimization while delivering highly effective performance. With certain adaptations, this method can also be extended to other downstream tasks.', 'abstract_zh': '近年来，对大规模语言模型（LLMs）日益增长的兴趣显著推动了提示工程的发展，从手动设计转向基于模型的优化。LLMs的提示通常由两个组件组成：\\textit{指令}，定义任务或目标；和\\textit{输入}，根据指令类型定制。在如机器翻译等自然语言生成（NLG）任务中，\\textit{输入}组件尤为重要，而\\textit{指令}组件通常较为简短。现有的提示工程方法主要侧重于通过使用大型参数量的LLMs对通用任务的\\textit{指令}组件进行优化。然而，这些方法对于机器翻译等任务的适用性有限，在这些任务中，\\textit{输入}组件发挥着更重要的作用。为解决这一局限性，本文提出了一种针对机器翻译任务的新型提示优化方法。该方法采用一种通过回译策略训练的小参数模型，在单任务优化中显著减少训练开销，并展现出高度有效的性能。经过适当的调整，该方法也可扩展应用于其他下游任务。', 'title_zh': '基于下游任务实训增强LLM的提示重写学习'}
{'arxiv_id': 'arXiv:2510.06687', 'title': 'Semantic Segmentation Algorithm Based on Light Field and LiDAR Fusion', 'authors': 'Jie Luo, Yuxuan Jiang, Xin Jin, Mingyu Liu, Yihui Fan', 'link': 'https://arxiv.org/abs/2510.06687', 'abstract': 'Semantic segmentation serves as a cornerstone of scene understanding in autonomous driving but continues to face significant challenges under complex conditions such as occlusion. Light field and LiDAR modalities provide complementary visual and spatial cues that are beneficial for robust perception; how- ever, their effective integration is hindered by limited viewpoint diversity and inherent modality discrepancies. To address these challenges, the first multimodal semantic segmentation dataset integrating light field data and point cloud data is proposed. Based on this dataset, we proposed a multi-modal light field point-cloud fusion segmentation network(Mlpfseg), incorporating feature completion and depth perception to segment both camera images and LiDAR point clouds simultaneously. The feature completion module addresses the density mismatch between point clouds and image pixels by performing differential re- construction of point-cloud feature maps, enhancing the fusion of these modalities. The depth perception module improves the segmentation of occluded objects by reinforcing attention scores for better occlusion awareness. Our method outperforms image- only segmentation by 1.71 Mean Intersection over Union(mIoU) and point cloud-only segmentation by 2.38 mIoU, demonstrating its effectiveness.', 'abstract_zh': '多模态光场点云融合分割网络（Mlpfseg）：基于光场数据和点云数据的语义分割', 'title_zh': '基于轻量级字段和LiDAR融合的语义分割算法'}
{'arxiv_id': 'arXiv:2510.06677', 'title': 'Incremental Summarization for Customer Support via Progressive Note-Taking and Agent Feedback', 'authors': 'Yisha Wu, Zhao, Yuanpei Cao, Xiaoqing Su, Yashar Mehdad, Mindy Ji, Claire Na Cheng', 'link': 'https://arxiv.org/abs/2510.06677', 'abstract': "We introduce an incremental summarization system for customer support agents that intelligently determines when to generate concise bullet notes during conversations, reducing agents' context-switching effort and redundant review. Our approach combines a fine-tuned Mixtral-8x7B model for continuous note generation with a DeBERTa-based classifier to filter trivial content. Agent edits refine the online notes generation and regularly inform offline model retraining, closing the agent edits feedback loop. Deployed in production, our system achieved a 3% reduction in case handling time compared to bulk summarization (with reductions of up to 9% in highly complex cases), alongside high agent satisfaction ratings from surveys. These results demonstrate that incremental summarization with continuous feedback effectively enhances summary quality and agent productivity at scale.", 'abstract_zh': '我们介绍了一种增量摘要系统，该系统能智能地在对话中确定何时生成简洁的要点笔记，从而减少客服代理的上下文切换 effort 和重复审查。我们的方法结合了对 Mixtral-8x7B 模型的微调以进行连续笔记生成，并使用基于 DeBERTa 的分类器来过滤琐碎内容。代理编辑 refinement 优化了在线笔记生成，并定期更新离线模型训练，形成了代理编辑反馈循环。在生产环境中部署后，与批量摘要相比，该系统实现了案例处理时间减少 3%（复杂案例最多减少 9%）的成绩，并获得了高满意度评分。这些结果表明，带有持续反馈的增量摘要能够有效提升总结质量并增强大规模的代理生产力。', 'title_zh': '基于逐步笔记和代理反馈的增量总结以支持客户支持'}
{'arxiv_id': 'arXiv:2510.06673', 'title': 'Heptapod: Language Modeling on Visual Signals', 'authors': 'Yongxin Zhu, Jiawei Chen, Yuanzhe Chen, Zhuo Chen, Dongya Jia, Jian Cong, Xiaobin Zhuang, Yuping Wang, Yuxuan Wang', 'link': 'https://arxiv.org/abs/2510.06673', 'abstract': 'We introduce Heptapod, an image autoregressive model that adheres to the foundational principles of language modeling. Heptapod employs \\textbf{causal attention}, \\textbf{eliminates reliance on CFG}, and \\textbf{eschews the trend of semantic tokenizers}. Our key innovation is \\textit{next 2D distribution prediction}: a causal Transformer with reconstruction-focused visual tokenizer, learns to predict the distribution over the entire 2D spatial grid of images at each timestep. This learning objective unifies the sequential modeling of autoregressive framework with the holistic self-supervised learning of masked autoencoding, enabling the model to capture comprehensive image semantics via generative training. On the ImageNet generation benchmark, Heptapod achieves an FID of $2.70$, significantly outperforming previous causal autoregressive approaches. We hope our work inspires a principled rethinking of language modeling on visual signals and beyond.', 'abstract_zh': '我们介绍了Heptapod，一种遵循语言模型基础原理的图像自回归模型。Heptapod采用因果注意力机制，消除对CFG的依赖，并摒弃语义分词趋势。我们的关键创新是“下一个2D分布预测”：一种以重构为重点的视觉分词因果Transformer，学习在每个时间步预测整个2D空间网格图像的概率分布。这一学习目标将自回归框架的序列建模与掩码自编码的整体自监督学习统一起来，使模型通过生成训练捕捉全面的图像语义。在ImageNet生成基准测试中，Heptapod的FID为2.70，显著优于先前的因果自回归方法。我们希望我们的工作能启发对视觉信号乃至更广泛领域语言模型原理性的重新思考。', 'title_zh': 'Heptapod：基于视觉信号的语言模型'}
{'arxiv_id': 'arXiv:2510.06669', 'title': 'Automated Neural Architecture Design for Industrial Defect Detection', 'authors': 'Yuxi Liu, Yunfeng Ma, Yi Tang, Min Liu, Shuai Jiang, Yaonan Wang', 'link': 'https://arxiv.org/abs/2510.06669', 'abstract': 'Industrial surface defect detection (SDD) is critical for ensuring product quality and manufacturing reliability. Due to the diverse shapes and sizes of surface defects, SDD faces two main challenges: intraclass difference and interclass similarity. Existing methods primarily utilize manually designed models, which require extensive trial and error and often struggle to address both challenges effectively. To overcome this, we propose AutoNAD, an automated neural architecture design framework for SDD that jointly searches over convolutions, transformers, and multi-layer perceptrons. This hybrid design enables the model to capture both fine-grained local variations and long-range semantic context, addressing the two key challenges while reducing the cost of manual network design. To support efficient training of such a diverse search space, AutoNAD introduces a cross weight sharing strategy, which accelerates supernet convergence and improves subnet performance. Additionally, a searchable multi-level feature aggregation module (MFAM) is integrated to enhance multi-scale feature learning. Beyond detection accuracy, runtime efficiency is essential for industrial deployment. To this end, AutoNAD incorporates a latency-aware prior to guide the selection of efficient architectures. The effectiveness of AutoNAD is validated on three industrial defect datasets and further applied within a defect imaging and detection platform. Code will be available at this https URL.', 'abstract_zh': '工业表面缺陷检测（SDD）对于确保产品质量和制造可靠性至关重要。由于表面缺陷的多样形状和尺寸，SDD 面临两大主要挑战：类内差异和类间相似性。现有方法主要依赖手工设计的模型，这需要大量的试错，并且往往难以同时有效应对这两个挑战。为克服这一问题，我们提出了一种名为 AutoNAD 的自动化神经架构设计框架，用于 SDD，该框架联合搜索卷积、变压器和多层感知机。这种混合设计使模型能够同时捕捉细粒度的局部变化和长范围的语义上下文，从而解决两个关键挑战，同时减少手动网络设计的成本。为了支持高效训练这种多样化的搜索空间，AutoNAD 引入了跨权重共享策略，加速超网络的收敛并提高子网的性能。此外，还集成了可搜索的多尺度特征聚合模块（MFAM），以增强多尺度特征学习。除了检测精度，运行时效率对于工业部署也至关重要。为此，AutoNAD 融合了感知延迟的先验知识，指导高效架构的选择。AutoNAD 的有效性已在三个工业缺陷数据集上得到验证，并进一步应用于缺陷影像和检测平台。代码将在此网址 https:// 提供。', 'title_zh': '工业缺陷检测的自动化神经网络架构设计'}
{'arxiv_id': 'arXiv:2510.06661', 'title': "Delay Independent Safe Control with Neural Networks: Positive Lur'e Certificates for Risk Aware Autonomy", 'authors': 'Hamidreza Montazeri Hedesh, Milad Siami', 'link': 'https://arxiv.org/abs/2510.06661', 'abstract': 'We present a risk-aware safety certification method for autonomous, learning enabled control systems. Focusing on two realistic risks, state/input delays and interval matrix uncertainty, we model the neural network (NN) controller with local sector bounds and exploit positivity structure to derive linear, delay-independent certificates that guarantee local exponential stability across admissible uncertainties. To benchmark performance, we adopt and implement a state-of-the-art IQC NN verification pipeline. On representative cases, our positivity-based tests run orders of magnitude faster than SDP-based IQC while certifying regimes the latter cannot-providing scalable safety guarantees that complement risk-aware control.', 'abstract_zh': '一种风险意识的安全认证方法：面向自主学习控制系统的安全性认证方法', 'title_zh': "基于神经网络的延迟无关安全控制：风险意识自主性的正Lur'e证明"}
{'arxiv_id': 'arXiv:2510.06649', 'title': 'Local Reinforcement Learning with Action-Conditioned Root Mean Squared Q-Functions', 'authors': 'Frank Wu, Mengye Ren', 'link': 'https://arxiv.org/abs/2510.06649', 'abstract': "The Forward-Forward (FF) Algorithm is a recently proposed learning procedure for neural networks that employs two forward passes instead of the traditional forward and backward passes used in backpropagation. However, FF remains largely confined to supervised settings, leaving a gap at domains where learning signals can be yielded more naturally such as RL. In this work, inspired by FF's goodness function using layer activity statistics, we introduce Action-conditioned Root mean squared Q-Functions (ARQ), a novel value estimation method that applies a goodness function and action conditioning for local RL using temporal difference learning. Despite its simplicity and biological grounding, our approach achieves superior performance compared to state-of-the-art local backprop-free RL methods in the MinAtar and the DeepMind Control Suite benchmarks, while also outperforming algorithms trained with backpropagation on most tasks. Code can be found at this https URL.", 'abstract_zh': '基于前向传播的Action-条件根均方Q函数（ARQ）方法', 'title_zh': '基于动作条件化的根均方Q函数的局部强化学习'}
{'arxiv_id': 'arXiv:2510.06646', 'title': 'The False Promise of Zero-Shot Super-Resolution in Machine-Learned Operators', 'authors': 'Mansi Sakarvadia, Kareem Hegazy, Amin Totounferoush, Kyle Chard, Yaoqing Yang, Ian Foster, Michael W. Mahoney', 'link': 'https://arxiv.org/abs/2510.06646', 'abstract': 'A core challenge in scientific machine learning, and scientific computing more generally, is modeling continuous phenomena which (in practice) are represented discretely. Machine-learned operators (MLOs) have been introduced as a means to achieve this modeling goal, as this class of architecture can perform inference at arbitrary resolution. In this work, we evaluate whether this architectural innovation is sufficient to perform "zero-shot super-resolution," namely to enable a model to serve inference on higher-resolution data than that on which it was originally trained. We comprehensively evaluate both zero-shot sub-resolution and super-resolution (i.e., multi-resolution) inference in MLOs. We decouple multi-resolution inference into two key behaviors: 1) extrapolation to varying frequency information; and 2) interpolating across varying resolutions. We empirically demonstrate that MLOs fail to do both of these tasks in a zero-shot manner. Consequently, we find MLOs are not able to perform accurate inference at resolutions different from those on which they were trained, and instead they are brittle and susceptible to aliasing. To address these failure modes, we propose a simple, computationally-efficient, and data-driven multi-resolution training protocol that overcomes aliasing and that provides robust multi-resolution generalization.', 'abstract_zh': '科学机器学习及科学计算中的一个核心挑战是建模连续现象，而在实践中这些现象是离散表示的。机器学习算子（MLOs）被提出作为一种实现这一建模目标的方法，因为这类架构可以在任意分辨率上进行推理。在本文中，我们评估这种架构创新是否足以实现“零样本超分辨率”，即使模型能够在高于其原始训练数据分辨率的数据上提供推理。我们全面评估了MLOs中的零样本亚分辨率和超分辨率（即多分辨率）推理。我们将多分辨率推理分解为两个关键行为：1）根据频率信息进行外推；2）跨不同分辨率进行插值。我们实验证明，MLOs无法在零样本情况下完成这两项任务。因此，我们发现MLOs无法在未训练过的分辨率上进行准确推理，而是显得脆弱且容易受到混叠的影响。为了应对这些失效模式，我们提出了一种简单、计算效率高且数据驱动的多分辨率训练协议，该协议克服了混叠问题，并提供了稳健的多分辨率泛化能力。', 'title_zh': '机器学习算子中零样本超分辨率的虚假承诺'}
{'arxiv_id': 'arXiv:2510.06645', 'title': 'Distilling Lightweight Language Models for C/C++ Vulnerabilities', 'authors': 'Zhiyuan Wei, Xiaoxuan Yang, Jing Sun, Zijian Zhang', 'link': 'https://arxiv.org/abs/2510.06645', 'abstract': 'The increasing complexity of modern software systems exacerbates the prevalence of security vulnerabilities, posing risks of severe breaches and substantial economic loss. Consequently, robust code vulnerability detection is essential for software security. While Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language processing, their potential for automated code vulnerability detection remains underexplored. This paper presents FineSec, a novel framework that harnesses LLMs through knowledge distillation to enable efficient and precise vulnerability identification in C/C++ codebases. FineSec utilizes knowledge distillation to transfer expertise from large teacher models to compact student models, achieving high accuracy with minimal computational cost. By integrating data preparation, training, evaluation, and continuous learning into a unified, single-task workflow, FineSec offers a streamlined approach. Extensive evaluations on C/C++ codebases demonstrate its superiority over both base models and larger LLMs in identifying complex vulnerabilities and logical flaws, establishing FineSec as a practical and scalable solution for real-world software security. To facilitate reproducibility, the datasets, source code, and experimental results are made publicly available at: this https URL.', 'abstract_zh': '现代软件系统的日益复杂加剧了安全漏洞的普遍性，带来了严重泄露和巨大经济损失的风险。因此，强大的代码漏洞检测对于软件安全至关重要。尽管大型语言模型（LLMs）在自然语言处理方面展现了卓越的能力，但它们在自动化代码漏洞检测方面的潜力尚未被充分探索。本文提出了一种名为FineSec的新颖框架，通过知识蒸馏利用LLMs，以实现对C/C++代码库中的高效精准漏洞识别。FineSec利用知识蒸馏将大型教师模型的知识传递给紧凑的学生模型，以在较小的计算成本下实现高精度。通过将数据准备、训练、评估和持续学习整合到统一的一体化单任务工作流中，FineSec提供了一种简化的方法。对C/C++代码库的广泛评估表明，FineSec在识别复杂漏洞和逻辑缺陷方面优于基础模型和更大规模的LLMs，确立了FineSec作为实际软件安全问题中实用且可扩展的解决方案的地位。为便于重复性，相关数据集、源代码和实验结果已公开发布于此：this https URL。', 'title_zh': '轻量级语言模型压缩以识别C/C++漏洞'}
{'arxiv_id': 'arXiv:2510.06638', 'title': 'StaR-KVQA: Structured Reasoning Traces for Implicit-Knowledge Visual Question Answering', 'authors': 'Zhihao Wen, Wenkang Wei, Yuan Fang, Xingtong Yu, Hui Zhang, Weicheng Zhu, Xin Zhang', 'link': 'https://arxiv.org/abs/2510.06638', 'abstract': 'Knowledge-based Visual Question Answering (KVQA) requires models to ground entities in images and reason over factual knowledge. We study its implicit-knowledge variant, IK-KVQA, where a multimodal large language model (MLLM) is the sole knowledge source, without external retrieval. Yet, MLLMs lack explicit reasoning supervision and produce inconsistent justifications, and generalize poorly after standard supervised fine-tuning (SFT). We present StaR-KVQA (Structured Reasoning Traces for IK-KVQA), which supervises structured traces - dual symbolic relation paths plus path-grounded natural-language explanations - so that reasoning becomes transparent and verifiable. With one open-source MLLM, StaR-KVQA constructs and selects path-grounded reasoning traces to form a trace-enriched dataset, then fine-tunes via structured self-distillation to align generation with supervision; no external retrievers, verifiers, or curated knowledge bases (KBs) are used, traces are built offline, and inference is a single autoregressive pass. Across benchmarks, StaR-KVQA improves both accuracy and interpretability, achieving up to +11.3% higher answer accuracy on OK-VQA over the strongest baseline while exhibiting robust cross-domain generalization.', 'abstract_zh': '基于知识的视觉问答（KVQA）要求模型在图像中定位实体并进行事实知识推理。我们研究其隐含知识变体IK-KVQA，其中多模态大型语言模型（MLLM）是唯一的知识来源，无需外部检索。然而，MLLM缺乏明确的推理监督，生成不一致的解释，并在标准监督细调（SFT）后泛化性能不佳。我们提出了StaR-KVQA（结构化推理轨迹用于IK-KVQA），对其进行结构化轨迹监督——双重符号关系路径加上路径支撑的自然语言解释——从而使推理变得透明和可验证。使用一个开源的MLLM，StaR-KVQA 构建并选择了路径支撑的推理轨迹以形成带有轨迹增强的数据集，然后通过结构化自我蒸馏进行微调以使生成与监督一致；未使用外部检索器、验证器或精心整理的知识库（KBs），轨迹离线构建，推理是一个单次自回归通过过程。在多个基准测试中，StaR-KVQA 提高了准确性和可解释性，与最强基线相比，在OK-VQA上的答案准确性提高了高达11.3%，并且表现出鲁棒的跨域泛化能力。', 'title_zh': 'StaR-KVQA: 结构化推理踪迹用于隐性知识视觉问答'}
{'arxiv_id': 'arXiv:2510.06637', 'title': 'Control-Augmented Autoregressive Diffusion for Data Assimilation', 'authors': 'Prakhar Srivastava, Farrin Marouf Sofian, Francesco Immorlano, Kushagra Pandey, Stephan Mandt', 'link': 'https://arxiv.org/abs/2510.06637', 'abstract': 'Despite recent advances in test-time scaling and finetuning of diffusion models, guidance in Auto-Regressive Diffusion Models (ARDMs) remains underexplored. We introduce an amortized framework that augments pretrained ARDMs with a lightweight controller network, trained offline by previewing future ARDM rollouts and learning stepwise controls that anticipate upcoming observations under a terminal cost objective. We evaluate this framework in the context of data assimilation (DA) for chaotic spatiotemporal partial differential equations (PDEs), a setting where existing methods are often computationally prohibitive and prone to forecast drift under sparse observations. Our approach reduces DA inference to a single forward rollout with on-the-fly corrections, avoiding expensive adjoint computations and/or optimizations during inference. We demonstrate that our method consistently outperforms four state-of-the-art baselines in stability, accuracy, and physical fidelity across two canonical PDEs and six observation regimes. We will release code and checkpoints publicly.', 'abstract_zh': '尽管近年来在扩散模型的测试时缩放和微调方面取得了进展，自动回归扩散模型（ARDMs）的引导仍待探索。我们提出了一种递归框架，该框架通过一个轻量级控制器网络来预训练的ARDMs进行增强，该控制器网络通过预览未来的ARDMs滚动预测并在终端成本目标下学习逐步控制以预见即将到来的观测值进行离线训练。我们在混沌时空偏微分方程（PDEs）的数据同化（DA）背景下评估了该框架，这是一个现有方法常常因计算成本高且在稀疏观测条件下容易出现预测漂移的场景。我们 Approach 将数据同化的推理归结为一次带有实时修正的前向滚动预测，避免了推理过程中昂贵的伴随计算和/或优化。我们展示了我们的方法在两个经典的PDE和六个观测条件下，在稳定性和准确性以及物理保真度方面始终优于四种最先进的基线方法。我们将公开发布代码和检查点。', 'title_zh': '控制增强自回归扩散数据同化'}
{'arxiv_id': 'arXiv:2510.06631', 'title': 'AI-Driven Forecasting and Monitoring of Urban Water System', 'authors': 'Qiming Guo, Bishal Khatri, Hua Zhang, Wenlu Wang', 'link': 'https://arxiv.org/abs/2510.06631', 'abstract': 'Underground water and wastewater pipelines are vital for city operations but plagued by anomalies like leaks and infiltrations, causing substantial water loss, environmental damage, and high repair costs. Conventional manual inspections lack efficiency, while dense sensor deployments are prohibitively expensive. In recent years, artificial intelligence has advanced rapidly and is increasingly applied to urban infrastructure. In this research, we propose an integrated AI and remote-sensor framework to address the challenge of leak detection in underground water pipelines, through deploying a sparse set of remote sensors to capture real-time flow and depth data, paired with HydroNet - a dedicated model utilizing pipeline attributes (e.g., material, diameter, slope) in a directed graph for higher-precision modeling. Evaluations on a real-world campus wastewater network dataset demonstrate that our system collects effective spatio-temporal hydraulic data, enabling HydroNet to outperform advanced baselines. This integration of edge-aware message passing with hydraulic simulations enables accurate network-wide predictions from limited sensor deployments. We envision that this approach can be effectively extended to a wide range of underground water pipeline networks.', 'abstract_zh': '地下供水和污水管道对于城市运营至关重要，但常受泄漏和渗漏等异常困扰，导致严重水资源损失、环境破坏和高昂的维修成本。传统的人工检查效率低下，而密集的传感器部署又成本高昂。近年来，人工智能技术取得了快速进步，并日益应用于城市基础设施。在本研究中，我们提出了一种集成人工智能和远程传感器的框架，用于解决地下供水管道泄漏检测的挑战，通过部署少量远程传感器来捕获实时流速和深度数据，并结合HydroNet模型——一种利用管道属性（如材料、直径、坡度）进行更精确建模的专用模型，以有向图的形式构建。在实际校园污水管网数据集上的评估表明，我们的系统能够收集有效的空间-时间水力数据，使HyroNet在性能上超越高级基线。这种基于边缘感知的消息传递与水力模拟的结合，使有限传感器部署能够实现全网准确预测。我们设想，此方法可以有效扩展应用于各种地下供水管道网络。', 'title_zh': 'AI驱动的城市水资源系统预测与监控'}
{'arxiv_id': 'arXiv:2510.06605', 'title': 'Reading Between the Lines: Towards Reliable Black-box LLM Fingerprinting via Zeroth-order Gradient Estimation', 'authors': 'Shuo Shao, Yiming Li, Hongwei Yao, Yifei Chen, Yuchen Yang, Zhan Qin', 'link': 'https://arxiv.org/abs/2510.06605', 'abstract': 'The substantial investment required to develop Large Language Models (LLMs) makes them valuable intellectual property, raising significant concerns about copyright protection. LLM fingerprinting has emerged as a key technique to address this, which aims to verify a model\'s origin by extracting an intrinsic, unique signature (a "fingerprint") and comparing it to that of a source model to identify illicit copies. However, existing black-box fingerprinting methods often fail to generate distinctive LLM fingerprints. This ineffectiveness arises because black-box methods typically rely on model outputs, which lose critical information about the model\'s unique parameters due to the usage of non-linear functions. To address this, we first leverage Fisher Information Theory to formally demonstrate that the gradient of the model\'s input is a more informative feature for fingerprinting than the output. Based on this insight, we propose ZeroPrint, a novel method that approximates these information-rich gradients in a black-box setting using zeroth-order estimation. ZeroPrint overcomes the challenge of applying this to discrete text by simulating input perturbations via semantic-preserving word substitutions. This operation allows ZeroPrint to estimate the model\'s Jacobian matrix as a unique fingerprint. Experiments on the standard benchmark show ZeroPrint achieves a state-of-the-art effectiveness and robustness, significantly outperforming existing black-box methods.', 'abstract_zh': '大型语言模型（LLMs）的开发需要大量投资，使其成为有价值的知识产权，引发了关于版权保护的重要 concern。LLM 指纹识别已经成为解决这一问题的关键技术，旨在通过提取内在的独特签名（“指纹”）并与源模型进行比较来验证模型的起源，以识别非法副本。然而，现有的黑盒指纹识别方法往往无法生成独特的LLM 指纹。这种无效性源于黑盒方法通常依赖于模型输出，而线性函数的使用导致了关键信息关于模型独特参数的损失。为解决这一问题，我们首先利用费雪信息理论正式证明了模型输入的梯度比输出更能提供指纹识别信息。基于这一洞察，我们提出了零印（ZeroPrint）这一新颖方法，在黑盒环境中使用零阶估计近似这些信息丰富的梯度。零印通过语义保留的单词替代模拟输入扰动来克服将此应用于离散文本的挑战。这一操作使零印能够估计模型的雅可比矩阵作为独特指纹。在标准基准上的实验显示，零印达到了最先进的有效性和稳健性，显著优于现有黑盒方法。', 'title_zh': '细读其中之意：通过零阶梯度估计实现可靠的黑盒大模型指纹识别'}
{'arxiv_id': 'arXiv:2510.06596', 'title': 'SDQM: Synthetic Data Quality Metric for Object Detection Dataset Evaluation', 'authors': 'Ayush Zenith, Arnold Zumbrun, Neel Raut, Jing Lin', 'link': 'https://arxiv.org/abs/2510.06596', 'abstract': 'The performance of machine learning models depends heavily on training data. The scarcity of large-scale, well-annotated datasets poses significant challenges in creating robust models. To address this, synthetic data generated through simulations and generative models has emerged as a promising solution, enhancing dataset diversity and improving the performance, reliability, and resilience of models. However, evaluating the quality of this generated data requires an effective metric. This paper introduces the Synthetic Dataset Quality Metric (SDQM) to assess data quality for object detection tasks without requiring model training to converge. This metric enables more efficient generation and selection of synthetic datasets, addressing a key challenge in resource-constrained object detection tasks. In our experiments, SDQM demonstrated a strong correlation with the mean Average Precision (mAP) scores of YOLOv11, a leading object detection model, while previous metrics only exhibited moderate or weak correlations. Additionally, it provides actionable insights for improving dataset quality, minimizing the need for costly iterative training. This scalable and efficient metric sets a new standard for evaluating synthetic data. The code for SDQM is available at this https URL', 'abstract_zh': '机器学习模型的性能高度依赖于训练数据。大规模、高质量标注数据的稀缺性给构建 robust 模型带来了重大挑战。为应对这一挑战，通过模拟和生成模型生成的合成数据已成为一种有前景的解决方案，提升了数据集的多样性并改善了模型的性能、可靠性和韧性。然而，评估这种生成数据的质量需要有效的度量标准。本文提出合成数据质量度量标准（SDQM）来评估物体检测任务中的数据质量，无需模型训练收敛。该度量标准有助于更高效地生成和选择合成数据集，解决了资源受限物体检测任务中的关键挑战。在我们的实验中，SDQM 与领先物体检测模型 YOLOv11 的平均准确率均值（mAP）分显示出强烈的相关性，而以往的度量标准仅表现出中等或弱的相关性。此外，它还提供了改进数据集质量的实用建议，减少了昂贵迭代训练的需求。该可扩展且高效的度量标准为评估合成数据设立了新标准。SDQM 的代码可通过以下链接获取：this https URL', 'title_zh': 'SDQM：对象检测数据集评估中的合成数据质量度量'}
{'arxiv_id': 'arXiv:2510.06567', 'title': 'The Framework That Survives Bad Models: Human-AI Collaboration For Clinical Trials', 'authors': 'Yao Chen, David Ohlssen, Aimee Readie, Gregory Ligozio, Ruvie Martin, Thibaud Coroller', 'link': 'https://arxiv.org/abs/2510.06567', 'abstract': 'Artificial intelligence (AI) holds great promise for supporting clinical trials, from patient recruitment and endpoint assessment to treatment response prediction. However, deploying AI without safeguards poses significant risks, particularly when evaluating patient endpoints that directly impact trial conclusions. We compared two AI frameworks against human-only assessment for medical image-based disease evaluation, measuring cost, accuracy, robustness, and generalization ability. To stress-test these frameworks, we injected bad models, ranging from random guesses to naive predictions, to ensure that observed treatment effects remain valid even under severe model degradation. We evaluated the frameworks using two randomized controlled trials with endpoints derived from spinal X-ray images. Our findings indicate that using AI as a supporting reader (AI-SR) is the most suitable approach for clinical trials, as it meets all criteria across various model types, even with bad models. This method consistently provides reliable disease estimation, preserves clinical trial treatment effect estimates and conclusions, and retains these advantages when applied to different populations.', 'abstract_zh': '人工智能（AI）在支持临床试验中的前景广阔，从患者招募、终点评估到治疗反应预测。然而，缺乏保障的AI应用存在重大风险，特别是在评估直接影响试验结论的患者终点时。我们对比了两种AI框架与仅人类评估在基于医学影像的疾病评估中的表现，测量了成本、准确性、鲁棒性和泛化能力。为测试这些框架，我们注入了从随机猜测到简单预测的各种不良模型，确保在模型严重退化的情况下，观察到的治疗效果依然有效。我们使用两个随机对照试验和来自脊柱X光片的终点评估结果来评估这些框架。我们的研究结果表明，使用AI作为辅助读片者（AI-SR）是临床试验中最合适的方案，即使在存在不良模型的情况下也能满足各种模型类型的要求。这种方法一致地提供了可靠疾病估计，保持了临床试验治疗效果估计和结论的完整性，并在应用于不同人群时仍保留这些优势。', 'title_zh': '一种能在模型不佳时生存的框架：临床试验中的人工智能协作'}
{'arxiv_id': 'arXiv:2510.06564', 'title': 'HSNet: Heterogeneous Subgraph Network for Single Image Super-resolution', 'authors': 'Qiongyang Hu, Wenyang Liu, Wenbin Zou, Yuejiao Su, Lap-Pui Chau, Yi Wang', 'link': 'https://arxiv.org/abs/2510.06564', 'abstract': 'Existing deep learning approaches for image super-resolution, particularly those based on CNNs and attention mechanisms, often suffer from structural inflexibility. Although graph-based methods offer greater representational adaptability, they are frequently impeded by excessive computational complexity. To overcome these limitations, this paper proposes the Heterogeneous Subgraph Network (HSNet), a novel framework that efficiently leverages graph modeling while maintaining computational feasibility. The core idea of HSNet is to decompose the global graph into manageable sub-components. First, we introduce the Constructive Subgraph Set Block (CSSB), which generates a diverse set of complementary subgraphs. Rather than relying on a single monolithic graph, CSSB captures heterogeneous characteristics of the image by modeling different relational patterns and feature interactions, producing a rich ensemble of both local and global graph structures. Subsequently, the Subgraph Aggregation Block (SAB) integrates the representations embedded across these subgraphs. Through adaptive weighting and fusion of multi-graph features, SAB constructs a comprehensive and discriminative representation that captures intricate interdependencies. Furthermore, a Node Sampling Strategy (NSS) is designed to selectively retain the most salient features, thereby enhancing accuracy while reducing computational overhead. Extensive experiments demonstrate that HSNet achieves state-of-the-art performance, effectively balancing reconstruction quality with computational efficiency. The code will be made publicly available.', 'abstract_zh': 'Heterogeneous Subgraph Network for Efficient and Adaptive Image Super-Resolution', 'title_zh': 'HSNet: 异构子图网络在单张图像超分辨率中的应用'}
{'arxiv_id': 'arXiv:2510.06559', 'title': "The Algebra of Meaning: Why Machines Need Montague More Than Moore's Law", 'authors': 'Cheonkam Jeong, Sungdo Kim, Jewoo Park', 'link': 'https://arxiv.org/abs/2510.06559', 'abstract': 'Contemporary language models are fluent yet routinely mis-handle the types of meaning their outputs entail. We argue that hallucination, brittle moderation, and opaque compliance outcomes are symptoms of missing type-theoretic semantics rather than data or scale limitations. Building on Montague\'s view of language as typed, compositional algebra, we recast alignment as a parsing problem: natural-language inputs must be compiled into structures that make explicit their descriptive, normative, and legal dimensions under context.\nWe present Savassan, a neuro-symbolic architecture that compiles utterances into Montague-style logical forms and maps them to typed ontologies extended with deontic operators and jurisdictional contexts. Neural components extract candidate structures from unstructured inputs; symbolic components perform type checking, constraint reasoning, and cross-jurisdiction mapping to produce compliance-aware guidance rather than binary censorship. In cross-border scenarios, the system "parses once" (e.g., defect claim(product x, company y)) and projects the result into multiple legal ontologies (e.g., defamation risk in KR/JP, protected opinion in US, GDPR checks in EU), composing outcomes into a single, explainable decision.\nThis paper contributes: (i) a diagnosis of hallucination as a type error; (ii) a formal Montague-ontology bridge for business/legal reasoning; and (iii) a production-oriented design that embeds typed interfaces across the pipeline. We outline an evaluation plan using legal reasoning benchmarks and synthetic multi-jurisdiction suites. Our position is that trustworthy autonomy requires compositional typing of meaning, enabling systems to reason about what is described, what is prescribed, and what incurs liability within a unified algebra of meaning.', 'abstract_zh': '当代语言模型虽然流利，但经常错误处理其输出所蕴含的类型意义。我们认为，幻觉、脆弱的控制以及不透明的合规结果是缺少类型理论语义的症状，而非数据或规模限制的问题。基于蒙塔古关于语言为类型化和组合代数的观点，我们将对齐重新定义为一个解析问题：自然语言输入必须被编译成结构，这些结构在其上下文中明确地体现出描述性、规范性和法律性维度。\n\n我们提出了Savassan，一个神经符号架构，将陈述编译为蒙塔古风格的逻辑形式，并映射到扩展了道义运算和管辖域上下文的类型化本体上。神经组件从无结构输入中提取候选结构；符号组件执行类型检查、约束推理和跨管辖域映射，以产生合规意识指导而非二元审查。在跨国场景中，该系统“一次解析”（例如，缺陷索赔（产品x，公司y））并将结果投影到多个法律本体中（例如，在KR/JP中判断诽谤风险，在US中判断保护意见，在EU中进行GDPR检查），将结果组合成一个可解释的决策。\n\n本文贡献：（i）将幻觉诊断为类型错误；（ii）建立形式化的蒙塔古本体桥接以支持商业/法律推理；（iii）一个生产导向的设计，贯穿流水线嵌入类型化界面。我们提出了一个使用法律推理基准和合成跨国套件进行评估的计划。我们认为，可信赖的自主性需要语义的组合类型化，使系统能够在统一的意义代数中推理描述、规范和法律责任。', 'title_zh': '意义代数：机器为何需要蒙塔古而非摩尔定律'}
{'arxiv_id': 'arXiv:2510.06557', 'title': 'The Markovian Thinker', 'authors': 'Milad Aghajohari, Kamran Chitsaz, Amirhossein Kazemnejad, Sarath Chandar, Alessandro Sordoni, Aaron Courville, Siva Reddy', 'link': 'https://arxiv.org/abs/2510.06557', 'abstract': 'Reinforcement learning (RL) has recently become a strong recipe for training reasoning LLMs that produce long chains of thought (LongCoT). Yet the standard RL "thinking environment", where the state is the prompt plus all prior reasoning tokens, makes the state unbounded and forces attention-based policies to pay quadratic compute as thoughts lengthen. We revisit the environment itself. We propose Markovian Thinking, a paradigm in which the policy advances reasoning while conditioning on a constant-size state, decoupling thinking length from context size. As an immediate consequence this yields linear compute with constant memory. We instantiate this idea with Delethink, an RL environment that structures reasoning into fixed-size chunks. Within each chunk, the model thinks as usual; at the boundary, the environment resets the context and reinitializes the prompt with a short carryover. Through RL, the policy learns to write a textual state near the end of each chunk sufficient for seamless continuation of reasoning after reset. Trained in this environment, an R1-Distill 1.5B model reasons in 8K-token chunks yet thinks up to 24K tokens, matching or surpassing LongCoT-RL trained with a 24K budget. With test-time scaling, Delethink continues to improve where LongCoT plateaus. The effect of linear compute is substantial: we empirically estimate at 96K average thinking length LongCoT-RL costs 27 H100-months vs. 7 for Delethink. Analysis at RL initialization shows off-the-shelf reasoning models (1.5B-120B) often sample Markovian traces zero-shot across diverse benchmarks, providing positive samples that make RL effective at scale. Our results show that redesigning the thinking environment is a powerful lever: it enables very long reasoning without quadratic overhead and opens a path toward efficient, scalable reasoning LLMs.', 'abstract_zh': '标记化思维：一种线性计算的长期链条推理强化学习环境', 'title_zh': '马尔可夫思维者'}
{'arxiv_id': 'arXiv:2510.06545', 'title': 'Incoherence in goal-conditioned autoregressive models', 'authors': 'Jacek Karwowski, Raymond Douglas', 'link': 'https://arxiv.org/abs/2510.06545', 'abstract': 'We investigate mathematically the notion of incoherence: a structural issue with reinforcement learning policies derived by naive goal-conditioning of autoregressive models. We focus on the process of re-training models on their own actions, that is, fine-tuning offline-learned policies with online RL. We prove that it decreases incoherence and leads to an improvement in return, and we aim to characterize the resulting trajectory of policies. By re-framing standard notions of control-as-inference and soft Q learning, we establish a three-way correspondence with two other ways of understanding the iterative re-training process: as folding the posterior into the reward and, in the deterministic case, as decreasing the temperature parameter; the correspondence has computational content via the training-inference trade-off. Through soft-conditioning generative models, we discuss the link between incoherence and the effective horizon.', 'abstract_zh': '我们从数学上探讨不一致性的问题：自回归模型通过天真目标调节衍生的强化学习策略中的结构问题。我们集中在重新训练模型在其自身动作上的过程，即用在线RL微调离线学习的策略。我们证明了这一过程减少了不一致性并提高了回报，并旨在描述由此产生的策略轨迹。通过重新定义控制即推理和软Q学习的标准概念，我们建立了重新训练过程的三重对应关系，分别与后验纳入奖励和在确定性情况下减少温度参数的理解方式相对应；该对应关系通过训练与推理之间的权衡具有计算内容。通过软条件生成模型，我们讨论了不一致性与有效时间范围之间的联系。', 'title_zh': '目标条件自回归模型中的不一致性'}
{'arxiv_id': 'arXiv:2510.06540', 'title': 'Scalable Policy-Based RL Algorithms for POMDPs', 'authors': 'Ameya Anjarlekar, Rasoul Etesami, R Srikant', 'link': 'https://arxiv.org/abs/2510.06540', 'abstract': 'The continuous nature of belief states in POMDPs presents significant computational challenges in learning the optimal policy. In this paper, we consider an approach that solves a Partially Observable Reinforcement Learning (PORL) problem by approximating the corresponding POMDP model into a finite-state Markov Decision Process (MDP) (called Superstate MDP). We first derive theoretical guarantees that improve upon prior work that relate the optimal value function of the transformed Superstate MDP to the optimal value function of the original POMDP. Next, we propose a policy-based learning approach with linear function approximation to learn the optimal policy for the Superstate MDP. Consequently, our approach shows that a POMDP can be approximately solved using TD-learning followed by Policy Optimization by treating it as an MDP, where the MDP state corresponds to a finite history. We show that the approximation error decreases exponentially with the length of this history. To the best of our knowledge, our finite-time bounds are the first to explicitly quantify the error introduced when applying standard TD learning to a setting where the true dynamics are not Markovian.', 'abstract_zh': 'POMDP中信念状态的连续性给最优策略的学习带来了显著的计算挑战。本文考虑了一种通过将相应的POMDP模型近似为有限状态马尔科夫决策过程（MDP）（称为超状态MDP）来解决部分可观测强化学习（PORL）问题的方法。首先，我们推导出理论保证，改进了先前将转换后的超状态MDP的最优值函数与其原始POMDP的最优值函数之间的关系的工作。接着，我们提出了一种基于策略的学习方法，使用线性函数逼近来学习超状态MDP的最优策略。因此，我们的方法表明，可以将POMDP近似为MDP，使用TD学习和策略优化进行求解，其中MDP状态对应于有限的历史记录。我们展示了该近似误差随着历史记录长度的增加呈指数级减少。据我们所知，我们的有限时间边界是首次明确量化标准TD学习应用于非马尔可夫性真实动力学环境时引入的误差。', 'title_zh': '基于策略的可扩展POMDPs RL算法'}
{'arxiv_id': 'arXiv:2510.06532', 'title': 'CLAQS: Compact Learnable All-Quantum Token Mixer with Shared-ansatz for Text Classification', 'authors': 'Junhao Chen, Yifan Zhou, Hanqi Jiang, Yi Pan, Yiwei Li, Huaqin Zhao, Wei Zhang, Yingfeng Wang, Tianming Liu', 'link': 'https://arxiv.org/abs/2510.06532', 'abstract': 'Quantum compute is scaling fast, from cloud QPUs to high throughput GPU simulators, making it timely to prototype quantum NLP beyond toy tasks. However, devices remain qubit limited and depth limited, training can be unstable, and classical attention is compute and memory heavy. This motivates compact, phase aware quantum token mixers that stabilize amplitudes and scale to long sequences. We present CLAQS, a compact, fully quantum token mixer for text classification that jointly learns complex-valued mixing and nonlinear transformations within a unified quantum circuit. To enable stable end-to-end optimization, we apply l1 normalization to regulate amplitude scaling and introduce a two-stage parameterized quantum architecture that decouples shared token embeddings from a window-level quantum feed-forward module. Operating under a sliding-window regime with document-level aggregation, CLAQS requires only eight data qubits and shallow circuits, yet achieves 91.64% accuracy on SST-2 and 87.08% on IMDB, outperforming both classical Transformer baselines and strong hybrid quantum-classical counterparts.', 'abstract_zh': '量子计算正快速扩展，从云端量子处理器到高吞吐量GPU模拟器，这使得超越玩具任务原型化量子NLP变得及时。然而，设备仍然受限于量子位数量和电路深度，训练可能不稳定，经典注意力机制计算和内存密集。这激励了紧凑且相位感知的量子token混配器，能够稳定振幅并扩展到长序列。我们提出CLAQS，这是一种用于文本分类的紧凑型全量子token混配器，在统一量子电路中联合学习复数混配和非线性变换。为了实现端到端优化的稳定性，我们应用L1归一化来调节振幅缩放，并引入两阶段参数化量子架构，将共享token嵌入与窗口级量子前馈模块解耦。在文档级别聚合的滑动窗口模式下，CLAQS仅需八个数据量子位和浅层电路，但在SST-2上达到91.64%的准确性，在IMDB上达到87.08%，优于经典Transformer基线和强大的量子-经典混合对手。', 'title_zh': 'CLAQS: 紧凑可学习的全量子 token 混合器与共享 ansatz 用于文本分类'}
{'arxiv_id': 'arXiv:2510.06517', 'title': 'Visualizing Multimodality in Combinatorial Search Landscapes', 'authors': 'Xavier F. C. Sánchez-Díaz, Ole Jakob Mengshoel', 'link': 'https://arxiv.org/abs/2510.06517', 'abstract': 'This work walks through different visualization techniques for combinatorial search landscapes, focusing on multimodality. We discuss different techniques from the landscape analysis literature, and how they can be combined to provide a more comprehensive view of the search landscape. We also include examples and discuss relevant work to show how others have used these techniques in practice, based on the geometric and aesthetic elements of the Grammar of Graphics. We conclude that there is no free lunch in visualization, and provide recommendations for future work as there are several paths to continue the work in this field.', 'abstract_zh': '本研究探讨组合搜索景观的不同可视化技术，重点讨论多模态性。我们讨论来自景观分析文献的不同技术，并探讨如何将这些技术结合起来提供更为全面的搜索景观视图。我们还通过几何和审美元素中的图形语法示例来展示这些技术在实践中的应用，并讨论相关研究工作。我们得出结论，在可视化中没有免费午餐，并为未来工作提供建议，因为在该领域还有多种路径可以继续研究。', 'title_zh': '可视化组合搜索景观中的多模态性'}
{'arxiv_id': 'arXiv:2510.06512', 'title': 'LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval', 'authors': 'Avishree Khare, Hideki Okamoto, Bardh Hoxha, Georgios Fainekos, Rajeev Alur', 'link': 'https://arxiv.org/abs/2510.06512', 'abstract': 'Neural models such as YOLO and HuBERT can be used to detect local properties such as objects ("car") and emotions ("angry") in individual frames of videos and audio clips respectively. The likelihood of these detections is indicated by scores in [0, 1]. Lifting these scores to temporal properties over sequences can be useful for several downstream applications such as query matching (e.g., "does the speaker eventually sound happy in this audio clip?"), and ranked retrieval (e.g., "retrieve top 5 videos with a 10 second scene where a car is detected until a pedestrian is detected"). In this work, we formalize this problem of assigning Scores for TempOral Properties (STOPs) over sequences, given potentially noisy score predictors for local properties. We then propose a scoring function called LogSTOP that can efficiently compute these scores for temporal properties represented in Linear Temporal Logic. Empirically, LogSTOP, with YOLO and HuBERT, outperforms Large Vision / Audio Language Models and other Temporal Logic-based baselines by at least 16% on query matching with temporal properties over objects-in-videos and emotions-in-speech respectively. Similarly, on ranked retrieval with temporal properties over objects and actions in videos, LogSTOP with Grounding DINO and SlowR50 reports at least a 19% and 16% increase in mean average precision and recall over zero-shot text-to-video retrieval baselines respectively.', 'abstract_zh': '基于序列的时间属性评分问题：给定局部属性分数预测器，利用神经模型进行时间属性评分', 'title_zh': 'LogSTOP: 预测序列的时序得分用于匹配和检索'}
{'arxiv_id': 'arXiv:2510.06505', 'title': 'A Median Perspective on Unlabeled Data for Out-of-Distribution Detection', 'authors': 'Momin Abbas, Ali Falahati, Hossein Goli, Mohammad Mohammadi Amiri', 'link': 'https://arxiv.org/abs/2510.06505', 'abstract': 'Out-of-distribution (OOD) detection plays a crucial role in ensuring the robustness and reliability of machine learning systems deployed in real-world applications. Recent approaches have explored the use of unlabeled data, showing potential for enhancing OOD detection capabilities. However, effectively utilizing unlabeled in-the-wild data remains challenging due to the mixed nature of both in-distribution (InD) and OOD samples. The lack of a distinct set of OOD samples complicates the task of training an optimal OOD classifier. In this work, we introduce Medix, a novel framework designed to identify potential outliers from unlabeled data using the median operation. We use the median because it provides a stable estimate of the central tendency, as an OOD detection mechanism, due to its robustness against noise and outliers. Using these identified outliers, along with labeled InD data, we train a robust OOD classifier. From a theoretical perspective, we derive error bounds that demonstrate Medix achieves a low error rate. Empirical results further substantiate our claims, as Medix outperforms existing methods across the board in open-world settings, confirming the validity of our theoretical insights.', 'abstract_zh': '出了分布(OOD)检测在确保部署在实际应用中的人工智能系统的稳健性和可靠性方面起着关键作用。最近的方法探索了使用未标记数据的潜力，以增强OOD检测能力。然而，有效地利用野外未标记数据仍然极具挑战性，因为内部分布(InD)和OOD样本的混合性质使得训练最优OOD分类器的任务复杂化。在这项工作中，我们提出了Medix，一种新型框架，用于通过中位数操作从未标记数据中识别潜在异常值。我们使用中位数，因为它提供了一种稳健的中心趋势估计，作为OOD检测机制，因为它对噪声和异常值具有鲁棒性。利用这些标识的异常值以及标记的InD数据，我们训练了一个稳健的OOD分类器。从理论上看，我们推导出错误界线以证明Medix实现了低错误率。经验结果进一步证实了我们的论点，Medix在开放世界的设定中优于现有方法，证实了我们理论洞见的有效性。', 'title_zh': '基于未标记数据的分布外检测中位数视角'}
{'arxiv_id': 'arXiv:2510.06503', 'title': 'ATLO-ML: Adaptive Time-Length Optimizer for Machine Learning -- Insights from Air Quality Forecasting', 'authors': 'I-Hsi Kao, Kanji Uchino', 'link': 'https://arxiv.org/abs/2510.06503', 'abstract': 'Accurate time-series predictions in machine learning are heavily influenced by the selection of appropriate input time length and sampling rate. This paper introduces ATLO-ML, an adaptive time-length optimization system that automatically determines the optimal input time length and sampling rate based on user-defined output time length. The system provides a flexible approach to time-series data pre-processing, dynamically adjusting these parameters to enhance predictive performance. ATLO-ML is validated using air quality datasets, including both GAMS-dataset and proprietary data collected from a data center, both in time series format. Results demonstrate that utilizing the optimized time length and sampling rate significantly improves the accuracy of machine learning models compared to fixed time lengths. ATLO-ML shows potential for generalization across various time-sensitive applications, offering a robust solution for optimizing temporal input parameters in machine learning workflows.', 'abstract_zh': '适配时间长度优化的机器学习系统：自动确定基于用户定义输出时间长度的最优输入时间长度和采样率', 'title_zh': 'ATLO-ML：机器学习的自适应时间和长度优化器——以空气质量预测为例'}
{'arxiv_id': 'arXiv:2510.06499', 'title': 'Webscale-RL: Automated Data Pipeline for Scaling RL Data to Pretraining Levels', 'authors': 'Zhepeng Cen, Haolin Chen, Shiyu Wang, Zuxin Liu, Zhiwei Liu, Ding Zhao, Silvio Savarese, Caiming Xiong, Huan Wang, Weiran Yao', 'link': 'https://arxiv.org/abs/2510.06499', 'abstract': 'Large Language Models (LLMs) have achieved remarkable success through imitation learning on vast text corpora, but this paradigm creates a training-generation gap and limits robust reasoning. Reinforcement learning (RL) offers a more data-efficient solution capable of bridging this gap, yet its application has been constrained by a critical data bottleneck: existing RL datasets are orders of magnitude smaller and less diverse than web-scale pre-training corpora. To address this, we introduce the Webscale-RL pipeline, a scalable data engine that systematically converts large-scale pre-training documents into millions of diverse, verifiable question-answer pairs for RL. Using this pipeline, we construct the Webscale-RL dataset, containing 1.2 million examples across more than 9 domains. Our experiments show that the model trained on this dataset significantly outperforms continual pretraining and strong data refinement baselines across a suite of benchmarks. Notably, RL training with our dataset proves substantially more efficient, achieving the performance of continual pre-training with up to 100$\\times$ fewer tokens. Our work presents a viable path toward scaling RL to pre-training levels, enabling more capable and efficient language models.', 'abstract_zh': '大规模语言模型（LLMs）通过在大量文本语料库上进行模仿学习取得了显著的成功，但这一范式造成了训练-生成差距，并限制了稳健的推理能力。强化学习（RL）提供了一种更高效的数据解决方案，能够弥补这一差距，然而其应用受到一个关键技术数据瓶颈的限制：现有的RL数据集在规模和多样性上远逊于面向网络规模的预训练语料库。为了解决这个问题，我们引入了Webscale-RL管道，这是一种可扩展的数据引擎，能够系统地将大规模预训练文档转换为数以百万计的多样化、可验证的问题-答案对，用于强化学习。借助这一管道，我们构建了Webscale-RL数据集，包含超过9个领域的120万个示例。我们的实验表明，该数据集训练的模型在一系列基准测试中的表现显著优于持续预训练和强大的数据精炼基线。值得注意的是，使用我们数据集的RL训练表现出极大的效率，实现了与最多100倍少的令牌量的持续预训练相当的性能。我们的工作为将RL扩展到预训练水平提供了可行路径，有望促进更多强大和高效的语言模型的发展。', 'title_zh': 'webscale-RL：自动化数据流水线，用于将RL数据扩展到预训练水平'}
{'arxiv_id': 'arXiv:2510.06478', 'title': 'Valid Stopping for LLM Generation via Empirical Dynamic Formal Lift', 'authors': 'Sanjeda Akter, Ibne Farabi Shihab, Anuj Sharma', 'link': 'https://arxiv.org/abs/2510.06478', 'abstract': 'We introduce Sequential-EDFL (Empirical Dynamic Formal Lift), applying anytime-valid sequential testing to language model generation stopping. Our approach tracks information lift -- the log-likelihood ratio between full models and deliberately weakened "skeleton" baselines -- using self-normalized empirical-Bernstein e-processes that provide formal delta-level error control regardless of stopping time. We handle unknown centering through online mean estimation, combine multiple parameters via mixture e-processes, and support adaptive resets under distributional drift. On six benchmarks, Sequential-EDFL reduces generation by 22-28% vs. sequential baselines while maintaining delta-level control with 12% computational overhead. We introduce automated skeletons (distilled submodels, randomized logits) and show robustness across skeleton families. Composing EDFL with a lightweight correctness gate (sentence boundaries + verifier) improves end-task correctness while preserving anytime-valid guarantees by only delaying stopping. Our certificates control information sufficiency, not factual correctness -- 10.9% of stopped sequences remain incorrect even with the gate (13.2-22.7% without it). EDFL serves as a first-stage filter reducing verification burden by 83%, not as a standalone solution for safety-critical domains.', 'abstract_zh': '我们引入了Sequential-EDFL（经验动态形式提升），将任意有效序列测试应用于语言模型生成停止。该方法使用自归一化经验伯恩斯坦e过程跟踪信息提升——即完整模型与故意削弱的“骨架”基线之间的对数似然比，并提供不受停止时间影响的正式delta级误差控制。通过在线均值估计处理未知中心化，通过混合e过程结合多个参数，并在分布漂移情况下支持自适应重置。在六个基准测试中，Sequential-EDFL相比序列基线将生成量减少了22-28%，同时通过12%的计算开销保持了delta级控制。我们引入了自动化骨架（精简子模型、随机化logits），并展示了其在不同骨架家族中的鲁棒性。将EDFL与轻量级正确性门（句子边界+验证器）结合，可以提高最终任务的正确性，同时通过仅延迟停止来保留任意有效保证。我们的证书控制信息充分性，而不是事实正确性，即使有门机制，仍有10.9%的停止序列是不正确的（没有门机制时，这一比例为13.2%-22.7%）。EDFL作为第一阶段过滤器可减少验证负担83%，而不是作为关键安全领域中的独立解决方案。', 'title_zh': '基于经验动态形式提升的LLM生成有效终止方法'}
{'arxiv_id': 'arXiv:2510.06477', 'title': 'Attention Sinks and Compression Valleys in LLMs are Two Sides of the Same Coin', 'authors': 'Enrique Queipo-de-Llano, Álvaro Arroyo, Federico Barbero, Xiaowen Dong, Michael Bronstein, Yann LeCun, Ravid Shwartz-Ziv', 'link': 'https://arxiv.org/abs/2510.06477', 'abstract': 'Attention sinks and compression valleys have attracted significant attention as two puzzling phenomena in large language models, but have been studied in isolation. In this work, we present a surprising connection between attention sinks and compression valleys, tracing both to the formation of massive activations in the residual stream. We prove theoretically that massive activations necessarily produce representational compression and establish bounds on the resulting entropy reduction. Through experiments across several models (410M-120B parameters), we confirm that when the beginning-of-sequence token develops extreme activation norms in the middle layers, both compression valleys and attention sinks emerge simultaneously. Targeted ablation studies validate our theoretical predictions. This unified view motivates us to propose the Mix-Compress-Refine theory of information flow, as an attempt to explain how LLMs organize their computation in depth by controlling attention and representational compression via massive activations. Specifically, we posit that Transformer-based LLMs process tokens in three distinct phases: (1) broad mixing in the early layers, (2) compressed computation with limited mixing in the middle layers, and (3) selective refinement in the late layers. Our framework helps explain why embedding tasks perform best at intermediate layers, whereas generation tasks benefit from full-depth processing, clarifying differences in task-dependent representations.', 'abstract_zh': '注意力陷阱和压缩谷值在大型语言模型中作为两个令人困惑的现象引起了广泛关注，但它们被单独研究。在这项工作中，我们提出了注意力陷阱和压缩谷值之间的意外联系，两者都追溯到残差流中巨大激活的形成。我们从理论上证明，巨大的激活必然导致表示压缩，并建立了其结果熵减少的边界。通过跨越多个模型（410M-120B参数）的实验，我们证实当序列起始标记在中间层发展出极端激活范数时，同时出现压缩谷值和注意力陷阱。目标消融实验验证了我们的理论预测。这一统一的视角促使我们提出了信息流的Mix-Compress-Refine理论，试图解释大型语言模型通过控制注意力和表示压缩来深度组织其计算的方式。具体而言，我们认为基于Transformer的大型语言模型在三个不同阶段处理标记：（1）早期层中的广泛混合，（2）中间层中的压缩计算伴随有限混合，以及（3）晚期层中的选择性精细处理。我们的框架有助于解释为什么嵌入任务在中间层表现最佳，而生成任务受益于全深度处理，澄清了任务依赖表示的差异。', 'title_zh': 'Attention Sinks and Compression Valleys in LLMs Are Two Sides of the Same Coin'}
{'arxiv_id': 'arXiv:2510.06473', 'title': 'Deep Generative Model for Human Mobility Behavior', 'authors': 'Ye Hong, Yatao Zhang, Konrad Schindler, Martin Raubal', 'link': 'https://arxiv.org/abs/2510.06473', 'abstract': 'Understanding and modeling human mobility is central to challenges in transport planning, sustainable urban design, and public health. Despite decades of effort, simulating individual mobility remains challenging because of its complex, context-dependent, and exploratory nature. Here, we present MobilityGen, a deep generative model that produces realistic mobility trajectories spanning days to weeks at large spatial scales. By linking behavioral attributes with environmental context, MobilityGen reproduces key patterns such as scaling laws for location visits, activity time allocation, and the coupled evolution of travel mode and destination choices. It reflects spatio-temporal variability and generates diverse, plausible, and novel mobility patterns consistent with the built environment. Beyond standard validation, MobilityGen yields insights not attainable with earlier models, including how access to urban space varies across travel modes and how co-presence dynamics shape social exposure and segregation. Our work establishes a new framework for mobility simulation, paving the way for fine-grained, data-driven studies of human behavior and its societal implications.', 'abstract_zh': '理解与建模人类移动性对于交通规划、可持续城市设计和公共卫生挑战至关重要。尽管经过几十年的努力，个体移动性的模拟仍然具有挑战性，因为其具有复杂性、情境依赖性和探索性。在这里，我们介绍了MobilityGen，这是一种深度生成模型，能够在大规模空间范围内生成从天到周的时间跨度的真实移动轨迹。通过将行为属性与环境背景联系起来，MobilityGen 重现了关键模式，如地点访问的标度律、活动时间分配以及出行方式和目的地选择的耦合进化。它反映了时空变化性，并生成与建成环境一致的各种可能和创新的移动模式。除了标准验证，MobilityGen 还提供了早期模型难以获得的见解，包括不同出行方式的城市空间可达性差异以及共在动态如何塑造社会暴露和隔离。我们的研究为移动性模拟建立了新的框架，为细粒度的、基于数据的人类行为及其社会影响的研究铺平了道路。', 'title_zh': '深度生成模型-human移动行为'}
{'arxiv_id': 'arXiv:2510.06457', 'title': 'Evaluating Node-tree Interfaces for AI Explainability', 'authors': 'Lifei Wang, Natalie Friedman, Chengchao Zhu, Zeshu Zhu, S.Joy Mountford', 'link': 'https://arxiv.org/abs/2510.06457', 'abstract': 'As large language models (LLMs) become ubiquitous in workplace tools and decision-making processes, ensuring explainability and fostering user trust are critical. Although advancements in LLM engineering continue, human-centered design is still catching up, particularly when it comes to embedding transparency and trust into AI interfaces. This study evaluates user experiences with two distinct AI interfaces - node-tree interfaces and chatbot interfaces - to assess their performance in exploratory, follow-up inquiry, decision-making, and problem-solving tasks. Our design-driven approach introduces a node-tree interface that visually structures AI-generated responses into hierarchically organized, interactive nodes, allowing users to navigate, refine, and follow up on complex information. In a comparative study with n=20 business users, we observed that while the chatbot interface effectively supports linear, step-by-step queries, it is the node-tree interface that enhances brainstorming. Quantitative and qualitative findings indicate that node-tree interfaces not only improve task performance and decision-making support but also promote higher levels of user trust by preserving context. Our findings suggest that adaptive AI interfaces capable of switching between structured visualizations and conversational formats based on task requirements can significantly enhance transparency and user confidence in AI-powered systems. This work contributes actionable insights to the fields of human-robot interaction and AI design, particularly for enterprise applications where trust-building is critical for teams.', 'abstract_zh': '随着大型语言模型（LLMs）在工作场所工具和决策过程中的广泛应用，确保可解释性和促进用户信任至关重要。尽管在LLM工程方面取得了进展，但在嵌入透明度和信任方面的人本化设计仍然滞后。本研究评估了两种不同的AI界面——节点树界面和聊天机器人界面——在探索性查询、后续查询、决策和解决问题任务中的性能。我们的以设计为导向的方法引入了一种节点树界面，该界面通过层次组织和交互式节点可视化地结构化AI生成的响应，使用户能够导航、完善和跟进复杂信息。在20名商务用户的对照研究中，我们观察到，尽管聊天机器人界面有效地支持线性、逐步查询，但节点树界面增强了头脑风暴。定量和定性研究结果表明，节点树界面不仅提高了任务性能和决策支持水平，还通过保留上下文提高了用户信任水平。研究结果表明，能够根据任务需求在结构化可视化和对话格式之间切换的自适应AI界面可以显著增强人工智能系统的透明度和用户信心。本研究为人类-机器人交互和AI设计领域，尤其是对需要建立信任的企业应用，提供了可操作的见解。', 'title_zh': '评估节点树界面的AI可解释性'}
{'arxiv_id': 'arXiv:2510.06448', 'title': 'How NOT to benchmark your SITE metric: Beyond Static Leaderboards and Towards Realistic Evaluation', 'authors': 'Prabhant Singh, Sibylle Hess, Joaquin Vanschoren', 'link': 'https://arxiv.org/abs/2510.06448', 'abstract': 'Transferability estimation metrics are used to find a high-performing pre-trained model for a given target task without fine-tuning models and without access to the source dataset. Despite the growing interest in developing such metrics, the benchmarks used to measure their progress have gone largely unexamined. In this work, we empirically show the shortcomings of widely used benchmark setups to evaluate transferability estimation metrics. We argue that the benchmarks on which these metrics are evaluated are fundamentally flawed. We empirically demonstrate that their unrealistic model spaces and static performance hierarchies artificially inflate the perceived performance of existing metrics, to the point where simple, dataset-agnostic heuristics can outperform sophisticated methods. Our analysis reveals a critical disconnect between current evaluation protocols and the complexities of real-world model selection. To address this, we provide concrete recommendations for constructing more robust and realistic benchmarks to guide future research in a more meaningful direction.', 'abstract_zh': '转让性评估指标的基准测试设置存在缺陷：实证分析表明广泛使用的转让性评估指标基准测试设置存在缺陷，并提出构建更 robust 和现实基准的建议。', 'title_zh': '如何不benchmark你的 SITE 指标：超越静态排行榜，迈向实际评估'}
{'arxiv_id': 'arXiv:2510.06445', 'title': 'A Survey on Agentic Security: Applications, Threats and Defenses', 'authors': 'Asif Shahriar, Md Nafiu Rahman, Sadif Ahmed, Farig Sadeque, Md Rizwan Parvez', 'link': 'https://arxiv.org/abs/2510.06445', 'abstract': 'The rapid shift from passive LLMs to autonomous LLM-agents marks a new paradigm in cybersecurity. While these agents can act as powerful tools for both offensive and defensive operations, the very agentic context introduces a new class of inherent security risks. In this work we present the first holistic survey of the agentic security landscape, structuring the field around three interdependent pillars: Applications, Threats, and Defenses. We provide a comprehensive taxonomy of over 150 papers, explaining how agents are used, the vulnerabilities they possess, and the countermeasures designed to protect them. A detailed cross-cutting analysis shows emerging trends in agent architecture while revealing critical research gaps in model and modality coverage.', 'abstract_zh': '快速从被动的大语言模型转向自主的大语言模型代理标志着网络安全领域的新范式。尽管这些代理可以作为强大的工具用于 Offensive 和 Defensive 操作，但自主性的引入带来了新的内在安全风险。在这项工作中，我们首次综述了代理安全景观，围绕三个相互依存的支柱：应用、威胁和防御构建领域。我们提供了一百余篇论文的全面分类体系，解释了代理的使用方式、它们所具备的漏洞以及设计的防护措施。详细的横向分析显示出代理架构的发展趋势，同时也揭示了模型和模态覆盖方面的关键研究缺口。', 'title_zh': '代理安全综述：应用、威胁与防御'}
{'arxiv_id': 'arXiv:2510.06444', 'title': 'Context-Aware Inference via Performance Forecasting in Decentralized Learning Networks', 'authors': 'Joel Pfeffer, J. M. Diederik Kruijssen, Clément Gossart, Mélanie Chevance, Diego Campo Millan, Florian Stecker, Steven N. Longmore', 'link': 'https://arxiv.org/abs/2510.06444', 'abstract': "In decentralized learning networks, predictions from many participants are combined to generate a network inference. While many studies have demonstrated performance benefits of combining multiple model predictions, existing strategies using linear pooling methods (ranging from simple averaging to dynamic weight updates) face a key limitation. Dynamic prediction combinations that rely on historical performance to update weights are necessarily reactive. Due to the need to average over a reasonable number of epochs (with moving averages or exponential weighting), they tend to be slow to adjust to changing circumstances (phase or regime changes). In this work, we develop a model that uses machine learning to forecast the performance of predictions by models at each epoch in a time series. This enables `context-awareness' by assigning higher weight to models that are likely to be more accurate at a given time. We show that adding a performance forecasting worker in a decentralized learning network, following a design similar to the Allora network, can improve the accuracy of network inferences. Specifically, we find forecasting models that predict regret (performance relative to the network inference) or regret z-score (performance relative to other workers) show greater improvement than models predicting losses, which often do not outperform the naive network inference (historically weighted average of all inferences). Through a series of optimization tests, we show that the performance of the forecasting model can be sensitive to choices in the feature set and number of training epochs. These properties may depend on the exact problem and should be tailored to each domain. Although initially designed for a decentralized learning network, using performance forecasting for prediction combination may be useful in any situation where predictive rather than reactive model weighting is needed.", 'abstract_zh': '在去中心化学习网络中，通过对众多参与者预测结果的整合生成网络推断。尽管许多研究已展示了结合多个模型预测结果的优势，现有的利用线性组合方法（包括简单平均和动态权重更新）的策略面临一个关键限制。依赖历史性能来更新权重的动态预测组合必须是反应性的。由于需要在合理数量的 epochs（使用移动平均或指数加权）中进行平均，它们往往难以迅速适应环境变化（相变或状态变化）。在本工作中，我们开发了一个模型，利用机器学习来预测时间序列中每个 epoch 模型预测结果的性能。这使我们可以根据预测准确性为模型分配更高的权重，实现情境感知能力。我们展示了在去中心化学习网络中增加一个性能预测工人（如Allora网络的设计类似），可以提高网络推断的准确性。具体而言，我们发现预测遗憾（相对于网络推断的性能）或遗憾 z 分数（相对于其他工人的性能）的预测模型优于预测损失的模型，后者通常无法超越简单的网络推断（历史加权平均所有推断）。通过一系列优化测试，我们证明了预测模型的表现对特征集选择和训练 epoch 数量等选择敏感。这些特性可能取决于具体问题，并且应针对不同领域进行调整。尽管最初设计用于去中心化学习网络，但使用性能预测进行预测组合在需要预测而非反应性模型加权的任何情况下都可能有益。', 'title_zh': '基于上下文感知的性能预测在去中心化学习网络中的推理'}
{'arxiv_id': 'arXiv:2510.06397', 'title': 'Geometry-Aware Backdoor Attacks: Leveraging Curvature in Hyperbolic Embeddings', 'authors': 'Ali Baheri', 'link': 'https://arxiv.org/abs/2510.06397', 'abstract': "Non-Euclidean foundation models increasingly place representations in curved spaces such as hyperbolic geometry. We show that this geometry creates a boundary-driven asymmetry that backdoor triggers can exploit. Near the boundary, small input changes appear subtle to standard input-space detectors but produce disproportionately large shifts in the model's representation space. Our analysis formalizes this effect and also reveals a limitation for defenses: methods that act by pulling points inward along the radius can suppress such triggers, but only by sacrificing useful model sensitivity in that same direction. Building on these insights, we propose a simple geometry-adaptive trigger and evaluate it across tasks and architectures. Empirically, attack success increases toward the boundary, whereas conventional detectors weaken, mirroring the theoretical trends. Together, these results surface a geometry-specific vulnerability in non-Euclidean models and offer analysis-backed guidance for designing and understanding the limits of defenses.", 'abstract_zh': '非欧clidean基础模型在双曲几何等弯曲空间中表示信息，这种几何结构导致边界驱动下的不对称性，攻击者可以利用这种不对称性。在边界附近，即使是细微的输入变化在标准输入空间检测器中显得不明显，但在模型的表示空间中却会产生显著差异。我们的分析正式化了这一效应，并且揭示了防御方法的一个局限性：通过向心方向拉近点的方法可以抑制此类触发器，但会牺牲该方向上的有用模型敏感性。基于这些见解，我们提出了一种简单的几何自适应触发器，并在不同任务和模型架构上进行了评估。实验证明，攻击成功率向边界靠近时增加，而传统的检测器效果减弱，这与理论趋势一致。这些结果揭示了非欧clidean模型的几何特定漏洞，并提供了基于分析的指导，以设计和理解防御方法的局限性。', 'title_zh': '几何感知后门攻击：利用双曲嵌入中的曲率'}
{'arxiv_id': 'arXiv:2510.06396', 'title': 'Adaptive Protein Design Protocols and Middleware', 'authors': 'Aymen Alsaadi, Jonathan Ash, Mikhail Titov, Matteo Turilli, Andre Merzky, Shantenu Jha, Sagar Khare', 'link': 'https://arxiv.org/abs/2510.06396', 'abstract': 'Computational protein design is experiencing a transformation driven by AI/ML. However, the range of potential protein sequences and structures is astronomically vast, even for moderately sized proteins. Hence, achieving convergence between generated and predicted structures demands substantial computational resources for sampling. The Integrated Machine-learning for Protein Structures at Scale (IMPRESS) offers methods and advanced computing systems for coupling AI to high-performance computing tasks, enabling the ability to evaluate the effectiveness of protein designs as they are developed, as well as the models and simulations used to generate data and train models. This paper introduces IMPRESS and demonstrates the development and implementation of an adaptive protein design protocol and its supporting computing infrastructure. This leads to increased consistency in the quality of protein design and enhanced throughput of protein design due to dynamic resource allocation and asynchronous workload execution.', 'abstract_zh': '基于AI/ML的计算蛋白质设计正在经历一场变革。然而，潜在的蛋白质序列和结构范围即使是对于中等大小的蛋白质来说也极其 vast，因此，实现生成结构与预测结构之间的收敛需要大量的计算资源进行采样。综合大规模蛋白质结构机器学习（IMPRESS）提供了将AI与高性能计算任务耦合的方法和先进的计算系统，使得在蛋白质设计的同时评估其效果，以及用于生成数据和训练模型的模型和模拟的有效性成为可能。本文介绍了IMPRESS，并展示了适应性蛋白质设计协议及其支持的计算基础设施的开发与实现。这导致蛋白质设计的质量一致性提高，并由于动态资源分配和异步工作负载执行而提高了蛋白质设计的吞吐量。', 'title_zh': '自适应蛋白质设计协议与中间件'}
{'arxiv_id': 'arXiv:2510.06391', 'title': 'Reward Model Perspectives: Whose Opinions Do Reward Models Reward?', 'authors': 'Elle', 'link': 'https://arxiv.org/abs/2510.06391', 'abstract': 'Reward models (RMs) are central to the alignment of language models (LMs). An RM often serves as a proxy for human preferences to guide downstream LM behavior. However, our understanding of RM behavior is limited. Our work (i) formalizes a framework for measuring the alignment of opinions captured by RMs, (ii) investigates the extent to which RMs demonstrate sociodemographic biases, and (iii) explores the effects of prompting to steer rewards towards the preferences of a target group. We study the subjective and diverse perspectives on controversial topics, which allows us to quantify RM perspectives in terms of their opinions, attitudes, and values. We show that RMs are poorly aligned with several demographic groups and can systematically reward harmful stereotypes, and steering alone is not enough to overcome these limitations. Our findings underscore the need for more careful consideration of RM behavior in model alignment during preference learning to prevent the propagation of unwanted social biases in the language technologies that we use.', 'abstract_zh': '奖励模型（RMs）是语言模型（LMs）对齐的核心。RMs通常作为人类偏好代理，引导下游LM的行为。然而，我们对RMs行为的理解有限。我们的工作（i）正式提出了一种衡量RMs捕捉意见对齐程度的框架，（ii）探究RMs表现社会人口偏见的程度，以及（iii）研究提示对引导奖励向目标群体偏好转变的影响。我们研究了争议性话题的主观和多样化观点，从而量化RMs观点在意见、态度和价值观方面的影响。我们发现，RMs与多个社会人口群体不契合，并且系统性地奖励有害刻板印象，单独调整不足以克服这些局限。我们的研究强调，在偏好学习过程中，对于RMs行为需要更加谨慎地考虑，以防止在语言技术中传播不希望的社会偏见。', 'title_zh': '奖励模型视角：奖励模型奖励的是哪方意见？'}
{'arxiv_id': 'arXiv:2510.06383', 'title': 'Protecting De-identified Documents from Search-based Linkage Attacks', 'authors': 'Pierre Lison, Mark Anderson', 'link': 'https://arxiv.org/abs/2510.06383', 'abstract': 'While de-identification models can help conceal the identity of the individual(s) mentioned in a document, they fail to address linkage risks, defined as the potential to map the de-identified text back to its source. One straightforward way to perform such linkages is to extract phrases from the de-identified document and then check their presence in the original dataset. This paper presents a method to counter search-based linkage attacks while preserving the semantic integrity of the text. The method proceeds in two steps. We first construct an inverted index of the N-grams occurring in the document collection, making it possible to efficiently determine which N-grams appear in less than $k$ documents (either alone or in combination with other N-grams). An LLM-based rewriter is then iteratively queried to reformulate those spans until linkage is no longer possible. Experimental results on a collection of court cases show that the method is able to effectively prevent search-based linkages while remaining faithful to the original content.', 'abstract_zh': '尽管去识别模型可以帮助隐藏文档中提及的个体身份，但它们未能解决链接风险，即可以将去识别的文本重新映射回其源头的风险。一种简单的方法是提取去识别文档中的短语，然后检查这些短语在原始数据集中的存在。本文提出了一个方法来抵御基于搜索的链接攻击同时保持文本的语义完整性。该方法分为两步。我们首先构建文档集合中出现的N-grams的倒排索引，使得能够高效地确定哪些N-grams出现在少于$k$个文档中（单独或与其他N-grams组合）。然后，基于LLM的重写器逐步查询以重新表述这些片段，直到无法进行链接。实验结果表明，该方法能够有效防止基于搜索的链接，并忠实地保留原始内容。', 'title_zh': '保护去标识化文档免受基于搜索的链接攻击'}
{'arxiv_id': 'arXiv:2510.06381', 'title': 'Monte Carlo Permutation Search', 'authors': 'Tristan Cazenave', 'link': 'https://arxiv.org/abs/2510.06381', 'abstract': 'We propose Monte Carlo Permutation Search (MCPS), a general-purpose Monte Carlo Tree Search (MCTS) algorithm that improves upon the GRAVE algorithm. MCPS is relevant when deep reinforcement learning is not an option, or when the computing power available before play is not substantial, such as in General Game Playing, for example. The principle of MCPS is to include in the exploration term of a node the statistics on all the playouts that contain all the moves on the path from the root to the node. We extensively test MCPS on a variety of games: board games, wargame, investment game, video game and multi-player games. MCPS has better results than GRAVE in all the two-player games. It has equivalent results for multi-player games because these games are inherently balanced even when players have different strengths. We also show that using abstract codes for moves instead of exact codes can be beneficial to both MCPS and GRAVE, as they improve the permutation statistics and the AMAF statistics. We also provide a mathematical derivation of the formulas used for weighting the three sources of statistics. These formulas are an improvement on the GRAVE formula since they no longer use the bias hyperparameter of GRAVE. Moreover, MCPS is not sensitive to the ref hyperparameter.', 'abstract_zh': '蒙特卡洛排列搜索（MCPS）：一种改进的蒙特卡洛树搜索算法及其应用', 'title_zh': '蒙特卡洛置换搜索'}
{'arxiv_id': 'arXiv:2510.06377', 'title': 'Relational Transformer: Toward Zero-Shot Foundation Models for Relational Data', 'authors': 'Rishabh Ranjan, Valter Hudovernik, Mark Znidar, Charilaos Kanatsoulis, Roshan Upendra, Mahmoud Mohammadi, Joe Meyer, Tom Palczewski, Carlos Guestrin, Jure Leskovec', 'link': 'https://arxiv.org/abs/2510.06377', 'abstract': "Pretrained transformers readily adapt to new sequence modeling tasks via zero-shot prompting, but relational domains still lack architectures that transfer across datasets and tasks. The core challenge is the diversity of relational data, with varying heterogeneous schemas, graph structures and functional dependencies. In this paper, we present the Relational Transformer (RT) architecture, which can be pretrained on diverse relational databases and directly applied to unseen datasets and tasks without task- or dataset-specific fine-tuning, or retrieval of in-context examples. RT (i) tokenizes cells with table/column metadata, (ii) is pretrained via masked token prediction, and (iii) utilizes a novel \\textit{Relational Attention} mechanism over columns, rows, and primary-foreign key links. Pretrained on RelBench datasets spanning tasks such as churn and sales forecasting, RT attains strong zero-shot performance, averaging 94% of fully supervised AUROC on binary classification tasks with a single forward pass of a 22M parameter model, as opposed to 84% for a 27B LLM. Fine-tuning yields state-of-the-art results with high sample efficiency. Our experiments show that RT's zero-shot transfer harnesses task-table context, relational attention patterns and schema semantics. Overall, RT provides a practical path toward foundation models for relational data.", 'abstract_zh': '预训练变换器通过零样本提示轻松适应新的序列建模任务，但关系领域仍然缺乏能够在不同数据集和任务间迁移的架构。核心挑战在于关系数据的多样性，包括变化的异构模式、图结构和函数依赖。本文提出了一种关系变换器（Relational Transformer，RT）架构，该架构可以在多元关系数据库上进行预训练，并可以直接应用于未见过的数据集和任务，无需针对特定任务或数据集进行微调，也无需检索上下文示例。RT 包括：(i) 使用表/列元数据对单元格进行分词，(ii) 通过掩码令牌预测进行预训练，(iii) 利用一种新颖的关系注意机制，该机制在列、行和主外键链接之间进行操作。RT 在跨越诸如客户流失和销售预测等任务的 RelBench 数据集上进行预训练，实现了强大的零样本性能，单次前向传递一个包含2200万参数的模型在二元分类任务上的平均AUROC达到94%，而270亿参数的语言模型为84%。通过微调，RT 达到了最先进的结果，具有高样本效率。我们的实验表明，RT 的零样本迁移利用了任务-表上下文、关系注意模式和模式语义。总体而言，RT 为关系数据提供了实用的基础模型路径。', 'title_zh': '关系变换器：面向关系数据的零样本基础模型'}
{'arxiv_id': 'arXiv:2510.06371', 'title': 'EverydayMMQA: A Multilingual and Multimodal Framework for Culturally Grounded Spoken Visual QA', 'authors': 'Firoj Alam, Ali Ezzat Shahroor, Md. Arid Hasan, Zien Sheikh Ali, Hunzalah Hassan Bhatti, Mohamed Bayan Kmainasi, Shammur Absar Chowdhury, Basel Mousi, Fahim Dalvi, Nadir Durrani, Natasa Milic-Frayling', 'link': 'https://arxiv.org/abs/2510.06371', 'abstract': 'Large-scale multimodal models achieve strong results on tasks like Visual Question Answering (VQA), but they often fail when queries require culturally grounded, everyday knowledge, particularly in low-resource and underrepresented languages. To bridge this gap, we introduce Everyday Multimodal and Multilingual QA (EverydayMMQA), a framework for creating large-scale, culturally-grounded datasets for spoken and visual question answering (SVQA). Using this framework, we developed OASIS, a multimodal dataset integrating speech, images, and text. With over ~0.92M images and 14.8M QA pairs, OASIS contains 3.7M spoken questions, enabling four unique input combinations: speech-only, text-only, speech+image, and text+image. Focused on English and Arabic varieties, 18 countries, the dataset content is curated to reflect diverse, real-world situations. OASIS tests models on tasks beyond object recognition that involve pragmatic, commonsense, and culturally aware reasoning. We benchmarked four closed-source models, three open-source models, and one fine-tuned model. EverydayMMQA and OASIS together provide a benchmark and training dataset for building multimodal LLMs for a comprehensive set of everyday tasks within cultural contexts. The framework and dataset will be made publicly available to the community.', 'abstract_zh': '大规模多模态模型在视觉问答（VQA）等任务上取得了出色的结果，但在要求文化背景下的日常生活知识时往往表现不佳，尤其是在低资源和少代表语言中。为弥合这一差距，我们引入了 Everyday Multimodal and Multilingual QA (EverydayMMQA) 框架，用于创建面向口语和视觉问答（SVQA）的大规模、文化背景扎根数据集。使用该框架，我们开发了 OASIS 多模态数据集，整合了语音、图像和文本。OASIS 包含超过 0.92 百万张图像和 1480 万 QA 对，其中包含 370 万条口语问题，支持四种独特的输入组合：语音仅、文本仅、语音+图像和文本+图像。该数据集专注于英语和阿拉伯语变体，包含来自 18 个国家的内容，内容策划以反映多元化的现实世界情境。OASIS 考察模型在涉及语用、常识和文化意识推理的任务上的表现，超越了对象识别。我们对四款封闭源代码模型、三款开源模型和一款微调模型进行了基准测试。EverydayMMQA 和 OASIS 一起提供了构建文化背景下涵盖广泛日常任务的多模态大语言模型的基准和训练数据集。框架和数据集将向社区公开。', 'title_zh': 'EverydayMMQA：一个基于文化的多语言多模态 spoken Visual QA 框架'}
{'arxiv_id': 'arXiv:2510.06357', 'title': 'Constrained Natural Language Action Planning for Resilient Embodied Systems', 'authors': 'Grayson Byrd, Corban Rivera, Bethany Kemp, Meghan Booker, Aurora Schmidt, Celso M de Melo, Lalithkumar Seenivasan, Mathias Unberath', 'link': 'https://arxiv.org/abs/2510.06357', 'abstract': 'Replicating human-level intelligence in the execution of embodied tasks remains challenging due to the unconstrained nature of real-world environments. Novel use of large language models (LLMs) for task planning seeks to address the previously intractable state/action space of complex planning tasks, but hallucinations limit their reliability, and thus, viability beyond a research context. Additionally, the prompt engineering required to achieve adequate system performance lacks transparency, and thus, repeatability. In contrast to LLM planning, symbolic planning methods offer strong reliability and repeatability guarantees, but struggle to scale to the complexity and ambiguity of real-world tasks. We introduce a new robotic planning method that augments LLM planners with symbolic planning oversight to improve reliability and repeatability, and provide a transparent approach to defining hard constraints with considerably stronger clarity than traditional prompt engineering. Importantly, these augmentations preserve the reasoning capabilities of LLMs and retain impressive generalization in open-world environments. We demonstrate our approach in simulated and real-world environments. On the ALFWorld planning benchmark, our approach outperforms current state-of-the-art methods, achieving a near-perfect 99% success rate. Deployment of our method to a real-world quadruped robot resulted in 100% task success compared to 50% and 30% for pure LLM and symbolic planners across embodied pick and place tasks. Our approach presents an effective strategy to enhance the reliability, repeatability and transparency of LLM-based robot planners while retaining their key strengths: flexibility and generalizability to complex real-world environments. We hope that this work will contribute to the broad goal of building resilient embodied intelligent systems.', 'abstract_zh': '在执行实体任务中复制人类级智能依然具有挑战性，因为现实世界环境具有未受约束的特性。将大型语言模型（LLMs）新颖地用于任务规划旨在解决复杂规划任务之前无法解决的状态/动作空间问题，但幻觉限制了其可靠性，从而使其在研究之外的有效性受到限制。此外，为了获得足够的系统性能所需的提示工程缺乏透明度，因此缺乏可重复性。与LLM规划不同，符号规划方法提供了强大的可靠性和可重复性保证，但难以应对真实世界任务的复杂性和模糊性。我们提出了一种新的机器人规划方法，通过将符号规划监督与LLM规划相结合来提高可靠性和可重复性，并提供了一种定义硬约束的透明方法，其清晰度远胜于传统提示工程。重要的是，这些增强保持了LLM的推理能力，并在开放世界环境中保留了出色的泛化能力。我们在模拟和真实世界环境中展示了我们的方法。在ALFWorld规划基准测试中，我们的方法超过了当前最先进的方法，实现了接近完美的99%成功率。将我们的方法部署到实际的四足机器人上，在抓取和放置任务中，其任务成功率达到了100%，而纯LLM和符号规划者分别为50%和30%。我们的方法提供了一种有效策略，以增强基于LLM的机器人规划者的可靠性和可重复性，同时保留其关键优势：灵活性和对复杂真实世界环境的泛化能力。我们希望这项工作能为构建更具韧性的体感智能系统做出贡献。', 'title_zh': '受约束的自然语言行动规划以实现稳健的体执行系统'}
{'arxiv_id': 'arXiv:2510.06353', 'title': 'TransFIRA: Transfer Learning for Face Image Recognizability Assessment', 'authors': 'Allen Tu, Kartik Narayan, Joshua Gleason, Jennifer Xu, Matthew Meyn, Tom Goldstein, Vishal M. Patel', 'link': 'https://arxiv.org/abs/2510.06353', 'abstract': "Face recognition in unconstrained environments such as surveillance, video, and web imagery must contend with extreme variation in pose, blur, illumination, and occlusion, where conventional visual quality metrics fail to predict whether inputs are truly recognizable to the deployed encoder. Existing FIQA methods typically rely on visual heuristics, curated annotations, or computationally intensive generative pipelines, leaving their predictions detached from the encoder's decision geometry. We introduce TransFIRA (Transfer Learning for Face Image Recognizability Assessment), a lightweight and annotation-free framework that grounds recognizability directly in embedding space. TransFIRA delivers three advances: (i) a definition of recognizability via class-center similarity (CCS) and class-center angular separation (CCAS), yielding the first natural, decision-boundary--aligned criterion for filtering and weighting; (ii) a recognizability-informed aggregation strategy that achieves state-of-the-art verification accuracy on BRIAR and IJB-C while nearly doubling correlation with true recognizability, all without external labels, heuristics, or backbone-specific training; and (iii) new extensions beyond faces, including encoder-grounded explainability that reveals how degradations and subject-specific factors affect recognizability, and the first recognizability-aware body recognition assessment. Experiments confirm state-of-the-art results on faces, strong performance on body recognition, and robustness under cross-dataset shifts. Together, these contributions establish TransFIRA as a unified, geometry-driven framework for recognizability assessment -- encoder-specific, accurate, interpretable, and extensible across modalities -- significantly advancing FIQA in accuracy, explainability, and scope.", 'abstract_zh': '基于传输学习的脸像可识别性评估', 'title_zh': 'TransFIRA: 转移学习在面部图像可识别性评估中的应用'}
{'arxiv_id': 'arXiv:2510.06350', 'title': 'Asking For It: Question-Answering for Predicting Rule Infractions in Online Content Moderation', 'authors': 'Mattia Samory, Diana Pamfile, Andrew To, Shruti Phadke', 'link': 'https://arxiv.org/abs/2510.06350', 'abstract': 'Online communities rely on a mix of platform policies and community-authored rules to define acceptable behavior and maintain order. However, these rules vary widely across communities, evolve over time, and are enforced inconsistently, posing challenges for transparency, governance, and automation. In this paper, we model the relationship between rules and their enforcement at scale, introducing ModQ, a novel question-answering framework for rule-sensitive content moderation. Unlike prior classification or generation-based approaches, ModQ conditions on the full set of community rules at inference time and identifies which rule best applies to a given comment. We implement two model variants - extractive and multiple-choice QA - and train them on large-scale datasets from Reddit and Lemmy, the latter of which we construct from publicly available moderation logs and rule descriptions. Both models outperform state-of-the-art baselines in identifying moderation-relevant rule violations, while remaining lightweight and interpretable. Notably, ModQ models generalize effectively to unseen communities and rules, supporting low-resource moderation settings and dynamic governance environments.', 'abstract_zh': '在线社区依赖于平台政策和社区制定的规则来定义 acceptable 行为并维持秩序。然而，这些规则在不同社区间差异很大，会随着时间演变，并且执行不一致，这为透明度、治理和自动化带来了挑战。本文构建了规则与执行之间关系的模型，引入了 ModQ，一种新的针对规则敏感内容管理的问答框架。与先前的分类或生成方法不同，ModQ 在推理时会依赖整个社区规则集，并确定哪条规则适用于给定评论。我们实现并训练了两种模型变体——提取式和多项选择问答，并使用来自 Reddit 和公开可用的莱姆睦社区管理日志和规则描述的大规模数据集对其进行训练。两种模型在识别管理相关规则违规方面均优于当前最佳基线，同时保持轻量级和可解释性。值得一提的是，ModQ 模型能够有效地泛化到未见过的社区和规则，支持低资源管理设置和动态治理环境。', 'title_zh': '索要答案：面向预测在线内容审核中规则违规的问答方法'}
{'arxiv_id': 'arXiv:2510.06349', 'title': 'Flexible Swarm Learning May Outpace Foundation Models in Essential Tasks', 'authors': 'Moein E. Samadi, Andreas Schuppert', 'link': 'https://arxiv.org/abs/2510.06349', 'abstract': 'Foundation models have rapidly advanced AI, raising the question of whether their decisions will ultimately surpass human strategies in real-world domains. The exponential, and possibly super-exponential, pace of AI development makes such analysis elusive. Nevertheless, many application areas that matter for daily life and society show only modest gains so far; a prominent case is diagnosing and treating dynamically evolving disease in intensive care.\nThe common challenge is adapting complex systems to dynamic environments. Effective strategies must optimize outcomes in systems composed of strongly interacting functions while avoiding shared side effects; this requires reliable, self-adaptive modeling. These tasks align with building digital twins of highly complex systems whose mechanisms are not fully or quantitatively understood. It is therefore essential to develop methods for self-adapting AI models with minimal data and limited mechanistic knowledge. As this challenge extends beyond medicine, AI should demonstrate clear superiority in these settings before assuming broader decision-making roles.\nWe identify the curse of dimensionality as a fundamental barrier to efficient self-adaptation and argue that monolithic foundation models face conceptual limits in overcoming it. As an alternative, we propose a decentralized architecture of interacting small agent networks (SANs). We focus on agents representing the specialized substructure of the system, where each agent covers only a subset of the full system functions. Drawing on mathematical results on the learning behavior of SANs and evidence from existing applications, we argue that swarm-learning in diverse swarms can enable self-adaptive SANs to deliver superior decision-making in dynamic environments compared with monolithic foundation models, though at the cost of reduced reproducibility in detail.', 'abstract_zh': '基础模型快速推进了人工智能的发展，引发了对其决策是否最终会在现实领域超越人类策略的质疑。人工智能发展的指数级，甚至有可能是超指数级的速度使得这种分析变得难以捉摸。尽管如此，对于日常生活和社会至关重要的许多应用领域目前仅显示出微小的进步；一个突出的例子是重症监护中对动态演变疾病的诊断和治疗。\n\n共同的挑战是将复杂系统适应动态环境。有效的策略必须在强交互的功能系统中优化结果，同时避免共享副作用；这需要可靠且自适应的建模。这些任务与构建机制尚不完全或无法定量理解的复杂系统的数字孪生相契合。因此，开发在有限数据和有限机制知识下自适应AI模型的方法至关重要。随着这一挑战超出医学领域，人工智能在这些情境中应表现出明显的优越性，才能承担更广泛的决策角色。\n\n我们识别维度灾作为高效自适应的根本障碍，并认为单一的基础模型面临概念上的局限性以克服它。作为替代方案，我们提出了一种交互式小型代理网络（SANs）的分散式架构。我们集中于代表系统专用子结构的代理，其中每个代理仅覆盖系统功能的子集。基于SANs学习行为的数学结果和现有应用的证据，我们论证了多样蜂群中的群学习可以使SANs在动态环境中提供优于单一基础模型的决策能力，尽管在细节上减少了再现性。', 'title_zh': '灵活的 Swarm 学习可能在关键任务上超越基础模型'}
{'arxiv_id': 'arXiv:2510.06343', 'title': 'Leveraging Large Language Models for Cybersecurity Risk Assessment -- A Case from Forestry Cyber-Physical Systems', 'authors': 'Fikret Mert Gültekin, Oscar Lilja, Ranim Khojah, Rebekka Wohlrab, Marvin Damschen, Mazen Mohamad', 'link': 'https://arxiv.org/abs/2510.06343', 'abstract': 'In safety-critical software systems, cybersecurity activities become essential, with risk assessment being one of the most critical. In many software teams, cybersecurity experts are either entirely absent or represented by only a small number of specialists. As a result, the workload for these experts becomes high, and software engineers would need to conduct cybersecurity activities themselves. This creates a need for a tool to support cybersecurity experts and engineers in evaluating vulnerabilities and threats during the risk assessment process. This paper explores the potential of leveraging locally hosted large language models (LLMs) with retrieval-augmented generation to support cybersecurity risk assessment in the forestry domain while complying with data protection and privacy requirements that limit external data sharing. We performed a design science study involving 12 experts in interviews, interactive sessions, and a survey within a large-scale project. The results demonstrate that LLMs can assist cybersecurity experts by generating initial risk assessments, identifying threats, and providing redundancy checks. The results also highlight the necessity for human oversight to ensure accuracy and compliance. Despite trust concerns, experts were willing to utilize LLMs in specific evaluation and assistance roles, rather than solely relying on their generative capabilities. This study provides insights that encourage the use of LLM-based agents to support the risk assessment process of cyber-physical systems in safety-critical domains.', 'abstract_zh': '在安全关键软件系统中，网络安全活动变得必不可少，风险评估是其中最关键的部分之一。在许多软件团队中，网络安全专家要么完全缺席，要么仅由少量专家代表。因此，这些专家的工作量增加，软件工程师需要自己进行网络安全活动。这产生了对工具的需求，以支持网络安全专家和工程师在风险评估过程中评估漏洞和威胁。本文探讨了利用本地托管的大语言模型（LLMs）及其检索增强生成技术，支持林业领域网络安全风险评估的可能性，同时遵守限制外部数据共享的数据保护和隐私要求。我们通过包含12位专家的访谈、互动会话和问卷调查进行了设计科学研究。研究结果表明，LLMs可以通过生成初始风险评估、识别威胁和提供冗余检查来协助网络安全专家。研究结果还强调了确保准确性和合规性的人工监督的必要性。尽管存在信任问题，专家们仍然愿意在特定评估和支持角色中使用LLMs，而不是完全依赖其生成能力。本文为利用LLM基础代理支持安全关键领域中的网络物理系统风险评估过程提供了见解。', 'title_zh': '利用大型语言模型进行网络安全风险评估——以林业 cyber-physical 系统为例'}
{'arxiv_id': 'arXiv:2510.06303', 'title': 'SDAR: A Synergistic Diffusion-AutoRegression Paradigm for Scalable Sequence Generation', 'authors': 'Shuang Cheng, Yihan Bian, Dawei Liu, Yuhua Jiang, Yihao Liu, Linfeng Zhang, Wenhai Wang, Qipeng Guo, Kai Chen, Biqing Qi, Bowen Zhou', 'link': 'https://arxiv.org/abs/2510.06303', 'abstract': 'We propose SDAR, a Synergistic Diffusion-Autoregression paradigm that unifies the training efficiency of autoregressive models with the parallel inference capability of diffusion. Instead of costly end-to-end diffusion training, SDAR performs a lightweight paradigm conversion that transforms a well-trained autoregressive (AR) model into a blockwise diffusion model through brief, data-efficient adaptation. During inference, SDAR generates sequences autoregressively across blocks for global coherence while decoding all tokens within each block in parallel via a discrete diffusion process. Extensive experiments show that AR models remain substantially more compute-efficient than masked diffusion models, providing a strong foundation for adaptation. Building on this insight, SDAR achieves efficient AR-to-diffusion conversion with minimal cost, preserving AR-level performance while enabling parallel generation. Scaling studies across dense and Mixture-of-Experts architectures confirm that SDAR scales without compromise: larger models exhibit stronger robustness to block size and decoding thresholds, yielding greater speedups without accuracy loss. Beyond efficiency, SDAR demonstrates enhanced reasoning and domain adaptability. Our 30B MoE model surpasses its AR counterpart on challenging scientific reasoning benchmarks such as GPQA and ChemBench, and gains further improvements under test-time scaling methods like majority voting and pass@k. Together, these results establish SDAR as a practical paradigm that combines the strengths of autoregression and diffusion for scalable, high-throughput reasoning.', 'abstract_zh': '我们提出SDAR（协同扩散自回归）范式，统一自回归模型的训练效率与扩散模型的并行推理能力。SDAR 不采用昂贵的端到端扩散训练，而是执行一种轻量级的范式转换，通过短暂的数据高效适应，将一个训练良好的自回归（AR）模型转换为块状扩散模型。在推理时，SDAR 通过离散扩散过程并行解码每个块内的所有令牌，同时自回归生成跨块的序列以保持全局一致性。大量实验表明，自回归模型在计算效率方面仍然显著优于掩膜扩散模型，为适应性提供了坚实的基石。基于这一洞察，SDAR 以极低的成本实现了高效的AR到扩散的转换，保持自回归级别的性能同时实现并行生成。对密集和混合专家架构的扩展研究表明，SDAR 在不失效的情况下扩展：更大的模型表现出更强的块大小和解码阈值鲁棒性，从而在不损失准确性的前提下获得更大的加速。除了效率，SDAR 还展示了增强的推理能力和领域适应性。我们的30B混合专家模型在GPQA和ChemBench等具有挑战性的科学推理基准测试中超过其自回归对应模型，并且在测试时使用多数投票和pass@k等扩展方法进一步改进。这些结果共同确立了SDAR 作为结合自回归和扩散优势的实用范式，适用于可扩展、高吞吐量推理。', 'title_zh': 'SDAR：一种协同扩散-自回归范式以实现可扩展的序列生成'}
{'arxiv_id': 'arXiv:2510.06298', 'title': 'RGBD Gaze Tracking Using Transformer for Feature Fusion', 'authors': 'Tobias J. Bauer', 'link': 'https://arxiv.org/abs/2510.06298', 'abstract': 'Subject of this thesis is the implementation of an AI-based Gaze Tracking system using RGBD images that contain both color (RGB) and depth (D) information. To fuse the features extracted from the images, a module based on the Transformer architecture is used. The combination of RGBD input images and Transformers was chosen because it has not yet been investigated. Furthermore, a new dataset is created for training the AI models as existing datasets either do not contain depth information or only contain labels for Gaze Point Estimation that are not suitable for the task of Gaze Angle Estimation. Various model configurations are trained, validated and evaluated on a total of three different datasets. The trained models are then to be used in a real-time pipeline to estimate the gaze direction and thus the gaze point of a person in front of a computer screen. The AI model architecture used in this thesis is based on an earlier work by Lian et al. It uses a Generative Adversarial Network (GAN) to simultaneously remove depth map artifacts and extract head pose features. Lian et al. achieve a mean Euclidean error of 38.7mm on their own dataset ShanghaiTechGaze+. In this thesis, a model architecture with a Transformer module for feature fusion achieves a mean Euclidean error of 55.3mm on the same dataset, but we show that using no pre-trained GAN module leads to a mean Euclidean error of 30.1mm. Replacing the Transformer module with a Multilayer Perceptron (MLP) improves the error to 26.9mm. These results are coherent with the ones on the other two datasets. On the ETH-XGaze dataset, the model with Transformer module achieves a mean angular error of 3.59° and without Transformer module 3.26°, whereas the fundamentally different model architecture used by the dataset authors Zhang et al. achieves a mean angular error of 2.04°. On the OTH-Gaze-Estimation dataset created for...', 'abstract_zh': '基于RGBD图像的人工智能眼动追踪系统实现：transformer架构在深度与颜色信息融合中的应用及新型数据集创建研究', 'title_zh': '使用变换器进行特征融合的RGBD凝视跟踪'}
{'arxiv_id': 'arXiv:2510.06296', 'title': 'VeriEquivBench: An Equivalence Score for Ground-Truth-Free Evaluation of Formally Verifiable Code', 'authors': 'Lingfei Zeng, Fengdi Che, Xuhan Huang, Fei Ye, Xu Xu, Binhang Yuan, Jie Fu', 'link': 'https://arxiv.org/abs/2510.06296', 'abstract': 'Formal verification is the next frontier for ensuring the correctness of code generated by Large Language Models (LLMs). While methods that co-generate code and formal specifications in formal languages, like Dafny, can, in principle, prove alignment with user intent, progress is bottlenecked by specification quality evaluation. Current benchmarks rely on matching against ground-truth specifications, a manual and expertise-intensive process that has limited existing datasets to a few hundred simple problems and also suffers from a reliability issue. To address this, we introduce VeriEquivBench, a new benchmark with $2,389$ complex algorithmic problems that probe the limitations of current models in both code generation and formal reasoning. Our evaluation framework replaces ground-truth matching with a formally grounded metric, the equivalence score, and rigorously verifies the quality of generated specifications and code. Our results show that generating formally verifiable code remains a profound challenge for state-of-the-art LLMs. This underscores both the difficulty of the task and the need for benchmarks like VeriEquivBench to drive progress toward scalable and reliable coding agents.', 'abstract_zh': '正式验证是确保由大规模语言模型（LLMs）生成的代码正确性的下一个前沿领域。为了克服现有基准因依赖于匹配真实规格而产生的手动且耗费专业技能的过程限制，我们引入了VeriEquivBench这一新的基准，其中包括2,389个复杂算法问题，旨在测试当前模型在代码生成和形式推理方面的局限性。我们的评估框架使用了一个形式化的指标，等价分数，来验证生成的规格和代码的质量。结果表明，生成可形式验证的代码依然是当今最先进的LLMs面临的重大挑战。这不仅揭示了任务的复杂性，还强调了需要如VeriEquivBench这样的基准来推动可扩展和可靠编程代理的研究进展。', 'title_zh': 'VeriEquivBench：一种无需ground-truth的正式可验证代码等价性评分方法'}
{'arxiv_id': 'arXiv:2510.06295', 'title': 'Efficient High-Resolution Image Editing with Hallucination-Aware Loss and Adaptive Tiling', 'authors': 'Young D. Kwon, Abhinav Mehrotra, Malcolm Chadwick, Alberto Gil Ramos, Sourav Bhattacharya', 'link': 'https://arxiv.org/abs/2510.06295', 'abstract': 'High-resolution (4K) image-to-image synthesis has become increasingly important for mobile applications. Existing diffusion models for image editing face significant challenges, in terms of memory and image quality, when deployed on resource-constrained devices. In this paper, we present MobilePicasso, a novel system that enables efficient image editing at high resolutions, while minimising computational cost and memory usage. MobilePicasso comprises three stages: (i) performing image editing at a standard resolution with hallucination-aware loss, (ii) applying latent projection to overcome going to the pixel space, and (iii) upscaling the edited image latent to a higher resolution with adaptive context-preserving tiling. Our user study with 46 participants reveals that MobilePicasso not only improves image quality by 18-48% but reduces hallucinations by 14-51% over existing methods. MobilePicasso demonstrates significantly lower latency, e.g., up to 55.8$\\times$ speed-up, yet with a small increase in runtime memory, e.g., a mere 9% increase over prior work. Surprisingly, the on-device runtime of MobilePicasso is observed to be faster than a server-based high-resolution image editing model running on an A100 GPU.', 'abstract_zh': '高分辨率（4K）图像到图像合成在移动应用中变得越来越重要。现有的基于扩散模型的图像编辑方法在资源受限设备上部署时，在内存和图像质量方面面临重大挑战。本文提出了一种名为MobilePicasso的新型系统，能够在保持高效图像编辑的同时，最大限度地降低计算成本和内存使用。MobilePicasso包括三个阶段：（i）在标准分辨率下进行带有幻觉意识损失的图像编辑；（ii）应用潜在投影以克服像素空间转换；（iii）使用自适应上下文保留切片方法将编辑后的图像潜在特征放大到更高分辨率。我们的用户研究结果表明，MobilePicasso不仅将图像质量提高了18-48%，而且将幻觉减少了14-51%，优于现有方法。MobilePicasso表现出显著更低的延迟，例如最高55.8倍的速度提升，同时运行时内存仅增加了9%，相较于以往工作。令人惊讶的是，MobilePicasso的设备运行时间比在A100 GPU上运行的服务器端高分辨率图像编辑模型还要快。', 'title_zh': '带有幻觉意识损失和自适应切分的高效高分辨率图像编辑'}
{'arxiv_id': 'arXiv:2510.06293', 'title': 'BlockGPT: Spatio-Temporal Modelling of Rainfall via Frame-Level Autoregression', 'authors': 'Cristian Meo, Varun Sarathchandran, Avijit Majhi, Shao Hung, Carlo Saccardi, Ruben Imhoff, Roberto Deidda, Remko Uijlenhoet, Justin Dauwels', 'link': 'https://arxiv.org/abs/2510.06293', 'abstract': 'Predicting precipitation maps is a highly complex spatiotemporal modeling task, critical for mitigating the impacts of extreme weather events. Short-term precipitation forecasting, or nowcasting, requires models that are not only accurate but also computationally efficient for real-time applications. Current methods, such as token-based autoregressive models, often suffer from flawed inductive biases and slow inference, while diffusion models can be computationally intensive. To address these limitations, we introduce BlockGPT, a generative autoregressive transformer using batched tokenization (Block) method that predicts full two-dimensional fields (frames) at each time step. Conceived as a model-agnostic paradigm for video prediction, BlockGPT factorizes space-time by using self-attention within each frame and causal attention across frames; in this work, we instantiate it for precipitation nowcasting. We evaluate BlockGPT on two precipitation datasets, viz. KNMI (Netherlands) and SEVIR (U.S.), comparing it to state-of-the-art baselines including token-based (NowcastingGPT) and diffusion-based (DiffCast+Phydnet) models. The results show that BlockGPT achieves superior accuracy, event localization as measured by categorical metrics, and inference speeds up to 31x faster than comparable baselines.', 'abstract_zh': '生成式自回归transformer在批量化标记方法下的短时降水nowcasting及其应用：BlockGPT方法的研究', 'title_zh': 'BlockGPT：基于帧级自回归的时空降雨 modeling'}
{'arxiv_id': 'arXiv:2510.06292', 'title': 'ChainMPQ: Interleaved Text-Image Reasoning Chains for Mitigating Relation Hallucinations', 'authors': 'Yike Wu, Yiwei Wang, Yujun Cai', 'link': 'https://arxiv.org/abs/2510.06292', 'abstract': 'While Large Vision-Language Models (LVLMs) achieve strong performance in multimodal tasks, hallucinations continue to hinder their reliability. Among the three categories of hallucinations, which include object, attribute, and relation, relation hallucinations account for the largest proportion but have received the least attention. To address this issue, we propose ChainMPQ (Multi-Perspective Questions guided Interleaved Chain of Image and Text), a training-free method that improves relational inference in LVLMs by utilizing accumulated textual and visual memories. ChainMPQ first extracts subject and object keywords from the question to enhance the corresponding image regions. It then constructs multi-perspective questions that focus on the three core components of a relationship: the subject, the object, and the relation that links them. These questions are sequentially input to the model, with textual and visual memories from earlier steps providing supporting context for subsequent ones, thereby forming an interleaved chain of images and text that guides progressive relational reasoning. Experiments on multiple LVLMs and benchmarks show that ChainMPQ substantially reduces relation hallucinations, while ablation studies further validate the effectiveness of its three core modules.', 'abstract_zh': '大型多模态模型中的关系幻觉持续影响其可靠性，尽管大型视觉-语言模型在多模态任务中表现出色。在对象、属性和关系三种幻觉类别中，关系幻觉占比最大但受到的关注最少。为解决这一问题，我们提出ChainMPQ（多视角问题引导的图像和文本交错链），这是一种无需训练的方法，通过利用积累的文字和视觉记忆来改善大型视觉-语言模型的关系推理。ChainMPQ 首先从问题中提取主词和宾词关键词，以增强相应的图像区域。接着构建专注于关系三个核心组成部分（主词、宾词和连接它们的关系）的多视角问题。这些问题按顺序输入模型，早期步骤中的文字和视觉记忆为后续步骤提供支持性背景，从而形成图像和文本交织链，引导渐进式关系推理。在多个大型多模态模型和基准上的实验表明，ChainMPQ 显著减少了关系幻觉，而消融研究进一步验证了其三个核心模块的有效性。', 'title_zh': 'ChainMPQ: 交错的文本-图像推理链以减轻关系幻觉问题'}
{'arxiv_id': 'arXiv:2510.06291', 'title': 'Traj-Transformer: Diffusion Models with Transformer for GPS Trajectory Generation', 'authors': 'Zhiyang Zhang, Ningcong Chen, Xin Zhang, Yanhua Li, Shen Su, Hui Lu, Jun Luo', 'link': 'https://arxiv.org/abs/2510.06291', 'abstract': 'The widespread use of GPS devices has driven advances in spatiotemporal data mining, enabling machine learning models to simulate human decision making and generate realistic trajectories, addressing both data collection costs and privacy concerns. Recent studies have shown the promise of diffusion models for high-quality trajectory generation. However, most existing methods rely on convolution based architectures (e.g. UNet) to predict noise during the diffusion process, which often results in notable deviations and the loss of fine-grained street-level details due to limited model capacity. In this paper, we propose Trajectory Transformer, a novel model that employs a transformer backbone for both conditional information embedding and noise prediction. We explore two GPS coordinate embedding strategies, location embedding and longitude-latitude embedding, and analyze model performance at different scales. Experiments on two real-world datasets demonstrate that Trajectory Transformer significantly enhances generation quality and effectively alleviates the deviation issues observed in prior approaches.', 'abstract_zh': '基于GPS设备的广泛应用推动了时空数据挖掘的进步，使得机器学习模型能够模拟人类决策并生成真实轨迹，解决数据采集成本和隐私问题。近期研究表明，扩散模型在高质量轨迹生成方面展现出潜力。然而，大多数现有方法依赖于基于卷积的架构（如UNet）来预测扩散过程中噪声，这通常会导致显著偏离和细粒度街道级细节的损失，由于模型容量有限。在本文中，我们提出了一种名为Trajectory Transformer的新型模型，该模型采用变换器骨干网络进行条件信息嵌入和噪声预测。我们探讨了两种GPS坐标嵌入策略，位置嵌入和经度-纬度嵌入，并在不同规模下分析了模型性能。在两个真实世界数据集上的实验表明，Trajectory Transformer显著提高了生成质量，并有效缓解了先前方法中观察到的偏差问题。', 'title_zh': 'GPS轨迹生成中的Traj-Transformer：基于Transformer的扩散模型'}
{'arxiv_id': 'arXiv:2510.06290', 'title': 'Soft-Evidence Fused Graph Neural Network for Cancer Driver Gene Identification across Multi-View Biological Graphs', 'authors': 'Bang Chen, Lijun Guo, Houli Fan, Wentao He, Rong Zhang', 'link': 'https://arxiv.org/abs/2510.06290', 'abstract': 'Identifying cancer driver genes (CDGs) is essential for understanding cancer mechanisms and developing targeted therapies. Graph neural networks (GNNs) have recently been employed to identify CDGs by capturing patterns in biological interaction networks. However, most GNN-based approaches rely on a single protein-protein interaction (PPI) network, ignoring complementary information from other biological networks. Some studies integrate multiple networks by aligning features with consistency constraints to learn unified gene representations for CDG identification. However, such representation-level fusion often assumes congruent gene relationships across networks, which may overlook network heterogeneity and introduce conflicting information. To address this, we propose Soft-Evidence Fusion Graph Neural Network (SEFGNN), a novel framework for CDG identification across multiple networks at the decision level. Instead of enforcing feature-level consistency, SEFGNN treats each biological network as an independent evidence source and performs uncertainty-aware fusion at the decision level using Dempster-Shafer Theory (DST). To alleviate the risk of overconfidence from DST, we further introduce a Soft Evidence Smoothing (SES) module that improves ranking stability while preserving discriminative performance. Experiments on three cancer datasets show that SEFGNN consistently outperforms state-of-the-art baselines and exhibits strong potential in discovering novel CDGs.', 'abstract_zh': '基于决策级软证据融合图神经网络的癌症驱动基因识别', 'title_zh': '跨多视图生物图谱的软证据融合图神经网络用于癌症驱动基因识别'}
{'arxiv_id': 'arXiv:2510.06283', 'title': 'SER-Diff: Synthetic Error Replay Diffusion for Incremental Brain Tumor Segmentation', 'authors': 'Sashank Makanaboyina', 'link': 'https://arxiv.org/abs/2510.06283', 'abstract': 'Incremental brain tumor segmentation is critical for models that must adapt to evolving clinical datasets without retraining on all prior data. However, catastrophic forgetting, where models lose previously acquired knowledge, remains a major obstacle. Recent incremental learning frameworks with knowledge distillation partially mitigate forgetting but rely heavily on generative replay or auxiliary storage. Meanwhile, diffusion models have proven effective for refining tumor segmentations, but have not been explored in incremental learning contexts. We propose Synthetic Error Replay Diffusion (SER-Diff), the first framework that unifies diffusion-based refinement with incremental learning. SER-Diff leverages a frozen teacher diffusion model to generate synthetic error maps from past tasks, which are replayed during training on new tasks. A dual-loss formulation combining Dice loss for new data and knowledge distillation loss for replayed errors ensures both adaptability and retention. Experiments on BraTS2020, BraTS2021, and BraTS2023 demonstrate that SER-Diff consistently outperforms prior methods. It achieves the highest Dice scores of 95.8\\%, 94.9\\%, and 94.6\\%, along with the lowest HD95 values of 4.4 mm, 4.7 mm, and 4.9 mm, respectively. These results indicate that SER-Diff not only mitigates catastrophic forgetting but also delivers more accurate and anatomically coherent segmentations across evolving datasets.', 'abstract_zh': '基于合成错误回放扩散的增量脑肿瘤分割', 'title_zh': 'SER-Diff: 合成错误重播扩散在增量脑肿瘤分割中的应用'}
{'arxiv_id': 'arXiv:2510.06281', 'title': 'Improving the Spatial Resolution of GONG Solar Images to GST Quality Using Deep Learning', 'authors': 'Chenyang Li, Qin Li, Haimin Wang, Bo Shen', 'link': 'https://arxiv.org/abs/2510.06281', 'abstract': 'High-resolution (HR) solar imaging is crucial for capturing fine-scale dynamic features such as filaments and fibrils. However, the spatial resolution of the full-disk H$\\alpha$ images is limited and insufficient to resolve these small-scale structures. To address this, we propose a GAN-based superresolution approach to enhance low-resolution (LR) full-disk H$\\alpha$ images from the Global Oscillation Network Group (GONG) to a quality comparable with HR observations from the Big Bear Solar Observatory/Goode Solar Telescope (BBSO/GST). We employ Real-ESRGAN with Residual-in-Residual Dense Blocks and a relativistic discriminator. We carefully aligned GONG-GST pairs. The model effectively recovers fine details within sunspot penumbrae and resolves fine details in filaments and fibrils, achieving an average mean squared error (MSE) of 467.15, root mean squared error (RMSE) of 21.59, and cross-correlation (CC) of 0.7794. Slight misalignments between image pairs limit quantitative performance, which we plan to address in future work alongside dataset expansion to further improve reconstruction quality.', 'abstract_zh': '基于GAN的高分辨率太阳高分辨率成像：将全球振荡网络群（GONG）低分辨率全盘H$\\alpha$图像增强至比格熊太阳 observatory/古多太阳望远镜（BBSO/GST）高分辨率观测更好的质量', 'title_zh': '使用深度学习提高GONG太阳图像的空间分辨率至GST质量'}
{'arxiv_id': 'arXiv:2510.06280', 'title': 'Surgeons Are Indian Males and Speech Therapists Are White Females: Auditing Biases in Vision-Language Models for Healthcare Professionals', 'authors': 'Zohaib Hasan Siddiqui, Dayam Nadeem, Mohammad Masudur Rahman, Mohammad Nadeem, Shahab Saquib Sohail, Beenish Moalla Chaudhry', 'link': 'https://arxiv.org/abs/2510.06280', 'abstract': 'Vision language models (VLMs), such as CLIP and OpenCLIP, can encode and reflect stereotypical associations between medical professions and demographic attributes learned from web-scale data. We present an evaluation protocol for healthcare settings that quantifies associated biases and assesses their operational risk. Our methodology (i) defines a taxonomy spanning clinicians and allied healthcare roles (e.g., surgeon, cardiologist, dentist, nurse, pharmacist, technician), (ii) curates a profession-aware prompt suite to probe model behavior, and (iii) benchmarks demographic skew against a balanced face corpus. Empirically, we observe consistent demographic biases across multiple roles and vision models. Our work highlights the importance of bias identification in critical domains such as healthcare as AI-enabled hiring and workforce analytics can have downstream implications for equity, compliance, and patient trust.', 'abstract_zh': 'Vision语言模型（VLMs）如CLIP和OpenCLIP可以编码并在大型网络数据中学习到医疗职业与人口统计属性之间的刻板关联。我们提出了一种评估协议，量化这些关联偏见并评估其操作风险。我们的方法包括：(i) 定义涵盖临床医生和辅助医疗角色的分类体系（例如，外科医生、心脏病专家、牙医、护士、药剂师、技术人员），(ii) 编制一套职业意识提示以探查模型行为，(iii) 将人口统计偏斜与平衡人脸数据集进行基准测试。实证研究表明，多种角色和视觉模型中存在一致性的人口统计偏见。我们的工作强调了在诸如医疗保健这样关键领域识别偏见的重要性，因为基于AI的招聘和劳动力分析可以对公平性、合规性和患者信任产生下游影响。', 'title_zh': '外科医生是印度男性，言语治疗师是白人女性：审计医疗保健专业人员中视觉-语言模型的偏差'}
{'arxiv_id': 'arXiv:2510.06278', 'title': 'RVFL-X: A Novel Randomized Network Based on Complex Transformed Real-Valued Tabular Datasets', 'authors': 'M. Sajid, Mushir Akhtar, A. Quadir, M. Tanveer', 'link': 'https://arxiv.org/abs/2510.06278', 'abstract': 'Recent advancements in neural networks, supported by foundational theoretical insights, emphasize the superior representational power of complex numbers. However, their adoption in randomized neural networks (RNNs) has been limited due to the lack of effective methods for transforming real-valued tabular datasets into complex-valued representations. To address this limitation, we propose two methods for generating complex-valued representations from real-valued datasets: a natural transformation and an autoencoder-driven method. Building on these mechanisms, we propose RVFL-X, a complex-valued extension of the random vector functional link (RVFL) network. RVFL-X integrates complex transformations into real-valued datasets while maintaining the simplicity and efficiency of the original RVFL architecture. By leveraging complex components such as input, weights, and activation functions, RVFL-X processes complex representations and produces real-valued outputs. Comprehensive evaluations on 80 real-valued UCI datasets demonstrate that RVFL-X consistently outperforms both the original RVFL and state-of-the-art (SOTA) RNN variants, showcasing its robustness and effectiveness across diverse application domains.', 'abstract_zh': 'Recent advancements in神经网络，得益于基础理论洞见的支撑，强调了复数的优越表征能力。然而，它们在随机神经网络（RNNs）中的应用受限于将实值表格数据转换为复值表示的有效方法的缺乏。为了解决这一限制，我们提出了两种从实值数据生成复值表示的方法：自然转换和基于自编码器的方法。在此基础上，我们提出了RVFL-X，这是一种随机向量功能链接（RVFL）网络的复值扩展。RVFL-X将复数值转换融入实值数据集，同时保持原始RVFL架构的简洁性和高效性。通过利用输入、权重和激活函数等复数组成部分，RVFL-X处理复值表示并生成实值输出。在80个实值UCI数据集上的全面评估表明，RVFL-X始终优于原始RVFL和最先进的（SOTA）RNN变体，在多个应用领域展示了其稳健性和有效性。', 'title_zh': 'RVFL-X：一种基于复杂变换实值表格数据的新型随机网络'}
{'arxiv_id': 'arXiv:2510.06276', 'title': 'A Total Variation Regularized Framework for Epilepsy-Related MRI Image Segmentation', 'authors': 'Mehdi Rabiee, Sergio Greco, Reza Shahbazian, Irina Trubitsyna', 'link': 'https://arxiv.org/abs/2510.06276', 'abstract': 'Focal Cortical Dysplasia (FCD) is a primary cause of drug-resistant epilepsy and is difficult to detect in brain {magnetic resonance imaging} (MRI) due to the subtle and small-scale nature of its lesions. Accurate segmentation of FCD regions in 3D multimodal brain MRI images is essential for effective surgical planning and treatment. However, this task remains highly challenging due to the limited availability of annotated FCD datasets, the extremely small size and weak contrast of FCD lesions, the complexity of handling 3D multimodal inputs, and the need for output smoothness and anatomical consistency, which is often not addressed by standard voxel-wise loss functions. This paper presents a new framework for segmenting FCD regions in 3D brain MRI images. We adopt state-of-the-art transformer-enhanced encoder-decoder architecture and introduce a novel loss function combining Dice loss with an anisotropic {Total Variation} (TV) term. This integration encourages spatial smoothness and reduces false positive clusters without relying on post-processing. The framework is evaluated on a public FCD dataset with 85 epilepsy patients and demonstrates superior segmentation accuracy and consistency compared to standard loss formulations. The model with the proposed TV loss shows an 11.9\\% improvement on the Dice coefficient and 13.3\\% higher precision over the baseline model. Moreover, the number of false positive clusters is reduced by 61.6%', 'abstract_zh': 'FCD在3D多模态脑MRI图像中区域分割的新框架：结合Dice损失和各向异性Total Variation术语', 'title_zh': '基于总量变正则化的与癫痫相关的MRI图像分割框架'}
{'arxiv_id': 'arXiv:2510.06275', 'title': 'Reproducibility Study of "XRec: Large Language Models for Explainable Recommendation"', 'authors': 'Ranjan Mishra, Julian I. Bibo, Quinten van Engelen, Henk Schaapman', 'link': 'https://arxiv.org/abs/2510.06275', 'abstract': 'In this study, we reproduced the work done in the paper "XRec: Large Language Models for Explainable Recommendation" by Ma et al. (2024). The original authors introduced XRec, a model-agnostic collaborative instruction-tuning framework that enables large language models (LLMs) to provide users with comprehensive explanations of generated recommendations. Our objective was to replicate the results of the original paper, albeit using Llama 3 as the LLM for evaluation instead of GPT-3.5-turbo. We built on the source code provided by Ma et al. (2024) to achieve our goal. Our work extends the original paper by modifying the input embeddings or deleting the output embeddings of XRec\'s Mixture of Experts module. Based on our results, XRec effectively generates personalized explanations and its stability is improved by incorporating collaborative information. However, XRec did not consistently outperform all baseline models in every metric. Our extended analysis further highlights the importance of the Mixture of Experts embeddings in shaping the explanation structures, showcasing how collaborative signals interact with language modeling. Through our work, we provide an open-source evaluation implementation that enhances accessibility for researchers and practitioners alike. Our complete code repository can be found at this https URL.', 'abstract_zh': '本研究重现了Ma等（2024）在论文“XRec：可解释推荐的大语言模型”中的工作。原始作者引入了XRec模型，这是一种模型无关的合作指令调校框架，使大语言模型能够为用户提供生成推荐的全面解释。我们的目标是使用Llama 3替代GPT-3.5-turbo进行评估，重现原论文的结果。我们基于Ma等（2024）提供的源代码实现了这一目标。我们的工作通过修改XRec的专家混合模块的输入嵌入或删除输出嵌入，扩展了原论文。根据我们的结果，XRec能够有效生成个性化解释，并且通过集成合作信息提高了稳定性。然而，XRec在所有指标上并未始终优于基准模型。我们的扩展分析进一步突出了专家混合嵌入在塑造解释结构中的重要性，展示了协作信号与语言建模的交互。通过我们的工作，我们提供了一个开源评估实现，以提高研究人员和实践者的可访问性。我们的完整代码库可以在以下网址找到：this https URL。', 'title_zh': 'XRec：可解释推荐的大语言模型再现性研究'}
{'arxiv_id': 'arXiv:2510.06270', 'title': 'MCCE: A Framework for Multi-LLM Collaborative Co-Evolution', 'authors': 'Nian Ran, Zhongzheng Li, Yue Wang, Qingsong Ran, Xiaoyuan Zhang, Shikun Feng, Richard Allmendinger, Xiaoguang Zhao', 'link': 'https://arxiv.org/abs/2510.06270', 'abstract': 'Multi-objective discrete optimization problems, such as molecular design, pose significant challenges due to their vast and unstructured combinatorial spaces. Traditional evolutionary algorithms often get trapped in local optima, while expert knowledge can provide crucial guidance for accelerating convergence. Large language models (LLMs) offer powerful priors and reasoning ability, making them natural optimizers when expert knowledge matters. However, closed-source LLMs, though strong in exploration, cannot update their parameters and thus cannot internalize experience. Conversely, smaller open models can be continually fine-tuned but lack broad knowledge and reasoning strength. We introduce Multi-LLM Collaborative Co-evolution (MCCE), a hybrid framework that unites a frozen closed-source LLM with a lightweight trainable model. The system maintains a trajectory memory of past search processes; the small model is progressively refined via reinforcement learning, with the two models jointly supporting and complementing each other in global exploration. Unlike model distillation, this process enhances the capabilities of both models through mutual inspiration. Experiments on multi-objective drug design benchmarks show that MCCE achieves state-of-the-art Pareto front quality and consistently outperforms baselines. These results highlight a new paradigm for enabling continual evolution in hybrid LLM systems, combining knowledge-driven exploration with experience-driven learning.', 'abstract_zh': '多目标离散优化问题，如分子设计，由于其庞大的无结构组合空间而面临重大挑战。传统进化算法往往陷入局部最优，而专家知识可以提供加速收敛的关键指导。大型语言模型（LLMs）具备强大的先验知识和推理能力，当专家知识至关重要时，它们是天然的优化器。然而，闭源的LLMs虽然在探索方面很强，但无法更新其参数，因此无法内化经验。相反，较小的开源模型可以持续微调，但缺乏广泛的知识和推理能力。我们介绍了多LLM协作共进化（MCCE）混合框架，该框架结合了一个冻结的闭源LLM和一个轻量级可训练模型。该系统维护了过去搜索过程的轨迹记忆；小型模型通过强化学习逐步优化，两种模型共同支持和补充彼此完成全局探索。与模型蒸馏不同，这一过程通过相互启发来增强两种模型的能力。在多目标药物设计基准测试上的实验表明，MCCE实现了最先进的帕累托前沿质量，并且一致地优于基线。这些结果突显了在一个结合了知识驱动探索和经验驱动学习的混合LLM系统中实现持续进化的新范式。', 'title_zh': 'MCCE：多大型语言模型协同协进化框架'}
{'arxiv_id': 'arXiv:2510.06267', 'title': 'RareGraph-Synth: Knowledge-Guided Diffusion Models for Generating Privacy-Preserving Synthetic Patient Trajectories in Ultra-Rare Diseases', 'authors': 'Khartik Uppalapati, Shakeel Abdulkareem, Bora Yimenicioglu', 'link': 'https://arxiv.org/abs/2510.06267', 'abstract': 'We propose RareGraph-Synth, a knowledge-guided, continuous-time diffusion framework that generates realistic yet privacy-preserving synthetic electronic-health-record (EHR) trajectories for ultra-rare diseases. RareGraph-Synth unifies five public resources: Orphanet/Orphadata, the Human Phenotype Ontology (HPO), the GARD rare-disease KG, PrimeKG, and the FDA Adverse Event Reporting System (FAERS) into a heterogeneous knowledge graph comprising approximately 8 M typed edges. Meta-path scores extracted from this 8-million-edge KG modulate the per-token noise schedule in the forward stochastic differential equation, steering generation toward biologically plausible lab-medication-adverse-event co-occurrences while retaining score-based diffusion model stability. The reverse denoiser then produces timestamped sequences of lab-code, medication-code, and adverse-event-flag triples that contain no protected health information. On simulated ultra-rare-disease cohorts, RareGraph-Synth lowers categorical Maximum Mean Discrepancy by 40 percent relative to an unguided diffusion baseline and by greater than 60 percent versus GAN counterparts, without sacrificing downstream predictive utility. A black-box membership-inference evaluation using the DOMIAS attacker yields AUROC approximately 0.53, well below the 0.55 safe-release threshold and substantially better than the approximately 0.61 plus or minus 0.03 observed for non-KG baselines, demonstrating strong resistance to re-identification. These results suggest that integrating biomedical knowledge graphs directly into diffusion noise schedules can simultaneously enhance fidelity and privacy, enabling safer data sharing for rare-disease research.', 'abstract_zh': 'RareGraph-Synth：一种知识导向的连续时间扩散框架，用于生成超罕见疾病的真实且隐私保护的合成电子健康记录轨迹', 'title_zh': 'RareGraph-Synth：知识引导的扩散模型在超罕见疾病中生成隐私保护的合成病人轨迹'}
{'arxiv_id': 'arXiv:2510.06266', 'title': 'Language models for longitudinal analysis of abusive content in Billboard Music Charts', 'authors': 'Rohitash Chandra, Yathin Suresh, Divyansh Raj Sinha, Sanchit Jindal', 'link': 'https://arxiv.org/abs/2510.06266', 'abstract': 'There is no doubt that there has been a drastic increase in abusive and sexually explicit content in music, particularly in Billboard Music Charts. However, there is a lack of studies that validate the trend for effective policy development, as such content has harmful behavioural changes in children and youths. In this study, we utilise deep learning methods to analyse songs (lyrics) from Billboard Charts of the United States in the last seven decades. We provide a longitudinal study using deep learning and language models and review the evolution of content using sentiment analysis and abuse detection, including sexually explicit content. Our results show a significant rise in explicit content in popular music from 1990 onwards. Furthermore, we find an increasing prevalence of songs with lyrics containing profane, sexually explicit, and otherwise inappropriate language. The longitudinal analysis of the ability of language models to capture nuanced patterns in lyrical content, reflecting shifts in societal norms and language use over time.', 'abstract_zh': '毫无疑问，音乐中 abusive 和露骨性内容的数量在大幅增加，特别是在 Billboard 音乐图表中。然而，缺乏验证这一趋势的研究，尤其是对于有效政策制定而言，此类内容会给孩子和青少年带来有害的行为变化。在本研究中，我们利用深度学习方法分析过去七十年美国 Billboard 音乐图表中的歌曲（歌词）。我们提供了一项 longitudinal 研究，利用深度学习和语言模型来审查内容的演变，包括使用情感分析和辱骂内容检测来评估露骨性内容。结果显示，从 1990 年代开始，流行音乐中的露骨内容显著增加。此外，我们发现包含粗俗、露骨和不适当语言的歌曲数量也在增加。纵向分析语言模型捕捉歌词内容中细微模式的能力，反映了随时间变化的社会规范和语言使用趋势。', 'title_zh': 'longitudinally分析 Billboard 音乐排行榜中 Abuse 内容的语言模型'}
{'arxiv_id': 'arXiv:2510.06263', 'title': 'Dual-stage and Lightweight Patient Chart Summarization for Emergency Physicians', 'authors': 'Jiajun Wu, Swaleh Zaidi, Braden Teitge, Henry Leung, Jiayu Zhou, Jessalyn Holodinsky, Steve Drew', 'link': 'https://arxiv.org/abs/2510.06263', 'abstract': "Electronic health records (EHRs) contain extensive unstructured clinical data that can overwhelm emergency physicians trying to identify critical information. We present a two-stage summarization system that runs entirely on embedded devices, enabling offline clinical summarization while preserving patient privacy. In our approach, a dual-device architecture first retrieves relevant patient record sections using the Jetson Nano-R (Retrieve), then generates a structured summary on another Jetson Nano-S (Summarize), communicating via a lightweight socket link. The summarization output is two-fold: (1) a fixed-format list of critical findings, and (2) a context-specific narrative focused on the clinician's query. The retrieval stage uses locally stored EHRs, splits long notes into semantically coherent sections, and searches for the most relevant sections per query. The generation stage uses a locally hosted small language model (SLM) to produce the summary from the retrieved text, operating within the constraints of two NVIDIA Jetson devices. We first benchmarked six open-source SLMs under 7B parameters to identify viable models. We incorporated an LLM-as-Judge evaluation mechanism to assess summary quality in terms of factual accuracy, completeness, and clarity. Preliminary results on MIMIC-IV and de-identified real EHRs demonstrate that our fully offline system can effectively produce useful summaries in under 30 seconds.", 'abstract_zh': '电子健康记录(EHRs)包含大量的非结构化临床数据，可能使急诊医师难以识别关键信息。我们提出了一种完全基于嵌入式设备的两阶段摘要系统，能够在离线条件下进行临床摘要的同时保护患者隐私。在我们的方法中，使用Jetson Nano-R（检索）设备首先检索相关患者记录部分，然后使用另一个Jetson Nano-S（生成）设备生成结构化总结，两者通过轻量级套接字链路进行通信。摘要输出包括两部分：(1) 固定格式的关键发现列表，(2) 与医生查询相关的上下文特定叙述。检索阶段使用本地存储的EHRs，将长笔记拆分成语义上连贯的部分，并根据每个查询查找最相关部分。生成阶段使用本地托管的小型语言模型（SLM）从检索到的文本中生成摘要，满足两个NVIDIA Jetson设备的限制。我们首先对参数少于7B的六种开源SLM进行了基准测试，以确定可行的模型。我们引入了一种基于大型语言模型（LLM）的评估机制来评估摘要的质量，包括事实准确性、完整性以及清晰度。初步结果表明，我们的完全离线系统能够在不到30秒的时间内有效地生成有用摘要。', 'title_zh': '面向急诊医师的双重阶段轻量级病历总结'}
{'arxiv_id': 'arXiv:2510.06262', 'title': 'Prakriti200: A Questionnaire-Based Dataset of 200 Ayurvedic Prakriti Assessments', 'authors': 'Aryan Kumar Singh, Janvi Singh', 'link': 'https://arxiv.org/abs/2510.06262', 'abstract': 'This dataset provides responses to a standardized, bilingual (English-Hindi) Prakriti Assessment Questionnaire designed to evaluate the physical, physiological, and psychological characteristics of individuals according to classical Ayurvedic principles. The questionnaire consists of 24 multiple-choice items covering body features, appetite, sleep patterns, energy levels, and temperament. It was developed following AYUSH/CCRAS guidelines to ensure comprehensive and accurate data collection. All questions are mandatory and neutrally phrased to minimize bias, and dosha labels (Vata, Pitta, Kapha) are hidden from participants. Data were collected via a Google Forms deployment, enabling automated scoring of responses to map individual traits to dosha-specific scores. The resulting dataset provides a structured platform for research in computational intelligence, Ayurvedic studies, and personalized health analytics, supporting analysis of trait distributions, correlations, and predictive modeling. It can also serve as a reference for future Prakriti-based studies and the development of intelligent health applications.', 'abstract_zh': '这个数据集提供了标准化双语（英语-印地语）生理类型评估问卷的回答，根据传统阿育吠陀原则评估个人的物理、生理和心理特征。问卷包括24个多项选择题，覆盖身体特征、食欲、睡眠模式、能量水平和气质。该问卷按照AYUSH/CCRAS指南开发，以确保数据收集的全面性和准确性。所有问题都是强制性和中性的，以减少偏见，dosha标签（维通、毗湿奴、迦发）对参与者隐藏。数据通过Google表单部署收集，实现自动化评分，将个人特征映射到特定的dosha评分。该数据集提供了一个结构化的平台，用于计算智能、阿育吠陀研究和个人健康分析，支持特质分布、相关性和预测模型的分析。它还可以作为未来基于生理类型的研究和智能健康应用开发的参考。', 'title_zh': 'Prakriti200：基于问卷的200例 Ayurvedic 印度医学 Prakriti 评估数据集'}
{'arxiv_id': 'arXiv:2510.06260', 'title': 'Ensemble Deep Learning and LLM-Assisted Reporting for Automated Skin Lesion Diagnosis', 'authors': 'Sher Khan, Raz Muhammad, Adil Hussain, Muhammad Sajjad, Muhammad Rashid', 'link': 'https://arxiv.org/abs/2510.06260', 'abstract': 'Cutaneous malignancies demand early detection for favorable outcomes, yet current diagnostics suffer from inter-observer variability and access disparities. While AI shows promise, existing dermatological systems are limited by homogeneous architectures, dataset biases across skin tones, and fragmented approaches that treat natural language processing as separate post-hoc explanations rather than integral to clinical decision-making. We introduce a unified framework that fundamentally reimagines AI integration for dermatological diagnostics through two synergistic innovations. First, a purposefully heterogeneous ensemble of architecturally diverse convolutional neural networks provides complementary diagnostic perspectives, with an intrinsic uncertainty mechanism flagging discordant cases for specialist review -- mimicking clinical best practices. Second, we embed large language model capabilities directly into the diagnostic workflow, transforming classification outputs into clinically meaningful assessments that simultaneously fulfill medical documentation requirements and deliver patient-centered education. This seamless integration generates structured reports featuring precise lesion characterization, accessible diagnostic reasoning, and actionable monitoring guidance -- empowering patients to recognize early warning signs between visits. By addressing both diagnostic reliability and communication barriers within a single cohesive system, our approach bridges the critical translational gap that has prevented previous AI implementations from achieving clinical impact. The framework represents a significant advancement toward deployable dermatological AI that enhances diagnostic precision while actively supporting the continuum of care from initial detection through patient education, ultimately improving early intervention rates for skin lesions.', 'abstract_zh': '皮肤恶性肿瘤需要早期检测以获得有利的治疗结果，但当前的诊断方法存在观察者间差异和获取不均的问题。尽管人工智能显示出潜力，现有的皮肤病诊断系统受限于同质化的架构、跨肤色数据集偏差以及将自然语言处理分离出临床决策过程的做法。我们提出了一种统一框架，从根本上重新设想了人工智能在皮肤病诊断中的集成，通过两种协同创新实现。首先，一组旨在异质的、架构多样的卷积神经网络提供了互补的诊断视角，并内置不确定性机制将存在分歧的病例标记给专家复审，模拟临床最佳实践。其次，我们直接将大型语言模型的能力嵌入诊断流程中，将分类输出转化为具有医疗记录要求和患者中心 Educate 成分的临床意义评估。这一无缝集成生成了包含精准病损表征、易懂诊断推理和可操作监测指导的结构化报告，使患者能够在就诊间识别早期预警信号。通过在一个统一系统中解决诊断可靠性和沟通障碍，我们的方法填补了之前人工智能实施未能实现临床影响的关键鸿沟。该框架代表了通往可部署皮肤病人工智能的重要进展，该人工智能不仅能提高诊断精准度，还能积极支持从初始检测到患者教育的整个治疗进程，最终提高皮肤病变早期干预率。', 'title_zh': '集成深度学习与大语言模型辅助报告的皮肤病变自动诊断'}
{'arxiv_id': 'arXiv:2510.06253', 'title': 'LLM-Driven Rubric-Based Assessment of Algebraic Competence in Multi-Stage Block Coding Tasks with Design and Field Evaluation', 'authors': 'Yong Oh Lee, Byeonghun Bang, Sejun Oh', 'link': 'https://arxiv.org/abs/2510.06253', 'abstract': "As online education platforms continue to expand, there is a growing need for assessment methods that not only measure answer accuracy but also capture the depth of students' cognitive processes in alignment with curriculum objectives. This study proposes and evaluates a rubric-based assessment framework powered by a large language model (LLM) for measuring algebraic competence, real-world-context block coding tasks. The problem set, designed by mathematics education experts, aligns each problem segment with five predefined rubric dimensions, enabling the LLM to assess both correctness and quality of students' problem-solving processes. The system was implemented on an online platform that records all intermediate responses and employs the LLM for rubric-aligned achievement evaluation. To examine the practical effectiveness of the proposed framework, we conducted a field study involving 42 middle school students engaged in multi-stage quadratic equation tasks with block coding. The study integrated learner self-assessments and expert ratings to benchmark the system's outputs. The LLM-based rubric evaluation showed strong agreement with expert judgments and consistently produced rubric-aligned, process-oriented feedback. These results demonstrate both the validity and scalability of incorporating LLM-driven rubric assessment into online mathematics and STEM education platforms.", 'abstract_zh': '随着在线教育平台的不断扩大，需要一种不仅可以衡量答案准确性，还能捕获学生认知过程深度并与课程目标保持一致的评估方法。本研究提出并评估了一种基于评分标准的评估框架，该框架借助大型语言模型（LLM）来衡量代数能力及基于现实情境的块式编程任务。由数学教育专家设计的问题集将每个问题部分与五个预设的评分标准维度对齐，使LLM能够评估学生解决问题过程的正确性和质量。该系统已在记录所有中间响应的在线平台上实现，并利用LLM进行评分标准对齐的表现评价。为了检验所提框架的实际有效性，我们在一项涉及42名中学生执行多阶段二次方程块式编程任务的实地研究中实施了该系统。该研究整合了学习者自我评估和专家评分，以衡量系统输出的基准。基于LLM的评分标准评估与专家判断高度一致，并持续提供与评分标准对齐的过程导向反馈。这些结果证明了将LLM驱动的评分标准评估集成到在线数学和STEM教育平台中的有效性和可扩展性。', 'title_zh': '基于设计与现场评估的多阶段积木编码任务中的代数能力评分驱动评估'}
{'arxiv_id': 'arXiv:2510.06252', 'title': 'Dream2Image : An Open Multimodal EEG Dataset for Decoding and Visualizing Dreams with Artificial Intelligence', 'authors': 'Yann Bellec', 'link': 'https://arxiv.org/abs/2510.06252', 'abstract': "Dream2Image is the world's first dataset combining EEG signals, dream transcriptions, and AI-generated images. Based on 38 participants and more than 31 hours of dream EEG recordings, it contains 129 samples offering: the final seconds of brain activity preceding awakening (T-15, T-30, T-60, T-120), raw reports of dream experiences, and an approximate visual reconstruction of the dream. This dataset provides a novel resource for dream research, a unique resource to study the neural correlates of dreaming, to develop models for decoding dreams from brain activity, and to explore new approaches in neuroscience, psychology, and artificial intelligence. Available in open access on Hugging Face and GitHub, Dream2Image provides a multimodal resource designed to support research at the interface of artificial intelligence and neuroscience. It was designed to inspire researchers and extend the current approaches to brain activity decoding. Limitations include the relatively small sample size and the variability of dream recall, which may affect generalizability.", 'abstract_zh': 'Dream2Image是首个结合EEG信号、梦境转述和AI生成图像的数据集。', 'title_zh': 'Dream2Image：一种用于使用人工智能解码和可视化梦境的开放多模态EEG数据集'}
{'arxiv_id': 'arXiv:2510.06250', 'title': 'Scalable multilingual PII annotation for responsible AI in LLMs', 'authors': 'Bharti Meena, Joanna Skubisz, Harshit Rajgarhia, Nand Dave, Kiran Ganesh, Shivali Dalmia, Abhishek Mukherji, Vasudevan Sundarababu, Olga Pospelova', 'link': 'https://arxiv.org/abs/2510.06250', 'abstract': 'As Large Language Models (LLMs) gain wider adoption, ensuring their reliable handling of Personally Identifiable Information (PII) across diverse regulatory contexts has become essential. This work introduces a scalable multilingual data curation framework designed for high-quality PII annotation across 13 underrepresented locales, covering approximately 336 locale-specific PII types. Our phased, human-in-the-loop annotation methodology combines linguistic expertise with rigorous quality assurance, leading to substantial improvements in recall and false positive rates from pilot, training, and production phases. By leveraging inter-annotator agreement metrics and root-cause analysis, the framework systematically uncovers and resolves annotation inconsistencies, resulting in high-fidelity datasets suitable for supervised LLM fine-tuning. Beyond reporting empirical gains, we highlight common annotator challenges in multilingual PII labeling and demonstrate how iterative, analytics-driven pipelines can enhance both annotation quality and downstream model reliability.', 'abstract_zh': '随着大型语言模型（LLMs）的广泛应用，确保其在多种监管环境下可靠处理个人可识别信息（PII）已成为必要。本文介绍了一种针对13个代表性不足的地域、涵盖约336种地域特定PII类型的可扩展多语言数据整理框架。该框架的人机结合标注方法结合了语言学专长和严格的质量保证，从试点、训练和生产阶段显著提高了召回率和减少误报率。通过利用注标者间一致性指标和根本原因分析，框架系统地发现和解决了标注不一致问题，生成适用于监督微调的高保真数据集。除了报告实证收益，我们还强调了多语言PII标注中的常见注标者挑战，并展示了迭代的数据驱动管道如何提高标注质量和下游模型的可靠性。', 'title_zh': '可扩展的多语言PII标注以实现LLM中的负责任人工智能'}
{'arxiv_id': 'arXiv:2510.06249', 'title': 'TRepLiNa: Layer-wise CKA+REPINA Alignment Improves Low-Resource Machine Translation in Aya-23 8B', 'authors': 'Toshiki Nakai, Ravi Kiran Chikkala, Lena Sophie Oberkircher, Nicholas Jennings, Natalia Skachkova, Tatiana Anikina, Jesujoba Oluwadara Alabi', 'link': 'https://arxiv.org/abs/2510.06249', 'abstract': "The 2025 Multimodal Models for Low-Resource Contexts and Social Impact (MMLoSo) Language Challenge addresses one of India's most pressing linguistic gaps: the lack of resources for its diverse low-resource languages (LRLs). In this study, we investigate whether enforcing cross-lingual similarity in specific internal layers of a decoder-only multilingual large language model (LLM) can improve translation quality from LRL to high-resource language (HRL). Specifically, we combine Centered Kernel Alignment (CKA), a similarity metric that encourages representations of different languages to align, with REPINA, a regularization method that constrains parameter updates to remain close to the pretrained model, into a joint method we call TRepLiNa. In this research project, we experiment with zero-shot, few-shot, and fine-tuning settings using Aya-23 8B with QLoRA across MMLoSo shared task language pairs (Mundari, Santali, Bhili) with Hindi/English pivots. Our results show that aligning mid-level layers using TRepLiNa (CKA+REPINA) is a low-cost, practical approach to improving LRL translation, especially in data-scarce settings.", 'abstract_zh': '2025多模态模型在低资源语境和社会影响（MMLoSo）语言挑战中的低资源语言（LRL）资源不足问题研究：强制特定解码器内部层的跨语言相似性以提高LRL到高资源语言（HRL）翻译质量', 'title_zh': 'TRepLiNa: 层级CKA+REPINA对齐改善了Aya-23 8B低资源机器翻译'}
{'arxiv_id': 'arXiv:2510.06245', 'title': 'DynBenchmark: Customizable Ground Truths to Benchmark Community Detection and Tracking in Temporal Networks', 'authors': 'Laurent Brisson, Cécile Bothorel, Nicolas Duminy', 'link': 'https://arxiv.org/abs/2510.06245', 'abstract': "Graph models help understand network dynamics and evolution. Creating graphs with controlled topology and embedded partitions is a common strategy for evaluating community detection algorithms. However, existing benchmarks often overlook the need to track the evolution of communities in real-world networks. To address this, a new community-centered model is proposed to generate customizable evolving community structures where communities can grow, shrink, merge, split, appear or disappear. This benchmark also generates the underlying temporal network, where nodes can appear, disappear, or move between communities. The benchmark has been used to test three methods, measuring their performance in tracking nodes' cluster membership and detecting community evolution. Python libraries, drawing utilities, and validation metrics are provided to compare ground truth with algorithm results for detecting dynamic communities.", 'abstract_zh': '基于图形的模型有助于理解网络动力学和演化。为了评估社区发现算法，通常采用具有可控拓扑和嵌入分区的图形模型。然而，现有的基准数据往往忽视了跟踪现实世界网络中社区演化的需求。为此，提出了一种以社区为中心的新模型，用于生成可定制的演化社区结构，其中社区可以增长、缩小、合并、分裂、出现或消失。该基准还生成了底层的时变网络，其中节点可以出现、消失或在社区间移动。该基准已被用于测试三种方法，测量其在追踪节点聚类成员身份和检测社区演化方面的性能。提供的Python库、绘图工具和验证指标可用于将检测动态社区的真实情况与算法结果进行比较。', 'title_zh': 'DynBenchmark: 可定制的真实标签用于时间网络社区检测与追踪评估'}
{'arxiv_id': 'arXiv:2510.06244', 'title': 'Evaluating Embedding Frameworks for Scientific Domain', 'authors': 'Nouman Ahmed, Ronin Wu, Victor Botev', 'link': 'https://arxiv.org/abs/2510.06244', 'abstract': 'Finding an optimal word representation algorithm is particularly important in terms of domain specific data, as the same word can have different meanings and hence, different representations depending on the domain and context. While Generative AI and transformer architecture does a great job at generating contextualized embeddings for any given work, they are quite time and compute extensive, especially if we were to pre-train such a model from scratch. In this work, we focus on the scientific domain and finding the optimal word representation algorithm along with the tokenization method that could be used to represent words in the scientific domain. The goal of this research is two fold: 1) finding the optimal word representation and tokenization methods that can be used in downstream scientific domain NLP tasks, and 2) building a comprehensive evaluation suite that could be used to evaluate various word representation and tokenization algorithms (even as new ones are introduced) in the scientific domain. To this end, we build an evaluation suite consisting of several downstream tasks and relevant datasets for each task. Furthermore, we use the constructed evaluation suite to test various word representation and tokenization algorithms.', 'abstract_zh': '在特定领域数据中寻找最优词表示算法尤为重要，因为同一个词在不同的领域和上下文中可能具有不同的含义和表示。虽然生成式AI和变压器架构在生成任何给定词的上下文化嵌入方面做得非常好，但在从头开始预训练这样的模型时，它们非常耗时且计算资源密集。在这项工作中，我们专注于科学领域，并寻找适用于科学领域的最优词表示算法及其标记化方法。本研究的目标有两个：1) 寻找适用于科学领域自然语言处理任务的最优词表示和标记化方法；2) 构建一个全面的评估套件，用于评估各种词表示和标记化算法（即使有新的算法出现），以评估科学领域的表现。为此，我们构建了一个评估套件，其中包括多个下游任务和每个任务的相关数据集。此外，我们使用构建的评估套件来测试各种词表示和标记化算法。', 'title_zh': '评价科学领域嵌入框架'}
{'arxiv_id': 'arXiv:2510.06243', 'title': 'CoT Referring: Improving Referring Expression Tasks with Grounded Reasoning', 'authors': 'Qihua Dong, Luis Figueroa, Handong Zhao, Kushal Kafle, Jason Kuen, Zhihong Ding, Scott Cohen, Yun Fu', 'link': 'https://arxiv.org/abs/2510.06243', 'abstract': 'Referring Expression Comprehension and Segmentation are critical tasks for assessing the integration of language understanding and image comprehension, serving as benchmarks for Multimodal Large Language Models (MLLMs) capabilities. To address these challenges, we propose a new strategy, CoT Referring, which enhances model reasoning across modalities through a structured, chain-of-thought training data structure. Our approach systematically parses textual structures to a sequential referring step, where in each step it identifies relationships and ensures consistent reference alignment, thereby improving accuracy in complex query scenarios. We restructure the training data to enforce a new output form, providing new annotations for existing datasets and compiling an evaluation benchmark from existing resources. This benchmark is designed explicitly for complex referring cases. We also integrate detection and segmentation capabilities into a unified MLLM framework, training it with a novel adaptive weighted loss to optimize performance. Experimental results on our curated benchmark and RefCOCO/+/g demonstrate the effectiveness of our approach, with a notable increase of 2.5%+ over baseline models.', 'abstract_zh': '参照表达理解和分割是评估语言理解与图像理解整合的关键任务，作为多模态大语言模型（MLLMs）能力的基准。为应对这些挑战，我们提出了一种新的策略CoT Referring，通过结构化的链式思考训练数据结构增强模型在多模态间的推理能力。我们的方法系统地将文本结构分解为顺序的参照步骤，在每一步中识别关系并确保一致的参照对齐，从而在复杂的查询场景中提高准确性。我们重构了训练数据以强制新的输出形式，并为现有数据集提供新的标注，同时整合现有资源构建了一个专门针对复杂参照情况的评估基准。我们还将检测和分割能力整合到统一的MLLM框架中，并使用新颖的自适应加权损失进行训练，以优化性能。在我们精心策划的基准和RefCOCO/+/g上的实验结果表明，我们的方法有效，相较于基线模型，准确率提高了2.5%以上。', 'title_zh': '基于grounded reasoning改进指称表达任务'}
{'arxiv_id': 'arXiv:2510.06242', 'title': 'Transparent Reference-free Automated Evaluation of Open-Ended User Survey Responses', 'authors': 'Subin An, Yugyeong Ji, Junyoung Kim, Heejin Kook, Yang Lu, Josh Seltzer', 'link': 'https://arxiv.org/abs/2510.06242', 'abstract': 'Open-ended survey responses provide valuable insights in marketing research, but low-quality responses not only burden researchers with manual filtering but also risk leading to misleading conclusions, underscoring the need for effective evaluation. Existing automatic evaluation methods target LLM-generated text and inadequately assess human-written responses with their distinct characteristics. To address such characteristics, we propose a two-stage evaluation framework specifically designed for human survey responses. First, gibberish filtering removes nonsensical responses. Then, three dimensions-effort, relevance, and completeness-are evaluated using LLM capabilities, grounded in empirical analysis of real-world survey data. Validation on English and Korean datasets shows that our framework not only outperforms existing metrics but also demonstrates high practical applicability for real-world applications such as response quality prediction and response rejection, showing strong correlations with expert assessment.', 'abstract_zh': '开放式的调查反馈为市场营销研究提供了宝贵的见解，但低质量的反馈不仅增加了研究人员的手动筛选负担，还可能导致错误结论，强调了有效评估的必要性。现有自动评估方法主要针对LLM生成的文本，未能充分评估具有独特特征的人类撰写的反馈。为应对这些特征，我们提出了一种两阶段评估框架，专门设计用于评估人类调查反馈。首先，无意义内容过滤去除无意义的反馈。然后，通过基于实际调查数据的实证分析，使用LLM能力从努力程度、相关性和完整性三个维度进行评估。在英语和韩语数据集上的验证表明，我们的框架不仅在现有指标上表现更优，还展示了在真实应用中预测和拒绝反馈的强大实用性，并与专家评估高度相关。', 'title_zh': '开放-ended用户调查响应的透明无参考自动评估'}
{'arxiv_id': 'arXiv:2510.06240', 'title': 'Knowledge Graph-Guided Multi-Agent Distillation for Reliable Industrial Question Answering with Datasets', 'authors': 'Jiqun Pan, Zhenke Duan, Jiani Tu, Anzhi Cheng, Yanqing Wang', 'link': 'https://arxiv.org/abs/2510.06240', 'abstract': 'Industrial question-answering (QA) systems require higher safety and reliability than general-purpose dialogue models, as errors in high-risk scenarios such as equipment fault diagnosis can have severe consequences. Although multi-agent large language models enhance reasoning depth, they suffer from uncontrolled iterations and unverifiable outputs, and conventional distillation methods struggle to transfer collaborative reasoning capabilities to lightweight, deployable student models. To address these challenges, we propose Knowledge Graph-guided Multi-Agent System Distillation (KG-MASD). Our approach formulates distillation as a Markov Decision Process and incorporates a knowledge graph as a verifiable structured prior to enrich state representation and ensure convergence. By integrating collaborative reasoning with knowledge grounding, KG-MASD generates high-confidence instruction-tuning data and jointly distills reasoning depth and verifiability into compact student models suitable for edge deployment. Experiments on an industrial QA dataset show that KG-MASD improves accuracy by 2.4 per cent to 20.1 per cent over baselines and significantly enhances reliability, enabling trustworthy AI deployment in safety-critical industrial scenarios. Code and data are available at this https URL.', 'abstract_zh': '基于知识图谱的多-agent系统蒸馏（KG-MASD）：提高工业问答系统的安全性和可靠性', 'title_zh': '基于知识图谱的多智能体精简方法以实现可靠的工业问题解答与数据集辅助'}
{'arxiv_id': 'arXiv:2510.06238', 'title': 'Uncertainty Quantification In Surface Landmines and UXO Classification Using MC Dropout', 'authors': 'Sagar Lekhak, Emmett J. Ientilucci, Dimah Dera, Susmita Ghosh', 'link': 'https://arxiv.org/abs/2510.06238', 'abstract': "Detecting surface landmines and unexploded ordnances (UXOs) using deep learning has shown promise in humanitarian demining. However, deterministic neural networks can be vulnerable to noisy conditions and adversarial attacks, leading to missed detection or misclassification. This study introduces the idea of uncertainty quantification through Monte Carlo (MC) Dropout, integrated into a fine-tuned ResNet-50 architecture for surface landmine and UXO classification, which was tested on a simulated dataset. Integrating the MC Dropout approach helps quantify epistemic uncertainty, providing an additional metric for prediction reliability, which could be helpful to make more informed decisions in demining operations. Experimental results on clean, adversarially perturbed, and noisy test images demonstrate the model's ability to flag unreliable predictions under challenging conditions. This proof-of-concept study highlights the need for uncertainty quantification in demining, raises awareness about the vulnerability of existing neural networks in demining to adversarial threats, and emphasizes the importance of developing more robust and reliable models for practical applications.", 'abstract_zh': '使用深度学习检测地表地雷和未爆弹药并通过蒙特卡洛 Dropout 量化不确定性在人道主义排雷中的潜力', 'title_zh': '表面地雷和UXO分类中的不确定性量化使用MC Dropout'}
{'arxiv_id': 'arXiv:2510.06235', 'title': 'Stacked Regression using Off-the-shelf, Stimulus-tuned and Fine-tuned Neural Networks for Predicting fMRI Brain Responses to Movies (Algonauts 2025 Report)', 'authors': 'Robert Scholz, Kunal Bagga, Christine Ahrends, Carlo Alberto Barbano', 'link': 'https://arxiv.org/abs/2510.06235', 'abstract': 'We present our submission to the Algonauts 2025 Challenge, where the goal is to predict fMRI brain responses to movie stimuli. Our approach integrates multimodal representations from large language models, video encoders, audio models, and vision-language models, combining both off-the-shelf and fine-tuned variants. To improve performance, we enhanced textual inputs with detailed transcripts and summaries, and we explored stimulus-tuning and fine-tuning strategies for language and vision models. Predictions from individual models were combined using stacked regression, yielding solid results. Our submission, under the team name Seinfeld, ranked 10th. We make all code and resources publicly available, contributing to ongoing efforts in developing multimodal encoding models for brain activity.', 'abstract_zh': '我们提交了对2025年Algonauts挑战赛的内容，目标是预测电影刺激下的fMRI脑部反应。我们的方法结合了大型语言模型、视频编码器、音频模型和视觉-语言模型的多模态表示，既包括现成的版本也包括微调后的版本。为了提高性能，我们通过详细的脚本和摘要增强了文本输入，并探索了语言模型和视觉模型的刺激调谐及微调策略。各模型的预测结果通过堆叠回归进行融合，取得了令人满意的结果。以Seinfeld团队名义提交的作品排名第十。我们已将所有代码和资源公开，为开发用于脑活动的多模态编码模型做出了贡献。', 'title_zh': '使用现成的、刺激调谐的和微调的神经网络堆叠回归方法预测电影观看引起的fMRI脑响应（Algonauts 2025报告）'}
{'arxiv_id': 'arXiv:2510.06225', 'title': 'Generalized Multi-agent Social Simulation Framework', 'authors': 'Gang Li, Jie Lin, Yining Tang, Ziteng Wang, Yirui Huang, Junyu Zhang, Shuang Luo, Chao Wu, Yike Guo', 'link': 'https://arxiv.org/abs/2510.06225', 'abstract': 'Multi-agent social interaction has clearly benefited from Large Language Models. However, current simulation systems still face challenges such as difficulties in scaling to diverse scenarios and poor reusability due to a lack of modular design. To address these issues, we designed and developed a modular, object-oriented framework that organically integrates various base classes through a hierarchical structure, harvesting scalability and reusability. We inherited the framework to realize common derived classes. Additionally, a memory summarization mechanism is proposed to filter and distill relevant information from raw memory data, prioritizing contextually salient events and interactions. By selecting and combining some necessary derived classes, we customized a specific simulated environment. Utilizing this simulated environment, we successfully simulated human interactions on social media, replicating real-world online social behaviors. The source code for the project will be released and evolve.', 'abstract_zh': '多智能体社会交互明显受益于大型语言模型。然而，当前的模拟系统仍然面临诸如难以扩展到多样化场景和由于缺乏模块化设计而导致的低重用性等挑战。为了解决这些问题，我们设计并开发了一个模块化、面向对象的框架，通过层次结构有机地整合了各种基类，实现了可扩展性和重用性。我们继承该框架以实现通用派生类。此外，我们提出了一种内存总结机制，用于过滤和提炼原始内存数据中的相关信息，优先处理上下文相关的事件和交互。通过选择并组合一些必要的派生类，我们定制了一个特定的模拟环境。利用该模拟环境，我们成功模拟了社会媒体上的人类交互，再现了真实世界的在线社会行为。该项目的源代码将被发布并不断演进。', 'title_zh': '广义多agent社会仿真框架'}
{'arxiv_id': 'arXiv:2510.06224', 'title': 'Exploring Human-AI Collaboration Using Mental Models of Early Adopters of Multi-Agent Generative AI Tools', 'authors': 'Suchismita Naik, Austin L. Toombs, Amanda Snellinger, Scott Saponas, Amanda K. Hall', 'link': 'https://arxiv.org/abs/2510.06224', 'abstract': 'With recent advancements in multi-agent generative AI (Gen AI), technology organizations like Microsoft are adopting these complex tools, redefining AI agents as active collaborators in complex workflows rather than as passive tools. In this study, we investigated how early adopters and developers conceptualize multi-agent Gen AI tools, focusing on how they understand human-AI collaboration mechanisms, general collaboration dynamics, and transparency in the context of AI tools. We conducted semi-structured interviews with 13 developers, all early adopters of multi-agent Gen AI technology who work at Microsoft. Our findings revealed that these early adopters conceptualize multi-agent systems as "teams" of specialized role-based and task-based agents, such as assistants or reviewers, structured similar to human collaboration models and ranging from AI-dominant to AI-assisted, user-controlled interactions. We identified key challenges, including error propagation, unpredictable and unproductive agent loop behavior, and the need for clear communication to mitigate the layered transparency issues. Early adopters\' perspectives about the role of transparency underscored its importance as a way to build trust, verify and trace errors, and prevent misuse, errors, and leaks. The insights and design considerations we present contribute to CSCW research about collaborative mechanisms with capabilities ranging from AI-dominant to AI-assisted interactions, transparency and oversight strategies in human-agent and agent-agent interactions, and how humans make sense of these multi-agent systems as dynamic, role-diverse collaborators which are customizable for diverse needs and workflows. We conclude with future research directions that extend CSCW approaches to the design of inter-agent and human mediation interactions.', 'abstract_zh': '随着多智能体生成人工智能（Gen AI）的进展，像微软这样的技术组织开始采用这些复杂工具，重新定义AI代理为复杂工作流程中的主动合作者，而非被动工具。本研究调查了早期采用者和开发者对多智能体Gen AI工具的认知，重点探讨他们对人类-AI协作机制、一般协作动态以及工具透明性的理解。我们对13名微软的早期采用者和开发人员进行了半结构化访谈。研究发现，这些早期采用者将多智能体系统视为具有专门角色和任务代理的“团队”，如助手或审查员，这些代理的结构类似于人类协作模型，并且从AI主导到AI辅助，再到用户控制的交互。我们识别出了几个关键挑战，包括错误传播、不可预测且无成效的代理循环行为以及需要清晰沟通以缓解多层透明性问题。早期采用者关于透明性的角色认识强调了其作为建立信任、验证和追踪错误、防止误用、错误和泄露的重要性。我们提出的见解和设计考虑有助于拓展社会计算与协作（CSCW）关于从AI主导到AI辅助交互的协作机制研究，关于人类-代理和代理-代理互动中的透明性和监督策略研究，以及人类如何将这些多智能体系统视为动态、角色多元的合作者的研究，并且这些系统可以根据不同的需求和工作流程进行定制。研究还指出了未来的研究方向，即扩展CSCW方法以设计跨代理和人类中介互动的设计。', 'title_zh': '探索多智能体生成AI工具早期采用者的心智模型中的人类-AI协作'}
{'arxiv_id': 'arXiv:2510.06223', 'title': 'A Multimodal GUI Architecture for Interfacing with LLM-Based Conversational Assistants', 'authors': 'Hans G.W. van Dam', 'link': 'https://arxiv.org/abs/2510.06223', 'abstract': "Advances in large language models (LLMs) and real-time speech recognition now make it possible to issue any graphical user interface (GUI) action through natural language and receive the corresponding system response directly through the GUI. Most production applications were never designed with speech in mind. This article provides a concrete architecture that enables GUIs to interface with LLM-based speech-enabled assistants.\nThe architecture makes an application's navigation graph and semantics available through the Model Context Protocol (MCP). The ViewModel, part of the MVVM (Model-View-ViewModel) pattern, exposes the application's capabilities to the assistant by supplying both tools applicable to a currently visible view and application-global tools extracted from the GUI tree router. This architecture facilitates full voice accessibility while ensuring reliable alignment between spoken input and the visual interface, accompanied by consistent feedback across modalities. It future-proofs apps for upcoming OS super assistants that employ computer use agents (CUAs) and natively consume MCP if an application provides it.\nTo address concerns about privacy and data security, the practical effectiveness of locally deployable, open-weight LLMs for speech-enabled multimodal UIs is evaluated. Findings suggest that recent smaller open-weight models approach the performance of leading proprietary models in overall accuracy and require enterprise-grade hardware for fast responsiveness.", 'abstract_zh': '大型语言模型（LLMs）和实时语音识别的进步现在使通过自然语言发布任何图形用户界面（GUI）操作并通过GUI直接接收相应系统响应成为可能。大多数生产应用程序从未专门为语音设计。本文提供了一种具体的架构，使GUI能够与基于LLM的语音助手进行交互。\n该架构通过模型上下文协议（MCP）使应用程序的导航图和语义可供应用。视图模型作为MVVM（模型-视图-视图模型）模式的一部分，通过提供适用于当前可见视图的工具以及从GUI树路由中提取的应用全局工具，向助手展示应用程序的能力。该架构促进了全面的语音访问，同时确保了口头输入与视觉界面之间的可靠对齐，并在不同模态中提供了一致的反馈。它为即将出现的使用计算使用代理（CUA）并原生消费MCP的OS超级助手做好了准备。\n为了应对隐私和数据安全方面的担忧，评估了在语音增强型多模态UI中本地部署和开放权重的LLM的实际效果。研究发现，最近较小的开放权重模型在总体准确率方面接近领先专有模型的表现，并且需要企业级硬件才能实现快速响应。', 'title_zh': '基于LLM的对话式助手的多模态GUI架构'}
{'arxiv_id': 'arXiv:2510.05336', 'title': 'WeatherArchive-Bench: Benchmarking Retrieval-Augmented Reasoning for Historical Weather Archives', 'authors': 'Yongan Yu, Xianda Du, Qingchen Hu, Jiahao Liang, Jingwei Ni, Dan Qiang, Kaiyu Huang, Grant McKenzie, Renee Sieber, Fengran Mo', 'link': 'https://arxiv.org/abs/2510.05336', 'abstract': "Historical archives on weather events are collections of enduring primary source records that offer rich, untapped narratives of how societies have experienced and responded to extreme weather events. These qualitative accounts provide insights into societal vulnerability and resilience that are largely absent from meteorological records, making them valuable for climate scientists to understand societal responses. However, their vast scale, noisy digitized quality, and archaic language make it difficult to transform them into structured knowledge for climate research. To address this challenge, we introduce WeatherArchive-Bench, the first benchmark for evaluating retrieval-augmented generation (RAG) systems on historical weather archives. WeatherArchive-Bench comprises two tasks: WeatherArchive-Retrieval, which measures a system's ability to locate historically relevant passages from over one million archival news segments, and WeatherArchive-Assessment, which evaluates whether Large Language Models (LLMs) can classify societal vulnerability and resilience indicators from extreme weather narratives. Extensive experiments across sparse, dense, and re-ranking retrievers, as well as a diverse set of LLMs, reveal that dense retrievers often fail on historical terminology, while LLMs frequently misinterpret vulnerability and resilience concepts. These findings highlight key limitations in reasoning about complex societal indicators and provide insights for designing more robust climate-focused RAG systems from archival contexts. The constructed dataset and evaluation framework are publicly available at this https URL.", 'abstract_zh': '历史天气档案作为持久的一手资料集合，提供了丰富的叙事，揭示了社会各界如何经历和应对极端天气事件。这些定性的记录为气候科学家理解社会响应提供了深刻的见解，但这些见解在气象记录中几乎是不存在的，使其对气候研究具有重要价值。然而，由于其庞大的规模、嘈杂的数字化质量和古老的语言，使其难以转换为结构化的知识用于气候研究。为解决这一挑战，我们引入了WeatherArchive-Bench，这是首个用于评估检索增强生成（RAG）系统在历史天气档案应用中的基准。WeatherArchive-Bench 包含两个任务：WeatherArchive-Retrieval，评估系统从超过一百万份档案新闻片段中找到相关历史段落的能力；以及WeatherArchive-Assessment，评估大型语言模型（LLMs）是否能够从极端天气叙事中分类出社会脆弱性和韧性的指标。广泛的实验表明，密集检索器在处理历史术语时经常失败，而大型语言模型频繁错误地解释脆弱性和韧性概念。这些发现强调了在复杂社会指标推理方面的重要限制，并为从档案视角设计更为稳健的气候聚焦RAG系统提供了指导。构建的数据集和评估框架可在<此链接>公开获取。', 'title_zh': 'WeatherArchive-Bench: 基于历史天气档案的检索增强推理基准测试'}
{'arxiv_id': 'arXiv:2510.04452', 'title': 'AgentBuilder: Exploring Scaffolds for Prototyping User Experiences of Interface Agents', 'authors': 'Jenny T. Liang, Titus Barik, Jeffrey Nichols, Eldon Schoop, Ruijia Cheng', 'link': 'https://arxiv.org/abs/2510.04452', 'abstract': 'Interface agents powered by generative AI models (referred to as "agents") can automate actions based on user commands. An important aspect of developing agents is their user experience (i.e., agent experience). There is a growing need to provide scaffolds for a broader set of individuals beyond AI engineers to prototype agent experiences, since they can contribute valuable perspectives to designing agent experiences. In this work, we explore the affordances agent prototyping systems should offer by conducting a requirements elicitation study with 12 participants with varying experience with agents. We identify key activities in agent experience prototyping and the desired capabilities of agent prototyping systems. We instantiate those capabilities in the AgentBuilder design probe for agent prototyping. We conduct an in situ agent prototyping study with 14 participants using AgentBuilder to validate the design requirements and elicit insights on how developers prototype agents and what their needs are in this process.', 'abstract_zh': '由生成式AI模型驱动的界面代理（简称“代理”）可以根据用户指令自动化执行动作。开发代理的一个重要方面是其用户体验（即代理体验）。由于他们可以为设计代理体验提供有价值的视角，因此有必要为更广泛的一系列个人（不仅限于AI工程师）提供代理体验原型设计的支架。在本工作中，我们通过一项包含12名具有不同代理经验的参与者的需要获取研究，探索代理体验原型设计系统应提供的功能。我们确定了代理体验原型设计中的关键活动以及代理体验原型设计系统所需的理想能力。我们通过在AgentBuilder设计探针中实现这些能力来实现这些理想能力。我们进一步通过一项包含14名参与者并使用AgentBuilder进行的现场代理体验原型设计研究，验证设计需求并获取开发人员在这一过程中的原型设计和需求方面的洞见。', 'title_zh': 'AgentBuilder: 探索原型设计界面代理用户体验的支持结构'}
{'arxiv_id': 'arXiv:2409.15838', 'title': 'TiltXter: CNN-based Electro-tactile Rendering of Tilt Angle for Telemanipulation of Pasteur Pipettes', 'authors': 'Miguel Altamirano Cabrera, Jonathan Tirado, Aleksey Fedoseev, Oleg Sautenkov, Vladimir Poliakov, Pavel Kopanev, Dzmitry Tsetserukou', 'link': 'https://arxiv.org/abs/2409.15838', 'abstract': "The shape of deformable objects can change drastically during grasping by robotic grippers, causing an ambiguous perception of their alignment and hence resulting in errors in robot positioning and telemanipulation. Rendering clear tactile patterns is fundamental to increasing users' precision and dexterity through tactile haptic feedback during telemanipulation. Therefore, different methods have to be studied to decode the sensors' data into haptic stimuli. This work presents a telemanipulation system for plastic pipettes that consists of a Force Dimension Omega.7 haptic interface endowed with two electro-stimulation arrays and two tactile sensor arrays embedded in the 2-finger Robotiq gripper. We propose a novel approach based on convolutional neural networks (CNN) to detect the tilt of deformable objects. The CNN generates a tactile pattern based on recognized tilt data to render further electro-tactile stimuli provided to the user during the telemanipulation. The study has shown that using the CNN algorithm, tilt recognition by users increased from 23.13\\% with the downsized data to 57.9%, and the success rate during teleoperation increased from 53.12% using the downsized data to 92.18% using the tactile patterns generated by the CNN.", 'abstract_zh': '可变形物体在机器人夹爪抓取过程中形状会急剧变化，导致其对齐感知模糊，从而影响机器人定位和遥操作的准确性。清晰的触觉模式呈现对于通过触觉力反馈增加用户精确度和灵巧性至关重要。因此，需要研究不同的方法将传感器数据解码为触觉刺激。本文提出了一种用于塑料移液管的遥操作系统，该系统包括一个配备有两个电刺激阵列和两个触觉传感器阵列的Force Dimension Omega.7 力觉接口，嵌入在2指Robotiq夹爪中。我们提出了一种基于卷积神经网络（CNN）的新方法来检测可变形物体的倾斜角度。CNN根据识别到的倾斜数据生成触觉模式，以便在遥操作系统中提供进一步的电触觉刺激给用户。研究表明，使用CNN算法后，用户倾斜角度识别率从数据缩小前的23.13%提高到57.9%，遥操作系统中的成功率从使用数据缩小后的53.12%提高到使用CNN生成的触觉模式后的92.18%。', 'title_zh': 'TiltXter: 基于CNN的 Pasteur 管倾斜角度电触觉渲染技术研发'}
{'arxiv_id': 'arXiv:2204.03521', 'title': 'DeepXPalm: Tilt and Position Rendering using Palm-worn Haptic Display and CNN-based Tactile Pattern Recognition', 'authors': 'Altamirano Cabrera Miguel, Sautenkov Oleg, Tirado Jonathan, Fedoseev Aleksey, Kopanev Pavel, Kajimoto Hiroyuki, Tsetserukou Dzmitry', 'link': 'https://arxiv.org/abs/2204.03521', 'abstract': "Telemanipulation of deformable objects requires high precision and dexterity from the users, which can be increased by kinesthetic and tactile feedback. However, the object shape can change dynamically, causing ambiguous perception of its alignment and hence errors in the robot positioning. Therefore, the tilt angle and position classification problem has to be solved to present a clear tactile pattern to the user. This work presents a telemanipulation system for plastic pipettes consisting of a multi-contact haptic device LinkGlide to deliver haptic feedback at the users' palm and two tactile sensors array embedded in the 2-finger Robotiq gripper. We propose a novel approach based on Convolutional Neural Networks (CNN) to detect the tilt and position while grasping deformable objects. The CNN generates a mask based on recognized tilt and position data to render further multi-contact tactile stimuli provided to the user during the telemanipulation. The study has shown that using the CNN algorithm and the preset mask, tilt, and position recognition by users is increased from 9.67% using the direct data to 82.5%.", 'abstract_zh': '软体物体的远程操作需要用户具备高精度和灵巧性，可以通过提供动能和触觉反馈来提高。然而，物体形状会动态变化，可能导致其对齐感知的模糊，从而影响机器人定位的准确性。因此，必须解决倾斜角度和位置分类问题，以向用户提供清晰的触觉模式。本文提出了一种基于塑料吸管的远程操作系统，该系统包括一个多接触力反馈设备LinkGlide和一个嵌入在两指Robotiq夹爪中的触觉传感器阵列。我们提出了一种基于卷积神经网络（CNN）的新方法来检测抓取软体物体时的倾斜和位置。CNN根据识别到的倾斜和位置数据生成一个遮罩，以渲染远程操作过程中提供给用户的多接触触觉刺激。研究结果显示，使用CNN算法和预设遮罩后，用户对倾斜和位置的识别准确率从9.67%提高到了82.5%。', 'title_zh': 'DeepXPalm: 倾斜和位置渲染使用掌戴触觉显示和基于CNN的触觉模式识别'}
