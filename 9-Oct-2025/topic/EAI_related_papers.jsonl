{'arxiv_id': 'arXiv:2510.07181', 'title': 'TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics', 'authors': 'Yi Han, Cheng Chi, Enshen Zhou, Shanyu Rong, Jingkun An, Pengwei Wang, Zhongyuan Wang, Lu Sheng, Shanghang Zhang', 'link': 'https://arxiv.org/abs/2510.07181', 'abstract': 'Vision-Language Models (VLMs) have shown remarkable capabilities in spatial reasoning, yet they remain fundamentally limited to qualitative precision and lack the computational precision required for real-world robotics. Current approaches fail to leverage metric cues from depth sensors and camera calibration, instead reducing geometric problems to pattern recognition tasks that cannot deliver the centimeter-level accuracy essential for robotic manipulation. We present TIGeR (Tool-Integrated Geometric Reasoning), a novel framework that transforms VLMs from perceptual estimators to geometric computers by enabling them to generate and execute precise geometric computations through external tools. Rather than attempting to internalize complex geometric operations within neural networks, TIGeR empowers models to recognize geometric reasoning requirements, synthesize appropriate computational code, and invoke specialized libraries for exact calculations. To support this paradigm, we introduce TIGeR-300K, a comprehensive tool-invocation-oriented dataset covering point transformations, pose estimation, trajectory generation, and spatial compatibility verification, complete with tool invocation sequences and intermediate computations. Through a two-stage training pipeline combining supervised fine-tuning (SFT) and reinforcement fine-tuning (RFT) with our proposed hierarchical reward design, TIGeR achieves SOTA performance on geometric reasoning benchmarks while demonstrating centimeter-level precision in real-world robotic manipulation tasks.', 'abstract_zh': 'Vision-Language模型（VLMs）在空间推理方面展现了卓越的能力，但仍从根本上局限于定性的精确度，并缺乏用于实际机器人应用所需的计算精确度。当前的方法未能利用深度传感器和相机校准提供的度量线索，而是将几何问题简化为模式识别任务，这些任务无法提供机器人操作所需的高度厘米级准确性。我们提出了TIGeR（Tool-Integrated Geometric Reasoning），一种新型框架，通过使模型能够生成和执行精确的几何计算，从而将VLMs从感知估计器转变为几何计算机。TIGeR 不试图在神经网络内部化复杂的几何操作，而是使模型能够识别几何推理需求、合成合适的计算代码，并调用专门的库进行精确计算。为了支持这一范式，我们引入了TIGeR-300K数据集，该数据集涵盖了点变换、姿态估计、轨迹生成和空间兼容性验证，其中包括工具调用序列和中间计算步骤。通过结合监督微调（SFT）和强化微调（RFT），以及我们提出的分层奖励设计的两阶段训练pipeline，TIGeR 在几何推理基准测试中达到了最优性能，并在实际机器人操作任务中展示了厘米级的精确度。', 'title_zh': 'TIGeR: 工具集成几何推理在视觉-语言模型中的机器人应用'}
{'arxiv_id': 'arXiv:2510.07152', 'title': 'DPL: Depth-only Perceptive Humanoid Locomotion via Realistic Depth Synthesis and Cross-Attention Terrain Reconstruction', 'authors': 'Jingkai Sun, Gang Han, Pihai Sun, Wen Zhao, Jiahang Cao, Jiaxu Wang, Yijie Guo, Qiang Zhang', 'link': 'https://arxiv.org/abs/2510.07152', 'abstract': 'Recent advancements in legged robot perceptive locomotion have shown promising progress. However, terrain-aware humanoid locomotion remains largely constrained to two paradigms: depth image-based end-to-end learning and elevation map-based methods. The former suffers from limited training efficiency and a significant sim-to-real gap in depth perception, while the latter depends heavily on multiple vision sensors and localization systems, resulting in latency and reduced robustness. To overcome these challenges, we propose a novel framework that tightly integrates three key components: (1) Terrain-Aware Locomotion Policy with a Blind Backbone, which leverages pre-trained elevation map-based perception to guide reinforcement learning with minimal visual input; (2) Multi-Modality Cross-Attention Transformer, which reconstructs structured terrain representations from noisy depth images; (3) Realistic Depth Images Synthetic Method, which employs self-occlusion-aware ray casting and noise-aware modeling to synthesize realistic depth observations, achieving over 30\\% reduction in terrain reconstruction error. This combination enables efficient policy training with limited data and hardware resources, while preserving critical terrain features essential for generalization. We validate our framework on a full-sized humanoid robot, demonstrating agile and adaptive locomotion across diverse and challenging terrains.', 'abstract_zh': '最近在腿式机器人知觉运动方面的进展显示出有希望的进步。然而，地形感知的人形运动主要局限于两种范式：基于深度图像的端到端学习和基于高程图的方法。前者由于训练效率有限和深度感知中的显著仿真实验差距而受到影响，而后者则严重依赖多个视觉传感器和定位系统，导致延迟并降低了鲁棒性。为克服这些挑战，我们提出了一种新的框架，该框架紧密整合了三个关键组件：（1）带有盲式主干的地形感知运动策略，利用预训练的高程图感知来引导强化学习，同时提供最少的视觉输入；（2）多模态跨注意力变压器，从噪声深度图像中重构结构化的地形表示；（3）真实的深度图像合成方法，采用自遮挡感知的射线投射和噪声感知建模来合成真实的深度观测，地形重建误差降低超过30%。该组合能够在有限的数据和硬件资源下实现高效的策略训练，同时保留对于泛化至关重要的关键地形特征。我们在一个全尺寸的人形机器人上验证了该框架，展示了其在各种复杂地形上的灵活和适应性运动。', 'title_zh': 'DPL: 仅深度感知的人形机器人行走通过现实深度合成和跨注意力地形重建'}
{'arxiv_id': 'arXiv:2510.07134', 'title': 'TrackVLA++: Unleashing Reasoning and Memory Capabilities in VLA Models for Embodied Visual Tracking', 'authors': 'Jiahang Liu, Yunpeng Qi, Jiazhao Zhang, Minghan Li, Shaoan Wang, Kui Wu, Hanjing Ye, Hong Zhang, Zhibo Chen, Fangwei Zhong, Zhizheng Zhang, He Wang', 'link': 'https://arxiv.org/abs/2510.07134', 'abstract': "Embodied Visual Tracking (EVT) is a fundamental ability that underpins practical applications, such as companion robots, guidance robots and service assistants, where continuously following moving targets is essential. Recent advances have enabled language-guided tracking in complex and unstructured scenes. However, existing approaches lack explicit spatial reasoning and effective temporal memory, causing failures under severe occlusions or in the presence of similar-looking distractors. To address these challenges, we present TrackVLA++, a novel Vision-Language-Action (VLA) model that enhances embodied visual tracking with two key modules, a spatial reasoning mechanism and a Target Identification Memory (TIM). The reasoning module introduces a Chain-of-Thought paradigm, termed Polar-CoT, which infers the target's relative position and encodes it as a compact polar-coordinate token for action prediction. Guided by these spatial priors, the TIM employs a gated update strategy to preserve long-horizon target memory, ensuring spatiotemporal consistency and mitigating target loss during extended occlusions. Extensive experiments show that TrackVLA++ achieves state-of-the-art performance on public benchmarks across both egocentric and multi-camera settings. On the challenging EVT-Bench DT split, TrackVLA++ surpasses the previous leading approach by 5.1 and 12, respectively. Furthermore, TrackVLA++ exhibits strong zero-shot generalization, enabling robust real-world tracking in dynamic and occluded scenarios.", 'abstract_zh': '具身视觉跟踪（EVT）是支撑 companion 机器人、引导机器人和服务助理等实际应用的基本能力，其中连续追踪移动目标是必不可少的。近期进展使得在复杂且无结构的场景中实现语言引导的跟踪成为可能。然而，现有方法缺乏明确的空间推理和有效的时序记忆，导致在严重遮挡或存在相似干扰物的情况下出现失败。为应对这些挑战，我们提出了 TrackVLA++，这是一种具有创新性的视觉-语言-动作（VLA）模型，通过两个关键模块——空间推理机制和目标识别记忆（TIM）来增强具身视觉跟踪能力。推理模块引入了一种称为 Polar-CoT 的思维链框架，通过推断目标的相对位置并将其编码为紧凑的极坐标 tokens 来预测动作。受这些空间先验的引导，TIM 采用门控更新策略来保持长期目标记忆，确保时空一致性和在长时间遮挡期间减轻目标丢失。广泛实验表明，TrackVLA++ 在公共基准测试中在第一人称和多摄像头设置下均达到最先进的性能。在具有挑战性的 EVT-Bench DT 分割中，TrackVLA++ 分别超越之前领先的方法 5.1 和 12 分。此外，TrackVLA++ 具有强大的零样本泛化能力，可在动态和遮挡场景中实现稳健的真实世界跟踪。', 'title_zh': 'TrackVLA++: 解锁VLA模型中的推理与记忆能力以实现沉浸式视觉跟踪'}
{'arxiv_id': 'arXiv:2510.07133', 'title': 'A Digital Twin Framework for Metamorphic Testing of Autonomous Driving Systems Using Generative Model', 'authors': 'Tony Zhang, Burak Kantarci, Umair Siddique', 'link': 'https://arxiv.org/abs/2510.07133', 'abstract': "Ensuring the safety of self-driving cars remains a major challenge due to the complexity and unpredictability of real-world driving environments. Traditional testing methods face significant limitations, such as the oracle problem, which makes it difficult to determine whether a system's behavior is correct, and the inability to cover the full range of scenarios an autonomous vehicle may encounter. In this paper, we introduce a digital twin-driven metamorphic testing framework that addresses these challenges by creating a virtual replica of the self-driving system and its operating environment. By combining digital twin technology with AI-based image generative models such as Stable Diffusion, our approach enables the systematic generation of realistic and diverse driving scenes. This includes variations in weather, road topology, and environmental features, all while maintaining the core semantics of the original scenario. The digital twin provides a synchronized simulation environment where changes can be tested in a controlled and repeatable manner. Within this environment, we define three metamorphic relations inspired by real-world traffic rules and vehicle behavior. We validate our framework in the Udacity self-driving simulator and demonstrate that it significantly enhances test coverage and effectiveness. Our method achieves the highest true positive rate (0.719), F1 score (0.689), and precision (0.662) compared to baseline approaches. This paper highlights the value of integrating digital twins with AI-powered scenario generation to create a scalable, automated, and high-fidelity testing solution for autonomous vehicle safety.", 'abstract_zh': '基于数字孪生的 metamorphic 测试框架：自动驾驶汽车安全测试的新挑战与解决方案', 'title_zh': '基于生成模型的自主驾驶系统 metamorphic 测试的数字孪生框架'}
{'arxiv_id': 'arXiv:2510.07077', 'title': 'Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications', 'authors': 'Kento Kawaharazuka, Jihoon Oh, Jun Yamada, Ingmar Posner, Yuke Zhu', 'link': 'https://arxiv.org/abs/2510.07077', 'abstract': 'Amid growing efforts to leverage advances in large language models (LLMs) and vision-language models (VLMs) for robotics, Vision-Language-Action (VLA) models have recently gained significant attention. By unifying vision, language, and action data at scale, which have traditionally been studied separately, VLA models aim to learn policies that generalise across diverse tasks, objects, embodiments, and environments. This generalisation capability is expected to enable robots to solve novel downstream tasks with minimal or no additional task-specific data, facilitating more flexible and scalable real-world deployment. Unlike previous surveys that focus narrowly on action representations or high-level model architectures, this work offers a comprehensive, full-stack review, integrating both software and hardware components of VLA systems. In particular, this paper provides a systematic review of VLAs, covering their strategy and architectural transition, architectures and building blocks, modality-specific processing techniques, and learning paradigms. In addition, to support the deployment of VLAs in real-world robotic applications, we also review commonly used robot platforms, data collection strategies, publicly available datasets, data augmentation methods, and evaluation benchmarks. Throughout this comprehensive survey, this paper aims to offer practical guidance for the robotics community in applying VLAs to real-world robotic systems. All references categorized by training approach, evaluation method, modality, and dataset are available in the table on our project website: this https URL .', 'abstract_zh': '随着对利用大规模语言模型（LLMs）和视觉-语言模型（VLMs）推动机器人技术发展的努力不断增长，视觉-语言-动作（VLA）模型最近吸引了显著的关注。通过大规模统一视觉、语言和动作数据，这些模型旨在学习能够在多样化的任务、物体、代理和环境中泛化的策略。这种泛化能力有望使机器人能够通过最少或无需额外的任务特定数据来解决新的下游任务，从而促进更灵活和可扩展的实际应用部署。不同于以往专注于动作表示或高层模型架构的综述，本文提供了一种全面的端到端综述，整合了VLA系统的软件和硬件组件。特别地，本文对VLA进行了系统的回顾，涵盖了其策略和架构演变、架构和构建块、特定模态的处理技术以及学习范式。此外，为了支持VLA在实际机器人应用中的部署，本文还回顾了常用机器人平台、数据收集策略、公开可用的数据集、数据增强方法以及评估基准。在整个综合综述中，本文旨在为机器人社区在实际机器人系统中应用VLA提供实用指导。所有按训练方法、评估方法、模态和数据集分类的参考文献均在我们项目网站上的表格中提供：this https URL。', 'title_zh': '视觉-语言-行动模型在机器人领域的研究：面向实际应用的综述'}
{'arxiv_id': 'arXiv:2510.07067', 'title': 'Bring the Apple, Not the Sofa: Impact of Irrelevant Context in Embodied AI Commands on VLA Models', 'authors': 'Daria Pugacheva, Andrey Moskalenko, Denis Shepelev, Andrey Kuznetsov, Vlad Shakhuro, Elena Tutubalina', 'link': 'https://arxiv.org/abs/2510.07067', 'abstract': 'Vision Language Action (VLA) models are widely used in Embodied AI, enabling robots to interpret and execute language instructions. However, their robustness to natural language variability in real-world scenarios has not been thoroughly investigated. In this work, we present a novel systematic study of the robustness of state-of-the-art VLA models under linguistic perturbations. Specifically, we evaluate model performance under two types of instruction noise: (1) human-generated paraphrasing and (2) the addition of irrelevant context. We further categorize irrelevant contexts into two groups according to their length and their semantic and lexical proximity to robot commands. In this study, we observe consistent performance degradation as context size expands. We also demonstrate that the model can exhibit relative robustness to random context, with a performance drop within 10%, while semantically and lexically similar context of the same length can trigger a quality decline of around 50%. Human paraphrases of instructions lead to a drop of nearly 20%. To mitigate this, we propose an LLM-based filtering framework that extracts core commands from noisy inputs. Incorporating our filtering step allows models to recover up to 98.5% of their original performance under noisy conditions.', 'abstract_zh': '基于视觉-语言-动作模型在语言 perturbations 下的鲁棒性研究', 'title_zh': 'bring the apple, not the sofa: 不相关背景对 embodied AI 命令影响的研究——基于视觉语言模型的视角'}
{'arxiv_id': 'arXiv:2510.07030', 'title': 'Diffusing Trajectory Optimization Problems for Recovery During Multi-Finger Manipulation', 'authors': 'Abhinav Kumar, Fan Yang, Sergio Aguilera Marinovic, Soshi Iba, Rana Soltani Zarrin, Dmitry Berenson', 'link': 'https://arxiv.org/abs/2510.07030', 'abstract': 'Multi-fingered hands are emerging as powerful platforms for performing fine manipulation tasks, including tool use. However, environmental perturbations or execution errors can impede task performance, motivating the use of recovery behaviors that enable normal task execution to resume. In this work, we take advantage of recent advances in diffusion models to construct a framework that autonomously identifies when recovery is necessary and optimizes contact-rich trajectories to recover. We use a diffusion model trained on the task to estimate when states are not conducive to task execution, framed as an out-of-distribution detection problem. We then use diffusion sampling to project these states in-distribution and use trajectory optimization to plan contact-rich recovery trajectories. We also propose a novel diffusion-based approach that distills this process to efficiently diffuse the full parameterization, including constraints, goal state, and initialization, of the recovery trajectory optimization problem, saving time during online execution. We compare our method to a reinforcement learning baseline and other methods that do not explicitly plan contact interactions, including on a hardware screwdriver-turning task where we show that recovering using our method improves task performance by 96% and that ours is the only method evaluated that can attempt recovery without causing catastrophic task failure. Videos can be found at this https URL.', 'abstract_zh': '多指灵巧手在进行精密操作任务时正逐渐成为强大的平台，包括工具使用。然而，环境干扰或执行错误会阻碍任务性能，促使采取恢复行为以恢复正常的任务执行。在本文中，我们利用最近在扩散模型方面的进展构建了一个框架，该框架能够自主识别何时需要恢复，并优化富含接触的轨迹以进行恢复。我们使用基于任务训练的扩散模型来估计哪些状态不利于任务执行，将其作为分布外检测问题。然后，我们使用扩散采样将这些状态映射到分布内，并使用轨迹优化来规划富含接触的恢复轨迹。我们还提出了一种基于扩散的新颖方法，该方法能够高效地扩散恢复轨迹优化问题的全部参数化，包括约束、目标状态和初始化，从而在线执行时节省时间。我们将我们的方法与强化学习基线以及其他未显式规划接触交互的方法进行比较，在一个硬件螺丝刀旋转任务中，我们证明使用我们的方法进行恢复可以将任务性能提高96%，并且这是唯一一个能够尝试恢复而不导致任务灾难性失败的方法。相关视频可以在以下链接找到：这个 https URL。', 'title_zh': '多指 manipulation 过程中恢复的扩散轨迹优化问题'}
{'arxiv_id': 'arXiv:2510.06633', 'title': 'Assist-As-Needed: Adaptive Multimodal Robotic Assistance for Medication Management in Dementia Care', 'authors': 'Kruthika Gangaraju, Tanmayi Inaparthy, Jiaqi Yang, Yihao Zheng, Fengpei Yuan', 'link': 'https://arxiv.org/abs/2510.06633', 'abstract': "People living with dementia (PLWDs) face progressively declining abilities in medication management-from simple forgetfulness to complete task breakdown-yet most assistive technologies fail to adapt to these changing needs. This one-size-fits-all approach undermines autonomy, accelerates dependence, and increases caregiver burden. Occupational therapy principles emphasize matching assistance levels to individual capabilities: minimal reminders for those who merely forget, spatial guidance for those who misplace items, and comprehensive multimodal support for those requiring step-by-step instruction. However, existing robotic systems lack this adaptive, graduated response framework essential for maintaining PLWD independence. We present an adaptive multimodal robotic framework using the Pepper robot that dynamically adjusts assistance based on real-time assessment of user needs. Our system implements a hierarchical intervention model progressing from (1) simple verbal reminders, to (2) verbal + gestural cues, to (3) full multimodal guidance combining physical navigation to medication locations with step-by-step verbal and gestural instructions. Powered by LLM-driven interaction strategies and multimodal sensing, the system continuously evaluates task states to provide just-enough assistance-preserving autonomy while ensuring medication adherence. We conducted a preliminary study with healthy adults and dementia care stakeholders in a controlled lab setting, evaluating the system's usability, comprehensibility, and appropriateness of adaptive feedback mechanisms. This work contributes: (1) a theoretically grounded adaptive assistance framework translating occupational therapy principles into HRI design, (2) a multimodal robotic implementation that preserves PLWD dignity through graduated support, and (3) empirical insights into stakeholder perceptions of adaptive robotic care.", 'abstract_zh': '适应性多模态机器人框架：基于帕金森病患者认知功能变化的动态照料', 'title_zh': '按需辅助：适应性多模态机器人辅助在失智照护中的药物管理'}
{'arxiv_id': 'arXiv:2510.06566', 'title': 'Safe Obstacle-Free Guidance of Space Manipulators in Debris Removal Missions via Deep Reinforcement Learning', 'authors': 'Vincent Lam, Robin Chhabra', 'link': 'https://arxiv.org/abs/2510.06566', 'abstract': 'The objective of this study is to develop a model-free workspace trajectory planner for space manipulators using a Twin Delayed Deep Deterministic Policy Gradient (TD3) agent to enable safe and reliable debris capture. A local control strategy with singularity avoidance and manipulability enhancement is employed to ensure stable execution. The manipulator must simultaneously track a capture point on a non-cooperative target, avoid self-collisions, and prevent unintended contact with the target. To address these challenges, we propose a curriculum-based multi-critic network where one critic emphasizes accurate tracking and the other enforces collision avoidance. A prioritized experience replay buffer is also used to accelerate convergence and improve policy robustness. The framework is evaluated on a simulated seven-degree-of-freedom KUKA LBR iiwa mounted on a free-floating base in Matlab/Simulink, demonstrating safe and adaptive trajectory generation for debris removal missions.', 'abstract_zh': '本研究的目标是开发一种基于TD3代理的无模型工作空间轨迹规划器，以空间 manipulator 为对象，实现对未配合目标的碎片捕获，确保安全可靠。该计划器采用具有奇异性避免和操作性增强的局部控制策略，以确保执行的稳定性。机械臂必须同时在非配合目标上跟踪捕获点，避免自碰撞，并防止意外接触目标。为应对这些挑战，我们提出了一种基于课程的学习多评价格值网络，其中一个是强调准确跟踪，另一个是强制执行碰撞避免。同时，使用优先经验重放缓冲区以加快收敛速度并提高策略的鲁棒性。该框架在Matlab/Simulink中对一个自由浮动底座上安装的七个自由度的KUKA LBR iiwa进行了仿真评估，展示了适用于碎片清除任务的安全自适应轨迹生成能力。', 'title_zh': '基于深度强化学习的空间 manipulation 安全无障碍引导以应对碎片清除任务'}
{'arxiv_id': 'arXiv:2510.06492', 'title': "What You Don't Know Can Hurt You: How Well do Latent Safety Filters Understand Partially Observable Safety Constraints?", 'authors': 'Matthew Kim, Kensuke Nakamura, Andrea Bajcsy', 'link': 'https://arxiv.org/abs/2510.06492', 'abstract': 'Safe control techniques, such as Hamilton-Jacobi reachability, provide principled methods for synthesizing safety-preserving robot policies but typically assume hand-designed state spaces and full observability. Recent work has relaxed these assumptions via latent-space safe control, where state representations and dynamics are learned jointly through world models that reconstruct future high-dimensional observations (e.g., RGB images) from current observations and actions. This enables safety constraints that are difficult to specify analytically (e.g., spilling) to be framed as classification problems in latent space, allowing controllers to operate directly from raw observations. However, these methods assume that safety-critical features are observable in the learned latent state. We ask: when are latent state spaces sufficient for safe control? To study this, we examine temperature-based failures, comparable to overheating in cooking or manufacturing tasks, and find that RGB-only observations can produce myopic safety behaviors, e.g., avoiding seeing failure states rather than preventing failure itself. To predict such behaviors, we introduce a mutual information-based measure that identifies when observations fail to capture safety-relevant features. Finally, we propose a multimodal-supervised training strategy that shapes the latent state with additional sensory inputs during training, but requires no extra modalities at deployment, and validate our approach in simulation and on hardware with a Franka Research 3 manipulator preventing a pot of wax from overheating.', 'abstract_zh': '基于潜在状态空间的安全控制技术：以高温故障为例的研究', 'title_zh': '你不知晓的可能会对你造成伤害：潜藏的安全过滤器对部分可观测安全约束的理解程度如何？'}
{'arxiv_id': 'arXiv:2510.06481', 'title': 'Active Next-Best-View Optimization for Risk-Averse Path Planning', 'authors': 'Amirhossein Mollaei Khass, Guangyi Liu, Vivek Pandey, Wen Jiang, Boshu Lei, Kostas Daniilidis, Nader Motee', 'link': 'https://arxiv.org/abs/2510.06481', 'abstract': 'Safe navigation in uncertain environments requires planning methods that integrate risk aversion with active perception. In this work, we present a unified framework that refines a coarse reference path by constructing tail-sensitive risk maps from Average Value-at-Risk statistics on an online-updated 3D Gaussian-splat Radiance Field. These maps enable the generation of locally safe and feasible trajectories. In parallel, we formulate Next-Best-View (NBV) selection as an optimization problem on the SE(3) pose manifold, where Riemannian gradient descent maximizes an expected information gain objective to reduce uncertainty most critical for imminent motion. Our approach advances the state-of-the-art by coupling risk-averse path refinement with NBV planning, while introducing scalable gradient decompositions that support efficient online updates in complex environments. We demonstrate the effectiveness of the proposed framework through extensive computational studies.', 'abstract_zh': '在不确定环境中安全导航需要结合风险规避与主动感知的规划方法。本文提出了一种统一框架，通过构建基于在线更新的3D高斯点辐射场平均价值-at-风险统计的尾敏感风险地图来细化粗参考路径。这些地图能够生成局部安全且可行的轨迹。同时，我们将最佳视图（NBV）选择形式化为SE(3)姿态流形上的优化问题，其中刘维尔梯度下降最大化预期信息增益目标，以减少即将发生的运动中最为关键的不确定性。我们的方法通过将风险规避路径细化与NBV规划耦合，并引入可扩展的梯度分解，支持复杂环境中高效的在线更新，从而超越了现有技术。我们通过广泛的眼动计算研究展示了所提出框架的有效性。', 'title_zh': '风险规避路径规划中的主动下一个最佳视图优化'}
{'arxiv_id': 'arXiv:2510.06357', 'title': 'Constrained Natural Language Action Planning for Resilient Embodied Systems', 'authors': 'Grayson Byrd, Corban Rivera, Bethany Kemp, Meghan Booker, Aurora Schmidt, Celso M de Melo, Lalithkumar Seenivasan, Mathias Unberath', 'link': 'https://arxiv.org/abs/2510.06357', 'abstract': 'Replicating human-level intelligence in the execution of embodied tasks remains challenging due to the unconstrained nature of real-world environments. Novel use of large language models (LLMs) for task planning seeks to address the previously intractable state/action space of complex planning tasks, but hallucinations limit their reliability, and thus, viability beyond a research context. Additionally, the prompt engineering required to achieve adequate system performance lacks transparency, and thus, repeatability. In contrast to LLM planning, symbolic planning methods offer strong reliability and repeatability guarantees, but struggle to scale to the complexity and ambiguity of real-world tasks. We introduce a new robotic planning method that augments LLM planners with symbolic planning oversight to improve reliability and repeatability, and provide a transparent approach to defining hard constraints with considerably stronger clarity than traditional prompt engineering. Importantly, these augmentations preserve the reasoning capabilities of LLMs and retain impressive generalization in open-world environments. We demonstrate our approach in simulated and real-world environments. On the ALFWorld planning benchmark, our approach outperforms current state-of-the-art methods, achieving a near-perfect 99% success rate. Deployment of our method to a real-world quadruped robot resulted in 100% task success compared to 50% and 30% for pure LLM and symbolic planners across embodied pick and place tasks. Our approach presents an effective strategy to enhance the reliability, repeatability and transparency of LLM-based robot planners while retaining their key strengths: flexibility and generalizability to complex real-world environments. We hope that this work will contribute to the broad goal of building resilient embodied intelligent systems.', 'abstract_zh': '在执行实体任务中复制人类级智能依然具有挑战性，因为现实世界环境具有未受约束的特性。将大型语言模型（LLMs）新颖地用于任务规划旨在解决复杂规划任务之前无法解决的状态/动作空间问题，但幻觉限制了其可靠性，从而使其在研究之外的有效性受到限制。此外，为了获得足够的系统性能所需的提示工程缺乏透明度，因此缺乏可重复性。与LLM规划不同，符号规划方法提供了强大的可靠性和可重复性保证，但难以应对真实世界任务的复杂性和模糊性。我们提出了一种新的机器人规划方法，通过将符号规划监督与LLM规划相结合来提高可靠性和可重复性，并提供了一种定义硬约束的透明方法，其清晰度远胜于传统提示工程。重要的是，这些增强保持了LLM的推理能力，并在开放世界环境中保留了出色的泛化能力。我们在模拟和真实世界环境中展示了我们的方法。在ALFWorld规划基准测试中，我们的方法超过了当前最先进的方法，实现了接近完美的99%成功率。将我们的方法部署到实际的四足机器人上，在抓取和放置任务中，其任务成功率达到了100%，而纯LLM和符号规划者分别为50%和30%。我们的方法提供了一种有效策略，以增强基于LLM的机器人规划者的可靠性和可重复性，同时保留其关键优势：灵活性和对复杂真实世界环境的泛化能力。我们希望这项工作能为构建更具韧性的体感智能系统做出贡献。', 'title_zh': '受约束的自然语言行动规划以实现稳健的体执行系统'}
{'arxiv_id': 'arXiv:2510.06339', 'title': 'Vi-TacMan: Articulated Object Manipulation via Vision and Touch', 'authors': 'Leiyao Cui, Zihang Zhao, Sirui Xie, Wenhuan Zhang, Zhi Han, Yixin Zhu', 'link': 'https://arxiv.org/abs/2510.06339', 'abstract': 'Autonomous manipulation of articulated objects remains a fundamental challenge for robots in human environments. Vision-based methods can infer hidden kinematics but can yield imprecise estimates on unfamiliar objects. Tactile approaches achieve robust control through contact feedback but require accurate initialization. This suggests a natural synergy: vision for global guidance, touch for local precision. Yet no framework systematically exploits this complementarity for generalized articulated manipulation. Here we present Vi-TacMan, which uses vision to propose grasps and coarse directions that seed a tactile controller for precise execution. By incorporating surface normals as geometric priors and modeling directions via von Mises-Fisher distributions, our approach achieves significant gains over baselines (all p<0.0001). Critically, manipulation succeeds without explicit kinematic models -- the tactile controller refines coarse visual estimates through real-time contact regulation. Tests on more than 50,000 simulated and diverse real-world objects confirm robust cross-category generalization. This work establishes that coarse visual cues suffice for reliable manipulation when coupled with tactile feedback, offering a scalable paradigm for autonomous systems in unstructured environments.', 'abstract_zh': '基于视觉与触觉的自适应物体 manipulation：细粒度执行的全局引导与局部精控', 'title_zh': 'Vi-TacMan: 通过视觉和触觉进行articulated对象操作'}
{'arxiv_id': 'arXiv:2510.07313', 'title': 'WristWorld: Generating Wrist-Views via 4D World Models for Robotic Manipulation', 'authors': 'Zezhong Qian, Xiaowei Chi, Yuming Li, Shizun Wang, Zhiyuan Qin, Xiaozhu Ju, Sirui Han, Shanghang Zhang', 'link': 'https://arxiv.org/abs/2510.07313', 'abstract': 'Wrist-view observations are crucial for VLA models as they capture fine-grained hand-object interactions that directly enhance manipulation performance. Yet large-scale datasets rarely include such recordings, resulting in a substantial gap between abundant anchor views and scarce wrist views. Existing world models cannot bridge this gap, as they require a wrist-view first frame and thus fail to generate wrist-view videos from anchor views alone. Amid this gap, recent visual geometry models such as VGGT emerge with geometric and cross-view priors that make it possible to address extreme viewpoint shifts. Inspired by these insights, we propose WristWorld, the first 4D world model that generates wrist-view videos solely from anchor views. WristWorld operates in two stages: (i) Reconstruction, which extends VGGT and incorporates our Spatial Projection Consistency (SPC) Loss to estimate geometrically consistent wrist-view poses and 4D point clouds; (ii) Generation, which employs our video generation model to synthesize temporally coherent wrist-view videos from the reconstructed perspective. Experiments on Droid, Calvin, and Franka Panda demonstrate state-of-the-art video generation with superior spatial consistency, while also improving VLA performance, raising the average task completion length on Calvin by 3.81% and closing 42.4% of the anchor-wrist view gap.', 'abstract_zh': '腕视图观察对于VLA模型至关重要，因为它们捕捉到精细的手-object交互，直接提升了操作表现。然而，大规模数据集很少包含此类记录，导致丰富锚视图与稀缺腕视图之间存在巨大差距。现有世界模型无法弥合这一差距，因为它们需要腕视图初始帧，从而无法仅从锚视图生成腕视图视频。在此差距中，最近的视觉几何模型如VGGT凭借几何先验和跨视图先验，使得应对极端视角转换成为可能。受此启发，我们提出了WristWorld，这是首个仅从锚视图生成腕视图视频的4D世界模型。WristWorld分为两个阶段：(i) 重构阶段，该阶段扩展了VGGT并结合了我们的空间投影一致性（SPC）损失以估计几何上一致的腕视图姿态和4D点云；(ii) 生成阶段，该阶段使用我们的视频生成模型从重构视点合成时空连贯的腕视图视频。实验在Droid、Calvin和Franka Panda上展示了最先进的视频生成，具有优越的空间一致性，同时提升了VLA性能，提高了Calvin上任务平均完成长度3.81%，并关闭了42.4%的锚视图-腕视图差距。', 'title_zh': '腕部世界：通过4D世界模型生成腕部视角以实现机器人 manipulation'}
{'arxiv_id': 'arXiv:2510.07151', 'title': 'ELMUR: External Layer Memory with Update/Rewrite for Long-Horizon RL', 'authors': 'Egor Cherepanov, Alexey K. Kovalev, Aleksandr I. Panov', 'link': 'https://arxiv.org/abs/2510.07151', 'abstract': 'Real-world robotic agents must act under partial observability and long horizons, where key cues may appear long before they affect decision making. However, most modern approaches rely solely on instantaneous information, without incorporating insights from the past. Standard recurrent or transformer models struggle with retaining and leveraging long-term dependencies: context windows truncate history, while naive memory extensions fail under scale and sparsity. We propose ELMUR (External Layer Memory with Update/Rewrite), a transformer architecture with structured external memory. Each layer maintains memory embeddings, interacts with them via bidirectional cross-attention, and updates them through an Least Recently Used (LRU) memory module using replacement or convex blending. ELMUR extends effective horizons up to 100,000 times beyond the attention window and achieves a 100% success rate on a synthetic T-Maze task with corridors up to one million steps. In POPGym, it outperforms baselines on more than half of the tasks. On MIKASA-Robo sparse-reward manipulation tasks with visual observations, it nearly doubles the performance of strong baselines. These results demonstrate that structured, layer-local external memory offers a simple and scalable approach to decision making under partial observability.', 'abstract_zh': '基于外部层次记忆更新/重写的真实世界机器人代理超越观察极限的Transformer架构', 'title_zh': 'ELMUR：用于长期展望RL的外部层记忆更新/重写方法'}
{'arxiv_id': 'arXiv:2510.07092', 'title': 'Generative World Modelling for Humanoids: 1X World Model Challenge Technical Report', 'authors': 'Riccardo Mereu, Aidan Scannell, Yuxin Hou, Yi Zhao, Aditya Jitta, Antonio Dominguez, Luigi Acerbi, Amos Storkey, Paul Chang', 'link': 'https://arxiv.org/abs/2510.07092', 'abstract': 'World models are a powerful paradigm in AI and robotics, enabling agents to reason about the future by predicting visual observations or compact latent states. The 1X World Model Challenge introduces an open-source benchmark of real-world humanoid interaction, with two complementary tracks: sampling, focused on forecasting future image frames, and compression, focused on predicting future discrete latent codes. For the sampling track, we adapt the video generation foundation model Wan-2.2 TI2V-5B to video-state-conditioned future frame prediction. We condition the video generation on robot states using AdaLN-Zero, and further post-train the model using LoRA. For the compression track, we train a Spatio-Temporal Transformer model from scratch. Our models achieve 23.0 dB PSNR in the sampling task and a Top-500 CE of 6.6386 in the compression task, securing 1st place in both challenges.', 'abstract_zh': '世界模型是AI和机器人领域的强大范式，使智能体能够通过预测视觉观察或紧凑的潜状态来推理未来。1X世界模型挑战引入了一个开源的现实世界类人交互基准，包含两个互补的赛道：采样，专注于预测未来的图像帧；压缩，专注于预测未来的离散潜代码。在采样赛道中，我们使用Wan-2.2 TI2V-5B视频生成基础模型，并将其适应于基于机器人状态的未来帧预测。我们使用AdaLN-Zero条件化视频生成，并进一步使用LoRA对模型进行后训练。在压缩赛道中，我们从零开始训练一个时空变换器模型。我们的模型在采样任务中达到23.0 dB的PSNR，在压缩任务中获得Top-500 CE 6.6386的成绩，分别获得两个挑战的第一名。', 'title_zh': 'humanoid生成世界建模：1X世界模型挑战技术报告'}
{'arxiv_id': 'arXiv:2510.06470', 'title': 'Terrain-Aided Navigation Using a Point Cloud Measurement Sensor', 'authors': 'Abdülbaki Şanlan, Fatih Erol, Murad Abu-Khalaf, Emre Koyuncu', 'link': 'https://arxiv.org/abs/2510.06470', 'abstract': 'We investigate the use of a point cloud measurement in terrain-aided navigation. Our goal is to aid an inertial navigation system, by exploring ways to generate a useful measurement innovation error for effective nonlinear state estimation. We compare two such measurement models that involve the scanning of a digital terrain elevation model: a) one that is based on typical ray-casting from a given pose, that returns the predicted point cloud measurement from that pose, and b) another computationally less intensive one that does not require raycasting and we refer to herein as a sliding grid. Besides requiring a pose, it requires the pattern of the point cloud measurement itself and returns a predicted point cloud measurement. We further investigate the observability properties of the altitude for both measurement models. As a baseline, we compare the use of a point cloud measurement performance to the use of a radar altimeter and show the gains in accuracy. We conclude by showing that a point cloud measurement outperforms the use of a radar altimeter, and the point cloud measurement model to use depends on the computational resources', 'abstract_zh': '基于地形辅助导航中点云测量的应用研究：一种提高非线性状态估计有效性的测量创新误差方法探讨', 'title_zh': '基于点云测量传感器的地形辅助导航'}
{'arxiv_id': 'arXiv:2510.07117', 'title': 'The Contingencies of Physical Embodiment Allow for Open-Endedness and Care', 'authors': "Leonardo Christov-Moore, Arthur Juliani, Alex Kiefer, Nicco Reggente, B. Scott Rousse, Adam Safron, Nicol'as Hinrichs, Daniel Polani, Antonio Damasio", 'link': 'https://arxiv.org/abs/2510.07117', 'abstract': "Physical vulnerability and mortality are often seen as obstacles to be avoided in the development of artificial agents, which struggle to adapt to open-ended environments and provide aligned care. Meanwhile, biological organisms survive, thrive, and care for each other in an open-ended physical world with relative ease and efficiency. Understanding the role of the conditions of life in this disparity can aid in developing more robust, adaptive, and caring artificial agents. Here we define two minimal conditions for physical embodiment inspired by the existentialist phenomenology of Martin Heidegger: being-in-the-world (the agent is a part of the environment) and being-towards-death (unless counteracted, the agent drifts toward terminal states due to the second law of thermodynamics). We propose that from these conditions we can obtain both a homeostatic drive - aimed at maintaining integrity and avoiding death by expending energy to learn and act - and an intrinsic drive to continue to do so in as many ways as possible. Drawing inspiration from Friedrich Nietzsche's existentialist concept of will-to-power, we examine how intrinsic drives to maximize control over future states, e.g., empowerment, allow agents to increase the probability that they will be able to meet their future homeostatic needs, thereby enhancing their capacity to maintain physical integrity. We formalize these concepts within a reinforcement learning framework, which enables us to examine how intrinsically driven embodied agents learning in open-ended multi-agent environments may cultivate the capacities for open-endedness and this http URL", 'abstract_zh': '物理脆弱性和死亡率往往被视为在开发人工代理过程中需避免的障碍，这些代理难以适应开放环境并提供一致性的关怀。与此同时，生物有机体能够相对容易和高效地在开放物理世界中生存、繁盛并相互照顾。理解这种差异中的生活条件作用有助于开发出更为 robust、适应性强且富有关怀的人工代理。在此基础上，我们受到马丁·海德格尔存在主义现象学的启发，定义了两种基本的物理具身条件：在世之物（代理是环境的一部分）和死亡之趋近（除非受阻，代理会因热力学第二定律而向终结状态趋近）。我们提出，从这些条件出发，可以获取一种稳态驱动——旨在维持完整性并避免死亡，通过耗散能量来学习和行动——以及一种内在驱动力，使其尽可能以多种方式持续这么做。借鉴弗里德里希·尼采的存在主义概念“权力意志”，我们探讨了内在驱动力最大化对未来状态的控制（例如，赋权），如何使代理增加其满足未来稳态需求的可能性，从而增强其维持物理完整性的能力。我们在这类概念中采用强化学习框架进行正式化，使我们能够探究内在驱动的具身代理在开放多代理环境中的学习如何培养开放性和相关能力。', 'title_zh': '物理 embodimen 的偶然性允许开放性和关怀'}
{'arxiv_id': 'arXiv:2510.06288', 'title': 'BuilderBench -- A benchmark for generalist agents', 'authors': 'Raj Ghugare, Catherine Ji, Kathryn Wantlin, Jin Schofield, Benjamin Eysenbach', 'link': 'https://arxiv.org/abs/2510.06288', 'abstract': "Today's AI models learn primarily through mimicry and sharpening, so it is not surprising that they struggle to solve problems beyond the limits set by existing data. To solve novel problems, agents should acquire skills for exploring and learning through experience. Finding a scalable learning mechanism for developing agents that learn through interaction remains a major open problem. In this work, we introduce BuilderBench, a benchmark to accelerate research into agent pre-training that centers open-ended exploration. BuilderBench requires agents to learn how to build any structure using blocks. BuilderBench is equipped with $(1)$ a hardware accelerated simulator of a robotic agent interacting with various physical blocks, and $(2)$ a task-suite with over 42 diverse target structures that are carefully curated to test an understanding of physics, mathematics, and long-horizon planning. During training, agents have to explore and learn general principles about the environment without any external supervision. During evaluation, agents have to build the unseen target structures from the task suite. Solving these tasks requires a sort of \\emph{embodied reasoning} that is not reflected in words but rather in actions, experimenting with different strategies and piecing them together. Our experiments show that many of these tasks challenge the current iteration of algorithms. Hence, we also provide a ``training wheels'' protocol, in which agents are trained and evaluated to build a single target structure from the task suite. Finally, we provide single-file implementations of six different algorithms as a reference point for researchers.", 'abstract_zh': '今天的AI模型主要通过模仿和精炼来学习，因此它们难以解决超出现有数据限制的问题也就不足为奇了。为了解决新型问题，代理应该获得通过经验探索和学习的技能。寻找一种可扩展的学习机制来培养通过互动学习的代理仍然是一个主要开放问题。在本工作中，我们介绍了BuilderBench这一基准，以加速专注于开放式探索的代理预训练研究。BuilderBench要求代理学习如何使用积木构建任何结构。（1）配备硬件加速的机器人代理与各种物理积木交互的模拟器；（2）包含超过42个精心筛选的多样化目标结构的任务套件，用于测试对物理、数学和远期规划的理解。在训练阶段，代理需要在没有外部监督的情况下探索和学习关于环境的一般原则。在评估阶段，代理需要从任务套件中构建未见过的目标结构。解决这些任务需要一种体现在行动中的“具身推理”，而不仅仅是语言。我们的实验表明，这些任务挑战了当前算法的迭代。因此，我们还提供了一个“训练轮”协议，其中代理被训练和评估以构建任务套件中的单个目标结构。最后，我们提供了六种不同算法的单文件实现，以供研究人员参考。', 'title_zh': 'BuilderBench —— 通用型代理的基准测试'}
{'arxiv_id': 'arXiv:2510.06540', 'title': 'Scalable Policy-Based RL Algorithms for POMDPs', 'authors': 'Ameya Anjarlekar, Rasoul Etesami, R Srikant', 'link': 'https://arxiv.org/abs/2510.06540', 'abstract': 'The continuous nature of belief states in POMDPs presents significant computational challenges in learning the optimal policy. In this paper, we consider an approach that solves a Partially Observable Reinforcement Learning (PORL) problem by approximating the corresponding POMDP model into a finite-state Markov Decision Process (MDP) (called Superstate MDP). We first derive theoretical guarantees that improve upon prior work that relate the optimal value function of the transformed Superstate MDP to the optimal value function of the original POMDP. Next, we propose a policy-based learning approach with linear function approximation to learn the optimal policy for the Superstate MDP. Consequently, our approach shows that a POMDP can be approximately solved using TD-learning followed by Policy Optimization by treating it as an MDP, where the MDP state corresponds to a finite history. We show that the approximation error decreases exponentially with the length of this history. To the best of our knowledge, our finite-time bounds are the first to explicitly quantify the error introduced when applying standard TD learning to a setting where the true dynamics are not Markovian.', 'abstract_zh': 'POMDP中信念状态的连续性给最优策略的学习带来了显著的计算挑战。本文考虑了一种通过将相应的POMDP模型近似为有限状态马尔科夫决策过程（MDP）（称为超状态MDP）来解决部分可观测强化学习（PORL）问题的方法。首先，我们推导出理论保证，改进了先前将转换后的超状态MDP的最优值函数与其原始POMDP的最优值函数之间的关系的工作。接着，我们提出了一种基于策略的学习方法，使用线性函数逼近来学习超状态MDP的最优策略。因此，我们的方法表明，可以将POMDP近似为MDP，使用TD学习和策略优化进行求解，其中MDP状态对应于有限的历史记录。我们展示了该近似误差随着历史记录长度的增加呈指数级减少。据我们所知，我们的有限时间边界是首次明确量化标准TD学习应用于非马尔可夫性真实动力学环境时引入的误差。', 'title_zh': '基于策略的可扩展POMDPs RL算法'}
{'arxiv_id': 'arXiv:2510.06260', 'title': 'Ensemble Deep Learning and LLM-Assisted Reporting for Automated Skin Lesion Diagnosis', 'authors': 'Sher Khan, Raz Muhammad, Adil Hussain, Muhammad Sajjad, Muhammad Rashid', 'link': 'https://arxiv.org/abs/2510.06260', 'abstract': 'Cutaneous malignancies demand early detection for favorable outcomes, yet current diagnostics suffer from inter-observer variability and access disparities. While AI shows promise, existing dermatological systems are limited by homogeneous architectures, dataset biases across skin tones, and fragmented approaches that treat natural language processing as separate post-hoc explanations rather than integral to clinical decision-making. We introduce a unified framework that fundamentally reimagines AI integration for dermatological diagnostics through two synergistic innovations. First, a purposefully heterogeneous ensemble of architecturally diverse convolutional neural networks provides complementary diagnostic perspectives, with an intrinsic uncertainty mechanism flagging discordant cases for specialist review -- mimicking clinical best practices. Second, we embed large language model capabilities directly into the diagnostic workflow, transforming classification outputs into clinically meaningful assessments that simultaneously fulfill medical documentation requirements and deliver patient-centered education. This seamless integration generates structured reports featuring precise lesion characterization, accessible diagnostic reasoning, and actionable monitoring guidance -- empowering patients to recognize early warning signs between visits. By addressing both diagnostic reliability and communication barriers within a single cohesive system, our approach bridges the critical translational gap that has prevented previous AI implementations from achieving clinical impact. The framework represents a significant advancement toward deployable dermatological AI that enhances diagnostic precision while actively supporting the continuum of care from initial detection through patient education, ultimately improving early intervention rates for skin lesions.', 'abstract_zh': '皮肤恶性肿瘤需要早期检测以获得有利的治疗结果，但当前的诊断方法存在观察者间差异和获取不均的问题。尽管人工智能显示出潜力，现有的皮肤病诊断系统受限于同质化的架构、跨肤色数据集偏差以及将自然语言处理分离出临床决策过程的做法。我们提出了一种统一框架，从根本上重新设想了人工智能在皮肤病诊断中的集成，通过两种协同创新实现。首先，一组旨在异质的、架构多样的卷积神经网络提供了互补的诊断视角，并内置不确定性机制将存在分歧的病例标记给专家复审，模拟临床最佳实践。其次，我们直接将大型语言模型的能力嵌入诊断流程中，将分类输出转化为具有医疗记录要求和患者中心 Educate 成分的临床意义评估。这一无缝集成生成了包含精准病损表征、易懂诊断推理和可操作监测指导的结构化报告，使患者能够在就诊间识别早期预警信号。通过在一个统一系统中解决诊断可靠性和沟通障碍，我们的方法填补了之前人工智能实施未能实现临床影响的关键鸿沟。该框架代表了通往可部署皮肤病人工智能的重要进展，该人工智能不仅能提高诊断精准度，还能积极支持从初始检测到患者教育的整个治疗进程，最终提高皮肤病变早期干预率。', 'title_zh': '集成深度学习与大语言模型辅助报告的皮肤病变自动诊断'}
{'arxiv_id': 'arXiv:2510.04452', 'title': 'AgentBuilder: Exploring Scaffolds for Prototyping User Experiences of Interface Agents', 'authors': 'Jenny T. Liang, Titus Barik, Jeffrey Nichols, Eldon Schoop, Ruijia Cheng', 'link': 'https://arxiv.org/abs/2510.04452', 'abstract': 'Interface agents powered by generative AI models (referred to as "agents") can automate actions based on user commands. An important aspect of developing agents is their user experience (i.e., agent experience). There is a growing need to provide scaffolds for a broader set of individuals beyond AI engineers to prototype agent experiences, since they can contribute valuable perspectives to designing agent experiences. In this work, we explore the affordances agent prototyping systems should offer by conducting a requirements elicitation study with 12 participants with varying experience with agents. We identify key activities in agent experience prototyping and the desired capabilities of agent prototyping systems. We instantiate those capabilities in the AgentBuilder design probe for agent prototyping. We conduct an in situ agent prototyping study with 14 participants using AgentBuilder to validate the design requirements and elicit insights on how developers prototype agents and what their needs are in this process.', 'abstract_zh': '由生成式AI模型驱动的界面代理（简称“代理”）可以根据用户指令自动化执行动作。开发代理的一个重要方面是其用户体验（即代理体验）。由于他们可以为设计代理体验提供有价值的视角，因此有必要为更广泛的一系列个人（不仅限于AI工程师）提供代理体验原型设计的支架。在本工作中，我们通过一项包含12名具有不同代理经验的参与者的需要获取研究，探索代理体验原型设计系统应提供的功能。我们确定了代理体验原型设计中的关键活动以及代理体验原型设计系统所需的理想能力。我们通过在AgentBuilder设计探针中实现这些能力来实现这些理想能力。我们进一步通过一项包含14名参与者并使用AgentBuilder进行的现场代理体验原型设计研究，验证设计需求并获取开发人员在这一过程中的原型设计和需求方面的洞见。', 'title_zh': 'AgentBuilder: 探索原型设计界面代理用户体验的支持结构'}
