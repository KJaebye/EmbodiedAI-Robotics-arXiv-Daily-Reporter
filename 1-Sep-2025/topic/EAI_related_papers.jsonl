{'arxiv_id': 'arXiv:2508.21690', 'title': 'Can a mobile robot learn from a pedestrian model to prevent the sidewalk salsa?', 'authors': 'Olger Siebinga, David Abbink', 'link': 'https://arxiv.org/abs/2508.21690', 'abstract': 'Pedestrians approaching each other on a sidewalk sometimes end up in an awkward interaction known as the "sidewalk salsa": they both (repeatedly) deviate to the same side to avoid a collision. This provides an interesting use case to study interactions between pedestrians and mobile robots because, in the vast majority of cases, this phenomenon is avoided through a negotiation based on implicit communication. Understanding how it goes wrong and how pedestrians end up in the sidewalk salsa will therefore provide insight into the implicit communication. This understanding can be used to design safe and acceptable robotic behaviour. In a previous attempt to gain this understanding, a model of pedestrian behaviour based on the Communication-Enabled Interaction (CEI) framework was developed that can replicate the sidewalk salsa. However, it is unclear how to leverage this model in robotic planning and decision-making since it violates the assumptions of game theory, a much-used framework in planning and decision-making. Here, we present a proof-of-concept for an approach where a Reinforcement Learning (RL) agent leverages the model to learn how to interact with pedestrians. The results show that a basic RL agent successfully learned to interact with the CEI model. Furthermore, a risk-averse RL agent that had access to the perceived risk of the CEI model learned how to effectively communicate its intention through its motion and thereby substantially lowered the perceived risk, and displayed effort by the modelled pedestrian. These results show this is a promising approach and encourage further exploration.', 'abstract_zh': '基于行人行为模型的强化学习方法探究：从侧面瓦萨尔到安全机器人交互', 'title_zh': '移动机器人能否从行人模型中学习以防止人行道桑巴舞？'}
{'arxiv_id': 'arXiv:2508.21501', 'title': 'Few-Shot Neuro-Symbolic Imitation Learning for Long-Horizon Planning and Acting', 'authors': 'Pierrick Lorang, Hong Lu, Johannes Huemer, Patrik Zips, Matthias Scheutz', 'link': 'https://arxiv.org/abs/2508.21501', 'abstract': 'Imitation learning enables intelligent systems to acquire complex behaviors with minimal supervision. However, existing methods often focus on short-horizon skills, require large datasets, and struggle to solve long-horizon tasks or generalize across task variations and distribution shifts. We propose a novel neuro-symbolic framework that jointly learns continuous control policies and symbolic domain abstractions from a few skill demonstrations. Our method abstracts high-level task structures into a graph, discovers symbolic rules via an Answer Set Programming solver, and trains low-level controllers using diffusion policy imitation learning. A high-level oracle filters task-relevant information to focus each controller on a minimal observation and action space. Our graph-based neuro-symbolic framework enables capturing complex state transitions, including non-spatial and temporal relations, that data-driven learning or clustering techniques often fail to discover in limited demonstration datasets. We validate our approach in six domains that involve four robotic arms, Stacking, Kitchen, Assembly, and Towers of Hanoi environments, and a distinct Automated Forklift domain with two environments. The results demonstrate high data efficiency with as few as five skill demonstrations, strong zero- and few-shot generalizations, and interpretable decision making.', 'abstract_zh': '模仿学习使智能系统能够在最少监督的情况下获得复杂行为。然而，现有方法往往专注于短期技能，需要大量数据集，并且难以解决长期任务或在任务变化和分布偏移的情况下泛化。我们提出了一种新的神经符号框架，该框架可以从少数技能示范中联合学习连续控制策略和符号领域抽象。该方法将高层任务结构抽象为图，并通过Answer Set Programming求解器发现符号规则，使用弥散策略模仿学习训练低层控制器。高层先验过滤任务相关信息，使每个控制器专注于最小的观测和行动空间。基于图的神经符号框架能够捕捉复杂的状态转换，包括非空间关系和时间关系，而数据驱动的学习或聚类技术在有限的示范数据集中往往难以发现这些关系。我们在涉及四个机器人手臂、堆积、厨房、装配和汉诺塔环境以及一个独特的自动叉车领域的六个领域中验证了我们的方法。结果表明，即使只有五个技能示范，也能实现高数据效率、强大的零样本和少样本泛化以及可解释的决策制定。', 'title_zh': '少量样本神经符号模仿学习：长时规划与执行'}
{'arxiv_id': 'arXiv:2508.21455', 'title': 'Assessing Human Cooperation for Enhancing Social Robot Navigation', 'authors': 'Hariharan Arunachalam, Phani Teja Singamaneni, Rachid Alami', 'link': 'https://arxiv.org/abs/2508.21455', 'abstract': "Socially aware robot navigation is a planning paradigm where the robot navigates in human environments and tries to adhere to social constraints while interacting with the humans in the scene. These navigation strategies were further improved using human prediction models, where the robot takes the potential future trajectory of humans while computing its own. Though these strategies significantly improve the robot's behavior, it faces difficulties from time to time when the human behaves in an unexpected manner. This happens as the robot fails to understand human intentions and cooperativeness, and the human does not have a clear idea of what the robot is planning to do. In this paper, we aim to address this gap through effective communication at an appropriate time based on a geometric analysis of the context and human cooperativeness in head-on crossing scenarios. We provide an assessment methodology and propose some evaluation metrics that could distinguish a cooperative human from a non-cooperative one. Further, we also show how geometric reasoning can be used to generate appropriate verbal responses or robot actions.", 'abstract_zh': '基于社会意识的机器人导航是一种规划范式，机器人在人类环境中导航并尝试在与场景中的人类互动时遵守社会约束。通过使用人类预测模型进一步改进了这些导航策略，机器人在计算自身路径时会考虑到未来人类的潜在轨迹。尽管这些策略显著提高了机器人的行为表现，但它在人类表现出意外行为时有时会遇到困难。这种情况的发生是因为机器人无法理解人类的意图和合作性，而人类也不清楚机器人计划做什么。本文旨在通过基于几何分析的上下文和人类合作性进行有效沟通来解决这一问题，特别是在迎面 crossing 情景下。我们提供了一种评估方法并提出了一些评价指标，以区分合作的人类和不合作的人类。此外，我们还展示了如何通过几何推理生成适当的口头回应或机器人动作。', 'title_zh': '评估人类合作以提高社会机器人导航能力'}
{'arxiv_id': 'arXiv:2508.21364', 'title': 'Multi-Modal Model Predictive Path Integral Control for Collision Avoidance', 'authors': 'Alberto Bertipaglia, Dariu M. Gavrila, Barys Shyrokau', 'link': 'https://arxiv.org/abs/2508.21364', 'abstract': 'This paper proposes a novel approach to motion planning and decision-making for automated vehicles, using a multi-modal Model Predictive Path Integral control algorithm. The method samples with Sobol sequences around the prior input and incorporates analytical solutions for collision avoidance. By leveraging multiple modes, the multi-modal control algorithm explores diverse trajectories, such as manoeuvring around obstacles or stopping safely before them, mitigating the risk of sub-optimal solutions. A non-linear single-track vehicle model with a Fiala tyre serves as the prediction model, and tyre force constraints within the friction circle are enforced to ensure vehicle stability during evasive manoeuvres. The optimised steering angle and longitudinal acceleration are computed to generate a collision-free trajectory and to control the vehicle. In a high-fidelity simulation environment, we demonstrate that the proposed algorithm can successfully avoid obstacles, keeping the vehicle stable while driving a double lane change manoeuvre on high and low-friction road surfaces and occlusion scenarios with moving obstacles, outperforming a standard Model Predictive Path Integral approach.', 'abstract_zh': '本文提出了一种用于自动车辆运动规划和决策的新方法，采用多模式模型预测路径积分控制算法。该方法利用Sobol序列对先验输入进行采样，并结合碰撞避免的解析解。通过利用多种模式，多模式控制算法探索多样化的轨迹，如绕过障碍物或在障碍物前安全停车，从而减轻次优解的风险。采用带有Fiala轮胎的非线性单通道车辆模型作为预测模型，在摩擦圆内的轮胎力约束确保了在避让机动过程中车辆的稳定性。优化的转向角和纵向加速度被计算以生成无碰撞轨迹并控制车辆。在高保真仿真环境中，证明了所提出的算法能够成功避开障碍物，在高摩擦和低摩擦路面以及移动障碍物遮挡场景下进行双车道变换机动时保持车辆稳定，且表现优于标准的模型预测路径积分方法。', 'title_zh': '多模态模型预测路径积分控制以实现避障'}
{'arxiv_id': 'arXiv:2508.21322', 'title': 'Robust Real-Time Coordination of CAVs: A Distributed Optimization Framework under Uncertainty', 'authors': 'Haojie Bai, Yang Wang, Cong Guo, Xiongwei Zhao, Hai Zhu', 'link': 'https://arxiv.org/abs/2508.21322', 'abstract': "Achieving both safety guarantees and real-time performance in cooperative vehicle coordination remains a fundamental challenge, particularly in dynamic and uncertain environments. This paper presents a novel coordination framework that resolves this challenge through three key innovations: 1) direct control of vehicles' trajectory distributions during coordination, formulated as a robust cooperative planning problem with adaptive enhanced safety constraints, ensuring a specified level of safety regarding the uncertainty of the interactive trajectory, 2) a fully parallel ADMM-based distributed trajectory negotiation (ADMM-DTN) algorithm that efficiently solves the optimization problem while allowing configurable negotiation rounds to balance solution quality and computational resources, and 3) an interactive attention mechanism that selectively focuses on critical interactive participants to further enhance computational efficiency. Both simulation results and practical experiments demonstrate that our framework achieves significant advantages in safety (reducing collision rates by up to 40.79\\% in various scenarios) and real-time performance compared to state-of-the-art methods, while maintaining strong scalability with increasing vehicle numbers. The proposed interactive attention mechanism further reduces the computational demand by 14.1\\%. The framework's effectiveness is further validated through real-world experiments with unexpected dynamic obstacles, demonstrating robust coordination in complex environments. The experiment demo could be found at this https URL.", 'abstract_zh': '在合作车辆协调中同时实现安全保证和实时性能仍然是一个基础挑战，尤其是在动态和不确定的环境中。本文提出了一种新颖的协调框架，通过三项关键技术解决这一挑战：1) 在协调过程中直接控制车辆的轨迹分布，将其建模为具有自适应增强安全约束的鲁棒协同规划问题，确保在交互轨迹不确定性方面的特定安全水平；2) 一种全并行的基于ADMM的分布式轨迹协商（ADMM-DTN）算法，能够在保证求解质量的同时灵活配置协商轮次，平衡解决方案质量与计算资源；3) 一种交互式注意力机制，能够有选择地关注关键的交互参与者，进一步提高计算效率。仿真结果和实际试验表明，与现有最佳方法相比，本框架在安全性（在多种场景下降低碰撞率高达40.79%）和实时性能上具有显著优势，且具有良好的可扩展性，随着车辆数量的增加保持高效。所提出的交互式注意力机制进一步降低了14.1%的计算需求。通过实际试验验证了该框架在具有意外动态障碍物的复杂环境中的鲁棒协调能力。完整的实验演示可以访问以下链接：this https URL。', 'title_zh': '具有不确定性条件下分布式优化框架的 robust 实时协调 of CAVs'}
{'arxiv_id': 'arXiv:2508.21272', 'title': 'Learning to Assemble the Soma Cube with Legal-Action Masked DQN and Safe ZYZ Regrasp on a Doosan M0609', 'authors': 'Jaehong Oh, Seungjun Jung, Sawoong Kim', 'link': 'https://arxiv.org/abs/2508.21272', 'abstract': 'This paper presents the first comprehensive application of legal-action masked Deep Q-Networks with safe ZYZ regrasp strategies to an underactuated gripper-equipped 6-DOF collaborative robot for autonomous Soma cube assembly learning. Our approach represents the first systematic integration of constraint-aware reinforcement learning with singularity-safe motion planning on a Doosan M0609 collaborative robot. We address critical challenges in robotic manipulation: combinatorial action space explosion, unsafe motion planning, and systematic assembly strategy learning. Our system integrates a legal-action masked DQN with hierarchical architecture that decomposes Q-function estimation into orientation and position components, reducing computational complexity from $O(3,132)$ to $O(116) + O(27)$ while maintaining solution completeness. The robot-friendly reward function encourages ground-first, vertically accessible assembly sequences aligned with manipulation constraints. Curriculum learning across three progressive difficulty levels (2-piece, 3-piece, 7-piece) achieves remarkable training efficiency: 100\\% success rate for Level 1 within 500 episodes, 92.9\\% for Level 2, and 39.9\\% for Level 3 over 105,300 total training episodes.', 'abstract_zh': '这篇论文提出了将法律行动掩码深度Q网络与安全的ZYZ重抓策略综合应用于一个装备有6自由度未饱和夹持器的协作机器人，以进行自适应Soma立方体组装学习的方法。我们的方法代表了将约束感知强化学习与奇异点安全运动规划系统性集成到Doosan M0609协作机器人上的首次尝试。我们解决了机器人操作中的关键挑战：组合动作空间爆炸、不安全的运动规划和系统化组装策略学习。该系统结合了带分层架构的法律行动掩码DQN，将Q函数估计分解为姿态和位置组件，将计算复杂度从$O(3,132)$降低到$O(116) + O(27)$，同时保持解的完整性。针对现有的机器人友好型奖励函数鼓励先地再垂直组装序列，该序列符合操作约束。跨三个逐步提高难度级别（2块、3块、7块）的分级课程学习实现了显著的训练效率：在一级中500个episode内100%成功，二级中92.9%，三级中39.9%（总计105,300个训练episode）。', 'title_zh': '使用合法动作掩蔽DQN和Safe ZYZ 重新抓取学习构建Soma立方体'}
{'arxiv_id': 'arXiv:2508.21112', 'title': 'EmbodiedOneVision: Interleaved Vision-Text-Action Pretraining for General Robot Control', 'authors': 'Delin Qu, Haoming Song, Qizhi Chen, Zhaoqing Chen, Xianqiang Gao, Xinyi Ye, Qi Lv, Modi Shi, Guanghui Ren, Cheng Ruan, Maoqing Yao, Haoran Yang, Jiacheng Bao, Bin Zhao, Dong Wang', 'link': 'https://arxiv.org/abs/2508.21112', 'abstract': 'The human ability to seamlessly perform multimodal reasoning and physical interaction in the open world is a core goal for general-purpose embodied intelligent systems. Recent vision-language-action (VLA) models, which are co-trained on large-scale robot and visual-text data, have demonstrated notable progress in general robot control. However, they still fail to achieve human-level flexibility in interleaved reasoning and interaction. In this work, introduce EO-Robotics, consists of EO-1 model and EO-Data1.5M dataset. EO-1 is a unified embodied foundation model that achieves superior performance in multimodal embodied reasoning and robot control through interleaved vision-text-action pre-training. The development of EO-1 is based on two key pillars: (i) a unified architecture that processes multimodal inputs indiscriminately (image, text, video, and action), and (ii) a massive, high-quality multimodal embodied reasoning dataset, EO-Data1.5M, which contains over 1.5 million samples with emphasis on interleaved vision-text-action comprehension. EO-1 is trained through synergies between auto-regressive decoding and flow matching denoising on EO-Data1.5M, enabling seamless robot action generation and multimodal embodied reasoning. Extensive experiments demonstrate the effectiveness of interleaved vision-text-action learning for open-world understanding and generalization, validated through a variety of long-horizon, dexterous manipulation tasks across multiple embodiments. This paper details the architecture of EO-1, the data construction strategy of EO-Data1.5M, and the training methodology, offering valuable insights for developing advanced embodied foundation models.', 'abstract_zh': '人类能够在开放世界中无缝进行多模态推理和物理交互的能力是通用体态智能系统的核心目标。近期的视觉-语言-动作（VLA）模型在大规模机器人和视觉-文本数据上的共同训练中，展示了在通用机器人控制方面显著的进步。然而，它们仍然无法达到人类级别的灵活的交互与推理能力。在这项工作中，我们引入了EO-Robotics，包括EO-1模型和EO-Data1.5M数据集。EO-1是一种统一的体态基础模型，通过交织的视觉-文本-动作预训练，在多模态体态推理和机器人控制方面表现出优越性能。EO-1的发展基于两大关键支柱：（i）一种可以无差别处理多模态输入（图像、文本、视频和动作）的统一架构，以及（ii）一个大规模的高质量多模态体态推理数据集EO-Data1.5M，该数据集包含超过150万个样本，重点放在交织的视觉-文本-动作理解上。EO-1通过在EO-Data1.5M上的自回归解码和流匹配去噪之间的协同作用进行训练，从而实现无缝的机器人动作生成和多模态体态推理。大量实验证明了交织的视觉-文本-动作学习在开放世界理解和泛化方面的有效性，并通过多个体态下的多种长时延灵巧操作任务得到了验证。本论文详细介绍了EO-1的架构、EO-Data1.5M的数据构建策略以及训练方法，为开发高级体态基础模型提供了宝贵见解。', 'title_zh': 'EmbodiedOneVision: 交错的视觉-文本-行动预训练面向通用机器人控制'}
{'arxiv_id': 'arXiv:2508.21797', 'title': 'DynaMark: A Reinforcement Learning Framework for Dynamic Watermarking in Industrial Machine Tool Controllers', 'authors': 'Navid Aftabi, Abhishek Hanchate, Satish Bukkapatnam, Dan Li', 'link': 'https://arxiv.org/abs/2508.21797', 'abstract': "Industry 4.0's highly networked Machine Tool Controllers (MTCs) are prime targets for replay attacks that use outdated sensor data to manipulate actuators. Dynamic watermarking can reveal such tampering, but current schemes assume linear-Gaussian dynamics and use constant watermark statistics, making them vulnerable to the time-varying, partly proprietary behavior of MTCs. We close this gap with DynaMark, a reinforcement learning framework that models dynamic watermarking as a Markov decision process (MDP). It learns an adaptive policy online that dynamically adapts the covariance of a zero-mean Gaussian watermark using available measurements and detector feedback, without needing system knowledge. DynaMark maximizes a unique reward function balancing control performance, energy consumption, and detection confidence dynamically. We develop a Bayesian belief updating mechanism for real-time detection confidence in linear systems. This approach, independent of specific system assumptions, underpins the MDP for systems with linear dynamics. On a Siemens Sinumerik 828D controller digital twin, DynaMark achieves a reduction in watermark energy by 70% while preserving the nominal trajectory, compared to constant variance baselines. It also maintains an average detection delay equivalent to one sampling interval. A physical stepper-motor testbed validates these findings, rapidly triggering alarms with less control performance decline and exceeding existing benchmarks.", 'abstract_zh': 'Industry 4.0中高度网络化的机床控制器是重放攻击的主要目标，这些攻击利用过时的传感器数据操控执行器。动态水印可以揭示此类篡改，但现有方案假设线性高斯动态，并采用恒定的水印统计值，使其容易受到机床控制器时间变化且部分专有的行为影响。我们通过DynaMark填补这一空白，DynaMark是一个基于强化学习的框架，将其动态水印建模为马尔可夫决策过程（MDP）。该框架在线学习自适应策略，动态调整零均值高斯水印的协方差，无需系统知识。DynaMark最大化一个独特的奖励函数，该函数平衡控制性能、能量消耗和检测置信度，使其能够动态变化。我们为线性系统开发了一种贝叶斯信念更新机制，以实现实时检测置信度。这种方法不依赖于特定系统假设，为具有线性动力学的系统提供了MDP基础。在西门子Sinumerik 828D控制器数字孪生中，DynaMark在保持名义轨迹的同时将水印能量降低了70%，与恒定方差基线相比。它还维持了相当于一个采样间隔的平均检测延迟。物理步进电机测试平台验证了这些发现，能够在控制性能下降更少的情况下迅速触发警报，超过了现有基准。', 'title_zh': 'DynaMark：工业机床控制器中动态水印的强化学习框架'}
{'arxiv_id': 'arXiv:2508.21430', 'title': 'Med-RewardBench: Benchmarking Reward Models and Judges for Medical Multimodal Large Language Models', 'authors': 'Meidan Ding, Jipeng Zhang, Wenxuan Wang, Cheng-Yi Li, Wei-Chieh Fang, Hsin-Yu Wu, Haiqin Zhong, Wenting Chen, Linlin Shen', 'link': 'https://arxiv.org/abs/2508.21430', 'abstract': 'Multimodal large language models (MLLMs) hold significant potential in medical applications, including disease diagnosis and clinical decision-making. However, these tasks require highly accurate, context-sensitive, and professionally aligned responses, making reliable reward models and judges critical. Despite their importance, medical reward models (MRMs) and judges remain underexplored, with no dedicated benchmarks addressing clinical requirements. Existing benchmarks focus on general MLLM capabilities or evaluate models as solvers, neglecting essential evaluation dimensions like diagnostic accuracy and clinical relevance. To address this, we introduce Med-RewardBench, the first benchmark specifically designed to evaluate MRMs and judges in medical scenarios. Med-RewardBench features a multimodal dataset spanning 13 organ systems and 8 clinical departments, with 1,026 expert-annotated cases. A rigorous three-step process ensures high-quality evaluation data across six clinically critical dimensions. We evaluate 32 state-of-the-art MLLMs, including open-source, proprietary, and medical-specific models, revealing substantial challenges in aligning outputs with expert judgment. Additionally, we develop baseline models that demonstrate substantial performance improvements through fine-tuning.', 'abstract_zh': '多模态大型语言模型在医疗应用中的潜力包括疾病诊断和临床决策，然而这些任务需要高度准确、上下文敏感和专业对齐的响应，因此可靠的奖励模型和评判者至关重要。尽管如此，医疗奖励模型（MRMs）和评判者仍未得到充分探索，缺少专门针对临床需求的基准测试。现有基准测试主要关注通用的MLLM能力或评估模型作为求解器，忽视了诊断准确性等关键评估维度。为解决这一问题，我们介绍了Med-RewardBench，这是首个专门用于评估MRMs和评判者在医疗场景中的基准测试。Med-RewardBench 包含涵盖13个器官系统和8个临床部门的多模态数据集，共有1026个专家标注的案例。严谨的三步过程确保了六个临床关键维度的高质量评估数据。我们评估了32个最先进的MLLMs，包括开源、专有和医疗专用模型，揭示了与专家判断对齐的巨大挑战。此外，我们还开发了基准模型，通过微调实现了显著的性能提升。', 'title_zh': 'Med-RewardBench: 评价医学多模态大型语言模型奖励模型和评估者的基准'}
{'arxiv_id': 'arXiv:2508.21201', 'title': 'Improving Aviation Safety Analysis: Automated HFACS Classification Using Reinforcement Learning with Group Relative Policy Optimization', 'authors': 'Arash Ahmadi, Sarah Sharif, Yaser Banad', 'link': 'https://arxiv.org/abs/2508.21201', 'abstract': 'Analyzing the human factors behind aviation accidents is crucial for preventing future incidents, yet traditional methods using the Human Factors Analysis and Classification System (HFACS) are limited by scalability and consistency. To address this, we introduce an automated HFACS classification framework for aviation safety analysis that utilizes Reinforcement Learning with Group Relative Policy Optimization (GRPO) to fine-tune a Llama-3.1 8B language model. Our approach incorporates a multi-component reward system tailored for aviation safety analysis and integrates synthetic data generation to overcome class imbalance in accident datasets. The resulting GRPO-optimized model achieved noticeable performance gains, including a 350% increase in exact match accuracy (from 0.0400 to 0.1800) and an improved partial match accuracy of 0.8800. Significantly, our specialized model outperforms state-of-the-art LLMs (Large Language Models), including GPT-5-mini and Gemini-2.5-fiash, on key metrics. This research also proposes exact match accuracy in multi-label HFACS classification problem as a new benchmarking methodology to evaluate the advanced reasoning capabilities of language models. Ultimately, our work validates that smaller, domain-optimized models can provide a computationally efficient and better solution for critical safety analysis. This approach makes powerful, low-latency deployment on resource-constrained edge devices feasible.', 'abstract_zh': '基于强化学习与组相对策略优化的航空安全分析自动化HFACS分类框架', 'title_zh': '改进航空安全分析：基于群体相对策略优化的强化学习自动HFACS分类'}
{'arxiv_id': 'arXiv:2508.19153', 'title': 'QuadKAN: KAN-Enhanced Quadruped Motion Control via End-to-End Reinforcement Learning', 'authors': 'Allen Wang, Gavin Tao', 'link': 'https://arxiv.org/abs/2508.19153', 'abstract': 'We address vision-guided quadruped motion control with reinforcement learning (RL) and highlight the necessity of combining proprioception with vision for robust control. We propose QuadKAN, a spline-parameterized cross-modal policy instantiated with Kolmogorov-Arnold Networks (KANs). The framework incorporates a spline encoder for proprioception and a spline fusion head for proprioception-vision inputs. This structured function class aligns the state-to-action mapping with the piecewise-smooth nature of gait, improving sample efficiency, reducing action jitter and energy consumption, and providing interpretable posture-action sensitivities. We adopt Multi-Modal Delay Randomization (MMDR) and perform end-to-end training with Proximal Policy Optimization (PPO). Evaluations across diverse terrains, including both even and uneven surfaces and scenarios with static or dynamic obstacles, demonstrate that QuadKAN achieves consistently higher returns, greater distances, and fewer collisions than state-of-the-art (SOTA) baselines. These results show that spline-parameterized policies offer a simple, effective, and interpretable alternative for robust vision-guided locomotion. A repository will be made available upon acceptance.', 'abstract_zh': '基于视觉的四足运动控制：结合知觉与强化学习的方法及其实现', 'title_zh': 'QuadKAN: 通过端到端强化学习增强的四足运动控制'}
