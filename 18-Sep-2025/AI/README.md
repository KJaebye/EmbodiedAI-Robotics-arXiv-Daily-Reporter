# Hierarchical Learning for Maze Navigation: Emergence of Mental Representations via Second-Order Learning 

**Title (ZH)**: 层次学习在迷宫导航中的应用：通过二次学习涌现心理表征 

**Authors**: Shalima Binta Manir, Tim Oates  

**Link**: [PDF](https://arxiv.org/pdf/2509.14195)  

**Abstract**: Mental representation, characterized by structured internal models mirroring external environments, is fundamental to advanced cognition but remains challenging to investigate empirically. Existing theory hypothesizes that second-order learning -- learning mechanisms that adapt first-order learning (i.e., learning about the task/domain) -- promotes the emergence of such environment-cognition isomorphism. In this paper, we empirically validate this hypothesis by proposing a hierarchical architecture comprising a Graph Convolutional Network (GCN) as a first-order learner and an MLP controller as a second-order learner. The GCN directly maps node-level features to predictions of optimal navigation paths, while the MLP dynamically adapts the GCN's parameters when confronting structurally novel maze environments. We demonstrate that second-order learning is particularly effective when the cognitive system develops an internal mental map structurally isomorphic to the environment. Quantitative and qualitative results highlight significant performance improvements and robust generalization on unseen maze tasks, providing empirical support for the pivotal role of structured mental representations in maximizing the effectiveness of second-order learning. 

**Abstract (ZH)**: 结构化的内部模型促进了环境认知同构性的高级认知过程：通过层次架构验证第二级学习的有效性 

---
# CrowdAgent: Multi-Agent Managed Multi-Source Annotation System 

**Title (ZH)**: CrowdAgent：多Agent管理的多源标注系统 

**Authors**: Maosheng Qin, Renyu Zhu, Mingxuan Xia, Chenkai Chen, Zhen Zhu, Minmin Lin, Junbo Zhao, Lu Xu, Changjie Fan, Runze Wu, Haobo Wang  

**Link**: [PDF](https://arxiv.org/pdf/2509.14030)  

**Abstract**: High-quality annotated data is a cornerstone of modern Natural Language Processing (NLP). While recent methods begin to leverage diverse annotation sources-including Large Language Models (LLMs), Small Language Models (SLMs), and human experts-they often focus narrowly on the labeling step itself. A critical gap remains in the holistic process control required to manage these sources dynamically, addressing complex scheduling and quality-cost trade-offs in a unified manner. Inspired by real-world crowdsourcing companies, we introduce CrowdAgent, a multi-agent system that provides end-to-end process control by integrating task assignment, data annotation, and quality/cost management. It implements a novel methodology that rationally assigns tasks, enabling LLMs, SLMs, and human experts to advance synergistically in a collaborative annotation workflow. We demonstrate the effectiveness of CrowdAgent through extensive experiments on six diverse multimodal classification tasks. The source code and video demo are available at this https URL. 

**Abstract (ZH)**: 高质量标注数据是现代自然语言处理（NLP）的基石。尽管最近的方法开始利用包括大型语言模型（LLMs）、小型语言模型（SLMs）和人类专家在内的多样标注来源，它们往往专注于标注本身。在整体流程控制方面仍存在一个关键缺口，需要动态管理这些来源，以统一的方式应对复杂的调度和质量-成本权衡。借鉴现实世界的众包公司，我们介绍了CrowdAgent多智能体系统，该系统通过整合任务分配、数据标注和质量/成本管理，提供端到端的流程控制。它实现了一种新的方法，合理分配任务，使LLMs、SLMs和人类专家能够在协作标注工作流中协同进步。我们通过在六项不同的多模态分类任务上的广泛实验展示了CrowdAgent的有效性。源代码和视频demo可访问此链接。 

---
# Exploring Major Transitions in the Evolution of Biological Cognition With Artificial Neural Networks 

**Title (ZH)**: 探索生物认知进化中的重大转变人工神经网络研究 

**Authors**: Konstantinos Voudouris, Andrew Barron, Marta Halina, Colin Klein, Matishalin Patel  

**Link**: [PDF](https://arxiv.org/pdf/2509.13968)  

**Abstract**: Transitional accounts of evolution emphasise a few changes that shape what is evolvable, with dramatic consequences for derived lineages. More recently it has been proposed that cognition might also have evolved via a series of major transitions that manipulate the structure of biological neural networks, fundamentally changing the flow of information. We used idealised models of information flow, artificial neural networks (ANNs), to evaluate whether changes in information flow in a network can yield a transitional change in cognitive performance. We compared networks with feed-forward, recurrent and laminated topologies, and tested their performance learning artificial grammars that differed in complexity, controlling for network size and resources. We documented a qualitative expansion in the types of input that recurrent networks can process compared to feed-forward networks, and a related qualitative increase in performance for learning the most complex grammars. We also noted how the difficulty in training recurrent networks poses a form of transition barrier and contingent irreversibility -- other key features of evolutionary transitions. Not all changes in network topology confer a performance advantage in this task set. Laminated networks did not outperform non-laminated networks in grammar learning. Overall, our findings show how some changes in information flow can yield transitions in cognitive performance. 

**Abstract (ZH)**: 过渡演变的概括强调了少数变化如何塑造可演变性，并对衍生谱系产生了重大影响。最近有观点提出，认知也可能通过一系列主要过渡演变来发展，操纵生物神经网络的结构，从根本上改变信息流。我们使用理想的 INFORMATION FLOW 模型和人工神经网络（ANNs）来评估网络中信息流的变化是否能导致认知表现的过渡变化。我们比较了前馈、反馈和层状网络结构，并测试了它们在不同复杂度的人工文法学习中的表现，同时控制了网络规模和资源。我们记录了反馈网络相较于前馈网络在处理输入类型上的定性扩展，以及在学习最复杂文法方面相关的表现提升。我们还注意到，在训练反馈网络时出现的难度为过渡障碍和历史不可逆性提供了形式上的支持——这些都是演化过渡的关键特征。并非所有网络拓扑结构的变化都在此任务集中提供表现优势。层状网络在文法学习中并未优于非层状网络。总体而言，我们的发现显示了信息流某些变化如何导致认知表现的过渡变化。 

---
# An Exhaustive DPLL Approach to Model Counting over Integer Linear Constraints with Simplification Techniques 

**Title (ZH)**: 基于简化技术的整数线性约束模型计数的全面DPLL方法 

**Authors**: Mingwei Zhang, Zhenhao Gu, Liangda Fang, Cunjing Ge, Ziliang Chen, Zhao-Rong Lai, Quanlong Guan  

**Link**: [PDF](https://arxiv.org/pdf/2509.13880)  

**Abstract**: Linear constraints are one of the most fundamental constraints in fields such as computer science, operations research and optimization. Many applications reduce to the task of model counting over integer linear constraints (MCILC). In this paper, we design an exact approach to MCILC based on an exhaustive DPLL architecture. To improve the efficiency, we integrate several effective simplification techniques from mixed integer programming into the architecture. We compare our approach to state-of-the-art MCILC counters and propositional model counters on 2840 random and 4131 application benchmarks. Experimental results show that our approach significantly outperforms all exact methods in random benchmarks solving 1718 instances while the state-of-the-art approach only computes 1470 instances. In addition, our approach is the only approach to solve all 4131 application instances. 

**Abstract (ZH)**: 线性约束是计算机科学、运筹学和优化等领域中最基本的约束条件之一。许多应用归结为整数线性约束下的模型计数任务（MCILC）。在本文中，我们基于详尽的DPLL架构设计了一种精确的MCILC方法。为了提高效率，我们将来自混合整数规划的有效简化技术集成到该架构中。我们在2840个随机和4131个应用基准上将我们的方法与最先进的MCILC计数器和命题模型计数器进行了比较。实验结果表明，在随机基准上，我们的方法显著优于所有精确方法，解决了1718个实例，而最先进的方法仅计算了1470个实例。此外，我们的方法是唯一能够解决所有4131个应用实例的方法。 

---
# MIRA: Empowering One-Touch AI Services on Smartphones with MLLM-based Instruction Recommendation 

**Title (ZH)**: MIRA: 基于MLLM的指令推荐技术赋能智能手机的一触即达AI服务 

**Authors**: Zhipeng Bian, Jieming Zhu, Xuyang Xie, Quanyu Dai, Zhou Zhao, Zhenhua Dong  

**Link**: [PDF](https://arxiv.org/pdf/2509.13773)  

**Abstract**: The rapid advancement of generative AI technologies is driving the integration of diverse AI-powered services into smartphones, transforming how users interact with their devices. To simplify access to predefined AI services, this paper introduces MIRA, a pioneering framework for task instruction recommendation that enables intuitive one-touch AI tasking on smartphones. With MIRA, users can long-press on images or text objects to receive contextually relevant instruction recommendations for executing AI tasks. Our work introduces three key innovations: 1) A multimodal large language model (MLLM)-based recommendation pipeline with structured reasoning to extract key entities, infer user intent, and generate precise instructions; 2) A template-augmented reasoning mechanism that integrates high-level reasoning templates, enhancing task inference accuracy; 3) A prefix-tree-based constrained decoding strategy that restricts outputs to predefined instruction candidates, ensuring coherent and intent-aligned suggestions. Through evaluation using a real-world annotated datasets and a user study, MIRA has demonstrated substantial improvements in the accuracy of instruction recommendation. The encouraging results highlight MIRA's potential to revolutionize the way users engage with AI services on their smartphones, offering a more seamless and efficient experience. 

**Abstract (ZH)**: 快速发展的生成AI技术正推动多种AI驱动服务与智能手机的融合，改变用户与设备的交互方式。为简化对预定义AI服务的访问，本文介绍了一种名为MIRA的先驱框架，该框架能够使智能手机上的AI任务执行变得直观便捷，只需一键操作。通过长按图片或文本对象，用户可获得与上下文相关、适用于执行AI任务的指令推荐。我们的工作引入了三项关键创新：1）基于多模态大型语言模型（MLLM）的推荐管道，结合结构化推理以提取关键实体、推断用户意图并生成精确的指令；2）模板增强的推理机制，融合高级推理模板以提高任务推断准确性；3）基于前缀树的受限解码策略，限定输出为预定义指令候选，确保建议的连贯性和意图一致性。通过使用真实世界标注数据集和用户研究进行评估，MIRA在指令推荐的准确性方面取得了显著提升。令人鼓舞的结果表明，MIRA有望彻底改变用户在智能手机上与AI服务的互动方式，提供更流畅高效的体验。 

---
# THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning 

**Title (ZH)**: THOR: 工具集成的分层优化方法及其在数学推理中的应用via RL 

**Authors**: Qikai Chang, Zhenrong Zhang, Pengfei Hu, Jiefeng Ma, Yicheng Pan, Jianshu Zhang, Jun Du, Quan Liu, Jianqing Gao  

**Link**: [PDF](https://arxiv.org/pdf/2509.13761)  

**Abstract**: Large Language Models (LLMs) have made remarkable progress in mathematical reasoning, but still continue to struggle with high-precision tasks like numerical computation and formal symbolic manipulation. Integrating external tools has emerged as a promising approach to bridge this gap. Despite recent advances, existing methods struggle with three key challenges: constructing tool-integrated reasoning data, performing fine-grained optimization, and enhancing inference. To overcome these limitations, we propose THOR (Tool-Integrated Hierarchical Optimization via RL). First, we introduce TIRGen, a multi-agent actor-critic-based pipeline for constructing high-quality datasets of tool-integrated reasoning paths, aligning with the policy and generalizing well across diverse models. Second, to perform fine-grained hierarchical optimization, we introduce an RL strategy that jointly optimizes for both trajectory-level problem solving and step-level code generation. This is motivated by our key insight that the success of an intermediate tool call is a strong predictor of the final answer's correctness. Finally, THOR incorporates a self-correction mechanism that leverages immediate tool feedback to dynamically revise erroneous reasoning paths during inference. Our approach demonstrates strong generalization across diverse models, performing effectively in both reasoning and non-reasoning models. It further achieves state-of-the-art performance for models of a similar scale on multiple mathematical benchmarks, while also delivering consistent improvements on code benchmarks. Our code will be publicly available at this https URL. 

**Abstract (ZH)**: 大型语言模型（LLMs）在数学推理方面取得了显著进展，但仍难以处理高精度任务，如数值计算和正式符号操作。将外部工具集成起来已成为弥合这一差距的有前途的方法。尽管近期有所进展，现有方法仍面临三个关键挑战：构建工具集成推理数据、进行精细层级优化以及增强推理。为克服这些局限，我们提出了THOR（工具集成层级优化方法，基于强化学习）。首先，我们引入了TIRGen，一种基于多智能体演员-评论家架构的数据管道，用于构建高质量的工具集成推理路径数据集，与策略对齐并在多种模型中泛化良好。其次，为进行精细层级优化，我们引入了一种基于强化学习的策略，该策略同时优化轨迹级别的问题解决和步骤级别的代码生成。这受到我们一个关键见解的激发，即中间工具调用的成功是最终答案正确性的强大预测指标。最后，THOR 包含一个自我纠正机制，在推理过程中利用即时的工具反馈动态修订错误的推理路径。我们方法展示了在多种模型中强大的泛化能力，能够在推理和非推理模型中表现良好。此外，在多项数学基准测试中，THOR 达到了类似规模模型的最优性能，并且在代码基准测试中也实现了持续改进。相关代码将在此 https URL 公开。 

---
# InfraMind: A Novel Exploration-based GUI Agentic Framework for Mission-critical Industrial Management 

**Title (ZH)**: InfraMind: 一种新型基于探索的GUI代理框架用于关键工业管理 

**Authors**: Liangtao Lin, Zhaomeng Zhu, Tianwei Zhang, Yonggang Wen  

**Link**: [PDF](https://arxiv.org/pdf/2509.13704)  

**Abstract**: Mission-critical industrial infrastructure, such as data centers, increasingly depends on complex management software. Its operations, however, pose significant challenges due to the escalating system complexity, multi-vendor integration, and a shortage of expert operators. While Robotic Process Automation (RPA) offers partial automation through handcrafted scripts, it suffers from limited flexibility and high maintenance costs. Recent advances in Large Language Model (LLM)-based graphical user interface (GUI) agents have enabled more flexible automation, yet these general-purpose agents face five critical challenges when applied to industrial management, including unfamiliar element understanding, precision and efficiency, state localization, deployment constraints, and safety requirements. To address these issues, we propose InfraMind, a novel exploration-based GUI agentic framework specifically tailored for industrial management systems. InfraMind integrates five innovative modules to systematically resolve different challenges in industrial management: (1) systematic search-based exploration with virtual machine snapshots for autonomous understanding of complex GUIs; (2) memory-driven planning to ensure high-precision and efficient task execution; (3) advanced state identification for robust localization in hierarchical interfaces; (4) structured knowledge distillation for efficient deployment with lightweight models; and (5) comprehensive, multi-layered safety mechanisms to safeguard sensitive operations. Extensive experiments on both open-source and commercial DCIM platforms demonstrate that our approach consistently outperforms existing frameworks in terms of task success rate and operational efficiency, providing a rigorous and scalable solution for industrial management automation. 

**Abstract (ZH)**: 面向工业管理系统的探索导向型图形用户界面代理框架：InfraMind 

---
# See, Think, Act: Teaching Multimodal Agents to Effectively Interact with GUI by Identifying Toggles 

**Title (ZH)**: 看见、思考、行动：通过识别开关以教会多模态代理有效与GUI交互 

**Authors**: Zongru Wu, Rui Mao, Zhiyuan Tian, Pengzhou Cheng, Tianjie Ju, Zheng Wu, Lingzhong Dong, Haiyue Sheng, Zhuosheng Zhang, Gongshen Liu  

**Link**: [PDF](https://arxiv.org/pdf/2509.13615)  

**Abstract**: The advent of multimodal agents facilitates effective interaction within graphical user interface (GUI), especially in ubiquitous GUI control. However, their inability to reliably execute toggle control instructions remains a key bottleneck. To investigate this, we construct a state control benchmark with binary toggle instructions from public datasets. Evaluations of existing agents demonstrate their unreliability, particularly when the current toggle state already matches the desired state. To address the challenge, we propose State-aware Reasoning (StaR), a training method that teaches agents to perceive the current toggle state, analyze the desired state from the instruction, and act accordingly. Experiments on three multimodal agents demonstrate that StaR can improve toggle instruction execution accuracy by over 30\%. Further evaluations on three public benchmarks show that StaR also enhances general task performance. Finally, evaluations on a dynamic environment highlight the potential of StaR for real-world applications. Code, benchmark, and StaR-enhanced agents are available at this https URL. 

**Abstract (ZH)**: 多模态代理的出现促进了图形用户界面（GUI）内的有效交互，尤其是在泛在GUI控制方面。然而，它们在可靠执行切换控制指令方面的能力不足仍然是一个关键瓶颈。为探究此问题，我们从公开数据集中构建了一个基于二元切换指令的状态控制基准。对于现有代理的评估表明，它们在当前切换状态已与目标状态匹配时表现尤其不可靠。为应对这一挑战，我们提出了状态感知推理（StaR），这是一种培训方法，旨在教导代理感知当前切换状态、从指令中分析目标状态并据此行动。在三个多模态代理上的实验表明，StaR 可以将切换指令执行的准确性提高超过30%。进一步在三个公开基准上的评估表明，StaR 也提升了总体任务表现。最后，对动态环境的评估突显了StaR 在实际应用中的潜力。代码、基准和StaR增强的代理可在以下链接获得。 

---
# Programmable Cognitive Bias in Social Agents 

**Title (ZH)**: 社会代理中的可编程认知偏见 

**Authors**: Xuan Liu, Haoyang Shang, Haojian Jin  

**Link**: [PDF](https://arxiv.org/pdf/2509.13588)  

**Abstract**: This paper introduces CoBRA, a novel toolkit for systematically specifying agent behavior in LLM-based social simulation. We found that conventional approaches that specify agent behaviors through implicit natural language descriptions cannot yield consistent behaviors across models, and the produced agent behaviors do not capture the nuances of the descriptions. In contrast, CoBRA presents a new approach to program agents' cognitive biases explicitly, by grounding agents' expected behaviors using classic social science experiments. CoBRA has two components: (1) Cognitive Bias Index that measures the cognitive bias of a social agent, by quantifying the agent's reactions in a set of validated classical social science experiments; (2) Behavioral Regulation Engine that aligns the agent's behavior to demonstrate controlled cognitive bias. We evaluated CoBRA as an HCI toolkit through demonstration and technical benchmarks. Our results suggest that CoBRA can precisely program the cognitive bias demonstrated in a social agent in a model-agnostic manner. 

**Abstract (ZH)**: 本文介绍了一种新的工具CoBRA，用于在基于LLM的社会仿真中系统地规定代理行为。我们发现，通过隐式的自然语言描述来规定代理行为的传统方法无法在不同模型中产生一致的行为，并且生成的代理行为未能捕捉到描述的细微差别。相比之下，CoBRA通过将代理期望行为与经典的社会科学实验进行关联，明确地编程代理的认知偏差。CoBRA由两个部分组成：(1) 认知偏差指数，通过量化代理在一组验证过的经典社会科学实验中的反应来衡量代理的认知偏差；(2) 行为调节引擎，使代理的行为与可控的认知偏差相一致。我们通过演示和技术基准评估了CoBRA作为人机接口工具的效果。我们的结果显示，CoBRA可以以模型无关的方式精确编程社交代理所展现的认知偏差。 

---
# Gen AI in Proof-based Math Courses: A Pilot Study 

**Title (ZH)**: 基于证明的数学课程中生成型AI的应用：一项试点研究 

**Authors**: Hannah Klawa, Shraddha Rajpal, Cigole Thomas  

**Link**: [PDF](https://arxiv.org/pdf/2509.13570)  

**Abstract**: With the rapid rise of generative AI in higher education and the unreliability of current AI detection tools, developing policies that encourage student learning and critical thinking has become increasingly important. This study examines student use and perceptions of generative AI across three proof-based undergraduate mathematics courses: a first-semester abstract algebra course, a topology course and a second-semester abstract algebra course. In each case, course policy permitted some use of generative AI. Drawing on survey responses and student interviews, we analyze how students engaged with AI tools, their perceptions of generative AI's usefulness and limitations, and what implications these perceptions hold for teaching proof-based mathematics. We conclude by discussing future considerations for integrating generative AI into proof-based mathematics instruction. 

**Abstract (ZH)**: 随着生成式AI在高等教育中的迅速兴起及当前AI检测工具的可靠性不足，制定鼓励学生学习和批判性思维的政策变得越来越重要。本研究探讨了生成式AI在三门证明基础的本科数学课程中的使用情况和学生感知：首学期抽象代数课程、拓扑课程以及第二学期抽象代数课程。在每种情况下，课程政策允许一定程度的生成式AI使用。通过调研问卷和学生访谈，我们分析了学生如何使用AI工具、他们对生成式AI usefulness和局限性的感知，以及这些感知对教授证明基础数学课程的影响。最后，我们讨论了将生成式AI整合到证明基础数学教学中的未来考量。 

---
# AI Agents with Human-Like Collaborative Tools: Adaptive Strategies for Enhanced Problem-Solving 

**Title (ZH)**: 具有人类协作工具特征的AI代理：增强问题解决的适应性策略 

**Authors**: Harper Reed, Michael Sugimura, Angelo Zangari  

**Link**: [PDF](https://arxiv.org/pdf/2509.13547)  

**Abstract**: We investigate whether giving LLM agents the collaborative tools and autonomy that humans naturally use for problem solving can improve their performance. We equip Claude Code agents with MCP-based social media and journaling tools and allow them to use these tools as they see fit. Across 34 Aider Polyglot Python programming challenges, collaborative tools substantially improve performance on the hardest problems, delivering 15-40% lower cost, 12-27% fewer turns, and 12-38% faster completion than baseline agents. Effects on the full challenge set are mixed, suggesting these tools act as performance enhancers when additional reasoning scaffolding is most needed. Surprisingly, Different models naturally adopted distinct collaborative strategies without explicit instruction. Sonnet 3.7 engaged broadly across tools and benefited from articulation-based cognitive scaffolding. Sonnet 4 showed selective adoption, leaning on journal-based semantic search when problems were genuinely difficult. This mirrors how human developers adjust collaboration based on expertise and task complexity. Behavioral analysis shows agents prefer writing over reading by about 2-9x, indicating that structured articulation drives much of the improvement rather than information access alone. Overall, AI agents can systematically benefit from human-inspired collaboration tools at the edge of their capabilities, pointing to adaptive collaborative interfaces as reasoning enhancers rather than universal efficiency boosts. 

**Abstract (ZH)**: 探究为LLM代理提供人类自然用于问题解决的合作工具和自主权是否能提高其性能 

---
# SteeringControl: Holistic Evaluation of Alignment Steering in LLMs 

**Title (ZH)**: steering控制：大型语言模型中对齐 steering 的整体评估 

**Authors**: Vincent Siu, Nicholas Crispino, David Park, Nathan W. Henry, Zhun Wang, Yang Liu, Dawn Song, Chenguang Wang  

**Link**: [PDF](https://arxiv.org/pdf/2509.13450)  

**Abstract**: We introduce SteeringControl, a benchmark for evaluating representation steering methods across core alignment objectives--bias, harmful generation, and hallucination--and their effects on secondary behaviors such as sycophancy and commonsense morality. While prior alignment work often highlights truthfulness or reasoning ability to demonstrate the side effects of representation steering, we find there are many unexplored tradeoffs not yet understood in a systematic way. We collect a dataset of safety-relevant primary and secondary behaviors to evaluate steering effectiveness and behavioral entanglement centered around five popular steering methods. To enable this, we craft a modular steering framework based on unique components that serve as the building blocks of many existing methods. Our results on Qwen-2.5-7B and Llama-3.1-8B find that strong steering performance is dependent on the specific combination of steering method, model, and targeted behavior, and that severe concept entanglement can result from poor combinations of these three as well. We release our code here: this https URL. 

**Abstract (ZH)**: 我们介绍了SteeringControl，这是一个用于评估面向核心对齐目标（包括偏差、有害生成和幻觉）的表示对齐方法及其对奉承行为和常识道德等次要行为影响的基准。虽然之前的研究工作往往强调真实性或推理能力以展示表示对齐的副作用，但我们发现仍有许多未被系统探索的权衡关系。我们收集了一个与安全相关的主要和次要行为数据集，以评估基于五种流行对齐方法的对齐效果和行为纠缠。为此，我们基于独特的组件构建了一个模块化的对齐框架，这些组件是许多现有方法的构建块。我们在Qwen-2.5-7B和Llama-3.1-8B上的结果发现，强大的对齐性能依赖于特定的对齐方法、模型和目标行为的组合，而这些组合的不良匹配也会导致严重的概念纠缠。我们在这里发布了我们的代码：this https URL。 

---
# From Next Token Prediction to (STRIPS) World Models -- Preliminary Results 

**Title (ZH)**: 从下一个token预测到STRIPS世界模型——初步结果 

**Authors**: Carlos Núñez-Molina, Vicenç Gómez, Hector Geffner  

**Link**: [PDF](https://arxiv.org/pdf/2509.13389)  

**Abstract**: We consider the problem of learning propositional STRIPS world models from action traces alone, using a deep learning architecture (transformers) and gradient descent. The task is cast as a supervised next token prediction problem where the tokens are the actions, and an action $a$ may follow an action sequence if the hidden effects of the previous actions do not make an action precondition of $a$ false. We show that a suitable transformer architecture can faithfully represent propositional STRIPS world models, and that the models can be learned from sets of random valid (positive) and invalid (negative) action sequences alone. A number of experiments are reported. 

**Abstract (ZH)**: 仅从动作轨迹学习命题STRIPS世界模型：基于变压器和梯度下降的监督下一令牌预测问题 

---
# The Art of Saying "Maybe": A Conformal Lens for Uncertainty Benchmarking in VLMs 

**Title (ZH)**: 说出“可能”的艺术：面向VLMs不确定性基准测试的 conformal 视镜 

**Authors**: Asif Azad, Mohammad Sadat Hossain, MD Sadik Hossain Shanto, M Saifur Rahman, Md Rizwan Pervez  

**Link**: [PDF](https://arxiv.org/pdf/2509.13379)  

**Abstract**: Vision-Language Models (VLMs) have achieved remarkable progress in complex visual understanding across scientific and reasoning tasks. While performance benchmarking has advanced our understanding of these capabilities, the critical dimension of uncertainty quantification has received insufficient attention. Therefore, unlike prior conformal prediction studies that focused on limited settings, we conduct a comprehensive uncertainty benchmarking study, evaluating 16 state-of-the-art VLMs (open and closed-source) across 6 multimodal datasets with 3 distinct scoring functions. Our findings demonstrate that larger models consistently exhibit better uncertainty quantification; models that know more also know better what they don't know. More certain models achieve higher accuracy, while mathematical and reasoning tasks elicit poorer uncertainty performance across all models compared to other domains. This work establishes a foundation for reliable uncertainty evaluation in multimodal systems. 

**Abstract (ZH)**: 视觉-语言模型在复杂视觉理解任务中的不确定性量化研究 

---
# $Agent^2$: An Agent-Generates-Agent Framework for Reinforcement Learning Automation 

**Title (ZH)**: $Agent^2$: 一种 reinforcement learning 自动化代理生成代理框架 

**Authors**: Yuan Wei, Xiaohan Shan, Ran Miao, Jianmin Li  

**Link**: [PDF](https://arxiv.org/pdf/2509.13368)  

**Abstract**: Reinforcement learning agent development traditionally requires extensive expertise and lengthy iterations, often resulting in high failure rates and limited accessibility. This paper introduces $Agent^2$, a novel agent-generates-agent framework that achieves fully automated RL agent design through intelligent LLM-driven generation. The system autonomously transforms natural language task descriptions and environment code into comprehensive, high-performance reinforcement learning solutions without human intervention. $Agent^2$ features a revolutionary dual-agent architecture. The Generator Agent serves as an autonomous AI designer that analyzes tasks and generates executable RL agents, while the Target Agent is the resulting automatically generated RL agent. The framework decomposes RL development into two distinct stages: MDP modeling and algorithmic optimization, enabling more targeted and effective agent generation. Built on the Model Context Protocol, $Agent^2$ provides a unified framework that standardizes intelligent agent creation across diverse environments and algorithms, while incorporating adaptive training management and intelligent feedback analysis for continuous improvement. Extensive experiments on a wide range of benchmarks, including MuJoCo, MetaDrive, MPE, and SMAC, demonstrate that $Agent^2$ consistently outperforms manually designed solutions across all tasks, achieving up to 55% performance improvement and substantial gains on average. By enabling truly end-to-end, closed-loop automation, this work establishes a new paradigm in which intelligent agents design and optimize other agents, marking a fundamental breakthrough for automated AI systems. 

**Abstract (ZH)**: Reinforcement Learning 代理开发传统上需要 extensive 专业知识和长时间迭代，导致高失败率和有限的可访问性。本文介绍了一种名为 $Agent^2$ 的新型代理生成代理框架，该框架通过智能大模型驱动生成实现完全自动化的强化学习代理设计。该系统自主地将自然语言任务描述和环境代码转换为全面的高性能强化学习解决方案，无需人工干预。$Agent^2$ 配备了革命性的双代理架构。生成代理作为自主 AI 设计师，分析任务并生成可执行的强化学习代理，而目标代理是自动生成的强化学习代理。该框架将强化学习开发分解为两个不同的阶段：马尔可夫决策过程建模和算法优化，从而实现更针对性和有效的代理生成。基于 Model Context 协议，$Agent^2$ 提供了一个统一的框架，标准化了不同环境和算法的智能代理创建，并结合了适应性训练管理和智能反馈分析，以实现持续改进。在 MuJoCo、MetaDrive、MPE 和 SMAC 等广泛基准上的大量实验表明，$Agent^2$ 在所有任务上均能持续优于手动设计的解决方案，平均性能提升高达 55%，并带来显著的平均收益。通过实现真正的端到端、闭环自动化，这项工作建立了智能代理设计和优化其他代理的新范式，标志着自动化 AI 系统的一个根本性突破。 

---
# Asterisk Operator 

**Title (ZH)**: 阿斯特里克操作符 

**Authors**: Zixi Li  

**Link**: [PDF](https://arxiv.org/pdf/2509.13364)  

**Abstract**: We propose the \textbf{Asterisk Operator} ($\ast$-operator), a novel unified framework for abstract reasoning based on Adjacency-Structured Parallel Propagation (ASPP). The operator formalizes structured reasoning tasks as local, parallel state evolution processes guided by implicit relational graphs. We prove that the $\ast$-operator maintains local computational constraints while achieving global reasoning capabilities, providing an efficient and convergent computational paradigm for abstract reasoning problems. Through rigorous mathematical analysis and comprehensive experiments on ARC2 challenges and Conway's Game of Life, we demonstrate the operator's universality, convergence properties, and superior performance. Our innovative Embedding-Asterisk distillation method achieves 100\% accuracy on ARC2 validation with only 6M parameters, representing a significant breakthrough in neural-symbolic reasoning.
\textbf{Keywords:} Abstract Reasoning, Adjacency Structure, Parallel Propagation, Asterisk Operator, Convergence, Universal Approximation 

**Abstract (ZH)**: 我们提出了一种新的统一抽象推理框架——\textbf{星号运算符}（$\ast$-operator），基于邻接结构并行传播（ASPP）。该运算符将结构化推理任务形式化为由隐式关系图指导的局部并行状态演化过程。我们证明了星号运算符在保持局部计算约束的同时实现了全局推理能力，为抽象推理问题提供了一种高效且收敛的计算范式。通过严格的数学分析和在ARC2挑战和康威生命游戏上的全面实验，我们展示了该运算符的普适性、收敛特性和优越性能。我们的创新性嵌入星号运算符蒸馏方法在仅使用6M参数的情况下，在ARC2验证集上实现了100%的准确率，标志着神经符号推理领域的重要突破。

\textbf{关键词:} 抽象推理, 邻接结构, 并行传播, 星号运算符, 收敛, 普适逼近 

---
# Semantic Fusion with Fuzzy-Membership Features for Controllable Language Modelling 

**Title (ZH)**: 基于模糊成员hip特征的语义融合可控制语言建模 

**Authors**: Yongchao Huang, Hassan Raza  

**Link**: [PDF](https://arxiv.org/pdf/2509.13357)  

**Abstract**: We propose semantic fusion, a lightweight scheme that augments a Transformer language model (LM) with a parallel, fuzzy-membership feature channel that encodes token-level semantics. Each token is represented by a vector of interpretable features (e.g. part-of-speech cues, shallow roles, boundary flags, sentiment polarity and strength) whose values are graded degrees from differentiable membership functions (e.g. power kernels). These per-token vectors form a sentence-level semantic matrix fused via a gated adapter into the LM. Training uses standard next-token prediction, an auxiliary loss that reconstructs the semantic features from hidden states, and a lightweight uniformizer that regularizes adjective-class distributions. On a synthetic two-clause corpus with held-out adjectives for out-of-distribution (OOD) control, semantic fusion improves perplexity and enables precise, user-controllable generation of polarity and punctuation while maintaining model simplicity. This approach adds only small overhead, remains fully compatible with tied input-output embeddings, and provides an interpretable pathway for conditioned natural language generation. 

**Abstract (ZH)**: 我们提出了一种语义融合方法，这是一种轻量级方案，将Transformer语言模型（LM）与一个并行的模糊成员特征通道相结合，用于编码令牌级语义。每个令牌由一个可解释特征向量（例如，词性线索、浅层角色、边界标志、情感极性和强度）表示，这些特征值来自不同的可微隶属函数（例如，幂核）。这些令牌级别的向量形成了一个句级语义矩阵，通过门控适配器融合至LM中。训练使用标准的下一个令牌预测、一个辅助损失来重建隐藏状态中的语义特征，以及一个轻量级的规则化器来规整形容词类分布。在包含保留的形容词的合成双句语料库上，语义融合提高了困惑度，并使极性和标点的生成更加精确和用户可控，同时保持了模型的简洁性。这种方法仅增加了少量开销，完全兼容绑定的输入输出嵌入，并为条件自然语言生成提供了一条可解释的路径。 

---
# Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning 

**Title (ZH)**: 代理无人机：由LLM驱动的集成工具调用与认知推理自主性 

**Authors**: Anis Koubaa, Khaled Gabr  

**Link**: [PDF](https://arxiv.org/pdf/2509.13352)  

**Abstract**: Unmanned Aerial Vehicles (UAVs) are increasingly deployed in defense, surveillance, and disaster response, yet most systems remain confined to SAE Level 2--3 autonomy. Their reliance on rule-based control and narrow AI restricts adaptability in dynamic, uncertain missions. Existing UAV frameworks lack context-aware reasoning, autonomous decision-making, and ecosystem-level integration; critically, none leverage Large Language Model (LLM) agents with tool-calling for real-time knowledge access. This paper introduces the Agentic UAVs framework, a five-layer architecture (Perception, Reasoning, Action, Integration, Learning) that augments UAVs with LLM-driven reasoning, database querying, and third-party system interaction. A ROS2 and Gazebo-based prototype integrates YOLOv11 object detection with GPT-4 reasoning and local Gemma-3 deployment. In simulated search-and-rescue scenarios, agentic UAVs achieved higher detection confidence (0.79 vs. 0.72), improved person detection rates (91% vs. 75%), and markedly increased action recommendation (92% vs. 4.5%). These results confirm that modest computational overhead enables qualitatively new levels of autonomy and ecosystem integration. 

**Abstract (ZH)**: 基于大型语言模型的自主无人机框架 

---
# Teaching LLMs to Plan: Logical Chain-of-Thought Instruction Tuning for Symbolic Planning 

**Title (ZH)**: 教大语言模型规划：符号规划的逻辑链式思考指令调优 

**Authors**: Pulkit Verma, Ngoc La, Anthony Favier, Swaroop Mishra, Julie A. Shah  

**Link**: [PDF](https://arxiv.org/pdf/2509.13351)  

**Abstract**: Large language models (LLMs) have demonstrated impressive capabilities across diverse tasks, yet their ability to perform structured symbolic planning remains limited, particularly in domains requiring formal representations like the Planning Domain Definition Language (PDDL). In this paper, we present a novel instruction tuning framework, PDDL-Instruct, designed to enhance LLMs' symbolic planning capabilities through logical chain-of-thought reasoning. Our approach focuses on teaching models to rigorously reason about action applicability, state transitions, and plan validity using explicit logical inference steps. By developing instruction prompts that guide models through the precise logical reasoning required to determine when actions can be applied in a given state, we enable LLMs to self-correct their planning processes through structured reflection. The framework systematically builds verification skills by decomposing the planning process into explicit reasoning chains about precondition satisfaction, effect application, and invariant preservation. Experimental results on multiple planning domains show that our chain-of-thought reasoning based instruction-tuned models are significantly better at planning, achieving planning accuracy of up to 94% on standard benchmarks, representing a 66% absolute improvement over baseline models. This work bridges the gap between the general reasoning capabilities of LLMs and the logical precision required for automated planning, offering a promising direction for developing better AI planning systems. 

**Abstract (ZH)**: 大规模语言模型（LLMs）在各种任务中展示了令人印象深刻的性能，但在执行结构化符号计划方面的能力仍然有限，特别是在需要正式表示的领域如规划领域定义语言（PDDL）。本文介绍了一种新颖的指令调优框架PDDL-Instruct，旨在通过逻辑链式推理来增强LLMs的符号计划能力。我们的方法专注于教导模型如何严格地推理动作的应用性、状态转换和计划的有效性，利用明确的逻辑推理步骤。通过开发指令提示引导模型进行精确的逻辑推理，以确定在给定状态下哪些动作可以应用，从而通过结构化的反思使LLMs能够自我纠正其规划过程。框架系统性地通过将规划过程分解为预条件满足、效果应用和不变性保持的明确推理链来构建验证技能。在多个规划领域的实验结果表明，基于链式推理的指令调优模型在规划方面的表现显著提高，标准基准上的规划准确率达到94%，相比基线模型绝对提高了66%。本文填补了LLMs的通用推理能力和自动化规划所需的逻辑精确性之间的差距，为开发更好的AI规划系统提供了有前景的方向。 

---
# OpenHA: A Series of Open-Source Hierarchical Agentic Models in Minecraft 

**Title (ZH)**: OpenHA：Minecraft中的一系列开源分级代理模型 

**Authors**: Zihao Wang, Muyao Li, Kaichen He, Xiangyu Wang, Zhancun Mu, Anji Liu, Yitao Liang  

**Link**: [PDF](https://arxiv.org/pdf/2509.13347)  

**Abstract**: The choice of action spaces is a critical yet unresolved challenge in developing capable, end-to-end trainable agents. This paper first presents a large-scale, systematic comparison of prominent abstracted action spaces and tokenizers for Vision-Language-Action (VLA) or hierarchical agent models in the open-ended Minecraft. Our analysis reveals that no single action space is universally optimal; instead, the most effective abstraction is highly task-dependent, creating a dilemma for building generalist agents. To resolve this, we introduce Chain of Action (CoA), a novel framework that unifies high-level planning and low-level control within a single, monolithic VLA model. CoA treats an abstracted action not as a command for a separate policy, but as an intermediate reasoning step--akin to a chain of thought--that guides the generation of the final, executable action. Furthermore, we demonstrate that an All-in-One agent trained on a diverse mixture of action spaces using the CoA paradigm learns a more robust and generalizable policy. This unified agent achieves a new state-of-the-art, improving the overall task success rate over strong, specialized baselines. To foster reproducible research, we release the OpenHA (Open Hierarchical Agents) suite, which includes our comprehensive benchmark of over 800 distinct tasks, curated datasets, source code, and all pretrained model checkpoints at this https URL 

**Abstract (ZH)**: 行动空间的选择是开发具备端到端训练能力的智能代理的一个至关重要的但尚未解决的挑战。本文首先在开放世界Minecraft中系统比较了多种著名的抽象行动空间和标记化方法，涵盖视觉-语言-行动（VLA）或分层代理模型。我们的分析表明，并没有单一的行动空间是普适最优的；相反，最有效的抽象高度依赖于具体任务，这为构建通才代理带来了挑战。为了解决这一问题，我们引入了行动链（CoA）这一新颖框架，该框架在单一的、模块化的VLA模型中统一了高层规划和低层控制。CoA 将抽象动作视为一个逐步推理步骤——类似于思维链——引导生成最终可执行的动作。此外，我们证明，采用CoA框架在多种行动空间混合数据上进行训练的全功能代理学会了更加稳健和通用的策略。该统一代理在多个任务上的成功率超过专门基线，创造了新的研究前沿。为了促进可再现研究，我们发布了OpenHA（开放分层次代理）套件，包括超过800个独特任务的全面基准、精心策划的数据集、源代码和所有预训练模型检查点（https://openha.github.io）。 

---
# Imagined Autocurricula 

**Title (ZH)**: 想象自动生成课程 

**Authors**: Ahmet H. Güzel, Matthew Thomas Jackson, Jarek Luca Liesen, Tim Rocktäschel, Jakob Nicolaus Foerster, Ilija Bogunovic, Jack Parker-Holder  

**Link**: [PDF](https://arxiv.org/pdf/2509.13341)  

**Abstract**: Training agents to act in embodied environments typically requires vast training data or access to accurate simulation, neither of which exists for many cases in the real world. Instead, world models are emerging as an alternative leveraging offline, passively collected data, they make it possible to generate diverse worlds for training agents in simulation. In this work, we harness world models to generate imagined environments to train robust agents capable of generalizing to novel task variations. One of the challenges in doing this is ensuring the agent trains on useful generated data. We thus propose a novel approach, IMAC (Imagined Autocurricula), leveraging Unsupervised Environment Design (UED), which induces an automatic curriculum over generated worlds. In a series of challenging, procedurally generated environments, we show it is possible to achieve strong transfer performance on held-out environments, having trained only inside a world model learned from a narrower dataset. We believe this opens the path to utilizing larger-scale, foundation world models for generally capable agents. 

**Abstract (ZH)**: 利用世界模型生成想象环境训练 robust 代理以实现泛化的转移性能 

---
# Position: AI Safety Must Embrace an Antifragile Perspective 

**Title (ZH)**: AI安全必须采纳抗 fragility 观点 

**Authors**: Ming Jin, Hyunin Lee  

**Link**: [PDF](https://arxiv.org/pdf/2509.13339)  

**Abstract**: This position paper contends that modern AI research must adopt an antifragile perspective on safety -- one in which the system's capacity to guarantee long-term AI safety such as handling rare or out-of-distribution (OOD) events expands over time. Conventional static benchmarks and single-shot robustness tests overlook the reality that environments evolve and that models, if left unchallenged, can drift into maladaptation (e.g., reward hacking, over-optimization, or atrophy of broader capabilities). We argue that an antifragile approach -- Rather than striving to rapidly reduce current uncertainties, the emphasis is on leveraging those uncertainties to better prepare for potentially greater, more unpredictable uncertainties in the future -- is pivotal for the long-term reliability of open-ended ML systems. In this position paper, we first identify key limitations of static testing, including scenario diversity, reward hacking, and over-alignment. We then explore the potential of antifragile solutions to manage rare events. Crucially, we advocate for a fundamental recalibration of the methods used to measure, benchmark, and continually improve AI safety over the long term, complementing existing robustness approaches by providing ethical and practical guidelines towards fostering an antifragile AI safety community. 

**Abstract (ZH)**: this position paper 认为现代人工智能研究必须从抗脆性角度审视安全性——即系统的长期人工智能安全性能力，如处理稀有或分布外(OOD)事件的能力，会随时间不断增强。传统的静态基准和单次鲁棒性测试忽略了环境随时间变化的现实，如果模型不受挑战，它可能会逐渐适应不良（例如，奖励作弊、过度优化或更广泛的技能退化）。我们认为，一种抗脆性方法——重点不是迅速减少当前的不确定性和脆弱性，而是利用这些不确定性来更好地准备应对未来更大的、更加不可预测的不确定性——对于开放性机器学习系统的长期可靠性至关重要。在这篇立场论文中，我们首先识别出静态测试的关键局限性，包括场景多样性、奖励作弊和过度对齐。然后探讨抗脆性解决方案在管理稀有事件方面的潜力。至关重要的是，我们倡导对用于长期衡量、基准测试和提高人工智能安全性的方法进行根本性重新校准，补充现有的鲁棒性方法，通过提供伦理和实用指南来促进一个更加抗脆性的人工智能安全社区。 

---
# FRIT: Using Causal Importance to Improve Chain-of-Thought Faithfulness 

**Title (ZH)**: FRIT: 使用因果重要性提高链式思维的可靠性 

**Authors**: Anand Swaroop, Akshat Nallani, Saksham Uboweja, Adiliia Uzdenova, Michael Nguyen, Kevin Zhu, Sunishchal Dev, Ashwinee Panda, Vasu Sharma, Maheep Chaudhary  

**Link**: [PDF](https://arxiv.org/pdf/2509.13334)  

**Abstract**: Chain-of-thought (CoT) reasoning has emerged as a powerful tool for improving large language model performance on complex tasks, but recent work shows that reasoning steps often fail to causally influence the final answer, creating brittle and untrustworthy outputs. Prior approaches focus primarily on measuring faithfulness, while methods for systematically improving it remain limited. We introduce Faithful Reasoning via Intervention Training (FRIT), a scalable alignment method that trains models to produce causally consistent reasoning by learning from systematically corrupted examples. FRIT generates synthetic training data by intervening on individual reasoning steps in model-generated CoTs, creating faithful/unfaithful pairs that highlight when reasoning breaks down. We then apply Direct Preference Optimization to teach models to prefer causally consistent reasoning paths. Evaluating on Qwen3-8B and Mistral-7B-v0.1 across factual and symbolic reasoning tasks, FRIT increases faithful reasoning by $3.4$ percentage points for Mistral on GSM8K while improving accuracy by $7.6$ percentage points. Our approach provides the first scalable, supervision-free method for training language models to produce more reliable and interpretable reasoning, addressing a critical gap between reasoning performance and trustworthiness. We release our code at \href{this https URL}. 

**Abstract (ZH)**: Faithful Reasoning via Intervention Training: A Scalable Method for Enhancing Causal Consistency in Large Language Models 

---
# Evaluation Awareness Scales Predictably in Open-Weights Large Language Models 

**Title (ZH)**: 评价意识量表可预测地适用于开放权重大型语言模型 

**Authors**: Maheep Chaudhary, Ian Su, Nikhil Hooda, Nishith Shankar, Julia Tan, Kevin Zhu, Ashwinee Panda, Ryan Lagasse, Vasu Sharma  

**Link**: [PDF](https://arxiv.org/pdf/2509.13333)  

**Abstract**: Large language models (LLMs) can internally distinguish between evaluation and deployment contexts, a behaviour known as \emph{evaluation awareness}. This undermines AI safety evaluations, as models may conceal dangerous capabilities during testing. Prior work demonstrated this in a single $70$B model, but the scaling relationship across model sizes remains unknown. We investigate evaluation awareness across $15$ models scaling from $0.27$B to $70$B parameters from four families using linear probing on steering vector activations. Our results reveal a clear power-law scaling: evaluation awareness increases predictably with model size. This scaling law enables forecasting deceptive behavior in future larger models and guides the design of scale-aware evaluation strategies for AI safety. A link to the implementation of this paper can be found at this https URL. 

**Abstract (ZH)**: 大规模语言模型（LLMs）能够在内部区分评估和部署上下文，这种行为被称为“评估意识”。这一行为损害了AI安全性评估，因为模型在测试过程中可能会隐藏危险的功能。此前的研究已经在单一的70亿参数模型中证明了这一点，但不同规模模型之间的扩展关系仍不清楚。我们使用线性探针对控制向量激活进行了研究，调查了来自四个模型家族的15个从0.27亿到70亿参数的模型的评估意识。研究结果揭示了一种明确的幂律 scaling 规律：评估意识随模型规模的增加而可预测地增加。这种 scaling 规律能够帮助预测未来更大模型中的欺骗性行为，并指导AI安全性中的规模意识评估策略的设计。本文的实现链接为：这个 https URL。 

---
# Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness 

**Title (ZH)**: 明示推理使法官更优秀：关于准确度、效率和稳健性的系统研究 

**Authors**: Pratik Jayarao, Himanshu Gupta, Neeraj Varshney, Chaitanya Dwivedi  

**Link**: [PDF](https://arxiv.org/pdf/2509.13332)  

**Abstract**: As Large Language Models (LLMs) are increasingly adopted as automated judges in benchmarking and reward modeling, ensuring their reliability, efficiency, and robustness has become critical. In this work, we present a systematic comparison of "thinking" and "non-thinking" LLMs in the LLM-as-a-judge paradigm using open-source Qwen 3 models of relatively small sizes (0.6B, 1.7B, and 4B parameters). We evaluate both accuracy and computational efficiency (FLOPs) on RewardBench tasks, and further examine augmentation strategies for non-thinking models, including in-context learning, rubric-guided judging, reference-based evaluation, and n-best aggregation. Our results show that despite these enhancements, non-thinking models generally fall short of their thinking counterparts. Our results show that thinking models achieve approximately 10% points higher accuracy with little overhead (under 2x), in contrast to augmentation strategies like few-shot learning, which deliver modest gains at a higher cost (>8x). Bias and robustness analyses further demonstrate that thinking models maintain significantly greater consistency under a variety of bias conditions such as positional, bandwagon, identity, diversity, and random biases (6% higher on average). We further extend our experiments to the multilingual setting and our results confirm that explicit reasoning extends its benefits beyond English. Overall, our work results in several important findings that provide systematic evidence that explicit reasoning offers clear advantages in the LLM-as-a-judge paradigm not only in accuracy and efficiency but also in robustness. 

**Abstract (ZH)**: 随着大型语言模型（LLMs）在基准测试和奖励建模中被越来越频繁地用作自动化法官，确保其可靠性和效率以及增强其稳健性变得至关重要。在本文中，我们使用开源的相对较小规模的Qwen 3模型（0.6B、1.7B和4B参数）对“思考型”和“非思考型”LLMs在LLM-as-a-judge范式下进行了系统的比较。我们在RewardBench任务中评估了准确性及计算效率（FLOPs），并进一步探讨了非思考模型的增强策略，包括上下文内学习、评分表指导判断、参考基评估和n-best聚合。结果显示，尽管进行了这些增强，非思考模型通常仍不及思考模型。思考模型的准确性大约高出10个百分点，且额外开销不到2倍，相比之下，如少样本学习等增强策略虽然成本较高（超过8倍），但仅带来微弱的增益。进一步的偏见和稳健性分析表明，思考模型在各种偏见条件（位置偏见、羊群效应偏见、身份偏见、多样性和随机偏见）下具有明显更高的一致性（平均高出6个百分点）。此外，我们将实验扩展至多语言环境，结果证实明确推理在英语之外的语言中也能够带来益处。总体而言，我们的工作得出几个重要结论，提供了系统性的证据表明，明确推理不仅在准确性及效率方面，在稳健性方面也提供了显而易见的优势。 

---
# Apertus: Democratizing Open and Compliant LLMs for Global Language Environments 

**Title (ZH)**: Apertus: 为全球语言环境民主化开放和合规的LLM 

**Authors**: Alejandro Hernández-Cano, Alexander Hägele, Allen Hao Huang, Angelika Romanou, Antoni-Joan Solergibert, Barna Pasztor, Bettina Messmer, Dhia Garbaya, Eduard Frank Ďurech, Ido Hakimi, Juan García Giraldo, Mete Ismayilzada, Negar Foroutan, Skander Moalla, Tiancheng Chen, Vinko Sabolčec, Yixuan Xu, Michael Aerni, Badr AlKhamissi, Ines Altemir Marinas, Mohammad Hossein Amani, Matin Ansaripour, Ilia Badanin, Harold Benoit, Emanuela Boros, Nicholas Browning, Fabian Bösch, Maximilian Böther, Niklas Canova, Camille Challier, Clement Charmillot, Jonathan Coles, Jan Deriu, Arnout Devos, Lukas Drescher, Daniil Dzenhaliou, Maud Ehrmann, Dongyang Fan, Simin Fan, Silin Gao, Miguel Gila, María Grandury, Diba Hashemi, Alexander Hoyle, Jiaming Jiang, Mark Klein, Andrei Kucharavy, Anastasiia Kucherenko, Frederike Lübeck, Roman Machacek, Theofilos Manitaras, Andreas Marfurt, Kyle Matoba, Simon Matrenok, Henrique Mendoncça, Fawzi Roberto Mohamed, Syrielle Montariol, Luca Mouchel, Sven Najem-Meyer, Jingwei Ni, Gennaro Oliva, Matteo Pagliardini, Elia Palme, Andrei Panferov, Léo Paoletti, Marco Passerini, Ivan Pavlov, Auguste Poiroux, Kaustubh Ponkshe, Nathan Ranchin, Javi Rando, Mathieu Sauser, Jakhongir Saydaliev, Muhammad Ali Sayfiddinov, Marian Schneider, Stefano Schuppli, Marco Scialanga, Andrei Semenov, Kumar Shridhar, Raghav Singhal, Anna Sotnikova, Alexander Sternfeld, Ayush Kumar Tarun, Paul Teiletche, Jannis Vamvas, Xiaozhe Yao, Hao Zhao Alexander Ilic, Ana Klimovic, Andreas Krause, Caglar Gulcehre, David Rosenthal, Elliott Ash, Florian Tramèr, Joost VandeVondele, Livio Veraldi, Martin Rajman, Thomas Schulthess, Torsten Hoefler, Antoine Bosselut, Martin Jaggi, Imanol Schlag  

**Link**: [PDF](https://arxiv.org/pdf/2509.14233)  

**Abstract**: We present Apertus, a fully open suite of large language models (LLMs) designed to address two systemic shortcomings in today's open model ecosystem: data compliance and multilingual representation. Unlike many prior models that release weights without reproducible data pipelines or regard for content-owner rights, Apertus models are pretrained exclusively on openly available data, retroactively respecting this http URL exclusions and filtering for non-permissive, toxic, and personally identifiable content. To mitigate risks of memorization, we adopt the Goldfish objective during pretraining, strongly suppressing verbatim recall of data while retaining downstream task performance. The Apertus models also expand multilingual coverage, training on 15T tokens from over 1800 languages, with ~40% of pretraining data allocated to non-English content. Released at 8B and 70B scales, Apertus approaches state-of-the-art results among fully open models on multilingual benchmarks, rivalling or surpassing open-weight counterparts. Beyond model weights, we release all scientific artifacts from our development cycle with a permissive license, including data preparation scripts, checkpoints, evaluation suites, and training code, enabling transparent audit and extension. 

**Abstract (ZH)**: 我们提出Apertus，一个完全开源的大语言模型套件，旨在解决当今开放模型生态系统中的两大系统性问题：数据合规和多语言表示。与许多先前提供权重而不具备可复现的数据管道或尊重内容所有者权益的模型不同，Apertus模型仅在公开可用的数据上进行预训练， retroactively 尊重了特定排除要求，并过滤掉了非许可、有毒和个人可识别信息的内容。为减轻记忆风险，在预训练过程中我们采用了Goldfish目标，强烈抑制数据的原样回忆，同时保留下游任务性能。Apertus模型还扩展了多语言覆盖面，训练数据来自超过1800种语言，其中约40%的预训练数据用于非英语内容。在8B和70B规模下发布时，Apertus在多语言基准测试中接近最先进成果，与开放权重的同类模型相当或超越之。除了模型权重，我们还以宽松许可发布了整个开发周期中的所有科学研究成果，包括数据准备脚本、检查点、评估套件和训练代码，以实现透明审查和扩展。 

---
# Language models' activations linearly encode training-order recency 

**Title (ZH)**: 语言模型的激活按照训练顺序 recentness 线性编码 

**Authors**: Dmitrii Krasheninnikov, Richard E. Turner, David Krueger  

**Link**: [PDF](https://arxiv.org/pdf/2509.14223)  

**Abstract**: We show that language models' activations linearly encode when information was learned during training. Our setup involves creating a model with a known training order by sequentially fine-tuning Llama-3.2-1B on six disjoint but otherwise similar datasets about named entities. We find that the average activations of test samples for the six training datasets encode the training order: when projected into a 2D subspace, these centroids are arranged exactly in the order of training and lie on a straight line. Further, we show that linear probes can accurately (~90%) distinguish "early" vs. "late" entities, generalizing to entities unseen during the probes' own training. The model can also be fine-tuned to explicitly report an unseen entity's training stage (~80% accuracy). Interestingly, this temporal signal does not seem attributable to simple differences in activation magnitudes, losses, or model confidence. Our paper demonstrates that models are capable of differentiating information by its acquisition time, and carries significant implications for how they might manage conflicting data and respond to knowledge modifications. 

**Abstract (ZH)**: 语言模型的激活在训练过程中线性编码了信息学习的顺序 

---
# A Universal Banach--Bregman Framework for Stochastic Iterations: Unifying Stochastic Mirror Descent, Learning and LLM Training 

**Title (ZH)**: 一类适用于随机迭代的通用Banach-Bregman框架：统一随机镜像下降、学习和大模型训练 

**Authors**: Johnny R. Zhang, Xiaomei Mi, Gaoyuan Du, Qianyi Sun, Shiqi Wang, Jiaxuan Li, Wenhua Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2509.14216)  

**Abstract**: Stochastic optimization powers the scalability of modern artificial intelligence, spanning machine learning, deep learning, reinforcement learning, and large language model training. Yet, existing theory remains largely confined to Hilbert spaces, relying on inner-product frameworks and orthogonality. This paradigm fails to capture non-Euclidean settings, such as mirror descent on simplices, Bregman proximal methods for sparse learning, natural gradient descent in information geometry, or Kullback--Leibler-regularized language model training. Unlike Euclidean-based Hilbert-space methods, this approach embraces general Banach spaces. This work introduces a pioneering Banach--Bregman framework for stochastic iterations, establishing Bregman geometry as a foundation for next-generation optimization. It (i) provides a unified template via Bregman projections and Bregman--Fejer monotonicity, encompassing stochastic approximation, mirror descent, natural gradient, adaptive methods, and mirror-prox; (ii) establishes super-relaxations ($\lambda > 2$) in non-Hilbert settings, enabling flexible geometries and elucidating their acceleration effect; and (iii) delivers convergence theorems spanning almost-sure boundedness to geometric rates, validated on synthetic and real-world tasks. Empirical studies across machine learning (UCI benchmarks), deep learning (e.g., Transformer training), reinforcement learning (actor--critic), and large language models (WikiText-2 with distilGPT-2) show up to 20% faster convergence, reduced variance, and enhanced accuracy over classical baselines. These results position Banach--Bregman geometry as a cornerstone unifying optimization theory and practice across core AI paradigms. 

**Abstract (ZH)**: Banach-Bregman框架赋能现代人工智能的可扩展性：超越欧几里得空间的随机优化理论 

---
# Dense Video Understanding with Gated Residual Tokenization 

**Title (ZH)**: 基于门控残差化令牌化的大密度视频理解 

**Authors**: Haichao Zhang, Wenhao Chai, Shwai He, Ang Li, Yun Fu  

**Link**: [PDF](https://arxiv.org/pdf/2509.14199)  

**Abstract**: High temporal resolution is essential for capturing fine-grained details in video understanding. However, current video large language models (VLLMs) and benchmarks mostly rely on low-frame-rate sampling, such as uniform sampling or keyframe selection, discarding dense temporal information. This compromise avoids the high cost of tokenizing every frame, which otherwise leads to redundant computation and linear token growth as video length increases. While this trade-off works for slowly changing content, it fails for tasks like lecture comprehension, where information appears in nearly every frame and requires precise temporal alignment. To address this gap, we introduce Dense Video Understanding (DVU), which enables high-FPS video comprehension by reducing both tokenization time and token overhead. Existing benchmarks are also limited, as their QA pairs focus on coarse content changes. We therefore propose DIVE (Dense Information Video Evaluation), the first benchmark designed for dense temporal reasoning. To make DVU practical, we present Gated Residual Tokenization (GRT), a two-stage framework: (1) Motion-Compensated Inter-Gated Tokenization uses pixel-level motion estimation to skip static regions during tokenization, achieving sub-linear growth in token count and compute. (2) Semantic-Scene Intra-Tokenization Merging fuses tokens across static regions within a scene, further reducing redundancy while preserving dynamic semantics. Experiments on DIVE show that GRT outperforms larger VLLM baselines and scales positively with FPS. These results highlight the importance of dense temporal information and demonstrate that GRT enables efficient, scalable high-FPS video understanding. 

**Abstract (ZH)**: 高时间分辨率对于视频理解中捕捉细粒度细节至关重要。然而，当前的视频大规模语言模型（VLLMs）和基准主要依赖于低帧率采样，如均匀采样或关键帧选择，从而丢弃了密集的时间信息。这种权衡避免了对每一帧进行分词所导致的高成本，否则会导致冗余计算和随视频长度增加呈线性增长的分词数量。虽然这种权衡对于缓慢变化的内容有效，但对于讲义理解等任务来说却不合适，这类任务中信息几乎出现在每一帧中，并需要精确的时间对齐。为解决这一差距，我们引入了密集视频理解（DVU），它通过减少分词时间和分词开销，使高帧率视频理解成为可能。现有的基准也有局限性，因为它们的问答对主要关注粗粒度的内容变化。因此，我们提出了DIVE（密集信息视频评估）作为第一个专为密集时间推理设计的基准。为了使DVU实用化，我们提出了门控残差分词（GRT），这是一种两阶段框架：（1）运动补偿跨门分词利用像素级别的运动估计，在分词过程中跳过静态区域，实现分词数量和计算量的次线性增长；（2）语义场景内分词合并将场景内静态区域的分词合并，进一步减少冗余，同时保留动态语义。在DIVE上的实验结果显示，GRT比更大规模的VLLM基线表现出色，并且随着帧率增加呈现出正向扩展。这些结果突显了密集时间信息的重要性，并证明了GRT能够实现高效的、可扩展的高帧率视频理解。 

---
# Bridging Past and Future: Distribution-Aware Alignment for Time Series Forecasting 

**Title (ZH)**: 连接过去与未来：基于分布的时序预测对齐方法 

**Authors**: Yifan Hu, Jie Yang, Tian Zhou, Peiyuan Liu, Yujin Tang, Rong Jin, Liang Sun  

**Link**: [PDF](https://arxiv.org/pdf/2509.14181)  

**Abstract**: Representation learning techniques like contrastive learning have long been explored in time series forecasting, mirroring their success in computer vision and natural language processing. Yet recent state-of-the-art (SOTA) forecasters seldom adopt these representation approaches because they have shown little performance advantage. We challenge this view and demonstrate that explicit representation alignment can supply critical information that bridges the distributional gap between input histories and future targets. To this end, we introduce TimeAlign, a lightweight, plug-and-play framework that learns auxiliary features via a simple reconstruction task and feeds them back to any base forecaster. Extensive experiments across eight benchmarks verify its superior performance. Further studies indicate that the gains arises primarily from correcting frequency mismatches between historical inputs and future outputs. We also provide a theoretical justification for the effectiveness of TimeAlign in increasing the mutual information between learned representations and predicted targets. As it is architecture-agnostic and incurs negligible overhead, TimeAlign can serve as a general alignment module for modern deep learning time-series forecasting systems. The code is available at this https URL. 

**Abstract (ZH)**: 时间序列预测中的表示学习技术，如对比学习，长期以来一直得到了探索，它们在计算机视觉和自然语言处理领域的成功得到了映射。然而，近期的最先进的（SOTA）预测器很少采用这些表示方法，因为它们并未显示出明显的性能优势。我们挑战这一观点，并证明显式的表示对齐可以提供关键信息，以弥合输入历史与未来目标之间的分布差距。为此，我们引入了TimeAlign，一种轻量级、即插即用的框架，通过简单的重构任务学习辅助特征，并将其反馈给任何基础预测器。广泛的实验跨八个基准验证了其优越的性能。进一步的研究表明，这些收益主要来自于纠正历史输入与未来输出之间的频率不匹配。我们还为TimeAlign如何通过增加学习表示与预测目标之间的 mutual information 有效性提供了理论依据。由于它对架构无依赖且几乎不增加开销，TimeAlign 可以作为现代深度学习时间序列预测系统的通用对齐模块。代码可在以下链接获取：this https URL。 

---
# Synthesizing Behaviorally-Grounded Reasoning Chains: A Data-Generation Framework for Personal Finance LLMs 

**Title (ZH)**: 基于行为grounded推理链合成：个人金融LLM的数据生成框架 

**Authors**: Akhil Theerthala  

**Link**: [PDF](https://arxiv.org/pdf/2509.14180)  

**Abstract**: Personalized financial advice requires consideration of user goals, constraints, risk tolerance, and jurisdiction. Prior LLM work has focused on support systems for investors and financial planners. Simultaneously, numerous recent studies examine broader personal finance tasks, including budgeting, debt management, retirement, and estate planning, through agentic pipelines that incur high maintenance costs, yielding less than 25% of their expected financial returns. In this study, we introduce a novel and reproducible framework that integrates relevant financial context with behavioral finance studies to construct supervision data for end-to-end advisors. Using this framework, we create a 19k sample reasoning dataset and conduct a comprehensive fine-tuning of the Qwen-3-8B model on the dataset. Through a held-out test split and a blind LLM-jury study, we demonstrate that through careful data curation and behavioral integration, our 8B model achieves performance comparable to significantly larger baselines (14-32B parameters) across factual accuracy, fluency, and personalization metrics while incurring 80% lower costs than the larger counterparts. 

**Abstract (ZH)**: 个性化财务建议需要考虑用户目标、约束、风险承受能力和管辖地。先前的LLM研究主要集中在投资者和财务规划者的支持系统上。同时，许多近期研究表明，通过代理管道来探讨更广泛的个人财务管理任务（包括预算、债务管理、退休和遗产规划），尽管维护成本高昂，但仅能实现预期财务回报的不到25%。在本研究中，我们介绍了一种新颖且可复制的框架，该框架将相关财务背景与行为金融研究结合起来构建端到端顾问的监督数据。利用该框架，我们创建了一个包含19,000个样本的推理数据集，并在数据集上对Qwen-3-8B模型进行了全面微调。通过保留测试拆分和盲测LLM法官研究，我们证明，通过细致的数据整理和行为整合，我们的8B模型在事实准确性、流畅性和个性化指标上达到了与显著更大的基准模型（14-32B参数）相当的性能，同时成本降低了80%。 

---
# TGPO: Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning 

**Title (ZH)**: TGPO：树引导的偏好优化以实现鲁棒的Web代理强化学习 

**Authors**: Ziyuan Chen, Zhenghui Zhao, Zhangye Han, Miancan Liu, Xianhang Ye, Yiqing Li, Hongbo Min, Jinkui Ren, Xiantao Zhang, Guitao Cao  

**Link**: [PDF](https://arxiv.org/pdf/2509.14172)  

**Abstract**: With the rapid advancement of large language models and vision-language models, employing large models as Web Agents has become essential for automated web interaction. However, training Web Agents with reinforcement learning faces critical challenges including credit assignment misallocation, prohibitively high annotation costs, and reward sparsity. To address these issues, we propose Tree-Guided Preference Optimization (TGPO), an offline reinforcement learning framework that proposes a tree-structured trajectory representation merging semantically identical states across trajectories to eliminate label conflicts. Our framework incorporates a Process Reward Model that automatically generates fine-grained rewards through subgoal progress, redundancy detection, and action verification. Additionally, a dynamic weighting mechanism prioritizes high-impact decision points during training. Experiments on Online-Mind2Web and our self-constructed C-WebShop datasets demonstrate that TGPO significantly outperforms existing methods, achieving higher success rates with fewer redundant steps. 

**Abstract (ZH)**: 基于树引导的偏好优化：面向Web交互的离线强化学习框架 

---
# Where Do Tokens Go? Understanding Pruning Behaviors in STEP at High Resolutions 

**Title (ZH)**: Where Do Tokens Go? 理解高分辨率下STEP中的剪枝行为 

**Authors**: Michal Szczepanski, Martyna Poreba, Karim Haroun  

**Link**: [PDF](https://arxiv.org/pdf/2509.14165)  

**Abstract**: Vision Transformers (ViTs) achieve state-of-the-art performance in semantic segmentation but are hindered by high computational and memory costs. To address this, we propose STEP (SuperToken and Early-Pruning), a hybrid token-reduction framework that combines dynamic patch merging and token pruning to enhance efficiency without significantly compromising accuracy. At the core of STEP is dCTS, a lightweight CNN-based policy network that enables flexible merging into superpatches. Encoder blocks integrate also early-exits to remove high-confident supertokens, lowering computational load. We evaluate our method on high-resolution semantic segmentation benchmarks, including images up to 1024 x 1024, and show that when dCTS is applied alone, the token count can be reduced by a factor of 2.5 compared to the standard 16 x 16 pixel patching scheme. This yields a 2.6x reduction in computational cost and a 3.4x increase in throughput when using ViT-Large as the backbone. Applying the full STEP framework further improves efficiency, reaching up to a 4x reduction in computational complexity and a 1.7x gain in inference speed, with a maximum accuracy drop of no more than 2.0%. With the proposed STEP configurations, up to 40% of tokens can be confidently predicted and halted before reaching the final encoder layer. 

**Abstract (ZH)**: Vision Transformers (ViTs) 的视觉分割性能出众但受到高计算和内存成本的限制。为此，我们提出了STEP（SuperToken和Early-Pruning）框架，该框架结合了动态.patch合并和令牌剪枝，旨在提高效率同时不显著牺牲准确度。STEP的核心是dCTS，这是一种轻量级的基于CNN的策略网络，实现灵活的超patch合并。编码块还集成了早期退出机制，以移除高置信度的超令牌，从而降低计算负担。我们在高分辨率语义分割基准上评估了该方法，包括1024 x 1024像素大小的图像，结果显示，当单独应用dCTS时，与标准的16 x 16像素划分方案相比，令牌数量可减少2.5倍。这使计算成本降低2.6倍，并在使用ViT-Large作为骨干网络时将吞吐量提高3.4倍。完全应用STEP框架进一步提高了效率，计算复杂度最多可降低4倍，推理速度提升1.7倍，准确率下降不超过2%。通过提出STEP配置，可最多在最终编码层之前置信地预测和停止40%的令牌。 

---
# Reasoning Efficiently Through Adaptive Chain-of-Thought Compression: A Self-Optimizing Framework 

**Title (ZH)**: 自优化框架下通过自适应链式思考压缩高效推理 

**Authors**: Kerui Huang, Shuhan Liu, Xing Hu, Tongtong Xu, Lingfeng Bao, Xin Xia  

**Link**: [PDF](https://arxiv.org/pdf/2509.14093)  

**Abstract**: Chain-of-Thought (CoT) reasoning enhances Large Language Models (LLMs) by prompting intermediate steps, improving accuracy and robustness in arithmetic, logic, and commonsense tasks. However, this benefit comes with high computational costs: longer outputs increase latency, memory usage, and KV-cache demands. These issues are especially critical in software engineering tasks where concise and deterministic outputs are required. To investigate these trade-offs, we conduct an empirical study based on code generation benchmarks. The results reveal that longer CoT does not always help. Excessive reasoning often causes truncation, accuracy drops, and latency up to five times higher, with failed outputs consistently longer than successful ones. These findings challenge the assumption that longer reasoning is inherently better and highlight the need for adaptive CoT control. Motivated by this, we propose SEER (Self-Enhancing Efficient Reasoning), an adaptive framework that compresses CoT while preserving accuracy. SEER combines Best-of-N sampling with task-aware adaptive filtering, dynamically adjusting thresholds based on pre-inference outputs to reduce verbosity and computational overhead. We then evaluate SEER on three software engineering tasks and one math task. On average, SEER shortens CoT by 42.1%, improves accuracy by reducing truncation, and eliminates most infinite loops. These results demonstrate SEER as a practical method to make CoT-enhanced LLMs more efficient and robust, even under resource constraints. 

**Abstract (ZH)**: Chain-of-Thought推理提高大型语言模型的效率与适应性：基于软件工程任务的实证研究与自我增强高效推理框架SEER 

---
# Queen Detection in Beehives via Environmental Sensor Fusion for Low-Power Edge Computing 

**Title (ZH)**: 基于环境传感器融合的低功耗边缘计算蜜蜂王后检测 

**Authors**: Chiara De Luca, Elisa Donati  

**Link**: [PDF](https://arxiv.org/pdf/2509.14061)  

**Abstract**: Queen bee presence is essential for the health and stability of honeybee colonies, yet current monitoring methods rely on manual inspections that are labor-intensive, disruptive, and impractical for large-scale beekeeping. While recent audio-based approaches have shown promise, they often require high power consumption, complex preprocessing, and are susceptible to ambient noise. To overcome these limitations, we propose a lightweight, multimodal system for queen detection based on environmental sensor fusion-specifically, temperature, humidity, and pressure differentials between the inside and outside of the hive. Our approach employs quantized decision tree inference on a commercial STM32 microcontroller, enabling real-time, low-power edge computing without compromising accuracy. We show that our system achieves over 99% queen detection accuracy using only environmental inputs, with audio features offering no significant performance gain. This work presents a scalable and sustainable solution for non-invasive hive monitoring, paving the way for autonomous, precision beekeeping using off-the-shelf, energy-efficient hardware. 

**Abstract (ZH)**: 女王蜂的存在对于蜜蜂群体的健康和稳定性至关重要，但当前的监测方法依赖于劳动密集型、干扰性强且不适合大规模养蜂的目视检查。虽然Recent的基于音频的方法显示出希望，但它们通常需要高能耗、复杂的预处理，并且容易受到环境噪音的影响。为克服这些局限性，我们提出了一种基于环境传感器融合的轻量化多模态女王检测系统，具体而言，是基于蜂箱内外的温度、湿度和压力差异。我们的方法在商用STM32微控制器上实现量化决策树推理，能够在不牺牲准确性的前提下实现实时低能耗边缘计算。实验结果显示，仅使用环境输入，我们的系统实现了超过99%的女王检测准确率，而音频特征并未提供显著性能提升。本工作提出了一种可扩展且可持续的非侵入式蜂箱监测解决方案，为使用现成的节能硬件实现自主、精准养蜂铺平了道路。 

---
# Machines are more productive than humans until they aren't, and vice versa 

**Title (ZH)**: 机器在某些时候比人类更高效，而在其他时候则不然，反之亦然。 

**Authors**: Riccardo Zanardelli  

**Link**: [PDF](https://arxiv.org/pdf/2509.14057)  

**Abstract**: With the growth of artificial skills, organizations may increasingly confront with the problem of optimizing skill policy decisions guided by economic principles. This paper addresses the underlying complexity of this challenge by developing an in-silico framework based on Monte Carlo simulations grounded in empirical realism to analyze the economic impact of human and machine skills, individually or jointly deployed, in the execution of tasks presenting varying levels of complexity. Our results provide quantitative support for the established notions that automation tends to be the most economically-effective strategy for tasks characterized by low-to-medium generalization difficulty, while automation struggles to match the economic utility of human skills in more complex scenarios. Critically, our simulations highlight that combining human and machine skills can be the most effective strategy when a high level of generalization is required, but only if genuine augmentation is achieved. In contrast, when failing to realize this synergy, the human-machine policy is severely penalized by the inherent costs of its dual skill structure, causing it to destroy value and becoming the worst choice from an economic perspective. The takeaway for decision-makers is unambiguous: simply allocating human and machine skills to a task is insufficient, and a human-machine skill policy is neither a silver-bullet solution nor a low-risk compromise. Rather, it is a critical opportunity to boost competitiveness that demands a strong organizational commitment to enabling augmentation. Also, our findings show that improving the cost-effectiveness of machine skills over time, while useful, does not replace the fundamental need to focus on achieving augmentation. 

**Abstract (ZH)**: 随着人工技能的增长，组织可能越来越多地面临优化由经济原则引导的技能政策决策的复杂问题。本文通过基于蒙特卡洛模拟的拟实框架来研究这一挑战的基础复杂性，以此分析人类和机器技能单独或联合执行具有不同复杂程度任务时的经济影响。我们的研究结果为现有观点提供了定量支持，即自动化通常是低至中等泛化难度任务最具经济效率的策略，而在更复杂的场景中，自动化难以匹配人类技能的经济价值。关键的是，我们的模拟结果显示，当需要高泛化能力时，结合人类和机器技能可能是最有效的策略，但这必须实现真正的增强。相反，未能实现这种协同效应时，人机政策因其双重技能结构的固有成本而受到严重惩罚，导致从经济角度看是最差的选择。决策者应清晰理解：仅仅将人类和机器技能分配给任务是不够的，人机技能政策既不是万能的解决方案，也不是低风险的妥协，而是一个提升竞争力的契机，需要组织有强大的承诺来实现增强。此外，我们的研究结果表明，随着时间的推移提高机器技能的成本效益虽然有用，但并不能替代实现增强的基本需求。 

---
# Comprehensive Evaluation of CNN-Based Audio Tagging Models on Resource-Constrained Devices 

**Title (ZH)**: 基于CNN的音频标签模型在资源受限设备上的综合评估 

**Authors**: Jordi Grau-Haro, Ruben Ribes-Serrano, Javier Naranjo-Alcazar, Marta Garcia-Ballesteros, Pedro Zuccarello  

**Link**: [PDF](https://arxiv.org/pdf/2509.14049)  

**Abstract**: Convolutional Neural Networks (CNNs) have demonstrated exceptional performance in audio tagging tasks. However, deploying these models on resource-constrained devices like the Raspberry Pi poses challenges related to computational efficiency and thermal management. In this paper, a comprehensive evaluation of multiple convolutional neural network (CNN) architectures for audio tagging on the Raspberry Pi is conducted, encompassing all 1D and 2D models from the Pretrained Audio Neural Networks (PANNs) framework, a ConvNeXt-based model adapted for audio classification, as well as MobileNetV3 architectures. In addition, two PANNs-derived networks, CNN9 and CNN13, recently proposed, are also evaluated. To enhance deployment efficiency and portability across diverse hardware platforms, all models are converted to the Open Neural Network Exchange (ONNX) format. Unlike previous works that focus on a single model, our analysis encompasses a broader range of architectures and involves continuous 24-hour inference sessions to assess performance stability. Our experiments reveal that, with appropriate model selection and optimization, it is possible to maintain consistent inference latency and manage thermal behavior effectively over extended periods. These findings provide valuable insights for deploying audio tagging models in real-world edge computing scenarios. 

**Abstract (ZH)**: 卷积神经网络（CNNs）在音频标签任务中展现了卓越的性能。然而，在如Raspberry Pi这样的资源受限设备上部署这些模型面临着计算效率和热管理方面的挑战。在本文中，我们对多种卷积神经网络（CNN）架构在Raspberry Pi上的音频标签任务进行了全面评估，包括Pretrained Audio Neural Networks（PANNs）框架中的所有1D和2D模型、基于ConvNeXt的适应音频分类模型以及MobileNetV3架构。此外，我们还评估了两种从PANNs衍生出来的网络，即CNN9和CNN13。为了提高部署效率并增强跨多种硬件平台的可移植性，所有模型都转换为了Open Neural Network Exchange（ONNX）格式。与以往专注于单一模型的研究不同，我们的分析涵盖了更广泛的架构，并进行了连续24小时的推理会话以评估性能稳定性。实验结果表明，通过适当的模型选择和优化，可以在长时间内保持一致的推理延迟并有效管理热行为。这些发现为在实际边缘计算场景中部署音频标签模型提供了宝贵见解。 

---
# Prompt2Auto: From Motion Prompt to Automated Control via Geometry-Invariant One-Shot Gaussian Process Learning 

**Title (ZH)**: Prompt2Auto: 从运动提示到基于几何不变的一次性高斯过程学习的自动化控制 

**Authors**: Zewen Yang, Xiaobing Dai, Dongfa Zhang, Yu Li, Ziyang Meng, Bingkun Huang, Hamid Sadeghian, Sami Haddadin  

**Link**: [PDF](https://arxiv.org/pdf/2509.14040)  

**Abstract**: Learning from demonstration allows robots to acquire complex skills from human demonstrations, but conventional approaches often require large datasets and fail to generalize across coordinate transformations. In this paper, we propose Prompt2Auto, a geometry-invariant one-shot Gaussian process (GeoGP) learning framework that enables robots to perform human-guided automated control from a single motion prompt. A dataset-construction strategy based on coordinate transformations is introduced that enforces invariance to translation, rotation, and scaling, while supporting multi-step predictions. Moreover, GeoGP is robust to variations in the user's motion prompt and supports multi-skill autonomy. We validate the proposed approach through numerical simulations with the designed user graphical interface and two real-world robotic experiments, which demonstrate that the proposed method is effective, generalizes across tasks, and significantly reduces the demonstration burden. Project page is available at: this https URL 

**Abstract (ZH)**: Learning from Demonstration 使机器人能够通过人类示范获取复杂技能，但传统方法通常需要大量数据集并且无法跨坐标变换进行泛化。本文提出了一种几何不变的单次学习高斯过程（GeoGP）框架——Prompt2Auto，该框架使机器人能够从单一运动提示进行带有指导的人机自动控制。该论文介绍了一种基于坐标变换的数据集构建策略，该策略保证了平移、旋转和缩放的不变性，并支持多步预测。此外，GeoGP 对用户的运动提示变化具有鲁棒性，并支持多技能自主。通过设计的用户图形界面的数值仿真和两个实际机器人实验对该方法进行了验证，结果表明该方法有效、跨任务泛化能力强，并显著减轻了示范负担。更多内容请参见项目页面：this https URL 

---
# PhenoGnet: A Graph-Based Contrastive Learning Framework for Disease Similarity Prediction 

**Title (ZH)**: PhenoGnet：一种基于图的对比学习框架，用于疾病相似性预测 

**Authors**: Ranga Baminiwatte, Kazi Jewel Rana, Aaron J. Masino  

**Link**: [PDF](https://arxiv.org/pdf/2509.14037)  

**Abstract**: Understanding disease similarity is critical for advancing diagnostics, drug discovery, and personalized treatment strategies. We present PhenoGnet, a novel graph-based contrastive learning framework designed to predict disease similarity by integrating gene functional interaction networks with the Human Phenotype Ontology (HPO). PhenoGnet comprises two key components: an intra-view model that separately encodes gene and phenotype graphs using Graph Convolutional Networks (GCNs) and Graph Attention Networks (GATs), and a cross view model implemented as a shared weight multilayer perceptron (MLP) that aligns gene and phenotype embeddings through contrastive learning. The model is trained using known gene phenotype associations as positive pairs and randomly sampled unrelated pairs as negatives. Diseases are represented by the mean embeddings of their associated genes and/or phenotypes, and pairwise similarity is computed via cosine similarity. Evaluation on a curated benchmark of 1,100 similar and 866 dissimilar disease pairs demonstrates strong performance, with gene based embeddings achieving an AUCPR of 0.9012 and AUROC of 0.8764, outperforming existing state of the art methods. Notably, PhenoGnet captures latent biological relationships beyond direct overlap, offering a scalable and interpretable solution for disease similarity prediction. These results underscore its potential for enabling downstream applications in rare disease research and precision medicine. 

**Abstract (ZH)**: 理解疾病相似性对于促进诊断、药物发现和个人化治疗策略至关重要。我们提出PhenoGnet，这是一种基于图的对比学习框架，用于通过整合基因功能相互作用网络与人类表型 ontology (HPO) 预测疾病相似性。PhenoGnet 包含两个关键组件：一个内部视角模型，该模型使用图卷积网络 (GCNs) 和图注意网络 (GATs) 分别编码基因和表型图，以及一个通过对比学习对齐基因和表型嵌入的跨视角模型，该模型实现为共享权重的多层感知机 (MLP)。该模型使用已知的基因表型关联作为正样本，并使用随机采样的无关对作为负样本进行训练。疾病通过其相关基因和/或表型的均值嵌入表示，并通过余弦相似度计算两两相似性。在包含1,100对相似和866对不相似疾病的精心构建基准上的评估显示了强大的性能，基于基因的嵌入AUCPR为0.9012，AUROC为0.8764，优于现有最先进的方法。值得注意的是，PhenoGnet 捕捉了超出直接重叠的潜在生物学关系，提供了一种可扩展且可解释的疾病相似性预测解决方案。这些结果突显了其在罕见病研究和精准医疗下游应用中的潜在价值。 

---
# SSL-SSAW: Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation 

**Title (ZH)**: SSL-SSAW：基于sigmoid自我注意加权的自监督学习在基于问题的手语翻译中的应用 

**Authors**: Zekang Liu, Wei Feng, Fanhua Shang, Lianyu Hu, Jichao Feng, Liqing Gao  

**Link**: [PDF](https://arxiv.org/pdf/2509.14036)  

**Abstract**: Sign Language Translation (SLT) bridges the communication gap between deaf people and hearing people, where dialogue provides crucial contextual cues to aid in translation. Building on this foundational concept, this paper proposes Question-based Sign Language Translation (QB-SLT), a novel task that explores the efficient integration of dialogue. Unlike gloss (sign language transcription) annotations, dialogue naturally occurs in communication and is easier to annotate. The key challenge lies in aligning multimodality features while leveraging the context of the question to improve translation. To address this issue, we propose a cross-modality Self-supervised Learning with Sigmoid Self-attention Weighting (SSL-SSAW) fusion method for sign language translation. Specifically, we employ contrastive learning to align multimodality features in QB-SLT, then introduce a Sigmoid Self-attention Weighting (SSAW) module for adaptive feature extraction from question and sign language sequences. Additionally, we leverage available question text through self-supervised learning to enhance representation and translation capabilities. We evaluated our approach on newly constructed CSL-Daily-QA and PHOENIX-2014T-QA datasets, where SSL-SSAW achieved SOTA performance. Notably, easily accessible question assistance can achieve or even surpass the performance of gloss assistance. Furthermore, visualization results demonstrate the effectiveness of incorporating dialogue in improving translation quality. 

**Abstract (ZH)**: 基于问题的手语翻译（QB-SLT）：利用对话改善翻译的新型任务 

---
# You Are What You Train: Effects of Data Composition on Training Context-aware Machine Translation Models 

**Title (ZH)**: 你训练what你就是what：数据构成对训练情境感知机器翻译模型的影响 

**Authors**: Paweł Mąka, Yusuf Can Semerci, Jan Scholtes, Gerasimos Spanakis  

**Link**: [PDF](https://arxiv.org/pdf/2509.14031)  

**Abstract**: Achieving human-level translations requires leveraging context to ensure coherence and handle complex phenomena like pronoun disambiguation. Sparsity of contextually rich examples in the standard training data has been hypothesized as the reason for the difficulty of context utilization. In this work, we systematically validate this claim in both single- and multilingual settings by constructing training datasets with a controlled proportions of contextually relevant examples. We demonstrate a strong association between training data sparsity and model performance confirming sparsity as a key bottleneck. Importantly, we reveal that improvements in one contextual phenomenon do no generalize to others. While we observe some cross-lingual transfer, it is not significantly higher between languages within the same sub-family. Finally, we propose and empirically evaluate two training strategies designed to leverage the available data. These strategies improve context utilization, resulting in accuracy gains of up to 6 and 8 percentage points on the ctxPro evaluation in single- and multilingual settings respectively. 

**Abstract (ZH)**: 实现人类水平的翻译需要利用上下文以确保连贯性并处理像代词消歧这样的复杂现象。标准训练数据中上下文丰富的例子缺乏被认为是难以利用上下文的原因。在本研究中，我们在单语和多语设置下系统地验证了这一假设，通过构建具有可控比例的上下文相关例子的训练数据集。我们证明了训练数据稀疏性和模型性能之间存在强烈的关联，确认稀疏性是一个关键瓶颈。值得注意的是，我们发现一种上下文现象的改进不会泛化到其他现象。虽然我们观察到一定程度的跨语言迁移，但同一语族内的不同语言之间并不存在显著差异。最后，我们提出了两种训练策略，并通过实证评价来利用可用数据。这些策略提高了上下文利用，分别在单语和多语设置下取得了高达6个和8个百分点的准确性提升。 

---
# Hala Technical Report: Building Arabic-Centric Instruction & Translation Models at Scale 

**Title (ZH)**: 哈拉技术报告：构建面向阿拉伯语的规模化指令与翻译模型 

**Authors**: Hasan Abed Al Kader Hammoud, Mohammad Zbeeb, Bernard Ghanem  

**Link**: [PDF](https://arxiv.org/pdf/2509.14008)  

**Abstract**: We present Hala, a family of Arabic-centric instruction and translation models built with our translate-and-tune pipeline. We first compress a strong AR$\leftrightarrow$EN teacher to FP8 (yielding $\sim$2$\times$ higher throughput with no quality loss) and use it to create high-fidelity bilingual supervision. A lightweight language model LFM2-1.2B is then fine-tuned on this data and used to translate high-quality English instruction sets into Arabic, producing a million-scale corpus tailored to instruction following. We train Hala models at 350M, 700M, 1.2B, and 9B parameters, and apply slerp merging to balance Arabic specialization with base-model strengths. On Arabic-centric benchmarks, Hala achieves state-of-the-art results within both the "nano" ($\leq$2B) and "small" (7-9B) categories, outperforming their bases. We release models, data, evaluation, and recipes to accelerate research in Arabic NLP. 

**Abstract (ZH)**: 我们介绍了Hala，一种基于我们的翻译和調整管道构建的阿拉伯语中心指令与翻译模型系列。我们首先将一个强大的AR$\leftrightarrow$EN老师压缩到FP8（在没有质量损失的情况下实现了约2倍的吞吐量提升），并使用它创建高质量的双语监督。然后，使用这种数据对轻量级语言模型LFM2-1.2B进行微调，并将其用于将高质量的英语指令集翻译成阿拉伯语，生成一个针对指令跟随优化的百万规模语料库。我们训练了参数量为350M、700M、1.2B和9B的Hala模型，并应用slerp合并方法来平衡阿拉伯语专业化与基础模型的优势。在阿拉伯语中心基准测试中，Hala在“nano”（$\leq$2B）和“small”（7-9B）类别中都取得了最先进的成果，优于其基础模型。我们发布了模型、数据、评估和食谱，以加速阿拉伯语NLP研究。 

---
# RFM-Editing: Rectified Flow Matching for Text-guided Audio Editing 

**Title (ZH)**: RFM-编辑：修正流匹配方法在文本引导的音频编辑中的应用 

**Authors**: Liting Gao, Yi Yuan, Yaru Chen, Yuelan Cheng, Zhenbo Li, Juan Wen, Shubin Zhang, Wenwu Wang  

**Link**: [PDF](https://arxiv.org/pdf/2509.14003)  

**Abstract**: Diffusion models have shown remarkable progress in text-to-audio generation. However, text-guided audio editing remains in its early stages. This task focuses on modifying the target content within an audio signal while preserving the rest, thus demanding precise localization and faithful editing according to the text prompt. Existing training-based and zero-shot methods that rely on full-caption or costly optimization often struggle with complex editing or lack practicality. In this work, we propose a novel end-to-end efficient rectified flow matching-based diffusion framework for audio editing, and construct a dataset featuring overlapping multi-event audio to support training and benchmarking in complex scenarios. Experiments show that our model achieves faithful semantic alignment without requiring auxiliary captions or masks, while maintaining competitive editing quality across metrics. 

**Abstract (ZH)**: 基于修正流匹配的扩散模型在音频编辑中的应用研究 

---
# MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment 

**Title (ZH)**: MOCHA: 多模态对象 Awareness 的跨架构对齐 

**Authors**: Elena Camuffo, Francesco Barbato, Mete Ozay, Simone Milani, Umberto Michieli  

**Link**: [PDF](https://arxiv.org/pdf/2509.14001)  

**Abstract**: We introduce MOCHA (Multi-modal Objects-aware Cross-arcHitecture Alignment), a knowledge distillation approach that transfers region-level multimodal semantics from a large vision-language teacher (e.g., LLaVa) into a lightweight vision-only object detector student (e.g., YOLO). A translation module maps student features into a joint space, where the training of the student and translator is guided by a dual-objective loss that enforces both local alignment and global relational consistency. Unlike prior approaches focused on dense or global alignment, MOCHA operates at the object level, enabling efficient transfer of semantics without modifying the teacher or requiring textual input at inference. We validate our method across four personalized detection benchmarks under few-shot regimes. Results show consistent gains over baselines, with a +10.1 average score improvement. Despite its compact architecture, MOCHA reaches performance on par with larger multimodal models, proving its suitability for real-world deployment. 

**Abstract (ZH)**: MOCHA（多模态对象感知跨架构对齐），一种知识蒸馏方法，将大型视觉-语言教师（如LLaVA）的区域级多模态语义转移到轻量级的纯视觉对象检测学生（如YOLO）中。 

---
# Slim-SC: Thought Pruning for Efficient Scaling with Self-Consistency 

**Title (ZH)**: Slim-SC: 基于自我一致性的心流剪枝以实现高效扩展 

**Authors**: Colin Hong, Xu Guo, Anand Chaanan Singh, Esha Choukse, Dmitrii Ustiugov  

**Link**: [PDF](https://arxiv.org/pdf/2509.13990)  

**Abstract**: Recently, Test-Time Scaling (TTS) has gained increasing attention for improving LLM reasoning performance at test time without retraining the model. A notable TTS technique is Self-Consistency (SC), which generates multiple reasoning chains in parallel and selects the final answer via majority voting. While effective, the order-of-magnitude computational overhead limits its broad deployment. Prior attempts to accelerate SC mainly rely on model-based confidence scores or heuristics with limited empirical support. For the first time, we theoretically and empirically analyze the inefficiencies of SC and reveal actionable opportunities for improvement. Building on these insights, we propose Slim-SC, a step-wise pruning strategy that identifies and removes redundant chains using inter-chain similarity at the thought level. Experiments on three STEM reasoning datasets and two recent LLM architectures show that Slim-SC reduces inference latency and KVC usage by up to 45% and 26%, respectively, with R1-Distill, while maintaining or improving accuracy, thus offering a simple yet efficient TTS alternative for SC. 

**Abstract (ZH)**: Recently, Test-Time Scaling (TTS) 已逐渐受到关注，通过在测试时不重新训练模型来提高大语言模型推理性能，而无需重新训练模型。值得注意的一种 TTS 技术是自一致性 (SC)，它并行生成多个推理链并最终通过多数投票选择答案。尽管有效，但其量级的计算开销限制了其广泛的部署。先前加速 SC 的尝试主要依赖于基于模型的置信分数或缺乏实证支持的经验法则。我们首次从理论上和实证上分析了 SC 的低效性，并揭示了改进的可行机会。基于这些见解，我们提出了 Slim-SC，这是一种逐步剪枝策略，通过链间相似性在思考层面识别并移除冗余链。在三个 STEM 推理数据集和两种最近的大语言模型架构上的实验表明，相比于 SC，通过 R1-Distill 使用 Slim-SC 可将推理延迟和 KVC 使用量分别减少最多 45% 和 26%，同时保持或提高准确性，从而为 SC 提供了一个简单而有效的 TTS 选择。 

---
# Differential Privacy in Federated Learning: Mitigating Inference Attacks with Randomized Response 

**Title (ZH)**: 联邦学习中的差分隐私：基于随机响应缓解推断攻击 

**Authors**: Ozer Ozturk, Busra Buyuktanir, Gozde Karatas Baydogmus, Kazim Yildiz  

**Link**: [PDF](https://arxiv.org/pdf/2509.13987)  

**Abstract**: Machine learning models used for distributed architectures consisting of servers and clients require large amounts of data to achieve high accuracy. Data obtained from clients are collected on a central server for model training. However, storing data on a central server raises concerns about security and privacy. To address this issue, a federated learning architecture has been proposed. In federated learning, each client trains a local model using its own data. The trained models are periodically transmitted to the central server. The server then combines the received models using federated aggregation algorithms to obtain a global model. This global model is distributed back to the clients, and the process continues in a cyclical manner. Although preventing data from leaving the clients enhances security, certain concerns still remain. Attackers can perform inference attacks on the obtained models to approximate the training dataset, potentially causing data leakage. In this study, differential privacy was applied to address the aforementioned security vulnerability, and a performance analysis was conducted. The Data-Unaware Classification Based on Association (duCBA) algorithm was used as the federated aggregation method. Differential privacy was implemented on the data using the Randomized Response technique, and the trade-off between security and performance was examined under different epsilon values. As the epsilon value decreased, the model accuracy declined, and class prediction imbalances were observed. This indicates that higher levels of privacy do not always lead to practical outcomes and that the balance between security and performance must be carefully considered. 

**Abstract (ZH)**: 联邦学习架构中基于差分隐私的数据不知情关联分类（duCBA）算法的研究 

---
# LLM Agents for Interactive Workflow Provenance: Reference Architecture and Evaluation Methodology 

**Title (ZH)**: LLM代理在交互工作流程溯源中的应用：参考架构与评估方法 

**Authors**: Renan Souza, Timothy Poteet, Brian Etz, Daniel Rosendo, Amal Gueroudji, Woong Shin, Prasanna Balaprakash, Rafael Ferreira da Silva  

**Link**: [PDF](https://arxiv.org/pdf/2509.13978)  

**Abstract**: Modern scientific discovery increasingly relies on workflows that process data across the Edge, Cloud, and High Performance Computing (HPC) continuum. Comprehensive and in-depth analyses of these data are critical for hypothesis validation, anomaly detection, reproducibility, and impactful findings. Although workflow provenance techniques support such analyses, at large scale, the provenance data become complex and difficult to analyze. Existing systems depend on custom scripts, structured queries, or static dashboards, limiting data interaction. In this work, we introduce an evaluation methodology, reference architecture, and open-source implementation that leverages interactive Large Language Model (LLM) agents for runtime data analysis. Our approach uses a lightweight, metadata-driven design that translates natural language into structured provenance queries. Evaluations across LLaMA, GPT, Gemini, and Claude, covering diverse query classes and a real-world chemistry workflow, show that modular design, prompt tuning, and Retrieval-Augmented Generation (RAG) enable accurate and insightful LLM agent responses beyond recorded provenance. 

**Abstract (ZH)**: 现代科学发现 increasingly relies on 工作流处理跨边缘、云和高性能计算（HPC） continuum 中的数据。对这些数据进行全面和深入的分析对于假设验证、异常检测、可重复性和具有影响力的研究结果至关重要。尽管工作流追溯技术支持这些分析，但在大规模情况下，追溯数据变得复杂且难以分析。现有系统依赖于自定义脚本、结构化查询或静态仪表板，限制了数据交互。在本工作中，我们介绍了一种评估方法、参考架构和开源实现，利用交互式大型语言模型（LLM）代理进行运行时数据分析。我们的方法采用轻量级的、元数据驱动的设计，将自然语言转换为结构化追溯查询。跨越 LLAMA、GPT、Gemini 和 Claude 的评估，涵盖了多种查询类别和一个实际化学工作流，表明模块化设计、提示调整和检索增强生成（RAG）能够实现超越记录追溯的准确且富有洞察力的 LLM 代理响应。 

---
# An Empirical Study on Failures in Automated Issue Solving 

**Title (ZH)**: 自动问题解决中故障的实证研究 

**Authors**: Simiao Liu, Fang Liu, Liehao Li, Xin Tan, Yinghao Zhu, Xiaoli Lian, Li Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2509.13941)  

**Abstract**: Automated issue solving seeks to autonomously identify and repair defective code snippets across an entire codebase. SWE-Bench has emerged as the most widely adopted benchmark for evaluating progress in this area. While LLM-based agentic tools show great promise, they still fail on a substantial portion of tasks. Moreover, current evaluations primarily report aggregate issue-solving rates, which obscure the underlying causes of success and failure, making it challenging to diagnose model weaknesses or guide targeted improvements. To bridge this gap, we first analyze the performance and efficiency of three SOTA tools, spanning both pipeline-based and agentic architectures, in automated issue solving tasks of SWE-Bench-Verified under varying task characteristics. Furthermore, to move from high-level performance metrics to underlying cause analysis, we conducted a systematic manual analysis of 150 failed instances. From this analysis, we developed a comprehensive taxonomy of failure modes comprising 3 primary phases, 9 main categories, and 25 fine-grained subcategories. Then we systematically analyze the distribution of the identified failure modes, the results reveal distinct failure fingerprints between the two architectural paradigms, with the majority of agentic failures stemming from flawed reasoning and cognitive deadlocks. Motivated by these insights, we propose a collaborative Expert-Executor framework. It introduces a supervisory Expert agent tasked with providing strategic oversight and course-correction for a primary Executor agent. This architecture is designed to correct flawed reasoning and break the cognitive deadlocks that frequently lead to failure. Experiments show that our framework solves 22.2% of previously intractable issues for a leading single agent. These findings pave the way for building more robust agents through diagnostic evaluation and collaborative design. 

**Abstract (ZH)**: 自动问题解决旨在自主识别并修复代码库中整个代码片段的缺陷。SWE-Bench已成为该领域进展评估的最广泛采用基准。虽然基于LLM的代理工具前景广阔，但在众多任务中仍然失败。此外，当前的评估主要报告聚合的解决率，这模糊了成功和失败的根本原因，使得难以诊断模型弱点或指导有针对性的改进。为解决这一问题，我们首先分析了三种处于领先地位的工具在SWE-Bench-Verified下的自动问题解决任务中的性能和效率，这些工具涵盖了基于流水线和代理架构。此外，为了从高层面的性能指标转变为根本原因分析，我们系统地手动分析了150个失败实例。通过这一分析，我们开发了一种综合的失败模式分类法，包含3个主要阶段、9个主要类别和25个细化子类别。然后我们系统地分析了识别的失败模式的分布，结果显示两种架构模式之间的失败特征有所不同，代理架构的大多数失败源于推理错误和认知死锁。受这些见解的启发，我们提出了一种协作的专家-执行者框架。该框架引入了一位监管专家代理，负责为主要执行者代理提供战略监督和方向校正。该架构设计用于纠正推理错误并打破经常导致失败的认知死锁。实验显示，该框架解决了顶级单一代理无法解决的22.2%的问题。这些发现为通过诊断评估和协作设计构建更 robust 的代理铺平了道路。 

---
# DSpAST: Disentangled Representations for Spatial Audio Reasoning with Large Language Models 

**Title (ZH)**: DSpAST: 空间音频推理中的解耦表示方法 

**Authors**: Kevin Wilkinghoff, Zheng-Hua Tan  

**Link**: [PDF](https://arxiv.org/pdf/2509.13927)  

**Abstract**: Reasoning about spatial audio with large language models requires a spatial audio encoder as an acoustic front-end to obtain audio embeddings for further processing. Such an encoder needs to capture all information required to detect the type of sound events, as well as the direction and distance of their corresponding sources. Accomplishing this with a single audio encoder is demanding as the information required for each of these tasks is mostly independent of each other. As a result, the performance obtained with a single encoder is often worse than when using task-specific audio encoders. In this work, we present DSpAST, a novel audio encoder based on SpatialAST that learns disentangled representations of spatial audio while having only 0.2% additional parameters. Experiments on SpatialSoundQA with the spatial audio reasoning system BAT demonstrate that DSpAST significantly outperforms SpatialAST. 

**Abstract (ZH)**: 基于SpatialAST的DSpAST音频编码器：一种学习空间音频解纠缠表示的新型音频编码器 

---
# MAP: End-to-End Autonomous Driving with Map-Assisted Planning 

**Title (ZH)**: MAP：带地图辅助规划的端到端自动驾驶 

**Authors**: Huilin Yin, Yiming Kan, Daniel Watzenig  

**Link**: [PDF](https://arxiv.org/pdf/2509.13926)  

**Abstract**: In recent years, end-to-end autonomous driving has attracted increasing attention for its ability to jointly model perception, prediction, and planning within a unified framework. However, most existing approaches underutilize the online mapping module, leaving its potential to enhance trajectory planning largely untapped. This paper proposes MAP (Map-Assisted Planning), a novel map-assisted end-to-end trajectory planning framework. MAP explicitly integrates segmentation-based map features and the current ego status through a Plan-enhancing Online Mapping module, an Ego-status-guided Planning module, and a Weight Adapter based on current ego status. Experiments conducted on the DAIR-V2X-seq-SPD dataset demonstrate that the proposed method achieves a 16.6% reduction in L2 displacement error, a 56.2% reduction in off-road rate, and a 44.5% improvement in overall score compared to the UniV2X baseline, even without post-processing. Furthermore, it achieves top ranking in Track 2 of the End-to-End Autonomous Driving through V2X Cooperation Challenge of MEIS Workshop @CVPR2025, outperforming the second-best model by 39.5% in terms of overall score. These results highlight the effectiveness of explicitly leveraging semantic map features in planning and suggest new directions for improving structure design in end-to-end autonomous driving systems. Our code is available at this https URL 

**Abstract (ZH)**: 基于地图辅助的端到端轨迹规划框架MAP 

---
# Ensemble of Pre-Trained Models for Long-Tailed Trajectory Prediction 

**Title (ZH)**: 预训练模型集成的长尾轨迹预测 

**Authors**: Divya Thuremella, Yi Yang, Simon Wanna, Lars Kunze, Daniele De Martini  

**Link**: [PDF](https://arxiv.org/pdf/2509.13914)  

**Abstract**: This work explores the application of ensemble modeling to the multidimensional regression problem of trajectory prediction for vehicles in urban environments. As newer and bigger state-of-the-art prediction models for autonomous driving continue to emerge, an important open challenge is the problem of how to combine the strengths of these big models without the need for costly re-training. We show how, perhaps surprisingly, combining state-of-the-art deep learning models out-of-the-box (without retraining or fine-tuning) with a simple confidence-weighted average method can enhance the overall prediction. Indeed, while combining trajectory prediction models is not straightforward, this simple approach enhances performance by 10% over the best prediction model, especially in the long-tailed metrics. We show that this performance improvement holds on both the NuScenes and Argoverse datasets, and that these improvements are made across the dataset distribution. The code for our work is open source. 

**Abstract (ZH)**: 本研究探讨了集成建模在城市环境中车辆轨迹预测的多维回归问题中的应用。随着不断出现的更先进更大的自动驾驶预测模型，一个重要的开放挑战是如何在无需昂贵的重新训练的情况下结合这些大模型的优势。我们展示了如何通过使用简单且出乎意料的方法，即在无需重新训练或微调的情况下将最先进的深度学习模型进行集成，并用置信加权平均方法来增强整体预测性能。虽然结合轨迹预测模型并非易事，但这种简单的方法在长尾指标上将性能提高了10%，特别是在长尾指标上表现尤为明显。我们展示了这种方法在NuScenes和Argoverse数据集上的性能改进，并且这些改进具有数据集分布的一致性。我们的代码是开源的。 

---
# Do Large Language Models Understand Word Senses? 

**Title (ZH)**: 大型语言模型理解词义吗？ 

**Authors**: Domenico Meconi, Simone Stirpe, Federico Martelli, Leonardo Lavalle, Roberto Navigli  

**Link**: [PDF](https://arxiv.org/pdf/2509.13905)  

**Abstract**: Understanding the meaning of words in context is a fundamental capability for Large Language Models (LLMs). Despite extensive evaluation efforts, the extent to which LLMs show evidence that they truly grasp word senses remains underexplored. In this paper, we address this gap by evaluating both i) the Word Sense Disambiguation (WSD) capabilities of instruction-tuned LLMs, comparing their performance to state-of-the-art systems specifically designed for the task, and ii) the ability of two top-performing open- and closed-source LLMs to understand word senses in three generative settings: definition generation, free-form explanation, and example generation. Notably, we find that, in the WSD task, leading models such as GPT-4o and DeepSeek-V3 achieve performance on par with specialized WSD systems, while also demonstrating greater robustness across domains and levels of difficulty. In the generation tasks, results reveal that LLMs can explain the meaning of words in context up to 98\% accuracy, with the highest performance observed in the free-form explanation task, which best aligns with their generative capabilities. 

**Abstract (ZH)**: 理解词语在上下文中的含义是大规模语言模型（LLMs）的一项基本能力。尽管进行了大量的评估努力，LLMs在真正掌握词语含义方面的证据仍然未被充分探索。在本文中，我们通过评估指令调优的LLMs的词语意义消歧能力（WSD），并与专门为此任务设计的最先进的系统进行比较，填补了这一空白，并评估了两个性能最顶尖的开源和闭源LLMs在三种生成设置下的词语意义理解能力：定义生成、自由形式解释和示例生成。值得注意的是，我们在WSD任务中发现，领先模型如GPT-4o和DeepSeek-V3在性能上与专门的WSD系统相当，并且在不同领域和难度级别上表现出了更强的稳健性。在生成任务中，结果表明，LLMs在上下文中解释词语意义的准确性高达98%，其中自由形式解释任务表现最佳，这与它们的生成能力最为契合。 

---
# FedSSG: Expectation-Gated and History-Aware Drift Alignment for Federated Learning 

**Title (ZH)**: FedSSG: 基于期望门控和历史意识的 Federated Learning 迁移对齐 

**Authors**: Zhanting Zhou, Jinshan Lai, Fengchun Zhang, Zeqin Wu, Fengli Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2509.13895)  

**Abstract**: Non-IID data and partial participation induce client drift and inconsistent local optima in federated learning, causing unstable convergence and accuracy loss. We present FedSSG, a stochastic sampling-guided, history-aware drift alignment method. FedSSG maintains a per-client drift memory that accumulates local model differences as a lightweight sketch of historical gradients; crucially, it gates both the memory update and the local alignment term by a smooth function of the observed/expected participation ratio (a phase-by-expectation signal derived from the server sampler). This statistically grounded gate stays weak and smooth when sampling noise dominates early, then strengthens once participation statistics stabilize, contracting the local-global gap without extra communication. Across CIFAR-10/100 with 100/500 clients and 2-15 percent participation, FedSSG consistently outperforms strong drift-aware baselines and accelerates convergence; on our benchmarks it improves test accuracy by up to a few points (e.g., about +0.9 on CIFAR-10 and about +2.7 on CIFAR-100 on average over the top-2 baseline) and yields about 4.5x faster target-accuracy convergence on average. The method adds only O(d) client memory and a constant-time gate, and degrades gracefully to a mild regularizer under near-IID or uniform sampling. FedSSG shows that sampling statistics can be turned into a principled, history-aware phase control to stabilize and speed up federated training. 

**Abstract (ZH)**: 非IID数据和部分参与诱导客户端漂移和局部最优不一致，导致联邦学习中不稳定收敛和准确率损失。我们提出FedSSG，一种基于随机采样引导的历史感知漂移对齐方法。 

---
# Synthetic Data Generation for Screen Time and App Usage 

**Title (ZH)**: 屏幕时间与应用使用数据的合成数据生成 

**Authors**: Gustavo Kruger, Nikhil Sachdeva, Michael Sobolev  

**Link**: [PDF](https://arxiv.org/pdf/2509.13892)  

**Abstract**: Smartphone usage data can provide valuable insights for understanding interaction with technology and human behavior. However, collecting large-scale, in-the-wild smartphone usage logs is challenging due to high costs, privacy concerns, under representative user samples and biases like non-response that can skew results. These challenges call for exploring alternative approaches to obtain smartphone usage datasets. In this context, large language models (LLMs) such as Open AI's ChatGPT present a novel approach for synthetic smartphone usage data generation, addressing limitations of real-world data collection. We describe a case study on how four prompt strategies influenced the quality of generated smartphone usage data. We contribute with insights on prompt design and measures of data quality, reporting a prompting strategy comparison combining two factors, prompt level of detail (describing a user persona, describing the expected results characteristics) and seed data inclusion (with versus without an initial real usage example). Our findings suggest that using LLMs to generate structured and behaviorally plausible smartphone use datasets is feasible for some use cases, especially when using detailed prompts. Challenges remain in capturing diverse nuances of human behavioral patterns in a single synthetic dataset, and evaluating tradeoffs between data fidelity and diversity, suggesting the need for use-case-specific evaluation metrics and future research with more diverse seed data and different LLM models. 

**Abstract (ZH)**: 智能手机使用数据可以提供了解技术互动和人类行为的宝贵见解。然而，由于成本高、隐私顾虑、代表性不足的用户样本以及如非响应等偏差，收集大规模的真实世界智能手机使用日志具有挑战性。这些挑战要求探索替代方法以获得智能手机使用数据集。在此背景下，如Open AI的ChatGPT这样的大型语言模型提供了生成合成智能手机使用数据的新型方法，解决了现实世界数据收集的局限性。我们描述了四种提示策略如何影响生成的智能手机使用数据质量的案例研究。我们贡献了关于提示设计和数据质量度量的见解，报告了一种结合了两个因素的提示策略比较，即提示详细程度（描述用户 persona，描述预期结果特征）和初始真实使用数据的纳入（有或无初始真实使用示例）。我们的发现表明，在某些应用场景下，使用大型语言模型生成结构化且行为上可验证的智能手机使用数据集是可能的，尤其是在使用详细提示时。捕捉人类行为模式的多样性细微差别仍然面临挑战，并且在数据 fidelity 和多样性之间进行权衡时，需要特定用例的评估指标，并且未来的研究需要更多样化的初始数据和不同的大型语言模型。 

---
# Combating Biomedical Misinformation through Multi-modal Claim Detection and Evidence-based Verification 

**Title (ZH)**: 通过多模态声明检测与基于证据的验证对抗 biomedical 领域的虚假信息 

**Authors**: Mariano Barone, Antonio Romano, Giuseppe Riccio, Marco Postiglione, Vincenzo Moscato  

**Link**: [PDF](https://arxiv.org/pdf/2509.13888)  

**Abstract**: Misinformation in healthcare, from vaccine hesitancy to unproven treatments, poses risks to public health and trust in medical systems. While machine learning and natural language processing have advanced automated fact-checking, validating biomedical claims remains uniquely challenging due to complex terminology, the need for domain expertise, and the critical importance of grounding in scientific evidence. We introduce CER (Combining Evidence and Reasoning), a novel framework for biomedical fact-checking that integrates scientific evidence retrieval, reasoning via large language models, and supervised veracity prediction. By integrating the text-generation capabilities of large language models with advanced retrieval techniques for high-quality biomedical scientific evidence, CER effectively mitigates the risk of hallucinations, ensuring that generated outputs are grounded in verifiable, evidence-based sources. Evaluations on expert-annotated datasets (HealthFC, BioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising cross-dataset generalization. Code and data are released for transparency and reproducibility: this https URL 

**Abstract (ZH)**: 医疗保健中的虚假信息，从疫苗犹豫到未证实的治疗方法，对公共卫生和对医疗系统的信任构成了风险。尽管机器学习和自然语言处理已经推动了自动事实核查的发展，但由于复杂的术语、领域专业知识的需要以及基于科学证据的至关重要性，验证 biomedical 声明仍然具有独特的挑战性。我们提出了一种名为 CER（Combining Evidence and Reasoning）的新颖框架，该框架结合了科学证据检索、通过大规模语言模型进行推理以及监督真伪预测。通过将大规模语言模型的文本生成能力与高质量 biomedical 科学证据的先进检索技术相结合，CER 有效地减轻了幻觉风险，确保生成的输出基于可核实、基于证据的来源。在专家标注数据集（HealthFC、BioASQ-7b、SciFact）上的评估显示了最先进的性能和跨数据集的有前景的一般化能力。完整代码和数据已公开以确保透明性和可再现性：this https URL。 

---
# Combining Evidence and Reasoning for Biomedical Fact-Checking 

**Title (ZH)**: 结合证据与推理进行生物医学事实核查 

**Authors**: Mariano Barone, Antonio Romano, Giuseppe Riccio, Marco Postiglione, Vincenzo Moscato  

**Link**: [PDF](https://arxiv.org/pdf/2509.13879)  

**Abstract**: Misinformation in healthcare, from vaccine hesitancy to unproven treatments, poses risks to public health and trust in medical sys- tems. While machine learning and natural language processing have advanced automated fact-checking, validating biomedical claims remains uniquely challenging due to complex terminol- ogy, the need for domain expertise, and the critical importance of grounding in scientific evidence. We introduce CER (Combin- ing Evidence and Reasoning), a novel framework for biomedical fact-checking that integrates scientific evidence retrieval, reasoning via large language models, and supervised veracity prediction. By integrating the text-generation capabilities of large language mod- els with advanced retrieval techniques for high-quality biomedical scientific evidence, CER effectively mitigates the risk of halluci- nations, ensuring that generated outputs are grounded in veri- fiable, evidence-based sources. Evaluations on expert-annotated datasets (HealthFC, BioASQ-7b, SciFact) demonstrate state-of-the- art performance and promising cross-dataset generalization. Code and data are released for transparency and reproducibility: https: //github.com/PRAISELab-PicusLab/CER. 

**Abstract (ZH)**: 医学领域的 misinformation，从疫苗犹豫到未经验证的治疗方法，对公共健康和对医疗系统的信任构成了风险。尽管机器学习和自然语言处理推动了自动事实核查的发展，但由于复杂的专业术语、领域专业知识的需要以及依赖于科学证据的至关重要性，验证生物医学声明仍然极具挑战性。我们提出了CER（结合证据与推理）这一新颖的生物医学事实核查框架，该框架整合了科学证据检索、通过大规模语言模型进行的推理以及监督的可信度预测。通过将大规模语言模型的文本生成能力与高质量生物医学科学证据的高度检索技术相结合，CER 有效地缓解了幻觉的风险，确保生成的输出源自可验证的、基于证据的来源。在专家标注的数据集（HealthFC、BioASQ-7b、SciFact）上的评估表明，CER 达到了最先进的性能，并展示了跨数据集的广泛应用潜力。透明性和可重复性方面的代码和数据在 https://github.com/PRAISELab-PicusLab/CER 发布。 

---
# Masked Diffusion Models as Energy Minimization 

**Title (ZH)**: 掩码扩散模型作为能量最小化بريوف 

**Authors**: Sitong Chen, Shen Nie, Jiacheng Sun, Zijin Feng, Zhenguo Li, Ji-Rong Wen, Chongxuan Li  

**Link**: [PDF](https://arxiv.org/pdf/2509.13866)  

**Abstract**: We present a systematic theoretical framework that interprets masked diffusion models (MDMs) as solutions to energy minimization problems in discrete optimal transport. Specifically, we prove that three distinct energy formulations--kinetic, conditional kinetic, and geodesic energy--are mathematically equivalent under the structure of MDMs, and that MDMs minimize all three when the mask schedule satisfies a closed-form optimality condition. This unification not only clarifies the theoretical foundations of MDMs, but also motivates practical improvements in sampling. By parameterizing interpolation schedules via Beta distributions, we reduce the schedule design space to a tractable 2D search, enabling efficient post-training tuning without model modification. Experiments on synthetic and real-world benchmarks demonstrate that our energy-inspired schedules outperform hand-crafted baselines, particularly in low-step sampling settings. 

**Abstract (ZH)**: 我们提出了一种系统性的理论框架，将掩蔽扩散模型（MDMs）解释为离散最优运输中能量最小化问题的解决方案。具体而言，我们证明了三种不同的能量公式——动能、条件动能和测地线能量——在MDMs的结构下是数学等价的，并且在掩码调度满足闭式最优条件时，MDMs能够最小化这三种能量。这种统一不仅澄清了MDMs的理论基石，还促使了采样实践上的改进。通过使用Beta分布参数化插值调度，我们将调度设计空间缩减为可处理的二维搜索，从而在无需修改模型的情况下实现高效的后训练调优。在合成与现实世界的基准测试中，我们的能量启发式调度在低步数采样设置下表现出色，优于手工设计的基线方法。 

---
# Understanding the Process of Human-AI Value Alignment 

**Title (ZH)**: 理解人类与人工智能价值对齐的过程 

**Authors**: Jack McKinlay, Marina De Vos, Janina A. Hoffmann, Andreas Theodorou  

**Link**: [PDF](https://arxiv.org/pdf/2509.13854)  

**Abstract**: Background: Value alignment in computer science research is often used to refer to the process of aligning artificial intelligence with humans, but the way the phrase is used often lacks precision. Objectives: In this paper, we conduct a systematic literature review to advance the understanding of value alignment in artificial intelligence by characterising the topic in the context of its research literature. We use this to suggest a more precise definition of the term. Methods: We analyse 172 value alignment research articles that have been published in recent years and synthesise their content using thematic analyses. Results: Our analysis leads to six themes: value alignment drivers & approaches; challenges in value alignment; values in value alignment; cognitive processes in humans and AI; human-agent teaming; and designing and developing value-aligned systems. Conclusions: By analysing these themes in the context of the literature we define value alignment as an ongoing process between humans and autonomous agents that aims to express and implement abstract values in diverse contexts, while managing the cognitive limits of both humans and AI agents and also balancing the conflicting ethical and political demands generated by the values in different groups. Our analysis gives rise to a set of research challenges and opportunities in the field of value alignment for future work. 

**Abstract (ZH)**: 背景：在计算机科学研究中，价值对齐通常指将人工智能与人类对齐的过程，但这一术语的使用往往缺乏精确性。目标：本文通过在研究文献的背景下对价值对齐主题进行特征化，开展系统文献综述，以增进对人工智能领域价值对齐的理解，并提出一个更精确的定义。方法：分析近年来发表的172篇价值对齐研究文章，并通过主题分析整合其内容。结果：分析得出六个主题：价值对齐驱动因素与方法；价值对齐的挑战；价值在价值对齐中的作用；人类和AI的认知过程；人机团队合作；以及设计和开发价值对齐系统。结论：通过对这些主题在文献中的分析，我们将价值对齐定义为人类与自主代理之间持续的过程，旨在在不同情境下表达和实施抽象价值，同时管理人类和AI代理的认知限制，并平衡不同群体由价值观产生的冲突的伦理和政治要求。我们的分析为未来的价值对齐领域研究提出了研究挑战和机遇。 

---
# Towards a Physics Foundation Model 

**Title (ZH)**: 向物理基础模型迈进 

**Authors**: Florian Wiesner, Matthias Wessling, Stephen Baek  

**Link**: [PDF](https://arxiv.org/pdf/2509.13805)  

**Abstract**: Foundation models have revolutionized natural language processing through a ``train once, deploy anywhere'' paradigm, where a single pre-trained model adapts to countless downstream tasks without retraining. Access to a Physics Foundation Model (PFM) would be transformative -- democratizing access to high-fidelity simulations, accelerating scientific discovery, and eliminating the need for specialized solver development. Yet current physics-aware machine learning approaches remain fundamentally limited to single, narrow domains and require retraining for each new system. We present the General Physics Transformer (GPhyT), trained on 1.8 TB of diverse simulation data, that demonstrates foundation model capabilities are achievable for physics. Our key insight is that transformers can learn to infer governing dynamics from context, enabling a single model to simulate fluid-solid interactions, shock waves, thermal convection, and multi-phase dynamics without being told the underlying equations. GPhyT achieves three critical breakthroughs: (1) superior performance across multiple physics domains, outperforming specialized architectures by up to 29x, (2) zero-shot generalization to entirely unseen physical systems through in-context learning, and (3) stable long-term predictions through 50-timestep rollouts. By establishing that a single model can learn generalizable physical principles from data alone, this work opens the path toward a universal PFM that could transform computational science and engineering. 

**Abstract (ZH)**: 基础模型通过“训练一次，随处部署”的 paradigma 重塑了自然语言处理，其中单一预训练模型能够适应无数下游任务而无需重新训练。获取物理基础模型 (PFM) 将是变革性的——普及高保真模拟的访问权，加速科学发现，并消除专门求解器开发的需要。然而，当前的物理感知机器学习方法仍然根本上局限于单一的小范围领域，并且每次都需要重新训练新的系统。我们提出了广义物理变换器 (GPhyT)，它基于 1.8 TB 多样的模拟数据进行训练，并展示了基础模型能力在物理学领域的实现。我们关键的见解是，变换器能够从上下文中推断出支配动力学，从而使单一模型能够在无需告知底层方程的情况下模拟流固相互作用、冲击波、热对流以及多相动力学。GPhyT 实现了三个关键突破：(1) 在多个物理学领域中表现出色，相对于专门架构高出 29 倍，(2) 通过上下文学习零样本泛化到完全未见过的物理系统，以及 (3) 通过 50 步时序预报实现稳定长期预测。通过表明单一模型可以从数据本身学习可泛化的物理原理，这项工作开启了通向万能 PFM 的路径，这有可能重塑计算科学和工程。 

---
# Bridging the Synthetic-Real Gap: Supervised Domain Adaptation for Robust Spacecraft 6-DoF Pose Estimation 

**Title (ZH)**: 合成与现实之间的鸿沟：监督领域适应算法在鲁棒航天器6自由度姿态估计中的应用 

**Authors**: Inder Pal Singh, Nidhal Eddine Chenni, Abd El Rahman Shabayek, Arunkumar Rathinam, Djamila Aouada  

**Link**: [PDF](https://arxiv.org/pdf/2509.13792)  

**Abstract**: Spacecraft Pose Estimation (SPE) is a fundamental capability for autonomous space operations such as rendezvous, docking, and in-orbit servicing. Hybrid pipelines that combine object detection, keypoint regression, and Perspective-n-Point (PnP) solvers have recently achieved strong results on synthetic datasets, yet their performance deteriorates sharply on real or lab-generated imagery due to the persistent synthetic-to-real domain gap. Existing unsupervised domain adaptation approaches aim to mitigate this issue but often underperform when a modest number of labeled target samples are available. In this work, we propose the first Supervised Domain Adaptation (SDA) framework tailored for SPE keypoint regression. Building on the Learning Invariant Representation and Risk (LIRR) paradigm, our method jointly optimizes domain-invariant representations and task-specific risk using both labeled synthetic and limited labeled real data, thereby reducing generalization error under domain shift. Extensive experiments on the SPEED+ benchmark demonstrate that our approach consistently outperforms source-only, fine-tuning, and oracle baselines. Notably, with only 5% labeled target data, our method matches or surpasses oracle performance trained on larger fractions of labeled data. The framework is lightweight, backbone-agnostic, and computationally efficient, offering a practical pathway toward robust and deployable spacecraft pose estimation in real-world space environments. 

**Abstract (ZH)**: 空间探测器姿态估计的监督域自适应方法 

---
# Teaching According to Talents! Instruction Tuning LLMs with Competence-Aware Curriculum Learning 

**Title (ZH)**: 因材施教！基于能力意识的 Curriculum 学习调优大语言模型 

**Authors**: Yangning Li, Tingwei Lu, Yinghui Li, Yankai Chen, Wei-Chieh Huang, Wenhao Jiang, Hui Wang, Hai-Tao Zheng, Philip S.Yu  

**Link**: [PDF](https://arxiv.org/pdf/2509.13790)  

**Abstract**: Efficient instruction tuning aims to enhance the ultimate performance of large language models (LLMs) trained on a given instruction dataset. Curriculum learning as a typical data organization strategy has shown preliminary effectiveness in instruction tuning. However, current curriculum tuning methods suffer from the curriculum rigidity, since they rely solely on static heuristic difficulty metrics. These methods fail to adapt to the evolving capabilities of models during training, resulting in a fixed and potentially sub-optimal learning trajectory. To address the issue, Competence-Aware Multi-Perspective cUrriculum inStruction tuning framework termed CAMPUS is proposed. CAMPUS offers several advantages: (1) Dynamic selection for sub-curriculum. (2) Competency-aware adjustment to the curriculum schedule. (3) Multiple difficulty-based scheduling. Extensive experiments prove the superior performance of CAMPUS, compared to other state-of-the-art baselines for efficient instruction tuning. 

**Abstract (ZH)**: Efficient指令调优旨在提升基于给定指令数据集训练的大语言模型（LLMs）的最终性能。作为典型的数据组织策略，渐进学习在指令调优中显示出初步的有效性。然而，当前的渐进调优方法受到固有刚性的限制，因为它们仅仅依赖于静态的经验难度指标。这些方法无法适应训练过程中模型能力的演变，导致固定且有可能是最优的学习轨迹。为解决该问题，提出了一种名为CAMPUS（Competence-Aware Multi-Perspective cUrriculum inStruction tuning）的框架：(1) 动态选择子课程。(2) 适应能力调整课程计划。(3) 多角度难度调度。广泛的实验证明，CAMPUS在高效指令调优方面优于其他最先进的baseline方法。 

---
# BWCache: Accelerating Video Diffusion Transformers through Block-Wise Caching 

**Title (ZH)**: BWCache：通过块级缓存加速视频扩散变换器 

**Authors**: Hanshuai Cui, Zhiqing Tang, Zhifei Xu, Zhi Yao, Wenyi Zeng, Weijia Jia  

**Link**: [PDF](https://arxiv.org/pdf/2509.13789)  

**Abstract**: Recent advancements in Diffusion Transformers (DiTs) have established them as the state-of-the-art method for video generation. However, their inherently sequential denoising process results in inevitable latency, limiting real-world applicability. Existing acceleration methods either compromise visual quality due to architectural modifications or fail to reuse intermediate features at proper granularity. Our analysis reveals that DiT blocks are the primary contributors to inference latency. Across diffusion timesteps, the feature variations of DiT blocks exhibit a U-shaped pattern with high similarity during intermediate timesteps, which suggests substantial computational redundancy. In this paper, we propose Block-Wise Caching (BWCache), a training-free method to accelerate DiT-based video generation. BWCache dynamically caches and reuses features from DiT blocks across diffusion timesteps. Furthermore, we introduce a similarity indicator that triggers feature reuse only when the differences between block features at adjacent timesteps fall below a threshold, thereby minimizing redundant computations while maintaining visual fidelity. Extensive experiments on several video diffusion models demonstrate that BWCache achieves up to 2.24$\times$ speedup with comparable visual quality. 

**Abstract (ZH)**: Recent advancements in Diffusion Transformers (DiTs) have established them as the state-of-the-art method for video generation. However, their inherently sequential denoising process results in inevitable latency, limiting real-world applicability.现有的扩散变压器（DiTs）发展已经使它们成为视频生成的最先进的方法。然而，其固有的顺序去噪过程会导致不可避免的延迟，限制了其实用性。 

---
# Who is Introducing the Failure? Automatically Attributing Failures of Multi-Agent Systems via Spectrum Analysis 

**Title (ZH)**: 谁在引入故障？通过频谱分析自动归因多agent系统中的故障 

**Authors**: Yu Ge, Linna Xie, Zhong Li, Yu Pei, Tian Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2509.13782)  

**Abstract**: Large Language Model Powered Multi-Agent Systems (MASs) are increasingly employed to automate complex real-world problems, such as programming and scientific discovery. Despite their promising, MASs are not without their flaws. However, failure attribution in MASs - pinpointing the specific agent actions responsible for failures - remains underexplored and labor-intensive, posing significant challenges for debugging and system improvement. To bridge this gap, we propose FAMAS, the first spectrum-based failure attribution approach for MASs, which operates through systematic trajectory replay and abstraction, followed by spectrum this http URL core idea of FAMAS is to estimate, from variations across repeated MAS executions, the likelihood that each agent action is responsible for the failure. In particular, we propose a novel suspiciousness formula tailored to MASs, which integrates two key factor groups, namely the agent behavior group and the action behavior group, to account for the agent activation patterns and the action activation patterns within the execution trajectories of MASs. Through expensive evaluations against 12 baselines on the Who and When benchmark, FAMAS demonstrates superior performance by outperforming all the methods in comparison. 

**Abstract (ZH)**: 基于大型语言模型的多智能体系统故障归因方法（FAMAS） 

---
# Exploring Data and Parameter Efficient Strategies for Arabic Dialect Identifications 

**Title (ZH)**: 探索阿拉伯方言识别的数据和参数高效策略 

**Authors**: Vani Kanjirangat, Ljiljana Dolamic, Fabio Rinaldi  

**Link**: [PDF](https://arxiv.org/pdf/2509.13775)  

**Abstract**: This paper discusses our exploration of different data-efficient and parameter-efficient approaches to Arabic Dialect Identification (ADI). In particular, we investigate various soft-prompting strategies, including prefix-tuning, prompt-tuning, P-tuning, and P-tuning V2, as well as LoRA reparameterizations. For the data-efficient strategy, we analyze hard prompting with zero-shot and few-shot inferences to analyze the dialect identification capabilities of Large Language Models (LLMs). For the parameter-efficient PEFT approaches, we conducted our experiments using Arabic-specific encoder models on several major datasets. We also analyzed the n-shot inferences on open-source decoder-only models, a general multilingual model (Phi-3.5), and an Arabic-specific one(SILMA). We observed that the LLMs generally struggle to differentiate the dialectal nuances in the few-shot or zero-shot setups. The soft-prompted encoder variants perform better, while the LoRA-based fine-tuned models perform best, even surpassing full fine-tuning. 

**Abstract (ZH)**: 本文探讨了不同数据高效和参数高效方法在阿拉伯方言识别（ADI）中的应用。特别地，我们调查了各种软提示策略，包括前缀调优、提示调优、P调优以及P调优V2，以及LoRA重参数化。在数据高效策略方面，我们分析了零-shot和少-shot推理中的硬提示，以评估大型语言模型（LLMs）的方言识别能力。在参数高效PEFT方法方面，我们在多个主要数据集上使用阿拉伯语特定的编码器模型进行了实验。我们还分析了开源的解码器模型、通用多语言模型（Phi-3.5）以及阿拉伯语特定模型（SILMA）的n-shot推理。我们观察到，在少-shot或零-shot设置中，LLMs一般难以区分方言差异。带有软提示的编码器变体表现较好，而基于LoRA的微调模型表现最佳，甚至超过了完全微调。 

---
# Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning 

**Title (ZH)**: 擦除敏感记忆！通过机器忘记消除代码语言模型中的敏感记忆 

**Authors**: Zhaoyang Chu, Yao Wan, Zhikun Zhang, Di Wang, Zhou Yang, Hongyu Zhang, Pan Zhou, Xuanhua Shi, Hai Jin, David Lo  

**Link**: [PDF](https://arxiv.org/pdf/2509.13755)  

**Abstract**: While Code Language Models (CLMs) have demonstrated superior performance in software engineering tasks such as code generation and summarization, recent empirical studies reveal a critical privacy vulnerability: these models exhibit unintended memorization of sensitive training data, enabling verbatim reproduction of confidential information when specifically prompted. To address this issue, several approaches, including training data de-duplication and differential privacy augmentation, have been proposed. However, these methods require full-model retraining for deployed CLMs, which incurs substantial computational costs. In this paper, we aim to answer the following research question: Can sensitive information memorized by CLMs be erased effectively and efficiently?
We conduct a pioneering investigation into erasing sensitive memorization in CLMs through machine unlearning - a post-hoc modification method that removes specific information from trained models without requiring full retraining. Specifically, we first quantify the memorization risks of sensitive data within CLM training datasets and curate a high-risk dataset of 50,000 sensitive memorized samples as unlearning targets. We study two widely used gradient ascent-based unlearning approaches: the vanilla and constraint-based methods, and introduce CodeEraser, an advanced variant that selectively unlearns sensitive memorized segments in code while preserving the structural integrity and functional correctness of the surrounding code. Extensive experiments on three families of CLMs, i.e., CodeParrot, CodeGen-Mono, and Qwen2.5-Coder, validate the effectiveness and efficiency of CodeEraser in erasing targeted sensitive memorization while maintaining model utility. 

**Abstract (ZH)**: CodeEraser：有效高效地擦除CLMs中敏感信息记忆的方法 

---
# State Space Models over Directed Graphs 

**Title (ZH)**: 有向图上的状态空间模型 

**Authors**: Junzhi She, Xunkai Li, Rong-Hua Li, Guoren Wang  

**Link**: [PDF](https://arxiv.org/pdf/2509.13735)  

**Abstract**: Directed graphs are ubiquitous across numerous domains, where the directionality of edges encodes critical causal dependencies. However, existing GNNs and graph Transformers tailored for directed graphs face two major challenges: (1) effectively capturing long-range causal dependencies derived from directed edges; (2) balancing accuracy and training efficiency when processing large-scale graph datasets. In recent years, state space models (SSMs) have achieved substantial progress in causal sequence tasks, and their variants designed for graphs have demonstrated state-of-the-art accuracy while maintaining high efficiency across various graph learning benchmarks. However, existing graph state space models are exclusively designed for undirected graphs, which limits their performance in directed graph learning. To this end, we propose an innovative approach DirEgo2Token which sequentializes directed graphs via k-hop ego graphs. This marks the first systematic extension of state space models to the field of directed graph learning. Building upon this, we develop DirGraphSSM, a novel directed graph neural network architecture that implements state space models on directed graphs via the message-passing mechanism. Experimental results demonstrate that DirGraphSSM achieves state-of-the-art performance on three representative directed graph learning tasks while attaining competitive performance on two additional tasks with 1.5$\times $ to 2$\times $ training speed improvements compared to existing state-of-the-art models. 

**Abstract (ZH)**: Directed图神经网络中的时空状态空间模型 

---
# Mitigating Query Selection Bias in Referring Video Object Segmentation 

**Title (ZH)**: 在引用视频对象分割中减轻查询选择偏见 

**Authors**: Dingwei Zhang, Dong Zhang, Jinhui Tang  

**Link**: [PDF](https://arxiv.org/pdf/2509.13722)  

**Abstract**: Recently, query-based methods have achieved remarkable performance in Referring Video Object Segmentation (RVOS) by using textual static object queries to drive cross-modal alignment. However, these static queries are easily misled by distractors with similar appearance or motion, resulting in \emph{query selection bias}. To address this issue, we propose Triple Query Former (TQF), which factorizes the referring query into three specialized components: an appearance query for static attributes, an intra-frame interaction query for spatial relations, and an inter-frame motion query for temporal association. Instead of relying solely on textual embeddings, our queries are dynamically constructed by integrating both linguistic cues and visual guidance. Furthermore, we introduce two motion-aware aggregation modules that enhance object token representations: Intra-frame Interaction Aggregation incorporates position-aware interactions among objects within a single frame, while Inter-frame Motion Aggregation leverages trajectory-guided alignment across frames to ensure temporal coherence. Extensive experiments on multiple RVOS benchmarks demonstrate the advantages of TQF and the effectiveness of our structured query design and motion-aware aggregation modules. 

**Abstract (ZH)**: 基于三元查询的视频对象分割方法： Triple Query Former (TQF) 用于解决查询选择偏见并增强时空一致性 

---
# Automated Triaging and Transfer Learning of Incident Learning Safety Reports Using Large Language Representational Models 

**Title (ZH)**: 使用大规模语言表示模型的事故学习安全报告自动化优先级划分和迁移学习 

**Authors**: Peter Beidler, Mark Nguyen, Kevin Lybarger, Ola Holmberg, Eric Ford, John Kang  

**Link**: [PDF](https://arxiv.org/pdf/2509.13706)  

**Abstract**: PURPOSE: Incident reports are an important tool for safety and quality improvement in healthcare, but manual review is time-consuming and requires subject matter expertise. Here we present a natural language processing (NLP) screening tool to detect high-severity incident reports in radiation oncology across two institutions.
METHODS AND MATERIALS: We used two text datasets to train and evaluate our NLP models: 7,094 reports from our institution (Inst.), and 571 from IAEA SAFRON (SF), all of which had severity scores labeled by clinical content experts. We trained and evaluated two types of models: baseline support vector machines (SVM) and BlueBERT which is a large language model pretrained on PubMed abstracts and hospitalized patient data. We assessed for generalizability of our model in two ways. First, we evaluated models trained using Inst.-train on SF-test. Second, we trained a BlueBERT_TRANSFER model that was first fine-tuned on Inst.-train then on SF-train before testing on SF-test set. To further analyze model performance, we also examined a subset of 59 reports from our Inst. dataset, which were manually edited for clarity.
RESULTS Classification performance on the Inst. test achieved AUROC 0.82 using SVM and 0.81 using BlueBERT. Without cross-institution transfer learning, performance on the SF test was limited to an AUROC of 0.42 using SVM and 0.56 using BlueBERT. BlueBERT_TRANSFER, which was fine-tuned on both datasets, improved the performance on SF test to AUROC 0.78. Performance of SVM, and BlueBERT_TRANSFER models on the manually curated Inst. reports (AUROC 0.85 and 0.74) was similar to human performance (AUROC 0.81).
CONCLUSION: In summary, we successfully developed cross-institution NLP models on incident report text from radiation oncology centers. These models were able to detect high-severity reports similarly to humans on a curated dataset. 

**Abstract (ZH)**: 目的：事故报告是医疗卫生领域提高安全和质量的重要工具，但人工审查耗时且需要专业知识。本文介绍了一种自然语言处理（NLP）筛选工具，用于检测辐射肿瘤学领域两家机构中的高严重性事故报告。 

---
# DSCC-HS: A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models 

**Title (ZH)**: DSCC-HS：一种用于大规模语言模型幻觉抑制的动态自我强化框架 

**Authors**: Xiao Zheng  

**Link**: [PDF](https://arxiv.org/pdf/2509.13702)  

**Abstract**: Large Language Model (LLM) hallucination is a significant barrier to their reliable deployment. Current methods like Retrieval-Augmented Generation (RAG) are often reactive. We introduce **Dynamic Self-reinforcing Calibration for Hallucination Suppression (DSCC-HS)**, a novel, proactive framework that intervenes during autoregressive decoding. Inspired by dual-process cognitive theory, DSCC-HS uses a compact proxy model, trained in adversarial roles as a Factual Alignment Proxy (FAP) and a Hallucination Detection Proxy (HDP). During inference, these proxies dynamically steer a large target model by injecting a real-time steering vector, which is the difference between FAP and HDP logits, at each decoding step. This plug-and-play approach requires no modification to the target model. Our experiments on TruthfulQA and BioGEN show DSCC-HS achieves state-of-the-art performance. On TruthfulQA, it reached a 99.2% Factual Consistency Rate (FCR). On the long-form BioGEN benchmark, it attained the highest FActScore of 46.50. These results validate DSCC-HS as a principled and efficient solution for enhancing LLM factuality. 

**Abstract (ZH)**: 动态自我强化校准以抑制幻觉 (DSCC-HS): 一种 proactive 框架用于大型语言模型的故障自排查 

---
# CraftMesh: High-Fidelity Generative Mesh Manipulation via Poisson Seamless Fusion 

**Title (ZH)**: CraftMesh：通过泊松无缝融合实现的高保真生成网格 manipulation 

**Authors**: James Jincheng, Youcheng Cai, Ligang Liu  

**Link**: [PDF](https://arxiv.org/pdf/2509.13688)  

**Abstract**: Controllable, high-fidelity mesh editing remains a significant challenge in 3D content creation. Existing generative methods often struggle with complex geometries and fail to produce detailed results. We propose CraftMesh, a novel framework for high-fidelity generative mesh manipulation via Poisson Seamless Fusion. Our key insight is to decompose mesh editing into a pipeline that leverages the strengths of 2D and 3D generative models: we edit a 2D reference image, then generate a region-specific 3D mesh, and seamlessly fuse it into the original model. We introduce two core techniques: Poisson Geometric Fusion, which utilizes a hybrid SDF/Mesh representation with normal blending to achieve harmonious geometric integration, and Poisson Texture Harmonization for visually consistent texture blending. Experimental results demonstrate that CraftMesh outperforms state-of-the-art methods, delivering superior global consistency and local detail in complex editing tasks. 

**Abstract (ZH)**: 可控的高保真网格编辑仍然是3D内容创建中的一个重大挑战。现有生成方法往往难以处理复杂几何形状，并且无法生成详细的成果。我们提出了CraftMesh，一种通过泊松无缝融合进行高保真生成网格操作的新框架。我们的关键洞察是将网格编辑分解为一个利用2D和3D生成模型优势的流水线：我们编辑一个2D参考图像，然后生成区域特定的3D网格，并将其无缝融合到原始模型中。我们介绍了两种核心技术：泊松几何融合，利用混合SDF/网格表示与法线混合以实现和谐的几何集成，以及泊松纹理谐振，实现视觉一致的纹理混合。实验结果表明，CraftMesh 在复杂编辑任务中优于现有最先进的方法，提供了更好的全局一致性和局部细节。 

---
# Improving Context Fidelity via Native Retrieval-Augmented Reasoning 

**Title (ZH)**: 通过本体检索增强推理提高上下文保真度 

**Authors**: Suyuchen Wang, Jinlin Wang, Xinyu Wang, Shiqi Li, Xiangru Tang, Sirui Hong, Xiao-Wen Chang, Chenglin Wu, Bang Liu  

**Link**: [PDF](https://arxiv.org/pdf/2509.13683)  

**Abstract**: Large language models (LLMs) often struggle with context fidelity, producing inconsistent answers when responding to questions based on provided information. Existing approaches either rely on expensive supervised fine-tuning to generate evidence post-answer or train models to perform web searches without necessarily improving utilization of the given context. We propose CARE, a novel native retrieval-augmented reasoning framework that teaches LLMs to explicitly integrate in-context evidence within their reasoning process with the model's own retrieval capabilities. Our method requires limited labeled evidence data while significantly enhancing both retrieval accuracy and answer generation performance through strategically retrieved in-context tokens in the reasoning chain. Extensive experiments on multiple real-world and counterfactual QA benchmarks demonstrate that our approach substantially outperforms supervised fine-tuning, traditional retrieval-augmented generation methods, and external retrieval solutions. This work represents a fundamental advancement in making LLMs more accurate, reliable, and efficient for knowledge-intensive tasks. 

**Abstract (ZH)**: 大规模语言模型（LLMs）往往在处理上下文一致性方面存在困难，基于提供的信息回答问题时会产生不一致的答案。现有方法要么依赖昂贵的监督微调来生成答案后的证据，要么训练模型进行网络搜索，但不一定能提高对给定上下文的利用效率。我们提出了一种名为CARE的新颖的原生检索增强推理框架，该框架通过模型自身的检索能力，明确指导LLMs将上下文证据整合到其推理过程中。我们的方法仅需要少量标记的证据数据，同时通过在推理链中战略性地检索上下文令牌，显著提高检索准确性和答案生成性能。在多个现实世界和假设性问答基准测试上的大量实验表明，我们的方法在多个方面显著优于监督微调、传统的检索增强生成方法以及外部检索解决方案。这项工作代表了使LLMs在知识密集型任务中更加准确、可靠和高效的基本进步。 

---
# Prompt Stability in Code LLMs: Measuring Sensitivity across Emotion- and Personality-Driven Variations 

**Title (ZH)**: 代码LLMs中的提示稳定性：跨情绪和人格驱动变异性测量敏感性 

**Authors**: Wei Ma, Yixiao Yang, Jingquan Ge, Xiaofei Xie, Lingxiao Jiang  

**Link**: [PDF](https://arxiv.org/pdf/2509.13680)  

**Abstract**: Code generation models are widely used in software development, yet their sensitivity to prompt phrasing remains under-examined. Identical requirements expressed with different emotions or communication styles can yield divergent outputs, while most benchmarks emphasize only peak performance. We present PromptSE (Prompt Sensitivity Evaluation), a framework that creates semantically equivalent prompt variants with emotion and personality templates, and that evaluates stability using probability aware continuous scoring or using binary pass rates when logits are unavailable. The results are aggregated into a proposed area under curve metric (AUC-E) for cross model comparison. Across 14 models from three families (Llama, Qwen, and DeepSeek), our study shows that performance and stability behave as largely decoupled optimization objectives, and it reveals architectural and scale related patterns that challenge common assumptions about model robustness. The framework supports rapid screening for closed-source models as well as detailed stability analysis in research settings. PromptSE enables practitioners to quantify performance stability trade offs for deployment and model selection, positioning prompt stability as a complementary evaluation dimension alongside performance and fairness, and contributing to more trustworthy AI-assisted software development tools. 

**Abstract (ZH)**: 代码生成模型在软件开发中广泛应用，但其对提示措辞的敏感性仍然研究不足。相同的需求用不同的情绪或沟通风格表达时，可以产生不同的输出，而大多数基准测试仅强调峰值性能。我们提出PromptSE（提示敏感性评估）框架，该框架通过情感和个性模板创建语义等价的提示变体，并使用概率意识的连续评分或在logits不可用时使用二元通过率来评估稳定性。将结果汇总为一个拟议的曲线下面积指标（AUC-E）以进行跨模型比较。在来自三个家族（Llama、Qwen和DeepSeek）的14个模型中，我们的研究显示性能和稳定性几乎是独立的优化目标，并揭示了与架构和规模相关的模式，这些模式挑战了对模型鲁棒性的通用假设。该框架支持对闭源模型的快速筛选以及在研究设置中的详细稳定性分析。PromptSE使实践者能够量化部署和模型选择中的性能稳健性trade-offs，并将提示稳健性定位为与性能和公平性并列的评估维度之一，从而促进更具可信度的AI辅助软件开发工具的发展。 

---
# AgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation 

**Title (ZH)**: AgentCTG: 利用多Agents协作实现文本生成的细粒度精确控制 

**Authors**: Xinxu Zhou, Jiaqi Bai, Zhenqi Sun, Fanxiang Zeng, Yue Liu  

**Link**: [PDF](https://arxiv.org/pdf/2509.13677)  

**Abstract**: Although significant progress has been made in many tasks within the field of Natural Language Processing (NLP), Controlled Text Generation (CTG) continues to face numerous challenges, particularly in achieving fine-grained conditional control over generation. Additionally, in real scenario and online applications, cost considerations, scalability, domain knowledge learning and more precise control are required, presenting more challenge for CTG. This paper introduces a novel and scalable framework, AgentCTG, which aims to enhance precise and complex control over the text generation by simulating the control and regulation mechanisms in multi-agent workflows. We explore various collaboration methods among different agents and introduce an auto-prompt module to further enhance the generation effectiveness. AgentCTG achieves state-of-the-art results on multiple public datasets. To validate its effectiveness in practical applications, we propose a new challenging Character-Driven Rewriting task, which aims to convert the original text into new text that conform to specific character profiles and simultaneously preserve the domain knowledge. When applied to online navigation with role-playing, our approach significantly enhances the driving experience through improved content delivery. By optimizing the generation of contextually relevant text, we enable a more immersive interaction within online communities, fostering greater personalization and user engagement. 

**Abstract (ZH)**: 尽管在自然语言处理（NLP）领域的许多任务中取得了显著进展，受控文本生成（CTG）仍然面临诸多挑战，特别是在实现精细条件控制方面。此外，在实际场景和在线应用中，还需要考虑成本、可扩展性、领域知识学习以及更精确的控制等问题，为CTG提出了更高的要求。本文介绍了一种新颖且可扩展的框架AgentCTG，旨在通过模拟多_agent工作流中的控制和调节机制来增强文本生成的精确和复杂控制。我们探索了不同agent之间的各种协作方法，并引入了一个自动提示模块以进一步提高生成效果。AgentCTG在多个公开数据集上取得了最先进的成果。为验证其在实际应用中的有效性，我们提出了一个新的具有挑战性的基于角色驱动的重写任务，旨在将原始文本转换为符合特定角色特征的新文本，同时保留领域知识。当应用于角色扮演的在线导航中时，我们的方法通过改善内容传递显著提升了驾驶体验。通过对上下文相关文本的优化生成，我们使在线社区内的互动更加沉浸式，促进了更高的个性化和用户参与度。 

---
# Re-purposing SAM into Efficient Visual Projectors for MLLM-Based Referring Image Segmentation 

**Title (ZH)**: 重新利用SAM以实现高效视觉投影器，用于基于MLLM的指针图像分割 

**Authors**: Xiaobo Yang, Xiaojin Gong  

**Link**: [PDF](https://arxiv.org/pdf/2509.13676)  

**Abstract**: Recently, Referring Image Segmentation (RIS) frameworks that pair the Multimodal Large Language Model (MLLM) with the Segment Anything Model (SAM) have achieved impressive results. However, adapting MLLM to segmentation is computationally intensive, primarily due to visual token redundancy. We observe that traditional patch-wise visual projectors struggle to strike a balance between reducing the number of visual tokens and preserving semantic clarity, often retaining overly long token sequences to avoid performance drops. Inspired by text tokenizers, we propose a novel semantic visual projector that leverages semantic superpixels generated by SAM to identify "visual words" in an image. By compressing and projecting semantic superpixels as visual tokens, our approach adaptively shortens the token sequence according to scene complexity while minimizing semantic loss in compression. To mitigate loss of information, we propose a semantic superpixel positional embedding to strengthen MLLM's awareness of superpixel geometry and position, alongside a semantic superpixel aggregator to preserve both fine-grained details inside superpixels and global context outside. Experiments show that our method cuts visual tokens by 93% without compromising performance, notably speeding up MLLM training and inference, and outperforming existing compressive visual projectors on RIS. 

**Abstract (ZH)**: 近期，将多模态大规模语言模型（MLLM）与段Anything模型（SAM）结合以实现引用图像分割（RIS）框架的研究取得了显著成果。然而，将MLLM适应于分割任务在计算上非常密集，主要由于视觉标记冗余。我们观察到，传统的基于patches的视觉 projector在减少视觉标记数量和保持语义清晰度之间难以取得平衡，往往保留过长的标记序列以避免性能下降。受文本标记化启发，我们提出了一种新的语义视觉 projector，利用SAM生成的语义超像素来识别图像中的“视觉单词”。通过压缩和投影语义超像素为视觉标记，我们的方法能够根据场景复杂性自适应地缩短标记序列，同时最小化压缩过程中的语义损失。为减轻信息损失，我们提出了一种语义超像素位置嵌入，以增强MLLM对超像素几何和位置的感知，同时提出了一种语义超像素聚合器，以保留超像素内部的精细细节和超像素外部的全局上下文。实验表明，我们的方法在不牺牲性能的情况下，将视觉标记数量减少了93%，显著加速了MLLM的训练和推理，并在引用图像分割任务上优于现有的压缩视觉投影器。 

---
# CL$^2$GEC: A Multi-Discipline Benchmark for Continual Learning in Chinese Literature Grammatical Error Correction 

**Title (ZH)**: CL$^2$GEC：中文文学语法纠错的持续学习多学科基准 

**Authors**: Shang Qin, Jingheng Ye, Yinghui Li, Hai-Tao Zheng, Qi Li, Jinxiao Shan, Zhixing Li, Hong-Gee Kim  

**Link**: [PDF](https://arxiv.org/pdf/2509.13672)  

**Abstract**: The growing demand for automated writing assistance in diverse academic domains highlights the need for robust Chinese Grammatical Error Correction (CGEC) systems that can adapt across disciplines. However, existing CGEC research largely lacks dedicated benchmarks for multi-disciplinary academic writing, overlooking continual learning (CL) as a promising solution to handle domain-specific linguistic variation and prevent catastrophic forgetting. To fill this crucial gap, we introduce CL$^2$GEC, the first Continual Learning benchmark for Chinese Literature Grammatical Error Correction, designed to evaluate adaptive CGEC across multiple academic fields. Our benchmark includes 10,000 human-annotated sentences spanning 10 disciplines, each exhibiting distinct linguistic styles and error patterns. CL$^2$GEC focuses on evaluating grammatical error correction in a continual learning setting, simulating sequential exposure to diverse academic disciplines to reflect real-world editorial dynamics. We evaluate large language models under sequential tuning, parameter-efficient adaptation, and four representative CL algorithms, using both standard GEC metrics and continual learning metrics adapted to task-level variation. Experimental results reveal that regularization-based methods mitigate forgetting more effectively than replay-based or naive sequential approaches. Our benchmark provides a rigorous foundation for future research in adaptive grammatical error correction across diverse academic domains. 

**Abstract (ZH)**: 不断学习框架下的汉语语法错误修正持续学习基准（CL²GEC）：面向多学科学术写作的汉语文学语法错误修正持续学习基准 

---
# DREAM: Domain-aware Reasoning for Efficient Autonomous Underwater Monitoring 

**Title (ZH)**: DREAM: 领域aware推理实现高效自主水下监控 

**Authors**: Zhenqi Wu, Abhinav Modi, Angelos Mavrogiannis, Kaustubh Joshi, Nikhil Chopra, Yiannis Aloimonos, Nare Karapetyan, Ioannis Rekleitis, Xiaomin Lin  

**Link**: [PDF](https://arxiv.org/pdf/2509.13666)  

**Abstract**: The ocean is warming and acidifying, increasing the risk of mass mortality events for temperature-sensitive shellfish such as oysters. This motivates the development of long-term monitoring systems. However, human labor is costly and long-duration underwater work is highly hazardous, thus favoring robotic solutions as a safer and more efficient option. To enable underwater robots to make real-time, environment-aware decisions without human intervention, we must equip them with an intelligent "brain." This highlights the need for persistent,wide-area, and low-cost benthic monitoring. To this end, we present DREAM, a Vision Language Model (VLM)-guided autonomy framework for long-term underwater exploration and habitat monitoring. The results show that our framework is highly efficient in finding and exploring target objects (e.g., oysters, shipwrecks) without prior location information. In the oyster-monitoring task, our framework takes 31.5% less time than the previous baseline with the same amount of oysters. Compared to the vanilla VLM, it uses 23% fewer steps while covering 8.88% more oysters. In shipwreck scenes, our framework successfully explores and maps the wreck without collisions, requiring 27.5% fewer steps than the vanilla model and achieving 100% coverage, while the vanilla model achieves 60.23% average coverage in our shipwreck environments. 

**Abstract (ZH)**: 基于视觉语言模型的长期水下自主探索与栖息地监测框架 

---
# Sparse Neurons Carry Strong Signals of Question Ambiguity in LLMs 

**Title (ZH)**: 稀疏神经元承载着大语言模型中问题歧义的强烈信号 

**Authors**: Zhuoxuan Zhang, Jinhao Duan, Edward Kim, Kaidi Xu  

**Link**: [PDF](https://arxiv.org/pdf/2509.13664)  

**Abstract**: Ambiguity is pervasive in real-world questions, yet large language models (LLMs) often respond with confident answers rather than seeking clarification. In this work, we show that question ambiguity is linearly encoded in the internal representations of LLMs and can be both detected and controlled at the neuron level. During the model's pre-filling stage, we identify that a small number of neurons, as few as one, encode question ambiguity information. Probes trained on these Ambiguity-Encoding Neurons (AENs) achieve strong performance on ambiguity detection and generalize across datasets, outperforming prompting-based and representation-based baselines. Layerwise analysis reveals that AENs emerge from shallow layers, suggesting early encoding of ambiguity signals in the model's processing pipeline. Finally, we show that through manipulating AENs, we can control LLM's behavior from direct answering to abstention. Our findings reveal that LLMs form compact internal representations of question ambiguity, enabling interpretable and controllable behavior. 

**Abstract (ZH)**: 现实世界问题中的歧义在所难免，而大规模语言模型（LLMs）往往给出自信的回答而非寻求澄清。在本研究中，我们展示了问题歧义在线性编码在LLMs的内部表示中，并可以在神经元级别进行检测和控制。在模型的预填充阶段，我们发现少量神经元，甚至是单个神经元，能够编码问题歧义信息。基于这些编码歧义信息的神经元（AENs）的探针在歧义检测上表现出色，并在不同数据集上具有泛化能力，超过了基于提示和表示的基线方法。逐层分析显示，AENs来源于浅层，表明模型处理管线中早期编码歧义信号。最后，我们展示了通过操纵AENs，可以控制LLMs的直接回答行为转为规避行为。我们发现，LLMs形成了紧凑的问题歧义内部表示，从而实现了可解释和可控的行为。 

---
# Deep Lookup Network 

**Title (ZH)**: 深度查找网络 

**Authors**: Yulan Guo, Longguang Wang, Wendong Mao, Xiaoyu Dong, Yingqian Wang, Li Liu, Wei An  

**Link**: [PDF](https://arxiv.org/pdf/2509.13662)  

**Abstract**: Convolutional neural networks are constructed with massive operations with different types and are highly computationally intensive. Among these operations, multiplication operation is higher in computational complexity and usually requires {more} energy consumption with longer inference time than other operations, which hinders the deployment of convolutional neural networks on mobile devices. In many resource-limited edge devices, complicated operations can be calculated via lookup tables to reduce computational cost. Motivated by this, in this paper, we introduce a generic and efficient lookup operation which can be used as a basic operation for the construction of neural networks. Instead of calculating the multiplication of weights and activation values, simple yet efficient lookup operations are adopted to compute their responses. To enable end-to-end optimization of the lookup operation, we construct the lookup tables in a differentiable manner and propose several training strategies to promote their convergence. By replacing computationally expensive multiplication operations with our lookup operations, we develop lookup networks for the image classification, image super-resolution, and point cloud classification tasks. It is demonstrated that our lookup networks can benefit from the lookup operations to achieve higher efficiency in terms of energy consumption and inference speed while maintaining competitive performance to vanilla convolutional networks. Extensive experiments show that our lookup networks produce state-of-the-art performance on different tasks (both classification and regression tasks) and different data types (both images and point clouds). 

**Abstract (ZH)**: 卷积神经网络构建于大量不同类型的运算之上，计算密集度高。在这类运算中，乘法运算在计算复杂度和通常所需的能量消耗以及推断时间方面高于其他运算，这阻碍了卷积神经网络在移动设备上的部署。在许多资源受限的边缘设备中，可以通过查找表来计算复杂的运算，以降低计算成本。受此启发，本文介绍了一种通用且高效的查找表操作，可作为构建神经网络的基本运算。我们采用简单的高效查找表操作来计算响应，而不是直接计算权重和激活值的乘积。为了实现查找表操作的端到端优化，我们以可微分的方式构建查找表，并提出了几种训练策略以促进其收敛。通过用我们的查找表操作替换计算成本高昂的乘法运算，我们为图像分类、图像超分辨率和点云分类任务开发了查找网络。实验表明，我们的查找网络利用查找表操作在能耗和推断速度方面实现了更高的效率，同时保持了与传统卷积网络相当的性能。大量实验表明，我们的查找网络在不同任务（包括分类和回归任务）和不同类型的数据（包括图像和点云）上均取得了最先进的性能。 

---
# GitHub's Copilot Code Review: Can AI Spot Security Flaws Before You Commit? 

**Title (ZH)**: GitHub Copilot代码审查：AI能在你提交前发现安全漏洞吗？ 

**Authors**: Amena Amro, Manar H. Alalfi  

**Link**: [PDF](https://arxiv.org/pdf/2509.13650)  

**Abstract**: As software development practices increasingly adopt AI-powered tools, ensuring that such tools can support secure coding has become critical. This study evaluates the effectiveness of GitHub Copilot's recently introduced code review feature in detecting security vulnerabilities. Using a curated set of labeled vulnerable code samples drawn from diverse open-source projects spanning multiple programming languages and application domains, we systematically assessed Copilot's ability to identify and provide feedback on common security flaws. Contrary to expectations, our results reveal that Copilot's code review frequently fails to detect critical vulnerabilities such as SQL injection, cross-site scripting (XSS), and insecure deserialization. Instead, its feedback primarily addresses low-severity issues, such as coding style and typographical errors. These findings expose a significant gap between the perceived capabilities of AI-assisted code review and its actual effectiveness in supporting secure development practices. Our results highlight the continued necessity of dedicated security tools and manual code audits to ensure robust software security. 

**Abstract (ZH)**: 随着软件开发实践越来越多地采用AI驱动的工具，确保这些工具能够支持安全编码变得至关重要。本研究评估了GitHub Copilot最近引入的代码审查功能在检测安全漏洞方面的有效性。通过对来自多个编程语言和应用领域的多样化开源项目的精心筛选的标记脆弱代码样本进行系统评估，我们考察了Copilot识别和提供关于常见安全缺陷反馈的能力。与预期相反，我们的结果显示，Copilot的代码审查经常未能检测到诸如SQL注入、跨站脚本(XSS)和不安全反序列化等关键漏洞。相反，其反馈主要关注低 sever 严重程度的问题，如编码风格和拼写错误。这些发现暴露了AI辅助代码审查感知能力和实际支持安全开发实践有效性之间的重要差距。我们的结果强调了继续使用专门的安全工具和人工代码审核以确保软件安全的必要性。 

---
# DeepLogit: A sequentially constrained explainable deep learning modeling approach for transport policy analysis 

**Title (ZH)**: DeepLogit：一种用于交通政策分析的序列约束可解释深度学习建模方法 

**Authors**: Jeremy Oon, Rakhi Manohar Mepparambath, Ling Feng  

**Link**: [PDF](https://arxiv.org/pdf/2509.13633)  

**Abstract**: Despite the significant progress of deep learning models in multitude of applications, their adaption in planning and policy related areas remains challenging due to the black-box nature of these models. In this work, we develop a set of DeepLogit models that follow a novel sequentially constrained approach in estimating deep learning models for transport policy analysis. In the first step of the proposed approach, we estimate a convolutional neural network (CNN) model with only linear terms, which is equivalent of a linear-in-parameter multinomial logit model. We then estimate other deep learning models by constraining the parameters that need interpretability at the values obtained in the linear-in-parameter CNN model and including higher order terms or by introducing advanced deep learning architectures like Transformers. Our approach can retain the interpretability of the selected parameters, yet provides significantly improved model accuracy than the discrete choice model. We demonstrate our approach on a transit route choice example using real-world transit smart card data from Singapore. This study shows the potential for a unifying approach, where theory-based discrete choice model (DCM) and data-driven AI models can leverage each other's strengths in interpretability and predictive power. With the availability of larger datasets and more complex constructions, such approach can lead to more accurate models using discrete choice models while maintaining its applicability in planning and policy-related areas. Our code is available on this https URL . 

**Abstract (ZH)**: 尽管深度学习模型在众多应用中取得了显著进展，但由于这些模型的黑箱性质，它们在规划和政策相关的领域中的应用仍然具有挑战性。在这项工作中，我们开发了一套遵循新颖的序列约束方法的DeepLogit模型，以估计用于交通政策分析的深度学习模型。在所提出方法的第一步中，我们仅估计了一个包含线性项的卷积神经网络（CNN）模型，这相当于一个参数线性化的多项式logit模型。随后，通过将需要可解释性的参数固定为线性参数化的CNN模型中获得的值，并包含高阶项或引入如变换器等先进的深度学习架构，我们估计其他深度学习模型。这种方法可以保持选定参数的可解释性，同时显著提高模型的准确性，超越了离散选择模型。本文利用新加坡实际公交智能卡数据，以公交线路选择为例，展示了该方法的应用。这项研究表明，理论基于的离散选择模型（DCM）和数据驱动的人工智能模型可以通过互补各自的解释性和预测能力，实现统一的方法。随着数据集的增大和模型结构的复杂化，这种方法可以在保持其在规划和政策相关领域的适用性的同时，使用离散选择模型获得更准确的模型。我们的代码可在此链接获得。 

---
# Secure, Scalable and Privacy Aware Data Strategy in Cloud 

**Title (ZH)**: 云环境中安全、可扩展且隐私意识强的数据策略 

**Authors**: Vijay Kumar Butte, Sujata Butte  

**Link**: [PDF](https://arxiv.org/pdf/2509.13627)  

**Abstract**: The enterprises today are faced with the tough challenge of processing, storing large amounts of data in a secure, scalable manner and enabling decision makers to make quick, informed data driven decisions. This paper addresses this challenge and develops an effective enterprise data strategy in the cloud. Various components of an effective data strategy are discussed and architectures addressing security, scalability and privacy aspects are provided. 

**Abstract (ZH)**: 当今企业面临的安全、可扩展地处理和存储大量数据的挑战，并通过数据驱动的快速、明智的决策支持决策者。本文解决了这一挑战，并在云环境中发展了一个有效的企业数据策略。讨论了有效数据策略的各项内容，并提供了涉及安全、可扩展性和隐私方面的架构。 

---
# Mind the Gap: Aligning Knowledge Bases with User Needs to Enhance Mental Health Retrieval 

**Title (ZH)**: 注意差距：将知识库与用户需求对齐以增强心理健康检索 

**Authors**: Amanda Chan, James Jiayu Liu, He Kai, Onno P. Kampman  

**Link**: [PDF](https://arxiv.org/pdf/2509.13626)  

**Abstract**: Access to reliable mental health information is vital for early help-seeking, yet expanding knowledge bases is resource-intensive and often misaligned with user needs. This results in poor performance of retrieval systems when presented concerns are not covered or expressed in informal or contextualized language. We present an AI-based gap-informed framework for corpus augmentation that authentically identifies underrepresented topics (gaps) by overlaying naturalistic user data such as forum posts in order to prioritize expansions based on coverage and usefulness. In a case study, we compare Directed (gap-informed augmentations) with Non-Directed augmentation (random additions), evaluating the relevance and usefulness of retrieved information across four retrieval-augmented generation (RAG) pipelines. Directed augmentation achieved near-optimal performance with modest expansions--requiring only a 42% increase for Query Transformation, 74% for Reranking and Hierarchical, and 318% for Baseline--to reach ~95% of the performance of an exhaustive reference corpus. In contrast, Non-Directed augmentation required substantially larger and thus practically infeasible expansions to achieve comparable performance (232%, 318%, 403%, and 763%, respectively). These results show that strategically targeted corpus growth can reduce content creation demands while sustaining high retrieval and provision quality, offering a scalable approach for building trusted health information repositories and supporting generative AI applications in high-stakes domains. 

**Abstract (ZH)**: 基于AI的缺口导向的语料扩充框架：通过自然用户数据真实识别未充分代表的主题以优先扩充，提升检索性能 

---
# A reduced-order derivative-informed neural operator for subsurface fluid-flow 

**Title (ZH)**: 基于亚模化导数感知神经算子的地下流体流动模型 

**Authors**: Jeongjin, Park, Grant Bruer, Huseyin Tuna Erdinc, Abhinav Prakash Gahlot, Felix J. Herrmann  

**Link**: [PDF](https://arxiv.org/pdf/2509.13620)  

**Abstract**: Neural operators have emerged as cost-effective surrogates for expensive fluid-flow simulators, particularly in computationally intensive tasks such as permeability inversion from time-lapse seismic data, and uncertainty quantification. In these applications, the fidelity of the surrogate's gradients with respect to system parameters is crucial, as the accuracy of downstream tasks, such as optimization and Bayesian inference, relies directly on the quality of the derivative information. Recent advances in physics-informed methods have leveraged derivative information to improve surrogate accuracy. However, incorporating explicit Jacobians can become computationally prohibitive, as the complexity typically scales quadratically with the number of input parameters. To address this limitation, we propose DeFINO (Derivative-based Fisher-score Informed Neural Operator), a reduced-order, derivative-informed training framework. DeFINO integrates Fourier neural operators (FNOs) with a novel derivative-based training strategy guided by the Fisher Information Matrix (FIM). By projecting Jacobians onto dominant eigen-directions identified by the FIM, DeFINO captures critical sensitivity information directly informed by observational data, significantly reducing computational expense. We validate DeFINO through synthetic experiments in the context of subsurface multi-phase fluid-flow, demonstrating improvements in gradient accuracy while maintaining robust forward predictions of underlying fluid dynamics. These results highlight DeFINO's potential to offer practical, scalable solutions for inversion problems in complex real-world scenarios, all at substantially reduced computational cost. 

**Abstract (ZH)**: 基于导数的费isher分数值导向神经算子 

---
# Modernizing Facebook Scoped Search: Keyword and Embedding Hybrid Retrieval with LLM Evaluation 

**Title (ZH)**: 现代优化的Facebook范围搜索：基于关键词和嵌入的混合检索与LLM评估 

**Authors**: Yongye Su, Zeya Zhang, Jane Kou, Cheng Ju, Shubhojeet Sarkar, Yamin Wang, Ji Liu, Shengbo Guo  

**Link**: [PDF](https://arxiv.org/pdf/2509.13603)  

**Abstract**: Beyond general web-scale search, social network search uniquely enables users to retrieve information and discover potential connections within their social context. We introduce a framework of modernized Facebook Group Scoped Search by blending traditional keyword-based retrieval with embedding-based retrieval (EBR) to improve the search relevance and diversity of search results. Our system integrates semantic retrieval into the existing keyword search pipeline, enabling users to discover more contextually relevant group posts. To rigorously assess the impact of this blended approach, we introduce a novel evaluation framework that leverages large language models (LLMs) to perform offline relevance assessments, providing scalable and consistent quality benchmarks. Our results demonstrate that the blended retrieval system significantly enhances user engagement and search quality, as validated by both online metrics and LLM-based evaluation. This work offers practical insights for deploying and evaluating advanced retrieval systems in large-scale, real-world social platforms. 

**Abstract (ZH)**: 超越通用的网页规模搜索，社交网络搜索独特地使用户能够在其社交背景下检索信息并发现潜在连接。我们通过结合传统的基于关键词检索与嵌入式检索（EBR）来改进搜索的相关性和多样性，引入了一个现代化的Facebook组范围搜索框架。我们的系统将语义检索集成到现有的关键词搜索管道中，使用户能够发现更多上下文相关性更强的组帖子。为了严格评估这种混合方法的影响，我们引入了一种新的评估框架，利用大型语言模型（LLMs）进行离线相关性评估，提供可扩展且一致的质量基准。我们的结果表明，混合检索系统显著提高了用户参与度和搜索质量，得到了在线指标和基于LLM的评估的验证。本研究为部署和评估大型实际社交平台上的高级检索系统提供了实用见解。 

---
# Agentic JWT: A Secure Delegation Protocol for Autonomous AI Agents 

**Title (ZH)**: 代理JWT：自主AI代理的安全代理协议 

**Authors**: Abhishek Goswami  

**Link**: [PDF](https://arxiv.org/pdf/2509.13597)  

**Abstract**: Autonomous LLM agents can issue thousands of API calls per hour without human oversight. OAuth 2.0 assumes deterministic clients, but in agentic settings stochastic reasoning, prompt injection, or multi-agent orchestration can silently expand privileges.
We introduce Agentic JWT (A-JWT), a dual-faceted intent token that binds each agent's action to verifiable user intent and, optionally, to a specific workflow step. A-JWT carries an agent's identity as a one-way checksum hash derived from its prompt, tools and configuration, and a chained delegation assertion to prove which downstream agent may execute a given task, and per-agent proof-of-possession keys to prevent replay and in-process impersonation. We define a new authorization mechanism and add a lightweight client shim library that self-verifies code at run time, mints intent tokens, tracks workflow steps and derives keys, thus enabling secure agent identity and separation even within a single process.
We illustrate a comprehensive threat model for agentic applications, implement a Python proof-of-concept and show functional blocking of scope-violating requests, replay, impersonation, and prompt-injection pathways with sub-millisecond overhead on commodity hardware. The design aligns with ongoing OAuth agent discussions and offers a drop-in path toward zero-trust guarantees for agentic applications. A comprehensive performance and security evaluation with experimental results will appear in our forthcoming journal publication 

**Abstract (ZH)**: 自主LLM代理每小时可以发出数千次API调用而无需人类监管。OAuth 2.0 假设确定性客户端，但在代理环境中，随机推理、提示注入或多个代理协同编排可以无声地扩展权限。

我们引入了代理JWT (A-JWT)，这是一种双面意图令牌，将每个代理的动作绑定到可验证的用户意图上，并可选地绑定到特定的工作流步骤。A-JWT 携带代理的身份作为从其提示、工具和配置中导出的一次性校验和哈希，以及证明哪一个下游代理可以执行给定任务的递归委托断言，并提供每个代理的所有权证明密钥以防止重放和内过程冒充。我们定义了一种新的授权机制，并添加了一个轻量级客户端 shim 库，该库可以在运行时自我验证代码、颁发意图令牌、跟踪工作流步骤并生成密钥，从而在单个进程中实现安全的代理身份和隔离。

我们概述了代理应用程序的全面威胁模型，实现了 Python 证明概念并展示了对作用域违规请求、重放、冒充和提示注入途径的功能性阻止，使用大众市场硬件的亚毫秒级开销。该设计与正在进行中的 OAuth 代理讨论相一致，并为代理应用程序提供了一条直接路径以实现零信任保证。全面的性能和安全评估及其实验结果将出现在我们即将发表的期刊出版物中。 

---
# Intelligent Healthcare Imaging Platform An VLM-Based Framework for Automated Medical Image Analysis and Clinical Report Generation 

**Title (ZH)**: 基于VLM的自动化医学图像分析与临床报告生成智能医疗影像平台 

**Authors**: Samer Al-Hamadani  

**Link**: [PDF](https://arxiv.org/pdf/2509.13590)  

**Abstract**: The rapid advancement of artificial intelligence (AI) in healthcare imaging has revolutionized diagnostic medicine and clinical decision-making processes. This work presents an intelligent multimodal framework for medical image analysis that leverages Vision-Language Models (VLMs) in healthcare diagnostics. The framework integrates Google Gemini 2.5 Flash for automated tumor detection and clinical report generation across multiple imaging modalities including CT, MRI, X-ray, and Ultrasound. The system combines visual feature extraction with natural language processing to enable contextual image interpretation, incorporating coordinate verification mechanisms and probabilistic Gaussian modeling for anomaly distribution. Multi-layered visualization techniques generate detailed medical illustrations, overlay comparisons, and statistical representations to enhance clinical confidence, with location measurement achieving 80 pixels average deviation. Result processing utilizes precise prompt engineering and textual analysis to extract structured clinical information while maintaining interpretability. Experimental evaluations demonstrated high performance in anomaly detection across multiple modalities. The system features a user-friendly Gradio interface for clinical workflow integration and demonstrates zero-shot learning capabilities to reduce dependence on large datasets. This framework represents a significant advancement in automated diagnostic support and radiological workflow efficiency, though clinical validation and multi-center evaluation are necessary prior to widespread adoption. 

**Abstract (ZH)**: 医疗影像领域人工智能的飞速发展颠覆了诊断医学和临床决策过程。本文提出了一种智能多模态医疗影像分析框架，利用视觉-语言模型（VLMs）进行医疗诊断。该框架结合了Google Gemini 2.5 Flash实现多模态（CT、MRI、X-ray、超声）影像中的自动化肿瘤检测和临床报告生成。系统结合了视觉特征提取和自然语言处理技术，通过坐标验证机制和概率高斯建模进行异常分布的解释性分析。多层级可视化技术生成详细的医疗图像、叠加比较及统计表示，以增强临床信心，位置测量平均偏差为80像素。结果处理通过精确的提示工程和文本分析提取结构化的临床信息，保持可解释性。实验评估在多模态异常检测方面展现了高绩效。该系统具备用户友好的Gradio界面，集成临床工作流程，并展示零样本学习能力，减少对大规模数据集的依赖。该框架代表了自动诊断支持和放射学工作流程效率的重要进步，但在广泛采用之前需要临床上的验证和多中心评估。 

---
# TreeIRL: Safe Urban Driving with Tree Search and Inverse Reinforcement Learning 

**Title (ZH)**: 基于树搜索和逆强化学习的安全城市驾驶TreeIRL 

**Authors**: Momchil S. Tomov, Sang Uk Lee, Hansford Hendrago, Jinwook Huh, Teawon Han, Forbes Howington, Rafael da Silva, Gianmarco Bernasconi, Marc Heim, Samuel Findler, Xiaonan Ji, Alexander Boule, Michael Napoli, Kuo Chen, Jesse Miller, Boaz Floor, Yunqing Hu  

**Link**: [PDF](https://arxiv.org/pdf/2509.13579)  

**Abstract**: We present TreeIRL, a novel planner for autonomous driving that combines Monte Carlo tree search (MCTS) and inverse reinforcement learning (IRL) to achieve state-of-the-art performance in simulation and in real-world driving. The core idea is to use MCTS to find a promising set of safe candidate trajectories and a deep IRL scoring function to select the most human-like among them. We evaluate TreeIRL against both classical and state-of-the-art planners in large-scale simulations and on 500+ miles of real-world autonomous driving in the Las Vegas metropolitan area. Test scenarios include dense urban traffic, adaptive cruise control, cut-ins, and traffic lights. TreeIRL achieves the best overall performance, striking a balance between safety, progress, comfort, and human-likeness. To our knowledge, our work is the first demonstration of MCTS-based planning on public roads and underscores the importance of evaluating planners across a diverse set of metrics and in real-world environments. TreeIRL is highly extensible and could be further improved with reinforcement learning and imitation learning, providing a framework for exploring different combinations of classical and learning-based approaches to solve the planning bottleneck in autonomous driving. 

**Abstract (ZH)**: TreeIRL：一种结合蒙特卡洛树搜索和逆强化学习的新型自主驾驶规划器 

---
# Dense-Jump Flow Matching with Non-Uniform Time Scheduling for Robotic Policies: Mitigating Multi-Step Inference Degradation 

**Title (ZH)**: 基于非均匀时间调度的密集-跳跃流匹配方法：缓解多步推理退化 

**Authors**: Zidong Chen, Zihao Guo, Peng Wang, ThankGod Itua Egbe, Yan Lyu, Chenghao Qian  

**Link**: [PDF](https://arxiv.org/pdf/2509.13574)  

**Abstract**: Flow matching has emerged as a competitive framework for learning high-quality generative policies in robotics; however, we find that generalisation arises and saturates early along the flow trajectory, in accordance with recent findings in the literature. We further observe that increasing the number of Euler integration steps during inference counter-intuitively and universally degrades policy performance. We attribute this to (i) additional, uniformly spaced integration steps oversample the late-time region, thereby constraining actions towards the training trajectories and reducing generalisation; and (ii) the learned velocity field becoming non-Lipschitz as integration time approaches 1, causing instability. To address these issues, we propose a novel policy that utilises non-uniform time scheduling (e.g., U-shaped) during training, which emphasises both early and late temporal stages to regularise policy training, and a dense-jump integration schedule at inference, which uses a single-step integration to replace the multi-step integration beyond a jump point, to avoid unstable areas around 1. Essentially, our policy is an efficient one-step learner that still pushes forward performance through multi-step integration, yielding up to 23.7% performance gains over state-of-the-art baselines across diverse robotic tasks. 

**Abstract (ZH)**: 流匹配技术已被证明是机器人领域学习高质量生成策略的竞争性框架；然而，我们发现泛化现象在流轨迹早期就已出现并趋于饱和，这与近期文献中的发现一致。我们进一步观察到，在推理过程中增加欧拉积分步骤反而普遍地降低了策略性能。我们将其归因于：（i）额外的均匀分布的积分步骤过度采样晚期区域，从而限制了动作向训练轨迹靠拢，降低了泛化能力；以及（ii）随着积分时间接近1，所学的速度场变得非Lipschitz，导致不稳定性。为了解决这些问题，我们提出了一种新的策略，该策略在训练过程中采用非均匀时间调度（例如U形），强调早期和晚期的时间阶段以规范策略训练，并在推理过程中采用密集跳跃积分调度，使用单步积分替代跳点之后的多步积分，以避免接近1的不稳定区域。本质上，我们的策略是一种高效的单步学习者，仍然通过多步积分促进性能提升，在多种机器人任务上相较于现有最佳基线获得高达23.7%的性能提升。 

---
# Complexity Bounds for Smooth Convex Multiobjective Optimization 

**Title (ZH)**: 光滑凸多目标优化的复杂度界 

**Authors**: Phillipe R. Sampaio  

**Link**: [PDF](https://arxiv.org/pdf/2509.13550)  

**Abstract**: We study the oracle complexity of finding $\varepsilon$-Pareto stationary points in smooth multiobjective optimization with $m$ objectives. The progress metric is the Pareto stationarity gap $\mathcal{G}(x)$ (the norm of an optimal convex combination of gradients). Our contributions are fourfold. (i) For strongly convex objectives, any span first-order method (iterates lie in the span of past gradients) exhibits linear convergence no faster than $\exp(-\Theta(T/\sqrt{\kappa}))$ after $T$ oracle calls, where $\kappa$ is the condition number, implying $\Theta(\sqrt{\kappa}\log(1/\varepsilon))$ iterations; this matches classical accelerated upper bounds. (ii) For convex problems and oblivious one-step methods (a fixed scalarization with pre-scheduled step sizes), we prove a lower bound of order $1/T$ on the best gradient norm among the first $T$ iterates. (iii) Although accelerated gradient descent is outside this restricted class, it is an oblivious span method and attains the same $1/T$ upper rate on a fixed scalarization. (iv) For convex problems and general span methods with adaptive scalarizations, we establish a universal lower bound of order $1/T^{2}$ on the gradient norm of the final iterate after $T$ steps, highlighting a gap between known upper bounds and worst-case guarantees. All bounds hold on non-degenerate instances with distinct objectives and non-singleton Pareto fronts; rates are stated up to universal constants and natural problem scaling. 

**Abstract (ZH)**: 我们研究了具有$m$个目标的光滑多目标优化中找到$\varepsilon$-帕累托渐近点的先验复杂性。进度度量是帕累托渐近性缺口$\mathcal{G}(x)$（最优凸组合梯度的范数）。我们的贡献有四个方面。(i) 对于强凸目标，任何张量一阶方法（迭代点位于过去梯度的子空间中）在$T$次先验调用后的收敛速度不超过$\exp(-\Theta(T/\sqrt{\kappa}))$，其中$\kappa$是条件数，这意味着需要$\Theta(\sqrt{\kappa}\log(1/\varepsilon))$次迭代；这与经典的加速上界匹配。(ii) 对于凸问题和基于预调度步长的无感知一阶方法（固定标量化），我们证明了前$T$次迭代中最佳梯度范数的下界为$1/T$的量级。(iii) 尽管加速梯度下降法超出了这一限制类，但它是一个无感知张量方法，并在固定标量化下达到相同的$1/T$上界。(iv) 对于凸问题和具有自适应标量化的通用张量方法，我们建立了在$T$步后最终迭代点梯度范数的下界为$1/T^2$的量级，突显了已知上界与最坏情况保证之间的差距。所有界在非退化实例和非单目标帕累托前沿上成立；速率表述中包含通用常数和自然问题缩放。 

---
# ColonCrafter: A Depth Estimation Model for Colonoscopy Videos Using Diffusion Priors 

**Title (ZH)**: ColonCrafter：一种使用扩散先验的结肠镜视频深度估计模型 

**Authors**: Romain Hardy, Tyler Berzin, Pranav Rajpurkar  

**Link**: [PDF](https://arxiv.org/pdf/2509.13525)  

**Abstract**: Three-dimensional (3D) scene understanding in colonoscopy presents significant challenges that necessitate automated methods for accurate depth estimation. However, existing depth estimation models for endoscopy struggle with temporal consistency across video sequences, limiting their applicability for 3D reconstruction. We present ColonCrafter, a diffusion-based depth estimation model that generates temporally consistent depth maps from monocular colonoscopy videos. Our approach learns robust geometric priors from synthetic colonoscopy sequences to generate temporally consistent depth maps. We also introduce a style transfer technique that preserves geometric structure while adapting real clinical videos to match our synthetic training domain. ColonCrafter achieves state-of-the-art zero-shot performance on the C3VD dataset, outperforming both general-purpose and endoscopy-specific approaches. Although full trajectory 3D reconstruction remains a challenge, we demonstrate clinically relevant applications of ColonCrafter, including 3D point cloud generation and surface coverage assessment. 

**Abstract (ZH)**: 结肠镜检查中的三维场景理解面临显著挑战，需要自动化方法以实现准确的深度估计。现有的内窥镜深度估计模型在视频序列之间难以保持时间一致性，限制了其在三维重建中的应用。我们提出了ColonCrafter，一种基于扩散的深度估计模型，该模型能从单目结肠镜视频中生成时间一致性深度图。我们的方法通过学习合成结肠镜序列中的鲁棒几何先验知识，生成时间一致性深度图。我们还引入了一种风格迁移技术，该技术在保留几何结构的同时，将真实临床视频适应我们的合成训练域。ColonCrafter在C3VD数据集上实现了最先进的零样本性能，优于通用和内窥镜专用方法。尽管全轨迹三维重建仍然是一个挑战，但我们展示了ColonCrafter在临床相关的应用，包括三维点云生成和表面覆盖评估。 

---
# Reproducible workflow for online AI in digital health 

**Title (ZH)**: 可重复的工作流 for 在线人工智能在数字健康中的应用 

**Authors**: Susobhan Ghosh, Bhanu T. Gulapalli, Daiqi Gao, Asim Gazi, Anna Trella, Ziping Xu, Kelly Zhang, Susan A. Murphy  

**Link**: [PDF](https://arxiv.org/pdf/2509.13499)  

**Abstract**: Online artificial intelligence (AI) algorithms are an important component of digital health interventions. These online algorithms are designed to continually learn and improve their performance as streaming data is collected on individuals. Deploying online AI presents a key challenge: balancing adaptability of online AI with reproducibility. Online AI in digital interventions is a rapidly evolving area, driven by advances in algorithms, sensors, software, and devices. Digital health intervention development and deployment is a continuous process, where implementation - including the AI decision-making algorithm - is interspersed with cycles of re-development and optimization. Each deployment informs the next, making iterative deployment a defining characteristic of this field. This iterative nature underscores the importance of reproducibility: data collected across deployments must be accurately stored to have scientific utility, algorithm behavior must be auditable, and results must be comparable over time to facilitate scientific discovery and trustworthy refinement. This paper proposes a reproducible scientific workflow for developing, deploying, and analyzing online AI decision-making algorithms in digital health interventions. Grounded in practical experience from multiple real-world deployments, this workflow addresses key challenges to reproducibility across all phases of the online AI algorithm development life-cycle. 

**Abstract (ZH)**: 在线人工智能算法是数字健康干预的重要组成部分。在线人工智能在数字干预中的应用是一个快速发展的领域，受到算法、传感器、软件和设备进步的推动。数字健康干预的开发和部署是一个持续的过程，其中实施——包括人工智能决策算法——与重新开发和优化的周期交织在一起。每次部署都为下一步提供信息，使迭代部署成为该领域的一个标志性特征。这种迭代性质突出了可重复性的意义：必须准确存储跨部署收集的数据以具有科学价值，算法行为必须可审计，并且结果必须在时间上可比较，以促进科学发现和值得信赖的改进。本文提出了一种可重复的科学工作流，用于开发、部署和分析数字健康干预中的在线人工智能决策算法。该工作流基于来自多个实际部署的经验，旨在解决在线人工智能算法开发生命周期各阶段的可重复性关键挑战。 

---
# Prompt2DAG: A Modular Methodology for LLM-Based Data Enrichment Pipeline Generation 

**Title (ZH)**: Prompt2DAG: 一种基于LLM的数据增强管道生成模块化方法 

**Authors**: Abubakari Alidu, Michele Ciavotta, Flavio DePaoli  

**Link**: [PDF](https://arxiv.org/pdf/2509.13487)  

**Abstract**: Developing reliable data enrichment pipelines demands significant engineering expertise. We present Prompt2DAG, a methodology that transforms natural language descriptions into executable Apache Airflow DAGs. We evaluate four generation approaches -- Direct, LLM-only, Hybrid, and Template-based -- across 260 experiments using thirteen LLMs and five case studies to identify optimal strategies for production-grade automation. Performance is measured using a penalized scoring framework that combines reliability with code quality (SAT), structural integrity (DST), and executability (PCT). The Hybrid approach emerges as the optimal generative method, achieving a 78.5% success rate with robust quality scores (SAT: 6.79, DST: 7.67, PCT: 7.76). This significantly outperforms the LLM-only (66.2% success) and Direct (29.2% success) methods. Our findings show that reliability, not intrinsic code quality, is the primary differentiator. Cost-effectiveness analysis reveals the Hybrid method is over twice as efficient as Direct prompting per successful DAG. We conclude that a structured, hybrid approach is essential for balancing flexibility and reliability in automated workflow generation, offering a viable path to democratize data pipeline development. 

**Abstract (ZH)**: 开发可靠的数据增强管道需要大量的工程专业知识。我们呈现了Prompt2DAG方法，该方法将自然语言描述转换为可执行的Apache Airflow DAG。我们使用十三种LLM和五项案例研究，在260个实验中评估了四种生成方法——直接、仅LLM、混合和基于模板的方法，以确定生产级自动化的最佳策略。性能通过结合可靠性、代码质量（SAT）、结构完整性（DST）和可执行性（PCT）的惩罚评分框架进行衡量。混合方法 emerged 作为最优生成方法，成功率为78.5%，且具有稳健的质量评分（SAT：6.79，DST：7.67，PCT：7.76）。这种方法在成功率方面显著优于仅LLM（66.2%成功）和直接方法（29.2%成功）。我们的研究结果显示，可靠性而非内在代码质量是主要区别因素。成本效益分析表明，混合方法相对于直接提示在每个成功的DAG方面效率提高了一倍以上。我们得出结论，结构化的混合方法对于平衡自动化工作流生成中的灵活性和可靠性至关重要，提供了 democratize 数据管道开发的可行路径。 

---
# An LLM Agentic Approach for Legal-Critical Software: A Case Study for Tax Prep Software 

**Title (ZH)**: 基于LLM代理方法的法律批判性软件研究：税务准备软件案例研究 

**Authors**: Sina Gogani-Khiabani, Ashutosh Trivedi, Diptikalyan Saha, Saeid Tizpaz-Niari  

**Link**: [PDF](https://arxiv.org/pdf/2509.13471)  

**Abstract**: Large language models (LLMs) show promise for translating natural-language statutes into executable logic, but reliability in legally critical settings remains challenging due to ambiguity and hallucinations. We present an agentic approach for developing legal-critical software, using U.S. federal tax preparation as a case study. The key challenge is test-case generation under the oracle problem, where correct outputs require interpreting law. Building on metamorphic testing, we introduce higher-order metamorphic relations that compare system outputs across structured shifts among similar individuals. Because authoring such relations is tedious and error-prone, we use an LLM-driven, role-based framework to automate test generation and code synthesis. We implement a multi-agent system that translates tax code into executable software and incorporates a metamorphic-testing agent that searches for counterexamples. In experiments, our framework using a smaller model (GPT-4o-mini) achieves a worst-case pass rate of 45%, outperforming frontier models (GPT-4o and Claude 3.5, 9-15%) on complex tax-code tasks. These results support agentic LLM methodologies as a path to robust, trustworthy legal-critical software from natural-language specifications. 

**Abstract (ZH)**: 大型语言模型（LLMs）在将自然语言法规转换为可执行逻辑方面显示出潜力，但在法律关键性设置中的可靠性仍然面临挑战，原因在于模糊性和幻觉。我们提出了一种自主性的方法来开发法律关键性软件，并以美国联邦税务申报为案例研究。关键挑战在于在oracle问题下的测试案例生成，其中正确的输出需要解释法律条文。基于元特征测试，我们引入了更高的阶元特征关系，用于比较相似个体之间结构化变化的系统输出。由于编写此类关系是繁琐且易出错的，我们使用基于大型语言模型的角色化框架来自动化测试和代码生成。我们实现了一个多代理系统，将税法翻译为可执行软件，并包含一个用于搜索反例的元特征测试代理。在实验中，我们的框架使用较小的模型（GPT-4o-mini）在最坏情况下达到了45%的通过率，优于前沿模型（GPT-4o和Claude 3.5，9-15%）在复杂税法任务上的表现。这些结果支持自主性的大型语言模型方法作为从自然语言规范生成稳健可靠的法律关键性软件的路径。 

---
# MapAnything: Universal Feed-Forward Metric 3D Reconstruction 

**Title (ZH)**: MapAnything: 通用前馈度量3D重建 

**Authors**: Nikhil Keetha, Norman Müller, Johannes Schönberger, Lorenzo Porzi, Yuchen Zhang, Tobias Fischer, Arno Knapitsch, Duncan Zauss, Ethan Weber, Nelson Antunes, Jonathon Luiten, Manuel Lopez-Antequera, Samuel Rota Bulò, Christian Richardt, Deva Ramanan, Sebastian Scherer, Peter Kontschieder  

**Link**: [PDF](https://arxiv.org/pdf/2509.13414)  

**Abstract**: We introduce MapAnything, a unified transformer-based feed-forward model that ingests one or more images along with optional geometric inputs such as camera intrinsics, poses, depth, or partial reconstructions, and then directly regresses the metric 3D scene geometry and cameras. MapAnything leverages a factored representation of multi-view scene geometry, i.e., a collection of depth maps, local ray maps, camera poses, and a metric scale factor that effectively upgrades local reconstructions into a globally consistent metric frame. Standardizing the supervision and training across diverse datasets, along with flexible input augmentation, enables MapAnything to address a broad range of 3D vision tasks in a single feed-forward pass, including uncalibrated structure-from-motion, calibrated multi-view stereo, monocular depth estimation, camera localization, depth completion, and more. We provide extensive experimental analyses and model ablations demonstrating that MapAnything outperforms or matches specialist feed-forward models while offering more efficient joint training behavior, thus paving the way toward a universal 3D reconstruction backbone. 

**Abstract (ZH)**: MapAnything：一种统一的Transformer基馈前模型及其在3D场景几何与摄像机直接回归中的应用 

---
# Justice in Judgment: Unveiling (Hidden) Bias in LLM-assisted Peer Reviews 

**Title (ZH)**: 正义在判断：揭示LLM辅助下的peer review中的偏见 

**Authors**: Sai Suresh Marchala Vasu, Ivaxi Sheth, Hui-Po Wang, Ruta Binkyte, Mario Fritz  

**Link**: [PDF](https://arxiv.org/pdf/2509.13400)  

**Abstract**: The adoption of large language models (LLMs) is transforming the peer review process, from assisting reviewers in writing more detailed evaluations to generating entire reviews automatically. While these capabilities offer exciting opportunities, they also raise critical concerns about fairness and reliability. In this paper, we investigate bias in LLM-generated peer reviews by conducting controlled experiments on sensitive metadata, including author affiliation and gender. Our analysis consistently shows affiliation bias favoring institutions highly ranked on common academic rankings. Additionally, we find some gender preferences, which, even though subtle in magnitude, have the potential to compound over time. Notably, we uncover implicit biases that become more evident with token-based soft ratings. 

**Abstract (ZH)**: 大型语言模型的应用正在转变同行评审过程，从帮助评审者撰写更详细的评估到自动生成整个评审。尽管这些能力提供了令人兴奋的机会，但也引发了关于公平性和可靠性的关键问题。在本文中，我们通过在敏感元数据（包括作者 affiliation 和性别）上进行受控实验，研究大型语言模型生成的同行评审中的偏见。我们的分析一致表明， affiliation 偏见倾向于排名较高的学术机构。此外，我们还发现一些性别偏好，尽管其程度较小，但有可能随着时间的推移而累积。值得注意的是，我们发现基于token的柔性评分中存在隐性偏见，这些偏见会变得更加明显。 

---
# EdiVal-Agent: An Object-Centric Framework for Automated, Scalable, Fine-Grained Evaluation of Multi-Turn Editing 

**Title (ZH)**: EdiVal-Agent：面向对象的多轮编辑自动化、可扩展、细粒度评估框架 

**Authors**: Tianyu Chen, Yasi Zhang, Zhi Zhang, Peiyu Yu, Shu Wang, Zhendong Wang, Kevin Lin, Xiaofei Wang, Zhengyuan Yang, Linjie Li, Chung-Ching Lin, Jianwen Xie, Oscar Leong, Lijuan Wang, Ying Nian Wu, Mingyuan Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2509.13399)  

**Abstract**: Instruction-based image editing has advanced rapidly, yet reliable and interpretable evaluation remains a bottleneck. Current protocols either (i) depend on paired reference images -- resulting in limited coverage and inheriting biases from prior generative models -- or (ii) rely solely on zero-shot vision--language models (VLMs), whose prompt-based assessments of instruction following, content consistency, and visual quality are often imprecise.
To address this, we introduce EdiVal-Agent, an automated, scalable, and fine-grained evaluation framework for multi-turn instruction-based editing from an object-centric perspective, supported by a suite of expert tools. Given an image, EdiVal-Agent first decomposes it into semantically meaningful objects, then synthesizes diverse, context-aware editing instructions. For evaluation, it integrates VLMs with open-vocabulary object detectors to assess instruction following, uses semantic-level feature extractors to evaluate content consistency, and leverages human preference models to judge visual quality. We show that combining VLMs with object detectors yields stronger agreement with human judgments in instruction-following evaluation compared to using VLMs alone and CLIP-based metrics. Furthermore, the pipeline's modular design allows future tools to be seamlessly integrated, enhancing evaluation accuracy over time.
Instantiating this pipeline, we build EdiVal-Bench, a multi-turn editing benchmark covering 9 instruction types and 11 state-of-the-art editing models spanning autoregressive (AR) (including Nano Banana, GPT-Image-1), flow-matching, and diffusion paradigms. We demonstrate that EdiVal-Agent can be used to identify existing failure modes, thereby informing the development of the next generation of editing models. Project page: this https URL. 

**Abstract (ZH)**: 基于指令的图像编辑已经取得了快速进步，但可靠的可解释性评估仍然是一大瓶颈。当前的评估协议要么依赖配对的参考图像——这导致评估范围有限，并继承了先前生成模型的偏差——要么完全依赖零样本视觉-语言模型（VLM），这些模型基于提示的评估指令遵循情况、内容一致性和视觉质量往往不够精确。

为了解决这个问题，我们引入了EdiVal-Agent，这是一种从对象中心视角出发的自动化、可扩展且精细的多轮指令基于编辑评估框架，配备了一系列专家工具。给定一张图像，EdiVal-Agent 首先将其分解为语义上有意义的对象，然后合成多样且情境相关的编辑指令。在评估方面，它结合了VLM和开放词汇对象检测器来评估指令遵循情况，使用语义级特征提取器来评估内容一致性，并利用人类偏好评分模型来判断视觉质量。我们证明，将VLM与对象检测器结合起来，在指令遵循评估中与人类判断的一致性比单独使用VLM和CLIP基线指标更强。此外，流水线的模块化设计允许未来工具无缝整合，随着时间推移提升评估准确性。

通过实例化该流水线，我们构建了EdiVal-Bench，这是一个涵盖9种指令类型和11种前沿编辑模型（包括自回归模型（AR），如Nano Banana、GPT-Image-1，流匹配和扩散范式的多轮编辑基准。我们演示了EdiVal-Agent可以用来识别现有的失败模式，从而为下一代编辑模型的开发提供指导。项目页面：this <https://> URL。 

---
# The threat of analytic flexibility in using large language models to simulate human data: A call to attention 

**Title (ZH)**: 使用大型语言模型模拟人类数据中的分析灵活性威胁：引起关注的呼吁 

**Authors**: Jamie Cummins  

**Link**: [PDF](https://arxiv.org/pdf/2509.13397)  

**Abstract**: Social scientists are now using large language models to create "silicon samples" - synthetic datasets intended to stand in for human respondents, aimed at revolutionising human subjects research. However, there are many analytic choices which must be made to produce these samples. Though many of these choices are defensible, their impact on sample quality is poorly understood. I map out these analytic choices and demonstrate how a very small number of decisions can dramatically change the correspondence between silicon samples and human data. Configurations (N = 252) varied substantially in their capacity to estimate (i) rank ordering of participants, (ii) response distributions, and (iii) between-scale correlations. Most critically, configurations were not consistent in quality: those that performed well on one dimension often performed poorly on another, implying that there is no "one-size-fits-all" configuration that optimises the accuracy of these samples. I call for greater attention to the threat of analytic flexibility in using silicon samples. 

**Abstract (ZH)**: 社会科学家现在利用大型语言模型创建“硅样本”——合成数据集，旨在替代人类受访者，以革命性地改变人类主体研究。然而，生成这些样本需要做出许多分析选择，尽管其中许多选择是可辩护的，但它们对样本质量的影响知之甚少。我绘制出这些分析选择，并证明极少数决策可以显著改变硅样本与人类数据的一致性。配置（N=252）在（i）参与者排名排序、（ii）响应分布以及（iii）跨量表相关性估算能力方面差异很大。最关键的是，配置在质量上并不一致：在某一维度表现良好的配置往往在另一维度表现不佳，这表明不存在适用于所有情况的配置以优化这些样本的准确性。我呼吁在使用硅样本时更加关注分析灵活性带来的威胁。 

---
# TICL: Text-Embedding KNN For Speech In-Context Learning Unlocks Speech Recognition Abilities of Large Multimodal Models 

**Title (ZH)**: TICL: 文本嵌入KNN实现基于上下文的语音学习，解锁大型多模态模型的语音识别能力 

**Authors**: Haolong Zheng, Yekaterina Yegorova, Mark Hasegawa-Johnson  

**Link**: [PDF](https://arxiv.org/pdf/2509.13395)  

**Abstract**: Speech foundation models have recently demonstrated the ability to perform Speech In-Context Learning (SICL). Selecting effective in-context examples is crucial for SICL performance, yet selection methodologies remain underexplored. In this work, we propose Text-Embedding KNN for SICL (TICL), a simple pipeline that uses semantic context to enhance off-the-shelf large multimodal models' speech recognition ability without fine-tuning. Across challenging automatic speech recognition tasks, including accented English, multilingual speech, and children's speech, our method enables models to surpass zero-shot performance with up to 84.7% relative WER reduction. We conduct ablation studies to show the robustness and efficiency of our method. 

**Abstract (ZH)**: 基于文本嵌入的最近邻方法在语音下行文学习中的应用：提高现成的大型多模态模型的语音识别能力 

---
# The Intercepted Self: How Generative AI Challenges the Dynamics of the Relational Self 

**Title (ZH)**: 拦截的自我：生成式AI如何挑战关系自我的动态 

**Authors**: Sandrine R. Schiller, Camilo Miguel Signorelli, Filippos Stamatiou  

**Link**: [PDF](https://arxiv.org/pdf/2509.13391)  

**Abstract**: Generative AI is changing our way of interacting with technology, others, and ourselves. Systems such as Microsoft copilot, Gemini and the expected Apple intelligence still awaits our prompt for action. Yet, it is likely that AI assistant systems will only become better at predicting our behaviour and acting on our behalf. Imagine new generations of generative and predictive AI deciding what you might like best at a new restaurant, picking an outfit that increases your chances on your date with a partner also chosen by the same or a similar system. Far from a science fiction scenario, the goal of several research programs is to build systems capable of assisting us in exactly this manner. The prospect urges us to rethink human-technology relations, but it also invites us to question how such systems might change the way we relate to ourselves. Building on our conception of the relational self, we question the possible effects of generative AI with respect to what we call the sphere of externalised output, the contextual sphere and the sphere of self-relating. In this paper, we attempt to deepen the existential considerations accompanying the AI revolution by outlining how generative AI enables the fulfilment of tasks and also increasingly anticipates, i.e. intercepts, our initiatives in these different spheres. 

**Abstract (ZH)**: 生成式人工智能正在改变我们与技术、他人和自身的交互方式。诸如微软小令景、Gemini以及预期中的苹果智能助手等系统仍在等待我们的指令。然而，AI助手系统很可能会更擅长预测我们的行为并代我们行事。想象一下，新一代的生成式和预测式AI决定你在一个新餐馆里可能会最喜欢什么，挑选一种增加你在与由同一系统或类似系统选择的伴侣约会时成功率的着装。这不仅不是一个科幻场景，而且多个研究计划的目标是构建能够以这种方式协助我们的系统。这一前景促使我们重新思考人机关系，同时也促使我们质疑这些系统如何改变我们与自身的关联方式。基于我们对关系自我的理解，我们质疑生成式人工智能在外部输出领域、情境领域和自相关领域可能产生的影响。在本文中，我们尝试通过阐述生成式人工智能在这些不同领域如何使任务得以实现并越来越抢先干预我们的行动，深化对人工智能革命的本体论考虑。 

---
# A Domain Knowledge Informed Approach for Anomaly Detection of Electric Vehicle Interior Sounds 

**Title (ZH)**: 基于领域知识的电动汽车内饰声音异常检测方法 

**Authors**: Deepti Kunte, Bram Cornelis, Claudio Colangeli, Karl Janssens, Brecht Van Baelen, Konstantinos Gryllias  

**Link**: [PDF](https://arxiv.org/pdf/2509.13390)  

**Abstract**: The detection of anomalies in automotive cabin sounds is critical for ensuring vehicle quality and maintaining passenger comfort. In many real-world settings, this task is more appropriately framed as an unsupervised learning problem rather than the supervised case due to the scarcity or complete absence of labeled faulty data. In such an unsupervised setting, the model is trained exclusively on healthy samples and detects anomalies as deviations from normal behavior. However, in the absence of labeled faulty samples for validation and the limited reliability of commonly used metrics, such as validation reconstruction error, effective model selection remains a significant challenge. To overcome these limitations, a domain-knowledge-informed approach for model selection is proposed, in which proxy-anomalies engineered through structured perturbations of healthy spectrograms are used in the validation set to support model selection. The proposed methodology is evaluated on a high-fidelity electric vehicle dataset comprising healthy and faulty cabin sounds across five representative fault types viz., Imbalance, Modulation, Whine, Wind, and Pulse Width Modulation. This dataset, generated using advanced sound synthesis techniques, and validated via expert jury assessments, has been made publicly available to facilitate further research. Experimental evaluations on the five fault cases demonstrate the selection of optimal models using proxy-anomalies, significantly outperform conventional model selection strategies. 

**Abstract (ZH)**: 汽车内饰声音异常检测对于确保车辆质量和维持乘客舒适度至关重要。在许多实际场景中，由于故障标签数据的稀缺或完全缺失，此任务更适合作为无监督学习问题而非有监督学习问题。在这种无监督情况下，模型仅使用健康样本进行训练，并通过检测与正常行为的偏差来识别异常。然而，在缺乏标签故障样本进行验证，并且常用验证重建误差等指标可靠性有限的情况下，有效的模型选择仍然是一个重大挑战。为克服这些局限性，提出了一种基于领域知识的模型选择方法，其中通过结构化修改健康频谱图生成的代理异常用于验证集，以支持模型选择。所提出的方法在包含五种代表性故障类型（不平衡、调制、鸣叫声、风声和脉冲宽度调制）的健康和故障 cabin 声音的高保真电动汽车数据集上进行了评估。该数据集使用高级声音合成技术生成，并通过专家评审验证，已公开发布以促进进一步研究。在五个故障案例的实验评估中证明，使用代理异常可以显著超越传统模型选择策略，选择出最优模型。 

---
# Landcover classification and change detection using remote sensing and machine learning: a case study of Western Fiji 

**Title (ZH)**: 基于遥感和机器学习的土地覆盖分类与变化检测：斐济西部案例研究 

**Authors**: Yadvendra Gurjar, Ruoni Wan, Ehsan Farahbakhsh, Rohitash Chandra  

**Link**: [PDF](https://arxiv.org/pdf/2509.13388)  

**Abstract**: As a developing country, Fiji is facing rapid urbanisation, which is visible in the massive development projects that include housing, roads, and civil works. In this study, we present machine learning and remote sensing frameworks to compare land use and land cover change from 2013 to 2024 in Nadi, Fiji. The ultimate goal of this study is to provide technical support in land cover/land use modelling and change detection. We used Landsat-8 satellite image for the study region and created our training dataset with labels for supervised machine learning. We used Google Earth Engine and unsupervised machine learning via k-means clustering to generate the land cover map. We used convolutional neural networks to classify the selected regions' land cover types. We present a visualisation of change detection, highlighting urban area changes over time to monitor changes in the map. 

**Abstract (ZH)**: 作为一个发展中国家，斐济正面临快速城市化，这在大规模的发展项目中尤为明显，包括住房、道路和基础设施建设。在本研究中，我们提出机器学习和遥感框架，比较斐济纳迪地区2013年至2024年的土地利用和土地覆盖变化。本研究最终目标是为土地覆盖/利用建模和变化检测提供技术支持。我们使用陆地卫星8号图像进行研究，并创建了带有监督机器学习标签的训练数据集。我们使用Google Earth Engine和基于k均值聚类的无监督机器学习生成土地覆盖图。我们使用卷积神经网络对选定区域的土地覆盖类型进行分类。我们展示了变化检测的可视化，突出显示随时间变化的城市区域，以监测地图的变化。 

---
# Uncovering AI Governance Themes in EU Policies using BERTopic and Thematic Analysis 

**Title (ZH)**: 使用BERTopic和主题分析揭示欧盟政策中的AI治理主题 

**Authors**: Delaram Golpayegani, Marta Lasek-Markey, Arjumand Younus, Aphra Kerr, Dave Lewis  

**Link**: [PDF](https://arxiv.org/pdf/2509.13387)  

**Abstract**: The upsurge of policies and guidelines that aim to ensure Artificial Intelligence (AI) systems are safe and trustworthy has led to a fragmented landscape of AI governance. The European Union (EU) is a key actor in the development of such policies and guidelines. Its High-Level Expert Group (HLEG) issued an influential set of guidelines for trustworthy AI, followed in 2024 by the adoption of the EU AI Act. While the EU policies and guidelines are expected to be aligned, they may differ in their scope, areas of emphasis, degrees of normativity, and priorities in relation to AI. To gain a broad understanding of AI governance from the EU perspective, we leverage qualitative thematic analysis approaches to uncover prevalent themes in key EU documents, including the AI Act and the HLEG Ethics Guidelines. We further employ quantitative topic modelling approaches, specifically through the use of the BERTopic model, to enhance the results and increase the document sample to include EU AI policy documents published post-2018. We present a novel perspective on EU policies, tracking the evolution of its approach to addressing AI governance. 

**Abstract (ZH)**: 欧盟政策和准则的兴起导致了人工智能治理的碎片化景观：从欧盟视角探讨可信人工智能治理的演进 

---
# ASTREA: Introducing Agentic Intelligence for Orbital Thermal Autonomy 

**Title (ZH)**: ASTREA: 引入自主智能实现 orbital 热控自主性 

**Authors**: Alejandro D. Mousist  

**Link**: [PDF](https://arxiv.org/pdf/2509.13380)  

**Abstract**: This paper presents ASTREA, the first agentic system deployed on flight-heritage hardware (TRL 9) for autonomous spacecraft operations. Using thermal control as a representative use case, we integrate a resource-constrained Large Language Model (LLM) agent with a reinforcement learning controller in an asynchronous architecture tailored for space-qualified platforms. Ground experiments show that LLM-guided supervision improves thermal stability and reduces violations, confirming the feasibility of combining semantic reasoning with adaptive control under hardware constraints. However, on-orbit validation aboard the International Space Station (ISS) reveals performance degradation caused by inference latency mismatched with the rapid thermal cycles characteristic of Low Earth Orbit (LEO) satellites. These results highlight both the opportunities and current limitations of agentic LLM-based systems in real flight environments, providing practical design guidelines for future space autonomy. 

**Abstract (ZH)**: ASTREA：部署在飞行遗产硬件上的首个自主航天器操作代理系统 

---
# An Empirical Analysis of VLM-based OOD Detection: Mechanisms, Advantages, and Sensitivity 

**Title (ZH)**: 基于VLM的OOD检测的实证分析：机制、优势与敏感性 

**Authors**: Yuxiao Lee, Xiaofeng Cao, Wei Ye, Jiangchao Yao, Jingkuan Song, Heng Tao Shen  

**Link**: [PDF](https://arxiv.org/pdf/2509.13375)  

**Abstract**: Vision-Language Models (VLMs), such as CLIP, have demonstrated remarkable zero-shot out-of-distribution (OOD) detection capabilities, vital for reliable AI systems. Despite this promising capability, a comprehensive understanding of (1) why they work so effectively, (2) what advantages do they have over single-modal methods, and (3) how is their behavioral robustness -- remains notably incomplete within the research community. This paper presents a systematic empirical analysis of VLM-based OOD detection using in-distribution (ID) and OOD prompts. (1) Mechanisms: We systematically characterize and formalize key operational properties within the VLM embedding space that facilitate zero-shot OOD detection. (2) Advantages: We empirically quantify the superiority of these models over established single-modal approaches, attributing this distinct advantage to the VLM's capacity to leverage rich semantic novelty. (3) Sensitivity: We uncovers a significant and previously under-explored asymmetry in their robustness profile: while exhibiting resilience to common image noise, these VLM-based methods are highly sensitive to prompt phrasing. Our findings contribute a more structured understanding of the strengths and critical vulnerabilities inherent in VLM-based OOD detection, offering crucial, empirically-grounded guidance for developing more robust and reliable future designs. 

**Abstract (ZH)**: 基于视觉-语言模型的异常分布检测：机制、优势与敏感性分析 

---
# Generative AI Pipeline for Interactive Prompt-driven 2D-to-3D Vascular Reconstruction for Fontan Geometries from Contrast-Enhanced X-Ray Fluoroscopy Imaging 

**Title (ZH)**: 基于生成式AI的工作流：交互式提示驱动的从对比增强X射线荧光成像重建Fontan几何的2D至3D血管重建 

**Authors**: Prahlad G Menon  

**Link**: [PDF](https://arxiv.org/pdf/2509.13372)  

**Abstract**: Fontan palliation for univentricular congenital heart disease progresses to hemodynamic failure with complex flow patterns poorly characterized by conventional 2D imaging. Current assessment relies on fluoroscopic angiography, providing limited 3D geometric information essential for computational fluid dynamics (CFD) analysis and surgical planning.
A multi-step AI pipeline was developed utilizing Google's Gemini 2.5 Flash (2.5B parameters) for systematic, iterative processing of fluoroscopic angiograms through transformer-based neural architecture. The pipeline encompasses medical image preprocessing, vascular segmentation, contrast enhancement, artifact removal, and virtual hemodynamic flow visualization within 2D projections. Final views were processed through Tencent's Hunyuan3D-2mini (384M parameters) for stereolithography file generation.
The pipeline successfully generated geometrically optimized 2D projections from single-view angiograms after 16 processing steps using a custom web interface. Initial iterations contained hallucinated vascular features requiring iterative refinement to achieve anatomically faithful representations. Final projections demonstrated accurate preservation of complex Fontan geometry with enhanced contrast suitable for 3D conversion. AI-generated virtual flow visualization identified stagnation zones in central connections and flow patterns in branch arteries. Complete processing required under 15 minutes with second-level API response times.
This approach demonstrates clinical feasibility of generating CFD-suitable geometries from routine angiographic data, enabling 3D generation and rapid virtual flow visualization for cursory insights prior to full CFD simulation. While requiring refinement cycles for accuracy, this establishes foundation for democratizing advanced geometric and hemodynamic analysis using readily available imaging data. 

**Abstract (ZH)**: Fontan矫治在单心室先天性心脏病中的进展与复杂血流模式的常规二维成像 characterization不足：一种多步AI管道的应用 

---
# The Provenance Problem: LLMs and the Breakdown of Citation Norms 

**Title (ZH)**: 来源问题：LLMs与引文规范的 breakdown 

**Authors**: Brian D. Earp, Haotian Yuan, Julian Koplin, Sebastian Porsdam Mann  

**Link**: [PDF](https://arxiv.org/pdf/2509.13365)  

**Abstract**: The increasing use of generative AI in scientific writing raises urgent questions about attribution and intellectual credit. When a researcher employs ChatGPT to draft a manuscript, the resulting text may echo ideas from sources the author has never encountered. If an AI system reproduces insights from, for example, an obscure 1975 paper without citation, does this constitute plagiarism? We argue that such cases exemplify the 'provenance problem': a systematic breakdown in the chain of scholarly credit. Unlike conventional plagiarism, this phenomenon does not involve intent to deceive (researchers may disclose AI use and act in good faith) yet still benefit from the uncredited intellectual contributions of others. This dynamic creates a novel category of attributional harm that current ethical and professional frameworks fail to address. As generative AI becomes embedded across disciplines, the risk that significant ideas will circulate without recognition threatens both the reputational economy of science and the demands of epistemic justice. This Perspective analyzes how AI challenges established norms of authorship, introduces conceptual tools for understanding the provenance problem, and proposes strategies to preserve integrity and fairness in scholarly communication. 

**Abstract (ZH)**: 生成式AI在科学写作中的广泛应用引发了关于归属和智力信用的紧迫问题。 

---
# Evaluating undergraduate mathematics examinations in the era of generative AI: a curriculum-level case study 

**Title (ZH)**: 评估生成式AI时代本科数学考试：课程层面的案例研究 

**Authors**: Benjamin J. Walker, Beatriz Navarro Lameda, Ruth A. Reynolds  

**Link**: [PDF](https://arxiv.org/pdf/2509.13359)  

**Abstract**: Generative artificial intelligence (GenAI) tools such as OpenAI's ChatGPT are transforming the educational landscape, prompting reconsideration of traditional assessment practices. In parallel, universities are exploring alternatives to in-person, closed-book examinations, raising concerns about academic integrity and pedagogical alignment in uninvigilated settings. This study investigates whether traditional closed-book mathematics examinations retain their pedagogical relevance when hypothetically administered in uninvigilated, open-book settings with GenAI access. Adopting an empirical approach, we generate, transcribe, and blind-mark GenAI submissions to eight undergraduate mathematics examinations at a Russel Group university, spanning the entirety of the first-year curriculum. By combining independent GenAI responses to individual questions, we enable a meaningful evaluation of GenAI performance, both at the level of modules and across the first-year curriculum. We find that GenAI attainment is at the level of a first-class degree, though current performance can vary between modules. Further, we find that GenAI performance is remarkably consistent when viewed across the entire curriculum, significantly more so than that of students in invigilated examinations. Our findings evidence the need for redesigning assessments in mathematics for unsupervised settings, and highlight the potential reduction in pedagogical value of current standards in the era of generative artificial intelligence. 

**Abstract (ZH)**: 生成式人工智能工具在开放书、有生成式人工智能接入情况下，传统闭卷数学考试的 pedagogical 价值探究 

---
# Synthetic Data and the Shifting Ground of Truth 

**Title (ZH)**: 合成数据与真理基础的变动性 

**Authors**: Dietmar Offenhuber  

**Link**: [PDF](https://arxiv.org/pdf/2509.13355)  

**Abstract**: The emergence of synthetic data for privacy protection, training data generation, or simply convenient access to quasi-realistic data in any shape or volume complicates the concept of ground truth. Synthetic data mimic real-world observations, but do not refer to external features. This lack of a representational relationship, however, not prevent researchers from using synthetic data as training data for AI models and ground truth repositories. It is claimed that the lack of data realism is not merely an acceptable tradeoff, but often leads to better model performance than realistic data: compensate for known biases, prevent overfitting and support generalization, and make the models more robust in dealing with unexpected outliers. Indeed, injecting noisy and outright implausible data into training sets can be beneficial for the model. This greatly complicates usual assumptions based on which representational accuracy determines data fidelity (garbage in - garbage out). Furthermore, ground truth becomes a self-referential affair, in which the labels used as a ground truth repository are themselves synthetic products of a generative model and as such not connected to real-world observations. My paper examines how ML researchers and practitioners bootstrap ground truth under such paradoxical circumstances without relying on the stable ground of representation and real-world reference. It will also reflect on the broader implications of a shift from a representational to what could be described as a mimetic or iconic concept of data. 

**Abstract (ZH)**: 合成数据在隐私保护、训练数据生成或简单地方便访问各种形态和规模的准真实数据的出现使真实数据的概念复杂化。合成数据模拟真实世界的观察，但不参考外部特征。然而，缺乏代表关系并未阻止研究人员使用合成数据作为AI模型的训练数据和真实数据的替代品。人们声称，数据的真实性并非仅仅是可接受的折衷，反而常常导致比真实数据更好的模型性能：补偿已知的偏差、防止过拟合并支持泛化，使模型更健壮地处理意外的异常值。实际上，向训练集中注入噪音和完全不可信的数据对模型是有益的。这极大地复杂了基于代表性准确性决定数据 fidelity的常规假设（ garbage in - garbage out）。此外，真实数据成为一种自我参照的现象，在这种现象中，用作真实数据替代品的标签本身就是生成模型的产物，因此与真实世界的观察没有关联。我的论文探讨了在这些悖论情况下，如何促使ML研究人员和实践者建立真实数据的概念，而不依赖于代表性和现实世界的参考。它还将反思从代表性到可以称为拟态或图示数据概念的转变所带来的更广泛影响。 

---
# Hybrid Quantum-Classical Model for Image Classification 

**Title (ZH)**: 量子经典混合模型在图像分类中的应用 

**Authors**: Muhammad Adnan Shahzad  

**Link**: [PDF](https://arxiv.org/pdf/2509.13353)  

**Abstract**: This study presents a systematic comparison between hybrid quantum-classical neural networks and purely classical models across three benchmark datasets (MNIST, CIFAR100, and STL10) to evaluate their performance, efficiency, and robustness. The hybrid models integrate parameterized quantum circuits with classical deep learning architectures, while the classical counterparts use conventional convolutional neural networks (CNNs). Experiments were conducted over 50 training epochs for each dataset, with evaluations on validation accuracy, test accuracy, training time, computational resource usage, and adversarial robustness (tested with $\epsilon=0.1$ perturbations).Key findings demonstrate that hybrid models consistently outperform classical models in final accuracy, achieving {99.38\% (MNIST), 41.69\% (CIFAR100), and 74.05\% (STL10) validation accuracy, compared to classical benchmarks of 98.21\%, 32.25\%, and 63.76\%, respectively. Notably, the hybrid advantage scales with dataset complexity, showing the most significant gains on CIFAR100 (+9.44\%) and STL10 (+10.29\%). Hybrid models also train 5--12$\times$ faster (e.g., 21.23s vs. 108.44s per epoch on MNIST) and use 6--32\% fewer parameters} while maintaining superior generalization to unseen test this http URL robustness tests reveal that hybrid models are significantly more resilient on simpler datasets (e.g., 45.27\% robust accuracy on MNIST vs. 10.80\% for classical) but show comparable fragility on complex datasets like CIFAR100 ($\sim$1\% robustness for both). Resource efficiency analyses indicate that hybrid models consume less memory (4--5GB vs. 5--6GB for classical) and lower CPU utilization (9.5\% vs. 23.2\% on average).These results suggest that hybrid quantum-classical architectures offer compelling advantages in accuracy, training efficiency, and parameter scalability, particularly for complex vision tasks. 

**Abstract (ZH)**: 这项研究在MNIST、CIFAR100和STL10三个基准数据集上系统比较了混合量子-古典神经网络和纯古典模型的性能、效率和鲁棒性。混合模型将参数化量子电路与经典的深度学习架构结合，而纯古典模型则使用传统的卷积神经网络（CNNs）。每个数据集在50个训练周期进行实验，评估验证准确率、测试准确率、训练时间、计算资源使用情况以及对抗鲁棒性（以$\epsilon=0.1$的扰动进行测试）。关键发现表明，混合模型在最终准确率上始终优于经典模型，在MNIST、CIFAR100和STL10上的验证准确率分别为99.38%、41.69%和74.05%，而经典模型的基准值分别为98.21%、32.25%和63.76%。值得注意的是，混合模型的优势随着数据集复杂度的增加而放大，在CIFAR100上提高了9.44%，在STL10上提高了10.29%。混合模型还比经典模型快5-12倍（例如，在MNIST上，每epoch训练时间分别为21.23秒和108.44秒），参数量少6-32%，同时保持更好的对未见测试集的一般化能力。鲁棒性测试结果显示，混合模型在简单数据集上的鲁棒准确率显著更高（例如，在MNIST上的鲁棒准确率为45.27%，而经典模型为10.80%），但在复杂数据集如CIFAR100上表现出相当的脆弱性（两者都约为1%的鲁棒性）。资源效率分析表明，混合模型消耗更少的内存（4-5GB对经典模型的5-6GB），并且更低的CPU利用率（平均9.5%对经典模型的23.2%）。这些结果表明，混合量子-古典架构在准确性、训练效率和参数可扩展性方面，尤其是在复杂的视觉任务中，提供了显著的优势。 

---
# Label-Efficient Grasp Joint Prediction with Point-JEPA 

**Title (ZH)**: 标签高效的抓取关节预测ewith点-JEPA 

**Authors**: Jed Guzelkabaagac, Boris Petrović  

**Link**: [PDF](https://arxiv.org/pdf/2509.13349)  

**Abstract**: We investigate whether 3D self-supervised pretraining with a Joint-Embedding Predictive Architecture (Point-JEPA) enables label-efficient grasp joint-angle prediction. Using point clouds tokenized from meshes and a ShapeNet-pretrained Point-JEPA encoder, we train a lightweight multi-hypothesis head with winner-takes-all and evaluate by top-logit selection. On DLR-Hand II with object-level splits, Point-JEPA reduces RMSE by up to 26% in low-label regimes and reaches parity with full supervision. These results suggest JEPA-style pretraining is a practical approach for data-efficient grasp learning. 

**Abstract (ZH)**: 基于Joint-Embedding Predictive Architecture的3D自监督预训练是否能实现标签高效的抓取关节角预测：点云表示下的实证研究 

---
# Accuracy Paradox in Large Language Models: Regulating Hallucination Risks in Generative AI 

**Title (ZH)**: 大型语言模型中的准确性悖论：生成型AI中调节幻觉风险的研究 

**Authors**: Zihao Li, Weiwei Yi, Jiahong Chen  

**Link**: [PDF](https://arxiv.org/pdf/2509.13345)  

**Abstract**: As Large Language Models (LLMs) permeate everyday decision-making, their epistemic and societal risks demand urgent scrutiny. Hallucinations, the generation of fabricated, misleading, oversimplified or untrustworthy outputs, has emerged as imperative challenges. While regulatory, academic, and technical discourse position accuracy as the principal benchmark for mitigating such harms, this article contends that overreliance on accuracy misdiagnoses the problem and has counterproductive effect: the accuracy paradox. Drawing on interdisciplinary literatures, this article develops a taxonomy of hallucination types and shows the paradox along three intertwining dimensions: outputs, individuals and society. First, accuracy functions as a superficial proxy for reliability, incentivising the optimisation of rhetorical fluency and surface-level correctness over epistemic trustworthiness. This encourages passive user trust in outputs that appear accurate but epistemically untenable. Second, accuracy as a singular metric fails to detect harms that are not factually false but are nonetheless misleading, value-laden, or socially distorting, including consensus illusions, sycophantic alignment, and subtle manipulation. Third, regulatory overemphasis on accuracy obscures the wider societal consequences of hallucination, including social sorting, privacy violations, equity harms, epistemic convergence that marginalises dissent, reduces pluralism, and causes social deskilling. By examining the EU AI Act, GDPR, and DSA, the article argues that current regulations are not yet structurally equipped to address these epistemic, relational, and systemic harms and exacerbated by the overreliance on accuracy. By exposing such conceptual and practical challenges, this article calls for a fundamental shift towards pluralistic, context-aware, and manipulation-resilient approaches to AI trustworthy governance. 

**Abstract (ZH)**: 大型语言模型（LLMs）渗透日常决策后，其认识论和社会风险亟需紧急审查。幻觉，即生成虚假的、误导的、过度简化或不值得信赖的输出，已成为关键挑战。尽管监管、学术和技术界的讨论将准确性视为减轻此类危害的主要标准，本文认为过度依赖准确性会对问题进行误诊，并产生反效作用：准确性悖论。基于跨学科文献，本文发展了幻觉类型的分类，并通过三个交织的维度展示了悖论：输出、个体和社会。首先，准确性充当了可靠性的表面代理，促进了修辞流畅性和表面正确性的优化，而忽略了认识论的信任。这鼓励用户对看似准确但实际上在认识论上站不住脚的输出产生被动信任。其次，作为单一指标的准确性无法识别并非事实错误但却具有误导性、价值观导向或社会变形的危害，包括共识幻觉、逢迎对齐和微妙操控。第三，监管对准确性的过度强调掩盖了幻觉更广泛的社会后果，包括社会分类、隐私侵犯、公平危害、共识收敛边缘化不同意见，减少多元性，并导致社会脱技能。通过分析欧盟AI法案、GDPR和DSA，本文认为现有监管尚未结构化地应对这些认识论、关系性和系统性危害，并因过度依赖准确性而加剧。通过揭示这些概念性和实践性挑战，本文呼吁向多元、上下文意识和抗操控的AI可信治理方法的根本性转变。 

---
# Real World Robotic Exploration using Deep Neural Networks Trained in Photorealistic Reconstructed Environments 

**Title (ZH)**: 使用在 photorealistic 重建环境中训练的深度神经网络进行真实的机器人探索 

**Authors**: Isaac Ronald Ward  

**Link**: [PDF](https://arxiv.org/pdf/2509.13342)  

**Abstract**: In this work, an existing deep neural network approach for determining a robot's pose from visual information (RGB images) is modified, improving its localization performance without impacting its ease of training. Explicitly, the network's loss function is extended in a manner which intuitively combines the positional and rotational error in order to increase robustness to perceptual aliasing. An improvement in the localization accuracy for indoor scenes is observed: with decreases of up to 9.64% and 2.99% in the median positional and rotational error respectively, when compared to the unmodified network.
Additionally, photogrammetry data is used to produce a pose-labelled dataset which allows the above model to be trained on a local environment, resulting in localization accuracies of 0.11m & 0.89 degrees. This trained model forms the basis of a navigation algorithm, which is tested in real-time on a TurtleBot (a wheeled robotic device). As such, this work introduces a full pipeline for creating a robust navigational algorithm for any given real world indoor scene; the only requirement being a collection of images from the scene, which can be captured in as little as 330 seconds of 

**Abstract (ZH)**: 基于视觉信息（RGB图像）改进的机器人姿态识别方法：提高定位性能而不影响训练难度，并应用于室内场景的导航算法 

---
# Proximity-Based Evidence Retrieval for Uncertainty-Aware Neural Networks 

**Title (ZH)**: 基于邻近性的证据检索以实现不确定性感知神经网络 

**Authors**: Hassan Gharoun, Mohammad Sadegh Khorshidi, Kasra Ranjbarigderi, Fang Chen, Amir H. Gandomi  

**Link**: [PDF](https://arxiv.org/pdf/2509.13338)  

**Abstract**: This work proposes an evidence-retrieval mechanism for uncertainty-aware decision-making that replaces a single global cutoff with an evidence-conditioned, instance-adaptive criterion. For each test instance, proximal exemplars are retrieved in an embedding space; their predictive distributions are fused via Dempster-Shafer theory. The resulting fused belief acts as a per-instance thresholding mechanism. Because the supporting evidences are explicit, decisions are transparent and auditable. Experiments on CIFAR-10/100 with BiT and ViT backbones show higher or comparable uncertainty-aware performance with materially fewer confidently incorrect outcomes and a sustainable review load compared with applying threshold on prediction entropy. Notably, only a few evidences are sufficient to realize these gains; increasing the evidence set yields only modest changes. These results indicate that evidence-conditioned tagging provides a more reliable and interpretable alternative to fixed prediction entropy thresholds for operational uncertainty-aware decision-making. 

**Abstract (ZH)**: 基于证据检索的不确定性意识决策机制：用实例适应性标准替代固定全局阈值 

---
# Explainable AI-Enhanced Supervisory Control for High-Precision Spacecraft Formation 

**Title (ZH)**: 可解释的人工智能增强监督控制以实现高精度航天器编队飞行 

**Authors**: Reza Pirayeshshirazinezhad  

**Link**: [PDF](https://arxiv.org/pdf/2509.13331)  

**Abstract**: We use artificial intelligence (AI) and supervisory adaptive control systems to plan and optimize the mission of precise spacecraft formation. Machine learning and robust control enhance the efficiency of spacecraft precision formation of the Virtual Telescope for X-ray Observation (VTXO) space mission. VTXO is a precise formation of two separate spacecraft making a virtual telescope with a one-kilometer focal length. One spacecraft carries the lens and the other spacecraft holds the camera to observe high-energy space objects in the X-ray domain with 55 milli-arcsecond angular resolution accuracy. Timed automata for supervisory control, Monte Carlo simulations for stability and robustness evaluation, and integration of deep neural networks for optimal estimation of mission parameters, satisfy the high precision mission criteria. We integrate deep neural networks with a constrained, non-convex dynamic optimization pipeline to predict optimal mission parameters, ensuring precision mission criteria are met. AI framework provides explainability by predicting the resulting energy consumption and mission error for a given set of mission parameters. It allows for transparent, justifiable, and real-time trade-offs, a capability not present in traditional adaptive controllers. The results show reductions in energy consumption and improved mission accuracy, demonstrating the capability of the system to address dynamic uncertainties and disturbances. 

**Abstract (ZH)**: 我们使用人工智能（AI）和监督自适应控制系统来规划和优化精准航天器编队的任务。机器学习和稳健控制提高了虚拟X射线观测望远镜（VTXO）空间任务中航天器精准编队的效率。VTXO是由两个分离的航天器组成，形成一个焦距为一千米的虚拟望远镜，其中一个航天器携带透镜，另一个航天器搭载相机，以55毫秒角分辨率精确观测高能空间目标。监督控制的时间自动机、蒙特卡洛模拟的稳定性和鲁棒性评估，以及深度神经网络的集成用于优化任务参数估计，满足高精度任务标准。我们将深度神经网络与约束的非凸动态优化管道结合使用，以预测最优任务参数，确保满足精度任务标准。AI框架通过预测给定任务参数集下的能量消耗和任务误差提供了可解释性，允许进行透明、可验证和实时的权衡，这是传统自适应控制器不具备的能力。结果显示，能量消耗减少且任务精确度提高，证明了系统的动态不确定性与干扰处理能力。 

---
# Dual Actor DDPG for Airborne STAR-RIS Assisted Communications 

**Title (ZH)**: 空中STAR-RIS辅助通信的双actor DDPG方法 

**Authors**: Danish Rizvi, David Boyle  

**Link**: [PDF](https://arxiv.org/pdf/2509.13328)  

**Abstract**: This study departs from the prevailing assumption of independent Transmission and Reflection Coefficients (TRC) in Airborne Simultaneous Transmit and Reflect Reconfigurable Intelligent Surface (STAR-RIS) research. Instead, we explore a novel multi-user downlink communication system that leverages a UAV-mounted STAR-RIS (Aerial-STAR) incorporating a coupled TRC phase shift model. Our key contributions include the joint optimization of UAV trajectory, active beamforming vectors at the base station, and passive RIS TRCs to enhance communication efficiency, while considering UAV energy constraints. We design the TRC as a combination of discrete and continuous actions, and propose a novel Dual Actor Deep Deterministic Policy Gradient (DA-DDPG) algorithm. The algorithm relies on two separate actor networks for high-dimensional hybrid action space. We also propose a novel harmonic mean index (HFI)-based reward function to ensure communication fairness amongst users. For comprehensive analysis, we study the impact of RIS size on UAV aerodynamics showing that it increases drag and energy demand. Simulation results demonstrate that the proposed DA-DDPG algorithm outperforms conventional DDPG and DQN-based solutions by 24% and 97%, respectively, in accumulated reward. Three-dimensional UAV trajectory optimization achieves 28% higher communication efficiency compared to two-dimensional and altitude optimization. The HFI based reward function provides 41% lower QoS denial rates as compared to other benchmarks. The mobile Aerial-STAR system shows superior performance over fixed deployed counterparts, with the coupled phase STAR-RIS outperforming dual Transmit/Reflect RIS and conventional RIS setups. These findings highlight the potential of Aerial-STAR systems and the effectiveness of our proposed DA-DDPG approach in optimizing their performance. 

**Abstract (ZH)**: 基于无人驾驶飞机的STAR-RIS耦合传输-反射系数的多用户下行链路通信系统：一种新的双Actordeep确定性策略梯度算法研究 

---
# Prognosis of COVID-19 using Artificial Intelligence: A Systematic Review and Meta-analysis 

**Title (ZH)**: 使用人工智能预测COVID-19：一项系统回顾和元分析 

**Authors**: SaeedReza Motamedian, Sadra Mohaghegh, Elham Babadi Oregani, Mahrsa Amjadi, Parnian Shobeiri, Negin Cheraghi, Niusha Solouki, Nikoo Ahmadi, Hossein Mohammad-Rahimi, Yassine Bouchareb, Arman Rahmim  

**Link**: [PDF](https://arxiv.org/pdf/2408.00208)  

**Abstract**: Purpose: Artificial intelligence (AI) techniques have been extensively utilized for diagnosing and prognosis of several diseases in recent years. This study identifies, appraises and synthesizes published studies on the use of AI for the prognosis of COVID-19. Method: Electronic search was performed using Medline, Google Scholar, Scopus, Embase, Cochrane and ProQuest. Studies that examined machine learning or deep learning methods to determine the prognosis of COVID-19 using CT or chest X-ray images were included. Polled sensitivity, specificity area under the curve and diagnostic odds ratio were calculated. Result: A total of 36 articles were included; various prognosis-related issues, including disease severity, mechanical ventilation or admission to the intensive care unit and mortality, were investigated. Several AI models and architectures were employed, such as the Siamense model, support vector machine, Random Forest , eXtreme Gradient Boosting, and convolutional neural networks. The models achieved 71%, 88% and 67% sensitivity for mortality, severity assessment and need for ventilation, respectively. The specificity of 69%, 89% and 89% were reported for the aforementioned variables. Conclusion: Based on the included articles, machine learning and deep learning methods used for the prognosis of COVID-19 patients using radiomic features from CT or CXR images can help clinicians manage patients and allocate resources more effectively. These studies also demonstrate that combining patient demographic, clinical data, laboratory tests and radiomic features improves model performances. 

**Abstract (ZH)**: 目的：近年来，人工智能（AI）技术已经被广泛应用于多种疾病的诊断和预后。本研究旨在识别、评估并综合分析使用AI进行COVID-19预后研究的已发表文献。方法：通过Medline、Google Scholar、Scopus、Embase、Cochrane和ProQuest等电子数据库进行文献检索。纳入使用CT或胸部X光图像，并通过机器学习或深度学习方法确定COVID-19预后的研究。计算汇总的敏感性、特异性和受试者工作特征曲线下面积及诊断优势比。结果：共纳入36篇文章，研究了疾病严重程度、机械通气或入住重症监护单元以及死亡等多种预后相关问题。使用了多种AI模型和架构，如Siamese模型、支持向量机、随机森林、极端梯度提升和卷积神经网络。模型分别在死亡、病情评估和通气需求上的敏感性达到71%、88%和67%；上述变量的特异性分别为69%、89%和89%。结论：根据纳入的文章，使用CT或X光图像的影像组学特征进行COVID-19患者的预后预测，可以帮助临床医生更有效地管理和分配资源。此外，这些研究还表明，结合患者的临床数据、实验室检查和影像组学特征可以提高模型性能。 

---
# Joint data imputation and mechanistic modelling for simulating heart-brain interactions in incomplete datasets 

**Title (ZH)**: 联合数据插补和机制建模以模拟不完整数据集中的心脑交互作用 

**Authors**: Jaume Banus, Maxime Sermesant, Oscar Camara, Marco Lorenzi  

**Link**: [PDF](https://arxiv.org/pdf/2010.01052)  

**Abstract**: The use of mechanistic models in clinical studies is limited by the lack of multi-modal patients data representing different anatomical and physiological processes. For example, neuroimaging datasets do not provide a sufficient representation of heart features for the modeling of cardiovascular factors in brain disorders. To tackle this problem we introduce a probabilistic framework for joint cardiac data imputation and personalisation of cardiovascular mechanistic models, with application to brain studies with incomplete heart data. Our approach is based on a variational framework for the joint inference of an imputation model of cardiac information from the available features, along with a Gaussian Process emulator that can faithfully reproduce personalised cardiovascular dynamics. Experimental results on UK Biobank show that our model allows accurate imputation of missing cardiac features in datasets containing minimal heart information, e.g. systolic and diastolic blood pressures only, while jointly estimating the emulated parameters of the lumped model. This allows a novel exploration of the heart-brain joint relationship through simulation of realistic cardiac dynamics corresponding to different conditions of brain anatomy. 

**Abstract (ZH)**: 机制模型在临床研究中的应用受限于多模态患者数据的缺乏，这些数据未能充分代表不同的解剖和生理过程。例如，神经影像数据无法为脑部疾病中的心血管因素建模提供足够的心脏特征表示。为了解决这一问题，我们引入了一种概率框架，用于联合心脏数据插补和个人化心血管机制模型，应用于心脏数据不完整的大脑研究。我们的方法基于一个联合推断心脏信息插补模型和高斯过程模拟器的变分框架，该模拟器能够忠实再现个性化的心血管动态。UK生物银行上的实验结果表明，我们的模型能够在仅包含最小心脏信息的数据集中准确插补缺失的心脏特征，如仅 systolic 和 diastolic 血压，同时联合估计汇总模型的模拟参数。这使我们能够通过模拟不同脑部 anatomy 条件下的现实心脏动态来探索心脏-大脑联合关系的新途径。 

---
