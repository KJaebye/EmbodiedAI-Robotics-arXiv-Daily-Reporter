# BIM Informed Visual SLAM for Construction Monitoring 

**Title (ZH)**: BIM驱动的视觉SLAM在施工监测中的应用 

**Authors**: Asier Bikandi, Miguel Fernandez-Cortizas, Muhammad Shaheer, Ali Tourani, Holger Voos, Jose Luis Sanchez-Lopez  

**Link**: [PDF](https://arxiv.org/pdf/2509.13972)  

**Abstract**: Simultaneous Localization and Mapping (SLAM) is a key tool for monitoring construction sites, where aligning the evolving as-built state with the as-planned design enables early error detection and reduces costly rework. LiDAR-based SLAM achieves high geometric precision, but its sensors are typically large and power-demanding, limiting their use on portable platforms. Visual SLAM offers a practical alternative with lightweight cameras already embedded in most mobile devices. however, visually mapping construction environments remains challenging: repetitive layouts, occlusions, and incomplete or low-texture structures often cause drift in the trajectory map. To mitigate this, we propose an RGB-D SLAM system that incorporates the Building Information Model (BIM) as structural prior knowledge. Instead of relying solely on visual cues, our system continuously establishes correspondences between detected wall and their BIM counterparts, which are then introduced as constraints in the back-end optimization. The proposed method operates in real time and has been validated on real construction sites, reducing trajectory error by an average of 23.71% and map RMSE by 7.14% compared to visual SLAM baselines. These results demonstrate that BIM constraints enable reliable alignment of the digital plan with the as-built scene, even under partially constructed conditions. 

**Abstract (ZH)**: 基于RGB-D的BIM约束SLAM系统在施工场地监测中的应用 

---
# Using Petri Nets for Context-Adaptive Robot Explanations 

**Title (ZH)**: 基于Petri网的上下文自适应机器人解释 

**Authors**: Görkem Kılınç Soylu, Neziha Akalin, Maria Riveiro  

**Link**: [PDF](https://arxiv.org/pdf/2509.13861)  

**Abstract**: In human-robot interaction, robots must communicate in a natural and transparent manner to foster trust, which requires adapting their communication to the context. In this paper, we propose using Petri nets (PNs) to model contextual information for adaptive robot explanations. PNs provide a formal, graphical method for representing concurrent actions, causal dependencies, and system states, making them suitable for analyzing dynamic interactions between humans and robots. We demonstrate this approach through a scenario involving a robot that provides explanations based on contextual cues such as user attention and presence. Model analysis confirms key properties, including deadlock-freeness, context-sensitive reachability, boundedness, and liveness, showing the robustness and flexibility of PNs for designing and verifying context-adaptive explanations in human-robot interactions. 

**Abstract (ZH)**: 在人类-机器人交互中，机器人必须以自然和透明的方式进行沟通以培养信任，这需要根据上下文适应其沟通方式。本文提出使用 Petri 网（PNs）来建模上下文信息以适应机器人解释。PNs 提供了一种形式化的图形方法来表示并发动作、因果依赖关系和系统状态，使其适用于分析人类与机器人之间的动态交互。我们通过一个场景来展示这种方法，该场景涉及一个根据用户注意力和在场等上下文线索提供解释的机器人。模型分析确认了关键属性，包括无死锁性、上下文感知可达性、有界性和活化性，展示了 PNs 在设计和验证人类-机器人交互中的上下文适应性解释方面的稳健性和灵活性。 

---
# InterKey: Cross-modal Intersection Keypoints for Global Localization on OpenStreetMap 

**Title (ZH)**: InterKey：跨模态交义关键点在OpenStreetMap中的全局定位 

**Authors**: Nguyen Hoang Khoi Tran, Julie Stephany Berrio, Mao Shan, Stewart Worrall  

**Link**: [PDF](https://arxiv.org/pdf/2509.13857)  

**Abstract**: Reliable global localization is critical for autonomous vehicles, especially in environments where GNSS is degraded or unavailable, such as urban canyons and tunnels. Although high-definition (HD) maps provide accurate priors, the cost of data collection, map construction, and maintenance limits scalability. OpenStreetMap (OSM) offers a free and globally available alternative, but its coarse abstraction poses challenges for matching with sensor data. We propose InterKey, a cross-modal framework that leverages road intersections as distinctive landmarks for global localization. Our method constructs compact binary descriptors by jointly encoding road and building imprints from point clouds and OSM. To bridge modality gaps, we introduce discrepancy mitigation, orientation determination, and area-equalized sampling strategies, enabling robust cross-modal matching. Experiments on the KITTI dataset demonstrate that InterKey achieves state-of-the-art accuracy, outperforming recent baselines by a large margin. The framework generalizes to sensors that can produce dense structural point clouds, offering a scalable and cost-effective solution for robust vehicle localization. 

**Abstract (ZH)**: 可靠的全局定位对于自动驾驶车辆至关重要，尤其是在全球导航卫星系统（GNSS）受到降级或不可用影响的城市峡谷和隧道等环境中。尽管高精度地图（HD Maps）提供了准确的先验信息，但其数据采集、地图构建和维护的成本限制了其扩展性。OpenStreetMap（OSM）提供了免费且全球可用的替代方案，但其粗粒度的抽象化为与传感器数据匹配带来了挑战。我们提出了一种跨模态框架InterKey，该框架利用道路交汇点作为独特的地标进行全局定位。我们的方法通过联合编码点云和OSM中的道路及建筑印记来构建紧凑的二进制描述子。为了弥合模态差异，我们引入了差异缓解、方向确定和区域均衡采样策略，从而实现稳健的跨模态匹配。在KITTI数据集上的实验表明，InterKey 达到了最先进的准确性，显著优于近期的基线方法。该框架适用于能够生成密集结构点云的传感器，提供了稳健车辆定位的可扩展且经济高效解决方案。 

---
# UltraHiT: A Hierarchical Transformer Architecture for Generalizable Internal Carotid Artery Robotic Ultrasonography 

**Title (ZH)**: UltraHiT: 一种用于可泛化的颈内动脉机器人超声成像的分层Transformer架构 

**Authors**: Teng Wang, Haojun Jiang, Yuxuan Wang, Zhenguo Sun, Xiangjie Yan, Xiang Li, Gao Huang  

**Link**: [PDF](https://arxiv.org/pdf/2509.13832)  

**Abstract**: Carotid ultrasound is crucial for the assessment of cerebrovascular health, particularly the internal carotid artery (ICA). While previous research has explored automating carotid ultrasound, none has tackled the challenging ICA. This is primarily due to its deep location, tortuous course, and significant individual variations, which greatly increase scanning complexity. To address this, we propose a Hierarchical Transformer-based decision architecture, namely UltraHiT, that integrates high-level variation assessment with low-level action decision. Our motivation stems from conceptualizing individual vascular structures as morphological variations derived from a standard vascular model. The high-level module identifies variation and switches between two low-level modules: an adaptive corrector for variations, or a standard executor for normal cases. Specifically, both the high-level module and the adaptive corrector are implemented as causal transformers that generate predictions based on the historical scanning sequence. To ensure generalizability, we collected the first large-scale ICA scanning dataset comprising 164 trajectories and 72K samples from 28 subjects of both genders. Based on the above innovations, our approach achieves a 95% success rate in locating the ICA on unseen individuals, outperforming baselines and demonstrating its effectiveness. Our code will be released after acceptance. 

**Abstract (ZH)**: 颈动脉超声对于评估脑血管健康至关重要，尤其是内颈动脉（ICA）。尽管以往研究已探索自动化颈动脉超声技术，但均未解决具有挑战性的ICA问题。这主要归因于ICA的深部位置、蜿蜒路径以及显著的个体差异，极大地增加了扫描的复杂性。为解决这一问题，我们提出了一种基于分层变换器的决策架构，即UltraHiT，该架构将高层次的变异性评估与低层次的动作决策相结合。我们的动机源于将个体血管结构视为源自标准血管模型的形态变异。高层次模块识别变异并切换到两个低层次模块之一：适应性校正器以处理变异，或标准执行器以处理正常情况。具体而言，高低层次模块均通过因果变换器实现，基于历史扫描序列生成预测。为了确保泛化能力，我们收集了包含164条轨迹和72,000个样本的大型ICA扫描数据集，涉及28名性别各异的受试者。在这些创新的基础上，我们的方法在未见个体中识别ICA的成功率达到95%，优于基线方法并展示了其有效性。我们的代码将在接受后发布。 

---
# CDFlow: Generative Gradient Flows for Configuration Space Distance Fields via Neural ODEs 

**Title (ZH)**: CDFlow: 生成梯度流方法在神经ODEs中的配置空间距离场建模 

**Authors**: Mengzhu Li, Yunyu Zhou, He Ying, F. Richard Yu  

**Link**: [PDF](https://arxiv.org/pdf/2509.13771)  

**Abstract**: Signed Distance Fields (SDFs) are a fundamental representation in robot motion planning. Their configuration-space counterpart, the Configuration Space Distance Field (CDF), directly encodes distances in joint space, offering a unified representation for optimization and control. However, existing CDF formulations face two major challenges in high-degree-of-freedom (DoF) robots: (1) they effectively return only a single nearest collision configuration, neglecting the multi-modal nature of minimal-distance collision configurations and leading to gradient ambiguity; and (2) they rely on sparse sampling of the collision boundary, which often fails to identify the true closest configurations, producing oversmoothed approximations and geometric distortion in high-dimensional spaces. We propose CDFlow, a novel framework that addresses these limitations by learning a continuous flow in configuration space via Neural Ordinary Differential Equations (Neural ODEs). We redefine the problem from finding a single nearest point to modeling the distribution of minimal-distance collision configurations. We also introduce an adaptive refinement sampling strategy to generate high-fidelity training data for this distribution. The resulting Neural ODE implicitly models this multi-modal distribution and produces a smooth, consistent gradient field-derived as the expected direction towards the distribution-that mitigates gradient ambiguity and preserves sharp geometric features. Extensive experiments on high-DoF motion planning tasks demonstrate that CDFlow significantly improves planning efficiency, trajectory quality, and robustness compared to existing CDF-based methods, enabling more robust and efficient planning for collision-aware robots in complex environments. 

**Abstract (ZH)**: 基于神经常微分方程的Configuration Space Distance Flow (CDFlow)在高自由度机器人运动规划中的应用 

---
# Using role-play and Hierarchical Task Analysis for designing human-robot interaction 

**Title (ZH)**: 基于角色扮演和层级任务分析的设计人类-机器人交互方法 

**Authors**: Mattias Wingren, Sören Andersson, Sara Rosenberg, Malin Andtfolk, Susanne Hägglund, Prashani Jayasingha Arachchige, Linda Nyholm  

**Link**: [PDF](https://arxiv.org/pdf/2509.13378)  

**Abstract**: We present the use of two methods we believe warrant more use than they currently have in the field of human-robot interaction: role-play and Hierarchical Task Analysis. Some of its potential is showcased through our use of them in an ongoing research project which entails developing a robot application meant to assist at a community pharmacy. The two methods have provided us with several advantages. The role-playing provided a controlled and adjustable environment for understanding the customers' needs where pharmacists could act as models for the robot's behavior; and the Hierarchical Task Analysis ensured the behavior displayed was modelled correctly and aided development through facilitating co-design. Future research could focus on developing task analysis methods especially suited for social robot interaction. 

**Abstract (ZH)**: 我们介绍了在人机交互领域应用两种我们认为应更多使用的 методs：角色扮演和层次任务分析。通过在一项旨在辅助社区药房的机器人应用开发的研究项目中使用这两种方法，展示了它们的一些潜在价值。这两种方法为我们的研究提供了多个优势。角色扮演提供了一个可控且可调的环境，使药剂师能够作为机器人行为的模型，帮助理解客户的需求；而层次任务分析确保了机器人行为的正确建模，并通过促进协同设计来辅助开发。未来的研究可以重点关注开发特别适用于社会机器人交互的任务分析方法。 

---
# Label-Efficient Grasp Joint Prediction with Point-JEPA 

**Title (ZH)**: 标签高效指尖抓取联合预测ewith点-JEPA 

**Authors**: Jed Guzelkabaagac, Boris Petrović  

**Link**: [PDF](https://arxiv.org/pdf/2509.13349)  

**Abstract**: We investigate whether 3D self-supervised pretraining with a Joint-Embedding Predictive Architecture (Point-JEPA) enables label-efficient grasp joint-angle prediction. Using point clouds tokenized from meshes and a ShapeNet-pretrained Point-JEPA encoder, we train a lightweight multi-hypothesis head with winner-takes-all and evaluate by top-logit selection. On DLR-Hand II with object-level splits, Point-JEPA reduces RMSE by up to 26% in low-label regimes and reaches parity with full supervision. These results suggest JEPA-style pretraining is a practical approach for data-efficient grasp learning. 

**Abstract (ZH)**: 基于Joint-Embedding Predictive Architecture的3D自监督预训练是否能实现标签高效的手抓取关节角预测 

---
# Multi-Attacker Single-Defender Target Defense in Conical Environments 

**Title (ZH)**: 圆锥环境下多攻击者单防卫者目标防御 

**Authors**: Arman Pourghorban, Dipankar Maity  

**Link**: [PDF](https://arxiv.org/pdf/2509.13564)  

**Abstract**: We consider a variant of the target defense problem in a planar conical environment where a single defender is tasked to capture a sequence of incoming attackers. The attackers' objective is to breach the target boundary without being captured by the defender. As soon as the current attacker breaches the target or gets captured by the defender, the next attacker appears at the boundary of the environment and moves radially toward the target with maximum speed. Therefore, the defender's final location at the end of the current game becomes its initial location for the next game. The attackers pick strategies that are advantageous for the current as well as for future engagements between the defender and the remaining attackers. The attackers have their own sensors with limited range, using which they can perfectly detect if the defender is within their sensing range. We derive equilibrium strategies for all the players to optimize the capture percentage using the notions of capture distribution. Finally, the theoretical results are verified through numerical examples using Monte Carlo type random trials of experiments. 

**Abstract (ZH)**: 我们在平面圆锥环境下的目标防御问题变种中考虑了一个单个防守者捕获序列入侵攻击者的问题。攻击者的目的是在不被防守者捕获的情况下突破目标边界。一旦当前攻击者突破目标或被防守者捕获，下一个攻击者就会出现在环境边界上，并以最大速度径向向目标移动。因此，防守者在当前游戏结束时的最终位置将成为下一个游戏的初始位置。攻击者选择策略，这些策略不仅对当前，而且对未来防御者与剩余攻击者的交战都有利。攻击者拥有有限范围的传感器，可以完美检测防守者是否在其检测范围内。我们利用捕获分布的概念推导出所有参与者的均衡策略，以优化捕获百分比。最后，通过蒙特卡罗类型随机试验的数值例子验证了理论结果。 

---
# CrowdAgent: Multi-Agent Managed Multi-Source Annotation System 

**Title (ZH)**: CrowdAgent：多Agent管理的多源标注系统 

**Authors**: Maosheng Qin, Renyu Zhu, Mingxuan Xia, Chenkai Chen, Zhen Zhu, Minmin Lin, Junbo Zhao, Lu Xu, Changjie Fan, Runze Wu, Haobo Wang  

**Link**: [PDF](https://arxiv.org/pdf/2509.14030)  

**Abstract**: High-quality annotated data is a cornerstone of modern Natural Language Processing (NLP). While recent methods begin to leverage diverse annotation sources-including Large Language Models (LLMs), Small Language Models (SLMs), and human experts-they often focus narrowly on the labeling step itself. A critical gap remains in the holistic process control required to manage these sources dynamically, addressing complex scheduling and quality-cost trade-offs in a unified manner. Inspired by real-world crowdsourcing companies, we introduce CrowdAgent, a multi-agent system that provides end-to-end process control by integrating task assignment, data annotation, and quality/cost management. It implements a novel methodology that rationally assigns tasks, enabling LLMs, SLMs, and human experts to advance synergistically in a collaborative annotation workflow. We demonstrate the effectiveness of CrowdAgent through extensive experiments on six diverse multimodal classification tasks. The source code and video demo are available at this https URL. 

**Abstract (ZH)**: 高质量标注数据是现代自然语言处理（NLP）的基石。尽管最近的方法开始利用包括大型语言模型（LLMs）、小型语言模型（SLMs）和人类专家在内的多样标注来源，它们往往专注于标注本身。在整体流程控制方面仍存在一个关键缺口，需要动态管理这些来源，以统一的方式应对复杂的调度和质量-成本权衡。借鉴现实世界的众包公司，我们介绍了CrowdAgent多智能体系统，该系统通过整合任务分配、数据标注和质量/成本管理，提供端到端的流程控制。它实现了一种新的方法，合理分配任务，使LLMs、SLMs和人类专家能够在协作标注工作流中协同进步。我们通过在六项不同的多模态分类任务上的广泛实验展示了CrowdAgent的有效性。源代码和视频demo可访问此链接。 

---
# An Exhaustive DPLL Approach to Model Counting over Integer Linear Constraints with Simplification Techniques 

**Title (ZH)**: 基于简化技术的整数线性约束模型计数的全面DPLL方法 

**Authors**: Mingwei Zhang, Zhenhao Gu, Liangda Fang, Cunjing Ge, Ziliang Chen, Zhao-Rong Lai, Quanlong Guan  

**Link**: [PDF](https://arxiv.org/pdf/2509.13880)  

**Abstract**: Linear constraints are one of the most fundamental constraints in fields such as computer science, operations research and optimization. Many applications reduce to the task of model counting over integer linear constraints (MCILC). In this paper, we design an exact approach to MCILC based on an exhaustive DPLL architecture. To improve the efficiency, we integrate several effective simplification techniques from mixed integer programming into the architecture. We compare our approach to state-of-the-art MCILC counters and propositional model counters on 2840 random and 4131 application benchmarks. Experimental results show that our approach significantly outperforms all exact methods in random benchmarks solving 1718 instances while the state-of-the-art approach only computes 1470 instances. In addition, our approach is the only approach to solve all 4131 application instances. 

**Abstract (ZH)**: 线性约束是计算机科学、运筹学和优化等领域中最基本的约束条件之一。许多应用归结为整数线性约束下的模型计数任务（MCILC）。在本文中，我们基于详尽的DPLL架构设计了一种精确的MCILC方法。为了提高效率，我们将来自混合整数规划的有效简化技术集成到该架构中。我们在2840个随机和4131个应用基准上将我们的方法与最先进的MCILC计数器和命题模型计数器进行了比较。实验结果表明，在随机基准上，我们的方法显著优于所有精确方法，解决了1718个实例，而最先进的方法仅计算了1470个实例。此外，我们的方法是唯一能够解决所有4131个应用实例的方法。 

---
# InfraMind: A Novel Exploration-based GUI Agentic Framework for Mission-critical Industrial Management 

**Title (ZH)**: InfraMind: 一种新型基于探索的GUI代理框架用于关键工业管理 

**Authors**: Liangtao Lin, Zhaomeng Zhu, Tianwei Zhang, Yonggang Wen  

**Link**: [PDF](https://arxiv.org/pdf/2509.13704)  

**Abstract**: Mission-critical industrial infrastructure, such as data centers, increasingly depends on complex management software. Its operations, however, pose significant challenges due to the escalating system complexity, multi-vendor integration, and a shortage of expert operators. While Robotic Process Automation (RPA) offers partial automation through handcrafted scripts, it suffers from limited flexibility and high maintenance costs. Recent advances in Large Language Model (LLM)-based graphical user interface (GUI) agents have enabled more flexible automation, yet these general-purpose agents face five critical challenges when applied to industrial management, including unfamiliar element understanding, precision and efficiency, state localization, deployment constraints, and safety requirements. To address these issues, we propose InfraMind, a novel exploration-based GUI agentic framework specifically tailored for industrial management systems. InfraMind integrates five innovative modules to systematically resolve different challenges in industrial management: (1) systematic search-based exploration with virtual machine snapshots for autonomous understanding of complex GUIs; (2) memory-driven planning to ensure high-precision and efficient task execution; (3) advanced state identification for robust localization in hierarchical interfaces; (4) structured knowledge distillation for efficient deployment with lightweight models; and (5) comprehensive, multi-layered safety mechanisms to safeguard sensitive operations. Extensive experiments on both open-source and commercial DCIM platforms demonstrate that our approach consistently outperforms existing frameworks in terms of task success rate and operational efficiency, providing a rigorous and scalable solution for industrial management automation. 

**Abstract (ZH)**: 面向工业管理系统的探索导向型图形用户界面代理框架：InfraMind 

---
# Gen AI in Proof-based Math Courses: A Pilot Study 

**Title (ZH)**: 基于证明的数学课程中生成型AI的应用：一项试点研究 

**Authors**: Hannah Klawa, Shraddha Rajpal, Cigole Thomas  

**Link**: [PDF](https://arxiv.org/pdf/2509.13570)  

**Abstract**: With the rapid rise of generative AI in higher education and the unreliability of current AI detection tools, developing policies that encourage student learning and critical thinking has become increasingly important. This study examines student use and perceptions of generative AI across three proof-based undergraduate mathematics courses: a first-semester abstract algebra course, a topology course and a second-semester abstract algebra course. In each case, course policy permitted some use of generative AI. Drawing on survey responses and student interviews, we analyze how students engaged with AI tools, their perceptions of generative AI's usefulness and limitations, and what implications these perceptions hold for teaching proof-based mathematics. We conclude by discussing future considerations for integrating generative AI into proof-based mathematics instruction. 

**Abstract (ZH)**: 随着生成式AI在高等教育中的迅速兴起及当前AI检测工具的可靠性不足，制定鼓励学生学习和批判性思维的政策变得越来越重要。本研究探讨了生成式AI在三门证明基础的本科数学课程中的使用情况和学生感知：首学期抽象代数课程、拓扑课程以及第二学期抽象代数课程。在每种情况下，课程政策允许一定程度的生成式AI使用。通过调研问卷和学生访谈，我们分析了学生如何使用AI工具、他们对生成式AI usefulness和局限性的感知，以及这些感知对教授证明基础数学课程的影响。最后，我们讨论了将生成式AI整合到证明基础数学教学中的未来考量。 

---
# Asterisk Operator 

**Title (ZH)**: 阿斯特里克操作符 

**Authors**: Zixi Li  

**Link**: [PDF](https://arxiv.org/pdf/2509.13364)  

**Abstract**: We propose the \textbf{Asterisk Operator} ($\ast$-operator), a novel unified framework for abstract reasoning based on Adjacency-Structured Parallel Propagation (ASPP). The operator formalizes structured reasoning tasks as local, parallel state evolution processes guided by implicit relational graphs. We prove that the $\ast$-operator maintains local computational constraints while achieving global reasoning capabilities, providing an efficient and convergent computational paradigm for abstract reasoning problems. Through rigorous mathematical analysis and comprehensive experiments on ARC2 challenges and Conway's Game of Life, we demonstrate the operator's universality, convergence properties, and superior performance. Our innovative Embedding-Asterisk distillation method achieves 100\% accuracy on ARC2 validation with only 6M parameters, representing a significant breakthrough in neural-symbolic reasoning.
\textbf{Keywords:} Abstract Reasoning, Adjacency Structure, Parallel Propagation, Asterisk Operator, Convergence, Universal Approximation 

**Abstract (ZH)**: 我们提出了一种新的统一抽象推理框架——\textbf{星号运算符}（$\ast$-operator），基于邻接结构并行传播（ASPP）。该运算符将结构化推理任务形式化为由隐式关系图指导的局部并行状态演化过程。我们证明了星号运算符在保持局部计算约束的同时实现了全局推理能力，为抽象推理问题提供了一种高效且收敛的计算范式。通过严格的数学分析和在ARC2挑战和康威生命游戏上的全面实验，我们展示了该运算符的普适性、收敛特性和优越性能。我们的创新性嵌入星号运算符蒸馏方法在仅使用6M参数的情况下，在ARC2验证集上实现了100%的准确率，标志着神经符号推理领域的重要突破。

\textbf{关键词:} 抽象推理, 邻接结构, 并行传播, 星号运算符, 收敛, 普适逼近 

---
# Position: AI Safety Must Embrace an Antifragile Perspective 

**Title (ZH)**: AI安全必须采纳抗 fragility 观点 

**Authors**: Ming Jin, Hyunin Lee  

**Link**: [PDF](https://arxiv.org/pdf/2509.13339)  

**Abstract**: This position paper contends that modern AI research must adopt an antifragile perspective on safety -- one in which the system's capacity to guarantee long-term AI safety such as handling rare or out-of-distribution (OOD) events expands over time. Conventional static benchmarks and single-shot robustness tests overlook the reality that environments evolve and that models, if left unchallenged, can drift into maladaptation (e.g., reward hacking, over-optimization, or atrophy of broader capabilities). We argue that an antifragile approach -- Rather than striving to rapidly reduce current uncertainties, the emphasis is on leveraging those uncertainties to better prepare for potentially greater, more unpredictable uncertainties in the future -- is pivotal for the long-term reliability of open-ended ML systems. In this position paper, we first identify key limitations of static testing, including scenario diversity, reward hacking, and over-alignment. We then explore the potential of antifragile solutions to manage rare events. Crucially, we advocate for a fundamental recalibration of the methods used to measure, benchmark, and continually improve AI safety over the long term, complementing existing robustness approaches by providing ethical and practical guidelines towards fostering an antifragile AI safety community. 

**Abstract (ZH)**: this position paper 认为现代人工智能研究必须从抗脆性角度审视安全性——即系统的长期人工智能安全性能力，如处理稀有或分布外(OOD)事件的能力，会随时间不断增强。传统的静态基准和单次鲁棒性测试忽略了环境随时间变化的现实，如果模型不受挑战，它可能会逐渐适应不良（例如，奖励作弊、过度优化或更广泛的技能退化）。我们认为，一种抗脆性方法——重点不是迅速减少当前的不确定性和脆弱性，而是利用这些不确定性来更好地准备应对未来更大的、更加不可预测的不确定性——对于开放性机器学习系统的长期可靠性至关重要。在这篇立场论文中，我们首先识别出静态测试的关键局限性，包括场景多样性、奖励作弊和过度对齐。然后探讨抗脆性解决方案在管理稀有事件方面的潜力。至关重要的是，我们倡导对用于长期衡量、基准测试和提高人工智能安全性的方法进行根本性重新校准，补充现有的鲁棒性方法，通过提供伦理和实用指南来促进一个更加抗脆性的人工智能安全社区。 

---
# Bridging Past and Future: Distribution-Aware Alignment for Time Series Forecasting 

**Title (ZH)**: 连接过去与未来：基于分布的时序预测对齐方法 

**Authors**: Yifan Hu, Jie Yang, Tian Zhou, Peiyuan Liu, Yujin Tang, Rong Jin, Liang Sun  

**Link**: [PDF](https://arxiv.org/pdf/2509.14181)  

**Abstract**: Representation learning techniques like contrastive learning have long been explored in time series forecasting, mirroring their success in computer vision and natural language processing. Yet recent state-of-the-art (SOTA) forecasters seldom adopt these representation approaches because they have shown little performance advantage. We challenge this view and demonstrate that explicit representation alignment can supply critical information that bridges the distributional gap between input histories and future targets. To this end, we introduce TimeAlign, a lightweight, plug-and-play framework that learns auxiliary features via a simple reconstruction task and feeds them back to any base forecaster. Extensive experiments across eight benchmarks verify its superior performance. Further studies indicate that the gains arises primarily from correcting frequency mismatches between historical inputs and future outputs. We also provide a theoretical justification for the effectiveness of TimeAlign in increasing the mutual information between learned representations and predicted targets. As it is architecture-agnostic and incurs negligible overhead, TimeAlign can serve as a general alignment module for modern deep learning time-series forecasting systems. The code is available at this https URL. 

**Abstract (ZH)**: 时间序列预测中的表示学习技术，如对比学习，长期以来一直得到了探索，它们在计算机视觉和自然语言处理领域的成功得到了映射。然而，近期的最先进的（SOTA）预测器很少采用这些表示方法，因为它们并未显示出明显的性能优势。我们挑战这一观点，并证明显式的表示对齐可以提供关键信息，以弥合输入历史与未来目标之间的分布差距。为此，我们引入了TimeAlign，一种轻量级、即插即用的框架，通过简单的重构任务学习辅助特征，并将其反馈给任何基础预测器。广泛的实验跨八个基准验证了其优越的性能。进一步的研究表明，这些收益主要来自于纠正历史输入与未来输出之间的频率不匹配。我们还为TimeAlign如何通过增加学习表示与预测目标之间的 mutual information 有效性提供了理论依据。由于它对架构无依赖且几乎不增加开销，TimeAlign 可以作为现代深度学习时间序列预测系统的通用对齐模块。代码可在以下链接获取：this https URL。 

---
# TGPO: Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning 

**Title (ZH)**: TGPO：树引导的偏好优化以实现鲁棒的Web代理强化学习 

**Authors**: Ziyuan Chen, Zhenghui Zhao, Zhangye Han, Miancan Liu, Xianhang Ye, Yiqing Li, Hongbo Min, Jinkui Ren, Xiantao Zhang, Guitao Cao  

**Link**: [PDF](https://arxiv.org/pdf/2509.14172)  

**Abstract**: With the rapid advancement of large language models and vision-language models, employing large models as Web Agents has become essential for automated web interaction. However, training Web Agents with reinforcement learning faces critical challenges including credit assignment misallocation, prohibitively high annotation costs, and reward sparsity. To address these issues, we propose Tree-Guided Preference Optimization (TGPO), an offline reinforcement learning framework that proposes a tree-structured trajectory representation merging semantically identical states across trajectories to eliminate label conflicts. Our framework incorporates a Process Reward Model that automatically generates fine-grained rewards through subgoal progress, redundancy detection, and action verification. Additionally, a dynamic weighting mechanism prioritizes high-impact decision points during training. Experiments on Online-Mind2Web and our self-constructed C-WebShop datasets demonstrate that TGPO significantly outperforms existing methods, achieving higher success rates with fewer redundant steps. 

**Abstract (ZH)**: 基于树引导的偏好优化：面向Web交互的离线强化学习框架 

---
# Where Do Tokens Go? Understanding Pruning Behaviors in STEP at High Resolutions 

**Title (ZH)**: Where Do Tokens Go? 理解高分辨率下STEP中的剪枝行为 

**Authors**: Michal Szczepanski, Martyna Poreba, Karim Haroun  

**Link**: [PDF](https://arxiv.org/pdf/2509.14165)  

**Abstract**: Vision Transformers (ViTs) achieve state-of-the-art performance in semantic segmentation but are hindered by high computational and memory costs. To address this, we propose STEP (SuperToken and Early-Pruning), a hybrid token-reduction framework that combines dynamic patch merging and token pruning to enhance efficiency without significantly compromising accuracy. At the core of STEP is dCTS, a lightweight CNN-based policy network that enables flexible merging into superpatches. Encoder blocks integrate also early-exits to remove high-confident supertokens, lowering computational load. We evaluate our method on high-resolution semantic segmentation benchmarks, including images up to 1024 x 1024, and show that when dCTS is applied alone, the token count can be reduced by a factor of 2.5 compared to the standard 16 x 16 pixel patching scheme. This yields a 2.6x reduction in computational cost and a 3.4x increase in throughput when using ViT-Large as the backbone. Applying the full STEP framework further improves efficiency, reaching up to a 4x reduction in computational complexity and a 1.7x gain in inference speed, with a maximum accuracy drop of no more than 2.0%. With the proposed STEP configurations, up to 40% of tokens can be confidently predicted and halted before reaching the final encoder layer. 

**Abstract (ZH)**: Vision Transformers (ViTs) 的视觉分割性能出众但受到高计算和内存成本的限制。为此，我们提出了STEP（SuperToken和Early-Pruning）框架，该框架结合了动态.patch合并和令牌剪枝，旨在提高效率同时不显著牺牲准确度。STEP的核心是dCTS，这是一种轻量级的基于CNN的策略网络，实现灵活的超patch合并。编码块还集成了早期退出机制，以移除高置信度的超令牌，从而降低计算负担。我们在高分辨率语义分割基准上评估了该方法，包括1024 x 1024像素大小的图像，结果显示，当单独应用dCTS时，与标准的16 x 16像素划分方案相比，令牌数量可减少2.5倍。这使计算成本降低2.6倍，并在使用ViT-Large作为骨干网络时将吞吐量提高3.4倍。完全应用STEP框架进一步提高了效率，计算复杂度最多可降低4倍，推理速度提升1.7倍，准确率下降不超过2%。通过提出STEP配置，可最多在最终编码层之前置信地预测和停止40%的令牌。 

---
# Queen Detection in Beehives via Environmental Sensor Fusion for Low-Power Edge Computing 

**Title (ZH)**: 基于环境传感器融合的低功耗边缘计算蜜蜂王后检测 

**Authors**: Chiara De Luca, Elisa Donati  

**Link**: [PDF](https://arxiv.org/pdf/2509.14061)  

**Abstract**: Queen bee presence is essential for the health and stability of honeybee colonies, yet current monitoring methods rely on manual inspections that are labor-intensive, disruptive, and impractical for large-scale beekeeping. While recent audio-based approaches have shown promise, they often require high power consumption, complex preprocessing, and are susceptible to ambient noise. To overcome these limitations, we propose a lightweight, multimodal system for queen detection based on environmental sensor fusion-specifically, temperature, humidity, and pressure differentials between the inside and outside of the hive. Our approach employs quantized decision tree inference on a commercial STM32 microcontroller, enabling real-time, low-power edge computing without compromising accuracy. We show that our system achieves over 99% queen detection accuracy using only environmental inputs, with audio features offering no significant performance gain. This work presents a scalable and sustainable solution for non-invasive hive monitoring, paving the way for autonomous, precision beekeeping using off-the-shelf, energy-efficient hardware. 

**Abstract (ZH)**: 女王蜂的存在对于蜜蜂群体的健康和稳定性至关重要，但当前的监测方法依赖于劳动密集型、干扰性强且不适合大规模养蜂的目视检查。虽然Recent的基于音频的方法显示出希望，但它们通常需要高能耗、复杂的预处理，并且容易受到环境噪音的影响。为克服这些局限性，我们提出了一种基于环境传感器融合的轻量化多模态女王检测系统，具体而言，是基于蜂箱内外的温度、湿度和压力差异。我们的方法在商用STM32微控制器上实现量化决策树推理，能够在不牺牲准确性的前提下实现实时低能耗边缘计算。实验结果显示，仅使用环境输入，我们的系统实现了超过99%的女王检测准确率，而音频特征并未提供显著性能提升。本工作提出了一种可扩展且可持续的非侵入式蜂箱监测解决方案，为使用现成的节能硬件实现自主、精准养蜂铺平了道路。 

---
# Machines are more productive than humans until they aren't, and vice versa 

**Title (ZH)**: 机器在某些时候比人类更高效，而在其他时候则不然，反之亦然。 

**Authors**: Riccardo Zanardelli  

**Link**: [PDF](https://arxiv.org/pdf/2509.14057)  

**Abstract**: With the growth of artificial skills, organizations may increasingly confront with the problem of optimizing skill policy decisions guided by economic principles. This paper addresses the underlying complexity of this challenge by developing an in-silico framework based on Monte Carlo simulations grounded in empirical realism to analyze the economic impact of human and machine skills, individually or jointly deployed, in the execution of tasks presenting varying levels of complexity. Our results provide quantitative support for the established notions that automation tends to be the most economically-effective strategy for tasks characterized by low-to-medium generalization difficulty, while automation struggles to match the economic utility of human skills in more complex scenarios. Critically, our simulations highlight that combining human and machine skills can be the most effective strategy when a high level of generalization is required, but only if genuine augmentation is achieved. In contrast, when failing to realize this synergy, the human-machine policy is severely penalized by the inherent costs of its dual skill structure, causing it to destroy value and becoming the worst choice from an economic perspective. The takeaway for decision-makers is unambiguous: simply allocating human and machine skills to a task is insufficient, and a human-machine skill policy is neither a silver-bullet solution nor a low-risk compromise. Rather, it is a critical opportunity to boost competitiveness that demands a strong organizational commitment to enabling augmentation. Also, our findings show that improving the cost-effectiveness of machine skills over time, while useful, does not replace the fundamental need to focus on achieving augmentation. 

**Abstract (ZH)**: 随着人工技能的增长，组织可能越来越多地面临优化由经济原则引导的技能政策决策的复杂问题。本文通过基于蒙特卡洛模拟的拟实框架来研究这一挑战的基础复杂性，以此分析人类和机器技能单独或联合执行具有不同复杂程度任务时的经济影响。我们的研究结果为现有观点提供了定量支持，即自动化通常是低至中等泛化难度任务最具经济效率的策略，而在更复杂的场景中，自动化难以匹配人类技能的经济价值。关键的是，我们的模拟结果显示，当需要高泛化能力时，结合人类和机器技能可能是最有效的策略，但这必须实现真正的增强。相反，未能实现这种协同效应时，人机政策因其双重技能结构的固有成本而受到严重惩罚，导致从经济角度看是最差的选择。决策者应清晰理解：仅仅将人类和机器技能分配给任务是不够的，人机技能政策既不是万能的解决方案，也不是低风险的妥协，而是一个提升竞争力的契机，需要组织有强大的承诺来实现增强。此外，我们的研究结果表明，随着时间的推移提高机器技能的成本效益虽然有用，但并不能替代实现增强的基本需求。 

---
# Comprehensive Evaluation of CNN-Based Audio Tagging Models on Resource-Constrained Devices 

**Title (ZH)**: 基于CNN的音频标签模型在资源受限设备上的综合评估 

**Authors**: Jordi Grau-Haro, Ruben Ribes-Serrano, Javier Naranjo-Alcazar, Marta Garcia-Ballesteros, Pedro Zuccarello  

**Link**: [PDF](https://arxiv.org/pdf/2509.14049)  

**Abstract**: Convolutional Neural Networks (CNNs) have demonstrated exceptional performance in audio tagging tasks. However, deploying these models on resource-constrained devices like the Raspberry Pi poses challenges related to computational efficiency and thermal management. In this paper, a comprehensive evaluation of multiple convolutional neural network (CNN) architectures for audio tagging on the Raspberry Pi is conducted, encompassing all 1D and 2D models from the Pretrained Audio Neural Networks (PANNs) framework, a ConvNeXt-based model adapted for audio classification, as well as MobileNetV3 architectures. In addition, two PANNs-derived networks, CNN9 and CNN13, recently proposed, are also evaluated. To enhance deployment efficiency and portability across diverse hardware platforms, all models are converted to the Open Neural Network Exchange (ONNX) format. Unlike previous works that focus on a single model, our analysis encompasses a broader range of architectures and involves continuous 24-hour inference sessions to assess performance stability. Our experiments reveal that, with appropriate model selection and optimization, it is possible to maintain consistent inference latency and manage thermal behavior effectively over extended periods. These findings provide valuable insights for deploying audio tagging models in real-world edge computing scenarios. 

**Abstract (ZH)**: 卷积神经网络（CNNs）在音频标签任务中展现了卓越的性能。然而，在如Raspberry Pi这样的资源受限设备上部署这些模型面临着计算效率和热管理方面的挑战。在本文中，我们对多种卷积神经网络（CNN）架构在Raspberry Pi上的音频标签任务进行了全面评估，包括Pretrained Audio Neural Networks（PANNs）框架中的所有1D和2D模型、基于ConvNeXt的适应音频分类模型以及MobileNetV3架构。此外，我们还评估了两种从PANNs衍生出来的网络，即CNN9和CNN13。为了提高部署效率并增强跨多种硬件平台的可移植性，所有模型都转换为了Open Neural Network Exchange（ONNX）格式。与以往专注于单一模型的研究不同，我们的分析涵盖了更广泛的架构，并进行了连续24小时的推理会话以评估性能稳定性。实验结果表明，通过适当的模型选择和优化，可以在长时间内保持一致的推理延迟并有效管理热行为。这些发现为在实际边缘计算场景中部署音频标签模型提供了宝贵见解。 

---
# PhenoGnet: A Graph-Based Contrastive Learning Framework for Disease Similarity Prediction 

**Title (ZH)**: PhenoGnet：一种基于图的对比学习框架，用于疾病相似性预测 

**Authors**: Ranga Baminiwatte, Kazi Jewel Rana, Aaron J. Masino  

**Link**: [PDF](https://arxiv.org/pdf/2509.14037)  

**Abstract**: Understanding disease similarity is critical for advancing diagnostics, drug discovery, and personalized treatment strategies. We present PhenoGnet, a novel graph-based contrastive learning framework designed to predict disease similarity by integrating gene functional interaction networks with the Human Phenotype Ontology (HPO). PhenoGnet comprises two key components: an intra-view model that separately encodes gene and phenotype graphs using Graph Convolutional Networks (GCNs) and Graph Attention Networks (GATs), and a cross view model implemented as a shared weight multilayer perceptron (MLP) that aligns gene and phenotype embeddings through contrastive learning. The model is trained using known gene phenotype associations as positive pairs and randomly sampled unrelated pairs as negatives. Diseases are represented by the mean embeddings of their associated genes and/or phenotypes, and pairwise similarity is computed via cosine similarity. Evaluation on a curated benchmark of 1,100 similar and 866 dissimilar disease pairs demonstrates strong performance, with gene based embeddings achieving an AUCPR of 0.9012 and AUROC of 0.8764, outperforming existing state of the art methods. Notably, PhenoGnet captures latent biological relationships beyond direct overlap, offering a scalable and interpretable solution for disease similarity prediction. These results underscore its potential for enabling downstream applications in rare disease research and precision medicine. 

**Abstract (ZH)**: 理解疾病相似性对于促进诊断、药物发现和个人化治疗策略至关重要。我们提出PhenoGnet，这是一种基于图的对比学习框架，用于通过整合基因功能相互作用网络与人类表型 ontology (HPO) 预测疾病相似性。PhenoGnet 包含两个关键组件：一个内部视角模型，该模型使用图卷积网络 (GCNs) 和图注意网络 (GATs) 分别编码基因和表型图，以及一个通过对比学习对齐基因和表型嵌入的跨视角模型，该模型实现为共享权重的多层感知机 (MLP)。该模型使用已知的基因表型关联作为正样本，并使用随机采样的无关对作为负样本进行训练。疾病通过其相关基因和/或表型的均值嵌入表示，并通过余弦相似度计算两两相似性。在包含1,100对相似和866对不相似疾病的精心构建基准上的评估显示了强大的性能，基于基因的嵌入AUCPR为0.9012，AUROC为0.8764，优于现有最先进的方法。值得注意的是，PhenoGnet 捕捉了超出直接重叠的潜在生物学关系，提供了一种可扩展且可解释的疾病相似性预测解决方案。这些结果突显了其在罕见病研究和精准医疗下游应用中的潜在价值。 

---
# SSL-SSAW: Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation 

**Title (ZH)**: SSL-SSAW：基于sigmoid自我注意加权的自监督学习在基于问题的手语翻译中的应用 

**Authors**: Zekang Liu, Wei Feng, Fanhua Shang, Lianyu Hu, Jichao Feng, Liqing Gao  

**Link**: [PDF](https://arxiv.org/pdf/2509.14036)  

**Abstract**: Sign Language Translation (SLT) bridges the communication gap between deaf people and hearing people, where dialogue provides crucial contextual cues to aid in translation. Building on this foundational concept, this paper proposes Question-based Sign Language Translation (QB-SLT), a novel task that explores the efficient integration of dialogue. Unlike gloss (sign language transcription) annotations, dialogue naturally occurs in communication and is easier to annotate. The key challenge lies in aligning multimodality features while leveraging the context of the question to improve translation. To address this issue, we propose a cross-modality Self-supervised Learning with Sigmoid Self-attention Weighting (SSL-SSAW) fusion method for sign language translation. Specifically, we employ contrastive learning to align multimodality features in QB-SLT, then introduce a Sigmoid Self-attention Weighting (SSAW) module for adaptive feature extraction from question and sign language sequences. Additionally, we leverage available question text through self-supervised learning to enhance representation and translation capabilities. We evaluated our approach on newly constructed CSL-Daily-QA and PHOENIX-2014T-QA datasets, where SSL-SSAW achieved SOTA performance. Notably, easily accessible question assistance can achieve or even surpass the performance of gloss assistance. Furthermore, visualization results demonstrate the effectiveness of incorporating dialogue in improving translation quality. 

**Abstract (ZH)**: 基于问题的手语翻译（QB-SLT）：利用对话改善翻译的新型任务 

---
# You Are What You Train: Effects of Data Composition on Training Context-aware Machine Translation Models 

**Title (ZH)**: 你训练what你就是what：数据构成对训练情境感知机器翻译模型的影响 

**Authors**: Paweł Mąka, Yusuf Can Semerci, Jan Scholtes, Gerasimos Spanakis  

**Link**: [PDF](https://arxiv.org/pdf/2509.14031)  

**Abstract**: Achieving human-level translations requires leveraging context to ensure coherence and handle complex phenomena like pronoun disambiguation. Sparsity of contextually rich examples in the standard training data has been hypothesized as the reason for the difficulty of context utilization. In this work, we systematically validate this claim in both single- and multilingual settings by constructing training datasets with a controlled proportions of contextually relevant examples. We demonstrate a strong association between training data sparsity and model performance confirming sparsity as a key bottleneck. Importantly, we reveal that improvements in one contextual phenomenon do no generalize to others. While we observe some cross-lingual transfer, it is not significantly higher between languages within the same sub-family. Finally, we propose and empirically evaluate two training strategies designed to leverage the available data. These strategies improve context utilization, resulting in accuracy gains of up to 6 and 8 percentage points on the ctxPro evaluation in single- and multilingual settings respectively. 

**Abstract (ZH)**: 实现人类水平的翻译需要利用上下文以确保连贯性并处理像代词消歧这样的复杂现象。标准训练数据中上下文丰富的例子缺乏被认为是难以利用上下文的原因。在本研究中，我们在单语和多语设置下系统地验证了这一假设，通过构建具有可控比例的上下文相关例子的训练数据集。我们证明了训练数据稀疏性和模型性能之间存在强烈的关联，确认稀疏性是一个关键瓶颈。值得注意的是，我们发现一种上下文现象的改进不会泛化到其他现象。虽然我们观察到一定程度的跨语言迁移，但同一语族内的不同语言之间并不存在显著差异。最后，我们提出了两种训练策略，并通过实证评价来利用可用数据。这些策略提高了上下文利用，分别在单语和多语设置下取得了高达6个和8个百分点的准确性提升。 

---
# RFM-Editing: Rectified Flow Matching for Text-guided Audio Editing 

**Title (ZH)**: RFM-编辑：修正流匹配方法在文本引导的音频编辑中的应用 

**Authors**: Liting Gao, Yi Yuan, Yaru Chen, Yuelan Cheng, Zhenbo Li, Juan Wen, Shubin Zhang, Wenwu Wang  

**Link**: [PDF](https://arxiv.org/pdf/2509.14003)  

**Abstract**: Diffusion models have shown remarkable progress in text-to-audio generation. However, text-guided audio editing remains in its early stages. This task focuses on modifying the target content within an audio signal while preserving the rest, thus demanding precise localization and faithful editing according to the text prompt. Existing training-based and zero-shot methods that rely on full-caption or costly optimization often struggle with complex editing or lack practicality. In this work, we propose a novel end-to-end efficient rectified flow matching-based diffusion framework for audio editing, and construct a dataset featuring overlapping multi-event audio to support training and benchmarking in complex scenarios. Experiments show that our model achieves faithful semantic alignment without requiring auxiliary captions or masks, while maintaining competitive editing quality across metrics. 

**Abstract (ZH)**: 基于修正流匹配的扩散模型在音频编辑中的应用研究 

---
# Differential Privacy in Federated Learning: Mitigating Inference Attacks with Randomized Response 

**Title (ZH)**: 联邦学习中的差分隐私：基于随机响应缓解推断攻击 

**Authors**: Ozer Ozturk, Busra Buyuktanir, Gozde Karatas Baydogmus, Kazim Yildiz  

**Link**: [PDF](https://arxiv.org/pdf/2509.13987)  

**Abstract**: Machine learning models used for distributed architectures consisting of servers and clients require large amounts of data to achieve high accuracy. Data obtained from clients are collected on a central server for model training. However, storing data on a central server raises concerns about security and privacy. To address this issue, a federated learning architecture has been proposed. In federated learning, each client trains a local model using its own data. The trained models are periodically transmitted to the central server. The server then combines the received models using federated aggregation algorithms to obtain a global model. This global model is distributed back to the clients, and the process continues in a cyclical manner. Although preventing data from leaving the clients enhances security, certain concerns still remain. Attackers can perform inference attacks on the obtained models to approximate the training dataset, potentially causing data leakage. In this study, differential privacy was applied to address the aforementioned security vulnerability, and a performance analysis was conducted. The Data-Unaware Classification Based on Association (duCBA) algorithm was used as the federated aggregation method. Differential privacy was implemented on the data using the Randomized Response technique, and the trade-off between security and performance was examined under different epsilon values. As the epsilon value decreased, the model accuracy declined, and class prediction imbalances were observed. This indicates that higher levels of privacy do not always lead to practical outcomes and that the balance between security and performance must be carefully considered. 

**Abstract (ZH)**: 联邦学习架构中基于差分隐私的数据不知情关联分类（duCBA）算法的研究 

---
# DSpAST: Disentangled Representations for Spatial Audio Reasoning with Large Language Models 

**Title (ZH)**: DSpAST: 空间音频推理中的解耦表示方法 

**Authors**: Kevin Wilkinghoff, Zheng-Hua Tan  

**Link**: [PDF](https://arxiv.org/pdf/2509.13927)  

**Abstract**: Reasoning about spatial audio with large language models requires a spatial audio encoder as an acoustic front-end to obtain audio embeddings for further processing. Such an encoder needs to capture all information required to detect the type of sound events, as well as the direction and distance of their corresponding sources. Accomplishing this with a single audio encoder is demanding as the information required for each of these tasks is mostly independent of each other. As a result, the performance obtained with a single encoder is often worse than when using task-specific audio encoders. In this work, we present DSpAST, a novel audio encoder based on SpatialAST that learns disentangled representations of spatial audio while having only 0.2% additional parameters. Experiments on SpatialSoundQA with the spatial audio reasoning system BAT demonstrate that DSpAST significantly outperforms SpatialAST. 

**Abstract (ZH)**: 基于SpatialAST的DSpAST音频编码器：一种学习空间音频解纠缠表示的新型音频编码器 

---
# Ensemble of Pre-Trained Models for Long-Tailed Trajectory Prediction 

**Title (ZH)**: 预训练模型集成的长尾轨迹预测 

**Authors**: Divya Thuremella, Yi Yang, Simon Wanna, Lars Kunze, Daniele De Martini  

**Link**: [PDF](https://arxiv.org/pdf/2509.13914)  

**Abstract**: This work explores the application of ensemble modeling to the multidimensional regression problem of trajectory prediction for vehicles in urban environments. As newer and bigger state-of-the-art prediction models for autonomous driving continue to emerge, an important open challenge is the problem of how to combine the strengths of these big models without the need for costly re-training. We show how, perhaps surprisingly, combining state-of-the-art deep learning models out-of-the-box (without retraining or fine-tuning) with a simple confidence-weighted average method can enhance the overall prediction. Indeed, while combining trajectory prediction models is not straightforward, this simple approach enhances performance by 10% over the best prediction model, especially in the long-tailed metrics. We show that this performance improvement holds on both the NuScenes and Argoverse datasets, and that these improvements are made across the dataset distribution. The code for our work is open source. 

**Abstract (ZH)**: 本研究探讨了集成建模在城市环境中车辆轨迹预测的多维回归问题中的应用。随着不断出现的更先进更大的自动驾驶预测模型，一个重要的开放挑战是如何在无需昂贵的重新训练的情况下结合这些大模型的优势。我们展示了如何通过使用简单且出乎意料的方法，即在无需重新训练或微调的情况下将最先进的深度学习模型进行集成，并用置信加权平均方法来增强整体预测性能。虽然结合轨迹预测模型并非易事，但这种简单的方法在长尾指标上将性能提高了10%，特别是在长尾指标上表现尤为明显。我们展示了这种方法在NuScenes和Argoverse数据集上的性能改进，并且这些改进具有数据集分布的一致性。我们的代码是开源的。 

---
# FedSSG: Expectation-Gated and History-Aware Drift Alignment for Federated Learning 

**Title (ZH)**: FedSSG: 基于期望门控和历史意识的 Federated Learning 迁移对齐 

**Authors**: Zhanting Zhou, Jinshan Lai, Fengchun Zhang, Zeqin Wu, Fengli Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2509.13895)  

**Abstract**: Non-IID data and partial participation induce client drift and inconsistent local optima in federated learning, causing unstable convergence and accuracy loss. We present FedSSG, a stochastic sampling-guided, history-aware drift alignment method. FedSSG maintains a per-client drift memory that accumulates local model differences as a lightweight sketch of historical gradients; crucially, it gates both the memory update and the local alignment term by a smooth function of the observed/expected participation ratio (a phase-by-expectation signal derived from the server sampler). This statistically grounded gate stays weak and smooth when sampling noise dominates early, then strengthens once participation statistics stabilize, contracting the local-global gap without extra communication. Across CIFAR-10/100 with 100/500 clients and 2-15 percent participation, FedSSG consistently outperforms strong drift-aware baselines and accelerates convergence; on our benchmarks it improves test accuracy by up to a few points (e.g., about +0.9 on CIFAR-10 and about +2.7 on CIFAR-100 on average over the top-2 baseline) and yields about 4.5x faster target-accuracy convergence on average. The method adds only O(d) client memory and a constant-time gate, and degrades gracefully to a mild regularizer under near-IID or uniform sampling. FedSSG shows that sampling statistics can be turned into a principled, history-aware phase control to stabilize and speed up federated training. 

**Abstract (ZH)**: 非IID数据和部分参与诱导客户端漂移和局部最优不一致，导致联邦学习中不稳定收敛和准确率损失。我们提出FedSSG，一种基于随机采样引导的历史感知漂移对齐方法。 

---
# Combining Evidence and Reasoning for Biomedical Fact-Checking 

**Title (ZH)**: 结合证据与推理进行生物医学事实核查 

**Authors**: Mariano Barone, Antonio Romano, Giuseppe Riccio, Marco Postiglione, Vincenzo Moscato  

**Link**: [PDF](https://arxiv.org/pdf/2509.13879)  

**Abstract**: Misinformation in healthcare, from vaccine hesitancy to unproven treatments, poses risks to public health and trust in medical sys- tems. While machine learning and natural language processing have advanced automated fact-checking, validating biomedical claims remains uniquely challenging due to complex terminol- ogy, the need for domain expertise, and the critical importance of grounding in scientific evidence. We introduce CER (Combin- ing Evidence and Reasoning), a novel framework for biomedical fact-checking that integrates scientific evidence retrieval, reasoning via large language models, and supervised veracity prediction. By integrating the text-generation capabilities of large language mod- els with advanced retrieval techniques for high-quality biomedical scientific evidence, CER effectively mitigates the risk of halluci- nations, ensuring that generated outputs are grounded in veri- fiable, evidence-based sources. Evaluations on expert-annotated datasets (HealthFC, BioASQ-7b, SciFact) demonstrate state-of-the- art performance and promising cross-dataset generalization. Code and data are released for transparency and reproducibility: https: //github.com/PRAISELab-PicusLab/CER. 

**Abstract (ZH)**: 医学领域的 misinformation，从疫苗犹豫到未经验证的治疗方法，对公共健康和对医疗系统的信任构成了风险。尽管机器学习和自然语言处理推动了自动事实核查的发展，但由于复杂的专业术语、领域专业知识的需要以及依赖于科学证据的至关重要性，验证生物医学声明仍然极具挑战性。我们提出了CER（结合证据与推理）这一新颖的生物医学事实核查框架，该框架整合了科学证据检索、通过大规模语言模型进行的推理以及监督的可信度预测。通过将大规模语言模型的文本生成能力与高质量生物医学科学证据的高度检索技术相结合，CER 有效地缓解了幻觉的风险，确保生成的输出源自可验证的、基于证据的来源。在专家标注的数据集（HealthFC、BioASQ-7b、SciFact）上的评估表明，CER 达到了最先进的性能，并展示了跨数据集的广泛应用潜力。透明性和可重复性方面的代码和数据在 https://github.com/PRAISELab-PicusLab/CER 发布。 

---
# Masked Diffusion Models as Energy Minimization 

**Title (ZH)**: 掩码扩散模型作为能量最小化بريوف 

**Authors**: Sitong Chen, Shen Nie, Jiacheng Sun, Zijin Feng, Zhenguo Li, Ji-Rong Wen, Chongxuan Li  

**Link**: [PDF](https://arxiv.org/pdf/2509.13866)  

**Abstract**: We present a systematic theoretical framework that interprets masked diffusion models (MDMs) as solutions to energy minimization problems in discrete optimal transport. Specifically, we prove that three distinct energy formulations--kinetic, conditional kinetic, and geodesic energy--are mathematically equivalent under the structure of MDMs, and that MDMs minimize all three when the mask schedule satisfies a closed-form optimality condition. This unification not only clarifies the theoretical foundations of MDMs, but also motivates practical improvements in sampling. By parameterizing interpolation schedules via Beta distributions, we reduce the schedule design space to a tractable 2D search, enabling efficient post-training tuning without model modification. Experiments on synthetic and real-world benchmarks demonstrate that our energy-inspired schedules outperform hand-crafted baselines, particularly in low-step sampling settings. 

**Abstract (ZH)**: 我们提出了一种系统性的理论框架，将掩蔽扩散模型（MDMs）解释为离散最优运输中能量最小化问题的解决方案。具体而言，我们证明了三种不同的能量公式——动能、条件动能和测地线能量——在MDMs的结构下是数学等价的，并且在掩码调度满足闭式最优条件时，MDMs能够最小化这三种能量。这种统一不仅澄清了MDMs的理论基石，还促使了采样实践上的改进。通过使用Beta分布参数化插值调度，我们将调度设计空间缩减为可处理的二维搜索，从而在无需修改模型的情况下实现高效的后训练调优。在合成与现实世界的基准测试中，我们的能量启发式调度在低步数采样设置下表现出色，优于手工设计的基线方法。 

---
# Understanding the Process of Human-AI Value Alignment 

**Title (ZH)**: 理解人类与人工智能价值对齐的过程 

**Authors**: Jack McKinlay, Marina De Vos, Janina A. Hoffmann, Andreas Theodorou  

**Link**: [PDF](https://arxiv.org/pdf/2509.13854)  

**Abstract**: Background: Value alignment in computer science research is often used to refer to the process of aligning artificial intelligence with humans, but the way the phrase is used often lacks precision. Objectives: In this paper, we conduct a systematic literature review to advance the understanding of value alignment in artificial intelligence by characterising the topic in the context of its research literature. We use this to suggest a more precise definition of the term. Methods: We analyse 172 value alignment research articles that have been published in recent years and synthesise their content using thematic analyses. Results: Our analysis leads to six themes: value alignment drivers & approaches; challenges in value alignment; values in value alignment; cognitive processes in humans and AI; human-agent teaming; and designing and developing value-aligned systems. Conclusions: By analysing these themes in the context of the literature we define value alignment as an ongoing process between humans and autonomous agents that aims to express and implement abstract values in diverse contexts, while managing the cognitive limits of both humans and AI agents and also balancing the conflicting ethical and political demands generated by the values in different groups. Our analysis gives rise to a set of research challenges and opportunities in the field of value alignment for future work. 

**Abstract (ZH)**: 背景：在计算机科学研究中，价值对齐通常指将人工智能与人类对齐的过程，但这一术语的使用往往缺乏精确性。目标：本文通过在研究文献的背景下对价值对齐主题进行特征化，开展系统文献综述，以增进对人工智能领域价值对齐的理解，并提出一个更精确的定义。方法：分析近年来发表的172篇价值对齐研究文章，并通过主题分析整合其内容。结果：分析得出六个主题：价值对齐驱动因素与方法；价值对齐的挑战；价值在价值对齐中的作用；人类和AI的认知过程；人机团队合作；以及设计和开发价值对齐系统。结论：通过对这些主题在文献中的分析，我们将价值对齐定义为人类与自主代理之间持续的过程，旨在在不同情境下表达和实施抽象价值，同时管理人类和AI代理的认知限制，并平衡不同群体由价值观产生的冲突的伦理和政治要求。我们的分析为未来的价值对齐领域研究提出了研究挑战和机遇。 

---
# Towards a Physics Foundation Model 

**Title (ZH)**: 向物理基础模型迈进 

**Authors**: Florian Wiesner, Matthias Wessling, Stephen Baek  

**Link**: [PDF](https://arxiv.org/pdf/2509.13805)  

**Abstract**: Foundation models have revolutionized natural language processing through a ``train once, deploy anywhere'' paradigm, where a single pre-trained model adapts to countless downstream tasks without retraining. Access to a Physics Foundation Model (PFM) would be transformative -- democratizing access to high-fidelity simulations, accelerating scientific discovery, and eliminating the need for specialized solver development. Yet current physics-aware machine learning approaches remain fundamentally limited to single, narrow domains and require retraining for each new system. We present the General Physics Transformer (GPhyT), trained on 1.8 TB of diverse simulation data, that demonstrates foundation model capabilities are achievable for physics. Our key insight is that transformers can learn to infer governing dynamics from context, enabling a single model to simulate fluid-solid interactions, shock waves, thermal convection, and multi-phase dynamics without being told the underlying equations. GPhyT achieves three critical breakthroughs: (1) superior performance across multiple physics domains, outperforming specialized architectures by up to 29x, (2) zero-shot generalization to entirely unseen physical systems through in-context learning, and (3) stable long-term predictions through 50-timestep rollouts. By establishing that a single model can learn generalizable physical principles from data alone, this work opens the path toward a universal PFM that could transform computational science and engineering. 

**Abstract (ZH)**: 基础模型通过“训练一次，随处部署”的 paradigma 重塑了自然语言处理，其中单一预训练模型能够适应无数下游任务而无需重新训练。获取物理基础模型 (PFM) 将是变革性的——普及高保真模拟的访问权，加速科学发现，并消除专门求解器开发的需要。然而，当前的物理感知机器学习方法仍然根本上局限于单一的小范围领域，并且每次都需要重新训练新的系统。我们提出了广义物理变换器 (GPhyT)，它基于 1.8 TB 多样的模拟数据进行训练，并展示了基础模型能力在物理学领域的实现。我们关键的见解是，变换器能够从上下文中推断出支配动力学，从而使单一模型能够在无需告知底层方程的情况下模拟流固相互作用、冲击波、热对流以及多相动力学。GPhyT 实现了三个关键突破：(1) 在多个物理学领域中表现出色，相对于专门架构高出 29 倍，(2) 通过上下文学习零样本泛化到完全未见过的物理系统，以及 (3) 通过 50 步时序预报实现稳定长期预测。通过表明单一模型可以从数据本身学习可泛化的物理原理，这项工作开启了通向万能 PFM 的路径，这有可能重塑计算科学和工程。 

---
# Who is Introducing the Failure? Automatically Attributing Failures of Multi-Agent Systems via Spectrum Analysis 

**Title (ZH)**: 谁在引入故障？通过频谱分析自动归因多agent系统中的故障 

**Authors**: Yu Ge, Linna Xie, Zhong Li, Yu Pei, Tian Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2509.13782)  

**Abstract**: Large Language Model Powered Multi-Agent Systems (MASs) are increasingly employed to automate complex real-world problems, such as programming and scientific discovery. Despite their promising, MASs are not without their flaws. However, failure attribution in MASs - pinpointing the specific agent actions responsible for failures - remains underexplored and labor-intensive, posing significant challenges for debugging and system improvement. To bridge this gap, we propose FAMAS, the first spectrum-based failure attribution approach for MASs, which operates through systematic trajectory replay and abstraction, followed by spectrum this http URL core idea of FAMAS is to estimate, from variations across repeated MAS executions, the likelihood that each agent action is responsible for the failure. In particular, we propose a novel suspiciousness formula tailored to MASs, which integrates two key factor groups, namely the agent behavior group and the action behavior group, to account for the agent activation patterns and the action activation patterns within the execution trajectories of MASs. Through expensive evaluations against 12 baselines on the Who and When benchmark, FAMAS demonstrates superior performance by outperforming all the methods in comparison. 

**Abstract (ZH)**: 基于大型语言模型的多智能体系统故障归因方法（FAMAS） 

---
# State Space Models over Directed Graphs 

**Title (ZH)**: 有向图上的状态空间模型 

**Authors**: Junzhi She, Xunkai Li, Rong-Hua Li, Guoren Wang  

**Link**: [PDF](https://arxiv.org/pdf/2509.13735)  

**Abstract**: Directed graphs are ubiquitous across numerous domains, where the directionality of edges encodes critical causal dependencies. However, existing GNNs and graph Transformers tailored for directed graphs face two major challenges: (1) effectively capturing long-range causal dependencies derived from directed edges; (2) balancing accuracy and training efficiency when processing large-scale graph datasets. In recent years, state space models (SSMs) have achieved substantial progress in causal sequence tasks, and their variants designed for graphs have demonstrated state-of-the-art accuracy while maintaining high efficiency across various graph learning benchmarks. However, existing graph state space models are exclusively designed for undirected graphs, which limits their performance in directed graph learning. To this end, we propose an innovative approach DirEgo2Token which sequentializes directed graphs via k-hop ego graphs. This marks the first systematic extension of state space models to the field of directed graph learning. Building upon this, we develop DirGraphSSM, a novel directed graph neural network architecture that implements state space models on directed graphs via the message-passing mechanism. Experimental results demonstrate that DirGraphSSM achieves state-of-the-art performance on three representative directed graph learning tasks while attaining competitive performance on two additional tasks with 1.5$\times $ to 2$\times $ training speed improvements compared to existing state-of-the-art models. 

**Abstract (ZH)**: Directed图神经网络中的时空状态空间模型 

---
# AgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation 

**Title (ZH)**: AgentCTG: 利用多Agents协作实现文本生成的细粒度精确控制 

**Authors**: Xinxu Zhou, Jiaqi Bai, Zhenqi Sun, Fanxiang Zeng, Yue Liu  

**Link**: [PDF](https://arxiv.org/pdf/2509.13677)  

**Abstract**: Although significant progress has been made in many tasks within the field of Natural Language Processing (NLP), Controlled Text Generation (CTG) continues to face numerous challenges, particularly in achieving fine-grained conditional control over generation. Additionally, in real scenario and online applications, cost considerations, scalability, domain knowledge learning and more precise control are required, presenting more challenge for CTG. This paper introduces a novel and scalable framework, AgentCTG, which aims to enhance precise and complex control over the text generation by simulating the control and regulation mechanisms in multi-agent workflows. We explore various collaboration methods among different agents and introduce an auto-prompt module to further enhance the generation effectiveness. AgentCTG achieves state-of-the-art results on multiple public datasets. To validate its effectiveness in practical applications, we propose a new challenging Character-Driven Rewriting task, which aims to convert the original text into new text that conform to specific character profiles and simultaneously preserve the domain knowledge. When applied to online navigation with role-playing, our approach significantly enhances the driving experience through improved content delivery. By optimizing the generation of contextually relevant text, we enable a more immersive interaction within online communities, fostering greater personalization and user engagement. 

**Abstract (ZH)**: 尽管在自然语言处理（NLP）领域的许多任务中取得了显著进展，受控文本生成（CTG）仍然面临诸多挑战，特别是在实现精细条件控制方面。此外，在实际场景和在线应用中，还需要考虑成本、可扩展性、领域知识学习以及更精确的控制等问题，为CTG提出了更高的要求。本文介绍了一种新颖且可扩展的框架AgentCTG，旨在通过模拟多_agent工作流中的控制和调节机制来增强文本生成的精确和复杂控制。我们探索了不同agent之间的各种协作方法，并引入了一个自动提示模块以进一步提高生成效果。AgentCTG在多个公开数据集上取得了最先进的成果。为验证其在实际应用中的有效性，我们提出了一个新的具有挑战性的基于角色驱动的重写任务，旨在将原始文本转换为符合特定角色特征的新文本，同时保留领域知识。当应用于角色扮演的在线导航中时，我们的方法通过改善内容传递显著提升了驾驶体验。通过对上下文相关文本的优化生成，我们使在线社区内的互动更加沉浸式，促进了更高的个性化和用户参与度。 

---
# CL$^2$GEC: A Multi-Discipline Benchmark for Continual Learning in Chinese Literature Grammatical Error Correction 

**Title (ZH)**: CL$^2$GEC：中文文学语法纠错的持续学习多学科基准 

**Authors**: Shang Qin, Jingheng Ye, Yinghui Li, Hai-Tao Zheng, Qi Li, Jinxiao Shan, Zhixing Li, Hong-Gee Kim  

**Link**: [PDF](https://arxiv.org/pdf/2509.13672)  

**Abstract**: The growing demand for automated writing assistance in diverse academic domains highlights the need for robust Chinese Grammatical Error Correction (CGEC) systems that can adapt across disciplines. However, existing CGEC research largely lacks dedicated benchmarks for multi-disciplinary academic writing, overlooking continual learning (CL) as a promising solution to handle domain-specific linguistic variation and prevent catastrophic forgetting. To fill this crucial gap, we introduce CL$^2$GEC, the first Continual Learning benchmark for Chinese Literature Grammatical Error Correction, designed to evaluate adaptive CGEC across multiple academic fields. Our benchmark includes 10,000 human-annotated sentences spanning 10 disciplines, each exhibiting distinct linguistic styles and error patterns. CL$^2$GEC focuses on evaluating grammatical error correction in a continual learning setting, simulating sequential exposure to diverse academic disciplines to reflect real-world editorial dynamics. We evaluate large language models under sequential tuning, parameter-efficient adaptation, and four representative CL algorithms, using both standard GEC metrics and continual learning metrics adapted to task-level variation. Experimental results reveal that regularization-based methods mitigate forgetting more effectively than replay-based or naive sequential approaches. Our benchmark provides a rigorous foundation for future research in adaptive grammatical error correction across diverse academic domains. 

**Abstract (ZH)**: 不断学习框架下的汉语语法错误修正持续学习基准（CL²GEC）：面向多学科学术写作的汉语文学语法错误修正持续学习基准 

---
# Deep Lookup Network 

**Title (ZH)**: 深度查找网络 

**Authors**: Yulan Guo, Longguang Wang, Wendong Mao, Xiaoyu Dong, Yingqian Wang, Li Liu, Wei An  

**Link**: [PDF](https://arxiv.org/pdf/2509.13662)  

**Abstract**: Convolutional neural networks are constructed with massive operations with different types and are highly computationally intensive. Among these operations, multiplication operation is higher in computational complexity and usually requires {more} energy consumption with longer inference time than other operations, which hinders the deployment of convolutional neural networks on mobile devices. In many resource-limited edge devices, complicated operations can be calculated via lookup tables to reduce computational cost. Motivated by this, in this paper, we introduce a generic and efficient lookup operation which can be used as a basic operation for the construction of neural networks. Instead of calculating the multiplication of weights and activation values, simple yet efficient lookup operations are adopted to compute their responses. To enable end-to-end optimization of the lookup operation, we construct the lookup tables in a differentiable manner and propose several training strategies to promote their convergence. By replacing computationally expensive multiplication operations with our lookup operations, we develop lookup networks for the image classification, image super-resolution, and point cloud classification tasks. It is demonstrated that our lookup networks can benefit from the lookup operations to achieve higher efficiency in terms of energy consumption and inference speed while maintaining competitive performance to vanilla convolutional networks. Extensive experiments show that our lookup networks produce state-of-the-art performance on different tasks (both classification and regression tasks) and different data types (both images and point clouds). 

**Abstract (ZH)**: 卷积神经网络构建于大量不同类型的运算之上，计算密集度高。在这类运算中，乘法运算在计算复杂度和通常所需的能量消耗以及推断时间方面高于其他运算，这阻碍了卷积神经网络在移动设备上的部署。在许多资源受限的边缘设备中，可以通过查找表来计算复杂的运算，以降低计算成本。受此启发，本文介绍了一种通用且高效的查找表操作，可作为构建神经网络的基本运算。我们采用简单的高效查找表操作来计算响应，而不是直接计算权重和激活值的乘积。为了实现查找表操作的端到端优化，我们以可微分的方式构建查找表，并提出了几种训练策略以促进其收敛。通过用我们的查找表操作替换计算成本高昂的乘法运算，我们为图像分类、图像超分辨率和点云分类任务开发了查找网络。实验表明，我们的查找网络利用查找表操作在能耗和推断速度方面实现了更高的效率，同时保持了与传统卷积网络相当的性能。大量实验表明，我们的查找网络在不同任务（包括分类和回归任务）和不同类型的数据（包括图像和点云）上均取得了最先进的性能。 

---
# GitHub's Copilot Code Review: Can AI Spot Security Flaws Before You Commit? 

**Title (ZH)**: GitHub Copilot代码审查：AI能在你提交前发现安全漏洞吗？ 

**Authors**: Amena Amro, Manar H. Alalfi  

**Link**: [PDF](https://arxiv.org/pdf/2509.13650)  

**Abstract**: As software development practices increasingly adopt AI-powered tools, ensuring that such tools can support secure coding has become critical. This study evaluates the effectiveness of GitHub Copilot's recently introduced code review feature in detecting security vulnerabilities. Using a curated set of labeled vulnerable code samples drawn from diverse open-source projects spanning multiple programming languages and application domains, we systematically assessed Copilot's ability to identify and provide feedback on common security flaws. Contrary to expectations, our results reveal that Copilot's code review frequently fails to detect critical vulnerabilities such as SQL injection, cross-site scripting (XSS), and insecure deserialization. Instead, its feedback primarily addresses low-severity issues, such as coding style and typographical errors. These findings expose a significant gap between the perceived capabilities of AI-assisted code review and its actual effectiveness in supporting secure development practices. Our results highlight the continued necessity of dedicated security tools and manual code audits to ensure robust software security. 

**Abstract (ZH)**: 随着软件开发实践越来越多地采用AI驱动的工具，确保这些工具能够支持安全编码变得至关重要。本研究评估了GitHub Copilot最近引入的代码审查功能在检测安全漏洞方面的有效性。通过对来自多个编程语言和应用领域的多样化开源项目的精心筛选的标记脆弱代码样本进行系统评估，我们考察了Copilot识别和提供关于常见安全缺陷反馈的能力。与预期相反，我们的结果显示，Copilot的代码审查经常未能检测到诸如SQL注入、跨站脚本(XSS)和不安全反序列化等关键漏洞。相反，其反馈主要关注低 sever 严重程度的问题，如编码风格和拼写错误。这些发现暴露了AI辅助代码审查感知能力和实际支持安全开发实践有效性之间的重要差距。我们的结果强调了继续使用专门的安全工具和人工代码审核以确保软件安全的必要性。 

---
# DeepLogit: A sequentially constrained explainable deep learning modeling approach for transport policy analysis 

**Title (ZH)**: DeepLogit：一种用于交通政策分析的序列约束可解释深度学习建模方法 

**Authors**: Jeremy Oon, Rakhi Manohar Mepparambath, Ling Feng  

**Link**: [PDF](https://arxiv.org/pdf/2509.13633)  

**Abstract**: Despite the significant progress of deep learning models in multitude of applications, their adaption in planning and policy related areas remains challenging due to the black-box nature of these models. In this work, we develop a set of DeepLogit models that follow a novel sequentially constrained approach in estimating deep learning models for transport policy analysis. In the first step of the proposed approach, we estimate a convolutional neural network (CNN) model with only linear terms, which is equivalent of a linear-in-parameter multinomial logit model. We then estimate other deep learning models by constraining the parameters that need interpretability at the values obtained in the linear-in-parameter CNN model and including higher order terms or by introducing advanced deep learning architectures like Transformers. Our approach can retain the interpretability of the selected parameters, yet provides significantly improved model accuracy than the discrete choice model. We demonstrate our approach on a transit route choice example using real-world transit smart card data from Singapore. This study shows the potential for a unifying approach, where theory-based discrete choice model (DCM) and data-driven AI models can leverage each other's strengths in interpretability and predictive power. With the availability of larger datasets and more complex constructions, such approach can lead to more accurate models using discrete choice models while maintaining its applicability in planning and policy-related areas. Our code is available on this https URL . 

**Abstract (ZH)**: 尽管深度学习模型在众多应用中取得了显著进展，但由于这些模型的黑箱性质，它们在规划和政策相关的领域中的应用仍然具有挑战性。在这项工作中，我们开发了一套遵循新颖的序列约束方法的DeepLogit模型，以估计用于交通政策分析的深度学习模型。在所提出方法的第一步中，我们仅估计了一个包含线性项的卷积神经网络（CNN）模型，这相当于一个参数线性化的多项式logit模型。随后，通过将需要可解释性的参数固定为线性参数化的CNN模型中获得的值，并包含高阶项或引入如变换器等先进的深度学习架构，我们估计其他深度学习模型。这种方法可以保持选定参数的可解释性，同时显著提高模型的准确性，超越了离散选择模型。本文利用新加坡实际公交智能卡数据，以公交线路选择为例，展示了该方法的应用。这项研究表明，理论基于的离散选择模型（DCM）和数据驱动的人工智能模型可以通过互补各自的解释性和预测能力，实现统一的方法。随着数据集的增大和模型结构的复杂化，这种方法可以在保持其在规划和政策相关领域的适用性的同时，使用离散选择模型获得更准确的模型。我们的代码可在此链接获得。 

---
# Secure, Scalable and Privacy Aware Data Strategy in Cloud 

**Title (ZH)**: 云环境中安全、可扩展且隐私意识强的数据策略 

**Authors**: Vijay Kumar Butte, Sujata Butte  

**Link**: [PDF](https://arxiv.org/pdf/2509.13627)  

**Abstract**: The enterprises today are faced with the tough challenge of processing, storing large amounts of data in a secure, scalable manner and enabling decision makers to make quick, informed data driven decisions. This paper addresses this challenge and develops an effective enterprise data strategy in the cloud. Various components of an effective data strategy are discussed and architectures addressing security, scalability and privacy aspects are provided. 

**Abstract (ZH)**: 当今企业面临的安全、可扩展地处理和存储大量数据的挑战，并通过数据驱动的快速、明智的决策支持决策者。本文解决了这一挑战，并在云环境中发展了一个有效的企业数据策略。讨论了有效数据策略的各项内容，并提供了涉及安全、可扩展性和隐私方面的架构。 

---
# Mind the Gap: Aligning Knowledge Bases with User Needs to Enhance Mental Health Retrieval 

**Title (ZH)**: 注意差距：将知识库与用户需求对齐以增强心理健康检索 

**Authors**: Amanda Chan, James Jiayu Liu, He Kai, Onno P. Kampman  

**Link**: [PDF](https://arxiv.org/pdf/2509.13626)  

**Abstract**: Access to reliable mental health information is vital for early help-seeking, yet expanding knowledge bases is resource-intensive and often misaligned with user needs. This results in poor performance of retrieval systems when presented concerns are not covered or expressed in informal or contextualized language. We present an AI-based gap-informed framework for corpus augmentation that authentically identifies underrepresented topics (gaps) by overlaying naturalistic user data such as forum posts in order to prioritize expansions based on coverage and usefulness. In a case study, we compare Directed (gap-informed augmentations) with Non-Directed augmentation (random additions), evaluating the relevance and usefulness of retrieved information across four retrieval-augmented generation (RAG) pipelines. Directed augmentation achieved near-optimal performance with modest expansions--requiring only a 42% increase for Query Transformation, 74% for Reranking and Hierarchical, and 318% for Baseline--to reach ~95% of the performance of an exhaustive reference corpus. In contrast, Non-Directed augmentation required substantially larger and thus practically infeasible expansions to achieve comparable performance (232%, 318%, 403%, and 763%, respectively). These results show that strategically targeted corpus growth can reduce content creation demands while sustaining high retrieval and provision quality, offering a scalable approach for building trusted health information repositories and supporting generative AI applications in high-stakes domains. 

**Abstract (ZH)**: 基于AI的缺口导向的语料扩充框架：通过自然用户数据真实识别未充分代表的主题以优先扩充，提升检索性能 

---
# A reduced-order derivative-informed neural operator for subsurface fluid-flow 

**Title (ZH)**: 基于亚模化导数感知神经算子的地下流体流动模型 

**Authors**: Jeongjin, Park, Grant Bruer, Huseyin Tuna Erdinc, Abhinav Prakash Gahlot, Felix J. Herrmann  

**Link**: [PDF](https://arxiv.org/pdf/2509.13620)  

**Abstract**: Neural operators have emerged as cost-effective surrogates for expensive fluid-flow simulators, particularly in computationally intensive tasks such as permeability inversion from time-lapse seismic data, and uncertainty quantification. In these applications, the fidelity of the surrogate's gradients with respect to system parameters is crucial, as the accuracy of downstream tasks, such as optimization and Bayesian inference, relies directly on the quality of the derivative information. Recent advances in physics-informed methods have leveraged derivative information to improve surrogate accuracy. However, incorporating explicit Jacobians can become computationally prohibitive, as the complexity typically scales quadratically with the number of input parameters. To address this limitation, we propose DeFINO (Derivative-based Fisher-score Informed Neural Operator), a reduced-order, derivative-informed training framework. DeFINO integrates Fourier neural operators (FNOs) with a novel derivative-based training strategy guided by the Fisher Information Matrix (FIM). By projecting Jacobians onto dominant eigen-directions identified by the FIM, DeFINO captures critical sensitivity information directly informed by observational data, significantly reducing computational expense. We validate DeFINO through synthetic experiments in the context of subsurface multi-phase fluid-flow, demonstrating improvements in gradient accuracy while maintaining robust forward predictions of underlying fluid dynamics. These results highlight DeFINO's potential to offer practical, scalable solutions for inversion problems in complex real-world scenarios, all at substantially reduced computational cost. 

**Abstract (ZH)**: 基于导数的费isher分数值导向神经算子 

---
# TreeIRL: Safe Urban Driving with Tree Search and Inverse Reinforcement Learning 

**Title (ZH)**: 基于树搜索和逆强化学习的安全城市驾驶TreeIRL 

**Authors**: Momchil S. Tomov, Sang Uk Lee, Hansford Hendrago, Jinwook Huh, Teawon Han, Forbes Howington, Rafael da Silva, Gianmarco Bernasconi, Marc Heim, Samuel Findler, Xiaonan Ji, Alexander Boule, Michael Napoli, Kuo Chen, Jesse Miller, Boaz Floor, Yunqing Hu  

**Link**: [PDF](https://arxiv.org/pdf/2509.13579)  

**Abstract**: We present TreeIRL, a novel planner for autonomous driving that combines Monte Carlo tree search (MCTS) and inverse reinforcement learning (IRL) to achieve state-of-the-art performance in simulation and in real-world driving. The core idea is to use MCTS to find a promising set of safe candidate trajectories and a deep IRL scoring function to select the most human-like among them. We evaluate TreeIRL against both classical and state-of-the-art planners in large-scale simulations and on 500+ miles of real-world autonomous driving in the Las Vegas metropolitan area. Test scenarios include dense urban traffic, adaptive cruise control, cut-ins, and traffic lights. TreeIRL achieves the best overall performance, striking a balance between safety, progress, comfort, and human-likeness. To our knowledge, our work is the first demonstration of MCTS-based planning on public roads and underscores the importance of evaluating planners across a diverse set of metrics and in real-world environments. TreeIRL is highly extensible and could be further improved with reinforcement learning and imitation learning, providing a framework for exploring different combinations of classical and learning-based approaches to solve the planning bottleneck in autonomous driving. 

**Abstract (ZH)**: TreeIRL：一种结合蒙特卡洛树搜索和逆强化学习的新型自主驾驶规划器 

---
# Complexity Bounds for Smooth Convex Multiobjective Optimization 

**Title (ZH)**: 光滑凸多目标优化的复杂度界 

**Authors**: Phillipe R. Sampaio  

**Link**: [PDF](https://arxiv.org/pdf/2509.13550)  

**Abstract**: We study the oracle complexity of finding $\varepsilon$-Pareto stationary points in smooth multiobjective optimization with $m$ objectives. The progress metric is the Pareto stationarity gap $\mathcal{G}(x)$ (the norm of an optimal convex combination of gradients). Our contributions are fourfold. (i) For strongly convex objectives, any span first-order method (iterates lie in the span of past gradients) exhibits linear convergence no faster than $\exp(-\Theta(T/\sqrt{\kappa}))$ after $T$ oracle calls, where $\kappa$ is the condition number, implying $\Theta(\sqrt{\kappa}\log(1/\varepsilon))$ iterations; this matches classical accelerated upper bounds. (ii) For convex problems and oblivious one-step methods (a fixed scalarization with pre-scheduled step sizes), we prove a lower bound of order $1/T$ on the best gradient norm among the first $T$ iterates. (iii) Although accelerated gradient descent is outside this restricted class, it is an oblivious span method and attains the same $1/T$ upper rate on a fixed scalarization. (iv) For convex problems and general span methods with adaptive scalarizations, we establish a universal lower bound of order $1/T^{2}$ on the gradient norm of the final iterate after $T$ steps, highlighting a gap between known upper bounds and worst-case guarantees. All bounds hold on non-degenerate instances with distinct objectives and non-singleton Pareto fronts; rates are stated up to universal constants and natural problem scaling. 

**Abstract (ZH)**: 我们研究了具有$m$个目标的光滑多目标优化中找到$\varepsilon$-帕累托渐近点的先验复杂性。进度度量是帕累托渐近性缺口$\mathcal{G}(x)$（最优凸组合梯度的范数）。我们的贡献有四个方面。(i) 对于强凸目标，任何张量一阶方法（迭代点位于过去梯度的子空间中）在$T$次先验调用后的收敛速度不超过$\exp(-\Theta(T/\sqrt{\kappa}))$，其中$\kappa$是条件数，这意味着需要$\Theta(\sqrt{\kappa}\log(1/\varepsilon))$次迭代；这与经典的加速上界匹配。(ii) 对于凸问题和基于预调度步长的无感知一阶方法（固定标量化），我们证明了前$T$次迭代中最佳梯度范数的下界为$1/T$的量级。(iii) 尽管加速梯度下降法超出了这一限制类，但它是一个无感知张量方法，并在固定标量化下达到相同的$1/T$上界。(iv) 对于凸问题和具有自适应标量化的通用张量方法，我们建立了在$T$步后最终迭代点梯度范数的下界为$1/T^2$的量级，突显了已知上界与最坏情况保证之间的差距。所有界在非退化实例和非单目标帕累托前沿上成立；速率表述中包含通用常数和自然问题缩放。 

---
# Reproducible workflow for online AI in digital health 

**Title (ZH)**: 可重复的工作流 for 在线人工智能在数字健康中的应用 

**Authors**: Susobhan Ghosh, Bhanu T. Gulapalli, Daiqi Gao, Asim Gazi, Anna Trella, Ziping Xu, Kelly Zhang, Susan A. Murphy  

**Link**: [PDF](https://arxiv.org/pdf/2509.13499)  

**Abstract**: Online artificial intelligence (AI) algorithms are an important component of digital health interventions. These online algorithms are designed to continually learn and improve their performance as streaming data is collected on individuals. Deploying online AI presents a key challenge: balancing adaptability of online AI with reproducibility. Online AI in digital interventions is a rapidly evolving area, driven by advances in algorithms, sensors, software, and devices. Digital health intervention development and deployment is a continuous process, where implementation - including the AI decision-making algorithm - is interspersed with cycles of re-development and optimization. Each deployment informs the next, making iterative deployment a defining characteristic of this field. This iterative nature underscores the importance of reproducibility: data collected across deployments must be accurately stored to have scientific utility, algorithm behavior must be auditable, and results must be comparable over time to facilitate scientific discovery and trustworthy refinement. This paper proposes a reproducible scientific workflow for developing, deploying, and analyzing online AI decision-making algorithms in digital health interventions. Grounded in practical experience from multiple real-world deployments, this workflow addresses key challenges to reproducibility across all phases of the online AI algorithm development life-cycle. 

**Abstract (ZH)**: 在线人工智能算法是数字健康干预的重要组成部分。在线人工智能在数字干预中的应用是一个快速发展的领域，受到算法、传感器、软件和设备进步的推动。数字健康干预的开发和部署是一个持续的过程，其中实施——包括人工智能决策算法——与重新开发和优化的周期交织在一起。每次部署都为下一步提供信息，使迭代部署成为该领域的一个标志性特征。这种迭代性质突出了可重复性的意义：必须准确存储跨部署收集的数据以具有科学价值，算法行为必须可审计，并且结果必须在时间上可比较，以促进科学发现和值得信赖的改进。本文提出了一种可重复的科学工作流，用于开发、部署和分析数字健康干预中的在线人工智能决策算法。该工作流基于来自多个实际部署的经验，旨在解决在线人工智能算法开发生命周期各阶段的可重复性关键挑战。 

---
# EdiVal-Agent: An Object-Centric Framework for Automated, Scalable, Fine-Grained Evaluation of Multi-Turn Editing 

**Title (ZH)**: EdiVal-Agent：面向对象的多轮编辑自动化、可扩展、细粒度评估框架 

**Authors**: Tianyu Chen, Yasi Zhang, Zhi Zhang, Peiyu Yu, Shu Wang, Zhendong Wang, Kevin Lin, Xiaofei Wang, Zhengyuan Yang, Linjie Li, Chung-Ching Lin, Jianwen Xie, Oscar Leong, Lijuan Wang, Ying Nian Wu, Mingyuan Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2509.13399)  

**Abstract**: Instruction-based image editing has advanced rapidly, yet reliable and interpretable evaluation remains a bottleneck. Current protocols either (i) depend on paired reference images -- resulting in limited coverage and inheriting biases from prior generative models -- or (ii) rely solely on zero-shot vision--language models (VLMs), whose prompt-based assessments of instruction following, content consistency, and visual quality are often imprecise.
To address this, we introduce EdiVal-Agent, an automated, scalable, and fine-grained evaluation framework for multi-turn instruction-based editing from an object-centric perspective, supported by a suite of expert tools. Given an image, EdiVal-Agent first decomposes it into semantically meaningful objects, then synthesizes diverse, context-aware editing instructions. For evaluation, it integrates VLMs with open-vocabulary object detectors to assess instruction following, uses semantic-level feature extractors to evaluate content consistency, and leverages human preference models to judge visual quality. We show that combining VLMs with object detectors yields stronger agreement with human judgments in instruction-following evaluation compared to using VLMs alone and CLIP-based metrics. Furthermore, the pipeline's modular design allows future tools to be seamlessly integrated, enhancing evaluation accuracy over time.
Instantiating this pipeline, we build EdiVal-Bench, a multi-turn editing benchmark covering 9 instruction types and 11 state-of-the-art editing models spanning autoregressive (AR) (including Nano Banana, GPT-Image-1), flow-matching, and diffusion paradigms. We demonstrate that EdiVal-Agent can be used to identify existing failure modes, thereby informing the development of the next generation of editing models. Project page: this https URL. 

**Abstract (ZH)**: 基于指令的图像编辑已经取得了快速进步，但可靠的可解释性评估仍然是一大瓶颈。当前的评估协议要么依赖配对的参考图像——这导致评估范围有限，并继承了先前生成模型的偏差——要么完全依赖零样本视觉-语言模型（VLM），这些模型基于提示的评估指令遵循情况、内容一致性和视觉质量往往不够精确。

为了解决这个问题，我们引入了EdiVal-Agent，这是一种从对象中心视角出发的自动化、可扩展且精细的多轮指令基于编辑评估框架，配备了一系列专家工具。给定一张图像，EdiVal-Agent 首先将其分解为语义上有意义的对象，然后合成多样且情境相关的编辑指令。在评估方面，它结合了VLM和开放词汇对象检测器来评估指令遵循情况，使用语义级特征提取器来评估内容一致性，并利用人类偏好评分模型来判断视觉质量。我们证明，将VLM与对象检测器结合起来，在指令遵循评估中与人类判断的一致性比单独使用VLM和CLIP基线指标更强。此外，流水线的模块化设计允许未来工具无缝整合，随着时间推移提升评估准确性。

通过实例化该流水线，我们构建了EdiVal-Bench，这是一个涵盖9种指令类型和11种前沿编辑模型（包括自回归模型（AR），如Nano Banana、GPT-Image-1，流匹配和扩散范式的多轮编辑基准。我们演示了EdiVal-Agent可以用来识别现有的失败模式，从而为下一代编辑模型的开发提供指导。项目页面：this <https://> URL。 

---
# The Intercepted Self: How Generative AI Challenges the Dynamics of the Relational Self 

**Title (ZH)**: 拦截的自我：生成式AI如何挑战关系自我的动态 

**Authors**: Sandrine R. Schiller, Camilo Miguel Signorelli, Filippos Stamatiou  

**Link**: [PDF](https://arxiv.org/pdf/2509.13391)  

**Abstract**: Generative AI is changing our way of interacting with technology, others, and ourselves. Systems such as Microsoft copilot, Gemini and the expected Apple intelligence still awaits our prompt for action. Yet, it is likely that AI assistant systems will only become better at predicting our behaviour and acting on our behalf. Imagine new generations of generative and predictive AI deciding what you might like best at a new restaurant, picking an outfit that increases your chances on your date with a partner also chosen by the same or a similar system. Far from a science fiction scenario, the goal of several research programs is to build systems capable of assisting us in exactly this manner. The prospect urges us to rethink human-technology relations, but it also invites us to question how such systems might change the way we relate to ourselves. Building on our conception of the relational self, we question the possible effects of generative AI with respect to what we call the sphere of externalised output, the contextual sphere and the sphere of self-relating. In this paper, we attempt to deepen the existential considerations accompanying the AI revolution by outlining how generative AI enables the fulfilment of tasks and also increasingly anticipates, i.e. intercepts, our initiatives in these different spheres. 

**Abstract (ZH)**: 生成式人工智能正在改变我们与技术、他人和自身的交互方式。诸如微软小令景、Gemini以及预期中的苹果智能助手等系统仍在等待我们的指令。然而，AI助手系统很可能会更擅长预测我们的行为并代我们行事。想象一下，新一代的生成式和预测式AI决定你在一个新餐馆里可能会最喜欢什么，挑选一种增加你在与由同一系统或类似系统选择的伴侣约会时成功率的着装。这不仅不是一个科幻场景，而且多个研究计划的目标是构建能够以这种方式协助我们的系统。这一前景促使我们重新思考人机关系，同时也促使我们质疑这些系统如何改变我们与自身的关联方式。基于我们对关系自我的理解，我们质疑生成式人工智能在外部输出领域、情境领域和自相关领域可能产生的影响。在本文中，我们尝试通过阐述生成式人工智能在这些不同领域如何使任务得以实现并越来越抢先干预我们的行动，深化对人工智能革命的本体论考虑。 

---
# A Domain Knowledge Informed Approach for Anomaly Detection of Electric Vehicle Interior Sounds 

**Title (ZH)**: 基于领域知识的电动汽车内饰声音异常检测方法 

**Authors**: Deepti Kunte, Bram Cornelis, Claudio Colangeli, Karl Janssens, Brecht Van Baelen, Konstantinos Gryllias  

**Link**: [PDF](https://arxiv.org/pdf/2509.13390)  

**Abstract**: The detection of anomalies in automotive cabin sounds is critical for ensuring vehicle quality and maintaining passenger comfort. In many real-world settings, this task is more appropriately framed as an unsupervised learning problem rather than the supervised case due to the scarcity or complete absence of labeled faulty data. In such an unsupervised setting, the model is trained exclusively on healthy samples and detects anomalies as deviations from normal behavior. However, in the absence of labeled faulty samples for validation and the limited reliability of commonly used metrics, such as validation reconstruction error, effective model selection remains a significant challenge. To overcome these limitations, a domain-knowledge-informed approach for model selection is proposed, in which proxy-anomalies engineered through structured perturbations of healthy spectrograms are used in the validation set to support model selection. The proposed methodology is evaluated on a high-fidelity electric vehicle dataset comprising healthy and faulty cabin sounds across five representative fault types viz., Imbalance, Modulation, Whine, Wind, and Pulse Width Modulation. This dataset, generated using advanced sound synthesis techniques, and validated via expert jury assessments, has been made publicly available to facilitate further research. Experimental evaluations on the five fault cases demonstrate the selection of optimal models using proxy-anomalies, significantly outperform conventional model selection strategies. 

**Abstract (ZH)**: 汽车内饰声音异常检测对于确保车辆质量和维持乘客舒适度至关重要。在许多实际场景中，由于故障标签数据的稀缺或完全缺失，此任务更适合作为无监督学习问题而非有监督学习问题。在这种无监督情况下，模型仅使用健康样本进行训练，并通过检测与正常行为的偏差来识别异常。然而，在缺乏标签故障样本进行验证，并且常用验证重建误差等指标可靠性有限的情况下，有效的模型选择仍然是一个重大挑战。为克服这些局限性，提出了一种基于领域知识的模型选择方法，其中通过结构化修改健康频谱图生成的代理异常用于验证集，以支持模型选择。所提出的方法在包含五种代表性故障类型（不平衡、调制、鸣叫声、风声和脉冲宽度调制）的健康和故障 cabin 声音的高保真电动汽车数据集上进行了评估。该数据集使用高级声音合成技术生成，并通过专家评审验证，已公开发布以促进进一步研究。在五个故障案例的实验评估中证明，使用代理异常可以显著超越传统模型选择策略，选择出最优模型。 

---
# Landcover classification and change detection using remote sensing and machine learning: a case study of Western Fiji 

**Title (ZH)**: 基于遥感和机器学习的土地覆盖分类与变化检测：斐济西部案例研究 

**Authors**: Yadvendra Gurjar, Ruoni Wan, Ehsan Farahbakhsh, Rohitash Chandra  

**Link**: [PDF](https://arxiv.org/pdf/2509.13388)  

**Abstract**: As a developing country, Fiji is facing rapid urbanisation, which is visible in the massive development projects that include housing, roads, and civil works. In this study, we present machine learning and remote sensing frameworks to compare land use and land cover change from 2013 to 2024 in Nadi, Fiji. The ultimate goal of this study is to provide technical support in land cover/land use modelling and change detection. We used Landsat-8 satellite image for the study region and created our training dataset with labels for supervised machine learning. We used Google Earth Engine and unsupervised machine learning via k-means clustering to generate the land cover map. We used convolutional neural networks to classify the selected regions' land cover types. We present a visualisation of change detection, highlighting urban area changes over time to monitor changes in the map. 

**Abstract (ZH)**: 作为一个发展中国家，斐济正面临快速城市化，这在大规模的发展项目中尤为明显，包括住房、道路和基础设施建设。在本研究中，我们提出机器学习和遥感框架，比较斐济纳迪地区2013年至2024年的土地利用和土地覆盖变化。本研究最终目标是为土地覆盖/利用建模和变化检测提供技术支持。我们使用陆地卫星8号图像进行研究，并创建了带有监督机器学习标签的训练数据集。我们使用Google Earth Engine和基于k均值聚类的无监督机器学习生成土地覆盖图。我们使用卷积神经网络对选定区域的土地覆盖类型进行分类。我们展示了变化检测的可视化，突出显示随时间变化的城市区域，以监测地图的变化。 

---
# Uncovering AI Governance Themes in EU Policies using BERTopic and Thematic Analysis 

**Title (ZH)**: 使用BERTopic和主题分析揭示欧盟政策中的AI治理主题 

**Authors**: Delaram Golpayegani, Marta Lasek-Markey, Arjumand Younus, Aphra Kerr, Dave Lewis  

**Link**: [PDF](https://arxiv.org/pdf/2509.13387)  

**Abstract**: The upsurge of policies and guidelines that aim to ensure Artificial Intelligence (AI) systems are safe and trustworthy has led to a fragmented landscape of AI governance. The European Union (EU) is a key actor in the development of such policies and guidelines. Its High-Level Expert Group (HLEG) issued an influential set of guidelines for trustworthy AI, followed in 2024 by the adoption of the EU AI Act. While the EU policies and guidelines are expected to be aligned, they may differ in their scope, areas of emphasis, degrees of normativity, and priorities in relation to AI. To gain a broad understanding of AI governance from the EU perspective, we leverage qualitative thematic analysis approaches to uncover prevalent themes in key EU documents, including the AI Act and the HLEG Ethics Guidelines. We further employ quantitative topic modelling approaches, specifically through the use of the BERTopic model, to enhance the results and increase the document sample to include EU AI policy documents published post-2018. We present a novel perspective on EU policies, tracking the evolution of its approach to addressing AI governance. 

**Abstract (ZH)**: 欧盟政策和准则的兴起导致了人工智能治理的碎片化景观：从欧盟视角探讨可信人工智能治理的演进 

---
# Evaluating undergraduate mathematics examinations in the era of generative AI: a curriculum-level case study 

**Title (ZH)**: 评估生成式AI时代本科数学考试：课程层面的案例研究 

**Authors**: Benjamin J. Walker, Beatriz Navarro Lameda, Ruth A. Reynolds  

**Link**: [PDF](https://arxiv.org/pdf/2509.13359)  

**Abstract**: Generative artificial intelligence (GenAI) tools such as OpenAI's ChatGPT are transforming the educational landscape, prompting reconsideration of traditional assessment practices. In parallel, universities are exploring alternatives to in-person, closed-book examinations, raising concerns about academic integrity and pedagogical alignment in uninvigilated settings. This study investigates whether traditional closed-book mathematics examinations retain their pedagogical relevance when hypothetically administered in uninvigilated, open-book settings with GenAI access. Adopting an empirical approach, we generate, transcribe, and blind-mark GenAI submissions to eight undergraduate mathematics examinations at a Russel Group university, spanning the entirety of the first-year curriculum. By combining independent GenAI responses to individual questions, we enable a meaningful evaluation of GenAI performance, both at the level of modules and across the first-year curriculum. We find that GenAI attainment is at the level of a first-class degree, though current performance can vary between modules. Further, we find that GenAI performance is remarkably consistent when viewed across the entire curriculum, significantly more so than that of students in invigilated examinations. Our findings evidence the need for redesigning assessments in mathematics for unsupervised settings, and highlight the potential reduction in pedagogical value of current standards in the era of generative artificial intelligence. 

**Abstract (ZH)**: 生成式人工智能工具在开放书、有生成式人工智能接入情况下，传统闭卷数学考试的 pedagogical 价值探究 

---
# Synthetic Data and the Shifting Ground of Truth 

**Title (ZH)**: 合成数据与真理基础的变动性 

**Authors**: Dietmar Offenhuber  

**Link**: [PDF](https://arxiv.org/pdf/2509.13355)  

**Abstract**: The emergence of synthetic data for privacy protection, training data generation, or simply convenient access to quasi-realistic data in any shape or volume complicates the concept of ground truth. Synthetic data mimic real-world observations, but do not refer to external features. This lack of a representational relationship, however, not prevent researchers from using synthetic data as training data for AI models and ground truth repositories. It is claimed that the lack of data realism is not merely an acceptable tradeoff, but often leads to better model performance than realistic data: compensate for known biases, prevent overfitting and support generalization, and make the models more robust in dealing with unexpected outliers. Indeed, injecting noisy and outright implausible data into training sets can be beneficial for the model. This greatly complicates usual assumptions based on which representational accuracy determines data fidelity (garbage in - garbage out). Furthermore, ground truth becomes a self-referential affair, in which the labels used as a ground truth repository are themselves synthetic products of a generative model and as such not connected to real-world observations. My paper examines how ML researchers and practitioners bootstrap ground truth under such paradoxical circumstances without relying on the stable ground of representation and real-world reference. It will also reflect on the broader implications of a shift from a representational to what could be described as a mimetic or iconic concept of data. 

**Abstract (ZH)**: 合成数据在隐私保护、训练数据生成或简单地方便访问各种形态和规模的准真实数据的出现使真实数据的概念复杂化。合成数据模拟真实世界的观察，但不参考外部特征。然而，缺乏代表关系并未阻止研究人员使用合成数据作为AI模型的训练数据和真实数据的替代品。人们声称，数据的真实性并非仅仅是可接受的折衷，反而常常导致比真实数据更好的模型性能：补偿已知的偏差、防止过拟合并支持泛化，使模型更健壮地处理意外的异常值。实际上，向训练集中注入噪音和完全不可信的数据对模型是有益的。这极大地复杂了基于代表性准确性决定数据 fidelity的常规假设（ garbage in - garbage out）。此外，真实数据成为一种自我参照的现象，在这种现象中，用作真实数据替代品的标签本身就是生成模型的产物，因此与真实世界的观察没有关联。我的论文探讨了在这些悖论情况下，如何促使ML研究人员和实践者建立真实数据的概念，而不依赖于代表性和现实世界的参考。它还将反思从代表性到可以称为拟态或图示数据概念的转变所带来的更广泛影响。 

---
# Proximity-Based Evidence Retrieval for Uncertainty-Aware Neural Networks 

**Title (ZH)**: 基于邻近性的证据检索以实现不确定性感知神经网络 

**Authors**: Hassan Gharoun, Mohammad Sadegh Khorshidi, Kasra Ranjbarigderi, Fang Chen, Amir H. Gandomi  

**Link**: [PDF](https://arxiv.org/pdf/2509.13338)  

**Abstract**: This work proposes an evidence-retrieval mechanism for uncertainty-aware decision-making that replaces a single global cutoff with an evidence-conditioned, instance-adaptive criterion. For each test instance, proximal exemplars are retrieved in an embedding space; their predictive distributions are fused via Dempster-Shafer theory. The resulting fused belief acts as a per-instance thresholding mechanism. Because the supporting evidences are explicit, decisions are transparent and auditable. Experiments on CIFAR-10/100 with BiT and ViT backbones show higher or comparable uncertainty-aware performance with materially fewer confidently incorrect outcomes and a sustainable review load compared with applying threshold on prediction entropy. Notably, only a few evidences are sufficient to realize these gains; increasing the evidence set yields only modest changes. These results indicate that evidence-conditioned tagging provides a more reliable and interpretable alternative to fixed prediction entropy thresholds for operational uncertainty-aware decision-making. 

**Abstract (ZH)**: 基于证据检索的不确定性意识决策机制：用实例适应性标准替代固定全局阈值 

---
# Dual Actor DDPG for Airborne STAR-RIS Assisted Communications 

**Title (ZH)**: 空中STAR-RIS辅助通信的双actor DDPG方法 

**Authors**: Danish Rizvi, David Boyle  

**Link**: [PDF](https://arxiv.org/pdf/2509.13328)  

**Abstract**: This study departs from the prevailing assumption of independent Transmission and Reflection Coefficients (TRC) in Airborne Simultaneous Transmit and Reflect Reconfigurable Intelligent Surface (STAR-RIS) research. Instead, we explore a novel multi-user downlink communication system that leverages a UAV-mounted STAR-RIS (Aerial-STAR) incorporating a coupled TRC phase shift model. Our key contributions include the joint optimization of UAV trajectory, active beamforming vectors at the base station, and passive RIS TRCs to enhance communication efficiency, while considering UAV energy constraints. We design the TRC as a combination of discrete and continuous actions, and propose a novel Dual Actor Deep Deterministic Policy Gradient (DA-DDPG) algorithm. The algorithm relies on two separate actor networks for high-dimensional hybrid action space. We also propose a novel harmonic mean index (HFI)-based reward function to ensure communication fairness amongst users. For comprehensive analysis, we study the impact of RIS size on UAV aerodynamics showing that it increases drag and energy demand. Simulation results demonstrate that the proposed DA-DDPG algorithm outperforms conventional DDPG and DQN-based solutions by 24% and 97%, respectively, in accumulated reward. Three-dimensional UAV trajectory optimization achieves 28% higher communication efficiency compared to two-dimensional and altitude optimization. The HFI based reward function provides 41% lower QoS denial rates as compared to other benchmarks. The mobile Aerial-STAR system shows superior performance over fixed deployed counterparts, with the coupled phase STAR-RIS outperforming dual Transmit/Reflect RIS and conventional RIS setups. These findings highlight the potential of Aerial-STAR systems and the effectiveness of our proposed DA-DDPG approach in optimizing their performance. 

**Abstract (ZH)**: 基于无人驾驶飞机的STAR-RIS耦合传输-反射系数的多用户下行链路通信系统：一种新的双Actordeep确定性策略梯度算法研究 

---
# Prognosis of COVID-19 using Artificial Intelligence: A Systematic Review and Meta-analysis 

**Title (ZH)**: 使用人工智能预测COVID-19：一项系统回顾和元分析 

**Authors**: SaeedReza Motamedian, Sadra Mohaghegh, Elham Babadi Oregani, Mahrsa Amjadi, Parnian Shobeiri, Negin Cheraghi, Niusha Solouki, Nikoo Ahmadi, Hossein Mohammad-Rahimi, Yassine Bouchareb, Arman Rahmim  

**Link**: [PDF](https://arxiv.org/pdf/2408.00208)  

**Abstract**: Purpose: Artificial intelligence (AI) techniques have been extensively utilized for diagnosing and prognosis of several diseases in recent years. This study identifies, appraises and synthesizes published studies on the use of AI for the prognosis of COVID-19. Method: Electronic search was performed using Medline, Google Scholar, Scopus, Embase, Cochrane and ProQuest. Studies that examined machine learning or deep learning methods to determine the prognosis of COVID-19 using CT or chest X-ray images were included. Polled sensitivity, specificity area under the curve and diagnostic odds ratio were calculated. Result: A total of 36 articles were included; various prognosis-related issues, including disease severity, mechanical ventilation or admission to the intensive care unit and mortality, were investigated. Several AI models and architectures were employed, such as the Siamense model, support vector machine, Random Forest , eXtreme Gradient Boosting, and convolutional neural networks. The models achieved 71%, 88% and 67% sensitivity for mortality, severity assessment and need for ventilation, respectively. The specificity of 69%, 89% and 89% were reported for the aforementioned variables. Conclusion: Based on the included articles, machine learning and deep learning methods used for the prognosis of COVID-19 patients using radiomic features from CT or CXR images can help clinicians manage patients and allocate resources more effectively. These studies also demonstrate that combining patient demographic, clinical data, laboratory tests and radiomic features improves model performances. 

**Abstract (ZH)**: 目的：近年来，人工智能（AI）技术已经被广泛应用于多种疾病的诊断和预后。本研究旨在识别、评估并综合分析使用AI进行COVID-19预后研究的已发表文献。方法：通过Medline、Google Scholar、Scopus、Embase、Cochrane和ProQuest等电子数据库进行文献检索。纳入使用CT或胸部X光图像，并通过机器学习或深度学习方法确定COVID-19预后的研究。计算汇总的敏感性、特异性和受试者工作特征曲线下面积及诊断优势比。结果：共纳入36篇文章，研究了疾病严重程度、机械通气或入住重症监护单元以及死亡等多种预后相关问题。使用了多种AI模型和架构，如Siamese模型、支持向量机、随机森林、极端梯度提升和卷积神经网络。模型分别在死亡、病情评估和通气需求上的敏感性达到71%、88%和67%；上述变量的特异性分别为69%、89%和89%。结论：根据纳入的文章，使用CT或X光图像的影像组学特征进行COVID-19患者的预后预测，可以帮助临床医生更有效地管理和分配资源。此外，这些研究还表明，结合患者的临床数据、实验室检查和影像组学特征可以提高模型性能。 

---
# Joint data imputation and mechanistic modelling for simulating heart-brain interactions in incomplete datasets 

**Title (ZH)**: 联合数据插补和机制建模以模拟不完整数据集中的心脑交互作用 

**Authors**: Jaume Banus, Maxime Sermesant, Oscar Camara, Marco Lorenzi  

**Link**: [PDF](https://arxiv.org/pdf/2010.01052)  

**Abstract**: The use of mechanistic models in clinical studies is limited by the lack of multi-modal patients data representing different anatomical and physiological processes. For example, neuroimaging datasets do not provide a sufficient representation of heart features for the modeling of cardiovascular factors in brain disorders. To tackle this problem we introduce a probabilistic framework for joint cardiac data imputation and personalisation of cardiovascular mechanistic models, with application to brain studies with incomplete heart data. Our approach is based on a variational framework for the joint inference of an imputation model of cardiac information from the available features, along with a Gaussian Process emulator that can faithfully reproduce personalised cardiovascular dynamics. Experimental results on UK Biobank show that our model allows accurate imputation of missing cardiac features in datasets containing minimal heart information, e.g. systolic and diastolic blood pressures only, while jointly estimating the emulated parameters of the lumped model. This allows a novel exploration of the heart-brain joint relationship through simulation of realistic cardiac dynamics corresponding to different conditions of brain anatomy. 

**Abstract (ZH)**: 机制模型在临床研究中的应用受限于多模态患者数据的缺乏，这些数据未能充分代表不同的解剖和生理过程。例如，神经影像数据无法为脑部疾病中的心血管因素建模提供足够的心脏特征表示。为了解决这一问题，我们引入了一种概率框架，用于联合心脏数据插补和个人化心血管机制模型，应用于心脏数据不完整的大脑研究。我们的方法基于一个联合推断心脏信息插补模型和高斯过程模拟器的变分框架，该模拟器能够忠实再现个性化的心血管动态。UK生物银行上的实验结果表明，我们的模型能够在仅包含最小心脏信息的数据集中准确插补缺失的心脏特征，如仅 systolic 和 diastolic 血压，同时联合估计汇总模型的模拟参数。这使我们能够通过模拟不同脑部 anatomy 条件下的现实心脏动态来探索心脏-大脑联合关系的新途径。 

---
