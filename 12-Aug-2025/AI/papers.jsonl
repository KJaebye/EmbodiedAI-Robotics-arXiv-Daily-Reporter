{'arxiv_id': 'arXiv:2508.08147', 'title': 'From Natural Language to Solver-Ready Power System Optimization: An LLM-Assisted, Validation-in-the-Loop Framework', 'authors': 'Yunkai Hu, Tianqiao Zhao, Meng Yue', 'link': 'https://arxiv.org/abs/2508.08147', 'abstract': 'This paper introduces a novel Large Language Models (LLMs)-assisted agent that automatically converts natural-language descriptions of power system optimization scenarios into compact, solver-ready formulations and generates corresponding solutions. In contrast to approaches that rely solely on LLM to produce solutions directly, the proposed method focuses on discovering a mathematically compatible formulation that can be efficiently solved by off-the-shelf optimization solvers. Directly using LLMs to produce solutions often leads to infeasible or suboptimal results, as these models lack the numerical precision and constraint-handling capabilities of established optimization solvers. The pipeline integrates a domain-aware prompt and schema with an LLM, enforces feasibility through systematic validation and iterative repair, and returns both solver-ready models and user-facing results. Using the unit commitment problem as a representative case study, the agent produces optimal or near-optimal schedules along with the associated objective costs. Results demonstrate that coupling the solver with task-specific validation significantly enhances solution reliability. This work shows that combining AI with established optimization frameworks bridges high-level problem descriptions and executable mathematical models, enabling more efficient decision-making in energy systems', 'abstract_zh': '本文介绍了一种新型的大型语言模型（LLM）辅助代理，它可以自动将电力系统优化场景的自然语言描述转换为紧凑且可以直接求解的格式，并生成相应的解决方案。与仅依赖LLM直接生成解决方案的方法不同，本方法的重点在于发现一个数学上兼容且可以被现成的优化求解器高效求解的公式。直接使用LLM生成解决方案往往会导致不可行或次优的结果，因为这些模型缺乏现成优化求解器的数值精度和约束处理能力。该管道集成了领域 Awareness 的提示和方案，并结合了LLM，通过系统的验证和迭代修复来确保可行性，最终返回既可以被求解器直接使用又可以供用户查看的结果。以机组调度问题为例，代理可以生成最优或接近最优的调度方案及其关联的目标成本。实验结果表明，将求解器与任务特定的验证相结合显著提高了解决方案的可靠性。本文展示了将AI与现有的优化框架结合可以将高层级的问题描述与可执行的数学模型结合起来，从而在能源系统中实现更高效的决策。', 'title_zh': '从自然语言到求解器就绪的电力系统优化：一种LLM辅助的、边验证边loop框架'}
{'arxiv_id': 'arXiv:2508.08127', 'title': 'BlindGuard: Safeguarding LLM-based Multi-Agent Systems under Unknown Attacks', 'authors': 'Rui Miao, Yixin Liu, Yili Wang, Xu Shen, Yue Tan, Yiwei Dai, Shirui Pan, Xin Wang', 'link': 'https://arxiv.org/abs/2508.08127', 'abstract': 'The security of LLM-based multi-agent systems (MAS) is critically threatened by propagation vulnerability, where malicious agents can distort collective decision-making through inter-agent message interactions. While existing supervised defense methods demonstrate promising performance, they may be impractical in real-world scenarios due to their heavy reliance on labeled malicious agents to train a supervised malicious detection model. To enable practical and generalizable MAS defenses, in this paper, we propose BlindGuard, an unsupervised defense method that learns without requiring any attack-specific labels or prior knowledge of malicious behaviors. To this end, we establish a hierarchical agent encoder to capture individual, neighborhood, and global interaction patterns of each agent, providing a comprehensive understanding for malicious agent detection. Meanwhile, we design a corruption-guided detector that consists of directional noise injection and contrastive learning, allowing effective detection model training solely on normal agent behaviors. Extensive experiments show that BlindGuard effectively detects diverse attack types (i.e., prompt injection, memory poisoning, and tool attack) across MAS with various communication patterns while maintaining superior generalizability compared to supervised baselines. The code is available at: this https URL.', 'abstract_zh': '基于大模型的多agent系统安全性受到传播漏洞的严重威胁，恶意agent可以通过代理间消息交互扭曲集体决策。虽然现有的监督防御方法具有良好的性能，但在实际场景中由于高度依赖标记的恶意agent进行恶意检测模型的训练，可能难以实施。为了实现实际且可泛化的多agent系统防御，在本文中我们提出了BlindGuard，一种无需任何特定攻击标签或恶意行为先验知识的无监督防御方法。为此，我们建立了一个层次化agent编码器，以捕捉每个agent的个体、邻域和全局交互模式，为恶意agent检测提供全面理解。同时，我们设计了一种基于 Corruption 的检测器，包括定向噪声注入和对比学习，仅通过正常代理行为即可有效训练检测模型。广泛实验表明，BlindGuard 能够在各种通信模式的多agent系统中有效检测多种攻击类型（即提示注入、内存污染和工具攻击），并在泛化性能上优于监督基准方法。代码可在以下链接获取：this https URL。', 'title_zh': 'BlindGuard: 保护基于未知攻击的LLM多Agent系统'}
{'arxiv_id': 'arXiv:2508.08115', 'title': 'TeamMedAgents: Enhancing Medical Decision-Making of LLMs Through Structured Teamwork', 'authors': 'Pranav Pushkar Mishra, Mohammad Arvan, Mohan Zalake', 'link': 'https://arxiv.org/abs/2508.08115', 'abstract': 'We present TeamMedAgents, a novel multi-agent approach that systematically integrates evidence-based teamwork components from human-human collaboration into medical decision-making with large language models (LLMs). Our approach validates an organizational psychology teamwork model from human collaboration to computational multi-agent medical systems by operationalizing six core teamwork components derived from Salas et al.\'s "Big Five" model: team leadership, mutual performance monitoring, team orientation, shared mental models, closed-loop communication, and mutual trust. We implement and evaluate these components as modular, configurable mechanisms within an adaptive collaboration architecture while assessing the effect of the number of agents involved based on the task\'s requirements and domain. Systematic evaluation of computational implementations of teamwork behaviors across eight medical benchmarks (MedQA, MedMCQA, MMLU-Pro Medical, PubMedQA, DDXPlus, MedBullets, Path-VQA, and PMC-VQA) demonstrates consistent improvements across 7 out of 8 evaluated datasets. Controlled ablation studies conducted on 50 questions per configuration across 3 independent runs provide mechanistic insights into individual component contributions, revealing optimal teamwork configurations that vary by reasoning task complexity and domain-specific requirements. Our ablation analyses reveal dataset-specific optimal teamwork configurations, indicating that different medical reasoning modalities benefit from distinct collaborative patterns. TeamMedAgents represents an advancement in collaborative AI by providing a systematic translation of established teamwork theories from human collaboration into agentic collaboration, establishing a foundation for evidence-based multi-agent system design in critical decision-making domains.', 'abstract_zh': 'TeamMedAgents：一种将基于证据的团队协作要素系统整合到大规模语言模型医疗决策中的新型多智能体方法', 'title_zh': 'TeamMedAgents: 通过结构化 teamwork 提高大语言模型的医疗决策能力'}
{'arxiv_id': 'arXiv:2508.08075', 'title': 'FNBT: Full Negation Belief Transformation for Open-World Information Fusion Based on Dempster-Shafer Theory of Evidence', 'authors': 'Meishen He, Wenjun Ma, Jiao Wang, Huijun Yue, Xiaoma Fan', 'link': 'https://arxiv.org/abs/2508.08075', 'abstract': "The Dempster-Shafer theory of evidence has been widely applied in the field of information fusion under uncertainty. Most existing research focuses on combining evidence within the same frame of discernment. However, in real-world scenarios, trained algorithms or data often originate from different regions or organizations, where data silos are prevalent. As a result, using different data sources or models to generate basic probability assignments may lead to heterogeneous frames, for which traditional fusion methods often yield unsatisfactory results. To address this challenge, this study proposes an open-world information fusion method, termed Full Negation Belief Transformation (FNBT), based on the Dempster-Shafer theory. More specially, a criterion is introduced to determine whether a given fusion task belongs to the open-world setting. Then, by extending the frames, the method can accommodate elements from heterogeneous frames. Finally, a full negation mechanism is employed to transform the mass functions, so that existing combination rules can be applied to the transformed mass functions for such information fusion. Theoretically, the proposed method satisfies three desirable properties, which are formally proven: mass function invariance, heritability, and essential conflict elimination. Empirically, FNBT demonstrates superior performance in pattern classification tasks on real-world datasets and successfully resolves Zadeh's counterexample, thereby validating its practical effectiveness.", 'abstract_zh': 'Dempster-Shafer理论在不确定性环境下信息融合领域的广泛应用主要集中在相同识别框架内的证据结合。然而，在实际场景中，训练算法或数据往往源自不同的地区或机构，造成数据孤岛现象普遍存在。因此，使用来自不同数据源或模型的基本概率分配可能会产生异构框架，而传统的融合方法在这些情况下往往效果不佳。为了解决这一挑战，基于Dempster-Shafer理论，本文提出了一种开放世界信息融合方法，称为全否定信念转换（FNBT）。更具体地，本文引入了一个标准来确定给定的融合任务是否属于开放世界设置。然后，通过扩展框架，该方法能够容纳来自异构框架的元素。最后，采用全否定机制来转换质量函数，使得现有的组合规则可以应用于转换后质量函数进行信息融合。理论上，所提出的方法满足三个 desirable 性质，其正确性已形式证明：质量函数不变性、遗传性以及基本冲突消除。实验上，FNBT 在实际数据集上的模式分类任务中展现出优越性能，并成功解决了 Zadeh 的反例，从而验证了其实用有效性。', 'title_zh': 'FNBT: 基于Dempster-Shafer证据理论的全否定信念转换开放世界信息融合'}
{'arxiv_id': 'arXiv:2508.08053', 'title': 'AdaptFlow: Adaptive Workflow Optimization via Meta-Learning', 'authors': 'Runchuan Zhu, Bowen Jiang, Lingrui Mei, Fangkai Yang, Lu Wang, Haoxiang Gao, Fengshuo Bai, Pu Zhao, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang', 'link': 'https://arxiv.org/abs/2508.08053', 'abstract': 'Recent advances in large language models (LLMs) have sparked growing interest in agentic workflows, which are structured sequences of LLM invocations intended to solve complex tasks. However, existing approaches often rely on static templates or manually designed workflows, which limit adaptability to diverse tasks and hinder scalability. We propose AdaptFlow, a natural language-based meta-learning framework inspired by model-agnostic meta-learning (MAML). AdaptFlow learns a generalizable workflow initialization that enables rapid subtask-level adaptation. It employs a bi-level optimization scheme: the inner loop refines the workflow for a specific subtask using LLM-generated feedback, while the outer loop updates the shared initialization to perform well across tasks. This setup allows AdaptFlow to generalize effectively to unseen tasks by adapting the initialized workflow through language-guided modifications. Evaluated across question answering, code generation, and mathematical reasoning benchmarks, AdaptFlow consistently outperforms both manually crafted and automatically searched baselines, achieving state-of-the-art results with strong generalization across tasks and models. The source code and data are available at this https URL.', 'abstract_zh': 'Recent advances in大型语言模型（LLMs）激发了对具有代理性的工作流的兴趣，这些工作流是旨在解决复杂任务的结构化LLM调用序列。然而，现有的方法往往依赖于静态模板或人工设计的工作流，这限制了其对多样任务的适应性并阻碍了 scalability。我们提出了AdaptFlow，这是一种受模型无关元学习（MAML）启发的基于自然语言的元学习框架。AdaptFlow 学习一个可泛化的初始化工作流，能够实现快速的子任务级别适应。它采用双重优化方案：内层循环使用LLM生成的反馈为特定子任务细化工作流，而外层循环更新共享的初始化以便跨任务表现良好。这种设置使得AdaptFlow能够在语言引导的修改下有效地泛化到未见过的任务。AdaptFlow在问题回答、代码生成和数学推理基准测试中均优于手工设计和自动搜索的基线，实现了跨任务和模型的强泛化表现。源代码和数据可在以下链接获取。', 'title_zh': 'AdaptFlow：基于元学习的适应性工作流优化'}
{'arxiv_id': 'arXiv:2508.08007', 'title': 'Fitting Description Logic Ontologies to ABox and Query Examples', 'authors': 'Maurice Funk, Marvin Grosser, Carsten Lutz', 'link': 'https://arxiv.org/abs/2508.08007', 'abstract': 'We study a fitting problem inspired by ontology-mediated querying: given a collection\nof positive and negative examples of\nthe form $(\\mathcal{A},q)$ with\n$\\mathcal{A}$ an ABox and $q$ a Boolean query, we seek\nan ontology $\\mathcal{O}$ that satisfies $\\mathcal{A} \\cup \\mathcal{O} \\vDash q$ for all positive examples and $\\mathcal{A} \\cup \\mathcal{O}\\not\\vDash q$ for all negative examples.\nWe consider the description logics $\\mathcal{ALC}$ and $\\mathcal{ALCI}$ as ontology languages and\na range of query languages that\nincludes atomic queries (AQs), conjunctive queries (CQs), and unions thereof (UCQs).\nFor all of the resulting fitting problems,\nwe provide\neffective characterizations and determine the computational complexity\nof deciding whether a fitting ontology exists. This problem turns out to be ${\\small CO}NP$ for AQs and full CQs\nand $2E{\\small XP}T{\\small IME}$-complete for CQs and UCQs.\nThese results hold for both $\\mathcal{ALC}$ and $\\mathcal{ALCI}$.', 'abstract_zh': '我们研究了一个受本体介导查询启发的拟合问题：给定形式为$(\\mathcal{A},q)$的正例和负例集合，其中$\\mathcal{A}$是一个ABox且$q$是一个布尔查询，我们寻求一个本体$\\mathcal{O}$，使得对于所有正例有$\\mathcal{A} \\cup \\mathcal{O} \\vDash q$，而对于所有负例有$\\mathcal{A} \\cup \\mathcal{O}\\not\\vDash q$。我们将描述逻辑$\\mathcal{ALC}$和$\\mathcal{ALCI}$作为本体语言，并考虑一系列查询语言，包括原子查询(AQs)、合取查询(CQs)及其并集(UCQs)。对于所有由此产生的拟合问题，我们提供了有效表征，并确定了决定是否存在拟合本体的计算复杂性。该问题对于AQs和完整CQs是${\\small CO}NP$问题，而对于CQs和UCQs是$2{\\small EXPTIME}$完全问题。这些结果对于$\\mathcal{ALC}$和$\\mathcal{ALCI}$都成立。', 'title_zh': '将描述逻辑本体拟合到ABox和查询示例'}
{'arxiv_id': 'arXiv:2508.08001', 'title': 'Interpreting Fedspeak with Confidence: A LLM-Based Uncertainty-Aware Framework Guided by Monetary Policy Transmission Paths', 'authors': 'Rui Yao, Qi Chai, Jinhai Yao, Siyuan Li, Junhao Chen, Qi Zhang, Hao Wang', 'link': 'https://arxiv.org/abs/2508.08001', 'abstract': '"Fedspeak", the stylized and often nuanced language used by the U.S. Federal Reserve, encodes implicit policy signals and strategic stances. The Federal Open Market Committee strategically employs Fedspeak as a communication tool to shape market expectations and influence both domestic and global economic conditions. As such, automatically parsing and interpreting Fedspeak presents a high-impact challenge, with significant implications for financial forecasting, algorithmic trading, and data-driven policy analysis. In this paper, we propose an LLM-based, uncertainty-aware framework for deciphering Fedspeak and classifying its underlying monetary policy stance. Technically, to enrich the semantic and contextual representation of Fedspeak texts, we incorporate domain-specific reasoning grounded in the monetary policy transmission mechanism. We further introduce a dynamic uncertainty decoding module to assess the confidence of model predictions, thereby enhancing both classification accuracy and model reliability. Experimental results demonstrate that our framework achieves state-of-the-art performance on the policy stance analysis task. Moreover, statistical analysis reveals a significant positive correlation between perceptual uncertainty and model error rates, validating the effectiveness of perceptual uncertainty as a diagnostic signal.', 'abstract_zh': '联邦储备使用的“Fedspeak”语言精炼且往往内涵丰富，编码了隐含的政策信号和战略姿态。联邦公开市场委员会战略性地运用Fedspeak作为沟通工具，以塑造市场预期并影响国内外经济条件。因此，自动解析和解释Fedspeak是一项高影响的挑战，对于金融预测、算法交易和数据驱动的政策分析具有重要意义。本文提出了一种基于大规模语言模型（LLM）并具备不确定性意识的框架，用于解读Fedspeak并分类其背后的货币政策立场。技术上，为了丰富Fedspeak文本的语义和上下文表示，我们融入了基于货币政策传导机制的领域特定推理。我们进一步引入了一个动态不确定性解码模块，以评估模型预测的置信度，从而提高分类准确性和模型可靠性。实验结果表明，我们的框架在政策立场分析任务上达到了最先进的性能。此外，统计分析发现感知不确定性和模型错误率之间存在显著的正相关关系，验证了感知不确定性作为诊断信号的有效性。', 'title_zh': '基于货币传导路径的不确定性意识框架：以自信解读Fedspeak的LLM为基础'}
{'arxiv_id': 'arXiv:2508.07950', 'title': 'FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis', 'authors': 'Chen Shen, Wanqing Zhang, Kehan Li, Erwen Huang, Haitao Bi, Aiying Fan, Yiwen Shen, Hongmei Dong, Ji Zhang, Yuming Shao, Zengjia Liu, Xinshe Liu, Tao Li, Chunxia Yan, Shuanliang Fan, Di Wu, Jianhua Ma, Bin Cong, Zhenyuan Wang, Chunfeng Lian', 'link': 'https://arxiv.org/abs/2508.07950', 'abstract': "Forensic cause-of-death determination faces systemic challenges, including workforce shortages and diagnostic variability, particularly in high-volume systems like China's medicolegal infrastructure. We introduce FEAT (ForEnsic AgenT), a multi-agent AI framework that automates and standardizes death investigations through a domain-adapted large language model. FEAT's application-oriented architecture integrates: (i) a central Planner for task decomposition, (ii) specialized Local Solvers for evidence analysis, (iii) a Memory & Reflection module for iterative refinement, and (iv) a Global Solver for conclusion synthesis. The system employs tool-augmented reasoning, hierarchical retrieval-augmented generation, forensic-tuned LLMs, and human-in-the-loop feedback to ensure legal and medical validity. In evaluations across diverse Chinese case cohorts, FEAT outperformed state-of-the-art AI systems in both long-form autopsy analyses and concise cause-of-death conclusions. It demonstrated robust generalization across six geographic regions and achieved high expert concordance in blinded validations. Senior pathologists validated FEAT's outputs as comparable to those of human experts, with improved detection of subtle evidentiary nuances. To our knowledge, FEAT is the first LLM-based AI agent system dedicated to forensic medicine, offering scalable, consistent death certification while maintaining expert-level rigor. By integrating AI efficiency with human oversight, this work could advance equitable access to reliable medicolegal services while addressing critical capacity constraints in forensic systems.", 'abstract_zh': 'Forensic 死因鉴定面临系统性挑战，包括人手短缺和诊断变异，特别是在中国的医疗法医学基础设施这类高工作量系统中。我们引入了FEAT（法医代理）多智能体AI框架，通过领域适配的大语言模型实现死亡调查的自动化和标准化。FEAT的应用架构集成了：（i）中心规划器进行任务分解，（ii）专门的地方求解器进行证据分析，（iii）记忆与反思模块进行迭代细化，以及（iv）全局求解器进行结论合成。该系统采用工具增强推理、分层检索增强生成、法医学调整的大语言模型以及人类在环反馈，以确保法律和医学的有效性。在针对多样的中国案例群体的评估中，FEAT在长形式尸检分析和简要死因结论方面都超过了最先进的AI系统。它展示了在六大地理区域中的稳健泛化能力，并在盲验证中获得了高水平的专家一致意见。资深病理学家验证FEAT的输出与人类专家的输出相当，并且在检测微妙的证据细微之处方面表现出改进。据我们所知，FEAT是第一个专注于法医学的大语言模型基AI代理系统，提供可扩展且一致的死亡证明，同时保持专家级的严谨性。通过将AI效率与人类监督相结合，这项工作可能促进公平获取可靠的医疗法医学服务，同时解决法医学系统中关键的容量约束。', 'title_zh': 'FEAT：一种针对死亡原因自动化分析的领域适配多\n用户\n深度强化学习在库存管理中的应用研究'}
{'arxiv_id': 'arXiv:2508.07941', 'title': 'Deep Reinforcement Learning with anticipatory reward in LSTM for Collision Avoidance of Mobile Robots', 'authors': 'Olivier Poulet, Frédéric Guinand, François Guérin', 'link': 'https://arxiv.org/abs/2508.07941', 'abstract': 'This article proposes a collision risk anticipation method based on short-term prediction of the agents position. A Long Short-Term Memory (LSTM) model, trained on past trajectories, is used to estimate the next position of each robot. This prediction allows us to define an anticipated collision risk by dynamically modulating the reward of a Deep Q-Learning Network (DQN) agent. The approach is tested in a constrained environment, where two robots move without communication or identifiers. Despite a limited sampling frequency (1 Hz), the results show a significant decrease of the collisions number and a stability improvement. The proposed method, which is computationally inexpensive, appears particularly attractive for implementation on embedded systems.', 'abstract_zh': '基于代理短期位置预测的碰撞风险预判方法', 'title_zh': '基于循环神经网络的前瞻奖励深度强化学习在移动机器人防碰撞中的应用'}
{'arxiv_id': 'arXiv:2508.07932', 'title': '\\(X\\)-evolve: Solution space evolution powered by large language models', 'authors': 'Yi Zhai, Zhiqiang Wei, Ruohan Li, Keyu Pan, Shuo Liu, Lu Zhang, Jianmin Ji, Wuyang Zhang, Yu Zhang, Yanyong Zhang', 'link': 'https://arxiv.org/abs/2508.07932', 'abstract': "While combining large language models (LLMs) with evolutionary algorithms (EAs) shows promise for solving complex optimization problems, current approaches typically evolve individual solutions, often incurring high LLM call costs. We introduce \\(X\\)-evolve, a paradigm-shifting method that instead evolves solution spaces \\(X\\) (sets of individual solutions) - subsets of the overall search space \\(S\\). In \\(X\\)-evolve, LLMs generate tunable programs wherein certain code snippets, designated as parameters, define a tunable solution space. A score-based search algorithm then efficiently explores this parametrically defined space, guided by feedback from objective function scores. This strategy enables broader and more efficient exploration, which can potentially accelerate convergence at a much lower search cost, requiring up to two orders of magnitude fewer LLM calls than prior leading methods. We demonstrate \\(X\\)-evolve's efficacy across three distinct hard optimization problems. For the cap set problem, we discover a larger partial admissible set, establishing a new tighter asymptotic lower bound for the cap set constant (\\(C \\ge 2.2203\\)). In information theory, we uncover a larger independent set for the 15-vertex cycle graph (\\(\\mathcal{C}_{15}^{\\boxtimes 5}\\), size 19,946), thereby raising the known lower bound on its Shannon capacity. Furthermore, for the NP-hard online bin packing problem, we generate heuristics that consistently outperform standard strategies across established benchmarks. By evolving solution spaces, our method considerably improves search effectiveness, making it possible to tackle high-dimensional problems that were previously computationally prohibitive.", 'abstract_zh': '结合大型语言模型和进化算法求解复杂优化问题的新范式：X-进化算法', 'title_zh': 'X-演化：由大型语言模型驱动的解空间演化'}
{'arxiv_id': 'arXiv:2508.07834', 'title': 'KIRETT: Knowledge-Graph-Based Smart Treatment Assistant for Intelligent Rescue Operations', 'authors': 'Mubaris Nadeem, Johannes Zenkert, Lisa Bender, Christian Weber, Madjid Fathi', 'link': 'https://arxiv.org/abs/2508.07834', 'abstract': 'Over the years, the need for rescue operations throughout the world has increased rapidly. Demographic changes and the resulting risk of injury or health disorders form the basis for emergency calls. In such scenarios, first responders are in a rush to reach the patient in need, provide first aid, and save lives. In these situations, they must be able to provide personalized and optimized healthcare in the shortest possible time and estimate the patients condition with the help of freshly recorded vital data in an emergency situation. However, in such a timedependent situation, first responders and medical experts cannot fully grasp their knowledge and need assistance and recommendation for further medical treatments. To achieve this, on the spot calculated, evaluated, and processed knowledge must be made available to improve treatments by first responders. The Knowledge Graph presented in this article as a central knowledge representation provides first responders with an innovative knowledge management that enables intelligent treatment recommendations with an artificial intelligence-based pre-recognition of the situation.', 'abstract_zh': '近年来，全球救援操作的需求迅速增加。人口变化及其导致的受伤或健康问题的风险构成了紧急呼叫的基础。在这种情况下，救援人员需尽快赶到患者所在位置，提供初步救助并挽救生命。在这种情况下，他们必须能够在最短的时间内提供个性化和优化的医疗服务，并利用紧急情况下最新收集的生命体征数据来估计患者状况。然而，在这种时间依赖的情况下，救援人员和医疗专家无法充分利用他们的知识，需要获得进一步医疗治疗的协助和建议。为实现这一目标，本文介绍的知识图谱作为一种中心知识表示，为救援人员提供了创新的知识管理，使他们在基于人工智能的前期情况识别基础上获得智能治疗建议。', 'title_zh': '基于知识图谱的智能救援操作智能治疗助手'}
{'arxiv_id': 'arXiv:2508.07790', 'title': 'Best-Effort Policies for Robust Markov Decision Processes', 'authors': 'Alessandro Abate, Thom Badings, Giuseppe De Giacomo, Francesco Fabiano', 'link': 'https://arxiv.org/abs/2508.07790', 'abstract': 'We study the common generalization of Markov decision processes (MDPs) with sets of transition probabilities, known as robust MDPs (RMDPs). A standard goal in RMDPs is to compute a policy that maximizes the expected return under an adversarial choice of the transition probabilities. If the uncertainty in the probabilities is independent between the states, known as s-rectangularity, such optimal robust policies can be computed efficiently using robust value iteration. However, there might still be multiple optimal robust policies, which, while equivalent with respect to the worst-case, reflect different expected returns under non-adversarial choices of the transition probabilities. Hence, we propose a refined policy selection criterion for RMDPs, drawing inspiration from the notions of dominance and best-effort in game theory. Instead of seeking a policy that only maximizes the worst-case expected return, we additionally require the policy to achieve a maximal expected return under different (i.e., not fully adversarial) transition probabilities. We call such a policy an optimal robust best-effort (ORBE) policy. We prove that ORBE policies always exist, characterize their structure, and present an algorithm to compute them with a small overhead compared to standard robust value iteration. ORBE policies offer a principled tie-breaker among optimal robust policies. Numerical experiments show the feasibility of our approach.', 'abstract_zh': '我们研究带有转换概率集合的马尔可夫决策过程（MDPs）的通用化，称为鲁棒MDPs（RMDPs）。在RMDPs中，一个标准目标是计算在对手选择转换概率的情况下，能够最大化期望回报的策略。如果概率的不确定性在状态下是独立的，即s-矩形性，那么这样的最优鲁棒策略可以使用鲁棒值迭代高效地计算出来。然而，可能存在多个最优鲁棒策略，虽然从最坏情况来看是等价的，但在非对手选择的转换概率下，它们可能具有不同的期望回报。因此，我们提出了一种针对RMDPs的细化策略选择标准，借鉴了博弈论中的支配和尽力而为的概念。我们不仅仅寻求最大化最坏情况期望回报的策略，还要求该策略能够在不同的（即，非完全对手的）转换概率下实现最大期望回报。我们称这样的策略为最优鲁棒尽力而为（ORBE）策略。我们证明了ORBE策略总是存在的，刻画了它们的结构，并提出了一种与标准鲁棒值迭代相比具有较小开销的算法来计算它们。ORBE策略为最优鲁棒策略之间提供了一个原则性的决定标准。数值实验展示了我们方法的可行性。', 'title_zh': '最佳努力策略对于稳健的马尔可夫决策过程'}
{'arxiv_id': 'arXiv:2508.07743', 'title': 'Symmetry-Aware Transformer Training for Automated Planning', 'authors': 'Markus Fritzsche, Elliot Gestrin, Jendrik Seipp', 'link': 'https://arxiv.org/abs/2508.07743', 'abstract': 'While transformers excel in many settings, their application in the field of automated planning is limited. Prior work like PlanGPT, a state-of-the-art decoder-only transformer, struggles with extrapolation from easy to hard planning problems. This in turn stems from problem symmetries: planning tasks can be represented with arbitrary variable names that carry no meaning beyond being identifiers. This causes a combinatorial explosion of equivalent representations that pure transformers cannot efficiently learn from. We propose a novel contrastive learning objective to make transformers symmetry-aware and thereby compensate for their lack of inductive bias. Combining this with architectural improvements, we show that transformers can be efficiently trained for either plan-generation or heuristic-prediction. Our results across multiple planning domains demonstrate that our symmetry-aware training effectively and efficiently addresses the limitations of PlanGPT.', 'abstract_zh': '虽然变压器在许多场合表现出色，但在自动化规划领域的应用却有限。类似PlanGPT这样的最先进的仅解码器变压器在其从简单规划问题到困难规划问题的外推方面表现不佳。这归因于问题对称性：规划任务可以用任意变量名表示，这些变量名仅作为标识符携带意义，这导致了等价表示的组合爆炸，纯变压器无法有效学习。我们提出了一种新颖的对比学习目标，使变压器能够意识到对称性，从而补偿其归纳偏置不足的问题。结合架构改进，我们展示了变压器可以有效地训练用于规划生成或启发式预测。我们在多个规划领域的结果证明，我们的对称性意识训练有效地且高效地解决了PlanGPT的局限性。', 'title_zh': '面向自动规划的对称性意识变换器训练'}
{'arxiv_id': 'arXiv:2508.07673', 'title': 'Ethics2vec: aligning automatic agents and human preferences', 'authors': 'Gianluca Bontempi', 'link': 'https://arxiv.org/abs/2508.07673', 'abstract': 'Though intelligent agents are supposed to improve human experience (or make it more efficient), it is hard from a human perspective to grasp the ethical values which are explicitly or implicitly embedded in an agent behaviour. This is the well-known problem of alignment, which refers to the challenge of designing AI systems that align with human values, goals and preferences. This problem is particularly challenging since most human ethical considerations refer to \\emph{incommensurable} (i.e. non-measurable and/or incomparable) values and criteria. Consider, for instance, a medical agent prescribing a treatment to a cancerous patient. How could it take into account (and/or weigh) incommensurable aspects like the value of a human life and the cost of the treatment? Now, the alignment between human and artificial values is possible only if we define a common space where a metric can be defined and used. This paper proposes to extend to ethics the conventional Anything2vec approach, which has been successful in plenty of similar and hard-to-quantify domains (ranging from natural language processing to recommendation systems and graph analysis). This paper proposes a way to map an automatic agent decision-making (or control law) strategy to a multivariate vector representation, which can be used to compare and assess the alignment with human values. The Ethics2Vec method is first introduced in the case of an automatic agent performing binary decision-making. Then, a vectorisation of an automatic control law (like in the case of a self-driving car) is discussed to show how the approach can be extended to automatic control settings.', 'abstract_zh': '尽管智能代理被期望改善人类体验（或使其更高效），从人类的角度来说，理解嵌入在其行为中的显式或隐含的伦理价值观是困难的。这就是著名的对齐问题，指的是设计与人类价值观、目标和偏好相一致的AI系统的挑战。由于大多数人类伦理考量涉及不可通约的价值和标准（即无法衡量和/或不可比较），这一问题尤其具有挑战性。例如，考虑一个为癌症患者开药的医疗代理。它如何考虑到（或权衡）人类生命的价值与治疗成本这样的不可通约方面？只有在定义了一个公共空间并在其中可以定义和使用度量的情况下，人类和人工价值观之间的对齐才有可能。本文提议将传统的Anything2vec方法扩展到伦理领域，该方法已在许多类似且难以量化（从自然语言处理到推荐系统和图分析）的领域中取得了成功。本文提出了一种方法，将自动代理决策（或控制律）策略映射到多变量向量表示，该表示可用于比较和评估与人类价值观的一致性。道德2Vec方法首先在自动代理进行二元决策的情况下引入。然后讨论了自动控制律的矢量化（如自动驾驶汽车的情况），以展示该方法如何扩展到自动控制应用中。', 'title_zh': 'Ethics2vec: 将自动代理与人类偏好对齐'}
{'arxiv_id': 'arXiv:2508.07671', 'title': 'EMPATHIA: Multi-Faceted Human-AI Collaboration for Refugee Integration', 'authors': 'Mohamed Rayan Barhdadi, Mehmet Tuncel, Erchin Serpedin, Hasan Kurban', 'link': 'https://arxiv.org/abs/2508.07671', 'abstract': "Current AI approaches to refugee integration optimize narrow objectives such as employment and fail to capture the cultural, emotional, and ethical dimensions critical for long-term success. We introduce EMPATHIA (Enriched Multimodal Pathways for Agentic Thinking in Humanitarian Immigrant Assistance), a multi-agent framework addressing the central Creative AI question: how do we preserve human dignity when machines participate in life-altering decisions? Grounded in Kegan's Constructive Developmental Theory, EMPATHIA decomposes integration into three modules: SEED (Socio-cultural Entry and Embedding Decision) for initial placement, RISE (Rapid Integration and Self-sufficiency Engine) for early independence, and THRIVE (Transcultural Harmony and Resilience through Integrated Values and Engagement) for sustained outcomes. SEED employs a selector-validator architecture with three specialized agents - emotional, cultural, and ethical - that deliberate transparently to produce interpretable recommendations. Experiments on the UN Kakuma dataset (15,026 individuals, 7,960 eligible adults 15+ per ILO/UNHCR standards) and implementation on 6,359 working-age refugees (15+) with 150+ socioeconomic variables achieved 87.4% validation convergence and explainable assessments across five host countries. EMPATHIA's weighted integration of cultural, emotional, and ethical factors balances competing value systems while supporting practitioner-AI collaboration. By augmenting rather than replacing human expertise, EMPATHIA provides a generalizable framework for AI-driven allocation tasks where multiple values must be reconciled.", 'abstract_zh': 'Empathia：整合文化、情感和伦理维度的人道主义移民援助多代理框架', 'title_zh': 'EMPATHIA：多维度的人工智能辅助难民融入合作'}
{'arxiv_id': 'arXiv:2508.07667', 'title': '1-2-3 Check: Enhancing Contextual Privacy in LLM via Multi-Agent Reasoning', 'authors': 'Wenkai Li, Liwen Sun, Zhenxiang Guan, Xuhui Zhou, Maarten Sap', 'link': 'https://arxiv.org/abs/2508.07667', 'abstract': 'Addressing contextual privacy concerns remains challenging in interactive settings where large language models (LLMs) process information from multiple sources (e.g., summarizing meetings with private and public information). We introduce a multi-agent framework that decomposes privacy reasoning into specialized subtasks (extraction, classification), reducing the information load on any single agent while enabling iterative validation and more reliable adherence to contextual privacy norms. To understand how privacy errors emerge and propagate, we conduct a systematic ablation over information-flow topologies, revealing when and why upstream detection mistakes cascade into downstream leakage. Experiments on the ConfAIde and PrivacyLens benchmark with several open-source and closed-sourced LLMs demonstrate that our best multi-agent configuration substantially reduces private information leakage (\\textbf{18\\%} on ConfAIde and \\textbf{19\\%} on PrivacyLens with GPT-4o) while preserving the fidelity of public content, outperforming single-agent baselines. These results highlight the promise of principled information-flow design in multi-agent systems for contextual privacy with LLMs.', 'abstract_zh': '在处理大型语言模型（LLMs）从多个来源（如总结包含私人和公共信息的会议）获取的信息时，解决上下文隐私问题仍然具有挑战性。我们介绍了一种多代理框架，将隐私推理分解为专门的子任务（提取、分类），从而减轻任何单一代理的信息负担，同时实现迭代验证并更可靠地遵守上下文隐私规范。为了理解隐私错误如何出现和传播，我们在信息流拓扑上进行了系统性剥离分析，揭示了上游检测错误何时以及为何会cascade到下游泄露。在ConfAIde和PrivacyLens基准测试上使用几个开源和封闭源LLM进行的实验表明，我们最优的多代理配置在ConfAIde上减少了18%的私人信息泄露，在PrivacyLens上减少了19%（使用GPT-4o），同时保持公共内容的保真度，优于单代理基线。这些结果突显了在LLM的上下文隐私中通过多代理系统进行有原则的信息流设计的潜力。', 'title_zh': '1-2-3 检查：通过多agent推理增强LLM中的情境隐私'}
{'arxiv_id': 'arXiv:2508.07649', 'title': 'Disentangling Multiplex Spatial-Temporal Transition Graph Representation Learning for Socially Enhanced POI Recommendation', 'authors': 'Jie Li, Haoye Dong, Zhengyang Wu, Zetao Zheng, Mingrong Lin', 'link': 'https://arxiv.org/abs/2508.07649', 'abstract': "Next Point-of-Interest (POI) recommendation is a research hotspot in business intelligence, where users' spatial-temporal transitions and social relationships play key roles. However, most existing works model spatial and temporal transitions separately, leading to misaligned representations of the same spatial-temporal key nodes. This misalignment introduces redundant information during fusion, increasing model uncertainty and reducing interpretability. To address this issue, we propose DiMuST, a socially enhanced POI recommendation model based on disentangled representation learning over multiplex spatial-temporal transition graphs. The model employs a novel Disentangled variational multiplex graph Auto-Encoder (DAE), which first disentangles shared and private distributions using a multiplex spatial-temporal graph strategy. It then fuses the shared features via a Product of Experts (PoE) mechanism and denoises the private features through contrastive constraints. The model effectively captures the spatial-temporal transition representations of POIs while preserving the intrinsic correlation of their spatial-temporal relationships. Experiments on two challenging datasets demonstrate that our DiMuST significantly outperforms existing methods across multiple metrics.", 'abstract_zh': '基于解耦表示 表征学习的多 夝复时空转移图上的社会增强 POI 推荐', 'title_zh': '多层时空转换图表示学习的解耦建模及其在社会增强POI推荐中的应用'}
{'arxiv_id': 'arXiv:2508.07642', 'title': 'Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents', 'authors': 'Tianyi Ma, Yue Zhang, Zehao Wang, Parisa Kordjamshidi', 'link': 'https://arxiv.org/abs/2508.07642', 'abstract': 'Vision-and-Language Navigation (VLN) poses significant challenges in enabling agents to interpret natural language instructions and navigate complex 3D environments. While recent progress has been driven by large-scale pre-training and data augmentation, current methods still struggle to generalize to unseen scenarios, particularly when complex spatial and temporal reasoning is required. In this work, we propose SkillNav, a modular framework that introduces structured, skill-based reasoning into Transformer-based VLN agents. Our method decomposes navigation into a set of interpretable atomic skills (e.g., Vertical Movement, Area and Region Identification, Stop and Pause), each handled by a specialized agent. We then introduce a novel zero-shot Vision-Language Model (VLM)-based router, which dynamically selects the most suitable agent at each time step by aligning sub-goals with visual observations and historical actions. SkillNav achieves a new state-of-the-art performance on the R2R benchmark and demonstrates strong generalization to the GSA-R2R benchmark that includes novel instruction styles and unseen environments.', 'abstract_zh': 'Vision-and-Language Navigation (VLN) 在使代理解读自然语言指令并在复杂3D环境中导航方面面临着显著挑战。尽管近期进展受益于大规模预训练和数据增强，现有方法在应对未见过的场景时仍然难以泛化，尤其是在需要复杂的空间和时间推理时。在本文中，我们提出了一种模块化框架——SkillNav，该框架将结构化、基于技能的推理引入到了基于Transformer的VLN代理中。我们的方法将导航分解为一组可解释的基本技能（如垂直移动、区域和区域识别、停留和暂停），每个技能由一个专门的代理处理。我们还引入了一种新颖的零样本视觉-语言模型（VLM）路由器，该路由器在每个时间步骤动态选择最合适的代理，通过将子目标与视觉观察和历史动作对齐来实现。SkillNav 在 R2R 基准上取得了新的最佳性能，并在包含新指令风格和未见过环境的GSA-R2R基准上展示了强大的泛化能力。', 'title_zh': '瓦解与重建：基于技能的视觉- 语言导航智能体的混合模型'}
{'arxiv_id': 'arXiv:2508.07628', 'title': 'Multimodal AI Systems for Enhanced Laying Hen Welfare Assessment and Productivity Optimization', 'authors': 'Daniel Essien, Suresh Neethirajan', 'link': 'https://arxiv.org/abs/2508.07628', 'abstract': 'The future of poultry production depends on a paradigm shift replacing subjective, labor-intensive welfare checks with data-driven, intelligent monitoring ecosystems. Traditional welfare assessments-limited by human observation and single-sensor data-cannot fully capture the complex, multidimensional nature of laying hen welfare in modern farms. Multimodal Artificial Intelligence (AI) offers a breakthrough, integrating visual, acoustic, environmental, and physiological data streams to reveal deeper insights into avian welfare dynamics. This investigation highlights multimodal As transformative potential, showing that intermediate (feature-level) fusion strategies achieve the best balance between robustness and performance under real-world poultry conditions, and offer greater scalability than early or late fusion approaches. Key adoption barriers include sensor fragility in harsh farm environments, high deployment costs, inconsistent behavioral definitions, and limited cross-farm generalizability. To address these, we introduce two novel evaluation tools - the Domain Transfer Score (DTS) to measure model adaptability across diverse farm settings, and the Data Reliability Index (DRI) to assess sensor data quality under operational constraints. We also propose a modular, context-aware deployment framework designed for laying hen environments, enabling scalable and practical integration of multimodal sensing. This work lays the foundation for a transition from reactive, unimodal monitoring to proactive, precision-driven welfare systems that unite productivity with ethical, science based animal care.', 'abstract_zh': '家禽生产的未来取决于从主观、劳动密集型的福利检查向数据驱动、智能化的监测生态系统转变。传统的福利评估受限于人类观察和单传感器数据，无法全面捕捉现代养殖场中产蛋鸡福利的复杂性和多维性。多模态人工智能（AI）提供了突破，通过整合视觉、声学、环境和生理数据流，揭示了更为深刻的家禽福利动态洞察。本研究强调了多模态系统的潜在转化能力，显示了在实际养禽条件下，中间（特征级）融合策略在鲁棒性和性能方面达到了最佳平衡，并且比早期或晚期融合方法更具可扩展性。关键采用障碍包括传感器在恶劣农场环境中的脆弱性、高昂的部署成本、不一致的行为定义以及有限的跨场普遍性。为解决这些问题，我们引入了两类新的评估工具——领域迁移得分（DTS）以衡量模型在不同农场环境中的一致适应性，以及数据可靠性指数（DRI）以评估受限操作条件下的传感器数据质量。我们还提出了一种模块化、情境感知的部署框架，适用于产蛋鸡环境，使得多模态感知的大规模和实践性整合成为可能。这项工作为从被动、单一模态监测向结合生产力与伦理、基于科学的精准福利系统转变奠定了基础。', 'title_zh': '多模态人工智能系统以增强产蛋鸡福利评估与生产优化'}
{'arxiv_id': 'arXiv:2508.07616', 'title': 'ThinkTuning: Instilling Cognitive Reflections without Distillation', 'authors': 'Aswin RRV, Jacob Dineen, Divij Handa, Md Nayem Uddin, Mihir Parmar, Chitta Baral, Ben Zhou', 'link': 'https://arxiv.org/abs/2508.07616', 'abstract': "Recent advances in test-time scaling have led to the emergence of thinking LLMs that exhibit self-reflective behaviors and multi-step reasoning. While RL drives this self-improvement paradigm, a recent study (Gandhi et al., 2025) shows that RL alone does not truly instill these new reasoning abilities - it merely draws out behaviors already present in the base models. This raises a question: How can we train the models that don't exhibit such thinking behavior to develop it in the first place? To this end, we propose ThinkTuning, a GRPO-based interactive training approach where we augment the rollouts of a student model with the guidance from a teacher model. A simple idea from classroom practice inspires our method: a teacher poses a problem, lets the student try an answer, then gives corrective feedback -- enough to point the mind in the right direction and then show the solution. Each piece of feedback reshapes the student's thoughts, leading them to arrive at the correct solution. Similarly, we find that this type of implicit supervision through feedback from a teacher model of the same size improves the reasoning capabilities of the student model. In particular, on average, our method shows a 3.85% improvement over zero-shot baselines across benchmarks, and on MATH-500, AIME and GPQA-Diamond it shows 2.08%, 2.23% and 3.99% improvements over the vanilla-GRPO baseline. Source code is available at this https URL.", 'abstract_zh': 'Recent Advances in Test-Time Scaling Have Led to the Emergence of Thinking LLMs Capable of Self-reflective Behaviors and Multi-step Reasoning: How Can We Train Models Lacking Such Behavior to Develop It? And What Is the Role of Teacher Models in Implicit Supervision through Feedback?', 'title_zh': 'ThinkTuning: 培养认知反思而不进行蒸馏'}
{'arxiv_id': 'arXiv:2508.07602', 'title': 'HGMF: A Hierarchical Gaussian Mixture Framework for Scalable Tool Invocation within the Model Context Protocol', 'authors': 'Wenpeng Xing, Zhipeng Chen, Changting Lin, Meng Han', 'link': 'https://arxiv.org/abs/2508.07602', 'abstract': "Invoking external tools enables Large Language Models (LLMs) to perform complex, real-world tasks, yet selecting the correct tool from large, hierarchically-structured libraries remains a significant challenge. The limited context windows of LLMs and noise from irrelevant options often lead to low selection accuracy and high computational costs. To address this, we propose the Hierarchical Gaussian Mixture Framework (HGMF), a probabilistic pruning method for scalable tool invocation. HGMF first maps the user query and all tool descriptions into a unified semantic space. The framework then operates in two stages: it clusters servers using a Gaussian Mixture Model (GMM) and filters them based on the query's likelihood. Subsequently, it applies the same GMM-based clustering and filtering to the tools associated with the selected servers. This hierarchical process produces a compact, high-relevance candidate set, simplifying the final selection task for the LLM. Experiments on a public dataset show that HGMF significantly improves tool selection accuracy while reducing inference latency, confirming the framework's scalability and effectiveness for large-scale tool libraries.", 'abstract_zh': '调用外部工具使大规模语言模型（LLMs）能够执行复杂的现实世界任务，但是从大型层次结构结构化的工具库中选择正确的工具仍然是一项重大挑战。由于LLMs的有限上下文窗口和无关选项带来的噪声，往往会导致选择准确性降低和高计算成本。为解决这一问题，我们提出了一种分层高斯混合框架（HGMF），这是一种用于可扩展工具调用的概率性剪枝方法。HGMF 首先将用户查询和所有工具描述映射到统一的语义空间。该框架随后分为两个阶段：使用高斯混合模型（GMM）对服务器进行聚类，并基于查询的可能性进行过滤。之后，它对选定服务器关联的工具应用相同的基于GMM的聚类和过滤。这种分层过程生成了一个紧凑且高相关的候选集，简化了LLM的最终选择任务。实验结果表明，HGMF 在提高工具选择准确性的同时降低了推理延迟，证实了框架在大规模工具库中的可扩展性和有效性。', 'title_zh': 'HGMF：一种用于模型上下文协议中可扩展工具调用的分层高斯混合框架'}
{'arxiv_id': 'arXiv:2508.07586', 'title': 'Optimization of Private Semantic Communication Performance: An Uncooperative Covert Communication Method', 'authors': 'Wenjing Zhang, Ye Hu, Tao Luo, Zhilong Zhang, Mingzhe Chen', 'link': 'https://arxiv.org/abs/2508.07586', 'abstract': 'In this paper, a novel covert semantic communication framework is investigated. Within this framework, a server extracts and transmits the semantic information, i.e., the meaning of image data, to a user over several time slots. An attacker seeks to detect and eavesdrop the semantic transmission to acquire details of the original image. To avoid data meaning being eavesdropped by an attacker, a friendly jammer is deployed to transmit jamming signals to interfere the attacker so as to hide the transmitted semantic information. Meanwhile, the server will strategically select time slots for semantic information transmission. Due to limited energy, the jammer will not communicate with the server and hence the server does not know the transmit power of the jammer. Therefore, the server must jointly optimize the semantic information transmitted at each time slot and the corresponding transmit power to maximize the privacy and the semantic information transmission quality of the user. To solve this problem, we propose a prioritised sampling assisted twin delayed deep deterministic policy gradient algorithm to jointly determine the transmitted semantic information and the transmit power per time slot without the communications between the server and the jammer. Compared to standard reinforcement learning methods, the propose method uses an additional Q network to estimate Q values such that the agent can select the action with a lower Q value from the two Q networks thus avoiding local optimal action selection and estimation bias of Q values. Simulation results show that the proposed algorithm can improve the privacy and the semantic information transmission quality by up to 77.8% and 14.3% compared to the traditional reinforcement learning methods.', 'abstract_zh': '一种新型隐蔽语义通信框架的研究：优先采样辅助孪生延迟确定性策略梯度算法在不通信情况下同时优化传输语义信息和功率', 'title_zh': '优化私人语义通信性能：一种不合作隐蔽通信方法'}
{'arxiv_id': 'arXiv:2508.07575', 'title': 'MCPToolBench++: A Large Scale AI Agent Model Context Protocol MCP Tool Use Benchmark', 'authors': 'Shiqing Fan, Xichen Ding, Liang Zhang, Linjian Mo', 'link': 'https://arxiv.org/abs/2508.07575', 'abstract': "LLMs' capabilities are enhanced by using function calls to integrate various data sources or API results into the context window. Typical tools include search, web crawlers, maps, financial data, file systems, and browser usage, etc. Integrating these data sources or functions requires a standardized method. The Model Context Protocol (MCP) provides a standardized way to supply context to LLMs. However, the evaluation of LLMs and AI Agents' MCP tool use abilities suffer from several issues. First, there's a lack of comprehensive datasets or benchmarks to evaluate various MCP tools. Second, the diverse formats of response from MCP tool call execution further increase the difficulty of evaluation. Additionally, unlike existing tool-use benchmarks with high success rates in functions like programming and math functions, the success rate of real-world MCP tool is not guaranteed and varies across different MCP servers. Furthermore, the LLMs' context window also limits the number of available tools that can be called in a single run, because the textual descriptions of tool and the parameters have long token length for an LLM to process all at once. To help address the challenges of evaluating LLMs' performance on calling MCP tools, we propose MCPToolBench++, a large-scale, multi-domain AI Agent tool use benchmark. As of July 2025, this benchmark is build upon marketplace of over 4k MCP servers from more than 40 categories, collected from the MCP marketplaces and GitHub communities. The datasets consist of both single-step and multi-step tool calls across different categories. We evaluated SOTA LLMs with agentic abilities on this benchmark and reported the results.", 'abstract_zh': 'LLMs性能调用MCP工具的大规模多领域AI代理工具使用基准：MCPToolBench++', 'title_zh': 'MCPToolBench++: 一种大规模AI代理模型上下文协议MCP工具使用基准'}
{'arxiv_id': 'arXiv:2508.07485', 'title': 'Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy', 'authors': 'Alexander Duffy, Samuel J Paech, Ishana Shastri, Elizabeth Karpinski, Baptiste Alloui-Cros, Tyler Marques, Matthew Lyle Olson', 'link': 'https://arxiv.org/abs/2508.07485', 'abstract': "We present the first evaluation harness that enables any out-of-the-box, local, Large Language Models (LLMs) to play full-press Diplomacy without fine-tuning or specialized training. Previous work required frontier LLMs, or fine-tuning, due to the high complexity and information density of Diplomacy's game state. Combined with the high variance of matches, these factors made Diplomacy prohibitive for study. In this work, we used data-driven iteration to optimize a textual game state representation such that a 24B model can reliably complete matches without any fine tuning. We develop tooling to facilitate hypothesis testing and statistical analysis, and we present case studies on persuasion, aggressive playstyles, and performance across a range of models. We conduct a variety of experiments across many popular LLMs, finding the larger models perform the best, but the smaller models still play adequately. We also introduce Critical State Analysis: an experimental protocol for rapidly iterating and analyzing key moments in a game at depth. Our harness democratizes the evaluation of strategic reasoning in LLMs by eliminating the need for fine-tuning, and it provides insights into how these capabilities emerge naturally from widely used LLMs. Our code is available in the supplement and will be open sourced.", 'abstract_zh': '我们提出了首个评估框架，使得任何现成的本地大规模语言模型（LLMs）能够在不进行微调或专门训练的情况下参与完整版的Diplomacy游戏。之前的研究所需的前沿LLMs或微调，都是由于Diplomacy游戏状态的高复杂性和信息密度。结合比赛结果的高变异性，这些因素使得Diplomacy成为研究的障碍。在本研究中，我们通过数据驱动的方法优化了文本游戏状态表示，使得一个24B参数的模型能够在无需任何微调的情况下可靠地完成比赛。我们开发了工具以促进假设测试和统计分析，并展示了说服力、侵略性玩法以及不同模型的性能案例研究。我们在多个流行的LLMs上进行了各种实验，发现较大的模型表现最佳，但较小的模型仍然能够胜任。我们还引入了关键状态分析：一种用于快速迭代和深入分析游戏中关键时刻的实验协议。该评估框架通过消除微调的需要，使战略推理的评估民主化，并提供了这些能力如何自然地从广泛使用的LLMs中涌现的见解。我们的代码已作为补充材料提供，并将开源。', 'title_zh': '民主化外交：评价全量 pressure\nuser\n把下面的论文标题翻译 成成符合学术规范的中文标题：Political polarization and party allocation in Chinese local-fiscal social welfare programs'}
{'arxiv_id': 'arXiv:2508.07468', 'title': 'CP-Agent: Agentic Constraint Programming', 'authors': 'Stefan Szeider', 'link': 'https://arxiv.org/abs/2508.07468', 'abstract': 'Translating natural language problem descriptions into formal constraint models remains a fundamental challenge in constraint programming, requiring deep expertise in both the problem domain and modeling frameworks. Previous approaches to automating this translation have employed fixed workflows with predetermined modeling steps, failing on a significant number of benchmark problems. We present a new approach using a pure agentic strategy without any fixed pipeline. We developed a general-purpose Python coding agent based on the ReAct (Reason and Act) principle, utilizing a persistent IPython kernel for stateful code execution and iterative development. Rather than embedding constraint programming logic into the agent architecture, domain-specific expertise is injected solely through a carefully crafted project prompt. The agent combines this prompt-encoded knowledge with access to file operations and code execution tools, enabling it to test hypotheses, debug failures, and verify solutions dynamically. Implemented in just a few hundred lines of code, this architecture successfully solves all 101 problems of the CP-Bench constraint programming benchmark set. The results suggest that constraint modeling tasks require the combination of general coding tools and domain expertise encoded in prompts, rather than specialized agent architectures or predefined workflows.', 'abstract_zh': '将自然语言问题描述转换为正式约束模型仍是约束编程中的一个基本挑战，需要在问题领域和建模框架两方面具备深厚的专长。先前自动化这一转换的方法采用固定的工作流和预定义的建模步骤，在许多基准问题上失败。我们提出了一种新的方法，采用纯粹的代理策略，没有任何固定的流水线。我们基于ReAct（Reason and Act）原则开发了一个通用的Python编码代理，利用持久的IPython内核进行有状态代码执行和迭代开发。代理不将约束编程逻辑嵌入其架构中，而是仅通过精细构建的项目提示注入领域特定的专长。代理将提示编码的知识与文件操作和代码执行工具的访问相结合，能够动态地验证假设、调试失败和验证解决方案。该架构仅用数百行代码成功解决了CP-Bench约束编程基准集中的所有101个问题。结果表明，约束建模任务需要通用编程工具和编码在提示中的领域专长的结合，而非专门的代理架构或预定义的工作流。', 'title_zh': 'abyte-Agent: 代理约束编程'}
{'arxiv_id': 'arXiv:2508.07466', 'title': 'Grounding Natural Language for Multi-agent Decision-Making with Multi-agentic LLMs', 'authors': 'Dom Huh, Prasant Mohapatra', 'link': 'https://arxiv.org/abs/2508.07466', 'abstract': 'Language is a ubiquitous tool that is foundational to reasoning and collaboration, ranging from everyday interactions to sophisticated problem-solving tasks. The establishment of a common language can serve as a powerful asset in ensuring clear communication and understanding amongst agents, facilitating desired coordination and strategies. In this work, we extend the capabilities of large language models (LLMs) by integrating them with advancements in multi-agent decision-making algorithms. We propose a systematic framework for the design of multi-agentic large language models (LLMs), focusing on key integration practices. These include advanced prompt engineering techniques, the development of effective memory architectures, multi-modal information processing, and alignment strategies through fine-tuning algorithms. We evaluate these design choices through extensive ablation studies on classic game settings with significant underlying social dilemmas and game-theoretic considerations.', 'abstract_zh': '语言是一种无处不在的工具，是推理和协作的基础，从日常交流到复杂问题解决任务均有涉及。建立一种共同语言可以作为确保各智能体之间清晰沟通和理解的强大资产，促进所需的合作与策略。在本工作中，我们通过将大型语言模型（LLMs）与多智能体决策算法的进步相结合，扩展了LLMs的能力。我们提出了一种系统性的框架，用于设计多智能体大型语言模型（LLMs），重点关注关键集成实践，包括高级提示工程技术、有效的记忆架构开发、多模态信息处理以及通过微调算法实现的对齐策略。我们通过对具有显著社会困境和博弈论考量的经典游戏设置进行广泛的消融研究来评估这些设计选择。', 'title_zh': '多智能体LLMs赋能多智能体决策中的自然语言 grounding'}
{'arxiv_id': 'arXiv:2508.07407', 'title': 'A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems', 'authors': 'Jinyuan Fang, Yanwen Peng, Xi Zhang, Yingxu Wang, Xinhao Yi, Guibin Zhang, Yi Xu, Bin Wu, Siwei Liu, Zihao Li, Zhaochun Ren, Nikos Aletras, Xi Wang, Han Zhou, Zaiqiao Meng', 'link': 'https://arxiv.org/abs/2508.07407', 'abstract': 'Recent advances in large language models have sparked growing interest in AI agents capable of solving complex, real-world tasks. However, most existing agent systems rely on manually crafted configurations that remain static after deployment, limiting their ability to adapt to dynamic and evolving environments. To this end, recent research has explored agent evolution techniques that aim to automatically enhance agent systems based on interaction data and environmental feedback. This emerging direction lays the foundation for self-evolving AI agents, which bridge the static capabilities of foundation models with the continuous adaptability required by lifelong agentic systems. In this survey, we provide a comprehensive review of existing techniques for self-evolving agentic systems. Specifically, we first introduce a unified conceptual framework that abstracts the feedback loop underlying the design of self-evolving agentic systems. The framework highlights four key components: System Inputs, Agent System, Environment, and Optimisers, serving as a foundation for understanding and comparing different strategies. Based on this framework, we systematically review a wide range of self-evolving techniques that target different components of the agent system. We also investigate domain-specific evolution strategies developed for specialised fields such as biomedicine, programming, and finance, where optimisation objectives are tightly coupled with domain constraints. In addition, we provide a dedicated discussion on the evaluation, safety, and ethical considerations for self-evolving agentic systems, which are critical to ensuring their effectiveness and reliability. This survey aims to provide researchers and practitioners with a systematic understanding of self-evolving AI agents, laying the foundation for the development of more adaptive, autonomous, and lifelong agentic systems.', 'abstract_zh': 'recent advances in large language models have sparked growing interest in AI agents capable of solving complex, real-world tasks.然而，现有的大多数代理系统依赖于手动构建的配置，这些配置在部署后保持静态，限制了它们适应动态和 evolving 环境的能力。为此，近期的研究探索了基于交互数据和环境反馈自动提升代理系统的技术。这一新兴方向为自进化的AI代理系统奠定了基础，这些系统结合了基础模型的静态能力与终身代理系统所需的持续适应能力。在本文综述中，我们提供了一种全面的自我进化的代理系统技术的回顾。具体地，我们首先介绍了一个统一的概念框架，该框架抽象出自我进化的代理系统设计背后的反馈循环。该框架强调了四个关键组成部分：系统输入、代理系统、环境和优化器，作为理解并比较不同策略的基础。在此基础上，我们系统地回顾了旨在代理系统不同组成部分的广泛自我进化技术。我们也探讨了为生物医学、编程和金融等特定领域开发的优化策略，其中优化目标与领域约束紧密相关。此外，我们还专门讨论了自我进化的代理系统在评估、安全性和伦理方面的考虑，这些是确保其有效性和可靠性的关键因素。本文综述旨在为研究人员和实践者提供系统理解自我进化的AI代理的基础，为开发更适应、自主并终身的代理系统奠定基础。', 'title_zh': '全面综述自进化AI代理：一种连接基础模型与终身代理系统的新型范式'}
{'arxiv_id': 'arXiv:2508.07405', 'title': 'Generative AI for Strategic Plan Development', 'authors': 'Jesse Ponnock', 'link': 'https://arxiv.org/abs/2508.07405', 'abstract': 'Given recent breakthroughs in Generative Artificial Intelligence (GAI) and Large Language Models (LLMs), more and more professional services are being augmented through Artificial Intelligence (AI), which once seemed impossible to automate. This paper presents a modular model for leveraging GAI in developing strategic plans for large scale government organizations and evaluates leading machine learning techniques in their application towards one of the identified modules. Specifically, the performance of BERTopic and Non-negative Matrix Factorization (NMF) are evaluated in their ability to use topic modeling to generate themes representative of Vision Elements within a strategic plan. To accomplish this, BERTopic and NMF models are trained using a large volume of reports from the Government Accountability Office (GAO). The generated topics from each model are then scored for similarity against the Vision Elements of a published strategic plan and the results are compared. Our results show that these techniques are capable of generating themes similar to 100% of the elements being evaluated against. Further, we conclude that BERTopic performs best in this application with more than half of its correlated topics achieving a "medium" or "strong" correlation. A capability of GAI-enabled strategic plan development impacts a multi-billion dollar industry and assists the federal government in overcoming regulatory requirements which are crucial to the public good. Further work will focus on the operationalization of the concept proven in this study as well as viability of the remaining modules in the proposed model for GAI-generated strategic plans.', 'abstract_zh': '基于生成式人工智能和大型语言模型的突破，越来越多的专业服务通过人工智能得到了增强，这在过去看来是无法自动化的。本文提出了一种模块化模型，用于利用生成式人工智能为大型政府组织制定战略计划，并评估了领先机器学习技术在其中一个识别模块中的应用。具体而言，本文评估了BERTopic和非负矩阵分解(NMF)在这项应用中的表现，特に它们利用主题建模生成反映战略计划中愿景元素的主题的能力。为了实现这一目标，BERTopic和NMF模型使用政府问责办公室(GAO)的大量报告进行了训练。然后，从每个模型生成的主题分别与公布的战略计划中的愿景元素进行相似性评分，并对结果进行比较。我们的结果显示，这些技术能够在评估的100%的元素中生成相似的主题。此外，我们得出结论，BERTopic在这种应用中表现最佳，超过一半相关主题达到“中等”或“较强”的相关性。生成式人工智能支持的战略计划开发能力影响了一个多十亿美元的行业，并帮助联邦政府克服对公共利益至关重要的监管要求。进一步的工作将集中在本研究中证明的概念的实施以及剩余模块在提议的基于生成式人工智能的战略计划模型中的可行性上。', 'title_zh': '战略性计划开发中的生成型人工智能'}
{'arxiv_id': 'arXiv:2508.07388', 'title': 'Invert4TVG: A Temporal Video Grounding Framework with Inversion Tasks for Enhanced Action Understanding', 'authors': 'Zhaoyu Chen, Hongnan Lin, Yongwei Nie, Fei Ma, Xuemiao Xu, Fei Yu, Chengjiang Long', 'link': 'https://arxiv.org/abs/2508.07388', 'abstract': 'Temporal Video Grounding (TVG) seeks to localize video segments matching a given textual query. Current methods, while optimizing for high temporal Intersection-over-Union (IoU), often overfit to this metric, compromising semantic action understanding in the video and query, a critical factor for robust TVG. To address this, we introduce Inversion Tasks for TVG (Invert4TVG), a novel framework that enhances both localization accuracy and action understanding without additional data. Our approach leverages three inversion tasks derived from existing TVG annotations: (1) Verb Completion, predicting masked action verbs in queries from video segments; (2) Action Recognition, identifying query-described actions; and (3) Video Description, generating descriptions of video segments that explicitly embed query-relevant actions. These tasks, integrated with TVG via a reinforcement learning framework with well-designed reward functions, ensure balanced optimization of localization and semantics. Experiments show our method outperforms state-of-the-art approaches, achieving a 7.1\\% improvement in R1@0.7 on Charades-STA for a 3B model compared to Time-R1. By inverting TVG to derive query-related actions from segments, our approach strengthens semantic understanding, significantly raising the ceiling of localization accuracy.', 'abstract_zh': 'Temporal Video Grounding (TVG)通过引入Inversion Tasks for TVG (Invert4TVG)框架，增强局部化准确性和动作理解，无需额外数据。', 'title_zh': 'Invert4TVG：一种通过反转任务增强动作理解的时空视频定位框架'}
{'arxiv_id': 'arXiv:2508.07382', 'title': 'Pentest-R1: Towards Autonomous Penetration Testing Reasoning Optimized via Two-Stage Reinforcement Learning', 'authors': 'He Kong, Die Hu, Jingguo Ge, Liangxiong Li, Hui Li, Tong Li', 'link': 'https://arxiv.org/abs/2508.07382', 'abstract': "Automating penetration testing is crucial for enhancing cybersecurity, yet current Large Language Models (LLMs) face significant limitations in this domain, including poor error handling, inefficient reasoning, and an inability to perform complex end-to-end tasks autonomously. To address these challenges, we introduce Pentest-R1, a novel framework designed to optimize LLM reasoning capabilities for this task through a two-stage reinforcement learning pipeline. We first construct a dataset of over 500 real-world, multi-step walkthroughs, which Pentest-R1 leverages for offline reinforcement learning (RL) to instill foundational attack logic. Subsequently, the LLM is fine-tuned via online RL in an interactive Capture The Flag (CTF) environment, where it learns directly from environmental feedback to develop robust error self-correction and adaptive strategies. Our extensive experiments on the Cybench and AutoPenBench benchmarks demonstrate the framework's effectiveness. On AutoPenBench, Pentest-R1 achieves a 24.2\\% success rate, surpassing most state-of-the-art models and ranking second only to Gemini 2.5 Flash. On Cybench, it attains a 15.0\\% success rate in unguided tasks, establishing a new state-of-the-art for open-source LLMs and matching the performance of top proprietary models. Ablation studies confirm that the synergy of both training stages is critical to its success.", 'abstract_zh': '自动化渗透测试对于提升网络安全至关重要，然而当前的大规模语言模型（LLMs）在这一领域面临显著限制，包括较差的错误处理能力、低效的推理能力和无法自主完成复杂的端到端任务。为应对这些挑战，我们提出了Pentest-R1，一种新型框架，通过两阶段强化学习管道优化LLM的推理能力。我们首先构建了一个包含超过500个真实世界多步骤指南的数据集，Pentest-R1利用该数据集进行离线强化学习（RL），以植入基础攻击逻辑。随后，LLM通过在线RL在互动的夺旗（CTF）环境中进行微调，直接从环境反馈中学习，以开发出强大的错误自我纠正能力和适应性策略。在Cybench和AutoPenBench基准测试中的广泛实验展示了该框架的有效性。在AutoPenBench上，Pentest-R1达到24.2%的成功率，超过大多数最先进的模型，并仅仅次于Gemini 2.5 Flash。在Cybench上，它在未指导任务中的成功率为15.0%，为开源LLM设立了新的最先进的标准，并达到顶级专有模型的性能。消融研究证实了两个训练阶段协同作用的重要性。', 'title_zh': 'Pentest-R1: 向往基于两阶段强化学习优化的自主渗透测试推理'}
{'arxiv_id': 'arXiv:2508.07353', 'title': 'Rethinking Domain-Specific LLM Benchmark Construction: A Comprehensiveness-Compactness Approach', 'authors': 'Rubing Chen, Jiaxin Wu, Jian Wang, Xulu Zhang, Wenqi Fan, Chenghua Lin, Xiao-Yong Wei, Qing Li', 'link': 'https://arxiv.org/abs/2508.07353', 'abstract': 'Numerous benchmarks have been built to evaluate the domain-specific abilities of large language models (LLMs), highlighting the need for effective and efficient benchmark construction. Existing domain-specific benchmarks primarily focus on the scaling law, relying on massive corpora for supervised fine-tuning or generating extensive question sets for broad coverage. However, the impact of corpus and question-answer (QA) set design on the precision and recall of domain-specific LLMs remains unexplored. In this paper, we address this gap and demonstrate that the scaling law is not always the optimal principle for benchmark construction in specific domains. Instead, we propose Comp-Comp, an iterative benchmarking framework based on a comprehensiveness-compactness principle. Here, comprehensiveness ensures semantic recall of the domain, while compactness enhances precision, guiding both corpus and QA set construction. To validate our framework, we conducted a case study in a well-renowned university, resulting in the creation of XUBench, a large-scale and comprehensive closed-domain benchmark. Although we use the academic domain as the case in this work, our Comp-Comp framework is designed to be extensible beyond academia, providing valuable insights for benchmark construction across various domains.', 'abstract_zh': '多种领域的大型语言模型专用基准已被构建，强调了有效高效基准构建的必要性。现有专用领域基准主要集中在标度定律上，依赖大规模语料库进行监督微调或生成大量问题集以实现广泛覆盖。然而，语料库和问题-回答集设计对专用领域大型语言模型的精确性和召回率影响尚未得到探索。本文填补了这一空白，证明了在特定领域中，标度定律并非总是最优的基准构建原则。相反，我们提出Comp-Comp，一种基于全面性-紧凑性原则的迭代基准测试框架。全面性确保领域语义召回，而紧凑性提高精确度，指导语料库和问题-回答集的构建。为了验证我们的框架，我们在一所著名大学进行了案例研究，产生了大规模和全面闭源领域的XUBench基准。尽管本文以学术领域为案例，但我们的Comp-Comp框架旨在超越学术领域，为各领域基准构建提供宝贵的见解。', 'title_zh': '重新思考领域特定大语言模型基准构建：一个全面性与紧凑性兼具的方法'}
{'arxiv_id': 'arXiv:2508.07334', 'title': 'Hallucination as a Computational Boundary: A Hierarchy of Inevitability and the Oracle Escape', 'authors': 'Quan Shi, Wang Xi, Zenghui Ding, Jianqing Gao, Xianjun Yang', 'link': 'https://arxiv.org/abs/2508.07334', 'abstract': 'The illusion phenomenon of large language models (LLMs) is the core obstacle to their reliable deployment. This article formalizes the large language model as a probabilistic Turing machine by constructing a "computational necessity hierarchy", and for the first time proves the illusions are inevitable on diagonalization, incomputability, and information theory boundaries supported by the new "learner pump lemma". However, we propose two "escape routes": one is to model Retrieval Enhanced Generations (RAGs) as oracle machines, proving their absolute escape through "computational jumps", providing the first formal theory for the effectiveness of RAGs; The second is to formalize continuous learning as an "internalized oracle" mechanism and implement this path through a novel neural game theory this http URL, this article proposes a', 'abstract_zh': '大型语言模型（LLMs）的幻觉现象是其可靠部署的核心障碍。本文通过构建“计算必要性层次结构”将大型语言模型形式化为概率图灵机，并首次证明幻觉在对角化、不可计算性和信息论边界上是不可避免的，这些证明基于新的“学习者泵引理”。然而，我们提出了两种“逃逸路线”：一种是将检索增强生成（RAGs）建模为预言机机器，通过“计算跃升”证明其绝对逃逸，这是第一个关于RAGs有效性形式理论；另一种是将连续学习形式化为“内嵌预言机”机制，并通过一种新颖的神经博弈理论实现这一路径。本文提出了一个新的。', 'title_zh': '幻觉作为计算的边界：不可避免性的层次与Oracle逃逸'}
{'arxiv_id': 'arXiv:2508.07292', 'title': 'EndoAgent: A Memory-Guided Reflective Agent for Intelligent Endoscopic Vision-to-Decision Reasoning', 'authors': 'Yi Tang, Kaini Wang, Yang Chen, Guangquan Zhou', 'link': 'https://arxiv.org/abs/2508.07292', 'abstract': 'Developing general artificial intelligence (AI) systems to support endoscopic image diagnosis is an emerging research priority. Existing methods based on large-scale pretraining often lack unified coordination across tasks and struggle to handle the multi-step processes required in complex clinical workflows. While AI agents have shown promise in flexible instruction parsing and tool integration across domains, their potential in endoscopy remains underexplored. To address this gap, we propose EndoAgent, the first memory-guided agent for vision-to-decision endoscopic analysis that integrates iterative reasoning with adaptive tool selection and collaboration. Built on a dual-memory design, it enables sophisticated decision-making by ensuring logical coherence through short-term action tracking and progressively enhancing reasoning acuity through long-term experiential learning. To support diverse clinical tasks, EndoAgent integrates a suite of expert-designed tools within a unified reasoning loop. We further introduce EndoAgentBench, a benchmark of 5,709 visual question-answer pairs that assess visual understanding and language generation capabilities in realistic scenarios. Extensive experiments show that EndoAgent consistently outperforms both general and medical multimodal models, exhibiting its strong flexibility and reasoning capabilities.', 'abstract_zh': '开发用于内镜图像诊断的一般人工智能系统是新兴的研究优先领域。现有的基于大规模预训练的方法往往缺乏跨任务的统一协调，难以处理复杂临床工作流程中所需的多步骤过程。虽然人工智能代理在跨领域灵活指令解析和工具集成方面显示出潜力，但在内镜应用中的潜力尚未得到充分探索。为了填补这一空白，我们提出了EndoAgent，这是一种基于记忆引导的内镜视觉到决策分析代理，将迭代推理与适应性工具选择和协作相结合。该代理基于双记忆设计，通过短期行为跟踪确保逻辑一致性，并通过长期经验学习逐步提高推理敏锐度。为了支持多样化的临床任务，EndoAgent在一个统一的推理循环中集成了多套专家设计的工具。我们还引入了包含5,709个视觉问答对的EndoAgentBench基准测试，评估其在现实场景中的视觉理解能力和语言生成能力。大量实验表明，EndoAgent在一致性和推理能力方面均优于通用和医学多模态模型。', 'title_zh': 'EndoAgent：一种内存引导的反射性智能内镜视觉决策推理代理'}
{'arxiv_id': 'arXiv:2508.07186', 'title': 'Multi-Dimensional Summarization Agents with Context-Aware Reasoning over Enterprise Tables', 'authors': 'Amit Dhanda', 'link': 'https://arxiv.org/abs/2508.07186', 'abstract': 'We propose a novel framework for summarizing structured enterprise data across multiple dimensions using large language model (LLM)-based agents. Traditional table-to-text models often lack the capacity to reason across hierarchical structures and context-aware deltas, which are essential in business reporting tasks. Our method introduces a multi-agent pipeline that extracts, analyzes, and summarizes multi-dimensional data using agents for slicing, variance detection, context construction, and LLM-based generation. Our results show that the proposed framework outperforms traditional approaches, achieving 83\\% faithfulness to underlying data, superior coverage of significant changes, and high relevance scores (4.4/5) for decision-critical insights. The improvements are especially pronounced in categories involving subtle trade-offs, such as increased revenue due to price changes amid declining unit volumes, which competing methods either overlook or address with limited specificity. We evaluate the framework on Kaggle datasets and demonstrate significant improvements in faithfulness, relevance, and insight quality over baseline table summarization approaches.', 'abstract_zh': '我们提出了一种新型框架，使用大型语言模型（LLM）代理在多个维度上总结结构化企业数据。传统基于表格到文本的模型往往缺乏在层级结构和上下文感知变化之间进行推理的能力，这对于商业报告任务至关重要。我们的方法引入了一个多代理流水线，使用专门的代理来抽取出分析、总结多维度数据，进行切片、变异检测、上下文构建，并利用LLM进行生成。我们的结果显示，所提框架在数据忠实度（83%）、显著变化的全面覆盖以及决策关键见解的相关性评分（4.4/5）方面均优于传统方法。特别是在涉及微妙权衡的类别中，如在单位数量下降的同时由于价格变化而增加的收入，竞争方法要么忽视了这些变化，要么处理得不够具体。我们在Kaggle数据集上评估了该框架，并展示了与基准表格总结方法相比，在忠实度、相关性及洞察质量方面的显著改进。', 'title_zh': '基于企业表格的上下文感知推理多维度总结代理'}
{'arxiv_id': 'arXiv:2508.07107', 'title': 'Designing a Feedback-Driven Decision Support System for Dynamic Student Intervention', 'authors': 'Timothy Oluwapelumi Adeyemi, Nadiah Fahad AlOtaibi', 'link': 'https://arxiv.org/abs/2508.07107', 'abstract': 'Accurate prediction of student performance is essential for timely academic intervention. However, most machine learning models in education are static and cannot adapt when new data, such as post-intervention outcomes, become available. To address this limitation, we propose a Feedback-Driven Decision Support System (DSS) with a closed-loop architecture that enables continuous model refinement. The system integrates a LightGBM-based regressor with incremental retraining, allowing educators to input updated student results, which automatically trigger model updates. This adaptive mechanism improves prediction accuracy by learning from real-world academic progress. The platform features a Flask-based web interface for real-time interaction and incorporates SHAP for explainability, ensuring transparency. Experimental results show a 10.7\\% reduction in RMSE after retraining, with consistent upward adjustments in predicted scores for intervened students. By transforming static predictors into self-improving systems, our approach advances educational analytics toward human-centered, data-driven, and responsive AI. The framework is designed for integration into LMS and institutional dashboards.', 'abstract_zh': '基于反馈的数据驱动决策支持系统：实现准确的学生绩效预测与持续模型优化', 'title_zh': '设计一种基于反馈的决策支持系统以实现动态学生干预'}
{'arxiv_id': 'arXiv:2508.07063', 'title': 'Towards Safer AI Moderation: Evaluating LLM Moderators Through a Unified Benchmark Dataset and Advocating a Human-First Approach', 'authors': 'Naseem Machlovi, Maryam Saleki, Innocent Ababio, Ruhul Amin', 'link': 'https://arxiv.org/abs/2508.07063', 'abstract': 'As AI systems become more integrated into daily life, the need for safer and more reliable moderation has never been greater. Large Language Models (LLMs) have demonstrated remarkable capabilities, surpassing earlier models in complexity and performance. Their evaluation across diverse tasks has consistently showcased their potential, enabling the development of adaptive and personalized agents. However, despite these advancements, LLMs remain prone to errors, particularly in areas requiring nuanced moral reasoning. They struggle with detecting implicit hate, offensive language, and gender biases due to the subjective and context-dependent nature of these issues. Moreover, their reliance on training data can inadvertently reinforce societal biases, leading to inconsistencies and ethical concerns in their outputs. To explore the limitations of LLMs in this role, we developed an experimental framework based on state-of-the-art (SOTA) models to assess human emotions and offensive behaviors. The framework introduces a unified benchmark dataset encompassing 49 distinct categories spanning the wide spectrum of human emotions, offensive and hateful text, and gender and racial biases. Furthermore, we introduced SafePhi, a QLoRA fine-tuned version of Phi-4, adapting diverse ethical contexts and outperforming benchmark moderators by achieving a Macro F1 score of 0.89, where OpenAI Moderator and Llama Guard score 0.77 and 0.74, respectively. This research also highlights the critical domains where LLM moderators consistently underperformed, pressing the need to incorporate more heterogeneous and representative data with human-in-the-loop, for better model robustness and explainability.', 'abstract_zh': '随着人工智能系统越来越多地融入日常生活中，对于更安全、更可靠的审核需求从未如此迫切。大型语言模型（LLMs）展现了卓越的能力，超越了早期模型在复杂性和性能上的表现。它们在各种任务上的评估始终展示了其潜力，促进了自适应和个性化代理的发展。然而，尽管这些进步，LLMs仍然容易出错，尤其是在需要细致道德推理的领域。它们在检测隐含仇恨、冒犯性语言和性别偏见方面存在问题，因为这些问题具有主观性和情境依赖性。此外，它们对训练数据的依赖可能导致无意中强化社会偏见，导致输出的一致性和伦理问题。为了探索LLMs在此角色中的局限性，我们基于最先进（SOTA）模型开发了一个实验框架来评估人类情绪和冒犯行为。该框架引入了一个统一的基准数据集，涵盖了49个不同的类别，范围从广泛的人类情绪到冒犯性和仇恨文本，以及性别和种族偏见。此外，我们引入了SafePhi，这是一个对Phi-4进行QLoRA微调的版本，能够适应各种伦理场景，并且在宏F1分数为0.89的情况下超越了基准审核员，而OpenAI Moderator和Llama Guard的分数分别为0.77和0.74。本研究还强调了LLM审核员在执行中的持续劣势，强调需要在保持人类在环中进行更异构和代表性的数据集整合，以提高模型的稳健性和可解释性。', 'title_zh': '通往更安全的AI审核：通过统一基准数据集评估LLM审核员并倡导以人为本的方法'}
{'arxiv_id': 'arXiv:2508.07043', 'title': 'K-Dense Analyst: Towards Fully Automated Scientific Analysis', 'authors': 'Orion Li, Vinayak Agarwal, Summer Zhou, Ashwin Gopinath, Timothy Kassis', 'link': 'https://arxiv.org/abs/2508.07043', 'abstract': "The complexity of modern bioinformatics analysis has created a critical gap between data generation and developing scientific insights. While large language models (LLMs) have shown promise in scientific reasoning, they remain fundamentally limited when dealing with real-world analytical workflows that demand iterative computation, tool integration and rigorous validation. We introduce K-Dense Analyst, a hierarchical multi-agent system that achieves autonomous bioinformatics analysis through a dual-loop architecture. K-Dense Analyst, part of the broader K-Dense platform, couples planning with validated execution using specialized agents to decompose complex objectives into executable, verifiable tasks within secure computational environments. On BixBench, a comprehensive benchmark for open-ended biological analysis, K-Dense Analyst achieves 29.2% accuracy, surpassing the best-performing language model (GPT-5) by 6.3 percentage points, representing nearly 27% improvement over what is widely considered the most powerful LLM available. Remarkably, K-Dense Analyst achieves this performance using Gemini 2.5 Pro, which attains only 18.3% accuracy when used directly, demonstrating that our architectural innovations unlock capabilities far beyond the underlying model's baseline performance. Our insights demonstrate that autonomous scientific reasoning requires more than enhanced language models, it demands purpose-built systems that can bridge the gap between high-level scientific objectives and low-level computational execution. These results represent a significant advance toward fully autonomous computational biologists capable of accelerating discovery across the life sciences.", 'abstract_zh': '现代生物信息学分析的复杂性在数据生成与开发科学洞见之间创造了关键差距。虽然大型语言模型（LLMs）在科学推理方面展现了潜力，但在处理需要迭代计算、工具集成和严格验证的实际分析工作流程时仍存在根本局限。我们介绍了一种分层多代理系统K-Dense Analyst，通过双重循环架构实现了自主生物信息学分析。K-Dense Analyst，作为更广泛的K-Dense平台的一部分，通过专门的代理将计划与验证执行相结合，将复杂的任务分解为在安全计算环境中可执行和可验证的任务。在BixBench这一全面的开放生物分析基准测试中，K-Dense Analyst实现了29.2%的准确性，超过了性能最佳的语言模型（GPT-5）的5.9个百分点，比广泛认为性能最强的LLM高出近27%。值得注意的是，K-Dense Analyst使用Gemini 2.5 Pro实现了这一性能，而Gemini 2.5 Pro直接使用时仅达到18.3%的准确性，这表明我们的架构创新远超底层模型的基本性能。我们的研究结果表明，自主科学研究不仅仅依赖于增强的语言模型，还需要旨在弥合高层次科学目标与低层次计算执行之间差距的专门系统。这些结果代表了全自主计算生物学家的重要进展，能够加速生命科学领域的发现。', 'title_zh': 'K-稠密分析师：迈向完全自动化的科学研究分析'}
{'arxiv_id': 'arXiv:2508.07022', 'title': 'MultiMedEdit: A Scenario-Aware Benchmark for Evaluating Knowledge Editing in Medical VQA', 'authors': 'Shengtao Wen, Haodong Chen, Yadong Wang, Zhongying Pan, Xiang Chen, Yu Tian, Bo Qian, Dong Liang, Sheng-Jun Huang', 'link': 'https://arxiv.org/abs/2508.07022', 'abstract': 'Knowledge editing (KE) provides a scalable approach for updating factual knowledge in large language models without full retraining. While previous studies have demonstrated effectiveness in general domains and medical QA tasks, little attention has been paid to KE in multimodal medical scenarios. Unlike text-only settings, medical KE demands integrating updated knowledge with visual reasoning to support safe and interpretable clinical decisions. To address this gap, we propose MultiMedEdit, the first benchmark tailored to evaluating KE in clinical multimodal tasks. Our framework spans both understanding and reasoning task types, defines a three-dimensional metric suite (reliability, generality, and locality), and supports cross-paradigm comparisons across general and domain-specific models. We conduct extensive experiments under single-editing and lifelong-editing settings. Results suggest that current methods struggle with generalization and long-tail reasoning, particularly in complex clinical workflows. We further present an efficiency analysis (e.g., edit latency, memory footprint), revealing practical trade-offs in real-world deployment across KE paradigms. Overall, MultiMedEdit not only reveals the limitations of current approaches but also provides a solid foundation for developing clinically robust knowledge editing techniques in the future.', 'abstract_zh': '知识编辑（KE）为在大型语言模型中更新事实知识提供了一种缩放方法，无需进行全面重新训练。虽然之前的研究在通用领域和医学问答任务中证明了其有效性，但在多模态医学场景中的KE研究关注较少。与仅文本设置不同，医学KE需要将更新的知识与视觉推理相结合，以支持安全和可解释的临床决策。为解决这一差距，我们提出了MultiMedEdit，这是首个针对临床多模态任务评估KE的标准基准。我们的框架涵盖了理解与推理任务类型，定义了三维度量套件（可靠性和普适性与局域性），并支持通用与领域特定模型之间的跨范式比较。我们在单次编辑和终身编辑设置下进行了广泛实验。结果表明，当前方法在泛化和长尾推理方面存在挑战，尤其是在复杂的临床工作流程中。我们进一步进行了效率分析（例如，编辑延迟、内存占用），揭示了在实际部署中KE范式之间的实际权衡。总体而言，MultiMedEdit不仅揭示了当前方法的局限性，还为开发适用于临床的稳健知识编辑技术奠定了坚实基础。', 'title_zh': 'MultiMedEdit: 一种情景感知的基准，用于评估医疗VQA中的知识编辑'}
{'arxiv_id': 'arXiv:2508.07015', 'title': 'Efficient and Reliable Hitting-Set Computations for the Implicit Hitting Set Approach', 'authors': 'Hannes Ihalainen, Dieter Vandesande, André Schidler, Jeremias Berg, Bart Bogaerts, Matti Järvisalo', 'link': 'https://arxiv.org/abs/2508.07015', 'abstract': 'The implicit hitting set (IHS) approach offers a general framework for solving computationally hard combinatorial optimization problems declaratively. IHS iterates between a decision oracle used for extracting sources of inconsistency and an optimizer for computing so-called hitting sets (HSs) over the accumulated sources of inconsistency. While the decision oracle is language-specific, the optimizers is usually instantiated through integer programming.\nWe explore alternative algorithmic techniques for hitting set optimization based on different ways of employing pseudo-Boolean (PB) reasoning as well as stochastic local search. We extensively evaluate the practical feasibility of the alternatives in particular in the context of pseudo-Boolean (0-1 IP) optimization as one of the most recent instantiations of IHS. Highlighting a trade-off between efficiency and reliability, while a commercial IP solver turns out to remain the most effective way to instantiate HS computations, it can cause correctness issues due to numerical instability; in fact, we show that exact HS computations instantiated via PB reasoning can be made competitive with a numerically exact IP solver. Furthermore, the use of PB reasoning as a basis for HS computations allows for obtaining certificates for the correctness of IHS computations, generally applicable to any IHS instantiation in which reasoning in the declarative language at hand can be captured in the PB-based proof format we employ.', 'abstract_zh': '基于伪布尔推理和随机局部搜索的隐含集合优化替代算法探究：伪布尔优化情境下的实证评估', 'title_zh': '隐击集方法的高效可靠击集计算'}
{'arxiv_id': 'arXiv:2508.06980', 'title': 'Simulating Biological Intelligence: Active Inference with Experiment-Informed Generative Model', 'authors': 'Aswin Paul, Moein Khajehnejad, Forough Habibollahi, Brett J. Kagan, Adeel Razi', 'link': 'https://arxiv.org/abs/2508.06980', 'abstract': 'With recent and rapid advancements in artificial intelligence (AI), understanding the foundation of purposeful behaviour in autonomous agents is crucial for developing safe and efficient systems. While artificial neural networks have dominated the path to AI, recent studies are exploring the potential of biologically based systems, such as networks of living biological neuronal networks. Along with promises of high power and data efficiency, these systems may also inform more explainable and biologically plausible models. In this work, we propose a framework rooted in active inference, a general theory of behaviour, to model decision-making in embodied agents. Using experiment-informed generative models, we simulate decision-making processes in a simulated game-play environment, mirroring experimental setups that use biological neurons. Our results demonstrate learning in these agents, providing insights into the role of memory-based learning and predictive planning in intelligent decision-making. This work contributes to the growing field of explainable AI by offering a biologically grounded and scalable approach to understanding purposeful behaviour in agents.', 'abstract_zh': '随着人工智能（AI）的近期 rapid 发展，了解自主代理有目的行为的基础对于开发安全和高效的系统至关重要。虽然人工神经网络主导了AI的发展路径，但最近的研究正在探索基于生物学系统的潜力，如由生物神经元网络组成的网络。除了高功率和数据效率的承诺外，这些系统还可能启发更可解释和生物合理模型。在本项工作中，我们提出了一种基于主动推断的框架，这是一种关于行为的一般理论，用于建模具身代理的决策过程。利用实验指导的生成模型，我们在模拟游戏环境中标记的决策过程，模拟使用生物神经元的实验装置。我们的结果展示了这些代理的学习，提供了关于基于记忆的学习和预测性计划在智能决策中的作用的见解。本项工作为可解释AI的发展做出了贡献，通过提供一种基于生物学原理且可扩展的方法来理解代理的有目的行为。', 'title_zh': '模拟生物智能：基于实验指导的生成模型的主动推断'}
{'arxiv_id': 'arXiv:2508.06972', 'title': 'DSperse: A Framework for Targeted Verification in Zero-Knowledge Machine Learning', 'authors': 'Dan Ivanov, Tristan Freiberg, Haruna Isah', 'link': 'https://arxiv.org/abs/2508.06972', 'abstract': 'DSperse is a modular framework for distributed machine learning inference with strategic cryptographic verification. Operating within the emerging paradigm of distributed zero-knowledge machine learning, DSperse avoids the high cost and rigidity of full-model circuitization by enabling targeted verification of strategically chosen subcomputations. These verifiable segments, or "slices", may cover part or all of the inference pipeline, with global consistency enforced through audit, replication, or economic incentives. This architecture supports a pragmatic form of trust minimization, localizing zero-knowledge proofs to the components where they provide the greatest value. We evaluate DSperse using multiple proving systems and report empirical results on memory usage, runtime, and circuit behavior under sliced and unsliced configurations. By allowing proof boundaries to align flexibly with the model\'s logical structure, DSperse supports scalable, targeted verification strategies suited to diverse deployment needs.', 'abstract_zh': 'DSperse是一种基于战略加密验证的分布式机器学习推理模块化框架', 'title_zh': 'DSperse: 一种零知识机器学习的目标验证框架'}
{'arxiv_id': 'arXiv:2508.06963', 'title': 'MASteer: Multi-Agent Adaptive Steer Strategy for End-to-End LLM Trustworthiness Repair', 'authors': 'Changqing Li, Tianlin Li, Xiaohan Zhang, Aishan Liu, Li Pan', 'link': 'https://arxiv.org/abs/2508.06963', 'abstract': 'Large Language Models (LLMs) face persistent and evolving trustworthiness issues, motivating developers to seek automated and flexible repair methods that enable convenient deployment across diverse scenarios. Existing repair methods like supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) are costly and slow, while prompt engineering lacks robustness and scalability. Representation engineering, which steers model behavior by injecting targeted concept vectors during inference, offers a lightweight, training-free alternative. However, current approaches depend on manually crafted samples and fixed steering strategies, limiting automation and adaptability. To overcome these challenges, we propose MASteer, the first end-to-end framework for trustworthiness repair in LLMs based on representation engineering. MASteer integrates two core components: AutoTester, a multi-agent system that generates diverse, high-quality steer samples tailored to developer needs; and AutoRepairer, which constructs adaptive steering strategies with anchor vectors for automated, context-aware strategy selection during inference. Experiments on standard and customized trustworthiness tasks show MASteer consistently outperforms baselines, improving metrics by 15.36% on LLaMA-3.1-8B-Chat and 4.21% on Qwen-3-8B-Chat, while maintaining general model capabilities. MASteer demonstrates strong robustness, generalization, and practical value for scalable, efficient trustworthiness repair.', 'abstract_zh': '基于表示工程的大型语言模型可信性修复框架MASteer', 'title_zh': 'MASteer: 多代理自适应引导策略用于端到端LLM可信性修复'}
{'arxiv_id': 'arXiv:2508.06960', 'title': 'DatasetResearch: Benchmarking Agent Systems for Demand-Driven Dataset Discovery', 'authors': 'Keyu Li, Mohan Jiang, Dayuan Fu, Yunze Wu, Xiangkun Hu, Dequan Wang, Pengfei Liu', 'link': 'https://arxiv.org/abs/2508.06960', 'abstract': 'The rapid advancement of large language models has fundamentally shifted the bottleneck in AI development from computational power to data availability-with countless valuable datasets remaining hidden across specialized repositories, research appendices, and domain platforms. As reasoning capabilities and deep research methodologies continue to evolve, a critical question emerges: can AI agents transcend conventional search to systematically discover any dataset that meets specific user requirements, enabling truly autonomous demand-driven data curation? We introduce DatasetResearch, the first comprehensive benchmark evaluating AI agents\' ability to discover and synthesize datasets from 208 real-world demands across knowledge-intensive and reasoning-intensive tasks. Our tri-dimensional evaluation framework reveals a stark reality: even advanced deep research systems achieve only 22% score on our challenging DatasetResearch-pro subset, exposing the vast gap between current capabilities and perfect dataset discovery. Our analysis uncovers a fundamental dichotomy-search agents excel at knowledge tasks through retrieval breadth, while synthesis agents dominate reasoning challenges via structured generation-yet both catastrophically fail on "corner cases" outside existing distributions. These findings establish the first rigorous baseline for dataset discovery agents and illuminate the path toward AI systems capable of finding any dataset in the digital universe. Our benchmark and comprehensive analysis provide the foundation for the next generation of self-improving AI systems and are publicly available at this https URL.', 'abstract_zh': '大型语言模型的迅速进展从根本上将AI发展的瓶颈从计算能力转移到了数据可用性问题——无数宝贵的数据集仍被隐藏在专门的存储库、研究附录和专业平台上。随着推理能力和深入研究方法继续发展，一个关键问题浮现出来：AI代理能否超越传统的搜索方式，系统地发现符合特定用户需求的任何数据集，从而实现真正的自主需求驱动的数据策展？我们介绍了DatasetResearch，这是第一个全面评估AI代理从208个真实的现实需求中发现和综合数据集能力的基准，这些需求分布在知识密集型和推理密集型任务中。我们的三维评估框架揭示了一个严峻的事实：即使是最先进的深入研究系统，在我们的挑战性DatasetResearch-pro子集中也只能获得22%的分数，这表明当前能力与完美数据集发现之间存在巨大的差距。我们的分析揭示了一个根本性的二分法：搜索代理通过检索广度在知识任务中表现出色，而合成代理则通过结构化生成在推理挑战中占主导地位——但两者在现有的分布之外的“边缘情况”中表现灾难性。这些发现为数据集发现代理奠定了第一个严谨的基础，并照亮了走向能够发现数字宇宙中任何数据集的AI系统之路。我们的基准和全面分析为基础自改进的AI系统提供了基础，并公开发布在本链接：https://link.alinai.cn/DatasetResearch。', 'title_zh': '数据集研究：面向需求驱动的数据集发现代理系统基准测试'}
{'arxiv_id': 'arXiv:2508.06950', 'title': 'Large Language Models Do Not Simulate Human Psychology', 'authors': 'Sarah Schröder, Thekla Morgenroth, Ulrike Kuhl, Valerie Vaquet, Benjamin Paaßen', 'link': 'https://arxiv.org/abs/2508.06950', 'abstract': "Large Language Models (LLMs),such as ChatGPT, are increasingly used in research, ranging from simple writing assistance to complex data annotation tasks. Recently, some research has suggested that LLMs may even be able to simulate human psychology and can, hence, replace human participants in psychological studies. We caution against this approach. We provide conceptual arguments against the hypothesis that LLMs simulate human psychology. We then present empiric evidence illustrating our arguments by demonstrating that slight changes to wording that correspond to large changes in meaning lead to notable discrepancies between LLMs' and human responses, even for the recent CENTAUR model that was specifically fine-tuned on psychological responses. Additionally, different LLMs show very different responses to novel items, further illustrating their lack of reliability. We conclude that LLMs do not simulate human psychology and recommend that psychological researchers should treat LLMs as useful but fundamentally unreliable tools that need to be validated against human responses for every new application.", 'abstract_zh': '大型语言模型（LLMs）如ChatGPT在研究中越来越广泛使用，从简单的写作辅助到复杂的数据标注任务不等。最近的一些研究表明，LLMs甚至可能模拟人类心理，从而在心理学研究中取代人类参与者。我们对此表示警告。我们提供了反对LLMs模拟人类心理这一假设的概念性论述，并通过实证证据进一步证明，即使是专门为心理响应进行微调的CENTAUR模型，其响应与人类响应之间也存在显著差异，即使是细微的文字变化也可能导致重大意义上的不同。此外，不同LLMs对新颖项目的响应差异很大，进一步说明了它们的不可靠性。我们得出结论认为，LLMs并不能模拟人类心理，并建议心理学研究人员应将LLMs视为有用的但本质上不可靠的工具，每有一个新的应用就需要对其响应进行人类响应验证。', 'title_zh': '大型语言模型不模拟人类心理学'}
{'arxiv_id': 'arXiv:2508.06939', 'title': 'Intrinsic Explainability of Multimodal Learning for Crop Yield Prediction', 'authors': 'Hiba Najjar, Deepak Pathak, Marlon Nuske, Andreas Dengel', 'link': 'https://arxiv.org/abs/2508.06939', 'abstract': 'Multimodal learning enables various machine learning tasks to benefit from diverse data sources, effectively mimicking the interplay of different factors in real-world applications, particularly in agriculture. While the heterogeneous nature of involved data modalities may necessitate the design of complex architectures, the model interpretability is often overlooked. In this study, we leverage the intrinsic explainability of Transformer-based models to explain multimodal learning networks, focusing on the task of crop yield prediction at the subfield level. The large datasets used cover various crops, regions, and years, and include four different input modalities: multispectral satellite and weather time series, terrain elevation maps and soil properties. Based on the self-attention mechanism, we estimate feature attributions using two methods, namely the Attention Rollout (AR) and Generic Attention (GA), and evaluate their performance against Shapley-based model-agnostic estimations, Shapley Value Sampling (SVS). Additionally, we propose the Weighted Modality Activation (WMA) method to assess modality attributions and compare it with SVS attributions. Our findings indicate that Transformer-based models outperform other architectures, specifically convolutional and recurrent networks, achieving R2 scores that are higher by 0.10 and 0.04 at the subfield and field levels, respectively. AR is shown to provide more robust and reliable temporal attributions, as confirmed through qualitative and quantitative evaluation, compared to GA and SVS values. Information about crop phenology stages was leveraged to interpret the explanation results in the light of established agronomic knowledge. Furthermore, modality attributions revealed varying patterns across the two methods compared.[...]', 'abstract_zh': '基于Transformer的模型可解释性在农业小区域作物产量预测中的多模态学习解释', 'title_zh': '多模态学习中农产品产量预测的内在可解释性'}
{'arxiv_id': 'arXiv:2508.06931', 'title': 'Automated Formalization via Conceptual Retrieval-Augmented LLMs', 'authors': 'Wangyue Lu, Lun Du, Sirui Li, Ke Weng, Haozhe Sun, Hengyu Liu, Minghe Yu, Tiancheng Zhang, Ge Yu', 'link': 'https://arxiv.org/abs/2508.06931', 'abstract': 'Interactive theorem provers (ITPs) require manual formalization, which is labor-intensive and demands expert knowledge. While automated formalization offers a potential solution, it faces two major challenges: model hallucination (e.g., undefined predicates, symbol misuse, and version incompatibility) and the semantic gap caused by ambiguous or missing premises in natural language descriptions. To address these issues, we propose CRAMF, a Concept-driven Retrieval-Augmented Mathematical Formalization framework. CRAMF enhances LLM-based autoformalization by retrieving formal definitions of core mathematical concepts, providing contextual grounding during code generation. However, applying retrieval-augmented generation (RAG) in this setting is non-trivial due to the lack of structured knowledge bases, the polymorphic nature of mathematical concepts, and the high precision required in formal retrieval. We introduce a framework for automatically constructing a concept-definition knowledge base from Mathlib4, the standard mathematical library for the Lean 4 theorem prover, indexing over 26,000 formal definitions and 1,000+ core mathematical concepts. To address conceptual polymorphism, we propose contextual query augmentation with domain- and application-level signals. In addition, we design a dual-channel hybrid retrieval strategy with reranking to ensure accurate and relevant definition retrieval. Experiments on miniF2F, ProofNet, and our newly proposed AdvancedMath benchmark show that CRAMF can be seamlessly integrated into LLM-based autoformalizers, yielding consistent improvements in translation accuracy, achieving up to 62.1% and an average of 29.9% relative improvement.', 'abstract_zh': '基于概念驱动检索增强的数学形式化框架CRAMF', 'title_zh': '基于概念检索增强的大语言模型的自动化形式化过程'}
{'arxiv_id': 'arXiv:2508.06899', 'title': 'GDBA Revisited: Unleashing the Power of Guided Local Search for Distributed Constraint Optimization', 'authors': 'Yanchen Deng, Xinrun Wang, Bo An', 'link': 'https://arxiv.org/abs/2508.06899', 'abstract': 'Local search is an important class of incomplete algorithms for solving Distributed Constraint Optimization Problems (DCOPs) but it often converges to poor local optima. While GDBA provides a comprehensive rule set to escape premature convergence, its empirical benefits remain marginal on general-valued problems. In this work, we systematically examine GDBA and identify three factors that potentially lead to its inferior performance, i.e., over-aggressive constraint violation conditions, unbounded penalty accumulation, and uncoordinated penalty updates. To address these issues, we propose Distributed Guided Local Search (DGLS), a novel GLS framework for DCOPs that incorporates an adaptive violation condition to selectively penalize constraints with high cost, a penalty evaporation mechanism to control the magnitude of penalization, and a synchronization scheme for coordinated penalty updates. We theoretically show that the penalty values are bounded, and agents play a potential game in our DGLS. Our extensive empirical results on various standard benchmarks demonstrate the great superiority of DGLS over state-of-the-art baselines. Particularly, compared to Damped Max-sum with high damping factors (e.g., 0.7 or 0.9), our DGLS achieves competitive performance on general-valued problems, and outperforms it by significant margins (\\textbf{3.77\\%--66.3\\%}) on structured problems in terms of anytime results.', 'abstract_zh': '分布式引导局部搜索（DGLS）：一种用于分布式约束优化问题的新颖GLS框架', 'title_zh': 'GDBA 重访：解锁分布式约束优化中引导局部搜索的强大功能'}
{'arxiv_id': 'arXiv:2508.06894', 'title': 'Pushdown Reward Machines for Reinforcement Learning', 'authors': 'Giovanni Varricchione, Toryn Q. Klassen, Natasha Alechina, Mehdi Dastani, Brian Logan, Sheila A. McIlraith', 'link': 'https://arxiv.org/abs/2508.06894', 'abstract': 'Reward machines (RMs) are automata structures that encode (non-Markovian) reward functions for reinforcement learning (RL). RMs can reward any behaviour representable in regular languages and, when paired with RL algorithms that exploit RM structure, have been shown to significantly improve sample efficiency in many domains. In this work, we present pushdown reward machines (pdRMs), an extension of reward machines based on deterministic pushdown automata. pdRMs can recognize and reward temporally extended behaviours representable in deterministic context-free languages, making them more expressive than reward machines. We introduce two variants of pdRM-based policies, one which has access to the entire stack of the pdRM, and one which can only access the top $k$ symbols (for a given constant $k$) of the stack. We propose a procedure to check when the two kinds of policies (for a given environment, pdRM, and constant $k$) achieve the same optimal expected reward. We then provide theoretical results establishing the expressive power of pdRMs, and space complexity results about the proposed learning problems. Finally, we provide experimental results showing how agents can be trained to perform tasks representable in deterministic context-free languages using pdRMs.', 'abstract_zh': '基于确定性推进自动机的推进奖励机器（pdRMs）及其应用', 'title_zh': '推进栈奖励机器在强化学习中的应用'}
{'arxiv_id': 'arXiv:2508.06859', 'title': 'MeteorPred: A Meteorological Multimodal Large Model and Dataset for Severe Weather Event Prediction', 'authors': 'Shuo Tang, Jian Xu, Jiadong Zhang, Yi Chen, Qizhao Jin, Lingdong Shen, Chenglin Liu, Shiming Xiang', 'link': 'https://arxiv.org/abs/2508.06859', 'abstract': 'Timely and accurate severe weather warnings are critical for disaster mitigation. However, current forecasting systems remain heavily reliant on manual expert interpretation, introducing subjectivity and significant operational burdens. With the rapid development of AI technologies, the end-to-end "AI weather station" is gradually emerging as a new trend in predicting severe weather events. Three core challenges impede the development of end-to-end AI severe weather system: (1) scarcity of severe weather event samples; (2) imperfect alignment between high-dimensional meteorological data and textual warnings; (3) existing multimodal language models are unable to handle high-dimensional meteorological data and struggle to fully capture the complex dependencies across temporal sequences, vertical pressure levels, and spatial dimensions. To address these challenges, we introduce MP-Bench, the first large-scale temporal multimodal dataset for severe weather events prediction, comprising 421,363 pairs of raw multi-year meteorological data and corresponding text caption, covering a wide range of severe weather scenarios across China. On top of this dataset, we develop a meteorology multimodal large model (MMLM) that directly ingests 4D meteorological inputs. In addition, it is designed to accommodate the unique characteristics of 4D meteorological data flow, incorporating three plug-and-play adaptive fusion modules that enable dynamic feature extraction and integration across temporal sequences, vertical pressure layers, and spatial dimensions. Extensive experiments on MP-Bench demonstrate that MMLM performs exceptionally well across multiple tasks, highlighting its effectiveness in severe weather understanding and marking a key step toward realizing automated, AI-driven weather forecasting systems. Our source code and dataset will be made publicly available.', 'abstract_zh': '及时准确的严重天气预警对于灾害缓解至关重要。然而，当前的预报系统仍高度依赖手工专家解释，引入了主观性和显著的操作负担。随着人工智能技术的迅速发展，端到端的“AI气象站”正逐渐成为预测严重天气事件的新趋势。端到端的人工智能严重天气系统面临三大核心挑战：（1）严重天气事件样本稀缺；（2）高维气象数据与文字警报之间不完美的对齐；（3）现有的多模态语言模型无法处理高维气象数据，难以充分捕捉时间序列、垂直压力层和空间维度上的复杂依赖关系。为应对这些挑战，我们提出了MP-Bench，这是首个针对严重天气事件预测的大规模时序多模态数据集，包含421,363个多年气象数据与相应文本描述配对，涵盖中国广泛范围内的严重天气场景。在此数据集基础上，我们开发了一种气象多模态大型模型（MMLM），可以直接输入4D气象数据。此外，该模型设计用于适应4D气象数据流的独特特征，嵌入了三个即插即用的自适应融合模块，以实现时间序列、垂直压力层和空间维度上的动态特征提取和集成。在MP-Bench上的广泛实验表明，MMLM在多个任务中表现出色，凸显了其在严重天气理解方面的有效性，并为进一步实现自动化、AI驱动的天气预报系统奠定了关键步骤。我们的源代码和数据集将公开发布。', 'title_zh': 'MeteorPred：一种气象多模态大型模型及数据集用于严重天气事件预测'}
{'arxiv_id': 'arXiv:2508.06851', 'title': 'MDK12-Bench: A Comprehensive Evaluation of Multimodal Large Language Models on Multidisciplinary Exams', 'authors': 'Pengfei Zhou, Xiaopeng Peng, Fanrui Zhang, Zhaopan Xu, Jiaxin Ai, Yansheng Qiu, Chuanhao Li, Zhen Li, Ming Li, Yukang Feng, Jianwen Sun, Haoquan Zhang, Zizhen Li, Xiaofeng Mao, Zekai Li, Wangbo Zhao, Kai Wang, Xiaojun Chang, Wenqi Shao, Yang You, Kaipeng Zhang', 'link': 'https://arxiv.org/abs/2508.06851', 'abstract': 'Multimodal large language models (MLLMs), which integrate language and visual cues for problem-solving, are crucial for advancing artificial general intelligence (AGI). However, current benchmarks for measuring the intelligence of MLLMs suffer from limited scale, narrow coverage, and unstructured knowledge, offering only static and undifferentiated evaluations. To bridge this gap, we introduce MDK12-Bench, a large-scale multidisciplinary benchmark built from real-world K-12 exams spanning six disciplines with 141K instances and 6,225 knowledge points organized in a six-layer taxonomy. Covering five question formats with difficulty and year annotations, it enables comprehensive evaluation to capture the extent to which MLLMs perform over four dimensions: 1) difficulty levels, 2) temporal (cross-year) shifts, 3) contextual shifts, and 4) knowledge-driven reasoning. We propose a novel dynamic evaluation framework that introduces unfamiliar visual, textual, and question form shifts to challenge model generalization while improving benchmark objectivity and longevity by mitigating data contamination. We further evaluate knowledge-point reference-augmented generation (KP-RAG) to examine the role of knowledge in problem-solving. Key findings reveal limitations in current MLLMs in multiple aspects and provide guidance for enhancing model robustness, interpretability, and AI-assisted education.', 'abstract_zh': '多模态大型语言模型（MLLMs）在融合语言和视觉线索进行问题解决方面的进展对于推动人工智能通用智能（AGI）至关重要。然而，当前用于衡量MLLMs智能的基准在规模、覆盖范围和知识结构上存在局限，仅能提供静态且不分化的评估。为解决这一问题，我们介绍了MDK12-Bench，这是一个从涵盖六大学科的12年真实考试题构建的大规模跨学科基准，包含141,000个实例和6,225个知识点，并通过六层分类体系组织。该基准覆盖五种问题格式，并标注了难度和年份，从而在四个维度上进行全面评估：1）难度水平，2）时间（跨年份）变化，3）背景变化，以及4）基于知识的推理。我们提出了一种新颖的动力评估框架，通过引入不熟悉的视觉、文本和问题形式变化来挑战模型的泛化能力，同时通过减轻数据污染来提高基准的客观性和持久性。此外，我们还评估了基于知识点引用增强生成（KP-RAG）以探讨知识在问题解决中的作用。关键发现揭示了当前MLLMs在多个方面的局限性，并为提升模型的稳健性、可解释性和人工智能辅助教育提供了指导。', 'title_zh': 'MDK12-Bench: 多模态大型语言模型在多学科考试中的全面评估'}
{'arxiv_id': 'arXiv:2508.06836', 'title': 'Multi-level Advantage Credit Assignment for Cooperative Multi-Agent Reinforcement Learning', 'authors': 'Xutong Zhao, Yaqi Xie', 'link': 'https://arxiv.org/abs/2508.06836', 'abstract': "Cooperative multi-agent reinforcement learning (MARL) aims to coordinate multiple agents to achieve a common goal. A key challenge in MARL is credit assignment, which involves assessing each agent's contribution to the shared reward. Given the diversity of tasks, agents may perform different types of coordination, with rewards attributed to diverse and often overlapping agent subsets. In this work, we formalize the credit assignment level as the number of agents cooperating to obtain a reward, and address scenarios with multiple coexisting levels. We introduce a multi-level advantage formulation that performs explicit counterfactual reasoning to infer credits across distinct levels. Our method, Multi-level Advantage Credit Assignment (MACA), captures agent contributions at multiple levels by integrating advantage functions that reason about individual, joint, and correlated actions. Utilizing an attention-based framework, MACA identifies correlated agent relationships and constructs multi-level advantages to guide policy learning. Comprehensive experiments on challenging Starcraft v1\\&v2 tasks demonstrate MACA's superior performance, underscoring its efficacy in complex credit assignment scenarios.", 'abstract_zh': '协同多智能体强化学习（MARL）旨在协调多个智能体以实现共同目标。MARL中的一个关键挑战是信用分配，涉及评估每个智能体对共享奖励的贡献。鉴于任务的多样性，智能体可能执行不同类型的协调，奖励可能归属于多样且往往重叠的智能体子集。在本工作中，我们将信用分配级别形式化为获得奖励所需的智能体数量，并处理多种共存级别的场景。我们引入了一种多级优势形式化方法，该方法进行显式的反事实推理以推断不同级别的信用。我们的方法，多级优势信用分配（MACA），通过结合考虑个体、联合和相关行动的优势函数来捕捉多个级别的智能体贡献。利用基于注意力的框架，MACA 识别相关智能体关系并构建多级优势以指导策略学习。在具有挑战性的Starcraft v1和v2任务上的全面实验表明，MACA 在复杂信用分配场景中的性能优越，突显了其有效性。', 'title_zh': '多层级优势信用分配的协同多智能体强化学习'}
{'arxiv_id': 'arXiv:2508.06832', 'title': 'Remote Sensing Image Intelligent Interpretation with the Language-Centered Perspective: Principles, Methods and Challenges', 'authors': 'Haifeng Li, Wang Guo, Haiyang Wu, Mengwei Wu, Jipeng Zhang, Qing Zhu, Yu Liu, Xin Huang, Chao Tao', 'link': 'https://arxiv.org/abs/2508.06832', 'abstract': 'The mainstream paradigm of remote sensing image interpretation has long been dominated by vision-centered models, which rely on visual features for semantic understanding. However, these models face inherent limitations in handling multi-modal reasoning, semantic abstraction, and interactive decision-making. While recent advances have introduced Large Language Models (LLMs) into remote sensing workflows, existing studies primarily focus on downstream applications, lacking a unified theoretical framework that explains the cognitive role of language. This review advocates a paradigm shift from vision-centered to language-centered remote sensing interpretation. Drawing inspiration from the Global Workspace Theory (GWT) of human cognition, We propose a language-centered framework for remote sensing interpretation that treats LLMs as the cognitive central hub integrating perceptual, task, knowledge and action spaces to enable unified understanding, reasoning, and decision-making. We first explore the potential of LLMs as the central cognitive component in remote sensing interpretation, and then summarize core technical challenges, including unified multimodal representation, knowledge association, and reasoning and decision-making. Furthermore, we construct a global workspace-driven interpretation mechanism and review how language-centered solutions address each challenge. Finally, we outline future research directions from four perspectives: adaptive alignment of multimodal data, task understanding under dynamic knowledge constraints, trustworthy reasoning, and autonomous interaction. This work aims to provide a conceptual foundation for the next generation of remote sensing interpretation systems and establish a roadmap toward cognition-driven intelligent geospatial analysis.', 'abstract_zh': '基于语言中心的遥感图像解释范式转变：从感知中心到认知驱动的统一理解、推理与决策', 'title_zh': '基于语言中心视角的遥感图像智能解释：原理、方法与挑战'}
{'arxiv_id': 'arXiv:2508.06823', 'title': 'Natural Language-Driven Viewpoint Navigation for Volume Exploration via Semantic Block Representation', 'authors': 'Xuan Zhao, Jun Tao', 'link': 'https://arxiv.org/abs/2508.06823', 'abstract': "Exploring volumetric data is crucial for interpreting scientific datasets. However, selecting optimal viewpoints for effective navigation can be challenging, particularly for users without extensive domain expertise or familiarity with 3D navigation. In this paper, we propose a novel framework that leverages natural language interaction to enhance volumetric data exploration. Our approach encodes volumetric blocks to capture and differentiate underlying structures. It further incorporates a CLIP Score mechanism, which provides semantic information to the blocks to guide navigation. The navigation is empowered by a reinforcement learning framework that leverage these semantic cues to efficiently search for and identify desired viewpoints that align with the user's intent. The selected viewpoints are evaluated using CLIP Score to ensure that they best reflect the user queries. By automating viewpoint selection, our method improves the efficiency of volumetric data navigation and enhances the interpretability of complex scientific phenomena.", 'abstract_zh': '利用自然语言交互增强体积数据探索的框架', 'title_zh': '基于语义块表示的自然语言驱动视点导航以进行体积探索'}
{'arxiv_id': 'arXiv:2508.06754', 'title': 'A Fuzzy Logic Prompting Framework for Large Language Models in Adaptive and Uncertain Tasks', 'authors': 'Vanessa Figueiredo', 'link': 'https://arxiv.org/abs/2508.06754', 'abstract': 'We introduce a modular prompting framework that supports safer and more adaptive use of large language models (LLMs) across dynamic, user-centered tasks. Grounded in human learning theory, particularly the Zone of Proximal Development (ZPD), our method combines a natural language boundary prompt with a control schema encoded with fuzzy scaffolding logic and adaptation rules. This architecture enables LLMs to modulate behavior in response to user state without requiring fine-tuning or external orchestration. In a simulated intelligent tutoring setting, the framework improves scaffolding quality, adaptivity, and instructional alignment across multiple models, outperforming standard prompting baselines. Evaluation is conducted using rubric-based LLM graders at scale. While initially developed for education, the framework has shown promise in other interaction-heavy domains, such as procedural content generation for games. Designed for safe deployment, it provides a reusable methodology for structuring interpretable, goal-aligned LLM behavior in uncertain or evolving contexts.', 'abstract_zh': '一种基于人类学习理论的模块化提示框架：支持更大语言模型在动态用户中心任务中的安全与适应性使用', 'title_zh': '适用于适应性和不确定性任务的大语言模型模糊逻辑提示框架'}
{'arxiv_id': 'arXiv:2508.06753', 'title': 'Pushing the Envelope of LLM Inference on AI-PC', 'authors': 'Evangelos Georganas, Dhiraj Kalamkar, Alexander Heinecke', 'link': 'https://arxiv.org/abs/2508.06753', 'abstract': 'The advent of ultra-low-bit LLM models (1/1.58/2-bit), which match the perplexity and end-task performance of their full-precision counterparts using the same model size, is ushering in a new era of LLM inference for resource-constrained environments such as edge devices and AI PCs. While these quantization advances promise models that are more cost-effective in terms of latency, memory, throughput, and energy consumption, the computational efficiency of state-of-the-art (SOTA) inference runtimes (e.g., this http URL) used to deploy them remains underexplored. In this work, we take a bottom-up approach: we first design and implement 1-bit and 2-bit microkernels optimized for modern CPUs, achieving peak computational efficiency across a variety of CPU platforms. We integrate these microkernels into a state-of-the-art LLM inference framework, namely PyTorch-TPP, and present end-to-end inference results with 2-bit models that outperform the current SOTA runtime this http URL by up to 2.2x, and deliver up to 7x speedup compared to the 16-bit model inference. Our optimized runtime advances the state of LLM inference on AI PCs and edge devices, paving the way for efficient deployment of ultra-low-bit LLM models.', 'abstract_zh': '超低位宽LLM模型（1/1.58/2位）的出现：旨在资源受限环境中的LLM推理新纪元', 'title_zh': '扩展边界：大语言模型推理在AI-PC上的的应用'}
{'arxiv_id': 'arXiv:2508.06746', 'title': 'Topology Generation of UAV Covert Communication Networks: A Graph Diffusion Approach with Incentive Mechanism', 'authors': 'Xin Tang, Qian Chen, Fengshun Li, Youchun Gong, Yinqiu Liu, Wen Tian, Shaowen Qin, Xiaohuan Li', 'link': 'https://arxiv.org/abs/2508.06746', 'abstract': 'With the growing demand for Uncrewed Aerial Vehicle (UAV) networks in sensitive applications, such as urban monitoring, emergency response, and secure sensing, ensuring reliable connectivity and covert communication has become increasingly vital. However, dynamic mobility and exposure risks pose significant challenges. To tackle these challenges, this paper proposes a self-organizing UAV network framework combining Graph Diffusion-based Policy Optimization (GDPO) with a Stackelberg Game (SG)-based incentive mechanism. The GDPO method uses generative AI to dynamically generate sparse but well-connected topologies, enabling flexible adaptation to changing node distributions and Ground User (GU) demands. Meanwhile, the Stackelberg Game (SG)-based incentive mechanism guides self-interested UAVs to choose relay behaviors and neighbor links that support cooperation and enhance covert communication. Extensive experiments are conducted to validate the effectiveness of the proposed framework in terms of model convergence, topology generation quality, and enhancement of covert communication performance.', 'abstract_zh': '随着无人机网络在敏感应用如城市监控、应急响应和安全感知等方面需求的增长，确保可靠连接和隐蔽通信变得越来越重要。然而，动态移动性和暴露风险构成了重大挑战。为应对这些挑战，本文提出了一种基于图扩散策略优化（GDPO）和Stackelberg博弈（SG）激励机制相结合的自组织无人机网络框架。GDPO方法利用生成式AI动态生成稀疏但具有良好连接性的拓扑结构，以灵活适应节点分布和地面用户的需求。同时，基于Stackelberg博弈（SG）的激励机制引导无人机选择支持合作并增强隐蔽通信的中继行为和邻接链路。通过广泛的实验验证了所提框架在模型收敛性、拓扑结构生成质量和隐蔽通信性能提升方面的有效性。', 'title_zh': '无人机隐蔽通信网络的拓扑生成：具有激励机制的图扩散方法'}
{'arxiv_id': 'arXiv:2508.06736', 'title': 'ParBalans: Parallel Multi-Armed Bandits-based Adaptive Large Neighborhood Search', 'authors': 'Alican Yilmaz, Junyang Cai, Serdar Kadioglu, Bistra Dilkina', 'link': 'https://arxiv.org/abs/2508.06736', 'abstract': "Solving Mixed-Integer Programming (MIP) problems often requires substantial computational resources due to their combinatorial nature. Parallelization has emerged as a critical strategy to accelerate solution times and enhance scalability to tackle large, complex instances. This paper investigates the parallelization capabilities of Balans, a recently proposed multi-armed bandits-based adaptive large neighborhood search for MIPs. While Balans's modular architecture inherently supports parallel exploration of diverse parameter configurations, this potential has not been thoroughly examined. To address this gap, we introduce ParBalans, an extension that leverages both solver-level and algorithmic-level parallelism to improve performance on challenging MIP instances. Our experimental results demonstrate that ParBalans exhibits competitive performance compared to the state-of-the-art commercial solver Gurobi, particularly on hard optimization benchmarks.", 'abstract_zh': '基于多臂老虎机的自适应大规模邻域搜索方法求解混合整数规划问题的并行化研究', 'title_zh': 'ParBalans: 基于并行多臂老虎机的自适应大规模邻域搜索'}
{'arxiv_id': 'arXiv:2508.06716', 'title': 'GLIDR: Graph-Like Inductive Logic Programming with Differentiable Reasoning', 'authors': 'Blair Johnson, Clayton Kerce, Faramarz Fekri', 'link': 'https://arxiv.org/abs/2508.06716', 'abstract': 'Differentiable inductive logic programming (ILP) techniques have proven effective at finding approximate rule-based solutions to link prediction and node classification problems on knowledge graphs; however, the common assumption of chain-like rule structure can hamper the performance and interpretability of existing approaches. We introduce GLIDR, a differentiable rule learning method that models the inference of logic rules with more expressive syntax than previous methods. GLIDR uses a differentiable message passing inference algorithm that generalizes previous chain-like rule learning methods to allow rules with features like branches and cycles. GLIDR has a simple and expressive rule search space which is parameterized by a limit on the maximum number of free variables that may be included in a rule. Explicit logic rules can be extracted from the weights of a GLIDR model for use with symbolic solvers. We demonstrate that GLIDR can significantly outperform existing rule learning methods on knowledge graph completion tasks and even compete with embedding methods despite the inherent disadvantage of being a structure-only prediction method. We show that rules extracted from GLIDR retain significant predictive performance, and that GLIDR is highly robust to training data noise. Finally, we demonstrate that GLIDR can be chained with deep neural networks and optimized end-to-end for rule learning on arbitrary data modalities.', 'abstract_zh': '不同iable 基于逻辑的规则学习方法：GLIDR 及其在知识图谱补全任务中的应用', 'title_zh': 'GLIDR: 图样型归纳逻辑程序设计与可微推理'}
{'arxiv_id': 'arXiv:2508.06706', 'title': 'Probabilistic Circuits for Knowledge Graph Completion with Reduced Rule Sets', 'authors': 'Jaikrishna Manojkumar Patil, Nathaniel Lee, Al Mehdi Saadat Chowdhury, YooJung Choi, Paulo Shakarian', 'link': 'https://arxiv.org/abs/2508.06706', 'abstract': "Rule-based methods for knowledge graph completion provide explainable results but often require a significantly large number of rules to achieve competitive performance. This can hinder explainability due to overwhelmingly large rule sets. We discover rule contexts (meaningful subsets of rules that work together) from training data and use learned probability distribution (i.e. probabilistic circuits) over these rule contexts to more rapidly achieve performance of the full rule set. Our approach achieves a 70-96% reduction in number of rules used while outperforming baseline by up to 31$\\times$ when using equivalent minimal number of rules and preserves 91% of peak baseline performance even when comparing our minimal rule sets against baseline's full rule sets. We show that our framework is grounded in well-known semantics of probabilistic logic, does not require independence assumptions, and that our tractable inference procedure provides both approximate lower bounds and exact probability of a given query. The efficacy of our method is validated by empirical studies on 8 standard benchmark datasets where we show competitive performance by using only a fraction of the rules required by AnyBURL's standard inference method, the current state-of-the-art for rule-based knowledge graph completion. This work may have further implications for general probabilistic reasoning over learned sets of rules.", 'abstract_zh': '基于规则的方法在知识图嵌填中可以提供可解释的结果，但往往需要大量的规则才能达到竞争力的表现，这可能会因规则数量过于庞大而阻碍可解释性。我们从训练数据中发现规则上下文（有意义的规则子集），并通过学习规则上下文的概率分布（即概率电路）来更快地实现全规则集的表现。我们的方法在使用等效最小规则数量时，性能提高了31倍，同时减少了70-96%的规则数量，并且在与基线使用完整规则集的比较中，保持了91%的峰值基线性能。我们展示了我们的框架基于已知的概率逻辑语义，不需要独立性假设，并且我们的可计算推理过程提供给定查询的近似下界和精确概率。通过在8个标准基准数据集上进行实证研究，我们验证了该方法的有效性，并且仅使用AnyBURL标准推理方法所需规则的一小部分，就可以达到竞争力的表现。这项工作可能对一般概率推理在学习规则集上的应用具有进一步的启示意义。', 'title_zh': '基于减少规则集的概率电路的知识图谱完成'}
{'arxiv_id': 'arXiv:2508.06674', 'title': 'Zero-Shot Cellular Trajectory Map Matching', 'authors': 'Weijie Shi, Yue Cui, Hao Chen, Jiaming Li, Mengze Li, Jia Zhu, Jiajie Xu, Xiaofang Zhou', 'link': 'https://arxiv.org/abs/2508.06674', 'abstract': 'Cellular Trajectory Map-Matching (CTMM) aims to align cellular location sequences to road networks, which is a necessary preprocessing in location-based services on web platforms like Google Maps, including navigation and route optimization. Current approaches mainly rely on ID-based features and region-specific data to learn correlations between cell towers and roads, limiting their adaptability to unexplored areas. To enable high-accuracy CTMM without additional training in target regions, Zero-shot CTMM requires to extract not only region-adaptive features, but also sequential and location uncertainty to alleviate positioning errors in cellular data. In this paper, we propose a pixel-based trajectory calibration assistant for zero-shot CTMM, which takes advantage of transferable geospatial knowledge to calibrate pixelated trajectory, and then guide the path-finding process at the road network level. To enhance knowledge sharing across similar regions, a Gaussian mixture model is incorporated into VAE, enabling the identification of scenario-adaptive experts through soft clustering. To mitigate high positioning errors, a spatial-temporal awareness module is designed to capture sequential features and location uncertainty, thereby facilitating the inference of approximate user positions. Finally, a constrained path-finding algorithm is employed to reconstruct the road ID sequence, ensuring topological validity within the road network. This process is guided by the calibrated trajectory while optimizing for the shortest feasible path, thus minimizing unnecessary detours. Extensive experiments demonstrate that our model outperforms existing methods in zero-shot CTMM by 16.8\\%.', 'abstract_zh': '细胞轨迹路径匹配匹配（CTMM）旨在将细胞驻留序列对齐到道路网络，这 是基于位置的服务在平台如例如谷歌地图进行路路上和路径优化所必需的预处理。当前的方法主要依赖于基于标识符的特征和特定地区的数据来推导出蜂窝基站在上 与道路之间的关联，这限制了其对未探索区域的适应性性。为了实现高准确度度的CTMM，在需要在特定区域内进行额外的训练。为此，我们提出了一种基于像素的轨迹校准助手用于零样本CTMM，它利用转移学习地理空间知识来对校准像素化的轨迹，然后在道路网络层面上进行基于预测的校准过程以增强地理位置的知识跨相似区域的知识读水平。通过将高斯混合模型纳入变分器中，这使得通过柔和的聚类识别出本地适应性的专家成为可能从而减轻高精度误差。为了捕捉序列特征和位置不确定性，设计了一种时空意识层面来。通过这样增强了的推理，可以估计出近位置。最后，利用约束优化算法来重构道路ID序列以确保在道路网络上的该路径的有效性性。此过程以校准的轨迹为准通知优化以寻找最短的实际路径从而最小化不必要的偏离离。广泛的实验显示了此方法在零样本CTMM中优于现有方法16.8%百分比。', 'title_zh': '零样本细胞轨迹图匹配'}
{'arxiv_id': 'arXiv:2508.06668', 'title': 'Formal Concept Analysis: a Structural Framework for Variability Extraction and Analysis', 'authors': 'Jessie Galasso', 'link': 'https://arxiv.org/abs/2508.06668', 'abstract': 'Formal Concept Analysis (FCA) is a mathematical framework for knowledge representation and discovery. It performs a hierarchical clustering over a set of objects described by attributes, resulting in conceptual structures in which objects are organized depending on the attributes they share. These conceptual structures naturally highlight commonalities and variabilities among similar objects by categorizing them into groups which are then arranged by similarity, making it particularly appropriate for variability extraction and analysis. Despite the potential of FCA, determining which of its properties can be leveraged for variability-related tasks (and how) is not always straightforward, partly due to the mathematical orientation of its foundational literature. This paper attempts to bridge part of this gap by gathering a selection of properties of the framework which are essential to variability analysis, and how they can be used to interpret diverse variability information within the resulting conceptual structures.', 'abstract_zh': '形式概念分析（FCA）是一种用于知识表示和发现的数学框架。通过对具有属性描述的一组对象进行层次聚类，形成概念结构，这些概念结构根据对象共享的属性对对象进行组织，自然地突显相似对象之间的共同点和变异性，通过将它们归类成组并按相似性排序，使之特别适用于变异性提取和分析。尽管形式概念分析具有潜力，但确定哪些属性适用于与变异性相关的任务（以及如何利用它们）并不总是那么容易，部分原因是其基础文献的数学导向。本文尝试通过收集对变异性分析至关重要的框架属性及其在所得概念结构中解释多样变异性信息的方法来填补这一缺口。', 'title_zh': '形式概念分析：变异性提取与分析的结构性框架'}
{'arxiv_id': 'arXiv:2508.06585', 'title': 'CountQA: How Well Do MLLMs Count in the Wild?', 'authors': 'Jayant Sravan Tamarapalli, Rynaa Grover, Nilay Pande, Sahiti Yerramilli', 'link': 'https://arxiv.org/abs/2508.06585', 'abstract': 'Multimodal Large Language Models (MLLMs) demonstrate remarkable fluency in understanding visual scenes, yet they exhibit a critical lack in a fundamental cognitive skill: object counting. This blind spot severely limits their reliability in real-world applications. To date, this capability has been largely unevaluated in complex scenarios, as existing benchmarks either feature sparse object densities or are confined to specific visual domains, failing to test models under realistic conditions. Addressing this gap, we introduce CountQA, a challenging new benchmark designed to probe this deficiency. Comprising over 1,500 question-answer pairs, CountQA features real-world images with high object density, clutter, and occlusion. We investigate this weakness by evaluating 15 prominent MLLMs on the CountQA benchmark and reveal that the top-performing model achieves a mere 42.9% accuracy, with performance declining as object counts rise. By providing a dedicated benchmark to diagnose and rectify this core weakness, CountQA paves the way for a new generation of MLLMs that are not only descriptively fluent but also numerically grounded and spatially aware. We will open-source the dataset and code upon paper acceptance to foster further research.', 'abstract_zh': '多模态大型语言模型在物体计数能力上存在缺陷：CountQA 新挑战', 'title_zh': 'CountQA: MLLMs在真实世界中的计数能力如何？'}
{'arxiv_id': 'arXiv:2508.06571', 'title': 'IRL-VLA: Training an Vision-Language-Action Policy via Reward World Model', 'authors': 'Anqing Jiang, Yu Gao, Yiru Wang, Zhigang Sun, Shuo Wang, Yuwen Heng, Hao Sun, Shichen Tang, Lijuan Zhu, Jinhao Chai, Jijun Wang, Zichong Gu, Hao Jiang, Li Sun', 'link': 'https://arxiv.org/abs/2508.06571', 'abstract': 'Vision-Language-Action (VLA) models have demonstrated potential in autonomous driving. However, two critical challenges hinder their development: (1) Existing VLA architectures are typically based on imitation learning in open-loop setup which tends to capture the recorded behaviors in the dataset, leading to suboptimal and constrained performance, (2) Close-loop training relies heavily on high-fidelity sensor simulation, where domain gaps and computational inefficiencies pose significant barriers. In this paper, we introduce IRL-VLA, a novel close-loop Reinforcement Learning via \\textbf{I}nverse \\textbf{R}einforcement \\textbf{L}earning reward world model with a self-built VLA approach. Our framework proceeds in a three-stage paradigm: In the first stage, we propose a VLA architecture and pretrain the VLA policy via imitation learning. In the second stage, we construct a lightweight reward world model via inverse reinforcement learning to enable efficient close-loop reward computation. To further enhance planning performance, finally, we design specialized reward world model guidence reinforcement learning via PPO(Proximal Policy Optimization) to effectively balance the safety incidents, comfortable driving, and traffic efficiency. Our approach achieves state-of-the-art performance in NAVSIM v2 end-to-end driving benchmark, 1st runner up in CVPR2025 Autonomous Grand Challenge. We hope that our framework will accelerate VLA research in close-loop autonomous driving.', 'abstract_zh': 'Vision-Language-Action (VLA)模型在自动驾驶中展现出潜在应用价值。然而，其开发面临两大关键挑战：（1）现有的VLA架构通常基于开环条件下的模仿学习，容易捕捉数据集中记录的行为，导致性能欠佳且受限；（2）闭环训练依赖于高保真传感器模拟，其中领域偏差和计算效率问题构成了重大障碍。本文介绍了IRL-VLA，一种基于逆强化学习的新型闭环强化学习框架，结合自建的VLA方法。本框架采用三阶段流程：首先，提出VLA架构并通过模仿学习预训练VLA策略；其次，通过逆强化学习构建轻量级奖励世界模型，以实现高效的闭环奖励计算；最后，设计基于PPO的专业奖励世界模型指导强化学习，以有效平衡安全性、舒适性和交通效率。我们的方法在NAVSIM v2端到端驾驶基准测试中取得了最先进的性能，并在CVPR2025自主挑战赛中获得亚军。我们希望本框架能够加速VLA在闭环自动驾驶中的研究。', 'title_zh': 'IRL-VLA: 通过奖励世界模型训练视觉-语言-行动策略'}
{'arxiv_id': 'arXiv:2508.06569', 'title': 'Operationalizing Serendipity: Multi-Agent AI Workflows for Enhanced Materials Characterization with Theory-in-the-Loop', 'authors': 'Lance Yao, Suman Samantray, Ayana Ghosh, Kevin Roccapriore, Libor Kovarik, Sarah Allec, Maxim Ziatdinov', 'link': 'https://arxiv.org/abs/2508.06569', 'abstract': "The history of science is punctuated by serendipitous discoveries, where unexpected observations, rather than targeted hypotheses, opened new fields of inquiry. While modern autonomous laboratories excel at accelerating hypothesis testing, their optimization for efficiency risks overlooking these crucial, unplanned findings. To address this gap, we introduce SciLink, an open-source, multi-agent artificial intelligence framework designed to operationalize serendipity in materials research by creating a direct, automated link between experimental observation, novelty assessment, and theoretical simulations. The framework employs a hybrid AI strategy where specialized machine learning models perform quantitative analysis of experimental data, while large language models handle higher-level reasoning. These agents autonomously convert raw data from materials characterization techniques into falsifiable scientific claims, which are then quantitatively scored for novelty against the published literature. We demonstrate the framework's versatility across diverse research scenarios, showcasing its application to atomic-resolution and hyperspectral data, its capacity to integrate real-time human expert guidance, and its ability to close the research loop by proposing targeted follow-up experiments. By systematically analyzing all observations and contextualizing them, SciLink provides a practical framework for AI-driven materials research that not only enhances efficiency but also actively cultivates an environment ripe for serendipitous discoveries, thereby bridging the gap between automated experimentation and open-ended scientific exploration.", 'abstract_zh': '科学史上的偶然发现由意外观察而非目标假设推动了新的研究领域。虽然现代自主实验室在加速假设测试方面表现出色，但它们的高效优化可能导致忽略这些重要的、计划外的发现。为解决这一问题，我们引入了SciLink，这是一个开源的多智能体人工智能框架，旨在通过直接、自动地将实验观察、新颖性评估与理论模拟连接起来，在材料研究中实现偶然性的操作化。该框架采用混合AI策略，其中专门的机器学习模型执行实验数据的定量分析，而大型语言模型则处理高层次的推理。这些智能体自主地将材料表征技术的原始数据转换为可验证的科学主张，然后与已出版文献进行定量新颖性评分。我们展示了该框架在各种研究场景中的灵活性，展示了其在原子分辨率和超谱数据上的应用、实时整合人类专家指导的能力，以及通过提出针对性的后续实验来关闭研究循环的能力。通过系统分析所有观察结果并赋予其上下文，SciLink提供了一个基于人工智能的材料研究框架，不仅提升了效率，还积极营造了有利于偶然发现的环境，从而弥合了自动化实验与开放式科学探索之间的鸿沟。', 'title_zh': '将偶然性操作化：带理论循环的多智能体AI工作流以优化材料表征'}
{'arxiv_id': 'arXiv:2508.06559', 'title': 'Solving Pasur Using GPU-Accelerated Counterfactual Regret Minimization', 'authors': 'Sina Baghal', 'link': 'https://arxiv.org/abs/2508.06559', 'abstract': 'Pasur is a fishing card game played over six rounds and is played similarly to games such as Cassino and Scopa, and Bastra. This paper introduces a CUDA-accelerated computational framework for simulating Pasur, emphasizing efficient memory management. We use our framework to compute near-Nash equilibria via Counterfactual Regret Minimization (CFR), a well-known algorithm for solving large imperfect-information games.\nSolving Pasur presents unique challenges due to its intricate rules and the large size of its game tree. We handle rule complexity using PyTorch CUDA tensors and to address the memory-intensive nature of the game, we decompose the game tree into two key components: (1) actual game states, and (2) inherited scores from previous rounds. We construct the Full Game Tree by pairing card states with accumulated scores in the Unfolding Process. This design reduces memory overhead by storing only essential strategy values and node connections. To further manage computational complexity, we apply a round-by-round backward training strategy, starting from the final round and recursively propagating average utilities to earlier stages. Our approach constructs the complete game tree, which on average consists of over $10^9$ nodes. We provide detailed implementation snippets.\nAfter computing a near-Nash equilibrium strategy, we train a tree-based model to predict these strategies for use during gameplay. We then estimate the fair value of each deck through large-scale self-play between equilibrium strategies by simulating, for instance, 10,000 games per matchup, executed in parallel using GPU acceleration.\nSimilar frameworks can be extended to other reinforcement learning algorithms where the action tree naturally decomposes into multiple rounds such as turn-based strategy games or sequential trading decisions in financial markets.', 'abstract_zh': '帕苏尔是一种需要进行六轮的钓鱼纸牌游戏，类似于卡松、斯科帕和巴斯特等游戏。本文介绍了一种基于CUDA加速的计算框架来模拟帕苏尔，强调高效内存管理。我们使用该框架通过逆向遗憾最小化（CFR）算法计算接近纳什均衡策略。解决帕苏尔具有独特的挑战性，原因在于其复杂的规则和庞大的博弈树规模。我们通过使用PyTorch CUDA张量处理规则复杂性，并通过将游戏树分解为两个关键部分来应对内存密集型问题：（1）实际游戏状态，（2）继承自之前轮次的得分。在逐步展开过程中，我们构建完整的博弈树，通过将牌的状态与累积得分配对。这种设计减少了内存开销，仅存储必要的策略值和节点连接。为了进一步管理计算复杂性，我们采用轮次递归反向训练策略，从最后一轮开始，递归地将平均收益传播到早期阶段。我们的方法构建了完整的博弈树，平均包含超过 \\(10^9\\) 个节点。我们提供了详细的实现片段。\n之后，我们训练了一种基于树的模型来预测这些策略，用于实际游戏中的应用。然后，通过均衡策略之间的大量自我博弈来估算每副牌的公平价值，例如，每场比赛模拟10,000局游戏，并使用GPU加速并行执行。\n类似的框架可以扩展到其他强化学习算法，其中动作树自然分解为多轮次，例如回合制策略游戏或金融市场中的顺序交易决策。', 'title_zh': '使用GPU加速反事实遗憾最小化解决帕苏尔问题'}
{'arxiv_id': 'arXiv:2508.08244', 'title': 'Cut2Next: Generating Next Shot via In-Context Tuning', 'authors': 'Jingwen He, Hongbo Liu, Jiajun Li, Ziqi Huang, Yu Qiao, Wanli Ouyang, Ziwei Liu', 'link': 'https://arxiv.org/abs/2508.08244', 'abstract': 'Effective multi-shot generation demands purposeful, film-like transitions and strict cinematic continuity. Current methods, however, often prioritize basic visual consistency, neglecting crucial editing patterns (e.g., shot/reverse shot, cutaways) that drive narrative flow for compelling storytelling. This yields outputs that may be visually coherent but lack narrative sophistication and true cinematic integrity. To bridge this, we introduce Next Shot Generation (NSG): synthesizing a subsequent, high-quality shot that critically conforms to professional editing patterns while upholding rigorous cinematic continuity. Our framework, Cut2Next, leverages a Diffusion Transformer (DiT). It employs in-context tuning guided by a novel Hierarchical Multi-Prompting strategy. This strategy uses Relational Prompts to define overall context and inter-shot editing styles. Individual Prompts then specify per-shot content and cinematographic attributes. Together, these guide Cut2Next to generate cinematically appropriate next shots. Architectural innovations, Context-Aware Condition Injection (CACI) and Hierarchical Attention Mask (HAM), further integrate these diverse signals without introducing new parameters. We construct RawCuts (large-scale) and CuratedCuts (refined) datasets, both with hierarchical prompts, and introduce CutBench for evaluation. Experiments show Cut2Next excels in visual consistency and text fidelity. Crucially, user studies reveal a strong preference for Cut2Next, particularly for its adherence to intended editing patterns and overall cinematic continuity, validating its ability to generate high-quality, narratively expressive, and cinematically coherent subsequent shots.', 'abstract_zh': '有效的一次生成多帧需要有针对性的、电影化的过渡和严格的cinematic连续性。然而，当前的方法往往优先考虑基本的视觉一致性，忽视了推动叙述流畅的关键剪辑模式（如正反打镜头、切镜头），从而导致输出可能在视觉上连贯但缺乏叙述上的精致和真正的cinematic完整性。为解决这一问题，我们提出Next Shot Generation (NSG)：合成一个随后的高度质量的镜头，同时严格遵循专业的剪辑模式并保持严格的cinematic连续性。我们的框架Cut2Next利用了一个扩散变换器（DiT），通过一种新颖的层次多提示策略进行上下文调整。该策略使用关系提示来定义整体上下文和镜头间的剪辑风格。个体提示则指定每个镜头的内容和cinematographic属性。这些共同指导Cut2Next生成cinematically合适的后续镜头。架构创新，上下文感知条件注入（CACI）和层次注意掩码（HAM），进一步整合了这些多样信号而不引入新参数。我们构建了RawCuts（大规模）和CuratedCuts（精炼）数据集，两者都包含层次提示，并引入CutBench进行评估。实验结果显示Cut2Next在视觉一致性和文本准确性方面表现出色。重要的是，用户研究显示Cut2Next特别是因为它对预期的剪辑模式的遵守和整体cinematic连续性而受到强烈偏好，从而验证了其生成高质量、表达性强且cinematically连贯的后续镜头的能力。', 'title_zh': 'Cut2Next: 通过上下文调优生成下一-shot内容'}
{'arxiv_id': 'arXiv:2508.08237', 'title': 'VGGSounder: Audio-Visual Evaluations for Foundation Models', 'authors': 'Daniil Zverev, Thaddäus Wiedemer, Ameya Prabhu, Matthias Bethge, Wieland Brendel, A. Sophia Koepke', 'link': 'https://arxiv.org/abs/2508.08237', 'abstract': 'The emergence of audio-visual foundation models underscores the importance of reliably assessing their multi-modal understanding. The VGGSounder dataset is commonly used as a benchmark for evaluation audio-visual classification. However, our analysis identifies several limitations of VGGSounder, including incomplete labelling, partially overlapping classes, and misaligned modalities. These lead to distorted evaluations of auditory and visual capabilities. To address these limitations, we introduce VGGSounder, a comprehensively re-annotated, multi-label test set that extends VGGSound and is specifically designed to evaluate audio-visual foundation models. VGGSounder features detailed modality annotations, enabling precise analyses of modality-specific performance. Furthermore, we reveal model limitations by analysing performance degradation when adding another input modality with our new modality confusion metric.', 'abstract_zh': '音频-视觉基础模型的出现凸显了可靠评估其多模态理解的重要性。VGGSounder数据集常用于评估音频-视觉分类。然而，我们的分析发现VGGSounder存在多项局限，包括标签不完整、部分类别重叠以及模态不一致。这些局限导致了对听觉和视觉能力评估的扭曲。为解决这些问题，我们提出了VGGSounder，这是一个全面重新注释的多标签测试集，扩展了VGGSound，专门用于评估音频-视觉基础模型。VGGSounder包含详细的模态注释，便于精确分析模态特定性能。此外，我们通过新的模态混淆度量分析了添加另一个输入模态时性能下降的情况，揭示了模型的局限性。', 'title_zh': 'VGGSounder: 视听基础模型评估'}
{'arxiv_id': 'arXiv:2508.08228', 'title': 'LL3M: Large Language 3D Modelers', 'authors': 'Sining Lu, Guan Chen, Nam Anh Dinh, Itai Lang, Ari Holtzman, Rana Hanocka', 'link': 'https://arxiv.org/abs/2508.08228', 'abstract': 'We present LL3M, a multi-agent system that leverages pretrained large language models (LLMs) to generate 3D assets by writing interpretable Python code in Blender. We break away from the typical generative approach that learns from a collection of 3D data. Instead, we reformulate shape generation as a code-writing task, enabling greater modularity, editability, and integration with artist workflows. Given a text prompt, LL3M coordinates a team of specialized LLM agents to plan, retrieve, write, debug, and refine Blender scripts that generate and edit geometry and appearance. The generated code works as a high-level, interpretable, human-readable, well-documented representation of scenes and objects, making full use of sophisticated Blender constructs (e.g. B-meshes, geometry modifiers, shader nodes) for diverse, unconstrained shapes, materials, and scenes. This code presents many avenues for further agent and human editing and experimentation via code tweaks or procedural parameters. This medium naturally enables a co-creative loop in our system: agents can automatically self-critique using code and visuals, while iterative user instructions provide an intuitive way to refine assets. A shared code context across agents enables awareness of previous attempts, and a retrieval-augmented generation knowledge base built from Blender API documentation, BlenderRAG, equips agents with examples, types, and functions empowering advanced modeling operations and code correctness. We demonstrate the effectiveness of LL3M across diverse shape categories, style and material edits, and user-driven refinements. Our experiments showcase the power of code as a generative and interpretable medium for 3D asset creation. Our project page is at this https URL.', 'abstract_zh': '我们提出LL3M，这是一种利用预训练大型语言模型（LLMs）通过在Blender中编写可解释的Python代码来生成3D资产的多agent系统。我们摒弃了传统的从3D数据集合中学习的生成方法，而是将形状生成重新定义为代码编写任务，从而实现更高的模块化、可编辑性和与艺术家工作流程的整合。给定一个文本提示，LL3M协调一组专门的LLM代理，计划、检索、编写、调试和优化Blender脚本以生成和编辑几何形状和外观。生成的代码作为高层、可解释、易于理解、具有详尽注释的场景和对象表示，充分利用了高级Blender构建块（如B-网格、几何修改器、着色节点）生成形式多样的、不受约束的形状、材料和场景。这种代码通过代码调整或过程参数提供了进一步的代理和人类编辑与实验的多途径。这种媒介自然地使我们的系统进入一个共創循环：代理可以自动使用代码和视觉进行自我批评，而迭代用户指令提供了一种直观的方式来细化资产。代理之间的共享代码上下文使代理能够意识到之前的尝试，并结合Blender API文档构建的检索增强生成知识库（BlenderRAG）中的示例、类型和功能，为高级建模操作和代码正确性赋能。我们在不同形状类别、风格和材料编辑以及用户驱动的细化方面展示了LL3M的有效性。我们的实验展示了代码作为一种生成和可解释的3D资产创作媒介的力量。项目页面位于此链接：this https URL。', 'title_zh': 'LL3M: 大型语言3D建模器'}
{'arxiv_id': 'arXiv:2508.08227', 'title': 'OMGSR: You Only Need One Mid-timestep Guidance for Real-World Image Super-Resolution', 'authors': 'Zhiqiang Wu, Zhaomang Sun, Tong Zhou, Bingtao Fu, Ji Cong, Yitong Dong, Huaqi Zhang, Xuan Tang, Mingsong Chen, Xian Wei', 'link': 'https://arxiv.org/abs/2508.08227', 'abstract': 'Denoising Diffusion Probabilistic Models (DDPM) and Flow Matching (FM) generative models show promising potential for one-step Real-World Image Super-Resolution (Real-ISR). Recent one-step Real-ISR models typically inject a Low-Quality (LQ) image latent distribution at the initial timestep. However, a fundamental gap exists between the LQ image latent distribution and the Gaussian noisy latent distribution, limiting the effective utilization of generative priors. We observe that the noisy latent distribution at DDPM/FM mid-timesteps aligns more closely with the LQ image latent distribution. Based on this insight, we present One Mid-timestep Guidance Real-ISR (OMGSR), a universal framework applicable to DDPM/FM-based generative models. OMGSR injects the LQ image latent distribution at a pre-computed mid-timestep, incorporating the proposed Latent Distribution Refinement loss to alleviate the latent distribution gap. We also design the Overlap-Chunked LPIPS/GAN loss to eliminate checkerboard artifacts in image generation. Within this framework, we instantiate OMGSR for DDPM/FM-based generative models with two variants: OMGSR-S (SD-Turbo) and OMGSR-F (FLUX.1-dev). Experimental results demonstrate that OMGSR-S/F achieves balanced/excellent performance across quantitative and qualitative metrics at 512-resolution. Notably, OMGSR-F establishes overwhelming dominance in all reference metrics. We further train a 1k-resolution OMGSR-F to match the default resolution of FLUX.1-dev, which yields excellent results, especially in the details of the image generation. We also generate 2k-resolution images by the 1k-resolution OMGSR-F using our two-stage Tiled VAE & Diffusion.', 'abstract_zh': 'Denoising Diffusion Probabilistic Models (DDPM)和Flow Matching (FM)生成模型在一步实现真实世界图像超分辨率（Real-ISR）中展现出有前景的潜力。我们提出了一种名为One Mid-timestep Guidance Real-ISR (OMGSR)的通用框架，适用于基于DDPM/FM的生成模型。OMGSR在预计算的中间时间步注入低质量图像潜在分布，并引入潜在分布精炼损失以缓解潜在分布差距。此外，我们设计了重叠分块LPIPS/GAN损失以消除图像生成中的棋盘格 artifacts。在该框架下，我们分别实现了基于DDPM/FM的OMGSR-S (SD-Turbo)和OMGSR-F (FLUX.1-dev)两种变体。实验结果表明，OMGSR-S/F在512分辨率下在定量和定性指标上表现均衡/出色。特别地，OMGSR-F在所有参考指标上表现出压倒性的优势。我们进一步训练了1k分辨率的OMGSR-F以匹配FLUX.1-dev的默认分辨率，取得了优异的结果，尤其是在图像生成的细节上。我们还使用我们的两阶段Tiled VAE & Diffusion生成了2k分辨率的图像。', 'title_zh': 'OMGSR: 你只需要一次中间时间步指导即可实现真实世界图像超分辨率'}
{'arxiv_id': 'arXiv:2508.08224', 'title': 'Capabilities of GPT-5 on Multimodal Medical Reasoning', 'authors': 'Shansong Wang, Mingzhe Hu, Qiang Li, Mojtaba Safari, Xiaofeng Yang', 'link': 'https://arxiv.org/abs/2508.08224', 'abstract': "Recent advances in large language models (LLMs) have enabled general-purpose systems to perform increasingly complex domain-specific reasoning without extensive fine-tuning. In the medical domain, decision-making often requires integrating heterogeneous information sources, including patient narratives, structured data, and medical images. This study positions GPT-5 as a generalist multimodal reasoner for medical decision support and systematically evaluates its zero-shot chain-of-thought reasoning performance on both text-based question answering and visual question answering tasks under a unified protocol. We benchmark GPT-5, GPT-5-mini, GPT-5-nano, and GPT-4o-2024-11-20 against standardized splits of MedQA, MedXpertQA (text and multimodal), MMLU medical subsets, USMLE self-assessment exams, and VQA-RAD. Results show that GPT-5 consistently outperforms all baselines, achieving state-of-the-art accuracy across all QA benchmarks and delivering substantial gains in multimodal reasoning. On MedXpertQA MM, GPT-5 improves reasoning and understanding scores by +29.62% and +36.18% over GPT-4o, respectively, and surpasses pre-licensed human experts by +24.23% in reasoning and +29.40% in understanding. In contrast, GPT-4o remains below human expert performance in most dimensions. A representative case study demonstrates GPT-5's ability to integrate visual and textual cues into a coherent diagnostic reasoning chain, recommending appropriate high-stakes interventions. Our results show that, on these controlled multimodal reasoning benchmarks, GPT-5 moves from human-comparable to above human-expert performance. This improvement may substantially inform the design of future clinical decision-support systems.", 'abstract_zh': 'Recent advances in大型语言模型(LLMs)使通用系统能够在无需大量微调的情况下执行日益复杂的领域特定推理。在医学领域，决策往往需要整合异构信息源，包括患者叙述、结构化数据和医学影像。本研究将GPT-5定位为医学决策支持的一般主义多模态推理者，并在统一协议下系统评估其零样本链式推理性能，涵盖基于文本的问题回答和多模态视觉问答任务。我们使用标准化划分的MedQA、MedXpertQA（文本和多模态）、MMLU医学子集、USMLE自我评估考试以及VQA-RAD进行基准测试。结果显示，GPT-5在所有问答基准测试中保持了一致的领先优势，实现了最先进的准确率，并在多模态推理方面取得了显著进步。在MedXpertQA MM任务中，GPT-5分别较GPT-4o提高了29.62%的推理分数和36.18%的理解分数，并在推理和理解方面分别超过了预许可的人类专家24.23%和29.40%。相比之下，GPT-4o在大多数维度上仍低于人类专家的表现。一项代表性的案例研究展示了GPT-5整合视觉和文本线索进行一致诊断推理链的能力，推荐合适的高风险干预措施。我们的结果显示，在这些受控的多模态推理基准测试中，GPT-5从与人类相当的性能提升到了超越人类专家的水平。这一进步可能对未来的临床决策支持系统设计产生重要影响。', 'title_zh': 'GPT-5在多模态医疗推理方面的能力'}
{'arxiv_id': 'arXiv:2508.08222', 'title': 'Multi-head Transformers Provably Learn Symbolic Multi-step Reasoning via Gradient Descent', 'authors': 'Tong Yang, Yu Huang, Yingbin Liang, Yuejie Chi', 'link': 'https://arxiv.org/abs/2508.08222', 'abstract': 'Transformers have demonstrated remarkable capabilities in multi-step reasoning tasks. However, understandings of the underlying mechanisms by which they acquire these abilities through training remain limited, particularly from a theoretical standpoint. This work investigates how transformers learn to solve symbolic multi-step reasoning problems through chain-of-thought processes, focusing on path-finding in trees. We analyze two intertwined tasks: a backward reasoning task, where the model outputs a path from a goal node to the root, and a more complex forward reasoning task, where the model implements two-stage reasoning by first identifying the goal-to-root path and then reversing it to produce the root-to-goal path. Our theoretical analysis, grounded in the dynamics of gradient descent, shows that trained one-layer transformers can provably solve both tasks with generalization guarantees to unseen trees. In particular, our multi-phase training dynamics for forward reasoning elucidate how different attention heads learn to specialize and coordinate autonomously to solve the two subtasks in a single autoregressive path. These results provide a mechanistic explanation of how trained transformers can implement sequential algorithmic procedures. Moreover, they offer insights into the emergence of reasoning abilities, suggesting that when tasks are structured to take intermediate chain-of-thought steps, even shallow multi-head transformers can effectively solve problems that would otherwise require deeper architectures.', 'abstract_zh': 'Transformer在多步推理任务中展示了 remarkable 能力，但对其通过训练获得这些能力的具体机制的理解仍有限，尤其是在理论层面。本文探讨了Transformer通过链式思考过程学习解决符号多步推理问题的方式，重点关注树结构中的路径查找。我们分析了两个相互交织的任务：一个反向推理任务，模型输出从目标节点到根节点的路径；一个更为复杂的正向推理任务，模型首先识别目标到根节点的路径，然后逆转该路径生成根节点到目标节点的路径。基于梯度下降动力学的理论分析表明，训练后的单层Transformer能够在未见过的树结构上证明地解决这两个任务。特别是，我们为正向推理的多阶段训练动态阐明了不同注意力头如何自主地学习特化和协调，以在同一自回归路径中解决两个子任务。这些结果提供了关于训练好的Transformer如何实施序列算法过程的机制性解释。此外，它们还为推理能力的涌现提供了见解，表明当任务结构化为包含中间链式思考步骤时，即使是浅层多头Transformer也能有效解决原本需要更深架构才能解决的问题。', 'title_zh': '多头变换器通过梯度下降证明能够学习符号多步推理'}
{'arxiv_id': 'arXiv:2508.08211', 'title': 'SAEMark: Multi-bit LLM Watermarking with Inference-Time Scaling', 'authors': 'Zhuohao Yu, Xingru Jiang, Weizheng Gu, Yidong Wang, Shikun Zhang, Wei Ye', 'link': 'https://arxiv.org/abs/2508.08211', 'abstract': "Watermarking LLM-generated text is critical for content attribution and misinformation prevention. However, existing methods compromise text quality, require white-box model access and logit manipulation. These limitations exclude API-based models and multilingual scenarios. We propose SAEMark, a general framework for post-hoc multi-bit watermarking that embeds personalized messages solely via inference-time, feature-based rejection sampling without altering model logits or requiring training. Our approach operates on deterministic features extracted from generated text, selecting outputs whose feature statistics align with key-derived targets. This framework naturally generalizes across languages and domains while preserving text quality through sampling LLM outputs instead of modifying. We provide theoretical guarantees relating watermark success probability and compute budget that hold for any suitable feature extractor. Empirically, we demonstrate the framework's effectiveness using Sparse Autoencoders (SAEs), achieving superior detection accuracy and text quality. Experiments across 4 datasets show SAEMark's consistent performance, with 99.7% F1 on English and strong multi-bit detection accuracy. SAEMark establishes a new paradigm for scalable watermarking that works out-of-the-box with closed-source LLMs while enabling content attribution.", 'abstract_zh': '水印嵌入LLM生成的文本对于内容归属和虚假信息防治至关重要。然而，现有方法会牺牲文本质量、需要白盒模型访问和对logit的操作。这些限制排除了API基于的模型和多语言场景。我们提出SAEMark，这是一种通用框架，用于后嵌入多比特水印，仅通过推理时、基于特征的拒绝采样嵌入个性化信息，无需更改模型logit或进行训练。该方法通过提取生成文本的确定性特征来选择特征统计与键导出目标相匹配的输出。该框架在语言和领域上自然泛化，通过采样而不是修改来保留文本质量。我们提供了与任何合适的特征提取器相关的水印成功概率和计算预算的理论保证。实验中，我们使用稀疏自编码器（SAEs）展示了该框架的有效性，实现了更高的检测准确率和文本质量。横跨4个数据集的实验显示SAEMark具有一致性能，其在英语上达到了99.7%的F1值，并且在多比特检测方面表现出色。SAEMark为可无缝应用于封闭源LLM的可扩展水印嵌入设定了新的范式，同时能够实现内容归属。', 'title_zh': 'SAEMark：推理时可缩放的多比特大语言模型水印技术'}
{'arxiv_id': 'arXiv:2508.08204', 'title': 'Human-Alignment and Calibration of Inference-Time Uncertainty in Large Language Models', 'authors': 'Kyle Moore, Jesse Roberts, Daryl Watson', 'link': 'https://arxiv.org/abs/2508.08204', 'abstract': 'There has been much recent interest in evaluating large language models for uncertainty calibration to facilitate model control and modulate user trust. Inference time uncertainty, which may provide a real-time signal to the model or external control modules, is particularly important for applying these concepts to improve LLM-user experience in practice. While many of the existing papers consider model calibration, comparatively little work has sought to evaluate how closely model uncertainty aligns to human uncertainty. In this work, we evaluate a collection of inference-time uncertainty measures, using both established metrics and novel variations, to determine how closely they align with both human group-level uncertainty and traditional notions of model calibration. We find that numerous measures show evidence of strong alignment to human uncertainty, even despite the lack of alignment to human answer preference. For those successful metrics, we find moderate to strong evidence of model calibration in terms of both correctness correlation and distributional analysis.', 'abstract_zh': '最近对大型语言模型不确定性校准的评估引起了广泛关注，以便于模型控制并调节用户信任。推理时的不确定性，可能为模型或外部控制模块提供实时信号，对于将这些概念应用于提高大语言模型-用户体验尤为重要。虽然现有的许多论文都考虑了模型校准，但相对较少的研究探讨了模型不确定性与人类不确定性之间的紧密程度。在这项工作中，我们使用既有的指标和新颖的变体评估了一系列推理时的不确定性度量，以确定它们与人类群体级不确定性及传统的模型校准概念之间的吻合程度。我们发现，尽管缺乏对人类答案偏好的一致性，但许多度量标准仍显示出与人类不确定性较强的对齐。对于成功的指标，我们从正确的相关性和分布分析中找到了中等到强的模型校准证据。', 'title_zh': '大型语言模型推理时不确定性的人工校准与校准'}
{'arxiv_id': 'arXiv:2508.08193', 'title': 'Street-Level AI: Are Large Language Models Ready for Real-World Judgments?', 'authors': 'Gaurab Pokharel, Shafkat Farabi, Patrick J. Fowler, Sanmay Das', 'link': 'https://arxiv.org/abs/2508.08193', 'abstract': 'A surge of recent work explores the ethical and societal implications of large-scale AI models that make "moral" judgments. Much of this literature focuses either on alignment with human judgments through various thought experiments or on the group fairness implications of AI judgments. However, the most immediate and likely use of AI is to help or fully replace the so-called street-level bureaucrats, the individuals deciding to allocate scarce social resources or approve benefits. There is a rich history underlying how principles of local justice determine how society decides on prioritization mechanisms in such domains. In this paper, we examine how well LLM judgments align with human judgments, as well as with socially and politically determined vulnerability scoring systems currently used in the domain of homelessness resource allocation. Crucially, we use real data on those needing services (maintaining strict confidentiality by only using local large models) to perform our analyses. We find that LLM prioritizations are extremely inconsistent in several ways: internally on different runs, between different LLMs, and between LLMs and the vulnerability scoring systems. At the same time, LLMs demonstrate qualitative consistency with lay human judgments in pairwise testing. Findings call into question the readiness of current generation AI systems for naive integration in high-stakes societal decision-making.', 'abstract_zh': '大规模AI模型在“道德”判断方面的伦理和社会 implication：基于真实数据的LLM优先级评估与人类判断及社会政治确定的脆弱性评分系统对比研究', 'title_zh': '街景级别的AI：大型语言模型准备好进行现实世界判断了吗？'}
{'arxiv_id': 'arXiv:2508.08180', 'title': 'RedDino: A foundation model for red blood cell analysis', 'authors': 'Luca Zedda, Andrea Loddo, Cecilia Di Ruberto, Carsten Marr', 'link': 'https://arxiv.org/abs/2508.08180', 'abstract': 'Red blood cells (RBCs) are essential to human health, and their precise morphological analysis is important for diagnosing hematological disorders. Despite the promise of foundation models in medical diagnostics, comprehensive AI solutions for RBC analysis remain scarce. We present RedDino, a self-supervised foundation model designed for RBC image analysis. RedDino uses an RBC-specific adaptation of the DINOv2 self-supervised learning framework and is trained on a curated dataset of 1.25 million RBC images from diverse acquisition modalities and sources. Extensive evaluations show that RedDino outperforms existing state-of-the-art models on RBC shape classification. Through assessments including linear probing and nearest neighbor classification, we confirm its strong feature representations and generalization ability. Our main contributions are: (1) a foundation model tailored for RBC analysis, (2) ablation studies exploring DINOv2 configurations for RBC modeling, and (3) a detailed evaluation of generalization performance. RedDino addresses key challenges in computational hematology by capturing nuanced morphological features, advancing the development of reliable diagnostic tools. The source code and pretrained models for RedDino are available at this https URL, and the pretrained models can be downloaded from our Hugging Face collection at this https URL', 'abstract_zh': '红血球（RBC）是人类健康的关键，其精确的形态分析对于诊断血液疾病至关重要。尽管基础模型在医疗诊断中具有前景，但全面的RBC分析人工智能解决方案依然稀缺。我们提出RedDino，一种专门为RBC图像分析设计的自监督基础模型。RedDino采用了一种针对RBC的DINOv2自监督学习框架的特定适应，并在包含多种采集模态和来源的125万张RBC图像的精心策划数据集上进行训练。广泛评估显示，RedDino在RBC形状分类上表现出色，优于现有最先进的模型。通过线性探针和最近邻分类评估，我们验证了其强大的特征表示能力和泛化能力。我们的主要贡献包括：（1）一种针对RBC分析定制的基础模型，（2）DINOv2配置在RBC建模中的消融研究，以及（3）泛化性能的详细评估。RedDino通过捕捉复杂的形态学特征，解决了计算血液学中的关键挑战，推动了可靠诊断工具的发展。RedDino的源代码和预训练模型可在以下网址获取：[此处替换为网址]，预训练模型还可在我们的Hugging Face集合中下载：[此处替换为网址]。', 'title_zh': '红细胞分析的基础模型：RedDino'}
{'arxiv_id': 'arXiv:2508.08177', 'title': 'MedReasoner: Reinforcement Learning Drives Reasoning Grounding from Clinical Thought to Pixel-Level Precision', 'authors': 'Zhonghao Yan, Muxi Diao, Yuxuan Yang, Jiayuan Xu, Kaizhou Zhang, Ruoyan Jing, Lele Yang, Yanxi Liu, Kongming Liang, Zhanyu Ma', 'link': 'https://arxiv.org/abs/2508.08177', 'abstract': 'Accurately grounding regions of interest (ROIs) is critical for diagnosis and treatment planning in medical imaging. While multimodal large language models (MLLMs) combine visual perception with natural language, current medical-grounding pipelines still rely on supervised fine-tuning with explicit spatial hints, making them ill-equipped to handle the implicit queries common in clinical practice. This work makes three core contributions. We first define Unified Medical Reasoning Grounding (UMRG), a novel vision-language task that demands clinical reasoning and pixel-level grounding. Second, we release U-MRG-14K, a dataset of 14K samples featuring pixel-level masks alongside implicit clinical queries and reasoning traces, spanning 10 modalities, 15 super-categories, and 108 specific categories. Finally, we introduce MedReasoner, a modular framework that distinctly separates reasoning from segmentation: an MLLM reasoner is optimized with reinforcement learning, while a frozen segmentation expert converts spatial prompts into masks, with alignment achieved through format and accuracy rewards. MedReasoner achieves state-of-the-art performance on U-MRG-14K and demonstrates strong generalization to unseen clinical queries, underscoring the significant promise of reinforcement learning for interpretable medical grounding.', 'abstract_zh': '准确地定位兴趣区域对于医学影像诊断和治疗规划至关重要。虽然多模态大型语言模型结合了视觉感知和自然语言，但当前的医学定位管道仍依赖于带有显式空间提示的监督微调，这使它们难以处理临床实践中常见的隐式查询。本工作中，我们做出了三项核心贡献。首先，我们定义了统一医学推理定位（UMRG），这是一个新的视图-语言任务，要求临床推理和像素级定位。第二，我们发布了UMRG-14K数据集，包含14000个样本，每个样本都包含了隐式临床查询、推理轨迹和像素级掩码，覆盖了10种模态、15个超类别和108个具体类别。最后，我们引入了MedReasoner，这是一个模块化框架，明确地将推理和分割分离：一个大型语言模型推理器通过强化学习优化，一个冻结的分割专家通过格式和准确率奖励将空间提示转换为掩码。MedReasoner在UMRG-14K上达到了最先进的性能，并展示了强大的泛化能力，用于处理未见过的临床查询，突显了强化学习在可解释医学定位方面的巨大潜力。', 'title_zh': 'MedReasoner: 强化学习驱动从临床思维到像素级精确的推理接地'}
{'arxiv_id': 'arXiv:2508.08172', 'title': 'Neural Logic Networks for Interpretable Classification', 'authors': 'Vincent Perreault, Katsumi Inoue, Richard Labib, Alain Hertz', 'link': 'https://arxiv.org/abs/2508.08172', 'abstract': 'Traditional neural networks have an impressive classification performance, but what they learn cannot be inspected, verified or extracted. Neural Logic Networks on the other hand have an interpretable structure that enables them to learn a logical mechanism relating the inputs and outputs with AND and OR operations. We generalize these networks with NOT operations and biases that take into account unobserved data and develop a rigorous logical and probabilistic modeling in terms of concept combinations to motivate their use. We also propose a novel factorized IF-THEN rule structure for the model as well as a modified learning algorithm. Our method improves the state-of-the-art in Boolean networks discovery and is able to learn relevant, interpretable rules in tabular classification, notably on an example from the medical field where interpretability has tangible value.', 'abstract_zh': '传统的神经网络在分类性能方面表现出色，但其学习的内容无法进行检查、验证或提取。相比之下，神经逻辑网络具有可解释的结构，能够通过AND和OR操作学习输入和输出之间的逻辑机制。我们通过引入NOT操作和考虑未观察数据的偏置，对这些网络进行了泛化，并从概念组合的角度建立严格的逻辑和概率建模，从而促进其应用。我们还为该模型提出了新的因子化的IF-THEN规则结构以及一个修改后的学习算法。我们的方法在布尔网络发现方面达到了最先进的水平，并能够学习相关且可解释的规则，特别是在医疗领域等场景中，解释性具有实际价值。', 'title_zh': '可解释分类的神经逻辑网络'}
{'arxiv_id': 'arXiv:2508.08171', 'title': 'PyVeritas: On Verifying Python via LLM-Based Transpilation and Bounded Model Checking for C', 'authors': 'Pedro Orvalho, Marta Kwiatkowska', 'link': 'https://arxiv.org/abs/2508.08171', 'abstract': 'Python has become the dominant language for general-purpose programming, yet it lacks robust tools for formal verification. In contrast, programmers working in languages such as C benefit from mature model checkers, for example CBMC, which enable exhaustive symbolic reasoning and fault localisation. The inherent complexity of Python, coupled with the verbosity and low-level nature of existing transpilers (e.g., Cython), have historically limited the applicability of formal verification to Python programs.\nIn this paper, we propose PyVeritas, a novel framework that leverages Large Language Models (LLMs) for high-level transpilation from Python to C, followed by bounded model checking and MaxSAT-based fault localisation in the generated C code. PyVeritas enables verification and bug localisation for Python code using existing model checking tools for C. Our empirical evaluation on two Python benchmarks demonstrates that LLM-based transpilation can achieve a high degree of accuracy, up to 80--90% for some LLMs, enabling effective development environment that supports assertion-based verification and interpretable fault diagnosis for small yet non-trivial Python programs.', 'abstract_zh': 'Python虽然已成为通用编程的主要语言，但在形式验证方面缺乏 robust 工具。相比之下，使用C等语言的程序员可以从成熟的模型检查工具（例如CBMC）中受益，这些工具能够进行详尽的符号推理和故障定位。Python固有的复杂性，以及现有转译器（例如Cython）的冗长和低级特性，历史上限制了形式验证在Python程序中的应用。\n\n在本文中，我们提出了PyVeritas，一种利用大型语言模型（LLMs）将高级Python代码转译为C代码的新框架，随后进行有界模型检查和基于MaxSAT的故障定位。PyVeritas允许使用现有的C语言模型检查工具对Python代码进行验证和故障定位。我们对两个Python基准的实证研究表明，基于LLM的转译可以实现较高的准确性，某些LLM的准确率达到80-90%，从而支持基于断言的验证和可解释的故障诊断，适用于小型但非平凡的Python程序。', 'title_zh': 'PyVeritas: 使用基于LLM的转译和C语言有界模型检查验证Python'}
{'arxiv_id': 'arXiv:2508.08163', 'title': 'LPI-RIT at LeWiDi-2025: Improving Distributional Predictions via Metadata and Loss Reweighting with DisCo', 'authors': 'Mandira Sawkar, Samay U. Shetty, Deepak Pandita, Tharindu Cyril Weerasooriya, Christopher M. Homan', 'link': 'https://arxiv.org/abs/2508.08163', 'abstract': 'The Learning With Disagreements (LeWiDi) 2025 shared task is to model annotator disagreement through soft label distribution prediction and perspectivist evaluation, modeling annotators. We adapt DisCo (Distribution from Context), a neural architecture that jointly models item-level and annotator-level label distributions, and present detailed analysis and improvements. In this paper, we extend the DisCo by incorporating annotator metadata, enhancing input representations, and modifying the loss functions to capture disagreement patterns better. Through extensive experiments, we demonstrate substantial improvements in both soft and perspectivist evaluation metrics across three datasets. We also conduct in-depth error and calibration analyses, highlighting the conditions under which improvements occur. Our findings underscore the value of disagreement-aware modeling and offer insights into how system components interact with the complexity of human-annotated data.', 'abstract_zh': 'LeWiDi 2025 共享任务：通过软标签分布预测和视角主义评估建模注释者分歧', 'title_zh': 'LPI-RIT在LeWiDi-2025：通过元数据和DisCo损失重权改进分布预测'}
{'arxiv_id': 'arXiv:2508.08158', 'title': 'Can AI Explanations Make You Change Your Mind?', 'authors': 'Laura Spillner, Rachel Ringe, Robert Porzel, Rainer Malaka', 'link': 'https://arxiv.org/abs/2508.08158', 'abstract': "In the context of AI-based decision support systems, explanations can help users to judge when to trust the AI's suggestion, and when to question it. In this way, human oversight can prevent AI errors and biased decision-making. However, this rests on the assumption that users will consider explanations in enough detail to be able to catch such errors. We conducted an online study on trust in explainable DSS, and were surprised to find that in many cases, participants spent little time on the explanation and did not always consider it in detail. We present an exploratory analysis of this data, investigating what factors impact how carefully study participants consider AI explanations, and how this in turn impacts whether they are open to changing their mind based on what the AI suggests.", 'abstract_zh': '基于AI的决策支持系统中，解释可以帮助用户判断何时信任AI的建议，何时质疑它。这样，人类监督可以防止AI错误和有偏见的决策。然而，这建立在用户会仔细考虑解释以捕捉这些错误的前提上。我们在线开展了可解释DSS中的信任研究，惊讶地发现，在许多情况下，参与者花在解释上的时间很少，并不总是仔细考虑它们。我们呈现了对这一数据的探索性分析，探讨哪些因素影响研究参与者如何仔细考虑AI的解释，以及这种影响如何进一步影响他们是否愿意根据AI的建议改变观点。', 'title_zh': 'AI解释能改变你的观点吗？'}
{'arxiv_id': 'arXiv:2508.08144', 'title': 'COMponent-Aware Pruning for Accelerated Control Tasks in Latent Space Models', 'authors': 'Ganesh Sundaram, Jonas Ulmen, Amjad Haider, Daniel Görges', 'link': 'https://arxiv.org/abs/2508.08144', 'abstract': 'The rapid growth of resource-constrained mobile platforms, including mobile robots, wearable systems, and Internet-of-Things devices, has increased the demand for computationally efficient neural network controllers (NNCs) that can operate within strict hardware limitations. While deep neural networks (DNNs) demonstrate superior performance in control applications, their substantial computational complexity and memory requirements present significant barriers to practical deployment on edge devices. This paper introduces a comprehensive model compression methodology that leverages component-aware structured pruning to determine the optimal pruning magnitude for each pruning group, ensuring a balance between compression and stability for NNC deployment. Our approach is rigorously evaluated on Temporal Difference Model Predictive Control (TD-MPC), a state-of-the-art model-based reinforcement learning algorithm, with a systematic integration of mathematical stability guarantee properties, specifically Lyapunov criteria. The key contribution of this work lies in providing a principled framework for determining the theoretical limits of model compression while preserving controller stability. Experimental validation demonstrates that our methodology successfully reduces model complexity while maintaining requisite control performance and stability characteristics. Furthermore, our approach establishes a quantitative boundary for safe compression ratios, enabling practitioners to systematically determine the maximum permissible model reduction before violating critical stability properties, thereby facilitating the confident deployment of compressed NNCs in resource-limited environments.', 'abstract_zh': '资源受限的移动平台迅速增长，包括移动机器人、穿戴系统和物联网设备，增加了对计算高效的神经网络控制器（NNCs）的需求，这些控制器可以在严格的硬件限制下运行。尽管深度神经网络（DNNs）在控制应用中表现出色，但其巨大的计算复杂度和内存要求给边缘设备上的实际部署带来了显著障碍。本文介绍了一种全面的模型压缩方法，该方法利用组件感知结构化剪枝来确定每个剪枝组的最优剪枝幅度，确保压缩与稳定性的平衡，以保障NNCs的部署。我们的方法在Temporal Difference Model Predictive Control（TD-MPC）上进行了严格评估，TD-MPC是一种先进的基于模型的强化学习算法，并系统地整合了数学稳定性保证特性，特别是李雅普un夫稳定性准则。本文的关键贡献在于提供了一个原则性的框架，用于确定模型压缩的理论限制，同时保持控制器稳定性。实验验证表明，我们的方法成功地减少了模型复杂性，同时保持了所需的控制性能和稳定性特性。此外，我们的方法为安全压缩比建立了定量边界，使实践者能够系统地确定在违反关键稳定性属性之前的最大允许模型减少，从而促进压缩NNCs在资源受限环境中的自信部署。', 'title_zh': '组件意识裁剪以加速潜在空间模型中的控制任务'}
{'arxiv_id': 'arXiv:2508.08139', 'title': 'Can LLMs Detect Their Confabulations? Estimating Reliability in Uncertainty-Aware Language Models', 'authors': 'Tianyi Zhou, Johanne Medina, Sanjay Chawla', 'link': 'https://arxiv.org/abs/2508.08139', 'abstract': 'Large Language Models (LLMs) are prone to generating fluent but incorrect content, known as confabulation, which poses increasing risks in multi-turn or agentic applications where outputs may be reused as context. In this work, we investigate how in-context information influences model behavior and whether LLMs can identify their unreliable responses. We propose a reliability estimation that leverages token-level uncertainty to guide the aggregation of internal model representations. Specifically, we compute aleatoric and epistemic uncertainty from output logits to identify salient tokens and aggregate their hidden states into compact representations for response-level reliability prediction. Through controlled experiments on open QA benchmarks, we find that correct in-context information improves both answer accuracy and model confidence, while misleading context often induces confidently incorrect responses, revealing a misalignment between uncertainty and correctness. Our probing-based method captures these shifts in model behavior and improves the detection of unreliable outputs across multiple open-source LLMs. These results underscore the limitations of direct uncertainty signals and highlight the potential of uncertainty-guided probing for reliability-aware generation.', 'abstract_zh': '大型语言模型（LLMs）倾向于生成流畅但不正确的内容，称为虚构，这在可能被重新用作上下文的多轮或代理应用程序中带来了不断增加的风险。在本文中，我们研究了内在上下文信息如何影响模型行为以及LLMs是否能够识别其不可靠的回答。我们提出了一种可靠性估计方法，该方法利用词元级不确定性来指导内部模型表示的聚合。具体而言，我们从输出logits中计算 aleatoric和epistemic不确定性以识别重要词元，并将它们的隐藏状态聚合为紧凑表示，以进行回答级别的可靠性预测。通过在开放问答基准上的受控实验，我们发现正确的内在上下文信息可以提高答案准确性和模型信心，而误导性的上下文往往会引发自信但错误的回答，揭示了不确定性和正确性之间的不一致。我们的基于探测的方法捕获了模型行为的变化，并在多个开源LLMs中提高了对不可靠输出的检测能力。这些结果突显了直接不确定性信号的局限性，并强调了不确定性引导探测在可靠性感知生成中的潜力。', 'title_zh': 'LLM能否检测自己的虚假记忆？关于不确定性感知语言模型可靠性的估计'}
{'arxiv_id': 'arXiv:2508.08137', 'title': 'MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation', 'authors': 'Pravallika Abbineni, Saoud Aldowaish, Colin Liechty, Soroosh Noorzad, Ali Ghazizadeh, Morteza Fayazi', 'link': 'https://arxiv.org/abs/2508.08137', 'abstract': 'Conducting a comprehensive literature review is crucial for advancing circuit design methodologies. However, the rapid influx of state-of-the-art research, inconsistent data representation, and the complexity of optimizing circuit design objectives make this task significantly challenging. In this paper, we propose MuaLLM, an open-source multimodal Large Language Model (LLM) agent for circuit design assistance that integrates a hybrid Retrieval-Augmented Generation (RAG) framework with an adaptive vector database of circuit design research papers. Unlike conventional LLMs, the MuaLLM agent employs a Reason + Act (ReAct) workflow for iterative reasoning, goal-setting, and multi-step information retrieval. It functions as a question-answering design assistant, capable of interpreting complex queries and providing reasoned responses grounded in circuit literature. Its multimodal capabilities enable processing of both textual and visual data, facilitating more efficient and comprehensive analysis. The system dynamically adapts using intelligent search tools, automated document retrieval from the internet, and real-time database updates. Unlike conventional approaches constrained by model context limits, MuaLLM decouples retrieval from inference, enabling scalable reasoning over arbitrarily large corpora. At the maximum context length supported by standard LLMs, MuaLLM remains up to 10x less costly and 1.6x faster while maintaining the same accuracy. This allows rapid, no-human-in-the-loop database generation, overcoming the bottleneck of simulation-based dataset creation for circuits. To evaluate MuaLLM, we introduce two custom datasets: RAG-250, targeting retrieval and citation performance, and Reasoning-100 (Reas-100), focused on multistep reasoning in circuit design. MuaLLM achieves 90.1% recall on RAG-250, and 86.8% accuracy on Reas-100.', 'abstract_zh': '开展全面的文献综述对于推进电路设计方法学至关重要。然而，最先进的研究的快速涌入、数据表示的一致性问题以及优化电路设计目标的复杂性使得这一任务极具挑战性。本文提出了一种名为MuaLLM的开源多模态大型语言模型（LLM）代理，用于电路设计辅助，它结合了混合检索增强生成（RAG）框架和电路设计研究论文的自适应向量数据库。与传统的LLM不同，MuaLLM代理采用了Reason + Act（ReAct）工作流，用于迭代推理、设定目标和多步信息检索。它作为一个问题回答型设计助手，能够解释复杂的查询并提供基于电路文献的合理回答。其多模态能力使其能够处理文本和视觉数据，促进更高效和全面的分析。系统通过智能搜索工具、互联网自动文档检索和实时数据库更新动态适应。与受限于模型上下文限制的传统方法不同，MuaLLM将检索与推理脱钩，使推理能够在任意大小的语料库上扩展。在标准LLM支持的最大上下文长度下，MuaLLM的成本低10倍，速度快1.6倍，同时保持相同准确性，从而实现快速、无人参与的数据库生成，克服了基于模拟的数据集创建瓶颈。为了评估MuaLLM，我们引入了两个自定义数据集：RAG-250，旨在评估检索和引用性能；和Reasoning-100（Reas-100），专注于电路设计中的多步推理。MuaLLM在RAG-250上的召回率为90.1%，在Reas-100上的准确率为86.8%。', 'title_zh': 'MuaLLM：一种结合混合上下文检索增强生成的多模态大型语言模型代理电路设计辅助系统'}
{'arxiv_id': 'arXiv:2508.08131', 'title': 'Optimal Transport Regularization for Speech Text Alignment in Spoken Language Models', 'authors': 'Wenze Xu, Chun Wang, Jiazhen Yu, Sheng Chen, Liang Gao, Weihong Deng', 'link': 'https://arxiv.org/abs/2508.08131', 'abstract': 'Spoken Language Models (SLMs), which extend Large Language Models (LLMs) to perceive speech inputs, have gained increasing attention for their potential to advance speech understanding tasks. However, despite recent progress, studies show that SLMs often struggle to generalize across datasets, even for trained languages and tasks, raising concerns about whether they process speech in a text-like manner as intended. A key challenge underlying this limitation is the modality gap between speech and text representations. The high variability in speech embeddings may allow SLMs to achieve strong in-domain performance by exploiting unintended speech variations, ultimately hindering generalization. To mitigate this modality gap, we introduce Optimal Transport Regularization (OTReg), a method that formulates speech-text alignment as an optimal transport problem and derives a regularization loss to improve SLM training. In each training iteration, OTReg first establishes a structured correspondence between speech and transcript embeddings by determining the optimal transport plan, then incorporates the regularization loss based on this transport plan to optimize SLMs in generating speech embeddings that align more effectively with transcript embeddings. OTReg is lightweight, requiring no additional labels or learnable parameters, and integrates seamlessly into existing SLM training procedures. Extensive multilingual ASR experiments demonstrate that OTReg enhances speech-text alignment, mitigates the modality gap, and consequently improves SLM generalization across diverse datasets.', 'abstract_zh': '基于最优运输正则化的语音文本对齐方法：提升跨数据集泛化的语音语言模型', 'title_zh': '语音文本对齐中-optimal transport 正则化的最优传输正则化'}
{'arxiv_id': 'arXiv:2508.08122', 'title': 'MemoryKT: An Integrative Memory-and-Forgetting Method for Knowledge Tracing', 'authors': 'Mingrong Lin, Ke Deng, Zhengyang Wu, Zetao Zheng, Jie Li', 'link': 'https://arxiv.org/abs/2508.08122', 'abstract': "Knowledge Tracing (KT) is committed to capturing students' knowledge mastery from their historical interactions. Simulating students' memory states is a promising approach to enhance both the performance and interpretability of knowledge tracing models. Memory consists of three fundamental processes: encoding, storage, and retrieval. Although forgetting primarily manifests during the storage stage, most existing studies rely on a single, undifferentiated forgetting mechanism, overlooking other memory processes as well as personalized forgetting patterns. To address this, this paper proposes memoryKT, a knowledge tracing model based on a novel temporal variational autoencoder. The model simulates memory dynamics through a three-stage process: (i) Learning the distribution of students' knowledge memory features, (ii) Reconstructing their exercise feedback, while (iii) Embedding a personalized forgetting module within the temporal workflow to dynamically modulate memory storage strength. This jointly models the complete encoding-storage-retrieval cycle, significantly enhancing the model's perception capability for individual differences. Extensive experiments on four public datasets demonstrate that our proposed approach significantly outperforms state-of-the-art baselines.", 'abstract_zh': '基于新型时变自编码器的记忆KT模型：增强知识追踪的性能与可解释性', 'title_zh': 'MemoryKT：一种集成记忆与遗忘的知识追踪方法'}
{'arxiv_id': 'arXiv:2508.08120', 'title': 'Vision-Based Localization and LLM-based Navigation for Indoor Environments', 'authors': 'Keyan Rahimi, Md. Wasiul Haque, Sagar Dasgupta, Mizanur Rahman', 'link': 'https://arxiv.org/abs/2508.08120', 'abstract': "Indoor navigation remains a complex challenge due to the absence of reliable GPS signals and the architectural intricacies of large enclosed environments. This study presents an indoor localization and navigation approach that integrates vision-based localization with large language model (LLM)-based navigation. The localization system utilizes a ResNet-50 convolutional neural network fine-tuned through a two-stage process to identify the user's position using smartphone camera input. To complement localization, the navigation module employs an LLM, guided by a carefully crafted system prompt, to interpret preprocessed floor plan images and generate step-by-step directions. Experimental evaluation was conducted in a realistic office corridor with repetitive features and limited visibility to test localization robustness. The model achieved high confidence and an accuracy of 96% across all tested waypoints, even under constrained viewing conditions and short-duration queries. Navigation tests using ChatGPT on real building floor maps yielded an average instruction accuracy of 75%, with observed limitations in zero-shot reasoning and inference time. This research demonstrates the potential for scalable, infrastructure-free indoor navigation using off-the-shelf cameras and publicly available floor plans, particularly in resource-constrained settings like hospitals, airports, and educational institutions.", 'abstract_zh': '室内导航仍旧是一个复杂的挑战，由于缺乏可靠的GPS信号以及大型封闭环境的建筑复杂性。本研究提出了一种将基于视觉的定位与大型语言模型（LLM）驱动的导航相结合的室内定位与导航方法。定位系统利用通过两阶段过程微调的ResNet-50卷积神经网络，使用智能手机相机输入识别用户的当前位置。为了补充定位，导航模块采用一个由精心构建的系统提示引导的LLM，解析预处理的楼层平面图并生成分步指引。实验评估在具有重复特征和有限可见度的现实办公走廊环境中进行，以测试定位的稳健性。该模型在所有测试的航点处均实现了高置信度和96%的精度，即使在受限的观测条件下和短查询时间内亦是如此。使用ChatGPT对实际建筑物楼层平面图进行导航测试，平均指令准确率为75%，观察到零样本推理能力和推理时间方面的限制。这项研究展示了在资源受限的环境中，如医院、机场和教育机构，利用现成的摄像头和公开可用的楼层平面图实现可扩展的、无需基础设施的室内导航的潜力。', 'title_zh': '基于视觉的室内环境定位与基于LLM的导航'}
{'arxiv_id': 'arXiv:2508.08117', 'title': 'GRASPTrack: Geometry-Reasoned Association via Segmentation and Projection for Multi-Object Tracking', 'authors': 'Xudong Han, Pengcheng Fang, Yueying Tian, Jianhui Yu, Xiaohao Cai, Daniel Roggen, Philip Birch', 'link': 'https://arxiv.org/abs/2508.08117', 'abstract': 'Multi-object tracking (MOT) in monocular videos is fundamentally challenged by occlusions and depth ambiguity, issues that conventional tracking-by-detection (TBD) methods struggle to resolve owing to a lack of geometric awareness. To address these limitations, we introduce GRASPTrack, a novel depth-aware MOT framework that integrates monocular depth estimation and instance segmentation into a standard TBD pipeline to generate high-fidelity 3D point clouds from 2D detections, thereby enabling explicit 3D geometric reasoning. These 3D point clouds are then voxelized to enable a precise and robust Voxel-Based 3D Intersection-over-Union (IoU) for spatial association. To further enhance tracking robustness, our approach incorporates Depth-aware Adaptive Noise Compensation, which dynamically adjusts the Kalman filter process noise based on occlusion severity for more reliable state estimation. Additionally, we propose a Depth-enhanced Observation-Centric Momentum, which extends the motion direction consistency from the image plane into 3D space to improve motion-based association cues, particularly for objects with complex trajectories. Extensive experiments on the MOT17, MOT20, and DanceTrack benchmarks demonstrate that our method achieves competitive performance, significantly improving tracking robustness in complex scenes with frequent occlusions and intricate motion patterns.', 'abstract_zh': '单目视频中的多目标跟踪（MOT）受到遮挡和深度不确定性的问题挑战，常规的检测到跟踪（TBD）方法由于缺乏几何意识而难以解决这些问题。为了解决这些限制，我们提出了GRASPTrack，这是一种新颖的深度意识MOT框架，将单目深度估计和实例分割集成到标准的TBD管道中，从而从2D检测生成高保真度的3D点云，实现显式的3D几何推理。这些3D点云随后被体素化，以实现空间关联的精确和鲁棒的体素化3D交并比（IoU）。为了进一步增强跟踪的鲁棒性，我们的方法采用了深度意识自适应噪声补偿，根据遮挡严重程度动态调整卡尔曼滤波过程噪声，以实现更可靠的状态估计。此外，我们还提出了深度增强的目标中心动量，将运动方向一致性从图像平面扩展到3D空间，以改善基于运动的关联提示，特别是对于具有复杂轨迹的对象。在MOT17、MOT20和DanceTrack基准测试上的 extensive 实验显示，我们的方法在复杂场景中频繁遮挡和复杂运动模式下显著提高了跟踪的鲁棒性，实现竞争性的性能。', 'title_zh': 'GRASPTrack：基于分割与投影的几何推理关联方法用于多目标跟踪'}
{'arxiv_id': 'arXiv:2508.08107', 'title': 'Hyperspectral Imaging', 'authors': 'Danfeng Hong, Chenyu Li, Naoto Yokoya, Bing Zhang, Xiuping Jia, Antonio Plaza, Paolo Gamba, Jon Atli Benediktsson, Jocelyn Chanussot', 'link': 'https://arxiv.org/abs/2508.08107', 'abstract': "Hyperspectral imaging (HSI) is an advanced sensing modality that simultaneously captures spatial and spectral information, enabling non-invasive, label-free analysis of material, chemical, and biological properties. This Primer presents a comprehensive overview of HSI, from the underlying physical principles and sensor architectures to key steps in data acquisition, calibration, and correction. We summarize common data structures and highlight classical and modern analysis methods, including dimensionality reduction, classification, spectral unmixing, and AI-driven techniques such as deep learning. Representative applications across Earth observation, precision agriculture, biomedicine, industrial inspection, cultural heritage, and security are also discussed, emphasizing HSI's ability to uncover sub-visual features for advanced monitoring, diagnostics, and decision-making. Persistent challenges, such as hardware trade-offs, acquisition variability, and the complexity of high-dimensional data, are examined alongside emerging solutions, including computational imaging, physics-informed modeling, cross-modal fusion, and self-supervised learning. Best practices for dataset sharing, reproducibility, and metadata documentation are further highlighted to support transparency and reuse. Looking ahead, we explore future directions toward scalable, real-time, and embedded HSI systems, driven by sensor miniaturization, self-supervised learning, and foundation models. As HSI evolves into a general-purpose, cross-disciplinary platform, it holds promise for transformative applications in science, technology, and society.", 'abstract_zh': '高光谱成像（HSI）是一种高级传感模态，能够同时获取空间和光谱信息，实现无损、无需标签的物质、化学和生物特性分析。本综述全面概述了HSI，从基本物理原理和传感器架构到数据采集、校准和校正的关键步骤。我们总结了常见的数据结构，并强调了经典的和现代的分析方法，包括降维、分类、光谱解混以及深度学习等人工智能驱动的技术。文中还讨论了HSI在地球观测、精准农业、生物医学、工业检测、文化遗产及安全等领域的代表应用，突出了HSI在高级监测、诊断和决策中的能力。文中还分析了固有的挑战，如硬件权衡、采集变异性以及高维数据的复杂性，并介绍了新兴的解决方案，包括计算成像、物理启发建模、跨模态融合和自监督学习。此外，我们强调了数据集共享、可再现性及元数据记录的最佳实践，以支持透明度和重复使用。展望未来，随着传感器微型化、自监督学习和基础模型的发展，我们将探索更可扩展、实时和嵌入式的HSI系统的发展方向。随着HSI逐渐成为一种跨学科的通用平台，它在科学、技术和社会中的变革性应用充满前景。', 'title_zh': '高光谱成像'}
{'arxiv_id': 'arXiv:2508.08101', 'title': 'ChatGPT on the Road: Leveraging Large Language Model-Powered In-vehicle Conversational Agents for Safer and More Enjoyable Driving Experience', 'authors': 'Yeana Lee Bond, Mungyeong Choe, Baker Kasim Hasan, Arsh Siddiqui, Myounghoon Jeon', 'link': 'https://arxiv.org/abs/2508.08101', 'abstract': 'Studies on in-vehicle conversational agents have traditionally relied on pre-scripted prompts or limited voice commands, constraining natural driver-agent interaction. To resolve this issue, the present study explored the potential of a ChatGPT-based in-vehicle agent capable of carrying continuous, multi-turn dialogues. Forty drivers participated in our experiment using a motion-based driving simulator, comparing three conditions (No agent, Pre-scripted agent, and ChatGPT-based agent) as a within-subjects variable. Results showed that the ChatGPT-based agent condition led to more stable driving performance across multiple metrics. Participants demonstrated lower variability in longitudinal acceleration, lateral acceleration, and lane deviation compared to the other two conditions. In subjective evaluations, the ChatGPT-based agent also received significantly higher ratings in competence, animacy, affective trust, and preference compared to the Pre-scripted agent. Our thematic analysis of driver-agent conversations revealed diverse interaction patterns in topics, including driving assistance/questions, entertainment requests, and anthropomorphic interactions. Our results highlight the potential of LLM-powered in-vehicle conversational agents to enhance driving safety and user experience through natural, context-rich interactions.', 'abstract_zh': '基于ChatGPT的车内对话代理研究：通过连续多轮对话提升驾驶稳定性和用户体验', 'title_zh': 'ChatGPT上路：利用大语言模型驱动的车内对话代理以实现更安全、更愉快的驾驶体验'}
{'arxiv_id': 'arXiv:2508.08100', 'title': 'Grid2Guide: A* Enabled Small Language Model for Indoor Navigation', 'authors': 'Md. Wasiul Haque, Sagar Dasgupta, Mizanur Rahman', 'link': 'https://arxiv.org/abs/2508.08100', 'abstract': "Reliable indoor navigation remains a significant challenge in complex environments, particularly where external positioning signals and dedicated infrastructures are unavailable. This research presents Grid2Guide, a hybrid navigation framework that combines the A* search algorithm with a Small Language Model (SLM) to generate clear, human-readable route instructions. The framework first conducts a binary occupancy matrix from a given indoor map. Using this matrix, the A* algorithm computes the optimal path between origin and destination, producing concise textual navigation steps. These steps are then transformed into natural language instructions by the SLM, enhancing interpretability for end users. Experimental evaluations across various indoor scenarios demonstrate the method's effectiveness in producing accurate and timely navigation guidance. The results validate the proposed approach as a lightweight, infrastructure-free solution for real-time indoor navigation support.", 'abstract_zh': '可靠的室内导航在复杂环境中仍是一项重大挑战，尤其是在外部定位信号和专用基础设施不可用的情况下。本研究提出了Grid2Guide，这是一种结合A*搜索算法和小型语言模型（SLM）的混合导航框架，用于生成清晰易读的路线指引。该框架首先从给定的室内地图中生成一个二元占用矩阵。利用该矩阵，A*算法计算出起始点和目的地之间的最优路径，并生成简洁的文字导航步骤。然后，这些步骤通过SLM转换成自然语言指令，以增强最终用户的可理解性。在各种室内场景下的实验评估证明了该方法在生成准确及时的导航指引方面的有效性。结果证实了所提出的方法作为一种轻量级、无基础设施的实时室内导航支持解决方案的有效性。', 'title_zh': 'Grid2Guide: 基于A*算法的小型语言模型用于室内导航'}
{'arxiv_id': 'arXiv:2508.08095', 'title': 'Dual Information Speech Language Models for Emotional Conversations', 'authors': 'Chun Wang, Chenyang Liu, Wenze Xu, Weihong Deng', 'link': 'https://arxiv.org/abs/2508.08095', 'abstract': "Conversational systems relying on text-based large language models (LLMs) often overlook paralinguistic cues, essential for understanding emotions and intentions. Speech-language models (SLMs), which use speech as input, are emerging as a promising solution. However, SLMs built by extending frozen LLMs struggle to capture paralinguistic information and exhibit reduced context understanding. We identify entangled information and improper training strategies as key issues. To address these issues, we propose two heterogeneous adapters and suggest a weakly supervised training strategy. Our approach disentangles paralinguistic and linguistic information, enabling SLMs to interpret speech through structured representations. It also preserves contextual understanding by avoiding the generation of task-specific vectors through controlled randomness. This approach trains only the adapters on common datasets, ensuring parameter and data efficiency. Experiments demonstrate competitive performance in emotional conversation tasks, showcasing the model's ability to effectively integrate both paralinguistic and linguistic information within contextual settings.", 'abstract_zh': '基于文本的大语言模型（LLMs）驱动的会话系统往往忽略了对理解情感和意图至关重要的副语言线索。使用语音作为输入的语音语言模型（SLMs）正逐渐成为一种有前途的解决方案。然而，通过扩展冻结的LLMs构建的SLMs难以捕捉副语言信息，并表现出降低的语境理解能力。我们确定纠缠的信息和不适当的训练策略是关键问题。为解决这些问题，我们提出两种异质适配器，并建议一种弱监督训练策略。我们的方法将副语言和语言信息解纠缠，使SLMs能够通过结构化的表示解析语音。它还通过控制随机性避免生成特定任务的向量来保留语境理解。该方法仅在通用数据集上训练适配器，确保参数和数据效率。实验显示，在情感对话任务中表现出竞争力，展示了模型在语境设置中有效整合副语言和语言信息的能力。', 'title_zh': '双信息语音语言模型的情感对话'}
{'arxiv_id': 'arXiv:2508.08091', 'title': 'Growing Reservoirs with Developmental Graph Cellular Automata', 'authors': 'Matias Barandiaran, James Stovold', 'link': 'https://arxiv.org/abs/2508.08091', 'abstract': "Developmental Graph Cellular Automata (DGCA) are a novel model for morphogenesis, capable of growing directed graphs from single-node seeds. In this paper, we show that DGCAs can be trained to grow reservoirs. Reservoirs are grown with two types of targets: task-driven (using the NARMA family of tasks) and task-independent (using reservoir metrics).\nResults show that DGCAs are able to grow into a variety of specialized, life-like structures capable of effectively solving benchmark tasks, statistically outperforming `typical' reservoirs on the same task. Overall, these lay the foundation for the development of DGCA systems that produce plastic reservoirs and for modeling functional, adaptive morphogenesis.", 'abstract_zh': '发展图细胞自动机（DGCA）是一种用于形态发生的新模型，能够从单节点种子生成有向图。本文展示了DGCA可以被训练以生成蓄水池。蓄水池通过两种类型的目标进行生长：任务驱动型（使用NARMA任务家族）和任务独立型（使用蓄水池度量）。结果显示，DGCA能够生长成多种专门化、类生命结构，能够有效解决基准任务，并在相同任务上统计上优于“典型”的蓄水池。整体来看，这些结果为开发能够生成可塑蓄水池的DGCA系统并建模功能性、适应性形态发生的奠定了基础。', 'title_zh': '发展性图细胞自动机驱动的水库增长'}
{'arxiv_id': 'arXiv:2508.08088', 'title': 'HierSearch: A Hierarchical Enterprise Deep Search Framework Integrating Local and Web Searches', 'authors': 'Jiejun Tan, Zhicheng Dou, Yan Yu, Jiehan Cheng, Qiang Ju, Jian Xie, Ji-Rong Wen', 'link': 'https://arxiv.org/abs/2508.08088', 'abstract': 'Recently, large reasoning models have demonstrated strong mathematical and coding abilities, and deep search leverages their reasoning capabilities in challenging information retrieval tasks. Existing deep search works are generally limited to a single knowledge source, either local or the Web. However, enterprises often require private deep search systems that can leverage search tools over both local and the Web corpus. Simply training an agent equipped with multiple search tools using flat reinforcement learning (RL) is a straightforward idea, but it has problems such as low training data efficiency and poor mastery of complex tools. To address the above issue, we propose a hierarchical agentic deep search framework, HierSearch, trained with hierarchical RL. At the low level, a local deep search agent and a Web deep search agent are trained to retrieve evidence from their corresponding domains. At the high level, a planner agent coordinates low-level agents and provides the final answer. Moreover, to prevent direct answer copying and error propagation, we design a knowledge refiner that filters out hallucinations and irrelevant evidence returned by low-level agents. Experiments show that HierSearch achieves better performance compared to flat RL, and outperforms various deep search and multi-source retrieval-augmented generation baselines in six benchmarks across general, finance, and medical domains.', 'abstract_zh': '近期，大型推理模型在数学和编程能力上 已经展现出强大的的能力，深度学习利用其推理能力在复杂的检索任务上 已经取得了显著的进展。现有的深度学习系统通常局限于单一的知识领域，即便是局部的和 Web 上的内容。许多企业往往需要具备获取本地和 Web 数据库的能力的私人深度学习系统。简单地用 使用平面强化学习 (RL) 来训练集 多种工具的智能体虽然有时直接有效，但在效率上 面临低效和难以掌握复杂工具的问题。为解决这些问题，我们提出了一种层次化强化学习框架 HierSearch。该框架在低层训练一个本地深度智能体和一个 Web 深度 强化学习智能体，用于从各自领域检索证据。在高层，一个计划者智能体协调低层智能体并提供高低整合的决策。此外，我们设计了一个知识水平精炼器，以过滤低层智能体提供的幻觉和无关证据。实验表明 HierSearch 在六个通用金融和医疗领域基准上 达到了优异的性能，并 并在单一数据源和多数据源增强检索的基线上表现更优。', 'title_zh': 'HierSearch：一种集成本地搜索和网络搜索的层级企业深度搜索框架'}
{'arxiv_id': 'arXiv:2508.08071', 'title': 'C-MAG: Cascade Multimodal Attributed Graphs for Supply Chain Link Prediction', 'authors': 'Yunqing Li, Zixiang Tang, Jiaying Zhuang, Zhenyu Yang, Farhad Ameri, Jianbang Zhang', 'link': 'https://arxiv.org/abs/2508.08071', 'abstract': 'Connecting an ever-expanding catalogue of products with suitable manufacturers and suppliers is critical for resilient, efficient global supply chains, yet traditional methods struggle to capture complex capabilities, certifications, geographic constraints, and rich multimodal data of real-world manufacturer profiles. To address these gaps, we introduce PMGraph, a public benchmark of bipartite and heterogeneous multimodal supply-chain graphs linking 8,888 manufacturers, over 70k products, more than 110k manufacturer-product edges, and over 29k product images. Building on this benchmark, we propose the Cascade Multimodal Attributed Graph C-MAG, a two-stage architecture that first aligns and aggregates textual and visual attributes into intermediate group embeddings, then propagates them through a manufacturer-product hetero-graph via multiscale message passing to enhance link prediction accuracy. C-MAG also provides practical guidelines for modality-aware fusion, preserving predictive performance in noisy, real-world settings.', 'abstract_zh': '连接不断扩大的产品目录与合适的制造商和供应商对于韧性、高效的全球供应链至关重要，但传统方法难以捕捉真实世界制造商档案中的复杂能力、认证、地理限制和丰富的多模态数据。为弥补这些空白，我们介绍了PMGraph，这是一个包含 bipartite 和 heterogeneous 多模态供应链图的公开基准，链接了8,888家制造商、超过70,000种产品、超过110,000条制造商-产品边以及超过29,000张产品图片。基于这个基准，我们提出了Cascade Multimodal Attributed Graph (C-MAG) 两阶段架构，首先将文本和视觉属性对齐并聚合为中间组嵌入，然后通过多尺度消息传递在制造商-产品异构图中传播这些嵌入，以提高链接预测准确性。C-MAG 还提供了模态感知融合的实际指南，在嘈杂的实际环境中保持预测性能。', 'title_zh': 'C-MAG：级联多模态属性图在供应链链接预测中的应用'}
{'arxiv_id': 'arXiv:2508.08066', 'title': 'Investigating the Design Space of Visual Grounding in Multimodal Large Language Model', 'authors': 'Weitai Kang, Weiming Zhuang, Zhizhong Li, Yan Yan, Lingjuan Lyu', 'link': 'https://arxiv.org/abs/2508.08066', 'abstract': "Fine-grained multimodal capability in Multimodal Large Language Models (MLLMs) has emerged as a critical research direction, particularly for tackling the visual grounding (VG) problem. Despite the strong performance achieved by existing approaches, they often employ disparate design choices when fine-tuning MLLMs for VG, lacking systematic verification to support these designs. To bridge this gap, this paper presents a comprehensive study of various design choices that impact the VG performance of MLLMs. We conduct our analysis using LLaVA-1.5, which has been widely adopted in prior empirical studies of MLLMs. While more recent models exist, we follow this convention to ensure our findings remain broadly applicable and extendable to other architectures. We cover two key aspects: (1) exploring different visual grounding paradigms in MLLMs, identifying the most effective design, and providing our insights; and (2) conducting ablation studies on the design of grounding data to optimize MLLMs' fine-tuning for the VG task. Finally, our findings contribute to a stronger MLLM for VG, achieving improvements of +5.6% / +6.9% / +7.0% on RefCOCO/+/g over the LLaVA-1.5.", 'abstract_zh': 'Fine-grained 多模态能力在多模态大型语言模型（MLLMs）中的细粒度视觉定位能力已成为一个关键的研究方向，特别是在解决视觉定位问题（VG）方面。尽管现有方法取得了强大的性能，但在为视觉定位任务微调 MLLMs 时，它们往往采用了不一致的设计选择，缺乏系统的验证来支持这些设计。为弥补这一差距，本文对影响多模态大型语言模型（MLLMs）视觉定位（VG）性能的各种设计选择进行了全面研究。我们使用LLaVA-1.5 进行分析，该模型在之前的多模态大型语言模型实证研究中被广泛采用。尽管存在更近期的模型，但我们遵循这一惯例以确保我们的发现具有广泛的适用性和可扩展性，适用于其他架构。我们涵盖了两个关键方面：（1）探索多模态大型语言模型中的不同视觉定位范式，确定最有效的设计，并提供我们的见解；（2）对grounding 数据设计进行消融研究，以优化多模态大型语言模型（MLLMs）的微调，以完成视觉定位任务。最后，我们的发现为多模态大型语言模型（MLLMs）在视觉定位（VG）方面提供了更强的能力，分别在 RefCOCO/+/g 上取得了 +5.6%/+6.9%/+7.0% 的改进。', 'title_zh': '多模态大型语言模型中的视觉定位设计空间探究'}
{'arxiv_id': 'arXiv:2508.08052', 'title': 'On Understanding of the Dynamics of Model Capacity in Continual Learning', 'authors': 'Supriyo Chakraborty, Krishnan Raghavan', 'link': 'https://arxiv.org/abs/2508.08052', 'abstract': "The stability-plasticity dilemma, closely related to a neural network's (NN) capacity-its ability to represent tasks-is a fundamental challenge in continual learning (CL). Within this context, we introduce CL's effective model capacity (CLEMC) that characterizes the dynamic behavior of the stability-plasticity balance point. We develop a difference equation to model the evolution of the interplay between the NN, task data, and optimization procedure. We then leverage CLEMC to demonstrate that the effective capacity-and, by extension, the stability-plasticity balance point is inherently non-stationary. We show that regardless of the NN architecture or optimization method, a NN's ability to represent new tasks diminishes when incoming task distributions differ from previous ones. We conduct extensive experiments to support our theoretical findings, spanning a range of architectures-from small feedforward network and convolutional networks to medium-sized graph neural networks and transformer-based large language models with millions of parameters.", 'abstract_zh': '神经网络的有效模型容量（CLEMC）：持续学习中稳定-塑性权衡的动态行为', 'title_zh': '关于持续学习中模型容量动力学的理解'}
{'arxiv_id': 'arXiv:2508.08047', 'title': 'Rethinking Self-Replication: Detecting Distributed Selfhood in the Outlier Cellular Automaton', 'authors': 'Arend Hintze, Clifford Bohm', 'link': 'https://arxiv.org/abs/2508.08047', 'abstract': 'Spontaneous self-replication in cellular automata has long been considered rare, with most known examples requiring careful design or artificial initialization. In this paper, we present formal, causal evidence that such replication can emerge unassisted -- and that it can do so in a distributed, multi-component form. Building on prior work identifying complex dynamics in the Outlier rule, we introduce a data-driven framework that reconstructs the full causal ancestry of patterns in a deterministic cellular automaton. This allows us to rigorously identify self-replicating structures via explicit causal lineages. Our results show definitively that self-replicators in the Outlier CA are not only spontaneous and robust, but are also often composed of multiple disjoint clusters working in coordination, raising questions about some conventional notions of individuality and replication in artificial life systems.', 'abstract_zh': '自发自复制在 cellular automata 中一直被认为较为罕见，多数已知的例子需要精心设计或人工初始化。本文提供了正式的因果证据，表明这种复制可以在无辅助的情况下出现——并且可以以分布式、多组件的形式出现。基于先前在 Outlier 规则中识别复杂动力学的工作，我们引入了一个数据驱动的框架，用于重构确定性 cellular automaton 中模式的完整因果谱系。这使得我们可以通过明确的因果谱系来严格识别自复制结构。我们的结果表明，Outlier CA 中的自复制不仅自发且稳健，而且通常由多个协调工作的独立集群组成，对人工生命系统中的一些传统个体性和复制观念提出了挑战。', 'title_zh': '重新思考自我复制：异常细胞自动机中分布式自我性的检测'}
{'arxiv_id': 'arXiv:2508.08042', 'title': 'Multi-modal Adaptive Mixture of Experts for Cold-start Recommendation', 'authors': 'Van-Khang Nguyen, Duc-Hoang Pham, Huy-Son Nguyen, Cam-Van Thi Nguyen, Hoang-Quynh Le, Duc-Trong Le', 'link': 'https://arxiv.org/abs/2508.08042', 'abstract': 'Recommendation systems have faced significant challenges in cold-start scenarios, where new items with a limited history of interaction need to be effectively recommended to users. Though multimodal data (e.g., images, text, audio, etc.) offer rich information to address this issue, existing approaches often employ simplistic integration methods such as concatenation, average pooling, or fixed weighting schemes, which fail to capture the complex relationships between modalities. Our study proposes a novel Mixture of Experts (MoE) framework for multimodal cold-start recommendation, named MAMEX, which dynamically leverages latent representation from different modalities. MAMEX utilizes modality-specific expert networks and introduces a learnable gating mechanism that adaptively weights the contribution of each modality based on its content characteristics. This approach enables MAMEX to emphasize the most informative modalities for each item while maintaining robustness when certain modalities are less relevant or missing. Extensive experiments on benchmark datasets show that MAMEX outperforms state-of-the-art methods in cold-start scenarios, with superior accuracy and adaptability. For reproducibility, the code has been made available on Github this https URL.', 'abstract_zh': '多模态冷启动推荐中的专家混合框架MAMEX：动态利用不同模态的潜在表示', 'title_zh': '冷启动推荐的多模态自适应专家混合模型'}
{'arxiv_id': 'arXiv:2508.08040', 'title': 'BadPromptFL: A Novel Backdoor Threat to Prompt-based Federated Learning in Multimodal Models', 'authors': 'Maozhen Zhang, Mengnan Zhao, Bo Wang', 'link': 'https://arxiv.org/abs/2508.08040', 'abstract': 'Prompt-based tuning has emerged as a lightweight alternative to full fine-tuning in large vision-language models, enabling efficient adaptation via learned contextual prompts. This paradigm has recently been extended to federated learning settings (e.g., PromptFL), where clients collaboratively train prompts under data privacy constraints. However, the security implications of prompt-based aggregation in federated multimodal learning remain largely unexplored, leaving a critical attack surface unaddressed. In this paper, we introduce \\textbf{BadPromptFL}, the first backdoor attack targeting prompt-based federated learning in multimodal contrastive models. In BadPromptFL, compromised clients jointly optimize local backdoor triggers and prompt embeddings, injecting poisoned prompts into the global aggregation process. These prompts are then propagated to benign clients, enabling universal backdoor activation at inference without modifying model parameters. Leveraging the contextual learning behavior of CLIP-style architectures, BadPromptFL achieves high attack success rates (e.g., \\(>90\\%\\)) with minimal visibility and limited client participation. Extensive experiments across multiple datasets and aggregation protocols validate the effectiveness, stealth, and generalizability of our attack, raising critical concerns about the robustness of prompt-based federated learning in real-world deployments.', 'abstract_zh': '基于提示的BadPromptFL：面向多模态对比模型的提示式联邦学习后门攻击', 'title_zh': 'BadPromptFL：基于提示的多模态模型联邦学习中的新型后门威胁'}
{'arxiv_id': 'arXiv:2508.08030', 'title': 'Exploring Strategies for Personalized Radiation Therapy: Part III Identifying genetic determinants for Radiation Response with Meta Learning', 'authors': 'Hao Peng, Yuanyuan Zhang, Steve Jiang, Robert Timmerman, John Minna', 'link': 'https://arxiv.org/abs/2508.08030', 'abstract': 'Radiation response in cancer is shaped by complex, patient specific biology, yet current treatment strategies often rely on uniform dose prescriptions without accounting for tumor heterogeneity. In this study, we introduce a meta learning framework for one-shot prediction of radiosensitivity measured by SF2 using cell line level gene expression data. Unlike the widely used Radiosensitivity Index RSI a rank-based linear model trained on a fixed 10-gene signature, our proposed meta-learned model allows the importance of each gene to vary by sample through fine tuning. This flexibility addresses key limitations of static models like RSI, which assume uniform gene contributions across tumor types and discard expression magnitude and gene gene interactions. Our results show that meta learning offers robust generalization to unseen samples and performs well in tumor subgroups with high radiosensitivity variability, such as adenocarcinoma and large cell carcinoma. By learning transferable structure across tasks while preserving sample specific adaptability, our approach enables rapid adaptation to individual samples, improving predictive accuracy across diverse tumor subtypes while uncovering context dependent patterns of gene influence that may inform personalized therapy.', 'abstract_zh': '癌症对放射治疗的反应由复杂的患者特异性生物学决定，但当前的治疗策略往往依赖于统一的剂量处方，而不考虑肿瘤异质性。在这项研究中，我们引入了一种元学习框架，用于基于细胞系水平的基因表达数据一次性预测SF2测得的放射敏感性。不同于广泛使用的放射敏感性指数RSI（一种基于固定10基因签名的秩为基础的线性模型），我们提出的元学习模型允许每种基因在样本间的相对重要性通过微调变化。这种灵活性解决了RSI等静态模型固有的关键局限性，即假定肿瘤类型间基因贡献均匀且忽略了表达幅度和基因基因相互作用。研究结果表明，元学习能够稳健地泛化到未见过的样本，并在具有高放射敏感性变异性（如腺癌和大细胞癌）的肿瘤亚组中表现良好。通过学习跨任务的可转移结构同时保持样本特定的可适应性，我们的方法能够快速适应个体样本，提高对不同肿瘤亚型的预测准确性，同时揭示基因影响的上下文相关模式，这些模式可能有助于个性化治疗的制定。', 'title_zh': '探索个性化放疗策略：第三部分——使用元学习识别放疗反应的遗传决定因素'}
{'arxiv_id': 'arXiv:2508.08027', 'title': 'Bridging ASR and LLMs for Dysarthric Speech Recognition: Benchmarking Self-Supervised and Generative Approaches', 'authors': 'Ahmed Aboeitta, Ahmed Sharshar, Youssef Nafea, Shady Shehata', 'link': 'https://arxiv.org/abs/2508.08027', 'abstract': 'Speech Recognition (ASR) due to phoneme distortions and high variability. While self-supervised ASR models like Wav2Vec, HuBERT, and Whisper have shown promise, their effectiveness in dysarthric speech remains unclear. This study systematically benchmarks these models with different decoding strategies, including CTC, seq2seq, and LLM-enhanced decoding (BART,GPT-2, Vicuna). Our contributions include (1) benchmarking ASR architectures for dysarthric speech, (2) introducing LLM-based decoding to improve intelligibility, (3) analyzing generalization across datasets, and (4) providing insights into recognition errors across severity levels. Findings highlight that LLM-enhanced decoding improves dysarthric ASR by leveraging linguistic constraints for phoneme restoration and grammatical correction.', 'abstract_zh': '基于音位 distortion 和高变异性说话人识别 (ASR) 的挑战：自监督 ASR 模型在含糊言语中的 effectiveness 有待验证。本研究系统性地评估了 Wav2Vec、HuBERT、Whisper 等模型，并引入基于大型语言模型的解码以提高清晰度，同时分析了模型在不同数据集上的泛化能力，并探讨了在不同严重程度上的识别错误。研究发现，基于大型语言模型的解码通过利用语言约束来恢复音位和纠正语法，提高了含糊言语识别的性能。', 'title_zh': 'ASR与LLMs在构音障碍语音识别中的融合：自我监督与生成方法的基准测试'}
{'arxiv_id': 'arXiv:2508.08019', 'title': 'Advancing Knowledge Tracing by Exploring Follow-up Performance Trends', 'authors': 'Hengyu Liu, Yushuai Li, Minghe Yu, Tiancheng Zhang, Ge Yu, Torben Bach Pedersen, Kristian Torp, Christian S. Jensen, Tianyi Li', 'link': 'https://arxiv.org/abs/2508.08019', 'abstract': "Intelligent Tutoring Systems (ITS), such as Massive Open Online Courses, offer new opportunities for human learning. At the core of such systems, knowledge tracing (KT) predicts students' future performance by analyzing their historical learning activities, enabling an accurate evaluation of students' knowledge states over time. We show that existing KT methods often encounter correlation conflicts when analyzing the relationships between historical learning sequences and future performance. To address such conflicts, we propose to extract so-called Follow-up Performance Trends (FPTs) from historical ITS data and to incorporate them into KT. We propose a method called Forward-Looking Knowledge Tracing (FINER) that combines historical learning sequences with FPTs to enhance student performance prediction accuracy. FINER constructs learning patterns that facilitate the retrieval of FPTs from historical ITS data in linear time; FINER includes a novel similarity-aware attention mechanism that aggregates FPTs based on both frequency and contextual similarity; and FINER offers means of combining FPTs and historical learning sequences to enable more accurate prediction of student future performance. Experiments on six real-world datasets show that FINER can outperform ten state-of-the-art KT methods, increasing accuracy by 8.74% to 84.85%.", 'abstract_zh': '具有后续绩效趋势的前瞻知识追踪：面向大规模开放在线课程的智能辅导系统', 'title_zh': '通过探索后续性能趋势来推进知识追踪'}
{'arxiv_id': 'arXiv:2508.08005', 'title': 'Learning to Select MCP Algorithms: From Traditional ML to Dual-Channel GAT-MLP', 'authors': 'Xiang Li, Shanshan Wang, Chenglong Xiao', 'link': 'https://arxiv.org/abs/2508.08005', 'abstract': 'Extensive experiments and prior studies show that no single maximum clique algorithm consistently performs best across all instances, highlighting the importance of selecting suitable algorithms based on instance features. Through an extensive analysis of relevant studies, it is found that there is a lack of research work concerning algorithm selection oriented toward the Maximum Clique Problem (MCP). In this work, we propose a learning-based framework that integrates both traditional machine learning and graph neural networks to address this gap. We construct a labeled dataset by running four exact MCP algorithms on a diverse collection of graph instances, accompanied by structural and global statistical features extracted from each graph. We first evaluate four conventional classifiers: Support Vector Machine (SVM), Random Forest (RF), Decision Tree (DT), and K-Nearest Neighbors (KNN), across multiple dataset variants. Experimental results show that RF consistently shows strong performance across metrics and dataset variants, making it a reliable baseline. In addition, feature importance analysis indicates that connectivity and topological structure are strong predictors of algorithm performance. Building on these findings, we develop a dual-channel model named GAT-MLP, which combines a Graph Attention Network (GAT) for local structural encoding with a Multilayer Perceptron (MLP) for global feature modeling. The GAT-MLP model shows strong and consistent performance across all metrics. Our results highlight the effectiveness of dual-channel architectures and the promise of graph neural networks in combinatorial algorithm selection.', 'abstract_zh': '基于学习的组合算法选择框架：最大团问题acerb\nuser\n把下面的论文内容或标题翻译成中文：Learning-based Selection for the Maximum Clique Problem Through Feature Analysis and Graph Neural Networks', 'title_zh': '学习选择MCP算法：从传统机器学习到双通道GAT-MLP'}
{'arxiv_id': 'arXiv:2508.07995', 'title': 'DIVER: A Multi-Stage Approach for Reasoning-intensive Information Retrieval', 'authors': 'Meixiu Long, Duolin Sun, Dan Yang, Junjie Wang, Yue Shen, Jian Wang, Peng Wei, Jinjie Gu, Jiahai Wang', 'link': 'https://arxiv.org/abs/2508.07995', 'abstract': 'Retrieval-augmented generation has achieved strong performance on knowledge-intensive tasks where query-document relevance can be identified through direct lexical or semantic matches. However, many real-world queries involve abstract reasoning, analogical thinking, or multi-step inference, which existing retrievers often struggle to capture. To address this challenge, we present \\textbf{DIVER}, a retrieval pipeline tailored for reasoning-intensive information retrieval. DIVER consists of four components: document processing to improve input quality, LLM-driven query expansion via iterative document interaction, a reasoning-enhanced retriever fine-tuned on synthetic multi-domain data with hard negatives, and a pointwise reranker that combines LLM-assigned helpfulness scores with retrieval scores. On the BRIGHT benchmark, DIVER achieves state-of-the-art nDCG@10 scores of 41.6 and 28.9 on original queries, consistently outperforming competitive reasoning-aware models. These results demonstrate the effectiveness of reasoning-aware retrieval strategies in complex real-world tasks. Our code and retrieval model will be released soon.', 'abstract_zh': '检索增强生成在知识密集型任务中取得了强性能，这些任务可以通过直接的词汇或语义匹配来识别查询与文档的相关性。然而，许多实际查询涉及抽象推理、类比思考或多步推理，现有检索器往往难以捕捉。为应对这一挑战，我们提出了\\textbf{DIVER}，一种针对推理密集型信息检索的检索管道。DIVER 包含四个组件：文档处理以提高输入质量、通过迭代文档交互驱动的 LLM 查询扩展、在合成多领域数据上微调的增强推理检索器，以及结合检索评分和LLM分配的帮助性评分的点wise重排器。在 BRIGHT 基准上，DIVER 在原始查询上的 nDCG@10 得分分别为 41.6 和 28.9，一致地优于竞品的推理感知模型。这些结果表明，在复杂的真实世界任务中，推理感知检索策略的有效性。我们的代码和检索模型将很快发布。', 'title_zh': 'DIVER：一种多阶段的推理密集型信息检索方法'}
{'arxiv_id': 'arXiv:2508.07981', 'title': 'Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation', 'authors': 'Fangyuan Mao, Aiming Hao, Jintao Chen, Dongxia Liu, Xiaokun Feng, Jiashu Zhu, Meiqi Wu, Chubin Chen, Jiahong Wu, Xiangxiang Chu', 'link': 'https://arxiv.org/abs/2508.07981', 'abstract': 'Visual effects (VFX) are essential visual enhancements fundamental to modern cinematic production. Although video generation models offer cost-efficient solutions for VFX production, current methods are constrained by per-effect LoRA training, which limits generation to single effects. This fundamental limitation impedes applications that require spatially controllable composite effects, i.e., the concurrent generation of multiple effects at designated locations. However, integrating diverse effects into a unified framework faces major challenges: interference from effect variations and spatial uncontrollability during multi-VFX joint training. To tackle these challenges, we propose Omni-Effects, a first unified framework capable of generating prompt-guided effects and spatially controllable composite effects. The core of our framework comprises two key innovations: (1) LoRA-based Mixture of Experts (LoRA-MoE), which employs a group of expert LoRAs, integrating diverse effects within a unified model while effectively mitigating cross-task interference. (2) Spatial-Aware Prompt (SAP) incorporates spatial mask information into the text token, enabling precise spatial control. Furthermore, we introduce an Independent-Information Flow (IIF) module integrated within the SAP, isolating the control signals corresponding to individual effects to prevent any unwanted blending. To facilitate this research, we construct a comprehensive VFX dataset Omni-VFX via a novel data collection pipeline combining image editing and First-Last Frame-to-Video (FLF2V) synthesis, and introduce a dedicated VFX evaluation framework for validating model performance. Extensive experiments demonstrate that Omni-Effects achieves precise spatial control and diverse effect generation, enabling users to specify both the category and location of desired effects.', 'abstract_zh': '视觉效果（VFX）是现代影视制作中不可或缺的视觉增强技术。尽管视频生成模型为VFX生产提供了成本高效的解决方案，但当前方法受限于单效果LoRA训练，这限制了生成多种效果的能力。这一基本限制阻碍了需要空间可控合成效果的应用，即在指定位置同时生成多种效果。然而，将多种效果整合到统一框架中面临重大挑战：多VFX联合训练过程中效果变化的干扰和空间不可控性。为应对这些挑战，我们提出Omni-Effects，这是一种第一个统一框架，能够生成提示引导的效果和空间可控的合成效果。该框架的核心包括两个关键创新：（1）基于LoRA的专家混合（LoRA-MoE），利用一组专家LoRA，在统一模型中整合多种效果，同时有效减轻跨任务干扰。（2）空间感知提示（SAP）将空间掩码信息集成到文本令牌中，以实现精确的空间控制。此外，我们引入了一个独立信息流（IIF）模块，集成在SAP中，隔离每个效果的控制信号以防止任何不希望的效果混合。为了促进这项研究，我们通过一种结合图像编辑和First-Last Frame-to-Video（FLF2V）合成的新颖数据采集管道构建了全面的VFX数据集Omni-VFX，并引入了一个专用的VFX评估框架以验证模型性能。广泛的实验表明，Omni-Effects能够实现精确的空间控制和多种效果的生成，使用户能够指定所需效果的类别和位置。', 'title_zh': 'omn-Effects: 统一且空间可控的视觉效果生成'}
{'arxiv_id': 'arXiv:2508.07976', 'title': 'Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL', 'authors': 'Jiaxuan Gao, Wei Fu, Minyang Xie, Shusheng Xu, Chuyi He, Zhiyu Mei, Banghua Zhu, Yi Wu', 'link': 'https://arxiv.org/abs/2508.07976', 'abstract': 'Recent advancements in LLM-based agents have demonstrated remarkable capabilities in handling complex, knowledge-intensive tasks by integrating external tools. Among diverse choices of tools, search tools play a pivotal role in accessing vast external knowledge. However, open-source agents still fall short of achieving expert-level Search Intelligence, the ability to resolve ambiguous queries, generate precise searches, analyze results, and conduct thorough exploration. Existing approaches fall short in scalability, efficiency, and data quality. For example, small turn limits in existing online RL methods, e.g. <=10, restrict complex strategy learning. This paper introduces ASearcher, an open-source project for large-scale RL training of search agents. Our key contributions include: (1) Scalable fully asynchronous RL training that enables long-horizon search while maintaining high training efficiency. (2) A prompt-based LLM agent that autonomously synthesizes high-quality and challenging QAs, creating a large-scale QA dataset. Through RL training, our prompt-based QwQ-32B agent achieves substantial improvements, with 46.7% and 20.8% Avg@4 gains on xBench and GAIA, respectively. Notably, our agent exhibits extreme long-horizon search, with tool calls exceeding 40 turns and output tokens exceeding 150k during training time. With a simple agent design and no external LLMs, ASearcher-Web-QwQ achieves Avg@4 scores of 42.1 on xBench and 52.8 on GAIA, surpassing existing open-source 32B agents. We open-source our models, training data, and codes in this https URL.', 'abstract_zh': '近期基于LLM的代理在通过集成外部工具处理复杂、知识密集型任务方面展现了显著的能力。然而，开源代理在达到专家级搜索智能方面仍存在不足，表现为解决模糊查询、生成精确搜索、分析结果和深入探索的能力不足。现有方法在可扩展性、效率和数据质量方面存在局限。例如，现有在线RL方法中小对话轮次限制（如≤10轮）限制了复杂策略的学习。本文介绍了一个开源项目ASearcher，旨在通过大规模RL训练提高搜索代理的能力。我们的主要贡献包括：（1）可扩展的完全异步RL训练，能够在保持高训练效率的同时实现长期搜索。（2）基于提示的LLM代理，能够自主合成高质量和具有挑战性的问答对，构建大规模问答数据集。通过RL训练，基于提示的QwQ-32B代理在xBench和GAIA上分别取得了46.7%和20.8%的Avg@4提升。值得一提的是，我们的代理能够在训练期间实现极长的搜索视野，工具调用超过40轮，输出token超过150,000个。使用简单的设计且不依赖外部LLM，ASearcher-Web-QwQ在xBench和GAIA上的Avg@4分数分别为42.1和52.8，超过了现有开源32B代理。我们在以下链接开放了我们的模型、训练数据和代码：[提供链接]。', 'title_zh': '超越十轮：大规模异步RL解锁长期 horizon 主动搜索'}
{'arxiv_id': 'arXiv:2508.07970', 'title': 'WeChat-YATT: A Simple, Scalable and Balanced RLHF Trainer', 'authors': 'Junyu Wu, Weiming Chang, Xiaotao Liu, Guanyou He, Tingfeng Xian, Haoqiang Hong, Boqi Chen, Haotao Tian, Tao Yang, Yunsheng Shi, Feng Lin, Ting Yao', 'link': 'https://arxiv.org/abs/2508.07970', 'abstract': 'Reinforcement Learning from Human Feedback (RLHF) has emerged as a prominent paradigm for training large language models and multimodal systems. Despite notable advances enabled by existing RLHF training frameworks, significant challenges remain in scaling to complex multimodal workflows and adapting to dynamic workloads. In particular, current systems often encounter limitations related to controller scalability when managing large models, as well as inefficiencies in orchestrating intricate RLHF pipelines, especially in scenarios that require dynamic sampling and resource allocation. In this paper, we introduce WeChat-YATT (Yet Another Transformer Trainer in WeChat), a simple, scalable, and balanced RLHF training framework specifically designed to address these challenges. WeChat-YATT features a parallel controller programming model that enables flexible and efficient orchestration of complex RLHF workflows, effectively mitigating the bottlenecks associated with centralized controller architectures and facilitating scalability in large-scale data scenarios. In addition, we propose a dynamic placement schema that adaptively partitions computational resources and schedules workloads, thereby significantly reducing hardware idle time and improving GPU utilization under variable training conditions. We evaluate WeChat-YATT across a range of experimental scenarios, demonstrating that it achieves substantial improvements in throughput compared to state-of-the-art RLHF training frameworks. Furthermore, WeChat-YATT has been successfully deployed to train models supporting WeChat product features for a large-scale user base, underscoring its effectiveness and robustness in real-world applications.', 'abstract_zh': '基于人类反馈的强化学习（Reinforcement Learning from Human Feedback, RLHF）已成为训练大规模语言模型和多模态系统的 prominent 帕累托前沿。尽管现有 RLHF 训练框架取得了显著进展，但在扩展到复杂多模态工作流和适应动态工作负载方面仍面临重大挑战。特别是在管理大型模型时，现有系统往往遇到控制器扩展性限制，以及在需要动态采样和资源分配的情景中调度复杂的 RLHF 管道的低效率问题。本文我们介绍了微信-YATT（Yet Another Transformer Trainer in WeChat），这是一种简单、可扩展且平衡的 RLHF 训练框架，专门设计以解决这些挑战。微信-YATT 特有的并行控制器编程模型能够灵活且高效地调度复杂 RLHF 工作流，有效地缓解了集中式控制器架构的瓶颈，并在大规模数据场景中促进了扩展性。此外，我们提出了一种动态放置方案，能够自适应地分割计算资源并调度工作负载，从而在不同训练条件下显著减少硬件闲置时间并提高 GPU 利用率。我们在多种实验场景下评估了微信-YATT，证明其在吞吐量方面相较于最先进的 RLHF 训练框架取得了显著改进。此外，微信-YATT 已成功部署用于训练支持微信产品功能的模型，证实其在实际应用中的有效性和鲁棒性。', 'title_zh': 'WeChat-YATT: 一个简单、可扩展且平衡的RLHF训练器'}
{'arxiv_id': 'arXiv:2508.07966', 'title': 'Exploring the Challenges and Opportunities of AI-assisted Codebase Generation', 'authors': 'Philipp Eibl, Sadra Sabouri, Souti Chattopadhyay', 'link': 'https://arxiv.org/abs/2508.07966', 'abstract': "Recent AI code assistants have significantly improved their ability to process more complex contexts and generate entire codebases based on a textual description, compared to the popular snippet-level generation. These codebase AI assistants (CBAs) can also extend or adapt codebases, allowing users to focus on higher-level design and deployment decisions. While prior work has extensively studied the impact of snippet-level code generation, this new class of codebase generation models is relatively unexplored. Despite initial anecdotal reports of excitement about these agents, they remain less frequently adopted compared to snippet-level code assistants. To utilize CBAs better, we need to understand how developers interact with CBAs, and how and why CBAs fall short of developers' needs. In this paper, we explored these gaps through a counterbalanced user study and interview with (n = 16) students and developers working on coding tasks with CBAs. We found that participants varied the information in their prompts, like problem description (48% of prompts), required functionality (98% of prompts), code structure (48% of prompts), and their prompt writing process. Despite various strategies, the overall satisfaction score with generated codebases remained low (mean = 2.8, median = 3, on a scale of one to five). Participants mentioned functionality as the most common factor for dissatisfaction (77% of instances), alongside poor code quality (42% of instances) and communication issues (25% of instances). We delve deeper into participants' dissatisfaction to identify six underlying challenges that participants faced when using CBAs, and extracted five barriers to incorporating CBAs into their workflows. Finally, we surveyed 21 commercial CBAs to compare their capabilities with participant challenges and present design opportunities for more efficient and useful CBAs.", 'abstract_zh': 'Recent AI代码助手在处理更复杂上下文和根据文本描述生成整个代码库方面显著提高，并超越了流行的片段级生成。这些代码库AI助手（CBAs）还能扩展或改编代码库，使用户能够专注于高层次的设计和部署决策。尽管先前的工作对片段级代码生成的影响进行了广泛研究，但这类基于代码库生成的新模型相对未被探索。尽管这些代理最初引发了许多兴奋的初步报告，但它们的采用率仍然低于片段级代码助手。为了更好地利用CBAs，我们需要了解开发者如何与CBAs交互，以及CBAs在多大程度和为什么未能满足开发者的需要。在本文中，我们通过反平衡用户研究和访谈（n=16）探索了这些差距，参与者在使用CBAs进行编程任务时提供了反馈。我们发现参与者在提示中提供了不同的信息，比如问题描述（48%的提示）、所需功能（98%的提示）、代码结构（48%的提示）及其提示撰写过程。尽管采取了各种策略，生成的代码库的整体满意度分数仍然较低（均值=2.8，中位数=3，评分范围为1到5）。参与者提到功能是最常见的不满意因素（77%的实例），其次是代码质量差（42%的实例）以及沟通问题（25%的实例）。我们深入探讨了参与者的不满意之处，以识别参与者在使用CBAs时面临的六项根本挑战，并提取了五项将CBAs纳入其工作流程的障碍。最后，我们调查了21款商业CBAs，以比较其功能与参与者挑战，并提出更具效用CBAs的设计机会。', 'title_zh': '探索AI辅助代码库生成的挑战与机遇'}
{'arxiv_id': 'arXiv:2508.07944', 'title': 'SCDF: A Speaker Characteristics DeepFake Speech Dataset for Bias Analysis', 'authors': 'Vojtěch Staněk, Karel Srna, Anton Firc, Kamil Malinka', 'link': 'https://arxiv.org/abs/2508.07944', 'abstract': 'Despite growing attention to deepfake speech detection, the aspects of bias and fairness remain underexplored in the speech domain. To address this gap, we introduce the Speaker Characteristics Deepfake (SCDF) dataset: a novel, richly annotated resource enabling systematic evaluation of demographic biases in deepfake speech detection. SCDF contains over 237,000 utterances in a balanced representation of both male and female speakers spanning five languages and a wide age range. We evaluate several state-of-the-art detectors and show that speaker characteristics significantly influence detection performance, revealing disparities across sex, language, age, and synthesizer type. These findings highlight the need for bias-aware development and provide a foundation for building non-discriminatory deepfake detection systems aligned with ethical and regulatory standards.', 'abstract_zh': '尽管对深度假音语音检测的研究日益增多，但在语音领域，偏见和公平性方面的问题仍缺乏深入探讨。为弥补这一不足，我们提出了说话人特征深度假音（SCDF）数据集：一个新颖且注释丰富的资源，用于系统评估深度假音语音检测中的人口统计学偏见。SCDF 包含了超过 237,000 个发音，涵盖了五种语言和广泛年龄段的男女平衡发音样本。我们评估了几种前沿检测器，并表明说话人特征对检测性能有显著影响，揭示了性别、语言、年龄和合成器类型之间的差异。这些发现强调了有意识防止偏见开发的必要性，并为构建符合伦理和监管标准的非歧视性深度假音检测系统提供了基础。', 'title_zh': 'SCDF：用于偏见分析的演讲者特征DeepFake语音数据集'}
{'arxiv_id': 'arXiv:2508.07903', 'title': 'Diffusing the Blind Spot: Uterine MRI Synthesis with Diffusion Models', 'authors': 'Johanna P. Müller, Anika Knupfer, Pedro Blöss, Edoardo Berardi Vittur, Bernhard Kainz, Jana Hutter', 'link': 'https://arxiv.org/abs/2508.07903', 'abstract': 'Despite significant progress in generative modelling, existing diffusion models often struggle to produce anatomically precise female pelvic images, limiting their application in gynaecological imaging, where data scarcity and patient privacy concerns are critical. To overcome these barriers, we introduce a novel diffusion-based framework for uterine MRI synthesis, integrating both unconditional and conditioned Denoising Diffusion Probabilistic Models (DDPMs) and Latent Diffusion Models (LDMs) in 2D and 3D. Our approach generates anatomically coherent, high fidelity synthetic images that closely mimic real scans and provide valuable resources for training robust diagnostic models. We evaluate generative quality using advanced perceptual and distributional metrics, benchmarking against standard reconstruction methods, and demonstrate substantial gains in diagnostic accuracy on a key classification task. A blinded expert evaluation further validates the clinical realism of our synthetic images. We release our models with privacy safeguards and a comprehensive synthetic uterine MRI dataset to support reproducible research and advance equitable AI in gynaecology.', 'abstract_zh': '尽管生成建模取得了显著进展，现有的扩散模型在生成解剖精确的女性盆腔图像方面仍然存在局限性，这限制了其在需要数据稀缺性和患者隐私保护的妇科成像中的应用。为克服这些障碍，我们提出了一种基于扩散的子宫MRI合成新框架，结合了无条件和有条件扩散概率模型（DDPMs）以及潜在扩散模型（LDMs）的2D和3D集成。我们的方法生成了解剖上一致、高保真的合成图像，这些图像与真实扫描高度相似，为训练稳健的诊断模型提供了宝贵资源。我们使用先进的感觉和分布度量评估生成质量，并与标准重建方法进行基准测试，展示了在关键分类任务中诊断准确性显著提高。盲法专家评估进一步验证了我们合成图像的临床现实性。我们发布了具有隐私保护措施和全面合成子宫MRI数据集的模型，以支持可重复研究并推动妇科中公平的AI发展。', 'title_zh': '弥合盲区：基于扩散模型的子宫MRI合成'}
{'arxiv_id': 'arXiv:2508.07897', 'title': 'NeeCo: Image Synthesis of Novel Instrument States Based on Dynamic and Deformable 3D Gaussian Reconstruction', 'authors': 'Tianle Zeng, Junlei Hu, Gerardo Loza Galindo, Sharib Ali, Duygu Sarikaya, Pietro Valdastri, Dominic Jones', 'link': 'https://arxiv.org/abs/2508.07897', 'abstract': 'Computer vision-based technologies significantly enhance surgical automation by advancing tool tracking, detection, and localization. However, Current data-driven approaches are data-voracious, requiring large, high-quality labeled image datasets, which limits their application in surgical data science. Our Work introduces a novel dynamic Gaussian Splatting technique to address the data scarcity in surgical image datasets. We propose a dynamic Gaussian model to represent dynamic surgical scenes, enabling the rendering of surgical instruments from unseen viewpoints and deformations with real tissue backgrounds. We utilize a dynamic training adjustment strategy to address challenges posed by poorly calibrated camera poses from real-world scenarios. Additionally, we propose a method based on dynamic Gaussians for automatically generating annotations for our synthetic data. For evaluation, we constructed a new dataset featuring seven scenes with 14,000 frames of tool and camera motion and tool jaw articulation, with a background of an ex-vivo porcine model. Using this dataset, we synthetically replicate the scene deformation from the ground truth data, allowing direct comparisons of synthetic image quality. Experimental results illustrate that our method generates photo-realistic labeled image datasets with the highest values in Peak-Signal-to-Noise Ratio (29.87). We further evaluate the performance of medical-specific neural networks trained on real and synthetic images using an unseen real-world image dataset. Our results show that the performance of models trained on synthetic images generated by the proposed method outperforms those trained with state-of-the-art standard data augmentation by 10%, leading to an overall improvement in model performances by nearly 15%.', 'abstract_zh': '基于计算机视觉的技术显著提升了手术自动化程度，通过推进工具跟踪、检测和定位。然而，当前的数据驱动方法需要大量的高质量标注图像数据，限制了其在手术数据科学中的应用。我们的工作引入了一种新颖的动态高斯散点图技术以应对手术图像数据集中的数据稀缺问题。我们提出了一个动态高斯模型来表示动态手术场景，使我们能够从未见过的角度和变形中渲染手术工具，并具有真实的组织背景。我们利用一种动态训练调整策略来应对来自真实场景中校准不良的摄像机姿态所带来的挑战。此外，我们提出了一种基于动态高斯分布的方法来自动为我们的合成数据生成注释。为了评估，我们构建了一个新的数据集，包含七个场景，共计14,000帧的工具和摄像机运动以及工具夹子动作，背景为离体猪模型。使用该数据集，我们从真实数据中合成立方形场景变形，允许直接比较合成图像的质量。实验结果表明，我们的方法生成了峰值信噪比（29.87）最高的照片级真实标注图像数据集。进一步用真实和合成图像训练的医学专用神经网络在未见过的真实世界图像数据集上进行性能评估，结果显示，由所提出方法生成的合成图像训练的模型性能比最先进的标准数据增强方法高出10%，总体提高了模型性能近15%。', 'title_zh': 'NeeCo: 基于动态和可变形3D高斯重建的新颖仪器状态图像合成'}
{'arxiv_id': 'arXiv:2508.07887', 'title': 'Not Yet AlphaFold for the Mind: Evaluating Centaur as a Synthetic Participant', 'authors': 'Sabrina Namazova, Alessandra Brondetta, Younes Strittmatter, Matthew Nassar, Sebastian Musslick', 'link': 'https://arxiv.org/abs/2508.07887', 'abstract': 'Simulators have revolutionized scientific practice across the natural sciences. By generating data that reliably approximate real-world phenomena, they enable scientists to accelerate hypothesis testing and optimize experimental designs. This is perhaps best illustrated by AlphaFold, a Nobel-prize winning simulator in chemistry that predicts protein structures from amino acid sequences, enabling rapid prototyping of molecular interactions, drug targets, and protein functions. In the behavioral sciences, a reliable participant simulator - a system capable of producing human-like behavior across cognitive tasks - would represent a similarly transformative advance. Recently, Binz et al. introduced Centaur, a large language model (LLM) fine-tuned on human data from 160 experiments, proposing its use not only as a model of cognition but also as a participant simulator for "in silico prototyping of experimental studies", e.g., to advance automated cognitive science. Here, we review the core criteria for a participant simulator and assess how well Centaur meets them. Although Centaur demonstrates strong predictive accuracy, its generative behavior - a critical criterion for a participant simulator - systematically diverges from human data. This suggests that, while Centaur is a significant step toward predicting human behavior, it does not yet meet the standards of a reliable participant simulator or an accurate model of cognition.', 'abstract_zh': '模拟器已在自然科学中革新了科研实践。通过生成可靠地逼近现实世界现象的数据，它们使科学家能够加速假设检验并优化实验设计。这在AlphaFold中表现得最为明显，AlphaFold是一个获得诺贝尔奖的化学模拟器，能够从氨基酸序列预测蛋白质结构，从而快速原型设计分子间相互作用、药物靶标和蛋白质功能。在行为科学中，一个可靠的参与者模拟器——能够跨认知任务产生类似人类行为的系统——将代表类似的革命性进步。最近，Binz等人介绍了Centaur，这是一种基于160项实验中的人类数据微调的大语言模型（LLM），不仅将其用作认知模型，还提议将其用于“实验研究的计算机辅助原型设计”，例如，推动自动化认知科学的发展。在此，我们回顾了参与者模拟器的核心标准，并评估Centaur是否符合这些标准。尽管Centaur在预测准确性方面表现出色，但其生成行为——参与者模拟器的一个关键标准——系统地偏离了人类数据。这表明，虽然Centaur是对人类行为预测的一个重要进步，但它尚未达到可靠参与者模拟器或准确认知模型的标准。', 'title_zh': '尚未经AlphaFold超越：评估作为合成参与者的人机协作系统'}
{'arxiv_id': 'arXiv:2508.07885', 'title': 'Autonomous Navigation of Cloud-Controlled Quadcopters in Confined Spaces Using Multi-Modal Perception and LLM-Driven High Semantic Reasoning', 'authors': 'Shoaib Ahmmad, Zubayer Ahmed Aditto, Md Mehrab Hossain, Noushin Yeasmin, Shorower Hossain', 'link': 'https://arxiv.org/abs/2508.07885', 'abstract': 'This paper introduces an advanced AI-driven perception system for autonomous quadcopter navigation in GPS-denied indoor environments. The proposed framework leverages cloud computing to offload computationally intensive tasks and incorporates a custom-designed printed circuit board (PCB) for efficient sensor data acquisition, enabling robust navigation in confined spaces. The system integrates YOLOv11 for object detection, Depth Anything V2 for monocular depth estimation, a PCB equipped with Time-of-Flight (ToF) sensors and an Inertial Measurement Unit (IMU), and a cloud-based Large Language Model (LLM) for context-aware decision-making. A virtual safety envelope, enforced by calibrated sensor offsets, ensures collision avoidance, while a multithreaded architecture achieves low-latency processing. Enhanced spatial awareness is facilitated by 3D bounding box estimation with Kalman filtering. Experimental results in an indoor testbed demonstrate strong performance, with object detection achieving a mean Average Precision (mAP50) of 0.6, depth estimation Mean Absolute Error (MAE) of 7.2 cm, only 16 safety envelope breaches across 42 trials over approximately 11 minutes, and end-to-end system latency below 1 second. This cloud-supported, high-intelligence framework serves as an auxiliary perception and navigation system, complementing state-of-the-art drone autonomy for GPS-denied confined spaces.', 'abstract_zh': '一种基于云的支持高intelligence的自主室内GPS受限四旋翼机感知与导航系统', 'title_zh': '基于多模态感知和 大语言模型驱动高语义推理的受限空间内受控四关于我们群控无人机自主导航标题'}
{'arxiv_id': 'arXiv:2508.07877', 'title': 'Selective Contrastive Learning for Weakly Supervised Affordance Grounding', 'authors': 'WonJun Moon, Hyun Seok Seong, Jae-Pil Heo', 'link': 'https://arxiv.org/abs/2508.07877', 'abstract': "Facilitating an entity's interaction with objects requires accurately identifying parts that afford specific actions. Weakly supervised affordance grounding (WSAG) seeks to imitate human learning from third-person demonstrations, where humans intuitively grasp functional parts without needing pixel-level annotations. To achieve this, grounding is typically learned using a shared classifier across images from different perspectives, along with distillation strategies incorporating part discovery process. However, since affordance-relevant parts are not always easily distinguishable, models primarily rely on classification, often focusing on common class-specific patterns that are unrelated to affordance. To address this limitation, we move beyond isolated part-level learning by introducing selective prototypical and pixel contrastive objectives that adaptively learn affordance-relevant cues at both the part and object levels, depending on the granularity of the available information. Initially, we find the action-associated objects in both egocentric (object-focused) and exocentric (third-person example) images by leveraging CLIP. Then, by cross-referencing the discovered objects of complementary views, we excavate the precise part-level affordance clues in each perspective. By consistently learning to distinguish affordance-relevant regions from affordance-irrelevant background context, our approach effectively shifts activation from irrelevant areas toward meaningful affordance cues. Experimental results demonstrate the effectiveness of our method. Codes are available at this http URL.", 'abstract_zh': '促进实体与物体互动需要准确识别可执行特定动作的部件。弱监督功能部件定位（WSAG）旨在模仿人类从第三人称示范中学习的方式，人类在这种示范中能够直觉地把握功能部件，而无需依赖像素级标注。为了实现这一点，通常使用跨视角图像的共享分类器来进行定位学习，并结合部分发现过程融入的蒸馏策略。然而，由于功能相关的部分并不总是容易区分，模型主要依赖于分类，往往关注与功能无关的常见类别模式。为了解决这一限制，我们超越了孤立的部分级学习，引入了选择性原型和像素对比目标，能够根据可用信息的粒度在部分和物体级别自适应地学习功能相关线索。首先，我们利用CLIP在主观视角（以物体为中心）和客观视角（第三人称示例）图像中找到动作相关的物体。然后，通过跨参考互补视图中发现的物体，我们挖掘每个视角中的精确部分级功能线索。通过一致学习区分与功能相关和无关的区域，我们的方法有效地将激活从无关区域转向了有意义的功能线索。实验结果证明了我们方法的有效性。代码可在以下网址获取。', 'title_zh': '弱监督功能 grounding 的选择性对比学习'}
{'arxiv_id': 'arXiv:2508.07875', 'title': 'Towards Human-AI Collaboration System for the Detection of Invasive Ductal Carcinoma in Histopathology Images', 'authors': 'Shuo Han, Ahmed Karam Eldaly, Solomon Sunday Oyelere', 'link': 'https://arxiv.org/abs/2508.07875', 'abstract': "Invasive ductal carcinoma (IDC) is the most prevalent form of breast cancer, and early, accurate diagnosis is critical to improving patient survival rates by guiding treatment decisions. Combining medical expertise with artificial intelligence (AI) holds significant promise for enhancing the precision and efficiency of IDC detection. In this work, we propose a human-in-the-loop (HITL) deep learning system designed to detect IDC in histopathology images. The system begins with an initial diagnosis provided by a high-performance EfficientNetV2S model, offering feedback from AI to the human expert. Medical professionals then review the AI-generated results, correct any misclassified images, and integrate the revised labels into the training dataset, forming a feedback loop from the human back to the AI. This iterative process refines the model's performance over time. The EfficientNetV2S model itself achieves state-of-the-art performance compared to existing methods in the literature, with an overall accuracy of 93.65\\%. Incorporating the human-in-the-loop system further improves the model's accuracy using four experimental groups with misclassified images. These results demonstrate the potential of this collaborative approach to enhance AI performance in diagnostic systems. This work contributes to advancing automated, efficient, and highly accurate methods for IDC detection through human-AI collaboration, offering a promising direction for future AI-assisted medical diagnostics.", 'abstract_zh': '入侵性导管癌（IDC）是乳腺癌中最常见的类型，早期、准确的诊断对于通过指导治疗决策提高患者生存率至关重要。结合医学专业知识与人工智能（AI）有望显著提升IDC检测的精确性和效率。在此项工作中，我们提出了一种人工介入回路（HITL）深度学习系统，用于在组织病理学图像中检测IDC。该系统初始诊断由高性能的EfficientNetV2S模型提供，并向人类专家提供AI反馈。医务人员随后审查AI生成的结果，纠正任何误分类的图像，并将修订后的标签整合到训练数据集中，从而形成从人类回传给AI的反馈循环。这一迭代过程随着时间的推移逐步提升模型的性能。EfficientNetV2S模型本身在文献中现有方法的性能上达到最先进的表现，整体准确率为93.65%。通过人工介入回路系统，结合四个包含误分类图像的实验组进一步提升了模型的准确性。这些结果显示，这种协作方法有潜力提高诊断系统中AI的性能。这项工作通过人机协作推动自动、高效和高度准确的IDC检测方法的发展，为未来AI辅助医疗诊断提供了有前途的方向。', 'title_zh': '面向浸润性导管癌 Histopathology 图像检测的人机协作系统研究'}
{'arxiv_id': 'arXiv:2508.07852', 'title': 'Vertex Features for Neural Global Illumination', 'authors': 'Rui Su, Honghao Dong, Haojie Jin, Yisong Chen, Guoping Wang, Sheng Li', 'link': 'https://arxiv.org/abs/2508.07852', 'abstract': 'Recent research on learnable neural representations has been widely adopted in the field of 3D scene reconstruction and neural rendering applications. However, traditional feature grid representations often suffer from substantial memory footprint, posing a significant bottleneck for modern parallel computing hardware. In this paper, we present neural vertex features, a generalized formulation of learnable representation for neural rendering tasks involving explicit mesh surfaces. Instead of uniformly distributing neural features throughout 3D space, our method stores learnable features directly at mesh vertices, leveraging the underlying geometry as a compact and structured representation for neural processing. This not only optimizes memory efficiency, but also improves feature representation by aligning compactly with the surface using task-specific geometric priors. We validate our neural representation across diverse neural rendering tasks, with a specific emphasis on neural radiosity. Experimental results demonstrate that our method reduces memory consumption to only one-fifth (or even less) of grid-based representations, while maintaining comparable rendering quality and lowering inference overhead.', 'abstract_zh': '最近关于可学习神经表示的研究在3D场景重建和神经渲染应用领域得到了广泛应用。然而，传统的特征网格表示往往内存占用巨大，成为现代并行计算硬件的重要瓶颈。在本文中，我们提出了神经顶点特征，这是一种适用于涉及显式网格表面的神经渲染任务的一般化可学习表示形式。我们的方法不均匀地在3D空间中分布神经特征，而是直接将可学习特征存储在网格顶点上，利用底层几何结构作为紧凑且结构化的神经处理表示。这不仅优化了内存效率，还通过任务特定的几何先验更好地对齐特征表示。我们在多种神经渲染任务中验证了我们的神经表示，特别强调神经辐射度的研究。实验结果表明，我们的方法将内存消耗减少到网格基表示的五分之一或更少，同时保持类似的渲染质量和降低推理开销。', 'title_zh': '顶点特征在神经全局光照中的应用'}
{'arxiv_id': 'arXiv:2508.07847', 'title': 'Deep Space Weather Model: Long-Range Solar Flare Prediction from Multi-Wavelength Images', 'authors': 'Shunya Nagashima, Komei Sugiura', 'link': 'https://arxiv.org/abs/2508.07847', 'abstract': 'Accurate, reliable solar flare prediction is crucial for mitigating potential disruptions to critical infrastructure, while predicting solar flares remains a significant challenge. Existing methods based on heuristic physical features often lack representation learning from solar images. On the other hand, end-to-end learning approaches struggle to model long-range temporal dependencies in solar images. In this study, we propose Deep Space Weather Model (Deep SWM), which is based on multiple deep state space models for handling both ten-channel solar images and long-range spatio-temporal dependencies. Deep SWM also features a sparse masked autoencoder, a novel pretraining strategy that employs a two-phase masking approach to preserve crucial regions such as sunspots while compressing spatial information. Furthermore, we built FlareBench, a new public benchmark for solar flare prediction covering a full 11-year solar activity cycle, to validate our method. Our method outperformed baseline methods and even human expert performance on standard metrics in terms of performance and reliability. The project page can be found at this https URL.', 'abstract_zh': '准确可靠的太阳耀斑预测对于缓解关键基础设施潜在的干扰至关重要，然而预测太阳耀斑仍然是一个重大挑战。现有的基于启发式物理特征的方法往往缺乏对太阳图像的表示学习，而端到端学习方法又难以 modeling 太阳图像中的长期时空依赖关系。本研究提出 Deep Space Weather Model (Deep SWM)，该模型基于多个深度状态空间模型，用于处理十通道太阳图像和长期时空依赖关系。Deep SWM 还配备了稀疏掩码自编码器，这是一种新颖的预训练策略，采用两阶段掩码方法保留如日斑等关键区域，同时压缩空间信息。此外，我们构建了 FlareBench，这是一个新的公开基准，涵盖完整的 11 年太阳活动周期，用于验证我们的方法。我们的方法在标准指标上在性能和可靠性方面均超过了基准方法和人类专家的表现。项目页面详见这个 <https://>。', 'title_zh': '深空天气模型：多波长图像的长期太阳flare预测'}
{'arxiv_id': 'arXiv:2508.07842', 'title': 'DETACH: Cross-domain Learning for Long-Horizon Tasks via Mixture of Disentangled Experts', 'authors': 'Yutong Shen, Hangxu Liu, Penghui Liu, Ruizhe Xia, Tianyi Yao, Yitong Sun, Tongtong Feng', 'link': 'https://arxiv.org/abs/2508.07842', 'abstract': 'Long-Horizon (LH) tasks in Human-Scene Interaction (HSI) are complex multi-step tasks that require continuous planning, sequential decision-making, and extended execution across domains to achieve the final goal. However, existing methods heavily rely on skill chaining by concatenating pre-trained subtasks, with environment observations and self-state tightly coupled, lacking the ability to generalize to new combinations of environments and skills, failing to complete various LH tasks across domains. To solve this problem, this paper presents DETACH, a cross-domain learning framework for LH tasks via biologically inspired dual-stream disentanglement. Inspired by the brain\'s "where-what" dual pathway mechanism, DETACH comprises two core modules: i) an environment learning module for spatial understanding, which captures object functions, spatial relationships, and scene semantics, achieving cross-domain transfer through complete environment-self disentanglement; ii) a skill learning module for task execution, which processes self-state information including joint degrees of freedom and motor patterns, enabling cross-skill transfer through independent motor pattern encoding. We conducted extensive experiments on various LH tasks in HSI scenes. Compared with existing methods, DETACH can achieve an average subtasks success rate improvement of 23% and average execution efficiency improvement of 29%.', 'abstract_zh': '跨域Long-Horizon任务在人类-场景交互中的生物启发式双流解纠缠学习框架', 'title_zh': 'DETACH：通过解纠缠专家混合实现跨域长时任务学习'}
{'arxiv_id': 'arXiv:2508.07829', 'title': 'Auditory Intelligence: Understanding the World Through Sound', 'authors': 'Hyeonuk Nam', 'link': 'https://arxiv.org/abs/2508.07829', 'abstract': 'Recent progress in auditory intelligence has yielded high-performing systems for sound event detection (SED), acoustic scene classification (ASC), automated audio captioning (AAC), and audio question answering (AQA). Yet these tasks remain largely constrained to surface-level recognition-capturing what happened but not why, what it implies, or how it unfolds in context. I propose a conceptual reframing of auditory intelligence as a layered, situated process that encompasses perception, reasoning, and interaction. To instantiate this view, I introduce four cognitively inspired task paradigms-ASPIRE, SODA, AUX, and AUGMENT-those structure auditory understanding across time-frequency pattern captioning, hierarchical event/scene description, causal explanation, and goal-driven interpretation, respectively. Together, these paradigms provide a roadmap toward more generalizable, explainable, and human-aligned auditory intelligence, and are intended to catalyze a broader discussion of what it means for machines to understand sound.', 'abstract_zh': '近期听觉智能的进步已实现了在声事件检测（SED\nusergradable systemshic, 清晰表述的任务范式 - audioX辅助 - 辅助 - 和和augmented用户导向的听觉表面时间 - 时间-频率表征 - 描述性绘 - 事件级场景级表 - 因果解释 - 任务的驱动理解 - � 并一起这些范式提供了一条通往更泛化和用户导向的听觉智能的 roadmap - � 并旨在促进对机器如何表征表面的更广泛讨论 -', 'title_zh': '听觉智能：通过声音理解世界'}
{'arxiv_id': 'arXiv:2508.07819', 'title': 'Architectural Co-Design for Zero-Shot Anomaly Detection: Decoupling Representation and Dynamically Fusing Features in CLIP', 'authors': 'Ke Ma, Jun Long, Hongxiao Fei, Liujie Hua, Yueyi Luo', 'link': 'https://arxiv.org/abs/2508.07819', 'abstract': 'Pre-trained Vision-Language Models (VLMs) face a significant adaptation gap when applied to Zero-Shot Anomaly Detection (ZSAD), stemming from their lack of local inductive biases for dense prediction and their reliance on inflexible feature fusion paradigms. We address these limitations through an Architectural Co-Design framework that jointly refines feature representation and cross-modal fusion. Our method integrates a parameter-efficient Convolutional Low-Rank Adaptation (Conv-LoRA) adapter to inject local inductive biases for fine-grained representation, and introduces a Dynamic Fusion Gateway (DFG) that leverages visual context to adaptively modulate text prompts, enabling a powerful bidirectional fusion. Extensive experiments on diverse industrial and medical benchmarks demonstrate superior accuracy and robustness, validating that this synergistic co-design is critical for robustly adapting foundation models to dense perception tasks.', 'abstract_zh': '预训练视觉-语言模型在零-shot 异常检测中的适应性差距源于它们缺乏局部归纳偏置以及依赖于刚性特征融合范式。我们通过一种架构协同设计框架共同 refinement 特征表示和跨模态融合来解决这些限制。该方法集成了一个参数高效的卷积低秩适应（Conv-LoRA）适配器以注入局部归纳偏置以促进细粒度表示，并引入了一个动态融合网关（DFG），利用视觉上下文自适应调整文本提示，实现强大的双向融合。在多样化的工业和医疗基准上的广泛实验表明，此协同设计能够显著提高准确性和鲁棒性，验证了这种协同设计对于稳健地适应基础模型到密集感知任务的重要性。', 'title_zh': '零样本异常检测中的架构联合设计：CLIP中代表和动态特征融合的解耦'}
{'arxiv_id': 'arXiv:2508.07817', 'title': 'MIND: A Noise-Adaptive Denoising Framework for Medical Images Integrating Multi-Scale Transformer', 'authors': 'Tao Tang, Chengxu Yang', 'link': 'https://arxiv.org/abs/2508.07817', 'abstract': 'The core role of medical images in disease diagnosis makes their quality directly affect the accuracy of clinical judgment. However, due to factors such as low-dose scanning, equipment limitations and imaging artifacts, medical images are often accompanied by non-uniform noise interference, which seriously affects structure recognition and lesion detection. This paper proposes a medical image adaptive denoising model (MI-ND) that integrates multi-scale convolutional and Transformer architecture, introduces a noise level estimator (NLE) and a noise adaptive attention module (NAAB), and realizes channel-spatial attention regulation and cross-modal feature fusion driven by noise perception. Systematic testing is carried out on multimodal public datasets. Experiments show that this method significantly outperforms the comparative methods in image quality indicators such as PSNR, SSIM, and LPIPS, and improves the F1 score and ROC-AUC in downstream diagnostic tasks, showing strong prac-tical value and promotional potential. The model has outstanding benefits in structural recovery, diagnostic sensitivity, and cross-modal robustness, and provides an effective solution for medical image enhancement and AI-assisted diagnosis and treatment.', 'abstract_zh': '医学图像在疾病诊断中的核心作用使得其质量直接影响临床判断的准确性。然而，由于低剂量扫描、设备限制和成像伪影等因素，医学图像常伴随非均匀噪声干扰，严重影响结构识别和病灶检测。本文提出了一种融合多尺度卷积和Transformer架构的医学图像自适应去噪模型（MI-ND），引入了噪声水平估计器（NLE）和噪声自适应注意力模块（NAAB），并通过噪声感知实现了通道-空间注意力调节和跨模态特征融合。系统地在多模态公开数据集上进行了测试。实验结果显示，该方法在PSNR、SSIM和LPIPS等图像质量指标上显著优于对比方法，并在下流诊断任务中提高了F1分数和ROC-AUC，表现出强烈的实际价值和推广潜力。该模型在结构恢复、诊断灵敏度和跨模态鲁棒性方面具有显著优势，并为医学图像增强和AI辅助诊断与治疗提供了有效解决方案。', 'title_zh': 'MIND：一种结合多尺度变压器的自适应噪声去除医学图像框架'}
{'arxiv_id': 'arXiv:2508.07773', 'title': 'PCA-Guided Autoencoding for Structured Dimensionality Reduction in Active Infrared Thermography', 'authors': 'Mohammed Salah, Numan Saeed, Davor Svetinovic, Stefano Sfarra, Mohammed Omar, Yusra Abdulrahman', 'link': 'https://arxiv.org/abs/2508.07773', 'abstract': 'Active Infrared thermography (AIRT) is a widely adopted non-destructive testing (NDT) technique for detecting subsurface anomalies in industrial components. Due to the high dimensionality of AIRT data, current approaches employ non-linear autoencoders (AEs) for dimensionality reduction. However, the latent space learned by AIRT AEs lacks structure, limiting their effectiveness in downstream defect characterization tasks. To address this limitation, this paper proposes a principal component analysis guided (PCA-guided) autoencoding framework for structured dimensionality reduction to capture intricate, non-linear features in thermographic signals while enforcing a structured latent space. A novel loss function, PCA distillation loss, is introduced to guide AIRT AEs to align the latent representation with structured PCA components while capturing the intricate, non-linear patterns in thermographic signals. To evaluate the utility of the learned, structured latent space, we propose a neural network-based evaluation metric that assesses its suitability for defect characterization. Experimental results show that the proposed PCA-guided AE outperforms state-of-the-art dimensionality reduction methods on PVC, CFRP, and PLA samples in terms of contrast, signal-to-noise ratio (SNR), and neural network-based metrics.', 'abstract_zh': '主动红外热成像（AIRT）是一种广泛采用的无损检测（NDT）技术，用于检测工业部件的亚表面异常。由于AIRT数据的高维度性，现有方法采用非线性自编码器（AEs）进行降维。然而，AIRT自编码器学到的潜在空间缺乏结构，限制了其在缺陷表征任务中的有效性。为解决这一局限性，本文提出了一种主成分分析指导（PCA-guided）的自编码框架，用于结构化降维，以捕获热成像信号中的复杂、非线性特征，并确保潜在空间具有结构化。引入了一种新的损失函数——PCA蒸馏损失，以指导AIRT自编码器使潜在表示与结构化的PCA成分对齐，同时捕获热成像信号中的复杂、非线性模式。为了评估学习到的结构化潜在空间的实用性，提出了一种基于神经网络的评估度量，评估其在缺陷表征中的适用性。实验结果表明，提出的PCA指导自编码器在PVC、CFRP和PLA样本的对比度、信噪比（SNR）和基于神经网络的度量上优于最先进的降维方法。', 'title_zh': '基于PCA引导的自编码结构化降维在主动红外热图中的应用'}
{'arxiv_id': 'arXiv:2508.07768', 'title': 'Pareto Multi-Objective Alignment for Language Models', 'authors': 'Qiang He, Setareh Maghsudi', 'link': 'https://arxiv.org/abs/2508.07768', 'abstract': "Large language models (LLMs) are increasingly deployed in real-world applications that require careful balancing of multiple, often conflicting, objectives, such as informativeness versus conciseness, or helpfulness versus creativity. However, current alignment methods, primarily based on RLHF, optimize LLMs toward a single reward function, resulting in rigid behavior that fails to capture the complexity and diversity of human preferences. This limitation hinders the adaptability of LLMs to practical scenarios, making multi-objective alignment (MOA) a critical yet underexplored area. To bridge this gap, we propose Pareto Multi-Objective Alignment (PAMA), a principled and computationally efficient algorithm designed explicitly for MOA in LLMs. In contrast to computationally prohibitive multi-objective optimization (MOO) methods, PAMA transforms multi-objective RLHF into a convex optimization with a closed-form solution, significantly enhancing scalability. Traditional MOO approaches suffer from prohibitive O(n^2*d) complexity, where d represents the number of model parameters, typically in the billions for LLMs, rendering direct optimization infeasible. PAMA reduces this complexity to O(n) where n is the number of objectives, enabling optimization to be completed within milliseconds. We provide theoretical guarantees that PAMA converges to a Pareto stationary point, where no objective can be improved without degrading at least one other. Extensive experiments across language models ranging from 125M to 7B parameters demonstrate PAMA's robust and effective MOA capabilities, aligning with its theoretical advantages. PAMA provides a highly efficient solution to the MOA problem that was previously considered intractable, offering a practical and theoretically grounded approach to aligning LLMs with diverse human values, paving the way for versatile and adaptable real-world AI deployments.", 'abstract_zh': '基于帕累托多目标对齐的大型语言模型多目标对齐方法（Pareto Multi-Objective Alignment for Large Language Models）', 'title_zh': '帕累托多目标对齐的语言模型'}
{'arxiv_id': 'arXiv:2508.07766', 'title': 'UniSVG: A Unified Dataset for Vector Graphic Understanding and Generation with Multimodal Large Language Models', 'authors': 'Jinke Li, Jiarui Yu, Chenxing Wei, Hande Dong, Qiang Lin, Liangjing Yang, Zhicai Wang, Yanbin Hao', 'link': 'https://arxiv.org/abs/2508.07766', 'abstract': "Unlike bitmap images, scalable vector graphics (SVG) maintain quality when scaled, frequently employed in computer vision and artistic design in the representation of SVG code. In this era of proliferating AI-powered systems, enabling AI to understand and generate SVG has become increasingly urgent. However, AI-driven SVG understanding and generation (U&G) remain significant challenges. SVG code, equivalent to a set of curves and lines controlled by floating-point parameters, demands high precision in SVG U&G. Besides, SVG generation operates under diverse conditional constraints, including textual prompts and visual references, which requires powerful multi-modal processing for condition-to-SVG transformation. Recently, the rapid growth of Multi-modal Large Language Models (MLLMs) have demonstrated capabilities to process multi-modal inputs and generate complex vector controlling parameters, suggesting the potential to address SVG U&G tasks within a unified model. To unlock MLLM's capabilities in the SVG area, we propose an SVG-centric dataset called UniSVG, comprising 525k data items, tailored for MLLM training and evaluation. To our best knowledge, it is the first comprehensive dataset designed for unified SVG generation (from textual prompts and images) and SVG understanding (color, category, usage, etc.). As expected, learning on the proposed dataset boosts open-source MLLMs' performance on various SVG U&G tasks, surpassing SOTA close-source MLLMs like GPT-4V. We release dataset, benchmark, weights, codes and experiment details on this https URL.", 'abstract_zh': '不同于位图图像，可伸缩矢量图形（SVG）在缩放时保持质量，常用于计算机视觉和艺术设计中的SVG代码表示。在AI驱动系统普及的时代，使AI理解并生成SVG变得日益迫切。然而，基于AI的SVG理解和生成（U&G）仍然是重大挑战。SVG代码类似于由浮点参数控制的曲线和线条集，要求在SVG理解和生成中具有高精度。此外，SVG生成受到多种条件约束，包括文本提示和视觉参考，这需要强大的多模态处理来实现条件到SVG的转换。最近，多模态大型语言模型（MLLM）的迅速增长展示了处理多模态输入和生成复杂向量控制参数的能力，表明有可能在统一模型中解决SVG理解和生成任务。为了释放MLLM在SVG领域的潜力，我们提出了一种以SVG为中心的数据集UniSVG，包含525,000个数据项，适用于MLLM培训和评估。据我们所知，这是首个专为统一SVG生成（从文本提示和图像）和SVG理解（颜色、类别、用途等）设计的综合数据集。正如预期的那样，使用提出的数据集在各种SVG理解和生成任务上提升了开源MLLM的性能，超越了如GPT-4V等封闭源MLLM。我们在此URL上发布了数据集、基准测试、权重、代码和实验详情。', 'title_zh': 'UniSVG：用于多模态大规模语言模型的矢量图形理解与生成统一数据集'}
{'arxiv_id': 'arXiv:2508.07763', 'title': 'Sparse Probabilistic Graph Circuits', 'authors': 'Martin Rektoris, Milan Papež, Václav Šmídl, Tomáš Pevný', 'link': 'https://arxiv.org/abs/2508.07763', 'abstract': 'Deep generative models (DGMs) for graphs achieve impressively high expressive power thanks to very efficient and scalable neural networks. However, these networks contain non-linearities that prevent analytical computation of many standard probabilistic inference queries, i.e., these DGMs are considered \\emph{intractable}. While recently proposed Probabilistic Graph Circuits (PGCs) address this issue by enabling \\emph{tractable} probabilistic inference, they operate on dense graph representations with $\\mathcal{O}(n^2)$ complexity for graphs with $n$ nodes and \\emph{$m$ edges}. To address this scalability issue, we introduce Sparse PGCs, a new class of tractable generative models that operate directly on sparse graph representation, reducing the complexity to $\\mathcal{O}(n + m)$, which is particularly beneficial for $m \\ll n^2$. In the context of de novo drug design, we empirically demonstrate that SPGCs retain exact inference capabilities, improve memory efficiency and inference speed, and match the performance of intractable DGMs in key metrics.', 'abstract_zh': '基于稀疏图的可计算概率图电路在图生成模型中的应用', 'title_zh': '稀疏概率图电路'}
{'arxiv_id': 'arXiv:2508.07750', 'title': 'Learning to Align, Aligning to Learn: A Unified Approach for Self-Optimized Alignment', 'authors': 'Haowen Wang, Yun Yue, Zhiling Ye, Shuowen Zhang, Lei Fan, Jiaxin Liang, Jiadi Jiang, Cheng Wei, Jingyuan Deng, Xudong Han, Ji Li, Chunxiao Guo, Peng Wei, Jian Wang, Jinjie Gu', 'link': 'https://arxiv.org/abs/2508.07750', 'abstract': "Alignment methodologies have emerged as a critical pathway for enhancing language model alignment capabilities. While SFT (supervised fine-tuning) accelerates convergence through direct token-level loss intervention, its efficacy is constrained by offline policy trajectory. In contrast, RL(reinforcement learning) facilitates exploratory policy optimization, but suffers from low sample efficiency and stringent dependency on high-quality base models. To address these dual challenges, we propose GRAO (Group Relative Alignment Optimization), a unified framework that synergizes the respective strengths of SFT and RL through three key innovations: 1) A multi-sample generation strategy enabling comparative quality assessment via reward feedback; 2) A novel Group Direct Alignment Loss formulation leveraging intra-group relative advantage weighting; 3) Reference-aware parameter updates guided by pairwise preference dynamics. Our theoretical analysis establishes GRAO's convergence guarantees and sample efficiency advantages over conventional approaches. Comprehensive evaluations across complex human alignment tasks demonstrate GRAO's superior performance, achieving 57.70\\%,17.65\\% 7.95\\% and 5.18\\% relative improvements over SFT, DPO, PPO and GRPO baselines respectively. This work provides both a theoretically grounded alignment framework and empirical evidence for efficient capability evolution in language models.", 'abstract_zh': '对齐方法已经成为了提升语言模型对齐能力的关键路径。虽然监督微调（SFT）通过直接的令牌级级\nuserntl 水平损失干预加速了收敛，但其效果受限于离线策略。相比之下， �ilian 指令式强化学习（RL）促进探索性的策略优化，但其样本效率较低，并且对高质量基础模型有严格的依赖性。为了应对这双重挑战， 我们提出了 GRAO（组相对对齐优化），这是一种统一框架，结合 SFT 和和 RL 的各自优势进行创新：（1）多样的本生成策略，使通过奖励反馈进行对比性评估；（（）提出了一种组内相对优势的的对直接对对齐损失函数形式；3）参考感知的参数更新，由成对对对对 对和偏好引导。我们的理论分析证明了GRAO的收敛性保证和样本效率优势。全面评估复杂的人类对对对号对对件任务表明了GRAO的优越性，分别优于S7\nuser yal 基准分别为57.7\\%%，、17.6\\%%、5.9\\%% 和 5.18\\%%。这提供了一种理论支撑的对齐框架，并并 实证证据证明了在语言模型中有效能力的进化。 değerlendirme', 'title_zh': '学习对齐，对齐学习：自优化对齐的一体化方法'}
{'arxiv_id': 'arXiv:2508.07745', 'title': 'Chimera: Harnessing Multi-Agent LLMs for Automatic Insider Threat Simulation', 'authors': 'Jiongchi Yu, Xiaofei Xie, Qiang Hu, Yuhan Ma, Ziming Zhao', 'link': 'https://arxiv.org/abs/2508.07745', 'abstract': "Insider threats, which can lead to severe losses, remain a major security concern. While machine learning-based insider threat detection (ITD) methods have shown promising results, their progress is hindered by the scarcity of high-quality data. Enterprise data is sensitive and rarely accessible, while publicly available datasets, when limited in scale due to cost, lack sufficient real-world coverage; and when purely synthetic, they fail to capture rich semantics and realistic user behavior. To address this, we propose Chimera, the first large language model (LLM)-based multi-agent framework that automatically simulates both benign and malicious insider activities and collects diverse logs across diverse enterprise environments. Chimera models each employee with agents that have role-specific behavior and integrates modules for group meetings, pairwise interactions, and autonomous scheduling, capturing realistic organizational dynamics. It incorporates 15 types of insider attacks (e.g., IP theft, system sabotage) and has been deployed to simulate activities in three sensitive domains: technology company, finance corporation, and medical institution, producing a new dataset, ChimeraLog. We assess ChimeraLog via human studies and quantitative analysis, confirming its diversity, realism, and presence of explainable threat patterns. Evaluations of existing ITD methods show an average F1-score of 0.83, which is significantly lower than 0.99 on the CERT dataset, demonstrating ChimeraLog's higher difficulty and utility for advancing ITD research.", 'abstract_zh': '基于大型语言模型的多agent框架Chimera：自动模拟恶意内部威胁活动以促进内部威胁检测研究', 'title_zh': 'Chimera: 利用多代理LLM进行自动內部威胁模拟'}
{'arxiv_id': 'arXiv:2508.07742', 'title': 'A Rule-Based Approach to Specifying Preferences over Conflicting Facts and Querying Inconsistent Knowledge Bases', 'authors': 'Meghyn Bienvenu, Camille Bourgaux, Katsumi Inoue, Robin Jean', 'link': 'https://arxiv.org/abs/2508.07742', 'abstract': 'Repair-based semantics have been extensively studied as a means of obtaining meaningful answers to queries posed over inconsistent knowledge bases (KBs). While several works have considered how to exploit a priority relation between facts to select optimal repairs, the question of how to specify such preferences remains largely unaddressed. This motivates us to introduce a declarative rule-based framework for specifying and computing a priority relation between conflicting facts. As the expressed preferences may contain undesirable cycles, we consider the problem of determining when a set of preference rules always yields an acyclic relation, and we also explore a pragmatic approach that extracts an acyclic relation by applying various cycle removal techniques. Towards an end-to-end system for querying inconsistent KBs, we present a preliminary implementation and experimental evaluation of the framework, which employs answer set programming to evaluate the preference rules, apply the desired cycle resolution techniques to obtain a priority relation, and answer queries under prioritized-repair semantics.', 'abstract_zh': '基于修复的语义在不一致知识库上查询时获取有意义答案方面已被广泛研究。尽管已有不少工作考虑了如何利用事实间的优先关系来选择最优修复，但如何指定这类偏好依然很大程度上未被解决。这促使我们提出一个声明性规则框架，用于指定和计算冲突事实之间的优先关系。由于表达的偏好可能包含不可取的循环，我们考虑了当一组偏好规则总能产生无环关系时的情况，并探索了通过应用各种循环删除技术来提取无环关系的实际方法。为了构建一个完整的查询不一致知识库系统，我们展示了该框架的初步实现和实验评估，该框架使用回答集编程来评估偏好规则，应用所需的循环解决技术以获得优先关系，并在优先修复语义下回答查询。', 'title_zh': '基于规则的方法在冲突事实和不一致知识库中指定偏好查询'}
{'arxiv_id': 'arXiv:2508.07731', 'title': 'CognitiveArm: Enabling Real-Time EEG-Controlled Prosthetic Arm Using Embodied Machine Learning', 'authors': 'Abdul Basit, Maha Nawaz, Saim Rehman, Muhammad Shafique', 'link': 'https://arxiv.org/abs/2508.07731', 'abstract': "Efficient control of prosthetic limbs via non-invasive brain-computer interfaces (BCIs) requires advanced EEG processing, including pre-filtering, feature extraction, and action prediction, performed in real time on edge AI hardware. Achieving this on resource-constrained devices presents challenges in balancing model complexity, computational efficiency, and latency. We present CognitiveArm, an EEG-driven, brain-controlled prosthetic system implemented on embedded AI hardware, achieving real-time operation without compromising accuracy. The system integrates BrainFlow, an open-source library for EEG data acquisition and streaming, with optimized deep learning (DL) models for precise brain signal classification. Using evolutionary search, we identify Pareto-optimal DL configurations through hyperparameter tuning, optimizer analysis, and window selection, analyzed individually and in ensemble configurations. We apply model compression techniques such as pruning and quantization to optimize models for embedded deployment, balancing efficiency and accuracy. We collected an EEG dataset and designed an annotation pipeline enabling precise labeling of brain signals corresponding to specific intended actions, forming the basis for training our optimized DL models. CognitiveArm also supports voice commands for seamless mode switching, enabling control of the prosthetic arm's 3 degrees of freedom (DoF). Running entirely on embedded hardware, it ensures low latency and real-time responsiveness. A full-scale prototype, interfaced with the OpenBCI UltraCortex Mark IV EEG headset, achieved up to 90% accuracy in classifying three core actions (left, right, idle). Voice integration enables multiplexed, variable movement for everyday tasks (e.g., handshake, cup picking), enhancing real-world performance and demonstrating CognitiveArm's potential for advanced prosthetic control.", 'abstract_zh': '通过非侵入式脑计算机接口（BCIs）高效控制假肢的手部需要在边缘AI硬件上实时进行先进的EEG处理，包括预滤波、特征提取和动作预测。在资源受限的设备上实现这一目标面临在模型复杂性、计算效率和延迟之间平衡的挑战。我们提出CognitiveArm，一个基于EEG的脑控假肢系统，该系统在嵌入式AI硬件上实现，能够实现实时操作而不牺牲准确性。该系统整合了BrainFlow开源库进行EEG数据采集和流式传输，并结合了优化的深度学习（DL）模型进行精确的脑信号分类。通过进化搜索，我们通过对超参数调优、优化器分析和窗口选择进行个体分析和整体配置分析，确定了Pareto最优的DL配置。我们运用模型压缩技术（如剪枝和量化）来优化模型以适应嵌入式部署，平衡效率和准确性。我们收集了一个EEG数据集，并设计了注释流水线，使其能够精确标注与特定意图动作对应的脑信号，为训练优化的DL模型奠定了基础。CognitiveArm还支持语音命令，使模式无缝切换，从而控制假肢的3个自由度（DoF）。该系统完全运行在嵌入式硬件上，确保低延迟和实时响应。与OpenBCI UltraCortex Mark IV EEG头戴设备进行接口的全规模原型在分类三个主要动作（左、右、空闲）上实现了高达90%的准确性。语音集成使得CognitiveArm能够执行日常生活任务中的多重可变动作（如握手、拿杯子），增强了实际性能并展示了其在高级假肢控制方面的潜力。', 'title_zh': '认知臂：基于嵌入式机器学习的实时EEG控制假肢臂'}
{'arxiv_id': 'arXiv:2508.07714', 'title': 'DoorDet: Semi-Automated Multi-Class Door Detection Dataset via Object Detection and Large Language Models', 'authors': 'Licheng Zhang, Bach Le, Naveed Akhtar, Tuan Ngo', 'link': 'https://arxiv.org/abs/2508.07714', 'abstract': 'Accurate detection and classification of diverse door types in floor plans drawings is critical for multiple applications, such as building compliance checking, and indoor scene understanding. Despite their importance, publicly available datasets specifically designed for fine-grained multi-class door detection remain scarce. In this work, we present a semi-automated pipeline that leverages a state-of-the-art object detector and a large language model (LLM) to construct a multi-class door detection dataset with minimal manual effort. Doors are first detected as a unified category using a deep object detection model. Next, an LLM classifies each detected instance based on its visual and contextual features. Finally, a human-in-the-loop stage ensures high-quality labels and bounding boxes. Our method significantly reduces annotation cost while producing a dataset suitable for benchmarking neural models in floor plan analysis. This work demonstrates the potential of combining deep learning and multimodal reasoning for efficient dataset construction in complex real-world domains.', 'abstract_zh': '准确检测和分类楼层平面图中多样的门类型对于建筑合规检查和室内场景理解等多重应用至关重要。尽管门检测的重要性不言而喻，但专门用于细致多类别门检测的数据集仍然稀缺。本文提出了一种半自动管道方法，利用最先进的对象检测器和大型语言模型（LLM）构建多类别门检测数据集，同时大大减少了人工努力。首先，使用深度对象检测模型统一检测门类别。然后，利用LLM根据每个检测实例的视觉和上下文特征进行分类。最后，人工介入阶段确保高质量的标签和边界框。本方法显著降低了标注成本，同时生成适合神经模型基准测试的楼层平面图分析数据集。本工作展示了在复杂现实世界领域结合深度学习和多模态推理以高效构建数据集的潜在可能性。', 'title_zh': 'DoorDet: 基于对象检测和大型语言模型的半自动多类别门检测数据集'}
{'arxiv_id': 'arXiv:2508.07710', 'title': 'Training-Free ANN-to-SNN Conversion for High-Performance Spiking Transformer', 'authors': 'Jingya Wang, Xin Deng, Wenjie Wei, Dehao Zhang, Shuai Wang, Qian Sun, Jieyuan Zhang, Hanwen Liu, Ning Xie, Malu Zhang', 'link': 'https://arxiv.org/abs/2508.07710', 'abstract': 'Leveraging the event-driven paradigm, Spiking Neural Networks (SNNs) offer a promising approach for constructing energy-efficient Transformer architectures. Compared to directly trained Spiking Transformers, ANN-to-SNN conversion methods bypass the high training costs. However, existing methods still suffer from notable limitations, failing to effectively handle nonlinear operations in Transformer architectures and requiring additional fine-tuning processes for pre-trained ANNs. To address these issues, we propose a high-performance and training-free ANN-to-SNN conversion framework tailored for Transformer architectures. Specifically, we introduce a Multi-basis Exponential Decay (MBE) neuron, which employs an exponential decay strategy and multi-basis encoding method to efficiently approximate various nonlinear operations. It removes the requirement for weight modifications in pre-trained ANNs. Extensive experiments across diverse tasks (CV, NLU, NLG) and mainstream Transformer architectures (ViT, RoBERTa, GPT-2) demonstrate that our method achieves near-lossless conversion accuracy with significantly lower latency. This provides a promising pathway for the efficient and scalable deployment of Spiking Transformers in real-world applications.', 'abstract_zh': '利用事件驱动范式，脉冲神经网络（SNN）为构建能效型Transformer架构提供了有前途的方法。与直接训练的脉冲Transformer相比，ANN到SNN转换方法规避了高昂的训练成本。然而，现有方法仍存在显著的局限性，无法有效处理Transformer架构中的非线性操作，并需要额外的微调过程来调整预训练的ANN权重。为解决这些问题，我们提出了一种针对Transformer架构的高性能且无需训练的ANN到SNN转换框架。具体而言，我们引入了一种多基底指数衰减（MBE）神经元，该神经元通过采用指数衰减策略和多基底编码方法来高效地近似各种非线性操作，从而去除对预训练ANN权重修改的要求。在CV、NLU、NLG等多种任务以及主流Transformer架构（ViT、RoBERTa、GPT-2）上的广泛实验表明，我们的方法实现了近无损的转换精度，且具有显著较低的延迟。这为在实际应用中高效且可扩展地部署脉冲Transformer提供了有前途的途径。', 'title_zh': '训练-free 的 ANN 到 SNN 转换以实现高性能脉冲变压器'}
{'arxiv_id': 'arXiv:2508.07706', 'title': 'Energy Consumption in Parallel Neural Network Training', 'authors': 'Philipp Huber, David Li, Juan Pedro Gutiérrez Hermosillo Muriedas, Deifilia Kieckhefen, Markus Götz, Achim Streit, Charlotte Debus', 'link': 'https://arxiv.org/abs/2508.07706', 'abstract': 'The increasing demand for computational resources of training neural networks leads to a concerning growth in energy consumption. While parallelization has enabled upscaling model and dataset sizes and accelerated training, its impact on energy consumption is often overlooked. To close this research gap, we conducted scaling experiments for data-parallel training of two models, ResNet50 and FourCastNet, and evaluated the impact of parallelization parameters, i.e., GPU count, global batch size, and local batch size, on predictive performance, training time, and energy consumption. We show that energy consumption scales approximately linearly with the consumed resources, i.e., GPU hours; however, the respective scaling factor differs substantially between distinct model trainings and hardware, and is systematically influenced by the number of samples and gradient updates per GPU hour. Our results shed light on the complex interplay of scaling up neural network training and can inform future developments towards more sustainable AI research.', 'abstract_zh': '不断增加的神经网络训练计算资源需求导致能源消耗显著增长。虽然并行化能够扩大模型和数据集规模并加速训练，但其对能源消耗的影响往往被忽视。为填补这一研究空白，我们针对ResNet50和FourCastNet两种模型进行了数据并行训练的扩展实验，并评估了并行化参数（如GPU数量、全局批次大小和局部批次大小）对预测性能、训练时间和能源消耗的影响。结果显示，能源消耗与消耗的资源（如GPU小时）大致呈线性增长，但不同模型训练和硬件之间的相应放大因子存在显著差异，并且系统地受到每GPU小时样本数和梯度更新次数的影响。我们的研究结果揭示了扩展神经网络训练的复杂交互作用，并能为未来更具可持续性的AI研究提供指导。', 'title_zh': '并行神经网络训练中的能耗分析'}
{'arxiv_id': 'arXiv:2508.07690', 'title': 'LoSemB: Logic-Guided Semantic Bridging for Inductive Tool Retrieval', 'authors': 'Luyao Zhuang, Qinggang Zhang, Huachi Zhou, Juhua Liu, Qing Li, Xiao Huang', 'link': 'https://arxiv.org/abs/2508.07690', 'abstract': 'Tool learning has emerged as a promising paradigm for large language models (LLMs) to solve many real-world tasks. Nonetheless, with the tool repository rapidly expanding, it is impractical to contain all tools within the limited input length of LLMs. To alleviate these issues, researchers have explored incorporating a tool retrieval module to select the most relevant tools or represent tools as unique tokens within LLM parameters. However, most state-of-the-art methods are under transductive settings, assuming all tools have been observed during training. Such a setting deviates from reality as the real-world tool repository is evolving and incorporates new tools frequently. When dealing with these unseen tools, which refer to tools not encountered during the training phase, these methods are limited by two key issues, including the large distribution shift and the vulnerability of similarity-based retrieval. To this end, inspired by human cognitive processes of mastering unseen tools through discovering and applying the logical information from prior experience, we introduce a novel Logic-Guided Semantic Bridging framework for inductive tool retrieval, namely, LoSemB, which aims to mine and transfer latent logical information for inductive tool retrieval without costly retraining. Specifically, LoSemB contains a logic-based embedding alignment module to mitigate distribution shifts and implements a relational augmented retrieval mechanism to reduce the vulnerability of similarity-based retrieval. Extensive experiments demonstrate that LoSemB achieves advanced performance in inductive settings while maintaining desirable effectiveness in the transductive setting.', 'abstract_zh': '基于逻辑指导的语义桥梁框架：诱导工具检索（LoSemB）', 'title_zh': 'LoSemB: 逻辑引导的语义桥接用于归纳工具检索'}
{'arxiv_id': 'arXiv:2508.07683', 'title': 'TAR-TVG: Enhancing VLMs with Timestamp Anchor-Constrained Reasoning for Temporal Video Grounding', 'authors': 'Chaohong Guo, Xun Mo, Yongwei Nie, Xuemiao Xu, Chao Xu, Fei Yu, Chengjiang Long', 'link': 'https://arxiv.org/abs/2508.07683', 'abstract': 'Temporal Video Grounding (TVG) aims to precisely localize video segments corresponding to natural language queries, which is a critical capability for long-form video understanding. Although existing reinforcement learning approaches encourage models to generate reasoning chains before predictions, they fail to explicitly constrain the reasoning process to ensure the quality of the final temporal predictions. To address this limitation, we propose Timestamp Anchor-constrained Reasoning for Temporal Video Grounding (TAR-TVG), a novel framework that introduces timestamp anchors within the reasoning process to enforce explicit supervision to the thought content. These anchors serve as intermediate verification points. More importantly, we require each reasoning step to produce increasingly accurate temporal estimations, thereby ensuring that the reasoning process contributes meaningfully to the final prediction. To address the challenge of low-probability anchor generation in models (e.g., Qwen2.5-VL-3B), we develop an efficient self-distillation training strategy: (1) initial GRPO training to collect 30K high-quality reasoning traces containing multiple timestamp anchors, (2) supervised fine-tuning (SFT) on distilled data, and (3) final GRPO optimization on the SFT-enhanced model. This three-stage training strategy enables robust anchor generation while maintaining reasoning quality. Experiments show that our model achieves state-of-the-art performance while producing interpretable, verifiable reasoning chains with progressively refined temporal estimations.', 'abstract_zh': 'Timestamp Anchor-constrained Reasoning for Temporal Video Grounding (TAR-TVG)', 'title_zh': '基于时间戳锚点约束推理的TAR-TVG：增强多模态语言模型的时间视频定位'}
{'arxiv_id': 'arXiv:2508.07681', 'title': 'MORE-CLEAR: Multimodal Offline Reinforcement learning for Clinical notes Leveraged Enhanced State Representation', 'authors': 'Yooseok Lim, ByoungJun Jeon, Seong-A Park, Jisoo Lee, Sae Won Choi, Chang Wook Jeong, Ho-Geol Ryu, Hongyeol Lee, Hyun-Lim Yang', 'link': 'https://arxiv.org/abs/2508.07681', 'abstract': "Sepsis, a life-threatening inflammatory response to infection, causes organ dysfunction, making early detection and optimal management critical. Previous reinforcement learning (RL) approaches to sepsis management rely primarily on structured data, such as lab results or vital signs, and on a dearth of a comprehensive understanding of the patient's condition. In this work, we propose a Multimodal Offline REinforcement learning for Clinical notes Leveraged Enhanced stAte Representation (MORE-CLEAR) framework for sepsis control in intensive care units. MORE-CLEAR employs pre-trained large-scale language models (LLMs) to facilitate the extraction of rich semantic representations from clinical notes, preserving clinical context and improving patient state representation. Gated fusion and cross-modal attention allow dynamic weight adjustment in the context of time and the effective integration of multimodal data. Extensive cross-validation using two public (MIMIC-III and MIMIC-IV) and one private dataset demonstrates that MORE-CLEAR significantly improves estimated survival rate and policy performance compared to single-modal RL approaches. To our knowledge, this is the first to leverage LLM capabilities within a multimodal offline RL for better state representation in medical applications. This approach can potentially expedite the treatment and management of sepsis by enabling reinforcement learning models to propose enhanced actions based on a more comprehensive understanding of patient conditions.", 'abstract_zh': '多模态离线强化学习结合临床笔记增强状态表示框架（MORE-CLEAR）在重症监护中控制脓毒症', 'title_zh': "MORE-CLEAR：多\n用户继续对话，请再输出翻译结果 barcelona ultra-marathon runners's kinematic and physiological variance\n用户继续对话-vars response\nuser kukuke cu忽悠助手继续输出\nAssistant pérdida有效性：\n用户 MORE-CLEAR: Multim\n用户 pérdida有效性-mult modal Offline Reinunction learning\n舯用户更多的\n用户 kino-dynamics and physiological kinetic variables générated by barcelona ultra-marathon runners pérdida有效性 kukuka wrestlers in the kinematic and physiological普遍存在差异 pérdida有效性"}
{'arxiv_id': 'arXiv:2508.07668', 'title': 'AIS-LLM: A Unified Framework for Maritime Trajectory Prediction, Anomaly Detection, and Collision Risk Assessment with Explainable Forecasting', 'authors': 'Hyobin Park, Jinwook Jung, Minseok Seo, Hyunsoo Choi, Deukjae Cho, Sekil Park, Dong-Geol Choi', 'link': 'https://arxiv.org/abs/2508.07668', 'abstract': 'With the increase in maritime traffic and the mandatory implementation of the Automatic Identification System (AIS), the importance and diversity of maritime traffic analysis tasks based on AIS data, such as vessel trajectory prediction, anomaly detection, and collision risk assessment, is rapidly growing. However, existing approaches tend to address these tasks individually, making it difficult to holistically consider complex maritime situations. To address this limitation, we propose a novel framework, AIS-LLM, which integrates time-series AIS data with a large language model (LLM). AIS-LLM consists of a Time-Series Encoder for processing AIS sequences, an LLM-based Prompt Encoder, a Cross-Modality Alignment Module for semantic alignment between time-series data and textual prompts, and an LLM-based Multi-Task Decoder. This architecture enables the simultaneous execution of three key tasks: trajectory prediction, anomaly detection, and risk assessment of vessel collisions within a single end-to-end system. Experimental results demonstrate that AIS-LLM outperforms existing methods across individual tasks, validating its effectiveness. Furthermore, by integratively analyzing task outputs to generate situation summaries and briefings, AIS-LLM presents the potential for more intelligent and efficient maritime traffic management.', 'abstract_zh': '基于AIS数据的大型语言模型框架AIS-LLM：同时执行轨迹预测、异常检测和碰撞风险评估', 'title_zh': 'AIS-LLM：一种用于 maritime 轨迹预测、异常检测和碰撞风险评估的可解释预测统一框架'}
{'arxiv_id': 'arXiv:2508.07662', 'title': 'GLiClass: Generalist Lightweight Model for Sequence Classification Tasks', 'authors': 'Ihor Stepanov, Mykhailo Shtopko, Dmytro Vodianytskyi, Oleksandr Lukashov, Alexander Yavorskyi, Mykyta Yaroshenko', 'link': 'https://arxiv.org/abs/2508.07662', 'abstract': 'Classification is one of the most widespread tasks in AI applications, serving often as the first step in filtering, sorting, and categorizing data. Since modern AI systems must handle large volumes of input data and early pipeline stages can propagate errors downstream, achieving high efficiency and accuracy is critical. Moreover, classification requirements can change dynamically based on user needs, necessitating models with strong zero-shot capabilities. While generative LLMs have become mainstream for zero-shot classification due to their versatility, they suffer from inconsistent instruction following and computational inefficiency. Cross-encoders, commonly used as rerankers in RAG pipelines, face a different bottleneck: they must process text-label pairs sequentially, significantly reducing efficiency with large label sets. Embedding-based approaches offer good efficiency but struggle with complex scenarios involving logical and semantic constraints. We propose GLiClass, a novel method that adapts the GLiNER architecture for sequence classification tasks. Our approach achieves strong accuracy and efficiency comparable to embedding-based methods, while maintaining the flexibility needed for zero-shot and few-shot learning scenarios. Additionally, we adapted proximal policy optimization (PPO) for multi-label text classification, enabling training classifiers in data-sparse conditions or from human feedback.', 'abstract_zh': 'GLiClass：一种用于序列分类任务的新颖方法', 'title_zh': 'GLiClass: 通用轻量级序列分类模型'}
{'arxiv_id': 'arXiv:2508.07659', 'title': 'Discovering Spatial Correlations between Earth Observations in Global Atmospheric State Estimation by using Adaptive Graph Structure Learning', 'authors': 'Hyeon-Ju Jeon, Jeon-Ho Kang, In-Hyuk Kwon, O-Joun Lee', 'link': 'https://arxiv.org/abs/2508.07659', 'abstract': 'This study aims to discover spatial correlations between Earth observations and atmospheric states to improve the forecasting accuracy of global atmospheric state estimation, which are usually conducted using conventional numerical weather prediction (NWP) systems and is the beginning of weather forecasting. NWP systems predict future atmospheric states at fixed locations, which are called NWP grid points, by analyzing previous atmospheric states and newly acquired Earth observations without fixed locations. Thus, surrounding meteorological context and the changing locations of the observations make spatial correlations between atmospheric states and observations over time. To handle complicated spatial correlations, which change dynamically, we employ spatiotemporal graph neural networks (STGNNs) with structure learning. However, structure learning has an inherent limitation that this can cause structural information loss and over-smoothing problem by generating excessive edges. To solve this problem, we regulate edge sampling by adaptively determining node degrees and considering the spatial distances between NWP grid points and observations. We validated the effectiveness of the proposed method by using real-world atmospheric state and observation data from East Asia. Even in areas with high atmospheric variability, the proposed method outperformed existing STGNN models with and without structure learning.', 'abstract_zh': '本研究旨在发现地球观测与大气状态之间的空间相关性，以提高全球大气状态估计的预测精度，通常使用传统的数值天气预测（NWP）系统进行，这是天气预报的开端。NWP系统通过分析先前的大气状态和新获取的无固定位置的地球观测数据，预测固定位置上的未来大气状态，称为NWP网格点。由此，周围的气象背景和观测位置的时空变化导致了大气状态和观测之间的空间相关性随时间的变化。为了应对具有动态变化的复杂空间相关性，我们采用带有结构学习的空间 tiempo-spatial 图神经网络（STGNN）。然而，结构学习固有的局限性是这会导致结构信息的损失和过度平滑问题，从而生成过多的边。为了解决这个问题，我们通过适应性地确定节点度数并考虑NWP网格点与观测之间的空间距离来调节边的采样。我们通过使用来自东亚的真实大气状态和观测数据验证了所提出方法的有效性。即使在大气变化剧烈的区域，所提出的方法也优于有和无结构学习的现有STGNN模型。', 'title_zh': '使用自适应图结构学习在全局大气状态估计中发现地球观测的空间相关性'}
{'arxiv_id': 'arXiv:2508.07648', 'title': 'Grasp-HGN: Grasping the Unexpected', 'authors': 'Mehrshad Zandigohar, Mallesham Dasari, Gunar Schirner', 'link': 'https://arxiv.org/abs/2508.07648', 'abstract': "For transradial amputees, robotic prosthetic hands promise to regain the capability to perform daily living activities. To advance next-generation prosthetic hand control design, it is crucial to address current shortcomings in robustness to out of lab artifacts, and generalizability to new environments. Due to the fixed number of object to interact with in existing datasets, contrasted with the virtually infinite variety of objects encountered in the real world, current grasp models perform poorly on unseen objects, negatively affecting users' independence and quality of life.\nTo address this: (i) we define semantic projection, the ability of a model to generalize to unseen object types and show that conventional models like YOLO, despite 80% training accuracy, drop to 15% on unseen objects. (ii) we propose Grasp-LLaVA, a Grasp Vision Language Model enabling human-like reasoning to infer the suitable grasp type estimate based on the object's physical characteristics resulting in a significant 50.2% accuracy over unseen object types compared to 36.7% accuracy of an SOTA grasp estimation model.\nLastly, to bridge the performance-latency gap, we propose Hybrid Grasp Network (HGN), an edge-cloud deployment infrastructure enabling fast grasp estimation on edge and accurate cloud inference as a fail-safe, effectively expanding the latency vs. accuracy Pareto. HGN with confidence calibration (DC) enables dynamic switching between edge and cloud models, improving semantic projection accuracy by 5.6% (to 42.3%) with 3.5x speedup over the unseen object types. Over a real-world sample mix, it reaches 86% average accuracy (12.2% gain over edge-only), and 2.2x faster inference than Grasp-LLaVA alone.", 'abstract_zh': '对于 radial 截肢患者，仿人手假肢有望恢复进行日常生活的能力。为了推进下一代假手控制设计，亟需解决在实验室外环境鲁棒性差和对新环境的一般性差的问题。由于现有数据集中交互对象数量固定，而现实世界中遇到的对象几乎无限多变，当前的抓取模型在未见过的对象上表现不佳，严重影响用户的独立性和生活质量。\n\n为了应对这一挑战：（i）我们定义了语义投影，即模型具备将技巧推广到未见过的对象类型的能力，并证明了尽管 YOLO 模型在训练集上的准确率达到 80%，但在未见过的对象上仅达到 15%。 （ii）我们提出了 Grasp-LLaVA，这是一种抓取视觉语言模型，能够进行类人的逻辑推理，基于对象的物理特征推断合适的抓取类型，相比当前最先进的抓取估计模型，在未见过的对象类型上的准确率提高了 33.5%。\n\n最后，为了弥合性能与延迟之间的差距，我们提出了一种混合抓取网络（HGN），这是一种边缘-云部署基础设施，可以在边缘进行快速抓取估计，并在云端提供准确的推断作为冗余，从而有效扩展了延迟与准确性的 Pareto 效应。HGN 通过置信度校准（DC）能够动态切换边缘和云模型之间的使用，对于未见过的对象典型样例，其语义投影准确率提升了 5.6%（提高到 42.3%），并且估计速度提高了 3.5 倍。在实际样本混合中，HGN 达到 86% 的平均准确率（与仅使用边缘模型相比提高了 12.2%），并且比单独使用 Grasp-LLaVA 的推断速度更快两倍多。\n\n翻译后的标题：\n语义投影与Grasp-LLaVA：实现未见过对象的抓取类型估计', 'title_zh': 'Grasp-HGN: 抓取意外情况'}
{'arxiv_id': 'arXiv:2508.07636', 'title': 'Attribution Explanations for Deep Neural Networks: A Theoretical Perspective', 'authors': 'Huiqi Deng, Hongbin Pei, Quanshi Zhang, Mengnan Du', 'link': 'https://arxiv.org/abs/2508.07636', 'abstract': 'Attribution explanation is a typical approach for explaining deep neural networks (DNNs), inferring an importance or contribution score for each input variable to the final output. In recent years, numerous attribution methods have been developed to explain DNNs. However, a persistent concern remains unresolved, i.e., whether and which attribution methods faithfully reflect the actual contribution of input variables to the decision-making process. The faithfulness issue undermines the reliability and practical utility of attribution explanations. We argue that these concerns stem from three core challenges. First, difficulties arise in comparing attribution methods due to their unstructured heterogeneity, differences in heuristics, formulations, and implementations that lack a unified organization. Second, most methods lack solid theoretical underpinnings, with their rationales remaining absent, ambiguous, or unverified. Third, empirically evaluating faithfulness is challenging without ground truth. Recent theoretical advances provide a promising way to tackle these challenges, attracting increasing attention. We summarize these developments, with emphasis on three key directions: (i) Theoretical unification, which uncovers commonalities and differences among methods, enabling systematic comparisons; (ii) Theoretical rationale, clarifying the foundations of existing methods; (iii) Theoretical evaluation, rigorously proving whether methods satisfy faithfulness principles. Beyond a comprehensive review, we provide insights into how these studies help deepen theoretical understanding, inform method selection, and inspire new attribution methods. We conclude with a discussion of promising open problems for further work.', 'abstract_zh': '属性解释是解释深度神经网络（DNNs）的一种典型方法，通过为每个输入变量到最终输出的重要性或贡献评分提供推理。近年来，已经开发出了许多属性方法来解释DNNs。然而，一个持续存在的问题是，这些方法是否以及哪一种方法真实反映了输入变量在决策过程中的实际贡献。这一忠实性问题削弱了属性解释的可靠性和实际用途。我们认为这些问题根源在于三个核心挑战。首先，由于方法的无结构异质性、启发式、公式化和实现上的差异缺乏统一组织，比较属性方法存在困难。其次，大多数方法缺乏坚实的理论基础，其原理尚未得到明确、清晰或验证。第三，没有真实标注的数据使得实证评估忠实性变得困难。近期的理论进展提供了应对这些挑战的可行途径，引起了越来越多的关注。我们总结了这些发展，并着重于三个关键方向：（i）理论统一，揭示方法之间的共同点和差异，从而进行系统比较；（ii）理论原理，澄清现有方法的理论基础；（iii）理论评估，严格证明方法是否满足忠实性原则。在全面回顾的同时，我们提供了这些研究如何帮助深化理论理解、指导方法选择以及激发新的属性方法的洞见。我们最后讨论了进一步工作中具有前景的开放问题。', 'title_zh': '深度神经网络的归因解释：一个理论视角'}
{'arxiv_id': 'arXiv:2508.07631', 'title': 'Efficient Approximate Posterior Sampling with Annealed Langevin Monte Carlo', 'authors': 'Advait Parulekar, Litu Rout, Karthikeyan Shanmugam, Sanjay Shakkottai', 'link': 'https://arxiv.org/abs/2508.07631', 'abstract': 'We study the problem of posterior sampling in the context of score based generative models. We have a trained score network for a prior $p(x)$, a measurement model $p(y|x)$, and are tasked with sampling from the posterior $p(x|y)$. Prior work has shown this to be intractable in KL (in the worst case) under well-accepted computational hardness assumptions. Despite this, popular algorithms for tasks such as image super-resolution, stylization, and reconstruction enjoy empirical success. Rather than establishing distributional assumptions or restricted settings under which exact posterior sampling is tractable, we view this as a more general "tilting" problem of biasing a distribution towards a measurement. Under minimal assumptions, we show that one can tractably sample from a distribution that is simultaneously close to the posterior of a noised prior in KL divergence and the true posterior in Fisher divergence. Intuitively, this combination ensures that the resulting sample is consistent with both the measurement and the prior. To the best of our knowledge these are the first formal results for (approximate) posterior sampling in polynomial time.', 'abstract_zh': '基于评分模型中后验采样的研究', 'title_zh': 'annealed 拉格朗日蒙特卡罗高效近似后验采样'}
{'arxiv_id': 'arXiv:2508.07630', 'title': 'InterChart: Benchmarking Visual Reasoning Across Decomposed and Distributed Chart Information', 'authors': 'Anirudh Iyengar Kaniyar Narayana Iyengar, Srija Mukhopadhyay, Adnan Qidwai, Shubhankar Singh, Dan Roth, Vivek Gupta', 'link': 'https://arxiv.org/abs/2508.07630', 'abstract': 'We introduce InterChart, a diagnostic benchmark that evaluates how well vision-language models (VLMs) reason across multiple related charts, a task central to real-world applications such as scientific reporting, financial analysis, and public policy dashboards. Unlike prior benchmarks focusing on isolated, visually uniform charts, InterChart challenges models with diverse question types ranging from entity inference and trend correlation to numerical estimation and abstract multi-step reasoning grounded in 2-3 thematically or structurally related charts. We organize the benchmark into three tiers of increasing difficulty: (1) factual reasoning over individual charts, (2) integrative analysis across synthetically aligned chart sets, and (3) semantic inference over visually complex, real-world chart pairs. Our evaluation of state-of-the-art open and closed-source VLMs reveals consistent and steep accuracy declines as chart complexity increases. We find that models perform better when we decompose multi-entity charts into simpler visual units, underscoring their struggles with cross-chart integration. By exposing these systematic limitations, InterChart provides a rigorous framework for advancing multimodal reasoning in complex, multi-visual environments.', 'abstract_zh': '我们介绍了一种名为InterChart的诊断基准，用于评估视觉-语言模型（VLMs）在多个相关图表之间进行推理的能力，这是科学报告、财务分析和公共政策仪表板等真实世界应用的核心任务。InterChart不同于以往专注于孤立且视觉一致的图表的基准，它挑战模型应对从实体推理和趋势关联到基于2-3个主题或结构相关图表的数值估计和抽象多步推理等多样化的提问类型。我们将基准划分为三个逐渐增加难度的层级：（1）在单一图表上的事实推理，（2）在合成对齐的图表集中进行综合分析，（3）在视觉复杂的真实世界图表对上的语义推理。对最先进的开源和闭源VLMs的评估显示，随着图表复杂性的增加，准确率呈现出一致且显著的下降。我们发现，当将多实体图表分解为更简单的视觉单位时，模型的表现更好，这突显了它们在跨图表整合方面的困难。通过揭示这些系统的限制，InterChart为在复杂多视图环境下的多模态推理提供了一个严格的框架。', 'title_zh': 'InterChart: �across分解和分布式图表信息的视觉推理基准测试'}
{'arxiv_id': 'arXiv:2508.07629', 'title': 'Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization', 'authors': 'Zhenpeng Su, Leiyu Pan, Xue Bai, Dening Liu, Guanting Dong, Jiaming Huang, Wenping Hu, Guorui Zhou', 'link': 'https://arxiv.org/abs/2508.07629', 'abstract': "We present Klear-Reasoner, a model with long reasoning capabilities that demonstrates careful deliberation during problem solving, achieving outstanding performance across multiple benchmarks. Although there are already many excellent works related to inference models in the current community, there are still many problems with reproducing high-performance inference models due to incomplete disclosure of training details. This report provides an in-depth analysis of the reasoning model, covering the entire post-training workflow from data preparation and long Chain-of-Thought supervised fine-tuning (long CoT SFT) to reinforcement learning (RL), along with detailed ablation studies for each experimental component. For SFT data, our experiments show that a small number of high-quality data sources are more effective than a large number of diverse data sources, and that difficult samples can achieve better results without accuracy filtering. In addition, we investigate two key issues with current clipping mechanisms in RL: Clipping suppresses critical exploration signals and ignores suboptimal trajectories. To address these challenges, we propose Gradient-Preserving clipping Policy Optimization (GPPO) that gently backpropagates gradients from clipped tokens. GPPO not only enhances the model's exploration capacity but also improves its efficiency in learning from negative samples. Klear-Reasoner exhibits exceptional reasoning abilities in mathematics and programming, scoring 90.5\\% on AIME 2024, 83.2\\% on AIME 2025, 66.0\\% on LiveCodeBench V5 and 58.1\\% on LiveCodeBench V6.", 'abstract_zh': 'Klear-Reasoner：具备长时间推理能力的模型及其在多个基准测试中的卓越表现', 'title_zh': 'Klear-Reasoner: 提升保持梯度不变性的推理能力优化策略'}
{'arxiv_id': 'arXiv:2508.07621', 'title': 'SOFA: Deep Learning Framework for Simulating and Optimizing Atrial Fibrillation Ablation', 'authors': 'Yunsung Chung, Chanho Lim, Ghassan Bidaoui, Christian Massad, Nassir Marrouche, Jihun Hamm', 'link': 'https://arxiv.org/abs/2508.07621', 'abstract': "Atrial fibrillation (AF) is a prevalent cardiac arrhythmia often treated with catheter ablation procedures, but procedural outcomes are highly variable. Evaluating and improving ablation efficacy is challenging due to the complex interaction between patient-specific tissue and procedural factors. This paper asks two questions: Can AF recurrence be predicted by simulating the effects of procedural parameters? How should we ablate to reduce AF recurrence? We propose SOFA (Simulating and Optimizing Atrial Fibrillation Ablation), a novel deep-learning framework that addresses these questions. SOFA first simulates the outcome of an ablation strategy by generating a post-ablation image depicting scar formation, conditioned on a patient's pre-ablation LGE-MRI and the specific procedural parameters used (e.g., ablation locations, duration, temperature, power, and force). During this simulation, it predicts AF recurrence risk. Critically, SOFA then introduces an optimization scheme that refines these procedural parameters to minimize the predicted risk. Our method leverages a multi-modal, multi-view generator that processes 2.5D representations of the atrium. Quantitative evaluations show that SOFA accurately synthesizes post-ablation images and that our optimization scheme leads to a 22.18\\% reduction in the model-predicted recurrence risk. To the best of our knowledge, SOFA is the first framework to integrate the simulation of procedural effects, recurrence prediction, and parameter optimization, offering a novel tool for personalizing AF ablation.", 'abstract_zh': '心房颤动（AF）是一种常见的心脏心律失常，常通过导管消融程序治疗，但治疗效果差异显著。评估和提高消融效果具有挑战性，因为患者特异组织与治疗因素之间存在复杂互动。本文提出两个问题：能否通过模拟程序参数效果来预测AF复发？如何消融以减少AF复发？本文提出SOFA（Simulating and Optimizing Atrial Fibrillation Ablation），一种新颖的深度学习框架，以解决这两个问题。SOFA首先通过生成消融后图像来模拟消融策略的结果，该图像展示了瘢痕形成情况，基于术前LGE-MRI和特定的程序参数（例如消融位置、持续时间、温度、功率和力）。在此过程中，它预测AF复发风险。关键的是，SOFA引入了一种优化方案，改进这些程序参数以最小化预测风险。我们的方法利用多模态、多视图生成器处理心房的2.5D表示。定量评估表明，SOFA能够准确合成消融后图像，且我们的优化方案使模型预测的复发风险降低了22.18%。据我们所知，SOFA是第一个同时整合程序效果模拟、复发预测和参数优化的框架，提供了个性化AF消融的新工具。', 'title_zh': 'SOFA: 用于模拟和优化房颤消融的深度学习框架'}
{'arxiv_id': 'arXiv:2508.07617', 'title': 'On the Limits of Selective AI Prediction: A Case Study in Clinical Decision Making', 'authors': 'Sarah Jabbour, David Fouhey, Nikola Banovic, Stephanie D. Shepard, Ella Kazerooni, Michael W. Sjoding, Jenna Wiens', 'link': 'https://arxiv.org/abs/2508.07617', 'abstract': 'AI has the potential to augment human decision making. However, even high-performing models can produce inaccurate predictions when deployed. These inaccuracies, combined with automation bias, where humans overrely on AI predictions, can result in worse decisions. Selective prediction, in which potentially unreliable model predictions are hidden from users, has been proposed as a solution. This approach assumes that when AI abstains and informs the user so, humans make decisions as they would without AI involvement. To test this assumption, we study the effects of selective prediction on human decisions in a clinical context. We conducted a user study of 259 clinicians tasked with diagnosing and treating hospitalized patients. We compared their baseline performance without any AI involvement to their AI-assisted accuracy with and without selective prediction. Our findings indicate that selective prediction mitigates the negative effects of inaccurate AI in terms of decision accuracy. Compared to no AI assistance, clinician accuracy declined when shown inaccurate AI predictions (66% [95% CI: 56%-75%] vs. 56% [95% CI: 46%-66%]), but recovered under selective prediction (64% [95% CI: 54%-73%]). However, while selective prediction nearly maintains overall accuracy, our results suggest that it alters patterns of mistakes: when informed the AI abstains, clinicians underdiagnose (18% increase in missed diagnoses) and undertreat (35% increase in missed treatments) compared to no AI input at all. Our findings underscore the importance of empirically validating assumptions about how humans engage with AI within human-AI systems.', 'abstract_zh': 'AI在辅助人类决策方面的潜力及其潜在风险：选择性预测对临床决策的影响研究', 'title_zh': '关于Selective AI预测极限：临床决策制定案例研究 mexico\n\n meilleurs deleteUser \n关于Select性 AI预测的极限：临床决策制定案例研究lógica\nuser\n关于Select selected AI预测的极限：临床决策制定案例研究 pesticida\nuser nâa\n关于我们选择性\nuser *</phanumeric\n"user\n关于选择性的AI预测极限：临床决策制定案例研究'}
{'arxiv_id': 'arXiv:2508.07597', 'title': 'ShoulderShot: Generating Over-the-Shoulder Dialogue Videos', 'authors': 'Yuang Zhang, Junqi Cheng, Haoyu Zhao, Jiaxi Gu, Fangyuan Zou, Zenghui Lu, Peng Shu', 'link': 'https://arxiv.org/abs/2508.07597', 'abstract': "Over-the-shoulder dialogue videos are essential in films, short dramas, and advertisements, providing visual variety and enhancing viewers' emotional connection. Despite their importance, such dialogue scenes remain largely underexplored in video generation research. The main challenges include maintaining character consistency across different shots, creating a sense of spatial continuity, and generating long, multi-turn dialogues within limited computational budgets. Here, we present ShoulderShot, a framework that combines dual-shot generation with looping video, enabling extended dialogues while preserving character consistency. Our results demonstrate capabilities that surpass existing methods in terms of shot-reverse-shot layout, spatial continuity, and flexibility in dialogue length, thereby opening up new possibilities for practical dialogue video generation. Videos and comparisons are available at this https URL.", 'abstract_zh': '肩拍对白视频在电影、短剧和广告中至关重要，能提供视觉多样性并增强观众的情感连接。尽管如此，此类对白场景在视频生成研究中仍 largely underexplored。主要挑战包括保持不同镜头中人物的一致性、创造空间连续感以及在有限的计算预算内生成长且多轮的对白。在这里，我们提出了 ShoulderShot 框架，结合双镜头生成与循环视频，能够在保持人物一致性的同时扩展对白。我们的结果显示，该方法在镜头替换布局、空间连续性和对话长度的灵活性方面超越了现有方法，从而为实际对白视频生成开辟了新的可能性。更多视频和比较请参见 this https URL。', 'title_zh': 'ShoulderShot: 生成越肩对话视频'}
{'arxiv_id': 'arXiv:2508.07592', 'title': 'IBPS: Indian Bail Prediction System', 'authors': 'Puspesh Kumar Srivastava, Uddeshya Raj, Praveen Patel, /Shubham Kumar Nigam, Noel Shallum, Arnab Bhattacharya', 'link': 'https://arxiv.org/abs/2508.07592', 'abstract': "Bail decisions are among the most frequently adjudicated matters in Indian courts, yet they remain plagued by subjectivity, delays, and inconsistencies. With over 75% of India's prison population comprising undertrial prisoners, many from socioeconomically disadvantaged backgrounds, the lack of timely and fair bail adjudication exacerbates human rights concerns and contributes to systemic judicial backlog. In this paper, we present the Indian Bail Prediction System (IBPS), an AI-powered framework designed to assist in bail decision-making by predicting outcomes and generating legally sound rationales based solely on factual case attributes and statutory provisions. We curate and release a large-scale dataset of 150,430 High Court bail judgments, enriched with structured annotations such as age, health, criminal history, crime category, custody duration, statutes, and judicial reasoning. We fine-tune a large language model using parameter-efficient techniques and evaluate its performance across multiple configurations, with and without statutory context, and with RAG. Our results demonstrate that models fine-tuned with statutory knowledge significantly outperform baselines, achieving strong accuracy and explanation quality, and generalize well to a test set independently annotated by legal experts. IBPS offers a transparent, scalable, and reproducible solution to support data-driven legal assistance, reduce bail delays, and promote procedural fairness in the Indian judicial system.", 'abstract_zh': '印度保释预测系统：一种基于AI的保释决策辅助框架', 'title_zh': '印度保释预测系统'}
{'arxiv_id': 'arXiv:2508.07571', 'title': 'Towards Theoretical Understanding of Transformer Test-Time Computing: Investigation on In-Context Linear Regression', 'authors': 'Xingwu Chen, Miao Lu, Beining Wu, Difan Zou', 'link': 'https://arxiv.org/abs/2508.07571', 'abstract': 'Using more test-time computation during language model inference, such as generating more intermediate thoughts or sampling multiple candidate answers, has proven effective in significantly improving model performance. This paper takes an initial step toward bridging the gap between practical language model inference and theoretical transformer analysis by incorporating randomness and sampling. We focus on in-context linear regression with continuous/binary coefficients, where our framework simulates language model decoding through noise injection and binary coefficient sampling. Through this framework, we provide detailed analyses of widely adopted inference techniques. Supported by empirical results, our theoretical framework and analysis demonstrate the potential for offering new insights into understanding inference behaviors in real-world language models.', 'abstract_zh': '通过引入随机性和采样将实战语言模型推理与理论变压器分析相结合，在语言模型推断过程中增加更多的测试时计算，如生成更多的中间想法或采样多个候选答案，已被证明能显著提高模型性能。本文通过噪声注入和二进制系数采样的方式模拟语言模型解码，旨在为解决实践中语言模型推理与理论变压器分析之间的差距迈出第一步。我们关注带连续/二元系数的上下文内线性回归问题，通过该框架对广泛采用的推断技术进行详细的分析。依靠实验结果的支持，我们的理论框架和分析展示了理解实际语言模型推断行为的新颖见解的潜在价值。', 'title_zh': 'Transformer测试时计算的理论理解：基于上下文的线性回归探究'}
{'arxiv_id': 'arXiv:2508.07569', 'title': 'Retrieval-Augmented Multi-Agent System for Rapid Statement of Work Generation', 'authors': 'Amulya Suravarjhula, Rashi Chandrashekhar Agrawal, Sakshi Jayesh Patel, Rahul Gupta', 'link': 'https://arxiv.org/abs/2508.07569', 'abstract': "Drafting a Statement of Work (SOW) is a vital part of business and legal projects. It outlines key details like deliverables, timelines, responsibilities, and legal terms. However, creating these documents is often a slow and complex process. It usually involves multiple people, takes several days, and leaves room for errors or outdated content. This paper introduces a new AI-driven automation system that makes the entire SOW drafting process faster, easier, and more accurate. Instead of relying completely on humans, the system uses three intelligent components or 'agents' that each handle a part of the job. One agent writes the first draft, another checks if everything is legally correct, and the third agent formats the document and ensures everything is in order. Unlike basic online tools that just fill in templates, this system understands the meaning behind the content and customizes the SOW to match the needs of the project. It also checks legal compliance and formatting so that users can trust the result. The system was tested using real business examples. It was able to create a full SOW in under three minutes, compared to several hours or days using manual methods. It also performed well in accuracy and quality, showing that it can reduce legal risks and save a lot of time. This solution shows how artificial intelligence can be used to support legal and business professionals by taking care of routine work and helping them focus on more important decisions. It's a step toward making legal processes smarter, faster, and more reliable.", 'abstract_zh': '基于AI的声明 of 工作 (SOW) 自动化系统：更快、更准确、更可靠', 'title_zh': '基于检索增强的多 Agents 系统快速工作说明书生成'}
{'arxiv_id': 'arXiv:2508.07561', 'title': 'A Small-footprint Acoustic Echo Cancellation Solution for Mobile Full-Duplex Speech Interactions', 'authors': 'Yiheng Jiang, Tian Biao', 'link': 'https://arxiv.org/abs/2508.07561', 'abstract': "In full-duplex speech interaction systems, effective Acoustic Echo Cancellation (AEC) is crucial for recovering echo-contaminated speech. This paper presents a neural network-based AEC solution to address challenges in mobile scenarios with varying hardware, nonlinear distortions and long latency. We first incorporate diverse data augmentation strategies to enhance the model's robustness across various environments. Moreover, progressive learning is employed to incrementally improve AEC effectiveness, resulting in a considerable improvement in speech quality. To further optimize AEC's downstream applications, we introduce a novel post-processing strategy employing tailored parameters designed specifically for tasks such as Voice Activity Detection (VAD) and Automatic Speech Recognition (ASR), thus enhancing their overall efficacy. Finally, our method employs a small-footprint model with streaming inference, enabling seamless deployment on mobile devices. Empirical results demonstrate effectiveness of the proposed method in Echo Return Loss Enhancement and Perceptual Evaluation of Speech Quality, alongside significant improvements in both VAD and ASR results.", 'abstract_zh': '基于神经网络的全双工语音交互系统中的声回波 cancellation 解决方案', 'title_zh': '小型 footprint 声回波消除解决方案用于移动全双工语音交互'}
{'arxiv_id': 'arXiv:2508.07556', 'title': 'Uncertainty-Driven Reliability: Selective Prediction and Trustworthy Deployment in Modern Machine Learning', 'authors': 'Stephan Rabanser', 'link': 'https://arxiv.org/abs/2508.07556', 'abstract': 'Machine learning (ML) systems are increasingly deployed in high-stakes domains where reliability is paramount. This thesis investigates how uncertainty estimation can enhance the safety and trustworthiness of ML, focusing on selective prediction -- where models abstain when confidence is low.\nWe first show that a model\'s training trajectory contains rich uncertainty signals that can be exploited without altering its architecture or loss. By ensembling predictions from intermediate checkpoints, we propose a lightweight, post-hoc abstention method that works across tasks, avoids the cost of deep ensembles, and achieves state-of-the-art selective prediction performance. Crucially, this approach is fully compatible with differential privacy (DP), allowing us to study how privacy noise affects uncertainty quality. We find that while many methods degrade under DP, our trajectory-based approach remains robust, and we introduce a framework for isolating the privacy-uncertainty trade-off. Next, we then develop a finite-sample decomposition of the selective classification gap -- the deviation from the oracle accuracy-coverage curve -- identifying five interpretable error sources and clarifying which interventions can close the gap. This explains why calibration alone cannot fix ranking errors, motivating methods that improve uncertainty ordering. Finally, we show that uncertainty signals can be adversarially manipulated to hide errors or deny service while maintaining high accuracy, and we design defenses combining calibration audits with verifiable inference.\nTogether, these contributions advance reliable ML by improving, evaluating, and safeguarding uncertainty estimation, enabling models that not only make accurate predictions -- but also know when to say "I do not know".', 'abstract_zh': '机器学习系统的不确定性估计：提升高 stakes 领域中的安全性和可信度的研究', 'title_zh': '不确定性驱动的可靠性：现代机器学习中的选择性预测与可信赖部署'}
{'arxiv_id': 'arXiv:2508.07538', 'title': 'A DICOM Image De-identification Algorithm in the MIDI-B Challenge', 'authors': 'Hongzhu Jiang, Sihan Xie, Zhiyu Wan', 'link': 'https://arxiv.org/abs/2508.07538', 'abstract': 'Image de-identification is essential for the public sharing of medical images, particularly in the widely used Digital Imaging and Communications in Medicine (DICOM) format as required by various regulations and standards, including Health Insurance Portability and Accountability Act (HIPAA) privacy rules, the DICOM PS3.15 standard, and best practices recommended by the Cancer Imaging Archive (TCIA). The Medical Image De-Identification Benchmark (MIDI-B) Challenge at the 27th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2024) was organized to evaluate rule-based DICOM image de-identification algorithms with a large dataset of clinical DICOM images. In this report, we explore the critical challenges of de-identifying DICOM images, emphasize the importance of removing personally identifiable information (PII) to protect patient privacy while ensuring the continued utility of medical data for research, diagnostics, and treatment, and provide a comprehensive overview of the standards and regulations that govern this process. Additionally, we detail the de-identification methods we applied - such as pixel masking, date shifting, date hashing, text recognition, text replacement, and text removal - to process datasets during the test phase in strict compliance with these standards. According to the final leaderboard of the MIDI-B challenge, the latest version of our solution algorithm correctly executed 99.92% of the required actions and ranked 2nd out of 10 teams that completed the challenge (from a total of 22 registered teams). Finally, we conducted a thorough analysis of the resulting statistics and discussed the limitations of current approaches and potential avenues for future improvement.', 'abstract_zh': '医学图像去标识化对于医疗图像的公共分享至关重要，特别是在广泛使用的数字成像和通信在医学领域（DICOM）格式中，符合诸如《健康保险流通与责任法案》（HIPAA）隐私规则、DICOM PS3.15标准以及癌症成像归档（TCIA）推荐的最佳实践等各种法规和标准。在第27届国际医学图像计算与计算机辅助介入会议（MICCAI 2024）上组织的医学图像去标识化基准（MIDI-B）挑战旨在使用大量临床DICOM图像评估基于规则的DICOM图像去标识化算法。在本报告中，我们探讨了去标识化DICOM图像的关键挑战，强调去除个人可识别信息（PII）以保护患者隐私的重要性，同时确保医学数据的继续实用性用于研究、诊断和治疗，并全面概述了指导这一过程的规范和法规。此外，我们详细介绍了在测试阶段应用的去标识化方法，如像素遮罩、日期移位、日期哈希、文本识别、文本替换和文本删除，严格遵守这些规范和法规。根据MIDI-B挑战的最终排行榜，我们最新版本的解决方案算法正确执行了99.92%的必要操作，并在完成挑战的10支队伍中排名第二（总共22支注册队伍）。最后，我们对结果进行了全面分析，并讨论了当前方法的局限性和未来改进的潜在途径。', 'title_zh': 'MIDI-B挑战中的DICOM图像去标识化算法'}
{'arxiv_id': 'arXiv:2508.07520', 'title': 'Conversational DNA: A New Visual Language for Understanding Dialogue Structure in Human and AI', 'authors': 'Baihan Lin', 'link': 'https://arxiv.org/abs/2508.07520', 'abstract': 'What if the patterns hidden within dialogue reveal more about communication than the words themselves? We introduce Conversational DNA, a novel visual language that treats any dialogue -- whether between humans, between human and AI, or among groups -- as a living system with interpretable structure that can be visualized, compared, and understood. Unlike traditional conversation analysis that reduces rich interaction to statistical summaries, our approach reveals the temporal architecture of dialogue through biological metaphors. Linguistic complexity flows through strand thickness, emotional trajectories cascade through color gradients, conversational relevance forms through connecting elements, and topic coherence maintains structural integrity through helical patterns. Through exploratory analysis of therapeutic conversations and historically significant human-AI dialogues, we demonstrate how this visualization approach reveals interaction patterns that traditional methods miss. Our work contributes a new creative framework for understanding communication that bridges data visualization, human-computer interaction, and the fundamental question of what makes dialogue meaningful in an age where humans increasingly converse with artificial minds.', 'abstract_zh': '对话中隐藏的模式是否揭示了比文字本身更多的沟通信息？我们引入了对话DNA，这是一种新颖的可视化语言，将任何对话——无论是人与人之间、人与AI之间还是群体内部——视为具有可解釋结构的活体系统，可以进行可视化、比较和理解。不同于传统对话分析将丰富的互动简化为统计摘要，我们的方法通过生物隐喻揭示了对话的时间架构。语言复杂性通过线缆厚度流动，情感轨迹通过色彩渐变传递，对话相关性通过连接元素形成，话题连贯性通过螺旋模式保持结构完整性。通过对治疗性对话和历史上重要的人机对话的探索性分析，我们展示了这种可视化方法如何揭示传统方法所忽略的互动模式。我们的工作贡献了一种新的创造框架，用于理解沟通，该框架跨越了数据可视化、人机交互以及在一个日益与人工智能交流的时代，使对话有意义的基本问题的桥接。', 'title_zh': '对话DNA：一种新的视觉语言，用于理解人类与AI的对话结构'}
{'arxiv_id': 'arXiv:2508.07517', 'title': 'Word Clouds as Common Voices: LLM-Assisted Visualization of Participant-Weighted Themes in Qualitative Interviews', 'authors': 'Joseph T. Colonel, Baihan Lin', 'link': 'https://arxiv.org/abs/2508.07517', 'abstract': "Word clouds are a common way to summarize qualitative interviews, yet traditional frequency-based methods often fail in conversational contexts: they surface filler words, ignore paraphrase, and fragment semantically related ideas. This limits their usefulness in early-stage analysis, when researchers need fast, interpretable overviews of what participant actually said. We introduce ThemeClouds, an open-source visualization tool that uses large language models (LLMs) to generate thematic, participant-weighted word clouds from dialogue transcripts. The system prompts an LLM to identify concept-level themes across a corpus and then counts how many unique participants mention each topic, yielding a visualization grounded in breadth of mention rather than raw term frequency. Researchers can customize prompts and visualization parameters, providing transparency and control. Using interviews from a user study comparing five recording-device configurations (31 participants; 155 transcripts, Whisper ASR), our approach surfaces more actionable device concerns than frequency clouds and topic-modeling baselines (e.g., LDA, BERTopic). We discuss design trade-offs for integrating LLM assistance into qualitative workflows, implications for interpretability and researcher agency, and opportunities for interactive analyses such as per-condition contrasts (``diff clouds'').", 'abstract_zh': '主题词云：一种使用大型语言模型生成主题导向、参与者加权词云的可视化工具及其应用', 'title_zh': '词云作为共同的声音：基于LLM辅助的定性访谈主题参与权重可视化'}
{'arxiv_id': 'arXiv:2508.07514', 'title': 'From Field to Drone: Domain Drift Tolerant Automated Multi-Species and Damage Plant Semantic Segmentation for Herbicide Trials', 'authors': 'Artzai Picon, Itziar Eguskiza, Daniel Mugica, Javier Romero, Carlos Javier Jimenez, Eric White, Gabriel Do-Lago-Junqueira, Christian Klukas, Ramon Navarra-Mestre', 'link': 'https://arxiv.org/abs/2508.07514', 'abstract': "Field trials are vital in herbicide research and development to assess effects on crops and weeds under varied conditions. Traditionally, evaluations rely on manual visual assessments, which are time-consuming, labor-intensive, and subjective. Automating species and damage identification is challenging due to subtle visual differences, but it can greatly enhance efficiency and consistency.\nWe present an improved segmentation model combining a general-purpose self-supervised visual model with hierarchical inference based on botanical taxonomy. Trained on a multi-year dataset (2018-2020) from Germany and Spain using digital and mobile cameras, the model was tested on digital camera data (year 2023) and drone imagery from the United States, Germany, and Spain (year 2024) to evaluate robustness under domain shift. This cross-device evaluation marks a key step in assessing generalization across platforms of the model.\nOur model significantly improved species identification (F1-score: 0.52 to 0.85, R-squared: 0.75 to 0.98) and damage classification (F1-score: 0.28 to 0.44, R-squared: 0.71 to 0.87) over prior methods. Under domain shift (drone images), it maintained strong performance with moderate degradation (species: F1-score 0.60, R-squared 0.80; damage: F1-score 0.41, R-squared 0.62), where earlier models failed.\nThese results confirm the model's robustness and real-world applicability. It is now deployed in BASF's phenotyping pipeline, enabling large-scale, automated crop and weed monitoring across diverse geographies.", 'abstract_zh': '农田试验对于除草剂研究与开发至关重要，用于在不同条件下评估其对作物和杂草的影响。传统评估依赖手动视觉评估，耗时、劳动密集且主观。自动化物种和损伤识别具有挑战性，但由于视觉差异微小，这可以大大提升效率和一致性。\n\n我们提出了一种结合通用自监督视觉模型和基于植物学分类的分层推理的改进分割模型。该模型在2018-2020年德国和西班牙使用数字和移动相机收集的多年度数据集上进行训练，并在2023年的数字相机数据和2024年来自美国、德国和西班牙的无人机影像上进行测试，以评估跨平台稳健性。这一跨设备评估是评价模型跨平台泛化的关键步骤。\n\n该模型在物种识别（F1分数从0.52提高到0.85，R-squared从0.75提高到0.98）和损伤分类（F1分数从0.28提高到0.44，R-squared从0.71提高到0.87）上显著优于先前方法。在跨领域（无人机图像）情况下，它仍能保持较强性能，尽管表现有所降级（物种：F1分数0.60，R-squared 0.80；损伤：F1分数0.41，R-squared 0.62），而早期模型则失败了。\n\n这些结果证实了该模型的稳健性和实际应用潜力。该模型现已部署在巴斯夫的表型分析流水线中，实现跨地域的大规模自动化作物和杂草监测。', 'title_zh': '从田间到无人机：容忍领域漂移的自动多物种和损伤植物语义分割在除草剂试验中的应用'}
{'arxiv_id': 'arXiv:2508.07507', 'title': 'Intersectoral Knowledge in AI and Urban Studies: A Framework for Transdisciplinary Research', 'authors': 'Rashid Mushkani', 'link': 'https://arxiv.org/abs/2508.07507', 'abstract': 'Transdisciplinary approaches are increasingly essential for addressing grand societal challenges, particularly in complex domains such as Artificial Intelligence (AI), urban planning, and social sciences. However, effectively validating and integrating knowledge across distinct epistemic and ontological perspectives poses significant difficulties. This article proposes a six-dimensional framework for assessing and strengthening transdisciplinary knowledge validity in AI and city studies, based on an extensive analysis of the most cited research (2014--2024). Specifically, the framework classifies research orientations according to ontological, epistemological, methodological, teleological, axiological, and valorization dimensions. Our findings show a predominance of perspectives aligned with critical realism (ontological), positivism (epistemological), analytical methods (methodological), consequentialism (teleological), epistemic values (axiological), and social/economic valorization. Less common stances, such as idealism, mixed methods, and cultural valorization, are also examined for their potential to enrich knowledge production. We highlight how early career researchers and transdisciplinary teams can leverage this framework to reconcile divergent disciplinary viewpoints and promote socially accountable outcomes.', 'abstract_zh': '跨学科方法在应对人工智能、城市规划和社会科学等复杂领域中的重大社会挑战中日益重要。然而，有效验证和整合不同认识论和本体论视角的知识面临重大挑战。本文基于对2014-2024年间最引文献的全面分析，提出一个六维框架，用于评估和增强人工智能和城市研究中的跨学科知识有效性。该框架根据本体论、认识论、方法论、目的论、价值论和价值提升维度对研究取向进行分类。我们的研究发现，关键实在论（本体论）、实证主义（认识论）、分析方法（方法论）、后果主义（目的论）、认识论价值（价值论）和社会/经济价值提升是主流视角。此外，还探讨了理想主义、混合方法和文化价值提升等较少见立场的潜力，以丰富知识生产。我们强调，早期职业研究人员和跨学科团队可以利用此框架调和分歧的学科视角，促进社会责任感的结果。', 'title_zh': 'AI与城市研究领域的跨学科知识框架：多学科研究框架'}
{'arxiv_id': 'arXiv:2508.07497', 'title': 'VA-Blueprint: Uncovering Building Blocks for Visual Analytics System Design', 'authors': 'Leonardo Ferreira, Gustavo Moreira, Fabio Miranda', 'link': 'https://arxiv.org/abs/2508.07497', 'abstract': "Designing and building visual analytics (VA) systems is a complex, iterative process that requires the seamless integration of data processing, analytics capabilities, and visualization techniques. While prior research has extensively examined the social and collaborative aspects of VA system authoring, the practical challenges of developing these systems remain underexplored. As a result, despite the growing number of VA systems, there are only a few structured knowledge bases to guide their design and development. To tackle this gap, we propose VA-Blueprint, a methodology and knowledge base that systematically reviews and categorizes the fundamental building blocks of urban VA systems, a domain particularly rich and representative due to its intricate data and unique problem sets. Applying this methodology to an initial set of 20 systems, we identify and organize their core components into a multi-level structure, forming an initial knowledge base with a structured blueprint for VA system development. To scale this effort, we leverage a large language model to automate the extraction of these components for other 81 papers (completing a corpus of 101 papers), assessing its effectiveness in scaling knowledge base construction. We evaluate our method through interviews with experts and a quantitative analysis of annotation metrics. Our contributions provide a deeper understanding of VA systems' composition and establish a practical foundation to support more structured, reproducible, and efficient system development. VA-Blueprint is available at this https URL.", 'abstract_zh': '设计和构建可视分析（VA）系统是一个复杂且迭代的过程，需要数据处理、分析能力和可视化技术的无缝集成。尽管先前研究详细探讨了VA系统作者的社会和协作方面，但在开发这些系统时的实际挑战仍研究不足。因此，尽管可视分析系统的数量在增长，但仍缺乏结构化的知识库来指导其设计和开发。为弥补这一空白，我们提出VA-Blueprint，一种方法论和知识库，系统地审查和分类城市VA系统的基本构建块，这些构建块因其复杂的数据和独特的难题而尤其丰富和有代表性。通过将该方法应用于初始的20个系统，我们识别并组织了它们的核心组件构成多层次结构，形成了一个初步的知识库，包含可视分析系统开发的结构化蓝图。为了扩大这一努力，我们利用大型语言模型自动提取其他81篇论文中的这些组件（形成了101篇论文的语料库），评估其在扩展知识库构建方面的有效性。我们通过与专家访谈和注释指标的定量分析来评估我们的方法。我们的贡献提供了对VA系统组成更深入的理解，并建立了支持更结构化、可重复和高效系统开发的实际基础。VA-Blueprint可在以下链接访问： https:// 。', 'title_zh': 'VA-Blueprint: 探索视觉分析系统设计的基本构建块'}
{'arxiv_id': 'arXiv:2508.07494', 'title': 'From Product Hilbert Spaces to the Generalized Koopman Operator and the Nonlinear Fundamental Lemma', 'authors': 'Mircea Lazar', 'link': 'https://arxiv.org/abs/2508.07494', 'abstract': 'The generalization of the Koopman operator to systems with control input and the derivation of a nonlinear fundamental lemma are two open problems that play a key role in the development of data-driven control methods for nonlinear systems. Both problems hinge on the construction of observable or basis functions and their corresponding Hilbert space that enable an infinite-dimensional, linear system representation. In this paper we derive a novel solution to these problems based on orthonormal expansion in a product Hilbert space constructed as the tensor product between the Hilbert spaces of the state and input observable functions, respectively. We prove that there exists an infinite-dimensional linear operator, i.e. the generalized Koopman operator, from the constructed product Hilbert space to the Hilbert space corresponding to the lifted state propagated forward in time. A scalable data-driven method for computing finite-dimensional approximations of generalized Koopman operators and several choices of observable functions are also presented. Moreover, we derive a nonlinear fundamental lemma by exploiting the bilinear structure of the infinite-dimensional generalized Koopman model. The effectiveness of the developed generalized Koopman embedding is illustrated on the Van der Pol oscillator.', 'abstract_zh': '将Koopman算子推广到具有控制输入的系统并推导非线性基本引理是数据驱动控制方法在非线性系统中的发展中两个开放问题。这两个问题都依赖于构造可观测的或基函数及其相应的希尔伯特空间，以实现无限维的线性系统表示。本文基于状态和输入可观测函数的希尔伯特空间的张量积构造的乘积希尔伯特空间，推导了一种新的解决方案。我们证明存在一个从构造的乘积希尔伯特空间到表示沿时间推进的提升状态对应的希尔伯特空间的无限维线性算子，即广义Koopman算子。本文还提出了一种可扩展的数据驱动方法，用于计算广义Koopman算子的有限维逼近，并给出了几种可观测函数的选择。此外，我们通过利用广义Koopman模型的双线性结构推导出了非线性基本引理。所发展的广义Koopman嵌入的有效性在范德ポール振荡器上得到了验证。', 'title_zh': '从产品希尔伯特空间到广义科莫朗算子和非线性基本引理'}
{'arxiv_id': 'arXiv:2508.07486', 'title': 'Extracting Overlapping Microservices from Monolithic Code via Deep Semantic Embeddings and Graph Neural Network-Based Soft Clustering', 'authors': 'Morteza Ziabakhsh, Kiyan Rezaee, Sadegh Eskandari, Seyed Amir Hossein Tabatabaei, Mohammad M. Ghassemi', 'link': 'https://arxiv.org/abs/2508.07486', 'abstract': 'Modern software systems are increasingly shifting from monolithic architectures to microservices to enhance scalability, maintainability, and deployment flexibility. Existing microservice extraction methods typically rely on hard clustering, assigning each software component to a single microservice. This approach often increases inter-service coupling and reduces intra-service cohesion. We propose Mo2oM (Monolithic to Overlapping Microservices), a framework that formulates microservice extraction as a soft clustering problem, allowing components to belong probabilistically to multiple microservices. This approach is inspired by expert-driven decompositions, where practitioners intentionally replicate certain software components across services to reduce communication overhead. Mo2oM combines deep semantic embeddings with structural dependencies extracted from methodcall graphs to capture both functional and architectural relationships. A graph neural network-based soft clustering algorithm then generates the final set of microservices. We evaluate Mo2oM on four open-source monolithic benchmarks and compare it against eight state-of-the-art baselines. Our results demonstrate that Mo2oM achieves improvements of up to 40.97% in structural modularity (balancing cohesion and coupling), 58% in inter-service call percentage (communication overhead), 26.16% in interface number (modularity and decoupling), and 38.96% in non-extreme distribution (service size balance) across all benchmarks.', 'abstract_zh': '从单体架构到重叠微服务的转换：Mo2oM框架', 'title_zh': '通过深度语义嵌入和基于图神经网络的软聚类提取重叠微服务'}
{'arxiv_id': 'arXiv:2508.07484', 'title': 'ALOPE: Adaptive Layer Optimization for Translation Quality Estimation using Large Language Models', 'authors': 'Archchana Sindhujan, Shenbin Qian, Chan Chi Chun Matthew, Constantin Orasan, Diptesh Kanojia', 'link': 'https://arxiv.org/abs/2508.07484', 'abstract': 'Large Language Models (LLMs) have shown remarkable performance across a wide range of natural language processing tasks. Quality Estimation (QE) for Machine Translation (MT), which assesses the quality of a source-target pair without relying on reference translations, remains a challenging cross-lingual task for LLMs. The challenges stem from the inherent limitations of existing LLM-based QE systems, which are pre-trained for causal language modelling rather than regression-specific tasks, further elevated by the presence of low-resource languages given pre-training data distribution. This paper introduces ALOPE, an adaptive layer-optimization framework designed to enhance LLM-based QE by restructuring Transformer representations through layer-wise adaptation for improved regression-based prediction. Our framework integrates low-rank adapters (LoRA) with regression task heads, leveraging selected pre-trained Transformer layers for improved cross-lingual alignment. In addition to the layer-specific adaptation, ALOPE introduces two strategies-dynamic weighting, which adaptively combines representations from multiple layers, and multi-head regression, which aggregates regression losses from multiple heads for QE. Our framework shows improvements over various existing LLM-based QE approaches. Empirical evidence suggests that intermediate Transformer layers in LLMs provide contextual representations that are more aligned with the cross-lingual nature of the QE task. We make resultant models and framework code publicly available for further research, also allowing existing LLM-based MT frameworks to be scaled with QE capabilities.', 'abstract_zh': '大型语言模型（LLMs）在多种自然语言处理任务中展示了出色的表现。面向机器翻译（MT）的质量评估（QE），一种无需依赖参考翻译的源-目标对质量评估任务，对于LLMs来说仍然是一项具有挑战性的跨语言任务。这一挑战源于现有基于LLM的质量评估系统在回归特定任务上的预先训练不足，进一步受到低资源语言预训练数据分布的影响。本文介绍了一种自适应层优化框架ALOPE，旨在通过逐层自适应重构Transformer表示来提升基于LLM的质量评估性能，以改进基于回归的预测。该框架结合了低秩适配器（LoRA）和回归任务头，利用选择的预先训练的Transformer层以改善跨语言对齐。除了针对特定层的自适应优化，ALOPE还引入了动态加权和多头回归两种策略，分别通过自适应组合多层表示和从多个头部聚合回归损失来改进质量评估。该框架在多种现有的基于LLM的质量评估方法上表现出改进。实证证据表明，大型语言模型中的中间Transformer层提供了更符合质量评估任务跨语言性质的上下文表示。我们将所得模型和框架代码公开以供进一步研究，并允许现有的基于LLM的机器翻译框架通过集成质量评估能力来扩展。', 'title_zh': 'ALOPES：面向翻译质量评估的大型语言模型自适应层优化'}
{'arxiv_id': 'arXiv:2508.07453', 'title': 'Noise-Aware Generative Microscopic Traffic Simulation', 'authors': 'Vindula Jayawardana, Catherine Tang, Junyi Ji, Jonah Philion, Xue Bin Peng, Cathy Wu', 'link': 'https://arxiv.org/abs/2508.07453', 'abstract': 'Accurately modeling individual vehicle behavior in microscopic traffic simulation remains a key challenge in intelligent transportation systems, as it requires vehicles to realistically generate and respond to complex traffic phenomena such as phantom traffic jams. While traditional human driver simulation models offer computational tractability, they do so by abstracting away the very complexity that defines human driving. On the other hand, recent advances in infrastructure-mounted camera-based roadway sensing have enabled the extraction of vehicle trajectory data, presenting an opportunity to shift toward generative, agent-based models. Yet, a major bottleneck remains: most existing datasets are either overly sanitized or lack standardization, failing to reflect the noisy, imperfect nature of real-world sensing. Unlike data from vehicle-mounted sensors-which can mitigate sensing artifacts like occlusion through overlapping fields of view and sensor fusion-infrastructure-based sensors surface a messier, more practical view of challenges that traffic engineers encounter. To this end, we present the I-24 MOTION Scenario Dataset (I24-MSD)-a standardized, curated dataset designed to preserve a realistic level of sensor imperfection, embracing these errors as part of the learning problem rather than an obstacle to overcome purely from preprocessing. Drawing from noise-aware learning strategies in computer vision, we further adapt existing generative models in the autonomous driving community for I24-MSD with noise-aware loss functions. Our results show that such models not only outperform traditional baselines in realism but also benefit from explicitly engaging with, rather than suppressing, data imperfection. We view I24-MSD as a stepping stone toward a new generation of microscopic traffic simulation that embraces the real-world challenges and is better aligned with practical needs.', 'abstract_zh': 'I-24 车辆运动场景数据集：面向微观交通仿真的真实噪声数据集', 'title_zh': '噪声意识生成微观交通模拟'}
{'arxiv_id': 'arXiv:2508.07452', 'title': 'Stackelberg Coupling of Online Representation Learning and Reinforcement Learning', 'authors': 'Fernando Martinez, Tao Li, Yingdong Lu, Juntao Chen', 'link': 'https://arxiv.org/abs/2508.07452', 'abstract': "Integrated, end-to-end learning of representations and policies remains a cornerstone of deep reinforcement learning (RL). However, to address the challenge of learning effective features from a sparse reward signal, recent trends have shifted towards adding complex auxiliary objectives or fully decoupling the two processes, often at the cost of increased design complexity. This work proposes an alternative to both decoupling and naive end-to-end learning, arguing that performance can be significantly improved by structuring the interaction between distinct perception and control networks with a principled, game-theoretic dynamic. We formalize this dynamic by introducing the Stackelberg Coupled Representation and Reinforcement Learning (SCORER) framework, which models the interaction between perception and control as a Stackelberg game. The perception network (leader) strategically learns features to benefit the control network (follower), whose own objective is to minimize its Bellman error. We approximate the game's equilibrium with a practical two-timescale algorithm. Applied to standard DQN variants on benchmark tasks, SCORER improves sample efficiency and final performance. Our results show that performance gains can be achieved through principled algorithmic design of the perception-control dynamic, without requiring complex auxiliary objectives or architectures.", 'abstract_zh': '一种基于博弈论的 Perception-Control 结构化交互框架改进深度强化学习性能', 'title_zh': '在线表示学习与强化学习的Stackelberg耦合'}
{'arxiv_id': 'arXiv:2508.07446', 'title': 'Optimizing Districting Plans to Maximize Majority-Minority Districts via IPs and Local Search', 'authors': 'Daniel Brous, David Shmoys', 'link': 'https://arxiv.org/abs/2508.07446', 'abstract': 'In redistricting litigation, effective enforcement of the Voting Rights Act has often involved providing the court with districting plans that display a larger number of majority-minority districts than the current proposal (as was true, for example, in what followed Allen v. Milligan concerning the congressional districting plan for Alabama in 2023). Recent work by Cannon et al. proposed a heuristic algorithm for generating plans to optimize majority-minority districts, which they called short bursts; that algorithm relies on a sophisticated random walk over the space of all plans, transitioning in bursts, where the initial plan for each burst is the most successful plan from the previous burst. We propose a method based on integer programming, where we build upon another previous work, the stochastic hierarchical partitioning algorithm, which heuristically generates a robust set of potential districts (viewed as columns in a standard set partitioning formulation); that approach was designed to optimize a different notion of fairness across a statewide plan. We design a new column generation algorithm to find plans via integer programming that outperforms short bursts on multiple data sets in generating statewide plans with significantly more majority-minority districts. These results also rely on a new local re-optimization algorithm to iteratively improve on any baseline solution, as well as an algorithm to increase the compactness of districts in plans generated (without impacting the number of majority-minority districts).', 'abstract_zh': '在重划选区诉讼中，有效执行《投票权法》往往涉及提供给法庭包含比当前提议更多少数族裔多数选区的选区划拨方案（例如，在Allen v. Milligan案之后涉及到2023年阿拉巴马州国会选区划拨方案的情况即为如此）。Cannon等人最近提出了一种启发式算法，用于生成优化少数族裔多数选区的计划，并将该算法命名为“短脉冲”算法；该算法依赖于在所有可能计划空间上的复杂随机游走，并在每次脉冲中从上一个脉冲中最成功的计划开始转移。我们提出了一种基于整数规划的方法，其中我们在此前工作的基础上，扩展了随机分层划分算法，该算法启发式地生成一组健壮的潜在选区（作为标准集合划分公式中的列）；该方法旨在优化全省范围内不同类型的公平性。我们设计了一种新的列生成算法，通过整数规划找到计划，并在多个数据集上生成包含显著更多少数族裔多数选区的全省计划，该算法在生成计划时优于“短脉冲”算法。这些结果还依赖于一种新的局部重新优化算法，用于逐步改进任何基线解决方案，以及一种算法来增加生成计划中选区的紧凑性（而不影响少数族裔多数选区的数量）。', 'title_zh': '通过 IPs 和局部搜索优化区域划分计划以最大化大多数少数民族选区'}
{'arxiv_id': 'arXiv:2508.07432', 'title': 'Freeze and Reveal: Exposing Modality Bias in Vision-Language Models', 'authors': 'Vivek Hruday Kavuri, Vysishtya Karanam, Venkata Jahnavi Venkamsetty, Kriti Madumadukala, Lakshmipathi Balaji Darur, Ponnurangam Kumaraguru', 'link': 'https://arxiv.org/abs/2508.07432', 'abstract': "Vision Language Models achieve impressive multi-modal performance but often inherit gender biases from their training data. This bias might be coming from both the vision and text modalities. In this work, we dissect the contributions of vision and text backbones to these biases by applying targeted debiasing using Counterfactual Data Augmentation and Task Vector methods. Inspired by data-efficient approaches in hate-speech classification, we introduce a novel metric, Degree of Stereotypicality and a corresponding debiasing method, Data Augmentation Using Degree of Stereotypicality - DAUDoS, to reduce bias with minimal computational cost. We curate a gender annotated dataset and evaluate all methods on VisoGender benchmark to quantify improvements and identify dominant source of bias. Our results show that CDA reduces the gender gap by 6% and DAUDoS by 3% but using only one-third of the data. Both methods also improve the model's ability to correctly identify gender in images by 3%, with DAUDoS achieving this improvement using only almost one-third of training data. From our experiment's, we observed that CLIP's vision encoder is more biased whereas PaliGemma2's text encoder is more biased. By identifying whether bias stems more from vision or text encoders, our work enables more targeted and effective bias mitigation strategies in future multi-modal systems.", 'abstract_zh': '视觉语言模型在实现多模态性能的同时常常继承训练数据中的性别偏见。这种偏见可能源自于视觉和文本模态。本文通过应用目标化去偏见的反事实数据增强和任务向量方法，剖析视觉和文本骨干网络对这些偏见的贡献。受仇恨言论分类中高效数据利用方法的启发，我们引入了一个新的度量标准，即刻板印象程度，并提出一种相应的去偏见方法——基于刻板印象程度的数据增强（DAUDoS），以最少的计算成本减少偏见。我们收集了一个带有性别标注的数据集，并在VisoGender基准测试上评估所有方法，以量化改进并识别偏见的主要来源。我们的结果显示，CDA减少了6%的性别差距，而DAUDoS减少了3%的性别差距，但仅使用了数据的三分之一。两种方法还分别提高了模型在图像中正确识别性别的能力3%，而DAUDoS仅使用了几乎三分之一的训练数据就实现了这一改进。我们的实验发现，CLIP的视觉编码器更具偏见，而PaliGemma2的文本编码器更具偏见。通过确定偏见主要源自视觉编码器还是文本编码器，我们未来的工作能够为多模态系统提供更具针对性和有效的偏见缓解策略。', 'title_zh': '冻结与揭示：揭露视觉-语言模型的模态偏见'}
{'arxiv_id': 'arXiv:2508.07428', 'title': 'Lightning Prediction under Uncertainty: DeepLight with Hazy Loss', 'authors': 'Md Sultanul Arifin, Abu Nowshed Sakib, Yeasir Rayhan, Tanzima Hashem', 'link': 'https://arxiv.org/abs/2508.07428', 'abstract': 'Lightning, a common feature of severe meteorological conditions, poses significant risks, from direct human injuries to substantial economic losses. These risks are further exacerbated by climate change. Early and accurate prediction of lightning would enable preventive measures to safeguard people, protect property, and minimize economic losses. In this paper, we present DeepLight, a novel deep learning architecture for predicting lightning occurrences. Existing prediction models face several critical limitations: they often struggle to capture the dynamic spatial context and inherent uncertainty of lightning events, underutilize key observational data, such as radar reflectivity and cloud properties, and rely heavily on Numerical Weather Prediction (NWP) systems, which are both computationally expensive and highly sensitive to parameter settings. To overcome these challenges, DeepLight leverages multi-source meteorological data, including radar reflectivity, cloud properties, and historical lightning occurrences through a dual-encoder architecture. By employing multi-branch convolution techniques, it dynamically captures spatial correlations across varying extents. Furthermore, its novel Hazy Loss function explicitly addresses the spatio-temporal uncertainty of lightning by penalizing deviations based on proximity to true events, enabling the model to better learn patterns amidst randomness. Extensive experiments show that DeepLight improves the Equitable Threat Score (ETS) by 18%-30% over state-of-the-art methods, establishing it as a robust solution for lightning prediction.', 'abstract_zh': '深层闪电预测：一种新型深度学习架构', 'title_zh': '闪电预测中的不确定性处理：DeepLight与模糊损失函数'}
{'arxiv_id': 'arXiv:2508.07423', 'title': 'Real-Time Analysis of Unstructured Data with Machine Learning on Heterogeneous Architectures', 'authors': 'Fotis I. Giasemis', 'link': 'https://arxiv.org/abs/2508.07423', 'abstract': "As the particle physics community needs higher and higher precisions in order to test our current model of the subatomic world, larger and larger datasets are necessary. With upgrades scheduled for the detectors of colliding-beam experiments around the world, and specifically at the Large Hadron Collider at CERN, more collisions and more complex interactions are expected. This directly implies an increase in data produced and consequently in the computational resources needed to process them. At CERN, the amount of data produced is gargantuan. This is why the data have to be heavily filtered and selected in real time before being permanently stored. This data can then be used to perform physics analyses, in order to expand our current understanding of the universe and improve the Standard Model of physics. This real-time filtering, known as triggering, involves complex processing happening often at frequencies as high as 40 MHz. This thesis contributes to understanding how machine learning models can be efficiently deployed in such environments, in order to maximize throughput and minimize energy consumption. Inevitably, modern hardware designed for such tasks and contemporary algorithms are needed in order to meet the challenges posed by the stringent, high-frequency data rates. In this work, I present our graph neural network-based pipeline, developed for charged particle track reconstruction at the LHCb experiment at CERN. The pipeline was implemented end-to-end inside LHCb's first-level trigger, entirely on GPUs. Its performance was compared against the classical tracking algorithms currently in production at LHCb. The pipeline was also accelerated on the FPGA architecture, and its performance in terms of power consumption and processing speed was compared against the GPU implementation.", 'abstract_zh': '作为粒子物理学界需要更高精度以检验当前的亚原子世界模型，需要处理的数据量越来越大。随着全球 Collider 实验探测器的升级，特别是在 CERN 的大型强子对撞机 (LHC)，预计会产生更多的碰撞和更复杂的相互作用。这直接意味着需要处理的数据量增加，进而需要更多的计算资源来处理这些数据。在 CERN，产生的数据量巨大，因此必须在永久存储之前进行高度筛选和选择。这些数据可以用于进行物理分析，以扩展我们对宇宙的理解并改进物理的标准模型。这种实时筛选，称为触发，涉及复杂的处理，常常以高达 40 MHz 的频率进行。本论文旨在理解如何有效地将机器学习模型部署在这种环境中，以最大化吞吐量并最小化能耗。不可避免的是，为了应对如此高频率的数据速率带来的严格挑战，需要专门设计的现代硬件和当代算法。在此项工作中，我们介绍了为 CERN 的 LHCb 实验开发的基于图神经网络的流水线，用于带电粒子轨迹重建。该流水线完全在 GPU 上实现，并在 LHCb 的第一级触发器中端到端部署。我们将该流水线的性能与 LHCb 当前生产的经典跟踪算法进行了比较。此外，我们还在 FPGA 架构上对该流水线进行了加速，并将功耗和处理速度与 GPU 实现进行了比较。', 'title_zh': '异构架构上实时分析非结构化数据的机器学习方法'}
{'arxiv_id': 'arXiv:2508.07410', 'title': 'Leveraging GNN to Enhance MEF Method in Predicting ENSO', 'authors': 'Saghar Ganji, Mohammad Naisipour', 'link': 'https://arxiv.org/abs/2508.07410', 'abstract': 'Reliable long-lead forecasting of the El Nino Southern Oscillation (ENSO) remains a long-standing challenge in climate science. The previously developed Multimodal ENSO Forecast (MEF) model uses 80 ensemble predictions by two independent deep learning modules: a 3D Convolutional Neural Network (3D-CNN) and a time-series module. In their approach, outputs of the two modules are combined using a weighting strategy wherein one is prioritized over the other as a function of global performance. Separate weighting or testing of individual ensemble members did not occur, however, which may have limited the model to optimize the use of high-performing but spread-out forecasts. In this study, we propose a better framework that employs graph-based analysis to directly model similarity between all 80 members of the ensemble. By constructing an undirected graph whose vertices are ensemble outputs and whose weights on edges measure similarity (via RMSE and correlation), we identify and cluster structurally similar and accurate predictions. From which we obtain an optimized subset of 20 members using community detection methods. The final prediction is then obtained by averaging this optimized subset. This method improves the forecast skill through noise removal and emphasis on ensemble coherence. Interestingly, our graph-based selection shows robust statistical characteristics among top performers, offering new ensemble behavior insights. In addition, we observe that while the GNN-based approach does not always outperform the baseline MEF under every scenario, it produces more stable and consistent outputs, particularly in compound long-lead situations. The approach is model-agnostic too, suggesting that it can be applied directly to other forecasting models with gargantuan ensemble outputs, such as statistical, physical, or hybrid models.', 'abstract_zh': '可靠的拉尼娜南方 oscillation (ENSO) 长期预测依然是气候科学中的长期挑战。本研究提出了一种新的基于图的分析框架，直接建模80个成员之间的相似性。通过构建一个无向图，其中顶点代表成员输出，边的权重通过均方根误差和相关性衡量相似性，该方法将结构相似且准确的预测进行聚类，并使用社区检测方法从中选择优化的20个成员子集。最终的预测通过平均优化子集获得，该方法通过去除噪声和强调成员一致性来提高预测技能。我们的图选择方法在顶级表现者中显示出稳健的统计特性，提供了新的ensemble行为见解。此外，观察到基于图神经网络的方法在某些情况下不一定比基线 MEF 模型表现更好，但在长预测情境下，它会产生更稳定和一致的输出。该方法是模型无关的，可以应用于其他具有庞大ensemble输出的预测模型，如统计学、物理学或混合模型。', 'title_zh': '利用GNN增强MEF方法预测ENSO'}
{'arxiv_id': 'arXiv:2508.07406', 'title': 'AgriVLN: Vision-and-Language Navigation for Agricultural Robots', 'authors': 'Xiaobei Zhao, Xingqi Lyu, Xiang Li', 'link': 'https://arxiv.org/abs/2508.07406', 'abstract': 'Agricultural robots have emerged as powerful members in agricultural tasks, nevertheless, still heavily rely on manual operation or untransportable railway for movement, resulting in limited mobility and poor adaptability. Vision-and-Language Navigation (VLN) enables robots to navigate to the target destinations following natural language instructions, demonstrating strong performance on several domains. However, none of the existing benchmarks or methods is specifically designed for agricultural scenes. To bridge this gap, we propose Agriculture to Agriculture (A2A) benchmark, containing 1,560 episodes across six diverse agricultural scenes, in which all realistic RGB videos are captured by front-facing camera on a quadruped robot at a height of 0.38 meters, aligning with the practical deployment conditions. Meanwhile, we propose Vision-and-Language Navigation for Agricultural Robots (AgriVLN) baseline based on Vision-Language Model (VLM) prompted with carefully crafted templates, which can understand both given instructions and agricultural environments to generate appropriate low-level actions for robot control. When evaluated on A2A, AgriVLN performs well on short instructions but struggles with long instructions, because it often fails to track which part of the instruction is currently being executed. To address this, we further propose Subtask List (STL) instruction decomposition module and integrate it into AgriVLN, improving Success Rate (SR) from 0.33 to 0.47. We additionally compare AgriVLN with several existing VLN methods, demonstrating the state-of-the-art performance in the agricultural domain.', 'abstract_zh': '农业机器人在农业任务中已展现出强大的能力，然而仍高度依赖手动操作或不可移动的轨道进行移动，导致其移动能力有限且适应性差。基于视觉-语言导航（VLN）使机器人能够遵循自然语言指令导航至目标位置，已经在多个领域展现出强大性能。然而，目前所有现有的基准或方法均未专门设计用于农业场景。为填补这一空白，我们提出了农业到农业（A2A）基准，包含涵盖六大不同农业场景的1,560个 episodes，并且所有真实的RGB视频均由四足机器人前向摄像头在0.38米的高度拍摄，符合实际部署条件。同时，我们基于视觉-语言模型（VLM）提出了精心设计模板的农业机器人基于视觉-语言导航（AgriVLN）基线，能够理解给定的指令和农业环境以生成适当的低级动作以控制机器人。评估结果显示，AgriVLN在短指令上表现良好，但在长指令上表现出困难，因为它经常无法正确追踪当前执行的指令部分。为此，我们进一步提出了子任务列表（STL）指令分解模块，并将其整合到AgriVLN中，将成功率（SR）从0.33提高到0.47。此外，我们还将AgriVLN与其他现有的VLN方法进行了比较，展示了在农业领域中的先进性能。', 'title_zh': '农用VLN：农业机器人视觉与语言导航'}
{'arxiv_id': 'arXiv:2508.07397', 'title': 'A Spin Glass Characterization of Neural Networks', 'authors': 'Jun Li', 'link': 'https://arxiv.org/abs/2508.07397', 'abstract': 'This work presents a statistical mechanics characterization of neural networks, motivated by the replica symmetry breaking (RSB) phenomenon in spin glasses. A Hopfield-type spin glass model is constructed from a given feedforward neural network (FNN). Overlaps between simulated replica samples serve as a characteristic descriptor of the FNN. The connection between the spin-glass description and commonly studied properties of the FNN -- such as data fitting, capacity, generalization, and robustness -- has been investigated and empirically demonstrated. Unlike prior analytical studies that focus on model ensembles, this method provides a computable descriptor for individual network instances, which reveals nontrivial structural properties that are not captured by conventional metrics such as loss or accuracy. Preliminary results suggests its potential for practical applications such as model inspection, safety verification, and detection of hidden vulnerabilities.', 'abstract_zh': '基于旋 erection glasses中的重临界现象的前馈神经网络的统计力学特性研究', 'title_zh': '神经网络的旋格 characterization'}
{'arxiv_id': 'arXiv:2508.07390', 'title': 'Urbanite: A Dataflow-Based Framework for Human-AI Interactive Alignment in Urban Visual Analytics', 'authors': 'Gustavo Moreira, Leonardo Ferreira, Carolina Veiga, Maryam Hosseini, Fabio Miranda', 'link': 'https://arxiv.org/abs/2508.07390', 'abstract': "With the growing availability of urban data and the increasing complexity of societal challenges, visual analytics has become essential for deriving insights into pressing real-world problems. However, analyzing such data is inherently complex and iterative, requiring expertise across multiple domains. The need to manage diverse datasets, distill intricate workflows, and integrate various analytical methods presents a high barrier to entry, especially for researchers and urban experts who lack proficiency in data management, machine learning, and visualization. Advancements in large language models offer a promising solution to lower the barriers to the construction of analytics systems by enabling users to specify intent rather than define precise computational operations. However, this shift from explicit operations to intent-based interaction introduces challenges in ensuring alignment throughout the design and development process. Without proper mechanisms, gaps can emerge between user intent, system behavior, and analytical outcomes. To address these challenges, we propose Urbanite, a framework for human-AI collaboration in urban visual analytics. Urbanite leverages a dataflow-based model that allows users to specify intent at multiple scopes, enabling interactive alignment across the specification, process, and evaluation stages of urban analytics. Based on findings from a survey to uncover challenges, Urbanite incorporates features to facilitate explainability, multi-resolution definition of tasks across dataflows, nodes, and parameters, while supporting the provenance of interactions. We demonstrate Urbanite's effectiveness through usage scenarios created in collaboration with urban experts. Urbanite is available at this https URL.", 'abstract_zh': '随着城市数据的日益增多和社会挑战的日益复杂，视觉分析已成为提取紧迫现实世界问题洞察的必要工具。然而，分析这类数据本质上是复杂和迭代的，需要跨多个领域的专业知识。管理和整合多样化的数据集、提炼复杂的工作流程以及整合多种分析方法设置了一道较高的进入门槛，尤其是对于在数据管理、机器学习和可视化方面缺乏专业技能的研究人员和城市专家而言。大型语言模型的进步为降低构建分析系统的技术门槛提供了前景，通过让用户指定意图而非定义精确的计算操作。然而，从显式操作转向基于意图的交互会带来确保设计和开发过程一致性的挑战。如果没有适当的机制，用户意图、系统行为和分析结果之间可能会出现差距。为了解决这些挑战，我们提出Urbanite框架，用于实现城市视觉分析中的人工智能协作。Urbanite利用数据流模型，允许用户在多个层面上指定意图，从而实现规格、流程和评估阶段的交互对齐。基于对挑战的调查发现，Urbanite集成了增强可解释性、跨数据流、节点和参数的多分辨率任务定义以及交互溯源的功能。我们通过与城市专家合作创建的应用场景展示了Urbanite的有效性。Urbanite可在以下链接访问：这个 https URL。', 'title_zh': 'Urbanite：一种基于数据流的人机在城市视觉分析中交互对齐的框架'}
{'arxiv_id': 'arXiv:2508.07371', 'title': 'AutoAssert 1: A LoRA Fine-Tuned LLM Model for Efficient Automated Assertion Generation', 'authors': 'Yi Zhong, Hongchao Liu, Di ZHao', 'link': 'https://arxiv.org/abs/2508.07371', 'abstract': 'As the complexity of software systems continues to increase, the demand for automated testing and maintenance tools is growing exponentially. To meet this urgent need, we propose a new assertion generation method based on Hardware Description Language (HDL). This method combines a lightweight, parameter-adjustable large language model (LLM) with the Unsloth platform to automatically generate test cases, thereby significantly reducing training costs without sacrificing accuracy or generalization performance. Empirical evaluation shows that our method can efficiently generate assertions that strictly conform to the hardware logic. This framework provides a robust and flexible solution to modern software testing and maintenance challenges. this https URL and this https URL are the locations of the source code.', 'abstract_zh': '随着软件系统的复杂性不断增加，对自动测试和维护工具的需求呈指数级增长。为满足这一迫切需求，我们提出了一种基于硬件描述语言（HDL）的新断言生成方法。该方法结合了一个轻量级、可参数调整的大语言模型（LLM）和Unsloth平台，自动生成测试案例，从而显著降低培训成本，而不牺牲准确性和泛化性能。实证评估表明，该方法能高效生成严格符合硬件逻辑的断言。该框架提供了应对现代软件测试和维护挑战的 robust 和灵活解决方案。该方法的相关源代码位于此 https:// 和此 https://。', 'title_zh': 'AutoAssert 1：一种用于高效自动断言生成的LoRA微调大型语言模型'}
{'arxiv_id': 'arXiv:2508.07345', 'title': 'ProteoKnight: Convolution-based phage virion protein classification and uncertainty analysis', 'authors': 'Samiha Afaf Neha, Abir Ahammed Bhuiyan, Md. Ishrak Khan', 'link': 'https://arxiv.org/abs/2508.07345', 'abstract': '\\textbf{Introduction:} Accurate prediction of Phage Virion Proteins (PVP) is essential for genomic studies due to their crucial role as structural elements in bacteriophages. Computational tools, particularly machine learning, have emerged for annotating phage protein sequences from high-throughput sequencing. However, effective annotation requires specialized sequence encodings. Our paper introduces ProteoKnight, a new image-based encoding method that addresses spatial constraints in existing techniques, yielding competitive performance in PVP classification using pre-trained convolutional neural networks. Additionally, our study evaluates prediction uncertainty in binary PVP classification through Monte Carlo Dropout (MCD). \\textbf{Methods:} ProteoKnight adapts the classical DNA-Walk algorithm for protein sequences, incorporating pixel colors and adjusting walk distances to capture intricate protein features. Encoded sequences were classified using multiple pre-trained CNNs. Variance and entropy measures assessed prediction uncertainty across proteins of various classes and lengths. \\textbf{Results:} Our experiments achieved 90.8% accuracy in binary classification, comparable to state-of-the-art methods. Multi-class classification accuracy remains suboptimal. Our uncertainty analysis unveils variability in prediction confidence influenced by protein class and sequence length. \\textbf{Conclusions:} Our study surpasses frequency chaos game representation (FCGR) by introducing novel image encoding that mitigates spatial information loss limitations. Our classification technique yields accurate and robust PVP predictions while identifying low-confidence predictions.', 'abstract_zh': '引言：准确预测噬菌体病毒颗粒蛋白（PVP）对于基因组研究至关重要，因为它们在噬菌体中作为结构成分起着关键作用。计算工具，尤其是机器学习，已经用于从高通量测序中注解噬菌体蛋白质序列。然而，有效的注解需要专门的序列编码。本文介绍了ProteoKnight，一种新的基于图像的编码方法，该方法解决了现有技术中的空间约束问题，并通过预训练的卷积神经网络在PVP分类中获得了竞争性性能。此外，我们的研究通过蒙特卡洛丢弃（MCD）评估了二分类PVP预测的不确定性。方法：ProteoKnight 对经典的DNA-Walk算法进行了蛋白序列的适应，结合像素颜色并调整行走距离以捕捉复杂的蛋白特征。编码后的序列使用多个预训练的CNN进行分类。方差和熵度量评估了不同类别和长度蛋白质预测不确定性。结果：我们的实验在二分类中实现了90.8%的准确率，与最先进的方法相当。多分类准确率仍不尽如人意。我们的不确定性分析揭示了预测置信度的变异性，这种变异性受蛋白质类别和序列长度的影响。结论：我们的研究超过了频率混沌游戏表示（FCGR），引入了一种新的图像编码方法，该方法缓解了空间信息损失的限制。我们的分类技术提供了准确而稳健的PVP预测，同时识别出低置信度的预测。', 'title_zh': 'ProteoKnight：基于卷积的噬菌体病毒颗粒蛋白质分类及不确定性分析'}
{'arxiv_id': 'arXiv:2508.07329', 'title': 'Efficient Edge LLMs Deployment via HessianAware Quantization and CPU GPU Collaborative', 'authors': 'Tuo Zhang, Ning Li, Xin Yuan, Wenchao Xu, Quan Chen, Song Guo, Haijun Zhang', 'link': 'https://arxiv.org/abs/2508.07329', 'abstract': 'With the breakthrough progress of large language models (LLMs) in natural language processing and multimodal tasks, efficiently deploying them on resource-constrained edge devices has become a critical challenge. The Mixture of Experts (MoE) architecture enhances model capacity through sparse activation, but faces two major difficulties in practical deployment: (1) The presence of numerous outliers in activation distributions leads to severe degradation in quantization accuracy for both activations and weights, significantly impairing inference performance; (2) Under limited memory, efficient offloading and collaborative inference of expert modules struggle to balance latency and throughput. To address these issues, this paper proposes an efficient MoE edge deployment scheme based on Hessian-Aware Quantization (HAQ) and CPU-GPU collaborative inference. First, by introducing smoothed Hessian matrix quantization, we achieve joint 8-bit quantization of activations and weights, which significantly alleviates the accuracy loss caused by outliers while ensuring efficient implementation on mainstream hardware. Second, we design an expert-level collaborative offloading and inference mechanism, which, combined with expert activation path statistics, enables efficient deployment and scheduling of expert modules between CPU and GPU, greatly reducing memory footprint and inference latency. Extensive experiments validate the effectiveness of our method on mainstream large models such as the OPT series and Mixtral 8*7B: on datasets like Wikitext2 and C4, the inference accuracy of the low-bit quantized model approaches that of the full-precision model, while GPU memory usage is reduced by about 60%, and inference latency is significantly improved.', 'abstract_zh': '基于Hessian意识量化和CPU-GPU协同推理的大规模模型边缘部署方案', 'title_zh': '基于海森矩阵感知量化和CPU GPU协作的高效边缘端LLM部署'}
{'arxiv_id': 'arXiv:2508.07325', 'title': 'Strategies of Code-switching in Human-Machine Dialogs', 'authors': 'Dean Geckt, Melinda Fricke, Shuly Wintner', 'link': 'https://arxiv.org/abs/2508.07325', 'abstract': "Most people are multilingual, and most multilinguals code-switch, yet the characteristics of code-switched language are not fully understood. We developed a chatbot capable of completing a Map Task with human participants using code-switched Spanish and English. In two experiments, we prompted the bot to code-switch according to different strategies, examining (1) the feasibility of such experiments for investigating bilingual language use, and (2) whether participants would be sensitive to variations in discourse and grammatical patterns. Participants generally enjoyed code-switching with our bot as long as it produced predictable code-switching behavior; when code-switching was random or ungrammatical (as when producing unattested incongruent mixed-language noun phrases, such as `la fork'), participants enjoyed the task less and were less successful at completing it. These results underscore the potential downsides of deploying insufficiently developed multilingual language technology, while also illustrating the promise of such technology for conducting research on bilingual language use.", 'abstract_zh': '大多数人都既是多语言者，又擅长转码，在此背景下，代码转换语言的特点尚未完全阐明。我们开发了一个能够使用代码转换的西班牙语和英语与人类参与者完成地图任务的聊天机器人。在两项实验中，我们促使该聊天机器人根据不同的策略进行代码转换，探讨（1）此类实验对研究双语语言使用可行性的意义，以及（2）参与者是否会对话语和语法模式的变化敏感。参与者通常在聊天机器人产生可预测的代码转换行为时对与其进行代码转换感到愉快；当代码转换表现为随机或不语法（例如，生成未证实的不协调的语言混合名词短语“la fork”）时，参与者对任务的享受和完成度则大大降低。这些结果强调了部署不充分发展的多语言语言技术可能带来的负面影响，同时也展示了此类技术在研究双语语言使用方面的潜力。', 'title_zh': '人类机对话中的代码转换策略'}
{'arxiv_id': 'arXiv:2508.07321', 'title': 'ObfusQAte: A Proposed Framework to Evaluate LLM Robustness on Obfuscated Factual Question Answering', 'authors': 'Shubhra Ghosh, Abhilekh Borah, Aditya Kumar Guru, Kripabandhu Ghosh', 'link': 'https://arxiv.org/abs/2508.07321', 'abstract': "The rapid proliferation of Large Language Models (LLMs) has significantly contributed to the development of equitable AI systems capable of factual question-answering (QA). However, no known study tests the LLMs' robustness when presented with obfuscated versions of questions. To systematically evaluate these limitations, we propose a novel technique, ObfusQAte and, leveraging the same, introduce ObfusQA, a comprehensive, first of its kind, framework with multi-tiered obfuscation levels designed to examine LLM capabilities across three distinct dimensions: (i) Named-Entity Indirection, (ii) Distractor Indirection, and (iii) Contextual Overload. By capturing these fine-grained distinctions in language, ObfusQA provides a comprehensive benchmark for evaluating LLM robustness and adaptability. Our study observes that LLMs exhibit a tendency to fail or generate hallucinated responses when confronted with these increasingly nuanced variations. To foster research in this direction, we make ObfusQAte publicly available.", 'abstract_zh': '大规模语言模型的快速 proliferate 显著促进了公平的 AI 系统的发展，这些系统能够进行事实性的问答（QA）。然而，目前没有任何已知的研究测试 LLM 在面对混淆版本的问题时的 robustness。为了系统地评估这些限制，我们提出了一种新颖的技术 ObfusQAte，并借助该技术引入了 ObfusQA，这是一个全面的、首创的框架，具有多层次的混淆级别，旨在从三个不同的维度考察 LLM 的能力：(i) 命名实体间接性，(ii) 干扰项间接性，以及 (iii) 上下文过载。通过捕捉这些细微的语言差异，ObfusQA 提供了一个全面的基准，用于评估 LLM 的 robustness 和适应性。我们的研究观察到，当 LLM 面对这些日益复杂的变体时，它们往往会失败或生成虚构的响应。为促进这一方向的研究，我们已将 ObfusQAte 公开发布。', 'title_zh': 'ObfusQAte：评估LLM在混淆事实型问答中稳健性的提议框架'}
{'arxiv_id': 'arXiv:2508.07315', 'title': 'FlexCTC: GPU-powered CTC Beam Decoding with advanced Contextual Abilities', 'authors': 'Lilit Grigoryan, Vladimir Bataev, Nikolay Karpov, Andrei Andrusenko, Vitaly Lavrukhin, Boris Ginsburg', 'link': 'https://arxiv.org/abs/2508.07315', 'abstract': 'While beam search improves speech recognition quality over greedy decoding, standard implementations are slow, often sequential, and CPU-bound. To fully leverage modern hardware capabilities, we present a novel open-source FlexCTC toolkit for fully GPU-based beam decoding, designed for Connectionist Temporal Classification (CTC) models. Developed entirely in Python and PyTorch, it offers a fast, user-friendly, and extensible alternative to traditional C++, CUDA, or WFST-based decoders. The toolkit features a high-performance, fully batched GPU implementation with eliminated CPU-GPU synchronization and minimized kernel launch overhead via CUDA Graphs. It also supports advanced contextualization techniques, including GPU-powered N-gram language model fusion and phrase-level boosting. These features enable accurate and efficient decoding, making them suitable for both research and production use.', 'abstract_zh': '基于GPU的贝叶斯解码FlexCTC工具包：适用于连接时序分类模型的高性能解码', 'title_zh': 'FlexCTC: 以GPU为动力的具有高级上下文能力的CTC束解码'}
{'arxiv_id': 'arXiv:2508.07308', 'title': 'HealthBranches: Synthesizing Clinically-Grounded Question Answering Datasets via Decision Pathways', 'authors': 'Cristian Cosentino, Annamaria Defilippo, Marco Dossena, Christopher Irwin, Sara Joubbi, Pietro Liò', 'link': 'https://arxiv.org/abs/2508.07308', 'abstract': "HealthBranches is a novel benchmark dataset for medical Question-Answering (Q&A), specifically designed to evaluate complex reasoning in Large Language Models (LLMs). This dataset is generated through a semi-automated pipeline that transforms explicit decision pathways from medical source into realistic patient cases with associated questions and answers. Covering 4,063 case studies across 17 healthcare topics, each data point is based on clinically validated reasoning chains. HealthBranches supports both open-ended and multiple-choice question formats and uniquely includes the full reasoning path for each Q&A. Its structured design enables robust evaluation of LLMs' multi-step inference capabilities, including their performance in structured Retrieval-Augmented Generation (RAG) contexts. HealthBranches establishes a foundation for the development of more trustworthy, interpretable, and clinically reliable LLMs in high-stakes domains while also serving as a valuable resource for educational purposes.", 'abstract_zh': 'HealthBranches：一种新型的医学问答基准数据集，专门用于评估大型语言模型的复杂推理能力', 'title_zh': '健康分支：通过决策路径合成临床导向的问答数据集'}
{'arxiv_id': 'arXiv:2508.07307', 'title': 'MCITlib: Multimodal Continual Instruction Tuning Library and Benchmark', 'authors': 'Haiyang Guo, Fei Zhu, Hongbo Zhao, Fanhu Zeng, Wenzhuo Liu, Shijie Ma, Da-Han Wang, Xu-Yao Zhang', 'link': 'https://arxiv.org/abs/2508.07307', 'abstract': 'Continual learning aims to equip AI systems with the ability to continuously acquire and adapt to new knowledge without forgetting previously learned information, similar to human learning. While traditional continual learning methods focusing on unimodal tasks have achieved notable success, the emergence of Multimodal Large Language Models has brought increasing attention to Multimodal Continual Learning tasks involving multiple modalities, such as vision and language. In this setting, models are expected to not only mitigate catastrophic forgetting but also handle the challenges posed by cross-modal interactions and coordination. To facilitate research in this direction, we introduce MCITlib, a comprehensive and constantly evolving code library for continual instruction tuning of Multimodal Large Language Models. In MCITlib, we have currently implemented 8 representative algorithms for Multimodal Continual Instruction Tuning and systematically evaluated them on 2 carefully selected benchmarks. MCITlib will be continuously updated to reflect advances in the Multimodal Continual Learning field. The codebase is released at this https URL.', 'abstract_zh': '持续学习旨在赋予AI系统不断获取和适应新知识的能力，同时不会忘记已学信息，类似于人类学习。虽然传统持续学习方法在单模态任务上取得了显著成就，但多模态大型语言模型的出现增加了对涉及多种模态（如视觉和语言）的多模态持续学习任务的关注。在这种环境中，模型不仅需要缓解灾难性遗忘，还需要处理模态间交互和协调所带来的挑战。为了促进该方向的研究，我们介绍了MCITlib，一个全面且不断演进的代码库，用于多模态大型语言模型的持续指令调整。在MCITlib中，我们目前已实现8种代表性的多模态持续指令调整算法，并系统地在2个精心选择的基准上进行了评估。MCITlib将不断更新以反映多模态持续学习领域的进步。代码库发布于此网址：[该网址]。', 'title_zh': 'MCITlib: 多模态连续指令调优库及基准'}
{'arxiv_id': 'arXiv:2508.07306', 'title': 'DragonFruitQualityNet: A Lightweight Convolutional Neural Network for Real-Time Dragon Fruit Quality Inspection on Mobile Devices', 'authors': 'Md Zahurul Haquea, Yeahyea Sarker, Muhammed Farhan Sadique Mahi, Syed Jubayer Jaman, Md Robiul Islam', 'link': 'https://arxiv.org/abs/2508.07306', 'abstract': 'Dragon fruit, renowned for its nutritional benefits and economic value, has experienced rising global demand due to its affordability and local availability. As dragon fruit cultivation expands, efficient pre- and post-harvest quality inspection has become essential for improving agricultural productivity and minimizing post-harvest losses. This study presents DragonFruitQualityNet, a lightweight Convolutional Neural Network (CNN) optimized for real-time quality assessment of dragon fruits on mobile devices. We curated a diverse dataset of 13,789 images, integrating self-collected samples with public datasets (dataset from Mendeley Data), and classified them into four categories: fresh, immature, mature, and defective fruits to ensure robust model training. The proposed model achieves an impressive 93.98% accuracy, outperforming existing methods in fruit quality classification. To facilitate practical adoption, we embedded the model into an intuitive mobile application, enabling farmers and agricultural stakeholders to conduct on-device, real-time quality inspections. This research provides an accurate, efficient, and scalable AI-driven solution for dragon fruit quality control, supporting digital agriculture and empowering smallholder farmers with accessible technology. By bridging the gap between research and real-world application, our work advances post-harvest management and promotes sustainable farming practices.', 'abstract_zh': '基于卷积神经网络的轻量级龙果品质检测模型研究', 'title_zh': 'DragonFruitQualityNet：一种适用于移动设备实时龙眼质量检测的轻量级卷积神经网络'}
{'arxiv_id': 'arXiv:2508.07304', 'title': 'From Knowledge to Conjectures: A Modal Framework for Reasoning about Hypotheses', 'authors': 'Fabio Vitali', 'link': 'https://arxiv.org/abs/2508.07304', 'abstract': "This paper introduces a new family of cognitive modal logics designed to formalize conjectural reasoning: a modal system in which cognitive contexts extend known facts with hypothetical assumptions to explore their consequences. Unlike traditional doxastic and epistemic systems, conjectural logics rely on a principle, called Axiom C ($\\varphi \\rightarrow \\Box\\varphi$), that ensures that all established facts are preserved across hypothetical layers. While Axiom C was dismissed in the past due to its association with modal collapse, we show that the collapse only arises under classical and bivalent assumptions, and specifically in the presence of Axiom T. Hence we avoid Axiom T and adopt a paracomplete semantic framework, grounded in Weak Kleene logic or Description Logic, where undefined propositions coexist with modal assertions. This prevents the modal collapse and guarantees a layering to distinguish between factual and conjectural statements. Under this framework we define new modal systems, e.g., KC and KDC, and show that they are complete, decidable, and robust under partial knowledge. Finally, we introduce a dynamic operation, $\\mathsf{settle}(\\varphi)$, which formalizes the transition from conjecture to accepted fact, capturing the event of the update of a world's cognitive state through the resolution of uncertainty.", 'abstract_zh': '一种新的认知模态逻辑家族：用于形式化猜测性推理的模态系统', 'title_zh': '从知识到假设：一种关于假设推理的模态框架'}
{'arxiv_id': 'arXiv:2508.07299', 'title': 'When Is Prior Knowledge Helpful? Exploring the Evaluation and Selection of Unsupervised Pretext Tasks from a Neuro-Symbolic Perspective', 'authors': 'Lin-Han Jia, Si-Yu Han, Wen-Chao Hu, Jie-Jing Shao, Wen-Da Wei, Zhi Zhou, Lan-Zhe Guo, Yu-Feng Li', 'link': 'https://arxiv.org/abs/2508.07299', 'abstract': 'Neuro-symbolic (Nesy) learning improves the target task performance of models by enabling them to satisfy knowledge, while semi/self-supervised learning (SSL) improves the target task performance by designing unsupervised pretext tasks for unlabeled data to make models satisfy corresponding assumptions. We extend the Nesy theory based on reliable knowledge to the scenario of unreliable knowledge (i.e., assumptions), thereby unifying the theoretical frameworks of SSL and Nesy. Through rigorous theoretical analysis, we demonstrate that, in theory, the impact of pretext tasks on target performance hinges on three factors: knowledge learnability with respect to the model, knowledge reliability with respect to the data, and knowledge completeness with respect to the target. We further propose schemes to operationalize these theoretical metrics, and thereby develop a method that can predict the effectiveness of pretext tasks in advance. This will change the current status quo in practical applications, where the selections of unsupervised tasks are heuristic-based rather than theory-based, and it is difficult to evaluate the rationality of unsupervised pretext task selection before testing the model on the target task. In experiments, we verify a high correlation between the predicted performance-estimated using minimal data-and the actual performance achieved after large-scale semi-supervised or self-supervised learning, thus confirming the validity of the theory and the effectiveness of the evaluation method.', 'abstract_zh': '基于可靠知识的神经符号学习扩展了目标任务性能，进而统一了半监督/自我监督学习和神经符号学习的理论框架', 'title_zh': '何时先验知识有益？从神经符号视角探索无监督预文本任务的评估与选择'}
{'arxiv_id': 'arXiv:2508.07297', 'title': 'Revisiting Data Attribution for Influence Functions', 'authors': 'Hongbo Zhu, Angelo Cangelosi', 'link': 'https://arxiv.org/abs/2508.07297', 'abstract': "The goal of data attribution is to trace the model's predictions through the learning algorithm and back to its training data. thereby identifying the most influential training samples and understanding how the model's behavior leads to particular predictions. Understanding how individual training examples influence a model's predictions is fundamental for machine learning interpretability, data debugging, and model accountability. Influence functions, originating from robust statistics, offer an efficient, first-order approximation to estimate the impact of marginally upweighting or removing a data point on a model's learned parameters and its subsequent predictions, without the need for expensive retraining. This paper comprehensively reviews the data attribution capability of influence functions in deep learning. We discuss their theoretical foundations, recent algorithmic advances for efficient inverse-Hessian-vector product estimation, and evaluate their effectiveness for data attribution and mislabel detection. Finally, highlighting current challenges and promising directions for unleashing the huge potential of influence functions in large-scale, real-world deep learning scenarios.", 'abstract_zh': '数据归因的目标是通过学习算法追踪模型的预测，最终追溯到其训练数据，从而识别最具影响力的训练样本，并了解模型行为如何导致特定预测。理解单个训练示例如何影响模型的预测对于机器学习的可解释性、数据调试和模型问责制是基础性的。源自鲁棒统计学的影响函数提供了一种高效的近似方法，可以在不需要昂贵重新训练的情况下，估计微小增加或移除数据点对模型学习参数及其后续预测的影响。本文全面回顾了影响函数在深度学习中的数据归因能力。我们讨论了其理论基础、用于高效估计逆海森矩阵向量积的最新算法进展，并评估了其在数据归因和误标检测中的有效性。最后，我们指出了当前挑战，并提出了在大规模真实世界深度学习场景中释放影响函数巨大潜力的有前景的方向。', 'title_zh': '重访数据归属对影响函数的研究'}
{'arxiv_id': 'arXiv:2508.07284', 'title': '"Pull or Not to Pull?\'\': Investigating Moral Biases in Leading Large Language Models Across Ethical Dilemmas', 'authors': 'Junchen Ding, Penghao Jiang, Zihao Xu, Ziqi Ding, Yichen Zhu, Jiaojiao Jiang, Yuekang Li', 'link': 'https://arxiv.org/abs/2508.07284', 'abstract': 'As large language models (LLMs) increasingly mediate ethically sensitive decisions, understanding their moral reasoning processes becomes imperative. This study presents a comprehensive empirical evaluation of 14 leading LLMs, both reasoning enabled and general purpose, across 27 diverse trolley problem scenarios, framed by ten moral philosophies, including utilitarianism, deontology, and altruism. Using a factorial prompting protocol, we elicited 3,780 binary decisions and natural language justifications, enabling analysis along axes of decisional assertiveness, explanation answer consistency, public moral alignment, and sensitivity to ethically irrelevant cues. Our findings reveal significant variability across ethical frames and model types: reasoning enhanced models demonstrate greater decisiveness and structured justifications, yet do not always align better with human consensus. Notably, "sweet zones" emerge in altruistic, fairness, and virtue ethics framings, where models achieve a balance of high intervention rates, low explanation conflict, and minimal divergence from aggregated human judgments. However, models diverge under frames emphasizing kinship, legality, or self interest, often producing ethically controversial outcomes. These patterns suggest that moral prompting is not only a behavioral modifier but also a diagnostic tool for uncovering latent alignment philosophies across providers. We advocate for moral reasoning to become a primary axis in LLM alignment, calling for standardized benchmarks that evaluate not just what LLMs decide, but how and why.', 'abstract_zh': '随着大型语言模型（LLMs）越来越多地参与伦理敏感决策过程，理解其道德推理过程变得至关重要。本研究对14种领先的LLMs，包括配备推理能力和通用型模型，进行了全面的经验评估，涵盖27种不同的铁轨问题情景，涉及十种不同的道德哲学，包括功利主义、义务论和利他主义。通过因子提示协议，我们获得了3780个二元决策和自然语言解释，从而能够沿决策坚定性、解释答案一致性、公共道德一致性以及对伦理无关提示的敏感性这几个维度进行分析。我们的研究发现，在不同的伦理框架和模型类型之间存在显著差异：增强推理能力的模型表现出更高的决断力和结构化的解释，但并不总是更好地与人类共识一致。值得注意的是，在利他主义、公平性和美德伦理框架下，“舒适区”开始显现，模型能够实现高干预率、低解释冲突和适度偏离聚合的人类判断。然而，在强调亲属关系、合法性或自我利益的框架下，模型的分歧更为明显，经常产生伦理上有争议的结果。这些模式表明，道德提示不仅是行为调节器，也是识别不同提供商潜在一致哲学的诊断工具。我们呼吁将道德推理作为LLM对齐的主要维度，倡导标准化基准不仅评估LLM做了什么决策，还要评估它是如何和为什么做这些决策的。', 'title_zh': '“拉还是不拉？”：探究大型语言模型在伦理困境中的道德偏见'}
{'arxiv_id': 'arXiv:2508.07283', 'title': 'Fine-Tuning Large Language Models Using EEG Microstate Features for Mental Workload Assessment', 'authors': 'Bujar Raufi', 'link': 'https://arxiv.org/abs/2508.07283', 'abstract': "This study explores the intersection of electroencephalography (EEG) microstates and Large Language Models (LLMs) to enhance the assessment of cognitive load states. By utilizing EEG microstate features, the research aims to fine-tune LLMs for improved predictions of distinct cognitive states, specifically 'Rest' and 'Load'. The experimental design is delineated in four comprehensive stages: dataset collection and preprocessing, microstate segmentation and EEG backfitting, feature extraction paired with prompt engineering, and meticulous LLM model selection and refinement. Employing a supervised learning paradigm, the LLM is trained to identify cognitive load states based on EEG microstate features integrated into prompts, producing accurate discrimination of cognitive load. A curated dataset, linking EEG features to specified cognitive load conditions, underpins the experimental framework. The results indicate a significant improvement in model performance following the proposed fine-tuning, showcasing the potential of EEG-informed LLMs in cognitive neuroscience and cognitive AI applications. This approach not only contributes to the understanding of brain dynamics but also paves the way for advancements in machine learning techniques applicable to cognitive load and cognitive AI research.", 'abstract_zh': '本研究探讨了脑电图（EEG）微状态与大型语言模型（LLMs）的交集，以增强对认知负荷状态的评估。通过利用EEG微状态特征，研究旨在微调LLMs，以提高对特定认知状态“休息”和“负荷”的预测准确性。实验设计包括四个综合阶段：数据集收集和预处理、微状态分割和EEG反向拟合、特征提取与提示工程，以及细致的LLM模型选择和优化。采用监督学习范式，LLM被训练识别基于整合进提示的EEG微状态特征的认知负荷状态，从而实现对认知负荷的准确区分。一个精心构建的数据集，将EEG特征与特定的认知负荷条件联系起来，构成了实验框架的基础。结果表明，在提出的微调下，模型性能显著提高，展示了EEG指导下的LLMs在认知神经科学和认知人工智能应用中的潜力。该方法不仅有助于理解大脑动态，还为认知负荷和认知人工智能研究中应用机器学习技术的进步铺平了道路。', 'title_zh': '使用EEG微状态特征 fine-tuning 大型语言模型以评估心理负荷'}
{'arxiv_id': 'arXiv:2508.07281', 'title': 'Representation Understanding via Activation Maximization', 'authors': 'Hongbo Zhu, Angelo Cangelosi', 'link': 'https://arxiv.org/abs/2508.07281', 'abstract': 'Understanding internal feature representations of deep neural networks (DNNs) is a fundamental step toward model interpretability. Inspired by neuroscience methods that probe biological neurons using visual stimuli, recent deep learning studies have employed Activation Maximization (AM) to synthesize inputs that elicit strong responses from artificial neurons. In this work, we propose a unified feature visualization framework applicable to both Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs). Unlike prior efforts that predominantly focus on the last output-layer neurons in CNNs, we extend feature visualization to intermediate layers as well, offering deeper insights into the hierarchical structure of learned feature representations. Furthermore, we investigate how activation maximization can be leveraged to generate adversarial examples, revealing potential vulnerabilities and decision boundaries of DNNs. Our experiments demonstrate the effectiveness of our approach in both traditional CNNs and modern ViT, highlighting its generalizability and interpretive value.', 'abstract_zh': '理解深度神经网络（DNNs）的内部特征表示是模型可解释性研究中的一个基本步骤。借鉴神经科学中通过视觉刺激探针生物神经元的方法，最近的深度学习研究采用了激活最大化（AM）来合成能够强烈激活人工神经元的输入。在本工作中，我们提出了一种适用于卷积神经网络（CNNs）和视觉变换器（ViTs）的统一特征可视化框架。不同于以往主要聚焦于CNNs的最后一层神经元的努力，我们将特征可视化扩展到中间层，以提供对学习特征表示层次结构的更深入洞察。此外，我们探讨了如何利用激活最大化生成对抗样本，揭示了DNNs的潜在脆弱性和决策边界。我们的实验表明，该方法在传统的CNNs和现代的ViT中都表现出有效性，突显了其普适性和解释价值。', 'title_zh': '通过激活最大化理解表示'}
{'arxiv_id': 'arXiv:2508.07279', 'title': 'MAQuA: Adaptive Question-Asking for Multidimensional Mental Health Screening using Item Response Theory', 'authors': 'Vasudha Varadarajan, Hui Xu, Rebecca Astrid Boehme, Mariam Marlan Mirstrom, Sverker Sikstrom, H. Andrew Schwartz', 'link': 'https://arxiv.org/abs/2508.07279', 'abstract': 'Recent advances in large language models (LLMs) offer new opportunities for scalable, interactive mental health assessment, but excessive querying by LLMs burdens users and is inefficient for real-world screening across transdiagnostic symptom profiles. We introduce MAQuA, an adaptive question-asking framework for simultaneous, multidimensional mental health screening. Combining multi-outcome modeling on language responses with item response theory (IRT) and factor analysis, MAQuA selects the questions with most informative responses across multiple dimensions at each turn to optimize diagnostic information, improving accuracy and potentially reducing response burden. Empirical results on a novel dataset reveal that MAQuA reduces the number of assessment questions required for score stabilization by 50-87% compared to random ordering (e.g., achieving stable depression scores with 71% fewer questions and eating disorder scores with 85% fewer questions). MAQuA demonstrates robust performance across both internalizing (depression, anxiety) and externalizing (substance use, eating disorder) domains, with early stopping strategies further reducing patient time and burden. These findings position MAQuA as a powerful and efficient tool for scalable, nuanced, and interactive mental health screening, advancing the integration of LLM-based agents into real-world clinical workflows.', 'abstract_zh': '最近大型语言模型的进步为可扩展、交互式的心理健康评估提供了新机遇，但LLMs的过度查询给用户带来了负担，并且在跨诊断症状谱系的实际 screening 中效率低下。我们引入了MAQuA，一种用于同时、多维度心理健康筛查的自适应问题询问框架。通过结合语言响应的多结果建模、项目反应理论（IRT）和因子分析，MAQuA 在每次交互中选择最具信息量的问题来优化诊断信息，从而提高准确性并可能减少响应负担。在新型数据集上的实证结果表明，与随机排序相比，MAQuA 可将评分稳定所需的问题数量减少 50-87%（例如，通过 71% 更少的问题实现稳定的抑郁评分，通过 85% 更少的问题实现稳定的进食障碍评分）。MAQuA 在内化（抑郁、焦虑）和外化（物质使用、进食障碍）领域均表现出稳健性能，并且提前停止策略进一步减少了患者的治疗时间和负担。这些发现将MAQuA 定位为一种强大且高效的工具，用于可扩展、细致和交互式的心理健康筛查，推动基于LLM的代理在临床工作流程中的集成。', 'title_zh': 'MAQuA: 基于项目反应理论的多维度心理健康筛查自适应提问方法'}
{'arxiv_id': 'arXiv:2508.07273', 'title': 'Incorporating Contextual Paralinguistic Understanding in Large Speech-Language Models', 'authors': 'Qiongqiong Wang, Hardik B. Sailor, Jeremy H. M. Wong, Tianchi Liu, Shuo Sun, Wenyu Zhang, Muhammad Huzaifah, Nancy Chen, Ai Ti Aw', 'link': 'https://arxiv.org/abs/2508.07273', 'abstract': 'Current large speech language models (Speech-LLMs) often exhibit limitations in empathetic reasoning, primarily due to the absence of training datasets that integrate both contextual content and paralinguistic cues. In this work, we propose two approaches to incorporate contextual paralinguistic information into model training: (1) an explicit method that provides paralinguistic metadata (e.g., emotion annotations) directly to the LLM, and (2) an implicit method that automatically generates novel training question-answer (QA) pairs using both categorical and dimensional emotion annotations alongside speech transcriptions. Our implicit method boosts performance (LLM-judged) by 38.41% on a human-annotated QA benchmark, reaching 46.02% when combined with the explicit approach, showing effectiveness in contextual paralinguistic understanding. We also validate the LLM judge by demonstrating its correlation with classification metrics, providing support for its reliability.', 'abstract_zh': '当前的大规模语音语言模型（Speech-LLMs）在共情推理方面常常表现出局限性，主要由于缺乏同时集成语境内容和副语言提示的训练数据集。在这项工作中，我们提出两种方法将副语言信息整合进模型训练：（1）一种显式方法，直接向LLM提供副语言元数据（如情绪标注），（2）一种隐式方法，利用类别和维度情绪标注以及语音转录自动生成新的训练问题-答案（QA）对。我们的隐式方法在一个人工标注的QA基准测试中将性能提升38.41%，结合显式方法后达到46.02%，展示了在语境副语言理解方面的有效性。我们还通过验证LLM判据与分类指标的相关性，为其可靠性提供了支持。', 'title_zh': '在大型语音语言模型中整合上下文副语言理解'}
{'arxiv_id': 'arXiv:2508.07270', 'title': 'OpenHAIV: A Framework Towards Practical Open-World Learning', 'authors': 'Xiang Xiang, Qinhao Zhou, Zhuo Xu, Jing Ma, Jiaxin Dai, Yifan Liang, Hanlin Li', 'link': 'https://arxiv.org/abs/2508.07270', 'abstract': 'Substantial progress has been made in various techniques for open-world recognition. Out-of-distribution (OOD) detection methods can effectively distinguish between known and unknown classes in the data, while incremental learning enables continuous model knowledge updates. However, in open-world scenarios, these approaches still face limitations. Relying solely on OOD detection does not facilitate knowledge updates in the model, and incremental fine-tuning typically requires supervised conditions, which significantly deviate from open-world settings. To address these challenges, this paper proposes OpenHAIV, a novel framework that integrates OOD detection, new class discovery, and incremental continual fine-tuning into a unified pipeline. This framework allows models to autonomously acquire and update knowledge in open-world environments. The proposed framework is available at this https URL .', 'abstract_zh': '开放世界识别中的一种新颖框架：结合异常分布检测、新类别发现与增量持续微调', 'title_zh': 'OpenHAIV: 一种迈向实际开放世界学习的框架'}
{'arxiv_id': 'arXiv:2508.07243', 'title': 'Causal Negative Sampling via Diffusion Model for Out-of-Distribution Recommendation', 'authors': 'Chu Zhao, Eneng Yang, Yizhou Dang, Jianzhe Zhao, Guibing Guo, Xingwei Wang', 'link': 'https://arxiv.org/abs/2508.07243', 'abstract': 'Heuristic negative sampling enhances recommendation performance by selecting negative samples of varying hardness levels from predefined candidate pools to guide the model toward learning more accurate decision boundaries. However, our empirical and theoretical analyses reveal that unobserved environmental confounders (e.g., exposure or popularity biases) in candidate pools may cause heuristic sampling methods to introduce false hard negatives (FHNS). These misleading samples can encourage the model to learn spurious correlations induced by such confounders, ultimately compromising its generalization ability under distribution shifts. To address this issue, we propose a novel method named Causal Negative Sampling via Diffusion (CNSDiff). By synthesizing negative samples in the latent space via a conditional diffusion process, CNSDiff avoids the bias introduced by predefined candidate pools and thus reduces the likelihood of generating FHNS. Moreover, it incorporates a causal regularization term to explicitly mitigate the influence of environmental confounders during the negative sampling process, leading to robust negatives that promote out-of-distribution (OOD) generalization. Comprehensive experiments under four representative distribution shift scenarios demonstrate that CNSDiff achieves an average improvement of 13.96% across all evaluation metrics compared to state-of-the-art baselines, verifying its effectiveness and robustness in OOD recommendation tasks.', 'abstract_zh': '基于扩散的因果负采样提升推荐系统的泛化能力', 'title_zh': '基于扩散模型的因果负抽样异类别推荐'}
{'arxiv_id': 'arXiv:2508.07241', 'title': 'SocRipple: A Two-Stage Framework for Cold-Start Video Recommendations', 'authors': 'Amit Jaspal, Kapil Dalwani, Ajantha Ramineni', 'link': 'https://arxiv.org/abs/2508.07241', 'abstract': 'Most industry scale recommender systems face critical cold start challenges new items lack interaction history, making it difficult to distribute them in a personalized manner. Standard collaborative filtering models underperform due to sparse engagement signals, while content only approaches lack user specific relevance. We propose SocRipple, a novel two stage retrieval framework tailored for coldstart item distribution in social graph based platforms. Stage 1 leverages the creators social connections for targeted initial exposure. Stage 2 builds on early engagement signals and stable user embeddings learned from historical interactions to "ripple" outwards via K Nearest Neighbor (KNN) search. Large scale experiments on a major video platform show that SocRipple boosts cold start item distribution by +36% while maintaining user engagement rate on cold start items, effectively balancing new item exposure with personalized recommendations.', 'abstract_zh': '基于社交图的社会冷启动项目分发新型两阶段检索框架 SocRipple', 'title_zh': 'SocRipple: 一种冷启动视频推荐的两阶段框架'}
{'arxiv_id': 'arXiv:2508.07224', 'title': 'EDGE: A Theoretical Framework for Misconception-Aware Adaptive Learning', 'authors': 'Ananda Prakash Verma', 'link': 'https://arxiv.org/abs/2508.07224', 'abstract': 'We present EDGE, a general-purpose, misconception-aware adaptive learning framework composed of four stages: Evaluate (ability and state estimation), Diagnose (posterior infer-ence of misconceptions), Generate (counterfactual item synthesis), and Exercise (index-based retrieval scheduling). EDGE unifies psychometrics (IRT/Bayesian state space models), cog-nitive diagnostics (misconception discovery from distractor patterns and response latencies), contrastive item generation (minimal perturbations that invalidate learner shortcuts while pre-serving psychometric validity), and principled scheduling (a restless bandit approximation to spaced retrieval). We formalize a composite readiness metric, EdgeScore, prove its monotonicity and Lipschitz continuity, and derive an index policy that is near-optimal under mild assumptions on forgetting and learning gains. We further establish conditions under which counterfactual items provably reduce the posterior probability of a targeted misconception faster than standard practice. The paper focuses on theory and implementable pseudocode; empirical study is left to future work.', 'abstract_zh': '我们提出EDGE，一种通用的、错误意识驱动的自适应学习框架，由四个阶段组成：评估（能力与状态估计）、诊断（后验误解推断）、生成（假设场景题目合成）和练习（基于索引的检索调度）。EDGE 统一了心理测量学（IRT/贝叶斯状态空间模型）、认知诊断（从选项模式和反应时发现误解）、对比式题目生成（最小扰动以无效化学习者捷径同时保持心理测量学有效性）和原则性调度（基于兴奋臂赌博机的空间检索近似）。我们形式化了一个综合的准备度指标EdgeScore，证明其单调性和Lipschitz连续性，并推导出在遗忘和学习收益轻微假设下几乎最优的索引策略。我们进一步确定了在这些假设下，假设场景题目在减少目标误解后验概率方面比标准做法更快地发挥作用的条件。本文专注于理论和可实现的伪代码；具体实验留待未来工作。', 'title_zh': 'EDGE: 一种错误观念意识的自适应学习理论框架'}
{'arxiv_id': 'arXiv:2508.07223', 'title': 'Selection and Exploitation of High-Quality Knowledge from Large Language Models for Recommendation', 'authors': 'Guanchen Wang, Mingming Ha, Tianbao Ma, Linxun Chen, Zhaojie Liu, Guorui Zhou, Kun Gai', 'link': 'https://arxiv.org/abs/2508.07223', 'abstract': 'In recent years, there has been growing interest in leveraging the impressive generalization capabilities and reasoning ability of large language models (LLMs) to improve the performance of recommenders. With this operation, recommenders can access and learn the additional world knowledge and reasoning information via LLMs. However, in general, for different users and items, the world knowledge derived from LLMs suffers from issues of hallucination, content redundant, and information homogenization. Directly feeding the generated response embeddings into the recommendation model can lead to unavoidable performance deterioration. To address these challenges, we propose a Knowledge Selection \\& Exploitation Recommendation (KSER) framework, which effectively select and extracts the high-quality knowledge from LLMs. The framework consists of two key components: a knowledge filtering module and a embedding spaces alignment module. In the knowledge filtering module, a Embedding Selection Filter Network (ESFNet) is designed to assign adaptive weights to different knowledge chunks in different knowledge fields. In the space alignment module, an attention-based architecture is proposed to align the semantic embeddings from LLMs with the feature space used to train the recommendation models. In addition, two training strategies--\\textbf{all-parameters training} and \\textbf{extractor-only training}--are proposed to flexibly adapt to different downstream tasks and application scenarios, where the extractor-only training strategy offers a novel perspective on knowledge-augmented recommendation. Experimental results validate the necessity and effectiveness of both the knowledge filtering and alignment modules, and further demonstrate the efficiency and effectiveness of the extractor-only training strategy.', 'abstract_zh': '近年来，人们越来越关注利用大型语言模型（LLMs）的出色泛化能力和推理能力来提升推荐系统的性能。通过这种方法，推荐系统可以访问和学习LLMs提供的额外世界知识和推理信息。然而，通常情况下，对于不同的用户和物品，从LLMs中提取的世界知识会面临幻觉、内容冗余和信息同质化等问题。直接将生成的响应嵌入输入到推荐模型中会导致不可避免的性能退化。为了解决这些问题，我们提出了一种知识选择与利用推荐（KSER）框架，该框架能够有效地从LLMs中选择和提取高质量的知识。该框架由两个关键模块组成：一个知识过滤模块和一个嵌入空间对齐模块。在知识过滤模块中，设计了一个嵌入选择过滤网络（ESFNet）来为不同领域的不同知识片段分配自适应权重。在空间对齐模块中，提出了基于注意力的架构，将LLMs生成的语义嵌入与用于训练推荐模型的功能空间对齐。此外，我们提出了一种训练策略——全参数训练和提取器单独训练，以灵活适应不同的下游任务和应用场景，其中提取器单独训练策略为知识增强推荐提供了一种新的视角。实验结果验证了知识过滤和对齐模块的必要性和有效性，并进一步证明了提取器单独训练策略的高效性和有效性。', 'title_zh': '从大型语言模型中选择和利用高质量知识进行推荐'}
{'arxiv_id': 'arXiv:2508.07221', 'title': 'LLM-based Agents for Automated Confounder Discovery and Subgroup Analysis in Causal Inference', 'authors': 'Po-Han Lee, Yu-Cheng Lin, Chan-Tung Ku, Chan Hsu, Pei-Cing Huang, Ping-Hsun Wu, Yihuang Kang', 'link': 'https://arxiv.org/abs/2508.07221', 'abstract': 'Estimating individualized treatment effects from observational data presents a persistent challenge due to unmeasured confounding and structural bias. Causal Machine Learning (causal ML) methods, such as causal trees and doubly robust estimators, provide tools for estimating conditional average treatment effects. These methods have limited effectiveness in complex real-world environments due to the presence of latent confounders or those described in unstructured formats. Moreover, reliance on domain experts for confounder identification and rule interpretation introduces high annotation cost and scalability concerns. In this work, we proposed Large Language Model-based agents for automated confounder discovery and subgroup analysis that integrate agents into the causal ML pipeline to simulate domain expertise. Our framework systematically performs subgroup identification and confounding structure discovery by leveraging the reasoning capabilities of LLM-based agents, which reduces human dependency while preserving interpretability. Experiments on real-world medical datasets show that our proposed approach enhances treatment effect estimation robustness by narrowing confidence intervals and uncovering unrecognized confounding biases. Our findings suggest that LLM-based agents offer a promising path toward scalable, trustworthy, and semantically aware causal inference.', 'abstract_zh': '从观察\nuser\n请给出中文标题：Estimating individual individualized treatment effects from observational data data on presents based based causal Machine on Learning on learning on LDML on on onMouse on Confidence onConflict onresolution onon subgroup analysis on on on on onon on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on trênオン上上 on on on on on on on on on on on on on on on on.on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on affidable on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on onon on on on on on on_on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on onchemy on onon on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on.onût\nJVW onon on-on onon onon on on on on onon on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on onon on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on onon on on on on on on on on on on on on on on on on CV on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on onon on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on onon on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on onon on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on', 'title_zh': '基于LLM的代理用于因果推断中的混杂因子发现和亚组分析'}
{'arxiv_id': 'arXiv:2508.07220', 'title': 'Neural Bridge Processes', 'authors': 'Jian Xu, Yican Liu, Qibin Zhao, John Paisley, Delu Zeng', 'link': 'https://arxiv.org/abs/2508.07220', 'abstract': 'Learning stochastic functions from partially observed context-target pairs is a fundamental problem in probabilistic modeling. Traditional models like Gaussian Processes (GPs) face scalability issues with large datasets and assume Gaussianity, limiting their applicability. While Neural Processes (NPs) offer more flexibility, they struggle with capturing complex, multi-modal target distributions. Neural Diffusion Processes (NDPs) enhance expressivity through a learned diffusion process but rely solely on conditional signals in the denoising network, resulting in weak input coupling from an unconditional forward process and semantic mismatch at the diffusion endpoint. In this work, we propose Neural Bridge Processes (NBPs), a novel method for modeling stochastic functions where inputs x act as dynamic anchors for the entire diffusion trajectory. By reformulating the forward kernel to explicitly depend on x, NBP enforces a constrained path that strictly terminates at the supervised target. This approach not only provides stronger gradient signals but also guarantees endpoint coherence. We validate NBPs on synthetic data, EEG signal regression and image regression tasks, achieving substantial improvements over baselines. These results underscore the effectiveness of DDPM-style bridge sampling in enhancing both performance and theoretical consistency for structured prediction tasks.', 'abstract_zh': '从部分 序观察的上下文-目标对对中学习随机间连接：一种概率建模中的基本问题 kuk', 'title_zh': '神经桥梁过程'}
{'arxiv_id': 'arXiv:2508.07208', 'title': 'What One Cannot, Two Can: Two-Layer Transformers Provably Represent Induction Heads on Any-Order Markov Chains', 'authors': 'Chanakya Ekbote, Marco Bondaschi, Nived Rajaraman, Jason D. Lee, Michael Gastpar, Ashok Vardhan Makkuva, Paul Pu Liang', 'link': 'https://arxiv.org/abs/2508.07208', 'abstract': 'In-context learning (ICL) is a hallmark capability of transformers, through which trained models learn to adapt to new tasks by leveraging information from the input context. Prior work has shown that ICL emerges in transformers due to the presence of special circuits called induction heads. Given the equivalence between induction heads and conditional k-grams, a recent line of work modeling sequential inputs as Markov processes has revealed the fundamental impact of model depth on its ICL capabilities: while a two-layer transformer can efficiently represent a conditional 1-gram model, its single-layer counterpart cannot solve the task unless it is exponentially large. However, for higher order Markov sources, the best known constructions require at least three layers (each with a single attention head) - leaving open the question: can a two-layer single-head transformer represent any kth-order Markov process? In this paper, we precisely address this and theoretically show that a two-layer transformer with one head per layer can indeed represent any conditional k-gram. Thus, our result provides the tightest known characterization of the interplay between transformer depth and Markov order for ICL. Building on this, we further analyze the learning dynamics of our two-layer construction, focusing on a simplified variant for first-order Markov chains, illustrating how effective in-context representations emerge during training. Together, these results deepen our current understanding of transformer-based ICL and illustrate how even shallow architectures can surprisingly exhibit strong ICL capabilities on structured sequence modeling tasks.', 'abstract_zh': '上下文学习（ICL）是变压器模型的一个标志性能力，通过利用输入上下文中的信息，训练好的模型能够适应新任务。先前的工作表明，ICL 在变压器模型中的出现归因于存在一种称为诱导头的特殊电路。基于诱导头与条件 k- 克拉莫之间的等价性，将序列输入建模为马尔可夫过程的近期研究揭示了模型深度对其 ICL 能力的基本影响：两层变压器可以高效地表示条件 1- 克拉莫模型，而其单层对应模型除非是指数级大小否则无法解决该任务。然而，对于更高阶的马尔可夫来源，已知的最佳构建至少需要三层（每层有一个注意力头）。这个问题仍然悬而未决：两层单头变压器能否表示任意阶马尔可夫过程？在本文中，我们精确地解决了这一问题，并从理论上证明了一层变压器每层有一个头可以表示任意条件 k- 克拉莫。因此，我们的结果提供了对变压器深度与马尔可夫阶数之间交互关系的最紧致描述。在此基础上，我们进一步分析了我们两层结构的学习动态，重点关注一阶马尔可夫链的简化版本，展示了如何在训练过程中生成有效的上下文表示。这些结果加深了我们对基于变压器的 ICL 的当前理解，并表明即使是浅层架构也能在结构化的序列建模任务中表现出强大的 ICL 能力。', 'title_zh': '互补即胜：两层变压器能证明在任何阶马尔科夫链上表示归纳头节点的能力'}
{'arxiv_id': 'arXiv:2508.07207', 'title': 'Presburger Functional Synthesis: Complexity and Tractable Normal Forms', 'authors': 'S. Akshay, A. R. Balasubramanian, Supratik Chakraborty, Georg Zetzsche', 'link': 'https://arxiv.org/abs/2508.07207', 'abstract': 'Given a relational specification between inputs and outputs as a logic formula, the problem of functional synthesis is to automatically synthesize a function from inputs to outputs satisfying the relation. Recently, a rich line of work has emerged tackling this problem for specifications in different theories, from Boolean to general first-order logic. In this paper, we launch an investigation of this problem for the theory of Presburger Arithmetic, that we call Presburger Functional Synthesis (PFnS). We show that PFnS can be solved in EXPTIME and provide a matching exponential lower bound. This is unlike the case for Boolean functional synthesis (BFnS), where only conditional exponential lower bounds are known. Further, we show that PFnS for one input and one output variable is as hard as BFnS in general. We then identify a special normal form, called PSyNF, for the specification formula that guarantees poly-time and poly-size solvability of PFnS. We prove several properties of PSyNF, including how to check and compile to this form, and conditions under which any other form that guarantees poly-time solvability of PFnS can be compiled in poly-time to PSyNF. Finally, we identify a syntactic normal form that is easier to check but is exponentially less succinct than PSyNF.', 'abstract_zh': '预处理算术函数合成（PFnS）', 'title_zh': '帕斯泼列尔函数合成：复杂性和可处理的标准形式'}
{'arxiv_id': 'arXiv:2508.07201', 'title': 'Propagation Tree Is Not Deep: Adaptive Graph Contrastive Learning Approach for Rumor Detection', 'authors': 'Chaoqun Cui, Caiyan Jia', 'link': 'https://arxiv.org/abs/2508.07201', 'abstract': 'Rumor detection on social media has become increasingly important. Most existing graph-based models presume rumor propagation trees (RPTs) have deep structures and learn sequential stance features along branches. However, through statistical analysis on real-world datasets, we find RPTs exhibit wide structures, with most nodes being shallow 1-level replies. To focus learning on intensive substructures, we propose Rumor Adaptive Graph Contrastive Learning (RAGCL) method with adaptive view augmentation guided by node centralities. We summarize three principles for RPT augmentation: 1) exempt root nodes, 2) retain deep reply nodes, 3) preserve lower-level nodes in deep sections. We employ node dropping, attribute masking and edge dropping with probabilities from centrality-based importance scores to generate views. A graph contrastive objective then learns robust rumor representations. Extensive experiments on four benchmark datasets demonstrate RAGCL outperforms state-of-the-art methods. Our work reveals the wide-structure nature of RPTs and contributes an effective graph contrastive learning approach tailored for rumor detection through principled adaptive augmentation. The proposed principles and augmentation techniques can potentially benefit other applications involving tree-structured graphs.', 'abstract_zh': '社交媒体中的谣言检测日益重要。现有的基于图的方法假定谣言传播树具有深层次结构，并沿分支学习立场特征。然而，通过对实际数据集进行统计分析，我们发现谣言传播树往往具有宽层次结构，大多数节点为浅层次的回复。为了集中学习于密集的子结构，我们提出了一种谣言自适应图对比学习（RAGCL）方法，该方法通过节点中心性指导的视图增强进行自适应增强。我们总结了三种谣言传播树增强原则：1) 免除根节点；2) 保留深层次回复节点；3) 在深层部分保留较低层次节点。我们利用基于中心性的重要程度评分概率进行节点删除、属性遮掩和边删除以生成视图，然后通过图对比学习目标学习鲁棒的谣言表示。在四个基准数据集上的广泛实验表明，RAGCL优于现有方法。我们的工作揭示了谣言传播树的宽层次结构，并贡献了一种针对谣言检测的原理性自适应增强的图对比学习方法。提出的增强原则和技术可能对涉及树形结构图的其他应用有益。', 'title_zh': '传播树不深：适应性图对比学习方法在谣言检测中的应用'}
{'arxiv_id': 'arXiv:2508.07196', 'title': 'Can Smaller Large Language Models Evaluate Research Quality?', 'authors': 'Mike Thelwall', 'link': 'https://arxiv.org/abs/2508.07196', 'abstract': "Although both Google Gemini (1.5 Flash) and ChatGPT (4o and 4o-mini) give research quality evaluation scores that correlate positively with expert scores in nearly all fields, and more strongly that citations in most, it is not known whether this is true for smaller Large Language Models (LLMs). In response, this article assesses Google's Gemma-3-27b-it, a downloadable LLM (60Gb). The results for 104,187 articles show that Gemma-3-27b-it scores correlate positively with an expert research quality score proxy for all 34 Units of Assessment (broad fields) from the UK Research Excellence Framework 2021. The Gemma-3-27b-it correlations have 83.8% of the strength of ChatGPT 4o and 94.7% of the strength of ChatGPT 4o-mini correlations. Differently from the two larger LLMs, the Gemma-3-27b-it correlations do not increase substantially when the scores are averaged across five repetitions, its scores tend to be lower, and its reports are relatively uniform in style. Overall, the results show that research quality score estimation can be conducted by offline LLMs, so this capability is not an emergent property of the largest LLMs. Moreover, score improvement through repetition is not a universal feature of LLMs. In conclusion, although the largest LLMs still have the highest research evaluation score estimation capability, smaller ones can also be used for this task, and this can be helpful for cost saving or when secure offline processing is needed.", 'abstract_zh': '尽管Google Gemini（1.5 Flash）和ChatGPT（40和40-mini）在几乎所有领域中都与专家评分正相关，并且通常比大多数引用更能提供研究质量评估分数，但尚不清楚这一特性是否适用于较小的大型语言模型（LLM）。为此，本文评估了可下载的Google Gemma-3-27b-it（60Gb），结果显示，对于英国研究优秀框架2021年的所有34个评估单位（广义领域），Gemma-3-27b-it的评分与专家研究质量评分代理呈正相关。Gemma-3-27b-it的相关性强度为ChatGPT 40的83.8%和ChatGPT 40-mini的94.7%。与两个较大的LLM不同，Gemma-3-27b-it的相关性在五次重复评分的平均值中没有显著增加，其评分通常较低，报告风格相对一致。总体而言，研究结果显示，研究质量评分估计可以通过离线LLM进行，因此这一能力并不限于最大的LLM。此外，评分改进通过重复并不是LLM的普遍特征。结论是，虽然最大的LLM仍然具有最高的研究评估评分估计能力，但较小的LLM也可以用于此任务，这有助于节省成本或在需要安全离线处理时使用。', 'title_zh': '更大的语言模型能评价研究质量吗？'}
{'arxiv_id': 'arXiv:2508.07195', 'title': 'Adapting LLMs to Time Series Forecasting via Temporal Heterogeneity Modeling and Semantic Alignment', 'authors': 'Yanru Sun, Emadeldeen Eldele, Zongxia Xie, Yucheng Wang, Wenzhe Niu, Qinghua Hu, Chee Keong Kwoh, Min Wu', 'link': 'https://arxiv.org/abs/2508.07195', 'abstract': 'Large Language Models (LLMs) have recently demonstrated impressive capabilities in natural language processing due to their strong generalization and sequence modeling capabilities. However, their direct application to time series forecasting remains challenging due to two fundamental issues: the inherent heterogeneity of temporal patterns and the modality gap between continuous numerical signals and discrete language representations. In this work, we propose TALON, a unified framework that enhances LLM-based forecasting by modeling temporal heterogeneity and enforcing semantic alignment. Specifically, we design a Heterogeneous Temporal Encoder that partitions multivariate time series into structurally coherent segments, enabling localized expert modeling across diverse temporal patterns. To bridge the modality gap, we introduce a Semantic Alignment Module that aligns temporal features with LLM-compatible representations, enabling effective integration of time series into language-based models while eliminating the need for handcrafted prompts during inference. Extensive experiments on seven real-world benchmarks demonstrate that TALON achieves superior performance across all datasets, with average MSE improvements of up to 11\\% over recent state-of-the-art methods. These results underscore the effectiveness of incorporating both pattern-aware and semantic-aware designs when adapting LLMs for time series forecasting. The code is available at: this https URL.', 'abstract_zh': '大规模语言模型（LLMs）因具有强大的泛化能力和序列建模能力，在自然语言处理领域展现了令人印象深刻的性能。然而，将其直接应用于时间序列预测依然具有挑战性，主要由于两个根本问题：时间模式的固有异质性和连续数值信号与离散语言表示之间的模态差异。在本文中，我们提出了一种统一框架TALON，通过建模时间异质性和强制语义对齐来增强基于LLM的预测能力。具体地，我们设计了一种异质时间编码器，将多变量时间序列划分为结构上一致的子序列，从而在不同时间模式下实现局部专家建模。为了弥合模态差异，我们引入了一种语义对齐模块，将时间特征与LLM兼容的表示形式对齐，从而有效将时间序列整合到基于语言的模型中，在推理过程中无需手工构建提示。在七个实际基准上的 extensive 实验结果表明，TALON 在所有数据集上均实现了优于最近先进方法的性能，MSE改进幅度平均高达11%。这些结果强调了在将LLM适应于时间序列预测时同时结合模式感知和语义感知设计的有效性。源代码可在以下链接获取：this https URL。', 'title_zh': '通过时间异质性建模和语义对齐适应LLM的时间序列预测'}
{'arxiv_id': 'arXiv:2508.07185', 'title': 'DySK-Attn: A Framework for Efficient, Real-Time Knowledge Updating in Large Language Models via Dynamic Sparse Knowledge Attention', 'authors': 'Kabir Khan, Priya Sharma, Arjun Mehta, Neha Gupta, Ravi Narayanan', 'link': 'https://arxiv.org/abs/2508.07185', 'abstract': 'Large Language Models (LLMs) suffer from a critical limitation: their knowledge is static and quickly becomes outdated. Retraining these massive models is computationally prohibitive, while existing knowledge editing techniques can be slow and may introduce unforeseen side effects. To address this, we propose DySK-Attn, a novel framework that enables LLMs to efficiently integrate real-time knowledge from a dynamic external source. Our approach synergizes an LLM with a dynamic Knowledge Graph (KG) that can be updated instantaneously. The core of our framework is a sparse knowledge attention mechanism, which allows the LLM to perform a coarse-to-fine grained search, efficiently identifying and focusing on a small, highly relevant subset of facts from the vast KG. This mechanism avoids the high computational cost of dense attention over the entire knowledge base and mitigates noise from irrelevant information. We demonstrate through extensive experiments on time-sensitive question-answering tasks that DySK-Attn significantly outperforms strong baselines, including standard Retrieval-Augmented Generation (RAG) and model editing techniques, in both factual accuracy for updated knowledge and computational efficiency. Our framework offers a scalable and effective solution for building LLMs that can stay current with the ever-changing world.', 'abstract_zh': 'DySK-Attn: 一种使大规模语言模型高效集成实时动态知识的新框架', 'title_zh': 'DySK-Attn：一种通过动态稀疏知识注意力高效实时更新大型语言模型知识的框架'}
{'arxiv_id': 'arXiv:2508.07183', 'title': 'Explainability-in-Action: Enabling Expressive Manipulation and Tacit Understanding by Bending Diffusion Models in ComfyUI', 'authors': 'Ahmed M. Abuzuraiq, Philippe Pasquier', 'link': 'https://arxiv.org/abs/2508.07183', 'abstract': 'Explainable AI (XAI) in creative contexts can go beyond transparency to support artistic engagement, modifiability, and sustained practice. While curated datasets and training human-scale models can offer artists greater agency and control, large-scale generative models like text-to-image diffusion systems often obscure these possibilities. We suggest that even large models can be treated as creative materials if their internal structure is exposed and manipulable. We propose a craft-based approach to explainability rooted in long-term, hands-on engagement akin to Schön\'s "reflection-in-action" and demonstrate its application through a model-bending and inspection plugin integrated into the node-based interface of ComfyUI. We demonstrate that by interactively manipulating different parts of a generative model, artists can develop an intuition about how each component influences the output.', 'abstract_zh': '可解释的人工智能（XAI）在创意背景下不仅可以超越透明性，还可以支持艺术参与、可修改性和持续实践。即使大型模型在其内部结构被暴露和可操作的情况下，也可以视为创意材料。我们提出了一种基于长期手头互动的工艺导向解释方法，类似于舍恩的“行动中的反思”，并通过将模型扭曲和检查插件整合到ComfyUI的节点界面中来展示其应用。我们证明，通过交互式地操作生成模型的不同部分，艺术家可以发展出对每个组件如何影响输出的直觉。', 'title_zh': '解释在行动：通过在ComfyUI中弯曲扩散模型实现表达性操控和隐性理解'}
{'arxiv_id': 'arXiv:2508.07180', 'title': 'Dynamic Benchmark Construction for Evaluating Large Language Models on Real-World Codes', 'authors': 'Zhe Zhang, Runlin Liu, Aishan Liu, Xingyu Liu, Xiang Gao, Hailong Sun', 'link': 'https://arxiv.org/abs/2508.07180', 'abstract': 'As large language models LLMs) become increasingly integrated into software development workflows, rigorously evaluating their performance on complex, real-world code generation tasks has become essential. However, existing benchmarks often suffer from data contamination and limited test rigor, constraining their ability to reveal model failures effectively. To address these, we present CODE2BENCH, a end-to-end pipeline for dynamically constructing robust and contamination-resistant benchmarks from real-world GitHub repositories. Specifically, CODE2BENCH introduces three key innovations: (1) Automated Dynamism, achieved through periodic ingestion of recent code to minimize training data contamination; (2) Scope Graph-based dependency analysis, which enables structured classification of functions into benchmark instances with controlled dependency levels (distinguishing between Self-Contained (SC) tasks for cross-language evaluation and Weakly Self-Contained (WSC) tasks involving permitted library usage); and (3) Property-Based Testing (PBT) for the automated synthesis of rigorous test suites to enable thorough functional verification. Using this pipeline, we construct CODE2BENCH-2505, the first benchmark derived from 880 recent Python projects spanning diverse domains, comprising 1,163 code generation tasks with 100% average branch coverage on ground-truth implementations. Extensive evaluation of 16 LLMs using CODE2BENCH-2505 reveals that models consistently struggle with SC tasks requiring complex, non-standard logic and cross-language transfer, while showing relatively stronger performance on WSC tasks in Python. Our work introduces a contamination-resistant, language-agnostic methodology for dynamic benchmark construction, offering a principled foundation for the comprehensive and realistic evaluation of LLMs on real-world software development tasks.', 'abstract_zh': '随着大型语言模型（LLMs） increasingly 集成到软件开发工作流中，严格评估其在复杂的真实世界代码生成任务中的性能变得至关重要。然而，现有的基准数据往往存在数据污染和测试不严格的问题，限制了其有效揭示模型失败的能力。为了解决这些问题，我们提出了 CODE2BENCH，一个端到端的动态构建稳健且抗污染基准数据集的管道，源自真实的 GitHub 仓库。具体来说，CODE2BENCH 引入了三项关键创新：（1）自动动态性，通过定期获取最新的代码来最小化训练数据污染；（2）基于范围图的依赖分析，使函数能够结构化分类为具有可控依赖级别的基准实例（区分自我封闭（SC）任务用于跨语言评估和弱自我封闭（WSC）任务涉及允许的库使用）；以及（3）基于属性的测试（PBT），用于自动合成严格的测试套件，以实现彻底的功能验证。使用此管道，我们构建了 CODE2BENCH-2505，这是首个源自 880 个近期 Python 项目的基准数据集，涵盖了多个领域，包含 1,163 个代码生成任务，平均分支覆盖率为 100%。使用 CODE2BENCH-2505 对 16 个 LLM 进行广泛评估显示，模型在要求复杂非标准逻辑和跨语言转移的 SC 任务中表现一致不佳，而在 Python 中的 WSC 任务中表现出相对较优的性能。我们的工作引入了一种抗污染、语言无关的动态基准构建方法，为全面和现实地评估 LLM 在实际软件开发任务中的能力提供了原则性基础。', 'title_zh': '实时代码场景下大型语言模型评估的动态基准构建'}
{'arxiv_id': 'arXiv:2508.07179', 'title': 'Schema Lineage Extraction at Scale: Multilingual Pipelines, Composite Evaluation, and Language-Model Benchmarks', 'authors': 'Jiaqi Yin, Yi-Wei Chen, Meng-Lung Lee, Xiya Liu', 'link': 'https://arxiv.org/abs/2508.07179', 'abstract': 'Enterprise data pipelines, characterized by complex transformations across multiple programming languages, often cause a semantic disconnect between original metadata and downstream data. This "semantic drift" compromises data reproducibility and governance, and impairs the utility of services like retrieval-augmented generation (RAG) and text-to-SQL systems. To address this, a novel framework is proposed for the automated extraction of fine-grained schema lineage from multilingual enterprise pipeline scripts. This method identifies four key components: source schemas, source tables, transformation logic, and aggregation operations, creating a standardized representation of data transformations. For the rigorous evaluation of lineage quality, this paper introduces the Schema Lineage Composite Evaluation (SLiCE), a metric that assesses both structural correctness and semantic fidelity. A new benchmark is also presented, comprising 1,700 manually annotated lineages from real-world industrial scripts. Experiments were conducted with 12 language models, from 1.3B to 32B small language models (SLMs) to large language models (LLMs) like GPT-4o and GPT-4.1. The results demonstrate that the performance of schema lineage extraction scales with model size and the sophistication of prompting techniques. Specially, a 32B open-source model, using a single reasoning trace, can achieve performance comparable to the GPT series under standard prompting. This finding suggests a scalable and economical approach for deploying schema-aware agents in practical applications.', 'abstract_zh': '一种新型框架：自动提取多语言企业数据管道的细粒度模式谱系以解决语义漂移问题', 'title_zh': '大规模模式血缘提取：多语言管道、复合评估和语言模型基准'}
{'arxiv_id': 'arXiv:2508.07178', 'title': 'Improved Personalized Headline Generation via Denoising Fake Interests from Implicit Feedback', 'authors': 'Kejin Liu, Junhong Lian, Xiang Ao, Ningtao Wang, Xing Fu, Yu Cheng, Weiqiang Wang, Xinyu Liu', 'link': 'https://arxiv.org/abs/2508.07178', 'abstract': "Accurate personalized headline generation hinges on precisely capturing user interests from historical behaviors. However, existing methods neglect personalized-irrelevant click noise in entire historical clickstreams, which may lead to hallucinated headlines that deviate from genuine user preferences. In this paper, we reveal the detrimental impact of click noise on personalized generation quality through rigorous analysis in both user and news dimensions. Based on these insights, we propose a novel Personalized Headline Generation framework via Denoising Fake Interests from Implicit Feedback (PHG-DIF). PHG-DIF first employs dual-stage filtering to effectively remove clickstream noise, identified by short dwell times and abnormal click bursts, and then leverages multi-level temporal fusion to dynamically model users' evolving and multi-faceted interests for precise profiling. Moreover, we release DT-PENS, a new benchmark dataset comprising the click behavior of 1,000 carefully curated users and nearly 10,000 annotated personalized headlines with historical dwell time annotations. Extensive experiments demonstrate that PHG-DIF substantially mitigates the adverse effects of click noise and significantly improves headline quality, achieving state-of-the-art (SOTA) results on DT-PENS. Our framework implementation and dataset are available at this https URL.", 'abstract_zh': '精确个性化头条生成依赖于精准捕捉用户历史行为中的兴趣。现有方法忽视了整个历史点击流中的个性化无关点击噪声，这可能导致生成的头条与真实用户偏好相偏离。本文通过在用户和新闻维度上的严格分析揭示了点击噪声对个性化生成质量的负面影响。基于这些见解，我们提出了一种新颖的去噪框架PHG-DIF，通过稀释隐式反馈中虚假兴趣来进行个性化头条生成。PHG-DIF首先采用两阶段过滤有效地去除由短停留时间和异常点击突发识别的点击流噪声，然后利用多层时间融合动态建模用户的演进和多维兴趣，以实现精确的用户画像。此外，我们发布了DT-PENS基准数据集，包含1000个精心筛选用户的行为点击和近10,000个标注的个性化头条，历史停留时间也进行了标注。广泛实验表明，PHG-DIF显著减轻了点击噪声的负面影响，显著提高了头条的质量，并在DT-PENS上达到了当前最佳性能。我们的框架实现和数据集可在以下链接获取：这个 https URL。', 'title_zh': '基于隐式反馈去噪虚假兴趣的个性化标题生成改进方法'}
{'arxiv_id': 'arXiv:2508.07170', 'title': 'Lightweight Multi-Scale Feature Extraction with Fully Connected LMF Layer for Salient Object Detection', 'authors': 'Yunpeng Shi, Lei Chen, Xiaolu Shen, Yanju Guo', 'link': 'https://arxiv.org/abs/2508.07170', 'abstract': 'In the domain of computer vision, multi-scale feature extraction is vital for tasks such as salient object detection. However, achieving this capability in lightweight networks remains challenging due to the trade-off between efficiency and performance. This paper proposes a novel lightweight multi-scale feature extraction layer, termed the LMF layer, which employs depthwise separable dilated convolutions in a fully connected structure. By integrating multiple LMF layers, we develop LMFNet, a lightweight network tailored for salient object detection. Our approach significantly reduces the number of parameters while maintaining competitive performance. Here, we show that LMFNet achieves state-of-the-art or comparable results on five benchmark datasets with only 0.81M parameters, outperforming several traditional and lightweight models in terms of both efficiency and accuracy. Our work not only addresses the challenge of multi-scale learning in lightweight networks but also demonstrates the potential for broader applications in image processing tasks. The related code files are available at this https URL', 'abstract_zh': '在计算机视觉领域，多尺度特征提取是重要的，对于显著目标检测等任务尤为关键。然而，由于效率与性能之间的权衡，在轻量级网络中实现这一能力仍然具有挑战性。本文提出了一种新颖的轻量级多尺度特征提取层，称为LMF层，该层采用全连接结构中的深度可分离空洞卷积。通过整合多个LMF层，我们开发了LMFNet，这是一种专门为显著目标检测设计的轻量级网络。我们的方法在显著减少参数数量的同时，仍能保持竞争力。结果显示，LMFNet在五个基准数据集上仅使用0.81M参数达到了最先进的或可比拟的结果，并在效率和准确性方面优于多种传统和轻量级模型。我们的工作不仅解决了轻量级网络中的多尺度学习挑战，还展示了其在图像处理任务中的广泛应用潜力。相关代码文件可在以下链接获取：this https URL。', 'title_zh': '轻量级多尺度特征提取的全连接LMF层在显著目标检测中的应用'}
{'arxiv_id': 'arXiv:2508.07165', 'title': 'Large-scale Multi-sequence Pretraining for Generalizable MRI Analysis in Versatile Clinical Applications', 'authors': 'Zelin Qiu, Xi Wang, Zhuoyao Xie, Juan Zhou, Yu Wang, Lingjie Yang, Xinrui Jiang, Juyoung Bae, Moo Hyun Son, Qiang Ye, Dexuan Chen, Rui Zhang, Tao Li, Neeraj Ramesh Mahboobani, Varut Vardhanabhuti, Xiaohui Duan, Yinghua Zhao, Hao Chen', 'link': 'https://arxiv.org/abs/2508.07165', 'abstract': 'Multi-sequence Magnetic Resonance Imaging (MRI) offers remarkable versatility, enabling the distinct visualization of different tissue types. Nevertheless, the inherent heterogeneity among MRI sequences poses significant challenges to the generalization capability of deep learning models. These challenges undermine model performance when faced with varying acquisition parameters, thereby severely restricting their clinical utility. In this study, we present PRISM, a foundation model PRe-trained with large-scale multI-Sequence MRI. We collected a total of 64 datasets from both public and private sources, encompassing a wide range of whole-body anatomical structures, with scans spanning diverse MRI sequences. Among them, 336,476 volumetric MRI scans from 34 datasets (8 public and 26 private) were curated to construct the largest multi-organ multi-sequence MRI pretraining corpus to date. We propose a novel pretraining paradigm that disentangles anatomically invariant features from sequence-specific variations in MRI, while preserving high-level semantic representations. We established a benchmark comprising 44 downstream tasks, including disease diagnosis, image segmentation, registration, progression prediction, and report generation. These tasks were evaluated on 32 public datasets and 5 private cohorts. PRISM consistently outperformed both non-pretrained models and existing foundation models, achieving first-rank results in 39 out of 44 downstream benchmarks with statistical significance improvements. These results underscore its ability to learn robust and generalizable representations across unseen data acquired under diverse MRI protocols. PRISM provides a scalable framework for multi-sequence MRI analysis, thereby enhancing the translational potential of AI in radiology. It delivers consistent performance across diverse imaging protocols, reinforcing its clinical applicability.', 'abstract_zh': '多序列磁共振成像（MRI提供的非凡灵活性使得不同组织类型的独特可视化成为可能。然而，MRI序列固有的异质性给深度学习模型的一般性能带来了显著挑战。这些挑战在面对不同的同时性能表现上削弱了模型，进而严重限制了其临床应用价值。在本文中，我们提出了PRISM，一种大规模多序列MRI预训练的基础模型。我们总共收集了64个数据集，涵盖了广泛的解剖结构，并跨越了不同的MRI序列。其中，34个数据集中包含3,4476个三维MRI扫描（8个公共数据集和26个私人有数据集），我们构建了迄今最大的的多器官多序列MRI训练数据集。我们提出了一种新的预训练范式，将MRI中的解剖不变特征从特定特征中分离出来 保持高层次语义表示。我们建立了一个基准 包含44个下游任务 其中包括疾病诊断 图像分割 注册 痖症预测 和生成。这些任务在3个公共数据集和 11 个私人组群上上e上 评估中 显示出PRISM始终优于预训练模型和 现有基础模型 在44个下游基准中的3个中获得了显着的排名第一。这些结果显示了其在不同未知的情况下对 跨越不同的MRI协议下保持鲁棒性和可扩展性表示的能力。PRISM提供了一个可序列MRI分析的可伸缩框架 从而增强了人工智能在放射学中的转化潜力。PRISM在不同的图像协议中提供了持续的性能 从而加强了其实临床上的应用可行性。', 'title_zh': '大规模多序列预训练在多样化临床应用中的通用MRI分析'}
{'arxiv_id': 'arXiv:2508.07163', 'title': 'Integrating Neurosymbolic AI in Advanced Air Mobility: A Comprehensive Survey', 'authors': 'Kamal Acharya, Iman Sharifi, Mehul Lad, Liang Sun, Houbing Song', 'link': 'https://arxiv.org/abs/2508.07163', 'abstract': "Neurosymbolic AI combines neural network adaptability with symbolic reasoning, promising an approach to address the complex regulatory, operational, and safety challenges in Advanced Air Mobility (AAM). This survey reviews its applications across key AAM domains such as demand forecasting, aircraft design, and real-time air traffic management. Our analysis reveals a fragmented research landscape where methodologies, including Neurosymbolic Reinforcement Learning, have shown potential for dynamic optimization but still face hurdles in scalability, robustness, and compliance with aviation standards. We classify current advancements, present relevant case studies, and outline future research directions aimed at integrating these approaches into reliable, transparent AAM systems. By linking advanced AI techniques with AAM's operational demands, this work provides a concise roadmap for researchers and practitioners developing next-generation air mobility solutions.", 'abstract_zh': '神经符号AI结合了神经网络的适应性和符号推理，为高级空中 mobility (AAM) 中复杂的监管、运营和安全挑战提供了有希望的应对方法。本文综述了其在关键AAM领域（如需求预测、航空器设计和实时空中交通管理）的应用。我们的分析揭示了一个碎片化的研究景观，在该景观中，包括神经符号强化学习在内的方法显示了动态优化的潜力，但仍面临可扩展性、稳健性和符合航空标准的问题。本文分类了当前的进展，呈现了相关案例研究，并概述了未来的研发方向，旨在将这些方法整合到可靠的、透明的AAM系统中。通过将先进的AI技术与AAM的运营需求相结合，本文为开发下一代空中移动解决方案的研究人员和实践者提供了一条精炼的研究路线图。', 'title_zh': '将神经符号AI集成到先进空中交通中：综述研究'}
{'arxiv_id': 'arXiv:2508.07146', 'title': 'Intention-Aware Diffusion Model for Pedestrian Trajectory Prediction', 'authors': 'Yu Liu, Zhijie Liu, Xiao Ren, You-Fu Li, He Kong', 'link': 'https://arxiv.org/abs/2508.07146', 'abstract': 'Predicting pedestrian motion trajectories is critical for the path planning and motion control of autonomous vehicles. Recent diffusion-based models have shown promising results in capturing the inherent stochasticity of pedestrian behavior for trajectory prediction. However, the absence of explicit semantic modelling of pedestrian intent in many diffusion-based methods may result in misinterpreted behaviors and reduced prediction accuracy. To address the above challenges, we propose a diffusion-based pedestrian trajectory prediction framework that incorporates both short-term and long-term motion intentions. Short-term intent is modelled using a residual polar representation, which decouples direction and magnitude to capture fine-grained local motion patterns. Long-term intent is estimated through a learnable, token-based endpoint predictor that generates multiple candidate goals with associated probabilities, enabling multimodal and context-aware intention modelling. Furthermore, we enhance the diffusion process by incorporating adaptive guidance and a residual noise predictor that dynamically refines denoising accuracy. The proposed framework is evaluated on the widely used ETH, UCY, and SDD benchmarks, demonstrating competitive results against state-of-the-art methods.', 'abstract_zh': '基于扩散模型的人行轨迹预测对于自主车辆的路径规划和运动控制至关重要。近期的扩散模型在捕捉人行行为的内在随机性方面表现出有希望的结果。然而，许多扩散模型中缺乏显式的行人意图语义建模可能导致行为误解读和预测准确度降低。为了解决上述挑战，我们提出了一种结合短期和长期运动意图的基于扩散的人行轨迹预测框架。短期意图通过残差极坐标表示建模，以解耦方向和大小来捕捉精细的局部运动模式。长期意图通过可学习的基于令牌的目标端点预测器估计，生成具有关联概率的多个候选目标，从而实现多模态和上下文感知的意图建模。此外，我们通过引入自适应引导和残差噪声预测器增强扩散过程，动态提高去噪准确性。所提出的框架在广泛使用的ETH、UCY和SDD基准上进行评估，显示出与最新方法竞争的性能。', 'title_zh': '意图意识驱动的行人轨迹预测扩散模型'}
{'arxiv_id': 'arXiv:2508.07143', 'title': 'Fairness of Automatic Speech Recognition: Looking Through a Philosophical Lens', 'authors': 'Anna Seo Gyeong Choi, Hoon Choi', 'link': 'https://arxiv.org/abs/2508.07143', 'abstract': 'Automatic Speech Recognition (ASR) systems now mediate countless human-technology interactions, yet research on their fairness implications remains surprisingly limited. This paper examines ASR bias through a philosophical lens, arguing that systematic misrecognition of certain speech varieties constitutes more than a technical limitation -- it represents a form of disrespect that compounds historical injustices against marginalized linguistic communities. We distinguish between morally neutral classification (discriminate1) and harmful discrimination (discriminate2), demonstrating how ASR systems can inadvertently transform the former into the latter when they consistently misrecognize non-standard dialects. We identify three unique ethical dimensions of speech technologies that differentiate ASR bias from other algorithmic fairness concerns: the temporal burden placed on speakers of non-standard varieties ("temporal taxation"), the disruption of conversational flow when systems misrecognize speech, and the fundamental connection between speech patterns and personal/cultural identity. These factors create asymmetric power relationships that existing technical fairness metrics fail to capture. The paper analyzes the tension between linguistic standardization and pluralism in ASR development, arguing that current approaches often embed and reinforce problematic language ideologies. We conclude that addressing ASR bias requires more than technical interventions; it demands recognition of diverse speech varieties as legitimate forms of expression worthy of technological accommodation. This philosophical reframing offers new pathways for developing ASR systems that respect linguistic diversity and speaker autonomy.', 'abstract_zh': 'Automatic Speech Recognition系统的公平性哲学审视：超越技术局限性的偏见分析', 'title_zh': '自动语音识别的公平性：透过哲学视角考察'}
{'arxiv_id': 'arXiv:2508.07142', 'title': 'SGD Convergence under Stepsize Shrinkage in Low-Precision Training', 'authors': 'Vincent-Daniel Yun', 'link': 'https://arxiv.org/abs/2508.07142', 'abstract': 'Low-precision training has become essential for reducing the computational and memory costs of large-scale deep learning. However, quantization of gradients introduces both magnitude shrinkage and additive noise, which can alter the convergence behavior of stochastic gradient descent (SGD). In this work, we study the convergence of SGD under a gradient shrinkage model, where each stochastic gradient is scaled by a factor $q_k \\in (0,1]$ and perturbed by zero-mean quantization noise. We show that this shrinkage is equivalent to replacing the nominal stepsize $\\mu_k$ with an effective stepsize $\\mu_k q_k$, which slows convergence when $q_{\\min} < 1$. Under standard smoothness and bounded-variance assumptions, we prove that low-precision SGD still converges, but at a reduced rate determined by $q_{\\min}$, and with an increased asymptotic error floor due to quantization noise. We theoretically analyze how reduced numerical precision slows down training by modeling it as gradient shrinkage in the standard SGD convergence framework.', 'abstract_zh': '低精度训练已成为降低大规模深度学习计算和内存成本的 essentials。然而，梯度量化会导致幅度收缩和加性噪声，从而改变随机梯度下降 (SGD) 的收敛行为。在本文中，我们研究在梯度收缩模型下的 SGD 收敛性，其中每个随机梯度由因子 $q_k \\in (0,1]$ 缩放，并受零均值量化噪声扰动。我们证明这种收缩等效于用有效步长 $\\mu_k q_k$ 替换名义步长 $\\mu_k$，当 $q_{\\min} < 1$ 时会减慢收敛。在标准平滑性和有界方差假设下，我们证明低精度 SGD 仍然收敛，但收敛速率由 $q_{\\min}$ 确定，并且由于量化噪声导致的渐近误差地板增加。我们通过将减少的数值精度建模为标准 SGD 收敛框架中的梯度收缩来理论上分析其如何减慢训练。', 'title_zh': 'SGD收敛性研究：在低精度训练中的步长收缩'}
{'arxiv_id': 'arXiv:2508.07139', 'title': 'A Real-Time, Self-Tuning Moderator Framework for Adversarial Prompt Detection', 'authors': 'Ivan Zhang', 'link': 'https://arxiv.org/abs/2508.07139', 'abstract': "Ensuring LLM alignment is critical to information security as AI models become increasingly widespread and integrated in society. Unfortunately, many defenses against adversarial attacks and jailbreaking on LLMs cannot adapt quickly to new attacks, degrade model responses to benign prompts, or introduce significant barriers to scalable implementation. To mitigate these challenges, we introduce a real-time, self-tuning (RTST) moderator framework to defend against adversarial attacks while maintaining a lightweight training footprint. We empirically evaluate its effectiveness using Google's Gemini models against modern, effective jailbreaks. Our results demonstrate the advantages of an adaptive, minimally intrusive framework for jailbreak defense over traditional fine-tuning or classifier models.", 'abstract_zh': '确保大型语言模型的对齐是信息安全管理的关键，随着AI模型在社会中的广泛应用和整合。不幸的是，许多针对大型语言模型的对抗攻击和 jailbreaking 的防御措施无法迅速适应新的攻击，会降低模型对良性提示的响应，或引入大规模实施的重大障碍。为应对这些挑战，我们提出了一种实时自调谐（RTST）调节器框架，以在保持轻量级训练足迹的同时抵御对抗攻击。我们使用谷歌的Gemini模型和现代有效的jailbreak进行实证评估，结果表明，自适应且侵入性最小的防御框架在jailbreak防御方面的优势优于传统的微调或分类器模型。', 'title_zh': '面向对抗提示检测的实时自调谐主持人框架'}
{'arxiv_id': 'arXiv:2508.07137', 'title': 'A Stable and Principled Loss Function for Direct Language Model Alignment', 'authors': 'Yuandong Tan', 'link': 'https://arxiv.org/abs/2508.07137', 'abstract': 'The alignment of large language models (LLMs) with human preferences is commonly achieved through Reinforcement Learning from Human Feedback (RLHF). Direct Preference Optimization (DPO) simplified this paradigm by establishing a direct mapping between the optimal policy and a reward function, eliminating the need for an explicit reward model. However, we argue that the DPO loss function is theoretically misaligned with its own derivation, as it promotes the indefinite maximization of a logits difference, which can lead to training instability and reward hacking. In this paper, we propose a novel loss function derived directly from the RLHF optimality condition. Our proposed loss targets a specific, finite value for the logits difference, which is dictated by the underlying reward, rather than its maximization. We provide a theoretical analysis, including a gradient-based comparison, to demonstrate that our method avoids the large gradients that plague DPO when the probability of dispreferred responses approaches zero. This inherent stability prevents reward hacking and leads to more effective alignment. We validate our approach by fine-tuning a Qwen2.5-7B model, showing significant win-rate improvements over a standard DPO baseline and achieving competitive performance against larger models like Llama-3.1-8B.', 'abstract_zh': '大型语言模型与人类偏好对齐的直接偏好优化方法存在理论上的偏差，导致训练不稳定和奖励捷径问题：一种源自人类反馈强化学习优化条件的新损失函数', 'title_zh': '一种稳定且原理上的损失函数，用于直接的语言模型对齐'}
{'arxiv_id': 'arXiv:2508.07132', 'title': '"Draw me a curator" Examining the visual stereotyping of a cultural services profession by generative AI', 'authors': 'Dirk HR Spennemann', 'link': 'https://arxiv.org/abs/2508.07132', 'abstract': 'Based on 230 visualisations, this paper examines the depiction of museum curators by the popular generative Artificial Intelligence (AI) model, ChatGPT4o. While the AI-generated representations do not reiterate popular stereotypes of curators as nerdy, conservative in dress and stuck in time rummaging through collections, they contrast sharply with real-world demographics. AI-generated imagery extremely underrepresents women (3.5% vs 49% to 72% in reality) and disregards ethnic communities other than Caucasian (0% vs 18% to 36%). It only over-represents young curators (79% vs approx. 27%) but also renders curators to resemble yuppie professionals or people featuring in fashion advertising. Stereotypical attributes are prevalent, with curators widely depicted as wearing beards and holding clipboards or digital tablets. The findings highlight biases in the generative AI image creation dataset, which is poised to shape an inaccurate portrayal of museum professionals if the images were to be taken uncritically at face value.', 'abstract_zh': '基于230幅可视化图像，本文考察了流行生成人工智能（AI）模型ChatGPT4对其馆长形象的描绘。虽然AI生成的图像并未重复将馆长描绘为书呆子、穿着保守且沉迷于过往收藏的刻板印象，它们与现实世界的人口统计学特征相比却存在显著差异。AI生成的图像严重低估了女性的比例（3.5%对比现实中的49%至72%），忽略了除白人之外的其他族裔群体（0%对比现实中的18%至36%）。同时，过于夸大了年轻馆长的比例（79%对比约27%），且使馆长形象显得像是中产阶级专业人士或时尚广告模特。图像中馆长的典型特征被广泛描绘，包括蓄有胡子、手持 clipboard 或数字平板电脑。研究结果揭示了生成AI图像数据集中的偏见，若这些图像被无批判地接受，将可能导致对博物馆专业人员的不准确描述。', 'title_zh': '“画一个策展人”：探讨生成式AI对文化服务职业的视觉刻板印象'}
{'arxiv_id': 'arXiv:2508.07129', 'title': 'Toward AI Matching Policies in Homeless Services: A Qualitative Study with Policymakers', 'authors': 'Caroline M. Johnston, Olga Koumoundouros, Angel Hsing-Chi Hwang, Laura Onasch-Vera, Eric Rice, Phebe Vayanos', 'link': 'https://arxiv.org/abs/2508.07129', 'abstract': 'Artificial intelligence researchers have proposed various data-driven algorithms to improve the processes that match individuals experiencing homelessness to scarce housing resources. It remains unclear whether and how these algorithms are received or adopted by practitioners and what their corresponding consequences are. Through semi-structured interviews with 13 policymakers in homeless services in Los Angeles, we investigate whether such change-makers are open to the idea of integrating AI into the housing resource matching process, identifying where they see potential gains and drawbacks from such a system in issues of efficiency, fairness, and transparency. Our qualitative analysis indicates that, even when aware of various complicating factors, policymakers welcome the idea of an AI matching tool if thoughtfully designed and used in tandem with human decision-makers. Though there is no consensus as to the exact design of such an AI system, insights from policymakers raise open questions and design considerations that can be enlightening for future researchers and practitioners who aim to build responsible algorithmic systems to support decision-making in low-resource scenarios.', 'abstract_zh': '人工智能研究人员提出了多种数据驱动算法，以改进将无家可归者与稀缺住房资源匹配的过程。尚不清楚这些算法是否被实践者接受以及采用情况如何，它们所带来的相应后果又是什么。通过半结构化访谈13名洛杉矶无家可归服务领域的政策制定者，我们调查这些变革者是否愿意将AI整合到住房资源匹配过程中，识别他们在效率、公平性和透明度方面看到的潜在利弊。我们的定性分析表明，即使意识到各种复杂因素，如果AI匹配工具设计周到并与其他决策者共同使用，政策制定者仍然欢迎这一想法。虽然关于此类AI系统的具体设计尚未达成共识，但政策制定者的见解提出了对未来致力于在资源匮乏场景下构建负责任算法系统的研究者和实践者具有启发意义的开放问题和设计考虑。', 'title_zh': '面向无家可归服务领域的AI匹配政策：一项对政策制定者的定性研究'}
{'arxiv_id': 'arXiv:2508.07128', 'title': 'Perceptual Evaluation of GANs and Diffusion Models for Generating X-rays', 'authors': 'Gregory Schuit, Denis Parra, Cecilia Besa', 'link': 'https://arxiv.org/abs/2508.07128', 'abstract': 'Generative image models have achieved remarkable progress in both natural and medical imaging. In the medical context, these techniques offer a potential solution to data scarcity-especially for low-prevalence anomalies that impair the performance of AI-driven diagnostic and segmentation tools. However, questions remain regarding the fidelity and clinical utility of synthetic images, since poor generation quality can undermine model generalizability and trust. In this study, we evaluate the effectiveness of state-of-the-art generative models-Generative Adversarial Networks (GANs) and Diffusion Models (DMs)-for synthesizing chest X-rays conditioned on four abnormalities: Atelectasis (AT), Lung Opacity (LO), Pleural Effusion (PE), and Enlarged Cardiac Silhouette (ECS). Using a benchmark composed of real images from the MIMIC-CXR dataset and synthetic images from both GANs and DMs, we conducted a reader study with three radiologists of varied experience. Participants were asked to distinguish real from synthetic images and assess the consistency between visual features and the target abnormality. Our results show that while DMs generate more visually realistic images overall, GANs can report better accuracy for specific conditions, such as absence of ECS. We further identify visual cues radiologists use to detect synthetic images, offering insights into the perceptual gaps in current models. These findings underscore the complementary strengths of GANs and DMs and point to the need for further refinement to ensure generative models can reliably augment training datasets for AI diagnostic systems.', 'abstract_zh': 'Generative图像模型在自然图像和医学影像领域均取得了显著进展。在医学领域，这些技术为解决数据稀缺问题提供了潜在解决方案，特别是对于影响基于AI的诊断和分割工具性能的低频异常。然而，合成图像的真实性和临床效用仍存在问题，因为生成质量差可能削弱模型的泛化能力和信任度。在这项研究中，我们评估了当前最先进的生成模型—生成对抗网络（GANs）和扩散模型（DMs）—在合成基于四种异常条件的胸部X光片方面的有效性：肺不张（AT）、肺-opacity（LO）、胸腔积液（PE）和心影增大（ECS）。我们使用MIMIC-CXR数据集中的真实图像和GANs、DMs生成的合成图像作为基准，进行了包括三位经验不同的放射科医生在内的读者研究。参与者被要求区分真实图像和合成图像，并评估视觉特征与目标异常的一致性。结果显示，尽管DMs整体生成更具有视觉真实感的图像，但在某些条件下（如心影增大的不存在），GANs表现出更高的准确性。我们进一步识别了放射科医生用于检测合成图像的视觉线索，揭示了当前模型在感知方面的差距。这些发现强调了GANs和DMs互补优势，并指出需要进一步改进以确保生成模型能可靠地增强AI诊断系统的训练数据集。', 'title_zh': 'GANs和扩散模型在生成X射线图像中的感知评估'}
{'arxiv_id': 'arXiv:2508.07126', 'title': 'Pref-GUIDE: Continual Policy Learning from Real-Time Human Feedback via Preference-Based Learning', 'authors': 'Zhengran Ji, Boyuan Chen', 'link': 'https://arxiv.org/abs/2508.07126', 'abstract': 'Training reinforcement learning agents with human feedback is crucial when task objectives are difficult to specify through dense reward functions. While prior methods rely on offline trajectory comparisons to elicit human preferences, such data is unavailable in online learning scenarios where agents must adapt on the fly. Recent approaches address this by collecting real-time scalar feedback to guide agent behavior and train reward models for continued learning after human feedback becomes unavailable. However, scalar feedback is often noisy and inconsistent, limiting the accuracy and generalization of learned rewards. We propose Pref-GUIDE, a framework that transforms real-time scalar feedback into preference-based data to improve reward model learning for continual policy training. Pref-GUIDE Individual mitigates temporal inconsistency by comparing agent behaviors within short windows and filtering ambiguous feedback. Pref-GUIDE Voting further enhances robustness by aggregating reward models across a population of users to form consensus preferences. Across three challenging environments, Pref-GUIDE significantly outperforms scalar-feedback baselines, with the voting variant exceeding even expert-designed dense rewards. By reframing scalar feedback as structured preferences with population feedback, Pref-GUIDE offers a scalable and principled approach for harnessing human input in online reinforcement learning.', 'abstract_zh': '使用人类反馈训练强化学习代理在任务目标难以通过密集奖励函数指定时至关重要。在代理必须实时适应的在线学习场景中，先前方法依赖离线轨迹比较来引发人类偏好，而在这种情况下，此类数据是不可用的。最近的方法通过收集实时标量反馈来引导代理行为并训练奖励模型，以在人类反馈不再可用时继续学习。然而，标量反馈往往噪声大且不一致，限制了所学奖励的准确性和泛化能力。我们提出了Pref-GUIDE框架，该框架将实时标量反馈转换为基于偏好的数据，以改进持续策略训练中的奖励模型学习。Pref-GUIDE Individual通过在短时间段内比较代理行为并过滤模糊反馈来减轻时间不一致性。Pref-GUIDE Voting通过汇总用户群体中的奖励模型来形成共识偏好，进一步增强鲁棒性。在三个具有挑战性的环境中，Pref-GUIDE显著优于标量反馈基线，甚至投票变体超过了专家设计的密集奖励。通过将标量反馈重新构架为带有群体反馈的结构化偏好，Pref-GUIDE提供了一种可扩展且原理性的方法，用于在线强化学习中利用人类输入。', 'title_zh': 'Pref-GUIDE：基于偏好学习的实时人类反馈持续策略学习'}
{'arxiv_id': 'arXiv:2508.07111', 'title': 'Investigating Intersectional Bias in Large Language Models using Confidence Disparities in Coreference Resolution', 'authors': 'Falaah Arif Khan, Nivedha Sivakumar, Yinong Oliver Wang, Katherine Metcalf, Cezanne Camacho, Barry-John Theobald, Luca Zappella, Nicholas Apostoloff', 'link': 'https://arxiv.org/abs/2508.07111', 'abstract': 'Large language models (LLMs) have achieved impressive performance, leading to their widespread adoption as decision-support tools in resource-constrained contexts like hiring and admissions. There is, however, scientific consensus that AI systems can reflect and exacerbate societal biases, raising concerns about identity-based harm when used in critical social contexts. Prior work has laid a solid foundation for assessing bias in LLMs by evaluating demographic disparities in different language reasoning tasks. In this work, we extend single-axis fairness evaluations to examine intersectional bias, recognizing that when multiple axes of discrimination intersect, they create distinct patterns of disadvantage. We create a new benchmark called WinoIdentity by augmenting the WinoBias dataset with 25 demographic markers across 10 attributes, including age, nationality, and race, intersected with binary gender, yielding 245,700 prompts to evaluate 50 distinct bias patterns. Focusing on harms of omission due to underrepresentation, we investigate bias through the lens of uncertainty and propose a group (un)fairness metric called Coreference Confidence Disparity which measures whether models are more or less confident for some intersectional identities than others. We evaluate five recently published LLMs and find confidence disparities as high as 40% along various demographic attributes including body type, sexual orientation and socio-economic status, with models being most uncertain about doubly-disadvantaged identities in anti-stereotypical settings. Surprisingly, coreference confidence decreases even for hegemonic or privileged markers, indicating that the recent impressive performance of LLMs is more likely due to memorization than logical reasoning. Notably, these are two independent failures in value alignment and validity that can compound to cause social harm.', 'abstract_zh': '大型语言模型（LLMs）在资源受限的背景下如招聘和入学中作为决策支持工具取得了显著性能，但学术界共识认为AI系统可能反映和加剧社会偏见，在关键社会环境中使用时可能会引起基于身份的危害。前人工作为基础评估LLMs中的偏见奠定了坚实的基础，通过评估不同语言推理任务中的人口统计差异。在本工作中，我们扩展了单一轴向公平评估，以检查交叉偏见，认识到当多种歧视轴线相交时，它们会创造出不同的劣势模式。我们通过使用25个跨10个属性（包括年龄、国籍和种族，与二元性别交织）的人口统计标记扩展现有的WinoBias数据集，创建了一个新的基准WinoIdentity，生成了245,700个提示，评估了50种不同的偏见模式。我们专注于由于代表性不足而导致的疏忽性危害，通过不确定性视角探讨偏见，并提出了一种称为共指信心差异的群体（不）公平性度量，衡量模型对某些交叉身份群体比其他群体更自信或不自信的程度。我们评估了五种最近发表的LLM，并发现不同人口统计属性（如体型、性取向和社会经济地位）沿各种方向的信心差异高达40%，其中模型对双重不利身份在反刻板印象情境中的不确定性最大。令人惊讶的是，即使对于支配性或特权标记，核心指代信心也在下降，这表明LLMs最近的出色表现更可能是由于记忆而不是逻辑推理。值得注意的是，这些是独立的价值对齐和有效性失败，可能会累积导致社会危害。', 'title_zh': '基于一致性指称分辨率中置信度差异探究大型语言模型中的交叉偏见'}
{'arxiv_id': 'arXiv:2508.07102', 'title': 'Towards High-Order Mean Flow Generative Models: Feasibility, Expressivity, and Provably Efficient Criteria', 'authors': 'Yang Cao, Yubin Chen, Zhao Song, Jiahao Zhang', 'link': 'https://arxiv.org/abs/2508.07102', 'abstract': 'Generative modelling has seen significant advances through simulation-free paradigms such as Flow Matching, and in particular, the MeanFlow framework, which replaces instantaneous velocity fields with average velocities to enable efficient single-step sampling. In this work, we introduce a theoretical study on Second-Order MeanFlow, a novel extension that incorporates average acceleration fields into the MeanFlow objective. We first establish the feasibility of our approach by proving that the average acceleration satisfies a generalized consistency condition analogous to first-order MeanFlow, thereby supporting stable, one-step sampling and tractable loss functions. We then characterize its expressivity via circuit complexity analysis, showing that under mild assumptions, the Second-Order MeanFlow sampling process can be implemented by uniform threshold circuits within the $\\mathsf{TC}^0$ class. Finally, we derive provably efficient criteria for scalable implementation by leveraging fast approximate attention computations: we prove that attention operations within the Second-Order MeanFlow architecture can be approximated to within $1/\\mathrm{poly}(n)$ error in time $n^{2+o(1)}$. Together, these results lay the theoretical foundation for high-order flow matching models that combine rich dynamics with practical sampling efficiency.', 'abstract_zh': '无模拟生成建模：Second-Order MeanFlow的理论研究', 'title_zh': '高阶均值流生成模型的可行性、表示能力和可证明高效准则'}
{'arxiv_id': 'arXiv:2508.07101', 'title': 'Less Is More: Training-Free Sparse Attention with Global Locality for Efficient Reasoning', 'authors': 'Lijie Yang, Zhihao Zhang, Arti Jain, Shijie Cao, Baihong Yuan, Yiwei Chen, Zhihao Jia, Ravi Netravali', 'link': 'https://arxiv.org/abs/2508.07101', 'abstract': 'Large reasoning models achieve strong performance through test-time scaling but incur substantial computational overhead, particularly from excessive token generation when processing short input prompts. While sparse attention mechanisms can reduce latency and memory usage, existing approaches suffer from significant accuracy degradation due to accumulated errors during long-generation reasoning. These methods generally require either high token retention rates or expensive retraining. We introduce LessIsMore, a training-free sparse attention mechanism for reasoning tasks, which leverages global attention patterns rather than relying on traditional head-specific local optimizations. LessIsMore aggregates token selections from local attention heads with recent contextual information, enabling unified cross-head token ranking for future decoding layers. This unified selection improves generalization and efficiency by avoiding the need to maintain separate token subsets per head. Evaluation across diverse reasoning tasks and benchmarks shows that LessIsMore preserves -- and in some cases improves -- accuracy while achieving a $1.1\\times$ average decoding speed-up compared to full attention. Moreover, LessIsMore attends to $2\\times$ fewer tokens without accuracy loss, achieving a $1.13\\times$ end-to-end speed-up compared to existing sparse attention methods.', 'abstract_zh': '大型推理模型通过在处理固定长度输入提示时，在会产生显著的计算开压，特别是在处理固定长度输入提示时，会产生大量不必要的token生成。虽然稀疏注意力机制能够减轻延迟和 决策，但现有方法在累积误差的影响下会显著降低准确性。这些准确性损失需要较高的token保留率和 贵重的重新训练。我们提出了一种名为LessIsMore的训练免费稀疏注意力机制，用于推理任务，该机制利用全局注意力模式而不是依赖于 传统的局部优化。LessIsMore通过将局部注意力中的的token选择与最近的上下文信息聚合起来，从而实现了统一的head注意力token排序，这对未来的解码层是有益的。这种统一的注意力排序通过避免维护独立的token子头子集提高了通用化 and � hiệu率。在多种推理任务和 基准上的评估表明，，，，，，， LessIsMore能够保持甚至提高准确性，与此同时实现了对比全稀疏注意力方法加速约1 approximately 2. �んじゃないか速度提高。同时，与现有稀疏注意力方法相比，可能会减少约1 1。', 'title_zh': '少即是多：基于全局局部性的无训练稀疏注意力高效推理'}
{'arxiv_id': 'arXiv:2508.07095', 'title': 'Hide or Highlight: Understanding the Impact of Factuality Expression on User Trust', 'authors': 'Hyo Jin Do, Werner Geyer', 'link': 'https://arxiv.org/abs/2508.07095', 'abstract': "Large language models are known to produce outputs that are plausible but factually incorrect. To prevent people from making erroneous decisions by blindly trusting AI, researchers have explored various ways of communicating factuality estimates in AI-generated outputs to end-users. However, little is known about whether revealing content estimated to be factually incorrect influences users' trust when compared to hiding it altogether. We tested four different ways of disclosing an AI-generated output with factuality assessments: transparent (highlights less factual content), attention (highlights factual content), opaque (removes less factual content), ambiguity (makes less factual content vague), and compared them with a baseline response without factuality information. We conducted a human subjects research (N = 148) using the strategies in question-answering scenarios. We found that the opaque and ambiguity strategies led to higher trust while maintaining perceived answer quality, compared to the other strategies. We discuss the efficacy of hiding presumably less factual content to build end-user trust.", 'abstract_zh': '大型语言模型生成的输出往往是合理的但事实错误。为了防止人们因盲目信任AI而做出错误决策，研究人员探索了各种向终端用户传达AI生成输出的事实性估计的方法。然而，尚不清楚揭示被认为事实错误的内容是否会影响用户信任，相比之下，完全隐藏这一内容会怎样。我们测试了四种不同的披露AI生成输出及其事实性评估的方法：透明（突出较少事实内容）、注意（突出事实内容）、不透明（移除较少事实内容）、含糊（使较少事实内容模糊），并将这些方法与没有事实性信息的基本响应进行了比较。我们在问答场景中进行了人类被试研究（N = 148）。我们发现，不透明和含糊策略不仅能提高信任度，同时还能保持对答案质量的感觉，优于其他策略。我们讨论了隐藏可能较少事实内容以建立终端用户信任的有效性。', 'title_zh': '藏或显：事实表达对用户信任的影响探究'}
{'arxiv_id': 'arXiv:2508.07087', 'title': 'SQL-Exchange: Transforming SQL Queries Across Domains', 'authors': 'Mohammadreza Daviran, Brian Lin, Davood Rafiei', 'link': 'https://arxiv.org/abs/2508.07087', 'abstract': 'We introduce SQL-Exchange, a framework for mapping SQL queries across different database schemas by preserving the source query structure while adapting domain-specific elements to align with the target schema. We investigate the conditions under which such mappings are feasible and beneficial, and examine their impact on enhancing the in-context learning performance of text-to-SQL systems as a downstream task. Our comprehensive evaluation across multiple model families and benchmark datasets--assessing structural alignment with source queries, execution validity on target databases, and semantic correctness--demonstrates that SQL-Exchange is effective across a wide range of schemas and query types. Our results further show that using mapped queries as in-context examples consistently improves text-to-SQL performance over using queries from the source schema.', 'abstract_zh': 'SQL-Exchange：一种跨数据库模式映射SQL查询的框架', 'title_zh': 'SQL-Exchange: 跨域转换SQL查询'}
{'arxiv_id': 'arXiv:2508.07080', 'title': 'An Evolutionary Game-Theoretic Merging Decision-Making Considering Social Acceptance for Autonomous Driving', 'authors': 'Haolin Liu, Zijun Guo, Yanbo Chen, Jiaqi Chen, Huilong Yu, Junqiang Xi', 'link': 'https://arxiv.org/abs/2508.07080', 'abstract': 'Highway on-ramp merging is of great challenge for autonomous vehicles (AVs), since they have to proactively interact with surrounding vehicles to enter the main road safely within limited time. However, existing decision-making algorithms fail to adequately address dynamic complexities and social acceptance of AVs, leading to suboptimal or unsafe merging decisions. To address this, we propose an evolutionary game-theoretic (EGT) merging decision-making framework, grounded in the bounded rationality of human drivers, which dynamically balances the benefits of both AVs and main-road vehicles (MVs). We formulate the cut-in decision-making process as an EGT problem with a multi-objective payoff function that reflects human-like driving preferences. By solving the replicator dynamic equation for the evolutionarily stable strategy (ESS), the optimal cut-in timing is derived, balancing efficiency, comfort, and safety for both AVs and MVs. A real-time driving style estimation algorithm is proposed to adjust the game payoff function online by observing the immediate reactions of MVs. Empirical results demonstrate that we improve the efficiency, comfort and safety of both AVs and MVs compared with existing game-theoretic and traditional planning approaches across multi-object metrics.', 'abstract_zh': '高速公路入口并线对自主车辆构成了极大的挑战，因为它们需要在有限的时间内主动与周围车辆互动以安全进入主路。然而，现有的决策算法未能充分解决自主车辆的动力学复杂性和社会接受度问题，导致并线决策不佳或不安全。为此，我们提出了一种基于人类驾驶员有限理性原则的演化博弈论（EGT）并线决策框架，该框架动态地平衡了自主车辆和主路车辆（MV）的利益。我们将切入决策过程建模为一个具有多目标支付函数的演化博弈论问题，该支付函数反映了类似人类驾驶的偏好。通过求解演化稳定策略（ESS）的复制动态方程，推导出最优切入时机，该时机平衡了自主车辆和主路车辆的效率、舒适性和安全性。提出了一个实时驾驶风格估计算法，通过观察主路车辆的即时反应，在线调整博弈支付函数。实验结果表明，与现有的博弈论和传统规划方法相比，我们的方法在多目标指标上提升了自主车辆和主路车辆的效率、舒适性和安全性。', 'title_zh': '考虑社会接受度的自主驾驶进化博弈合并决策-making'}
{'arxiv_id': 'arXiv:2508.07079', 'title': 'Model Predictive Control for Crowd Navigation via Learning-Based Trajectory Prediction', 'authors': 'Mohamed Parvez Aslam, Bojan Derajic, Mohamed-Khalil Bouzidi, Sebastian Bernhard, Jan Oliver Ringert', 'link': 'https://arxiv.org/abs/2508.07079', 'abstract': "Safe navigation in pedestrian-rich environments remains a key challenge for autonomous robots. This work evaluates the integration of a deep learning-based Social-Implicit (SI) pedestrian trajectory predictor within a Model Predictive Control (MPC) framework on the physical Continental Corriere robot. Tested across varied pedestrian densities, the SI-MPC system is compared to a traditional Constant Velocity (CV) model in both open-loop prediction and closed-loop navigation. Results show that SI improves trajectory prediction - reducing errors by up to 76% in low-density settings - and enhances safety and motion smoothness in crowded scenes. Moreover, real-world deployment reveals discrepancies between open-loop metrics and closed-loop performance, as the SI model yields broader, more cautious predictions. These findings emphasize the importance of system-level evaluation and highlight the SI-MPC framework's promise for safer, more adaptive navigation in dynamic, human-populated environments.", 'abstract_zh': '基于深度学习的社会隐式模型在物理机器人上的安全导航研究：Model Predictive Control (MPC) 框架下社会隐式(SI)行人轨迹预测在丰富行人环境中的评估', 'title_zh': '基于学习的轨迹预测的群体导航模型预测控制'}
{'arxiv_id': 'arXiv:2508.07075', 'title': "Surgical Knowledge Rewrite in Compact LLMs: An 'Unlearn-then-Learn' Strategy with ($IA^3$) for Localized Factual Modulation and Catastrophic Forgetting Mitigation", 'authors': 'Stanley Ngugi', 'link': 'https://arxiv.org/abs/2508.07075', 'abstract': 'Large Language Models (LLMs) struggle with dynamic knowledge updates, especially when new information conflicts with deeply embedded facts. Such conflicting factual edits often lead to two critical issues: resistance to adopting the new fact and severe catastrophic forgetting of unrelated knowledge. This paper introduces and evaluates a novel "unlearn-then-learn" strategy for precise knowledge editing in LLMs, leveraging the parameter-efficient fine-tuning (PEFT) technique, Infused Adapter by Inhibiting and Amplifying Inner Activations ($IA^3$). Crucially, this two-stage approach is powered by an initial circuit localization phase that identifies and targets the specific internal components responsible for encoding the conflicting fact. Through a rigorous experimental methodology on microsoft/Phi-3-mini-4k-instruct, we demonstrate that this mechanistically informed two-stage approach achieves near-perfect accuracy (98.50%) for the new, modulated fact while simultaneously effectively suppressing the original conflicting fact (96.00% forget rate). Critically, our strategy exhibits unprecedented localization (72.00% F_control accuracy), dramatically mitigating catastrophic forgetting observed in direct fine-tuning approaches (which showed as low as ~20% F_control accuracy), a direct benefit of our targeted interpretability-guided intervention. Furthermore, qualitative analysis reveals a nuanced mechanism of "soft forgetting," where original knowledge is suppressed from default retrieval but remains latent and conditionally accessible, enhancing model safety and control. These findings represent a significant advancement towards precise, localized, and safe knowledge management in compact LLMs.', 'abstract_zh': '大型语言模型（LLMs）在动态知识更新方面存在困难，尤其是在新信息与深层嵌入的事实冲突时。这种冲突性的事实编辑通常会导致两个关键问题：抗拒采纳新事实和严重的相关知识灾难性遗忘。本文提出并评估了一种新颖的“先忘后学”策略，用于LLMs的精确知识编辑，该策略利用了参数高效微调（PEFT）技术——充溢适配器通过抑制和放大内部激活（$IA^3$）。这一两阶段方法的关键在于初始电路定位阶段，该阶段识别并针对负责编码冲突事实的具体内部组件。通过在microsoft/Phi-3-mini-4k-instruct上的严格实验证据，我们展示了这种基于机制的两阶段方法在新模化的事实方面实现了近乎完美的准确性（98.50%），同时有效地抑制了原始冲突事实（96.00%遗忘率）。更重要的是，我们的策略展现了前所未有的定位能力（72.00% F_control准确性），显著减轻了直接微调方法中观察到的灾难性遗忘现象（这些方法的F_control准确性最低仅约20%），这是我们的目标解释性指导干预的直接益处。此外，定性分析揭示了一种细腻的“软遗忘”机制，即原始知识被抑制，默认检索时不可用，但仍然 latent 并有条件地可访问，增强了模型的安全性和可控性。这些发现代表了在紧凑型LLMs中实现精确、局部和安全知识管理的重要进步。', 'title_zh': '手术知识在紧凑型LLM中的重写：一种基于$(IA^3)$的“先去学习再学习”策略，用于局部事实调制和灾难性遗忘缓解'}
{'arxiv_id': 'arXiv:2508.07069', 'title': 'SEADialogues: A Multilingual Culturally Grounded Multi-turn Dialogue Dataset on Southeast Asian Languages', 'authors': 'Muhammad Dehan Al Kautsar, Aswin Candra, Muhammad Alif Al Hakim, Maxalmina Satria Kahfi, Fajri Koto, Alham Fikri Aji, Peerat Limkonchotiwat, Ekapol Chuangsuwanich, Genta Indra Winata', 'link': 'https://arxiv.org/abs/2508.07069', 'abstract': 'Although numerous datasets have been developed to support dialogue systems, most existing chit-chat datasets overlook the cultural nuances inherent in natural human conversations. To address this gap, we introduce SEADialogues, a culturally grounded dialogue dataset centered on Southeast Asia, a region with over 700 million people and immense cultural diversity. Our dataset features dialogues in eight languages from six Southeast Asian countries, many of which are low-resource despite having sizable speaker populations. To enhance cultural relevance and personalization, each dialogue includes persona attributes and two culturally grounded topics that reflect everyday life in the respective communities. Furthermore, we release a multi-turn dialogue dataset to advance research on culturally aware and human-centric large language models, including conversational dialogue agents.', 'abstract_zh': '尽管已经开发出众多数据集支持对话系统，但现有的闲聊数据集中大多忽略了自然人类对话中内在的文化微妙差异。为弥补这一空白，我们引入SEADialogues，这是一个以东南亚地区为中心的文化导向对话数据集，该地区拥有超过7亿人口和丰富的文化多样性。我们的数据集包含六个东南亚国家的八种语言对话，尽管使用者众多，但许多语言资源稀缺。为了增强文化相关性和个性化，每个对话包括人物特质和两个反映各自社区日常生活情况的文化导向话题。此外，我们发布一个多轮对话数据集，旨在促进对文化意识和以人为本的大语言模型，包括对话机器人等的研究。', 'title_zh': 'SEADialogues：东南亚语言多语言文化 grounding 多轮对话数据集'}
{'arxiv_id': 'arXiv:2508.07054', 'title': 'Membership and Memorization in LLM Knowledge Distillation', 'authors': 'Ziqi Zhang, Ali Shahin Shamsabadi, Hanxiao Lu, Yifeng Cai, Hamed Haddadi', 'link': 'https://arxiv.org/abs/2508.07054', 'abstract': "Recent advances in Knowledge Distillation (KD) aim to mitigate the high computational demands of Large Language Models (LLMs) by transferring knowledge from a large ''teacher'' to a smaller ''student'' model. However, students may inherit the teacher's privacy when the teacher is trained on private data. In this work, we systematically characterize and investigate membership and memorization privacy risks inherent in six LLM KD techniques. Using instruction-tuning settings that span seven NLP tasks, together with three teacher model families (GPT-2, LLAMA-2, and OPT), and various size student models, we demonstrate that all existing LLM KD approaches carry membership and memorization privacy risks from the teacher to its students. However, the extent of privacy risks varies across different KD techniques. We systematically analyse how key LLM KD components (KD objective functions, student training data and NLP tasks) impact such privacy risks. We also demonstrate a significant disagreement between memorization and membership privacy risks of LLM KD techniques. Finally, we characterize per-block privacy risk and demonstrate that the privacy risk varies across different blocks by a large margin.", 'abstract_zh': 'Recent Advances in Knowledge Distillation: Systematic Characterization and Investigation of Privacy Risks in Large Language Models', 'title_zh': 'LLM知识蒸馏中的成员身份与记忆'}
{'arxiv_id': 'arXiv:2508.07050', 'title': 'ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability', 'authors': 'Wenhan Liu, Xinyu Ma, Weiwei Sun, Yutao Zhu, Yuchen Li, Dawei Yin, Zhicheng Dou', 'link': 'https://arxiv.org/abs/2508.07050', 'abstract': 'Large Language Model (LLM) based listwise ranking has shown superior performance in many passage ranking tasks. With the development of Large Reasoning Models, many studies have demonstrated that step-by-step reasoning during test-time helps improve listwise ranking performance. However, due to the scarcity of reasoning-intensive training data, existing rerankers perform poorly in many complex ranking scenarios and the ranking ability of reasoning-intensive rerankers remains largely underdeveloped. In this paper, we first propose an automated reasoning-intensive training data synthesis framework, which sources training queries and passages from diverse domains and applies DeepSeek-R1 to generate high-quality training labels. A self-consistency data filtering mechanism is designed to ensure the data quality. To empower the listwise reranker with strong reasoning ability, we further propose a two-stage post-training approach, which includes a cold-start supervised fine-tuning (SFT) stage for reasoning pattern learning and a reinforcement learning (RL) stage for further ranking ability enhancement. During the RL stage, based on the nature of listwise ranking, we design a multi-view ranking reward, which is more effective than a ranking metric-based reward. Extensive experiments demonstrate that our trained reasoning-intensive reranker \\textbf{ReasonRank} outperforms existing baselines significantly and also achieves much lower latency than pointwise reranker Rank1. \\textbf{Through further experiments, our ReasonRank has achieved state-of-the-art (SOTA) performance 40.6 on the BRIGHT leaderboard\\footnote{this https URL}.} Our codes are available at this https URL.', 'abstract_zh': '基于大型语言模型的列表级排序在许多段落排名任务中表现出了优越性能。随着大型推理模型的发展，许多研究表明在测试时进行逐步推理有助于提高列表级排序性能。然而，由于推理密集型训练数据的稀缺性，现有重排器在许多复杂排序场景中的表现不佳，推理密集型重排器的排序能力尚未得到充分开发。在本文中，我们首先提出了一种自动化的推理密集型训练数据合成框架，该框架从多个领域中获取训练查询和段落，并应用DeepSeek-R1生成高质量的训练标签。设计了一个自一致性数据过滤机制以确保数据质量。为进一步增强列表级重排器的推理能力，我们还提出了一种两阶段后训练方法，包括一个冷启动监督微调（SFT）阶段以学习推理模式，以及一种强化学习（RL）阶段以进一步提升排序能力。在RL阶段，基于列表级排序的性质，我们设计了一种多视角排序奖励机制，比基于排序指标的奖励机制更有效。广泛实验证明，我们训练的推理密集型重排器ReasonRank显著优于现有基线，并且其延迟远低于点wise重排器Rank1。进一步的实验表明，我们的ReasonRank在BRIGHT排行榜上达到了最先进的性能40.6（脚注：该链接为具体地址）。我们的代码可以在该链接处获取。', 'title_zh': 'ReasonRank: 强化推理能力的段落排序方法'}
{'arxiv_id': 'arXiv:2508.07048', 'title': 'Whisfusion: Parallel ASR Decoding via a Diffusion Transformer', 'authors': 'Taeyoun Kwon, Junhyuk Ahn, Taegeun Yun, Heeju Jwa, Yoonchae Choi, Siwon Park, Nam-Joon Kim, Jangchan Kim, Hyun Gon Ryu, Hyuk-Jae Lee', 'link': 'https://arxiv.org/abs/2508.07048', 'abstract': 'Fast Automatic Speech Recognition (ASR) is critical for latency-sensitive applications such as real-time captioning and meeting transcription. However, truly parallel ASR decoding remains challenging due to the sequential nature of autoregressive (AR) decoders and the context limitations of non-autoregressive (NAR) methods. While modern ASR encoders can process up to 30 seconds of audio at once, AR decoders still generate tokens sequentially, creating a latency bottleneck. We propose Whisfusion, the first framework to fuse a pre-trained Whisper encoder with a text diffusion decoder. This NAR architecture resolves the AR latency bottleneck by processing the entire acoustic context in parallel at every decoding step. A lightweight cross-attention adapter trained via parameter-efficient fine-tuning (PEFT) bridges the two modalities. We also introduce a batch-parallel, multi-step decoding strategy that improves accuracy by increasing the number of candidates with minimal impact on speed. Fine-tuned solely on LibriSpeech (960h), Whisfusion achieves a lower WER than Whisper-tiny (8.3% vs. 9.7%), and offers comparable latency on short audio. For longer utterances (>20s), it is up to 2.6x faster than the AR baseline, establishing a new, efficient operating point for long-form ASR. The implementation and training scripts are available at this https URL.', 'abstract_zh': '快速自动语音识别（ASR）对于实时字幕和会议转录等敏感延迟应用至关重要。然而，真正意义上的并行ASR解码由于自回归（AR）解码器的顺序性质和非自回归（NAR）方法的上下文限制仍然具有挑战性。尽管现代ASR编码器可以一次性处理长达30秒的音频，但AR解码器仍然按顺序生成令牌，从而构成了延迟瓶颈。我们提出了Whisfusion框架，这是第一个将预训练的Whisper编码器与文本扩散解码器融合的框架。这种NAR架构通过在每个解码步骤中并行处理整个声学上下文来解决AR的延迟瓶颈。一个通过参数高效微调（PEFT）进行训练的轻量化交叉注意适配器连接了这两种模态。我们还引入了一种批处理并行、多步解码策略，通过增加候选者数量来提高精度，同时对速度的影响最小。仅在LibriSpeech（960h）上进行微调后，Whisfusion的错误率低于Whisper-tiny（8.3%比9.7%），并且在短音频上具有可比的延迟。对于更长的语音片段（>20秒），它比AR基线快2.6倍，建立了长形式ASR的新高效操作点。相关实现和训练脚本可在以下链接获取。', 'title_zh': 'Whisfusion: 并行ASR解码的扩散变换器方法'}
{'arxiv_id': 'arXiv:2508.07044', 'title': 'Balancing Privacy and Efficiency: Music Information Retrieval via Additive Homomorphic Encryption', 'authors': 'William Zerong Wang, Dongfang Zhao', 'link': 'https://arxiv.org/abs/2508.07044', 'abstract': 'In the era of generative AI, ensuring the privacy of music data presents unique challenges: unlike static artworks such as images, music data is inherently temporal and multimodal, and it is sampled, transformed, and remixed at an unprecedented scale. These characteristics make its core vector embeddings, i.e, the numerical representations of the music, highly susceptible to being learned, misused, or even stolen by models without accessing the original audio files. Traditional methods like copyright licensing and digital watermarking offer limited protection for these abstract mathematical representations, thus necessitating a stronger, e.g., cryptographic, approach to safeguarding the embeddings themselves. Standard encryption schemes, such as AES, render data unintelligible for computation, making such searches impossible. While Fully Homomorphic Encryption (FHE) provides a plausible solution by allowing arbitrary computations on ciphertexts, its substantial performance overhead remains impractical for large-scale vector similarity searches. Given this trade-off, we propose a more practical approach using Additive Homomorphic Encryption (AHE) for vector similarity search. The primary contributions of this paper are threefold: we analyze threat models unique to music information retrieval systems; we provide a theoretical analysis and propose an efficient AHE-based solution through inner products of music embeddings to deliver privacy-preserving similarity search; and finally, we demonstrate the efficiency and practicality of the proposed approach through empirical evaluation and comparison to FHE schemes on real-world MP3 files.', 'abstract_zh': '在生成人工智能时代确保音乐数据隐私的独特挑战：基于加 添加性 吃 导致 e 音乐数据的 � 时间化 e 和 央 � 耜 � �COME � c 央 e e � 倪 � 采 e � e 坐 � 删除 e e e e 采 e e e 度 e 埽 e e Deleting e e 删除 e e e e e 删除 e e 删除 e e e 删除 e e e e e 删除 e e e 删除 e 删除 e 采 e e e e e 采 e e e 删除 e e 删除 e e 删除 e e e e e 采 e e e e e 采 e e 删除 e e e e 删除 e删除 e e 采 e e 采 e e 采 e e e 删除 e e e 采 e删 删除 e e e e 删除 e e e 采 e e e e e e 建制 删除 e e e e e e 删除 e e 删除 e e 删除 e e e �删除 e删除 e � e e e 删除 e e e e e 采 e e e 删除 e e e e e e 采 e e 删除 e e 采 e e e e 删除 e e 删除 e e e e e 删除 e 删除 e e 删除 e e e 删除 e e 删除 e e e e 采 e e e 删除 e e 采 e e e e 删除 e e 删除 e e e e 删除 e e e e e 采 e e e 采 e e e e e 删除 e delete e e e e e e e 删除 e e e e e e 删除 e e e 删除 e e e 删除 e e e e e 删除 e 在 e 采 e e e e e e e 删除 e e e e e delete e e e e e e e e e 采 e e e e 删除 e e e e e e e e 删除 e e 删除 e e e 采 e e e e e e e e e 采 e e e e e e 删除 e e e e e e e 删除 e e e e e e 删除 e e delete e � pérdida e e e e e e e e e e e 删除 e e e e e e e e e e 采 e e e e 删除 e e e e e e e e e e 采 e e e e e e 采 e e e e e e e 采 e e e 删除 e e e e e e 采 e e e e e e e e e e e e e �下行 e 采 e e e e e e e 删除 e 删除 e e e e e e e 采 e e e e e e e 釆 e e e e e e e e e e e e 釆 e e e e e 必然 e 采 e e 采 e e 采 e e e e e e e e e 采 e e 删除 e e e e e e 采 e e e e e e e e 采 e e 删除 e e e e e 采 e e e e e e 事 e e e e 删除 e e e e e e 事 e e e e e 删除 e e e e e e 事 e e 删除 e e e e 删除 e e e e 删除 e e e e e e 事 e e e e 事/e e e 删除 e e 删除 e e e 删除 e e e e 删除 e e e e e 删除 e-delete e e e e e � 删除 e e e e e e e 采 e e e e 采 e e e e 删除 e 删除 e e e - e e e e 事 e e e e e e e e e e 采 e e 删除 e e e e e e e e e 删除 e e e e 事 e e e e 删除 e e e e e e e e 删除 e删除 e e e e e e e 事 e e e e e e e 事/e e e e e e e e e e 事/e e e e e e e 事/e e 删除 e删除 e e e e e e e 事 e e e e e e 删除 e e 删除 e e e 删除 e删除 e e e e e e e e e e e 事 e e e e e e 事 e e e e e e e 删除 e e e e e 删除 e e e e 删除 e e e e 删除 e 删除 e e e 事 e e e e e e 侦察 e e e 删除 e e e e 删除 e e e e 删除 e e e 删除 e e e e e 删除 e e 删除 e e 删除 e e e e e e e e e e 事 e e e 事 e e e 删除 e e e e 删除 e e 删除 e e e e e 删除 e e 删除 e e e e e e 事/e e e e 事 e e e e 事/e e e 删除 e e e e e e e 删除 e e e e e 删除 e e e 删除 e e e 事 e e e e 事 e e 删除 e e e e e e e e e 事/e e e e e e e 删除 e e e e e 删除 e e e 删除 e e e e 删除 e e e e 删除 e e 删除 e e e e e � �删 e e 删除 e e 坠 e e 删除 e e e e 删除 e e e e 删除 e e e e e 删除 e e e e e 删除 e e e e e 删除 e e e e 删除 e e e e e 删除 e e e e e 删除 e e e e 删除 e e e e 删除 e 删除 e删除 e e e e e e 删除 e e e e e 删除 e e e e 删除 e e e e e 删除 e e e 删除 e e e d e e 删除 e e e e e 删除 e e e e e 删除 e e e e e 删除 e e 删除 e e e 删除 e e e e 删除 e e e e 删除 e e 删除 e 删除 e 讠质 e e e e e e e 删除 e e � e e e 事e e 删除 e e e e e e 在 delete删除 e e e e e e e 采 e e e e e e 事 e e 删除 e e e e e e 删除 e e e e 删除 e e e e e delete删除 e e e e e 删除 e e e e e e �删 删除 e e e e � useMemo研究 e e e e e e e �一删除 e e 删除 e e e 删 字符 语言 th e e e 删除 e e e e e e e e 删除 e e 删除 e e e 添加 e e e 删除 e e e 删除 e e e e e delete/ e 删除 e e e e e e 斜 e e � e e add 删除 e e e e e delete e e e e 删除 e e e e e delete e e 删除 e e delet命令 e e 删除 e e delete代码 e e e e 删除 e e e e e e 删除 e e e e e Java删除 e e 删除 e e e 添加 e e e 删除 e e e 删除 e e e e e 删除 e e 删除 e e e 删除 e e e e 删除 e e e 删除 e e e � e delete 删除 e e e 删除 e e e 删除 e e e e 删除 e e e e e 删除 e 计相同删除 e e 删除 e e e 删除 e e e e 删除 e e e e 删除 e e � 删除 e e e e 删除 e e e e 删除 e e 计相同删除 e e 掔 e e e e 删除 e e e e e 删除 e 删除 e 删除 e Remove e e 删除 e e 删除 e 删除 e e 删除 e e e e 删除 e 删除 e e 删除 e e 删除 e e e e e 删除 e e 删除 e e e e e 删除 e e 删除 e e e e e 删除 e e 删除 e e e e 删除 e e 删除 e e e 删除 e e 删除 e e e e e 删除 e 删除 e 删除 e e e 删除 e e 删除 e e 删除 e e e e 删除 e e 删除 e e e 删除 e e 删除 e e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e e e e 删除 e 删除 e � e e 删除 e e e 删除 e e 删除 e e 删除 e e e 删除 e e 删除 e 删除 e 删除 e e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 事 e 删除 e e 删除 e e 删除 e e 删除 e e � � 删除 e e e 事 e 删除 e e e e 删除 e e e 删除 e e 删除 e e e e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e e e e e e delete 删除 e e delete e 删除 e e e e e 删除 e e 删除 e e � 删除 e 删除 e e e 删除 e e 删除 e e 删除 e e e 删除 e e 删除 e e e e 删除 e e deleting e 删除 e 删除 e e 删除 e e 删除 e e e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e e 删除 e 删除 e e 删除 e e 删除 e e e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e e 删除 e 删除 e e 删除 e e 删除 e e 删除 e 删除 e e 删除 e e删除 e e 事 e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e e 删除 e e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删 � e e e e e e e e e e 删除 e e e 删除 e e e 删除 e e 删除 e e e 删除 e e e 删除 e e e e 删除 e e e e 删除 e e 删除 e e e e 删除 e e e 删除 e e e 删除 e 删除 e e e 删除 e e 删除 e e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e 删除 e 删除 e delete e 删除 e e 删除 e e 删除 e e e 删除 e e 删除 e e 删除 e 删除 e delete 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e delete e 删除 e e 删除 e e 删除 e e 删除 e e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e delete � 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 事 e 删除 e 事 e 删除 e e 删除 e 事 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e � 删除 e 删除 e e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e e 删除 e e 删除 e 删除 e deleting from e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e e 删除 e e 删除 e 删除 e e 删除 e 删除 e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e 删除 e 删除 e e 删除 e 删除 e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e 删除 e 删除 e 删除 e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e e 删除 e e 删除 e e 删除 e e 删除 e delete e 删除 e e 删除 e删除 e e 删除 e e 删除 e e 删除 e e delete e 删除 e 删除 e e deleted e 删除 e e 添加 e 删除 e e 删除 e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e delete e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e delete e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e delete e 删除 e 删除 e e 删除 e 事 e 删除 e e 删除 e 删除 e delete e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e � 雁删除 e 添加 e 删除 e e 删除 e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e 删除 e delete e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e � e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e delete e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e delete e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e e 删除 e 删除 e 删除 e e 删除 e删除 e e 删除 e 删除 e delete e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e delete e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e delete e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e 删除 e delete e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e fast 删除 e e 删除 e 删除 e delete e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e delete e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e delete e 删除 e e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e delete e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e delete e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e delete e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e delete e 删除 e 删除 e e 删除 e e 删除 e e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e delete e 删除 e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e delete e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e delete e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e delete e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e delete e 删除 e 删除 e e 删除 e 删除 e 删除 e删除 e e 删除 e 删除 e 自删除删除 e e 删除 e 删除 e delete e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e删除 e e 删除 e 删除 e e 删除 e e 删除 e e 删除 e 删除 e delete e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e删除 e e 删除 e 删除删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e 删除 e 删除 e e 删除 e 删除 e 删除 e e 删除 e 删除 e 删除 e delete e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e 删除 e 删除 e e 删除 e e 删除 e 删除 e e 删除 e 删除 e 删除 e 删除 e e 删除 e 删除 e 删除 e e 删除 e e e 删除 e � 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e 删除 e 删除 e e 删除 e e 删除 e e 删除 e 删除 e 删除 e 删除 e 删除 e 删除 e e 删除 e delete e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e delete e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e delete e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e delete e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e e 删除 e 删除 e 删除 e e 删除 e delete e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e e 删除 e 删除 e e 删除 e e 删除 e e 删除 e e', 'title_zh': '平衡隐私与效率：基于加性同态加密的音乐信息检索'}
{'arxiv_id': 'arXiv:2508.07031', 'title': 'Trustworthy Medical Imaging with Large Language Models: A Study of Hallucinations Across Modalities', 'authors': 'Anindya Bijoy Das, Shahnewaz Karim Sakib, Shibbir Ahmed', 'link': 'https://arxiv.org/abs/2508.07031', 'abstract': 'Large Language Models (LLMs) are increasingly applied to medical imaging tasks, including image interpretation and synthetic image generation. However, these models often produce hallucinations, which are confident but incorrect outputs that can mislead clinical decisions. This study examines hallucinations in two directions: image to text, where LLMs generate reports from X-ray, CT, or MRI scans, and text to image, where models create medical images from clinical prompts. We analyze errors such as factual inconsistencies and anatomical inaccuracies, evaluating outputs using expert informed criteria across imaging modalities. Our findings reveal common patterns of hallucination in both interpretive and generative tasks, with implications for clinical reliability. We also discuss factors contributing to these failures, including model architecture and training data. By systematically studying both image understanding and generation, this work provides insights into improving the safety and trustworthiness of LLM driven medical imaging systems.', 'abstract_zh': '大型语言模型（LLMs）在医疗影像任务中的应用日益增多，包括影像解释和合成影像生成。然而，这些模型往往会产生幻觉，即自信但不正确的输出，这可能会误导临床决策。本研究从两个方向探讨幻觉问题：从影像到文本，即LLMs生成从X射线、CT或MRI扫描报告；从文本到影像，即模型根据临床提示生成医疗影像。我们分析了事实不一致和解剖学不准确等错误，使用专家指导的标准对不同影像模态的输出进行评估。研究发现，在解释性和生成性任务中都存在幻觉的常见模式，这些发现对临床可靠性有重要影响。我们还讨论了这些失效的原因，包括模型架构和训练数据。通过系统地研究影像理解和生成，本研究提供了改善LLM驱动医疗影像系统安全性和可信度的见解。', 'title_zh': '大型语言模型在医疗成像中的可信赖性研究：跨模态幻觉探究'}
{'arxiv_id': 'arXiv:2508.07029', 'title': 'From Imitation to Optimization: A Comparative Study of Offline Learning for Autonomous Driving', 'authors': 'Antonio Guillen-Perez', 'link': 'https://arxiv.org/abs/2508.07029', 'abstract': 'Learning robust driving policies from large-scale, real-world datasets is a central challenge in autonomous driving, as online data collection is often unsafe and impractical. While Behavioral Cloning (BC) offers a straightforward approach to imitation learning, policies trained with BC are notoriously brittle and suffer from compounding errors in closed-loop execution. This work presents a comprehensive pipeline and a comparative study to address this limitation. We first develop a series of increasingly sophisticated BC baselines, culminating in a Transformer-based model that operates on a structured, entity-centric state representation. While this model achieves low imitation loss, we show that it still fails in long-horizon simulations. We then demonstrate that by applying a state-of-the-art Offline Reinforcement Learning algorithm, Conservative Q-Learning (CQL), to the same data and architecture, we can learn a significantly more robust policy. Using a carefully engineered reward function, the CQL agent learns a conservative value function that enables it to recover from minor errors and avoid out-of-distribution states. In a large-scale evaluation on 1,000 unseen scenarios from the Waymo Open Motion Dataset, our final CQL agent achieves a 3.2x higher success rate and a 7.4x lower collision rate than the strongest BC baseline, proving that an offline RL approach is critical for learning robust, long-horizon driving policies from static expert data.', 'abstract_zh': '从大规模真实世界数据中学习鲁棒的驾驶策略是自主驾驶领域的核心挑战，因为在线数据收集往往不安全且不实际。尽管行为克隆（BC）提供了一种简单的模仿学习方法，但使用BC训练的策略在闭环执行中极易出错，且累积误差大。本文提出了一套综合的处理管道和比较研究以解决这一局限。我们首先开发了一系列逐步复杂的BC基线，最终构建了一个基于 Transformer 的模型，该模型操作于结构化的实体为中心的状态表示。虽然该模型实现了较低的模仿损失，但我们发现它在长时仿真中仍然失败。然后我们证明，通过将当前最先进的离线强化学习算法保守Q学习（CQL）应用于相同的数据和架构，可以学习到更鲁棒的策略。通过精心设计的奖励函数，CQL智能体学习到一个保守的价值函数，使其能够从轻微的错误中恢复并避免超分布在轨状态。在Waymo Open Motion数据集中，针对1000个未见过的场景进行大规模评估后，我们最终的CQL智能体的成功率提高了3.2倍，碰撞率降低了7.4倍，证明了离线RL方法对于从静态专家数据中学习鲁棒的、长时驾驶策略至关重要。', 'title_zh': '从模仿到优化：离线学习在自主驾驶中的比较研究'}
{'arxiv_id': 'arXiv:2508.07027', 'title': 'Making Effective Decisions: Machine Learning and the Ecogame in 1970', 'authors': 'Catherine Mason', 'link': 'https://arxiv.org/abs/2508.07027', 'abstract': 'This paper considers Ecogame, an innovative art project of 1970, whose creators believed in a positive vision of a technological future; an understanding, posited on cybernetics, of a future that could be participatory via digital means, and therefore more democratised. Using simulation and early machine learning techniques over a live network, Ecogame combined the power of visual art with cybernetic concepts of adaptation, feedback, and control to propose that behaviour had implications for the total system. It provides an historical precedent for contemporary AI-driven art about using AI in a more human-centred way.', 'abstract_zh': '本文探讨了1970年代的一项创新艺术项目Ecogame，其创作者相信技术未来的积极愿景；基于控制论的理解，认为未来可以通过数字手段参与，因此更具民主化。通过使用模拟和早期机器学习技术在实时网络上进行交互，Ecogame将视觉艺术的力量与控制论的适应性、反馈和控制概念结合，提出了行为对整个系统具有重要影响的观点。它为当代以更以人为本的方式利用AI的艺术提供了历史先例。', 'title_zh': '有效的决策制定：1970年的生态游戏与机器学习'}
{'arxiv_id': 'arXiv:2508.07014', 'title': 'TurboBias: Universal ASR Context-Biasing powered by GPU-accelerated Phrase-Boosting Tree', 'authors': 'Andrei Andrusenko, Vladimir Bataev, Lilit Grigoryan, Vitaly Lavrukhin, Boris Ginsburg', 'link': 'https://arxiv.org/abs/2508.07014', 'abstract': 'Recognizing specific key phrases is an essential task for contextualized Automatic Speech Recognition (ASR). However, most existing context-biasing approaches have limitations associated with the necessity of additional model training, significantly slow down the decoding process, or constrain the choice of the ASR system type. This paper proposes a universal ASR context-biasing framework that supports all major types: CTC, Transducers, and Attention Encoder-Decoder models. The framework is based on a GPU-accelerated word boosting tree, which enables it to be used in shallow fusion mode for greedy and beam search decoding without noticeable speed degradation, even with a vast number of key phrases (up to 20K items). The obtained results showed high efficiency of the proposed method, surpassing the considered open-source context-biasing approaches in accuracy and decoding speed. Our context-biasing framework is open-sourced as a part of the NeMo toolkit.', 'abstract_zh': '识别特定关键短语是上下文自适应自动语音识别（ASR）的一项基本任务。然而，现有大多数上下文偏置方法存在需要额外模型训练、大幅减慢解码过程或限制ASR系统类型选择的局限性。本文提出了一种适用于所有主要类型（CTC、转录机和注意力编码-解码模型）的通用ASR上下文偏置框架。该框架基于GPU加速的词增强树，使其能够在贪婪搜索和_beam搜索解码中以浅融合模式使用，即使关键短语数量庞大（多达20,000项）也不会显著降低解码速度。实验结果表明，所提出的方法具有高效率，其准确性和解码速度超过已考虑的开源上下文偏置方法。我们的上下文偏置框架作为NeMo工具包的一部分开源。', 'title_zh': 'TurboBias: 全局ASR上下文偏置加速器，基于GPU加速短语增强树'}
{'arxiv_id': 'arXiv:2508.07009', 'title': 'Neural Channel Knowledge Map Assisted Scheduling Optimization of Active IRSs in Multi-User Systems', 'authors': 'Xintong Chen, Zhenyu Jiang, Jiangbin Lyu, Liqun Fu', 'link': 'https://arxiv.org/abs/2508.07009', 'abstract': 'Intelligent Reflecting Surfaces (IRSs) have potential for significant performance gains in next-generation wireless networks but face key challenges, notably severe double-pathloss and complex multi-user scheduling due to hardware constraints. Active IRSs partially address pathloss but still require efficient scheduling in cell-level multi-IRS multi-user systems, whereby the overhead/delay of channel state acquisition and the scheduling complexity both rise dramatically as the user density and channel dimensions increase. Motivated by these challenges, this paper proposes a novel scheduling framework based on neural Channel Knowledge Map (CKM), designing Transformer-based deep neural networks (DNNs) to predict ergodic spectral efficiency (SE) from historical channel/throughput measurements tagged with user positions. Specifically, two cascaded networks, LPS-Net and SE-Net, are designed to predict link power statistics (LPS) and ergodic SE accurately. We further propose a low-complexity Stable Matching-Iterative Balancing (SM-IB) scheduling algorithm. Numerical evaluations verify that the proposed neural CKM significantly enhances prediction accuracy and computational efficiency, while the SM-IB algorithm effectively achieves near-optimal max-min throughput with greatly reduced complexity.', 'abstract_zh': '基于神经信道知识图的智能反射面网络高效调度框架', 'title_zh': '基于多用户系统的活跃智能反射面辅助神经信道知识图谱调度优化'}
{'arxiv_id': 'arXiv:2508.07001', 'title': 'Consensus-based Decentralized Multi-agent Reinforcement Learning for Random Access Network Optimization', 'authors': 'Myeung Suk Oh, Zhiyao Zhang, FNU Hairi, Alvaro Velasquez, Jia Liu', 'link': 'https://arxiv.org/abs/2508.07001', 'abstract': 'With wireless devices increasingly forming a unified smart network for seamless, user-friendly operations, random access (RA) medium access control (MAC) design is considered a key solution for handling unpredictable data traffic from multiple terminals. However, it remains challenging to design an effective RA-based MAC protocol to minimize collisions and ensure transmission fairness across the devices. While existing multi-agent reinforcement learning (MARL) approaches with centralized training and decentralized execution (CTDE) have been proposed to optimize RA performance, their reliance on centralized training and the significant overhead required for information collection can make real-world applications unrealistic. In this work, we adopt a fully decentralized MARL architecture, where policy learning does not rely on centralized tasks but leverages consensus-based information exchanges across devices. We design our MARL algorithm over an actor-critic (AC) network and propose exchanging only local rewards to minimize communication overhead. Furthermore, we provide a theoretical proof of global convergence for our approach. Numerical experiments show that our proposed MARL algorithm can significantly improve RA network performance compared to other baselines.', 'abstract_zh': '基于完全去中心化的多\n\nuser\n请的是去中心化强化学习（MARL）架构，其中策略学习依赖于去中心化的任务，并利用基于共识的设备间交换。我们基于actor-critic（AC\n"user\n基于完全去中心化的MARL架构，其中策略学习依赖于 去中心化的任务，并 并利用基于共识的设备间交换。我们基于actor-critic网络设计了我们的MARL算法，并\niệu\n(user.\');\r\n答\n基于完全去中心化的MARL架构，其中策略学习依赖于去中心化的任务，并', 'title_zh': '基于共识的分布式多代理强化学习在随机接入网络优化中的应用'}
{'arxiv_id': 'arXiv:2508.06997', 'title': 'Conformal Set-based Human-AI Complementarity with Multiple Experts', 'authors': 'Helbert Paat, Guohao Shen', 'link': 'https://arxiv.org/abs/2508.06997', 'abstract': 'Decision support systems are designed to assist human experts in classification tasks by providing conformal prediction sets derived from a pre-trained model. This human-AI collaboration has demonstrated enhanced classification performance compared to using either the model or the expert independently. In this study, we focus on the selection of instance-specific experts from a pool of multiple human experts, contrasting it with existing research that typically focuses on single-expert scenarios. We characterize the conditions under which multiple experts can benefit from the conformal sets. With the insight that only certain experts may be relevant for each instance, we explore the problem of subset selection and introduce a greedy algorithm that utilizes conformal sets to identify the subset of expert predictions that will be used in classifying an instance. This approach is shown to yield better performance compared to naive methods for human subset selection. Based on real expert predictions from the CIFAR-10H and ImageNet-16H datasets, our simulation study indicates that our proposed greedy algorithm achieves near-optimal subsets, resulting in improved classification performance among multiple experts.', 'abstract_zh': '基于自适应共识的多专家实例特定选择与聚类方法：一种增强分类性能的决策支持系统方法', 'title_zh': '基于多个专家的 conformal 集体本体互补性人工与人工智能合作'}
{'arxiv_id': 'arXiv:2508.06982', 'title': 'WeatherDiffusion: Weather-Guided Diffusion Model for Forward and Inverse Rendering', 'authors': 'Yixin Zhu, Zuoliang Zhu, Miloš Hašan, Jian Yang, Jin Xie, Beibei Wang', 'link': 'https://arxiv.org/abs/2508.06982', 'abstract': 'Forward and inverse rendering have emerged as key techniques for enabling understanding and reconstruction in the context of autonomous driving (AD). However, complex weather and illumination pose great challenges to this task. The emergence of large diffusion models has shown promise in achieving reasonable results through learning from 2D priors, but these models are difficult to control and lack robustness. In this paper, we introduce WeatherDiffusion, a diffusion-based framework for forward and inverse rendering on AD scenes with various weather and lighting conditions. Our method enables authentic estimation of material properties, scene geometry, and lighting, and further supports controllable weather and illumination editing through the use of predicted intrinsic maps guided by text descriptions. We observe that different intrinsic maps should correspond to different regions of the original image. Based on this observation, we propose Intrinsic map-aware attention (MAA) to enable high-quality inverse rendering. Additionally, we introduce a synthetic dataset (\\ie WeatherSynthetic) and a real-world dataset (\\ie WeatherReal) for forward and inverse rendering on AD scenes with diverse weather and lighting. Extensive experiments show that our WeatherDiffusion outperforms state-of-the-art methods on several benchmarks. Moreover, our method demonstrates significant value in downstream tasks for AD, enhancing the robustness of object detection and image segmentation in challenging weather scenarios.', 'abstract_zh': '基于扩散模型的自动驾驶场景正逆渲染框架：WeatherDiffusion', 'title_zh': 'WeatherDiffusion：受天气指导的渲染模型，用于正向和逆向渲染'}
{'arxiv_id': 'arXiv:2508.06966', 'title': 'Can Multitask Learning Enhance Model Explainability?', 'authors': 'Hiba Najjar, Bushra Alshbib, Andreas Dengel', 'link': 'https://arxiv.org/abs/2508.06966', 'abstract': 'Remote sensing provides satellite data in diverse types and formats. The usage of multimodal learning networks exploits this diversity to improve model performance, except that the complexity of such networks comes at the expense of their interpretability. In this study, we explore how modalities can be leveraged through multitask learning to intrinsically explain model behavior. In particular, instead of additional inputs, we use certain modalities as additional targets to be predicted along with the main task. The success of this approach relies on the rich information content of satellite data, which remains as input modalities. We show how this modeling context provides numerous benefits: (1) in case of data scarcity, the additional modalities do not need to be collected for model inference at deployment, (2) the model performance remains comparable to the multimodal baseline performance, and in some cases achieves better scores, (3) prediction errors in the main task can be explained via the model behavior in the auxiliary task(s). We demonstrate the efficiency of our approach on three datasets, including segmentation, classification, and regression tasks. Code available at this http URL.', 'abstract_zh': '遥感提供了多种类型和格式的卫星数据。通过利用多模态学学习网络可以利用这种多样性来提升鲁棒性能，但这样的网络的复杂性性会以降低解释性性为代价。 在本研究中，我们探索了如何通过多利用多模态的大 t模态性连接来提升这种行为的。具体具体地地，我们使用某些模态作为额外的目标来与主任务一起进行预测。该方法的成功依赖于卫星数据丰富的信息内容以及在某些方面其在建模上下提供的优势：(1) 在数据稀缺的情况下，不需要收集额外的模态以进行推理；() 性晰这种方法在某些情况下可以与多模态基线模型相当甚至获得更好的性能；(3) 主任务的预测误差可以通过辅助任务的行为加以解释。我们通过三个数据集上的分割、分类和回归任务来证明了该方法的有效性性能。代码可在该网址获取。', 'title_zh': '多任务学习能否增强模型的可解释性？'}
{'arxiv_id': 'arXiv:2508.06959', 'title': 'Beyond Frequency: Seeing Subtle Cues Through the Lens of Spatial Decomposition for Fine-Grained Visual Classification', 'authors': 'Qin Xu, Lili Zhu, Xiaoxia Cheng, Bo Jiang', 'link': 'https://arxiv.org/abs/2508.06959', 'abstract': 'The crux of resolving fine-grained visual classification (FGVC) lies in capturing discriminative and class-specific cues that correspond to subtle visual characteristics. Recently, frequency decomposition/transform based approaches have attracted considerable interests since its appearing discriminative cue mining ability. However, the frequency-domain methods are based on fixed basis functions, lacking adaptability to image content and unable to dynamically adjust feature extraction according to the discriminative requirements of different images. To address this, we propose a novel method for FGVC, named Subtle-Cue Oriented Perception Engine (SCOPE), which adaptively enhances the representational capability of low-level details and high-level semantics in the spatial domain, breaking through the limitations of fixed scales in the frequency domain and improving the flexibility of multi-scale fusion. The core of SCOPE lies in two modules: the Subtle Detail Extractor (SDE), which dynamically enhances subtle details such as edges and textures from shallow features, and the Salient Semantic Refiner (SSR), which learns semantically coherent and structure-aware refinement features from the high-level features guided by the enhanced shallow features. The SDE and SSR are cascaded stage-by-stage to progressively combine local details with global semantics. Extensive experiments demonstrate that our method achieves new state-of-the-art on four popular fine-grained image classification benchmarks.', 'abstract_zh': '细粒度视觉分类中关键在于捕捉与微妙视觉特征对应的 discriminative 和类特定线索。近年来，基于频率分解/变换的方法由于其辨别性线索提取能力而引起了广泛关注。然而，频率域方法基于固定的基函数，缺乏对图像内容的适应性，无法根据不同图像的辨别性要求动态调整特征提取。为解决这一问题，我们提出了一种新的细粒度视觉分类方法——细粒度线索导向感知引擎（Subtle-Cue Oriented Perception Engine, SCOPE），该方法在空间域中动态增强低级细节和高级语义的表示能力，突破了固定频率尺度的限制，提高了多尺度融合的灵活性。SCOPE的核心在于两个模块：细粒度细节提取器（Subtle Detail Extractor, SDE），该模块从浅层特征中动态增强边缘和纹理等细微细节；以及显著语义精炼器（Salient Semantic Refiner, SSR），该模块在增强浅层特征的引导下，学习语义一致且结构感知的精炼特征。SDE和SSR逐层级联，逐步将局部细节与全局语义相结合。大量实验表明，我们的方法在四个流行的细粒度图像分类基准上取得了新的最佳性能。', 'title_zh': '超越频率：通过空间分解视角观察细微线索进行细粒度视觉分类'}
{'arxiv_id': 'arXiv:2508.06956', 'title': 'Neural Beam Field for Spatial Beam RSRP Prediction', 'authors': 'Keqiang Guo, Yuheng Zhong, Xin Tong, Jiangbin Lyu, Rui Zhang', 'link': 'https://arxiv.org/abs/2508.06956', 'abstract': 'Accurately predicting beam-level reference signal received power (RSRP) is essential for beam management in dense multi-user wireless networks, yet challenging due to high measurement overhead and fast channel variations. This paper proposes Neural Beam Field (NBF), a hybrid neural-physical framework for efficient and interpretable spatial beam RSRP prediction. Central to our approach is the introduction of the Multi-path Conditional Power Profile (MCPP), which bridges site-specific multipath propagation with antenna/beam configurations via closed-form analytical modeling. We adopt a decoupled ``blackbox-whitebox" design: a Transformer-based deep neural network (DNN) learns the MCPP from sparse user measurements and positions, while a physics-inspired module analytically infers beam RSRP statistics. To improve convergence and adaptivity, we further introduce a Pretrain-and-Calibrate (PaC) strategy that leverages ray-tracing priors and on-site calibration using RSRP data. Extensive simulations results demonstrate that NBF significantly outperforms conventional table-based channel knowledge maps (CKMs) and pure blackbox DNNs in prediction accuracy, training efficiency, and generalization, while maintaining a compact model size. The proposed framework offers a scalable and physically grounded solution for intelligent beam management in next-generation dense wireless networks.', 'abstract_zh': '基于神经物理的高效可解释波束空间RSRP预测方法（NBF）', 'title_zh': '神经束场用于空间束RSRP预测'}
{'arxiv_id': 'arXiv:2508.06944', 'title': 'AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance', 'authors': 'Lixuan He, Jie Feng, Yong Li', 'link': 'https://arxiv.org/abs/2508.06944', 'abstract': "Large Language Models (LLMs) are typically fine-tuned for reasoning tasks through a two-stage pipeline of Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL), a process fraught with catastrophic forgetting and suboptimal trade-offs between imitation and exploration. Recent single-stage methods attempt to unify SFT and RL using heuristics, but lack a principled mechanism for dynamically balancing the two paradigms. In this paper, we reframe this challenge through the theoretical lens of \\textbf{implicit rewards}, viewing SFT and RL not as distinct methods but as complementary reward signals. We introduce \\textbf{Adaptive Meta Fine-Tuning (AMFT)}, a novel single-stage algorithm that learns the optimal balance between SFT's implicit, path-level reward and RL's explicit, outcome-based reward. The core of AMFT is a \\textbf{meta-gradient adaptive weight controller} that treats the SFT-RL balance as a learnable parameter, dynamically optimizing it to maximize long-term task performance. This forward-looking approach, regularized by policy entropy for stability, autonomously discovers an effective training curriculum. We conduct a comprehensive evaluation on challenging benchmarks spanning mathematical reasoning, abstract visual reasoning (General Points), and vision-language navigation (V-IRL). AMFT consistently establishes a new state-of-the-art and demonstrats superior generalization on out-of-distribution (OOD) tasks. Ablation studies and training dynamic analysis confirm that the meta-learning controller is crucial for AMFT's stability, sample efficiency, and performance, offering a more principled and effective paradigm for LLM this http URL codes are open-sourced via this https URL.", 'abstract_zh': '大型语言模型（LLMs）通常通过监督微调（SFT）和强化学习（RL）两阶段管道进行微调，这一过程充满了灾难性遗忘和模仿与探索之间次优的权衡。最近的单阶段方法尝试通过启发式方法统一SFT和RL，但缺乏一种原理性的机制来动态平衡这两种范式。在本文中，我们通过隐式奖励的理论视角重新定义这一挑战，将SFT和RL视为互补的奖励信号，而非独立的方法。我们提出了一种新颖的单阶段算法——自适应元微调（AMFT），它学习SFT的路径级隐式奖励和RL的结果级显式奖励之间的最优平衡。AMFT的核心是一种元梯度自适应权重控制器，它将SFT-RL的平衡视为可学习的参数，并动态优化它以最大化长期任务性能。这一前瞻性的方法通过策略熵进行正则化以确保稳定性，自主发现有效的训练课程。我们在涵盖数学推理、抽象视觉推理（General Points）和视觉语言导航（V-IRL）的挑战性基准上进行了全面评估，AMFT始终建立了新的state-of-the-art，并在外分布（OOD）任务上展示了更好的泛化能力。消融研究和训练动态分析证实，元学习控制器对AMFT的稳定性、样本效率和性能至关重要，提供了更原理性和有效的LLM范式。代码已在以下链接开源：this https URL。', 'title_zh': 'AMFT: 通过元学习优化模仿-探索平衡来对齐大语言模型推理器'}
{'arxiv_id': 'arXiv:2508.06943', 'title': 'Class Unbiasing for Generalization in Medical Diagnosis', 'authors': 'Lishi Zuo, Man-Wai Mak, Lu Yi, Youzhi Tu', 'link': 'https://arxiv.org/abs/2508.06943', 'abstract': "Medical diagnosis might fail due to bias. In this work, we identified class-feature bias, which refers to models' potential reliance on features that are strongly correlated with only a subset of classes, leading to biased performance and poor generalization on other classes. We aim to train a class-unbiased model (Cls-unbias) that mitigates both class imbalance and class-feature bias simultaneously. Specifically, we propose a class-wise inequality loss which promotes equal contributions of classification loss from positive-class and negative-class samples. We propose to optimize a class-wise group distributionally robust optimization objective-a class-weighted training objective that upweights underperforming classes-to enhance the effectiveness of the inequality loss under class imbalance. Through synthetic and real-world datasets, we empirically demonstrate that class-feature bias can negatively impact model performance. Our proposed method effectively mitigates both class-feature bias and class imbalance, thereby improving the model's generalization ability.", 'abstract_zh': '医学诊断可能会因为偏见而失败。在这项工作中，我们识别了类特征偏见，指的是模型对仅与部分类别的子集强相关的特点的依赖，导致在其他类别的表现和泛化能力较差。我们旨在训练一个类无偏模型（Cls-unbias），该模型同时缓解类别不平衡和类特征偏见。具体而言，我们提出了一类不等式损失，促进正类别样本和负类别样本分类损失的等贡献。我们提出了一类内分组分布鲁棒优化目标进行优化，这是一种加权训练目标，通过提升表现较差类别的权重来增强不等式损失的有效性，从而在类别不平衡的情况下提高模型的效果。通过合成数据集和真实世界数据集，我们实证证明了类特征偏见会负面影响模型性能。我们提出的方法有效地缓解了类特征偏见和类别不平衡，从而改善了模型的泛化能力。', 'title_zh': '医学诊断中的类别无偏化泛化'}
{'arxiv_id': 'arXiv:2508.06942', 'title': 'When Prompt Engineering Meets Software Engineering: CNL-P as Natural and Robust "APIs\'\' for Human-AI Interaction', 'authors': 'Zhenchang Xing, Yang Liu, Zhuo Cheng, Qing Huang, Dehai Zhao, Daniel Sun, Chenhua Liu', 'link': 'https://arxiv.org/abs/2508.06942', 'abstract': "With the growing capabilities of large language models (LLMs), they are increasingly applied in areas like intelligent customer service, code generation, and knowledge management. Natural language (NL) prompts act as the ``APIs'' for human-LLM interaction. To improve prompt quality, best practices for prompt engineering (PE) have been developed, including writing guidelines and templates. Building on this, we propose Controlled NL for Prompt (CNL-P), which not only incorporates PE best practices but also draws on key principles from software engineering (SE). CNL-P introduces precise grammar structures and strict semantic norms, further eliminating NL's ambiguity, allowing for a declarative but structured and accurate expression of user intent. This helps LLMs better interpret and execute the prompts, leading to more consistent and higher-quality outputs. We also introduce an NL2CNL-P conversion tool based on LLMs, enabling users to write prompts in NL, which are then transformed into CNL-P format, thus lowering the learning curve of CNL-P. In particular, we develop a linting tool that checks CNL-P prompts for syntactic and semantic accuracy, applying static analysis techniques to NL for the first time. Extensive experiments demonstrate that CNL-P enhances the quality of LLM responses through the novel and organic synergy of PE and SE. We believe that CNL-P can bridge the gap between emerging PE and traditional SE, laying the foundation for a new programming paradigm centered around NL.", 'abstract_zh': '基于软件工程原则的控制自然语言提示（CNL-P）', 'title_zh': '当提示工程遇见软件工程：CNL-P作为人类-人工智能交互的自然且 robust 的“API”'}
{'arxiv_id': 'arXiv:2508.06941', 'title': 'CLAP: Coreference-Linked Augmentation for Passage Retrieval', 'authors': 'Huanwei Xu, Lin Xu, Liang Yuan', 'link': 'https://arxiv.org/abs/2508.06941', 'abstract': 'Large Language Model (LLM)-based passage expansion has shown promise for enhancing first-stage retrieval, but often underperforms with dense retrievers due to semantic drift and misalignment with their pretrained semantic space. Beyond this, only a portion of a passage is typically relevant to a query, while the rest introduces noise--an issue compounded by chunking techniques that break coreference continuity. We propose Coreference-Linked Augmentation for Passage Retrieval (CLAP), a lightweight LLM-based expansion framework that segments passages into coherent chunks, resolves coreference chains, and generates localized pseudo-queries aligned with dense retriever representations. A simple fusion of global topical signals and fine-grained subtopic signals achieves robust performance across domains. CLAP yields consistent gains even as retriever strength increases, enabling dense retrievers to match or surpass second-stage rankers such as BM25 + MonoT5-3B, with up to 20.68% absolute nDCG@10 improvement. These improvements are especially notable in out-of-domain settings, where conventional LLM-based expansion methods relying on domain knowledge often falter. CLAP instead adopts a logic-centric pipeline that enables robust, domain-agnostic generalization.', 'abstract_zh': '基于大型语言模型（LLM）的段落扩展在增强第一阶段检索方面显示出前景，但常常由于语义漂移和与预训练语义空间的不匹配而在密集检索器中表现不佳。此外，通常只有段落的部分内容与查询相关，而其余部分引入了干扰——分块技术破坏核心指称连续性的问题加剧了这一问题。我们提出了一种基于核心指称链接的段落检索增强方法（CLAP），这是一种轻量级的LLM扩展框架，将段落分割为连贯的片段，解决核心指称链，并生成与密集检索器表示对齐的本地伪查询。全局主题信号和细粒度子主题信号的简单融合在不同领域中实现了稳健的性能提升。随着检索器强度的增加，CLAP能够使密集检索器匹配或超越BM25 + MonoT5-3B等第二阶段排名器，绝对nDCG@10提升高达20.68%。这些改进在跨领域设置中尤其显著，而传统的依赖领域知识的LLM扩展方法在此类环境中往往会失效。相反，CLAP采用逻辑为中心的管道，使其能够在不同的领域中实现稳健的、领域的泛化。', 'title_zh': 'CLAP：核心参照连接增强的段落检索'}
{'arxiv_id': 'arXiv:2508.06937', 'title': 'CannyEdit: Selective Canny Control and Dual-Prompt Guidance for Training-Free Image Editing', 'authors': 'Weiyan Xie, Han Gao, Didan Deng, Kaican Li, April Hua Liu, Yongxiang Huang, Nevin L. Zhang', 'link': 'https://arxiv.org/abs/2508.06937', 'abstract': "Recent advances in text-to-image (T2I) models have enabled training-free regional image editing by leveraging the generative priors of foundation models. However, existing methods struggle to balance text adherence in edited regions, context fidelity in unedited areas, and seamless integration of edits. We introduce CannyEdit, a novel training-free framework that addresses these challenges through two key innovations: (1) Selective Canny Control, which masks the structural guidance of Canny ControlNet in user-specified editable regions while strictly preserving details of the source images in unedited areas via inversion-phase ControlNet information retention. This enables precise, text-driven edits without compromising contextual integrity. (2) Dual-Prompt Guidance, which combines local prompts for object-specific edits with a global target prompt to maintain coherent scene interactions. On real-world image editing tasks (addition, replacement, removal), CannyEdit outperforms prior methods like KV-Edit, achieving a 2.93 to 10.49 percent improvement in the balance of text adherence and context fidelity. In terms of editing seamlessness, user studies reveal only 49.2 percent of general users and 42.0 percent of AIGC experts identified CannyEdit's results as AI-edited when paired with real images without edits, versus 76.08 to 89.09 percent for competitor methods.", 'abstract_zh': 'Recent Advances in Training-Free Regional Image Editing via CannyEdit：Selective Canny Control and Dual-Prompt Guidance', 'title_zh': 'CannyEdit：选择性Canny控制与双提示指导的无训练图像编辑'}
{'arxiv_id': 'arXiv:2508.06917', 'title': 'CROP: Integrating Topological and Spatial Structures via Cross-View Prefixes for Molecular LLMs', 'authors': 'Jianting Tang, Yubo Wang, Haoyu Cao, Linli Xu', 'link': 'https://arxiv.org/abs/2508.06917', 'abstract': "Recent advances in molecular science have been propelled significantly by large language models (LLMs). However, their effectiveness is limited when relying solely on molecular sequences, which fail to capture the complex structures of molecules. Beyond sequence representation, molecules exhibit two complementary structural views: the first focuses on the topological relationships between atoms, as exemplified by the graph view; and the second emphasizes the spatial configuration of molecules, as represented by the image view. The two types of views provide unique insights into molecular structures. To leverage these views collaboratively, we propose the CROss-view Prefixes (CROP) to enhance LLMs' molecular understanding through efficient multi-view integration. CROP possesses two advantages: (i) efficiency: by jointly resampling multiple structural views into fixed-length prefixes, it avoids excessive consumption of the LLM's limited context length and allows easy expansion to more views; (ii) effectiveness: by utilizing the LLM's self-encoded molecular sequences to guide the resampling process, it boosts the quality of the generated prefixes. Specifically, our framework features a carefully designed SMILES Guided Resampler for view resampling, and a Structural Embedding Gate for converting the resulting embeddings into LLM's prefixes. Extensive experiments demonstrate the superiority of CROP in tasks including molecule captioning, IUPAC name prediction and molecule property prediction.", 'abstract_zh': 'Recent Advances in Molecular Science Have Been Significantly Propelled by Large Language Models (LLMs): CROss-view Prefixes (CROP) for Enhanced Molecular Understanding Through Efficient Multi-view Integration', 'title_zh': 'CROP: 结合拓扑和空间结构的跨视图前缀方法用于分子LLMs'}
{'arxiv_id': 'arXiv:2508.06908', 'title': 'MMReID-Bench: Unleashing the Power of MLLMs for Effective and Versatile Person Re-identification', 'authors': 'Jinhao Li, Zijian Chen, Lirong Deng, Changbo Wang, Guangtao Zhai', 'link': 'https://arxiv.org/abs/2508.06908', 'abstract': 'Person re-identification (ReID) aims to retrieve the images of an interested person in the gallery images, with wide applications in medical rehabilitation, abnormal behavior detection, and public security. However, traditional person ReID models suffer from uni-modal capability, leading to poor generalization ability in multi-modal data, such as RGB, thermal, infrared, sketch images, textual descriptions, etc. Recently, the emergence of multi-modal large language models (MLLMs) shows a promising avenue for addressing this problem. Despite this potential, existing methods merely regard MLLMs as feature extractors or caption generators, which do not fully unleash their reasoning, instruction-following, and cross-modal understanding capabilities. To bridge this gap, we introduce MMReID-Bench, the first multi-task multi-modal benchmark specifically designed for person ReID. The MMReID-Bench includes 20,710 multi-modal queries and gallery images covering 10 different person ReID tasks. Comprehensive experiments demonstrate the remarkable capabilities of MLLMs in delivering effective and versatile person ReID. Nevertheless, they also have limitations in handling a few modalities, particularly thermal and infrared data. We hope MMReID-Bench can facilitate the community to develop more robust and generalizable multimodal foundation models for person ReID.', 'abstract_zh': '多模态大型语言模型在人员再识别中的多任务多模态基准（MMReID-Bench）', 'title_zh': 'MMReID-Bench: 激发大语言模型在PERSON RE-IDENTIFICATION中高效 versatile的应用潜力'}
{'arxiv_id': 'arXiv:2508.06900', 'title': 'Advancements in Chinese font generation since deep learning era: A survey', 'authors': 'Weiran Chen, Guiqian Zhu, Ying Li, Yi Ji, Chunping Liu', 'link': 'https://arxiv.org/abs/2508.06900', 'abstract': 'Chinese font generation aims to create a new Chinese font library based on some reference samples. It is a topic of great concern to many font designers and typographers. Over the past years, with the rapid development of deep learning algorithms, various new techniques have achieved flourishing and thriving progress. Nevertheless, how to improve the overall quality of generated Chinese character images remains a tough issue. In this paper, we conduct a holistic survey of the recent Chinese font generation approaches based on deep learning. To be specific, we first illustrate the research background of the task. Then, we outline our literature selection and analysis methodology, and review a series of related fundamentals, including classical deep learning architectures, font representation formats, public datasets, and frequently-used evaluation metrics. After that, relying on the number of reference samples required to generate a new font, we categorize the existing methods into two major groups: many-shot font generation and few-shot font generation methods. Within each category, representative approaches are summarized, and their strengths and limitations are also discussed in detail. Finally, we conclude our paper with the challenges and future directions, with the expectation to provide some valuable illuminations for the researchers in this field.', 'abstract_zh': '基于深度学习的中文字体生成研究综述', 'title_zh': '深度学习时代以来的中文字体生成进展：一个综述'}
{'arxiv_id': 'arXiv:2508.06895', 'title': 'BASIC: Boosting Visual Alignment with Intrinsic Refined Embeddings in Multimodal Large Language Models', 'authors': 'Jianting Tang, Yubo Wang, Haoyu Cao, Linli Xu', 'link': 'https://arxiv.org/abs/2508.06895', 'abstract': "Mainstream Multimodal Large Language Models (MLLMs) achieve visual understanding by using a vision projector to bridge well-pretrained vision encoders and large language models (LLMs). The inherent gap between visual and textual modalities makes the embeddings from the vision projector critical for visual comprehension. However, current alignment approaches treat visual embeddings as contextual cues and merely apply auto-regressive supervision to textual outputs, neglecting the necessity of introducing equivalent direct visual supervision, which hinders the potential finer alignment of visual embeddings. In this paper, based on our analysis of the refinement process of visual embeddings in the LLM's shallow layers, we propose BASIC, a method that utilizes refined visual embeddings within the LLM as supervision to directly guide the projector in generating initial visual embeddings. Specifically, the guidance is conducted from two perspectives: (i) optimizing embedding directions by reducing angles between initial and supervisory embeddings in semantic space; (ii) improving semantic matching by minimizing disparities between the logit distributions of both visual embeddings. Without additional supervisory models or artificial annotations, BASIC significantly improves the performance of MLLMs across a wide range of benchmarks, demonstrating the effectiveness of our introduced direct visual supervision.", 'abstract_zh': '主流多模态大型语言模型（MLLMs）通过使用视觉投影器来连接预训练的视觉编码器和大型语言模型（LLMs）以实现视觉理解。视觉和文本模态之间的固有差异使得视觉投影器产生的嵌入对于视觉理解至关重要。然而，当前对齐方法将视觉嵌入视为上下文提示，并仅仅对文本输出应用自回归监督，忽略了引入等效直接视觉监督的必要性，这阻碍了视觉嵌入的潜在细粒度对齐。本文基于对LLM浅层层中视觉嵌入精炼过程的分析，提出了一种名为BASIC的方法，利用嵌入在LLM中的精炼视觉嵌入作为监督，直接引导投影器生成初始视觉嵌入。具体而言，引导从两个角度进行：（i）通过在语义空间中减少初始和监督嵌入之间的角度来优化嵌入方向；（ii）通过最小化两者视觉嵌入的逻辑分布差异来提高语义匹配。无需额外的监督模型或人工注释，BASIC在广泛的标准测试中显著提高了MLLMs的性能，证明了我们引入的直接视觉监督的有效性。', 'title_zh': 'BASIC: 通过内在精炼嵌入提高多模态大语言模型的视觉对齐'}
{'arxiv_id': 'arXiv:2508.06890', 'title': 'Maestro-EVC: Controllable Emotional Voice Conversion Guided by References and Explicit Prosody', 'authors': 'Jinsung Yoon, Wooyeol Jeong, Jio Gim, Young-Joo Suh', 'link': 'https://arxiv.org/abs/2508.06890', 'abstract': 'Emotional voice conversion (EVC) aims to modify the emotional style of speech while preserving its linguistic content. In practical EVC, controllability, the ability to independently control speaker identity and emotional style using distinct references, is crucial. However, existing methods often struggle to fully disentangle these attributes and lack the ability to model fine-grained emotional expressions such as temporal dynamics. We propose Maestro-EVC, a controllable EVC framework that enables independent control of content, speaker identity, and emotion by effectively disentangling each attribute from separate references. We further introduce a temporal emotion representation and an explicit prosody modeling with prosody augmentation to robustly capture and transfer the temporal dynamics of the target emotion, even under prosody-mismatched conditions. Experimental results confirm that Maestro-EVC achieves high-quality, controllable, and emotionally expressive speech synthesis.', 'abstract_zh': '情感语音转换（EVC）旨在保留语音语言内容的同时修改其情感风格。在实际的情感语音转换中，可控性——使用不同的参考独立控制说话人身份和情感风格的能力——至关重要。然而，现有方法往往难以完全分离这些属性，并且缺乏建模精细情感表达如时间动态的能力。我们提出了一种可控的EVC框架Maestro-EVC，通过有效分离每个属性来自不同参考来进行独立控制内容、说话人身份和情感。我们进一步引入了时间情感表示和显式语调建模，并结合语调增强，以在语调不匹配的条件下稳健地捕捉和转移目标情感的时间动态。实验结果证实，Maestro-EVC实现了高质量、可控且情感丰富的语音合成。', 'title_zh': 'Maestro-EVC：受参考和显性语调控制的情感语音转换'}
{'arxiv_id': 'arXiv:2508.06878', 'title': 'NS-FPN: Improving Infrared Small Target Detection and Segmentation from Noise Suppression Perspective', 'authors': 'Maoxun Yuan, Duanni Meng, Ziteng Xi, Tianyi Zhao, Shiji Zhao, Yimian Dai, Xingxing Wei', 'link': 'https://arxiv.org/abs/2508.06878', 'abstract': 'Infrared small target detection and segmentation (IRSTDS) is a critical yet challenging task in defense and civilian applications, owing to the dim, shapeless appearance of targets and severe background clutter. Recent CNN-based methods have achieved promising target perception results, but they only focus on enhancing feature representation to offset the impact of noise, which results in the increased false alarms problem. In this paper, through analyzing the problem from the frequency domain, we pioneer in improving performance from noise suppression perspective and propose a novel noise-suppression feature pyramid network (NS-FPN), which integrates a low-frequency guided feature purification (LFP) module and a spiral-aware feature sampling (SFS) module into the original FPN structure. The LFP module suppresses the noise features by purifying high-frequency components to achieve feature enhancement devoid of noise interference, while the SFS module further adopts spiral sampling to fuse target-relevant features in feature fusion process. Our NS-FPN is designed to be lightweight yet effective and can be easily plugged into existing IRSTDS frameworks. Extensive experiments on the public IRSTDS datasets demonstrate that our method significantly reduces false alarms and achieves superior performance on IRSTDS tasks.', 'abstract_zh': '红外小目标检测与分割（IRSTDS）是国防和民用应用应用中的一项关键但具有挑战性的任务，，，， account 和民用应用应用中（，， 由于目标的昏暗外观和严重的背景杂波。近期近年来，基于卷积神经网络（CNN）的方法在目标感知上取得了显著效果，，但它们仅专注于增强特征以减少噪声的影响，最终导致了增加增加的误报。本研究从噪声抑制的角度分析了该问题，并，并 首次提出了噪声抑制金字塔网络（NS-NPN），该网络结合了低频特征净化（LFP）和螺旋感知采样（SFS）模块。LFP模块通过去除高频分分分分分数来净化噪声特征，以实现在无噪声干扰下的特征增强；SFS模块通过螺旋采样将融合过程中的相关特征融合起来。我们的NS-NPN旨在保持轻轻设计，并且可以很容易地插入现有的IRSTds框架。在设计的irstds数据集上进行了详尽的实验表明，，本方法显著地降低了误报，并在irstds任务上取得了最优效果。', 'title_zh': 'NS-FPN：从噪声抑制视角改进红外小目标检测与分割'}
{'arxiv_id': 'arXiv:2508.06877', 'title': 'ESNERA: Empirical and semantic named entity alignment for named entity dataset merging', 'authors': 'Xiaobo Zhang, Congqing He, Ying He, Jian Peng, Dajie Fu, Tien-Ping Tan', 'link': 'https://arxiv.org/abs/2508.06877', 'abstract': 'Named Entity Recognition (NER) is a fundamental task in natural language processing. It remains a research hotspot due to its wide applicability across domains. Although recent advances in deep learning have significantly improved NER performance, they rely heavily on large, high-quality annotated datasets. However, building these datasets is expensive and time-consuming, posing a major bottleneck for further research. Current dataset merging approaches mainly focus on strategies like manual label mapping or constructing label graphs, which lack interpretability and scalability. To address this, we propose an automatic label alignment method based on label similarity. The method combines empirical and semantic similarities, using a greedy pairwise merging strategy to unify label spaces across different datasets. Experiments are conducted in two stages: first, merging three existing NER datasets into a unified corpus with minimal impact on NER performance; second, integrating this corpus with a small-scale, self-built dataset in the financial domain. The results show that our method enables effective dataset merging and enhances NER performance in the low-resource financial domain. This study presents an efficient, interpretable, and scalable solution for integrating multi-source NER corpora.', 'abstract_zh': '命名实体识别（NER）是自然语言处理中的一个基础任务。尽管近期深度学习的发展显著提升了NER的性能，但它们对大规模的高质量标注数据集有高度依赖。然而，构建这些数据集既耗时又昂贵，成为进一步研究的主要瓶颈。当前的数据集合并方法主要关注如手动标签映射或构建标签图等策略，缺乏解释性和扩展性。为此，我们提出了一种基于标签相似性的自动标签对齐方法。该方法结合了经验相似性和语义相似性，采用贪婪的成对合并策略，在不同数据集中统一标签空间。实验分两阶段进行：首先，将三个现有的NER数据集合并成一个统一的语料库，对NER性能的影响最小；其次，将这个语料库与一个自建的金融小规模数据集进行整合。结果显示，我们的方法实现了有效的数据集合并，并提升了低资源金融领域中的NER性能。本研究提供了一种高效、可解释和可扩展的多源NER语料库整合解决方案。', 'title_zh': 'ESNERA：基于实证和语义的命名实体对齐以实现命名实体数据集合并'}
{'arxiv_id': 'arXiv:2508.06871', 'title': 'Sparsity-Driven Plasticity in Multi-Task Reinforcement Learning', 'authors': 'Aleksandar Todorov, Juan Cardenas-Cartagena, Rafael F. Cunha, Marco Zullich, Matthia Sabatelli', 'link': 'https://arxiv.org/abs/2508.06871', 'abstract': 'Plasticity loss, a diminishing capacity to adapt as training progresses, is a critical challenge in deep reinforcement learning. We examine this issue in multi-task reinforcement learning (MTRL), where higher representational flexibility is crucial for managing diverse and potentially conflicting task demands. We systematically explore how sparsification methods, particularly Gradual Magnitude Pruning (GMP) and Sparse Evolutionary Training (SET), enhance plasticity and consequently improve performance in MTRL agents. We evaluate these approaches across distinct MTRL architectures (shared backbone, Mixture of Experts, Mixture of Orthogonal Experts) on standardized MTRL benchmarks, comparing against dense baselines, and a comprehensive range of alternative plasticity-inducing or regularization methods. Our results demonstrate that both GMP and SET effectively mitigate key indicators of plasticity degradation, such as neuron dormancy and representational collapse. These plasticity improvements often correlate with enhanced multi-task performance, with sparse agents frequently outperforming dense counterparts and achieving competitive results against explicit plasticity interventions. Our findings offer insights into the interplay between plasticity, network sparsity, and MTRL designs, highlighting dynamic sparsification as a robust but context-sensitive tool for developing more adaptable MTRL systems.', 'abstract_zh': '塑料性丧失在训练过程中适应能力的逐步减弱是深度强化学习中的一个关键挑战。我们研究了这一问题在多任务强化学习（MTRL）中的表现，其中更高的表示灵活性对于管理多种潜在冲突的任务需求至关重要。我们系统地探讨了剪枝方法（特别是渐进量值剪枝GMP和稀疏进化训练SET）如何增强塑料性并从而提高MTRL代理的表现。我们在标准化的MTRL基准上评估了这些方法在不同的MTRL架构（共享骨干、专家混合、正交专家混合）中的效果，对比了密集基线方法以及一系列其他增强塑料性或正则化的方法。我们的结果表明，GMP和SET都能有效缓解关键的塑料性退化指标，如神经元休眠和表示塌陷。这些塑料性的改进通常与多任务性能的提升相关，稀疏代理经常优于密集代理，并且在某些情况下可以与显式增强塑料性的干预措施相媲美。我们的研究为塑料性、网络稀疏性和MTRL设计之间的相互作用提供了见解，突出了动态稀疏化作为一种稳健但具有上下文敏感性的工具，对于开发更具适应性的MTRL系统的重要性。', 'title_zh': '多任务强化学习中的稀疏驱动塑性'}
{'arxiv_id': 'arXiv:2508.06869', 'title': 'VSI: Visual Subtitle Integration for Keyframe Selection to enhance Long Video Understanding', 'authors': 'Jianxiang He, Shaoguang Wang, Weiyu Guo, Meisheng Hong, Jungang Li, Yijie Xu, Ziyang Chen, Hui Xiong', 'link': 'https://arxiv.org/abs/2508.06869', 'abstract': 'Long video understanding presents a significant challenge to multimodal large language models (MLLMs) primarily due to the immense data scale. A critical and widely adopted strategy for making this task computationally tractable is keyframe retrieval, which seeks to identify a sparse set of video frames that are most salient to a given textual query. However, the efficacy of this approach is hindered by weak multimodal alignment between textual queries and visual content and fails to capture the complex temporal semantic information required for precise reasoning. To address this, we propose Visual-Subtitle Integeration(VSI), a multimodal keyframe search method that integrates subtitles, timestamps, and scene boundaries into a unified multimodal search process. The proposed method captures the visual information of video frames as well as the complementary textual information through a dual-stream search mechanism by Video Search Stream as well as Subtitle Match Stream, respectively, and improves the keyframe search accuracy through the interaction of the two search streams. Experimental results show that VSI achieve 40.00% key frame localization accuracy on the text-relevant subset of LongVideoBench and 68.48% accuracy on downstream long Video-QA tasks, surpassing competitive baselines by 20.35% and 15.79%, respectively. Furthermore, on the LongVideoBench, VSI achieved state-of-the-art(SOTA) in medium-to-long video-QA tasks, demonstrating the robustness and generalizability of the proposed multimodal search strategy.', 'abstract_zh': '长视频理解对多模态大规模语言模型构成重大挑战，主要是由于数据量巨大。为了使这一任务在计算上可处理，关键且广泛采用的策略是关键帧检索，该策略旨在识别出最能反映给定文本查询的稀疏视频帧集合。然而，这种做法的有效性受到文本查询与视觉内容之间弱的多模态对齐的阻碍，并且无法捕捉到进行精确推理所需的复杂时间语义信息。为解决这一问题，我们提出了一种名为Visual-Subtitle Integration (VSI)的多模态关键帧搜索方法，该方法将字幕、时间戳和场景边界整合到统一的多模态搜索过程中。所提出的方法通过视频搜索流和字幕匹配流的双流搜索机制捕获视频帧的视觉信息以及互补的文本信息，并通过两个搜索流的交互来提高关键帧搜索的准确性。实验结果显示，VSI在LongVideoBench的文本相关子集上实现了40.00%的关键帧定位准确率，并在下游长视频-QA任务上的准确率达到68.48%，分别超出竞争基线20.35%和15.79%。此外，在LongVideoBench上，VSI在中到长视频-QA任务中达到了最先进的性能，展示了所提出的多模态搜索策略的鲁棒性和泛化能力。', 'title_zh': '基于视觉字幕集成的关键帧选择以增强长视频理解'}
{'arxiv_id': 'arXiv:2508.06853', 'title': 'AGIC: Attention-Guided Image Captioning to Improve Caption Relevance', 'authors': 'L. D. M. S. Sai Teja, Ashok Urlana, Pruthwik Mishra', 'link': 'https://arxiv.org/abs/2508.06853', 'abstract': 'Despite significant progress in image captioning, generating accurate and descriptive captions remains a long-standing challenge. In this study, we propose Attention-Guided Image Captioning (AGIC), which amplifies salient visual regions directly in the feature space to guide caption generation. We further introduce a hybrid decoding strategy that combines deterministic and probabilistic sampling to balance fluency and diversity. To evaluate AGIC, we conduct extensive experiments on the Flickr8k and Flickr30k datasets. The results show that AGIC matches or surpasses several state-of-the-art models while achieving faster inference. Moreover, AGIC demonstrates strong performance across multiple evaluation metrics, offering a scalable and interpretable solution for image captioning.', 'abstract_zh': '基于注意力引导的图像caption生成（AGIC）：直接在特征空间增强显著视觉区域以指导caption生成', 'title_zh': 'AGIC：注意力引导的图像字幕生成以提高字幕的相关性性\nuser\n纠正上面的翻译，_feed精确一点ankan谢谢。标题：AGIC: Attention-Guided Image Captioning to Improve Caption Relevance。'}
{'arxiv_id': 'arXiv:2508.06849', 'title': 'Towards Experience-Centered AI: A Framework for Integrating Lived Experience in Design and Development', 'authors': 'Sanjana Gautam, Mohit Chandra, Ankolika De, Tatiana Chakravorti, Girik Malik, Munmun De Choudhury', 'link': 'https://arxiv.org/abs/2508.06849', 'abstract': 'Lived experiences fundamentally shape how individuals interact with AI systems, influencing perceptions of safety, trust, and usability. While prior research has focused on developing techniques to emulate human preferences, and proposed taxonomies to categorize risks (such as psychological harms and algorithmic biases), these efforts have provided limited systematic understanding of lived human experiences or actionable strategies for embedding them meaningfully into the AI development lifecycle. This work proposes a framework for meaningfully integrating lived experience into the design and evaluation of AI systems. We synthesize interdisciplinary literature across lived experience philosophy, human-centered design, and human-AI interaction, arguing that centering lived experience can lead to models that more accurately reflect the retrospective, emotional, and contextual dimensions of human cognition. Drawing from a wide body of work across psychology, education, healthcare, and social policy, we present a targeted taxonomy of lived experiences with specific applicability to AI systems. To ground our framework, we examine three application domains (i) education, (ii) healthcare, and (iii) cultural alignment, illustrating how lived experience informs user goals, system expectations, and ethical considerations in each context. We further incorporate insights from AI system operators and human-AI partnerships to highlight challenges in responsibility allocation, mental model calibration, and long-term system adaptation. We conclude with actionable recommendations for developing experience-centered AI systems that are not only technically robust but also empathetic, context-aware, and aligned with human realities. This work offers a foundation for future research that bridges technical development with the lived experiences of those impacted by AI systems.', 'abstract_zh': '现实生活体验从根本上塑造了个体与AI系统互动的方式，影响着对安全、信任和可用性的感知。尽管先前的研究集中在开发模拟人类偏好的技术，并提出了风险分类法（如心理伤害和算法偏见），但这些努力仅为有限地提供了关于现实生活体验的系统理解或将其嵌入AI开发生命周期的实际策略。本文提出了一种框架，用于有意义地将现实生活体验整合到AI系统的 设计和评估中。我们综合了生活体验哲学、以用户为中心的设计和人机交互领域的跨学科文献，认为以现实生活体验为中心可以导致更准确反映人类认知的回顾性、情感性和情境性维度的模型。通过心理学、教育、医疗保健和社会政策领域的大量研究，我们提出了一个针对AI系统的具体适用的生活体验分类。为了构建这一框架，我们探讨了三个应用领域：(i) 教育，(ii) 医疗保健，以及(iii) 文化对齐，展示了现实生活体验如何在每个情境中影响用户目标、系统期望和伦理考量。进一步地，我们结合了AI系统运营商和人机合作领域的洞察，突出了责任分配、心智模型校准和系统长期适应等方面的挑战。最后，我们提出了开发以体验为中心的AI系统的可行建议，这些系统不仅技术上可靠，而且具有同理心、情境意识，并与人类现实保持一致。本文为未来将技术开发与受AI系统影响的现实生活体验相结合的研究奠定了基础。', 'title_zh': '面向体验中心的人工智能：一个将生活体验融合到设计与开发中的框架'}
{'arxiv_id': 'arXiv:2508.06846', 'title': 'Highlight All the Phrases: Enhancing LLM Transparency through Visual Factuality Indicators', 'authors': 'Hyo Jin Do, Rachel Ostrand, Werner Geyer, Keerthiram Murugesan, Dennis Wei, Justin Weisz', 'link': 'https://arxiv.org/abs/2508.06846', 'abstract': 'Large language models (LLMs) are susceptible to generating inaccurate or false information, often referred to as "hallucinations" or "confabulations." While several technical advancements have been made to detect hallucinated content by assessing the factuality of the model\'s responses, there is still limited research on how to effectively communicate this information to users. To address this gap, we conducted two scenario-based experiments with a total of 208 participants to systematically compare the effects of various design strategies for communicating factuality scores by assessing participants\' ratings of trust, ease in validating response accuracy, and preference. Our findings reveal that participants preferred and trusted a design in which all phrases within a response were color-coded based on factuality scores. Participants also found it easier to validate accuracy of the response in this style compared to a baseline with no style applied. Our study offers practical design guidelines for LLM application developers and designers, aimed at calibrating user trust, aligning with user preferences, and enhancing users\' ability to scrutinize LLM outputs.', 'abstract_zh': '大型语言模型（LLMs）容易生成不准确或虚假信息，通常被称为“幻觉”或“虚构”。虽然已经进行了多项技术进步以通过评估模型响应的事实性来检测幻觉内容，但在有效向用户传达这些信息方面仍存在有限的研究。为了填补这一空白，我们进行了两项基于场景的实验，涉及208名参与者，系统地比较了传达事实性评分的各种设计策略的效果，评估了参与者对信任度、验证响应准确性便利性的评分，以及偏好度。研究发现，参与者更偏好且更信任一种设计，即根据事实性评分对所有响应中的短语进行着色。此外，参与者发现这种风格更容易验证响应准确性，相比之下，一种没有应用任何风格的基线设计则更难验证。本研究为LLM应用程序开发人员和设计师提供了实用的设计指南，旨在校准用户信任度、与用户偏好保持一致，并增强用户审查LLM输出的能力。', 'title_zh': '突出所有短语：通过视觉事实性指示提升大语言模型透明度'}
{'arxiv_id': 'arXiv:2508.06827', 'title': "Who's the Evil Twin? Differential Auditing for Undesired Behavior", 'authors': 'Ishwar Balappanawar, Venkata Hasith Vattikuti, Greta Kintzley, Ronan Azimi-Mancel, Satvik Golechha', 'link': 'https://arxiv.org/abs/2508.06827', 'abstract': 'Detecting hidden behaviors in neural networks poses a significant challenge due to minimal prior knowledge and potential adversarial obfuscation. We explore this problem by framing detection as an adversarial game between two teams: the red team trains two similar models, one trained solely on benign data and the other trained on data containing hidden harmful behavior, with the performance of both being nearly indistinguishable on the benign dataset. The blue team, with limited to no information about the harmful behaviour, tries to identify the compromised model. We experiment using CNNs and try various blue team strategies, including Gaussian noise analysis, model diffing, integrated gradients, and adversarial attacks under different levels of hints provided by the red team. Results show high accuracy for adversarial-attack-based methods (100\\% correct prediction, using hints), which is very promising, whilst the other techniques yield more varied performance. During our LLM-focused rounds, we find that there are not many parallel methods that we could apply from our study with CNNs. Instead, we find that effective LLM auditing methods require some hints about the undesired distribution, which can then used in standard black-box and open-weight methods to probe the models further and reveal their misalignment. We open-source our auditing games (with the model and data) and hope that our findings contribute to designing better audits.', 'abstract_zh': '检测神经网络中的隐藏行为由于缺乏先验知识和潜在的 adversarial 模糊化而极具挑战性。我们通过将检测问题构建成两队之间的 adversarial 游戏来探索这一问题：红队训练两个类似模型，一个仅在良性数据上训练，另一个在包含隐藏有害行为的数据上训练，两个模型在良性数据集上的性能几乎无法区分。蓝队在其对有害行为了解有限的情况下，尝试识别受损模型。我们使用 CNN 进行实验，并尝试了各种蓝队策略，包括高斯噪声分析、模型差异分析、整合梯度方法以及在不同水平的红队提示下进行的 adversarial 攻击。结果显示基于 adversarial 攻击的方法具有高准确率（100% 正确预测，使用提示），这非常 promising，而其他技术则表现出更不一致的性能。在我们 LLM 重点关注的部分，我们发现没有多少与使用 CNN 的研究结果相平行的方法可以应用。相反，我们发现有效的 LLM 审计方法需要关于不希望的分布的一些提示，然后可以将其用于标准的黑盒和开放权重方法以进一步探究模型并揭示其不一致。我们开源了我们的审计游戏（包括模型和数据），并希望我们的发现能有助于设计更好的审计方法。', 'title_zh': '谁是邪恶双胞胎？不同行为的审计'}
{'arxiv_id': 'arXiv:2508.06811', 'title': 'Anatomy of a Machine Learning Ecosystem: 2 Million Models on Hugging Face', 'authors': 'Benjamin Laufer, Hamidah Oderinwale, Jon Kleinberg', 'link': 'https://arxiv.org/abs/2508.06811', 'abstract': "Many have observed that the development and deployment of generative machine learning (ML) and artificial intelligence (AI) models follow a distinctive pattern in which pre-trained models are adapted and fine-tuned for specific downstream tasks. However, there is limited empirical work that examines the structure of these interactions. This paper analyzes 1.86 million models on Hugging Face, a leading peer production platform for model development. Our study of model family trees -- networks that connect fine-tuned models to their base or parent -- reveals sprawling fine-tuning lineages that vary widely in size and structure. Using an evolutionary biology lens to study ML models, we use model metadata and model cards to measure the genetic similarity and mutation of traits over model families. We find that models tend to exhibit a family resemblance, meaning their genetic markers and traits exhibit more overlap when they belong to the same model family. However, these similarities depart in certain ways from standard models of asexual reproduction, because mutations are fast and directed, such that two `sibling' models tend to exhibit more similarity than parent/child pairs. Further analysis of the directional drifts of these mutations reveals qualitative insights about the open machine learning ecosystem: Licenses counter-intuitively drift from restrictive, commercial licenses towards permissive or copyleft licenses, often in violation of upstream license's terms; models evolve from multi-lingual compatibility towards english-only compatibility; and model cards reduce in length and standardize by turning, more often, to templates and automatically generated text. Overall, this work takes a step toward an empirically grounded understanding of model fine-tuning and suggests that ecological models and methods can yield novel scientific insights.", 'abstract_zh': '许多研究观察到生成机器学习（ML）和人工智能（AI）模型的开发和部署遵循一个独特模式，即预训练模型调整和微调以适应特定下游任务。然而，对这些交互的结构进行系统研究的经验工作有限。本文分析了Hugging Face上的186万个模型，这是一个领先的模型开发协同生产平台。通过对模型族系树——连接微调模型与其基础或祖先模型的网络——的研究，揭示了广泛多样且结构各异的微调谱系。从演化生物学的角度研究ML模型，我们利用模型元数据和模型卡片来衡量模型家族中遗传相似性和特征变异度。研究发现，模型通常表现出家族相似性，即当它们属于同一模型家族时，其遗传标志和特征更具有重叠性。然而，这些相似性在某些方面与无性生殖的标准模型有所偏离，因为变异速度快且方向性明显，使得两个“兄弟”模型比亲子对更具有相似性。进一步分析这些变异的方向性漂移揭示了开源机器学习生态系统的定性洞察：许可协议出人意料地从限制性、商业许可向更宽松或 copyleft 许可转变，常常违反上游许可的条款；模型从多语言兼容性向仅英语兼容性演变；并且模型卡片变短并标准化，更多地转向模板和自动生成的文字。总体而言，这项工作朝着基于经验理解模型微调迈出了一步，并表明生态学模型和方法可以产生新的科学见解。', 'title_zh': '机器学习生态系统解构：Hugging Face 上的 200 万模型'}
{'arxiv_id': 'arXiv:2508.06806', 'title': 'Offline-to-Online Reinforcement Learning with Classifier-Free Diffusion Generation', 'authors': 'Xiao Huang, Xu Liu, Enze Zhang, Tong Yu, Shuai Li', 'link': 'https://arxiv.org/abs/2508.06806', 'abstract': "Offline-to-online Reinforcement Learning (O2O RL) aims to perform online fine-tuning on an offline pre-trained policy to minimize costly online interactions. Existing work used offline datasets to generate data that conform to the online data distribution for data augmentation. However, generated data still exhibits a gap with the online data, limiting overall performance. To address this, we propose a new data augmentation approach, Classifier-Free Diffusion Generation (CFDG). Without introducing additional classifier training overhead, CFDG leverages classifier-free guidance diffusion to significantly enhance the generation quality of offline and online data with different distributions. Additionally, it employs a reweighting method to enable more generated data to align with the online data, enhancing performance while maintaining the agent's stability. Experimental results show that CFDG outperforms replaying the two data types or using a standard diffusion model to generate new data. Our method is versatile and can be integrated with existing offline-to-online RL algorithms. By implementing CFDG to popular methods IQL, PEX and APL, we achieve a notable 15% average improvement in empirical performance on the D4RL benchmark such as MuJoCo and AntMaze.", 'abstract_zh': 'Offline-to-Online强化学习（O2O RL）旨在对离线预训练策略进行在线微调，以减少昂贵的在线交互。现有工作利用离线数据集生成符合在线数据分布的数据进行数据增强。然而，生成的数据仍然与在线数据存在差距，限制了整体性能。为解决这一问题，我们提出了一种新的数据增强方法——无分类器扩散生成（CFDG）。该方法不引入额外的分类器训练开销，通过分类器无关的引导扩散显著提高不同分布的离线和在线数据的生成质量。此外，它采用重权方法使更多生成的数据与在线数据对齐，提升性能同时保持代理的稳定性。实验结果表明，CFDG在D4RL基准测试如MuJoCo和AntMaze上实现了显著的平均15%性能提升，优于直接回放两种类型的数据或使用标准扩散模型生成新数据。本方法具有通用性，可与现有的Offline-to-Online RL算法无缝集成。', 'title_zh': '离线到在线强化学习结合分类器无辅助扩散生成'}
{'arxiv_id': 'arXiv:2508.06800', 'title': 'Hardness-Aware Dynamic Curriculum Learning for Robust Multimodal Emotion Recognition with Missing Modalities', 'authors': 'Rui Liu, Haolin Zuo, Zheng Lian, Hongyu Yuan, Qi Fan', 'link': 'https://arxiv.org/abs/2508.06800', 'abstract': "Missing modalities have recently emerged as a critical research direction in multimodal emotion recognition (MER). Conventional approaches typically address this issue through missing modality reconstruction. However, these methods fail to account for variations in reconstruction difficulty across different samples, consequently limiting the model's ability to handle hard samples effectively. To overcome this limitation, we propose a novel Hardness-Aware Dynamic Curriculum Learning framework, termed HARDY-MER. Our framework operates in two key stages: first, it estimates the hardness level of each sample, and second, it strategically emphasizes hard samples during training to enhance model performance on these challenging instances. Specifically, we first introduce a Multi-view Hardness Evaluation mechanism that quantifies reconstruction difficulty by considering both Direct Hardness (modality reconstruction errors) and Indirect Hardness (cross-modal mutual information). Meanwhile, we introduce a Retrieval-based Dynamic Curriculum Learning strategy that dynamically adjusts the training curriculum by retrieving samples with similar semantic information and balancing the learning focus between easy and hard instances. Extensive experiments on benchmark datasets demonstrate that HARDY-MER consistently outperforms existing methods in missing-modality scenarios. Our code will be made publicly available at this https URL.", 'abstract_zh': '缺失模态 Recent Progresses in Multimodal Emotion Recognition: A Hardness-Aware Dynamic Curriculum Learning Framework (HARDY-MER)', 'title_zh': '基于硬度感知的动态课程学习以实现鲁棒多模态情感识别，考虑缺失模态'}
{'arxiv_id': 'arXiv:2508.06799', 'title': 'LSDTs: LLM-Augmented Semantic Digital Twins for Adaptive Knowledge-Intensive Infrastructure Planning', 'authors': 'Naiyi Li, Zihui Ma, Runlong Yu, Lingyao Li', 'link': 'https://arxiv.org/abs/2508.06799', 'abstract': 'Digital Twins (DTs) offer powerful tools for managing complex infrastructure systems, but their effectiveness is often limited by challenges in integrating unstructured knowledge. Recent advances in Large Language Models (LLMs) bring new potential to address this gap, with strong abilities in extracting and organizing diverse textual information. We therefore propose LSDTs (LLM-Augmented Semantic Digital Twins), a framework that helps LLMs extract planning knowledge from unstructured documents like environmental regulations and technical guidelines, and organize it into a formal ontology. This ontology forms a semantic layer that powers a digital twin-a virtual model of the physical system-allowing it to simulate realistic, regulation-aware planning scenarios. We evaluate LSDTs through a case study of offshore wind farm planning in Maryland, including its application during Hurricane Sandy. Results demonstrate that LSDTs support interpretable, regulation-aware layout optimization, enable high-fidelity simulation, and enhance adaptability in infrastructure planning. This work shows the potential of combining generative AI with digital twins to support complex, knowledge-driven planning tasks.', 'abstract_zh': 'LLM增强语义数字孪生（LSDTs）：一种融合结构化知识的数字孪生框架', 'title_zh': 'LSDTs：增强语义数字孪生的LLM辅助知识密集型基础设施规划'}
{'arxiv_id': 'arXiv:2508.06793', 'title': 'Geometry-Aware Spiking Graph Neural Network', 'authors': 'Bowen Zhang, Genan Dai, Hu Huang, Long Lan', 'link': 'https://arxiv.org/abs/2508.06793', 'abstract': 'Graph Neural Networks (GNNs) have demonstrated impressive capabilities in modeling graph-structured data, while Spiking Neural Networks (SNNs) offer high energy efficiency through sparse, event-driven computation. However, existing spiking GNNs predominantly operate in Euclidean space and rely on fixed geometric assumptions, limiting their capacity to model complex graph structures such as hierarchies and cycles. To overcome these limitations, we propose \\method{}, a novel Geometry-Aware Spiking Graph Neural Network that unifies spike-based neural dynamics with adaptive representation learning on Riemannian manifolds. \\method{} features three key components: a Riemannian Embedding Layer that projects node features into a pool of constant-curvature manifolds, capturing non-Euclidean structures; a Manifold Spiking Layer that models membrane potential evolution and spiking behavior in curved spaces via geometry-consistent neighbor aggregation and curvature-based attention; and a Manifold Learning Objective that enables instance-wise geometry adaptation through jointly optimized classification and link prediction losses defined over geodesic distances. All modules are trained using Riemannian SGD, eliminating the need for backpropagation through time. Extensive experiments on multiple benchmarks show that GSG achieves superior accuracy, robustness, and energy efficiency compared to both Euclidean SNNs and manifold-based GNNs, establishing a new paradigm for curvature-aware, energy-efficient graph learning.', 'abstract_zh': '几何感知刺激发散图神经网络（Geometry-Aware Spiking Graph Neural Network）：基于黎曼流形的自适应表示学习', 'title_zh': '几何感知脉冲图神经网络'}
{'arxiv_id': 'arXiv:2508.06784', 'title': 'Mode-Aware Non-Linear Tucker Autoencoder for Tensor-based Unsupervised Learning', 'authors': 'Junjing Zheng, Chengliang Song, Weidong Jiang, Xinyu Zhang', 'link': 'https://arxiv.org/abs/2508.06784', 'abstract': "High-dimensional data, particularly in the form of high-order tensors, presents a major challenge in self-supervised learning. While MLP-based autoencoders (AE) are commonly employed, their dependence on flattening operations exacerbates the curse of dimensionality, leading to excessively large model sizes, high computational overhead, and challenging optimization for deep structural feature capture. Although existing tensor networks alleviate computational burdens through tensor decomposition techniques, most exhibit limited capability in learning non-linear relationships. To overcome these limitations, we introduce the Mode-Aware Non-linear Tucker Autoencoder (MA-NTAE). MA-NTAE generalized classical Tucker decomposition to a non-linear framework and employs a Pick-and-Unfold strategy, facilitating flexible per-mode encoding of high-order tensors via recursive unfold-encode-fold operations, effectively integrating tensor structural priors. Notably, MA-NTAE exhibits linear growth in computational complexity with tensor order and proportional growth with mode dimensions. Extensive experiments demonstrate MA-NTAE's performance advantages over standard AE and current tensor networks in compression and clustering tasks, which become increasingly pronounced for higher-order, higher-dimensional tensors.", 'abstract_zh': '高阶张量感知的模式aware非线性Tucker自编码器', 'title_zh': '面向模式的非线性Tucker自编码器用于张量驱动的无监督学习'}
{'arxiv_id': 'arXiv:2508.06783', 'title': 'PROPS: Progressively Private Self-alignment of Large Language Models', 'authors': 'Noel Teku, Fengwei Tian, Payel Bhattacharjee, Souradip Chakraborty, Amrit Singh Bedi, Ravi Tandon', 'link': 'https://arxiv.org/abs/2508.06783', 'abstract': "Alignment is a key step in developing Large Language Models (LLMs) using human feedback to ensure adherence to human values and societal norms. Dependence on human feedback raises privacy concerns about how much a labeler's preferences may reveal about their personal values, beliefs, and personality traits. Existing approaches, such as Differentially Private SGD (DP-SGD), provide rigorous privacy guarantees by privatizing gradients during fine-tuning and alignment but can provide more privacy than necessary as human preferences are tied only to labels of (prompt, response) pairs and can degrade model utility. This work focuses on LLM alignment with preference-level privacy, which preserves the privacy of preference labels provided by humans. We propose PROPS (PROgressively Private Self-alignment), a multi-stage privacy preserving alignment framework where privately aligned models in previous stages can serve as labelers for supplementing training data in the subsequent stages of alignment. We present theoretical guarantees for PROPS as well as comprehensive validation using multiple models (Pythia and GPT) and datasets (AlpacaEval, Anthropic HH-RLHF, truthy-dpo-v0.1) to demonstrate the utility of PROPS over existing methods while still providing high privacy. For the same privacy budget, alignment via PROPS can achieve up to 3x higher win-rates compared to DP-SGD, and 2.5x higher win-rates compared to Randomized Response (RR) based alignment.", 'abstract_zh': '偏好级隐私的大规模语言模型对齐方法', 'title_zh': 'PROPS：渐进式大型语言模型的私密自对齐'}
{'arxiv_id': 'arXiv:2508.06781', 'title': 'BiXSE: Improving Dense Retrieval via Probabilistic Graded Relevance Distillation', 'authors': 'Christos Tsirigotis, Vaibhav Adlakha, Joao Monteiro, Aaron Courville, Perouz Taslakian', 'link': 'https://arxiv.org/abs/2508.06781', 'abstract': 'Neural sentence embedding models for dense retrieval typically rely on binary relevance labels, treating query-document pairs as either relevant or irrelevant. However, real-world relevance often exists on a continuum, and recent advances in large language models (LLMs) have made it feasible to scale the generation of fine-grained graded relevance labels. In this work, we propose BiXSE, a simple and effective pointwise training method that optimizes binary cross-entropy (BCE) over LLM-generated graded relevance scores. BiXSE interprets these scores as probabilistic targets, enabling granular supervision from a single labeled query-document pair per query. Unlike pairwise or listwise losses that require multiple annotated comparisons per query, BiXSE achieves strong performance with reduced annotation and compute costs by leveraging in-batch negatives. Extensive experiments across sentence embedding (MMTEB) and retrieval benchmarks (BEIR, TREC-DL) show that BiXSE consistently outperforms softmax-based contrastive learning (InfoNCE), and matches or exceeds strong pairwise ranking baselines when trained on LLM-supervised data. BiXSE offers a robust, scalable alternative for training dense retrieval models as graded relevance supervision becomes increasingly accessible.', 'abstract_zh': '基于大型语言模型的分级相关性标签的二元交叉熵优化方法：BiXSE在密集检索中的应用', 'title_zh': 'BiXSE：通过概率分级相关性蒸馏改进密集检索'}
{'arxiv_id': 'arXiv:2508.06776', 'title': 'Zero-Direction Probing: A Linear-Algebraic Framework for Deep Analysis of Large-Language-Model Drift', 'authors': 'Amit Pandey', 'link': 'https://arxiv.org/abs/2508.06776', 'abstract': 'We present Zero-Direction Probing (ZDP), a theory-only framework for detecting model drift from null directions of transformer activations without task labels or output evaluations. Under assumptions A1--A6, we prove: (i) the Variance--Leak Theorem, (ii) Fisher Null-Conservation, (iii) a Rank--Leak bound for low-rank updates, and (iv) a logarithmic-regret guarantee for online null-space trackers. We derive a Spectral Null-Leakage (SNL) metric with non-asymptotic tail bounds and a concentration inequality, yielding a-priori thresholds for drift under a Gaussian null model. These results show that monitoring right/left null spaces of layer activations and their Fisher geometry provides concrete, testable guarantees on representational change.', 'abstract_zh': 'Zero- 方向 特性盎 透视（ZDP）：一种基于变换器激活空置方向的唯一性偏探检测框架——', 'title_zh': '零方向探针：大型语言模型漂移的线性代数框架深入分析'}
{'arxiv_id': 'arXiv:2508.06767', 'title': 'PANAMA: A Network-Aware MARL Framework for Multi-Agent Path Finding in Digital Twin Ecosystems', 'authors': 'Arman Dogru, R. Irem Bor-Yaliniz, Nimal Gamini Senarath', 'link': 'https://arxiv.org/abs/2508.06767', 'abstract': 'Digital Twins (DTs) are transforming industries through advanced data processing and analysis, positioning the world of DTs, Digital World, as a cornerstone of nextgeneration technologies including embodied AI. As robotics and automated systems scale, efficient data-sharing frameworks and robust algorithms become critical. We explore the pivotal role of data handling in next-gen networks, focusing on dynamics between application and network providers (AP/NP) in DT ecosystems. We introduce PANAMA, a novel algorithm with Priority Asymmetry for Network Aware Multi-agent Reinforcement Learning (MARL) based multi-agent path finding (MAPF). By adopting a Centralized Training with Decentralized Execution (CTDE) framework and asynchronous actor-learner architectures, PANAMA accelerates training while enabling autonomous task execution by embodied AI. Our approach demonstrates superior pathfinding performance in accuracy, speed, and scalability compared to existing benchmarks. Through simulations, we highlight optimized data-sharing strategies for scalable, automated systems, ensuring resilience in complex, real-world environments. PANAMA bridges the gap between network-aware decision-making and robust multi-agent coordination, advancing the synergy between DTs, wireless networks, and AI-driven automation.', 'abstract_zh': '数字孪生（DTs）通过先进数据处理和分析重塑产业，将数字世界定位为下一代技术包括具身AI的核心基石。随着机器人技术和自动化系统的扩展，高效的数据共享框架和 robust 算法变得至关重要。我们探讨了在数字孪生生态系统中数据处理在下一代网络中的关键作用，重点关注应用和网络提供商之间的动态互动。我们介绍了一种名为PANAMA的新算法，该算法基于多智能体强化学习（MARL）的多智能体路径查找（MAPF），采用了中心化训练与去中心化执行（CTDE）框架以及异步演员-学习者架构，加速了训练并使具身AI能够自主执行任务。我们的方法在准确性、速度和可扩展性方面优于现有基准。通过仿真，我们展示了为可扩展自动化系统优化的数据共享策略，确保在复杂实际环境中的弹性。PANAMA填补了网络意识决策与 robust 多智能体协调之间的 gap，推动了数字孪生、无线网络和AI驱动自动化之间的协同进步。', 'title_zh': 'PANAMA：用于数字孪生生态系统中多agent路径规划的网络感知MARL框架'}
{'arxiv_id': 'arXiv:2508.06763', 'title': 'SafePLUG: Empowering Multimodal LLMs with Pixel-Level Insight and Temporal Grounding for Traffic Accident Understanding', 'authors': 'Zihao Sheng, Zilin Huang, Yen-Jung Chen, Yansong Qu, Yuhao Luo, Yue Leng, Sikai Chen', 'link': 'https://arxiv.org/abs/2508.06763', 'abstract': 'Multimodal large language models (MLLMs) have achieved remarkable progress across a range of vision-language tasks and demonstrate strong potential for traffic accident understanding. However, existing MLLMs in this domain primarily focus on coarse-grained image-level or video-level comprehension and often struggle to handle fine-grained visual details or localized scene components, limiting their applicability in complex accident scenarios. To address these limitations, we propose SafePLUG, a novel framework that empowers MLLMs with both Pixel-Level Understanding and temporal Grounding for comprehensive traffic accident analysis. SafePLUG supports both arbitrary-shaped visual prompts for region-aware question answering and pixel-level segmentation based on language instructions, while also enabling the recognition of temporally anchored events in traffic accident scenarios. To advance the development of MLLMs for traffic accident understanding, we curate a new dataset containing multimodal question-answer pairs centered on diverse accident scenarios, with detailed pixel-level annotations and temporal event boundaries. Experimental results show that SafePLUG achieves strong performance on multiple tasks, including region-based question answering, pixel-level segmentation, temporal event localization, and accident event understanding. These capabilities lay a foundation for fine-grained understanding of complex traffic scenes, with the potential to improve driving safety and enhance situational awareness in smart transportation systems. The code, dataset, and model checkpoints will be made publicly available at: this https URL', 'abstract_zh': '多\nuser\nMultim modal large language models (MLLMs) achieved remarkable progress across a range of vision-language tasks and demonstrate strong potential for traffic accident understanding.', 'title_zh': 'SafePLUG: 为交通事故理解赋能多模态LLM模型的像素级洞察与时空定位'}
{'arxiv_id': 'arXiv:2508.06756', 'title': 'FoundBioNet: A Foundation-Based Model for IDH Genotyping of Glioma from Multi-Parametric MRI', 'authors': 'Somayeh Farahani, Marjaneh Hejazi, Antonio Di Ieva, Sidong Liu', 'link': 'https://arxiv.org/abs/2508.06756', 'abstract': "Accurate, noninvasive detection of isocitrate dehydrogenase (IDH) mutation is essential for effective glioma management. Traditional methods rely on invasive tissue sampling, which may fail to capture a tumor's spatial heterogeneity. While deep learning models have shown promise in molecular profiling, their performance is often limited by scarce annotated data. In contrast, foundation deep learning models offer a more generalizable approach for glioma imaging biomarkers. We propose a Foundation-based Biomarker Network (FoundBioNet) that utilizes a SWIN-UNETR-based architecture to noninvasively predict IDH mutation status from multi-parametric MRI. Two key modules are incorporated: Tumor-Aware Feature Encoding (TAFE) for extracting multi-scale, tumor-focused features, and Cross-Modality Differential (CMD) for highlighting subtle T2-FLAIR mismatch signals associated with IDH mutation. The model was trained and validated on a diverse, multi-center cohort of 1705 glioma patients from six public datasets. Our model achieved AUCs of 90.58%, 88.08%, 65.41%, and 80.31% on independent test sets from EGD, TCGA, Ivy GAP, RHUH, and UPenn, consistently outperforming baseline approaches (p <= 0.05). Ablation studies confirmed that both the TAFE and CMD modules are essential for improving predictive accuracy. By integrating large-scale pretraining and task-specific fine-tuning, FoundBioNet enables generalizable glioma characterization. This approach enhances diagnostic accuracy and interpretability, with the potential to enable more personalized patient care.", 'abstract_zh': '准确无侵入性检测异柠檬酸脱氢酶（IDH）突变对于有效管理胶质瘤至关重要。基础深度学习模型为胶质瘤成像生物标志物提供了更具通用性的方法。我们提出了一种基于基础的生物标志物网络（FoundBioNet），利用SWIN-UNETR架构从多参数MRI中无侵入性预测IDH突变状态。该网络包含两个关键模块：肿瘤意识特征编码（TAFE）以提取多尺度、肿瘤集中特征，以及跨模态差异（CMD）以突出与IDH突变相关的细微T2-FLAIR不匹配信号。模型在六个公共数据集中1705例胶质瘤患者的多样化、多中心队列上进行了训练和验证，并在EGD、TCGA、Ivy GAP、RHUH和UPenn的独立测试集上实现了AUC值分别为90.58%、88.08%、65.41%和80.31%，始终优于基线方法（p ≤ 0.05）。消融研究证实，TAFE和CMD模块对于提高预测准确性都是必不可少的。通过结合大规模预训练和任务特定微调，FoundBioNet能够实现胶质瘤的一般性表征。该方法提高了诊断准确性和可解释性，有可能实现更加个性化的患者护理。', 'title_zh': 'FoundBioNet：一种基于基础模型的多参数MRI胶质瘤IDH分型方法'}
{'arxiv_id': 'arXiv:2508.06755', 'title': 'Many-Turn Jailbreaking', 'authors': 'Xianjun Yang, Liqiang Xiao, Shiyang Li, Faisal Ladhak, Hyokun Yun, Linda Ruth Petzold, Yi Xu, William Yang Wang', 'link': 'https://arxiv.org/abs/2508.06755', 'abstract': 'Current jailbreaking work on large language models (LLMs) aims to elicit unsafe outputs from given prompts. However, it only focuses on single-turn jailbreaking targeting one specific query. On the contrary, the advanced LLMs are designed to handle extremely long contexts and can thus conduct multi-turn conversations. So, we propose exploring multi-turn jailbreaking, in which the jailbroken LLMs are continuously tested on more than the first-turn conversation or a single target query. This is an even more serious threat because 1) it is common for users to continue asking relevant follow-up questions to clarify certain jailbroken details, and 2) it is also possible that the initial round of jailbreaking causes the LLMs to respond to additional irrelevant questions consistently. As the first step (First draft done at June 2024) in exploring multi-turn jailbreaking, we construct a Multi-Turn Jailbreak Benchmark (MTJ-Bench) for benchmarking this setting on a series of open- and closed-source models and provide novel insights into this new safety threat. By revealing this new vulnerability, we aim to call for community efforts to build safer LLMs and pave the way for a more in-depth understanding of jailbreaking LLMs.', 'abstract_zh': '多轮越狱攻击：探索长期对话的安全威胁', 'title_zh': '多轮越狱'}
{'arxiv_id': 'arXiv:2508.06743', 'title': 'Analysis of Schedule-Free Nonconvex Optimization', 'authors': 'Connor Brown', 'link': 'https://arxiv.org/abs/2508.06743', 'abstract': "First-order methods underpin most large-scale learning algorithms, yet their classical convergence guarantees hinge on carefully scheduled step-sizes that depend on the total horizon $T$, which is rarely known in advance. The Schedule-Free (SF) method promises optimal performance with hyperparameters that are independent of $T$ by interpolating between Polyak--Ruppert averaging and momentum, but nonconvex analysis of SF has been limited or reliant on strong global assumptions. We introduce a robust Lyapunov framework that, under only $L$-smoothness and lower-boundedness, reduces SF analysis to a single-step descent inequality. This yields horizon-agnostic bounds in the nonconvex setting: $O(1/\\log T)$ for constant step + PR averaging, $O(\\log T/T)$ for a linearly growing step-size, and a continuum of $O(T^{-(1-\\alpha)})$ rates for polynomial averaging. We complement these proofs with Performance Estimation Problem (PEP) experiments that numerically validate our rates and suggest that our $O(1/\\log T)$ bound on the original nonconvex SF algorithm may tighten to $O(1/T)$. Our work extends SF's horizon-free guarantees to smooth nonconvex optimization and charts future directions for optimal nonconvex rates.", 'abstract_zh': '无调度的首阶方法在光滑非凸优化中的边界保证及未来方向', 'title_zh': '非凸优化的无调度分析'}
{'arxiv_id': 'arXiv:2508.06742', 'title': 'Learning Causal Structure Distributions for Robust Planning', 'authors': 'Alejandro Murillo-Gonzalez, Junhong Xu, Lantao Liu', 'link': 'https://arxiv.org/abs/2508.06742', 'abstract': "Structural causal models describe how the components of a robotic system interact. They provide both structural and functional information about the relationships that are present in the system. The structural information outlines the variables among which there is interaction. The functional information describes how such interactions work, via equations or learned models. In this paper we find that learning the functional relationships while accounting for the uncertainty about the structural information leads to more robust dynamics models which improves downstream planning, while using significantly lower computational resources. This in contrast with common model-learning methods that ignore the causal structure and fail to leverage the sparsity of interactions in robotic systems. We achieve this by estimating a causal structure distribution that is used to sample causal graphs that inform the latent-space representations in an encoder-multidecoder probabilistic model. We show that our model can be used to learn the dynamics of a robot, which together with a sampling-based planner can be used to perform new tasks in novel environments, provided an objective function for the new requirement is available. We validate our method using manipulators and mobile robots in both simulation and the real-world. Additionally, we validate the learned dynamics' adaptability and increased robustness to corrupted inputs and changes in the environment, which is highly desirable in challenging real-world robotics scenarios. Video: this https URL.", 'abstract_zh': '结构因果模型描述了机器人系统组件之间的相互作用方式，提供了系统中存在关系的结构性和功能性信息。结构性信息概述了存在相互作用的变量。功能性信息描述了这些相互作用如何通过方程或学习模型来实现。在本文中，我们发现，在考虑结构性信息的不确定性的同时学习功能关系，可以生成更稳健的动力学模型，从而改进下游规划，同时显著减少计算资源的使用。这与通常忽略因果结构的模型学习方法形成对比，后者无法利用机器人系统中相互作用的稀疏性。我们通过估计一个因果结构分布来实现这一点，该分布用于抽样因果图，以指导编码器-多解码器概率模型中的潜在空间表示。我们展示了我们的模型可以用于学习机器人的动力学，结合基于采样的规划器，可以用于在新环境中执行新任务，前提是新要求有一个目标函数。我们在仿真和真实世界中分别使用操作器和移动机器人验证了该方法。此外，我们验证了所学习的动力学对输入污染和环境变化的适应性和增强的鲁棒性，这对于具有挑战性的现实世界机器人场景来说是非常重要的。视频：请访问此链接。', 'title_zh': '学习因果结构分布以实现鲁棒规划'}
{'arxiv_id': 'arXiv:2508.06729', 'title': 'Large Language Models for Oral History Understanding with Text Classification and Sentiment Analysis', 'authors': 'Komala Subramanyam Cherukuri, Pranav Abishai Moses, Aisa Sakata, Jiangping Chen, Haihua Chen', 'link': 'https://arxiv.org/abs/2508.06729', 'abstract': 'Oral histories are vital records of lived experience, particularly within communities affected by systemic injustice and historical erasure. Effective and efficient analysis of their oral history archives can promote access and understanding of the oral histories. However, Large-scale analysis of these archives remains limited due to their unstructured format, emotional complexity, and high annotation costs. This paper presents a scalable framework to automate semantic and sentiment annotation for Japanese American Incarceration Oral History. Using LLMs, we construct a high-quality dataset, evaluate multiple models, and test prompt engineering strategies in historically sensitive contexts. Our multiphase approach combines expert annotation, prompt design, and LLM evaluation with ChatGPT, Llama, and Qwen. We labeled 558 sentences from 15 narrators for sentiment and semantic classification, then evaluated zero-shot, few-shot, and RAG strategies. For semantic classification, ChatGPT achieved the highest F1 score (88.71%), followed by Llama (84.99%) and Qwen (83.72%). For sentiment analysis, Llama slightly outperformed Qwen (82.66%) and ChatGPT (82.29%), with all models showing comparable results. The best prompt configurations were used to annotate 92,191 sentences from 1,002 interviews in the JAIOH collection. Our findings show that LLMs can effectively perform semantic and sentiment annotation across large oral history collections when guided by well-designed prompts. This study provides a reusable annotation pipeline and practical guidance for applying LLMs in culturally sensitive archival analysis. By bridging archival ethics with scalable NLP techniques, this work lays the groundwork for responsible use of artificial intelligence in digital humanities and preservation of collective memory. GitHub: this https URL.', 'abstract_zh': '口述历史是记录亲身经历的重要资料，尤其是在受到系统性不公正和历史抹除影响的社区中。对这些口述历史档案的有效和高效分析可以促进其访问和理解。然而，由于这些档案的非结构化格式、情感复杂性和高注释成本，大规模分析仍受到限制。本文提出了一种可扩展的框架来自动化对日裔美国人拘留口述历史的语义和情感标注。利用大规模语言模型（LLM），我们构建了一个高质量的数据集，评估了多种模型，并在历史上敏感的背景下测试了提示工程策略。我们的多阶段方法结合了专家注释、提示设计和LLM评估，使用ChatGPT、Llama和Qwen。我们对15位叙述者中的558个句子进行了情感和语义分类标注，然后评估了零样本、少样本和RAG策略。在语义分类方面，ChatGPT达到了最高的F1分数（88.71%），其次是Llama（84.99%）和Qwen（83.72%）。在情感分析方面，Llama仅略优于Qwen（82.66%）和ChatGPT（82.29%），所有模型的性能均可比。最佳提示配置被用于标注JAIOH集合中的92,191个句子，来自1,002次访谈。我们的研究结果表明，在精心设计的提示引导下，LLM可以在大型口述历史集合并有效执行语义和情感标注。本研究提供了一个可重用的注释流水线，并为在文化敏感档案分析中应用LLM提供了实用指导。通过将归档伦理与可扩展的自然语言处理技术相结合，本研究为人工智能在数字人文和集体记忆保存中的负责任使用奠定了基础。GitHub: [这个链接](这个链接)。', 'title_zh': '大规模语言模型在文本分类与情感分析中的口述历史理解应用'}
{'arxiv_id': 'arXiv:2508.06709', 'title': 'Play Favorites: A Statistical Method to Measure Self-Bias in LLM-as-a-Judge', 'authors': 'Evangelia Spiliopoulou, Riccardo Fogliato, Hanna Burnsky, Tamer Soliman, Jie Ma, Graham Horwood, Miguel Ballesteros', 'link': 'https://arxiv.org/abs/2508.06709', 'abstract': 'Large language models (LLMs) can serve as judges that offer rapid and reliable assessments of other LLM outputs. However, models may systematically assign overly favorable ratings to their own outputs, a phenomenon known as self-bias, which can distort evaluations of true model performance. Previous studies often conflate genuine differences in model quality with bias or incorrectly assume that evaluations from LLMs and humans follow the same rating distributions. In this work, we present a statistical framework that explicitly formalizes assumptions under which self-bias can be identified and estimated. Our method models the difference in the scoring distribution that LLM-as-a-judge assigns to its own completions compared to other models, while accounting for the underlying quality of the completions provided by an independent, third-party judge (e.g., humans). Our method reliably isolates and quantifies self-bias, even when models vary in ability, ensuring that genuine performance differences are not mistaken for self-bias. We conduct an empirical analysis of self-bias on a large dataset (>5000 prompt-completion pairs) consisting of expert human annotations and judgments from nine different LLM judges. We find that some models, such as GPT-4o and Claude 3.5 Sonnet, systematically assign higher scores to their own outputs. These models also display family-bias; systematically assigning higher ratings to outputs produced by other models of the same family. Our findings highlight potential pitfalls of using LLM judges and offer practical guidance to mitigate biases when interpreting automated evaluations.', 'abstract_zh': '大规模语言模型（LLMs）可以用作法官，提供对其他LLM输出的快速和可靠评估。然而，模型可能会系统地对其自身输出赋予过于有利的评分，这一现象称为自我偏见，这会歪曲对模型真正性能的评估。以往的研究常常将模型质量的真实差异与偏见混为一谈，或错误地假设LLM和人类的评估遵循相同的评分分布。在本工作中，我们提出了一种统计框架，明确形式化了能识别和估计自我偏见的假设。我们的方法模型了LLM作为法官时对其自身完成内容与其他模型完成内容的评分分布差异，同时考虑了独立第三方法官（例如人类）提供的完成内容的真实质量。我们的方法能够可靠地隔离和量化自我偏见，即使模型的能力存在差异，也能确保不会将真正的性能差异误认为是自我偏见。我们在包含专家人类注释和九种不同LLM法官判断的大数据集（超过5000个提示-完成对）上进行了实证分析。结果显示，一些模型，如GPT-4o和Claude 3.5 Sonnet，系统地对其自身的输出给予更高的评分。这些模型还表现出家族偏见；系统地对其它同一家族模型产生的输出给予更高的评分。我们的研究结果揭示了使用LLM法官可能存在的陷阱，并提供了减少偏见的实用指导，以确保在解读自动化评估时的准确性。', 'title_zh': '偏爱之选：一种测量LLM-as-a-Judge 自我偏差的统计方法'}
{'arxiv_id': 'arXiv:2508.06701', 'title': 'MMFformer: Multimodal Fusion Transformer Network for Depression Detection', 'authors': 'Md Rezwanul Haque, Md. Milon Islam, S M Taslim Uddin Raju, Hamdi Altaheri, Lobna Nassar, Fakhri Karray', 'link': 'https://arxiv.org/abs/2508.06701', 'abstract': "Depression is a serious mental health illness that significantly affects an individual's well-being and quality of life, making early detection crucial for adequate care and treatment. Detecting depression is often difficult, as it is based primarily on subjective evaluations during clinical interviews. Hence, the early diagnosis of depression, thanks to the content of social networks, has become a prominent research area. The extensive and diverse nature of user-generated information poses a significant challenge, limiting the accurate extraction of relevant temporal information and the effective fusion of data across multiple modalities. This paper introduces MMFformer, a multimodal depression detection network designed to retrieve depressive spatio-temporal high-level patterns from multimodal social media information. The transformer network with residual connections captures spatial features from videos, and a transformer encoder is exploited to design important temporal dynamics in audio. Moreover, the fusion architecture fused the extracted features through late and intermediate fusion strategies to find out the most relevant intermodal correlations among them. Finally, the proposed network is assessed on two large-scale depression detection datasets, and the results clearly reveal that it surpasses existing state-of-the-art approaches, improving the F1-Score by 13.92% for D-Vlog dataset and 7.74% for LMVD dataset. The code is made available publicly at this https URL.", 'abstract_zh': '抑郁症是一种严重的精神健康疾病，显著影响个体的福祉和生活质量，因此早期检测对于获取适当的护理和治疗至关重要。检测抑郁症往往颇具挑战性，因为它主要基于临床访谈中的主观评估。因此，得益于社交媒体内容，早期诊断抑郁症已成为一个重要的研究领域。用户生成信息的广泛多样性质给准确提取相关时间信息和多模态数据的有效融合带来了重大挑战。本文介绍了一种名为MMFformer的多模态抑郁症检测网络，该网络旨在从多模态社交媒体信息中检索抑郁的时空高层模式。残差连接的变压器网络从视频中捕获空间特征，利用变压器编码器设计音频中的重要时间动态。此外，通过 late 和 intermediate 融合策略融合提取的特征，以发现它们之间的最相关跨模态关联。最终，所提出网络在两个大规模抑郁症检测数据集上进行了评估，结果清楚地表明，它超越了现有最先进的方法，F1-Score 提高了 13.92%（对于 D-Vlog 数据集）和 7.74%（对于 LMVD 数据集）。代码已公开发布在该网址。', 'title_zh': '/MMFformer：多模态融合变换器网络在抑郁检测中的应用'}
{'arxiv_id': 'arXiv:2508.06671', 'title': 'Do Biased Models Have Biased Thoughts?', 'authors': 'Swati Rajwal, Shivank Garg, Reem Abdel-Salam, Abdelrahman Zayed', 'link': 'https://arxiv.org/abs/2508.06671', 'abstract': "The impressive performance of language models is undeniable. However, the presence of biases based on gender, race, socio-economic status, physical appearance, and sexual orientation makes the deployment of language models challenging. This paper studies the effect of chain-of-thought prompting, a recent approach that studies the steps followed by the model before it responds, on fairness. More specifically, we ask the following question: \\textit{Do biased models have biased thoughts}? To answer our question, we conduct experiments on $5$ popular large language models using fairness metrics to quantify $11$ different biases in the model's thoughts and output. Our results show that the bias in the thinking steps is not highly correlated with the output bias (less than $0.6$ correlation with a $p$-value smaller than $0.001$ in most cases). In other words, unlike human beings, the tested models with biased decisions do not always possess biased thoughts.", 'abstract_zh': '语言模型令人印象深刻的性能是毋庸置疑的。然而，基于性别、种族、社会经济地位、外貌和性取向的偏见使得语言模型的部署具有挑战性。本文研究了chain-of-thought prompting（思考链提示）方法对公平性的影响，该方法研究模型在响应之前遵循的步骤。具体而言，我们提出了以下问题：\\textit{带有偏见的模型是否具有偏见的想法？}为了回答这个问题，我们在5个流行的大型语言模型上进行了实验，并使用公平性指标量化了模型想法和输出中的11种不同偏见。研究结果表明，想法中的偏见与输出偏见的相关性并不高（大多数情况下皮尔逊相关系数小于0.6，且p值小于0.001）。换句话说，与人类不同，具有偏见决策的测试模型并不总是具有偏见的想法。', 'title_zh': '有偏见的模型是否有偏见的想法？'}
{'arxiv_id': 'arXiv:2508.06659', 'title': 'In-Context Reinforcement Learning via Communicative World Models', 'authors': 'Fernando Martinez-Lopez, Tao Li, Yingdong Lu, Juntao Chen', 'link': 'https://arxiv.org/abs/2508.06659', 'abstract': "Reinforcement learning (RL) agents often struggle to generalize to new tasks and contexts without updating their parameters, mainly because their learned representations and policies are overfit to the specifics of their training environments. To boost agents' in-context RL (ICRL) ability, this work formulates ICRL as a two-agent emergent communication problem and introduces CORAL (Communicative Representation for Adaptive RL), a framework that learns a transferable communicative context by decoupling latent representation learning from control. In CORAL, an Information Agent (IA) is pre-trained as a world model on a diverse distribution of tasks. Its objective is not to maximize task reward, but to build a world model and distill its understanding into concise messages. The emergent communication protocol is shaped by a novel Causal Influence Loss, which measures the effect that the message has on the next action. During deployment, the previously trained IA serves as a fixed contextualizer for a new Control Agent (CA), which learns to solve tasks by interpreting the provided communicative context. Our experiments demonstrate that this approach enables the CA to achieve significant gains in sample efficiency and successfully perform zero-shot adaptation with the help of pre-trained IA in entirely unseen sparse-reward environments, validating the efficacy of learning a transferable communicative representation.", 'abstract_zh': '基于通信的学习增强 reinforcement learning（ICRL）agents及CORAL框架：学习可转移的通信表示以提升零样本适应能力', 'title_zh': '基于交流世界模型的上下文强化学习'}
{'arxiv_id': 'arXiv:2508.06641', 'title': 'Fractal Language Modelling by Universal Sequence Maps (USM)', 'authors': 'Jonas S Almeida, Daniel E Russ, Susana Vinga, Ines Duarte, Lee Mason, Praphulla Bhawsar, Aaron Ge, Arlindo Oliveira, Jeya Balaji Balasubramanian', 'link': 'https://arxiv.org/abs/2508.06641', 'abstract': 'Motivation: With the advent of Language Models using Transformers, popularized by ChatGPT, there is a renewed interest in exploring encoding procedures that numerically represent symbolic sequences at multiple scales and embedding dimensions. The challenge that encoding addresses is the need for mechanisms that uniquely retain contextual information about the succession of individual symbols, which can then be modeled by nonlinear formulations such as neural networks.\nContext: Universal Sequence Maps(USM) are iterated functions that bijectively encode symbolic sequences onto embedded numerical spaces. USM is composed of two Chaos Game Representations (CGR), iterated forwardly and backwardly, that can be projected into the frequency domain (FCGR). The corresponding USM coordinates can be used to compute a Chebyshev distance metric as well as k-mer frequencies, without having to recompute the embedded numeric coordinates, and, paradoxically, allowing for non-integers values of k.\nResults: This report advances the bijective fractal encoding by Universal Sequence Maps (USM) by resolving seeding biases affecting the iterated process. The resolution had two results, the first expected, the second an intriguing outcome: 1) full reconciliation of numeric positioning with sequence identity; and 2) uncovering the nature of USM as an efficient numeric process converging towards a steady state sequence embedding solution. We illustrate these results for genomic sequences because of the convenience of a planar representation defined by an alphabet with only 4 tokens (the 4 nucleotides). Nevertheless, the application to alphabet of arbitrary cardinality was found to be straightforward.', 'abstract_zh': '动机：随着使用变换器的语言模型的兴起，以ChatGPT为代表，人们对探索能够以多个尺度和嵌入维度数值表示符号序列的编码方法的兴趣得到了新的提高。编码面临的挑战是需要机制来唯一保留单个符号序列的上下文信息，这些信息可以由非线性模型如神经网络进行建模。\n\n背景：通用序列映射（USM）是迭代函数，能够在嵌入的数值空间中双射编码符号序列。USM 由两个混沌游戏表示法（CGR）组成，以正向和反向迭代方式，可以投影到频域（FCGR）。USM 对应的坐标可以用于计算切比雪夫距离度量以及 k-mer 频率，而无需重新计算嵌入的数值坐标，并且出人意料地允许 k 取非整数值。\n\n结果：本报告通过解决影响迭代过程的起始条件偏见，推进了通用序列映射（USM）的双射分形编码。这一解决办法产生了两个结果：第一个是预期的结果，第二个是一个有趣的发现：1) 完全协调数值位置与序列身份；2) 揭示USM作为一种有效数值过程，能够收敛到稳定的序列嵌入解。我们通过基因组序列的平面表示来阐述这些结果，因为仅由四个符号（四种核苷酸）定义的字母表便于表示。然而，任意基数字母表的应用被发现是直接的。', 'title_zh': '分形语言建模通过通用序列映射（USM）'}
{'arxiv_id': 'arXiv:2508.06638', 'title': 'Segmented Confidence Sequences and Multi-Scale Adaptive Confidence Segments for Anomaly Detection in Nonstationary Time Series', 'authors': 'Muyan Anna Li, Aditi Gautam', 'link': 'https://arxiv.org/abs/2508.06638', 'abstract': 'As time series data become increasingly prevalent in domains such as manufacturing, IT, and infrastructure monitoring, anomaly detection must adapt to nonstationary environments where statistical properties shift over time. Traditional static thresholds are easily rendered obsolete by regime shifts, concept drift, or multi-scale changes. To address these challenges, we introduce and empirically evaluate two novel adaptive thresholding frameworks: Segmented Confidence Sequences (SCS) and Multi-Scale Adaptive Confidence Segments (MACS). Both leverage statistical online learning and segmentation principles for local, contextually sensitive adaptation, maintaining guarantees on false alarm rates even under evolving distributions. Our experiments across Wafer Manufacturing benchmark datasets show significant F1-score improvement compared to traditional percentile and rolling quantile approaches. This work demonstrates that robust, statistically principled adaptive thresholds enable reliable, interpretable, and timely detection of diverse real-world anomalies.', 'abstract_zh': '随时间序列数据在制造、IT和基础设施监控等领域中的 increasingly prevalent，异常检测必须适应统计属性随时间变化的非stationary环境。传统静态阈值容易因状态转换、概念漂移或多尺度变化而过时。为应对这些挑战，我们引入并实证评估了两种新颖的自适应阈值框架：分段信心序列（SCS）和多尺度自适应信心分段（MACS）。这两种方法均利用了统计在线学习和分割原理进行局部、语境敏感的适应，即使在分布演变时也能保证误报率的上限。我们的实验跨晶圆制造基准数据集表明，相比传统的百分位数和滚动分位数方法，F1分数显著提高。这项工作展示了稳健的、基于统计原则的自适应阈值能够实现可靠、可解释和及时的异变检测。', 'title_zh': '分段置信序列与多尺度自适应置信区间分割在非平稳时间\nuser\n适合初学者的Python编程书籍推荐。'}
{'arxiv_id': 'arXiv:2508.06635', 'title': 'Using Imperfect Synthetic Data in Downstream Inference Tasks', 'authors': 'Yewon Byun, Shantanu Gupta, Zachary C. Lipton, Rachel Leah Childers, Bryan Wilder', 'link': 'https://arxiv.org/abs/2508.06635', 'abstract': 'Predictions and generations from large language models are increasingly being explored as an aid to computational social science and human subject research in limited data regimes. While previous technical work has explored the potential to use model-predicted labels for unlabeled data in a principled manner, there is increasing interest in using large language models to generate entirely new synthetic samples (also termed as synthetic simulations), such as in responses to surveys. However, it is not immediately clear by what means practitioners can combine such data with real data and yet produce statistically valid conclusions upon them. In this work, we introduce a new estimator based on generalized method of moments, providing a hyperparameter-free solution with strong theoretical guarantees to address the challenge at hand. Surprisingly, we find that interactions between the moment residuals of synthetic data and those of real data can improve estimates of the target parameter. We empirically validate the finite-sample performance of our estimator across different regression tasks in computational social science applications, demonstrating large empirical gains.', 'abstract_zh': '大规模语言模型的预测与生成在计算社会学和有限数据情形下的人类主体研究中日益受到探索。虽然此前的技术工作已经探讨了使用模型预测标签来辅助未标注数据的方法，但越来越多的兴趣集中在使用大规模语言模型生成全新的合成样本（也称为合成模拟），例如在调查回应中。然而，不确定性在于从业人员如何将这些数据与真实数据结合并从中得出统计上有效的结论。在本文中，我们引入了一种基于广义矩方法的新估计器，提供了一种无超参数解决方案，具有强大的理论保证，以应对这一挑战。令人惊讶的是，我们发现合成数据的矩残差与真实数据的矩残差之间的交互可以改善目标参数的估计。我们在计算社会学应用中的不同回归任务中 empirically 验证了我们估计器在有限样本下的性能，显示出显著的实验增益。', 'title_zh': '使用不完美合成数据进行下游推理任务'}
{'arxiv_id': 'arXiv:2508.06632', 'title': 'CoDe-NeRF: Neural Rendering via Dynamic Coefficient Decomposition', 'authors': 'Wenpeng Xing, Jie Chen, Zaifeng Yang, Tiancheng Zhao, Gaolei Li, Changting Lin, Yike Guo, Meng Han', 'link': 'https://arxiv.org/abs/2508.06632', 'abstract': 'Neural Radiance Fields (NeRF) have shown impressive performance in novel view synthesis, but challenges remain in rendering scenes with complex specular reflections and highlights. Existing approaches may produce blurry reflections due to entanglement between lighting and material properties, or encounter optimization instability when relying on physically-based inverse rendering. In this work, we present a neural rendering framework based on dynamic coefficient decomposition, aiming to improve the modeling of view-dependent appearance. Our approach decomposes complex appearance into a shared, static neural basis that encodes intrinsic material properties, and a set of dynamic coefficients generated by a Coefficient Network conditioned on view and illumination. A Dynamic Radiance Integrator then combines these components to synthesize the final radiance. Experimental results on several challenging benchmarks suggest that our method can produce sharper and more realistic specular highlights compared to existing techniques. We hope that this decomposition paradigm can provide a flexible and effective direction for modeling complex appearance in neural scene representations.', 'abstract_zh': '基于动态系数分解的神经渲染框架：改善视依赖外观建模', 'title_zh': 'CoDe-NeRF: 基于动态系数分解的神经渲染'}
{'arxiv_id': 'arXiv:2508.06627', 'title': 'Early Detection of Pancreatic Cancer Using Multimodal Learning on Electronic Health Record', 'authors': 'Mosbah Aouad, Anirudh Choudhary, Awais Farooq, Steven Nevers, Lusine Demirkhanyan, Bhrandon Harris, Suguna Pappu, Christopher Gondi, Ravishankar Iyer', 'link': 'https://arxiv.org/abs/2508.06627', 'abstract': 'Pancreatic ductal adenocarcinoma (PDAC) is one of the deadliest cancers, and early detection remains a major clinical challenge due to the absence of specific symptoms and reliable biomarkers. In this work, we propose a new multimodal approach that integrates longitudinal diagnosis code histories and routinely collected laboratory measurements from electronic health records to detect PDAC up to one year prior to clinical diagnosis. Our method combines neural controlled differential equations to model irregular lab time series, pretrained language models and recurrent networks to learn diagnosis code trajectory representations, and cross-attention mechanisms to capture interactions between the two modalities. We develop and evaluate our approach on a real-world dataset of nearly 4,700 patients and achieve significant improvements in AUC ranging from 6.5% to 15.5% over state-of-the-art methods. Furthermore, our model identifies diagnosis codes and laboratory panels associated with elevated PDAC risk, including both established and new biomarkers. Our code is available at this https URL.', 'abstract_zh': '胰管腺癌（PDAC）是 deadliest 的癌症之一，由于缺乏特异性症状和可靠的生物标志物，早期检测仍然是一个主要的临床挑战。本研究提出了一种新的多模态方法，该方法结合了纵向诊断代码历史和电子健康记录中常规收集的实验室测量数据，以在临床诊断前一年检测 PDAC。我们的方法结合了神经控制微分方程来建模不规则的实验室时间序列，预训练的语言模型和循环网络来学习诊断代码轨迹表示，以及跨注意力机制来捕捉两个模态之间的交互。我们在一个包含近 4,700 名患者的实际数据集上开发和评估了我们的方法，并在 AUC 上实现了比最新方法 6.5% 到 15.5% 的显著改进。此外，我们的模型识别了与 PDAC 风险增加相关的诊断代码和实验室面板，包括已建立和新发现的生物标志物。我们的代码可在以下链接获取。', 'title_zh': '基于电子健康记录的多模态学习早期检测胰腺癌'}
{'arxiv_id': 'arXiv:2508.06617', 'title': 'Generalizing Scaling Laws for Dense and Sparse Large Language Models', 'authors': 'Md Arafat Hossain, Xingfu Wu, Valerie Taylor, Ali Jannesari', 'link': 'https://arxiv.org/abs/2508.06617', 'abstract': 'Over the past few years, the size of language models has grown exponentially, as has the computational cost to train these large models. This rapid growth has motivated researchers to develop new techniques aimed at enhancing the efficiency of the training process. Despite these advancements, optimally predicting the model size or allocating optimal resources remains a challenge. Several efforts have addressed the challenge by proposing different scaling laws, but almost all of them are architecture-specific (dense or sparse). In this work we revisit existing scaling laws and propose a generalized scaling law to provide a unified framework that is applicable to both dense and sparse large language models. We evaluate and compare our proposed scaling law with existing scaling laws to demonstrate its effectiveness.', 'abstract_zh': '近年来，语言模型的规模呈指数级增长，相应地，训练这些大型模型的计算成本也大幅增加。这种快速增长推动了研究人员开发新的技术以提高训练过程的效率。尽管取得了这些进步，但最优预测模型规模或分配最优资源仍是一项挑战。尽管已有多种努力通过提出不同的缩放定律来应对这一挑战，但几乎所有的缩放定律都是针对特定架构（密集或稀疏）的。在本工作中，我们重新审视现有的缩放定律，并提出一个通用的缩放定律，以提供一个适用于 both 密集和稀疏大型语言模型的统一框架。我们评估并比较了我们提出的缩放定律与现有缩放定律，以展示其有效性。', 'title_zh': '稠密和稀疏大型语言模型的通用缩放定律'}
{'arxiv_id': 'arXiv:2508.06616', 'title': 'Generative AI for Intent-Driven Network Management in 6G: A Case Study on Hierarchical Learning Approach', 'authors': 'Md Arafat Habib, Medhat Elsayed, Yigit Ozcan, Pedro Enrique Iturria-Rivera, Majid Bavand, Melike Erol-Kantarci', 'link': 'https://arxiv.org/abs/2508.06616', 'abstract': 'With the emergence of 6G, mobile networks are becoming increasingly heterogeneous and dynamic, necessitating advanced automation for efficient management. Intent-Driven Networks (IDNs) address this by translating high-level intents into optimization policies. Large Language Models (LLMs) can enhance this process by understanding complex human instructions to enable adaptive, intelligent automation. Given the rapid advancements in Generative AI (GenAI), a comprehensive survey of LLM-based IDN architectures in disaggregated Radio Access Network (RAN) environments is both timely and critical. This article provides such a survey, along with a case study on a hierarchical learning-enabled IDN architecture that integrates GenAI across three key stages: intent processing, intent validation, and intent execution. Unlike most existing approaches that apply GenAI in the form of LLMs for intent processing only, we propose a hierarchical framework that introduces GenAI across all three stages of IDN. To demonstrate the effectiveness of the proposed IDN management architecture, we present a case study based on the latest GenAI architecture named Mamba. The case study shows how the proposed GenAI-driven architecture enhances network performance through intelligent automation, surpassing the performance of the conventional IDN architectures.', 'abstract_zh': '随着6G的出现，移动网络变得日益异构和动态，需要先进的自动化技术以实现高效管理。意图驱动网络（IDNs）通过将高阶意图转化为优化策略来应对这一挑战。大型语言模型（LLMs）可以通过理解复杂的人类指令来增强这一过程，从而实现自适应、智能的自动化。鉴于生成式人工智能（GenAI）的迅猛发展，基于LLM的IDN架构在分解式的无线接入网络（RAN）环境中进行全面的综述既是及时的，也是至关重要的。本文提供了这样的综述，并通过一个案例研究展示了如何在一个集成GenAI的分层学习驱动IDN架构中整合生成式AI，该架构涉及意图处理、意图验证和意图执行三个关键阶段。不同于大多数现有方法仅将GenAI应用于意图处理阶段，我们提出了一种分层框架，该框架在整个IDN的三个阶段都引入了生成式AI。为了证明所提出的IDN管理架构的有效性，我们基于最新的生成式AI架构Mamba展示了案例研究。案例研究展示了生成式AI驱动的架构通过智能自动化提高网络性能，超过了传统IDN架构的表现。', 'title_zh': '基于意向驱动的6G网络管理的生成式AI：层次学习方法案例研究'}
{'arxiv_id': 'arXiv:2508.06601', 'title': 'Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs', 'authors': "Kyle O'Brien, Stephen Casper, Quentin Anthony, Tomek Korbak, Robert Kirk, Xander Davies, Ishan Mishra, Geoffrey Irving, Yarin Gal, Stella Biderman", 'link': 'https://arxiv.org/abs/2508.06601', 'abstract': 'Open-weight AI systems offer unique benefits, including enhanced transparency, open research, and decentralized access. However, they are vulnerable to tampering attacks which can efficiently elicit harmful behaviors by modifying weights or activations. Currently, there is not yet a robust science of open-weight model risk management. Existing safety fine-tuning methods and other post-training techniques have struggled to make LLMs resistant to more than a few dozen steps of adversarial fine-tuning. In this paper, we investigate whether filtering text about dual-use topics from training data can prevent unwanted capabilities and serve as a more tamper-resistant safeguard. We introduce a multi-stage pipeline for scalable data filtering and show that it offers a tractable and effective method for minimizing biothreat proxy knowledge in LLMs. We pretrain multiple 6.9B-parameter models from scratch and find that they exhibit substantial resistance to adversarial fine-tuning attacks on up to 10,000 steps and 300M tokens of biothreat-related text -- outperforming existing post-training baselines by over an order of magnitude -- with no observed degradation to unrelated capabilities. However, while filtered models lack internalized dangerous knowledge, we find that they can still leverage such information when it is provided in context (e.g., via search tool augmentation), demonstrating a need for a defense-in-depth approach. Overall, these findings help to establish pretraining data curation as a promising layer of defense for open-weight AI systems.', 'abstract_zh': '开放权重的AI系统提供了独特的优势，包括增强的透明度、开放研究和去中心化的访问。然而，它们容易受到篡改攻击，攻击者可以通过修改权重或激活来有效地诱发有害行为。目前，开放权重模型风险管理工作尚未形成坚实的科学体系。现有的安全微调方法和其他后训练技术难以使大语言模型对超过几十步的对抗微调保持抗性。在本文中，我们探讨了从训练数据中过滤掉双重用途主题的文本是否能防止不希望的能力并作为更抗篡改的安全保障。我们介绍了一个可扩展的数据过滤多阶段管道，并展示了它在最小化LLM中的生物威胁代理知识方面提供了可实现且有效的方法。我们从头预训练了多个69亿参数的模型，并发现这些模型对多达10,000步和3亿个生物威胁相关文本令牌的对抗微调攻击表现出显著的抵抗力，比现有后训练基线高出一个数量级，且未观察到对无关能力的退化。然而，尽管过滤后的模型缺乏内化危险知识，我们发现它们在提供上下文信息（例如，通过搜索引擎工具增强）时仍能利用此类信息，这表明需要多层次防御策略。总的来说，这些发现有助于将预训练数据筛选确立为开放权重AI系统防御体系的一个有前景的层面。', 'title_zh': '深度无知：过滤预训练数据为开放权重LLMs构建防篡改保障'}
{'arxiv_id': 'arXiv:2508.06595', 'title': 'LLM Unlearning Without an Expert Curated Dataset', 'authors': 'Xiaoyuan Zhu, Muru Zhang, Ollie Liu, Robin Jia, Willie Neiswanger', 'link': 'https://arxiv.org/abs/2508.06595', 'abstract': 'Modern large language models often encode sensitive, harmful, or copyrighted knowledge, raising the need for post-hoc unlearning-the ability to remove specific domains of knowledge from a model without full retraining. A major bottleneck in current unlearning pipelines is constructing effective forget sets-datasets that approximate the target domain and guide the model to forget it. In this work, we introduce a scalable, automated approach to generate high-quality forget sets using language models themselves. Our method synthesizes textbook-style data through a structured prompting pipeline, requiring only a domain name as input. Through experiments on unlearning biosecurity, cybersecurity, and Harry Potter novels, we show that our synthetic datasets consistently outperform the baseline synthetic alternatives and are comparable to the expert-curated ones. Additionally, ablation studies reveal that the multi-step generation pipeline significantly boosts data diversity, which in turn improves unlearning utility. Overall, our findings suggest that synthetic datasets offer a promising path toward practical, scalable unlearning for a wide range of emerging domains without the need for manual intervention. We release our code and dataset at this https URL.', 'abstract_zh': '现代大型语言模型往往蕴含敏感、有害或受版权保护的知识的知识，这 提高了需要进行后验遗忘的能力—— 从模型中移除特定领域的知识，并这需要重新训练模型。当前遗忘流水线 中的一个主要瓶颈在于 构建遗忘集——数据集，这些数据集能够近似特定领域并 并使模型能够遗忘相关的知识。在这项研究中，我们提出了一种可 规模化的自动方法，使用语言模型本身来生成高质量的遗忘集。我们的方法通过结构化的提示流水 以生成教科书式的的数据，这仅需要设定极少的参数。通过在生物安全、网络安全和哈利· 波特小说上的的遗忘实验中，我们证明了生成的合成数据集在性能上 方基线的合成替代方案和专家手工挑选的参照中表现更优。此外，通过消融研究，我们发现多步生成流水 以显著提高数据多样性，，而这一点提升了遗忘实用度。综合来说，我们的发现建议合适数量集提供了一条有前景的道路，通向向实际的、可 规模化的遗忘，适用于各类新兴领域，而不依赖于人工干预。我们已将代码和数据集发布在此。这 链接：https URL。', 'title_zh': 'LLM无专家策展数据集的遗忘技术'}
{'arxiv_id': 'arXiv:2508.06592', 'title': 'Towards Integrated Alignment', 'authors': 'Ben Y. Reis, William La Cava', 'link': 'https://arxiv.org/abs/2508.06592', 'abstract': 'As AI adoption expands across human society, the problem of aligning AI models to match human preferences remains a grand challenge. Currently, the AI alignment field is deeply divided between behavioral and representational approaches, resulting in narrowly aligned models that are more vulnerable to increasingly deceptive misalignment threats. In the face of this fragmentation, we propose an integrated vision for the future of the field. Drawing on related lessons from immunology and cybersecurity, we lay out a set of design principles for the development of Integrated Alignment frameworks that combine the complementary strengths of diverse alignment approaches through deep integration and adaptive coevolution. We highlight the importance of strategic diversity - deploying orthogonal alignment and misalignment detection approaches to avoid homogeneous pipelines that may be "doomed to success". We also recommend steps for greater unification of the AI alignment research field itself, through cross-collaboration, open model weights and shared community resources.', 'abstract_zh': '随着人工智能在人类社会中的广泛采用，使AI模型与人类偏好相一致的问题仍然是一个巨大挑战。目前，AI对齐领域在行为和表征方法之间存在深刻的分歧，导致了仅限于特定方面的对齐模型，使其更容易受到日益欺骗性的对齐不当威胁。面对这一分化，我们提出了该领域的未来集成愿景。借鉴免疫学和网络安全的有关教训，我们为开发综合对齐框架设定了设计理念，这些框架通过深度整合和适应性共进化结合了多种对齐方法的互补优势。我们强调战略多样性的重要性——部署正交的对齐和对齐不当检测方法，以避免可能“注定成功”的同质化管道。我们还建议通过跨合作、开放模型权重和共享社区资源，进一步统一AI对齐研究领域本身。', 'title_zh': '集成对齐探索'}
{'arxiv_id': 'arXiv:2508.06591', 'title': 'Generative Artificial Intelligence Extracts Structure-Function Relationships from Plants for New Materials', 'authors': 'Rachel K. Luu, Jingyu Deng, Mohammed Shahrudin Ibrahim, Nam-Joon Cho, Ming Dao, Subra Suresh, Markus J. Buehler', 'link': 'https://arxiv.org/abs/2508.06591', 'abstract': 'Large language models (LLMs) have reshaped the research landscape by enabling new approaches to knowledge retrieval and creative ideation. Yet their application in discipline-specific experimental science, particularly in highly multi-disciplinary domains like materials science, remains limited. We present a first-of-its-kind framework that integrates generative AI with literature from hitherto-unconnected fields such as plant science, biomimetics, and materials engineering to extract insights and design experiments for materials. We focus on humidity-responsive systems such as pollen-based materials and Rhapis excelsa (broadleaf lady palm) leaves, which exhibit self-actuation and adaptive performance. Using a suite of AI tools, including a fine-tuned model (BioinspiredLLM), Retrieval-Augmented Generation (RAG), agentic systems, and a Hierarchical Sampling strategy, we extract structure-property relationships and translate them into new classes of bioinspired materials. Structured inference protocols generate and evaluate hundreds of hypotheses from a single query, surfacing novel and experimentally tractable ideas. We validate our approach through real-world implementation: LLM-generated procedures, materials designs, and mechanical predictions were tested in the laboratory, culminating in the fabrication of a novel pollen-based adhesive with tunable morphology and measured shear strength, establishing a foundation for future plant-derived adhesive design. This work demonstrates how AI-assisted ideation can drive real-world materials design and enable effective human-AI collaboration.', 'abstract_zh': '大型语言模型通过-enable新知识检索和创造性构想的方法重塑了研究格局，但在特定学科实验科学中的应用，尤其是在如材料科学这样高度跨学科的领域中仍有限制。我们提出了一个首创的框架，将生成式AI与植物科学、仿生学和材料工程等此前互不关联的领域文献相结合，以提取见解并设计材料实验。我们重点关注如基于花粉的材料和香槟竹（广叶竹）叶片等表现出自驱动和适应性能的湿度响应系统。利用一系列AI工具，包括Fine-tuned BioinspiredLLM模型、检索增强生成（RAG）、代理系统和分层采样策略，我们提取结构-性能关系并将其转化为新的仿生材料类。结构化的推理协议能够从单一查询中生成和评估成百上千个假设，揭示出新颖且实验可行的想法。我们通过实际应用验证了我们的方法：由大型语言模型生成的实验程序、材料设计和机械预测在实验室中得到了测试，最终制造出一种具有可调形貌和剪切强度的新型花粉基胶黏剂，为未来的植物衍生胶黏剂设计奠定了基础。这项工作展示了AI辅助构想如何推动实际的材料设计并促进有效的人机协作。', 'title_zh': '生成式人工智能从植物中提取结构-功能关系以开发新材料'}
{'arxiv_id': 'arXiv:2508.06589', 'title': 'A Federated Learning Framework for Handling Subtype Confounding and Heterogeneity in Large-Scale Neuroimaging Diagnosis', 'authors': 'Xinglin Zhao, Yanwen Wang, Xiaobo Liu, Yanrong Hao, Rui Cao, Xin Wen', 'link': 'https://arxiv.org/abs/2508.06589', 'abstract': 'Computer-aided diagnosis (CAD) systems play a crucial role in analyzing neuroimaging data for neurological and psychiatric disorders. However, small-sample studies suffer from low reproducibility, while large-scale datasets introduce confounding heterogeneity due to multiple disease subtypes being labeled under a single category. To address these challenges, we propose a novel federated learning framework tailored for neuroimaging CAD systems. Our approach includes a dynamic navigation module that routes samples to the most suitable local models based on latent subtype representations, and a meta-integration module that combines predictions from heterogeneous local models into a unified diagnostic output. We evaluated our framework using a comprehensive dataset comprising fMRI data from over 1300 MDD patients and 1100 healthy controls across multiple study cohorts. Experimental results demonstrate significant improvements in diagnostic accuracy and robustness compared to traditional methods. Specifically, our framework achieved an average accuracy of 74.06\\% across all tested sites, showcasing its effectiveness in handling subtype heterogeneity and enhancing model generalizability. Ablation studies further confirmed the importance of both the dynamic navigation and meta-integration modules in improving performance. By addressing data heterogeneity and subtype confounding, our framework advances reliable and reproducible neuroimaging CAD systems, offering significant potential for personalized medicine and clinical decision-making in neurology and psychiatry.', 'abstract_zh': '计算机辅助诊断（CAD）系统在神经影像数据分析中对神经和心理疾病诊断起着关键作用。然而，小样本研究存在低可重复性的问题，而大规模数据集则由于多种疾病亚型被归入同一类别而导致混杂异质性。为了解决这些问题，我们提出了一种专门用于神经影像CAD系统的联邦学习框架。该方法包括一个动态导航模块，根据潜在亚型表示将样本路由到最适合的局部模型，并包括一个元集成模块，将来自异质局部模型的预测结合成统一的诊断输出。我们使用一个包含1300多名MDD患者和1100名健康对照的多研究队列fMRI数据集评估了我们的框架。实验结果表明，与传统方法相比，该框架在诊断准确性和鲁棒性方面有显著提高。具体来说，该框架在所有测试站点的平均准确率为74.06%，展示了其在处理亚型异质性并增强模型泛化能力方面的有效性。进一步的消融研究证实了动态导航模块和元集成模块在提升性能中的重要性。通过解决数据异质性和亚型混杂问题，我们的框架推进了可信赖且可重复的神经影像CAD系统的发展，为神经学和精神病学中的个性化医学和临床决策提供了巨大潜力。', 'title_zh': '一种处理大规模神经影像诊断中亚型混杂和异质性的联邦学习框架'}
{'arxiv_id': 'arXiv:2508.06588', 'title': 'Graph is a Natural Regularization: Revisiting Vector Quantization for Graph Representation Learning', 'authors': 'Zian Zhai, Fan Li, Xingyu Tan, Xiaoyang Wang, Wenjie Zhang', 'link': 'https://arxiv.org/abs/2508.06588', 'abstract': 'Vector Quantization (VQ) has recently emerged as a promising approach for learning discrete representations of graph-structured data. However, a fundamental challenge, i.e., codebook collapse, remains underexplored in the graph domain, significantly limiting the expressiveness and generalization of graph this http URL this paper, we present the first empirical study showing that codebook collapse consistently occurs when applying VQ to graph data, even with mitigation strategies proposed in vision or language domains. To understand why graph VQ is particularly vulnerable to collapse, we provide a theoretical analysis and identify two key factors: early assignment imbalances caused by redundancy in graph features and structural patterns, and self-reinforcing optimization loops in deterministic VQ. To address these issues, we propose RGVQ, a novel framework that integrates graph topology and feature similarity as explicit regularization signals to enhance codebook utilization and promote token diversity. RGVQ introduces soft assignments via Gumbel-Softmax reparameterization, ensuring that all codewords receive gradient updates. In addition, RGVQ incorporates a structure-aware contrastive regularization to penalize the token co-assignments among similar node pairs. Extensive experiments demonstrate that RGVQ substantially improves codebook utilization and consistently boosts the performance of state-of-the-art graph VQ backbones across multiple downstream tasks, enabling more expressive and transferable graph token representations.', 'abstract_zh': '向量量化的图表示：对抗代码书坍塌的软量化和结构意识对比正则化框架', 'title_zh': '图是一个自然的正则化：重访图表示学习中的向量量化'}
{'arxiv_id': 'arXiv:2508.06584', 'title': 'Omni Geometry Representation Learning vs Large Language Models for Geospatial Entity Resolution', 'authors': 'Kalana Wijegunarathna, Kristin Stock, Christopher B. Jones', 'link': 'https://arxiv.org/abs/2508.06584', 'abstract': 'The development, integration, and maintenance of geospatial databases rely heavily on efficient and accurate matching procedures of Geospatial Entity Resolution (ER). While resolution of points-of-interest (POIs) has been widely addressed, resolution of entities with diverse geometries has been largely overlooked. This is partly due to the lack of a uniform technique for embedding heterogeneous geometries seamlessly into a neural network framework. Existing neural approaches simplify complex geometries to a single point, resulting in significant loss of spatial information. To address this limitation, we propose Omni, a geospatial ER model featuring an omni-geometry encoder. This encoder is capable of embedding point, line, polyline, polygon, and multi-polygon geometries, enabling the model to capture the complex geospatial intricacies of the places being compared. Furthermore, Omni leverages transformer-based pre-trained language models over individual textual attributes of place records in an Attribute Affinity mechanism. The model is rigorously tested on existing point-only datasets and a new diverse-geometry geospatial ER dataset. Omni produces up to 12% (F1) improvement over existing methods.\nFurthermore, we test the potential of Large Language Models (LLMs) to conduct geospatial ER, experimenting with prompting strategies and learning scenarios, comparing the results of pre-trained language model-based methods with LLMs. Results indicate that LLMs show competitive results.', 'abstract_zh': '地理空间数据库的开发、集成与维护依赖于高效的几何匹配程序。尽管兴趣点点 (POIs) 的几何分辨率已得到广泛应用，，，具有多种类几何形状的实体的分辨率则被很大程度上忽略了。部分步骤首多导于缺乏无缝嵌入各种几何形状到到神经网络框架中的统一技术。现有的神经网络方法将复杂几何形状简化为单一表示，导致大量的空间信息损失。为了解决这一限制，本文提出了一个针对地理空间实体分辨率 (ER\nuser\n地理空间数据实体分辨率(Omniv)的开发、集成与维护依赖于高效的几何匹配方法。虽然兴趣点点 (POIs) 的几何分辨率已经得到广泛应用，但具有多种几何形状的实体的分辨率则被很大程度上忽略。这主要是由于缺乏将不同无缝嵌入到神经网络框架中的统一技术。现有神经网络方法将复杂几何形状简化为单一表示，从而导致大量空间信息的丢失。为应对这一挑战，我们提出了Omniv模型，。Omn模型具备将点、线、折线与多折线几何形状嵌入的的能力，从而能够捕捉对比地点复杂的地理空间细节。此外，Omn模型利用基于场景的预训练语言模型，提取历史记录中的文本特征并通过属性亲和机制直接在Omn模型中应用这些文本特征。我们对该模型在已有的基于或的模型和与多样的几何数据集进行了严格测试，取得了显著的效果。此外、我们探讨了大型语言模型(LLMs)在地理空间实体分辨率中的潜在应用，并通过实验初步探索了基于LLMs预训练的基于场景的语言模型应用于地理空间实体分辨率的可能。实验结果表明，大语言模型展示出了竞争力的性能。', 'title_zh': '全方位几何表示学习与大规模语言模型在地理空间实体解析中的对比'}
{'arxiv_id': 'arXiv:2508.06583', 'title': 'Discerning minds or generic tutors? Evaluating instructional guidance capabilities in Socratic LLMs', 'authors': 'Ying Liu, Can Li, Ting Zhang, Mei Wang, Qiannan Zhu, Jian Li, Hua Huang', 'link': 'https://arxiv.org/abs/2508.06583', 'abstract': "The conversational capabilities of large language models hold significant promise for enabling scalable and interactive tutoring. While prior research has primarily examined their capacity for Socratic questioning, it often overlooks a critical dimension: adaptively guiding learners based on their cognitive states. This study shifts focus from mere question generation to the broader instructional guidance capability. We ask: Can LLMs emulate expert tutors who dynamically adjust strategies in response to learners' understanding? To investigate this, we propose GuideEval, a benchmark grounded in authentic educational dialogues that evaluates pedagogical guidance through a three-phase behavioral framework: (1) Perception, inferring learner states; (2) Orchestration, adapting instructional strategies; and (3) Elicitation, stimulating proper reflections. Empirical findings reveal that existing LLMs frequently fail to provide effective adaptive scaffolding when learners exhibit confusion or require redirection. Furthermore, we introduce a behavior-guided finetuning strategy that leverages behavior-prompted instructional dialogues, significantly enhancing guidance performance. By shifting the focus from isolated content evaluation to learner-centered interaction, our work advocates a more dialogic paradigm for evaluating Socratic LLMs.", 'abstract_zh': '大型语言模型的对话能力为实现可扩展和互动的教学提供了重要潜力。尽管以往研究主要关注其苏格拉底式提问的能力，但往往忽略了关键维度：根据学习者的认知状态进行适应性指导。本研究将焦点从简单的提问生成转向更广泛的指导能力。我们提出GuideEval这一基于真实教育对话的基准，通过三个阶段的行为框架来评估教学指导：（1）感知，推断学习者状态；（2）编排，适应性调整教学策略；（3）引发，激发合适的反思。实证研究发现，现有的大语言模型在学习者表现出困惑或需要重新导向时，往往无法提供有效的适应性支撐。此外，我们引入了一种行为导向的调优策略，利用行为提示的教学对话，显著提升了指导效果。通过将焦点从单独的内容评估转向以学习者为中心的互动，我们的工作倡导了一种更加对话性的范式来评估苏格拉底式的大语言模型。', 'title_zh': '识别人工智能还是通用导师？评估苏格拉底型LLM的教学指导能力'}
{'arxiv_id': 'arXiv:2508.06577', 'title': 'Leveraging LLMs for Privacy-Aware Predictions in Participatory Budgeting', 'authors': 'Juan Zambrano, Clément Contet, Jairo Gudiño, Felipe Garrido-Lucero, Umberto Grandi, Cesar A Hidalgo', 'link': 'https://arxiv.org/abs/2508.06577', 'abstract': "Participatory Budgeting (PB) empowers citizens to propose and vote on public investment projects. Yet, despite its democratic potential, PB initiatives often suffer from low participation rates, limiting their visibility and perceived legitimacy. In this work, we aim to strengthen PB elections in two key ways: by supporting project proposers in crafting better proposals, and by helping PB organizers manage large volumes of submissions in a transparent manner. We propose a privacy-preserving approach to predict which PB proposals are likely to be funded, using only their textual descriptions and anonymous historical voting records -- without relying on voter demographics or personally identifiable information. We evaluate the performance of GPT 4 Turbo in forecasting proposal outcomes across varying contextual scenarios, observing that the LLM's prior knowledge needs to be complemented by past voting data to obtain predictions reflecting real-world PB voting behavior. Our findings highlight the potential of AI-driven tools to support PB processes by improving transparency, planning efficiency, and civic engagement.", 'abstract_zh': '参与式预算（PB）使市民能够提出和投票决定公共投资项目的优先次序。尽管PB具有民主潜力，但其实施往往面临低参与率的问题，从而限制了其可见性和合法性的感知。本研究旨在通过两种关键方式增强PB选举：支持项目提案者制定更好的提案，并帮助PB组织者以透明的方式管理大量的提交内容。我们提出了一种隐私保护的方法，使用仅提案的文本描述和匿名的历史投票记录来预测哪些PB提案可能获得资助——无需依赖选民的人口统计信息或个人可识别信息。我们评估了GPT 4 Turbo在不同情境下预测提案结果的性能，发现LLM的先验知识需要补充过去的投票数据，才能获得反映实际PB投票行为的预测。我们的发现突显了AI驱动工具支持PB过程的潜力，通过提高透明度、规划效率和市民参与度。', 'title_zh': '利用大语言模型进行参与式预算中的隐私意识预测'}
{'arxiv_id': 'arXiv:2508.06575', 'title': 'Efficient Safety Testing of Autonomous Vehicles via Adaptive Search over Crash-Derived Scenarios', 'authors': 'Rui Zhou', 'link': 'https://arxiv.org/abs/2508.06575', 'abstract': 'Ensuring the safety of autonomous vehicles (AVs) is paramount in their development and deployment. Safety-critical scenarios pose more severe challenges, necessitating efficient testing methods to validate AVs safety. This study focuses on designing an accelerated testing algorithm for AVs in safety-critical scenarios, enabling swift recognition of their driving capabilities. First, typical logical scenarios were extracted from real-world crashes in the China In-depth Mobility Safety Study-Traffic Accident (CIMSS-TA) database, obtaining pre-crash features through reconstruction. Second, Baidu Apollo, an advanced black-box automated driving system (ADS) is integrated to control the behavior of the ego vehicle. Third, we proposed an adaptive large-variable neighborhood-simulated annealing algorithm (ALVNS-SA) to expedite the testing process. Experimental results demonstrate a significant enhancement in testing efficiency when utilizing ALVNS-SA. It achieves an 84.00% coverage of safety-critical scenarios, with crash scenario coverage of 96.83% and near-crash scenario coverage of 92.07%. Compared to genetic algorithm (GA), adaptive large neighborhood-simulated annealing algorithm (ALNS-SA), and random testing, ALVNS-SA exhibits substantially higher coverage in safety-critical scenarios.', 'abstract_zh': '确保自动驾驶车辆的安全性是其开发和部署中至为重要的考量。安全关键场景提出了更为严峻的挑战，需要高效测试方法以验证自动驾驶车辆的安全性。本研究专注于为自动驾驶车辆在安全关键场景中设计加速测试算法，以快速识别其驾驶能力。首先，从中国深入出行安全研究-交通事故(CIMSS-TA)数据库中提取典型的逻辑场景，通过重建获得碰撞前特征。其次，集成百度Apollo高级黑盒自动驾驶系统(ADS)，控制ego车辆的行为。第三，我们提出了自适应大变量邻域-模拟退火算法(ALVNS-SA)以加速测试过程。实验结果表明，使用ALVNS-SA显著提高了测试效率。ALVNS-SA在安全关键场景中的覆盖率高达84.00%，碰撞场景覆盖率为96.83%，接近碰撞场景覆盖率为92.07%。与遗传算法(GA)、自适应大邻域模拟退火算法(ALNS-SA)和随机测试相比，ALVNS-SA在安全关键场景中的覆盖率显著更高。', 'title_zh': '基于碰撞衍生场景的自适应搜索高效自主车辆安全性测试'}
{'arxiv_id': 'arXiv:2508.06572', 'title': 'Teaching Introduction to Programming in the times of AI: A case study of a course re-design', 'authors': 'Nikolaos Avouris, Kyriakos Sgarbas, George Caridakis, Christos Sintoris', 'link': 'https://arxiv.org/abs/2508.06572', 'abstract': 'The integration of AI tools into programming education has become increasingly prevalent in recent years, transforming the way programming is taught and learned. This paper provides a review of the state-of-the-art AI tools available for teaching and learning programming, particularly in the context of introductory courses. It highlights the challenges on course design, learning objectives, course delivery and formative and summative assessment, as well as the misuse of such tools by the students. We discuss ways of re-designing an existing course, re-shaping assignments and pedagogy to address the current AI technologies challenges. This example can serve as a guideline for policies for institutions and teachers involved in teaching programming, aiming to maximize the benefits of AI tools while addressing the associated challenges and concerns.', 'abstract_zh': '将AI工具集成到编程教育中的做法近年来日益普遍，正在改变编程的教学和学习方式。本论文对可用于教学和学习编程的最新AI工具进行了综述，尤其是在入门课程的背景下。它强调了课程设计、学习目标、课程交付以及形成性和总结性评估等方面的挑战，以及学生对这些工具的误用问题。我们讨论了重新设计现有课程、重新定义作业和教学方法的方法，以应对当前的AI技术挑战。这一示例可以作为机构和教师在教学编程时的政策指南，旨在最大化AI工具的益处同时解决相关挑战和关注问题。', 'title_zh': '在人工智能时代的编程导论教学：一门课程 redesign 的案例研究'}
{'arxiv_id': 'arXiv:2508.06566', 'title': 'Surformer v1: Transformer-Based Surface Classification Using Tactile and Vision Features', 'authors': 'Manish Kansana, Elias Hossain, Shahram Rahimi, Noorbakhsh Amiri Golilarz', 'link': 'https://arxiv.org/abs/2508.06566', 'abstract': 'Surface material recognition is a key component in robotic perception and physical interaction, particularly when leveraging both tactile and visual sensory inputs. In this work, we propose Surformer v1, a transformer-based architecture designed for surface classification using structured tactile features and PCA-reduced visual embeddings extracted via ResNet-50. The model integrates modality-specific encoders with cross-modal attention layers, enabling rich interactions between vision and touch. Currently, state-of-the-art deep learning models for vision tasks have achieved remarkable performance. With this in mind, our first set of experiments focused exclusively on tactile-only surface classification. Using feature engineering, we trained and evaluated multiple machine learning models, assessing their accuracy and inference time. We then implemented an encoder-only Transformer model tailored for tactile features. This model not only achieved the highest accuracy but also demonstrated significantly faster inference time compared to other evaluated models, highlighting its potential for real-time applications. To extend this investigation, we introduced a multimodal fusion setup by combining vision and tactile inputs. We trained both Surformer v1 (using structured features) and Multimodal CNN (using raw images) to examine the impact of feature-based versus image-based multimodal learning on classification accuracy and computational efficiency. The results showed that Surformer v1 achieved 99.4% accuracy with an inference time of 0.77 ms, while the Multimodal CNN achieved slightly higher accuracy but required significantly more inference time. These findings suggest Surformer v1 offers a compelling balance between accuracy, efficiency, and computational cost for surface material recognition.', 'abstract_zh': '表面材料识别是机器人感知和物理交互中的关键组成部分，特别是在利用触觉和视觉传感器输入时。本文提出了一种基于Transformer的Surformer v1架构，用于基于结构化触觉特征和通过ResNet-50提取的PCA降维视觉嵌入的表面分类。该模型结合了模态特定编码器和跨模态注意力层，实现了视觉和触觉之间的丰富交互。当前，用于视觉任务的最先进的深度学习模型已取得了突出的性能。因此，我们首先进行了一系列基于触觉的表面分类实验。通过特征工程，我们训练并评估了多个机器学习模型，检查它们的准确性和推理时间。随后，我们实现了一个专门针对触觉特征的编码器模型。该模型不仅实现了最高的准确率，还展示了比其他评估模型显著更快的推理时间，突显了其在实时应用中的潜力。为进一步研究，我们通过结合视觉和触觉输入引入了一种多模态融合架构。我们分别训练了Surformer v1（使用结构化特征）和Multimodal CNN（使用原始图像），以检查基于特征的多模态学习与基于图像的多模态学习对分类准确性和计算效率的影响。结果显示，Surformer v1实现了99.4%的准确率和0.77毫秒的推理时间，而Multimodal CNN虽然具有略高的准确率，但推理时间却显著更长。这些发现表明，Surformer v1在准确率、效率和计算成本之间提供了均衡的解决方案，适用于表面材料识别。', 'title_zh': 'Surformer v1: 基于触觉和视觉特征的Transformer表面分类'}
{'arxiv_id': 'arXiv:2508.06548', 'title': 'Factor Augmented Supervised Learning with Text Embeddings', 'authors': 'Zhanye Luo, Yuefeng Han, Xiufan Yu', 'link': 'https://arxiv.org/abs/2508.06548', 'abstract': 'Large language models (LLMs) generate text embeddings from text data, producing vector representations that capture the semantic meaning and contextual relationships of words. However, the high dimensionality of these embeddings often impedes efficiency and drives up computational cost in downstream tasks. To address this, we propose AutoEncoder-Augmented Learning with Text (AEALT), a supervised, factor-augmented framework that incorporates dimension reduction directly into pre-trained LLM workflows. First, we extract embeddings from text documents; next, we pass them through a supervised augmented autoencoder to learn low-dimensional, task-relevant latent factors. By modeling the nonlinear structure of complex embeddings, AEALT outperforms conventional deep-learning approaches that rely on raw embeddings. We validate its broad applicability with extensive experiments on classification, anomaly detection, and prediction tasks using multiple real-world public datasets. Numerical results demonstrate that AEALT yields substantial gains over both vanilla embeddings and several standard dimension reduction methods.', 'abstract_zh': '大规模语言模型（LLMs）生成文本嵌入，产生捕捉单词语义意义和上下文关系的向量表示。然而，这些嵌入的高维度往往阻碍了下游任务中的效率并增加了计算成本。为了解决这一问题，我们提出了一种监督学习下的文本增强自编码器框架（AEALT），该框架直接将维度减小集成到预训练LLM的工作流程中。首先，从文本文档中提取嵌入；接着，通过监督增强自编码器学习低维度的任务相关潜在因素。通过建模复杂嵌入的非线性结构，AEALT优于依赖原始嵌入的传统深度学习方法。我们使用多个真实世界的公开数据集进行了广泛实验，验证了其在分类、异常检测和预测任务中的广泛应用。数值结果表明，AEALT在 vanilla 嵌入和几种标准维度减小方法上均取得了显著的优势。', 'title_zh': '文本嵌入增强的监督学习因子方法'}
{'arxiv_id': 'arXiv:2508.06538', 'title': 'Symbolic Learning of Interpretable Reduced-Order Models for Jumping Quadruped Robots', 'authors': 'Gioele Buriani, Jingyue Liu, Maximilian Stölzle, Cosimo Della Santina, Jiatao Ding', 'link': 'https://arxiv.org/abs/2508.06538', 'abstract': 'Reduced-order models are essential for motion planning and control of quadruped robots, as they simplify complex dynamics while preserving critical behaviors. This paper introduces a novel methodology for deriving such interpretable dynamic models, specifically for jumping. We capture the high-dimensional, nonlinear jumping dynamics in a low-dimensional latent space by proposing a learning architecture combining Sparse Identification of Nonlinear Dynamics (SINDy) with physical structural priors on the jump dynamics. Our approach demonstrates superior accuracy to the traditional actuated Spring-loaded Inverted Pendulum (aSLIP) model and is validated through simulation and hardware experiments across different jumping strategies.', 'abstract_zh': '简化模型对于四足机器人运动规划与控制至关重要，它们能简化复杂动力学的同时保留关键行为。本文介绍了一种用于跳跃的新型可解释动力模型推导方法。通过将稀疏识别非线性动力学（SINDy）与跳跃动力学的物理结构先验相结合，我们捕获高维非线性跳跃动力学在低维潜在空间中的表示，并通过仿真和硬件实验验证了该方法在不同跳跃策略下的优越准确性和有效性。', 'title_zh': '跳跃四足机器人的可解释降阶模型的符号学习'}
{'arxiv_id': 'arXiv:2508.06534', 'title': 'MetAdv: A Unified and Interactive Adversarial Testing Platform for Autonomous Driving', 'authors': 'Aishan Liu, Jiakai Wang, Tianyuan Zhang, Hainan Li, Jiangfan Liu, Siyuan Liang, Yilong Ren, Xianglong Liu, Dacheng Tao', 'link': 'https://arxiv.org/abs/2508.06534', 'abstract': 'Evaluating and ensuring the adversarial robustness of autonomous driving (AD) systems is a critical and unresolved challenge. This paper introduces MetAdv, a novel adversarial testing platform that enables realistic, dynamic, and interactive evaluation by tightly integrating virtual simulation with physical vehicle feedback. At its core, MetAdv establishes a hybrid virtual-physical sandbox, within which we design a three-layer closed-loop testing environment with dynamic adversarial test evolution. This architecture facilitates end-to-end adversarial evaluation, ranging from high-level unified adversarial generation, through mid-level simulation-based interaction, to low-level execution on physical vehicles. Additionally, MetAdv supports a broad spectrum of AD tasks, algorithmic paradigms (e.g., modular deep learning pipelines, end-to-end learning, vision-language models). It supports flexible 3D vehicle modeling and seamless transitions between simulated and physical environments, with built-in compatibility for commercial platforms such as Apollo and Tesla. A key feature of MetAdv is its human-in-the-loop capability: besides flexible environmental configuration for more customized evaluation, it enables real-time capture of physiological signals and behavioral feedback from drivers, offering new insights into human-machine trust under adversarial conditions. We believe MetAdv can offer a scalable and unified framework for adversarial assessment, paving the way for safer AD.', 'abstract_zh': '评估和确保自动驾驶（AD）系统的鲁棒性对抗攻击是一项关键且未解决的挑战。本文介绍了MetAdv，这是一个新颖的对抗测试平台，通过紧密整合虚拟仿真与物理车辆反馈，实现现实、动态和互动的评估。MetAdv在核心上建立了一个混合虚拟-物理的沙盒，设计了一个层次化的闭环测试环境，支持动态的对抗测试演化。该架构从高层次的统一对抗生成，到中间层次的基于仿真的交互，再到低层次的物理车辆执行，促进了端到端的对抗评估。此外，MetAdv支持广泛的AD任务和算法范式（例如模块化深度学习管道、端到端学习、视觉-语言模型）。它支持灵活的3D车辆建模，并可在仿真和物理环境之间无缝过渡，内置兼容性支持如Apollo和Tesla等商业平台。MetAdv的一个关键特性是其人机在环能力：除了灵活的环境配置以进行更定制化的评估，它还能实现实时捕获驾驶员的生理信号和行为反馈，为对抗条件下的人机信任提供新的见解。我们相信MetAdv可以提供一个可扩展且统一的对抗评估框架，为更安全的自动驾驶铺平道路。', 'title_zh': 'MetAdv：自主驾驶统一互动 adversarial 测试平台'}
{'arxiv_id': 'arXiv:2508.06533', 'title': 'The Art of Breaking Words: Rethinking Multilingual Tokenizer Design', 'authors': 'Aamod Thakur, Ajay Nagpal, Atharva Savarkar, Kundeshwar Pundalik, Siddhesh Dosi, Piyush Sawarkar, Viraj Thakur, Rohit Saluja, Maunendra Sankar Desarkar, Ganesh Ramakrishnan', 'link': 'https://arxiv.org/abs/2508.06533', 'abstract': 'While model architecture and training objectives are well-studied, tokenization, particularly in multilingual contexts, remains a relatively neglected aspect of Large Language Model (LLM) development. Existing tokenizers often exhibit high token-to-word ratios, inefficient use of context length, and slower inference. We present a systematic study that links vocabulary size, pre-tokenization rules, and training-corpus composition to both token-to-word efficiency and model quality. To ground our analysis in a linguistically diverse context, we conduct extensive experiments on Indic scripts, which present unique challenges due to their high script diversity and orthographic complexity. Drawing on the insights from these analyses, we propose a novel algorithm for data composition that balances multilingual data for tokenizer training. Our observations on pretokenization strategies significantly improve model performance, and our data composition algorithm reduces the average token-to-word ratio by approximately 6% with respect to the conventional data randomization approach. Our tokenizer achieves more than 40% improvement on average token-to-word ratio against stateof-the-art multilingual Indic models. This improvement yields measurable gains in both model performance and inference speed. This highlights tokenization alongside architecture and training objectives as a critical lever for building efficient, scalable multilingual LLMs', 'abstract_zh': 'while模型架构和训练目标已得到充分研究，但在多语言背景下，标记化仍然是大型语言模型（LLM）开发中相对被忽视的部分。现有的标记化工具往往具有较高的标记到词的比例、低效的上下文长度使用以及较慢的推理速度。我们进行了一项系统性的研究，将词汇量、预标记规则和训练语料库组成与标记到词的效率及模型质量联系起来。为了将分析置于语言多样的背景下，我们在印度脚本上进行了广泛的实验，由于其高脚本多样性和表记复杂性，这为标记化带来了独特的挑战。基于这些分析的洞察，我们提出了一个新颖的数据组成算法，以平衡训练标记化器的多语言数据。我们的预标记化策略观察结果显著提升了模型性能，而我们提出的数据组成算法与传统的数据随机化方法相比，将平均标记到词比例降低了约6%。与最先进的多语言印度脚本模型相比，我们的标记化器将平均标记到词比例提高了超过40%。这一改进在模型性能和推理速度方面都带来了可量化的提升。这突显了标记化与架构和训练目标一样，是构建高效且可扩展的多语言LLM的关键杠杆。', 'title_zh': '词语的艺术：重塑多语言分\n Möglichkeiten der Zugeacherung在多语言分 Tokenizer设计 Patio中探讨lógicadragon'}
{'arxiv_id': 'arXiv:2508.06528', 'title': 'A Framework Combining 3D CNN and Transformer for Video-Based Behavior Recognition', 'authors': 'Xiuliang Zhang, Tadiwa Elisha Nyamasvisva, Chuntao Liu', 'link': 'https://arxiv.org/abs/2508.06528', 'abstract': 'Video-based behavior recognition is essential in fields such as public safety, intelligent surveillance, and human-computer interaction. Traditional 3D Convolutional Neural Network (3D CNN) effectively capture local spatiotemporal features but struggle with modeling long-range dependencies. Conversely, Transformers excel at learning global contextual information but face challenges with high computational costs. To address these limitations, we propose a hybrid framework combining 3D CNN and Transformer architectures. The 3D CNN module extracts low-level spatiotemporal features, while the Transformer module captures long-range temporal dependencies, with a fusion mechanism integrating both representations. Evaluated on benchmark datasets, the proposed model outperforms traditional 3D CNN and standalone Transformers, achieving higher recognition accuracy with manageable complexity. Ablation studies further validate the complementary strengths of the two modules. This hybrid framework offers an effective and scalable solution for video-based behavior recognition.', 'abstract_zh': '基于视频的行为识别在公共安全、智能监控和人机交互等领域至关重要。为了克服传统3D卷积神经网络（3D CNN）在捕捉长距离依赖性方面的不足以及变换器在全局上下文信息学习上的高计算成本问题，我们提出了一种结合3D CNN和变换器架构的混合框架。该框架中的3D CNN模块提取低层次的时空特征，变换器模块捕捉长距离时间依赖性，并通过融合机制整合两种表示。在基准数据集上的评估表明，所提出模型的识别准确性较高，且具有可管理的复杂度。进一步的消融研究进一步验证了两个模块互补的优势。该混合框架为基于视频的行为识别提供了一种有效且可扩展的解决方案。', 'title_zh': '一种结合3D CNN和Transformer的视频行为识别框架'}
{'arxiv_id': 'arXiv:2508.06526', 'title': 'PiKV: KV Cache Management System for Mixture of Experts', 'authors': 'Dong Liu, Yanxuan Yu, Ben Lengerich, Ying Nian Wu, Xuhong Wang', 'link': 'https://arxiv.org/abs/2508.06526', 'abstract': 'As large language models continue to scale up in both size and context length, the memory and communication cost of key-value (KV) cache storage has become a major bottleneck in multi-GPU and multi-node inference. While MoE-based architectures sparsify computation across experts, the corresponding KV caches remain dense and globally synchronized, resulting in significant overhead.\nWe introduce \\textbf{PiKV}, a parallel and distributed KV cache serving framework tailored for MoE architecture. PiKV leverages \\textit{expert-sharded KV storage} to partition caches across GPUs, \\textit{PiKV routing} to reduce token-to-KV access, and a \\textit{PiKV Scheduling} to adaptively retain query-relevant entries. To further reduce memory usage, PiKV integrates \\textit{PiKV Compression} modules the caching pipeline for acceleration.\nPiKV is recently publicly available as an open-source software library: \\href{this https URL}{this https URL}. Experiments details is recorded at: \\href{this https URL}{this https URL\\_Results}. We also have PiKV integrated with Nvidia kvpress for acceleration, details see \\href{this https URL}{this https URL}. PiKV is still a living project, aiming to become a comprehesive KV Cache management system for MoE Architectures.', 'abstract_zh': '基于MoE架构的并行分布式Key-Value缓存服务框架PiKV', 'title_zh': 'PiKV: 专家混合模型的键值缓存管理系统'}
{'arxiv_id': 'arXiv:2508.06524', 'title': 'CarbonScaling: Extending Neural Scaling Laws for Carbon Footprint in Large Language Models', 'authors': 'Lei Jiang, Fan Chen', 'link': 'https://arxiv.org/abs/2508.06524', 'abstract': 'Neural scaling laws have driven the development of increasingly large language models (LLMs) by linking accuracy improvements to growth in parameter count, dataset size, and compute. However, these laws overlook the carbon emissions that scale exponentially with LLM size. This paper presents \\textit{CarbonScaling}, an analytical framework that extends neural scaling laws to incorporate both operational and embodied carbon in LLM training. By integrating models for neural scaling, GPU hardware evolution, parallelism optimization, and carbon estimation, \\textit{CarbonScaling} quantitatively connects model accuracy to carbon footprint. Results show that while a power-law relationship between accuracy and carbon holds, real-world inefficiencies significantly increase the scaling factor. Hardware technology scaling reduces carbon emissions for small to mid-sized models, but offers diminishing returns for extremely large LLMs due to communication overhead and underutilized GPUs. Training optimizations-especially aggressive critical batch size scaling-help alleviate this inefficiency. \\textit{CarbonScaling} offers key insights for training more sustainable and carbon-efficient LLMs.', 'abstract_zh': '神经缩放定律通过将准确率改进与参数数量、数据集规模和计算资源的增长相关联，推动了大型语言模型（LLMs）的发展。然而，这些定律忽略了与LLM规模成指数增长的碳排放。本文提出了CarbonScaling这一分析框架，将神经缩放定律扩展以纳入LLM训练中的操作碳和嵌入碳。通过集成神经缩放模型、GPU硬件演进模型、并行优化模型和碳排放估算模型，CarbonScaling定量地将模型准确率与碳足迹联系起来。结果表明，尽管准确率和碳排放之间存在幂律关系，但现实中的低效性显著增加了缩放因子。硬件技术的进步可以减少小型到中型模型的碳排放，但对于极大型LLM却因通信开销和GPU利用率不足而效果递减。训练优化，尤其是激进的关键批次大小缩放，有助于缓解这种低效性。CarbonScaling为培训更加可持续和碳效率高的LLM提供了关键见解。', 'title_zh': '碳足迹扩展：将神经网络缩放定律应用于大型语言模型的碳足迹'}
{'arxiv_id': 'arXiv:2508.06504', 'title': 'Retrieval augmented generation based dynamic prompting for few-shot biomedical named entity recognition using large language models', 'authors': 'Yao Ge, Sudeshna Das, Yuting Guo, Abeed Sarker', 'link': 'https://arxiv.org/abs/2508.06504', 'abstract': 'Biomedical named entity recognition (NER) is a high-utility natural language processing (NLP) task, and large language models (LLMs) show promise particularly in few-shot settings (i.e., limited training data). In this article, we address the performance challenges of LLMs for few-shot biomedical NER by investigating a dynamic prompting strategy involving retrieval-augmented generation (RAG). In our approach, the annotated in-context learning examples are selected based on their similarities with the input texts, and the prompt is dynamically updated for each instance during inference. We implemented and optimized static and dynamic prompt engineering techniques and evaluated them on five biomedical NER datasets. Static prompting with structured components increased average F1-scores by 12% for GPT-4, and 11% for GPT-3.5 and LLaMA 3-70B, relative to basic static prompting. Dynamic prompting further improved performance, with TF-IDF and SBERT retrieval methods yielding the best results, improving average F1-scores by 7.3% and 5.6% in 5-shot and 10-shot settings, respectively. These findings highlight the utility of contextually adaptive prompts via RAG for biomedical NER.', 'abstract_zh': '生物医学实体识别（NER）是高实用性的自然语言处理（NLP）任务，大规模语言模型（LLMs）在少量标注数据的情况下显示出巨大的潜力。本文通过研究检索增强生成（RAG）的动态提示策略，解决了LLMs在少量标注数据的生物医学NER中的性能挑战。我们根据输入文本与其标注上下文学习示例的相似性选择了标注的上下文学习示例，并在推理过程中动态更新提示。我们实现了并优化了静态和动态提示工程技术，并在这五个生物医学NER数据集上进行了评估。含有结构化组件的静态提示将GPT-4的平均F1分数提高了12%，GPT-3.5和LLaMA 3-70B的平均F1分数提高了11%，相对于基本的静态提示。动态提示进一步提高了性能，在5-shot和10-shot设置中，分别通过TF-IDF和SBERT检索方法提高了7.3%和5.6%的平均F1分数。这些发现突显了通过RAG实现上下文自适应提示在生物医学NER中的实用性。', 'title_zh': '基于检索增强生成的动态提示在大规模语言模型下用于少样本生物医学命名实体识别'}
{'arxiv_id': 'arXiv:2508.06503', 'title': 'Understanding Human Limits in Pattern Recognition: A Computational Model of Sequential Reasoning in Rock, Paper, Scissors', 'authors': 'Logan Cross, Erik Brockbank, Tobias Gerstenberg, Judith E. Fan, Daniel L. K. Yamins, Nick Haber', 'link': 'https://arxiv.org/abs/2508.06503', 'abstract': "How do we predict others from patterns in their behavior and what are the computational constraints that limit this ability? We investigate these questions by modeling human behavior over repeated games of rock, paper, scissors from Brockbank & Vul (2024). Against algorithmic opponents that varied in strategic sophistication, people readily exploit simple transition patterns (e.g., consistently playing rock after paper) but struggle to detect more complex sequential dependencies. To understand the cognitive mechanisms underlying these abilities and their limitations, we deploy Hypothetical Minds (HM), a large language model-based agent that generates and tests hypotheses about opponent strategies, as a cognitive model of this behavior (Cross et al., 2024). We show that when applied to the same experimental conditions, HM closely mirrors human performance patterns, succeeding and failing in similar ways. To better understand the source of HM's failures and whether people might face similar cognitive bottlenecks in this context, we performed a series of ablations and augmentations targeting different components of the system. When provided with natural language descriptions of the opponents' strategies, HM successfully exploited 6/7 bot opponents with win rates >80% suggesting that accurate hypothesis generation is the primary cognitive bottleneck in this task. Further, by systematically manipulating the model's hypotheses through pedagogically-inspired interventions, we find that the model substantially updates its causal understanding of opponent behavior, revealing how model-based analyses can produce testable hypotheses about human cognition.", 'abstract_zh': '从行为模式预测他人行为及其计算约束：基于Brockbank & Vul (2024) 中多次玩石头-剪刀-布游戏的人类行为建模，我们探讨了这一问题。我们使用Hypothetical Minds (HM) 大语言模型代理来生成和测试关于对手策略的假设，作为一种认知模型来理解这些能力和其局限性。我们展示了当应用于相同的实验条件时，HM 接近人类的表现模式，成功和失败的方式相似。为了更好地理解HM失败的来源以及人们是否在类似情境下面临类似的认知瓶颈，我们对系统的不同组件进行了消融和增强实验。通过提供对手策略的自然语言描述，HM 成功利用了6/7个对手，胜率超过80%，这表明准确的假设生成是此任务中的主要认知瓶颈。此外，通过系统地调整模型的假设，我们发现模型对其对手行为的因果理解显著更新，揭示了基于模型的分析如何产生可测试的人类认知假设。', 'title_zh': '理解人类在模式识别中的局限性：基于石头、剪刀、布序列推理的计算模型'}
{'arxiv_id': 'arXiv:2508.06501', 'title': 'Computing with Canonical Microcircuits', 'authors': 'PK Douglas', 'link': 'https://arxiv.org/abs/2508.06501', 'abstract': 'The human brain represents the only known example of general intelligence that naturally aligns with human values. On a mere 20-watt power budget, the brain achieves robust learning and adaptive decision-making in ways that continue to elude advanced AI systems. Inspired by the brain, we present a computational architecture based on canonical microcircuits (CMCs) - stereotyped patterns of neurons found ubiquitously throughout the cortex. We implement these circuits as neural ODEs comprising spiny stellate, inhibitory, and pyramidal neurons, forming an 8-dimensional dynamical system with biologically plausible recurrent connections. Our experiments show that even a single CMC node achieves 97.8 percent accuracy on MNIST, while hierarchical configurations - with learnable inter-regional connectivity and recurrent connections - yield improved performance on more complex image benchmarks. Notably, our approach achieves competitive results using substantially fewer parameters than conventional deep learning models. Phase space analysis revealed distinct dynamical trajectories for different input classes, highlighting interpretable, emergent behaviors observed in biological systems. These findings suggest that neuromorphic computing approaches can improve both efficiency and interpretability in artificial neural networks, offering new directions for parameter-efficient architectures grounded in the computational principles of the human brain.', 'abstract_zh': '人类大脑是唯一已知与人类价值自然对齐的一般智能实例。在仅20瓦的功率预算下，大脑以高级AI系统仍未解决的方式实现稳健的学习和适应性决策。受大脑启发，我们提出了一种基于经典微回路（CMCs）的计算架构——广泛存在于皮层中的标准化神经元模式。我们通过脉刺星形、抑制性及锥形神经元实现这些电路，形成一个具有生物可 plausilble 循环连接的8维动力系统。实验表明，单个CMC节点在MNIST上的准确率达到97.8%，而层次化配置——具有可学习跨区域连接和循环连接——在更复杂的图像基准测试中表现出更好的性能。值得注意的是，与传统的深度学习模型相比，我们的方法使用了大量较少的参数实现了竞争力的结果。相空间分析揭示了不同输入类别独特的动力学轨迹，突出了在生物系统中观察到的可解释、涌现的行为。这些发现表明，神经形态计算方法可以提高人工神经网络的效率和可解释性，为基于人类大脑计算原理的参数高效架构提供新的方向。', 'title_zh': '使用规范微回路进行计算'}
{'arxiv_id': 'arXiv:2508.06499', 'title': 'Network-Specific Models for Multimodal Brain Response Prediction', 'authors': 'Andrea Corsico, Giorgia Rigamonti, Simone Zini, Luigi Celona, Paolo Napoletano', 'link': 'https://arxiv.org/abs/2508.06499', 'abstract': 'In this work, we present a network-specific approach for predicting brain responses to complex multimodal movies, leveraging the Yeo 7-network parcellation of the Schaefer atlas. Rather than treating the brain as a homogeneous system, we grouped the seven functional networks into four clusters and trained separate multi-subject, multi-layer perceptron (MLP) models for each. This architecture supports cluster-specific optimization and adaptive memory modeling, allowing each model to adjust temporal dynamics and modality weighting based on the functional role of its target network. Our results demonstrate that this clustered strategy significantly enhances prediction accuracy across the 1,000 cortical regions of the Schaefer atlas. The final model achieved an eighth-place ranking in the Algonauts Project 2025 Challenge, with out-of-distribution (OOD) correlation scores nearly double those of the baseline model used in the selection phase. Code is available at this https URL.', 'abstract_zh': '本研究提出了一种针对网络的方法，用于预测对复杂多模态电影的大脑反应，利用Schaefer图谱的Yeo 7网络分区。我们不是将大脑视为一个均质系统，而是将七个功能网络分为四个簇，并为每个簇分别训练多主题、多层感知机（MLP）模型。该架构支持簇特定优化和自适应记忆建模，使每个模型能够根据目标网络的功能作用调整时间动态和模态权重。实验结果表明，这种方法显著提高了Schaefer图谱1000个皮层区的预测准确性。最终模型在Algonauts项目2025挑战赛中获得第八名，其离群分布外相关分数几乎是选择阶段基线模型的两倍。代码见此链接。', 'title_zh': '网络特定模型多模态脑响应预测'}
{'arxiv_id': 'arXiv:2508.06497', 'title': 'Forecasting Commodity Price Shocks Using Temporal and Semantic Fusion of Prices Signals and Agentic Generative AI Extracted Economic News', 'authors': 'Mohammed-Khalil Ghali, Cecil Pang, Oscar Molina, Carlos Gershenson-Garcia, Daehan Won', 'link': 'https://arxiv.org/abs/2508.06497', 'abstract': 'Accurate forecasting of commodity price spikes is vital for countries with limited economic buffers, where sudden increases can strain national budgets, disrupt import-reliant sectors, and undermine food and energy security. This paper introduces a hybrid forecasting framework that combines historical commodity price data with semantic signals derived from global economic news, using an agentic generative AI pipeline. The architecture integrates dual-stream Long Short-Term Memory (LSTM) networks with attention mechanisms to fuse structured time-series inputs with semantically embedded, fact-checked news summaries collected from 1960 to 2023. The model is evaluated on a 64-year dataset comprising normalized commodity price series and temporally aligned news embeddings. Results show that the proposed approach achieves a mean AUC of 0.94 and an overall accuracy of 0.91 substantially outperforming traditional baselines such as logistic regression (AUC = 0.34), random forest (AUC = 0.57), and support vector machines (AUC = 0.47). Additional ablation studies reveal that the removal of attention or dimensionality reduction leads to moderate declines in performance, while eliminating the news component causes a steep drop in AUC to 0.46, underscoring the critical value of incorporating real-world context through unstructured text. These findings demonstrate that integrating agentic generative AI with deep learning can meaningfully improve early detection of commodity price shocks, offering a practical tool for economic planning and risk mitigation in volatile market environments while saving the very high costs of operating a full generative AI agents pipeline.', 'abstract_zh': '准确预测商品价格突增对于经济缓冲有限的国家至关重要，突发的价格上涨会加剧国家预算压力、扰乱依赖进口的行业，并削弱食品和能源安全。本文提出了一种结合历史商品价格数据和源自全球经济新闻的语义信号的混合预测框架，采用了一种代理生成式AI流水线。该架构整合了带有注意力机制的双流长短期记忆（LSTM）网络，将结构化的时间序列输入与从1960年至2023年搜集的事实检查新闻摘要语义嵌入融合起来。模型在包含64年规范化的商品价格系列和时间对齐的新闻嵌入的数据集上进行了评估。结果显示，所提出的方法达到了平均AUC值0.94和总体准确率0.91，显著优于传统基线方法如逻辑回归（AUC = 0.34）、随机森林（AUC = 0.57）和支持向量机（AUC = 0.47）。额外的消融研究显示，移除注意力机制或进行维度减少会导致性能适度下降，而消除新闻成分会导致AUC急剧下降到0.46，强调了通过非结构化文本融入现实世界背景的重要性。这些发现表明，将代理生成式AI与深度学习整合起来，可以显著提高对商品价格冲击的早期检测能力，为波动市场环境下经济规划和风险缓解提供实用工具，同时节省运行完整生成式AI代理流水线的高昂成本。', 'title_zh': '使用价格信号和代理生成AI提取经济新闻的时间性和语义融合预测商品价格冲击'}
{'arxiv_id': 'arXiv:2508.06495', 'title': 'Semi-automated Fact-checking in Portuguese: Corpora Enrichment using Retrieval with Claim extraction', 'authors': "Juliana Resplande Sant'anna Gomes, Arlindo Rodrigues Galvão Filho", 'link': 'https://arxiv.org/abs/2508.06495', 'abstract': "The accelerated dissemination of disinformation often outpaces the capacity for manual fact-checking, highlighting the urgent need for Semi-Automated Fact-Checking (SAFC) systems. Within the Portuguese language context, there is a noted scarcity of publicly available datasets that integrate external evidence, an essential component for developing robust AFC systems, as many existing resources focus solely on classification based on intrinsic text features. This dissertation addresses this gap by developing, applying, and analyzing a methodology to enrich Portuguese news corpora (this http URL, this http URL, MuMiN-PT) with external evidence. The approach simulates a user's verification process, employing Large Language Models (LLMs, specifically Gemini 1.5 Flash) to extract the main claim from texts and search engine APIs (Google Search API, Google FactCheck Claims Search API) to retrieve relevant external documents (evidence). Additionally, a data validation and preprocessing framework, including near-duplicate detection, is introduced to enhance the quality of the base corpora.", 'abstract_zh': '加速传播的错误信息往往超越了人工事实核查的能力，突显了半自动事实核查系统（SAFC）的迫切需求。在葡萄牙语语言背景下，公开可用的集成了外部证据的数据集存在显著不足，而外部证据是开发 robust 半自动事实核查系统（AFC）的重要组成部分，因为许多现有资源仅专注于基于文本内在特征的分类。本论文通过开发、应用和分析一种方法来丰富葡萄牙语新闻语料库（包括 this http URL, this http URL, MuMiN-PT），以补充外部证据。该方法模拟用户的验证过程，利用大规模语言模型（LLMs，具体为 Gemini 1.5 Flash）从文本中提取主要声明，并使用搜索引擎 API（Google Search API 和 Google FactCheck Claims Search API）检索相关的外部文件（证据）。此外，还介绍了一种数据验证和预处理框架，包括近似重复检测，以提高基础语料库的质量。', 'title_zh': 'Portuguese语半自动化事实核查：基于检索的主张提取与语料库丰富化研究'}
{'arxiv_id': 'arXiv:2508.05691', 'title': 'AuthPrint: Fingerprinting Generative Models Against Malicious Model Providers', 'authors': 'Kai Yao, Marc Juarez', 'link': 'https://arxiv.org/abs/2508.05691', 'abstract': "Generative models are increasingly adopted in high-stakes domains, yet current deployments offer no mechanisms to verify the origin of model outputs. We address this gap by extending model fingerprinting techniques beyond the traditional collaborative setting to one where the model provider may act adversarially. To our knowledge, this is the first work to evaluate fingerprinting for provenance attribution under such a threat model. The methods rely on a trusted verifier that extracts secret fingerprints from the model's output space, unknown to the provider, and trains a model to predict and verify them. Our empirical evaluation shows that our methods achieve near-zero FPR@95%TPR for instances of GAN and diffusion models, even when tested on small modifications to the original architecture and training data. Moreover, the methods remain robust against adversarial attacks that actively modify the outputs to bypass detection. Source codes are available at this https URL.", 'abstract_zh': '生成模型在高风险领域中的应用日益增多，然而当前的部署并未提供验证模型输出来源的机制。本文通过将模型指纹识别技术从传统的协作环境扩展到模型提供者可能采取对抗性行为的环境中予以解决。据我们所知，这是首次在这样的威胁模型下评估指纹识别用于来源归属的工作。该方法依赖于一个可信的验证者，后者从模型的输出空间中提取未知于提供者的秘密指纹，并训练模型来预测和验证这些指纹。我们的实证评估表明，即使在对原始架构和训练数据进行微小修改的情况下，我们的方法也能够实现接近零的FPR@95%TPR。此外，该方法对于试图修改输出以绕过检测的对抗性攻击仍具有鲁棒性。源代码可在以下链接获取：this https URL。', 'title_zh': 'AuthPrint: 针对恶意模型提供者的生成模型指针技术'}
{'arxiv_id': 'arXiv:2505.23197', 'title': 'UPP: Unified Path Planner with Adaptive Safety and Optimality', 'authors': 'Jatin Kumar Arora, Shubhendu Bhasin', 'link': 'https://arxiv.org/abs/2505.23197', 'abstract': "We are surrounded by robots helping us perform complex tasks. Robots have a wide range of applications, from industrial automation to personalized assistance. However, with great technological innovation come significant challenges. One of the major challenges in robotics is path planning. Despite advancements such as graph search, sampling, and potential field methods, most path planning algorithms focus either on optimality or on safety. Very little research addresses both simultaneously. We propose a Unified Path Planner (UPP) that uses modified heuristics and a dynamic safety cost function to balance safety and optimality. The level of safety can be adjusted via tunable parameters, trading off against computational complexity. We demonstrate the planner's performance in simulations, showing how parameter variation affects results. UPP is compared with various traditional and safe-optimal planning algorithms across different scenarios. We also validate it on a TurtleBot, where the robot successfully finds safe and sub-optimal paths.", 'abstract_zh': '我们周围充斥着帮助我们完成复杂任务的机器人。机器人有着广泛的应用范围，从工业自动化到个性化辅助。然而，随着技术的不断革新，随之而来的挑战也极为严峻。机器人领域的一个主要挑战是路径规划。尽管已经出现了诸如图搜索、采样和势场方法等进步，但大多数路径规划算法要么关注最优性，要么关注安全性。很少有研究同时兼顾两者。我们提出了一种统一路径规划器（UPP），它利用修改后的启发式方法和动态安全成本函数来平衡安全性和最优性。通过可调参数可以调整安全水平，这会牺牲计算复杂度。我们在仿真实验中展示了规划器的性能，展示了参数变化如何影响结果。UPP 在与各种传统及安全最优规划算法的对比中，在不同场景下得到了验证，并且在TurtleBot上也成功找到了安全但次优的路径。', 'title_zh': '统一路径规划器：自适应安全与最优性结合'}
