{'arxiv_id': 'arXiv:2508.04696', 'title': 'Achieving Precise and Reliable Locomotion with Differentiable Simulation-Based System Identification', 'authors': 'Vyacheslav Kovalev, Ekaterina Chaikovskaia, Egor Davydenko, Roman Gorbachev', 'link': 'https://arxiv.org/abs/2508.04696', 'abstract': 'Accurate system identification is crucial for reducing trajectory drift in bipedal locomotion, particularly in reinforcement learning and model-based control. In this paper, we present a novel control framework that integrates system identification into the reinforcement learning training loop using differentiable simulation. Unlike traditional approaches that rely on direct torque measurements, our method estimates system parameters using only trajectory data (positions, velocities) and control inputs. We leverage the differentiable simulator MuJoCo-XLA to optimize system parameters, ensuring that simulated robot behavior closely aligns with real-world motion. This framework enables scalable and flexible parameter optimization. Accurate system identification is crucial for reducing trajectory drift in bipedal locomotion, particularly in reinforcement learning and model-based control. In this paper, we present a novel control framework that integrates system identification into the reinforcement learning training loop using differentiable simulation. Unlike traditional approaches that rely on direct torque measurements, our method estimates system parameters using only trajectory data (positions, velocities) and control inputs. We leverage the differentiable simulator MuJoCo-XLA to optimize system parameters, ensuring that simulated robot behavior closely aligns with real-world motion. This framework enables scalable and flexible parameter optimization. It supports fundamental physical properties such as mass and inertia. Additionally, it handles complex system nonlinear behaviors, including advanced friction models, through neural network approximations. Experimental results show that our framework significantly improves trajectory following.', 'abstract_zh': '准确的系统识别对于减少双足步行中的轨迹漂移，特别是在强化学习和模型导向控制中，至关重要。本文提出了一种新的控制框架，将系统识别集成到强化学习训练循环中，使用可微分仿真。与依赖直接扭矩测量的传统方法不同，我们的方法仅通过轨迹数据（位置、速度）和控制输入估计系统参数。我们利用可微分仿真器MuJoCo-XLA优化系统参数，确保模拟的机器人行为与现实世界运动紧密一致。该框架支持大规模和灵活的参数优化。准确的系统识别对于减少双足步行中的轨迹漂移，特别是在强化学习和模型导向控制中，至关重要。本文提出了一种新的控制框架，将系统识别集成到强化学习训练循环中，使用可微分仿真。与依赖直接扭矩测量的传统方法不同，我们的方法仅通过轨迹数据（位置、速度）和控制输入估计系统参数。我们利用可微分仿真器MuJoCo-XLA优化系统参数，确保模拟的机器人行为与现实世界运动紧密一致。该框架支持大规模和灵活的参数优化。', 'title_zh': '基于可微模拟的系统识别实现精确可靠的運動控制'}
{'arxiv_id': 'arXiv:2508.04691', 'title': 'From MAS to MARS: Coordination Failures and Reasoning Trade-offs in Hierarchical Multi-Agent Robotic Systems within a Healthcare Scenario', 'authors': 'Yuanchen Bai, Zijian Ding, Shaoyue Wen, Xiang Chang, Angelique Taylor', 'link': 'https://arxiv.org/abs/2508.04691', 'abstract': "Multi-agent robotic systems (MARS) build upon multi-agent systems by integrating physical and task-related constraints, increasing the complexity of action execution and agent coordination. However, despite the availability of advanced multi-agent frameworks, their real-world deployment on robots remains limited, hindering the advancement of MARS research in practice. To bridge this gap, we conducted two studies to investigate performance trade-offs of hierarchical multi-agent frameworks in a simulated real-world multi-robot healthcare scenario. In Study 1, using CrewAI, we iteratively refine the system's knowledge base, to systematically identify and categorize coordination failures (e.g., tool access violations, lack of timely handling of failure reports) not resolvable by providing contextual knowledge alone. In Study 2, using AutoGen, we evaluate a redesigned bidirectional communication structure and further measure the trade-offs between reasoning and non-reasoning models operating within the same robotic team setting. Drawing from our empirical findings, we emphasize the tension between autonomy and stability and the importance of edge-case testing to improve system reliability and safety for future real-world deployment. Supplementary materials, including codes, task agent setup, trace outputs, and annotated examples of coordination failures and reasoning behaviors, are available at: this https URL.", 'abstract_zh': '多代理机器人系统（MARS）通过整合物理和任务相关的约束，增强了行动执行和代理协调的复杂性。尽管存在先进的多代理框架，但在机器人上的实际部署仍然有限，阻碍了MARS研究的实际进展。为弥补这一差距，我们进行了两项研究，以调查在模拟的真实多机器人医疗场景中分层多代理框架的性能权衡。在研究1中，我们使用CrewAI，逐步细化系统的知识库，系统地识别和分类不能仅通过提供上下文知识解决的协调失败（如工具访问违规、故障报告未能及时处理）。在研究2中，我们使用AutoGen评估改进后的双向通信结构，并进一步衡量在同一机器人团队设置中推理和非推理模型之间的权衡。从我们的实证发现中，我们强调自主性和稳定性之间的张力以及边缘案例测试的重要性，以提高未来实际部署时系统的可靠性和安全性。辅助材料，包括代码、任务代理设置、跟踪输出和协调失败及推理行为的注解示例，可在以下网址获取：this https URL。', 'title_zh': '从MAS到MARS：医疗场景下分级多智能体机器人系统中的协调失败与推理权衡研究'}
{'arxiv_id': 'arXiv:2508.04678', 'title': 'Open Scene Graphs for Open-World Object-Goal Navigation', 'authors': 'Joel Loo, Zhanxin Wu, David Hsu', 'link': 'https://arxiv.org/abs/2508.04678', 'abstract': 'How can we build general-purpose robot systems for open-world semantic navigation, e.g., searching a novel environment for a target object specified in natural language? To tackle this challenge, we introduce OSG Navigator, a modular system composed of foundation models, for open-world Object-Goal Navigation (ObjectNav). Foundation models provide enormous semantic knowledge about the world, but struggle to organise and maintain spatial information effectively at scale. Key to OSG Navigator is the Open Scene Graph representation, which acts as spatial memory for OSG Navigator. It organises spatial information hierarchically using OSG schemas, which are templates, each describing the common structure of a class of environments. OSG schemas can be automatically generated from simple semantic labels of a given environment, e.g., "home" or "supermarket". They enable OSG Navigator to adapt zero-shot to new environment types. We conducted experiments using both Fetch and Spot robots in simulation and in the real world, showing that OSG Navigator achieves state-of-the-art performance on ObjectNav benchmarks and generalises zero-shot over diverse goals, environments, and robot embodiments.', 'abstract_zh': '如何构建适用于开放世界语义导航的通用机器人系统，例如根据自然语言指定的目标对象在新型环境中进行搜索？为了应对这一挑战，我们介绍了OSG导航器，这是一个由基础模型组成的模块化系统，用于开放世界对象目标导航（ObjectNav）。基础模型提供了关于世界的大量语义知识，但在大规模组织和维护空间信息方面存在困难。OSG导航器的核心在于开放场景图表示，它作为OSG导航器的空间记忆。它通过OSG模式以层次结构组织空间信息，这些模式是模板，每个模板描述了一类环境的常见结构。OSG模式可以从给定环境的简单语义标签自动生成，例如“家庭”或“超市”。它们使OSG导航器能够零样本适应新的环境类型。我们在使用Fetch和Spot机器人进行的模拟和真实环境中实验表明，OSG导航器在对象导航基准测试中实现了最佳性能，并且能够在多样的目标、环境和机器人实体之间进行零样本泛化。', 'title_zh': '开放世界场景图用于开放目标物体导航'}
{'arxiv_id': 'arXiv:2508.04642', 'title': 'RoboTron-Sim: Improving Real-World Driving via Simulated Hard-Case', 'authors': 'Baihui Xiao, Chengjian Feng, Zhijian Huang, Feng yan, Yujie Zhong, Lin Ma', 'link': 'https://arxiv.org/abs/2508.04642', 'abstract': 'Collecting real-world data for rare high-risk scenarios, long-tailed driving events, and complex interactions remains challenging, leading to poor performance of existing autonomous driving systems in these critical situations. In this paper, we propose RoboTron-Sim that improves real-world driving in critical situations by utilizing simulated hard cases. First, we develop a simulated dataset called Hard-case Augmented Synthetic Scenarios (HASS), which covers 13 high-risk edge-case categories, as well as balanced environmental conditions such as day/night and sunny/rainy. Second, we introduce Scenario-aware Prompt Engineering (SPE) and an Image-to-Ego Encoder (I2E Encoder) to enable multimodal large language models to effectively learn real-world challenging driving skills from HASS, via adapting to environmental deviations and hardware differences between real-world and simulated scenarios. Extensive experiments on nuScenes show that RoboTron-Sim improves driving performance in challenging scenarios by around 50%, achieving state-of-the-art results in real-world open-loop planning. Qualitative results further demonstrate the effectiveness of RoboTron-Sim in better managing rare high-risk driving scenarios. Project page: this https URL', 'abstract_zh': '收集罕见高风险场景、长尾驾驶事件以及复杂交互的现实世界数据仍然具有挑战性，导致现有自动驾驶系统在这些关键情况下表现不佳。本文提出RoboTron-Sim，通过利用模拟的难案例来改进现实世界中的关键驾驶情况。首先，我们开发了一个称为难案例增强合成场景（HASS）的数据集，涵盖了13种高风险的边缘案例类别，并且平衡了昼夜和晴雨等环境条件。其次，我们引入了场景感知提示工程（SPE）和图像到自身编码器（I2E编码器），通过适应现实世界和模拟场景之间的环境差异和硬件差异，使多模态大型语言模型能够有效学习来自HASS的现实世界挑战性驾驶技能。在nuScenes上的广泛实验表明，RoboTron-Sim在挑战性场景中的驾驶性能提高了约50%，实现了在现实世界开环规划中的最先进成果。定性结果进一步证明了RoboTron-Sim在更好地管理罕见高风险驾驶场景方面的有效性。项目页面：this https URL。', 'title_zh': 'RoboTron-Sim: 通过模拟极端案例提高现实世界驾驶性能'}
{'arxiv_id': 'arXiv:2508.04598', 'title': '$NavA^3$: Understanding Any Instruction, Navigating Anywhere, Finding Anything', 'authors': 'Lingfeng Zhang, Xiaoshuai Hao, Yingbo Tang, Haoxiang Fu, Xinyu Zheng, Pengwei Wang, Zhongyuan Wang, Wenbo Ding, Shanghang Zhang', 'link': 'https://arxiv.org/abs/2508.04598', 'abstract': 'Embodied navigation is a fundamental capability of embodied intelligence, enabling robots to move and interact within physical environments. However, existing navigation tasks primarily focus on predefined object navigation or instruction following, which significantly differs from human needs in real-world scenarios involving complex, open-ended scenes. To bridge this gap, we introduce a challenging long-horizon navigation task that requires understanding high-level human instructions and performing spatial-aware object navigation in real-world environments. Existing embodied navigation methods struggle with such tasks due to their limitations in comprehending high-level human instructions and localizing objects with an open vocabulary. In this paper, we propose $NavA^3$, a hierarchical framework divided into two stages: global and local policies. In the global policy, we leverage the reasoning capabilities of Reasoning-VLM to parse high-level human instructions and integrate them with global 3D scene views. This allows us to reason and navigate to regions most likely to contain the goal object. In the local policy, we have collected a dataset of 1.0 million samples of spatial-aware object affordances to train the NaviAfford model (PointingVLM), which provides robust open-vocabulary object localization and spatial awareness for precise goal identification and navigation in complex environments. Extensive experiments demonstrate that $NavA^3$ achieves SOTA results in navigation performance and can successfully complete longhorizon navigation tasks across different robot embodiments in real-world settings, paving the way for universal embodied navigation. The dataset and code will be made available. Project website: this https URL.', 'abstract_zh': '具身导航是具身智能的基本能力，使机器人能够在物理环境中移动和交互。然而，现有的导航任务主要侧重于预定义的对象导航或指令跟随，这与真实世界场景中复杂、开放性场景下人类的需求存在显著差异。为弥补这一差距，我们引入了一个具有挑战性的长期导航任务，要求理解高层次的人类指令并在真实环境中的进行空间感知对象导航。现有的具身导航方法由于难以理解高层次的人类指令和定位具有开放词汇的对象而难以完成此类任务。在本文中，我们提出了一种分层框架$NavA^3$，分为两个阶段：全局策略和局部策略。在全局策略中，我们利用Reasoning-VLM的推理能力解析高层次的人类指令，并将其与全局3D场景视图相结合，从而能够推理和导航到最有可能包含目标对象的区域。在局部策略中，我们收集了100万样本的空间感知对象操作数据集来训练NaviAfford模型（PointingVLM），该模型提供了在复杂环境中的鲁棒的开放词汇对象定位和空间感知，以实现精确的目标识别和导航。广泛的实验表明，$NavA^3$在导航性能方面取得了SOTA结果，并且可以在不同机器人具身形态的真实环境中成功完成长期导航任务，为普遍适用的具身导航铺平了道路。数据集和代码将开源。项目网站：this https URL。', 'title_zh': '$NavA^3$: 理解任何指令，前往任何地点，查找任何事物'}
{'arxiv_id': 'arXiv:2508.04537', 'title': 'Behaviorally Adaptive Multi-Robot Hazard Localization in Failure-Prone, Communication-Denied Environments', 'authors': 'Alkesh K. Srivastava, Aamodh Suresh, Carlos Nieto-Granda', 'link': 'https://arxiv.org/abs/2508.04537', 'abstract': 'We address the challenge of multi-robot autonomous hazard mapping in high-risk, failure-prone, communication-denied environments such as post-disaster zones, underground mines, caves, and planetary surfaces. In these missions, robots must explore and map hazards while minimizing the risk of failure due to environmental threats or hardware limitations. We introduce a behavior-adaptive, information-theoretic planning framework for multi-robot teams grounded in the concept of Behavioral Entropy (BE), that generalizes Shannon entropy (SE) to capture diverse human-like uncertainty evaluations. Building on this formulation, we propose the Behavior-Adaptive Path Planning (BAPP) framework, which modulates information gathering strategies via a tunable risk-sensitivity parameter, and present two planning algorithms: BAPP-TID for intelligent triggering of high-fidelity robots, and BAPP-SIG for safe deployment under high risk. We provide theoretical insights on the informativeness of the proposed BAPP framework and validate its effectiveness through both single-robot and multi-robot simulations. Our results show that the BAPP stack consistently outperforms Shannon-based and random strategies: BAPP-TID accelerates entropy reduction, while BAPP-SIG improves robot survivability with minimal loss in information gain. In multi-agent deployments, BAPP scales effectively through spatial partitioning, mobile base relocation, and role-aware heterogeneity. These findings underscore the value of behavior-adaptive planning for robust, risk-sensitive exploration in complex, failure-prone environments.', 'abstract_zh': '多机器人自主危险 mapping 在高风险、故障多发、通信受限环境中的挑战及解决方案：基于行为熵的行为自适应信息论规划框架', 'title_zh': '行为自适应多机器人危险定位在故障易发、通信受限环境中'}
{'arxiv_id': 'arXiv:2508.04436', 'title': 'Reliable and Real-Time Highway Trajectory Planning via Hybrid Learning-Optimization Frameworks', 'authors': 'Yujia Lu, Chong Wei, Lu Ma', 'link': 'https://arxiv.org/abs/2508.04436', 'abstract': 'Autonomous highway driving presents a high collision risk due to fast-changing environments and limited reaction time, necessitating reliable and efficient trajectory planning. This paper proposes a hybrid trajectory planning framework that integrates the adaptability of learning-based methods with the formal safety guarantees of optimization-based approaches. The framework features a two-layer architecture: an upper layer employing a graph neural network (GNN) trained on real-world highway data to predict human-like longitudinal velocity profiles, and a lower layer utilizing path optimization formulated as a mixed-integer quadratic programming (MIQP) problem. The primary contribution is the lower-layer path optimization model, which introduces a linear approximation of discretized vehicle geometry to substantially reduce computational complexity, while enforcing strict spatiotemporal non-overlapping constraints to formally guarantee collision avoidance throughout the planning horizon. Experimental results demonstrate that the planner generates highly smooth, collision-free trajectories in complex real-world emergency scenarios, achieving success rates exceeding 97% with average planning times of 54 ms, thereby confirming real-time capability.', 'abstract_zh': '基于学习方法的适应性与优化方法的形式安全保证相结合的自驾车高速道路规划框架', 'title_zh': '基于混合学习-优化框架的可靠实时高速公路轨迹规划'}
{'arxiv_id': 'arXiv:2508.04384', 'title': 'Incorporating Stochastic Models of Controller Behavior into Kinodynamic Efficiently Adaptive State Lattices for Mobile Robot Motion Planning in Off-Road Environments', 'authors': 'Eric R. Damm, Eli S. Lancaster, Felix A. Sanchez, Kiana Bronder, Jason M. Gregory, Thomas M. Howard', 'link': 'https://arxiv.org/abs/2508.04384', 'abstract': 'Mobile robot motion planners rely on theoretical models to predict how the robot will move through the world. However, when deployed on a physical robot, these models are subject to errors due to real-world physics and uncertainty in how the lower-level controller follows the planned trajectory. In this work, we address this problem by presenting three methods of incorporating stochastic controller behavior into the recombinant search space of the Kinodynamic Efficiently Adaptive State Lattice (KEASL) planner. To demonstrate this work, we analyze the results of experiments performed on a Clearpath Robotics Warthog Unmanned Ground Vehicle (UGV) in an off-road, unstructured environment using two different perception algorithms, and performed an ablation study using a full spectrum of simulated environment map complexities. Analysis of the data found that incorporating stochastic controller sampling into KEASL leads to more conservative trajectories that decrease predicted collision likelihood when compared to KEASL without sampling. When compared to baseline planning with expanded obstacle footprints, the predicted likelihood of collisions becomes more comparable, but reduces the planning success rate for baseline search.', 'abstract_zh': '移动机器人运动规划器依赖于理论模型来预测机器人如何在环境中移动。然而，在实际部署到物理机器人后，这些模型会因现实世界物理条件和底层控制器跟随计划轨迹的不确定性而出现误差。在这项工作中，我们通过将随机控制器行为纳入基于Kinodynamic Efficiently Adaptive State Lattice（KEASL）规划器的重组搜索空间中，来解决这一问题，并提出了三种方法。为了验证这一工作，我们在Clearpath Robotics Warthog无人地面车辆（UGV）上进行户外、非结构化环境下的实验，使用了两种不同的感知算法，并进行了全谱模拟环境地图复杂度的消融研究。数据分析显示，将随机控制器采样纳入KEASL中可以产生更为保守的轨迹，从而降低预测碰撞的可能性。与基线规划扩展障碍物足迹相比，预测的碰撞可能性更加接近，但降低了基线搜索的成功率。', 'title_zh': '将控制器行为的随机模型整合进离线高效自适应状态格网中以优化离路环境下的移动机器人运动规划'}
{'arxiv_id': 'arXiv:2508.04372', 'title': 'Tactile Comfort: Lowering Heart Rate Through Interactions', 'authors': 'Morten Roed Frederiksen, Kasper Støy, Maja Matarić', 'link': 'https://arxiv.org/abs/2508.04372', 'abstract': "Children diagnosed with anxiety disorders are taught a range of strategies to navigate situations of heightened anxiety. Techniques such as deep breathing and repetition of mantras are commonly employed, as they are known to be calming and reduce elevated heart rates. Although these strategies are often effective, their successful application relies on prior training of the children for successful use when faced with challenging situations. This paper investigates a pocket-sized companion robot designed to offer a relaxation technique requiring no prior training, with a focus on immediate impact on the user's heart rate. The robot utilizes a tactile game to divert the user's attention, thereby promoting relaxation. We conducted two studies with children who were not diagnosed with anxiety: a 14-day pilot study with two children (age 8) and a main study with 18 children (ages 7-8). Both studies employed a within-subjects design and focused on measuring heart rate during tactile interaction with the robot and during non-use. Interacting with the robot was found to significantly lower the study participants' heart rate (p$<$0.01) compared to the non-use condition, indicating a consistent calming effect across all participants. These results suggest that tactile companion robots have the potential to enhance the therapeutic value of relaxation techniques.", 'abstract_zh': '患有焦虑障碍的儿童被教授多种策略以应对高度焦虑的情况。常见的技术包括深呼吸和重复咒语，因为它们具有安抚效果并能降低心率。尽管这些策略通常很有效，但在面对具有挑战性的情况时成功应用这些策略仍需要儿童事先接受训练。本文探讨了一款便携式伴侣型机器人，旨在提供一种无需事先训练即可使用的放松技巧，并重点考察其对用户心率的即时影响。该机器人利用触觉游戏转移用户的注意力，从而促进放松。我们对未被诊断为焦虑的儿童进行了两项研究：一项为期14天的初步研究，参与者为两名8岁儿童，一项主要研究，参与者为18名7至8岁儿童。两项研究均采用了被试内设计，并重点关注触觉与机器人互动期间和不使用期间心率的测量。结果发现，与不使用条件相比，与机器人互动显著降低了研究参与者的即时心率（p<0.01），表明所有参与者的镇静效果一致。这表明触觉伴侣型机器人有可能增强放松技巧的治疗价值。', 'title_zh': '触觉舒适：通过互动降低心率'}
{'arxiv_id': 'arXiv:2508.04338', 'title': 'Improving Tactile Gesture Recognition with Optical Flow', 'authors': 'Shaohong Zhong, Alessandro Albini, Giammarco Caroleo, Giorgio Cannata, Perla Maiolino', 'link': 'https://arxiv.org/abs/2508.04338', 'abstract': 'Tactile gesture recognition systems play a crucial role in Human-Robot Interaction (HRI) by enabling intuitive communication between humans and robots. The literature mainly addresses this problem by applying machine learning techniques to classify sequences of tactile images encoding the pressure distribution generated when executing the gestures. However, some gestures can be hard to differentiate based on the information provided by tactile images alone. In this paper, we present a simple yet effective way to improve the accuracy of a gesture recognition classifier. Our approach focuses solely on processing the tactile images used as input by the classifier. In particular, we propose to explicitly highlight the dynamics of the contact in the tactile image by computing the dense optical flow. This additional information makes it easier to distinguish between gestures that produce similar tactile images but exhibit different contact dynamics. We validate the proposed approach in a tactile gesture recognition task, showing that a classifier trained on tactile images augmented with optical flow information achieved a 9% improvement in gesture classification accuracy compared to one trained on standard tactile images.', 'abstract_zh': '触觉手势识别系统在人机交互（HRI）中发挥着关键作用，通过使人类和机器人之间的通信直观化。文献主要通过应用机器学习技术来对编码执行手势时产生的压力分布的触觉图像序列进行分类来解决这一问题。然而，仅凭触觉图像的信息，某些手势可能会难以区分。在本文中，我们提出了一种简单而有效的方法，以提高手势识别分类器的准确率。我们的方法仅专注于处理用于输入分类器的触觉图像。具体来说，我们建议通过计算密集型光学流来显式地突出触觉图像中的接触动态。这种额外的信息使得更容易区分产生相似触觉图像但接触动态不同的手势。我们在触觉手势识别任务中验证了所提出的方法，结果显示，与仅使用标准触觉图像训练的分类器相比，使用包含光学流信息的触觉图像训练的分类器在手势分类准确率上提高了9%。', 'title_zh': '基于光学流提高触觉手势识别性能'}
{'arxiv_id': 'arXiv:2508.04146', 'title': 'Industrial Robot Motion Planning with GPUs: Integration of cuRobo for Extended DOF Systems', 'authors': 'Luai Abuelsamen, Harsh Rana, Ho-Wei Lu, Wenhan Tang, Swati Priyadarshini, Gabriel Gomes', 'link': 'https://arxiv.org/abs/2508.04146', 'abstract': "Efficient motion planning remains a key challenge in industrial robotics, especially for multi-axis systems operating in complex environments. This paper addresses that challenge by integrating GPU-accelerated motion planning through NVIDIA's cuRobo library into Vention's modular automation platform. By leveraging accurate CAD-based digital twins and real-time parallel optimization, our system enables rapid trajectory generation and dynamic collision avoidance for pick-and-place tasks. We demonstrate this capability on robots equipped with additional degrees of freedom, including a 7th-axis gantry, and benchmark performance across various scenarios. The results show significant improvements in planning speed and robustness, highlighting the potential of GPU-based planning pipelines for scalable, adaptable deployment in modern industrial workflows.", 'abstract_zh': '高效的运动规划仍然是工业机器人领域的关键挑战，特别是在复杂环境中操作的多轴系统中。本文通过将NVIDIA cuRobo库的GPU加速运动规划技术集成到Vention的模块化自动化平台上，解决了这一挑战。通过利用基于准确的CAD数字孪生和实时并行优化，我们的系统能够快速生成轨迹并实现动态碰撞避免，以支持拾取和放置任务。我们在具有额外自由度的机器人上展示了这种能力，包括7轴龙门架，并在各种场景下进行了性能基准测试。结果表明，在规划速度和鲁棒性方面有显著改进，突显了基于GPU的规划流水线在现代工业工作流程中可扩展和灵活部署的潜力。', 'title_zh': '基于GPU的工业机器人运动规划：cuRobo在扩展自由度系统中的集成'}
{'arxiv_id': 'arXiv:2508.04066', 'title': 'DRIVE: Dynamic Rule Inference and Verified Evaluation for Constraint-Aware Autonomous Driving', 'authors': 'Longling Geng, Huangxing Li, Viktor Lado Naess, Mert Pilanci', 'link': 'https://arxiv.org/abs/2508.04066', 'abstract': 'Understanding and adhering to soft constraints is essential for safe and socially compliant autonomous driving. However, such constraints are often implicit, context-dependent, and difficult to specify explicitly. In this work, we present DRIVE, a novel framework for Dynamic Rule Inference and Verified Evaluation that models and evaluates human-like driving constraints from expert demonstrations. DRIVE leverages exponential-family likelihood modeling to estimate the feasibility of state transitions, constructing a probabilistic representation of soft behavioral rules that vary across driving contexts. These learned rule distributions are then embedded into a convex optimization-based planning module, enabling the generation of trajectories that are not only dynamically feasible but also compliant with inferred human preferences. Unlike prior approaches that rely on fixed constraint forms or purely reward-based modeling, DRIVE offers a unified framework that tightly couples rule inference with trajectory-level decision-making. It supports both data-driven constraint generalization and principled feasibility verification. We validate DRIVE on large-scale naturalistic driving datasets, including inD, highD, and RoundD, and benchmark it against representative inverse constraint learning and planning baselines. Experimental results show that DRIVE achieves 0.0% soft constraint violation rates, smoother trajectories, and stronger generalization across diverse driving scenarios. Verified evaluations further demonstrate the efficiency, explanability, and robustness of the framework for real-world deployment.', 'abstract_zh': '动态规则推理与验证评估框架DRIVE对于安全和社会合规的自主驾驶至关重要。然而，这类约束往往是隐性的、情境依赖的且难以明确指定。在这种工作下，我们提出DRIVE，一种新型的动态规则推理与验证评估框架，该框架从专家演示中建模和评估类似人类驾驶的约束。DRIVE利用指数族似然建模来估计状态转换的可行性，构建一种软行为规则的概率表示，这些规则在不同的驾驶情境下有所不同。然后将这些学习到的规则分布嵌入到基于凸优化的规划模块中，从而生成既动态可行又符合推理出的人类偏好的路径。与依赖于固定约束形式或纯粹基于奖励建模的先前方法不同，DRIVE提供了一个紧密耦合规则推理与路径级别决策的统一框架，支持基于数据的约束泛化和原理驱动的可行性验证。我们在大规模自然驾驶数据集（包括inD、highD和RoundD）上验证了DRIVE，并将其与代表性的逆向约束学习和规划基准进行对比。实验结果表明，DRIVE实现了0%的软约束违反率，路径更加平滑，并且在不同驾驶场景下具有更强的泛化能力。验证评估进一步证明了该框架在实际部署中的高效性、可解释性和鲁棒性。', 'title_zh': 'DRIVE: 动态规则推理与约束感知自主驾驶的验证评估'}
{'arxiv_id': 'arXiv:2508.04056', 'title': 'SCOUT: An in-vivo Methane Sensing System for Real-time Monitoring of Enteric Emissions in Cattle with ex-vivo Validation', 'authors': 'Yuelin Deng, Hinayah Rojas de Oliveira, Richard M. Voyles, Upinder Kaur', 'link': 'https://arxiv.org/abs/2508.04056', 'abstract': 'Accurate measurement of enteric methane emissions remains a critical bottleneck for advancing livestock sustainability through genetic selection and precision management. Existing ambient sampling approaches suffer from low data retention rates, environmental interference, and limited temporal resolution. We developed SCOUT (Smart Cannula-mounted Optical Unit for Trace-methane), the first robust in-vivo sensing system enabling continuous, high-resolution monitoring of ruminal methane concentrations through an innovative closed-loop gas recirculation design. We conducted comprehensive validation with two cannulated Simmental heifers under contrasting dietary treatments, with cross-platform comparison against established ambient sniffer systems. SCOUT achieved exceptional performance with 82% data retention compared to 17% for conventional sniffer systems, while capturing methane concentrations 100-1000x higher than ambient approaches. Cross-platform validation demonstrated strong scale-dependent correlations, with optimal correlation strength (r = -0.564 $\\pm$ 0.007) at biologically relevant 40-minute windows and 100% statistical significance. High-frequency monitoring revealed novel behavior-emission coupling, including rapid concentration changes (14.5 $\\pm$ 11.3k ppm) triggered by postural transitions within 15 minutes, insights previously inaccessible through existing technologies. The SCOUT system represents a transformative advancement, enabling accurate, continuous emission phenotyping essential for genomic selection programs and sustainable precision livestock management. This validation framework establishes new benchmarks for agricultural sensor performance while generating unprecedented biological insights into ruminal methane dynamics, contributing essential tools for sustainable livestock production in climate-conscious agricultural systems.', 'abstract_zh': '精确测量肠道甲烷排放对于通过遗传选择和精准管理推进 livestock 可持续性仍然是一项关键瓶颈。现有的环境采样方法存在数据保留率低、环境干扰严重和时间分辨率有限的问题。我们开发了 SCOUT（智能套管光谱仪用于痕量甲烷检测），这是首个坚固的体内传感系统，通过创新的闭环气体循环设计，实现对瘤胃甲烷浓度的连续、高分辨率监测。我们在两种不同饲料处理下的 Simmental 妊牛身上进行了全面验证，并与现有的环境嗅探系统进行了跨平台对比。SCOUT 的数据保留率为 82%，而传统嗅探系统的数据保留率为 17%，同时捕获的甲烷浓度比环境方法高 100-1000 倍。跨平台验证结果显示在生物学相关 40 分钟窗口内具有较强的规模依赖性相关性（r = -0.564 ± 0.007），且具有 100% 统计显著性。高频率监测揭示了新的行为-排放耦合现象，包括 15 分钟内由姿势转换触发的快速浓度变化（变化范围 14.5 ± 11.3k ppm），这是现有技术无法获得的见解。SCOUT 系统代表了转型性进步，能够实现用于基因组选择计划和可持续精准畜牧业管理所需的准确、连续排放表型分析。该验证框架建立了农业传感器性能的新基准，同时生成了前所未有的有关瘤胃甲烷动力学的生物学见解，为气候意识农业系统中的可持续牲畜生产提供了必不可少的工具。', 'title_zh': 'SCOUT：一种用于实时监测牛 enteric 温室气体排放的体内甲烷传感系统，结合体外验证'}
{'arxiv_id': 'arXiv:2508.04009', 'title': 'Optimization of sliding control parameters for a 3-dof robot arm using genetic algorithm (GA)', 'authors': 'Vu Ngoc Son, Pham Van Cuong, Dao Thi My Linh, Le Tieu Nien', 'link': 'https://arxiv.org/abs/2508.04009', 'abstract': 'This paper presents a method for optimizing the sliding mode control (SMC) parameter for a robot manipulator applying a genetic algorithm (GA). The objective of the SMC is to achieve precise and consistent tracking of the trajectory of the robot manipulator under uncertain and disturbed conditions. However, the system effectiveness and robustness depend on the choice of the SMC parameters, which is a difficult and crucial task. To solve this problem, a genetic algorithm is used to locate the optimal values of these parameters that gratify the capability criteria. The proposed method is efficient compared with the conventional SMC and Fuzzy-SMC. The simulation results show that the genetic algorithm with SMC can achieve better tracking capability and reduce the chattering effect.', 'abstract_zh': '基于遗传算法优化机器人 manipulator 滑模控制参数的方法', 'title_zh': '使用遗传算法（GA）优化三自由度机器人手臂滑动控制参数'}
{'arxiv_id': 'arXiv:2508.03944', 'title': 'Constraint-Preserving Data Generation for Visuomotor Policy Learning', 'authors': 'Kevin Lin, Varun Ragunath, Andrew McAlinden, Aaditya Prasad, Jimmy Wu, Yuke Zhu, Jeannette Bohg', 'link': 'https://arxiv.org/abs/2508.03944', 'abstract': 'Large-scale demonstration data has powered key breakthroughs in robot manipulation, but collecting that data remains costly and time-consuming. We present Constraint-Preserving Data Generation (CP-Gen), a method that uses a single expert trajectory to generate robot demonstrations containing novel object geometries and poses. These generated demonstrations are used to train closed-loop visuomotor policies that transfer zero-shot to the real world and generalize across variations in object geometries and poses. Similar to prior work using pose variations for data generation, CP-Gen first decomposes expert demonstrations into free-space motions and robot skills. But unlike those works, we achieve geometry-aware data generation by formulating robot skills as keypoint-trajectory constraints: keypoints on the robot or grasped object must track a reference trajectory defined relative to a task-relevant object. To generate a new demonstration, CP-Gen samples pose and geometry transforms for each task-relevant object, then applies these transforms to the object and its associated keypoints or keypoint trajectories. We optimize robot joint configurations so that the keypoints on the robot or grasped object track the transformed keypoint trajectory, and then motion plan a collision-free path to the first optimized joint configuration. Experiments on 16 simulation tasks and four real-world tasks, featuring multi-stage, non-prehensile and tight-tolerance manipulation, show that policies trained using CP-Gen achieve an average success rate of 77%, outperforming the best baseline that achieves an average of 50%.', 'abstract_zh': '基于约束保持数据生成的大规模机器人操作演示数据驱动方法', 'title_zh': '基于约束保持的数据生成的视听运动策略学习'}
{'arxiv_id': 'arXiv:2508.03890', 'title': 'Uncertainty-aware Accurate Elevation Modeling for Off-road Navigation via Neural Processes', 'authors': 'Sanghun Jung, Daehoon Gwak, Byron Boots, James Hays', 'link': 'https://arxiv.org/abs/2508.03890', 'abstract': 'Terrain elevation modeling for off-road navigation aims to accurately estimate changes in terrain geometry in real-time and quantify the corresponding uncertainties. Having precise estimations and uncertainties plays a crucial role in planning and control algorithms to explore safe and reliable maneuver strategies. However, existing approaches, such as Gaussian Processes (GPs) and neural network-based methods, often fail to meet these needs. They are either unable to perform in real-time due to high computational demands, underestimating sharp geometry changes, or harming elevation accuracy when learned with uncertainties. Recently, Neural Processes (NPs) have emerged as a promising approach that integrates the Bayesian uncertainty estimation of GPs with the efficiency and flexibility of neural networks. Inspired by NPs, we propose an effective NP-based method that precisely estimates sharp elevation changes and quantifies the corresponding predictive uncertainty without losing elevation accuracy. Our method leverages semantic features from LiDAR and camera sensors to improve interpolation and extrapolation accuracy in unobserved regions. Also, we introduce a local ball-query attention mechanism to effectively reduce the computational complexity of global attention by 17\\% while preserving crucial local and spatial information. We evaluate our method on off-road datasets having interesting geometric features, collected from trails, deserts, and hills. Our results demonstrate superior performance over baselines and showcase the potential of neural processes for effective and expressive terrain modeling in complex off-road environments.', 'abstract_zh': '基于神经过程的地形高程建模以实现越野导航aims to精确实时估计地形几何学变化并量化相应的不确定性。具备精确的估计值和不确定性对于规划和控制算法以规划安全可靠的机动策略至关重要。然而，现有方法如高斯过程(GPs)和基于神经网络的方法往往难以满足这些需求。它们要么由于高计算需求难以实时运行，要么低估了几何学的急剧变化，或者在学习不确定性时损害了高程的准确性。最近，神经过程(NPs)作为一种有前途的方法出现，它结合了GPs的贝叶斯不确定性估计和神经网络的高效性和灵活性。受NPs启发，我们提出了一种有效的NP基方法，能够精确估计尖锐的高程变化并量化相应的预测不确定性，同时不损失高程准确性。该方法利用LiDAR和摄像头传感器的语义特征，以提高未观测区域的插值和外推准确性。我们还引入了一种局部球查询注意力机制，有效地将全局注意力的计算复杂度降低了17%，同时保留了关键的局部和空间信息。我们在包含有趣几何特征的越野数据集上评估了该方法，该数据集来自小径、沙漠和山丘等区域。我们的结果显示了该方法在复杂越野环境中的优越性能，并展示了神经过程在有效的地形建模方面的潜力。', 'title_zh': '面向越野导航的具有不确定性意识的准确高程建模via神经过程'}
{'arxiv_id': 'arXiv:2508.04611', 'title': 'OmniDepth: Bridging Monocular and Stereo Reasoning with Latent Alignment', 'authors': 'Tongfan Guan, Jiaxin Guo, Chen Wang, Yun-Hui Liu', 'link': 'https://arxiv.org/abs/2508.04611', 'abstract': 'Monocular and stereo depth estimation offer complementary strengths: monocular methods capture rich contextual priors but lack geometric precision, while stereo approaches leverage epipolar geometry yet struggle with ambiguities such as reflective or textureless surfaces. Despite post-hoc synergies, these paradigms remain largely disjoint in practice. We introduce OmniDepth, a unified framework that bridges both through iterative bidirectional alignment of their latent representations. At its core, a novel cross-attentive alignment mechanism dynamically synchronizes monocular contextual cues with stereo hypothesis representations during stereo reasoning. This mutual alignment resolves stereo ambiguities (e.g., specular surfaces) by injecting monocular structure priors while refining monocular depth with stereo geometry within a single network. Extensive experiments demonstrate state-of-the-art results: \\textbf{OmniDepth reduces zero-shot generalization error by $\\!>\\!40\\%$ on Middlebury and ETH3D}, while addressing longstanding failures on transparent and reflective surfaces. By harmonizing multi-view geometry with monocular context, OmniDepth enables robust 3D perception that transcends modality-specific limitations. Codes available at this https URL.', 'abstract_zh': '单目和立体深度估计各有优势：单目方法捕获丰富的上下文先验但缺乏几何精度，而立体方法利用单应几何但难以处理反射或纹理缺失表面等歧义。尽管存在后处理 synergy，这两种范式在实践中仍然 largely 独立。我们提出 OmniDepth，这是一种统一框架，通过迭代双向对齐其潜在表示来连接这两种方法。其核心是一种新颖的交叉注意对齐机制，在立体推理过程中动态同步单目上下文线索与立体假设表示。这种相互对齐通过注入单目结构先验解决立体歧义（如镜面表面），并在单一网络中细化单目深度几何。 extensive 实验结果显示，OmniDepth 在 Middlebury 和 ETH3D 上的 zero-shot 通用性误差降低超过 40%，同时解决了透明和反射表面的长期问题。通过协调多视图几何与单目上下文，OmniDepth 实现了超越单一模态限制的稳健三维感知。代码可在此链接获取。', 'title_zh': 'OmniDepth：单目与 stereo  reasoning 通过潜变量对齐的融合'}
{'arxiv_id': 'arXiv:2508.04378', 'title': 'Position-Based Flocking for Robust Alignment', 'authors': 'Hossein B. Jond', 'link': 'https://arxiv.org/abs/2508.04378', 'abstract': "This paper presents a position-based flocking model for interacting agents, balancing cohesion-separation and alignment to achieve stable collective motion. The model modifies a velocity-based approach by approximating velocity differences using initial and current positions, introducing a threshold weight to ensure sustained alignment. Simulations with 50 agents in 2D demonstrate that the position-based model produces stronger alignment and more rigid and compact formations compared to the velocity-based model. The alignment metric and separation distances highlight the efficacy of the proposed model in achieving robust flocking behavior. The model's use of positions ensures robust alignment, with applications in robotics and collective dynamics.", 'abstract_zh': '基于位置的交互代理群集移动模型：平衡凝聚力与分离以及对齐以实现稳定的集体运动', 'title_zh': '基于位置的群集同步方法'}
{'arxiv_id': 'arXiv:2508.04335', 'title': 'RiemanLine: Riemannian Manifold Representation of 3D Lines for Factor Graph Optimization', 'authors': 'Yanyan Li, Ze Yang, Keisuke Tateno, Federico Tombari Liang Zhao, Gim Hee Lee', 'link': 'https://arxiv.org/abs/2508.04335', 'abstract': 'Minimal parametrization of 3D lines plays a critical role in camera localization and structural mapping. Existing representations in robotics and computer vision predominantly handle independent lines, overlooking structural regularities such as sets of parallel lines that are pervasive in man-made environments. This paper introduces \\textbf{RiemanLine}, a unified minimal representation for 3D lines formulated on Riemannian manifolds that jointly accommodates both individual lines and parallel-line groups. Our key idea is to decouple each line landmark into global and local components: a shared vanishing direction optimized on the unit sphere $\\mathcal{S}^2$, and scaled normal vectors constrained on orthogonal subspaces, enabling compact encoding of structural regularities. For $n$ parallel lines, the proposed representation reduces the parameter space from $4n$ (orthonormal form) to $2n+2$, naturally embedding parallelism without explicit constraints. We further integrate this parameterization into a factor graph framework, allowing global direction alignment and local reprojection optimization within a unified manifold-based bundle adjustment. Extensive experiments on ICL-NUIM, TartanAir, and synthetic benchmarks demonstrate that our method achieves significantly more accurate pose estimation and line reconstruction, while reducing parameter dimensionality and improving convergence stability.', 'abstract_zh': 'RiemanLine: 统一的黎曼流形上最小参数化表示及其在相机定位和结构映射中的应用', 'title_zh': 'R射曼线线线表示_trajectory：黎曼流形表示3D线条_对于因子图优化优化优化'}
{'arxiv_id': 'arXiv:2508.03727', 'title': 'TIR-Diffusion: Diffusion-based Thermal Infrared Image Denoising via Latent and Wavelet Domain Optimization', 'authors': 'Tai Hyoung Rhee, Dong-guw Lee, Ayoung Kim', 'link': 'https://arxiv.org/abs/2508.03727', 'abstract': 'Thermal infrared imaging exhibits considerable potentials for robotic perception tasks, especially in environments with poor visibility or challenging lighting conditions. However, TIR images typically suffer from heavy non-uniform fixed-pattern noise, complicating tasks such as object detection, localization, and mapping. To address this, we propose a diffusion-based TIR image denoising framework leveraging latent-space representations and wavelet-domain optimization. Utilizing a pretrained stable diffusion model, our method fine-tunes the model via a novel loss function combining latent-space and discrete wavelet transform (DWT) / dual-tree complex wavelet transform (DTCWT) losses. Additionally, we implement a cascaded refinement stage to enhance fine details, ensuring high-fidelity denoising results. Experiments on benchmark datasets demonstrate superior performance of our approach compared to state-of-the-art denoising methods. Furthermore, our method exhibits robust zero-shot generalization to diverse and challenging real-world TIR datasets, underscoring its effectiveness for practical robotic deployment.', 'abstract_zh': '热红外成像在机器人感知任务中展现出巨大的潜力，尤其是在能见度差或光照条件具有挑战性的环境中。然而，热红外图像通常受到严重的非均匀固定模式噪声影响，这使得物体检测、定位和建图等任务复杂化。为应对这一挑战，我们提出了一种基于扩散的热红外图像去噪框架，该框架利用潜在空间表示和小波域优化。利用预训练的稳定扩散模型，我们的方法通过结合潜在空间和离散小波变换（DWT）/双树复小波变换（DTCWT）损失的新型损失函数来细调模型。此外，我们实施了一级递增细化阶段以增强细小细节，确保高保真去噪结果。在基准数据集上的实验表明，与现有先进的去噪方法相比，我们的方法性能更优。进一步地，我们的方法对多样且具有挑战性的实地热红外数据集展示了鲁棒的零样本泛化能力，证明了其在实际机器人部署中的有效性。', 'title_zh': 'TIR-去噪：基于扩散的热红外图像去噪方法，通过潜在域和小波域优化'}
