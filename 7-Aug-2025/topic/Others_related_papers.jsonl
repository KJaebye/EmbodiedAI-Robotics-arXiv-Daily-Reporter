{'arxiv_id': 'arXiv:2508.04066', 'title': 'DRIVE: Dynamic Rule Inference and Verified Evaluation for Constraint-Aware Autonomous Driving', 'authors': 'Longling Geng, Huangxing Li, Viktor Lado Naess, Mert Pilanci', 'link': 'https://arxiv.org/abs/2508.04066', 'abstract': 'Understanding and adhering to soft constraints is essential for safe and socially compliant autonomous driving. However, such constraints are often implicit, context-dependent, and difficult to specify explicitly. In this work, we present DRIVE, a novel framework for Dynamic Rule Inference and Verified Evaluation that models and evaluates human-like driving constraints from expert demonstrations. DRIVE leverages exponential-family likelihood modeling to estimate the feasibility of state transitions, constructing a probabilistic representation of soft behavioral rules that vary across driving contexts. These learned rule distributions are then embedded into a convex optimization-based planning module, enabling the generation of trajectories that are not only dynamically feasible but also compliant with inferred human preferences. Unlike prior approaches that rely on fixed constraint forms or purely reward-based modeling, DRIVE offers a unified framework that tightly couples rule inference with trajectory-level decision-making. It supports both data-driven constraint generalization and principled feasibility verification. We validate DRIVE on large-scale naturalistic driving datasets, including inD, highD, and RoundD, and benchmark it against representative inverse constraint learning and planning baselines. Experimental results show that DRIVE achieves 0.0% soft constraint violation rates, smoother trajectories, and stronger generalization across diverse driving scenarios. Verified evaluations further demonstrate the efficiency, explanability, and robustness of the framework for real-world deployment.', 'abstract_zh': '理解并遵守软约束对于自主驾驶的安全性和社会合规性至关重要。然而，这些约束往往是隐式的、情境相关的且难以明确指定。在此工作中，我们提出DRIVE，一种动态规则推理与验证评估框架，用于从专家演示中建模和评估类似人类驾驶的约束。DRIVE 利用指数族似然建模来估计状态转换的可行性，构建一种在不同驾驶情境下可变的软行为规则的概率表示。然后将这些学习到的规则分布嵌入到基于凸优化的规划模块中，从而生成不仅动态可行而且符合推断出的人类偏好轨迹。与依赖于固定约束形式或纯粹基于奖励建模的先前方法不同，DRIVE 提供了一个统一框架，将规则推理紧密耦合到轨迹级决策制定中。该框架支持基于数据的约束泛化和原则上的可行性验证。我们在大规模自然驾驶数据集中验证了DRIVE，包括inD、highD和RoundD，并将其与代表性逆约束学习和规划 baselines 进行对比。实验结果表明，DRIVE 实现了0.0%的软约束违反率、更平滑的轨迹以及在多种驾驶场景中更强的泛化能力。验证评估进一步证明了该框架在实际部署中的高效性、可解释性和鲁棒性。', 'title_zh': 'DRIVE: 动态规则推断与约束aware自主驾驶的验证评价'}
{'arxiv_id': 'arXiv:2508.04056', 'title': 'SCOUT: An in-vivo Methane Sensing System for Real-time Monitoring of Enteric Emissions in Cattle with ex-vivo Validation', 'authors': 'Yuelin Deng, Hinayah Rojas de Oliveira, Richard M. Voyles, Upinder Kaur', 'link': 'https://arxiv.org/abs/2508.04056', 'abstract': 'Accurate measurement of enteric methane emissions remains a critical bottleneck for advancing livestock sustainability through genetic selection and precision management. Existing ambient sampling approaches suffer from low data retention rates, environmental interference, and limited temporal resolution. We developed SCOUT (Smart Cannula-mounted Optical Unit for Trace-methane), the first robust in-vivo sensing system enabling continuous, high-resolution monitoring of ruminal methane concentrations through an innovative closed-loop gas recirculation design. We conducted comprehensive validation with two cannulated Simmental heifers under contrasting dietary treatments, with cross-platform comparison against established ambient sniffer systems. SCOUT achieved exceptional performance with 82% data retention compared to 17% for conventional sniffer systems, while capturing methane concentrations 100-1000x higher than ambient approaches. Cross-platform validation demonstrated strong scale-dependent correlations, with optimal correlation strength (r = -0.564 $\\pm$ 0.007) at biologically relevant 40-minute windows and 100% statistical significance. High-frequency monitoring revealed novel behavior-emission coupling, including rapid concentration changes (14.5 $\\pm$ 11.3k ppm) triggered by postural transitions within 15 minutes, insights previously inaccessible through existing technologies. The SCOUT system represents a transformative advancement, enabling accurate, continuous emission phenotyping essential for genomic selection programs and sustainable precision livestock management. This validation framework establishes new benchmarks for agricultural sensor performance while generating unprecedented biological insights into ruminal methane dynamics, contributing essential tools for sustainable livestock production in climate-conscious agricultural systems.', 'abstract_zh': '精确测量肠道甲烷排放对于通过遗传选择和精准管理推进 livestock 可持续性仍然是一项关键瓶颈。现有的环境采样方法存在数据保留率低、环境干扰严重和时间分辨率有限的问题。我们开发了 SCOUT（智能套管光谱仪用于痕量甲烷检测），这是首个坚固的体内传感系统，通过创新的闭环气体循环设计，实现对瘤胃甲烷浓度的连续、高分辨率监测。我们在两种不同饲料处理下的 Simmental 妊牛身上进行了全面验证，并与现有的环境嗅探系统进行了跨平台对比。SCOUT 的数据保留率为 82%，而传统嗅探系统的数据保留率为 17%，同时捕获的甲烷浓度比环境方法高 100-1000 倍。跨平台验证结果显示在生物学相关 40 分钟窗口内具有较强的规模依赖性相关性（r = -0.564 ± 0.007），且具有 100% 统计显著性。高频率监测揭示了新的行为-排放耦合现象，包括 15 分钟内由姿势转换触发的快速浓度变化（变化范围 14.5 ± 11.3k ppm），这是现有技术无法获得的见解。SCOUT 系统代表了转型性进步，能够实现用于基因组选择计划和可持续精准畜牧业管理所需的准确、连续排放表型分析。该验证框架建立了农业传感器性能的新基准，同时生成了前所未有的有关瘤胃甲烷动力学的生物学见解，为气候意识农业系统中的可持续牲畜生产提供了必不可少的工具。', 'title_zh': 'SCOUT：一种用于实时监测牛 enteric 温室气体排放的体内甲烷传感系统，结合体外验证'}
{'arxiv_id': 'arXiv:2508.04335', 'title': 'RiemanLine: Riemannian Manifold Representation of 3D Lines for Factor Graph Optimization', 'authors': 'Yanyan Li, Ze Yang, Keisuke Tateno, Federico Tombari Liang Zhao, Gim Hee Lee', 'link': 'https://arxiv.org/abs/2508.04335', 'abstract': 'Minimal parametrization of 3D lines plays a critical role in camera localization and structural mapping. Existing representations in robotics and computer vision predominantly handle independent lines, overlooking structural regularities such as sets of parallel lines that are pervasive in man-made environments. This paper introduces \\textbf{RiemanLine}, a unified minimal representation for 3D lines formulated on Riemannian manifolds that jointly accommodates both individual lines and parallel-line groups. Our key idea is to decouple each line landmark into global and local components: a shared vanishing direction optimized on the unit sphere $\\mathcal{S}^2$, and scaled normal vectors constrained on orthogonal subspaces, enabling compact encoding of structural regularities. For $n$ parallel lines, the proposed representation reduces the parameter space from $4n$ (orthonormal form) to $2n+2$, naturally embedding parallelism without explicit constraints. We further integrate this parameterization into a factor graph framework, allowing global direction alignment and local reprojection optimization within a unified manifold-based bundle adjustment. Extensive experiments on ICL-NUIM, TartanAir, and synthetic benchmarks demonstrate that our method achieves significantly more accurate pose estimation and line reconstruction, while reducing parameter dimensionality and improving convergence stability.', 'abstract_zh': 'RiemanLine: 统一的黎曼流形上最小参数化表示及其在相机定位和结构映射中的应用', 'title_zh': 'R射曼线线线表示_trajectory：黎曼流形表示3D线条_对于因子图优化优化优化'}
{'arxiv_id': 'arXiv:2508.04511', 'title': 'Argumentative Debates for Transparent Bias Detection [Technical Report]', 'authors': 'Hamed Ayoobi, Nico Potyka, Anna Rapberger, Francesca Toni', 'link': 'https://arxiv.org/abs/2508.04511', 'abstract': 'As the use of AI systems in society grows, addressing potential biases that emerge from data or are learned by models is essential to prevent systematic disadvantages against specific groups. Several notions of (un)fairness have been proposed in the literature, alongside corresponding algorithmic methods for detecting and mitigating unfairness, but, with very few exceptions, these tend to ignore transparency. Instead, interpretability and explainability are core requirements for algorithmic fairness, even more so than for other algorithmic solutions, given the human-oriented nature of fairness. In this paper, we contribute a novel interpretable, explainable method for bias detection relying on debates about the presence of bias against individuals, based on the values of protected features for the individuals and others in their neighbourhoods. Our method builds upon techniques from formal and computational argumentation, whereby debates result from arguing about biases within and across neighbourhoods. We provide formal, quantitative, and qualitative evaluations of our method, highlighting its strengths in performance against baselines, as well as its interpretability and explainability.', 'abstract_zh': '随着社会中人工智能系统的使用增长，应对数据中可能产生的偏见或模型学习到的偏见以防止对特定群体产生系统性不利影响是至关重要的。文献中提出了多种（不）公平的概念，以及相应的算法方法来检测和缓解不公平性，但除了少数例外，这些方法往往忽略了透明度。相比之下，可解释性和可理解性是公平算法的核心要求，这给公平性的人本性质带来了更多关注。在本文中，我们贡献了一种基于对个体及其邻里中保护特征值的辩论来检测偏见的新颖可解释、可理解的方法。该方法建立在形式化和计算辩论技术的基础上，其中辩论是在个体及其邻里内部和跨邻里讨论偏见的结果。我们提供了对该方法的正式、定量和定性评估，突显了其相对于基准方法的优势，以及其可解释性和可理解性。', 'title_zh': '论辩式辩论以实现透明的偏见检测 [技术报告'}
{'arxiv_id': 'arXiv:2508.04383', 'title': 'Artificial Consciousness as Interface Representation', 'authors': 'Robert Prentner', 'link': 'https://arxiv.org/abs/2508.04383', 'abstract': 'Whether artificial intelligence (AI) systems can possess consciousness is a contentious question because of the inherent challenges of defining and operationalizing subjective experience. This paper proposes a framework to reframe the question of artificial consciousness into empirically tractable tests. We introduce three evaluative criteria - S (subjective-linguistic), L (latent-emergent), and P (phenomenological-structural) - collectively termed SLP-tests, which assess whether an AI system instantiates interface representations that facilitate consciousness-like properties. Drawing on category theory, we model interface representations as mappings between relational substrates (RS) and observable behaviors, akin to specific types of abstraction layers. The SLP-tests collectively operationalize subjective experience not as an intrinsic property of physical systems but as a functional interface to a relational entity.', 'abstract_zh': '是否人工智能系统能够具备意识：一种将人工意识问题重新框定为可验证测试的框架', 'title_zh': '人工意识作为界面表示'}
{'arxiv_id': 'arXiv:2508.04282', 'title': 'Synthetic POMDPs to Challenge Memory-Augmented RL: Memory Demand Structure Modeling', 'authors': 'Yongyi Wang, Lingfeng Li, Bozhou Chen, Ang Li, Hanyu Liu, Qirui Zheng, Xionghui Yang, Wenxin Li', 'link': 'https://arxiv.org/abs/2508.04282', 'abstract': 'Recent research has developed benchmarks for memory-augmented reinforcement learning (RL) algorithms, providing Partially Observable Markov Decision Process (POMDP) environments where agents depend on past observations to make decisions. While many benchmarks incorporate sufficiently complex real-world problems, they lack controllability over the degree of challenges posed to memory models. In contrast, synthetic environments enable fine-grained manipulation of dynamics, making them critical for detailed and rigorous evaluation of memory-augmented RL. Our study focuses on POMDP synthesis with three key contributions:\n1. A theoretical framework for analyzing POMDPs, grounded in Memory Demand Structure (MDS), transition invariance, and related concepts; 2. A methodology leveraging linear process dynamics, state aggregation, and reward redistribution to construct customized POMDPs with predefined properties; 3. Empirically validated series of POMDP environments with increasing difficulty levels, designed based on our theoretical insights. Our work clarifies the challenges of memory-augmented RL in solving POMDPs, provides guidelines for analyzing and designing POMDP environments, and offers empirical support for selecting memory models in RL tasks.', 'abstract_zh': 'Recent research has developed benchmarks for记忆增强强化学习（RL）算法，提供了部分可观测量决策过程（POMDP）环境，其中代理依赖于过去的观测来做决策。虽然许多基准包含了足够复杂的现实世界问题，但在给定对记忆模型挑战难度的控制方面仍有所欠缺。相比之下，合成环境允许对动力学进行精细操控，使其成为详细和严格评估记忆增强RL的关键。我们的研究集中在POMDP合成，并作出以下三个关键贡献：\n1. 一个基于记忆需求结构（MDS）、状态不变性和相关概念的理论框架；\n2. 一种利用线性过程动力学、状态聚类和奖励重分配来构建具有预定义属性的定制化POMDP的方法；\n3. 一系列经验验证的POMDP环境，难度逐步增加，根据我们的理论洞见设计。我们的工作阐明了解决POMDP问题中记忆增强RL面临的挑战，提供了分析和设计POMDP环境的指南，并为在RL任务中选择记忆模型提供了实证支持。', 'title_zh': '合成POMDP模型以挑战增强记忆的RL：记忆需求结构建模'}
{'arxiv_id': 'arXiv:2508.04235', 'title': 'Circuit-Aware SAT Solving: Guiding CDCL via Conditional Probabilities', 'authors': 'Jiaying Zhu, Ziyang Zheng, Zhengyuan Shi, Yalun Cai, Qiang Xu', 'link': 'https://arxiv.org/abs/2508.04235', 'abstract': 'Circuit Satisfiability (CSAT) plays a pivotal role in Electronic Design Automation. The standard workflow for solving CSAT problems converts circuits into Conjunctive Normal Form (CNF) and employs generic SAT solvers powered by Conflict-Driven Clause Learning (CDCL). However, this process inherently discards rich structural and functional information, leading to suboptimal solver performance. To address this limitation, we introduce CASCAD, a novel circuit-aware SAT solving framework that directly leverages circuit-level conditional probabilities computed via Graph Neural Networks (GNNs). By explicitly modeling gate-level conditional probabilities, CASCAD dynamically guides two critical CDCL heuristics -- variable phase selection and clause managementto significantly enhance solver efficiency. Extensive evaluations on challenging real-world Logical Equivalence Checking (LEC) benchmarks demonstrate that CASCAD reduces solving times by up to 10x compared to state-of-the-art CNF-based approaches, achieving an additional 23.5% runtime reduction via our probability-guided clause filtering strategy. Our results underscore the importance of preserving circuit-level structural insights within SAT solvers, providing a robust foundation for future improvements in SAT-solving efficiency and EDA tool design.', 'abstract_zh': '电路可满足性（CSAT）在电子设计自动化中发挥着核心作用。为了解决CSAT问题的标准工作流程将电路转换为合取范式（CNF），并使用基于冲突驱动的子句学习（CDCL）的通用SAT求解器。然而，这一过程不可避免地会丢弃丰富的结构和功能信息，导致求解器性能不佳。为解决这一限制，我们提出了CASCAD，一种新颖的电路感知SAT求解框架，该框架可以直接利用通过图神经网络（GNN）计算得到的电路级条件概率。通过明确建模门级条件概率，CASCAD动态指导两个关键的CDCL启发式算法——变量相位选择和子句管理，显著提升求解器效率。在具有挑战性的实际逻辑等价性验证（LEC）基准测试上的广泛评估表明，与基于CNF的方法相比，CASCAD的求解时间最多可减少10倍，通过我们基于概率的子句过滤策略额外实现了23.5%的运行时间减少。我们的结果强调了在SAT求解器中保留电路级结构洞察的重要性，为未来的SAT求解效率和EDA工具设计提供了稳健的基础。', 'title_zh': '电路感知的SAT求解：基于条件概率引导的CDCL'}
{'arxiv_id': 'arXiv:2508.04163', 'title': 'Generic-to-Specific Reasoning and Learning for Scalable Ad Hoc Teamwork', 'authors': 'Hasra Dodampegama, Mohan Sridharan', 'link': 'https://arxiv.org/abs/2508.04163', 'abstract': "AI agents deployed in assistive roles often have to collaborate with other agents (humans, AI systems) without prior coordination. Methods considered state of the art for such ad hoc teamwork often pursue a data-driven approach that needs a large labeled dataset of prior observations, lacks transparency, and makes it difficult to rapidly revise existing knowledge in response to changes. As the number of agents increases, the complexity of decision-making makes it difficult to collaborate effectively. This paper advocates leveraging the complementary strengths of knowledge-based and data-driven methods for reasoning and learning for ad hoc teamwork. For any given goal, our architecture enables each ad hoc agent to determine its actions through non-monotonic logical reasoning with: (a) prior commonsense domain-specific knowledge; (b) models learned and revised rapidly to predict the behavior of other agents; and (c) anticipated abstract future goals based on generic knowledge of similar situations in an existing foundation model. We experimentally evaluate our architecture's capabilities in VirtualHome, a realistic physics-based 3D simulation environment.", 'abstract_zh': 'AI代理在辅助角色中部署时往往需要与其他代理（人类、AI系统）进行无需事先协调的合作。目前被认为是此类临时团队工作的先进方法通常采用数据驱动的方法，这需要大量标记的前期观察数据集，缺乏透明性，并使在面对变化时迅速修订现有知识变得困难。随着代理数量的增加，决策的复杂性使得有效协作变得困难。本文倡导结合基于知识的方法和数据驱动方法的互补优势来实现临时团队工作中的推理和学习。对于任何给定的目标，我们的架构使每个临时代理能够通过非单调逻辑推理来确定其行为：（a）先验的领域特定常识知识；（b）快速学习和修订的模型以预测其他代理的行为；以及（c）基于现有基础模型中类似情况的一般知识预测的抽象未来目标。我们在一个具真实性物理的3D仿真环境中VirtualHome上实验性地评估了我们架构的能力。', 'title_zh': '从通用到具体的推理与学习以实现可扩展的临时团队协作'}
{'arxiv_id': 'arXiv:2508.04118', 'title': 'AgREE: Agentic Reasoning for Knowledge Graph Completion on Emerging Entities', 'authors': 'Ruochen Zhao, Simone Conia, Eric Peng, Min Li, Saloni Potdar', 'link': 'https://arxiv.org/abs/2508.04118', 'abstract': "Open-domain Knowledge Graph Completion (KGC) faces significant challenges in an ever-changing world, especially when considering the continual emergence of new entities in daily news. Existing approaches for KGC mainly rely on pretrained language models' parametric knowledge, pre-constructed queries, or single-step retrieval, typically requiring substantial supervision and training data. Even so, they often fail to capture comprehensive and up-to-date information about unpopular and/or emerging entities. To this end, we introduce Agentic Reasoning for Emerging Entities (AgREE), a novel agent-based framework that combines iterative retrieval actions and multi-step reasoning to dynamically construct rich knowledge graph triplets. Experiments show that, despite requiring zero training efforts, AgREE significantly outperforms existing methods in constructing knowledge graph triplets, especially for emerging entities that were not seen during language models' training processes, outperforming previous methods by up to 13.7%. Moreover, we propose a new evaluation methodology that addresses a fundamental weakness of existing setups and a new benchmark for KGC on emerging entities. Our work demonstrates the effectiveness of combining agent-based reasoning with strategic information retrieval for maintaining up-to-date knowledge graphs in dynamic information environments.", 'abstract_zh': '基于代理推理的新兴实体知识图谱完成（Agentic Reasoning for Emerging Entities in Open-domain Knowledge Graph Completion）', 'title_zh': 'AgGREE: 主体推理在新兴实体知识图谱完成中的应用'}
{'arxiv_id': 'arXiv:2508.04116', 'title': 'A Compositional Framework for On-the-Fly LTLf Synthesis', 'authors': 'Yongkang Li, Shengping Xiao, Shufang Zhu, Jianwen Li, Geguang Pu', 'link': 'https://arxiv.org/abs/2508.04116', 'abstract': 'Reactive synthesis from Linear Temporal Logic over finite traces (LTLf) can be reduced to a two-player game over a Deterministic Finite Automaton (DFA) of the LTLf specification. The primary challenge here is DFA construction, which is 2EXPTIME-complete in the worst case. Existing techniques either construct the DFA compositionally before solving the game, leveraging automata minimization to mitigate state-space explosion, or build the DFA incrementally during game solving to avoid full DFA construction. However, neither is dominant. In this paper, we introduce a compositional on-the-fly synthesis framework that integrates the strengths of both approaches, focusing on large conjunctions of smaller LTLf formulas common in practice. This framework applies composition during game solving instead of automata (game arena) construction. While composing all intermediate results may be necessary in the worst case, pruning these results simplifies subsequent compositions and enables early detection of unrealizability. Specifically, the framework allows two composition variants: pruning before composition to take full advantage of minimization or pruning during composition to guide on-the-fly synthesis. Compared to state-of-the-art synthesis solvers, our framework is able to solve a notable number of instances that other solvers cannot handle. A detailed analysis shows that both composition variants have unique merits.', 'abstract_zh': '基于有限迹线的线性时序逻辑（LTLf）的反应合成可以归约为关于LTLf规范的确定有限自动机（DFA）上的两人游戏。这里的主要挑战是DFA的构造，其在最坏情况下是2EXPTIME完备的。现有技术要么在解决游戏之前组合性地构造DFA，利用自动机最小化来缓解状态空间膨胀，要么在解决游戏中增量构建DFA以避免完整的DFA构造。然而，这两种方法都不是占优的。本文介绍了一种组合性的“边解决边组合”合成框架，融合了两种方法的优势，重点关注实践中常见的较小的LTLf公式的大量联合。该框架在解决游戏中进行组合，而不是在自动机（游戏竞技场）构造时进行组合。虽然在最坏情况下可能需要组合所有中间结果，但对这些结果进行剪枝简化了后续的组合，并能早期检测到不可实现性。具体而言，该框架允许两种组合变体：在组合之前进行剪枝以充分利用最小化，或在组合过程中进行剪枝以指导动态合成。与最先进的合成求解器相比，我们的框架能够解决其他求解器无法处理的一些实例。详细的分析表明，这两种组合变体各有独特的优点。', 'title_zh': '一种实时合成LTLf的组合框架'}
{'arxiv_id': 'arXiv:2508.04105', 'title': 'Towards Transparent AI Grading: Semantic Entropy as a Signal for Human-AI Disagreement', 'authors': 'Karrtik Iyer, Manikandan Ravikiran, Prasanna Pendse, Shayan Mohanty', 'link': 'https://arxiv.org/abs/2508.04105', 'abstract': 'Automated grading systems can efficiently score short-answer responses, yet they often fail to indicate when a grading decision is uncertain or potentially contentious. We introduce semantic entropy, a measure of variability across multiple GPT-4-generated explanations for the same student response, as a proxy for human grader disagreement. By clustering rationales via entailment-based similarity and computing entropy over these clusters, we quantify the diversity of justifications without relying on final output scores. We address three research questions: (1) Does semantic entropy align with human grader disagreement? (2) Does it generalize across academic subjects? (3) Is it sensitive to structural task features such as source dependency? Experiments on the ASAP-SAS dataset show that semantic entropy correlates with rater disagreement, varies meaningfully across subjects, and increases in tasks requiring interpretive reasoning. Our findings position semantic entropy as an interpretable uncertainty signal that supports more transparent and trustworthy AI-assisted grading workflows.', 'abstract_zh': '自动评分系统可以高效地评分简答题，但往往无法指示评分决定是否含糊或存在争议。我们引入语义熵，这是一种衡量同一学生回答在多个GPT-4生成解释之间变异性的指标，以此作为人类评分者分歧的代理。通过基于包含关系的相似性对理由进行聚类，并计算这些聚类的熵，我们量化了理由的多样性，而不依赖于最终的输出分数。我们回答了三个研究问题：（1）语义熵与人类评分者分歧是否一致？（2）它是否跨学科领域普适？（3）它是否对结构性任务特征如来源依赖性敏感？实验结果表明，语义熵与评判者分歧相关，随学科领域不同而显著变化，并在需要解释性推理的任务中增加。我们的发现将语义熵定位为一种可解释的不确定性信号，支持更透明和可信赖的人工智能辅助评分工作流程。', 'title_zh': '透明AI评分的探讨：语义熵作为人机分歧的信号'}
{'arxiv_id': 'arXiv:2508.04070', 'title': 'Personalized Knowledge Transfer Through Generative AI: Contextualizing Learning to Individual Career Goals', 'authors': 'Ronja Mehlan, Claudia Hess, Quintus Stierstorfer, Kristina Schaaff', 'link': 'https://arxiv.org/abs/2508.04070', 'abstract': "As artificial intelligence becomes increasingly integrated into digital learning environments, the personalization of learning content to reflect learners' individual career goals offers promising potential to enhance engagement and long-term motivation. In our study, we investigate how career goal-based content adaptation in learning systems based on generative AI (GenAI) influences learner engagement, satisfaction, and study efficiency. The mixed-methods experiment involved more than 4,000 learners, with one group receiving learning scenarios tailored to their career goals and a control group. Quantitative results show increased session duration, higher satisfaction ratings, and a modest reduction in study duration compared to standard content. Qualitative analysis highlights that learners found the personalized material motivating and practical, enabling deep cognitive engagement and strong identification with the content. These findings underscore the value of aligning educational content with learners' career goals and suggest that scalable AI personalization can bridge academic knowledge and workplace applicability.", 'abstract_zh': '随着人工智能越来越多地融入数字学习环境，基于个人职业目标定制学习内容具备增强参与度和长期动机的潜力。在我们的研究中，我们探讨了基于生成式人工智能（GenAI）的职业目标导向内容适应如何影响学习者的参与度、满意度和学习效率。该混合方法实验涉及超过4000名学习者，其中一组接收了根据其职业目标量身定制的学习场景，另一组为对照组。定量结果显示，与标准内容相比，适应性内容的会话时长增加、满意度评分较高，并且学习时间略有减少。定性分析表明，学习者发现个性化材料具有激励性和实用性，能够促进深度认知参与并加强与内容的联系。这些发现强调了将教育内容与学习者的职业目标相结合的价值，并表明可扩展的人工智能个性化可以弥合学术知识与实际应用之间的差距。', 'title_zh': '通过生成式人工智能实现个性化知识转移：根据个人职业目标情境化学习'}
{'arxiv_id': 'arXiv:2508.04037', 'title': 'SEA: Self-Evolution Agent with Step-wise Reward for Computer Use', 'authors': 'Liang Tang, Shuxian Li, Yuhao Cheng, Yukang Huo, Zhepeng Wang, Yiqiang Yan, Kaer Huang, Yanzhe Jing, Tiaonan Duan', 'link': 'https://arxiv.org/abs/2508.04037', 'abstract': "Computer use agent is an emerging area in artificial intelligence that aims to operate the computers to achieve the user's tasks, which attracts a lot of attention from both industry and academia. However, the present agents' performance is far from being used. In this paper, we propose the Self-Evolution Agent (SEA) for computer use, and to develop this agent, we propose creative methods in data generation, reinforcement learning, and model enhancement. Specifically, we first propose an automatic pipeline to generate the verifiable trajectory for training. And then, we propose efficient step-wise reinforcement learning to alleviate the significant computational requirements for long-horizon training. In the end, we propose the enhancement method to merge the grounding and planning ability into one model without any extra training. Accordingly, based on our proposed innovation of data generation, training strategy, and enhancement, we get the Selfevolution Agent (SEA) for computer use with only 7B parameters, which outperforms models with the same number of parameters and has comparable performance to larger ones. We will make the models' weight and related codes open-source in the future.", 'abstract_zh': '计算机使用代理是人工智能的一个新兴领域，旨在操作计算机以实现用户任务，这一领域吸引了工业和学术界的广泛关注。然而，现有代理的表现还远远不够。本文提出了一种用于计算机使用的自我进化代理（SEA），并通过数据生成、强化学习和模型增强的创新方法来开发这一代理。具体来说，我们首先提出了一种自动生成可验证轨迹的自动流水线，然后提出了高效的分步强化学习方法来缓解长期训练中显著的计算需求。最后，我们提出了一种增强方法，将接地能力和规划能力整合到一个模型中，无需额外训练。基于我们提出的这些创新，在数据生成、训练策略和增强方法方面，我们构建了一个仅包含7B参数的自我进化代理（SEA），其性能优于具有相同参数数量的模型，并且与更大规模的模型具有可比的性能。我们将在未来开源该模型的权重及相关代码。', 'title_zh': 'SEA：具有良好阶梯奖励机制的自我进化计算机使用代理'}
{'arxiv_id': 'arXiv:2508.04025', 'title': 'Uncertainty-Aware GUI Agent: Adaptive Perception through Component Recommendation and Human-in-the-Loop Refinement', 'authors': 'Chao Hao, Shuai Wang, Kaiwen Zhou', 'link': 'https://arxiv.org/abs/2508.04025', 'abstract': 'Graphical user interface (GUI) agents have shown promise in automating mobile tasks but still struggle with input redundancy and decision ambiguity. In this paper, we present \\textbf{RecAgent}, an uncertainty-aware agent that addresses these issues through adaptive perception. We distinguish two types of uncertainty in GUI navigation: (1) perceptual uncertainty, caused by input redundancy and noise from comprehensive screen information, and (2) decision uncertainty, arising from ambiguous tasks and complex reasoning. To reduce perceptual uncertainty, RecAgent employs a component recommendation mechanism that identifies and focuses on the most relevant UI elements. For decision uncertainty, it uses an interactive module to request user feedback in ambiguous situations, enabling intent-aware decisions. These components are integrated into a unified framework that proactively reduces input complexity and reacts to high-uncertainty cases via human-in-the-loop refinement. Additionally, we propose a dataset called \\textbf{ComplexAction} to evaluate the success rate of GUI agents in executing specified single-step actions within complex scenarios. Extensive experiments validate the effectiveness of our approach. The dataset and code will be available at this https URL.', 'abstract_zh': '图形用户界面（GUI）代理在自动化移动任务方面展现出潜力，但仍存在输入冗余和决策模糊的问题。本文介绍了一种名为RecAgent的不确定性感知代理，通过适应性感知解决这些问题。我们区分了GUI导航中的两种不确定性：（1）感知不确定性，由输入冗余和综合屏幕信息中的噪音引起；（2）决策不确定性，由任务模糊性和复杂的推理引起。为了减少感知不确定性，RecAgent采用了组件推荐机制，识别并关注最相关的UI元素。对于决策不确定性，它使用一个交互模块，在模糊情况下请求用户反馈，以实现意图感知的决策。这些组件被集成到一个统一框架中，该框架能主动降低输入复杂性，并通过人工在环改进来应对高不确定性情况。此外，我们提出了一个名为ComplexAction的数据集，用于评估GUI代理在复杂场景中执行指定单步骤操作的成功率。大量实验证明了该方法的有效性。数据集和代码可从此网址获取。', 'title_zh': '不确定性意识的GUI代理：基于组件推荐和人机交互循环改进的自适应感知'}
{'arxiv_id': 'arXiv:2508.04699', 'title': 'Hop, Skip, and Overthink: Diagnosing Why Reasoning Models Fumble during Multi-Hop Analysis', 'authors': 'Anushka Yadav, Isha Nalawade, Srujana Pillarichety, Yashwanth Babu, Reshmi Ghosh, Samyadeep Basu, Wenlong Zhao, Ali Nasaeh, Sriram Balasubramanian, Soundararajan Srinivasan', 'link': 'https://arxiv.org/abs/2508.04699', 'abstract': 'The emergence of reasoning models and their integration into practical AI chat bots has led to breakthroughs in solving advanced math, deep search, and extractive question answering problems that requires a complex and multi-step thought process. Yet, a complete understanding of why these models hallucinate more than general purpose language models is missing. In this investigative study, we systematicallyexplore reasoning failures of contemporary language models on multi-hop question answering tasks. We introduce a novel, nuanced error categorization framework that examines failures across three critical dimensions: the diversity and uniqueness of source documents involved ("hops"), completeness in capturing relevant information ("coverage"), and cognitive inefficiency ("overthinking"). Through rigorous hu-man annotation, supported by complementary automated metrics, our exploration uncovers intricate error patterns often hidden by accuracy-centric evaluations. This investigative approach provides deeper insights into the cognitive limitations of current models and offers actionable guidance toward enhancing reasoning fidelity, transparency, and robustness in future language modeling efforts.', 'abstract_zh': '推理模型的出现及其融入实际AI聊天机器人，推动了解决高级数学、深入搜索和提取式问答等问题的突破，这些问题需要复杂的多步推理过程。然而，关于这些模型为何比通用语言模型更容易产生幻觉的原因尚未完全理解。在此探究性研究中，我们系统地探讨了当代语言模型在多跳问答任务中的推理失败。我们引入了一种新颖而精炼的错误分类框架，该框架从三个关键维度考察失败情况：涉及的多样性和独特性来源文档（"跳"）、捕获相关信息的完整性（"覆盖"），以及认知上的低效率（"过度思考"）。通过严格的手动标注，并辅以互补的自动化评估指标，我们的研究揭示了通常在以准确率为中心的评估中难以察觉的复杂错误模式。这种探究性方法提供了对当前模型认知限制的更深入理解，并为提高未来语言建模中的推理保真度、透明度和鲁棒性提供了可操作的指导。', 'title_zh': '跳一跳，Skip一下，深思熟虑：诊断多跳分析中推理模型失误的原因'}
{'arxiv_id': 'arXiv:2508.04683', 'title': 'Query Attribute Modeling: Improving search relevance with Semantic Search and Meta Data Filtering', 'authors': 'Karthik Menon, Batool Arhamna Haider, Muhammad Arham, Kanwal Mehreen, Ram Mohan Rao Kadiyala, Hamza Farooq', 'link': 'https://arxiv.org/abs/2508.04683', 'abstract': "This study introduces Query Attribute Modeling (QAM), a hybrid framework that enhances search precision and relevance by decomposing open text queries into structured metadata tags and semantic elements. QAM addresses traditional search limitations by automatically extracting metadata filters from free-form text queries, reducing noise and enabling focused retrieval of relevant items.\nExperimental evaluation using the Amazon Toys Reviews dataset (10,000 unique items with 40,000+ reviews and detailed product attributes) demonstrated QAM's superior performance, achieving a mean average precision at 5 (mAP@5) of 52.99\\%. This represents significant improvement over conventional methods, including BM25 keyword search, encoder-based semantic similarity search, cross-encoder re-ranking, and hybrid search combining BM25 and semantic results via Reciprocal Rank Fusion (RRF). The results establish QAM as a robust solution for Enterprise Search applications, particularly in e-commerce systems.", 'abstract_zh': 'This study introduces Query Attribute Modeling (QAM)，一种通过将开放文本查询分解为结构化元数据标签和语义元素来增强搜索精确度和相关性的混合框架。QAM通过自动从非结构化文本查询中提取元数据过滤器，减少噪声并实现对相关项目的集中检索，从而克服传统搜索的局限性。使用Amazon Toys Reviews数据集（包含10,000个独特项目和40,000多条评论及详细产品属性）的实验评估证明了QAM的优越性能，其5位平均精确度（mAP@5）达到52.99%。这比包括BM25关键字搜索、基于编码器的语义相似性搜索、交叉编码再排序以及结合BM25和语义结果的混合搜索（通过互惠排名融合RRF）在内的传统方法有显著改善。这些结果确立了QAM在企业搜索应用，特别是在电子商务系统中的稳健解决方案的地位。', 'title_zh': '查询属性建模：通过语义搜索和元数据过滤提高搜索相关性'}
{'arxiv_id': 'arXiv:2508.04667', 'title': 'How are CS students using resources and AI tools for coding tasks?', 'authors': 'Natalia Echeverry, Arun Lekshmi Narayanan', 'link': 'https://arxiv.org/abs/2508.04667', 'abstract': 'A survey of 26 CS students reveals that AI coding assistants are mainly used for writing code (second to online searches) while AI chatbots are the top resource for debugging. Participants with different coding experience prefer online help over direct human help from peers and instructors.', 'abstract_zh': '一项对26名计算机科学学生的研究发现，AI代码助手主要被用于阅读代码（仅次于在线搜索） � rechercher 而AI聊天机器人则是调试的主要资源。查阅编码经验主要来自在线线线上的帮助 比直接从同学和教师那里得到的帮助更加常见。', 'title_zh': 'CS学生如何使用资源和AI工具进行编程任务？'}
{'arxiv_id': 'arXiv:2508.04663', 'title': 'HierarchicalPrune: Position-Aware Compression for Large-Scale Diffusion Models', 'authors': 'Young D. Kwon, Rui Li, Sijia Li, Da Li, Sourav Bhattacharya, Stylianos I. Venieris', 'link': 'https://arxiv.org/abs/2508.04663', 'abstract': 'State-of-the-art text-to-image diffusion models (DMs) achieve remarkable quality, yet their massive parameter scale (8-11B) poses significant challenges for inferences on resource-constrained devices. In this paper, we present HierarchicalPrune, a novel compression framework grounded in a key observation: DM blocks exhibit distinct functional hierarchies, where early blocks establish semantic structures while later blocks handle texture refinements. HierarchicalPrune synergistically combines three techniques: (1) Hierarchical Position Pruning, which identifies and removes less essential later blocks based on position hierarchy; (2) Positional Weight Preservation, which systematically protects early model portions that are essential for semantic structural integrity; and (3) Sensitivity-Guided Distillation, which adjusts knowledge-transfer intensity based on our discovery of block-wise sensitivity variations. As a result, our framework brings billion-scale diffusion models into a range more suitable for on-device inference, while preserving the quality of the output images. Specifically, when combined with INT4 weight quantisation, HierarchicalPrune achieves 77.5-80.4% memory footprint reduction (e.g., from 15.8 GB to 3.2 GB) and 27.9-38.0% latency reduction, measured on server and consumer grade GPUs, with the minimum drop of 2.6% in GenEval score and 7% in HPSv2 score compared to the original model. Last but not least, our comprehensive user study with 85 participants demonstrates that HierarchicalPrune maintains perceptual quality comparable to the original model while significantly outperforming prior works.', 'abstract_zh': '先进文本到图像扩散模型的层次化剪枝框架', 'title_zh': '层次剪枝: 基于位置的大型扩散模型压缩方法'}
{'arxiv_id': 'arXiv:2508.04645', 'title': 'A Scalable Pretraining Framework for Link Prediction with Efficient Adaptation', 'authors': 'Yu Song, Zhigang Hua, Harry Shomer, Yan Xie, Jingzhe Liu, Bo Long, Hui Liu', 'link': 'https://arxiv.org/abs/2508.04645', 'abstract': 'Link Prediction (LP) is a critical task in graph machine learning. While Graph Neural Networks (GNNs) have significantly advanced LP performance recently, existing methods face key challenges including limited supervision from sparse connectivity, sensitivity to initialization, and poor generalization under distribution shifts. We explore pretraining as a solution to address these challenges. Unlike node classification, LP is inherently a pairwise task, which requires the integration of both node- and edge-level information. In this work, we present the first systematic study on the transferability of these distinct modules and propose a late fusion strategy to effectively combine their outputs for improved performance. To handle the diversity of pretraining data and avoid negative transfer, we introduce a Mixture-of-Experts (MoE) framework that captures distinct patterns in separate experts, facilitating seamless application of the pretrained model on diverse downstream datasets. For fast adaptation, we develop a parameter-efficient tuning strategy that allows the pretrained model to adapt to unseen datasets with minimal computational overhead. Experiments on 16 datasets across two domains demonstrate the effectiveness of our approach, achieving state-of-the-art performance on low-resource link prediction while obtaining competitive results compared to end-to-end trained methods, with over 10,000x lower computational overhead.', 'abstract_zh': '图机器学习中的链接预测（LP）是一项关键任务。尽管图神经网络（GNNs）最近显著提升了LP性能，但现有方法仍面临来自稀疏连接的有限监督、初始化敏感性以及分布转移下泛化能力差等关键挑战。我们探索预训练作为一种解决方案来应对这些挑战。不同于节点分类，LP本质上是一个成对任务，需要节点级和边级信息的整合。在本文中，我们首次系统研究了这些不同模块的迁移性，并提出了一种晚期融合策略，以有效结合它们的输出以提高性能。为处理预训练数据的多样性并避免负迁移，我们引入了Mixture-of-Experts（MoE）框架，该框架分别在各个专家中捕获不同的模式，从而无缝地将预训练模型应用于多样化的下游数据集。为了快速适应，我们开发了一种参数高效的调整策略，使预训练模型能够在较低的计算开销下适应未见过的数据集。实验结果表明，我们的方法在低资源链接预测任务中达到了最先进的性能，相比端到端训练方法在计算开销上低了超过10,000倍的同时，还获得了具有竞争力的结果。', 'title_zh': '一种具有高效适应性的可扩展预训练框架用于链接预测'}
{'arxiv_id': 'arXiv:2508.04618', 'title': 'HiD-VAE: Interpretable Generative Recommendation via Hierarchical and Disentangled Semantic IDs', 'authors': 'Dengzhao Fang, Jingtong Gao, Chengcheng Zhu, Yu Li, Xiangyu Zhao, Yi Chang', 'link': 'https://arxiv.org/abs/2508.04618', 'abstract': "Recommender systems are indispensable for helping users navigate the immense item catalogs of modern online platforms. Recently, generative recommendation has emerged as a promising paradigm, unifying the conventional retrieve-and-rank pipeline into an end-to-end model capable of dynamic generation. However, existing generative methods are fundamentally constrained by their unsupervised tokenization, which generates semantic IDs suffering from two critical flaws: (1) they are semantically flat and uninterpretable, lacking a coherent hierarchy, and (2) they are prone to representation entanglement (i.e., ``ID collisions''), which harms recommendation accuracy and diversity. To overcome these limitations, we propose HiD-VAE, a novel framework that learns hierarchically disentangled item representations through two core innovations. First, HiD-VAE pioneers a hierarchically-supervised quantization process that aligns discrete codes with multi-level item tags, yielding more uniform and disentangled IDs. Crucially, the trained codebooks can predict hierarchical tags, providing a traceable and interpretable semantic path for each recommendation. Second, to combat representation entanglement, HiD-VAE incorporates a novel uniqueness loss that directly penalizes latent space overlap. This mechanism not only resolves the critical ID collision problem but also promotes recommendation diversity by ensuring a more comprehensive utilization of the item representation space. These high-quality, disentangled IDs provide a powerful foundation for downstream generative models. Extensive experiments on three public benchmarks validate HiD-VAE's superior performance against state-of-the-art methods. The code is available at this https URL.", 'abstract_zh': '推荐系统对于帮助用户导航现代在线平台上的海量商品目录是必不可少的。最近，生成推荐作为一种有前景的范式出现了，它将传统的检索-排名管道统一成一个端到端的动态生成模型。然而，现有的生成方法本质上受到无监督标记的限制，生成的语义ID存在两个关键缺陷：（1）它们在语义上是扁平且难以解释的，缺乏连贯的层次结构；（2）它们易遭受表示纠缠（即“ID碰撞”），这对推荐的准确性和多样性造成了危害。为克服这些限制，我们提出了HiD-VAE，一种新颖的框架，通过两项核心创新学习层次解纠缠的商品表示。首先，HiD-VAE 开创了一种层次监督的量化过程，使离散代码与多级商品标签对齐，从而产生更均匀和解纠缠的ID。关键的是，训练后的码本可以预测层次标签，为每个推荐提供可追踪和可解释的语义路径。其次，为了应对表示纠缠，HiD-VAE 引入了一种新的唯一性损失，直接惩罚潜在空间的重叠。这一机制不仅解决了关键的ID碰撞问题，还通过确保更全面利用商品表示空间来促进推荐多样性。这些高质量、解纠缠的ID为下游生成模型提供了强大的基础。在三个公开基准上的广泛实验验证了HiD-VAE相对于现有最佳方法的优越性能。代码可在以下链接获取。', 'title_zh': 'HiD-VAE：通过层次和解混语义ID实现可解释的生成推荐'}
{'arxiv_id': 'arXiv:2508.04610', 'title': 'Neuromorphic Cybersecurity with Semi-supervised Lifelong Learning', 'authors': 'Md Zesun Ahmed Mia, Malyaban Bal, Sen Lu, George M. Nishibuchi, Suhas Chelian, Srini Vasan, Abhronil Sengupta', 'link': 'https://arxiv.org/abs/2508.04610', 'abstract': "Inspired by the brain's hierarchical processing and energy efficiency, this paper presents a Spiking Neural Network (SNN) architecture for lifelong Network Intrusion Detection System (NIDS). The proposed system first employs an efficient static SNN to identify potential intrusions, which then activates an adaptive dynamic SNN responsible for classifying the specific attack type. Mimicking biological adaptation, the dynamic classifier utilizes Grow When Required (GWR)-inspired structural plasticity and a novel Adaptive Spike-Timing-Dependent Plasticity (Ad-STDP) learning rule. These bio-plausible mechanisms enable the network to learn new threats incrementally while preserving existing knowledge. Tested on the UNSW-NB15 benchmark in a continual learning setting, the architecture demonstrates robust adaptation, reduced catastrophic forgetting, and achieves $85.3$\\% overall accuracy. Furthermore, simulations using the Intel Lava framework confirm high operational sparsity, highlighting the potential for low-power deployment on neuromorphic hardware.", 'abstract_zh': '受大脑层次处理和能效启发的持续网络入侵检测系统中基于脉冲神经网络的架构', 'title_zh': '基于半监督终身学习的神经形态网络安全'}
{'arxiv_id': 'arXiv:2508.04594', 'title': 'GraphProp: Training the Graph Foundation Models using Graph Properties', 'authors': 'Ziheng Sun, Qi Feng, Lehao Lin, Chris Ding, Jicong Fan', 'link': 'https://arxiv.org/abs/2508.04594', 'abstract': 'This work focuses on training graph foundation models (GFMs) that have strong generalization ability in graph-level tasks such as graph classification. Effective GFM training requires capturing information consistent across different domains. We discover that graph structures provide more consistent cross-domain information compared to node features and graph labels. However, traditional GFMs primarily focus on transferring node features from various domains into a unified representation space but often lack structural cross-domain generalization. To address this, we introduce GraphProp, which emphasizes structural generalization. The training process of GraphProp consists of two main phases. First, we train a structural GFM by predicting graph invariants. Since graph invariants are properties of graphs that depend only on the abstract structure, not on particular labellings or drawings of the graph, this structural GFM has a strong ability to capture the abstract structural information and provide discriminative graph representations comparable across diverse domains. In the second phase, we use the representations given by the structural GFM as positional encodings to train a comprehensive GFM. This phase utilizes domain-specific node attributes and graph labels to further improve cross-domain node feature generalization. Our experiments demonstrate that GraphProp significantly outperforms the competitors in supervised learning and few-shot learning, especially in handling graphs without node attributes.', 'abstract_zh': '本研究专注于训练在图级别任务如图分类中具有强泛化能力的图基础模型（GFMs）。有效的GFMs训练需要捕捉跨领域一致的信息。我们发现，图结构相比节点特征和图标签提供了更多的跨领域一致性信息。然而，传统的GFMs主要侧重于将来自不同领域的节点特征转换到一个统一的表示空间，但往往缺乏结构上的跨领域泛化能力。为了解决这一问题，我们引入了GraphProp，强调结构上的泛化能力。GraphProp的训练过程包括两个主要阶段。首先，通过预测图不变量来训练一个结构化的GFMs，由于图不变量仅依赖于图的抽象结构，与具体的标记或绘制无关，因此这种结构化的GFMs具备较强的抽象结构信息捕捉能力，提供在多样领域中可比的具有辨别力的图表示。在第二个阶段，我们使用结构化GFMs给出的表示作为位置编码来训练一个综合的GFMs，这一阶段利用领域特异性的节点属性和图标签以进一步提高节点特征的跨领域泛化能力。我们的实验表明，GraphProp在监督学习和少样本学习中显著优于竞争对手，特别是在处理无节点属性的图时更为有效。', 'title_zh': 'GraphProp：使用图属性训练图基础模型'}
{'arxiv_id': 'arXiv:2508.04588', 'title': 'A Comprehensive Framework for Uncertainty Quantification of Voxel-wise Supervised Models in IVIM MRI', 'authors': 'Nicola Casali, Alessandro Brusaferri, Giuseppe Baselli, Stefano Fumagalli, Edoardo Micotti, Gianluigi Forloni, Riaz Hussein, Giovanna Rizzo, Alfonso Mastropietro', 'link': 'https://arxiv.org/abs/2508.04588', 'abstract': 'Accurate estimation of intravoxel incoherent motion (IVIM) parameters from diffusion-weighted MRI remains challenging due to the ill-posed nature of the inverse problem and high sensitivity to noise, particularly in the perfusion compartment. In this work, we propose a probabilistic deep learning framework based on Deep Ensembles (DE) of Mixture Density Networks (MDNs), enabling estimation of total predictive uncertainty and decomposition into aleatoric (AU) and epistemic (EU) components. The method was benchmarked against non probabilistic neural networks, a Bayesian fitting approach and a probabilistic network with single Gaussian parametrization. Supervised training was performed on synthetic data, and evaluation was conducted on both simulated and two in vivo datasets. The reliability of the quantified uncertainties was assessed using calibration curves, output distribution sharpness, and the Continuous Ranked Probability Score (CRPS). MDNs produced more calibrated and sharper predictive distributions for the D and f parameters, although slight overconfidence was observed in D*. The Robust Coefficient of Variation (RCV) indicated smoother in vivo estimates for D* with MDNs compared to Gaussian model. Despite the training data covering the expected physiological range, elevated EU in vivo suggests a mismatch with real acquisition conditions, highlighting the importance of incorporating EU, which was allowed by DE. Overall, we present a comprehensive framework for IVIM fitting with uncertainty quantification, which enables the identification and interpretation of unreliable estimates. The proposed approach can also be adopted for fitting other physical models through appropriate architectural and simulation adjustments.', 'abstract_zh': '基于深度混合密度网络集成的深度学习框架在弥散加权MRI中准确估计IVIM参数及不确定性量化', 'title_zh': '体素级监督模型在IVIM MRI中不确定性量化 Comprehensive Framework'}
{'arxiv_id': 'arXiv:2508.04586', 'title': 'Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference', 'authors': 'Nuo Chen, Moming Duan, Andre Huikai Lin, Qian Wang, Jiaying Wu, Bingsheng He', 'link': 'https://arxiv.org/abs/2508.04586', 'abstract': 'Artificial Intelligence (AI) conferences are essential for advancing research, sharing knowledge, and fostering academic community. However, their rapid expansion has rendered the centralized conference model increasingly unsustainable. This paper offers a data-driven diagnosis of a structural crisis that threatens the foundational goals of scientific dissemination, equity, and community well-being. We identify four key areas of strain: (1) scientifically, with per-author publication rates more than doubling over the past decade to over 4.5 papers annually; (2) environmentally, with the carbon footprint of a single conference exceeding the daily emissions of its host city; (3) psychologically, with 71% of online community discourse reflecting negative sentiment and 35% referencing mental health concerns; and (4) logistically, with attendance at top conferences such as NeurIPS 2024 beginning to outpace venue capacity. These pressures point to a system that is misaligned with its core mission. In response, we propose the Community-Federated Conference (CFC) model, which separates peer review, presentation, and networking into globally coordinated but locally organized components, offering a more sustainable, inclusive, and resilient path forward for AI research.', 'abstract_zh': '人工智能（AI）会议对于推进研究、传播知识和促进学术社区具有重要作用。然而\n其余内容翻译如下：\n\n然而\n随着快速发展，，中心化的会议模式变得越来越不可持续。本文提供了一种数据驱动的诊断，并分析威胁科学研究、公平性和社区福祉基础目标的结构性危机。我们确定了四个关键领域的压力：（1）科学性性在过去十年中每位作者发表论文的数量超过四篇增至超过四.5篇四年；（）环境科学性单个会议的碳排放量超过该地区城市每日的排放量；（3）心理健康科学在线上社区讨论中75%反映消极情绪并且35%提到心理健康问题；和（4）会议容量科学呈现如像如NeurIPS等 2  24等等参展人数已经超出会场容量。这些压力表明该系统与其核心使命不一致。为了应对这一挑战，我们提出了一种社区联邦会议（CFC）模式，该模式将评审、展示和交流整合为一个全球协调、当地组织的结构形式，为AI研究提供一种更可持续、包容和 弹性性强的战略方向。', 'title_zh': '位置：当前集中化AI会议模式不可持续！诊断集中化AI会议危机'}
{'arxiv_id': 'arXiv:2508.04575', 'title': 'Beyond Brainstorming: What Drives High-Quality Scientific Ideas? Lessons from Multi-Agent Collaboration', 'authors': 'Nuo Chen, Yicheng Tong, Jiaying Wu, Minh Duc Duong, Qian Wang, Qingyun Zou, Bryan Hooi, Bingsheng He', 'link': 'https://arxiv.org/abs/2508.04575', 'abstract': 'While AI agents show potential in scientific ideation, most existing frameworks rely on single-agent refinement, limiting creativity due to bounded knowledge and perspective. Inspired by real-world research dynamics, this paper investigates whether structured multi-agent discussions can surpass solitary ideation. We propose a cooperative multi-agent framework for generating research proposals and systematically compare configurations including group size, leaderled versus leaderless structures, and team compositions varying in interdisciplinarity and seniority. To assess idea quality, we employ a comprehensive protocol with agent-based scoring and human review across dimensions such as novelty, strategic vision, and integration depth. Our results show that multi-agent discussions substantially outperform solitary baselines. A designated leader acts as a catalyst, transforming discussion into more integrated and visionary proposals. Notably, we find that cognitive diversity is a primary driver of quality, yet expertise is a non-negotiable prerequisite, as teams lacking a foundation of senior knowledge fail to surpass even a single competent agent. These findings offer actionable insights for designing collaborative AI ideation systems and shed light on how team structure influences creative outcomes.', 'abstract_zh': '基于结构化多agent讨论的科学研究提案生成 WHETHER STRUCTURED MULTI-AGENT DISCUSSIONS CAN超越孤独式创意思考：一个合作多agent框架的研究', 'title_zh': '超越头脑风暴：高质量科学构想的驱动因素——多代理合作的启示'}
{'arxiv_id': 'arXiv:2508.04524', 'title': 'RAIDX: A Retrieval-Augmented Generation and GRPO Reinforcement Learning Framework for Explainable Deepfake Detection', 'authors': 'Tianxiao Li, Zhenglin Huang, Haiquan Wen, Yiwei He, Shuchang Lyu, Baoyuan Wu, Guangliang Cheng', 'link': 'https://arxiv.org/abs/2508.04524', 'abstract': "The rapid advancement of AI-generation models has enabled the creation of hyperrealistic imagery, posing ethical risks through widespread misinformation. Current deepfake detection methods, categorized as face specific detectors or general AI-generated detectors, lack transparency by framing detection as a classification task without explaining decisions. While several LLM-based approaches offer explainability, they suffer from coarse-grained analyses and dependency on labor-intensive annotations. This paper introduces RAIDX (Retrieval-Augmented Image Deepfake Detection and Explainability), a novel deepfake detection framework integrating Retrieval-Augmented Generation (RAG) and Group Relative Policy Optimization (GRPO) to enhance detection accuracy and decision explainability. Specifically, RAIDX leverages RAG to incorporate external knowledge for improved detection accuracy and employs GRPO to autonomously generate fine-grained textual explanations and saliency maps, eliminating the need for extensive manual annotations. Experiments on multiple benchmarks demonstrate RAIDX's effectiveness in identifying real or fake, and providing interpretable rationales in both textual descriptions and saliency maps, achieving state-of-the-art detection performance while advancing transparency in deepfake identification. RAIDX represents the first unified framework to synergize RAG and GRPO, addressing critical gaps in accuracy and explainability. Our code and models will be publicly available.", 'abstract_zh': 'AI生成模型的飞速发展产生了超逼真图像，引发了广泛 misinformation的伦理风险。当前的深度伪造检测方法，分为面部专用检测器或通用AI生成检测器，缺乏透明度，将检测视为分类任务而不解释决策过程。虽然基于大规模语言模型的方法提供了可解释性，但它们存在粗粒度分析和依赖大量劳动密集型标注的缺点。本文 introduces RAIDX（检索增强图像深度伪造检测与解释），一种结合检索增强生成（RAG）和组相对策略优化（GRPO）的新颖深度伪造检测框架，以提升检测准确性和决策解释性。具体来说，RAIDX 利用 RAG 融合外部知识以提高检测准确性，并采用 GRPO 自动生成细粒度的文本解释和显著性图，从而消除对大量手动标注的需求。多个基准上的实验表明，RAIDX 在识别真实或伪造内容，以及在文本描述和显著性图中提供可解释的理由方面表现出色，同时在深度伪造识别方面达到了最先进的检测性能，推进了检测透明度的发展。RAIDX 代表了第一个结合 RAG 和 GRPO 的统一框架，解决了准确性与解释性的重要缺口。我们的代码和模型将公开发布。', 'title_zh': 'RAIDX：一种检索增强生成与GRPO强化学习框架以实现可解释的深度假信息检测'}
{'arxiv_id': 'arXiv:2508.04503', 'title': 'PRISM: Lightweight Multivariate Time-Series Classification through Symmetric Multi-Resolution Convolutional Layers', 'authors': 'Federico Zucchi, Thomas Lampert', 'link': 'https://arxiv.org/abs/2508.04503', 'abstract': 'Multivariate time-series classification is pivotal in domains ranging from wearable sensing to biomedical monitoring. Despite recent advances, Transformer- and CNN-based models often remain computationally heavy, offer limited frequency diversity, and require extensive parameter budgets. We propose PRISM (Per-channel Resolution-Informed Symmetric Module), a convolutional-based feature extractor that applies symmetric finite-impulse-response (FIR) filters at multiple temporal scales, independently per channel. This multi-resolution, per-channel design yields highly frequency-selective embeddings without any inter-channel convolutions, greatly reducing model size and complexity. Across human-activity, sleep-stage and biomedical benchmarks, PRISM, paired with lightweight classification heads, matches or outperforms leading CNN and Transformer baselines, while using roughly an order of magnitude fewer parameters and FLOPs. By uniting classical signal processing insights with modern deep learning, PRISM offers an accurate, resource-efficient solution for multivariate time-series classification.', 'abstract_zh': '多时间序列分类在可\n.user\nMultivariate time-series classification is pivotal in domains ranging from wearable sensing to biomedical monitoring. Despite recent advances, transformer- and CNN-based models often remain computationally heavy and require extensive parameter budgets. We propose PRISM (Per-channel Resolution-Informed Symmetric Module), a convolutional-based feature extractor that applies symmetric finite-impulse-response (FIR) filters across multiple temporal scales independently per across channel.. This multi-resolution application channel-based approach provides highly channel-selective embeddings through through channel convolutions greatly reducing applies and complexity. Across human activity sleep and biomedical benchmarks, PRISM paired with lightweight classification base achieves outper performs CNN and Transformer baselines while using roughly an order of magnitude fewer parameters and F F operations. By unit into classical signal processing insights with modern deep learning PRISM offers an accurate and resource-efficient solution for multivariate time-series classification.\n\n标题：', 'title_zh': 'PRISM：通过对称多分辨率卷积层实现的轻量级多变量时间序列分类'}
{'arxiv_id': 'arXiv:2508.04492', 'title': 'Learning Robust Intervention Representations with Delta Embeddings', 'authors': 'Panagiotis Alimisis, Christos Diou', 'link': 'https://arxiv.org/abs/2508.04492', 'abstract': 'Causal representation learning has attracted significant research interest during the past few years, as a means for improving model generalization and robustness. Causal representations of interventional image pairs, have the property that only variables corresponding to scene elements affected by the intervention / action are changed between the start state and the end state. While most work in this area has focused on identifying and representing the variables of the scene under a causal model, fewer efforts have focused on representations of the interventions themselves. In this work, we show that an effective strategy for improving out of distribution (OOD) robustness is to focus on the representation of interventions in the latent space. Specifically, we propose that an intervention can be represented by a Causal Delta Embedding that is invariant to the visual scene and sparse in terms of the causal variables it affects. Leveraging this insight, we propose a framework that is capable of learning causal representations from image pairs, without any additional supervision. Experiments in the Causal Triplet challenge demonstrate that Causal Delta Embeddings are highly effective in OOD settings, significantly exceeding baseline performance in both synthetic and real-world benchmarks.', 'abstract_zh': '因果表示学习在过去的几年中吸引了显著的研究兴趣，作为一种提高模型泛化能力和鲁棒性的手段。因果模型下的干涉及图像对的因果表示具有特性，即干预/动作作用于场景元素的变量在初始状态和最终状态之间发生变化。虽然该领域的大部分工作集中在识别和表示场景中的因果变量，但较少有研究集中在干预本身的表示上。在本工作中，我们展示了提高分布外（OOD）鲁棒性的有效策略是关注潜空间中干预的表示。具体而言，我们提出干预可以通过一个不变于视觉场景且在影响的因果变量上稀疏的因果差嵌入（Causal Delta Embedding）来表示。利用这一洞察，我们提出了一种框架，能够在无需额外监督的情况下从图像对中学习因果表示。因果三元组挑战中的实验表明，因果差嵌入在OOD设置中非常有效，显著超过基线性能，无论是合成数据还是真实世界基准。', 'title_zh': '基于Delta嵌入学习稳健的干预表示'}
{'arxiv_id': 'arXiv:2508.04489', 'title': 'Hierarchical Scoring for Machine Learning Classifier Error Impact Evaluation', 'authors': 'Erin Lanus, Daniel Wolodkin, Laura J. Freeman', 'link': 'https://arxiv.org/abs/2508.04489', 'abstract': 'A common use of machine learning (ML) models is predicting the class of a sample. Object detection is an extension of classification that includes localization of the object via a bounding box within the sample. Classification, and by extension object detection, is typically evaluated by counting a prediction as incorrect if the predicted label does not match the ground truth label. This pass/fail scoring treats all misclassifications as equivalent. In many cases, class labels can be organized into a class taxonomy with a hierarchical structure to either reflect relationships among the data or operator valuation of misclassifications. When such a hierarchical structure exists, hierarchical scoring metrics can return the model performance of a given prediction related to the distance between the prediction and the ground truth label. Such metrics can be viewed as giving partial credit to predictions instead of pass/fail, enabling a finer-grained understanding of the impact of misclassifications. This work develops hierarchical scoring metrics varying in complexity that utilize scoring trees to encode relationships between class labels and produce metrics that reflect distance in the scoring tree. The scoring metrics are demonstrated on an abstract use case with scoring trees that represent three weighting strategies and evaluated by the kind of errors discouraged. Results demonstrate that these metrics capture errors with finer granularity and the scoring trees enable tuning. This work demonstrates an approach to evaluating ML performance that ranks models not only by how many errors are made but by the kind or impact of errors. Python implementations of the scoring metrics will be available in an open-source repository at time of publication.', 'abstract_zh': '机器学习模型的层次评分指标：基于分类标签层次结构的预测评估', 'title_zh': '层次评分法用于机器学习分类器误差影响评估'}
{'arxiv_id': 'arXiv:2508.04488', 'title': 'Benchmarking Quantum and Classical Sequential Models for Urban Telecommunication Forecasting', 'authors': 'Chi-Sheng Chen, Samuel Yen-Chi Chen, Yun-Cheng Tsai', 'link': 'https://arxiv.org/abs/2508.04488', 'abstract': 'In this study, we evaluate the performance of classical and quantum-inspired sequential models in forecasting univariate time series of incoming SMS activity (SMS-in) using the Milan Telecommunication Activity Dataset. Due to data completeness limitations, we focus exclusively on the SMS-in signal for each spatial grid cell. We compare five models, LSTM (baseline), Quantum LSTM (QLSTM), Quantum Adaptive Self-Attention (QASA), Quantum Receptance Weighted Key-Value (QRWKV), and Quantum Fast Weight Programmers (QFWP), under varying input sequence lengths (4, 8, 12, 16, 32 and 64). All models are trained to predict the next 10-minute SMS-in value based solely on historical values within a given sequence window. Our findings indicate that different models exhibit varying sensitivities to sequence length, suggesting that quantum enhancements are not universally advantageous. Rather, the effectiveness of quantum modules is highly dependent on the specific task and architectural design, reflecting inherent trade-offs among model size, parameterization strategies, and temporal modeling capabilities.', 'abstract_zh': '本研究评估了经典和量子启发式序列模型在使用米兰电信活动数据集预测入站短信活动（SMS-in）的单变量时间序列方面的性能。由于数据完整性限制，我们仅专注于每个空间网格单元的SMS-in信号。我们在不同的输入序列长度（4, 8, 12, 16, 32和64）下比较了五种模型：LSTM（基线）、量子LSTM（QLSTM）、量子自适应自注意力（QASA）、量子受容抗权键值（QRWKV）和量子快速权重程序员（QFWP）。所有模型均被训练以基于给定序列窗口内的历史值预测下一个10分钟的SMS-in值。我们的研究结果表明，不同模型对序列长度的敏感性不同，这表明量子增强并非普遍有利。相反，量子模块的有效性高度依赖于特定任务和架构设计，反映了模型规模、参数化策略和时间建模能力之间的固有权衡。', 'title_zh': '基于量子和经典串行模型的城市电信 forecasting 效能基准测试'}
{'arxiv_id': 'arXiv:2508.04476', 'title': 'Metric Learning in an RKHS', 'authors': 'Gokcan Tatli, Yi Chen, Blake Mason, Robert Nowak, Ramya Korlakai Vinayak', 'link': 'https://arxiv.org/abs/2508.04476', 'abstract': 'Metric learning from a set of triplet comparisons in the form of "Do you think item h is more similar to item i or item j?", indicating similarity and differences between items, plays a key role in various applications including image retrieval, recommendation systems, and cognitive psychology. The goal is to learn a metric in the RKHS that reflects the comparisons. Nonlinear metric learning using kernel methods and neural networks have shown great empirical promise. While previous works have addressed certain aspects of this problem, there is little or no theoretical understanding of such methods. The exception is the special (linear) case in which the RKHS is the standard Euclidean space $\\mathbb{R}^d$; there is a comprehensive theory for metric learning in $\\mathbb{R}^d$. This paper develops a general RKHS framework for metric learning and provides novel generalization guarantees and sample complexity bounds. We validate our findings through a set of simulations and experiments on real datasets. Our code is publicly available at this https URL.', 'abstract_zh': '从三元组比较中学习度量：在形式为“您认为项目h与项目i还是项目j更相似？”的比较中学习相似性和差异性度量，在图像检索、推荐系统和认知心理学等诸多应用中扮演着关键角色。目标是在RKHS中学习反映这些比较的度量。使用核方法和神经网络的非线性度量学习显示出巨大的实证潜力。尽管先前的工作已经解决了该问题的一些方面，但对这些方法的理论理解却很少或几乎没有。唯一的例外是RKHS为标准欧几里得空间$\\mathbb{R}^d$的特殊（线性）情况，在$\\mathbb{R}^d$中已有完整的度量学习理论。本文发展了RKHS中度量学习的通用框架，并提供了新的泛化保证和样本复杂度界。我们通过一系列仿真和实际数据集上的实验验证了我们的发现。我们的代码可在下列网址获取：this https URL。', 'title_zh': '核希尔伯特空间中的度量学习'}
{'arxiv_id': 'arXiv:2508.04461', 'title': 'Small transformer architectures for task switching', 'authors': 'Claudius Gros', 'link': 'https://arxiv.org/abs/2508.04461', 'abstract': "The rapid progress seen in terms of large-scale generative AI is largely based on the attention mechanism. It is conversely non-trivial to conceive small-scale applications for which attention-based architectures outperform traditional approaches, such as multi-layer perceptrons or recurrent networks. We examine this problem in the context of 'task switching'. In this framework models work on ongoing token sequences with the current task being determined by stochastically interspersed control tokens. We show that standard transformers cannot solve a basic task switching reference model based on finite domain arithmetics which contains subtasks dedicated to increment / addition / reverse copy / context (IARC). We show that transformers, long short-term memory recurrent networks (LSTM), and plain multi-layer perceptrons (MLPs) achieve similar, but only modest prediction accuracies. We enlarge our comparative study by including an extension of the standard transformer architecture to its non-translational invariant counterpart, the cisformer, and an alternative attention mechanism, extensive attention. A combination of the latter is found to be the only model able to achieve considerable performance levels, of around 95%. Our results indicate that the workings of attention can be understood better, and even improved, when comparing qualitatively different formulations in task-switching settings.", 'abstract_zh': '大规模生成AI快速进步很大程度上依赖于注意机制。但在小型应用中，基于注意机制的架构超越传统方法（如多层感知机或多层递归网络）的情况则不常见。我们在此框架下探讨“任务切换”问题。在这种框架下，模型处理连续的令牌序列，当前任务由随机插入的控制令牌决定。我们展示了标准变压器在基于有限域算术的基本任务切换参考模型中的表现不佳，该模型包含专门针对增量/加法/反向复制/上下文（IARC）的子任务。我们展示了变压器、长短期记忆递归网络（LSTM）和平常的多层感知机（MLPs）在预测准确性上表现相似，但仅有一定的提升。我们通过纳入标准变压器架构的非平移不变版本cisformer和扩展注意力机制（extensive attention）来扩大了比较研究范围。发现这两种技术的结合是唯一能够实现约95%性能水平的模型。我们的结果表明，在任务切换设置中比较不同形式的注意力机制有助于更深入地理解注意力的工作原理，甚至可以对其进行改进。', 'title_zh': '小规模变压器架构用于任务切换'}
{'arxiv_id': 'arXiv:2508.04447', 'title': 'Cloud Model Characteristic Function Auto-Encoder: Integrating Cloud Model Theory with MMD Regularization for Enhanced Generative Modeling', 'authors': 'Biao Hu, Guoyin Wang', 'link': 'https://arxiv.org/abs/2508.04447', 'abstract': 'We introduce Cloud Model Characteristic Function Auto-Encoder (CMCFAE), a novel generative model that integrates the cloud model into the Wasserstein Auto-Encoder (WAE) framework. By leveraging the characteristic functions of the cloud model to regularize the latent space, our approach enables more accurate modeling of complex data distributions. Unlike conventional methods that rely on a standard Gaussian prior and traditional divergence measures, our method employs a cloud model prior, providing a more flexible and realistic representation of the latent space, thus mitigating the homogenization observed in reconstructed samples. We derive the characteristic function of the cloud model and propose a corresponding regularizer within the WAE framework. Extensive quantitative and qualitative evaluations on MNIST, FashionMNIST, CIFAR-10, and CelebA demonstrate that CMCFAE outperforms existing models in terms of reconstruction quality, latent space structuring, and sample diversity. This work not only establishes a novel integration of cloud model theory with MMD-based regularization but also offers a promising new perspective for enhancing autoencoder-based generative models.', 'abstract_zh': '云模型特征函数自动编码器（CMCFAE）：一种将云模型集成到Wasserstein自动编码器框架中的新颖生成模型', 'title_zh': '基于云模型理论与MMD正则化的云模型特征函数自编码器：增强生成 modeling'}
{'arxiv_id': 'arXiv:2508.04442', 'title': 'Automated Generation of Curriculum-Aligned Multiple-Choice Questions for Malaysian Secondary Mathematics Using Generative AI', 'authors': 'Rohaizah Abdul Wahid, Muhamad Said Nizamuddin Nadim, Suliana Sulaiman, Syahmi Akmal Shaharudin, Muhammad Danial Jupikil, Iqqwan Jasman Su Azlan Su', 'link': 'https://arxiv.org/abs/2508.04442', 'abstract': "This paper addresses the critical need for scalable and high-quality educational assessment tools within the Malaysian education system. It highlights the potential of Generative AI (GenAI) while acknowledging the significant challenges of ensuring factual accuracy and curriculum alignment, especially for low-resource languages like Bahasa Melayu. This research introduces and compares four incremental pipelines for generating Form 1 Mathematics multiple-choice questions (MCQs) in Bahasa Melayu using OpenAI's GPT-4o. The methods range from non-grounded prompting (structured and basic) to Retrieval-Augmented Generation (RAG) approaches (one using the LangChain framework, one implemented manually). The system is grounded in official curriculum documents, including teacher-prepared notes and the yearly teaching plan (RPT). A dual-pronged automated evaluation framework is employed to assess the generated questions. Curriculum alignment is measured using Semantic Textual Similarity (STS) against the RPT, while contextual validity is verified through a novel RAG-based Question-Answering (RAG-QA) method. The results demonstrate that RAG-based pipelines significantly outperform non-grounded prompting methods, producing questions with higher curriculum alignment and factual validity. The study further analyzes the trade-offs between the ease of implementation of framework-based RAG and the fine-grained control offered by a manual pipeline. This work presents a validated methodology for generating curriculum-specific educational content in a low-resource language, introduces a symbiotic RAG-QA evaluation technique, and provides actionable insights for the development and deployment of practical EdTech solutions in Malaysia and similar regions.", 'abstract_zh': '本文探讨了马来西亚教育系统中对可扩展且高质量教育评估工具的迫切需求，并强调了生成式人工智能（GenAI）的潜力，同时承认了确保事实准确性和课程对接的重大挑战，特别是在马来语等低资源语言方面。本文介绍了并比较了四种生成马来西亚形式一数学选择题（MCQ）的递增管道，使用了OpenAI的GPT-4o。这些方法从非嵌入式提示（结构化和基础）到检索增强生成（RAG）方法（包括LangChain框架和手动实现的方法）不等。系统基于官方课程文档，包括教师准备的讲义和年度教学计划（RPT）。采用双重自动评估框架来评估生成的问题。通过语义文本相似性（STS）衡量课程对接情况，通过基于RAG的问题-答案方法（RAG-QA）验证情境有效性。结果显示，基于RAG的管道显著优于非嵌入式提示方法，生成的问题在课程对接和事实有效性方面表现更好。本文进一步分析了基于框架的RAG易于实现与手动管道提供的详细控制之间的权衡。本文提出了在低资源语言中生成特定课程教育内容的有效方法，引入了一种共生的RAG-QA评估技术，并提供了有关在马来西亚及其他类似地区开发和部署实际EdTech解决方案的可操作见解。', 'title_zh': 'Malaysian 中文应为“马来西亚的”，因此更准确的翻译标题为：\n\n基于生成式人工智能的马来西亚中学数学课程对齐的多项选择题自动化生成'}
{'arxiv_id': 'arXiv:2508.04390', 'title': 'AIC CTU@FEVER 8: On-premise fact checking through long context RAG', 'authors': 'Herbert Ullrich, Jan Drchal', 'link': 'https://arxiv.org/abs/2508.04390', 'abstract': "In this paper, we present our fact-checking pipeline which has scored first in FEVER 8 shared task. Our fact-checking system is a simple two-step RAG pipeline based on our last year's submission. We show how the pipeline can be redeployed on-premise, achieving state-of-the-art fact-checking performance (in sense of Ev2R test-score), even under the constraint of a single NVidia A10 GPU, 23GB of graphical memory and 60s running time per claim.", 'abstract_zh': '本文介绍了我们在FEVER 8共享任务中荣获第一名的fact-checking流水线。我们的fact-checking系统是基于去年提交内容的一个简单的两步RAG流水线。我们展示了即使在仅使用一个NVIDIA A10 GPU（23GB显存）且每条声明运行时间为60秒的限制条件下，该流水线仍能实现最先进的事实核查性能（以Ev2R测试分数衡量）。', 'title_zh': 'AIC CTU@FEVER 8：基于长期上下文的现场事实核查'}
{'arxiv_id': 'arXiv:2508.04381', 'title': 'ProtoN: Prototype Node Graph Neural Network for Unconstrained Multi-Impression Ear Recognition', 'authors': 'Santhoshkumar Peddi, Sadhvik Bathini, Arun Balasubramanian, Monalisa Sarma, Debasis Samanta', 'link': 'https://arxiv.org/abs/2508.04381', 'abstract': 'Ear biometrics offer a stable and contactless modality for identity recognition, yet their effectiveness remains limited by the scarcity of annotated data and significant intra-class variability. Existing methods typically extract identity features from individual impressions in isolation, restricting their ability to capture consistent and discriminative representations. To overcome these limitations, a few-shot learning framework, ProtoN, is proposed to jointly process multiple impressions of an identity using a graph-based approach. Each impression is represented as a node in a class-specific graph, alongside a learnable prototype node that encodes identity-level information. This graph is processed by a Prototype Graph Neural Network (PGNN) layer, specifically designed to refine both impression and prototype representations through a dual-path message-passing mechanism. To further enhance discriminative power, the PGNN incorporates a cross-graph prototype alignment strategy that improves class separability by enforcing intra-class compactness while maintaining inter-class distinction. Additionally, a hybrid loss function is employed to balance episodic and global classification objectives, thereby improving the overall structure of the embedding space. Extensive experiments on five benchmark ear datasets demonstrate that ProtoN achieves state-of-the-art performance, with Rank-1 identification accuracy of up to 99.60% and an Equal Error Rate (EER) as low as 0.025, showing the effectiveness for few-shot ear recognition under limited data conditions.', 'abstract_zh': '基于图的Few-Shot学习框架ProtoN在有限标注数据下的耳纹识别中表现出稳定且非接触的特点，但仍受限于标注数据稀缺性和类内显著变异性。现有方法通常单独处理每个样本特征，限制了其捕获一致性和判别性表示的能力。为克服这些局限，提出了一种基于图的Few-Shot学习框架ProtoN，利用类特定图联合处理单一身份的多个样本。每个样本表示为图中的一个节点，并且伴随一个可学习的原型节点，编码身份级信息。该图通过专为双重路径消息传递机制设计的Prototype Graph Neural Network (PGNN) 层进行处理，以精炼样本和原型表示。为了进一步增强判别力，PGNN引入了一种跨图原型对齐策略，通过强化类内紧凑性和维护类间区分性来提高类间的可分性。此外，采用一种混合损失函数来平衡局部和全局分类目标，从而改进嵌入空间的整体结构。在五个基准耳纹数据集上的广泛实验表明，ProtoN达到了最先进的性能，Rank-1识别准确率达到99.60%，等错误率（EER）低至0.025，展示了其在有限数据条件下进行少样本耳纹识别的有效性。', 'title_zh': 'ProtoN：原型节点图神经网络在无约束多印象耳识别中的应用'}
{'arxiv_id': 'arXiv:2508.04337', 'title': 'Modelling and Classifying the Components of a Literature Review', 'authors': 'Francisco Bolaños, Angelo Salatino, Francesco Osborne, Enrico Motta', 'link': 'https://arxiv.org/abs/2508.04337', 'abstract': 'Previous work has demonstrated that AI methods for analysing scientific literature benefit significantly from annotating sentences in papers according to their rhetorical roles, such as research gaps, results, limitations, extensions of existing methodologies, and others. Such representations also have the potential to support the development of a new generation of systems capable of producing high-quality literature reviews. However, achieving this goal requires the definition of a relevant annotation schema and effective strategies for large-scale annotation of the literature. This paper addresses these challenges by 1) introducing a novel annotation schema specifically designed to support literature review generation and 2) conducting a comprehensive evaluation of a wide range of state-of-the-art large language models (LLMs) in classifying rhetorical roles according to this schema. To this end, we also present Sci-Sentence, a novel multidisciplinary benchmark comprising 700 sentences manually annotated by domain experts and 2,240 sentences automatically labelled using LLMs. We evaluate 37 LLMs on this benchmark, spanning diverse model families and sizes, using both zero-shot learning and fine-tuning approaches. The experiments yield several novel insights that advance the state of the art in this challenging domain. First, the current generation of LLMs performs remarkably well on this task when fine-tuned on high-quality data, achieving performance levels above 96\\% F1. Second, while large proprietary models like GPT-4o achieve the best results, some lightweight open-source alternatives also demonstrate excellent performance. Finally, enriching the training data with semi-synthetic examples generated by LLMs proves beneficial, enabling small encoders to achieve robust results and significantly enhancing the performance of several open decoder models.', 'abstract_zh': '先前的工作已经证明，通过根据修辞角色标注论文中的句子（如研究空白、结果、局限性、现有方法的扩展等），可以显著提升分析科学文献的AI方法的效果。这种表示方式还有潜力支持开发新一代能生成高质量文献综述的系统。然而，实现这一目标需要定义相关的标注框架并开发大规模文献标注的有效策略。本文通过1) 引入一种新型标注框架，专门支持文献综述生成；2) 对多种最新的大型语言模型（LLMs）在根据此框架分类修辞角色方面的性能进行全面评估，来应对这些挑战。为此，我们还提出了Sci-Sentence这一多学科基准数据集，包含700个由领域专家人工标注的句子和2,240个使用LLMs自动标记的句子。我们使用零样本学习和微调方法评估了37种不同模型家族和规模的LLMs在该基准数据上的性能。实验结果提供了多项推动该领域技术进步的新见解。首先，当在高质量数据上进行微调时，当前一代的LLMs在该任务上的表现非常出色，F1分数超过96%。其次，虽然如GPT-4o等大型专有模型性能最佳，但一些轻量级开源替代方案也表现出色。最后，通过使用由LLMs生成的半合成训练数据来丰富训练数据，有助于小型编码器获得稳健的结果，并显著提高多种开源解码器模型的性能。', 'title_zh': '建模与分类文献综述的组件'}
{'arxiv_id': 'arXiv:2508.04293', 'title': 'Comparative Analysis of Novel NIRMAL Optimizer Against Adam and SGD with Momentum', 'authors': 'Nirmal Gaud, Surej Mouli, Preeti Katiyar, Vaduguru Venkata Ramya', 'link': 'https://arxiv.org/abs/2508.04293', 'abstract': "This study proposes NIRMAL (Novel Integrated Robust Multi-Adaptation Learning), a novel optimization algorithm that combines multiple strategies inspired by the movements of the chess piece. These strategies include gradient descent, momentum, stochastic perturbations, adaptive learning rates, and non-linear transformations. We carefully evaluated NIRMAL against two widely used and successful optimizers, Adam and SGD with Momentum, on four benchmark image classification datasets: MNIST, FashionMNIST, CIFAR-10, and CIFAR-100. The custom convolutional neural network (CNN) architecture is applied on each dataset. The experimental results show that NIRMAL achieves competitive performance, particularly on the more challenging CIFAR-100 dataset, where it achieved a test accuracy of 45.32\\%and a weighted F1-score of 0.4328. This performance surpasses Adam (41.79\\% accuracy, 0.3964 F1-score) and closely matches SGD with Momentum (46.97\\% accuracy, 0.4531 F1-score). Also, NIRMAL exhibits robust convergence and strong generalization capabilities, especially on complex datasets, as evidenced by stable training results in loss and accuracy curves. These findings underscore NIRMAL's significant ability as a versatile and effective optimizer for various deep learning tasks.", 'abstract_zh': '本研究提出了一种新型集成鲁棒多适应学习算法NIRMAL，该算法结合了受国际象棋棋子移动启发的多种策略，包括梯度下降、动量、随机扰动、自适应学习率和非线性变换。我们在四个基准图像分类数据集（MNIST、FashionMNIST、CIFAR-10和CIFAR-100）上将NIRMAL与广泛应用且成功的优化器Adam和带有动量的SGD进行了仔细评估，并在每个数据集上应用了自定义卷积神经网络（CNN）架构。实验结果显示，NIRMAL在性能上具有竞争力，特别是在更具挑战性的CIFAR-100数据集上，测试准确率为45.32%，加权F1分为0.4328。这一性能超过了Adam（准确率41.79%，F1分0.3964）并接近与SGD（准确率46.97%，F1分0.4531）结合的动量优化器。此外，NIRMAL表现出色的收敛性和强大的泛化能力，尤其是在复杂数据集上，由损失和准确率曲线的稳定训练结果得以证实。这些发现突显了NIRMAL作为各种深度学习任务中的多功能和有效优化器的重要能力。', 'title_zh': '新型Nedirmal优化器与Adam和带有动量的SGD的的比较分析'}
{'arxiv_id': 'arXiv:2508.04288', 'title': 'Challenges in Applying Variational Quantum Algorithms to Dynamic Satellite Network Routing', 'authors': 'Phuc Hao Do, Tran Duc Le', 'link': 'https://arxiv.org/abs/2508.04288', 'abstract': 'Applying near-term variational quantum algorithms to the problem of dynamic satellite network routing represents a promising direction for quantum computing. In this work, we provide a critical evaluation of two major approaches: static quantum optimizers such as the Variational Quantum Eigensolver (VQE) and the Quantum Approximate Optimization Algorithm (QAOA) for offline route computation, and Quantum Reinforcement Learning (QRL) methods for online decision-making. Using ideal, noise-free simulations, we find that these algorithms face significant challenges. Specifically, static optimizers are unable to solve even a classically easy 4-node shortest path problem due to the complexity of the optimization landscape. Likewise, a basic QRL agent based on policy gradient methods fails to learn a useful routing strategy in a dynamic 8-node environment and performs no better than random actions. These negative findings highlight key obstacles that must be addressed before quantum algorithms can offer real advantages in communication networks. We discuss the underlying causes of these limitations, including barren plateaus and learning instability, and suggest future research directions to overcome them.', 'abstract_zh': '将近期变量子量子算法应用于动态卫星网络路由问题的研究代表了量子计算的一个有 Hope的方向。本文对两种主要方法进行了批判性评估：用于离线路由计算的静态量子优化器（如变量子特征值求解器VQE和量子近似优化算法QAOA），以及用于在线决策的量子增强学习方法QRL。使用理想噪声-free模拟，我们发现这些算法面临重大挑战。具体来说，静态优化器无法解决一个经典的4节点最短路径问题，因为优化景观的复杂性。同样，基于策略梯度方法的基本QRL代理在动态8节点环境中学不会有效的路由策略，并且与随机动作表现相当。这些负面发现突显了在量子算法能够在通信网络中提供实际优势之前必须解决的关键障碍。我们讨论了这些限制的根本原因，包括荒地 plateau和学习不稳定性，并建议未来的研究方向以克服这些问题。', 'title_zh': '变分量子算法在动态卫星网络路由中的挑战'}
{'arxiv_id': 'arXiv:2508.04269', 'title': 'A Visual Tool for Interactive Model Explanation using Sensitivity Analysis', 'authors': 'Manuela Schuler', 'link': 'https://arxiv.org/abs/2508.04269', 'abstract': 'We present SAInT, a Python-based tool for visually exploring and understanding the behavior of Machine Learning (ML) models through integrated local and global sensitivity analysis. Our system supports Human-in-the-Loop (HITL) workflows by enabling users - both AI researchers and domain experts - to configure, train, evaluate, and explain models through an interactive graphical interface without programming. The tool automates model training and selection, provides global feature attribution using variance-based sensitivity analysis, and offers per-instance explanation via LIME and SHAP. We demonstrate the system on a classification task predicting survival on the Titanic dataset and show how sensitivity information can guide feature selection and data refinement.', 'abstract_zh': '基于Python的SAInT工具：通过集成局部和全局敏感性分析视觉探索和理解机器学习模型的行为', 'title_zh': '基于敏感性分析的交互模型解释可视化工具'}
{'arxiv_id': 'arXiv:2508.04265', 'title': 'SelectiveShield: Lightweight Hybrid Defense Against Gradient Leakage in Federated Learning', 'authors': 'Borui Li, Li Yan, Jianmin Liu', 'link': 'https://arxiv.org/abs/2508.04265', 'abstract': 'Federated Learning (FL) enables collaborative model training on decentralized data but remains vulnerable to gradient leakage attacks that can reconstruct sensitive user information. Existing defense mechanisms, such as differential privacy (DP) and homomorphic encryption (HE), often introduce a trade-off between privacy, model utility, and system overhead, a challenge that is exacerbated in heterogeneous environments with non-IID data and varying client capabilities. To address these limitations, we propose SelectiveShield, a lightweight hybrid defense framework that adaptively integrates selective homomorphic encryption and differential privacy. SelectiveShield leverages Fisher information to quantify parameter sensitivity, allowing clients to identify critical parameters locally. Through a collaborative negotiation protocol, clients agree on a shared set of the most sensitive parameters for protection via homomorphic encryption. Parameters that are uniquely important to individual clients are retained locally, fostering personalization, while non-critical parameters are protected with adaptive differential privacy noise. Extensive experiments demonstrate that SelectiveShield maintains strong model utility while significantly mitigating gradient leakage risks, offering a practical and scalable defense mechanism for real-world federated learning deployments.', 'abstract_zh': '联邦学习(Federated Learning)能够在分散的数据上实现协作模型训练，但仍然容易受到梯度泄露攻击的影响，这种攻击可以重建敏感用户信息。现有的防御机制，如差分隐私(Differential Privacy, DP)和同态加密(Homomorphic Encryption, HE)，通常会在隐私、模型实用性和系统开销之间引入权衡，这一挑战在非同态数据和客户端能力各异的异质环境中被进一步放大。为了解决这些局限性，我们提出了一种名为SelectiveShield的轻量级混合防御框架，该框架能够适应性地集成选择性的同态加密和差分隐私。SelectiveShield利用Fisher信息来量化参数敏感性，使客户端能够局部识别关键参数。通过协作协商协议，客户端同意保护一组最敏感参数，这些参数通过同态加密进行保护。对客户端而言独一无二的重要参数保留在本地，以促进个性化，而非关键参数则通过自适应差分隐私噪声进行保护。广泛的实验表明，SelectiveShield在保持强模型实用性的同时，显著减轻了梯度泄露风险，提供了一种适用于实际联邦学习部署的实用且可扩展的防御机制。', 'title_zh': 'SelectiveShield：面向联邦学习中梯度泄漏的轻量级混合防御方法'}
{'arxiv_id': 'arXiv:2508.04243', 'title': 'Automated ultrasound doppler angle estimation using deep learning', 'authors': 'Nilesh Patil, Ajay Anand', 'link': 'https://arxiv.org/abs/2508.04243', 'abstract': 'Angle estimation is an important step in the Doppler ultrasound clinical workflow to measure blood velocity. It is widely recognized that incorrect angle estimation is a leading cause of error in Doppler-based blood velocity measurements. In this paper, we propose a deep learning-based approach for automated Doppler angle estimation. The approach was developed using 2100 human carotid ultrasound images including image augmentation. Five pre-trained models were used to extract images features, and these features were passed to a custom shallow network for Doppler angle estimation. Independently, measurements were obtained by a human observer reviewing the images for comparison. The mean absolute error (MAE) between the automated and manual angle estimates ranged from 3.9° to 9.4° for the models evaluated. Furthermore, the MAE for the best performing model was less than the acceptable clinical Doppler angle error threshold thus avoiding misclassification of normal velocity values as a stenosis. The results demonstrate potential for applying a deep-learning based technique for automated ultrasound Doppler angle estimation. Such a technique could potentially be implemented within the imaging software on commercial ultrasound scanners.', 'abstract_zh': '基于深度学习的自动多普勒角度估计方法研究', 'title_zh': '使用深度学习的自动超声多普勒角度估计'}
{'arxiv_id': 'arXiv:2508.04225', 'title': 'Symmetric Behavior Regularization via Taylor Expansion of Symmetry', 'authors': 'Lingwei Zhu, Zheng Chen, Han Wang, Yukie Nagai', 'link': 'https://arxiv.org/abs/2508.04225', 'abstract': 'This paper introduces symmetric divergences to behavior regularization policy optimization (BRPO) to establish a novel offline RL framework. Existing methods focus on asymmetric divergences such as KL to obtain analytic regularized policies and a practical minimization objective. We show that symmetric divergences do not permit an analytic policy as regularization and can incur numerical issues as loss. We tackle these challenges by the Taylor series of $f$-divergence. Specifically, we prove that an analytic policy can be obtained with a finite series. For loss, we observe that symmetric divergences can be decomposed into an asymmetry and a conditional symmetry term, Taylor-expanding the latter alleviates numerical issues. Summing together, we propose Symmetric $f$ Actor-Critic (S$f$-AC), the first practical BRPO algorithm with symmetric divergences. Experimental results on distribution approximation and MuJoCo verify that S$f$-AC performs competitively.', 'abstract_zh': '这篇论文将对称分散度引入行为正则化策略优化（BRPO）中，建立一个新的 Offline RL 框架。', 'title_zh': '通过对称性的泰勒展开实现对称行为正则化'}
{'arxiv_id': 'arXiv:2508.04213', 'title': 'A Hybrid AI Methodology for Generating Ontologies of Research Topics from Scientific Paper Corpora', 'authors': 'Alessia Pisu, Livio Pompianu, Francesco Osborne, Diego Reforgiato Recupero, Daniele Riboni, Angelo Salatino', 'link': 'https://arxiv.org/abs/2508.04213', 'abstract': 'Taxonomies and ontologies of research topics (e.g., MeSH, UMLS, CSO, NLM) play a central role in providing the primary framework through which intelligent systems can explore and interpret the literature. However, these resources have traditionally been manually curated, a process that is time-consuming, prone to obsolescence, and limited in granularity. This paper presents Sci-OG, a semi-auto\\-mated methodology for generating research topic ontologies, employing a multi-step approach: 1) Topic Discovery, extracting potential topics from research papers; 2) Relationship Classification, determining semantic relationships between topic pairs; and 3) Ontology Construction, refining and organizing topics into a structured ontology. The relationship classification component, which constitutes the core of the system, integrates an encoder-based language model with features describing topic occurrence in the scientific literature. We evaluate this approach against a range of alternative solutions using a dataset of 21,649 manually annotated semantic triples. Our method achieves the highest F1 score (0.951), surpassing various competing approaches, including a fine-tuned SciBERT model and several LLM baselines, such as the fine-tuned GPT4-mini. Our work is corroborated by a use case which illustrates the practical application of our system to extend the CSO ontology in the area of cybersecurity. The presented solution is designed to improve the accessibility, organization, and analysis of scientific knowledge, thereby supporting advancements in AI-enabled literature management and research exploration.', 'abstract_zh': '研究主题的分类学和本体（例如MeSH、UMLS、CSO、NLM）在为智能系统提供探索和解释文献的主要框架中扮演着中心角色。然而，这些资源通常通过手动编目，这一过程耗时、容易过时且在细致程度上有限。本文介绍了Sci-OG，一种用于生成研究主题本体的半自动化方法，采用多步骤方法：1）主题发现，从研究论文中提取潜在主题；2）关系分类，确定主题对之间的语义关系；3）本体构建，对主题进行细化和组织，形成结构化的本体。构成系统核心的关系分类组件结合了一种基于编码器的语言模型和描述主题在科学文献中出现特征。我们使用包含21,649个手动标注语义三元组的数据集对该方法进行了评估，该方法达到了最高的F1分数（0.951），超越了包括优化后的SciBERT模型和优化后的GPT4-mini在内的多种竞争方法。我们的工作通过一个用例得到了验证，该用例展示了我们的系统在网络安全领域的实际应用，以扩展CSO本体。所提出的解决方案旨在提高科学知识的可访问性、组织性和分析性，从而支持基于AI的文献管理和研究探索的进步。', 'title_zh': '一种生成科研主题本体的混合AI方法论'}
{'arxiv_id': 'arXiv:2508.04201', 'title': 'ViFP: A Framework for Visual False Positive Detection to Enhance Reasoning Reliability in VLMs', 'authors': 'Ben Zhang, LuLu Yu, Lei Gao, Jing Liu, QuanJiang Guo, Hui Gao', 'link': 'https://arxiv.org/abs/2508.04201', 'abstract': 'In visual-language model (VLM) reasoning, false positive(FP) reasoning occurs when a model generates a correct answer but follows an incorrect reasoning path. Existing methods based on specific multi-step reasoning datasets and reinforcement learning strategies, leading to high training costs and limited generalization. In this work, we propose ViFP, a general framework for enhancing visual reasoning reliability. It improves both answer accuracy and reasoning soundness by detecting FPs. ViFP tackles the limitations of dataset dependency and poor generalization by constructing sub-question templates grounded in the core dimensions of visual reasoning, such as object localization, characteristic description, and object discovery. ViFP then builds effective reasoning paths via multi-turn QA to improve reasoning accuracy. Meanwhile, ViFP dynamically analyzes the consistency of reasoning path to identify potential FPs, and introduces a targeted chain-of-thought (CoT) mechanism that adaptively guides both FP and non-FP samples. Thereby reducing logical errors in the reasoning path while preserving accuracy. Finally, we introduce a reliability evaluation metric-VoC, which integrates answer accuracy and the FP rate, providing a quantitative tool to assess whether a VLM not only answers correctly, but also reasons reliably. Our experiments on closed-source VLMs show that ViFP consistently improves performance across three datasets: A-OKVQA, OKVQA, and FVQA. On A-OKVQA, ViFP improves accuracy by up to 5.4%, surpassing the previous state-of-the-art by 4.3%, and significantly reduces the number of FPs, validating its benefits in enhancing reasoning reliability.', 'abstract_zh': '增强视觉推理可靠性的ViFP框架', 'title_zh': 'ViFP: 一种视觉假阳性检测框架，以提高VLMs推理可靠性'}
{'arxiv_id': 'arXiv:2508.04195', 'title': 'NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations', 'authors': 'Huan Liao, Qinke Ni, Yuancheng Wang, Yiheng Lu, Haoyue Zhan, Pengyuan Xie, Qiang Zhang, Zhizheng Wu', 'link': 'https://arxiv.org/abs/2508.04195', 'abstract': 'Paralinguistic vocalizations-including non-verbal sounds like laughter and breathing, as well as lexicalized interjections such as "uhm" and "oh"-are integral to natural spoken communication. Despite their importance in conveying affect, intent, and interactional cues, such cues remain largely overlooked in conventional automatic speech recognition (ASR) and text-to-speech (TTS) systems. We present NVSpeech, an integrated and scalable pipeline that bridges the recognition and synthesis of paralinguistic vocalizations, encompassing dataset construction, ASR modeling, and controllable TTS. (1) We introduce a manually annotated dataset of 48,430 human-spoken utterances with 18 word-level paralinguistic categories. (2) We develop the paralinguistic-aware ASR model, which treats paralinguistic cues as inline decodable tokens (e.g., "You\'re so funny [Laughter]"), enabling joint lexical and non-verbal transcription. This model is then used to automatically annotate a large corpus, the first large-scale Chinese dataset of 174,179 utterances (573 hours) with word-level alignment and paralingustic cues. (3) We finetune zero-shot TTS models on both human- and auto-labeled data to enable explicit control over paralinguistic vocalizations, allowing context-aware insertion at arbitrary token positions for human-like speech synthesis. By unifying the recognition and generation of paralinguistic vocalizations, NVSpeech offers the first open, large-scale, word-level annotated pipeline for expressive speech modeling in Mandarin, integrating recognition and synthesis in a scalable and controllable manner. Dataset and audio demos are available at this https URL.', 'abstract_zh': '平行语 vocalizations——包括笑声和呼吸等非 verbal 声音，以及“uhm”和“oh”等词汇化插语——是自然口语交流的重要组成部分。尽管这些声音在传达情感、意图和互动线索方面至关重要，但在传统的自动语音识别（ASR）和文本到语音（TTS）系统中，这些线索仍然被很大程度上忽视。我们提出 NVSpeech，这是一个集成和可扩展的框架，用于弥合平行语声音的识别和合成之间的差距，涵盖数据集构建、ASR 模型和可控 TTS。该框架包括：(1) 一个包含 48,430 个手动注释的人声片段，具有 18 个词级平行语类别；(2) 开发了平行语意识的 ASR 模型，将平行语线索视为可嵌入的解码令牌（例如，“你真有趣 [笑声]”），实现联合词汇和非 verbal 转录；该模型随后被用于自动注释大量语料库，即包含词级对齐和平行语线索的首个大规模中文数据集，含 174,179 个片段（573小时）；(3) 在人工和自动标注数据上微调零-shot TTS 模型，以实现对平行语声音的显式控制，允许在任意令牌位置进行上下文感知的插入选入，实现类人语音合成。通过统一平行语声音的识别和生成，NVSpeech 提供了首个面向表达性 Mandarin 语音建模的开放、大规模、词级注释框架，集成识别和合成于一体，具可扩展性和可控性。数据集和音频示例可在以下网址获得。', 'title_zh': 'NVSpeech: 一种集成和可扩展的人类-like 语音建模管道，包括副语言语音化表达'}
{'arxiv_id': 'arXiv:2508.04174', 'title': 'Quasi-Clique Discovery via Energy Diffusion', 'authors': 'Yu Zhang, Yilong Luo, Mingyuan Ma, Yao Chen, Enqiang Zhu, Jin Xu, Chanjuan Liu', 'link': 'https://arxiv.org/abs/2508.04174', 'abstract': 'Discovering quasi-cliques -- subgraphs with edge density no less than a given threshold -- is a fundamental task in graph mining, with broad applications in social networks, bioinformatics, and e-commerce. Existing heuristics often rely on greedy rules, similarity measures, or metaheuristic search, but struggle to maintain both efficiency and solution consistency across diverse graphs. This paper introduces EDQC, a novel quasi-clique discovery algorithm inspired by energy diffusion. Instead of explicitly enumerating candidate subgraphs, EDQC performs stochastic energy diffusion from source vertices, naturally concentrating energy within structurally cohesive regions. The approach enables efficient dense subgraph discovery without exhaustive search or dataset-specific tuning. Experimental results on 30 real-world datasets demonstrate that EDQC consistently discovers larger quasi-cliques than state-of-the-art baselines on the majority of datasets, while also yielding lower variance in solution quality. To the best of our knowledge, EDQC is the first method to incorporate energy diffusion into quasi-clique discovery.', 'abstract_zh': '发现准团簇——基于给定边密度阈值的子图发现是图挖掘中的基础任务，广泛应用于社交网络、生物信息学和电子商务。现有的启发式方法通常依赖贪婪规则、相似性度量或元启发式搜索，但在不同类型的图中难以同时保证高效性和解的一致性。本文介绍了一种受能量扩散启发的新型准团簇发现算法EDQC。该算法不显式枚举候选子图，而是从源顶点进行随机能量扩散，自然地将能量集中在结构上紧密的区域。该方法能够高效发现密集子图，而无需 exhaustive 搜索或针对特定数据集进行调优。在30个真实数据集上的实验结果表明，EDQC 在大多数数据集上能够一致地发现比当前最先进的基线更大的准团簇，同时在解的质量上也具有更低的方差。据我们所知，EDQC 是首个将能量扩散应用于准团簇发现的方法。', 'title_zh': '通过能量扩散的准团簇发现'}
{'arxiv_id': 'arXiv:2508.04100', 'title': 'SenseCrypt: Sensitivity-guided Selective Homomorphic Encryption for Joint Federated Learning in Cross-Device Scenarios', 'authors': 'Borui Li, Li Yan, Junhao Han, Jianmin Liu, Lei Yu', 'link': 'https://arxiv.org/abs/2508.04100', 'abstract': "Homomorphic Encryption (HE) prevails in securing Federated Learning (FL), but suffers from high overhead and adaptation cost. Selective HE methods, which partially encrypt model parameters by a global mask, are expected to protect privacy with reduced overhead and easy adaptation. However, in cross-device scenarios with heterogeneous data and system capabilities, traditional Selective HE methods deteriorate client straggling, and suffer from degraded HE overhead reduction performance. Accordingly, we propose SenseCrypt, a Sensitivity-guided selective Homomorphic EnCryption framework, to adaptively balance security and HE overhead per cross-device FL client. Given the observation that model parameter sensitivity is effective for measuring clients' data distribution similarity, we first design a privacy-preserving method to respectively cluster the clients with similar data distributions. Then, we develop a scoring mechanism to deduce the straggler-free ratio of model parameters that can be encrypted by each client per cluster. Finally, for each client, we formulate and solve a multi-objective model parameter selection optimization problem, which minimizes HE overhead while maximizing model security without causing straggling. Experiments demonstrate that SenseCrypt ensures security against the state-of-the-art inversion attacks, while achieving normal model accuracy as on IID data, and reducing training time by 58.4%-88.7% as compared to traditional HE methods.", 'abstract_zh': '基于敏感性指导的选择性同态加密框架SenseCrypt：适配跨设备联邦学习中的安全与计算开销', 'title_zh': 'SenseCrypt：面向跨设备场景联合联邦学习的敏感性引导选择性同态加密'}
{'arxiv_id': 'arXiv:2508.04064', 'title': 'FLAT: Latent-Driven Arbitrary-Target Backdoor Attacks in Federated Learning', 'authors': 'Tuan Nguyen, Khoa D Doan, Kok-Seng Wong', 'link': 'https://arxiv.org/abs/2508.04064', 'abstract': 'Federated learning (FL) is vulnerable to backdoor attacks, yet most existing methods are limited by fixed-pattern or single-target triggers, making them inflexible and easier to detect. We propose FLAT (FL Arbitrary-Target Attack), a novel backdoor attack that leverages a latent-driven conditional autoencoder to generate diverse, target-specific triggers as needed. By introducing a latent code, FLAT enables the creation of visually adaptive and highly variable triggers, allowing attackers to select arbitrary targets without retraining and to evade conventional detection mechanisms. Our approach unifies attack success, stealth, and diversity within a single framework, introducing a new level of flexibility and sophistication to backdoor attacks in FL. Extensive experiments show that FLAT achieves high attack success and remains robust against advanced FL defenses. These results highlight the urgent need for new defense strategies to address latent-driven, multi-target backdoor threats in federated settings.', 'abstract_zh': 'FLAT：面向联邦学习的任意目标后门攻击', 'title_zh': 'FLAT: 潜在驱动的联邦学习中任意目标后门攻击'}
{'arxiv_id': 'arXiv:2508.04036', 'title': 'CORE-ReID V2: Advancing the Domain Adaptation for Object Re-Identification with Optimized Training and Ensemble Fusion', 'authors': 'Trinh Quoc Nguyen, Oky Dicky Ardiansyah Prima, Syahid Al Irfan, Hindriyanto Dwi Purnomo, Radius Tanone', 'link': 'https://arxiv.org/abs/2508.04036', 'abstract': 'This study presents CORE-ReID V2, an enhanced framework building upon CORE-ReID. The new framework extends its predecessor by addressing Unsupervised Domain Adaptation (UDA) challenges in Person ReID and Vehicle ReID, with further applicability to Object ReID. During pre-training, CycleGAN is employed to synthesize diverse data, bridging image characteristic gaps across different domains. In the fine-tuning, an advanced ensemble fusion mechanism, consisting of the Efficient Channel Attention Block (ECAB) and the Simplified Efficient Channel Attention Block (SECAB), enhances both local and global feature representations while reducing ambiguity in pseudo-labels for target samples. Experimental results on widely used UDA Person ReID and Vehicle ReID datasets demonstrate that the proposed framework outperforms state-of-the-art methods, achieving top performance in Mean Average Precision (mAP) and Rank-k Accuracy (Top-1, Top-5, Top-10). Moreover, the framework supports lightweight backbones such as ResNet18 and ResNet34, ensuring both scalability and efficiency. Our work not only pushes the boundaries of UDA-based Object ReID but also provides a solid foundation for further research and advancements in this domain. Our codes and models are available at this https URL.', 'abstract_zh': '本研究提出了CORE-ReID V2，这是一种基于CORE-ReID增强的框架。该新框架通过解决Person ReID和Vehicle ReID中的无监督域适应（UDA）挑战，并进一步适用于Object ReID，扩展了其前一个版本。在预训练过程中，使用CycleGAN生成多样化数据，以跨越不同域之间的图像特征差距。在微调过程中，采用高效的通道注意模块（ECAB）和简化高效通道注意模块（SECAB）组成的先进集成融合机制，同时增强局部和全局特征表示，减少目标样本伪标签的模糊性。在广泛使用的UDA Person ReID和Vehicle ReID数据集上的实验结果表明，所提出框架优于现有方法，在Mean Average Precision（mAP）和Rank-k Accuracy（Top-1, Top-5, Top-10）上表现出最佳性能。此外，该框架支持轻量级骨干网络，如ResNet18和ResNet34，确保了其可扩展性和效率。我们的工作不仅推动了UDA基础上的Object ReID边界，还为该领域的进一步研究和进步奠定了坚实基础。我们的代码和模型可从以下网址获取。', 'title_zh': 'CORE-ReID V2: 提升基于优化训练和集成融合的目标重识别领域适应性'}
{'arxiv_id': 'arXiv:2508.04035', 'title': 'A Comparative Survey of PyTorch vs TensorFlow for Deep Learning: Usability, Performance, and Deployment Trade-offs', 'authors': 'Zakariya Ba Alawi', 'link': 'https://arxiv.org/abs/2508.04035', 'abstract': "This paper presents a comprehensive comparative survey of TensorFlow and PyTorch, the two leading deep learning frameworks, focusing on their usability, performance, and deployment trade-offs. We review each framework's programming paradigm and developer experience, contrasting TensorFlow's graph-based (now optionally eager) approach with PyTorch's dynamic, Pythonic style. We then compare model training speeds and inference performance across multiple tasks and data regimes, drawing on recent benchmarks and studies. Deployment flexibility is examined in depth - from TensorFlow's mature ecosystem (TensorFlow Lite for mobile/embedded, TensorFlow Serving, and JavaScript support) to PyTorch's newer production tools (TorchScript compilation, ONNX export, and TorchServe). We also survey ecosystem and community support, including library integrations, industry adoption, and research trends (e.g., PyTorch's dominance in recent research publications versus TensorFlow's broader tooling in enterprise). Applications in computer vision, natural language processing, and other domains are discussed to illustrate how each framework is used in practice. Finally, we outline future directions and open challenges in deep learning framework design, such as unifying eager and graph execution, improving cross-framework interoperability, and integrating compiler optimizations (XLA, JIT) for improved speed. Our findings indicate that while both frameworks are highly capable for state-of-the-art deep learning, they exhibit distinct trade-offs: PyTorch offers simplicity and flexibility favored in research, whereas TensorFlow provides a fuller production-ready ecosystem - understanding these trade-offs is key for practitioners selecting the appropriate tool. We include charts, code snippets, and more than 20 references to academic papers and official documentation to support this comparative analysis", 'abstract_zh': 'TensorFlow与PyTorch两大深度学习框架的综合比较研究：重点在于易用性、性能和部署权衡', 'title_zh': 'PyTorch与TensorFlow在深度学习中的比较研究：易用性、性能及部署权衡'}
{'arxiv_id': 'arXiv:2508.04024', 'title': 'Identity Theft in AI Conference Peer Review', 'authors': 'Nihar B. Shah, Melisa Bok, Xukun Liu, Andrew McCallum', 'link': 'https://arxiv.org/abs/2508.04024', 'abstract': 'We discuss newly uncovered cases of identity theft in the scientific peer-review process within artificial intelligence (AI) research, with broader implications for other academic procedures. We detail how dishonest researchers exploit the peer-review system by creating fraudulent reviewer profiles to manipulate paper evaluations, leveraging weaknesses in reviewer recruitment workflows and identity verification processes. The findings highlight the critical need for stronger safeguards against identity theft in peer review and academia at large, and to this end, we also propose mitigating strategies.', 'abstract_zh': '我们在人工智能研究中发现新的身份盗窃案例：对科学同行评审过程的影响及相关学术程序的更广泛影响', 'title_zh': 'AI会议同行评审中的身份盗用'}
{'arxiv_id': 'arXiv:2508.04010', 'title': 'HarmonyGuard: Toward Safety and Utility in Web Agents via Adaptive Policy Enhancement and Dual-Objective Optimization', 'authors': 'Yurun Chen, Xavier Hu, Yuhan Liu, Keting Yin, Juncheng Li, Zhuosheng Zhang, Shengyu Zhang', 'link': 'https://arxiv.org/abs/2508.04010', 'abstract': 'Large language models enable agents to autonomously perform tasks in open web environments. However, as hidden threats within the web evolve, web agents face the challenge of balancing task performance with emerging risks during long-sequence operations. Although this challenge is critical, current research remains limited to single-objective optimization or single-turn scenarios, lacking the capability for collaborative optimization of both safety and utility in web environments. To address this gap, we propose HarmonyGuard, a multi-agent collaborative framework that leverages policy enhancement and objective optimization to jointly improve both utility and safety. HarmonyGuard features a multi-agent architecture characterized by two fundamental capabilities: (1) Adaptive Policy Enhancement: We introduce the Policy Agent within HarmonyGuard, which automatically extracts and maintains structured security policies from unstructured external documents, while continuously updating policies in response to evolving threats. (2) Dual-Objective Optimization: Based on the dual objectives of safety and utility, the Utility Agent integrated within HarmonyGuard performs the Markovian real-time reasoning to evaluate the objectives and utilizes metacognitive capabilities for their optimization. Extensive evaluations on multiple benchmarks show that HarmonyGuard improves policy compliance by up to 38% and task completion by up to 20% over existing baselines, while achieving over 90% policy compliance across all tasks. Our project is available here: this https URL.', 'abstract_zh': 'harmonyguard：多agent协作框架以提升网络环境中的安全与效用', 'title_zh': 'HarmonyGuard: 向往Web代理的安全性和实用性通过自适应策略增强和双目标优化'}
{'arxiv_id': 'arXiv:2508.03989', 'title': 'Dynamic User-controllable Privacy-preserving Few-shot Sensing Framework', 'authors': 'Ajesh Koyatan Chathoth, Shuhao Yu, Stephen Lee', 'link': 'https://arxiv.org/abs/2508.03989', 'abstract': 'User-controllable privacy is important in modern sensing systems, as privacy preferences can vary significantly from person to person and may evolve over time. This is especially relevant in devices equipped with Inertial Measurement Unit (IMU) sensors, such as smartphones and wearables, which continuously collect rich time-series data that can inadvertently expose sensitive user behaviors. While prior work has proposed privacy-preserving methods for sensor data, most rely on static, predefined privacy labels or require large quantities of private training data, limiting their adaptability and user agency. In this work, we introduce PrivCLIP, a dynamic, user-controllable, few-shot privacy-preserving sensing framework. PrivCLIP allows users to specify and modify their privacy preferences by categorizing activities as sensitive (black-listed), non-sensitive (white-listed), or neutral (gray-listed). Leveraging a multimodal contrastive learning approach, PrivCLIP aligns IMU sensor data with natural language activity descriptions in a shared embedding space, enabling few-shot detection of sensitive activities. When a privacy-sensitive activity is identified, the system uses a language-guided activity sanitizer and a motion generation module (IMU-GPT) to transform the original data into a privacy-compliant version that semantically resembles a non-sensitive activity. We evaluate PrivCLIP on multiple human activity recognition datasets and demonstrate that it significantly outperforms baseline methods in terms of both privacy protection and data utility.', 'abstract_zh': '用户可控的隐私在现代传感系统中非常重要，因为人们的隐私偏好可能因人而异且会随时间变化。这对于配备了加速度计和陀螺仪传感器的智能手机和可穿戴设备尤其 relevant，在这些设备中，它们会持续收集丰富的时序数据，这些数据可能会无意中暴露用户的敏感行为。虽然此前的工作提出了一些传感器数据的隐私保护方法，但大多数方法依赖于静态的预定义隐私标签或需要大量的私人训练数据，这限制了其适应性和用户的自主权。在这项工作中，我们提出了 PrivCLIP，这是一种动态的、用户可控的、少量示例即可的隐私保护传感框架。PrivCLIP 允许用户通过将活动分类为敏感（黑名单）、非敏感（白名单）或中性（灰名单）来指定和修改其隐私偏好。借助多模态对比学习方法，PrivCLIP 将加速度计传感器数据与自然语言活动描述对齐到共享的嵌入空间中，从而实现对敏感活动的少量示例检测。当识别到隐私敏感的活动时，系统会使用语言引导的活动去噪器和运动生成模块（IMU-GPT）将原始数据转换为一种与非敏感活动在语义上相似的隐私合规版本。我们在多个生物识别数据集上评估了 PrivCLIP，并证明其在隐私保护和数据效用方面均显著优于基线方法。', 'title_zh': '动态可控隐私保护少样本传感框架'}
{'arxiv_id': 'arXiv:2508.03962', 'title': 'Accelerating Scientific Discovery with Multi-Document Summarization of Impact-Ranked Papers', 'authors': 'Paris Koloveas, Serafeim Chatzopoulos, Dionysis Diamantis, Christos Tryfonopoulos, Thanasis Vergoulis', 'link': 'https://arxiv.org/abs/2508.03962', 'abstract': "The growing volume of scientific literature makes it challenging for scientists to move from a list of papers to a synthesized understanding of a topic. Because of the constant influx of new papers on a daily basis, even if a scientist identifies a promising set of papers, they still face the tedious task of individually reading through dozens of titles and abstracts to make sense of occasionally conflicting findings. To address this critical bottleneck in the research workflow, we introduce a summarization feature to BIP! Finder, a scholarly search engine that ranks literature based on distinct impact aspects like popularity and influence. Our approach enables users to generate two types of summaries from top-ranked search results: a concise summary for an instantaneous at-a-glance comprehension and a more comprehensive literature review-style summary for greater, better-organized comprehension. This ability dynamically leverages BIP! Finder's already existing impact-based ranking and filtering features to generate context-sensitive, synthesized narratives that can significantly accelerate literature discovery and comprehension.", 'abstract_zh': '不断增加的科学文献数量使得科学家难以从一篇篇论文过渡到对某一主题的综合理解。由于每天都有新的论文涌入，即使科学家识别出一组有前途的论文，他们仍然需要逐个阅读数十篇论文的标题和摘要，以理解偶尔相互矛盾的研究发现。为解决研究工作流中的这一关键瓶颈，我们向BIP! Finder——一种基于影响因子排名的学术搜索引擎——引入了一种总结功能。我们的方法使用户能够从高排名的搜索结果中生成两种类型的摘要：一种是简洁的摘要，供即时概览，另一种是更为全面的文献综述式摘要，供更深入、更有组织的理解。这种方法动态利用了BIP! Finder现有的基于影响因子的排序和过滤功能，生成上下文敏感的、综合的叙述，从而显著加速文献发现和理解。', 'title_zh': '基于影响排序论文的多文档总结加速科学发现'}
{'arxiv_id': 'arXiv:2508.03940', 'title': 'FairPOT: Balancing AUC Performance and Fairness with Proportional Optimal Transport', 'authors': 'Pengxi Liu, Yi Shen, Matthew M. Engelhard, Benjamin A. Goldstein, Michael J. Pencina, Nicoleta J. Economou-Zavlanos, Michael M. Zavlanos', 'link': 'https://arxiv.org/abs/2508.03940', 'abstract': 'Fairness metrics utilizing the area under the receiver operator characteristic curve (AUC) have gained increasing attention in high-stakes domains such as healthcare, finance, and criminal justice. In these domains, fairness is often evaluated over risk scores rather than binary outcomes, and a common challenge is that enforcing strict fairness can significantly degrade AUC performance. To address this challenge, we propose Fair Proportional Optimal Transport (FairPOT), a novel, model-agnostic post-processing framework that strategically aligns risk score distributions across different groups using optimal transport, but does so selectively by transforming a controllable proportion, i.e., the top-lambda quantile, of scores within the disadvantaged group. By varying lambda, our method allows for a tunable trade-off between reducing AUC disparities and maintaining overall AUC performance. Furthermore, we extend FairPOT to the partial AUC setting, enabling fairness interventions to concentrate on the highest-risk regions. Extensive experiments on synthetic, public, and clinical datasets show that FairPOT consistently outperforms existing post-processing techniques in both global and partial AUC scenarios, often achieving improved fairness with slight AUC degradation or even positive gains in utility. The computational efficiency and practical adaptability of FairPOT make it a promising solution for real-world deployment.', 'abstract_zh': '利用接收器操作特征曲线（AUC）区域的公平性度量在医疗保健、金融和刑事司法等高风险领域获得了越来越多的关注。为了解决这一挑战，我们提出了公平最优运输（FairPOT），这是一种新的、模型无关的后处理框架，通过最优运输战略性地对不同群体的风险分数分布进行对齐，但仅通过转换处于不利地位群体中可控比例（即，前-lambda 分位数）的分数来进行选择性调整。通过调整 lambda，我们的方法可以实现降低 AUC 不平等性与保持总体 AUC 性能之间的可调衡。此外，我们将 FairPOT 扩展到部分 AUC 设置，使公平干预能够集中在高风险区域。在合成的、公开的和临床数据集上的广泛实验表明，FairPOT 在全局和部分 AUC 情景下均优于现有的后处理技术，通常能够在 AUC 稍有下降或甚至功能效益增加的情况下实现公平性的改进。FairPOT 的计算效率和实际适用性使其成为实际部署中的有前途的解决方案。', 'title_zh': 'FairPOT：基于比例最优传输平衡AUC性能与公平性'}
{'arxiv_id': 'arXiv:2508.03921', 'title': 'Active Learning and Transfer Learning for Anomaly Detection in Time-Series Data', 'authors': 'John D. Kelleher, Matthew Nicholson, Rahul Agrahari, Clare Conran', 'link': 'https://arxiv.org/abs/2508.03921', 'abstract': 'This paper examines the effectiveness of combining active learning and transfer learning for anomaly detection in cross-domain time-series data. Our results indicate that there is an interaction between clustering and active learning and in general the best performance is achieved using a single cluster (in other words when clustering is not applied). Also, we find that adding new samples to the training set using active learning does improve model performance but that in general, the rate of improvement is slower than the results reported in the literature suggest. We attribute this difference to an improved experimental design where distinct data samples are used for the sampling and testing pools. Finally, we assess the ceiling performance of transfer learning in combination with active learning across several datasets and find that performance does initially improve but eventually begins to tail off as more target points are selected for inclusion in training. This tail-off in performance may indicate that the active learning process is doing a good job of sequencing data points for selection, pushing the less useful points towards the end of the selection process and that this tail-off occurs when these less useful points are eventually added. Taken together our results indicate that active learning is effective but that the improvement in model performance follows a linear flat function concerning the number of points selected and labelled.', 'abstract_zh': '本文考察了将主动学习与迁移学习结合用于跨域时间序列数据异常检测的有效性。结果显示，聚类与主动学习之间存在交互作用，通常最优性能是在不应用聚类的情况下使用单一聚类实现的。我们还发现，通过主动学习增加训练集中的新样本可以提高模型性能，但总体而言，这种改进的速度慢于文献中的报告结果。我们将这种差异归因于实验设计的改进，即使用不同的数据样本作为采样池和测试池。最后，我们评估了在多种数据集上将迁移学习与主动学习结合的天花板性能，并发现性能最初会提升，但随着更多目标点被选入训练，这种提升会逐渐放缓。这种性能放缓可能表明主动学习过程在数据点的选择排序方面做得很好，将较不重要的点推向选择过程的末尾，并且在这些较不重要的点最终被添加时，出现了这种放缓现象。综合来看，我们的结果表明主动学习是有效的，但性能改进与所选和标注的数据点数量之间的关系呈现出线性平坦函数。', 'title_zh': '时间序列数据中的异常检测中的主动学习与迁移学习'}
{'arxiv_id': 'arXiv:2508.03913', 'title': 'Fast and Accurate Explanations of Distance-Based Classifiers by Uncovering Latent Explanatory Structures', 'authors': 'Florian Bley, Jacob Kauffmann, Simon León Krug, Klaus-Robert Müller, Grégoire Montavon', 'link': 'https://arxiv.org/abs/2508.03913', 'abstract': 'Distance-based classifiers, such as k-nearest neighbors and support vector machines, continue to be a workhorse of machine learning, widely used in science and industry. In practice, to derive insights from these models, it is also important to ensure that their predictions are explainable. While the field of Explainable AI has supplied methods that are in principle applicable to any model, it has also emphasized the usefulness of latent structures (e.g. the sequence of layers in a neural network) to produce explanations. In this paper, we contribute by uncovering a hidden neural network structure in distance-based classifiers (consisting of linear detection units combined with nonlinear pooling layers) upon which Explainable AI techniques such as layer-wise relevance propagation (LRP) become applicable. Through quantitative evaluations, we demonstrate the advantage of our novel explanation approach over several baselines. We also show the overall usefulness of explaining distance-based models through two practical use cases.', 'abstract_zh': '基于距离的分类器，如k近邻和支持向量机，仍然是机器学习中的重要工具，广泛应用于科学研究和工业领域。为了从这些模型中提取有价值的洞察，确保其预测具有解释性也非常重要。尽管可解释人工智能领域提供了一些适用于任何模型的方法，但也强调了潜在结构（例如神经网络中的层序列）在生成解释方面的有效性。在本文中，我们通过发现一个隐藏在基于距离的分类器中的神经网络结构（由线性检测单元与非线性聚合层组成），使得可解释人工智能技术（如层化相关传播层LRP）变得适用。通过定量评估，我们展示了我们新颖的解释方法相较于多个基线的优势。我们还通过两个实际案例展示了解释基于距离的模型的整体有效性。', 'title_zh': '基于latent解释结构的快速准确距离基分类器解释'}
{'arxiv_id': 'arXiv:2508.03898', 'title': 'Calibrating Biophysical Models for Grape Phenology Prediction via Multi-Task Learning', 'authors': 'William Solow, Sandhya Saisubramanian', 'link': 'https://arxiv.org/abs/2508.03898', 'abstract': 'Accurate prediction of grape phenology is essential for timely vineyard management decisions, such as scheduling irrigation and fertilization, to maximize crop yield and quality. While traditional biophysical models calibrated on historical field data can be used for season-long predictions, they lack the precision required for fine-grained vineyard management. Deep learning methods are a compelling alternative but their performance is hindered by sparse phenology datasets, particularly at the cultivar level. We propose a hybrid modeling approach that combines multi-task learning with a recurrent neural network to parameterize a differentiable biophysical model. By using multi-task learning to predict the parameters of the biophysical model, our approach enables shared learning across cultivars while preserving biological structure, thereby improving the robustness and accuracy of predictions. Empirical evaluation using real-world and synthetic datasets demonstrates that our method significantly outperforms both conventional biophysical models and baseline deep learning approaches in predicting phenological stages, as well as other crop state variables such as cold-hardiness and wheat yield.', 'abstract_zh': '精确预测葡萄生长阶段对于及时进行葡萄园管理决策（如灌溉和施肥）以最大化作物产量和质量至关重要 nâ森林公园管理阶段预测准确对于及时进行葡萄园管理决策（如灌溉和施肥）以最大化作物产量和质量至关重要', 'title_zh': '基于多任务学习的葡萄生理期预测生物物理模型校准'}
{'arxiv_id': 'arXiv:2508.03882', 'title': 'Simulating Cyberattacks through a Breach Attack Simulation (BAS) Platform empowered by Security Chaos Engineering (SCE)', 'authors': 'Arturo Sánchez-Matas, Pablo Escribano Ruiz, Daniel Díaz-López, Angel Luis Perales Gómez, Pantaleone Nespoli, Gregorio Martínez Pérez', 'link': 'https://arxiv.org/abs/2508.03882', 'abstract': 'In today digital landscape, organizations face constantly evolving cyber threats, making it essential to discover slippery attack vectors through novel techniques like Security Chaos Engineering (SCE), which allows teams to test defenses and identify vulnerabilities effectively. This paper proposes to integrate SCE into Breach Attack Simulation (BAS) platforms, leveraging adversary profiles and abilities from existing threat intelligence databases. This innovative proposal for cyberattack simulation employs a structured architecture composed of three layers: SCE Orchestrator, Connector, and BAS layers. Utilizing MITRE Caldera in the BAS layer, our proposal executes automated attack sequences, creating inferred attack trees from adversary profiles. Our proposal evaluation illustrates how integrating SCE with BAS can enhance the effectiveness of attack simulations beyond traditional scenarios, and be a useful component of a cyber defense strategy.', 'abstract_zh': '在当今数字landscape中，组织面临不断演变的网络威胁，通过如安全混沌工程（SCE）等新型技术发现易滑动的攻击向量变得至关重要，这允许团队有效测试防御并在现有威胁情报数据库中利用攻击者画像和能力。本文提议将SCE整合进漏洞攻击模拟（BAS）平台，采用了一个由三层组成的结构化架构：SCE编排器、连接器和BAS层。在BAS层使用MITRE Caldera，我们的提议执行自动化攻击序列，并根据攻击者画像推断出攻击树。我们的提案评估展示了将SCE与BAS集成如何超越传统场景提高攻击模拟的有效性，并成为网络防御策略中的有用组成部分。', 'title_zh': '基于安全性混沌工程(SCE)赋能的Breached攻击模拟平台(Baled)的网络攻击模拟研究'}
{'arxiv_id': 'arXiv:2508.03872', 'title': 'Intelligent Sampling of Extreme-Scale Turbulence Datasets for Accurate and Efficient Spatiotemporal Model Training', 'authors': 'Wesley Brewer, Murali Meena Gopalakrishnan, Matthias Maiterth, Aditya Kashi, Jong Youl Choi, Pei Zhang, Stephen Nichols, Riccardo Balin, Miles Couchman, Stephen de Bruyn Kops, P.K. Yeung, Daniel Dotson, Rohini Uma-Vaideswaran, Sarp Oral, Feiyi Wang', 'link': 'https://arxiv.org/abs/2508.03872', 'abstract': "With the end of Moore's law and Dennard scaling, efficient training increasingly requires rethinking data volume. Can we train better models with significantly less data via intelligent subsampling? To explore this, we develop SICKLE, a sparse intelligent curation framework for efficient learning, featuring a novel maximum entropy (MaxEnt) sampling approach, scalable training, and energy benchmarking. We compare MaxEnt with random and phase-space sampling on large direct numerical simulation (DNS) datasets of turbulence. Evaluating SICKLE at scale on Frontier, we show that subsampling as a preprocessing step can improve model accuracy and substantially lower energy consumption, with reductions of up to 38x observed in certain cases.", 'abstract_zh': '随着摩尔定律和 Dennard 尺度定律的终结，高效的模型训练 increasingly 越来越需要重新思考数据量的问题。我们能否通过智能子采样以显著减少数据量来训练更好的模型？为了探索这一问题，我们开发了 SICKLE，一种稀疏智能的数据精选框架，该框架具备一种新颖的最大熵采样方法、可伸缩的训练以及能源耗散评估功能。我们在大规模直接数值模拟（DNS）湍流数据集上将最大熵采样与随机采样和相空间采样进行了比较。在 Frontier 平台上大规模评估 SICKLE，结果显示，作为预处理步骤的子采样可以提高模型精度并显著降低能源消耗，在某些情况下能耗降低了高达 38 倍。', 'title_zh': '大规模湍流数据的智能采样以实现精确且高效的空时模型训练'}
{'arxiv_id': 'arXiv:2508.03839', 'title': 'VAE-DNN: Energy-Efficient Trainable-by-Parts Surrogate Model For Parametric Partial Differential Equations', 'authors': 'Yifei Zong, Alexandre M. Tartakovsky', 'link': 'https://arxiv.org/abs/2508.03839', 'abstract': 'We propose a trainable-by-parts surrogate model for solving forward and inverse parameterized nonlinear partial differential equations. Like several other surrogate and operator learning models, the proposed approach employs an encoder to reduce the high-dimensional input $y(\\bm{x})$ to a lower-dimensional latent space, $\\bm\\mu_{\\bm\\phi_y}$. Then, a fully connected neural network is used to map $\\bm\\mu_{\\bm\\phi_y}$ to the latent space, $\\bm\\mu_{\\bm\\phi_h}$, of the PDE solution $h(\\bm{x},t)$. Finally, a decoder is utilized to reconstruct $h(\\bm{x},t)$. The innovative aspect of our model is its ability to train its three components independently. This approach leads to a substantial decrease in both the time and energy required for training when compared to leading operator learning models such as FNO and DeepONet. The separable training is achieved by training the encoder as part of the variational autoencoder (VAE) for $y(\\bm{x})$ and the decoder as part of the $h(\\bm{x},t)$ VAE. We refer to this model as the VAE-DNN model. VAE-DNN is compared to the FNO and DeepONet models for obtaining forward and inverse solutions to the nonlinear diffusion equation governing groundwater flow in an unconfined aquifer. Our findings indicate that VAE-DNN not only demonstrates greater efficiency but also delivers superior accuracy in both forward and inverse solutions compared to the FNO and DeepONet models.', 'abstract_zh': '一种分而训练的代理模型用于求解参数化的非线性偏微分方程正问题和逆问题', 'title_zh': 'VAE-DNN：参数偏微分方程的分段可训练高效代理模型'}
{'arxiv_id': 'arXiv:2508.03818', 'title': 'Mechanism Design for Facility Location using Predictions', 'authors': 'Toby Walsh', 'link': 'https://arxiv.org/abs/2508.03818', 'abstract': 'We study mechanisms for the facility location problem augmented with predictions of the optimal facility location. We demonstrate that an egalitarian viewpoint which considers both the maximum distance of any agent from the facility and the minimum utility of any agent provides important new insights compared to a viewpoint that just considers the maximum distance. As in previous studies, we consider performance in terms of consistency (worst case when predictions are accurate) and robustness (worst case irrespective of the accuracy of predictions). By considering how mechanisms with predictions can perform poorly, we design new mechanisms that are more robust. Indeed, by adjusting parameters, we demonstrate how to trade robustness for consistency. We go beyond the single facility problem by designing novel strategy proof mechanisms for locating two facilities with bounded consistency and robustness that use two predictions for where to locate the two facilities.', 'abstract_zh': '我们研究了设施部署问题中包含预测最优设施位置机制的机制。我们表明，考虑每个代理到设施的最大距离和每个代理最小效用的公平视角相比，仅考虑最大距离的视角提供了更多的见解。在之前的研究所关注的一致性（预测准确时的最坏情况）和鲁棒性（预测不准确时时的最坏情况）标准下，我们研究了包含预测的机制的一致性和鲁棒性表现。通过研究预测机制，我们比较了更具鲁棒性的机制。确实通过调整参数，我们证明了如何平衡一致性和鲁棒性。我们超越了单一设施问题，设计了使用两种预测来定位两个设施的机制，同时保持一致性和鲁棒性的界。', 'title_zh': '基于预测的设施定位机制设计'}
{'arxiv_id': 'arXiv:2508.03783', 'title': 'Probing and Enhancing the Robustness of GNN-based QEC Decoders with Reinforcement Learning', 'authors': 'Ryota Ikeda', 'link': 'https://arxiv.org/abs/2508.03783', 'abstract': "Graph Neural Networks (GNNs) have emerged as a powerful, data-driven approach for Quantum Error Correction (QEC) decoding, capable of learning complex noise characteristics directly from syndrome data. However, the robustness of these decoders against subtle, adversarial perturbations remains a critical open question. This work introduces a novel framework to systematically probe the vulnerabilities of a GNN decoder using a reinforcement learning (RL) agent. The RL agent is trained as an adversary with the goal of finding minimal syndrome modifications that cause the decoder to misclassify. We apply this framework to a Graph Attention Network (GAT) decoder trained on experimental surface code data from Google Quantum AI. Our results show that the RL agent can successfully identify specific, critical vulnerabilities, achieving a high attack success rate with a minimal number of bit flips. Furthermore, we demonstrate that the decoder's robustness can be significantly enhanced through adversarial training, where the model is retrained on the adversarial examples generated by the RL agent. This iterative process of automated vulnerability discovery and targeted retraining presents a promising methodology for developing more reliable and robust neural network decoders for fault-tolerant quantum computing.", 'abstract_zh': '基于 reinforcement learning 的图神经网络解码器漏洞系统性探针框架：应用于Google Quantum AI的表面码数据的图注意网络解码器 robustness 提升研究', 'title_zh': '基于图神经网络的量子错误校正解码器的鲁棒性探查与增强方法'}
{'arxiv_id': 'arXiv:2508.03782', 'title': 'Do GNN-based QEC Decoders Require Classical Knowledge? Evaluating the Efficacy of Knowledge Distillation from MWPM', 'authors': 'Ryota Ikeda', 'link': 'https://arxiv.org/abs/2508.03782', 'abstract': 'The performance of decoders in Quantum Error Correction (QEC) is key to realizing practical quantum computers. In recent years, Graph Neural Networks (GNNs) have emerged as a promising approach, but their training methodologies are not yet well-established. It is generally expected that transferring theoretical knowledge from classical algorithms like Minimum Weight Perfect Matching (MWPM) to GNNs, a technique known as knowledge distillation, can effectively improve performance. In this work, we test this hypothesis by rigorously comparing two models based on a Graph Attention Network (GAT) architecture that incorporates temporal information as node features. The first is a purely data-driven model (baseline) trained only on ground-truth labels, while the second incorporates a knowledge distillation loss based on the theoretical error probabilities from MWPM. Using public experimental data from Google, our evaluation reveals that while the final test accuracy of the knowledge distillation model was nearly identical to the baseline, its training loss converged more slowly, and the training time increased by a factor of approximately five. This result suggests that modern GNN architectures possess a high capacity to efficiently learn complex error correlations directly from real hardware data, without guidance from approximate theoretical models.', 'abstract_zh': '量子纠错（QEC）中解码器的性能是实现实用量子计算机的关键。近年来，图神经网络（GNNs）被认为是一种有前途的方法，但其训练方法尚不成熟。人们普遍认为，将经典算法如最小权重完备匹配（MWPM）的理论知识转移到GNN中，一种技术称为知识蒸馏，可以有效提升性能。在本工作中，我们通过严格比较基于图注意网络（GAT）架构、将时间信息作为节点特征的两种模型来验证这一假设。第一种模型是纯数据驱动的基线模型，仅基于真实标签进行训练；第二种模型则包含基于MWPM理论错误概率的知识蒸馏损失。使用谷歌公开的实验数据，我们的评估显示，虽然知识蒸馏模型的最终测试精度几乎与基线模型相同，但其训练损失收敛速度较慢，训练时间大约增加了五倍。这一结果表明，现代GNN架构具有高效直接从真实硬件数据中学习复杂错误关联的强大能力，无需依赖近似理论模型的指导。', 'title_zh': '基于GNN的量子纠错解码器需要经典知识吗？评估来自MWPM的知识蒸馏效用'}
{'arxiv_id': 'arXiv:2508.03780', 'title': 'Are Inherently Interpretable Models More Robust? A Study In Music Emotion Recognition', 'authors': 'Katharina Hoedt, Arthur Flexer, Gerhard Widmer', 'link': 'https://arxiv.org/abs/2508.03780', 'abstract': "One of the desired key properties of deep learning models is the ability to generalise to unseen samples. When provided with new samples that are (perceptually) similar to one or more training samples, deep learning models are expected to produce correspondingly similar outputs. Models that succeed in predicting similar outputs for similar inputs are often called robust. Deep learning models, on the other hand, have been shown to be highly vulnerable to minor (adversarial) perturbations of the input, which manage to drastically change a model's output and simultaneously expose its reliance on spurious correlations. In this work, we investigate whether inherently interpretable deep models, i.e., deep models that were designed to focus more on meaningful and interpretable features, are more robust to irrelevant perturbations in the data, compared to their black-box counterparts. We test our hypothesis by comparing the robustness of an interpretable and a black-box music emotion recognition (MER) model when challenged with adversarial examples. Furthermore, we include an adversarially trained model, which is optimised to be more robust, in the comparison. Our results indicate that inherently more interpretable models can indeed be more robust than their black-box counterparts, and achieve similar levels of robustness as adversarially trained models, at lower computational cost.", 'abstract_zh': '具有固有解释性的深度模型在面对无关数据扰动时是否更 robust：一项音乐情感识别的对比研究', 'title_zh': '固有可解释模型更稳健？音乐情绪识别中的研究'}
{'arxiv_id': 'arXiv:2508.03777', 'title': 'When Agents Break Down in Multiagent Path Finding', 'authors': 'Foivos Fioravantes, Dušan Knop, Nikolaos Melissinos, Michal Opler', 'link': 'https://arxiv.org/abs/2508.03777', 'abstract': "In Multiagent Path Finding (MAPF), the goal is to compute efficient, collision-free paths for multiple agents navigating a network from their sources to targets, minimizing the schedule's makespan-the total time until all agents reach their destinations. We introduce a new variant that formally models scenarios where some agents may experience delays due to malfunctions, posing significant challenges for maintaining optimal schedules.\nRecomputing an entirely new schedule from scratch after each malfunction is often computationally infeasible. To address this, we propose a framework for dynamic schedule adaptation that does not rely on full replanning. Instead, we develop protocols enabling agents to locally coordinate and adjust their paths on the fly. We prove that following our primary communication protocol, the increase in makespan after k malfunctions is bounded by k additional turns, effectively limiting the impact of malfunctions on overall efficiency. Moreover, recognizing that agents may have limited computational capabilities, we also present a secondary protocol that shifts the necessary computations onto the network's nodes, ensuring robustness without requiring enhanced agent processing power. Our results demonstrate that these protocols provide a practical, scalable approach to resilient multiagent navigation in the face of agent failures.", 'abstract_zh': '多智能体路径规划中，目标是为多个智能体在网络中从起始点导航到目标点计算高效且无碰撞的路径，同时最小化完成所有智能体任务的总时间。我们引入了一种新的变种，正式模型了某些智能体因故障而延迟的情况，这为保持最优时间表提出了重大挑战。\n每次故障后重新计算全新的时间表通常会变得计算上不可行。为解决这一问题，我们提出了一种动态时间表适应框架，该框架无需完全重新规划。相反，我们开发了协议，使智能体能够在本地协调并实时调整路径。我们证明，在我们的主要通信协议下，k次故障后的总时间增加量被限制在k个额外的转弯内，有效限制了故障对整体效率的影响。此外，鉴于智能体可能具有有限的计算能力，我们还提出了第二个协议，将必要的计算任务转移到网络节点上，确保了鲁棒性，而无需增强智能体的处理能力。我们的结果表明，这些协议提供了一种实用且可扩展的方法，以在面对智能体故障时实现鲁棒的多智能体导航。', 'title_zh': '多代理路径寻找中代理失效时的情形'}
{'arxiv_id': 'arXiv:2508.03776', 'title': 'Revisiting Heat Flux Analysis of Tungsten Monoblock Divertor on EAST using Physics-Informed Neural Network', 'authors': 'Xiao Wang, Zikang Yan, Hao Si, Zhendong Yang, Qingquan Yang, Dengdi Sun, Wanli Lyu, Jin Tang', 'link': 'https://arxiv.org/abs/2508.03776', 'abstract': "Estimating heat flux in the nuclear fusion device EAST is a critically important task. Traditional scientific computing methods typically model this process using the Finite Element Method (FEM). However, FEM relies on grid-based sampling for computation, which is computationally inefficient and hard to perform real-time simulations during actual experiments. Inspired by artificial intelligence-powered scientific computing, this paper proposes a novel Physics-Informed Neural Network (PINN) to address this challenge, significantly accelerating the heat conduction estimation process while maintaining high accuracy. Specifically, given inputs of different materials, we first feed spatial coordinates and time stamps into the neural network, and compute boundary loss, initial condition loss, and physical loss based on the heat conduction equation. Additionally, we sample a small number of data points in a data-driven manner to better fit the specific heat conduction scenario, further enhancing the model's predictive capability. We conduct experiments under both uniform and non-uniform heating conditions on the top surface. Experimental results show that the proposed thermal conduction physics-informed neural network achieves accuracy comparable to the finite element method, while achieving $\\times$40 times acceleration in computational efficiency. The dataset and source code will be released on this https URL.", 'abstract_zh': '核聚变装置EAST中热量_flux_估计是一个至关重要的任务。受人工智能增强科学计算的启发，本文提出了一种新的物理知情神经网络（PINN）来解决这一挑战，显著加速了热传导估计过程同时保持高精度。实验结果表明，所提出的热传导物理知情神经网络在计算效率上比有限元方法快40倍，但仍能达到相当的精度。详细的数据集和源代码将发布在该网址。', 'title_zh': '基于物理约束神经网络的 EAST 钨单块抽气器热通量分析再探'}
{'arxiv_id': 'arXiv:2508.03775', 'title': '4D-PreNet: A Unified Preprocessing Framework for 4D-STEM Data Analysis', 'authors': 'Mingyu Liu, Zian Mao, Zhu Liu, Haoran Zhang, Jintao Guo, Xiaoya He, Xi Huang, Shufen Chu, Chun Cheng, Jun Ding, Yujun Xie', 'link': 'https://arxiv.org/abs/2508.03775', 'abstract': 'Automated experimentation with real time data analysis in scanning transmission electron microscopy (STEM) often require end-to-end framework. The four-dimensional scanning transmission electron microscopy (4D-STEM) with high-throughput data acquisition has been constrained by the critical bottleneck results from data preprocessing. Pervasive noise, beam center drift, and elliptical distortions during high-throughput acquisition inevitably corrupt diffraction patterns, systematically biasing quantitative measurements. Yet, conventional correction algorithms are often material-specific and fail to provide a robust, generalizable solution. In this work, we present 4D-PreNet, an end-to-end deep-learning pipeline that integrates attention-enhanced U-Net and ResNet architectures to simultaneously perform denoising, center correction, and elliptical distortion calibration. The network is trained on large, simulated datasets encompassing a wide range of noise levels, drift magnitudes, and distortion types, enabling it to generalize effectively to experimental data acquired under varying conditions. Quantitative evaluations demonstrate that our pipeline reduces mean squared error by up to 50% during denoising and achieves sub-pixel center localization in the center detection task, with average errors below 0.04 pixels. The outputs are bench-marked against traditional algorithms, highlighting improvements in both noise suppression and restoration of diffraction patterns, thereby facilitating high-throughput, reliable 4D-STEM real-time analysis for automated characterization.', 'abstract_zh': '基于实时数据分析的自动实验在扫描传输电子显微镜（STEM）中往往需要端到端框架。高通量4D扫描传输电子显微镜（4D-STEM）由于数据预处理的关键瓶颈而受到限制。在高通量采集过程中普遍存在的噪声、束中心漂移和椭圆变形不可避免地会损坏衍射图案，系统性地影响定量测量结果。然而，传统的校正算法往往是材料特定的，无法提供稳健且通用的解决方案。在本工作中，我们提出了一种端到端的深度学习管道4D-PreNet，该管道结合了注意力增强的U-Net和ResNet架构，同时进行降噪、中心校正和椭圆变形校准。该网络在包含广泛噪声水平、漂移幅度和变形类型的大型模拟数据集上进行训练，使其能够在不同条件下有效泛化到实验数据。定量评估表明，我们的管道在降噪过程中可将均方误差降低50%，并在中心检测任务中实现亚像素中心定位，平均误差低于0.04像素。输出结果与传统算法进行了基准测试，突显了在噪声抑制和衍射图案恢复方面的改进，从而推动了高通量可靠的4D-STEM实时分析在自动化表征中的应用。', 'title_zh': '4D-PreNet: 4D-STEM数据预处理统一框架'}
{'arxiv_id': 'arXiv:2508.03774', 'title': 'U-PINet: End-to-End Hierarchical Physics-Informed Learning With Sparse Graph Coupling for 3D EM Scattering Modeling', 'authors': 'Rui Zhu, Yuexing Peng, Peng Wang, George C. Alexandropoulos, Wenbo Wang, Wei Xiang', 'link': 'https://arxiv.org/abs/2508.03774', 'abstract': 'Electromagnetic (EM) scattering modeling is critical for radar remote sensing, however, its inherent complexity introduces significant computational challenges. Traditional numerical solvers offer high accuracy, but suffer from scalability issues and substantial computational costs. Pure data-driven deep learning approaches, while efficient, lack physical constraints embedding during training and require extensive labeled data, limiting their applicability and generalization. To overcome these limitations, we propose a U-shaped Physics-Informed Network (U-PINet), the first fully deep-learning-based, physics-informed hierarchical framework for computational EM designed to ensure physical consistency while maximizing computational efficiency. Motivated by the hierarchical decomposition strategy in EM solvers and the inherent sparsity of local EM coupling, the U-PINet models the decomposition and coupling of near- and far-field interactions through a multiscale processing neural network architecture, while employing a physics-inspired sparse graph representation to efficiently model both self- and mutual- coupling among mesh elements of complex $3$-Dimensional (3D) objects. This principled approach enables end-to-end multiscale EM scattering modeling with improved efficiency, generalization, and physical consistency. Experimental results showcase that the U-PINet accurately predicts surface current distributions, achieving close agreement with traditional solver, while significantly reducing computational time and outperforming conventional deep learning baselines in both accuracy and robustness. Furthermore, our evaluations on radar cross section prediction tasks confirm the feasibility of the U-PINet for downstream EM scattering applications.', 'abstract_zh': '基于物理的U型深层网络（U-PINet）在计算电磁散射建模中的应用', 'title_zh': 'U-PINet：基于稀疏图耦合的端到端分层物理信息学习方法及其在3D电磁散射建模中的应用'}
{'arxiv_id': 'arXiv:2508.03773', 'title': "When Deep Learning Fails: Limitations of Recurrent Models on Stroke-Based Handwriting for Alzheimer's Disease Detection", 'authors': "Emanuele Nardone, Tiziana D'Alessandro, Francesco Fontanella, Claudio De Stefano", 'link': 'https://arxiv.org/abs/2508.03773', 'abstract': "Alzheimer's disease detection requires expensive neuroimaging or invasive procedures, limiting accessibility. This study explores whether deep learning can enable non-invasive Alzheimer's disease detection through handwriting analysis. Using a dataset of 34 distinct handwriting tasks collected from healthy controls and Alzheimer's disease patients, we evaluate and compare three recurrent neural architectures (LSTM, GRU, RNN) against traditional machine learning models. A crucial distinction of our approach is that the recurrent models process pre-extracted features from discrete strokes, not raw temporal signals. This violates the assumption of a continuous temporal flow that recurrent networks are designed to capture. Results reveal that they exhibit poor specificity and high variance. Traditional ensemble methods significantly outperform all deep architectures, achieving higher accuracy with balanced metrics. This demonstrates that recurrent architectures, designed for continuous temporal sequences, fail when applied to feature vectors extracted from ambiguously segmented strokes. Despite their complexity, deep learning models cannot overcome the fundamental disconnect between their architectural assumptions and the discrete, feature-based nature of stroke-level handwriting data. Although performance is limited, the study highlights several critical issues in data representation and model compatibility, pointing to valuable directions for future research.", 'abstract_zh': '阿尔茨海默病检测需要昂贵的神经影像学检查或侵入性程序，限制了其可访问性。本研究探索深度学习是否能通过笔迹分析实现无侵入性的阿尔茨海默病检测。通过从健康对照组和阿尔茨海默病患者收集的34项不同笔迹任务数据集，我们评估并比较了三种循环神经网络架构（LSTM、GRU、RNN）与传统机器学习模型的性能。我们的方法的关键区别在于，循环模型处理从离散笔划预先提取的特征，而不是原始的时间信号。这违反了循环网络设计时假设的连续时间流。结果表明，这些模型表现较差，且具有高方差。传统的集成方法显著优于所有深度架构，以平衡的度量标准实现了更高的准确性。这表明，设计用于连续时间序列的循环架构在应用于从模糊分割的笔划提取的特征向量时会失效。尽管深度学习模型结构复杂，但它们无法克服其架构假设与笔迹级特征基于的离散性之间的根本分歧。尽管性能受到限制，但研究突显了几种关键的数据表示和模型兼容性问题，为未来研究指明了有价值的方向。', 'title_zh': '当深度学习失效：基于笔画的手写识别在阿尔茨海默病检测中的局限性'}
{'arxiv_id': 'arXiv:2508.03769', 'title': 'Development of management systems using artificial intelligence systems and machine learning methods for boards of directors (preprint, unofficial translation)', 'authors': 'Anna Romanova', 'link': 'https://arxiv.org/abs/2508.03769', 'abstract': 'The study addresses the paradigm shift in corporate management, where AI is moving from a decision support tool to an autonomous decision-maker, with some AI systems already appointed to leadership roles in companies. A central problem identified is that the development of AI technologies is far outpacing the creation of adequate legal and ethical guidelines.\nThe research proposes a "reference model" for the development and implementation of autonomous AI systems in corporate management. This model is based on a synthesis of several key components to ensure legitimate and ethical decision-making. The model introduces the concept of "computational law" or "algorithmic law". This involves creating a separate legal framework for AI systems, with rules and regulations translated into a machine-readable, algorithmic format to avoid the ambiguity of natural language. The paper emphasises the need for a "dedicated operational context" for autonomous AI systems, analogous to the "operational design domain" for autonomous vehicles. This means creating a specific, clearly defined environment and set of rules within which the AI can operate safely and effectively. The model advocates for training AI systems on controlled, synthetically generated data to ensure fairness and ethical considerations are embedded from the start. Game theory is also proposed as a method for calculating the optimal strategy for the AI to achieve its goals within these ethical and legal constraints. The provided analysis highlights the importance of explainable AI (XAI) to ensure the transparency and accountability of decisions made by autonomous systems. This is crucial for building trust and for complying with the "right to explanation".', 'abstract_zh': '企业管理中的人工智能 paradigm转变：从决策支持工具到自主决策制定者的研发与实施参考模型', 'title_zh': '使用人工智能系统和机器学习方法开发董事会管理系统的研究（预印本，非正式翻译）'}
{'arxiv_id': 'arXiv:2508.03747', 'title': 'Data-Driven Discovery of Mobility Periodicity for Understanding Urban Transportation Systems', 'authors': 'Xinyu Chen, Qi Wang, Yunhan Zheng, Nina Cao, HanQin Cai, Jinhua Zhao', 'link': 'https://arxiv.org/abs/2508.03747', 'abstract': 'Uncovering the temporal regularity of human mobility is crucial for discovering urban dynamics and has implications for various decision-making processes and urban system applications. This study formulates the periodicity quantification problem in complex and multidimensional human mobility data as a sparse identification of dominant positive auto-correlations in time series autoregression, allowing one to discover and quantify significant periodic patterns such as weekly periodicity from a data-driven and interpretable machine learning perspective. We apply our framework to real-world human mobility data, including metro passenger flow in Hangzhou, China and ridesharing trips in New York City (NYC) and Chicago, USA, revealing the interpretable weekly periodicity across different spatial locations over past several years. In particular, our analysis of ridesharing data from 2019 to 2024 demonstrates the disruptive impact of the COVID-19 pandemic on mobility regularity and the subsequent recovery trends, highlighting differences in the recovery pattern percentages and speeds between NYC and Chicago. We explore that both NYC and Chicago experienced a remarkable reduction of weekly periodicity in 2020, and the recovery of mobility regularity in NYC is faster than Chicago. The interpretability of sparse autoregression provides insights into the underlying temporal patterns of human mobility, offering a valuable tool for understanding urban systems. Our findings highlight the potential of interpretable machine learning to unlock crucial insights from real-world mobility data.', 'abstract_zh': '揭示人类移动的时间规律对于发现城市动态至关重要，并对各种决策过程和城市系统应用具有重要影响。本文将复杂多维的人类移动数据中的周期性量化问题表述为时间序列自回归中主导正自相关性的稀疏识别问题，从数据驱动和可解释的机器学习视角发现并量化显著的周期性模式，如周周期性。我们将该框架应用于中国杭州的地铁客流量数据和美国纽约市和芝加哥的拼车出行数据，揭示过去几年不同地理位置的可解释周周期性。特别是，2019年至2024年拼车数据的分析表明了COVID-19疫情对移动规律的破坏性影响及随后的恢复趋势，并突出了纽约市和芝加哥恢复模式和速度之间的差异。研究表明，2020年纽约市和芝加哥的周周期性均显著减少，纽约市的移动规律恢复速度比芝加哥更快。稀疏自回归的可解释性为理解人类移动的潜在时间模式提供了见解，提供了理解城市系统的重要工具。我们的研究突显了可解释机器学习从现实移动数据中解锁关键洞察的潜力。', 'title_zh': '基于数据的移动周期性性'}
{'arxiv_id': 'arXiv:2508.03745', 'title': "Tobler's First Law in GeoAI: A Spatially Explicit Deep Learning Model for Terrain Feature Detection Under Weak Supervision", 'authors': 'Wenwen Li, Chia-Yu Hsu, Maosheng Hu', 'link': 'https://arxiv.org/abs/2508.03745', 'abstract': "Recent interest in geospatial artificial intelligence (GeoAI) has fostered a wide range of applications using artificial intelligence (AI), especially deep learning, for geospatial problem solving. However, major challenges such as a lack of training data and the neglect of spatial principles and spatial effects in AI model design remain, significantly hindering the in-depth integration of AI with geospatial research. This paper reports our work in developing a deep learning model that enables object detection, particularly of natural features, in a weakly supervised manner. Our work makes three contributions: First, we present a method of object detection using only weak labels. This is achieved by developing a spatially explicit model based on Tobler's first law of geography. Second, we incorporate attention maps into the object detection pipeline and develop a multistage training strategy to improve performance. Third, we apply this model to detect impact craters on Mars, a task that previously required extensive manual effort. The model generalizes to both natural and human-made features on the surfaces of Earth and other planets. This research advances the theoretical and methodological foundations of GeoAI.", 'abstract_zh': 'Recent Interest in Geospatial Artificial Intelligence (GeoAI): Developing a Deep Learning Model for Weakly Supervised Object Detection in Weak Labels and Its Application to Impact Crater Detection on Mars', 'title_zh': 'Tobler’s 第一定律在GeoAI中的应用：在弱监督下基于空间显式的深度学习地形特征检测模型'}
{'arxiv_id': 'arXiv:2508.03744', 'title': 'Do We Need Pre-Processing for Deep Learning Based Ultrasound Shear Wave Elastography?', 'authors': 'Sarah Grube, Sören Grünhagen, Sarah Latus, Michael Meyling, Alexander Schlaefer', 'link': 'https://arxiv.org/abs/2508.03744', 'abstract': 'Estimating the elasticity of soft tissue can provide useful information for various diagnostic applications. Ultrasound shear wave elastography offers a non-invasive approach. However, its generalizability and standardization across different systems and processing pipelines remain limited. Considering the influence of image processing on ultrasound based diagnostics, recent literature has discussed the impact of different image processing steps on reliable and reproducible elasticity analysis. In this work, we investigate the need of ultrasound pre-processing steps for deep learning-based ultrasound shear wave elastography. We evaluate the performance of a 3D convolutional neural network in predicting shear wave velocities from spatio-temporal ultrasound images, studying different degrees of pre-processing on the input images, ranging from fully beamformed and filtered ultrasound images to raw radiofrequency data. We compare the predictions from our deep learning approach to a conventional time-of-flight method across four gelatin phantoms with different elasticity levels. Our results demonstrate statistically significant differences in the predicted shear wave velocity among all elasticity groups, regardless of the degree of pre-processing. Although pre-processing slightly improves performance metrics, our results show that the deep learning approach can reliably differentiate between elasticity groups using raw, unprocessed radiofrequency data. These results show that deep learning-based approaches could reduce the need for and the bias of traditional ultrasound pre-processing steps in ultrasound shear wave elastography, enabling faster and more reliable clinical elasticity assessments.', 'abstract_zh': '基于深度学习的超声剪切波弹性成像的超声预处理需求探究', 'title_zh': '基于深度学习的超声剪切波弹性成像是否需要预处理？'}
{'arxiv_id': 'arXiv:2508.03740', 'title': 'VQ-DeepISC: Vector Quantized-Enabled Digital Semantic Communication with Channel Adaptive Image Transmission', 'authors': 'Jianqiao Chen, Tingting Zhu, Huishi Song, Nan Ma, Xiaodong Xu', 'link': 'https://arxiv.org/abs/2508.03740', 'abstract': 'Discretization of semantic features enables interoperability between semantic and digital communication systems, showing significant potential for practical applications. The fundamental difficulty in digitizing semantic features stems from the need to preserve continuity and context in inherently analog representations during their compression into discrete symbols while ensuring robustness to channel degradation. In this paper, we propose a vector quantized (VQ)-enabled digital semantic communication system with channel adaptive image transmission, named VQ-DeepISC. Guided by deep joint source-channel coding (DJSCC), we first design a Swin Transformer backbone for hierarchical semantic feature extraction, followed by VQ modules projecting features into discrete latent spaces. Consequently, it enables efficient index-based transmission instead of raw feature transmission. To further optimize this process, we develop an attention mechanism-driven channel adaptation module to dynamically optimize index transmission. Secondly, to counteract codebook collapse during training process, we impose a distributional regularization by minimizing the Kullback-Leibler divergence (KLD) between codeword usage frequencies and a uniform prior. Meanwhile, exponential moving average (EMA) is employed to stabilize training and ensure balanced feature coverage during codebook updates. Finally, digital communication is implemented using quadrature phase shift keying (QPSK) modulation alongside orthogonal frequency division multiplexing (OFDM), adhering to the IEEE 802.11a standard. Experimental results demonstrate superior reconstruction fidelity of the proposed system over benchmark methods.', 'abstract_zh': '语义特征的离散化使语义通信系统与数字通信系统之间实现互操作性，展示了在实际应用中的巨大潜力。本论文提出了一种基于矢量量化（VQ）的数字语义通信系统，并集成了通道自适应图像传输，命名为VQ-DeepISC。基于深度联合源-信道编码（DJSCC），我们首先设计了一个Swin Transformer骨干网络以进行分层语义特征提取，随后使用VQ模块将特征投影到离散的潜在空间。这使得可以通过索引方式进行高效传输，而不是原始特征传输。为了进一步优化这个过程，我们开发了一种基于注意力机制的通道自适应模块，以动态优化索引传输。其次，为应对训练过程中码书坍塌的问题，我们通过最小化码字使用频率与均匀先验之间的克劳德-莱布尼兹散度（KLD）来施加分布正则化。同时，采用指数移动平均（EMA）来稳定训练，并在码书更新期间确保特征覆盖的均衡。最后，采用 quadrature phase shift keying (QPSK) 调制与 orthogonal frequency division multiplexing (OFDM) 实施数字通信，并符合IEEE 802.11a标准。实验结果表明，所提出系统在重建保真度方面优于基准方法。', 'title_zh': 'VQ-DeepISC：通道自适应图像传输的向量量化 Enabled 数字语义通信'}
{'arxiv_id': 'arXiv:2508.03737', 'title': 'GanitBench: A bi-lingual benchmark for evaluating mathematical reasoning in Vision Language Models', 'authors': 'Ashutosh Bandooni, Brindha Subburaj', 'link': 'https://arxiv.org/abs/2508.03737', 'abstract': 'Benchmarks for evaluating reasoning among Vision Language Models (VLMs) on several fields and domains are being curated more frequently over the last few years. However these are often monolingual, mostly available in English. Additionally there also is a lack of datasets available in Hindi on tasks apart from comprehension and translation. We introduce GanitBench, a tough benchmark consisting of 1527 vision-only questions covering several topics in Mathematics - available in languages English and Hindi. Collected from two major examinations from India, the JEE Advanced and the CBSE Boards examinations, this benchmark includes questions in the form of images comprising of figures essential to a question as well as text. We evaluate two closed source models for the same, in zero-shot Chain-of-Thought (CoT) and two-shot CoT settings. GPT-4o mini is found to be the more dominant model on the benchmark, with it\'s highest average accuracy being 38.15%. We also evaluate models through a "Double Lock" constraint, which brings down the performance of the models by considerable margins. We observe that two-shot CoT appears to be a more effective setting under this environment. Performance of the two VLMs also decreases when answering the same questions in the Hindi language. We hope to facilitate the inclusion of languages like Hindi in research through our work.', 'abstract_zh': '用于评估视觉语言模型在若干领域和领域中推理能力的基准正在逐年增加，但这些基准大多为单一语言，主要为英语。此外，有关数学等任务的数据集在印地语方面也较为缺乏。我们介绍了GanitBench，这是一个包含1527个仅涉及视觉问题的严格基准，涵盖多个数学主题，并以英语和印地语提供。这些问题来源于印度的两场主要考试——JEE Advanced和CBSE Boards考试，其中包括包含问题所需图形及文本的图像形式的问题。我们在此基准上对两种闭源模型分别进行了零样本链式思考（CoT）和两样本链式思考设置下的评估。GPT-4o mini 在该基准上表现出更高的主导性，其最高平均准确率为38.15%。我们还通过“双重锁定”约束对模型进行评估，这明显降低了模型的性能。在该环境中，我们观察到两样本链式思考可能是更有效的设置。当使用印地语回答相同的问题时，两种视觉语言模型的表现也有所下降。我们希望我们的工作能够促进语言如印地语在研究中的应用。', 'title_zh': 'GanitBench: 一种用于评估视觉语言模型数学推理能力的双语基准测试'}
{'arxiv_id': 'arXiv:2508.03719', 'title': 'Intent Aware Context Retrieval for Multi-Turn Agricultural Question Answering', 'authors': 'Abhay Vijayvargia, Ajay Nagpal, Kundeshwar Pundalik, Atharva Savarkar, Smita Gautam, Pankaj Singh, Rohit Saluja, Ganesh Ramakrishnan', 'link': 'https://arxiv.org/abs/2508.03719', 'abstract': "Indian farmers often lack timely, accessible, and language-friendly agricultural advice, especially in rural areas with low literacy. To address this gap in accessibility, this paper presents a novel AI-powered agricultural chatbot, Krishi Sathi, designed to support Indian farmers by providing personalized, easy-to-understand answers to their queries through both text and speech. The system's intelligence stems from an IFT model, subsequently refined through fine-tuning on Indian agricultural knowledge across three curated datasets. Unlike traditional chatbots that respond to one-off questions, Krishi Sathi follows a structured, multi-turn conversation flow to gradually collect the necessary details from the farmer, ensuring the query is fully understood before generating a response. Once the intent and context are extracted, the system performs Retrieval-Augmented Generation (RAG) by first fetching information from a curated agricultural database and then generating a tailored response using the IFT model. The chatbot supports both English and Hindi languages, with speech input and output features (via ASR and TTS) to make it accessible for users with low literacy or limited digital skills. This work demonstrates how combining intent-driven dialogue flows, instruction-tuned models, and retrieval-based generation can improve the quality and accessibility of digital agricultural support in India.\nThis approach yielded strong results, with the system achieving a query response accuracy of 97.53%, 91.35% contextual relevance and personalization, and a query completion rate of 97.53%. The average response time remained under 6 seconds, ensuring timely support for users across both English and Hindi interactions.", 'abstract_zh': '印度农民往往缺乏及时、易获取且语言友好的农业建议，尤其是在低 literacy 的农村地区。为了填补这一易获取性的缺口，本文介绍了一种新型的 AI 助手型农业聊天机器人 Krishi Sathi，旨在通过文本和语音提供个性化、易懂的答案，支持印度农民。该系统的智能来源于一个 IFT 模型，并通过三个精心策划的数据集进行微调。与只对单一问题作出回应的传统聊天机器人不同，Krishi Sathi 采用结构化的多回合对话流程，逐步收集所需详情，确保完全理解查询后再作出响应。提取意图和上下文后，系统通过从精心策划的农业数据库检索信息并结合 IFT 模型生成定制化回复，执行 Retrieval-Augmented Generation (RAG)。聊天机器人支持英语和印地语，具备语音输入和输出功能（通过 ASR 和 TTS），以使其对于低 literacy 或有限数字技能的用户更加易用。本文展示了通过结合意图驱动的对话流程、指令微调模型以及检索生成的方法，如何提高印度数字农业支持的质量和易获取性。', 'title_zh': '意图aware的多轮农业问答上下文检索'}
{'arxiv_id': 'arXiv:2508.03718', 'title': 'Health Insurance Coverage Rule Interpretation Corpus: Law, Policy, and Medical Guidance for Health Insurance Coverage Understanding', 'authors': 'Mike Gartner', 'link': 'https://arxiv.org/abs/2508.03718', 'abstract': 'U.S. health insurance is complex, and inadequate understanding and limited access to justice have dire implications for the most vulnerable. Advances in natural language processing present an opportunity to support efficient, case-specific understanding, and to improve access to justice and healthcare. Yet existing corpora lack context necessary for assessing even simple cases. We collect and release a corpus of reputable legal and medical text related to U.S. health insurance. We also introduce an outcome prediction task for health insurance appeals designed to support regulatory and patient self-help applications, and release a labeled benchmark for our task, and models trained on it.', 'abstract_zh': '美国健康保险体系复杂且不够完善，有限的法律途径对最脆弱群体造成了严重影响。自然语言处理技术为提高法律途径的获取和健康保险效率提供了机会 kukjl。然而，现有的数据集缺乏评估简单案件所需的背景信息。因此，我们构建了一个与美国健康保险相关的可靠法律和医疗数据集，并并我们还还 引入了一个健康保险上诉结果预测任务，旨在为监管和辅助设计工具提供支持，并构建了一个标记基准用于该任务和训练模型。', 'title_zh': '健康保险覆盖规则解释语料库：健康保险覆盖理解的法律、政策与医学指导'}
{'arxiv_id': 'arXiv:2508.03714', 'title': '"Think First, Verify Always": Training Humans to Face AI Risks', 'authors': 'Yuksel Aydin', 'link': 'https://arxiv.org/abs/2508.03714', 'abstract': 'Artificial intelligence enables unprecedented attacks on human cognition, yet cybersecurity remains predominantly device-centric. This paper introduces the "Think First, Verify Always" (TFVA) protocol, which repositions humans as \'Firewall Zero\', the first line of defense against AI-enabled threats. The protocol is grounded in five operational principles: Awareness, Integrity, Judgment, Ethical Responsibility, and Transparency (AIJET). A randomized controlled trial (n=151) demonstrated that a minimal 3-minute intervention produced statistically significant improvements in cognitive security task performance, with participants showing an absolute +7.87% gains compared to controls. These results suggest that brief, principles-based training can rapidly enhance human resilience against AI-driven cognitive manipulation. We recommend that GenAI platforms embed "Think First, Verify Always" as a standard prompt, replacing passive warnings with actionable protocols to enhance trustworthy and ethical AI use. By bridging the gap between technical cybersecurity and human factors, the TFVA protocol establishes human-empowered security as a vital component of trustworthy AI systems.', 'abstract_zh': '人工智能力量下的空前认知攻击使人类认知安全防护仍以设备为中心。本文介绍“先思考，再验证”（TFVA）协议，重新定位人类为“防火墙零号”，成为对抗AI驱动威胁的第一道防线。该协议基于五个运作原则：意识、完整性、判断、伦理责任和透明度（AIJET）。随机对照试验（n=151）显示，短暂3分钟的干预在认知安全任务表现上产生了统计意义上的显著改善，参与者与对照组相比绝对提高了7.87%。这些结果表明，基于原则的简短培训可以迅速增强人类抵御AI驱动的认知操纵的韧性。我们建议，通用AI平台将“先思考，再验证”作为标准提示，用可操作的流程替代被动警告，以促进可信和伦理的AI使用。通过弥合技术网络安全与人类因素之间的差距，TFVA协议确立了以人类为中心的安全机制对于可信AI系统的重要性。', 'title_zh': '先思考，始终验证：培训人类应对AI风险'}
{'arxiv_id': 'arXiv:2508.03711', 'title': 'A Social Data-Driven System for Identifying Estate-related Events and Topics', 'authors': 'Wenchuan Mu, Menglin Li, Kwan Hui Lim', 'link': 'https://arxiv.org/abs/2508.03711', 'abstract': 'Social media platforms such as Twitter and Facebook have become deeply embedded in our everyday life, offering a dynamic stream of localized news and personal experiences. The ubiquity of these platforms position them as valuable resources for identifying estate-related issues, especially in the context of growing urban populations. In this work, we present a language model-based system for the detection and classification of estate-related events from social media content. Our system employs a hierarchical classification framework to first filter relevant posts and then categorize them into actionable estate-related topics. Additionally, for posts lacking explicit geotags, we apply a transformer-based geolocation module to infer posting locations at the point-of-interest level. This integrated approach supports timely, data-driven insights for urban management, operational response and situational awareness.', 'abstract_zh': '社交媒体平台如Twitter和Facebook已深深嵌入我们的日常生活，提供了本地化新闻和个人体验的动态流。这些平台的普及使其成为识别房地产相关问题的重要资源，尤其是在城市人口增长的背景下。本文提出了一种基于语言模型的系统，用于从社交媒体内容中检测和分类房地产相关事件。我们的系统采用分层分类框架，首先筛选出相关的帖子，然后将其归类为可操作的房地产相关主题。此外，对于缺乏明确地理标记的帖子，我们应用基于变换器的地理定位模块，在兴趣点级别推断发布位置。这种集成方法支持及时的数据驱动洞察，助力城市管理和操作响应，以及态势感知。', 'title_zh': '基于社会数据驱动的 Estates 相关事件和话题识别系统'}
{'arxiv_id': 'arXiv:2508.03706', 'title': 'Controllable Surface Diffusion Generative Model for Neurodevelopmental Trajectories', 'authors': 'Zhenshan Xie, Levente Baljer, M. Jorge Cardoso, Emma Robinson', 'link': 'https://arxiv.org/abs/2508.03706', 'abstract': 'Preterm birth disrupts the typical trajectory of cortical neurodevelopment, increasing the risk of cognitive and behavioral difficulties. However, outcomes vary widely, posing a significant challenge for early prediction. To address this, individualized simulation offers a promising solution by modeling subject-specific neurodevelopmental trajectories, enabling the identification of subtle deviations from normative patterns that might act as biomarkers of risk. While generative models have shown potential for simulating neurodevelopment, prior approaches often struggle to preserve subject-specific cortical folding patterns or to reproduce region-specific morphological variations. In this paper, we present a novel graph-diffusion network that supports controllable simulation of cortical maturation. Using cortical surface data from the developing Human Connectome Project (dHCP), we demonstrate that the model maintains subject-specific cortical morphology while modeling cortical maturation sufficiently well to fool an independently trained age regression network, achieving a prediction accuracy of $0.85 \\pm 0.62$.', 'abstract_zh': '早产打断了皮层神经发育的典型轨迹，增加了认知和行为问题的风险。然而，结果差异较大，对早期预测构成了重大挑战。为此，个体化模拟提供了一种有前景的解决方案，通过建模个体特定的神经发育轨迹，能够识别出可能作为风险生物标志物的细微偏差。尽管生成模型在模拟神经发育方面显示出潜力，但先前的方法往往难以保留个体特定的皮层折叠模式或再现区域特异性形态学变异。在本文中，我们提出了一种新型图扩散网络，支持可控模拟皮层成熟。利用发育中的人类连接组项目（dHCP）的皮层表面数据，我们证明该模型能够保持个体特定的皮层形态，同时充分模拟皮层成熟，使一个独立训练的年龄回归网络误认为是真实的年龄数据，预测准确率为$0.85 \\pm 0.62$。', 'title_zh': '可控表面前进生成模型用于神经发育轨迹'}
{'arxiv_id': 'arXiv:2508.03700', 'title': 'MagicGUI: A Foundational Mobile GUI Agent with Scalable Data Pipeline and Reinforcement Fine-tuning', 'authors': 'Liujian Tang, Shaokang Dong, Yijia Huang, Minqi Xiang, Hongtao Ruan, Bin Wang, Shuo Li, Zhihui Cao, Hailiang Pang, Heng Kong, He Yang, Mingxu Chai, Zhilin Gao, Xingyu Liu, Yingnan Fu, Jiaming Liu, Tao Gui, Xuanjing Huang, Yu-Gang Jiang, Qi Zhang, Kang Wang, Yunke Zhang, Yuran Wang', 'link': 'https://arxiv.org/abs/2508.03700', 'abstract': 'This paper presents MagicGUI, a foundational mobile GUI agent designed to address critical challenges in perception, grounding, and reasoning within real-world mobile GUI environments. The framework is underpinned by following six key components: (1) a comprehensive and accurate dataset, constructed via the scalable GUI Data Pipeline, which aggregates the largest and most diverse GUI-centric multimodal data to date from open-source repositories, automated crawling, and targeted manual annotation; (2) enhanced perception and grounding capabilities, facilitating fine-grained multimodal alignment for UI element referencing, grounding, and screen comprehension; (3) a comprehensive and unified action space, encompassing both fundamental UI operations and complex interactive intents to support human-agent interactions; (4) planning-oriented reasoning mechanisms that enable the model to decompose complex user instructions into sequential actions with explicit intermediate meta-paln reasoning; (5) an iterative two-stage training procedure, combining large-scale continue pre-training on 7.8M samples with reinforcement fine-tuning utilizing a spatially enhanced composite reward and dual filtering strategy; and (6) competitive performance on both the proprietary Magic-RICH benchmark and over a dozen public benchmarks, achieving superior performance across GUI perception and agent tasks, while demonstrating robust generalization and real-world deployment potential in practical mobile GUI scenarios, as detailed in Figure 1.', 'abstract_zh': 'MagicGUI：一种用于解决移动GUI环境中感知、定位和推理关键挑战的基础移动GUI代理框架', 'title_zh': 'MagicGUI：一个具备扩展数据管道和 强化微调的基础移动GUI代理'}
{'arxiv_id': 'arXiv:2508.03696', 'title': 'PLA: Prompt Learning Attack against Text-to-Image Generative Models', 'authors': 'Xinqi Lyu, Yihao Liu, Yanjie Li, Bin Xiao', 'link': 'https://arxiv.org/abs/2508.03696', 'abstract': 'Text-to-Image (T2I) models have gained widespread adoption across various applications. Despite the success, the potential misuse of T2I models poses significant risks of generating Not-Safe-For-Work (NSFW) content. To investigate the vulnerability of T2I models, this paper delves into adversarial attacks to bypass the safety mechanisms under black-box settings. Most previous methods rely on word substitution to search adversarial prompts. Due to limited search space, this leads to suboptimal performance compared to gradient-based training. However, black-box settings present unique challenges to training gradient-driven attack methods, since there is no access to the internal architecture and parameters of T2I models. To facilitate the learning of adversarial prompts in black-box settings, we propose a novel prompt learning attack framework (PLA), where insightful gradient-based training tailored to black-box T2I models is designed by utilizing multimodal similarities. Experiments show that our new method can effectively attack the safety mechanisms of black-box T2I models including prompt filters and post-hoc safety checkers with a high success rate compared to state-of-the-art methods. Warning: This paper may contain offensive model-generated content.', 'abstract_zh': '基于文本到图像模型的安全性研究：黑盒设置下的对抗攻击方法', 'title_zh': 'PLA: 针对文本到图像生成模型的提示学习攻击'}
{'arxiv_id': 'arXiv:2508.02314', 'title': 'Large AI Models for Wireless Physical Layer', 'authors': 'Jiajia Guo, Yiming Cui, Shi Jin, Jun Zhang', 'link': 'https://arxiv.org/abs/2508.02314', 'abstract': 'Large artificial intelligence models (LAMs) are transforming wireless physical layer technologies through their robust generalization, multitask processing, and multimodal capabilities. This article reviews recent advancements in LAM applications for physical layer communications, addressing limitations of conventional AI-based approaches. LAM applications are classified into two strategies: leveraging pre-trained LAMs and developing native LAMs designed specifically for physical layer tasks. The motivations and key frameworks of these approaches are comprehensively examined through multiple use cases. Both strategies significantly improve performance and adaptability across diverse wireless scenarios. Future research directions, including efficient architectures, interpretability, standardized datasets, and collaboration between large and small models, are proposed to advance LAM-based physical layer solutions for next-generation communication systems.', 'abstract_zh': '大型人工智能模型（LAMs）正通过其强大的泛化能力、多任务处理能力和多模态能力，变革无线物理层技术。本文回顾了LAM在物理层通信中的最新应用进展，解决了传统基于AI的方法的局限性。LAM应用策略分为两类：利用预训练的LAM和为物理层任务专门设计的原生LAM。通过多种应用场景全面分析了这两种策略的动机和关键框架。两种策略均显著提升了在各种无线场景中的性能和适应性。提出了包括高效架构、可解释性、标准化数据集以及大模型与小模型的合作等未来研究方向，以推进基于LAM的物理层解决方案在下一代通信系统中的应用。', 'title_zh': '大型AI模型在无线物理层中的应用'}
{'arxiv_id': 'arXiv:2409.15173', 'title': 'Recommendation with Generative Models', 'authors': 'Yashar Deldjoo, Zhankui He, Julian McAuley, Anton Korikov, Scott Sanner, Arnau Ramisa, Rene Vidal, Maheswaran Sathiamoorthy, Atoosa Kasrizadeh, Silvia Milano, Francesco Ricci', 'link': 'https://arxiv.org/abs/2409.15173', 'abstract': 'Generative models are a class of AI models capable of creating new instances of data by learning and sampling from their statistical distributions. In recent years, these models have gained prominence in machine learning due to the development of approaches such as generative adversarial networks (GANs), variational autoencoders (VAEs), and transformer-based architectures such as GPT. These models have applications across various domains, such as image generation, text synthesis, and music composition. In recommender systems, generative models, referred to as Gen-RecSys, improve the accuracy and diversity of recommendations by generating structured outputs, text-based interactions, and multimedia content. By leveraging these capabilities, Gen-RecSys can produce more personalized, engaging, and dynamic user experiences, expanding the role of AI in eCommerce, media, and beyond.\nOur book goes beyond existing literature by offering a comprehensive understanding of generative models and their applications, with a special focus on deep generative models (DGMs) and their classification. We introduce a taxonomy that categorizes DGMs into three types: ID-driven models, large language models (LLMs), and multimodal models. Each category addresses unique technical and architectural advancements within its respective research area. This taxonomy allows researchers to easily navigate developments in Gen-RecSys across domains such as conversational AI and multimodal content generation. Additionally, we examine the impact and potential risks of generative models, emphasizing the importance of robust evaluation frameworks.', 'abstract_zh': '生成模型是一类能够通过学习和从其统计分布中采样来创建新数据实例的AI模型。近年来，随着生成对抗网络（GANs）、变分自编码器（VAEs）和基于变换器的架构（如GPT）的发展，这些模型在机器学习中获得了 prominence。生成模型在图像生成、文本合成和音乐创作等多个领域有着应用。在推荐系统中，生成模型，即Gen-RecSys，通过生成结构化输出、基于文本的交互和多媒体内容，来提高推荐的准确性和多样性。利用这些能力，Gen-RecSys能够提供更加个性化、互动和动态的用户体验，扩展AI在电子商务、媒体等领域的角色。\n\n我们的书籍超越了现有文献，提供了对生成模型及其应用的全面理解，特别关注深度生成模型（DGMs）及其分类。我们引入了一种分类法，将DGMs分为三大类别：ID驱动模型、大型语言模型（LLMs）和多模态模型。每类模型在其各自的研究领域内解决独特的技术和架构上的进步。该分类法使研究人员能够轻松导航跨对话AI和多模态内容生成等领域的Gen-RecSys发展。此外，我们还探讨了生成模型的影响及其潜在风险，并强调了稳健评估框架的重要性。', 'title_zh': '生成模型中的推荐方法'}
{'arxiv_id': 'arXiv:2312.10925', 'title': 'Delving Deeper Into Astromorphic Transformers', 'authors': 'Md Zesun Ahmed Mia, Malyaban Bal, Abhronil Sengupta', 'link': 'https://arxiv.org/abs/2312.10925', 'abstract': 'Preliminary attempts at incorporating the critical role of astrocytes - cells that constitute more than 50\\% of human brain cells - in brain-inspired neuromorphic computing remain in infancy. This paper seeks to delve deeper into various key aspects of neuron-synapse-astrocyte interactions to mimic self-attention mechanisms in Transformers. The cross-layer perspective explored in this work involves bioplausible modeling of Hebbian and presynaptic plasticities in neuron-astrocyte networks, incorporating effects of non-linearities and feedback along with algorithmic formulations to map the neuron-astrocyte computations to self-attention mechanism and evaluating the impact of incorporating bio-realistic effects from the machine learning application side. Our analysis on sentiment and image classification tasks (IMDB and CIFAR10 datasets) highlights the advantages of Astromorphic Transformers, offering improved accuracy and learning speed. Furthermore, the model demonstrates strong natural language generation capabilities on the WikiText-2 dataset, achieving better perplexity compared to conventional models, thus showcasing enhanced generalization and stability across diverse machine learning tasks.', 'abstract_zh': '初步尝试将星形胶质细胞的关键作用纳入类脑神经形态计算仍处于初级阶段。本文旨在深入探讨神经元-突触-星形胶质细胞相互作用的各个关键方面，以模拟Transformer中的自注意力机制。本研究从跨层视角出发，探索生物可能的Hebbian和前突触可塑性建模在神经元-星形胶质细胞网络中的应用，结合非线性和反馈效果以及算法公式，将神经元-星形胶质细胞计算映射到自注意力机制，并评估从机器学习应用端引入生物现实效果的影响。我们的分析表明，Astromorphic Transformer在情感分析和图像分类任务（IMDB和CIFAR10数据集）中表现出了优势，提供了更高的准确性和学习速度。此外，该模型在WikiText-2数据集上展示了强大的自然语言生成能力，困惑度优于传统模型，从而展示了其在多种机器学习任务中增强的泛化能力和稳定性。', 'title_zh': '深入探究星形变换器'}
