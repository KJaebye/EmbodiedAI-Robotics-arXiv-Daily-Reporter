# D-AWSIM: Distributed Autonomous Driving Simulator for Dynamic Map Generation Framework 

**Title (ZH)**: D-AWSIM：分布式自主驾驶模拟器及其用于动态地图生成框架 

**Authors**: Shunsuke Ito, Chaoran Zhao, Ryo Okamura, Takuya Azumi  

**Link**: [PDF](https://arxiv.org/pdf/2511.09080)  

**Abstract**: Autonomous driving systems have achieved significant advances, and full autonomy within defined operational design domains near practical deployment. Expanding these domains requires addressing safety assurance under diverse conditions. Information sharing through vehicle-to-vehicle and vehicle-to-infrastructure communication, enabled by a Dynamic Map platform built from vehicle and roadside sensor data, offers a promising solution. Real-world experiments with numerous infrastructure sensors incur high costs and regulatory challenges. Conventional single-host simulators lack the capacity for large-scale urban traffic scenarios. This paper proposes D-AWSIM, a distributed simulator that partitions its workload across multiple machines to support the simulation of extensive sensor deployment and dense traffic environments. A Dynamic Map generation framework on D-AWSIM enables researchers to explore information-sharing strategies without relying on physical testbeds. The evaluation shows that D-AWSIM increases throughput for vehicle count and LiDAR sensor processing substantially compared to a single-machine setup. Integration with Autoware demonstrates applicability for autonomous driving research. 

**Abstract (ZH)**: 自主驾驶系统已取得显著进步，并在定义的操作设计域内接近实际部署的全自主驾驶。扩展这些领域需要在多种条件下解决安全保证问题。通过车辆间和车辆与基础设施之间的通信共享信息，利用从车辆和路边传感器数据构建的动态地图平台提供了一种有前景的解决方案。实际基础设施传感器的广泛应用会带来高昂的成本和监管挑战。传统单机模拟器无法支持大规模城市交通场景。本文提出了一种分布式模拟器D-AWSIM，该模拟器将工作负载分配到多台机器上，以支持广泛的传感器部署和密集交通环境的模拟。D-AWSIM上的动态地图生成框架使研究人员能够在不依赖物理试验床的情况下探索信息共享策略。评估结果显示，与单机设置相比，D-AWSIM在车辆数量和LiDAR传感器处理方面的吞吐量显著提高。与Autoware的集成展示了其在自主驾驶研究中的应用潜力。 

---
# Practical and Performant Enhancements for Maximization of Algebraic Connectivity 

**Title (ZH)**: 具有良好代数连通性的实用高效增强方法 

**Authors**: Leonard Jung, Alan Papalia, Kevin Doherty, Michael Everett  

**Link**: [PDF](https://arxiv.org/pdf/2511.08694)  

**Abstract**: Long-term state estimation over graphs remains challenging as current graph estimation methods scale poorly on large, long-term graphs. To address this, our work advances a current state-of-the-art graph sparsification algorithm, maximizing algebraic connectivity (MAC). MAC is a sparsification method that preserves estimation performance by maximizing the algebraic connectivity, a spectral graph property that is directly connected to the estimation error. Unfortunately, MAC remains computationally prohibitive for online use and requires users to manually pre-specify a connectivity-preserving edge set. Our contributions close these gaps along three complementary fronts: we develop a specialized solver for algebraic connectivity that yields an average 2x runtime speedup; we investigate advanced step size strategies for MAC's optimization procedure to enhance both convergence speed and solution quality; and we propose automatic schemes that guarantee graph connectivity without requiring manual specification of edges. Together, these contributions make MAC more scalable, reliable, and suitable for real-time estimation applications. 

**Abstract (ZH)**: 长期图上状态估计仍然具有挑战性，因为当前的图估计方法在大型、长期的图上扩展性差。为了应对这一挑战，我们的工作改进了当前最先进的图稀疏化算法，最大化代数连通性（MAC）。MAC是一种通过最大化代数连通性（与估计误差直接相关的谱图性质）来保持估计性能的稀疏化方法。然而，MAC仍难以用于在线应用，并要求用户手动预先指定一个保持连通性的边集。我们的贡献从三个方面解决了这些缺陷：我们开发了一个专有的代数连通性求解器，平均提供了2倍的运行时间加速；我们研究了MAC优化过程中的高级步长策略，以提高收敛速度和解决方案质量；我们提出了一种自动方案，能够保证图的连通性而不必手动指定边。这些贡献使得MAC更具有可扩展性、可靠性和适用于实时估计应用。 

---
# Argus: Resilience-Oriented Safety Assurance Framework for End-to-End ADSs 

**Title (ZH)**: Argus: 面向端到端ADS的韧性安全保证框架 

**Authors**: Dingji Wang, You Lu, Bihuan Chen, Shuo Hao, Haowen Jiang, Yifan Tian, Xin Peng  

**Link**: [PDF](https://arxiv.org/pdf/2511.09032)  

**Abstract**: End-to-end autonomous driving systems (ADSs), with their strong capabilities in environmental perception and generalizable driving decisions, are attracting growing attention from both academia and industry. However, once deployed on public roads, ADSs are inevitably exposed to diverse driving hazards that may compromise safety and degrade system performance. This raises a strong demand for resilience of ADSs, particularly the capability to continuously monitor driving hazards and adaptively respond to potential safety violations, which is crucial for maintaining robust driving behaviors in complex driving scenarios.
To bridge this gap, we propose a runtime resilience-oriented framework, Argus, to mitigate the driving hazards, thus preventing potential safety violations and improving the driving performance of an ADS. Argus continuously monitors the trajectories generated by the ADS for potential hazards and, whenever the EGO vehicle is deemed unsafe, seamlessly takes control through a hazard mitigator. We integrate Argus with three state-of-the-art end-to-end ADSs, i.e., TCP, UniAD and VAD. Our evaluation has demonstrated that Argus effectively and efficiently enhances the resilience of ADSs, improving the driving score of the ADS by up to 150.30% on average, and preventing up to 64.38% of the violations, with little additional time overhead. 

**Abstract (ZH)**: 端到端自动驾驶系统（ADS）的运行时鲁棒性框架Argus：减轻驾驶风险与提升驾驶性能 

---
# Information-Driven Fault Detection and Identification for Multi-Agent Spacecraft Systems: Collaborative On-Orbit Inspection Mission 

**Title (ZH)**: 基于信息驱动的多智能体航天器系统故障检测与识别：协同在轨检查任务 

**Authors**: Akshita Gupta, Arna Bhardwaj, Yashwanth Kumar Nakka, Changrak Choi, Amir Rahmani  

**Link**: [PDF](https://arxiv.org/pdf/2511.08752)  

**Abstract**: This work presents a global-to-local, task-aware fault detection and identification (FDI) framework for multi-spacecraft systems conducting collaborative inspection missions in low Earth orbit. The inspection task is represented by a global information-driven cost functional that integrates the sensor model, spacecraft poses, and mission-level information-gain objectives. This formulation links guidance, control, and FDI by using the same cost function to drive both global task allocation and local sensing or motion decisions. Fault detection is achieved through comparisons between expected and observed task metrics, while higher-order cost-gradient measures enable the identification of faults among sensors, actuators, and state estimators. An adaptive thresholding mechanism captures the time-varying inspection geometry and dynamic mission conditions. Simulation results for representative multi-spacecraft inspection scenarios demonstrate the reliability of fault localization and classification under uncertainty, providing a unified, information-driven foundation for resilient autonomous inspection architectures. 

**Abstract (ZH)**: 一种面向低地球轨道多航天器协同探测任务的全局到局部、任务aware故障检测与识别框架 

---
# Evader-Agnostic Team-Based Pursuit Strategies in Partially-Observable Environments 

**Title (ZH)**: 部分可观测环境中无逃逸者假设的团队追捕策略 

**Authors**: Addison Kalanther, Daniel Bostwick, Chinmay Maheshwari, Shankar Sastry  

**Link**: [PDF](https://arxiv.org/pdf/2511.05812)  

**Abstract**: We consider a scenario where a team of two unmanned aerial vehicles (UAVs) pursue an evader UAV within an urban environment. Each agent has a limited view of their environment where buildings can occlude their field-of-view. Additionally, the pursuer team is agnostic about the evader in terms of its initial and final location, and the behavior of the evader. Consequently, the team needs to gather information by searching the environment and then track it to eventually intercept. To solve this multi-player, partially-observable, pursuit-evasion game, we develop a two-phase neuro-symbolic algorithm centered around the principle of bounded rationality. First, we devise an offline approach using deep reinforcement learning to progressively train adversarial policies for the pursuer team against fictitious evaders. This creates $k$-levels of rationality for each agent in preparation for the online phase. Then, we employ an online classification algorithm to determine a "best guess" of our current opponent from the set of iteratively-trained strategic agents and apply the best player response. Using this schema, we improved average performance when facing a random evader in our environment. 

**Abstract (ZH)**: 我们考虑一个场景，其中两只无人驾驶航空器（UAV）在城市环境中追逐一个逃逸的UAV。每个代理都有一个受限的视野，建筑物会阻挡其视野。此外，追击团队对逃逸者的位置及其行为一无所知。因此，团队需要通过搜索环境来收集信息，然后追踪这些信息以最终实施拦截。为了解决这个多玩家、部分可观测的追逐博弈问题，我们开发了一个以有限理性为核心原则的两阶段神经符号算法。首先，我们使用深度强化学习设计一个离线方法，逐步训练追击团队与虚构的逃逸者之间的对抗策略，从而为每个代理预设了$k$级理性。然后，我们使用在线分类算法来确定当前对手的最佳猜测，并应用最佳对抗策略。利用这种方案，在面对环境中的随机逃逸者时，我们改进了平均性能。 

---
# Breadth-First Search vs. Restarting Random Walks for Escaping Uninformed Heuristic Regions 

**Title (ZH)**: 广度优先搜索与重启随机游走逃离不知情启发式区域比较 

**Authors**: Daniel Platnick, Dawson Tomasz, Eamon Earl, Sourena Khanzadeh, Richard Valenzano  

**Link**: [PDF](https://arxiv.org/pdf/2511.09549)  

**Abstract**: Greedy search methods like Greedy Best-First Search (GBFS) and Enforced Hill-Climbing (EHC) often struggle when faced with Uninformed Heuristic Regions (UHRs) like heuristic local minima or plateaus. In this work, we theoretically and empirically compare two popular methods for escaping UHRs in breadth-first search (BrFS) and restarting random walks (RRWs). We first derive the expected runtime of escaping a UHR using BrFS and RRWs, based on properties of the UHR and the random walk procedure, and then use these results to identify when RRWs will be faster in expectation than BrFS. We then evaluate these methods for escaping UHRs by comparing standard EHC, which uses BrFS to escape UHRs, to variants of EHC called EHC-RRW, which use RRWs for that purpose. EHC-RRW is shown to have strong expected runtime guarantees in cases where EHC has previously been shown to be effective. We also run experiments with these approaches on PDDL planning benchmarks to better understand their relative effectiveness for escaping UHRs. 

**Abstract (ZH)**: 贪婪搜索方法如贪婪最佳优先搜索（GBFS）和强制爬坡搜索（EHC）在面对无信息启发式区域（UHRs）如启发式局部最小值或平台时常常表现出色受限。在本文中，我们从理论上和实验上比较了两种在广度优先搜索（BrFS）和重启随机游走（RRWs）中逃脱UHRs的方法。我们首先根据UHR的性质和随机游走过程的特性推导出使用BrFS和RRWs逃脱UHRs的期望运行时间，然后利用这些结果来识别在期望意义上RRWs比BrFS更快的情况。接着，我们通过将标准EHC与用于该目的的RRWs变体EHC-RRW进行比较来评估这些方法在逃脱UHRs方面的有效性。EHC-RRW在EHC之前已被证明有效的情况下展示了强的期望运行时间保证。我们还对此类方法进行了实验，研究它们在PDDL规划基准测试中的相对有效性，以更好地了解它们在逃脱UHRs方面的效果。 

---
# Robust and Diverse Multi-Agent Learning via Rational Policy Gradient 

**Title (ZH)**: 基于理性策略梯度的鲁棒且多样的多智能体学习 

**Authors**: Niklas Lauffer, Ameesh Shah, Micah Carroll, Sanjit A. Seshia, Stuart Russell, Michael Dennis  

**Link**: [PDF](https://arxiv.org/pdf/2511.09535)  

**Abstract**: Adversarial optimization algorithms that explicitly search for flaws in agents' policies have been successfully applied to finding robust and diverse policies in multi-agent settings. However, the success of adversarial optimization has been largely limited to zero-sum settings because its naive application in cooperative settings leads to a critical failure mode: agents are irrationally incentivized to self-sabotage, blocking the completion of tasks and halting further learning. To address this, we introduce Rationality-preserving Policy Optimization (RPO), a formalism for adversarial optimization that avoids self-sabotage by ensuring agents remain rational--that is, their policies are optimal with respect to some possible partner policy. To solve RPO, we develop Rational Policy Gradient (RPG), which trains agents to maximize their own reward in a modified version of the original game in which we use opponent shaping techniques to optimize the adversarial objective. RPG enables us to extend a variety of existing adversarial optimization algorithms that, no longer subject to the limitations of self-sabotage, can find adversarial examples, improve robustness and adaptability, and learn diverse policies. We empirically validate that our approach achieves strong performance in several popular cooperative and general-sum environments. Our project page can be found at this https URL. 

**Abstract (ZH)**: 对抗优化算法通过明确搜索代理政策中的缺陷，在多代理环境中已被成功用于发现 robust 和多样的政策。然而，对抗优化的成功主要局限于零和环境，因为在合作环境中其简单应用会导致一个关键的失败模式：代理被不理性地激励进行自我破坏，阻碍任务的完成并终止进一步的学习。为解决这一问题，我们引入了一种称为理性保留策略优化（RPO）的对抗优化形式主义，通过确保代理保持理性——即，他们的政策相对于某些可能的合作伙伴政策是优化的——来避免自我破坏。为了解决RPO，我们开发了理性策略梯度（RPG），这是一种训练代理在修改后的原游戏中最大化自身奖励的方法，其中我们使用对手塑造技术来优化对抗目标。RPG 使我们能够扩展多种现有的对抗优化算法，这些算法不再受自我破坏的限制，可以找到对抗示例，提高 robustness 和适应性，并学习多样的政策。我们实验证明，我们的方法在多种流行的协同和非零和环境中表现出色。我们的项目页面可以在以下链接访问：this https URL。 

---
# Consensus Sampling for Safer Generative AI 

**Title (ZH)**: 安全生成AI的共识采样方法 

**Authors**: Adam Tauman Kalai, Yael Tauman Kalai, Or Zamir  

**Link**: [PDF](https://arxiv.org/pdf/2511.09493)  

**Abstract**: Many approaches to AI safety rely on inspecting model outputs or activations, yet certain risks are inherently undetectable by inspection alone. We propose a complementary, architecture-agnostic approach that enhances safety through the aggregation of multiple generative models, with the aggregated model inheriting its safety from the safest subset of a given size among them. Specifically, we present a consensus sampling algorithm that, given $k$ models and a prompt, achieves risk competitive with the average risk of the safest $s$ of the $k$ models, where $s$ is a chosen parameter, while abstaining when there is insufficient agreement between them. The approach leverages the models' ability to compute output probabilities, and we bound the probability of abstention when sufficiently many models are safe and exhibit adequate agreement. The algorithm is inspired by the provable copyright protection algorithm of Vyas et al. (2023). It requires some overlap among safe models, offers no protection when all models are unsafe, and may accumulate risk over repeated use. Nonetheless, our results provide a new, model-agnostic approach for AI safety by amplifying safety guarantees from an unknown subset of models within a collection to that of a single reliable model. 

**Abstract (ZH)**: 一种通过聚合多个生成模型增强AI安全性的新方法：基于最安全模型子集的共识采样算法 

---
# What We Don't C: Representations for scientific discovery beyond VAEs 

**Title (ZH)**: What We Don't C: 科学发现中超出VAEs的表示方法 

**Authors**: Brian Rogers, Micah Bowles, Chris J. Lintott, Steve Croft  

**Link**: [PDF](https://arxiv.org/pdf/2511.09433)  

**Abstract**: Accessing information in learned representations is critical for scientific discovery in high-dimensional domains. We introduce a novel method based on latent flow matching with classifier-free guidance that disentangles latent subspaces by explicitly separating information included in conditioning from information that remains in the residual representation. Across three experiments -- a synthetic 2D Gaussian toy problem, colored MNIST, and the Galaxy10 astronomy dataset -- we show that our method enables access to meaningful features of high dimensional data. Our results highlight a simple yet powerful mechanism for analyzing, controlling, and repurposing latent representations, providing a pathway toward using generative models for scientific exploration of what we don't capture, consider, or catalog. 

**Abstract (ZH)**: 基于潜在流匹配和无分类引导的方法在高维领域通过分解潜在子空间以分离条件信息和残差表示中的信息，实现高维数据有意义特征的访问 

---
# Not Everything That Counts Can Be Counted: A Case for Safe Qualitative AI 

**Title (ZH)**: 计不可尽，质不可量：一种关于安全定性AI的论点 

**Authors**: Stine Beltoft, Lukas Galke  

**Link**: [PDF](https://arxiv.org/pdf/2511.09325)  

**Abstract**: Artificial intelligence (AI) and large language models (LLM) are reshaping science, with most recent advances culminating in fully-automated scientific discovery pipelines. But qualitative research has been left behind. Researchers in qualitative methods are hesitant about AI adoption. Yet when they are willing to use AI at all, they have little choice but to rely on general-purpose tools like ChatGPT to assist with interview interpretation, data annotation, and topic modeling - while simultaneously acknowledging these system's well-known limitations of being biased, opaque, irreproducible, and privacy-compromising. This creates a critical gap: while AI has substantially advanced quantitative methods, the qualitative dimensions essential for meaning-making and comprehensive scientific understanding remain poorly integrated. We argue for developing dedicated qualitative AI systems built from the ground up for interpretive research. Such systems must be transparent, reproducible, and privacy-friendly. We review recent literature to show how existing automated discovery pipelines could be enhanced by robust qualitative capabilities, and identify key opportunities where safe qualitative AI could advance multidisciplinary and mixed-methods research. 

**Abstract (ZH)**: 人工智能（AI）和大型语言模型（LLM）正在重塑科学，最近的进展 culminating 在完全自动化的科学发现流程中，但定性研究却被忽略了。使用定性方法的研究人员对AI的采用持犹豫态度。然而，当他们愿意使用AI时，他们几乎没有选择，只能依赖像ChatGPT这样的通用工具来协助访谈解释、数据标注和主题建模——同时承认这些系统的已知限制，如偏见、不透明、不可再现和侵犯隐私。这造成了一个关键缺口：虽然AI在量化方法方面取得了显著进展，但进行意义建构和全面科学理解所必需的定性维度仍未得到充分整合。我们主张开发从头构建的专门用于诠释研究的定性AI系统。此类系统必须透明、可再现且保护隐私。我们回顾近期文献，以展示现有的自动化发现流程如何通过增强的定性能力得到增强，并确定安全的定性AI如何促进跨学科和混合方法研究的关键机会。 

---
# HyperD: Hybrid Periodicity Decoupling Framework for Traffic Forecasting 

**Title (ZH)**: HyperD: 结合周期性解耦框架用于交通预测 

**Authors**: Minlan Shao, Zijian Zhang, Yili Wang, Yiwei Dai, Xu Shen, Xin Wang  

**Link**: [PDF](https://arxiv.org/pdf/2511.09275)  

**Abstract**: Accurate traffic forecasting plays a vital role in intelligent transportation systems, enabling applications such as congestion control, route planning, and urban mobility this http URL, traffic forecasting remains challenging due to two key factors: (1) complex spatial dependencies arising from dynamic interactions between road segments and traffic sensors across the network, and (2) the coexistence of multi-scale periodic patterns (e.g., daily and weekly periodic patterns driven by human routines) with irregular fluctuations caused by unpredictable events (e.g., accidents, weather, or construction). To tackle these challenges, we propose HyperD (Hybrid Periodic Decoupling), a novel framework that decouples traffic data into periodic and residual components. The periodic component is handled by the Hybrid Periodic Representation Module, which extracts fine-grained daily and weekly patterns using learnable periodic embeddings and spatial-temporal attention. The residual component, which captures non-periodic, high-frequency fluctuations, is modeled by the Frequency-Aware Residual Representation Module, leveraging complex-valued MLP in frequency domain. To enforce semantic separation between the two components, we further introduce a Dual-View Alignment Loss, which aligns low-frequency information with the periodic branch and high-frequency information with the residual branch. Extensive experiments on four real-world traffic datasets demonstrate that HyperD achieves state-of-the-art prediction accuracy, while offering superior robustness under disturbances and improved computational efficiency compared to existing methods. 

**Abstract (ZH)**: 基于混合周期解耦的交通流量准确预测方法 

---
# MedFuse: Multiplicative Embedding Fusion For Irregular Clinical Time Series 

**Title (ZH)**: MedFuse: 不规则临床时间序列的乘性嵌入融合 

**Authors**: Yi-Hsien Hsieh, Ta-Jung Chien, Chun-Kai Huang, Shao-Hua Sun, Che Lin  

**Link**: [PDF](https://arxiv.org/pdf/2511.09247)  

**Abstract**: Clinical time series derived from electronic health records (EHRs) are inherently irregular, with asynchronous sampling, missing values, and heterogeneous feature dynamics. While numerical laboratory measurements are highly informative, existing embedding strategies usually combine feature identity and value embeddings through additive operations, which constrains their ability to capture value-dependent feature interactions. We propose MedFuse, a framework for irregular clinical time series centered on the MuFuse (Multiplicative Embedding Fusion) module. MuFuse fuses value and feature embeddings through multiplicative modulation, preserving feature-specific information while modeling higher-order dependencies across features. Experiments on three real-world datasets covering both intensive and chronic care show that MedFuse consistently outperforms state-of-the-art baselines on key predictive tasks. Analysis of the learned representations further demonstrates that multiplicative fusion enhances expressiveness and supports cross-dataset pretraining. These results establish MedFuse as a generalizable approach for modeling irregular clinical time series. 

**Abstract (ZH)**: 来自电子健康记录的临床时间序列本质上是不规则的，具有异步采样、缺失值和异质特征动态。虽然数值实验室测量数据高度信息丰富，现有嵌入策略通常通过加法操作结合特征标识和值嵌入，限制了其捕捉值依赖特征相互作用的能力。我们提出MedFuse框架，该框架以MuFuse（乘法嵌入融合）模块为中心，通过乘法调制融合值和特征嵌入，保留特征特定信息并建模跨特征的高阶依赖关系。实验结果表明，MedFuse在三个涵盖急性与慢性护理的真实世界数据集上一致地优于最先进的基线方法。进一步的研究表明，乘法融合增强了表达能力并支持跨数据集预训练。这些结果确立了MedFuse作为一种可泛化的不规则临床时间序列建模方法的地位。 

---
# Perspectives on a Reliability Monitoring Framework for Agentic AI Systems 

**Title (ZH)**: 代理人工智能系统可靠性监控框架的观点分析 

**Authors**: Niclas Flehmig, Mary Ann Lundteigen, Shen Yin  

**Link**: [PDF](https://arxiv.org/pdf/2511.09178)  

**Abstract**: The implementation of agentic AI systems has the potential of providing more helpful AI systems in a variety of applications. These systems work autonomously towards a defined goal with reduced external control. Despite their potential, one of their flaws is the insufficient reliability which makes them especially unsuitable for high-risk domains such as healthcare or process industry. Unreliable systems pose a risk in terms of unexpected behavior during operation and mitigation techniques are needed. In this work, we derive the main reliability challenges of agentic AI systems during operation based on their characteristics. We draw the connection to traditional AI systems and formulate a fundamental reliability challenge during operation which is inherent to traditional and agentic AI systems. As our main contribution, we propose a two-layered reliability monitoring framework for agentic AI systems which consists of a out-of-distribution detection layer for novel inputs and AI transparency layer to reveal internal operations. This two-layered monitoring approach gives a human operator the decision support which is needed to decide whether an output is potential unreliable or not and intervene. This framework provides a foundation for developing mitigation techniques to reduce risk stemming from uncertain reliability during operation. 

**Abstract (ZH)**: 基于代理AI系统的实施有可能在多种应用中提供更具帮助性的AI系统。这些系统自主朝着定义的目标工作，并减少外部控制。尽管如此，它们的一个缺点是可靠性不足，特别是在医疗保健或过程工业等高风险领域尤其不适合。不可靠性系统在运行过程中可能存在意外行为的风险，需要采取缓解措施。在本工作中，我们根据其特性推导出代理AI系统在运行过程中主要的可靠性挑战。我们将这些挑战与传统AI系统联系起来，并制定了一个适用于传统和代理AI系统的根本性运行可靠性挑战。作为我们主要的贡献，我们提出了一种两层式可靠性监控框架，包括一个用于新颖输入的离群值检测层和一个揭示内部操作的AI透明度层。这种两层式监控方法为人类操作员提供了必要的决策支持，以判断输出是否可能不可靠并及时干预。该框架为开发减少不确定可靠性带来的风险的缓解技术奠定了基础。 

---
# ProBench: Benchmarking GUI Agents with Accurate Process Information 

**Title (ZH)**: ProBench: 基于准确进程信息的GUI代理性能评估 

**Authors**: Leyang Yang, Ziwei Wang, Xiaoxuan Tang, Sheng Zhou, Dajun Chen, Wei Jiang, Yong Li  

**Link**: [PDF](https://arxiv.org/pdf/2511.09157)  

**Abstract**: With the deep integration of artificial intelligence and interactive technology, Graphical User Interface (GUI) Agent, as the carrier connecting goal-oriented natural language and real-world devices, has received widespread attention from the community. Contemporary benchmarks aim to evaluate the comprehensive capabilities of GUI agents in GUI operation tasks, generally determining task completion solely by inspecting the final screen state. However, GUI operation tasks consist of multiple chained steps while not all critical information is presented in the final few pages. Although a few research has begun to incorporate intermediate steps into evaluation, accurately and automatically capturing this process information still remains an open challenge. To address this weakness, we introduce ProBench, a comprehensive mobile benchmark with over 200 challenging GUI tasks covering widely-used scenarios. Remaining the traditional State-related Task evaluation, we extend our dataset to include Process-related Task and design a specialized evaluation method. A newly introduced Process Provider automatically supplies accurate process information, enabling presice assessment of agent's performance. Our evaluation of advanced GUI agents reveals significant limitations for real-world GUI scenarios. These shortcomings are prevalent across diverse models, including both large-scale generalist models and smaller, GUI-specific models. A detailed error analysis further exposes several universal problems, outlining concrete directions for future improvements. 

**Abstract (ZH)**: 随着人工智能与交互技术的深度融合，图形用户界面（GUI）代理作为连接目标导向自然语言和现实世界设备的载体，受到了学术界的广泛关注。当代基准测试旨在评估GUI代理在GUI操作任务中的综合能力，通常仅通过检查最终屏幕状态来判断任务完成情况。然而，GUI操作任务包含多个链式步骤，而并非所有关键信息都体现在最后几页中。虽有少量研究开始将中间步骤纳入评估范围，但准确且自动地捕获这一过程信息仍然是一个待解决问题。为解决这一不足，我们引入了ProBench，这是一个包含超过200个具有挑战性的GUI任务的全面移动基准，涵盖了广泛使用的情景。我们延续传统的状态相关任务评估方法，扩展了数据集以包括过程相关任务，并设计了专门的评估方法。新引入的过程提供商自动提供准确的过程信息，从而精确评估代理的表现。我们的高级GUI代理评估揭示了在真实世界GUI情景中的显著局限性。这些不足出现在多种模型中，包括大规模通用模型和较小的、专门针对GUI的模型。详细错误分析进一步揭示了几种普遍存在的问题，指出了未来改进的具体方向。 

---
# Heterogeneous Graph Neural Networks for Assumption-Based Argumentation 

**Title (ZH)**: 基于假设的论证中的异质图神经网络 

**Authors**: Preesha Gehlot, Anna Rapberger, Fabrizio Russo, Francesca Toni  

**Link**: [PDF](https://arxiv.org/pdf/2511.08982)  

**Abstract**: Assumption-Based Argumentation (ABA) is a powerful structured argumentation formalism, but exact computation of extensions under stable semantics is intractable for large frameworks. We present the first Graph Neural Network (GNN) approach to approximate credulous acceptance in ABA. To leverage GNNs, we model ABA frameworks via a dependency graph representation encoding assumptions, claims and rules as nodes, with heterogeneous edge labels distinguishing support, derive and attack relations. We propose two GNN architectures - ABAGCN and ABAGAT - that stack residual heterogeneous convolution or attention layers, respectively, to learn node embeddings. Our models are trained on the ICCMA 2023 benchmark, augmented with synthetic ABAFs, with hyperparameters optimised via Bayesian search. Empirically, both ABAGCN and ABAGAT outperform a state-of-the-art GNN baseline that we adapt from the abstract argumentation literature, achieving a node-level F1 score of up to 0.71 on the ICCMA instances. Finally, we develop a sound polynomial time extension-reconstruction algorithm driven by our predictor: it reconstructs stable extensions with F1 above 0.85 on small ABAFs and maintains an F1 of about 0.58 on large frameworks. Our work opens new avenues for scalable approximate reasoning in structured argumentation. 

**Abstract (ZH)**: 基于假设的论辩（假设论辩）是一种强大的结构化论辩形式化方法，但在大规模框架下，精确计算在稳定语义下的结论是不可行的。我们提出了首个使用图神经网络（GNN）来近似估计假设论辩中的无拘束接受度的方法。为了利用GNN，我们将假设论辩框架通过依赖图表示进行建模，其中假设、主张和规则作为节点，异质边标签区分支持、推出和攻击关系。我们提出了两种GNN架构——ABAGCN和ABAGAT，分别通过堆叠残差异质卷积层或注意力层来学习节点嵌入。我们的模型在ICCMACM 2023基准数据集上进行训练，数据集通过合成的论辩框架进行扩充，并通过贝叶斯搜索优化超参数。实验结果显示，ABAGCN和ABAGAT在ICCMACM实例上优于我们从抽象论辩文献中调整的最先进的GNN基线，节点级别F1分数达到0.71。最后，我们开发了一种由我们的预测器驱动的正确多项式时间扩展重构算法，该算法在小规模论辩框架上重构稳定扩展的F1分数超过0.85，并在大规模框架上保持F1分数约为0.58。我们的工作为结构化论辩中的可扩展近似推理开辟了新的途径。 

---
# A Research on Business Process Optimisation Model Integrating AI and Big Data Analytics 

**Title (ZH)**: 基于AI和大数据分析的业务流程优化模型研究 

**Authors**: Di Liao, Ruijia Liang, Ziyi Ye  

**Link**: [PDF](https://arxiv.org/pdf/2511.08934)  

**Abstract**: With the deepening of digital transformation, business process optimisation has become the key to improve the competitiveness of enterprises. This study constructs a business process optimisation model integrating artificial intelligence and big data to achieve intelligent management of the whole life cycle of processes. The model adopts a three-layer architecture incorporating data processing, AI algorithms, and business logic to enable real-time process monitoring and optimization. Through distributed computing and deep learning techniques, the system can handle complex business scenarios while maintaining high performance and reliability. Experimental validation across multiple enterprise scenarios shows that the model shortens process processing time by 42%, improves resource utilisation by 28%, and reduces operating costs by 35%. The system maintained 99.9% availability under high concurrent loads. The research results have important theoretical and practical value for promoting the digital transformation of enterprises, and provide new ideas for improving the operational efficiency of enterprises. 

**Abstract (ZH)**: 随着数字化转型的深化，业务流程优化已成为提升企业竞争力的关键。本研究构建了一个集成人工智能和大数据的业务流程优化模型，以实现业务流程全生命周期的智能管理。该模型采用三层架构，包括数据处理、AI算法和业务逻辑，以实现实时流程监控和优化。通过分布式计算和深度学习技术，系统能够在复杂业务场景下保持高性能和高可靠性。在多个企业场景下的实验验证表明，该模型将流程处理时间缩短了42%，资源利用率提高了28%，运营成本降低了35%。在高并发负载下，系统保持了99.9%的可用性。研究结果对于推动企业的数字化转型具有重要的理论和实用价值，并为提高企业运营效率提供了新的思路。 

---
# The Double Contingency Problem: AI Recursion and the Limits of Interspecies Understanding 

**Title (ZH)**: 双重 contingency问题：AI递归与跨物种理解的限度 

**Authors**: Graham L. Bishop  

**Link**: [PDF](https://arxiv.org/pdf/2511.08927)  

**Abstract**: Current bioacoustic AI systems achieve impressive cross-species performance by processing animal communication through transformer architectures, foundation model paradigms, and other computational approaches. However, these approaches overlook a fundamental question: what happens when one form of recursive cognition--AI systems with their attention mechanisms, iterative processing, and feedback loops--encounters the recursive communicative processes of other species? Drawing on philosopher Yuk Hui's work on recursivity and contingency, I argue that AI systems are not neutral pattern detectors but recursive cognitive agents whose own information processing may systematically obscure or distort other species' communicative structures. This creates a double contingency problem: each species' communication emerges through contingent ecological and evolutionary conditions, while AI systems process these signals through their own contingent architectural and training conditions. I propose that addressing this challenge requires reconceptualizing bioacoustic AI from universal pattern recognition toward diplomatic encounter between different forms of recursive cognition, with implications for model design, evaluation frameworks, and research methodologies. 

**Abstract (ZH)**: 当前的生物声学AI系统通过变压器架构、基础模型范式和其他计算方法在不同物种间实现了令人印象深刻的性能，但这些方法忽视了一个基本问题：当一种递归认知形式——具有注意力机制、迭代处理和反馈循环的AI系统——遇到其他物种的递归通讯过程时会发生什么？借鉴哲学家Yuk Hui关于递归和偶然性的探讨，我认为AI系统不仅是中立的模式检测器，而是递归认知代理，其自身的信息处理可能系统性地模糊或扭曲其他物种的通讯结构。这造成了双重偶然性问题：每个物种的通讯都是在偶然的生态和进化条件下产生的，而AI系统则是通过其自身的偶然架构和训练条件来处理这些信号。我认为解决这一挑战需要从普遍的模式识别重新构想生物声学AI，转向不同形式递归认知之间的外交相遇，对于模型设计、评估框架和研究方法都有重要影响。 

---
# Neural Value Iteration 

**Title (ZH)**: 神经值迭代 

**Authors**: Yang You, Ufuk Çakır, Alex Schutz, Robert Skilton, Nick Hawes  

**Link**: [PDF](https://arxiv.org/pdf/2511.08825)  

**Abstract**: The value function of a POMDP exhibits the piecewise-linear-convex (PWLC) property and can be represented as a finite set of hyperplanes, known as $\alpha$-vectors. Most state-of-the-art POMDP solvers (offline planners) follow the point-based value iteration scheme, which performs Bellman backups on $\alpha$-vectors at reachable belief points until convergence. However, since each $\alpha$-vector is $|S|$-dimensional, these methods quickly become intractable for large-scale problems due to the prohibitive computational cost of Bellman backups. In this work, we demonstrate that the PWLC property allows a POMDP's value function to be alternatively represented as a finite set of neural networks. This insight enables a novel POMDP planning algorithm called \emph{Neural Value Iteration}, which combines the generalization capability of neural networks with the classical value iteration framework. Our approach achieves near-optimal solutions even in extremely large POMDPs that are intractable for existing offline solvers. 

**Abstract (ZH)**: 部分线性凸值函数的Partially Observable Markov Decision Process的值函数可以表示为有限个超平面的集合，即α向量。大多数最先进的POMDP求解器（离线规划器）遵循基于点的值迭代方案，在可达信念点上进行贝尔曼备份，直到收敛。然而，由于每个α向量都是|S|维的，这些方法对于大规模问题由于贝尔曼备份的计算成本高昂而变得不可行。在本工作中，我们证明部分线性凸性允许POMDP的值函数被表示为有限个神经网络的集合。这一洞察促进了名为Neural Value Iteration的新型POMDP规划算法，该算法结合了神经网络的泛化能力和经典的值迭代框架。我们的方法即使在现有离线求解器无法处理的极大POMDP中也能近似获得最优解。 

---
# Vector Symbolic Algebras for the Abstraction and Reasoning Corpus 

**Title (ZH)**: 向量符号代数用于抽象与推理语料库 

**Authors**: Isaac Joffe, Chris Eliasmith  

**Link**: [PDF](https://arxiv.org/pdf/2511.08747)  

**Abstract**: The Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI) is a generative, few-shot fluid intelligence benchmark. Although humans effortlessly solve ARC-AGI, it remains extremely difficult for even the most advanced artificial intelligence systems. Inspired by methods for modelling human intelligence spanning neuroscience to psychology, we propose a cognitively plausible ARC-AGI solver. Our solver integrates System 1 intuitions with System 2 reasoning in an efficient and interpretable process using neurosymbolic methods based on Vector Symbolic Algebras (VSAs). Our solver works by object-centric program synthesis, leveraging VSAs to represent abstract objects, guide solution search, and enable sample-efficient neural learning. Preliminary results indicate success, with our solver scoring 10.8% on ARC-AGI-1-Train and 3.0% on ARC-AGI-1-Eval. Additionally, our solver performs well on simpler benchmarks, scoring 94.5% on Sort-of-ARC and 83.1% on 1D-ARC -- the latter outperforming GPT-4 at a tiny fraction of the computational cost. Importantly, our approach is unique; we believe we are the first to apply VSAs to ARC-AGI and have developed the most cognitively plausible ARC-AGI solver yet. Our code is available at: this https URL. 

**Abstract (ZH)**: 人工通用 intelligence 的抽象和推理语料库（ARC-AGI）是一种生成式、少样本流式智能基准。尽管人类轻松解决 ARC-AGI，但对于最先进的 AI 系统来说，它仍然极为困难。借鉴涵盖神经科学到心理学的人类智能建模方法，我们提出了一种认知合理的 ARC-AGI 解决方案。我们的解决方案通过基于向量符号代数（VSAs）的神经符号方法，将 System 1 直觉与 System 2 推理高效且可解释地结合在一起。我们的解决方案通过基于对象的程序合成工作，利用 VSAs 表征抽象对象、指导解决方案搜索并实现样本高效神经学习。初步结果表明，我们的解决方案在 ARC-AGI-1-Train 上得分为 10.8%，在 ARC-AGI-1-Eval 上得分为 3.0%。此外，我们的解决方案在更简单的基准测试中表现良好，在 Sort-of-ARC 上得分为 94.5%，在 1D-ARC 上得分为 83.1%，后者在极低的计算成本下优于 GPT-4。重要的是，我们的方法独树一帜；我们认为我们是首次将 VSAs 应用于 ARC-AGI，并且已开发出迄今为止最符合认知的 ARC-AGI 解决方案。我们的代码可在此处获取：this https URL。 

---
# Digital Co-Founders: Transforming Imagination into Viable Solo Business via Agentic AI 

**Title (ZH)**: 数字联合创始人：通过代理人工智能将想象转化为可行的独立业务 

**Authors**: Farhad Rezazadeh, Pegah Bonehgazy  

**Link**: [PDF](https://arxiv.org/pdf/2511.09533)  

**Abstract**: This paper investigates how individual entrepreneurs can turn creative ideas into successful solo businesses in an era increasingly shaped by Artificial Intelligence (AI) agents. It highlights the key steps that connect personal vision, structured experimentation, and lasting value creation, and shows how AI agents can act as digital co-founders throughout this journey. Building on research in entrepreneurship, creativity, and innovation, we present a framework with three key stages: (1) Imagination shaping, where vague goals become clear value propositions, supported by AI agents that help with market scanning, idea refinement, and rapid concept generation; (2) Reality testing, where these ideas are tested through low-cost experiments, structured feedback loops, and efficient execution, with AI agents automating tasks such as prototyping, content creation, customer interaction, and data analysis; and (3) Reality scaling, where successful ideas are transformed into repeatable processes, scalable market strategies, and long-term business models, increasingly operated and optimized by autonomous or semi-autonomous AI workflows. We focus on the specific context of solopreneurship, characterized by limited human resources, complete accountability for decision-making, and a strong association between the founder's identity and the business. The framework clearly identifies key enabling factors such as mental adaptability, effective planning, and successful human-AI collaboration within digital ecosystems. It also thoughtfully addresses ongoing challenges, like uncertainty and cognitive overload, which are heightened by our constant connectivity. 

**Abstract (ZH)**: 本研究探讨了个创业人士如何在日益受到人工智能代理影响的时代将创造性想法转化为成功的单人企业。它强调了将个人愿景、结构化实验和持久价值创造联系起来的关键步骤，并展示了人工智能代理在整个旅程中作为数字联合创始人发挥作用的方式。基于创业、创造力和创新方面的研究，我们提出了一种具有三个关键阶段的框架：（1）想象塑造，其中模糊的目标变为清晰的价值主张，并有辅助市场调查、想法细化和快速概念生成的人工智能代理的支持；（2）现实测试，其中这些想法通过低成本实验、结构化的反馈循环和高效执行进行测试，人工智能代理自动化原型制作、内容创作、客户互动和数据分析等任务；（3）现实扩展，其中成功的想法被转化为可重复的过程、可扩展的市场策略和长期的企业模型，越来越多地由自主或半自主的人工智能工作流操作和优化。我们重点关注单人创业的具体背景，其特征为有限的人力资源、决策的全面负责以及创始人身份与企业之间的强烈关联。该框架明确界定了关键的促成因素，如心理适应性、有效规划以及数字生态系统中的人机协作。它还仔细考虑了持续存在的挑战，如不确定性与认知超载，这些挑战因我们不断的技术连接而加剧。 

---
# Enhancing Password Security Through a High-Accuracy Scoring Framework Using Random Forests 

**Title (ZH)**: 利用随机森林构建高精度评分框架以增强密码安全 

**Authors**: Muhammed El Mustaqeem Mazelan, Noor Hazlina Abdul, Nouar AlDahoul  

**Link**: [PDF](https://arxiv.org/pdf/2511.09492)  

**Abstract**: Password security plays a crucial role in cybersecurity, yet traditional password strength meters, which rely on static rules like character-type requirements, often fail. Such methods are easily bypassed by common password patterns (e.g., 'P@ssw0rd1!'), giving users a false sense of security. To address this, we implement and evaluate a password strength scoring system by comparing four machine learning models: Random Forest (RF), Support Vector Machine (SVM), a Convolutional Neural Network (CNN), and Logistic Regression with a dataset of over 660,000 real-world passwords. Our primary contribution is a novel hybrid feature engineering approach that captures nuanced vulnerabilities missed by standard metrics. We introduce features like leetspeak-normalized Shannon entropy to assess true randomness, pattern detection for keyboard walks and sequences, and character-level TF-IDF n-grams to identify frequently reused substrings from breached password datasets. our RF model achieved superior performance, achieving 99.12% accuracy on a held-out test set. Crucially, the interpretability of the Random Forest model allows for feature importance analysis, providing a clear pathway to developing security tools that offer specific, actionable feedback to users. This study bridges the gap between predictive accuracy and practical usability, resulting in a high-performance scoring system that not only reduces password-based vulnerabilities but also empowers users to make more informed security decisions. 

**Abstract (ZH)**: 密码安全性在网络安全中起着至关重要的作用，然而依赖于字符类型要求等静态规则的传统密码强度测量方法往往效果不佳。这些方法容易被常见的密码模式（如“P@ssw0rd1!”）绕过，给用户造成虚假的安全感。为解决这一问题，我们通过将超过660,000个真实密码的大规模数据集与四种机器学习模型（随机森林、支持向量机、卷积神经网络和逻辑回归）进行对比，实现并评估了一种密码强度评分系统。我们的主要贡献是一种新颖的混合特征工程方法，能够捕捉标准度量忽视的细微漏洞。我们引入了诸如Leetspeak归一化香农熵来评估真正的随机性、键盘行走和序列的模式检测，以及基于字符级TF-IDF n-克隆来识别泄露密码数据集中频繁 reuse 的子字符串特征。我们的随机森林模型表现 superior， achieved 99.12% 的准确率。至关重要的是，随机森林模型的可解释性使得可以进行特征重要性分析，为用户提供具体的、可行的安全反馈提供明确的途径。这项研究弥补了预测准确性和实际可用性之间的差距，从而生成了一个高性能的评分系统，不仅能减少基于密码的漏洞，还能让用户做出更加明智的安全决策。 

---
# A general framework for adaptive nonparametric dimensionality reduction 

**Title (ZH)**: 自适应非参数降维的通用框架 

**Authors**: Antonio Di Noia, Federico Ravenda, Antonietta Mira  

**Link**: [PDF](https://arxiv.org/pdf/2511.09486)  

**Abstract**: Dimensionality reduction is a fundamental task in modern data science. Several projection methods specifically tailored to take into account the non-linearity of the data via local embeddings have been proposed. Such methods are often based on local neighbourhood structures and require tuning the number of neighbours that define this local structure, and the dimensionality of the lower-dimensional space onto which the data are projected. Such choices critically influence the quality of the resulting embedding. In this paper, we exploit a recently proposed intrinsic dimension estimator which also returns the optimal locally adaptive neighbourhood sizes according to some desirable criteria. In principle, this adaptive framework can be employed to perform an optimal hyper-parameter tuning of any dimensionality reduction algorithm that relies on local neighbourhood structures. Numerical experiments on both real-world and simulated datasets show that the proposed method can be used to significantly improve well-known projection methods when employed for various learning tasks, with improvements measurable through both quantitative metrics and the quality of low-dimensional visualizations. 

**Abstract (ZH)**: 局部自适应维数递减：一种基于内在维数估计的方法 

---
# Algorithmic Advice as a Strategic Signal on Competitive Markets 

**Title (ZH)**: 算法建议作为竞争力市场中的战略信号 

**Authors**: Tobias R. Rebholz, Maxwell Uphoff, Christian H. R. Bernges, Florian Scholten  

**Link**: [PDF](https://arxiv.org/pdf/2511.09454)  

**Abstract**: As algorithms increasingly mediate competitive decision-making, their influence extends beyond individual outcomes to shaping strategic market dynamics. In two preregistered experiments, we examined how algorithmic advice affects human behavior in classic economic games with unique, non-collusive, and analytically traceable equilibria. In Experiment 1 (N = 107), participants played a Bertrand price competition with individualized or collective algorithmic recommendations. Initially, collusively upward-biased advice increased prices, particularly when individualized, but prices gradually converged toward equilibrium over the course of the experiment. However, participants avoided setting prices above the algorithm's recommendation throughout the experiment, suggesting that advice served as a soft upper bound for acceptable prices. In Experiment 2 (N = 129), participants played a Cournot quantity competition with equilibrium-aligned or strategically biased algorithmic recommendations. Here, individualized equilibrium advice supported stable convergence, whereas collusively downward-biased advice led to sustained underproduction and supracompetitive profits - hallmarks of tacit collusion. In both experiments, participants responded more strongly and consistently to individualized advice than collective advice, potentially due to greater perceived ownership of the former. These findings demonstrate that algorithmic advice can function as a strategic signal, shaping coordination even without explicit communication. The results echo real-world concerns about algorithmic collusion and underscore the need for careful design and oversight of algorithmic decision-support systems in competitive environments. 

**Abstract (ZH)**: 随着算法在竞争决策中越来越起主导作用，其影响超越了个体结果，进而塑造了战略市场动态。在两项预先注册的实验中，我们研究了算法建议如何影响人类在具有独特、非串谋且可分析均衡的经典经济博弈中的行为。在实验1（N = 107）中，参与者在个体化或集体算法建议下进行了伯特兰价格竞争。最初，存在串谋倾向的建议提高了价格，尤其是在个体化的情况下，但价格在整个实验过程中逐渐趋向均衡。然而，参与者在整个实验过程中都避免将价格设定在算法建议之上，这表明建议充当了可接受价格的软上限。在实验2（N = 129）中，参与者在接受均衡对齐或策略性偏差的算法建议下进行了古诺数量竞争。在这里，个体化均衡建议支持了稳定的收敛，而串谋倾向的下调建议导致了持续的低产出和超竞争利润——这是隐性串谋的特征。在两个实验中，参与者对个体化建议的反应比集体建议更为强烈且一致，可能是因为前者更具有感知上的归属感。这些发现表明，算法建议可以作为战略信号，影响协调而无需明确沟通。结果反映了关于算法共谋的现实世界担忧，并强调了在竞争环境中设计和监管算法决策支持系统的重要性。 

---
# How does the Performance of the Data-driven Traffic Flow Forecasting Models deteriorate with Increasing Forecasting Horizon? An Extensive Approach Considering Statistical, Machine Learning and Deep Learning Models 

**Title (ZH)**: 数据驱动的交通流量预测模型随预测期延长性能下降的原因探究：统计、机器学习和深度学习模型的全面分析 

**Authors**: Amanta Sherfenaz, Nazmul Haque, Protiva Sadhukhan Prova, Md Asif Raihan, Md. Hadiuzzaman  

**Link**: [PDF](https://arxiv.org/pdf/2511.09450)  

**Abstract**: With rapid urbanization in recent decades, traffic congestion has intensified due to increased movement of people and goods. As planning shifts from demand-based to supply-oriented strategies, Intelligent Transportation Systems (ITS) have become essential for managing traffic within existing infrastructure. A core ITS function is traffic forecasting, enabling proactive measures like ramp metering, signal control, and dynamic routing through platforms such as Google Maps. This study assesses the performance of statistical, machine learning (ML), and deep learning (DL) models in forecasting traffic speed and flow using real-world data from California's Harbor Freeway, sourced from the Caltrans Performance Measurement System (PeMS). Each model was evaluated over 20 forecasting windows (up to 1 hour 40 minutes) using RMSE, MAE, and R-Square metrics. Results show ANFIS-GP performs best at early windows with RMSE of 0.038, MAE of 0.0276, and R-Square of 0.9983, while Bi-LSTM is more robust for medium-term prediction due to its capacity to model long-range temporal dependencies, achieving RMSE of 0.1863, MAE of 0.0833, and R-Square of 0.987 at a forecasting of 20. The degradation in model performance was quantified using logarithmic transformation, with slope values used to measure robustness. Among DL models, Bi-LSTM had the flattest slope (0.0454 RMSE, 0.0545 MAE for flow), whereas ANFIS-GP had 0.1058 for RMSE and 0.1037 for flow MAE. The study concludes by identifying hybrid models as a promising future direction. 

**Abstract (ZH)**: 近年来快速的城市化进程加剧了交通拥堵。随着规划策略从需求导向转向供给导向，智能交通系统（ITS）已成为在现有基础设施内管理交通的重要工具。ITS的核心功能之一是交通预测，通过谷歌地图等平台实现诸如匝道控制、信号控制和动态路线规划等主动措施。本研究利用加利福尼亚州港湾高速公路的真实数据，评估统计模型、机器学习（ML）模型和深度学习（DL）模型在交通速度和流量预测中的表现，数据来源于加州交通部性能测量系统（PeMS）。每种模型在20个不同的预测窗口（最长1小时40分钟）上进行了评估，使用均方根误差（RMSE）、平均绝对误差（MAE）和决定系数（R-Square）作为评估指标。结果表明，ANFIS-GP在早期窗口表现最佳，其RMSE为0.038，MAE为0.0276，R-Square为0.9983；而Bi-LSTM在中短期预测中更为稳健，通过建模长期时间依赖关系，其在20分钟内的预测中RMSE为0.1863，MAE为0.0833，R-Square为0.987。通过对模型性能下降进行对数变换，使用斜率衡量稳健性，DL模型中Bi-LSTM表现最稳定，对于流量的RMSE斜率为0.0545，MAE斜率为0.0545；ANFIS-GP对于流量的RMSE斜率为0.1058，MAE斜率为0.1037。研究结论提出，混合模型是未来研究的一个有希望的方向。 

---
# Spatio-Temporal Graph Unlearning 

**Title (ZH)**: 时空图遗忘 

**Authors**: Qiming Guo, Wenbo Sun, Wenlu Wang  

**Link**: [PDF](https://arxiv.org/pdf/2511.09404)  

**Abstract**: Spatio-temporal graphs are widely used in modeling complex dynamic processes such as traffic forecasting, molecular dynamics, and healthcare monitoring. Recently, stringent privacy regulations such as GDPR and CCPA have introduced significant new challenges for existing spatio-temporal graph models, requiring complete unlearning of unauthorized data. Since each node in a spatio-temporal graph diffuses information globally across both spatial and temporal dimensions, existing unlearning methods primarily designed for static graphs and localized data removal cannot efficiently erase a single node without incurring costs nearly equivalent to full model retraining. Therefore, an effective approach for complete spatio-temporal graph unlearning is a pressing need. To address this, we propose CallosumNet, a divide-and-conquer spatio-temporal graph unlearning framework inspired by the corpus callosum structure that facilitates communication between the brain's two hemispheres. CallosumNet incorporates two novel techniques: (1) Enhanced Subgraph Construction (ESC), which adaptively constructs multiple localized subgraphs based on several factors, including biologically-inspired virtual ganglions; and (2) Global Ganglion Bridging (GGB), which reconstructs global spatio-temporal dependencies from these localized subgraphs, effectively restoring the full graph representation. Empirical results on four diverse real-world datasets show that CallosumNet achieves complete unlearning with only 1%-2% relative MAE loss compared to the gold model, significantly outperforming state-of-the-art baselines. Ablation studies verify the effectiveness of both proposed techniques. 

**Abstract (ZH)**: 时空图在交通预测、分子动力学和医疗监控等复杂动态过程建模中的广泛应用面临严峻的隐私法规挑战，如GDPR和CCPA，要求完全遗忘未经授权的数据。由于时空图中的每个节点在全球的空间和时间维度上扩散信息，现有的针对静态图和局部数据删除的遗忘方法难以在不几乎等于全模型重新训练成本的情况下高效地擦除单个节点。因此，一种有效的时空图完全遗忘方法迫在眉睫。为了解决这一问题，我们提出了CallosumNet，这是一种受大脑两个半球间胼胝体结构启发的分而治之的时空图遗忘框架。CallosumNet包含两种新颖的技术：（1）增强子图构建（ESC），基于多个因素自适应构建多个局部子图，包括生物启发的虚拟神经节；（2）全局神经节桥接（GGB），从这些局部子图重建全局时空依赖性，有效恢复完整的图表示。在四个不同领域的真实数据集上的实验结果表明，CallosumNet相比黄金模型仅在相对MAE损失上增加1%-2%，显著优于现有最先进的基线方法。消融研究验证了所提出技术的有效性。 

---
# Potent but Stealthy: Rethink Profile Pollution against Sequential Recommendation via Bi-level Constrained Reinforcement Paradigm 

**Title (ZH)**: 潜在但隐秘：通过双层约束强化范式重新思考针对序贯推荐的配置污染 

**Authors**: Jiajie Su, Zihan Nan, Yunshan Ma, Xiaobo Xia, Xiaohua Feng, Weiming Liu, Xiaolin Zheng, Chaochao Chen  

**Link**: [PDF](https://arxiv.org/pdf/2511.09392)  

**Abstract**: Sequential Recommenders, which exploit dynamic user intents through interaction sequences, is vulnerable to adversarial attacks. While existing attacks primarily rely on data poisoning, they require large-scale user access or fake profiles thus lacking practicality. In this paper, we focus on the Profile Pollution Attack that subtly contaminates partial user interactions to induce targeted mispredictions. Previous PPA methods suffer from two limitations, i.e., i) over-reliance on sequence horizon impact restricts fine-grained perturbations on item transitions, and ii) holistic modifications cause detectable distribution shifts. To address these challenges, we propose a constrained reinforcement driven attack CREAT that synergizes a bi-level optimization framework with multi-reward reinforcement learning to balance adversarial efficacy and stealthiness. We first develop a Pattern Balanced Rewarding Policy, which integrates pattern inversion rewards to invert critical patterns and distribution consistency rewards to minimize detectable shifts via unbalanced co-optimal transport. Then we employ a Constrained Group Relative Reinforcement Learning paradigm, enabling step-wise perturbations through dynamic barrier constraints and group-shared experience replay, achieving targeted pollution with minimal detectability. Extensive experiments demonstrate the effectiveness of CREAT. 

**Abstract (ZH)**: 基于交互序列的推荐系统易受配置文件污染攻击，该攻击通过微妙污染部分用户交互以诱导目标性预测错误。 previous PPA方法存在两个局限性，即i) 过度依赖序列窗口影响限制了对项目转换的细粒度扰动，ii) 全局修改导致可检测的分布偏移。为解决这些挑战，我们提出了一种受限强化驱动攻击 CREAT，其结合了多级优化框架与多奖励强化学习，以平衡对抗效果和隐蔽性。我们首先开发了一种模式平衡奖励策略，将模式反转奖励和分布一致性奖励相结合，以通过不平衡的共最优传输最小化可检测的偏移。然后我们采用受限分组相对强化学习范式，通过动态边界约束和分组共享经验重放实现逐步扰动，实现最小可检测性的目标污染。广泛实验验证了CREAT的有效性。 

---
# Distribution-Based Feature Attribution for Explaining the Predictions of Any Classifier 

**Title (ZH)**: 基于分布的特征归因：解释任何分类器的预测 

**Authors**: Xinpeng Li, Kai Ming Ting  

**Link**: [PDF](https://arxiv.org/pdf/2511.09332)  

**Abstract**: The proliferation of complex, black-box AI models has intensified the need for techniques that can explain their decisions. Feature attribution methods have become a popular solution for providing post-hoc explanations, yet the field has historically lacked a formal problem definition. This paper addresses this gap by introducing a formal definition for the problem of feature attribution, which stipulates that explanations be supported by an underlying probability distribution represented by the given dataset. Our analysis reveals that many existing model-agnostic methods fail to meet this criterion, while even those that do often possess other limitations. To overcome these challenges, we propose Distributional Feature Attribution eXplanations (DFAX), a novel, model-agnostic method for feature attribution. DFAX is the first feature attribution method to explain classifier predictions directly based on the data distribution. We show through extensive experiments that DFAX is more effective and efficient than state-of-the-art baselines. 

**Abstract (ZH)**: 复杂、黑盒AI模型的 proliferations 加剧了对其决策进行解释的技术需求。特征归因方法已成为提供事后解释的流行解决方案，但该领域历史上缺乏正式问题定义。本文通过引入特征归因问题的正式定义来填补这一空白，该定义要求解释基于给定数据集代表的概率分布得以支持。我们的分析表明，许多现有的模型无关方法未能满足这一标准，而即使是满足这一标准的方法也往往存在其他局限性。为克服这些挑战，我们提出了分布归因解释（DFAX），这是一种全新的、模型无关的特征归因方法。DFAX是第一个直接基于数据分布解释分类器预测的特征归因方法。通过大量实验，我们证明了DFAX比最先进的基线方法更有效率。 

---
# DensiCrafter: Physically-Constrained Generation and Fabrication of Self-Supporting Hollow Structures 

**Title (ZH)**: DensiCrafter: 物理约束下的自支撑空心结构生成与制造 

**Authors**: Shengqi Dang, Fu Chai, Jiaxin Li, Chao Yuan, Wei Ye, Nan Cao  

**Link**: [PDF](https://arxiv.org/pdf/2511.09298)  

**Abstract**: The rise of 3D generative models has enabled automatic 3D geometry and texture synthesis from multimodal inputs (e.g., text or images). However, these methods often ignore physical constraints and manufacturability considerations. In this work, we address the challenge of producing 3D designs that are both lightweight and self-supporting. We present DensiCrafter, a framework for generating lightweight, self-supporting 3D hollow structures by optimizing the density field. Starting from coarse voxel grids produced by Trellis, we interpret these as continuous density fields to optimize and introduce three differentiable, physically constrained, and simulation-free loss terms. Additionally, a mass regularization penalizes unnecessary material, while a restricted optimization domain preserves the outer surface. Our method seamlessly integrates with pretrained Trellis-based models (e.g., Trellis, DSO) without any architectural changes. In extensive evaluations, we achieve up to 43% reduction in material mass on the text-to-3D task. Compared to state-of-the-art baselines, our method could improve the stability and maintain high geometric fidelity. Real-world 3D-printing experiments confirm that our hollow designs can be reliably fabricated and could be self-supporting. 

**Abstract (ZH)**: 3D生成模型的兴起使得从多模态输入（例如文本或图像）中自动合成3D几何和纹理成为可能。然而，这些方法Often忽略了物理约束和可制造性考虑。在本文中，我们解决了生成既轻量化又自支撑的3D设计的挑战。我们提出了DensiCrafter框架，通过优化密度场生成轻量化、自支撑的3D空心结构。从Trellis生成的粗糙体素网格入手，我们将这些网格解释为连续的密度场进行优化，并引入了三种可微分的、受物理约束的且无需模拟的损失项。此外，质量正则化惩罚不必要的材料，而限制的优化域则保持外部表面。我们的方法无需任何架构更改即可无缝集成到预训练的Trellis基模型（例如Trellis、DSO）中。在广泛的评估中，我们能够在文本到3D任务中实现最高43%的材料质量减少。与最先进的基线方法相比，我们的方法能够提高稳定性并保持高几何保真度。现实世界的3D打印实验验证了我们的空心设计可以可靠地制造并能够自支撑。 

---
# GuardFed: A Trustworthy Federated Learning Framework Against Dual-Facet Attacks 

**Title (ZH)**: GuardFed: 一种对抗双面攻击的可信赖联邦学习框架 

**Authors**: Yanli Li, Yanan Zhou, Zhongliang Guo, Nan Yang, Yuning Zhang, Huaming Chen, Dong Yuan, Weiping Ding, Witold Pedrycz  

**Link**: [PDF](https://arxiv.org/pdf/2511.09294)  

**Abstract**: Federated learning (FL) enables privacy-preserving collaborative model training but remains vulnerable to adversarial behaviors that compromise model utility or fairness across sensitive groups. While extensive studies have examined attacks targeting either objective, strategies that simultaneously degrade both utility and fairness remain largely unexplored. To bridge this gap, we introduce the Dual-Facet Attack (DFA), a novel threat model that concurrently undermines predictive accuracy and group fairness. Two variants, Synchronous DFA (S-DFA) and Split DFA (Sp-DFA), are further proposed to capture distinct real-world collusion scenarios. Experimental results show that existing robust FL defenses, including hybrid aggregation schemes, fail to resist DFAs effectively. To counter these threats, we propose GuardFed, a self-adaptive defense framework that maintains a fairness-aware reference model using a small amount of clean server data augmented with synthetic samples. In each training round, GuardFed computes a dual-perspective trust score for every client by jointly evaluating its utility deviation and fairness degradation, thereby enabling selective aggregation of trustworthy updates. Extensive experiments on real-world datasets demonstrate that GuardFed consistently preserves both accuracy and fairness under diverse non-IID and adversarial conditions, achieving state-of-the-art performance compared with existing robust FL methods. 

**Abstract (ZH)**: 联邦学习（FL）实现了隐私保护下的协作模型训练，但仍然容易受到损害模型实用性和公平性的 adversarial 行为的攻击。尽管已有大量研究针对单一目标展开了攻击研究，同时损害实用性和公平性的策略仍然鲜有探讨。为填补这一空白，我们引入了双面攻击（Dual-Facet Attack, DFA）这一新的威胁模型，以同时削弱预测准确性和群体公平性。进一步提出了同步双面攻击（Synchronous DFA, S-DFA）和分裂双面攻击（Split DFA, Sp-DFA）两种变体，以捕捉不同的现实世界协作场景。实验结果表明，现有的稳健联邦学习（FL）防御措施，包括混合聚合方案，无法有效抵御 DFA 攻击。为应对这些威胁，我们提出了一种自适应防御框架 GuardFed，该框架利用少量干净的服务器数据与合成样本相结合，维护一个公平意识的参考模型。在每一次训练周期中，GuardFed 通过联合评估每个客户端的实用性和公平性下降来计算双重视角的信任分数，从而实现可信赖更新的有选择性聚合。在真实世界数据集上的广泛实验表明，GuardFed 在各种非IID 和对抗条件下均能一致地保持准确性和公平性，其性能优于现有的稳健联邦学习方法。 

---
# Unveiling Hidden Threats: Using Fractal Triggers to Boost Stealthiness of Distributed Backdoor Attacks in Federated Learning 

**Title (ZH)**: 揭示隐匿威胁：使用分形触发器提升分布式后门攻击在联邦学习中的隐蔽性 

**Authors**: Jian Wang, Hong Shen, Chan-Tong Lam  

**Link**: [PDF](https://arxiv.org/pdf/2511.09252)  

**Abstract**: Traditional distributed backdoor attacks (DBA) in federated learning improve stealthiness by decomposing global triggers into sub-triggers, which however requires more poisoned data to maintian the attck strength and hence increases the exposure risk. To overcome this defect, This paper proposes a novel method, namely Fractal-Triggerred Distributed Backdoor Attack (FTDBA), which leverages the self-similarity of fractals to enhance the feature strength of sub-triggers and hence significantly reduce the required poisoning volume for the same attack strength. To address the detectability of fractal structures in the frequency and gradient domains, we introduce a dynamic angular perturbation mechanism that adaptively adjusts perturbation intensity across the training phases to balance efficiency and stealthiness. Experiments show that FTDBA achieves a 92.3\% attack success rate with only 62.4\% of the poisoning volume required by traditional DBA methods, while reducing the detection rate by 22.8\% and KL divergence by 41.2\%. This study presents a low-exposure, high-efficiency paradigm for federated backdoor attacks and expands the application of fractal features in adversarial sample generation. 

**Abstract (ZH)**: 分形触发分布式后门攻击：一种低暴露高效率的联邦后门攻击方法 

---
# Learning Binary Autoencoder-Based Codes with Progressive Training 

**Title (ZH)**: 基于分阶训练的二进制自编码器编码学习 

**Authors**: Vukan Ninkovic, Dejan Vukobratovic  

**Link**: [PDF](https://arxiv.org/pdf/2511.09221)  

**Abstract**: Error correcting codes play a central role in digital communication, ensuring that transmitted information can be accurately reconstructed despite channel impairments. Recently, autoencoder (AE) based approaches have gained attention for the end-to-end design of communication systems, offering a data driven alternative to conventional coding schemes. However, enforcing binary codewords within differentiable AE architectures remains difficult, as discretization breaks gradient flow and often leads to unstable convergence. To overcome this limitation, a simplified two stage training procedure is proposed, consisting of a continuous pretraining phase followed by direct binarization and fine tuning without gradient approximation techniques. For the (7,4) block configuration over a binary symmetric channel (BSC), the learned encoder-decoder pair learns a rotated version (coset code) of the optimal Hamming code, naturally recovering its linear and distance properties and thereby achieving the same block error rate (BLER) with maximum likelihood (ML) decoding. These results indicate that compact AE architectures can effectively learn structured, algebraically optimal binary codes through stable and straightforward training. 

**Abstract (ZH)**: 纠错码在数字通信中发挥着核心作用，确保 transmitted 信息在信道损伤的情况下能够被准确重建。最近，基于自动编码器（AE）的方法受到了关注，用于端到端设计通信系统，提供了一种基于数据驱动的替代传统编码方案的方法。然而，在不同的iable AE 架构中强制使用二进制码字仍然具有挑战性，因为离散化会破坏梯度流并经常导致不稳定收敛。为了克服这一限制，提出了一种简化的两阶段训练过程，包括一个连续的预训练阶段，随后是直接二进制化和 fine tuning，不使用梯度近似技术。对于二进制对称信道（BSC）上的（7,4）块配置，通过学习到的编码器-解码器配对学习到了最优汉明码的旋转版本（余子码），自然地恢复了其线性和距离性质，并从而通过最大似然（ML）解码达到了相同的块错误率（BLER）。这些结果表明，紧凑的 AE 架构可以通过稳定且直接的训练有效学习结构化的代数最优二进制码。 

---
# Enhancing PIBT via Multi-Action Operations 

**Title (ZH)**: 通过多动作操作增强PIBT 

**Authors**: Egor Yukhnevich, Anton Andreychuk  

**Link**: [PDF](https://arxiv.org/pdf/2511.09193)  

**Abstract**: PIBT is a rule-based Multi-Agent Path Finding (MAPF) solver, widely used as a low-level planner or action sampler in many state-of-the-art approaches. Its primary advantage lies in its exceptional speed, enabling action selection for thousands of agents within milliseconds by considering only the immediate next timestep. However, this short-horizon design leads to poor performance in scenarios where agents have orientation and must perform time-consuming rotation actions. In this work, we present an enhanced version of PIBT that addresses this limitation by incorporating multi-action operations. We detail the modifications introduced to improve PIBT's performance while preserving its hallmark efficiency. Furthermore, we demonstrate how our method, when combined with graph-guidance technique and large neighborhood search optimization, achieves state-of-the-art performance in the online LMAPF-T setting. 

**Abstract (ZH)**: PIBT是一种基于规则的多Agent路径规划（MAPF）求解器，广泛用作许多最先进的方法中的低级规划器或动作采样器。其主要优势在于其卓越的速度，能够在毫秒内为成千上万的Agent选择动作，仅考虑即时的下一时间切片。然而，这种短视的设计使其在Agent具有方向性且必须执行耗时的旋转动作的场景中表现较差。在本工作中，我们提出了一种增强版的PIBT，通过引入多动作操作来解决这一局限性。我们详细介绍了为提高PIBT性能而引入的改进措施，同时保持其标志性的高效性。此外，我们展示了我们的方法结合图引导技术和大规模邻域搜索优化后，在在线LMAPF-T设置中实现了最先进的性能。 

---
# Tractable Weighted First-Order Model Counting with Bounded Treewidth Binary Evidence 

**Title (ZH)**: 可计算的具有 bounded treewidth 二元证据的加权一阶模型计数 

**Authors**: Václav Kůla, Qipeng Kuang, Yuyi Wang, Yuanhong Wang, Ondřej Kuželka  

**Link**: [PDF](https://arxiv.org/pdf/2511.09174)  

**Abstract**: The Weighted First-Order Model Counting Problem (WFOMC) asks to compute the weighted sum of models of a given first-order logic sentence over a given domain. Conditioning WFOMC on evidence -- fixing the truth values of a set of ground literals -- has been shown impossible in time polynomial in the domain size (unless $\mathsf{\#P \subseteq FP}$) even for fragments of logic that are otherwise tractable for WFOMC without evidence. In this work, we address the barrier by restricting the binary evidence to the case where the underlying Gaifman graph has bounded treewidth. We present a polynomial-time algorithm in the domain size for computing WFOMC for the two-variable fragments $\text{FO}^2$ and $\text{C}^2$ conditioned on such binary evidence. Furthermore, we show the applicability of our algorithm in combinatorial problems by solving the stable seating arrangement problem on bounded-treewidth graphs of bounded degree, which was an open problem. We also conducted experiments to show the scalability of our algorithm compared to the existing model counting solvers. 

**Abstract (ZH)**: 加权一阶模型计数问题（WFOMC）要求计算给定一阶逻辑句子在给定领域中的加权模型和。基于证据对WFOMC进行条件化——固定一组基础文字的真值——即使是对逻辑片段进行条件化，否则在没有证据的情况下WFOMC是可处理的，也被证明在领域大小多项式时间内是不可能的（除非 \#P ⊆ FP）。在本工作中，我们通过限制二元证据的底层Gaifman图的 treewidth 有界来克服这一障碍。我们提出了一种基于领域大小的多项式时间算法，用于在二元证据条件下计算 \text{FO}^2 和 \text{C}^2 的WFOMC。此外，我们通过在有界 treewidth 且有界度的图上解决稳定就座安排问题展示了我们算法的应用性，这是尚未解决的问题。我们也进行了实验来展示与现有模型计数求解器相比，我们算法的可扩展性。 

---
# Data Fusion-Enhanced Decision Transformer for Stable Cross-Domain Generalization 

**Title (ZH)**: 数据融合增强的决策变换器以实现稳定跨域泛化 

**Authors**: Guojian Wang, Quinson Hon, Xuyang Chen, Lin Zhao  

**Link**: [PDF](https://arxiv.org/pdf/2511.09173)  

**Abstract**: Cross-domain shifts present a significant challenge for decision transformer (DT) policies. Existing cross-domain policy adaptation methods typically rely on a single simple filtering criterion to select source trajectory fragments and stitch them together. They match either state structure or action feasibility. However, the selected fragments still have poor stitchability: state structures can misalign, the return-to-go (RTG) becomes incomparable when the reward or horizon changes, and actions may jump at trajectory junctions. As a result, RTG tokens lose continuity, which compromises DT's inference ability. To tackle these challenges, we propose Data Fusion-Enhanced Decision Transformer (DFDT), a compact pipeline that restores stitchability. Particularly, DFDT fuses scarce target data with selectively trusted source fragments via a two-level data filter, maximum mean discrepancy (MMD) mismatch for state-structure alignment, and optimal transport (OT) deviation for action feasibility. It then trains on a feasibility-weighted fusion distribution. Furthermore, DFDT replaces RTG tokens with advantage-conditioned tokens, which improves the continuity of the semantics in the token sequence. It also applies a $Q$-guided regularizer to suppress junction value and action jumps. Theoretically, we provide bounds that tie state value and policy performance gaps to the MMD-mismatch and OT-deviation measures, and show that the bounds tighten as these two measures shrink. We show that DFDT improves return and stability over strong offline RL and sequence-model baselines across gravity, kinematic, and morphology shifts on D4RL-style control tasks, and further corroborate these gains with token-stitching and sequence-semantics stability analyses. 

**Abstract (ZH)**: 跨域变化为决策变换器(DT)策略带来了重大挑战。Data Fusion-Enhanced Decision Transformer (DFDT)通过恢复拼接性来应对这些挑战。 

---
# Differentially Private Rankings via Outranking Methods and Performance Data Aggregation 

**Title (ZH)**: 差分隐私下的递战胜出方法与性能数据聚合-ranking方法下的差分隐私保护 

**Authors**: Luis Del Vasto-Terrientes  

**Link**: [PDF](https://arxiv.org/pdf/2511.09120)  

**Abstract**: Multiple-Criteria Decision Making (MCDM) is a sub-discipline of Operations Research that helps decision-makers in choosing, ranking, or sorting alternatives based on conflicting criteria. Over time, its application has been expanded into dynamic and data-driven domains, such as recommender systems. In these contexts, the availability and handling of personal and sensitive data can play a critical role in the decision-making process. Despite this increased reliance on sensitive data, the integration of privacy mechanisms with MCDM methods is underdeveloped. This paper introduces an integrated approach that combines MCDM outranking methods with Differential Privacy (DP), safeguarding individual contributions' privacy in ranking problems. This approach relies on a pre-processing step to aggregate multiple user evaluations into a comprehensive performance matrix. The evaluation results show a strong to very strong statistical correlation between the true rankings and their anonymized counterparts, ensuring robust privacy parameter guarantees. 

**Abstract (ZH)**: 多准则决策分析（MCDM）是运筹学的一个分支，它帮助决策者基于冲突的标准选择、排名或排序备选方案。随着时间的推移，其应用扩展到了动态和数据驱动的领域，如推荐系统。在这些领域中，个人和敏感数据的可用性及其处理可以在决策过程中发挥关键作用。尽管对敏感数据的依赖性增加，但将隐私机制与MCDM方法的集成尚不充分。本文介绍了一种集成方法，该方法结合了MCDM支配方法和差分隐私（DP），在排名问题中保护个体贡献的隐私。该方法依赖于预处理步骤，将多个用户评估综合为一个全面的性能矩阵。评估结果表明，真实排名和匿名排名之间存在强烈的统计相关性，确保了 robust 的隐私参数保证。 

---
# Factorization-in-Loop: Proximal Fill-in Minimization for Sparse Matrix Reordering 

**Title (ZH)**: 环中因子化：proximal 填充最小化Sparse 矩阵重排序 

**Authors**: Ziwei Li, Shuzi Niu, Tao Yuan, Huiyuan Li, Wenjia Wu  

**Link**: [PDF](https://arxiv.org/pdf/2511.09093)  

**Abstract**: Fill-ins are new nonzero elements in the summation of the upper and lower triangular factors generated during LU factorization. For large sparse matrices, they will increase the memory usage and computational time, and be reduced through proper row or column arrangement, namely matrix reordering. Finding a row or column permutation with the minimal fill-ins is NP-hard, and surrogate objectives are designed to derive fill-in reduction permutations or learn a reordering function. However, there is no theoretical guarantee between the golden criterion and these surrogate objectives. Here we propose to learn a reordering network by minimizing \(l_1\) norm of triangular factors of the reordered matrix to approximate the exact number of fill-ins. The reordering network utilizes a graph encoder to predict row or column node scores. For inference, it is easy and fast to derive the permutation from sorting algorithms for matrices. For gradient based optimization, there is a large gap between the predicted node scores and resultant triangular factors in the optimization objective. To bridge the gap, we first design two reparameterization techniques to obtain the permutation matrix from node scores. The matrix is reordered by multiplying the permutation matrix. Then we introduce the factorization process into the objective function to arrive at target triangular factors. The overall objective function is optimized with the alternating direction method of multipliers and proximal gradient descent. Experimental results on benchmark sparse matrix collection SuiteSparse show the fill-in number and LU factorization time reduction of our proposed method is 20% and 17.8% compared with state-of-the-art baselines. 

**Abstract (ZH)**: 填补元素是矩阵LU分解过程中上三角和下三角因子求和中新出现的非零元素。对于大型稀疏矩阵，这些填补元素会增加内存使用和计算时间，并可以通过适当的行或列排列（即矩阵重排）减少。找到具有最小填补元素的行或列置换是NP难问题，因此设计了替代目标来获得填补元素减少的置换或学习一个重排函数。然而，这些替代目标与理想目标之间没有理论保证。我们提出通过最小化重排矩阵的三角因子的\(l_1\)范数来学习一个重排网络，以近似填补元素的确切数量。重排网络利用图编码器预测行或列节点得分。在推断过程中，通过排序算法容易快速地从节点得分导出置换。对于基于梯度的优化，预测节点得分与优化目标中产生的三角因子之间存在较大差距。为了弥合这一差距，我们首先设计了两种再参数化技术，从节点得分中获得置换矩阵。该矩阵通过乘以置换矩阵进行重排。然后我们将分解过程引入目标函数中，以达到目标三角因子。最终的目标函数使用交替方向乘法器和 proximal 梯度下降进行优化。在基准稀疏矩阵集合SuiteSparse上的实验结果表明，与最先进的基线方法相比，我们提出的方法可以减少20%的填补元素数量和17.8%的LU分解时间。 

---
# Improving Sustainability of Adversarial Examples in Class-Incremental Learning 

**Title (ZH)**: 提高类增量学习中对抗样本的可持续性 

**Authors**: Taifeng Liu, Xinjing Liu, Liangqiu Dong, Yang Liu, Yilong Yang, Zhuo Ma  

**Link**: [PDF](https://arxiv.org/pdf/2511.09088)  

**Abstract**: Current adversarial examples (AEs) are typically designed for static models. However, with the wide application of Class-Incremental Learning (CIL), models are no longer static and need to be updated with new data distributed and labeled differently from the old ones. As a result, existing AEs often fail after CIL updates due to significant domain drift. In this paper, we propose SAE to enhance the sustainability of AEs against CIL. The core idea of SAE is to enhance the robustness of AE semantics against domain drift by making them more similar to the target class while distinguishing them from all other classes. Achieving this is challenging, as relying solely on the initial CIL model to optimize AE semantics often leads to overfitting. To resolve the problem, we propose a Semantic Correction Module. This module encourages the AE semantics to be generalized, based on a visual-language model capable of producing universal semantics. Additionally, it incorporates the CIL model to correct the optimization direction of the AE semantics, guiding them closer to the target class. To further reduce fluctuations in AE semantics, we propose a Filtering-and-Augmentation Module, which first identifies non-target examples with target-class semantics in the latent space and then augments them to foster more stable semantics. Comprehensive experiments demonstrate that SAE outperforms baselines by an average of 31.28% when updated with a 9-fold increase in the number of classes. 

**Abstract (ZH)**: 当前的 adversarial examples (AEs) 主要针对静态模型设计。然而，随着类增量学习（CIL）的广泛应用，模型不再静态，而是需要随着新数据的分布式和不同标签的数据进行更新。结果，现有的 AEs 往往在 CIL 更新后由于显著的领域漂移而失效。本文提出 SAE 以增强 AEs 对 CIL 的可持续性。SAE 的核心思想是通过使 AE 语义更接近目标类并与其他所有类区分开来，增强 AE 语义对领域漂移的鲁棒性。实现这一点具有挑战性，因为仅依赖初始 CIL 模型来优化 AE 语义往往会引发过拟合。为了解决该问题，我们提出了一种语义修正模块。该模块基于能够生成通用语义的视觉-语言模型，鼓励 AE 语义泛化，并结合 CIL 模型来纠正 AE 语义的优化方向，使其更接近目标类。为了进一步减少 AE 语义的波动，我们还提出了一种过滤与扩充模块，该模块首先在潜在空间中识别具有目标类语义的非目标示例，然后对其进行扩充以促进更稳定的语义。综合实验表明，当类别数量增加 9 倍时，SAE 在损耗平均基准性能 31.28% 的情况下表现出更优的效果。 

---
# Good-for-MDP State Reduction for Stochastic LTL Planning 

**Title (ZH)**: 适合MDP的状态减少方法用于随机LTL规划 

**Authors**: Christoph Weinhuber, Giuseppe De Giacomo, Yong Li, Sven Schewe, Qiyi Tang  

**Link**: [PDF](https://arxiv.org/pdf/2511.09073)  

**Abstract**: We study stochastic planning problems in Markov Decision Processes (MDPs) with goals specified in Linear Temporal Logic (LTL). The state-of-the-art approach transforms LTL formulas into good-for-MDP (GFM) automata, which feature a restricted form of nondeterminism. These automata are then composed with the MDP, allowing the agent to resolve the nondeterminism during policy synthesis. A major factor affecting the scalability of this approach is the size of the generated automata. In this paper, we propose a novel GFM state-space reduction technique that significantly reduces the number of automata states. Our method employs a sophisticated chain of transformations, leveraging recent advances in good-for-games minimisation developed for adversarial settings. In addition to our theoretical contributions, we present empirical results demonstrating the practical effectiveness of our state-reduction technique. Furthermore, we introduce a direct construction method for formulas of the form $\mathsf{G}\mathsf{F}\varphi$, where $\varphi$ is a co-safety formula. This construction is provably single-exponential in the worst case, in contrast to the general doubly-exponential complexity. Our experiments confirm the scalability advantages of this specialised construction. 

**Abstract (ZH)**: 我们研究线性时逻辑（LTL）目标下马尔可夫决策过程（MDP）中的随机规划问题。最先进的方法是将LTL公式转换为适合MDP（GFM）自动机，这种自动机具有受限的非确定性形式。然后将这些自动机与MDP组合，使代理可以在策略合成过程中解决非确定性问题。影响这一方法可扩展性的一个重要因素是生成的自动机状态数量。在本文中，我们提出了一种新颖的GFM状态空间缩减技术，显著减少了自动机状态的数量。该方法利用了在对抗环境中发展起来的GFM最小化最近进展进行了一系列复杂的转换。除了我们的理论贡献外，我们还提供了实证结果，证明了我们的状态缩减技术的实用有效性。此外，我们介绍了一种直接构造形式为$\mathsf{G}\mathsf{F}\varphi$的公式的构造方法，其中$\varphi$为补安全性公式，这种构造在最坏情况下的复杂性是可以证明的单指数级的，而一般的复杂性是双重指数级的。我们的实验验证了这种专门构造方法的可扩展性优势。 

---
# MM-CRITIC: A Holistic Evaluation of Large Multimodal Models as Multimodal Critique 

**Title (ZH)**: MM-CRITIC: 多模态大型模型的综合评估作为多模态批评 

**Authors**: Gailun Zeng, Ziyang Luo, Hongzhan Lin, Yuchen Tian, Kaixin Li, Ziyang Gong, Jianxiong Guo, Jing Ma  

**Link**: [PDF](https://arxiv.org/pdf/2511.09067)  

**Abstract**: The ability of critique is vital for models to self-improve and serve as reliable AI assistants. While extensively studied in language-only settings, multimodal critique of Large Multimodal Models (LMMs) remains underexplored despite their growing capabilities in tasks like captioning and visual reasoning. In this work, we introduce MM-CRITIC, a holistic benchmark for evaluating the critique ability of LMMs across multiple dimensions: basic, correction, and comparison. Covering 8 main task types and over 500 tasks, MM-CRITIC collects responses from various LMMs with different model sizes and is composed of 4471 samples. To enhance the evaluation reliability, we integrate expert-informed ground answers into scoring rubrics that guide GPT-4o in annotating responses and generating reference critiques, which serve as anchors for trustworthy judgments. Extensive experiments validate the effectiveness of MM-CRITIC and provide a comprehensive assessment of leading LMMs' critique capabilities under multiple dimensions. Further analysis reveals some key insights, including the correlation between response quality and critique, and varying critique difficulty across evaluation dimensions. Our code is available at this https URL. 

**Abstract (ZH)**: 多媒体批判能力评估对于模型的自我提升和成为可靠的AI助手至关重要。尽管在语言仅有的设置中已被广泛研究，但在多种模态批评方面的大规模多媒体模型（LMMs）仍然未被充分探索，尽管它们在字幕生成和视觉推理等任务中的能力正在不断提高。在本工作中，我们介绍了MM-CRITIC，这是一个全面的基准，用于从多个维度评估LMMs的批判能力：基本、修正和比较。MM-CRITIC涵盖了8种主要任务类型和超过500个任务，收集了不同模型规模的各种LMMs的响应，共有4471个样本。为提高评估的可靠性，我们将专家指导的地面 truth答案整合到评分标准中，引导GPT-4o标注响应并生成参考批判，为可靠判断提供参考点。广泛的实验证明了MM-CRITIC的有效性，并提供了对多个维度下领先LMMs批判能力的全面评估。进一步的分析揭示了一些关键见解，包括响应质量与批判的相关性，以及在评估维度上的不同批判难度。我们的代码可在以下链接获取：这个 https URL。 

---
# Break the Tie: Learning Cluster-Customized Category Relationships for Categorical Data Clustering 

**Title (ZH)**: 打破约束：学习聚类定制的类别关系进行分类数据聚类 

**Authors**: Mingjie Zhao, Zhanpei Huang, Yang Lu, Mengke Li, Yiqun Zhang, Weifeng Su, Yiu-ming Cheung  

**Link**: [PDF](https://arxiv.org/pdf/2511.09049)  

**Abstract**: Categorical attributes with qualitative values are ubiquitous in cluster analysis of real datasets. Unlike the Euclidean distance of numerical attributes, the categorical attributes lack well-defined relationships of their possible values (also called categories interchangeably), which hampers the exploration of compact categorical data clusters. Although most attempts are made for developing appropriate distance metrics, they typically assume a fixed topological relationship between categories when learning distance metrics, which limits their adaptability to varying cluster structures and often leads to suboptimal clustering performance. This paper, therefore, breaks the intrinsic relationship tie of attribute categories and learns customized distance metrics suitable for flexibly and accurately revealing various cluster distributions. As a result, the fitting ability of the clustering algorithm is significantly enhanced, benefiting from the learnable category relationships. Moreover, the learned category relationships are proved to be Euclidean distance metric-compatible, enabling a seamless extension to mixed datasets that include both numerical and categorical attributes. Comparative experiments on 12 real benchmark datasets with significance tests show the superior clustering accuracy of the proposed method with an average ranking of 1.25, which is significantly higher than the 5.21 ranking of the current best-performing method. 

**Abstract (ZH)**: 类别型属性在实际数据集的聚类分析中无处不在。与数值属性的欧几里得距离不同，类别型属性缺乏其可能值（称为类别）之间明确的关系，这阻碍了紧凑类别数据集探索。尽管大多数努力集中在开发合适的距离度量上，它们在学习距离度量时通常假定类别之间的固定拓扑关系，这限制了它们对变化的聚类结构的适应性，并常常导致聚类性能不佳。因此，本文打破属性类别的固有关系，学习适用于灵活准确揭示各种聚类分布的定制距离度量。结果，聚类算法的拟合能力显著增强，得益于可学习的类别关系。此外，学习到的类别关系证明与欧几里得距离度量兼容，使得该方法可以直接扩展到包含数值和类别属性的混合数据集。在包含12个真实基准数据集的比较实验中，经过显著性检验，所提出方法的聚类准确性的平均排名为1.25，显著高于当前表现最佳方法的5.21排名。 

---
# MedHE: Communication-Efficient Privacy-Preserving Federated Learning with Adaptive Gradient Sparsification for Healthcare 

**Title (ZH)**: MedHE: 通信高效且保护隐私的自适应梯度稀疏化医疗联邦学习 

**Authors**: Farjana Yesmin  

**Link**: [PDF](https://arxiv.org/pdf/2511.09043)  

**Abstract**: Healthcare federated learning requires strong privacy guarantees while maintaining computational efficiency across resource-constrained medical institutions. This paper presents MedHE, a novel framework combining adaptive gradient sparsification with CKKS homomorphic encryption to enable privacy-preserving collaborative learning on sensitive medical data. Our approach introduces a dynamic threshold mechanism with error compensation for top-k gradient selection, achieving 97.5 percent communication reduction while preserving model utility. We provide formal security analysis under Ring Learning with Errors assumptions and demonstrate differential privacy guarantees with epsilon less than or equal to 1.0. Statistical testing across 5 independent trials shows MedHE achieves 89.5 percent plus or minus 0.8 percent accuracy, maintaining comparable performance to standard federated learning (p=0.32) while reducing communication from 1277 MB to 32 MB per training round. Comprehensive evaluation demonstrates practical feasibility for real-world medical deployments with HIPAA compliance and scalability to 100 plus institutions. 

**Abstract (ZH)**: 医疗 federated 学习需要在严格保护隐私的同时保持计算效率，以适应资源受限的医疗机构。本文提出 MedHE 框架，结合自适应梯度稀疏化与 CKKS 同态加密，以实现对敏感医疗数据的隐私保护协作学习。该方法引入动态阈值机制并带有误差补偿的 top-k 梯度选择，实现了 97.5% 的通信减少，同时保持模型性能。我们在 Ring LWE 假设下提供正式的安全性分析，并证明其差分隐私保证，ε ≤ 1.0。跨 5 次独立试验的统计测试显示，MedHE 的准确率为 89.5% ± 0.8%，在保持与标准 federated 学习相当的性能（p=0.32）的同时，将每轮训练的通信量从 1277 MB 减少到 32 MB。全面评估表明，MedHE 具有 HIPAA 合规性和扩展性，适用于 100 家以上的医疗机构部署。 

---
# FedSDWC: Federated Synergistic Dual-Representation Weak Causal Learning for OOD 

**Title (ZH)**: FedSDWC: 联邦协同双表示弱因果学习以处理OOD任务 

**Authors**: Zhenyuan Huang, Hui Zhang, Wenzhong Tang, Haijun Yang  

**Link**: [PDF](https://arxiv.org/pdf/2511.09036)  

**Abstract**: Amid growing demands for data privacy and advances in computational infrastructure, federated learning (FL) has emerged as a prominent distributed learning paradigm. Nevertheless, differences in data distribution (such as covariate and semantic shifts) severely affect its reliability in real-world deployments. To address this issue, we propose FedSDWC, a causal inference method that integrates both invariant and variant features. FedSDWC infers causal semantic representations by modeling the weak causal influence between invariant and variant features, effectively overcoming the limitations of existing invariant learning methods in accurately capturing invariant features and directly constructing causal representations. This approach significantly enhances FL's ability to generalize and detect OOD data. Theoretically, we derive FedSDWC's generalization error bound under specific conditions and, for the first time, establish its relationship with client prior distributions. Moreover, extensive experiments conducted on multiple benchmark datasets validate the superior performance of FedSDWC in handling covariate and semantic shifts. For example, FedSDWC outperforms FedICON, the next best baseline, by an average of 3.04% on CIFAR-10 and 8.11% on CIFAR-100. 

**Abstract (ZH)**: 在日益增长的数据隐私需求及计算基础设施的进步背景下，联邦学习（FL）已成为一种突出的分布式学习范式。然而，数据分布差异（如共变量和语义偏移）严重影响了其在实际部署中的可靠性。为了解决这一问题，我们提出了一种因果推理方法FedSDWC，该方法结合了不变特征和可变特征。FedSDWC通过建模不变特征和可变特征之间的弱因果影响来推断因果语义表示，从而有效克服了现有不变特征学习方法在准确捕捉不变特征和直接构建因果表示方面的局限性。该方法显著提高了联邦学习在泛化能力和检测OOD数据方面的性能。理论上，我们在特定条件下推导了FedSDWC的泛化误差界，并首次建立了其与客户端先验分布之间的关系。此外，对多个基准数据集进行的广泛实验验证了FedSDWC在处理共变量和语义偏移方面的优越性能。例如，FedSDWC在CIFAR-10上的平均性能优于最接近的基线FedICON 3.04%，在CIFAR-100上的性能优于3.62%。 

---
# DeepVRegulome: DNABERT-based deep-learning framework for predicting the functional impact of short genomic variants on the human regulome 

**Title (ZH)**: DeepVRegulome：基于DNABERT的深度学习框架，用于预测短基因组变异对人类调控组的功能影响 

**Authors**: Pratik Dutta, Matthew Obusan, Rekha Sathian, Max Chao, Pallavi Surana, Nimisha Papineni, Yanrong Ji, Zhihan Zhou, Han Liu, Alisa Yurovsky, Ramana V Davuluri  

**Link**: [PDF](https://arxiv.org/pdf/2511.09026)  

**Abstract**: Whole-genome sequencing (WGS) has revealed numerous non-coding short variants whose functional impacts remain poorly understood. Despite recent advances in deep-learning genomic approaches, accurately predicting and prioritizing clinically relevant mutations in gene regulatory regions remains a major challenge. Here we introduce Deep VRegulome, a deep-learning method for prediction and interpretation of functionally disruptive variants in the human regulome, which combines 700 DNABERT fine-tuned models, trained on vast amounts of ENCODE gene regulatory regions, with variant scoring, motif analysis, attention-based visualization, and survival analysis. We showcase its application on TCGA glioblastoma WGS dataset in prioritizing survival-associated mutations and regulatory regions. The analysis identified 572 splice-disrupting and 9,837 transcription-factor binding site altering mutations occurring in greater than 10% of glioblastoma samples. Survival analysis linked 1352 mutations and 563 disrupted regulatory regions to patient outcomes, enabling stratification via non-coding mutation signatures. All the code, fine-tuned models, and an interactive data portal are publicly available. 

**Abstract (ZH)**: Whole-genome sequencing (WGS) 揭示了大量非编码短变异，其功能影响仍 poorly understood。尽管近年来深度学习基因组方法取得了进步，但准确预测和优先级排序与基因调控区域相关的临床相关突变仍然是一项重大挑战。我们介绍了 Deep VRegulome，这是一种用于预测和解释人类调控组中功能破坏性变异的深度学习方法，该方法结合了700个在大量ENCODE基因调控区域上微调的DNABERT模型，以及变异评分、motif分析、基于注意力的可视化和生存分析。我们在TCGA胶质母细胞瘤WGS数据集中展示了其应用，以优先级排序与生存相关的变异和调控区域。分析识别出572个剪接破坏性和9,837个转录因子结合位点改变的突变，在超过10%的胶质母细胞瘤样本中发生。生存分析将1352个突变和563个受损的调控区域与患者预后联系起来，使通过非编码突变特征进行分层成为可能。所有代码、微调模型以及一个交互式数据门户均已公开。 

---
# A Neurosymbolic Approach to Natural Language Formalization and Verification 

**Title (ZH)**: 基于神经符号方法的自然语言形式化与验证 

**Authors**: Sam Bayless, Stefano Buliani, Darion Cassel, Byron Cook, Duncan Clough, Rémi Delmas, Nafi Diallo, Ferhat Erata, Nick Feng, Dimitra Giannakopoulou, Aman Goel, Aditya Gokhale, Joe Hendrix, Marc Hudak, Dejan Jovanović, Andrew M. Kent, Benjamin Kiesl-Reiter, Jeffrey J. Kuna, Nadia Labai, Joseph Lilien, Divya Raghunathan, Zvonimir Rakamarić, Niloofar Razavi, Michael Tautschnig, Ali Torkamani, Nathaniel Weir, Michael W. Whalen, Jianan Yao  

**Link**: [PDF](https://arxiv.org/pdf/2511.09008)  

**Abstract**: Large Language Models perform well at natural language interpretation and reasoning, but their inherent stochasticity limits their adoption in regulated industries like finance and healthcare that operate under strict policies. To address this limitation, we present a two-stage neurosymbolic framework that (1) uses LLMs with optional human guidance to formalize natural language policies, allowing fine-grained control of the formalization process, and (2) uses inference-time autoformalization to validate logical correctness of natural language statements against those policies. When correctness is paramount, we perform multiple redundant formalization steps at inference time, cross checking the formalizations for semantic equivalence. Our benchmarks demonstrate that our approach exceeds 99% soundness, indicating a near-zero false positive rate in identifying logical validity. Our approach produces auditable logical artifacts that substantiate the verification outcomes and can be used to improve the original text. 

**Abstract (ZH)**: 大型语言模型在自然语言解释和推理方面表现优异，但由于其固有的随机性，它们在受严格政策监管的金融和医疗等行业中的应用受到限制。为解决这一问题，我们提出了一种两阶段神经符号框架，该框架（1）利用带有可选人类指导的大型语言模型来正式化自然语言政策，从而实现形式化过程的精细控制；（2）在推理时自动形式化自然语言声明，以验证其与政策的逻辑正确性。当逻辑正确性至关重要时，我们会在推理时执行多个冗余形式化步骤，并通过语义等价性交叉检查形式化结果。我们的基准测试表明，我们的方法 Soundness 超过了 99%，显示出几乎零的假阳性率，用于识别逻辑有效性。我们的方法生成可审计的逻辑成果，可以验证验证结果，并可用于改进原始文本。 

---
# AuthSig: Safeguarding Scanned Signatures Against Unauthorized Reuse in Paperless Workflows 

**Title (ZH)**: 无纸化工作流中保护扫描签名免遭未经授权重用的安全机制 

**Authors**: RuiQiang Zhang, Zehua Ma, Guanjie Wang, Chang Liu, Hengyi Wang, Weiming Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2511.08967)  

**Abstract**: With the deepening trend of paperless workflows, signatures as a means of identity authentication are gradually shifting from traditional ink-on-paper to electronic this http URL the availability of dynamic pressure-sensitive and PKI-based digital signatures, static scanned signatures remain prevalent in practice due to their convenience. However, these static images, having almost lost their authentication attributes, cannot be reliably verified and are vulnerable to malicious copying and reuse. To address these issues, we propose AuthSig, a novel static electronic signature framework based on generative models and watermark, which binds authentication information to the signature image. Leveraging the human visual system's insensitivity to subtle style variations, AuthSig finely modulates style embeddings during generation to implicitly encode watermark bits-enforcing a One Signature, One Use this http URL overcome the scarcity of handwritten signature data and the limitations of traditional augmentation methods, we introduce a keypoint-driven data augmentation strategy that effectively enhances style diversity to support robust watermark embedding. Experimental results show that AuthSig achieves over 98% extraction accuracy under both digital-domain distortions and signature-specific degradations, and remains effective even in print-scan scenarios. 

**Abstract (ZH)**: 基于生成模型和水印的新型静态电子签名框架(AuthSig) 

---
# From Structure to Detail: Hierarchical Distillation for Efficient Diffusion Model 

**Title (ZH)**: 从结构到细节：分层蒸馏高效扩散模型 

**Authors**: Hanbo Cheng, Peng Wang, Kaixiang Lei, Qi Li, Zhen Zou, Pengfei Hu, Jun Du  

**Link**: [PDF](https://arxiv.org/pdf/2511.08930)  

**Abstract**: The inference latency of diffusion models remains a critical barrier to their real-time application. While trajectory-based and distribution-based step distillation methods offer solutions, they present a fundamental trade-off. Trajectory-based methods preserve global structure but act as a "lossy compressor", sacrificing high-frequency details. Conversely, distribution-based methods can achieve higher fidelity but often suffer from mode collapse and unstable training. This paper recasts them from independent paradigms into synergistic components within our novel Hierarchical Distillation (HD) framework. We leverage trajectory distillation not as a final generator, but to establish a structural ``sketch", providing a near-optimal initialization for the subsequent distribution-based refinement stage. This strategy yields an ideal initial distribution that enhances the ceiling of overall performance. To further improve quality, we introduce and refine the adversarial training process. We find standard discriminator structures are ineffective at refining an already high-quality generator. To overcome this, we introduce the Adaptive Weighted Discriminator (AWD), tailored for the HD pipeline. By dynamically allocating token weights, AWD focuses on local imperfections, enabling efficient detail refinement. Our approach demonstrates state-of-the-art performance across diverse tasks. On ImageNet $256\times256$, our single-step model achieves an FID of 2.26, rivaling its 250-step teacher. It also achieves promising results on the high-resolution text-to-image MJHQ benchmark, proving its generalizability. Our method establishes a robust new paradigm for high-fidelity, single-step diffusion models. 

**Abstract (ZH)**: 扩散模型的推理延迟仍然是其实时应用的关键障碍。虽然基于轨迹和基于分布的步进蒸馏方法提供了解决方案，但它们之间存在基本的权衡。基于轨迹的方法保留全局结构，但作为“冗余压缩器”，牺牲了高频细节。相反，基于分布的方法可以实现更高的保真度，但往往遭受模式崩溃和不稳定的训练。本文将它们从独立范式重新构想为我们全新的层次蒸馏（HD）框架中的协同组件。我们利用基于轨迹的蒸馏不仅作为最终生成器，而是用来建立一个结构“素描”，为后续的基于分布的精加工阶段提供近最优的初始化。这种策略产生了一个理想的初始分布，增强了整体性能的天花板。为了进一步提高质量，我们引入并改进了对抗训练过程。我们发现标准的鉴别器结构对精炼已经高质量的生成器效果不佳。为此，我们引入了适应性加权鉴别器（AWD），专门针对HD流水线。通过动态分配TOKEN权重，AWD专注于局部瑕疵，从而实现高效详细的精加工。我们的方法在多种任务中表现出最先进的性能。在ImageNet $256\times256$上，我们的一步模型达到了2.26的FID，接近其250步的教师模型。此外，它在高分辨率文本到图像的MJHQ基准测试上也取得了令人振奋的结果，证明了其通用性。我们的方法建立了高保真、单步骤扩散模型的稳健新范式。 

---
# Achieving Equilibrium under Utility Heterogeneity: An Agent-Attention Framework for Multi-Agent Multi-Objective Reinforcement Learning 

**Title (ZH)**: 在效用异质性下的均衡实现：基于代理注意力的多代理多目标 reinforcement learning 框架 

**Authors**: Zhuhui Li, Chunbo Luo, Liming Huang, Luyu Qi, Geyong Min  

**Link**: [PDF](https://arxiv.org/pdf/2511.08926)  

**Abstract**: Multi-agent multi-objective systems (MAMOS) have emerged as powerful frameworks for modelling complex decision-making problems across various real-world domains, such as robotic exploration, autonomous traffic management, and sensor network optimisation. MAMOS offers enhanced scalability and robustness through decentralised control and more accurately reflects inherent trade-offs between conflicting objectives. In MAMOS, each agent uses utility functions that map return vectors to scalar values. Existing MAMOS optimisation methods face challenges in handling heterogeneous objective and utility function settings, where training non-stationarity is intensified due to private utility functions and the associated policies. In this paper, we first theoretically prove that direct access to, or structured modeling of, global utility functions is necessary for the Bayesian Nash Equilibrium under decentralised execution constraints. To access the global utility functions while preserving the decentralised execution, we propose an Agent-Attention Multi-Agent Multi-Objective Reinforcement Learning (AA-MAMORL) framework. Our approach implicitly learns a joint belief over other agents' utility functions and their associated policies during centralised training, effectively mapping global states and utilities to each agent's policy. In execution, each agent independently selects actions based on local observations and its private utility function to approximate a BNE, without relying on inter-agent communication. We conduct comprehensive experiments in both a custom-designed MAMO Particle environment and the standard MOMALand benchmark. The results demonstrate that access to global preferences and our proposed AA-MAMORL significantly improve performance and consistently outperform state-of-the-art methods. 

**Abstract (ZH)**: 多代理多目标系统中的多代理注意机制多目标强化学习框架（Agent-Attention Multi-Agent Multi-Objective Reinforcement Learning for MAMOS） 

---
# Consistency Change Detection Framework for Unsupervised Remote Sensing Change Detection 

**Title (ZH)**: 基于无监督遥感变化检测的一致性变化检测框架 

**Authors**: Yating Liu, Yan Lu  

**Link**: [PDF](https://arxiv.org/pdf/2511.08904)  

**Abstract**: Unsupervised remote sensing change detection aims to monitor and analyze changes from multi-temporal remote sensing images in the same geometric region at different times, without the need for labeled training data. Previous unsupervised methods attempt to achieve style transfer across multi-temporal remote sensing images through reconstruction by a generator network, and then capture the unreconstructable areas as the changed regions. However, it often leads to poor performance due to generator overfitting. In this paper, we propose a novel Consistency Change Detection Framework (CCDF) to address this challenge. Specifically, we introduce a Cycle Consistency (CC) module to reduce the overfitting issues in the generator-based reconstruction. Additionally, we propose a Semantic Consistency (SC) module to enable detail reconstruction. Extensive experiments demonstrate that our method outperforms other state-of-the-art approaches. 

**Abstract (ZH)**: 无监督遥感变化检测旨在通过生成网络进行重构，监测和分析同一几何区域在不同时段的多时相遥感图像的变化，无需使用标注训练数据。以往的无监督方法试图通过生成网络实现多时相遥感图像之间的风格迁移，并通过捕捉不可重构的区域来识别变化区域，但由于生成器过拟合常常导致性能较差。本文提出了一种新的一致性变化检测框架（CCDF）以应对这一挑战。具体地，我们引入了一致性循环模块（CC 模块）以减轻基于生成器的重构中的过拟合问题，并提出了语义一致性（SC）模块以实现细节重构。 extensive 实验表明，我们的方法优于其他最先进的方法。 

---
# Classifying Histopathologic Glioblastoma Sub-regions with EfficientNet 

**Title (ZH)**: 使用EfficientNet对组织病理学胶质母细胞瘤亚区进行分类 

**Authors**: Sanyukta Adap, Ujjwal Baid, Spyridon Bakas  

**Link**: [PDF](https://arxiv.org/pdf/2511.08896)  

**Abstract**: Glioblastoma (GBM) is the most common aggressive, fast-growing brain tumor, with a grim prognosis. Despite clinical diagnostic advancements, there have not been any substantial improvements to patient prognosis. Histopathological assessment of excised tumors is the first line of clinical diagnostic routine. We hypothesize that automated, robust, and accurate identification of distinct histological sub-regions within GBM could contribute to morphologically understanding this disease at scale. In this study, we designed a four-step deep learning approach to classify six (6) histopathological regions and quantitatively evaluated it on the BraTS-Path 2024 challenge dataset, which includes digitized Hematoxylin \& Eosin (H\&E) stained GBM tissue sections annotated for six distinct regions. We used the challenge's publicly available training dataset to develop and evaluate the effectiveness of several variants of EfficientNet architectures (i.e., B0, B1, B2, B3, B4). EfficientNet-B1 and EfficientNet-B4 achieved the best performance, achieving an F1 score of 0.98 in a 5-fold cross-validation configuration using the BraTS-Path training set. The quantitative performance evaluation of our proposed approach with EfficientNet-B1 on the BraTS-Path hold-out validation data and the final hidden testing data yielded F1 scores of 0.546 and 0.517, respectively, for the associated 6-class classification task. The difference in the performance on training, validation, and testing data highlights the challenge of developing models that generalize well to new data, which is crucial for clinical applications. The source code of the proposed approach can be found at the GitHub repository of Indiana University Division of Computational Pathology: this https URL. 

**Abstract (ZH)**: 胶质母细胞瘤（GBM）是最常见的一种侵袭性、快速生长的脑肿瘤，预后极为严峻。尽管临床诊断技术有所进步，患者的预后仍未有显著改善。切除肿瘤的组织病理学评估是临床诊断的第一步。我们假设自动化、稳健且准确地识别胶质母细胞瘤中不同的组织病理学亚区域，能够大规模地从形态学上理解这种疾病。在本研究中，我们设计了一种四步深度学习方法，用于分类六个组织病理学区域，并在包含六个不同区域注释的BraTS-Path 2024挑战数据集上进行定量评估。我们利用挑战提供的公开训练数据集，开发并评估了几种EfficientNet架构（即B0、B1、B2、B3、B4）的有效性。EfficientNet-B1和EfficientNet-B4表现出最佳性能，在使用BraTS-Path训练集的5折交叉验证配置中，F1分数达到了0.98。在使用BraTS-Path保留验证数据和最终隐藏测试数据进行的定量性能评估中，相应6类分类任务的F1分数分别为0.546和0.517。训练、验证和测试数据上的性能差异突显了开发在新数据上泛化良好的模型的挑战，这对于临床应用至关重要。所提出方法的源代码可以在Indiana University Computational Pathology Division的GitHub仓库中找到：this https URL。 

---
# FAST-CAD: A Fairness-Aware Framework for Non-Contact Stroke Diagnosis 

**Title (ZH)**: FAST-CAD：一个公平性的意识框架用于非接触式中风诊断 

**Authors**: Tianming Sha, Zechuan Chen, Zhan Cheng, Haotian Zhai, Xuwei Ding, Junnan Li, Haixiang Tang, Zaoting Sun, Yanchuan Tang, Yongzhe Yi, Yanjie Huang, Anhao Li, Yuan Gao, Keze Wang  

**Link**: [PDF](https://arxiv.org/pdf/2511.08887)  

**Abstract**: Stroke is an acute cerebrovascular disease, and timely diagnosis significantly improves patient survival. However, existing automated diagnosis methods suffer from fairness issues across demographic groups, potentially exacerbating healthcare disparities. In this work we propose FAST-CAD, a theoretically grounded framework that combines domain-adversarial training (DAT) with group distributionally robust optimization (Group-DRO) for fair and accurate non-contact stroke diagnosis. Our approach is built on domain adaptation and minimax fairness theory and provides convergence guarantees and fairness bounds. We curate a multimodal dataset covering 12 demographic subgroups defined by age, gender, and posture. FAST-CAD employs self-supervised encoders with adversarial domain discrimination to learn demographic-invariant representations, while Group-DRO optimizes worst-group risk to ensure robust performance across all subgroups. Extensive experiments show that our method achieves superior diagnostic performance while maintaining fairness across demographic groups, and our theoretical analysis supports the effectiveness of the unified DAT + Group-DRO framework. This work provides both practical advances and theoretical insights for fair medical AI systems. 

**Abstract (ZH)**: 面向公正和准确的无接触中风诊断的FAST-CAD框架 

---
# Conformal Prediction for Multi-Source Detection on a Network 

**Title (ZH)**: 网络多源检测的齐性预测 

**Authors**: Xingchao Jian, Purui Zhang, Lan Tian, Feng Ji, Wenfei Liang, Wee Peng Tay, Bihan Wen, Felix Krahmer  

**Link**: [PDF](https://arxiv.org/pdf/2511.08867)  

**Abstract**: Detecting the origin of information or infection spread in networks is a fundamental challenge with applications in misinformation tracking, epidemiology, and beyond. We study the multi-source detection problem: given snapshot observations of node infection status on a graph, estimate the set of source nodes that initiated the propagation. Existing methods either lack statistical guarantees or are limited to specific diffusion models and assumptions. We propose a novel conformal prediction framework that provides statistically valid recall guarantees for source set detection, independent of the underlying diffusion process or data distribution. Our approach introduces principled score functions to quantify the alignment between predicted probabilities and true sources, and leverages a calibration set to construct prediction sets with user-specified recall and coverage levels. The method is applicable to both single- and multi-source scenarios, supports general network diffusion dynamics, and is computationally efficient for large graphs. Empirical results demonstrate that our method achieves rigorous coverage with competitive accuracy, outperforming existing baselines in both reliability and this http URL code is available online. 

**Abstract (ZH)**: 检测网络中信息或感染传播的起源是一个基本挑战，具有 misinformation 跟踪、流行病学等领域中的应用。我们研究多源检测问题：给定图上节点感染状态的快照观察结果，估计引发传播的源节点集合。现有方法要么缺乏统计保证，要么局限于特定的扩散模型和假设。我们提出了一种新的卷积预测框架，该框架独立于底层扩散过程或数据分布，提供了源集检测的统计有效性检索保证。该方法引入了可量化预测概率与真实源节点之间对齐程度的原则性评分函数，并利用校准集构建具有用户指定检索率和覆盖率的预测集。该方法适用于单源和多源情景，支持一般的网络扩散动力学，并且对于大型图具有高效性。实验证明，我们的方法在可靠性和准确性方面都表现出色，优于现有基线方法。该代码已在网上公开。 

---
# Transformer-Based Sleep Stage Classification Enhanced by Clinical Information 

**Title (ZH)**: 基于Transformer的睡眠阶段分类方法融合临床信息 

**Authors**: Woosuk Chung, Seokwoo Hong, Wonhyeok Lee, Sangyoon Bae  

**Link**: [PDF](https://arxiv.org/pdf/2511.08864)  

**Abstract**: Manual sleep staging from polysomnography (PSG) is labor-intensive and prone to inter-scorer variability. While recent deep learning models have advanced automated staging, most rely solely on raw PSG signals and neglect contextual cues used by human experts. We propose a two-stage architecture that combines a Transformer-based per-epoch encoder with a 1D CNN aggregator, and systematically investigates the effect of incorporating explicit context: subject-level clinical metadata (age, sex, BMI) and per-epoch expert event annotations (apneas, desaturations, arousals, periodic breathing). Using the Sleep Heart Health Study (SHHS) cohort (n=8,357), we demonstrate that contextual fusion substantially improves staging accuracy. Compared to a PSG-only baseline (macro-F1 0.7745, micro-F1 0.8774), our final model achieves macro-F1 0.8031 and micro-F1 0.9051, with event annotations contributing the largest gains. Notably, feature fusion outperforms multi-task alternatives that predict the same auxiliary labels. These results highlight that augmenting learned representations with clinically meaningful features enhances both performance and interpretability, without modifying the PSG montage or requiring additional sensors. Our findings support a practical and scalable path toward context-aware, expert-aligned sleep staging systems. 

**Abstract (ZH)**: 基于 polysomnography 的手动睡眠分期劳动密集且易受评分者间变异影响。虽然近年来的深度学习模型提升了自动分期的能力，但大多数模型仅依赖原始 PSG 信号而忽视了人类专家使用的上下文线索。我们提出了一种两阶段架构，结合了基于 Transformer 的每 Epoch 编码器和 1D CNN 聚合器，并系统地研究了引入明确上下文的影响：受试者级别的临床元数据（年龄、性别、BMI）和每 Epoch 专家事件注释（呼吸暂停、低氧血症、觉醒、周期性呼吸）。使用 Sleep Heart Health Study（SHHS）队列（n=8,357），我们展示了上下文融合显著提高了分期准确性。与仅基于 PSG 的基线模型（macro-F1 0.7745，micro-F1 0.8774）相比，我们的最终模型实现了 macro-F1 0.8031 和 micro-F1 0.9051，其中事件注释带来了最大的提升。值得注意的是，特征融合优于预测相同辅助标签的多任务替代方案。这些结果强调，将学习表示与临床相关的特征结合起来，不仅能提高性能，还增强了可解释性，无需修改 PSG 检测配置或增加传感器。我们的发现支持了一种实用且可扩展的途径，以实现上下文感知且与专家一致的睡眠分期系统。 

---
# When is a System Discoverable from Data? Discovery Requires Chaos 

**Title (ZH)**: 何时可以从数据中发现一个系统？发现需要混沌。 

**Authors**: Zakhar Shumaylov, Peter Zaika, Philipp Scholl, Gitta Kutyniok, Lior Horesh, Carola-Bibiane Schönlieb  

**Link**: [PDF](https://arxiv.org/pdf/2511.08860)  

**Abstract**: The deep learning revolution has spurred a rise in advances of using AI in sciences. Within physical sciences the main focus has been on discovery of dynamical systems from observational data. Yet the reliability of learned surrogates and symbolic models is often undermined by the fundamental problem of non-uniqueness. The resulting models may fit the available data perfectly, but lack genuine predictive power. This raises the question: under what conditions can the systems governing equations be uniquely identified from a finite set of observations? We show, counter-intuitively, that chaos, typically associated with unpredictability, is crucial for ensuring a system is discoverable in the space of continuous or analytic functions. The prevalence of chaotic systems in benchmark datasets may have inadvertently obscured this fundamental limitation.
More concretely, we show that systems chaotic on their entire domain are discoverable from a single trajectory within the space of continuous functions, and systems chaotic on a strange attractor are analytically discoverable under a geometric condition on the attractor. As a consequence, we demonstrate for the first time that the classical Lorenz system is analytically discoverable. Moreover, we establish that analytic discoverability is impossible in the presence of first integrals, common in real-world systems. These findings help explain the success of data-driven methods in inherently chaotic domains like weather forecasting, while revealing a significant challenge for engineering applications like digital twins, where stable, predictable behavior is desired. For these non-chaotic systems, we find that while trajectory data alone is insufficient, certain prior physical knowledge can help ensure discoverability. These findings warrant a critical re-evaluation of the fundamental assumptions underpinning purely data-driven discovery. 

**Abstract (ZH)**: 深度学习革命促进了在科学中使用AI的技术进步。在物理科学领域，主要关注从观测数据中发现动力系统。然而，学到的替代模型和符号模型的可靠性往往受到非唯一性这一基本问题的挑战。这些模型可能完美地拟合可用数据，但缺乏真正的预测能力。这引发了问题：在什么条件下可以从有限的观测数据中唯一地识别出支配方程？我们表明，令人惊讶的是，通常与不可预测性相关联的混沌对于确保系统在连续或解析函数空间中可被发现至关重要。基准数据集中混沌系统的普遍性可能无意中模糊了这一基本局限性。

更具体地说，我们证明了在整个域上混沌的系统可以从单个轨迹在连续函数空间中被发现，而奇性吸引子上的混沌系统在满足吸引子的几何条件下是解析可发现的。因此，我们首次证明经典洛伦兹系统是解析可发现的。此外，我们建立了在存在守恒量情况下解析可发现性是不可能的，而守恒量在真实系统中常见。这些发现有助于解释在天气预报等固有混沌领域中数据驱动方法的成功，同时揭示了工程应用如数字孪生中所需稳定可预测行为的重大挑战。对于这些非混沌系统，我们发现仅轨迹数据是不足的，但某些先验物理知识可以确保可发现性。这些发现要求对纯粹基于数据驱动发现的基本假设进行重新评估。 

---
# Rethinking Graph Super-resolution: Dual Frameworks for Topological Fidelity 

**Title (ZH)**: 重新思考图超分辨率：拓扑保真的双框架方法 

**Authors**: Pragya Singh, Islem Rekik  

**Link**: [PDF](https://arxiv.org/pdf/2511.08853)  

**Abstract**: Graph super-resolution, the task of inferring high-resolution (HR) graphs from low-resolution (LR) counterparts, is an underexplored yet crucial research direction that circumvents the need for costly data acquisition. This makes it especially desirable for resource-constrained fields such as the medical domain. While recent GNN-based approaches show promise, they suffer from two key limitations: (1) matrix-based node super-resolution that disregards graph structure and lacks permutation invariance; and (2) reliance on node representations to infer edge weights, which limits scalability and expressivity. In this work, we propose two GNN-agnostic frameworks to address these issues. First, Bi-SR introduces a bipartite graph connecting LR and HR nodes to enable structure-aware node super-resolution that preserves topology and permutation invariance. Second, DEFEND learns edge representations by mapping HR edges to nodes of a dual graph, allowing edge inference via standard node-based GNNs. We evaluate both frameworks on a real-world brain connectome dataset, where they achieve state-of-the-art performance across seven topological measures. To support generalization, we introduce twelve new simulated datasets that capture diverse topologies and LR-HR relationships. These enable comprehensive benchmarking of graph super-resolution methods. 

**Abstract (ZH)**: 图超分辨率：从低分辨率图推断高分辨率图的任务是未充分探索但至关重要的研究方向，可以避免昂贵的数据获取需求，尤其适用于资源受限领域如医疗领域。尽管基于图神经网络（GNN）的方法显示出潜力，但它们存在两个关键限制：（1）基于矩阵的节点超分辨率忽视了图结构，缺乏置换不变性；（2）依赖节点表示来推断边权重，限制了可扩展性和表达能力。在本文中，我们提出了两种GNN无关的框架来解决这些问题。首先，Bi-SR通过将低分辨率和高分辨率节点连接到双图来引入结构感知的节点超分辨率，以保持拓扑和置换不变性。其次，DEFEND通过将高分辨率边映射到双图的节点上来学习边表示，允许通过标准的基于节点的GNN进行边推断。我们在一个真实的脑连接组数据集上评估了这两个框架，它们在七个拓扑度量上达到了最先进的性能。为了支持泛化，我们引入了十二个新的模拟数据集，这些数据集捕捉到了多样化的拓扑结构和低分辨率-高分辨率关系，这使我们能够对图超分辨率方法进行全面基准测试。 

---
# 3D Guard-Layer: An Integrated Agentic AI Safety System for Edge Artificial Intelligence 

**Title (ZH)**: 3D 代理安全层：边缘人工智能的集成自主AI安全系统 

**Authors**: Eren Kurshan, Yuan Xie, Paul Franzon  

**Link**: [PDF](https://arxiv.org/pdf/2511.08842)  

**Abstract**: AI systems have found a wide range of real-world applications in recent years. The adoption of edge artificial intelligence, embedding AI directly into edge devices, is rapidly growing. Despite the implementation of guardrails and safety mechanisms, security vulnerabilities and challenges have become increasingly prevalent in this domain, posing a significant barrier to the practical deployment and safety of AI systems. This paper proposes an agentic AI safety architecture that leverages 3D to integrate a dedicated safety layer. It introduces an adaptive AI safety infrastructure capable of dynamically learning and mitigating attacks against the AI system. The system leverages the inherent advantages of co-location with the edge computing hardware to continuously monitor, detect and proactively mitigate threats to the AI system. The integration of local processing and learning capabilities enhances resilience against emerging network-based attacks while simultaneously improving system reliability, modularity, and performance, all with minimal cost and 3D integration overhead. 

**Abstract (ZH)**: 基于3D的代理AI安全架构：集成专用安全层以适应AI系统动态学习和缓解攻击 

---
# Enhancing DPSGD via Per-Sample Momentum and Low-Pass Filtering 

**Title (ZH)**: 基于样本动量和低通滤波的DPSGD增强方法 

**Authors**: Xincheng Xu, Thilina Ranbaduge, Qing Wang, Thierry Rakotoarivelo, David Smith  

**Link**: [PDF](https://arxiv.org/pdf/2511.08841)  

**Abstract**: Differentially Private Stochastic Gradient Descent (DPSGD) is widely used to train deep neural networks with formal privacy guarantees. However, the addition of differential privacy (DP) often degrades model accuracy by introducing both noise and bias. Existing techniques typically address only one of these issues, as reducing DP noise can exacerbate clipping bias and vice-versa. In this paper, we propose a novel method, \emph{DP-PMLF}, which integrates per-sample momentum with a low-pass filtering strategy to simultaneously mitigate DP noise and clipping bias. Our approach uses per-sample momentum to smooth gradient estimates prior to clipping, thereby reducing sampling variance. It further employs a post-processing low-pass filter to attenuate high-frequency DP noise without consuming additional privacy budget. We provide a theoretical analysis demonstrating an improved convergence rate under rigorous DP guarantees, and our empirical evaluations reveal that DP-PMLF significantly enhances the privacy-utility trade-off compared to several state-of-the-art DPSGD variants. 

**Abstract (ZH)**: Differentially Private Stochastic Gradient Descent (DPSGD)具有形式化隐私保证的深度神经网络训练方法 

---
# Beyond Task-Oriented and Chitchat Dialogues: Proactive and Transition-Aware Conversational Agents 

**Title (ZH)**: 超越任务导向和闲聊对话：前瞻性和状态转移 Awareness 对话代理 

**Authors**: Yejin Yoon, Yuri Son, Namyoung So, Minseo Kim, Minsoo Cho, Chanhee Park, Seungshin Lee, Taeuk Kim  

**Link**: [PDF](https://arxiv.org/pdf/2511.08835)  

**Abstract**: Conversational agents have traditionally been developed for either task-oriented dialogue (TOD) or open-ended chitchat, with limited progress in unifying the two. Yet, real-world conversations naturally involve fluid transitions between these modes. To address this gap, we introduce TACT (TOD-And-Chitchat Transition), a dataset designed for transition-aware dialogue modeling that incorporates structurally diverse and integrated mode flows. TACT supports both user- and agent-driven mode switches, enabling robust modeling of complex conversational dynamics. To evaluate an agent's ability to initiate and recover from mode transitions, we propose two new metrics -- Switch and Recovery. Models trained on TACT outperform baselines in both intent detection and mode transition handling. Moreover, applying Direct Preference Optimization (DPO) to TACT-trained models yields additional gains, achieving 75.74\% joint mode-intent accuracy and a 70.1\% win rate against GPT-4o in human evaluation. These results demonstrate that pairing structurally diverse data with DPO enhances response quality and transition control, paving the way for more proactive and transition-aware conversational agents. 

**Abstract (ZH)**: 基于转换意识的对话模型数据集TACT：任务导向对话与开放式闲聊的过渡融合 

---
# TIGER-MARL: Enhancing Multi-Agent Reinforcement Learning with Temporal Information through Graph-based Embeddings and Representations 

**Title (ZH)**: TIGER-MARL：通过基于图的嵌入与表示增强多智能体强化学习中的时间信息 

**Authors**: Nikunj Gupta, Ludwika Twardecka, James Zachary Hare, Jesse Milzman, Rajgopal Kannan, Viktor Prasanna  

**Link**: [PDF](https://arxiv.org/pdf/2511.08832)  

**Abstract**: In this paper, we propose capturing and utilizing \textit{Temporal Information through Graph-based Embeddings and Representations} or \textbf{TIGER} to enhance multi-agent reinforcement learning (MARL). We explicitly model how inter-agent coordination structures evolve over time. While most MARL approaches rely on static or per-step relational graphs, they overlook the temporal evolution of interactions that naturally arise as agents adapt, move, or reorganize cooperation strategies. Capturing such evolving dependencies is key to achieving robust and adaptive coordination. To this end, TIGER constructs dynamic temporal graphs of MARL agents, connecting their current and historical interactions. It then employs a temporal attention-based encoder to aggregate information across these structural and temporal neighborhoods, yielding time-aware agent embeddings that guide cooperative policy learning. Through extensive experiments on two coordination-intensive benchmarks, we show that TIGER consistently outperforms diverse value-decomposition and graph-based MARL baselines in task performance and sample efficiency. Furthermore, we conduct comprehensive ablation studies to isolate the impact of key design parameters in TIGER, revealing how structural and temporal factors can jointly shape effective policy learning in MARL. All codes can be found here: this https URL. 

**Abstract (ZH)**: 基于图表示的时序信息捕获与利用或TIGER以增强多agent强化学习（MARL） 

---
# Hey Pentti, We Did (More of) It!: A Vector-Symbolic Lisp With Residue Arithmetic 

**Title (ZH)**: 嘿皮嫩尼，我们又做到了（更多的部分）：一种基于同余算术的向量-符号Lisp 

**Authors**: Connor Hanley, Eilene Tomkins-Flanaganm, Mary Alexandria Kelly  

**Link**: [PDF](https://arxiv.org/pdf/2511.08767)  

**Abstract**: Using Frequency-domain Holographic Reduced Representations (FHRRs), we extend a Vector-Symbolic Architecture (VSA) encoding of Lisp 1.5 with primitives for arithmetic operations using Residue Hyperdimensional Computing (RHC). Encoding a Turing-complete syntax over a high-dimensional vector space increases the expressivity of neural network states, enabling network states to contain arbitrarily structured representations that are inherently interpretable. We discuss the potential applications of the VSA encoding in machine learning tasks, as well as the importance of encoding structured representations and designing neural networks whose behavior is sensitive to the structure of their representations in virtue of attaining more general intelligent agents than exist at present. 

**Abstract (ZH)**: 使用频域全息简化表示（FHRRs），我们扩展了Lisp 1.5的向量符号架构（VSA）编码，并使用残差超维计算（RHC）为其添加了算术操作原语。在高维向量空间中对图灵完备的语法进行编码增加了神经网络状态的表达能力，使网络状态能够包含任意结构化的表示，这些表示本原上具有可解释性。我们讨论了VSA编码在机器学习任务中的潜在应用，以及编码结构化表示和设计对表示结构敏感的神经网络的重要性，以便实现比当前更加通用的智能代理。 

---
# FAIRPLAI: A Human-in-the-Loop Approach to Fair and Private Machine Learning 

**Title (ZH)**: FAIRPLAI：以人为本的公平性和隐私性机器学习方法 

**Authors**: David Sanchez Jr., Holly Lopez, Michelle Buraczyk, Anantaa Kotal  

**Link**: [PDF](https://arxiv.org/pdf/2511.08702)  

**Abstract**: As machine learning systems move from theory to practice, they are increasingly tasked with decisions that affect healthcare access, financial opportunities, hiring, and public services. In these contexts, accuracy is only one piece of the puzzle - models must also be fair to different groups, protect individual privacy, and remain accountable to stakeholders. Achieving all three is difficult: differential privacy can unintentionally worsen disparities, fairness interventions often rely on sensitive data that privacy restricts, and automated pipelines ignore that fairness is ultimately a human and contextual judgment. We introduce FAIRPLAI (Fair and Private Learning with Active Human Influence), a practical framework that integrates human oversight into the design and deployment of machine learning systems. FAIRPLAI works in three ways: (1) it constructs privacy-fairness frontiers that make trade-offs between accuracy, privacy guarantees, and group outcomes transparent; (2) it enables interactive stakeholder input, allowing decision-makers to select fairness criteria and operating points that reflect their domain needs; and (3) it embeds a differentially private auditing loop, giving humans the ability to review explanations and edge cases without compromising individual data security. Applied to benchmark datasets, FAIRPLAI consistently preserves strong privacy protections while reducing fairness disparities relative to automated baselines. More importantly, it provides a straightforward, interpretable process for practitioners to manage competing demands of accuracy, privacy, and fairness in socially impactful applications. By embedding human judgment where it matters most, FAIRPLAI offers a pathway to machine learning systems that are effective, responsible, and trustworthy in practice. GitHub: this https URL 

**Abstract (ZH)**: 面向公平与隐私的主动人类监督学习框架：FAIRPLAI 

---
# Binary and Multiclass Cyberattack Classification on GeNIS Dataset 

**Title (ZH)**: 基于GeNIS数据集的二分类和多分类网络攻击识别 

**Authors**: Miguel Silva, Daniela Pinto, João Vitorino, Eva Maia, Isabel Praça, Ivone Amorim, Maria João Viamonte  

**Link**: [PDF](https://arxiv.org/pdf/2511.08660)  

**Abstract**: The integration of Artificial Intelligence (AI) in Network Intrusion Detection Systems (NIDS) is a promising approach to tackle the increasing sophistication of cyberattacks. However, since Machine Learning (ML) and Deep Learning (DL) models rely heavily on the quality of their training data, the lack of diverse and up-to-date datasets hinders their generalization capability to detect malicious activity in previously unseen network traffic. This study presents an experimental validation of the reliability of the GeNIS dataset for AI-based NIDS, to serve as a baseline for future benchmarks. Five feature selection methods, Information Gain, Chi-Squared Test, Recursive Feature Elimination, Mean Absolute Deviation, and Dispersion Ratio, were combined to identify the most relevant features of GeNIS and reduce its dimensionality, enabling a more computationally efficient detection. Three decision tree ensembles and two deep neural networks were trained for both binary and multiclass classification tasks. All models reached high accuracy and F1-scores, and the ML ensembles achieved slightly better generalization while remaining more efficient than DL models. Overall, the obtained results indicate that the GeNIS dataset supports intelligent intrusion detection and cyberattack classification with time-based and quantity-based behavioral features. 

**Abstract (ZH)**: 人工智能（AI）在网络入侵检测系统（NIDS）中的集成是应对日益 sophisticated 的网络攻击的一种有前途的方法。然而，由于机器学习（ML）和深度学习（DL）模型高度依赖其训练数据的质量，缺乏多样性和及时更新的数据集阻碍了它们在检测未知网络流量中的恶意活动时的一般化能力。本研究通过实验验证了GeNIS数据集在基于AI的NIDS中的可靠性，以作为未来基准测试的基线。结合使用了五种特征选择方法（信息增益、卡方检验、递归特征消除、绝对均值偏差和分散比），以识别GeNIS中最相关的特征并减少其维度，从而提高计算效率。训练了三种决策树集成和两种深度神经网络模型，用于二分类和多分类任务。所有模型均达到较高的准确率和F1分数，而机器学习集成在保持计算效率的同时略好于深度学习模型。总体而言，实验结果表明，GeNIS数据集支持基于时间特征和数量特征的智能入侵检测和网络攻击分类。 

---
# Introduction to Automated Negotiation 

**Title (ZH)**: 自动化协商导论 

**Authors**: Dave de Jonge  

**Link**: [PDF](https://arxiv.org/pdf/2511.08659)  

**Abstract**: This book is an introductory textbook targeted towards computer science students who are completely new to the topic of automated negotiation. It does not require any prerequisite knowledge, except for elementary mathematics and basic programming skills.
This book comes with an simple toy-world negotiation framework implemented in Python that can be used by the readers to implement their own negotiation algorithms and perform experiments with them. This framework is small and simple enough that any reader who does not like to work in Python should be able to re-implement it very quickly in any other programming language of their choice. 

**Abstract (ZH)**: 本书面向完全新接触自动谈判主题的计算机科学学生，是一本入门教材。它不需要任何先修知识，只需具备基础数学和基本编程能力。本书附带一个用Python实现的简单玩具世界谈判框架，读者可以使用该框架实现自己的谈判算法并进行实验。该框架足够小且简单，任何不喜欢在Python中工作的读者都可以很快用他们选择的其他编程语言重实现它。 

---
# Learning the Basis: A Kolmogorov-Arnold Network Approach Embedding Green's Function Priors 

**Title (ZH)**: 学习基函数：Kolmogorov-Arnold 网络方法嵌入格林函数先验 

**Authors**: Rui Zhu, Yuexing Peng, George C. Alexandropoulos, Wenbo Wang, Wei Xiang  

**Link**: [PDF](https://arxiv.org/pdf/2511.08655)  

**Abstract**: The Method of Moments (MoM) is constrained by the usage of static, geometry-defined basis functions, such as the Rao-Wilton-Glisson (RWG) basis. This letter reframes electromagnetic modeling around a learnable basis representation rather than solving for the coefficients over a fixed basis. We first show that the RWG basis is essentially a static and piecewise-linear realization of the Kolmogorov-Arnold representation theorem. Inspired by this insight, we propose PhyKAN, a physics-informed Kolmogorov-Arnold Network (KAN) that generalizes RWG into a learnable and adaptive basis family. Derived from the EFIE, PhyKAN integrates a local KAN branch with a global branch embedded with Green's function priors to preserve physical consistency. It is demonstrated that, across canonical geometries, PhyKAN achieves sub-0.01 reconstruction errors as well as accurate, unsupervised radar cross section predictions, offering an interpretable, physics-consistent bridge between classical solvers and modern neural network models for electromagnetic modeling. 

**Abstract (ZH)**: PhyKAN：基于物理信息的Kolmogorov-Arnold网络在电磁建模中的应用 

---
# AI-generated podcasts: Synthetic Intimacy and Cultural Translation in NotebookLM's Audio Overviews 

**Title (ZH)**: AI生成的播客：NotebookLM音频概述中的合成亲密感与文化翻译 

**Authors**: Jill Walker Rettberg  

**Link**: [PDF](https://arxiv.org/pdf/2511.08654)  

**Abstract**: This paper analyses AI-generated podcasts produced by Google's NotebookLM, which generates audio podcasts with two chatty AI hosts discussing whichever documents a user uploads. While AI-generated podcasts have been discussed as tools, for instance in medical education, they have not yet been analysed as media. By uploading different types of text and analysing the generated outputs I show how the podcasts' structure is built around a fixed template. I also find that NotebookLM not only translates texts from other languages into a perky standardised Mid-Western American accent, it also translates cultural contexts to a white, educated, middle-class American default. This is a distinct development in how publics are shaped by media, marking a departure from the multiple public spheres that scholars have described in human podcasting from the early 2000s until today, where hosts spoke to specific communities and responded to listener comments, to an abstraction of the podcast genre. 

**Abstract (ZH)**: 本研究分析了由Google的NotebookLM生成的AI播客，该系统生成包含两位聊天式AI主持人讨论用户上传文档的音频播客。虽然AI生成的播客已在诸如医学教育等领域被用作工具，但它们尚未被作为媒体进行分析。通过上传不同类型的文本并分析生成的输出，本文展示了播客结构如何围绕固定模板构建。此外，我发现在将其他语言的文本翻译成典型的中西部美国口音的同时，NotebookLM还将文化背景翻译为白人、受过教育的中产阶级美国默认模式。这是一种在公共空间由媒体塑造方面的新发展，标志着与自2000年代初至今人类播客所描述的多个公共领域形态的分离，从主持人面向特定社区并与听众交流，转变为播客类型的抽象化。 

---
# Accelerating Training Speed of Tiny Recursive Models via Curriculum Guided Adaptive Recursion 

**Title (ZH)**: 基于 Curriculum 引导自适应递归加速 Tiny 递归模型训练速度 

**Authors**: Kaleem Ullah Qasim, Jiashu Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2511.08653)  

**Abstract**: Recursive reasoning models achieve remarkable performance on complex reasoning tasks through iterative refinement, enabling tiny networks to match large language models thousands of times their size. However, training remains computationally expensive, prior work reporting approximately 36 GPU-hours per dataset, limiting broader adoption and research. We propose CGAR, a novel training methodology that applies curriculum learning to architectural depth rather than traditional data ordering. CGAR introduces two synergistic components: Progressive Depth Curriculum dynamically adjusts recursion depth from shallow to deep configurations during training, preventing early overfitting while reducing computational cost, and Hierarchical Supervision Weighting applies exponentially decaying importance to supervision steps, aligning loss weighting with observed gradient magnitude decay. On Sudoku-Extreme with 423,168 test puzzles, CGAR achieves 1.71x training speedup (10.93 to 6.38 hours, 42% cost reduction) with only 0.63% accuracy drop (86.65% to 86.02%). Systematic ablations reveal Progressive Depth Curriculum alone achieves 2.26x speedup with 85.47% accuracy, demonstrating a rare Pareto improvement where architectural curriculum simultaneously enhances training efficiency and solution quality. CGAR-trained models exhibit superior inference efficiency with 100% halting accuracy and 11% fewer reasoning steps. Our work demonstrates that principled curriculum on architectural depth enables efficient training of recursive reasoning models on modest hardware. Code and models: this https URL and this https URL 

**Abstract (ZH)**: Recursive推理模型通过迭代优化在复杂推理任务中表现出色，使小型网络能够匹配合其数千倍大的语言模型。然而，训练依然计算成本高昂，先前工作报告每个数据集大约需要36个GPU小时，限制了更广泛的应用和研究。我们提出了CGAR，一种新颖的训练方法，该方法将课程学习应用于架构深度而非传统的数据排序。CGAR引入了两个协同工作的组件：渐进深度课程在训练过程中动态调整递归深度，从浅层到深层配置，防止早期过拟合并降低计算成本；分层监督加权应用指数衰减的重要性权重，使损失权重与观察到的梯度幅度衰减相一致。在包含423,168个测试数独谜题的Sudoku-Extreme数据集上，CGAR实现了1.71倍的训练速度提升（从10.93小时减少到6.38小时，成本降低42%），同时只降低了0.63%的准确率（从86.65%下降到86.02%）。系统性的消融实验表明，仅渐进深度课程即可实现2.26倍的速度提升，并且准确率达到85.47%，显示出一种罕见的帕累托改进，其中架构课程同时提升了训练效率和解的质量。CGAR训练的模型在推理效率方面表现出色，准确率达到100%，推理步骤减少11%。我们的工作表明，基于架构深度的原则性课程学习能够在 modest 硬件上有效训练递归推理模型。代码和模型：此链接和此链接。 

---
# Bio AI Agent: A Multi-Agent Artificial Intelligence System for Autonomous CAR-T Cell Therapy Development with Integrated Target Discovery, Toxicity Prediction, and Rational Molecular Design 

**Title (ZH)**: 生物AI代理：一种集成靶点发现、毒性预测和理性分子设计的自主CAR-T细胞疗法开发多智能体人工智能系统 

**Authors**: Yi Ni, Liwei Zhu, Shuai Li  

**Link**: [PDF](https://arxiv.org/pdf/2511.08649)  

**Abstract**: Chimeric antigen receptor T-cell (CAR-T) therapy represents a paradigm shift in cancer treatment, yet development timelines of 8-12 years and clinical attrition rates exceeding 40-60% highlight critical inefficiencies in target selection, safety assessment, and molecular optimization. We present Bio AI Agent, a multi-agent artificial intelligence system powered by large language models that enables autonomous CAR-T development through collaborative specialized agents. The system comprises six autonomous agents: Target Selection Agent for multi-parametric antigen prioritization across >10,000 cancer-associated targets, Toxicity Prediction Agent for comprehensive safety profiling integrating tissue expression atlases and pharmacovigilance databases, Molecular Design Agent for rational CAR engineering, Patent Intelligence Agent for freedom-to-operate analysis, Clinical Translation Agent for regulatory compliance, and Decision Orchestration Agent for multi-agent coordination. Retrospective validation demonstrated autonomous identification of high-risk targets including FcRH5 (hepatotoxicity) and CD229 (off-tumor toxicity), patent infringement risks for CD38+SLAMF7 combinations, and generation of comprehensive development roadmaps. By enabling parallel processing, specialized reasoning, and autonomous decision-making superior to monolithic AI systems, Bio AI Agent addresses critical gaps in precision oncology development and has potential to accelerate translation of next-generation immunotherapies from discovery to clinic. 

**Abstract (ZH)**: Bio AI代理：一种多智能体人工智能系统，推动CAR-T疗法自主开发 

---
# Energy Consumption of Dataframe Libraries for End-to-End Deep Learning Pipelines:A Comparative Analysis 

**Title (ZH)**: 数据框架库在端到端深度学习管道中的能耗比较分析 

**Authors**: Punit Kumar, Asif Imran, Tevfik Kosar  

**Link**: [PDF](https://arxiv.org/pdf/2511.08644)  

**Abstract**: This paper presents a detailed comparative analysis of the performance of three major Python data manipulation libraries - Pandas, Polars, and Dask - specifically when embedded within complete deep learning (DL) training and inference pipelines. The research bridges a gap in existing literature by studying how these libraries interact with substantial GPU workloads during critical phases like data loading, preprocessing, and batch feeding. The authors measured key performance indicators including runtime, memory usage, disk usage, and energy consumption (both CPU and GPU) across various machine learning models and datasets. 

**Abstract (ZH)**: 本研究详细比较分析了三种主要的Python数据 manipulation 库——Pandas、Polars和Dask，在嵌入完整的深度学习（DL）训练和推理pipeline中的性能，特别是研究了这些库在数据加载、预处理和批次喂入等关键阶段与大规模GPU工作负载的交互情况。研究人员针对各种机器学习模型和数据集，衡量了包括运行时间、内存使用、磁盘使用和能耗（CPU和GPU）在内的关键性能指标。 

---
# The Journal of Prompt-Engineered Philosophy Or: How I Started to Track AI Assistance and Stopped Worrying About Slop 

**Title (ZH)**: 《促进型哲学杂志：或是我如何开始追踪AI协助并停止担心粗糙部分内容》 

**Authors**: Michele Loi  

**Link**: [PDF](https://arxiv.org/pdf/2511.08639)  

**Abstract**: Academic publishing increasingly requires authors to disclose AI assistance, yet imposes reputational costs for doing so--especially when such assistance is substantial. This article analyzes that structural contradiction, showing how incentives discourage transparency in precisely the work where it matters most. Traditional venues cannot resolve this tension through policy tweaks alone, as the underlying prestige economy rewards opacity. To address this, the article proposes an alternative publishing infrastructure: a venue outside prestige systems that enforces mandatory disclosure, enables reproduction-based review, and supports ecological validity through detailed documentation. As a demonstration of this approach, the article itself is presented as an example of AI-assisted scholarship under reasonably detailed disclosure, with representative prompt logs and modification records included. Rather than taking a position for or against AI-assisted scholarship, the article outlines conditions under which such work can be evaluated on its own terms: through transparent documentation, verification-oriented review, and participation by methodologically committed scholars. While focused on AI, the framework speaks to broader questions about how academic systems handle methodological innovation. 

**Abstract (ZH)**: 学术出版日益要求作者披露AI辅助，但披露反而会带来声誉成本——尤其是在这种辅助相当显著的情况下。本文分析了这一结构性矛盾，展示了激励机制如何在最为需要透明度的工作中抑制透明度。传统出版平台通过政策微调无法解决这一矛盾，因为基础的声望机制奖励 opacity。为此，本文提出了一种替代的出版基础设施：一个位于声望体系之外的平台，强制要求披露、支持基于再现的评审，并通过详细的文档支持生态效度。作为这一方法的示范，本文本身就被呈现为合理详细披露下的AI辅助研究的一个例子，附有代表性的提示日志和修改记录。本文不赞成或反对AI辅助研究，而是概述了在这种研究中可以自我评价的条件：通过透明的文档、基于验证的评审和方法论承诺学者的参与。尽管专注于AI，但这一框架涉及更广泛的关于学术系统如何处理方法创新的问题。 

---
# How do data owners say no? A case study of data consent mechanisms in web-scraped vision-language AI training datasets 

**Title (ZH)**: 数据拥有者如何说“不”？基于网页抓取的视觉-语言AI训练数据集中的数据同意机制案例研究 

**Authors**: Chung Peng Lee, Rachel Hong, Harry Jiang, Aster Plotnik, William Agnew, Jamie Morgenstern  

**Link**: [PDF](https://arxiv.org/pdf/2511.08637)  

**Abstract**: The internet has become the main source of data to train modern text-to-image or vision-language models, yet it is increasingly unclear whether web-scale data collection practices for training AI systems adequately respect data owners' wishes. Ignoring the owner's indication of consent around data usage not only raises ethical concerns but also has recently been elevated into lawsuits around copyright infringement cases. In this work, we aim to reveal information about data owners' consent to AI scraping and training, and study how it's expressed in DataComp, a popular dataset of 12.8 billion text-image pairs. We examine both the sample-level information, including the copyright notice, watermarking, and metadata, and the web-domain-level information, such as a site's Terms of Service (ToS) and Robots Exclusion Protocol. We estimate at least 122M of samples exhibit some indication of copyright notice in CommonPool, and find that 60\% of the samples in the top 50 domains come from websites with ToS that prohibit scraping. Furthermore, we estimate 9-13\% with 95\% confidence interval of samples from CommonPool to contain watermarks, where existing watermark detection methods fail to capture them in high fidelity. Our holistic methods and findings show that data owners rely on various channels to convey data consent, of which current AI data collection pipelines do not entirely respect. These findings highlight the limitations of the current dataset curation/release practice and the need for a unified data consent framework taking AI purposes into consideration. 

**Abstract (ZH)**: 互联网已成为训练现代文本-to-图像或视觉-语言模型的主要数据来源，但日益不清楚大规模网络数据采集实践是否充分尊重数据所有者的意愿。忽视数据使用时的数据主人同意 indication不仅引发了伦理上的关切，近年来还在版权侵权诉讼中被提升为法律诉讼。在本项工作中，我们旨在揭示数据主人对AI抓取和训练的数据使用的同意信息，并研究这些信息如何在 DataComp 这一流行的包含128亿对文本-图像的数据集中表达。我们检查了样本级别信息，包括版权通知、水印和元数据，以及网站级别信息，如网站的服务条款 (ToS) 和robots排除协议。我们估计至少有1.22亿样本在CommonPool中表现出某种版权通知的迹象，并发现排名前50的网站中，60%的样本来自禁止抓取的服务条款网站。此外，我们估计95%置信区间内，9-13%的CommonPool样本包含水印，而现有的水印检测方法未能高保真地捕捉到这些水印。我们的综合方法和发现表明，数据主人通过多种渠道传达数据使用同意，而当前的AI数据采集管道并未完全尊重这些同意。这些发现凸显了当前数据集编目/发布实践的局限性，并强调了需要考虑AI用途的统一数据同意框架的必要性。 

---
# Detecting Suicidal Ideation in Text with Interpretable Deep Learning: A CNN-BiGRU with Attention Mechanism 

**Title (ZH)**: 基于可解释深度学习的文本自杀意念检测：带有注意力机制的CNN-BiGRU 

**Authors**: Mohaiminul Islam Bhuiyan, Nur Shazwani Kamarudin, Nur Hafieza Ismail  

**Link**: [PDF](https://arxiv.org/pdf/2511.08636)  

**Abstract**: Worldwide, suicide is the second leading cause of death for adolescents with past suicide attempts to be an important predictor for increased future suicides. While some people with suicidal thoughts may try to suppress them, many signal their intentions in social media platforms. To address these issues, we propose a new type of hybrid deep learning scheme, i.e., the combination of a CNN architecture and a BiGRU technique, which can accurately identify the patterns of suicidal ideation from SN datasets. Also, we apply Explainable AI methods using SHapley Additive exPlanations to interpret the prediction results and verifying the model reliability. This integration of CNN local feature extraction, BiGRU bidirectional sequence modeling, attention mechanisms, and SHAP interpretability provides a comprehensive framework for suicide detection. Training and evaluation of the system were performed on a publicly available dataset. Several performance metrics were used for evaluating model performance. Our method was found to have achieved 93.97 accuracy in experimental results. Comparative study to different state-of-the-art Machine Learning and DL models and existing literature demonstrates the superiority of our proposed technique over all the competing methods. 

**Abstract (ZH)**: 全球范围内，自杀是青少年死亡的第二大致死原因， past suicide attempts 是未来自杀风险增加的重要预测指标。尽管一些存在自杀念头的人可能试图抑制这些念头，但许多人在社交媒体平台上会信号其意图。为应对这些问题，我们提出了一种新的混合深度学习方案，即 CNN 架构与 BiGRU 技术的结合，可以从 SN 数据集准确识别自杀念头的模式。同时，我们采用了解释性 AI 方法（SHapley Additive exPlanations）来解释预测结果并验证模型可靠性。这一方案综合了 CNN 局部特征提取、BiGRU 双向序列建模、注意力机制和 SHAP 可解释性，提供了全面的自杀检测框架。系统在公开可用的数据集上进行了训练和评估，并使用多种性能指标评估了模型性能。实验结果显示，我们的方法达到了 93.97% 的准确率。与现有的最佳机器学习和深度学习模型及文献进行对比研究，证明了我们提出的技术在所有竞争方法中更优越。 

---
# CADIC: Continual Anomaly Detection Based on Incremental Coreset 

**Title (ZH)**: CADIC：基于增量核心集的持续异常检测 

**Authors**: Gen Yang, Zhipeng Deng, Junfeng Man  

**Link**: [PDF](https://arxiv.org/pdf/2511.08634)  

**Abstract**: The primary objective of Continual Anomaly Detection (CAD) is to learn the normal patterns of new tasks under dynamic data distribution assumptions while mitigating catastrophic forgetting. Existing embedding-based CAD approaches continuously update a memory bank with new embeddings to adapt to sequential tasks. However, these methods require constructing class-specific sub-memory banks for each task, which restricts their flexibility and scalability. To address this limitation, we propose a novel CAD framework where all tasks share a unified memory bank. During training, the method incrementally updates embeddings within a fixed-size coreset, enabling continuous knowledge acquisition from sequential tasks without task-specific memory fragmentation. In the inference phase, anomaly scores are computed via a nearest-neighbor matching mechanism, achieving state-of-the-art detection accuracy. We validate the method through comprehensive experiments on MVTec AD and Visa datasets. Results show that our approach outperforms existing baselines, achieving average image-level AUROC scores of 0.972 (MVTec AD) and 0.891 (Visa). Notably, on a real-world electronic paper dataset, it demonstrates 100% accuracy in anomaly sample detection, confirming its robustness in practical scenarios. The implementation will be open-sourced on GitHub. 

**Abstract (ZH)**: 持续异常检测（CAD）的主要目标是在动态数据分布假设下学习新任务的正常模式，同时减轻灾难性遗忘。现有的基于嵌入的CAD方法通过不断更新内存库以适应序列任务。然而，这些方法需要为每个任务构建特定类别的子内存库，这限制了它们的灵活性和扩展性。为了解决这一局限性，我们提出了一种新颖的CAD框架，其中所有任务共享一个统一的内存库。在训练过程中，该方法逐步更新固定大小的核心集中的嵌入，能够在不特定任务内存碎片化的情况下持续获取知识。在推理阶段，异常得分通过最近邻匹配机制计算，实现了最先进的检测精度。我们通过在MVTec AD和Visa数据集上的全面实验验证了该方法。结果显示，我们的方法优于现有基线，平均图像级AUROC得分为0.972（MVTec AD）和0.891（Visa）。值得注意的是，在一个实际的电子纸数据集上，它实现了100%的异常样本检测准确性，证实了其在实际场景中的鲁棒性。该实施将在GitHub上公开发布。 

---
# Hope, Aspirations, and the Impact of LLMs on Female Programming Learners in Afghanistan 

**Title (ZH)**: 希望、抱负与大语言模型对阿富汗女性编程学习者的影响 

**Authors**: Hamayoon Behmanush, Freshta Akhtari, Roghieh Nooripour, Ingmar Weber, Vikram Kamath Cannanure  

**Link**: [PDF](https://arxiv.org/pdf/2511.08630)  

**Abstract**: Designing impactful educational technologies in contexts of socio-political instability requires a nuanced understanding of educational aspirations. Currently, scalable metrics for measuring aspirations are limited. This study adapts, translates, and evaluates Snyder's Hope Scale as a metric for measuring aspirations among 136 women learning programming online during a period of systemic educational restrictions in Afghanistan. The adapted scale demonstrated good reliability (Cronbach's {\alpha} = 0.78) and participants rated it as understandable and relevant. While overall aspiration-related scores did not differ significantly by access to Large Language Models (LLMs), those with access reported marginally higher scores on the Avenues subscale (p = .056), suggesting broader perceived pathways to achieving educational aspirations. These findings support the use of the adapted scale as a metric for aspirations in contexts of socio-political instability. More broadly, the adapted scale can be used to evaluate the impact of aspiration-driven design of educational technologies. 

**Abstract (ZH)**: 在社会政治不稳定背景下设计影响深远的教育技术需要对教育抱负有细致的理解。本研究适应、翻译并评估Snyder的希望量表，作为衡量阿富汗系统性教育限制期间136名在线学习编程女性抱负的指标。适应后的量表显示良好的信度（Cronbach’s α = 0.78），参与者认为其易于理解且相关。虽然总体抱负相关得分在大型语言模型（LLMs）访问权限方面未见显著差异，但有访问权限的参与者在路径子量表上的得分略高（p = .056），表明更广泛的实现教育抱负的感知途径。这些发现支持在社会政治不稳定背景下使用适应后的量表作为测量抱负的指标。更广泛地说，适应后的量表可用于评估以抱负为导向的教育技术设计的影响。 

---
# Learning Topology-Driven Multi-Subspace Fusion for Grassmannian Deep Network 

**Title (ZH)**: 基于流形驱动的多子空间融合的格拉斯曼深度网络学习 

**Authors**: Xuan Yu, Tianyang Xu  

**Link**: [PDF](https://arxiv.org/pdf/2511.08628)  

**Abstract**: Grassmannian manifold offers a powerful carrier for geometric representation learning by modelling high-dimensional data as low-dimensional subspaces. However, existing approaches predominantly rely on static single-subspace representations, neglecting the dynamic interplay between multiple subspaces critical for capturing complex geometric structures. To address this limitation, we propose a topology-driven multi-subspace fusion framework that enables adaptive subspace collaboration on the Grassmannian. Our solution introduces two key innovations: (1) Inspired by the Kolmogorov-Arnold representation theorem, an adaptive multi-subspace modelling mechanism is proposed that dynamically selects and weights task-relevant subspaces via topological convergence analysis, and (2) a multi-subspace interaction block that fuses heterogeneous geometric representations through Fréchet mean optimisation on the manifold. Theoretically, we establish the convergence guarantees of adaptive subspaces under a projection metric topology, ensuring stable gradient-based optimisation. Practically, we integrate Riemannian batch normalisation and mutual information regularisation to enhance discriminability and robustness. Extensive experiments on 3D action recognition (HDM05, FPHA), EEG classification (MAMEM-SSVEPII), and graph tasks demonstrate state-of-the-art performance. Our work not only advances geometric deep learning but also successfully adapts the proven multi-channel interaction philosophy of Euclidean networks to non-Euclidean domains, achieving superior discriminability and interpretability. 

**Abstract (ZH)**: Grassmannian流形提供了一种强大的几何表示学习载体，通过将高维数据建模为低维子空间。然而，现有方法主要依赖于静态单一子空间表示，忽略了捕捉复杂几何结构时多个子空间之间的动态交互。为解决这一限制，我们提出了一种基于拓扑的多子空间融合框架，能够在Grassmannian上实现自适应子空间协作。我们的解决方案引入了两项关键创新：（1）受柯尔莫哥洛夫-阿诺尔德表示定理启发，提出了一种自适应的多子空间建模机制，通过拓扑收敛分析动态选择和加权任务相关子空间；（2）通过流形上的Fréchet均值优化实现异构几何表示的融合模块。理论上，我们在投影度量拓扑下建立了自适应子空间的收敛保证，确保稳定的梯度优化。实践中，我们结合黎曼批量归一化和互信息正则化以增强可分性和鲁棒性。在3D动作识别（HDM05, FPHA）、EEG分类（MAMEM-SSVEPII）和图任务上进行的广泛实验显示了最先进的性能。我们的工作不仅推动了几何深度学习的发展，还成功地将欧几里得网络的多通道交互理念应用于非欧几里得领域，实现了更好的可分性和可解释性。 

---
# SAMora: Enhancing SAM through Hierarchical Self-Supervised Pre-Training for Medical Images 

**Title (ZH)**: SAMora：通过分层自我监督预训练增强SAM用于医学图像处理 

**Authors**: Shuhang Chen, Hangjie Yuan, Pengwei Liu, Hanxue Gu, Tao Feng, Dong Ni  

**Link**: [PDF](https://arxiv.org/pdf/2511.08626)  

**Abstract**: The Segment Anything Model (SAM) has demonstrated significant potential in medical image segmentation. Yet, its performance is limited when only a small amount of labeled data is available, while there is abundant valuable yet often overlooked hierarchical information in medical data. To address this limitation, we draw inspiration from self-supervised learning and propose SAMora, an innovative framework that captures hierarchical medical knowledge by applying complementary self-supervised learning objectives at the image, patch, and pixel levels. To fully exploit the complementarity of hierarchical knowledge within LoRAs, we introduce HL-Attn, a hierarchical fusion module that integrates multi-scale features while maintaining their distinct characteristics. SAMora is compatible with various SAM variants, including SAM2, SAMed, and H-SAM. Experimental results on the Synapse, LA, and PROMISE12 datasets demonstrate that SAMora outperforms existing SAM variants. It achieves state-of-the-art performance in both few-shot and fully supervised settings while reducing fine-tuning epochs by 90%. The code is available at this https URL. 

**Abstract (ZH)**: SAMora：基于层次自监督学习的医学图像分割模型 

---
# Cross-Field Interface-Aware Neural Operators for Multiphase Flow Simulation 

**Title (ZH)**: 考虑交叉场接口的神经算子方法在多相流模拟中的应用 

**Authors**: ZhenZhong Wang, Xin Zhang, Jun Liao, Min Jiang  

**Link**: [PDF](https://arxiv.org/pdf/2511.08625)  

**Abstract**: Multiphase flow systems, with their complex dynamics, field discontinuities, and interphase interactions, pose significant computational challenges for traditional numerical solvers. While neural operators offer efficient alternatives, they often struggle to achieve high-resolution numerical accuracy in these systems. This limitation primarily stems from the inherent spatial heterogeneity and the scarcity of high-quality training data in multiphase flows. In this work, we propose the Interface Information-Aware Neural Operator (IANO), a novel framework that explicitly leverages interface information as a physical prior to enhance the prediction accuracy. The IANO architecture introduces two key components: 1) An interface-aware multiple function encoding mechanism jointly models multiple physical fields and interfaces, thus capturing the high-frequency physical features at the interface. 2) A geometry-aware positional encoding mechanism further establishes the relationship between interface information, physical variables, and spatial positions, enabling it to achieve pointwise super-resolution prediction even in the low-data regimes. Experimental results demonstrate that IANO outperforms baselines by $\sim$10\% in accuracy for multiphase flow simulations while maintaining robustness under data-scarce and noise-perturbed conditions. 

**Abstract (ZH)**: 具有界面信息感知的神经算子（IANO）：一种增强相变流动模拟预测准确性的新型框架 

---
# Multi-period Learning for Financial Time Series Forecasting 

**Title (ZH)**: 多期学习在金融时间序列预测中的应用 

**Authors**: Xu Zhang, Zhengang Huang, Yunzhi Wu, Xun Lu, Erpeng Qi, Yunkai Chen, Zhongya Xue, Qitong Wang, Peng Wang, Wei Wang  

**Link**: [PDF](https://arxiv.org/pdf/2511.08622)  

**Abstract**: Time series forecasting is important in finance domain. Financial time series (TS) patterns are influenced by both short-term public opinions and medium-/long-term policy and market trends. Hence, processing multi-period inputs becomes crucial for accurate financial time series forecasting (TSF). However, current TSF models either use only single-period input, or lack customized designs for addressing multi-period characteristics. In this paper, we propose a Multi-period Learning Framework (MLF) to enhance financial TSF performance. MLF considers both TSF's accuracy and efficiency requirements. Specifically, we design three new modules to better integrate the multi-period inputs for improving accuracy: (i) Inter-period Redundancy Filtering (IRF), that removes the information redundancy between periods for accurate self-attention modeling, (ii) Learnable Weighted-average Integration (LWI), that effectively integrates multi-period forecasts, (iii) Multi-period self-Adaptive Patching (MAP), that mitigates the bias towards certain periods by setting the same number of patches across all periods. Furthermore, we propose a Patch Squeeze module to reduce the number of patches in self-attention modeling for maximized efficiency. MLF incorporates multiple inputs with varying lengths (periods) to achieve better accuracy and reduces the costs of selecting input lengths during training. The codes and datasets are available at this https URL. 

**Abstract (ZH)**: 多时期学习框架在金融时间序列预测中的应用 

---
# Reasoning on Time-Series for Financial Technical Analysis 

**Title (ZH)**: 基于时间序列的金融技术分析推理 

**Authors**: Kelvin J.L. Koa, Jan Chen, Yunshan Ma, Huanhuan Zheng, Tat-Seng Chua  

**Link**: [PDF](https://arxiv.org/pdf/2511.08616)  

**Abstract**: While Large Language Models have been used to produce interpretable stock forecasts, they mainly focus on analyzing textual reports but not historical price data, also known as Technical Analysis. This task is challenging as it switches between domains: the stock price inputs and outputs lie in the time-series domain, while the reasoning step should be in natural language. In this work, we introduce Verbal Technical Analysis (VTA), a novel framework that combine verbal and latent reasoning to produce stock time-series forecasts that are both accurate and interpretable. To reason over time-series, we convert stock price data into textual annotations and optimize the reasoning trace using an inverse Mean Squared Error (MSE) reward objective. To produce time-series outputs from textual reasoning, we condition the outputs of a time-series backbone model on the reasoning-based attributes. Experiments on stock datasets across U.S., Chinese, and European markets show that VTA achieves state-of-the-art forecasting accuracy, while the reasoning traces also perform well on evaluation by industry experts. 

**Abstract (ZH)**: VERBAL TECHNICAL ANALYSIS: A NOVEL FRAMEWORK FOR INTERPRETABLE STOCK TIME-SERIES FORECASTING 

---
# Data-driven Feynman-Kac Discovery with Applications to Prediction and Data Generation 

**Title (ZH)**: 基于数据驱动的费曼-卡克发现及其在预测和数据生成中的应用 

**Authors**: Qi Feng, Guang Lin, Purav Matlia, Denny Serdarevic  

**Link**: [PDF](https://arxiv.org/pdf/2511.08606)  

**Abstract**: In this paper, we propose a novel data-driven framework for discovering probabilistic laws underlying the Feynman-Kac formula. Specifically, we introduce the first stochastic SINDy method formulated under the risk-neutral probability measure to recover the backward stochastic differential equation (BSDE) from a single pair of stock and option trajectories. Unlike existing approaches to identifying stochastic differential equations-which typically require ergodicity-our framework leverages the risk-neutral measure, thereby eliminating the ergodicity assumption and enabling BSDE recovery from limited financial time series data. Using this algorithm, we are able not only to make forward-looking predictions but also to generate new synthetic data paths consistent with the underlying probabilistic law. 

**Abstract (ZH)**: 基于费曼-卡克公式的概率定律发现的新型数据驱动框架 

---
# Where did you get that? Towards Summarization Attribution for Analysts 

**Title (ZH)**: 从哪里获得这些信息？面向分析师的总结归因 

**Authors**: Violet B, John M. Conroy, Sean Lynch, Danielle M, Neil P. Molino, Aaron Wiechmann, Julia S. Yang  

**Link**: [PDF](https://arxiv.org/pdf/2511.08589)  

**Abstract**: Analysts require attribution, as nothing can be reported without knowing the source of the information. In this paper, we will focus on automatic methods for attribution, linking each sentence in the summary to a portion of the source text, which may be in one or more documents. We explore using a hybrid summarization, i.e., an automatic paraphrase of an extractive summary, to ease attribution. We also use a custom topology to identify the proportion of different categories of attribution-related errors. 

**Abstract (ZH)**: 分析师需要归因，因为没有信息来源就无法报告任何内容。在本文中，我们将重点探讨自动归因方法，即将摘要中的每一句与来源文本的一部分关联起来，该来源文本可能存在于一个或多个文档中。我们探索使用混合摘要，即对抽提摘要的自动改写，以简化归因过程。我们还使用自定义拓扑结构来识别不同类别的归因错误的比例。 

---
# CometNet: Contextual Motif-guided Long-term Time Series Forecasting 

**Title (ZH)**: CometNet：基于上下文模式的长-term时间序列预测 

**Authors**: Weixu Wang, Xiaobo Zhou, Xin Qiao, Lei Wang, Tie Qiu  

**Link**: [PDF](https://arxiv.org/pdf/2511.08049)  

**Abstract**: Long-term Time Series Forecasting is crucial across numerous critical domains, yet its accuracy remains fundamentally constrained by the receptive field bottleneck in existing models. Mainstream Transformer- and Multi-layer Perceptron (MLP)-based methods mainly rely on finite look-back windows, limiting their ability to model long-term dependencies and hurting forecasting performance. Naively extending the look-back window proves ineffective, as it not only introduces prohibitive computational complexity, but also drowns vital long-term dependencies in historical noise. To address these challenges, we propose CometNet, a novel Contextual Motif-guided Long-term Time Series Forecasting framework. CometNet first introduces a Contextual Motif Extraction module that identifies recurrent, dominant contextual motifs from complex historical sequences, providing extensive temporal dependencies far exceeding limited look-back windows; Subsequently, a Motif-guided Forecasting module is proposed, which integrates the extracted dominant motifs into forecasting. By dynamically mapping the look-back window to its relevant motifs, CometNet effectively harnesses their contextual information to strengthen long-term forecasting capability. Extensive experimental results on eight real-world datasets have demonstrated that CometNet significantly outperforms current state-of-the-art (SOTA) methods, particularly on extended forecast horizons. 

**Abstract (ZH)**: 长周期时间序列预测在众多关键领域中至关重要，但其准确性受限于现有模型中的感受野瓶颈。主流基于Transformer和多层感知机（MLP）的方法主要依赖于有限的历史窗口，这限制了它们建模长期依赖性的能力，从而损害了预测性能。简单地延长历史窗口效果不佳，因为它不仅引入了巨大的计算复杂性，还淹没了历史噪声中的关键长期依赖性。为了解决这些挑战，我们提出了CometNet，一种新颖的基于上下文模态的长周期时间序列预测框架。CometNet 首先引入了一个上下文模态提取模块，该模块可以从复杂的歷史序列中识别出反复出现的主导上下文模态，提供了远超过有限历史窗口的广泛时间依赖性；随后，提出了一种基于模态的预测模块，该模块将提取的主导模态整合到预测中。通过动态将历史窗口映射到相关的模态，CometNet 有效利用了它们的上下文信息，增强了长期预测能力。在八个真实世界数据集上的广泛实验结果表明，CometNet 显著优于当前最先进的（SOTA）方法，特别是在延长的预测时间范围内。 

---
