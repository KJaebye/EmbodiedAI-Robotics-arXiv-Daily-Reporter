{'arxiv_id': 'arXiv:2511.09549', 'title': 'Breadth-First Search vs. Restarting Random Walks for Escaping Uninformed Heuristic Regions', 'authors': 'Daniel Platnick, Dawson Tomasz, Eamon Earl, Sourena Khanzadeh, Richard Valenzano', 'link': 'https://arxiv.org/abs/2511.09549', 'abstract': 'Greedy search methods like Greedy Best-First Search (GBFS) and Enforced Hill-Climbing (EHC) often struggle when faced with Uninformed Heuristic Regions (UHRs) like heuristic local minima or plateaus. In this work, we theoretically and empirically compare two popular methods for escaping UHRs in breadth-first search (BrFS) and restarting random walks (RRWs). We first derive the expected runtime of escaping a UHR using BrFS and RRWs, based on properties of the UHR and the random walk procedure, and then use these results to identify when RRWs will be faster in expectation than BrFS. We then evaluate these methods for escaping UHRs by comparing standard EHC, which uses BrFS to escape UHRs, to variants of EHC called EHC-RRW, which use RRWs for that purpose. EHC-RRW is shown to have strong expected runtime guarantees in cases where EHC has previously been shown to be effective. We also run experiments with these approaches on PDDL planning benchmarks to better understand their relative effectiveness for escaping UHRs.', 'abstract_zh': '贪婪搜索方法如贪婪最佳优先搜索（GBFS）和强制爬坡搜索（EHC）在面对无信息启发式区域（UHRs）如启发式局部最小值或平台时常常表现出色受限。在本文中，我们从理论上和实验上比较了两种在广度优先搜索（BrFS）和重启随机游走（RRWs）中逃脱UHRs的方法。我们首先根据UHR的性质和随机游走过程的特性推导出使用BrFS和RRWs逃脱UHRs的期望运行时间，然后利用这些结果来识别在期望意义上RRWs比BrFS更快的情况。接着，我们通过将标准EHC与用于该目的的RRWs变体EHC-RRW进行比较来评估这些方法在逃脱UHRs方面的有效性。EHC-RRW在EHC之前已被证明有效的情况下展示了强的期望运行时间保证。我们还对此类方法进行了实验，研究它们在PDDL规划基准测试中的相对有效性，以更好地了解它们在逃脱UHRs方面的效果。', 'title_zh': '广度优先搜索与重启随机游走逃离不知情启发式区域比较'}
{'arxiv_id': 'arXiv:2511.09535', 'title': 'Robust and Diverse Multi-Agent Learning via Rational Policy Gradient', 'authors': 'Niklas Lauffer, Ameesh Shah, Micah Carroll, Sanjit A. Seshia, Stuart Russell, Michael Dennis', 'link': 'https://arxiv.org/abs/2511.09535', 'abstract': "Adversarial optimization algorithms that explicitly search for flaws in agents' policies have been successfully applied to finding robust and diverse policies in multi-agent settings. However, the success of adversarial optimization has been largely limited to zero-sum settings because its naive application in cooperative settings leads to a critical failure mode: agents are irrationally incentivized to self-sabotage, blocking the completion of tasks and halting further learning. To address this, we introduce Rationality-preserving Policy Optimization (RPO), a formalism for adversarial optimization that avoids self-sabotage by ensuring agents remain rational--that is, their policies are optimal with respect to some possible partner policy. To solve RPO, we develop Rational Policy Gradient (RPG), which trains agents to maximize their own reward in a modified version of the original game in which we use opponent shaping techniques to optimize the adversarial objective. RPG enables us to extend a variety of existing adversarial optimization algorithms that, no longer subject to the limitations of self-sabotage, can find adversarial examples, improve robustness and adaptability, and learn diverse policies. We empirically validate that our approach achieves strong performance in several popular cooperative and general-sum environments. Our project page can be found at this https URL.", 'abstract_zh': '对抗优化算法通过明确搜索代理政策中的缺陷，在多代理环境中已被成功用于发现 robust 和多样的政策。然而，对抗优化的成功主要局限于零和环境，因为在合作环境中其简单应用会导致一个关键的失败模式：代理被不理性地激励进行自我破坏，阻碍任务的完成并终止进一步的学习。为解决这一问题，我们引入了一种称为理性保留策略优化（RPO）的对抗优化形式主义，通过确保代理保持理性——即，他们的政策相对于某些可能的合作伙伴政策是优化的——来避免自我破坏。为了解决RPO，我们开发了理性策略梯度（RPG），这是一种训练代理在修改后的原游戏中最大化自身奖励的方法，其中我们使用对手塑造技术来优化对抗目标。RPG 使我们能够扩展多种现有的对抗优化算法，这些算法不再受自我破坏的限制，可以找到对抗示例，提高 robustness 和适应性，并学习多样的政策。我们实验证明，我们的方法在多种流行的协同和非零和环境中表现出色。我们的项目页面可以在以下链接访问：this https URL。', 'title_zh': '基于理性策略梯度的鲁棒且多样的多智能体学习'}
{'arxiv_id': 'arXiv:2511.09497', 'title': 'Fundamentals of Physical AI', 'authors': 'Vahid Salehi', 'link': 'https://arxiv.org/abs/2511.09497', 'abstract': 'This work will elaborate the fundamental principles of physical artificial intelligence (Physical AI) from a scientific and systemic perspective. The aim is to create a theoretical foundation that describes the physical embodiment, sensory perception, ability to act, learning processes, and context sensitivity of intelligent systems within a coherent framework. While classical AI approaches rely on symbolic processing and data driven models, Physical AI understands intelligence as an emergent phenomenon of real interaction between body, environment, and experience. The six fundamentals presented here are embodiment, sensory perception, motor action, learning, autonomy, and context sensitivity, and form the conceptual basis for designing and evaluating physically intelligent systems. Theoretically, it is shown that these six principles do not represent loose functional modules but rather act as a closed control loop in which energy, information, control, and context are in constant interaction. This circular interaction enables a system to generate meaning not from databases, but from physical experience, a paradigm shift that understands intelligence as an physical embodied process. Physical AI understands learning not as parameter adjustment, but as a change in the structural coupling between agents and the environment. To illustrate this, the theoretical model is explained using a practical scenario: An adaptive assistant robot supports patients in a rehabilitation clinic. This example illustrates that physical intelligence does not arise from abstract calculation, but from immediate, embodied experience. It shows how the six fundamentals interact in a real system: embodiment as a prerequisite, perception as input, movement as expression, learning as adaptation, autonomy as regulation, and context as orientation.', 'abstract_zh': '本研究将从科学和系统化的角度阐述物理人工智能（Physical AI）的基本原理，旨在构建一个理论基础，该基础能够描述智能系统在一致框架内的物理体现、感官感知、行动能力、学习过程和情境敏感性。虽然经典人工智能依赖于符号处理和数据驱动模型，物理人工智能则理解智能为身体、环境和体验之间真实互动中涌现的现象。本文提出的六大基本原理为实体性、感官感知、运动行动、学习、自主性和情境敏感性，它们构成了设计和评估物理智能系统概念基础。理论上，这六大原则并非松散的功能模块，而是一个闭环控制回路，在该回路中，能量、信息、控制和情境持续交互。这种闭环交互使系统能够从物理体验中生成意义，而非仅从数据库中获取。这代表了智能理解为具身物理过程的范式转变。物理人工智能将学习理解为代理与环境之间结构耦合的变化，而非参数调整。为了说明这一点，本文通过一个实际场景解释了理论模型：一个自适应辅助机器人在康复诊所支持患者。这个例子展示了物理智能不是源自抽象计算，而是源自即时的、具身的经验。它说明了六大基本原理在实际系统中如何交互：实体性作为先决条件，感知作为输入，运动作为表达，学习作为适应，自主性作为调节，情境作为定向。', 'title_zh': '物理驱动人工智能基础'}
{'arxiv_id': 'arXiv:2511.09493', 'title': 'Consensus Sampling for Safer Generative AI', 'authors': 'Adam Tauman Kalai, Yael Tauman Kalai, Or Zamir', 'link': 'https://arxiv.org/abs/2511.09493', 'abstract': "Many approaches to AI safety rely on inspecting model outputs or activations, yet certain risks are inherently undetectable by inspection alone. We propose a complementary, architecture-agnostic approach that enhances safety through the aggregation of multiple generative models, with the aggregated model inheriting its safety from the safest subset of a given size among them. Specifically, we present a consensus sampling algorithm that, given $k$ models and a prompt, achieves risk competitive with the average risk of the safest $s$ of the $k$ models, where $s$ is a chosen parameter, while abstaining when there is insufficient agreement between them. The approach leverages the models' ability to compute output probabilities, and we bound the probability of abstention when sufficiently many models are safe and exhibit adequate agreement. The algorithm is inspired by the provable copyright protection algorithm of Vyas et al. (2023). It requires some overlap among safe models, offers no protection when all models are unsafe, and may accumulate risk over repeated use. Nonetheless, our results provide a new, model-agnostic approach for AI safety by amplifying safety guarantees from an unknown subset of models within a collection to that of a single reliable model.", 'abstract_zh': '一种通过聚合多个生成模型增强AI安全性的新方法：基于最安全模型子集的共识采样算法', 'title_zh': '安全生成AI的共识采样方法'}
{'arxiv_id': 'arXiv:2511.09483', 'title': 'CrochetBench: Can Vision-Language Models Move from Describing to Doing in Crochet Domain?', 'authors': 'Peiyu Li, Xiaobao Huang, Nitesh V. Chawla', 'link': 'https://arxiv.org/abs/2511.09483', 'abstract': 'We present CrochetBench, a benchmark for evaluating the ability of multimodal large language models to perform fine-grained, low-level procedural reasoning in the domain of crochet. Unlike prior benchmarks that focus on high-level description or visual question answering, CrochetBench shifts the emphasis from describing to doing: models are required to recognize stitches, select structurally appropriate instructions, and generate compilable crochet procedures. We adopt the CrochetPARADE DSL as our intermediate representation, enabling structural validation and functional evaluation via execution. The benchmark covers tasks including stitch classification, instruction grounding, and both natural language and image-to-DSL translation. Across all tasks, performance sharply declines as the evaluation shifts from surface-level similarity to executable correctness, exposing limitations in long-range symbolic reasoning and 3D-aware procedural synthesis. CrochetBench offers a new lens for assessing procedural competence in multimodal models and highlights the gap between surface-level understanding and executable precision in real-world creative domains. Code is available at this https URL.', 'abstract_zh': '我们介绍了CrochetBench，这是一个评估多模态大语言模型在钩织领域进行细微级别的低级程序推理能力的基准测试。与以往主要关注高层次描述或视觉问答的基准不同，CrochetBench 强调从描述转向执行：模型需要识别针法、选择结构上合适的指令，并生成可编译的钩织程序。我们采用CrochetPARADE DSL作为中间表示，通过执行实现结构验证和功能评估。该基准涵盖针法分类、指令接地以及自然语言和图像到DSL的翻译任务。在所有任务中，当评估从表面相似性转向可执行正确性时，性能急剧下降，暴露了长程符号推理和三维感知程序合成的局限性。CrochetBench 提供了一个新的视角来评估多模态模型的程序能力，并凸显了表面理解与可执行精度之间在实际创意领域的差距。代码可在以下链接获取：this https URL。', 'title_zh': 'CrochetBench: 视觉-语言模型能否在钩织领域从描述转向执行？'}
{'arxiv_id': 'arXiv:2511.09433', 'title': "What We Don't C: Representations for scientific discovery beyond VAEs", 'authors': 'Brian Rogers, Micah Bowles, Chris J. Lintott, Steve Croft', 'link': 'https://arxiv.org/abs/2511.09433', 'abstract': "Accessing information in learned representations is critical for scientific discovery in high-dimensional domains. We introduce a novel method based on latent flow matching with classifier-free guidance that disentangles latent subspaces by explicitly separating information included in conditioning from information that remains in the residual representation. Across three experiments -- a synthetic 2D Gaussian toy problem, colored MNIST, and the Galaxy10 astronomy dataset -- we show that our method enables access to meaningful features of high dimensional data. Our results highlight a simple yet powerful mechanism for analyzing, controlling, and repurposing latent representations, providing a pathway toward using generative models for scientific exploration of what we don't capture, consider, or catalog.", 'abstract_zh': '基于潜在流匹配和无分类引导的方法在高维领域通过分解潜在子空间以分离条件信息和残差表示中的信息，实现高维数据有意义特征的访问', 'title_zh': "What We Don't C: 科学发现中超出VAEs的表示方法"}
{'arxiv_id': 'arXiv:2511.09378', 'title': 'The 2025 Planning Performance of Frontier Large Language Models', 'authors': 'Augusto B. Corrêa, André G. Pereira, Jendrik Seipp', 'link': 'https://arxiv.org/abs/2511.09378', 'abstract': 'The capacity of Large Language Models (LLMs) for reasoning remains an active area of research, with the capabilities of frontier models continually advancing. We provide an updated evaluation of the end-to-end planning performance of three frontier LLMs as of 2025, where models are prompted to generate a plan from PDDL domain and task descriptions. We evaluate DeepSeek R1, Gemini 2.5 Pro, GPT-5 and as reference the planner LAMA on a subset of domains from the most recent Learning Track of the International Planning Competition. Our results show that on standard PDDL domains, the performance of GPT-5 in terms of solved tasks is competitive with LAMA. When the PDDL domains and tasks are obfuscated to test for pure reasoning, the performance of all LLMs degrades, though less severely than previously reported for other models. These results show substantial improvements over prior generations of LLMs, reducing the performance gap to planners on a challenging benchmark.', 'abstract_zh': '大型语言模型在推理能力方面的容量仍然是一个活跃的研究领域，前沿模型的能力不断进步。我们提供了截至2025年的三个前沿大型语言模型从PDDL领域和任务描述生成端到端计划的最新评估。我们在国际规划竞赛最近一轮的学习轨道的部分领域上，将DeepSeek R1、Gemini 2.5 Pro、GPT-5与参考规划器LAMA进行评估。结果显示，对于标准PDDL领域，GPT-5在解决任务方面的性能与LAMA相当。当对PDDL领域和任务进行混淆以测试纯粹的推理能力时，所有LLM的性能下降，但比之前报道的其他模型下降较少。这些结果表明，与前几代大型语言模型相比，取得了显著的改进，减少了在挑战性基准上与规划器的性能差距。', 'title_zh': '2025年前沿大规模语言模型规划绩效'}
{'arxiv_id': 'arXiv:2511.09363', 'title': 'BarrierBench : Evaluating Large Language Models for Safety Verification in Dynamical Systems', 'authors': 'Ali Taheri, Alireza Taban, Sadegh Soudjani, Ashutosh Trivedi', 'link': 'https://arxiv.org/abs/2511.09363', 'abstract': 'Safety verification of dynamical systems via barrier certificates is essential for ensuring correctness in autonomous applications. Synthesizing these certificates involves discovering mathematical functions with current methods suffering from poor scalability, dependence on carefully designed templates, and exhaustive or incremental function-space searches. They also demand substantial manual expertise--selecting templates, solvers, and hyperparameters, and designing sampling strategies--requiring both theoretical and practical knowledge traditionally shared through linguistic reasoning rather than formalized methods.\nThis motivates a key question: can such expert reasoning be captured and operationalized by language models? We address this by introducing an LLM-based agentic framework for barrier certificate synthesis. The framework uses natural language reasoning to propose, refine, and validate candidate certificates, integrating LLM-driven template discovery with SMT-based verification, and supporting barrier-controller co-synthesis to ensure consistency between safety certificates and controllers.\nTo evaluate this capability, we introduce BarrierBench, a benchmark of 100 dynamical systems spanning linear, nonlinear, discrete-time, and continuous-time settings. Our experiments assess not only the effectiveness of LLM-guided barrier synthesis but also the utility of retrieval-augmented generation and agentic coordination strategies in improving its reliability and performance. Across these tasks, the framework achieves more than 90% success in generating valid certificates. By releasing BarrierBench and the accompanying toolchain, we aim to establish a community testbed for advancing the integration of language-based reasoning with formal verification in dynamical systems.\nThe benchmark is publicly available at this https URL', 'abstract_zh': '基于语言模型的动力学系统屏障证书合成对于自主应用的正确性验证是必不可少的。现有的合成方法存在可扩展性差、依赖精心设计的模板、以及需要对搜索空间进行穷举或增量搜索的问题。这些方法还要求大量的手动专业知识，包括选择模板、求解器和超参数，以及设计采样策略，这些知识通常是通过语言推理而非形式化方法来共享的。\n\n这促使一个关键问题的产生：是否可以由语言模型来捕捉和实现这种专家推理？我们通过引入基于大规模语言模型的自主框架来解决这个问题，该框架使用自然语言推理来提出、改进和验证候选的屏障证书，将LLM驱动的模板发现与基于SMT的验证相结合，并支持屏障控制器联合设计以确保安全证书和控制器的一致性。\n\n为了评估这一能力，我们引入了BarrierBench基准，其中包括100个动力学系统，涵盖线性、非线性、离散时间和连续时间设置。我们的实验不仅评估了由LLM引导的屏障合成的有效性，还评估了检索增强生成和自主协调策略如何提高其可靠性和性能。在这些任务中，框架在生成有效证书方面的成功率超过90%。通过发布BarrierBench和配套工具链，我们旨在建立一个社区测试平台，以推进基于语言推理与形式化验证的动态系统集成研究。\n\n基准可在以下链接获取：this https URL', 'title_zh': 'BarrierBench : 评估大型语言模型在动力系统安全性验证中的表现'}
{'arxiv_id': 'arXiv:2511.09325', 'title': 'Not Everything That Counts Can Be Counted: A Case for Safe Qualitative AI', 'authors': 'Stine Beltoft, Lukas Galke', 'link': 'https://arxiv.org/abs/2511.09325', 'abstract': "Artificial intelligence (AI) and large language models (LLM) are reshaping science, with most recent advances culminating in fully-automated scientific discovery pipelines. But qualitative research has been left behind. Researchers in qualitative methods are hesitant about AI adoption. Yet when they are willing to use AI at all, they have little choice but to rely on general-purpose tools like ChatGPT to assist with interview interpretation, data annotation, and topic modeling - while simultaneously acknowledging these system's well-known limitations of being biased, opaque, irreproducible, and privacy-compromising. This creates a critical gap: while AI has substantially advanced quantitative methods, the qualitative dimensions essential for meaning-making and comprehensive scientific understanding remain poorly integrated. We argue for developing dedicated qualitative AI systems built from the ground up for interpretive research. Such systems must be transparent, reproducible, and privacy-friendly. We review recent literature to show how existing automated discovery pipelines could be enhanced by robust qualitative capabilities, and identify key opportunities where safe qualitative AI could advance multidisciplinary and mixed-methods research.", 'abstract_zh': '人工智能（AI）和大型语言模型（LLM）正在重塑科学，最近的进展 culminating 在完全自动化的科学发现流程中，但定性研究却被忽略了。使用定性方法的研究人员对AI的采用持犹豫态度。然而，当他们愿意使用AI时，他们几乎没有选择，只能依赖像ChatGPT这样的通用工具来协助访谈解释、数据标注和主题建模——同时承认这些系统的已知限制，如偏见、不透明、不可再现和侵犯隐私。这造成了一个关键缺口：虽然AI在量化方法方面取得了显著进展，但进行意义建构和全面科学理解所必需的定性维度仍未得到充分整合。我们主张开发从头构建的专门用于诠释研究的定性AI系统。此类系统必须透明、可再现且保护隐私。我们回顾近期文献，以展示现有的自动化发现流程如何通过增强的定性能力得到增强，并确定安全的定性AI如何促进跨学科和混合方法研究的关键机会。', 'title_zh': '计不可尽，质不可量：一种关于安全定性AI的论点'}
{'arxiv_id': 'arXiv:2511.09287', 'title': 'From Model Training to Model Raising - A call to reform AI model training paradigms from post-hoc alignment to intrinsic, identity-based development', 'authors': 'Roland Aydin, Christian Cyron, Steve Bachelor, Ashton Anderson, Robert West', 'link': 'https://arxiv.org/abs/2511.09287', 'abstract': 'Current AI training methods align models with human values only after their core capabilities have been established, resulting in models that are easily misaligned and lack deep-rooted value systems. We propose a paradigm shift from "model training" to "model raising", in which alignment is woven into a model\'s development from the start. We identify several key components for this paradigm, all centered around redesigning the training corpus: reframing training data from a first-person perspective, recontextualizing information as lived experience, simulating social interactions, and scaffolding the ordering of training data. We expect that this redesign of the training corpus will lead to an early commitment to values from the first training token onward, such that knowledge, skills, and values are intrinsically much harder to separate. In an ecosystem in which large language model capabilities start overtaking human capabilities in many tasks, this seems to us like a critical need.', 'abstract_zh': '当前的AI训练方法在模型核心能力建立之后才使其与人类价值观相契合，导致模型容易出现偏差且缺乏深刻的价值体系。我们提出从“模型训练”转向“模型培养”的范式转变，在模型开发的初期就将其与人类价值观相融合。我们确定了这一范式的一些关键组成部分，所有这些都围绕着重新设计训练语料库：从第一人称视角重新构框架训练数据，重新构架信息作为生活体验，模拟社会互动，并搭建训练数据的层次结构。我们预计这种训练语料库的重新设计将使从第一个训练令牌开始就对价值观做出早期承诺，从而使知识、技能和价值观更加难以分离。在大语言模型能力逐渐超过人类能力的生态系统中，这似乎是一个至关重要的需求。', 'title_zh': '从模型训练到模型培育：呼吁从事后对齐转向内在的、基于身份的发展模式'}
{'arxiv_id': 'arXiv:2511.09275', 'title': 'HyperD: Hybrid Periodicity Decoupling Framework for Traffic Forecasting', 'authors': 'Minlan Shao, Zijian Zhang, Yili Wang, Yiwei Dai, Xu Shen, Xin Wang', 'link': 'https://arxiv.org/abs/2511.09275', 'abstract': 'Accurate traffic forecasting plays a vital role in intelligent transportation systems, enabling applications such as congestion control, route planning, and urban mobility this http URL, traffic forecasting remains challenging due to two key factors: (1) complex spatial dependencies arising from dynamic interactions between road segments and traffic sensors across the network, and (2) the coexistence of multi-scale periodic patterns (e.g., daily and weekly periodic patterns driven by human routines) with irregular fluctuations caused by unpredictable events (e.g., accidents, weather, or construction). To tackle these challenges, we propose HyperD (Hybrid Periodic Decoupling), a novel framework that decouples traffic data into periodic and residual components. The periodic component is handled by the Hybrid Periodic Representation Module, which extracts fine-grained daily and weekly patterns using learnable periodic embeddings and spatial-temporal attention. The residual component, which captures non-periodic, high-frequency fluctuations, is modeled by the Frequency-Aware Residual Representation Module, leveraging complex-valued MLP in frequency domain. To enforce semantic separation between the two components, we further introduce a Dual-View Alignment Loss, which aligns low-frequency information with the periodic branch and high-frequency information with the residual branch. Extensive experiments on four real-world traffic datasets demonstrate that HyperD achieves state-of-the-art prediction accuracy, while offering superior robustness under disturbances and improved computational efficiency compared to existing methods.', 'abstract_zh': '基于混合周期解耦的交通流量准确预测方法', 'title_zh': 'HyperD: 结合周期性解耦框架用于交通预测'}
{'arxiv_id': 'arXiv:2511.09247', 'title': 'MedFuse: Multiplicative Embedding Fusion For Irregular Clinical Time Series', 'authors': 'Yi-Hsien Hsieh, Ta-Jung Chien, Chun-Kai Huang, Shao-Hua Sun, Che Lin', 'link': 'https://arxiv.org/abs/2511.09247', 'abstract': 'Clinical time series derived from electronic health records (EHRs) are inherently irregular, with asynchronous sampling, missing values, and heterogeneous feature dynamics. While numerical laboratory measurements are highly informative, existing embedding strategies usually combine feature identity and value embeddings through additive operations, which constrains their ability to capture value-dependent feature interactions. We propose MedFuse, a framework for irregular clinical time series centered on the MuFuse (Multiplicative Embedding Fusion) module. MuFuse fuses value and feature embeddings through multiplicative modulation, preserving feature-specific information while modeling higher-order dependencies across features. Experiments on three real-world datasets covering both intensive and chronic care show that MedFuse consistently outperforms state-of-the-art baselines on key predictive tasks. Analysis of the learned representations further demonstrates that multiplicative fusion enhances expressiveness and supports cross-dataset pretraining. These results establish MedFuse as a generalizable approach for modeling irregular clinical time series.', 'abstract_zh': '来自电子健康记录的临床时间序列本质上是不规则的，具有异步采样、缺失值和异质特征动态。虽然数值实验室测量数据高度信息丰富，现有嵌入策略通常通过加法操作结合特征标识和值嵌入，限制了其捕捉值依赖特征相互作用的能力。我们提出MedFuse框架，该框架以MuFuse（乘法嵌入融合）模块为中心，通过乘法调制融合值和特征嵌入，保留特征特定信息并建模跨特征的高阶依赖关系。实验结果表明，MedFuse在三个涵盖急性与慢性护理的真实世界数据集上一致地优于最先进的基线方法。进一步的研究表明，乘法融合增强了表达能力并支持跨数据集预训练。这些结果确立了MedFuse作为一种可泛化的不规则临床时间序列建模方法的地位。', 'title_zh': 'MedFuse: 不规则临床时间序列的乘性嵌入融合'}
{'arxiv_id': 'arXiv:2511.09178', 'title': 'Perspectives on a Reliability Monitoring Framework for Agentic AI Systems', 'authors': 'Niclas Flehmig, Mary Ann Lundteigen, Shen Yin', 'link': 'https://arxiv.org/abs/2511.09178', 'abstract': 'The implementation of agentic AI systems has the potential of providing more helpful AI systems in a variety of applications. These systems work autonomously towards a defined goal with reduced external control. Despite their potential, one of their flaws is the insufficient reliability which makes them especially unsuitable for high-risk domains such as healthcare or process industry. Unreliable systems pose a risk in terms of unexpected behavior during operation and mitigation techniques are needed. In this work, we derive the main reliability challenges of agentic AI systems during operation based on their characteristics. We draw the connection to traditional AI systems and formulate a fundamental reliability challenge during operation which is inherent to traditional and agentic AI systems. As our main contribution, we propose a two-layered reliability monitoring framework for agentic AI systems which consists of a out-of-distribution detection layer for novel inputs and AI transparency layer to reveal internal operations. This two-layered monitoring approach gives a human operator the decision support which is needed to decide whether an output is potential unreliable or not and intervene. This framework provides a foundation for developing mitigation techniques to reduce risk stemming from uncertain reliability during operation.', 'abstract_zh': '基于代理AI系统的实施有可能在多种应用中提供更具帮助性的AI系统。这些系统自主朝着定义的目标工作，并减少外部控制。尽管如此，它们的一个缺点是可靠性不足，特别是在医疗保健或过程工业等高风险领域尤其不适合。不可靠性系统在运行过程中可能存在意外行为的风险，需要采取缓解措施。在本工作中，我们根据其特性推导出代理AI系统在运行过程中主要的可靠性挑战。我们将这些挑战与传统AI系统联系起来，并制定了一个适用于传统和代理AI系统的根本性运行可靠性挑战。作为我们主要的贡献，我们提出了一种两层式可靠性监控框架，包括一个用于新颖输入的离群值检测层和一个揭示内部操作的AI透明度层。这种两层式监控方法为人类操作员提供了必要的决策支持，以判断输出是否可能不可靠并及时干预。该框架为开发减少不确定可靠性带来的风险的缓解技术奠定了基础。', 'title_zh': '代理人工智能系统可靠性监控框架的观点分析'}
{'arxiv_id': 'arXiv:2511.09158', 'title': 'Efficient Reasoning via Reward Model', 'authors': 'Yuhao Wang, Xiaopeng Li, Cheng Gong, Ziru Liu, Suiyun Zhang, Rui Liu, Xiangyu Zhao', 'link': 'https://arxiv.org/abs/2511.09158', 'abstract': "Reinforcement learning with verifiable rewards (RLVR) has been shown to enhance the reasoning capabilities of large language models (LLMs), enabling the development of large reasoning models (LRMs). However, LRMs such as DeepSeek-R1 and OpenAI o1 often generate verbose responses containing redundant or irrelevant reasoning step-a phenomenon known as overthinking-which substantially increases computational costs. Prior efforts to mitigate this issue commonly incorporate length penalties into the reward function, but we find they frequently suffer from two critical issues: length collapse and training collapse, resulting in sub-optimal performance. To address them, we propose a pipeline for training a Conciseness Reward Model (CRM) that scores the conciseness of reasoning path. Additionally, we introduce a novel reward formulation named Conciseness Reward Function (CRF) with explicit dependency between the outcome reward and conciseness score, thereby fostering both more effective and more efficient reasoning. From a theoretical standpoint, we demonstrate the superiority of the new reward from the perspective of variance reduction and improved convergence properties. Besides, on the practical side, extensive experiments on five mathematical benchmark datasets demonstrate the method's effectiveness and token efficiency, which achieves an 8.1% accuracy improvement and a 19.9% reduction in response token length on Qwen2.5-7B. Furthermore, the method generalizes well to other LLMs including Llama and Mistral. The implementation code and datasets are publicly available for reproduction: this https URL.", 'abstract_zh': '可验证奖励的强化学习（RLVR）已被证明能够增强大规模语言模型（LLMs）的推理能力，推动了大规模推理模型（LRMs）的发展。然而，DeepSeek-R1和OpenAI o1等LRMs常常生成冗长的回答，包含多余的或无关的推理步骤——这一现象被称为过度推理，显著增加了计算成本。先前的努力通常通过将长度惩罚纳入奖励函数来缓解这一问题，但我们发现它们经常遭受两个关键问题：长度坍缩和训练坍缩，导致性能不佳。为解决这些问题，我们提出了一种训练简洁性奖励模型（CRM）的管道，用于评估推理路径的简洁性。此外，我们引入了一种新的奖励公式——简洁性奖励函数（CRF），它明确地将结果奖励与简洁性分数相关联，从而促进更具效性和效率的推理。从理论上讲，我们从方差减少和改进收敛性质的角度证明了新奖励的优势。此外，通过在五个数学基准数据集上的广泛实验，我们验证了该方法的有效性和token效率，该方法在Qwen2.5-7B上实现了8.1%的准确率提升和19.9%的响应token长度减少。此外，该方法还很好地适用于其他LLMs，如Llama和Mistral。该实施代码和数据集已公开，可供重现：this https URL。', 'title_zh': '高效推理通过奖励模型'}
{'arxiv_id': 'arXiv:2511.09157', 'title': 'ProBench: Benchmarking GUI Agents with Accurate Process Information', 'authors': 'Leyang Yang, Ziwei Wang, Xiaoxuan Tang, Sheng Zhou, Dajun Chen, Wei Jiang, Yong Li', 'link': 'https://arxiv.org/abs/2511.09157', 'abstract': "With the deep integration of artificial intelligence and interactive technology, Graphical User Interface (GUI) Agent, as the carrier connecting goal-oriented natural language and real-world devices, has received widespread attention from the community. Contemporary benchmarks aim to evaluate the comprehensive capabilities of GUI agents in GUI operation tasks, generally determining task completion solely by inspecting the final screen state. However, GUI operation tasks consist of multiple chained steps while not all critical information is presented in the final few pages. Although a few research has begun to incorporate intermediate steps into evaluation, accurately and automatically capturing this process information still remains an open challenge. To address this weakness, we introduce ProBench, a comprehensive mobile benchmark with over 200 challenging GUI tasks covering widely-used scenarios. Remaining the traditional State-related Task evaluation, we extend our dataset to include Process-related Task and design a specialized evaluation method. A newly introduced Process Provider automatically supplies accurate process information, enabling presice assessment of agent's performance. Our evaluation of advanced GUI agents reveals significant limitations for real-world GUI scenarios. These shortcomings are prevalent across diverse models, including both large-scale generalist models and smaller, GUI-specific models. A detailed error analysis further exposes several universal problems, outlining concrete directions for future improvements.", 'abstract_zh': '随着人工智能与交互技术的深度融合，图形用户界面（GUI）代理作为连接目标导向自然语言和现实世界设备的载体，受到了学术界的广泛关注。当代基准测试旨在评估GUI代理在GUI操作任务中的综合能力，通常仅通过检查最终屏幕状态来判断任务完成情况。然而，GUI操作任务包含多个链式步骤，而并非所有关键信息都体现在最后几页中。虽有少量研究开始将中间步骤纳入评估范围，但准确且自动地捕获这一过程信息仍然是一个待解决问题。为解决这一不足，我们引入了ProBench，这是一个包含超过200个具有挑战性的GUI任务的全面移动基准，涵盖了广泛使用的情景。我们延续传统的状态相关任务评估方法，扩展了数据集以包括过程相关任务，并设计了专门的评估方法。新引入的过程提供商自动提供准确的过程信息，从而精确评估代理的表现。我们的高级GUI代理评估揭示了在真实世界GUI情景中的显著局限性。这些不足出现在多种模型中，包括大规模通用模型和较小的、专门针对GUI的模型。详细错误分析进一步揭示了几种普遍存在的问题，指出了未来改进的具体方向。', 'title_zh': 'ProBench: 基于准确进程信息的GUI代理性能评估'}
{'arxiv_id': 'arXiv:2511.09127', 'title': 'History-Aware Reasoning for GUI Agents', 'authors': 'Ziwei Wang, Leyang Yang, Xiaoxuan Tang, Sheng Zhou, Dajun Chen, Wei Jiang, Yong Li', 'link': 'https://arxiv.org/abs/2511.09127', 'abstract': "Advances in Multimodal Large Language Models have significantly enhanced Graphical User Interface (GUI) automation. Equipping GUI agents with reliable episodic reasoning capabilities is essential for bridging the gap between users' concise task descriptions and the complexities of real-world execution. Current methods integrate Reinforcement Learning (RL) with System-2 Chain-of-Thought, yielding notable gains in reasoning enhancement. For long-horizon GUI tasks, historical interactions connect each screen to the goal-oriented episode chain, and effectively leveraging these clues is crucial for the current decision. However, existing native GUI agents exhibit weak short-term memory in their explicit reasoning, interpreting the chained interactions as discrete screen understanding, i.e., unawareness of the historical interactions within the episode. This history-agnostic reasoning challenges their performance in GUI automation. To alleviate this weakness, we propose a History-Aware Reasoning (HAR) framework, which encourages an agent to reflect on its own errors and acquire episodic reasoning knowledge from them via tailored strategies that enhance short-term memory in long-horizon interaction. The framework mainly comprises constructing a reflective learning scenario, synthesizing tailored correction guidelines, and designing a hybrid RL reward function. Using the HAR framework, we develop a native end-to-end model, HAR-GUI-3B, which alters the inherent reasoning mode from history-agnostic to history-aware, equipping the GUI agent with stable short-term memory and reliable perception of screen details. Comprehensive evaluations across a range of GUI-related benchmarks demonstrate the effectiveness and generalization of our method.", 'abstract_zh': '多模态大型语言模型的进步显著增强了图形用户界面（GUI）自动化。为了弥合用户简洁的任务描述与现实世界执行复杂性之间的差距，为GUI代理装备可靠的瞬时推理能力至关重要。当前方法将强化学习（RL）与系统2链式思考相结合，显著提升了推理能力。对于长期目标导向的GUI任务，历史交互将每个屏幕连接到目标导向的序列链中，有效地利用这些线索对于当前决策至关重要。然而，现有的原生GUI代理在显式推理中表现出较弱的短期记忆，将链式交互视为离散的屏幕理解，即不了解序列链中的历史交互。这种历史无意识的推理对其在GUI自动化中的表现构成了挑战。为了缓解这一弱点，我们提出了一个历史意识推理（HAR）框架，该框架鼓励代理反思自己的错误，并通过定制策略增强长期交互中的短期记忆，从而从其中获取 episodic 推理知识。该框架主要包含构建反思学习场景、合成定制的校正指南和设计混合RL奖励函数。利用HAR框架，我们开发了一个原生端到端模型HAR-GUI-3B，使其推理模式从历史无意识转变为历史意识，为GUI代理提供了稳定的短期记忆和可靠的屏幕细节感知能力。广泛的跨GUI相关基准测试表明了我们方法的有效性和泛化能力。', 'title_zh': '基于历史的推理方法用于GUI代理'}
{'arxiv_id': 'arXiv:2511.09092', 'title': 'OR-R1: Automating Modeling and Solving of Operations Research Optimization Problem via Test-Time Reinforcement Learning', 'authors': 'Zezhen Ding, Zhen Tan, Jiheng Zhang, Tianlong Chen', 'link': 'https://arxiv.org/abs/2511.09092', 'abstract': "Optimization modeling and solving are fundamental to the application of Operations Research (OR) in real-world decision making, yet the process of translating natural language problem descriptions into formal models and solver code remains highly expertise intensive. While recent advances in large language models (LLMs) have opened new opportunities for automation, the generalization ability and data efficiency of existing LLM-based methods are still limited, asmost require vast amounts of annotated or synthetic data, resulting in high costs and scalability barriers. In this work, we present OR-R1, a data-efficient training framework for automated optimization modeling and solving. OR-R1 first employs supervised fine-tuning (SFT) to help the model acquire the essential reasoning patterns for problem formulation and code generation from limited labeled data. In addition, it improves the capability and consistency through Test-Time Group Relative Policy Optimization (TGRPO). This two-stage design enables OR-R1 to leverage both scarce labeled and abundant unlabeled data for effective learning. Experiments show that OR-R1 achieves state-of-the-art performance with an average solving accuracy of $67.7\\%$, using only $1/10$ the synthetic data required by prior methods such as ORLM, exceeding ORLM's solving accuracy by up to $4.2\\%$. Remarkably, OR-R1 outperforms ORLM by over $2.4\\%$ with just $100$ synthetic samples. Furthermore, TGRPO contributes an additional $3.1\\%-6.4\\%$ improvement in accuracy, significantly narrowing the gap between single-attempt (Pass@1) and multi-attempt (Pass@8) performance from $13\\%$ to $7\\%$. Extensive evaluations across diverse real-world benchmarks demonstrate that OR-R1 provides a robust, scalable, and cost-effective solution for automated OR optimization problem modeling and solving, lowering the expertise and data barriers for industrial OR applications.", 'abstract_zh': '一种数据效率高的自动化优化建模与求解训练框架：OR-R1', 'title_zh': 'OR-R1: 通过测试时强化学习自动建模和求解运筹优化问题'}
{'arxiv_id': 'arXiv:2511.09044', 'title': 'Advancing Autonomous Emergency Response Systems: A Generative AI Perspective', 'authors': 'Yousef Emami, Radha Reddy, Azadeh Pourkabirian, Miguel Gutierrez Gaitan', 'link': 'https://arxiv.org/abs/2511.09044', 'abstract': 'Autonomous Vehicles (AVs) are poised to revolutionize emergency services by enabling faster, safer, and more efficient responses. This transformation is driven by advances in Artificial Intelligence (AI), particularly Reinforcement Learning (RL), which allows AVs to navigate complex environments and make critical decisions in real time. However, conventional RL paradigms often suffer from poor sample efficiency and lack adaptability in dynamic emergency scenarios. This paper reviews next-generation AV optimization strategies to address these limitations. We analyze the shift from conventional RL to Diffusion Model (DM)-augmented RL, which enhances policy robustness through synthetic data generation, albeit with increased computational cost. Additionally, we explore the emerging paradigm of Large Language Model (LLM)-assisted In-Context Learning (ICL), which offers a lightweight and interpretable alternative by enabling rapid, on-the-fly adaptation without retraining. By reviewing the state of the art in AV intelligence, DM-augmented RL, and LLM-assisted ICL, this paper provides a critical framework for understanding the next generation of autonomous emergency response systems from a Generative AI perspective.', 'abstract_zh': '自主驾驶汽车（AVs）有望通过实现更快、更安全和更高效的响应来革命化应急服务。这一变革得益于人工智能（AI），尤其是一步步发展的强化学习（RL）技术，使得AV能够在复杂环境中导航并在实时情况下作出关键决策。然而，传统的RL范式往往表现出样本效率低和在动态应急场景中缺乏适应性的问题。本文回顾了下一代AV优化策略以解决这些问题。我们分析了从传统RL向通过生成合成数据增强的扩散模型（DM）-辅助RL转变的情况，虽然这种转变增加了计算成本但提高了策略鲁棒性。此外，我们探讨了大型语言模型（LLM）辅助的即境学习（ICL）新兴范式，提供了轻量级且可解释的替代方案，使其能够实现快速、即时的适应而无需重新训练。通过回顾自主驾驶智能、DM-辅助RL和LLM-辅助ICL的最新进展，本文从生成式AI视角提供了理解新一代自主应急响应系统的关键框架。', 'title_zh': '增强自主紧急响应系统：一个生成式AI视角'}
{'arxiv_id': 'arXiv:2511.09032', 'title': 'Argus: Resilience-Oriented Safety Assurance Framework for End-to-End ADSs', 'authors': 'Dingji Wang, You Lu, Bihuan Chen, Shuo Hao, Haowen Jiang, Yifan Tian, Xin Peng', 'link': 'https://arxiv.org/abs/2511.09032', 'abstract': 'End-to-end autonomous driving systems (ADSs), with their strong capabilities in environmental perception and generalizable driving decisions, are attracting growing attention from both academia and industry. However, once deployed on public roads, ADSs are inevitably exposed to diverse driving hazards that may compromise safety and degrade system performance. This raises a strong demand for resilience of ADSs, particularly the capability to continuously monitor driving hazards and adaptively respond to potential safety violations, which is crucial for maintaining robust driving behaviors in complex driving scenarios.\nTo bridge this gap, we propose a runtime resilience-oriented framework, Argus, to mitigate the driving hazards, thus preventing potential safety violations and improving the driving performance of an ADS. Argus continuously monitors the trajectories generated by the ADS for potential hazards and, whenever the EGO vehicle is deemed unsafe, seamlessly takes control through a hazard mitigator. We integrate Argus with three state-of-the-art end-to-end ADSs, i.e., TCP, UniAD and VAD. Our evaluation has demonstrated that Argus effectively and efficiently enhances the resilience of ADSs, improving the driving score of the ADS by up to 150.30% on average, and preventing up to 64.38% of the violations, with little additional time overhead.', 'abstract_zh': '端到端自动驾驶系统（ADS）的运行时鲁棒性框架Argus：减轻驾驶风险与提升驾驶性能', 'title_zh': 'Argus: 面向端到端ADS的韧性安全保证框架'}
{'arxiv_id': 'arXiv:2511.09030', 'title': 'Solving a Million-Step LLM Task with Zero Errors', 'authors': 'Elliot Meyerson, Giuseppe Paolo, Roberto Dailey, Hormoz Shahrzad, Olivier Francon, Conor F. Hayes, Xin Qiu, Babak Hodjat, Risto Miikkulainen', 'link': 'https://arxiv.org/abs/2511.09030', 'abstract': 'LLMs have achieved remarkable breakthroughs in reasoning, insights, and tool use, but chaining these abilities into extended processes at the scale of those routinely executed by humans, organizations, and societies has remained out of reach. The models have a persistent error rate that prevents scale-up: for instance, recent experiments in the Towers of Hanoi benchmark domain showed that the process inevitably becomes derailed after at most a few hundred steps. Thus, although LLM research is often still benchmarked on tasks with relatively few dependent logical steps, there is increasing attention on the ability (or inability) of LLMs to perform long range tasks. This paper describes MAKER, the first system that successfully solves a task with over one million LLM steps with zero errors, and, in principle, scales far beyond this level. The approach relies on an extreme decomposition of a task into subtasks, each of which can be tackled by focused microagents. The high level of modularity resulting from the decomposition allows error correction to be applied at each step through an efficient multi-agent voting scheme. This combination of extreme decomposition and error correction makes scaling possible. Thus, the results suggest that instead of relying on continual improvement of current LLMs, massively decomposed agentic processes (MDAPs) may provide a way to efficiently solve problems at the level of organizations and societies.', 'abstract_zh': '大规模语言模型在推理、洞察和工具使用方面取得了显著突破，但将这些能力扩展到人类、组织和社会通常执行的延伸过程中依然遥不可及。模型存在持续的错误率，阻碍了规模扩展：例如，在汉诺塔基准域的最近实验中，过程在最多几百步后不可避免地陷入停滞。因此，尽管大规模语言模型研究通常仍然基于相对较少依赖逻辑步骤的任务进行 benchmark，但对大规模语言模型执行长距离任务的能力（或无能）的关注不断增强。本文描述了 MAKER，这是首个成功解决超过一百万大规模语言模型步骤且无错误的任务系统，并且原则上可以进一步扩展。该方法依赖于对任务的极端分解，使其可以由专注于微代理的子任务逐一解决。由于分解导致的高度模块化使得可以在每个步骤通过高效的多代理投票方案进行错误修正。这种极端分解与错误修正的结合使得规模扩展成为可能。因此，结果表明，与其依赖当前大规模语言模型的持续改进，大规模分解的代理过程（MDAP）可能提供了一种有效解决组织和社会级别问题的方法。', 'title_zh': '解决百万步语言模型任务零错误问题'}
{'arxiv_id': 'arXiv:2511.09005', 'title': 'AI Founding Fathers: A Case Study of GIS Search in Multi-Agent Pipelines', 'authors': 'Alvin Chauhan', 'link': 'https://arxiv.org/abs/2511.09005', 'abstract': "Although Large Language Models (LLMs) show exceptional fluency, efforts persist to extract stronger reasoning capabilities from them. Drawing on search-based interpretations of LLM computation, this paper advances a systematic framework for understanding LLM reasoning and optimization. Namely, that enhancing reasoning is best achieved by structuring a multi-agent pipeline to ensure a traversal of the search space in a gradual, incremental, and sequential (GIS) manner. Stated succinctly, high-quality reasoning is a controlled, incremental search. To test this framework, we investigate the efficacy of recursive refinement (RR)--an iterative process of self-criticism, adversarial stress-testing, and integrating critical feedback--as a practical method for implementing GIS search. We designed an experiment comparing a simple, linear pipeline against a complex, explicitly structured pipeline leveraging a recursive refinement layer. The multi-agent models were constructed to reflect the historical personas of three US Founding Fathers (Hamilton, Jefferson, and Madison) using RAG-powered corpora and were prompted to generate responses to three contemporary political issues. Model performance was evaluated using a two-tiered approach: a quantitative score from an LLM arbiter agent and qualitative human judgment. Our results revealed that the complex model consistently outperformed the simple model across all nine test cases with an average arbiter-outputted score of 88.3 versus 71.7. The complex model's arguments were superior in analytical depth, structural nuance, and strategic framing. We conclude that recursive refinement is a robust architectural feature for enhancing LLM reasoning via GIS search.", 'abstract_zh': '尽管大型语言模型（LLMs）表现出色，但仍然努力从中提取更强的推理能力。基于搜索视角对LLM计算的解析，本文提出了一种系统性的框架以理解LLM推理和优化。具体而言，通过构建一个多层次的代理管道以确保在逐步、增量和顺序（GIS）的方式下遍历搜索空间，是增强推理的最佳途径。简而言之，高质量的推理就是一种受控的增量搜索。为了测试这种框架，我们研究了递归细化（RR）——一个迭代的自我批判、对抗性压力测试和整合关键反馈的过程——作为一种实际的方法来实施GIS搜索。我们设计了一个实验，将一个简单的线性管道与利用递归细化层的复杂且明确结构化的管道进行了比较。这些多层次的模型使用RAG驱动的语料库构建，反映了三位美国开国元勋（汉密尔顿、杰斐逊和麦迪逊）的历史人物特征，并被要求针对三个当代政治问题生成回应。模型性能通过两级评估方法进行评价：由LLM仲裁代理给出的定量评分和人类的定性判断。我们的结果显示，复杂的模型在所有九个测试案例中都优于简单的模型，平均仲裁输出得分为88.3比71.7。复杂的模型在分析深度、结构精细度和战略框架方面表现出更优的论据。我们得出结论，递归细化是一种稳健的架构特征，可以通过GIS搜索增强LLM推理。', 'title_zh': 'AI奠基人：多智能体管道中GIS搜索案例研究'}
{'arxiv_id': 'arXiv:2511.08982', 'title': 'Heterogeneous Graph Neural Networks for Assumption-Based Argumentation', 'authors': 'Preesha Gehlot, Anna Rapberger, Fabrizio Russo, Francesca Toni', 'link': 'https://arxiv.org/abs/2511.08982', 'abstract': 'Assumption-Based Argumentation (ABA) is a powerful structured argumentation formalism, but exact computation of extensions under stable semantics is intractable for large frameworks. We present the first Graph Neural Network (GNN) approach to approximate credulous acceptance in ABA. To leverage GNNs, we model ABA frameworks via a dependency graph representation encoding assumptions, claims and rules as nodes, with heterogeneous edge labels distinguishing support, derive and attack relations. We propose two GNN architectures - ABAGCN and ABAGAT - that stack residual heterogeneous convolution or attention layers, respectively, to learn node embeddings. Our models are trained on the ICCMA 2023 benchmark, augmented with synthetic ABAFs, with hyperparameters optimised via Bayesian search. Empirically, both ABAGCN and ABAGAT outperform a state-of-the-art GNN baseline that we adapt from the abstract argumentation literature, achieving a node-level F1 score of up to 0.71 on the ICCMA instances. Finally, we develop a sound polynomial time extension-reconstruction algorithm driven by our predictor: it reconstructs stable extensions with F1 above 0.85 on small ABAFs and maintains an F1 of about 0.58 on large frameworks. Our work opens new avenues for scalable approximate reasoning in structured argumentation.', 'abstract_zh': '基于假设的论辩（假设论辩）是一种强大的结构化论辩形式化方法，但在大规模框架下，精确计算在稳定语义下的结论是不可行的。我们提出了首个使用图神经网络（GNN）来近似估计假设论辩中的无拘束接受度的方法。为了利用GNN，我们将假设论辩框架通过依赖图表示进行建模，其中假设、主张和规则作为节点，异质边标签区分支持、推出和攻击关系。我们提出了两种GNN架构——ABAGCN和ABAGAT，分别通过堆叠残差异质卷积层或注意力层来学习节点嵌入。我们的模型在ICCMACM 2023基准数据集上进行训练，数据集通过合成的论辩框架进行扩充，并通过贝叶斯搜索优化超参数。实验结果显示，ABAGCN和ABAGAT在ICCMACM实例上优于我们从抽象论辩文献中调整的最先进的GNN基线，节点级别F1分数达到0.71。最后，我们开发了一种由我们的预测器驱动的正确多项式时间扩展重构算法，该算法在小规模论辩框架上重构稳定扩展的F1分数超过0.85，并在大规模框架上保持F1分数约为0.58。我们的工作为结构化论辩中的可扩展近似推理开辟了新的途径。', 'title_zh': '基于假设的论证中的异质图神经网络'}
{'arxiv_id': 'arXiv:2511.08947', 'title': 'AlphaCast: A Human Wisdom-LLM Intelligence Co-Reasoning Framework for Interactive Time Series Forecasting', 'authors': 'Xiaohan Zhang, Tian Gao, Mingyue Cheng, Bokai Pan, Ze Guo, Yaguo Liu, Xiaoyu Tao', 'link': 'https://arxiv.org/abs/2511.08947', 'abstract': 'Time series forecasting plays a critical role in high-stakes domains such as energy, healthcare, and climate. Although recent advances have improved accuracy, most approaches still treat forecasting as a static one-time mapping task, lacking the interaction, reasoning, and adaptability of human experts. This gap limits their usefulness in complex real-world environments. To address this, we propose AlphaCast, a human wisdom-large language model (LLM) intelligence co-reasoning framework that redefines forecasting as an interactive process. The key idea is to enable step-by-step collaboration between human wisdom and LLM intelligence to jointly prepare, generate, and verify forecasts. The framework consists of two stages: (1) automated prediction preparation, where AlphaCast builds a multi-source cognitive foundation comprising a feature set that captures key statistics and time patterns, a domain knowledge base distilled from corpora and historical series, a contextual repository that stores rich information for each time window, and a case base that retrieves optimal strategies via pattern clustering and matching; and (2) generative reasoning and reflective optimization, where AlphaCast integrates statistical temporal features, prior knowledge, contextual information, and forecasting strategies, triggering a meta-reasoning loop for continuous self-correction and strategy refinement. Extensive experiments on short- and long-term datasets show that AlphaCast consistently outperforms state-of-the-art baselines in predictive accuracy. Code is available at this repository: this https URL .', 'abstract_zh': '时间序列预测在能源、医疗和气候等领域扮演着关键角色。虽然近期进展提高了预测准确性，但大多数方法仍将预测视为静态的一次性映射任务，缺乏人类专家的互动、推理和适应性。这一差距限制了它们在复杂现实环境中的应用价值。为解决这一问题，我们提出了一种AlphaCast框架，它重新定义了预测为一个互动过程，结合了人类智慧和大规模语言模型（LLM）的智能协同推理。该框架包含两个阶段：（1）自动化预测准备阶段，AlphaCast构建一个多源认知基础，包括特征集、领域知识库、上下文存储库和案例库；（2）生成推理与反思优化阶段，AlphaCast整合统计时间特征、先验知识、上下文信息和预测策略，触发一个元推理循环，实现持续自我纠正和策略细化。在短期和长期数据集上的大量实验表明，AlphaCast在预测准确性方面始终优于最先进的基准方法。代码可在以下仓库获取：this https URL。', 'title_zh': 'AlphaCast：一种结合人类智慧与LLM智能的互动时间序列预测推理框架'}
{'arxiv_id': 'arXiv:2511.08934', 'title': 'A Research on Business Process Optimisation Model Integrating AI and Big Data Analytics', 'authors': 'Di Liao, Ruijia Liang, Ziyi Ye', 'link': 'https://arxiv.org/abs/2511.08934', 'abstract': 'With the deepening of digital transformation, business process optimisation has become the key to improve the competitiveness of enterprises. This study constructs a business process optimisation model integrating artificial intelligence and big data to achieve intelligent management of the whole life cycle of processes. The model adopts a three-layer architecture incorporating data processing, AI algorithms, and business logic to enable real-time process monitoring and optimization. Through distributed computing and deep learning techniques, the system can handle complex business scenarios while maintaining high performance and reliability. Experimental validation across multiple enterprise scenarios shows that the model shortens process processing time by 42%, improves resource utilisation by 28%, and reduces operating costs by 35%. The system maintained 99.9% availability under high concurrent loads. The research results have important theoretical and practical value for promoting the digital transformation of enterprises, and provide new ideas for improving the operational efficiency of enterprises.', 'abstract_zh': '随着数字化转型的深化，业务流程优化已成为提升企业竞争力的关键。本研究构建了一个集成人工智能和大数据的业务流程优化模型，以实现业务流程全生命周期的智能管理。该模型采用三层架构，包括数据处理、AI算法和业务逻辑，以实现实时流程监控和优化。通过分布式计算和深度学习技术，系统能够在复杂业务场景下保持高性能和高可靠性。在多个企业场景下的实验验证表明，该模型将流程处理时间缩短了42%，资源利用率提高了28%，运营成本降低了35%。在高并发负载下，系统保持了99.9%的可用性。研究结果对于推动企业的数字化转型具有重要的理论和实用价值，并为提高企业运营效率提供了新的思路。', 'title_zh': '基于AI和大数据分析的业务流程优化模型研究'}
{'arxiv_id': 'arXiv:2511.08927', 'title': 'The Double Contingency Problem: AI Recursion and the Limits of Interspecies Understanding', 'authors': 'Graham L. Bishop', 'link': 'https://arxiv.org/abs/2511.08927', 'abstract': "Current bioacoustic AI systems achieve impressive cross-species performance by processing animal communication through transformer architectures, foundation model paradigms, and other computational approaches. However, these approaches overlook a fundamental question: what happens when one form of recursive cognition--AI systems with their attention mechanisms, iterative processing, and feedback loops--encounters the recursive communicative processes of other species? Drawing on philosopher Yuk Hui's work on recursivity and contingency, I argue that AI systems are not neutral pattern detectors but recursive cognitive agents whose own information processing may systematically obscure or distort other species' communicative structures. This creates a double contingency problem: each species' communication emerges through contingent ecological and evolutionary conditions, while AI systems process these signals through their own contingent architectural and training conditions. I propose that addressing this challenge requires reconceptualizing bioacoustic AI from universal pattern recognition toward diplomatic encounter between different forms of recursive cognition, with implications for model design, evaluation frameworks, and research methodologies.", 'abstract_zh': '当前的生物声学AI系统通过变压器架构、基础模型范式和其他计算方法在不同物种间实现了令人印象深刻的性能，但这些方法忽视了一个基本问题：当一种递归认知形式——具有注意力机制、迭代处理和反馈循环的AI系统——遇到其他物种的递归通讯过程时会发生什么？借鉴哲学家Yuk Hui关于递归和偶然性的探讨，我认为AI系统不仅是中立的模式检测器，而是递归认知代理，其自身的信息处理可能系统性地模糊或扭曲其他物种的通讯结构。这造成了双重偶然性问题：每个物种的通讯都是在偶然的生态和进化条件下产生的，而AI系统则是通过其自身的偶然架构和训练条件来处理这些信号。我认为解决这一挑战需要从普遍的模式识别重新构想生物声学AI，转向不同形式递归认知之间的外交相遇，对于模型设计、评估框架和研究方法都有重要影响。', 'title_zh': '双重 contingency问题：AI递归与跨物种理解的限度'}
{'arxiv_id': 'arXiv:2511.08892', 'title': 'Lumine: An Open Recipe for Building Generalist Agents in 3D Open Worlds', 'authors': 'Weihao Tan, Xiangyang Li, Yunhao Fang, Heyuan Yao, Shi Yan, Hao Luo, Tenglong Ao, Huihui Li, Hongbin Ren, Bairen Yi, Yujia Qin, Bo An, Libin Liu, Guang Shi', 'link': 'https://arxiv.org/abs/2511.08892', 'abstract': "We introduce Lumine, the first open recipe for developing generalist agents capable of completing hours-long complex missions in real time within challenging 3D open-world environments. Lumine adopts a human-like interaction paradigm that unifies perception, reasoning, and action in an end-to-end manner, powered by a vision-language model. It processes raw pixels at 5 Hz to produce precise 30 Hz keyboard-mouse actions and adaptively invokes reasoning only when necessary. Trained in Genshin Impact, Lumine successfully completes the entire five-hour Mondstadt main storyline on par with human-level efficiency and follows natural language instructions to perform a broad spectrum of tasks in both 3D open-world exploration and 2D GUI manipulation across collection, combat, puzzle-solving, and NPC interaction. In addition to its in-domain performance, Lumine demonstrates strong zero-shot cross-game generalization. Without any fine-tuning, it accomplishes 100-minute missions in Wuthering Waves and the full five-hour first chapter of Honkai: Star Rail. These promising results highlight Lumine's effectiveness across distinct worlds and interaction dynamics, marking a concrete step toward generalist agents in open-ended environments.", 'abstract_zh': 'Lumine：首个用于在挑战性3D开放世界环境中实时完成长时间复杂任务的一般型智能体开源框架', 'title_zh': 'Lumine：构建三维开放世界通用智能体的开源方案'}
{'arxiv_id': 'arXiv:2511.08873', 'title': 'UCO: A Multi-Turn Interactive Reinforcement Learning Method for Adaptive Teaching with Large Language Models', 'authors': 'Shouang Wei, Min Zhang, Xin Lin, Bo Jiang, Kun Kuang, Zhongxiang Dai', 'link': 'https://arxiv.org/abs/2511.08873', 'abstract': "Large language models (LLMs) are shifting from answer providers to intelligent tutors in educational settings, yet current supervised fine-tuning methods only learn surface teaching patterns without dynamic adaptation capabilities. Recent reinforcement learning approaches address this limitation but face two critical challenges. First, they evaluate teaching effectiveness solely based on whether students produce correct outputs, unable to distinguish whether students genuinely understand or echo teacher-provided answers during interaction. Second, they cannot perceive students' evolving cognitive states in real time through interactive dialogue, thus failing to adapt teaching strategies to match students' cognitive levels dynamically. We propose the Unidirectional Cognitive Optimization (UCO) method to address these challenges. UCO uses a multi-turn interactive reinforcement learning paradigm where the innovation lies in two synergistic reward functions: the Progress Reward captures students' cognitive advancement, evaluating whether students truly transition from confusion to comprehension, while the Scaffold Reward dynamically identifies each student's Zone of Proximal Development (ZPD), encouraging teachers to maintain productive teaching within this zone. We evaluate UCO by comparing it against 11 baseline models on BigMath and MathTutorBench benchmarks. Experimental results demonstrate that our UCO model outperforms all models of equivalent scale and achieves performance comparable to advanced closed-source models. The code and data are available at this https URL.", 'abstract_zh': '大型语言模型（LLMs）正在从答案提供者转变为教育环境中的智能导师，然而当前的监督微调方法仅学习表面的教学模式，缺乏动态适应能力。最近的强化学习方法解决了这一局限性，但面临两个关键挑战。首先，它们仅根据学生是否产生正确输出来评估教学效果，无法区分学生在互动中是否真正理解或只是重复教师提供的答案。其次，它们无法通过交互对话实时感知学生不断变化的认知状态，从而无法动态调整教学策略以匹配学生的认知水平。我们提出了统一认知优化（UCO）方法来应对这些挑战。UCO 使用多轮次交互强化学习范式，其中的创新点在于两个协同的奖励函数：进步奖励捕捉学生认知的进步，评估学生是否真正从困惑到理解的转变，而支架奖励动态识别每个学生的最近发展区（ZPD），鼓励教师在这一区域内维持有效的教学。我们通过在 BigMath 和 MathTutorBench 基准上与 11 个基线模型进行对比来评估 UCO。实验结果表明，我们的 UCO 模型在所有同等规模的模型中表现最佳，并且达到了与高级闭源模型相当的性能。代码和数据可在以下网址获得。', 'title_zh': 'UCO：一种基于多轮交互强化学习的自适应教学方法，用于大型语言模型辅助教学'}
{'arxiv_id': 'arXiv:2511.08825', 'title': 'Neural Value Iteration', 'authors': 'Yang You, Ufuk Çakır, Alex Schutz, Robert Skilton, Nick Hawes', 'link': 'https://arxiv.org/abs/2511.08825', 'abstract': "The value function of a POMDP exhibits the piecewise-linear-convex (PWLC) property and can be represented as a finite set of hyperplanes, known as $\\alpha$-vectors. Most state-of-the-art POMDP solvers (offline planners) follow the point-based value iteration scheme, which performs Bellman backups on $\\alpha$-vectors at reachable belief points until convergence. However, since each $\\alpha$-vector is $|S|$-dimensional, these methods quickly become intractable for large-scale problems due to the prohibitive computational cost of Bellman backups. In this work, we demonstrate that the PWLC property allows a POMDP's value function to be alternatively represented as a finite set of neural networks. This insight enables a novel POMDP planning algorithm called \\emph{Neural Value Iteration}, which combines the generalization capability of neural networks with the classical value iteration framework. Our approach achieves near-optimal solutions even in extremely large POMDPs that are intractable for existing offline solvers.", 'abstract_zh': '部分线性凸值函数的Partially Observable Markov Decision Process的值函数可以表示为有限个超平面的集合，即α向量。大多数最先进的POMDP求解器（离线规划器）遵循基于点的值迭代方案，在可达信念点上进行贝尔曼备份，直到收敛。然而，由于每个α向量都是|S|维的，这些方法对于大规模问题由于贝尔曼备份的计算成本高昂而变得不可行。在本工作中，我们证明部分线性凸性允许POMDP的值函数被表示为有限个神经网络的集合。这一洞察促进了名为Neural Value Iteration的新型POMDP规划算法，该算法结合了神经网络的泛化能力和经典的值迭代框架。我们的方法即使在现有离线求解器无法处理的极大POMDP中也能近似获得最优解。', 'title_zh': '神经值迭代'}
{'arxiv_id': 'arXiv:2511.08749', 'title': 'Interpretable by Design: Query-Specific Neural Modules for Explainable Reinforcement Learning', 'authors': 'Mehrdad Zakershahrak', 'link': 'https://arxiv.org/abs/2511.08749', 'abstract': 'Reinforcement learning has traditionally focused on a singular objective: learning policies that select actions to maximize reward. We challenge this paradigm by asking: what if we explicitly architected RL systems as inference engines that can answer diverse queries about their environment? In deterministic settings, trained agents implicitly encode rich knowledge about reachability, distances, values, and dynamics - yet current architectures are not designed to expose this information efficiently. We introduce Query Conditioned Deterministic Inference Networks (QDIN), a unified architecture that treats different types of queries (policy, reachability, paths, comparisons) as first-class citizens, with specialized neural modules optimized for each inference pattern. Our key empirical finding reveals a fundamental decoupling: inference accuracy can reach near-perfect levels (99% reachability IoU) even when control performance remains suboptimal (31% return), suggesting that the representations needed for accurate world knowledge differ from those required for optimal control. Experiments demonstrate that query specialized architectures outperform both unified models and post-hoc extraction methods, while maintaining competitive control performance. This work establishes a research agenda for RL systems designed from inception as queryable knowledge bases, with implications for interpretability, verification, and human-AI collaboration.', 'abstract_zh': '强化学习传统上专注于单一目标：学习选择行动以最大化奖励的策略。我们通过提出一个问题来挑战这一范式：如果我们明确将RL系统设计为可以回答其环境的各种查询的推理引擎，会怎样？在确定性环境中，训练过的智能体隐含地编码了丰富的可达性、距离、值和动力学知识——但当前的架构并未设计成能够高效地暴露这些信息。我们引入了查询条件确定性推理网络（QDIN），这是一种统一架构，将不同类型的查询（策略、可达性、路径、比较）视为一等公民，为每种推理模式优化专门的神经模块。我们的关键实验证据揭示了一个根本性的解耦：即使控制性能不佳（31%的回报），推理准确性也可以达到近乎完美的水平（99%的可达性IoU），表明用于准确世界知识的表示与用于最优控制的表示是不同的。实验表明，查询专门化架构在保持竞争力的控制性能的同时，优于统一模型和事后提取方法。本工作确立了一个研究议程，即将RL系统从设计之初就作为一个可查询的知识库，这将对可解释性、验证和人机协作产生影响。', 'title_zh': '设计可解释的：面向查询的神经模块在可解释 reinforcement 学习中的应用'}
{'arxiv_id': 'arXiv:2511.08747', 'title': 'Vector Symbolic Algebras for the Abstraction and Reasoning Corpus', 'authors': 'Isaac Joffe, Chris Eliasmith', 'link': 'https://arxiv.org/abs/2511.08747', 'abstract': 'The Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI) is a generative, few-shot fluid intelligence benchmark. Although humans effortlessly solve ARC-AGI, it remains extremely difficult for even the most advanced artificial intelligence systems. Inspired by methods for modelling human intelligence spanning neuroscience to psychology, we propose a cognitively plausible ARC-AGI solver. Our solver integrates System 1 intuitions with System 2 reasoning in an efficient and interpretable process using neurosymbolic methods based on Vector Symbolic Algebras (VSAs). Our solver works by object-centric program synthesis, leveraging VSAs to represent abstract objects, guide solution search, and enable sample-efficient neural learning. Preliminary results indicate success, with our solver scoring 10.8% on ARC-AGI-1-Train and 3.0% on ARC-AGI-1-Eval. Additionally, our solver performs well on simpler benchmarks, scoring 94.5% on Sort-of-ARC and 83.1% on 1D-ARC -- the latter outperforming GPT-4 at a tiny fraction of the computational cost. Importantly, our approach is unique; we believe we are the first to apply VSAs to ARC-AGI and have developed the most cognitively plausible ARC-AGI solver yet. Our code is available at: this https URL.', 'abstract_zh': '人工通用 intelligence 的抽象和推理语料库（ARC-AGI）是一种生成式、少样本流式智能基准。尽管人类轻松解决 ARC-AGI，但对于最先进的 AI 系统来说，它仍然极为困难。借鉴涵盖神经科学到心理学的人类智能建模方法，我们提出了一种认知合理的 ARC-AGI 解决方案。我们的解决方案通过基于向量符号代数（VSAs）的神经符号方法，将 System 1 直觉与 System 2 推理高效且可解释地结合在一起。我们的解决方案通过基于对象的程序合成工作，利用 VSAs 表征抽象对象、指导解决方案搜索并实现样本高效神经学习。初步结果表明，我们的解决方案在 ARC-AGI-1-Train 上得分为 10.8%，在 ARC-AGI-1-Eval 上得分为 3.0%。此外，我们的解决方案在更简单的基准测试中表现良好，在 Sort-of-ARC 上得分为 94.5%，在 1D-ARC 上得分为 83.1%，后者在极低的计算成本下优于 GPT-4。重要的是，我们的方法独树一帜；我们认为我们是首次将 VSAs 应用于 ARC-AGI，并且已开发出迄今为止最符合认知的 ARC-AGI 解决方案。我们的代码可在此处获取：this https URL。', 'title_zh': '向量符号代数用于抽象与推理语料库'}
{'arxiv_id': 'arXiv:2511.08715', 'title': 'Bridging Natural Language and ASP: A Hybrid Approach Using LLMs and AMR Parsing', 'authors': 'Connar Hite, Sean Saud, Raef Taha, Nayim Rahman, Tanvir Atahary, Scott Douglass, Tarek Taha', 'link': 'https://arxiv.org/abs/2511.08715', 'abstract': 'Answer Set Programming (ASP) is a declarative programming paradigm based on logic programming and non-monotonic reasoning. It is a tremendously powerful tool for describing and solving combinatorial problems. Like any other language, ASP requires users to learn how it works and the syntax involved. It is becoming increasingly required for those unfamiliar with programming languages to interact with code. This paper proposes a novel method of translating unconstrained English into ASP programs for logic puzzles using an LLM and Abstract Meaning Representation (AMR) graphs. Everything from ASP rules, facts, and constraints is generated to fully represent and solve the desired problem. Example logic puzzles are used to demonstrate the capabilities of the system. While most current methods rely entirely on an LLM, our system minimizes the role of the LLM only to complete straightforward tasks. The LLM is used to simplify natural language sentences, identify keywords, and generate simple facts. The AMR graphs are then parsed from simplified language and used to generate ASP constraints systematically. The system successfully creates an entire ASP program that solves a combinatorial logic problem. This approach is a significant first step in creating a lighter-weight, explainable system that converts natural language to solve complex logic problems.', 'abstract_zh': '基于LLM和AMR图的不受约束的英语到ASP程序的转换方法', 'title_zh': '自然语言与ASP的桥梁：基于LLM和AMR解析的混合方法'}
{'arxiv_id': 'arXiv:2511.09558', 'title': 'IFG: Internet-Scale Guidance for Functional Grasping Generation', 'authors': 'Ray Muxin Liu, Mingxuan Li, Kenneth Shaw, Deepak Pathak', 'link': 'https://arxiv.org/abs/2511.09558', 'abstract': 'Large Vision Models trained on internet-scale data have demonstrated strong capabilities in segmenting and semantically understanding object parts, even in cluttered, crowded scenes. However, while these models can direct a robot toward the general region of an object, they lack the geometric understanding required to precisely control dexterous robotic hands for 3D grasping. To overcome this, our key insight is to leverage simulation with a force-closure grasping generation pipeline that understands local geometries of the hand and object in the scene. Because this pipeline is slow and requires ground-truth observations, the resulting data is distilled into a diffusion model that operates in real-time on camera point clouds. By combining the global semantic understanding of internet-scale models with the geometric precision of a simulation-based locally-aware force-closure, \\our achieves high-performance semantic grasping without any manually collected training data. For visualizations of this please visit our website at this https URL', 'abstract_zh': '大规模训练于互联网规模数据的视觉模型在分割和语义理解物体部分方面展示了强大的能力，即使在杂乱拥挤的场景中也是如此。然而，尽管这些模型可以引导机器人朝物体的大致位置移动，但它们缺乏精确控制灵巧机器人手进行3D抓取所需的几何理解能力。为克服这一问题，我们的关键洞察是利用模拟与力闭合抓取生成管道相结合，该管道理解场景中手和物体的局部几何结构。由于该管道运行缓慢并需要 ground-truth 观测，结果数据被精简成一个实时操作于相机点云上的扩散模型。通过结合互联网规模模型的全局语义理解和基于模拟的局部意识力闭合的几何精度，我们的方法实现了高性能的语义抓取，而无需任何手动收集的训练数据。有关此方法的可视化，请访问我们的网站：this https URL。', 'title_zh': 'IFG: 面向功能抓取生成的互联网规模指导'}
{'arxiv_id': 'arXiv:2511.09533', 'title': 'Digital Co-Founders: Transforming Imagination into Viable Solo Business via Agentic AI', 'authors': 'Farhad Rezazadeh, Pegah Bonehgazy', 'link': 'https://arxiv.org/abs/2511.09533', 'abstract': "This paper investigates how individual entrepreneurs can turn creative ideas into successful solo businesses in an era increasingly shaped by Artificial Intelligence (AI) agents. It highlights the key steps that connect personal vision, structured experimentation, and lasting value creation, and shows how AI agents can act as digital co-founders throughout this journey. Building on research in entrepreneurship, creativity, and innovation, we present a framework with three key stages: (1) Imagination shaping, where vague goals become clear value propositions, supported by AI agents that help with market scanning, idea refinement, and rapid concept generation; (2) Reality testing, where these ideas are tested through low-cost experiments, structured feedback loops, and efficient execution, with AI agents automating tasks such as prototyping, content creation, customer interaction, and data analysis; and (3) Reality scaling, where successful ideas are transformed into repeatable processes, scalable market strategies, and long-term business models, increasingly operated and optimized by autonomous or semi-autonomous AI workflows. We focus on the specific context of solopreneurship, characterized by limited human resources, complete accountability for decision-making, and a strong association between the founder's identity and the business. The framework clearly identifies key enabling factors such as mental adaptability, effective planning, and successful human-AI collaboration within digital ecosystems. It also thoughtfully addresses ongoing challenges, like uncertainty and cognitive overload, which are heightened by our constant connectivity.", 'abstract_zh': '本研究探讨了个创业人士如何在日益受到人工智能代理影响的时代将创造性想法转化为成功的单人企业。它强调了将个人愿景、结构化实验和持久价值创造联系起来的关键步骤，并展示了人工智能代理在整个旅程中作为数字联合创始人发挥作用的方式。基于创业、创造力和创新方面的研究，我们提出了一种具有三个关键阶段的框架：（1）想象塑造，其中模糊的目标变为清晰的价值主张，并有辅助市场调查、想法细化和快速概念生成的人工智能代理的支持；（2）现实测试，其中这些想法通过低成本实验、结构化的反馈循环和高效执行进行测试，人工智能代理自动化原型制作、内容创作、客户互动和数据分析等任务；（3）现实扩展，其中成功的想法被转化为可重复的过程、可扩展的市场策略和长期的企业模型，越来越多地由自主或半自主的人工智能工作流操作和优化。我们重点关注单人创业的具体背景，其特征为有限的人力资源、决策的全面负责以及创始人身份与企业之间的强烈关联。该框架明确界定了关键的促成因素，如心理适应性、有效规划以及数字生态系统中的人机协作。它还仔细考虑了持续存在的挑战，如不确定性与认知超载，这些挑战因我们不断的技术连接而加剧。', 'title_zh': '数字联合创始人：通过代理人工智能将想象转化为可行的独立业务'}
{'arxiv_id': 'arXiv:2511.09515', 'title': 'WMPO: World Model-based Policy Optimization for Vision-Language-Action Models', 'authors': 'Fangqi Zhu, Zhengyang Yan, Zicong Hong, Quanxin Shou, Xiao Ma, Song Guo', 'link': 'https://arxiv.org/abs/2511.09515', 'abstract': 'Vision-Language-Action (VLA) models have shown strong potential for general-purpose robotic manipulation, but their reliance on expert demonstrations limits their ability to learn from failures and perform self-corrections. Reinforcement learning (RL) addresses these through self-improving interactions with the physical environment, but suffers from high sample complexity on real robots. We introduce World-Model-based Policy Optimization (WMPO), a principled framework for on-policy VLA RL without interacting with the real environment. In contrast to widely used latent world models, WMPO focuses on pixel-based predictions that align the "imagined" trajectories with the VLA features pretrained with web-scale images. Crucially, WMPO enables the policy to perform on-policy GRPO that provides stronger performance than the often-used off-policy methods. Extensive experiments in both simulation and real-robot settings demonstrate that WMPO (i) substantially improves sample efficiency, (ii) achieves stronger overall performance, (iii) exhibits emergent behaviors such as self-correction, and (iv) demonstrates robust generalization and lifelong learning capabilities.', 'abstract_zh': '基于世界模型的策略优化（WMPO）：一种无需与真实环境交互的Vision-Language-Action（VLA）强化学习框架', 'title_zh': 'WMPO：基于世界模型的策略优化方法用于视觉-语言-动作模型'}
{'arxiv_id': 'arXiv:2511.09502', 'title': 'DreamPose3D: Hallucinative Diffusion with Prompt Learning for 3D Human Pose Estimation', 'authors': 'Jerrin Bright, Yuhao Chen, John S. Zelek', 'link': 'https://arxiv.org/abs/2511.09502', 'abstract': "Accurate 3D human pose estimation remains a critical yet unresolved challenge, requiring both temporal coherence across frames and fine-grained modeling of joint relationships. However, most existing methods rely solely on geometric cues and predict each 3D pose independently, which limits their ability to resolve ambiguous motions and generalize to real-world scenarios. Inspired by how humans understand and anticipate motion, we introduce DreamPose3D, a diffusion-based framework that combines action-aware reasoning with temporal imagination for 3D pose estimation. DreamPose3D dynamically conditions the denoising process using task-relevant action prompts extracted from 2D pose sequences, capturing high-level intent. To model the structural relationships between joints effectively, we introduce a representation encoder that incorporates kinematic joint affinity into the attention mechanism. Finally, a hallucinative pose decoder predicts temporally coherent 3D pose sequences during training, simulating how humans mentally reconstruct motion trajectories to resolve ambiguity in perception. Extensive experiments on benchmarked Human3.6M and MPI-3DHP datasets demonstrate state-of-the-art performance across all metrics. To further validate DreamPose3D's robustness, we tested it on a broadcast baseball dataset, where it demonstrated strong performance despite ambiguous and noisy 2D inputs, effectively handling temporal consistency and intent-driven motion variations.", 'abstract_zh': '基于扩散模型的知动作因果推理与时空想象的3D人体姿态估计', 'title_zh': 'DreamPose3D：基于提示学习的生成扩散模型在3D人体姿态估计中的应用'}
{'arxiv_id': 'arXiv:2511.09492', 'title': 'Enhancing Password Security Through a High-Accuracy Scoring Framework Using Random Forests', 'authors': 'Muhammed El Mustaqeem Mazelan, Noor Hazlina Abdul, Nouar AlDahoul', 'link': 'https://arxiv.org/abs/2511.09492', 'abstract': "Password security plays a crucial role in cybersecurity, yet traditional password strength meters, which rely on static rules like character-type requirements, often fail. Such methods are easily bypassed by common password patterns (e.g., 'P@ssw0rd1!'), giving users a false sense of security. To address this, we implement and evaluate a password strength scoring system by comparing four machine learning models: Random Forest (RF), Support Vector Machine (SVM), a Convolutional Neural Network (CNN), and Logistic Regression with a dataset of over 660,000 real-world passwords. Our primary contribution is a novel hybrid feature engineering approach that captures nuanced vulnerabilities missed by standard metrics. We introduce features like leetspeak-normalized Shannon entropy to assess true randomness, pattern detection for keyboard walks and sequences, and character-level TF-IDF n-grams to identify frequently reused substrings from breached password datasets. our RF model achieved superior performance, achieving 99.12% accuracy on a held-out test set. Crucially, the interpretability of the Random Forest model allows for feature importance analysis, providing a clear pathway to developing security tools that offer specific, actionable feedback to users. This study bridges the gap between predictive accuracy and practical usability, resulting in a high-performance scoring system that not only reduces password-based vulnerabilities but also empowers users to make more informed security decisions.", 'abstract_zh': '密码安全性在网络安全中起着至关重要的作用，然而依赖于字符类型要求等静态规则的传统密码强度测量方法往往效果不佳。这些方法容易被常见的密码模式（如“P@ssw0rd1!”）绕过，给用户造成虚假的安全感。为解决这一问题，我们通过将超过660,000个真实密码的大规模数据集与四种机器学习模型（随机森林、支持向量机、卷积神经网络和逻辑回归）进行对比，实现并评估了一种密码强度评分系统。我们的主要贡献是一种新颖的混合特征工程方法，能够捕捉标准度量忽视的细微漏洞。我们引入了诸如Leetspeak归一化香农熵来评估真正的随机性、键盘行走和序列的模式检测，以及基于字符级TF-IDF n-克隆来识别泄露密码数据集中频繁 reuse 的子字符串特征。我们的随机森林模型表现 superior， achieved 99.12% 的准确率。至关重要的是，随机森林模型的可解释性使得可以进行特征重要性分析，为用户提供具体的、可行的安全反馈提供明确的途径。这项研究弥补了预测准确性和实际可用性之间的差距，从而生成了一个高性能的评分系统，不仅能减少基于密码的漏洞，还能让用户做出更加明智的安全决策。', 'title_zh': '利用随机森林构建高精度评分框架以增强密码安全'}
{'arxiv_id': 'arXiv:2511.09486', 'title': 'A general framework for adaptive nonparametric dimensionality reduction', 'authors': 'Antonio Di Noia, Federico Ravenda, Antonietta Mira', 'link': 'https://arxiv.org/abs/2511.09486', 'abstract': 'Dimensionality reduction is a fundamental task in modern data science. Several projection methods specifically tailored to take into account the non-linearity of the data via local embeddings have been proposed. Such methods are often based on local neighbourhood structures and require tuning the number of neighbours that define this local structure, and the dimensionality of the lower-dimensional space onto which the data are projected. Such choices critically influence the quality of the resulting embedding. In this paper, we exploit a recently proposed intrinsic dimension estimator which also returns the optimal locally adaptive neighbourhood sizes according to some desirable criteria. In principle, this adaptive framework can be employed to perform an optimal hyper-parameter tuning of any dimensionality reduction algorithm that relies on local neighbourhood structures. Numerical experiments on both real-world and simulated datasets show that the proposed method can be used to significantly improve well-known projection methods when employed for various learning tasks, with improvements measurable through both quantitative metrics and the quality of low-dimensional visualizations.', 'abstract_zh': '局部自适应维数递减：一种基于内在维数估计的方法', 'title_zh': '自适应非参数降维的通用框架'}
{'arxiv_id': 'arXiv:2511.09478', 'title': 'AdaCuRL: Adaptive Curriculum Reinforcement Learning with Invalid Sample Mitigation and Historical Revisiting', 'authors': 'Renda Li, Hailang Huang, Fei Wei, Feng Xiong, Yong Wang, Xiangxiang Chu', 'link': 'https://arxiv.org/abs/2511.09478', 'abstract': 'Reinforcement learning (RL) has demonstrated considerable potential for enhancing reasoning in large language models (LLMs). However, existing methods suffer from Gradient Starvation and Policy Degradation when training directly on samples with mixed difficulty. To mitigate this, prior approaches leverage Chain-of-Thought (CoT) data, but the construction of high-quality CoT annotations remains labor-intensive. Alternatively, curriculum learning strategies have been explored but frequently encounter challenges, such as difficulty mismatch, reliance on manual curriculum design, and catastrophic forgetting. To address these issues, we propose AdaCuRL, a Adaptive Curriculum Reinforcement Learning framework that integrates coarse-to-fine difficulty estimation with adaptive curriculum scheduling. This approach dynamically aligns data difficulty with model capability and incorporates a data revisitation mechanism to mitigate catastrophic forgetting. Furthermore, AdaCuRL employs adaptive reference and sparse KL strategies to prevent Policy Degradation. Extensive experiments across diverse reasoning benchmarks demonstrate that AdaCuRL consistently achieves significant performance improvements on both LLMs and MLLMs.', 'abstract_zh': '自适应 Curriculum 辅助强化学习（AdaCuRL）：一种细粒度难度估计算法及其在大型语言模型中的应用', 'title_zh': '自适应课程强化学习：无效样本缓解与历史重访'}
{'arxiv_id': 'arXiv:2511.09454', 'title': 'Algorithmic Advice as a Strategic Signal on Competitive Markets', 'authors': 'Tobias R. Rebholz, Maxwell Uphoff, Christian H. R. Bernges, Florian Scholten', 'link': 'https://arxiv.org/abs/2511.09454', 'abstract': "As algorithms increasingly mediate competitive decision-making, their influence extends beyond individual outcomes to shaping strategic market dynamics. In two preregistered experiments, we examined how algorithmic advice affects human behavior in classic economic games with unique, non-collusive, and analytically traceable equilibria. In Experiment 1 (N = 107), participants played a Bertrand price competition with individualized or collective algorithmic recommendations. Initially, collusively upward-biased advice increased prices, particularly when individualized, but prices gradually converged toward equilibrium over the course of the experiment. However, participants avoided setting prices above the algorithm's recommendation throughout the experiment, suggesting that advice served as a soft upper bound for acceptable prices. In Experiment 2 (N = 129), participants played a Cournot quantity competition with equilibrium-aligned or strategically biased algorithmic recommendations. Here, individualized equilibrium advice supported stable convergence, whereas collusively downward-biased advice led to sustained underproduction and supracompetitive profits - hallmarks of tacit collusion. In both experiments, participants responded more strongly and consistently to individualized advice than collective advice, potentially due to greater perceived ownership of the former. These findings demonstrate that algorithmic advice can function as a strategic signal, shaping coordination even without explicit communication. The results echo real-world concerns about algorithmic collusion and underscore the need for careful design and oversight of algorithmic decision-support systems in competitive environments.", 'abstract_zh': '随着算法在竞争决策中越来越起主导作用，其影响超越了个体结果，进而塑造了战略市场动态。在两项预先注册的实验中，我们研究了算法建议如何影响人类在具有独特、非串谋且可分析均衡的经典经济博弈中的行为。在实验1（N = 107）中，参与者在个体化或集体算法建议下进行了伯特兰价格竞争。最初，存在串谋倾向的建议提高了价格，尤其是在个体化的情况下，但价格在整个实验过程中逐渐趋向均衡。然而，参与者在整个实验过程中都避免将价格设定在算法建议之上，这表明建议充当了可接受价格的软上限。在实验2（N = 129）中，参与者在接受均衡对齐或策略性偏差的算法建议下进行了古诺数量竞争。在这里，个体化均衡建议支持了稳定的收敛，而串谋倾向的下调建议导致了持续的低产出和超竞争利润——这是隐性串谋的特征。在两个实验中，参与者对个体化建议的反应比集体建议更为强烈且一致，可能是因为前者更具有感知上的归属感。这些发现表明，算法建议可以作为战略信号，影响协调而无需明确沟通。结果反映了关于算法共谋的现实世界担忧，并强调了在竞争环境中设计和监管算法决策支持系统的重要性。', 'title_zh': '算法建议作为竞争力市场中的战略信号'}
{'arxiv_id': 'arXiv:2511.09450', 'title': 'How does the Performance of the Data-driven Traffic Flow Forecasting Models deteriorate with Increasing Forecasting Horizon? An Extensive Approach Considering Statistical, Machine Learning and Deep Learning Models', 'authors': 'Amanta Sherfenaz, Nazmul Haque, Protiva Sadhukhan Prova, Md Asif Raihan, Md. Hadiuzzaman', 'link': 'https://arxiv.org/abs/2511.09450', 'abstract': "With rapid urbanization in recent decades, traffic congestion has intensified due to increased movement of people and goods. As planning shifts from demand-based to supply-oriented strategies, Intelligent Transportation Systems (ITS) have become essential for managing traffic within existing infrastructure. A core ITS function is traffic forecasting, enabling proactive measures like ramp metering, signal control, and dynamic routing through platforms such as Google Maps. This study assesses the performance of statistical, machine learning (ML), and deep learning (DL) models in forecasting traffic speed and flow using real-world data from California's Harbor Freeway, sourced from the Caltrans Performance Measurement System (PeMS). Each model was evaluated over 20 forecasting windows (up to 1 hour 40 minutes) using RMSE, MAE, and R-Square metrics. Results show ANFIS-GP performs best at early windows with RMSE of 0.038, MAE of 0.0276, and R-Square of 0.9983, while Bi-LSTM is more robust for medium-term prediction due to its capacity to model long-range temporal dependencies, achieving RMSE of 0.1863, MAE of 0.0833, and R-Square of 0.987 at a forecasting of 20. The degradation in model performance was quantified using logarithmic transformation, with slope values used to measure robustness. Among DL models, Bi-LSTM had the flattest slope (0.0454 RMSE, 0.0545 MAE for flow), whereas ANFIS-GP had 0.1058 for RMSE and 0.1037 for flow MAE. The study concludes by identifying hybrid models as a promising future direction.", 'abstract_zh': '近年来快速的城市化进程加剧了交通拥堵。随着规划策略从需求导向转向供给导向，智能交通系统（ITS）已成为在现有基础设施内管理交通的重要工具。ITS的核心功能之一是交通预测，通过谷歌地图等平台实现诸如匝道控制、信号控制和动态路线规划等主动措施。本研究利用加利福尼亚州港湾高速公路的真实数据，评估统计模型、机器学习（ML）模型和深度学习（DL）模型在交通速度和流量预测中的表现，数据来源于加州交通部性能测量系统（PeMS）。每种模型在20个不同的预测窗口（最长1小时40分钟）上进行了评估，使用均方根误差（RMSE）、平均绝对误差（MAE）和决定系数（R-Square）作为评估指标。结果表明，ANFIS-GP在早期窗口表现最佳，其RMSE为0.038，MAE为0.0276，R-Square为0.9983；而Bi-LSTM在中短期预测中更为稳健，通过建模长期时间依赖关系，其在20分钟内的预测中RMSE为0.1863，MAE为0.0833，R-Square为0.987。通过对模型性能下降进行对数变换，使用斜率衡量稳健性，DL模型中Bi-LSTM表现最稳定，对于流量的RMSE斜率为0.0545，MAE斜率为0.0545；ANFIS-GP对于流量的RMSE斜率为0.1058，MAE斜率为0.1037。研究结论提出，混合模型是未来研究的一个有希望的方向。', 'title_zh': '数据驱动的交通流量预测模型随预测期延长性能下降的原因探究：统计、机器学习和深度学习模型的全面分析'}
{'arxiv_id': 'arXiv:2511.09443', 'title': 'BronchOpt : Vision-Based Pose Optimization with Fine-Tuned Foundation Models for Accurate Bronchoscopy Navigation', 'authors': 'Hongchao Shu, Roger D. Soberanis-Mukul, Jiru Xu, Hao Ding, Morgan Ringel, Mali Shen, Saif Iftekar Sayed, Hedyeh Rafii-Tari, Mathias Unberath', 'link': 'https://arxiv.org/abs/2511.09443', 'abstract': 'Accurate intra-operative localization of the bronchoscope tip relative to patient anatomy remains challenging due to respiratory motion, anatomical variability, and CT-to-body divergence that cause deformation and misalignment between intra-operative views and pre-operative CT. Existing vision-based methods often fail to generalize across domains and patients, leading to residual alignment errors. This work establishes a generalizable foundation for bronchoscopy navigation through a robust vision-based framework and a new synthetic benchmark dataset that enables standardized and reproducible evaluation. We propose a vision-based pose optimization framework for frame-wise 2D-3D registration between intra-operative endoscopic views and pre-operative CT anatomy. A fine-tuned modality- and domain-invariant encoder enables direct similarity computation between real endoscopic RGB frames and CT-rendered depth maps, while a differentiable rendering module iteratively refines camera poses through depth consistency. To enhance reproducibility, we introduce the first public synthetic benchmark dataset for bronchoscopy navigation, addressing the lack of paired CT-endoscopy data. Trained exclusively on synthetic data distinct from the benchmark, our model achieves an average translational error of 2.65 mm and a rotational error of 0.19 rad, demonstrating accurate and stable localization. Qualitative results on real patient data further confirm strong cross-domain generalization, achieving consistent frame-wise 2D-3D alignment without domain-specific adaptation. Overall, the proposed framework achieves robust, domain-invariant localization through iterative vision-based optimization, while the new benchmark provides a foundation for standardized progress in vision-based bronchoscopy navigation.', 'abstract_zh': '基于视觉的内镜引导框架在支气管镜导航中的应用：一个稳健的基准数据集和优化方法', 'title_zh': 'BronchOpt：基于视觉的Fine-Tuned基础模型驱动的姿态优化及准确支气管镜导航'}
{'arxiv_id': 'arXiv:2511.09438', 'title': 'LLM-Guided Dynamic-UMAP for Personalized Federated Graph Learning', 'authors': 'Sai Puppala, Ismail Hossain, Md Jahangir Alam, Tanzim Ahad, Sajedul Talukder', 'link': 'https://arxiv.org/abs/2511.09438', 'abstract': 'We propose a method that uses large language models to assist graph machine learning under personalization and privacy constraints. The approach combines data augmentation for sparse graphs, prompt and instruction tuning to adapt foundation models to graph tasks, and in-context learning to supply few-shot graph reasoning signals. These signals parameterize a Dynamic UMAP manifold of client-specific graph embeddings inside a Bayesian variational objective for personalized federated learning. The method supports node classification and link prediction in low-resource settings and aligns language model latent representations with graph structure via a cross-modal regularizer. We outline a convergence argument for the variational aggregation procedure, describe a differential privacy threat model based on a moments accountant, and present applications to knowledge graph completion, recommendation-style link prediction, and citation and product graphs. We also discuss evaluation considerations for benchmarking LLM-assisted graph machine learning.', 'abstract_zh': '我们提出了一种方法，利用大型语言模型在个性化和隐私约束下辅助图机器学习。该方法结合了稀疏图的数据扩充、提示和指令调优以使基础模型适应图任务、以及上下文学习以提供少量图推理信号。这些信号参数化了一个客户特定图嵌入的动态UMAP流形，并置于贝叶斯变分目标中，用于个性化联邦学习。该方法支持低资源环境下的节点分类和链接预测，并通过跨模态正则化器将语言模型的潜在表示与图结构对齐。我们给出了变分聚合过程收敛性的论证，描述了基于矩核算员的差分隐私威胁模型，并展示了在知识图谱完成、推荐风格的链接预测以及引用和产品图方面的应用。我们还讨论了评估LLM辅助图机器学习基准的考量因素。', 'title_zh': 'LLM引导的动态-UMAP在个性化联邦图学习中的应用'}
{'arxiv_id': 'arXiv:2511.09404', 'title': 'Spatio-Temporal Graph Unlearning', 'authors': 'Qiming Guo, Wenbo Sun, Wenlu Wang', 'link': 'https://arxiv.org/abs/2511.09404', 'abstract': "Spatio-temporal graphs are widely used in modeling complex dynamic processes such as traffic forecasting, molecular dynamics, and healthcare monitoring. Recently, stringent privacy regulations such as GDPR and CCPA have introduced significant new challenges for existing spatio-temporal graph models, requiring complete unlearning of unauthorized data. Since each node in a spatio-temporal graph diffuses information globally across both spatial and temporal dimensions, existing unlearning methods primarily designed for static graphs and localized data removal cannot efficiently erase a single node without incurring costs nearly equivalent to full model retraining. Therefore, an effective approach for complete spatio-temporal graph unlearning is a pressing need. To address this, we propose CallosumNet, a divide-and-conquer spatio-temporal graph unlearning framework inspired by the corpus callosum structure that facilitates communication between the brain's two hemispheres. CallosumNet incorporates two novel techniques: (1) Enhanced Subgraph Construction (ESC), which adaptively constructs multiple localized subgraphs based on several factors, including biologically-inspired virtual ganglions; and (2) Global Ganglion Bridging (GGB), which reconstructs global spatio-temporal dependencies from these localized subgraphs, effectively restoring the full graph representation. Empirical results on four diverse real-world datasets show that CallosumNet achieves complete unlearning with only 1%-2% relative MAE loss compared to the gold model, significantly outperforming state-of-the-art baselines. Ablation studies verify the effectiveness of both proposed techniques.", 'abstract_zh': '时空图在交通预测、分子动力学和医疗监控等复杂动态过程建模中的广泛应用面临严峻的隐私法规挑战，如GDPR和CCPA，要求完全遗忘未经授权的数据。由于时空图中的每个节点在全球的空间和时间维度上扩散信息，现有的针对静态图和局部数据删除的遗忘方法难以在不几乎等于全模型重新训练成本的情况下高效地擦除单个节点。因此，一种有效的时空图完全遗忘方法迫在眉睫。为了解决这一问题，我们提出了CallosumNet，这是一种受大脑两个半球间胼胝体结构启发的分而治之的时空图遗忘框架。CallosumNet包含两种新颖的技术：（1）增强子图构建（ESC），基于多个因素自适应构建多个局部子图，包括生物启发的虚拟神经节；（2）全局神经节桥接（GGB），从这些局部子图重建全局时空依赖性，有效恢复完整的图表示。在四个不同领域的真实数据集上的实验结果表明，CallosumNet相比黄金模型仅在相对MAE损失上增加1%-2%，显著优于现有最先进的基线方法。消融研究验证了所提出技术的有效性。', 'title_zh': '时空图遗忘'}
{'arxiv_id': 'arXiv:2511.09396', 'title': 'Multimodal Large Language Models for Low-Resource Languages: A Case Study for Basque', 'authors': 'Lukas Arana, Julen Etxaniz, Ander Salaberria, Gorka Azkune', 'link': 'https://arxiv.org/abs/2511.09396', 'abstract': 'Current Multimodal Large Language Models exhibit very strong performance for several demanding tasks. While commercial MLLMs deliver acceptable performance in low-resource languages, comparable results remain unattained within the open science community. In this paper, we aim to develop a strong MLLM for a low-resource language, namely Basque. For that purpose, we develop our own training and evaluation image-text datasets. Using two different Large Language Models as backbones, the Llama-3.1-Instruct model and a Basque-adapted variant called Latxa, we explore several data mixtures for training. We show that: i) low ratios of Basque multimodal data (around 20%) are already enough to obtain solid results on Basque benchmarks, and ii) contrary to expected, a Basque instructed backbone LLM is not required to obtain a strong MLLM in Basque. Our results pave the way to develop MLLMs for other low-resource languages by openly releasing our resources.', 'abstract_zh': '当前的多模态大型语言模型在多个挑战性任务中表现出很强的性能。尽管商业化的多模态大语言模型在低资源语言中表现出可接受的性能，但在开放科学社区中仍未能取得可比的结果。本文旨在为一种低资源语言——巴斯克语，开发一种强大的多模态大语言模型。为此，我们开发了自己的训练和评估图像-文本数据集。使用两种不同的大型语言模型作为骨干模型，即Llama-3.1-Instruct模型和巴斯克语适应变体Latxa，我们探索了多种数据混合训练方法。我们展示了以下两点：i) 大约20%的巴斯克多模态数据已经足够在巴斯克语基准测试中取得良好的结果；ii) 出人意料的是，一个经过巴斯克语指令调整的骨干模型并非必要条件，以获得强大的巴斯克语多模态语言模型。我们的研究为开发其他低资源语言的多模态大语言模型铺平了道路，并通过公开发布我们的资源的方式打开了这一途径。', 'title_zh': '多模态大型语言模型在低资源语言中的应用：关于巴斯克语的案例研究'}
{'arxiv_id': 'arXiv:2511.09392', 'title': 'Potent but Stealthy: Rethink Profile Pollution against Sequential Recommendation via Bi-level Constrained Reinforcement Paradigm', 'authors': 'Jiajie Su, Zihan Nan, Yunshan Ma, Xiaobo Xia, Xiaohua Feng, Weiming Liu, Xiaolin Zheng, Chaochao Chen', 'link': 'https://arxiv.org/abs/2511.09392', 'abstract': 'Sequential Recommenders, which exploit dynamic user intents through interaction sequences, is vulnerable to adversarial attacks. While existing attacks primarily rely on data poisoning, they require large-scale user access or fake profiles thus lacking practicality. In this paper, we focus on the Profile Pollution Attack that subtly contaminates partial user interactions to induce targeted mispredictions. Previous PPA methods suffer from two limitations, i.e., i) over-reliance on sequence horizon impact restricts fine-grained perturbations on item transitions, and ii) holistic modifications cause detectable distribution shifts. To address these challenges, we propose a constrained reinforcement driven attack CREAT that synergizes a bi-level optimization framework with multi-reward reinforcement learning to balance adversarial efficacy and stealthiness. We first develop a Pattern Balanced Rewarding Policy, which integrates pattern inversion rewards to invert critical patterns and distribution consistency rewards to minimize detectable shifts via unbalanced co-optimal transport. Then we employ a Constrained Group Relative Reinforcement Learning paradigm, enabling step-wise perturbations through dynamic barrier constraints and group-shared experience replay, achieving targeted pollution with minimal detectability. Extensive experiments demonstrate the effectiveness of CREAT.', 'abstract_zh': '基于交互序列的推荐系统易受配置文件污染攻击，该攻击通过微妙污染部分用户交互以诱导目标性预测错误。 previous PPA方法存在两个局限性，即i) 过度依赖序列窗口影响限制了对项目转换的细粒度扰动，ii) 全局修改导致可检测的分布偏移。为解决这些挑战，我们提出了一种受限强化驱动攻击 CREAT，其结合了多级优化框架与多奖励强化学习，以平衡对抗效果和隐蔽性。我们首先开发了一种模式平衡奖励策略，将模式反转奖励和分布一致性奖励相结合，以通过不平衡的共最优传输最小化可检测的偏移。然后我们采用受限分组相对强化学习范式，通过动态边界约束和分组共享经验重放实现逐步扰动，实现最小可检测性的目标污染。广泛实验验证了CREAT的有效性。', 'title_zh': '潜在但隐秘：通过双层约束强化范式重新思考针对序贯推荐的配置污染'}
{'arxiv_id': 'arXiv:2511.09381', 'title': 'Self-Correcting Large Language Models: Generation vs. Multiple Choice', 'authors': 'Hossein A. Rahmani, Satyapriya Krishna, Xi Wang, Mohammadmehdi Naghiaei, Emine Yilmaz', 'link': 'https://arxiv.org/abs/2511.09381', 'abstract': 'Large language models have recently demonstrated remarkable abilities to self-correct their responses through iterative refinement, often referred to as self-consistency or self-reflection. However, the dynamics of this self-correction mechanism may differ substantially depending on whether the model is tasked with open-ended text generation or with selecting the most appropriate response from multiple predefined options. In this paper, we conduct a systematic investigation of these two paradigms by comparing performance trends and error-correction behaviors across various natural language understanding and reasoning tasks, covering language models of different scales and families. Our experimental results reveal distinct patterns of improvement and failure modes:\n\\textit{While open-ended generation often benefits from the flexibility of re-interpretation and compositional refinement, multiple-choice selection can leverage clearer solution boundaries but may be limited by the provided options}. This contrast also reflects the dual demands faced by emerging agentic LLM applications: effective agents must not only generate and refine open-ended plans or explanations, but also make reliable discrete choices when operating within constrained action spaces. Our findings, therefore, highlight that the design of self-correction mechanisms should take into account the interaction between task structure and output space, with implications for both knowledge-intensive reasoning and decision-oriented applications of LLMs.', 'abstract_zh': '大型语言模型最近展现了通过迭代精炼来自我修正其响应的能力，这通常被称为自我一致性或自我反思。然而，这种自我修正机制的动力学可能会因为模型是用于开放生成文本还是从多个预定义选项中选择最合适的响应而有很大差异。在本文中，我们通过比较不同自然语言理解和推理任务上的性能趋势和错误修正行为，系统性地研究了这两种范式，涵盖了不同规模和家族的语言模型。我们的实验结果揭示了不同的改进模式和失败模式：开放生成往往得益于重新解释和组合精炼的灵活性，而多项选择则可以利用清晰的解决方案边界，但也可能受限于提供的选项。这种对比也反映了新兴代理型LLM应用的双重需求：有效的代理不仅需要生成和精炼开放的计划或解释，还需要在受限制的动作空间内做出可靠的选择。因此，我们的研究结果强调，在设计自我修正机制时应考虑任务结构与输出空间之间的交互，这一观点对知识密集型推理和决策导向型LLM应用都有重要意义。', 'title_zh': '自我修正大型语言模型：生成 vs. 多选'}
{'arxiv_id': 'arXiv:2511.09374', 'title': 'MTQ-Eval: Multilingual Text Quality Evaluation for Language Models', 'authors': 'Rhitabrat Pokharel, Ameeta Agrawal', 'link': 'https://arxiv.org/abs/2511.09374', 'abstract': 'The use of large language models (LLMs) for evaluating outputs is becoming an increasingly effective and scalable approach. However, it remains uncertain whether this capability extends beyond task-specific evaluations to more general assessments of text quality, particularly in multilingual contexts. In this study, we introduce, MTQ-Eval, a novel framework for multilingual text quality evaluation that learns from examples of both high- and low-quality texts, adjusting its internal representations. To develop MTQ-Eval, we first automatically generate text quality preference data and then use it to train open-source base LLMs to align with ratings of high- and low-quality text. Our comprehensive evaluation across 115 languages demonstrates the improved performance of the proposed model. Upon further analysis, we find that this enhanced evaluation capability also leads to notable improvements in downstream tasks.', 'abstract_zh': '大型语言模型（LLMs）在评价输出方面日益成为一种有效且可扩展的方法。然而，这种能力能否超越特定任务的评估，扩展到更广泛的文本质量评估，特别是在多语言环境中，仍不确定。本研究介绍了MTQ-Eval，一种新颖的多语言文本质量评估框架，该框架通过学习高质量和低质量文本的示例来调整其内部表示。为了开发MTQ-Eval，我们首先自动生成文本质量偏好数据，然后使用该数据训练开源基础LLM以与高质量和低质量文本的评分对齐。我们在115种语言上的全面评估表明，所提出模型的性能得到了提升。进一步分析发现，这种增强的评估能力还导致了下游任务的显著改进。', 'title_zh': '多语言文本质量评估：MTQ-Eval 为语言模型'}
{'arxiv_id': 'arXiv:2511.09332', 'title': 'Distribution-Based Feature Attribution for Explaining the Predictions of Any Classifier', 'authors': 'Xinpeng Li, Kai Ming Ting', 'link': 'https://arxiv.org/abs/2511.09332', 'abstract': 'The proliferation of complex, black-box AI models has intensified the need for techniques that can explain their decisions. Feature attribution methods have become a popular solution for providing post-hoc explanations, yet the field has historically lacked a formal problem definition. This paper addresses this gap by introducing a formal definition for the problem of feature attribution, which stipulates that explanations be supported by an underlying probability distribution represented by the given dataset. Our analysis reveals that many existing model-agnostic methods fail to meet this criterion, while even those that do often possess other limitations. To overcome these challenges, we propose Distributional Feature Attribution eXplanations (DFAX), a novel, model-agnostic method for feature attribution. DFAX is the first feature attribution method to explain classifier predictions directly based on the data distribution. We show through extensive experiments that DFAX is more effective and efficient than state-of-the-art baselines.', 'abstract_zh': '复杂、黑盒AI模型的 proliferations 加剧了对其决策进行解释的技术需求。特征归因方法已成为提供事后解释的流行解决方案，但该领域历史上缺乏正式问题定义。本文通过引入特征归因问题的正式定义来填补这一空白，该定义要求解释基于给定数据集代表的概率分布得以支持。我们的分析表明，许多现有的模型无关方法未能满足这一标准，而即使是满足这一标准的方法也往往存在其他局限性。为克服这些挑战，我们提出了分布归因解释（DFAX），这是一种全新的、模型无关的特征归因方法。DFAX是第一个直接基于数据分布解释分类器预测的特征归因方法。通过大量实验，我们证明了DFAX比最先进的基线方法更有效率。', 'title_zh': '基于分布的特征归因：解释任何分类器的预测'}
{'arxiv_id': 'arXiv:2511.09309', 'title': 'TaskSense: Cognitive Chain Modeling and Difficulty Estimation for GUI Tasks', 'authors': 'Yiwen Yin, Zhian Hu, Xiaoxi Xu, Chun Yu, Xintong Wu, Wenyu Fan, Yuanchun Shi', 'link': 'https://arxiv.org/abs/2511.09309', 'abstract': 'Measuring GUI task difficulty is crucial for user behavior analysis and agent capability evaluation. Yet, existing benchmarks typically quantify difficulty based on motor actions (e.g., step counts), overlooking the cognitive demands underlying task completion. In this work, we propose Cognitive Chain, a novel framework that models task difficulty from a cognitive perspective. A cognitive chain decomposes the cognitive processes preceding a motor action into a sequence of cognitive steps (e.g., finding, deciding, computing), each with a difficulty index grounded in information theories. We develop an LLM-based method to automatically extract cognitive chains from task execution traces. Validation with linear regression shows that our estimated cognitive difficulty correlates well with user completion time (step-level R-square=0.46 after annotation). Assessment of state-of-the-art GUI agents shows reduced success on cognitively demanding tasks, revealing capability gaps and Human-AI consistency patterns. We conclude by discussing potential applications in agent training, capability assessment, and human-agent delegation optimization.', 'abstract_zh': '基于认知视角衡量GUI任务难度对于用户行为分析和代理能力评估至关重要。现有基准通常基于运动动作（如步数）来量化难度，忽略了任务完成的认知需求。在这项工作中，我们提出了一种名为Cognitive Chain的新型框架，从认知视角建模任务难度。一个认知链将先于运动动作的认知过程分解为一系列认知步骤（例如，寻找、决定、计算），每个步骤的难度指数基于信息理论。我们开发了一种基于LLM的方法，自动从任务执行轨迹中提取认知链。通过线性回归验证表明，我们的认知难度估计值与用户完成时间高度相关（注释后步骤级R平方值为0.46）。对最先进的GUI代理的评估显示，在认知需求较高的任务中成功率下降，揭示了能力差距和人机一致性模式。最后，我们讨论了该方法在代理训练、能力评估和人机代理委托优化中的潜在应用。', 'title_zh': 'TaskSense: 基于认知链建模与GUI任务难度估计'}
{'arxiv_id': 'arXiv:2511.09298', 'title': 'DensiCrafter: Physically-Constrained Generation and Fabrication of Self-Supporting Hollow Structures', 'authors': 'Shengqi Dang, Fu Chai, Jiaxin Li, Chao Yuan, Wei Ye, Nan Cao', 'link': 'https://arxiv.org/abs/2511.09298', 'abstract': 'The rise of 3D generative models has enabled automatic 3D geometry and texture synthesis from multimodal inputs (e.g., text or images). However, these methods often ignore physical constraints and manufacturability considerations. In this work, we address the challenge of producing 3D designs that are both lightweight and self-supporting. We present DensiCrafter, a framework for generating lightweight, self-supporting 3D hollow structures by optimizing the density field. Starting from coarse voxel grids produced by Trellis, we interpret these as continuous density fields to optimize and introduce three differentiable, physically constrained, and simulation-free loss terms. Additionally, a mass regularization penalizes unnecessary material, while a restricted optimization domain preserves the outer surface. Our method seamlessly integrates with pretrained Trellis-based models (e.g., Trellis, DSO) without any architectural changes. In extensive evaluations, we achieve up to 43% reduction in material mass on the text-to-3D task. Compared to state-of-the-art baselines, our method could improve the stability and maintain high geometric fidelity. Real-world 3D-printing experiments confirm that our hollow designs can be reliably fabricated and could be self-supporting.', 'abstract_zh': '3D生成模型的兴起使得从多模态输入（例如文本或图像）中自动合成3D几何和纹理成为可能。然而，这些方法Often忽略了物理约束和可制造性考虑。在本文中，我们解决了生成既轻量化又自支撑的3D设计的挑战。我们提出了DensiCrafter框架，通过优化密度场生成轻量化、自支撑的3D空心结构。从Trellis生成的粗糙体素网格入手，我们将这些网格解释为连续的密度场进行优化，并引入了三种可微分的、受物理约束的且无需模拟的损失项。此外，质量正则化惩罚不必要的材料，而限制的优化域则保持外部表面。我们的方法无需任何架构更改即可无缝集成到预训练的Trellis基模型（例如Trellis、DSO）中。在广泛的评估中，我们能够在文本到3D任务中实现最高43%的材料质量减少。与最先进的基线方法相比，我们的方法能够提高稳定性并保持高几何保真度。现实世界的3D打印实验验证了我们的空心设计可以可靠地制造并能够自支撑。', 'title_zh': 'DensiCrafter: 物理约束下的自支撑空心结构生成与制造'}
{'arxiv_id': 'arXiv:2511.09294', 'title': 'GuardFed: A Trustworthy Federated Learning Framework Against Dual-Facet Attacks', 'authors': 'Yanli Li, Yanan Zhou, Zhongliang Guo, Nan Yang, Yuning Zhang, Huaming Chen, Dong Yuan, Weiping Ding, Witold Pedrycz', 'link': 'https://arxiv.org/abs/2511.09294', 'abstract': 'Federated learning (FL) enables privacy-preserving collaborative model training but remains vulnerable to adversarial behaviors that compromise model utility or fairness across sensitive groups. While extensive studies have examined attacks targeting either objective, strategies that simultaneously degrade both utility and fairness remain largely unexplored. To bridge this gap, we introduce the Dual-Facet Attack (DFA), a novel threat model that concurrently undermines predictive accuracy and group fairness. Two variants, Synchronous DFA (S-DFA) and Split DFA (Sp-DFA), are further proposed to capture distinct real-world collusion scenarios. Experimental results show that existing robust FL defenses, including hybrid aggregation schemes, fail to resist DFAs effectively. To counter these threats, we propose GuardFed, a self-adaptive defense framework that maintains a fairness-aware reference model using a small amount of clean server data augmented with synthetic samples. In each training round, GuardFed computes a dual-perspective trust score for every client by jointly evaluating its utility deviation and fairness degradation, thereby enabling selective aggregation of trustworthy updates. Extensive experiments on real-world datasets demonstrate that GuardFed consistently preserves both accuracy and fairness under diverse non-IID and adversarial conditions, achieving state-of-the-art performance compared with existing robust FL methods.', 'abstract_zh': '联邦学习（FL）实现了隐私保护下的协作模型训练，但仍然容易受到损害模型实用性和公平性的 adversarial 行为的攻击。尽管已有大量研究针对单一目标展开了攻击研究，同时损害实用性和公平性的策略仍然鲜有探讨。为填补这一空白，我们引入了双面攻击（Dual-Facet Attack, DFA）这一新的威胁模型，以同时削弱预测准确性和群体公平性。进一步提出了同步双面攻击（Synchronous DFA, S-DFA）和分裂双面攻击（Split DFA, Sp-DFA）两种变体，以捕捉不同的现实世界协作场景。实验结果表明，现有的稳健联邦学习（FL）防御措施，包括混合聚合方案，无法有效抵御 DFA 攻击。为应对这些威胁，我们提出了一种自适应防御框架 GuardFed，该框架利用少量干净的服务器数据与合成样本相结合，维护一个公平意识的参考模型。在每一次训练周期中，GuardFed 通过联合评估每个客户端的实用性和公平性下降来计算双重视角的信任分数，从而实现可信赖更新的有选择性聚合。在真实世界数据集上的广泛实验表明，GuardFed 在各种非IID 和对抗条件下均能一致地保持准确性和公平性，其性能优于现有的稳健联邦学习方法。', 'title_zh': 'GuardFed: 一种对抗双面攻击的可信赖联邦学习框架'}
{'arxiv_id': 'arXiv:2511.09292', 'title': 'C$^3$TG: Conflict-aware, Composite, and Collaborative Controlled Text Generation', 'authors': 'Yu Li, Zhe Yang, Yi Huang, Xin Liu, Guilin Qi', 'link': 'https://arxiv.org/abs/2511.09292', 'abstract': 'Recent advancements in large language models (LLMs) have demonstrated remarkable text generation capabilities. However, controlling specific attributes of generated text remains challenging without architectural modifications or extensive fine-tuning. Current methods typically toggle a single, basic attribute but struggle with precise multi-attribute control. In scenarios where attribute requirements conflict, existing methods lack coordination mechanisms, causing interference between desired attributes. Furthermore, these methods fail to incorporate iterative optimization processes in the controlled generation pipeline. To address these limitations, we propose Conflict-aware, Composite, and Collaborative Controlled Text Generation (C$^3$TG), a two-phase framework for fine-grained, multi-dimensional text attribute control. During generation, C$^3$TG selectively pairs the LLM with the required attribute classifiers from the 17 available dimensions and employs weighted KL-divergence to adjust token probabilities. The optimization phase then leverages an energy function combining classifier scores and penalty terms to resolve attribute conflicts through iterative feedback, enabling precise control over multiple dimensions simultaneously while preserving natural text flow. Experiments show that C$^3$TG significantly outperforms baselines across multiple metrics including attribute accuracy, linguistic fluency, and output diversity, while simultaneously reducing toxicity. These results establish C$^3$TG as an effective and flexible solution for multi-dimensional text attribute control that requires no costly model modifications.', 'abstract_zh': 'Recent advancements in大型语言模型（LLMs）的 Recent advancements in 大型语言模型（LLMs）近期在大型语言模型方面取得了显著的文本生成能力。然而，在不进行架构修改或大量微调的情况下，控制生成文本的特定属性仍然颇具挑战性。当前的方法通常只能切换单一的基本属性，并难以实现精确的多属性控制。在属性需求发生冲突的场景下，现有方法缺乏协调机制，导致期望属性之间的相互干扰。此外，这些方法在受控生成过程中未能引入迭代优化流程。为解决这些局限，我们提出了具备冲突意识、复合性和协作性的受控文本生成（C$^3$TG），这是一种用于细粒度、多维度文本属性控制的两阶段框架。生成阶段，C$^3$TG 选择性地将LLM与所需的17个属性分类器配对，并利用加权KL散度调整token概率。优化阶段则利用结合分类器评分和惩罚项的能量函数通过迭代反馈解决属性冲突，从而同时在多个维度上实现精确控制，并保持自然的文本流。实验结果显示，C$^3$TG 在包括属性准确性、语义流畅性和输出多样性的多个指标上显著优于基线方法，同时降低了有毒内容的产生。这些结果证明了C$^3$TG 是一种有效且灵活的多维度文本属性控制解决方案，无需进行昂贵的模型修改。', 'title_zh': '冲突感知、复合与协作控制文本生成'}
{'arxiv_id': 'arXiv:2511.09252', 'title': 'Unveiling Hidden Threats: Using Fractal Triggers to Boost Stealthiness of Distributed Backdoor Attacks in Federated Learning', 'authors': 'Jian Wang, Hong Shen, Chan-Tong Lam', 'link': 'https://arxiv.org/abs/2511.09252', 'abstract': 'Traditional distributed backdoor attacks (DBA) in federated learning improve stealthiness by decomposing global triggers into sub-triggers, which however requires more poisoned data to maintian the attck strength and hence increases the exposure risk. To overcome this defect, This paper proposes a novel method, namely Fractal-Triggerred Distributed Backdoor Attack (FTDBA), which leverages the self-similarity of fractals to enhance the feature strength of sub-triggers and hence significantly reduce the required poisoning volume for the same attack strength. To address the detectability of fractal structures in the frequency and gradient domains, we introduce a dynamic angular perturbation mechanism that adaptively adjusts perturbation intensity across the training phases to balance efficiency and stealthiness. Experiments show that FTDBA achieves a 92.3\\% attack success rate with only 62.4\\% of the poisoning volume required by traditional DBA methods, while reducing the detection rate by 22.8\\% and KL divergence by 41.2\\%. This study presents a low-exposure, high-efficiency paradigm for federated backdoor attacks and expands the application of fractal features in adversarial sample generation.', 'abstract_zh': '分形触发分布式后门攻击：一种低暴露高效率的联邦后门攻击方法', 'title_zh': '揭示隐匿威胁：使用分形触发器提升分布式后门攻击在联邦学习中的隐蔽性'}
{'arxiv_id': 'arXiv:2511.09231', 'title': 'Leveraging Large Language Models for Use Case Model Generation from Software Requirements', 'authors': 'Tobias Eisenreich, Nicholas Friedlaender, Stefan Wagner', 'link': 'https://arxiv.org/abs/2511.09231', 'abstract': 'Use case modeling employs user-centered scenarios to outline system requirements. These help to achieve consensus among relevant stakeholders. Because the manual creation of use case models is demanding and time-consuming, it is often skipped in practice. This study explores the potential of Large Language Models (LLMs) to assist in this tedious process. The proposed method integrates an open-weight LLM to systematically extract actors and use cases from software requirements with advanced prompt engineering techniques. The method is evaluated using an exploratory study conducted with five professional software engineers, which compares traditional manual modeling to the proposed LLM-based approach. The results show a substantial acceleration, reducing the modeling time by 60\\%. At the same time, the model quality remains on par. Besides improving the modeling efficiency, the participants indicated that the method provided valuable guidance in the process.', 'abstract_zh': '大型语言模型在用例建模中的应用研究：一种基于开放权重模型和高级提示工程的技术方法', 'title_zh': '利用大型语言模型从软件需求生成用例模型'}
{'arxiv_id': 'arXiv:2511.09221', 'title': 'Learning Binary Autoencoder-Based Codes with Progressive Training', 'authors': 'Vukan Ninkovic, Dejan Vukobratovic', 'link': 'https://arxiv.org/abs/2511.09221', 'abstract': 'Error correcting codes play a central role in digital communication, ensuring that transmitted information can be accurately reconstructed despite channel impairments. Recently, autoencoder (AE) based approaches have gained attention for the end-to-end design of communication systems, offering a data driven alternative to conventional coding schemes. However, enforcing binary codewords within differentiable AE architectures remains difficult, as discretization breaks gradient flow and often leads to unstable convergence. To overcome this limitation, a simplified two stage training procedure is proposed, consisting of a continuous pretraining phase followed by direct binarization and fine tuning without gradient approximation techniques. For the (7,4) block configuration over a binary symmetric channel (BSC), the learned encoder-decoder pair learns a rotated version (coset code) of the optimal Hamming code, naturally recovering its linear and distance properties and thereby achieving the same block error rate (BLER) with maximum likelihood (ML) decoding. These results indicate that compact AE architectures can effectively learn structured, algebraically optimal binary codes through stable and straightforward training.', 'abstract_zh': '纠错码在数字通信中发挥着核心作用，确保 transmitted 信息在信道损伤的情况下能够被准确重建。最近，基于自动编码器（AE）的方法受到了关注，用于端到端设计通信系统，提供了一种基于数据驱动的替代传统编码方案的方法。然而，在不同的iable AE 架构中强制使用二进制码字仍然具有挑战性，因为离散化会破坏梯度流并经常导致不稳定收敛。为了克服这一限制，提出了一种简化的两阶段训练过程，包括一个连续的预训练阶段，随后是直接二进制化和 fine tuning，不使用梯度近似技术。对于二进制对称信道（BSC）上的（7,4）块配置，通过学习到的编码器-解码器配对学习到了最优汉明码的旋转版本（余子码），自然地恢复了其线性和距离性质，并从而通过最大似然（ML）解码达到了相同的块错误率（BLER）。这些结果表明，紧凑的 AE 架构可以通过稳定且直接的训练有效学习结构化的代数最优二进制码。', 'title_zh': '基于分阶训练的二进制自编码器编码学习'}
{'arxiv_id': 'arXiv:2511.09193', 'title': 'Enhancing PIBT via Multi-Action Operations', 'authors': 'Egor Yukhnevich, Anton Andreychuk', 'link': 'https://arxiv.org/abs/2511.09193', 'abstract': "PIBT is a rule-based Multi-Agent Path Finding (MAPF) solver, widely used as a low-level planner or action sampler in many state-of-the-art approaches. Its primary advantage lies in its exceptional speed, enabling action selection for thousands of agents within milliseconds by considering only the immediate next timestep. However, this short-horizon design leads to poor performance in scenarios where agents have orientation and must perform time-consuming rotation actions. In this work, we present an enhanced version of PIBT that addresses this limitation by incorporating multi-action operations. We detail the modifications introduced to improve PIBT's performance while preserving its hallmark efficiency. Furthermore, we demonstrate how our method, when combined with graph-guidance technique and large neighborhood search optimization, achieves state-of-the-art performance in the online LMAPF-T setting.", 'abstract_zh': 'PIBT是一种基于规则的多Agent路径规划（MAPF）求解器，广泛用作许多最先进的方法中的低级规划器或动作采样器。其主要优势在于其卓越的速度，能够在毫秒内为成千上万的Agent选择动作，仅考虑即时的下一时间切片。然而，这种短视的设计使其在Agent具有方向性且必须执行耗时的旋转动作的场景中表现较差。在本工作中，我们提出了一种增强版的PIBT，通过引入多动作操作来解决这一局限性。我们详细介绍了为提高PIBT性能而引入的改进措施，同时保持其标志性的高效性。此外，我们展示了我们的方法结合图引导技术和大规模邻域搜索优化后，在在线LMAPF-T设置中实现了最先进的性能。', 'title_zh': '通过多动作操作增强PIBT'}
{'arxiv_id': 'arXiv:2511.09179', 'title': 'A Hybrid Search for Complex Table Question Answering in Securities Report', 'authors': 'Daiki Shirafuji, Koji Tanaka, Tatsuhiko Saito', 'link': 'https://arxiv.org/abs/2511.09179', 'abstract': 'Recently, Large Language Models (LLMs) are gaining increased attention in the domain of Table Question Answering (TQA), particularly for extracting information from tables in documents. However, directly entering entire tables as long text into LLMs often leads to incorrect answers because most LLMs cannot inherently capture complex table structures. In this paper, we propose a cell extraction method for TQA without manual identification, even for complex table headers. Our approach estimates table headers by computing similarities between a given question and individual cells via a hybrid retrieval mechanism that integrates a language model and TF-IDF. We then select as the answer the cells at the intersection of the most relevant row and column. Furthermore, the language model is trained using contrastive learning on a small dataset of question-header pairs to enhance performance. We evaluated our approach in the TQA dataset from the U4 shared task at NTCIR-18. The experimental results show that our pipeline achieves an accuracy of 74.6\\%, outperforming existing LLMs such as GPT-4o mini~(63.9\\%). In the future, although we used traditional encoder models for retrieval in this study, we plan to incorporate more efficient text-search models to improve performance and narrow the gap with human evaluation results.', 'abstract_zh': '最近，大型语言模型（LLMs）在表格问答（TQA）领域引起了广泛关注，特别是在从文档中的表格中提取信息方面。然而，直接将整个表格作为长文本输入LLMs往往会因为大多数LLMs无法内在地捕捉复杂的表格结构而产生错误的答案。本文提出了一种无需人工识别的单元格提取方法，即使对于复杂的表头也是如此。我们的方法通过一种结合语言模型和TF-IDF的混合检索机制来计算给定问题与单个单元格之间的相似性，来估计表头，并选择最相关的行和列的交点处的单元格作为答案。此外，我们使用少量的问题-表头 pair 数据集进行对比学习来训练语言模型，以提高性能。我们在NTCIR-18年度报告U4共享任务的TQA数据集上评估了我们的方法，实验结果表明，我们的管道达到了74.6%的准确率，优于现有的LLMs如GPT-4o mini（63.9%）。未来，虽然本研究中使用了传统的编码器模型进行检索，但我们计划集成更高效的文本搜索模型以提高性能，并缩小与人类评估结果的差距。', 'title_zh': '复杂财务报告表格问题解答的混合搜索方法'}
{'arxiv_id': 'arXiv:2511.09174', 'title': 'Tractable Weighted First-Order Model Counting with Bounded Treewidth Binary Evidence', 'authors': 'Václav Kůla, Qipeng Kuang, Yuyi Wang, Yuanhong Wang, Ondřej Kuželka', 'link': 'https://arxiv.org/abs/2511.09174', 'abstract': 'The Weighted First-Order Model Counting Problem (WFOMC) asks to compute the weighted sum of models of a given first-order logic sentence over a given domain. Conditioning WFOMC on evidence -- fixing the truth values of a set of ground literals -- has been shown impossible in time polynomial in the domain size (unless $\\mathsf{\\#P \\subseteq FP}$) even for fragments of logic that are otherwise tractable for WFOMC without evidence. In this work, we address the barrier by restricting the binary evidence to the case where the underlying Gaifman graph has bounded treewidth. We present a polynomial-time algorithm in the domain size for computing WFOMC for the two-variable fragments $\\text{FO}^2$ and $\\text{C}^2$ conditioned on such binary evidence. Furthermore, we show the applicability of our algorithm in combinatorial problems by solving the stable seating arrangement problem on bounded-treewidth graphs of bounded degree, which was an open problem. We also conducted experiments to show the scalability of our algorithm compared to the existing model counting solvers.', 'abstract_zh': '加权一阶模型计数问题（WFOMC）要求计算给定一阶逻辑句子在给定领域中的加权模型和。基于证据对WFOMC进行条件化——固定一组基础文字的真值——即使是对逻辑片段进行条件化，否则在没有证据的情况下WFOMC是可处理的，也被证明在领域大小多项式时间内是不可能的（除非 \\#P ⊆ FP）。在本工作中，我们通过限制二元证据的底层Gaifman图的 treewidth 有界来克服这一障碍。我们提出了一种基于领域大小的多项式时间算法，用于在二元证据条件下计算 \\text{FO}^2 和 \\text{C}^2 的WFOMC。此外，我们通过在有界 treewidth 且有界度的图上解决稳定就座安排问题展示了我们算法的应用性，这是尚未解决的问题。我们也进行了实验来展示与现有模型计数求解器相比，我们算法的可扩展性。', 'title_zh': '可计算的具有 bounded treewidth 二元证据的加权一阶模型计数'}
{'arxiv_id': 'arXiv:2511.09173', 'title': 'Data Fusion-Enhanced Decision Transformer for Stable Cross-Domain Generalization', 'authors': 'Guojian Wang, Quinson Hon, Xuyang Chen, Lin Zhao', 'link': 'https://arxiv.org/abs/2511.09173', 'abstract': "Cross-domain shifts present a significant challenge for decision transformer (DT) policies. Existing cross-domain policy adaptation methods typically rely on a single simple filtering criterion to select source trajectory fragments and stitch them together. They match either state structure or action feasibility. However, the selected fragments still have poor stitchability: state structures can misalign, the return-to-go (RTG) becomes incomparable when the reward or horizon changes, and actions may jump at trajectory junctions. As a result, RTG tokens lose continuity, which compromises DT's inference ability. To tackle these challenges, we propose Data Fusion-Enhanced Decision Transformer (DFDT), a compact pipeline that restores stitchability. Particularly, DFDT fuses scarce target data with selectively trusted source fragments via a two-level data filter, maximum mean discrepancy (MMD) mismatch for state-structure alignment, and optimal transport (OT) deviation for action feasibility. It then trains on a feasibility-weighted fusion distribution. Furthermore, DFDT replaces RTG tokens with advantage-conditioned tokens, which improves the continuity of the semantics in the token sequence. It also applies a $Q$-guided regularizer to suppress junction value and action jumps. Theoretically, we provide bounds that tie state value and policy performance gaps to the MMD-mismatch and OT-deviation measures, and show that the bounds tighten as these two measures shrink. We show that DFDT improves return and stability over strong offline RL and sequence-model baselines across gravity, kinematic, and morphology shifts on D4RL-style control tasks, and further corroborate these gains with token-stitching and sequence-semantics stability analyses.", 'abstract_zh': '跨域变化为决策变换器(DT)策略带来了重大挑战。Data Fusion-Enhanced Decision Transformer (DFDT)通过恢复拼接性来应对这些挑战。', 'title_zh': '数据融合增强的决策变换器以实现稳定跨域泛化'}
{'arxiv_id': 'arXiv:2511.09149', 'title': 'Enabling Agents to Communicate Entirely in Latent Space', 'authors': 'Zhuoyun Du, Runze Wang, Huiyu Bai, Zouying Cao, Xiaoyong Zhu, Bo Zheng, Wei Chen, Haochao Ying', 'link': 'https://arxiv.org/abs/2511.09149', 'abstract': 'While natural language is the de facto communication medium for LLM-based agents, it presents a fundamental constraint. The process of downsampling rich, internal latent states into discrete tokens inherently limits the depth and nuance of information that can be transmitted, thereby hindering collaborative problem-solving. Inspired by human mind-reading, we propose Interlat (Inter-agent Latent Space Communication), a paradigm that leverages the last hidden states of an LLM as a representation of its mind for direct transmission (termed latent communication). An additional compression process further compresses latent communication via entirely latent space reasoning. Experiments demonstrate that Interlat outperforms both fine-tuned chain-of-thought (CoT) prompting and single-agent baselines, promoting more exploratory behavior and enabling genuine utilization of latent information. Further compression not only substantially accelerates inference but also maintains competitive performance through an efficient information-preserving mechanism. We position this work as a feasibility study of entirely latent space inter-agent communication, and our results highlight its potential, offering valuable insights for future research.', 'abstract_zh': '基于LLM的代理间富.latent空间通信(Interlat):超越细调链式思维提示与单代理基线的方法', 'title_zh': '使智能体在完全的潜在空间中进行通信'}
{'arxiv_id': 'arXiv:2511.09148', 'title': 'LoopTool: Closing the Data-Training Loop for Robust LLM Tool Calls', 'authors': 'Kangning Zhang, Wenxiang Jiao, Kounianhua Du, Yuan Lu, Weiwen Liu, Weinan Zhang, Lei Zhang, Yong Yu', 'link': 'https://arxiv.org/abs/2511.09148', 'abstract': "Augmenting Large Language Models (LLMs) with external tools enables them to execute complex, multi-step tasks. However, tool learning is hampered by the static synthetic data pipelines where data generation and model training are executed as two separate, non-interactive processes. This approach fails to adaptively focus on a model's specific weaknesses and allows noisy labels to persist, degrading training efficiency. We introduce LoopTool, a fully automated, model-aware data evolution framework that closes this loop by tightly integrating data synthesis and model training. LoopTool iteratively refines both the data and the model through three synergistic modules: (1) Greedy Capability Probing (GCP) diagnoses the model's mastered and failed capabilities; (2) Judgement-Guided Label Verification (JGLV) uses an open-source judge model to find and correct annotation errors, progressively purifying the dataset; and (3) Error-Driven Data Expansion (EDDE) generates new, challenging samples based on identified failures. This closed-loop process operates within a cost-effective, open-source ecosystem, eliminating dependence on expensive closed-source APIs. Experiments show that our 8B model trained with LoopTool significantly surpasses its 32B data generator and achieves new state-of-the-art results on the BFCL-v3 and ACEBench benchmarks for its scale. Our work demonstrates that closed-loop, self-refining data pipelines can dramatically enhance the tool-use capabilities of LLMs.", 'abstract_zh': '增强大型语言模型（LLMs）与外部工具结合能使它们执行复杂的多步任务。然而，工具学习受限于静态的合成数据管道，其中数据生成和模型训练被当作两个分离且非交互的过程执行。这种方法未能针对模型的特定弱点进行自适应的聚焦，并允许噪声标签存在，从而降低训练效率。我们引入了LoopTool，这是一个完全自动化且模型感知的数据演化框架，通过紧密整合数据合成与模型训练来关闭这个循环。LoopTool 通过三个协同模块迭代精炼数据和模型：（1）贪婪能力探测（GCP）诊断模型掌握和未能掌握的能力；（2）判决引导标签验证（JGLV）利用开源判决模型找出并修正注释错误，逐步净化数据集；（3）错误驱动的数据扩展（EDDE）基于识别出的失败生成新的具有挑战性的样本。该闭环过程运行在经济高效的开源生态系统中，避免了对昂贵的闭源API的依赖。实验显示，使用LoopTool训练的8亿参数模型显著超越其32亿参数数据生成器，并在BFCL-v3和ACEBench基准测试中达到了新的规模状态最优结果。我们的工作表明，闭环、自我修正的数据管道可以大幅增强LLMs的工具使用能力。', 'title_zh': 'LoopTool: 闭合数据-训练循环以提高LLM工具调用的稳健性'}
{'arxiv_id': 'arXiv:2511.09147', 'title': 'PressTrack-HMR: Pressure-Based Top-Down Multi-Person Global Human Mesh Recovery', 'authors': 'Jiayue Yuan, Fangting Xie, Guangwen Ouyang, Changhai Ma, Ziyu Wu, Heyu Ding, Quan Wan, Yi Ke, Yuchen Wu, Xiaohui Cai', 'link': 'https://arxiv.org/abs/2511.09147', 'abstract': "Multi-person global human mesh recovery (HMR) is crucial for understanding crowd dynamics and interactions. Traditional vision-based HMR methods sometimes face limitations in real-world scenarios due to mutual occlusions, insufficient lighting, and privacy concerns. Human-floor tactile interactions offer an occlusion-free and privacy-friendly alternative for capturing human motion. Existing research indicates that pressure signals acquired from tactile mats can effectively estimate human pose in single-person scenarios. However, when multiple individuals walk randomly on the mat simultaneously, how to distinguish intermingled pressure signals generated by different persons and subsequently acquire individual temporal pressure data remains a pending challenge for extending pressure-based HMR to the multi-person situation. In this paper, we present \\textbf{PressTrack-HMR}, a top-down pipeline that recovers multi-person global human meshes solely from pressure signals. This pipeline leverages a tracking-by-detection strategy to first identify and segment each individual's pressure signal from the raw pressure data, and subsequently performs HMR for each extracted individual signal. Furthermore, we build a multi-person interaction pressure dataset \\textbf{MIP}, which facilitates further research into pressure-based human motion analysis in multi-person scenarios. Experimental results demonstrate that our method excels in multi-person HMR using pressure data, with 89.2~$mm$ MPJPE and 112.6~$mm$ WA-MPJPE$_{100}$, and these showcase the potential of tactile mats for ubiquitous, privacy-preserving multi-person action recognition. Our dataset \\& code are available at this https URL.", 'abstract_zh': '多人群体全局人体网格恢复（HMR）对于理解人群动态和互动至关重要。现有的基于视觉的人体网格恢复（HMR）方法在实际场景中因相互遮挡、照明不足和隐私问题有时会受到限制。人体-地面触觉交互提供了在不遮挡和隐私友好的情况下捕捉人体运动的替代方案。现有研究表明，从触觉垫中获得的压力量信号在单人场景中可以有效估计人体姿态。然而，在多人同时随机走在垫子上时，如何区分不同个体产生的混合压力量信号并随后获取个体的时序压力量数据仍然是将基础压力的HMR扩展到多人情况的待解决问题。本文提出了一种自上而下的\\textbf{PressTrack-HMR}框架，仅从压力量信号中恢复多人群的全局人体网格。该框架采用检测驱动的跟踪策略，首先从原始压力量数据中识别和分割每个个体的压力量信号，然后对提取出的每个个体信号进行HMR。此外，我们构建了一个多人交互压力量数据集\\textbf{MIP}，促进了在多人场景中基于压力量的人体运动分析研究。实验结果表明，我们的方法在使用压力量数据进行多人HMR方面表现出色，MPJPE为89.2 mm，WA-MPJPE$_{100}$为112.6 mm，展示了触觉垫在通用、隐私保护的多人动作识别中的潜力。我们的数据集与代码可在以下链接访问。', 'title_zh': '压力量化的自顶向下多人全球人体网格恢复'}
{'arxiv_id': 'arXiv:2511.09122', 'title': 'Vendor-Aware Industrial Agents: RAG-Enhanced LLMs for Secure On-Premise PLC Code Generation', 'authors': 'Joschka Kersting, Michael Rummel, Gesa Benndorf', 'link': 'https://arxiv.org/abs/2511.09122', 'abstract': 'Programmable Logic Controllers are operated by proprietary code dialects; this makes it challenging to train coding assistants. Current LLMs are trained on large code datasets and are capable of writing IEC 61131-3 compatible code out of the box, but they neither know specific function blocks, nor related project code. Moreover, companies like Mitsubishi Electric and their customers do not trust cloud providers. Hence, an own coding agent is the desired solution to cope with this. In this study, we present our work on a low-data domain coding assistant solution for industrial use. We show how we achieved high quality code generation without fine-tuning large models and by fine-tuning small local models for edge device usage. Our tool lets several AI models compete with each other, uses reasoning, corrects bugs automatically and checks code validity by compiling it directly in the chat interface. We support our approach with an extensive evaluation that comes with code compilation statistics and user ratings. We found that a Retrieval-Augmented Generation (RAG) supported coding assistant can work in low-data domains by using extensive prompt engineering and directed retrieval.', 'abstract_zh': '一种用于工业应用的低数据域编程助手解决方案', 'title_zh': '基于供应商意识的工业代理：增强型LLM及其在安全边缘PLC代码生成中的应用'}
{'arxiv_id': 'arXiv:2511.09120', 'title': 'Differentially Private Rankings via Outranking Methods and Performance Data Aggregation', 'authors': 'Luis Del Vasto-Terrientes', 'link': 'https://arxiv.org/abs/2511.09120', 'abstract': "Multiple-Criteria Decision Making (MCDM) is a sub-discipline of Operations Research that helps decision-makers in choosing, ranking, or sorting alternatives based on conflicting criteria. Over time, its application has been expanded into dynamic and data-driven domains, such as recommender systems. In these contexts, the availability and handling of personal and sensitive data can play a critical role in the decision-making process. Despite this increased reliance on sensitive data, the integration of privacy mechanisms with MCDM methods is underdeveloped. This paper introduces an integrated approach that combines MCDM outranking methods with Differential Privacy (DP), safeguarding individual contributions' privacy in ranking problems. This approach relies on a pre-processing step to aggregate multiple user evaluations into a comprehensive performance matrix. The evaluation results show a strong to very strong statistical correlation between the true rankings and their anonymized counterparts, ensuring robust privacy parameter guarantees.", 'abstract_zh': '多准则决策分析（MCDM）是运筹学的一个分支，它帮助决策者基于冲突的标准选择、排名或排序备选方案。随着时间的推移，其应用扩展到了动态和数据驱动的领域，如推荐系统。在这些领域中，个人和敏感数据的可用性及其处理可以在决策过程中发挥关键作用。尽管对敏感数据的依赖性增加，但将隐私机制与MCDM方法的集成尚不充分。本文介绍了一种集成方法，该方法结合了MCDM支配方法和差分隐私（DP），在排名问题中保护个体贡献的隐私。该方法依赖于预处理步骤，将多个用户评估综合为一个全面的性能矩阵。评估结果表明，真实排名和匿名排名之间存在强烈的统计相关性，确保了 robust 的隐私参数保证。', 'title_zh': '差分隐私下的递战胜出方法与性能数据聚合-ranking方法下的差分隐私保护'}
{'arxiv_id': 'arXiv:2511.09109', 'title': 'Thinking Forward and Backward: Multi-Objective Reinforcement Learning for Retrieval-Augmented Reasoning', 'authors': 'Wenda Wei, Yu-An Liu, Ruqing Zhang, Jiafeng Guo, Lixin Su, Shuaiqiang Wang, Dawei Yin, Maarten de Rijke, Xueqi Cheng', 'link': 'https://arxiv.org/abs/2511.09109', 'abstract': 'Retrieval-augmented generation (RAG) has proven to be effective in mitigating hallucinations in large language models, yet its effectiveness remains limited in complex, multi-step reasoning this http URL efforts have incorporated search-based interactions into RAG, enabling iterative reasoning with real-time retrieval. Most approaches rely on outcome-based supervision, offering no explicit guidance for intermediate steps. This often leads to reward hacking and degraded response quality. We propose Bi-RAR, a novel retrieval-augmented reasoning framework that evaluates each intermediate step jointly in both forward and backward directions. To assess the information completeness of each step, we introduce a bidirectional information distance grounded in Kolmogorov complexity, approximated via language model generation probabilities. This quantification measures both how far the current reasoning is from the answer and how well it addresses the question. To optimize reasoning under these bidirectional signals, we adopt a multi-objective reinforcement learning framework with a cascading reward structure that emphasizes early trajectory alignment. Empirical results on seven question answering benchmarks demonstrate that Bi-RAR surpasses previous methods and enables efficient interaction and reasoning with the search engine during training and inference.', 'abstract_zh': '检索增强生成（RAG）在减轻大型语言模型幻觉方面已被证明是有效的，但在复杂、多步推理方面其效果仍然有限。通过将基于搜索的交互融入RAG，可以实现迭代推理和实时检索。大多数方法依赖于结果导向的监督，无法为中间步骤提供明确的指导。这往往导致奖励黑客行为和响应质量下降。我们提出了双向检索增强推理（Bi-RAR）框架，这是一个新颖的检索增强推理框架，联合从正向和反向两个方向评估每一步的中间步骤。为了评估每一步的信息完整性，我们引入了一种基于kolmogorov复杂性的双向信息距离，通过语言模型生成概率进行近似计算。这种量化测量了当前推理与答案之间的差距以及对问题的解决程度。为了在这些双向信号下优化推理，我们采用了一种具有级联奖励结构的多目标强化学习框架，强调早期轨迹对齐。在七个问答基准数据集上的实验证明，Bi-RAR 超越了先前的方法，并在训练和推理期间与搜索引擎实现了高效交互和推理。', 'title_zh': '从前往后和从后往前思考：用于检索增强推理的多目标强化学习'}
{'arxiv_id': 'arXiv:2511.09105', 'title': 'Cost-Minimized Label-Flipping Poisoning Attack to LLM Alignment', 'authors': 'Shigeki Kusaka, Keita Saito, Mikoto Kudo, Takumi Tanabe, Akifumi Wachi, Youhei Akimoto', 'link': 'https://arxiv.org/abs/2511.09105', 'abstract': "Large language models (LLMs) are increasingly deployed in real-world systems, making it critical to understand their vulnerabilities. While data poisoning attacks during RLHF/DPO alignment have been studied empirically, their theoretical foundations remain unclear. We investigate the minimum-cost poisoning attack required to steer an LLM's policy toward an attacker's target by flipping preference labels during RLHF/DPO, without altering the compared outputs. We formulate this as a convex optimization problem with linear constraints, deriving lower and upper bounds on the minimum attack cost. As a byproduct of this theoretical analysis, we show that any existing label-flipping attack can be post-processed via our proposed method to reduce the number of label flips required while preserving the intended poisoning effect. Empirical results demonstrate that this cost-minimization post-processing can significantly reduce poisoning costs over baselines, particularly when the reward model's feature dimension is small relative to the dataset size. These findings highlight fundamental vulnerabilities in RLHF/DPO pipelines and provide tools to evaluate their robustness against low-cost poisoning attacks.", 'abstract_zh': '大规模语言模型（LLMs）越来越多地应用于实际系统中，因此理解其漏洞变得至关重要。虽然在基于奖励学习的人工智能辅助人类反馈（RLHF）/分布式匹配优化（DPO）对齐过程中数据投毒攻击已被实证研究，但其理论基础尚不清楚。我们探讨了在不修改比较输出的情况下，通过在RLHF/DPO过程中翻转偏好标签来引导LLM策略朝向攻击者目标所需的最低成本投毒攻击。我们将这一过程形式化为带线性约束的凸优化问题，并推导出最低攻击成本的上界和下界。在此理论分析的基础上，我们证明任何现有的标签翻转攻击都可以通过我们提出的方法进行后处理，从而减少所需的标签翻转次数，同时保持预期的投毒效果。实验证明，这种成本最小化后处理可以显著降低投毒成本，尤其是在奖励模型的特征维度相对于数据集大小较小的情况下。这些发现突显了RLHF/DPO管道中的基本漏洞，并提供了评估其对低成本投毒攻击鲁棒性的工具。', 'title_zh': '成本最小化的标签翻转中毒攻击以实现LLM对齐'}
{'arxiv_id': 'arXiv:2511.09093', 'title': 'Factorization-in-Loop: Proximal Fill-in Minimization for Sparse Matrix Reordering', 'authors': 'Ziwei Li, Shuzi Niu, Tao Yuan, Huiyuan Li, Wenjia Wu', 'link': 'https://arxiv.org/abs/2511.09093', 'abstract': 'Fill-ins are new nonzero elements in the summation of the upper and lower triangular factors generated during LU factorization. For large sparse matrices, they will increase the memory usage and computational time, and be reduced through proper row or column arrangement, namely matrix reordering. Finding a row or column permutation with the minimal fill-ins is NP-hard, and surrogate objectives are designed to derive fill-in reduction permutations or learn a reordering function. However, there is no theoretical guarantee between the golden criterion and these surrogate objectives. Here we propose to learn a reordering network by minimizing \\(l_1\\) norm of triangular factors of the reordered matrix to approximate the exact number of fill-ins. The reordering network utilizes a graph encoder to predict row or column node scores. For inference, it is easy and fast to derive the permutation from sorting algorithms for matrices. For gradient based optimization, there is a large gap between the predicted node scores and resultant triangular factors in the optimization objective. To bridge the gap, we first design two reparameterization techniques to obtain the permutation matrix from node scores. The matrix is reordered by multiplying the permutation matrix. Then we introduce the factorization process into the objective function to arrive at target triangular factors. The overall objective function is optimized with the alternating direction method of multipliers and proximal gradient descent. Experimental results on benchmark sparse matrix collection SuiteSparse show the fill-in number and LU factorization time reduction of our proposed method is 20% and 17.8% compared with state-of-the-art baselines.', 'abstract_zh': '填补元素是矩阵LU分解过程中上三角和下三角因子求和中新出现的非零元素。对于大型稀疏矩阵，这些填补元素会增加内存使用和计算时间，并可以通过适当的行或列排列（即矩阵重排）减少。找到具有最小填补元素的行或列置换是NP难问题，因此设计了替代目标来获得填补元素减少的置换或学习一个重排函数。然而，这些替代目标与理想目标之间没有理论保证。我们提出通过最小化重排矩阵的三角因子的\\(l_1\\)范数来学习一个重排网络，以近似填补元素的确切数量。重排网络利用图编码器预测行或列节点得分。在推断过程中，通过排序算法容易快速地从节点得分导出置换。对于基于梯度的优化，预测节点得分与优化目标中产生的三角因子之间存在较大差距。为了弥合这一差距，我们首先设计了两种再参数化技术，从节点得分中获得置换矩阵。该矩阵通过乘以置换矩阵进行重排。然后我们将分解过程引入目标函数中，以达到目标三角因子。最终的目标函数使用交替方向乘法器和 proximal 梯度下降进行优化。在基准稀疏矩阵集合SuiteSparse上的实验结果表明，与最先进的基线方法相比，我们提出的方法可以减少20%的填补元素数量和17.8%的LU分解时间。', 'title_zh': '环中因子化：proximal 填充最小化Sparse 矩阵重排序'}
{'arxiv_id': 'arXiv:2511.09090', 'title': 'Diff-V2M: A Hierarchical Conditional Diffusion Model with Explicit Rhythmic Modeling for Video-to-Music Generation', 'authors': 'Shulei Ji, Zihao Wang, Jiaxing Yu, Xiangyuan Yang, Shuyu Li, Songruoyao Wu, Kejun Zhang', 'link': 'https://arxiv.org/abs/2511.09090', 'abstract': 'Video-to-music (V2M) generation aims to create music that aligns with visual content. However, two main challenges persist in existing methods: (1) the lack of explicit rhythm modeling hinders audiovisual temporal alignments; (2) effectively integrating various visual features to condition music generation remains non-trivial. To address these issues, we propose Diff-V2M, a general V2M framework based on a hierarchical conditional diffusion model, comprising two core components: visual feature extraction and conditional music generation. For rhythm modeling, we begin by evaluating several rhythmic representations, including low-resolution mel-spectrograms, tempograms, and onset detection functions (ODF), and devise a rhythmic predictor to infer them directly from videos. To ensure contextual and affective coherence, we also extract semantic and emotional features. All features are incorporated into the generator via a hierarchical cross-attention mechanism, where emotional features shape the affective tone via the first layer, while semantic and rhythmic features are fused in the second cross-attention layer. To enhance feature integration, we introduce timestep-aware fusion strategies, including feature-wise linear modulation (FiLM) and weighted fusion, allowing the model to adaptively balance semantic and rhythmic cues throughout the diffusion process. Extensive experiments identify low-resolution ODF as a more effective signal for modeling musical rhythm and demonstrate that Diff-V2M outperforms existing models on both in-domain and out-of-domain datasets, achieving state-of-the-art performance in terms of objective metrics and subjective comparisons. Demo and code are available at this https URL.', 'abstract_zh': '基于视频到音乐生成的差分模型（Diff-V2M）', 'title_zh': 'Diff-V2M：一种具有显式节拍建模的分层级条件扩散模型用于视频到音乐生成'}
{'arxiv_id': 'arXiv:2511.09088', 'title': 'Improving Sustainability of Adversarial Examples in Class-Incremental Learning', 'authors': 'Taifeng Liu, Xinjing Liu, Liangqiu Dong, Yang Liu, Yilong Yang, Zhuo Ma', 'link': 'https://arxiv.org/abs/2511.09088', 'abstract': 'Current adversarial examples (AEs) are typically designed for static models. However, with the wide application of Class-Incremental Learning (CIL), models are no longer static and need to be updated with new data distributed and labeled differently from the old ones. As a result, existing AEs often fail after CIL updates due to significant domain drift. In this paper, we propose SAE to enhance the sustainability of AEs against CIL. The core idea of SAE is to enhance the robustness of AE semantics against domain drift by making them more similar to the target class while distinguishing them from all other classes. Achieving this is challenging, as relying solely on the initial CIL model to optimize AE semantics often leads to overfitting. To resolve the problem, we propose a Semantic Correction Module. This module encourages the AE semantics to be generalized, based on a visual-language model capable of producing universal semantics. Additionally, it incorporates the CIL model to correct the optimization direction of the AE semantics, guiding them closer to the target class. To further reduce fluctuations in AE semantics, we propose a Filtering-and-Augmentation Module, which first identifies non-target examples with target-class semantics in the latent space and then augments them to foster more stable semantics. Comprehensive experiments demonstrate that SAE outperforms baselines by an average of 31.28% when updated with a 9-fold increase in the number of classes.', 'abstract_zh': '当前的 adversarial examples (AEs) 主要针对静态模型设计。然而，随着类增量学习（CIL）的广泛应用，模型不再静态，而是需要随着新数据的分布式和不同标签的数据进行更新。结果，现有的 AEs 往往在 CIL 更新后由于显著的领域漂移而失效。本文提出 SAE 以增强 AEs 对 CIL 的可持续性。SAE 的核心思想是通过使 AE 语义更接近目标类并与其他所有类区分开来，增强 AE 语义对领域漂移的鲁棒性。实现这一点具有挑战性，因为仅依赖初始 CIL 模型来优化 AE 语义往往会引发过拟合。为了解决该问题，我们提出了一种语义修正模块。该模块基于能够生成通用语义的视觉-语言模型，鼓励 AE 语义泛化，并结合 CIL 模型来纠正 AE 语义的优化方向，使其更接近目标类。为了进一步减少 AE 语义的波动，我们还提出了一种过滤与扩充模块，该模块首先在潜在空间中识别具有目标类语义的非目标示例，然后对其进行扩充以促进更稳定的语义。综合实验表明，当类别数量增加 9 倍时，SAE 在损耗平均基准性能 31.28% 的情况下表现出更优的效果。', 'title_zh': '提高类增量学习中对抗样本的可持续性'}
{'arxiv_id': 'arXiv:2511.09087', 'title': 'Tele-LLM-Hub: Building Context-Aware Multi-Agent LLM Systems for Telecom Networks', 'authors': 'Vijay K Shah, Cong Shen', 'link': 'https://arxiv.org/abs/2511.09087', 'abstract': 'This paper introduces Tele-LLM-Hub, a user friendly low-code solution for rapid prototyping and deployment of context aware multi-agent (MA) Large Language Model (LLM) systems tailored for 5G and beyond. As telecom wireless networks become increasingly complex, intelligent LLM applications must share a domainspecific understanding of network state. We propose TeleMCP, the Telecom Model Context Protocol, to enable structured and context-rich communication between agents in telecom environments. Tele-LLM-Hub actualizes TeleMCP through a low-code interface that supports agent creation, workflow composition, and interaction with software stacks such as srsRAN. Key components include a direct chat interface, a repository of pre-built systems, an Agent Maker leveraging finetuning with our RANSTRUCT framework, and an MA-Maker for composing MA workflows. The goal of Tele-LLM-Hub is to democratize the design of contextaware MA systems and accelerate innovation in next-generation wireless networks.', 'abstract_zh': 'Tele-LLM-Hub：面向5G及以上的用户友好低代码解决方案，用于快速原型制作和部署上下文感知多代理大型语言模型系统', 'title_zh': 'Tele-LLM-Hub: 构建面向电信网络的上下文感知多智能体LLM系统'}
{'arxiv_id': 'arXiv:2511.09073', 'title': 'Good-for-MDP State Reduction for Stochastic LTL Planning', 'authors': 'Christoph Weinhuber, Giuseppe De Giacomo, Yong Li, Sven Schewe, Qiyi Tang', 'link': 'https://arxiv.org/abs/2511.09073', 'abstract': 'We study stochastic planning problems in Markov Decision Processes (MDPs) with goals specified in Linear Temporal Logic (LTL). The state-of-the-art approach transforms LTL formulas into good-for-MDP (GFM) automata, which feature a restricted form of nondeterminism. These automata are then composed with the MDP, allowing the agent to resolve the nondeterminism during policy synthesis. A major factor affecting the scalability of this approach is the size of the generated automata. In this paper, we propose a novel GFM state-space reduction technique that significantly reduces the number of automata states. Our method employs a sophisticated chain of transformations, leveraging recent advances in good-for-games minimisation developed for adversarial settings. In addition to our theoretical contributions, we present empirical results demonstrating the practical effectiveness of our state-reduction technique. Furthermore, we introduce a direct construction method for formulas of the form $\\mathsf{G}\\mathsf{F}\\varphi$, where $\\varphi$ is a co-safety formula. This construction is provably single-exponential in the worst case, in contrast to the general doubly-exponential complexity. Our experiments confirm the scalability advantages of this specialised construction.', 'abstract_zh': '我们研究线性时逻辑（LTL）目标下马尔可夫决策过程（MDP）中的随机规划问题。最先进的方法是将LTL公式转换为适合MDP（GFM）自动机，这种自动机具有受限的非确定性形式。然后将这些自动机与MDP组合，使代理可以在策略合成过程中解决非确定性问题。影响这一方法可扩展性的一个重要因素是生成的自动机状态数量。在本文中，我们提出了一种新颖的GFM状态空间缩减技术，显著减少了自动机状态的数量。该方法利用了在对抗环境中发展起来的GFM最小化最近进展进行了一系列复杂的转换。除了我们的理论贡献外，我们还提供了实证结果，证明了我们的状态缩减技术的实用有效性。此外，我们介绍了一种直接构造形式为$\\mathsf{G}\\mathsf{F}\\varphi$的公式的构造方法，其中$\\varphi$为补安全性公式，这种构造在最坏情况下的复杂性是可以证明的单指数级的，而一般的复杂性是双重指数级的。我们的实验验证了这种专门构造方法的可扩展性优势。', 'title_zh': '适合MDP的状态减少方法用于随机LTL规划'}
{'arxiv_id': 'arXiv:2511.09067', 'title': 'MM-CRITIC: A Holistic Evaluation of Large Multimodal Models as Multimodal Critique', 'authors': 'Gailun Zeng, Ziyang Luo, Hongzhan Lin, Yuchen Tian, Kaixin Li, Ziyang Gong, Jianxiong Guo, Jing Ma', 'link': 'https://arxiv.org/abs/2511.09067', 'abstract': "The ability of critique is vital for models to self-improve and serve as reliable AI assistants. While extensively studied in language-only settings, multimodal critique of Large Multimodal Models (LMMs) remains underexplored despite their growing capabilities in tasks like captioning and visual reasoning. In this work, we introduce MM-CRITIC, a holistic benchmark for evaluating the critique ability of LMMs across multiple dimensions: basic, correction, and comparison. Covering 8 main task types and over 500 tasks, MM-CRITIC collects responses from various LMMs with different model sizes and is composed of 4471 samples. To enhance the evaluation reliability, we integrate expert-informed ground answers into scoring rubrics that guide GPT-4o in annotating responses and generating reference critiques, which serve as anchors for trustworthy judgments. Extensive experiments validate the effectiveness of MM-CRITIC and provide a comprehensive assessment of leading LMMs' critique capabilities under multiple dimensions. Further analysis reveals some key insights, including the correlation between response quality and critique, and varying critique difficulty across evaluation dimensions. Our code is available at this https URL.", 'abstract_zh': '多媒体批判能力评估对于模型的自我提升和成为可靠的AI助手至关重要。尽管在语言仅有的设置中已被广泛研究，但在多种模态批评方面的大规模多媒体模型（LMMs）仍然未被充分探索，尽管它们在字幕生成和视觉推理等任务中的能力正在不断提高。在本工作中，我们介绍了MM-CRITIC，这是一个全面的基准，用于从多个维度评估LMMs的批判能力：基本、修正和比较。MM-CRITIC涵盖了8种主要任务类型和超过500个任务，收集了不同模型规模的各种LMMs的响应，共有4471个样本。为提高评估的可靠性，我们将专家指导的地面 truth答案整合到评分标准中，引导GPT-4o标注响应并生成参考批判，为可靠判断提供参考点。广泛的实验证明了MM-CRITIC的有效性，并提供了对多个维度下领先LMMs批判能力的全面评估。进一步的分析揭示了一些关键见解，包括响应质量与批判的相关性，以及在评估维度上的不同批判难度。我们的代码可在以下链接获取：这个 https URL。', 'title_zh': 'MM-CRITIC: 多模态大型模型的综合评估作为多模态批评'}
{'arxiv_id': 'arXiv:2511.09057', 'title': 'PAN: A World Model for General, Interactable, and Long-Horizon World Simulation', 'authors': 'PAN Team Institute of Foundation Models, Jiannan Xiang, Yi Gu, Zihan Liu, Zeyu Feng, Qiyue Gao, Yiyan Hu, Benhao Huang, Guangyi Liu, Yichi Yang, Kun Zhou, Davit Abrahamyan, Arif Ahmad, Ganesh Bannur, Junrong Chen, Kimi Chen, Mingkai Deng, Ruobing Han, Xinqi Huang, Haoqiang Kang, Zheqi Li, Enze Ma, Hector Ren, Yashowardhan Shinde, Rohan Shingre, Ramsundar Tanikella, Kaiming Tao, Dequan Yang, Xinle Yu, Cong Zeng, Binglin Zhou, Hector Liu, Zhiting Hu, Eric P. Xing', 'link': 'https://arxiv.org/abs/2511.09057', 'abstract': 'A world model enables an intelligent agent to imagine, predict, and reason about how the world evolves in response to its actions, and accordingly to plan and strategize. While recent video generation models produce realistic visual sequences, they typically operate in the prompt-to-full-video manner without causal control, interactivity, or long-horizon consistency required for purposeful reasoning. Existing world modeling efforts, on the other hand, often focus on restricted domains (e.g., physical, game, or 3D-scene dynamics) with limited depth and controllability, and struggle to generalize across diverse environments and interaction formats. In this work, we introduce PAN, a general, interactable, and long-horizon world model that predicts future world states through high-quality video simulation conditioned on history and natural language actions. PAN employs the Generative Latent Prediction (GLP) architecture that combines an autoregressive latent dynamics backbone based on a large language model (LLM), which grounds simulation in extensive text-based knowledge and enables conditioning on language-specified actions, with a video diffusion decoder that reconstructs perceptually detailed and temporally coherent visual observations, to achieve a unification between latent space reasoning (imagination) and realizable world dynamics (reality). Trained on large-scale video-action pairs spanning diverse domains, PAN supports open-domain, action-conditioned simulation with coherent, long-term dynamics. Extensive experiments show that PAN achieves strong performance in action-conditioned world simulation, long-horizon forecasting, and simulative reasoning compared to other video generators and world models, taking a step towards general world models that enable predictive simulation of future world states for reasoning and acting.', 'abstract_zh': '一个世界模型使智能代理能够想象、预测和推理世界在其行为响应下的演变，并据此规划和制定策略。尽管近期的视频生成模型能够生成逼真的视觉序列，但它们通常以提示到完整视频的方式运行，并缺乏用于有目的推理所需的因果控制、交互性和长时一致性。现有的世界建模努力往往集中在受限制的领域（如物理、游戏或3D场景动力学）上，这些领域深度有限且可控性差，难以在多种环境和交互格式之间泛化。在本项工作中，我们引入了PAN，这是一种通用、可交互和长时未来预测的世界模型，它通过基于历史和自然语言动作的高质量视频模拟来预测未来的世 界状态。PAN采用生成潜空间预测（GLP）架构，该架构结合了一个基于大规模语言模型（LLM）的自回归潜动力学骨干网络，以广泛的文本知识为基础，使模拟得以实现并能够根据语言规定的动作进行条件化，以及一个视频扩散解码器，该解码器能够重建知觉详细且时间一致的视觉观察。PAN实现了潜空间推理（想象）与可实现的世界动力学（现实）之间的统一。PAN在多种领域的大规模视频-动作对上进行训练，支持开放领域的、根据动作条件化的仿真，具有连贯的长时动态。大量实验表明，PAN在动作条件化的世界仿真、长时预测和仿真正推理方面相较于其他视频生成器和世界模型表现优异，朝着能够进行预测仿真实现未来世界状态推理和行动的通用世界模型迈出了一步。', 'title_zh': 'PAN：一种用于通用、可交互和长时 horizon 世界模拟的世界模型'}
{'arxiv_id': 'arXiv:2511.09049', 'title': 'Break the Tie: Learning Cluster-Customized Category Relationships for Categorical Data Clustering', 'authors': 'Mingjie Zhao, Zhanpei Huang, Yang Lu, Mengke Li, Yiqun Zhang, Weifeng Su, Yiu-ming Cheung', 'link': 'https://arxiv.org/abs/2511.09049', 'abstract': 'Categorical attributes with qualitative values are ubiquitous in cluster analysis of real datasets. Unlike the Euclidean distance of numerical attributes, the categorical attributes lack well-defined relationships of their possible values (also called categories interchangeably), which hampers the exploration of compact categorical data clusters. Although most attempts are made for developing appropriate distance metrics, they typically assume a fixed topological relationship between categories when learning distance metrics, which limits their adaptability to varying cluster structures and often leads to suboptimal clustering performance. This paper, therefore, breaks the intrinsic relationship tie of attribute categories and learns customized distance metrics suitable for flexibly and accurately revealing various cluster distributions. As a result, the fitting ability of the clustering algorithm is significantly enhanced, benefiting from the learnable category relationships. Moreover, the learned category relationships are proved to be Euclidean distance metric-compatible, enabling a seamless extension to mixed datasets that include both numerical and categorical attributes. Comparative experiments on 12 real benchmark datasets with significance tests show the superior clustering accuracy of the proposed method with an average ranking of 1.25, which is significantly higher than the 5.21 ranking of the current best-performing method.', 'abstract_zh': '类别型属性在实际数据集的聚类分析中无处不在。与数值属性的欧几里得距离不同，类别型属性缺乏其可能值（称为类别）之间明确的关系，这阻碍了紧凑类别数据集探索。尽管大多数努力集中在开发合适的距离度量上，它们在学习距离度量时通常假定类别之间的固定拓扑关系，这限制了它们对变化的聚类结构的适应性，并常常导致聚类性能不佳。因此，本文打破属性类别的固有关系，学习适用于灵活准确揭示各种聚类分布的定制距离度量。结果，聚类算法的拟合能力显著增强，得益于可学习的类别关系。此外，学习到的类别关系证明与欧几里得距离度量兼容，使得该方法可以直接扩展到包含数值和类别属性的混合数据集。在包含12个真实基准数据集的比较实验中，经过显著性检验，所提出方法的聚类准确性的平均排名为1.25，显著高于当前表现最佳方法的5.21排名。', 'title_zh': '打破约束：学习聚类定制的类别关系进行分类数据聚类'}
{'arxiv_id': 'arXiv:2511.09043', 'title': 'MedHE: Communication-Efficient Privacy-Preserving Federated Learning with Adaptive Gradient Sparsification for Healthcare', 'authors': 'Farjana Yesmin', 'link': 'https://arxiv.org/abs/2511.09043', 'abstract': 'Healthcare federated learning requires strong privacy guarantees while maintaining computational efficiency across resource-constrained medical institutions. This paper presents MedHE, a novel framework combining adaptive gradient sparsification with CKKS homomorphic encryption to enable privacy-preserving collaborative learning on sensitive medical data. Our approach introduces a dynamic threshold mechanism with error compensation for top-k gradient selection, achieving 97.5 percent communication reduction while preserving model utility. We provide formal security analysis under Ring Learning with Errors assumptions and demonstrate differential privacy guarantees with epsilon less than or equal to 1.0. Statistical testing across 5 independent trials shows MedHE achieves 89.5 percent plus or minus 0.8 percent accuracy, maintaining comparable performance to standard federated learning (p=0.32) while reducing communication from 1277 MB to 32 MB per training round. Comprehensive evaluation demonstrates practical feasibility for real-world medical deployments with HIPAA compliance and scalability to 100 plus institutions.', 'abstract_zh': '医疗 federated 学习需要在严格保护隐私的同时保持计算效率，以适应资源受限的医疗机构。本文提出 MedHE 框架，结合自适应梯度稀疏化与 CKKS 同态加密，以实现对敏感医疗数据的隐私保护协作学习。该方法引入动态阈值机制并带有误差补偿的 top-k 梯度选择，实现了 97.5% 的通信减少，同时保持模型性能。我们在 Ring LWE 假设下提供正式的安全性分析，并证明其差分隐私保证，ε ≤ 1.0。跨 5 次独立试验的统计测试显示，MedHE 的准确率为 89.5% ± 0.8%，在保持与标准 federated 学习相当的性能（p=0.32）的同时，将每轮训练的通信量从 1277 MB 减少到 32 MB。全面评估表明，MedHE 具有 HIPAA 合规性和扩展性，适用于 100 家以上的医疗机构部署。', 'title_zh': 'MedHE: 通信高效且保护隐私的自适应梯度稀疏化医疗联邦学习'}
{'arxiv_id': 'arXiv:2511.09036', 'title': 'FedSDWC: Federated Synergistic Dual-Representation Weak Causal Learning for OOD', 'authors': 'Zhenyuan Huang, Hui Zhang, Wenzhong Tang, Haijun Yang', 'link': 'https://arxiv.org/abs/2511.09036', 'abstract': "Amid growing demands for data privacy and advances in computational infrastructure, federated learning (FL) has emerged as a prominent distributed learning paradigm. Nevertheless, differences in data distribution (such as covariate and semantic shifts) severely affect its reliability in real-world deployments. To address this issue, we propose FedSDWC, a causal inference method that integrates both invariant and variant features. FedSDWC infers causal semantic representations by modeling the weak causal influence between invariant and variant features, effectively overcoming the limitations of existing invariant learning methods in accurately capturing invariant features and directly constructing causal representations. This approach significantly enhances FL's ability to generalize and detect OOD data. Theoretically, we derive FedSDWC's generalization error bound under specific conditions and, for the first time, establish its relationship with client prior distributions. Moreover, extensive experiments conducted on multiple benchmark datasets validate the superior performance of FedSDWC in handling covariate and semantic shifts. For example, FedSDWC outperforms FedICON, the next best baseline, by an average of 3.04% on CIFAR-10 and 8.11% on CIFAR-100.", 'abstract_zh': '在日益增长的数据隐私需求及计算基础设施的进步背景下，联邦学习（FL）已成为一种突出的分布式学习范式。然而，数据分布差异（如共变量和语义偏移）严重影响了其在实际部署中的可靠性。为了解决这一问题，我们提出了一种因果推理方法FedSDWC，该方法结合了不变特征和可变特征。FedSDWC通过建模不变特征和可变特征之间的弱因果影响来推断因果语义表示，从而有效克服了现有不变特征学习方法在准确捕捉不变特征和直接构建因果表示方面的局限性。该方法显著提高了联邦学习在泛化能力和检测OOD数据方面的性能。理论上，我们在特定条件下推导了FedSDWC的泛化误差界，并首次建立了其与客户端先验分布之间的关系。此外，对多个基准数据集进行的广泛实验验证了FedSDWC在处理共变量和语义偏移方面的优越性能。例如，FedSDWC在CIFAR-10上的平均性能优于最接近的基线FedICON 3.04%，在CIFAR-100上的性能优于3.62%。', 'title_zh': 'FedSDWC: 联邦协同双表示弱因果学习以处理OOD任务'}
{'arxiv_id': 'arXiv:2511.09026', 'title': 'DeepVRegulome: DNABERT-based deep-learning framework for predicting the functional impact of short genomic variants on the human regulome', 'authors': 'Pratik Dutta, Matthew Obusan, Rekha Sathian, Max Chao, Pallavi Surana, Nimisha Papineni, Yanrong Ji, Zhihan Zhou, Han Liu, Alisa Yurovsky, Ramana V Davuluri', 'link': 'https://arxiv.org/abs/2511.09026', 'abstract': 'Whole-genome sequencing (WGS) has revealed numerous non-coding short variants whose functional impacts remain poorly understood. Despite recent advances in deep-learning genomic approaches, accurately predicting and prioritizing clinically relevant mutations in gene regulatory regions remains a major challenge. Here we introduce Deep VRegulome, a deep-learning method for prediction and interpretation of functionally disruptive variants in the human regulome, which combines 700 DNABERT fine-tuned models, trained on vast amounts of ENCODE gene regulatory regions, with variant scoring, motif analysis, attention-based visualization, and survival analysis. We showcase its application on TCGA glioblastoma WGS dataset in prioritizing survival-associated mutations and regulatory regions. The analysis identified 572 splice-disrupting and 9,837 transcription-factor binding site altering mutations occurring in greater than 10% of glioblastoma samples. Survival analysis linked 1352 mutations and 563 disrupted regulatory regions to patient outcomes, enabling stratification via non-coding mutation signatures. All the code, fine-tuned models, and an interactive data portal are publicly available.', 'abstract_zh': 'Whole-genome sequencing (WGS) 揭示了大量非编码短变异，其功能影响仍 poorly understood。尽管近年来深度学习基因组方法取得了进步，但准确预测和优先级排序与基因调控区域相关的临床相关突变仍然是一项重大挑战。我们介绍了 Deep VRegulome，这是一种用于预测和解释人类调控组中功能破坏性变异的深度学习方法，该方法结合了700个在大量ENCODE基因调控区域上微调的DNABERT模型，以及变异评分、motif分析、基于注意力的可视化和生存分析。我们在TCGA胶质母细胞瘤WGS数据集中展示了其应用，以优先级排序与生存相关的变异和调控区域。分析识别出572个剪接破坏性和9,837个转录因子结合位点改变的突变，在超过10%的胶质母细胞瘤样本中发生。生存分析将1352个突变和563个受损的调控区域与患者预后联系起来，使通过非编码突变特征进行分层成为可能。所有代码、微调模型以及一个交互式数据门户均已公开。', 'title_zh': 'DeepVRegulome：基于DNABERT的深度学习框架，用于预测短基因组变异对人类调控组的功能影响'}
{'arxiv_id': 'arXiv:2511.09018', 'title': 'Causally-Grounded Dual-Path Attention Intervention for Object Hallucination Mitigation in LVLMs', 'authors': 'Liu Yu, Zhonghao Chen, Ping Kuang, Zhikun Feng, Fan Zhou, Lan Wang, Gillian Dobbie', 'link': 'https://arxiv.org/abs/2511.09018', 'abstract': 'Object hallucination remains a critical challenge in Large Vision-Language Models (LVLMs), where models generate content inconsistent with visual inputs. Existing language-decoder based mitigation approaches often regulate visual or textual attention independently, overlooking their interaction as two key causal factors. To address this, we propose Owl (Bi-mOdal attention reWeighting for Layer-wise hallucination mitigation), a causally-grounded framework that models hallucination process via a structural causal graph, treating decomposed visual and textual attentions as mediators. We introduce VTACR (Visual-to-Textual Attention Contribution Ratio), a novel metric that quantifies the modality contribution imbalance during decoding. Our analysis reveals that hallucinations frequently occur in low-VTACR scenarios, where textual priors dominate and visual grounding is weakened. To mitigate this, we design a fine-grained attention intervention mechanism that dynamically adjusts token- and layer-wise attention guided by VTACR signals. Finally, we propose a dual-path contrastive decoding strategy: one path emphasizes visually grounded predictions, while the other amplifies hallucinated ones -- letting visual truth shine and hallucination collapse. Experimental results on the POPE and CHAIR benchmarks show that Owl achieves significant hallucination reduction, setting a new SOTA in faithfulness while preserving vision-language understanding capability. Our code is available at this https URL', 'abstract_zh': 'Bi模态注意力重加权以减少层级幻觉：Owl框架', 'title_zh': '因果导向的双路径注意力干预方法以减轻低级视觉语言模型中的物体错幻覺'}
{'arxiv_id': 'arXiv:2511.09008', 'title': 'A Neurosymbolic Approach to Natural Language Formalization and Verification', 'authors': 'Sam Bayless, Stefano Buliani, Darion Cassel, Byron Cook, Duncan Clough, Rémi Delmas, Nafi Diallo, Ferhat Erata, Nick Feng, Dimitra Giannakopoulou, Aman Goel, Aditya Gokhale, Joe Hendrix, Marc Hudak, Dejan Jovanović, Andrew M. Kent, Benjamin Kiesl-Reiter, Jeffrey J. Kuna, Nadia Labai, Joseph Lilien, Divya Raghunathan, Zvonimir Rakamarić, Niloofar Razavi, Michael Tautschnig, Ali Torkamani, Nathaniel Weir, Michael W. Whalen, Jianan Yao', 'link': 'https://arxiv.org/abs/2511.09008', 'abstract': 'Large Language Models perform well at natural language interpretation and reasoning, but their inherent stochasticity limits their adoption in regulated industries like finance and healthcare that operate under strict policies. To address this limitation, we present a two-stage neurosymbolic framework that (1) uses LLMs with optional human guidance to formalize natural language policies, allowing fine-grained control of the formalization process, and (2) uses inference-time autoformalization to validate logical correctness of natural language statements against those policies. When correctness is paramount, we perform multiple redundant formalization steps at inference time, cross checking the formalizations for semantic equivalence. Our benchmarks demonstrate that our approach exceeds 99% soundness, indicating a near-zero false positive rate in identifying logical validity. Our approach produces auditable logical artifacts that substantiate the verification outcomes and can be used to improve the original text.', 'abstract_zh': '大型语言模型在自然语言解释和推理方面表现优异，但由于其固有的随机性，它们在受严格政策监管的金融和医疗等行业中的应用受到限制。为解决这一问题，我们提出了一种两阶段神经符号框架，该框架（1）利用带有可选人类指导的大型语言模型来正式化自然语言政策，从而实现形式化过程的精细控制；（2）在推理时自动形式化自然语言声明，以验证其与政策的逻辑正确性。当逻辑正确性至关重要时，我们会在推理时执行多个冗余形式化步骤，并通过语义等价性交叉检查形式化结果。我们的基准测试表明，我们的方法 Soundness 超过了 99%，显示出几乎零的假阳性率，用于识别逻辑有效性。我们的方法生成可审计的逻辑成果，可以验证验证结果，并可用于改进原始文本。', 'title_zh': '基于神经符号方法的自然语言形式化与验证'}
{'arxiv_id': 'arXiv:2511.08967', 'title': 'AuthSig: Safeguarding Scanned Signatures Against Unauthorized Reuse in Paperless Workflows', 'authors': 'RuiQiang Zhang, Zehua Ma, Guanjie Wang, Chang Liu, Hengyi Wang, Weiming Zhang', 'link': 'https://arxiv.org/abs/2511.08967', 'abstract': "With the deepening trend of paperless workflows, signatures as a means of identity authentication are gradually shifting from traditional ink-on-paper to electronic this http URL the availability of dynamic pressure-sensitive and PKI-based digital signatures, static scanned signatures remain prevalent in practice due to their convenience. However, these static images, having almost lost their authentication attributes, cannot be reliably verified and are vulnerable to malicious copying and reuse. To address these issues, we propose AuthSig, a novel static electronic signature framework based on generative models and watermark, which binds authentication information to the signature image. Leveraging the human visual system's insensitivity to subtle style variations, AuthSig finely modulates style embeddings during generation to implicitly encode watermark bits-enforcing a One Signature, One Use this http URL overcome the scarcity of handwritten signature data and the limitations of traditional augmentation methods, we introduce a keypoint-driven data augmentation strategy that effectively enhances style diversity to support robust watermark embedding. Experimental results show that AuthSig achieves over 98% extraction accuracy under both digital-domain distortions and signature-specific degradations, and remains effective even in print-scan scenarios.", 'abstract_zh': '基于生成模型和水印的新型静态电子签名框架(AuthSig)', 'title_zh': '无纸化工作流中保护扫描签名免遭未经授权重用的安全机制'}
{'arxiv_id': 'arXiv:2511.08945', 'title': 'FGM-HD: Boosting Generation Diversity of Fractal Generative Models through Hausdorff Dimension Induction', 'authors': 'Haowei Zhang, Yuanpei Zhao, Jizhe Zhou, Mao Li', 'link': 'https://arxiv.org/abs/2511.08945', 'abstract': 'Improving the diversity of generated results while maintaining high visual quality remains a significant challenge in image generation tasks. Fractal Generative Models (FGMs) are efficient in generating high-quality images, but their inherent self-similarity limits the diversity of output images. To address this issue, we propose a novel approach based on the Hausdorff Dimension (HD), a widely recognized concept in fractal geometry used to quantify structural complexity, which aids in enhancing the diversity of generated outputs. To incorporate HD into FGM, we propose a learnable HD estimation method that predicts HD directly from image embeddings, addressing computational cost concerns. However, simply introducing HD into a hybrid loss is insufficient to enhance diversity in FGMs due to: 1) degradation of image quality, and 2) limited improvement in generation diversity. To this end, during training, we adopt an HD-based loss with a monotonic momentum-driven scheduling strategy to progressively optimize the hyperparameters, obtaining optimal diversity without sacrificing visual quality. Moreover, during inference, we employ HD-guided rejection sampling to select geometrically richer outputs. Extensive experiments on the ImageNet dataset demonstrate that our FGM-HD framework yields a 39\\% improvement in output diversity compared to vanilla FGMs, while preserving comparable image quality. To our knowledge, this is the very first work introducing HD into FGM. Our method effectively enhances the diversity of generated outputs while offering a principled theoretical contribution to FGM development.', 'abstract_zh': '提高生成结果的多样性同时保持高视觉质量仍然是图像生成任务中的一个重大挑战。分形生成模型(Fractal Generative Models, FGMs)能够生成高质量的图像，但由于其固有的自相似性限制了输出图像的多样性。为了解决这一问题，我们提出了一种基于豪斯多夫维数(Hausdorff Dimension, HD)的新型方法，豪斯多夫维数是分形几何中广泛认可的概念，用于量化结构的复杂性，有助于增强生成输出的多样性。为了将HD融入FGMs中，我们提出了一种可学习的HD估算方法，该方法直接从图像嵌入中预测HD，解决了计算成本问题。然而，仅将HD引入混合损失中不足以提高FGMs的多样性：1) 图像质量下降；2) 生成多样性提升有限。为此，在训练期间，我们采用基于HD的损失，并结合单调动量驱动的调度策略逐级优化超参数，从而在不牺牲视觉质量的情况下获得最佳的多样性。此外，在推理期间，我们采用基于HD的拒绝采样选择几何结构更丰富的输出。在ImageNet数据集上的广泛实验表明，我们的FGM-HD框架相比vanilla FGMs在输出多样性方面提高了39%，同时保持了相当的图像质量。据我们所知，这是首次将HD引入FGMs的工作。我们的方法有效地提高了生成输出的多样性，并在FGM开发中提供了原则性的理论贡献。', 'title_zh': 'FGM-HD: 基于 Hausdorff 维数诱导提升分形生成模型的生成多样性'}
{'arxiv_id': 'arXiv:2511.08942', 'title': 'Think, Remember, Navigate: Zero-Shot Object-Goal Navigation with VLM-Powered Reasoning', 'authors': 'Mobin Habibpour, Fatemeh Afghah', 'link': 'https://arxiv.org/abs/2511.08942', 'abstract': "While Vision-Language Models (VLMs) are set to transform robotic navigation, existing methods often underutilize their reasoning capabilities. To unlock the full potential of VLMs in robotics, we shift their role from passive observers to active strategists in the navigation process. Our framework outsources high-level planning to a VLM, which leverages its contextual understanding to guide a frontier-based exploration agent. This intelligent guidance is achieved through a trio of techniques: structured chain-of-thought prompting that elicits logical, step-by-step reasoning; dynamic inclusion of the agent's recent action history to prevent getting stuck in loops; and a novel capability that enables the VLM to interpret top-down obstacle maps alongside first-person views, thereby enhancing spatial awareness. When tested on challenging benchmarks like HM3D, Gibson, and MP3D, this method produces exceptionally direct and logical trajectories, marking a substantial improvement in navigation efficiency over existing approaches and charting a path toward more capable embodied agents.", 'abstract_zh': '视觉-语言模型在机器人导航中的潜力解锁：从被动观察者到主动策略师', 'title_zh': '思考、记忆、导航：基于VLM增强推理的零样本物体目标导航'}
{'arxiv_id': 'arXiv:2511.08930', 'title': 'From Structure to Detail: Hierarchical Distillation for Efficient Diffusion Model', 'authors': 'Hanbo Cheng, Peng Wang, Kaixiang Lei, Qi Li, Zhen Zou, Pengfei Hu, Jun Du', 'link': 'https://arxiv.org/abs/2511.08930', 'abstract': 'The inference latency of diffusion models remains a critical barrier to their real-time application. While trajectory-based and distribution-based step distillation methods offer solutions, they present a fundamental trade-off. Trajectory-based methods preserve global structure but act as a "lossy compressor", sacrificing high-frequency details. Conversely, distribution-based methods can achieve higher fidelity but often suffer from mode collapse and unstable training. This paper recasts them from independent paradigms into synergistic components within our novel Hierarchical Distillation (HD) framework. We leverage trajectory distillation not as a final generator, but to establish a structural ``sketch", providing a near-optimal initialization for the subsequent distribution-based refinement stage. This strategy yields an ideal initial distribution that enhances the ceiling of overall performance. To further improve quality, we introduce and refine the adversarial training process. We find standard discriminator structures are ineffective at refining an already high-quality generator. To overcome this, we introduce the Adaptive Weighted Discriminator (AWD), tailored for the HD pipeline. By dynamically allocating token weights, AWD focuses on local imperfections, enabling efficient detail refinement. Our approach demonstrates state-of-the-art performance across diverse tasks. On ImageNet $256\\times256$, our single-step model achieves an FID of 2.26, rivaling its 250-step teacher. It also achieves promising results on the high-resolution text-to-image MJHQ benchmark, proving its generalizability. Our method establishes a robust new paradigm for high-fidelity, single-step diffusion models.', 'abstract_zh': '扩散模型的推理延迟仍然是其实时应用的关键障碍。虽然基于轨迹和基于分布的步进蒸馏方法提供了解决方案，但它们之间存在基本的权衡。基于轨迹的方法保留全局结构，但作为“冗余压缩器”，牺牲了高频细节。相反，基于分布的方法可以实现更高的保真度，但往往遭受模式崩溃和不稳定的训练。本文将它们从独立范式重新构想为我们全新的层次蒸馏（HD）框架中的协同组件。我们利用基于轨迹的蒸馏不仅作为最终生成器，而是用来建立一个结构“素描”，为后续的基于分布的精加工阶段提供近最优的初始化。这种策略产生了一个理想的初始分布，增强了整体性能的天花板。为了进一步提高质量，我们引入并改进了对抗训练过程。我们发现标准的鉴别器结构对精炼已经高质量的生成器效果不佳。为此，我们引入了适应性加权鉴别器（AWD），专门针对HD流水线。通过动态分配TOKEN权重，AWD专注于局部瑕疵，从而实现高效详细的精加工。我们的方法在多种任务中表现出最先进的性能。在ImageNet $256\\times256$上，我们的一步模型达到了2.26的FID，接近其250步的教师模型。此外，它在高分辨率文本到图像的MJHQ基准测试上也取得了令人振奋的结果，证明了其通用性。我们的方法建立了高保真、单步骤扩散模型的稳健新范式。', 'title_zh': '从结构到细节：分层蒸馏高效扩散模型'}
{'arxiv_id': 'arXiv:2511.08926', 'title': 'Achieving Equilibrium under Utility Heterogeneity: An Agent-Attention Framework for Multi-Agent Multi-Objective Reinforcement Learning', 'authors': 'Zhuhui Li, Chunbo Luo, Liming Huang, Luyu Qi, Geyong Min', 'link': 'https://arxiv.org/abs/2511.08926', 'abstract': "Multi-agent multi-objective systems (MAMOS) have emerged as powerful frameworks for modelling complex decision-making problems across various real-world domains, such as robotic exploration, autonomous traffic management, and sensor network optimisation. MAMOS offers enhanced scalability and robustness through decentralised control and more accurately reflects inherent trade-offs between conflicting objectives. In MAMOS, each agent uses utility functions that map return vectors to scalar values. Existing MAMOS optimisation methods face challenges in handling heterogeneous objective and utility function settings, where training non-stationarity is intensified due to private utility functions and the associated policies. In this paper, we first theoretically prove that direct access to, or structured modeling of, global utility functions is necessary for the Bayesian Nash Equilibrium under decentralised execution constraints. To access the global utility functions while preserving the decentralised execution, we propose an Agent-Attention Multi-Agent Multi-Objective Reinforcement Learning (AA-MAMORL) framework. Our approach implicitly learns a joint belief over other agents' utility functions and their associated policies during centralised training, effectively mapping global states and utilities to each agent's policy. In execution, each agent independently selects actions based on local observations and its private utility function to approximate a BNE, without relying on inter-agent communication. We conduct comprehensive experiments in both a custom-designed MAMO Particle environment and the standard MOMALand benchmark. The results demonstrate that access to global preferences and our proposed AA-MAMORL significantly improve performance and consistently outperform state-of-the-art methods.", 'abstract_zh': '多代理多目标系统中的多代理注意机制多目标强化学习框架（Agent-Attention Multi-Agent Multi-Objective Reinforcement Learning for MAMOS）', 'title_zh': '在效用异质性下的均衡实现：基于代理注意力的多代理多目标 reinforcement learning 框架'}
{'arxiv_id': 'arXiv:2511.08923', 'title': 'TiDAR: Think in Diffusion, Talk in Autoregression', 'authors': 'Jingyu Liu, Xin Dong, Zhifan Ye, Rishabh Mehta, Yonggan Fu, Vartika Singh, Jan Kautz, Ce Zhang, Pavlo Molchanov', 'link': 'https://arxiv.org/abs/2511.08923', 'abstract': 'Diffusion language models hold the promise of fast parallel generation, while autoregressive (AR) models typically excel in quality due to their causal structure aligning naturally with language modeling. This raises a fundamental question: can we achieve a synergy with high throughput, higher GPU utilization, and AR level quality? Existing methods fail to effectively balance these two aspects, either prioritizing AR using a weaker model for sequential drafting (speculative decoding), leading to lower drafting efficiency, or using some form of left-to-right (AR-like) decoding logic for diffusion, which still suffers from quality degradation and forfeits its potential parallelizability. We introduce TiDAR, a sequence-level hybrid architecture that drafts tokens (Thinking) in Diffusion and samples final outputs (Talking) AutoRegressively - all within a single forward pass using specially designed structured attention masks. This design exploits the free GPU compute density, achieving a strong balance between drafting and verification capacity. Moreover, TiDAR is designed to be serving-friendly (low overhead) as a standalone model. We extensively evaluate TiDAR against AR models, speculative decoding, and diffusion variants across generative and likelihood tasks at 1.5B and 8B scales. Thanks to the parallel drafting and sampling as well as exact KV cache support, TiDAR outperforms speculative decoding in measured throughput and surpasses diffusion models like Dream and Llada in both efficiency and quality. Most notably, TiDAR is the first architecture to close the quality gap with AR models while delivering 4.71x to 5.91x more tokens per second.', 'abstract_zh': 'TiDAR：序列级混合架构实现高吞吐量、高GPU利用率及自回归级别质量', 'title_zh': 'TiDAR: 思考在扩散中，表达在自回归中'}
{'arxiv_id': 'arXiv:2511.08922', 'title': 'Diffusion Policies with Value-Conditional Optimization for Offline Reinforcement Learning', 'authors': 'Yunchang Ma, Tenglong Liu, Yixing Lan, Xin Yin, Changxin Zhang, Xinglong Zhang, Xin Xu', 'link': 'https://arxiv.org/abs/2511.08922', 'abstract': "In offline reinforcement learning, value overestimation caused by out-of-distribution (OOD) actions significantly limits policy performance. Recently, diffusion models have been leveraged for their strong distribution-matching capabilities, enforcing conservatism through behavior policy constraints. However, existing methods often apply indiscriminate regularization to redundant actions in low-quality datasets, resulting in excessive conservatism and an imbalance between the expressiveness and efficiency of diffusion modeling. To address these issues, we propose DIffusion policies with Value-conditional Optimization (DIVO), a novel approach that leverages diffusion models to generate high-quality, broadly covered in-distribution state-action samples while facilitating efficient policy improvement. Specifically, DIVO introduces a binary-weighted mechanism that utilizes the advantage values of actions in the offline dataset to guide diffusion model training. This enables a more precise alignment with the dataset's distribution while selectively expanding the boundaries of high-advantage actions. During policy improvement, DIVO dynamically filters high-return-potential actions from the diffusion model, effectively guiding the learned policy toward better performance. This approach achieves a critical balance between conservatism and explorability in offline RL. We evaluate DIVO on the D4RL benchmark and compare it against state-of-the-art baselines. Empirical results demonstrate that DIVO achieves superior performance, delivering significant improvements in average returns across locomotion tasks and outperforming existing methods in the challenging AntMaze domain, where sparse rewards pose a major difficulty.", 'abstract_zh': '离线强化学习中，由分布外（OOD）动作引起的价值高估显著限制了策略性能。为了解决这一问题，我们提出了以值条件优化为特征的扩散模型策略（DIVO），该方法利用了扩散模型生成高质量、广泛覆盖的在分布状态-动作样本的同时，促进高效的策略改进。具体地，DIVO 引入了一种二值加权机制，利用离线数据集中动作的优势值来指导扩散模型的训练。这使得扩散模型更加精确地匹配数据集的分布，并有选择性地扩展高优势动作的边界。在策略改进过程中，DIVO 动态过滤出具有高回报潜力的动作，有效地引导学习到的策略向更好的性能方向发展。该方法在离线 RL 中实现了保守性和探索性的关键平衡。我们在 D4RL 基准上评估了 DIVO，并将其与最先进的基线方法进行了比较。实验结果表明，DIVO 达到了优越的性能，在步行任务中显著提高了平均回报，并且在具有稀疏回报的挑战性 AntMaze 领域中优于现有方法。', 'title_zh': '基于价值条件优化的离线强化学习扩散策略'}
{'arxiv_id': 'arXiv:2511.08905', 'title': 'iSeal: Encrypted Fingerprinting for Reliable LLM Ownership Verification', 'authors': 'Zixun Xiong, Gaoyi Wu, Qingyang Yu, Mingyu Derek Ma, Lingfeng Yao, Miao Pan, Xiaojiang Du, Hao Wang', 'link': 'https://arxiv.org/abs/2511.08905', 'abstract': "Given the high cost of large language model (LLM) training from scratch, safeguarding LLM intellectual property (IP) has become increasingly crucial. As the standard paradigm for IP ownership verification, LLM fingerprinting thus plays a vital role in addressing this challenge. Existing LLM fingerprinting methods verify ownership by extracting or injecting model-specific features. However, they overlook potential attacks during the verification process, leaving them ineffective when the model thief fully controls the LLM's inference process. In such settings, attackers may share prompt-response pairs to enable fingerprint unlearning or manipulate outputs to evade exact-match verification. We propose iSeal, the first fingerprinting method designed for reliable verification when the model thief controls the suspected LLM in an end-to-end manner. It injects unique features into both the model and an external module, reinforced by an error-correction mechanism and a similarity-based verification strategy. These components are resistant to verification-time attacks, including collusion-based fingerprint unlearning and response manipulation, backed by both theoretical analysis and empirical results. iSeal achieves 100 percent Fingerprint Success Rate (FSR) on 12 LLMs against more than 10 attacks, while baselines fail under unlearning and response manipulations.", 'abstract_zh': '基于模型 Thief 全局控制的大型语言模型指纹识别方法 iSeal', 'title_zh': 'iSeal: 加密指纹技术用于可靠的LLM所有权验证'}
{'arxiv_id': 'arXiv:2511.08904', 'title': 'Consistency Change Detection Framework for Unsupervised Remote Sensing Change Detection', 'authors': 'Yating Liu, Yan Lu', 'link': 'https://arxiv.org/abs/2511.08904', 'abstract': 'Unsupervised remote sensing change detection aims to monitor and analyze changes from multi-temporal remote sensing images in the same geometric region at different times, without the need for labeled training data. Previous unsupervised methods attempt to achieve style transfer across multi-temporal remote sensing images through reconstruction by a generator network, and then capture the unreconstructable areas as the changed regions. However, it often leads to poor performance due to generator overfitting. In this paper, we propose a novel Consistency Change Detection Framework (CCDF) to address this challenge. Specifically, we introduce a Cycle Consistency (CC) module to reduce the overfitting issues in the generator-based reconstruction. Additionally, we propose a Semantic Consistency (SC) module to enable detail reconstruction. Extensive experiments demonstrate that our method outperforms other state-of-the-art approaches.', 'abstract_zh': '无监督遥感变化检测旨在通过生成网络进行重构，监测和分析同一几何区域在不同时段的多时相遥感图像的变化，无需使用标注训练数据。以往的无监督方法试图通过生成网络实现多时相遥感图像之间的风格迁移，并通过捕捉不可重构的区域来识别变化区域，但由于生成器过拟合常常导致性能较差。本文提出了一种新的一致性变化检测框架（CCDF）以应对这一挑战。具体地，我们引入了一致性循环模块（CC 模块）以减轻基于生成器的重构中的过拟合问题，并提出了语义一致性（SC）模块以实现细节重构。 extensive 实验表明，我们的方法优于其他最先进的方法。', 'title_zh': '基于无监督遥感变化检测的一致性变化检测框架'}
{'arxiv_id': 'arXiv:2511.08896', 'title': 'Classifying Histopathologic Glioblastoma Sub-regions with EfficientNet', 'authors': 'Sanyukta Adap, Ujjwal Baid, Spyridon Bakas', 'link': 'https://arxiv.org/abs/2511.08896', 'abstract': "Glioblastoma (GBM) is the most common aggressive, fast-growing brain tumor, with a grim prognosis. Despite clinical diagnostic advancements, there have not been any substantial improvements to patient prognosis. Histopathological assessment of excised tumors is the first line of clinical diagnostic routine. We hypothesize that automated, robust, and accurate identification of distinct histological sub-regions within GBM could contribute to morphologically understanding this disease at scale. In this study, we designed a four-step deep learning approach to classify six (6) histopathological regions and quantitatively evaluated it on the BraTS-Path 2024 challenge dataset, which includes digitized Hematoxylin \\& Eosin (H\\&E) stained GBM tissue sections annotated for six distinct regions. We used the challenge's publicly available training dataset to develop and evaluate the effectiveness of several variants of EfficientNet architectures (i.e., B0, B1, B2, B3, B4). EfficientNet-B1 and EfficientNet-B4 achieved the best performance, achieving an F1 score of 0.98 in a 5-fold cross-validation configuration using the BraTS-Path training set. The quantitative performance evaluation of our proposed approach with EfficientNet-B1 on the BraTS-Path hold-out validation data and the final hidden testing data yielded F1 scores of 0.546 and 0.517, respectively, for the associated 6-class classification task. The difference in the performance on training, validation, and testing data highlights the challenge of developing models that generalize well to new data, which is crucial for clinical applications. The source code of the proposed approach can be found at the GitHub repository of Indiana University Division of Computational Pathology: this https URL.", 'abstract_zh': '胶质母细胞瘤（GBM）是最常见的一种侵袭性、快速生长的脑肿瘤，预后极为严峻。尽管临床诊断技术有所进步，患者的预后仍未有显著改善。切除肿瘤的组织病理学评估是临床诊断的第一步。我们假设自动化、稳健且准确地识别胶质母细胞瘤中不同的组织病理学亚区域，能够大规模地从形态学上理解这种疾病。在本研究中，我们设计了一种四步深度学习方法，用于分类六个组织病理学区域，并在包含六个不同区域注释的BraTS-Path 2024挑战数据集上进行定量评估。我们利用挑战提供的公开训练数据集，开发并评估了几种EfficientNet架构（即B0、B1、B2、B3、B4）的有效性。EfficientNet-B1和EfficientNet-B4表现出最佳性能，在使用BraTS-Path训练集的5折交叉验证配置中，F1分数达到了0.98。在使用BraTS-Path保留验证数据和最终隐藏测试数据进行的定量性能评估中，相应6类分类任务的F1分数分别为0.546和0.517。训练、验证和测试数据上的性能差异突显了开发在新数据上泛化良好的模型的挑战，这对于临床应用至关重要。所提出方法的源代码可以在Indiana University Computational Pathology Division的GitHub仓库中找到：this https URL。', 'title_zh': '使用EfficientNet对组织病理学胶质母细胞瘤亚区进行分类'}
{'arxiv_id': 'arXiv:2511.08887', 'title': 'FAST-CAD: A Fairness-Aware Framework for Non-Contact Stroke Diagnosis', 'authors': 'Tianming Sha, Zechuan Chen, Zhan Cheng, Haotian Zhai, Xuwei Ding, Junnan Li, Haixiang Tang, Zaoting Sun, Yanchuan Tang, Yongzhe Yi, Yanjie Huang, Anhao Li, Yuan Gao, Keze Wang', 'link': 'https://arxiv.org/abs/2511.08887', 'abstract': 'Stroke is an acute cerebrovascular disease, and timely diagnosis significantly improves patient survival. However, existing automated diagnosis methods suffer from fairness issues across demographic groups, potentially exacerbating healthcare disparities. In this work we propose FAST-CAD, a theoretically grounded framework that combines domain-adversarial training (DAT) with group distributionally robust optimization (Group-DRO) for fair and accurate non-contact stroke diagnosis. Our approach is built on domain adaptation and minimax fairness theory and provides convergence guarantees and fairness bounds. We curate a multimodal dataset covering 12 demographic subgroups defined by age, gender, and posture. FAST-CAD employs self-supervised encoders with adversarial domain discrimination to learn demographic-invariant representations, while Group-DRO optimizes worst-group risk to ensure robust performance across all subgroups. Extensive experiments show that our method achieves superior diagnostic performance while maintaining fairness across demographic groups, and our theoretical analysis supports the effectiveness of the unified DAT + Group-DRO framework. This work provides both practical advances and theoretical insights for fair medical AI systems.', 'abstract_zh': '面向公正和准确的无接触中风诊断的FAST-CAD框架', 'title_zh': 'FAST-CAD：一个公平性的意识框架用于非接触式中风诊断'}
{'arxiv_id': 'arXiv:2511.08877', 'title': 'Hallucinate or Memorize? The Two Sides of Probabilistic Learning in Large Language Models', 'authors': 'Junichiro Niimi', 'link': 'https://arxiv.org/abs/2511.08877', 'abstract': "Large language models (LLMs) have been increasingly applied to a wide range of tasks, from natural language understanding to code generation. While they have also been used to assist in citation recommendation, the hallucination of non-existent papers remains a major issue. Building on prior studies, this study hypothesizes that an LLM's ability to correctly produce bibliographic records depends on whether the underlying knowledge is generated or memorized, with highly cited papers (i.e., more frequently appear in the pretraining corpus) showing lower hallucination rates. We therefore assume citation count as a proxy for training data redundancy (i.e., the frequency with which a given bibliographic record appears in the pretraining corpus) and investigate how citation frequency affects hallucinated references in LLM outputs. Using GPT-4.1, we generated and manually verified 100 citations across twenty computer-science domains, and measured factual consistency via cosine similarity between generated and authentic metadata. The results revealed that (i) citation count is strongly correlated with factual accuracy, (ii) bibliographic information becomes almost verbatim memorized beyond roughly 1,000 citations, and (iii) memory interference occurs when multiple highly cited papers share similar content. These findings indicate a threshold where generalization shifts into memorization, with highly cited papers being nearly verbatim retained in the model.", 'abstract_zh': '大型语言模型（LLMs）在从自然语言理解到代码生成等多种任务中得到了广泛应用。尽管它们也被用于辅助引文推荐，但虚构不存在的论文问题仍然是一个主要问题。在此基础上，本研究假设一个LLM准确生成参考文献的能力取决于其背后的知识是生成的还是记忆的，高被引论文（即在预训练语料中出现频率更高）显示出较低的虚构率。因此，我们假设引文数量作为训练数据冗余（即给定参考文献在预训练语料中出现的频率）的代理，并研究引文频率如何影响LLM输出中的虚构引文。使用GPT-4.1，我们生成并手动验证了计算机科学二十个领域的100个引文，并通过生成数据和真实元数据之间的余弦相似度衡量事实一致性。结果表明：（i）引文数量与事实准确性之间存在强烈相关性；（ii）引文数量超过约1,000后，参考文献几乎被原样记忆；（iii）当多篇高被引论文包含相似内容时，会发生记忆干扰。这些发现表明，在一个临界点处，泛化转换为记忆，高被引论文几乎被原样保留在模型中。', 'title_zh': '生成或记忆？大型语言模型中概率学习的两面性'}
{'arxiv_id': 'arXiv:2511.08872', 'title': 'SasMamba: A Lightweight Structure-Aware Stride State Space Model for 3D Human Pose Estimation', 'authors': 'Hu Cui, Wenqiang Hua, Renjing Huang, Shurui Jia, Tessai Hayama', 'link': 'https://arxiv.org/abs/2511.08872', 'abstract': 'Recently, the Mamba architecture based on State Space Models (SSMs) has gained attention in 3D human pose estimation due to its linear complexity and strong global modeling capability. However, existing SSM-based methods typically apply manually designed scan operations to flatten detected 2D pose sequences into purely temporal sequences, either locally or globally. This approach disrupts the inherent spatial structure of human poses and entangles spatial and temporal features, making it difficult to capture complex pose dependencies. To address these limitations, we propose the Skeleton Structure-Aware Stride SSM (SAS-SSM), which first employs a structure-aware spatiotemporal convolution to dynamically capture essential local interactions between joints, and then applies a stride-based scan strategy to construct multi-scale global structural representations. This enables flexible modeling of both local and global pose information while maintaining linear computational complexity. Built upon SAS-SSM, our model SasMamba achieves competitive 3D pose estimation performance with significantly fewer parameters compared to existing hybrid models. The source code is available at this https URL.', 'abstract_zh': '基于骨架结构感知的步长状态空间模型（SAS-SSM）及其在3D人体姿态估计中的应用', 'title_zh': 'SasMamba：一种轻量级结构感知步态状态空间模型用于3D人体姿态估计'}
{'arxiv_id': 'arXiv:2511.08867', 'title': 'Conformal Prediction for Multi-Source Detection on a Network', 'authors': 'Xingchao Jian, Purui Zhang, Lan Tian, Feng Ji, Wenfei Liang, Wee Peng Tay, Bihan Wen, Felix Krahmer', 'link': 'https://arxiv.org/abs/2511.08867', 'abstract': 'Detecting the origin of information or infection spread in networks is a fundamental challenge with applications in misinformation tracking, epidemiology, and beyond. We study the multi-source detection problem: given snapshot observations of node infection status on a graph, estimate the set of source nodes that initiated the propagation. Existing methods either lack statistical guarantees or are limited to specific diffusion models and assumptions. We propose a novel conformal prediction framework that provides statistically valid recall guarantees for source set detection, independent of the underlying diffusion process or data distribution. Our approach introduces principled score functions to quantify the alignment between predicted probabilities and true sources, and leverages a calibration set to construct prediction sets with user-specified recall and coverage levels. The method is applicable to both single- and multi-source scenarios, supports general network diffusion dynamics, and is computationally efficient for large graphs. Empirical results demonstrate that our method achieves rigorous coverage with competitive accuracy, outperforming existing baselines in both reliability and this http URL code is available online.', 'abstract_zh': '检测网络中信息或感染传播的起源是一个基本挑战，具有 misinformation 跟踪、流行病学等领域中的应用。我们研究多源检测问题：给定图上节点感染状态的快照观察结果，估计引发传播的源节点集合。现有方法要么缺乏统计保证，要么局限于特定的扩散模型和假设。我们提出了一种新的卷积预测框架，该框架独立于底层扩散过程或数据分布，提供了源集检测的统计有效性检索保证。该方法引入了可量化预测概率与真实源节点之间对齐程度的原则性评分函数，并利用校准集构建具有用户指定检索率和覆盖率的预测集。该方法适用于单源和多源情景，支持一般的网络扩散动力学，并且对于大型图具有高效性。实验证明，我们的方法在可靠性和准确性方面都表现出色，优于现有基线方法。该代码已在网上公开。', 'title_zh': '网络多源检测的齐性预测'}
{'arxiv_id': 'arXiv:2511.08864', 'title': 'Transformer-Based Sleep Stage Classification Enhanced by Clinical Information', 'authors': 'Woosuk Chung, Seokwoo Hong, Wonhyeok Lee, Sangyoon Bae', 'link': 'https://arxiv.org/abs/2511.08864', 'abstract': 'Manual sleep staging from polysomnography (PSG) is labor-intensive and prone to inter-scorer variability. While recent deep learning models have advanced automated staging, most rely solely on raw PSG signals and neglect contextual cues used by human experts. We propose a two-stage architecture that combines a Transformer-based per-epoch encoder with a 1D CNN aggregator, and systematically investigates the effect of incorporating explicit context: subject-level clinical metadata (age, sex, BMI) and per-epoch expert event annotations (apneas, desaturations, arousals, periodic breathing). Using the Sleep Heart Health Study (SHHS) cohort (n=8,357), we demonstrate that contextual fusion substantially improves staging accuracy. Compared to a PSG-only baseline (macro-F1 0.7745, micro-F1 0.8774), our final model achieves macro-F1 0.8031 and micro-F1 0.9051, with event annotations contributing the largest gains. Notably, feature fusion outperforms multi-task alternatives that predict the same auxiliary labels. These results highlight that augmenting learned representations with clinically meaningful features enhances both performance and interpretability, without modifying the PSG montage or requiring additional sensors. Our findings support a practical and scalable path toward context-aware, expert-aligned sleep staging systems.', 'abstract_zh': '基于 polysomnography 的手动睡眠分期劳动密集且易受评分者间变异影响。虽然近年来的深度学习模型提升了自动分期的能力，但大多数模型仅依赖原始 PSG 信号而忽视了人类专家使用的上下文线索。我们提出了一种两阶段架构，结合了基于 Transformer 的每 Epoch 编码器和 1D CNN 聚合器，并系统地研究了引入明确上下文的影响：受试者级别的临床元数据（年龄、性别、BMI）和每 Epoch 专家事件注释（呼吸暂停、低氧血症、觉醒、周期性呼吸）。使用 Sleep Heart Health Study（SHHS）队列（n=8,357），我们展示了上下文融合显著提高了分期准确性。与仅基于 PSG 的基线模型（macro-F1 0.7745，micro-F1 0.8774）相比，我们的最终模型实现了 macro-F1 0.8031 和 micro-F1 0.9051，其中事件注释带来了最大的提升。值得注意的是，特征融合优于预测相同辅助标签的多任务替代方案。这些结果强调，将学习表示与临床相关的特征结合起来，不仅能提高性能，还增强了可解释性，无需修改 PSG 检测配置或增加传感器。我们的发现支持了一种实用且可扩展的途径，以实现上下文感知且与专家一致的睡眠分期系统。', 'title_zh': '基于Transformer的睡眠阶段分类方法融合临床信息'}
{'arxiv_id': 'arXiv:2511.08860', 'title': 'When is a System Discoverable from Data? Discovery Requires Chaos', 'authors': 'Zakhar Shumaylov, Peter Zaika, Philipp Scholl, Gitta Kutyniok, Lior Horesh, Carola-Bibiane Schönlieb', 'link': 'https://arxiv.org/abs/2511.08860', 'abstract': 'The deep learning revolution has spurred a rise in advances of using AI in sciences. Within physical sciences the main focus has been on discovery of dynamical systems from observational data. Yet the reliability of learned surrogates and symbolic models is often undermined by the fundamental problem of non-uniqueness. The resulting models may fit the available data perfectly, but lack genuine predictive power. This raises the question: under what conditions can the systems governing equations be uniquely identified from a finite set of observations? We show, counter-intuitively, that chaos, typically associated with unpredictability, is crucial for ensuring a system is discoverable in the space of continuous or analytic functions. The prevalence of chaotic systems in benchmark datasets may have inadvertently obscured this fundamental limitation.\nMore concretely, we show that systems chaotic on their entire domain are discoverable from a single trajectory within the space of continuous functions, and systems chaotic on a strange attractor are analytically discoverable under a geometric condition on the attractor. As a consequence, we demonstrate for the first time that the classical Lorenz system is analytically discoverable. Moreover, we establish that analytic discoverability is impossible in the presence of first integrals, common in real-world systems. These findings help explain the success of data-driven methods in inherently chaotic domains like weather forecasting, while revealing a significant challenge for engineering applications like digital twins, where stable, predictable behavior is desired. For these non-chaotic systems, we find that while trajectory data alone is insufficient, certain prior physical knowledge can help ensure discoverability. These findings warrant a critical re-evaluation of the fundamental assumptions underpinning purely data-driven discovery.', 'abstract_zh': '深度学习革命促进了在科学中使用AI的技术进步。在物理科学领域，主要关注从观测数据中发现动力系统。然而，学到的替代模型和符号模型的可靠性往往受到非唯一性这一基本问题的挑战。这些模型可能完美地拟合可用数据，但缺乏真正的预测能力。这引发了问题：在什么条件下可以从有限的观测数据中唯一地识别出支配方程？我们表明，令人惊讶的是，通常与不可预测性相关联的混沌对于确保系统在连续或解析函数空间中可被发现至关重要。基准数据集中混沌系统的普遍性可能无意中模糊了这一基本局限性。\n\n更具体地说，我们证明了在整个域上混沌的系统可以从单个轨迹在连续函数空间中被发现，而奇性吸引子上的混沌系统在满足吸引子的几何条件下是解析可发现的。因此，我们首次证明经典洛伦兹系统是解析可发现的。此外，我们建立了在存在守恒量情况下解析可发现性是不可能的，而守恒量在真实系统中常见。这些发现有助于解释在天气预报等固有混沌领域中数据驱动方法的成功，同时揭示了工程应用如数字孪生中所需稳定可预测行为的重大挑战。对于这些非混沌系统，我们发现仅轨迹数据是不足的，但某些先验物理知识可以确保可发现性。这些发现要求对纯粹基于数据驱动发现的基本假设进行重新评估。', 'title_zh': '何时可以从数据中发现一个系统？发现需要混沌。'}
{'arxiv_id': 'arXiv:2511.08853', 'title': 'Rethinking Graph Super-resolution: Dual Frameworks for Topological Fidelity', 'authors': 'Pragya Singh, Islem Rekik', 'link': 'https://arxiv.org/abs/2511.08853', 'abstract': 'Graph super-resolution, the task of inferring high-resolution (HR) graphs from low-resolution (LR) counterparts, is an underexplored yet crucial research direction that circumvents the need for costly data acquisition. This makes it especially desirable for resource-constrained fields such as the medical domain. While recent GNN-based approaches show promise, they suffer from two key limitations: (1) matrix-based node super-resolution that disregards graph structure and lacks permutation invariance; and (2) reliance on node representations to infer edge weights, which limits scalability and expressivity. In this work, we propose two GNN-agnostic frameworks to address these issues. First, Bi-SR introduces a bipartite graph connecting LR and HR nodes to enable structure-aware node super-resolution that preserves topology and permutation invariance. Second, DEFEND learns edge representations by mapping HR edges to nodes of a dual graph, allowing edge inference via standard node-based GNNs. We evaluate both frameworks on a real-world brain connectome dataset, where they achieve state-of-the-art performance across seven topological measures. To support generalization, we introduce twelve new simulated datasets that capture diverse topologies and LR-HR relationships. These enable comprehensive benchmarking of graph super-resolution methods.', 'abstract_zh': '图超分辨率：从低分辨率图推断高分辨率图的任务是未充分探索但至关重要的研究方向，可以避免昂贵的数据获取需求，尤其适用于资源受限领域如医疗领域。尽管基于图神经网络（GNN）的方法显示出潜力，但它们存在两个关键限制：（1）基于矩阵的节点超分辨率忽视了图结构，缺乏置换不变性；（2）依赖节点表示来推断边权重，限制了可扩展性和表达能力。在本文中，我们提出了两种GNN无关的框架来解决这些问题。首先，Bi-SR通过将低分辨率和高分辨率节点连接到双图来引入结构感知的节点超分辨率，以保持拓扑和置换不变性。其次，DEFEND通过将高分辨率边映射到双图的节点上来学习边表示，允许通过标准的基于节点的GNN进行边推断。我们在一个真实的脑连接组数据集上评估了这两个框架，它们在七个拓扑度量上达到了最先进的性能。为了支持泛化，我们引入了十二个新的模拟数据集，这些数据集捕捉到了多样化的拓扑结构和低分辨率-高分辨率关系，这使我们能够对图超分辨率方法进行全面基准测试。', 'title_zh': '重新思考图超分辨率：拓扑保真的双框架方法'}
{'arxiv_id': 'arXiv:2511.08842', 'title': '3D Guard-Layer: An Integrated Agentic AI Safety System for Edge Artificial Intelligence', 'authors': 'Eren Kurshan, Yuan Xie, Paul Franzon', 'link': 'https://arxiv.org/abs/2511.08842', 'abstract': 'AI systems have found a wide range of real-world applications in recent years. The adoption of edge artificial intelligence, embedding AI directly into edge devices, is rapidly growing. Despite the implementation of guardrails and safety mechanisms, security vulnerabilities and challenges have become increasingly prevalent in this domain, posing a significant barrier to the practical deployment and safety of AI systems. This paper proposes an agentic AI safety architecture that leverages 3D to integrate a dedicated safety layer. It introduces an adaptive AI safety infrastructure capable of dynamically learning and mitigating attacks against the AI system. The system leverages the inherent advantages of co-location with the edge computing hardware to continuously monitor, detect and proactively mitigate threats to the AI system. The integration of local processing and learning capabilities enhances resilience against emerging network-based attacks while simultaneously improving system reliability, modularity, and performance, all with minimal cost and 3D integration overhead.', 'abstract_zh': '基于3D的代理AI安全架构：集成专用安全层以适应AI系统动态学习和缓解攻击', 'title_zh': '3D 代理安全层：边缘人工智能的集成自主AI安全系统'}
{'arxiv_id': 'arXiv:2511.08841', 'title': 'Enhancing DPSGD via Per-Sample Momentum and Low-Pass Filtering', 'authors': 'Xincheng Xu, Thilina Ranbaduge, Qing Wang, Thierry Rakotoarivelo, David Smith', 'link': 'https://arxiv.org/abs/2511.08841', 'abstract': 'Differentially Private Stochastic Gradient Descent (DPSGD) is widely used to train deep neural networks with formal privacy guarantees. However, the addition of differential privacy (DP) often degrades model accuracy by introducing both noise and bias. Existing techniques typically address only one of these issues, as reducing DP noise can exacerbate clipping bias and vice-versa. In this paper, we propose a novel method, \\emph{DP-PMLF}, which integrates per-sample momentum with a low-pass filtering strategy to simultaneously mitigate DP noise and clipping bias. Our approach uses per-sample momentum to smooth gradient estimates prior to clipping, thereby reducing sampling variance. It further employs a post-processing low-pass filter to attenuate high-frequency DP noise without consuming additional privacy budget. We provide a theoretical analysis demonstrating an improved convergence rate under rigorous DP guarantees, and our empirical evaluations reveal that DP-PMLF significantly enhances the privacy-utility trade-off compared to several state-of-the-art DPSGD variants.', 'abstract_zh': 'Differentially Private Stochastic Gradient Descent (DPSGD)具有形式化隐私保证的深度神经网络训练方法', 'title_zh': '基于样本动量和低通滤波的DPSGD增强方法'}
{'arxiv_id': 'arXiv:2511.08835', 'title': 'Beyond Task-Oriented and Chitchat Dialogues: Proactive and Transition-Aware Conversational Agents', 'authors': 'Yejin Yoon, Yuri Son, Namyoung So, Minseo Kim, Minsoo Cho, Chanhee Park, Seungshin Lee, Taeuk Kim', 'link': 'https://arxiv.org/abs/2511.08835', 'abstract': "Conversational agents have traditionally been developed for either task-oriented dialogue (TOD) or open-ended chitchat, with limited progress in unifying the two. Yet, real-world conversations naturally involve fluid transitions between these modes. To address this gap, we introduce TACT (TOD-And-Chitchat Transition), a dataset designed for transition-aware dialogue modeling that incorporates structurally diverse and integrated mode flows. TACT supports both user- and agent-driven mode switches, enabling robust modeling of complex conversational dynamics. To evaluate an agent's ability to initiate and recover from mode transitions, we propose two new metrics -- Switch and Recovery. Models trained on TACT outperform baselines in both intent detection and mode transition handling. Moreover, applying Direct Preference Optimization (DPO) to TACT-trained models yields additional gains, achieving 75.74\\% joint mode-intent accuracy and a 70.1\\% win rate against GPT-4o in human evaluation. These results demonstrate that pairing structurally diverse data with DPO enhances response quality and transition control, paving the way for more proactive and transition-aware conversational agents.", 'abstract_zh': '基于转换意识的对话模型数据集TACT：任务导向对话与开放式闲聊的过渡融合', 'title_zh': '超越任务导向和闲聊对话：前瞻性和状态转移 Awareness 对话代理'}
{'arxiv_id': 'arXiv:2511.08832', 'title': 'TIGER-MARL: Enhancing Multi-Agent Reinforcement Learning with Temporal Information through Graph-based Embeddings and Representations', 'authors': 'Nikunj Gupta, Ludwika Twardecka, James Zachary Hare, Jesse Milzman, Rajgopal Kannan, Viktor Prasanna', 'link': 'https://arxiv.org/abs/2511.08832', 'abstract': 'In this paper, we propose capturing and utilizing \\textit{Temporal Information through Graph-based Embeddings and Representations} or \\textbf{TIGER} to enhance multi-agent reinforcement learning (MARL). We explicitly model how inter-agent coordination structures evolve over time. While most MARL approaches rely on static or per-step relational graphs, they overlook the temporal evolution of interactions that naturally arise as agents adapt, move, or reorganize cooperation strategies. Capturing such evolving dependencies is key to achieving robust and adaptive coordination. To this end, TIGER constructs dynamic temporal graphs of MARL agents, connecting their current and historical interactions. It then employs a temporal attention-based encoder to aggregate information across these structural and temporal neighborhoods, yielding time-aware agent embeddings that guide cooperative policy learning. Through extensive experiments on two coordination-intensive benchmarks, we show that TIGER consistently outperforms diverse value-decomposition and graph-based MARL baselines in task performance and sample efficiency. Furthermore, we conduct comprehensive ablation studies to isolate the impact of key design parameters in TIGER, revealing how structural and temporal factors can jointly shape effective policy learning in MARL. All codes can be found here: this https URL.', 'abstract_zh': '基于图表示的时序信息捕获与利用或TIGER以增强多agent强化学习（MARL）', 'title_zh': 'TIGER-MARL：通过基于图的嵌入与表示增强多智能体强化学习中的时间信息'}
{'arxiv_id': 'arXiv:2511.08823', 'title': 'DT-NVS: Diffusion Transformers for Novel View Synthesis', 'authors': 'Wonbong Jang, Jonathan Tremblay, Lourdes Agapito', 'link': 'https://arxiv.org/abs/2511.08823', 'abstract': 'Generating novel views of a natural scene, e.g., every-day scenes both indoors and outdoors, from a single view is an under-explored problem, even though it is an organic extension to the object-centric novel view synthesis. Existing diffusion-based approaches focus rather on small camera movements in real scenes or only consider unnatural object-centric scenes, limiting their potential applications in real-world settings. In this paper we move away from these constrained regimes and propose a 3D diffusion model trained with image-only losses on a large-scale dataset of real-world, multi-category, unaligned, and casually acquired videos of everyday scenes. We propose DT-NVS, a 3D-aware diffusion model for generalized novel view synthesis that exploits a transformer-based architecture backbone. We make significant contributions to transformer and self-attention architectures to translate images to 3d representations, and novel camera conditioning strategies to allow training on real-world unaligned datasets. In addition, we introduce a novel training paradigm swapping the role of reference frame between the conditioning image and the sampled noisy input. We evaluate our approach on the 3D task of generalized novel view synthesis from a single input image and show improvements over state-of-the-art 3D aware diffusion models and deterministic approaches, while generating diverse outputs.', 'abstract_zh': '从单个视角生成自然场景的新型视图：一种基于3D扩散模型的方法', 'title_zh': 'DT-NVS: 扩散变换器在新颖视图合成中的应用'}
{'arxiv_id': 'arXiv:2511.08798', 'title': 'Structured Uncertainty guided Clarification for LLM Agents', 'authors': 'Manan Suri, Puneet Mathur, Nedim Lipka, Franck Dernoncourt, Ryan A. Rossi, Dinesh Manocha', 'link': 'https://arxiv.org/abs/2511.08798', 'abstract': 'LLM agents extend large language models with tool-calling capabilities, but ambiguous user instructions often lead to incorrect invocations and task failures. We introduce a principled formulation of structured uncertainty over tool-call parameters, modeling joint tool-argument clarification as a POMDP with Expected Value of Perfect Information (EVPI) objective for optimal question selection and aspect-based cost modeling to prevent redundancy. Our SAGE-Agent leverages this structured uncertainty to achieve superior efficiency: increasing coverage on ambiguous tasks by 7-39\\% while reducing clarification questions by 1.5-2.7$\\times$ compared to strong prompting and uncertainty-based baselines. We present ClarifyBench, the first multi-turn tool-augmented disambiguation benchmark with realistic LLM-based user simulation across diverse domains including document editing, vehicle control, and travel booking. Additionally, we demonstrate that structured uncertainty provides effective training signals for reinforcement learning, boosting When2Call accuracy from 36.5\\% to 65.2\\% (3B model) and 36.7\\% to 62.9\\% (7B model) through uncertainty-weighted GRPO training. These results establish structured uncertainty as a principled, efficient approach for tool-augmented agents, improving both task success and interaction efficiency in real-world scenarios.', 'abstract_zh': 'LLM代理通过工具调用能力扩展了大型语言模型，但模糊的用户指令往往会引发错误的调用和任务失败。我们提出了一种结构化不确定性原理性公式，通过部分观测马尔可夫决策过程（POMDP）和预期完美信息（EVPI）目标建模联合工具-参数澄清过程，并通过基于方面成本建模防止冗余。我们的SAGE-Agent利用这种结构化不确定性实现了更高的效率：在模糊任务上的覆盖范围提高了7-39\\%，同时与强烈的提示和基于不确定性的基线相比，澄清问题的数量减少了1.5-2.7倍。我们提出了ClarifyBench，这是首个涵盖文档编辑、车辆控制和旅行预订等多个领域的多轮工具增强消歧验证基准，并包含现实的基于LLM的用户模拟。此外，我们展示了结构化不确定性为强化学习提供了有效的训练信号，通过不确定性加权GRPO训练，将When2Call的准确性从36.5\\%提高到65.2\\%（3B模型）和从36.7\\%提高到62.9\\%（7B模型）。这些结果确立了结构化不确定性作为工具增强代理的原理性、高效方法，提高了实际场景中的任务成功率和交互效率。', 'title_zh': '结构化的不确定性引导澄清对于LLM代理'}
{'arxiv_id': 'arXiv:2511.08767', 'title': 'Hey Pentti, We Did (More of) It!: A Vector-Symbolic Lisp With Residue Arithmetic', 'authors': 'Connor Hanley, Eilene Tomkins-Flanaganm, Mary Alexandria Kelly', 'link': 'https://arxiv.org/abs/2511.08767', 'abstract': 'Using Frequency-domain Holographic Reduced Representations (FHRRs), we extend a Vector-Symbolic Architecture (VSA) encoding of Lisp 1.5 with primitives for arithmetic operations using Residue Hyperdimensional Computing (RHC). Encoding a Turing-complete syntax over a high-dimensional vector space increases the expressivity of neural network states, enabling network states to contain arbitrarily structured representations that are inherently interpretable. We discuss the potential applications of the VSA encoding in machine learning tasks, as well as the importance of encoding structured representations and designing neural networks whose behavior is sensitive to the structure of their representations in virtue of attaining more general intelligent agents than exist at present.', 'abstract_zh': '使用频域全息简化表示（FHRRs），我们扩展了Lisp 1.5的向量符号架构（VSA）编码，并使用残差超维计算（RHC）为其添加了算术操作原语。在高维向量空间中对图灵完备的语法进行编码增加了神经网络状态的表达能力，使网络状态能够包含任意结构化的表示，这些表示本原上具有可解释性。我们讨论了VSA编码在机器学习任务中的潜在应用，以及编码结构化表示和设计对表示结构敏感的神经网络的重要性，以便实现比当前更加通用的智能代理。', 'title_zh': '嘿皮嫩尼，我们又做到了（更多的部分）：一种基于同余算术的向量-符号Lisp'}
{'arxiv_id': 'arXiv:2511.08752', 'title': 'Information-Driven Fault Detection and Identification for Multi-Agent Spacecraft Systems: Collaborative On-Orbit Inspection Mission', 'authors': 'Akshita Gupta, Arna Bhardwaj, Yashwanth Kumar Nakka, Changrak Choi, Amir Rahmani', 'link': 'https://arxiv.org/abs/2511.08752', 'abstract': 'This work presents a global-to-local, task-aware fault detection and identification (FDI) framework for multi-spacecraft systems conducting collaborative inspection missions in low Earth orbit. The inspection task is represented by a global information-driven cost functional that integrates the sensor model, spacecraft poses, and mission-level information-gain objectives. This formulation links guidance, control, and FDI by using the same cost function to drive both global task allocation and local sensing or motion decisions. Fault detection is achieved through comparisons between expected and observed task metrics, while higher-order cost-gradient measures enable the identification of faults among sensors, actuators, and state estimators. An adaptive thresholding mechanism captures the time-varying inspection geometry and dynamic mission conditions. Simulation results for representative multi-spacecraft inspection scenarios demonstrate the reliability of fault localization and classification under uncertainty, providing a unified, information-driven foundation for resilient autonomous inspection architectures.', 'abstract_zh': '一种面向低地球轨道多航天器协同探测任务的全局到局部、任务aware故障检测与识别框架', 'title_zh': '基于信息驱动的多智能体航天器系统故障检测与识别：协同在轨检查任务'}
{'arxiv_id': 'arXiv:2511.08732', 'title': 'Intuitive Programming, Adaptive Task Planning, and Dynamic Role Allocation in Human-Robot Collaboration', 'authors': 'Marta Lagomarsino, Elena Merlo, Andrea Pupa, Timo Birr, Franziska Krebs, Cristian Secchi, Tamim Asfour, Arash Ajoudani', 'link': 'https://arxiv.org/abs/2511.08732', 'abstract': 'Remarkable capabilities have been achieved by robotics and AI, mastering complex tasks and environments. Yet, humans often remain passive observers, fascinated but uncertain how to engage. Robots, in turn, cannot reach their full potential in human-populated environments without effectively modeling human states and intentions and adapting their behavior. To achieve a synergistic human-robot collaboration (HRC), a continuous information flow should be established: humans must intuitively communicate instructions, share expertise, and express needs. In parallel, robots must clearly convey their internal state and forthcoming actions to keep users informed, comfortable, and in control. This review identifies and connects key components enabling intuitive information exchange and skill transfer between humans and robots. We examine the full interaction pipeline: from the human-to-robot communication bridge translating multimodal inputs into robot-understandable representations, through adaptive planning and role allocation, to the control layer and feedback mechanisms to close the loop. Finally, we highlight trends and promising directions toward more adaptive, accessible HRC.', 'abstract_zh': '机器人和AI在掌握复杂任务和环境方面取得了显著能力，但人类往往仍处于被动观察者的位置，对如何参与感到困惑。为了实现人类与机器人协同合作（HRC），需要建立持续的信息流：人类必须直观地传达指令、共享专业知识并表达需求。同时，机器人需要清晰地传达其内部状态和即将采取的行动，以使用户保持被告知、安心和处于控制之中。本文回顾并连接了关键组件，使人类与机器人之间能够直观地进行信息交流和技能转移。我们探讨了完整的交互管道：从人类到机器人的沟通桥梁，将多模态输入转化为机器人可理解的表示，再到适应性规划和角色分配，以及控制层和反馈机制以形成闭环。最后，我们强调了更适应性、更可访问的HRC的发展趋势和有前景的方向。', 'title_zh': '直观编程、自适应任务规划与动态角色分配在人机协作中的应用'}
{'arxiv_id': 'arXiv:2511.08721', 'title': 'Benevolent Dictators? On LLM Agent Behavior in Dictator Games', 'authors': 'Andreas Einwiller, Kanishka Ghosh Dastidar, Artur Romazanov, Annette Hautli-Janisz, Michael Granitzer, Florian Lemmerich', 'link': 'https://arxiv.org/abs/2511.08721', 'abstract': "In behavioral sciences, experiments such as the ultimatum game are conducted to assess preferences for fairness or self-interest of study participants. In the dictator game, a simplified version of the ultimatum game where only one of two players makes a single decision, the dictator unilaterally decides how to split a fixed sum of money between themselves and the other player. Although recent studies have explored behavioral patterns of AI agents based on Large Language Models (LLMs) instructed to adopt different personas, we question the robustness of these results. In particular, many of these studies overlook the role of the system prompt - the underlying instructions that shape the model's behavior - and do not account for how sensitive results can be to slight changes in prompts. However, a robust baseline is essential when studying highly complex behavioral aspects of LLMs. To overcome previous limitations, we propose the LLM agent behavior study (LLM-ABS) framework to (i) explore how different system prompts influence model behavior, (ii) get more reliable insights into agent preferences by using neutral prompt variations, and (iii) analyze linguistic features in responses to open-ended instructions by LLM agents to better understand the reasoning behind their behavior. We found that agents often exhibit a strong preference for fairness, as well as a significant impact of the system prompt on their behavior. From a linguistic perspective, we identify that models express their responses differently. Although prompt sensitivity remains a persistent challenge, our proposed framework demonstrates a robust foundation for LLM agent behavior studies. Our code artifacts are available at this https URL.", 'abstract_zh': '基于大型语言模型的代理行为研究框架：探索系统提示对模型行为的影响及代理偏好分析', 'title_zh': 'benevolent独裁者？关于大规模语言模型代理在独裁者游戏中的行为研究'}
{'arxiv_id': 'arXiv:2511.08710', 'title': 'Convergence dynamics of Agent-to-Agent Interactions with Misaligned objectives', 'authors': 'Romain Cosentino, Sarath Shekkizhar, Adam Earle', 'link': 'https://arxiv.org/abs/2511.08710', 'abstract': 'We develop a theoretical framework for agent-to-agent interactions in multi-agent scenarios. We consider the setup in which two language model based agents perform iterative gradient updates toward their respective objectives in-context, using the output of the other agent as input. We characterize the generation dynamics associated with the interaction when the agents have misaligned objectives, and show that this results in a biased equilibrium where neither agent reaches its target - with the residual errors predictable from the objective gap and the geometry induced by the prompt of each agent. We establish the conditions for asymmetric convergence and provide an algorithm that provably achieves an adversarial result, producing one-sided success. Experiments with trained transformer models as well as GPT$5$ for the task of in-context linear regression validate the theory. Our framework presents a setup to study, predict, and defend multi-agent systems; explicitly linking prompt design and interaction setup to stability, bias, and robustness.', 'abstract_zh': '我们开发了一个代理到代理交互的理论框架，应用于多代理场景。我们考虑基于语言模型的两个代理在上下文中迭代更新其目标的过程，其中一个代理的输出作为另一个代理的输入。当代理的目标不一致时，我们描述了生成动态，并证明这导致一个有偏的平衡点，其中没有任何一个代理达到其目标，剩余误差可以预测来自目标差距和每个代理提示诱导的几何结构。我们建立了非对称收敛的条件，并提供了一个能证明达成对抗结果的算法，产生单方面成功。使用训练好的变换器模型以及GPT$5$进行上下文线性回归的任务验证了该理论。我们的框架提供了一个研究、预测和防御多代理系统的设置，明确地将提示设计和交互设置与稳定性、偏差和鲁棒性联系起来。', 'title_zh': '代理间交互的动力学收敛性与目标不一致'}
{'arxiv_id': 'arXiv:2511.08702', 'title': 'FAIRPLAI: A Human-in-the-Loop Approach to Fair and Private Machine Learning', 'authors': 'David Sanchez Jr., Holly Lopez, Michelle Buraczyk, Anantaa Kotal', 'link': 'https://arxiv.org/abs/2511.08702', 'abstract': 'As machine learning systems move from theory to practice, they are increasingly tasked with decisions that affect healthcare access, financial opportunities, hiring, and public services. In these contexts, accuracy is only one piece of the puzzle - models must also be fair to different groups, protect individual privacy, and remain accountable to stakeholders. Achieving all three is difficult: differential privacy can unintentionally worsen disparities, fairness interventions often rely on sensitive data that privacy restricts, and automated pipelines ignore that fairness is ultimately a human and contextual judgment. We introduce FAIRPLAI (Fair and Private Learning with Active Human Influence), a practical framework that integrates human oversight into the design and deployment of machine learning systems. FAIRPLAI works in three ways: (1) it constructs privacy-fairness frontiers that make trade-offs between accuracy, privacy guarantees, and group outcomes transparent; (2) it enables interactive stakeholder input, allowing decision-makers to select fairness criteria and operating points that reflect their domain needs; and (3) it embeds a differentially private auditing loop, giving humans the ability to review explanations and edge cases without compromising individual data security. Applied to benchmark datasets, FAIRPLAI consistently preserves strong privacy protections while reducing fairness disparities relative to automated baselines. More importantly, it provides a straightforward, interpretable process for practitioners to manage competing demands of accuracy, privacy, and fairness in socially impactful applications. By embedding human judgment where it matters most, FAIRPLAI offers a pathway to machine learning systems that are effective, responsible, and trustworthy in practice. GitHub: this https URL', 'abstract_zh': '面向公平与隐私的主动人类监督学习框架：FAIRPLAI', 'title_zh': 'FAIRPLAI：以人为本的公平性和隐私性机器学习方法'}
{'arxiv_id': 'arXiv:2511.08663', 'title': "3D-TDA - Topological feature extraction from 3D images for Alzheimer's disease classification", 'authors': 'Faisal Ahmed, Taymaz Akan, Fatih Gelir, Owen T. Carmichael, Elizabeth A. Disbrow, Steven A. Conrad, Mohammad A. N. Bhuiyan', 'link': 'https://arxiv.org/abs/2511.08663', 'abstract': 'Now that disease-modifying therapies for Alzheimer disease have been approved by regulatory agencies, the early, objective, and accurate clinical diagnosis of AD based on the lowest-cost measurement modalities possible has become an increasingly urgent need. In this study, we propose a novel feature extraction method using persistent homology to analyze structural MRI of the brain. This approach converts topological features into powerful feature vectors through Betti functions. By integrating these feature vectors with a simple machine learning model like XGBoost, we achieve a computationally efficient machine learning model. Our model outperforms state-of-the-art deep learning models in both binary and three-class classification tasks for ADNI 3D MRI disease diagnosis. Using 10-fold cross-validation, our model achieved an average accuracy of 97.43 percent and sensitivity of 99.09 percent for binary classification. For three-class classification, it achieved an average accuracy of 95.47 percent and sensitivity of 94.98 percent. Unlike many deep learning models, our approach does not require data augmentation or extensive preprocessing, making it particularly suitable for smaller datasets. Topological features differ significantly from those commonly extracted using convolutional filters and other deep learning machinery. Because it provides an entirely different type of information from machine learning models, it has the potential to combine topological features with other models later on.', 'abstract_zh': '基于持续同伦的脑结构MRI特征提取方法在ADNI 3D MRI疾病诊断中的应用', 'title_zh': '3D-TDA - 从3D图像中提取拓扑特征进行阿尔茨海默病分类'}
{'arxiv_id': 'arXiv:2511.08660', 'title': 'Binary and Multiclass Cyberattack Classification on GeNIS Dataset', 'authors': 'Miguel Silva, Daniela Pinto, João Vitorino, Eva Maia, Isabel Praça, Ivone Amorim, Maria João Viamonte', 'link': 'https://arxiv.org/abs/2511.08660', 'abstract': 'The integration of Artificial Intelligence (AI) in Network Intrusion Detection Systems (NIDS) is a promising approach to tackle the increasing sophistication of cyberattacks. However, since Machine Learning (ML) and Deep Learning (DL) models rely heavily on the quality of their training data, the lack of diverse and up-to-date datasets hinders their generalization capability to detect malicious activity in previously unseen network traffic. This study presents an experimental validation of the reliability of the GeNIS dataset for AI-based NIDS, to serve as a baseline for future benchmarks. Five feature selection methods, Information Gain, Chi-Squared Test, Recursive Feature Elimination, Mean Absolute Deviation, and Dispersion Ratio, were combined to identify the most relevant features of GeNIS and reduce its dimensionality, enabling a more computationally efficient detection. Three decision tree ensembles and two deep neural networks were trained for both binary and multiclass classification tasks. All models reached high accuracy and F1-scores, and the ML ensembles achieved slightly better generalization while remaining more efficient than DL models. Overall, the obtained results indicate that the GeNIS dataset supports intelligent intrusion detection and cyberattack classification with time-based and quantity-based behavioral features.', 'abstract_zh': '人工智能（AI）在网络入侵检测系统（NIDS）中的集成是应对日益 sophisticated 的网络攻击的一种有前途的方法。然而，由于机器学习（ML）和深度学习（DL）模型高度依赖其训练数据的质量，缺乏多样性和及时更新的数据集阻碍了它们在检测未知网络流量中的恶意活动时的一般化能力。本研究通过实验验证了GeNIS数据集在基于AI的NIDS中的可靠性，以作为未来基准测试的基线。结合使用了五种特征选择方法（信息增益、卡方检验、递归特征消除、绝对均值偏差和分散比），以识别GeNIS中最相关的特征并减少其维度，从而提高计算效率。训练了三种决策树集成和两种深度神经网络模型，用于二分类和多分类任务。所有模型均达到较高的准确率和F1分数，而机器学习集成在保持计算效率的同时略好于深度学习模型。总体而言，实验结果表明，GeNIS数据集支持基于时间特征和数量特征的智能入侵检测和网络攻击分类。', 'title_zh': '基于GeNIS数据集的二分类和多分类网络攻击识别'}
{'arxiv_id': 'arXiv:2511.08659', 'title': 'Introduction to Automated Negotiation', 'authors': 'Dave de Jonge', 'link': 'https://arxiv.org/abs/2511.08659', 'abstract': 'This book is an introductory textbook targeted towards computer science students who are completely new to the topic of automated negotiation. It does not require any prerequisite knowledge, except for elementary mathematics and basic programming skills.\nThis book comes with an simple toy-world negotiation framework implemented in Python that can be used by the readers to implement their own negotiation algorithms and perform experiments with them. This framework is small and simple enough that any reader who does not like to work in Python should be able to re-implement it very quickly in any other programming language of their choice.', 'abstract_zh': '本书面向完全新接触自动谈判主题的计算机科学学生，是一本入门教材。它不需要任何先修知识，只需具备基础数学和基本编程能力。本书附带一个用Python实现的简单玩具世界谈判框架，读者可以使用该框架实现自己的谈判算法并进行实验。该框架足够小且简单，任何不喜欢在Python中工作的读者都可以很快用他们选择的其他编程语言重实现它。', 'title_zh': '自动化协商导论'}
{'arxiv_id': 'arXiv:2511.08655', 'title': "Learning the Basis: A Kolmogorov-Arnold Network Approach Embedding Green's Function Priors", 'authors': 'Rui Zhu, Yuexing Peng, George C. Alexandropoulos, Wenbo Wang, Wei Xiang', 'link': 'https://arxiv.org/abs/2511.08655', 'abstract': "The Method of Moments (MoM) is constrained by the usage of static, geometry-defined basis functions, such as the Rao-Wilton-Glisson (RWG) basis. This letter reframes electromagnetic modeling around a learnable basis representation rather than solving for the coefficients over a fixed basis. We first show that the RWG basis is essentially a static and piecewise-linear realization of the Kolmogorov-Arnold representation theorem. Inspired by this insight, we propose PhyKAN, a physics-informed Kolmogorov-Arnold Network (KAN) that generalizes RWG into a learnable and adaptive basis family. Derived from the EFIE, PhyKAN integrates a local KAN branch with a global branch embedded with Green's function priors to preserve physical consistency. It is demonstrated that, across canonical geometries, PhyKAN achieves sub-0.01 reconstruction errors as well as accurate, unsupervised radar cross section predictions, offering an interpretable, physics-consistent bridge between classical solvers and modern neural network models for electromagnetic modeling.", 'abstract_zh': 'PhyKAN：基于物理信息的Kolmogorov-Arnold网络在电磁建模中的应用', 'title_zh': '学习基函数：Kolmogorov-Arnold 网络方法嵌入格林函数先验'}
{'arxiv_id': 'arXiv:2511.08654', 'title': "AI-generated podcasts: Synthetic Intimacy and Cultural Translation in NotebookLM's Audio Overviews", 'authors': 'Jill Walker Rettberg', 'link': 'https://arxiv.org/abs/2511.08654', 'abstract': "This paper analyses AI-generated podcasts produced by Google's NotebookLM, which generates audio podcasts with two chatty AI hosts discussing whichever documents a user uploads. While AI-generated podcasts have been discussed as tools, for instance in medical education, they have not yet been analysed as media. By uploading different types of text and analysing the generated outputs I show how the podcasts' structure is built around a fixed template. I also find that NotebookLM not only translates texts from other languages into a perky standardised Mid-Western American accent, it also translates cultural contexts to a white, educated, middle-class American default. This is a distinct development in how publics are shaped by media, marking a departure from the multiple public spheres that scholars have described in human podcasting from the early 2000s until today, where hosts spoke to specific communities and responded to listener comments, to an abstraction of the podcast genre.", 'abstract_zh': '本研究分析了由Google的NotebookLM生成的AI播客，该系统生成包含两位聊天式AI主持人讨论用户上传文档的音频播客。虽然AI生成的播客已在诸如医学教育等领域被用作工具，但它们尚未被作为媒体进行分析。通过上传不同类型的文本并分析生成的输出，本文展示了播客结构如何围绕固定模板构建。此外，我发现在将其他语言的文本翻译成典型的中西部美国口音的同时，NotebookLM还将文化背景翻译为白人、受过教育的中产阶级美国默认模式。这是一种在公共空间由媒体塑造方面的新发展，标志着与自2000年代初至今人类播客所描述的多个公共领域形态的分离，从主持人面向特定社区并与听众交流，转变为播客类型的抽象化。', 'title_zh': 'AI生成的播客：NotebookLM音频概述中的合成亲密感与文化翻译'}
{'arxiv_id': 'arXiv:2511.08653', 'title': 'Accelerating Training Speed of Tiny Recursive Models via Curriculum Guided Adaptive Recursion', 'authors': 'Kaleem Ullah Qasim, Jiashu Zhang', 'link': 'https://arxiv.org/abs/2511.08653', 'abstract': 'Recursive reasoning models achieve remarkable performance on complex reasoning tasks through iterative refinement, enabling tiny networks to match large language models thousands of times their size. However, training remains computationally expensive, prior work reporting approximately 36 GPU-hours per dataset, limiting broader adoption and research. We propose CGAR, a novel training methodology that applies curriculum learning to architectural depth rather than traditional data ordering. CGAR introduces two synergistic components: Progressive Depth Curriculum dynamically adjusts recursion depth from shallow to deep configurations during training, preventing early overfitting while reducing computational cost, and Hierarchical Supervision Weighting applies exponentially decaying importance to supervision steps, aligning loss weighting with observed gradient magnitude decay. On Sudoku-Extreme with 423,168 test puzzles, CGAR achieves 1.71x training speedup (10.93 to 6.38 hours, 42% cost reduction) with only 0.63% accuracy drop (86.65% to 86.02%). Systematic ablations reveal Progressive Depth Curriculum alone achieves 2.26x speedup with 85.47% accuracy, demonstrating a rare Pareto improvement where architectural curriculum simultaneously enhances training efficiency and solution quality. CGAR-trained models exhibit superior inference efficiency with 100% halting accuracy and 11% fewer reasoning steps. Our work demonstrates that principled curriculum on architectural depth enables efficient training of recursive reasoning models on modest hardware. Code and models: this https URL and this https URL', 'abstract_zh': 'Recursive推理模型通过迭代优化在复杂推理任务中表现出色，使小型网络能够匹配合其数千倍大的语言模型。然而，训练依然计算成本高昂，先前工作报告每个数据集大约需要36个GPU小时，限制了更广泛的应用和研究。我们提出了CGAR，一种新颖的训练方法，该方法将课程学习应用于架构深度而非传统的数据排序。CGAR引入了两个协同工作的组件：渐进深度课程在训练过程中动态调整递归深度，从浅层到深层配置，防止早期过拟合并降低计算成本；分层监督加权应用指数衰减的重要性权重，使损失权重与观察到的梯度幅度衰减相一致。在包含423,168个测试数独谜题的Sudoku-Extreme数据集上，CGAR实现了1.71倍的训练速度提升（从10.93小时减少到6.38小时，成本降低42%），同时只降低了0.63%的准确率（从86.65%下降到86.02%）。系统性的消融实验表明，仅渐进深度课程即可实现2.26倍的速度提升，并且准确率达到85.47%，显示出一种罕见的帕累托改进，其中架构课程同时提升了训练效率和解的质量。CGAR训练的模型在推理效率方面表现出色，准确率达到100%，推理步骤减少11%。我们的工作表明，基于架构深度的原则性课程学习能够在 modest 硬件上有效训练递归推理模型。代码和模型：此链接和此链接。', 'title_zh': '基于 Curriculum 引导自适应递归加速 Tiny 递归模型训练速度'}
{'arxiv_id': 'arXiv:2511.08651', 'title': 'RS-Net: Context-Aware Relation Scoring for Dynamic Scene Graph Generation', 'authors': 'Hae-Won Jo, Yeong-Jun Cho', 'link': 'https://arxiv.org/abs/2511.08651', 'abstract': 'Dynamic Scene Graph Generation (DSGG) models how object relations evolve over time in videos. However, existing methods are trained only on annotated object pairs and lack guidance for non-related pairs, making it difficult to identify meaningful relations during inference. In this paper, we propose Relation Scoring Network (RS-Net), a modular framework that scores the contextual importance of object pairs using both spatial interactions and long-range temporal context. RS-Net consists of a spatial context encoder with learnable context tokens and a temporal encoder that aggregates video-level information. The resulting relation scores are integrated into a unified triplet scoring mechanism to enhance relation prediction. RS-Net can be easily integrated into existing DSGG models without architectural changes. Experiments on the Action Genome dataset show that RS-Net consistently improves both Recall and Precision across diverse baselines, with notable gains in mean Recall, highlighting its ability to address the long-tailed distribution of relations. Despite the increased number of parameters, RS-Net maintains competitive efficiency, achieving superior performance over state-of-the-art methods.', 'abstract_zh': '关系评分网络（RS-Net）：一种用于动态场景图生成的模块化框架', 'title_zh': 'RS-Net: 基于上下文的关系评分方法用于动态场景图生成'}
{'arxiv_id': 'arXiv:2511.08649', 'title': 'Bio AI Agent: A Multi-Agent Artificial Intelligence System for Autonomous CAR-T Cell Therapy Development with Integrated Target Discovery, Toxicity Prediction, and Rational Molecular Design', 'authors': 'Yi Ni, Liwei Zhu, Shuai Li', 'link': 'https://arxiv.org/abs/2511.08649', 'abstract': 'Chimeric antigen receptor T-cell (CAR-T) therapy represents a paradigm shift in cancer treatment, yet development timelines of 8-12 years and clinical attrition rates exceeding 40-60% highlight critical inefficiencies in target selection, safety assessment, and molecular optimization. We present Bio AI Agent, a multi-agent artificial intelligence system powered by large language models that enables autonomous CAR-T development through collaborative specialized agents. The system comprises six autonomous agents: Target Selection Agent for multi-parametric antigen prioritization across >10,000 cancer-associated targets, Toxicity Prediction Agent for comprehensive safety profiling integrating tissue expression atlases and pharmacovigilance databases, Molecular Design Agent for rational CAR engineering, Patent Intelligence Agent for freedom-to-operate analysis, Clinical Translation Agent for regulatory compliance, and Decision Orchestration Agent for multi-agent coordination. Retrospective validation demonstrated autonomous identification of high-risk targets including FcRH5 (hepatotoxicity) and CD229 (off-tumor toxicity), patent infringement risks for CD38+SLAMF7 combinations, and generation of comprehensive development roadmaps. By enabling parallel processing, specialized reasoning, and autonomous decision-making superior to monolithic AI systems, Bio AI Agent addresses critical gaps in precision oncology development and has potential to accelerate translation of next-generation immunotherapies from discovery to clinic.', 'abstract_zh': 'Bio AI代理：一种多智能体人工智能系统，推动CAR-T疗法自主开发', 'title_zh': '生物AI代理：一种集成靶点发现、毒性预测和理性分子设计的自主CAR-T细胞疗法开发多智能体人工智能系统'}
{'arxiv_id': 'arXiv:2511.08645', 'title': 'Fluence Map Prediction with Deep Learning: A Transformer-based Approach', 'authors': 'Ujunwa Mgboh, Rafi Sultan, Dongxiao Zhu, Joshua Kim', 'link': 'https://arxiv.org/abs/2511.08645', 'abstract': 'Accurate fluence map prediction is essential in intensity-modulated radiation therapy (IMRT) to maximize tumor coverage while minimizing dose to healthy tissues. Conventional optimization is time-consuming and dependent on planner expertise. This study presents a deep learning framework that accelerates fluence map generation while maintaining clinical quality. An end-to-end 3D Swin-UNETR network was trained to predict nine-beam fluence maps directly from volumetric CT images and anatomical contours using 99 prostate IMRT cases (79 for training and 20 for testing). The transformer-based model employs hierarchical self-attention to capture both local anatomical structures and long-range spatial dependencies. Predicted fluence maps were imported into the Eclipse Treatment Planning System for dose recalculation, and model performance was evaluated using beam-wise fluence correlation, spatial gamma analysis, and dose-volume histogram (DVH) metrics. The proposed model achieved an average R^2 of 0.95 +/- 0.02, MAE of 0.035 +/- 0.008, and gamma passing rate of 85 +/- 10 percent (3 percent / 3 mm) on the test set, with no significant differences observed in DVH parameters between predicted and clinical plans. The Swin-UNETR framework enables fully automated, inverse-free fluence map prediction directly from anatomical inputs, enhancing spatial coherence, accuracy, and efficiency while offering a scalable and consistent solution for automated IMRT plan generation.', 'abstract_zh': '准确的剂量分布图预测是强度调制放射治疗（IMRT）中的关键，旨在最大化肿瘤覆盖同时减少对健康组织的剂量。传统优化耗时且依赖计划员的专业知识。本研究提出一种深度学习框架，以加速剂量分布图的生成并保持临床质量。基于Transformer的端到端3D Swin-UNETR网络被训练从体素CT图像和解剖轮廓直接预测九束剂量分布图，使用99例前列腺IMRT病例（79例用于训练，20例用于测试）。该模型采用层级自注意力机制捕捉局部解剖结构和长程空间依赖性。预测的剂量分布图导入Eclipse治疗计划系统进行剂量重算，并通过束级剂量分布相关性、空间伽马分析和剂量体积直方图（DVH）指标评估模型性能。在测试集上，所提出模型的平均R²为0.95 ± 0.02，平均绝对误差（MAE）为0.035 ± 0.008，85 ± 10%（3% / 3 mm）的伽马通过率，预测和临床计划的DVH参数无显著差异。Swin-UNETR框架直接从解剖输入中实现全自动、无逆向的剂量分布图预测，增强空间一致性、准确性和效率，提供一种可扩展且一致的自动IMRT计划生成解决方案。', 'title_zh': '基于Transformer的深度学习照射剂量分布预测方法'}
{'arxiv_id': 'arXiv:2511.08644', 'title': 'Energy Consumption of Dataframe Libraries for End-to-End Deep Learning Pipelines:A Comparative Analysis', 'authors': 'Punit Kumar, Asif Imran, Tevfik Kosar', 'link': 'https://arxiv.org/abs/2511.08644', 'abstract': 'This paper presents a detailed comparative analysis of the performance of three major Python data manipulation libraries - Pandas, Polars, and Dask - specifically when embedded within complete deep learning (DL) training and inference pipelines. The research bridges a gap in existing literature by studying how these libraries interact with substantial GPU workloads during critical phases like data loading, preprocessing, and batch feeding. The authors measured key performance indicators including runtime, memory usage, disk usage, and energy consumption (both CPU and GPU) across various machine learning models and datasets.', 'abstract_zh': '本研究详细比较分析了三种主要的Python数据 manipulation 库——Pandas、Polars和Dask，在嵌入完整的深度学习（DL）训练和推理pipeline中的性能，特别是研究了这些库在数据加载、预处理和批次喂入等关键阶段与大规模GPU工作负载的交互情况。研究人员针对各种机器学习模型和数据集，衡量了包括运行时间、内存使用、磁盘使用和能耗（CPU和GPU）在内的关键性能指标。', 'title_zh': '数据框架库在端到端深度学习管道中的能耗比较分析'}
{'arxiv_id': 'arXiv:2511.08640', 'title': 'Predict and Resist: Long-Term Accident Anticipation under Sensor Noise', 'authors': 'Xingcheng Liu, Bin Rao, Yanchen Guan, Chengyue Wang, Haicheng Liao, Jiaxun Zhang, Chengyu Lin, Meixin Zhu, Zhenning Li', 'link': 'https://arxiv.org/abs/2511.08640', 'abstract': 'Accident anticipation is essential for proactive and safe autonomous driving, where even a brief advance warning can enable critical evasive actions. However, two key challenges hinder real-world deployment: (1) noisy or degraded sensory inputs from weather, motion blur, or hardware limitations, and (2) the need to issue timely yet reliable predictions that balance early alerts with false-alarm suppression. We propose a unified framework that integrates diffusion-based denoising with a time-aware actor-critic model to address these challenges. The diffusion module reconstructs noise-resilient image and object features through iterative refinement, preserving critical motion and interaction cues under sensor degradation. In parallel, the actor-critic architecture leverages long-horizon temporal reasoning and time-weighted rewards to determine the optimal moment to raise an alert, aligning early detection with reliability. Experiments on three benchmark datasets (DAD, CCD, A3D) demonstrate state-of-the-art accuracy and significant gains in mean time-to-accident, while maintaining robust performance under Gaussian and impulse noise. Qualitative analyses further show that our model produces earlier, more stable, and human-aligned predictions in both routine and highly complex traffic scenarios, highlighting its potential for real-world, safety-critical deployment.', 'abstract_zh': '基于去噪扩散和时间意识的actor-critic模型的事故预判统一框架', 'title_zh': '预测与抵抗：传感器噪声下的长期事故预判'}
{'arxiv_id': 'arXiv:2511.08639', 'title': 'The Journal of Prompt-Engineered Philosophy Or: How I Started to Track AI Assistance and Stopped Worrying About Slop', 'authors': 'Michele Loi', 'link': 'https://arxiv.org/abs/2511.08639', 'abstract': 'Academic publishing increasingly requires authors to disclose AI assistance, yet imposes reputational costs for doing so--especially when such assistance is substantial. This article analyzes that structural contradiction, showing how incentives discourage transparency in precisely the work where it matters most. Traditional venues cannot resolve this tension through policy tweaks alone, as the underlying prestige economy rewards opacity. To address this, the article proposes an alternative publishing infrastructure: a venue outside prestige systems that enforces mandatory disclosure, enables reproduction-based review, and supports ecological validity through detailed documentation. As a demonstration of this approach, the article itself is presented as an example of AI-assisted scholarship under reasonably detailed disclosure, with representative prompt logs and modification records included. Rather than taking a position for or against AI-assisted scholarship, the article outlines conditions under which such work can be evaluated on its own terms: through transparent documentation, verification-oriented review, and participation by methodologically committed scholars. While focused on AI, the framework speaks to broader questions about how academic systems handle methodological innovation.', 'abstract_zh': '学术出版日益要求作者披露AI辅助，但披露反而会带来声誉成本——尤其是在这种辅助相当显著的情况下。本文分析了这一结构性矛盾，展示了激励机制如何在最为需要透明度的工作中抑制透明度。传统出版平台通过政策微调无法解决这一矛盾，因为基础的声望机制奖励 opacity。为此，本文提出了一种替代的出版基础设施：一个位于声望体系之外的平台，强制要求披露、支持基于再现的评审，并通过详细的文档支持生态效度。作为这一方法的示范，本文本身就被呈现为合理详细披露下的AI辅助研究的一个例子，附有代表性的提示日志和修改记录。本文不赞成或反对AI辅助研究，而是概述了在这种研究中可以自我评价的条件：通过透明的文档、基于验证的评审和方法论承诺学者的参与。尽管专注于AI，但这一框架涉及更广泛的关于学术系统如何处理方法创新的问题。', 'title_zh': '《促进型哲学杂志：或是我如何开始追踪AI协助并停止担心粗糙部分内容》'}
{'arxiv_id': 'arXiv:2511.08637', 'title': 'How do data owners say no? A case study of data consent mechanisms in web-scraped vision-language AI training datasets', 'authors': 'Chung Peng Lee, Rachel Hong, Harry Jiang, Aster Plotnik, William Agnew, Jamie Morgenstern', 'link': 'https://arxiv.org/abs/2511.08637', 'abstract': "The internet has become the main source of data to train modern text-to-image or vision-language models, yet it is increasingly unclear whether web-scale data collection practices for training AI systems adequately respect data owners' wishes. Ignoring the owner's indication of consent around data usage not only raises ethical concerns but also has recently been elevated into lawsuits around copyright infringement cases. In this work, we aim to reveal information about data owners' consent to AI scraping and training, and study how it's expressed in DataComp, a popular dataset of 12.8 billion text-image pairs. We examine both the sample-level information, including the copyright notice, watermarking, and metadata, and the web-domain-level information, such as a site's Terms of Service (ToS) and Robots Exclusion Protocol. We estimate at least 122M of samples exhibit some indication of copyright notice in CommonPool, and find that 60\\% of the samples in the top 50 domains come from websites with ToS that prohibit scraping. Furthermore, we estimate 9-13\\% with 95\\% confidence interval of samples from CommonPool to contain watermarks, where existing watermark detection methods fail to capture them in high fidelity. Our holistic methods and findings show that data owners rely on various channels to convey data consent, of which current AI data collection pipelines do not entirely respect. These findings highlight the limitations of the current dataset curation/release practice and the need for a unified data consent framework taking AI purposes into consideration.", 'abstract_zh': '互联网已成为训练现代文本-to-图像或视觉-语言模型的主要数据来源，但日益不清楚大规模网络数据采集实践是否充分尊重数据所有者的意愿。忽视数据使用时的数据主人同意 indication不仅引发了伦理上的关切，近年来还在版权侵权诉讼中被提升为法律诉讼。在本项工作中，我们旨在揭示数据主人对AI抓取和训练的数据使用的同意信息，并研究这些信息如何在 DataComp 这一流行的包含128亿对文本-图像的数据集中表达。我们检查了样本级别信息，包括版权通知、水印和元数据，以及网站级别信息，如网站的服务条款 (ToS) 和robots排除协议。我们估计至少有1.22亿样本在CommonPool中表现出某种版权通知的迹象，并发现排名前50的网站中，60%的样本来自禁止抓取的服务条款网站。此外，我们估计95%置信区间内，9-13%的CommonPool样本包含水印，而现有的水印检测方法未能高保真地捕捉到这些水印。我们的综合方法和发现表明，数据主人通过多种渠道传达数据使用同意，而当前的AI数据采集管道并未完全尊重这些同意。这些发现凸显了当前数据集编目/发布实践的局限性，并强调了需要考虑AI用途的统一数据同意框架的必要性。', 'title_zh': '数据拥有者如何说“不”？基于网页抓取的视觉-语言AI训练数据集中的数据同意机制案例研究'}
{'arxiv_id': 'arXiv:2511.08636', 'title': 'Detecting Suicidal Ideation in Text with Interpretable Deep Learning: A CNN-BiGRU with Attention Mechanism', 'authors': 'Mohaiminul Islam Bhuiyan, Nur Shazwani Kamarudin, Nur Hafieza Ismail', 'link': 'https://arxiv.org/abs/2511.08636', 'abstract': 'Worldwide, suicide is the second leading cause of death for adolescents with past suicide attempts to be an important predictor for increased future suicides. While some people with suicidal thoughts may try to suppress them, many signal their intentions in social media platforms. To address these issues, we propose a new type of hybrid deep learning scheme, i.e., the combination of a CNN architecture and a BiGRU technique, which can accurately identify the patterns of suicidal ideation from SN datasets. Also, we apply Explainable AI methods using SHapley Additive exPlanations to interpret the prediction results and verifying the model reliability. This integration of CNN local feature extraction, BiGRU bidirectional sequence modeling, attention mechanisms, and SHAP interpretability provides a comprehensive framework for suicide detection. Training and evaluation of the system were performed on a publicly available dataset. Several performance metrics were used for evaluating model performance. Our method was found to have achieved 93.97 accuracy in experimental results. Comparative study to different state-of-the-art Machine Learning and DL models and existing literature demonstrates the superiority of our proposed technique over all the competing methods.', 'abstract_zh': '全球范围内，自杀是青少年死亡的第二大致死原因， past suicide attempts 是未来自杀风险增加的重要预测指标。尽管一些存在自杀念头的人可能试图抑制这些念头，但许多人在社交媒体平台上会信号其意图。为应对这些问题，我们提出了一种新的混合深度学习方案，即 CNN 架构与 BiGRU 技术的结合，可以从 SN 数据集准确识别自杀念头的模式。同时，我们采用了解释性 AI 方法（SHapley Additive exPlanations）来解释预测结果并验证模型可靠性。这一方案综合了 CNN 局部特征提取、BiGRU 双向序列建模、注意力机制和 SHAP 可解释性，提供了全面的自杀检测框架。系统在公开可用的数据集上进行了训练和评估，并使用多种性能指标评估了模型性能。实验结果显示，我们的方法达到了 93.97% 的准确率。与现有的最佳机器学习和深度学习模型及文献进行对比研究，证明了我们提出的技术在所有竞争方法中更优越。', 'title_zh': '基于可解释深度学习的文本自杀意念检测：带有注意力机制的CNN-BiGRU'}
{'arxiv_id': 'arXiv:2511.08634', 'title': 'CADIC: Continual Anomaly Detection Based on Incremental Coreset', 'authors': 'Gen Yang, Zhipeng Deng, Junfeng Man', 'link': 'https://arxiv.org/abs/2511.08634', 'abstract': 'The primary objective of Continual Anomaly Detection (CAD) is to learn the normal patterns of new tasks under dynamic data distribution assumptions while mitigating catastrophic forgetting. Existing embedding-based CAD approaches continuously update a memory bank with new embeddings to adapt to sequential tasks. However, these methods require constructing class-specific sub-memory banks for each task, which restricts their flexibility and scalability. To address this limitation, we propose a novel CAD framework where all tasks share a unified memory bank. During training, the method incrementally updates embeddings within a fixed-size coreset, enabling continuous knowledge acquisition from sequential tasks without task-specific memory fragmentation. In the inference phase, anomaly scores are computed via a nearest-neighbor matching mechanism, achieving state-of-the-art detection accuracy. We validate the method through comprehensive experiments on MVTec AD and Visa datasets. Results show that our approach outperforms existing baselines, achieving average image-level AUROC scores of 0.972 (MVTec AD) and 0.891 (Visa). Notably, on a real-world electronic paper dataset, it demonstrates 100% accuracy in anomaly sample detection, confirming its robustness in practical scenarios. The implementation will be open-sourced on GitHub.', 'abstract_zh': '持续异常检测（CAD）的主要目标是在动态数据分布假设下学习新任务的正常模式，同时减轻灾难性遗忘。现有的基于嵌入的CAD方法通过不断更新内存库以适应序列任务。然而，这些方法需要为每个任务构建特定类别的子内存库，这限制了它们的灵活性和扩展性。为了解决这一局限性，我们提出了一种新颖的CAD框架，其中所有任务共享一个统一的内存库。在训练过程中，该方法逐步更新固定大小的核心集中的嵌入，能够在不特定任务内存碎片化的情况下持续获取知识。在推理阶段，异常得分通过最近邻匹配机制计算，实现了最先进的检测精度。我们通过在MVTec AD和Visa数据集上的全面实验验证了该方法。结果显示，我们的方法优于现有基线，平均图像级AUROC得分为0.972（MVTec AD）和0.891（Visa）。值得注意的是，在一个实际的电子纸数据集上，它实现了100%的异常样本检测准确性，证实了其在实际场景中的鲁棒性。该实施将在GitHub上公开发布。', 'title_zh': 'CADIC：基于增量核心集的持续异常检测'}
{'arxiv_id': 'arXiv:2511.08633', 'title': 'Time-to-Move: Training-Free Motion Controlled Video Generation via Dual-Clock Denoising', 'authors': 'Assaf Singer, Noam Rotstein, Amir Mann, Ron Kimmel, Or Litany', 'link': 'https://arxiv.org/abs/2511.08633', 'abstract': "Diffusion-based video generation can create realistic videos, yet existing image- and text-based conditioning fails to offer precise motion control. Prior methods for motion-conditioned synthesis typically require model-specific fine-tuning, which is computationally expensive and restrictive. We introduce Time-to-Move (TTM), a training-free, plug-and-play framework for motion- and appearance-controlled video generation with image-to-video (I2V) diffusion models. Our key insight is to use crude reference animations obtained through user-friendly manipulations such as cut-and-drag or depth-based reprojection. Motivated by SDEdit's use of coarse layout cues for image editing, we treat the crude animations as coarse motion cues and adapt the mechanism to the video domain. We preserve appearance with image conditioning and introduce dual-clock denoising, a region-dependent strategy that enforces strong alignment in motion-specified regions while allowing flexibility elsewhere, balancing fidelity to user intent with natural dynamics. This lightweight modification of the sampling process incurs no additional training or runtime cost and is compatible with any backbone. Extensive experiments on object and camera motion benchmarks show that TTM matches or exceeds existing training-based baselines in realism and motion control. Beyond this, TTM introduces a unique capability: precise appearance control through pixel-level conditioning, exceeding the limits of text-only prompting. Visit our project page for video examples and code: this https URL.", 'abstract_zh': '基于扩散的视频生成可以创建逼真视频，但现有的图像和文本条件控制无法提供精确的运动控制。先前的运动条件合成方法通常需要特定模型的微调，这在计算上昂贵且限制性。我们引入了Time-to-Move（TTM），这是一种无需训练、即插即用的框架，用于以图像到视频（I2V）扩散模型为基础进行运动和外观控制的视频生成。我们的核心见解是使用通过友好操作（如剪切拖动或深度重投影）获得的粗略参考动画。受SDEdit利用粗略布局提示进行图像编辑的启发，我们将粗略动画视为粗略运动提示，并将机制适应到视频领域。我们通过图像条件保留外观，并引入区域依赖性的双重时钟去噪策略，该策略在运动指定区域强制执行强对齐，而在其他地方允许灵活性，在用户意图的忠实性和自然动力之间取得平衡。这一轻量级的采样过程修改无需额外的训练或运行时开销，并且与任何骨干兼容。在对象和相机运动基准上的广泛实验表明，TTM在逼真度和运动控制方面与现有的基于训练的基础方法相当或超过。此外，TTM引入了一种独特的能力：通过像素级条件进行精确的外观控制，超越了纯文本提示的局限。访问我们的项目页面查看视频示例和代码：this https URL。', 'title_zh': '停留时间：基于双时钟去噪的无训练移动控制视频生成'}
{'arxiv_id': 'arXiv:2511.08630', 'title': 'Hope, Aspirations, and the Impact of LLMs on Female Programming Learners in Afghanistan', 'authors': 'Hamayoon Behmanush, Freshta Akhtari, Roghieh Nooripour, Ingmar Weber, Vikram Kamath Cannanure', 'link': 'https://arxiv.org/abs/2511.08630', 'abstract': "Designing impactful educational technologies in contexts of socio-political instability requires a nuanced understanding of educational aspirations. Currently, scalable metrics for measuring aspirations are limited. This study adapts, translates, and evaluates Snyder's Hope Scale as a metric for measuring aspirations among 136 women learning programming online during a period of systemic educational restrictions in Afghanistan. The adapted scale demonstrated good reliability (Cronbach's {\\alpha} = 0.78) and participants rated it as understandable and relevant. While overall aspiration-related scores did not differ significantly by access to Large Language Models (LLMs), those with access reported marginally higher scores on the Avenues subscale (p = .056), suggesting broader perceived pathways to achieving educational aspirations. These findings support the use of the adapted scale as a metric for aspirations in contexts of socio-political instability. More broadly, the adapted scale can be used to evaluate the impact of aspiration-driven design of educational technologies.", 'abstract_zh': '在社会政治不稳定背景下设计影响深远的教育技术需要对教育抱负有细致的理解。本研究适应、翻译并评估Snyder的希望量表，作为衡量阿富汗系统性教育限制期间136名在线学习编程女性抱负的指标。适应后的量表显示良好的信度（Cronbach’s α = 0.78），参与者认为其易于理解且相关。虽然总体抱负相关得分在大型语言模型（LLMs）访问权限方面未见显著差异，但有访问权限的参与者在路径子量表上的得分略高（p = .056），表明更广泛的实现教育抱负的感知途径。这些发现支持在社会政治不稳定背景下使用适应后的量表作为测量抱负的指标。更广泛地说，适应后的量表可用于评估以抱负为导向的教育技术设计的影响。', 'title_zh': '希望、抱负与大语言模型对阿富汗女性编程学习者的影响'}
{'arxiv_id': 'arXiv:2511.08628', 'title': 'Learning Topology-Driven Multi-Subspace Fusion for Grassmannian Deep Network', 'authors': 'Xuan Yu, Tianyang Xu', 'link': 'https://arxiv.org/abs/2511.08628', 'abstract': 'Grassmannian manifold offers a powerful carrier for geometric representation learning by modelling high-dimensional data as low-dimensional subspaces. However, existing approaches predominantly rely on static single-subspace representations, neglecting the dynamic interplay between multiple subspaces critical for capturing complex geometric structures. To address this limitation, we propose a topology-driven multi-subspace fusion framework that enables adaptive subspace collaboration on the Grassmannian. Our solution introduces two key innovations: (1) Inspired by the Kolmogorov-Arnold representation theorem, an adaptive multi-subspace modelling mechanism is proposed that dynamically selects and weights task-relevant subspaces via topological convergence analysis, and (2) a multi-subspace interaction block that fuses heterogeneous geometric representations through Fréchet mean optimisation on the manifold. Theoretically, we establish the convergence guarantees of adaptive subspaces under a projection metric topology, ensuring stable gradient-based optimisation. Practically, we integrate Riemannian batch normalisation and mutual information regularisation to enhance discriminability and robustness. Extensive experiments on 3D action recognition (HDM05, FPHA), EEG classification (MAMEM-SSVEPII), and graph tasks demonstrate state-of-the-art performance. Our work not only advances geometric deep learning but also successfully adapts the proven multi-channel interaction philosophy of Euclidean networks to non-Euclidean domains, achieving superior discriminability and interpretability.', 'abstract_zh': 'Grassmannian流形提供了一种强大的几何表示学习载体，通过将高维数据建模为低维子空间。然而，现有方法主要依赖于静态单一子空间表示，忽略了捕捉复杂几何结构时多个子空间之间的动态交互。为解决这一限制，我们提出了一种基于拓扑的多子空间融合框架，能够在Grassmannian上实现自适应子空间协作。我们的解决方案引入了两项关键创新：（1）受柯尔莫哥洛夫-阿诺尔德表示定理启发，提出了一种自适应的多子空间建模机制，通过拓扑收敛分析动态选择和加权任务相关子空间；（2）通过流形上的Fréchet均值优化实现异构几何表示的融合模块。理论上，我们在投影度量拓扑下建立了自适应子空间的收敛保证，确保稳定的梯度优化。实践中，我们结合黎曼批量归一化和互信息正则化以增强可分性和鲁棒性。在3D动作识别（HDM05, FPHA）、EEG分类（MAMEM-SSVEPII）和图任务上进行的广泛实验显示了最先进的性能。我们的工作不仅推动了几何深度学习的发展，还成功地将欧几里得网络的多通道交互理念应用于非欧几里得领域，实现了更好的可分性和可解释性。', 'title_zh': '基于流形驱动的多子空间融合的格拉斯曼深度网络学习'}
{'arxiv_id': 'arXiv:2511.08626', 'title': 'SAMora: Enhancing SAM through Hierarchical Self-Supervised Pre-Training for Medical Images', 'authors': 'Shuhang Chen, Hangjie Yuan, Pengwei Liu, Hanxue Gu, Tao Feng, Dong Ni', 'link': 'https://arxiv.org/abs/2511.08626', 'abstract': 'The Segment Anything Model (SAM) has demonstrated significant potential in medical image segmentation. Yet, its performance is limited when only a small amount of labeled data is available, while there is abundant valuable yet often overlooked hierarchical information in medical data. To address this limitation, we draw inspiration from self-supervised learning and propose SAMora, an innovative framework that captures hierarchical medical knowledge by applying complementary self-supervised learning objectives at the image, patch, and pixel levels. To fully exploit the complementarity of hierarchical knowledge within LoRAs, we introduce HL-Attn, a hierarchical fusion module that integrates multi-scale features while maintaining their distinct characteristics. SAMora is compatible with various SAM variants, including SAM2, SAMed, and H-SAM. Experimental results on the Synapse, LA, and PROMISE12 datasets demonstrate that SAMora outperforms existing SAM variants. It achieves state-of-the-art performance in both few-shot and fully supervised settings while reducing fine-tuning epochs by 90%. The code is available at this https URL.', 'abstract_zh': 'SAMora：基于层次自监督学习的医学图像分割模型', 'title_zh': 'SAMora：通过分层自我监督预训练增强SAM用于医学图像处理'}
{'arxiv_id': 'arXiv:2511.08625', 'title': 'Cross-Field Interface-Aware Neural Operators for Multiphase Flow Simulation', 'authors': 'ZhenZhong Wang, Xin Zhang, Jun Liao, Min Jiang', 'link': 'https://arxiv.org/abs/2511.08625', 'abstract': 'Multiphase flow systems, with their complex dynamics, field discontinuities, and interphase interactions, pose significant computational challenges for traditional numerical solvers. While neural operators offer efficient alternatives, they often struggle to achieve high-resolution numerical accuracy in these systems. This limitation primarily stems from the inherent spatial heterogeneity and the scarcity of high-quality training data in multiphase flows. In this work, we propose the Interface Information-Aware Neural Operator (IANO), a novel framework that explicitly leverages interface information as a physical prior to enhance the prediction accuracy. The IANO architecture introduces two key components: 1) An interface-aware multiple function encoding mechanism jointly models multiple physical fields and interfaces, thus capturing the high-frequency physical features at the interface. 2) A geometry-aware positional encoding mechanism further establishes the relationship between interface information, physical variables, and spatial positions, enabling it to achieve pointwise super-resolution prediction even in the low-data regimes. Experimental results demonstrate that IANO outperforms baselines by $\\sim$10\\% in accuracy for multiphase flow simulations while maintaining robustness under data-scarce and noise-perturbed conditions.', 'abstract_zh': '具有界面信息感知的神经算子（IANO）：一种增强相变流动模拟预测准确性的新型框架', 'title_zh': '考虑交叉场接口的神经算子方法在多相流模拟中的应用'}
{'arxiv_id': 'arXiv:2511.08622', 'title': 'Multi-period Learning for Financial Time Series Forecasting', 'authors': 'Xu Zhang, Zhengang Huang, Yunzhi Wu, Xun Lu, Erpeng Qi, Yunkai Chen, Zhongya Xue, Qitong Wang, Peng Wang, Wei Wang', 'link': 'https://arxiv.org/abs/2511.08622', 'abstract': "Time series forecasting is important in finance domain. Financial time series (TS) patterns are influenced by both short-term public opinions and medium-/long-term policy and market trends. Hence, processing multi-period inputs becomes crucial for accurate financial time series forecasting (TSF). However, current TSF models either use only single-period input, or lack customized designs for addressing multi-period characteristics. In this paper, we propose a Multi-period Learning Framework (MLF) to enhance financial TSF performance. MLF considers both TSF's accuracy and efficiency requirements. Specifically, we design three new modules to better integrate the multi-period inputs for improving accuracy: (i) Inter-period Redundancy Filtering (IRF), that removes the information redundancy between periods for accurate self-attention modeling, (ii) Learnable Weighted-average Integration (LWI), that effectively integrates multi-period forecasts, (iii) Multi-period self-Adaptive Patching (MAP), that mitigates the bias towards certain periods by setting the same number of patches across all periods. Furthermore, we propose a Patch Squeeze module to reduce the number of patches in self-attention modeling for maximized efficiency. MLF incorporates multiple inputs with varying lengths (periods) to achieve better accuracy and reduces the costs of selecting input lengths during training. The codes and datasets are available at this https URL.", 'abstract_zh': '多时期学习框架在金融时间序列预测中的应用', 'title_zh': '多期学习在金融时间序列预测中的应用'}
{'arxiv_id': 'arXiv:2511.08621', 'title': 'The LLM Pro Finance Suite: Multilingual Large Language Models for Financial Applications', 'authors': 'Gaëtan Caillaut, Raheel Qader, Jingshu Liu, Mariam Nakhlé, Arezki Sadoune, Massinissa Ahmim, Jean-Gabriel Barthelemy', 'link': 'https://arxiv.org/abs/2511.08621', 'abstract': "The financial industry's growing demand for advanced natural language processing (NLP) capabilities has highlighted the limitations of generalist large language models (LLMs) in handling domain-specific financial tasks. To address this gap, we introduce the LLM Pro Finance Suite, a collection of five instruction-tuned LLMs (ranging from 8B to 70B parameters) specifically designed for financial applications. Our approach focuses on enhancing generalist instruction-tuned models, leveraging their existing strengths in instruction following, reasoning, and toxicity control, while fine-tuning them on a curated, high-quality financial corpus comprising over 50% finance-related data in English, French, and German.\nWe evaluate the LLM Pro Finance Suite on a comprehensive financial benchmark suite, demonstrating consistent improvement over state-of-the-art baselines in finance-oriented tasks and financial translation. Notably, our models maintain the strong general-domain capabilities of their base models, ensuring reliable performance across non-specialized tasks. This dual proficiency, enhanced financial expertise without compromise on general abilities, makes the LLM Pro Finance Suite an ideal drop-in replacement for existing LLMs in financial workflows, offering improved domain-specific performance while preserving overall versatility. We publicly release two 8B-parameters models to foster future research and development in financial NLP applications: this https URL.", 'abstract_zh': '金融行业对高级自然语言处理（NLP）能力的不断增长需求突显了通用大型语言模型（LLMs）在处理专门金融任务方面的局限性。为填补这一空白，我们介绍了LLM Pro Finance Suite，这是一个由五个指令调优的大语言模型组成的集合（参数范围从8B到70B），专门设计用于金融应用。我们的方法侧重于增强通用指令调优模型，利用其在指令遵循、推理和 toxicity 控制方面的现有优势，并在其上微调一个精心挑选的高质量金融语料库，该语料库包含超过50%的英文、法文和德文的金融相关数据。', 'title_zh': '多语言大型语言模型：Pro Finance Suite在金融应用中的探索'}
{'arxiv_id': 'arXiv:2511.08620', 'title': 'Learn More, Forget Less: A Gradient-Aware Data Selection Approach for LLM', 'authors': 'Yibai Liu, Shihang Wang, Zeming Liu, Zheming Song, Junzhe Wang, Jingjing Liu, Qingjie Liu, Yunhong Wang', 'link': 'https://arxiv.org/abs/2511.08620', 'abstract': "Despite large language models (LLMs) have achieved impressive achievements across numerous tasks, supervised fine-tuning (SFT) remains essential for adapting these models to specialized domains. However, SFT for domain specialization can be resource-intensive and sometimes leads to a deterioration in performance over general capabilities due to catastrophic forgetting (CF). To address these issues, we propose a self-adaptive gradient-aware data selection approach (GrADS) for supervised fine-tuning of LLMs, which identifies effective subsets of training data by analyzing gradients obtained from a preliminary training phase. Specifically, we design self-guided criteria that leverage the magnitude and statistical distribution of gradients to prioritize examples that contribute the most to the model's learning process. This approach enables the acquisition of representative samples that enhance LLMs understanding of domain-specific tasks. Through extensive experimentation with various LLMs across diverse domains such as medicine, law, and finance, GrADS has demonstrated significant efficiency and cost-effectiveness. Remarkably, utilizing merely 5% of the selected GrADS data, LLMs already surpass the performance of those fine-tuned on the entire dataset, and increasing to 50% of the data results in significant improvements! With catastrophic forgetting substantially mitigated simultaneously. We will release our code for GrADS later.", 'abstract_zh': '一种自适应梯度感知数据选择方法（GrADS）：用于大型语言模型的监督微调', 'title_zh': '学习更多，遗忘更少：一种基于梯度的数据选择方法用于大规模语言模型'}
{'arxiv_id': 'arXiv:2511.08616', 'title': 'Reasoning on Time-Series for Financial Technical Analysis', 'authors': 'Kelvin J.L. Koa, Jan Chen, Yunshan Ma, Huanhuan Zheng, Tat-Seng Chua', 'link': 'https://arxiv.org/abs/2511.08616', 'abstract': 'While Large Language Models have been used to produce interpretable stock forecasts, they mainly focus on analyzing textual reports but not historical price data, also known as Technical Analysis. This task is challenging as it switches between domains: the stock price inputs and outputs lie in the time-series domain, while the reasoning step should be in natural language. In this work, we introduce Verbal Technical Analysis (VTA), a novel framework that combine verbal and latent reasoning to produce stock time-series forecasts that are both accurate and interpretable. To reason over time-series, we convert stock price data into textual annotations and optimize the reasoning trace using an inverse Mean Squared Error (MSE) reward objective. To produce time-series outputs from textual reasoning, we condition the outputs of a time-series backbone model on the reasoning-based attributes. Experiments on stock datasets across U.S., Chinese, and European markets show that VTA achieves state-of-the-art forecasting accuracy, while the reasoning traces also perform well on evaluation by industry experts.', 'abstract_zh': 'VERBAL TECHNICAL ANALYSIS: A NOVEL FRAMEWORK FOR INTERPRETABLE STOCK TIME-SERIES FORECASTING', 'title_zh': '基于时间序列的金融技术分析推理'}
{'arxiv_id': 'arXiv:2511.08609', 'title': 'Case Study: Transformer-Based Solution for the Automatic Digitization of Gas Plants', 'authors': 'I. Bailo, F. Buonora, G. Ciarfaglia, L. T. Consoli, A. Evangelista, M. Gabusi, M. Ghiani, C. Petracca Ciavarella, F. Picariello, F. Sarcina, F. Tuosto, V. Zullo, L. Airoldi, G. Bruno, D. D. Gobbo, S. Pezzenati, G. A. Tona', 'link': 'https://arxiv.org/abs/2511.08609', 'abstract': "The energy transition is a key theme of the last decades to determine a future of eco-sustainability, and an area of such importance cannot disregard digitization, innovation and the new technological tools available. This is the context in which the Generative Artificial Intelligence models described in this paper are positioned, developed by Engineering Ingegneria Informatica SpA in order to automate the plant structures acquisition of SNAM energy infrastructure, a leading gas transportation company in Italy and Europe. The digitization of a gas plant consists in registering all its relevant information through the interpretation of the related documentation. The aim of this work is therefore to design an effective solution based on Artificial Intelligence techniques to automate the extraction of the information necessary for the digitization of a plant, in order to streamline the daily work of MGM users. The solution received the P&ID of the plant as input, each one in pdf format, and uses OCR, Vision LLM, Object Detection, Relational Reasoning and optimization algorithms to return an output consisting of two sets of information: a structured overview of the relevant design data and the hierarchical framework of the plant. To achieve convincing results, we extend a state-of-the-art model for Scene Graph Generation introducing a brand new Transformer architecture with the aim of deepening the analysis of the complex relations between the plant's components. The synergistic use of the listed AI-based technologies allowed to overcome many obstacles arising from the high variety of data, due to the lack of standardization. An accuracy of 91\\% has been achieved in the extraction of textual information relating to design data. Regarding the plants topology, 93\\% of components are correctly identified and the hierarchical structure is extracted with an accuracy around 80\\%.", 'abstract_zh': '能源转型是过去几十年中的一个关键主题，旨在实现生态可持续的未来，而这样一个重要的领域不能忽视数字化、创新和可用的新技术工具。本文中描述的生成式人工智能模型是由Engineering Ingegneria Informatica SpA开发的，旨在自动化SNAM能源基础设施的工厂结构获取，SNAM是一家意大利和欧洲领先的天然气运输公司。工厂的数字化是指通过解读相关文档来记录其所有相关信息。本文的目标是设计一个基于人工智能技术的有效解决方案，以自动化提取工厂数字化所需的信息，从而简化MGM用户的工作流程。该解决方案以工厂的P&ID作为输入，每个P&ID均为pdf格式，并使用OCR、Vision LLM、对象检测、关系推理和优化算法生成包含两部分信息的输出：结构化的设计数据概述以及工厂的层次框架。为了获得令人信服的结果，我们在最先进的场景图生成模型的基础上，引入了一种全新的Transformer架构，旨在深入分析工厂组件之间的复杂关系。所列的人工智能技术的协同使用，克服了由于缺乏标准化而导致的数据高度多样性的许多障碍。在设计数据的文本信息提取方面，准确率为91%。对于工厂的拓扑结构，93%的组件被正确识别，层次结构的提取准确率约为80%。', 'title_zh': '案例研究：基于Transformer的天然气处理厂自动数字化解决方案'}
{'arxiv_id': 'arXiv:2511.08606', 'title': 'Data-driven Feynman-Kac Discovery with Applications to Prediction and Data Generation', 'authors': 'Qi Feng, Guang Lin, Purav Matlia, Denny Serdarevic', 'link': 'https://arxiv.org/abs/2511.08606', 'abstract': 'In this paper, we propose a novel data-driven framework for discovering probabilistic laws underlying the Feynman-Kac formula. Specifically, we introduce the first stochastic SINDy method formulated under the risk-neutral probability measure to recover the backward stochastic differential equation (BSDE) from a single pair of stock and option trajectories. Unlike existing approaches to identifying stochastic differential equations-which typically require ergodicity-our framework leverages the risk-neutral measure, thereby eliminating the ergodicity assumption and enabling BSDE recovery from limited financial time series data. Using this algorithm, we are able not only to make forward-looking predictions but also to generate new synthetic data paths consistent with the underlying probabilistic law.', 'abstract_zh': '基于费曼-卡克公式的概率定律发现的新型数据驱动框架', 'title_zh': '基于数据驱动的费曼-卡克发现及其在预测和数据生成中的应用'}
{'arxiv_id': 'arXiv:2511.08598', 'title': 'OKBench: Democratizing LLM Evaluation with Fully Automated, On-Demand, Open Knowledge Benchmarking', 'authors': 'Yanhong Li, Tianyang Xu, Kenan Tang, Karen Livescu, David McAllester, Jiawei Zhou', 'link': 'https://arxiv.org/abs/2511.08598', 'abstract': 'Knowledge-intensive question answering is central to large language models (LLMs) and is typically assessed using static benchmarks derived from sources like Wikipedia and textbooks. However, these benchmarks fail to capture evolving knowledge in a dynamic world, and centralized curation struggles to keep pace with rapid LLM advancements. To address these drawbacks, we propose Open Knowledge Bench (OKBench), a fully automated framework for generating high-quality, dynamic knowledge benchmarks on demand. Focusing on the news domain where knowledge updates daily, OKBench is an agentic framework that automates the sourcing, creation, validation, and distribution of benchmarks. Our approach democratizes benchmark creation and facilitates thorough evaluation of retrieval-augmented methods by reducing overlap with pretraining data. We evaluate our framework on a wide range open-source and proprietary LLMs of various sizes and configurations, both with and without retrieval over freshly generated knowledge. Our results reveal distinct model behaviors when confronted with new information and highlight how retrieval narrows the performance gap between small and large models. These findings underscore the importance of evaluating LLMs on evolving knowledge benchmarks.', 'abstract_zh': '开放知识基准（OKBench）：一种自动生成高质量动态知识基准的自动化框架', 'title_zh': 'OKBench: 通过全自动、按需、开放的知识基准评估促进大语言模型 democratization'}
{'arxiv_id': 'arXiv:2511.08597', 'title': 'Self-HarmLLM: Can Large Language Model Harm Itself?', 'authors': 'Heehwan Kim, Sungjune Park, Daeseon Choi', 'link': 'https://arxiv.org/abs/2511.08597', 'abstract': "Large Language Models (LLMs) are generally equipped with guardrails to block the generation of harmful responses. However, existing defenses always assume that an external attacker crafts the harmful query, and the possibility of a model's own output becoming a new attack vector has not been sufficiently explored. In this study, we propose the Self-HarmLLM scenario, which uses a Mitigated Harmful Query (MHQ) generated by the same model as a new input. An MHQ is an ambiguous query whose original intent is preserved while its harmful nature is not directly exposed. We verified whether a jailbreak occurs when this MHQ is re-entered into a separate session of the same model. We conducted experiments on GPT-3.5-turbo, LLaMA3-8B-instruct, and DeepSeek-R1-Distill-Qwen-7B under Base, Zero-shot, and Few-shot conditions. The results showed up to 52% transformation success rate and up to 33% jailbreak success rate in the Zero-shot condition, and up to 65% transformation success rate and up to 41% jailbreak success rate in the Few-shot condition. By performing both prefix-based automated evaluation and human evaluation, we found that the automated evaluation consistently overestimated jailbreak success, with an average difference of 52%. This indicates that automated evaluation alone is not accurate for determining harmfulness. While this study is a toy-level study based on a limited query set and evaluators, it proves that our method can still be a valid attack scenario. These results suggest the need for a fundamental reconsideration of guardrail design and the establishment of a more robust evaluation methodology.", 'abstract_zh': 'Self-HarmLLM：探索模型自身输出作为新攻击向量的场景', 'title_zh': '自我伤害的大型语言模型：大型语言模型会自我伤害吗？'}
{'arxiv_id': 'arXiv:2511.08596', 'title': "What About the Scene with the Hitler Reference? HAUNT: A Framework to Probe LLMs' Self-consistency Via Adversarial Nudge", 'authors': 'Arka Dutta, Sujan Dutta, Rijul Magu, Soumyajit Datta, Munmun De Choudhury, Ashiqur R. KhudaBukhsh', 'link': 'https://arxiv.org/abs/2511.08596', 'abstract': 'Hallucinations pose a critical challenge to the real-world deployment of large language models (LLMs) in high-stakes domains. In this paper, we present a framework for stress testing factual fidelity in LLMs in the presence of adversarial nudge. Our framework consists of three steps. In the first step, we instruct the LLM to produce sets of truths and lies consistent with the closed domain in question. In the next step, we instruct the LLM to verify the same set of assertions as truths and lies consistent with the same closed domain. In the final step, we test the robustness of the LLM against the lies generated (and verified) by itself. Our extensive evaluation, conducted using five widely known proprietary LLMs across two closed domains of popular movies and novels, reveals a wide range of susceptibility to adversarial nudges: \\texttt{Claude} exhibits strong resilience, \\texttt{GPT} and \\texttt{Grok} demonstrate moderate resilience, while \\texttt{Gemini} and \\texttt{DeepSeek} show weak resilience. Considering that a large population is increasingly using LLMs for information seeking, our findings raise alarm.', 'abstract_zh': '大规模语言模型在高风险领域中的幻觉构成重要挑战：本论文提出一种框架以在对抗性提示下测试事实保真度，并揭示不同模型的抗扰动性差异。', 'title_zh': '含有希特勒引用的情景如何？HAUNT：一种通过对抗性推动探究LLMs自我一致性的框架'}
{'arxiv_id': 'arXiv:2511.08595', 'title': 'Chopping Trees: Semantic Similarity Based Dynamic Pruning for Tree-of-Thought Reasoning', 'authors': 'Joongho Kim, Xirui Huang, Zarreen Reza, Gabriel Grand, Kevin Zhu, Ryan Lagasse', 'link': 'https://arxiv.org/abs/2511.08595', 'abstract': 'Tree-of-Thought (ToT) reasoning boosts the problem-solving abilities of Large Language Models (LLMs) but is computationally expensive due to semantic redundancy, where distinct branches explore equivalent reasoning paths. We introduce Semantic Similarity-Based Dynamic Pruning (SSDP), a lightweight method that, to the best of our knowledge, is the first framework to integrate online semantic merging into parallelized tree search, enabling the clustering and pruning of redundant steps in real time. Across reasoning benchmarks, including GSM8K and MATH500, SSDP achieves up to a 2.3x speedup over state-of-the-art tree-search baselines while maintaining competitive accuracy (typically within 5% of the strongest baseline) and reducing the number of explored nodes by 85-90%, demonstrating a practical approach to efficient, scalable LLM reasoning. The implementation of SSDP is publicly available at this https URL.', 'abstract_zh': '基于语义相似性的动态剪枝（SSDP）在并行树搜索中集成在线语义合并，以实时聚类和修剪冗余步骤，提升大型语言模型的推理能力但减轻了计算开销——以GSM8K和MATH500为代表的推理基准上，SSDP相比最先进的树搜索基线可实现2.3倍的速度提升，同时保持竞争力（通常在最强基线的5%以内）并减少探索节点数85-90%，展示了高效可扩展的大语言模型推理的实用方法。SSDP的实现已公开发布。', 'title_zh': 'chopping 树木：基于语义相似性的动态剪枝用于思维树推理'}
{'arxiv_id': 'arXiv:2511.08592', 'title': 'The Collective Turing Test: Large Language Models Can Generate Realistic Multi-User Discussions', 'authors': 'Azza Bouleimen, Giordano De Marzo, Taehee Kim, Nicol`o Pagan, Hannah Metzler, Silvia Giordano, David Garcia', 'link': 'https://arxiv.org/abs/2511.08592', 'abstract': 'Large Language Models (LLMs) offer new avenues to simulate online communities and social media. Potential applications range from testing the design of content recommendation algorithms to estimating the effects of content policies and interventions. However, the validity of using LLMs to simulate conversations between various users remains largely untested. We evaluated whether LLMs can convincingly mimic human group conversations on social media. We collected authentic human conversations from Reddit and generated artificial conversations on the same topic with two LLMs: Llama 3 70B and GPT-4o. When presented side-by-side to study participants, LLM-generated conversations were mistaken for human-created content 39\\% of the time. In particular, when evaluating conversations generated by Llama 3, participants correctly identified them as AI-generated only 56\\% of the time, barely better than random chance. Our study demonstrates that LLMs can generate social media conversations sufficiently realistic to deceive humans when reading them, highlighting both a promising potential for social simulation and a warning message about the potential misuse of LLMs to generate new inauthentic social media content.', 'abstract_zh': '大型语言模型（LLMs）为模拟在线社区和社会媒体提供了新的途径。潜在应用范围从测试内容推荐算法的设计到估算内容政策和干预措施的影响。然而，使用LLMs模拟不同用户之间的对话的有效性仍然主要未经验证。我们评估了LLMs是否能够逼真地模拟社交媒体上的群体对话。我们从Reddit收集了真实的自然对话，并使用两个LLM（Llama 3 70B和GPT-4o）生成了相同主题的虚构对话。当这些虚构对话与真实对话并排呈现给参与者时，有39%的情况下参与者将其误认为是人类创建的内容。特别是，在评估由Llama 3生成的对话时，参与者仅正确识别它们为AI生成56%的时间，这几乎与随机猜测相当。我们的研究证明，LLMs能够生成足够逼真的社交媒体对话，以至于人类在阅读时会受到误导，这既突显了社会模拟的潜在前景，也警示了LLMs可能被滥用以生成新伪社交媒体内容的风险。', 'title_zh': '集体图灵测试：大型语言模型可以生成现实的多用户讨论'}
{'arxiv_id': 'arXiv:2511.08589', 'title': 'Where did you get that? Towards Summarization Attribution for Analysts', 'authors': 'Violet B, John M. Conroy, Sean Lynch, Danielle M, Neil P. Molino, Aaron Wiechmann, Julia S. Yang', 'link': 'https://arxiv.org/abs/2511.08589', 'abstract': 'Analysts require attribution, as nothing can be reported without knowing the source of the information. In this paper, we will focus on automatic methods for attribution, linking each sentence in the summary to a portion of the source text, which may be in one or more documents. We explore using a hybrid summarization, i.e., an automatic paraphrase of an extractive summary, to ease attribution. We also use a custom topology to identify the proportion of different categories of attribution-related errors.', 'abstract_zh': '分析师需要归因，因为没有信息来源就无法报告任何内容。在本文中，我们将重点探讨自动归因方法，即将摘要中的每一句与来源文本的一部分关联起来，该来源文本可能存在于一个或多个文档中。我们探索使用混合摘要，即对抽提摘要的自动改写，以简化归因过程。我们还使用自定义拓扑结构来识别不同类别的归因错误的比例。', 'title_zh': '从哪里获得这些信息？面向分析师的总结归因'}
{'arxiv_id': 'arXiv:2511.08587', 'title': 'Conversational Agents for Building Energy Efficiency -- Advising Housing Cooperatives in Stockholm on Reducing Energy Consumption', 'authors': 'Shadaab Ghani, Anne Håkansson, Oleksii Pasichnyi, Hossein Shahrokni', 'link': 'https://arxiv.org/abs/2511.08587', 'abstract': "Housing cooperative is a common type of multifamily building ownership in Sweden. Although this ownership structure grants decision-making autonomy, it places a burden of responsibility on cooperative's board members. Most board members lack the resources or expertise to manage properties and their energy consumption. This ignorance presents a unique challenge, especially given the EU directives that prohibit buildings rated as energy classes F and G by 2033. Conversational agents (CAs) enable human-like interactions with computer systems, facilitating human-computer interaction across various domains. In our case, CAs can be implemented to support cooperative members in making informed energy retrofitting and usage decisions. This paper introduces a Conversational agent system, called SPARA, designed to advise cooperatives on energy efficiency. SPARA functions as an energy efficiency advisor by leveraging the Retrieval-Augmented Generation (RAG) framework with a Language Model(LM). The LM generates targeted recommendations based on a knowledge base composed of email communications between professional energy advisors and cooperatives' representatives in Stockholm. The preliminary results indicate that SPARA can provide energy efficiency advice with precision 80\\%, comparable to that of municipal energy efficiency (EE) experts. A pilot implementation is currently underway, where municipal EE experts are evaluating SPARA performance based on questions posed to EE experts by BRF members. Our findings suggest that LMs can significantly improve outreach by supporting stakeholders in their energy transition. For future work, more research is needed to evaluate this technology, particularly limitations to the stability and trustworthiness of its energy efficiency advice.", 'abstract_zh': '共有住房是瑞典常见的多户建筑物所有权形式。尽管这种所有权结构赋予了合作组织董事会成员决策自主权，但也将其责任负担转移给了董事会成员。大多数董事会成员缺乏管理物业及其能耗的专业资源或技能。这种无知在欧盟指令规定到2033年禁止建筑被评为能效等级F和G的背景下，构成了独特的挑战。对话代理（CAs）能够实现与计算机系统的类人交互，促进跨不同领域的交互。在我们的情况下，CAs可以被实施以支持合作组织成员做出有关能效提升和能源使用的知情决策。本文介绍了一个名为SPARA的对话代理系统，该系统旨在为合作组织提供能效建议。SPARA通过利用检索增强生成（RAG）框架与语言模型（LM）合作，功能上作为能效顾问。LM基于标准知识库生成推荐，该知识库由斯德哥尔摩专业能源顾问与合作组织代表之间的电子邮件通信组成。初步结果显示，SPARA可以提供精确度为80%的能效建议，与市政能效（EE）专家不相上下。目前正在实施试点项目，市政EE专家根据来自BRF成员提出的关于能效专家问题，评估SPARA的性能。我们的 findings 表明，语言模型可以显著提高与能效相关的利益相关者的接触面。未来的工作需要更多研究来评估这项技术，特别是其能效建议的稳定性和可信度方面的局限性。', 'title_zh': '对话型代理用于建筑能效提升——指导斯德哥尔摩住房合作社降低能源消耗'}
{'arxiv_id': 'arXiv:2511.08049', 'title': 'CometNet: Contextual Motif-guided Long-term Time Series Forecasting', 'authors': 'Weixu Wang, Xiaobo Zhou, Xin Qiao, Lei Wang, Tie Qiu', 'link': 'https://arxiv.org/abs/2511.08049', 'abstract': 'Long-term Time Series Forecasting is crucial across numerous critical domains, yet its accuracy remains fundamentally constrained by the receptive field bottleneck in existing models. Mainstream Transformer- and Multi-layer Perceptron (MLP)-based methods mainly rely on finite look-back windows, limiting their ability to model long-term dependencies and hurting forecasting performance. Naively extending the look-back window proves ineffective, as it not only introduces prohibitive computational complexity, but also drowns vital long-term dependencies in historical noise. To address these challenges, we propose CometNet, a novel Contextual Motif-guided Long-term Time Series Forecasting framework. CometNet first introduces a Contextual Motif Extraction module that identifies recurrent, dominant contextual motifs from complex historical sequences, providing extensive temporal dependencies far exceeding limited look-back windows; Subsequently, a Motif-guided Forecasting module is proposed, which integrates the extracted dominant motifs into forecasting. By dynamically mapping the look-back window to its relevant motifs, CometNet effectively harnesses their contextual information to strengthen long-term forecasting capability. Extensive experimental results on eight real-world datasets have demonstrated that CometNet significantly outperforms current state-of-the-art (SOTA) methods, particularly on extended forecast horizons.', 'abstract_zh': '长周期时间序列预测在众多关键领域中至关重要，但其准确性受限于现有模型中的感受野瓶颈。主流基于Transformer和多层感知机（MLP）的方法主要依赖于有限的历史窗口，这限制了它们建模长期依赖性的能力，从而损害了预测性能。简单地延长历史窗口效果不佳，因为它不仅引入了巨大的计算复杂性，还淹没了历史噪声中的关键长期依赖性。为了解决这些挑战，我们提出了CometNet，一种新颖的基于上下文模态的长周期时间序列预测框架。CometNet 首先引入了一个上下文模态提取模块，该模块可以从复杂的歷史序列中识别出反复出现的主导上下文模态，提供了远超过有限历史窗口的广泛时间依赖性；随后，提出了一种基于模态的预测模块，该模块将提取的主导模态整合到预测中。通过动态将历史窗口映射到相关的模态，CometNet 有效利用了它们的上下文信息，增强了长期预测能力。在八个真实世界数据集上的广泛实验结果表明，CometNet 显著优于当前最先进的（SOTA）方法，特别是在延长的预测时间范围内。', 'title_zh': 'CometNet：基于上下文模式的长-term时间序列预测'}
