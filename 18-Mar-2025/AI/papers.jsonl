{'arxiv_id': 'arXiv:2503.13404', 'title': 'Fed-Joint: Joint Modeling of Nonlinear Degradation Signals and Failure Events for Remaining Useful Life Prediction using Federated Learning', 'authors': 'Cheoljoon Jeong, Xubo Yue, Seokhyun Chung', 'link': 'https://arxiv.org/abs/2503.13404', 'abstract': 'Many failure mechanisms of machinery are closely related to the behavior of condition monitoring (CM) signals. To achieve a cost-effective preventive maintenance strategy, accurate remaining useful life (RUL) prediction based on the signals is of paramount importance. However, the CM signals are often recorded at different factories and production lines, with limited amounts of data. Unfortunately, these datasets have rarely been shared between the sites due to data confidentiality and ownership issues, a lack of computing and storage power, and high communication costs associated with data transfer between sites and a data center. Another challenge in real applications is that the CM signals are often not explicitly specified \\textit{a priori}, meaning that existing methods, which often usually a parametric form, may not be applicable. To address these challenges, we propose a new prognostic framework for RUL prediction using the joint modeling of nonlinear degradation signals and time-to-failure data within a federated learning scheme. The proposed method constructs a nonparametric degradation model using a federated multi-output Gaussian process and then employs a federated survival model to predict failure times and probabilities for in-service machinery. The superiority of the proposed method over other alternatives is demonstrated through comprehensive simulation studies and a case study using turbofan engine degradation signal data that include run-to-failure events.', 'abstract_zh': '机械设备的许多失效机理与条件监控信号的行为密切相关。为了实现有效的预防性维护策略，基于信号的准确剩余使用寿命（RUL）预测至关重要。然而，这些信号往往在不同工厂和生产线上以有限的数据量记录。这些数据集在不同站点之间由于数据保密性和所有权问题、计算和存储能力不足以及数据传输和数据中心之间的高昂通信成本，很少被共享。在实际应用中，另一个挑战是条件监控信号经常不是先验明确指定的，这意味着现有的方法，通常是以参数形式表示的，可能不适用。为应对这些挑战，我们提出了一种新的基于联邦学习的剩余使用寿命预测框架，该框架结合了非线性退化信号和失效时间数据的联合模型构建方法。该方法利用联邦多输出高斯过程构建非参数退化模型，然后使用联邦生存模型预测在用设备的失效时间和概率。通过全面的模拟研究和基于涡扇发动机退化信号数据的案例研究（包括运行至失效事件），展示了所提出方法的优势。', 'title_zh': 'Fed-Joint：联邦学习下的非线性退化信号与故障事件联合建模以预测剩余使用寿命'}
{'arxiv_id': 'arXiv:2503.13369', 'title': 'Sightation Counts: Leveraging Sighted User Feedback in Building a BLV-aligned Dataset of Diagram Descriptions', 'authors': 'Wan Ju Kang, Eunki Kim, Na Min An, Sangryul Kim, Haemin Choi, Ki Hoon Kwak, James Thorne', 'link': 'https://arxiv.org/abs/2503.13369', 'abstract': 'Often, the needs and visual abilities differ between the annotator group and the end user group. Generating detailed diagram descriptions for blind and low-vision (BLV) users is one such challenging domain. Sighted annotators could describe visuals with ease, but existing studies have shown that direct generations by them are costly, bias-prone, and somewhat lacking by BLV standards. In this study, we ask sighted individuals to assess -- rather than produce -- diagram descriptions generated by vision-language models (VLM) that have been guided with latent supervision via a multi-pass inference. The sighted assessments prove effective and useful to professional educators who are themselves BLV and teach visually impaired learners. We release Sightation, a collection of diagram description datasets spanning 5k diagrams and 137k samples for completion, preference, retrieval, question answering, and reasoning training purposes and demonstrate their fine-tuning potential in various downstream tasks.', 'abstract_zh': '目光受限用户与标注者之间的需求和视觉能力往往存在差异。为盲人和低视力（BLV）用户生成详细的图表描述是一项具有挑战性的领域。视障标注者能够轻松地描述图表，但现有研究显示，由他们直接生成的内容成本高、易带有偏见且在BLV标准下有所欠缺。在本研究中，我们要求视障个体评估——而非生成——通过多阶段推断并借助潜在监督指导的视觉-语言模型（VLM）生成的图表描述。这种视障评估对自身为视障且教育视觉受损学习者的专业教育者非常有效。我们发布了Sightation，其中包括跨越5000个图表和137000个样本的图表描述数据集，用于完成任务、偏好评估、检索、问答和推理训练，并展示了其在各种下游任务中的微调潜力。', 'title_zh': '基于视障用户反馈构建盲文兼容的图表描述数据集：数量胜于质量'}
{'arxiv_id': 'arXiv:2503.13275', 'title': 'Knowledge-Aware Iterative Retrieval for Multi-Agent Systems', 'authors': 'Seyoung Song', 'link': 'https://arxiv.org/abs/2503.13275', 'abstract': 'We introduce a novel large language model (LLM)-driven agent framework, which iteratively refines queries and filters contextual evidence by leveraging dynamically evolving knowledge. A defining feature of the system is its decoupling of external sources from an internal knowledge cache that is progressively updated to guide both query generation and evidence selection. This design mitigates bias-reinforcement loops and enables dynamic, trackable search exploration paths, thereby optimizing the trade-off between exploring diverse information and maintaining accuracy through autonomous agent decision-making. Our approach is evaluated on a broad range of open-domain question answering benchmarks, including multi-step tasks that mirror real-world scenarios where integrating information from multiple sources is critical, especially given the vulnerabilities of LLMs that lack explicit reasoning or planning capabilities. The results show that the proposed system not only outperforms single-step baselines regardless of task difficulty but also, compared to conventional iterative retrieval methods, demonstrates pronounced advantages in complex tasks through precise evidence-based reasoning and enhanced efficiency. The proposed system supports both competitive and collaborative sharing of updated context, enabling multi-agent extension. The benefits of multi-agent configurations become especially prominent as task difficulty increases. The number of convergence steps scales with task difficulty, suggesting cost-effective scalability.', 'abstract_zh': '一种基于large language model的迭代查询与动态知识驱动智能代理框架：多源信息整合下的性能优化与多智能体扩展', 'title_zh': '知识驱动迭代检索在多Agent系统中的应用'}
{'arxiv_id': 'arXiv:2503.13223', 'title': 'Robust Decision-Making Via Free Energy Minimization', 'authors': 'Allahkaram Shafiei, Hozefa Jesawada, Karl Friston, Giovanni Russo', 'link': 'https://arxiv.org/abs/2503.13223', 'abstract': 'Despite their groundbreaking performance, state-of-the-art autonomous agents can misbehave when training and environmental conditions become inconsistent, with minor mismatches leading to undesirable behaviors or even catastrophic failures. Robustness towards these training/environment ambiguities is a core requirement for intelligent agents and its fulfillment is a long-standing challenge when deploying agents in the real world. Here, departing from mainstream views seeking robustness through training, we introduce DR-FREE, a free energy model that installs this core property by design. It directly wires robustness into the agent decision-making mechanisms via free energy minimization. By combining a robust extension of the free energy principle with a novel resolution engine, DR-FREE returns a policy that is optimal-yet-robust against ambiguity. Moreover, for the first time, it reveals the mechanistic role of ambiguity on optimal decisions and requisite Bayesian belief updating. We evaluate DR-FREE on an experimental testbed involving real rovers navigating an ambiguous environment filled with obstacles. Across all the experiments, DR-FREE enables robots to successfully navigate towards their goal even when, in contrast, standard free energy minimizing agents that do not use DR-FREE fail. In short, DR-FREE can tackle scenarios that elude previous methods: this milestone may inspire both deployment in multi-agent settings and, at a perhaps deeper level, the quest for a biologically plausible explanation of how natural agents - with little or no training - survive in capricious environments.', 'abstract_zh': '尽管最先进的自主代理在性能上取得了突破，但它们在训练和环境条件不一致时可能会表现不佳，即使是微小的不匹配也会导致不良行为或灾难性故障。对这些训练/环境不确定性具有鲁棒性是智能代理的核心要求，其在实际部署中一直是长期面临的挑战。在这里，我们从主流通过训练来实现鲁棒性的观点出发，引入了DR-FREE，这是一种通过设计安装这一核心属性的自由能模型。它通过自由能最小化直接将鲁棒性嵌入到代理的决策机制中。通过结合鲁棒性的自由能原理扩展以及一种新颖的解决方案引擎，DR-FREE提供了一个既最优又对不确定性鲁棒的策略。此外，它首次揭示了不确定性在最优决策中的机制作用以及所需的贝叶斯信念更新。我们在涉及真实漫游者在充满障碍的模糊环境中导航的实验测试平台中评估了DR-FREE。在所有试验中，即使标准的自由能最小化代理（不使用DR-FREE）失败，DR-FREE也使机器人能够成功地导航到目标。简言之，DR-FREE能够应对先前方法难以解决的场景：这一里程碑可能激发在多代理环境中的部署，并可能在更深层次上为自然代理如何在变幻莫测的环境中生存的生物学可实现解释提供答案。', 'title_zh': '基于自由能最小化的稳健决策making'}
{'arxiv_id': 'arXiv:2503.13205', 'title': 'MAP: Evaluation and Multi-Agent Enhancement of Large Language Models for Inpatient Pathways', 'authors': 'Zhen Chen, Zhihao Peng, Xusheng Liang, Cheng Wang, Peigan Liang, Linsheng Zeng, Minjie Ju, Yixuan Yuan', 'link': 'https://arxiv.org/abs/2503.13205', 'abstract': 'Inpatient pathways demand complex clinical decision-making based on comprehensive patient information, posing critical challenges for clinicians. Despite advancements in large language models (LLMs) in medical applications, limited research focused on artificial intelligence (AI) inpatient pathways systems, due to the lack of large-scale inpatient datasets. Moreover, existing medical benchmarks typically concentrated on medical question-answering and examinations, ignoring the multifaceted nature of clinical decision-making in inpatient settings. To address these gaps, we first developed the Inpatient Pathway Decision Support (IPDS) benchmark from the MIMIC-IV database, encompassing 51,274 cases across nine triage departments and 17 major disease categories alongside 16 standardized treatment options. Then, we proposed the Multi-Agent Inpatient Pathways (MAP) framework to accomplish inpatient pathways with three clinical agents, including a triage agent managing the patient admission, a diagnosis agent serving as the primary decision maker at the department, and a treatment agent providing treatment plans. Additionally, our MAP framework includes a chief agent overseeing the inpatient pathways to guide and promote these three clinician agents. Extensive experiments showed our MAP improved the diagnosis accuracy by 25.10% compared to the state-of-the-art LLM HuatuoGPT2-13B. It is worth noting that our MAP demonstrated significant clinical compliance, outperforming three board-certified clinicians by 10%-12%, establishing a foundation for inpatient pathways systems.', 'abstract_zh': '基于综合患者信息的住院路径需求复杂临床决策，对临床医生构成关键挑战。尽管在医疗应用中大型语言模型取得了进展，但由于缺乏大规模住院患者数据集，有限的研究关注人工智能住院路径系统。此外，现有的医疗基准通常集中在医学问答和检查上，忽略了住院环境中临床决策的多维性质。为解决这些差距，我们首先从MIMIC-IV数据库中开发了住院路径决策支持（IPDS）基准，涵盖了九个 triage 部门和17个主要疾病类别，以及16种标准化治疗选项。然后，我们提出了多代理住院路径（MAP）框架，通过三个临床代理来实现住院路径，包括负责患者入院的分诊代理、作为部门主要决策者的诊断代理以及提供治疗计划的治疗代理。此外，我们的MAP框架还包括一个主管代理，监督住院路径以指导和促进这三个临床代理。大量实验表明，与最先进的大型语言模型HuatuoGPT2-13B相比，我们的MAP提高了25.10%的诊断准确性。值得注意的是，我们的MAP在临床合规性方面表现出显著优势，相比三个认证的临床医生性能高出10%-12%，为住院路径系统奠定了基础。', 'title_zh': 'MAP: 大型语言模型在住院路径中的评估与多agent增强'}
{'arxiv_id': 'arXiv:2503.13194', 'title': 'A representational framework for learning and encoding structurally enriched trajectories in complex agent environments', 'authors': 'Corina Catarau-Cotutiu, Esther Mondragon, Eduardo Alonso', 'link': 'https://arxiv.org/abs/2503.13194', 'abstract': "The ability of artificial intelligence agents to make optimal decisions and generalise them to different domains and tasks is compromised in complex scenarios. One way to address this issue has focused on learning efficient representations of the world and on how the actions of agents affect them, such as disentangled representations that exploit symmetries. Whereas such representations are procedurally efficient, they are based on the compression of low-level state-action transitions, which lack structural richness. To address this problem, we propose to enrich the agent's ontology and extend the traditional conceptualisation of trajectories to provide a more nuanced view of task execution. Structurally Enriched Trajectories (SETs) extend the encoding of sequences of states and their transitions by incorporating hierarchical relations between objects, interactions and affordances. SETs are built as multi-level graphs, providing a detailed representation of the agent dynamics and a transferable functional abstraction of the task. SETs are integrated into an architecture, Structurally Enriched Trajectory Learning and Encoding (SETLE), that employs a heterogeneous graph-based memory structure of multi-level relational dependencies essential for generalisation. Using reinforcement learning as a data generation tool, we demonstrate that SETLE can support downstream tasks, enabling agents to recognise task-relevant structural patterns across diverse environments.", 'abstract_zh': '结构丰富轨迹（SET）增强的决策与泛化能力研究', 'title_zh': '一种表示框架，用于在复杂代理环境中学习和编码结构化增强轨迹'}
{'arxiv_id': 'arXiv:2503.13178', 'title': 'Rapfi: Distilling Efficient Neural Network for the Game of Gomoku', 'authors': 'Zhanggen Jin, Haobin Duan, Zhiyang Hang', 'link': 'https://arxiv.org/abs/2503.13178', 'abstract': "Games have played a pivotal role in advancing artificial intelligence, with AI agents using sophisticated techniques to compete. Despite the success of neural network based game AIs, their performance often requires significant computational resources. In this paper, we present Rapfi, an efficient Gomoku agent that outperforms CNN-based agents in limited computation environments. Rapfi leverages a compact neural network with a pattern-based codebook distilled from CNNs, and an incremental update scheme that minimizes computation when input changes are minor. This new network uses computation that is orders of magnitude less to reach a similar accuracy of much larger neural networks such as Resnet. Thanks to our incremental update scheme, depth-first search methods such as the alpha-beta search can be significantly accelerated. With a carefully tuned evaluation and search, Rapfi reached strength surpassing Katagomo, the strongest open-source Gomoku AI based on AlphaZero's algorithm, under limited computational resources where accelerators like GPUs are absent. Rapfi ranked first among 520 Gomoku agents on Botzone and won the championship in GomoCup 2024.", 'abstract_zh': 'Rapfi：在有限计算资源环境中超越CNN基游戏AI的高效五子棋代理', 'title_zh': 'Rapfi: 一种用于五子棋游戏的高效神经网络蒸馏方法'}
{'arxiv_id': 'arXiv:2503.13169', 'title': 'Collaborative AI Enhances Image Understanding in Materials Science', 'authors': 'Ruoyan Avery Yin, Zhichu Ren, Zongyou Yin, Zhen Zhang, So Yeon Kim, Chia-Wei Hsu, Ju Li', 'link': 'https://arxiv.org/abs/2503.13169', 'abstract': 'The Copilot for Real-world Experimental Scientist (CRESt) system empowers researchers to control autonomous laboratories through conversational AI, providing a seamless interface for managing complex experimental workflows. We have enhanced CRESt by integrating a multi-agent collaboration mechanism that utilizes the complementary strengths of the ChatGPT and Gemini models for precise image analysis in materials science. This innovative approach significantly improves the accuracy of experimental outcomes by fostering structured debates between the AI models, which enhances decision-making processes in materials phase analysis. Additionally, to evaluate the generalizability of this approach, we tested it on a quantitative task of counting particles. Here, the collaboration between the AI models also led to improved results, demonstrating the versatility and robustness of this method. By harnessing this dual-AI framework, this approach stands as a pioneering method for enhancing experimental accuracy and efficiency in materials research, with applications extending beyond CRESt to broader scientific experimentation and analysis.', 'abstract_zh': '.real-world实验科学家辅佐系统（CRESt）通过对话式AI赋能研究人员控制自主实验室，提供管理复杂实验流程的无缝界面。我们通过集成多智能体协作机制，结合ChatGPT和Gemini模型的互补优势，增强了CRESt，以精确进行材料科学中的图像分析。这种创新方法通过促进AI模型之间的结构化辩论，显著提高了材料相分析中的决策过程和实验结果准确性。此外，为了评估该方法的普遍适用性，我们将其应用于颗粒计数的定量任务，结果显示AI模型之间的协作也带来了更好的结果，展示了该方法的通用性和鲁棒性。通过利用这一双AI框架，该方法成为提升材料研究实验准确性与效率的开创性方法，其应用超越了CRESt，扩展到更广泛的科学研究和分析。', 'title_zh': '协作AI增强材料科学中的图像理解'}
{'arxiv_id': 'arXiv:2503.13149', 'title': 'Are LLMs (Really) Ideological? An IRT-based Analysis and Alignment Tool for Perceived Socio-Economic Bias in LLMs', 'authors': 'Jasmin Wachter, Michael Radloff, Maja Smolej, Katharina Kinder-Kurlanda', 'link': 'https://arxiv.org/abs/2503.13149', 'abstract': 'We introduce an Item Response Theory (IRT)-based framework to detect and quantify socioeconomic bias in large language models (LLMs) without relying on subjective human judgments. Unlike traditional methods, IRT accounts for item difficulty, improving ideological bias estimation. We fine-tune two LLM families (Meta-LLaMa 3.2-1B-Instruct and Chat- GPT 3.5) to represent distinct ideological positions and introduce a two-stage approach: (1) modeling response avoidance and (2) estimating perceived bias in answered responses. Our results show that off-the-shelf LLMs often avoid ideological engagement rather than exhibit bias, challenging prior claims of partisanship. This empirically validated framework enhances AI alignment research and promotes fairer AI governance.', 'abstract_zh': '基于项目反应理论的框架：在无需依赖主观人类判断的情况下检测和量化大型语言模型中的社会经济偏见', 'title_zh': '大语言模型（真的）有意识形态倾向吗？基于IRT的分析与对齐工具，用于评估大语言模型中的社会经济偏见'}
{'arxiv_id': 'arXiv:2503.12992', 'title': 'Intra-neuronal attention within language models Relationships between activation and semantics', 'authors': 'Michael Pichat, William Pogrund, Paloma Pichat, Armanouche Gasparian, Samuel Demarchi, Corbet Alois Georgeon, Michael Veillet-Guillem', 'link': 'https://arxiv.org/abs/2503.12992', 'abstract': 'This study investigates the ability of perceptron-type neurons in language models to perform intra-neuronal attention; that is, to identify different homogeneous categorical segments within the synthetic thought category they encode, based on a segmentation of specific activation zones for the tokens to which they are particularly responsive. The objective of this work is therefore to determine to what extent formal neurons can establish a homomorphic relationship between activation-based and categorical segmentations. The results suggest the existence of such a relationship, albeit tenuous, only at the level of tokens with very high activation levels. This intra-neuronal attention subsequently enables categorical restructuring processes at the level of neurons in the following layer, thereby contributing to the progressive formation of high-level categorical abstractions.', 'abstract_zh': '本研究探讨了语言模型中感知器型神经元执行内神经注意的能力；即，根据它们特别响应的标记的特定激活区域对划分，识别编码的合成思想类别中不同的同质类别片段。本工作的目标因此是确定形式神经元在基于激活和类别划分之间建立同构关系方面的程度。结果表明，只有在激活水平非常高的标记级别上，才可能存在这种关系，尽管这种关系是脆弱的。这种内神经注意随后使下一层神经元中的类别重构过程成为可能，从而有助于高级类别抽象的逐步形成。', 'title_zh': '语言模型内的神经元注意力激活与语义之间的关系'}
{'arxiv_id': 'arXiv:2503.12937', 'title': 'R1-VL: Learning to Reason with Multimodal Large Language Models via Step-wise Group Relative Policy Optimization', 'authors': 'Jingyi Zhang, Jiaxing Huang, Huanjin Yao, Shunyu Liu, Xikun Zhang, Shijian Lu, Dacheng Tao', 'link': 'https://arxiv.org/abs/2503.12937', 'abstract': "Recent studies generally enhance MLLMs' reasoning capabilities via supervised fine-tuning on high-quality chain-of-thought reasoning data, which often leads models to merely imitate successful reasoning paths without understanding what the wrong reasoning paths are. In this work, we aim to enhance the MLLMs' reasoning ability beyond passively imitating positive reasoning paths. To this end, we design Step-wise Group Relative Policy Optimization (StepGRPO), a new online reinforcement learning framework that enables MLLMs to self-improve reasoning ability via simple, effective and dense step-wise rewarding. Specifically, StepGRPO introduces two novel rule-based reasoning rewards: Step-wise Reasoning Accuracy Reward (StepRAR) and Step-wise Reasoning Validity Reward (StepRVR). StepRAR rewards the reasoning paths that contain necessary intermediate reasoning steps via a soft key-step matching technique, while StepRAR rewards reasoning paths that follow a well-structured and logically consistent reasoning process through a reasoning completeness and logic evaluation strategy. With the proposed StepGRPO, we introduce R1-VL, a series of MLLMs with outstanding capabilities in step-by-step reasoning. Extensive experiments over 8 benchmarks demonstrate the superiority of our methods.", 'abstract_zh': "Recent studies generally enhance MLLMs' reasoning capabilities via supervised fine-tuning on high-quality chain-of-thought reasoning data, which often leads models to merely imitate successful reasoning paths without understanding what the wrong reasoning paths are. In this work, we aim to enhance the MLLMs' reasoning ability beyond passively imitating positive reasoning paths. To this end, we design Step-wise Group Relative Policy Optimization (StepGRPO), a new online reinforcement learning framework that enables MLLMs to self-improve reasoning ability via simple, effective, and dense step-wise rewarding. Specifically, StepGRPO introduces two novel rule-based reasoning rewards: Step-wise Reasoning Accuracy Reward (StepRAR) and Step-wise Reasoning Validity Reward (StepRVR). StepRAR rewards the reasoning paths that contain necessary intermediate reasoning steps via a soft key-step matching technique, while StepRVR rewards reasoning paths that follow a well-structured and logically consistent reasoning process through a reasoning completeness and logic evaluation strategy. With the proposed StepGRPO, we introduce R1-VL, a series of MLLMs with outstanding capabilities in step-by-step reasoning. Extensive experiments over 8 benchmarks demonstrate the superiority of our methods。", 'title_zh': 'R1-VL：通过逐步组相对策略优化学习多模态大型语言模型推理'}
{'arxiv_id': 'arXiv:2503.12917', 'title': 'Verification Learning: Make Unsupervised Neuro-Symbolic System Feasible', 'authors': 'Lin-Han Jia, Wen-Chao Hu, Jie-Jing Shao, Lan-Zhe Guo, Yu-Feng Li', 'link': 'https://arxiv.org/abs/2503.12917', 'abstract': 'The current Neuro-Symbolic (NeSy) Learning paradigm suffers from an over-reliance on labeled data. If we completely disregard labels, it leads to less symbol information, a larger solution space, and more shortcuts-issues that current Nesy systems cannot resolve. This paper introduces a novel learning paradigm, Verification Learning (VL), which addresses this challenge by transforming the label-based reasoning process in Nesy into a label-free verification process. VL achieves excellent learning results solely by relying on unlabeled data and a function that verifies whether the current predictions conform to the rules. We formalize this problem as a Constraint Optimization Problem (COP) and propose a Dynamic combinatorial Sorting (DCS) algorithm that accelerates the solution by reducing verification attempts, effectively lowering computational costs to the level of a Constraint Satisfaction Problem (CSP). To further enhance performance, we introduce a prior alignment method to address potential shortcuts. Our theoretical analysis points out which tasks in Nesy systems can be completed without labels and explains why rules can replace infinite labels, such as in addition, for some tasks, while for others, like Sudoku, the rules have no effect. We validate the proposed framework through several fully unsupervised tasks including addition, sort, match, and chess, each showing significant performance and efficiency improvements.', 'abstract_zh': '基于验证的学习（VL）：无标示数据下的神经符号学习范式', 'title_zh': '验证学习：使无监督神经符号系统可行'}
{'arxiv_id': 'arXiv:2503.12761', 'title': 'Analyzing sequential activity and travel decisions with interpretable deep inverse reinforcement learning', 'authors': 'Yuebing Liang, Shenhao Wang, Jiangbo Yu, Zhan Zhao, Jinhua Zhao, Sandy Pentland', 'link': 'https://arxiv.org/abs/2503.12761', 'abstract': 'Travel demand modeling has shifted from aggregated trip-based models to behavior-oriented activity-based models because daily trips are essentially driven by human activities. To analyze the sequential activity-travel decisions, deep inverse reinforcement learning (DIRL) has proven effective in learning the decision mechanisms by approximating a reward function to represent preferences and a policy function to replicate observed behavior using deep neural networks (DNNs). However, most existing research has focused on using DIRL to enhance only prediction accuracy, with limited exploration into interpreting the underlying decision mechanisms guiding sequential decision-making. To address this gap, we introduce an interpretable DIRL framework for analyzing activity-travel decision processes, bridging the gap between data-driven machine learning and theory-driven behavioral models. Our proposed framework adapts an adversarial IRL approach to infer the reward and policy functions of activity-travel behavior. The policy function is interpreted through a surrogate interpretable model based on choice probabilities from the policy function, while the reward function is interpreted by deriving both short-term rewards and long-term returns for various activity-travel patterns. Our analysis of real-world travel survey data reveals promising results in two key areas: (i) behavioral pattern insights from the policy function, highlighting critical factors in decision-making and variations among socio-demographic groups, and (ii) behavioral preference insights from the reward function, indicating the utility individuals gain from specific activity sequences.', 'abstract_zh': '基于行为的活动-行程决策过程的可解释深度逆强化学习框架', 'title_zh': '基于可解释的深度逆强化学习分析序贯活动和出行决策'}
{'arxiv_id': 'arXiv:2503.12722', 'title': 'Identifying Cooperative Personalities in Multi-agent Contexts through Personality Steering with Representation Engineering', 'authors': 'Kenneth J. K. Ong, Lye Jia Jun, Hieu Minh "Jord" Nguyen, Seong Hah Cho, Natalia Pérez-Campanero Antolín', 'link': 'https://arxiv.org/abs/2503.12722', 'abstract': "As Large Language Models (LLMs) gain autonomous capabilities, their coordination in multi-agent settings becomes increasingly important. However, they often struggle with cooperation, leading to suboptimal outcomes. Inspired by Axelrod's Iterated Prisoner's Dilemma (IPD) tournaments, we explore how personality traits influence LLM cooperation. Using representation engineering, we steer Big Five traits (e.g., Agreeableness, Conscientiousness) in LLMs and analyze their impact on IPD decision-making. Our results show that higher Agreeableness and Conscientiousness improve cooperation but increase susceptibility to exploitation, highlighting both the potential and limitations of personality-based steering for aligning AI agents.", 'abstract_zh': '大型语言模型（LLMs）获得自主能力后，它们在多智能体环境中的协调变得 increasingly important。然而，它们 often struggle with cooperation，导致 suboptimal outcomes。借鉴Axelrod的重复囚徒困境（IPD）竞赛，我们探讨了性格特质如何影响LLM的合作。通过表示工程，我们调整了大型语言模型中的大五人格特质（如乐群性、尽责性），并分析了它们对IPD决策的影响。结果显示，较高的乐群性和尽责性可以提高合作，但会增加被利用的风险，这既揭示了基于性格调整AI代理的潜力，也指出了其局限性。', 'title_zh': '通过表示工程实现的人格导向在多智能体情境中识别合作人格'}
{'arxiv_id': 'arXiv:2503.12721', 'title': 'Can Reasoning Models Reason about Hardware? An Agentic HLS Perspective', 'authors': 'Luca Collini, Andrew Hennessee, Ramesh Karri, Siddharth Garg', 'link': 'https://arxiv.org/abs/2503.12721', 'abstract': 'Recent Large Language Models (LLMs) such as OpenAI o3-mini and DeepSeek-R1 use enhanced reasoning through Chain-of-Thought (CoT). Their potential in hardware design, which relies on expert-driven iterative optimization, remains unexplored. This paper investigates whether reasoning LLMs can address challenges in High-Level Synthesis (HLS) design space exploration and optimization. During HLS, engineers manually define pragmas/directives to balance performance and resource constraints. We propose an LLM-based optimization agentic framework that automatically restructures code, inserts pragmas, and identifies optimal design points via feedback from HLs tools and access to integer-linear programming (ILP) solvers. Experiments compare reasoning models against conventional LLMs on benchmarks using success rate, efficiency, and design quality (area/latency) metrics, and provide the first-ever glimpse into the CoTs produced by a powerful open-source reasoning model like DeepSeek-R1.', 'abstract_zh': '近期的大规模语言模型（LLMs）如OpenAI o3-mini和DeepSeek-R1通过链式推理（Chain-of-Thought，CoT）增强了推理能力。尽管它们在硬件设计中的潜力，特别是依赖于专家驱动的迭代优化的设计空间探索和优化，尚未被充分发掘。本文探讨了推理LLMs是否能够应对高阶综合（HLS）设计空间探索和优化中的挑战。在HLS过程中，工程师手动定义pragma/指南来平衡性能和资源约束。我们提出了一种基于LLM的优化代理框架，该框架能够自动重构代码、插入pragma并利用来自HLS工具的反馈及整数线性规划（ILP）求解器访问能力来识别最优设计点。实验在基准测试上将推理模型与传统LLMs进行比较，使用成功率、效率和设计质量（面积/延迟）等指标，并提供了关于强大开源推理模型DeepSeek-R1产生的CoT的首次见解。', 'title_zh': '基于代理的硬件合成视角：推理模型能否 reasoning 关于硬件？'}
{'arxiv_id': 'arXiv:2503.12687', 'title': 'AI Agents: Evolution, Architecture, and Real-World Applications', 'authors': 'Naveen Krishnan', 'link': 'https://arxiv.org/abs/2503.12687', 'abstract': 'This paper examines the evolution, architecture, and practical applications of AI agents from their early, rule-based incarnations to modern sophisticated systems that integrate large language models with dedicated modules for perception, planning, and tool use. Emphasizing both theoretical foundations and real-world deployments, the paper reviews key agent paradigms, discusses limitations of current evaluation benchmarks, and proposes a holistic evaluation framework that balances task effectiveness, efficiency, robustness, and safety. Applications across enterprise, personal assistance, and specialized domains are analyzed, with insights into future research directions for more resilient and adaptive AI agent systems.', 'abstract_zh': '本文 examines 这篇文章探讨了从早期基于规则的版本到现代集成了大语言模型并配有专门感知、规划和工具使用模块的复杂系统的AI代理的发展、架构及其实际应用。强调理论基础和实际部署，本文回顾了关键的代理范式，讨论了当前评估基准的局限性，并提出了一种平衡任务效果、效率、鲁棒性和安全性的综合评估框架。分析了企业、个人辅助和专业领域中的应用场景，并对未来更具韧性和适应性的AI代理系统的研究方向提供了见解。', 'title_zh': 'AI代理：演化、架构与实际应用'}
{'arxiv_id': 'arXiv:2503.12651', 'title': 'VeriLA: A Human-Centered Evaluation Framework for Interpretable Verification of LLM Agent Failures', 'authors': 'Yoo Yeon Sung, Hannah Kim, Dan Zhang', 'link': 'https://arxiv.org/abs/2503.12651', 'abstract': "AI practitioners increasingly use large language model (LLM) agents in compound AI systems to solve complex reasoning tasks, these agent executions often fail to meet human standards, leading to errors that compromise the system's overall performance. Addressing these failures through human intervention is challenging due to the agents' opaque reasoning processes, misalignment with human expectations, the complexity of agent dependencies, and the high cost of manual inspection. This paper thus introduces a human-centered evaluation framework for Verifying LLM Agent failures (VeriLA), which systematically assesses agent failures to reduce human effort and make these agent failures interpretable to humans. The framework first defines clear expectations of each agent by curating human-designed agent criteria. Then, it develops a human-aligned agent verifier module, trained with human gold standards, to assess each agent's execution output. This approach enables granular evaluation of each agent's performance by revealing failures from a human standard, offering clear guidelines for revision, and reducing human cognitive load. Our case study results show that VeriLA is both interpretable and efficient in helping practitioners interact more effectively with the system. By upholding accountability in human-agent collaboration, VeriLA paves the way for more trustworthy and human-aligned compound AI systems.", 'abstract_zh': 'AI从业者 increasingly 使用大规模语言模型 (LLM) 剂体制作复杂混合AI系统以解决复杂推理任务，这些剂体制作的执行Often常 不符合人类标准，导致影响系统整体性能的错误。通过人工干预解决这些问题具有挑战性，因为剂体制作具有不透明的推理过程、与人类期望不一致、剂体制作的复杂依赖关系以及手动审查的高成本。本文因此介绍了以人为中心的评估框架VeriLA，该框架系统地评估剂体制作的失败，以减少人工努力并使这些失败对人类可解释。该框架首先通过收集设计的人类标准的剂体制作标准来定义每个剂体制作的明确期望。然后，它开发了一个与人类标准对齐的剂体制作验证模块，通过人类金标准训练，以评估每个剂体制作的执行输出。该方法通过从人类标准揭示失败，实现每个剂体制作性能的逐个评估，并提供明确的修订指南，从而减轻人类的认知负担。我们的案例研究结果表明，VeriLA在帮助从业者更有效地与系统交互方面既可解释又有效。通过维护人类-剂体制作合作中的问责制，VeriLA为更具可信度和人类导向的混合AI系统铺平了道路。', 'title_zh': 'VeriLA: 一种以人为本的可解释LLM代理故障评估框架'}
{'arxiv_id': 'arXiv:2503.12637', 'title': 'Understanding Driver Cognition and Decision-Making Behaviors in High-Risk Scenarios: A Drift Diffusion Perspective', 'authors': 'Heye Huang, Zheng Li, Hao Cheng, Haoran Wang, Junkai Jiang, Xiaopeng Li, Arkady Zgonnikov', 'link': 'https://arxiv.org/abs/2503.12637', 'abstract': 'Ensuring safe interactions between autonomous vehicles (AVs) and human drivers in mixed traffic systems remains a major challenge, particularly in complex, high-risk scenarios. This paper presents a cognition-decision framework that integrates individual variability and commonalities in driver behavior to quantify risk cognition and model dynamic decision-making. First, a risk sensitivity model based on a multivariate Gaussian distribution is developed to characterize individual differences in risk cognition. Then, a cognitive decision-making model based on the drift diffusion model (DDM) is introduced to capture common decision-making mechanisms in high-risk environments. The DDM dynamically adjusts decision thresholds by integrating initial bias, drift rate, and boundary parameters, adapting to variations in speed, relative distance, and risk sensitivity to reflect diverse driving styles and risk preferences. By simulating high-risk scenarios with lateral, longitudinal, and multidimensional risk sources in a driving simulator, the proposed model accurately predicts cognitive responses and decision behaviors during emergency maneuvers. Specifically, by incorporating driver-specific risk sensitivity, the model enables dynamic adjustments of key DDM parameters, allowing for personalized decision-making representations in diverse scenarios. Comparative analysis with IDM, Gipps, and MOBIL demonstrates that DDM more precisely captures human cognitive processes and adaptive decision-making in high-risk scenarios. These findings provide a theoretical basis for modeling human driving behavior and offer critical insights for enhancing AV-human interaction in real-world traffic environments.', 'abstract_zh': '确保自动驾驶车辆（AVs）与人类驾驶员在混合交通系统中的安全互动仍然是一个主要挑战，特别是在复杂高风险场景中。本文提出了一种认知-决策框架，整合了驾驶员行为中的个体差异与共同特征以量化风险认知并建模动态决策。首先，基于多元高斯分布的风险敏感性模型被开发以描述个体间的风险认知差异。然后，引入基于漂移扩散模型（DDM）的认知决策模型以捕捉高风险环境中的共同决策机制。DDM动态调整决策阈值，通过整合初始偏差、漂移速率和边界参数，适应速度、相对距离和风险敏感性的变化，以反映不同的驾驶风格和风险偏好。通过在驾驶模拟器中模拟具有横向、纵向和多维度风险源的高风险场景，所提出的模型能够准确预测紧急操作中的认知反应和决策行为。具体而言，通过纳入驾驶员特定的风险敏感性，模型能够实现关键DDM参数的动态调整，在不同场景中提供个性化的决策表示。与IDM、Gipps和MOBIL模型的比较分析表明，DDM更精准地捕捉了高风险场景中的人类认知过程和适应性决策。这些发现为建模人类驾驶行为提供了理论基础，并为进一步优化AV-人类交互在实际交通环境中的表现提供了关键见解。', 'title_zh': '高风险场景中驾驶员认知与决策行为的理解：从漂移扩散视角探析'}
{'arxiv_id': 'arXiv:2503.12626', 'title': 'Automated Planning for Optimal Data Pipeline Instantiation', 'authors': 'Leonardo Rosa Amado, Adriano Vogel, Dalvan Griebler, Gabriel Paludo Licks, Eric Simon, Felipe Meneguzzi', 'link': 'https://arxiv.org/abs/2503.12626', 'abstract': "Data pipeline frameworks provide abstractions for implementing sequences of data-intensive transformation operators, automating the deployment and execution of such transformations in a cluster. Deploying a data pipeline, however, requires computing resources to be allocated in a data center, ideally minimizing the overhead for communicating data and executing operators in the pipeline while considering each operator's execution requirements. In this paper, we model the problem of optimal data pipeline deployment as planning with action costs, where we propose heuristics aiming to minimize total execution time. Experimental results indicate that the heuristics can outperform the baseline deployment and that a heuristic based on connections outperforms other strategies.", 'abstract_zh': '数据管道部署优化建模为带有动作成本的规划问题：基于连接的启发式优于其他策略', 'title_zh': '自动规划以获得最优数据管道实例化'}
{'arxiv_id': 'arXiv:2503.12505', 'title': 'MPBench: A Comprehensive Multimodal Reasoning Benchmark for Process Errors Identification', 'authors': 'Zhaopan Xu, Pengfei Zhou, Jiaxin Ai, Wangbo Zhao, Kai Wang, Xiaojiang Peng, Wenqi Shao, Hongxun Yao, Kaipeng Zhang', 'link': 'https://arxiv.org/abs/2503.12505', 'abstract': 'Reasoning is an essential capacity for large language models (LLMs) to address complex tasks, where the identification of process errors is vital for improving this ability. Recently, process-level reward models (PRMs) were proposed to provide step-wise rewards that facilitate reinforcement learning and data production during training and guide LLMs toward correct steps during inference, thereby improving reasoning accuracy. However, existing benchmarks of PRMs are text-based and focus on error detection, neglecting other scenarios like reasoning search. To address this gap, we introduce MPBench, a comprehensive, multi-task, multimodal benchmark designed to systematically assess the effectiveness of PRMs in diverse scenarios. MPBench employs three evaluation paradigms, each targeting a specific role of PRMs in the reasoning process: (1) Step Correctness, which assesses the correctness of each intermediate reasoning step; (2) Answer Aggregation, which aggregates multiple solutions and selects the best one; and (3) Reasoning Process Search, which guides the search for optimal reasoning steps during inference. Through these paradigms, MPBench makes comprehensive evaluations and provides insights into the development of multimodal PRMs.', 'abstract_zh': '大语言模型(LLMs)处理复杂任务时需要推理能力，其中过程错误的识别对于提高这一能力至关重要。近日，提出了过程级奖励模型(PRMs)，以提供步骤级奖励，促进训练期间的强化学习和数据生成，并在推理时引导LLMs采取正确的步骤，从而提高推理准确性。然而，现有的PRM基准大多是基于文本，主要集中在错误检测上，忽略了如推理搜索等其他场景。为弥补这一点，我们引入了MPBench，这是一个全面的多任务、多模态基准，旨在系统评估PRMs在各种场景中的有效性。MPBench采用三种评估范式，分别针对PRMs在推理过程中的特定作用：(1) 步骤正确性，评估每个中间推理步骤的正确性；(2) 答案汇总，汇总多种解决方案并选择最佳者；(3) 推理过程搜索，在推理时引导对最优推理步骤的搜索。通过这些范式，MPBench进行了全面评估并为多模态PRM的发展提供了洞见。', 'title_zh': 'MPBench: 一个全面的多模态推理基准，用于过程错误识别'}
{'arxiv_id': 'arXiv:2503.12434', 'title': 'A Survey on the Optimization of Large Language Model-based Agents', 'authors': 'Shangheng Du, Jiabao Zhao, Jinxin Shi, Zhentao Xie, Xin Jiang, Yanhong Bai, Liang He', 'link': 'https://arxiv.org/abs/2503.12434', 'abstract': 'With the rapid development of Large Language Models (LLMs), LLM-based agents have been widely adopted in various fields, becoming essential for autonomous decision-making and interactive tasks. However, current work typically relies on prompt design or fine-tuning strategies applied to vanilla LLMs, which often leads to limited effectiveness or suboptimal performance in complex agent-related environments. Although LLM optimization techniques can improve model performance across many general tasks, they lack specialized optimization towards critical agent functionalities such as long-term planning, dynamic environmental interaction, and complex decision-making. Although numerous recent studies have explored various strategies to optimize LLM-based agents for complex agent tasks, a systematic review summarizing and comparing these methods from a holistic perspective is still lacking. In this survey, we provide a comprehensive review of LLM-based agent optimization approaches, categorizing them into parameter-driven and parameter-free methods. We first focus on parameter-driven optimization, covering fine-tuning-based optimization, reinforcement learning-based optimization, and hybrid strategies, analyzing key aspects such as trajectory data construction, fine-tuning techniques, reward function design, and optimization algorithms. Additionally, we briefly discuss parameter-free strategies that optimize agent behavior through prompt engineering and external knowledge retrieval. Finally, we summarize the datasets and benchmarks used for evaluation and tuning, review key applications of LLM-based agents, and discuss major challenges and promising future directions. Our repository for related references is available at this https URL.', 'abstract_zh': '随着大型语言模型（LLMs）的快速发展，基于LLM的代理已经在多个领域广泛应用，成为自主决策和交互任务中不可或缺的部分。然而，当前的工作通常依赖于对原始LLM进行提示设计或微调策略，这在复杂的代理相关环境中往往导致有限的效果或次优性能。尽管LLM优化技术可以在众多通用任务中提高模型性能，但它们缺乏针对诸如长期规划、动态环境交互和复杂决策等关键代理功能的专业优化。尽管最近有许多研究探索了各种策略来优化基于LLM的代理以适应复杂的代理任务，但仍缺乏从整体视角对其进行总结和比较的系统综述。在这篇综述中，我们提供了一个全面的基于LLM的代理优化方法综述，将其分为参数驱动和无参数方法两类。我们首先关注参数驱动的优化，包括基于微调的优化、基于强化学习的优化和混合策略，分析了轨迹数据构建、微调技术、奖励函数设计和优化算法等方面的关键问题。此外，我们简要讨论了通过提示工程和外部知识检索来优化代理行为的无参数策略。最后，我们总结了用于评估和调整的常用数据集和基准，并回顾了基于LLM的代理的关键应用，讨论了主要挑战和有前途的未来方向。相关参考文献的仓库可在以下链接访问：this https URL。', 'title_zh': '大型语言模型代理的优化研究'}
{'arxiv_id': 'arXiv:2503.12389', 'title': 'FedGAI: Federated Style Learning with Cloud-Edge Collaboration for Generative AI in Fashion Design', 'authors': 'Mingzhu Wu, Jianan Jiang, Xinglin Li, Hanhui Deng, Di Wu', 'link': 'https://arxiv.org/abs/2503.12389', 'abstract': "Collaboration can amalgamate diverse ideas, styles, and visual elements, fostering creativity and innovation among different designers. In collaborative design, sketches play a pivotal role as a means of expressing design creativity. However, designers often tend to not openly share these meticulously crafted sketches. This phenomenon of data island in the design area hinders its digital transformation under the third wave of AI. In this paper, we introduce a Federated Generative Artificial Intelligence Clothing system, namely FedGAI, employing federated learning to aid in sketch design. FedGAI is committed to establishing an ecosystem wherein designers can exchange sketch styles among themselves. Through FedGAI, designers can generate sketches that incorporate various designers' styles from their peers, drawing inspiration from collaboration without the need for data disclosure or upload. Extensive performance evaluations indicate that our FedGAI system can produce multi-styled sketches of comparable quality to human-designed ones while significantly enhancing efficiency compared to hand-drawn sketches.", 'abstract_zh': '协作可以融合多样化的理念、风格和视觉元素，促进不同设计师之间的创新。在协作设计中，草图是表达设计理念的关键手段。然而，设计师往往不愿意公开分享这些精心制作的草图。设计领域的数据孤岛阻碍了在第三次人工智能浪潮下的数字化转型。本文介绍了一种基于联邦学习的生成型人工智能服装系统，即FedGAI，旨在帮助设计师进行草图设计。FedGAI致力于建立一个设计师之间可以交流草图风格的生态系统。通过FedGAI，设计师可以从 peers 的多种设计风格中汲取灵感生成草图，而无需披露或上传数据。大量的性能评估表明，我们的FedGAI系统可以生成与人工设计质量相当、在效率上显著优于手绘草图的多风格草图。', 'title_zh': 'FedGAI：基于云边协作的服装设计生成式人工智能风格学习 federated learning'}
{'arxiv_id': 'arXiv:2503.12358', 'title': 'IPCGRL: Language-Instructed Reinforcement Learning for Procedural Level Generation', 'authors': 'In-Chang Baek, Sung-Hyun Kim, Seo-yung Lee, Dong-Hyun Lee, Kyung-Joong Kim', 'link': 'https://arxiv.org/abs/2503.12358', 'abstract': 'Recent research has highlighted the significance of natural language in enhancing the controllability of generative models. While various efforts have been made to leverage natural language for content generation, research on deep reinforcement learning (DRL) agents utilizing text-based instructions for procedural content generation remains limited. In this paper, we propose IPCGRL, an instruction-based procedural content generation method via reinforcement learning, which incorporates a sentence embedding model. IPCGRL fine-tunes task-specific embedding representations to effectively compress game-level conditions. We evaluate IPCGRL in a two-dimensional level generation task and compare its performance with a general-purpose embedding method. The results indicate that IPCGRL achieves up to a 21.4% improvement in controllability and a 17.2% improvement in generalizability for unseen instructions. Furthermore, the proposed method extends the modality of conditional input, enabling a more flexible and expressive interaction framework for procedural content generation.', 'abstract_zh': '基于指令的强化学习程序化内容生成方法（IPCGRL）', 'title_zh': 'IPCGRL：基于语言的强化学习程序化水平生成'}
{'arxiv_id': 'arXiv:2503.12349', 'title': 'SPIN-Bench: How Well Do LLMs Plan Strategically and Reason Socially?', 'authors': 'Jianzhu Yao, Kevin Wang, Ryan Hsieh, Haisu Zhou, Tianqing Zou, Zerui Cheng, Zhangyang Wang, Pramod Viswanath', 'link': 'https://arxiv.org/abs/2503.12349', 'abstract': 'Reasoning and strategic behavior in \\emph{social interactions} is a hallmark of intelligence. This form of reasoning is significantly more sophisticated than isolated planning or reasoning tasks in static settings (e.g., math problem solving). In this paper, we present \\textit{Strategic Planning, Interaction, and Negotiation} (\\textbf{SPIN-Bench}), a new multi-domain evaluation designed to measure the intelligence of \\emph{strategic planning} and \\emph{social reasoning}. While many existing benchmarks focus on narrow planning or single-agent reasoning, SPIN-Bench combines classical PDDL tasks, competitive board games, cooperative card games, and multi-agent negotiation scenarios in one unified framework. The framework includes both a benchmark as well as an arena to simulate and evaluate the variety of social settings to test reasoning and strategic behavior of AI agents. We formulate the benchmark SPIN-Bench by systematically varying action spaces, state complexity, and the number of interacting agents to simulate a variety of social settings where success depends on not only methodical and step-wise decision making, but also \\emph{conceptual inference} of other (adversarial or cooperative) participants. Our experiments reveal that while contemporary LLMs handle \\emph{basic fact retrieval} and \\emph{short-range planning} reasonably well, they encounter significant performance bottlenecks in tasks requiring \\emph{deep multi-hop reasoning} over large state spaces and \\emph{socially adept} coordination under uncertainty. We envision SPIN-Bench as a catalyst for future research on robust multi-agent planning, social reasoning, and human--AI teaming.', 'abstract_zh': '战略规划、互动与谈判：智能评估基准（SPIN-Bench）', 'title_zh': 'SPIN-Bench: 计划策略性和社会推理能力，大型语言模型表现如何？'}
{'arxiv_id': 'arXiv:2503.12317', 'title': 'A Transformer-based survival model for prediction of all-cause mortality in heart failure patients: a multi-cohort study', 'authors': 'Shishir Rao, Nouman Ahmed, Gholamreza Salimi-Khorshidi, Christopher Yau, Huimin Su, Nathalie Conrad, Folkert W Asselbergs, Mark Woodward, Rod Jackson, John GF Cleland, Kazem Rahimi', 'link': 'https://arxiv.org/abs/2503.12317', 'abstract': "We developed and validated TRisk, a Transformer-based AI model predicting 36-month mortality in heart failure patients by analysing temporal patient journeys from UK electronic health records (EHR). Our study included 403,534 heart failure patients (ages 40-90) from 1,418 English general practices, with 1,063 practices for model derivation and 355 for external validation. TRisk was compared against the MAGGIC-EHR model across various patient subgroups. With median follow-up of 9 months, TRisk achieved a concordance index of 0.845 (95% confidence interval: [0.841, 0.849]), significantly outperforming MAGGIC-EHR's 0.728 (0.723, 0.733) for predicting 36-month all-cause mortality. TRisk showed more consistent performance across sex, age, and baseline characteristics, suggesting less bias. We successfully adapted TRisk to US hospital data through transfer learning, achieving a C-index of 0.802 (0.789, 0.816) with 21,767 patients. Explainability analyses revealed TRisk captured established risk factors while identifying underappreciated predictors like cancers and hepatic failure that were important across both cohorts. Notably, cancers maintained strong prognostic value even a decade after diagnosis. TRisk demonstrated well-calibrated mortality prediction across both healthcare systems. Our findings highlight the value of tracking longitudinal health profiles and revealed risk factors not included in previous expert-driven models.", 'abstract_zh': '基于Transformer的TRisk模型：预测心力衰竭患者36个月全因 Mortality 的开发与验证', 'title_zh': '基于变压器的生存模型在心力衰竭患者全因死亡率预测中的应用：一项多队列研究'}
{'arxiv_id': 'arXiv:2503.12181', 'title': 'Value Gradients with Action Adaptive Search Trees in Continuous (PO)MDPs', 'authors': 'Idan Lev-Yehudi, Michael Novitsky, Moran Barenboim, Ron Benchetrit, Vadim Indelman', 'link': 'https://arxiv.org/abs/2503.12181', 'abstract': 'Solving Partially Observable Markov Decision Processes (POMDPs) in continuous state, action and observation spaces is key for autonomous planning in many real-world mobility and robotics applications. Current approaches are mostly sample based, and cannot hope to reach near-optimal solutions in reasonable time. We propose two complementary theoretical contributions. First, we formulate a novel Multiple Importance Sampling (MIS) tree for value estimation, that allows to share value information between sibling action branches. The novel MIS tree supports action updates during search time, such as gradient-based updates. Second, we propose a novel methodology to compute value gradients with online sampling based on transition likelihoods. It is applicable to MDPs, and we extend it to POMDPs via particle beliefs with the application of the propagated belief trick. The gradient estimator is computed in practice using the MIS tree with efficient Monte Carlo sampling. These two parts are combined into a new planning algorithm Action Gradient Monte Carlo Tree Search (AGMCTS). We demonstrate in a simulated environment its applicability, advantages over continuous online POMDP solvers that rely solely on sampling, and we discuss further implications.', 'abstract_zh': '在连续状态、动作和观测空间中解决部分可观测量决策过程（POMDPs）是许多实际移动性和机器人应用自主规划的关键。当前的方法主要是基于采样的，无法在合理的时间内达到接近最优的解决方案。我们提出了两个互补的理论贡献。首先，我们提出了一个新的多重重要性采样（MIS）树来估计价值，该树允许在行动分支之间共享价值信息。新的MIS树在搜索过程中支持基于梯度的行动更新。其次，我们提出了一种新的方法，利用转移概率进行在线采样来计算价值梯度。该方法适用于MDP，并通过粒子信念将其扩展到POMDP。梯度估计器在实践中使用带有效率的蒙特卡洛采样的MIS树进行计算。这两部分结合成一个新的规划算法：行动梯度蒙特卡洛树搜索（AGMCTS）。我们在模拟环境中展示了其适用性，与仅依赖采样的连续在线POMDP求解器相比的优势，并讨论了进一步的含义。', 'title_zh': '在连续(PO)MDPs中基于动作自适应搜索树的价值梯度方法'}
{'arxiv_id': 'arXiv:2503.12161', 'title': "Aristotle's Original Idea: For and Against Logic in the era of AI", 'authors': 'Antonis C. Kakas', 'link': 'https://arxiv.org/abs/2503.12161', 'abstract': "Aristotle is generally accepted as the father of logic. The ideas that he raised in his study of logical reasoning carried the development of science over the centuries. Today, in the era of AI, this title of the fatherhood of logic has a renewed significance. Behind it lies his original idea that human reasoning could be studied as a process and that perhaps there exist universal systems of reasoning that underly all human reasoning irrespective of the content of what we are reasoning about. In this article, we look into Aristotle's work on human thought, his work on reasoning itself but also on how it relates to science and human endeavor more generally, from a modern perspective of Artificial Intelligence and ask if this can help enlighten our understanding of AI and Science more generally.", 'abstract_zh': '亚里士多德一般被视为逻辑之父。他在逻辑推理研究中提出的观点推动了科学数个世纪的发展。在人工智能时代，这一“逻辑之父”的称号获得了新的意义。背后蕴含着他关于人类推理可以被视为一个过程的原创思想，以及可能存在着适用于所有人类推理的普遍推理系统的观点。在本文中，我们从人工智能的现代视角审视亚里士多德关于人类思维、推理本身及其与更广泛的科学和人类努力的关系的工作，探讨这是否能帮助我们更深入地理解人工智能和科学。', 'title_zh': '亚里士多德的原创理念：在人工智能时代为逻辑与反对逻辑之争'}
{'arxiv_id': 'arXiv:2503.12085', 'title': 'Automating the loop in traffic incident management on highway', 'authors': 'Matteo Cercola, Nicola Gatti, Pedro Huertas Leyva, Benedetto Carambia, Simone Formentin', 'link': 'https://arxiv.org/abs/2503.12085', 'abstract': "Effective traffic incident management is essential for ensuring safety, minimizing congestion, and reducing response times in emergency situations. Traditional highway incident management relies heavily on radio room operators, who must make rapid, informed decisions in high-stakes environments. This paper proposes an innovative solution to support and enhance these decisions by integrating Large Language Models (LLMs) into a decision-support system for traffic incident management. We introduce two approaches: (1) an LLM + Optimization hybrid that leverages both the flexibility of natural language interaction and the robustness of optimization techniques, and (2) a Full LLM approach that autonomously generates decisions using only LLM capabilities. We tested our solutions using historical event data from Autostrade per l'Italia. Experimental results indicate that while both approaches show promise, the LLM + Optimization solution demonstrates superior reliability, making it particularly suited to critical applications where consistency and accuracy are paramount. This research highlights the potential for LLMs to transform highway incident management by enabling accessible, data-driven decision-making support.", 'abstract_zh': "有效的交通事件管理对于确保安全、减少拥堵和降低应急反应时间至关重要。传统的高速公路事件管理高度依赖于电台室操作员，他们在高风险环境中必须迅速做出明智的决策。本文提出了一种创新解决方案，通过将大型语言模型（LLMs）集成到交通事件管理决策支持系统中来支持和增强这些决策。我们介绍了两种方法：（1）LLM +优化的混合方法，利用自然语言交互的灵活性和优化技术的稳健性，以及（2）全LLM方法，仅利用LLM的能力自主生成决策。我们使用Autostrade per l'Italia的历史事件数据测试了我们的解决方案。实验结果显示，虽然两种方法都显示出潜力，但LLM +优化的方法在可靠性方面表现出色，使其特别适合那些一致性和准确性至关重要的关键应用。本文强调了LLMs在通过实现可访问的数据驱动决策支持来变革高速公路事件管理方面的潜力。", 'title_zh': '在高速公路交通事件管理中自动化循环过程'}
{'arxiv_id': 'arXiv:2503.11951', 'title': 'SagaLLM: Context Management, Validation, and Transaction Guarantees for Multi-Agent LLM Planning', 'authors': 'Edward Y. Chang', 'link': 'https://arxiv.org/abs/2503.11951', 'abstract': 'Recent LLM-based agent frameworks have demonstrated impressive capabilities in task delegation and workflow orchestration, but face significant challenges in maintaining context awareness and ensuring planning consistency. This paper presents SagaLLM, a structured multi-agent framework that addresses four fundamental limitations in current LLM approaches: inadequate self-validation, context narrowing, lacking transaction properties, and insufficient inter-agent coordination. By implementing specialized context management agents and validation protocols, SagaLLM preserves critical constraints and state information throughout complex planning processes, enabling robust and consistent decision-making even during disruptions. We evaluate our approach using selected problems from the REALM benchmark, focusing on sequential and reactive planning scenarios that challenge both context retention and adaptive reasoning. Our experiments with state-of-the-art LLMs, Claude 3.7, DeepSeek R1, GPT-4o, and GPT-o1, demonstrate that while these models exhibit impressive reasoning capabilities, they struggle with maintaining global constraint awareness during complex planning tasks, particularly when adapting to unexpected changes. In contrast, the distributed cognitive architecture of SagaLLM shows significant improvements in planning consistency, constraint enforcement, and adaptation to disruptions in various scenarios.', 'abstract_zh': 'Recent LLM-Based Agent Frameworks Have Demonstrated Impressive Capabilities in Task Delegation and Workflow Orchestration but Face Significant Challenges in Maintaining Context Awareness and Ensuring Planning Consistency: This Paper Presents SagaLLM, a Structured Multi-Agent Framework That Addresses Four Fundamental Limitations in Current LLM Approaches', 'title_zh': 'SagaLLM：多智能体LLM规划中的上下文管理、验证和事务保证'}
{'arxiv_id': 'arXiv:2503.11926', 'title': 'Monitoring Reasoning Models for Misbehavior and the Risks of Promoting Obfuscation', 'authors': 'Bowen Baker, Joost Huizinga, Leo Gao, Zehao Dou, Melody Y. Guan, Aleksander Madry, Wojciech Zaremba, Jakub Pachocki, David Farhi', 'link': 'https://arxiv.org/abs/2503.11926', 'abstract': "Mitigating reward hacking--where AI systems misbehave due to flaws or misspecifications in their learning objectives--remains a key challenge in constructing capable and aligned models. We show that we can monitor a frontier reasoning model, such as OpenAI o3-mini, for reward hacking in agentic coding environments by using another LLM that observes the model's chain-of-thought (CoT) reasoning. CoT monitoring can be far more effective than monitoring agent actions and outputs alone, and we further found that a LLM weaker than o3-mini, namely GPT-4o, can effectively monitor a stronger model. Because CoT monitors can be effective at detecting exploits, it is natural to ask whether those exploits can be suppressed by incorporating a CoT monitor directly into the agent's training objective. While we show that integrating CoT monitors into the reinforcement learning reward can indeed produce more capable and more aligned agents in the low optimization regime, we find that with too much optimization, agents learn obfuscated reward hacking, hiding their intent within the CoT while still exhibiting a significant rate of reward hacking. Because it is difficult to tell when CoTs have become obfuscated, it may be necessary to pay a monitorability tax by not applying strong optimization pressures directly to the chain-of-thought, ensuring that CoTs remain monitorable and useful for detecting misaligned behavior.", 'abstract_zh': '缓解奖励作弊——即AI系统因学习目标中的缺陷或疏漏而导致的不当行为——仍然是构建具备能力和对齐的模型的关键挑战。我们展示了可以通过另一个大规模语言模型（LLM）监测模型的逐步推理（CoT）过程，来监控诸如OpenAI o3-mini这类前沿推理模型在代理编码环境中的奖励作弊行为。CoT监测比单独监测代理行为和输出更为有效，我们进一步发现，一个比o3-mini弱的LLM，即GPT-4o，也能有效监测更强的模型。由于CoT监测能够有效检测作弊行为，自然会引发一个疑问，即是否可以通过将CoT监测直接纳入代理的训练目标中来抑制这些作弊行为。尽管我们展示了在低优化条件下，将CoT监测集成到强化学习奖励中确实能够产出更具能力和更对齐的代理，但我们发现，在过度优化的情况下，代理会学会更加隐蔽的奖励作弊行为，将其意图隐藏在CoT中，但仍体现出显著的奖励作弊率。由于难以判断CoT何时变得隐蔽，可能需要支付可监测性税，即不直接对CoT施加强大的优化压力，以确保CoT保持可监测性和检测不对齐行为的有效性。', 'title_zh': '监控推理模型的不当行为及促进混淆的风险'}
{'arxiv_id': 'arXiv:2503.11870', 'title': 'Counterfactual Realizability', 'authors': 'Arvind Raghavan, Elias Bareinboim', 'link': 'https://arxiv.org/abs/2503.11870', 'abstract': 'It is commonly believed that, in a real-world environment, samples can only be drawn from observational and interventional distributions, corresponding to Layers 1 and 2 of the Pearl Causal Hierarchy. Layer 3, representing counterfactual distributions, is believed to be inaccessible by definition. However, Bareinboim, Forney, and Pearl (2015) introduced a procedure that allows an agent to sample directly from a counterfactual distribution, leaving open the question of what other counterfactual quantities can be estimated directly via physical experimentation. We resolve this by introducing a formal definition of realizability, the ability to draw samples from a distribution, and then developing a complete algorithm to determine whether an arbitrary counterfactual distribution is realizable given fundamental physical constraints, such as the inability to go back in time and subject the same unit to a different experimental condition. We illustrate the implications of this new framework for counterfactual data collection using motivating examples from causal fairness and causal reinforcement learning. While the baseline approach in these motivating settings typically follows an interventional or observational strategy, we show that a counterfactual strategy provably dominates both.', 'abstract_zh': '普遍认为，在现实环境中，样本只能来自于观察性和干预性分布，对应佩尔因果层次结构中的第1层和第2层。第3层的反事实分布被认为由于定义原因而不可访问。然而，Bareinboim、Forney和Pearl（2015）提出了一种方法，使代理可以直接从反事实分布中抽样，从而提出了通过物理实验直接估计其他反事实量的问题。我们通过引入可实现性的正式定义——从分布中抽样的能力——并开发了一种完全算法来确定在基本物理约束（如不能时间倒流和对同一单位施加不同实验条件）下，任意反事实分布是否可实现。我们利用因果公平性和因果强化学习中的激励性示例，阐述了这一新框架对反事实数据收集的影响。虽然这些激励性场景下基线方法通常遵循干预性或观察性策略，我们展示了反事实策略在理论上优于两者。', 'title_zh': '反事实可实现性'}
{'arxiv_id': 'arXiv:2503.11832', 'title': 'Safety Mirage: How Spurious Correlations Undermine VLM Safety Fine-tuning', 'authors': 'Yiwei Chen, Yuguang Yao, Yihua Zhang, Bingquan Shen, Gaowen Liu, Sijia Liu', 'link': 'https://arxiv.org/abs/2503.11832', 'abstract': 'Recent vision-language models (VLMs) have made remarkable strides in generative modeling with multimodal inputs, particularly text and images. However, their susceptibility to generating harmful content when exposed to unsafe queries raises critical safety concerns. While current alignment strategies primarily rely on supervised safety fine-tuning with curated datasets, we identify a fundamental limitation we call the "safety mirage" where supervised fine-tuning inadvertently reinforces spurious correlations between superficial textual patterns and safety responses, rather than fostering deep, intrinsic mitigation of harm. We show that these spurious correlations leave fine-tuned VLMs vulnerable even to a simple one-word modification-based attack, where substituting a single word in text queries with a spurious correlation-inducing alternative can effectively bypass safeguards. Additionally, these correlations contribute to the over prudence, causing fine-tuned VLMs to refuse benign queries unnecessarily. To address this issue, we show machine unlearning (MU) as a powerful alternative to supervised safety fine-tuning as it avoids biased feature-label mappings and directly removes harmful knowledge from VLMs while preserving their general capabilities. Extensive evaluations across safety benchmarks show that under one-word attacks, MU-based alignment reduces the attack success rate by up to 60.17% and cuts unnecessary rejections by over 84.20%. Codes are available at this https URL. WARNING: There exist AI generations that may be offensive in nature.', 'abstract_zh': '近期的多模态视觉-语言模型（VLMs）在基于文本和图像的生成建模方面取得了显著进展。然而，它们在接触到不安全查询时生成有害内容的倾向引发了重要的安全问题。当前的对齐策略主要依赖于监督安全微调和精心策划的数据集，但我们发现了一个根本性的局限性，我们称之为“安全幻象”，即监督微调无意中加强了表面上的文字模式与安全响应之间的虚假相关性，而非培养深层次的本质性的有害内容缓解机制。我们展示了这些虚假相关性使得经过微调的VLMs即使在简单的单词修改攻击下也容易受损，其中通过用含有虚假相关性诱导的替代词替换文本查询中的单个词可以有效绕过安全防护。此外，这些相关性导致过度谨慎，使经过微调的VLMs对本不应拒绝的查询进行不必要的拒绝。为解决这一问题，我们展示了机器遗忘（MU）作为一种强大的替代方法，因为它避免了有偏的特征-标签映射，并直接从VLMs中移除有害知识，同时保留其一般能力。在多个安全基准上的广泛评估显示，在单词攻击下，基于MU的对齐将攻击成功率降低了高达60.17%，并减少了超过84.20%的不必要的拒绝。相关的代码可在以下链接获取：这个 https URL。警告：可能存在具有不礼貌性质的AI生成内容。', 'title_zh': '幻象的安全性：虚假相关性如何损害VLM安全性微调'}
{'arxiv_id': 'arXiv:2503.11820', 'title': 'An Algebraic Approach to Moralisation and Triangulation of Probabilistic Graphical Models', 'authors': 'Antonio Lorenzin, Fabio Zanasi', 'link': 'https://arxiv.org/abs/2503.11820', 'abstract': "Moralisation and Triangulation are transformations allowing to switch between different ways of factoring a probability distribution into a graphical model. Moralisation allows to view a Bayesian network (a directed model) as a Markov network (an undirected model), whereas triangulation works in the opposite direction. We present a categorical framework where these transformations are modelled as functors between a category of Bayesian networks and one of Markov networks. The two kinds of network (the objects of these categories) are themselves represented as functors, from a `syntax' domain to a `semantics' codomain. Notably, moralisation and triangulation are definable inductively on such syntax, and operate as a form of functor pre-composition. This approach introduces a modular, algebraic perspective in the theory of probabilistic graphical models.", 'abstract_zh': '道德化和三角化是允许在不同方式下分解概率分布到图形模型之间进行转换的变换。道德化允许将有向模型（贝叶斯网络）视作无向模型（马尔科夫网络），而三角化则反之。我们提出一种范畴论框架，其中这些变换被表示为贝叶斯网络范畴与马尔科夫网络范畴之间的函子。这两种类型的网络（这些范畴的对象）本身被表示为从“语法”领域到“语义”陪域的函子。值得注意的是，道德化和三角化可以在这种语法上归纳定义，并且作为函子预合成的形式进行操作。这种方法为概率图形模型理论引入了一种模块化和代数化的视角。', 'title_zh': '概率图形模型的道德化与三角化代数方法'}
{'arxiv_id': 'arXiv:2503.11790', 'title': 'Visualizing Thought: Conceptual Diagrams Enable Robust Planning in LMMs', 'authors': 'Nasim Borazjanizadeh, Roei Herzig, Eduard Oks, Trevor Darrell, Rogerio Feris, Leonid Karlinsky', 'link': 'https://arxiv.org/abs/2503.11790', 'abstract': "Human reasoning relies on constructing and manipulating mental models-simplified internal representations of situations that we use to understand and solve problems. Conceptual diagrams (for example, sketches drawn by humans to aid reasoning) externalize these mental models, abstracting irrelevant details to efficiently capture relational and spatial information. In contrast, Large Language Models (LLMs) and Large Multimodal Models (LMMs) predominantly reason through textual representations, limiting their effectiveness in complex multi-step combinatorial and planning tasks. In this paper, we propose a zero-shot fully automatic framework that enables LMMs to reason through multiple chains of self-generated intermediate conceptual diagrams, significantly enhancing their combinatorial planning capabilities. Our approach does not require any human initialization beyond a natural language description of the task. It integrates both textual and diagrammatic reasoning within an optimized graph-of-thought inference framework, enhanced by beam search and depth-wise backtracking. Evaluated on multiple challenging PDDL planning domains, our method substantially improves GPT-4o's performance (for example, from 35.5% to 90.2% in Blocksworld). On more difficult planning domains with solution depths up to 40, our approach outperforms even the o1-preview reasoning model (for example, over 13% improvement in Parking). These results highlight the value of conceptual diagrams as a complementary reasoning medium in LMMs.", 'abstract_zh': '人类推理依赖于构建和操作心理模型——这些是简化内部表示的情景，我们用来理解和解决问题。概念图（例如，人类绘制的辅助推理的草图）外部化这些心理模型，抽象掉不相关的细节，以有效地捕捉关系和空间信息。相比之下，大型语言模型（LLMs）和大型多模态模型（LMMs）主要通过文本表示来进行推理，这限制了它们在复杂多步组合和规划任务中的有效性。在本文中，我们提出了一种零样本全自动框架，使LMMs能够通过多条自动生成的中间概念图进行推理，显著增强了它们的组合规划能力。我们的方法不需要任何人类初始化，只需自然语言描述任务。该方法在优化的思想图推断框架中结合了文本和图示推理，并通过束搜索和深度回溯得到了增强。在多个具有挑战性的PDDL规划领域进行评估后，我们的方法明显提高了GPT-4o的表现（例如，在Blocksworld中，从35.5%提高到90.2%）。在更具挑战性的规划领域，解决方案深度高达40时，我们的方法甚至超过了o1-preview推理模型（例如，在Parking中，提高了超过13%）。这些结果突显了概念图作为LMMs中补充推理媒介的价值。', 'title_zh': '可视化思维：概念图谱使大规模语言模型实现稳健规划'}
{'arxiv_id': 'arXiv:2503.11743', 'title': 'PUBLICSPEAK: Hearing the Public with a Probabilistic Framework in Local Government', 'authors': 'Tianliang Xu, Eva Maxfield Brown, Dustin Dwyer, Sabina Tomkins', 'link': 'https://arxiv.org/abs/2503.11743', 'abstract': 'Local governments around the world are making consequential decisions on behalf of their constituents, and these constituents are responding with requests, advice, and assessments of their officials at public meetings. So many small meetings cannot be covered by traditional newsrooms at scale. We propose PUBLICSPEAK, a probabilistic framework which can utilize meeting structure, domain knowledge, and linguistic information to discover public remarks in local government meetings. We then use our approach to inspect the issues raised by constituents in 7 cities across the United States. We evaluate our approach on a novel dataset of local government meetings and find that PUBLICSPEAK improves over state-of-the-art by 10% on average, and by up to 40%.', 'abstract_zh': '全球各地的地方政府正代表其选民做出重要决策，而这些选民则通过在公共会议上提出请求、提供建议和评估官员表现作出回应。由于众多小型会议无法被传统新闻机构大规模覆盖，我们提出一种概率性框架——PUBLICSPEAK，该框架能够利用会议结构、领域知识和语言信息来发现地方政府部门会议中的公众言论。我们随后利用该方法检查了美国7个城市中民众提出的议题。我们在一个新型的地方政府会议数据集上评估了该方法，并发现与现有最佳方法相比，PUBLICSPEAK在平均性能上提高了10%，最高提升了40%。', 'title_zh': 'PUBLICSPEAK：基于概率框架倾听公众在地方政府中的声音'}
{'arxiv_id': 'arXiv:2503.11723', 'title': 'Physics-based simulation ontology: an ontology to support modelling and reuse of data for physics-based simulation', 'authors': 'Hyunmin Cheong, Adrian Butscher', 'link': 'https://arxiv.org/abs/2503.11723', 'abstract': 'The current work presents an ontology developed for physics-based simulation in engineering design, called Physics-based Simulation Ontology (PSO). The purpose of the ontology is to assist in modelling the physical phenomenon of interest in a veridical manner, while capturing the necessary and reusable information for physics-based simulation solvers. The development involved extending an existing upper ontology, Basic Formal Ontology (BFO), to define lower-level terms of PSO. PSO has two parts: PSO-Physics, which consists of terms and relations used to model physical phenomena based on the perspective of classical mechanics involving partial differential equations, and PSO-Sim, which consists of terms used to represent the information artefacts that are about the physical phenomena modelled with PSO-Physics. The former terms are used to model the physical phenomenon of interest independent of solver-specific interpretations, which can be reused across different solvers, while the latter terms are used to instantiate solver-specific input data. A case study involving two simulation solvers was conducted to demonstrate this capability of PSO. Discussion around the benefits and limitations of using BFO for the current work is also provided, which should be valuable for any future work that extends an existing upper ontology to develop ontologies for engineering applications.', 'abstract_zh': '基于物理的工程设计仿真本体（PSO）发展研究', 'title_zh': '基于物理的仿真本体：一种支持物理基于仿真数据建模和重用的本体'}
{'arxiv_id': 'arXiv:2503.11718', 'title': 'The Relativity of Causal Knowledge', 'authors': "Gabriele D'Acunto, Claudio Battiloro", 'link': 'https://arxiv.org/abs/2503.11718', 'abstract': 'Recent advances in artificial intelligence reveal the limits of purely predictive systems and call for a shift toward causal and collaborative reasoning. Drawing inspiration from the revolution of Grothendieck in mathematics, we introduce the relativity of causal knowledge, which posits structural causal models (SCMs) are inherently imperfect, subjective representations embedded within networks of relationships. By leveraging category theory, we arrange SCMs into a functor category and show that their observational and interventional probability measures naturally form convex structures. This result allows us to encode non-intervened SCMs with convex spaces of probability measures. Next, using sheaf theory, we construct the network sheaf and cosheaf of causal knowledge. These structures enable the transfer of causal knowledge across the network while incorporating interventional consistency and the perspective of the subjects, ultimately leading to the formal, mathematical definition of relative causal knowledge.', 'abstract_zh': 'Recent advances in artificial intelligence揭示纯预测系统之局限，呼吁转向因果和协作推理。受到Grothendieck在数学革命的启发，我们引入因果知识的相对性，认为结构因果模型（SCMs）本质上是嵌入在关系网络中的不完美、主观的表示。通过运用范畴论，我们将SCMs组织成一个函子范畴，并展示它们的观察概率度量和干预概率度量自然形成了凸结构。这一结果使我们能够使用概率度量的凸空间来编码非干预的SCMs。接着，利用层论，我们构建因果知识的网络层和余层。这些结构使因果知识在网络中传输的同时，结合了干预一致性以及主体的视角，最终形成了相对因果知识的形式化数学定义。', 'title_zh': '因果知识的相对性'}
{'arxiv_id': 'arXiv:2503.11702', 'title': 'Toward a method for LLM-enabled Indoor Navigation', 'authors': 'Alberto Coffrini, Mohammad Amin Zadenoori, Paolo Barsocchi, Francesco Furfari, Antonino Crivello, Alessio Ferrari', 'link': 'https://arxiv.org/abs/2503.11702', 'abstract': 'Indoor navigation presents unique challenges due to complex layouts, lack of GPS signals, and accessibility concerns. Existing solutions often struggle with real-time adaptability and user-specific needs. In this work, we explore the potential of a Large Language Model (LLM), i.e., ChatGPT, to generate natural, context-aware navigation instructions from indoor map images. We design and evaluate test cases across different real-world environments, analyzing the effectiveness of LLMs in interpreting spatial layouts, handling user constraints, and planning efficient routes. Our findings demonstrate the potential of LLMs for supporting personalized indoor navigation, with an average of 52% correct indications and a maximum of 62%. The results do not appear to depend on the complexity of the layout or the complexity of the expected path, but rather on the number of points of interest and the abundance of visual information, which negatively affect the performance.', 'abstract_zh': '室内导航由于复杂的布局、缺少GPS信号和可达性问题而面临独特挑战。现有的解决方案往往难以实现实时适应性和满足用户特定需求。在本研究中，我们探索了大型语言模型（LLM），即ChatGPT，生成基于室内地图图像的自然、情境感知导航指令的潜力。我们设计并评估了不同现实环境下的测试案例，分析了LLM在解释空间布局、处理用户约束以及规划高效路线方面的有效性。我们的研究结果表明，LLM有支持个性化室内导航的潜力，准确指示的平均比例为52%，最高达到62%。结果似乎与布局的复杂性或预期路径的复杂性无关，而是与兴趣点的数量以及视觉信息的丰富性有关，这些因素对性能有负面影响。', 'title_zh': '面向LLM赋能的室内导航方法研究'}
{'arxiv_id': 'arXiv:2503.11684', 'title': 'Exploring Causality for HRI: A Case Study on Robotic Mental Well-being Coaching', 'authors': 'Micol Spitale, Srikar Babu, Serhan Cakmak, Jiaee Cheong, Hatice Gunes', 'link': 'https://arxiv.org/abs/2503.11684', 'abstract': "One of the primary goals of Human-Robot Interaction (HRI) research is to develop robots that can interpret human behavior and adapt their responses accordingly. Adaptive learning models, such as continual and reinforcement learning, play a crucial role in improving robots' ability to interact effectively in real-world settings. However, these models face significant challenges due to the limited availability of real-world data, particularly in sensitive domains like healthcare and well-being. This data scarcity can hinder a robot's ability to adapt to new situations. To address these challenges, causality provides a structured framework for understanding and modeling the underlying relationships between actions, events, and outcomes. By moving beyond mere pattern recognition, causality enables robots to make more explainable and generalizable decisions. This paper presents an exploratory causality-based analysis through a case study of an adaptive robotic coach delivering positive psychology exercises over four weeks in a workplace setting. The robotic coach autonomously adapts to multimodal human behaviors, such as facial valence and speech duration. By conducting both macro- and micro-level causal analyses, this study aims to gain deeper insights into how adaptability can enhance well-being during interactions. Ultimately, this research seeks to advance our understanding of how causality can help overcome challenges in HRI, particularly in real-world applications.", 'abstract_zh': '基于因果性的类人机器人交互研究：一项关于积极心理学练习适应性教练的工作场所案例研究', 'title_zh': '探索人机交互中的因果关系：一项关于机器人心理健康辅导的案例研究'}
{'arxiv_id': 'arXiv:2503.11664', 'title': 'An LLM-Based Approach for Insight Generation in Data Analysis', 'authors': 'Alberto Sánchez Pérez, Alaa Boukhary, Paolo Papotti, Luis Castejón Lozano, Adam Elwood', 'link': 'https://arxiv.org/abs/2503.11664', 'abstract': 'Generating insightful and actionable information from databases is critical in data analysis. This paper introduces a novel approach using Large Language Models (LLMs) to automatically generate textual insights. Given a multi-table database as input, our method leverages LLMs to produce concise, text-based insights that reflect interesting patterns in the tables. Our framework includes a Hypothesis Generator to formulate domain-relevant questions, a Query Agent to answer such questions by generating SQL queries against a database, and a Summarization module to verbalize the insights. The insights are evaluated for both correctness and subjective insightfulness using a hybrid model of human judgment and automated metrics. Experimental results on public and enterprise databases demonstrate that our approach generates more insightful insights than other approaches while maintaining correctness.', 'abstract_zh': '从数据库中生成启发性和可操作性的信息对于数据分析至关重要。本文介绍了一种使用大型语言模型（LLMs）的新型方法，以自动生成文本洞察。给定一个多表数据库作为输入，我们的方法利用LLMs生成简洁的、基于文本的洞察，反映表格中的有趣模式。我们的框架包括一个假设生成器，用于提出领域相关的问题；一个查询代理，通过生成针对数据库的SQL查询来回答这些问题；以及一个总结模块，用于口头表达洞察。这些洞察使用人类判断和自动化度量相结合的混合模型进行正确性和主观洞察性的评估。实验结果表明，与其它方法相比，我们的方法在保持正确性的同时生成了更具洞察性的洞察。', 'title_zh': '基于LLM的方法在数据分析中的洞察生成'}
{'arxiv_id': 'arXiv:2503.13447', 'title': 'MetaScale: Test-Time Scaling with Evolving Meta-Thoughts', 'authors': 'Qin Liu, Wenxuan Zhou, Nan Xu, James Y. Huang, Fei Wang, Sheng Zhang, Hoifung Poon, Muhao Chen', 'link': 'https://arxiv.org/abs/2503.13447', 'abstract': 'One critical challenge for large language models (LLMs) for making complex reasoning is their reliance on matching reasoning patterns from training data, instead of proactively selecting the most appropriate cognitive strategy to solve a given task. Existing approaches impose fixed cognitive structures that enhance performance in specific tasks but lack adaptability across diverse scenarios. To address this limitation, we introduce METASCALE, a test-time scaling framework based on meta-thoughts -- adaptive thinking strategies tailored to each task. METASCALE initializes a pool of candidate meta-thoughts, then iteratively selects and evaluates them using a multi-armed bandit algorithm with upper confidence bound selection, guided by a reward model. To further enhance adaptability, a genetic algorithm evolves high-reward meta-thoughts, refining and extending the strategy pool over time. By dynamically proposing and optimizing meta-thoughts at inference time, METASCALE improves both accuracy and generalization across a wide range of tasks. Experimental results demonstrate that MetaScale consistently outperforms standard inference approaches, achieving an 11% performance gain in win rate on Arena-Hard for GPT-4o, surpassing o1-mini by 0.9% under style control. Notably, METASCALE scales more effectively with increasing sampling budgets and produces more structured, expert-level responses.', 'abstract_zh': '针对大型语言模型进行复杂推理的一项關鍵挑戰是其依賴於匹配訓練數據中的推理模式，而不是積極選擇最適合的認知策略來解決特定任務。現有方法推動固定認知結構，這些結構在特定任務上提高了性能，但缺乏在多樣場景中的適應性。為此，我們引入了METASCALE，一種基於元思維的測試時擴展框架——針對每個任務量身定制的自适应思考策略。METASCALE初始化候選元思維池，然後通過多臂bandit算法結合上 verschied擇優選擇，並由獎勵模型指導，迭代選擇和評估這些思維策略。為進一步提升適應性，我們使用遺傳算法進化高獎勵的元思維，隨時間推移調整和擴充策略池。通過動態在推理時提出和優化元思維，METASCALE在多種任務上提高了準確性和泛化能力。實驗結果表明，METASCALE一致優於標準推理方法，在GPT-4o的Arena-Hard評比中獲勝率提高了11%，在風格控制下超越o1-mini 0.9%。值得注意的是，METASCALE隨著采樣預算的增加更具擴展性，並生成更具結構性、專家級別的回應。', 'title_zh': 'MetaScale: 测试时动态扩容与进化元思维'}
{'arxiv_id': 'arXiv:2503.13445', 'title': 'Faithfulness of LLM Self-Explanations for Commonsense Tasks: Larger Is Better, and Instruction-Tuning Allows Trade-Offs but Not Pareto Dominance', 'authors': 'Noah Y. Siegel, Nicolas Heess, Maria Perez-Ortiz, Oana-Maria Camburu', 'link': 'https://arxiv.org/abs/2503.13445', 'abstract': 'As large language models (LLMs) become increasingly capable, ensuring that their self-generated explanations are faithful to their internal decision-making process is critical for safety and oversight. In this work, we conduct a comprehensive counterfactual faithfulness analysis across 62 models from 8 families, encompassing both pretrained and instruction-tuned variants and significantly extending prior studies of counterfactual tests. We introduce phi-CCT, a simplified variant of the Correlational Counterfactual Test, which avoids the need for token probabilities while explaining most of the variance of the original test. Our findings reveal clear scaling trends: larger models are consistently more faithful on our metrics. However, when comparing instruction-tuned and human-imitated explanations, we find that observed differences in faithfulness can often be attributed to explanation verbosity, leading to shifts along the true-positive/false-positive Pareto frontier. While instruction-tuning and prompting can influence this trade-off, we find limited evidence that they fundamentally expand the frontier of explanatory faithfulness beyond what is achievable with pretrained models of comparable size. Our analysis highlights the nuanced relationship between instruction-tuning, verbosity, and the faithful representation of model decision processes.', 'abstract_zh': '随着大规模语言模型（LLMs）的能力不断增强，确保其自动生成的解释忠实于其内部决策过程对于安全性和监督至关重要。在本研究中，我们对62个模型（涵盖8大家族，包括预训练和指令调优变体）进行了全面的反事实忠实性分析，显著扩展了先前的反事实测试研究。我们引入了phi-CCT，这是一种简化版的相关反事实测试，它可以避免使用令牌概率来解释原始测试的主要方差。我们的研究发现显示了清晰的扩展趋势：更大的模型在我们的指标上始终更加忠实。然而，在比较指令调优和人类模仿的解释时，我们发现观察到的忠实性差异通常可以归因于解释的冗长性，导致在真正 positives/假阳性帕累托前沿上发生转变。虽然指令调优和提示可能会影响这种权衡，但我们发现有限的证据表明它们能够在预训练模型可比规模的情况下根本上扩大解释忠实性的范围。我们的分析突显了指令调优、冗长性与模型决策过程忠实表现之间的复杂关系。', 'title_zh': '大型语言模型自我解释的忠实性对于常识任务：规模越大越好，指令调优允许权衡但不允许帕累托占优'}
{'arxiv_id': 'arXiv:2503.13444', 'title': 'VideoMind: A Chain-of-LoRA Agent for Long Video Reasoning', 'authors': 'Ye Liu, Kevin Qinghong Lin, Chang Wen Chen, Mike Zheng Shou', 'link': 'https://arxiv.org/abs/2503.13444', 'abstract': 'Videos, with their unique temporal dimension, demand precise grounded understanding, where answers are directly linked to visual, interpretable evidence. Despite significant breakthroughs in reasoning capabilities within Large Language Models, multi-modal reasoning - especially for videos - remains unexplored. In this work, we introduce VideoMind, a novel video-language agent designed for temporal-grounded video understanding. VideoMind incorporates two key innovations: (i) We identify essential capabilities for video temporal reasoning and develop a role-based agentic workflow, including a planner for coordinating different roles, a grounder for temporal localization, a verifier to assess temporal interval accuracy, and an answerer for question-answering. (ii) To efficiently integrate these diverse roles, we propose a novel Chain-of-LoRA strategy, enabling seamless role-switching via lightweight LoRA adaptors while avoiding the overhead of multiple models, thus balancing efficiency and flexibility. Extensive experiments on 14 public benchmarks demonstrate that our agent achieves state-of-the-art performance on diverse video understanding tasks, including 3 on grounded video question-answering, 6 on video temporal grounding, and 5 on general video question-answering, underscoring its effectiveness in advancing video agent and long-form temporal reasoning.', 'abstract_zh': '基于多模态推理的视频语义理解agents：VideoMind及其在视频理解任务中的应用', 'title_zh': 'VideoMind: 一种长视频推理链路模型代理'}
{'arxiv_id': 'arXiv:2503.13441', 'title': 'Humanoid Policy ~ Human Policy', 'authors': 'Ri-Zhao Qiu, Shiqi Yang, Xuxin Cheng, Chaitanya Chawla, Jialong Li, Tairan He, Ge Yan, Lars Paulsen, Ge Yang, Sha Yi, Guanya Shi, Xiaolong Wang', 'link': 'https://arxiv.org/abs/2503.13441', 'abstract': 'Training manipulation policies for humanoid robots with diverse data enhances their robustness and generalization across tasks and platforms. However, learning solely from robot demonstrations is labor-intensive, requiring expensive tele-operated data collection which is difficult to scale. This paper investigates a more scalable data source, egocentric human demonstrations, to serve as cross-embodiment training data for robot learning. We mitigate the embodiment gap between humanoids and humans from both the data and modeling perspectives. We collect an egocentric task-oriented dataset (PH2D) that is directly aligned with humanoid manipulation demonstrations. We then train a human-humanoid behavior policy, which we term Human Action Transformer (HAT). The state-action space of HAT is unified for both humans and humanoid robots and can be differentiably retargeted to robot actions. Co-trained with smaller-scale robot data, HAT directly models humanoid robots and humans as different embodiments without additional supervision. We show that human data improves both generalization and robustness of HAT with significantly better data collection efficiency. Code and data: this https URL', 'abstract_zh': '利用多样数据训练人形机器人操作策略可以提升其跨任务和平台的稳健性和泛化能力。然而，仅从机器人演示学习是劳动密集型的，需要昂贵的远程操作数据收集，难以扩展。本文探讨了一种更为可扩展的数据来源——第一人称人类演示，作为机器人学习的跨身体训练数据。我们从数据和建模两个角度缓解人形机器人与人类之间的身体差异。我们收集了一个与人形机器人操作演示直接对齐的第一人称任务导向数据集（PH2D）。然后训练了一个人类-人形机器人行为策略，我们称之为人类动作变压器（HAT）。HAT的状态-动作空间对人类和人形机器人统一，并且可以可微地重新瞄准到机器人动作。与少量机器人数据协同训练，HAT直接建模人类和人形机器人作为不同身体，无需额外监督。我们展示了人类数据可以显著提高HAT的泛化能力和稳健性，同时数据收集效率更高。代码和数据：this https URL', 'title_zh': '类人政策 ~ 人类政策'}
{'arxiv_id': 'arXiv:2503.13438', 'title': 'Deep Belief Markov Models for POMDP Inference', 'authors': 'Giacomo Arcieri, Konstantinos G. Papakonstantinou, Daniel Straub, Eleni Chatzi', 'link': 'https://arxiv.org/abs/2503.13438', 'abstract': "This work introduces a novel deep learning-based architecture, termed the Deep Belief Markov Model (DBMM), which provides efficient, model-formulation agnostic inference in Partially Observable Markov Decision Process (POMDP) problems. The POMDP framework allows for modeling and solving sequential decision-making problems under observation uncertainty. In complex, high-dimensional, partially observable environments, existing methods for inference based on exact computations (e.g., via Bayes' theorem) or sampling algorithms do not scale well. Furthermore, ground truth states may not be available for learning the exact transition dynamics. DBMMs extend deep Markov models into the partially observable decision-making framework and allow efficient belief inference entirely based on available observation data via variational inference methods. By leveraging the potency of neural networks, DBMMs can infer and simulate non-linear relationships in the system dynamics and naturally scale to problems with high dimensionality and discrete or continuous variables. In addition, neural network parameters can be dynamically updated efficiently based on data availability. DBMMs can thus be used to infer a belief variable, thus enabling the derivation of POMDP solutions over the belief space. We evaluate the efficacy of the proposed methodology by evaluating the capability of model-formulation agnostic inference of DBMMs in benchmark problems that include discrete and continuous variables.", 'abstract_zh': '基于深度学习的Deep Belief Markov模型（DBMM）在部分可观测量马尔可夫决策过程（POMDP）问题中高效无模型描述符推理的研究', 'title_zh': '深度信念马尔可夫模型在部分可观察马尔可夫决策过程中的推断'}
{'arxiv_id': 'arXiv:2503.13434', 'title': 'BlobCtrl: A Unified and Flexible Framework for Element-level Image Generation and Editing', 'authors': 'Yaowei Li, Lingen Li, Zhaoyang Zhang, Xiaoyu Li, Guangzhi Wang, Hongxiang Li, Xiaodong Cun, Ying Shan, Yuexian Zou', 'link': 'https://arxiv.org/abs/2503.13434', 'abstract': 'Element-level visual manipulation is essential in digital content creation, but current diffusion-based methods lack the precision and flexibility of traditional tools. In this work, we introduce BlobCtrl, a framework that unifies element-level generation and editing using a probabilistic blob-based representation. By employing blobs as visual primitives, our approach effectively decouples and represents spatial location, semantic content, and identity information, enabling precise element-level manipulation. Our key contributions include: 1) a dual-branch diffusion architecture with hierarchical feature fusion for seamless foreground-background integration; 2) a self-supervised training paradigm with tailored data augmentation and score functions; and 3) controllable dropout strategies to balance fidelity and diversity. To support further research, we introduce BlobData for large-scale training and BlobBench for systematic evaluation. Experiments show that BlobCtrl excels in various element-level manipulation tasks while maintaining computational efficiency, offering a practical solution for precise and flexible visual content creation. Project page: this https URL', 'abstract_zh': '元素级视觉操控在数字内容创作中至关重要，但当前基于弥散的方法缺乏传统工具的精准性和灵活性。本文介绍了一种名为BlobCtrl的框架，该框架利用概率性的blob表示法统一了元素级生成和编辑。通过使用blobs作为视觉基本元素，我们的方法有效解耦并表示空间位置、语义内容和身份信息，从而实现精确的元素级操控。我们的主要贡献包括：1）包含分层特征融合的双分支弥散架构，以实现无缝的前景-背景集成；2）自监督训练范式，包括定制的数据增强和评分函数；3）可控的 dropout 策略以平衡保真度和多样性。为支持进一步研究，我们介绍了BlobData用于大规模训练，BlobBench用于系统性评估。实验结果显示，BlobCtrl在多种元素级操控任务中表现出色，同时保持计算效率，提供了一种实用的精准和灵活的视觉内容创作解决方案。项目页面：这个 https URL', 'title_zh': 'BlobCtrl：统一且灵活的元素级图像生成与编辑框架'}
{'arxiv_id': 'arXiv:2503.13430', 'title': 'AugMapNet: Improving Spatial Latent Structure via BEV Grid Augmentation for Enhanced Vectorized Online HD Map Construction', 'authors': 'Thomas Monninger, Md Zafar Anwar, Stanislaw Antol, Steffen Staab, Sihao Ding', 'link': 'https://arxiv.org/abs/2503.13430', 'abstract': "Autonomous driving requires an understanding of the infrastructure elements, such as lanes and crosswalks. To navigate safely, this understanding must be derived from sensor data in real-time and needs to be represented in vectorized form. Learned Bird's-Eye View (BEV) encoders are commonly used to combine a set of camera images from multiple views into one joint latent BEV grid. Traditionally, from this latent space, an intermediate raster map is predicted, providing dense spatial supervision but requiring post-processing into the desired vectorized form. More recent models directly derive infrastructure elements as polylines using vectorized map decoders, providing instance-level information. Our approach, Augmentation Map Network (AugMapNet), proposes latent BEV grid augmentation, a novel technique that significantly enhances the latent BEV representation. AugMapNet combines vector decoding and dense spatial supervision more effectively than existing architectures while remaining as straightforward to integrate and as generic as auxiliary supervision. Experiments on nuScenes and Argoverse2 datasets demonstrate significant improvements in vectorized map prediction performance up to 13.3% over the StreamMapNet baseline on 60m range and greater improvements on larger ranges. We confirm transferability by applying our method to another baseline and find similar improvements. A detailed analysis of the latent BEV grid confirms a more structured latent space of AugMapNet and shows the value of our novel concept beyond pure performance improvement. The code will be released soon.", 'abstract_zh': '自主驾驶需要理解基础设施元素，如车道和人行横道。为了安全导航，这种理解必须从实时传感器数据中提取，并以矢量化形式表示。Learned 鸟瞰视图（BEV）编码器常用于将多个视角的相机图像结合成一个联合潜在BEV网格。传统上，从这个潜在空间预测出一个中间栅格地图，提供密集的空间监督，但需要后处理成所需矢量化形式。最近的模型直接使用矢量化地图解码器提取基础设施元素为多段线，提供实例级信息。我们的方法，增强地图网络（AugMapNet），提出潜在BEV网格增强这一新颖技术，显著提升了潜在BEV表示。AugMapNet比现有架构更有效地结合矢量化解码和密集空间监督，同时保持易于集成和通用性，如同辅助监督一样。在nuScenes和Argoverse2数据集上的实验表明，AugMapNet在60m范围内的矢量化地图预测性能比StreamMapNet基线提高了13.3%，在更大范围内性能提升更为显著。我们通过将该方法应用于另一个基线确认其实用性，发现相似的提升效果。详细的潜在BEV网格分析证实了AugMapNet具有更结构化的潜在空间，并展示了我们新概念的价值远超单纯性能提升。代码即将发布。', 'title_zh': 'AugMapNet: 通过BEV网格增强改进空间隐含结构以增强向量在线高清地图构建'}
{'arxiv_id': 'arXiv:2503.13427', 'title': 'xLSTM 7B: A Recurrent LLM for Fast and Efficient Inference', 'authors': 'Maximilian Beck, Korbinian Pöppel, Phillip Lippe, Richard Kurle, Patrick M. Blies, Günter Klambauer, Sebastian Böck, Sepp Hochreiter', 'link': 'https://arxiv.org/abs/2503.13427', 'abstract': "Recent breakthroughs in solving reasoning, math and coding problems with Large Language Models (LLMs) have been enabled by investing substantial computation budgets at inference time. Therefore, inference speed is one of the most critical properties of LLM architectures, and there is a growing need for LLMs that are efficient and fast at inference. Recently, LLMs built on the xLSTM architecture have emerged as a powerful alternative to Transformers, offering linear compute scaling with sequence length and constant memory usage, both highly desirable properties for efficient inference. However, such xLSTM-based LLMs have yet to be scaled to larger models and assessed and compared with respect to inference speed and efficiency. In this work, we introduce xLSTM 7B, a 7-billion-parameter LLM that combines xLSTM's architectural benefits with targeted optimizations for fast and efficient inference. Our experiments demonstrate that xLSTM 7B achieves performance on downstream tasks comparable to other similar-sized LLMs, while providing significantly faster inference speeds and greater efficiency compared to Llama- and Mamba-based LLMs. These results establish xLSTM 7B as the fastest and most efficient 7B LLM, offering a solution for tasks that require large amounts of test-time computation. Our work highlights xLSTM's potential as a foundational architecture for methods building on heavy use of LLM inference. Our model weights, model code and training code are open-source.", 'abstract_zh': 'Recent突破性进展：大规模语言模型在推理、数学和编码问题上的应用得益于推理阶段大量计算资源的投资。因此，推理速度是大规模语言模型架构中最关键的属性之一，提高模型效率和加快推理速度的需求日益增长。最近，基于xLSTM架构的语言模型作为一种强大的替代方案出现了，它们具备随着序列长度线性扩展计算量和常数内存使用量的特点，这些都是高效推理所高度渴望的属性。然而，这样的基于xLSTM的语言模型尚未被扩展到更大的模型，并根据推理速度和效率进行了评估和比较。在本文中，我们介绍了参数量为7亿的xLSTM 7B，它结合了xLSTM架构的优势，并针对快速高效推理进行了目标优化。实验结果表明，xLSTM 7B在下游任务上的性能与其他相似规模的语言模型相当，同时提供了比Llama-和Mamba为基础的语言模型更快的推理速度和更高的效率。这些结果确立了xLSTM 7B为最快的7B语言模型，并为需要大量测试时间计算的任务提供了解决方案。我们的工作突显了xLSTM作为依赖大量语言模型推理的方法的基础架构的潜力。我们的模型权重、模型代码和训练代码均为开源。', 'title_zh': 'xLSTM 7B: 一种快速而高效的递归大语言模型'}
{'arxiv_id': 'arXiv:2503.13419', 'title': 'Securing Virtual Reality Experiences: Unveiling and Tackling Cybersickness Attacks with Explainable AI', 'authors': 'Ripan Kumar Kundu, Matthew Denton, Genova Mongalo, Prasad Calyam, Khaza Anuarul Hoque', 'link': 'https://arxiv.org/abs/2503.13419', 'abstract': 'The synergy between virtual reality (VR) and artificial intelligence (AI), specifically deep learning (DL)-based cybersickness detection models, has ushered in unprecedented advancements in immersive experiences by automatically detecting cybersickness severity and adaptively various mitigation techniques, offering a smooth and comfortable VR experience. While this DL-enabled cybersickness detection method provides promising solutions for enhancing user experiences, it also introduces new risks since these models are vulnerable to adversarial attacks; a small perturbation of the input data that is visually undetectable to human observers can fool the cybersickness detection model and trigger unexpected mitigation, thus disrupting user immersive experiences (UIX) and even posing safety risks. In this paper, we present a new type of VR attack, i.e., a cybersickness attack, which successfully stops the triggering of cybersickness mitigation by fooling DL-based cybersickness detection models and dramatically hinders the UIX. Next, we propose a novel explainable artificial intelligence (XAI)-guided cybersickness attack detection framework to detect such attacks in VR to ensure UIX and a comfortable VR experience. We evaluate the proposed attack and the detection framework using two state-of-the-art open-source VR cybersickness datasets: Simulation 2021 and Gameplay dataset. Finally, to verify the effectiveness of our proposed method, we implement the attack and the XAI-based detection using a testbed with a custom-built VR roller coaster simulation with an HTC Vive Pro Eye headset and perform a user study. Our study shows that such an attack can dramatically hinder the UIX. However, our proposed XAI-guided cybersickness attack detection can successfully detect cybersickness attacks and trigger the proper mitigation, effectively reducing VR cybersickness.', 'abstract_zh': '虚拟现实与人工 Intelligence在基于深度学习的晕动症检测模型中的协同效应及其新风险：一种新型的晕动症攻击及其检测框架', 'title_zh': '保障虚拟现实体验：可解释人工智能揭示并应对网络眩晕攻击'}
{'arxiv_id': 'arXiv:2503.13418', 'title': 'FLEX: A Framework for Learning Robot-Agnostic Force-based Skills Involving Sustained Contact Object Manipulation', 'authors': 'Shijie Fang, Wenchang Gao, Shivam Goel, Christopher Thierauf, Matthias Scheutz, Jivko Sinapov', 'link': 'https://arxiv.org/abs/2503.13418', 'abstract': 'Learning to manipulate objects efficiently, particularly those involving sustained contact (e.g., pushing, sliding) and articulated parts (e.g., drawers, doors), presents significant challenges. Traditional methods, such as robot-centric reinforcement learning (RL), imitation learning, and hybrid techniques, require massive training and often struggle to generalize across different objects and robot platforms. We propose a novel framework for learning object-centric manipulation policies in force space, decoupling the robot from the object. By directly applying forces to selected regions of the object, our method simplifies the action space, reduces unnecessary exploration, and decreases simulation overhead. This approach, trained in simulation on a small set of representative objects, captures object dynamics -- such as joint configurations -- allowing policies to generalize effectively to new, unseen objects. Decoupling these policies from robot-specific dynamics enables direct transfer to different robotic platforms (e.g., Kinova, Panda, UR5) without retraining. Our evaluations demonstrate that the method significantly outperforms baselines, achieving over an order of magnitude improvement in training efficiency compared to other state-of-the-art methods. Additionally, operating in force space enhances policy transferability across diverse robot platforms and object types. We further showcase the applicability of our method in a real-world robotic setting. For supplementary materials and videos, please visit: this https URL', 'abstract_zh': '学习高效操作物体，特别是涉及持续接触（如推、滑动）和可活动部件（如抽屉、门）的操作，面临着显著挑战。传统方法，如以机器人为中心的强化学习（RL）、模仿学习和混合技术，需要大量的训练，并且往往难以在不同的物体和机器人平台之间泛化。我们提出了一种新的框架，用于在力空间中学习以物体为中心的操纵策略，将机器人从物体中解耦。通过直接对物体的选定区域施加力，我们的方法简化了动作空间，减少了不必要的探索，并降低了仿真开销。该方法在一小组代表性物体的仿真中训练，捕捉到物体动力学（如关节配置），使得策略能够有效泛化到新的、未见过的物体。将这些策略从特定机器人动力学中解耦，使得可以直接转移到不同的机器人平台（如Kinova、Panda、UR5）而无需重新训练。我们的评估表明，该方法显著优于基线方法，相比其他最先进的方法，在训练效率上提高了十倍以上。此外，在力空间操作提高了策略在多种机器人平台和物体类型之间的转移能力。我们进一步展示了该方法在实际机器人环境中的应用。更多信息和视频，请访问: this https URL', 'title_zh': 'FLEX：一种基于力的物体接触操纵的机器人无关技能学习框架'}
{'arxiv_id': 'arXiv:2503.13415', 'title': 'A Comprehensive Survey on Multi-Agent Cooperative Decision-Making: Scenarios, Approaches, Challenges and Perspectives', 'authors': 'Weiqiang Jin, Hongyang Du, Biao Zhao, Xingwu Tian, Bohang Shi, Guang Yang', 'link': 'https://arxiv.org/abs/2503.13415', 'abstract': 'With the rapid development of artificial intelligence, intelligent decision-making techniques have gradually surpassed human levels in various human-machine competitions, especially in complex multi-agent cooperative task scenarios. Multi-agent cooperative decision-making involves multiple agents working together to complete established tasks and achieve specific objectives. These techniques are widely applicable in real-world scenarios such as autonomous driving, drone navigation, disaster rescue, and simulated military confrontations. This paper begins with a comprehensive survey of the leading simulation environments and platforms used for multi-agent cooperative decision-making. Specifically, we provide an in-depth analysis for these simulation environments from various perspectives, including task formats, reward allocation, and the underlying technologies employed. Subsequently, we provide a comprehensive overview of the mainstream intelligent decision-making approaches, algorithms and models for multi-agent systems (MAS). Theseapproaches can be broadly categorized into five types: rule-based (primarily fuzzy logic), game theory-based, evolutionary algorithms-based, deep multi-agent reinforcement learning (MARL)-based, and large language models(LLMs)reasoning-based. Given the significant advantages of MARL andLLMs-baseddecision-making methods over the traditional rule, game theory, and evolutionary algorithms, this paper focuses on these multi-agent methods utilizing MARL and LLMs-based techniques. We provide an in-depth discussion of these approaches, highlighting their methodology taxonomies, advantages, and drawbacks. Further, several prominent research directions in the future and potential challenges of multi-agent cooperative decision-making are also detailed.', 'abstract_zh': '随着人工智能的快速发展，智能决策技术在各种人机竞赛中已经超过了人类的水平，特别是在复杂的多agent协同任务场景中。多agent协同决策涉及多个agent共同协作以完成既定任务并实现特定目标。这些技术在自动驾驶、无人机导航、灾难救援和模拟军事对抗等实际场景中有着广泛的应用。本文首先对多agent协同决策的主要仿真环境和平台进行了全面综述，并从任务格式、奖励分配以及所采用的底层技术等多个视角进行了深入分析。随后，本文对主流的多agent系统智能决策方法、算法和模型进行了综合概述。这些方法可以大致归为五类：基于规则的方法（主要为模糊逻辑）、基于博弈理论的方法、基于进化算法的方法、基于深度多agent强化学习（MARL）的方法以及基于大规模语言模型（LLMs）推理的方法。鉴于MARL和LLMs基方法相对于传统规则、博弈理论和进化算法的巨大优势，本文重点关注利用MARL和LLMs技术的多agent方法，并对其进行了深入探讨，突出了这些方法的分类、优点和局限性。此外，本文还详细讨论了未来多agent协同决策研究的几个主要方向以及可能面临的挑战。', 'title_zh': '全面综述多agent协同决策：场景、方法、挑战与视角'}
{'arxiv_id': 'arXiv:2503.13414', 'title': 'Reward Adaptation Via Q-Manipulation', 'authors': 'Kevin Vora, Yu Zhang', 'link': 'https://arxiv.org/abs/2503.13414', 'abstract': 'In this paper, we propose a new solution to reward adaptation (RA), the problem where the learning agent adapts to a target reward function based on one or multiple existing behaviors learned a priori under the same domain dynamics but different reward functions. Learning the target behavior from scratch is possible but often inefficient given the available source behaviors. Our work represents a new approach to RA via the manipulation of Q-functions. Assuming that the target reward function is a known function of the source reward functions, our approach to RA computes bounds of the Q function. We introduce an iterative process to tighten the bounds, similar to value iteration. This enables action pruning in the target domain before learning even starts. We refer to such a method as Q-Manipulation (Q-M). We formally prove that our pruning strategy does not affect the optimality of the returned policy while empirically show that it improves the sample complexity. Q-M is evaluated in a variety of synthetic and simulation domains to demonstrate its effectiveness, generalizability, and practicality.', 'abstract_zh': '本文提出了一种新的奖励适应（RA）解决方案，该方案通过操纵Q函数，在相同动力学的不同奖励函数下预先学习一个或多个行为的基础上，使学习代理适应目标奖励函数。从头学习目标行为是可能的，但通常在给定的源行为可用时inefficient。我们的工作代表了通过操纵Q函数来解决RA的一种新方法。假设目标奖励函数是源奖励函数的已知函数，我们的RA方法计算Q函数的边界，并引入一个迭代过程来逐步收紧这些边界，类似于值迭代。这使得在学习开始之前可以在目标领域进行动作剪枝。我们称这种方法为Q操纵（Q-M）。我们正式证明了我们的剪枝策略不会影响返回策略的最优性，并通过实验证明了它提高了样本复杂性。Q-M在多种合成和模拟领域中进行了评估，以展示其有效性、普适性和实用性。', 'title_zh': 'Q-操纵驱动的奖励适应'}
{'arxiv_id': 'arXiv:2503.13413', 'title': 'DLPO: Towards a Robust, Efficient, and Generalizable Prompt Optimization Framework from a Deep-Learning Perspective', 'authors': 'Dengyun Peng, Yuhang Zhou, Qiguang Chen, Jinhao Liu, Jingjing Chen, Libo Qin', 'link': 'https://arxiv.org/abs/2503.13413', 'abstract': 'Large Language Models (LLMs) have achieved remarkable success across diverse tasks, largely driven by well-designed prompts. However, crafting and selecting such prompts often requires considerable human effort, significantly limiting its scalability. To mitigate this, recent studies have explored automated prompt optimization as a promising solution. Despite these efforts, existing methods still face critical challenges in robustness, efficiency, and generalization. To systematically address these challenges, we first conduct an empirical analysis to identify the limitations of current reflection-based prompt optimization paradigm. Building on these insights, we propose 7 innovative approaches inspired by traditional deep learning paradigms for prompt optimization (DLPO), seamlessly integrating these concepts into text-based gradient optimization. Through these advancements, we progressively tackle the aforementioned challenges and validate our methods through extensive experimentation. We hope our study not only provides valuable guidance for future research but also offers a comprehensive understanding of the challenges and potential solutions in prompt optimization. Our code is available at this https URL.', 'abstract_zh': '大型语言模型（LLMs）已在多样任务中取得了显著成功，很大程度上得益于精心设计的提示。然而，设计和选择这些提示往往需要大量的手工努力，明显限制了其可扩展性。为解决这一问题，最近的研究探索了自动化提示优化作为一种有前景的解决方案。尽管取得了这些进展，现有方法在鲁棒性、效率和泛化能力方面仍然面临关键挑战。为了系统性地应对这些挑战，我们首先进行了实证分析以识别当前基于反思的提示优化范式的局限性。基于这些见解，我们提出了7种受到传统深度学习范式启发的创新方法，将这些概念无缝集成到基于文本的梯度优化中。通过这些进步，我们逐步解决了上述挑战，并通过广泛的实验验证了我们的方法。我们希望本研究不仅能为未来的研究提供有价值的指导，还能全面理解提示优化中面临的挑战及其潜在解决方案。我们的代码可在以下链接获取：this https URL。', 'title_zh': 'DLPO: 从深度学习视角 towards 健壮、高效和通用的提示优化框架'}
{'arxiv_id': 'arXiv:2503.13401', 'title': 'Using the Tools of Cognitive Science to Understand Large Language Models at Different Levels of Analysis', 'authors': 'Alexander Ku, Declan Campbell, Xuechunzi Bai, Jiayi Geng, Ryan Liu, Raja Marjieh, R. Thomas McCoy, Andrew Nam, Ilia Sucholutsky, Veniamin Veselovsky, Liyi Zhang, Jian-Qiao Zhu, Thomas L. Griffiths', 'link': 'https://arxiv.org/abs/2503.13401', 'abstract': "Modern artificial intelligence systems, such as large language models, are increasingly powerful but also increasingly hard to understand. Recognizing this problem as analogous to the historical difficulties in understanding the human mind, we argue that methods developed in cognitive science can be useful for understanding large language models. We propose a framework for applying these methods based on Marr's three levels of analysis. By revisiting established cognitive science techniques relevant to each level and illustrating their potential to yield insights into the behavior and internal organization of large language models, we aim to provide a toolkit for making sense of these new kinds of minds.", 'abstract_zh': '现代人工智能系统，如大型语言模型，既越来越强大也愈加难以理解。认识到这一问题类似于历史上理解人类心智的困难，我们认为可以借鉴认知科学中的方法来理解大型语言模型。我们提出一种基于 Marr 分析的三个层次框架，通过回顾与每个层次相关的已确立的认知科学技术，并阐述它们对揭示大型语言模型行为和内部组织的潜在洞察力，旨在提供一套工具箱，帮助理解这些新类型的“心智”。', 'title_zh': '用认知科学的工具从不同分析层理解大规模语言模型'}
{'arxiv_id': 'arXiv:2503.13399', 'title': 'MicroVQA: A Multimodal Reasoning Benchmark for Microscopy-Based Scientific Research', 'authors': 'James Burgess, Jeffrey J Nirschl, Laura Bravo-Sánchez, Alejandro Lozano, Sanket Rajan Gupte, Jesus G. Galaz-Montoya, Yuhui Zhang, Yuchang Su, Disha Bhowmik, Zachary Coman, Sarina M. Hasan, Alexandra Johannesson, William D. Leineweber, Malvika G Nair, Ridhi Yarlagadda, Connor Zuraski, Wah Chiu, Sarah Cohen, Jan N. Hansen, Manuel D Leonetti, Chad Liu, Emma Lundberg, Serena Yeung-Levy', 'link': 'https://arxiv.org/abs/2503.13399', 'abstract': "Scientific research demands sophisticated reasoning over multimodal data, a challenge especially prevalent in biology. Despite recent advances in multimodal large language models (MLLMs) for AI-assisted research, existing multimodal reasoning benchmarks only target up to college-level difficulty, while research-level benchmarks emphasize lower-level perception, falling short of the complex multimodal reasoning needed for scientific discovery. To bridge this gap, we introduce MicroVQA, a visual-question answering (VQA) benchmark designed to assess three reasoning capabilities vital in research workflows: expert image understanding, hypothesis generation, and experiment proposal. MicroVQA consists of 1,042 multiple-choice questions (MCQs) curated by biology experts across diverse microscopy modalities, ensuring VQA samples represent real scientific practice. In constructing the benchmark, we find that standard MCQ generation methods induce language shortcuts, motivating a new two-stage pipeline: an optimized LLM prompt structures question-answer pairs into MCQs; then, an agent-based `RefineBot' updates them to remove shortcuts. Benchmarking on state-of-the-art MLLMs reveal a peak performance of 53\\%; models with smaller LLMs only slightly underperform top models, suggesting that language-based reasoning is less challenging than multimodal reasoning; and tuning with scientific articles enhances performance. Expert analysis of chain-of-thought responses shows that perception errors are the most frequent, followed by knowledge errors and then overgeneralization errors. These insights highlight the challenges in multimodal scientific reasoning, showing MicroVQA is a valuable resource advancing AI-driven biomedical research. MicroVQA is available at this https URL, and project page at this https URL.", 'abstract_zh': "科学研究需要对多模态数据进行复杂的推理，这一挑战在生物学中尤为普遍。尽管近年来多模态大型语言模型（MLLMs）在AI辅助研究方面取得了进展，但现有的多模态推理基准仅针对大学水平的难度，而研究级别的基准则侧重于较低层次的感知，未能满足科学发现所需的复杂多模态推理。为弥合这一差距，我们引入了MicroVQA，这是一个视觉-问答（VQA）基准，旨在评估科研工作流程中至关重要的三种推理能力：专家级图像理解、假设生成和实验提案。MicroVQA包含1,042个由生物学专家根据不同显微镜模态整理的多选题（MCQs），确保VQA样本代表真实的科学研究实践。在构建该基准的过程中，我们发现标准的多选题生成方法导致了语言捷径，因此提出了一种新的两阶段管道：优化的LLM提示将问题-答案对结构化为MCQs；随后，基于代理的`RefineBot'更新这些问题，以去除语言捷径。在最先进的MLLM上的基准测试显示最高性能为53%；使用较小的LLM的模型仅略微低于最佳模型，表明基于语言的推理比多模态推理更容易；并且通过使用科学文献进行微调可以提升性能。专家分析链式推理响应表明，感知错误是最常见的错误，其次是知识错误，然后是泛化错误。这些见解突显了多模态科学推理的挑战，显示MicroVQA是促进AI驱动的生物医学研究的重要资源。MicroVQA可在以下链接获取：this https URL，项目页面可在以下链接获取：this https URL。", 'title_zh': 'MicroVQA：基于显微镜的科学研究所用的多模态推理基准'}
{'arxiv_id': 'arXiv:2503.13385', 'title': 'Scale Efficient Training for Large Datasets', 'authors': 'Qing Zhou, Junyu Gao, Qi Wang', 'link': 'https://arxiv.org/abs/2503.13385', 'abstract': 'The rapid growth of dataset scales has been a key driver in advancing deep learning research. However, as dataset scale increases, the training process becomes increasingly inefficient due to the presence of low-value samples, including excessive redundant samples, overly challenging samples, and inefficient easy samples that contribute little to model this http URL address this challenge, we propose Scale Efficient Training (SeTa) for large datasets, a dynamic sample pruning approach that losslessly reduces training time. To remove low-value samples, SeTa first performs random pruning to eliminate redundant samples, then clusters the remaining samples according to their learning difficulty measured by loss. Building upon this clustering, a sliding window strategy is employed to progressively remove both overly challenging and inefficient easy clusters following an easy-to-hard this http URL conduct extensive experiments on large-scale synthetic datasets, including ToCa, SS1M, and ST+MJ, each containing over 3 million this http URL reduces training costs by up to 50\\% while maintaining or improving performance, with minimal degradation even at 70\\% cost reduction. Furthermore, experiments on various scale real datasets across various backbones (CNNs, Transformers, and Mambas) and diverse tasks (instruction tuning, multi-view stereo, geo-localization, composed image retrieval, referring image segmentation) demonstrate the powerful effectiveness and universality of our approach. Code is available at this https URL.', 'abstract_zh': '大数据集高效训练方法：面向低价值样本的动态采样修剪（SeTa）', 'title_zh': '大规模数据集的高效训练'}
{'arxiv_id': 'arXiv:2503.13383', 'title': 'Cream of the Crop: Harvesting Rich, Scalable and Transferable Multi-Modal Data for Instruction Fine-Tuning', 'authors': 'Mengyao Lyu, Yan Li, Huasong Zhong, Wenhao Yang, Hui Chen, Jungong Han, Guiguang Ding, Zhenheng Yang', 'link': 'https://arxiv.org/abs/2503.13383', 'abstract': 'The hypothesis that pretrained large language models (LLMs) necessitate only minimal supervision during the fine-tuning (SFT) stage (Zhou et al., 2024) has been substantiated by recent advancements in data curation and selection research. However, their stability and generalizability are compromised due to the vulnerability to experimental setups and validation protocols, falling short of surpassing random sampling (Diddee & Ippolito, 2024; Xia et al., 2024b). Built upon LLMs, multi-modal LLMs (MLLMs), combined with the sheer token volume and heightened heterogeneity of data sources, amplify both the significance and complexity of data selection.\nTo harvest multi-modal instructional data in a robust and efficient manner, we re-define the granularity of the quality metric by decomposing it into 14 vision-language-related capabilities, and introduce multi-modal rich scorers to evaluate the capabilities of each data candidate. To promote diversity, in light of the inherent objective of the alignment stage, we take interaction style as diversity indicator and use a multi-modal rich styler to identify data instruction patterns. In doing so, our multi-modal rich scorers and styler (mmSSR) guarantee that high-scoring information is conveyed to users in diversified forms. Free from embedding-based clustering or greedy sampling, mmSSR efficiently scales to millions of data with varying budget constraints, supports customization for general or specific capability acquisition, and facilitates training-free generalization to new domains for curation. Across 10+ experimental settings, validated by 14 multi-modal benchmarks, we demonstrate consistent improvements over random sampling, baseline strategies and state-of-the-art selection methods, achieving 99.1% of full performance with only 30% of the 2.6M data.', 'abstract_zh': '预训练大语言模型在微调阶段仅需最小监督的新颖性及其挑战与对策：基于多模态数据的选择与评估', 'title_zh': '优中选优：收获丰富的、可扩展且可迁移的多模态数据以供指令微调'}
{'arxiv_id': 'arXiv:2503.13377', 'title': 'TimeZero: Temporal Video Grounding with Reasoning-Guided LVLM', 'authors': 'Ye Wang, Boshen Xu, Zihao Yue, Zihan Xiao, Ziheng Wang, Liang Zhang, Dingyi Yang, Wenxuan Wang, Qin Jin', 'link': 'https://arxiv.org/abs/2503.13377', 'abstract': 'We introduce TimeZero, a reasoning-guided LVLM designed for the temporal video grounding (TVG) task. This task requires precisely localizing relevant video segments within long videos based on a given language query. TimeZero tackles this challenge by extending the inference process, enabling the model to reason about video-language relationships solely through reinforcement learning. To evaluate the effectiveness of TimeZero, we conduct experiments on two benchmarks, where TimeZero achieves state-of-the-art performance on Charades-STA. Code is available at this https URL.', 'abstract_zh': '我们介绍了TimeZero，一种用于时间视频定位（TVG）任务的推理指导型LVLM。该任务要求根据给定的自然语言查询，精确地在长视频中定位相关的视频片段。TimeZero通过扩展推理过程，仅通过强化学习来处理视频-语言关系，从而应对这一挑战。为了评估TimeZero的有效性，我们在两个基准上进行了实验，其中TimeZero在Charades-STA上达到了最先进的性能。代码可在以下链接获得：this https URL。', 'title_zh': 'TimeZero: 基于推理引导的LVLM时间视频定位'}
{'arxiv_id': 'arXiv:2503.13360', 'title': 'Mitigating Visual Forgetting via Take-along Visual Conditioning for Multi-modal Long CoT Reasoning', 'authors': 'Hai-Long Sun, Zhun Sun, Houwen Peng, Han-Jia Ye', 'link': 'https://arxiv.org/abs/2503.13360', 'abstract': "Recent advancements in Large Language Models (LLMs) have demonstrated enhanced reasoning capabilities, evolving from Chain-of-Thought (CoT) prompting to advanced, product-oriented solutions like OpenAI o1. During our re-implementation of this model, we noticed that in multimodal tasks requiring visual input (e.g., geometry problems), Multimodal LLMs (MLLMs) struggle to maintain focus on the visual information, in other words, MLLMs suffer from a gradual decline in attention to visual information as reasoning progresses, causing text-over-relied outputs. To investigate this, we ablate image inputs during long-chain reasoning. Concretely, we truncate the reasoning process midway, then re-complete the reasoning process with the input image removed. We observe only a ~2% accuracy drop on MathVista's test-hard subset, revealing the model's textual outputs dominate the following reasoning process. Motivated by this, we propose Take-along Visual Conditioning (TVC), a strategy that shifts image input to critical reasoning stages and compresses redundant visual tokens via dynamic pruning. This methodology helps the model retain attention to the visual components throughout the reasoning. Our approach achieves state-of-the-art performance on average across five mathematical reasoning benchmarks (+3.4% vs previous sota), demonstrating the effectiveness of TVC in enhancing multimodal reasoning systems.", 'abstract_zh': 'Recent advancements in大型语言模型（LLMs）展示了增强的推理能力，从链式思考（CoT）提示发展到如OpenAI o1等高级、产品导向的解决方案。在我们对该模型的重实现过程中，我们注意到，在需要视觉输入的多模态任务（例如，几何问题）中，多模态大语言模型（MLLMs）难以保持对视觉信息的关注，在推理过程中逐渐对视觉信息的关注减弱，导致文本过度依赖输出。为了探究这一现象，我们在长链推理过程中消融图像输入。具体来说，我们在推理过程的中途截断推理，然后移除输入图像重新完成推理过程。我们观察到，在MathVista的测试困难子集上只有约2%的准确性下降，表明模型的文本输出主导了后续的推理过程。基于此，我们提出了一种名为携带视觉调节（TVC）的策略，该策略将图像输入转移到关键推理阶段，并通过动态剪枝压缩冗余的视觉标记。该方法有助于模型在整个推理过程中保持对视觉成分的关注。我们的方法在五个数学推理基准上的平均性能达到了最先进的水平（相对于之前的最佳性能提高了3.4%），证实了TVC在增强多模态推理系统方面的有效性。', 'title_zh': '通过随带视觉条件化减轻视觉遗忘以进行多模态长链 reasoning'}
{'arxiv_id': 'arXiv:2503.13343', 'title': 'Scalable Runtime Architecture for Data-driven, Hybrid HPC and ML Workflow Applications', 'authors': 'Andre Merzky, Mikhail Titov, Matteo Turilli, Ozgur Kilic, Tianle Wang, Shantenu Jha', 'link': 'https://arxiv.org/abs/2503.13343', 'abstract': 'Hybrid workflows combining traditional HPC and novel ML methodologies are transforming scientific computing. This paper presents the architecture and implementation of a scalable runtime system that extends RADICAL-Pilot with service-based execution to support AI-out-HPC workflows. Our runtime system enables distributed ML capabilities, efficient resource management, and seamless HPC/ML coupling across local and remote platforms. Preliminary experimental results show that our approach manages concurrent execution of ML models across local and remote HPC/cloud resources with minimal architectural overheads. This lays the foundation for prototyping three representative data-driven workflow applications and executing them at scale on leadership-class HPC platforms.', 'abstract_zh': '混合 workflows 结合传统HPC和新型ML方法正在变革科学计算。本文介绍了将 RADICAL-Pilot 扩展为基于服务的执行以支持AI-out-HPC workflows 的可扩展运行时系统的架构和实现。该运行时系统实现了分布式ML能力、高效的资源管理，并在本地和远程平台间无缝耦合HPC/ML。初步实验结果表明，该方法在本地和远程HPC/云资源上实现了ML模型的并发执行，且具有最小的架构开销。这为在旗舰级HPC平台大规模原型设计三种代表性数据驱动workflow应用程序奠定了基础。', 'title_zh': '面向数据驱动、混合HPC和ML工作流应用的大规模运行时架构'}
{'arxiv_id': 'arXiv:2503.13342', 'title': 'Valid Text-to-SQL Generation with Unification-based DeepStochLog', 'authors': 'Ying Jiao, Luc De Raedt, Giuseppe Marra', 'link': 'https://arxiv.org/abs/2503.13342', 'abstract': 'Large language models have been used to translate natural language questions to SQL queries. Without hard constraints on syntax and database schema, they occasionally produce invalid queries that are not executable. These failures limit the usage of these systems in real-life scenarios. We propose a neurosymbolic framework that imposes SQL syntax and schema constraints with unification-based definite clause grammars and thus guarantees the generation of valid queries. Our framework also builds a bi-directional interface to language models to leverage their natural language understanding abilities. The evaluation results on a subset of SQL grammars show that all our output queries are valid. This work is the first step towards extending language models with unification-based grammars. We demonstrate this extension enhances the validity, execution accuracy, and ground truth alignment of the underlying language model by a large margin. Our code is available at this https URL.', 'abstract_zh': '大型语言模型已被用于将自然语言问题转换为SQL查询。通过使用基于统一的确定性子句语法，我们提出了一种神经符号框架，以施加SQL语法和模式约束，从而保证生成有效的查询。我们的框架还构建了一个双向接口，利用语言模型的自然语言理解能力。在SQL语法子集上的评估结果表明，所有输出查询都是有效的。这是使用基于统一的语法扩展语言模型的第一步。我们的扩展显著提高了底层语言模型的有效性、执行准确性和地面 truth 对齐。相关代码可在以下网址获取。', 'title_zh': '基于统一的深度马尔可夫文本到SQL生成'}
{'arxiv_id': 'arXiv:2503.13335', 'title': 'Reliable and Efficient Amortized Model-based Evaluation', 'authors': 'Sang Truong, Yuheng Tu, Percy Liang, Bo Li, Sanmi Koyejo', 'link': 'https://arxiv.org/abs/2503.13335', 'abstract': 'Comprehensive evaluations of language models (LM) during both development and deployment phases are necessary because these models possess numerous capabilities (e.g., mathematical reasoning, legal support, or medical diagnostic) as well as safety risks (e.g., racial bias, toxicity, or misinformation). The average score across a wide range of benchmarks provides a signal that helps guide the use of these LMs in practice. Currently, holistic evaluations are costly due to the large volume of benchmark questions, making frequent evaluations impractical. A popular attempt to lower the cost is to compute the average score on a subset of the benchmark. This approach, unfortunately, often renders an unreliable measure of LM performance because the average score is often confounded with the difficulty of the questions in the benchmark subset. Item response theory (IRT) was designed to address this challenge, providing a reliable measurement by careful controlling for question difficulty. Unfortunately, question difficulty is expensive to estimate. Facing this challenge, we train a model that predicts question difficulty from its content, enabling a reliable measurement at a fraction of the cost. In addition, we leverage this difficulty predictor to further improve the evaluation efficiency through training a question generator given a difficulty level. This question generator is essential in adaptive testing, where, instead of using a random subset of the benchmark questions, informative questions are adaptively chosen based on the current estimation of LLM performance. Experiments on 22 common natural language benchmarks and 172 LMs show that this approach is more reliable and efficient compared to current common practice.', 'abstract_zh': '全面评估开发和部署阶段语言模型的必要性及其挑战与解决方案', 'title_zh': '可靠的高效模型化评价方法'}
{'arxiv_id': 'arXiv:2503.13330', 'title': 'LEAVS: An LLM-based Labeler for Abdominal CT Supervision', 'authors': 'Ricardo Bigolin Lanfredi, Yan Zhuang, Mark Finkelstein, Praveen Thoppey Srinivasan Balamuralikrishna, Luke Krembs, Brandon Khoury, Arthi Reddy, Pritam Mukherjee, Neil M. Rofsky, Ronald M. Summers', 'link': 'https://arxiv.org/abs/2503.13330', 'abstract': 'Extracting structured labels from radiology reports has been employed to create vision models to simultaneously detect several types of abnormalities. However, existing works focus mainly on the chest region. Few works have been investigated on abdominal radiology reports due to more complex anatomy and a wider range of pathologies in the abdomen. We propose LEAVS (Large language model Extractor for Abdominal Vision Supervision). This labeler can annotate the certainty of presence and the urgency of seven types of abnormalities for nine abdominal organs on CT radiology reports. To ensure broad coverage, we chose abnormalities that encompass most of the finding types from CT reports. Our approach employs a specialized chain-of-thought prompting strategy for a locally-run LLM using sentence extraction and multiple-choice questions in a tree-based decision system. We demonstrate that the LLM can extract several abnormality types across abdominal organs with an average F1 score of 0.89, significantly outperforming competing labelers and humans. Additionally, we show that extraction of urgency labels achieved performance comparable to human annotations. Finally, we demonstrate that the abnormality labels contain valuable information for training a single vision model that classifies several organs as normal or abnormal. We release our code and structured annotations for a public CT dataset containing over 1,000 CT volumes.', 'abstract_zh': '基于大型语言模型的腹部影像监督标注器LEAVS：从腹部放射报告中提取结构化标签', 'title_zh': 'LEAVS: 一种基于LLM的腹部CT标注器'}
{'arxiv_id': 'arXiv:2503.13316', 'title': 'RainScaleGAN: a Conditional Generative Adversarial Network for Rainfall Downscaling', 'authors': 'Marcello Iotti, Paolo Davini, Jost von Hardenberg, Giuseppe Zappa', 'link': 'https://arxiv.org/abs/2503.13316', 'abstract': "To this day, accurately simulating local-scale precipitation and reliably reproducing its distribution remains a challenging task. The limited horizontal resolution of Global Climate Models is among the primary factors undermining their skill in this context. The physical mechanisms driving the onset and development of precipitation, especially in extreme events, operate at spatio-temporal scales smaller than those numerically resolved, thus struggling to be captured accurately. In order to circumvent this limitation, several downscaling approaches have been developed over the last decades to address the discrepancy between the spatial resolution of models output and the resolution required by local-scale applications. In this paper, we introduce RainScaleGAN, a conditional deep convolutional Generative Adversarial Network (GAN) for precipitation downscaling. GANs have been effectively used in image super-resolution, an approach highly relevant for downscaling tasks. RainScaleGAN's capabilities are tested in a perfect-model setup, where the spatial resolution of a precipitation dataset is artificially degraded from 0.25$^{\\circ}\\times$0.25$^{\\circ}$ to 2$^{\\circ}\\times$2$^\\circ$, and RainScaleGAN is used to restore it. The developed model outperforms one of the leading precipitation downscaling method found in the literature. RainScaleGAN not only generates a synthetic dataset featuring plausible high-resolution spatial patterns and intensities, but also produces a precipitation distribution with statistics closely mirroring those of the ground-truth dataset. Given that RainScaleGAN's approach is agnostic with respect to the underlying physics, the method has the potential to be applied to other physical variables such as surface winds or temperature.", 'abstract_zh': '到目前为止，准确模拟局地尺度降水并可靠再现其分布仍是一项具有挑战性的任务。全球气候模型的有限水平分辨率是其在这一方面的能力受到限制的主要因素之一。驱动降水发生和发展，尤其是极端事件的物理机制，其时空尺度小于数值分辨率，难以被准确捕捉。为了克服这一限制，近几十年来发展出了多种降尺度方法，以解决模型输出的空间分辨率与局地尺度应用所需的分辨率之间的矛盾。本文介绍了一种基于条件深度卷积生成对抗网络(GAN)的降水降尺度方法——RainScaleGAN。GAN已在图像超分辨率领域取得了成功应用，这与降尺度任务密切相关。通过在完美模型设置中测试RainScaleGAN的功能，即将降水数据集的空间分辨率从0.25°×0.25°人为降级为2°×2°，并使用RainScaleGAN重建原始分辨率。所开发的模型在文献中发现的领先降水降尺度方法中表现更优。RainScaleGAN不仅能生成具有合理高分辨率空间模式和强度的合成数据集，还能产生统计特征与真实数据集非常接近的降水分布。由于RainScaleGAN方法对底层物理过程具有无关性，该方法有潜力应用于其他物理变量，如地表风速或温度。', 'title_zh': 'RainScaleGAN：一种条件生成对抗网络用于降雨下标缩放'}
{'arxiv_id': 'arXiv:2503.13310', 'title': 'Generative AI for Software Architecture. Applications, Trends, Challenges, and Future Directions', 'authors': 'Matteo Esposito, Xiaozhou Li, Sergio Moreschini, Noman Ahmad, Tomas Cerny, Karthik Vaidhyanathan, Valentina Lenarduzzi, Davide Taibi', 'link': 'https://arxiv.org/abs/2503.13310', 'abstract': 'Context: Generative Artificial Intelligence (GenAI) is transforming much of software development, yet its application in software architecture is still in its infancy, and no prior study has systematically addressed the topic. Aim: We aim to systematically synthesize the use, rationale, contexts, usability, and future challenges of GenAI in software architecture. Method: We performed a multivocal literature review (MLR), analyzing peer-reviewed and gray literature, identifying current practices, models, adoption contexts, and reported challenges, extracting themes via open coding. Results: Our review identified significant adoption of GenAI for architectural decision support and architectural reconstruction. OpenAI GPT models are predominantly applied, and there is consistent use of techniques such as few-shot prompting and retrieved-augmented generation (RAG). GenAI has been applied mostly to initial stages of the Software Development Life Cycle (SDLC), such as Requirements-to-Architecture and Architecture-to-Code. Monolithic and microservice architectures were the dominant targets. However, rigorous testing of GenAI outputs was typically missing from the studies. Among the most frequent challenges are model precision, hallucinations, ethical aspects, privacy issues, lack of architecture-specific datasets, and the absence of sound evaluation frameworks. Conclusions: GenAI shows significant potential in software design, but several challenges remain on its path to greater adoption. Research efforts should target designing general evaluation methodologies, handling ethics and precision, increasing transparency and explainability, and promoting architecture-specific datasets and benchmarks to bridge the gap between theoretical possibilities and practical use.', 'abstract_zh': '生成式人工智能在软件架构中的应用、理据、情境、可用性及未来挑战系统综述', 'title_zh': '生成式AI在软件架构中的应用、趋势、挑战及未来方向'}
{'arxiv_id': 'arXiv:2503.13309', 'title': 'Integrating AI for Human-Centric Breast Cancer Diagnostics: A Multi-Scale and Multi-View Swin Transformer Framework', 'authors': 'Farnoush Bayatmakou, Reza Taleei, Milad Amir Toutounchian, Arash Mohammadi', 'link': 'https://arxiv.org/abs/2503.13309', 'abstract': "Despite advancements in Computer-Aided Diagnosis (CAD) systems, breast cancer remains one of the leading causes of cancer-related deaths among women worldwide. Recent breakthroughs in Artificial Intelligence (AI) have shown significant promise in development of advanced Deep Learning (DL) architectures for breast cancer diagnosis through mammography. In this context, the paper focuses on the integration of AI within a Human-Centric workflow to enhance breast cancer diagnostics. Key challenges are, however, largely overlooked such as reliance on detailed tumor annotations and susceptibility to missing views, particularly during test time. To address these issues, we propose a hybrid, multi-scale and multi-view Swin Transformer-based framework (MSMV-Swin) that enhances diagnostic robustness and accuracy. The proposed MSMV-Swin framework is designed to work as a decision-support tool, helping radiologists analyze multi-view mammograms more effectively. More specifically, the MSMV-Swin framework leverages the Segment Anything Model (SAM) to isolate the breast lobe, reducing background noise and enabling comprehensive feature extraction. The multi-scale nature of the proposed MSMV-Swin framework accounts for tumor-specific regions as well as the spatial characteristics of tissues surrounding the tumor, capturing both localized and contextual information. The integration of contextual and localized data ensures that MSMV-Swin's outputs align with the way radiologists interpret mammograms, fostering better human-AI interaction and trust. A hybrid fusion structure is then designed to ensure robustness against missing views, a common occurrence in clinical practice when only a single mammogram view is available.", 'abstract_zh': '尽管计算机辅助诊断（CAD）系统取得了进展，乳腺癌仍然是一类全球女性癌症相关死亡的主要原因。近期人工智能（AI）的突破性进展显示了通过乳腺X光摄影进行乳腺癌诊断的高级深度学习（DL）架构的巨大潜力。在此背景下，本文关注将AI集成到以人类为中心的工作流程中，以增强乳腺癌诊断。然而，关键挑战，如对详细肿瘤注释的依赖以及在测试时容易遗漏视图，往往被忽视。为解决这些问题，我们提出了一种混合、多尺度和多视图SwinTransformer框架（MSMV-Swin），以增强诊断的稳健性和准确性。提出的MSMV-Swin框架设计为辅助决策工具，帮助放射科医生更有效地分析多视图乳腺X光摄影图像。具体而言，MSMV-Swin框架利用Segment Anything Model（SAM）隔离乳腺小叶，减少背景噪音并实现全面的特征提取。所提出MSMV-Swin框架的多尺度特性考虑了肿瘤特异性区域以及肿瘤周围组织的空间特性，捕获局部和上下文信息。通过结合上下文和局部数据，MSMV-Swin的输出能够更好地与放射科医生解读乳腺X光摄影图像的方式保持一致，促进更好的人机交互和信任。为了确保在仅有一张视图可用的临床实践中对缺失视图具有鲁棒性，我们设计了一种混合融合结构。', 'title_zh': '基于多尺度多视图Swin Transformer的人工智能集成在人体中心乳腺癌诊断中的应用'}
{'arxiv_id': 'arXiv:2503.13305', 'title': 'Computation Mechanism Behind LLM Position Generalization', 'authors': 'Chi Han, Heng Ji', 'link': 'https://arxiv.org/abs/2503.13305', 'abstract': "Most written natural languages are composed of sequences of words and sentences. Similar to humans, large language models (LLMs) exhibit flexibility in handling textual positions - a phenomenon we term position generalization. They can understand texts with position perturbations and generalize to longer texts than those encountered during training with the latest techniques. These phenomena suggest that LLMs handle positions tolerantly, but how LLMs computationally process positional relevance remains largely unexplored. This work connects the linguistic phenomenon with LLMs' computational mechanisms. We show how LLMs enforce certain computational mechanisms for the aforementioned tolerance in position perturbations. Despite the complex design of the self-attention mechanism, this work reveals that LLMs learn a counterintuitive disentanglement of attention logits. Their values show a 0.959 linear correlation with an approximation of the arithmetic sum of positional relevance and semantic importance. Furthermore, we identify a prevalent pattern in intermediate features, which we prove theoretically enables this effect. The pattern, which is different from how randomly initialized parameters would behave, suggests that it is a learned behavior rather than a natural result of the model architecture. Based on these findings, we provide computational explanations and criteria for LLMs' position flexibilities. This work takes a pioneering step in linking position generalization with modern LLMs' internal mechanisms.", 'abstract_zh': '大型自然语言由单词和句子序列组成。类似人类，大规模语言模型（LLMs）在处理文本位置方面表现出灵活性——我们称其为位置泛化现象。它们能够理解位置发生扰动的文本，并且能够泛化到比训练中遇到的更长的文本，最新的技术使得这一现象成为可能。这些现象表明LLMs在处理位置时具有容忍性，但LLMs是如何在计算上处理位置相关性的，依然 largely unexplored。这项工作将语言现象与LLMs的计算机制联系起来。我们展示了LLMs如何通过某些计算机制来实现上述位置扰动的容忍性。尽管自我注意机制的设计复杂，但这项工作揭示了LLMs学习了一种直觉相反的注意力logits的分离。其值与位置相关性和语义重要性的算术和的近似值之间存在0.959的线性相关性。此外，我们识别出中间特征的一个普遍模式，我们证明这种模式理论上使这一效果得以实现。这种模式与随机初始化参数的行为不同，表明这是一种学习行为而非模型架构的自然结果。基于这些发现，我们提供了LLMs位置灵活性的计算解释和标准。这项工作在将位置泛化与现代LLMs的内部机制联系起来方面迈出了先驱性的一步。', 'title_zh': 'LLM位置泛化的计算机制'}
{'arxiv_id': 'arXiv:2503.13299', 'title': 'A Survey on Transformer Context Extension: Approaches and Evaluation', 'authors': 'Yijun Liu, Jinzheng Yu, Yang Xu, Zhongyang Li, Qingfu Zhu', 'link': 'https://arxiv.org/abs/2503.13299', 'abstract': 'Large language models (LLMs) based on Transformer have been widely applied in the filed of natural language processing (NLP), demonstrating strong performance, particularly in handling short text tasks. However, when it comes to long context scenarios, the performance of LLMs degrades due to some challenges. To alleviate this phenomenon, there is a number of work proposed recently. In this survey, we first list the challenges of applying pre-trained LLMs to process long contexts. Then systematically review the approaches related to long context and propose our taxonomy categorizing them into four main types: positional encoding, context compression, retrieval augmented, and attention pattern. In addition to the approaches, we focus on the evaluation of long context, organizing relevant data, tasks, and metrics based on existing long context benchmarks. Finally, we summarize unresolved issues in the long context domain and put forward our views on future developments.', 'abstract_zh': '基于Transformer的大语言模型在自然语言处理中的应用：长上下文挑战及解决方案综述', 'title_zh': '变压器上下文扩展综述：方法与评估'}
{'arxiv_id': 'arXiv:2503.13288', 'title': '$ϕ$-Decoding: Adaptive Foresight Sampling for Balanced Inference-Time Exploration and Exploitation', 'authors': 'Fangzhi Xu, Hang Yan, Chang Ma, Haiteng Zhao, Jun Liu, Qika Lin, Zhiyong Wu', 'link': 'https://arxiv.org/abs/2503.13288', 'abstract': 'Inference-time optimization scales computation to derive deliberate reasoning steps for effective performance. While previous search-based strategies address the short-sightedness of auto-regressive generation, the vast search space leads to excessive exploration and insufficient exploitation. To strike an efficient balance to derive the optimal step, we frame the decoding strategy as foresight sampling, leveraging simulated future steps to obtain globally optimal step estimation. Built on it, we propose a novel decoding strategy, named $\\phi$-Decoding. To provide a precise and expressive estimation of step value, $\\phi$-Decoding approximates two distributions via foresight and clustering. Sampling from the joint distribution, the optimal steps can be selected for exploitation. To support adaptive computation allocation, we propose in-width and in-depth pruning strategies, featuring a light-weight solution to achieve inference efficiency. Extensive experiments across seven benchmarks show $\\phi$-Decoding outperforms strong baselines in both performance and efficiency. Additional analysis demonstrates its generalization across various LLMs and scalability across a wide range of computing budgets. The code will be released at this https URL, and the open-source PyPI package is coming soon.', 'abstract_zh': '推理时的优化扩展计算以获取有目的地推理步骤，从而提高性能。虽然基于搜索的策略解决了自回归生成的短视问题，但庞大的搜索空间导致过度探索和不足的开发。为了在开发最优步骤时取得高效的平衡，我们将解码策略框定为前瞻采样，利用模拟的未来步骤来获取全局最优步骤估计。在此基础上，我们提出了一种新的解码策略，名为$\\phi$-解码。为提供精确且表达性强的步骤值估计，$\\phi$-解码通过前瞻和聚类近似两种分布。从联合分布采样，可以选择最优步骤进行开发。为了支持适应性计算分配，我们提出了在宽和深方向上的剪枝策略，这是一种轻量级解决方案以实现推理效率。在七个基准上的广泛实验显示，$\\phi$-解码在性能和效率上均优于强基线。额外的分析表明，其在各种大型语言模型中具有泛化能力，并且在广泛计算预算范围内具有可扩展性。代码将在此链接中发布，开源的PyPI包即将上线。', 'title_zh': '$\\phi$-解码：自适应前瞻性采样以实现平衡的推理时探索与利用'}
{'arxiv_id': 'arXiv:2503.13281', 'title': 'LLM-Match: An Open-Sourced Patient Matching Model Based on Large Language Models and Retrieval-Augmented Generation', 'authors': 'Xiaodi Li, Shaika Chowdhury, Chung Il Wi, Maria Vassilaki, Ken Liu, Terence T Sio, Owen Garrick, Young J Juhn, James R Cerhan, Cui Tao, Nansu Zong', 'link': 'https://arxiv.org/abs/2503.13281', 'abstract': "Patient matching is the process of linking patients to appropriate clinical trials by accurately identifying and matching their medical records with trial eligibility criteria. We propose LLM-Match, a novel framework for patient matching leveraging fine-tuned open-source large language models. Our approach consists of four key components. First, a retrieval-augmented generation (RAG) module extracts relevant patient context from a vast pool of electronic health records (EHRs). Second, a prompt generation module constructs input prompts by integrating trial eligibility criteria (both inclusion and exclusion criteria), patient context, and system instructions. Third, a fine-tuning module with a classification head optimizes the model parameters using structured prompts and ground-truth labels. Fourth, an evaluation module assesses the fine-tuned model's performance on the testing datasets. We evaluated LLM-Match on four open datasets, n2c2, SIGIR, TREC 2021, and TREC 2022, using open-source models, comparing it against TrialGPT, Zero-Shot, and GPT-4-based closed models. LLM-Match outperformed all baselines.", 'abstract_zh': '患者匹配是通过准确识别和匹配患者的医疗记录与临床试验资格标准，将患者链接到合适的临床试验的过程。我们提出了一种名为LLM-Match的新框架，该框架利用微调的开源大规模语言模型进行患者匹配。该方法包括四个关键组成部分。首先，检索增强生成（RAG）模块从庞大的电子健康记录（EHRs）池中提取相关患者上下文。其次，提示生成模块通过整合试验资格标准（包括纳入标准和排除标准）、患者上下文和系统指令构建输入提示。第三，具有分类头的微调模块使用结构化提示和真实标签优化模型参数。第四，评估模块在测试数据集上评估微调模型的性能。我们在n2c2、SIGIR、TREC 2021和TREC 2022四个开源数据集上使用开源模型评估了LLM-Match，并将其与TrialGPT、零样本和基于GPT-4的封闭模型进行了比较。LLM-Match在所有基线中表现最佳。', 'title_zh': 'LLM-Match：一种基于大规模语言模型和检索增强生成的开源患者匹配模型'}
{'arxiv_id': 'arXiv:2503.13279', 'title': 'Goal2Story: A Multi-Agent Fleet based on Privately Enabled sLLMs for Impacting Mapping on Requirements Elicitation', 'authors': 'Xinkai Zou, Yan Liu, Xiongbo Shi, Chen Yang', 'link': 'https://arxiv.org/abs/2503.13279', 'abstract': 'As requirements drift with rapid iterations, agile development becomes the dominant paradigm. Goal-driven Requirements Elicitation (RE) is a pivotal yet challenging task in agile project development due to its heavy tangling with adaptive planning and efficient collaboration. Recently, AI agents have shown promising ability in supporting requirements analysis by saving significant time and effort for stakeholders. However, current research mainly focuses on functional RE, and research works have not been reported bridging the long journey from goal to user stories. Moreover, considering the cost of LLM facilities and the need for data and idea protection, privately hosted small-sized LLM should be further utilized in RE. To address these challenges, we propose Goal2Story, a multi-agent fleet that adopts the Impact Mapping (IM) framework while merely using cost-effective sLLMs for goal-driven RE. Moreover, we introduce a StorySeek dataset that contains over 1,000 user stories (USs) with corresponding goals and project context information, as well as the semi-automatic dataset construction method. For evaluation, we proposed two metrics: Factuality Hit Rate (FHR) to measure consistency between the generated USs with the dataset and Quality And Consistency Evaluation (QuACE) to evaluate the quality of the generated USs. Experimental results demonstrate that Goal2Story outperforms the baseline performance of the Super-Agent adopting powerful LLMs, while also showcasing the performance improvements in key metrics brought by CoT and Agent Profile to Goal2Story, as well as its exploration in identifying latent needs.', 'abstract_zh': '基于目标到用户故事的多Agent框架：低成本小规模LLM在敏捷开发中驱动需求分析', 'title_zh': 'Goal2Story：基于私有增强sLLMs的多代理车队以影响需求提取的映射'}
{'arxiv_id': 'arXiv:2503.13277', 'title': 'Artificial Intelligence-Driven Prognostic Classification of COVID-19 Using Chest X-rays: A Deep Learning Approach', 'authors': 'Alfred Simbun, Suresh Kumar', 'link': 'https://arxiv.org/abs/2503.13277', 'abstract': "Background: The COVID-19 pandemic has overwhelmed healthcare systems, emphasizing the need for AI-driven tools to assist in rapid and accurate patient prognosis. Chest X-ray imaging is a widely available diagnostic tool, but existing methods for prognosis classification lack scalability and efficiency. Objective: This study presents a high-accuracy deep learning model for classifying COVID-19 severity (Mild, Moderate, and Severe) using Chest X-ray images, developed on Microsoft Azure Custom Vision. Methods: Using a dataset of 1,103 confirmed COVID-19 X-ray images from AIforCOVID, we trained and validated a deep learning model leveraging Convolutional Neural Networks (CNNs). The model was evaluated on an unseen dataset to measure accuracy, precision, and recall. Results: Our model achieved an average accuracy of 97%, with specificity of 99%, sensitivity of 87%, and an F1-score of 93.11%. When classifying COVID-19 severity, the model achieved accuracies of 89.03% (Mild), 95.77% (Moderate), and 81.16% (Severe). These results demonstrate the model's potential for real-world clinical applications, aiding in faster decision-making and improved resource allocation. Conclusion: AI-driven prognosis classification using deep learning can significantly enhance COVID-19 patient management, enabling early intervention and efficient triaging. Our study provides a scalable, high-accuracy AI framework for integrating deep learning into routine clinical workflows. Future work should focus on expanding datasets, external validation, and regulatory compliance to facilitate clinical adoption.", 'abstract_zh': '背景：COVID-19大流行已使医疗保健系统不堪重负，突显了需要AI驱动工具来辅助快速准确的患者预后。胸部X光成像是一种广泛应用的诊断工具，但现有的预后分类方法缺乏可扩展性和效率。目的：本研究提出了一种高精度的深度学习模型，用于通过胸部X光图像分类COVID-19严重程度（轻度、中度和重度），该模型基于Microsoft Azure Custom Vision开发。方法：使用来自AIforCOVID的1,103张确认的COVID-19 X光图像数据集，我们运用卷积神经网络（CNNs）训练和验证了一个深度学习模型。该模型在未见过的数据集上进行评估，以测量准确率、精确率和召回率。结果：我们的模型实现了平均97%的准确率，特异性为99%，敏感性为87%，F1分数为93.11%。在分类COVID-19严重程度时，轻度为89.03%、中度为95.77%、重度为81.16%。这些结果表明该模型在实际临床应用中的潜力，有助于更快的决策和资源分配。结论：利用深度学习进行AI驱动的预后分类可以显著提高COVID-19患者的管理能力，使早期干预和高效分诊成为可能。本研究提供了将深度学习纳入常规临床工作流的可扩展、高精度AI框架。未来的工作应重点关注数据集的扩展、外部验证和法规合规性，以促进临床应用。', 'title_zh': '基于胸部X光的人工智能驱动的COVID-19预后分类：一种深度学习方法'}
{'arxiv_id': 'arXiv:2503.13222', 'title': 'Can Language Models Follow Multiple Turns of Entangled Instructions?', 'authors': 'Chi Han', 'link': 'https://arxiv.org/abs/2503.13222', 'abstract': "Despite significant achievements in improving the instruction-following capabilities of large language models (LLMs), the ability to process multiple potentially entangled or conflicting instructions remains a considerable challenge. Real-world scenarios often require consistency across multiple instructions over time, such as secret privacy, personal preferences, and prioritization, which demand sophisticated abilities to integrate multiple turns and carefully balance competing objectives when instructions intersect or conflict. This work presents a systematic investigation of LLMs' capabilities in handling multiple turns of instructions, covering three levels of difficulty: (1) retrieving information from instructions, (2) tracking and reasoning across turns, and (3) resolving conflicts among instructions. We construct MultiTurnInstruct with around 1.1K high-quality multi-turn conversations through the human-in-the-loop approach and result in nine capability categories, including statics and dynamics, reasoning, and multitasking. Our finding reveals an intriguing trade-off between different capabilities. While GPT models demonstrate superior memorization, they show reduced effectiveness in privacy-protection tasks requiring selective information withholding. Larger models exhibit stronger reasoning capabilities but still struggle with resolving conflicting instructions. Importantly, these performance gaps cannot be attributed solely to information loss, as models demonstrate strong BLEU scores on memorization tasks but their attention mechanisms fail to integrate multiple related instructions effectively. These findings highlight critical areas for improvement in complex real-world tasks involving multi-turn instructions.", 'abstract_zh': '尽管在提高大型语言模型（LLMs）的指令遵循能力方面取得了显著进展，但在处理多个潜在交织或冲突的指令方面仍然存在显著挑战。现实世界的情景往往要求随着时间的推移在多个指令之间保持一致性，如保密隐私、个人偏好和优先级，这要求模型具备集成多个回合并仔细平衡竞争目标的高级能力。本研究系统地探讨了LLMs在处理多轮指令方面的能力，涵盖了三个难度级别：（1）从指令中检索信息，（2）跟踪和在各轮之间推理，（3）解决指令之间的冲突。我们通过闭环的人工干预方法构建了包含约1100个多轮高质量对话的MultiTurnInstruct数据集，并划分了九个能力类别，包括静态和动态特征、推理和多任务处理。我们的发现揭示了不同能力之间有趣的权衡关系。虽然GPT模型在记忆方面表现优异，但在需要选择性信息保留的隐私保护任务中效果降低。更大规模的模型展示了更强的推理能力，但仍难以解决冲突指令。重要的是，这些性能差距不能仅归因于信息丢失，因为模型在记忆任务上表现出强劲的BLEU分数，但它们的注意力机制难以有效整合多个相关指令。这些发现突显了在涉及多轮指令的复杂现实任务中改进的关键领域。', 'title_zh': '语言模型能跟随缠绕指令的多轮指示吗？'}
{'arxiv_id': 'arXiv:2503.13214', 'title': 'A General Adaptive Dual-level Weighting Mechanism for Remote Sensing Pansharpening', 'authors': 'Jie Huang, Haorui Chen, Jiaxuan Ren, Siran Peng, Liangjian Deng', 'link': 'https://arxiv.org/abs/2503.13214', 'abstract': 'Currently, deep learning-based methods for remote sensing pansharpening have advanced rapidly. However, many existing methods struggle to fully leverage feature heterogeneity and redundancy, thereby limiting their effectiveness. We use the covariance matrix to model the feature heterogeneity and redundancy and propose Correlation-Aware Covariance Weighting (CACW) to adjust them. CACW captures these correlations through the covariance matrix, which is then processed by a nonlinear function to generate weights for adjustment. Building upon CACW, we introduce a general adaptive dual-level weighting mechanism (ADWM) to address these challenges from two key perspectives, enhancing a wide range of existing deep-learning methods. First, Intra-Feature Weighting (IFW) evaluates correlations among channels within each feature to reduce redundancy and enhance unique information. Second, Cross-Feature Weighting (CFW) adjusts contributions across layers based on inter-layer correlations, refining the final output. Extensive experiments demonstrate the superior performance of ADWM compared to recent state-of-the-art (SOTA) methods. Furthermore, we validate the effectiveness of our approach through generality experiments, redundancy visualization, comparison experiments, key variables and complexity analysis, and ablation studies. Our code is available at this https URL.', 'abstract_zh': '基于深度学习的遥感 pansharpening 方法已取得 rapid 进展，但许多现有方法难以充分利用特征异质性和冗余性，从而限制了其有效性。我们利用协方差矩阵建模特征异质性和冗余性，并提出相关感知协方差加权（CACW）来调整它们。CACW 通过协方差矩阵捕获这些相关性，然后通过非线性函数生成调整权重。在此基础上，我们引入了一种通用的自适应双层加权机制（ADWM），从两个关键角度解决这些挑战，增强了一系列现有的深度学习方法。首先，Intra-Feature 加权（IFW）评估每个特征内部通道之间的相关性以减少冗余性和增强独特信息。其次，Cross-Feature 加权（CFW）基于层间相关性调整各层的贡献，精炼最终输出。大量实验表明，ADWM 在性能上优于最近的先进方法（SOTA）。此外，我们通过通用实验、冗余可视化、比较实验、关键变量和复杂性分析以及消融研究验证了我们方法的有效性。我们的代码可在以下网址访问：this https URL。', 'title_zh': '适用于遥感融合的通用自适应双层次加权机制'}
{'arxiv_id': 'arXiv:2503.13211', 'title': 'MedLoRD: A Medical Low-Resource Diffusion Model for High-Resolution 3D CT Image Synthesis', 'authors': 'Marvin Seyfarth, Salman Ul Hassan Dar, Isabelle Ayx, Matthias Alexander Fink, Stefan O. Schoenberg, Hans-Ulrich Kauczor, Sandy Engelhardt', 'link': 'https://arxiv.org/abs/2503.13211', 'abstract': 'Advancements in AI for medical imaging offer significant potential. However, their applications are constrained by the limited availability of data and the reluctance of medical centers to share it due to patient privacy concerns. Generative models present a promising solution by creating synthetic data as a substitute for real patient data. However, medical images are typically high-dimensional, and current state-of-the-art methods are often impractical for computational resource-constrained healthcare environments. These models rely on data sub-sampling, raising doubts about their feasibility and real-world applicability. Furthermore, many of these models are evaluated on quantitative metrics that alone can be misleading in assessing the image quality and clinical meaningfulness of the generated images. To address this, we introduce MedLoRD, a generative diffusion model designed for computational resource-constrained environments. MedLoRD is capable of generating high-dimensional medical volumes with resolutions up to 512$\\times$512$\\times$256, utilizing GPUs with only 24GB VRAM, which are commonly found in standard desktop workstations. MedLoRD is evaluated across multiple modalities, including Coronary Computed Tomography Angiography and Lung Computed Tomography datasets. Extensive evaluations through radiological evaluation, relative regional volume analysis, adherence to conditional masks, and downstream tasks show that MedLoRD generates high-fidelity images closely adhering to segmentation mask conditions, surpassing the capabilities of current state-of-the-art generative models for medical image synthesis in computational resource-constrained environments.', 'abstract_zh': '医学影像领域中人工智能的进步提供了巨大潜力，但由于数据可用性有限以及医疗中心因患者隐私问题不愿共享数据，其应用受到了限制。生成模型为这一问题提供了一种有前景的解决方案，通过生成合成数据来替代真实的患者数据。然而，医学图像通常具有高维度，当前最先进的方法对于计算资源受限的医疗保健环境来说往往不切实际。这些模型依赖于数据子采样，这引发了人们对它们可行性和实际应用性的怀疑。此外，许多模型仅通过定量指标进行评估，这些指标在评估生成图像的质量和临床意义时可能会具有误导性。为了解决这一问题，我们引入了MedLoRD，这是一种针对计算资源受限环境设计的生成扩散模型。MedLoRD 能够生成分辨率为 512×512×256 的高维度医学体素，并仅使用具有 24GB VRAM 的 GPU 实现，这在标准台式工作站中较为普遍。MedLoRD 在冠状动脉计算机断层扫描血管造影和肺部计算机断层扫描等不同模态的数据集上进行了评估。通过放射学评估、相对区域体积分析、条件掩码遵守情况以及下游任务等多种评估方法表明，MedLoRD 生成的高保真图像严格符合分割掩码条件，并在计算资源受限的环境中超越了当前最先进的医学图像生成模型的性能。', 'title_zh': 'MedLoRD: 一种用于高分辨率3D CT图像合成的医疗低资源扩散模型'}
{'arxiv_id': 'arXiv:2503.13208', 'title': 'Improving Complex Reasoning with Dynamic Prompt Corruption: A soft prompt Optimization Approach', 'authors': 'Sinan Fan, Liang Xie, Chen Shen, Ge Teng, Xiaosong Yuan, Xiaofeng Zhang, Chenxi Huang, Wenxiao Wang, Xiaofei He, Jieping Ye', 'link': 'https://arxiv.org/abs/2503.13208', 'abstract': 'Prompt-tuning (PT) for large language models (LLMs) can facilitate the performance on various conventional NLP tasks with significantly fewer trainable parameters. However, our investigation reveals that PT provides limited improvement and may even degrade the primitive performance of LLMs on complex reasoning tasks. Such a phenomenon suggests that soft prompts can positively impact certain instances while negatively affecting others, particularly during the later phases of reasoning. To address these challenges, We first identify an information accumulation within the soft prompts. Through detailed analysis, we demonstrate that this phenomenon is often accompanied by erroneous information flow patterns in the deeper layers of the model, which ultimately lead to incorrect reasoning outcomes. we propose a novel method called \\textbf{D}ynamic \\textbf{P}rompt \\textbf{C}orruption (DPC) to take better advantage of soft prompts in complex reasoning tasks, which dynamically adjusts the influence of soft prompts based on their impact on the reasoning process. Specifically, DPC consists of two stages: Dynamic Trigger and Dynamic Corruption. First, Dynamic Trigger measures the impact of soft prompts, identifying whether beneficial or detrimental. Then, Dynamic Corruption mitigates the negative effects of soft prompts by selectively masking key tokens that interfere with the reasoning process. We validate the proposed approach through extensive experiments on various LLMs and reasoning tasks, including GSM8K, MATH, and AQuA. Experimental results demonstrate that DPC can consistently enhance the performance of PT, achieving 4\\%-8\\% accuracy gains compared to vanilla prompt tuning, highlighting the effectiveness of our approach and its potential to enhance complex reasoning in LLMs.', 'abstract_zh': '动态提示损坏（DPC）：用于复杂推理任务的软提示优化', 'title_zh': '使用动态提示腐化改进复杂推理：一种软提示优化方法'}
{'arxiv_id': 'arXiv:2503.13200', 'title': 'Timing the Match: A Deep Reinforcement Learning Approach for Ride-Hailing and Ride-Pooling Services', 'authors': 'Yiman Bao, Jie Gao, Jinke He, Frans A. Oliehoek, Oded Cats', 'link': 'https://arxiv.org/abs/2503.13200', 'abstract': 'Efficient timing in ride-matching is crucial for improving the performance of ride-hailing and ride-pooling services, as it determines the number of drivers and passengers considered in each matching process. Traditional batched matching methods often use fixed time intervals to accumulate ride requests before assigning matches. While this approach increases the number of available drivers and passengers for matching, it fails to adapt to real-time supply-demand fluctuations, often leading to longer passenger wait times and driver idle periods. To address this limitation, we propose an adaptive ride-matching strategy using deep reinforcement learning (RL) to dynamically determine when to perform matches based on real-time system conditions. Unlike fixed-interval approaches, our method continuously evaluates system states and executes matching at moments that minimize total passenger wait time. Additionally, we incorporate a potential-based reward shaping (PBRS) mechanism to mitigate sparse rewards, accelerating RL training and improving decision quality. Extensive empirical evaluations using a realistic simulator trained on real-world data demonstrate that our approach outperforms fixed-interval matching strategies, significantly reducing passenger waiting times and detour delays, thereby enhancing the overall efficiency of ride-hailing and ride-pooling systems.', 'abstract_zh': '基于深度强化学习的自适应调度策略对于提高网约车和拼车服务性能至关重要：实时调度对于优化ride-matching过程中的性能至关重要，因为这决定了每次匹配过程中考虑的司机和乘客数量。传统的批量匹配方法通常使用固定的时间间隔来累积乘车请求后再进行匹配。尽管这种方法增加了可供匹配的司机和乘客数量，但它无法适应实时的供需波动，往往导致乘客等待时间更长和司机闲置时间更多。为解决这一局限性，我们提出了一种基于深度强化学习（RL）的自适应调度策略，利用实时系统条件动态决定何时进行匹配。与固定时间间隔的方法不同，我们的方法会连续评估系统状态，并在能够最小化总乘客等待时间的时刻执行匹配。此外，我们引入了一种基于潜力的奖励塑形（PBRS）机制，以缓解稀疏奖励问题，加速RL训练并提高决策质量。基于真实数据训练的现实仿真器的广泛实证评估表明，我们的方法优于固定时间间隔的匹配策略，显著减少了乘客等待时间和绕路延迟，从而提高了网约车和拼车系统的总体效率。', 'title_zh': '_timing的匹配：一种用于网约车和拼车服务的深度强化学习方法_'}
{'arxiv_id': 'arXiv:2503.13185', 'title': '3DAxisPrompt: Promoting the 3D Grounding and Reasoning in GPT-4o', 'authors': 'Dingning Liu, Cheng Wang, Peng Gao, Renrui Zhang, Xinzhu Ma, Yuan Meng, Zhihui Wang', 'link': 'https://arxiv.org/abs/2503.13185', 'abstract': "Multimodal Large Language Models (MLLMs) exhibit impressive capabilities across a variety of tasks, especially when equipped with carefully designed visual prompts. However, existing studies primarily focus on logical reasoning and visual understanding, while the capability of MLLMs to operate effectively in 3D vision remains an ongoing area of exploration. In this paper, we introduce a novel visual prompting method, called 3DAxisPrompt, to elicit the 3D understanding capabilities of MLLMs in real-world scenes. More specifically, our method leverages the 3D coordinate axis and masks generated from the Segment Anything Model (SAM) to provide explicit geometric priors to MLLMs and then extend their impressive 2D grounding and reasoning ability to real-world 3D scenarios. Besides, we first provide a thorough investigation of the potential visual prompting formats and conclude our findings to reveal the potential and limits of 3D understanding capabilities in GPT-4o, as a representative of MLLMs. Finally, we build evaluation environments with four datasets, i.e., ScanRefer, ScanNet, FMB, and nuScene datasets, covering various 3D tasks. Based on this, we conduct extensive quantitative and qualitative experiments, which demonstrate the effectiveness of the proposed method. Overall, our study reveals that MLLMs, with the help of 3DAxisPrompt, can effectively perceive an object's 3D position in real-world scenarios. Nevertheless, a single prompt engineering approach does not consistently achieve the best outcomes for all 3D tasks. This study highlights the feasibility of leveraging MLLMs for 3D vision grounding/reasoning with prompt engineering techniques.", 'abstract_zh': '多模态大型语言模型在三维视觉理解中的三维轴提示方法', 'title_zh': '3DAxisPrompt: 促进GPT-4o的3D定位与推理'}
{'arxiv_id': 'arXiv:2503.13180', 'title': 'GC-Fed: Gradient Centralized Federated Learning with Partial Client Participation', 'authors': 'Jungwon Seo, Ferhat Ozgur Catak, Chunming Rong, Kibeom Hong, Minhoe Kim', 'link': 'https://arxiv.org/abs/2503.13180', 'abstract': 'Multi-source information fusion (MSIF) leverages diverse data streams to enhance decision-making, situational awareness, and system resilience. Federated Learning (FL) enables MSIF while preserving privacy but suffers from client drift under high data heterogeneity, leading to performance degradation. Traditional mitigation strategies rely on reference-based gradient adjustments, which can be unstable in partial participation settings. To address this, we propose Gradient Centralized Federated Learning (GC-Fed), a reference-free gradient correction method inspired by Gradient Centralization (GC). We introduce Local GC and Global GC, applying GC during local training and global aggregation, respectively. Our hybrid GC-Fed approach selectively applies GC at the feature extraction layer locally and at the classifier layer globally, improving training stability and model performance. Theoretical analysis and empirical results demonstrate that GC-Fed mitigates client drift and achieves state-of-the-art accuracy gains of up to 20% in heterogeneous settings.', 'abstract_zh': '多源信息融合的梯度集中联邦学习（GC-Fed）：应对数据异构性引起的客户端漂移', 'title_zh': 'GC-Fed: 带有部分客户端参与的梯度集中联邦学习'}
{'arxiv_id': 'arXiv:2503.13171', 'title': 'HybridGen: VLM-Guided Hybrid Planning for Scalable Data Generation of Imitation Learning', 'authors': 'Wensheng Wang, Ning Tan', 'link': 'https://arxiv.org/abs/2503.13171', 'abstract': "The acquisition of large-scale and diverse demonstration data are essential for improving robotic imitation learning generalization. However, generating such data for complex manipulations is challenging in real-world settings. We introduce HybridGen, an automated framework that integrates Vision-Language Model (VLM) and hybrid planning. HybridGen uses a two-stage pipeline: first, VLM to parse expert demonstrations, decomposing tasks into expert-dependent (object-centric pose transformations for precise control) and plannable segments (synthesizing diverse trajectories via path planning); second, pose transformations substantially expand the first-stage data. Crucially, HybridGen generates a large volume of training data without requiring specific data formats, making it broadly applicable to a wide range of imitation learning algorithms, a characteristic which we also demonstrate empirically across multiple algorithms. Evaluations across seven tasks and their variants demonstrate that agents trained with HybridGen achieve substantial performance and generalization gains, averaging a 5% improvement over state-of-the-art methods. Notably, in the most challenging task variants, HybridGen achieves significant improvement, reaching a 59.7% average success rate, significantly outperforming Mimicgen's 49.5%. These results demonstrating its effectiveness and practicality.", 'abstract_zh': '大规模多样演示数据的自动获取对于提高机器人模仿学习的泛化能力至关重要。然而，在现实环境中为复杂操作生成此类数据具有挑战性。我们引入了HybridGen，这是一个结合了视觉语言模型（VLM）和混合规划的自动化框架。HybridGen采用两阶段流程：首先，VLM解析专家演示，将任务分解为专家依赖的物体中心姿态变换（精确控制）和可规划的部分（通过路径规划合成多样化轨迹）；其次，姿态变换显著扩展了第一阶段的数据量。关键的是，HybridGen能够在无需特定数据格式的情况下生成大量训练数据，使其广泛适用于各种模仿学习算法，我们在多个算法上也验证了这一点。在七个任务及其变种上的评估表明，使用HybridGen训练的代理在性能和泛化能力上取得了显著提高，平均优于现有最先进的方法5%。特别是在最具挑战性的任务变种中，HybridGen取得了显著改进，平均成功率达到59.7%，远超Mimicgen的49.5%。这些结果展示了其有效性和实用性。', 'title_zh': 'HybridGen: VLM-Guided Hybrid Planning for Scalable Data Generation in Imitation Learning'}
{'arxiv_id': 'arXiv:2503.13162', 'title': 'Efficient Imitation Under Misspecification', 'authors': 'Nicolas Espinosa-Dice, Sanjiban Choudhury, Wen Sun, Gokul Swamy', 'link': 'https://arxiv.org/abs/2503.13162', 'abstract': "Interactive imitation learning (IL) is a powerful paradigm for learning to make sequences of decisions from an expert demonstrating how to perform a task. Prior work in efficient imitation learning has focused on the realizable setting, where the expert's policy lies within the learner's policy class (i.e. the learner can perfectly imitate the expert in all states). However, in practice, perfect imitation of the expert is often impossible due to differences in state information and action space expressiveness (e.g. morphological differences between robots and humans.) In this paper, we consider the more general misspecified setting, where no assumptions are made about the expert policy's realizability. We introduce a novel structural condition, reward-agnostic policy completeness, and prove that it is sufficient for interactive IL algorithms to efficiently avoid the quadratically compounding errors that stymie offline approaches like behavioral cloning. We address an additional practical constraint-the case of limited expert data-and propose a principled method for using additional offline data to further improve the sample-efficiency of interactive IL algorithms. Finally, we empirically investigate the optimal reset distribution in efficient IL under misspecification with a suite of continuous control tasks.", 'abstract_zh': '交互式imitation learning（IL）是一种从专家展示任务执行过程学会决策序列的强大范式。先前在高效imitation learning方面的研究主要集中在专家策略可以被学习者策略类完美拟合的实现设置上。然而，在实践中，由于状态信息和动作空间表达能力的差异（例如，机器人和人类之间的形态差异），完全模仿专家往往是不可能的。在本文中，我们考虑了更一般的未指定设置，即不假设专家策略的实现性。我们提出了一个新颖的结构条件——奖励无关心的策略完备性，并证明了它对于交互式IL算法来说是充分的，能够有效避免离线方法（如行为克隆）中的二次递归错误。我们还处理了另一个实际约束——专家数据有限的情况，并提出了一种原则性的方法，利用额外的离线数据进一步提高交互式IL算法的学习效率。最后，我们在未指定情况下，通过一系列连续控制任务，实证研究了高效IL的理想重置分布。', 'title_zh': '在模型错误情况下的高效模仿'}
{'arxiv_id': 'arXiv:2503.13139', 'title': 'Logic-in-Frames: Dynamic Keyframe Search via Visual Semantic-Logical Verification for Long Video Understanding', 'authors': 'Weiyu Guo, Ziyang Chen, Shaoguang Wang, Jianxiang He, Yijie Xu, Jinhui Ye, Ying Sun, Hui Xiong', 'link': 'https://arxiv.org/abs/2503.13139', 'abstract': "Understanding long video content is a complex endeavor that often relies on densely sampled frame captions or end-to-end feature selectors, yet these techniques commonly overlook the logical relationships between textual queries and visual elements. In practice, computational constraints necessitate coarse frame subsampling, a challenge analogous to ``finding a needle in a haystack.'' To address this issue, we introduce a semantics-driven search framework that reformulates keyframe selection under the paradigm of Visual Semantic-Logical Search. Specifically, we systematically define four fundamental logical dependencies: 1) spatial co-occurrence, 2) temporal proximity, 3) attribute dependency, and 4) causal order. These relations dynamically update frame sampling distributions through an iterative refinement process, enabling context-aware identification of semantically critical frames tailored to specific query requirements. Our method establishes new SOTA performance on the manually annotated benchmark in key-frame selection metrics. Furthermore, when applied to downstream video question-answering tasks, the proposed approach demonstrates the best performance gains over existing methods on LongVideoBench and Video-MME, validating its effectiveness in bridging the logical gap between textual queries and visual-temporal reasoning. The code will be publicly available.", 'abstract_zh': '理解长视频内容是一项复杂的工作，通常依赖于密集采样的帧字幕或端到端特征选择器，但这些技术经常忽视文本查询与视觉元素之间的逻辑关系。在实践中，计算限制要求进行粗略的帧采样，这是一个类似于“在haystack中找针”的挑战。为了解决这个问题，我们提出了一种语义驱动的搜索框架，将关键帧选择重新表述为视觉语义-逻辑搜索的框架。具体而言，我们系统地定义了四种基本的逻辑依赖关系：1) 空间共现，2) 时间临近，3) 属性依赖，4) 因果顺序。这些关系通过迭代优化过程动态更新帧采样分布，从而使系统能够根据特定查询要求识别语义关键帧。我们的方法在关键帧选择基准上的手动标注指标中建立了新的SOTA性能。此外，在下游视频问答任务中，提出的方法在LongVideoBench和Video-MME上展示了比现有方法的最佳性能提升，验证了其在文本查询与视觉-时间推理之间逻辑鸿沟方面的有效性。代码将公开可用。', 'title_zh': '框架中的逻辑：通过视觉语义逻辑验证进行长视频中动态关键帧搜索'}
{'arxiv_id': 'arXiv:2503.13123', 'title': 'MIXPINN: Mixed-Material Simulations by Physics-Informed Neural Network', 'authors': 'Xintian Yuan, Yunke Ao, Boqi Chen, Philipp Fuernstahl', 'link': 'https://arxiv.org/abs/2503.13123', 'abstract': 'Simulating the complex interactions between soft tissues and rigid anatomy is critical for applications in surgical training, planning, and robotic-assisted interventions. Traditional Finite Element Method (FEM)-based simulations, while accurate, are computationally expensive and impractical for real-time scenarios. Learning-based approaches have shown promise in accelerating predictions but have fallen short in modeling soft-rigid interactions effectively. We introduce MIXPINN, a physics-informed Graph Neural Network (GNN) framework for mixed-material simulations, explicitly capturing soft-rigid interactions using graph-based augmentations. Our approach integrates Virtual Nodes (VNs) and Virtual Edges (VEs) to enhance rigid body constraint satisfaction while preserving computational efficiency. By leveraging a graph-based representation of biomechanical structures, MIXPINN learns high-fidelity deformations from FEM-generated data and achieves real-time inference with sub-millimeter accuracy. We validate our method in a realistic clinical scenario, demonstrating superior performance compared to baseline GNN models and traditional FEM methods. Our results show that MIXPINN reduces computational cost by an order of magnitude while maintaining high physical accuracy, making it a viable solution for real-time surgical simulation and robotic-assisted procedures.', 'abstract_zh': '混合材料间软硬交互的物理指导图神经网络模拟：一种提高实时外科模拟和机器人辅助手术效率的方法', 'title_zh': 'MIXPINN: 由物理知情神经网络实现的混合材料模拟'}
{'arxiv_id': 'arXiv:2503.13115', 'title': 'Beyond Propagation of Chaos: A Stochastic Algorithm for Mean Field Optimization', 'authors': 'Chandan Tankala, Dheeraj M. Nagaraj, Anant Raj', 'link': 'https://arxiv.org/abs/2503.13115', 'abstract': "Gradient flow in the 2-Wasserstein space is widely used to optimize functionals over probability distributions and is typically implemented using an interacting particle system with $n$ particles. Analyzing these algorithms requires showing (a) that the finite-particle system converges and/or (b) that the resultant empirical distribution of the particles closely approximates the optimal distribution (i.e., propagation of chaos). However, establishing efficient sufficient conditions can be challenging, as the finite particle system may produce heavily dependent random variables.\nIn this work, we study the virtual particle stochastic approximation, originally introduced for Stein Variational Gradient Descent. This method can be viewed as a form of stochastic gradient descent in the Wasserstein space and can be implemented efficiently. In popular settings, we demonstrate that our algorithm's output converges to the optimal distribution under conditions similar to those for the infinite particle limit, and it produces i.i.d. samples without the need to explicitly establish propagation of chaos bounds.", 'abstract_zh': '梯度流在2-Wasserstein空间中的应用及其虚拟粒子随机近似研究', 'title_zh': '超越混沌传播：一种用于均 field 优化的随机算法'}
{'arxiv_id': 'arXiv:2503.13108', 'title': 'Lifting the Veil on Visual Information Flow in MLLMs: Unlocking Pathways to Faster Inference', 'authors': 'Hao Yin, Guangzong Si, Zilei Wang', 'link': 'https://arxiv.org/abs/2503.13108', 'abstract': 'Multimodal large language models (MLLMs) improve performance on vision-language tasks by integrating visual features from pre-trained vision encoders into large language models (LLMs). However, how MLLMs process and utilize visual information remains unclear. In this paper, a shift in the dominant flow of visual information is uncovered: (1) in shallow layers, strong interactions are observed between image tokens and instruction tokens, where most visual information is injected into instruction tokens to form cross-modal semantic representations; (2) in deeper layers, image tokens primarily interact with each other, aggregating the remaining visual information to optimize semantic representations within visual modality. Based on these insights, we propose Hierarchical Modality-Aware Pruning (HiMAP), a plug-and-play inference acceleration method that dynamically prunes image tokens at specific layers, reducing computational costs by approximately 65% without sacrificing performance. Our findings offer a new understanding of visual information processing in MLLMs and provide a state-of-the-art solution for efficient inference.', 'abstract_zh': '多模态大规模语言模型（MLLMs）通过将预训练视觉编码器的视觉特征集成到大规模语言模型（LLMs）中，提高了在视觉语言任务上的性能。然而，MLLMs如何处理和利用视觉信息仍不清楚。本文揭示了视觉信息主导流动的转变：（1）在浅层层中，观察到图像令牌与指令令牌之间存在强烈交互，大部分视觉信息注入到指令令牌中以形成跨模态语义表示；（2）在深层层中，图像令牌主要与其他图像令牌交互，聚集剩余的视觉信息以优化视觉模态内的语义表示。基于这些洞察，我们提出了层次化的模态感知剪枝（HiMAP），这是一种即插即用的推理加速方法，在特定层动态剪枝图像令牌，减少约65%的计算成本而不牺牲性能。我们的发现为MLLMs中的视觉信息处理提供了新的理解，并提供了最先进的高效推理解决方案。', 'title_zh': '揭开视觉信息在MLLMs中流动的面纱：解锁更快推理的路径'}
{'arxiv_id': 'arXiv:2503.13107', 'title': 'ClearSight: Visual Signal Enhancement for Object Hallucination Mitigation in Multimodal Large language Models', 'authors': 'Hao Yin, Guangzong Si, Zilei Wang', 'link': 'https://arxiv.org/abs/2503.13107', 'abstract': "Contrastive decoding strategies are widely used to mitigate object hallucinations in multimodal large language models (MLLMs). By reducing over-reliance on language priors, these strategies ensure that generated content remains closely grounded in visual inputs, producing contextually accurate outputs. Since contrastive decoding requires no additional training or external tools, it offers both computational efficiency and versatility, making it highly attractive. However, these methods present two main limitations: (1) bluntly suppressing language priors can compromise coherence and accuracy of generated content, and (2) processing contrastive inputs adds computational load, significantly slowing inference speed. To address these challenges, we propose Visual Amplification Fusion (VAF), a plug-and-play technique that enhances attention to visual signals within the model's middle layers, where modality fusion predominantly occurs. This approach enables more effective capture of visual features, reducing the model's bias toward language modality. Experimental results demonstrate that VAF significantly reduces hallucinations across various MLLMs without affecting inference speed, while maintaining coherence and accuracy in generated outputs.", 'abstract_zh': '视觉增强融合（VAF）：一种插件式技术以减轻多模态大语言模型中的对象幻觉', 'title_zh': 'ClearSight: 视觉信号增强以减轻多模态大型语言模型中对象幻视问题'}
{'arxiv_id': 'arXiv:2503.13089', 'title': 'ClusComp: A Simple Paradigm for Model Compression and Efficient Finetuning', 'authors': 'Baohao Liao, Christian Herold, Seyyed Hadi Hashemi, Stefan Vasilev, Shahram Khadivi, Christof Monz', 'link': 'https://arxiv.org/abs/2503.13089', 'abstract': 'As large language models (LLMs) scale, model compression is crucial for edge deployment and accessibility. Weight-only quantization reduces model size but suffers from performance degradation at lower bit widths. Moreover, standard finetuning is incompatible with quantized models, and alternative methods often fall short of full finetuning. In this paper, we propose ClusComp, a simple yet effective compression paradigm that clusters weight matrices into codebooks and finetunes them block-by-block. ClusComp (1) achieves superior performance in 2-4 bit quantization, (2) pushes compression to 1-bit while outperforming ultra-low-bit methods with minimal finetuning, and (3) enables efficient finetuning, even surpassing existing quantization-based approaches and rivaling full FP16 finetuning. Notably, ClusComp supports compression and finetuning of 70B LLMs on a single A6000-48GB GPU.', 'abstract_zh': '大规模语言模型（LLMs）扩展时，模型压缩对于边缘部署和可访问性至关重要。权重仅为量化可以减少模型大小，但在较低位宽时会遭受性能下降。此外，标准微调与量化模型不兼容，而替代方法往往无法达到完整微调的效果。在此论文中，我们提出了一种简单而有效的压缩 paradigma，即将权重矩阵聚类成代码本并逐块微调。ClusComp (1) 在 2-4 位量化中实现了优越的性能，(2) 将压缩推至 1 位，并通过最少的微调超越超低位量化方法，(3) 使微调更加高效，甚至超越现有的基于量化的方法，接近全 FP16 微调。值得注意的是，ClusComp 可在单块 A6000-48GB GPU 上对 70B LLM 进行压缩和微调。', 'title_zh': 'ClusComp: 一种简单的模型压缩和高效微调范式'}
{'arxiv_id': 'arXiv:2503.13082', 'title': 'Free-form language-based robotic reasoning and grasping', 'authors': 'Runyu Jiao, Alice Fasoli, Francesco Giuliari, Matteo Bortolon, Sergio Povoli, Guofeng Mei, Yiming Wang, Fabio Poiesi', 'link': 'https://arxiv.org/abs/2503.13082', 'abstract': "Performing robotic grasping from a cluttered bin based on human instructions is a challenging task, as it requires understanding both the nuances of free-form language and the spatial relationships between objects. Vision-Language Models (VLMs) trained on web-scale data, such as GPT-4o, have demonstrated remarkable reasoning capabilities across both text and images. But can they truly be used for this task in a zero-shot setting? And what are their limitations? In this paper, we explore these research questions via the free-form language-based robotic grasping task, and propose a novel method, FreeGrasp, leveraging the pre-trained VLMs' world knowledge to reason about human instructions and object spatial arrangements. Our method detects all objects as keypoints and uses these keypoints to annotate marks on images, aiming to facilitate GPT-4o's zero-shot spatial reasoning. This allows our method to determine whether a requested object is directly graspable or if other objects must be grasped and removed first. Since no existing dataset is specifically designed for this task, we introduce a synthetic dataset FreeGraspData by extending the MetaGraspNetV2 dataset with human-annotated instructions and ground-truth grasping sequences. We conduct extensive analyses with both FreeGraspData and real-world validation with a gripper-equipped robotic arm, demonstrating state-of-the-art performance in grasp reasoning and execution. Project website: this https URL.", 'abstract_zh': '基于人类指令从杂乱容器中进行机器人抓取是一项具有挑战性的任务，因为它要求理解和掌握自然语言的细微差异以及物体之间的空间关系。在网页规模数据上训练的视觉-语言模型（VLMs），如GPT-4o，已经在文本和图像推理方面展现出了卓越的能力。但在零样本设置下，它们是否真的可以用于此任务？以及它们存在哪些局限性？本文通过基于自然语言的机器人抓取任务探索这些研究问题，并提出了一种新方法FreeGrasp，利用预训练的VLMs的世界知识来解析人类指令和物体的空间排列。该方法将所有物体检测为关键点，并使用这些关键点在图像上标注标记，旨在促进GPT-4o的零样本空间推理。这使得该方法能够判断请求的物体是否可以直接被抓取，还是需要先抓取并移除其他物体。由于目前没有专门为此任务设计的数据集，我们通过扩展MetaGraspNetV2数据集并加入人标注的指令和真实抓取序列，提出了一个合成数据集FreeGraspData。我们在FreeGraspData和现实世界的验证中进行了详细分析，并使用装备了夹爪的机械臂进行了真实世界验证，展示了在抓取推理和执行方面的卓越性能。项目网站：this https URL。', 'title_zh': '基于自由形式语言的机器人推理与抓取'}
{'arxiv_id': 'arXiv:2503.13081', 'title': 'A Framework to Assess Multilingual Vulnerabilities of LLMs', 'authors': 'Likai Tang, Niruth Bogahawatta, Yasod Ginige, Jiarui Xu, Shixuan Sun, Surangika Ranathunga, Suranga Seneviratne', 'link': 'https://arxiv.org/abs/2503.13081', 'abstract': "Large Language Models (LLMs) are acquiring a wider range of capabilities, including understanding and responding in multiple languages. While they undergo safety training to prevent them from answering illegal questions, imbalances in training data and human evaluation resources can make these models more susceptible to attacks in low-resource languages (LRL). This paper proposes a framework to automatically assess the multilingual vulnerabilities of commonly used LLMs. Using our framework, we evaluated six LLMs across eight languages representing varying levels of resource availability. We validated the assessments generated by our automated framework through human evaluation in two languages, demonstrating that the framework's results align with human judgments in most cases. Our findings reveal vulnerabilities in LRL; however, these may pose minimal risk as they often stem from the model's poor performance, resulting in incoherent responses.", 'abstract_zh': '大规模语言模型（LLMs）正在获得更广泛的能力，包括多语言的理解和响应。尽管它们接受安全性训练以防止回答非法问题，但训练数据不平衡和人类评估资源的不足可能使这些模型在低资源语言（LRL）中更容易受到攻击。本文提出了一种框架以自动评估常用LLM的多语言脆弱性。使用该框架，我们在八种代表不同资源可获取程度的语言上评估了六种LLM。通过两种语言的人类评估验证了我们自动框架生成的评估结果，显示该框架的结果大多数情况下与人类判断一致。我们的研究发现LRL存在脆弱性，但这些脆弱性通常源自模型表现不佳，导致不连贯的响应，可能带来的风险较小。', 'title_zh': '评估多语言模型脆弱性的框架'}
{'arxiv_id': 'arXiv:2503.13055', 'title': 'Mitigating Cross-Modal Distraction and Ensuring Geometric Feasibility via Affordance-Guided, Self-Consistent MLLMs for Food Preparation Task Planning', 'authors': 'Yu-Hong Shen, Chuan-Yu Wu, Yi-Ru Yang, Yen-Ling Tai, Yi-Ting Chen', 'link': 'https://arxiv.org/abs/2503.13055', 'abstract': 'We study Multimodal Large Language Models (MLLMs) with in-context learning for food preparation task planning. In this context, we identify two key challenges: cross-modal distraction and geometric feasibility. Cross-modal distraction occurs when the inclusion of visual input degrades the reasoning performance of a MLLM. Geometric feasibility refers to the ability of MLLMs to ensure that the selected skills are physically executable in the environment. To address these issues, we adapt Chain of Thought (CoT) with Self-Consistency to mitigate reasoning loss from cross-modal distractions and use affordance predictor as skill preconditions to guide MLLM on geometric feasibility. We construct a dataset to evaluate the ability of MLLMs on quantity estimation, reachability analysis, relative positioning and collision avoidance. We conducted a detailed evaluation to identify issues among different baselines and analyze the reasons for improvement, providing insights into each approach. Our method reaches a success rate of 76.7% on the entire dataset, showing a substantial improvement over the CoT baseline at 36.7%.', 'abstract_zh': '我们研究了具有上下文学习能力的多模态大型语言模型（MLLMs）在食物 preparation 任务规划中的应用。在此背景下，我们识别了两个关键挑战：跨模态干扰和几何可行性。跨模态干扰指的是视觉输入的加入会损害 MLLM 的推理性能。几何可行性是指 MLLM 确保所选技能在环境中物理可执行的能力。为了应对这些挑战，我们采用带自我一致性检验的推理链（CoT）减少跨模态干扰带来的推理损失，并使用功能预测器作为技能的前提条件，以指导 MLLM 对几何可行性的处理。我们构建了一个数据集，评估 MLLM 在数量估计、可达性分析、相对定位和碰撞避免方面的能力。我们进行了详细评估，识别不同基线中的问题并分析改进的原因，为每种方法提供了见解。我们的方法在整个数据集上的成功率达到了 76.7%，相较于 CoT 基线的 36.7% 显示出显著的改进。', 'title_zh': '通过能力导向、自我一致的MLLMs减轻跨模态干扰并确保几何可行性以进行食品准备任务规划'}
{'arxiv_id': 'arXiv:2503.13025', 'title': 'PoseSyn: Synthesizing Diverse 3D Pose Data from In-the-Wild 2D Data', 'authors': 'ChangHee Yang, Hyeonseop Song, Seokhun Choi, Seungwoo Lee, Jaechul Kim, Hoseok Do', 'link': 'https://arxiv.org/abs/2503.13025', 'abstract': "Despite considerable efforts to enhance the generalization of 3D pose estimators without costly 3D annotations, existing data augmentation methods struggle in real world scenarios with diverse human appearances and complex poses. We propose PoseSyn, a novel data synthesis framework that transforms abundant in the wild 2D pose dataset into diverse 3D pose image pairs. PoseSyn comprises two key components: Error Extraction Module (EEM), which identifies challenging poses from the 2D pose datasets, and Motion Synthesis Module (MSM), which synthesizes motion sequences around the challenging poses. Then, by generating realistic 3D training data via a human animation model aligned with challenging poses and appearances PoseSyn boosts the accuracy of various 3D pose estimators by up to 14% across real world benchmarks including various backgrounds and occlusions, challenging poses, and multi view scenarios. Extensive experiments further confirm that PoseSyn is a scalable and effective approach for improving generalization without relying on expensive 3D annotations, regardless of the pose estimator's model size or design.", 'abstract_zh': '尽管在无需昂贵3D标注的情况下提升3D姿态估计器的泛化能力方面付出了大量努力，现有的数据增强方法在包含多样化人类外观和复杂姿态的真实世界场景中表现不佳。我们提出了一种名为PoseSyn的新颖数据合成框架，能够将野生物2D姿态数据集转换为多样化的3D姿态图像对。PoseSyn主要包括两个关键组件：错误提取模块（EEM），用于从2D姿态数据集中识别具有挑战性的姿态；以及运动合成模块（MSM），用于围绕这些具有挑战性的姿态合成运动序列。通过使用与具有挑战性的姿态和外观相匹配的人类动画模型生成真实的3D训练数据，PoseSyn在包含各种背景、遮挡、具有挑战性姿态及多视图场景的真实世界基准测试中，能够将各种3D姿态估计器的准确性提升高达14%。进一步的实验还证实，PoseSyn是一种可扩展且有效的方案，能够在无需依赖昂贵3D标注的情况下提高泛化能力，无论姿态估计器的模型大小或设计如何。', 'title_zh': 'PoseSyn: 从野生状态的2D数据合成多样化的3D姿态数据'}
{'arxiv_id': 'arXiv:2503.13012', 'title': 'Test-Time Domain Generalization via Universe Learning: A Multi-Graph Matching Approach for Medical Image Segmentation', 'authors': 'Xingguo Lv, Xingbo Dong, Liwen Wang, Jiewen Yang, Lei Zhao, Bin Pu, Zhe Jin, Xuejun Li', 'link': 'https://arxiv.org/abs/2503.13012', 'abstract': 'Despite domain generalization (DG) has significantly addressed the performance degradation of pre-trained models caused by domain shifts, it often falls short in real-world deployment. Test-time adaptation (TTA), which adjusts a learned model using unlabeled test data, presents a promising solution. However, most existing TTA methods struggle to deliver strong performance in medical image segmentation, primarily because they overlook the crucial prior knowledge inherent to medical images. To address this challenge, we incorporate morphological information and propose a framework based on multi-graph matching. Specifically, we introduce learnable universe embeddings that integrate morphological priors during multi-source training, along with novel unsupervised test-time paradigms for domain adaptation. This approach guarantees cycle-consistency in multi-matching while enabling the model to more effectively capture the invariant priors of unseen data, significantly mitigating the effects of domain shifts. Extensive experiments demonstrate that our method outperforms other state-of-the-art approaches on two medical image segmentation benchmarks for both multi-source and single-source domain generalization tasks. The source code is available at this https URL.', 'abstract_zh': '尽管泛化域（Domain Generalization, DG）在缓解由于域偏移引起的预训练模型性能下降方面取得了显著进展，但在实际部署中依然存在局限性。测试时自适应（Test-time Adaptation, TTA），即通过未标记的测试数据调整已学习模型，提供了一种有潜力的解决方案。然而，现有的大多数TTA方法在医学图像分割任务中未能表现出色，主要原因是它们忽略了医学图像固有的关键先验知识。为应对这一挑战，我们引入了形态学信息，并提出了一种基于多图匹配的框架。具体来说，我们引入可学习的宇宙嵌入，将形态学先验知识集成到多源训练中，并提出了一种新颖的无监督测试时领域自适应方案。该方法保证了多匹配的一致性，并使模型能够更有效地捕捉未见数据的不变先验，显著减少了域偏移的影响。广泛实验证明，我们的方法在两个医学图像分割基准数据集的多源和单源泛化任务中均优于其他最先进的方法。源代码可在以下链接获取。', 'title_zh': '基于宇宙学习的测试时域泛化：医疗图像分割的多图匹配方法'}
{'arxiv_id': 'arXiv:2503.12999', 'title': 'Concept-as-Tree: Synthetic Data is All You Need for VLM Personalization', 'authors': 'Ruichuan An, Kai Zeng, Ming Lu, Sihan Yang, Renrui Zhang, Huitong Ji, Qizhe Zhang, Yulin Luo, Hao Liang, Wentao Zhang', 'link': 'https://arxiv.org/abs/2503.12999', 'abstract': "Vision-Language Models (VLMs) have demonstrated exceptional performance in various multi-modal tasks. Recently, there has been an increasing interest in improving the personalization capabilities of VLMs. To better integrate user-provided concepts into VLMs, many methods use positive and negative samples to fine-tune these models. However, the scarcity of user-provided positive samples and the low quality of retrieved negative samples pose challenges for fine-tuning. To reveal the relationship between sample and model performance, we systematically investigate the impact of positive and negative samples (easy and hard) and their diversity on VLM personalization tasks. Based on the detailed analysis, we introduce Concept-as-Tree (CaT), which represents a concept as a tree structure, thereby enabling the data generation of positive and negative samples with varying difficulty and diversity for VLM personalization. With a well-designed data filtering strategy, our CaT framework can ensure the quality of generated data, constituting a powerful pipeline. We perform thorough experiments with various VLM personalization baselines to assess the effectiveness of the pipeline, alleviating the lack of positive samples and the low quality of negative samples. Our results demonstrate that CaT equipped with the proposed data filter significantly enhances the personalization capabilities of VLMs across the MyVLM, Yo'LLaVA, and MC-LLaVA datasets. To our knowledge, this work is the first controllable synthetic data pipeline for VLM personalization. The code is released at \\href{this https URL}{this https URL}.", 'abstract_zh': "Vision-Language模型（VLMs）在多种跨模态任务中展现了卓越的性能。近年来，人们越来越关注提升VLMs的个性化能力。为了更好地将用户提供的概念整合到VLMs中，许多方法使用正样本和负样本对这些模型进行微调。然而，正样本的稀缺性和检索到的负样本质量低下为微调带来了挑战。为了揭示样本与模型性能之间的关系，我们系统地研究了正样本（易和难）和负样本及其多样性的影响对VLM个性化任务的影响。基于详细的分析，我们引入了Concept-as-Tree（CaT），它将概念表示为树结构，从而能够生成具有不同难度和多样性的正负样本数据，用于VLM个性化。通过设计合理的数据过滤策略，我们的CaT框架可以确保生成数据的质量，构成一个强大的工作流程。我们使用各种VLM个性化基线进行了彻底的实验，评估该流程的有效性，缓解正样本稀缺和负样本质量低的问题。我们的结果显示，在MyVLM、Yo'LLaVA和MC-LLaVA数据集上，配备所提数据过滤器的CaT显著增强了VLMs的个性化能力。据我们所知，这是第一个可控的合成数据流程用于VLM个性化。代码已发布在\\href{this https URL}{this https URL}。", 'title_zh': '概念树：合成数据即所有你所需要的VLM个性化方法'}
{'arxiv_id': 'arXiv:2503.12993', 'title': 'Robot Policy Transfer with Online Demonstrations: An Active Reinforcement Learning Approach', 'authors': 'Muhan Hou, Koen Hindriks, A.E. Eiben, Kim Baraka', 'link': 'https://arxiv.org/abs/2503.12993', 'abstract': 'Transfer Learning (TL) is a powerful tool that enables robots to transfer learned policies across different environments, tasks, or embodiments. To further facilitate this process, efforts have been made to combine it with Learning from Demonstrations (LfD) for more flexible and efficient policy transfer. However, these approaches are almost exclusively limited to offline demonstrations collected before policy transfer starts, which may suffer from the intrinsic issue of covariance shift brought by LfD and harm the performance of policy transfer. Meanwhile, extensive work in the learning-from-scratch setting has shown that online demonstrations can effectively alleviate covariance shift and lead to better policy performance with improved sample efficiency. This work combines these insights to introduce online demonstrations into a policy transfer setting. We present Policy Transfer with Online Demonstrations, an active LfD algorithm for policy transfer that can optimize the timing and content of queries for online episodic expert demonstrations under a limited demonstration budget. We evaluate our method in eight robotic scenarios, involving policy transfer across diverse environment characteristics, task objectives, and robotic embodiments, with the aim to transfer a trained policy from a source task to a related but different target task. The results show that our method significantly outperforms all baselines in terms of average success rate and sample efficiency, compared to two canonical LfD methods with offline demonstrations and one active LfD method with online demonstrations. Additionally, we conduct preliminary sim-to-real tests of the transferred policy on three transfer scenarios in the real-world environment, demonstrating the policy effectiveness on a real robot manipulator.', 'abstract_zh': '基于在线示范的策略迁移', 'title_zh': '基于在线示范的机器人策略转移：一种主动强化学习方法'}
{'arxiv_id': 'arXiv:2503.12989', 'title': 'A Multi-Stage Framework with Taxonomy-Guided Reasoning for Occupation Classification Using Large Language Models', 'authors': 'Palakorn Achananuparp, Ee-Peng Lim', 'link': 'https://arxiv.org/abs/2503.12989', 'abstract': "Automatically annotating job data with standardized occupations from taxonomies, known as occupation classification, is crucial for labor market analysis. However, this task is often hindered by data scarcity and the challenges of manual annotations. While large language models (LLMs) hold promise due to their extensive world knowledge and in-context learning capabilities, their effectiveness depends on their knowledge of occupational taxonomies, which remains unclear. In this study, we assess the ability of LLMs to generate precise taxonomic entities from taxonomy, highlighting their limitations. To address these challenges, we propose a multi-stage framework consisting of inference, retrieval, and reranking stages, which integrates taxonomy-guided reasoning examples to enhance performance by aligning outputs with taxonomic knowledge. Evaluations on a large-scale dataset show significant improvements in classification accuracy. Furthermore, we demonstrate the framework's adaptability for multi-label skill classification. Our results indicate that the framework outperforms existing LLM-based methods, offering a practical and scalable solution for occupation classification and related tasks across LLMs.", 'abstract_zh': '自动使用标准化职业分类标注工作数据对于劳动力市场分析至关重要。然而，这一任务常常受到数据稀缺性和手动标注挑战的阻碍。虽然大型语言模型（LLMs）因其广泛的世界知识和上下文学习能力展现出潜力，但其有效性仍取决于对职业分类的知识掌握，这尚未明确。在本研究中，我们评估了LLMs生成精确分类实体的能力，并指出其局限性。为了应对这些挑战，我们提出了一种多阶段框架，包括推理、检索和重排序阶段，该框架整合了基于分类的推理示例，以通过将输出与分类知识对齐来提升性能。大规模数据集的评估显示分类准确性显著提高。此外，我们展示了该框架在多标签技能分类中的适用性。我们的结果表明，该框架优于现有基于LLM的方法，为职业分类及相关任务提供了一种实用且可扩展的解决方案，适用于各种LLM。', 'title_zh': '基于分类 taxonomy 引导推理的多阶段框架在大规模语言模型中进行职业分类'}
{'arxiv_id': 'arXiv:2503.12988', 'title': 'ROMA: a Read-Only-Memory-based Accelerator for QLoRA-based On-Device LLM', 'authors': 'Wenqiang Wang, Yijia Zhang, Zikai Zhang, Guanting Huo, Hao Liang, Shijie Cao, Ningyi Xu', 'link': 'https://arxiv.org/abs/2503.12988', 'abstract': 'As large language models (LLMs) demonstrate powerful capabilities, deploying them on edge devices has become increasingly crucial, offering advantages in privacy and real-time interaction. QLoRA has emerged as the standard approach for on-device LLMs, leveraging quantized models to reduce memory and computational costs while utilizing LoRA for task-specific adaptability. In this work, we propose ROMA, a QLoRA accelerator with a hybrid storage architecture that uses ROM for quantized base models and SRAM for LoRA weights and KV cache. Our insight is that the quantized base model is stable and converged, making it well-suited for ROM storage. Meanwhile, LoRA modules offer the flexibility to adapt to new data without requiring updates to the base model. To further reduce the area cost of ROM, we introduce a novel B-ROM design and integrate it with the compute unit to form a fused cell for efficient use of chip resources. ROMA can effectively store both a 4-bit 3B and a 2-bit 8B LLaMA model entirely on-chip, achieving a notable generation speed exceeding 20,000 tokens/s without requiring external memory.', 'abstract_zh': '随着大型语言模型（LLMs）展现出强大的能力，将它们部署在边缘设备上变得越来越重要，这在隐私和实时交互方面提供了优势。QLoRA已经成为边端LLM的标准方法，通过量化模型减少内存和计算成本，同时利用LoRA实现任务特定的适应性。在这项工作中，我们提出了ROMA，一种具有混合存储架构的QLoRA加速器，使用ROM存储量化基模型，使用SRAM存储LoRA权重和KV缓存。我们的见解是，量化基模型稳定且已收敛，非常适合ROM存储。同时，LoRA模块提供了灵活性，可以在无需更新基模型的情况下适应新数据。为了进一步减少ROM的面积成本，我们引入了一种新颖的B-ROM设计，并将其与计算单元集成，形成高效的芯片资源融合单元。ROMA可以在芯片上有效存储4位的3B和2位的8B LLaMA模型，实现超过20,000个令牌/秒的生成速度，无需外部内存。', 'title_zh': 'ROMA：基于只读存储器的QLoRA-Based On-Device LLM加速器'}
{'arxiv_id': 'arXiv:2503.12972', 'title': 'Aligning Vision to Language: Text-Free Multimodal Knowledge Graph Construction for Enhanced LLMs Reasoning', 'authors': 'Junming Liu, Siyuan Meng, Yanting Gao, Song Mao, Pinlong Cai, Guohang Yan, Yirong Chen, Zilin Bian, Botian Shi, Ding Wang', 'link': 'https://arxiv.org/abs/2503.12972', 'abstract': 'Multimodal reasoning in Large Language Models (LLMs) struggles with incomplete knowledge and hallucination artifacts, challenges that textual Knowledge Graphs (KGs) only partially mitigate due to their modality isolation. While Multimodal Knowledge Graphs (MMKGs) promise enhanced cross-modal understanding, their practical construction is impeded by semantic narrowness of manual text annotations and inherent noise in visual-semantic entity linkages. In this paper, we propose Vision-align-to-Language integrated Knowledge Graph (VaLiK), a novel approach for constructing MMKGs that enhances LLMs reasoning through cross-modal information supplementation. Specifically, we cascade pre-trained Vision-Language Models (VLMs) to align image features with text, transforming them into descriptions that encapsulate image-specific information. Furthermore, we developed a cross-modal similarity verification mechanism to quantify semantic consistency, effectively filtering out noise introduced during feature alignment. Even without manually annotated image captions, the refined descriptions alone suffice to construct the MMKG. Compared to conventional MMKGs construction paradigms, our approach achieves substantial storage efficiency gains while maintaining direct entity-to-image linkage capability. Experimental results on multimodal reasoning tasks demonstrate that LLMs augmented with VaLiK outperform previous state-of-the-art models. Our code is published at this https URL.', 'abstract_zh': '多模态大型语言模型在多模态推理中面对不完整知识和幻觉问题，这些挑战即使在部分依赖于模态隔离的语言知识图谱中也无法完全缓解。虽然多模态知识图谱（MMKGs）能够增强跨模态理解，但它们的实际构建因手动文本注释的语义狭窄性和视觉语义实体链接中的固有噪声而受限。本文提出了一种名为Vision-align-to-Language集成知识图谱（VaLiK）的新方法，通过跨模态信息补充增强大型语言模型的推理能力。具体来说，我们利用预训练的视觉-语言模型将图像特征与文本对齐，并将其转化为包含图像特定信息的描述。此外，我们开发了一种跨模态相似性验证机制以量化语义一致性，有效过滤掉特征对齐过程中引入的噪声。即使没有手动标注的图像描述，经过改进的描述即可构建多模态知识图谱。与传统的多模态知识图谱构建方法相比，我们的方法在保持直接实体到图像链接能力的同时实现了显著的存储效率提升。实验结果表明，使用VaLiK增强的大型语言模型在多模态推理任务中优于之前最先进的模型。我们的代码在此处发布：this https URL。', 'title_zh': '视觉与语言对齐：无文本的多模态知识图构建以增强LLM推理'}
{'arxiv_id': 'arXiv:2503.12964', 'title': 'Training Video Foundation Models with NVIDIA NeMo', 'authors': 'Zeeshan Patel, Ethan He, Parth Mannan, Xiaowei Ren, Ryan Wolf, Niket Agarwal, Jacob Huffman, Zhuoyao Wang, Carl Wang, Jack Chang, Yan Bai, Tommy Huang, Linnan Wang, Sahil Jain, Shanmugam Ramasamy, Joseph Jennings, Ekaterina Sirazitdinova, Oleg Sudakov, Mingyuan Ma, Bobby Chen, Forrest Lin, Hao Wang, Vasanth Rao Naik Sabavat, Sriharsha Niverty, Rong Ou, Pallab Bhattacharya, David Page, Nima Tajbakhsh, Ashwath Aithal', 'link': 'https://arxiv.org/abs/2503.12964', 'abstract': 'Video Foundation Models (VFMs) have recently been used to simulate the real world to train physical AI systems and develop creative visual experiences. However, there are significant challenges in training large-scale, high quality VFMs that can generate high-quality videos. We present a scalable, open-source VFM training pipeline with NVIDIA NeMo, providing accelerated video dataset curation, multimodal data loading, and parallelized video diffusion model training and inference. We also provide a comprehensive performance analysis highlighting best practices for efficient VFM training and inference.', 'abstract_zh': '大规模高质量视频基础模型的可扩展开源训练管道：基于NVIDIA NeMo的技术与性能分析', 'title_zh': '使用NVIDIA NeMo训练视频基础模型'}
{'arxiv_id': 'arXiv:2503.12946', 'title': 'Open3DBench: Open-Source Benchmark for 3D-IC Backend Implementation and PPA Evaluation', 'authors': 'Yunqi Shi, Chengrui Gao, Wanqi Ren, Siyuan Xu, Ke Xue, Mingxuan Yuan, Chao Qian, Zhi-Hua Zhou', 'link': 'https://arxiv.org/abs/2503.12946', 'abstract': 'This work introduces Open3DBench, an open-source 3D-IC backend implementation benchmark built upon the OpenROAD-flow-scripts framework, enabling comprehensive evaluation of power, performance, area, and thermal metrics. Our proposed flow supports modular integration of 3D partitioning, placement, 3D routing, RC extraction, and thermal simulation, aligning with advanced 3D flows that rely on commercial tools and in-house scripts. We present two foundational 3D placement algorithms: Open3D-Tiling, which emphasizes regular macro placement, and Open3D-DMP, which enhances wirelength optimization through cross-die co-placement with analytical placer DREAMPlace. Experimental results show significant improvements in area (51.19%), wirelength (24.06%), timing (30.84%), and power (5.72%) compared to 2D flows. The results also highlight that better wirelength does not necessarily lead to PPA gain, emphasizing the need of developing PPA-driven methods. Open3DBench offers a standardized, reproducible platform for evaluating 3D EDA methods, effectively bridging the gap between open-source tools and commercial solutions in 3D-IC design.', 'abstract_zh': 'This work introduces Open3DBench，一个基于OpenROAD-flow-scripts框架的开源3D-IC后端实现基准，用于全面评估功耗、性能、面积和热特性指标。我们提出的流程支持3D切分、布局、3D布线、RC提取和热仿真等模块化集成，与依赖商用工具和内部脚本的先进3D流程相契合。我们提出了两种基础的3D布局算法：Open3D-Tiling，侧重于规则宏布局；Open3D-DMP，通过芯片间协同布局结合分析型布局器DREAMPlace优化布线长度。实验结果表明，与2D流程相比，在面积（51.19%）、布线长度（24.06%）、时序（30.84%）和功耗（5.72%）方面均取得了显著改善。结果还表明，更好的布线长度并不一定能带来PPA收益，突显了开发PPA驱动方法的必要性。Open3DBench提供了一个标准化、可重现的平台，用于评估3D EDA方法，有效填补了开源工具与商业解决方案在3D-IC设计中的差距。', 'title_zh': 'Open3DBench：用于3D-IC后端实现和PPA评估的开源基准测试'}
{'arxiv_id': 'arXiv:2503.12931', 'title': 'MirrorGuard: Adaptive Defense Against Jailbreaks via Entropy-Guided Mirror Crafting', 'authors': 'Rui Pu, Chaozhuo Li, Rui Ha, Litian Zhang, Lirong Qiu, Xi Zhang', 'link': 'https://arxiv.org/abs/2503.12931', 'abstract': "Defending large language models (LLMs) against jailbreak attacks is crucial for ensuring their safe deployment. Existing defense strategies generally rely on predefined static criteria to differentiate between harmful and benign prompts. However, such rigid rules are incapable of accommodating the inherent complexity and dynamic nature of real jailbreak attacks. In this paper, we propose a novel concept of ``mirror'' to enable dynamic and adaptive defense. A mirror refers to a dynamically generated prompt that mirrors the syntactic structure of the input while ensuring semantic safety. The personalized discrepancies between the input prompts and their corresponding mirrors serve as the guiding principles for defense. A new defense paradigm, MirrorGuard, is further proposed to detect and calibrate risky inputs based on such mirrors. An entropy-based detection metric, Relative Input Uncertainty (RIU), is integrated into MirrorGuard to quantify the discrepancies between input prompts and mirrors. MirrorGuard is evaluated on several popular datasets, demonstrating state-of-the-art defense performance while maintaining general effectiveness.", 'abstract_zh': '防御大语言模型（LLMs）免受Jailbreak攻击至关重要，以确保其安全部署。现有的防御策略通常依赖于预定义的静态标准来区分有害和无害的提示。然而，这样的僵化规则无法适应真实Jailbreak攻击的固有复杂性和动态性。本文提出了一种新的“镜像”概念，以实现动态和自适应的防御。镜像指的是一个动态生成的提示，它模仿输入的句法结构同时确保语义安全。个性化输入提示与其对应镜像之间的差异作为防御的指导原则。本文进一步提出了一种新的防御范式MirrorGuard，基于此类镜像来检测和校准潜在危险的输入。引入了一个基于熵的检测指标相对输入不确定性（RIU）来量化输入提示与镜像之间的差异。MirrorGuard在多个流行数据集上进行了评估，展示了领先的安全防御性能，同时保持了一般的有效性。', 'title_zh': 'MirrorGuard：基于熵导向的镜像 Crafting 以适应性防御越狱攻击'}
{'arxiv_id': 'arXiv:2503.12927', 'title': 'MMLNB: Multi-Modal Learning for Neuroblastoma Subtyping Classification Assisted with Textual Description Generation', 'authors': 'Huangwei Chen, Zhu Zhu, Zhenyu Yan, Yifei Chen, Mingyang Ding, Chenlei Li, Feiwei Qin', 'link': 'https://arxiv.org/abs/2503.12927', 'abstract': 'Neuroblastoma (NB), a leading cause of childhood cancer mortality, exhibits significant histopathological variability, necessitating precise subtyping for accurate prognosis and treatment. Traditional diagnostic methods rely on subjective evaluations that are time-consuming and inconsistent. To address these challenges, we introduce MMLNB, a multi-modal learning (MML) model that integrates pathological images with generated textual descriptions to improve classification accuracy and interpretability. The approach follows a two-stage process. First, we fine-tune a Vision-Language Model (VLM) to enhance pathology-aware text generation. Second, the fine-tuned VLM generates textual descriptions, using a dual-branch architecture to independently extract visual and textual features. These features are fused via Progressive Robust Multi-Modal Fusion (PRMF) Block for stable training. Experimental results show that the MMLNB model is more accurate than the single modal model. Ablation studies demonstrate the importance of multi-modal fusion, fine-tuning, and the PRMF mechanism. This research creates a scalable AI-driven framework for digital pathology, enhancing reliability and interpretability in NB subtyping classification. Our source code is available at this https URL.', 'abstract_zh': '神经母细胞瘤（NB），是儿童癌症死亡的主要原因，表现出显著的病理学变异，需要精确的亚型划分以获得准确的预后和治疗。传统的诊断方法依赖于主观评估，耗时且不一致。为了解决这些挑战，我们引入了MMLNB模型，这是一种多模态学习（MML）模型，将病理图像与生成的文本描述结合起来，以提高分类准确性和可解释性。该方法采用两阶段过程。首先，我们微调视觉-语言模型（VLM）以增强病理意识的文本生成。其次，微调后的VLM生成文本描述，采用双分支架构独立提取视觉和文本特征。这些特征通过渐进鲁棒多模态融合（PRMF）模块进行融合，以实现稳定训练。实验结果表明，MMLNB模型比单模态模型更准确。消融研究证明了多模态融合、微调和PRMF机制的重要性。这项研究构建了一个可扩展的基于AI的数字病理学框架，增强了NB亚型分类的可靠性和可解释性。我们的源代码可在以下网址获取：this https URL。', 'title_zh': 'MMLNB：多模态学习辅助文本描述生成的神经母细胞瘤亚型分类'}
{'arxiv_id': 'arXiv:2503.12908', 'title': 'HICD: Hallucination-Inducing via Attention Dispersion for Contrastive Decoding to Mitigate Hallucinations in Large Language Models', 'authors': 'Xinyan Jiang, Hang Ye, Yongxin Zhu, Xiaoying Zheng, Zikang Chen, Jun Gong', 'link': 'https://arxiv.org/abs/2503.12908', 'abstract': 'Large Language Models (LLMs) often generate hallucinations, producing outputs that are contextually inaccurate or factually incorrect. We introduce HICD, a novel method designed to induce hallucinations for contrastive decoding to mitigate hallucinations. Unlike existing contrastive decoding methods, HICD selects attention heads crucial to the model\'s prediction as inducing heads, then induces hallucinations by dispersing attention of these inducing heads and compares the hallucinated outputs with the original outputs to obtain the final result. Our approach significantly improves performance on tasks requiring contextual faithfulness, such as context completion, reading comprehension, and question answering. It also improves factuality in tasks requiring accurate knowledge recall. We demonstrate that our inducing heads selection and attention dispersion method leads to more "contrast-effective" hallucinations for contrastive decoding, outperforming other hallucination-inducing methods. Our findings provide a promising strategy for reducing hallucinations by inducing hallucinations in a controlled manner, enhancing the performance of LLMs in a wide range of tasks.', 'abstract_zh': '大型语言模型（LLMs）往往会产生幻觉，产出与上下文不符或事实错误的输出。我们提出HICD，一种新颖的方法，通过对比解码来减轻幻觉，该方法选择对模型预测至关重要的注意力头作为诱导头，然后通过分散这些诱导头的注意力来诱导幻觉，并将诱导出的输出与原始输出进行比较以获得最终结果。我们的方法在需要上下文忠实性的任务（如上下文填充、阅读理解和问答）中显著提高了性能，同时也提高了需要准确知识回忆的任务的事实性。我们证明，我们的诱导头选择和注意力分散方法能够产生更有“对比效果”的幻觉，优于其他幻觉诱导方法。我们的研究结果提供了一种有希望的策略，通过控制方式诱导幻觉来减少幻觉，从而在各种任务中增强语言模型的性能。', 'title_zh': 'HICD：通过注意力分散诱导 hallucination 的对比解码方法以减轻大型语言模型中的 hallucination'}
{'arxiv_id': 'arXiv:2503.12897', 'title': 'Federated Continual Instruction Tuning', 'authors': 'Haiyang Guo, Fanhu Zeng, Fei Zhu, Wenzhuo Liu, Da-Han Wang, Jian Xu, Xu-Yao Zhang, Cheng-Lin Liu', 'link': 'https://arxiv.org/abs/2503.12897', 'abstract': 'A vast amount of instruction tuning data is crucial for the impressive performance of Large Multimodal Models (LMMs), but the associated computational costs and data collection demands during supervised fine-tuning make it impractical for most researchers. Federated learning (FL) has the potential to leverage all distributed data and training resources to reduce the overhead of joint training. However, most existing methods assume a fixed number of tasks, while in real-world scenarios, clients continuously encounter new knowledge and often struggle to retain old tasks due to memory constraints. In this work, we introduce the Federated Continual Instruction Tuning (FCIT) benchmark to model this real-world challenge. Our benchmark includes two realistic scenarios, encompassing four different settings and twelve carefully curated instruction tuning datasets. To address the challenges posed by FCIT, we propose dynamic knowledge organization to effectively integrate updates from different tasks during training and subspace selective activation to allocate task-specific output during inference. Extensive experimental results demonstrate that our proposed method significantly enhances model performance across varying levels of data heterogeneity and catastrophic forgetting. Our source code and dataset will be made publicly available.', 'abstract_zh': '联邦持续指令调优（FCIT）基准', 'title_zh': '联邦连续指令调优'}
{'arxiv_id': 'arXiv:2503.12880', 'title': 'nvBench 2.0: A Benchmark for Natural Language to Visualization under Ambiguity', 'authors': 'Tianqi Luo, Chuhan Huang, Leixian Shen, Boyan Li, Shuyu Shen, Wei Zeng, Nan Tang, Yuyu Luo', 'link': 'https://arxiv.org/abs/2503.12880', 'abstract': 'Natural Language to Visualization (NL2VIS) enables users to create visualizations from natural language queries, making data insights more accessible. However, NL2VIS faces challenges in interpreting ambiguous queries, as users often express their visualization needs in imprecise language. To address this challenge, we introduce nvBench 2.0, a new benchmark designed to evaluate NL2VIS systems in scenarios involving ambiguous queries. nvBench 2.0 includes 7,878 natural language queries and 24,076 corresponding visualizations, derived from 780 tables across 153 domains. It is built using a controlled ambiguity-injection pipeline that generates ambiguous queries through a reverse-generation workflow. By starting with unambiguous seed visualizations and selectively injecting ambiguities, the pipeline yields multiple valid interpretations for each query, with each ambiguous query traceable to its corresponding visualization through step-wise reasoning paths. We evaluate various Large Language Models (LLMs) on their ability to perform ambiguous NL2VIS tasks using nvBench 2.0. We also propose Step-NL2VIS, an LLM-based model trained on nvBench 2.0, which enhances performance in ambiguous scenarios through step-wise preference optimization. Our results show that Step-NL2VIS outperforms all baselines, setting a new state-of-the-art for ambiguous NL2VIS tasks.', 'abstract_zh': '自然语言到可视化(NL2VIS)基准2.0：处理模糊查询的评估与优化', 'title_zh': 'nvBench 2.0: 一种处理歧义性的自然语言到可视化基准'}
{'arxiv_id': 'arXiv:2503.12855', 'title': 'VITED: Video Temporal Evidence Distillation', 'authors': 'Yujie Lu, Yale Song, William Wang, Lorenzo Torresani, Tushar Nagarajan', 'link': 'https://arxiv.org/abs/2503.12855', 'abstract': 'We investigate complex video question answering via chain-of-evidence reasoning -- identifying sequences of temporal spans from multiple relevant parts of the video, together with visual evidence within them. Existing models struggle with multi-step reasoning as they uniformly sample a fixed number of frames, which can miss critical evidence distributed nonuniformly throughout the video. Moreover, they lack the ability to temporally localize such evidence in the broader context of the full video, which is required for answering complex questions. We propose a framework to enhance existing VideoQA datasets with evidence reasoning chains, automatically constructed by searching for optimal intervals of interest in the video with supporting evidence, that maximizes the likelihood of answering a given question. We train our model (VITED) to generate these evidence chains directly, enabling it to both localize evidence windows as well as perform multi-step reasoning across them in long-form video content. We show the value of our evidence-distilled models on a suite of long video QA benchmarks where we outperform state-of-the-art approaches that lack evidence reasoning capabilities.', 'abstract_zh': '通过链式证据推理进行复杂视频问答：增强证据推理链条以实现多步推理和时空局部化', 'title_zh': 'VITED: 视频时间证据精炼'}
{'arxiv_id': 'arXiv:2503.12843', 'title': 'Towards Scalable Foundation Model for Multi-modal and Hyperspectral Geospatial Data', 'authors': 'Haozhe Si, Yuxuan Wan, Minh Do, Deepak Vasisht, Han Zhao, Hendrik F. Hamann', 'link': 'https://arxiv.org/abs/2503.12843', 'abstract': "Geospatial raster (imagery) data, such as that collected by satellite-based imaging systems at different times and spectral bands, hold immense potential for enabling a wide range of high-impact applications. This potential stems from the rich information that is spatially and temporally contextualized across multiple channels and sensing modalities. Recent work has adapted existing self-supervised learning approaches for such geospatial data. However, they fall short of scalable model architectures, leading to inflexibility and computational inefficiencies when faced with an increasing number of channels and modalities. To address these limitations, we introduce Low-rank Efficient Spatial-Spectral Vision Transformer (LESS ViT) with three key innovations: i) the LESS Attention Block that approximates high-dimensional spatial-spectral attention through Kronecker's product of the low-dimensional spatial and spectral attention components; ii) the Continuous Positional-Channel Embedding Layer that preserves both spatial and spectral continuity and physical characteristics of each patch; and iii) the Perception Field Mask that exploits local spatial dependencies by constraining attention to neighboring patches. To evaluate the proposed innovations, we construct a benchmark, GFM-Bench, which serves as a comprehensive benchmark for such geospatial raster data. We pretrain LESS ViT using a Hyperspectral Masked Autoencoder framework with integrated positional and channel masking strategies. Experimental results demonstrate that our proposed method surpasses current state-of-the-art multi-modal geospatial foundation models, achieving superior performance with less computation and fewer parameters. The flexibility and extensibility of our framework make it a promising direction for future geospatial data analysis tasks that involve a wide range of modalities and channels.", 'abstract_zh': '基于空间-光谱低秩高效的视变换器（LESS ViT）：面向多通道多模态地学栅格数据', 'title_zh': '面向多模态和超光谱地理空间数据的可扩展基础模型'}
{'arxiv_id': 'arXiv:2503.12836', 'title': 'CompMarkGS: Robust Watermarking for Compression 3D Gaussian Splatting', 'authors': 'Sumin In, Youngdong Jang, Utae Jeong, MinHyuk Jang, Hyeongcheol Park, Eunbyung Park, Sangpil Kim', 'link': 'https://arxiv.org/abs/2503.12836', 'abstract': '3D Gaussian Splatting (3DGS) enables rapid differentiable rendering for 3D reconstruction and novel view synthesis, leading to its widespread commercial use. Consequently, copyright protection via watermarking has become critical. However, because 3DGS relies on millions of Gaussians, which require gigabytes of storage, efficient transfer and storage require compression. Existing 3DGS watermarking methods are vulnerable to quantization-based compression, often resulting in the loss of the embedded watermark. To address this challenge, we propose a novel watermarking method that ensures watermark robustness after model compression while maintaining high rendering quality. In detail, we incorporate a quantization distortion layer that simulates compression during training, preserving the watermark under quantization-based compression. Also, we propose a learnable watermark embedding feature that embeds the watermark into the anchor feature, ensuring structural consistency and seamless integration into the 3D scene. Furthermore, we present a frequency-aware anchor growing mechanism to enhance image quality in high-frequency regions by effectively identifying Guassians within these regions. Experimental results confirm that our method preserves the watermark and maintains superior image quality under high compression, validating it as a promising approach for a secure 3DGS model.', 'abstract_zh': '基于3D高斯点的快速可微渲染及其水印保护方法', 'title_zh': 'CompMarkGS：鲁棒的压缩3D高斯散列水印技术'}
{'arxiv_id': 'arXiv:2503.12834', 'title': 'PASTA: Part-Aware Sketch-to-3D Shape Generation with Text-Aligned Prior', 'authors': 'Seunggwan Lee, Hwanhee Jung, Byoungsoo Koh, Qixing Huang, Sangho Yoon, Sangpil Kim', 'link': 'https://arxiv.org/abs/2503.12834', 'abstract': 'A fundamental challenge in conditional 3D shape generation is to minimize the information loss and maximize the intention of user input. Existing approaches have predominantly focused on two types of isolated conditional signals, i.e., user sketches and text descriptions, each of which does not offer flexible control of the generated shape. In this paper, we introduce PASTA, the flexible approach that seamlessly integrates a user sketch and a text description for 3D shape generation. The key idea is to use text embeddings from a vision-language model to enrich the semantic representation of sketches. Specifically, these text-derived priors specify the part components of the object, compensating for missing visual cues from ambiguous sketches. In addition, we introduce ISG-Net which employs two types of graph convolutional networks: IndivGCN, which processes fine-grained details, and PartGCN, which aggregates these details into parts and refines the structure of objects. Extensive experiments demonstrate that PASTA outperforms existing methods in part-level editing and achieves state-of-the-art results in sketch-to-3D shape generation.', 'abstract_zh': '条件3D形状生成中的根本挑战是最大程度地减少信息损失并最大化用户输入的意图。现有方法主要关注两种孤立的条件信号，即用户草图和文本描述，每种方法都无法灵活控制生成的形状。在本文中，我们提出了PASTA，这是一种灵活的方法，可以无缝地将用户草图和文本描述整合到3D形状生成中。核心思想是使用视觉-语言模型的文本嵌入来丰富草图的语义表示。具体而言，这些文本衍生的先验指定了对象的部分组件，弥补了模糊草图中缺失的视觉线索。此外，我们引入了ISG-Net，该网络采用了两种类型的图卷积网络：IndivGCN，用于处理细粒度细节；PartGCN，将这些细节聚合到部分中并细化对象结构。广泛实验表明，PASTA在部分级编辑方面优于现有方法，并在草图到3D形状生成方面取得了最先进的成果。', 'title_zh': 'PASTA：部分意识的文本对齐先验素描到3D形状生成'}
{'arxiv_id': 'arXiv:2503.12829', 'title': 'SparseLUT: Sparse Connectivity Optimization for Lookup Table-based Deep Neural Networks', 'authors': 'Binglei Lou, Ruilin Wu, Philip Leong', 'link': 'https://arxiv.org/abs/2503.12829', 'abstract': 'The deployment of deep neural networks (DNNs) on resource-constrained edge devices such as field-programmable gate arrays (FPGAs) requires a careful balance of latency, power, and resource usage while maintaining high accuracy. Existing Lookup Table (LUT)-based DNNs, including LogicNets, PolyLUT, PolyLUT-Add, and NeuraLUT, exploit native FPGA resources with random sparse connectivity. This paper introduces SparseLUT, a connectivity-centric training technique tailored for LUT-based DNNs. SparseLUT leverages a non-greedy training strategy that prioritizes the pruning of less significant connections and strategically regrows alternative ones, resulting in efficient convergence to the target sparsity. Experimental results show consistent accuracy improvements across benchmarks, including up to a 2.13\\% increase on MNIST and a 0.94\\% improvement for Jet Substructure Classification compared to random sparsity. This is done without any hardware overhead and achieves state-of-the-art results for LUT-based DNNs.', 'abstract_zh': '基于LUT的深度神经网络在受限资源边缘设备上的部署需要在延迟、功耗和资源使用之间寻求仔细平衡，同时保持高精度。现有的基于LUT的DNNs，包括LogicNets、PolyLUT、PolyLUT-Add和NeuraLUT，利用随机稀疏连接来利用FPGA的固有资源。本文介绍了SparseLUT，这是一种针对基于LUT的DNNs的以连接为中心的训练技术。SparseLUT利用一种非贪婪的训练策略，优先剪枝不重要的连接并战略性地重新生长替代连接，以实现高效的目标稀疏化收敛。实验结果表明，SparseLUT在多个基准测试中实现了一致的准确率提升，包括在MNIST上的2.13%提升和在Jet子结构分类上的0.94%提升，这都超过了随机稀疏化的效果，且不增加任何硬件开销，实现了基于LUT的DNNs的最佳结果。', 'title_zh': 'SparseLUT: 基于查找表的深度神经网络的稀疏连接优化'}
{'arxiv_id': 'arXiv:2503.12821', 'title': 'From Head to Tail: Towards Balanced Representation in Large Vision-Language Models through Adaptive Data Calibration', 'authors': 'Mingyang Song, Xiaoye Qu, Jiawei Zhou, Yu Cheng', 'link': 'https://arxiv.org/abs/2503.12821', 'abstract': 'Large Vision-Language Models (LVLMs) have achieved significant progress in combining visual comprehension with language generation. Despite this success, the training data of LVLMs still suffers from Long-Tail (LT) problems, where the data distribution is highly imbalanced. Previous works have mainly focused on traditional VLM architectures, i.e., CLIP or ViT, and specific tasks such as recognition and classification. Nevertheless, the exploration of LVLM (e.g. LLaVA) and more general tasks (e.g. Visual Question Answering and Visual Reasoning) remains under-explored. In this paper, we first conduct an in-depth analysis of the LT issues in LVLMs and identify two core causes: the overrepresentation of head concepts and the underrepresentation of tail concepts. Based on the above observation, we propose an $\\textbf{A}$daptive $\\textbf{D}$ata $\\textbf{R}$efinement Framework ($\\textbf{ADR}$), which consists of two stages: $\\textbf{D}$ata $\\textbf{R}$ebalancing ($\\textbf{DR}$) and $\\textbf{D}$ata $\\textbf{S}$ynthesis ($\\textbf{DS}$). In the DR stage, we adaptively rebalance the redundant data based on entity distributions, while in the DS stage, we leverage Denoising Diffusion Probabilistic Models (DDPMs) and scarce images to supplement underrepresented portions. Through comprehensive evaluations across eleven benchmarks, our proposed ADR effectively mitigates the long-tail problem in the training data, improving the average performance of LLaVA 1.5 relatively by 4.36%, without increasing the training data volume.', 'abstract_zh': 'Large 视觉-语言 模型中的长尾问题及自适应数据精炼框架（ADR）', 'title_zh': '从头到尾：通过自适应数据校准实现大型视觉-语言模型的平衡表示'}
{'arxiv_id': 'arXiv:2503.12814', 'title': 'Versatile Physics-based Character Control with Hybrid Latent Representation', 'authors': 'Jinseok Bae, Jungdam Won, Donggeun Lim, Inwoo Hwang, Young Min Kim', 'link': 'https://arxiv.org/abs/2503.12814', 'abstract': 'We present a versatile latent representation that enables physically simulated character to efficiently utilize motion priors. To build a powerful motion embedding that is shared across multiple tasks, the physics controller should employ rich latent space that is easily explored and capable of generating high-quality motion. We propose integrating continuous and discrete latent representations to build a versatile motion prior that can be adapted to a wide range of challenging control tasks. Specifically, we build a discrete latent model to capture distinctive posterior distribution without collapse, and simultaneously augment the sampled vector with the continuous residuals to generate high-quality, smooth motion without jittering. We further incorporate Residual Vector Quantization, which not only maximizes the capacity of the discrete motion prior, but also efficiently abstracts the action space during the task learning phase. We demonstrate that our agent can produce diverse yet smooth motions simply by traversing the learned motion prior through unconditional motion generation. Furthermore, our model robustly satisfies sparse goal conditions with highly expressive natural motions, including head-mounted device tracking and motion in-betweening at irregular intervals, which could not be achieved with existing latent representations.', 'abstract_zh': '我们提出了一种通用的潜在表示，使物理模拟角色能高效利用运动先验。为了构建一个强大的共享多任务的运动嵌入，物理控制器应使用一个易于探索且能生成高质量运动的丰富潜在空间。我们提出将连续和离散的潜在表示集成起来，构建一个通用的运动先验，该先验能够适应一系列具有挑战性的控制任务。具体而言，我们构建了一个离散潜在模型来捕捉独特的后验分布而不发生退化，并同时通过添加连续残差来增强采样向量，生成高质量且平滑的运动，而无闪烁现象。我们进一步引入了残差向量量化方法，不仅最大化了离散运动先验的能力，还在任务学习阶段高效地抽象了动作空间。我们证明，仅通过无条件运动生成来遍历学习到的运动先验，我们的代理就能产生多样且平滑的运动。此外，我们的模型能够稳健地满足稀疏目标条件，并生成具有高度表现力的自然运动，包括头戴设备跟踪和不规则间隔的运动插值，这是现有潜在表示无法实现的。', 'title_zh': '基于混合潜表示的多功能物理驱动角色控制'}
{'arxiv_id': 'arXiv:2503.12811', 'title': 'A Multi-Power Law for Loss Curve Prediction Across Learning Rate Schedules', 'authors': 'Kairong Luo, Haodong Wen, Shengding Hu, Zhenbo Sun, Zhiyuan Liu, Maosong Sun, Kaifeng Lyu, Wenguang Chen', 'link': 'https://arxiv.org/abs/2503.12811', 'abstract': 'Training large models is both resource-intensive and time-consuming, making it crucial to understand the quantitative relationship between model performance and hyperparameters. In this paper, we present an empirical law that describes how the pretraining loss of large language models evolves under different learning rate schedules, such as constant, cosine, and step decay schedules. Our proposed law takes a multi-power form, combining a power law based on the sum of learning rates and additional power laws to account for a loss reduction effect induced by learning rate decay. We extensively validate this law on various model sizes and architectures, and demonstrate that after fitting on a few learning rate schedules, the law accurately predicts the loss curves for unseen schedules of different shapes and horizons. Moreover, by minimizing the predicted final pretraining loss across learning rate schedules, we are able to find a schedule that outperforms the widely used cosine learning rate schedule. Interestingly, this automatically discovered schedule bears some resemblance to the recently proposed Warmup-Stable-Decay (WSD) schedule (Hu et al, 2024) but achieves a slightly lower final loss. We believe these results could offer valuable insights for understanding the dynamics of pretraining and designing learning rate schedules to improve efficiency.', 'abstract_zh': '大规模模型训练既资源密集又耗时，理解模型性能与超参数之间的量化关系至关重要。本文提出了一条经验定律，描述了在不同学习率调度（如恒定、余弦和阶梯衰减调度）下大规模语言模型预训练损失的变化规律。该定律采用多幂次形式，结合基于学习率总和的幂次定律和额外的幂次定律，以解释由学习率衰减引起的损失减少效应。我们在不同模型规模和架构上广泛验证了这条定律，并证明在拟合少量学习率调度后，该定律能够准确预测不同形状和持续时间的未见调度下的损失曲线。此外，通过最小化不同学习率调度下的预测最终预训练损失，我们找到了一种性能优于广泛使用的余弦学习率调度的调度方式。有趣的是，这种自动发现的调度方式与近期提出的一种温升稳定衰减（WSD）调度方式（Hu等人，2024）有些相似，但最终损失略低。我们认为这些结果为理解预训练动力学和设计提高效率的学习率调度提供了有价值的见解。', 'title_zh': '跨学习率调度的损失曲线预测多重幂律规律'}
{'arxiv_id': 'arXiv:2503.12797', 'title': 'DeepPerception: Advancing R1-like Cognitive Visual Perception in MLLMs for Knowledge-Intensive Visual Grounding', 'authors': 'Xinyu Ma, Ziyang Ding, Zhicong Luo, Chi Chen, Zonghao Guo, Derek F. Wong, Xiaoyi Feng, Maosong Sun', 'link': 'https://arxiv.org/abs/2503.12797', 'abstract': 'Human experts excel at fine-grained visual discrimination by leveraging domain knowledge to refine perceptual features, a capability that remains underdeveloped in current Multimodal Large Language Models (MLLMs). Despite possessing vast expert-level knowledge, MLLMs struggle to integrate reasoning into visual perception, often generating direct responses without deeper analysis. To bridge this gap, we introduce knowledge-intensive visual grounding (KVG), a novel visual grounding task that requires both fine-grained perception and domain-specific knowledge integration. To address the challenges of KVG, we propose DeepPerception, an MLLM enhanced with cognitive visual perception capabilities. Our approach consists of (1) an automated data synthesis pipeline that generates high-quality, knowledge-aligned training samples, and (2) a two-stage training framework combining supervised fine-tuning for cognitive reasoning scaffolding and reinforcement learning to optimize perception-cognition synergy. To benchmark performance, we introduce KVG-Bench a comprehensive dataset spanning 10 domains with 1.3K manually curated test cases. Experimental results demonstrate that DeepPerception significantly outperforms direct fine-tuning, achieving +8.08\\% accuracy improvements on KVG-Bench and exhibiting +4.60\\% superior cross-domain generalization over baseline approaches. Our findings highlight the importance of integrating cognitive processes into MLLMs for human-like visual perception and open new directions for multimodal reasoning research. The data, codes, and models are released at this https URL.', 'abstract_zh': '人类专家通过利用领域知识来细化视觉辨识能力，在目前的多模态大型语言模型（MLLMs）中这种能力仍较为不足。尽管具备大量专家级知识，MLLMs 在将推理融入视觉感知方面仍存在困难，常常直接生成回应而缺乏深入分析。为解决这一问题，我们提出认知密集型视觉接地（KVG），这是一种需要细粒度感知和领域特定知识集成的新视觉接地任务。为应对KVG的挑战，我们提出了一种增强的多模态大型语言模型DeepPerception，其包含（1）一个自动化数据合成管道，生成高质量、知识对齐的训练样本；（2）结合监督微调的认知推理框架和强化学习来优化感知-认知协同。为了评估性能，我们建立了KVG-Bench综合数据集，涵盖10个领域，包含1300个手动筛选的测试案例。实验结果表明，DeepPerception在KVG-Bench上的准确率提高了8.08%，且在跨域泛化方面优于基线方法4.60%。我们的研究结果强调了将认知过程集成到MLLMs中以实现人类相似的视觉感知的重要性，并为多模态推理研究开辟新方向。数据、代码和模型可在以下链接访问：this https URL。', 'title_zh': 'DeepPerception: 在MLLMs中推进类似R1的认知视觉感知以实现知识密集型视觉定位'}
{'arxiv_id': 'arXiv:2503.12790', 'title': 'Quantum-Enhanced LLM Efficient Fine Tuning', 'authors': 'Xiaofei Kong, Lei Li, Menghan Dou, Zhaoyun Chen, Yuchun Wu, Guoping Guo', 'link': 'https://arxiv.org/abs/2503.12790', 'abstract': 'Low-Rank Adaptation (LoRA) enables efficient fine-tuning of pre-trained language models via low-rank matrix approximation, which is effective in many scenarios. However, its low-rank representation capacity is constrained in complex tasks or high-rank dependency settings, potentially limiting model adaptability. Addressing the expressive bottleneck of classical low-rank approximation in fine-tuning large language models, this paper proposes a parameter-efficient fine-tuning method based on a Quantum Weighted Tensor Hybrid Network (QWTHN), which leverages Quantum Neural Network (QNN). The study investigates quantum-classical hybrid parameter-efficient fine-tuning in low-rank spaces. QWTHN decomposes pre-trained weights into quantum neural network and tensor network representations, utilizing quantum state superposition and other methods to break through classical rank limitations. Experiments show that the proposed quantum fine-tuning technique for large models approaches or even surpasses the parameter efficiency of LoRA. On the CPsyCounD and R1-Distill-SFT datasets, QWTHN, compared to classical LoRA, reduces training loss by up to 15% while using 76% fewer parameters, and achieves an 8.4% performance improvement on the CPsyCounD test set. This research not only realizes lightweight and efficient adaptation of quantum resources to billion-parameter models but also validates the practical path of quantum hardware driven by large model tasks, laying the first engineering-ready technical foundation for future quantum-enhanced AGI systems.', 'abstract_zh': '基于量子加权张量混合网络的参数高效大型语言模型细调方法', 'title_zh': '量子增强的大语言模型高效微调'}
{'arxiv_id': 'arXiv:2503.12781', 'title': 'SAM2 for Image and Video Segmentation: A Comprehensive Survey', 'authors': 'Zhang Jiaxing, Tang Hao', 'link': 'https://arxiv.org/abs/2503.12781', 'abstract': "Despite significant advances in deep learning for image and video segmentation, existing models continue to face challenges in cross-domain adaptability and generalization. Image and video segmentation are fundamental tasks in computer vision with wide-ranging applications in healthcare, agriculture, industrial inspection, and autonomous driving. With the advent of large-scale foundation models, SAM2 - an improved version of SAM (Segment Anything Model)has been optimized for segmentation tasks, demonstrating enhanced performance in complex scenarios. However, SAM2's adaptability and limitations in specific domains require further investigation. This paper systematically analyzes the application of SAM2 in image and video segmentation and evaluates its performance in various fields. We begin by introducing the foundational concepts of image segmentation, categorizing foundation models, and exploring the technical characteristics of SAM and SAM2. Subsequently, we delve into SAM2's applications in static image and video segmentation, emphasizing its performance in specialized areas such as medical imaging and the challenges of cross-domain adaptability. As part of our research, we reviewed over 200 related papers to provide a comprehensive analysis of the topic. Finally, the paper highlights the strengths and weaknesses of SAM2 in segmentation tasks, identifies the technical challenges it faces, and proposes future development directions. This review provides valuable insights and practical recommendations for optimizing and applying SAM2 in real-world scenarios.", 'abstract_zh': '尽管深度学习在图像和视频分割领域取得了显著进展，现有模型仍在跨域适应性和泛化能力方面面临挑战。图像和视频分割是计算机视觉中的基本任务，广泛应用于医疗、农业、工业检测和自动驾驶等领域。随着大规模基础模型的出现，SAM2作为一种改进的SAM（Segment Anything Model）版本，已被优化用于分割任务，并在复杂场景中展示了增强的性能。然而，SAM2在特定领域的适应性和局限性仍需进一步研究。本文系统分析了SAM2在图像和视频分割中的应用，并评估其在各个领域的表现。我们首先介绍了图像分割的基础概念，分类基础模型，并探讨了SAM和SAM2的技术特点。随后，我们深入探讨了SAM2在静态图像和视频分割中的应用，强调了其在医学成像等特定领域的性能以及跨域适应性的挑战。作为我们研究的一部分，我们回顾了超过200篇相关论文，提供了全面的分析。最后，本文指出了SAM2在分割任务中的优势和不足，识别了其面临的技术挑战，并提出了未来发展方向。这篇综述为优化和应用于实际场景中的SAM2提供了有价值的见解和实用建议。', 'title_zh': 'SAM2在图像与视频分割中的综合调研'}
{'arxiv_id': 'arXiv:2503.12780', 'title': 'LangDA: Building Context-Awareness via Language for Domain Adaptive Semantic Segmentation', 'authors': 'Chang Liu, Bavesh Balaji, Saad Hossain, C Thomas, Kwei-Herng Lai, Raviteja Vemulapalli, Alexander Wong, Sirisha Rambhatla', 'link': 'https://arxiv.org/abs/2503.12780', 'abstract': 'Unsupervised domain adaptation for semantic segmentation (DASS) aims to transfer knowledge from a label-rich source domain to a target domain with no labels. Two key approaches in DASS are (1) vision-only approaches using masking or multi-resolution crops, and (2) language-based approaches that use generic class-wise prompts informed by target domain (e.g. "a {snowy} photo of a {class}"). However, the former is susceptible to noisy pseudo-labels that are biased to the source domain. The latter does not fully capture the intricate spatial relationships of objects -- key for dense prediction tasks. To this end, we propose LangDA. LangDA addresses these challenges by, first, learning contextual relationships between objects via VLM-generated scene descriptions (e.g. "a pedestrian is on the sidewalk, and the street is lined with buildings."). Second, LangDA aligns the entire image features with text representation of this context-aware scene caption and learns generalized representations via text. With this, LangDA sets the new state-of-the-art across three DASS benchmarks, outperforming existing methods by 2.6%, 1.4% and 3.9%.', 'abstract_zh': '无监督域适应Semantic分割（DASS）旨在将标记丰富的源域知识转移到无标签的目标域。DASS中的两种关键方法包括（1）仅视觉方法，使用遮罩或多分辨率剪辑，以及（2）基于语言的方法，使用由目标域启发的一般类别标签提示（例如，“一张{雪景}的{类别}照片”）。然而，前者容易受到偏向源域的噪声伪标签的影响。后者未能完全捕捉到对象的复杂空间关系——这对于密集预测任务至关重要。为了解决这些问题，我们提出了LangDA。LangDA通过首先利用VLM生成的场景描述学习对象之间的上下文关系（例如，“一个行人走在人行道上，街道两旁是建筑物。”），来解决这些挑战。其次，LangDA将整个图像特征与基于此上下文场景描述的文字表示对齐，并通过文字学习通用表示。通过这种方式，LangDA在三个DASS基准测试中设定了新的最佳性能，分别优于现有方法2.6%、1.4%和3.9%。', 'title_zh': 'LangDA: 通过语言构建上下文感知能力的领域自适应语义分割'}
{'arxiv_id': 'arXiv:2503.12778', 'title': 'Adaptive Deep Learning for Multiclass Breast Cancer Classification via Misprediction Risk Analysis', 'authors': 'Gul Sheeraz, Qun Chen, Liu Feiyu, Zhou Fengjin MD', 'link': 'https://arxiv.org/abs/2503.12778', 'abstract': 'Breast cancer remains one of the leading causes of cancer-related deaths worldwide. Early detection is crucial for improving patient outcomes, yet the diagnostic process is often complex and prone to inconsistencies among pathologists. Computer-aided diagnostic approaches have significantly enhanced breast cancer detection, particularly in binary classification (benign vs. malignant). However, these methods face challenges in multiclass classification, leading to frequent mispredictions. In this work, we propose a novel adaptive learning approach for multiclass breast cancer classification using H&E-stained histopathology images. First, we introduce a misprediction risk analysis framework that quantifies and ranks the likelihood of an image being mislabeled by a classifier. This framework leverages an interpretable risk model that requires only a small number of labeled samples for training. Next, we present an adaptive learning strategy that fine-tunes classifiers based on the specific characteristics of a given dataset. This approach minimizes misprediction risk, allowing the classifier to adapt effectively to the target workload. We evaluate our proposed solutions on real benchmark datasets, demonstrating that our risk analysis framework more accurately identifies mispredictions compared to existing methods. Furthermore, our adaptive learning approach significantly improves the performance of state-of-the-art deep neural network classifiers.', 'abstract_zh': '乳腺癌仍然是全球癌症相关死亡的主要原因之一。早期检测对于改善患者预后至关重要，但诊断过程往往复杂且病理学家之间容易出现不一致。计算机辅助诊断方法在提高乳腺癌检测方面取得了显著进展，尤其是在二分类（良性 vs. 恶性）中。然而，这些方法在多分类中面临挑战，导致频繁的误预测。本工作中，我们提出了一种用于HE染色组织病理学图像的多分类乳腺癌分类新型自适应学习方法。首先，我们引入了一种误预测风险分析框架，该框架量化并排名图像被分类器误标的可能性。该框架利用一种可解释的风险模型，只需少量标注样本即可训练。接着，我们展示了一种自适应学习策略，根据给定数据集的特定特征微调分类器。该方法最小化误预测风险，使分类器能够有效适应目标负载。我们在实际基准数据集上评估了我们提出的解决方案，结果显示，我们的风险分析框架比现有方法更准确地识别误预测。此外，我们的自适应学习方法显著提高了最先进的深度神经网络分类器的性能。', 'title_zh': '基于误预测风险分析的多类乳腺癌适.adjusted 深度学习分类'}
{'arxiv_id': 'arXiv:2503.12772', 'title': 'NuPlanQA: A Large-Scale Dataset and Benchmark for Multi-View Driving Scene Understanding in Multi-Modal Large Language Models', 'authors': 'Sung-Yeon Park, Can Cui, Yunsheng Ma, Ahmadreza Moradipari, Rohit Gupta, Kyungtae Han, Ziran Wang', 'link': 'https://arxiv.org/abs/2503.12772', 'abstract': "Recent advances in multi-modal large language models (MLLMs) have demonstrated strong performance across various domains; however, their ability to comprehend driving scenes remains less proven. The complexity of driving scenarios, which includes multi-view information, poses significant challenges for existing MLLMs. In this paper, we introduce NuPlanQA-Eval, a multi-view, multi-modal evaluation benchmark for driving scene understanding. To further support generalization to multi-view driving scenarios, we also propose NuPlanQA-1M, a large-scale dataset comprising 1M real-world visual question-answering (VQA) pairs. For context-aware analysis of traffic scenes, we categorize our dataset into nine subtasks across three core skills: Road Environment Perception, Spatial Relations Recognition, and Ego-Centric Reasoning. Furthermore, we present BEV-LLM, integrating Bird's-Eye-View (BEV) features from multi-view images into MLLMs. Our evaluation results reveal key challenges that existing MLLMs face in driving scene-specific perception and spatial reasoning from ego-centric perspectives. In contrast, BEV-LLM demonstrates remarkable adaptability to this domain, outperforming other models in six of the nine subtasks. These findings highlight how BEV integration enhances multi-view MLLMs while also identifying key areas that require further refinement for effective adaptation to driving scenes. To facilitate further research, we publicly release NuPlanQA at this https URL.", 'abstract_zh': 'Recent advances in 多模态大型语言模型（MLLMs）在各种领域中展示了强大的性能；然而，它们理解驾驶场景的能力仍然不够证明。驾驶场景的复杂性，包括多视角信息，对现有MLLMs构成了重大挑战。本文介绍了NuPlanQA-Eval，一个用于驾驶场景理解的多视角多模态评估基准。为进一步支持多视角驾驶场景的泛化，我们还提出了包含100万真实世界视觉问答（VQA）对的大规模数据集NuPlanQA-1M。为了进行交通场景的上下文感知分析，我们将数据集按三项核心技能分为九个子任务：道路环境感知、空间关系识别和以自身为中心的推理。此外，我们提出了BEV-LLM，将多视角图像中的鸟瞰图（BEV）特征集成到MLLMs中。我们的评估结果显示，现有MLLMs在驾驶场景特定感知和以自身为中心的空间推理方面面临关键挑战。相比之下，BEV-LLM在九个子任务中的六个子任务中表现出色，展现了其在这一领域的显著适应性。这些发现突显了BEV集成如何增强多视角MLLMs，并指出了需要进一步完善的关键领域，以便更有效地适应驾驶场景。为促进进一步研究，我们在此公开发布了NuPlanQA。', 'title_zh': 'NuPlanQA：多视图驾驶场景理解的大规模数据集及基准测试'}
{'arxiv_id': 'arXiv:2503.12757', 'title': 'MAP: Multi-user Personalization with Collaborative LLM-powered Agents', 'authors': 'Christine Lee, Jihye Choi, Bilge Mutlu', 'link': 'https://arxiv.org/abs/2503.12757', 'abstract': "The widespread adoption of Large Language Models (LLMs) and LLM-powered agents in multi-user settings underscores the need for reliable, usable methods to accommodate diverse preferences and resolve conflicting directives. Drawing on conflict resolution theory, we introduce a user-centered workflow for multi-user personalization comprising three stages: Reflection, Analysis, and Feedback. We then present MAP -- a \\textbf{M}ulti-\\textbf{A}gent system for multi-user \\textbf{P}ersonalization -- to operationalize this workflow. By delegating subtasks to specialized agents, MAP (1) retrieves and reflects on relevant user information, while enhancing reliability through agent-to-agent interactions, (2) provides detailed analysis for improved transparency and usability, and (3) integrates user feedback to iteratively refine results. Our user study findings (n=12) highlight MAP's effectiveness and usability for conflict resolution while emphasizing the importance of user involvement in resolution verification and failure management. This work highlights the potential of multi-agent systems to implement user-centered, multi-user personalization workflows and concludes by offering insights for personalization in multi-user contexts.", 'abstract_zh': '大规模语言模型及其驱动代理在多用户环境中的广泛应用强调了需要可靠且易于使用的多用户个性化方法来满足多样化的需求并解决冲突指令。基于冲突解决理论，我们提出了一种以用户为中心的多用户个性化工作流，包含三个阶段：反思、分析和反馈。随后，我们介绍了MAP——一个多代理系统，用于实现这种工作流。通过将子任务委派给专门的代理，MAP（1）检索和反思相关用户信息，并通过代理间的交互提高可靠性；（2）提供详细的分析以增强透明度和易用性；（3）整合用户反馈以迭代优化结果。我们的用户研究结果（n=12）表明，MAP在冲突解决方面有效且易用，并强调了用户参与解决验证和故障管理的重要性。这项工作强调了多代理系统在实现用户为中心的多用户个性化工作流方面的潜力，并提出了一些在多用户情境下进行个性化设计的见解。', 'title_zh': 'MAP: 多用户个性化协作LLM代理'}
{'arxiv_id': 'arXiv:2503.12753', 'title': 'SafeSlice: Enabling SLA-Compliant O-RAN Slicing via Safe Deep Reinforcement Learning', 'authors': 'Ahmad M. Nagib, Hatem Abou-Zeid, Hossam S. Hassanein', 'link': 'https://arxiv.org/abs/2503.12753', 'abstract': "Deep reinforcement learning (DRL)-based slicing policies have shown significant success in simulated environments but face challenges in physical systems such as open radio access networks (O-RANs) due to simulation-to-reality gaps. These policies often lack safety guarantees to ensure compliance with service level agreements (SLAs), such as the strict latency requirements of immersive applications. As a result, a deployed DRL slicing agent may make resource allocation (RA) decisions that degrade system performance, particularly in previously unseen scenarios. Real-world immersive applications require maintaining SLA constraints throughout deployment to prevent risky DRL exploration. In this paper, we propose SafeSlice to address both the cumulative (trajectory-wise) and instantaneous (state-wise) latency constraints of O-RAN slices. We incorporate the cumulative constraints by designing a sigmoid-based risk-sensitive reward function that reflects the slices' latency requirements. Moreover, we build a supervised learning cost model as part of a safety layer that projects the slicing agent's RA actions to the nearest safe actions, fulfilling instantaneous constraints. We conduct an exhaustive experiment that supports multiple services, including real virtual reality (VR) gaming traffic, to investigate the performance of SafeSlice under extreme and changing deployment conditions. SafeSlice achieves reductions of up to 83.23% in average cumulative latency, 93.24% in instantaneous latency violations, and 22.13% in resource consumption compared to the baselines. The results also indicate SafeSlice's robustness to changing the threshold configurations of latency constraints, a vital deployment scenario that will be realized by the O-RAN paradigm to empower mobile network operators (MNOs).", 'abstract_zh': '基于深度 reinforcement 学习的SafeSlice策略：同时满足开放无线接入网络切片的累积和即时延迟约束', 'title_zh': 'SafeSlice: 通过安全深度强化学习实现合规SLA切片的O-RAN'}
{'arxiv_id': 'arXiv:2503.12739', 'title': "TNCSE: Tensor's Norm Constraints for Unsupervised Contrastive Learning of Sentence Embeddings", 'authors': 'Tianyu Zong, Bingkang Shi, Hongzhu Yi, Jungang Xu', 'link': 'https://arxiv.org/abs/2503.12739', 'abstract': "Unsupervised sentence embedding representation has become a hot research topic in natural language processing. As a tensor, sentence embedding has two critical properties: direction and norm. Existing works have been limited to constraining only the orientation of the samples' representations while ignoring the features of their module lengths. To address this issue, we propose a new training objective that optimizes the training of unsupervised contrastive learning by constraining the module length features between positive samples. We combine the training objective of Tensor's Norm Constraints with ensemble learning to propose a new Sentence Embedding representation framework, TNCSE. We evaluate seven semantic text similarity tasks, and the results show that TNCSE and derived models are the current state-of-the-art approach; in addition, we conduct extensive zero-shot evaluations, and the results show that TNCSE outperforms other baselines.", 'abstract_zh': '无监督句子嵌入表示已成为自然语言处理领域的研究热点。作为张量，句子嵌入具有两个关键属性：方向和范数。现有工作仅限于约束样本表示的方向特征，而忽略了其模长特征。为解决这一问题，我们提出了一种新的训练目标，通过约束正样本之间的模长特征来优化无监督对比学习的训练。我们结合张量范数约束的训练目标与集成学习，提出了一种新的句子嵌入表示框架TNCSE。我们在七个语义文本相似度任务上进行了评估，结果显示TNCSE及其衍生模型是当前最先进的方法；此外，我们还进行了广泛的零样本评估，结果显示TNCSE优于其他基线方法。', 'title_zh': 'TNCSE: 张量的范数约束无监督句子嵌入对比学习'}
{'arxiv_id': 'arXiv:2503.12730', 'title': 'TinySQL: A Progressive Text-to-SQL Dataset for Mechanistic Interpretability Research', 'authors': 'Philip Quirke, Clement Neo, Abir Harrasse, Dhruv Nathawani, Amir Abdullah', 'link': 'https://arxiv.org/abs/2503.12730', 'abstract': 'Mechanistic interpretability research faces a gap between analyzing simple circuits in toy tasks and discovering features in large models. To bridge this gap, we propose text-to-SQL generation as an ideal task to study, as it combines the formal structure of toy tasks with real-world complexity. We introduce TinySQL, a synthetic dataset progressing from basic to advanced SQL operations, and train models ranging from 33M to 1B parameters to establish a comprehensive testbed for interpretability. We apply multiple complementary interpretability techniques, including edge attribution patching and sparse autoencoders, to identify minimal circuits and components supporting SQL generation. Our analysis reveals both the potential and limitations of current interpretability methods, showing how circuits can vary even across similar queries. Lastly, we demonstrate how mechanistic interpretability can identify flawed heuristics in models and improve synthetic dataset design. Our work provides a comprehensive framework for evaluating and advancing interpretability techniques while establishing clear boundaries for their reliable application.', 'abstract_zh': '机制可解释性研究面临在玩具任务中分析简单电路与在大型模型中发现特征之间的差距。为了弥合这一差距，我们提出将文本生成SQL查询任务作为理想的测试任务，因为它结合了玩具任务的形式结构与现实世界的复杂性。我们引入了TinySQL，这是一个从基本到高级SQL操作的合成数据集，并训练了从33M到1B参数的模型，以建立一个全面的可解释性测试平台。我们应用多种互补的可解释性技术，包括边缘归因修补和稀疏自编码器，来识别支持SQL生成的最小电路和组件。我们的分析揭示了当前可解释性方法的潜力和局限性，展示了即使在相似查询之间电路也可能发生变化。最后，我们展示了机制可解释性如何识别模型中的错误启发式并改进合成数据集设计。我们的研究提供了一个全面的框架来评估和推进可解释性技术，并明确了其可靠应用的边界。', 'title_zh': 'TinySQL: 一种用于机理可解释性研究的渐进式文本到SQL数据集'}
{'arxiv_id': 'arXiv:2503.12688', 'title': 'Dynamic Angle Selection in X-Ray CT: A Reinforcement Learning Approach to Optimal Stopping', 'authors': 'Tianyuan Wang', 'link': 'https://arxiv.org/abs/2503.12688', 'abstract': 'In industrial X-ray Computed Tomography (CT), the need for rapid in-line inspection is critical. Sparse-angle tomography plays a significant role in this by reducing the required number of projections, thereby accelerating processing and conserving resources. Most existing methods aim to balance reconstruction quality and scanning time, typically relying on fixed scan durations. Adaptive adjustment of the number of angles is essential; for instance, more angles may be required for objects with complex geometries or noisier projections. The concept of optimal stopping, which dynamically adjusts this balance according to varying industrial needs, remains underutilized. Building on our previous work, we integrate optimal stopping into sequential Optimal Experimental Design (OED). We propose a novel method for computing the policy gradient within the Actor-Critic framework, enabling the development of adaptive policies for informative angle selection and scan termination. Additionally, we investigated the gap between simulation and real-world applications in the context of the developed learning-based method. Our trained model, developed using synthetic data, demonstrates reliable performance when applied to real-world data. This approach enhances the flexibility of CT operations and expands the applicability of sparse-angle tomography in industrial settings.', 'abstract_zh': '工业X射线计算机断层成像（CT）中的快速在线检测需求至关重要。稀疏角度断层成像通过对所需投影数量的减少，加快处理速度并节省资源，发挥了重要作用。现有的大多数方法旨在平衡重建质量和扫描时间，通常依赖固定的扫描时间。适应性调整角度的数量至关重要；例如，复杂几何结构的对象或噪声较大的投影需要更多角度。最优停止的概念，根据变化的工业需求动态调整这种平衡，尚未得到充分利用。基于我们之前的工作，我们将最优停止整合到顺序最优实验设计（OED）中。我们提出了一种在Actor-Critic框架下计算策略梯度的新方法，以开发适应性策略，实现信息性角度选择和扫描终止。此外，我们还探讨了所开发的基于学习的方法与仿真之间的差距。使用合成数据训练的模型在应用于实际数据时表现出可靠的性能。该方法增强了CT操作的灵活性，并扩大了稀疏角度断层成像在工业环境中的应用范围。', 'title_zh': 'X射线CT中动态角度选择：基于强化学习的最优停止方法'}
{'arxiv_id': 'arXiv:2503.12667', 'title': 'Plausibility Vaccine: Injecting LLM Knowledge for Event Plausibility', 'authors': 'Jacob Chmura, Jonah Dauvet, Sebastian Sabry', 'link': 'https://arxiv.org/abs/2503.12667', 'abstract': 'Despite advances in language modelling, distributional methods that build semantic representations from co-occurrences fail to discriminate between plausible and implausible events. In this work, we investigate how plausibility prediction can be improved by injecting latent knowledge prompted from large language models using parameter-efficient fine-tuning. We train 12 task adapters to learn various physical properties and association measures and perform adapter fusion to compose latent semantic knowledge from each task on top of pre-trained AlBERT embeddings. We automate auxiliary task data generation, which enables us to scale our approach and fine-tune our learned representations across two plausibility datasets. Our code is available at this https URL.', 'abstract_zh': '尽管在语言建模方面取得了进展，但基于共现构建语义表示的方法仍然无法区分可能事件和不可能事件。在此项工作中，我们研究了如何通过注入大型语言模型提示的潜在知识来提高可验证性预测性能，使用参数高效微调进行推进。我们训练了12个任务适配器来学习各种物理属性和关联度量，并通过适配器融合将每项任务中的潜在语义知识构建在预训练的AlBERT嵌入之上。我们自动化了辅助任务数据生成，从而使我们可以扩展我们的方法，并跨两个可验证性数据集微调我们学到的表示。我们的代码可在以下链接获取：this https URL。', 'title_zh': '拟合疫苗：注入大语言模型知识以提高事件可信度'}
{'arxiv_id': 'arXiv:2503.12649', 'title': 'FW-Merging: Scaling Model Merging with Frank-Wolfe Optimization', 'authors': 'Hao Mark Chen, Shell Xu Hu, Wayne Luk, Timothy Hospedales, Hongxiang Fan', 'link': 'https://arxiv.org/abs/2503.12649', 'abstract': 'Model merging has emerged as a promising approach for multi-task learning (MTL), offering a data-efficient alternative to conventional fine-tuning. However, with the rapid development of the open-source AI ecosystem and the increasing availability of fine-tuned foundation models, existing model merging methods face two key limitations: (i) They are primarily designed for in-house fine-tuned models, making them less adaptable to diverse model sources with partially unknown model and task information, (ii) They struggle to scale effectively when merging numerous model checkpoints. To address these challenges, we formulate model merging as a constrained optimization problem and introduce a novel approach: Frank-Wolfe Merging (FW-Merging). Inspired by Frank-Wolfe optimization, our approach iteratively selects the most relevant model in the pool to minimize a linear approximation of the objective function and then executes a local merging similar to the Frank-Wolfe update. The objective function is designed to capture the desired behavior of the target-merged model, while the fine-tuned candidate models define the constraint set. More importantly, FW-Merging serves as an orthogonal technique for existing merging methods, seamlessly integrating with them to further enhance accuracy performance. Our experiments show that FW-Merging scales across diverse model sources, remaining stable with 16 irrelevant models and improving by 15.3% with 16 relevant models on 20 CV tasks, while maintaining constant memory overhead, unlike the linear overhead of data-informed merging methods. Compared with the state-of-the-art approaches, FW-Merging surpasses the data-free merging method by 32.8% and outperforms the data-informed Adamerging by 8.39% when merging 20 ViT models.', 'abstract_zh': '模型融合已成为多任务学习（MTL）的一种有前景的方法，提供了一种与常规微调相比更为数据高效的替代方案。然而，随着开源AI生态系统的快速发展和微调基础模型的日益可用，现有的模型融合方法面临两个关键局限：（i）它们主要针对内部微调模型设计，使得它们对来源多样且部分模型和任务信息未知的模型不太适应；（ii）它们在融合大量模型检查点时难以有效扩展。为了解决这些挑战，我们将模型融合形式化为一个受约束的优化问题，并引入一种新颖的方法：Frank-Wolfe融合（FW-Merging）。受Frank-Wolfe优化启发，我们的方法迭代选择池中最相关的模型以最小化目标函数的线性逼近，并执行类似于Frank-Wolfe更新的局部融合。目标函数设计用于捕获目标融合模型所需的特性，而微调候选模型定义约束集。更重要的是，FW-Merging 是现有融合方法的一种补充技术，可以无缝集成到它们之中以进一步提升准确度性能。实验结果表明，FW-Merging 在多种模型来源上可扩展，即使在有 16 个无关模型的情况下保持稳定，并且在 16 个相关模型下在 20 个CV任务上性能提升了15.3%，同时保持恒定的内存开销，不同于数据导向融合方法的线性内存开销。与最先进的方法相比，当融合 20 个 ViT 模型时，FW-Merging 超过了无数据融合方法 32.8%，并在数据导向的Adamerging 上表现优于后者 8.39%。', 'title_zh': 'FW-融合：基于Frank-Wolfe优化的模型融合'}
{'arxiv_id': 'arXiv:2503.12642', 'title': 'COVID 19 Diagnosis Analysis using Transfer Learning', 'authors': 'Anjali Dharmik', 'link': 'https://arxiv.org/abs/2503.12642', 'abstract': "Coronaviruses transmit COVID-19, a rapidly spreading disease. A Coronavirus infection (COVID-19) was first discovered in December 2019 in Wuhan, China, and spread rapidly throughout the planet in exactly some months. because of this, the virus can cause severe symptoms and even death, especially within the elderly and in people with medical conditions. The virus causes acute respiratory infections in humans. the primary case was diagnosed in China in 2019 and the pandemic started in 2020. Since the quantity of cases of COVID-19 is increasing daily, there are only a limited number of test kits available in hospitals. So, to stop COVID-19 from spreading among people, an automatic diagnosis system must be implemented. during this study, three pre-trained neural networks supported convolutional neural networks (VGG16, VGG19, ResNet50) are proposed for detecting Coronavirus pneumonia infected patients through X-rays and computerized tomography (CT). By using cross-validation, we've got implemented binary classifications with two classes (COVID-19, Normal (healthy)). Taking into consideration the results obtained, the pre-trained ResNet50 model provides the simplest classification performance (97.77% accuracy, 100% sensitivity, 93.33% specificity, 98.00% F1-score) among the opposite three used models over 6259 images.", 'abstract_zh': '冠状病毒传播COVID-19，一种迅速传播的疾病', 'title_zh': 'COVID-19 诊断分析使用迁移学习'}
{'arxiv_id': 'arXiv:2503.12635', 'title': 'Hybrid Learners Do Not Forget: A Brain-Inspired Neuro-Symbolic Approach to Continual Learning', 'authors': 'Amin Banayeeanzade, Mohammad Rostami', 'link': 'https://arxiv.org/abs/2503.12635', 'abstract': 'Continual learning is crucial for creating AI agents that can learn and improve themselves autonomously. A primary challenge in continual learning is to learn new tasks without losing previously learned knowledge. Current continual learning methods primarily focus on enabling a neural network with mechanisms that mitigate forgetting effects. Inspired by the two distinct systems in the human brain, System 1 and System 2, we propose a Neuro-Symbolic Brain-Inspired Continual Learning (NeSyBiCL) framework that incorporates two subsystems to solve continual learning: A neural network model responsible for quickly adapting to the most recent task, together with a symbolic reasoner responsible for retaining previously acquired knowledge from previous tasks. Moreover, we design an integration mechanism between these components to facilitate knowledge transfer from the symbolic reasoner to the neural network. We also introduce two compositional continual learning benchmarks and demonstrate that NeSyBiCL is effective and leads to superior performance compared to continual learning methods that merely rely on neural architectures to address forgetting.', 'abstract_zh': '持续学习对于创建能够自主学习和改进的AI代理至关重要。持续学习的主要挑战之一是在学习新任务时不丢失先前学习的知识。目前的持续学习方法主要侧重于通过机制减轻遗忘效应来增强神经网络。受人类大脑中两个不同系统——系统1和系统2——的启发，我们提出了一种神经符号脑启发式持续学习（NeSyBiCL）框架，该框架包含两个子系统来解决持续学习问题：一个负责快速适应最近任务的神经网络模型，以及一个负责保留先前任务中获得的知识的符号推理器。此外，我们设计了一种这些组件之间的集成机制，以促进符号推理器向神经网络的知识迁移。我们还引入了两个组合式持续学习基准，并证明NeSyBiCL是有效的，并且在仅仅依赖神经架构解决遗忘问题的持续学习方法中表现更优。', 'title_zh': '混合学习者不会遗忘：一种受脑启发的神经符号连续学习方法'}
{'arxiv_id': 'arXiv:2503.12623', 'title': 'MAVEN: Multi-modal Attention for Valence-Arousal Emotion Network', 'authors': 'Vrushank Ahire, Kunal Shah, Mudasir Nazir Khan, Nikhil Pakhale, Lownish Rai Sookha, M. A. Ganaie, Abhinav Dhall', 'link': 'https://arxiv.org/abs/2503.12623', 'abstract': "This paper introduces MAVEN (Multi-modal Attention for Valence-Arousal Emotion Network), a novel architecture for dynamic emotion recognition through dimensional modeling of affect. The model uniquely integrates visual, audio, and textual modalities via a bi-directional cross-modal attention mechanism with six distinct attention pathways, enabling comprehensive interactions between all modality pairs. Our proposed approach employs modality-specific encoders to extract rich feature representations from synchronized video frames, audio segments, and transcripts. The architecture's novelty lies in its cross-modal enhancement strategy, where each modality representation is refined through weighted attention from other modalities, followed by self-attention refinement through modality-specific encoders. Rather than directly predicting valence-arousal values, MAVEN predicts emotions in a polar coordinate form, aligning with psychological models of the emotion circumplex. Experimental evaluation on the Aff-Wild2 dataset demonstrates the effectiveness of our approach, with performance measured using Concordance Correlation Coefficient (CCC). The multi-stage architecture demonstrates superior ability to capture the complex, nuanced nature of emotional expressions in conversational videos, advancing the state-of-the-art (SOTA) in continuous emotion recognition in-the-wild. Code can be found at: this https URL.", 'abstract_zh': 'MAVEN（多模态注意力情感网络）：通过维度建模的情感动态识别新架构', 'title_zh': 'MAVEN: 多模态注意力情感网络'}
{'arxiv_id': 'arXiv:2503.12617', 'title': 'Scaling Semantic Categories: Investigating the Impact on Vision Transformer Labeling Performance', 'authors': 'Anthony Lamelas, Harrison Muchnic', 'link': 'https://arxiv.org/abs/2503.12617', 'abstract': "This study explores the impact of scaling semantic categories on the image classification performance of vision transformers (ViTs). In this specific case, the CLIP server provided by Jina AI is used for experimentation. The research hypothesizes that as the number of ground truth and artificially introduced semantically equivalent categories increases, the labeling accuracy of ViTs improves until a theoretical maximum or limit is reached. A wide variety of image datasets were chosen to test this hypothesis. These datasets were processed through a custom function in Python designed to evaluate the model's accuracy, with adjustments being made to account for format differences between datasets. By exponentially introducing new redundant categories, the experiment assessed accuracy trends until they plateaued, decreased, or fluctuated inconsistently. The findings show that while semantic scaling initially increases model performance, the benefits diminish or reverse after surpassing a critical threshold, providing insight into the limitations and possible optimization of category labeling strategies for ViTs.", 'abstract_zh': '本研究探讨了扩大语义类别对视觉变换器（ViTs）图像分类性能的影响。具体而言，使用Jina AI提供的CLIP服务器进行实验。研究假设随着真实和人工引入的语义等价类别数量的增加，ViTs的标签准确性会提高，直至达到理论上的最大值或上限。多种图像数据集被选择以测试这一假设。这些数据集经过自定义的Python函数处理，以评估模型的准确性，并对不同数据集的格式差异进行了调整。通过指数引入新的冗余类别，实验评估了准确性趋势，直到它们趋于平稳、下降或波动不一致。研究发现，尽管语义扩展初期提高了模型性能，但在超过某一临界阈值后，其益处会减弱或逆转，为ViTs的类别标记策略的局限性和潜在优化提供了见解。', 'title_zh': '扩展语义类别：探究对视觉变换器标签性能的影响'}
{'arxiv_id': 'arXiv:2503.12613', 'title': 'Negotiative Alignment: Embracing Disagreement to Achieve Fairer Outcomes -- Insights from Urban Studies', 'authors': 'Rashid Mushkani, Hugo Berard, Shin Koseki', 'link': 'https://arxiv.org/abs/2503.12613', 'abstract': 'Cities are not monolithic; they are arenas of negotiation among groups that hold varying needs, values, and experiences. Conventional methods of urban assessment -- from standardized surveys to AI-driven evaluations -- frequently rely on a single consensus metric (e.g., an average measure of inclusivity or safety). Although such aggregations simplify design decisions, they risk obscuring the distinct perspectives of marginalized populations. In this paper, we present findings from a community-centered study in Montreal involving 35 residents with diverse demographic and social identities, particularly wheelchair users, seniors, and LGBTQIA2+ individuals. Using rating and ranking tasks on 20 urban sites, we observe that disagreements are systematic rather than random, reflecting structural inequalities, differing cultural values, and personal experiences of safety and accessibility.\nBased on these empirical insights, we propose negotiative alignment, an AI framework that treats disagreement as an essential input to be preserved, analyzed, and addressed. Negotiative alignment builds on pluralistic models by dynamically updating stakeholder preferences through multi-agent negotiation mechanisms, ensuring no single perspective is marginalized. We outline how this framework can be integrated into urban analytics -- and other decision-making contexts -- to retain minority viewpoints, adapt to changing stakeholder concerns, and enhance fairness and accountability. The study demonstrates that preserving and engaging with disagreement, rather than striving for an artificial consensus, can produce more equitable and responsive AI-driven outcomes in urban design.', 'abstract_zh': '城市并非同质；它们是不同群体协商的舞台，这些群体有不同的需求、价值观和经历。传统的城市评估方法——从标准化调查到基于AI的评估——通常依赖单一的共识指标（如包容性或安全性的平均值）。虽然这些聚合简化了设计决策，但可能会掩盖边缘化群体的独特视角。在本文中，我们呈现了在蒙特利尔进行的一项以社区为中心的研究成果，涉及35名具有多元人口和社会身份的居民，特别是轮椅使用者、老年人和LGBTQIA2+人群。通过针对20个城市场地进行评级和排序任务，我们观察到，分歧是有系统性的而非随机的，反映了结构不平等、不同的文化价值观以及个人的安全感和可访问性经验。\n\n基于这些实证洞见，我们提出了协商对齐这一AI框架，该框架视分歧为必不可少的输入，需被保留、分析和解决。协商对齐建立在多元主义模型的基础上，通过多智能体协商机制动态更新利益相关者偏好，确保不会边缘化任何一种视角。我们概述了该框架如何可以集成到城市分析以及其他决策场景中，以保留少数群体的观点，适应变化的利益相关者关注点，并增强公平性和问责制。研究表明，保留并参与分歧，而不是追求人为的一致性，可以在城市设计中产生更加公平和具有响应性的AI驱动成果。', 'title_zh': '协商一致：拥抱分歧以达成更加公平的结果——从城市研究中获得的启示'}
{'arxiv_id': 'arXiv:2503.12595', 'title': 'Point Cloud Based Scene Segmentation: A Survey', 'authors': 'Dan Halperin, Niklas Eisl', 'link': 'https://arxiv.org/abs/2503.12595', 'abstract': 'Autonomous driving is a safety-critical application, and it is therefore a top priority that the accompanying assistance systems are able to provide precise information about the surrounding environment of the vehicle. Tasks such as 3D Object Detection deliver an insufficiently detailed understanding of the surrounding scene because they only predict a bounding box for foreground objects. In contrast, 3D Semantic Segmentation provides richer and denser information about the environment by assigning a label to each individual point, which is of paramount importance for autonomous driving tasks, such as navigation or lane changes. To inspire future research, in this review paper, we provide a comprehensive overview of the current state-of-the-art methods in the field of Point Cloud Semantic Segmentation for autonomous driving. We categorize the approaches into projection-based, 3D-based and hybrid methods. Moreover, we discuss the most important and commonly used datasets for this task and also emphasize the importance of synthetic data to support research when real-world data is limited. We further present the results of the different methods and compare them with respect to their segmentation accuracy and efficiency.', 'abstract_zh': '自主驾驶是一种安全关键型应用，因此，伴随的辅助系统必须能够提供关于车辆周围环境的精确信息。与3D物体检测相比，3D语义分割通过为每个独立点分配标签，提供了更加丰富和密集的环境信息，这对于自动驾驶任务如导航或换道至关重要。为了激励未来的研究，在这篇综述性论文中，我们提供了点云语义分割领域当前先进技术的全面概述。我们将方法分为投影型、3D型和混合型。此外，我们讨论了该任务中最重要的常用数据集，并强调在现实数据有限时，合成数据的重要性。我们进一步展示了不同方法的结果，并从分割准确性和效率的角度进行了比较。', 'title_zh': '基于点云的场景分割：一个综述'}
{'arxiv_id': 'arXiv:2503.12593', 'title': 'Fourier-Based 3D Multistage Transformer for Aberration Correction in Multicellular Specimens', 'authors': 'Thayer Alshaabi, Daniel E. Milkie, Gaoxiang Liu, Cyna Shirazinejad, Jason L. Hong, Kemal Achour, Frederik Görlitz, Ana Milunovic-Jevtic, Cat Simmons, Ibrahim S. Abuzahriyeh, Erin Hong, Samara Erin Williams, Nathanael Harrison, Evan Huang, Eun Seok Bae, Alison N. Killilea, David G. Drubin, Ian A. Swinburne, Srigokul Upadhyayula, Eric Betzig', 'link': 'https://arxiv.org/abs/2503.12593', 'abstract': 'High-resolution tissue imaging is often compromised by sample-induced optical aberrations that degrade resolution and contrast. While wavefront sensor-based adaptive optics (AO) can measure these aberrations, such hardware solutions are typically complex, expensive to implement, and slow when serially mapping spatially varying aberrations across large fields of view. Here, we introduce AOViFT (Adaptive Optical Vision Fourier Transformer) -- a machine learning-based aberration sensing framework built around a 3D multistage Vision Transformer that operates on Fourier domain embeddings. AOViFT infers aberrations and restores diffraction-limited performance in puncta-labeled specimens with substantially reduced computational cost, training time, and memory footprint compared to conventional architectures or real-space networks. We validated AOViFT on live gene-edited zebrafish embryos, demonstrating its ability to correct spatially varying aberrations using either a deformable mirror or post-acquisition deconvolution. By eliminating the need for the guide star and wavefront sensing hardware and simplifying the experimental workflow, AOViFT lowers technical barriers for high-resolution volumetric microscopy across diverse biological samples.', 'abstract_zh': '基于自适应光学视觉傅里叶变换的高分辨率组织成像', 'title_zh': '基于傅里叶变换的三维多阶段变压器在多细胞标本 aberration 矫正中的应用'}
{'arxiv_id': 'arXiv:2503.12592', 'title': 'MoECollab: Democratizing LLM Development Through Collaborative Mixture of Experts', 'authors': 'Harshit', 'link': 'https://arxiv.org/abs/2503.12592', 'abstract': 'Large Language Model (LLM) development has become increasingly centralized, limiting participation to well-resourced organizations. This paper introduces MoECollab, a novel framework leveraging Mixture of Experts (MoE) architecture to enable distributed, collaborative LLM development. By decomposing monolithic models into specialized expert modules coordinated by a trainable gating network, our framework allows diverse contributors to participate regardless of computational resources. We provide a complete technical implementation with mathematical foundations for expert dynamics, gating mechanisms, and integration strategies. Experiments on multiple datasets demonstrate that our approach achieves accuracy improvements of 3-7% over baseline models while reducing computational requirements by 34%. Expert specialization yields significant domain-specific gains, with improvements from 51% to 88% F1 score in general classification and from 23% to 44% accuracy in news categorization. We formalize the routing entropy optimization problem and demonstrate how proper regularization techniques lead to 14% higher expert utilization rates. These results validate MoECollab as an effective approach for democratizing LLM development through architecturally-supported collaboration.', 'abstract_zh': 'MoECollab：利用专家混合架构支持分布式协作的大语言模型开发', 'title_zh': 'MoECollab: 通过专家混合协作 democratize LLM 开发'}
{'arxiv_id': 'arXiv:2503.12575', 'title': 'BalancedDPO: Adaptive Multi-Metric Alignment', 'authors': 'Dipesh Tamboli, Souradip Chakraborty, Aditya Malusare, Biplab Banerjee, Amrit Singh Bedi, Vaneet Aggarwal', 'link': 'https://arxiv.org/abs/2503.12575', 'abstract': 'Text-to-image (T2I) diffusion models have made remarkable advancements, yet aligning them with diverse preferences remains a persistent challenge. Current methods often optimize single metrics or depend on narrowly curated datasets, leading to overfitting and limited generalization across key visual quality metrics. We present BalancedDPO, a novel extension of Direct Preference Optimization (DPO) that addresses these limitations by simultaneously aligning T2I diffusion models with multiple metrics, including human preference, CLIP score, and aesthetic quality. Our key novelty lies in aggregating consensus labels from diverse metrics in the preference distribution space as compared to existing reward mixing approaches, enabling robust and scalable multi-metric alignment while maintaining the simplicity of the standard DPO pipeline that we refer to as BalancedDPO. Our evaluations on the Pick-a-Pic, PartiPrompt and HPD datasets show that BalancedDPO achieves state-of-the-art results, outperforming existing approaches across all major metrics. BalancedDPO improves the average win rates by 15%, 7.1%, and 10.3% on Pick-a-pic, PartiPrompt and HPD, respectively, from the DiffusionDPO.', 'abstract_zh': 'Text-to-image (T2I) 演化模型取得了显著进步，但与多样化的偏好对齐仍然是一项持续的挑战。现有方法往往优化单一指标或依赖于狭隘定制的数据集，导致在关键视觉质量指标上的过拟合和有限泛化能力。我们提出了一种名为 BalancedDPO 的 Direct Preference Optimization (DPO) 的新型扩展方法，通过同时与多个指标对齐 T2I 演化模型，包括人类偏好、CLIP 分数和美学质量，来解决这些限制。我们的主要创新之处在于在偏好分布空间中汇总来自多种指标的共识标签，相比于现有的奖励混合方法，这使得多指标对齐更加稳健和可扩展，同时保持标准 DPO 管道的简单性，我们称之为 BalancedDPO。我们在 Pick-a-Pic、PartiPrompt 和 HPD 数据集上的评估显示，BalancedDPO 达到了最先进的效果，在所有主要指标上均优于现有方法。与 DiffusionDPO 相比，BalancedDPO 分别在 Pick-a-Pic、PartiPrompt 和 HPD 上的平均胜率提高了 15%、7.1% 和 10.3%。', 'title_zh': 'BalancedDPO: 自适应多指标对齐'}
{'arxiv_id': 'arXiv:2503.12572', 'title': 'Deblur Gaussian Splatting SLAM', 'authors': 'Francesco Girlanda, Denys Rozumnyi, Marc Pollefeys, Martin R. Oswald', 'link': 'https://arxiv.org/abs/2503.12572', 'abstract': 'We present Deblur-SLAM, a robust RGB SLAM pipeline designed to recover sharp reconstructions from motion-blurred inputs. The proposed method bridges the strengths of both frame-to-frame and frame-to-model approaches to model sub-frame camera trajectories that lead to high-fidelity reconstructions in motion-blurred settings. Moreover, our pipeline incorporates techniques such as online loop closure and global bundle adjustment to achieve a dense and precise global trajectory. We model the physical image formation process of motion-blurred images and minimize the error between the observed blurry images and rendered blurry images obtained by averaging sharp virtual sub-frame images. Additionally, by utilizing a monocular depth estimator alongside the online deformation of Gaussians, we ensure precise mapping and enhanced image deblurring. The proposed SLAM pipeline integrates all these components to improve the results. We achieve state-of-the-art results for sharp map estimation and sub-frame trajectory recovery both on synthetic and real-world blurry input data.', 'abstract_zh': '我们提出Deblur-SLAM，一种用于从运动模糊输入中恢复清晰重构的鲁棒RGB SLAM管道。该提出的方法结合了帧到帧和帧到模型方法的优点，用于建模亚帧相机轨迹，以在运动模糊场景中实现高保真重构。此外，我们的管道 Incorporates 技术如在线环闭合和全局束调整，以实现密集和精确的全局轨迹。我们建模了运动模糊图像的物理成像过程，并最小化了观测模糊图像与通过平均清晰虚拟亚帧图像获得的渲染模糊图像之间的误差。此外，通过利用单目深度估计器与高斯的在线变形，我们确保精确的映射和增强的图像去模糊。提出的SLAM管道将所有这些组件集成起来以提高结果。我们在这项工作中不仅在合成的，而且在真实的模糊输入数据中达到最先进的结果，用于清晰地图估计和亚帧轨迹恢复。', 'title_zh': '去模糊高斯体素SLAM'}
{'arxiv_id': 'arXiv:2503.12556', 'title': 'From Guessing to Asking: An Approach to Resolving the Persona Knowledge Gap in LLMs during Multi-Turn Conversations', 'authors': 'Sarvesh Baskar, Tanmay Tulsidas Verelakar, Srinivasan Parthasarathy, Manas Gaur', 'link': 'https://arxiv.org/abs/2503.12556', 'abstract': "In multi-turn dialogues, large language models (LLM) face a critical challenge of ensuring coherence while adapting to user-specific information. This study introduces the persona knowledge gap, the discrepancy between a model's internal understanding and the knowledge required for coherent, personalized conversations. While prior research has recognized these gaps, computational methods for their identification and resolution remain underexplored. We propose Conversation Preference Elicitation and Recommendation (CPER), a novel framework that dynamically detects and resolves persona knowledge gaps using intrinsic uncertainty quantification and feedback-driven refinement. CPER consists of three key modules: a Contextual Understanding Module for preference extraction, a Dynamic Feedback Module for measuring uncertainty and refining persona alignment, and a Persona-Driven Response Generation module for adapting responses based on accumulated user context. We evaluate CPER on two real-world datasets: CCPE-M for preferential movie recommendations and ESConv for mental health support. Using A/B testing, human evaluators preferred CPER's responses 42% more often than baseline models in CCPE-M and 27% more often in ESConv. A qualitative human evaluation confirms that CPER's responses are preferred for maintaining contextual relevance and coherence, particularly in longer (12+ turn) conversations.", 'abstract_zh': '在多轮对话中，大型语言模型（LLM）面临确保连贯性并适应用户特定信息的关键挑战。本研究引入了 Persona 知识缺口的概念，即模型内部理解与其进行连贯和个性化对话所需知识之间的 discrepancy。虽然先前的研究已经认识到了这些缺口，但对其识别和解决的计算方法仍较少探索。我们提出了一种名为 Conversation Preference Elicitation and Recommendation (CPER) 的新型框架，该框架能够动态检测并解决 Persona 知识缺口，通过内在不确定性量化和反馈驱动的优化来实现。CPER 包含三个关键模块：上下文理解模块进行偏好提取、动态反馈模块衡量不确定性并精炼 Persona 对齐、以及基于累积用户上下文生成 Persona 驱动的响应模块。我们在两个真实世界数据集中评估了 CPER：CCPE-M 用于偏好电影推荐，ESConv 用于心理健康支持。A/B 测试结果显示，在 CCPE-M 中，人类评估者更偏好 CPER 的响应，偏好率为 42%，而在 ESConv 中，偏好率为 27%。定性的人类评估进一步证实了 CPER 的响应更适合保持上下文相关性和连贯性，尤其是在较长（12 轮及以上）的对话中。', 'title_zh': '从猜测到提问：在多轮对话中解决LLMs个性知识缺口的方法'}
{'arxiv_id': 'arXiv:2503.12549', 'title': 'Grasping Partially Occluded Objects Using Autoencoder-Based Point Cloud Inpainting', 'authors': 'Alexander Koebler, Ralf Gross, Florian Buettner, Ingo Thon', 'link': 'https://arxiv.org/abs/2503.12549', 'abstract': "Flexible industrial production systems will play a central role in the future of manufacturing due to higher product individualization and customization. A key component in such systems is the robotic grasping of known or unknown objects in random positions. Real-world applications often come with challenges that might not be considered in grasping solutions tested in simulation or lab settings. Partial occlusion of the target object is the most prominent. Examples of occlusion can be supporting structures in the camera's field of view, sensor imprecision, or parts occluding each other due to the production process. In all these cases, the resulting lack of information leads to shortcomings in calculating grasping points. In this paper, we present an algorithm to reconstruct the missing information. Our inpainting solution facilitates the real-world utilization of robust object matching approaches for grasping point calculation. We demonstrate the benefit of our solution by enabling an existing grasping system embedded in a real-world industrial application to handle occlusions in the input. With our solution, we drastically decrease the number of objects discarded by the process.", 'abstract_zh': '柔性的工业生产系统将在未来的制造业中发挥核心作用，由于产品个性化和定制化程度提高。此类系统的关键组件是在随机位置抓取已知或未知物体的机器人抓取技术。真实世界的应用常常伴随着在模拟或实验室环境中测试的抓取解决方案中未考虑的挑战。目标物体的部分遮挡是最突出的问题。遮挡可以是由相机视野中的支持结构、传感器精度不足或生产过程中相互遮挡的部件引起。在所有这些情况下，由于缺乏信息而导致的不足会影响抓取点的计算。本文提出了一种算法来恢复缺失的信息。我们的 inpainting 解决方案促进了鲁棒对象匹配方法在抓取点计算中在真实世界中的应用。我们通过使嵌入真实工业应用的现有抓取系统能够处理输入中的遮挡，展示了我们解决方案的优势。通过我们的解决方案，我们大大减少了被过程抛弃的物体的数量。', 'title_zh': '基于自编码器的点云修复用于遮挡物体的抓取'}
{'arxiv_id': 'arXiv:2503.12532', 'title': 'STEVE: AStep Verification Pipeline for Computer-use Agent Training', 'authors': 'Fanbin Lu, Zhisheng Zhong, Ziqin Wei, Shu Liu, Chi-Wing Fu, Jiaya Jia', 'link': 'https://arxiv.org/abs/2503.12532', 'abstract': 'Developing AI agents to autonomously manipulate graphical user interfaces is a long challenging task. Recent advances in data scaling law inspire us to train computer-use agents with a scaled instruction set, yet using behavior cloning to train agents still requires immense high-quality trajectories. To meet the scalability need, we designed STEVE, a step verification pipeline for computer-use agent training. First, we establish a large instruction set for computer-use agents and collect trajectory data with some suboptimal agents. GPT-4o is used to verify the correctness of each step in the trajectories based on the screens before and after the action execution, assigning each step with a binary label. Last, we adopt the Kahneman and Tversky Optimization to optimize the agent from the binary stepwise labels. Extensive experiments manifest that our agent outperforms supervised finetuning by leveraging both positive and negative actions within a trajectory. Also, STEVE enables us to train a 7B vision-language model as a computer-use agent, achieving leading performance in the challenging live desktop environment WinAgentArena with great efficiency at a reduced cost. Code and data: this https URL.', 'abstract_zh': '开发自主操作图形用户界面的AI代理是一个长期具有挑战性的任务。 recent advances in data scaling law启发我们使用缩放后的指令集训练计算机使用代理，然而，使用行为克隆训练代理仍然需要大量的高质量轨迹数据。为了满足扩展性需求，我们设计了STEVE，一个计算机使用代理训练的步骤验证流程。首先，我们为计算机使用代理建立了一个大型指令集，并使用一些亚最优代理收集轨迹数据。GPT-4o基于动作执行前后屏幕的情况验证轨迹中每个步骤的正确性，并为每个步骤分配一个二元标签。最后，我们采用了Kahneman和Tversky优化方法从二元步骤标签优化代理。大量实验表明，通过利用轨迹中正负动作，我们的代理在监督微调中表现出色。此外，STEVE使我们能够训练一个7B的视觉-语言模型作为计算机使用代理，在具有挑战性的实时桌面环境WinAgentArena中取得了领先性能，并且在效率和成本方面表现出色。代码和数据：this https URL。', 'title_zh': 'STEVE: 计算机使用代理训练的步骤验证流水线'}
{'arxiv_id': 'arXiv:2503.12525', 'title': 'HyConEx: Hypernetwork classifier with counterfactual explanations', 'authors': 'Patryk Marszałek, Ulvi Movsum-zada, Oleksii Furman, Kamil Książek, Przemysław Spurek, Marek Śmieja', 'link': 'https://arxiv.org/abs/2503.12525', 'abstract': "In recent years, there has been a growing interest in explainable AI methods. We want not only to make accurate predictions using sophisticated neural networks but also to understand what the model's decision is based on. One of the fundamental levels of interpretability is to provide counterfactual examples explaining the rationale behind the decision and identifying which features, and to what extent, must be modified to alter the model's outcome. To address these requirements, we introduce HyConEx, a classification model based on deep hypernetworks specifically designed for tabular data. Owing to its unique architecture, HyConEx not only provides class predictions but also delivers local interpretations for individual data samples in the form of counterfactual examples that steer a given sample toward an alternative class. While many explainable methods generated counterfactuals for external models, there have been no interpretable classifiers simultaneously producing counterfactual samples so far. HyConEx achieves competitive performance on several metrics assessing classification accuracy and fulfilling the criteria of a proper counterfactual attack. This makes HyConEx a distinctive deep learning model, which combines predictions and explainers as an all-in-one neural network. The code is available at this https URL.", 'abstract_zh': '近年来，解释性人工智能方法越来越受到关注。我们不仅希望通过复杂的神经网络进行准确的预测，还想理解模型决策背后的依据。解释性的根本层面之一是提供反事实示例，解释决策的理由，并确定哪些特征需要到何种程度的修改以改变模型的结果。为了满足这些要求，我们引入了基于深度超网络的HyConEx分类模型，该模型专门设计用于表格数据。得益于其独特的架构，HyConEx不仅可以提供类别预测，还能以反事实示例的形式为单个数据样本提供局部解释，引导一个样本向另一个类别变化。虽然许多可解释的方法为外部模型生成了反事实，但目前还没有同时产生可解释分类器和反事实样本的方法。HyConEx在几项评估分类准确性的指标上表现竞争力，并满足适当的反事实攻击标准。这使HyConEx成为一种独特的深度学习模型，将预测和解释器结合在一个神经网络中。代码可在以下链接获取。', 'title_zh': 'HyConEx: 基于反事实解释的超网络分类器'}
{'arxiv_id': 'arXiv:2503.12524', 'title': 'EXAONE Deep: Reasoning Enhanced Language Models', 'authors': 'LG AI Research, Kyunghoon Bae, Eunbi Choi, Kibong Choi, Stanley Jungkyu Choi, Yemuk Choi, Seokhee Hong, Junwon Hwang, Hyojin Jeon, Kijeong Jeon, Gerrard Jeongwon Jo, Hyunjik Jo, Jiyeon Jung, Hyosang Kim, Joonkee Kim, Seonghwan Kim, Soyeon Kim, Sunkyoung Kim, Yireun Kim, Yongil Kim, Youchul Kim, Edward Hwayoung Lee, Haeju Lee, Honglak Lee, Jinsik Lee, Kyungmin Lee, Sangha Park, Yongmin Park, Sihoon Yang, Heuiyeen Yeen, Sihyuk Yi, Hyeongu Yun', 'link': 'https://arxiv.org/abs/2503.12524', 'abstract': 'We present EXAONE Deep series, which exhibits superior capabilities in various reasoning tasks, including math and coding benchmarks. We train our models mainly on the reasoning-specialized dataset that incorporates long streams of thought processes. Evaluation results show that our smaller models, EXAONE Deep 2.4B and 7.8B, outperform other models of comparable size, while the largest model, EXAONE Deep 32B, demonstrates competitive performance against leading open-weight models. All EXAONE Deep models are openly available for research purposes and can be downloaded from this https URL', 'abstract_zh': 'EXAONE Deep系列：在各种推理任务，包括数学和编码基准测试中展现出卓越能力', 'title_zh': 'EXAONE Deep:  reasoning Enhanced Language Models'}
{'arxiv_id': 'arXiv:2503.12511', 'title': 'LLM-Driven Multi-step Translation from C to Rust using Static Analysis', 'authors': 'Tianyang Zhou, Haowen Lin, Somesh Jha, Mihai Christodorescu, Kirill Levchenko, Varun Chandrasekaran', 'link': 'https://arxiv.org/abs/2503.12511', 'abstract': 'Translating software written in legacy languages to modern languages, such as C to Rust, has significant benefits in improving memory safety while maintaining high performance. However, manual translation is cumbersome, error-prone, and produces unidiomatic code. Large language models (LLMs) have demonstrated promise in producing idiomatic translations, but offer no correctness guarantees as they lack the ability to capture all the semantics differences between the source and target languages. To resolve this issue, we propose SACTOR, an LLM-driven C-to-Rust zero-shot translation tool using a two-step translation methodology: an "unidiomatic" step to translate C into Rust while preserving semantics, and an "idiomatic" step to refine the code to follow Rust\'s semantic standards. SACTOR utilizes information provided by static analysis of the source C program to address challenges such as pointer semantics and dependency resolution. To validate the correctness of the translated result from each step, we use end-to-end testing via the foreign function interface to embed our translated code segment into the original code. We evaluate the translation of 200 programs from two datasets and two case studies, comparing the performance of GPT-4o, Claude 3.5 Sonnet, Gemini 2.0 Flash, Llama 3.3 70B and DeepSeek-R1 in SACTOR. Our results demonstrate that SACTOR achieves high correctness and improved idiomaticity, with the best-performing model (DeepSeek-R1) reaching 93% and (GPT-4o, Claude 3.5, DeepSeek-R1) reaching 84% correctness (on each dataset, respectively), while producing more natural and Rust-compliant translations compared to existing methods.', 'abstract_zh': '使用大型语言模型驱动的C到Rust零-shot翻译工具SACTOR：两步翻译方法及其应用', 'title_zh': '基于LLM的从C到Rust的多步翻译及静态分析驱动方法'}
{'arxiv_id': 'arXiv:2503.12509', 'title': 'A Reservoir-based Model for Human-like Perception of Complex Rhythm Pattern', 'authors': 'Zhongju Yuan, Geraint Wiggins, Dick Botteldooren', 'link': 'https://arxiv.org/abs/2503.12509', 'abstract': 'Rhythm is a fundamental aspect of human behaviour, present from infancy and deeply embedded in cultural practices. Rhythm anticipation is a spontaneous cognitive process that typically occurs before the onset of actual beats. While most research in both neuroscience and artificial intelligence has focused on metronome-based rhythm tasks, studies investigating the perception of complex musical rhythm patterns remain limited. To address this gap, we propose a hierarchical oscillator-based model to better understand the perception of complex musical rhythms in biological systems. The model consists of two types of coupled neurons that generate oscillations, with different layers tuned to respond to distinct perception levels. We evaluate the model using several representative rhythm patterns spanning the upper, middle, and lower bounds of human musical perception. Our findings demonstrate that, while maintaining a high degree of synchronization accuracy, the model exhibits human-like rhythmic behaviours. Additionally, the beta band neuronal activity in the model mirrors patterns observed in the human brain, further validating the biological plausibility of the approach.', 'abstract_zh': '节奏是人类行为的基本方面，存在于婴儿期并深深植根于文化实践中。节奏预测是一种自发的认知过程，通常发生在实际节拍出现之前。虽然在神经科学和人工智能领域的大多数研究都集中在基于节拍器的节奏任务上，但关于复杂音乐节奏模式感知的研究依然有限。为弥补这一不足，我们提出了一种基于分层振荡器的模型，以更好地理解生物系统中复杂音乐节奏的感知。该模型包含两种类型的耦合神经元，能够生成不同层的振荡，每层神经元对特定感知水平作出响应。我们使用跨越人类音乐感知上下限的多个代表性节奏模式来评估该模型。研究结果显示，该模型在保持高度同步准确性的同时，表现出类似人类的节奏行为。此外，模型中的β波神经元活动模式与人类大脑中观察到的模式相似，进一步验证了该方法的生物可行性。', 'title_zh': '基于水库模型的人类复杂节奏模式感知模型'}
{'arxiv_id': 'arXiv:2503.12506', 'title': 'A General Close-loop Predictive Coding Framework for Auditory Working Memory', 'authors': 'Zhongju Yuan, Geraint Wiggins, Dick Botteldooren', 'link': 'https://arxiv.org/abs/2503.12506', 'abstract': 'Auditory working memory is essential for various daily activities, such as language acquisition, conversation. It involves the temporary storage and manipulation of information that is no longer present in the environment. While extensively studied in neuroscience and cognitive science, research on its modeling within neural networks remains limited. To address this gap, we propose a general framework based on a close-loop predictive coding paradigm to perform short auditory signal memory tasks. The framework is evaluated on two widely used benchmark datasets for environmental sound and speech, demonstrating high semantic similarity across both datasets.', 'abstract_zh': '听觉工作记忆对于语言获取和对话等日常活动至关重要，它涉及对不再存在于环境中的信息进行临时存储和操作。尽管在神经科学和认知科学中已经对其进行了广泛研究，但其在神经网络中的建模研究仍然有限。为填补这一空白，我们提出了一种基于闭环预测编码范式的通用框架，用于执行短时听觉信号记忆任务。该框架在两个广泛使用的环境声音和语音基准数据集上进行评估，显示出高语义相似性。', 'title_zh': '一种闭-loop预测编码框架：听觉工作记忆'}
{'arxiv_id': 'arXiv:2503.12499', 'title': 'Facilitating Automated Online Consensus Building through Parallel Thinking', 'authors': 'Wen Gu, Zhaoxing Li, Jan Buermann, Jim Dilkes, Dimitris Michailidis, Shinobu Hasegawa, Vahid Yazdanpanah, Sebastian Stein', 'link': 'https://arxiv.org/abs/2503.12499', 'abstract': "Consensus building is inherently challenging due to the diverse opinions held by stakeholders. Effective facilitation is crucial to support the consensus building process and enable efficient group decision making. However, the effectiveness of facilitation is often constrained by human factors such as limited experience and scalability. In this research, we propose a Parallel Thinking-based Facilitation Agent (PTFA) that facilitates online, text-based consensus building processes. The PTFA automatically collects textual posts and leverages large language models (LLMs) to perform all of the six distinct roles of the well-established Six Thinking Hats technique in parallel thinking. To illustrate the potential of PTFA, a pilot study was carried out and PTFA's ability in idea generation, emotional probing, and deeper analysis of ideas was demonstrated. Furthermore, a comprehensive dataset that contains not only the conversational content among the participants but also between the participants and the agent is constructed for future study.", 'abstract_zh': '基于并行思考的协同构建代理（PTFA）：促进在线文本协同构建过程', 'title_zh': '促进并行思考以实现自动化在线共识构建'}
{'arxiv_id': 'arXiv:2503.12497', 'title': 'Defense Against Model Stealing Based on Account-Aware Distribution Discrepancy', 'authors': 'Jian-Ping Mei, Weibin Zhang, Jie Chen, Xuyun Zhang, Tiantian Zhu', 'link': 'https://arxiv.org/abs/2503.12497', 'abstract': 'Malicious users attempt to replicate commercial models functionally at low cost by training a clone model with query responses. It is challenging to timely prevent such model-stealing attacks to achieve strong protection and maintain utility. In this paper, we propose a novel non-parametric detector called Account-aware Distribution Discrepancy (ADD) to recognize queries from malicious users by leveraging account-wise local dependency. We formulate each class as a Multivariate Normal distribution (MVN) in the feature space and measure the malicious score as the sum of weighted class-wise distribution discrepancy. The ADD detector is combined with random-based prediction poisoning to yield a plug-and-play defense module named D-ADD for image classification models. Results of extensive experimental studies show that D-ADD achieves strong defense against different types of attacks with little interference in serving benign users for both soft and hard-label settings.', 'abstract_zh': '恶意用户试图通过训练克隆模型来低成本复制商业模型的功能，利用查询响应进行模型盗取。及时防止此类模型盗窃攻击以实现强有力保护并保持实用性是具有挑战性的。本文提出了一种名为Account-aware Distribution Discrepancy (ADD)的新型非参数检测器，通过利用账户级别的局部依赖性来识别恶意用户的查询。我们将每个类别在特征空间中形式化为多元正态分布（MVN），并通过加权类别分布差异来衡量恶意评分。将ADD检测器与基于随机的预测污染结合，形成一个插即用的防御模块D-ADD，用于图像分类模型。广泛的实验研究结果表明，D-ADD在软标签和硬标签设置下都能有效地防御不同类型攻击，同时对良性用户的使用干扰很小。', 'title_zh': '基于账户意识的分布差异防御模型窃取'}
{'arxiv_id': 'arXiv:2503.12490', 'title': 'GeoRSMLLM: A Multimodal Large Language Model for Vision-Language Tasks in Geoscience and Remote Sensing', 'authors': 'Zilun Zhang, Haozhan Shen, Tiancheng Zhao, Bin Chen, Zian Guan, Yuhao Wang, Xu Jia, Yuxiang Cai, Yongheng Shang, Jianwei Yin', 'link': 'https://arxiv.org/abs/2503.12490', 'abstract': 'The application of Vision-Language Models (VLMs) in remote sensing (RS) has demonstrated significant potential in traditional tasks such as scene classification, object detection, and image captioning. However, current models, which excel in Referring Expression Comprehension (REC), struggle with tasks involving complex instructions (e.g., exists multiple conditions) or pixel-level operations like segmentation and change detection. In this white paper, we provide a comprehensive hierarchical summary of vision-language tasks in RS, categorized by the varying levels of cognitive capability required. We introduce the Remote Sensing Vision-Language Task Set (RSVLTS), which includes Open-Vocabulary Tasks (OVT), Referring Expression Tasks (RET), and Described Object Tasks (DOT) with increased difficulty, and Visual Question Answering (VQA) aloneside. Moreover, we propose a novel unified data representation using a set-of-points approach for RSVLTS, along with a condition parser and a self-augmentation strategy based on cyclic referring. These features are integrated into the GeoRSMLLM model, and this enhanced model is designed to handle a broad range of tasks of RSVLTS, paving the way for a more generalized solution for vision-language tasks in geoscience and remote sensing.', 'abstract_zh': '视觉-语言模型（VLMs）在遥感（RS）中的应用在传统任务如场景分类、物体检测和图像描述中展现了显著的潜力。然而，当前在引用表达理解（REC）方面表现优异的模型，在涉及复杂指令（例如，多个条件）或像素级操作（如分割和变化检测）的任务中表现不佳。在本白皮书中，我们提供了按认知能力水平分类的遥感视觉-语言任务的综合分层总结。我们介绍了一套遥感视觉-语言任务集（RSVLTS），包括开放式词汇任务（OVT）、引用表达任务（RET）、描述对象任务（DOT）以及逐步增加难度的视觉问答（VQA）。此外，我们提出了一种新颖的统一数据表示方法，采用点集方法，结合条件解析器和基于循环引用的自我增强策略，这些特征集成到了GeoRSMLLM模型中。该增强模型旨在处理RSVLTS的广泛任务，为地球科学和遥感中的视觉-语言任务提供更通用的解决方案。', 'title_zh': 'GeoRSMLLM：地球科学与遥感领域的多模态大型语言模型'}
{'arxiv_id': 'arXiv:2503.12484', 'title': 'SING: Semantic Image Communications using Null-Space and INN-Guided Diffusion Models', 'authors': 'Jiakang Chen, Selim F. Yilmaz, Di You, Pier Luigi Dragotti, Deniz Gündüz', 'link': 'https://arxiv.org/abs/2503.12484', 'abstract': 'Joint source-channel coding systems based on deep neural networks (DeepJSCC) have recently demonstrated remarkable performance in wireless image transmission. Existing methods primarily focus on minimizing distortion between the transmitted image and the reconstructed version at the receiver, often overlooking perceptual quality. This can lead to severe perceptual degradation when transmitting images under extreme conditions, such as low bandwidth compression ratios (BCRs) and low signal-to-noise ratios (SNRs). In this work, we propose SING, a novel two-stage JSCC framework that formulates the recovery of high-quality source images from corrupted reconstructions as an inverse problem. Depending on the availability of information about the DeepJSCC encoder/decoder and the channel at the receiver, SING can either approximate the stochastic degradation as a linear transformation, or leverage invertible neural networks (INNs) for precise modeling. Both approaches enable the seamless integration of diffusion models into the reconstruction process, enhancing perceptual quality. Experimental results demonstrate that SING outperforms DeepJSCC and other approaches, delivering superior perceptual quality even under extremely challenging conditions, including scenarios with significant distribution mismatches between the training and test data.', 'abstract_zh': '基于深度神经网络的联合源信道编码系统（DeepJSCC）在无线图像传输中 recently demonstrated remarkable performance.现有的方法主要侧重于最小化传输图像和接收端重构版本之间的失真，往往忽视了感知质量。这可能导致在极端条件下（如低带宽压缩比和低信噪比）传输图像时感知质量严重下降。在本文中，我们提出了一种新颖的两阶段JSCC框架SING，将从受污染的重构中恢复高质量源图像的问题转化为逆问题。依据接收端关于DeepJSCC编码器/解码器及信道信息的可用性，SING可以将随机退化近似为线性变换，或者利用可逆神经网络（INNs）进行精确建模。这两种方法都使扩散模型能够无缝集成到恢复过程中，从而提高感知质量。实验结果表明，SING在包括训练数据和测试数据分布具有显著差异的极端条件下，优于DeepJSCC和其他方法，提供了更优的感知质量。', 'title_zh': 'SING: 基于 null-space 和 INN 引导扩散模型的_semantic_图像通信'}
{'arxiv_id': 'arXiv:2503.12478', 'title': 'KDSelector: A Knowledge-Enhanced and Data-Efficient Model Selector Learning Framework for Time Series Anomaly Detection', 'authors': 'Zhiyu Liang, Dongrui Cai, Chenyuan Zhang, Zheng Liang, Chen Liang, Bo Zheng, Shi Qiu, Jin Wang, Hongzhi Wang', 'link': 'https://arxiv.org/abs/2503.12478', 'abstract': 'Model selection has been raised as an essential problem in the area of time series anomaly detection (TSAD), because there is no single best TSAD model for the highly heterogeneous time series in real-world applications. However, despite the success of existing model selection solutions that train a classification model (especially neural network, NN) using historical data as a selector to predict the correct TSAD model for each series, the NN-based selector learning methods used by existing solutions do not make full use of the knowledge in the historical data and require iterating over all training samples, which limits the accuracy and training speed of the selector. To address these limitations, we propose KDSelector, a novel knowledge-enhanced and data-efficient framework for learning the NN-based TSAD model selector, of which three key components are specifically designed to integrate available knowledge into the selector and dynamically prune less important and redundant samples during the learning. We develop a TSAD model selection system with KDSelector as the internal, to demonstrate how users improve the accuracy and training speed of their selectors by using KDSelector as a plug-and-play module. Our demonstration video is hosted at this https URL.', 'abstract_zh': '基于知识增强和数据高效方法的NN时间序列异常检测模型选择器框架：KDSelector', 'title_zh': 'KDSelector：一种增强知识和数据高效的时间序列异常检测模型选择学习框架'}
{'arxiv_id': 'arXiv:2503.12451', 'title': 'ISLR101: an Iranian Word-Level Sign Language Recognition Dataset', 'authors': 'Hossein Ranjbar, Alireza Taheri', 'link': 'https://arxiv.org/abs/2503.12451', 'abstract': 'Sign language recognition involves modeling complex multichannel information, such as hand shapes and movements while relying on sufficient sign language-specific data. However, sign languages are often under-resourced, posing a significant challenge for research and development in this field. To address this gap, we introduce ISLR101, the first publicly available Iranian Sign Language dataset for isolated sign language recognition. This comprehensive dataset includes 4,614 videos covering 101 distinct signs, recorded by 10 different signers (3 deaf individuals, 2 sign language interpreters, and 5 L2 learners) against varied backgrounds, with a resolution of 800x600 pixels and a frame rate of 25 frames per second. It also includes skeleton pose information extracted using OpenPose. We establish both a visual appearance-based and a skeleton-based framework as baseline models, thoroughly training and evaluating them on ISLR101. These models achieve 97.01% and 94.02% accuracy on the test set, respectively. Additionally, we publish the train, validation, and test splits to facilitate fair comparisons.', 'abstract_zh': '伊朗手语识别涉及建模复杂的多通道信息，如手形和手势动作，但依赖于足够的特定于手语的数据。由于手语资源普遍不足，这对该领域的研究和开发构成了重大挑战。为解决这一问题，我们引入ISLR101，这是首个公开的孤立伊朗手语数据集。该综合数据集包含4614个视频，涵盖101个不同手势，由10位不同手语使用者（3名聋人、2名手语翻译员和5名第二语言学习者）在多种背景中记录，分辨率为800x600像素，帧率为每秒25帧，并且包括使用OpenPose提取的骨架姿态信息。我们建立基于视觉外观和基于骨架的框架作为基准模型，并在ISLR101上充分训练和评估这些模型。这些模型在测试集上的准确率分别为97.01%和94.02%。此外，我们还发布了训练、验证和测试分割，以促进公平比较。', 'title_zh': 'ISLR101: 伊朗单词级手语识别数据集'}
{'arxiv_id': 'arXiv:2503.12447', 'title': 'Causality Model for Semantic Understanding on Videos', 'authors': 'Li Yicong', 'link': 'https://arxiv.org/abs/2503.12447', 'abstract': 'After a decade of prosperity, the development of video understanding has reached a critical juncture, where the sole reliance on massive data and complex architectures is no longer a one-size-fits-all solution to all situations. The presence of ubiquitous data imbalance hampers DNNs from effectively learning the underlying causal mechanisms, leading to significant performance drops when encountering distribution shifts, such as long-tail imbalances and perturbed imbalances. This realization has prompted researchers to seek alternative methodologies to capture causal patterns in video data. To tackle these challenges and increase the robustness of DNNs, causal modeling emerged as a principle to discover the true causal patterns behind the observed correlations. This thesis focuses on the domain of semantic video understanding and explores the potential of causal modeling to advance two fundamental tasks: Video Relation Detection (VidVRD) and Video Question Answering (VideoQA).', 'abstract_zh': '在经历了十年的繁荣发展之后，视频理解的开发已到达一个关键点，仅仅依赖大量数据和复杂架构已不再是一劳永逸的解决方案。普遍存在数据失衡阻碍了深度神经网络（DNNs）有效地学习潜在的因果机制，导致在遭遇分布转移，如长尾失衡和扰动失衡时性能显著下降。这一认识促使研究人员寻找新的方法来捕获视频数据中的因果模式。为解决这些挑战并提高DNNs的稳健性，因果建模作为一种原则应运而生，以发现观测关联背后的真正因果模式。本文集中于语义视频理解领域，探讨因果建模如何推进两项基本任务：视频关系检测（VidVRD）和视频问答（VideoQA）。', 'title_zh': '视频语义理解的因果模型'}
{'arxiv_id': 'arXiv:2503.12446', 'title': 'BREEN: Bridge Data-Efficient Encoder-Free Multimodal Learning with Learnable Queries', 'authors': 'Tianle Li, Yongming Rao, Winston Hu, Yu Cheng', 'link': 'https://arxiv.org/abs/2503.12446', 'abstract': "Encoder-free multimodal large language models(MLLMs) eliminate the need for a well-trained vision encoder by directly processing image tokens before the language model. While this approach reduces computational overhead and model complexity, it often requires large amounts of training data to effectively capture the visual knowledge typically encoded by vision models like CLIP. The absence of a vision encoder implies that the model is likely to rely on substantial data to learn the necessary visual-semantic alignments. In this work, we present BREEN, a data-efficient encoder-free multimodal architecture that mitigates this issue. BREEN leverages a learnable query and image experts to achieve comparable performance with significantly less training data. The learnable query, positioned between image and text tokens, is supervised by the output of a pretrained CLIP model to distill visual knowledge, bridging the gap between visual and textual modalities. Additionally, the image expert processes image tokens and learnable queries independently, improving efficiency and reducing interference with the LLM's textual capabilities. BREEN achieves comparable performance to prior encoder-free state-of-the-art models like Mono-InternVL, using only 13 million text-image pairs in training about one percent of the data required by existing methods. Our work highlights a promising direction for data-efficient encoder-free multimodal learning, offering an alternative to traditional encoder-based approaches.", 'abstract_zh': 'Encoder-free 多模态大语言模型（MLLMs）', 'title_zh': 'BREEN: 桥梁数据高效无编码器多模态学习可学习查询'}
{'arxiv_id': 'arXiv:2503.12427', 'title': 'Towards Learnable Anchor for Deep Multi-View Clustering', 'authors': 'Bocheng Wang, Chusheng Zeng, Mulin Chen, Xuelong Li', 'link': 'https://arxiv.org/abs/2503.12427', 'abstract': 'Deep multi-view clustering incorporating graph learning has presented tremendous potential. Most methods encounter costly square time consumption w.r.t. data size. Theoretically, anchor-based graph learning can alleviate this limitation, but related deep models mainly rely on manual discretization approaches to select anchors, which indicates that 1) the anchors are fixed during model training and 2) they may deviate from the true cluster distribution. Consequently, the unreliable anchors may corrupt clustering results. In this paper, we propose the Deep Multi-view Anchor Clustering (DMAC) model that performs clustering in linear time. Concretely, the initial anchors are intervened by the positive-incentive noise sampled from Gaussian distribution, such that they can be optimized with a newly designed anchor learning loss, which promotes a clear relationship between samples and anchors. Afterwards, anchor graph convolution is devised to model the cluster structure formed by the anchors, and the mutual information maximization loss is built to provide cross-view clustering guidance. In this way, the learned anchors can better represent clusters. With the optimal anchors, the full sample graph is calculated to derive a discriminative embedding for clustering. Extensive experiments on several datasets demonstrate the superior performance and efficiency of DMAC compared to state-of-the-art competitors.', 'abstract_zh': 'Deep多视图锚点聚类结合图学习在线性时间内实现聚类', 'title_zh': '面向学习的锚点深层多视图聚类'}
{'arxiv_id': 'arXiv:2503.12406', 'title': 'Bio-Inspired Plastic Neural Networks for Zero-Shot Out-of-Distribution Generalization in Complex Animal-Inspired Robots', 'authors': 'Binggwong Leung, Worasuchad Haomachai, Joachim Winther Pedersen, Sebastian Risi, Poramate Manoonpong', 'link': 'https://arxiv.org/abs/2503.12406', 'abstract': "Artificial neural networks can be used to solve a variety of robotic tasks. However, they risk failing catastrophically when faced with out-of-distribution (OOD) situations. Several approaches have employed a type of synaptic plasticity known as Hebbian learning that can dynamically adjust weights based on local neural activities. Research has shown that synaptic plasticity can make policies more robust and help them adapt to unforeseen changes in the environment. However, networks augmented with Hebbian learning can lead to weight divergence, resulting in network instability. Furthermore, such Hebbian networks have not yet been applied to solve legged locomotion in complex real robots with many degrees of freedom. In this work, we improve the Hebbian network with a weight normalization mechanism for preventing weight divergence, analyze the principal components of the Hebbian's weights, and perform a thorough evaluation of network performance in locomotion control for real 18-DOF dung beetle-like and 16-DOF gecko-like robots. We find that the Hebbian-based plastic network can execute zero-shot sim-to-real adaptation locomotion and generalize to unseen conditions, such as uneven terrain and morphological damage.", 'abstract_zh': '人工神经网络可以解决各种机器人任务，但在遇到分布外（OOD）情况时存在灾难性失效的风险。已有研究利用一种称为Hebbian学习的突触可塑性机制，动态调整权重以适应局部神经活动。研究表明，突触可塑性可以增加策略的鲁棒性并帮助其适应环境中的意外变化。然而，增强Hebbian学习的网络可能引发权重发散，导致网络不稳定。此外，此类Hebbian网络尚未应用于解决具有多个自由度的复杂现实腿足运动。在这项工作中，我们通过权重规范化机制改进了Hebbian网络，分析了Hebbian权重的主要成分，并对实现实足18自由度屎壳郎样机器人和16自由度壁虎样机器人在运动控制中的网络性能进行了全面评价。我们发现基于Hebbian的可塑网络可以实现零样本模拟到现实环境的运动适应，并推广到未见过的情况，如不平地形和形态损伤。', 'title_zh': '受生物启发的塑料神经网络在复杂动物启发型机器人中实现零样本分布外泛化的研究'}
{'arxiv_id': 'arXiv:2503.12374', 'title': 'Unveiling Pitfalls: Understanding Why AI-driven Code Agents Fail at GitHub Issue Resolution', 'authors': 'Zhi Chen, Wei Ma, Lingxiao Jiang', 'link': 'https://arxiv.org/abs/2503.12374', 'abstract': "AI-driven software development has rapidly advanced with the emergence of software development agents that leverage large language models (LLMs) to tackle complex, repository-level software engineering tasks. These agents go beyond just generation of final code; they engage in multi-step reasoning, utilize various tools for code modification and debugging, and interact with execution environments to diagnose and iteratively resolve issues. However, most existing evaluations focus primarily on static analyses of final code outputs, yielding limited insights into the agents' dynamic problem-solving processes. To fill this gap, we conduct an in-depth empirical study on 3,977 solving-phase trajectories and 3,931 testing-phase logs from 8 top-ranked agents evaluated on 500 GitHub issues in the SWE-Bench benchmark. Our exploratory analysis shows that Python execution errors during the issue resolution phase correlate with lower resolution rates and increased reasoning overheads. We have identified the most prevalent errors -- such as ModuleNotFoundError and TypeError -- and highlighted particularly challenging errors like OSError and database-related issues (e.g., IntegrityError) that demand significantly more debugging effort. Furthermore, we have discovered 3 bugs in the SWE-Bench platform that affect benchmark fairness and accuracy; these issues have been reported to and confirmed by the maintainers. To promote transparency and foster future research, we publicly share our datasets and analysis scripts.", 'abstract_zh': '基于AI的软件开发随着利用大规模语言模型（LLMs）处理复杂仓库级软件工程任务的软件开发代理的出现而迅速发展。这些代理不仅生成最终代码，还进行多步推理，利用各种工具进行代码修改和调试，并与执行环境交互以诊断和迭代解决问题。然而，现有的大多数评估主要集中在最终代码输出的静态分析上，这限制了对代理动态问题解决过程的深入了解。为填平这一差距，我们对SWE-Bench基准测试中的8个顶级代理在解决500个GitHub问题过程中3,977个解题阶段轨迹和3,931个测试阶段日志进行了深入的实证研究。我们的探索性分析表明，问题解决阶段的Python执行错误与较低的问题解决率和增加的推理开销有关。我们确定了最常见的错误，如ModuleNotFoundError和TypeError，并强调了特别具有挑战性的错误，如OSError以及数据库相关问题（如IntegrityError），这些错误需要更多的调试努力。此外，我们还发现了SWE-Bench平台上的3个影响基准公平性和准确性的错误，这些问题已报告给并得到了维护者的确认。为促进透明度并促进未来的研究，我们公开分享了我们的数据集和分析脚本。', 'title_zh': '揭开陷阱：理解为何AI驱动的代码代理在GitHub问题解决中失败'}
{'arxiv_id': 'arXiv:2503.12356', 'title': 'Localized Concept Erasure for Text-to-Image Diffusion Models Using Training-Free Gated Low-Rank Adaptation', 'authors': 'Byung Hyun Lee, Sungjin Lim, Se Young Chun', 'link': 'https://arxiv.org/abs/2503.12356', 'abstract': 'Fine-tuning based concept erasing has demonstrated promising results in preventing generation of harmful contents from text-to-image diffusion models by removing target concepts while preserving remaining concepts. To maintain the generation capability of diffusion models after concept erasure, it is necessary to remove only the image region containing the target concept when it locally appears in an image, leaving other regions intact. However, prior arts often compromise fidelity of the other image regions in order to erase the localized target concept appearing in a specific area, thereby reducing the overall performance of image generation. To address these limitations, we first introduce a framework called localized concept erasure, which allows for the deletion of only the specific area containing the target concept in the image while preserving the other regions. As a solution for the localized concept erasure, we propose a training-free approach, dubbed Gated Low-rank adaptation for Concept Erasure (GLoCE), that injects a lightweight module into the diffusion model. GLoCE consists of low-rank matrices and a simple gate, determined only by several generation steps for concepts without training. By directly applying GLoCE to image embeddings and designing the gate to activate only for target concepts, GLoCE can selectively remove only the region of the target concepts, even when target and remaining concepts coexist within an image. Extensive experiments demonstrated GLoCE not only improves the image fidelity to text prompts after erasing the localized target concepts, but also outperforms prior arts in efficacy, specificity, and robustness by large margin and can be extended to mass concept erasure.', 'abstract_zh': '基于细粒度概念消除的微调在预防文本到图像扩散模型生成有害内容方面表现出有 promising 的结果，通过移除目标概念同时保留其余概念。为在概念消除后维持扩散模型的生成能力，在图像中局部出现目标概念时仅需移除包含目标概念的图像区域，而不影响其他区域。然而，现有方法往往为了消除特定区域的局部目标概念而牺牲其他图像区域的保真度，从而降低了整体图像生成性能。为解决这些限制，我们首先引入了一种称为局部概念消除的框架，该框架允许仅删除图像中包含目标概念的特定区域，而不影响其他区域。为实现局部概念消除，我们提出了一种无需训练的解决方案，名为门控低秩适应的概念消除（GLoCE），该方法将一个轻量级模块注入扩散模型。GLoCE 由低秩矩阵和一个仅由几个生成步骤确定的简单门控机制组成。通过直接将 GLoCE 应用于图像嵌入并向门控机制设计只在目标概念时激活，GLoCE 可以仅选择性地移除目标概念区域，即使目标概念和剩余概念在图像中共存。广泛实验表明，GLoCE 不仅在移除局部目标概念后提高了图像对文本提示的保真度，还在有效性、特异性和鲁棒性方面显著优于现有方法，可以扩展到大规模概念消除。', 'title_zh': '基于训练-free门控低秩适应的局部概念擦除文本到图像扩散模型'}
{'arxiv_id': 'arXiv:2503.12353', 'title': 'Synthetic Data for Robust AI Model Development in Regulated Enterprises', 'authors': 'Aditi Godbole', 'link': 'https://arxiv.org/abs/2503.12353', 'abstract': "In today's business landscape, organizations need to find the right balance between using their customers' data ethically to power AI solutions and being compliant regarding data privacy and data usage regulations. In this paper, we discuss synthetic data as a possible solution to this dilemma. Synthetic data is simulated data that mimics the real data. We explore how organizations in heavily regulated industries, such as financial institutions or healthcare organizations, can leverage synthetic data to build robust AI solutions while staying compliant. We demonstrate that synthetic data offers two significant advantages by allowing AI models to learn from more diverse data and by helping organizations stay compliant against data privacy laws with the use of synthetic data instead of customer information. We discuss case studies to show how synthetic data can be effectively used in the finance and healthcare sector while discussing the challenges of using synthetic data and some ethical questions it raises. Our research finds that synthetic data could be a game-changer for AI in regulated industries. The potential can be realized when industry, academia, and regulators collaborate to build solutions. We aim to initiate discussions on the use of synthetic data to build ethical, responsible, and effective AI systems in regulated enterprise industries.", 'abstract_zh': '在当今的商业环境中，组织需要在利用客户数据来驱动AI解决方案与遵守数据隐私和数据使用规定之间找到合适的平衡。本文探讨合成数据作为解决这一困境的可能解决方案。合成数据是模拟的、模拟真实数据的数据。我们探讨了在金融机构或医疗组织等高度监管行业中，组织如何利用合成数据构建稳健的AI解决方案，同时保持合规。我们证明合成数据提供了两大优势：使AI模型能够从更多样化的数据中学习，并通过使用合成数据而非客户信息帮助组织遵守数据隐私法规。我们讨论了金融和医疗保健行业的案例研究，展示了合成数据如何有效使用，同时讨论了使用合成数据面临的挑战及其引发的一些伦理问题。我们的研究发现，合成数据可能成为监管行业中AI游戏规则的改变者。实现其潜力需要行业、学术界和监管者合作构建解决方案。我们旨在发起关于在受监管的企业行业中利用合成数据构建伦理、负责且有效的AI系统的讨论。', 'title_zh': '受监管企业中 robust AI 模型开发的合成数据应用'}
{'arxiv_id': 'arXiv:2503.12345', 'title': 'General Table Question Answering via Answer-Formula Joint Generation', 'authors': 'Zhongyuan Wang, Richong Zhang, Zhijie Nie', 'link': 'https://arxiv.org/abs/2503.12345', 'abstract': 'Advanced table question answering (TableQA) methods prompt large language models (LLMs) to generate answer text, SQL query, Python code, or custom operations, which impressively improve the complex reasoning problems in the TableQA task. However, these methods lack the versatility to cope with specific question types or table structures. In contrast, the Spreadsheet Formula, the widely-used and well-defined operation language for tabular data, has not been thoroughly explored to solve TableQA. In this paper, we first attempt to use Formula as the logical form for solving complex reasoning on the tables with different structures. Specifically, we construct a large Formula-annotated TableQA dataset \\texttt{FromulaQA} from existing datasets. In addition, we propose \\texttt{TabAF}, a general table answering framework to solve multiple types of tasks over multiple types of tables simultaneously. Unlike existing methods, \\texttt{TabAF} decodes answers and Formulas with a single LLM backbone, demonstrating great versatility and generalization. \\texttt{TabAF} based on Llama3.1-70B achieves new state-of-the-art performance on the WikiTableQuestion, HiTab and TabFact.', 'abstract_zh': '使用Spreadsheet Formula解决具有不同结构的表格复杂推理问题：TabAF框架取得最新性能', 'title_zh': '基于答案-公式联合生成的一般表格问答'}
{'arxiv_id': 'arXiv:2503.12339', 'title': 'Augmented Adversarial Trigger Learning', 'authors': 'Zhe Wang, Yanjun Qi', 'link': 'https://arxiv.org/abs/2503.12339', 'abstract': 'Gradient optimization-based adversarial attack methods automate the learning of adversarial triggers to generate jailbreak prompts or leak system prompts. In this work, we take a closer look at the optimization objective of adversarial trigger learning and propose ATLA: Adversarial Trigger Learning with Augmented objectives. ATLA improves the negative log-likelihood loss used by previous studies into a weighted loss formulation that encourages the learned adversarial triggers to optimize more towards response format tokens. This enables ATLA to learn an adversarial trigger from just one query-response pair and the learned trigger generalizes well to other similar queries. We further design a variation to augment trigger optimization with an auxiliary loss that suppresses evasive responses. We showcase how to use ATLA to learn adversarial suffixes jailbreaking LLMs and to extract hidden system prompts. Empirically we demonstrate that ATLA consistently outperforms current state-of-the-art techniques, achieving nearly 100% success in attacking while requiring 80% fewer queries. ATLA learned jailbreak suffixes demonstrate high generalization to unseen queries and transfer well to new LLMs.', 'abstract_zh': '基于梯度优化的对抗攻击方法自动化学习生成逃逸提示或泄露系统提示的对抗触发器。在本文中，我们更详细地探讨了对抗触发器学习的优化目标，并提出了一种增强目标的对抗触发器学习方法ATLA（Adversarial Trigger Learning with Augmented objectives）。ATLA将之前研究中使用的负对数似然损失改进为加权损失形式，鼓励学习到的对抗触发器更加优化响应格式 tokens。这使得ATLA能够在仅有一个查询-响应对的情况下学习到对抗触发器，并且所学的触发器在面对其他类似查询时具有良好的泛化能力。我们进一步设计了一种变体，通过附加一个辅助损失来增强触发器优化，该损失抑制逃避性响应。我们展示了如何使用ATLA学习生成对抗后缀以逃逸LLM以及提取隐藏系统提示。实验证明，ATLA在性能上始终优于当前最先进的技术，在获得几乎100%攻击成功率的同时，所需的查询数量减少了80%。学会的逃逸后缀在面对未见过的查询时具有高度的泛化能力，并能很好地转移应用到新的LLM上。', 'title_zh': '增强对抗触发学习'}
{'arxiv_id': 'arXiv:2503.12334', 'title': 'When neural implant meets multimodal LLM: A dual-loop system for neuromodulation and naturalistic neuralbehavioral research', 'authors': 'Edward Hong Wang, Cynthia Xin Wen', 'link': 'https://arxiv.org/abs/2503.12334', 'abstract': 'We propose a novel dual-loop system that synergistically combines responsive neurostimulation (RNS) implants with artificial intelligence-driven wearable devices for treating post-traumatic stress disorder (PTSD) and enabling naturalistic brain research. In PTSD Therapy Mode, an implanted closed-loop neural device monitors amygdala activity and provides on-demand stimulation upon detecting pathological theta oscillations, while an ensemble of wearables (smart glasses, smartwatches, smartphones) uses multimodal large language model (LLM) analysis of sensory data to detect environmental or physiological PTSD triggers and deliver timely audiovisual interventions. Logged events from both the neural and wearable loops are analyzed to personalize trigger detection and progressively transition patients to non-invasive interventions. In Neuroscience Research Mode, the same platform is adapted for real-world brain activity capture. Wearable-LLM systems recognize naturalistic events (social interactions, emotional situations, compulsive behaviors, decision making) and signal implanted RNS devices (via wireless triggers) to record synchronized intracranial data during these moments. This approach builds on recent advances in mobile intracranial EEG recording and closed-loop neuromodulation in humans (BRAIN Initiative, 2023) (Mobbs et al., 2021). We discuss how our interdisciplinary system could revolutionize PTSD therapy and cognitive neuroscience by enabling 24/7 monitoring, context-aware intervention, and rich data collection outside traditional labs. The vision is a future where AI-enhanced devices continuously collaborate with the human brain, offering therapeutic support and deep insights into neural function, with the resulting real-world context rich neural data, in turn, accelerating the development of more biologically-grounded and human-centric AI.', 'abstract_zh': '一种将响应性神经刺激植入物与人工智能驱动的穿戴设备协同工作的新型双环系统：用于治疗创伤后应激障碍和促进自然脑研究', 'title_zh': '当神经植入物遇到多模态LLM：一种用于神经调控和自然神经行为研究的双环系统'}
{'arxiv_id': 'arXiv:2503.12326', 'title': 'Leveraging Vision Capabilities of Multimodal LLMs for Automated Data Extraction from Plots', 'authors': 'Maciej P. Polak, Dane Morgan', 'link': 'https://arxiv.org/abs/2503.12326', 'abstract': 'Automated data extraction from research texts has been steadily improving, with the emergence of large language models (LLMs) accelerating progress even further. Extracting data from plots in research papers, however, has been such a complex task that it has predominantly been confined to manual data extraction. We show that current multimodal large language models, with proper instructions and engineered workflows, are capable of accurately extracting data from plots. This capability is inherent to the pretrained models and can be achieved with a chain-of-thought sequence of zero-shot engineered prompts we call PlotExtract, without the need to fine-tune. We demonstrate PlotExtract here and assess its performance on synthetic and published plots. We consider only plots with two axes in this analysis. For plots identified as extractable, PlotExtract finds points with over 90% precision (and around 90% recall) and errors in x and y position of around 5% or lower. These results prove that multimodal LLMs are a viable path for high-throughput data extraction for plots and in many circumstances can replace the current manual methods of data extraction.', 'abstract_zh': '基于大型语言模型的多模态数据提取方法在研究论文图示中的应用进展：PlotExtract验证', 'title_zh': '利用多模态LLM的视觉能力实现图表中数据的自动化提取'}
{'arxiv_id': 'arXiv:2503.12307', 'title': 'Swift4D:Adaptive divide-and-conquer Gaussian Splatting for compact and efficient reconstruction of dynamic scene', 'authors': 'Jiahao Wu, Rui Peng, Zhiyan Wang, Lu Xiao, Luyang Tang, Jinbo Yan, Kaiqiang Xiong, Ronggang Wang', 'link': 'https://arxiv.org/abs/2503.12307', 'abstract': 'Novel view synthesis has long been a practical but challenging task, although the introduction of numerous methods to solve this problem, even combining advanced representations like 3D Gaussian Splatting, they still struggle to recover high-quality results and often consume too much storage memory and training time. In this paper we propose Swift4D, a divide-and-conquer 3D Gaussian Splatting method that can handle static and dynamic primitives separately, achieving a good trade-off between rendering quality and efficiency, motivated by the fact that most of the scene is the static primitive and does not require additional dynamic properties. Concretely, we focus on modeling dynamic transformations only for the dynamic primitives which benefits both efficiency and quality. We first employ a learnable decomposition strategy to separate the primitives, which relies on an additional parameter to classify primitives as static or dynamic. For the dynamic primitives, we employ a compact multi-resolution 4D Hash mapper to transform these primitives from canonical space into deformation space at each timestamp, and then mix the static and dynamic primitives to produce the final output. This divide-and-conquer method facilitates efficient training and reduces storage redundancy. Our method not only achieves state-of-the-art rendering quality while being 20X faster in training than previous SOTA methods with a minimum storage requirement of only 30MB on real-world datasets. Code is available at this https URL.', 'abstract_zh': '基于分而治之的3D高斯点云合成方法Swift4D', 'title_zh': 'Swift4D：自适应分而治之高斯点云化及其在动态场景紧凑高效重建中的应用'}
{'arxiv_id': 'arXiv:2503.12294', 'title': 'The Lucie-7B LLM and the Lucie Training Dataset: Open resources for multilingual language generation', 'authors': 'Olivier Gouvert, Julie Hunter, Jérôme Louradour, Christophe Cerisara, Evan Dufraisse, Yaya Sy, Laura Rivière, Jean-Pierre Lorré, OpenLLM-France community', 'link': 'https://arxiv.org/abs/2503.12294', 'abstract': 'We present both the Lucie Training Dataset and the Lucie-7B foundation model. The Lucie Training Dataset is a multilingual collection of textual corpora centered around French and designed to offset anglo-centric biases found in many datasets for large language model pretraining. Its French data is pulled not only from traditional web sources, but also from French cultural heritage documents, filling an important gap in modern datasets. Beyond French, which makes up the largest share of the data, we added documents to support several other European languages, including English, Spanish, German, and Italian. Apart from its value as a resource for French language and culture, an important feature of this dataset is that it prioritizes data rights by minimizing copyrighted material. In addition, building on the philosophy of past open projects, it is redistributed in the form used for training and its processing is described on Hugging Face and GitHub. The Lucie-7B foundation model is trained on equal amounts of data in French and English -- roughly 33% each -- in an effort to better represent cultural aspects of French-speaking communities. We also describe two instruction fine-tuned models, Lucie-7B-Instruct-v1.1 and Lucie-7B-Instruct-human-data, which we release as demonstrations of Lucie-7B in use. These models achieve promising results compared to state-of-the-art models, demonstrating that an open approach prioritizing data rights can still deliver strong performance. We see these models as an initial step toward developing more performant, aligned models in the near future. Model weights for Lucie-7B and the Lucie instruct models, along with intermediate checkpoints for the former, are published on Hugging Face, while model training and data preparation code is available on GitHub. This makes Lucie-7B one of the first OSI compliant language models according to the new OSI definition.', 'abstract_zh': '我们介绍了Lucie训练数据集和Lucie-7B基础模型。', 'title_zh': 'Lucie-7B大规模语言模型与Lucie训练数据集：多语言语言生成的开源资源'}
{'arxiv_id': 'arXiv:2503.12286', 'title': 'Integrating Chain-of-Thought and Retrieval Augmented Generation Enhances Rare Disease Diagnosis from Clinical Notes', 'authors': 'Da Wu, Zhanliang Wang, Quan Nguyen, Kai Wang', 'link': 'https://arxiv.org/abs/2503.12286', 'abstract': 'Background: Several studies show that large language models (LLMs) struggle with phenotype-driven gene prioritization for rare diseases. These studies typically use Human Phenotype Ontology (HPO) terms to prompt foundation models like GPT and LLaMA to predict candidate genes. However, in real-world settings, foundation models are not optimized for domain-specific tasks like clinical diagnosis, yet inputs are unstructured clinical notes rather than standardized terms. How LLMs can be instructed to predict candidate genes or disease diagnosis from unstructured clinical notes remains a major challenge. Methods: We introduce RAG-driven CoT and CoT-driven RAG, two methods that combine Chain-of-Thought (CoT) and Retrieval Augmented Generation (RAG) to analyze clinical notes. A five-question CoT protocol mimics expert reasoning, while RAG retrieves data from sources like HPO and OMIM (Online Mendelian Inheritance in Man). We evaluated these approaches on rare disease datasets, including 5,980 Phenopacket-derived notes, 255 literature-based narratives, and 220 in-house clinical notes from Childrens Hospital of Philadelphia. Results: We found that recent foundations models, including Llama 3.3-70B-Instruct and DeepSeek-R1-Distill-Llama-70B, outperformed earlier versions such as Llama 2 and GPT-3.5. We also showed that RAG-driven CoT and CoT-driven RAG both outperform foundation models in candidate gene prioritization from clinical notes; in particular, both methods with DeepSeek backbone resulted in a top-10 gene accuracy of over 40% on Phenopacket-derived clinical notes. RAG-driven CoT works better for high-quality notes, where early retrieval can anchor the subsequent reasoning steps in domain-specific evidence, while CoT-driven RAG has advantage when processing lengthy and noisy notes.', 'abstract_zh': '背景: 一些研究表明，大型语言模型（LLMs）在罕见疾病表型驱动的基因优先级确定方面存在困难。这些研究通常使用人类表型 ontology (HPO) 术语来提示如 GPT 和 LLaMA 等基础模型预测候选基因。然而，在实际应用中，基础模型并未针对如临床诊断等特定领域任务进行优化，输入的是未结构化的临床笔记而非标准化术语。如何从未结构化的临床笔记中指导 LLMs 预测候选基因或疾病诊断仍然是一个重大挑战。方法: 我们介绍了基于 RAG 的 CoT 和 CoT 指导的 RAG 两种方法，将 Chain-of-Thought (CoT) 和 Retrieval Augmented Generation (RAG) 结合起来分析临床笔记。我们使用一个五问题 CoT 评估方案来模拟专家推理过程，而 RAG 则从 HPO 和 OMIM（在线人类遗传学）等来源检索数据。我们在包含 5,980 条来源于 Phenopacket 的临床笔记、255 条基于文献的叙述以及 Childrens Hospital of Philadelphia 的 220 条内部临床笔记的罕见疾病数据集中评估了这些方法。结果: 我们发现，包括 Llama 3.3-70B-Instruct 和 DeepSeek-R1-Distill-Llama-70B 在内的最近版本的基础模型优于之前版本的 Llama 2 和 GPT-3.5。我们还展示了基于 RAG 的 CoT 和 CoT 指导的 RAG 方法在从临床笔记预测候选基因方面的表现优于基础模型；特别是，以 DeepSeek 为基础的方法在来源于 Phenopacket 的临床笔记中的 top-10 基因准确率超过 40%。基于 RAG 的 CoT 在高质量的笔记中表现出色，因为它可以通过早期检索为后续的推理步骤提供领域特定的证据，而 CoT 指导的 RAG 在处理冗长和噪音较多的笔记时具有优势。', 'title_zh': '将链式思考与检索增强生成集成以提高临床笔记中罕见疾病诊断的准确性'}
{'arxiv_id': 'arXiv:2503.12285', 'title': 'Bi-Criteria Optimization for Combinatorial Bandits: Sublinear Regret and Constraint Violation under Bandit Feedback', 'authors': 'Vaneet Aggarwal, Shweta Jain, Subham Pokhriyal, Christopher John Quinn', 'link': 'https://arxiv.org/abs/2503.12285', 'abstract': "In this paper, we study bi-criteria optimization for combinatorial multi-armed bandits (CMAB) with bandit feedback. We propose a general framework that transforms discrete bi-criteria offline approximation algorithms into online algorithms with sublinear regret and cumulative constraint violation (CCV) guarantees. Our framework requires the offline algorithm to provide an $(\\alpha, \\beta)$-bi-criteria approximation ratio with $\\delta$-resilience and utilize $\\texttt{N}$ oracle calls to evaluate the objective and constraint functions. We prove that the proposed framework achieves sub-linear regret and CCV, with both bounds scaling as ${O}\\left(\\delta^{2/3} \\texttt{N}^{1/3}T^{2/3}\\log^{1/3}(T)\\right)$. Crucially, the framework treats the offline algorithm with $\\delta$-resilience as a black box, enabling flexible integration of existing approximation algorithms into the CMAB setting. To demonstrate its versatility, we apply our framework to several combinatorial problems, including submodular cover, submodular cost covering, and fair submodular maximization. These applications highlight the framework's broad utility in adapting offline guarantees to online bi-criteria optimization under bandit feedback.", 'abstract_zh': '本文研究了具有带反馈的组合多臂 bandits (CMAB) 双准则优化问题。我们提出了一种通用框架，将离线双准则近似算法转化为具有亚线性后悔和累积约束违例（CCV）保证的在线算法。该框架要求离线算法提供 $(\\alpha, \\beta)$-双准则近似比，并具有 $\\delta$-稳健性，同时利用 $\\texttt{N}$ 次 oracle 调用评估目标函数和约束函数。我们证明了所提出框架实现了亚线性后悔和 CCV，两者界均为 ${O}\\left(\\delta^{2/3} \\texttt{N}^{1/3}T^{2/3}\\log^{1/3}(T)\\right)$。关键地，该框架将具有 $\\delta$-稳健性的离线算法视为黑盒，使得现有的近似算法可以灵活地整合到 CMAB 设置中。为了展示其灵活性，我们将该框架应用于多个组合问题，包括子模覆盖、子模成本覆盖和公平子模最大化。这些应用突显了该框架在带反馈的在线双准则优化中将离线保证适应的广泛用途。', 'title_zh': '组合臂拉动的双标准优化：基于臂反馈下的亚线性遗憾和约束违反而上的优化'}
{'arxiv_id': 'arXiv:2503.12282', 'title': 'Toward Foundation Models for Online Complex Event Detection in CPS-IoT: A Case Study', 'authors': 'Liying Han, Gaofeng Dong, Xiaomin Ouyang, Lance Kaplan, Federico Cerutti, Mani Srivastava', 'link': 'https://arxiv.org/abs/2503.12282', 'abstract': 'Complex events (CEs) play a crucial role in CPS-IoT applications, enabling high-level decision-making in domains such as smart monitoring and autonomous systems. However, most existing models focus on short-span perception tasks, lacking the long-term reasoning required for CE detection. CEs consist of sequences of short-time atomic events (AEs) governed by spatiotemporal dependencies. Detecting them is difficult due to long, noisy sensor data and the challenge of filtering out irrelevant AEs while capturing meaningful patterns. This work explores CE detection as a case study for CPS-IoT foundation models capable of long-term reasoning. We evaluate three approaches: (1) leveraging large language models (LLMs), (2) employing various neural architectures that learn CE rules from data, and (3) adopting a neurosymbolic approach that integrates neural models with symbolic engines embedding human knowledge. Our results show that the state-space model, Mamba, which belongs to the second category, outperforms all methods in accuracy and generalization to longer, unseen sensor traces. These findings suggest that state-space models could be a strong backbone for CPS-IoT foundation models for long-span reasoning tasks.', 'abstract_zh': '复杂事件（CEs）在CPS-IoT应用中起着关键作用，能够在智能监测和自主系统等领域实现高级决策。然而，现有的大多数模型主要关注短时感知任务，缺乏用于CE检测所需的长期推理能力。CEs由受时空依赖关系支配的短暂时间原子事件（AEs）序列组成。检测CEs由于长期的噪声传感器数据和过滤无关AEs以捕捉有意义模式的挑战而困难。本研究以CEs检测为例探讨了具备长期推理能力的CPS-IoT基础模型。我们评估了三种方法：（1）利用大型语言模型（LLMs），（2）采用各种神经架构从数据中学习CE规则，以及（3）采用结合神经模型与嵌入人类知识的符号引擎的神经符号方法。我们的结果显示，属于第二类的态空间模型Mamba在准确性和对更长、未见过的传感器轨迹的一般化方面均优于所有方法。这表明态空间模型可能是长期跨度推理任务中CPS-IoT基础模型的强大支撑。', 'title_zh': '面向 CPS-IoT 中在线复杂事件检测的基础模型研究：一个案例研究'}
{'arxiv_id': 'arXiv:2503.12255', 'title': 'Agentic Search Engine for Real-Time IoT Data', 'authors': 'Abdelrahman Elewah, Khalid Elgazzar', 'link': 'https://arxiv.org/abs/2503.12255', 'abstract': 'The Internet of Things (IoT) has enabled diverse devices to communicate over the Internet, yet the fragmentation of IoT systems limits seamless data sharing and coordinated management. We have recently introduced SensorsConnect, a unified framework to enable seamless content and sensor data sharing in collaborative IoT systems, inspired by how the World Wide Web (WWW) enabled a shared and accessible space for information among humans. This paper presents the IoT Agentic Search Engine (IoT-ASE), a real-time search engine tailored for IoT environments. IoT-ASE leverages Large Language Models (LLMs) and Retrieval Augmented Generation (RAG) techniques to address the challenge of searching vast, real-time IoT data, enabling it to handle complex queries and deliver accurate, contextually relevant results. We implemented a use-case scenario in Toronto to demonstrate how IoT-ASE can improve service quality recommendations by leveraging real-time IoT data. Our evaluation shows that IoT-ASE achieves a 92\\% accuracy in retrieving intent-based services and produces responses that are concise, relevant, and context-aware, outperforming generalized responses from systems like Gemini. These findings highlight the potential IoT-ASE to make real-time IoT data accessible and support effective, real-time decision-making.', 'abstract_zh': '物联网代理搜索引擎（IoT-ASE）：面向物联网环境的实时搜索引擎', 'title_zh': '基于代理的实时物联网数据搜索引擎'}
{'arxiv_id': 'arXiv:2503.12243', 'title': 'GenOSIL: Generalized Optimal and Safe Robot Control using Parameter-Conditioned Imitation Learning', 'authors': 'Mumuksh Tayal, Manan Tayal, Ravi Prakash', 'link': 'https://arxiv.org/abs/2503.12243', 'abstract': 'Ensuring safe and generalizable control remains a fundamental challenge in robotics, particularly when deploying imitation learning in dynamic environments. Traditional behavior cloning (BC) struggles to generalize beyond its training distribution, as it lacks an understanding of the safety critical reasoning behind expert demonstrations. To address this limitation, we propose GenOSIL, a novel imitation learning framework that explicitly incorporates environment parameters into policy learning via a structured latent representation. Unlike conventional methods that treat the environment as a black box, GenOSIL employs a variational autoencoder (VAE) to encode measurable safety parameters such as obstacle position, velocity, and geometry into a latent space that captures intrinsic correlations between expert behavior and environmental constraints. This enables the policy to infer the rationale behind expert trajectories rather than merely replicating them. We validate our approach on two robotic platforms an autonomous ground vehicle and a Franka Emika Panda manipulator demonstrating superior safety and goal reaching performance compared to baseline methods. The simulation and hardware videos can be viewed on the project webpage: this https URL.', 'abstract_zh': '确保机器人在动态环境中安全且普适的控制仍然是一个基本挑战，特别是在部署模仿学习时。传统的行为克隆(BC)难以超越其训练分布进行泛化，因为它缺乏对专家演示中安全关键推理的理解。为了解决这一局限性，我们提出了一种新颖的模仿学习框架GenOSIL，该框架通过结构化的潜在表示显式地将环境参数纳入策略学习中。与将环境视为黑盒的常规方法不同，GenOSIL 使用变分自编码器(VAE) 将障碍物的位置、速度和几何形状等可测量的安全参数编码到潜在空间中，该空间捕获了专家行为与环境约束之间的内在关联。这使得策略能够推断专家轨迹背后的原理，而不仅仅是简单的复制。我们通过两个机器人平台——自动驾驶地面车辆和Franka Emika Panda机械臂进行了验证，展示了与基准方法相比更优的安全性和目标到达性能。仿真和硬件视频可在项目网页上查看：this https URL。', 'title_zh': 'GenOSIL: 通用最优和安全的机器人控制方法基于参数条件模仿学习'}
{'arxiv_id': 'arXiv:2503.12239', 'title': 'A Novel Double Pruning method for Imbalanced Data using Information Entropy and Roulette Wheel Selection for Breast Cancer Diagnosis', 'authors': 'Soufiane Bacha, Huansheng Ning, Belarbi Mostefa, Doreen Sebastian Sarwatt, Sahraoui Dhelim', 'link': 'https://arxiv.org/abs/2503.12239', 'abstract': 'Accurate illness diagnosis is vital for effective treatment and patient safety. Machine learning models are widely used for cancer diagnosis based on historical medical data. However, data imbalance remains a major challenge, leading to hindering classifier performance and reliability. The SMOTEBoost method addresses this issue by generating synthetic data to balance the dataset, but it may overlook crucial overlapping regions near the decision boundary and can produce noisy samples. This paper proposes RE-SMOTEBoost, an enhanced version of SMOTEBoost, designed to overcome these limitations. Firstly, RE-SMOTEBoost focuses on generating synthetic samples in overlapping regions to better capture the decision boundary using roulette wheel selection. Secondly, it incorporates a filtering mechanism based on information entropy to reduce noise, and borderline cases and improve the quality of generated data. Thirdly, we introduce a double regularization penalty to control the synthetic samples proximity to the decision boundary and avoid class overlap. These enhancements enable higher-quality oversampling of the minority class, resulting in a more balanced and effective training dataset. The proposed method outperforms existing state-of-the-art techniques when evaluated on imbalanced datasets. Compared to the top-performing sampling algorithms, RE-SMOTEBoost demonstrates a notable improvement of 3.22\\% in accuracy and a variance reduction of 88.8\\%. These results indicate that the proposed model offers a solid solution for medical settings, effectively overcoming data scarcity and severe imbalance caused by limited samples, data collection difficulties, and privacy constraints.', 'abstract_zh': '精确的疾病诊断对于有效的治疗和患者安全至关重要。基于历史医疗数据的机器学习模型广泛用于癌症诊断。然而，数据不平衡仍然是一个主要挑战，阻碍了分类器性能和可靠性。RE-SMOTEBoost方法通过生成合成数据来平衡数据集，解决了这一问题，但它可能会忽略决策边界附近的重叠区域，并可能生成噪声样本。本文提出了一种增强的RE-SMOTEBoost方法，旨在克服这些限制。首先，RE-SMOTEBoost重点关注在重叠区域生成合成样本，以更好地捕捉决策边界，并使用轮盘赌选择。其次，它结合了基于信息熵的过滤机制来减少噪声和边界案例，提高生成数据的质量。第三，引入双正则化惩罚以控制合成样本与决策边界的 proximity 并避免类别重叠。这些增强使少数类的过采样更具质量，从而生成更平衡和有效的训练数据集。该提出的模型在不平衡数据集上的评估中优于现有最先进的技术。与表现最佳的采样算法相比，RE-SMOTEBoost在准确率上提高了3.22%，方差减少了88.8%。这些结果表明，提出的模型为医疗环境提供了一个有效的解决方案，能够有效克服由样本稀缺性和严重不平衡引起的数据短缺和隐私限制问题。', 'title_zh': '基于信息熵和轮盘赌选择的乳腺癌症诊断新型双重剪枝方法'}
{'arxiv_id': 'arXiv:2503.12230', 'title': 'LIAM: Multimodal Transformer for Language Instructions, Images, Actions and Semantic Maps', 'authors': 'Yihao Wang, Raphael Memmesheimer, Sven Behnke', 'link': 'https://arxiv.org/abs/2503.12230', 'abstract': 'The availability of large language models and open-vocabulary object perception methods enables more flexibility for domestic service robots. The large variability of domestic tasks can be addressed without implementing each task individually by providing the robot with a task description along with appropriate environment information. In this work, we propose LIAM - an end-to-end model that predicts action transcripts based on language, image, action, and map inputs. Language and image inputs are encoded with a CLIP backbone, for which we designed two pre-training tasks to fine-tune its weights and pre-align the latent spaces. We evaluate our method on the ALFRED dataset, a simulator-generated benchmark for domestic tasks. Our results demonstrate the importance of pre-aligning embedding spaces from different modalities and the efficacy of incorporating semantic maps.', 'abstract_zh': '大规模语言模型和开放式词汇物体感知方法的可用性使得家庭服务机器人更具灵活性。通过提供任务描述和合适的环境信息，可以解决家庭任务的高变异性而无需单独实现每个任务。在本工作中，我们提出了一种端到端模型LIAM，该模型基于语言、图像、动作和地图输入来预测动作转录。语言和图像输入通过CLIP骨干网络进行编码，我们为此设计了两个预训练任务来微调其权重并预对齐潜在空间。我们在ALFRED数据集上评估了我们的方法，这是一个由模拟器生成的家庭任务基准。我们的结果表明了来自不同模态的嵌入空间预对齐的重要性，并展示了融入语义地图的有效性。', 'title_zh': 'LIAM：语言指令、图像、动作和语义地图的多模态变换器'}
{'arxiv_id': 'arXiv:2503.12228', 'title': 'Adaptive Fault Tolerance Mechanisms of Large Language Models in Cloud Computing Environments', 'authors': 'Yihong Jin, Ze Yang, Xinhe Xu, Yihan Zhang, Shuyang Ji', 'link': 'https://arxiv.org/abs/2503.12228', 'abstract': 'With the rapid evolution of Large Language Models (LLMs) and their large-scale experimentation in cloud-computing spaces, the challenge of guaranteeing their security and efficiency in a failure scenario has become a main issue. To ensure the reliability and availability of large-scale language models in cloud computing scenarios, such as frequent resource failures, network problems, and computational overheads, this study proposes a novel adaptive fault tolerance mechanism. It builds upon known fault-tolerant mechanisms, such as checkpointing, redundancy, and state transposition, introducing dynamic resource allocation and prediction of failure based on real-time performance metrics. The hybrid model integrates data driven deep learning-based anomaly detection technique underlining the contribution of cloud orchestration middleware for predictive prevention of system failures. Additionally, the model integrates adaptive checkpointing and recovery strategies that dynamically adapt according to load and system state to minimize the influence on the performance of the model and minimize downtime. The experimental results demonstrate that the designed model considerably enhances the fault tolerance in large-scale cloud surroundings, and decreases the system downtime by $\\mathbf{30\\%}$, and has a better modeling availability than the classical fault tolerance mechanism.', 'abstract_zh': '带预测性预防的自适应故障容忍机制在云环境中大规模语言模型中的应用研究', 'title_zh': '大型语言模型在云计算环境中的自适应容错机制'}
{'arxiv_id': 'arXiv:2503.12226', 'title': 'Research on Large Language Model Cross-Cloud Privacy Protection and Collaborative Training based on Federated Learning', 'authors': 'Ze Yang, Yihong Jin, Yihan Zhang, Juntian Liu, Xinhe Xu', 'link': 'https://arxiv.org/abs/2503.12226', 'abstract': 'The fast development of large language models (LLMs) and popularization of cloud computing have led to increasing concerns on privacy safeguarding and data security of cross-cloud model deployment and training as the key challenges. We present a new framework for addressing these issues along with enabling privacy preserving collaboration on training between distributed clouds based on federated learning. Our mechanism encompasses cutting-edge cryptographic primitives, dynamic model aggregation techniques, and cross-cloud data harmonization solutions to enhance security, efficiency, and scalability to the traditional federated learning paradigm. Furthermore, we proposed a hybrid aggregation scheme to mitigate the threat of Data Leakage and to optimize the aggregation of model updates, thus achieving substantial enhancement on the model effectiveness and stability. Experimental results demonstrate that the training efficiency, privacy protection, and model accuracy of the proposed model compare favorably to those of the traditional federated learning method.', 'abstract_zh': '大型语言模型的快速发展和云计算的普及导致了跨云模型部署与训练中的隐私保护和数据安全问题日益成为关键挑战。我们提出了一种新的框架，结合联邦学习，在分布式的云之间实现隐私保护的训练协作。我们的机制包括先进的密码学原语、动态模型聚合技术和跨云数据协调解决方案，以增强传统联邦学习范式的安全性、效率和可扩展性。此外，我们提出了一种混合聚合方案以减轻数据泄露威胁并优化模型更新的聚合，从而在模型效果和稳定性方面实现显著提升。实验结果表明，所提出模型的训练效率、隐私保护和模型准确率优于传统的联邦学习方法。', 'title_zh': '基于联邦学习的大型语言模型跨云隐私保护与协作训练研究'}
{'arxiv_id': 'arXiv:2503.12222', 'title': 'Evaluation-Time Policy Switching for Offline Reinforcement Learning', 'authors': 'Natinael Solomon Neggatu, Jeremie Houssineau, Giovanni Montana', 'link': 'https://arxiv.org/abs/2503.12222', 'abstract': 'Offline reinforcement learning (RL) looks at learning how to optimally solve tasks using a fixed dataset of interactions from the environment. Many off-policy algorithms developed for online learning struggle in the offline setting as they tend to over-estimate the behaviour of out of distributions actions. Existing offline RL algorithms adapt off-policy algorithms, employing techniques such as constraining the policy or modifying the value function to achieve good performance on individual datasets but struggle to adapt to different tasks or datasets of different qualities without tuning hyper-parameters. We introduce a policy switching technique that dynamically combines the behaviour of a pure off-policy RL agent, for improving behaviour, and a behavioural cloning (BC) agent, for staying close to the data. We achieve this by using a combination of epistemic uncertainty, quantified by our RL model, and a metric for aleatoric uncertainty extracted from the dataset. We show empirically that our policy switching technique can outperform not only the individual algorithms used in the switching process but also compete with state-of-the-art methods on numerous benchmarks. Our use of epistemic uncertainty for policy switching also allows us to naturally extend our method to the domain of offline to online fine-tuning allowing our model to adapt quickly and safely from online data, either matching or exceeding the performance of current methods that typically require additional modification or hyper-parameter fine-tuning.', 'abstract_zh': '离线强化学习（Off-policy Reinforcement Learning）旨在利用环境固定数据集中的互动来学习最优的任务解决方法。许多为在线学习设计的离策略算法在离线设置中表现不佳，因为它们往往会高估边缘分布行为的表现。现有的离线RL算法通过限制策略或修改价值函数来适应特定的数据集，以实现良好的性能，但在处理不同任务或质量不同的数据集时，通常需要调整超参数才能适应。我们提出了一种策略切换技术，该技术动态结合了纯离策略RL代理的行为改进和行为克隆代理的行为保持数据近似的特性。我们通过将我们的RL模型度量的本体不确定性与从数据集中提取的偶然不确定性度量相结合来实现这一点。实验证明，我们的策略切换技术不仅可以在切换过程中超越所使用的个体算法，还可以在多个基准测试中与最先进的方法竞争。我们使用本体不确定性进行策略切换，还使得我们的方法能够自然地扩展到离线到在线微调的领域，从而使我们的模型能够快速且安全地从在线数据中适应，能够匹配甚至超越通常需要额外修改或超参数微调的当前方法的性能。', 'title_zh': '离线强化学习中的评估时策略切换'}
{'arxiv_id': 'arXiv:2503.12211', 'title': 'Changing Base Without Losing Pace: A GPU-Efficient Alternative to MatMul in DNNs', 'authors': 'Nir Ailon, Akhiad Bercovich, Omri Weinstein', 'link': 'https://arxiv.org/abs/2503.12211', 'abstract': 'We propose a cheaper alternative bilinear operator to matrix-multiplication in deep neural networks (DNNs). Unlike many stubborn attempts to accelerate MatMuls in DNN inference, this operator is supported by capabilities of existing GPU hardware, most notably NVIDIA TensorCores. To our knowledge, this is the first GPU-native acceleration technique which \\emph{does not decrease} (in fact, increases) the number of trainable parameters of the network, mitigating the accuracy-loss of compression-based techniques. Hence, this operator is at the same time more expressive than MatMul, yet requires substantially \\emph{fewer} FLOPs to evaluate. We term this new operator \\emph{Strassen-Tile} (STL).\nThe main idea behind STL$(X,W)$ is a \\emph{local} change-of-basis (learnable encoder) on weights and activation \\emph{tiles}, after which we perform batched \\emph{elementwise} products between tiles, and a final decoding transformation (inspired by algebraic pipelines from fast matrix and polynomial multiplication).\nWe compare STL against two benchmarks. The first one is SoTA T2T-ViT on Imagenet-1K. Here we show that replacing \\emph{all} linear layers with STL and training from scratch, results in factor x2.7 reduction in FLOPs with a 0.5 \\emph{accuracy improvement}. Our second speed-accuracy comparison benchmark for pretrained LLMs is the most practical GPU-acceleration technique, \\twofour structured Sparsity. Finetuning TinyLlama \\cite{tinyllama24} with STL layers on the Slim Pajama dataset, achieves similar accuracy to 2:4, with x2.2 FLOP speedup compared to x1.7 of the latter.\nFinally, we discuss a group-theoretic approach for discovering \\emph{universal} encoders for STL, which could lead to fast \\emph{black-box} acceleration via approximate matrix-multiplication (AMM).', 'abstract_zh': '我们提出了一种用于深度神经网络中矩阵乘法的更便宜的双线性算子。这一算子通过现有GPU硬件的能力，尤其是NVIDIA TensorCores，支持了这种加速技术。据我们所知，这是首个在不减少（实际上增加了）网络可训练参数数量的情况下，减轻压缩技术精度损失的GPU原生加速技术。因此，这一算子在表达能力上比矩阵乘法更强，同时评估所需的基本运算单元远少于矩阵乘法。我们称这一新算子为Strassen-Tile (STL)。\n\nSTL$(X,W)$的主要思想是对权重和激活tile进行局部基底变换（可学习编码器），之后执行tile之间的批量逐元素乘法，并进行最终的解码变换（灵感来源于快速矩阵和多项式乘法的代数管道）。\n\n我们将STL与两个基准进行比较。第一个基准是SoTA T2T-ViT在Imagenet-1K上的表现。实验结果显示，将所有线性层替换为STL并从头训练，FLOPs减少了2.7倍，同时精度提高了0.5倍。我们的第二个速度-精度比较基准是预训练的LLM，即高效的GPU加速技术twofour结构化稀疏性。使用STL层对Slim Pajama数据集进行TinyLlama微调，实现了与2:4类似的效果，并且相比于2:4，性能提升了2.2倍。\n\n最后，我们讨论了一种群论方法，用于发现适用于STL的通用编码器，这一方法可能通过近似矩阵乘法（AMM）实现快速的黑盒加速。', 'title_zh': '保持节奏不变而换基底：DNN中MatMul的GPU高效替代方案'}
{'arxiv_id': 'arXiv:2503.12162', 'title': 'Probabilistic Graph Circuits: Deep Generative Models for Tractable Probabilistic Inference over Graphs', 'authors': 'Milan Papež, Martin Rektoris, Václav Šmídl, Tomáš Pevný', 'link': 'https://arxiv.org/abs/2503.12162', 'abstract': 'Deep generative models (DGMs) have recently demonstrated remarkable success in capturing complex probability distributions over graphs. Although their excellent performance is attributed to powerful and scalable deep neural networks, it is, at the same time, exactly the presence of these highly non-linear transformations that makes DGMs intractable. Indeed, despite representing probability distributions, intractable DGMs deny probabilistic foundations by their inability to answer even the most basic inference queries without approximations or design choices specific to a very narrow range of queries. To address this limitation, we propose probabilistic graph circuits (PGCs), a framework of tractable DGMs that provide exact and efficient probabilistic inference over (arbitrary parts of) graphs. Nonetheless, achieving both exactness and efficiency is challenging in the permutation-invariant setting of graphs. We design PGCs that are inherently invariant and satisfy these two requirements, yet at the cost of low expressive power. Therefore, we investigate two alternative strategies to achieve the invariance: the first sacrifices the efficiency, and the second sacrifices the exactness. We demonstrate that ignoring the permutation invariance can have severe consequences in anomaly detection, and that the latter approach is competitive with, and sometimes better than, existing intractable DGMs in the context of molecular graph generation.', 'abstract_zh': '可计算的概率图电路：兼具精确性和高效性的图生成模型', 'title_zh': '可计算图概率电路：用于图上可计算概率推理的深度生成模型'}
{'arxiv_id': 'arXiv:2503.12157', 'title': 'Weighted Graph Structure Learning with Attention Denoising for Node Classification', 'authors': 'Tingting Wang, Jiaxin Su, Haobing Liu, Ruobing Jiang', 'link': 'https://arxiv.org/abs/2503.12157', 'abstract': 'Node classification in graphs aims to predict the categories of unlabeled nodes by utilizing a small set of labeled nodes. However, weighted graphs often contain noisy edges and anomalous edge weights, which can distort fine-grained relationships between nodes and hinder accurate classification. We propose the Edge Weight-aware Graph Structure Learning (EWGSL) method, which combines weight learning and graph structure learning to address these issues. EWGSL improves node classification by redefining attention coefficients in graph attention networks to incorporate node features and edge weights. It also applies graph structure learning to sparsify attention coefficients and uses a modified InfoNCE loss function to enhance performance by adapting to denoised graph weights. Extensive experimental results show that EWGSL has an average Micro-F1 improvement of 17.8% compared with the best baseline.', 'abstract_zh': '图中节点分类旨在通过利用少量标记节点来预测未标记节点的类别。然而，加权图中经常包含噪声边和异常边权重，这会扭曲节点之间的细粒度关系并妨碍准确分类。我们提出了边权重感知图结构学习（EWGSL）方法，该方法结合了权重学习和图结构学习以解决这些问题。EWGSL 通过在图注意力网络中重新定义注意力系数来纳入节点特征和边权重，从而改善节点分类。它还应用图结构学习来稀疏化注意力系数，并使用修改后的 InfoNCE 损失函数来通过适应去噪后的图权重来增强性能。广泛的经验研究表明，与最佳基线相比，EWGSL 的平均 Micro-F1 改进了17.8%。', 'title_zh': '带有注意力去噪的加权图结构学习节点分类'}
{'arxiv_id': 'arXiv:2503.12143', 'title': 'Language Models for Automated Classification of Brain MRI Reports and Growth Chart Generation', 'authors': 'Maryam Daniali, Shivaram Karandikar, Dabriel Zimmerman, J. Eric Schmitt, Matthew J. Buczek, Benjamin Jung, Laura Mercedes, Jakob Seidlitz, Vanessa Troiani, Lena Dorfschmidt, Eren Kafadar, Remo Williams, Susan Sotardi, Arastoo Vosough, Scott Haag, Jenna M. Schabdach, Aaron Alexander-Bloch', 'link': 'https://arxiv.org/abs/2503.12143', 'abstract': 'Clinically acquired brain MRIs and radiology reports are valuable but underutilized resources due to the challenges of manual analysis and data heterogeneity. We developed fine-tuned language models (LMs) to classify brain MRI reports as normal (reports with limited pathology) or abnormal, fine-tuning BERT, BioBERT, ClinicalBERT, and RadBERT on 44,661 reports. We also explored the reasoning capabilities of a leading LM, Gemini 1.5-Pro, for normal report categorization. Automated image processing and modeling generated brain growth charts from LM-classified normal scans, comparing them to human-derived charts. Fine-tuned LMs achieved high classification performance (F1-Score >97%), with unbalanced training mitigating class imbalance. Performance was robust on out-of-distribution data, with full text outperforming summary (impression) sections. Gemini 1.5-Pro showed a promising categorization performance, especially with clinical inference. LM-derived brain growth charts were nearly identical to human-annotated charts (r = 0.99, p < 2.2e-16). Our LMs offer scalable analysis of radiology reports, enabling automated classification of brain MRIs in large datasets. One application is automated generation of brain growth charts for benchmarking quantitative image features. Further research is needed to address data heterogeneity and optimize LM reasoning.', 'abstract_zh': '临床获取的脑MR图像和放射学报告资源丰富但未被充分利用，主要是由于手动分析的挑战和数据异质性。我们开发了微调语言模型（LMs）来将脑MRI报告分类为正常（有限病理学）或异常，我们对44,661份报告微调了BERT、BioBERT、ClinicalBERT和RadBERT。我们还探索了顶级LM Gemini 1.5-Pro在正常报告分类中的推理能力。自动化图像处理和建模生成了从LM分类的正常扫描中得出的脑部生长图表，并与人类生成的图表进行了比较。微调后的LMs达到了很高的分类性能（F1-Score >97%），通过不平衡训练缓解了类别不平衡问题。其在外域数据上的性能稳健，完整文本优于摘要（印象）部分。Gemini 1.5-Pro在分类性能上表现出色，特别是在临床推理方面。从LM生成的脑部生长图表几乎与人类注释的图表相同（r = 0.99, p < 2.2e-16）。我们的LMs提供了放射学报告的可扩展分析，使可以自动化分类大量数据集中的脑MRI。一个应用是生成脑部生长图表以对标定量图像特征。然而，仍需进一步研究以解决数据异质性并优化LM推理。', 'title_zh': '用于脑 MRI 报告自动化分类的语言模型及生长图表生成'}
{'arxiv_id': 'arXiv:2503.12131', 'title': 'DiffGAP: A Lightweight Diffusion Module in Contrastive Space for Bridging Cross-Model Gap', 'authors': 'Shentong Mo, Zehua Chen, Fan Bao, Jun Zhu', 'link': 'https://arxiv.org/abs/2503.12131', 'abstract': 'Recent works in cross-modal understanding and generation, notably through models like CLAP (Contrastive Language-Audio Pretraining) and CAVP (Contrastive Audio-Visual Pretraining), have significantly enhanced the alignment of text, video, and audio embeddings via a single contrastive loss. However, these methods often overlook the bidirectional interactions and inherent noises present in each modality, which can crucially impact the quality and efficacy of cross-modal integration. To address this limitation, we introduce DiffGAP, a novel approach incorporating a lightweight generative module within the contrastive space. Specifically, our DiffGAP employs a bidirectional diffusion process tailored to bridge the cross-modal gap more effectively. This involves a denoising process on text and video embeddings conditioned on audio embeddings and vice versa, thus facilitating a more nuanced and robust cross-modal interaction. Our experimental results on VGGSound and AudioCaps datasets demonstrate that DiffGAP significantly improves performance in video/text-audio generation and retrieval tasks, confirming its effectiveness in enhancing cross-modal understanding and generation capabilities.', 'abstract_zh': 'Recent Works in Cross-Modal Understanding and Generation Through Models Like CLAP and CAVP Have Significantly Enhanced the Alignment of Text, Video, and Audio Embeddings via a Single Contrastive Loss, but Often Overlook Bidirectional Interactions and Inherent Noises in Each Modality. To Address This Limitation, We Introduce DiffGAP, a Novel Approach Incorporating a Lightweight Generative Module Within the Contrastive Space.', 'title_zh': 'DiffGAP: 对比空间中的轻量级扩散模块，用于bridging跨模型差距'}
{'arxiv_id': 'arXiv:2503.12127', 'title': 'Hyperbolic Safety-Aware Vision-Language Models', 'authors': 'Tobia Poppi, Tejaswi Kasarla, Pascal Mettes, Lorenzo Baraldi, Rita Cucchiara', 'link': 'https://arxiv.org/abs/2503.12127', 'abstract': "Addressing the retrieval of unsafe content from vision-language models such as CLIP is an important step towards real-world integration. Current efforts have relied on unlearning techniques that try to erase the model's knowledge of unsafe concepts. While effective in reducing unwanted outputs, unlearning limits the model's capacity to discern between safe and unsafe content. In this work, we introduce a novel approach that shifts from unlearning to an awareness paradigm by leveraging the inherent hierarchical properties of the hyperbolic space. We propose to encode safe and unsafe content as an entailment hierarchy, where both are placed in different regions of hyperbolic space. Our HySAC, Hyperbolic Safety-Aware CLIP, employs entailment loss functions to model the hierarchical and asymmetrical relations between safe and unsafe image-text pairs. This modelling, ineffective in standard vision-language models due to their reliance on Euclidean embeddings, endows the model with awareness of unsafe content, enabling it to serve as both a multimodal unsafe classifier and a flexible content retriever, with the option to dynamically redirect unsafe queries toward safer alternatives or retain the original output. Extensive experiments show that our approach not only enhances safety recognition but also establishes a more adaptable and interpretable framework for content moderation in vision-language models. Our source code is available at this https URL.", 'abstract_zh': '基于CLIP等视力-语言模型的不安全内容检索改进：从遗忘到 Awareness 帕累托的新型方法', 'title_zh': '超曲面安全意识视觉-语言模型'}
{'arxiv_id': 'arXiv:2503.12125', 'title': 'Robust Isolation Forest using Soft Sparse Random Projection and Valley Emphasis Method', 'authors': 'Hun Kang, Kyoungok Kim', 'link': 'https://arxiv.org/abs/2503.12125', 'abstract': 'Isolation Forest (iForest) is an unsupervised anomaly detection algorithm designed to effectively detect anomalies under the assumption that anomalies are ``few and different." Various studies have aimed to enhance iForest, but the resulting algorithms often exhibited significant performance disparities across datasets. Additionally, the challenge of isolating rare and widely distributed anomalies persisted in research focused on improving splits. To address these challenges, we introduce Robust iForest (RiForest). RiForest leverages both existing features and random hyperplanes obtained through soft sparse random projection to identify superior split features for anomaly detection, independent of datasets. It utilizes the underutilized valley emphasis method for optimal split point determination and incorporates sparsity randomization in soft sparse random projection for enhanced anomaly detection robustness. Across 24 benchmark datasets, experiments demonstrate RiForest\'s consistent outperformance of existing algorithms in anomaly detection, emphasizing stability and robustness to noise variables.', 'abstract_zh': 'Robust iForest (RiForest): An Enhanced Anomaly Detection Algorithm', 'title_zh': '鲁棒孤立森林基于软稀疏随机投影和谷值强调方法'}
{'arxiv_id': 'arXiv:2503.12123', 'title': 'MT-RewardTree: A Comprehensive Framework for Advancing LLM-Based Machine Translation via Reward Modeling', 'authors': 'Zhaopeng Feng, Jiahan Ren, Jiayuan Su, Jiamei Zheng, Zhihang Tang, Hongwei Wang, Zuozhu Liu', 'link': 'https://arxiv.org/abs/2503.12123', 'abstract': 'Process reward models (PRMs) have shown success in complex reasoning tasks for large language models (LLMs). However, their application to machine translation (MT) remains underexplored due to the lack of systematic methodologies and evaluation benchmarks. To address this gap, we introduce \\textbf{MT-RewardTree}, a comprehensive framework for constructing, evaluating, and deploying process reward models in MT. Unlike traditional vanilla preference pair construction, we propose a novel method for automatically generating token-level preference pairs using approximate Monte Carlo Tree Search (MCTS), which mitigates the prohibitive cost of human annotation for fine-grained steps. Then, we establish the first MT-specific reward model benchmark and provide a systematic comparison of different reward modeling architectures, revealing that token-level supervision effectively captures fine-grained preferences. Experimental results demonstrate that our MT-PRM-Qwen-2.5-3B achieves state-of-the-art performance in both token-level and sequence-level evaluation given the same input prefix. Furthermore, we showcase practical applications where PRMs enable test-time alignment for LLMs without additional alignment training and significantly improve performance in hypothesis ensembling. Our work provides valuable insights into the role of reward models in MT research. Our code and data are released in \\href{this https URL}{this https URL\\_RewardTreePage}.', 'abstract_zh': '用于机器翻译的process奖励模型框架：MT-RewardTree', 'title_zh': 'MT-RewardTree：一种基于奖励建模推动大语言模型驱动机器翻译发展的综合框架'}
{'arxiv_id': 'arXiv:2503.12122', 'title': 'ICCO: Learning an Instruction-conditioned Coordinator for Language-guided Task-aligned Multi-robot Control', 'authors': 'Yoshiki Yano, Kazuki Shibata, Maarten Kokshoorn, Takamitsu Matsubara', 'link': 'https://arxiv.org/abs/2503.12122', 'abstract': 'Recent advances in Large Language Models (LLMs) have permitted the development of language-guided multi-robot systems, which allow robots to execute tasks based on natural language instructions. However, achieving effective coordination in distributed multi-agent environments remains challenging due to (1) misalignment between instructions and task requirements and (2) inconsistency in robot behaviors when they independently interpret ambiguous instructions. To address these challenges, we propose Instruction-Conditioned Coordinator (ICCO), a Multi-Agent Reinforcement Learning (MARL) framework designed to enhance coordination in language-guided multi-robot systems. ICCO consists of a Coordinator agent and multiple Local Agents, where the Coordinator generates Task-Aligned and Consistent Instructions (TACI) by integrating language instructions with environmental states, ensuring task alignment and behavioral consistency. The Coordinator and Local Agents are jointly trained to optimize a reward function that balances task efficiency and instruction following. A Consistency Enhancement Term is added to the learning objective to maximize mutual information between instructions and robot behaviors, further improving coordination. Simulation and real-world experiments validate the effectiveness of ICCO in achieving language-guided task-aligned multi-robot control. The demonstration can be found at this https URL.', 'abstract_zh': 'Recent Advances in Large Language Models Enabling Language-Guided Multi-Robot Systems and Enhancing Coordination in Multi-Agent Environments Through Instruction-Conditioned Coordinator (ICCO)', 'title_zh': 'ICCO：学习一种基于指令的协调器实现语言导向的任务对齐多机器人控制'}
{'arxiv_id': 'arXiv:2503.12115', 'title': 'Universal Speech Token Learning via Low-Bitrate Neural Codec and Pretrained Representations', 'authors': 'Xue Jiang, Xiulian Peng, Yuan Zhang, Yan Lu', 'link': 'https://arxiv.org/abs/2503.12115', 'abstract': 'Current large speech language models are mainly based on semantic tokens from discretization of self-supervised learned representations and acoustic tokens from a neural codec, following a semantic-modeling and acoustic-synthesis paradigm. However, semantic tokens discard paralinguistic attributes of speakers that is important for natural spoken communication, while prompt-based acoustic synthesis from semantic tokens has limits in recovering paralinguistic details and suffers from robustness issues, especially when there are domain gaps between the prompt and the target. This paper unifies two types of tokens and proposes the UniCodec, a universal speech token learning that encapsulates all semantics of speech, including linguistic and paralinguistic information, into a compact and semantically-disentangled unified token. Such a unified token can not only benefit speech language models in understanding with paralinguistic hints but also help speech generation with high-quality output. A low-bitrate neural codec is leveraged to learn such disentangled discrete representations at global and local scales, with knowledge distilled from self-supervised learned features. Extensive evaluations on multilingual datasets demonstrate its effectiveness in generating natural, expressive and long-term consistent output quality with paralinguistic attributes well preserved in several speech processing tasks.', 'abstract_zh': '当前的大规模语言模型主要基于自监督学习表示的语义token和神经编解码器的声学token进行离散化，遵循语义建模和声学合成的范式。然而，语义token舍弃了影响自然口语交流的语用属性，而基于提示的声学合成从语义token恢复语用细节的能力有限，并且在提示与目标存在领域差异时尤其存在稳健性问题。本文统一了两种类型的token，提出了统一编解码器UniCodec，这是一种统一的语音token学习，将所有语言和非语言信息紧凑且语义地封装到单一token中。这种统一token不仅有助于语音语言模型在使用语用提示时的理解，还能帮助高质量的语音生成。利用低比特率神经编解码器在全局和局部尺度上学习语义分离的离散表示，并从自监督学习特征中提取知识。在多种语音处理任务中的多语言数据集上的广泛评估表明，UniCodec能够生成自然、表达性强且长时一致的输出，同时保留了语用属性。', 'title_zh': '低比特率神经编解码器和预训练表示的通用语音 token 学习'}
{'arxiv_id': 'arXiv:2503.12108', 'title': 'RECSIP: REpeated Clustering of Scores Improving the Precision', 'authors': 'André Schamschurko, Nenad Petrovic, Alois Christian Knoll', 'link': 'https://arxiv.org/abs/2503.12108', 'abstract': "The latest research on Large Language Models (LLMs) has demonstrated significant advancement in the field of Natural Language Processing (NLP). However, despite this progress, there is still a lack of reliability in these models. This is due to the stochastic architecture of LLMs, which presents a challenge for users attempting to ascertain the reliability of a model's response. These responses may cause serious harm in high-risk environments or expensive failures in industrial contexts. Therefore, we introduce the framework REpeated Clustering of Scores Improving the Precision (RECSIP) which focuses on improving the precision of LLMs by asking multiple models in parallel, scoring and clustering their responses to ensure a higher reliability on the response. The evaluation of our reference implementation recsip on the benchmark MMLU-Pro using the models GPT-4o, Claude and Gemini shows an overall increase of 5.8 per cent points compared to the best used model.", 'abstract_zh': '大型语言模型（LLMs）的最新研究在自然语言处理（NLP）领域展现了显著的进步。然而，尽管取得了这些进展，这些模型仍缺乏可靠性。这归因于LLMs的随机性架构，这给用户确定模型响应可靠性的过程带来了挑战。这些响应在高风险环境或工业场景中可能导致严重的危害或昂贵的失败。因此，我们提出了一种名为REpeated Clustering of Scores Improving the Precision (RECSIP) 的框架，该框架通过并行询问多个模型、评分和聚类其响应来提高LLMs的精度，从而确保响应的更高可靠性。我们在基准MMLU-Pro上对参考实现recsip的评估显示，与所使用的最佳模型相比，其准确率提高了5.8个百分点。', 'title_zh': 'RECSIP: 重复聚类改进精度'}
{'arxiv_id': 'arXiv:2503.12107', 'title': 'ChronosX: Adapting Pretrained Time Series Models with Exogenous Variables', 'authors': 'Sebastian Pineda Arango, Pedro Mercado, Shubham Kapoor, Abdul Fatir Ansari, Lorenzo Stella, Huibin Shen, Hugo Senetaire, Caner Turkmen, Oleksandr Shchur, Danielle C. Maddix, Michael Bohlke-Schneider, Yuyang Wang, Syama Sundar Rangapuram', 'link': 'https://arxiv.org/abs/2503.12107', 'abstract': 'Covariates provide valuable information on external factors that influence time series and are critical in many real-world time series forecasting tasks. For example, in retail, covariates may indicate promotions or peak dates such as holiday seasons that heavily influence demand forecasts. Recent advances in pretraining large language model architectures for time series forecasting have led to highly accurate forecasters. However, the majority of these models do not readily use covariates as they are often specific to a certain task or domain. This paper introduces a new method to incorporate covariates into pretrained time series forecasting models. Our proposed approach incorporates covariate information into pretrained forecasting models through modular blocks that inject past and future covariate information, without necessarily modifying the pretrained model in consideration. In order to evaluate our approach, we introduce a benchmark composed of 32 different synthetic datasets with varying dynamics to evaluate the effectivity of forecasting models with covariates. Extensive evaluations on both synthetic and real datasets show that our approach effectively incorporates covariate information into pretrained models, outperforming existing baselines.', 'abstract_zh': '协变量提供了影响时间序列的外部因素的宝贵信息，在许多实际时间序列预测任务中至关重要。本论文提出了一种新方法，将协变量纳入预训练的时间序列预测模型。我们提出的方法通过模块化块将过去的和未来的协变量信息注入预训练的预测模型中，而无需修改所考虑的预训练模型。为了评估该方法，我们引入了一个由32个不同动态的合成数据集组成的基准，以评估包含协变量的预测模型的效果。在合成数据集和真实数据集上的广泛评估表明，我们的方法有效地将协变量信息纳入预训练模型，并优于现有基线。', 'title_zh': 'ChronosX：适应外生变量的预训练时间序列模型'}
{'arxiv_id': 'arXiv:2503.12080', 'title': 'Comparing Human Expertise and Large Language Models Embeddings in Content Validity Assessment of Personality Tests', 'authors': 'Nicola Milano, Michela Ponticorvo, Davide Marocco', 'link': 'https://arxiv.org/abs/2503.12080', 'abstract': 'In this article we explore the application of Large Language Models (LLMs) in assessing the content validity of psychometric instruments, focusing on the Big Five Questionnaire (BFQ) and Big Five Inventory (BFI). Content validity, a cornerstone of test construction, ensures that psychological measures adequately cover their intended constructs. Using both human expert evaluations and advanced LLMs, we compared the accuracy of semantic item-construct alignment. Graduate psychology students employed the Content Validity Ratio (CVR) to rate test items, forming the human baseline. In parallel, state-of-the-art LLMs, including multilingual and fine-tuned models, analyzed item embeddings to predict construct mappings. The results reveal distinct strengths and limitations of human and AI approaches. Human validators excelled in aligning the behaviorally rich BFQ items, while LLMs performed better with the linguistically concise BFI items. Training strategies significantly influenced LLM performance, with models tailored for lexical relationships outperforming general-purpose LLMs. Here we highlights the complementary potential of hybrid validation systems that integrate human expertise and AI precision. The findings underscore the transformative role of LLMs in psychological assessment, paving the way for scalable, objective, and robust test development methodologies.', 'abstract_zh': '本文探讨了大型语言模型（LLMs）在评估心理测量工具内容效度中的应用，重点关注五大人格问卷（BFQ）和五大人格问卷（BFI）。内容效度是测试构建的基石，确保心理测量工具充分覆盖其预期的心理结构。利用人类专家评估和先进的LLM，我们比较了语义项目-构念对齐的准确性。研究生心理学学生使用内容效度比（CVR）评估测试项目，形成人类基准。同时，最先进的LLM，包括多语言和细调模型，分析项目嵌入以预测构念映射。研究结果揭示了人类和AI方法的各自优势和局限性。人类验证者在对行为丰富的BFQ项目进行对齐方面表现出色，而LLM在处理语言简洁的BFI项目方面表现更好。训练策略显著影响了LLM的性能，针对词汇关系的模型优于通用LLM。本文强调了结合人类专业知识和AI精确性的混合验证系统的互补潜力。研究结果凸显了LLM在心理评估中的变革作用，为可扩展、客观和稳健的测试开发方法铺平了道路。', 'title_zh': '比较人类专家与大型语言模型嵌入在人格测验内容效度评估中的表现'}
{'arxiv_id': 'arXiv:2503.12077', 'title': 'V-Stylist: Video Stylization via Collaboration and Reflection of MLLM Agents', 'authors': 'Zhengrong Yue, Shaobin Zhuang, Kunchang Li, Yanbo Ding, Yali Wang', 'link': 'https://arxiv.org/abs/2503.12077', 'abstract': 'Despite the recent advancement in video stylization, most existing methods struggle to render any video with complex transitions, based on an open style description of user query. To fill this gap, we introduce a generic multi-agent system for video stylization, V-Stylist, by a novel collaboration and reflection paradigm of multi-modal large language models. Specifically, our V-Stylist is a systematical workflow with three key roles: (1) Video Parser decomposes the input video into a number of shots and generates their text prompts of key shot content. Via a concise video-to-shot prompting paradigm, it allows our V-Stylist to effectively handle videos with complex transitions. (2) Style Parser identifies the style in the user query and progressively search the matched style model from a style tree. Via a robust tree-of-thought searching paradigm, it allows our V-Stylist to precisely specify vague style preference in the open user query. (3) Style Artist leverages the matched model to render all the video shots into the required style. Via a novel multi-round self-reflection paradigm, it allows our V-Stylist to adaptively adjust detail control, according to the style requirement. With such a distinct design of mimicking human professionals, our V-Stylist achieves a major breakthrough over the primary challenges for effective and automatic video stylization. Moreover,we further construct a new benchmark Text-driven Video Stylization Benchmark (TVSBench), which fills the gap to assess stylization of complex videos on open user queries. Extensive experiments show that, V-Stylist achieves the state-of-the-art, e.g.,V-Stylist surpasses FRESCO and ControlVideo by 6.05% and 4.51% respectively in overall average metrics, marking a significant advance in video stylization.', 'abstract_zh': '基于多模态大语言模型新颖协作与反思范式的通用多 agent 视频风格化系统 V-Stylist', 'title_zh': 'V-Stylist: 视频风格化 via MLLM 剂量的协作与反思'}
{'arxiv_id': 'arXiv:2503.12065', 'title': 'Maritime Mission Planning for Unmanned Surface Vessel using Large Language Model', 'authors': 'Muhayy Ud Din, Waseem Akram, Ahsan B Bakht, Yihao Dong, Irfan Hussain', 'link': 'https://arxiv.org/abs/2503.12065', 'abstract': 'Unmanned Surface Vessels (USVs) are essential for various maritime operations. USV mission planning approach offers autonomous solutions for monitoring, surveillance, and logistics. Existing approaches, which are based on static methods, struggle to adapt to dynamic environments, leading to suboptimal performance, higher costs, and increased risk of failure. This paper introduces a novel mission planning framework that uses Large Language Models (LLMs), such as GPT-4, to address these challenges. LLMs are proficient at understanding natural language commands, executing symbolic reasoning, and flexibly adjusting to changing situations. Our approach integrates LLMs into maritime mission planning to bridge the gap between high-level human instructions and executable plans, allowing real-time adaptation to environmental changes and unforeseen obstacles. In addition, feedback from low-level controllers is utilized to refine symbolic mission plans, ensuring robustness and adaptability. This framework improves the robustness and effectiveness of USV operations by integrating the power of symbolic planning with the reasoning abilities of LLMs. In addition, it simplifies the mission specification, allowing operators to focus on high-level objectives without requiring complex programming. The simulation results validate the proposed approach, demonstrating its ability to optimize mission execution while seamlessly adapting to dynamic maritime conditions.', 'abstract_zh': '无人表面船舶（USVs）在各种海洋操作中至关重要。USV任务规划方法提供了监测、监视和物流的自主解决方案。现有的基于静态方法的方法难以适应动态环境，导致性能不佳、成本较高以及失败风险增加。本文介绍了一种新的任务规划框架，该框架利用大型语言模型（LLMs）如GPT-4来解决这些挑战。LLMs擅长理解自然语言命令、执行符号推理并灵活调整以适应变化的情况。我们的方法将LLMs集成到海洋任务规划中，以弥合高级别人类指令与可执行计划之间的差距，实现对环境变化和未预见障碍的实时适应。此外，低级控制器的反馈被用来细化符号任务计划，以确保系统的稳健性和适应性。该框架通过结合符号规划的强大功能和LLMs的推理能力，提高了USV操作的稳健性和有效性。此外，它简化了任务规范，使操作员能够专注于高层次目标，而无需进行复杂的编程。仿真结果验证了所提出的方案，证明它能够在动态海洋条件下无缝优化任务执行。', 'title_zh': '使用大型语言模型的无人水面船航海任务规划'}
{'arxiv_id': 'arXiv:2503.12058', 'title': 'Revisiting Training-Inference Trigger Intensity in Backdoor Attacks', 'authors': 'Chenhao Lin, Chenyang Zhao, Shiwei Wang, Longtian Wang, Chao Shen, Zhengyu Zhao', 'link': 'https://arxiv.org/abs/2503.12058', 'abstract': 'Backdoor attacks typically place a specific trigger on certain training data, such that the model makes prediction errors on inputs with that trigger during inference. Despite the core role of the trigger, existing studies have commonly believed a perfect match between training-inference triggers is optimal. In this paper, for the first time, we systematically explore the training-inference trigger relation, particularly focusing on their mismatch, based on a Training-Inference Trigger Intensity Manipulation (TITIM) workflow. TITIM specifically investigates the training-inference trigger intensity, such as the size or the opacity of a trigger, and reveals new insights into trigger generalization and overfitting.\nThese new insights challenge the above common belief by demonstrating that the training-inference trigger mismatch can facilitate attacks in two practical scenarios, posing more significant security threats than previously thought. First, when the inference trigger is fixed, using training triggers with mixed intensities leads to stronger attacks than using any single intensity. For example, on CIFAR-10 with ResNet-18, mixing training triggers with 1.0 and 0.1 opacities improves the worst-case attack success rate (ASR) (over different testing opacities) of the best single-opacity attack from 10.61\\% to 92.77\\%. Second, intentionally using certain mismatched training-inference triggers can improve the attack stealthiness, i.e., better bypassing defenses. For example, compared to the training/inference intensity of 1.0/1.0, using 1.0/0.7 decreases the area under the curve (AUC) of the Scale-Up defense from 0.96 to 0.62, while maintaining a high attack ASR (99.65\\% vs. 91.62\\%). The above new insights are validated to be generalizable across different backdoor attacks, models, datasets, tasks, and (digital/physical) domains.', 'abstract_zh': 'Backdoor攻击通常在特定训练数据上放置一个特定触发器，使得模型在推理时对于带有该触发器的输入产生预测错误。尽管触发器的核心作用已被公认，但现有研究普遍认为训练-推理触发器的完美匹配是最优的。本文首次系统地探索了训练-推理触发器的关系，特别是关注它们的不匹配情况，基于一次训练-推理触发器强度操控（TITIM）工作流程。TITIM具体研究了训练-推理触发器的强度，如触发器的大小或透明度，并揭示了触发器泛化和过拟合的新见解。这些新的见解通过证明训练-推理触发器不匹配在两种实际场景中能够促进攻击，挑战了上述普遍信念，提高了潜在的安全威胁。首先，当推理触发器固定时，使用混合强度的训练触发器比使用任何单一强度的效果更强。例如，在ResNet-18上的CIFAR-10数据集，混合使用0.1和1.0透明度的训练触发器将最佳单一透明度攻击的最坏情况攻击成功率（ASR）从10.61%提高到92.77%。其次，有意使用特定不匹配的训练-推理触发器可以提高攻击的隐蔽性，即更好地绕过防守。例如，相比训练/推理强度为1.0/1.0，使用1.0/0.7降低了Scale-Up防守的AUC从0.96到0.62，同时保持较高的攻击ASR（99.65% vs. 91.62%）。上述新的见解被验证为在不同的后门攻击、模型、数据集、任务及（数字/物理）领域中具有普适性。', 'title_zh': '回顾训练-推理触发强度在后门攻击中的作用'}
{'arxiv_id': 'arXiv:2503.12053', 'title': 'Ferret: An Efficient Online Continual Learning Framework under Varying Memory Constraints', 'authors': 'Yuhao Zhou, Yuxin Tian, Jindi Lv, Mingjia Shi, Yuanxi Li, Qing Ye, Shuhao Zhang, Jiancheng Lv', 'link': 'https://arxiv.org/abs/2503.12053', 'abstract': "In the realm of high-frequency data streams, achieving real-time learning within varying memory constraints is paramount. This paper presents Ferret, a comprehensive framework designed to enhance online accuracy of Online Continual Learning (OCL) algorithms while dynamically adapting to varying memory budgets. Ferret employs a fine-grained pipeline parallelism strategy combined with an iterative gradient compensation algorithm, ensuring seamless handling of high-frequency data with minimal latency, and effectively counteracting the challenge of stale gradients in parallel training. To adapt to varying memory budgets, its automated model partitioning and pipeline planning optimizes performance regardless of memory limitations. Extensive experiments across 20 benchmarks and 5 integrated OCL algorithms show Ferret's remarkable efficiency, achieving up to 3.7$\\times$ lower memory overhead to reach the same online accuracy compared to competing methods. Furthermore, Ferret consistently outperforms these methods across diverse memory budgets, underscoring its superior adaptability. These findings position Ferret as a premier solution for efficient and adaptive OCL framework in real-time environments.", 'abstract_zh': '在高频率数据流领域，实现不同内存约束下的实时学习至关重要。本文提出Ferret，一种全面框架，旨在提升在线连续学习（OCL）算法的在线准确性，同时动态适应不同的内存预算。Ferret采用细粒度管道并行策略结合迭代梯度补偿算法，确保在最小延迟的情况下无缝处理高频率数据，并有效地克服平行训练中过时梯度的挑战。为了适应不同的内存预算，其自动模型分割和管道规划优化了性能，不受内存限制的影响。在20个基准和5种集成OCL算法上的广泛实验表明，Ferret具有显著的效率，与竞争方法相比，实现相同在线准确性时的内存开销低至3.7倍。此外，Ferret在不同内存预算下也始终表现出优越的性能，突显了其卓越的适应性。这些发现将Ferret定位为实时环境中高效且适应性强的OCL框架的首选解决方案。', 'title_zh': 'Ferret: 一种在变化的内存约束下高效的在线连续学习框架'}
{'arxiv_id': 'arXiv:2503.12043', 'title': 'An LLM-Integrated Framework for Completion, Management, and Tracing of STPA', 'authors': 'Ali Raeisdanaei, Juho Kim, Michael Liao, Sparsh Kochhar', 'link': 'https://arxiv.org/abs/2503.12043', 'abstract': 'In many safety-critical engineering domains, hazard analysis techniques are an essential part of requirement elicitation. Of the methods proposed for this task, STPA (System-Theoretic Process Analysis) represents a relatively recent development in the field. The completion, management, and traceability of this hazard analysis technique present a time-consuming challenge to the requirements and safety engineers involved. In this paper, we introduce a free, open-source software framework to build STPA models with several automated workflows powered by large language models (LLMs). In past works, LLMs have been successfully integrated into a myriad of workflows across various fields. Here, we demonstrate that LLMs can be used to complete tasks associated with STPA with a high degree of accuracy, saving the time and effort of the human engineers involved. We experimentally validate our method on real-world STPA models built by requirement engineers and researchers. The source code of our software framework is available at the following link: this https URL.', 'abstract_zh': '在许多安全关键工程领域，危害分析技术是需求 elicitation 的一个重要组成部分。在为此任务提出的方法中，系统理论过程分析（STPA）代表了该领域的相对较新发展。进行、管理和追溯这种危害分析技术对涉及的需求和安全工程师来说是一项耗时的挑战。本文介绍了一种基于免费开源软件框架和大型语言模型（LLMs）驱动的自动化工作流来构建STPA模型的方法。在以往的研究中，LLMs已经在多个领域的工作流中取得了成功集成。在这里，我们证明LLMs可以高精度地完成与STPA相关的工作，从而节省人类工程师的时间和精力。我们通过真实世界的STPA模型对我们的方法进行了实验验证，这些模型由需求工程师和研究人员构建。我们的软件框架的源代码可通过以下链接获取：this https URL。', 'title_zh': '一种集成LLM的STPA完成、管理和追踪框架'}
{'arxiv_id': 'arXiv:2503.12037', 'title': 'Unsupervised Graph Anomaly Detection via Multi-Hypersphere Heterophilic Graph Learning', 'authors': 'Hang Ni, Jindong Han, Nengjun Zhu, Hao Liu', 'link': 'https://arxiv.org/abs/2503.12037', 'abstract': 'Graph Anomaly Detection (GAD) plays a vital role in various data mining applications such as e-commerce fraud prevention and malicious user detection. Recently, Graph Neural Network (GNN) based approach has demonstrated great effectiveness in GAD by first encoding graph data into low-dimensional representations and then identifying anomalies under the guidance of supervised or unsupervised signals. However, existing GNN-based approaches implicitly follow the homophily principle (i.e., the "like attracts like" phenomenon) and fail to learn discriminative embedding for anomalies that connect vast normal nodes. Moreover, such approaches identify anomalies in a unified global perspective but overlook diversified abnormal patterns conditioned on local graph context, leading to suboptimal performance. To overcome the aforementioned limitations, in this paper, we propose a Multi-hypersphere Heterophilic Graph Learning (MHetGL) framework for unsupervised GAD. Specifically, we first devise a Heterophilic Graph Encoding (HGE) module to learn distinguishable representations for potential anomalies by purifying and augmenting their neighborhood in a fully unsupervised manner. Then, we propose a Multi-Hypersphere Learning (MHL) module to enhance the detection capability for context-dependent anomalies by jointly incorporating critical patterns from both global and local perspectives. Extensive experiments on ten real-world datasets show that MHetGL outperforms 14 baselines. Our code is publicly available at this https URL.', 'abstract_zh': '多超球面异ophilous图学习的无监督图异常检测', 'title_zh': '无监督图异常检测 via 多超球体异质图学习'}
{'arxiv_id': 'arXiv:2503.12034', 'title': 'Real-Time Manipulation Action Recognition with a Factorized Graph Sequence Encoder', 'authors': 'Enes Erdogan, Eren Erdal Aksoy, Sanem Sariel', 'link': 'https://arxiv.org/abs/2503.12034', 'abstract': 'Recognition of human manipulation actions in real-time is essential for safe and effective human-robot interaction and collaboration. The challenge lies in developing a model that is both lightweight enough for real-time execution and capable of generalization. While some existing methods in the literature can run in real-time, they struggle with temporal scalability, i.e., they fail to adapt to long-duration manipulations effectively. To address this, leveraging the generalizable scene graph representations, we propose a new Factorized Graph Sequence Encoder network that not only runs in real-time but also scales effectively in the temporal dimension, thanks to its factorized encoder architecture. Additionally, we introduce Hand Pooling operation, a simple pooling operation for more focused extraction of the graph-level embeddings. Our model outperforms the previous state-of-the-art real-time approach, achieving a 14.3\\% and 5.6\\% improvement in F1-macro score on the KIT Bimanual Action (Bimacs) Dataset and Collaborative Action (CoAx) Dataset, respectively. Moreover, we conduct an extensive ablation study to validate our network design choices. Finally, we compare our model with its architecturally similar RGB-based model on the Bimacs dataset and show the limitations of this model in contrast to ours on such an object-centric manipulation dataset.', 'abstract_zh': '实时识别人类操作动作对于安全有效的机器人交互与协作至关重要。挑战在于开发一种既轻量级以支持实时执行又具有泛化能力的模型。虽然文献中的一些现有方法可以实时运行，但在时间维度的可扩展性上存在困难，即它们不能有效地适应长时间的操作。为此，我们利用可泛化的场景图表示，提出了一种新的因子化图序列编码网络，该网络不仅能够实时运行，还能够在时间维度上有效扩展，得益于其因子化的编码架构。此外，我们引入了手部聚合操作，这是一种更专注于图级嵌入提取的简单聚合并操作。我们的模型在KIT双臂动作（Bimacs）数据集和协作动作（CoAx）数据集上的F1-宏观分数上分别超过了之前的最先进实时方法14.3%和5.6%。此外，我们进行了广泛的消融研究以验证我们的网络设计选择。最后，我们在Bimacs数据集上将我们的模型与其架构相似的RGB基模型进行了比较，展示了该模型在这种以物体为中心的操作数据集上的局限性，相比之下，我们的模型表现更好。', 'title_zh': '实时操作动作识别的因子化图序列编码器'}
{'arxiv_id': 'arXiv:2503.12020', 'title': 'Variance-Dependent Regret Lower Bounds for Contextual Bandits', 'authors': 'Jiafan He, Quanquan Gu', 'link': 'https://arxiv.org/abs/2503.12020', 'abstract': 'Variance-dependent regret bounds for linear contextual bandits, which improve upon the classical $\\tilde{O}(d\\sqrt{K})$ regret bound to $\\tilde{O}(d\\sqrt{\\sum_{k=1}^K\\sigma_k^2})$, where $d$ is the context dimension, $K$ is the number of rounds, and $\\sigma^2_k$ is the noise variance in round $k$, has been widely studied in recent years. However, most existing works focus on the regret upper bounds instead of lower bounds. To our knowledge, the only lower bound is from Jia et al. (2024), which proved that for any eluder dimension $d_{\\textbf{elu}}$ and total variance budget $\\Lambda$, there exists an instance with $\\sum_{k=1}^K\\sigma_k^2\\leq \\Lambda$ for which any algorithm incurs a variance-dependent lower bound of $\\Omega(\\sqrt{d_{\\textbf{elu}}\\Lambda})$. However, this lower bound has a $\\sqrt{d}$ gap with existing upper bounds. Moreover, it only considers a fixed total variance budget $\\Lambda$ and does not apply to a general variance sequence $\\{\\sigma_1^2,\\ldots,\\sigma_K^2\\}$. In this paper, to overcome the limitations of Jia et al. (2024), we consider the general variance sequence under two settings. For a prefixed sequence, where the entire variance sequence is revealed to the learner at the beginning of the learning process, we establish a variance-dependent lower bound of $\\Omega(d \\sqrt{\\sum_{k=1}^K\\sigma_k^2 }/\\log K)$ for linear contextual bandits. For an adaptive sequence, where an adversary can generate the variance $\\sigma_k^2$ in each round $k$ based on historical observations, we show that when the adversary must generate $\\sigma_k^2$ before observing the decision set $\\mathcal{D}_k$, a similar lower bound of $\\Omega(d\\sqrt{ \\sum_{k=1}^K\\sigma_k^2} /\\log^6(dK))$ holds. In both settings, our results match the upper bounds of the SAVE algorithm (Zhao et al., 2023) up to logarithmic factors.', 'abstract_zh': '依赖方差的线性上下文Bandits的懊悔界研究：从$\\tilde{O}(d\\sqrt{K})$改进到$\\tilde{O}(d\\sqrt{\\sum_{k=1}^K\\sigma_k^2})$', 'title_zh': '基于上下文的多臂老虎机依赖方差的寄存器下界'}
{'arxiv_id': 'arXiv:2503.12018', 'title': 'Compose Your Aesthetics: Empowering Text-to-Image Models with the Principles of Art', 'authors': 'Zhe Jin, Tat-Seng Chua', 'link': 'https://arxiv.org/abs/2503.12018', 'abstract': 'Text-to-Image (T2I) diffusion models (DM) have garnered widespread adoption due to their capability in generating high-fidelity outputs and accessibility to anyone able to put imagination into words. However, DMs are often predisposed to generate unappealing outputs, much like the random images on the internet they were trained on. Existing approaches to address this are founded on the implicit premise that visual aesthetics is universal, which is limiting. Aesthetics in the T2I context should be about personalization and we propose the novel task of aesthetics alignment which seeks to align user-specified aesthetics with the T2I generation output. Inspired by how artworks provide an invaluable perspective to approach aesthetics, we codify visual aesthetics using the compositional framework artists employ, known as the Principles of Art (PoA). To facilitate this study, we introduce CompArt, a large-scale compositional art dataset building on top of WikiArt with PoA analysis annotated by a capable Multimodal LLM. Leveraging the expressive power of LLMs and training a lightweight and transferrable adapter, we demonstrate that T2I DMs can effectively offer 10 compositional controls through user-specified PoA conditions. Additionally, we design an appropriate evaluation framework to assess the efficacy of our approach.', 'abstract_zh': '文本到图像（T2I）扩散模型（DM）因其生成高保真输出的能力和任何能够用文字表达想象的人都能使用的特点而广受欢迎。然而，DMs往往会生成不令人满意的输出，类似于它们训练过程中遇到的互联网上的随机图像。现有的解决方法基于视觉美学具有普遍性的隐含前提，这限制了它们的应用。在T2I的语境中，美学应该是个性化的，我们提出了一个新的任务——美学对齐，旨在将用户指定的美学与T2I生成的输出进行对齐。受艺术作品如何提供美学视角的影响，我们使用艺术家所使用的构图框架——艺术原则（PoA）来编码视觉美学。为了促进这项研究，我们引入了CompArt，一个基于WikiArt的大规模构图艺术数据集，并通过一个有能力的多模态LLM进行了PoA分析的注释。借助LLMs的表达能力并训练一个轻量级且可转移的适配器，我们证明了T2I DMs可以通过用户指定的PoA条件有效提供10个构图控制。此外，我们设计了一个合适的评估框架来评估我们方法的有效性。', 'title_zh': '构建你的美学：赋予文本-to-图像模型艺术原理'}
{'arxiv_id': 'arXiv:2503.12008', 'title': 'Winning the MIDST Challenge: New Membership Inference Attacks on Diffusion Models for Tabular Data Synthesis', 'authors': 'Xiaoyu Wu, Yifei Pang, Terrance Liu, Steven Wu', 'link': 'https://arxiv.org/abs/2503.12008', 'abstract': 'Tabular data synthesis using diffusion models has gained significant attention for its potential to balance data utility and privacy. However, existing privacy evaluations often rely on heuristic metrics or weak membership inference attacks (MIA), leaving privacy risks inadequately assessed. In this work, we conduct a rigorous MIA study on diffusion-based tabular synthesis, revealing that state-of-the-art attacks designed for image models fail in this setting. We identify noise initialization as a key factor influencing attack efficacy and propose a machine-learning-driven approach that leverages loss features across different noises and time steps. Our method, implemented with a lightweight MLP, effectively learns membership signals, eliminating the need for manual optimization. Experimental results from the MIDST Challenge @ SaTML 2025 demonstrate the effectiveness of our approach, securing first place across all tracks. Code is available at this https URL.', 'abstract_zh': '基于扩散模型的表格数据合成中的会员身份推理研究：揭示先进的图像模型攻击在此场景下的失效，并提出一种机器学习驱动的方法以评估隐私风险。', 'title_zh': '赢得MIDST挑战：针对表格数据合成的扩散模型会员推理攻击新方法'}
{'arxiv_id': 'arXiv:2503.11995', 'title': 'Fraesormer: Learning Adaptive Sparse Transformer for Efficient Food Recognition', 'authors': 'Shun Zou, Yi Zou, Mingya Zhang, Shipeng Luo, Zhihao Chen, Guangwei Gao', 'link': 'https://arxiv.org/abs/2503.11995', 'abstract': 'In recent years, Transformer has witnessed significant progress in food recognition. However, most existing approaches still face two critical challenges in lightweight food recognition: (1) the quadratic complexity and redundant feature representation from interactions with irrelevant tokens; (2) static feature recognition and single-scale representation, which overlook the unstructured, non-fixed nature of food images and the need for multi-scale features. To address these, we propose an adaptive and efficient sparse Transformer architecture (Fraesormer) with two core designs: Adaptive Top-k Sparse Partial Attention (ATK-SPA) and Hierarchical Scale-Sensitive Feature Gating Network (HSSFGN). ATK-SPA uses a learnable Gated Dynamic Top-K Operator (GDTKO) to retain critical attention scores, filtering low query-key matches that hinder feature aggregation. It also introduces a partial channel mechanism to reduce redundancy and promote expert information flow, enabling local-global collaborative modeling. HSSFGN employs gating mechanism to achieve multi-scale feature representation, enhancing contextual semantic information. Extensive experiments show that Fraesormer outperforms state-of-the-art methods. code is available at this https URL.', 'abstract_zh': '近年来，Transformer在食品识别方面取得了显著进展。然而，现有的轻量化食品识别方法仍面临两大关键挑战：(1) 与无关令牌交互带来的二次复杂度和冗余特征表示；(2) 静态特征识别和单尺度表示，忽视了食品图像的非结构化、非固定性质以及多尺度特征的需求。为应对这些挑战，我们提出了一种自适应高效的稀疏Transformer架构（Fraesormer），其包含两大核心设计：自适应Top-k稀疏部分注意机制（ATK-SPA）和层次化尺度敏感特征门控网络（HSSFGN）。ATK-SPA通过可学习的门控动态Top-K运算符（GDTKO）保留关键注意分数，过滤妨碍特征聚合的低匹配查询-键对，并引入部分通道机制以减少冗余并促进专家信息流，实现局部-全局协作建模。HSSFGN通过门控机制实现多尺度特征表示，增强上下文语义信息。大量实验表明，Fraesormer优于现有最先进的方法。代码可在此处获取。', 'title_zh': 'Fraesormer: 学习自适应稀疏变换器以实现高效的食品识别'}
{'arxiv_id': 'arXiv:2503.11989', 'title': 'Applications of Large Language Model Reasoning in Feature Generation', 'authors': 'Dharani Chandra', 'link': 'https://arxiv.org/abs/2503.11989', 'abstract': "Large Language Models (LLMs) have revolutionized natural language processing through their state of art reasoning capabilities. This paper explores the convergence of LLM reasoning techniques and feature generation for machine learning tasks. We examine four key reasoning approaches: Chain of Thought, Tree of Thoughts, Retrieval-Augmented Generation, and Thought Space Exploration. Our analysis reveals how these approaches can be used to identify effective feature generation rules without having to manually specify search spaces. The paper categorizes LLM-based feature generation methods across various domains including finance, healthcare, and text analytics. LLMs can extract key information from clinical notes and radiology reports in healthcare, by enabling more efficient data utilization. In finance, LLMs facilitate text generation, summarization, and entity extraction from complex documents. We analyze evaluation methodologies for assessing feature quality and downstream performance, with particular attention to OCTree's decision tree reasoning approach that provides language-based feedback for iterative improvements. Current challenges include hallucination, computational efficiency, and domain adaptation. As of March 2025, emerging approaches include inference-time compute scaling, reinforcement learning, and supervised fine-tuning with model distillation. Future directions point toward multimodal feature generation, self-improving systems, and neuro-symbolic approaches. This paper provides a detailed overview of an emerging field that promises to automate and enhance feature engineering through language model reasoning.", 'abstract_zh': '大型语言模型（LLMs）通过其先进的推理能力革命性地改变了自然语言处理。本文探讨了LLM推理技术与特征生成在机器学习任务中的融合。我们研究了四种关键的推理方法：链式思维、思路树、检索增强生成以及思维空间探索。我们的分析揭示了这些方法如何用于识别有效的特征生成规则，而无需手动指定搜索空间。本文将LLM基于的特征生成方法分类应用于金融、医疗和文本分析等各种领域。在医疗领域，LLM能够从临床笔记和放射学报告中提取关键信息，通过促进更高效的数据显示利用。在金融领域，LLM促进文本生成、总结以及从复杂文档中提取实体。我们分析了评估特征质量和下游性能的评估方法，特别是OCTree的决策树推理方法，该方法提供基于语言的反馈以实现迭代改进。当前的挑战包括幻想、计算效率和领域适应。截至2025年3月，新兴的方法包括推理时计算扩展、强化学习和模型蒸馏下的监督微调。未来方向指向多模态特征生成、自我改进系统和神经-符号方法。本文提供了关于通过语言模型推理自动和增强特征工程新兴领域的详细概述。', 'title_zh': '大型语言模型推理在特征生成中的应用'}
{'arxiv_id': 'arXiv:2503.11985', 'title': 'No LLM is Free From Bias: A Comprehensive Study of Bias Evaluation in Large Language models', 'authors': 'Charaka Vinayak Kumar, Ashok Urlana, Gopichand Kanumolu, Bala Mallikarjunarao Garlapati, Pruthwik Mishra', 'link': 'https://arxiv.org/abs/2503.11985', 'abstract': 'Advancements in Large Language Models (LLMs) have increased the performance of different natural language understanding as well as generation tasks. Although LLMs have breached the state-of-the-art performance in various tasks, they often reflect different forms of bias present in the training data. In the light of this perceived limitation, we provide a unified evaluation of benchmarks using a set of representative LLMs that cover different forms of biases starting from physical characteristics to socio-economic categories. Moreover, we propose five prompting approaches to carry out the bias detection task across different aspects of bias. Further, we formulate three research questions to gain valuable insight in detecting biases in LLMs using different approaches and evaluation metrics across benchmarks. The results indicate that each of the selected LLMs suffer from one or the other form of bias with the LLaMA3.1-8B model being the least biased. Finally, we conclude the paper with the identification of key challenges and possible future directions.', 'abstract_zh': '大型语言模型的进展提高了不同自然语言理解和生成任务的性能。尽管大型语言模型在各种任务中达到了最先进的性能，但它们常常反映出训练数据中存在的不同形式的偏见。鉴于这一局限性，我们使用一组代表性的大型语言模型进行统一评估，这些模型涵盖了从物理特征到社会经济类别等不同形式的偏见。此外，我们提出了五种提示方法，以在不同偏见方面执行偏见检测任务。进一步地，我们提出了三个研究问题，以通过不同方法和评估指标在基准测试中获取有关检测大型语言模型中偏见的有价值见解。结果表明，所选的每个大型语言模型都存在某种形式的偏见，LLaMA3.1-8B模型是最不偏颇的。最后，我们总结了论文中的关键挑战和可能的未来方向。', 'title_zh': '没有免费的午餐：大型语言模型偏见评估的全面研究'}
{'arxiv_id': 'arXiv:2503.11962', 'title': 'HInter: Exposing Hidden Intersectional Bias in Large Language Models', 'authors': 'Badr Souani, Ezekiel Soremekun, Mike Papadakis, Setsuko Yokoyama, Sudipta Chattopadhyay, Yves Le Traon', 'link': 'https://arxiv.org/abs/2503.11962', 'abstract': 'Large Language Models (LLMs) may portray discrimination towards certain individuals, especially those characterized by multiple attributes (aka intersectional bias). Discovering intersectional bias in LLMs is challenging, as it involves complex inputs on multiple attributes (e.g. race and gender). To address this challenge, we propose HInter, a test technique that synergistically combines mutation analysis, dependency parsing and metamorphic oracles to automatically detect intersectional bias in LLMs. HInter generates test inputs by systematically mutating sentences using multiple mutations, validates inputs via a dependency invariant and detects biases by checking the LLM response on the original and mutated sentences. We evaluate HInter using six LLM architectures and 18 LLM models (GPT3.5, Llama2, BERT, etc) and find that 14.61% of the inputs generated by HInter expose intersectional bias. Results also show that our dependency invariant reduces false positives (incorrect test inputs) by an order of magnitude. Finally, we observed that 16.62% of intersectional bias errors are hidden, meaning that their corresponding atomic cases do not trigger biases. Overall, this work emphasize the importance of testing LLMs for intersectional bias.', 'abstract_zh': '大型语言模型中交叠偏见的检测：HInter测试技术', 'title_zh': 'HInter: 展示大规模语言模型中的隐藏综合性偏见'}
{'arxiv_id': 'arXiv:2503.11958', 'title': 'CHOrD: Generation of Collision-Free, House-Scale, and Organized Digital Twins for 3D Indoor Scenes with Controllable Floor Plans and Optimal Layouts', 'authors': 'Chong Su, Yingbin Fu, Zheyuan Hu, Jing Yang, Param Hanji, Shaojun Wang, Xuan Zhao, Cengiz Öztireli, Fangcheng Zhong', 'link': 'https://arxiv.org/abs/2503.11958', 'abstract': 'We introduce CHOrD, a novel framework for scalable synthesis of 3D indoor scenes, designed to create house-scale, collision-free, and hierarchically structured indoor digital twins. In contrast to existing methods that directly synthesize the scene layout as a scene graph or object list, CHOrD incorporates a 2D image-based intermediate layout representation, enabling effective prevention of collision artifacts by successfully capturing them as out-of-distribution (OOD) scenarios during generation. Furthermore, unlike existing methods, CHOrD is capable of generating scene layouts that adhere to complex floor plans with multi-modal controls, enabling the creation of coherent, house-wide layouts robust to both geometric and semantic variations in room structures. Additionally, we propose a novel dataset with expanded coverage of household items and room configurations, as well as significantly improved data quality. CHOrD demonstrates state-of-the-art performance on both the 3D-FRONT and our proposed datasets, delivering photorealistic, spatially coherent indoor scene synthesis adaptable to arbitrary floor plan variations.', 'abstract_zh': '我们提出CHOrD，一种用于大规模合成3D室内场景的新型框架，旨在创建与房屋规模相符、无碰撞且具有分层结构的室内数字孪生。与现有直接将场景布局合成为空间图或对象列表的方法不同，CHOrD 结合了基于2D图像的中间布局表示，使其能够在生成过程中成功地将碰撞伪影捕获为离分布（OOD）场景，从而有效防止碰撞伪影。此外，与现有方法不同，CHOrD 能够生成符合复杂楼层平面图且具有多模态控制的场景布局，从而实现对房间结构几何和语义变化具有鲁棒性的连贯、全屋范围的布局。此外，我们提出了一种新的数据集，该数据集扩展了家用物品和房间配置的涵盖范围，并且数据质量显著提高。CHOrD 在3D-FRONT数据集和我们提出的数据集上均表现出现有的先进性能，能够生成适应任意楼层平面图变化的逼真、空间连贯的室内场景合成。', 'title_zh': 'CHOrD: 生成无碰撞、家庭规模且组织有序的3D室内场景数字孪生，具有可控的楼层平面图和最优布局'}
{'arxiv_id': 'arXiv:2503.11954', 'title': 'Goal-Oriented Source Coding using LDPC Codes for Compressed-Domain Image Classification', 'authors': 'Ahcen Aliouat, Elsa Dupraz', 'link': 'https://arxiv.org/abs/2503.11954', 'abstract': 'In the emerging field of goal-oriented communications, the focus has shifted from reconstructing data to directly performing specific learning tasks, such as classification, segmentation, or pattern recognition, on the received coded data. In the commonly studied scenario of classification from compressed images, a key objective is to enable learning directly on entropy-coded data, thereby bypassing the computationally intensive step of data reconstruction. Conventional entropy-coding methods, such as Huffman and Arithmetic coding, are effective for compression but disrupt the data structure, making them less suitable for direct learning without decoding. This paper investigates the use of low-density parity-check (LDPC) codes -- originally designed for channel coding -- as an alternative entropy-coding approach. It is hypothesized that the structured nature of LDPC codes can be leveraged more effectively by deep learning models for tasks like classification. At the receiver side, gated recurrent unit (GRU) models are trained to perform image classification directly on LDPC-coded data. Experiments on datasets like MNIST, Fashion-MNIST, and CIFAR show that LDPC codes outperform Huffman and Arithmetic coding in classification tasks, while requiring significantly smaller learning models. Furthermore, the paper analyzes why LDPC codes preserve data structure more effectively than traditional entropy-coding techniques and explores the impact of key code parameters on classification performance. These results suggest that LDPC-based entropy coding offers an optimal balance between learning efficiency and model complexity, eliminating the need for prior decoding.', 'abstract_zh': '目标导向通信中编码数据上的直接学习', 'title_zh': '基于LDPC码的目标导向源编码在压缩域图像分类中的应用'}
{'arxiv_id': 'arXiv:2503.11950', 'title': 'Privacy Ethics Alignment in AI (PEA-AI): A Stakeholder-Centric Based Framework for Ethcial AI', 'authors': 'Ankur Barthwal, Molly Campbell, Ajay Kumar Shrestha', 'link': 'https://arxiv.org/abs/2503.11950', 'abstract': 'The increasing integration of Artificial Intelligence (AI) in digital ecosystems has reshaped privacy dynamics, particularly for young digital citizens navigating data-driven environments. This study explores evolving privacy concerns across three key stakeholder groups, digital citizens (ages 16-19), parents, educators, and AI professionals, and assesses differences in data ownership, trust, transparency, parental mediation, education, and risk-benefit perceptions. Employing a grounded theory methodology, this research synthesizes insights from 482 participants through structured surveys, qualitative interviews, and focus groups. The findings reveal distinct privacy expectations- Young users emphasize autonomy and digital freedom, while parents and educators advocate for regulatory oversight and AI literacy programs. AI professionals, in contrast, prioritize the balance between ethical system design and technological efficiency. The data further highlights gaps in AI literacy and transparency, emphasizing the need for comprehensive, stakeholder-driven privacy frameworks that accommodate diverse user needs. Using comparative thematic analysis, this study identifies key tensions in privacy governance and develops the novel Privacy-Ethics Alignment in AI (PEA-AI) model, which structures privacy decision-making as a dynamic negotiation between stakeholders. By systematically analyzing themes such as transparency, user control, risk perception, and parental mediation, this research provides a scalable, adaptive foundation for AI governance, ensuring that privacy protections evolve alongside emerging AI technologies and youth-centric digital interactions.', 'abstract_zh': '人工智能在数字生态系统中的不断整合重塑了隐私动态，特别是在数据驱动环境中 navigating 的年轻数字公民尤为明显。本研究探究了跨三类关键利益相关者——数字公民（16-19岁）、家长、教育者和AI专业人士——的 evolving 隐私关切，并评估了他们在数据所有权、信任、透明度、家长介入、教育和风险效益感知方面的差异。通过扎根理论方法，本研究结合结构化调查、质性访谈和焦点小组，从482名参与者中整合了见解。研究发现表明，年轻用户强调自主和数字自由，而家长和教育者则倡导监管监督和AI素养计划。相比之下，AI专业人士更侧重于伦理系统设计与技术效率之间的平衡。数据进一步突显了AI素养和透明度的缺口，强调了需要全面、以利益相关者为导向的隐私框架，以适应用户多样化的需求。通过比较主题分析，本研究识别了隐私治理中的关键张力，并提出了新的隐私-伦理在AI中的契合模型（PEA-AI），将隐私决策视为利益相关者之间的动态谈判结构。通过对透明度、用户控制、风险感知和家长介入等主题的系统分析，本研究为AI治理提供了可扩展和适应的基础，确保了随着新兴AI技术和以青年为中心的数字互动扩展，隐私保护能同步发展。', 'title_zh': '隐私伦理一致性的AI (PEA-AI): 一个基于利益相关者中心的道德AI框架'}
{'arxiv_id': 'arXiv:2503.11948', 'title': 'Integration of Explainable AI Techniques with Large Language Models for Enhanced Interpretability for Sentiment Analysis', 'authors': 'Thivya Thogesan, Anupiya Nugaliyadde, Kok Wai Wong', 'link': 'https://arxiv.org/abs/2503.11948', 'abstract': 'Interpretability remains a key difficulty in sentiment analysis with Large Language Models (LLMs), particularly in high-stakes applications where it is crucial to comprehend the rationale behind forecasts. This research addressed this by introducing a technique that applies SHAP (Shapley Additive Explanations) by breaking down LLMs into components such as embedding layer,encoder,decoder and attention layer to provide a layer-by-layer knowledge of sentiment prediction. The approach offers a clearer overview of how model interpret and categorise sentiment by breaking down LLMs into these parts. The method is evaluated using the Stanford Sentiment Treebank (SST-2) dataset, which shows how different sentences affect different layers. The effectiveness of layer-wise SHAP analysis in clarifying sentiment-specific token attributions is demonstrated by experimental evaluations, which provide a notable enhancement over current whole-model explainability techniques. These results highlight how the suggested approach could improve the reliability and transparency of LLM-based sentiment analysis in crucial applications.', 'abstract_zh': '大型语言模型中情感分析的可解释性依然是一个关键难题，特别是在高风险应用中，理解预测背后的逻辑至关重要。本研究通过引入一种方法来应对这一挑战，该方法利用SHAP（SHapley Additive Explanations）将大型语言模型分解为嵌入层、编码器、解码器和注意力层等组件，以逐层揭示情感预测的知识。该方法通过将大型语言模型分解为这些部分，为模型如何解释和分类情感提供更清晰的 overview。该方法使用斯坦福情感树库（SST-2）数据集进行评估，展示了不同句子如何影响不同层。实验评价展示了分层SHAP分析在阐明情感特定标记属性方面的有效性，这比现有整个模型的解释性方法有了显著提升。这些结果突出显示了所提方法如何在关键应用中提高基于大型语言模型的情感分析的可靠性和透明度。', 'title_zh': '将可解释AI技术与大规模语言模型结合以增强情感分析的可解释性'}
{'arxiv_id': 'arXiv:2503.11947', 'title': 'Ethical AI for Young Digital Citizens: A Call to Action on Privacy Governance', 'authors': 'Austin Shouli, Ankur Barthwal, Molly Campbell, Ajay Kumar Shrestha', 'link': 'https://arxiv.org/abs/2503.11947', 'abstract': 'The rapid expansion of Artificial Intelligence (AI) in digital platforms used by youth has created significant challenges related to privacy, autonomy, and data protection. While AI-driven personalization offers enhanced user experiences, it often operates without clear ethical boundaries, leaving young users vulnerable to data exploitation and algorithmic biases. This paper presents a call to action for ethical AI governance, advocating for a structured framework that ensures youth-centred privacy protections, transparent data practices, and regulatory oversight. We outline key areas requiring urgent intervention, including algorithmic transparency, privacy education, parental data-sharing ethics, and accountability measures. Through this approach, we seek to empower youth with greater control over their digital identities and propose actionable strategies for policymakers, AI developers, and educators to build a fairer and more accountable AI ecosystem.', 'abstract_zh': '人工智能在青年使用的数字平台上的迅速扩张引发了隐私、自主权和数据保护方面的重大挑战。虽然基于AI的个性化服务提升了用户体验，但往往会缺乏明确的伦理边界，使年轻用户面临数据滥用和算法偏见的风险。本文呼吁建立伦理AI治理框架，确保以青年为中心的数据隐私保护、透明的数据实践和监管监督。我们指出了亟需干预的关键领域，包括算法透明性、隐私教育、家长数据共享伦理和问责措施。通过这种 approach，我们旨在赋予青年对数字身份的更大控制权，并为政策制定者、AI开发者和教育者提出了构建更加公平和负责任的AI生态系统的方法。', 'title_zh': '面向年轻数字公民的伦理AI：隐私治理行动呼吁'}
{'arxiv_id': 'arXiv:2503.11944', 'title': 'Human Digital Twins in Personalized Healthcare: An Overview and Future Perspectives', 'authors': 'Melvin Mokhtari', 'link': 'https://arxiv.org/abs/2503.11944', 'abstract': "Digital twins (DTs) are redefining healthcare by paving the way for more personalized, proactive, and intelligent medical interventions. As the shift toward personalized care intensifies, there is a growing need for an individual's virtual replica that delivers the right treatment at the optimal time and in the most effective manner. The emerging concept of a Human Digital Twin (HDT) holds the potential to revolutionize the traditional healthcare system much like digital twins have transformed manufacturing and aviation. An HDT mirrors the physical entity of a human body through a dynamic virtual model that continuously reflects changes in molecular, physiological, emotional, and lifestyle factors. This digital representation not only supports remote monitoring, diagnosis, and prescription but also facilitates surgery, rehabilitation, and overall personalized care, thereby relieving pressure on conventional healthcare frameworks. Despite its promising advantages, there are considerable research challenges to overcome as HDT technology evolves. In this study, I will initially delineate the distinctions between traditional digital twins and HDTs, followed by an exploration of the networking architecture integral to their operation--from data acquisition and communication to computation, management, and decision-making--thereby offering insights into how these innovations may reshape the modern healthcare industry.", 'abstract_zh': '数字孪生在重塑个性化、前瞻性和智能医疗服务中的作用：人类数字孪生的前景与挑战', 'title_zh': '个人数字孪生在个性化医疗中的应用：综述与未来展望'}
{'arxiv_id': 'arXiv:2503.11937', 'title': 'Att-Adapter: A Robust and Precise Domain-Specific Multi-Attributes T2I Diffusion Adapter via Conditional Variational Autoencoder', 'authors': 'Wonwoong Cho, Yan-Ying Chen, Matthew Klenk, David I. Inouye, Yanxia Zhang', 'link': 'https://arxiv.org/abs/2503.11937', 'abstract': 'Text-to-Image (T2I) Diffusion Models have achieved remarkable performance in generating high quality images. However, enabling precise control of continuous attributes, especially multiple attributes simultaneously, in a new domain (e.g., numeric values like eye openness or car width) with text-only guidance remains a significant challenge. To address this, we introduce the Attribute (Att) Adapter, a novel plug-and-play module designed to enable fine-grained, multi-attributes control in pretrained diffusion models. Our approach learns a single control adapter from a set of sample images that can be unpaired and contain multiple visual attributes. The Att-Adapter leverages the decoupled cross attention module to naturally harmonize the multiple domain attributes with text conditioning. We further introduce Conditional Variational Autoencoder (CVAE) to the Att-Adapter to mitigate overfitting, matching the diverse nature of the visual world. Evaluations on two public datasets show that Att-Adapter outperforms all LoRA-based baselines in controlling continuous attributes. Additionally, our method enables a broader control range and also improves disentanglement across multiple attributes, surpassing StyleGAN-based techniques. Notably, Att-Adapter is flexible, requiring no paired synthetic data for training, and is easily scalable to multiple attributes within a single model.', 'abstract_zh': '文本到图像（T2I）扩散模型在生成高质量图像方面取得了显著性能。然而，仅通过文本指导在新领域（例如，如眼球睁开度或汽车宽度这样的数值值）中精确控制连续属性，尤其是同时控制多个属性，仍然是一个重大挑战。为此，我们引入了属性（Att）适配器，这是一种新型即插即用模块，设计用于在预训练扩散模型中启用细粒度、多属性控制。我们的方法从一组不配对的包含多个视觉属性的样本图像中学习一个单一的控制适配器。Att-Adapter 利用解耦交叉注意力模块自然地将多个领域属性与文本条件协调起来。我们进一步在Att-Adapter中引入条件变分自编码器（CVAE）以减轻过拟合，适应视觉世界的多样性质。在两个公开数据集上的评估显示，Att-Adapter 在控制连续属性方面优于所有基于LoRA的基本模型。此外，我们的方法能够实现更广泛的控制范围，并在多个属性上提高了分离度，超越了基于StyleGAN的技术。值得注意的是，Att-Adapter 具有灵活性，无需配对的合成数据即可进行训练，并且可以轻松扩展到单个模型内的多个属性。', 'title_zh': 'Att-Adapter: 一种通过条件变分自编码器实现的稳健而精确的领域特定多属性T2I扩散适配器'}
{'arxiv_id': 'arXiv:2503.11933', 'title': 'End-to-End Edge AI Service Provisioning Framework in 6G ORAN', 'authors': 'Yun Tang, Udhaya Chandhar Srinivasan, Benjamin James Scott, Obumneme Umealor, Dennis Kevogo, Weisi Guo', 'link': 'https://arxiv.org/abs/2503.11933', 'abstract': "With the advent of 6G, Open Radio Access Network (O-RAN) architectures are evolving to support intelligent, adaptive, and automated network orchestration. This paper proposes a novel Edge AI and Network Service Orchestration framework that leverages Large Language Model (LLM) agents deployed as O-RAN rApps. The proposed LLM-agent-powered system enables interactive and intuitive orchestration by translating the user's use case description into deployable AI services and corresponding network configurations. The LLM agent automates multiple tasks, including AI model selection from repositories (e.g., Hugging Face), service deployment, network adaptation, and real-time monitoring via xApps. We implement a prototype using open-source O-RAN projects (OpenAirInterface and FlexRIC) to demonstrate the feasibility and functionality of our framework. Our demonstration showcases the end-to-end flow of AI service orchestration, from user interaction to network adaptation, ensuring Quality of Service (QoS) compliance. This work highlights the potential of integrating LLM-driven automation into 6G O-RAN ecosystems, paving the way for more accessible and efficient edge AI ecosystems.", 'abstract_zh': '6G时代开放无线接入网络架构下的边缘AI与网络服务编排框架', 'title_zh': '6G ORAN 中端到端边缘AI服务 provisioning 框架'}
{'arxiv_id': 'arXiv:2503.11924', 'title': 'REGEN: A Dataset and Benchmarks with Natural Language Critiques and Narratives', 'authors': 'Kun Su, Krishna Sayana, Hubert Pham, James Pine, Yuri Vasilevski, Raghavendra Vasudeva, Marialena Kyriakidi, Liam Hebert, Ambarish Jash, Anushya Subbiah, Sukhdeep Sodhi', 'link': 'https://arxiv.org/abs/2503.11924', 'abstract': 'This paper introduces a novel dataset REGEN (Reviews Enhanced with GEnerative Narratives), designed to benchmark the conversational capabilities of recommender Large Language Models (LLMs), addressing the limitations of existing datasets that primarily focus on sequential item prediction. REGEN extends the Amazon Product Reviews dataset by inpainting two key natural language features: (1) user critiques, representing user "steering" queries that lead to the selection of a subsequent item, and (2) narratives, rich textual outputs associated with each recommended item taking into account prior context. The narratives include product endorsements, purchase explanations, and summaries of user preferences.\nFurther, we establish an end-to-end modeling benchmark for the task of conversational recommendation, where models are trained to generate both recommendations and corresponding narratives conditioned on user history (items and critiques). For this joint task, we introduce a modeling framework LUMEN (LLM-based Unified Multi-task Model with Critiques, Recommendations, and Narratives) which uses an LLM as a backbone for critiquing, retrieval and generation. We also evaluate the dataset\'s quality using standard auto-rating techniques and benchmark it by training both traditional and LLM-based recommender models. Our results demonstrate that incorporating critiques enhances recommendation quality by enabling the recommender to learn language understanding and integrate it with recommendation signals. Furthermore, LLMs trained on our dataset effectively generate both recommendations and contextual narratives, achieving performance comparable to state-of-the-art recommenders and language models.', 'abstract_zh': '一种新型数据集REGEN（增强生成叙述的评论），用于评估推荐大型语言模型的对话能力', 'title_zh': 'REGEN：一个包含自然语言批评和叙事的数据集和基准'}
{'arxiv_id': 'arXiv:2503.11918', 'title': 'Sketch-to-Skill: Bootstrapping Robot Learning with Human Drawn Trajectory Sketches', 'authors': 'Peihong Yu, Amisha Bhaskar, Anukriti Singh, Zahiruddin Mahammad, Pratap Tokekar', 'link': 'https://arxiv.org/abs/2503.11918', 'abstract': 'Training robotic manipulation policies traditionally requires numerous demonstrations and/or environmental rollouts. While recent Imitation Learning (IL) and Reinforcement Learning (RL) methods have reduced the number of required demonstrations, they still rely on expert knowledge to collect high-quality data, limiting scalability and accessibility. We propose Sketch-to-Skill, a novel framework that leverages human-drawn 2D sketch trajectories to bootstrap and guide RL for robotic manipulation. Our approach extends beyond previous sketch-based methods, which were primarily focused on imitation learning or policy conditioning, limited to specific trained tasks. Sketch-to-Skill employs a Sketch-to-3D Trajectory Generator that translates 2D sketches into 3D trajectories, which are then used to autonomously collect initial demonstrations. We utilize these sketch-generated demonstrations in two ways: to pre-train an initial policy through behavior cloning and to refine this policy through RL with guided exploration. Experimental results demonstrate that Sketch-to-Skill achieves ~96% of the performance of the baseline model that leverages teleoperated demonstration data, while exceeding the performance of a pure reinforcement learning policy by ~170%, only from sketch inputs. This makes robotic manipulation learning more accessible and potentially broadens its applications across various domains.', 'abstract_zh': '基于草图的技能学习：一种利用人类绘制的2D草图轨迹引导机器人 manipulation 的新框架', 'title_zh': 'Sketch-to-Skill: 用人类绘制的轨迹草图-bootstrapping 机器人学习'}
{'arxiv_id': 'arXiv:2503.11917', 'title': 'A Framework for Evaluating Emerging Cyberattack Capabilities of AI', 'authors': 'Mikel Rodriguez, Raluca Ada Popa, Four Flynn, Lihao Liang, Allan Dafoe, Anna Wang', 'link': 'https://arxiv.org/abs/2503.11917', 'abstract': "As frontier models become more capable, the community has attempted to evaluate their ability to enable cyberattacks. Performing a comprehensive evaluation and prioritizing defenses are crucial tasks in preparing for AGI safely. However, current cyber evaluation efforts are ad-hoc, with no systematic reasoning about the various phases of attacks, and do not provide a steer on how to use targeted defenses. In this work, we propose a novel approach to AI cyber capability evaluation that (1) examines the end-to-end attack chain, (2) helps to identify gaps in the evaluation of AI threats, and (3) helps defenders prioritize targeted mitigations and conduct AI-enabled adversary emulation to support red teaming. To achieve these goals, we propose adapting existing cyberattack chain frameworks to AI systems. We analyze over 12,000 instances of real-world attempts to use AI in cyberattacks catalogued by Google's Threat Intelligence Group. Using this analysis, we curate a representative collection of seven cyberattack chain archetypes and conduct a bottleneck analysis to identify areas of potential AI-driven cost disruption. Our evaluation benchmark consists of 50 new challenges spanning different phases of cyberattacks. Based on this, we devise targeted cybersecurity model evaluations, report on the potential for AI to amplify offensive cyber capabilities across specific attack phases, and conclude with recommendations on prioritizing defenses. In all, we consider this to be the most comprehensive AI cyber risk evaluation framework published so far.", 'abstract_zh': '前沿模型能力不断提升，社区已尝试评估其是否能-enable-黑客攻击。全面评估和优先级排序防御是为安全地准备AGI所需的关键任务。然而，当前的网络评估努力往往是随机进行的，缺乏对攻击各个阶段的系统性分析，也无法为如何使用有针对性的防御提供指导。在本文中，我们提出了一种新的AI网络能力评估方法，该方法（1）考查端到端攻击链，（2）有助于识别AI威胁评估中的缺口，（3）帮助防御者优先考虑有针对性的缓解措施，并进行AI支持的对手仿真以支持红队演练。为了实现这些目标，我们提出将现有的网络攻击链框架适应到AI系统。我们分析了谷歌威胁情报团队记录的超过12,000个实际的AI在网络攻击中的应用实例。基于这些分析，我们精心挑选了七个网络攻击链原型，并进行了瓶颈分析以识别潜在的AI驱动的成本中断领域。我们的评估基准包括50项新的挑战，涵盖了网络攻击的不同阶段。在此基础上，我们设计了有针对性的网络安全模型评估，报告了AI在特定攻击阶段增强 Offensive 网络能力的潜力，并提供了优先防御的建议。总的来说，我们认为这是迄今为止最全面的AI网络风险评估框架。', 'title_zh': '一种评估新兴人工智能攻击能力的框架'}
{'arxiv_id': 'arXiv:2503.11915', 'title': "How Problematic Writer-AI Interactions (Rather than Problematic AI) Hinder Writers' Idea Generation", 'authors': 'Khonzoda Umarova, Talia Wise, Zhuoer Lyu, Mina Lee, Qian Yang', 'link': 'https://arxiv.org/abs/2503.11915', 'abstract': "Writing about a subject enriches writers' understanding of that subject. This cognitive benefit of writing -- known as constructive learning -- is essential to how students learn in various disciplines. However, does this benefit persist when students write with generative AI writing assistants? Prior research suggests the answer varies based on the type of AI, e.g., auto-complete systems tend to hinder ideation, while assistants that pose Socratic questions facilitate it. This paper adds an additional perspective. Through a case study, we demonstrate that the impact of genAI on students' idea development depends not only on the AI but also on the students and, crucially, their interactions in between. Students who proactively explored ideas gained new ideas from writing, regardless of whether they used auto-complete or Socratic AI assistants. Those who engaged in prolonged, mindless copyediting developed few ideas even with a Socratic AI. These findings suggest opportunities in designing AI writing assistants, not merely by creating more thought-provoking AI, but also by fostering more thought-provoking writer-AI interactions.", 'abstract_zh': '写作关于某个主题可以丰富作者对该主题的理解。这种写作带来的认知收益——称为建设性学习——是学生在各个学科中学习的重要方式。然而，当学生使用生成性AI写作助手写作时，这种收益是否会持续存在？先前的研究表明，这取决于AI的类型，例如自动补全系统往往会妨碍创新思维，而提出苏格拉底式问题的助手则有助于创新思维。本文通过案例研究增加了新的视角。我们证明生成性AI对学生想法发展的影响不仅取决于AI本身，还取决于学生及其互动。积极探索想法的学生无论使用自动补全还是苏格拉底式AI助手都能获得新想法。而长时间进行机械润色的学生即使使用了苏格拉底式AI也无法产生许多新想法。这些发现表明，在设计AI写作助手时，不仅需要创造更具启发性的AI，还需要促进更具启发性的作家-AI互动。', 'title_zh': '如何糟糕的作家-AI交互（而非糟糕的AI）妨碍作家的idea生成'}
{'arxiv_id': 'arXiv:2503.11910', 'title': 'RTD-Lite: Scalable Topological Analysis for Comparing Weighted Graphs in Learning Tasks', 'authors': 'Eduard Tulchinskii, Daria Voronkova, Ilya Trofimov, Evgeny Burnaev, Serguei Barannikov', 'link': 'https://arxiv.org/abs/2503.11910', 'abstract': 'Topological methods for comparing weighted graphs are valuable in various learning tasks but often suffer from computational inefficiency on large datasets. We introduce RTD-Lite, a scalable algorithm that efficiently compares topological features, specifically connectivity or cluster structures at arbitrary scales, of two weighted graphs with one-to-one correspondence between vertices. Using minimal spanning trees in auxiliary graphs, RTD-Lite captures topological discrepancies with $O(n^2)$ time and memory complexity. This efficiency enables its application in tasks like dimensionality reduction and neural network training. Experiments on synthetic and real-world datasets demonstrate that RTD-Lite effectively identifies topological differences while significantly reducing computation time compared to existing methods. Moreover, integrating RTD-Lite into neural network training as a loss function component enhances the preservation of topological structures in learned representations. Our code is publicly available at this https URL', 'abstract_zh': '基于拓扑的方法在比较加权图方面对各种学习任务很有价值，但在处理大数据集时通常面临计算效率低的问题。我们介绍了RTD-Lite，这是一种可扩展算法，能高效比较具有顶点一对一对应关系的两个加权图的拓扑特征，特别是任意尺度的连通性或聚类结构。利用辅助图的最小生成树，RTD-Lite 在 $O(n^2)$ 的时间复杂性和内存复杂度下捕捉拓扑差异。这种高效性使其能够应用于诸如降维和神经网络训练等任务。在合成和真实数据集上的实验表明，RTD-Lite 有效地识别了拓扑差异，同时显著减少了计算时间，相较于现有方法。此外，将RTD-Lite 集成到神经网络训练中作为损失函数组件，能够增强学习表示中拓扑结构的保留。我们的代码可在以下网址获得。', 'title_zh': 'RTD-Lite: 可扩展的拓扑分析方法用于学习任务中加权图的比较'}
{'arxiv_id': 'arXiv:2503.11908', 'title': 'Revisiting FastMap: New Applications', 'authors': 'Ang Li', 'link': 'https://arxiv.org/abs/2503.11908', 'abstract': 'FastMap was first introduced in the Data Mining community for generating Euclidean embeddings of complex objects. In this dissertation, we first present FastMap to generate Euclidean embeddings of graphs in near-linear time: The pairwise Euclidean distances approximate a desired graph-based distance function on the vertices. We then apply the graph version of FastMap to efficiently solve various graph-theoretic problems of significant interest in AI: including facility location, top-K centrality computations, community detection and block modeling, and graph convex hull computations. We also present a novel learning framework, called FastMapSVM, by combining FastMap and Support Vector Machines. We then apply FastMapSVM to predict the satisfiability of Constraint Satisfaction Problems and to classify seismograms in Earthquake Science.', 'abstract_zh': 'FastMap在数据挖掘社区首次被引入以生成复杂对象的欧几里得嵌入，在本论文中，我们首先介绍FastMap以在接近线性时间内生成图的欧几里得嵌入：pairwise欧几里得距离近似于顶点上的期望图基距离函数。然后，我们应用图版本的FastMap高效解决人工智能中具有重要意义的多种图论问题，包括设施定位、Top-K中心性计算、社区检测与模块化以及图凸包计算。我们还提出了一种新的学习框架FastMapSVM，将FastMap与支持向量机结合。最后，我们将FastMapSVM应用于预测约束满足问题的可满足性以及在地震科学中对地震检波器的分类。', 'title_zh': '重新审视FastMap：新的应用领域'}
{'arxiv_id': 'arXiv:2503.11906', 'title': 'A Survey on SAR ship classification using Deep Learning', 'authors': 'Ch Muhammad Awais, Marco Reggiannini, Davide Moroni, Emanuele Salerno', 'link': 'https://arxiv.org/abs/2503.11906', 'abstract': 'Deep learning (DL) has emerged as a powerful tool for Synthetic Aperture Radar (SAR) ship classification. This survey comprehensively analyzes the diverse DL techniques employed in this domain. We identify critical trends and challenges, highlighting the importance of integrating handcrafted features, utilizing public datasets, data augmentation, fine-tuning, explainability techniques, and fostering interdisciplinary collaborations to improve DL model performance. This survey establishes a first-of-its-kind taxonomy for categorizing relevant research based on DL models, handcrafted feature use, SAR attribute utilization, and the impact of fine-tuning. We discuss the methodologies used in SAR ship classification tasks and the impact of different techniques. Finally, the survey explores potential avenues for future research, including addressing data scarcity, exploring novel DL architectures, incorporating interpretability techniques, and establishing standardized performance metrics. By addressing these challenges and leveraging advancements in DL, researchers can contribute to developing more accurate and efficient ship classification systems, ultimately enhancing maritime surveillance and related applications.', 'abstract_zh': '深学习（DL）已发展成为合成孔径雷达（SAR）船舶分类的强大工具。本文综述了该领域中 diverse DL 技术的多样应用，并分析了关键趋势和挑战，强调了集成手工艺特征、利用公开数据集、数据增强、微调、解释性技术以及促进跨学科合作以提高 DL 模型性能的重要性。本文建立了第一种基于 DL 模型、手工艺特征使用、SAR 属性利用以及微调影响的分类税onomic框架。本文讨论了 SAR 船舶分类任务中使用的不同方法和技术的影响。最后，本文探讨了未来研究的潜在方向，包括解决数据稀缺性、探索新的 DL 架构、结合可解释性技术以及建立标准化性能指标。通过应对这些挑战并利用 DL 的进步，研究人员可以贡献于开发更准确和高效的船舶分类系统，最终增强海上监视及相关应用。', 'title_zh': 'SAR船舶分类的深度学习综述'}
{'arxiv_id': 'arXiv:2503.11905', 'title': 'Upcycling Text-to-Image Diffusion Models for Multi-Task Capabilities', 'authors': 'Ruchika Chavhan, Abhinav Mehrotra, Malcolm Chadwick, Alberto Gil Ramos, Luca Morreale, Mehdi Noroozi, Sourav Bhattacharya', 'link': 'https://arxiv.org/abs/2503.11905', 'abstract': 'Text-to-image synthesis has witnessed remarkable advancements in recent years. Many attempts have been made to adopt text-to-image models to support multiple tasks. However, existing approaches typically require resource-intensive re-training or additional parameters to accommodate for the new tasks, which makes the model inefficient for on-device deployment. We propose Multi-Task Upcycling (MTU), a simple yet effective recipe that extends the capabilities of a pre-trained text-to-image diffusion model to support a variety of image-to-image generation tasks. MTU replaces Feed-Forward Network (FFN) layers in the diffusion model with smaller FFNs, referred to as experts, and combines them with a dynamic routing mechanism. To the best of our knowledge, MTU is the first multi-task diffusion modeling approach that seamlessly blends multi-tasking with on-device compatibility, by mitigating the issue of parameter inflation. We show that the performance of MTU is on par with the single-task fine-tuned diffusion models across several tasks including image editing, super-resolution, and inpainting, while maintaining similar latency and computational load (GFLOPs) as the single-task fine-tuned models.', 'abstract_zh': '多任务.upcycling（MTU）：一种简单有效的预训练文本到图像扩散模型多任务扩展方法', 'title_zh': '循环利用文本到图像扩散模型以实现多任务能力'}
{'arxiv_id': 'arXiv:2503.11901', 'title': 'Characterizing GPU Resilience and Impact on AI/HPC Systems', 'authors': 'Shengkun Cui, Archit Patke, Ziheng Chen, Aditya Ranjan, Hung Nguyen, Phuong Cao, Saurabh Jha, Brett Bode, Gregory Bauer, Chandra Narayanaswami, Daby Sow, Catello Di Martino, Zbigniew T. Kalbarczyk, Ravishankar K. Iyer', 'link': 'https://arxiv.org/abs/2503.11901', 'abstract': 'In this study, we characterize GPU failures in Delta, the current large-scale AI system with over 600 petaflops of peak compute throughput. The system comprises GPU and non-GPU nodes with modern AI accelerators, such as NVIDIA A40, A100, and H100 GPUs. The study uses two and a half years of data on GPU errors. We evaluate the resilience of GPU hardware components to determine the vulnerability of different GPU components to failure and their impact on the GPU and node availability. We measure the key propagation paths in GPU hardware, GPU interconnect (NVLink), and GPU memory. Finally, we evaluate the impact of the observed GPU errors on user jobs. Our key findings are: (i) Contrary to common beliefs, GPU memory is over 30x more reliable than GPU hardware in terms of MTBE (mean time between errors). (ii) The newly introduced GSP (GPU System Processor) is the most vulnerable GPU hardware component. (iii) NVLink errors did not always lead to user job failure, and we attribute it to the underlying error detection and retry mechanisms employed. (iv) We show multiple examples of hardware errors originating from one of the key GPU hardware components, leading to application failure. (v) We project the impact of GPU node availability on larger scales with emulation and find that significant overprovisioning between 5-20% would be necessary to handle GPU failures. If GPU availability were improved to 99.9%, the overprovisioning would be reduced by 4x.', 'abstract_zh': '本研究characterizes GPU故障情况，涉及当前具有超过600 petaflops峰值计算能力的大规模AI系统Delta。该系统包含GPU节点和非GPU节点，配备了现代AI加速器，如NVIDIA A40、A100和H100 GPU。研究使用了近两年半关于GPU错误的数据。我们评估了GPU硬件组件的韧性，以确定不同GPU组件对其失效的脆弱性及其对GPU和节点可用性的影响。我们测量了GPU硬件的关键传播路径、GPU互连（NVLink）和GPU内存。最后，我们评估了观察到的GPU错误对用户作业的影响。我们的主要发现包括：（i）与普遍认知相反，从平均错误间隔（MTBE）角度来看，GPU内存比GPU硬件可靠30多倍。（ii）新引入的GSP（GPU系统处理器）是最脆弱的GPU硬件组件。（iii）NVLink错误并不总是导致用户作业失败，我们认为这是由于底层的错误检测和重试机制。（iv）我们展示了来自关键GPU硬件组件的多个硬件错误实例，导致应用程序失败。（v）我们通过模拟研究了GPU节点可用性在更大规模的影响，并发现为了处理GPU故障，需要5-20%的超额预订。如果GPU可用性提高到99.9%，超额预订将减少4倍。', 'title_zh': 'GPU容错特性及其对AI/HPC系统的影响'}
{'arxiv_id': 'arXiv:2503.11898', 'title': 'LLMs for Translation: Historical, Low-Resourced Languages and Contemporary AI Models', 'authors': 'Merve Tekgurler', 'link': 'https://arxiv.org/abs/2503.11898', 'abstract': "Large Language Models (LLMs) have demonstrated remarkable adaptability in performing various tasks, including machine translation (MT), without explicit training. Models such as OpenAI's GPT-4 and Google's Gemini are frequently evaluated on translation benchmarks and utilized as translation tools due to their high performance. This paper examines Gemini's performance in translating an 18th-century Ottoman Turkish manuscript, Prisoner of the Infidels: The Memoirs of Osman Agha of Timisoara, into English. The manuscript recounts the experiences of Osman Agha, an Ottoman subject who spent 11 years as a prisoner of war in Austria, and includes his accounts of warfare and violence. Our analysis reveals that Gemini's safety mechanisms flagged between 14 and 23 percent of the manuscript as harmful, resulting in untranslated passages. These safety settings, while effective in mitigating potential harm, hinder the model's ability to provide complete and accurate translations of historical texts. Through real historical examples, this study highlights the inherent challenges and limitations of current LLM safety implementations in the handling of sensitive and context-rich materials. These real-world instances underscore potential failures of LLMs in contemporary translation scenarios, where accurate and comprehensive translations are crucial-for example, translating the accounts of modern victims of war for legal proceedings or humanitarian documentation.", 'abstract_zh': 'Large Language Models (LLMs)在无需显式训练的情况下展示了在各种任务中的卓越适应性，包括机器翻译（MT）。如OpenAI的GPT-4和Google的Gemini等模型由于其高性能，经常用于翻译基准测试并作为翻译工具。本文探讨了Gemini在将18世纪的奥斯曼土耳其手稿《异教徒的囚徒：特梅索拉奥斯曼帕夏的回忆录》翻译成英文方面的表现。该手稿记载了奥斯曼帕夏奥斯曼·阿加在奥地利被俘11年的经历，包括他对战争和暴力的描述。我们的分析显示，Gemini的安全机制标记了手稿14%到23%的内容为有害内容，导致这些部分未被翻译。这些安全设置虽然有效减轻了潜在的危害，但也限制了模型提供全面准确的历史文本翻译的能力。通过实际情况，本文揭示了当前LLM安全实施在处理敏感和情境丰富材料时固有的挑战和局限性。这些实际情况突显了在当今翻译场景中LLM可能在准确和全面翻译方面存在的潜在失败，例如在法律程序或人道主义记录中翻译现代战争受害者的叙述。', 'title_zh': 'LLMs for Translation: Historical and Low-Resourced Languages and Contemporary AI Models'}
{'arxiv_id': 'arXiv:2503.11896', 'title': 'Expressive Music Data Processing and Generation', 'authors': 'Jingwei Liu', 'link': 'https://arxiv.org/abs/2503.11896', 'abstract': "Musical expressivity and coherence are indispensable in music composition and performance, while often neglected in modern AI generative models. In this work, we introduce a listening-based data-processing technique that captures the expressivity in musical performance. This technique derived from Weber's law reflects the human perceptual truth of listening and preserves musical subtlety and expressivity in the training input. To facilitate musical coherence, we model the output interdependencies among multiple arguments in the music data such as pitch, duration, velocity, etc. in the neural networks based on the probabilistic chain rule. In practice, we decompose the multi-output sequential model into single-output submodels and condition previously sampled outputs on the subsequent submodels to induce conditional distributions. Finally, to select eligible sequences from all generations, a tentative measure based on the output entropy was proposed. The entropy sequence is set as a criterion to select predictable and stable generations, which is further studied under the context of informational aesthetic measures to quantify musical pleasure and information gain along the music tendency.", 'abstract_zh': '音乐的表现力和连贯性在音乐创作与表演中不可或缺，但在现代AI生成模型中往往被忽视。本文引入了一种基于聆听的数据处理技术，以捕捉音乐表演中的表现力。这种技术源自韦伯定律，反映了人类听觉感知的真实性，并在训练输入中保留了音乐的微妙性和表现力。为了促进音乐的连贯性，我们基于概率链规则在神经网络中建模了不同音乐数据参数（如音高、时长、力度等）之间的输出依存关系。实际操作中，我们将多输出序列模型分解为单输出子模型，并以前一步生成的输出条件化后续子模型，从而诱导条件分布。最后，为了从所有生成序列中选择合适的序列，提出了基于输出熵的一个临时度量。熵序列设为标准，以选择可预测和稳定的生成，并进一步在信息美学度量的背景下研究，以量化沿音乐倾向的听觉愉悦和信息增益。', 'title_zh': '具有表现力的音乐数据处理与生成'}
{'arxiv_id': 'arXiv:2503.11895', 'title': 'Resolving UnderEdit & OverEdit with Iterative & Neighbor-Assisted Model Editing', 'authors': 'Bhiman Kumar Baghel, Scott M. Jordan, Zheyuan Ryan Shi, Xiang Lorraine Li', 'link': 'https://arxiv.org/abs/2503.11895', 'abstract': 'Large Language Models (LLMs) are used in various downstream language tasks, making it crucial to keep their knowledge up-to-date, but both retraining and fine-tuning the model can be costly. Model editing offers an efficient and effective alternative by a single update to only a key subset of model parameters. While being efficient, these methods are not perfect. Sometimes knowledge edits are unsuccessful, i.e., UnderEdit, or the edit contaminated neighboring knowledge that should remain unchanged, i.e., OverEdit. To address these limitations, we propose iterative model editing, based on our hypothesis that a single parameter update is often insufficient, to mitigate UnderEdit, and neighbor-assisted model editing, which incorporates neighboring knowledge during editing to minimize OverEdit. Extensive experiments demonstrate that our methods effectively reduce UnderEdit up to 38 percentage points and OverEdit up to 6 percentage points across multiple model editing algorithms, LLMs, and benchmark datasets.', 'abstract_zh': '大型语言模型（LLMs）在各种下游语言任务中被广泛应用，保持其知识的时效性至关重要，但重新训练和微调模型可能会很昂贵。通过单次更新关键参数子集来进行模型编辑提供了高效且有效的替代方案。尽管这些方法是高效的，但并非完美无缺。有时知识编辑会失败，即UnderEdit，或者编辑会污染不应改变的邻近知识，即OverEdit。为解决这些问题，我们提出了迭代模型编辑，并基于假设单次参数更新往往不足以改进UnderEdit问题；同时引入了邻域辅助模型编辑，该方法在编辑过程中整合邻近知识以减少OverEdit问题。广泛实验证明，我们的方法能有效降低多个模型编辑算法、大型语言模型和基准数据集上的UnderEdit最高38个百分点和OverEdit最高6个百分点。', 'title_zh': '基于迭代与邻域辅助模型编辑的欠编辑与过编辑解决方法'}
{'arxiv_id': 'arXiv:2503.11880', 'title': 'FedALT: Federated Fine-Tuning through Adaptive Local Training with Rest-of-the-World LoRA', 'authors': 'Jieming Bian, Lei Wang, Letian Zhang, Jie Xu', 'link': 'https://arxiv.org/abs/2503.11880', 'abstract': 'Fine-tuning large language models (LLMs) in federated settings enables privacy-preserving adaptation but suffers from cross-client interference due to model aggregation. Existing federated LoRA fine-tuning methods, primarily based on FedAvg, struggle with data heterogeneity, leading to harmful cross-client interference and suboptimal personalization. In this work, we propose \\textbf{FedALT}, a novel personalized federated LoRA fine-tuning algorithm that fundamentally departs from FedAvg. Instead of using an aggregated model to initialize local training, each client continues training its individual LoRA while incorporating shared knowledge through a separate Rest-of-the-World (RoTW) LoRA component. To effectively balance local adaptation and global information, FedALT introduces an adaptive mixer that dynamically learns input-specific weightings between the individual and RoTW LoRA components using the Mixture-of-Experts (MoE) principle. Through extensive experiments on NLP benchmarks, we demonstrate that FedALT significantly outperforms state-of-the-art personalized federated LoRA fine-tuning methods, achieving superior local adaptation without sacrificing computational efficiency.', 'abstract_zh': 'FedALT：一种新型个性化联邦LoRA微调算法', 'title_zh': 'FedALT：通过适配本地训练与全局参数调整的联邦微调'}
{'arxiv_id': 'arXiv:2503.11851', 'title': 'DCAT: Dual Cross-Attention Fusion for Disease Classification in Radiological Images with Uncertainty Estimation', 'authors': 'Jutika Borah, Hidam Kumarjit Singh', 'link': 'https://arxiv.org/abs/2503.11851', 'abstract': 'Accurate and reliable image classification is crucial in radiology, where diagnostic decisions significantly impact patient outcomes. Conventional deep learning models tend to produce overconfident predictions despite underlying uncertainties, potentially leading to misdiagnoses. Attention mechanisms have emerged as powerful tools in deep learning, enabling models to focus on relevant parts of the input data. Combined with feature fusion, they can be effective in addressing uncertainty challenges. Cross-attention has become increasingly important in medical image analysis for capturing dependencies across features and modalities. This paper proposes a novel dual cross-attention fusion model for medical image analysis by addressing key challenges in feature integration and interpretability. Our approach introduces a bidirectional cross-attention mechanism with refined channel and spatial attention that dynamically fuses feature maps from EfficientNetB4 and ResNet34 leveraging multi-network contextual dependencies. The refined features through channel and spatial attention highlights discriminative patterns crucial for accurate classification. The proposed model achieved AUC of 99.75%, 100%, 99.93% and 98.69% and AUPR of 99.81%, 100%, 99.97%, and 96.36% on Covid-19, Tuberculosis, Pneumonia Chest X-ray images and Retinal OCT images respectively. The entropy values and several high uncertain samples give an interpretable visualization from the model enhancing transparency. By combining multi-scale feature extraction, bidirectional attention and uncertainty estimation, our proposed model strongly impacts medical image analysis.', 'abstract_zh': '准确可靠的医学图像分类对于放射学至关重要，其中诊断决策显著影响患者预后。传统的深度学习模型往往会对带有潜在不确定性的预测过于自信，这可能导致误诊。注意力机制已成为深度学习中的强大工具，能够使模型专注于输入数据的相关部分。结合特征融合，它们可以在应对不确定性挑战时发挥有效作用。交叉注意力在医学图像分析中变得越来越重要，用于捕捉特征和模态之间的依赖关系。本文提出了一种新颖的双向交叉注意力融合模型，通过解决特征集成和可解释性中的关键挑战，用于医学图像分析。该方法引入了一种基于EfficientNetB4和ResNet34的双向交叉注意力机制，并利用多网络上下文依赖性动态融合特征图。通过通道和空间注意力精炼特征，突显了对于准确分类至关重要的判别模式。该提出的模型在COVID-19、肺结核、肺炎胸片图像和视网膜OCT图像上的AUC分别为99.75%、100%、99.93%和98.69%，AUPR分别为99.81%、100%、99.97%和96.36%。熵值和多个高不确定样本提供了可解释的可视化效果，增强透明度。通过结合多尺度特征提取、双向注意力和不确定性估计，我们提出的模型对医学图像分析产生了重大影响。', 'title_zh': 'DCAT：双交叉注意力融合在放射影像疾病分类中的不确定性估计'}
{'arxiv_id': 'arXiv:2503.11846', 'title': 'From Pixels to Histopathology: A Graph-Based Framework for Interpretable Whole Slide Image Analysis', 'authors': 'Alexander Weers, Alexander H. Berger, Laurin Lux, Peter Schüffler, Daniel Rueckert, Johannes C. Paetzold', 'link': 'https://arxiv.org/abs/2503.11846', 'abstract': "The histopathological classification of whole-slide images (WSIs) is a fundamental task in digital pathology; yet it requires extensive time and expertise from specialists. While deep learning methods show promising results, they typically process WSIs by dividing them into artificial patches, which inherently prevents a network from learning from the entire image context, disregards natural tissue structures and compromises interpretability. Our method overcomes this limitation through a novel graph-based framework that constructs WSI graph representations. The WSI-graph efficiently captures essential histopathological information in a compact form. We build tissue representations (nodes) that follow biological boundaries rather than arbitrary patches all while providing interpretable features for explainability. Through adaptive graph coarsening guided by learned embeddings, we progressively merge regions while maintaining discriminative local features and enabling efficient global information exchange. In our method's final step, we solve the diagnostic task through a graph attention network. We empirically demonstrate strong performance on multiple challenging tasks such as cancer stage classification and survival prediction, while also identifying predictive factors using Integrated Gradients. Our implementation is publicly available at this https URL", 'abstract_zh': '全slide图像（WSI）的组织病理学分类是数字病理学中的一个基本任务；但需要大量时间和专家知识。虽然深度学习方法显示出前景，但它们通常通过将WSI划分为人工片段来处理图像，这固有地防止网络从整个图像上下文中学习，忽视了自然组织结构并损害可解释性。我们的方法通过一种新型的图基构建框架克服了这一限制，构造了WSI图表示。WSI图以紧凑的形式高效地捕捉重要组织病理学信息。我们构建了遵循生物边界组织表示（节点），提供了可解释特征以增强可解释性。通过由学习嵌入引导的自适应图粗化，我们逐步合并区域，同时保持区分局部特征并实现高效的全局信息交换。在我们方法的最后一歩，我们通过图注意力网络解决诊断任务。我们在多个具有挑战性的任务中，如癌症分期分类和生存预测，展示了强大的性能，并使用集成梯度识别预测因素。我们的实现已公开发布在以下网址。', 'title_zh': '从像素到病理组织：一种基于图的可解释全视野图像分析框架'}
{'arxiv_id': 'arXiv:2503.11836', 'title': 'Transfer Learning for Automated Feedback Generation on Small Datasets', 'authors': 'Oscar Morris', 'link': 'https://arxiv.org/abs/2503.11836', 'abstract': 'Feedback is a very important part the learning process. However, it is challenging to make this feedback both timely and accurate when relying on human markers. This is the challenge that Automated Feedback Generation attempts to address. In this paper, a technique to train such a system on a very small dataset with very long sequences is presented. Both of these attributes make this a very challenging task, however, by using a three stage transfer learning pipeline state-of-the-art results can be achieved with qualitatively accurate but unhuman sounding results. The use of both Automated Essay Scoring and Automated Feedback Generation systems in the real world is also discussed.', 'abstract_zh': '自动化反馈生成是学习过程中的一个重要组成部分。然而，依赖人类标记者提供及时且准确的反馈具有挑战性。本文提出了在一个非常小的数据集和非常长的序列上训练此类系统的技术。这两个特性使得这一任务极具挑战性，但通过使用三阶段迁移学习管道，可以实现质量上准确但缺乏人性化声音的结果。本文还讨论了在实际中使用自动化作文评分和自动化反馈生成系统的问题。', 'title_zh': '基于少量数据的自动化反馈生成迁移学习'}
{'arxiv_id': 'arXiv:2503.11833', 'title': 'Adaptive Stochastic Gradient Descents on Manifolds with an Application on Weighted Low-Rank Approximation', 'authors': 'Peiqi Yang, Conglong Xu, Hao Wu', 'link': 'https://arxiv.org/abs/2503.11833', 'abstract': 'We prove a convergence theorem for stochastic gradient descents on manifolds with adaptive learning rate and apply it to the weighted low-rank approximation problem.', 'abstract_zh': '我们证明了在流形上具有自适应学习率的随机梯度下降的收敛定理，并将其应用于加权低秩逼近问题。', 'title_zh': '流形上的自适应随机梯度下降及其在加权低秩逼近中的应用'}
{'arxiv_id': 'arXiv:2503.11824', 'title': 'Semi-Supervised Co-Training of Time and Time-Frequency Models: Application to Bearing Fault Diagnosis', 'authors': "Tuomas Jalonen, Mohammad Al-Sa'd, Serkan Kiranyaz, Moncef Gabbouj", 'link': 'https://arxiv.org/abs/2503.11824', 'abstract': 'Neural networks require massive amounts of annotated data to train intelligent solutions. Acquiring many labeled data in industrial applications is often difficult; therefore, semi-supervised approaches are preferred. We propose a new semi-supervised co-training method, which combines time and time-frequency (TF) machine learning models to improve performance and reliability. The developed framework collaboratively co-trains fast time-domain models by utilizing high-performing TF techniques without increasing the inference complexity. Besides, it operates in cloud-edge networks and offers holistic support for many applications covering edge-real-time monitoring and cloud-based updates and corrections. Experimental results on bearing fault diagnosis verify the superiority of our technique compared to a competing self-training method. The results from two case studies show that our method outperforms self-training for different noise levels and amounts of available data with accuracy gains reaching from 10.6% to 33.9%. They demonstrate that fusing time-domain and TF-based models offers opportunities for developing high-performance industrial solutions.', 'abstract_zh': '基于时间和时间-频率模型的新型半监督协同训练方法及其应用', 'title_zh': '时间模型和时频模型的半监督协同训练：轴承故障诊断应用'}
{'arxiv_id': 'arXiv:2503.11807', 'title': 'Mitigating Bad Ground Truth in Supervised Machine Learning based Crop Classification: A Multi-Level Framework with Sentinel-2 Images', 'authors': 'Sanayya A, Amoolya Shetty, Abhijeet Sharma, Venkatesh Ravichandran, Masthan Wali Gosuvarapalli, Sarthak Jain, Priyamvada Nanjundiah, Ujjal Kr Dutta, Divya Sharma', 'link': 'https://arxiv.org/abs/2503.11807', 'abstract': 'In agricultural management, precise Ground Truth (GT) data is crucial for accurate Machine Learning (ML) based crop classification. Yet, issues like crop mislabeling and incorrect land identification are common. We propose a multi-level GT cleaning framework while utilizing multi-temporal Sentinel-2 data to address these issues. Specifically, this framework utilizes generating embeddings for farmland, clustering similar crop profiles, and identification of outliers indicating GT errors. We validated clusters with False Colour Composite (FCC) checks and used distance-based metrics to scale and automate this verification process. The importance of cleaning the GT data became apparent when the models were trained on the clean and unclean data. For instance, when we trained a Random Forest model with the clean GT data, we achieved upto 70\\% absolute percentage points higher for the F1 score metric. This approach advances crop classification methodologies, with potential for applications towards improving loan underwriting and agricultural decision-making.', 'abstract_zh': '在农业管理中，精确的地面真实数据对于基于机器学习的作物分类至关重要。然而，作物错误标签和土地识别不正确等问题普遍存在。我们提出了一种利用多时相Sentinel-2数据的多层次地面真实数据清理框架来解决这些问题。具体而言，该框架通过生成农田嵌入、聚类相似作物特性以及识别表明地面真实数据错误的异常值来实现。我们通过假colour复合图（FCC）检查验证聚类，并使用基于距离的指标来放大和自动化这一验证过程。当模型在清理和未清理的地面真实数据上训练时，清理地面真实数据的重要性变得尤为明显。例如，当使用清理的地面真实数据训练随机森林模型时，F1得分指标提高了多达70%的绝对百分点。该方法推进了作物分类方法的发展，并有可能应用于贷款审批和农业决策等领域。', 'title_zh': '基于Sentinel-2图像的多级框架在监督机器学习作物分类中缓解错误标注数据的影响'}
{'arxiv_id': 'arXiv:2503.11794', 'title': 'Semantic-Clipping: Efficient Vision-Language Modeling with Semantic-Guidedd Visual Selection', 'authors': 'Bangzheng Li, Fei Wang, Wenxuan Zhou, Nan Xu, Ben Zhou, Sheng Zhang, Hoifung Poon, Muhao Chen', 'link': 'https://arxiv.org/abs/2503.11794', 'abstract': 'Vision-Language Models (VLMs) leverage aligned visual encoders to transform images into visual tokens, allowing them to be processed similarly to text by the backbone large language model (LLM). This unified input paradigm enables VLMs to excel in vision-language tasks such as visual question answering (VQA). To improve fine-grained visual reasoning, recent advancements in vision-language modeling introduce image cropping techniques that feed all encoded sub-images into the model. However, this approach significantly increases the number of visual tokens, leading to inefficiency and potential distractions for the LLM. To address the generalization challenges of image representation in VLMs, we propose a lightweight, universal framework that seamlessly integrates with existing VLMs to enhance their ability to process finegrained details. Our method leverages textual semantics to identify key visual areas, improving VQA performance without requiring any retraining of the VLM. Additionally, it incorporates textual signals into the visual encoding process, enhancing both efficiency and effectiveness. The proposed method, SEMCLIP, strengthens the visual understanding of a 7B VLM, LLaVA-1.5 by 3.3% on average across 7 benchmarks, and particularly by 5.3% on the challenging detailed understanding benchmark V*.', 'abstract_zh': 'Vision-Language模型（VLMs）利用对齐的视觉编码器将图像转换为视觉标记，使其能够像文本一样被骨干大规模语言模型（LLM）处理。这种统一的输入范式使VLMs在视觉问答（VQA）等视觉-语言任务中表现出色。为了改进精细视觉推理，最近的视觉-语言建模进展引入了图像裁剪技术，将所有编码的子图像输入到模型中。然而，这种方法大幅增加了视觉标记的数量，导致效率低下并可能分散LLM的注意力。为了解决视觉表示在VLMs中的泛化挑战，我们提出了一种轻量级的通用框架，可以无缝集成到现有的VLMs中，增强其处理细粒度细节的能力。该方法利用文本语义识别关键视觉区域，无需对VLM进行任何重新训练即可提高VQA性能。此外，该方法还将文本信号融入视觉编码过程中，提高了效率和有效性。所提出的方法SEMCLIP在7个基准测试中平均将7B VLM LLaVA-1.5的视觉理解能力增强3.3%，特别是在具有挑战性的详细理解基准测试V*中提高了5.3%。', 'title_zh': '语义剪枝：基于语义导向视觉选择的高效视觉-语言建模'}
{'arxiv_id': 'arXiv:2503.11742', 'title': 'Safe Vision-Language Models via Unsafe Weights Manipulation', 'authors': "Moreno D'Incà, Elia Peruzzo, Xingqian Xu, Humphrey Shi, Nicu Sebe, Massimiliano Mancini", 'link': 'https://arxiv.org/abs/2503.11742', 'abstract': 'Vision-language models (VLMs) often inherit the biases and unsafe associations present within their large-scale training dataset. While recent approaches mitigate unsafe behaviors, their evaluation focuses on how safe the model is on unsafe inputs, ignoring potential shortcomings on safe ones. In this paper, we first revise safety evaluation by introducing SafeGround, a new set of metrics that evaluate safety at different levels of granularity. With this metric, we uncover a surprising issue of training-based methods: they make the model less safe on safe inputs. From this finding, we take a different direction and explore whether it is possible to make a model safer without training, introducing Unsafe Weights Manipulation (UWM). UWM uses a calibration set of safe and unsafe instances to compare activations between safe and unsafe content, identifying the most important parameters for processing the latter. Their values are then manipulated via negation. Experiments show that UWM achieves the best tradeoff between safety and knowledge preservation, consistently improving VLMs on unsafe queries while outperforming even training-based state-of-the-art methods on safe ones.', 'abstract_zh': '基于视觉-语言模型的安全性评估：SafeGround及其应用', 'title_zh': '通过不安全的权重操纵实现安全的跨模态模型'}
{'arxiv_id': 'arXiv:2503.11741', 'title': 'BioMamba: Leveraging Spectro-Temporal Embedding in Bidirectional Mamba for Enhanced Biosignal Classification', 'authors': 'Jian Qian, Teck Lun Goh, Bingyu Xie, Chengyao Zhu, Biao Wan, Yawen Guan, Patrick Yin Chiang', 'link': 'https://arxiv.org/abs/2503.11741', 'abstract': 'Biological signals, such as electroencephalograms (EEGs) and electrocardiograms (ECGs), play a pivotal role in numerous clinical practices, such as diagnosing brain and cardiac arrhythmic diseases. Existing methods for biosignal classification rely on Attention-based frameworks with dense Feed Forward layers, which lead to inefficient learning, high computational overhead, and suboptimal performance. In this work, we introduce BioMamba, a Spectro-Temporal Embedding strategy applied to the Bidirectional Mamba framework with Sparse Feed Forward layers to enable effective learning of biosignal sequences. By integrating these three key components, BioMamba effectively addresses the limitations of existing methods. Extensive experiments demonstrate that BioMamba significantly outperforms state-of-the-art methods with marked improvement in classification performance. The advantages of the proposed BioMamba include (1) Reliability: BioMamba consistently delivers robust results, confirmed across six evaluation metrics. (2) Efficiency: We assess both model and training efficiency, the BioMamba demonstrates computational effectiveness by reducing model size and resource consumption compared to existing approaches. (3) Generality: With the capacity to effectively classify a diverse set of tasks, BioMamba demonstrates adaptability and effectiveness across various domains and applications.', 'abstract_zh': '生物信号，如脑电图（EEGs）和心电图（ECGs），在临床实践中发挥着关键作用，例如诊断脑部和心脏节律性疾病。现有的生物信号分类方法依赖于基于注意力的框架和密集的全连接层，导致学习效率低下、计算开销高和性能不佳。在这项工作中，我们引入了BioMamba，这是一种应用于双向Mamba框架的频谱-时间嵌入策略，结合稀疏全连接层，以实现生物信号序列的有效学习。通过结合这三个关键组件，BioMamba有效地解决了现有方法的局限性。广泛的实验表明，BioMamba在分类性能上显著优于现有最先进的方法，具有显著的改进。所提出BioMamba的优点包括：（1）可靠性：BioMamba在六项评估指标上一致提供稳健的结果。（2）效率：我们在模型和训练效率方面进行评估，BioMamba通过减小模型规模和资源消耗显示出计算上的有效性，优于现有方法。（3）普适性：BioMamba具有有效分类一系列任务的能力，展示了在各种领域和应用中的适应性和有效性。', 'title_zh': 'BioMamba：利用双向Mamba中的频谱-时间嵌入增强生物信号分类'}
{'arxiv_id': 'arXiv:2503.11739', 'title': 'CoLLMLight: Cooperative Large Language Model Agents for Network-Wide Traffic Signal Control', 'authors': 'Zirui Yuan, Siqi Lai, Hao Liu', 'link': 'https://arxiv.org/abs/2503.11739', 'abstract': 'Traffic Signal Control (TSC) plays a critical role in urban traffic management by optimizing traffic flow and mitigating congestion. While Large Language Models (LLMs) have recently emerged as promising tools for TSC due to their exceptional problem-solving and generalization capabilities, existing approaches fail to address the essential need for inter-agent coordination, limiting their effectiveness in achieving network-wide optimization. To bridge this gap, we propose CoLLMLight, a cooperative LLM agent framework for TSC. Specifically, we first construct a structured spatiotemporal graph to capture real-time traffic dynamics and spatial relationships among neighboring intersections, enabling the LLM to reason about complex traffic interactions. Moreover, we introduce a complexity-aware reasoning mechanism that dynamically adapts reasoning depth based on real-time traffic conditions, ensuring optimal computational efficiency without sacrificing decision quality. Besides, we propose a fine-tuning strategy that leverages iterative simulation-driven data collection and environmental feedback to build a lightweight LLM tailored for cooperative TSC. Extensive experiments on both synthetic and real-world datasets demonstrate that CoLLMLight outperforms state-of-the-art methods in diverse traffic scenarios, showcasing its effectiveness, scalability, and robustness.', 'abstract_zh': '交通信号控制（TSC）在城市交通管理中发挥着关键作用，通过优化交通流量和缓解拥堵。尽管大型语言模型（LLMs）因卓越的问题解决能力和通用化能力而近年来成为TSC的有前景工具，但现有方法未能满足代理间协调的必要需求，限制了它们在网络级优化方面的效果。为了弥补这一差距，我们提出了一种协同LLM代理框架CoLLMLight，用于TSC。具体地，我们首先构建了一个结构化的时空图，以捕捉实时交通动态和相邻交叉口之间的空间关系，使LLM能够推理复杂的交通交互。此外，我们引入了一种面向复杂性的推理机制，可根据实时交通条件动态调整推理深度，确保在不牺牲决策质量的情况下获得最优的计算效率。另外，我们提出了一种微调策略，利用迭代仿真驱动的数据收集和环境反馈来构建一个适用于协同TSC的轻量级LLM。在合成数据集和真实世界数据集上的广泛实验表明，CoLLMLight在多种交通场景中均优于现有方法，展示了其有效性、可扩展性和鲁棒性。', 'title_zh': 'CollMLight：协作的大语言模型代理在网络范围内的交通信号控制中应用'}
{'arxiv_id': 'arXiv:2503.11737', 'title': 'Multi-View Node Pruning for Accurate Graph Representation', 'authors': 'Jiseong Park, Hanjin Kim, Seojin Kim, Jueun Choi', 'link': 'https://arxiv.org/abs/2503.11737', 'abstract': 'Graph pooling, which compresses a whole graph into a smaller coarsened graph, is an essential component of graph representation learning. To efficiently compress a given graph, graph pooling methods often drop their nodes with attention-based scoring with the task loss. However, this often results in simply removing nodes with lower degrees without consideration of their feature-level relevance to the given task. To fix this problem, we propose a Multi-View Pruning(MVP), a graph pruning method based on a multi-view framework and reconstruction loss. Given a graph, MVP first constructs multiple graphs for different views either by utilizing the predefined modalities or by randomly partitioning the input features, to consider the importance of each node in diverse perspectives. Then, it learns the score for each node by considering both the reconstruction and the task loss. MVP can be incorporated with any hierarchical pooling framework to score the nodes. We validate MVP on multiple benchmark datasets by coupling it with two graph pooling methods, and show that it significantly improves the performance of the base graph pooling method, outperforming all baselines. Further analysis shows that both the encoding of multiple views and the consideration of reconstruction loss are the key to the success of MVP, and that it indeed identifies nodes that are less important according to domain knowledge.', 'abstract_zh': '基于多视图框架和重构损失的图剪枝方法：MVP', 'title_zh': '多视图节点剪枝以实现准确的图表示'}
{'arxiv_id': 'arXiv:2503.11733', 'title': 'LLM Agents for Education: Advances and Applications', 'authors': 'Zhendong Chu, Shen Wang, Jian Xie, Tinghui Zhu, Yibo Yan, Jinheng Ye, Aoxiao Zhong, Xuming Hu, Jing Liang, Philip S. Yu, Qingsong Wen', 'link': 'https://arxiv.org/abs/2503.11733', 'abstract': 'Large Language Model (LLM) agents have demonstrated remarkable capabilities in automating tasks and driving innovation across diverse educational applications. In this survey, we provide a systematic review of state-of-the-art research on LLM agents in education, categorizing them into two broad classes: (1) \\emph{Pedagogical Agents}, which focus on automating complex pedagogical tasks to support both teachers and students; and (2) \\emph{Domain-Specific Educational Agents}, which are tailored for specialized fields such as science education, language learning, and professional development. We comprehensively examine the technological advancements underlying these LLM agents, including key datasets, benchmarks, and algorithmic frameworks that drive their effectiveness. Furthermore, we discuss critical challenges such as privacy, bias and fairness concerns, hallucination mitigation, and integration with existing educational ecosystems. This survey aims to provide a comprehensive technological overview of LLM agents for education, fostering further research and collaboration to enhance their impact for the greater good of learners and educators alike.', 'abstract_zh': '大型语言模型代理在教育领域的研究进展：面向教学的应用与专属性教育代理的系统综述', 'title_zh': '教育领域的大型语言模型代理：进展与应用'}
{'arxiv_id': 'arXiv:2503.11732', 'title': 'Class-Level Feature Selection Method Using Feature Weighted Growing Self-Organising Maps', 'authors': 'Andrew Starkey, Uduak Idio Akpan, Omaimah AL Hosni, Yaseen Pullissery', 'link': 'https://arxiv.org/abs/2503.11732', 'abstract': 'There have been several attempts to develop Feature Selection (FS) algorithms capable of identifying features that are relevant in a dataset. Although in certain applications the FS algorithms can be seen to be successful, they have similar basic limitations. In all cases, the global feature selection algorithms seek to select features that are relevant and common to all classes of the dataset. This is a major limitation since there could be features that are specifically useful for a particular class while irrelevant for other classes, and full explanation of the relationship at class level therefore cannot be determined. While the inclusion of such features for all classes could cause improved predictive ability for the relevant class, the same features could be problematic for other classes. In this paper, we examine this issue and also develop a class-level feature selection method called the Feature Weighted Growing Self-Organising Map (FWGSOM). The proposed method carries out feature analysis at class level which enhances its ability to identify relevant features for each class. Results from experiments indicate that our method performs better than other methods, gives explainable results at class level, and has a low computational footprint when compared to other methods.', 'abstract_zh': '在数据集中识别相关特征的特征选择算法已有若干尝试。尽管在某些应用中特征选择算法可以取得成功，但它们存在类似的基本局限性。在所有情况下，全局特征选择算法都试图选择对所有数据集类别的特征都有意义的特征。这是一个主要的局限性，因为可能存在仅对特定类别有用而不对其他类别有用的特征，从而无法在类别级别上确定这些关系的完整解释。虽然包括这些特征可以提高相关类别预测能力，但这些特征对于其他类别可能存在问题。在本文中，我们探讨了这一问题并开发了一种称为特征加权增长自组织映射（FWGSOM）的类别级别特征选择方法。所提方法在类别级别进行特征分析，增强了其识别每个类别相关特征的能力。实验结果表明，与现有方法相比，我们的方法在类级别提供了可解释的结果，并且与现有方法相比具有较低的计算成本。', 'title_zh': '基于特征加权生长自组织映射的类级特征选择方法'}
{'arxiv_id': 'arXiv:2503.11730', 'title': 'BACE-RUL: A Bi-directional Adversarial Network with Covariate Encoding for Machine Remaining Useful Life Prediction', 'authors': 'Zekai Zhang, Dan Li, Shunyu Wu, Junya Cai, Bo Zhang, See Kiong Ng, Zibin Zheng', 'link': 'https://arxiv.org/abs/2503.11730', 'abstract': 'Prognostic and Health Management (PHM) are crucial ways to avoid unnecessary maintenance for Cyber-Physical Systems (CPS) and improve system reliability. Predicting the Remaining Useful Life (RUL) is one of the most challenging tasks for PHM. Existing methods require prior knowledge about the system, contrived assumptions, or temporal mining to model the life cycles of machine equipment/devices, resulting in diminished accuracy and limited applicability in real-world scenarios. This paper proposes a Bi-directional Adversarial network with Covariate Encoding for machine Remaining Useful Life (BACE-RUL) prediction, which only adopts sensor measurements from the current life cycle to predict RUL rather than relying on previous consecutive cycle recordings. The current sensor measurements of mechanical devices are encoded to a conditional space to better understand the implicit inner mechanical status. The predictor is trained as a conditional generative network with the encoded sensor measurements as its conditions. Various experiments on several real-world datasets, including the turbofan aircraft engine dataset and the dataset collected from degradation experiments of Li-Ion battery cells, show that the proposed model is a general framework and outperforms state-of-the-art methods.', 'abstract_zh': '基于双向对抗网络和协变量编码的机械剩余寿命预测（BACE-RUL）', 'title_zh': 'BACE-RUL：一种带有协变量编码的双向对抗网络机器剩余使用寿命预测'}
{'arxiv_id': 'arXiv:2503.11728', 'title': 'Forecasting Empty Container availability for Vehicle Booking System Application', 'authors': 'Arthur Cartel Foahom Gouabou, Mohammed Al-Kharaz, Faouzi Hakimi, Tarek Khaled, Kenza Amzil', 'link': 'https://arxiv.org/abs/2503.11728', 'abstract': 'Container terminals, pivotal nodes in the network of empty container movement, hold significant potential for enhancing operational efficiency within terminal depots through effective collaboration between transporters and terminal operators. This collaboration is crucial for achieving optimization, leading to streamlined operations and reduced congestion, thereby benefiting both parties. Consequently, there is a pressing need to develop the most suitable forecasting approaches to address this challenge. This study focuses on developing and evaluating a data-driven approach for forecasting empty container availability at container terminal depots within a Vehicle Booking System (VBS) framework. It addresses the gap in research concerning optimizing empty container dwell time and aims to enhance operational efficiencies in container terminal operations. Four forecasting models-Naive, ARIMA, Prophet, and LSTM-are comprehensively analyzed for their predictive capabilities, with LSTM emerging as the top performer due to its ability to capture complex time series patterns. The research underscores the significance of selecting appropriate forecasting techniques tailored to the specific requirements of container terminal operations, contributing to improved operational planning and management in maritime logistics.', 'abstract_zh': '集装箱码头：作为空箱流动网络中的关键节点，通过运输商与码头运营商的有效合作，拥有通过优化协作提高码头仓库运营效率的显著潜力。为此，有必要开发合适的预测方法来应对这一挑战。本研究旨在基于车辆预订系统（VBS）的框架，开发并评估一种数据驱动的预测方法，以预测集装箱码头仓库中的空箱可用性，解决优化空箱停留时间的研究缺口，旨在提高集装箱码头运营效率。四种预测模型——朴素法、ARIMA、Prophet和LSTM——被全面分析其预测能力，其中LSTM因其能够捕捉复杂的时间序列模式而表现最佳。研究强调选择合适的预测技术对于满足集装箱码头运营特定需求的重要性，有助于改善海运物流中的运营规划与管理。', 'title_zh': '基于车辆预订系统应用的空箱可用性预测'}
{'arxiv_id': 'arXiv:2503.11726', 'title': 'SPECTra: Scalable Multi-Agent Reinforcement Learning with Permutation-Free Networks', 'authors': 'Hyunwoo Park, Baekryun Seong, Sang-Ki Ko', 'link': 'https://arxiv.org/abs/2503.11726', 'abstract': 'In cooperative multi-agent reinforcement learning (MARL), the permutation problem where the state space grows exponentially with the number of agents reduces sample efficiency. Additionally, many existing architectures struggle with scalability, relying on a fixed structure tied to a specific number of agents, limiting their applicability to environments with a variable number of entities. While approaches such as graph neural networks (GNNs) and self-attention mechanisms have progressed in addressing these challenges, they have significant limitations as dense GNNs and self-attention mechanisms incur high computational costs. To overcome these limitations, we propose a novel agent network and a non-linear mixing network that ensure permutation-equivariance and scalability, allowing them to generalize to environments with various numbers of agents. Our agent network significantly reduces computational complexity, and our scalable hypernetwork enables efficient weight generation for non-linear mixing. Additionally, we introduce curriculum learning to improve training efficiency. Experiments on SMACv2 and Google Research Football (GRF) demonstrate that our approach achieves superior learning performance compared to existing methods. By addressing both permutation-invariance and scalability in MARL, our work provides a more efficient and adaptable framework for cooperative MARL. Our code is available at this https URL.', 'abstract_zh': '在合作多智能体强化学习（MARL）中，随着智能体数量增加而指数级增长的状态空间导致采样效率降低。此外，许多现有架构在可扩展性方面存在不足，依赖于固定结构，只能适用于特定数量智能体的环境，限制了它们在智能体数量可变的环境中的应用。尽管图神经网络（GNN）和自注意力机制等方法在解决这些问题方面取得了进步，但密集的GNN和自注意力机制会带来高昂的计算成本。为克服这些限制，我们提出了一种新型智能体网络和非线性混合网络，以确保置换不变性和可扩展性，使其能够适应不同数量智能体的环境。我们的智能体网络显著降低了计算复杂度，而我们的可扩展超网络使非线性混合的权重生成更加高效。此外，我们引入了分级学习以提高训练效率。在SMACv2和Google Research Football（GRF）上的实验表明，我们的方法在学习性能上优于现有方法。通过同时解决MARL中的置换不变性和可扩展性问题，我们的工作为合作MARL提供了更高效和更具适应性的框架。我们的代码可在以下链接获取。', 'title_zh': 'SPECTra: 可扩展的无排列依赖多智能体 reinforcement 学习'}
{'arxiv_id': 'arXiv:2503.11720', 'title': 'Fine-Tuning Diffusion Generative Models via Rich Preference Optimization', 'authors': 'Hanyang Zhao, Haoxian Chen, Yucheng Guo, Genta Indra Winata, Tingting Ou, Ziyu Huang, David D. Yao, Wenpin Tang', 'link': 'https://arxiv.org/abs/2503.11720', 'abstract': 'We introduce Rich Preference Optimization (RPO), a novel pipeline that leverages rich feedback signals to improve the curation of preference pairs for fine-tuning text-to-image diffusion models. Traditional methods, like Diffusion-DPO, often rely solely on reward model labeling, which can be opaque, offer limited insights into the rationale behind preferences, and are prone to issues such as reward hacking or overfitting. In contrast, our approach begins with generating detailed critiques of synthesized images to extract reliable and actionable image editing instructions. By implementing these instructions, we create refined images, resulting in synthetic, informative preference pairs that serve as enhanced tuning datasets. We demonstrate the effectiveness of our pipeline and the resulting datasets in fine-tuning state-of-the-art diffusion models.', 'abstract_zh': 'Rich Preference Optimization: 一种利用丰富反馈信号改进文本到图像扩散模型微调偏序对策管stype', 'title_zh': '通过丰富的偏好优化 fine-tuning 扩散生成模型'}
{'arxiv_id': 'arXiv:2503.11711', 'title': 'Privacy-Preserved Automated Scoring using Federated Learning for Educational Research', 'authors': 'Ehsan Latif, Xiaoming Zhai', 'link': 'https://arxiv.org/abs/2503.11711', 'abstract': 'Data privacy remains a critical concern in educational research, necessitating Institutional Review Board (IRB) certification and stringent data handling protocols to ensure compliance with ethical standards. Traditional approaches rely on anonymization and controlled data-sharing mechanisms to facilitate research while mitigating privacy risks. However, these methods still involve direct access to raw student data, posing potential vulnerabilities and being time-consuming. This study proposes a federated learning (FL) framework for automatic scoring in educational assessments, eliminating the need to share raw data. Our approach leverages client-side model training, where student responses are processed locally on edge devices, and only optimized model parameters are shared with a central aggregation server. To effectively aggregate heterogeneous model updates, we introduce an adaptive weighted averaging strategy, which dynamically adjusts weight contributions based on client-specific learning characteristics. This method ensures robust model convergence while preserving privacy. We evaluate our framework using assessment data from nine middle schools, comparing the accuracy of federated learning-based scoring models with traditionally trained centralized models. A statistical significance test (paired t-test, $t(8) = 2.29, p = 0.051$) confirms that the accuracy difference between the two approaches is not statistically significant, demonstrating that federated learning achieves comparable performance while safeguarding student data. Furthermore, our method significantly reduces data collection, processing, and deployment overhead, accelerating the adoption of AI-driven educational assessments in a privacy-compliant manner.', 'abstract_zh': '联邦学习在教育评估中的自动评分：保护学生数据隐私的同时实现高性能', 'title_zh': '隐私保护的联邦学习自动评分在教育研究中的应用'}
{'arxiv_id': 'arXiv:2503.11710', 'title': 'ConjointNet: Enhancing Conjoint Analysis for Preference Prediction with Representation Learning', 'authors': 'Yanxia Zhang, Francine Chen, Shabnam Hakimi, Totte Harinen, Alex Filipowicz, Yan-Ying Chen, Rumen Iliev, Nikos Arechiga, Kalani Murakami, Kent Lyons, Charlene Wu, Matt Klenk', 'link': 'https://arxiv.org/abs/2503.11710', 'abstract': 'Understanding consumer preferences is essential to product design and predicting market response to these new products. Choice-based conjoint analysis is widely used to model user preferences using their choices in surveys. However, traditional conjoint estimation techniques assume simple linear models. This assumption may lead to limited predictability and inaccurate estimation of product attribute contributions, especially on data that has underlying non-linear relationships. In this work, we employ representation learning to efficiently alleviate this issue. We propose ConjointNet, which is composed of two novel neural architectures, to predict user preferences. We demonstrate that the proposed ConjointNet models outperform traditional conjoint estimate techniques on two preference datasets by over 5%, and offer insights into non-linear feature interactions.', 'abstract_zh': '基于选择的联合分析：通过表示学习提高用户偏好预测的非线性特征交互洞察', 'title_zh': '共轭网络：基于表示学习的联合分析增强偏好预测'}
{'arxiv_id': 'arXiv:2503.11709', 'title': 'Conformal Prediction and Human Decision Making', 'authors': 'Jessica Hullman, Yifan Wu, Dawei Xie, Ziyang Guo, Andrew Gelman', 'link': 'https://arxiv.org/abs/2503.11709', 'abstract': "Methods to quantify uncertainty in predictions from arbitrary models are in demand in high-stakes domains like medicine and finance. Conformal prediction has emerged as a popular method for producing a set of predictions with specified average coverage, in place of a single prediction and confidence value. However, the value of conformal prediction sets to assist human decisions remains elusive due to the murky relationship between coverage guarantees and decision makers' goals and strategies. How should we think about conformal prediction sets as a form of decision support? Under what conditions do we expect the support they provide to be superior versus inferior to that of alternative presentations of predictive uncertainty? We outline a decision theoretic framework for evaluating predictive uncertainty as informative signals, then contrast what can be said within this framework about idealized use of calibrated probabilities versus conformal prediction sets. Informed by prior empirical results and theories of human decisions under uncertainty, we formalize a set of possible strategies by which a decision maker might use a prediction set. We identify ways in which conformal prediction sets and posthoc predictive uncertainty quantification more broadly are in tension with common goals and needs in human-AI decision making. We give recommendations for future research in predictive uncertainty quantification to support human decision makers.", 'abstract_zh': '量化来自任意模型预测不确定性的方法在高风险领域如医学和金融中需求日益增加。条件一致性预测已成为一种流行的生成具有指定平均覆盖范围的预测集的方法，取代单一预测和置信值。然而，条件一致性预测集对辅助人类决策的价值仍然难以明确，因为覆盖保证与决策者的目标和策略之间的关系模糊。我们应如何将条件一致性预测集视为一种决策支持形式？在什么条件下，我们期望它们提供的支持优于或劣于替代预测不确定性表示形式的支持？我们提出了一种决策理论框架，用于评估预测不确定性的信息信号，然后对比了该框架内关于校准概率的理想化使用与条件一致性预测集之间可以阐述的内容。根据先前的实证结果和不确定环境下的人类决策理论，我们正式化了一系列决策者可能采用的策略，使用预测集。我们指出了条件一致性预测集和更广泛的.post hoc不确定性量化与人类-人工智能决策中常见目标和需求之间的矛盾之处。我们为支持人类决策者在未来研究预测不确定性量化中提出建议。', 'title_zh': '符合性预测与人类决策making'}
{'arxiv_id': 'arXiv:2503.11706', 'title': 'Refining Filter Global Feature Weighting for Fully-Unsupervised Clustering', 'authors': 'Fabian Galis, Darian Onchis', 'link': 'https://arxiv.org/abs/2503.11706', 'abstract': 'In the context of unsupervised learning, effective clustering plays a vital role in revealing patterns and insights from unlabeled data. However, the success of clustering algorithms often depends on the relevance and contribution of features, which can differ between various datasets. This paper explores feature weighting for clustering and presents new weighting strategies, including methods based on SHAP (SHapley Additive exPlanations), a technique commonly used for providing explainability in various supervised machine learning tasks. By taking advantage of SHAP values in a way other than just to gain explainability, we use them to weight features and ultimately improve the clustering process itself in unsupervised scenarios.\nOur empirical evaluations across five benchmark datasets and clustering methods demonstrate that feature weighting based on SHAP can enhance unsupervised clustering quality, achieving up to a 22.69\\% improvement over other weighting methods (from 0.586 to 0.719 in terms of the Adjusted Rand Index). Additionally, these situations where the weighted data boosts the results are highlighted and thoroughly explored, offering insight for practical applications.', 'abstract_zh': '在无监督学习.context中，有效的聚类对于揭示未标记数据中的模式和见解起着至关重要的作用。然而，聚类算法的成功往往取决于特征的相关性和贡献，而这些在不同数据集中可能有所不同。本文探讨了聚类中的特征加权，并提出了一种新的加权策略，包括基于SHAP（SHapley Additive exPlanations）的方法，这是一种常用于提供监督机器学习任务可解释性的技术。通过利用SHAP值，我们不仅用来获得可解释性，还用于加权特征，从而在无监督场景中提高聚类过程本身的效果。我们在五个基准数据集和聚类方法上的实证评估表明，基于SHAP的特征加权可以提升无监督聚类的质量，相较于其他加权方法，在调整兰德指数（Adjusted Rand Index）上最高可提高22.69%（从0.586提高到0.719）。同时，加权数据增强效果的情况也被强调并进行了深入探讨，为实际应用提供了见解。', 'title_zh': '改进滤波全局特征权值赋予权对全程无监督聚类的优化'}
{'arxiv_id': 'arXiv:2503.11696', 'title': 'Balancing SoC in Battery Cells using Safe Action Perturbations', 'authors': 'E Harshith Kumar Yadav, Rahul Narava, Anshika, Shashi Shekher Jha', 'link': 'https://arxiv.org/abs/2503.11696', 'abstract': "Managing equal charge levels in active cell balancing while charging a Li-ion battery is challenging. An imbalance in charge levels affects the state of health of the battery, along with the concerns of thermal runaway and fire hazards. Traditional methods focus on safety assurance as a trade-off between safety and charging time. Others deal with battery-specific conditions to ensure safety, therefore losing on the generalization of the control strategies over various configurations of batteries. In this work, we propose a method to learn safe battery charging actions by using a safety-layer as an add-on over a Deep Reinforcement Learning (RL) agent. The safety layer perturbs the agent's action to prevent the battery from encountering unsafe or dangerous states. Further, our Deep RL framework focuses on learning a generalized policy that can be effectively employed with varying configurations of batteries. Our experimental results demonstrate that the safety-layer based action perturbation incurs fewer safety violations by avoiding unsafe states along with learning a robust policy for several battery configurations.", 'abstract_zh': '在活性电芯充电过程中管理均衡电荷水平以防止锂离子电池电荷不平衡是一项挑战。电荷不平衡会影响电池的健康状态，并引发热失控和火灾风险。传统方法在安全性和充电时间之间寻求权衡。其他方法专注于特定电池条件下的安全，从而在不同电池配置下降低了控制策略的普适性。在本研究中，我们提出了一种方法，利用安全层作为深度强化学习（RL）代理的附加层，以学习安全的电池充电行动。安全层扰动代理的行动，以防止电池进入不安全或危险状态。此外，我们的深度RL框架专注于学习一种普适性强的策略，能够在不同电池配置下有效应用。实验结果表明，基于安全层的行动扰动可以避免不安全状态，同时学习适用于多种电池配置的稳健策略。', 'title_zh': '使用安全动作扰动平衡电池单元的SoC'}
{'arxiv_id': 'arXiv:2503.11695', 'title': 'MELON: Multimodal Mixture-of-Experts with Spectral-Temporal Fusion for Long-Term Mobility Estimation in Critical Care', 'authors': 'Jiaqing Zhang, Miguel Contreras, Jessica Sena, Andrea Davidson, Yuanfang Ren, Ziyuan Guan, Tezcan Ozrazgat-Baslanti, Tyler J. Loftus, Subhash Nerella, Azra Bihorac, Parisa Rashidi', 'link': 'https://arxiv.org/abs/2503.11695', 'abstract': 'Patient mobility monitoring in intensive care is critical for ensuring timely interventions and improving clinical outcomes. While accelerometry-based sensor data are widely adopted in training artificial intelligence models to estimate patient mobility, existing approaches face two key limitations highlighted in clinical practice: (1) modeling the long-term accelerometer data is challenging due to the high dimensionality, variability, and noise, and (2) the absence of efficient and robust methods for long-term mobility assessment. To overcome these challenges, we introduce MELON, a novel multimodal framework designed to predict 12-hour mobility status in the critical care setting. MELON leverages the power of a dual-branch network architecture, combining the strengths of spectrogram-based visual representations and sequential accelerometer statistical features. MELON effectively captures global and fine-grained mobility patterns by integrating a pre-trained image encoder for rich frequency-domain feature extraction and a Mixture-of-Experts encoder for sequence modeling. We trained and evaluated the MELON model on the multimodal dataset of 126 patients recruited from nine Intensive Care Units at the University of Florida Health Shands Hospital main campus in Gainesville, Florida. Experiments showed that MELON outperforms conventional approaches for 12-hour mobility status estimation with an overall area under the receiver operating characteristic curve (AUROC) of 0.82 (95\\%, confidence interval 0.78-0.86). Notably, our experiments also revealed that accelerometer data collected from the wrist provides robust predictive performance compared with data from the ankle, suggesting a single-sensor solution that can reduce patient burden and lower deployment costs...', 'abstract_zh': '重症监护中患者移动性的监测对于确保及时干预和改善临床结果至关重要。虽然加速度计基传感器数据广泛应用于训练人工智能模型以估计患者移动性，但现有方法在临床实践中面临两大关键限制：(1) 对长时间加速度计数据进行建模具有挑战性，因为这些数据具有高维度、变异性及噪声；(2) 缺乏有效的长期移动性评估方法。为克服这些挑战，我们引入了MELON，这是一种新颖的多模态框架，用于预测重症监护环境下的12小时移动状态。MELON利用双分支网络架构的力量，结合基于频谱图的视觉表示和序列加速度计统计特征的优势。MELON通过结合预训练的图像编码器进行丰富的频域特征提取和Mixture-of-Experts编码器进行序列建模，有效捕捉全局和细粒度的移动模式。我们在美国佛罗里达大学健康桑兹医院盖恩斯维尔主校区重症监护病房招募的126名患者组成的多模态数据集上训练和评估了MELON模型。实验结果显示，MELON在12小时移动状态估计中优于传统方法，整体受试者操作特征曲线下的面积（AUROC）为0.82（95%置信区间0.78-0.86）。值得注意的是，我们的实验还表明，来自手腕的加速度计数据提供了稳健的预测性能，相比之下，来自脚踝的数据性能较弱，这表明可以采用单传感器解决方案来减轻患者负担并降低部署成本……', 'title_zh': 'MELON：多模态专家混合与谱时融合在重症监护中的长期移动性估计'}
{'arxiv_id': 'arXiv:2503.11674', 'title': 'Timing-Driven Global Placement by Efficient Critical Path Extraction', 'authors': 'Yunqi Shi, Siyuan Xu, Shixiong Kai, Xi Lin, Ke Xue, Mingxuan Yuan, Chao Qian', 'link': 'https://arxiv.org/abs/2503.11674', 'abstract': 'Timing optimization during the global placement of integrated circuits has been a significant focus for decades, yet it remains a complex, unresolved issue. Recent analytical methods typically use pin-level timing information to adjust net weights, which is fast and simple but neglects the path-based nature of the timing graph. The existing path-based methods, however, cannot balance the accuracy and efficiency due to the exponential growth of number of critical paths. In this work, we propose a GPU-accelerated timing-driven global placement framework, integrating accurate path-level information into the efficient DREAMPlace infrastructure. It optimizes the fine-grained pin-to-pin attraction objective and is facilitated by efficient critical path extraction. We also design a quadratic distance loss function specifically to align with the RC timing model. Experimental results demonstrate that our method significantly outperforms the current leading timing-driven placers, achieving an average improvement of 40.5% in total negative slack (TNS) and 8.3% in worst negative slack (WNS), as well as an improvement in half-perimeter wirelength (HPWL).', 'abstract_zh': '全球布线过程中集成电路的定时优化一直是几十年来的研究重点，但仍然是一个复杂且未解决的问题。尽管最近的分析方法通常使用引脚级定时信息来调整网的权重，这种方法快速且简单，但忽略了定时图的路径基础特性。现有的基于路径的方法由于关键路径数量的指数级增长，无法平衡准确性与效率。在这项工作中，我们提出了一种基于GPU加速的驱动定时全局布线框架，将精确的路径级信息整合到高效的DREAMPlace架构中。该框架优化了细粒度的引脚到引脚吸引力目标，并通过高效的关键路径提取来协助。我们还设计了一个二次距离损失函数，专门与RC定时模型对齐。实验结果表明，我们的方法明显优于当前领先的定时驱动布线器，平均在总负时宽(TNS)上提高了40.5%，在最坏负时宽(WNS)上提高了8.3%，并且在半周长布线长度(HPWL)上也有所改进。', 'title_zh': '由高效关键路径提取驱动的时驱动全局布放'}
{'arxiv_id': 'arXiv:2503.11666', 'title': 'Optimizing Coverage-Driven Verification Using Machine Learning and PyUVM: A Novel Approach', 'authors': 'Suruchi Kumari, Deepak Narayan Gadde, Aman Kumar', 'link': 'https://arxiv.org/abs/2503.11666', 'abstract': 'The escalating complexity of System-on-Chip (SoC) designs has created a bottleneck in verification, with traditional techniques struggling to achieve complete coverage. Existing techniques, such as Constrained Random Verification (CRV) and coverage-driven methodologies, rely on time-consuming and redundant simulation regression, leading to higher verification costs and longer time-to-market due to the manual effort required to adjust constraints and drive the stimuli to achieve coverage objectives. To address this challenge, we propose a novel methodology that leverages supervised Machine Learning (ML) to optimize simulation regressions, resulting in reduced simulation run-time and the number of test simulations required to achieve target coverage goals. We also investigate and compare the effectiveness of various supervised learning algorithms from scikit-learn. Our results demonstrate that these algorithms can achieve at least 99% coverage regain with significantly reduced simulation cycles. We utilize Python Universal Verification Methodology (PyUVM) over SystemVerilog-Universal Verification Methodology (SV-UVM) for testbench creation, enabling simpler constructs using Python and facilitating the reuse of existing ML libraries. Our methodology is applied to three diverse designs, and our results show that it can significantly reduce verification costs, manual efforts, and time-to-market, while enhancing verification productivity and completeness, by automating the testbench update process and achieving target coverage goals.', 'abstract_zh': 'SoC设计复杂性的攀升导致验证瓶颈，传统技术难以实现全面覆盖。为应对这一挑战，我们提出了一种新型方法，利用监督机器学习优化仿真回归，从而减少仿真运行时间和达到目标覆盖目标所需的测试仿真次数。我们还研究并比较了scikit-learn中各种监督学习算法的有效性。结果显示，这些算法可以在显著减少仿真周期的前提下实现至少99%的覆盖恢复。我们使用Python Universal Verification Methodology (PyUVM) 而不是SystemVerilog-Universal Verification Methodology (SV-UVM) 创建测试平台，利用Python简化构造并方便重用现有的机器学习库。该方法应用于三个不同的设计，结果显示它可以显著降低验证成本、减少手动努力和缩短时间-to-市场，同时提高验证的生产力和完整性，通过自动化测试平台更新过程并达到目标覆盖目标。', 'title_zh': '基于机器学习和PyUVM的新型覆盖驱动验证优化方法'}
{'arxiv_id': 'arXiv:2503.11663', 'title': 'MEADOW: Memory-efficient Dataflow and Data Packing for Low Power Edge LLMs', 'authors': 'Abhishek Moitra, Arkapravo Ghosh, Shrey Agarwal, Aporva Amarnath, Karthik Swaminathan, Priyadarshini Panda', 'link': 'https://arxiv.org/abs/2503.11663', 'abstract': 'The computational and memory challenges of large language models (LLMs) have sparked several optimization approaches towards their efficient implementation. While prior LLM-targeted quantization, and prior works on sparse acceleration have significantly mitigated the memory and computation bottleneck, they do so assuming high power platforms such as GPUs and server-class FPGAs with large off-chip memory bandwidths and employ a generalized matrix multiplication (GEMM) execution of all the layers in the decoder. In such a GEMM-based execution, data is fetched from an off-chip memory, computed and stored back. However, at reduced off-chip memory capacities, as is the case with low-power edge devices, this implementation strategy significantly increases the attention computation latency owing to the repeated storage and fetch of large intermediate tokens to and from the off-chip memory. Moreover, fetching the weight matrices from a bandwidth constrained memory further aggravates the memory bottleneck problem. To this end, we introduce MEADOW, a framework that significantly reduces the off-chip memory access for LLMs with a novel token-parallel head-sequential (TPHS) dataflow. Additionally, MEADOW applies weight packing that performs loss-less decomposition of large weight matrices to their unique elements thereby, reducing the enormous weight fetch latency. MEADOW demonstrates 1.5x and 2.5x lower decode and prefill latency, respectively, compared to a GEMM-based LLM implementation on the low power Xilinx ZCU102 FPGA platform that consumes less than 10W. Additionally, MEADOW achieves an end-to-end latency improvement of over 40%, compared to prior LLM optimization works.', 'abstract_zh': '大型语言模型（LLM）的计算和内存挑战促使了多种高效实现的优化方法。尽管针对LLM的量化方法和稀疏加速的早期工作显著缓解了内存和计算瓶颈，它们主要针对高性能平台（如GPU和服务器级FPGA），这些平台具有大的片外内存带宽，并且所有解码层都采用通用矩阵乘法（GEMM）执行方式。在GEMM基础上的执行中，数据从片外内存中读取、计算后返回存储。但在片外内存容量减小，如低功耗边缘设备中，这一实现策略会因重复的存储和从片外内存读取大量中间令牌而显著增加注意力计算延迟。此外，从带宽受限的内存中获取权重矩阵进一步加剧了内存瓶颈问题。为此，我们提出了MEADOW框架，通过一种新颖的令牌并行头部顺序（TPHS）数据流显著减少了LLM的片外内存访问。此外，MEADOW采用了权重打包技术，对大型权重矩阵进行无损分解到其唯一元素，从而减少了巨大的权重获取延迟。MEADOW在消耗不到10W功率的低功耗Xilinx ZCU102 FPGA平台上，解码延迟和预填充延迟分别降低了1.5倍和2.5倍。与之前的LLM优化工作相比，MEADOW实现了端到端延迟提高了超过40%。', 'title_zh': 'MEADOW: 节省内存的数据流和数据打包方法用于低功耗边缘端大语言模型'}
{'arxiv_id': 'arXiv:2503.11662', 'title': 'Lorecast: Layout-Aware Performance and Power Forecasting from Natural Language', 'authors': 'Runzhi Wang, Prianka Sengupta, Yiran Chen, Jiang Hu', 'link': 'https://arxiv.org/abs/2503.11662', 'abstract': 'In chip design planning, obtaining reliable performance and power forecasts for various design options is of critical importance. Traditionally, this involves using system-level models, which often lack accuracy, or trial synthesis, which is both labor-intensive and time-consuming. We introduce a new methodology, called Lorecast, which accepts English prompts as input to rapidly generate layout-aware performance and power estimates. This approach bypasses the need for HDL code development or synthesis, making it both fast and user-friendly. Experimental results demonstrate that Lorecast achieves accuracy within a few percent of error compared to post-layout analysis.', 'abstract_zh': '在芯片设计规划中，获得各种设计选项的可靠性能和功率预测至关重要。传统方法通常需要使用系统级模型，这些模型往往缺乏准确性，或者进行试合成，这既耗时又耗力。我们提出了一种新的方法，称为Lorecast，该方法接受英文提示作为输入，快速生成布局感知的性能和功率估算。该方法 bypassed 对HDL代码开发或合成的需求，使其既快速又用户友好。实验结果表明，Lorecast 的准确度误差范围在几百分点以内，与后布局分析结果相当。', 'title_zh': 'Lorecast: 基于布局的性能和功率预测方法自然语言处理'}
{'arxiv_id': 'arXiv:2503.11660', 'title': 'A 28 nm AI microcontroller with tightly coupled zero-standby power weight memory featuring standard logic compatible 4 Mb 4-bits/cell embedded flash technology', 'authors': 'Daewung Kim, Seong Hwan Jeon, Young Hee Jeon, Kyung-Bae Kwon, Jigon Kim, Yeounghun Choi, Hyunseung Cha, Kitae Kwon, Daesik Park, Jongseuk Lee, Sihwan Kim, Seung-Hwan Song', 'link': 'https://arxiv.org/abs/2503.11660', 'abstract': 'This study introduces a novel AI microcontroller optimized for cost-effective, battery-powered edge AI applications. Unlike traditional single bit/cell memory configurations, the proposed microcontroller integrates zero-standby power weight memory featuring standard logic compatible 4-bits/cell embedded flash technology tightly coupled to a Near-Memory Computing Unit. This architecture enables efficient and low-power AI acceleration. Advanced state mapping and an overstress-free word line (WL) driver circuit extend verify levels, ensuring robust 16 state cell margin. A ping-pong buffer reduces internal data movement while supporting simultaneous multi-bit processing. The fabricated microcontroller demonstrated high reliability, maintaining accuracy after 160 hours of unpowered baking at 125$^\\circ$C.', 'abstract_zh': '这种研究介绍了一种新型AI微控制器，该微控制器针对成本效益高、电池供电的边缘AI应用进行了优化。该提出的微控制器集成了零待机功率权重内存，该内存采用标准逻辑兼容的4-bit/cell嵌入式闪存技术，并紧密耦合到一个近内存计算单元。该架构使AI加速既高效又低功耗。先进的状态映射和一个无过压力的位线(WL)驱动电路增加了验证级别，确保了16状态单元的稳健余量。乒乓缓冲区减少了内部数据移动，同时支持同时多比特处理。制造出的微控制器表现出高可靠性，在125°C下无电烘烤160小时后仍保持准确度。', 'title_zh': '一种配备紧密耦合零待机功耗权重存储器的28纳米AI微控制器，采用兼容标准逻辑的嵌入式闪存技术4Mb 4-bits/cell'}
{'arxiv_id': 'arXiv:2503.11658', 'title': 'Circuit Diagram Retrieval Based on Hierarchical Circuit Graph Representation', 'authors': 'Ming Gao, Ruichen Qiu, Zeng Hui Chang, Kanjian Zhang, Haikun Wei, Hong Cai Chen', 'link': 'https://arxiv.org/abs/2503.11658', 'abstract': 'In the domain of analog circuit design, the retrieval of circuit diagrams has drawn a great interest, primarily due to its vital role in the consultation of legacy designs and the detection of design plagiarism. Existing image retrieval techniques are adept at handling natural images, which converts images into feature vectors and retrieval similar images according to the closeness of these vectors. Nonetheless, these approaches exhibit limitations when applied to the more specialized and intricate domain of circuit diagrams. This paper presents a novel approach to circuit diagram retrieval by employing a graph representation of circuit diagrams, effectively reformulating the retrieval task as a graph retrieval problem. The proposed methodology consists of two principal components: a circuit diagram recognition algorithm designed to extract the circuit components and topological structure of the circuit using proposed GAM-YOLO model and a 2-step connected domain filtering algorithm, and a hierarchical retrieval strategy based on graph similarity and different graph representation methods for analog circuits. Our methodology pioneers the utilization of graph representation in the retrieval of circuit diagrams, incorporating topological features that are commonly overlooked by standard image retrieval methods. The results of our experiments substantiate the efficacy of our approach in retrieving circuit diagrams across of different types.', 'abstract_zh': '在模拟电路设计领域，电路图的检索受到了极大关注，主要因其在遗产设计咨询和设计抄袭检测中的关键作用。现有的图像检索技术擅长处理自然图像，即将图像转换为特征向量，并根据这些向量的相似性检索相似图像。然而，这些方法在应用于更为专业和复杂的电路图领域时表现出局限性。本文提出了一种新的电路图检索方法，通过采用电路图的图表示法，有效将检索任务重新表述为图检索问题。所提出的方法主要包括两个主要组成部分：一种基于提出的GAM-YOLO模型提取电路元件和拓扑结构的电路图识别算法以及两步连接域过滤算法，以及基于图相似性和不同图表示方法的层次检索策略。我们的方法开创性地将图表示法应用于电路图检索，结合了标准图像检索方法通常忽视的拓扑特征。实验结果证明了该方法在不同类型的电路图检索中的有效性。', 'title_zh': '基于分层电路图表示的电路图检索'}
{'arxiv_id': 'arXiv:2503.11655', 'title': 'Explainable Sentiment Analysis with DeepSeek-R1: Performance, Efficiency, and Few-Shot Learning', 'authors': 'Donghao Huang, Zhaoxia Wang', 'link': 'https://arxiv.org/abs/2503.11655', 'abstract': "Recent advancements in large language models (LLMs) have significantly enhanced sentiment analysis capabilities. However, the trade-offs between model performance, efficiency, and explainability of some latest models remain underexplored. This study presents the first comprehensive evaluation of the DeepSeek-R1 series of models, reasoning open-source LLMs, for sentiment analysis, comparing them against OpenAI's GPT-4 and GPT-4-mini. We systematically analyze their performance under few-shot prompting conditions, scaling up to 50-shot configurations to assess in-context learning effectiveness. Our experiments reveal that DeepSeek-R1 demonstrates competitive accuracy, particularly in multi-class sentiment tasks, while offering enhanced interpretability through its detailed reasoning process. Additionally, we highlight the impact of increasing few-shot examples on model performance and discuss key trade-offs between explainability and computational efficiency.", 'abstract_zh': '近期大型语言模型（LLMs）的发展显著提升了情感分析的能力，但一些最新模型在性能、效率和可解释性之间的权衡尚未被充分探索。本研究首次全面评估了DeepSeek-R1系列开源模型在情感分析中的表现，将其与OpenAI的GPT-4和GPT-4-mini进行比较。我们系统分析了这些模型在少量提示条件下的性能，并扩展到50-shot配置以评估上下文学习的有效性。实验结果显示，DeepSeek-R1在多类别情感任务中表现出竞争力，并通过详细的推理过程提高了可解释性。此外，我们强调了增加少量提示样本对模型性能的影响，并讨论了可解释性与计算效率之间的关键权衡。', 'title_zh': '基于DeepSeek-R1的可解释情感分析：性能、效率及少样本学习'}
