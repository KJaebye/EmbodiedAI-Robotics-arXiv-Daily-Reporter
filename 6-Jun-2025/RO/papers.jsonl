{'arxiv_id': 'arXiv:2506.05168', 'title': 'Fabrica: Dual-Arm Assembly of General Multi-Part Objects via Integrated Planning and Learning', 'authors': 'Yunsheng Tian, Joshua Jacob, Yijiang Huang, Jialiang Zhao, Edward Gu, Pingchuan Ma, Annan Zhang, Farhad Javid, Branden Romero, Sachin Chitta, Shinjiro Sueda, Hui Li, Wojciech Matusik', 'link': 'https://arxiv.org/abs/2506.05168', 'abstract': 'Multi-part assembly poses significant challenges for robots to execute long-horizon, contact-rich manipulation with generalization across complex geometries. We present Fabrica, a dual-arm robotic system capable of end-to-end planning and control for autonomous assembly of general multi-part objects. For planning over long horizons, we develop hierarchies of precedence, sequence, grasp, and motion planning with automated fixture generation, enabling general multi-step assembly on any dual-arm robots. The planner is made efficient through a parallelizable design and is optimized for downstream control stability. For contact-rich assembly steps, we propose a lightweight reinforcement learning framework that trains generalist policies across object geometries, assembly directions, and grasp poses, guided by equivariance and residual actions obtained from the plan. These policies transfer zero-shot to the real world and achieve 80% successful steps. For systematic evaluation, we propose a benchmark suite of multi-part assemblies resembling industrial and daily objects across diverse categories and geometries. By integrating efficient global planning and robust local control, we showcase the first system to achieve complete and generalizable real-world multi-part assembly without domain knowledge or human demonstrations. Project website: this http URL', 'abstract_zh': '多部件装配对机器人执行长期、富含接触的通用操纵任务构成显著挑战。我们提出Fabrica，一个双臂机器人系统，具备端到端规划和控制能力，用于自主装配通用多部件物体。通过长时间规划，我们开发了优先级、序列、抓取和运动规划的层次结构，并自动生成夹具，使任意双臂机器人能够进行通用多步装配。该规划器通过并行化设计变得高效，并优化了下游控制稳定性。对于富含接触的装配步骤，我们提出了一种轻量级的强化学习框架，训练出针对不同物体几何形状、装配方向和抓取姿态的通用策略，这些策略通过计划中的不变性和残差动作进行引导。这些策略在没有领域知识或人类示范的情况下，在实际世界中实现零样本转移，并实现80%的成功步骤。为系统评估，我们提出了一个基准测试套件，包括类似工业和日常物体的多部件装配，涵盖多种类别和几何形状。通过整合高效的全局规划和鲁棒的局部控制，我们展示了第一个能够在实际世界中实现完整且可泛化的多部件装配的系统。项目网站：这个链接', 'title_zh': 'Fabrica：通过集成规划与学习的双臂通用多部件对象装配'}
{'arxiv_id': 'arXiv:2506.05165', 'title': 'LiPo: A Lightweight Post-optimization Framework for Smoothing Action Chunks Generated by Learned Policies', 'authors': 'Dongwoo Son, Suhan Park', 'link': 'https://arxiv.org/abs/2506.05165', 'abstract': 'Recent advances in imitation learning have enabled robots to perform increasingly complex manipulation tasks in unstructured environments. However, most learned policies rely on discrete action chunking, which introduces discontinuities at chunk boundaries. These discontinuities degrade motion quality and are particularly problematic in dynamic tasks such as throwing or lifting heavy objects, where smooth trajectories are critical for momentum transfer and system stability. In this work, we present a lightweight post-optimization framework for smoothing chunked action sequences. Our method combines three key components: (1) inference-aware chunk scheduling to proactively generate overlapping chunks and avoid pauses from inference delays; (2) linear blending in the overlap region to reduce abrupt transitions; and (3) jerk-minimizing trajectory optimization constrained within a bounded perturbation space. The proposed method was validated on a position-controlled robotic arm performing dynamic manipulation tasks. Experimental results demonstrate that our approach significantly reduces vibration and motion jitter, leading to smoother execution and improved mechanical robustness.', 'abstract_zh': '近期模仿学习的进步使机器人能够在非结构化环境中执行越来越复杂的操作任务。然而，大多数学到的策略依赖于离散的动作分块，这会在分块边界引入不连续性，这些不连续性会降低运动质量，并在抛掷或提起重物等动态任务中特别存在问题，因为在这些任务中平滑的轨迹对于动量传递和系统稳定性至关重要。在此工作中，我们提出了一种轻量级后优化框架以平滑分块动作序列。本文方法结合了三个关键组件：(1) 模型感知的分块调度，以事先生成重叠分块并避免推理延迟导致的停顿；(2) 在重叠区域进行线性混合以减少突变过渡；(3) 在限定的扰动空间内最小化冲击的轨迹优化。所提出的算法已在执行动态操作任务的位置控制型机器人手臂上进行了验证。实验结果表明，我们的方法显著减少了振动和运动颤动，从而实现了更平滑的执行并提高了机械鲁棒性。', 'title_zh': 'LiPo：一种轻量级后优化框架，用于平滑由学习策略生成的动作片段'}
{'arxiv_id': 'arXiv:2506.05117', 'title': 'Realizing Text-Driven Motion Generation on NAO Robot: A Reinforcement Learning-Optimized Control Pipeline', 'authors': 'Zihan Xu, Mengxian Hu, Kaiyan Xiao, Qin Fang, Chengju Liu, Qijun Chen', 'link': 'https://arxiv.org/abs/2506.05117', 'abstract': "Human motion retargeting for humanoid robots, transferring human motion data to robots for imitation, presents significant challenges but offers considerable potential for real-world applications. Traditionally, this process relies on human demonstrations captured through pose estimation or motion capture systems. In this paper, we explore a text-driven approach to mapping human motion to humanoids. To address the inherent discrepancies between the generated motion representations and the kinematic constraints of humanoid robots, we propose an angle signal network based on norm-position and rotation loss (NPR Loss). It generates joint angles, which serve as inputs to a reinforcement learning-based whole-body joint motion control policy. The policy ensures tracking of the generated motions while maintaining the robot's stability during execution. Our experimental results demonstrate the efficacy of this approach, successfully transferring text-driven human motion to a real humanoid robot NAO.", 'abstract_zh': '基于文本驱动的 humanoid 机器人人体 motion 转移：一种基于 norm-position 和旋转损失的关节角度信号网络方法', 'title_zh': '基于强化学习优化的文本驱动运动生成控制管道在NAO机器人上的实现'}
{'arxiv_id': 'arXiv:2506.05115', 'title': 'Whole-Body Constrained Learning for Legged Locomotion via Hierarchical Optimization', 'authors': 'Haoyu Wang, Ruyi Zhou, Liang Ding, Tie Liu, Zhelin Zhang, Peng Xu, Haibo Gao, Zongquan Deng', 'link': 'https://arxiv.org/abs/2506.05115', 'abstract': 'Reinforcement learning (RL) has demonstrated impressive performance in legged locomotion over various challenging environments. However, due to the sim-to-real gap and lack of explainability, unconstrained RL policies deployed in the real world still suffer from inevitable safety issues, such as joint collisions, excessive torque, or foot slippage in low-friction environments. These problems limit its usage in missions with strict safety requirements, such as planetary exploration, nuclear facility inspection, and deep-sea operations. In this paper, we design a hierarchical optimization-based whole-body follower, which integrates both hard and soft constraints into RL framework to make the robot move with better safety guarantees. Leveraging the advantages of model-based control, our approach allows for the definition of various types of hard and soft constraints during training or deployment, which allows for policy fine-tuning and mitigates the challenges of sim-to-real transfer. Meanwhile, it preserves the robustness of RL when dealing with locomotion in complex unstructured environments. The trained policy with introduced constraints was deployed in a hexapod robot and tested in various outdoor environments, including snow-covered slopes and stairs, demonstrating the great traversability and safety of our approach.', 'abstract_zh': '基于层次优化的整体身体跟随者：将硬约束和软约束集成到强化学习框架中以提高机器人移动的安全性', 'title_zh': '基于分层优化的全身约束学习腿部运动控制'}
{'arxiv_id': 'arXiv:2506.05106', 'title': 'EDEN: Efficient Dual-Layer Exploration Planning for Fast UAV Autonomous Exploration in Large 3-D Environments', 'authors': 'Qianli Dong, Xuebo Zhang, Shiyong Zhang, Ziyu Wang, Zhe Ma, Haobo Xi', 'link': 'https://arxiv.org/abs/2506.05106', 'abstract': 'Efficient autonomous exploration in large-scale environments remains challenging due to the high planning computational cost and low-speed maneuvers. In this paper, we propose a fast and computationally efficient dual-layer exploration planning method. The insight of our dual-layer method is efficiently finding an acceptable long-term region routing and greedily exploring the target in the region of the first routing area with high speed. Specifically, the proposed method finds the long-term area routing through an approximate algorithm to ensure real-time planning in large-scale environments. Then, the viewpoint in the first routing region with the lowest curvature-penalized cost, which can effectively reduce decelerations caused by sharp turn motions, will be chosen as the next exploration target. To further speed up the exploration, we adopt an aggressive and safe exploration-oriented trajectory to enhance exploration continuity. The proposed method is compared to state-of-the-art methods in challenging simulation environments. The results show that the proposed method outperforms other methods in terms of exploration efficiency, computational cost, and trajectory speed. We also conduct real-world experiments to validate the effectiveness of the proposed method. The code will be open-sourced.', 'abstract_zh': '大规模环境中的高效自主探索仍然具有挑战性，因为规划计算成本高且操纵速度低。本文提出了一种快速且计算高效的双层探索规划方法。我们双层方法的见解是高效地找到一个可接受的长期区域路线，并在第一个路由区域中以高速贪婪地探索目标。具体来说，提出的算法通过近似算法找到长期区域路线，以确保在大规模环境中实现实时规划。然后，选择第一个路由区域中曲率惩罚成本最低的视角作为下一个探索目标，以有效减少因急转弯运动引起的减速。为了进一步加快探索，我们采用了一种积极且安全的探索导向轨迹来提高探索连续性。我们将提出的方法与最先进的方法在具有挑战性的仿真环境中进行了比较。结果表明，提出的方法在探索效率、计算成本和轨迹速度方面优于其他方法。我们还进行了实地实验以验证提出方法的有效性。代码将开源。', 'title_zh': 'EDEN:高效双层探索规划以实现大型三维环境快速无人机自主探索'}
{'arxiv_id': 'arXiv:2506.05092', 'title': 'Synthetic Dataset Generation for Autonomous Mobile Robots Using 3D Gaussian Splatting for Vision Training', 'authors': 'Aneesh Deogan, Wout Beks, Peter Teurlings, Koen de Vos, Mark van den Brand, Rene van de Molengraft', 'link': 'https://arxiv.org/abs/2506.05092', 'abstract': 'Annotated datasets are critical for training neural networks for object detection, yet their manual creation is time- and labour-intensive, subjective to human error, and often limited in diversity. This challenge is particularly pronounced in the domain of robotics, where diverse and dynamic scenarios further complicate the creation of representative datasets. To address this, we propose a novel method for automatically generating annotated synthetic data in Unreal Engine. Our approach leverages photorealistic 3D Gaussian splats for rapid synthetic data generation. We demonstrate that synthetic datasets can achieve performance comparable to that of real-world datasets while significantly reducing the time required to generate and annotate data. Additionally, combining real-world and synthetic data significantly increases object detection performance by leveraging the quality of real-world images with the easier scalability of synthetic data. To our knowledge, this is the first application of synthetic data for training object detection algorithms in the highly dynamic and varied environment of robot soccer. Validation experiments reveal that a detector trained on synthetic images performs on par with one trained on manually annotated real-world images when tested on robot soccer match scenarios. Our method offers a scalable and comprehensive alternative to traditional dataset creation, eliminating the labour-intensive error-prone manual annotation process. By generating datasets in a simulator where all elements are intrinsically known, we ensure accurate annotations while significantly reducing manual effort, which makes it particularly valuable for robotics applications requiring diverse and scalable training data.', 'abstract_zh': '基于 Unreal Engine 的自动生成标注合成数据方法在机器人足球场景下的物体检测应用', 'title_zh': '使用3D高斯点绘制生成自主移动机器人视觉训练的合成数据集'}
{'arxiv_id': 'arXiv:2506.05064', 'title': 'DemoSpeedup: Accelerating Visuomotor Policies via Entropy-Guided Demonstration Acceleration', 'authors': 'Lingxiao Guo, Zhengrong Xue, Zijing Xu, Huazhe Xu', 'link': 'https://arxiv.org/abs/2506.05064', 'abstract': "Imitation learning has shown great promise in robotic manipulation, but the policy's execution is often unsatisfactorily slow due to commonly tardy demonstrations collected by human operators. In this work, we present DemoSpeedup, a self-supervised method to accelerate visuomotor policy execution via entropy-guided demonstration acceleration. DemoSpeedup starts from training an arbitrary generative policy (e.g., ACT or Diffusion Policy) on normal-speed demonstrations, which serves as a per-frame action entropy estimator. The key insight is that frames with lower action entropy estimates call for more consistent policy behaviors, which often indicate the demands for higher-precision operations. In contrast, frames with higher entropy estimates correspond to more casual sections, and therefore can be more safely accelerated. Thus, we segment the original demonstrations according to the estimated entropy, and accelerate them by down-sampling at rates that increase with the entropy values. Trained with the speedup demonstrations, the resulting policies execute up to 3 times faster while maintaining the task completion performance. Interestingly, these policies could even achieve higher success rates than those trained with normal-speed demonstrations, due to the benefits of reduced decision-making horizons.", 'abstract_zh': '基于熵指导的演示加速：DemoSpeedup在机器人操作中的自监督方法', 'title_zh': 'DemoSpeedup: 通过熵导引的示范加速来加速知觉-运动策略'}
{'arxiv_id': 'arXiv:2506.05056', 'title': 'PulseRide: A Robotic Wheelchair for Personalized Exertion Control with Human-in-the-Loop Reinforcement Learning', 'authors': 'Azizul Zahid, Bibek Poudel, Danny Scott, Jason Scott, Scott Crouter, Weizi Li, Sai Swaminathan', 'link': 'https://arxiv.org/abs/2506.05056', 'abstract': "Maintaining an active lifestyle is vital for quality of life, yet challenging for wheelchair users. For instance, powered wheelchairs face increasing risks of obesity and deconditioning due to inactivity. Conversely, manual wheelchair users, who propel the wheelchair by pushing the wheelchair's handrims, often face upper extremity injuries from repetitive motions. These challenges underscore the need for a mobility system that promotes activity while minimizing injury risk. Maintaining optimal exertion during wheelchair use enhances health benefits and engagement, yet the variations in individual physiological responses complicate exertion optimization. To address this, we introduce PulseRide, a novel wheelchair system that provides personalized assistance based on each user's physiological responses, helping them maintain their physical exertion goals. Unlike conventional assistive systems focused on obstacle avoidance and navigation, PulseRide integrates real-time physiological data-such as heart rate and ECG-with wheelchair speed to deliver adaptive assistance. Using a human-in-the-loop reinforcement learning approach with Deep Q-Network algorithm (DQN), the system adjusts push assistance to keep users within a moderate activity range without under- or over-exertion. We conducted preliminary tests with 10 users on various terrains, including carpet and slate, to assess PulseRide's effectiveness. Our findings show that, for individual users, PulseRide maintains heart rates within the moderate activity zone as much as 71.7 percent longer than manual wheelchairs. Among all users, we observed an average reduction in muscle contractions of 41.86 percent, delaying fatigue onset and enhancing overall comfort and engagement. These results indicate that PulseRide offers a healthier, adaptive mobility solution, bridging the gap between passive and physically taxing mobility options.", 'abstract_zh': '基于生理响应的个性化辅助轮椅系统：PulseRide研究', 'title_zh': 'PulseRide：一种基于人类在环强化学习的个性化用力控制机器人轮椅'}
{'arxiv_id': 'arXiv:2506.05020', 'title': 'Hierarchical Language Models for Semantic Navigation and Manipulation in an Aerial-Ground Robotic System', 'authors': 'Haokun Liu, Zhaoqi Ma, Yunong Li, Junichiro Sugihara, Yicheng Chen, Jinjie Li, Moju Zhao', 'link': 'https://arxiv.org/abs/2506.05020', 'abstract': "Heterogeneous multi-robot systems show great potential in complex tasks requiring coordinated hybrid cooperation. However, traditional approaches relying on static models often struggle with task diversity and dynamic environments. This highlights the need for generalizable intelligence that can bridge high-level reasoning with low-level execution across heterogeneous agents. To address this, we propose a hierarchical framework integrating a prompted Large Language Model (LLM) and a GridMask-enhanced fine-tuned Vision Language Model (VLM). The LLM performs task decomposition and global semantic map construction, while the VLM extracts task-specified semantic labels and 2D spatial information from aerial images to support local planning. Within this framework, the aerial robot follows a globally optimized semantic path and continuously provides bird-view images, guiding the ground robot's local semantic navigation and manipulation, including target-absent scenarios where implicit alignment is maintained. Experiments on a real-world letter-cubes arrangement task demonstrate the framework's adaptability and robustness in dynamic environments. To the best of our knowledge, this is the first demonstration of an aerial-ground heterogeneous system integrating VLM-based perception with LLM-driven task reasoning and motion planning.", 'abstract_zh': '异构多机器人系统在需要协调混合合作的复杂任务中展现出巨大潜力。然而，依赖静态模型的传统方法往往难以应对任务多样性和动态环境。这突显了跨异构代理实现高层推理与底层执行通用智能的必要性。为解决这一问题，我们提出了一种层次化框架，该框架结合了提示增强的大语言模型（LLM）和GridMask增强的微调视觉语言模型（VLM）。LLM执行任务分解和全局语义地图构建，而VLM从空中图像中提取任务特定的语义标签和2D空间信息以支持局部规划。在该框架中，空中机器人遵循全局优化的语义路径，并持续提供鸟瞰图图像，引导地面机器人的局部语义导航和操作，包括目标不存在的场景，其中隐式对齐得以维持。通过在实际字母立方体排列任务上的实验，证明了该框架在动态环境中的适应性和鲁棒性。据我们所知，这是首个将基于VLM的感知与由LLM驱动的任务推理和运动规划结合的空中-地面异构系统示例。', 'title_zh': '具有层次语言模型的semantic导航与操作在空地机器人系统中的应用'}
{'arxiv_id': 'arXiv:2506.05012', 'title': 'A Unified Framework for Simulating Strongly-Coupled Fluid-Robot Multiphysics', 'authors': 'Jeong Hun Lee, Junzhe Hu, Sofia Kwok, Carmel Majidi, Zachary Manchester', 'link': 'https://arxiv.org/abs/2506.05012', 'abstract': "We present a framework for simulating fluid-robot multiphysics as a single, unified optimization problem. The coupled manipulator and incompressible Navier-Stokes equations governing the robot and fluid dynamics are derived together from a single Lagrangian using the principal of least action. We then employ discrete variational mechanics to derive a stable, implicit time-integration scheme for jointly simulating both the fluid and robot dynamics, which are tightly coupled by a constraint that enforces the no-slip boundary condition at the fluid-robot interface. Extending the classical immersed boundary method, we derive a new formulation of the no-slip constraint that is numerically well-conditioned and physically accurate for multibody systems commonly found in robotics. We demonstrate our approach's physical accuracy on benchmark computational fluid-dynamics problems, including Poiseuille flow and a disc in free stream. We then design a locomotion policy for a novel swimming robot in simulation and validate results on real-world hardware, showcasing our framework's sim-to-real capability for robotics tasks.", 'abstract_zh': '我们提出了一种将流体-机器人多物理模拟作为单一统一优化问题的框架。通过单一拉格朗日函数并利用最小作用原理，结合推导出机器人和流体力学的耦合操作器及不可压缩纳维-斯托克斯方程。随后，我们运用离散变分力学推导出一种稳定且隐式的时间积分方案来联合模拟流体和机器人动力学，二者通过确保流体-机器人界面无滑移边界条件的约束紧密耦合。在此基础上，我们扩展了经典的浸入边界方法，推导出一种新的无滑移约束形式，其在机器人中常见的多体系统中具有良好的数值条件稳定性和物理准确性。我们在基准计算流体力学问题上展示了该方法的物理准确性，包括泊流流和自由流中的盘体。然后，我们在模拟中为一种新型游泳机器人设计了运动策略，并在实际硬件上验证结果，展示了该框架在机器人任务中的从仿真到现实的能力。', 'title_zh': '统一的强耦合流体-机器人多物理场仿真框架'}
{'arxiv_id': 'arXiv:2506.04982', 'title': 'GEX: Democratizing Dexterity with Fully-Actuated Dexterous Hand and Exoskeleton Glove', 'authors': 'Yunlong Dong, Xing Liu, Jun Wan, Zelin Deng', 'link': 'https://arxiv.org/abs/2506.04982', 'abstract': 'This paper introduces GEX, an innovative low-cost dexterous manipulation system that combines the GX11 tri-finger anthropomorphic hand (11 DoF) with the EX12 tri-finger exoskeleton glove (12 DoF), forming a closed-loop teleoperation framework through kinematic retargeting for high-fidelity control. Both components employ modular 3D-printed finger designs, achieving ultra-low manufacturing costs while maintaining full actuation capabilities. Departing from conventional tendon-driven or underactuated approaches, our electromechanical system integrates independent joint motors across all 23 DoF, ensuring complete state observability and accurate kinematic modeling. This full-actuation architecture enables precise bidirectional kinematic calculations, substantially enhancing kinematic retargeting fidelity between the exoskeleton and robotic hand. The proposed system bridges the cost-performance gap in dexterous manipulation research, providing an accessible platform for acquiring high-quality demonstration data to advance embodied AI and dexterous robotic skill transfer learning.', 'abstract_zh': '本文介绍了GEX，这是一个创新性的低成本灵巧 manipulation 系统，结合了GX11三指类人手（11 自由度）和EX12三指外骨骼手套（12 自由度），通过运动学重定位形成闭环远程操作框架，实现高保真控制。两个组件采用模块化3D打印手指设计，同时实现超低制造成本并保持完整的驱动能力。不同于传统的腱驱动或欠驱动方法，我们的机电系统在所有23个自由度上集成独立关节电机，确保完全的状态可观测性和精确的运动学建模。这种全驱动架构使精确的双向运动学计算成为可能，极大地提高了外骨骼和机器人手之间的运动学重定位保真度。所提出的系统弥合了灵巧 manipulation 研究中的成本与性能差距，提供了一个可访问的平台，以获取高质量的演示数据，推进体态人工智能和灵巧机器人技能转移学习。', 'title_zh': 'GEX: 通过全驱动灵巧手和外骨骼手套实现灵巧性的民主化'}
{'arxiv_id': 'arXiv:2506.04942', 'title': 'A Pillbug-Inspired Morphing Mechanism Covered with Sliding Shells', 'authors': 'Jieyu Wang, Yingzhong Tian, Fengfeng Xi, Damien Chablat, Jianing Lin, Gaoke Ren, Yinjun Zhao', 'link': 'https://arxiv.org/abs/2506.04942', 'abstract': "This research proposes a novel morphing structure with shells inspired by the movement of pillbugs. Instead of the pillbug body, a loopcoupled mechanism based on slider-crank mechanisms is utilized to achieve the rolling up and spreading motion. This mechanism precisely imitates three distinct curves that mimic the shape morphing of a pillbug. To decrease the degree-of-freedom (DOF) of the mechanism to one, scissor mechanisms are added. 3D curved shells are then attached to the tracer points of the morphing mechanism to safeguard it from attacks while allowing it to roll. Through type and dimensional synthesis, a complete system that includes shells and an underlying morphing mechanism is developed. A 3D model is created and tested to demonstrate the proposed system's shape-changing capability. Lastly, a robot with two modes is developed based on the proposed mechanism, which can curl up to roll down hills and can spread to move in a straight line via wheels.", 'abstract_zh': '基于多足虫运动灵感的新型折纸结构及其变形机制研究', 'title_zh': '基于滑动壳覆盖的 Pill虫启发自形态机制'}
{'arxiv_id': 'arXiv:2506.04941', 'title': 'ArtVIP: Articulated Digital Assets of Visual Realism, Modular Interaction, and Physical Fidelity for Robot Learning', 'authors': 'Zhao Jin, Zhengping Che, Zhen Zhao, Kun Wu, Yuheng Zhang, Yinuo Zhao, Zehui Liu, Qiang Zhang, Xiaozhu Ju, Jing Tian, Yousong Xue, Jian Tang', 'link': 'https://arxiv.org/abs/2506.04941', 'abstract': "Robot learning increasingly relies on simulation to advance complex ability such as dexterous manipulations and precise interactions, necessitating high-quality digital assets to bridge the sim-to-real gap. However, existing open-source articulated-object datasets for simulation are limited by insufficient visual realism and low physical fidelity, which hinder their utility for training models mastering robotic tasks in real world. To address these challenges, we introduce ArtVIP, a comprehensive open-source dataset comprising high-quality digital-twin articulated objects, accompanied by indoor-scene assets. Crafted by professional 3D modelers adhering to unified standards, ArtVIP ensures visual realism through precise geometric meshes and high-resolution textures, while physical fidelity is achieved via fine-tuned dynamic parameters. Meanwhile, the dataset pioneers embedded modular interaction behaviors within assets and pixel-level affordance annotations. Feature-map visualization and optical motion capture are employed to quantitatively demonstrate ArtVIP 's visual and physical fidelity, with its applicability validated across imitation learning and reinforcement learning experiments. Provided in USD format with detailed production guidelines, \\ours is fully open-source, benefiting the research community and advancing robot learning research. Our project is at this https URL", 'abstract_zh': '机器人学习越来越多地依赖仿真来提高如灵巧操作和精确交互等复杂能力，这要求有高质量的数字资产来弥补仿真到现实的差距。然而，现有开源的关节物体数据集在视觉真实感和物理保真度方面存在局限，这限制了其在训练掌握机器人任务模型方面的应用。为了解决这些挑战，我们引入了ArtVIP，这是一个包含高质量数字孪生关节物体和室内场景资产的全面开源数据集。由专业的3D建模师按照统一标准打造，ArtVIP通过精确的几何网格和高分辨率纹理确保了视觉真实感，同时通过精细调整的动力学参数实现了物理保真度。此外，数据集在资产中嵌入了模块化的交互行为，并提供了像素级的功能性注释。通过特征图可视化和光学动作捕捉，定量展示了ArtVIP的视觉和物理保真度，并通过模仿学习和强化学习实验验证了其适用性。提供USD格式并附有详细生产指南，我们的项目完全开源，服务于研究社区并推动机器人学习研究。项目链接：this https URL', 'title_zh': 'ArtVIP: 视觉现实性、模块化交互和物理保真度的articulated数字资产及其在机器人学习中的应用'}
{'arxiv_id': 'arXiv:2506.04881', 'title': 'Efficient Path Planning and Task Allocation Algorithm for Boolean Specifications', 'authors': 'Ioana Hustiu, Roozbeh Abolpour, Cristian Mahulea, Marius Kloetzer', 'link': 'https://arxiv.org/abs/2506.04881', 'abstract': 'This paper presents a novel path-planning and task assignment algorithm for multi-robot systems that should fulfill a global Boolean specification. The proposed method is based on Integer Linear Programming (ILP) formulations, which are combined with structural insights from Petri nets to improve scalability and computational efficiency. By proving that the \\emph{constraint matrix} is totally unimodular (TU) for certain classes of problems, the ILP formulation can be relaxed into a Linear Programming (LP) problem without losing the integrality of the solution. This relaxation eliminates complex combinatorial techniques, significantly reducing computational overhead and thus ensuring scalability for large-scale systems. Using the approach proposed in this paper, we can solve path-planning problems for teams made up to 500 robots. The method guarantees computational tractability, handles collision avoidance and reduces computational demands through iterative LP optimization techniques. Case studies demonstrate the efficiency of the algorithm in generating scalable, collision-free paths for large robot teams navigating in complex environments. While the conservative nature of collision avoidance introduces additional constraints, and thus, computational requirements, the solution remains practical and impactful for diverse applications. The algorithm is particularly applicable to real-world scenarios, including warehouse logistics where autonomous robots must efficiently coordinate tasks or search-and-rescue operations in various environments. This work contributes both theoretically and practically to scalable multi-robot path planning and task allocation, offering an efficient framework for coordinating autonomous agents in shared environments.', 'abstract_zh': '一种多机器人系统满足全局布尔规范的新型路径规划与任务分配算法', 'title_zh': '布尔规格化下的高效路径规划与任务分配算法'}
{'arxiv_id': 'arXiv:2506.04842', 'title': 'MineInsight: A Multi-sensor Dataset for Humanitarian Demining Robotics in Off-Road Environments', 'authors': 'Mario Malizia, Charles Hamesse, Ken Hasselmann, Geert De Cubber, Nikolaos Tsiogkas, Eric Demeester, Rob Haelterman', 'link': 'https://arxiv.org/abs/2506.04842', 'abstract': 'The use of robotics in humanitarian demining increasingly involves computer vision techniques to improve landmine detection capabilities. However, in the absence of diverse and realistic datasets, the reliable validation of algorithms remains a challenge for the research community. In this paper, we introduce MineInsight, a publicly available multi-sensor, multi-spectral dataset designed for off-road landmine detection. The dataset features 35 different targets (15 landmines and 20 commonly found objects) distributed along three distinct tracks, providing a diverse and realistic testing environment. MineInsight is, to the best of our knowledge, the first dataset to integrate dual-view sensor scans from both an Unmanned Ground Vehicle and its robotic arm, offering multiple viewpoints to mitigate occlusions and improve spatial awareness. It features two LiDARs, as well as images captured at diverse spectral ranges, including visible (RGB, monochrome), visible short-wave infrared (VIS-SWIR), and long-wave infrared (LWIR). Additionally, the dataset comes with an estimation of the location of the targets, offering a benchmark for evaluating detection algorithms. We recorded approximately one hour of data in both daylight and nighttime conditions, resulting in around 38,000 RGB frames, 53,000 VIS-SWIR frames, and 108,000 LWIR frames. MineInsight serves as a benchmark for developing and evaluating landmine detection algorithms. Our dataset is available at this https URL.', 'abstract_zh': '机器人技术在人道主义地雷清除中的应用 increasingly involves 计算机视觉技术以提高地雷检测能力。然而，由于缺乏多样性和现实性的数据集，算法的可靠验证仍然是研究社区面临的挑战。本文我们介绍了 MineInsight，一个用于非道路地雷检测的多传感器、多光谱公开数据集。该数据集包含35个不同的目标（15个地雷和20个常见物体），分布在三条不同的轨道上，提供了一个多样且现实的测试环境。据我们所知，MineInsight 是第一个整合无人地面车辆及其机械臂双重视角传感器扫描数据的数据集，提供了多个视角以减轻遮挡并提高空间意识。该数据集包含两个LiDAR以及在不同谱段捕获的图像，包括可见光（RGB、单色）、可见短波红外（VIS-SWIR）和长波红外（LWIR）图像。此外，数据集还提供了目标位置的估计，为评估检测算法提供了一个基准。我们分别在白天和夜间记录了约一小时的数据，结果产生了约38,000帧RGB图像、53,000帧VIS-SWIR图像和108,000帧LWIR图像。MineInsight 作为开发和评估地雷检测算法的基准。我们的数据集可通过以下链接访问：this https URL。', 'title_zh': 'MineInsight: 适用于非道路环境的人道主义地雷清除机器人多传感器数据集'}
{'arxiv_id': 'arXiv:2506.04752', 'title': 'Tire Wear Aware Trajectory Tracking Control for Multi-axle Swerve-drive Autonomous Mobile Robots', 'authors': 'Tianxin Hu, Xinhang Xu, Thien-Minh Nguyen, Fen Liu, Shenghai Yuan, Lihua Xie', 'link': 'https://arxiv.org/abs/2506.04752', 'abstract': "Multi-axle Swerve-drive Autonomous Mobile Robots (MS-AGVs) equipped with independently steerable wheels are commonly used for high-payload transportation. In this work, we present a novel model predictive control (MPC) method for MS-AGV trajectory tracking that takes tire wear minimization consideration in the objective function. To speed up the problem-solving process, we propose a hierarchical controller design and simplify the dynamic model by integrating the \\textit{magic formula tire model} and \\textit{simplified tire wear model}. In the experiment, the proposed method can be solved by simulated annealing in real-time on a normal personal computer and by incorporating tire wear into the objective function, tire wear is reduced by 19.19\\% while maintaining the tracking accuracy in curve-tracking experiments. In the more challenging scene: the desired trajectory is offset by 60 degrees from the vehicle's heading, the reduction in tire wear increased to 65.20\\% compared to the kinematic model without considering the tire wear optimization.", 'abstract_zh': '带有独立转向轮的多轴偏转驱动自主移动机器人（MS-AGVs）常用于高载重运输。本文提出了一种新的考虑轮胎磨损最小化的模型预测控制（MPC）方法，用于MS-AGV轨迹跟踪。为了加快问题求解速度，我们提出了分层控制器设计，并通过集成“魔法公式轮胎模型”和“简化轮胎磨损模型”简化动态模型。在实验中，所提出的方法可以在普通个人计算机上通过模拟退火在实时下求解，并通过将轮胎磨损纳入目标函数，曲轨实验中的轮胎磨损降低了19.19%，同时保持了跟踪精度。在更具挑战性的场景中，期望轨迹相对于车辆航向偏移60度，与不考虑轮胎磨损优化的动力学模型相比，轮胎磨损减少了65.20%。', 'title_zh': '基于胎纹磨损的多轴转向驱动自主移动机器人轨迹跟踪控制'}
{'arxiv_id': 'arXiv:2506.04684', 'title': 'Real-Time LPV-Based Non-Linear Model Predictive Control for Robust Trajectory Tracking in Autonomous Vehicles', 'authors': 'Nitish Kumar, Rajalakshmi Pachamuthu', 'link': 'https://arxiv.org/abs/2506.04684', 'abstract': 'This paper presents the development and implementation of a Model Predictive Control (MPC) framework for trajectory tracking in autonomous vehicles under diverse driving conditions. The proposed approach incorporates a modular architecture that integrates state estimation, vehicle dynamics modeling, and optimization to ensure real-time performance. The state-space equations are formulated in a Linear Parameter Varying (LPV) form, and a curvature-based tuning method is introduced to optimize weight matrices for varying trajectories. The MPC framework is implemented using the Robot Operating System (ROS) for parallel execution of state estimation and control optimization, ensuring scalability and minimal latency. Extensive simulations and real-time experiments were conducted on multiple predefined trajectories, demonstrating high accuracy with minimal cross-track and orientation errors, even under aggressive maneuvers and high-speed conditions. The results highlight the robustness and adaptability of the proposed system, achieving seamless alignment between simulated and real-world performance. This work lays the foundation for dynamic weight tuning and integration into cooperative autonomous navigation systems, paving the way for enhanced safety and efficiency in autonomous driving applications.', 'abstract_zh': '本文提出了一种用于在各种驾驶条件下自主车辆轨迹跟踪的模型预测控制(MPC)框架的发展与实施。该提出的方案结合了模块化架构，该架构集成了状态估计、车辆动力学建模和优化，以确保实时性能。状态空间方程被形式化为线性参数变化(LPV)形式，并引入了一种基于曲率的调优方法以优化不同轨迹的权重矩阵。MPC框架使用机器人操作系统(ROS)实现，并行执行状态估计和控制优化，确保可扩展性并最小化延迟。在多种预定义轨迹上进行了广泛的仿真和实时实验，即使在激进操作和高速条件下也表现出高精度，且侧向和姿态误差较小。研究结果强调了所提出系统的稳健性和适应性，实现了模拟与实际性能的无缝对接。本文为动态权重调优及其在协同自主导航系统中的集成奠定了基础，为进一步提高自动驾驶应用的安全性和效率铺平了道路。', 'title_zh': '基于实时LPV的非线性模型预测控制在自主车辆 robust 轨迹跟踪中的应用'}
{'arxiv_id': 'arXiv:2506.04680', 'title': 'Application of SDRE to Achieve Gait Control in a Bipedal Robot for Knee-Type Exoskeleton Testing', 'authors': 'Ping-Kong Huang, Chien-Wu Lan, Chin-Tien Wu', 'link': 'https://arxiv.org/abs/2506.04680', 'abstract': 'Exoskeletons are widely used in rehabilitation and industrial applications to assist human motion. However, direct human testing poses risks due to possible exoskeleton malfunctions and inconsistent movement replication. To provide a safer and more repeatable testing environment, this study employs a bipedal robot platform to reproduce human gait, allowing for controlled exoskeleton evaluations. A control strategy based on the State-Dependent Riccati Equation (SDRE) is formulated to achieve optimal torque control for accurate gait replication. The bipedal robot dynamics are represented using double pendulum model, where SDRE-optimized control inputs minimize deviations from human motion trajectories. To align with motor behavior constraints, a parameterized control method is introduced to simplify the control process while effectively replicating human gait. The proposed approach initially adopts a ramping trapezoidal velocity model, which is then adapted into a piecewise linear velocity-time representation through motor command overwriting. This modification enables finer control over gait phase transitions while ensuring compatibility with motor dynamics. The corresponding cost function optimizes the control parameters to minimize errors in joint angles, velocities, and torques relative to SDRE control result. By structuring velocity transitions in accordance with motor limitations, the method reduce the computational load associated with real-time control. Experimental results verify the feasibility of the proposed parameterized control method in reproducing human gait. The bipedal robot platform provides a reliable and repeatable testing mechanism for knee-type exoskeletons, offering insights into exoskeleton performance under controlled conditions.', 'abstract_zh': '外骨骼在康复和工业应用中广泛用于辅助人体运动。然而，直接人体测试存在风险，因为可能出现外骨骼故障和运动复制不一致的问题。为了提供一个更安全和更具可重复性的测试环境，本研究采用双足机器人平台来再现人类步态，从而实现对外骨骼的受控评估。基于状态依赖型里卡提方程（SDRE）的控制策略被制定出来，以实现最优扭矩控制，准确再现步态。双足机器人动力学通过双摆模型表示，其中SDRE优化的控制输入最小化与人类运动轨迹的偏差。为了符合电机行为约束，引入了一种参数化控制方法来简化控制过程同时有效再现人类步态。所提出的方法最初采用梯形加速度模型，然后通过电机命令覆盖将其改编为分段线性速度-时间表示。这种修改在细控步态相位转换的同时，确保与电机动力学的兼容性。相应的代价函数优化控制参数，以最小化关节角度、速度和扭矩相对于SDRE控制结果的误差。通过根据电机限制结构化速度过渡，该方法减少了实时控制相关的计算负担。实验结果验证了所提出参数化控制方法在再现人类步态方面的可行性。双足机器人平台为膝型外骨骼提供了一种可靠且可重复的测试机制，在受控条件下揭示了外骨骼的性能。', 'title_zh': '基于SDRE的膝式外骨骼测试 bipedal机器人步态控制应用'}
{'arxiv_id': 'arXiv:2506.04646', 'title': 'ActivePusher: Active Learning and Planning with Residual Physics for Nonprehensile Manipulation', 'authors': 'Zhuoyun Zhong, Seyedali Golestaneh, Constantinos Chamzas', 'link': 'https://arxiv.org/abs/2506.04646', 'abstract': 'Planning with learned dynamics models offers a promising approach toward real-world, long-horizon manipulation, particularly in nonprehensile settings such as pushing or rolling, where accurate analytical models are difficult to obtain. Although learning-based methods hold promise, collecting training data can be costly and inefficient, as it often relies on randomly sampled interactions that are not necessarily the most informative. To address this challenge, we propose ActivePusher, a novel framework that combines residual-physics modeling with kernel-based uncertainty-driven active learning to focus data acquisition on the most informative skill parameters. Additionally, ActivePusher seamlessly integrates with model-based kinodynamic planners, leveraging uncertainty estimates to bias control sampling toward more reliable actions. We evaluate our approach in both simulation and real-world environments and demonstrate that it improves data efficiency and planning success rates compared to baseline methods.', 'abstract_zh': '基于学习动态模型的规划为实现真实世界中的长期操作提供了有前景的方法，特别是在推搡或滚动等非受握操作中，准确的分析模型难以获得。尽管基于学习的方法具有潜力，但收集训练数据可能代价高昂且效率低下，因为这通常依赖于随机采样的交互，未必是最具信息性的。为应对这一挑战，我们提出了ActivePusher，一种结合残差物理建模与核基于不确定性驱动的主动学习的新框架，专注于最信息性的技能参数的数据获取。此外，ActivePusher 无缝集成到基于模型的运动动力学规划器中，利用不确定性估计对控制采样进行偏置，以更倾向于可靠的操作。我们在模拟和真实世界环境中评估了这种方法，并证明其在数据效率和规划成功率方面优于基准方法。', 'title_zh': '主动推� Zhang: 基于残差物理的主动学习与计划在非挟持操作中'}
{'arxiv_id': 'arXiv:2506.04627', 'title': 'Enhancing Efficiency and Propulsion in Bio-mimetic Robotic Fish through End-to-End Deep Reinforcement Learning', 'authors': 'Xinyu Cui, Boai Sun, Yi Zhu, Ning Yang, Haifeng Zhang, Weicheng Cui, Dixia Fan, Jun Wang', 'link': 'https://arxiv.org/abs/2506.04627', 'abstract': "Aquatic organisms are known for their ability to generate efficient propulsion with low energy expenditure. While existing research has sought to leverage bio-inspired structures to reduce energy costs in underwater robotics, the crucial role of control policies in enhancing efficiency has often been overlooked. In this study, we optimize the motion of a bio-mimetic robotic fish using deep reinforcement learning (DRL) to maximize propulsion efficiency and minimize energy consumption. Our novel DRL approach incorporates extended pressure perception, a transformer model processing sequences of observations, and a policy transfer scheme. Notably, significantly improved training stability and speed within our approach allow for end-to-end training of the robotic fish. This enables agiler responses to hydrodynamic environments and possesses greater optimization potential compared to pre-defined motion pattern controls. Our experiments are conducted on a serially connected rigid robotic fish in a free stream with a Reynolds number of 6000 using computational fluid dynamics (CFD) simulations. The DRL-trained policies yield impressive results, demonstrating both high efficiency and propulsion. The policies also showcase the agent's embodiment, skillfully utilizing its body structure and engaging with surrounding fluid dynamics, as revealed through flow analysis. This study provides valuable insights into the bio-mimetic underwater robots optimization through DRL training, capitalizing on their structural advantages, and ultimately contributing to more efficient underwater propulsion systems.", 'abstract_zh': '使用深度强化学习优化仿生机器人鱼的运动以提高推进效率和减少能耗', 'title_zh': '通过端到端深度强化学习提升仿生鱼类机器人效率和推进性能'}
{'arxiv_id': 'arXiv:2506.04577', 'title': 'A Novel Transformer-Based Method for Full Lower-Limb Joint Angles and Moments Prediction in Gait Using sEMG and IMU data', 'authors': 'Farshad Haghgoo Daryakenari, Tara Farizeh', 'link': 'https://arxiv.org/abs/2506.04577', 'abstract': 'This study presents a transformer-based deep learning framework for the long-horizon prediction of full lower-limb joint angles and joint moments using surface electromyography (sEMG) and inertial measurement unit (IMU) signals. Two separate Transformer Neural Networks (TNNs) were designed: one for kinematic prediction and one for kinetic prediction. The model was developed with real-time application in mind, using only wearable sensors suitable for outside-laboratory use. Two prediction horizons were considered to evaluate short- and long-term performance. The network achieved high accuracy in both tasks, with Spearman correlation coefficients exceeding 0.96 and R-squared scores above 0.92 across all joints. Notably, the model consistently outperformed a recent benchmark method in joint angle prediction, reducing RMSE errors by an order of magnitude. The results confirmed the complementary role of sEMG and IMU signals in capturing both kinematic and kinetic information. This work demonstrates the potential of transformer-based models for real-time, full-limb biomechanical prediction in wearable and robotic applications, with future directions including input minimization and modality-specific weighting strategies to enhance model efficiency and accuracy.', 'abstract_zh': '基于变压器的深度学习框架在表面肌电图和惯性测量单元信号下的全下肢关节角度和关节力矩长时距预测', 'title_zh': '基于变压器的方法用于步态中下肢关节角度和力矩预测的新型数据融合技术（使用sEMG和IMU数据）'}
{'arxiv_id': 'arXiv:2506.04547', 'title': 'Multimodal Limbless Crawling Soft Robot with a Kirigami Skin', 'authors': 'Jonathan Tirado, Aida Parvaresh, Burcu Seyidoğlu, Darryl A. Bedford, Jonas Jørgensen, Ahmad Rafsanjani', 'link': 'https://arxiv.org/abs/2506.04547', 'abstract': "Limbless creatures can crawl on flat surfaces by deforming their bodies and interacting with asperities on the ground, offering a biological blueprint for designing efficient limbless robots. Inspired by this natural locomotion, we present a soft robot capable of navigating complex terrains using a combination of rectilinear motion and asymmetric steering gaits. The robot is made of a pair of antagonistic inflatable soft actuators covered with a flexible kirigami skin with asymmetric frictional properties. The robot's rectilinear locomotion is achieved through cyclic inflation of internal chambers with precise phase shifts, enabling forward progression. Steering is accomplished using an asymmetric gait, allowing for both in-place rotation and wide turns. To validate its mobility in obstacle-rich environments, we tested the robot in an arena with coarse substrates and multiple obstacles. Real-time feedback from onboard proximity sensors, integrated with a human-machine interface (HMI), allowed adaptive control to avoid collisions. This study highlights the potential of bioinspired soft robots for applications in confined or unstructured environments, such as search-and-rescue operations, environmental monitoring, and industrial inspections.", 'abstract_zh': '无肢生物通过变形身体并利用地面凸起进行爬行，为设计高效的无肢机器人提供了生物学蓝图。受此自然运动方式启发，我们提出了一种可以利用直线运动与不对称转向步态组合方式进行复杂地形导航的软机器人。该机器人由一对对抗式充气软执行器组成，表面覆盖着具有不对称摩擦性质的柔性 kirigami 外皮。机器人的直线爬行通过内部隔室的循环充气和精确的相位移实现，从而实现前进。转向则通过不对称步态实现，允许原地旋转和大范围转弯。为了验证其在多障碍环境中的移动性，我们在此类地形中具有粗糙材质的竞技场中对机器人进行了测试。通过集成内置接近传感器和人机界面（HMI），实现实时反馈并进行适应性控制以避免碰撞。本研究突显了受生物启发的软机器人在受限或未结构化环境中的应用潜力，如搜救、环境监测和工业检查等领域。', 'title_zh': 'kirigami 基皮肤的多模态无肢爬行软机器人'}
{'arxiv_id': 'arXiv:2506.04540', 'title': 'Chronoamperometry with Room-Temperature Ionic Liquids: Sub-Second Inference Techniques', 'authors': 'Kordel K. France', 'link': 'https://arxiv.org/abs/2506.04540', 'abstract': 'Chronoamperometry (CA) is a fundamental electrochemical technique used for quantifying redox-active species. However, in room-temperature ionic liquids (RTILs), the high viscosity and slow mass transport often lead to extended measurement durations. This paper presents a novel mathematical regression approach that reduces CA measurement windows to under 1 second, significantly faster than previously reported methods, which typically require 1-4 seconds or longer. By applying an inference algorithm to the initial transient current response, this method accurately predicts steady-state electrochemical parameters without requiring additional hardware modifications. The approach is validated through comparison with standard chronoamperometric techniques and is demonstrated to maintain reasonable accuracy while dramatically reducing data acquisition time. The implications of this technique are explored in analytical chemistry, sensor technology, and battery science, where rapid electrochemical quantification is critical. Our technique is focused on enabling faster multiplexing of chronoamperometric measurements for rapid olfactory and electrochemical analysis.', 'abstract_zh': 'chronoamperometry (CA)是一种用于定量测定氧化还原活性物种的基本电化学技术。然而，在室温离子液体（RTILs）中，高粘度和缓慢的质量传输往往导致测量时间延长。本文提出了一种新的数学回归方法，将CA测量窗口缩短至不足1秒，显著快于以往通常需要1-4秒或更长时间的方法。通过将推理算法应用于初始瞬态电流响应，该方法能够准确预测稳态电化学参数，无需额外的硬件修改。该方法通过与标准chronoamperometric技术进行比较得到了验证，并展示出可以在大幅减少数据采集时间的同时保持合理的准确性。该技术在分析化学、传感器技术和电池科学等领域具有重要意义，特别是在快速电化学定量分析中。本文方法侧重于实现更快的chronoamperometric测量的多路复用，以实现快速嗅觉和电化学分析。', 'title_zh': '室温离子液体介导的 chronoamperometry：亚秒级推断技术'}
{'arxiv_id': 'arXiv:2506.04539', 'title': 'Olfactory Inertial Odometry: Sensor Calibration and Drift Compensation', 'authors': 'Kordel K. France, Ovidiu Daescu, Anirban Paul, Shalini Prasad', 'link': 'https://arxiv.org/abs/2506.04539', 'abstract': "Visual inertial odometry (VIO) is a process for fusing visual and kinematic data to understand a machine's state in a navigation task. Olfactory inertial odometry (OIO) is an analog to VIO that fuses signals from gas sensors with inertial data to help a robot navigate by scent. Gas dynamics and environmental factors introduce disturbances into olfactory navigation tasks that can make OIO difficult to facilitate. With our work here, we define a process for calibrating a robot for OIO that generalizes to several olfaction sensor types. Our focus is specifically on calibrating OIO for centimeter-level accuracy in localizing an odor source on a slow-moving robot platform to demonstrate use cases in robotic surgery and touchless security screening. We demonstrate our process for OIO calibration on a real robotic arm and show how this calibration improves performance over a cold-start olfactory navigation task.", 'abstract_zh': '视觉惯性里程计（VIO）是一种融合视觉和动力学数据以理解机器在导航任务中状态的过程。气味惯性里程计（OIO）是一种将气体传感器信号与惯性数据融合以助机器人靠气味导航的技术。气体动力学和环境因素会对气味导航任务引入干扰，使OIO难以实现。通过我们的研究，我们定义了一种适用于多种气味传感器类型的校准过程，重点在于为缓慢移动的机器人平台校准OIO，以实现厘米级精度的气味源定位，应用于机器人手术和无接触安全筛查等场景。我们在实际的机器人手臂上展示了OIO校准过程，并展示了这种校准如何提升从冷启动开始的气味导航任务的性能。', 'title_zh': '嗅觉惯性里程计：传感器标定与漂移补偿'}
{'arxiv_id': 'arXiv:2506.04505', 'title': 'SGN-CIRL: Scene Graph-based Navigation with Curriculum, Imitation, and Reinforcement Learning', 'authors': 'Nikita Oskolkov, Huzhenyu Zhang, Dmitry Makarov, Dmitry Yudin, Aleksandr Panov', 'link': 'https://arxiv.org/abs/2506.04505', 'abstract': 'The 3D scene graph models spatial relationships between objects, enabling the agent to efficiently navigate in a partially observable environment and predict the location of the target this http URL paper proposes an original framework named SGN-CIRL (3D Scene Graph-Based Reinforcement Learning Navigation) for mapless reinforcement learning-based robot navigation with learnable representation of open-vocabulary 3D scene graph. To accelerate and stabilize the training of reinforcement learning-based algorithms, the framework also employs imitation learning and curriculum learning. The first one enables the agent to learn from demonstrations, while the second one structures the training process by gradually increasing task complexity from simple to more advanced scenarios. Numerical experiments conducted in the Isaac Sim environment showed that using a 3D scene graph for reinforcement learning significantly increased the success rate in difficult navigation cases. The code is open-sourced and available at: this https URL\\_graph.', 'abstract_zh': '基于3D场景图的强化学习导航：可学习开放词汇3D场景图的无地图机器人导航框架', 'title_zh': 'SGN-CIRL：基于场景图的 Curriculum、模仿和强化学习导航'}
{'arxiv_id': 'arXiv:2506.04484', 'title': 'Online Adaptation of Terrain-Aware Dynamics for Planning in Unstructured Environments', 'authors': 'William Ward, Sarah Etter, Tyler Ingebrand, Christian Ellis, Adam J. Thorpe, Ufuk Topcu', 'link': 'https://arxiv.org/abs/2506.04484', 'abstract': "Autonomous mobile robots operating in remote, unstructured environments must adapt to new, unpredictable terrains that can change rapidly during operation. In such scenarios, a critical challenge becomes estimating the robot's dynamics on changing terrain in order to enable reliable, accurate navigation and planning. We present a novel online adaptation approach for terrain-aware dynamics modeling and planning using function encoders. Our approach efficiently adapts to new terrains at runtime using limited online data without retraining or fine-tuning. By learning a set of neural network basis functions that span the robot dynamics on diverse terrains, we enable rapid online adaptation to new, unseen terrains and environments as a simple least-squares calculation. We demonstrate our approach for terrain adaptation in a Unity-based robotics simulator and show that the downstream controller has better empirical performance due to higher accuracy of the learned model. This leads to fewer collisions with obstacles while navigating in cluttered environments as compared to a neural ODE baseline.", 'abstract_zh': '自主移动机器人在远程和未结构化的环境中操作时必须适应新的、不可预测且可能会迅速变化的地形。在这种场景中，一个关键挑战是估计机器人在变化地形上的动力学，以便实现可靠的、精确的导航和规划。我们提出了一种基于功能编码的地形感知动力学建模与规划的新型在线适应方法。该方法能够在运行时利用有限的在线数据高效地适应新的地形，而无需重新训练或微调。通过学习一组神经网络基函数，这些函数概括了机器人在不同地形上的动力学特性，我们能够通过简单的最小二乘计算实现快速的在线适应，快速适应未见过的新地形和环境。我们在Unity基于的机器人模拟器中展示了该方法在地形适应方面的应用，并表明由于学习模型具有更高的准确性，下游控制器具有更好的实际性能。这导致在拥挤环境中导航时与障碍物的碰撞更少，优于神经常微分方程基线方法。', 'title_zh': '在线适应地形aware动力学规划在未结构化环境中'}
{'arxiv_id': 'arXiv:2506.04362', 'title': 'Learning Smooth State-Dependent Traversability from Dense Point Clouds', 'authors': 'Zihao Dong, Alan Papalia, Leonard Jung, Alenna Spiro, Philip R. Osteen, Christa S. Robison, Michael Everett', 'link': 'https://arxiv.org/abs/2506.04362', 'abstract': "A key open challenge in off-road autonomy is that the traversability of terrain often depends on the vehicle's state. In particular, some obstacles are only traversable from some orientations. However, learning this interaction by encoding the angle of approach as a model input demands a large and diverse training dataset and is computationally inefficient during planning due to repeated model inference. To address these challenges, we present SPARTA, a method for estimating approach angle conditioned traversability from point clouds. Specifically, we impose geometric structure into our network by outputting a smooth analytical function over the 1-Sphere that predicts risk distribution for any angle of approach with minimal overhead and can be reused for subsequent queries. The function is composed of Fourier basis functions, which has important advantages for generalization due to their periodic nature and smoothness. We demonstrate SPARTA both in a high-fidelity simulation platform, where our model achieves a 91\\% success rate crossing a 40m boulder field (compared to 73\\% for the baseline), and on hardware, illustrating the generalization ability of the model to real-world settings.", 'abstract_zh': '户外自主驾驶中的一个关键开放挑战是地形的可通行性往往依赖于车辆的状态。特别地，一些障碍物仅从某些角度通过是可通行的。然而，通过将接近角度编码为模型输入来学习这种相互作用需要大量的多样化的训练数据集，并且在规划过程中由于重复的模型推断而计算效率低下。为了解决这些挑战，我们提出了一种基于点云估计条件通行角度的方法SPARTA。具体来说，我们通过输出在1-球体上连续的解析函数来在网络中嵌入几何结构，该函数可以预测任何接近角度的风险分布，并且具有极低的开销并且可以在后续查询中重用。该函数由傅里叶基函数组成，由于其周期性和平滑性，这对模型的泛化能力至关重要。我们在高保真仿真平台上展示了SPARTA，其中我们的模型在穿过40米石场时的成功率为91%（基线为73%），并在硬件上展示了模型在实际场景中的泛化能力。', 'title_zh': '从密集点云学习平滑状态依赖可通过性'}
{'arxiv_id': 'arXiv:2506.04359', 'title': 'cuVSLAM: CUDA accelerated visual odometry', 'authors': 'Alexander Korovko, Dmitry Slepichev, Alexander Efitorov, Aigul Dzhumamuratova, Viktor Kuznetsov, Hesam Rabeti, Joydeep Biswas', 'link': 'https://arxiv.org/abs/2506.04359', 'abstract': 'Accurate and robust pose estimation is a key requirement for any autonomous robot. We present cuVSLAM, a state-of-the-art solution for visual simultaneous localization and mapping, which can operate with a variety of visual-inertial sensor suites, including multiple RGB and depth cameras, and inertial measurement units. cuVSLAM supports operation with as few as one RGB camera to as many as 32 cameras, in arbitrary geometric configurations, thus supporting a wide range of robotic setups. cuVSLAM is specifically optimized using CUDA to deploy in real-time applications with minimal computational overhead on edge-computing devices such as the NVIDIA Jetson. We present the design and implementation of cuVSLAM, example use cases, and empirical results on several state-of-the-art benchmarks demonstrating the best-in-class performance of cuVSLAM.', 'abstract_zh': '准确且 robust 的姿态估计是任何自主机器人的重要要求。我们提出了 cuVSLAM，一种最先进的视觉同时定位与建图解决方案，可与多种视觉-惯性传感器套件一起使用，包括多台 RGB 和深度相机以及惯性测量单元。cuVSLAM 在最少一个 RGB 摄像头到多达 32 个摄像头的任意几何配置下均能运行，从而支持广泛的机器人配置。cuVSLAM 特别针对 CUDA 进行优化，可在诸如 NVIDIA Jetson 的边缘计算设备上实现实时应用并保持最小的计算开销。我们介绍了 cuVSLAM 的设计与实现、示例用例以及在多个最先进的基准测试上的实验证据，证明了 cuVSLAM 的最佳性能。', 'title_zh': 'CUDA 加速的视觉里程柱 cuVSLAM'}
{'arxiv_id': 'arXiv:2506.04308', 'title': 'RoboRefer: Towards Spatial Referring with Reasoning in Vision-Language Models for Robotics', 'authors': 'Enshen Zhou, Jingkun An, Cheng Chi, Yi Han, Shanyu Rong, Chi Zhang, Pengwei Wang, Zhongyuan Wang, Tiejun Huang, Lu Sheng, Shanghang Zhang', 'link': 'https://arxiv.org/abs/2506.04308', 'abstract': 'Spatial referring is a fundamental capability of embodied robots to interact with the 3D physical world. However, even with the powerful pretrained vision language models (VLMs), recent approaches are still not qualified to accurately understand the complex 3D scenes and dynamically reason about the instruction-indicated locations for interaction. To this end, we propose RoboRefer, a 3D-aware VLM that can first achieve precise spatial understanding by integrating a disentangled but dedicated depth encoder via supervised fine-tuning (SFT). Moreover, RoboRefer advances generalized multi-step spatial reasoning via reinforcement fine-tuning (RFT), with metric-sensitive process reward functions tailored for spatial referring tasks. To support SFT and RFT training, we introduce RefSpatial, a large-scale dataset of 20M QA pairs (2x prior), covering 31 spatial relations (vs. 15 prior) and supporting complex reasoning processes (up to 5 steps). In addition, we introduce RefSpatial-Bench, a challenging benchmark filling the gap in evaluating spatial referring with multi-step reasoning. Experiments show that SFT-trained RoboRefer achieves state-of-the-art spatial understanding, with an average success rate of 89.6%. RFT-trained RoboRefer further outperforms all other baselines by a large margin, even surpassing Gemini-2.5-Pro by 17.4% in average accuracy on RefSpatial-Bench. Notably, RoboRefer can be integrated with various control policies to execute long-horizon, dynamic tasks across diverse robots (e,g., UR5, G1 humanoid) in cluttered real-world scenes.', 'abstract_zh': '基于空间参考的三维感知机器人三维空间推理能力对于与三维物理世界交互至关重要。然而，即使配备了强大的预训练视觉语言模型（VLMs），近期的方法仍然无法准确理解复杂的三维场景并动态推理指令指示的交互位置。为此，我们提出了RoboRefer，一种三维感知的VLM，通过监督微调(SFT)集成一个解耦但专门的深度编码器，首先实现精确的空间理解。此外，RoboRefer通过强化微调(RFT)推进了多步空间推理的泛化能力，使用敏感于度量的空间推理过程奖励函数，专门针对空间参考任务。为了支持SFT和RFT训练，我们引入了RefSpatial，一个包含2000万QA对的大规模数据集（是之前的两倍），覆盖了31种空间关系（相比之前的15种）并支持复杂的推理过程（最多5步）。此外，我们引入了RefSpatial-Bench，一个具有挑战性的基准测试，填补了多步推理评价空间参考的空白。实验表明，经过SFT训练的RoboRefer在空间理解方面达到了最先进的水平，平均成功率高达89.6%。经过RFT训练的RoboRefer在RefSpatial-Bench上的平均准确率上大幅超越其他基准，甚至在准确率上比Gemini-2.5-Pro高17.4%。值得注意的是，RoboRefer可以与其他控制策略集成，执行各种机器人（例如UR5、G1类人机器人）在复杂真实场景中的长期动态任务。', 'title_zh': 'RoboRefer: 向量语言模型在机器人领域中的空间指称推理研究'}
{'arxiv_id': 'arXiv:2506.05282', 'title': 'Rectified Point Flow: Generic Point Cloud Pose Estimation', 'authors': 'Tao Sun, Liyuan Zhu, Shengyu Huang, Shuran Song, Iro Armeni', 'link': 'https://arxiv.org/abs/2506.05282', 'abstract': 'We introduce Rectified Point Flow, a unified parameterization that formulates pairwise point cloud registration and multi-part shape assembly as a single conditional generative problem. Given unposed point clouds, our method learns a continuous point-wise velocity field that transports noisy points toward their target positions, from which part poses are recovered. In contrast to prior work that regresses part-wise poses with ad-hoc symmetry handling, our method intrinsically learns assembly symmetries without symmetry labels. Together with a self-supervised encoder focused on overlapping points, our method achieves a new state-of-the-art performance on six benchmarks spanning pairwise registration and shape assembly. Notably, our unified formulation enables effective joint training on diverse datasets, facilitating the learning of shared geometric priors and consequently boosting accuracy. Project page: this https URL.', 'abstract_zh': '我们引入了一种统一参数化方法——归一化点流，将点云配对注册和多部分形状组装统一 formulations 为单个条件生成问题。给定未配准的点云，我们的方法学习一个连续的点 wise 速度场，将噪声点运输到目标位置，并从中恢复部分姿态。与以往需要手工处理对称性的方法不同，我们的方法能够内在地学习组装对称性而无需对称性标签。结合一个专注于重叠点的自我监督编码器，我们的方法在六个涵盖配对注册和形状组装的基准测试中达到了新的最先进性能。值得注意的是，我们统一的框架能够有效地在多种数据集上进行联合训练，从而学习共享的几何先验并提高准确性。项目页面: this https URL。', 'title_zh': '正则化点流：通用点云姿态估计'}
{'arxiv_id': 'arXiv:2506.05250', 'title': 'Spatiotemporal Contrastive Learning for Cross-View Video Localization in Unstructured Off-road Terrains', 'authors': 'Zhiyun Deng, Dongmyeong Lee, Amanda Adkins, Jesse Quattrociocchi, Christian Ellis, Joydeep Biswas', 'link': 'https://arxiv.org/abs/2506.05250', 'abstract': 'Robust cross-view 3-DoF localization in GPS-denied, off-road environments remains challenging due to (1) perceptual ambiguities from repetitive vegetation and unstructured terrain, and (2) seasonal shifts that significantly alter scene appearance, hindering alignment with outdated satellite imagery. To address this, we introduce MoViX, a self-supervised cross-view video localization framework that learns viewpoint- and season-invariant representations while preserving directional awareness essential for accurate localization. MoViX employs a pose-dependent positive sampling strategy to enhance directional discrimination and temporally aligned hard negative mining to discourage shortcut learning from seasonal cues. A motion-informed frame sampler selects spatially diverse frames, and a lightweight temporal aggregator emphasizes geometrically aligned observations while downweighting ambiguous ones. At inference, MoViX runs within a Monte Carlo Localization framework, using a learned cross-view matching module in place of handcrafted models. Entropy-guided temperature scaling enables robust multi-hypothesis tracking and confident convergence under visual ambiguity. We evaluate MoViX on the TartanDrive 2.0 dataset, training on under 30 minutes of data and testing over 12.29 km. Despite outdated satellite imagery, MoViX localizes within 25 meters of ground truth 93% of the time, and within 50 meters 100% of the time in unseen regions, outperforming state-of-the-art baselines without environment-specific tuning. We further demonstrate generalization on a real-world off-road dataset from a geographically distinct site with a different robot platform.', 'abstract_zh': 'Robust跨视图3-DoF定位在GPS受限的非铺装路环境中依然具有挑战性，主要原因包括（1）重复植被和未结构化地形导致的感知歧义，以及（2）季节变化显著改变场景外观，妨碍与过时卫星影像的对齐。为解决这一问题，我们提出MoViX，一种自监督跨视图视频定位框架，学习视点和季节不变的表示，同时保留对于准确定位至关重要的方向感知。MoViX采用姿态依赖的正样本采样策略以增强方向性区分能力，并利用基于季节线索的临时对齐硬负挖掘避免捷径学习。运动信息驱动的帧选择器选择时空多样化的帧，轻量级的时空聚合器强调几何对齐的观测结果并削弱歧义观测结果。在推理时，MoViX运行在Monte Carlo定位框架内，使用学习到的跨视图匹配模块替代手工设计模型。熵引导的温度缩放使MoViX能够在视觉歧义下实现稳健的多假设跟踪和可靠的收敛。我们在TartanDrive 2.0数据集上评估MoViX，训练数据不足30分钟，测试距离超过12.29公里。尽管使用了过时的卫星影像，MoViX仍能在93%的时间内将定位误差控制在25米以内，在新区域中这一比例提升至100%，且在不同地理区域和机器人平台的现实世界非铺装路数据集上展示了泛化能力，超越了现有基线方法。', 'title_zh': '时空对比学习在无结构离路地形跨视图视频定位中的应用'}
{'arxiv_id': 'arXiv:2506.04867', 'title': 'LLMs for sensory-motor control: Combining in-context and iterative learning', 'authors': 'Jônata Tyska Carvalho, Stefano Nolfi', 'link': 'https://arxiv.org/abs/2506.04867', 'abstract': 'We propose a method that enables large language models (LLMs) to control embodied agents by directly mapping continuous observation vectors to continuous action vectors. Initially, the LLMs generate a control strategy based on a textual description of the agent, its environment, and the intended goal. This strategy is then iteratively refined through a learning process in which the LLMs are repeatedly prompted to improve the current strategy, using performance feedback and sensory-motor data collected during its evaluation. The method is validated on classic control tasks from the Gymnasium library and the inverted pendulum task from the MuJoCo library. In most cases, it successfully identifies optimal or high-performing solutions by integrating symbolic knowledge derived through reasoning with sub-symbolic sensory-motor data gathered as the agent interacts with its environment.', 'abstract_zh': '我们提出一种方法，使大型语言模型（LLMs）能够通过直接将连续观测向量映射到连续动作向量来控制具身代理。最初，LLMs 根据对代理、其环境以及预期目标的文本描述生成控制策略。然后，通过迭代学习过程不断细化该策略，在该过程中，LLMs 在评估过程中反复被提示改进当前策略，使用性能反馈和收集的感官-运动数据。该方法在 Gymnasium 库的经典控制任务和 MuJoCo 库的倒立摆任务上进行了验证。在大多数情况下，该方法通过结合通过推理获取的符号知识与代理与环境互动过程中收集的次符号感官-运动数据，成功识别出最优或高性能的解决方案。', 'title_zh': '感官-运动控制中的大型语言模型：结合上下文学习和迭代学习'}
{'arxiv_id': 'arXiv:2506.04500', 'title': '"Don\'t Do That!": Guiding Embodied Systems through Large Language Model-based Constraint Generation', 'authors': 'Aladin Djuhera, Amin Seffo, Masataro Asai, Holger Boche', 'link': 'https://arxiv.org/abs/2506.04500', 'abstract': "Recent advancements in large language models (LLMs) have spurred interest in robotic navigation that incorporates complex spatial, mathematical, and conditional constraints from natural language into the planning problem. Such constraints can be informal yet highly complex, making it challenging to translate into a formal description that can be passed on to a planning algorithm. In this paper, we propose STPR, a constraint generation framework that uses LLMs to translate constraints (expressed as instructions on ``what not to do'') into executable Python functions. STPR leverages the LLM's strong coding capabilities to shift the problem description from language into structured and transparent code, thus circumventing complex reasoning and avoiding potential hallucinations. We show that these LLM-generated functions accurately describe even complex mathematical constraints, and apply them to point cloud representations with traditional search algorithms. Experiments in a simulated Gazebo environment show that STPR ensures full compliance across several constraints and scenarios, while having short runtimes. We also verify that STPR can be used with smaller, code-specific LLMs, making it applicable to a wide range of compact models at low inference cost.", 'abstract_zh': 'Recent advancements in大型语言模型（LLMs）推动了将复杂空间、数学和条件约束从自然语言融入规划问题的类人导航研究。这类约束往往是非正式的但高度复杂，使得将其转化为可以传递给规划算法的正式描述变得具有挑战性。本文 propose STPR，一种使用大型语言模型生成约束的框架，将约束（以“不要做什么”的指示形式表达）转化为可执行的Python函数。STPR 利用大型语言模型强大的编码能力，将问题描述从自然语言转变为结构化和透明的代码，从而绕过了复杂的推理并避免潜在的幻觉。实验表明，这些由大型语言模型生成的函数能够准确描述复杂的数学约束，并将其应用于传统搜索算法中的点云表示。在Gazebo仿真环境中进行的实验显示，STPR 能确保在多种约束和场景下完全合规，同时具有短的运行时间。此外，我们验证了STPR可以结合使用较小的、代码特定的大型语言模型，使其适用于广泛的紧凑模型且推理成本较低。', 'title_zh': '“不要这么做！”：通过基于大型语言模型的约束生成引导具身系统'}
{'arxiv_id': 'arXiv:2506.04404', 'title': 'A Framework Leveraging Large Language Models for Autonomous UAV Control in Flying Networks', 'authors': 'Diana Nunes, Ricardo Amorim, Pedro Ribeiro, André Coelho, Rui Campos', 'link': 'https://arxiv.org/abs/2506.04404', 'abstract': "This paper proposes FLUC, a modular framework that integrates open-source Large Language Models (LLMs) with Unmanned Aerial Vehicle (UAV) autopilot systems to enable autonomous control in Flying Networks (FNs). FLUC translates high-level natural language commands into executable UAV mission code, bridging the gap between operator intent and UAV behaviour.\nFLUC is evaluated using three open-source LLMs - Qwen 2.5, Gemma 2, and LLaMA 3.2 - across scenarios involving code generation and mission planning. Results show that Qwen 2.5 excels in multi-step reasoning, Gemma 2 balances accuracy and latency, and LLaMA 3.2 offers faster responses with lower logical coherence. A case study on energy-aware UAV positioning confirms FLUC's ability to interpret structured prompts and autonomously execute domain-specific logic, showing its effectiveness in real-time, mission-driven control.", 'abstract_zh': '本文提出FLUC，这是一种模块化框架，将开源大规模语言模型（LLMs）与无人机（UAV）自主飞行控制系统集成，以实现飞行网络（FNs）的自主控制。FLUC将高级自然语言指令转换为可执行的无人机任务代码，填补了操作员意图与无人机行为之间的差距。', 'title_zh': '一种利用大规模语言模型实现飞行网络中自主无人机控制的框架'}
{'arxiv_id': 'arXiv:2506.04399', 'title': 'Unsupervised Meta-Testing with Conditional Neural Processes for Hybrid Meta-Reinforcement Learning', 'authors': 'Suzan Ece Ada, Emre Ugur', 'link': 'https://arxiv.org/abs/2506.04399', 'abstract': 'We introduce Unsupervised Meta-Testing with Conditional Neural Processes (UMCNP), a novel hybrid few-shot meta-reinforcement learning (meta-RL) method that uniquely combines, yet distinctly separates, parameterized policy gradient-based (PPG) and task inference-based few-shot meta-RL. Tailored for settings where the reward signal is missing during meta-testing, our method increases sample efficiency without requiring additional samples in meta-training. UMCNP leverages the efficiency and scalability of Conditional Neural Processes (CNPs) to reduce the number of online interactions required in meta-testing. During meta-training, samples previously collected through PPG meta-RL are efficiently reused for learning task inference in an offline manner. UMCNP infers the latent representation of the transition dynamics model from a single test task rollout with unknown parameters. This approach allows us to generate rollouts for self-adaptation by interacting with the learned dynamics model. We demonstrate our method can adapt to an unseen test task using significantly fewer samples during meta-testing than the baselines in 2D-Point Agent and continuous control meta-RL benchmarks, namely, cartpole with unknown angle sensor bias, walker agent with randomized dynamics parameters.', 'abstract_zh': '无监督元测试条件神经过程（UMCNP）：一种独特的参数化策略梯度（PPG）和任务推断（基于任务）元强化学习（元-RL）方法的混合体', 'title_zh': '基于条件神经过程的无监督元测试在混合元强化学习中的应用'}
