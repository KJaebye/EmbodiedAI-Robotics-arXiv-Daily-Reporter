# LiPo: A Lightweight Post-optimization Framework for Smoothing Action Chunks Generated by Learned Policies 

**Title (ZH)**: LiPo：一种轻量级后优化框架，用于平滑由学习策略生成的动作片段 

**Authors**: Dongwoo Son, Suhan Park  

**Link**: [PDF](https://arxiv.org/pdf/2506.05165)  

**Abstract**: Recent advances in imitation learning have enabled robots to perform increasingly complex manipulation tasks in unstructured environments. However, most learned policies rely on discrete action chunking, which introduces discontinuities at chunk boundaries. These discontinuities degrade motion quality and are particularly problematic in dynamic tasks such as throwing or lifting heavy objects, where smooth trajectories are critical for momentum transfer and system stability. In this work, we present a lightweight post-optimization framework for smoothing chunked action sequences. Our method combines three key components: (1) inference-aware chunk scheduling to proactively generate overlapping chunks and avoid pauses from inference delays; (2) linear blending in the overlap region to reduce abrupt transitions; and (3) jerk-minimizing trajectory optimization constrained within a bounded perturbation space. The proposed method was validated on a position-controlled robotic arm performing dynamic manipulation tasks. Experimental results demonstrate that our approach significantly reduces vibration and motion jitter, leading to smoother execution and improved mechanical robustness. 

**Abstract (ZH)**: 近期模仿学习的进步使机器人能够在非结构化环境中执行越来越复杂的操作任务。然而，大多数学到的策略依赖于离散的动作分块，这会在分块边界引入不连续性，这些不连续性会降低运动质量，并在抛掷或提起重物等动态任务中特别存在问题，因为在这些任务中平滑的轨迹对于动量传递和系统稳定性至关重要。在此工作中，我们提出了一种轻量级后优化框架以平滑分块动作序列。本文方法结合了三个关键组件：(1) 模型感知的分块调度，以事先生成重叠分块并避免推理延迟导致的停顿；(2) 在重叠区域进行线性混合以减少突变过渡；(3) 在限定的扰动空间内最小化冲击的轨迹优化。所提出的算法已在执行动态操作任务的位置控制型机器人手臂上进行了验证。实验结果表明，我们的方法显著减少了振动和运动颤动，从而实现了更平滑的执行并提高了机械鲁棒性。 

---
# Realizing Text-Driven Motion Generation on NAO Robot: A Reinforcement Learning-Optimized Control Pipeline 

**Title (ZH)**: 基于强化学习优化的文本驱动运动生成控制管道在NAO机器人上的实现 

**Authors**: Zihan Xu, Mengxian Hu, Kaiyan Xiao, Qin Fang, Chengju Liu, Qijun Chen  

**Link**: [PDF](https://arxiv.org/pdf/2506.05117)  

**Abstract**: Human motion retargeting for humanoid robots, transferring human motion data to robots for imitation, presents significant challenges but offers considerable potential for real-world applications. Traditionally, this process relies on human demonstrations captured through pose estimation or motion capture systems. In this paper, we explore a text-driven approach to mapping human motion to humanoids. To address the inherent discrepancies between the generated motion representations and the kinematic constraints of humanoid robots, we propose an angle signal network based on norm-position and rotation loss (NPR Loss). It generates joint angles, which serve as inputs to a reinforcement learning-based whole-body joint motion control policy. The policy ensures tracking of the generated motions while maintaining the robot's stability during execution. Our experimental results demonstrate the efficacy of this approach, successfully transferring text-driven human motion to a real humanoid robot NAO. 

**Abstract (ZH)**: 基于文本驱动的 humanoid 机器人人体 motion 转移：一种基于 norm-position 和旋转损失的关节角度信号网络方法 

---
# Whole-Body Constrained Learning for Legged Locomotion via Hierarchical Optimization 

**Title (ZH)**: 基于分层优化的全身约束学习腿部运动控制 

**Authors**: Haoyu Wang, Ruyi Zhou, Liang Ding, Tie Liu, Zhelin Zhang, Peng Xu, Haibo Gao, Zongquan Deng  

**Link**: [PDF](https://arxiv.org/pdf/2506.05115)  

**Abstract**: Reinforcement learning (RL) has demonstrated impressive performance in legged locomotion over various challenging environments. However, due to the sim-to-real gap and lack of explainability, unconstrained RL policies deployed in the real world still suffer from inevitable safety issues, such as joint collisions, excessive torque, or foot slippage in low-friction environments. These problems limit its usage in missions with strict safety requirements, such as planetary exploration, nuclear facility inspection, and deep-sea operations. In this paper, we design a hierarchical optimization-based whole-body follower, which integrates both hard and soft constraints into RL framework to make the robot move with better safety guarantees. Leveraging the advantages of model-based control, our approach allows for the definition of various types of hard and soft constraints during training or deployment, which allows for policy fine-tuning and mitigates the challenges of sim-to-real transfer. Meanwhile, it preserves the robustness of RL when dealing with locomotion in complex unstructured environments. The trained policy with introduced constraints was deployed in a hexapod robot and tested in various outdoor environments, including snow-covered slopes and stairs, demonstrating the great traversability and safety of our approach. 

**Abstract (ZH)**: 基于层次优化的整体身体跟随者：将硬约束和软约束集成到强化学习框架中以提高机器人移动的安全性 

---
# Synthetic Dataset Generation for Autonomous Mobile Robots Using 3D Gaussian Splatting for Vision Training 

**Title (ZH)**: 使用3D高斯点绘制生成自主移动机器人视觉训练的合成数据集 

**Authors**: Aneesh Deogan, Wout Beks, Peter Teurlings, Koen de Vos, Mark van den Brand, Rene van de Molengraft  

**Link**: [PDF](https://arxiv.org/pdf/2506.05092)  

**Abstract**: Annotated datasets are critical for training neural networks for object detection, yet their manual creation is time- and labour-intensive, subjective to human error, and often limited in diversity. This challenge is particularly pronounced in the domain of robotics, where diverse and dynamic scenarios further complicate the creation of representative datasets. To address this, we propose a novel method for automatically generating annotated synthetic data in Unreal Engine. Our approach leverages photorealistic 3D Gaussian splats for rapid synthetic data generation. We demonstrate that synthetic datasets can achieve performance comparable to that of real-world datasets while significantly reducing the time required to generate and annotate data. Additionally, combining real-world and synthetic data significantly increases object detection performance by leveraging the quality of real-world images with the easier scalability of synthetic data. To our knowledge, this is the first application of synthetic data for training object detection algorithms in the highly dynamic and varied environment of robot soccer. Validation experiments reveal that a detector trained on synthetic images performs on par with one trained on manually annotated real-world images when tested on robot soccer match scenarios. Our method offers a scalable and comprehensive alternative to traditional dataset creation, eliminating the labour-intensive error-prone manual annotation process. By generating datasets in a simulator where all elements are intrinsically known, we ensure accurate annotations while significantly reducing manual effort, which makes it particularly valuable for robotics applications requiring diverse and scalable training data. 

**Abstract (ZH)**: 基于 Unreal Engine 的自动生成标注合成数据方法在机器人足球场景下的物体检测应用 

---
# DemoSpeedup: Accelerating Visuomotor Policies via Entropy-Guided Demonstration Acceleration 

**Title (ZH)**: DemoSpeedup: 通过熵导引的示范加速来加速知觉-运动策略 

**Authors**: Lingxiao Guo, Zhengrong Xue, Zijing Xu, Huazhe Xu  

**Link**: [PDF](https://arxiv.org/pdf/2506.05064)  

**Abstract**: Imitation learning has shown great promise in robotic manipulation, but the policy's execution is often unsatisfactorily slow due to commonly tardy demonstrations collected by human operators. In this work, we present DemoSpeedup, a self-supervised method to accelerate visuomotor policy execution via entropy-guided demonstration acceleration. DemoSpeedup starts from training an arbitrary generative policy (e.g., ACT or Diffusion Policy) on normal-speed demonstrations, which serves as a per-frame action entropy estimator. The key insight is that frames with lower action entropy estimates call for more consistent policy behaviors, which often indicate the demands for higher-precision operations. In contrast, frames with higher entropy estimates correspond to more casual sections, and therefore can be more safely accelerated. Thus, we segment the original demonstrations according to the estimated entropy, and accelerate them by down-sampling at rates that increase with the entropy values. Trained with the speedup demonstrations, the resulting policies execute up to 3 times faster while maintaining the task completion performance. Interestingly, these policies could even achieve higher success rates than those trained with normal-speed demonstrations, due to the benefits of reduced decision-making horizons. 

**Abstract (ZH)**: 基于熵指导的演示加速：DemoSpeedup在机器人操作中的自监督方法 

---
# PulseRide: A Robotic Wheelchair for Personalized Exertion Control with Human-in-the-Loop Reinforcement Learning 

**Title (ZH)**: PulseRide：一种基于人类在环强化学习的个性化用力控制机器人轮椅 

**Authors**: Azizul Zahid, Bibek Poudel, Danny Scott, Jason Scott, Scott Crouter, Weizi Li, Sai Swaminathan  

**Link**: [PDF](https://arxiv.org/pdf/2506.05056)  

**Abstract**: Maintaining an active lifestyle is vital for quality of life, yet challenging for wheelchair users. For instance, powered wheelchairs face increasing risks of obesity and deconditioning due to inactivity. Conversely, manual wheelchair users, who propel the wheelchair by pushing the wheelchair's handrims, often face upper extremity injuries from repetitive motions. These challenges underscore the need for a mobility system that promotes activity while minimizing injury risk. Maintaining optimal exertion during wheelchair use enhances health benefits and engagement, yet the variations in individual physiological responses complicate exertion optimization. To address this, we introduce PulseRide, a novel wheelchair system that provides personalized assistance based on each user's physiological responses, helping them maintain their physical exertion goals. Unlike conventional assistive systems focused on obstacle avoidance and navigation, PulseRide integrates real-time physiological data-such as heart rate and ECG-with wheelchair speed to deliver adaptive assistance. Using a human-in-the-loop reinforcement learning approach with Deep Q-Network algorithm (DQN), the system adjusts push assistance to keep users within a moderate activity range without under- or over-exertion. We conducted preliminary tests with 10 users on various terrains, including carpet and slate, to assess PulseRide's effectiveness. Our findings show that, for individual users, PulseRide maintains heart rates within the moderate activity zone as much as 71.7 percent longer than manual wheelchairs. Among all users, we observed an average reduction in muscle contractions of 41.86 percent, delaying fatigue onset and enhancing overall comfort and engagement. These results indicate that PulseRide offers a healthier, adaptive mobility solution, bridging the gap between passive and physically taxing mobility options. 

**Abstract (ZH)**: 基于生理响应的个性化辅助轮椅系统：PulseRide研究 

---
# Hierarchical Language Models for Semantic Navigation and Manipulation in an Aerial-Ground Robotic System 

**Title (ZH)**: 基于层次语言模型的空地机器人系统中语义导航与操控 

**Authors**: Haokun Liu, Zhaoqi Ma, Yunong Li, Junichiro Sugihara, Yicheng Chen, Jinjie Li, Moju Zhao  

**Link**: [PDF](https://arxiv.org/pdf/2506.05020)  

**Abstract**: Heterogeneous multi-robot systems show great potential in complex tasks requiring coordinated hybrid cooperation. However, traditional approaches relying on static models often struggle with task diversity and dynamic environments. This highlights the need for generalizable intelligence that can bridge high-level reasoning with low-level execution across heterogeneous agents. To address this, we propose a hierarchical framework integrating a prompted Large Language Model (LLM) and a GridMask-enhanced fine-tuned Vision Language Model (VLM). The LLM performs task decomposition and global semantic map construction, while the VLM extracts task-specified semantic labels and 2D spatial information from aerial images to support local planning. Within this framework, the aerial robot follows a globally optimized semantic path and continuously provides bird-view images, guiding the ground robot's local semantic navigation and manipulation, including target-absent scenarios where implicit alignment is maintained. Experiments on a real-world letter-cubes arrangement task demonstrate the framework's adaptability and robustness in dynamic environments. To the best of our knowledge, this is the first demonstration of an aerial-ground heterogeneous system integrating VLM-based perception with LLM-driven task reasoning and motion planning. 

**Abstract (ZH)**: 异构多机器人系统在需要协调混合合作的复杂任务中显示出巨大的潜力。然而，传统的依赖静态模型的方法往往难以应对任务多样性和动态环境。这强调了需要一种可泛化的智能，能够跨越异构代理的高层推理与低层执行进行桥梁构建。为了解决这个问题，我们提出了一种层次框架，该框架整合了一个被提示的大语言模型（LLM）和一个GridMask增强的微调视觉语言模型（VLM）。LLM负责任务分解和全局语义地图构建，而VLM从空中图像中提取任务特定的语义标签和二维空间信息，以支持局部规划。在该框架中，空中机器人遵循全局优化的语义路径，并持续提供鸟瞰图图像，引导地面机器人进行局部语义导航和操作，包括目标缺席的场景，其中保持隐式的对齐。在现实世界的字母立方体排列任务上的实验表明，该框架在动态环境中的适应性和鲁棒性。据我们所知，这是首次将基于VLM的感知与LLM驱动的任务推理和运动规划集成到空中-地面异构系统中的演示。 

---
# GEX: Democratizing Dexterity with Fully-Actuated Dexterous Hand and Exoskeleton Glove 

**Title (ZH)**: GEX: 通过全驱动灵巧手和外骨骼手套实现灵巧性的民主化 

**Authors**: Yunlong Dong, Xing Liu, Jun Wan, Zelin Deng  

**Link**: [PDF](https://arxiv.org/pdf/2506.04982)  

**Abstract**: This paper introduces GEX, an innovative low-cost dexterous manipulation system that combines the GX11 tri-finger anthropomorphic hand (11 DoF) with the EX12 tri-finger exoskeleton glove (12 DoF), forming a closed-loop teleoperation framework through kinematic retargeting for high-fidelity control. Both components employ modular 3D-printed finger designs, achieving ultra-low manufacturing costs while maintaining full actuation capabilities. Departing from conventional tendon-driven or underactuated approaches, our electromechanical system integrates independent joint motors across all 23 DoF, ensuring complete state observability and accurate kinematic modeling. This full-actuation architecture enables precise bidirectional kinematic calculations, substantially enhancing kinematic retargeting fidelity between the exoskeleton and robotic hand. The proposed system bridges the cost-performance gap in dexterous manipulation research, providing an accessible platform for acquiring high-quality demonstration data to advance embodied AI and dexterous robotic skill transfer learning. 

**Abstract (ZH)**: 本文介绍了GEX，这是一个创新性的低成本灵巧 manipulation 系统，结合了GX11三指类人手（11 自由度）和EX12三指外骨骼手套（12 自由度），通过运动学重定位形成闭环远程操作框架，实现高保真控制。两个组件采用模块化3D打印手指设计，同时实现超低制造成本并保持完整的驱动能力。不同于传统的腱驱动或欠驱动方法，我们的机电系统在所有23个自由度上集成独立关节电机，确保完全的状态可观测性和精确的运动学建模。这种全驱动架构使精确的双向运动学计算成为可能，极大地提高了外骨骼和机器人手之间的运动学重定位保真度。所提出的系统弥合了灵巧 manipulation 研究中的成本与性能差距，提供了一个可访问的平台，以获取高质量的演示数据，推进体态人工智能和灵巧机器人技能转移学习。 

---
# ArtVIP: Articulated Digital Assets of Visual Realism, Modular Interaction, and Physical Fidelity for Robot Learning 

**Title (ZH)**: ArtVIP: 视觉现实性、模块化交互和物理保真度的articulated数字资产及其在机器人学习中的应用 

**Authors**: Zhao Jin, Zhengping Che, Zhen Zhao, Kun Wu, Yuheng Zhang, Yinuo Zhao, Zehui Liu, Qiang Zhang, Xiaozhu Ju, Jing Tian, Yousong Xue, Jian Tang  

**Link**: [PDF](https://arxiv.org/pdf/2506.04941)  

**Abstract**: Robot learning increasingly relies on simulation to advance complex ability such as dexterous manipulations and precise interactions, necessitating high-quality digital assets to bridge the sim-to-real gap. However, existing open-source articulated-object datasets for simulation are limited by insufficient visual realism and low physical fidelity, which hinder their utility for training models mastering robotic tasks in real world. To address these challenges, we introduce ArtVIP, a comprehensive open-source dataset comprising high-quality digital-twin articulated objects, accompanied by indoor-scene assets. Crafted by professional 3D modelers adhering to unified standards, ArtVIP ensures visual realism through precise geometric meshes and high-resolution textures, while physical fidelity is achieved via fine-tuned dynamic parameters. Meanwhile, the dataset pioneers embedded modular interaction behaviors within assets and pixel-level affordance annotations. Feature-map visualization and optical motion capture are employed to quantitatively demonstrate ArtVIP 's visual and physical fidelity, with its applicability validated across imitation learning and reinforcement learning experiments. Provided in USD format with detailed production guidelines, \ours is fully open-source, benefiting the research community and advancing robot learning research. Our project is at this https URL 

**Abstract (ZH)**: 机器人学习越来越多地依赖仿真来提高如灵巧操作和精确交互等复杂能力，这要求有高质量的数字资产来弥补仿真到现实的差距。然而，现有开源的关节物体数据集在视觉真实感和物理保真度方面存在局限，这限制了其在训练掌握机器人任务模型方面的应用。为了解决这些挑战，我们引入了ArtVIP，这是一个包含高质量数字孪生关节物体和室内场景资产的全面开源数据集。由专业的3D建模师按照统一标准打造，ArtVIP通过精确的几何网格和高分辨率纹理确保了视觉真实感，同时通过精细调整的动力学参数实现了物理保真度。此外，数据集在资产中嵌入了模块化的交互行为，并提供了像素级的功能性注释。通过特征图可视化和光学动作捕捉，定量展示了ArtVIP的视觉和物理保真度，并通过模仿学习和强化学习实验验证了其适用性。提供USD格式并附有详细生产指南，我们的项目完全开源，服务于研究社区并推动机器人学习研究。项目链接：this https URL 

---
# Enhancing Efficiency and Propulsion in Bio-mimetic Robotic Fish through End-to-End Deep Reinforcement Learning 

**Title (ZH)**: 通过端到端深度强化学习提升仿生鱼类机器人效率和推进性能 

**Authors**: Xinyu Cui, Boai Sun, Yi Zhu, Ning Yang, Haifeng Zhang, Weicheng Cui, Dixia Fan, Jun Wang  

**Link**: [PDF](https://arxiv.org/pdf/2506.04627)  

**Abstract**: Aquatic organisms are known for their ability to generate efficient propulsion with low energy expenditure. While existing research has sought to leverage bio-inspired structures to reduce energy costs in underwater robotics, the crucial role of control policies in enhancing efficiency has often been overlooked. In this study, we optimize the motion of a bio-mimetic robotic fish using deep reinforcement learning (DRL) to maximize propulsion efficiency and minimize energy consumption. Our novel DRL approach incorporates extended pressure perception, a transformer model processing sequences of observations, and a policy transfer scheme. Notably, significantly improved training stability and speed within our approach allow for end-to-end training of the robotic fish. This enables agiler responses to hydrodynamic environments and possesses greater optimization potential compared to pre-defined motion pattern controls. Our experiments are conducted on a serially connected rigid robotic fish in a free stream with a Reynolds number of 6000 using computational fluid dynamics (CFD) simulations. The DRL-trained policies yield impressive results, demonstrating both high efficiency and propulsion. The policies also showcase the agent's embodiment, skillfully utilizing its body structure and engaging with surrounding fluid dynamics, as revealed through flow analysis. This study provides valuable insights into the bio-mimetic underwater robots optimization through DRL training, capitalizing on their structural advantages, and ultimately contributing to more efficient underwater propulsion systems. 

**Abstract (ZH)**: 使用深度强化学习优化仿生机器人鱼的运动以提高推进效率和减少能耗 

---
# SGN-CIRL: Scene Graph-based Navigation with Curriculum, Imitation, and Reinforcement Learning 

**Title (ZH)**: SGN-CIRL：基于场景图的 Curriculum、模仿和强化学习导航 

**Authors**: Nikita Oskolkov, Huzhenyu Zhang, Dmitry Makarov, Dmitry Yudin, Aleksandr Panov  

**Link**: [PDF](https://arxiv.org/pdf/2506.04505)  

**Abstract**: The 3D scene graph models spatial relationships between objects, enabling the agent to efficiently navigate in a partially observable environment and predict the location of the target this http URL paper proposes an original framework named SGN-CIRL (3D Scene Graph-Based Reinforcement Learning Navigation) for mapless reinforcement learning-based robot navigation with learnable representation of open-vocabulary 3D scene graph. To accelerate and stabilize the training of reinforcement learning-based algorithms, the framework also employs imitation learning and curriculum learning. The first one enables the agent to learn from demonstrations, while the second one structures the training process by gradually increasing task complexity from simple to more advanced scenarios. Numerical experiments conducted in the Isaac Sim environment showed that using a 3D scene graph for reinforcement learning significantly increased the success rate in difficult navigation cases. The code is open-sourced and available at: this https URL\_graph. 

**Abstract (ZH)**: 基于3D场景图的强化学习导航：可学习开放词汇3D场景图的无地图机器人导航框架 

---
# Online Adaptation of Terrain-Aware Dynamics for Planning in Unstructured Environments 

**Title (ZH)**: 在线适应地形aware动力学规划在未结构化环境中 

**Authors**: William Ward, Sarah Etter, Tyler Ingebrand, Christian Ellis, Adam J. Thorpe, Ufuk Topcu  

**Link**: [PDF](https://arxiv.org/pdf/2506.04484)  

**Abstract**: Autonomous mobile robots operating in remote, unstructured environments must adapt to new, unpredictable terrains that can change rapidly during operation. In such scenarios, a critical challenge becomes estimating the robot's dynamics on changing terrain in order to enable reliable, accurate navigation and planning. We present a novel online adaptation approach for terrain-aware dynamics modeling and planning using function encoders. Our approach efficiently adapts to new terrains at runtime using limited online data without retraining or fine-tuning. By learning a set of neural network basis functions that span the robot dynamics on diverse terrains, we enable rapid online adaptation to new, unseen terrains and environments as a simple least-squares calculation. We demonstrate our approach for terrain adaptation in a Unity-based robotics simulator and show that the downstream controller has better empirical performance due to higher accuracy of the learned model. This leads to fewer collisions with obstacles while navigating in cluttered environments as compared to a neural ODE baseline. 

**Abstract (ZH)**: 自主移动机器人在远程和未结构化的环境中操作时必须适应新的、不可预测且可能会迅速变化的地形。在这种场景中，一个关键挑战是估计机器人在变化地形上的动力学，以便实现可靠的、精确的导航和规划。我们提出了一种基于功能编码的地形感知动力学建模与规划的新型在线适应方法。该方法能够在运行时利用有限的在线数据高效地适应新的地形，而无需重新训练或微调。通过学习一组神经网络基函数，这些函数概括了机器人在不同地形上的动力学特性，我们能够通过简单的最小二乘计算实现快速的在线适应，快速适应未见过的新地形和环境。我们在Unity基于的机器人模拟器中展示了该方法在地形适应方面的应用，并表明由于学习模型具有更高的准确性，下游控制器具有更好的实际性能。这导致在拥挤环境中导航时与障碍物的碰撞更少，优于神经常微分方程基线方法。 

---
# RoboRefer: Towards Spatial Referring with Reasoning in Vision-Language Models for Robotics 

**Title (ZH)**: RoboRefer：面向机器人领域中视觉-语言模型的空间指称推理研究 

**Authors**: Enshen Zhou, Jingkun An, Cheng Chi, Yi Han, Shanyu Rong, Chi Zhang, Pengwei Wang, Zhongyuan Wang, Tiejun Huang, Lu Sheng, Shanghang Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2506.04308)  

**Abstract**: Spatial referring is a fundamental capability of embodied robots to interact with the 3D physical world. However, even with the powerful pretrained vision language models (VLMs), recent approaches are still not qualified to accurately understand the complex 3D scenes and dynamically reason about the instruction-indicated locations for interaction. To this end, we propose RoboRefer, a 3D-aware VLM that can first achieve precise spatial understanding by integrating a disentangled but dedicated depth encoder via supervised fine-tuning (SFT). Moreover, RoboRefer advances generalized multi-step spatial reasoning via reinforcement fine-tuning (RFT), with metric-sensitive process reward functions tailored for spatial referring tasks. To support SFT and RFT training, we introduce RefSpatial, a large-scale dataset of 20M QA pairs (2x prior), covering 31 spatial relations (vs. 15 prior) and supporting complex reasoning processes (up to 5 steps). In addition, we introduce RefSpatial-Bench, a challenging benchmark filling the gap in evaluating spatial referring with multi-step reasoning. Experiments show that SFT-trained RoboRefer achieves state-of-the-art spatial understanding, with an average success rate of 89.6%. RFT-trained RoboRefer further outperforms all other baselines by a large margin, even surpassing Gemini-2.5-Pro by 17.4% in average accuracy on RefSpatial-Bench. Notably, RoboRefer can be integrated with various control policies to execute long-horizon, dynamic tasks across diverse robots (e,g., UR5, G1 humanoid) in cluttered real-world scenes. 

**Abstract (ZH)**: 基于三维空间感知的机器人空间引用方法 

---
# LLMs for sensory-motor control: Combining in-context and iterative learning 

**Title (ZH)**: 基于感知-运动控制的大语言模型：结合上下文学习和迭代学习 

**Authors**: Jônata Tyska Carvalho, Stefano Nolfi  

**Link**: [PDF](https://arxiv.org/pdf/2506.04867)  

**Abstract**: We propose a method that enables large language models (LLMs) to control embodied agents by directly mapping continuous observation vectors to continuous action vectors. Initially, the LLMs generate a control strategy based on a textual description of the agent, its environment, and the intended goal. This strategy is then iteratively refined through a learning process in which the LLMs are repeatedly prompted to improve the current strategy, using performance feedback and sensory-motor data collected during its evaluation. The method is validated on classic control tasks from the Gymnasium library and the inverted pendulum task from the MuJoCo library. In most cases, it successfully identifies optimal or high-performing solutions by integrating symbolic knowledge derived through reasoning with sub-symbolic sensory-motor data gathered as the agent interacts with its environment. 

**Abstract (ZH)**: 我们提出了一种方法，使大型语言模型（LLMs）能够通过直接将连续观察向量映射到连续动作向量来控制具身代理。初始阶段，LLMs基于对代理、其环境以及预期目标的文字描述生成控制策略。随后，通过反复提示LLMs改进当前策略并结合评价过程中收集的性能反馈和感觉运动数据，该策略被迭代优化。该方法在Gymnasium库的经典控制任务和MuJoCo库的倒立摆任务上得到了验证。在大多数情况下，该方法通过结合通过代理与其环境互动收集的子符号感觉运动数据推断出的符号知识，成功地识别出最优或高性能的解决方案。 

---
# "Don't Do That!": Guiding Embodied Systems through Large Language Model-based Constraint Generation 

**Title (ZH)**: “不要这么做！”：通过基于大型语言模型的约束生成引导具身系统 

**Authors**: Aladin Djuhera, Amin Seffo, Masataro Asai, Holger Boche  

**Link**: [PDF](https://arxiv.org/pdf/2506.04500)  

**Abstract**: Recent advancements in large language models (LLMs) have spurred interest in robotic navigation that incorporates complex spatial, mathematical, and conditional constraints from natural language into the planning problem. Such constraints can be informal yet highly complex, making it challenging to translate into a formal description that can be passed on to a planning algorithm. In this paper, we propose STPR, a constraint generation framework that uses LLMs to translate constraints (expressed as instructions on ``what not to do'') into executable Python functions. STPR leverages the LLM's strong coding capabilities to shift the problem description from language into structured and transparent code, thus circumventing complex reasoning and avoiding potential hallucinations. We show that these LLM-generated functions accurately describe even complex mathematical constraints, and apply them to point cloud representations with traditional search algorithms. Experiments in a simulated Gazebo environment show that STPR ensures full compliance across several constraints and scenarios, while having short runtimes. We also verify that STPR can be used with smaller, code-specific LLMs, making it applicable to a wide range of compact models at low inference cost. 

**Abstract (ZH)**: Recent advancements in大型语言模型（LLMs）促进了将复杂的空间、数学和条件约束从自然语言融入规划问题中的机器人导航研究。这类约束可能是非正式的但极其复杂，使它们难以转化为可以传递给规划算法的正式描述。本文提出STPR，一种利用大型语言模型生成约束的框架，将约束（以“不要做什么”的指令表达）转换为可执行的Python函数。STPR利用大型语言模型的强大编码能力，将问题描述从语言转换为结构化和透明的代码，从而绕过复杂的推理并避免潜在的幻觉。实验表明，这些由大型语言模型生成的函数能够准确描述复杂的数学约束，并应用于传统的搜索算法中。在Simulated Gazebo环境中的实验结果显示，STPR能够在多个约束和场景下确保完全合规，并且运行时间较短。我们还验证了STPR可以与较小的、代码特定的大型语言模型一起使用，使其适用于各种紧凑模型并具有较低的推理成本。 

---
# Energentic Intelligence: From Self-Sustaining Systems to Enduring Artificial Life 

**Title (ZH)**: 能量智能：从自 sustenance 系统到持久人工生命 

**Authors**: Atahan Karagoz  

**Link**: [PDF](https://arxiv.org/pdf/2506.04916)  

**Abstract**: This paper introduces Energentic Intelligence, a class of autonomous systems defined not by task performance, but by their capacity to sustain themselves through internal energy regulation. Departing from conventional reward-driven paradigms, these agents treat survival-maintaining functional operation under fluctuating energetic and thermal conditions-as the central objective. We formalize this principle through an energy-based utility function and a viability-constrained survival horizon, and propose a modular architecture that integrates energy harvesting, thermal regulation, and adaptive computation into a closed-loop control system. A simulated environment demonstrates the emergence of stable, resource-aware behavior without external supervision. Together, these contributions provide a theoretical and architectural foundation for deploying autonomous agents in resource-volatile settings where persistence must be self-regulated and infrastructure cannot be assumed. 

**Abstract (ZH)**: 基于能量智能的自主系统：一种通过内部能量调节维持自我可持续性的类自主系统的研究 

---
# Safe Planning and Policy Optimization via World Model Learning 

**Title (ZH)**: 基于世界模型学习的安全规划与策略优化 

**Authors**: Artem Latyshev, Gregory Gorbov, Aleksandr I. Panov  

**Link**: [PDF](https://arxiv.org/pdf/2506.04828)  

**Abstract**: Reinforcement Learning (RL) applications in real-world scenarios must prioritize safety and reliability, which impose strict constraints on agent behavior. Model-based RL leverages predictive world models for action planning and policy optimization, but inherent model inaccuracies can lead to catastrophic failures in safety-critical settings. We propose a novel model-based RL framework that jointly optimizes task performance and safety. To address world model errors, our method incorporates an adaptive mechanism that dynamically switches between model-based planning and direct policy execution. We resolve the objective mismatch problem of traditional model-based approaches using an implicit world model. Furthermore, our framework employs dynamic safety thresholds that adapt to the agent's evolving capabilities, consistently selecting actions that surpass safe policy suggestions in both performance and safety. Experiments demonstrate significant improvements over non-adaptive methods, showing that our approach optimizes safety and performance simultaneously rather than merely meeting minimum safety requirements. The proposed framework achieves robust performance on diverse safety-critical continuous control tasks, outperforming existing methods. 

**Abstract (ZH)**: 基于模型的强化学习框架在实际场景中的应用必须优先考虑安全性和可靠性，这对智能体的行为提出了严格约束。我们提出了一种新颖的基于模型的强化学习框架，联合优化任务性能和安全性。为解决世界模型的误差问题，我们的方法结合了动态切换机制，该机制能在基于模型的规划与直接策略执行之间动态切换。我们使用隐式世界模型解决传统基于模型方法的目标不匹配问题。此外，我们的框架采用动态安全阈值，能够适应智能体能力的演变，并始终选择在性能和安全性上都优于安全策略建议的动作。实验结果表明，我们的方法在同时优化安全性和性能方面显著优于非自适应方法，实现了在各种安全关键连续控制任务中的稳健性能，优于现有方法。 

---
# Direct Numerical Layout Generation for 3D Indoor Scene Synthesis via Spatial Reasoning 

**Title (ZH)**: 直接基于空间推理的3D室内场景合成布局生成 

**Authors**: Xingjian Ran, Yixuan Li, Linning Xu, Mulin Yu, Bo Dai  

**Link**: [PDF](https://arxiv.org/pdf/2506.05341)  

**Abstract**: Realistic 3D indoor scene synthesis is vital for embodied AI and digital content creation. It can be naturally divided into two subtasks: object generation and layout generation. While recent generative models have significantly advanced object-level quality and controllability, layout generation remains challenging due to limited datasets. Existing methods either overfit to these datasets or rely on predefined constraints to optimize numerical layout that sacrifice flexibility. As a result, they fail to generate scenes that are both open-vocabulary and aligned with fine-grained user instructions. We introduce DirectLayout, a framework that directly generates numerical 3D layouts from text descriptions using generalizable spatial reasoning of large language models (LLMs). DirectLayout decomposes the generation into three stages: producing a Bird's-Eye View (BEV) layout, lifting it into 3D space, and refining object placements. To enable explicit spatial reasoning and help the model grasp basic principles of object placement, we employ Chain-of-Thought (CoT) Activation based on the 3D-Front dataset. Additionally, we design CoT-Grounded Generative Layout Reward to enhance generalization and spatial planning. During inference, DirectLayout addresses asset-layout mismatches via Iterative Asset-Layout Alignment through in-context learning. Extensive experiments demonstrate that DirectLayout achieves impressive semantic consistency, generalization and physical plausibility. 

**Abstract (ZH)**: 现实istic 3D室内场景合成对于沉浸式AI和数字内容创作至关重要。它可以自然地分为两个子任务：对象生成和布局生成。尽管最近的生成模型在对象级的质量和可控性方面取得了显著进步，但由于数据集有限，布局生成仍然具有挑战性。现有方法要么过度拟合这些数据集，要么依赖预定义的约束来优化数值布局，牺牲了灵活性。因此，它们无法生成既符合宽泛词汇表又与精细用户指令对齐的场景。我们引入了DirectLayout框架，该框架直接使用大型语言模型（LLMs）的通用空间推理从文本描述生成数值3D布局。DirectLayout将生成过程分解为三个阶段：生成鸟瞰图（BEV）布局、将其提升到3D空间，并细化对象放置。为使空间推理显式化并帮助模型掌握对象放置的基本原则，我们基于3D-Front数据集使用Chain-of-Thought（CoT）激活。此外，我们设计了CoT-Grounded生成布局奖励，以增强泛化能力和空间规划。在推理过程中，DirectLayout通过上下文学习迭代资产-布局对齐来解决资产-布局不匹配问题。广泛的实验表明，DirectLayout实现了令人印象深刻的语义一致性、泛化能力和物理合理性。 

---
# Bridging the Performance Gap Between Target-Free and Target-Based Reinforcement Learning With Iterated Q-Learning 

**Title (ZH)**: 目标无关强化学习与目标导向强化学习之间性能差距的迭代Q学习桥接 

**Authors**: Théo Vincent, Yogesh Tripathi, Tim Faust, Yaniv Oren, Jan Peters, Carlo D'Eramo  

**Link**: [PDF](https://arxiv.org/pdf/2506.04398)  

**Abstract**: In value-based reinforcement learning, removing the target network is tempting as the boostrapped target would be built from up-to-date estimates, and the spared memory occupied by the target network could be reallocated to expand the capacity of the online network. However, eliminating the target network introduces instability, leading to a decline in performance. Removing the target network also means we cannot leverage the literature developed around target networks. In this work, we propose to use a copy of the last linear layer of the online network as a target network, while sharing the remaining parameters with the up-to-date online network, hence stepping out of the binary choice between target-based and target-free methods. It enables us to leverage the concept of iterated Q-learning, which consists of learning consecutive Bellman iterations in parallel, to reduce the performance gap between target-free and target-based approaches. Our findings demonstrate that this novel method, termed iterated Shared Q-Learning (iS-QL), improves the sample efficiency of target-free approaches across various settings. Importantly, iS-QL requires a smaller memory footprint and comparable training time to classical target-based algorithms, highlighting its potential to scale reinforcement learning research. 

**Abstract (ZH)**: 基于价值的强化学习中，移除目标网络令人向往，因为这样可以从最新的估计中构建增强的目标，从而释放出目标网络占用的内存并重新分配给在线网络以扩大其容量。然而，消除目标网络会带来不稳定性，导致性能下降。移除目标网络还意味着我们无法利用围绕目标网络发展的文献资料。在本工作中，我们提出了一种方法，即使用在线网络最后一层的副本作为目标网络，同时与最新的在线网络共享其余参数，从而走出基于目标和目标自由方法之间的二元选择。这种方法使我们能够利用迭代Q学习的概念，即并行学习连续的贝尔曼迭代，以减小目标自由和基于目标方法之间的性能差距。我们的研究表明，这种方法被称为迭代共享Q学习（iS-QL）能在各种设置中提高目标自由方法的样本效率。重要的是，iS-QL所需的内存占用更小，训练时间与经典基于目标的算法相当，突显了其在强化学习研究中的扩展潜力。 

---
