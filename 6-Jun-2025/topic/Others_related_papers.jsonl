{'arxiv_id': 'arXiv:2506.04881', 'title': 'Efficient Path Planning and Task Allocation Algorithm for Boolean Specifications', 'authors': 'Ioana Hustiu, Roozbeh Abolpour, Cristian Mahulea, Marius Kloetzer', 'link': 'https://arxiv.org/abs/2506.04881', 'abstract': 'This paper presents a novel path-planning and task assignment algorithm for multi-robot systems that should fulfill a global Boolean specification. The proposed method is based on Integer Linear Programming (ILP) formulations, which are combined with structural insights from Petri nets to improve scalability and computational efficiency. By proving that the \\emph{constraint matrix} is totally unimodular (TU) for certain classes of problems, the ILP formulation can be relaxed into a Linear Programming (LP) problem without losing the integrality of the solution. This relaxation eliminates complex combinatorial techniques, significantly reducing computational overhead and thus ensuring scalability for large-scale systems. Using the approach proposed in this paper, we can solve path-planning problems for teams made up to 500 robots. The method guarantees computational tractability, handles collision avoidance and reduces computational demands through iterative LP optimization techniques. Case studies demonstrate the efficiency of the algorithm in generating scalable, collision-free paths for large robot teams navigating in complex environments. While the conservative nature of collision avoidance introduces additional constraints, and thus, computational requirements, the solution remains practical and impactful for diverse applications. The algorithm is particularly applicable to real-world scenarios, including warehouse logistics where autonomous robots must efficiently coordinate tasks or search-and-rescue operations in various environments. This work contributes both theoretically and practically to scalable multi-robot path planning and task allocation, offering an efficient framework for coordinating autonomous agents in shared environments.', 'abstract_zh': '一种多机器人系统满足全局布尔规范的新型路径规划与任务分配算法', 'title_zh': '布尔规格化下的高效路径规划与任务分配算法'}
{'arxiv_id': 'arXiv:2506.04577', 'title': 'A Novel Transformer-Based Method for Full Lower-Limb Joint Angles and Moments Prediction in Gait Using sEMG and IMU data', 'authors': 'Farshad Haghgoo Daryakenari, Tara Farizeh', 'link': 'https://arxiv.org/abs/2506.04577', 'abstract': 'This study presents a transformer-based deep learning framework for the long-horizon prediction of full lower-limb joint angles and joint moments using surface electromyography (sEMG) and inertial measurement unit (IMU) signals. Two separate Transformer Neural Networks (TNNs) were designed: one for kinematic prediction and one for kinetic prediction. The model was developed with real-time application in mind, using only wearable sensors suitable for outside-laboratory use. Two prediction horizons were considered to evaluate short- and long-term performance. The network achieved high accuracy in both tasks, with Spearman correlation coefficients exceeding 0.96 and R-squared scores above 0.92 across all joints. Notably, the model consistently outperformed a recent benchmark method in joint angle prediction, reducing RMSE errors by an order of magnitude. The results confirmed the complementary role of sEMG and IMU signals in capturing both kinematic and kinetic information. This work demonstrates the potential of transformer-based models for real-time, full-limb biomechanical prediction in wearable and robotic applications, with future directions including input minimization and modality-specific weighting strategies to enhance model efficiency and accuracy.', 'abstract_zh': '基于变压器的深度学习框架在表面肌电图和惯性测量单元信号下的全下肢关节角度和关节力矩长时距预测', 'title_zh': '基于变压器的方法用于步态中下肢关节角度和力矩预测的新型数据融合技术（使用sEMG和IMU数据）'}
{'arxiv_id': 'arXiv:2506.04540', 'title': 'Chronoamperometry with Room-Temperature Ionic Liquids: Sub-Second Inference Techniques', 'authors': 'Kordel K. France', 'link': 'https://arxiv.org/abs/2506.04540', 'abstract': 'Chronoamperometry (CA) is a fundamental electrochemical technique used for quantifying redox-active species. However, in room-temperature ionic liquids (RTILs), the high viscosity and slow mass transport often lead to extended measurement durations. This paper presents a novel mathematical regression approach that reduces CA measurement windows to under 1 second, significantly faster than previously reported methods, which typically require 1-4 seconds or longer. By applying an inference algorithm to the initial transient current response, this method accurately predicts steady-state electrochemical parameters without requiring additional hardware modifications. The approach is validated through comparison with standard chronoamperometric techniques and is demonstrated to maintain reasonable accuracy while dramatically reducing data acquisition time. The implications of this technique are explored in analytical chemistry, sensor technology, and battery science, where rapid electrochemical quantification is critical. Our technique is focused on enabling faster multiplexing of chronoamperometric measurements for rapid olfactory and electrochemical analysis.', 'abstract_zh': 'chronoamperometry (CA)是一种用于定量测定氧化还原活性物种的基本电化学技术。然而，在室温离子液体（RTILs）中，高粘度和缓慢的质量传输往往导致测量时间延长。本文提出了一种新的数学回归方法，将CA测量窗口缩短至不足1秒，显著快于以往通常需要1-4秒或更长时间的方法。通过将推理算法应用于初始瞬态电流响应，该方法能够准确预测稳态电化学参数，无需额外的硬件修改。该方法通过与标准chronoamperometric技术进行比较得到了验证，并展示出可以在大幅减少数据采集时间的同时保持合理的准确性。该技术在分析化学、传感器技术和电池科学等领域具有重要意义，特别是在快速电化学定量分析中。本文方法侧重于实现更快的chronoamperometric测量的多路复用，以实现快速嗅觉和电化学分析。', 'title_zh': '室温离子液体介导的 chronoamperometry：亚秒级推断技术'}
{'arxiv_id': 'arXiv:2506.04362', 'title': 'Learning Smooth State-Dependent Traversability from Dense Point Clouds', 'authors': 'Zihao Dong, Alan Papalia, Leonard Jung, Alenna Spiro, Philip R. Osteen, Christa S. Robison, Michael Everett', 'link': 'https://arxiv.org/abs/2506.04362', 'abstract': "A key open challenge in off-road autonomy is that the traversability of terrain often depends on the vehicle's state. In particular, some obstacles are only traversable from some orientations. However, learning this interaction by encoding the angle of approach as a model input demands a large and diverse training dataset and is computationally inefficient during planning due to repeated model inference. To address these challenges, we present SPARTA, a method for estimating approach angle conditioned traversability from point clouds. Specifically, we impose geometric structure into our network by outputting a smooth analytical function over the 1-Sphere that predicts risk distribution for any angle of approach with minimal overhead and can be reused for subsequent queries. The function is composed of Fourier basis functions, which has important advantages for generalization due to their periodic nature and smoothness. We demonstrate SPARTA both in a high-fidelity simulation platform, where our model achieves a 91\\% success rate crossing a 40m boulder field (compared to 73\\% for the baseline), and on hardware, illustrating the generalization ability of the model to real-world settings.", 'abstract_zh': '户外自主驾驶中的一个关键开放挑战是地形的可通行性往往依赖于车辆的状态。特别地，一些障碍物仅从某些角度通过是可通行的。然而，通过将接近角度编码为模型输入来学习这种相互作用需要大量的多样化的训练数据集，并且在规划过程中由于重复的模型推断而计算效率低下。为了解决这些挑战，我们提出了一种基于点云估计条件通行角度的方法SPARTA。具体来说，我们通过输出在1-球体上连续的解析函数来在网络中嵌入几何结构，该函数可以预测任何接近角度的风险分布，并且具有极低的开销并且可以在后续查询中重用。该函数由傅里叶基函数组成，由于其周期性和平滑性，这对模型的泛化能力至关重要。我们在高保真仿真平台上展示了SPARTA，其中我们的模型在穿过40米石场时的成功率为91%（基线为73%），并在硬件上展示了模型在实际场景中的泛化能力。', 'title_zh': '从密集点云学习平滑状态依赖可通过性'}
{'arxiv_id': 'arXiv:2506.04399', 'title': 'Unsupervised Meta-Testing with Conditional Neural Processes for Hybrid Meta-Reinforcement Learning', 'authors': 'Suzan Ece Ada, Emre Ugur', 'link': 'https://arxiv.org/abs/2506.04399', 'abstract': 'We introduce Unsupervised Meta-Testing with Conditional Neural Processes (UMCNP), a novel hybrid few-shot meta-reinforcement learning (meta-RL) method that uniquely combines, yet distinctly separates, parameterized policy gradient-based (PPG) and task inference-based few-shot meta-RL. Tailored for settings where the reward signal is missing during meta-testing, our method increases sample efficiency without requiring additional samples in meta-training. UMCNP leverages the efficiency and scalability of Conditional Neural Processes (CNPs) to reduce the number of online interactions required in meta-testing. During meta-training, samples previously collected through PPG meta-RL are efficiently reused for learning task inference in an offline manner. UMCNP infers the latent representation of the transition dynamics model from a single test task rollout with unknown parameters. This approach allows us to generate rollouts for self-adaptation by interacting with the learned dynamics model. We demonstrate our method can adapt to an unseen test task using significantly fewer samples during meta-testing than the baselines in 2D-Point Agent and continuous control meta-RL benchmarks, namely, cartpole with unknown angle sensor bias, walker agent with randomized dynamics parameters.', 'abstract_zh': '无监督元测试条件神经过程（UMCNP）：一种新颖的混合少量样本元强化学习方法', 'title_zh': '基于条件神经过程的无监督元测试在混合元强化学习中的应用'}
{'arxiv_id': 'arXiv:2506.05296', 'title': 'Control Tax: The Price of Keeping AI in Check', 'authors': 'Mikhail Terekhov, Zhen Ning David Liu, Caglar Gulcehre, Samuel Albanie', 'link': 'https://arxiv.org/abs/2506.05296', 'abstract': 'The rapid integration of agentic AI into high-stakes real-world applications requires robust oversight mechanisms. The emerging field of AI Control (AIC) aims to provide such an oversight mechanism, but practical adoption depends heavily on implementation overhead. To study this problem better, we introduce the notion of Control tax -- the operational and financial cost of integrating control measures into AI pipelines. Our work makes three key contributions to the field of AIC: (1) we introduce a theoretical framework that quantifies the Control Tax and maps classifier performance to safety assurances; (2) we conduct comprehensive evaluations of state-of-the-art language models in adversarial settings, where attacker models insert subtle backdoors into code while monitoring models attempt to detect these vulnerabilities; and (3) we provide empirical financial cost estimates for control protocols and develop optimized monitoring strategies that balance safety and cost-effectiveness while accounting for practical constraints like auditing budgets. Our framework enables practitioners to make informed decisions by systematically connecting safety guarantees with their costs, advancing AIC through principled economic feasibility assessment across different deployment contexts.', 'abstract_zh': '高风险实际应用中代理AI的迅速集成需要 robust 监督机制。新兴的AI控制（AIC）领域旨在提供这种监督机制，但其实用采用取决于实施开销。为了更好地研究这一问题，我们引入了控制税的概念——将控制措施集成到AI管道中的运营和财务成本。我们的工作在AI控制领域做出了三项关键贡献：（1）我们引入了一个理论框架，量化了控制税，并将分类器性能与安全保证联系起来；（2）我们在对抗性环境中全面评估了最先进的语言模型，其中攻击模型在代码中插入隐蔽后门，而监控模型则试图检测这些漏洞；（3）我们提供了控制协议的实证财务成本估计，并开发了平衡安全性和成本效益的优化监控策略，同时考虑到审计预算等实际限制。我们的框架通过系统地将安全保证与其成本联系起来，使从业人员能够做出知情决策，并通过基础经济可行性评估推动AI控制在不同部署环境中的发展。', 'title_zh': '控制税：保持AI可控的代价'}
{'arxiv_id': 'arXiv:2506.05256', 'title': 'Just Enough Thinking: Efficient Reasoning with Adaptive Length Penalties Reinforcement Learning', 'authors': 'Violet Xiang, Chase Blagden, Rafael Rafailov, Nathan Lile, Sang Truong, Chelsea Finn, Nick Haber', 'link': 'https://arxiv.org/abs/2506.05256', 'abstract': "Large reasoning models (LRMs) achieve higher performance on challenging reasoning tasks by generating more tokens at inference time, but this verbosity often wastes computation on easy problems. Existing solutions, including supervised finetuning on shorter traces, user-controlled budgets, or RL with uniform penalties, either require data curation, manual configuration, or treat all problems alike regardless of difficulty. We introduce Adaptive Length Penalty (ALP), a reinforcement learning objective tailoring generation length to per-prompt solve rate. During training, ALP monitors each prompt's online solve rate through multiple rollouts and adds a differentiable penalty whose magnitude scales inversely with that rate, so confident (easy) prompts incur a high cost for extra tokens while hard prompts remain unhindered. Posttraining DeepScaleR-1.5B with ALP cuts average token usage by 50\\% without significantly dropping performance. Relative to fixed-budget and uniform penalty baselines, ALP redistributes its reduced budget more intelligently by cutting compute on easy prompts and reallocating saved tokens to difficult ones, delivering higher accuracy on the hardest problems with higher cost.", 'abstract_zh': '自适应长度惩罚（ALP）：一种根据提示解决率调整生成长度的强化学习目标', 'title_zh': '恰到好处的思考：具有自适应长度惩罚的 reinforcement learning 有效推理'}
{'arxiv_id': 'arXiv:2506.05109', 'title': 'Truly Self-Improving Agents Require Intrinsic Metacognitive Learning', 'authors': 'Tennison Liu, Mihaela van der Schaar', 'link': 'https://arxiv.org/abs/2506.05109', 'abstract': "Self-improving agents aim to continuously acquire new capabilities with minimal supervision. However, current approaches face two key limitations: their self-improvement processes are often rigid, fail to generalize across tasks domains, and struggle to scale with increasing agent capabilities. We argue that effective self-improvement requires intrinsic metacognitive learning, defined as an agent's intrinsic ability to actively evaluate, reflect on, and adapt its own learning processes. Drawing inspiration from human metacognition, we introduce a formal framework comprising three components: metacognitive knowledge (self-assessment of capabilities, tasks, and learning strategies), metacognitive planning (deciding what and how to learn), and metacognitive evaluation (reflecting on learning experiences to improve future learning). Analyzing existing self-improving agents, we find they rely predominantly on extrinsic metacognitive mechanisms, which are fixed, human-designed loops that limit scalability and adaptability. Examining each component, we contend that many ingredients for intrinsic metacognition are already present. Finally, we explore how to optimally distribute metacognitive responsibilities between humans and agents, and robustly evaluate and improve intrinsic metacognitive learning, key challenges that must be addressed to enable truly sustained, generalized, and aligned self-improvement.", 'abstract_zh': '自我提升代理旨在在最少监督的情况下持续获取新能力。然而，当前的方法面临两大关键限制：其自我提升过程往往僵化，无法跨任务领域泛化，并且难以随着代理能力的增强而扩展。我们主张有效的自我提升需要内在元认知学习，定义为代理内在地主动评估、反思和适应自身学习过程的能力。借鉴人类元认知，我们引入了一个正式框架，包括三个组成部分：元认知知识（自我评估能力、任务和学习策略）、元认知规划（决定学什么和如何学习）以及元认知评估（反思学习经历以改进未来学习）。分析现有的自我提升代理，我们发现它们主要依赖外在元认知机制，这些机制是固定的、由人类设计的循环，限制了可扩展性和适应性。逐一考察每个组成部分，我们认为许多内在元认知的成分已经存在。最后，我们探讨如何在人类和代理之间优化元认知责任的分配，并稳健地评估和改进内在元认知学习，这些都是为了实现真正持续、泛化和对齐的自我提升所必须解决的关键挑战。', 'title_zh': '真正自适应改进的智能代理需要内在元认知学习'}
{'arxiv_id': 'arXiv:2506.04912', 'title': 'Differentiable Logic Cellular Automata: From Game of Life to Pattern Generation', 'authors': 'Pietro Miotti, Eyvind Niklasson, Ettore Randazzo, Alexander Mordvintsev', 'link': 'https://arxiv.org/abs/2506.04912', 'abstract': "This paper introduces Differentiable Logic Cellular Automata (DiffLogic CA), a novel combination of Neural Cellular Automata (NCA) and Differentiable Logic Gates Networks (DLGNs). The fundamental computation units of the model are differentiable logic gates, combined into a circuit. During training, the model is fully end-to-end differentiable allowing gradient-based training, and at inference time it operates in a fully discrete state space. This enables learning local update rules for cellular automata while preserving their inherent discrete nature. We demonstrate the versatility of our approach through a series of milestones: (1) fully learning the rules of Conway's Game of Life, (2) generating checkerboard patterns that exhibit resilience to noise and damage, (3) growing a lizard shape, and (4) multi-color pattern generation. Our model successfully learns recurrent circuits capable of generating desired target patterns. For simpler patterns, we observe success with both synchronous and asynchronous updates, demonstrating significant generalization capabilities and robustness to perturbations. We make the case that this combination of DLGNs and NCA represents a step toward programmable matter and robust computing systems that combine binary logic, neural network adaptability, and localized processing. This work, to the best of our knowledge, is the first successful application of differentiable logic gate networks in recurrent architectures.", 'abstract_zh': '不同可微逻辑细胞自动机（DiffLogic CA）：神经细胞自动机与可微逻辑门网络的结合', 'title_zh': '可微逻辑细胞自动机：从游戏 of-life 到模式生成'}
{'arxiv_id': 'arXiv:2506.04849', 'title': 'Towards a Multi-Agent Simulation of Cyber-attackers and Cyber-defenders Battles', 'authors': 'Julien Soulé, Jean-Paul Jamont, Michel Occello, Paul Théron, Louis-Marie Traonouez', 'link': 'https://arxiv.org/abs/2506.04849', 'abstract': "As cyber-attacks show to be more and more complex and coordinated, cyber-defenders strategy through multi-agent approaches could be key to tackle against cyber-attacks as close as entry points in a networked system. This paper presents a Markovian modeling and implementation through a simulator of fighting cyber-attacker agents and cyber-defender agents deployed on host network nodes. It aims to provide an experimental framework to implement realistically based coordinated cyber-attack scenarios while assessing cyber-defenders dynamic organizations. We abstracted network nodes by sets of properties including agents' ones. Actions applied by agents model how the network reacts depending in a given state and what properties are to change. Collective choice of the actions brings the whole environment closer or farther from respective cyber-attackers and cyber-defenders goals. Using the simulator, we implemented a realistically inspired scenario with several behavior implementation approaches for cyber-defenders and cyber-attackers.", 'abstract_zh': '随着网络攻击变得更加复杂和协调，通过多智能体方法的网络防御策略可能是应对网络攻击的关键。本文通过模拟器呈现一种马尔可夫模型和实现方法，用于部署在网络节点上的网络攻击者智能体和网络防御者智能体的对抗。该研究旨在提供一个基于实际的实验框架，实施协同网络攻击场景，同时评估网络防御者的动态组织。我们将网络节点抽象为包括智能体属性在内的集合。智能体执行的动作模型了网络在给定状态下如何响应，以及哪些属性会发生变化。智能体集体选择的行动使整个环境更接近或远离网络攻击者和网络防御者的目标。通过模拟器，我们实施了一个受真实场景启发的场景，并采用了几种网络防御者和网络攻击者的行为实现方法。', 'title_zh': '向多agent仿真网络攻击者与网络防御者战斗的研究'}
{'arxiv_id': 'arXiv:2506.04756', 'title': 'Ontology-based knowledge representation for bone disease diagnosis: a foundation for safe and sustainable medical artificial intelligence systems', 'authors': 'Loan Dao, Ngoc Quoc Ly', 'link': 'https://arxiv.org/abs/2506.04756', 'abstract': 'Medical artificial intelligence (AI) systems frequently lack systematic domain expertise integration, potentially compromising diagnostic reliability. This study presents an ontology-based framework for bone disease diagnosis, developed in collaboration with Ho Chi Minh City Hospital for Traumatology and Orthopedics. The framework introduces three theoretical contributions: (1) a hierarchical neural network architecture guided by bone disease ontology for segmentation-classification tasks, incorporating Visual Language Models (VLMs) through prompts, (2) an ontology-enhanced Visual Question Answering (VQA) system for clinical reasoning, and (3) a multimodal deep learning model that integrates imaging, clinical, and laboratory data through ontological relationships. The methodology maintains clinical interpretability through systematic knowledge digitization, standardized medical terminology mapping, and modular architecture design. The framework demonstrates potential for extension beyond bone diseases through its standardized structure and reusable components. While theoretical foundations are established, experimental validation remains pending due to current dataset and computational resource limitations. Future work will focus on expanding the clinical dataset and conducting comprehensive system validation.', 'abstract_zh': '基于本体的骨疾病诊断医疗人工智能系统研究', 'title_zh': '基于本体的知识表示在骨疾病诊断中的应用：安全可持续医疗人工智能系统的基石'}
{'arxiv_id': 'arXiv:2506.04636', 'title': 'CHANCERY: Evaluating corporate governance reasoning capabilities in language models', 'authors': 'Lucas Irwin, Arda Kaz, Peiyao Sheng, Pramod Viswanath', 'link': 'https://arxiv.org/abs/2506.04636', 'abstract': "Law has long been a domain that has been popular in natural language processing (NLP) applications. Reasoning (ratiocination and the ability to make connections to precedent) is a core part of the practice of the law in the real world. Nevertheless, while multiple legal datasets exist, none have thus far focused specifically on reasoning tasks. We focus on a specific aspect of the legal landscape by introducing a corporate governance reasoning benchmark (CHANCERY) to test a model's ability to reason about whether executive/board/shareholder's proposed actions are consistent with corporate governance charters. This benchmark introduces a first-of-its-kind corporate governance reasoning test for language models - modeled after real world corporate governance law. The benchmark consists of a corporate charter (a set of governing covenants) and a proposal for executive action. The model's task is one of binary classification: reason about whether the action is consistent with the rules contained within the charter. We create the benchmark following established principles of corporate governance - 24 concrete corporate governance principles established in and 79 real life corporate charters selected to represent diverse industries from a total dataset of 10k real life corporate charters. Evaluations on state-of-the-art (SOTA) reasoning models confirm the difficulty of the benchmark, with models such as Claude 3.7 Sonnet and GPT-4o achieving 64.5% and 75.2% accuracy respectively. Reasoning agents exhibit superior performance, with agents based on the ReAct and CodeAct frameworks scoring 76.1% and 78.1% respectively, further confirming the advanced legal reasoning capabilities required to score highly on the benchmark. We also conduct an analysis of the types of questions which current reasoning models struggle on, revealing insights into the legal reasoning capabilities of SOTA models.", 'abstract_zh': '法律一直是自然语言处理（NLP）应用中流行的研究领域。推理（推理和建立先例联系的能力）是现实世界法律实践中核心的部分。尽管存在多个法律数据集，但至今为止，没有一个专门针对推理任务的数据集。我们通过引入一个公司治理推理基准（CHANCERY），专注于法律环境中的特定方面，以测试模型推理公司治理章程中股东/董事会提议行动是否与其一致的能力。这一基准为语言模型引入了首款基于现实世界公司治理法的推理测试。该基准包括公司章程（一系列治理契约）和执行行动提案。模型的任务是一项二元分类任务：判断行动是否符合章程中包含的规则。我们按照确立的公司治理原则创建了基准——24项具体的公司治理原则和79份反映不同行业的现实生活中公司章程，从总共10,000份现实生活中公司章程中选择。对最先进的推理模型的评估证实了基准的难度，如Claude 3.7 Sonnet和GPT-4o分别达到64.5%和75.2%的准确率。推理代理展示了优越的性能，基于ReAct和CodeAct框架的代理分别达到76.1%和78.1%，进一步证实了在基准上获得高分所需的高级法律推理能力。我们还对当前推理模型难以回答的问题类型进行了分析，揭示了SOTA模型法律推理能力的洞察。', 'title_zh': '商院：评估语言模型在企业治理推理能力方面的能力'}
{'arxiv_id': 'arXiv:2506.04614', 'title': 'Look Before You Leap: A GUI-Critic-R1 Model for Pre-Operative Error Diagnosis in GUI Automation', 'authors': 'Yuyang Wanyan, Xi Zhang, Haiyang Xu, Haowei Liu, Junyang Wang, Jiabo Ye, Yutong Kou, Ming Yan, Fei Huang, Xiaoshan Yang, Weiming Dong, Changsheng Xu', 'link': 'https://arxiv.org/abs/2506.04614', 'abstract': "In recent years, Multimodal Large Language Models (MLLMs) have been extensively utilized for multimodal reasoning tasks, including Graphical User Interface (GUI) automation. Unlike general offline multimodal tasks, GUI automation is executed in online interactive environments, necessitating step-by-step decision-making based on real-time status of the environment. This task has a lower tolerance for decision-making errors at each step, as any mistakes may cumulatively disrupt the process and potentially lead to irreversible outcomes like deletions or payments. To address these issues, we introduce a pre-operative critic mechanism that provides effective feedback prior to the actual execution, by reasoning about the potential outcome and correctness of actions. Specifically, we propose a Suggestion-aware Gradient Relative Policy Optimization (S-GRPO) strategy to construct our pre-operative critic model GUI-Critic-R1, incorporating a novel suggestion reward to enhance the reliability of the model's feedback. Furthermore, we develop a reasoning-bootstrapping based data collection pipeline to create a GUI-Critic-Train and a GUI-Critic-Test, filling existing gaps in GUI critic data. Static experiments on the GUI-Critic-Test across both mobile and web domains reveal that our GUI-Critic-R1 offers significant advantages in critic accuracy compared to current MLLMs. Dynamic evaluation on GUI automation benchmark further highlights the effectiveness and superiority of our model, as evidenced by improved success rates and operational efficiency.", 'abstract_zh': '近年来，多模态大型语言模型（MLLMs）被广泛应用于包括图形用户界面（GUI）自动化在内的多模态推理任务中。不同于一般的离线多模态任务，GUI自动化是在在线交互环境中执行的，要求基于环境的实时状态进行逐步决策。这一任务对于每一步的决策错误容忍度较低，任何错误都有可能累计破坏过程，并可能导致无法逆转的结果，如删除或支付错误。为解决这些问题，我们引入了一种预操作批评机制，在实际执行前提供有效的反馈，通过推理潜在结果和行动的正确性来实现。具体来说，我们提出了一种感知建议的梯度相对策略优化（S-GRPO）策略来构建预操作批评模型GUI-Critic-R1，并引入了一种新的建议奖励，以增强模型反馈的可靠性。此外，我们开发了一种基于推理自我提升的数据采集管道，创建了GUI-Critic-Train和GUI-Critic-Test，填补了现有GUI批评数据的空白。在GUI-Critic-Test的静态实验中，无论是移动设备还是Web领域，均显示我们的GUI-Critic-R1在批评准确性方面较当前的MLLMs具有显著优势。进一步在GUI自动化基准上的动态评估也凸显了我们的模型的有效性和优越性，表现为成功率和操作效率的提高。', 'title_zh': '前瞻而后行：一种GUI-Critic-R1模型用于GUI自动化预手术错误诊断'}
{'arxiv_id': 'arXiv:2506.04613', 'title': 'DeePoly: A High-Order Accuracy and Efficiency Deep-Polynomial Framework for Scientific Machine Learning', 'authors': 'Li Liu, Heng Yong', 'link': 'https://arxiv.org/abs/2506.04613', 'abstract': 'Recently, machine learning methods have gained significant traction in scientific computing, particularly for solving Partial Differential Equations (PDEs). However, methods based on deep neural networks (DNNs) often lack convergence guarantees and computational efficiency compared to traditional numerical schemes. This work introduces DeePoly, a novel framework that transforms the solution paradigm from pure non-convex parameter optimization to a two-stage approach: first employing a DNN to capture complex global features, followed by linear space optimization with combined DNN-extracted features (Scoper) and polynomial basis functions (Sniper). This strategic combination leverages the complementary strengths of both methods -- DNNs excel at approximating complex global features (i.e., high-gradient features) and stabilize the polynomial approximation while polynomial bases provide high-precision local corrections with convergence guarantees. Theoretical analysis and numerical experiments demonstrate that this approach significantly enhances both high-order accuracy and efficiency across diverse problem types while maintaining mesh-free and scheme-free properties. This paper also serves as a theoretical exposition for the open-source project DeePoly.', 'abstract_zh': '最近，机器学习方法在科学计算中得到了显著发展，尤其是在求解偏微分方程（PDEs）方面。然而，基于深度神经网络（DNNs）的方法在收敛性和计算效率上往往不如传统数值方案。本文介绍了一种名为DeePoly的新框架，将求解范式从纯粹的非凸参数优化转变为两阶段方法：首先使用DNN捕获复杂的全局特征，然后通过Scoper（结合DNN提取特征和多项式基函数）和Sniper（多项式基函数）进行线性空间优化。这种策略性组合利用了两种方法的互补优势——DNN在近似复杂全局特征（如高梯度特征）和稳定多项式逼近方面表现出色，而多项式基函数提供高精度的局部修正，并具有收敛性保证。理论分析和数值实验表明，这种方法显著提高了各类问题的高阶精度和效率，同时保持了无网格和无方案依赖性。本文还对开源项目DeePoly进行了理论阐述。', 'title_zh': 'DeePoly: 一种高阶精度和效率的科学机器学习深多项式框架'}
{'arxiv_id': 'arXiv:2506.04610', 'title': 'Judicial Permission', 'authors': 'Guido Governatori, Antonino Rotolo', 'link': 'https://arxiv.org/abs/2506.04610', 'abstract': 'This paper examines the significance of weak permissions in criminal trials (\\emph{judicial permission}). It introduces a dialogue game model to systematically address judicial permissions, considering different standards of proof and argumentation semantics.', 'abstract_zh': '本文探讨了弱权限在刑事审判（司法许可）中的重要性。引入对话博弈模型，系统地处理司法权限问题，考虑不同的证明标准和论辩语义。', 'title_zh': '司法许可'}
{'arxiv_id': 'arXiv:2506.04571', 'title': 'OpenAg: Democratizing Agricultural Intelligence', 'authors': 'Srikanth Thudumu, Jason Fisher', 'link': 'https://arxiv.org/abs/2506.04571', 'abstract': 'Agriculture is undergoing a major transformation driven by artificial intelligence (AI), machine learning, and knowledge representation technologies. However, current agricultural intelligence systems often lack contextual understanding, explainability, and adaptability, especially for smallholder farmers with limited resources. General-purpose large language models (LLMs), while powerful, typically lack the domain-specific knowledge and contextual reasoning needed for practical decision support in farming. They tend to produce recommendations that are too generic or unrealistic for real-world applications. To address these challenges, we present OpenAg, a comprehensive framework designed to advance agricultural artificial general intelligence (AGI). OpenAg combines domain-specific foundation models, neural knowledge graphs, multi-agent reasoning, causal explainability, and adaptive transfer learning to deliver context-aware, explainable, and actionable insights. The system includes: (i) a unified agricultural knowledge base that integrates scientific literature, sensor data, and farmer-generated knowledge; (ii) a neural agricultural knowledge graph for structured reasoning and inference; (iii) an adaptive multi-agent reasoning system where AI agents specialize and collaborate across agricultural domains; and (iv) a causal transparency mechanism that ensures AI recommendations are interpretable, scientifically grounded, and aligned with real-world constraints. OpenAg aims to bridge the gap between scientific knowledge and the tacit expertise of experienced farmers to support scalable and locally relevant agricultural decision-making.', 'abstract_zh': '农业正经历由人工智能（AI）、机器学习和知识表示技术推动的重大转型。然而，当前的农业智能系统往往缺乏上下文理解、可解释性和适应性，尤其对于资源有限的小规模农户。通用的大规模语言模型（LLMs），虽然强大，通常缺乏在农业领域中进行实际决策支持所需的特定领域知识和上下文推理能力。它们倾向于提出过于通用或不切实际的建议。为应对这些挑战，我们提出了OpenAg，一个旨在推进农业通用人工智能（AGI）的综合框架。OpenAg将领域特定的基础模型、神经知识图谱、多智能体推理、因果可解释性和自适应迁移学习相结合，以提供上下文感知、可解释且可操作的见解。该系统包括：（i）一个统一的农业知识库，整合了科学文献、传感器数据和农民生成的知识；（ii）一个神经农业知识图谱，用于结构化推理和推断；（iii）一个自适应的多智能体推理系统，其中AI代理在农业领域内专业化并协同工作；（iv）一个因果透明机制，确保AI建议具有可解释性、科学依据，并与现实世界约束条件相一致。OpenAg旨在弥合科学知识与经验农民隐性专长之间的差距，以支持可扩展且地域相关的农业决策。', 'title_zh': 'OpenAg: 民主化农业智能'}
{'arxiv_id': 'arXiv:2506.04429', 'title': 'An AI-Based Public Health Data Monitoring System', 'authors': 'Ananya Joshi, Nolan Gormley, Richa Gadgil, Tina Townes, Roni Rosenfeld, Bryan Wilder', 'link': 'https://arxiv.org/abs/2506.04429', 'abstract': 'Public health experts need scalable approaches to monitor large volumes of health data (e.g., cases, hospitalizations, deaths) for outbreaks or data quality issues. Traditional alert-based monitoring systems struggle with modern public health data monitoring systems for several reasons, including that alerting thresholds need to be constantly reset and the data volumes may cause application lag. Instead, we propose a ranking-based monitoring paradigm that leverages new AI anomaly detection methods. Through a multi-year interdisciplinary collaboration, the resulting system has been deployed at a national organization to monitor up to 5,000,000 data points daily. A three-month longitudinal deployed evaluation revealed a significant improvement in monitoring objectives, with a 54x increase in reviewer speed efficiency compared to traditional alert-based methods. This work highlights the potential of human-centered AI to transform public health decision-making.', 'abstract_zh': '公共卫生专家需要针对大规模健康数据开发可拓展的方法以监测疫情或数据质量问题。传统基于警报的监测系统因警报阈值需要不断调整且数据量可能引起应用程序滞后等原因，在现代公共卫生数据监测中面临挑战。相反，我们提出了一种基于排名的监测范式，利用新型AI异常检测方法。通过多年跨学科合作，该系统已在国家级机构部署，每日监测高达5,000,000个数据点。三个月的纵向部署评估显示，与传统基于警报的方法相比，监测效率提高了54倍。这项工作突显了以人为中心的AI在革新公共卫生决策方面的潜力。', 'title_zh': '基于AI的公共卫生数据分析监测系统'}
{'arxiv_id': 'arXiv:2506.04410', 'title': 'Matter-of-Fact: A Benchmark for Verifying the Feasibility of Literature-Supported Claims in Materials Science', 'authors': 'Peter Jansen, Samiah Hassan, Ruoyao Wang', 'link': 'https://arxiv.org/abs/2506.04410', 'abstract': 'Contemporary approaches to assisted scientific discovery use language models to automatically generate large numbers of potential hypothesis to test, while also automatically generating code-based experiments to test those hypotheses. While hypotheses can be comparatively inexpensive to generate, automated experiments can be costly, particularly when run at scale (i.e. thousands of experiments). Developing the capacity to filter hypotheses based on their feasibility would allow discovery systems to run at scale, while increasing their likelihood of making significant discoveries. In this work we introduce Matter-of-Fact, a challenge dataset for determining the feasibility of hypotheses framed as claims. Matter-of-Fact includes 8.4k claims extracted from scientific articles spanning four high-impact contemporary materials science topics, including superconductors, semiconductors, batteries, and aerospace materials, while including qualitative and quantitative claims from theoretical, experimental, and code/simulation results. We show that strong baselines that include retrieval augmented generation over scientific literature and code generation fail to exceed 72% performance on this task (chance performance is 50%), while domain-expert verification suggests nearly all are solvable -- highlighting both the difficulty of this task for current models, and the potential to accelerate scientific discovery by making near-term progress.', 'abstract_zh': '基于事实的假设可行性挑战数据集：加速科学发现能力研究', 'title_zh': '事实在眼前：材料科学中基于文献声明可行性的基准测试'}
{'arxiv_id': 'arXiv:2506.04244', 'title': 'Zero-Shot Adaptation of Parameter-Efficient Fine-Tuning in Diffusion Models', 'authors': 'Farzad Farhadzadeh, Debasmit Das, Shubhankar Borse, Fatih Porikli', 'link': 'https://arxiv.org/abs/2506.04244', 'abstract': "We introduce ProLoRA, enabling zero-shot adaptation of parameter-efficient fine-tuning in text-to-image diffusion models. ProLoRA transfers pre-trained low-rank adjustments (e.g., LoRA) from a source to a target model without additional training data. This overcomes the limitations of traditional methods that require retraining when switching base models, often challenging due to data constraints. ProLoRA achieves this via projection of source adjustments into the target model's weight space, leveraging subspace and null space similarities and selectively targeting aligned layers. Evaluations on established text-to-image models demonstrate successful knowledge transfer and comparable performance without retraining.", 'abstract_zh': 'ProLoRA:使参数高效微调在文本到图像扩散模型中零样本适应成为可能', 'title_zh': '参数高效的零样本适应在扩散模型中的应用'}
{'arxiv_id': 'arXiv:2506.05340', 'title': 'Exploring Diffusion Transformer Designs via Grafting', 'authors': 'Keshigeyan Chandrasegaran, Michael Poli, Daniel Y. Fu, Dongjun Kim, Lea M. Hadzic, Manling Li, Agrim Gupta, Stefano Massaroli, Azalia Mirhoseini, Juan Carlos Niebles, Stefano Ermon, Li Fei-Fei', 'link': 'https://arxiv.org/abs/2506.05340', 'abstract': 'Designing model architectures requires decisions such as selecting operators (e.g., attention, convolution) and configurations (e.g., depth, width). However, evaluating the impact of these decisions on model quality requires costly pretraining, limiting architectural investigation. Inspired by how new software is built on existing code, we ask: can new architecture designs be studied using pretrained models? To this end, we present grafting, a simple approach for editing pretrained diffusion transformers (DiTs) to materialize new architectures under small compute budgets. Informed by our analysis of activation behavior and attention locality, we construct a testbed based on the DiT-XL/2 design to study the impact of grafting on model quality. Using this testbed, we develop a family of hybrid designs via grafting: replacing softmax attention with gated convolution, local attention, and linear attention, and replacing MLPs with variable expansion ratio and convolutional variants. Notably, many hybrid designs achieve good quality (FID: 2.38-2.64 vs. 2.27 for DiT-XL/2) using <2% pretraining compute. We then graft a text-to-image model (PixArt-Sigma), achieving a 1.43x speedup with less than a 2% drop in GenEval score. Finally, we present a case study that restructures DiT-XL/2 by converting every pair of sequential transformer blocks into parallel blocks via grafting. This reduces model depth by 2x and yields better quality (FID: 2.77) than other models of comparable depth. Together, we show that new diffusion model designs can be explored by grafting pretrained DiTs, with edits ranging from operator replacement to architecture restructuring. Code and grafted models: this https URL', 'abstract_zh': '预训练模型设计的新架构研究： grafting 方法探索', 'title_zh': '通过嫁接探索扩散变压器设计'}
{'arxiv_id': 'arXiv:2506.05281', 'title': 'Fast-DataShapley: Neural Modeling for Training Data Valuation', 'authors': 'Haifeng Sun, Yu Xiong, Runze Wu, Xinyu Cai, Changjie Fan, Lan Zhang, Xiang-Yang Li', 'link': 'https://arxiv.org/abs/2506.05281', 'abstract': "The value and copyright of training data are crucial in the artificial intelligence industry. Service platforms should protect data providers' legitimate rights and fairly reward them for their contributions. Shapley value, a potent tool for evaluating contributions, outperforms other methods in theory, but its computational overhead escalates exponentially with the number of data providers. Recent works based on Shapley values attempt to mitigate computation complexity by approximation algorithms. However, they need to retrain for each test sample, leading to intolerable costs. We propose Fast-DataShapley, a one-pass training method that leverages the weighted least squares characterization of the Shapley value to train a reusable explainer model with real-time reasoning speed. Given new test samples, no retraining is required to calculate the Shapley values of the training data. Additionally, we propose three methods with theoretical guarantees to reduce training overhead from two aspects: the approximate calculation of the utility function and the group calculation of the training data. We analyze time complexity to show the efficiency of our methods. The experimental evaluations on various image datasets demonstrate superior performance and efficiency compared to baselines. Specifically, the performance is improved to more than 2.5 times, and the explainer's training speed can be increased by two orders of magnitude.", 'abstract_zh': '训练数据的价值和版权在人工智能行业中至关重要。服务平台应保护数据提供者的合法权益，并公平地奖励他们的贡献。Shapley值作为评估贡献的强大工具，在理论上优于其他方法，但其计算开销随数据提供者数量的增加呈指数级上升。基于Shapley值的近期研究试图通过近似算法减轻计算复杂性，但它们需要为每个测试样本重新训练，导致不可接受的成本。我们提出Fast-DataShapley，这是一种一次训练方法，通过利用Shapley值的加权最小二乘表示来训练一个可重用的解释模型，并具备实时推理速度。对于新的测试样本，无需重新训练即可计算训练数据的Shapley值。此外，我们提出三种具有理论保证的方法，从两个方面减少训练开销：近似计算效用函数和批量计算训练数据。我们通过时间复杂度分析展示了方法的效率。在多种图像数据集上的实验评估表明，与基准方法相比，我们的方法在性能和效率方面都更优。具体而言，性能提高了2.5倍以上，解释器的训练速度提高了两个数量级。', 'title_zh': 'Fast-DataShapley: 基于神经网络的训练数据价值评估模型'}
{'arxiv_id': 'arXiv:2506.05233', 'title': 'MesaNet: Sequence Modeling by Locally Optimal Test-Time Training', 'authors': 'Johannes von Oswald, Nino Scherrer, Seijin Kobayashi, Luca Versari, Songlin Yang, Maximilian Schlegel, Kaitlin Maile, Yanick Schimpf, Oliver Sieberling, Alexander Meulemans, Rif A. Saurous, Guillaume Lajoie, Charlotte Frenkel, Razvan Pascanu, Blaise Agüera y Arcas, João Sacramento', 'link': 'https://arxiv.org/abs/2506.05233', 'abstract': 'Sequence modeling is currently dominated by causal transformer architectures that use softmax self-attention. Although widely adopted, transformers require scaling memory and compute linearly during inference. A recent stream of work linearized the softmax operation, resulting in powerful recurrent neural network (RNN) models with constant memory and compute costs such as DeltaNet, Mamba or xLSTM. These models can be unified by noting that their recurrent layer dynamics can all be derived from an in-context regression objective, approximately optimized through an online learning rule. Here, we join this line of work and introduce a numerically stable, chunkwise parallelizable version of the recently proposed Mesa layer (von Oswald et al., 2024), and study it in language modeling at the billion-parameter scale. This layer again stems from an in-context loss, but which is now minimized to optimality at every time point using a fast conjugate gradient solver. Through an extensive suite of experiments, we show that optimal test-time training enables reaching lower language modeling perplexity and higher downstream benchmark performance than previous RNNs, especially on tasks requiring long context understanding. This performance gain comes at the cost of additional flops spent during inference time. Our results are therefore intriguingly related to recent trends of increasing test-time compute to improve performance -- here by spending compute to solve sequential optimization problems within the neural network itself.', 'abstract_zh': '基于上下文回归目标驱动的数值稳定且可分块并行的Mesa层在大规模语言模型中的研究', 'title_zh': 'MesaNet：本地最优测试时训练的序列建模'}
{'arxiv_id': 'arXiv:2506.05214', 'title': 'Mitigating Degree Bias Adaptively with Hard-to-Learn Nodes in Graph Contrastive Learning', 'authors': 'Jingyu Hu, Hongbo Bo, Jun Hong, Xiaowei Liu, Weiru Liu', 'link': 'https://arxiv.org/abs/2506.05214', 'abstract': 'Graph Neural Networks (GNNs) often suffer from degree bias in node classification tasks, where prediction performance varies across nodes with different degrees. Several approaches, which adopt Graph Contrastive Learning (GCL), have been proposed to mitigate this bias. However, the limited number of positive pairs and the equal weighting of all positives and negatives in GCL still lead to low-degree nodes acquiring insufficient and noisy information. This paper proposes the Hardness Adaptive Reweighted (HAR) contrastive loss to mitigate degree bias. It adds more positive pairs by leveraging node labels and adaptively weights positive and negative pairs based on their learning hardness. In addition, we develop an experimental framework named SHARP to extend HAR to a broader range of scenarios. Both our theoretical analysis and experiments validate the effectiveness of SHARP. The experimental results across four datasets show that SHARP achieves better performance against baselines at both global and degree levels.', 'abstract_zh': 'Graph神经网络（GNNs）在节点分类任务中常常遭受度偏差的问题，其中预测性能在具有不同度的节点之间有所不同。已经提出了几种采用图对比学习（GCL）的方法来缓解这种偏差。然而，GCL中正样本对数量有限且正负样本等权重分配仍然导致低度节点获得不足且噪声较大的信息。本文提出了一种适应难度加权（HAR）对比损失，通过利用节点标签增加了更多的正样本对，并根据正负样本的学习难度自适应地分配权重。此外，我们开发了一个命名为SHARP的实验框架，将HAR扩展到更广泛的情景中。我们的理论分析和实验结果都验证了SHARP的有效性。跨四个数据集的实验结果表明，SHARP在全局和度的层面上都优于baseline方法。', 'title_zh': '基于图对比学习中难以学习节点的自适应缓解度分布偏差'}
{'arxiv_id': 'arXiv:2506.05211', 'title': 'Intentionally Unintentional: GenAI Exceptionalism and the First Amendment', 'authors': 'David Atkinson, Jena D. Hwang, Jacob Morrison', 'link': 'https://arxiv.org/abs/2506.05211', 'abstract': "This paper challenges the assumption that courts should grant First Amendment protections to outputs from large generative AI models, such as GPT-4 and Gemini. We argue that because these models lack intentionality, their outputs do not constitute speech as understood in the context of established legal precedent, so there can be no speech to protect. Furthermore, if the model outputs are not speech, users cannot claim a First Amendment speech right to receive the outputs. We also argue that extending First Amendment rights to AI models would not serve the fundamental purposes of free speech, such as promoting a marketplace of ideas, facilitating self-governance, or fostering self-expression. In fact, granting First Amendment protections to AI models would be detrimental to society because it would hinder the government's ability to regulate these powerful technologies effectively, potentially leading to the unchecked spread of misinformation and other harms.", 'abstract_zh': '本文挑战了法院应给予大型生成型人工智能模型如GPT-4和Gemini的输出第一修正案保护的假设。我们argue认为，由于这些模型缺乏意图性，它们的输出并不构成在现有法律先例下所理解的言论，因此不存在可保护的言论。此外，如果模型输出并非言论，用户无法主张第一修正案的言论权利以获取这些输出。我们还argue认为，将第一修正案权利扩展到AI模型不会服务于言论自由的基本目的，如促进思想市场的繁荣、促进自治或促进自我表达。实际上，给予AI模型第一修正案保护反而会对社会有害，因为它会妨碍政府有效监管这些强大技术的能力，可能导致信息误导和其他危害的不受控制的传播。', 'title_zh': '有意的无意：GenAI特设论与第一修正案'}
{'arxiv_id': 'arXiv:2506.05104', 'title': 'Survey on the Evaluation of Generative Models in Music', 'authors': 'Alexander Lerch, Claire Arthur, Nick Bryan-Kinns, Corey Ford, Qianyi Sun, Ashvala Vinay', 'link': 'https://arxiv.org/abs/2506.05104', 'abstract': 'Research on generative systems in music has seen considerable attention and growth in recent years. A variety of attempts have been made to systematically evaluate such systems. We provide an interdisciplinary review of the common evaluation targets, methodologies, and metrics for the evaluation of both system output and model usability, covering subjective and objective approaches, qualitative and quantitative approaches, as well as empirical and computational methods. We discuss the advantages and challenges of such approaches from a musicological, an engineering, and an HCI perspective.', 'abstract_zh': '近年来，音乐生成系统的研究受到了 considerable 关注和增长。已经尝试了各种方法系统性地评估这些系统。本文从音乐学、工程学和人机交互角度综述了评估系统输出和模型可用性的共同评价目标、方法和指标，涵盖了主观与客观方法、定性与定量方法以及经验性与计算性方法，并讨论了这些方法的优势和挑战。', 'title_zh': '音乐生成模型评估研究'}
{'arxiv_id': 'arXiv:2506.05035', 'title': 'TIMING: Temporality-Aware Integrated Gradients for Time Series Explanation', 'authors': 'Hyeongwon Jang, Changhun Kim, Eunho Yang', 'link': 'https://arxiv.org/abs/2506.05035', 'abstract': 'Recent explainable artificial intelligence (XAI) methods for time series primarily estimate point-wise attribution magnitudes, while overlooking the directional impact on predictions, leading to suboptimal identification of significant points. Our analysis shows that conventional Integrated Gradients (IG) effectively capture critical points with both positive and negative impacts on predictions. However, current evaluation metrics fail to assess this capability, as they inadvertently cancel out opposing feature contributions. To address this limitation, we propose novel evaluation metrics-Cumulative Prediction Difference (CPD) and Cumulative Prediction Preservation (CPP)-to systematically assess whether attribution methods accurately identify significant positive and negative points in time series XAI. Under these metrics, conventional IG outperforms recent counterparts. However, directly applying IG to time series data may lead to suboptimal outcomes, as generated paths ignore temporal relationships and introduce out-of-distribution samples. To overcome these challenges, we introduce TIMING, which enhances IG by incorporating temporal awareness while maintaining its theoretical properties. Extensive experiments on synthetic and real-world time series benchmarks demonstrate that TIMING outperforms existing time series XAI baselines. Our code is available at this https URL.', 'abstract_zh': '近期用于时间序列的可解释人工智能(XAI)方法主要估计点 wise 归因 magnitude，而忽视了对预测的导向性影响，导致显著点的识别不够优化。我们的分析表明，传统的集成梯度(IG)能够有效地捕捉对预测既有正面又有负面影 响的关键点。然而，当前的评估指标未能评估这一能力，因为它们无意中抵消了特征贡献的对立面。为解决这一局限性，我们提出了新的评估指标——累计预测差异(CPD)和累计预测保留(CPP)，以系统地评估归因方法是否准确地识别出时间序列XAI中的重要正面和负面点。在这些指标下，传统的IG优于近期的同类方法。然而，直接将IG应用于时间序列数据可能会导致次优结果，因为生成的路径忽略了时间关系，并引入了分布外样本。为应对这些挑战，我们引入了TIMING，通过引入时间意识来增强IG，同时保持其理论特性。广泛的实验证明，TIMING 在合成和真实世界的时间序列基准上优于现有时间序列XAI基线。我们的代码可在以下链接获取。', 'title_zh': '基于时间感知集成梯度的时间序列解释'}
{'arxiv_id': 'arXiv:2506.05032', 'title': 'Identifying and Understanding Cross-Class Features in Adversarial Training', 'authors': 'Zeming Wei, Yiwen Guo, Yisen Wang', 'link': 'https://arxiv.org/abs/2506.05032', 'abstract': 'Adversarial training (AT) has been considered one of the most effective methods for making deep neural networks robust against adversarial attacks, while the training mechanisms and dynamics of AT remain open research problems. In this paper, we present a novel perspective on studying AT through the lens of class-wise feature attribution. Specifically, we identify the impact of a key family of features on AT that are shared by multiple classes, which we call cross-class features. These features are typically useful for robust classification, which we offer theoretical evidence to illustrate through a synthetic data model. Through systematic studies across multiple model architectures and settings, we find that during the initial stage of AT, the model tends to learn more cross-class features until the best robustness checkpoint. As AT further squeezes the training robust loss and causes robust overfitting, the model tends to make decisions based on more class-specific features. Based on these discoveries, we further provide a unified view of two existing properties of AT, including the advantage of soft-label training and robust overfitting. Overall, these insights refine the current understanding of AT mechanisms and provide new perspectives on studying them. Our code is available at this https URL.', 'abstract_zh': '对抗训练（AT）被认为是使深度神经网络对对抗攻击具有鲁棒性的最有效方法之一，尽管AT的训练机制和动态仍然是开放的研究问题。在本文中，我们通过类内特征归因的视角提出了研究AT的全新观点。具体而言，我们识别了在多个类别间共享的关键特征家族对AT的影响，我们将这些特征称为跨类别特征。这些特征通常对鲁棒分类是有用的，我们通过合成数据模型提供了理论证据来说明这一点。通过在多种模型架构和设置下的系统研究，我们发现，在AT的初始阶段，模型倾向于更多地学习跨类别特征，直到达到最佳鲁棒性检查点。随着AT进一步压缩训练的鲁棒损失并导致鲁棒过拟合，模型倾向于基于更多类别特定特征来做决策。基于这些发现，我们进一步提供了一种对AT现有两个性质的统一观点，包括软标签训练的优势和鲁棒过拟合。总体而言，这些见解细化了对AT机制的理解，并提供了研究它们的新视角。我们的代码可在以下链接获取：这个https链接。', 'title_zh': '识别和理解对抗训练中的跨类别特征'}
{'arxiv_id': 'arXiv:2506.05030', 'title': 'Artificial Intelligence Should Genuinely Support Clinical Reasoning and Decision Making To Bridge the Translational Gap', 'authors': 'Kacper Sokol, James Fackler, Julia E Vogt', 'link': 'https://arxiv.org/abs/2506.05030', 'abstract': "Artificial intelligence promises to revolutionise medicine, yet its impact remains limited because of the pervasive translational gap. We posit that the prevailing technology-centric approaches underpin this challenge, rendering such systems fundamentally incompatible with clinical practice, specifically diagnostic reasoning and decision making. Instead, we propose a novel sociotechnical conceptualisation of data-driven support tools designed to complement doctors' cognitive and epistemic activities. Crucially, it prioritises real-world impact over superhuman performance on inconsequential benchmarks.", 'abstract_zh': '人工智能有望革新医学，但其影响受限于普遍存在的转化_gap。我们提出，现行的技术导向方法是这一挑战的根源，使得这些系统与临床实践，特别是诊断推理和决策制定，根本无法兼容。相反，我们建议一种新的社会技术概念化数据驱动支持工具，旨在补充医生的认知和知识活动。关键在于强调现实世界的影响而非在无关基准上的超人表现。', 'title_zh': '人工智能应真正支持临床推理和决策以桥接 translational 静默处的gap'}
{'arxiv_id': 'arXiv:2506.05014', 'title': 'Towards Reasonable Concept Bottleneck Models', 'authors': 'Nektarios Kalampalikis, Kavya Gupta, Georgi Vitanov, Isabel Valera', 'link': 'https://arxiv.org/abs/2506.05014', 'abstract': 'In this paper, we propose $\\textbf{C}$oncept $\\textbf{REA}$soning $\\textbf{M}$odels (CREAM), a novel family of Concept Bottleneck Models (CBMs) that: (i) explicitly encodes concept-concept (${\\texttt{C-C}}$) and concept-task (${\\texttt{C$\\rightarrow$Y}}$) relationships to enforce a desired model reasoning; and (ii) use a regularized side-channel to achieve competitive task performance, while keeping high concept importance. Specifically, CREAM architecturally embeds (bi)directed concept-concept, and concept to task relationships specified by a human expert, while severing undesired information flows (e.g., to handle mutually exclusive concepts). Moreover, CREAM integrates a black-box side-channel that is regularized to encourage task predictions to be grounded in the relevant concepts, thereby utilizing the side-channel only when necessary to enhance performance. Our experiments show that: (i) CREAM mainly relies on concepts while achieving task performance on par with black-box models; and (ii) the embedded ${\\texttt{C-C}}$ and ${\\texttt{C$\\rightarrow$Y}}$ relationships ease model interventions and mitigate concept leakage.', 'abstract_zh': '基于概念推理的模型(CREAM)：一种新型的概念瓶颈模型家族', 'title_zh': '合理概念瓶颈模型研究'}
{'arxiv_id': 'arXiv:2506.04987', 'title': 'A Multi-Dataset Evaluation of Models for Automated Vulnerability Repair', 'authors': 'Zanis Ali Khan, Aayush Garg, Qiang Tang', 'link': 'https://arxiv.org/abs/2506.04987', 'abstract': 'Software vulnerabilities pose significant security threats, requiring effective mitigation. While Automated Program Repair (APR) has advanced in fixing general bugs, vulnerability patching, a security-critical aspect of APR remains underexplored. This study investigates pre-trained language models, CodeBERT and CodeT5, for automated vulnerability patching across six datasets and four languages. We evaluate their accuracy and generalization to unknown vulnerabilities. Results show that while both models face challenges with fragmented or sparse context, CodeBERT performs comparatively better in such scenarios, whereas CodeT5 excels in capturing complex vulnerability patterns. CodeT5 also demonstrates superior scalability. Furthermore, we test fine-tuned models on both in-distribution (trained) and out-of-distribution (unseen) datasets. While fine-tuning improves in-distribution performance, models struggle to generalize to unseen data, highlighting challenges in robust vulnerability detection. This study benchmarks model performance, identifies limitations in generalization, and provides actionable insights to advance automated vulnerability patching for real-world security applications.', 'abstract_zh': '预训练语言模型在跨六大数据集和四种语言的自动漏洞修补中的研究', 'title_zh': '多数据集评估的自动化漏洞修复模型研究'}
{'arxiv_id': 'arXiv:2506.04951', 'title': 'Robustness as Architecture: Designing IQA Models to Withstand Adversarial Perturbations', 'authors': 'Igor Meleshin, Anna Chistyakova, Anastasia Antsiferova, Dmitriy Vatolin', 'link': 'https://arxiv.org/abs/2506.04951', 'abstract': 'Image Quality Assessment (IQA) models are increasingly relied upon to evaluate image quality in real-world systems -- from compression and enhancement to generation and streaming. Yet their adoption brings a fundamental risk: these models are inherently unstable. Adversarial manipulations can easily fool them, inflating scores and undermining trust. Traditionally, such vulnerabilities are addressed through data-driven defenses -- adversarial retraining, regularization, or input purification. But what if this is the wrong lens? What if robustness in perceptual models is not something to learn but something to design? In this work, we propose a provocative idea: robustness as an architectural prior. Rather than training models to resist perturbations, we reshape their internal structure to suppress sensitivity from the ground up. We achieve this by enforcing orthogonal information flow, constraining the network to norm-preserving operations -- and further stabilizing the system through pruning and fine-tuning. The result is a robust IQA architecture that withstands adversarial attacks without requiring adversarial training or significant changes to the original model. This approach suggests a shift in perspective: from optimizing robustness through data to engineering it through design.', 'abstract_zh': '感知模型稳健性作为架构先验的图像品质评估（IQA）模型', 'title_zh': '鲁棒性作为架构：设计能抵抗对抗性扰动的IQA模型'}
{'arxiv_id': 'arXiv:2506.04860', 'title': 'Towards Network Data Analytics in 5G Systems and Beyond', 'authors': 'Marcos Lima Romero, Ricardo Suyama', 'link': 'https://arxiv.org/abs/2506.04860', 'abstract': 'Data has become a critical asset in the digital economy, yet it remains underutilized by Mobile Network Operators (MNOs), unlike Over-the-Top (OTT) players that lead global market valuations. To move beyond the commoditization of connectivity and deliver greater value to customers, data analytics emerges as a strategic enabler. Using data efficiently is essential for unlocking new service opportunities, optimizing operational efficiency, and mitigating operational and business risks. Since Release 15, the 3rd Generation Partnership Project (3GPP) has introduced the Network Data Analytics Function (NWDAF) to provide powerful insights and predictions using data collected across mobile networks, supporting both user-centric and network-oriented use cases. However, academic research has largely focused on a limited set of methods and use cases, driven by the availability of datasets, restricting broader exploration. This study analyzes trends and gaps in more than 70 articles and proposes two novel use cases to promote the adoption of NWDAF and explore its potential for monetization.', 'abstract_zh': '数据已成为数字经济中的关键资产，然而移动网络运营商（MNOs）仍未充分利用数据，相比之下，Over-the-Top（OTT）玩家主导了全球市场估值。为了超越连接服务的同质化并且为客户提供更大的价值，数据分析师工具成为战略性的使能器。有效地利用数据对于解锁新的服务机会、优化运营效率以及减轻运营和业务风险至关重要。自R15起，3GPP引入了网络数据分析功能（NWDAF），利用移动网络中收集的数据提供强大的洞察和预测，支持用户中心和网络导向的应用场景。然而，学术研究主要集中在有限的方法和应用案例上，这限制了更广泛的研究探索。本研究分析了逾70篇论文的趋势和空白，并提出两个新型应用案例，以促进NWDAF的采用并探索其潜在的商业化可能性。', 'title_zh': '向5G系统及更远未来的网络数据分析迈进'}
{'arxiv_id': 'arXiv:2506.04859', 'title': 'Sparse Autoencoders, Again?', 'authors': 'Yin Lu, Tong He, Xuening Zhu, David Wipf', 'link': 'https://arxiv.org/abs/2506.04859', 'abstract': 'Is there really much more to say about sparse autoencoders (SAEs)? Autoencoders in general, and SAEs in particular, represent deep architectures that are capable of modeling low-dimensional latent structure in data. Such structure could reflect, among other things, correlation patterns in large language model activations, or complex natural image manifolds. And yet despite the wide-ranging applicability, there have been relatively few changes to SAEs beyond the original recipe from decades ago, namely, standard deep encoder/decoder layers trained with a classical/deterministic sparse regularizer applied within the latent space. One possible exception is the variational autoencoder (VAE), which adopts a stochastic encoder module capable of producing sparse representations when applied to manifold data. In this work we formalize underappreciated weaknesses with both canonical SAEs, as well as analogous VAEs applied to similar tasks, and propose a hybrid alternative model that circumvents these prior limitations. In terms of theoretical support, we prove that global minima of our proposed model recover certain forms of structured data spread across a union of manifolds. Meanwhile, empirical evaluations on synthetic and real-world datasets substantiate the efficacy of our approach in accurately estimating underlying manifold dimensions and producing sparser latent representations without compromising reconstruction error. In general, we are able to exceed the performance of equivalent-capacity SAEs and VAEs, as well as recent diffusion models where applicable, within domains such as images and language model activation patterns.', 'abstract_zh': '关于稀疏自编码器(SAEs)真的还有很多可说的内容吗？：稀疏自编码器作为能够建模数据低维潜在结构的深层架构，在一般情况下，特别是SAEs中，这种结构可以反映大规模语言模型激活中的相关模式，或复杂自然图像流形。然而，尽管应用范围广泛，自几十年前的原始配方以来，SAEs的变化相对较少，主要是在潜在空间中应用标准的深度编码/解码层和经典的确定性稀疏正则化。唯一的例外可能是变分自编码器（VAE），它采用了一个能够生成稀疏表示的随机编码模块。在本工作中，我们 formalize 了经典 SAEs 和应用于类似任务的类似 VAEs 的未被充分认识的局限性，并提出了一种新的混合模型来克服这些先前的限制。在理论支持方面，我们证明了我们所提出的模型的全局最小值能够恢复跨流形联合分布的某些结构数据形式。同时，对合成和真实世界数据集的经验评估证明了我们方法的有效性，它能够准确估计潜在流形维度并产生更稀疏的潜在表示，而不牺牲重构误差。总体而言，我们能够在图像和语言模型激活模式等领域超越具有相同容量的 SAEs 和 VAEs，以及适用的情况下超越最近的扩散模型。', 'title_zh': '稀疏自编码器，再次登场？'}
{'arxiv_id': 'arXiv:2506.04836', 'title': 'Oversight Structures for Agentic AI in Public-Sector Organizations', 'authors': 'Chris Schmitz, Jonathan Rystrøm, Jan Batzner', 'link': 'https://arxiv.org/abs/2506.04836', 'abstract': 'This paper finds that the introduction of agentic AI systems intensifies existing challenges to traditional public sector oversight mechanisms -- which rely on siloed compliance units and episodic approvals rather than continuous, integrated supervision. We identify five governance dimensions essential for responsible agent deployment: cross-departmental implementation, comprehensive evaluation, enhanced security protocols, operational visibility, and systematic auditing. We evaluate the capacity of existing oversight structures to meet these challenges, via a mixed-methods approach consisting of a literature review and interviews with civil servants in AI-related roles. We find that agent oversight poses intensified versions of three existing governance challenges: continuous oversight, deeper integration of governance and operational capabilities, and interdepartmental coordination. We propose approaches that both adapt institutional structures and design agent oversight compatible with public sector constraints.', 'abstract_zh': '本文发现，代理型人工智能系统的引入加剧了传统公共部门监督机制面临的现有挑战——这些机制依赖于隔离的合规单位和 episodic 审批，而非连续性、集成的监督。我们确定了五项对于负责任地部署代理的关键治理维度：跨部门实施、全面评估、增强的安全协议、操作透明度以及系统性审计。我们通过包含文献回顾和对相关领域公务员的访谈的混合方法评估现有监督结构的能力，以应对这些挑战。我们发现，代理监督加剧了三个现有治理挑战：持续监督、治理和操作能力的更深层次整合以及跨部门协调。我们提出了既适应机构结构又与公共服务约束兼容的代理监督方案。', 'title_zh': '公共部门组织中代理人工智能的监管结构'}
{'arxiv_id': 'arXiv:2506.04755', 'title': 'Truth in the Few: High-Value Data Selection for Efficient Multi-Modal Reasoning', 'authors': 'Shenshen Li, Kaiyuan Deng, Lei Wang, Hao Yang, Chong Peng, Peng Yan, Fumin Shen, Heng Tao Shen, Xing Xu', 'link': 'https://arxiv.org/abs/2506.04755', 'abstract': "While multi-modal large language models (MLLMs) have made significant progress in complex reasoning tasks via reinforcement learning, it is commonly believed that extensive training data is necessary for improving multi-modal reasoning ability, inevitably leading to data redundancy and substantial computational costs. However, can smaller high-value datasets match or outperform full corpora for multi-modal reasoning in MLLMs? In this work, we challenge this assumption through a key observation: meaningful multi-modal reasoning is triggered by only a sparse subset of training samples, termed cognitive samples, whereas the majority contribute marginally. Building on this insight, we propose a novel data selection paradigm termed Reasoning Activation Potential (RAP), which identifies cognitive samples by estimating each sample's potential to stimulate genuine multi-modal reasoning by two complementary estimators: 1) Causal Discrepancy Estimator (CDE) based on the potential outcome model principle, eliminates samples that overly rely on language priors by comparing outputs between multi-modal and text-only inputs; 2) Attention Confidence Estimator (ACE), which exploits token-level self-attention to discard samples dominated by irrelevant but over-emphasized tokens in intermediate reasoning stages. Moreover, we introduce a Difficulty-aware Replacement Module (DRM) to substitute trivial instances with cognitively challenging ones, thereby ensuring complexity for robust multi-modal reasoning. Experiments on six datasets show that our RAP method consistently achieves superior performance using only 9.3% of the training data, while reducing computational costs by over 43%. Our code is available at this https URL.", 'abstract_zh': '多模态大型语言模型中的有限高价值数据能否匹配或超越全面语料库的多模态推理能力：基于推理激活潜力的新型数据选择范式', 'title_zh': '少即是真：高效多模态推理中的高价值数据选择'}
{'arxiv_id': 'arXiv:2506.04742', 'title': 'Was Residual Penalty and Neural Operators All We Needed for Solving Optimal Control Problems?', 'authors': 'Oliver G. S. Lundqvist, Fabricio Oliveira', 'link': 'https://arxiv.org/abs/2506.04742', 'abstract': 'Neural networks have been used to solve optimal control problems, typically by training neural networks using a combined loss function that considers data, differential equation residuals, and objective costs. We show that including cost functions in the training process is unnecessary, advocating for a simpler architecture and streamlined approach by decoupling the optimal control problem from the training process. Thus, our work shows that a simple neural operator architecture, such as DeepONet, coupled with an unconstrained optimization routine, can solve multiple optimal control problems with a single physics-informed training phase and a subsequent optimization phase. We achieve this by adding a penalty term based on the differential equation residual to the cost function and computing gradients with respect to the control using automatic differentiation through the trained neural operator within an iterative optimization routine. We showcase our method on nine distinct optimal control problems by training three separate DeepONet models, each corresponding to a different differential equation. For each model, we solve three problems with varying cost functions, demonstrating accurate and consistent performance across all cases.', 'abstract_zh': '神经网络已被用于解决最优控制问题，通常通过使用结合数据、微分方程残差和目标成本的损失函数来训练神经网络。我们表明，在训练过程中包含成本函数是不必要的，并且通过将最优控制问题与训练过程脱钩，采用一种更简单且简洁的架构可以解决问题。因此，我们的工作表明，结合无约束优化方法的简单神经算子架构，如DeepONet，可以在单次基于物理的训练阶段和后续的优化阶段解决多个最优控制问题。我们通过在成本函数中增加基于微分方程残差的惩罚项，并使用自动微分通过训练的神经算子在迭代优化过程中计算控制的梯度来实现这一点。我们在九个不同的最优控制问题上展示了我们的方法，通过训练三个分别对应不同微分方程的DeepONet模型。对于每个模型，我们解决了三个具有不同成本函数的问题，展示了所有情况下的准确且一致的性能。', 'title_zh': '残差罚函数和神经算子足以解决最优控制问题吗？'}
{'arxiv_id': 'arXiv:2506.04717', 'title': 'Using In-Context Learning for Automatic Defect Labelling of Display Manufacturing Data', 'authors': 'Babar Hussain, Qiang Liu, Gang Chen, Bihai She, Dahai Yu', 'link': 'https://arxiv.org/abs/2506.04717', 'abstract': 'This paper presents an AI-assisted auto-labeling system for display panel defect detection that leverages in-context learning capabilities. We adopt and enhance the SegGPT architecture with several domain-specific training techniques and introduce a scribble-based annotation mechanism to streamline the labeling process. Our two-stage training approach, validated on industrial display panel datasets, demonstrates significant improvements over the baseline model, achieving an average IoU increase of 0.22 and a 14% improvement in recall across multiple product types, while maintaining approximately 60% auto-labeling coverage. Experimental results show that models trained on our auto-labeled data match the performance of those trained on human-labeled data, offering a practical solution for reducing manual annotation efforts in industrial inspection systems.', 'abstract_zh': '基于上下文学习的AI辅助自动标注系统在显示面板缺陷检测中的应用研究', 'title_zh': '基于上下文学习的显示制造数据自动缺陷标注'}
{'arxiv_id': 'arXiv:2506.04712', 'title': 'UNO: Unlearning via Orthogonalization in Generative models', 'authors': 'Pinak Mandal, Georg A. Gottwald', 'link': 'https://arxiv.org/abs/2506.04712', 'abstract': 'As generative models become increasingly powerful and pervasive, the ability to unlearn specific data, whether due to privacy concerns, legal requirements, or the correction of harmful content, has become increasingly important. Unlike in conventional training, where data are accumulated and knowledge is reinforced, unlearning aims to selectively remove the influence of particular data points without costly retraining from scratch. To be effective and reliable, such algorithms need to achieve (i) forgetting of the undesired data, (ii) preservation of the quality of the generation, (iii) preservation of the influence of the desired training data on the model parameters, and (iv) small number of training steps. We propose fast unlearning algorithms based on loss gradient orthogonalization. We show that our algorithms are able to forget data while maintaining the fidelity of the original model. Using MNIST and CelebA data, we demonstrate that our algorithms achieve orders of magnitude faster unlearning times than their predecessors, such as gradient surgery.', 'abstract_zh': '随着生成模型变得越来越强大和普及，由于隐私问题、法律规定或有害内容的更正等原因，去除特定数据的能力变得越来越重要。与传统训练中数据积累和知识强化不同，去除特定数据旨在不进行昂贵的从头开始重新训练的情况下选择性地去除特定数据点的影响。为了有效和可靠，此类算法需要实现（i）遗忘不需要的数据，（ii）保持生成的质量，（iii）保持希望的训练数据对模型参数的影响，以及（iv）少量的训练步骤。我们提出了基于损失梯度正交化的快速去除算法。我们证明，我们的算法能够在保持原始模型保真度的同时遗忘数据。使用MNIST和CelebA数据，我们展示了我们的算法比前驱算法（如梯度手术）快多个数量级的去除时间。', 'title_zh': 'UNO：生成模型中的正交化去学习'}
{'arxiv_id': 'arXiv:2506.04704', 'title': 'HoliSafe: Holistic Safety Benchmarking and Modeling with Safety Meta Token for Vision-Language Model', 'authors': 'Youngwan Lee, Kangsan Kim, Kwanyong Park, Ilcahe Jung, Soojin Jang, Seanie Lee, Yong-Ju Lee, Sung Ju Hwang', 'link': 'https://arxiv.org/abs/2506.04704', 'abstract': 'Despite emerging efforts to enhance the safety of Vision-Language Models (VLMs), current approaches face two main shortcomings. 1) Existing safety-tuning datasets and benchmarks only partially consider how image-text interactions can yield harmful content, often overlooking contextually unsafe outcomes from seemingly benign pairs. This narrow coverage leaves VLMs vulnerable to jailbreak attacks in unseen configurations. 2) Prior methods rely primarily on data-centric tuning, with limited architectural innovations to intrinsically strengthen safety. We address these gaps by introducing a holistic safety dataset and benchmark, HoliSafe, that spans all five safe/unsafe image-text combinations, providing a more robust basis for both training and evaluation. We further propose SafeLLaVA, a novel VLM augmented with a learnable safety meta token and a dedicated safety head. The meta token encodes harmful visual cues during training, intrinsically guiding the language model toward safer responses, while the safety head offers interpretable harmfulness classification aligned with refusal rationales. Experiments show that SafeLLaVA, trained on HoliSafe, achieves state-of-the-art safety performance across multiple VLM benchmarks. Additionally, the HoliSafe benchmark itself reveals critical vulnerabilities in existing models. We hope that HoliSafe and SafeLLaVA will spur further research into robust and interpretable VLM safety, expanding future avenues for multimodal alignment.', 'abstract_zh': '尽管在增强视觉语言模型（VLMs）的安全性方面已经做出了努力，但当前的方法仍存在两个主要不足。1）现有的安全调优数据集和基准仅部分考虑了图像-文本互动可能产生的有害内容，并且往往忽视了看似无害的配对在上下文中的不安全结果，这种狭窄的覆盖面使得VLMs在未见配置中容易受到 Jailbreak 攻击。2）先前的方法主要依赖数据为中心的调优，缺乏从根本上增强安全性的架构创新。我们通过引入一个全面的安全数据集和基准HoliSafe来弥补这些不足，HoliSafe涵盖了所有五种安全/不安全的图像-文本组合，为训练和评估提供了更 robust 的基础。我们还提出了SafeLLaVA，这是一种配备了可学习的安全元标记和专用安全头部的新型VLM。在训练过程中，元标记编码有害的视觉提示，内在地引导语言模型产生更安全的响应，而安全头部提供了与拒绝理由一致的可解释的有害性分类。实验结果显示，SafeLLaVA在多个VLM基准上的安全性能达到了最先进的水平。此外，HoliSafe基准本身揭示了现有模型中的关键漏洞。我们希望HoliSafe和SafeLLaVA能促进对 robust 和可解释的VLM安全性的进一步研究，拓展未来多模态对齐的方向。', 'title_zh': 'HoliSafe: 综合安全基准构建与安全元令牌建模在视觉语言模型中'}
{'arxiv_id': 'arXiv:2506.04700', 'title': 'Explicit Density Approximation for Neural Implicit Samplers Using a Bernstein-Based Convex Divergence', 'authors': 'José Manuel de Frutos, Manuel A. Vázquez, Pablo M. Olmos, Joaquín Míguez', 'link': 'https://arxiv.org/abs/2506.04700', 'abstract': 'Rank-based statistical metrics, such as the invariant statistical loss (ISL), have recently emerged as robust and practically effective tools for training implicit generative models. In this work, we introduce dual-ISL, a novel likelihood-free objective for training implicit generative models that interchanges the roles of the target and model distributions in the ISL framework, yielding a convex optimization problem in the space of model densities. We prove that the resulting rank-based discrepancy $d_K$ is i) continuous under weak convergence and with respect to the $L^1$ norm, and ii) convex in its first argument-properties not shared by classical divergences such as KL or Wasserstein distances. Building on this, we develop a theoretical framework that interprets $d_K$ as an $L^2$-projection of the density ratio $q = p/\\tilde p$ onto a Bernstein polynomial basis, from which we derive exact bounds on the truncation error, precise convergence rates, and a closed-form expression for the truncated density approximation. We further extend our analysis to the multivariate setting via random one-dimensional projections, defining a sliced dual-ISL divergence that retains both convexity and continuity. We empirically show that these theoretical advantages translate into practical ones. Specifically, across several benchmarks dual-ISL converges more rapidly, delivers markedly smoother and more stable training, and more effectively prevents mode collapse than classical ISL and other leading implicit generative methods-while also providing an explicit density approximation.', 'abstract_zh': '基于排名的统计指标，如不变统计损失（ISL），最近已被用作训练隐式生成模型的强大而实用的工具。在本文中，我们介绍了一种新颖的概率测度自由目标——对偶-ISL，该目标在ISL框架中交换目标分布和模型分布的角色，形成了模型密度空间中的凸优化问题。我们证明，由此产生的基于排名的差异$d_K$具有如下性质：i) 在弱收敛和$L^1$范数意义下连续；ii) 在其第一个参数上凸——这些性质不是KL或Wasserstein距离等经典发散所共有的。基于此，我们建立了一个理论框架，将$d_K$解释为密度比$q = p/\\tilde p$在伯恩斯坦多项式基底上的$L^2$投影，从中我们得到了截断误差的确切界、精确收敛速率以及截断密度近似的闭式表达。进一步地，我们通过对各维随机一维投影的分析，将该框架扩展到多元设置，定义了一种切片对偶-ISL散度，该散度保留了凸性和连续性。我们在实验上展示了这些理论优势转化为实际优点的具体表现。具体而言，在多个基准测试中，对偶-ISL收敛速度更快，提供明显更平滑和更稳定的训练过程，并更有效地防止了模式缺失，同时提供了显式的密度近似，而这种性能优于经典ISL及其他领先的隐式生成方法。', 'title_zh': '使用Bernstein基凸散度的显式密度逼近神经隐式采样器'}
{'arxiv_id': 'arXiv:2506.04694', 'title': 'Influence Functions for Edge Edits in Non-Convex Graph Neural Networks', 'authors': 'Jaeseung Heo, Kyeongheung Yun, Seokwon Yoon, MoonJeong Park, Jungseul Ok, Dongwoo Kim', 'link': 'https://arxiv.org/abs/2506.04694', 'abstract': 'Understanding how individual edges influence the behavior of graph neural networks (GNNs) is essential for improving their interpretability and robustness. Graph influence functions have emerged as promising tools to efficiently estimate the effects of edge deletions without retraining. However, existing influence prediction methods rely on strict convexity assumptions, exclusively consider the influence of edge deletions while disregarding edge insertions, and fail to capture changes in message propagation caused by these modifications. In this work, we propose a proximal Bregman response function specifically tailored for GNNs, relaxing the convexity requirement and enabling accurate influence prediction for standard neural network architectures. Furthermore, our method explicitly accounts for message propagation effects and extends influence prediction to both edge deletions and insertions in a principled way. Experiments with real-world datasets demonstrate accurate influence predictions for different characteristics of GNNs. We further demonstrate that the influence function is versatile in applications such as graph rewiring and adversarial attacks.', 'abstract_zh': '理解单个边缘如何影响图神经网络（GNN）的行为对于提高其可解释性和鲁棒性至关重要。proximal Bregman 响应函数在本文中专门针对 GNN 被提出，放宽了凸性要求，使得可以准确预测标准神经网络架构的影响。此外，我们的方法明确考虑了消息传播效果，并以一种原则性的方式将影响预测扩展到边的删除和插入。实验结果表明，该方法能够准确预测不同特征下 GNN 的影响。我们进一步证明，影响函数在图重 wiring 和对抗攻击等领域具有灵活性。', 'title_zh': '非凸图神经网络中边编辑的影响函数'}
{'arxiv_id': 'arXiv:2506.04690', 'title': 'Towards Better Generalization via Distributional Input Projection Network', 'authors': 'Yifan Hao, Yanxin Lu, Xinwei Shen, Tong Zhang', 'link': 'https://arxiv.org/abs/2506.04690', 'abstract': 'As overparameterized models become increasingly prevalent, training loss alone offers limited insight into generalization performance. While smoothness has been linked to improved generalization across various settings, directly enforcing smoothness in neural networks remains challenging. To address this, we introduce Distributional Input Projection Networks (DIPNet), a novel framework that projects inputs into learnable distributions at each layer. This distributional representation induces a smoother loss landscape with respect to the input, promoting better generalization. We provide theoretical analysis showing that DIPNet reduces both local smoothness measures and the Lipschitz constant of the network, contributing to improved generalization performance. Empirically, we validate DIPNet across a wide range of architectures and tasks, including Vision Transformers (ViTs), Large Language Models (LLMs), ResNet and MLPs. Our method consistently enhances test performance under standard settings, adversarial attacks, out-of-distribution inputs, and reasoning benchmarks. We demonstrate that the proposed input projection strategy can be seamlessly integrated into existing models, providing a general and effective approach for boosting generalization performance in modern deep learning.', 'abstract_zh': '过度参数化模型日益普及，训练损失 alone 未能充分揭示泛化性能。尽管平滑性在各种设置中与改进的泛化性能相关联，直接在神经网络中施加平滑性仍然具有挑战性。为此，我们提出了分布输入投影网络（DIPNet），这是一种新颖的框架，在每一层将输入投影到可学习的概率分布中。这种分布表示诱导了输入相关的更平滑的损失景观，促进了更好的泛化性能。我们提供了理论分析，证明 DIPNet 降低了局部平滑度度量并减少了网络的利普希茨常数，从而促进了泛化性能的提升。在实验中，我们在包括视觉变压器（ViTs）、大规模语言模型（LLMs）、ResNet 和 MLP 等多种架构和任务上验证了 DIPNet 的有效性。我们的方法在标准设置、对抗攻击、离分布输入和推理基准上均能持续提升测试性能。我们展示了所提出输入投影策略可以无缝集成到现有模型中，提供了一种通用且有效的提升现代深度学习泛化性能的方法。', 'title_zh': '通过分布输入投影网络实现更好的泛化能力'}
{'arxiv_id': 'arXiv:2506.04668', 'title': 'Feature-Based Lie Group Transformer for Real-World Applications', 'authors': 'Takayuki Komatsu, Yoshiyuki Ohmura, Kayato Nishitsunoi, Yasuo Kuniyoshi', 'link': 'https://arxiv.org/abs/2506.04668', 'abstract': 'The main goal of representation learning is to acquire meaningful representations from real-world sensory inputs without supervision. Representation learning explains some aspects of human development. Various neural network (NN) models have been proposed that acquire empirically good representations. However, the formulation of a good representation has not been established. We recently proposed a method for categorizing changes between a pair of sensory inputs. A unique feature of this approach is that transformations between two sensory inputs are learned to satisfy algebraic structural constraints. Conventional representation learning often assumes that disentangled independent feature axes is a good representation; however, we found that such a representation cannot account for conditional independence. To overcome this problem, we proposed a new method using group decomposition in Galois algebra theory. Although this method is promising for defining a more general representation, it assumes pixel-to-pixel translation without feature extraction, and can only process low-resolution images with no background, which prevents real-world application. In this study, we provide a simple method to apply our group decomposition theory to a more realistic scenario by combining feature extraction and object segmentation. We replace pixel translation with feature translation and formulate object segmentation as grouping features under the same transformation. We validated the proposed method on a practical dataset containing both real-world object and background. We believe that our model will lead to a better understanding of human development of object recognition in the real world.', 'abstract_zh': '无监督表征学习的主要目标是从现实世界的感知输入中获取有意义的表征。无监督表征学习解释了一些人类发展的方面。各种神经网络（NN）模型被提出，以获取实证较好的表征。然而，良好表征的公设尚未建立。我们最近提出了一种对感知输入对之间变化进行分类的方法。该方法的一个独特特征是，学习感知输入之间的变换以满足代数结构约束。传统的表征学习通常假设解耦独立特征轴是良好的表征；然而，我们发现这样的表征无法解释条件独立性。为解决此问题，我们提出了一种新的基于伽罗华代数理论中的群分解方法。尽管该方法有可能定义更一般的表征，但它假设像素到像素的翻译而不进行特征提取，并且只能处理没有背景的低分辨率图片，这限制了其实用性。在本研究中，我们提供了一种简单的方法，通过结合特征提取和对象分割将我们的群分解理论应用于更现实的场景。我们用特征翻译取代像素翻译，并将对象分割表述为在相同变换下的特征分组。我们通过包含现实世界对象和背景的实际数据集验证了所提出的方法。我们相信，我们的模型将有助于更好地理解人类在现实世界中对物体识别的发展。', 'title_zh': '基于特征的李群变换器在实际应用中的研究'}
{'arxiv_id': 'arXiv:2506.04624', 'title': 'Static Word Embeddings for Sentence Semantic Representation', 'authors': 'Takashi Wada, Yuki Hirakawa, Ryotaro Shimizu, Takahiro Kawashima, Yuki Saito', 'link': 'https://arxiv.org/abs/2506.04624', 'abstract': 'We propose new static word embeddings optimised for sentence semantic representation. We first extract word embeddings from a pre-trained Sentence Transformer, and improve them with sentence-level principal component analysis, followed by either knowledge distillation or contrastive learning. During inference, we represent sentences by simply averaging word embeddings, which requires little computational cost. We evaluate models on both monolingual and cross-lingual tasks and show that our model substantially outperforms existing static models on sentence semantic tasks, and even rivals a basic Sentence Transformer model (SimCSE) on some data sets. Lastly, we perform a variety of analyses and show that our method successfully removes word embedding components that are irrelevant to sentence semantics, and adjusts the vector norms based on the influence of words on sentence semantics.', 'abstract_zh': '我们提出了一种新的静态词嵌入方法，旨在优化句子语义表示。我们首先从预训练的Sentence Transformer中提取词嵌入，并通过句子级主成分分析改进它们，随后使用知识蒸馏或对比学习。在推理过程中，我们通过简单地对词嵌入求平均来表示句子，这需要较少的计算成本。我们在单语任务和跨语言任务上评估了模型，并表明我们的模型在句子语义任务上的表现显著优于现有的静态模型，在某些数据集上甚至与基本的Sentence Transformer模型（SimCSE）相当。最后，我们进行了多种分析，并展示了我们的方法成功地去除了与句子语义无关的词嵌入成分，并根据词对句子语义的影响调整了向量范数。', 'title_zh': '静态词嵌入在句义表示中的应用'}
{'arxiv_id': 'arXiv:2506.04594', 'title': 'Intelligent Channel Allocation for IEEE 802.11be Multi-Link Operation: When MAB Meets LLM', 'authors': 'Shumin Lian, Jingwen Tong, Jun Zhang, Liqun Fu', 'link': 'https://arxiv.org/abs/2506.04594', 'abstract': 'WiFi networks have achieved remarkable success in enabling seamless communication and data exchange worldwide. The IEEE 802.11be standard, known as WiFi 7, introduces Multi-Link Operation (MLO), a groundbreaking feature that enables devices to establish multiple simultaneous connections across different bands and channels. While MLO promises substantial improvements in network throughput and latency reduction, it presents significant challenges in channel allocation, particularly in dense network environments. Current research has predominantly focused on performance analysis and throughput optimization within static WiFi 7 network configurations. In contrast, this paper addresses the dynamic channel allocation problem in dense WiFi 7 networks with MLO capabilities. We formulate this challenge as a combinatorial optimization problem, leveraging a novel network performance analysis mechanism. Given the inherent lack of prior network information, we model the problem within a Multi-Armed Bandit (MAB) framework to enable online learning of optimal channel allocations. Our proposed Best-Arm Identification-enabled Monte Carlo Tree Search (BAI-MCTS) algorithm includes rigorous theoretical analysis, providing upper bounds for both sample complexity and error probability. To further reduce sample complexity and enhance generalizability across diverse network scenarios, we put forth LLM-BAI-MCTS, an intelligent algorithm for the dynamic channel allocation problem by integrating the Large Language Model (LLM) into the BAI-MCTS algorithm. Numerical results demonstrate that the BAI-MCTS algorithm achieves a convergence rate approximately $50.44\\%$ faster than the state-of-the-art algorithms when reaching $98\\%$ of the optimal value. Notably, the convergence rate of the LLM-BAI-MCTS algorithm increases by over $63.32\\%$ in dense networks.', 'abstract_zh': 'WiFi网络已在全球范围内实现了无缝通信和数据交换的显著成功。IEEE 802.11be标准，即WiFi 7，引入了多链路操作(Multi-Link Operation, MLO)功能，使设备能够在不同频段和信道上建立多个同时连接。虽然MLO有望大幅提高网络吞吐量并减少延迟，但它在密集网络环境中提出了显著的信道分配挑战。当前研究主要集中在静态WiFi 7网络配置下的性能分析和吞吐量优化。相比之下，本文探讨了具有MLO能力的密集WiFi 7网络中的动态信道分配问题。我们将这一挑战形式化为组合优化问题，并利用新的网络性能分析机制。鉴于先前网络信息的固有缺乏，我们将问题建模为多臂 bandit (MAB)框架，以实现在线学习最优信道分配。我们提出的Best-Arm Identification-enabled Monte Carlo Tree Search (BAI-MCTS)算法包括严谨的理论分析，提供了样本复杂性和错误概率的上界。为了进一步减少样本复杂性和增强适用于各种网络场景的泛化能力，我们提出了一种将大型语言模型（LLM）集成到BAI-MCTS算法中的智能动态信道分配算法LLM-BAI-MCTS。数值结果表明，当达到98%最优值时，BAI-MCTS算法的收敛速度比最先进的算法快约50.44%。值得注意的是，在密集网络中，LLM-BAI-MCTS算法的收敛速度提高了超过63.32%。', 'title_zh': '基于MAB与LLM的IEEE 802.11be多链路操作智能信道分配'}
{'arxiv_id': 'arXiv:2506.04583', 'title': 'SUCEA: Reasoning-Intensive Retrieval for Adversarial Fact-checking through Claim Decomposition and Editing', 'authors': 'Hongjun Liu, Yilun Zhao, Arman Cohan, Chen Zhao', 'link': 'https://arxiv.org/abs/2506.04583', 'abstract': 'Automatic fact-checking has recently received more attention as a means of combating misinformation. Despite significant advancements, fact-checking systems based on retrieval-augmented language models still struggle to tackle adversarial claims, which are intentionally designed by humans to challenge fact-checking systems. To address these challenges, we propose a training-free method designed to rephrase the original claim, making it easier to locate supporting evidence. Our modular framework, SUCEA, decomposes the task into three steps: 1) Claim Segmentation and Decontextualization that segments adversarial claims into independent sub-claims; 2) Iterative Evidence Retrieval and Claim Editing that iteratively retrieves evidence and edits the subclaim based on the retrieved evidence; 3) Evidence Aggregation and Label Prediction that aggregates all retrieved evidence and predicts the entailment label. Experiments on two challenging fact-checking datasets demonstrate that our framework significantly improves on both retrieval and entailment label accuracy, outperforming four strong claim-decomposition-based baselines.', 'abstract_zh': '自动事实核查近年来因其对抗 misinformation 而受到更多关注。尽管取得了显著进展，基于检索增强语言模型的事实核查系统仍然难以应对由人类故意设计的对抗性声明。为应对这些挑战，我们提出了一种无需训练的方法，旨在重新表述原始声明，使其更容易找到支持性证据。我们的模块化框架 SUCEA 将任务分解为三个步骤：1) 声明分段与脱嵌以将对抗性声明拆分为独立子声明；2) 迭代证据检索与声明编辑，根据检索到的证据迭代检索证据并编辑子声明；3) 证据聚合与标签预测，整合所有检索到的证据并预测涵摄标签。实验结果表明，我们的框架在检索和涵摄标签准确性上均显著优于四种强大的声明分解基线。', 'title_zh': 'SUCEA：通过论断分解和编辑进行推理密集型对抗事实核查检索'}
{'arxiv_id': 'arXiv:2506.04556', 'title': 'BESA: Boosting Encoder Stealing Attack with Perturbation Recovery', 'authors': 'Xuhao Ren, Haotian Liang, Yajie Wang, Chuan Zhang, Zehui Xiong, Liehuang Zhu', 'link': 'https://arxiv.org/abs/2506.04556', 'abstract': 'To boost the encoder stealing attack under the perturbation-based defense that hinders the attack performance, we propose a boosting encoder stealing attack with perturbation recovery named BESA. It aims to overcome perturbation-based defenses. The core of BESA consists of two modules: perturbation detection and perturbation recovery, which can be combined with canonical encoder stealing attacks. The perturbation detection module utilizes the feature vectors obtained from the target encoder to infer the defense mechanism employed by the service provider. Once the defense mechanism is detected, the perturbation recovery module leverages the well-designed generative model to restore a clean feature vector from the perturbed one. Through extensive evaluations based on various datasets, we demonstrate that BESA significantly enhances the surrogate encoder accuracy of existing encoder stealing attacks by up to 24.63\\% when facing state-of-the-art defenses and combinations of multiple defenses.', 'abstract_zh': '基于扰动恢复的增强编码器窃取攻击：BESA', 'title_zh': 'BESA: 基于扰动恢复的编码器窃取攻击增强technique'}
{'arxiv_id': 'arXiv:2506.04536', 'title': 'NOBLE -- Neural Operator with Biologically-informed Latent Embeddings to Capture Experimental Variability in Biological Neuron Models', 'authors': 'Luca Ghafourpour, Valentin Duruisseaux, Bahareh Tolooshams, Philip H. Wong, Costas A. Anastassiou, Anima Anandkumar', 'link': 'https://arxiv.org/abs/2506.04536', 'abstract': 'Characterizing the diverse computational properties of human neurons via multimodal electrophysiological, transcriptomic, and morphological data provides the foundation for constructing and validating bio-realistic neuron models that can advance our understanding of fundamental mechanisms underlying brain function. However, current modeling approaches remain constrained by the limited availability and intrinsic variability of experimental neuronal data. To capture variability, ensembles of deterministic models are often used, but are difficult to scale as model generation requires repeating computationally expensive optimization for each neuron. While deep learning is becoming increasingly relevant in this space, it fails to capture the full biophysical complexity of neurons, their nonlinear voltage dynamics, and variability. To address these shortcomings, we introduce NOBLE, a neural operator framework that learns a mapping from a continuous frequency-modulated embedding of interpretable neuron features to the somatic voltage response induced by current injection. Trained on data generated from biophysically realistic neuron models, NOBLE predicts distributions of neural dynamics accounting for the intrinsic experimental variability. Unlike conventional bio-realistic neuron models, interpolating within the embedding space offers models whose dynamics are consistent with experimentally observed responses. NOBLE is the first scaled-up deep learning framework validated on real experimental data, enabling efficient generation of synthetic neurons that exhibit trial-to-trial variability and achieve a $4200\\times$ speedup over numerical solvers. To this end, NOBLE captures fundamental neural properties, opening the door to a better understanding of cellular composition and computations, neuromorphic architectures, large-scale brain circuits, and general neuroAI applications.', 'abstract_zh': '通过多模态电生理、转录组和形态学数据表征人类神经元的多样计算属性为构建和验证生物现实神经元模型奠定了基础，这些模型能够推进我们对脑功能基本机制的理解。然而，当前的建模方法仍然受到实验神经元数据有限性和内在变异性限制。为了捕捉这种变异性，通常使用一组确定性模型，但由于每次生成模型都需要进行计算昂贵的优化，这难以扩大规模。虽然深度学习在这个领域变得越来越相关，但未能捕捉到神经元的完整生物物理复杂性、非线性电压动力学及其变异性。为了解决这些问题，我们引入了NOBLE，一种神经操作符框架，从可解释神经元特征的连续频率调制嵌入到由电流注入引起的胞体电压响应之间的映射进行学习。该模型在生物物理现实神经元模型生成的数据上进行训练，从而预测神经动力学分布，考虑到固有的实验变异性。与传统的生物现实神经元模型不同，在嵌入空间中的插值提供了动力学与实验观察响应一致的模型。NOBLE是首个在真实实验数据上进行验证的扩展规模的深度学习框架，能够高效生成表现出试次间变性的合成神经元，并实现比数值求解器快4200倍的速度提升。通过这种方式，NOBLE捕获了基本的神经属性，为更好地理解细胞组成和计算、类脑架构、大规模脑回路以及通用神经AI应用打开了大门。', 'title_zh': 'NOBLE -- 基于生物学信息潜在嵌入的神经运算子，用于捕捉生物神经元模型中的实验变异性'}
{'arxiv_id': 'arXiv:2506.04515', 'title': 'The Latent Space Hypothesis: Toward Universal Medical Representation Learning', 'authors': 'Salil Patel', 'link': 'https://arxiv.org/abs/2506.04515', 'abstract': "Medical data range from genomic sequences and retinal photographs to structured laboratory results and unstructured clinical narratives. Although these modalities appear disparate, many encode convergent information about a single underlying physiological state. The Latent Space Hypothesis frames each observation as a projection of a unified, hierarchically organized manifold -- much like shadows cast by the same three-dimensional object. Within this learned geometric representation, an individual's health status occupies a point, disease progression traces a trajectory, and therapeutic intervention corresponds to a directed vector. Interpreting heterogeneous evidence in a shared space provides a principled way to re-examine eponymous conditions -- such as Parkinson's or Crohn's -- that often mask multiple pathophysiological entities and involve broader anatomical domains than once believed. By revealing sub-trajectories and patient-specific directions of change, the framework supplies a quantitative rationale for personalised diagnosis, longitudinal monitoring, and tailored treatment, moving clinical practice away from grouping by potentially misleading labels toward navigation of each person's unique trajectory. Challenges remain -- bias amplification, data scarcity for rare disorders, privacy, and the correlation-causation divide -- but scale-aware encoders, continual learning on longitudinal data streams, and perturbation-based validation offer plausible paths forward.", 'abstract_zh': '医学数据包括基因组序列、视网膜照片、结构化的实验室结果以及非结构化的临床病历。尽管这些模态看似不同，但它们常常包含了关于单一生理状态的共通信息。潜在空间假说将每项观察视为一个统一、分层组织流形的投影——就像同一三个维度物体投下的阴影。在这种学习到的几何表示中，个体的健康状况占据一个点，疾病进展绘制出一条轨迹，而治疗干预对应于一个定向向量。在共享空间中解释异质性证据为重新审视帕金森病或克罗恩病等同名病症提供了一种合乎逻辑的方法，这些病症往往掩盖了多种病理生理实体，并涉及比过去所认为的更广泛的解剖区域。通过揭示子轨迹和患者特异性的变化方向，该框架为个性化诊断、纵向监测和个性化治疗提供了定量依据，将临床实践从基于可能误导性的标签分类向导航每个人独特轨迹转变。仍存在挑战——如偏差放大、稀有疾病的缺乏数据、隐私问题以及因果推断的差异——但意识尺度编码器、基于纵向数据流的持续学习以及基于扰动的验证提供了可行的前进路径。', 'title_zh': '潜在空间假设：通往通用医学表示学习的途径'}
{'arxiv_id': 'arXiv:2506.04479', 'title': 'Comparative performance of ensemble models in predicting dental provider types: insights from fee-for-service data', 'authors': 'Mohammad Subhi Al-Batah, Muhyeeddin Alqaraleh, Mowafaq Salem Alzboon, Abdullah Alourani', 'link': 'https://arxiv.org/abs/2506.04479', 'abstract': 'Dental provider classification plays a crucial role in optimizing healthcare resource allocation and policy planning. Effective categorization of providers, such as standard rendering providers and safety net clinic (SNC) providers, enhances service delivery to underserved populations. This study aimed to evaluate the performance of machine learning models in classifying dental providers using a 2018 dataset. A dataset of 24,300 instances with 20 features was analyzed, including beneficiary and service counts across fee-for-service (FFS), Geographic Managed Care, and Pre-Paid Health Plans. Providers were categorized by delivery system and patient age groups (0-20 and 21+). Despite 38.1% missing data, multiple machine learning algorithms were tested, including k-Nearest Neighbors (kNN), Decision Trees, Support Vector Machines (SVM), Stochastic Gradient Descent (SGD), Random Forest, Neural Networks, and Gradient Boosting. A 10-fold cross-validation approach was applied, and models were evaluated using AUC, classification accuracy (CA), F1-score, precision, and recall. Neural Networks achieved the highest AUC (0.975) and CA (94.1%), followed by Random Forest (AUC: 0.948, CA: 93.0%). These models effectively handled imbalanced data and complex feature interactions, outperforming traditional classifiers like Logistic Regression and SVM. Advanced machine learning techniques, particularly ensemble and deep learning models, significantly enhance dental workforce classification. Their integration into healthcare analytics can improve provider identification and resource distribution, benefiting underserved populations.', 'abstract_zh': '牙科服务提供者分类在优化健康资源分配和政策规划中扮演着重要角色。有效的服务提供者分类，如标准服务提供者和安全网诊所（SNC）提供者，可以增强对未服务群体的服务交付。本研究旨在评估机器学习模型在使用2018年数据集分类牙科提供者方面的性能。分析了一个包含24,300个实例和20个特征的数据集，其中包括按服务方式（按服务付费、地理管理护理和预付费健康计划）和服务对象（受益人和患者）的治疗次数和服务次数。提供者根据服务体系和患者年龄组（0-20岁和21+岁）进行分类。尽管有38.1%的数据缺失，但仍测试了多种机器学习算法，包括k-最近邻（kNN）、决策树、支持向量机（SVM）、随机梯度下降（SGD）、随机森林、神经网络和梯度提升。应用了10折交叉验证方法，并使用AUC、分类准确率（CA）、F1分数、精确率和召回率评估模型。神经网络实现了最高AUC（0.975）和CA（94.1%），其次是随机森林（AUC：0.948，CA：93.0%）。这些模型有效地处理了不平衡数据和复杂特征相互作用，优于传统的分类器如逻辑回归和SVM。先进的机器学习技术，尤其是集成和深度学习模型，显著提升了牙科劳动力分类的性能。将这些技术集成到健康医疗分析中可以提高服务提供者识别和资源配置，从而惠及未服务群体。', 'title_zh': '基于费用报销数据的集成模型在预测牙科提供者类型方面的表现比较：见解'}
{'arxiv_id': 'arXiv:2506.04474', 'title': 'Classifying Dental Care Providers Through Machine Learning with Features Ranking', 'authors': 'Mohammad Subhi Al-Batah, Mowafaq Salem Alzboon, Muhyeeddin Alqaraleh, Mohammed Hasan Abu-Arqoub, Rashiq Rafiq Marie', 'link': 'https://arxiv.org/abs/2506.04474', 'abstract': 'This study investigates the application of machine learning (ML) models for classifying dental providers into two categories - standard rendering providers and safety net clinic (SNC) providers - using a 2018 dataset of 24,300 instances with 20 features. The dataset, characterized by high missing values (38.1%), includes service counts (preventive, treatment, exams), delivery systems (FFS, managed care), and beneficiary demographics. Feature ranking methods such as information gain, Gini index, and ANOVA were employed to identify critical predictors, revealing treatment-related metrics (TXMT_USER_CNT, TXMT_SVC_CNT) as top-ranked features. Twelve ML models, including k-Nearest Neighbors (kNN), Decision Trees, Support Vector Machines (SVM), Stochastic Gradient Descent (SGD), Random Forest, Neural Networks, and Gradient Boosting, were evaluated using 10-fold cross-validation. Classification accuracy was tested across incremental feature subsets derived from rankings. The Neural Network achieved the highest accuracy (94.1%) using all 20 features, followed by Gradient Boosting (93.2%) and Random Forest (93.0%). Models showed improved performance as more features were incorporated, with SGD and ensemble methods demonstrating robustness to missing data. Feature ranking highlighted the dominance of treatment service counts and annotation codes in distinguishing provider types, while demographic variables (AGE_GROUP, CALENDAR_YEAR) had minimal impact. The study underscores the importance of feature selection in enhancing model efficiency and accuracy, particularly in imbalanced healthcare datasets. These findings advocate for integrating feature-ranking techniques with advanced ML algorithms to optimize dental provider classification, enabling targeted resource allocation for underserved populations.', 'abstract_zh': '本研究 investigate 了使用机器学习（ML）模型对牙科提供者进行分类的应用，将其分为标准渲染提供者和安全网诊所（SNC）提供者两类，使用的是2018年的数据集，包含24,300个实例和20个特征。数据集具有较高的缺失值（38.1%），包括服务计数（预防性、治疗、检查）、交付系统（FFS、管理护理）和受益人人口统计学数据。通过信息增益、基尼指数和ANOVA等特征排名方法来识别关键预测因子，结果显示与治疗相关的度量（TXMT_USER_CNT、TXMT_SVC_CNT）是顶级特征。研究评估了包括k-近邻（kNN）、决策树、支持向量机（SVM）、随机梯度下降（SGD）、随机森林、神经网络和梯度提升在内的12种ML模型，采用了10折交叉验证。分类准确性基于排名衍生的逐步特征子集进行了测试。神经网络在使用所有20个特征时达到了最高的准确性（94.1%），其次是梯度提升（93.2%）和随机森林（93.0%）。随着特征数量的增加，模型性能有所提升，随机梯度下降和集成方法对缺失数据具有鲁棒性。特征排名突出了治疗服务计数和注释代码在区分提供者类型方面的主导地位，而人口统计变量（AGE_GROUP、CALENDAR_YEAR）的影响较小。本研究强调了在不平衡的医疗保健数据集增强模型效率和准确性的特征选择的重要性。这些发现提倡将特征排名技术与先进的ML算法相结合，以优化牙科提供者分类，从而为未充分服务的人群分配目标化的资源。', 'title_zh': '通过特征排序进行机器学习分类的牙科护理提供者分类'}
{'arxiv_id': 'arXiv:2506.04467', 'title': 'Diffusion Transformer-based Universal Dose Denoising for Pencil Beam Scanning Proton Therapy', 'authors': 'Yuzhen Ding, Jason Holmes, Hongying Feng, Martin Bues, Lisa A. McGee, Jean-Claude M. Rwigema, Nathan Y. Yu, Terence S. Sio, Sameer R. Keole, William W. Wong, Steven E. Schild, Jonathan B. Ashman, Sujay A. Vora, Daniel J. Ma, Samir H. Patel, Wei Liu', 'link': 'https://arxiv.org/abs/2506.04467', 'abstract': 'Purpose: Intensity-modulated proton therapy (IMPT) offers precise tumor coverage while sparing organs at risk (OARs) in head and neck (H&N) cancer. However, its sensitivity to anatomical changes requires frequent adaptation through online adaptive radiation therapy (oART), which depends on fast, accurate dose calculation via Monte Carlo (MC) simulations. Reducing particle count accelerates MC but degrades accuracy. To address this, denoising low-statistics MC dose maps is proposed to enable fast, high-quality dose generation.\nMethods: We developed a diffusion transformer-based denoising framework. IMPT plans and 3D CT images from 80 H&N patients were used to generate noisy and high-statistics dose maps using MCsquare (1 min and 10 min per plan, respectively). Data were standardized into uniform chunks with zero-padding, normalized, and transformed into quasi-Gaussian distributions. Testing was done on 10 H&N, 10 lung, 10 breast, and 10 prostate cancer cases, preprocessed identically. The model was trained with noisy dose maps and CT images as input and high-statistics dose maps as ground truth, using a combined loss of mean square error (MSE), residual loss, and regional MAE (focusing on top/bottom 10% dose voxels). Performance was assessed via MAE, 3D Gamma passing rate, and DVH indices.\nResults: The model achieved MAEs of 0.195 (H&N), 0.120 (lung), 0.172 (breast), and 0.376 Gy[RBE] (prostate). 3D Gamma passing rates exceeded 92% (3%/2mm) across all sites. DVH indices for clinical target volumes (CTVs) and OARs closely matched the ground truth.\nConclusion: A diffusion transformer-based denoising framework was developed and, though trained only on H&N data, generalizes well across multiple disease sites.', 'abstract_zh': '目的：强度调制质子疗法（IMPT）在头颈癌治疗中能够实现精准的肿瘤覆盖同时减少对危及器官（OARs）的照射，但其对解剖变化的敏感性要求通过在线适应性放疗（oART）频繁调整，这依赖于快速、准确的Monte Carlo（MC）模拟剂量计算。降低粒子数目可以加速MC模拟，但会降低准确性。为此，提出通过去噪低统计量MC剂量图来实现快速高质量剂量生成。\n\n方法：我们开发了一种基于扩散变换器的去噪框架。使用MCsquare生成了80例头颈癌患者的IMPT计划和3D CT图像，并分别用1分钟和10分钟计算出噪声剂量图和高统计量剂量图。数据被标准化为均匀的块，并进行了零填充处理和归一化，转化为准高斯分布。测试在10例头颈癌、10例肺癌、10例乳腺癌和10例前列腺癌病例上进行，所有病例预先进行了相同的处理。模型使用有噪声的剂量图和CT图像作为输入，高统计量剂量图作为真实值，使用均方误差（MSE）、残差损失和区域MAE（集中在剂量最高/最低的10%体素）的组合损失进行训练。性能通过使用MAE、3D剂量率通过率和DVH指数进行了评估。\n\n结果：模型在头颈癌、肺癌、乳腺癌和前列腺癌中的MAE分别为0.195 Gy[RBE]、0.120 Gy[RBE]、0.172 Gy[RBE]和0.376 Gy[RBE]。3D剂量率通过率在所有部位均超过92%（3%/2mm）。CTV和OARs的DVH指数与真实值高度匹配。\n\n结论：开发了一种基于扩散变换器的去噪框架，虽然仅通过头颈癌数据进行训练，但在多个疾病部位具有良好的泛化能力。', 'title_zh': '基于扩散变换器的通用剂量去噪方法用于-pencil束扫描质子疗法'}
{'arxiv_id': 'arXiv:2506.04461', 'title': 'Behavioural vs. Representational Systematicity in End-to-End Models: An Opinionated Survey', 'authors': 'Ivan Vegner, Sydelle de Souza, Valentin Forch, Martha Lewis, Leonidas A.A. Doumas', 'link': 'https://arxiv.org/abs/2506.04461', 'abstract': "A core aspect of compositionality, systematicity is a desirable property in ML models as it enables strong generalization to novel contexts. This has led to numerous studies proposing benchmarks to assess systematic generalization, as well as models and training regimes designed to enhance it. Many of these efforts are framed as addressing the challenge posed by Fodor and Pylyshyn. However, while they argue for systematicity of representations, existing benchmarks and models primarily focus on the systematicity of behaviour. We emphasize the crucial nature of this distinction. Furthermore, building on Hadley's (1994) taxonomy of systematic generalization, we analyze the extent to which behavioural systematicity is tested by key benchmarks in the literature across language and vision. Finally, we highlight ways of assessing systematicity of representations in ML models as practiced in the field of mechanistic interpretability.", 'abstract_zh': '组成性中的系统性是一个 desirable property 在 ML 模型中，因为它能够使模型在新情境中表现出强大的泛化能力。这导致了大量研究提出评估系统性泛化的基准，并设计模型和训练制度以增强这种能力。尽管这些努力多被框定为解决 Fodor 和 Pylyshyn 提出的挑战，但它们在论代理表示的系统性的同时，现有的基准和模型主要集中在行为的系统性上。我们强调了这种区别的关键性。此外，基于 Hadley (1994) 对系统性泛化的分类，我们分析了文献中语言和视觉领域关键基准到何种程度测试了行为的系统性。最后，我们指出了在机械解释领域评估模型表示系统性的方法。', 'title_zh': '端到端模型中行为系统性和表示系统性的对比：一份观点性的综述'}
{'arxiv_id': 'arXiv:2506.04452', 'title': 'An Expansion-Based Approach for Quantified Integer Programming', 'authors': 'Michael Hartisch, Leroy Chew', 'link': 'https://arxiv.org/abs/2506.04452', 'abstract': 'Quantified Integer Programming (QIP) bridges multiple domains by extending Quantified Boolean Formulas (QBF) to incorporate general integer variables and linear constraints while also generalizing Integer Programming through variable quantification. As a special case of Quantified Constraint Satisfaction Problems (QCSP), QIP provides a versatile framework for addressing complex decision-making scenarios. Additionally, the inclusion of a linear objective function enables QIP to effectively model multistage robust discrete linear optimization problems, making it a powerful tool for tackling uncertainty in optimization.\nWhile two primary solution paradigms exist for QBF -- search-based and expansion-based approaches -- only search-based methods have been explored for QIP and QCSP. We introduce an expansion-based approach for QIP using Counterexample-Guided Abstraction Refinement (CEGAR), adapting techniques from QBF. We extend this methodology to tackle multistage robust discrete optimization problems with linear constraints and further embed it in an optimization framework, enhancing its applicability. Our experimental results highlight the advantages of this approach, demonstrating superior performance over existing search-based solvers for QIP in specific instances. Furthermore, the ability to model problems using linear constraints enables notable performance gains over state-of-the-art expansion-based solvers for QBF.', 'abstract_zh': '量化整数规划（QIP）通过将量化的布尔公式（QBF）扩展到包含一般整数变量和线性约束，同时推广整数规划并通过变量量化，架起了多个领域的桥梁。作为量化约束满足问题（QCSP）的特殊案例，QIP为解决复杂的决策场景提供了灵活的框架。此外，线性目标函数的引入使QIP能够有效地模拟具有线性约束的多阶段鲁棒离散线性优化问题，使其成为处理优化中不确定性的一种强大工具。虽然存在两种主要的QBF求解范式——搜索基和扩展基方法——仅搜索基方法被探索用于QIP和QCSP。我们提出了一种基于扩展的方法来解决QIP，使用基于反例指引的抽象细化（CEGAR）方法，借鉴了QBF的技术。我们进一步将此方法扩展以解决具有线性约束的多阶段鲁棒离散优化问题，并将其嵌入优化框架中，增强了其适用性。实验结果表明了该方法的优势，在特定实例中优于现有的基于搜索的QIP求解器。此外，使用线性约束建模问题的能力还使其在QBF最先进的基于扩展的求解器中表现出显著的性能优势。', 'title_zh': '基于扩展的方法在量化整数规划中的应用'}
{'arxiv_id': 'arXiv:2506.04434', 'title': 'Grokking and Generalization Collapse: Insights from \\texttt{HTSR} theory', 'authors': 'Hari K. Prakash, Charles H. Martin', 'link': 'https://arxiv.org/abs/2506.04434', 'abstract': 'We study the well-known grokking phenomena in neural networks (NNs) using a 3-layer MLP trained on 1 k-sample subset of MNIST, with and without weight decay, and discover a novel third phase -- \\emph{anti-grokking} -- that occurs very late in training and resembles but is distinct from the familiar \\emph{pre-grokking} phases: test accuracy collapses while training accuracy stays perfect. This late-stage collapse is distinct, from the known pre-grokking and grokking phases, and is not detected by other proposed grokking progress measures. Leveraging Heavy-Tailed Self-Regularization HTSR through the open-source WeightWatcher tool, we show that the HTSR layer quality metric $\\alpha$ alone delineates all three phases, whereas the best competing metrics detect only the first two. The \\emph{anti-grokking} is revealed by training for $10^7$ and is invariably heralded by $\\alpha < 2$ and the appearance of \\emph{Correlation Traps} -- outlier singular values in the randomized layer weight matrices that make the layer weight matrix atypical and signal overfitting of the training set. Such traps are verified by visual inspection of the layer-wise empirical spectral densities, and by using Kolmogorov--Smirnov tests on randomized spectra. Comparative metrics, including activation sparsity, absolute weight entropy, circuit complexity, and $l^2$ weight norms track pre-grokking and grokking but fail to distinguish grokking from anti-grokking. This discovery provides a way to measure overfitting and generalization collapse without direct access to the test data. These results strengthen the claim that the \\emph{HTSR} $\\alpha$ provides universal layer-convergence target at $\\alpha \\approx 2$ and underscore the value of using the HTSR alpha $(\\alpha)$ metric as a measure of generalization.', 'abstract_zh': '我们使用针对MNIST数据集中1 k样本子集进行训练的3层MLP网络研究了神经网络（NNs）中熟知的grokking现象，并加入了权重衰减进行研究，发现了一个新的第三阶段——反grokking——这一阶段发生在训练的很晚期，并类似于但不同于熟悉的pre-grokking阶段：测试准确性崩溃而训练准确性保持完美。这种晚期的崩溃与已知的pre-grokking和grokking阶段不同，并且不会被其他提出的grokking进展度量所检测。利用开源工具WeightWatcher中的重尾自我正则化HTSR，我们发现仅通过$\\alpha$层质量度量即可区分这三个阶段，而最好的竞争度量仅能区分前两个阶段。反grokking通过训练$10^7$次得到揭示，并且每次都由$\\alpha < 2$和出现相关陷阱——随机层权重矩阵中的异常奇异值导致层权重矩阵非典型并指示训练集的过拟合——所预示。这些陷阱通过层间经验谱密度的视觉检查和使用柯尔莫哥洛夫-斯米尔诺夫检验来验证。比较度量，包括激活稀疏性、绝对权重熵、电路复杂性和$l^2$权重范数，可以跟踪pre-grokking和grokking，但无法区分grokking和反grokking。这一发现提供了一种在无直接测试数据访问的情况下衡量过拟合和泛化崩溃的方法。这些结果增强了HTSR $\\alpha$提供在$\\alpha \\approx 2$时的通用层收敛目标的论断，并强调了使用HTSR $\\alpha$度量作为泛化衡量标准的价值。', 'title_zh': '理解崩塌与泛化消失：从HTSR理论的视角'}
{'arxiv_id': 'arXiv:2506.04409', 'title': 'Empaths at SemEval-2025 Task 11: Retrieval-Augmented Approach to Perceived Emotions Prediction', 'authors': 'Lev Morozov, Aleksandr Mogilevskii, Alexander Shirnin', 'link': 'https://arxiv.org/abs/2506.04409', 'abstract': 'This paper describes EmoRAG, a system designed to detect perceived emotions in text for SemEval-2025 Task 11, Subtask A: Multi-label Emotion Detection. We focus on predicting the perceived emotions of the speaker from a given text snippet, labeling it with emotions such as joy, sadness, fear, anger, surprise, and disgust. Our approach does not require additional model training and only uses an ensemble of models to predict emotions. EmoRAG achieves results comparable to the best performing systems, while being more efficient, scalable, and easier to implement.', 'abstract_zh': 'EmoRAG：SemEval-2025 Task 11 Subtask A的多标签情感检测系统', 'title_zh': 'Empaths at SemEval-2025 任务11：基于检索增强的方法预测感知情绪'}
{'arxiv_id': 'arXiv:2506.04390', 'title': 'Through the Stealth Lens: Rethinking Attacks and Defenses in RAG', 'authors': 'Sarthak Choudhary, Nils Palumbo, Ashish Hooda, Krishnamurthy Dj Dvijotham, Somesh Jha', 'link': 'https://arxiv.org/abs/2506.04390', 'abstract': 'Retrieval-augmented generation (RAG) systems are vulnerable to attacks that inject poisoned passages into the retrieved set, even at low corruption rates. We show that existing attacks are not designed to be stealthy, allowing reliable detection and mitigation. We formalize stealth using a distinguishability-based security game. If a few poisoned passages are designed to control the response, they must differentiate themselves from benign ones, inherently compromising stealth. This motivates the need for attackers to rigorously analyze intermediate signals involved in generation$\\unicode{x2014}$such as attention patterns or next-token probability distributions$\\unicode{x2014}$to avoid easily detectable traces of manipulation. Leveraging attention patterns, we propose a passage-level score$\\unicode{x2014}$the Normalized Passage Attention Score$\\unicode{x2014}$used by our Attention-Variance Filter algorithm to identify and filter potentially poisoned passages. This method mitigates existing attacks, improving accuracy by up to $\\sim 20 \\%$ over baseline defenses. To probe the limits of attention-based defenses, we craft stealthier adaptive attacks that obscure such traces, achieving up to $35 \\%$ attack success rate, and highlight the challenges in improving stealth.', 'abstract_zh': '基于检索的生成系统（RAG）易受注入污染段落的攻击，即使在低污染率下也是如此。现有的攻击并非设计为隐蔽，允许可靠的检测和缓解。我们使用可分性为基础的安全博弈来形式化隐蔽性。如果少量污染段落旨在控制响应，它们必须与其他良性段落区分开来，从而本质上有损隐蔽性。这促使攻击者需要严格分析生成过程中的中间信号，如注意力模式或下一个标记的概率分布，以避免易于检测的操纵痕迹。利用注意力模式，我们提出了一种段落级得分——归一化段落注意力得分——作为我们的注意力方差过滤算法的一部分，用于识别和过滤潜在的污染段落。该方法能够缓解现有攻击，相较于基线防御提高了约20%的准确性。为了探索基于注意力的防御的极限，我们构建了更隐蔽的自适应攻击，力求隐藏这些痕迹，攻击成功率可达35%，并突显了提高隐蔽性所面临的挑战。', 'title_zh': 'Through the Stealth Lens: 重新思考RAG中的攻击与防御'}
{'arxiv_id': 'arXiv:2506.04379', 'title': 'Visualizing and Controlling Cortical Responses Using Voxel-Weighted Activation Maximization', 'authors': 'Matthew W. Shinkle, Mark D. Lescroart', 'link': 'https://arxiv.org/abs/2506.04379', 'abstract': 'Deep neural networks (DNNs) trained on visual tasks develop feature representations that resemble those in the human visual system. Although DNN-based encoding models can accurately predict brain responses to visual stimuli, they offer limited insight into the specific features driving these responses. Here, we demonstrate that activation maximization -- a technique designed to interpret vision DNNs -- can be applied to DNN-based encoding models of the human brain. We extract and adaptively downsample activations from multiple layers of a pretrained Inception V3 network, then use linear regression to predict fMRI responses. This yields a full image-computable model of brain responses. Next, we apply activation maximization to generate images optimized for predicted responses in individual cortical voxels. We find that these images contain visual characteristics that qualitatively correspond with known selectivity and enable exploration of selectivity across the visual cortex. We further extend our method to whole regions of interest (ROIs) of the brain and validate its efficacy by presenting these images to human participants in an fMRI study. We find that the generated images reliably drive activity in targeted regions across both low- and high-level visual areas and across subjects. These results demonstrate that activation maximization can be successfully applied to DNN-based encoding models. By addressing key limitations of alternative approaches that require natively generative models, our approach enables flexible characterization and modulation of responses across the human visual system.', 'abstract_zh': '基于深度神经网络的人脑编码模型的激活最大化方法：揭示视觉响应的视觉特征与选择性', 'title_zh': '使用体素加权激活最大化可视化和控制皮层响应'}
{'arxiv_id': 'arXiv:2506.04373', 'title': 'Mechanistic Decomposition of Sentence Representations', 'authors': 'Matthieu Tehenan, Vikram Natarajan, Jonathan Michala, Milton Lin, Juri Opitz', 'link': 'https://arxiv.org/abs/2506.04373', 'abstract': 'Sentence embeddings are central to modern NLP and AI systems, yet little is known about their internal structure. While we can compare these embeddings using measures such as cosine similarity, the contributing features are not human-interpretable, and the content of an embedding seems untraceable, as it is masked by complex neural transformations and a final pooling operation that combines individual token embeddings. To alleviate this issue, we propose a new method to mechanistically decompose sentence embeddings into interpretable components, by using dictionary learning on token-level representations. We analyze how pooling compresses these features into sentence representations, and assess the latent features that reside in a sentence embedding. This bridges token-level mechanistic interpretability with sentence-level analysis, making for more transparent and controllable representations. In our studies, we obtain several interesting insights into the inner workings of sentence embedding spaces, for instance, that many semantic and syntactic aspects are linearly encoded in the embeddings.', 'abstract_zh': '句向量是现代NLP和AI系统中的核心，但对其内部结构知之甚少。尽管可以使用余弦相似度等度量来比较这些向量，但贡献的特征对人类是不可解释的，句向量的内容似乎无法追溯，因为它们被复杂的神经变换和最终的池化操作所掩盖，后者将单个词项向量融合在一起。为了解决这一问题，我们提出了一种新方法，通过在词项级表示上使用字典学习来机械地分解句向量，从而获得可解释的组件。我们分析了池化如何将这些特征压缩成句向量表示，并评估句向量中潜藏的特征。这将词项级机械可解释性与句级分析结合起来，使表示更加透明可控。在我们的研究中，我们获得了句向量空间内部运作机制的一些有趣见解，例如，许多语义和句法方面在向量中是线性编码的。', 'title_zh': '句子表示的机理分解'}
{'arxiv_id': 'arXiv:2506.04303', 'title': 'Knowledge-guided Contextual Gene Set Analysis Using Large Language Models', 'authors': 'Zhizheng Wang, Chi-Ping Day, Chih-Hsuan Wei, Qiao Jin, Robert Leaman, Yifan Yang, Shubo Tian, Aodong Qiu, Yin Fang, Qingqing Zhu, Xinghua Lu, Zhiyong Lu', 'link': 'https://arxiv.org/abs/2506.04303', 'abstract': 'Gene set analysis (GSA) is a foundational approach for interpreting genomic data of diseases by linking genes to biological processes. However, conventional GSA methods overlook clinical context of the analyses, often generating long lists of enriched pathways with redundant, nonspecific, or irrelevant results. Interpreting these requires extensive, ad-hoc manual effort, reducing both reliability and reproducibility. To address this limitation, we introduce cGSA, a novel AI-driven framework that enhances GSA by incorporating context-aware pathway prioritization. cGSA integrates gene cluster detection, enrichment analysis, and large language models to identify pathways that are not only statistically significant but also biologically meaningful. Benchmarking on 102 manually curated gene sets across 19 diseases and ten disease-related biological mechanisms shows that cGSA outperforms baseline methods by over 30%, with expert validation confirming its increased precision and interpretability. Two independent case studies in melanoma and breast cancer further demonstrate its potential to uncover context-specific insights and support targeted hypothesis generation.', 'abstract_zh': '基于上下文的基因集分析（Context-Aware Gene Set Analysis, cGSA）：一种整合生物学意义的新型人工智能驱动框架', 'title_zh': '基于知识导向的上下文基因集分析利用大规模语言模型'}
{'arxiv_id': 'arXiv:2506.04276', 'title': 'Autonomous Collaborative Scheduling of Time-dependent UAVs, Workers and Vehicles for Crowdsensing in Disaster Response', 'authors': 'Lei Han, Yitong Guo, Pengfei Yang, Zhiyong Yu, Liang Wang, Quan Wang, Zhiwen Yu', 'link': 'https://arxiv.org/abs/2506.04276', 'abstract': 'Natural disasters have caused significant losses to human society, and the timely and efficient acquisition of post-disaster environmental information is crucial for the effective implementation of rescue operations. Due to the complexity of post-disaster environments, existing sensing technologies face challenges such as weak environmental adaptability, insufficient specialized sensing capabilities, and limited practicality of sensing solutions. This paper explores the heterogeneous multi-agent online autonomous collaborative scheduling algorithm HoAs-PALN, aimed at achieving efficient collection of post-disaster environmental information. HoAs-PALN is realized through adaptive dimensionality reduction in the matching process and local Nash equilibrium game, facilitating autonomous collaboration among time-dependent UAVs, workers and vehicles to enhance sensing scheduling. (1) In terms of adaptive dimensionality reduction during the matching process, HoAs-PALN significantly reduces scheduling decision time by transforming a five-dimensional matching process into two categories of three-dimensional matching processes; (2) Regarding the local Nash equilibrium game, HoAs-PALN combines the softmax function to optimize behavior selection probabilities and introduces a local Nash equilibrium determination mechanism to ensure scheduling decision performance. Finally, we conducted detailed experiments based on extensive real-world and simulated data. Compared with the baselines (GREEDY, K-WTA, MADL and MARL), HoAs-PALN improves task completion rates by 64.12%, 46.48%, 16.55%, and 14.03% on average, respectively, while each online scheduling decision takes less than 10 seconds, demonstrating its effectiveness in dynamic post-disaster environments.', 'abstract_zh': '自然灾难对人类社会造成了重大损失，及时和高效地获取灾后环境信息对于救援行动的有效实施至关重要。由于灾后环境的复杂性，现有传感技术面临环境适应性弱、专业传感能力不足以及传感解决方案实用性受限等挑战。本文探讨了一种异构多智能体在线自主协同调度算法HoAs-PALN，旨在实现灾后环境信息的有效收集。HoAs-PALN通过匹配过程中自适应降维和局部纳什均衡游戏实现，促进时间依赖的无人机、工人和车辆之间的自主协作，以增强传感调度。通过详细实验基于广泛的现实和模拟数据，与基线算法（GREEDY、K-WTA、MADL和MARL）相比，HoAs-PALN的平均任务完成率分别提高了64.12%、46.48%、16.55%和14.03%，而每次在线调度决策的时间少于10秒，证明了其在动态灾后环境中的有效性。', 'title_zh': '灾害响应中基于时间依赖性的自主协作无人机、工人和车辆协同调度用于 crowdsensing'}
{'arxiv_id': 'arXiv:2506.04268', 'title': 'MUC-G4: Minimal Unsat Core-Guided Incremental Verification for Deep Neural Network Compression', 'authors': 'Jingyang Li, Guoqiang Li', 'link': 'https://arxiv.org/abs/2506.04268', 'abstract': 'The rapid development of deep learning has led to challenges in deploying neural networks on edge devices, mainly due to their high memory and runtime complexity. Network compression techniques, such as quantization and pruning, aim to reduce this complexity while maintaining accuracy. However, existing incremental verification methods often focus only on quantization and struggle with structural changes. This paper presents MUC-G4 (Minimal Unsat Core-Guided Incremental Verification), a novel framework for incremental verification of compressed deep neural networks. It encodes both the original and compressed networks into SMT formulas, classifies changes, and use \\emph{Minimal Unsat Cores (MUCs)} from the original network to guide efficient verification for the compressed network. Experimental results show its effectiveness in handling quantization and pruning, with high proof reuse rates and significant speedup in verification time compared to traditional methods. MUC-G4 hence offers a promising solution for ensuring the safety and reliability of compressed neural networks in practical applications.', 'abstract_zh': '快速发展的深度学习导致了在边缘设备上部署神经网络的挑战，主要原因是它们的高内存和运行时复杂度。网络压缩技术，如量化和剪枝，旨在在保持准确性的前提下减少这一复杂度。然而，现有的增量验证方法往往仅关注量化，并难以处理结构变化。本文提出了一种新型框架MUC-G4（Minimal Unsat Core-Guided Incremental Verification），用于压缩深度神经网络的增量验证。该框架将原始网络和压缩网络编码为SMT公式，分类变化，并利用原始网络的最小不满足内核（MUCs）引导高效的验证。实验结果表明，MUC-G4在处理量化和剪枝方面非常有效，与传统方法相比，验证时间有显著的加速，并且具有较高的证明重用率。因此，MUC-G4为确保压缩神经网络在实际应用中的安全性和可靠性提供了有前景的解决方案。', 'title_zh': 'MUC-G4: 最小不饱和核引导的增量验证方法用于深度神经网络压缩'}
{'arxiv_id': 'arXiv:2506.04265', 'title': 'CORA: Coalitional Rational Advantage Decomposition for Multi-Agent Policy Gradients', 'authors': 'Mengda Ji, Genjiu Xu, Liying Wang', 'link': 'https://arxiv.org/abs/2506.04265', 'abstract': 'This work focuses on the credit assignment problem in cooperative multi-agent reinforcement learning (MARL). Sharing the global advantage among agents often leads to suboptimal policy updates as it fails to account for the distinct contributions of agents. Although numerous methods consider global or individual contributions for credit assignment, a detailed analysis at the coalition level remains lacking in many approaches. This work analyzes the over-updating problem during multi-agent policy updates from a coalition-level perspective. To address this issue, we propose a credit assignment method called Coalitional Rational Advantage Decomposition (CORA). CORA evaluates coalitional advantages via marginal contributions from all possible coalitions and decomposes advantages using the core solution from cooperative game theory, ensuring coalitional rationality. To reduce computational overhead, CORA employs random coalition sampling. Experiments on matrix games, differential games, and multi-agent collaboration benchmarks demonstrate that CORA outperforms strong baselines, particularly in tasks with multiple local optima. These findings highlight the importance of coalition-aware credit assignment for improving MARL performance.', 'abstract_zh': '本研究聚焦于合作多智能体强化学习(MARL)中的信用分配问题。从联盟层面分析多智能体策略更新过程中的过度更新问题，并提出了一种名为Coalitional Rational Advantage Decomposition (CORA)的信用分配方法，通过评价所有可能联盟的边际贡献并使用合作博弈理论的核心解分解优势，确保联盟理性。为了减少计算开销，CORA采用随机联盟采样。实验结果表明，CORA在具有多个局部最优解的任务中显著优于强基线方法，强调了联盟感知信用分配对提高MARL性能的重要性。', 'title_zh': 'CORA: 合作理性优势分解在多智能体策略梯度中的应用'}
{'arxiv_id': 'arXiv:2506.04254', 'title': 'Localized Forest Fire Risk Prediction: A Department-Aware Approach for Operational Decision Support', 'authors': 'Nicolas Caron, Christophe Guyeux, Hassan Noura, Benjamin Aynes', 'link': 'https://arxiv.org/abs/2506.04254', 'abstract': 'Forest fire prediction involves estimating the likelihood of fire ignition or related risk levels in a specific area over a defined time period. With climate change intensifying fire behavior and frequency, accurate prediction has become one of the most pressing challenges in Artificial Intelligence (AI). Traditionally, fire ignition is approached as a binary classification task in the literature. However, this formulation oversimplifies the problem, especially from the perspective of end-users such as firefighters. In general, as is the case in France, firefighting units are organized by department, each with its terrain, climate conditions, and historical experience with fire events. Consequently, fire risk should be modeled in a way that is sensitive to local conditions and does not assume uniform risk across all regions. This paper proposes a new approach that tailors fire risk assessment to departmental contexts, offering more actionable and region-specific predictions for operational use. With this, we present the first national-scale AI benchmark for metropolitan France using state-of-the-art AI models on a relatively unexplored dataset. Finally, we offer a summary of important future works that should be taken into account. Supplementary materials are available on GitHub.', 'abstract_zh': '森林火灾预测涉及估计在特定区域内某一时间段内火灾点火的可能性或相关风险等级。随着气候变化加剧火灾行为和频率，准确的预测已成为人工智能领域最紧迫的挑战之一。传统上，文献中的火灾点火被视作一个二元分类任务。然而，这种表述过于简化了问题，尤其是从消防员等终端用户的角度来看。通常情况下，如France，消防单位按部门组织，每个部门有自己的地形、气候条件和火灾事件的历史经验。因此，火灾风险应根据当地条件建模，而不假设所有地区风险均一。本文提出了一种新的方法，针对部门环境定制火灾风险评估，提供了更具操作性和区域特异性的预测。以此为基础，我们利用最先进的AI模型，在相对未被探索的数据集上构建了法国全国规模的首个AI基准测试。最后，我们总结了未来工作中需要考虑的重要内容。补充材料可在GitHub上获取。', 'title_zh': '局部森林火灾风险预测：面向部门的操作决策支持部门意识方法'}
{'arxiv_id': 'arXiv:2506.04247', 'title': 'The GAIN Model: A Nature-Inspired Neural Network Framework Based on an Adaptation of the Izhikevich Model', 'authors': 'Gage K. R. Hooper', 'link': 'https://arxiv.org/abs/2506.04247', 'abstract': 'While many neural networks focus on layers to process information, the GAIN model uses a grid-based structure to improve biological plausibility and the dynamics of the model. The grid structure helps neurons to interact with their closest neighbors and improve their connections with one another, which is seen in biological neurons. While also being implemented with the Izhikevich model this approach allows for a computationally efficient and biologically accurate simulation that can aid in the development of neural networks, large scale simulations, and the development in the neuroscience field. This adaptation of the Izhikevich model can improve the dynamics and accuracy of the model, allowing for its uses to be specialized but efficient.', 'abstract_zh': 'GAIN模型的网格结构改进及其生物学准确性仿真', 'title_zh': 'GAIN模型：基于Izhikevich模型改进的自然界启发的神经网络框架'}
{'arxiv_id': 'arXiv:2506.04243', 'title': 'Triple Attention Transformer Architecture for Time-Dependent Concrete Creep Prediction', 'authors': 'Warayut Dokduea, Weerachart Tangchirapat, Sompote Youwai', 'link': 'https://arxiv.org/abs/2506.04243', 'abstract': "This paper presents a novel Triple Attention Transformer Architecture for predicting time-dependent concrete creep, addressing fundamental limitations in current approaches that treat time as merely an input parameter rather than modeling the sequential nature of deformation development. By transforming concrete creep prediction into an autoregressive sequence modeling task similar to language processing, our architecture leverages the transformer's self-attention mechanisms to capture long-range dependencies in historical creep patterns. The model implements a triple-stream attention framework incorporating temporal attention for sequential progression, feature attention for material property interactions, and batch attention for inter-sample relationships. Evaluated on experimental datasets with standardized daily measurements spanning 160 days, the architecture achieves exceptional performance with mean absolute percentage error of 1.63% and R2 values of 0.999 across all datasets, substantially outperforming traditional empirical models and existing machine learning approaches. Ablation studies confirm the critical role of attention mechanisms, with attention pooling contributing most significantly to model performance. SHAP analysis reveals Young's modulus as the primary predictive feature, followed by density and compressive strength, providing interpretability essential for engineering applications. A deployed web-based interface facilitates practical implementation, enabling real-time predictions using standard laboratory parameters. This work establishes the viability of applying transformer architectures to materials science problems, demonstrating the potential for data-driven approaches to revolutionize structural behavior prediction and engineering design practices.", 'abstract_zh': '基于三 attention 机制的新型变换器架构用于预测时间依赖性混凝土徐变', 'title_zh': '时间依赖混凝土徐变预测的三重注意力变压器架构'}
{'arxiv_id': 'arXiv:2506.04237', 'title': 'A Comprehensive Survey on the Risks and Limitations of Concept-based Models', 'authors': 'Sanchit Sinha, Aidong Zhang', 'link': 'https://arxiv.org/abs/2506.04237', 'abstract': "Concept-based Models are a class of inherently explainable networks that improve upon standard Deep Neural Networks by providing a rationale behind their predictions using human-understandable `concepts'. With these models being highly successful in critical applications like medical diagnosis and financial risk prediction, there is a natural push toward their wider adoption in sensitive domains to instill greater trust among diverse stakeholders. However, recent research has uncovered significant limitations in the structure of such networks, their training procedure, underlying assumptions, and their susceptibility to adversarial vulnerabilities. In particular, issues such as concept leakage, entangled representations, and limited robustness to perturbations pose challenges to their reliability and generalization. Additionally, the effectiveness of human interventions in these models remains an open question, raising concerns about their real-world applicability. In this paper, we provide a comprehensive survey on the risks and limitations associated with Concept-based Models. In particular, we focus on aggregating commonly encountered challenges and the architecture choices mitigating these challenges for Supervised and Unsupervised paradigms. We also examine recent advances in improving their reliability and discuss open problems and promising avenues of future research in this domain.", 'abstract_zh': '基于概念的模型是一类本质上可解释的网络，通过使用人类可理解的“概念”来提供其预测背后的理由，从而改进了标准深度神经网络。随着这类模型在医学诊断和金融风险预测等关键应用中取得了巨大成功，它们自然被推向了敏感领域的广泛应用，以在不同利益相关者中建立更大的信任。然而，近期的研究揭示了这类网络结构、训练过程、底层假设以及对抗性脆弱性方面的显著局限性。特别是概念泄露、纠缠表示以及对扰动的有限鲁棒性等具体问题，对这些模型的可靠性和泛化能力构成了挑战。此外，人类干预在这些模型中的有效性仍是一个开放问题，引发了对其实际应用性的担忧。在本文中，我们提供了关于基于概念的模型的风险和局限性的全面综述。特别是，我们重点关注两类范式中经常遇到的挑战及其缓解这些挑战的架构选择。此外，我们评估了近期提高其可靠性的进展，并讨论了该领域未来研究方向中的开放问题和有希望的途径。', 'title_zh': '基于概念的模型的风险和局限性综述'}
{'arxiv_id': 'arXiv:2506.04235', 'title': 'Benchmark for Antibody Binding Affinity Maturation and Design', 'authors': 'Xinyan Zhao, Yi-Ching Tang, Akshita Singh, Victor J Cantu, KwanHo An, Junseok Lee, Adam E Stogsdill, Ashwin Kumar Ramesh, Zhiqiang An, Xiaoqian Jiang, Yejin Kim', 'link': 'https://arxiv.org/abs/2506.04235', 'abstract': "We introduce AbBiBench (Antibody Binding Benchmarking), a benchmarking framework for antibody binding affinity maturation and design. Unlike existing antibody evaluation strategies that rely on antibody alone and its similarity to natural ones (e.g., amino acid identity rate, structural RMSD), AbBiBench considers an antibody-antigen (Ab-Ag) complex as a functional unit and evaluates the potential of an antibody design binding to given antigen by measuring protein model's likelihood on the Ab-Ag complex. We first curate, standardize, and share 9 datasets containing 9 antigens (involving influenza, anti-lysozyme, HER2, VEGF, integrin, and SARS-CoV-2) and 155,853 heavy chain mutated antibodies. Using these datasets, we systematically compare 14 protein models including masked language models, autoregressive language models, inverse folding models, diffusion-based generative models, and geometric graph models. The correlation between model likelihood and experimental affinity values is used to evaluate model performance. Additionally, in a case study to increase binding affinity of antibody F045-092 to antigen influenza H1N1, we evaluate the generative power of the top-performing models by sampling a set of new antibodies binding to the antigen and ranking them based on structural integrity and biophysical properties of the Ab-Ag complex. As a result, structure-conditioned inverse folding models outperform others in both affinity correlation and generation tasks. Overall, AbBiBench provides a unified, biologically grounded evaluation framework to facilitate the development of more effective, function-aware antibody design models.", 'abstract_zh': 'AbBiBench（抗体结合基准测试）：一种用于抗体结合亲和力成熟与设计的基准测试框架', 'title_zh': '抗体亲和力成熟与设计基准'}
{'arxiv_id': 'arXiv:2506.04230', 'title': 'Computationally Intensive Research: Advancing a Role for Secondary Analysis of Qualitative Data', 'authors': 'Kaveh Mohajeri, Amir Karami', 'link': 'https://arxiv.org/abs/2506.04230', 'abstract': 'This paper draws attention to the potential of computational methods in reworking data generated in past qualitative studies. While qualitative inquiries often produce rich data through rigorous and resource-intensive processes, much of this data usually remains unused. In this paper, we first make a general case for secondary analysis of qualitative data by discussing its benefits, distinctions, and epistemological aspects. We then argue for opportunities with computationally intensive secondary analysis, highlighting the possibility of drawing on data assemblages spanning multiple contexts and timeframes to address cross-contextual and longitudinal research phenomena and questions. We propose a scheme to perform computationally intensive secondary analysis and advance ideas on how this approach can help facilitate the development of innovative research designs. Finally, we enumerate some key challenges and ongoing concerns associated with qualitative data sharing and reuse.', 'abstract_zh': '本文关注计算方法在重构过去定性研究生成的数据中的潜力。虽然定性研究经常通过严谨且资源密集的过程产生丰富的数据，但其中大部分数据通常未被利用。本文首先通过讨论其优势、差异和认识论方面，论证了对定性数据进行二次分析的普遍性。然后，我们强调了通过密集计算的二次分析充分利用横跨多个上下文和时间框架的数据集的可能性，以解决跨上下文和纵向研究现象和问题。我们提出了一种进行密集计算的二次分析的方案，并探讨了该方法如何有助于促进创新研究设计的发展。最后，我们列出了与定性数据共享和再利用相关的一些关键挑战和持续关注的问题。', 'title_zh': '计算密集型研究：推进定性数据二次分析的作用'}
