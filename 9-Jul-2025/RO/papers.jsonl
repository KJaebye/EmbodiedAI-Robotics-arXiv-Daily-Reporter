{'arxiv_id': 'arXiv:2507.06224', 'title': 'EC-Flow: Enabling Versatile Robotic Manipulation from Action-Unlabeled Videos via Embodiment-Centric Flow', 'authors': 'Yixiang Chen, Peiyan Li, Yan Huang, Jiabing Yang, Kehan Chen, Liang Wang', 'link': 'https://arxiv.org/abs/2507.06224', 'abstract': "Current language-guided robotic manipulation systems often require low-level action-labeled datasets for imitation learning. While object-centric flow prediction methods mitigate this issue, they remain limited to scenarios involving rigid objects with clear displacement and minimal occlusion. In this work, we present Embodiment-Centric Flow (EC-Flow), a framework that directly learns manipulation from action-unlabeled videos by predicting embodiment-centric flow. Our key insight is that incorporating the embodiment's inherent kinematics significantly enhances generalization to versatile manipulation scenarios, including deformable object handling, occlusions, and non-object-displacement tasks. To connect the EC-Flow with language instructions and object interactions, we further introduce a goal-alignment module by jointly optimizing movement consistency and goal-image prediction. Moreover, translating EC-Flow to executable robot actions only requires a standard robot URDF (Unified Robot Description Format) file to specify kinematic constraints across joints, which makes it easy to use in practice. We validate EC-Flow on both simulation (Meta-World) and real-world tasks, demonstrating its state-of-the-art performance in occluded object handling (62% improvement), deformable object manipulation (45% improvement), and non-object-displacement tasks (80% improvement) than prior state-of-the-art object-centric flow methods. For more information, see our project website at this https URL .", 'abstract_zh': '基于知觉的流动导向_stub_finishing manipulation系统直接从未标注动作的视频中学习操作，通过预测知觉导向的流动来缓解低级动作标注数据集的需求。我们的关键洞察是，将操作内在的运动学特性纳入显著增强了其在多样化操作场景中的泛化能力，包括可变形物体处理、遮挡和非物体位移任务。为了连接EC-Flow与语言指令和物体交互，我们进一步引入了一个目标对齐模块，通过联合优化运动一致性与目标图像预测进行联合优化。此外，将EC-Flow转换为可执行的机器人动作只需一个标准的URDF文件来指定关节间的形式约束，这使其在实践中易于使用。我们在仿真（Meta-World）和实际操作任务中验证了EC-Flow，展示了其在遮挡物体处理（62%的提升）、可变形物体操纵（45%的提升）和非物体位移任务（80%的提升）上的性能超越了先前最先进的基于物体的流动方法。欲了解更多信息，请访问我们的项目网站: this https URL。', 'title_zh': 'EC-Flow: 从未标记动作的视频中实现以具身为中心的多样机器人操作'}
{'arxiv_id': 'arXiv:2507.06219', 'title': 'Is Diversity All You Need for Scalable Robotic Manipulation?', 'authors': 'Modi Shi, Li Chen, Jin Chen, Yuxiang Lu, Chiming Liu, Guanghui Ren, Ping Luo, Di Huang, Maoqing Yao, Hongyang Li', 'link': 'https://arxiv.org/abs/2507.06219', 'abstract': 'Data scaling has driven remarkable success in foundation models for Natural Language Processing (NLP) and Computer Vision (CV), yet the principles of effective data scaling in robotic manipulation remain insufficiently understood. In this work, we investigate the nuanced role of data diversity in robot learning by examining three critical dimensions-task (what to do), embodiment (which robot to use), and expert (who demonstrates)-challenging the conventional intuition of "more diverse is better". Throughout extensive experiments on various robot platforms, we reveal that (1) task diversity proves more critical than per-task demonstration quantity, benefiting transfer from diverse pre-training tasks to novel downstream scenarios; (2) multi-embodiment pre-training data is optional for cross-embodiment transfer-models trained on high-quality single-embodiment data can efficiently transfer to different platforms, showing more desirable scaling property during fine-tuning than multi-embodiment pre-trained models; and (3) expert diversity, arising from individual operational preferences and stochastic variations in human demonstrations, can be confounding to policy learning, with velocity multimodality emerging as a key contributing factor. Based on this insight, we propose a distribution debiasing method to mitigate velocity ambiguity, the yielding GO-1-Pro achieves substantial performance gains of 15%, equivalent to using 2.5 times pre-training data. Collectively, these findings provide new perspectives and offer practical guidance on how to scale robotic manipulation datasets effectively.', 'abstract_zh': '数据缩放推动了自然语言处理和计算机视觉基础模型的显著成功，但在机器人操作中的有效数据缩放原则仍然不够清晰。本文通过探讨任务、体态和专家三个关键维度，考察数据多样性在机器人学习中的微妙作用，挑战了“多样性越多越好”的传统直觉。通过在多种机器人平台上进行广泛实验，我们揭示了以下几点：（1）任务多样性比每任务演示的数量更为关键，能够促进从多样化的预训练任务向新的下游场景的迁移；（2）跨体态预训练数据可选，基于高质量单一体态数据训练的模型在微调时表现出更好的缩放特性，比多体态预训练模型更有效；（3）源自个人操作偏好和人类演示中的随机变化的专家多样性，会对策略学习造成干扰，速度多模态性是主要的贡献因素之一。基于此洞见，我们提出了一种分布偏差修正方法以减轻速度不确定性，GO-1-Pro 方法实现了显著的性能提升，相当于使用2.5倍的预训练数据。这些发现提供了新的视角，并为有效缩放机器人操作数据集提供了实用指导。', 'title_zh': '规模化机器人操作中，多样性足矣吗？'}
{'arxiv_id': 'arXiv:2507.06174', 'title': 'Fast Bilateral Teleoperation and Imitation Learning Using Sensorless Force Control via Accurate Dynamics Model', 'authors': 'Koki Yamane, Yunhan Li, Masashi Konosu, Koki Inami, Junji Oaki, Sho Sakaino, Toshiaki Tsuji', 'link': 'https://arxiv.org/abs/2507.06174', 'abstract': 'In recent years, the advancement of imitation learning has led to increased interest in teleoperating low-cost manipulators to collect demonstration data. However, most existing systems rely on unilateral control, which only transmits target position values. While this approach is easy to implement and suitable for slow, non-contact tasks, it struggles with fast or contact-rich operations due to the absence of force feedback. This work demonstrates that fast teleoperation with force feedback is feasible even with force-sensorless, low-cost manipulators by leveraging 4-channel bilateral control. Based on accurately identified manipulator dynamics, our method integrates nonlinear terms compensation, velocity and external force estimation, and variable gain corresponding to inertial variation. Furthermore, using data collected by 4-channel bilateral control, we show that incorporating force information into both the input and output of learned policies improves performance in imitation learning. These results highlight the practical effectiveness of our system for high-fidelity teleoperation and data collection on affordable hardware.', 'abstract_zh': '近年来，模仿学习的进步增加了对使用低成本操作机构进行遥操作以收集示例数据的兴趣。然而，现有系统大多依赖于单向控制，仅传输目标位置值。虽然这种做法易于实现且适用于慢速、非接触任务，但在高速或接触丰富的操作中由于缺乏力反馈而难以应对。本工作展示了即使在无传感器、低成本操作机构中通过利用四通道双向控制实现高速遥操作结合力反馈是可行的。基于准确识别的操作机构动力学，我们的方法整合了非线性项补偿、速度和外部力估计以及与惯性变化对应的可变增益。此外，我们使用四通道双向控制收集的数据表明，在学习策略的输入和输出中纳入力信息可以提高模仿学习中的性能。这些结果突显了我们在经济型硬件上实现高保真遥操作和数据收集的实际有效性。', 'title_zh': '无传感器力控制基于精确动力学模型的快速双边远程操作及模仿学习'}
{'arxiv_id': 'arXiv:2507.06172', 'title': 'Learning Agile Tensile Perching for Aerial Robots from Demonstrations', 'authors': 'Kangle Yuan, Atar Babgei, Luca Romanello, Hai-Nguyen Nguyen, Ronald Clark, Mirko Kovac, Sophie F. Armanini, Basaran Bahadir Kocer', 'link': 'https://arxiv.org/abs/2507.06172', 'abstract': 'Perching on structures such as trees, beams, and ledges is essential for extending the endurance of aerial robots by enabling energy conservation in standby or observation modes. A tethered tensile perching mechanism offers a simple, adaptable solution that can be retrofitted to existing robots and accommodates a variety of structure sizes and shapes. However, tethered tensile perching introduces significant modelling challenges which require precise management of aerial robot dynamics, including the cases of tether slack & tension, and momentum transfer. Achieving smooth wrapping and secure anchoring by targeting a specific tether segment adds further complexity. In this work, we present a novel trajectory framework for tethered tensile perching, utilizing reinforcement learning (RL) through the Soft Actor-Critic from Demonstrations (SACfD) algorithm. By incorporating both optimal and suboptimal demonstrations, our approach enhances training efficiency and responsiveness, achieving precise control over position and velocity. This framework enables the aerial robot to accurately target specific tether segments, facilitating reliable wrapping and secure anchoring. We validate our framework through extensive simulation and real-world experiments, and demonstrate effectiveness in achieving agile and reliable trajectory generation for tensile perching.', 'abstract_zh': '树木、梁柱和凸出部位等结构上的悬挂对于扩展空中机器人的续航能力至关重要，可以通过在待机或观察模式下节约能量来实现。受限于缆绳的张力悬挂机制提供了一种简单的、可适应现有机器人并能兼容多种结构尺寸和形状的解决方案。然而，受限于缆绳的张力悬挂带来了显著的建模挑战，需要精确管理空中机器人的动力学，包括缆绳松弛与张紧、动量传递等情况。通过瞄准特定的缆绳段进行平滑包裹和牢固锚定增加了进一步的复杂性。在本文中，我们提出了一种新的轨迹框架，利用Soft Actor-Critic from Demonstrations (SACfD) 算法通过强化学习（RL）来实现受限张力悬挂。通过结合最优和次优示范，我们的方法提高了训练效率和响应性，实现了对位置和速度的精确控制。该框架使空中机器人能够准确瞄准特定的缆绳段，促进可靠的包裹和牢固锚定。我们通过广泛的仿真和实际实验验证了该框架，并展示了其在实现敏捷可靠的受限张力悬挂轨迹生成方面的有效性。', 'title_zh': '从示范学习敏捷拉伸着陆的空中机器人'}
{'arxiv_id': 'arXiv:2507.06157', 'title': 'Evaluation of Habitat Robotics using Large Language Models', 'authors': 'William Li, Lei Hamilton, Kaise Al-natour, Sanjeev Mohindra', 'link': 'https://arxiv.org/abs/2507.06157', 'abstract': "This paper focuses on evaluating the effectiveness of Large Language Models at solving embodied robotic tasks using the Meta PARTNER benchmark. Meta PARTNR provides simplified environments and robotic interactions within randomized indoor kitchen scenes. Each randomized kitchen scene is given a task where two robotic agents cooperatively work together to solve the task. We evaluated multiple frontier models on Meta PARTNER environments. Our results indicate that reasoning models like OpenAI o3-mini outperform non-reasoning models like OpenAI GPT-4o and Llama 3 when operating in PARTNR's robotic embodied environments. o3-mini displayed outperform across centralized, decentralized, full observability, and partial observability configurations. This provides a promising avenue of research for embodied robotic development.", 'abstract_zh': '本文 focuses于使用 Meta PARTNER 基准评估大型语言模型解决具身机器人任务的有效性。Meta PARTNER 提供了简化环境和随机化室内厨房场景中的机器人交互。每个随机化的厨房场景分配一个任务，两个机器人代理合作解决该任务。我们在 Meta PARTNER 环境中评估了多个前沿模型。我们的结果表明，在 PARTNER 的具身机器人环境中，推理模型如 OpenAI o3-mini 在性能上优于非推理模型如 OpenAI GPT-4o 和 Llama 3。o3-mini 在集中式、分散式、完全可观测性和部分可观测性配置中均表现出色。这为具身机器人开发提供了有希望的研究方向。', 'title_zh': '大型语言模型在 Habitat Robotics中的评估'}
{'arxiv_id': 'arXiv:2507.06149', 'title': 'Fast and Accurate Collision Probability Estimation for Autonomous Vehicles using Adaptive Sigma-Point Sampling', 'authors': 'Charles Champagne Cossette, Taylor Scott Clawson, Andrew Feit', 'link': 'https://arxiv.org/abs/2507.06149', 'abstract': "A novel algorithm is presented for the estimation of collision probabilities between dynamic objects with uncertain trajectories, where the trajectories are given as a sequence of poses with Gaussian distributions. We propose an adaptive sigma-point sampling scheme, which ultimately produces a fast, simple algorithm capable of estimating the collision probability with a median error of 3.5%, and a median runtime of 0.21ms, when measured on an Intel Xeon Gold 6226R Processor. Importantly, the algorithm explicitly accounts for the collision probability's temporal dependence, which is often neglected in prior work and otherwise leads to an overestimation of the collision probability. Finally, the method is tested on a diverse set of relevant real-world scenarios, consisting of 400 6-second snippets of autonomous vehicle logs, where the accuracy and latency is rigorously evaluated.", 'abstract_zh': '一种新颖的算法用于估计具有不确定性轨迹的动力学对象之间的碰撞概率，轨迹以高斯分布的一系列姿势给出。我们提出了一种自适应sigma点采样方案，最终产生了一种快速、简单的算法，能够在Intel Xeon Gold 6226R处理器上以中位数误差3.5%和中位数运行时间0.21ms估算碰撞概率。值得注意的是，该算法明确考虑了碰撞概率的时间依赖性，这是先前工作中经常忽视的，否则会导致碰撞概率被高估。最后，该方法在包括400个6秒自动驾驶车辆日志片段的多种实际场景中进行了测试，其中准确性和延迟得到了严格评估。', 'title_zh': '基于自适应σ点采样的自动驾驶车辆快速准确碰撞概率估计'}
{'arxiv_id': 'arXiv:2507.06129', 'title': 'Learning-Augmented Model-Based Multi-Robot Planning for Time-Critical Search and Inspection Under Uncertainty', 'authors': 'Abhish Khanal, Joseph Prince Mathew, Cameron Nowzari, Gregory J. Stein', 'link': 'https://arxiv.org/abs/2507.06129', 'abstract': 'In disaster response or surveillance operations, quickly identifying areas needing urgent attention is critical, but deploying response teams to every location is inefficient or often impossible. Effective performance in this domain requires coordinating a multi-robot inspection team to prioritize inspecting locations more likely to need immediate response, while also minimizing travel time. This is particularly challenging because robots must directly observe the locations to determine which ones require additional attention. This work introduces a multi-robot planning framework for coordinated time-critical multi-robot search under uncertainty. Our approach uses a graph neural network to estimate the likelihood of PoIs needing attention from noisy sensor data and then uses those predictions to guide a multi-robot model-based planner to determine the cost-effective plan. Simulated experiments demonstrate that our planner improves performance at least by 16.3\\%, 26.7\\%, and 26.2\\% for 1, 3, and 5 robots, respectively, compared to non-learned and learned baselines. We also validate our approach on real-world platforms using quad-copters.', 'abstract_zh': '在灾害响应或监控操作中，迅速识别需要紧急关注的区域至关重要，但将响应团队部署到每一个地点往往是低效的或不可能的。该领域有效地完成任务需要协调一个多机器人检查团队，优先检查更可能需要立即响应的位置，同时尽量减少旅行时间。由于机器人必须直接观察这些位置以确定哪些位置需要额外的关注，这使得这一任务极具挑战性。本研究介绍了一种在不确定性下协调时间关键多机器人搜索的多机器人规划框架。我们的方法使用图神经网络从噪声传感器数据中估计潜在兴趣点（PoIs）需要关注的可能性，然后利用这些预测来引导一个多机器人模型为基础的规划者确定成本效益最高的方案。模拟实验表明，与非学习基准和学习基准相比，我们的规划者分别在1个、3个和5个机器人的情况下，性能至少提高16.3%、26.7%和26.2%。我们还在现实世界平台（使用四旋翼飞行器）上验证了我们的方法。', 'title_zh': '基于学习增强模型的不确定性条件下时间关键搜索与检测多机器人规划'}
{'arxiv_id': 'arXiv:2507.06053', 'title': 'SCCRUB: Surface Cleaning Compliant Robot Utilizing Bristles', 'authors': 'Jakub F. Kowalewski, Keeyon Hajjafar, Alyssa Ugent, Jeffrey Ian Lipton', 'link': 'https://arxiv.org/abs/2507.06053', 'abstract': "Scrubbing surfaces is a physically demanding and time-intensive task. Removing adhered contamination requires substantial friction generated through pressure and torque or high lateral forces. Rigid robotic manipulators, while capable of exerting these forces, are usually confined to structured environments isolated from humans due to safety risks. In contrast, soft robot arms can safely work around humans and adapt to environmental uncertainty, but typically struggle to transmit the continuous torques or lateral forces necessary for scrubbing. Here, we demonstrate a soft robotic arm scrubbing adhered residues using torque and pressure, a task traditionally challenging for soft robots. We train a neural network to learn the arm's inverse kinematics and elasticity, which enables open-loop force and position control. Using this learned model, the robot successfully scrubbed burnt food residue from a plate and sticky fruit preserve from a toilet seat, removing an average of 99.7% of contamination. This work demonstrates how soft robots, capable of exerting continuous torque, can effectively and safely scrub challenging contamination from surfaces.", 'abstract_zh': '柔体机械臂通过扭矩和压力清除附着残留物的研究', 'title_zh': 'SCCRUB：利用刷子的表面清洁合规机器人'}
{'arxiv_id': 'arXiv:2507.05985', 'title': 'Robust Speech-Workload Estimation for Intelligent Human-Robot Systems', 'authors': 'Julian Fortune, Julie A. Adams, Jamison Heard', 'link': 'https://arxiv.org/abs/2507.05985', 'abstract': "Demanding task environments (e.g., supervising a remotely piloted aircraft) require performing tasks quickly and accurately; however, periods of low and high operator workload can decrease task performance. Intelligent modulation of the system's demands and interaction modality in response to changes in operator workload state may increase performance by avoiding undesirable workload states. This system requires real-time estimation of each workload component (i.e., cognitive, physical, visual, speech, and auditory) to adapt the correct modality. Existing workload systems estimate multiple workload components post-hoc, but few estimate speech workload, or function in real-time. An algorithm to estimate speech workload and mitigate undesirable workload states in real-time is presented. An analysis of the algorithm's accuracy is presented, along with the results demonstrating the algorithm's generalizability across individuals and human-machine teaming paradigms. Real-time speech workload estimation is a crucial element towards developing adaptive human-machine systems.", 'abstract_zh': '需求高的任务环境（例如，远程操作无人机）要求快速而准确地执行任务；然而，操作员工作负荷低和高时期的出现会降低任务性能。响应操作员工作负荷状态的变化智能地调节系统的需要和交互方式可能会通过避免不良工作负荷状态来提高性能。该系统需要实时估计每个工作负荷成分（即认知、物理、视觉、言语和听觉）以适应正确的交互方式。现有的工作负荷系统事后估计多种工作负荷成分，但很少有系统能够实时估计言语工作负荷或实时运行。本文提出了一种能够实时估计言语工作负荷并缓解不良工作负荷状态的算法，并分析了该算法的准确性，以及该算法在不同个体和人机团队范式中的普适性。实时言语工作负荷估计是开发自适应人机系统的关键要素。', 'title_zh': '智能人机系统中鲁棒语音工作负载估计'}
{'arxiv_id': 'arXiv:2507.05979', 'title': 'AURA-CVC: Autonomous Ultrasound-guided Robotic Assistance for Central Venous Catheterization', 'authors': 'Deepak Raina, Lidia Al-Zogbi, Brian Teixeira, Vivek Singh, Ankur Kapoor, Thorsten Fleiter, Muyinatu A. Lediju Bell, Vinciya Pandian, Axel Krieger', 'link': 'https://arxiv.org/abs/2507.05979', 'abstract': "Purpose: Central venous catheterization (CVC) is a critical medical procedure for vascular access, hemodynamic monitoring, and life-saving interventions. Its success remains challenging due to the need for continuous ultrasound-guided visualization of a target vessel and approaching needle, which is further complicated by anatomical variability and operator dependency. Errors in needle placement can lead to life-threatening complications. While robotic systems offer a potential solution, achieving full autonomy remains challenging. In this work, we propose an end-to-end robotic-ultrasound-guided CVC pipeline, from scan initialization to needle insertion. Methods: We introduce a deep-learning model to identify clinically relevant anatomical landmarks from a depth image of the patient's neck, obtained using RGB-D camera, to autonomously define the scanning region and paths. Then, a robot motion planning framework is proposed to scan, segment, reconstruct, and localize vessels (veins and arteries), followed by the identification of the optimal insertion zone. Finally, a needle guidance module plans the insertion under ultrasound guidance with operator's feedback. This pipeline was validated on a high-fidelity commercial phantom across 10 simulated clinical scenarios. Results: The proposed pipeline achieved 10 out of 10 successful needle placements on the first attempt. Vessels were reconstructed with a mean error of 2.15 \\textit{mm}, and autonomous needle insertion was performed with an error less than or close to 1 \\textit{mm}. Conclusion: To our knowledge, this is the first robotic CVC system demonstrated on a high-fidelity phantom with integrated planning, scanning, and insertion. Experimental results show its potential for clinical translation.", 'abstract_zh': '目的：中心静脉导管放置（CVC）是血管通路、血流动力学监测和生命挽救性干预的 critical 医疗程序。由于需要持续的超声引导以可视化目标血管和进针路径，其成功率受到解剖变异性和操作者依赖性的挑战。针头放置错误可能导致危及生命的风险。虽然机器人系统可能提供解决方案，但实现完全自主操作仍具有挑战性。本文提出了一种从扫描初始化到针头插入的端到端的机器人-超声引导CVC流程。', 'title_zh': 'AURA-CVC: 自主超声引导机器人辅助中心静脉导管置入'}
{'arxiv_id': 'arXiv:2507.05978', 'title': 'FineGrasp: Towards Robust Grasping for Delicate Objects', 'authors': 'Yun Du, Mengao Zhao, Tianwei Lin, Yiwei Jin, Chaodong Huang, Zhizhong Su', 'link': 'https://arxiv.org/abs/2507.05978', 'abstract': 'Recent advancements in robotic grasping have led to its integration as a core module in many manipulation systems. For instance, language-driven semantic segmentation enables the grasping of any designated object or object part. However, existing methods often struggle to generate feasible grasp poses for small objects or delicate components, potentially causing the entire pipeline to fail. To address this issue, we propose a novel grasping method, FineGrasp, which introduces improvements in three key aspects. First, we introduce multiple network modifications to enhance the ability of to handle delicate regions. Second, we address the issue of label imbalance and propose a refined graspness label normalization strategy. Third, we introduce a new simulated grasp dataset and show that mixed sim-to-real training further improves grasp performance. Experimental results show significant improvements, especially in grasping small objects, and confirm the effectiveness of our system in semantic grasping.', 'abstract_zh': 'Recent advancements in robotic grasping have led to its integration as a core module in many manipulation systems. FineGrasp: Improvements in Handling Delicate Regions, Addressing Label Imbalance, and Enhancing Sim-to-Real Training for Semantic Grasping', 'title_zh': 'FineGrasp: 向向精细物件抓取的稳健性迈进'}
{'arxiv_id': 'arXiv:2507.05884', 'title': 'Comparison of Path Planning Algorithms for Autonomous Vehicle Navigation Using Satellite and Airborne LiDAR Data', 'authors': 'Chang Liu, Zhexiong Xue, Tamas Sziranyi', 'link': 'https://arxiv.org/abs/2507.05884', 'abstract': 'Autonomous vehicle navigation in unstructured environments, such as forests and mountainous regions, presents significant challenges due to irregular terrain and complex road conditions. This work provides a comparative evaluation of mainstream and well-established path planning algorithms applied to weighted pixel-level road networks derived from high-resolution satellite imagery and airborne LiDAR data. For 2D road-map navigation, where the weights reflect road conditions and terrain difficulty, A*, Dijkstra, RRT*, and a Novel Improved Ant Colony Optimization Algorithm (NIACO) are tested on the DeepGlobe satellite dataset. For 3D road-map path planning, 3D A*, 3D Dijkstra, RRT-Connect, and NIACO are evaluated using the Hamilton airborne LiDAR dataset, which provides detailed elevation information. All algorithms are assessed under identical start and end point conditions, focusing on path cost, computation time, and memory consumption. Results demonstrate that Dijkstra consistently offers the most stable and efficient performance in both 2D and 3D scenarios, particularly when operating on dense, pixel-level geospatial road-maps. These findings highlight the reliability of Dijkstra-based planning for static terrain navigation and establish a foundation for future research on dynamic path planning under complex environmental constraints.', 'abstract_zh': '自主车辆在未结构化环境（如森林和山区）中的导航由于地形不规则和道路条件复杂而面临重大挑战。本文对基于高分辨率卫星图像和机载LiDAR数据提取的加权像素级道路网络上主流和成熟的路径规划算法进行了比较评估。对于2D道路图导航，其中权重反映了道路条件和地形难度，测试了A*、迪杰斯特拉、RRT*和一种改进的蚁群优化算法（NIACO）在DeepGlobe卫星数据集上的表现。对于3D道路图路径规划，使用提供详细高程信息的Hamilton机载LiDAR数据集，测试了3D A*、3D迪杰斯特拉、RRT-Connect和NIACO。所有算法均在相同的起点和终点条件下进行评估，重点关注路径成本、计算时间和内存消耗。结果表明，迪杰斯特拉在2D和3D场景中均表现出最稳定和高效的性能，尤其是在密集的像素级地理道路图上运行时。这些发现突显了基于迪杰斯特拉的规划方法在静态地形导航中的可靠性，并为复杂环境约束下的动态路径规划研究奠定了基础。', 'title_zh': '基于卫星和机载LiDAR数据的自主车辆导航路径规划算法比较'}
{'arxiv_id': 'arXiv:2507.05861', 'title': 'Communication-Efficient Module-Wise Federated Learning for Grasp Pose Detection in Cluttered Environments', 'authors': 'Woonsang Kang, Joohyung Lee, Seungjun Kim, Jungchan Cho, Yoonseon Oh', 'link': 'https://arxiv.org/abs/2507.05861', 'abstract': "Grasp pose detection (GPD) is a fundamental capability for robotic autonomy, but its reliance on large, diverse datasets creates significant data privacy and centralization challenges. Federated Learning (FL) offers a privacy-preserving solution, but its application to GPD is hindered by the substantial communication overhead of large models, a key issue for resource-constrained robots. To address this, we propose a novel module-wise FL framework that begins by analyzing the learning dynamics of the GPD model's functional components. This analysis identifies slower-converging modules, to which our framework then allocates additional communication effort. This is realized through a two-phase process: a standard full-model training phase is followed by a communication-efficient phase where only the identified subset of slower-converging modules is trained and their partial updates are aggregated. Extensive experiments on the GraspNet-1B dataset demonstrate that our method outperforms standard FedAvg and other baselines, achieving higher accuracy for a given communication budget. Furthermore, real-world experiments on a physical robot validate our approach, showing a superior grasp success rate compared to baseline methods in cluttered scenes. Our work presents a communication-efficient framework for training robust, generalized GPD models in a decentralized manner, effectively improving the trade-off between communication cost and model performance.", 'abstract_zh': '模块级别的联邦学习框架：面向抓取姿态检测的通信高效分散训练方法', 'title_zh': '通信高效的模块级联邦学习在杂乱环境中抓取姿态检测'}
{'arxiv_id': 'arXiv:2507.05754', 'title': 'LeAD: The LLM Enhanced Planning System Converged with End-to-end Autonomous Driving', 'authors': 'Yuhang Zhang, Jiaqi Liu, Chengkai Xu, Peng Hang, Jian Sun', 'link': 'https://arxiv.org/abs/2507.05754', 'abstract': "A principal barrier to large-scale deployment of urban autonomous driving systems lies in the prevalence of complex scenarios and edge cases. Existing systems fail to effectively interpret semantic information within traffic contexts and discern intentions of other participants, consequently generating decisions misaligned with skilled drivers' reasoning patterns. We present LeAD, a dual-rate autonomous driving architecture integrating imitation learning-based end-to-end (E2E) frameworks with large language model (LLM) augmentation. The high-frequency E2E subsystem maintains real-time perception-planning-control cycles, while the low-frequency LLM module enhances scenario comprehension through multi-modal perception fusion with HD maps and derives optimal decisions via chain-of-thought (CoT) reasoning when baseline planners encounter capability limitations. Our experimental evaluation in the CARLA Simulator demonstrates LeAD's superior handling of unconventional scenarios, achieving 71 points on Leaderboard V1 benchmark, with a route completion of 93%.", 'abstract_zh': '大规模部署城市自动驾驶系统的主要障碍在于复杂场景和边缘情况的普遍存在。现有系统无法有效地解释交通场景中的语义信息，也无法识别其他参与者的意图，从而导致决策与熟练驾驶员的推理模式不一致。我们提出了一种LeAD双速率自动驾驶架构，该架构结合了基于模仿学习的端到端（E2E）框架和大语言模型（LLM）增强技术。高频率的E2E子系统保持实时感知-规划-控制循环，而低频率的LLM模块通过多模态感知融合高清地图增强场景理解，并在基本规划器遇到能力限制时通过链式思考（CoT）推理得出最优决策。在CARLA模拟器的实验评估表明，LeAD在Leaderboard V1基准测试中表现出色，获得了71分，路线完成率为93%。', 'title_zh': 'LeAD：增强型规划系统结合端到端自主驾驶'}
{'arxiv_id': 'arXiv:2507.05748', 'title': 'A Learning-based Planning and Control Framework for Inertia Drift Vehicles', 'authors': 'Bei Zhou, Zhouheng Li, Lei Xie, Hongye Su, Johannes Betz', 'link': 'https://arxiv.org/abs/2507.05748', 'abstract': 'Inertia drift is a transitional maneuver between two sustained drift stages in opposite directions, which provides valuable insights for navigating consecutive sharp corners for autonomous this http URL, this can be a challenging scenario for the drift controller to handle rapid transitions between opposing sideslip angles while maintaining accurate path tracking. Moreover, accurate drift control depends on a high-fidelity vehicle model to derive drift equilibrium points and predict vehicle states, but this is often compromised by the strongly coupled longitudinal-lateral drift dynamics and unpredictable environmental variations. To address these challenges, this paper proposes a learning-based planning and control framework utilizing Bayesian optimization (BO), which develops a planning logic to ensure a smooth transition and minimal velocity loss between inertia and sustained drift phases. BO is further employed to learn a performance-driven control policy that mitigates modeling errors for enhanced system performance. Simulation results on an 8-shape reference path demonstrate that the proposed framework can achieve smooth and stable inertia drift through sharp corners.', 'abstract_zh': '基于贝叶斯优化的自主过渡漂移规划与控制框架', 'title_zh': '基于学习的规划与控制框架：用于惯性漂移车辆'}
{'arxiv_id': 'arXiv:2507.05717', 'title': 'Simultaneous Triggering and Synchronization of Sensors and Onboard Computers', 'authors': 'Morten Nissov, Nikhil Khedekar, Kostas Alexis', 'link': 'https://arxiv.org/abs/2507.05717', 'abstract': 'High fidelity estimation algorithms for robotics require accurate data. However, timestamping of sensor data is a key issue that rarely receives the attention it deserves. Inaccurate timestamping can be compensated for in post-processing but is imperative for online estimation. Simultaneously, even online mitigation of timing issues can be achieved through a relaxation of the tuning parameters from their otherwise more performative optimal values, but at a detriment to performance. To address the need for real-time, low-cost timestamping, a versatile system which utilizes readily-available components and established methods for synchronization is introduced. The synchronization and triggering (of both high- and low-rate sensors) capabilities of the system are demonstrated.', 'abstract_zh': '基于机器人应用的高保真估计算法需要准确的数据。然而，传感器数据的时间戳标记是经常被忽视的关键问题。不准确的时间戳可以通过后处理进行补偿，但对于在线估计却至关重要。同时，即使通过放松从最优值更高效的调参值来在线缓解时间问题，性能也会受到影响。为了满足实时、低成本的时间戳需求，介绍了一种灵活的系统，该系统利用 readily-available 组件和已建立的同步方法。展示了该系统的同步和触发（高和低速率传感器）能力。', 'title_zh': '传感器和机载计算机的同步触发与同步'}
{'arxiv_id': 'arXiv:2507.05710', 'title': 'DRO-EDL-MPC: Evidential Deep Learning-Based Distributionally Robust Model Predictive Control for Safe Autonomous Driving', 'authors': 'Hyeongchan Ham, Heejin Ahn', 'link': 'https://arxiv.org/abs/2507.05710', 'abstract': 'Safety is a critical concern in motion planning for autonomous vehicles. Modern autonomous vehicles rely on neural network-based perception, but making control decisions based on these inference results poses significant safety risks due to inherent uncertainties. To address this challenge, we present a distributionally robust optimization (DRO) framework that accounts for both aleatoric and epistemic perception uncertainties using evidential deep learning (EDL). Our approach introduces a novel ambiguity set formulation based on evidential distributions that dynamically adjusts the conservativeness according to perception confidence levels. We integrate this uncertainty-aware constraint into model predictive control (MPC), proposing the DRO-EDL-MPC algorithm with computational tractability for autonomous driving applications. Validation in the CARLA simulator demonstrates that our approach maintains efficiency under high perception confidence while enforcing conservative constraints under low confidence.', 'abstract_zh': '基于证据深度学习的分布鲁棒优化在自主车辆运动规划中的安全应用', 'title_zh': '基于证据深度学习的分布鲁棒模型预测控制方法及其在安全自主驾驶中的应用'}
{'arxiv_id': 'arXiv:2507.05695', 'title': 'Hybrid Diffusion Policies with Projective Geometric Algebra for Efficient Robot Manipulation Learning', 'authors': 'Xiatao Sun, Yuxuan Wang, Shuo Yang, Yinxing Chen, Daniel Rakita', 'link': 'https://arxiv.org/abs/2507.05695', 'abstract': 'Diffusion policies have become increasingly popular in robot learning due to their reliable convergence in motion generation tasks. At a high level, these policies learn to transform noisy action trajectories into effective ones, conditioned on observations. However, each time such a model is trained in a robotics context, the network must relearn fundamental spatial representations and operations, such as translations and rotations, from scratch in order to ground itself and operate effectively in a 3D environment. Incorporating geometric inductive biases directly into the network can alleviate this redundancy and substantially improve training efficiency. In this paper, we introduce hPGA-DP, a diffusion policy approach that integrates a mathematical framework called Projective Geometric Algebra (PGA) to embed strong geometric inductive biases. PGA is particularly well-suited for this purpose as it provides a unified algebraic framework that naturally encodes geometric primitives, such as points, directions, and rotations, enabling neural networks to reason about spatial structure through interpretable and composable operations. Specifically, we propose a novel diffusion policy architecture that incorporates the Projective Geometric Algebra Transformer (P-GATr), leveraging its E(3)-equivariant properties established in prior work. Our approach adopts a hybrid architecture strategy, using P-GATr as both a state encoder and action decoder, while employing U-Net or Transformer-based modules for the denoising process. Several experiments and ablation studies in both simulated and real-world environments demonstrate that hPGA-DP not only improves task performance and training efficiency through the geometric bias of P-GATr, but also achieves substantially faster convergence through its hybrid model compared to architectures that rely solely on P-GATr.', 'abstract_zh': 'PGA集成的扩散策略：基于投影几何代数的机器人学习方法', 'title_zh': '基于射影几何代数的混合扩散策略高效机器人 manipul 完成学习'}
{'arxiv_id': 'arXiv:2507.05674', 'title': 'Integrating Diffusion-based Multi-task Learning with Online Reinforcement Learning for Robust Quadruped Robot Control', 'authors': 'Xinyao Qin, Xiaoteng Ma, Yang Qi, Qihan Liu, Chuanyi Xue, Ning Gui, Qinyu Dong, Jun Yang, Bin Liang', 'link': 'https://arxiv.org/abs/2507.05674', 'abstract': 'Recent research has highlighted the powerful capabilities of imitation learning in robotics. Leveraging generative models, particularly diffusion models, these approaches offer notable advantages such as strong multi-task generalization, effective language conditioning, and high sample efficiency. While their application has been successful in manipulation tasks, their use in legged locomotion remains relatively underexplored, mainly due to compounding errors that affect stability and difficulties in task transition under limited data. Online reinforcement learning (RL) has demonstrated promising results in legged robot control in the past years, providing valuable insights to address these challenges. In this work, we propose DMLoco, a diffusion-based framework for quadruped robots that integrates multi-task pretraining with online PPO finetuning to enable language-conditioned control and robust task transitions. Our approach first pretrains the policy on a diverse multi-task dataset using diffusion models, enabling language-guided execution of various skills. Then, it finetunes the policy in simulation to ensure robustness and stable task transition during real-world deployment. By utilizing Denoising Diffusion Implicit Models (DDIM) for efficient sampling and TensorRT for optimized deployment, our policy runs onboard at 50Hz, offering a scalable and efficient solution for adaptive, language-guided locomotion on resource-constrained robotic platforms.', 'abstract_zh': '基于扩散模型的 quadruped 机器人群体模仿学习框架：多任务预训练结合在线 PPO 微调实现语言条件控制和鲁棒任务过渡', 'title_zh': '基于扩散网络的多任务学习与在线强化学习结合的稳健四足机器人控制'}
{'arxiv_id': 'arXiv:2507.05663', 'title': 'Stable Tracking-in-the-Loop Control of Cable-Driven Surgical Manipulators under Erroneous Kinematic Chains', 'authors': 'Neelay Joglekar, Fei Liu, Florian Richter, Michael C. Yip', 'link': 'https://arxiv.org/abs/2507.05663', 'abstract': "Remote Center of Motion (RCM) robotic manipulators have revolutionized Minimally Invasive Surgery, enabling precise, dexterous surgical manipulation within the patient's body cavity without disturbing the insertion point on the patient. Accurate RCM tool control is vital for incorporating autonomous subtasks like suturing, blood suction, and tumor resection into robotic surgical procedures, reducing surgeon fatigue and improving patient outcomes. However, these cable-driven systems are subject to significant joint reading errors, corrupting the kinematics computation necessary to perform control. Although visual tracking with endoscopic cameras can correct errors on in-view joints, errors in the kinematic chain prior to the insertion point are irreparable because they remain out of view. No prior work has characterized the stability of control under these conditions. We fill this gap by designing a provably stable tracking-in-the-loop controller for the out-of-view portion of the RCM manipulator kinematic chain. We additionally incorporate this controller into a bilevel control scheme for the full kinematic chain. We rigorously benchmark our method in simulated and real world settings to verify our theoretical findings. Our work provides key insights into the next steps required for the transition from teleoperated to autonomous surgery.", 'abstract_zh': 'Remote Center of Motion (RCM) 轨道 manipulator 控制的稳健性：从可视化关节到不可视化关节的端到端自主手术控制', 'title_zh': '基于错误运动链的电缆驱动手术 manipulators 在环稳定跟踪控制'}
{'arxiv_id': 'arXiv:2507.05661', 'title': '3DGS_LSR:Large_Scale Relocation for Autonomous Driving Based on 3D Gaussian Splatting', 'authors': 'Haitao Lu, Haijier Chen, Haoze Liu, Shoujian Zhang, Bo Xu, Ziao Liu', 'link': 'https://arxiv.org/abs/2507.05661', 'abstract': 'In autonomous robotic systems, precise localization is a prerequisite for safe navigation. However, in complex urban environments, GNSS positioning often suffers from signal occlusion and multipath effects, leading to unreliable absolute positioning. Traditional mapping approaches are constrained by storage requirements and computational inefficiency, limiting their applicability to resource-constrained robotic platforms. To address these challenges, we propose 3DGS-LSR: a large-scale relocalization framework leveraging 3D Gaussian Splatting (3DGS), enabling centimeter-level positioning using only a single monocular RGB image on the client side. We combine multi-sensor data to construct high-accuracy 3DGS maps in large outdoor scenes, while the robot-side localization requires just a standard camera input. Using SuperPoint and SuperGlue for feature extraction and matching, our core innovation is an iterative optimization strategy that refines localization results through step-by-step rendering, making it suitable for real-time autonomous navigation. Experimental validation on the KITTI dataset demonstrates our 3DGS-LSR achieves average positioning accuracies of 0.026m, 0.029m, and 0.081m in town roads, boulevard roads, and traffic-dense highways respectively, significantly outperforming other representative methods while requiring only monocular RGB input. This approach provides autonomous robots with reliable localization capabilities even in challenging urban environments where GNSS fails.', 'abstract_zh': '基于3D高斯斑点的大规模重定位框架3DGS-LSR：一种单目RGB图像在复杂城市环境中的厘米级定位方法', 'title_zh': '3DGS_LSR：基于3D高斯点阵的大规模自主 relocation技术'}
{'arxiv_id': 'arXiv:2507.05643', 'title': 'A Physics-Based Continuum Model for Versatile, Scalable, and Fast Terramechanics Simulation', 'authors': 'Huzaifa Unjhawala, Luning Bakke, Harry Zhang, Michael Taylor, Ganesh Arivoli, Radu Serban, Dan Negrut', 'link': 'https://arxiv.org/abs/2507.05643', 'abstract': "This paper discusses Chrono's Continuous Representation Model (called herein Chrono::CRM), a general-purpose, scalable, and efficient simulation solution for terramechanics problems. Built on Chrono's Smoothed Particle Hydrodynamics (SPH) framework, Chrono::CRM moves beyond semi-empirical terramechanics approaches, e.g., Bekker-Wong/Janosi-Hanamoto, to provide a physics-based model able to address complex tasks such as digging, grading, as well as interaction with deformable wheels and complex grouser/lug patterns. The terramechanics model is versatile in that it allows the terrain to interact with both rigid and flexible implements simulated via the Chrono dynamics engine. We validate Chrono::CRM against experimental data from three physical tests, including one involving NASA's MGRU3 rover. In addition, the simulator is benchmarked against a high-fidelity Discrete Element Method (DEM) simulation of a digging scenario involving the Regolith Advanced Surface Systems Operations Robot (RASSOR). Being GPU-accelerated, Chrono::CRM achieves computational efficiency comparable to that of semi-empirical simulation approaches for terramechanics problems. Through an ``active domains'' implementation, Chrono::CRM can handle terrain stretches up to 10 km long with 100 million SPH particles at near interactive rates, making high-fidelity off-road simulations at large scales feasible. As a component of the Chrono package, the CRM model is open source and released under a BSD-3 license. All models and simulations used in this contribution are available in a public GitHub repository for reproducibility studies and further research.", 'abstract_zh': 'Chrono的连续表示模型：一种面向地形机械学问题的一般性、可扩展性和高效性仿真解决方案', 'title_zh': '基于物理的连续模型用于多功能、可扩展和快速的地表力学模拟'}
{'arxiv_id': 'arXiv:2507.05627', 'title': 'DreamGrasp: Zero-Shot 3D Multi-Object Reconstruction from Partial-View Images for Robotic Manipulation', 'authors': 'Young Hun Kim, Seungyeon Kim, Yonghyeon Lee, Frank Chongwoo Park', 'link': 'https://arxiv.org/abs/2507.05627', 'abstract': 'Partial-view 3D recognition -- reconstructing 3D geometry and identifying object instances from a few sparse RGB images -- is an exceptionally challenging yet practically essential task, particularly in cluttered, occluded real-world settings where full-view or reliable depth data are often unavailable. Existing methods, whether based on strong symmetry priors or supervised learning on curated datasets, fail to generalize to such scenarios. In this work, we introduce DreamGrasp, a framework that leverages the imagination capability of large-scale pre-trained image generative models to infer the unobserved parts of a scene. By combining coarse 3D reconstruction, instance segmentation via contrastive learning, and text-guided instance-wise refinement, DreamGrasp circumvents limitations of prior methods and enables robust 3D reconstruction in complex, multi-object environments. Our experiments show that DreamGrasp not only recovers accurate object geometry but also supports downstream tasks like sequential decluttering and target retrieval with high success rates.', 'abstract_zh': '部分视角3D识别——从几幅稀疏RGB图像重建3D几何和识别物体实例——是一个极具挑战性但又实际必需的任务，特别是在全视角或可靠深度数据不可用的杂乱遮挡的真实环境中。现有方法，无论是基于强烈的对称先验还是在精心标注的数据集上的监督学习，都未能在这些场景中泛化。在本文中，我们提出DreamGrasp框架，该框架利用大规模预训练图像生成模型的想象力，推断场景中未观察到的部分。通过结合粗略的3D重建、对比学习实例分割以及文本引导的实例级细化，DreamGrasp克服了先前方法的局限性，并能在复杂多物体环境中实现鲁棒的3D重建。我们的实验表明，DreamGrasp不仅能准确恢复物体几何结构，还能在高成功率下支持后续任务如顺序去杂物和目标检索。', 'title_zh': 'DreamGrasp: 基于部分视图图像的零样本三维多对象重建及其在机器人 manipulation 中的应用'}
{'arxiv_id': 'arXiv:2507.05607', 'title': "Structured Task Solving via Modular Embodied Intelligence: A Case Study on Rubik's Cube", 'authors': 'Chongshan Fan, Shenghai Yuan', 'link': 'https://arxiv.org/abs/2507.05607', 'abstract': "This paper presents Auto-RubikAI, a modular autonomous planning framework that integrates a symbolic Knowledge Base (KB), a vision-language model (VLM), and a large language model (LLM) to solve structured manipulation tasks exemplified by Rubik's Cube restoration. Unlike traditional robot systems based on predefined scripts, or modern approaches relying on pretrained networks and large-scale demonstration data, Auto-RubikAI enables interpretable, multi-step task execution with minimal data requirements and no prior demonstrations. The proposed system employs a KB module to solve group-theoretic restoration steps, overcoming LLMs' limitations in symbolic reasoning. A VLM parses RGB-D input to construct a semantic 3D scene representation, while the LLM generates structured robotic control code via prompt chaining. This tri-module architecture enables robust performance under spatial uncertainty. We deploy Auto-RubikAI in both simulation and real-world settings using a 7-DOF robotic arm, demonstrating effective Sim-to-Real adaptation without retraining. Experiments show a 79% end-to-end task success rate across randomized configurations. Compared to CFOP, DeepCubeA, and Two-Phase baselines, our KB-enhanced method reduces average solution steps while maintaining interpretability and safety. Auto-RubikAI provides a cost-efficient, modular foundation for embodied task planning in smart manufacturing, robotics education, and autonomous execution scenarios. Code, prompts, and hardware modules will be released upon publication.", 'abstract_zh': 'Auto-RubikAI：一种集成了符号知识库、视觉语言模型和大型语言模型的模块化自主规划框架', 'title_zh': "模块化 embodied 智能驱动的结构化任务解决：Rubik's Cube 案例研究"}
{'arxiv_id': 'arXiv:2507.05555', 'title': 'PAPRLE (Plug-And-Play Robotic Limb Environment): A Modular Ecosystem for Robotic Limbs', 'authors': 'Obin Kwon, Sankalp Yamsani, Noboru Myers, Sean Taylor, Jooyoung Hong, Kyungseo Park, Alex Alspach, Joohyung Kim', 'link': 'https://arxiv.org/abs/2507.05555', 'abstract': 'We introduce PAPRLE (Plug-And-Play Robotic Limb Environment), a modular ecosystem that enables flexible placement and control of robotic limbs. With PAPRLE, a user can change the arrangement of the robotic limbs, and control them using a variety of input devices, including puppeteers, gaming controllers, and VR-based interfaces. This versatility supports a wide range of teleoperation scenarios and promotes adaptability to different task requirements. To further enhance configurability, we introduce a pluggable puppeteer device that can be easily mounted and adapted to match the target robot configurations. PAPRLE supports bilateral teleoperation through these puppeteer devices, agnostic to the type or configuration of the follower robot. By supporting both joint-space and task-space control, the system provides real-time force feedback, improving user fidelity and physical interaction awareness. The modular design of PAPRLE facilitates novel spatial arrangements of the limbs and enables scalable data collection, thereby advancing research in embodied AI and learning-based control. We validate PAPRLE in various real-world settings, demonstrating its versatility across diverse combinations of leader devices and follower robots. The system will be released as open source, including both hardware and software components, to support broader adoption and community-driven extension. Additional resources and demonstrations are available at the project website: this https URL', 'abstract_zh': 'PAPRLE（即插即用机器人肢体环境）模块化生态系统：灵活的机器人肢体放置与控制', 'title_zh': 'PAPRLE（即插即用可玩机器人肢体环境）：机器人肢体的模块化生态系统'}
{'arxiv_id': 'arXiv:2507.05522', 'title': 'Gaussian Process-Based Active Exploration Strategies in Vision and Touch', 'authors': 'Ho Jin Choi, Nadia Figueroa', 'link': 'https://arxiv.org/abs/2507.05522', 'abstract': 'Robots struggle to understand object properties like shape, material, and semantics due to limited prior knowledge, hindering manipulation in unstructured environments. In contrast, humans learn these properties through interactive multi-sensor exploration. This work proposes fusing visual and tactile observations into a unified Gaussian Process Distance Field (GPDF) representation for active perception of object properties. While primarily focusing on geometry, this approach also demonstrates potential for modeling surface properties beyond geometry. The GPDF encodes signed distance using point cloud, analytic gradient and Hessian, and surface uncertainty estimates, which are attributes that common neural network shape representation lack. By utilizing a point cloud to construct a distance function, GPDF does not need extensive pretraining on large datasets and can incorporate observations by aggregation. Starting with an initial visual shape estimate, the framework iteratively refines the geometry by integrating dense vision measurements using differentiable rendering and tactile measurements at uncertain surface regions. By quantifying multi-sensor uncertainties, it plans exploratory motions to maximize information gain for recovering precise 3D structures. For the real-world robot experiment, we utilize the Franka Research 3 robot manipulator, which is fixed on a table and has a customized DIGIT tactile sensor and an Intel Realsense D435 RGBD camera mounted on the end-effector. In these experiments, the robot explores the shape and properties of objects assumed to be static and placed on the table. To improve scalability, we investigate approximation methods like inducing point method for Gaussian Processes. This probabilistic multi-modal fusion enables active exploration and mapping of complex object geometries, extending potentially beyond geometry.', 'abstract_zh': '机器人由于先验知识有限，难以理解物体的形状、材质和语义属性，这阻碍了其在非结构化环境中的操作。相比之下，人类通过交互式的多传感器探索来学习这些属性。本文提出了一种将视觉和触觉观察融合到统一的高斯过程距离场（GPDF）表示中的方法，以实现对物体属性的主动感知。虽然主要侧重于几何属性，该方法也展示了对几何属性之外的表面属性建模的潜力。GPDF通过点云、分析梯度和 Hess 矩阵以及表面不确定性估计来编码带符号距离，而这些属性是常见神经网络形状表示缺失的。通过利用点云构建距离函数，GPDF不需要在大规模数据集上进行大量的预训练，并且可以通过聚合来纳入观察。从初始的视觉形状估计开始，该框架通过集成密集视图测量和在不确定表面区域的触觉测量迭代地细化几何结构。通过量化多传感器的不确定性，该方法计划探索性运动以最大化信息获取，从而恢复精确的3D结构。在真实世界机器人实验中，我们使用固定在桌子上的 Franka Research 3 机器人操作臂，其末端效应器装有定制的 DIGIT 触觉传感器和 Intel Realsense D435 彩色深度相机。在这些实验中，机器人探索假定为静止并放置在桌面上的物体的形状和属性。为了提高可扩展性，我们研究了高斯过程的近似方法，如诱导点方法。这种概率多模式融合能够主动探索和映射复杂的物体几何结构，扩展可能超越几何属性。', 'title_zh': '基于高斯过程的主动探索策略在视觉和触觉中的应用'}
{'arxiv_id': 'arXiv:2507.05458', 'title': 'CRED: Counterfactual Reasoning and Environment Design for Active Preference Learning', 'authors': 'Yi-Shiuan Tung, Bradley Hayes, Alessandro Roncone', 'link': 'https://arxiv.org/abs/2507.05458', 'abstract': 'For effective real-world deployment, robots should adapt to human preferences, such as balancing distance, time, and safety in delivery routing. Active preference learning (APL) learns human reward functions by presenting trajectories for ranking. However, existing methods often struggle to explore the full trajectory space and fail to identify informative queries, particularly in long-horizon tasks. We propose CRED, a trajectory generation method for APL that improves reward estimation by jointly optimizing environment design and trajectory selection. CRED "imagines" new scenarios through environment design and uses counterfactual reasoning -- by sampling rewards from its current belief and asking "What if this reward were the true preference?" -- to generate a diverse and informative set of trajectories for ranking. Experiments in GridWorld and real-world navigation using OpenStreetMap data show that CRED improves reward learning and generalizes effectively across different environments.', 'abstract_zh': '基于有效实际部署的机器人应适应人类偏好，如在配送路由中平衡距离、时间和安全。基于主动偏好学习（APL）通过提供轨迹进行排序来学习人类奖励函数。然而，现有方法往往难以探索完整的轨迹空间并识别出具有信息性的查询，特别是在长时_horizon_任务中。我们提出了一种用于APL的轨迹生成方法CRED，通过联合优化环境设计和轨迹选择来提高奖励估计。CRED通过环境设计“构想”新的场景，并通过反事实推理——从其当前信念中采样奖励并询问“如果该奖励是真正的偏好会怎样？”——生成一组多样且具有信息性的轨迹供排序。在GridWorld和基于OpenStreetMap数据的真实世界导航实验中，CRED提高了奖励学习并实现了跨不同环境的有效泛化。', 'title_zh': '基于反事实推理和环境设计的主动偏好学习'}
{'arxiv_id': 'arXiv:2507.05410', 'title': 'Feature Geometry for Stereo Sidescan and Forward-looking Sonar', 'authors': 'Kalin Norman, Joshua G. Mangelson', 'link': 'https://arxiv.org/abs/2507.05410', 'abstract': 'In this paper, we address stereo acoustic data fusion for marine robotics and propose a geometry-based method for projecting observed features from one sonar to another for a cross-modal stereo sonar setup that consists of both a forward-looking and a sidescan sonar. Our acoustic geometry for sidescan and forward-looking sonar is inspired by the epipolar geometry for stereo cameras, and we leverage relative pose information to project where an observed feature in one sonar image will be found in the image of another sonar. Additionally, we analyze how both the feature location relative to the sonar and the relative pose between the two sonars impact the projection. From simulated results, we identify desirable stereo configurations for applications in field robotics like feature correspondence and recovery of the 3D information of the feature.', 'abstract_zh': '本文针对海洋机器人提出了一种立体声学数据融合方法，并提出了一种基于几何的方法，将前视声纳和侧扫声纳（一个向前观测，一个向侧面观测）组成的跨模态立体声纳系统中观测到的特征投影到另一声纳的图像上。我们的声纳几何学受到立体摄像机的极线几何学的启发，并利用相对姿态信息预测一个声纳图像中观测到的特征在另一个声纳图像中的位置。此外，我们分析了特征相对于声纳的位置及其俩声纳之间的相对姿态对投影的影响。通过仿真结果，我们确定了适用于场机器人领域的特征对应和特征三维信息恢复的理想立体声纳配置。', 'title_zh': '声纳侧视和前视声纳的特征几何学'}
{'arxiv_id': 'arXiv:2507.05331', 'title': 'A Careful Examination of Large Behavior Models for Multitask Dexterous Manipulation', 'authors': 'TRI LBM Team, Jose Barreiros, Andrew Beaulieu, Aditya Bhat, Rick Cory, Eric Cousineau, Hongkai Dai, Ching-Hsin Fang, Kunimatsu Hashimoto, Muhammad Zubair Irshad, Masha Itkina, Naveen Kuppuswamy, Kuan-Hui Lee, Katherine Liu, Dale McConachie, Ian McMahon, Haruki Nishimura, Calder Phillips-Grafflin, Charles Richter, Paarth Shah, Krishnan Srinivasan, Blake Wulfe, Chen Xu, Mengchao Zhang, Alex Alspach, Maya Angeles, Kushal Arora, Vitor Campagnolo Guizilini, Alejandro Castro, Dian Chen, Ting-Sheng Chu, Sam Creasey, Sean Curtis, Richard Denitto, Emma Dixon, Eric Dusel, Matthew Ferreira, Aimee Goncalves, Grant Gould, Damrong Guoy, Swati Gupta, Xuchen Han, Kyle Hatch, Brendan Hathaway, Allison Henry, Hillel Hochsztein, Phoebe Horgan, Shun Iwase, Donovon Jackson, Siddharth Karamcheti, Sedrick Keh, Joseph Masterjohn, Jean Mercat, Patrick Miller, Paul Mitiguy, Tony Nguyen, Jeremy Nimmer, Yuki Noguchi, Reko Ong, Aykut Onol, Owen Pfannenstiehl, Richard Poyner, Leticia Priebe Mendes Rocha, Gordon Richardson, Christopher Rodriguez, Derick Seale, Michael Sherman, Mariah Smith-Jones, David Tago, Pavel Tokmakov, Matthew Tran, Basile Van Hoorick, Igor Vasiljevic, Sergey Zakharov, Mark Zolotas, Rares Ambrus, Kerri Fetzer-Borelli, Benjamin Burchfiel, Hadas Kress-Gazit, Siyuan Feng, Stacie Ford, Russ Tedrake', 'link': 'https://arxiv.org/abs/2507.05331', 'abstract': 'Robot manipulation has seen tremendous progress in recent years, with imitation learning policies enabling successful performance of dexterous and hard-to-model tasks. Concurrently, scaling data and model size has led to the development of capable language and vision foundation models, motivating large-scale efforts to create general-purpose robot foundation models. While these models have garnered significant enthusiasm and investment, meaningful evaluation of real-world performance remains a challenge, limiting both the pace of development and inhibiting a nuanced understanding of current capabilities. In this paper, we rigorously evaluate multitask robot manipulation policies, referred to as Large Behavior Models (LBMs), by extending the Diffusion Policy paradigm across a corpus of simulated and real-world robot data. We propose and validate an evaluation pipeline to rigorously analyze the capabilities of these models with statistical confidence. We compare against single-task baselines through blind, randomized trials in a controlled setting, using both simulation and real-world experiments. We find that multi-task pretraining makes the policies more successful and robust, and enables teaching complex new tasks more quickly, using a fraction of the data when compared to single-task baselines. Moreover, performance predictably increases as pretraining scale and diversity grows. Project page: this https URL', 'abstract_zh': '机器人操作在近年来取得了 tremendous 进展，模仿学习策略使其能够成功完成灵巧且难以建模的任务。同时，数据和模型规模的扩展推动了强大语言和视觉基础模型的发展，激发了创建通用机器人基础模型的大规模努力。尽管这些模型吸引了大量关注和投资，但对其实际性能的有效评估仍然是一项挑战，限制了研发的步伐，并阻碍了对当前能力的深入理解。本文通过将扩散策略 paradigm 扩展到模拟和实际机器人数据集，严格评估多任务机器人操作策略，称为大型行为模型（LBMs）。我们提出并验证了一种评估管道，以统计学信心严格分析这些模型的能力。我们通过控制环境下的盲随机试验，使用模拟和实际实验来与单任务基线进行对比。我们发现，多任务预训练使策略更加成功且稳健，并能更快地教授复杂的新型任务，所需数据仅为单任务基线的一小部分。此外，预训练规模和多样性增长时，性能可预测地提高。项目页面: this https URL', 'title_zh': '大规模行为模型在多任务灵巧操作中的仔细考察'}
{'arxiv_id': 'arXiv:2507.06111', 'title': 'Safe Domain Randomization via Uncertainty-Aware Out-of-Distribution Detection and Policy Adaptation', 'authors': 'Mohamad H. Danesh, Maxime Wabartha, Stanley Wu, Joelle Pineau, Hsiu-Chin Lin', 'link': 'https://arxiv.org/abs/2507.06111', 'abstract': 'Deploying reinforcement learning (RL) policies in real-world involves significant challenges, including distribution shifts, safety concerns, and the impracticality of direct interactions during policy refinement. Existing methods, such as domain randomization (DR) and off-dynamics RL, enhance policy robustness by direct interaction with the target domain, an inherently unsafe practice. We propose Uncertainty-Aware RL (UARL), a novel framework that prioritizes safety during training by addressing Out-Of-Distribution (OOD) detection and policy adaptation without requiring direct interactions in target domain. UARL employs an ensemble of critics to quantify policy uncertainty and incorporates progressive environmental randomization to prepare the policy for diverse real-world conditions. By iteratively refining over high-uncertainty regions of the state space in simulated environments, UARL enhances robust generalization to the target domain without explicitly training on it. We evaluate UARL on MuJoCo benchmarks and a quadrupedal robot, demonstrating its effectiveness in reliable OOD detection, improved performance, and enhanced sample efficiency compared to baselines.', 'abstract_zh': '基于不确定性感知的强化学习（UARL）：一种在训练期间优先考虑安全性的新框架', 'title_zh': '基于不确定性意识的域外检测与策略调整的安全领域随机化'}
{'arxiv_id': 'arXiv:2507.05906', 'title': 'Feature-Based vs. GAN-Based Learning from Demonstrations: When and Why', 'authors': 'Chenhao Li, Marco Hutter, Andreas Krause', 'link': 'https://arxiv.org/abs/2507.05906', 'abstract': 'This survey provides a comparative analysis of feature-based and GAN-based approaches to learning from demonstrations, with a focus on the structure of reward functions and their implications for policy learning. Feature-based methods offer dense, interpretable rewards that excel at high-fidelity motion imitation, yet often require sophisticated representations of references and struggle with generalization in unstructured settings. GAN-based methods, in contrast, use implicit, distributional supervision that enables scalability and adaptation flexibility, but are prone to training instability and coarse reward signals. Recent advancements in both paradigms converge on the importance of structured motion representations, which enable smoother transitions, controllable synthesis, and improved task integration. We argue that the dichotomy between feature-based and GAN-based methods is increasingly nuanced: rather than one paradigm dominating the other, the choice should be guided by task-specific priorities such as fidelity, diversity, interpretability, and adaptability. This work outlines the algorithmic trade-offs and design considerations that underlie method selection, offering a framework for principled decision-making in learning from demonstrations.', 'abstract_zh': '基于特征的方法与基于生成对抗网络的方法在示 REUTERS 数据集上的比较分析：奖励函数结构及其对策略学习的影响', 'title_zh': '基于特征的学习与基于生成对抗网络的学习从演示中学习：何时以及为何选用'}
{'arxiv_id': 'arXiv:2507.05867', 'title': 'Assessing Linear Control Strategies for Zero-Speed Fin Roll Damping', 'authors': 'Nikita Savin, Elena Ambrosovskaya, Dmitry Romaev, Anton Proskurnikov', 'link': 'https://arxiv.org/abs/2507.05867', 'abstract': 'Roll stabilization is a critical aspect of ship motion control, particularly for vessels operating in low-speed or zero-speed conditions, where traditional hydrodynamic fins lose their effectiveness. In this paper, we consider a roll damping system, developed by Navis JSC, based on two actively controlled zero-speed fins. Unlike conventional fin stabilizers, zero-speed fins employ a drag-based mechanism and active oscillations to generate stabilizing forces even when the vessel is stationary. We propose a simple linear control architecture that, however, accounts for nonlinear drag forces and actuator limitations. Simulation results on a high-fidelity vessel model used for HIL testing demonstrate the effectiveness of the proposed approach.', 'abstract_zh': '基于零速鳍片的卷制衰减系统在船舶低速或静止状态下的横摇抑制', 'title_zh': '评估零速度鳍卷阻尼的线性控制策略'}
{'arxiv_id': 'arXiv:2507.05698', 'title': 'Event-RGB Fusion for Spacecraft Pose Estimation Under Harsh Lighting', 'authors': 'Mohsi Jawaid, Marcus Märtens, Tat-Jun Chin', 'link': 'https://arxiv.org/abs/2507.05698', 'abstract': 'Spacecraft pose estimation is crucial for autonomous in-space operations, such as rendezvous, docking and on-orbit servicing. Vision-based pose estimation methods, which typically employ RGB imaging sensors, is a compelling solution for spacecraft pose estimation, but are challenged by harsh lighting conditions, which produce imaging artifacts such as glare, over-exposure, blooming and lens flare. Due to their much higher dynamic range, neuromorphic or event sensors are more resilient to extreme lighting conditions. However, event sensors generally have lower spatial resolution and suffer from reduced signal-to-noise ratio during periods of low relative motion. This work addresses these individual sensor limitations by introducing a sensor fusion approach combining RGB and event sensors. A beam-splitter prism was employed to achieve precise optical and temporal alignment. Then, a RANSAC-based technique was developed to fuse the information from the RGB and event channels to achieve pose estimation that leveraged the strengths of the two modalities. The pipeline was complemented by dropout uncertainty estimation to detect extreme conditions that affect either channel. To benchmark the performance of the proposed event-RGB fusion method, we collected a comprehensive real dataset of RGB and event data for satellite pose estimation in a laboratory setting under a variety of challenging illumination conditions. Encouraging results on the dataset demonstrate the efficacy of our event-RGB fusion approach and further supports the usage of event sensors for spacecraft pose estimation. To support community research on this topic, our dataset will be released publicly.', 'abstract_zh': '基于RGB和事件传感器融合的航天器姿态估计方法', 'title_zh': '基于事件-RGB融合的空间探测器姿态估计在恶劣光照条件下的方法'}
