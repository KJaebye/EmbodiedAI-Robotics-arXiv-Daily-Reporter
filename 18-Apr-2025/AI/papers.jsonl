{'arxiv_id': 'arXiv:2504.13171', 'title': 'Sleep-time Compute: Beyond Inference Scaling at Test-time', 'authors': 'Kevin Lin, Charlie Snell, Yu Wang, Charles Packer, Sarah Wooders, Ion Stoica, Joseph E. Gonzalez', 'link': 'https://arxiv.org/abs/2504.13171', 'abstract': 'Scaling test-time compute has emerged as a key ingredient for enabling large language models (LLMs) to solve difficult problems, but comes with high latency and inference cost. We introduce sleep-time compute, which allows models to "think" offline about contexts before queries are presented: by anticipating what queries users might ask and pre-computing useful quantities, we can significantly reduce the compute requirements at test-time. To demonstrate the efficacy of our method, we create modified versions of two reasoning tasks - Stateful GSM-Symbolic and Stateful AIME. We find that sleep-time compute can reduce the amount of test-time compute needed to achieve the same accuracy by ~ 5x on Stateful GSM-Symbolic and Stateful AIME and that by scaling sleep-time compute we can further increase accuracy by up to 13% on Stateful GSM-Symbolic and 18% on Stateful AIME. Furthermore, we introduce Multi-Query GSM-Symbolic, which extends GSM-Symbolic by including multiple related queries per context. By amortizing sleep-time compute across related queries about the same context using Multi-Query GSM-Symbolic, we can decrease the average cost per query by 2.5x. We then conduct additional analysis to understand when sleep-time compute is most effective, finding the predictability of the user query to be well correlated with the efficacy of sleep-time compute. Finally, we conduct a case-study of applying sleep-time compute to a realistic agentic SWE task.', 'abstract_zh': '睡眠时间计算作为一种降低测试时计算需求的方法，在帮助大型语言模型解决复杂问题方面展现出关键作用，但同时也带来了高延迟和推理成本。我们引入了睡眠时间计算，允许模型在接收到查询之前对上下文进行“离线思考”：通过预测用户可能提出的查询并预先计算有用的数量，可以显著减少测试时的计算需求。为了演示我们方法的有效性，我们对两种推理任务——有状态的GSM-Symbolic和有状态的AIME进行了修改版本的创建。我们发现，睡眠时间计算可以使在Stateful GSM-Symbolic和Stateful AIME上实现相同准确度所需的测试时计算量减少约5倍，并且通过扩展睡眠时间计算的规模，可以在Stateful GSM-Symbolic上进一步提高多达13%的准确率，在Stateful AIME上提高多达18%的准确率。此外，我们引入了多查询GSM-Symbolic，它通过每个上下文中包含多个相关的查询来扩展GSM-Symbolic。使用多查询GSM-Symbolic来摊销针对相同上下文的多个相关查询的睡眠时间计算，可以将每查询的平均成本降低2.5倍。然后我们进行了进一步的分析，以了解何时睡眠时间计算最为有效，并发现用户查询的可预测性与睡眠时间计算的效果密切相关。最后，我们对将睡眠时间计算应用于一个实际的代理SWE任务进行了案例研究。', 'title_zh': '睡眠时间计算：超越测试时的推理扩展'}
{'arxiv_id': 'arXiv:2504.13150', 'title': 'Readable Twins of Unreadable Models', 'authors': 'Krzysztof Pancerz, Piotr Kulicki, Michał Kalisz, Andrzej Burda, Maciej Stanisławski, Jaromir Sarzyński', 'link': 'https://arxiv.org/abs/2504.13150', 'abstract': 'Creating responsible artificial intelligence (AI) systems is an important issue in contemporary research and development of works on AI. One of the characteristics of responsible AI systems is their explainability. In the paper, we are interested in explainable deep learning (XDL) systems. On the basis of the creation of digital twins of physical objects, we introduce the idea of creating readable twins (in the form of imprecise information flow models) for unreadable deep learning models. The complete procedure for switching from the deep learning model (DLM) to the imprecise information flow model (IIFM) is presented. The proposed approach is illustrated with an example of a deep learning classification model for image recognition of handwritten digits from the MNIST data set.', 'abstract_zh': '负责任的人工智能系统创建是当前人工智能研究与开发中的一个重要议题。负责任的人工智能系统的一个特征是可解释性。在本文中，我们关注可解释的深度学习(XDL)系统。基于物理对象的数字孪生创建，我们提出了创建易于理解的孪生（以不精确信息流模型的形式）的思想，以解释难以理解的深度学习模型。从深度学习模型(DLM)切换到不精确信息流模型(IIFM)的完整过程被详细呈现。所提出的方法通过一个基于MNIST数据集的手写数字图像识别深度学习分类模型示例进行了说明。', 'title_zh': '难读模型的易读双胞胎'}
{'arxiv_id': 'arXiv:2504.13146', 'title': 'Antidistillation Sampling', 'authors': 'Yash Savani, Asher Trockman, Zhili Feng, Avi Schwarzschild, Alexander Robey, Marc Finzi, J. Zico Kolter', 'link': 'https://arxiv.org/abs/2504.13146', 'abstract': "Frontier models that generate extended reasoning traces inadvertently produce rich token sequences that can facilitate model distillation. Recognizing this vulnerability, model owners may seek sampling strategies that limit the effectiveness of distillation without compromising model performance. \\emph{Antidistillation sampling} provides exactly this capability. By strategically modifying a model's next-token probability distribution, antidistillation sampling poisons reasoning traces, rendering them significantly less effective for distillation while preserving the model's practical utility. For further details, see this https URL.", 'abstract_zh': '对抗蒸馏采样通过战略性修改模型的下一-token概率分布，污染推理踪迹，从而显著降低其蒸馏有效性，同时保持模型的实际实用价值。更多信息，请参见：https://<insert_link_here>', 'title_zh': '反浓缩采样'}
{'arxiv_id': 'arXiv:2504.13145', 'title': 'Exploring Expert Failures Improves LLM Agent Tuning', 'authors': 'Li-Cheng Lan, Andrew Bai, Minhao Cheng, Ruochen Wang, Cho-Jui Hsieh, Tianyi Zhou', 'link': 'https://arxiv.org/abs/2504.13145', 'abstract': 'Large Language Models (LLMs) have shown tremendous potential as agents, excelling at tasks that require multiple rounds of reasoning and interactions. Rejection Sampling Fine-Tuning (RFT) has emerged as an effective method for finetuning LLMs as agents: it first imitates expert-generated successful trajectories and further improves agentic skills through iterative fine-tuning on successful, self-generated trajectories. However, since the expert (e.g., GPT-4) succeeds primarily on simpler subtasks and RFT inherently favors simpler scenarios, many complex subtasks remain unsolved and persistently out-of-distribution (OOD). Upon investigating these challenging subtasks, we discovered that previously failed expert trajectories can often provide valuable guidance, e.g., plans and key actions, that can significantly improve agent exploration efficiency and acquisition of critical skills. Motivated by these observations, we propose Exploring Expert Failures (EEF), which identifies beneficial actions from failed expert trajectories and integrates them into the training dataset. Potentially harmful actions are meticulously excluded to prevent contamination of the model learning process. By leveraging the beneficial actions in expert failures, EEF successfully solves some previously unsolvable subtasks and improves agent tuning performance. Remarkably, our approach achieved a 62\\% win rate in WebShop, outperforming RFT (53. 6\\%) and GPT-4 (35. 6\\%), and to the best of our knowledge, setting a new state-of-the-art as the first method to surpass a score of 0.81 in WebShop and exceed 81 in SciWorld.', 'abstract_zh': '大规模语言模型（LLMs）作为代理表现出巨大的潜力，擅长需要多轮推理和交互的任务。拒绝采样微调（RFT）已成为一种有效的LLM代理微调方法：它首先模仿專家生成的成功轨迹，并通过迭代微调成功、自我生成的轨迹进一步提升代理技能。然而，由于专家（例如GPT-4）主要在较简单的子任务上成功，而且RFT本身更倾向于简单的场景，许多复杂的子任务仍然无法解决并且持续处于分布之外（OOD）。在调查这些具有挑战性的子任务后，我们发现，先前失败的专家轨迹通常能提供有价值的指导，例如计划和关键行为，这些能显著提高代理的探索效率和关键技能的获取。受这些观察的启发，我们提出了探索专家失败（EEF），该方法从失败的专家轨迹中识别有益的动作，并将这些动作整合到训练数据集中。潜在有害的动作被仔细排除，以防止污染模型的学习过程。通过利用专家失败中的有益动作，EEF成功解决了部分先前无法解决的子任务，并提高了代理的调优性能。值得注意的是，我们的方法在WebShop中的胜率为62%，超过RFT（53.6%）和GPT-4（35.6%），据我们所知，这是首次方法在WebShop中超过0.81分数并在SciWorld中超过81分，达到了新的最先进水平。', 'title_zh': '探索专家失败有助于提升LLM代理调优'}
{'arxiv_id': 'arXiv:2504.13032', 'title': 'InstructRAG: Leveraging Retrieval-Augmented Generation on Instruction Graphs for LLM-Based Task Planning', 'authors': 'Zheng Wang, Shu Xian Teo, Jun Jie Chew, Wei Shi', 'link': 'https://arxiv.org/abs/2504.13032', 'abstract': "Recent advancements in large language models (LLMs) have enabled their use as agents for planning complex tasks. Existing methods typically rely on a thought-action-observation (TAO) process to enhance LLM performance, but these approaches are often constrained by the LLMs' limited knowledge of complex tasks. Retrieval-augmented generation (RAG) offers new opportunities by leveraging external databases to ground generation in retrieved information. In this paper, we identify two key challenges (enlargability and transferability) in applying RAG to task planning. We propose InstructRAG, a novel solution within a multi-agent meta-reinforcement learning framework, to address these challenges. InstructRAG includes a graph to organize past instruction paths (sequences of correct actions), an RL-Agent with Reinforcement Learning to expand graph coverage for enlargability, and an ML-Agent with Meta-Learning to improve task generalization for transferability. The two agents are trained end-to-end to optimize overall planning performance. Our experiments on four widely used task planning datasets demonstrate that InstructRAG significantly enhances performance and adapts efficiently to new tasks, achieving up to a 19.2% improvement over the best existing approach.", 'abstract_zh': '近期大规模语言模型的进展使其能够作为规划复杂任务的代理。现有的方法通常依赖于思考-行动-观察（TAO）过程来提升语言模型的性能，但这些方法往往受限于语言模型对复杂任务的有限知识。检索增强生成（RAG）通过利用外部数据库提供的相关信息提供了新的机遇。在本文中，我们识别了将RAG应用于任务规划时的两个关键挑战（可扩展性和移植性）。我们提出了InstructRAG，这是一种基于多代理元强化学习框架的新颖解决方案，以应对这些挑战。InstructRAG包含一个图来组织过去指令路径（正确行动的序列），一个通过强化学习扩展图覆盖范围以实现可扩展性的RL-Agent，以及一个通过元学习提高任务泛化能力的ML-Agent。两个代理端到端训练以优化整体规划性能。我们在四个广泛使用的任务规划数据集上的实验表明，InstructRAG显著提升了性能并能高效地适应新任务，相比现有最佳方法实现了高达19.2%的性能提升。', 'title_zh': '基于指令图的检索增强生成方法：InstructRAG'}
{'arxiv_id': 'arXiv:2504.12682', 'title': 'WebLists: Extracting Structured Information From Complex Interactive Websites Using Executable LLM Agents', 'authors': 'Arth Bohra, Manvel Saroyan, Danil Melkozerov, Vahe Karufanyan, Gabriel Maher, Pascal Weinberger, Artem Harutyunyan, Giovanni Campagna', 'link': 'https://arxiv.org/abs/2504.12682', 'abstract': 'Most recent web agent research has focused on navigation and transaction tasks, with little emphasis on extracting structured data at scale. We present WebLists, a benchmark of 200 data-extraction tasks across four common business and enterprise use-cases. Each task requires an agent to navigate to a webpage, configure it appropriately, and extract complete datasets with well-defined schemas. We show that both LLMs with search capabilities and SOTA web agents struggle with these tasks, with a recall of 3% and 31%, respectively, despite higher performance on question-answering tasks.\nTo address this challenge, we propose BardeenAgent, a novel framework that enables web agents to convert their execution into repeatable programs, and replay them at scale across pages with similar structure. BardeenAgent is also the first LLM agent to take advantage of the regular structure of HTML. In particular BardeenAgent constructs a generalizable CSS selector to capture all relevant items on the page, then fits the operations to extract the data.\nOn the WebLists benchmark, BardeenAgent achieves 66% recall overall, more than doubling the performance of SOTA web agents, and reducing cost per output row by 3x.', 'abstract_zh': '最近的网络代理研究主要集中在导航和交易任务上，对大规模提取结构化数据的关注较少。我们提出了WebLists基准，包含涵盖四种常见商业和企业应用场景的200项数据提取任务。每个任务都需要代理导航到网页，适当地配置网页，并提取具有明确模式的完整数据集。研究表明，具有搜索能力的语言模型和最先进的网络代理在这些任务上表现不佳，召回率分别为3%和31%，尽管在问答任务上表现出更高的性能。\n\n为了应对这一挑战，我们提出了一种名为BardeenAgent的新框架，该框架使网络代理能够将其实现转换为可重复的程序，并在具有相似结构的页面上大规模重放这些程序。此外，BardeenAgent是首个利用HTML规律结构的语言模型代理。具体而言，BardeenAgent构建了一种可泛化的CSS选择器，以捕获页面上所有相关项，然后将操作适应以提取数据。\n\n在WebLists基准测试中，BardeenAgent的整体召回率为66%，相比最先进的网络代理性能提高了两倍多，产出每行的成本降低了3倍。', 'title_zh': 'WebLists：使用可执行的大语言模型代理从复杂交互式网站中提取结构化信息'}
{'arxiv_id': 'arXiv:2504.12680', 'title': 'Embodied-R: Collaborative Framework for Activating Embodied Spatial Reasoning in Foundation Models via Reinforcement Learning', 'authors': 'Baining Zhao, Ziyou Wang, Jianjie Fang, Chen Gao, Fanhang Man, Jinqiang Cui, Xin Wang, Xinlei Chen, Yong Li, Wenwu Zhu', 'link': 'https://arxiv.org/abs/2504.12680', 'abstract': 'Humans can perceive and reason about spatial relationships from sequential visual observations, such as egocentric video streams. However, how pretrained models acquire such abilities, especially high-level reasoning, remains unclear. This paper introduces Embodied-R, a collaborative framework combining large-scale Vision-Language Models (VLMs) for perception and small-scale Language Models (LMs) for reasoning. Using Reinforcement Learning (RL) with a novel reward system considering think-answer logical consistency, the model achieves slow-thinking capabilities with limited computational resources. After training on only 5k embodied video samples, Embodied-R with a 3B LM matches state-of-the-art multimodal reasoning models (OpenAI-o1, Gemini-2.5-pro) on both in-distribution and out-of-distribution embodied spatial reasoning tasks. Embodied-R also exhibits emergent thinking patterns such as systematic analysis and contextual integration. We further explore research questions including response length, training on VLM, strategies for reward design, and differences in model generalization after SFT (Supervised Fine-Tuning) and RL training.', 'abstract_zh': '人类可以从连续的视觉观察中感知和推理空间关系，例如第一人称视频流。然而，预训练模型如何获取这些能力，尤其是高级推理能力，尚不明确。本文介绍了一种协作框架Embodied-R，该框架结合大规模视觉-语言模型（VLMs）用于感知，小型语言模型（LMs）用于推理。通过考虑思考-回答逻辑一致性的新型强化学习（RL）奖励系统，模型在有限的计算资源下实现了慢思考能力。在仅使用5000个 embodied 视频样本训练后，Embodied-R 结合一个3B LMs达到了当前最先进的跨模态推理模型（OpenAI-o1，Gemini-2.5-pro）在分布内和分布外 embodied 空间推理任务中的性能。Embodied-R 还展示了系统分析和上下文整合等新兴思考模式。我们进一步探讨了包括响应长度、在VLM上进行训练、奖励设计策略以及SFT（监督微调）和RL训练后模型泛化能力差异等研究问题。', 'title_zh': '具身-R：通过强化学习激活基础模型中具身处境空间推理的协作框架'}
{'arxiv_id': 'arXiv:2504.12612', 'title': 'The Chronicles of Foundation AI for Forensics of Multi-Agent Provenance', 'authors': 'Ching-Chun Chang, Isao Echizen', 'link': 'https://arxiv.org/abs/2504.12612', 'abstract': 'Provenance is the chronology of things, resonating with the fundamental pursuit to uncover origins, trace connections, and situate entities within the flow of space and time. As artificial intelligence advances towards autonomous agents capable of interactive collaboration on complex tasks, the provenance of generated content becomes entangled in the interplay of collective creation, where contributions are continuously revised, extended or overwritten. In a multi-agent generative chain, content undergoes successive transformations, often leaving little, if any, trace of prior contributions. In this study, we investigates the problem of tracking multi-agent provenance across the temporal dimension of generation. We propose a chronological system for post hoc attribution of generative history from content alone, without reliance on internal memory states or external meta-information. At its core lies the notion of symbolic chronicles, representing signed and time-stamped records, in a form analogous to the chain of custody in forensic science. The system operates through a feedback loop, whereby each generative timestep updates the chronicle of prior interactions and synchronises it with the synthetic content in the very act of generation. This research seeks to develop an accountable form of collaborative artificial intelligence within evolving cyber ecosystems.', 'abstract_zh': '起源追踪：复杂任务中交互生成内容的时间维度集体创作追溯体系研究', 'title_zh': 'Foundation AI for 多代理溯源的forensics 纪事'}
{'arxiv_id': 'arXiv:2504.12562', 'title': 'ZeroSumEval: Scaling LLM Evaluation with Inter-Model Competition', 'authors': 'Haidar Khan, Hisham A. Alyahya, Yazeed Alnumay, M Saiful Bari, Bülent Yener', 'link': 'https://arxiv.org/abs/2504.12562', 'abstract': "Evaluating the capabilities of Large Language Models (LLMs) has traditionally relied on static benchmark datasets, human assessments, or model-based evaluations - methods that often suffer from overfitting, high costs, and biases. ZeroSumEval is a novel competition-based evaluation protocol that leverages zero-sum games to assess LLMs with dynamic benchmarks that resist saturation. ZeroSumEval encompasses a diverse suite of games, including security challenges (PyJail), classic games (Chess, Liar's Dice, Poker), knowledge tests (MathQuiz), and persuasion challenges (Gandalf, Debate). These games are designed to evaluate a range of AI capabilities such as strategic reasoning, planning, knowledge application, and creativity. Building upon recent studies that highlight the effectiveness of game-based evaluations for LLMs, ZeroSumEval enhances these approaches by providing a standardized and extensible framework. To demonstrate this, we conduct extensive experiments with >7000 simulations across 7 games and 13 models. Our results show that while frontier models from the GPT and Claude families can play common games and answer questions, they struggle to play games that require creating novel and challenging questions. We also observe that models cannot reliably jailbreak each other and fail generally at tasks requiring creativity. We release our code at this https URL.", 'abstract_zh': '评估大型语言模型（LLMs）的能力 traditionally 依赖于静态基准数据集、人工评估或基于模型的评估——这些方法 often 患有过度拟合、高成本和偏见的问题。ZeroSumEval 是一种新颖的竞争性评估协议，利用零和博弈来使用动态基准评估 LLMs，这些基准 resists 满载。ZeroSumEval 包含一系列多样的游戏，包括安全挑战（PyJail）、经典游戏（国际象棋、骰子谎言、扑克）、知识测试（MathQuiz）和说服挑战（Gandalf、辩论）。这些游戏旨在评估战略推理、规划、知识运用和创造性等一系列 AI 能力。基于最近研究强调的游戏评估方法对 LLMs 的有效性，ZeroSumEval 在此之上提供了一个标准化且可扩展的框架。为了证明这一点，我们在 7 款游戏中进行了超过 7000 次模拟，涵盖了 13 模型。结果表明，GPT 和 Claude 家族的前沿模型可以玩常见游戏和回答问题，但在需要创建新颖和具有挑战性的问题的游戏上表现不佳。我们还观察到，模型无法可靠地互相越狱，并且在需要创造力的任务上普遍表现不佳。我们在此 https:// 上发布我们的代码。', 'title_zh': 'ZeroSumEval: 利用模型间竞争扩展LLM评估'}
{'arxiv_id': 'arXiv:2504.12529', 'title': 'Is Trust Correlated With Explainability in AI? A Meta-Analysis', 'authors': 'Zahra Atf, Peter R. Lewis', 'link': 'https://arxiv.org/abs/2504.12529', 'abstract': 'This study critically examines the commonly held assumption that explicability in artificial intelligence (AI) systems inherently boosts user trust. Utilizing a meta-analytical approach, we conducted a comprehensive examination of the existing literature to explore the relationship between AI explainability and trust. Our analysis, incorporating data from 90 studies, reveals a statistically significant but moderate positive correlation between the explainability of AI systems and the trust they engender among users. This indicates that while explainability contributes to building trust, it is not the sole or predominant factor in this equation. In addition to academic contributions to the field of Explainable AI (XAI), this research highlights its broader socio-technical implications, particularly in promoting accountability and fostering user trust in critical domains such as healthcare and justice. By addressing challenges like algorithmic bias and ethical transparency, the study underscores the need for equitable and sustainable AI adoption. Rather than focusing solely on immediate trust, we emphasize the normative importance of fostering authentic and enduring trustworthiness in AI systems.', 'abstract_zh': '本研究批判性地审视了人工智能（AI）系统中可解释性普遍被认为会增强用户信任这一假设。通过元分析的方法，我们对现有文献进行了全面考察，探讨了AI解释性和信任之间的关系。我们的分析结合了90项研究的数据，揭示出AI系统的可解释性与用户信任之间存在统计学上显著但中等程度的正相关关系。这表明虽然可解释性有助于建立信任，但它不是这一方程中的唯一或主要因素。除了为可解释人工智能（XAI）领域的学术贡献外，本研究还强调了其更广泛的社会和技术意义，特别是在医疗保健和司法等关键领域促进问责制和用户信任方面的重要性。通过解决算法偏见和伦理透明度等挑战，研究突显了公平和可持续的AI采用的必要性。本研究强调了培养AI系统中真实持久的信任价值的规范重要性，而不仅仅是即时的信任。', 'title_zh': 'AI中的可解释性与信任相关吗？一项元分析'}
{'arxiv_id': 'arXiv:2504.12497', 'title': 'Heuristic Recognition and Rapid Response to Unfamiliar Events Outside of Agent Design Scope', 'authors': 'Robert E. Wray, Steven J. Jones, John E. Laird', 'link': 'https://arxiv.org/abs/2504.12497', 'abstract': 'Regardless of past learning, an agent in an open world will face unfamiliar situations and events outside of prior experience, existing models, or policies. Further, the agent will sometimes lack relevant knowledge and/or sufficient time to assess the situation, generate and evaluate options, and pursue a robustly considered course of action. How can an agent respond reasonably to situations that are outside of its original design scope? How can it recognize such situations sufficiently quickly and reliably to determine reasonable, adaptive courses of action? We identify key characteristics needed for solutions, evaluate the state-of-the-art by these requirements, and outline a proposed, novel approach that combines domain-general meta-knowledge (in the form of appraisals inspired by human cognition) and metareasoning. It has the potential to provide fast, adaptive responses to unfamiliar situations, more fully meeting the performance characteristics required for open-world, general agents.', 'abstract_zh': '无论过去的学习如何，一个开放世界中的智能体将面临超出其先前经验、现有模型或策略的不熟悉情况和事件。此外，智能体有时会缺乏相关的知识和/或充足的时间来评估情况、产生和评估选项，并采取一个慎重考虑的行动方案。当情况超出了其原始设计范围时，智能体如何做出合理的反应？它如何能够足够快速和可靠地识别这些情况，以确定合理的适应性行动方案？我们识别出所需的关键特征，根据这些要求评估现有的最先进的方法，并提出一种新的结合领域通用元知识（以人类认知启发的评估形式）和元推理的方法。该方法具有提供快速适应性反应以处理不熟悉情况的潜力，更全面地满足开放世界通用智能体所需的表现特征。', 'title_zh': '启发式识别和快速响应超出代理设计范围的陌生事件'}
{'arxiv_id': 'arXiv:2504.12482', 'title': 'Agentic AI Optimisation (AAIO): what it is, how it works, why it matters, and how to deal with it', 'authors': 'Luciano Floridi, Carlotta Buttaboni, Emmie Hine, Jessica Morley, Claudio Novelli, Tyler Schroder', 'link': 'https://arxiv.org/abs/2504.12482', 'abstract': "The emergence of Agentic Artificial Intelligence (AAI) systems capable of independently initiating digital interactions necessitates a new optimisation paradigm designed explicitly for seamless agent-platform interactions. This article introduces Agentic AI Optimisation (AAIO) as an essential methodology for ensuring effective integration between websites and agentic AI systems. Like how Search Engine Optimisation (SEO) has shaped digital content discoverability, AAIO can define interactions between autonomous AI agents and online platforms. By examining the mutual interdependency between website optimisation and agentic AI success, the article highlights the virtuous cycle that AAIO can create. It further explores the governance, ethical, legal, and social implications (GELSI) of AAIO, emphasising the necessity of proactive regulatory frameworks to mitigate potential negative impacts. The article concludes by affirming AAIO's essential role as part of a fundamental digital infrastructure in the era of autonomous digital agents, advocating for equitable and inclusive access to its benefits.", 'abstract_zh': '具备自主发起数字交互能力的代理人工智能（AAI）系统 emergence necessitates a new optimisation paradigm designed explicitly for seamless agent-platform interactions. 这篇文章介绍了代理人工智能优化（AAIO）作为确保网站和代理人工智能系统有效集成的重要方法。类似于搜索引擎优化（SEO）塑造了数字内容的可发现性，AAIO 可以定义自主人工智能代理与在线平台之间的交互。通过分析网站优化与代理人工智能成功之间的互依关系，本文强调了AAIO 可以创造的良性循环。进一步探讨了AAIO 的治理、伦理、法律和社会影响（GELSI），强调了需要前瞻性的监管框架来减轻潜在的负面影响。文章最后肯定了AAIO 在自主数字代理时代作为基础数字基础设施的重要作用，倡导其利益的公平和包容性访问。', 'title_zh': '代理人工智能优化（AAIO）：什么是代理人工智能优化，它如何运作，为何重要，以及如何应对'}
{'arxiv_id': 'arXiv:2504.12477', 'title': 'Towards Conversational AI for Human-Machine Collaborative MLOps', 'authors': 'George Fatouros, Georgios Makridis, George Kousiouris, John Soldatos, Anargyros Tsadimas, Dimosthenis Kyriazis', 'link': 'https://arxiv.org/abs/2504.12477', 'abstract': 'This paper presents a Large Language Model (LLM) based conversational agent system designed to enhance human-machine collaboration in Machine Learning Operations (MLOps). We introduce the Swarm Agent, an extensible architecture that integrates specialized agents to create and manage ML workflows through natural language interactions. The system leverages a hierarchical, modular design incorporating a KubeFlow Pipelines (KFP) Agent for ML pipeline orchestration, a MinIO Agent for data management, and a Retrieval-Augmented Generation (RAG) Agent for domain-specific knowledge integration. Through iterative reasoning loops and context-aware processing, the system enables users with varying technical backgrounds to discover, execute, and monitor ML pipelines; manage datasets and artifacts; and access relevant documentation, all via intuitive conversational interfaces. Our approach addresses the accessibility gap in complex MLOps platforms like Kubeflow, making advanced ML tools broadly accessible while maintaining the flexibility to extend to other platforms. The paper describes the architecture, implementation details, and demonstrates how this conversational MLOps assistant reduces complexity and lowers barriers to entry for users across diverse technical skill levels.', 'abstract_zh': '基于大型语言模型的 Swarm 剂体制作人机协作增强的机器学习运营（MLOps）对话代理系统', 'title_zh': '面向人类-机器协作MLOps的对话式AI'}
{'arxiv_id': 'arXiv:2504.12417', 'title': 'Interpretable AI-driven Guidelines for Type 2 Diabetes Treatment from Observational Data', 'authors': 'Dewang Kumar Agarwal, Dimitris J. Bertsimas', 'link': 'https://arxiv.org/abs/2504.12417', 'abstract': "Objective: Create precise, structured, data-backed guidelines for type 2 diabetes treatment progression, suitable for clinical adoption.\nResearch Design and Methods: Our training cohort was composed of patient (with type 2 diabetes) visits from Boston Medical Center (BMC) from 1998 to 2014. We divide visits into 4 groups based on the patient's treatment regimen before the visit, and further divide them into subgroups based on the recommended treatment during the visit. Since each subgroup has observational data, which has confounding bias (sicker patients are prescribed more aggressive treatments), we used machine learning and optimization to remove some datapoints so that the remaining data resembles a randomized trial. On each subgroup, we train AI-backed tree-based models to prescribe treatment changes. Once we train these tree models, we manually combine the models for every group to create an end-to-end prescription pipeline for all patients in that group. In this process, we prioritize stepping up to a more aggressive treatment before considering less aggressive options. We tested this pipeline on unseen data from BMC, and an external dataset from Hartford healthcare (type 2 diabetes patient visits from January 2020 to May 2024).\nResults: The median HbA1c reduction achieved by our pipelines is 0.26% more than what the doctors achieved on the unseen BMC patients. For the Hartford cohort, our pipelines were better by 0.13%.\nConclusions: This precise, interpretable, and efficient AI-backed approach to treatment progression in type 2 diabetes is predicted to outperform the current practice and can be deployed to improve patient outcomes.", 'abstract_zh': '研究目标：创建基于精确、结构化和数据支持的2型糖尿病治疗进展指南，适合临床应用。', 'title_zh': '基于观察数据的可解释人工智能驱动的2型糖尿病治疗指南'}
{'arxiv_id': 'arXiv:2504.13180', 'title': 'PerceptionLM: Open-Access Data and Models for Detailed Visual Understanding', 'authors': 'Jang Hyun Cho, Andrea Madotto, Effrosyni Mavroudi, Triantafyllos Afouras, Tushar Nagarajan, Muhammad Maaz, Yale Song, Tengyu Ma, Shuming Hu, Suyog Jain, Miguel Martin, Huiyu Wang, Hanoona Rasheed, Peize Sun, Po-Yao Huang, Daniel Bolya, Nikhila Ravi, Shashank Jain, Tammy Stark, Shane Moon, Babak Damavandi, Vivian Lee, Andrew Westbury, Salman Khan, Philipp Krähenbühl, Piotr Dollár, Lorenzo Torresani, Kristen Grauman, Christoph Feichtenhofer', 'link': 'https://arxiv.org/abs/2504.13180', 'abstract': 'Vision-language models are integral to computer vision research, yet many high-performing models remain closed-source, obscuring their data, design and training recipe. The research community has responded by using distillation from black-box models to label training data, achieving strong benchmark results, at the cost of measurable scientific progress. However, without knowing the details of the teacher model and its data sources, scientific progress remains difficult to measure. In this paper, we study building a Perception Language Model (PLM) in a fully open and reproducible framework for transparent research in image and video understanding. We analyze standard training pipelines without distillation from proprietary models and explore large-scale synthetic data to identify critical data gaps, particularly in detailed video understanding. To bridge these gaps, we release 2.8M human-labeled instances of fine-grained video question-answer pairs and spatio-temporally grounded video captions. Additionally, we introduce PLM-VideoBench, a suite for evaluating challenging video understanding tasks focusing on the ability to reason about "what", "where", "when", and "how" of a video. We make our work fully reproducible by providing data, training recipes, code & models.', 'abstract_zh': '视觉语言模型是计算机视觉研究中的重要组成部分，但许多高性能模型仍为封闭源代码，遮蔽了其数据、设计和训练方法。研究社区通过从黑盒模型中提取知识标记训练数据，实现了强有力的基准结果，但牺牲了可量化的科学进步。然而，缺乏了解教师模型及其数据源的细节，科学进步仍难以衡量。在本文中，我们研究了在开放和可重复的框架下构建感知语言模型（PLM），以推动图像和视频理解的透明研究。我们分析了不依赖专有模型的知识提取的标准训练流水线，并探索大规模合成数据以识别关键的数据缺口，特别是针对详细的视频理解。为填补这些缺口，我们发布了280万个人标注的细粒度视频问答实例和时空定位的视频描述。此外，我们引入了PLM-VideoBench，这是一个评估视频理解任务的套件，重点关注对视频中“什么”、“哪里”、“何时”和“如何”的推理能力。我们通过提供数据、训练方法、代码和模型来使我们的工作完全可重复。', 'title_zh': 'PerceptionLM：开放访问的数据和模型 for 详细视觉理解'}
{'arxiv_id': 'arXiv:2504.13173', 'title': "It's All Connected: A Journey Through Test-Time Memorization, Attentional Bias, Retention, and Online Optimization", 'authors': 'Ali Behrouz, Meisam Razaviyayn, Peilin Zhong, Vahab Mirrokni', 'link': 'https://arxiv.org/abs/2504.13173', 'abstract': 'Designing efficient and effective architectural backbones has been in the core of research efforts to enhance the capability of foundation models. Inspired by the human cognitive phenomenon of attentional bias-the natural tendency to prioritize certain events or stimuli-we reconceptualize neural architectures, including Transformers, Titans, and modern linear recurrent neural networks as associative memory modules that learn a mapping of keys and values using an internal objective, referred to as attentional bias. Surprisingly, we observed that most existing sequence models leverage either (1) dot-product similarity, or (2) L2 regression objectives as their attentional bias. Going beyond these objectives, we present a set of alternative attentional bias configurations along with their effective approximations to stabilize their training procedure. We then reinterpret forgetting mechanisms in modern deep learning architectures as a form of retention regularization, providing a novel set of forget gates for sequence models. Building upon these insights, we present Miras, a general framework to design deep learning architectures based on four choices of: (i) associative memory architecture, (ii) attentional bias objective, (iii) retention gate, and (iv) memory learning algorithm. We present three novel sequence models-Moneta, Yaad, and Memora-that go beyond the power of existing linear RNNs while maintaining a fast parallelizable training process. Our experiments show different design choices in Miras yield models with varying strengths. For example, certain instances of Miras achieve exceptional performance in special tasks such as language modeling, commonsense reasoning, and recall intensive tasks, even outperforming Transformers and other modern linear recurrent models.', 'abstract_zh': '设计高效的认知偏置架构背骨一直是提升基础模型能力研究的核心。受人类认知现象中注意偏向的启发，我们重新概念化包括变换器、泰坦和现代线性递归神经网络在内的神经架构，将其视为基于内部目标（即注意偏向）学习键值映射的关联记忆模块。令人惊讶的是，我们发现大多数现有序列模型要么使用点积相似性，要么使用L2回归目标作为其注意偏向。超越这些目标，我们提出了几种替代的注意偏向配置及其有效的逼近方法，以稳定训练过程。接着，我们将现代深度学习架构中的遗忘机制重新解释为保持正则化的一种形式，并为序列模型提供了一组新型的遗忘门控。基于这些洞见，我们提出了Miras，一种基于四种选择设计深度学习架构的一般框架：（i）关联记忆架构，（ii）注意偏置目标，（iii）保持门控，和（iv）记忆学习算法。我们介绍了三种新颖的序列模型——Moneta、Yaad和Memora，这些模型超越了现有线性递归神经网络的能力，同时保持了快速并行训练过程。我们的实验表明，Miras中的不同设计选择会导致具有不同优势的模型。例如，Miras的某些实例在特定任务（如语言建模、常识推理和检索密集任务）上取得了卓越的性能，甚至超过了变换器和其他现代线性递归模型。', 'title_zh': '一切皆相连：从测试时记忆、注意力偏差、保持能力到在线优化的探究之旅'}
{'arxiv_id': 'arXiv:2504.13165', 'title': 'RUKA: Rethinking the Design of Humanoid Hands with Learning', 'authors': 'Anya Zorin, Irmak Guzey, Billy Yan, Aadhithya Iyer, Lisa Kondrich, Nikhil X. Bhattasali, Lerrel Pinto', 'link': 'https://arxiv.org/abs/2504.13165', 'abstract': "Dexterous manipulation is a fundamental capability for robotic systems, yet progress has been limited by hardware trade-offs between precision, compactness, strength, and affordability. Existing control methods impose compromises on hand designs and applications. However, learning-based approaches present opportunities to rethink these trade-offs, particularly to address challenges with tendon-driven actuation and low-cost materials. This work presents RUKA, a tendon-driven humanoid hand that is compact, affordable, and capable. Made from 3D-printed parts and off-the-shelf components, RUKA has 5 fingers with 15 underactuated degrees of freedom enabling diverse human-like grasps. Its tendon-driven actuation allows powerful grasping in a compact, human-sized form factor. To address control challenges, we learn joint-to-actuator and fingertip-to-actuator models from motion-capture data collected by the MANUS glove, leveraging the hand's morphological accuracy. Extensive evaluations demonstrate RUKA's superior reachability, durability, and strength compared to other robotic hands. Teleoperation tasks further showcase RUKA's dexterous movements. The open-source design and assembly instructions of RUKA, code, and data are available at this https URL.", 'abstract_zh': '灵巧操作是机器人系统的一项基本能力，但由于精确度、紧凑性、力量和成本之间的硬件权衡限制了进展。现有的控制方法在手部设计和应用上做出了妥协。然而，基于学习的方法提供了重新思考这些权衡的可能性，尤其是针对肌腱驱动执行和低成本材料的挑战。本研究介绍了RUKA，一种紧凑、经济且功能强大的肌腱驱动人形手。RUKA采用3D打印部件和现成组件制成，具有5个手指和15个未驱动的自由度，能够实现多种类似人类的握持方式。其肌腱驱动的执行允许在紧凑的人类尺寸形式因子中进行强大的抓取。为了解决控制方面的挑战，我们利用MANUS手套采集的运动捕捉数据学习关节到执行器和指尖到执行器的模型，利用手部的形态准确性。广泛评估表明，RUKA在抓取范围、耐用性和强度方面优于其他机器人手。远程操作任务还展示了RUKA的灵巧动作。RUKA的开源设计和组装说明、代码和数据可在此访问：this https URL。', 'title_zh': 'RUKA: 重新思考类人手的设计与学习'}
{'arxiv_id': 'arXiv:2504.13151', 'title': 'MIB: A Mechanistic Interpretability Benchmark', 'authors': 'Aaron Mueller, Atticus Geiger, Sarah Wiegreffe, Dana Arad, Iván Arcuschin, Adam Belfki, Yik Siu Chan, Jaden Fiotto-Kaufman, Tal Haklay, Michael Hanna, Jing Huang, Rohan Gupta, Yaniv Nikankin, Hadas Orgad, Nikhil Prakash, Anja Reusch, Aruna Sankaranarayanan, Shun Shao, Alessandro Stolfo, Martin Tutek, Amir Zur, David Bau, Yonatan Belinkov', 'link': 'https://arxiv.org/abs/2504.13151', 'abstract': 'How can we know whether new mechanistic interpretability methods achieve real improvements? In pursuit of meaningful and lasting evaluation standards, we propose MIB, a benchmark with two tracks spanning four tasks and five models. MIB favors methods that precisely and concisely recover relevant causal pathways or specific causal variables in neural language models. The circuit localization track compares methods that locate the model components - and connections between them - most important for performing a task (e.g., attribution patching or information flow routes). The causal variable localization track compares methods that featurize a hidden vector, e.g., sparse autoencoders (SAEs) or distributed alignment search (DAS), and locate model features for a causal variable relevant to the task. Using MIB, we find that attribution and mask optimization methods perform best on circuit localization. For causal variable localization, we find that the supervised DAS method performs best, while SAE features are not better than neurons, i.e., standard dimensions of hidden vectors. These findings illustrate that MIB enables meaningful comparisons of methods, and increases our confidence that there has been real progress in the field.', 'abstract_zh': '如何知道新的机制可解释性方法是否实现了真正的改进？为了追求有意义且持久的评估标准，我们提出MIB基准，该基准涵盖四个任务和五种模型，分为两条赛道。MIB倾向于那些能够精确且简洁地恢复神经语言模型中相关因果路径或特定因果变量的方法。电路定位赛道比较了在执行特定任务时识别出最重要模型组件及其连接的方法（例如归因补丁或信息流路径）。因果变量定位赛道比较了能够特征化隐藏向量、例如稀疏自编码器（SAEs）或分布式对齐搜索（DAS），并定位与任务相关的因果变量模型特征的方法。使用MIB，我们发现归因和掩码优化方法在电路定位表现最佳。对于因果变量定位，我们发现监督DAS方法表现最佳，而SAE特征并不优于神经元，即隐藏向量的标准维度。这些发现表明，MIB能够进行有意义的方法对比，并增强了我们对领域确实在进步的信心。', 'title_zh': 'MIB: 机制可解释性基准'}
{'arxiv_id': 'arXiv:2504.13143', 'title': '$\\texttt{Complex-Edit}$: CoT-Like Instruction Generation for Complexity-Controllable Image Editing Benchmark', 'authors': 'Siwei Yang, Mude Hui, Bingchen Zhao, Yuyin Zhou, Nataniel Ruiz, Cihang Xie', 'link': 'https://arxiv.org/abs/2504.13143', 'abstract': "We introduce $\\texttt{Complex-Edit}$, a comprehensive benchmark designed to systematically evaluate instruction-based image editing models across instructions of varying complexity. To develop this benchmark, we harness GPT-4o to automatically collect a diverse set of editing instructions at scale. Our approach follows a well-structured ``Chain-of-Edit'' pipeline: we first generate individual atomic editing tasks independently and then integrate them to form cohesive, complex instructions. Additionally, we introduce a suite of metrics to assess various aspects of editing performance, along with a VLM-based auto-evaluation pipeline that supports large-scale assessments. Our benchmark yields several notable insights: 1) Open-source models significantly underperform relative to proprietary, closed-source models, with the performance gap widening as instruction complexity increases; 2) Increased instructional complexity primarily impairs the models' ability to retain key elements from the input images and to preserve the overall aesthetic quality; 3) Decomposing a complex instruction into a sequence of atomic steps, executed in a step-by-step manner, substantially degrades performance across multiple metrics; 4) A straightforward Best-of-N selection strategy improves results for both direct editing and the step-by-step sequential approach; and 5) We observe a ``curse of synthetic data'': when synthetic data is involved in model training, the edited images from such models tend to appear increasingly synthetic as the complexity of the editing instructions rises -- a phenomenon that intriguingly also manifests in the latest GPT-4o outputs.", 'abstract_zh': '我们介绍了一个综合基准$\\texttt{Complex-Edit}$，用于系统地评估基于指令的图像编辑模型在不同复杂度指令下的性能。为了开发这一基准，我们利用GPT-4o自动收集了大量多样化的编辑指令。我们的方法遵循一个精心设计的“编辑链”管道：首先独立生成个体的原子编辑任务，然后将其整合形成连贯且复杂的指令。此外，我们还引入了一套评估编辑性能各个方面的度量标准，并提供了一种基于VLM的自动评估管道，支持大规模评估。基准测试提供了几个重要的见解：1）开源模型相对于闭源的专有模型显著性能较低，随着指令复杂性的增加，性能差距逐渐扩大；2）指令复杂性的增加主要影响模型保持输入图像的关键要素和保留整体视觉质量的能力；3）将复杂的指令分解为一系列原子步骤，逐步执行，会显著在多个度量标准上降低性能；4）简单的Best-of-N选择策略能改善直接编辑和逐步顺序方法的结果；5）我们观察到“合成数据的诅咒”：当合成数据参与模型训练时，随着编辑指令复杂性的增加，从这些模型生成的编辑图像倾向于越来越具合成性——这一现象在最新的GPT-4o输出中也有所体现。', 'title_zh': '$\\texttt{Complex-Edit}$: 基于CoT-like指令生成的复杂度可控图片编辑基准'}
{'arxiv_id': 'arXiv:2504.13139', 'title': 'Syntactic and Semantic Control of Large Language Models via Sequential Monte Carlo', 'authors': "João Loula, Benjamin LeBrun, Li Du, Ben Lipkin, Clemente Pasti, Gabriel Grand, Tianyu Liu, Yahya Emara, Marjorie Freedman, Jason Eisner, Ryan Cotterel, Vikash Mansinghka, Alexander K. Lew, Tim Vieira, Timothy J. O'Donnell", 'link': 'https://arxiv.org/abs/2504.13139', 'abstract': "A wide range of LM applications require generating text that conforms to syntactic or semantic constraints. Imposing such constraints can be naturally framed as probabilistic conditioning, but exact generation from the resulting distribution -- which can differ substantially from the LM's base distribution -- is generally intractable. In this work, we develop an architecture for controlled LM generation based on sequential Monte Carlo (SMC). Our SMC framework allows us to flexibly incorporate domain- and problem-specific constraints at inference time, and efficiently reallocate computational resources in light of new information during the course of generation. By comparing to a number of alternatives and ablations on four challenging domains -- Python code generation for data science, text-to-SQL, goal inference, and molecule synthesis -- we demonstrate that, with little overhead, our approach allows small open-source language models to outperform models over 8x larger, as well as closed-source, fine-tuned ones. In support of the probabilistic perspective, we show that these performance improvements are driven by better approximation to the posterior distribution. Our system builds on the framework of Lew et al. (2023) and integrates with its language model probabilistic programming language, giving users a simple, programmable way to apply SMC to a broad variety of controlled generation problems.", 'abstract_zh': '一种基于顺序蒙特卡洛的方法实现受控语言模型生成', 'title_zh': '大型语言模型的语法和语义控制通过序列蒙特卡洛方法'}
{'arxiv_id': 'arXiv:2504.13131', 'title': 'NTIRE 2025 Challenge on Short-form UGC Video Quality Assessment and Enhancement: Methods and Results', 'authors': 'Xin Li, Kun Yuan, Bingchen Li, Fengbin Guan, Yizhen Shao, Zihao Yu, Xijun Wang, Yiting Lu, Wei Luo, Suhang Yao, Ming Sun, Chao Zhou, Zhibo Chen, Radu Timofte, Yabin Zhang, Ao-Xiang Zhang, Tianwu Zhi, Jianzhao Liu, Yang Li, Jingwen Xu, Yiting Liao, Yushen Zuo, Mingyang Wu, Renjie Li, Shengyun Zhong, Zhengzhong Tu, Yufan Liu, Xiangguang Chen, Zuowei Cao, Minhao Tang, Shan Liu, Kexin Zhang, Jingfen Xie, Yan Wang, Kai Chen, Shijie Zhao, Yunchen Zhang, Xiangkai Xu, Hong Gao, Ji Shi, Yiming Bao, Xiugang Dong, Xiangsheng Zhou, Yaofeng Tu, Ying Liang, Yiwen Wang, Xinning Chai, Yuxuan Zhang, Zhengxue Cheng, Yingsheng Qin, Yucai Yang, Rong Xie, Li Song, Wei Sun, Kang Fu, Linhan Cao, Dandan Zhu, Kaiwei Zhang, Yucheng Zhu, Zicheng Zhang, Menghan Hu, Xiongkuo Min, Guangtao Zhai, Zhi Jin, Jiawei Wu, Wei Wang, Wenjian Zhang, Yuhai Lan, Gaoxiong Yi, Hengyuan Na, Wang Luo, Di Wu, MingYin Bai, Jiawang Du, Zilong Lu, Zhenyu Jiang, Hui Zeng, Ziguan Cui, Zongliang Gan, Guijin Tang, Xinglin Xie, Kehuan Song, Xiaoqiang Lu, Licheng Jiao, Fang Liu, Xu Liu, Puhua Chen, Ha Thu Nguyen, Katrien De Moor, Seyed Ali Amirshahi, Mohamed-Chaker Larabi, Qi Tang, Linfeng He, Zhiyong Gao, Zixuan Gao, Guohua Zhang, Zhiye Huang, Yi Deng, Qingmiao Jiang, Lu Chen', 'link': 'https://arxiv.org/abs/2504.13131', 'abstract': 'This paper presents a review for the NTIRE 2025 Challenge on Short-form UGC Video Quality Assessment and Enhancement. The challenge comprises two tracks: (i) Efficient Video Quality Assessment (KVQ), and (ii) Diffusion-based Image Super-Resolution (KwaiSR). Track 1 aims to advance the development of lightweight and efficient video quality assessment (VQA) models, with an emphasis on eliminating reliance on model ensembles, redundant weights, and other computationally expensive components in the previous IQA/VQA competitions. Track 2 introduces a new short-form UGC dataset tailored for single image super-resolution, i.e., the KwaiSR dataset. It consists of 1,800 synthetically generated S-UGC image pairs and 1,900 real-world S-UGC images, which are split into training, validation, and test sets using a ratio of 8:1:1. The primary objective of the challenge is to drive research that benefits the user experience of short-form UGC platforms such as Kwai and TikTok. This challenge attracted 266 participants and received 18 valid final submissions with corresponding fact sheets, significantly contributing to the progress of short-form UGC VQA and image superresolution. The project is publicly available at this https URL ChallengeCVPR-NTIRE2025.', 'abstract_zh': 'NTIRE 2025 挑战赛：短形式UGC视频质量评估与增强综述', 'title_zh': 'NTIRE 2025挑战赛：短形式UGC视频质量评估与增强的方法与结果'}
{'arxiv_id': 'arXiv:2504.13129', 'title': 'Science-T2I: Addressing Scientific Illusions in Image Synthesis', 'authors': 'Jialuo Li, Wenhao Chai, Xingyu Fu, Haiyang Xu, Saining Xie', 'link': 'https://arxiv.org/abs/2504.13129', 'abstract': 'We present a novel approach to integrating scientific knowledge into generative models, enhancing their realism and consistency in image synthesis. First, we introduce Science-T2I, an expert-annotated adversarial dataset comprising adversarial 20k image pairs with 9k prompts, covering wide distinct scientific knowledge categories. Leveraging Science-T2I, we present SciScore, an end-to-end reward model that refines the assessment of generated images based on scientific knowledge, which is achieved by augmenting both the scientific comprehension and visual capabilities of pre-trained CLIP model. Additionally, based on SciScore, we propose a two-stage training framework, comprising a supervised fine-tuning phase and a masked online fine-tuning phase, to incorporate scientific knowledge into existing generative models. Through comprehensive experiments, we demonstrate the effectiveness of our framework in establishing new standards for evaluating the scientific realism of generated content. Specifically, SciScore attains performance comparable to human-level, demonstrating a 5% improvement similar to evaluations conducted by experienced human evaluators. Furthermore, by applying our proposed fine-tuning method to FLUX, we achieve a performance enhancement exceeding 50% on SciScore.', 'abstract_zh': '我们将一种将科学知识整合到生成模型中的新颖方法应用于图像合成，增强了生成图像的真实性和一致性。首先，我们介绍了Science-T2I，一个由专家注释的对抗性数据集，包含20,000个图像对和9,000个提示，涵盖广泛的科学知识类别。借助Science-T2I，我们提出了SciScore，这是一种端到端的奖励模型，基于科学知识精炼生成图像的评估，通过增强预训练CLIP模型的科学理解和视觉能力实现。此外，基于SciScore，我们提出了一个两阶段训练框架，包括监督微调阶段和掩码在线微调阶段，以将科学知识整合到现有的生成模型中。通过全面的实验，我们展示了该框架在评估生成内容的科学真实性方面建立新标准的有效性。具体而言，SciScore的表现达到与人类相当的水平，显示出与经验丰富的评估者进行评价类似的5%的改善。此外，通过对FLUX进行我们提出的微调方法的应用，在SciScore上的性能提升超过50%。', 'title_zh': '科学-图像合成：解决图像合成中的科学错觉'}
{'arxiv_id': 'arXiv:2504.13128', 'title': 'FreshStack: Building Realistic Benchmarks for Evaluating Retrieval on Technical Documents', 'authors': 'Nandan Thakur, Jimmy Lin, Sam Havens, Michael Carbin, Omar Khattab, Andrew Drozdov', 'link': 'https://arxiv.org/abs/2504.13128', 'abstract': 'We introduce FreshStack, a reusable framework for automatically building information retrieval (IR) evaluation benchmarks from community-asked questions and answers. FreshStack conducts the following steps: (1) automatic corpus collection from code and technical documentation, (2) nugget generation from community-asked questions and answers, and (3) nugget-level support, retrieving documents using a fusion of retrieval techniques and hybrid architectures. We use FreshStack to build five datasets on fast-growing, recent, and niche topics to ensure the tasks are sufficiently challenging. On FreshStack, existing retrieval models, when applied out-of-the-box, significantly underperform oracle approaches on all five topics, denoting plenty of headroom to improve IR quality. In addition, we identify cases where rerankers do not clearly improve first-stage retrieval accuracy (two out of five topics). We hope that FreshStack will facilitate future work toward constructing realistic, scalable, and uncontaminated IR and RAG evaluation benchmarks. FreshStack datasets are available at: this https URL.', 'abstract_zh': '我们引入了FreshStack，一个可重复使用的框架，用于从社区提出的问答自动构建信息检索（IR）评价基准。FreshStack包括以下步骤：(1) 从代码和技术文档自动收集语料库，(2) 从社区提出的问答生成关键信息片段，以及(3) 在融合检索技术和混合架构的基础上在关键信息片段层面进行文档检索。我们使用FreshStack构建了五个针对快速增长、近期和专门领域的话题数据集，以确保任务具有足够的挑战性。在FreshStack上，现有的检索模型在所有五个话题上与奥卡姆方法相比显著表现不佳，表明提升信息检索质量的空间很大。此外，我们发现有两个话题中无需重新排序器就能显着提高初步检索准确性。我们希望FreshStack能够促进未来构建现实的、可扩展的和未受污染的IR和RAG评价基准的工作。FreshStack数据集可在以下网址获取：this https URL。', 'title_zh': 'FreshStack: 构建评估技术文档检索的现实基准'}
{'arxiv_id': 'arXiv:2504.13125', 'title': 'LLMs Meet Finance: Fine-Tuning Foundation Models for the Open FinLLM Leaderboard', 'authors': 'Varun Rao, Youran Sun, Mahendra Kumar, Tejas Mutneja, Agastya Mukherjee, Haizhao Yang', 'link': 'https://arxiv.org/abs/2504.13125', 'abstract': 'This paper investigates the application of large language models (LLMs) to financial tasks. We fine-tuned foundation models using the Open FinLLM Leaderboard as a benchmark. Building on Qwen2.5 and Deepseek-R1, we employed techniques including supervised fine-tuning (SFT), direct preference optimization (DPO), and reinforcement learning (RL) to enhance their financial capabilities. The fine-tuned models demonstrated substantial performance gains across a wide range of financial tasks. Moreover, we measured the data scaling law in the financial domain. Our work demonstrates the potential of large language models (LLMs) in financial applications.', 'abstract_zh': '本文探讨了大型语言模型（LLMs）在金融任务中的应用。我们以Open FinLLM Leaderboard为基准，对基础模型进行了微调。在Qwen2.5和Deepseek-R1的基础上，我们采用了监督微调（SFT）、直接偏好优化（DPO）和强化学习（RL）等技术来增强其金融能力。微调后的模型在一系列金融任务中表现出显著的性能提升。此外，我们还在金融领域测量了数据的规模律。我们的工作展示了大型语言模型（LLMs）在金融应用中的潜力。', 'title_zh': 'LLMs遇金融：为开放FinLLM榜单微调基础模型'}
{'arxiv_id': 'arXiv:2504.13123', 'title': 'Low-hallucination Synthetic Captions for Large-Scale Vision-Language Model Pre-training', 'authors': 'Xinsong Zhang, Yarong Zeng, Xinting Huang, Hu Hu, Runquan Xie, Han Hu, Zhanhui Kang', 'link': 'https://arxiv.org/abs/2504.13123', 'abstract': 'In recent years, the field of vision-language model pre-training has experienced rapid advancements, driven primarily by the continuous enhancement of textual capabilities in large language models. However, existing training paradigms for multimodal large language models heavily rely on high-quality image-text pairs. As models and data scales grow exponentially, the availability of such meticulously curated data has become increasingly scarce and saturated, thereby severely limiting further advancements in this domain. This study investigates scalable caption generation techniques for vision-language model pre-training and demonstrates that large-scale low-hallucination synthetic captions can serve dual purposes: 1) acting as a viable alternative to real-world data for pre-training paradigms and 2) achieving superior performance enhancement when integrated into vision-language models through empirical validation. This paper presents three key contributions: 1) a novel pipeline for generating high-quality, low-hallucination, and knowledge-rich synthetic captions. Our continuous DPO methodology yields remarkable results in reducing hallucinations. Specifically, the non-hallucination caption rate on a held-out test set increases from 48.2% to 77.9% for a 7B-size model. 2) Comprehensive empirical validation reveals that our synthetic captions confer superior pre-training advantages over their counterparts. Across 35 vision language tasks, the model trained with our data achieves a significant performance gain of at least 6.2% compared to alt-text pairs and other previous work. Meanwhile, it also offers considerable support in the text-to-image domain. With our dataset, the FID score is reduced by 17.1 on a real-world validation benchmark and 13.3 on the MSCOCO validation benchmark. 3) We will release Hunyuan-Recap100M, a low-hallucination and knowledge-intensive synthetic caption dataset.', 'abstract_zh': '近年来，视觉-语言模型预训练领域经历了快速的进步，这主要得益于大规模语言模型文本能力的持续增强。然而，现有的大规模多模态语言模型的训练范式高度依赖高质量的图像-文本配对。随着模型和数据规模的指数级增长，此类精心整理的数据变得越发稀缺和饱和，从而严重限制了该领域的进一步发展。本研究调查了适用于视觉-语言模型预训练的可扩展的标题生成技术，并证明了大规模低幻觉合成标题的双重用途：1）作为现实数据的可行替代品用于预训练范式；2）通过经验验证，在视觉-语言模型中集成时能实现更好的性能提升。本文提出三大贡献：1）一种生成高质量、低幻觉和知识丰富的合成标题的新型管道。我们连续DPO方法在减少幻觉方面取得了显著成果，特别是在7B规模的模型中，非幻觉标题率从48.2%提高到77.9%。2）全面的经验验证表明，我们生成的合成标题相较于其他同类数据提供了更优越的预训练优势。在35个视觉语言任务中，使用我们数据集训练的模型相较于alt-text配对和其他以往工作，实现了至少6.2%的显著性能提升，同时也在文本到图像领域提供了大力支持。使用我们数据集，在真实验证基准上的FID分数降低了17.1分，在MS COCO验证基准上降低了13.3分。3）我们将发布低幻觉和知识密集型合成标题数据集Hunyuan-Recap100M。', 'title_zh': '大规模视觉-语言模型预训练的低幻觉合成描述词'}
{'arxiv_id': 'arXiv:2504.13120', 'title': 'Probing and Inducing Combinational Creativity in Vision-Language Models', 'authors': 'Yongqian Peng, Yuxi Ma, Mengmeng Wang, Yuxuan Wang, Yizhou Wang, Chi Zhang, Yixin Zhu, Zilong Zheng', 'link': 'https://arxiv.org/abs/2504.13120', 'abstract': 'The ability to combine existing concepts into novel ideas stands as a fundamental hallmark of human intelligence. Recent advances in Vision-Language Models (VLMs) like GPT-4V and DALLE-3 have sparked debate about whether their outputs reflect combinational creativity--defined by M. A. Boden (1998) as synthesizing novel ideas through combining existing concepts--or sophisticated pattern matching of training data. Drawing inspiration from cognitive science, we investigate the combinational creativity of VLMs from the lens of concept blending. We propose the Identification-Explanation-Implication (IEI) framework, which decomposes creative processes into three levels: identifying input spaces, extracting shared attributes, and deriving novel semantic implications. To validate this framework, we curate CreativeMashup, a high-quality dataset of 666 artist-generated visual mashups annotated according to the IEI framework. Through extensive experiments, we demonstrate that in comprehension tasks, best VLMs have surpassed average human performance while falling short of expert-level understanding; in generation tasks, incorporating our IEI framework into the generation pipeline significantly enhances the creative quality of VLMs outputs. Our findings establish both a theoretical foundation for evaluating artificial creativity and practical guidelines for improving creative generation in VLMs.', 'abstract_zh': '具备将现有概念组合成新颖想法的能力是人类智能的基本特征。最近，在视觉-语言模型（VLMs）领域如GPT-4V和DALLE-3的进展引发了对其输出是否反映了组合创造力的辩论——组合创造力被M. A. Boden（1998）定义为通过组合现有概念来合成新颖想法——或仅仅是训练数据中的复杂模式匹配。借鉴认知科学的视角，我们从概念融合的视角探讨了VLMs的组合创造力。我们提出了识别-解释-隐含（IEI）框架，将创造过程分解为三个层面：识别输入空间、提取共享属性以及推导新颖的语义隐含。为了验证这一框架，我们编纂了CreativeMashup数据集，包含666个由艺术家生成的视觉混搭作品，并按照IEI框架进行了注释。通过大量实验，我们证明，在理解任务中，最佳VLMs已经超过了平均水平的人类表现，但在专家级理解方面仍未达到专家水平；在生成任务中，将我们的IEI框架整合到生成流水线中显著提高了VLMs输出的创造性质量。我们的研究结果不仅为评估人工创造力奠定了理论基础，也为提高VLMs的创造性生成提供了实用指南。', 'title_zh': '探究和诱导视觉语言模型的组合创造力'}
{'arxiv_id': 'arXiv:2504.13102', 'title': 'A Multi-task Learning Balanced Attention Convolutional Neural Network Model for Few-shot Underwater Acoustic Target Recognition', 'authors': 'Wei Huang, Shumeng Sun, Junpeng Lu, Zhenpeng Xu, Zhengyang Xiu, Hao Zhang', 'link': 'https://arxiv.org/abs/2504.13102', 'abstract': 'Underwater acoustic target recognition (UATR) is of great significance for the protection of marine diversity and national defense security. The development of deep learning provides new opportunities for UATR, but faces challenges brought by the scarcity of reference samples and complex environmental interference. To address these issues, we proposes a multi-task balanced channel attention convolutional neural network (MT-BCA-CNN). The method integrates a channel attention mechanism with a multi-task learning strategy, constructing a shared feature extractor and multi-task classifiers to jointly optimize target classification and feature reconstruction tasks. The channel attention mechanism dynamically enhances discriminative acoustic features such as harmonic structures while suppressing noise. Experiments on the Watkins Marine Life Dataset demonstrate that MT-BCA-CNN achieves 97\\% classification accuracy and 95\\% $F1$-score in 27-class few-shot scenarios, significantly outperforming traditional CNN and ACNN models, as well as popular state-of-the-art UATR methods. Ablation studies confirm the synergistic benefits of multi-task learning and attention mechanisms, while a dynamic weighting adjustment strategy effectively balances task contributions. This work provides an efficient solution for few-shot underwater acoustic recognition, advancing research in marine bioacoustics and sonar signal processing.', 'abstract_zh': '水下声学目标识别（UATR）在保护海洋生物多样性和国家安全方面具有重要意义。深度学习的发展为UATR提供了新机遇，但也面临着参考样本稀缺和复杂环境干扰的挑战。为了应对这些问题，我们提出了一种多任务平衡通道注意卷积神经网络（MT-BCA-CNN）。该方法结合了通道注意机制和多任务学习策略，构建了共享特征提取器和多任务分类器，同时优化目标分类和特征重构任务。通道注意机制动态增强具有辨别力的声学特征，如谐波结构，并抑制噪声。实验表明，MT-BCA-CNN在Watkins海洋生物数据集的27类少样本场景中实现了97%的分类准确率和95%的$F1$分数，明显优于传统CNN和ACNN模型以及现有的UATR方法。消融研究证实了多任务学习和注意力机制的协同效益，而动态权重调整策略有效平衡了任务贡献。这项工作为水下声学少样本识别提供了高效解决方案，促进了海洋生物声学和声纳信号处理的研究。', 'title_zh': '多任务学习平衡注意力卷积神经网络模型在少量样本水下声目标识别中应用'}
{'arxiv_id': 'arXiv:2504.13101', 'title': 'An Empirically Grounded Identifiability Theory Will Accelerate Self-Supervised Learning Research', 'authors': 'Patrik Reizinger, Randall Balestriero, David Klindt, Wieland Brendel', 'link': 'https://arxiv.org/abs/2504.13101', 'abstract': "Self-Supervised Learning (SSL) powers many current AI systems. As research interest and investment grow, the SSL design space continues to expand. The Platonic view of SSL, following the Platonic Representation Hypothesis (PRH), suggests that despite different methods and engineering approaches, all representations converge to the same Platonic ideal. However, this phenomenon lacks precise theoretical explanation. By synthesizing evidence from Identifiability Theory (IT), we show that the PRH can emerge in SSL. However, current IT cannot explain SSL's empirical success. To bridge the gap between theory and practice, we propose expanding IT into what we term Singular Identifiability Theory (SITh), a broader theoretical framework encompassing the entire SSL pipeline. SITh would allow deeper insights into the implicit data assumptions in SSL and advance the field towards learning more interpretable and generalizable representations. We highlight three critical directions for future research: 1) training dynamics and convergence properties of SSL; 2) the impact of finite samples, batch size, and data diversity; and 3) the role of inductive biases in architecture, augmentations, initialization schemes, and optimizers.", 'abstract_zh': '自主学习（SSL）驱动了许多当前的AI系统。随着研究兴趣和投资的增加，SSL的设计空间继续扩展。柏拉图视角下的SSL，遵循柏拉图表示假设（PRH），表明尽管有不同的方法和工程手段，所有表示最终会趋向于同一个柏拉图理想。然而，这一现象缺乏精确的理论解释。通过综合可识别性理论（IT）的证据，我们表明PRH可以在SSL中出现。然而，当前的IT无法解释SSL的经验成功。为了弥合理论与实践之间的差距，我们建议将IT扩展为我们称之为单一可识别性理论（SITh）的更广泛的理论框架，涵盖整个SSL管道。SITh将有助于更深入地了解SSL中的隐含数据假设，并推动该领域朝着学习更具可解释性和泛化能力的表示前进。我们指出了未来研究的三个关键方向：1）SSL的训练动力学和收敛性质；2）有限样本、批次大小和数据多样性的影响；3）架构、增强、初始化方案和优化器中的归纳偏见的作用。', 'title_zh': '基于经验的可辨识性理论将加速自我监督学习研究'}
{'arxiv_id': 'arXiv:2504.13079', 'title': 'Retrieval-Augmented Generation with Conflicting Evidence', 'authors': 'Han Wang, Archiki Prasad, Elias Stengel-Eskin, Mohit Bansal', 'link': 'https://arxiv.org/abs/2504.13079', 'abstract': 'Large language model (LLM) agents are increasingly employing retrieval-augmented generation (RAG) to improve the factuality of their responses. However, in practice, these systems often need to handle ambiguous user queries and potentially conflicting information from multiple sources while also suppressing inaccurate information from noisy or irrelevant documents. Prior work has generally studied and addressed these challenges in isolation, considering only one aspect at a time, such as handling ambiguity or robustness to noise and misinformation. We instead consider multiple factors simultaneously, proposing (i) RAMDocs (Retrieval with Ambiguity and Misinformation in Documents), a new dataset that simulates complex and realistic scenarios for conflicting evidence for a user query, including ambiguity, misinformation, and noise; and (ii) MADAM-RAG, a multi-agent approach in which LLM agents debate over the merits of an answer over multiple rounds, allowing an aggregator to collate responses corresponding to disambiguated entities while discarding misinformation and noise, thereby handling diverse sources of conflict jointly. We demonstrate the effectiveness of MADAM-RAG using both closed and open-source models on AmbigDocs -- which requires presenting all valid answers for ambiguous queries -- improving over strong RAG baselines by up to 11.40% and on FaithEval -- which requires suppressing misinformation -- where we improve by up to 15.80% (absolute) with Llama3.3-70B-Instruct. Furthermore, we find that RAMDocs poses a challenge for existing RAG baselines (Llama3.3-70B-Instruct only obtains 32.60 exact match score). While MADAM-RAG begins to address these conflicting factors, our analysis indicates that a substantial gap remains especially when increasing the level of imbalance in supporting evidence and misinformation.', 'abstract_zh': '大型语言模型代理越来越多地采用检索增强生成（RAG）来提高其响应的事实准确性。然而，在实践中，这些系统往往需要处理含糊不清的用户查询和多来源的潜在矛盾信息，同时抑制来自嘈杂或无关文档的不准确信息。前人工作通常在单一方面研究和解决这些挑战，例如仅处理模糊性或抗噪性问题。我们则同时考虑多个因素，提出(i) RAMDocs（包含文档中的模糊性与误导信息的检索），一个新数据集，模拟用户查询的复杂和现实场景中的矛盾证据，包括模糊性、误导信息和噪音；以及(ii) MADAM-RAG，一种多代理方法，在多轮中代理争论答案的优劣，使聚合器能够整理经过去模糊化实体对应的回答，同时丢弃误导信息和噪音，从而联合处理多重冲突来源。我们使用闭源和开源模型在AmbigDocs上证明了MADAM-RAG的有效性——这需要呈现含糊查询的所有有效答案，相比强大的RAG基线提升最高11.4%；在FaithEval上也有所提升——这要求抑制误导信息，使用Llama3.3-70B-Instruct我们提升至最高15.8%（绝对值）。此外，我们发现RAMDocs对现有RAG基线构成了挑战（Llama3.3-70B-Instruct仅获得32.60分的精确匹配分数）。虽然MADAM-RAG开始解决这些冲突因素，但我们的分析表明，在支持证据和误导信息的不平衡程度提高时，仍存在显著差距。', 'title_zh': '具有矛盾证据的检索增强生成'}
{'arxiv_id': 'arXiv:2504.13078', 'title': 'Enhancing Person-to-Person Virtual Try-On with Multi-Garment Virtual Try-Off', 'authors': 'Riza Velioglu, Petra Bevandic, Robin Chan, Barbara Hammer', 'link': 'https://arxiv.org/abs/2504.13078', 'abstract': 'Computer vision is transforming fashion through Virtual Try-On (VTON) and Virtual Try-Off (VTOFF). VTON generates images of a person in a specified garment using a target photo and a standardized garment image, while a more challenging variant, Person-to-Person Virtual Try-On (p2p-VTON), uses a photo of another person wearing the garment. VTOFF, on the other hand, extracts standardized garment images from clothed individuals. We introduce TryOffDiff, a diffusion-based VTOFF model. Built on a latent diffusion framework with SigLIP image conditioning, it effectively captures garment properties like texture, shape, and patterns. TryOffDiff achieves state-of-the-art results on VITON-HD and strong performance on DressCode dataset, covering upper-body, lower-body, and dresses. Enhanced with class-specific embeddings, it pioneers multi-garment VTOFF, the first of its kind. When paired with VTON models, it improves p2p-VTON by minimizing unwanted attribute transfer, such as skin color. Code is available at: this https URL', 'abstract_zh': '计算机视觉正在通过虚拟试穿（VTON）和虚拟脱下（VTOFF）改造时尚。VTON利用目标照片和标准服装图像生成一名人在指定服装中的图像，而更具挑战性的变体Person-to-Person Virtual Try-On（p2p-VTON）使用另一人在穿该服装的照片。VTOFF从穿着者身上提取标准服装图像。我们提出了TryOffDiff，这是一种基于扩散机制的VTOFF模型，通过潜空间扩散框架和SigLIP图像条件化，有效地捕捉服装的纹理、形状和图案特征。TryOffDiff在VITON-HD上取得了最先进的性能，并在涵盖上身、下身和连衣裙的DressCode数据集上表现出强大的性能。通过类别特定嵌入的增强，TryOffDiff开创了多件服装VTOFF，这是该领域的首个模型。当与VTON模型结合使用时，它可以减少不必要的属性转移，例如肤色。更多信息请参阅：this https URL。', 'title_zh': '基于多 garments 虚拟试脱的 Personen-to-Person 虚拟试穿增强'}
{'arxiv_id': 'arXiv:2504.13068', 'title': 'Accuracy is Not Agreement: Expert-Aligned Evaluation of Crash Narrative Classification Models', 'authors': 'Sudesh Ramesh Bhagat, Ibne Farabi Shihab, Anuj Sharma', 'link': 'https://arxiv.org/abs/2504.13068', 'abstract': "This study explores the relationship between deep learning (DL) model accuracy and expert agreement in the classification of crash narratives. We evaluate five DL models -- including BERT variants, the Universal Sentence Encoder (USE), and a zero-shot classifier -- against expert-labeled data and narrative text. The analysis is further extended to four large language models (LLMs): GPT-4, LLaMA 3, Qwen, and Claude. Our results reveal a counterintuitive trend: models with higher technical accuracy often exhibit lower agreement with domain experts, whereas LLMs demonstrate greater expert alignment despite relatively lower accuracy scores. To quantify and interpret model-expert agreement, we employ Cohen's Kappa, Principal Component Analysis (PCA), and SHAP-based explainability techniques. Findings indicate that expert-aligned models tend to rely more on contextual and temporal language cues, rather than location-specific keywords. These results underscore that accuracy alone is insufficient for evaluating models in safety-critical NLP applications. We advocate for incorporating expert agreement as a complementary metric in model evaluation frameworks and highlight the promise of LLMs as interpretable, scalable tools for crash analysis pipelines.", 'abstract_zh': '本研究探讨了深度学习（DL）模型准确性和专家在车祸叙述分类中共识之间的关系。我们评估了包括BERT变体、通用句子编码器（USE）和零 shot 分类器在内的五种DL模型与专家标注数据和叙述文本的对比。进一步将分析扩展到四种大型语言模型（LLMs）：GPT-4、LLaMA 3、Qwen 和 Claude。研究结果揭示了一个反直觉的趋势：技术准确性更高的模型往往与领域专家的共识较低，而LLMs表现出更高的专家一致性，尽管其准确性相对较低。为了量化和解释模型与专家的一致性，我们采用了科恩κ系数、主成分分析（PCA）和基于SHAP的可解释性技术。研究结果表明，专家一致性的模型更倾向于依赖于上下文和时间语言线索，而不是特定位置的关键词。这些结果表明，在安全关键的自然语言处理（NLP）应用中，单独的准确性是不够的。我们提倡在模型评估框架中纳入专家共识作为补充指标，并强调LLMs作为可解释和可扩展的工具在事故分析管道中的潜力。', 'title_zh': '准确性并不等同于一致性：专家对碰撞叙述分类模型的评价'}
{'arxiv_id': 'arXiv:2504.13059', 'title': 'RoboTwin: Dual-Arm Robot Benchmark with Generative Digital Twins', 'authors': 'Yao Mu, Tianxing Chen, Zanxin Chen, Shijia Peng, Zhiqian Lan, Zeyu Gao, Zhixuan Liang, Qiaojun Yu, Yude Zou, Mingkun Xu, Lunkai Lin, Zhiqiang Xie, Mingyu Ding, Ping Luo', 'link': 'https://arxiv.org/abs/2504.13059', 'abstract': 'In the rapidly advancing field of robotics, dual-arm coordination and complex object manipulation are essential capabilities for developing advanced autonomous systems. However, the scarcity of diverse, high-quality demonstration data and real-world-aligned evaluation benchmarks severely limits such development. To address this, we introduce RoboTwin, a generative digital twin framework that uses 3D generative foundation models and large language models to produce diverse expert datasets and provide a real-world-aligned evaluation platform for dual-arm robotic tasks. Specifically, RoboTwin creates varied digital twins of objects from single 2D images, generating realistic and interactive scenarios. It also introduces a spatial relation-aware code generation framework that combines object annotations with large language models to break down tasks, determine spatial constraints, and generate precise robotic movement code. Our framework offers a comprehensive benchmark with both simulated and real-world data, enabling standardized evaluation and better alignment between simulated training and real-world performance. We validated our approach using the open-source COBOT Magic Robot platform. Policies pre-trained on RoboTwin-generated data and fine-tuned with limited real-world samples demonstrate significant potential for enhancing dual-arm robotic manipulation systems by improving success rates by over 70% for single-arm tasks and over 40% for dual-arm tasks compared to models trained solely on real-world data.', 'abstract_zh': '机器人领域中，双臂协调与复杂物体操控是发展高级自主系统的关键能力。然而，多样化的高质量示范数据和与现实世界对齐的评估基准的缺乏严重限制了这一发展。为了解决这一问题，我们引入了RoboTwin，这是一种使用3D生成基础模型和大规模语言模型生成多样化专家数据集，并提供双臂机器人任务现实世界对齐评估平台的生成数字孪生框架。具体而言，RoboTwin 从单张2D图像生成物体的多样化数字孪生，生成真实且互动的场景。它还引入了一种空间关系感知的代码生成框架，结合对象标注和大规模语言模型来分解任务、确定空间约束并生成精确的机器人运动代码。我们的框架提供了包含模拟和现实世界数据的综合基准，使得标准化评估和模拟训练与现实世界性能更好的对齐成为可能。我们使用开源的COBOT Magic Robot平台验证了这种方法。基于RoboTwin生成数据预训练并在有限的现实世界样本上微调的策略，在单臂任务上成功率提高了70%以上，在双臂任务上提高了40%以上，相较于仅使用现实世界数据训练的模型具有显著潜力。', 'title_zh': 'RoboTwin: 双臂机器人基准测试与生成式数字孪生'}
{'arxiv_id': 'arXiv:2504.13054', 'title': 'Aspect-Based Summarization with Self-Aspect Retrieval Enhanced Generation', 'authors': 'Yichao Feng, Shuai Zhao, Yueqiu Li, Luwei Xiao, Xiaobao Wu, Anh Tuan Luu', 'link': 'https://arxiv.org/abs/2504.13054', 'abstract': 'Aspect-based summarization aims to generate summaries tailored to specific aspects, addressing the resource constraints and limited generalizability of traditional summarization approaches. Recently, large language models have shown promise in this task without the need for training. However, they rely excessively on prompt engineering and face token limits and hallucination challenges, especially with in-context learning. To address these challenges, in this paper, we propose a novel framework for aspect-based summarization: Self-Aspect Retrieval Enhanced Summary Generation. Rather than relying solely on in-context learning, given an aspect, we employ an embedding-driven retrieval mechanism to identify its relevant text segments. This approach extracts the pertinent content while avoiding unnecessary details, thereby mitigating the challenge of token limits. Moreover, our framework optimizes token usage by deleting unrelated parts of the text and ensuring that the model generates output strictly based on the given aspect. With extensive experiments on benchmark datasets, we demonstrate that our framework not only achieves superior performance but also effectively mitigates the token limitation problem.', 'abstract_zh': '基于方面摘要生成旨在生成针对特定方面定制的摘要，以解决传统摘要方法在资源约束和泛化能力上的局限性。近期，大规模语言模型在该任务上显示出潜力，无需进行专门训练即可完成。然而，它们过度依赖于提示工程技术，并面临标记限制和幻觉挑战，尤其是在上下文学习的情况下。为应对这些挑战，本文提出了一种新的基于方面摘要生成框架：Self-Aspect Retrieval Enhanced Summary Generation。该框架不仅依赖于上下文学习，还采用嵌入驱动的检索机制，根据给定的方面识别其相关文本片段。这种方法提取关键内容的同时避免冗余细节，从而缓解了标记限制挑战。此外，该框架通过删除与给定方面无关的部分来优化标记使用，并确保模型严格基于给定方面生成输出。通过在基准数据集上进行广泛实验，我们证明了该框架不仅能够实现更好的性能，还能有效地缓解标记限制问题。', 'title_zh': '基于自方面检索增强生成的方面级摘要生成'}
{'arxiv_id': 'arXiv:2504.13048', 'title': 'Design Topological Materials by Reinforcement Fine-Tuned Generative Model', 'authors': 'Haosheng Xu, Dongheng Qian, Zhixuan Liu, Yadong Jiang, Jing Wang', 'link': 'https://arxiv.org/abs/2504.13048', 'abstract': "Topological insulators (TIs) and topological crystalline insulators (TCIs) are materials with unconventional electronic properties, making their discovery highly valuable for practical applications. However, such materials, particularly those with a full band gap, remain scarce. Given the limitations of traditional approaches that scan known materials for candidates, we focus on the generation of new topological materials through a generative model. Specifically, we apply reinforcement fine-tuning (ReFT) to a pre-trained generative model, thereby aligning the model's objectives with our material design goals. We demonstrate that ReFT is effective in enhancing the model's ability to generate TIs and TCIs, with minimal compromise on the stability of the generated materials. Using the fine-tuned model, we successfully identify a large number of new topological materials, with Ge$_2$Bi$_2$O$_6$ serving as a representative example--a TI with a full band gap of 0.26 eV, ranking among the largest known in this category.", 'abstract_zh': '拓扑绝缘体（TIs）和拓扑晶体绝缘体（TCIs）是具有非常规电子性质的材料，其发现对于实际应用具有高度的价值。然而，尤其是全带隙的这类材料仍然相对稀缺。鉴于传统方法在已知材料中寻找候选材料的局限性，我们着眼于通过生成模型来生成新的拓扑材料。具体地，我们应用强化微调（ReFT）到预训练的生成模型中，从而使模型的目标与我们的材料设计目标保持一致。我们证明ReFT在增强模型生成TIs和TCIs的能力方面是有效的，并且对生成材料的稳定性影响 minimal。使用微调后的模型，我们成功地识别出大量的新拓扑材料，其中Ge$_2$Bi$_2$O$_6$作为代表性例子——是一种具有0.26 eV全带隙的TIs，位列此类已知的最大值之一。', 'title_zh': '通过强化细调生成模型设计拓扑材料'}
{'arxiv_id': 'arXiv:2504.13042', 'title': 'Event-Enhanced Blurry Video Super-Resolution', 'authors': 'Dachun Kai, Yueyi Zhang, Jin Wang, Zeyu Xiao, Zhiwei Xiong, Xiaoyan Sun', 'link': 'https://arxiv.org/abs/2504.13042', 'abstract': 'In this paper, we tackle the task of blurry video super-resolution (BVSR), aiming to generate high-resolution (HR) videos from low-resolution (LR) and blurry inputs. Current BVSR methods often fail to restore sharp details at high resolutions, resulting in noticeable artifacts and jitter due to insufficient motion information for deconvolution and the lack of high-frequency details in LR frames. To address these challenges, we introduce event signals into BVSR and propose a novel event-enhanced network, Ev-DeblurVSR. To effectively fuse information from frames and events for feature deblurring, we introduce a reciprocal feature deblurring module that leverages motion information from intra-frame events to deblur frame features while reciprocally using global scene context from the frames to enhance event features. Furthermore, to enhance temporal consistency, we propose a hybrid deformable alignment module that fully exploits the complementary motion information from inter-frame events and optical flow to improve motion estimation in the deformable alignment process. Extensive evaluations demonstrate that Ev-DeblurVSR establishes a new state-of-the-art performance on both synthetic and real-world datasets. Notably, on real data, our method is +2.59 dB more accurate and 7.28$\\times$ faster than the recent best BVSR baseline FMA-Net. Code: this https URL.', 'abstract_zh': '基于事件信号的模糊视频超分辨率：Ev-DeblurVSR', 'title_zh': '事件增强模糊视频超分辨率'}
{'arxiv_id': 'arXiv:2504.13037', 'title': 'Towards Cardiac MRI Foundation Models: Comprehensive Visual-Tabular Representations for Whole-Heart Assessment and Beyond', 'authors': 'Yundi Zhang, Paul Hager, Che Liu, Suprosanna Shit, Chen Chen, Daniel Rueckert, Jiazhen Pan', 'link': 'https://arxiv.org/abs/2504.13037', 'abstract': "Cardiac magnetic resonance imaging is the gold standard for non-invasive cardiac assessment, offering rich spatio-temporal views of the cardiac anatomy and physiology. Patient-level health factors, such as demographics, metabolic, and lifestyle, are known to substantially influence cardiovascular health and disease risk, yet remain uncaptured by CMR alone. To holistically understand cardiac health and to enable the best possible interpretation of an individual's disease risk, CMR and patient-level factors must be jointly exploited within an integrated framework. Recent multi-modal approaches have begun to bridge this gap, yet they often rely on limited spatio-temporal data and focus on isolated clinical tasks, thereby hindering the development of a comprehensive representation for cardiac health evaluation. To overcome these limitations, we introduce ViTa, a step toward foundation models that delivers a comprehensive representation of the heart and a precise interpretation of individual disease risk. Leveraging data from 42,000 UK Biobank participants, ViTa integrates 3D+T cine stacks from short-axis and long-axis views, enabling a complete capture of the cardiac cycle. These imaging data are then fused with detailed tabular patient-level factors, enabling context-aware insights. This multi-modal paradigm supports a wide spectrum of downstream tasks, including cardiac phenotype and physiological feature prediction, segmentation, and classification of cardiac and metabolic diseases within a single unified framework. By learning a shared latent representation that bridges rich imaging features and patient context, ViTa moves beyond traditional, task-specific models toward a universal, patient-specific understanding of cardiac health, highlighting its potential to advance clinical utility and scalability in cardiac analysis.", 'abstract_zh': '心脏磁共振成像是非侵入性心脏评估的金标准，能提供丰富的空间-时间心脏解剖和生理视图。患者的健康因素，如人口统计学、代谢和生活方式，已知会对心血管健康和疾病风险产生重大影响，但这些因素目前无法仅通过CMR捕捉。为了全方位理解心脏健康并为个体疾病风险提供最准确的解释，必须在集成框架中同时利用CMR和患者的健康因素。近期的多模态方法已经开始填补这一空白，但它们往往依赖有限的空间-时间数据并专注于孤立的临床任务，限制了全面心脏健康评估表示的发展。为克服这些限制，我们引入了ViTa，这是一个迈向基础模型的步骤，能提供心脏的全面表示并精确解释个体疾病风险。基于来自42,000名UK生物银行参与者的数据，ViTa整合了短轴和长轴视角的3D+T心脏动态序列，能够完整捕捉心脏周期。这些影像数据随后与详细的患者级表格因素融合，提供情境感知的见解。这一多模态范式支持一系列下游任务，包括心脏表型和生理特征预测、心脏和代谢疾病的分割和分类，都在同一统一框架中进行。通过学习将丰富的影像特征和患者情境联系起来的共享潜在表示，ViTa超越了传统、任务特定的模型，朝着所有患者特定的心脏健康理解迈进，突显其在心脏分析中的临床效用和可扩展性的潜力。', 'title_zh': '面向心脏MRI基础模型：全面的视觉-表格式表示以实现整个心脏评估及其他应用'}
{'arxiv_id': 'arXiv:2504.13035', 'title': 'Prototypes are Balanced Units for Efficient and Effective Partially Relevant Video Retrieval', 'authors': 'WonJun Moon, Cheol-Ho Cho, Woojin Jun, Minho Shim, Taeoh Kim, Inwoong Lee, Dongyoon Wee, Jae-Pil Heo', 'link': 'https://arxiv.org/abs/2504.13035', 'abstract': 'In a retrieval system, simultaneously achieving search accuracy and efficiency is inherently challenging. This challenge is particularly pronounced in partially relevant video retrieval (PRVR), where incorporating more diverse context representations at varying temporal scales for each video enhances accuracy but increases computational and memory costs. To address this dichotomy, we propose a prototypical PRVR framework that encodes diverse contexts within a video into a fixed number of prototypes. We then introduce several strategies to enhance text association and video understanding within the prototypes, along with an orthogonal objective to ensure that the prototypes capture a diverse range of content. To keep the prototypes searchable via text queries while accurately encoding video contexts, we implement cross- and uni-modal reconstruction tasks. The cross-modal reconstruction task aligns the prototypes with textual features within a shared space, while the uni-modal reconstruction task preserves all video contexts during encoding. Additionally, we employ a video mixing technique to provide weak guidance to further align prototypes and associated textual representations. Extensive evaluations on TVR, ActivityNet-Captions, and QVHighlights validate the effectiveness of our approach without sacrificing efficiency.', 'abstract_zh': '在检索系统中同时实现搜索准确性和效率本质上是具有挑战性的。这一挑战在部分相关视频检索（PRVR）中尤为突出，通过在每个视频中引入不同时间和尺度的多样性上下文表示可以提高准确性，但会增加计算和内存成本。为了解决这种二难境地，我们提出了一种原型PRVR框架，将视频中的多样性上下文编码为固定数量的原型。我们还引入了几种策略来增强原型内的文本关联和视频理解，并引入了一个正交目标以确保原型能够捕捉多样化的内容。为了在保持原型可通过文本查询检索的同时准确编码视频上下文，我们实现了跨模态和单模态重构任务。跨模态重构任务在共享空间中对齐原型和文本特征，而单模态重构任务在编码过程中保存所有视频上下文。此外，我们采用视频混音技术以提供弱指导，进一步对齐原型及其相关的文本表示。在TVR、ActivityNet-Captions和QVHighlights上的广泛评估验证了我们方法的有效性，而不牺牲效率。', 'title_zh': '原型是高效的部分相关视频检索中的平衡单元'}
{'arxiv_id': 'arXiv:2504.13021', 'title': 'Pose and Facial Expression Transfer by using StyleGAN', 'authors': 'Petr Jahoda, Jan Cech', 'link': 'https://arxiv.org/abs/2504.13021', 'abstract': 'We propose a method to transfer pose and expression between face images. Given a source and target face portrait, the model produces an output image in which the pose and expression of the source face image are transferred onto the target identity. The architecture consists of two encoders and a mapping network that projects the two inputs into the latent space of StyleGAN2, which finally generates the output. The training is self-supervised from video sequences of many individuals. Manual labeling is not required. Our model enables the synthesis of random identities with controllable pose and expression. Close-to-real-time performance is achieved.', 'abstract_zh': '我们提出了一种在面部图像间transfer姿态和表情的方法。给定源面部肖像和目标面部身份，模型产生一个输出图像，在该图像中，源面部图像的姿态和表情被转移至目标面部身份上。该架构包含两个编码器和一个映射网络，将两个输入投影到StyleGAN2的潜在空间中，最终生成输出。训练是从多人的视频序列中进行自监督的，不需要手动标注。我们的模型能够合成具有可控姿态和表情的随机面部身份，并实现了接近实时的表现。', 'title_zh': '基于StyleGAN的表情和姿态转移'}
{'arxiv_id': 'arXiv:2504.12996', 'title': 'SHA256 at SemEval-2025 Task 4: Selective Amnesia -- Constrained Unlearning for Large Language Models via Knowledge Isolation', 'authors': 'Saransh Agrawal, Kuan-Hao Huang', 'link': 'https://arxiv.org/abs/2504.12996', 'abstract': 'Large language models (LLMs) frequently memorize sensitive information during training, posing risks when deploying publicly accessible models. Current machine unlearning methods struggle to selectively remove specific data associations without degrading overall model capabilities. This paper presents our solution to SemEval-2025 Task 4 on targeted unlearning, which introduces a two-stage methodology that combines causal mediation analysis with layer-specific optimization. Through systematic causal tracing experiments on OLMo architectures (1B and 7B parameters), we identify the critical role of the first few transformer layers (layers 0-5) in storing subject-attribute associations within MLP modules. Building on this insight, we develop a constrained optimization approach that freezes upper layers while applying a novel joint loss function to lower layers-simultaneously maximizing forget set loss via output token cross-entropy penalties and minimizing retain set deviation through adaptive regularization. Our method achieves 2nd place in the 1B model track, demonstrating strong task performance while maintaining 88% of baseline MMLU accuracy. These results establish causal-informed layer optimization as a promising paradigm for efficient, precise unlearning in LLMs, offering a significant step forward in addressing data privacy concerns in AI systems.', 'abstract_zh': '大型语言模型（LLMs）在训练过程中经常记忆敏感信息，部署公开可访问的模型时带来风险。当前的机器遗忘方法难以在不降级整体模型能力的情况下选择性地去除特定数据关联。本文提出了一种针对SemEval-2025 Task 4的目标遗忘解决方案，该方案结合因果中介分析和层特定优化，采用两阶段方法。通过在OLMo架构（1B和7B参数）上进行系统的因果追踪实验，我们确定了前几层变换器（层0-5）在MLP模块中存储主题属性关联的关键作用。基于这一洞察，我们开发了一种受限优化方法，在冻结高层的同时，对低层应用一种新型联合损失函数，通过输出令牌交叉熵惩罚最大化遗忘集损失，并通过自适应正则化最小化保留集偏差。该方法在1B模型赛道中获得第2名，展示了良好的任务性能，同时保持了88%的基本MMLU准确率。这些结果确立了因果导向的层优化作为在LLMs中实现高效、精确遗忘的有前途范式的地位，为解决AI系统中的数据隐私问题带来了重要进展。', 'title_zh': 'SemEval-2025 任务4中的SHA256：选择性失忆——通过知识隔离对大型语言模型进行约束性遗忘'}
{'arxiv_id': 'arXiv:2504.12984', 'title': 'A Virtual Machine for Arbitrary Low-Precision GPGPU Computation in LLM Serving', 'authors': 'Yaoyao Ding, Bohan Hou, Xiao Zhang, Allan Lin, Tianqi Chen, Cody Yu Hao, Yida Wang, Gennady Pekhimenko', 'link': 'https://arxiv.org/abs/2504.12984', 'abstract': 'Serving Large Language Models (LLMs) is critical for AI-powered applications but demands substantial computational resources, particularly in memory bandwidth and computational throughput. Low-precision computation has emerged as a key technique to improve efficiency while reducing resource consumption. Existing approaches for generating low-precision kernels are limited to weight bit widths that are powers of two and suffer from suboptimal performance due to high-level GPU programming abstractions. These abstractions restrict critical optimizations, such as fine-grained register management and optimized memory access patterns, which are essential for efficient low-precision computations. In this paper, we introduce a virtual machine (VM) designed for General-Purpose GPU (GPGPU) computing, enabling support for low-precision data types with arbitrary bit widths while maintaining GPU programmability. The proposed VM features a thread-block-level programming model, a hierarchical memory space, a novel algebraic layout system, and extensive support for diverse low-precision data types. VM programs are compiled into highly efficient GPU programs with automatic vectorization and instruction selection. Extensive experiments demonstrate that our VM efficiently supports a full spectrum of low-precision data types, and outperforms state-of-the-art low-precision kernels on their supported types. Compared to existing compilers like Triton and Ladder, as well as hand-optimized kernels such as QuantLLM and Marlin, our VM achieves performance improvements of 1.75x, 2.61x, 1.29x and 1.03x, respectively.', 'abstract_zh': '面向大规模语言模型的低精度计算虚拟机', 'title_zh': '一种用于大型语言模型服务的任意精度低精度GPGPU计算的虚拟机'}
{'arxiv_id': 'arXiv:2504.12982', 'title': 'Accommodate Knowledge Conflicts in Retrieval-augmented LLMs: Towards Reliable Response Generation in the Wild', 'authors': 'Jiatai Wang, Zhiwei Xu, Di Jin, Xuewen Yang, Tao Li', 'link': 'https://arxiv.org/abs/2504.12982', 'abstract': 'The proliferation of large language models (LLMs) has significantly advanced information retrieval systems, particularly in response generation (RG). Unfortunately, LLMs often face knowledge conflicts between internal memory and retrievaled external information, arising from misinformation, biases, or outdated knowledge. These conflicts undermine response reliability and introduce uncertainty in decision-making. In this work, we analyze how LLMs navigate knowledge conflicts from an information-theoretic perspective and reveal that when conflicting and supplementary information exhibit significant differences, LLMs confidently resolve their preferences. However, when the distinction is ambiguous, LLMs experience heightened uncertainty. Based on this insight, we propose Swin-VIB, a novel framework that integrates a pipeline of variational information bottleneck models into adaptive augmentation of retrieved information and guiding LLM preference in response generation. Extensive experiments on single-choice, open-ended question-answering (QA), and retrieval augmented generation (RAG) validate our theoretical findings and demonstrate the efficacy of Swin-VIB. Notably, our method improves single-choice task accuracy by at least 7.54\\% over competitive baselines.', 'abstract_zh': '大规模语言模型的普及显著推进了信息检索系统，尤其是在响应生成方面。不幸的是，大规模语言模型常常面临来自错误信息、偏见或过时知识的内部记忆与检索到的外部信息之间的知识冲突。这些冲突损害了响应的可靠性并在决策中引入了不确定性。在这项工作中，我们从信息论的角度分析了大规模语言模型如何处理知识冲突，并揭示出当冲突信息和补充信息存在显著差异时，大规模语言模型会自信地做出偏好选择。然而，当差异模糊不清时，语言模型会经历更高的不确定性。基于这一洞察，我们提出了一种名为Swin-VIB的新型框架，该框架将变分信息瓶颈模型的管道整合到检索信息的自适应增强中，并指导大规模语言模型在响应生成过程中的偏好。大量实验验证了我们的理论发现，并展示了Swin-VIB的有效性。值得注意的是，我们的方法在单选任务上的准确率至少提高了7.54%，超过了竞争基线。', 'title_zh': '在检索增强的大语言模型中缓解知识冲突：迈向可靠的实时响应生成'}
{'arxiv_id': 'arXiv:2504.12977', 'title': "A Phenomenological Approach to Analyzing User Queries in IT Systems Using Heidegger's Fundamental Ontology", 'authors': 'Maksim Vishnevskiy', 'link': 'https://arxiv.org/abs/2504.12977', 'abstract': "This paper presents a novel research analytical IT system grounded in Martin Heidegger's Fundamental Ontology, distinguishing between beings (das Seiende) and Being (das Sein). The system employs two modally distinct, descriptively complete languages: a categorical language of beings for processing user inputs and an existential language of Being for internal analysis. These languages are bridged via a phenomenological reduction module, enabling the system to analyze user queries (including questions, answers, and dialogues among IT specialists), identify recursive and self-referential structures, and provide actionable insights in categorical terms. Unlike contemporary systems limited to categorical analysis, this approach leverages Heidegger's phenomenological existential analysis to uncover deeper ontological patterns in query processing, aiding in resolving logical traps in complex interactions, such as metaphor usage in IT contexts. The path to full realization involves formalizing the language of Being by a research team based on Heidegger's Fundamental Ontology; given the existing completeness of the language of beings, this reduces the system's computability to completeness, paving the way for a universal query analysis tool. The paper presents the system's architecture, operational principles, technical implementation, use cases--including a case based on real IT specialist dialogues--comparative evaluation with existing tools, and its advantages and limitations.", 'abstract_zh': '本文基于马丁·海德格尔的基本 ontology，提出了一种新颖的研究分析 IT 系统，区分了存在者（das Seiende）和存在（das Sein）。该系统采用两种模态上不同的、描述性完整语言：一种是关于存在者的分类语言，用于处理用户输入；另一种是关于存在的存在语言，用于内部分析。通过现象学还原模块将这两种语言相连接，使系统能够分析用户查询（包括问题、答案和 IT 专家之间的对话），识别递归和自指结构，并以分类术语提供可操作的洞见。与仅限于分类分析的当代系统不同，该方法利用海德格尔的现象学存在分析来揭示查询处理中的更深层次本体模式，有助于在复杂交互中解决逻辑陷阱，例如在 IT 上文中的比喻使用。实现完整性的路径涉及基于海德格尔的基本 ontology 由研究团队形式化存在的语言；鉴于存在者的语言已具备完整性，这将系统的可计算性简化为完整性，从而为普遍查询分析工具铺平道路。本文介绍了该系统的架构、运作原则、技术实现、应用场景（包括基于真实 IT 专家对话的案例）、现有工具的比较评估，以及其优势和局限性。', 'title_zh': '使用海德格尔的基本本体论分析信息技术系统中用户查询的现象学方法'}
{'arxiv_id': 'arXiv:2504.12971', 'title': 'Transferrable Surrogates in Expressive Neural Architecture Search Spaces', 'authors': 'Shiwen Qin, Gabriela Kadlecová, Martin Pilát, Shay B. Cohen, Roman Neruda, Elliot J. Crowley, Jovita Lukasik, Linus Ericsson', 'link': 'https://arxiv.org/abs/2504.12971', 'abstract': 'Neural architecture search (NAS) faces a challenge in balancing the exploration of expressive, broad search spaces that enable architectural innovation with the need for efficient evaluation of architectures to effectively search such spaces. We investigate surrogate model training for improving search in highly expressive NAS search spaces based on context-free grammars. We show that i) surrogate models trained either using zero-cost-proxy metrics and neural graph features (GRAF) or by fine-tuning an off-the-shelf LM have high predictive power for the performance of architectures both within and across datasets, ii) these surrogates can be used to filter out bad architectures when searching on novel datasets, thereby significantly speeding up search and achieving better final performances, and iii) the surrogates can be further used directly as the search objective for huge speed-ups.', 'abstract_zh': '基于上下文无关文法的代理模型训练在扩展表达性强的神经架构搜索空间中的应用', 'title_zh': '可转移的代理模型在表征神经架构搜索空间中'}
{'arxiv_id': 'arXiv:2504.12961', 'title': 'QLLM: Do We Really Need a Mixing Network for Credit Assignment in Multi-Agent Reinforcement Learning?', 'authors': 'Zhouyang Jiang, Bin Zhang, Airong Wei, Zhiwei Xu', 'link': 'https://arxiv.org/abs/2504.12961', 'abstract': 'Credit assignment has remained a fundamental challenge in multi-agent reinforcement learning (MARL). Previous studies have primarily addressed this issue through value decomposition methods under the centralized training with decentralized execution paradigm, where neural networks are utilized to approximate the nonlinear relationship between individual Q-values and the global Q-value. Although these approaches have achieved considerable success in various benchmark tasks, they still suffer from several limitations, including imprecise attribution of contributions, limited interpretability, and poor scalability in high-dimensional state spaces. To address these challenges, we propose a novel algorithm, \\textbf{QLLM}, which facilitates the automatic construction of credit assignment functions using large language models (LLMs). Specifically, the concept of \\textbf{TFCAF} is introduced, wherein the credit allocation process is represented as a direct and expressive nonlinear functional formulation. A custom-designed \\textit{coder-evaluator} framework is further employed to guide the generation, verification, and refinement of executable code by LLMs, significantly mitigating issues such as hallucination and shallow reasoning during inference. Extensive experiments conducted on several standard MARL benchmarks demonstrate that the proposed method consistently outperforms existing state-of-the-art baselines. Moreover, QLLM exhibits strong generalization capability and maintains compatibility with a wide range of MARL algorithms that utilize mixing networks, positioning it as a promising and versatile solution for complex multi-agent scenarios.', 'abstract_zh': '信用分配仍然是多智能体强化学习（MARL）中的一个基本挑战。以往研究主要通过在集中训练与分散执行范式下的价值分解方法来解决这一问题，其中神经网络被用于近似个体Q值与全局Q值之间的非线性关系。尽管这些方法在各种基准任务中取得了显著成果，但仍存在贡献分配不精确、可解释性有限以及在高维度状态空间中伸缩性差等局限性。为解决上述挑战，我们提出了一种新型算法\\textbf{QLLM}，利用大型语言模型（LLMs）自动生成信用分配函数。具体地，我们引入了\\textbf{TFCAF}的概念，其中信用分配过程表示为直接且表达力强的非线性函数表述。进一步，我们设计了一种\\textit{编码-评估}框架，引导LLMs生成、验证和优化可执行代码，显著减轻推理过程中幻觉和浅层推理问题。在多个标准MARL基准上的广泛实验表明，所提出的方法在各方面均优于现有最先进的基线方法。此外，QLLM展现出强大的泛化能力和与利用混合网络的广泛MARL算法的兼容性，为其在复杂多智能体场景中的应用提供了有前景且灵活的解决方案。', 'title_zh': 'QLLM：在多智能体 reinforcement learning 中，我们真的需要一个混合网络来进行责任分配吗？'}
{'arxiv_id': 'arXiv:2504.12951', 'title': 'Are Retrials All You Need? Enhancing Large Language Model Reasoning Without Verbalized Feedback', 'authors': 'Nearchos Potamitis, Akhil Arora', 'link': 'https://arxiv.org/abs/2504.12951', 'abstract': "Recent advancements in large language models (LLMs) have catalyzed the development of general-purpose autonomous agents, demonstrating remarkable performance in complex reasoning tasks across various domains. This surge has spurred the evolution of a plethora of prompt-based reasoning frameworks. A recent focus has been on iterative reasoning strategies that refine outputs through self-evaluation and verbalized feedback. However, these strategies require additional computational complexity to enable models to recognize and correct their mistakes, leading to a significant increase in their cost. In this work, we introduce the concept of ``retrials without feedback'', an embarrassingly simple yet powerful mechanism for enhancing reasoning frameworks by allowing LLMs to retry problem-solving attempts upon identifying incorrect answers. Unlike conventional iterative refinement methods, our method does not require explicit self-reflection or verbalized feedback, simplifying the refinement process. Our findings indicate that simpler retrial-based approaches often outperform more sophisticated reasoning frameworks, suggesting that the benefits of complex methods may not always justify their computational costs. By challenging the prevailing assumption that more intricate reasoning strategies inherently lead to better performance, our work offers new insights into how simpler, more efficient approaches can achieve optimal results. So, are retrials all you need?", 'abstract_zh': 'Recent advancements in大型语言模型（LLMs）的进步催生了通用自主代理的发展，这些代理在各类领域的复杂推理任务中表现出色。这一进展推动了基于提示的推理框架的进化。最近的研究重点是通过自我评估和口头反馈来迭代的推理策略，以细化输出。然而，这些策略需要额外的计算复杂性，以便模型能够识别并纠正错误，从而导致成本显著增加。本研究引入了“无反馈重试”的概念，这是一种简便而强大的机制，通过允许LLMs在识别错误答案时重试问题求解尝试来增强推理框架。与传统的迭代改进方法不同，我们的方法不需要显式的自我反省或口头反馈，简化了改进过程。我们的研究结果显示，基于简单重试的方法往往优于更复杂的推理框架，表明复杂方法的好处可能并不总是值得其计算成本。通过挑战更复杂推理策略必然导致更好性能的现有假设，我们的研究为如何通过更简单、更高效的方法实现最优结果提供了新的见解。因此，重试就是你需要的吗？', 'title_zh': '都需要重试吗？无需口头反馈提高大型语言模型推理能力'}
{'arxiv_id': 'arXiv:2504.12911', 'title': 'Benchmarking Multi-National Value Alignment for Large Language Models', 'authors': 'Chengyi Ju, Weijie Shi, Chengzhong Liu, Jiaming Ji, Jipeng Zhang, Ruiyuan Zhang, Jia Zhu, Jiajie Xu, Yaodong Yang, Sirui Han, Yike Guo', 'link': 'https://arxiv.org/abs/2504.12911', 'abstract': "Do Large Language Models (LLMs) hold positions that conflict with your country's values? Occasionally they do! However, existing works primarily focus on ethical reviews, failing to capture the diversity of national values, which encompass broader policy, legal, and moral considerations. Furthermore, current benchmarks that rely on spectrum tests using manually designed questionnaires are not easily scalable.\nTo address these limitations, we introduce NaVAB, a comprehensive benchmark to evaluate the alignment of LLMs with the values of five major nations: China, the United States, the United Kingdom, France, and Germany. NaVAB implements a national value extraction pipeline to efficiently construct value assessment datasets. Specifically, we propose a modeling procedure with instruction tagging to process raw data sources, a screening process to filter value-related topics and a generation process with a Conflict Reduction mechanism to filter non-conflicting this http URL conduct extensive experiments on various LLMs across countries, and the results provide insights into assisting in the identification of misaligned scenarios. Moreover, we demonstrate that NaVAB can be combined with alignment techniques to effectively reduce value concerns by aligning LLMs' values with the target country.", 'abstract_zh': '大型语言模型（LLMs）持有的立场是否与您国家的价值观相冲突？偶尔会发生！然而，现有研究主要集中在伦理审查上，忽视了国家价值观的多样性，后者涵盖了更广泛的政治、法律和道德考虑。此外，当前依赖于手动设计问卷的频谱测试基准也不易于扩展。\n\n为解决这些局限性，我们提出了NaVAB，这是一个全面的基准，用于评估LLM与五个主要国家（中国、美国、英国、法国和德国）价值观的一致性。NaVAB实现了国家价值观提取管道，以高效构建价值评估数据集。具体来说，我们提出了一种带有指令标记的建模流程来处理原始数据源，一种筛选流程来筛选与价值观相关的主题，以及一种带有冲突减少机制的生成流程来筛选非冲突的数据。我们还在多个国家的各种LLM上进行了广泛的实验，结果提供了帮助识别不一致情景的见解。此外，我们展示了NaVAB可以与对齐技术结合使用，有效减少价值观关切，通过使LLM的价值与目标国家的价值观对齐。', 'title_zh': '多国价值观对大型语言模型的价值导向基准研究'}
{'arxiv_id': 'arXiv:2504.12898', 'title': 'Information Gain-Guided Causal Intervention for Autonomous Debiasing Large Language Models', 'authors': 'Zhouhao Sun, Xiao Ding, Li Du, Yunpeng Xu, Yixuan Ma, Yang Zhao, Bing Qin, Ting Liu', 'link': 'https://arxiv.org/abs/2504.12898', 'abstract': 'Despite significant progress, recent studies indicate that current large language models (LLMs) may still capture dataset biases and utilize them during inference, leading to the poor generalizability of LLMs. However, due to the diversity of dataset biases and the insufficient nature of bias suppression based on in-context learning, the effectiveness of previous prior knowledge-based debiasing methods and in-context learning based automatic debiasing methods is limited. To address these challenges, we explore the combination of causal mechanisms with information theory and propose an information gain-guided causal intervention debiasing (IGCIDB) framework. This framework first utilizes an information gain-guided causal intervention method to automatically and autonomously balance the distribution of instruction-tuning dataset. Subsequently, it employs a standard supervised fine-tuning process to train LLMs on the debiased dataset. Experimental results show that IGCIDB can effectively debias LLM to improve its generalizability across different tasks.', 'abstract_zh': '尽管取得了显著进展，近期研究表明，当前的大规模语言模型（LLMs）仍可能捕捉到数据集偏见并在推理过程中利用这些偏见，导致LLMs的一般性较差。然而，由于数据集偏见的多样性以及基于上下文学习的偏见抑制不足，先前基于先验知识的去偏方法和基于上下文学习的自动去偏方法的有效性有限。为应对这些挑战，我们探索将因果机制与信息论相结合，并提出一种信息增益引导的因果干预去偏框架（IGCIDB）。该框架首先利用信息增益引导的因果干预方法自动且自主地平衡指令微调数据集的分布；随后，使用标准的监督微调过程在去偏数据集上训练LLMs。实验结果显示，IGCIDB能够有效去偏LLMs，提高其在不同任务中的可移植性。', 'title_zh': '信息增益引导的因果干预用于自主去偏大型语言模型'}
{'arxiv_id': 'arXiv:2504.12891', 'title': 'Are AI agents the new machine translation frontier? Challenges and opportunities of single- and multi-agent systems for multilingual digital communication', 'authors': 'Vicent Briva-Iglesias', 'link': 'https://arxiv.org/abs/2504.12891', 'abstract': 'The rapid evolution of artificial intelligence (AI) has introduced AI agents as a disruptive paradigm across various industries, yet their application in machine translation (MT) remains underexplored. This paper describes and analyses the potential of single- and multi-agent systems for MT, reflecting on how they could enhance multilingual digital communication. While single-agent systems are well-suited for simpler translation tasks, multi-agent systems, which involve multiple specialized AI agents collaborating in a structured manner, may offer a promising solution for complex scenarios requiring high accuracy, domain-specific knowledge, and contextual awareness. To demonstrate the feasibility of multi-agent workflows in MT, we are conducting a pilot study in legal MT. The study employs a multi-agent system involving four specialized AI agents for (i) translation, (ii) adequacy review, (iii) fluency review, and (iv) final editing. Our findings suggest that multi-agent systems may have the potential to significantly improve domain-adaptability and contextual awareness, with superior translation quality to traditional MT or single-agent systems. This paper also sets the stage for future research into multi-agent applications in MT, integration into professional translation workflows, and shares a demo of the system analyzed in the paper.', 'abstract_zh': '人工智能（AI）的快速演进引入了AI代理作为各行各业的游戏规则改变者，但在机器翻译（MT）中的应用仍未被充分探索。本文描述并分析了单个和多代理系统在MT中的潜力，探讨了它们如何提升多语言数字通信的效果。虽然单代理系统适用于简单的翻译任务，但涉及多个专业AI代理以结构化方式协作的多代理系统可能为需要高准确度、领域特定知识和上下文意识的复杂场景提供有力解决方案。为了证明多代理工作流程在MT中的可行性，我们正在进行一项针对法律MT的试点研究。该研究采用了一个涉及四个人工智能代理的多代理系统，分别是（i）翻译，（ii） adequacy审查，（iii）流畅性审查，以及（iv）最终编辑。我们的研究发现表明，多代理系统可能在增强领域适应性和上下文意识方面具有巨大潜力，并且具有比传统MT或单代理系统更高的翻译质量。本文还为多代理应用在MT中的未来研究、整合到专业翻译工作流中奠定了基础，并分享了本文分析的系统演示。', 'title_zh': 'AI代理是否代表了机器翻译的新前沿？单Agent与多Agent系统在多语言数字通信中的挑战与机遇'}
{'arxiv_id': 'arXiv:2504.12867', 'title': 'EmoVoice: LLM-based Emotional Text-To-Speech Model with Freestyle Text Prompting', 'authors': 'Guanrou Yang, Chen Yang, Qian Chen, Ziyang Ma, Wenxi Chen, Wen Wang, Tianrui Wang, Yifan Yang, Zhikang Niu, Wenrui Liu, Fan Yu, Zhihao Du, Zhifu Gao, ShiLiang Zhang, Xie Chen', 'link': 'https://arxiv.org/abs/2504.12867', 'abstract': 'Human speech goes beyond the mere transfer of information; it is a profound exchange of emotions and a connection between individuals. While Text-to-Speech (TTS) models have made huge progress, they still face challenges in controlling the emotional expression in the generated speech. In this work, we propose EmoVoice, a novel emotion-controllable TTS model that exploits large language models (LLMs) to enable fine-grained freestyle natural language emotion control, and a phoneme boost variant design that makes the model output phoneme tokens and audio tokens in parallel to enhance content consistency, inspired by chain-of-thought (CoT) and modality-of-thought (CoM) techniques. Besides, we introduce EmoVoice-DB, a high-quality 40-hour English emotion dataset featuring expressive speech and fine-grained emotion labels with natural language descriptions. EmoVoice achieves state-of-the-art performance on the English EmoVoice-DB test set using only synthetic training data, and on the Chinese Secap test set using our in-house data. We further investigate the reliability of existing emotion evaluation metrics and their alignment with human perceptual preferences, and explore using SOTA multimodal LLMs GPT-4o-audio and Gemini to assess emotional speech. Demo samples are available at this https URL. Dataset, code, and checkpoints will be released.', 'abstract_zh': '人类言语远超信息传递的范畴，它是一种深刻的情感交流和人与人之间的连接。尽管文本转语音（TTS）模型取得了巨大进展，但仍面临生成语音中情感表达可控性的挑战。在本文中，我们提出了一种名为EmoVoice的新颖情感可控TTS模型，利用大规模语言模型（LLMs）实现精细的自由风格自然语言情感控制，并设计了一种音素增强变体，使模型同时输出音素令牌和音频令牌以增强内容一致性，灵感来源于链式思维（CoT）和思维模态（CoM）技术。此外，我们引入了EmoVoice-DB，这是一个高质量的40小时英情感数据库，包含表现力强的语音和带有自然语言描述的精细粒度情感标签。EmoVoice仅使用合成训练数据在English EmoVoice-DB测试集和使用我们内部数据的Chinese Secap测试集上实现了当前最佳性能。我们进一步探讨了现有情感评估指标的可靠性及其与人类感知偏好的一致性，并探索使用SOTA多模态LLM GPT-4o-audio和Gemini评估情感语音。演示样本可在以下链接获取：this https URL。数据集、代码和检查点将公开发布。', 'title_zh': 'EmoVoice：基于LLM的情感文本到语音模型与即兴文本提示'}
{'arxiv_id': 'arXiv:2504.12856', 'title': '3D-PNAS: 3D Industrial Surface Anomaly Synthesis with Perlin Noise', 'authors': 'Yifeng Cheng, Juan Du', 'link': 'https://arxiv.org/abs/2504.12856', 'abstract': 'Large pretrained vision foundation models have shown significant potential in various vision tasks. However, for industrial anomaly detection, the scarcity of real defect samples poses a critical challenge in leveraging these models. While 2D anomaly generation has significantly advanced with established generative models, the adoption of 3D sensors in industrial manufacturing has made leveraging 3D data for surface quality inspection an emerging trend. In contrast to 2D techniques, 3D anomaly generation remains largely unexplored, limiting the potential of 3D data in industrial quality inspection. To address this gap, we propose a novel yet simple 3D anomaly generation method, 3D-PNAS, based on Perlin noise and surface parameterization. Our method generates realistic 3D surface anomalies by projecting the point cloud onto a 2D plane, sampling multi-scale noise values from a Perlin noise field, and perturbing the point cloud along its normal direction. Through comprehensive visualization experiments, we demonstrate how key parameters - including noise scale, perturbation strength, and octaves, provide fine-grained control over the generated anomalies, enabling the creation of diverse defect patterns from pronounced deformations to subtle surface variations. Additionally, our cross-category experiments show that the method produces consistent yet geometrically plausible anomalies across different object types, adapting to their specific surface characteristics. We also provide a comprehensive codebase and visualization toolkit to facilitate future research.', 'abstract_zh': '基于珀林噪声和表面参数化的3D异常生成方法3D-PNAS', 'title_zh': '3D-PNAS：使用Perlin噪声的3D工业表面 anomaly 合成'}
{'arxiv_id': 'arXiv:2504.12841', 'title': 'ALT: A Python Package for Lightweight Feature Representation in Time Series Classification', 'authors': 'Balázs P. Halmos, Balázs Hajós, Vince Á. Molnár, Marcell T. Kurbucz, Antal Jakovác', 'link': 'https://arxiv.org/abs/2504.12841', 'abstract': 'We introduce ALT, an open-source Python package created for efficient and accurate time series classification (TSC). The package implements the adaptive law-based transformation (ALT) algorithm, which transforms raw time series data into a linearly separable feature space using variable-length shifted time windows. This adaptive approach enhances its predecessor, the linear law-based transformation (LLT), by effectively capturing patterns of varying temporal scales. The software is implemented for scalability, interpretability, and ease of use, achieving state-of-the-art performance with minimal computational overhead. Extensive benchmarking on real-world datasets demonstrates the utility of ALT for diverse TSC tasks in physics and related domains.', 'abstract_zh': '我们介绍了ALT，一个用于高效准确时间序列分类的开源Python包。该包实现了基于自适应法则的转换（ALT）算法，通过可变长度时间滑窗将原始时间序列数据转换至线性可分特征空间。这一自适应方法提高了其前身线性法则转换（LLT）算法，有效捕捉不同时间尺度的模式。该软件在可扩展性、可解释性和易用性方面进行了实现，以最小的计算开销达到最先进的性能。在实际数据集上的广泛基准测试展示了ALT在物理及相关领域各种时间序列分类任务中的实用价值。', 'title_zh': 'ALT: 一个轻量级时间序列分类特征表示的Python包'}
{'arxiv_id': 'arXiv:2504.12833', 'title': 'Image-Editing Specialists: An RLAIF Approach for Diffusion Models', 'authors': 'Elior Benarous, Yilun Du, Heng Yang', 'link': 'https://arxiv.org/abs/2504.12833', 'abstract': "We present a novel approach to training specialized instruction-based image-editing diffusion models, addressing key challenges in structural preservation with input images and semantic alignment with user prompts. We introduce an online reinforcement learning framework that aligns the diffusion model with human preferences without relying on extensive human annotations or curating a large dataset. Our method significantly improves the realism and alignment with instructions in two ways. First, the proposed models achieve precise and structurally coherent modifications in complex scenes while maintaining high fidelity in instruction-irrelevant areas. Second, they capture fine nuances in the desired edit by leveraging a visual prompt, enabling detailed control over visual edits without lengthy textual prompts. This approach simplifies users' efforts to achieve highly specific edits, requiring only 5 reference images depicting a certain concept for training. Experimental results demonstrate that our models can perform intricate edits in complex scenes, after just 10 training steps. Finally, we showcase the versatility of our method by applying it to robotics, where enhancing the visual realism of simulated environments through targeted sim-to-real image edits improves their utility as proxies for real-world settings.", 'abstract_zh': '我们提出了一种新的基于指令的图像编辑扩散模型训练方法，解决了输入图像的结构保真和用户提示的语义对齐的关键挑战。我们引入了一种在线强化学习框架，无需依赖大量的人工注释或收集大数据集，即可使扩散模型与人类偏好对齐。我们的方法通过两种方式显著提高了真实感和指令对齐。首先，所提出的模型在复杂场景中实现了精细且结构一致的修改，同时在与指令无关的区域保持高度保真度。其次，通过利用视觉提示捕捉所需的细微修改，实现了对视觉编辑的详细控制，而无需冗长的文本提示。该方法简化了用户实现高度特定编辑的努力，只需5张表示某个概念的参考图像即可进行训练。实验结果表明，我们的模型仅经过10次训练步骤即可在复杂场景中执行复杂的编辑。最后，我们展示了我们方法的灵活性，将其应用于机器人领域，通过目标导向的模拟到现实的图像编辑来增强模拟环境的视觉真实感，从而提高它们作为现实世界替代品的实用性。', 'title_zh': '图像编辑专家：基于RLAIF的方法在扩散模型中的应用'}
{'arxiv_id': 'arXiv:2504.12817', 'title': 'Explainable Scene Understanding with Qualitative Representations and Graph Neural Networks', 'authors': 'Nassim Belmecheri, Arnaud Gotlieb, Nadjib Lazaar, Helge Spieker', 'link': 'https://arxiv.org/abs/2504.12817', 'abstract': "This paper investigates the integration of graph neural networks (GNNs) with Qualitative Explainable Graphs (QXGs) for scene understanding in automated driving. Scene understanding is the basis for any further reactive or proactive decision-making. Scene understanding and related reasoning is inherently an explanation task: why is another traffic participant doing something, what or who caused their actions? While previous work demonstrated QXGs' effectiveness using shallow machine learning models, these approaches were limited to analysing single relation chains between object pairs, disregarding the broader scene context. We propose a novel GNN architecture that processes entire graph structures to identify relevant objects in traffic scenes. We evaluate our method on the nuScenes dataset enriched with DriveLM's human-annotated relevance labels. Experimental results show that our GNN-based approach achieves superior performance compared to baseline methods. The model effectively handles the inherent class imbalance in relevant object identification tasks while considering the complete spatial-temporal relationships between all objects in the scene. Our work demonstrates the potential of combining qualitative representations with deep learning approaches for explainable scene understanding in autonomous driving systems.", 'abstract_zh': '本文研究了图神经网络（GNNs）与定性可解释图（QXGs）在自动驾驶中场景理解中的集成应用。场景理解是任何进一步反应性或前瞻性决策的基础。场景理解和相关推理本质上是一种解释任务：为什么另一个交通参与者会采取某种行动，是什么或谁引起了他们的行为？尽管先前的工作展示了QXGs在浅层机器学习模型中的有效性，但这些方法仅限于分析对象对之间的单一关系链，忽略了更广泛的情景上下文。我们提出了一种新的GNN架构，用于处理整个图结构以识别交通场景中的相关对象。我们在带有DriveLM的人标注相关性标签的nuScenes数据集上评估了该方法。实验结果表明，基于GNN的方法在基准方法上取得了更好的性能。该模型有效处理了相关对象识别任务中的固有类别不平衡问题，同时考虑了场景中所有对象的完整空间-时间关系。我们的工作展示了将定性表示与深度学习方法结合以实现可解释的自动驾驶系统场景理解的潜力。', 'title_zh': '基于定性表示和图神经网络的可解释场景理解'}
{'arxiv_id': 'arXiv:2504.12807', 'title': 'Hybrid Dense-UNet201 Optimization for Pap Smear Image Segmentation Using Spider Monkey Optimization', 'authors': 'Ach Khozaimi, Isnani Darti, Syaiful Anam, Wuryansari Muharini Kusumawinahyu', 'link': 'https://arxiv.org/abs/2504.12807', 'abstract': 'Pap smear image segmentation is crucial for cervical cancer diagnosis. However, traditional segmentation models often struggle with complex cellular structures and variations in pap smear images. This study proposes a hybrid Dense-UNet201 optimization approach that integrates a pretrained DenseNet201 as the encoder for the U-Net architecture and optimizes it using the spider monkey optimization (SMO) algorithm. The Dense-UNet201 model excelled at feature extraction. The SMO was modified to handle categorical and discrete parameters. The SIPaKMeD dataset was used in this study and evaluated using key performance metrics, including loss, accuracy, Intersection over Union (IoU), and Dice coefficient. The experimental results showed that Dense-UNet201 outperformed U-Net, Res-UNet50, and Efficient-UNetB0. SMO Dense-UNet201 achieved a segmentation accuracy of 96.16%, an IoU of 91.63%, and a Dice coefficient score of 95.63%. These findings underscore the effectiveness of image preprocessing, pretrained models, and metaheuristic optimization in improving medical image analysis and provide new insights into cervical cell segmentation methods.', 'abstract_zh': 'Pap 疣片图像分割对于宫颈癌诊断至关重要。然而，传统分割模型往往难以处理 Pap 疣片图像中的复杂细胞结构和变化。本研究提出了一种结合预训练 DenseNet201 作为 U-Net 架构编码器并在其上使用蜘蛛猴优化（SMO）算法进行优化的混合 Dense-UNet201 优化方法。Dense-UNet201 模型在特征提取方面表现优异。SMO 被修改以处理类别和离散参数。本研究使用 SIPaKMeD 数据集，并使用包括损失、准确率、交并比 (IoU) 和 Dice 系数在内的关键性能指标进行评估。实验结果表明，Dense-UNet201 超过了 U-Net、Res-UNet50 和 Efficient-UNetB0。SMO 调整后的 Dense-UNet201 达到了 96.16% 的分割准确率、91.63% 的交并比和 95.63% 的 Dice 系数。这些发现强调了图像预处理、预训练模型和元启发式优化在提高医学图像分析方面的有效性，并为宫颈细胞分割方法提供了新的见解。', 'title_zh': '基于蜘蛛猴优化的Hybrid Dense-UNet20宫颈抹片图像分割优化'}
{'arxiv_id': 'arXiv:2504.12806', 'title': 'A Numerical Gradient Inversion Attack in Variational Quantum Neural-Networks', 'authors': 'Georgios Papadopoulos, Shaltiel Eloul, Yash Satsangi, Jamie Heredge, Niraj Kumar, Chun-Fu Chen, Marco Pistoia', 'link': 'https://arxiv.org/abs/2504.12806', 'abstract': "The loss landscape of Variational Quantum Neural Networks (VQNNs) is characterized by local minima that grow exponentially with increasing qubits. Because of this, it is more challenging to recover information from model gradients during training compared to classical Neural Networks (NNs). In this paper we present a numerical scheme that successfully reconstructs input training, real-world, practical data from trainable VQNNs' gradients. Our scheme is based on gradient inversion that works by combining gradients estimation with the finite difference method and adaptive low-pass filtering. The scheme is further optimized with Kalman filter to obtain efficient convergence. Our experiments show that our algorithm can invert even batch-trained data, given the VQNN model is sufficiently over-parameterized.", 'abstract_zh': 'Variational Quantum Neural Networks的损失景观特征在于随量子比特增加呈指数增长的局部最小值，这使得在训练过程中从模型梯度中恢复输入训练、实际世界的数据比经典神经网络更具挑战性。本文提出一种数值方案，能够成功从可训练的变量子神经网络(VQNN)的梯度中重构输入训练数据和实际世界数据。该方案基于梯度反转，结合梯度估计、有限差分方法和自适应低通滤波。进一步使用卡尔曼滤波器优化以实现高效的收敛。实验表明，当VQNN模型足够过参数化时，该算法即使对批量训练数据也能实现反转。', 'title_zh': '变分量子神经网络中的数值梯度逆向攻击'}
{'arxiv_id': 'arXiv:2504.12803', 'title': 'Enhancing Explainability and Reliable Decision-Making in Particle Swarm Optimization through Communication Topologies', 'authors': 'Nitin Gupta, Indu Bala, Bapi Dutta, Luis Martínez, Anupam Yadav', 'link': 'https://arxiv.org/abs/2504.12803', 'abstract': "Swarm intelligence effectively optimizes complex systems across fields like engineering and healthcare, yet algorithm solutions often suffer from low reliability due to unclear configurations and hyperparameters. This study analyzes Particle Swarm Optimization (PSO), focusing on how different communication topologies Ring, Star, and Von Neumann affect convergence and search behaviors. Using an adapted IOHxplainer , an explainable benchmarking tool, we investigate how these topologies influence information flow, diversity, and convergence speed, clarifying the balance between exploration and exploitation. Through visualization and statistical analysis, the research enhances interpretability of PSO's decisions and provides practical guidelines for choosing suitable topologies for specific optimization tasks. Ultimately, this contributes to making swarm based optimization more transparent, robust, and trustworthy.", 'abstract_zh': 'swarmintelligence在工程和医疗等领域有效地优化复杂系统，但由于配置和超参数不明确，算法解决方案往往可靠性较低。本研究分析了粒子群优化（PSO），关注环形、星形和冯·诺伊曼不同通信拓扑如何影响收敛性和搜索行为。通过使用可解释的基准工具IOHxplainer，研究探讨了这些拓扑如何影响信息流、多样性和收敛速度，澄清了探索与利用之间的平衡。通过可视化和统计分析，研究增强了PSO决策的可解释性，并提供了为特定优化任务选择合适拓扑的具体指导。最终，这有助于使基于群智的优化变得更加透明、稳健和可信。', 'title_zh': '通过通信拓扑提升粒子群优化的可解释性和可靠决策能力'}
{'arxiv_id': 'arXiv:2504.12782', 'title': 'Set You Straight: Auto-Steering Denoising Trajectories to Sidestep Unwanted Concepts', 'authors': 'Leyang Li, Shilin Lu, Yan Ren, Adams Wai-Kin Kong', 'link': 'https://arxiv.org/abs/2504.12782', 'abstract': 'Ensuring the ethical deployment of text-to-image models requires effective techniques to prevent the generation of harmful or inappropriate content. While concept erasure methods offer a promising solution, existing finetuning-based approaches suffer from notable limitations. Anchor-free methods risk disrupting sampling trajectories, leading to visual artifacts, while anchor-based methods rely on the heuristic selection of anchor concepts. To overcome these shortcomings, we introduce a finetuning framework, dubbed ANT, which Automatically guides deNoising Trajectories to avoid unwanted concepts. ANT is built on a key insight: reversing the condition direction of classifier-free guidance during mid-to-late denoising stages enables precise content modification without sacrificing early-stage structural integrity. This inspires a trajectory-aware objective that preserves the integrity of the early-stage score function field, which steers samples toward the natural image manifold, without relying on heuristic anchor concept selection. For single-concept erasure, we propose an augmentation-enhanced weight saliency map to precisely identify the critical parameters that most significantly contribute to the unwanted concept, enabling more thorough and efficient erasure. For multi-concept erasure, our objective function offers a versatile plug-and-play solution that significantly boosts performance. Extensive experiments demonstrate that ANT achieves state-of-the-art results in both single and multi-concept erasure, delivering high-quality, safe outputs without compromising the generative fidelity. Code is available at this https URL', 'abstract_zh': '确保文本到图像模型的伦理部署需要有效的技术来防止生成有害或不适当的内容。虽然概念擦除方法提供了有前景的解决方案，但现有的微调方法存在显著的限制。无锚方法存在破坏采样轨迹的风险，导致视觉 artifacts，而基于锚的方法依赖于启发式选择锚概念。为克服这些不足，我们引入了一种名为ANT的微调框架，它自动引导去噪轨迹以避免不必要的概念。ANT建立在一个关键洞察上：在中后期去噪阶段反向分类器无条件引导的条件方向能够实现精确的内容修改而不牺牲早期阶段的结构完整性。这启发了一个轨迹感知的目标，该目标保留了早期阶段得分函数域的完整性，引导样本向自然图像流形发展，而不依赖于启发式的锚概念选择。对于单一概念擦除，我们提出了一种增强增广的权重灵敏度图来精确识别对不需要的概念贡献最大的关键参数，从而实现更彻底和高效的擦除。对于多概念擦除，我们的目标函数提供了灵活的即插即用解决方案，显著提升了性能。大量实验表明，ANT在单概念和多概念擦除中均取得了最先进的结果，提供了高质量且安全的输出，而不牺牲生成保真度。代码可在以下链接获取。', 'title_zh': '正确定向：自动避开 unwanted 概念的去噪轨迹自引导'}
{'arxiv_id': 'arXiv:2504.12778', 'title': 'Towards Lossless Token Pruning in Late-Interaction Retrieval Models', 'authors': 'Yuxuan Zong, Benjamin Piwowarski', 'link': 'https://arxiv.org/abs/2504.12778', 'abstract': "Late interaction neural IR models like ColBERT offer a competitive effectiveness-efficiency trade-off across many benchmarks. However, they require a huge memory space to store the contextual representation for all the document tokens. Some works have proposed using either heuristics or statistical-based techniques to prune tokens from each document. This however doesn't guarantee that the removed tokens have no impact on the retrieval score. Our work uses a principled approach to define how to prune tokens without impacting the score between a document and a query. We introduce three regularization losses, that induce a solution with high pruning ratios, as well as two pruning strategies. We study them experimentally (in and out-domain), showing that we can preserve ColBERT's performance while using only 30\\% of the tokens.", 'abstract_zh': 'Late交互神经IR模型如ColBERT在许多基准测试中提供了竞争力的效果-效率折衷。然而，它们需要巨大的内存空间来存储所有文档词元的上下文表示。一些工作提出了使用启发式方法或统计技术从每个文档中修剪词元。但这并不能保证删除的词元不会影响检索得分。我们的工作采用了一个原则性的方法，定义了如何修剪词元而不影响文档和查询之间的得分。我们引入了三种正则化损失，诱导了高修剪比例的解，以及两种修剪策略。我们在实验中研究了它们（领域内和跨领域），展示了可以保留ColBERT的性能同时仅使用30%的词元。', 'title_zh': '向晚交互检索模型中无损令牌剪枝迈进'}
{'arxiv_id': 'arXiv:2504.12777', 'title': 'Multi-Agent Reinforcement Learning Simulation for Environmental Policy Synthesis', 'authors': 'James Rudd-Jones, Mirco Musolesi, María Pérez-Ortiz', 'link': 'https://arxiv.org/abs/2504.12777', 'abstract': 'Climate policy development faces significant challenges due to deep uncertainty, complex system dynamics, and competing stakeholder interests. Climate simulation methods, such as Earth System Models, have become valuable tools for policy exploration. However, their typical use is for evaluating potential polices, rather than directly synthesizing them. The problem can be inverted to optimize for policy pathways, but the traditional optimization approaches often struggle with non-linear dynamics, heterogeneous agents, and comprehensive uncertainty quantification. We propose a framework for augmenting climate simulations with Multi-Agent Reinforcement Learning (MARL) to address these limitations. We identify key challenges at the interface between climate simulations and the application of MARL in the context of policy synthesis, including reward definition, scalability with increasing agents and state spaces, uncertainty propagation across linked systems, and solution validation. Additionally, we discuss challenges in making MARL-derived solutions interpretable and useful for policy-makers. Our framework provides a foundation for more sophisticated climate policy exploration while acknowledging important limitations and areas for future research.', 'abstract_zh': '气候政策制定面临着深不确定性的重大挑战、复杂系统动力学以及利益相关方的矛盾利益。气候模拟方法，如地球系统模型，已成为政策探索的重要工具。然而，它们通常用于评估潜在政策，而非直接综合生成政策。该问题可以反转为优化政策路径，但传统的优化方法往往难以处理非线性动力学、异质代理和全面的不确定性量化。我们提出了一种利用多智能体强化学习（MARL）增强气候模拟的框架，以解决这些局限性。我们在气候模拟与MARL应用于政策综合的接口处识别了几个关键挑战，包括奖励定义、随着代理和状态空间增加的可扩展性、链接系统中的不确定性传播以及解决方案验证。此外，我们讨论了如何使从MARL推导出的解决方案可解释并适用于政策制定者。该框架为更复杂的气候政策探索提供了基础，同时承认了重要的限制和未来研究的领域。', 'title_zh': '多agent强化学习仿真用于环境政策合成'}
{'arxiv_id': 'arXiv:2504.12773', 'title': 'Enhancing the Geometric Problem-Solving Ability of Multimodal LLMs via Symbolic-Neural Integration', 'authors': 'Yicheng Pan, Zhenrong Zhang, Pengfei Hu, Jiefeng Ma, Jun Du, Jianshu Zhang, Quan Liu, Jianqing Gao, Feng Ma', 'link': 'https://arxiv.org/abs/2504.12773', 'abstract': 'Recent advances in Multimodal Large Language Models (MLLMs) have achieved remarkable progress in general domains and demonstrated promise in multimodal mathematical reasoning. However, applying MLLMs to geometry problem solving (GPS) remains challenging due to lack of accurate step-by-step solution data and severe hallucinations during reasoning. In this paper, we propose GeoGen, a pipeline that can automatically generates step-wise reasoning paths for geometry diagrams. By leveraging the precise symbolic reasoning, \\textbf{GeoGen} produces large-scale, high-quality question-answer pairs. To further enhance the logical reasoning ability of MLLMs, we train \\textbf{GeoLogic}, a Large Language Model (LLM) using synthetic data generated by GeoGen. Serving as a bridge between natural language and symbolic systems, GeoLogic enables symbolic tools to help verifying MLLM outputs, making the reasoning process more rigorous and alleviating hallucinations. Experimental results show that our approach consistently improves the performance of MLLMs, achieving remarkable results on benchmarks for geometric reasoning tasks. This improvement stems from our integration of the strengths of LLMs and symbolic systems, which enables a more reliable and interpretable approach for the GPS task. Codes are available at this https URL.', 'abstract_zh': 'Recent Advances in Multimodal Large Language Models for Geometry Problem Solving', 'title_zh': '通过符号-神经集成增强多模态大语言模型的几何问题求解能力'}
{'arxiv_id': 'arXiv:2504.12757', 'title': 'MCP Guardian: A Security-First Layer for Safeguarding MCP-Based AI System', 'authors': 'Sonu Kumar, Anubhav Girdhar, Ritesh Patil, Divyansh Tripathi', 'link': 'https://arxiv.org/abs/2504.12757', 'abstract': 'As Agentic AI gain mainstream adoption, the industry invests heavily in model capabilities, achieving rapid leaps in reasoning and quality. However, these systems remain largely confined to data silos, and each new integration requires custom logic that is difficult to scale. The Model Context Protocol (MCP) addresses this challenge by defining a universal, open standard for securely connecting AI-based applications (MCP clients) to data sources (MCP servers). However, the flexibility of the MCP introduces new risks, including malicious tool servers and compromised data integrity. We present MCP Guardian, a framework that strengthens MCP-based communication with authentication, rate-limiting, logging, tracing, and Web Application Firewall (WAF) scanning. Through real-world scenarios and empirical testing, we demonstrate how MCP Guardian effectively mitigates attacks and ensures robust oversight with minimal overheads. Our approach fosters secure, scalable data access for AI assistants, underscoring the importance of a defense-in-depth approach that enables safer and more transparent innovation in AI-driven environments.', 'abstract_zh': '随着代理型AI获得主流采用，行业在模型能力上投入大量资源，实现了推理和质量的迅速提升。然而，这些系统仍然主要局限于数据孤岛，每次新的整合都需要定制逻辑，难以规模化。模型上下文协议（MCP）通过定义一种安全连接基于AI的应用程序（MCP客户端）和数据源（MCP服务器）的通用开放标准来应对这一挑战。然而，MCP的灵活性引入了新的风险，包括恶意工具服务器和数据完整性的受损。我们提出了MCP监护，一个通过身份认证、速率限制、日志记录、追踪和Web应用防火墙（WAF）扫描来增强MCP基础通信的框架。通过实际场景和实证测试，我们展示了MCP监护如何有效地缓解攻击，实现最小开销下的全面监督。我们的方法促进了安全、可扩展的AI助手数据访问，强调了多层次防御在AI驱动环境中实现更安全、更透明创新的重要性。', 'title_zh': 'MCP守护者：一种基于MCP的AI系统安全防护层'}
{'arxiv_id': 'arXiv:2504.12755', 'title': 'Trajectory Adaptation using Large Language Models', 'authors': 'Anurag Maurya, Tashmoy Ghosh, Ravi Prakash', 'link': 'https://arxiv.org/abs/2504.12755', 'abstract': 'Adapting robot trajectories based on human instructions as per new situations is essential for achieving more intuitive and scalable human-robot interactions. This work proposes a flexible language-based framework to adapt generic robotic trajectories produced by off-the-shelf motion planners like RRT, A-star, etc, or learned from human demonstrations. We utilize pre-trained LLMs to adapt trajectory waypoints by generating code as a policy for dense robot manipulation, enabling more complex and flexible instructions than current methods. This approach allows us to incorporate a broader range of commands, including numerical inputs. Compared to state-of-the-art feature-based sequence-to-sequence models which require training, our method does not require task-specific training and offers greater interpretability and more effective feedback mechanisms. We validate our approach through simulation experiments on the robotic manipulator, aerial vehicle, and ground robot in the Pybullet and Gazebo simulation environments, demonstrating that LLMs can successfully adapt trajectories to complex human instructions.', 'abstract_zh': '基于人类指令调整机器人轨迹对于实现更加直观和可扩展的人机交互至关重要。本文提出了一种灵活的语言框架，用于调整通用机器人轨迹，这些轨迹由RRT、A*等现成的运动规划器生成，或从人类演示中学习。我们利用预训练的语言模型生成代码作为政策，以适应轨迹的路径点，从而实现更复杂和灵活的指令，这超过了现有方法的能力。该方法允许我们纳入更广泛的命令，包括数值输入。与需要训练的最先进的基于特征的序列到序列模型相比，我们的方法不需要特定任务的训练，提供了更高的可解释性和更有效的反馈机制。我们通过Pybullet和Gazebo仿真环境中的机器人 manipulator、空中无人机和地面机器人仿真实验验证了我们的方法，证明语言模型可以成功地将轨迹适应复杂的人类指令。', 'title_zh': '大规模语言模型驱动的轨迹适应'}
{'arxiv_id': 'arXiv:2504.12740', 'title': 'GPMFS: Global Foundation and Personalized Optimization for Multi-Label Feature Selection', 'authors': 'Yifan Cao, Zhilong Mi, Ziqiao Yin, Binghui Guo, Jin Dong', 'link': 'https://arxiv.org/abs/2504.12740', 'abstract': 'As artificial intelligence methods are increasingly applied to complex task scenarios, high dimensional multi-label learning has emerged as a prominent research focus. At present, the curse of dimensionality remains one of the major bottlenecks in high-dimensional multi-label learning, which can be effectively addressed through multi-label feature selection methods. However, existing multi-label feature selection methods mostly focus on identifying global features shared across all labels, which overlooks personalized characteristics and specific requirements of individual labels. This global-only perspective may limit the ability to capture label-specific discriminative information, thereby affecting overall performance. In this paper, we propose a novel method called GPMFS (Global Foundation and Personalized Optimization for Multi-Label Feature Selection). GPMFS firstly identifies global features by exploiting label correlations, then adaptively supplements each label with a personalized subset of discriminative features using a threshold-controlled strategy. Experiments on multiple real-world datasets demonstrate that GPMFS achieves superior performance while maintaining strong interpretability and robustness. Furthermore, GPMFS provides insights into the label-specific strength across different multi-label datasets, thereby demonstrating the necessity and potential applicability of personalized feature selection approaches.', 'abstract_zh': '基于全局基础与个性化优化的多标签特征选择方法（GPMFS）', 'title_zh': 'GPMFS：全局基础与个性化优化的多标签特征选择'}
{'arxiv_id': 'arXiv:2504.12735', 'title': 'The Athenian Academy: A Seven-Layer Architecture Model for Multi-Agent Systems', 'authors': 'Lidong Zhai, Zhijie Qiu, Xizhong Guo, Jiaqi Li', 'link': 'https://arxiv.org/abs/2504.12735', 'abstract': 'This paper proposes the "Academy of Athens" multi-agent seven-layer framework, aimed at systematically addressing challenges in multi-agent systems (MAS) within artificial intelligence (AI) art creation, such as collaboration efficiency, role allocation, environmental adaptation, and task parallelism. The framework divides MAS into seven layers: multi-agent collaboration, single-agent multi-role playing, single-agent multi-scene traversal, single-agent multi-capability incarnation, different single agents using the same large model to achieve the same target agent, single-agent using different large models to achieve the same target agent, and multi-agent synthesis of the same target agent. Through experimental validation in art creation, the framework demonstrates its unique advantages in task collaboration, cross-scene adaptation, and model fusion. This paper further discusses current challenges such as collaboration mechanism optimization, model stability, and system security, proposing future exploration through technologies like meta-learning and federated learning. The framework provides a structured methodology for multi-agent collaboration in AI art creation and promotes innovative applications in the art field.', 'abstract_zh': '基于雅典学院的多代理七层框架：人工智能艺术创作中的多代理系统挑战系统化解决方法', 'title_zh': '雅典学院：多代理系统-seven层架构模型'}
{'arxiv_id': 'arXiv:2504.12734', 'title': 'Pandora: A Code-Driven Large Language Model Agent for Unified Reasoning Across Diverse Structured Knowledge', 'authors': 'Yongrui Chen, Junhao He, Linbo Fu, Shenyu Zhang, Rihui Jin, Xinbang Dai, Jiaqi Li, Dehai Min, Nan Hu, Yuxin Zhang, Guilin Qi, Yi Huang, Tongtong Wu', 'link': 'https://arxiv.org/abs/2504.12734', 'abstract': "Unified Structured Knowledge Reasoning (USKR) aims to answer natural language questions (NLQs) by using structured sources such as tables, databases, and knowledge graphs in a unified way. Existing USKR methods either rely on employing task-specific strategies or custom-defined representations, which struggle to leverage the knowledge transfer between different SKR tasks or align with the prior of LLMs, thereby limiting their performance. This paper proposes a novel USKR framework named \\textsc{Pandora}, which takes advantage of \\textsc{Python}'s \\textsc{Pandas} API to construct a unified knowledge representation for alignment with LLM pre-training. It employs an LLM to generate textual reasoning steps and executable Python code for each question. Demonstrations are drawn from a memory of training examples that cover various SKR tasks, facilitating knowledge transfer. Extensive experiments on four benchmarks involving three SKR tasks demonstrate that \\textsc{Pandora} outperforms existing unified frameworks and competes effectively with task-specific methods.", 'abstract_zh': '统一结构化知识推理（USKR）旨在通过统一利用表格、数据库和知识图等结构化来源来回答自然语言问题（NLQs）。现有USKR方法要么依赖于特定任务策略的使用，要么依赖于自定义表示，这些方法难以利用不同SKR任务之间的知识转移或与LLM先验一致，从而限制了它们的性能。本文提出了一种名为Pandora的新颖USKR框架，利用Python的Pandas API构建统一的知识表示，以便与LLM预训练对齐。它使用LLM生成每个问题的文本推理步骤和可执行的Python代码。从涵盖各种SKR任务的训练示例记忆中抽取示例，促进知识迁移。在四个涉及三种SKR任务的基准上的广泛实验表明，Pandora优于现有统一框架，并且能够与特定任务方法竞争。', 'title_zh': '潘多拉：一个代码驱动的大语言模型代理，用于跨多样结构化知识统一推理'}
{'arxiv_id': 'arXiv:2504.12722', 'title': 'SimUSER: Simulating User Behavior with Large Language Models for Recommender System Evaluation', 'authors': 'Nicolas Bougie, Narimasa Watanabe', 'link': 'https://arxiv.org/abs/2504.12722', 'abstract': 'Recommender systems play a central role in numerous real-life applications, yet evaluating their performance remains a significant challenge due to the gap between offline metrics and online behaviors. Given the scarcity and limits (e.g., privacy issues) of real user data, we introduce SimUSER, an agent framework that serves as believable and cost-effective human proxies. SimUSER first identifies self-consistent personas from historical data, enriching user profiles with unique backgrounds and personalities. Then, central to this evaluation are users equipped with persona, memory, perception, and brain modules, engaging in interactions with the recommender system. SimUSER exhibits closer alignment with genuine humans than prior work, both at micro and macro levels. Additionally, we conduct insightful experiments to explore the effects of thumbnails on click rates, the exposure effect, and the impact of reviews on user engagement. Finally, we refine recommender system parameters based on offline A/B test results, resulting in improved user engagement in the real world.', 'abstract_zh': '推荐系统在众多实际应用中扮演着核心角色，但由于离线指标与在线行为之间的差距，评估其性能仍是一项重大挑战。鉴于真实用户数据的稀缺性和限制（如隐私问题），我们引入了SimUSER这一代理框架，作为可信且经济高效的虚拟用户代理。SimUSER首先从历史数据中识别出自洽的人格，丰富用户的背景和个性特征。在此评价的核心则是配备了人格、记忆、感知和大脑模块的用户，与推荐系统进行交互。SimUSER在微观和宏观层面上都更接近真实人类，此外，我们还进行了深入的实验，探讨缩略图对点击率的影响、曝光效应以及评论对用户参与度的影响。最后，我们根据离线A/B测试结果调整推荐系统参数，从而在实际应用中提高了用户参与度。', 'title_zh': 'SimUSER：使用大型语言模型模拟用户行为以评估推荐系统'}
{'arxiv_id': 'arXiv:2504.12721', 'title': 'TimeCapsule: Solving the Jigsaw Puzzle of Long-Term Time Series Forecasting with Compressed Predictive Representations', 'authors': 'Yihang Lu, Yangyang Xu, Qitao Qing, Xianwei Meng', 'link': 'https://arxiv.org/abs/2504.12721', 'abstract': 'Recent deep learning models for Long-term Time Series Forecasting (LTSF) often emphasize complex, handcrafted designs, while simpler architectures like linear models or MLPs have often outperformed these intricate solutions. In this paper, we revisit and organize the core ideas behind several key techniques, such as redundancy reduction and multi-scale modeling, which are frequently employed in advanced LTSF models. Our goal is to streamline these ideas for more efficient deep learning utilization. To this end, we introduce TimeCapsule, a model built around the principle of high-dimensional information compression that unifies these techniques in a generalized yet simplified framework. Specifically, we model time series as a 3D tensor, incorporating temporal, variate, and level dimensions, and leverage mode production to capture multi-mode dependencies while achieving dimensionality compression. We propose an internal forecast within the compressed representation domain, supported by the Joint-Embedding Predictive Architecture (JEPA), to monitor the learning of predictive representations. Extensive experiments on challenging benchmarks demonstrate the versatility of our method, showing that TimeCapsule can achieve state-of-the-art performance.', 'abstract_zh': '最近的长期时间序列 forecasting 深度学习模型往往强调复杂的手工艺品设计，而简单的架构如线性模型或MLPs常常表现出更优的效果。本文重新审视并组织了几种关键技术的核心思想，如冗余减少和多尺度建模，这些技术经常被高级长期时间序列 forecasting 模型所采用。我们的目标是为了更高效的深度学习应用简化这些思想。为此，我们提出 TimeCapsule 模型，该模型围绕高维信息压缩原则构建，将这些技术统一于一个通用且简化框架中。具体而言，我们将时间序列建模为3D张量，结合时间、变量和尺度维度，并利用模式生成来捕捉多模式依赖关系同时实现维数压缩。我们提出基于联合嵌入预测架构（JEPA）的支持，在压缩表示域内进行内部预测，以监控预测表示的学习。在具有挑战性的基准上的广泛实验表明，我们的方法具有灵活性，TimeCapsule 可以达到最先进的性能。', 'title_zh': 'TimeCapsule：通过压缩预测表示解决长期时间序列预测难题'}
{'arxiv_id': 'arXiv:2504.12718', 'title': 'TUMLS: Trustful Fully Unsupervised Multi-Level Segmentation for Whole Slide Images of Histology', 'authors': 'Walid Rehamnia, Alexandra Getmanskaya, Evgeniy Vasilyev, Vadim Turlapov', 'link': 'https://arxiv.org/abs/2504.12718', 'abstract': 'Digital pathology, augmented by artificial intelligence (AI), holds significant promise for improving the workflow of pathologists. However, challenges such as the labor-intensive annotation of whole slide images (WSIs), high computational demands, and trust concerns arising from the absence of uncertainty estimation in predictions hinder the practical application of current AI methodologies in histopathology. To address these issues, we present a novel trustful fully unsupervised multi-level segmentation methodology (TUMLS) for WSIs. TUMLS adopts an autoencoder (AE) as a feature extractor to identify the different tissue types within low-resolution training data. It selects representative patches from each identified group based on an uncertainty measure and then does unsupervised nuclei segmentation in their respective higher-resolution space without using any ML algorithms. Crucially, this solution integrates seamlessly into clinicians workflows, transforming the examination of a whole WSI into a review of concise, interpretable cross-level insights. This integration significantly enhances and accelerates the workflow while ensuring transparency. We evaluated our approach using the UPENN-GBM dataset, where the AE achieved a mean squared error (MSE) of 0.0016. Additionally, nucleus segmentation is assessed on the MoNuSeg dataset, outperforming all unsupervised approaches with an F1 score of 77.46% and a Jaccard score of 63.35%. These results demonstrate the efficacy of TUMLS in advancing the field of digital pathology.', 'abstract_zh': '基于人工智能增强的数字病理学：一种新型可信无监督多级分割方法（TUMLS）的研究', 'title_zh': 'TUMLS: 可信的完全无监督多级分割方法用于病理学 Whole Slide Images'}
{'arxiv_id': 'arXiv:2504.12717', 'title': 'Post-pre-training for Modality Alignment in Vision-Language Foundation Models', 'authors': "Shin'ya Yamaguchi, Dewei Feng, Sekitoshi Kanai, Kazuki Adachi, Daiki Chijiwa", 'link': 'https://arxiv.org/abs/2504.12717', 'abstract': 'Contrastive language image pre-training (CLIP) is an essential component of building modern vision-language foundation models. While CLIP demonstrates remarkable zero-shot performance on downstream tasks, the multi-modal feature spaces still suffer from a modality gap, which is a gap between image and text feature clusters and limits downstream task performance. Although existing works attempt to address the modality gap by modifying pre-training or fine-tuning, they struggle with heavy training costs with large datasets or degradations of zero-shot performance. This paper presents CLIP-Refine, a post-pre-training method for CLIP models at a phase between pre-training and fine-tuning. CLIP-Refine aims to align the feature space with 1 epoch training on small image-text datasets without zero-shot performance degradations. To this end, we introduce two techniques: random feature alignment (RaFA) and hybrid contrastive-distillation (HyCD). RaFA aligns the image and text features to follow a shared prior distribution by minimizing the distance to random reference vectors sampled from the prior. HyCD updates the model with hybrid soft labels generated by combining ground-truth image-text pair labels and outputs from the pre-trained CLIP model. This contributes to achieving both maintaining the past knowledge and learning new knowledge to align features. Our extensive experiments with multiple classification and retrieval tasks show that CLIP-Refine succeeds in mitigating the modality gap and improving the zero-shot performance.', 'abstract_zh': 'CLIP-Refine：预训练后多模态特征空间对齐方法以缓解模态缺口并提升零样本性能', 'title_zh': '视觉-语言基础模型中的模态对齐后预训练'}
{'arxiv_id': 'arXiv:2504.12714', 'title': 'Cross-environment Cooperation Enables Zero-shot Multi-agent Coordination', 'authors': 'Kunal Jha, Wilka Carvalho, Yancheng Liang, Simon S. Du, Max Kleiman-Weiner, Natasha Jaques', 'link': 'https://arxiv.org/abs/2504.12714', 'abstract': 'Zero-shot coordination (ZSC), the ability to adapt to a new partner in a cooperative task, is a critical component of human-compatible AI. While prior work has focused on training agents to cooperate on a single task, these specialized models do not generalize to new tasks, even if they are highly similar. Here, we study how reinforcement learning on a distribution of environments with a single partner enables learning general cooperative skills that support ZSC with many new partners on many new problems. We introduce two Jax-based, procedural generators that create billions of solvable coordination challenges. We develop a new paradigm called Cross-Environment Cooperation (CEC), and show that it outperforms competitive baselines quantitatively and qualitatively when collaborating with real people. Our findings suggest that learning to collaborate across many unique scenarios encourages agents to develop general norms, which prove effective for collaboration with different partners. Together, our results suggest a new route toward designing generalist cooperative agents capable of interacting with humans without requiring human data.', 'abstract_zh': '零样本协调（ZSC）：在新任务中适应新伙伴的协作能力是人类兼容AI的关键组成部分。以往的工作集中在训练代理在同一任务上协作，但这些专门的模型不适用于新任务，即使新任务非常相似。在这里，我们研究了在包含单一伙伴的环境分布上使用强化学习如何促进学习适用于与许多新伙伴在多种新问题上实现ZSC的一般协作技能。我们引入了基于Jax的两个过程生成器，创建了数亿个可解协调挑战。我们提出了一个新的范式，称为跨环境协作（CEC），并与人类协作时，展示了其在定量和定性上优于竞争基线。我们的发现表明，在多种独特场景中学习协作促使代理发展出一般性规范，这些规范对于与不同伙伴协作证明是有效的。结合我们的结果，这表明了一种新的设计途径，旨在设计能够与人类互动的一般性协作代理，而无需使用人类数据。', 'title_zh': '跨环境协作实现零样本多智能体协调'}
{'arxiv_id': 'arXiv:2504.12711', 'title': 'NTIRE 2025 Challenge on Day and Night Raindrop Removal for Dual-Focused Images: Methods and Results', 'authors': 'Xin Li, Yeying Jin, Xin Jin, Zongwei Wu, Bingchen Li, Yufei Wang, Wenhan Yang, Yu Li, Zhibo Chen, Bihan Wen, Robby T. Tan, Radu Timofte, Qiyu Rong, Hongyuan Jing, Mengmeng Zhang, Jinglong Li, Xiangyu Lu, Yi Ren, Yuting Liu, Meng Zhang, Xiang Chen, Qiyuan Guan, Jiangxin Dong, Jinshan Pan, Conglin Gou, Qirui Yang, Fangpu Zhang, Yunlong Lin, Sixiang Chen, Guoxi Huang, Ruirui Lin, Yan Zhang, Jingyu Yang, Huanjing Yue, Jiyuan Chen, Qiaosi Yi, Hongjun Wang, Chenxi Xie, Shuai Li, Yuhui Wu, Kaiyi Ma, Jiakui Hu, Juncheng Li, Liwen Pan, Guangwei Gao, Wenjie Li, Zhenyu Jin, Heng Guo, Zhanyu Ma, Yubo Wang, Jinghua Wang, Wangzhi Xing, Anjusree Karnavar, Diqi Chen, Mohammad Aminul Islam, Hao Yang, Ruikun Zhang, Liyuan Pan, Qianhao Luo, XinCao, Han Zhou, Yan Min, Wei Dong, Jun Chen, Taoyi Wu, Weijia Dou, Yu Wang, Shengjie Zhao, Yongcheng Huang, Xingyu Han, Anyan Huang, Hongtao Wu, Hong Wang, Yefeng Zheng, Abhijeet Kumar, Aman Kumar, Marcos V. Conde, Paula Garrido, Daniel Feijoo, Juan C. Benito, Guanglu Dong, Xin Lin, Siyuan Liu, Tianheng Zheng, Jiayu Zhong, Shouyi Wang, Xiangtai Li, Lanqing Guo, Lu Qi, Chao Ren, Shuaibo Wang, Shilong Zhang, Wanyu Zhou, Yunze Wu, Qinzhong Tan, Jieyuan Pei, Zhuoxuan Li, Jiayu Wang, Haoyu Bian, Haoran Sun', 'link': 'https://arxiv.org/abs/2504.12711', 'abstract': 'This paper reviews the NTIRE 2025 Challenge on Day and Night Raindrop Removal for Dual-Focused Images. This challenge received a wide range of impressive solutions, which are developed and evaluated using our collected real-world Raindrop Clarity dataset. Unlike existing deraining datasets, our Raindrop Clarity dataset is more diverse and challenging in degradation types and contents, which includes day raindrop-focused, day background-focused, night raindrop-focused, and night background-focused degradations. This dataset is divided into three subsets for competition: 14,139 images for training, 240 images for validation, and 731 images for testing. The primary objective of this challenge is to establish a new and powerful benchmark for the task of removing raindrops under varying lighting and focus conditions. There are a total of 361 participants in the competition, and 32 teams submitting valid solutions and fact sheets for the final testing phase. These submissions achieved state-of-the-art (SOTA) performance on the Raindrop Clarity dataset. The project can be found at this https URL.', 'abstract_zh': 'NTIRE 2025日夜雨滴去除挑战评审：面向双焦图像的Raindrop Clarity数据集', 'title_zh': 'NTIRE 2025挑战赛：双焦距图像日间和夜间雨滴去除的方法与结果'}
{'arxiv_id': 'arXiv:2504.12681', 'title': 'GRAIL: Gradient-Based Adaptive Unlearning for Privacy and Copyright in LLMs', 'authors': 'Kun-Woo Kim, Ji-Hoon Park, Ju-Min Han, Seong-Whan Lee', 'link': 'https://arxiv.org/abs/2504.12681', 'abstract': 'Large Language Models (LLMs) trained on extensive datasets often learn sensitive information, which raises significant social and legal concerns under principles such as the "Right to be forgotten." Retraining entire models from scratch to remove undesired information is both costly and impractical. Furthermore, existing single-domain unlearning methods fail to address multi-domain scenarios, where knowledge is interwoven across domains such as privacy and copyright, creating overlapping representations that lead to excessive knowledge removal or degraded performance. To tackle these issues, we propose GRAIL (GRadient-based AdaptIve unLearning), a novel multi-domain unlearning framework. GRAIL leverages gradient information from multiple domains to precisely distinguish the unlearning scope from the retention scope, and applies an adaptive parameter-wise localization strategy to selectively remove targeted knowledge while preserving critical parameters for each domain. Experimental results on unlearning benchmarks show that GRAIL achieves unlearning success on par with the existing approaches, while also demonstrating up to 17% stronger knowledge retention success compared to the previous state-of-art method. Our findings establish a new paradigm for effectively managing and regulating sensitive information in large-scale pre-trained language models.', 'abstract_zh': '基于梯度的适应性多域抹除框架（GRAIL）：在大规模预训练语言模型中有效管理和调节敏感信息的新范式', 'title_zh': 'GRAIL：基于梯度的自适应遗忘技术以保护LLMs中的隐私和版权'}
{'arxiv_id': 'arXiv:2504.12673', 'title': 'ACoRN: Noise-Robust Abstractive Compression in Retrieval-Augmented Language Models', 'authors': 'Singon Kim, Gunho Jung, Seong-Whan Lee', 'link': 'https://arxiv.org/abs/2504.12673', 'abstract': 'Abstractive compression utilizes smaller langauge models to condense query-relevant context, reducing computational costs in retrieval-augmented generation (RAG). However,retrieved documents often include information that is either irrelevant to answering the query or misleading due to factual incorrect content, despite having high relevance scores. This behavior indicates that abstractive compressors are more likely to omit important information essential for the correct answer, especially in long contexts where attention dispersion occurs. To address this issue, we categorize retrieved documents in a more fine-grained manner and propose Abstractive Compression Robust against Noise (ACoRN), which introduces two novel training steps. First, we use offline data augmentation on the training dataset to enhance compressor robustness against two distinct types of retrieval noise. Second, since the language modelbased compressor cannot fully utilize information from multiple retrieved documents and exhibits positional bias, we perform finetuning to generate summaries centered around key information that directly supports the correct answer. Our experiments demonstrate that T5-large, trained with ACoRN as a compressor, improves EM and F1 scores while preserving the answer string, which could serve as direct evidence. ACoRN excels on datasets with many accuracy-reducing documents, making it highly useful in real-world scenarios.', 'abstract_zh': '基于抽取的压缩利用较小的语言模型压缩查询相关上下文，降低检索增强生成（RAG）中的计算成本。然而，检索到的文档有时包含与查询无关的信息，或者由于事实错误内容而导致误导，尽管具有高相关性得分。这种行为表明，基于抽取的压缩器更有可能遗漏对正确答案至关重要的信息，尤其是在长上下文中注意力分散的情况下。为了解决这个问题，我们对检索到的文档进行更细致的分类，并提出了抗噪声的基于抽取的压缩（ACoRN），引入了两个新的训练步骤。首先，我们对训练数据集进行离线数据增强，以增强压缩器对两种不同的检索噪声的鲁棒性。其次，由于基于语言模型的压缩器不能充分利用多个检索到的文档中的信息，并表现出位置偏差，我们进行微调以生成以支持正确答案的关键信息为中心的摘要。我们的实验表明，使用ACoRN作为压缩器训练的T5-large，在保持答案字符串的同时提高了EM和F1分数，这可以作为直接证据。ACoRN在包含许多降低准确性的文档的数据集上表现优异，使其在实际场景中非常有用。', 'title_zh': 'ACoRN: 在检索增强语言模型中具有噪声鲁棒性的抽象压缩'}
{'arxiv_id': 'arXiv:2504.12672', 'title': 'Post-processing improves accuracy of Artificial Intelligence weather forecasts', 'authors': 'Belinda Trotta, Robert Johnson, Catherine de Burgh-Day, Debra Hudson, Esteban Abellan, James Canvin, Andrew Kelly, Daniel Mentiplay, Benjamin Owen, Jennifer Whelan', 'link': 'https://arxiv.org/abs/2504.12672', 'abstract': "Artificial Intelligence (AI) weather models are now reaching operational-grade performance for some variables, but like traditional Numerical Weather Prediction (NWP) models, they exhibit systematic biases and reliability issues. We test the application of the Bureau of Meteorology's existing statistical post-processing system, IMPROVER, to ECMWF's deterministic Artificial Intelligence Forecasting System (AIFS), and compare results against post-processed outputs from the ECMWF HRES and ENS models. Without any modification to configuration or processing workflows, post-processing yields comparable accuracy improvements for AIFS as for traditional NWP forecasts, in both expected value and probabilistic outputs. We show that blending AIFS with NWP models improves overall forecast skill, even when AIFS alone is not the most accurate component. These findings show that statistical post-processing methods developed for NWP are directly applicable to AI models, enabling national meteorological centres to incorporate AI forecasts into existing workflows in a low-risk, incremental fashion.", 'abstract_zh': '人工智能天气模型现在在某些变量上达到了运营级性能，但像传统的数值天气预报模型一样，它们也表现出系统偏差和可靠性问题。我们测试了气象局现有统计后处理系统IMPROVER在欧洲中期天气预报中心（ECMWF）确定性人工智能预报系统（AIFS）中的应用，并将结果与ECMWF HRES和ENS模型经过后处理的输出进行比较。在不做任何配置或处理工作流修改的情况下，后处理为AIFS带来了与传统数值天气预报相近的准确度提高，无论是期望值还是概率输出。我们演示了将AIFS与数值天气预报模型结合使用可以提高总体预报技能，即使在单独使用时AIFS并非最准确的成分也是如此。这些发现表明，为数值天气预报开发的统计后处理方法可以直接应用于人工智能模型，使国家气象中心能够以低风险、渐进的方式将人工智能预报整合到现有工作流程中。', 'title_zh': '后处理提高人工神经网络天气预报的准确性'}
{'arxiv_id': 'arXiv:2504.12663', 'title': 'Persona-judge: Personalized Alignment of Large Language Models via Token-level Self-judgment', 'authors': 'Xiaotian Zhang, Ruizhe Chen, Yang Feng, Zuozhu Liu', 'link': 'https://arxiv.org/abs/2504.12663', 'abstract': 'Aligning language models with human preferences presents significant challenges, particularly in achieving personalization without incurring excessive computational costs. Existing methods rely on reward signals and additional annotated data, limiting their scalability and adaptability to diverse human values. To address these challenges, we introduce Persona-judge, a novel discriminative paradigm that enables training-free personalized alignment with unseen preferences. Instead of optimizing policy parameters through external reward feedback, Persona-judge leverages the intrinsic preference judgment capabilities of the model. Specifically, a draft model generates candidate tokens conditioned on a given preference, while a judge model, embodying another preference, cross-validates the predicted tokens whether to be accepted. Experimental results demonstrate that Persona-judge, using the inherent preference evaluation mechanisms of the model, offers a scalable and computationally efficient solution to personalized alignment, paving the way for more adaptive customized alignment.', 'abstract_zh': '基于个人信息偏好对语言模型进行对齐面临显著挑战，特别是如何在不增加过多计算成本的情况下实现个性化对齐。现有方法依赖于奖励信号和额外的标注数据，限制了其可扩展性和对多样化人类价值观的适应性。为解决这些问题，我们引入了Persona-judge这一新型辨别范式，使其能够在未训练的情况下实现对未知偏好的个性化对齐。Persona-judge 不是通过外部奖励反馈优化策略参数，而是利用模型自身的内在偏好判断能力。具体来说，草稿模型根据给定的偏好生成候选词，而裁判模型则代表另一种偏好，对预测的词是否被接受进行交叉验证。实验结果表明，Persona-judge 利用模型固有的偏好评估机制，提供了一种可扩展且计算高效的个性化对齐解决方案，为更具适应性的定制对齐打开了大门。', 'title_zh': 'personality-judge: 面向大型语言模型的基于token级别自我判断的个性化对齐'}
{'arxiv_id': 'arXiv:2504.12644', 'title': 'Quantum Computing Supported Adversarial Attack-Resilient Autonomous Vehicle Perception Module for Traffic Sign Classification', 'authors': 'Reek Majumder, Mashrur Chowdhury, Sakib Mahmud Khan, Zadid Khan, Fahim Ahmad, Frank Ngeni, Gurcan Comert, Judith Mwakalonge, Dimitra Michalaka', 'link': 'https://arxiv.org/abs/2504.12644', 'abstract': 'Deep learning (DL)-based image classification models are essential for autonomous vehicle (AV) perception modules since incorrect categorization might have severe repercussions. Adversarial attacks are widely studied cyberattacks that can lead DL models to predict inaccurate output, such as incorrectly classified traffic signs by the perception module of an autonomous vehicle. In this study, we create and compare hybrid classical-quantum deep learning (HCQ-DL) models with classical deep learning (C-DL) models to demonstrate robustness against adversarial attacks for perception modules. Before feeding them into the quantum system, we used transfer learning models, alexnet and vgg-16, as feature extractors. We tested over 1000 quantum circuits in our HCQ-DL models for projected gradient descent (PGD), fast gradient sign attack (FGSA), and gradient attack (GA), which are three well-known untargeted adversarial approaches. We evaluated the performance of all models during adversarial attacks and no-attack scenarios. Our HCQ-DL models maintain accuracy above 95\\% during a no-attack scenario and above 91\\% for GA and FGSA attacks, which is higher than C-DL models. During the PGD attack, our alexnet-based HCQ-DL model maintained an accuracy of 85\\% compared to C-DL models that achieved accuracies below 21\\%. Our results highlight that the HCQ-DL models provide improved accuracy for traffic sign classification under adversarial settings compared to their classical counterparts.', 'abstract_zh': '基于深度学习的图像分类模型对于自动驾驶车辆感知模块至关重要，因为错误分类可能导致严重后果。我们创建并比较了混合经典-量子深度学习（HCQ-DL）模型与经典深度学习（C-DL）模型，以展示其在感知模块中对抗敌对攻击的鲁棒性。在将这些模型输入量子系统之前，我们使用了转移学习模型alexnet和vgg-16作为特征提取器。我们在HCQ-DL模型中测试了超过1000个量子电路，针对三种广为人知的无目标敌对攻击方法（投影梯度下降法PGD、快速梯度符号攻击FGSA和梯度攻击GA）。我们在敌对攻击和无攻击情况下评估了所有模型的性能。在无攻击情况下，我们的HCQ-DL模型保持了95%以上的准确性，在FGSA和FGSA攻击下保持了91%以上的准确性，这高于C-DL模型。在PGD攻击中，基于alexnet的HCQ-DL模型保持了85%的准确性，而C-DL模型的准确性低于21%。我们的结果表明，在敌对设置下，HCQ-DL模型在交通标志分类中的准确性优于其经典对手。', 'title_zh': '基于量子计算支持的对抗攻击鲁棒自主车辆感知模块用于交通标志分类'}
{'arxiv_id': 'arXiv:2504.12637', 'title': 'Scaling Instruction-Tuned LLMs to Million-Token Contexts via Hierarchical Synthetic Data Generation', 'authors': 'Linda He, Jue Wang, Maurice Weber, Shang Zhu, Ben Athiwaratkun, Ce Zhang', 'link': 'https://arxiv.org/abs/2504.12637', 'abstract': 'Large Language Models (LLMs) struggle with long-context reasoning, not only due to the quadratic scaling of computational complexity with sequence length but also because of the scarcity and expense of annotating long-context data. There has been barely any open-source work that systematically ablates long-context data, nor is there any openly available instruction tuning dataset with contexts surpassing 100K tokens. To bridge this gap, we introduce a novel post-training synthetic data generation strategy designed to efficiently extend the context window of LLMs while preserving their general task performance. Our approach scalably extends to arbitrarily long context lengths, unconstrained by the length of available real-world data, which effectively addresses the scarcity of raw long-context data. Through a step-by-step rotary position embedding (RoPE) scaling training strategy, we demonstrate that our model, with a context length of up to 1M tokens, performs well on the RULER benchmark and InfiniteBench and maintains robust performance on general language tasks.', 'abstract_zh': '大型语言模型在长上下文推理方面存在困难，不仅因为计算复杂性随序列长度呈二次增长，还因为长上下文数据标注稀缺且昂贵。鲜有开源工作系统地剔除长上下文数据，也没有公开可用的指令调优数据集包含超过100K令牌的上下文。为解决这一问题，我们提出了一种新型后训练合成数据生成策略，旨在高效扩展大型语言模型的上下文窗口，同时保持其一般任务性能。通过可扩展地扩展到任意长的上下文长度，不受真实世界可用数据长度的限制，我们有效解决了长上下文数据稀缺的问题。通过逐步旋转位置嵌入（RoPE）缩放训练策略，我们证明了该模型在RULER基准测试和InfiniteBench上表现出色，并在一般语言任务中保持了稳健的性能。', 'title_zh': '通过层次合成数据生成扩展指令调优的大规模语言模型至百万-token 上下文'}
{'arxiv_id': 'arXiv:2504.12609', 'title': 'Crossing the Human-Robot Embodiment Gap with Sim-to-Real RL using One Human Demonstration', 'authors': 'Tyler Ga Wei Lum, Olivia Y. Lee, C. Karen Liu, Jeannette Bohg', 'link': 'https://arxiv.org/abs/2504.12609', 'abstract': 'Teaching robots dexterous manipulation skills often requires collecting hundreds of demonstrations using wearables or teleoperation, a process that is challenging to scale. Videos of human-object interactions are easier to collect and scale, but leveraging them directly for robot learning is difficult due to the lack of explicit action labels from videos and morphological differences between robot and human hands. We propose Human2Sim2Robot, a novel real-to-sim-to-real framework for training dexterous manipulation policies using only one RGB-D video of a human demonstrating a task. Our method utilizes reinforcement learning (RL) in simulation to cross the human-robot embodiment gap without relying on wearables, teleoperation, or large-scale data collection typically necessary for imitation learning methods. From the demonstration, we extract two task-specific components: (1) the object pose trajectory to define an object-centric, embodiment-agnostic reward function, and (2) the pre-manipulation hand pose to initialize and guide exploration during RL training. We found that these two components are highly effective for learning the desired task, eliminating the need for task-specific reward shaping and tuning. We demonstrate that Human2Sim2Robot outperforms object-aware open-loop trajectory replay by 55% and imitation learning with data augmentation by 68% across grasping, non-prehensile manipulation, and multi-step tasks. Project Site: this https URL', 'abstract_zh': '基于人类演示的实时到模拟再到实时的 Dexterous 操作策略训练框架', 'title_zh': '通过基于一人示范的仿真实验到现实的RL方法跨越人类与机器人 bodilic 缩隙'}
{'arxiv_id': 'arXiv:2504.12608', 'title': 'Code Copycat Conundrum: Demystifying Repetition in LLM-based Code Generation', 'authors': 'Mingwei Liu, Juntao Li, Ying Wang, Xueying Du, Zuoyu Ou, Qiuyuan Chen, Bingxu An, Zhao Wei, Yong Xu, Fangming Zou, Xin Peng, Yiling Lou', 'link': 'https://arxiv.org/abs/2504.12608', 'abstract': "Despite recent advances in Large Language Models (LLMs) for code generation, the quality of LLM-generated code still faces significant challenges. One significant issue is code repetition, which refers to the model's tendency to generate structurally redundant code, resulting in inefficiencies and reduced readability. To address this, we conduct the first empirical study to investigate the prevalence and nature of repetition across 19 state-of-the-art code LLMs using three widely-used benchmarks. Our study includes both quantitative and qualitative analyses, revealing that repetition is pervasive and manifests at various granularities and extents, including character, statement, and block levels. We further summarize a taxonomy of 20 repetition patterns. Building on our findings, we propose DeRep, a rule-based technique designed to detect and mitigate repetition in generated code. We evaluate DeRep using both open-source benchmarks and in an industrial setting. Our results demonstrate that DeRep significantly outperforms baselines in reducing repetition (with an average improvements of 91.3%, 93.5%, and 79.9% in rep-3, rep-line, and sim-line metrics) and enhancing code quality (with a Pass@1 increase of 208.3% over greedy search). Furthermore, integrating DeRep improves the performance of existing repetition mitigation methods, with Pass@1 improvements ranging from 53.7% to 215.7%.", 'abstract_zh': '尽管大型语言模型(LLMs)在代码生成方面取得了最近的进展，但LLM生成的代码质量仍面临显著挑战。其中一个重大问题是代码重复，这指的是模型倾向于生成结构冗余的代码，导致效率低下和可读性降低。为应对这一问题，我们首次通过使用三种广泛使用的基准对19个最先进的代码LLM进行实证研究，以调查代码重复的普遍性和性质。该研究包括定量和定性的分析，揭示出重复现象普遍存在，并在字符、语句和代码块等多个粒度和程度上表现出来。我们进一步总结了20种重复模式。基于研究发现，我们提出了一种基于规则的技术DeRep，旨在检测并减轻生成代码中的重复。我们使用开源基准和工业环境对DeRep进行了评估。结果表明，DeRep在减少重复（repetition-3、repetition-line和similarity-line指标分别为91.3%、93.5%和79.9%的平均改进）和提高代码质量（Pass@1指标相对于贪婪搜索提高208.3%）方面显著优于基准方法。此外，集成DeRep还能提升现有重复性减轻方法的性能，Pass@1指标的改进范围从53.7%到215.7%。', 'title_zh': '代码复制猫难题：揭开基于LLM的代码生成中重复现象的面纱'}
{'arxiv_id': 'arXiv:2504.12606', 'title': 'Robo-SGG: Exploiting Layout-Oriented Normalization and Restitution for Robust Scene Graph Generation', 'authors': 'Changsheng Lv, Mengshi Qi, Zijian Fu, Huadong Ma', 'link': 'https://arxiv.org/abs/2504.12606', 'abstract': 'In this paper, we introduce a novel method named Robo-SGG, i.e., Layout-Oriented Normalization and Restitution for Robust Scene Graph Generation. Compared to the existing SGG setting, the robust scene graph generation aims to perform inference on a diverse range of corrupted images, with the core challenge being the domain shift between the clean and corrupted images. Existing SGG methods suffer from degraded performance due to compromised visual features e.g., corruption interference or occlusions. To obtain robust visual features, we exploit the layout information, which is domain-invariant, to enhance the efficacy of existing SGG methods on corrupted images. Specifically, we employ Instance Normalization(IN) to filter out the domain-specific feature and recover the unchangeable structural features, i.e., the positional and semantic relationships among objects by the proposed Layout-Oriented Restitution. Additionally, we propose a Layout-Embedded Encoder (LEE) that augments the existing object and predicate encoders within the SGG framework, enriching the robust positional and semantic features of objects and predicates. Note that our proposed Robo-SGG module is designed as a plug-and-play component, which can be easily integrated into any baseline SGG model. Extensive experiments demonstrate that by integrating the state-of-the-art method into our proposed Robo-SGG, we achieve relative improvements of 5.6%, 8.0%, and 6.5% in mR@50 for PredCls, SGCls, and SGDet tasks on the VG-C dataset, respectively, and achieve new state-of-the-art performance in corruption scene graph generation benchmark (VG-C and GQA-C). We will release our source code and model.', 'abstract_zh': '一种面向布局的鲁棒场景图生成方法：Robo-SGG，即基于布局的归一化与恢复方法', 'title_zh': 'Robo-SGG：利用布局导向的规范化和重构实现稳健的场景图生成'}
{'arxiv_id': 'arXiv:2504.12585', 'title': 'Identifying and Mitigating the Influence of the Prior Distribution in Large Language Models', 'authors': 'Liyi Zhang, Veniamin Veselovsky, R. Thomas McCoy, Thomas L. Griffiths', 'link': 'https://arxiv.org/abs/2504.12585', 'abstract': 'Large language models (LLMs) sometimes fail to respond appropriately to deterministic tasks -- such as counting or forming acronyms -- because the implicit prior distribution they have learned over sequences of tokens influences their responses. In this work, we show that, in at least some cases, LLMs actually compute the information needed to perform these tasks correctly, and we identify some interventions that can allow them to access this information to improve their performance. First, we show that simply prompting the language model to not rely on its prior knowledge leads to dramatic improvements in prior-dominated tasks. We then use mechanistic interpretability techniques to localize the prior within the LLM and manipulate the extent to which that prior influences its responses. Specifically, we show that it is possible to identify layers of the underlying neural network that correlate with the prior probability of a response and that lightweight finetuning of these layers with basic prompts on prior-dominated tasks achieves high performance on held-out answers. These results suggest that the information required to produce a correct response is contained within the representations of the problems formed by the models. Furthermore, we show that this finetuning is significantly more effective for prior-dominated tasks, and that the error after finetuning is no longer correlated with the prior. Our results suggest that it may be possible to define effective methods for manipulating the extent to which LLMs rely upon their priors in solving problems, potentially increasing their performance in settings where LLMs hallucinate for reasons related to the prior probability of token sequences.', 'abstract_zh': '大型语言模型有时在执行确定性任务（如计数或形成缩写）时无法恰当响应，因为它们学习到的词元序列先验分布影响了其响应。在本文中，我们展示，在至少某些情况下，大型语言模型实际上计算了执行这些任务所需的信息，并识别了一些可以使其访问这些信息以提高性能的干预措施。首先，我们展示了仅仅提示语言模型不要依赖其先验知识会在先验主导的任务中带来显著性能提升。然后，我们使用机制可解释性技术定位大型语言模型中的先验，并操控其对响应的影响程度。具体来说，我们展示了识别与响应先验概率相关的底层神经网络层的可能性，并且通过基本提示对这些层进行轻量级微调，在保留集答案上实现了高性能。这些结果表明，生成正确响应所需的信息包含在模型形成的问题表示中。此外，我们展示了这种微调对先验主导的任务特别有效，且在微调后错误不再与先验相关。我们的结果表明，可能定义有效方法来操控语言模型在解决问题时依赖其先验的程度，从而在语言模型因词元序列先验概率原因产生幻觉的场景中提升其性能。', 'title_zh': '识别并缓解先验分布对大型语言模型的影响'}
{'arxiv_id': 'arXiv:2504.12577', 'title': 'Local Data Quantity-Aware Weighted Averaging for Federated Learning with Dishonest Clients', 'authors': 'Leming Wu, Yaochu Jin, Kuangrong Hao, Han Yu', 'link': 'https://arxiv.org/abs/2504.12577', 'abstract': "Federated learning (FL) enables collaborative training of deep learning models without requiring data to leave local clients, thereby preserving client privacy. The aggregation process on the server plays a critical role in the performance of the resulting FL model. The most commonly used aggregation method is weighted averaging based on the amount of data from each client, which is thought to reflect each client's contribution. However, this method is prone to model bias, as dishonest clients might report inaccurate training data volumes to the server, which is hard to verify. To address this issue, we propose a novel secure \\underline{Fed}erated \\underline{D}ata q\\underline{u}antity-\\underline{a}ware weighted averaging method (FedDua). It enables FL servers to accurately predict the amount of training data from each client based on their local model gradients uploaded. Furthermore, it can be seamlessly integrated into any FL algorithms that involve server-side model aggregation. Extensive experiments on three benchmarking datasets demonstrate that FedDua improves the global model performance by an average of 3.17% compared to four popular FL aggregation methods in the presence of inaccurate client data volume declarations.", 'abstract_zh': '联邦学习中的安全数据数量感知加权平均方法（FedDua）', 'title_zh': '带有不诚实客户端的联邦学习中基于局部数据量感知加权平均的方法'}
{'arxiv_id': 'arXiv:2504.12576', 'title': 'CM3AE: A Unified RGB Frame and Event-Voxel/-Frame Pre-training Framework', 'authors': 'Wentao Wu, Xiao Wang, Chenglong Li, Bo Jiang, Jin Tang, Bin Luo, Qi Liu', 'link': 'https://arxiv.org/abs/2504.12576', 'abstract': "Event cameras have attracted increasing attention in recent years due to their advantages in high dynamic range, high temporal resolution, low power consumption, and low latency. Some researchers have begun exploring pre-training directly on event data. Nevertheless, these efforts often fail to establish strong connections with RGB frames, limiting their applicability in multi-modal fusion scenarios. To address these issues, we propose a novel CM3AE pre-training framework for the RGB-Event perception. This framework accepts multi-modalities/views of data as input, including RGB images, event images, and event voxels, providing robust support for both event-based and RGB-event fusion based downstream tasks. Specifically, we design a multi-modal fusion reconstruction module that reconstructs the original image from fused multi-modal features, explicitly enhancing the model's ability to aggregate cross-modal complementary information. Additionally, we employ a multi-modal contrastive learning strategy to align cross-modal feature representations in a shared latent space, which effectively enhances the model's capability for multi-modal understanding and capturing global dependencies. We construct a large-scale dataset containing 2,535,759 RGB-Event data pairs for the pre-training. Extensive experiments on five downstream tasks fully demonstrated the effectiveness of CM3AE. Source code and pre-trained models will be released on this https URL.", 'abstract_zh': '基于RGB-事件感知的新型CM3AE预训练框架', 'title_zh': 'CM3AE：统一的RGB帧和事件体素/帧预训练框架'}
{'arxiv_id': 'arXiv:2504.12563', 'title': 'MetaSynth: Meta-Prompting-Driven Agentic Scaffolds for Diverse Synthetic Data Generation', 'authors': 'Haris Riaz, Sourav Bhabesh, Vinayak Arannil, Miguel Ballesteros, Graham Horwood', 'link': 'https://arxiv.org/abs/2504.12563', 'abstract': 'Recent smaller language models such Phi-3.5 and Phi-4 rely on synthetic data generated using larger Language models. Questions remain about leveraging synthetic data for other use cases, such as adapting LLMs to specific domains. A key limitation of synthetic data is low diversity, which negatively impacts its downstream applicability for improving other models. To address this, we propose MetaSynth, a method for generating synthetic data that enhances diversity through meta-prompting, where a language model orchestrates multiple "expert" LLM agents to collaboratively generate data. Using only 25 million tokens of synthetic data generated with MetaSynth, we successfully adapt a well-trained LLM (Mistral-7B-v0.3) to two specialized domains-Finance and Biomedicine-without compromising the capabilities of the resulting model in general tasks. In addition, we evaluate the diversity of our synthetic data using seven automated metrics, and find that it approaches the diversity of LLM pre-training corpora.\nContinually pre-training Mistral-7B-v0.3 with MetaSynth notably outperforms the base LLM, showing improvements of up to 4.08% in Finance and 13.75% in Biomedicine. The same model shows degraded performance when trained on data generated using a template prompt, even when the template includes prior generations and varying In-Context exemplars of real data. Our findings suggest that a few million tokens of diverse synthetic data without mixing any real data, is sufficient for effective domain adaptation when using MetaSynth.', 'abstract_zh': '近期较小的语言模型Phi-3.5和Phi-4依赖于 larger 语言模型生成的合成数据。对于合成数据在其他应用场景中的利用，如使大型语言模型适应特定领域，仍存在疑问。合成数据的一个关键局限性是其多样性较低，这对其下游应用和提高其他模型的效果产生了负面影响。为解决这一问题，我们提出了一种名为MetaSynth的方法，该方法通过元提示（meta-prompting），由语言模型协调多个“专家”大型语言模型代理共同生成数据，以增强多样性。仅使用2500万个token的合成数据，我们成功地将一个经过充分训练的语言模型（Mistral-7B-v0.3）适配到金融和生物医学两个特定领域，而不会影响其在通用任务中的能力。此外，我们使用七个自动化指标评估了合成数据的多样性，并发现其接近于预先训练语言模型语料库的多样性。通过使用MetaSynth持续预训练Mistral-7B-v0.3，显著优于基础语言模型，在金融领域表现提高了4.08%，在生物医学领域提高了13.75%。使用模板提示进行训练时，即使模板包含先前生成的示例和不同内省示例的真实数据，同一模型的表现也会下降。我们的研究结果表明，在使用MetaSynth时，不混入任何真实数据的少量多样化的合成数据（几百万token）就足以实现有效的领域适配。', 'title_zh': 'MetaSynth：元提示驱动的自主支架用于生成多样化的合成数据'}
{'arxiv_id': 'arXiv:2504.12557', 'title': 'TraCeS: Trajectory Based Credit Assignment From Sparse Safety Feedback', 'authors': 'Siow Meng Low, Akshat Kumar', 'link': 'https://arxiv.org/abs/2504.12557', 'abstract': "In safe reinforcement learning (RL), auxiliary safety costs are used to align the agent to safe decision making. In practice, safety constraints, including cost functions and budgets, are unknown or hard to specify, as it requires anticipation of all possible unsafe behaviors. We therefore address a general setting where the true safety definition is unknown, and has to be learned from sparsely labeled data. Our key contributions are: first, we design a safety model that performs credit assignment to estimate each decision step's impact on the overall safety using a dataset of diverse trajectories and their corresponding binary safety labels (i.e., whether the corresponding trajectory is safe/unsafe). Second, we illustrate the architecture of our safety model to demonstrate its ability to learn a separate safety score for each timestep. Third, we reformulate the safe RL problem using the proposed safety model and derive an effective algorithm to optimize a safe yet rewarding policy. Finally, our empirical results corroborate our findings and show that this approach is effective in satisfying unknown safety definition, and scalable to various continuous control tasks.", 'abstract_zh': '在安全强化学习中，辅助安全成本用于使智能体进行安全决策。由于安全约束、成本函数和预算在实践中往往是未知的或难以具体化，需要预测所有可能的不安全行为，我们因此提出了一种通用框架，其中真正的安全定义是未知的，并需要从稀疏标注的数据中学习。我们的主要贡献包括：首先，设计了一个安全模型来为每个决策步骤对整体安全的影响进行归因估计，使用多样轨迹及其相应的二元安全标签（即对应轨迹是否安全/不安全）的数据集。其次，展示了安全模型的架构，证明其能够为每个时间步学习一个独立的安全评分。第三，使用提出的安全模型重新表述安全强化学习问题，并推导出一种有效算法来优化安全且具有奖励性的策略。最后，我们的实证结果验证了这些发现，并展示了该方法有效满足未知的安全定义，并适用于各种连续控制任务。', 'title_zh': 'TraCeS: 基于轨迹的安全反馈稀疏信用分配'}
{'arxiv_id': 'arXiv:2504.12552', 'title': 'Privacy-Preserving Operating Room Workflow Analysis using Digital Twins', 'authors': 'Alejandra Perez, Han Zhang, Yu-Chun Ku, Lalithkumar Seenivasan, Roger Soberanis, Jose L. Porras, Richard Day, Jeff Jopling, Peter Najjar, Mathias Unberath', 'link': 'https://arxiv.org/abs/2504.12552', 'abstract': 'Purpose: The operating room (OR) is a complex environment where optimizing workflows is critical to reduce costs and improve patient outcomes. The use of computer vision approaches for the automatic recognition of perioperative events enables identification of bottlenecks for OR optimization. However, privacy concerns limit the use of computer vision for automated event detection from OR videos, which makes privacy-preserving approaches needed for OR workflow analysis. Methods: We propose a two-stage pipeline for privacy-preserving OR video analysis and event detection. In the first stage, we leverage vision foundation models for depth estimation and semantic segmentation to generate de-identified Digital Twins (DT) of the OR from conventional RGB videos. In the second stage, we employ the SafeOR model, a fused two-stream approach that processes segmentation masks and depth maps for OR event detection. We evaluate this method on an internal dataset of 38 simulated surgical trials with five event classes. Results: Our results indicate that this DT-based approach to the OR event detection model achieves performance on par and sometimes even better than raw RGB video-based models on detecting OR events. Conclusion: DTs enable privacy-preserving OR workflow analysis, facilitating the sharing of de-identified data across institutions and they can potentially enhance model generalizability by mitigating domain-specific appearance differences.', 'abstract_zh': '目的：手术室（OR）是一个复杂的工作环境，优化工作流程对于降低成本和改善患者结局至关重要。使用计算机视觉方法自动识别围手术期事件能够识别OR优化中的瓶颈。然而，隐私问题限制了计算机视觉在OR视频自动事件检测中的应用，因此需要隐私保护的方法来分析OR工作流程。方法：我们提出了一种两阶段的隐私保护OR视频分析和事件检测管道。在第一阶段，我们利用视觉基础模型进行深度估计和语义分割，从传统RGB视频中生成匿名的数字孪生（DT）模拟OR。在第二阶段，我们采用了SafeOR模型，这是一种融合了两流的方法，处理分割掩码和深度图进行OR事件检测。我们对该方法在包含38场模拟手术试验的内部数据集上，针对五个事件类进行了评估。结果：结果显示，基于DT的方法在检测OR事件方面与其他基于原始RGB视频的方法具有相当甚至更好的性能。结论：DT使隐私保护的OR工作流程分析成为可能，促进了机构间去识别数据的共享，并有可能通过缓解领域特定外观差异来增强模型的泛化能力。', 'title_zh': '基于数字孪生的隐私保护手术室工作流程分析'}
{'arxiv_id': 'arXiv:2504.12549', 'title': 'Memorization: A Close Look at Books', 'authors': 'Iris Ma, Ian Domingo, Alberto Krone-Martins, Pierre Baldi, Cristina V. Lopes', 'link': 'https://arxiv.org/abs/2504.12549', 'abstract': 'To what extent can entire books be extracted from LLMs? Using the Llama 3 70B family of models, and the "prefix-prompting" extraction technique, we were able to auto-regressively reconstruct, with a very high level of similarity, one entire book (Alice\'s Adventures in Wonderland) from just the first 500 tokens. We were also able to obtain high extraction rates on several other books, piece-wise. However, these successes do not extend uniformly to all books. We show that extraction rates of books correlate with book popularity and thus, likely duplication in the training data.\nWe also confirm the undoing of mitigations in the instruction-tuned Llama 3.1, following recent work (Nasr et al., 2025). We further find that this undoing comes from changes to only a tiny fraction of weights concentrated primarily in the lower transformer blocks. Our results provide evidence of the limits of current regurgitation mitigation strategies and introduce a framework for studying how fine-tuning affects the retrieval of verbatim memorization in aligned LLMs.', 'abstract_zh': 'entire书籍从LLMs中提取的限度：使用Llama 3 70B家族模型和“前缀提示”提取技术，我们仅从最初的500个令牌自回归地重建了一整本书（《爱丽丝梦游仙境》），相似度非常高。我们还能够在其他几本书上获得较高的提取率，逐步进行。然而，这些成功并不均匀地适用于所有书籍。我们展示了书籍的提取率与书籍的流行度相关，因此很可能与训练数据中的重复有关。我们还确认了针对指令微调的Llama 3.1中的缓解措施已失效，这一发现与近期工作相符（Nasr等，2025）。我们进一步发现这种失效源于仅一小部分权重的变化，主要集中在较低的变换器块中。我们的结果提供了当前重温缓解策略局限性的证据，并引入了一种研究微调如何影响对齐LLMs中逐字记忆检索的框架。', 'title_zh': '记忆化：对书籍的一次深入审视'}
{'arxiv_id': 'arXiv:2504.12546', 'title': 'Anonymous Public Announcements', 'authors': 'Thomas Ågotnes, Rustam Galimullin, Ken Satoh, Satoshi Tojo', 'link': 'https://arxiv.org/abs/2504.12546', 'abstract': 'We formalise the notion of an \\emph{anonymous public announcement} in the tradition of public announcement logic. Such announcements can be seen as in-between a public announcement from ``the outside" (an announcement of $\\phi$) and a public announcement by one of the agents (an announcement of $K_a\\phi$): we get more information than just $\\phi$, but not (necessarily) about exactly who made it. Even if such an announcement is prima facie anonymous, depending on the background knowledge of the agents it might reveal the identity of the announcer: if I post something on a message board, the information might reveal who I am even if I don\'t sign my name. Furthermore, like in the Russian Cards puzzle, if we assume that the announcer\'s intention was to stay anonymous, that in fact might reveal more information. In this paper we first look at the case when no assumption about intentions are made, in which case the logic with an anonymous public announcement operator is reducible to epistemic logic. We then look at the case when we assume common knowledge of the intention to stay anonymous, which is both more complex and more interesting: in several ways it boils down to the notion of a ``safe" announcement (again, similarly to Russian Cards). Main results include formal expressivity results and axiomatic completeness for key logical languages.', 'abstract_zh': '我们形式化了公佈論文中匿名公佈的概念。这样的公佈可以被视为介于外部公佈（宣布$\\phi$）和一个代理进行的公佈（宣布$K_a\\phi$）之间的一种形式：我们获得的信息不仅包括$\\phi$，但不一定具体知道是谁提供的。即使这样的公佈看似匿名，根据代理的背景知识，它可能会揭示信息发布者的身份：例如，我在留言板上发布信息，即使我没有签名，信息也可能透露出我的身份。此外，类似于俄罗斯扑克牌谜题的情况，如果假设信息发布者意图保持匿名，这实际上可能会泄露更多信息。在本文中，我们首先考虑没有假设意图的情况，在这种情况下，带有匿名公佈操作符的逻辑可以归约为知识逻辑。然后我们考虑假设共同知道意图保持匿名的情况，这既更复杂也更有趣：在多个方面都涉及“安全”公佈的概念（再次类似于俄罗斯扑克牌谜题）。主要结果包括对关键逻辑语言的形式表达能力和公理完全性结果。', 'title_zh': '匿名公共公告'}
{'arxiv_id': 'arXiv:2504.12545', 'title': 'Knowledge Acquisition on Mass-shooting Events via LLMs for AI-Driven Justice', 'authors': 'Benign John Ihugba, Afsana Nasrin, Ling Wu, Lin Li, Lijun Qian, Xishuang Dong', 'link': 'https://arxiv.org/abs/2504.12545', 'abstract': 'Mass-shooting events pose a significant challenge to public safety, generating large volumes of unstructured textual data that hinder effective investigations and the formulation of public policy. Despite the urgency, few prior studies have effectively automated the extraction of key information from these events to support legal and investigative efforts. This paper presented the first dataset designed for knowledge acquisition on mass-shooting events through the application of named entity recognition (NER) techniques. It focuses on identifying key entities such as offenders, victims, locations, and criminal instruments, that are vital for legal and investigative purposes. The NER process is powered by Large Language Models (LLMs) using few-shot prompting, facilitating the efficient extraction and organization of critical information from diverse sources, including news articles, police reports, and social media. Experimental results on real-world mass-shooting corpora demonstrate that GPT-4o is the most effective model for mass-shooting NER, achieving the highest Micro Precision, Micro Recall, and Micro F1-scores. Meanwhile, o1-mini delivers competitive performance, making it a resource-efficient alternative for less complex NER tasks. It is also observed that increasing the shot count enhances the performance of all models, but the gains are more substantial for GPT-4o and o1-mini, highlighting their superior adaptability to few-shot learning scenarios.', 'abstract_zh': '大规模枪击事件对公共安全构成重大挑战，生成了大量未结构化的文本数据，阻碍了有效调查和公共政策的制定。尽管情况紧迫，但很少有先前的研究能够有效地自动提取这些事件中的关键信息以支持法律和调查努力。本文介绍了首个通过命名实体识别（NER）技术设计的数据集，旨在通过知识获取大规模枪击事件的相关信息。该研究专注于识别对于法律和调查目的至关重要的实体，如作案者、受害者、地点和犯罪工具。NER过程由大型语言模型（LLMs）通过少量示例提示驱动，有助于从包括新闻文章、警方报告和社交媒体在内的多种来源中高效提取和组织关键信息。在实际大规模枪击事件语料库上的实验结果表明，GPT-4o是最有效的模型，实现了最高的宏精确度、宏召回率和宏F1分数。同时，o1-mini表现出竞争力，使其成为一个资源高效的替代方案，适用于较简单的NER任务。观察到增加示例数量可以提高所有模型的表现，但增幅对于GPT-4o和o1-mini更为显著，突显了它们在少量示例学习场景中的优越适应性。', 'title_zh': '基于大规模语言模型的knowledge acquisition on mass-shooting events for AI-driven justice'}
{'arxiv_id': 'arXiv:2504.12535', 'title': 'Decision-based AI Visual Navigation for Cardiac Ultrasounds', 'authors': 'Andy Dimnaku, Dominic Yurk, Zhiyuan Gao, Arun Padmanabhan, Mandar Aras, Yaser Abu-Mostafa', 'link': 'https://arxiv.org/abs/2504.12535', 'abstract': 'Ultrasound imaging of the heart (echocardiography) is widely used to diagnose cardiac diseases. However, obtaining an echocardiogram requires an expert sonographer and a high-quality ultrasound imaging device, which are generally only available in hospitals. Recently, AI-based navigation models and algorithms have been used to aid novice sonographers in acquiring the standardized cardiac views necessary to visualize potential disease pathologies. These navigation systems typically rely on directional guidance to predict the necessary rotation of the ultrasound probe. This paper demonstrates a novel AI navigation system that builds on a decision model for identifying the inferior vena cava (IVC) of the heart. The decision model is trained offline using cardiac ultrasound videos and employs binary classification to determine whether the IVC is present in a given ultrasound video. The underlying model integrates a novel localization algorithm that leverages the learned feature representations to annotate the spatial location of the IVC in real-time. Our model demonstrates strong localization performance on traditional high-quality hospital ultrasound videos, as well as impressive zero-shot performance on lower-quality ultrasound videos from a more affordable Butterfly iQ handheld ultrasound machine. This capability facilitates the expansion of ultrasound diagnostics beyond hospital settings. Currently, the guidance system is undergoing clinical trials and is available on the Butterfly iQ app.', 'abstract_zh': '基于AI的心脏超声成像导航系统：识别下腔静脉的新颖决策模型与应用', 'title_zh': '基于决策的AI视觉导航心血管超声'}
{'arxiv_id': 'arXiv:2504.12532', 'title': 'Generalization through variance: how noise shapes inductive biases in diffusion models', 'authors': 'John J. Vastola', 'link': 'https://arxiv.org/abs/2504.12532', 'abstract': "How diffusion models generalize beyond their training set is not known, and is somewhat mysterious given two facts: the optimum of the denoising score matching (DSM) objective usually used to train diffusion models is the score function of the training distribution; and the networks usually used to learn the score function are expressive enough to learn this score to high accuracy. We claim that a certain feature of the DSM objective -- the fact that its target is not the training distribution's score, but a noisy quantity only equal to it in expectation -- strongly impacts whether and to what extent diffusion models generalize. In this paper, we develop a mathematical theory that partly explains this 'generalization through variance' phenomenon. Our theoretical analysis exploits a physics-inspired path integral approach to compute the distributions typically learned by a few paradigmatic under- and overparameterized diffusion models. We find that the distributions diffusion models effectively learn to sample from resemble their training distributions, but with 'gaps' filled in, and that this inductive bias is due to the covariance structure of the noisy target used during training. We also characterize how this inductive bias interacts with feature-related inductive biases.", 'abstract_zh': '扩散模型如何泛化到训练集之外还尚未可知，这基于两点事实显得尤为神秘：用于训练扩散模型的去噪评分匹配（DSM）目标函数的最优值通常是训练分布的评分函数；通常用于学习评分函数的网络具有足够的表达能力，能够高精度地学习这一评分函数。我们主张，DSM目标函数的一项特定特征——其目标不是训练分布的评分函数，而是一个仅在期望意义下等于评分函数的噪声量——强烈影响扩散模型泛化的程度和范围。在本文中，我们发展了部分解释这种“通过方差泛化”现象的数学理论。我们的理论分析利用了一种受物理启发的路径积分方法，计算了几种范型的欠参数化和过参数化扩散模型通常学习到的分布。我们发现，扩散模型有效地学习到的分布类似于其训练分布，但填充了“空缺”，这种归纳偏见是由于训练过程中使用的噪声目标的协方差结构。我们还分析了这种归纳偏见与特征相关归纳偏见的相互作用。', 'title_zh': '通过方差的一般化：噪声如何塑造扩散模型的归纳偏置'}
{'arxiv_id': 'arXiv:2504.12526', 'title': 'MOM: Memory-Efficient Offloaded Mini-Sequence Inference for Long Context Language Models', 'authors': 'Junyang Zhang, Tianyi Zhu, Cheng Luo, Anima Anandkumar', 'link': 'https://arxiv.org/abs/2504.12526', 'abstract': 'Long-context language models exhibit impressive performance but remain challenging to deploy due to high GPU memory demands during inference. We propose Memory-efficient Offloaded Mini-sequence Inference (MOM), a method that partitions critical layers into smaller "mini-sequences" and integrates seamlessly with KV cache offloading. Experiments on various Llama, Qwen, and Mistral models demonstrate that MOM reduces peak memory usage by over 50\\% on average. On Meta-Llama-3.2-8B, MOM extends the maximum context length from 155k to 455k tokens on a single A100 80GB GPU, while keeping outputs identical and not compromising accuracy. MOM also maintains highly competitive throughput due to minimal computational overhead and efficient last-layer processing. Compared to traditional chunked prefill methods, MOM achieves a 35\\% greater context length extension. More importantly, our method drastically reduces prefill memory consumption, eliminating it as the longstanding dominant memory bottleneck during inference. This breakthrough fundamentally changes research priorities, redirecting future efforts from prefill-stage optimizations to improving decode-stage residual KV cache efficiency.', 'abstract_zh': '长上下文语言模型表现出色但因推理过程中高GPU内存需求仍难以部署。我们提出了一种名为Memory-efficient Offloaded Mini-sequence Inference (MOM)的方法，该方法将关键层划分为较小的“迷你序列”，并无缝集成到KV缓存卸载中。对Llama、Qwen和Mistral等多种模型的实验表明，MOM平均将峰值内存使用量减少超过50%。在单块A100 80GB GPU上，MOM将Meta-Llama-3.2-8B的最大上下文长度从155k扩展到455k令牌，同时保持输出一致且不损害准确性。MOM还由于计算开销极小和高效的最后一层处理而保持了高度竞争力的吞吐量。与传统的分块预填充方法相比，MOM实现了35%更长的上下文长度扩展。更重要的是，我们的方法极大减少了预填充内存消耗，消除了推理过程中长期存在的主要内存瓶颈。这一突破从根本上改变了研究优先级，将未来的努力从预填充阶段优化转向提高解码阶段剩余KV缓存效率。', 'title_zh': 'MOM: 记忆高效卸载的小序列推理 for 长上下文语言模型'}
{'arxiv_id': 'arXiv:2504.12523', 'title': 'Memorization vs. Reasoning: Updating LLMs with New Knowledge', 'authors': 'Aochong Oliver Li, Tanya Goyal', 'link': 'https://arxiv.org/abs/2504.12523', 'abstract': 'Large language models (LLMs) encode vast amounts of pre-trained knowledge in their parameters, but updating them as real-world information evolves remains a challenge. Existing methodologies and benchmarks primarily target entity substitutions, failing to capture the full breadth of complex real-world dynamics. In this paper, we introduce Knowledge Update Playground (KUP), an automatic pipeline for simulating realistic knowledge updates reflected in an evidence corpora. KUP\'s evaluation framework includes direct and indirect probes to both test memorization of updated facts and reasoning over them, for any update learning methods. Next, we present a lightweight method called memory conditioned training (MCT), which conditions tokens in the update corpus on self-generated "memory" tokens during training. Our strategy encourages LLMs to surface and reason over newly memorized knowledge at inference. Our results on two strong LLMs show that (1) KUP benchmark is highly challenging, with the best CPT models achieving $<2\\%$ in indirect probing setting (reasoning) and (2) MCT training significantly outperforms prior continued pre-training (CPT) baselines, improving direct probing (memorization) results by up to $25.4\\%$.', 'abstract_zh': '大规模语言模型（LLMs）在其参数中编码了大量的预训练知识，但随着现实世界信息的发展更新它们仍然充满挑战。现有方法和基准主要针对实体替换，未能捕捉复杂现实世界动态的全貌。本文我们提出了知识更新游乐场（KUP），这是一种自动模拟证据库中反映的真实知识更新的管道。KUP的评估框架包括直接和间接探针，以测试更新事实的记忆和推理，适用于任何更新学习方法。随后，我们提出了一种轻量级方法——基于记忆训练（MCT），该方法在训练期间将更新语料中的标记条件化为自我生成的“记忆”标记。我们的策略鼓励LLMs在推理时表面并推理最新的记忆知识。我们在两个强大的LLM上的结果表明：（1）KUP基准极具挑战性，最佳CPT模型在间接探针（推理）设置下的表现低于2%；（2）基于记忆训练显著优于先前连续预训练（CPT）基线，直接探针（记忆）结果提高了高达25.4%。', 'title_zh': '记忆与推理：用新知识更新大语言模型'}
{'arxiv_id': 'arXiv:2504.12522', 'title': 'Evaluating the Diversity and Quality of LLM Generated Content', 'authors': 'Alexander Shypula, Shuo Li, Botong Zhang, Vishakh Padmakumar, Kayo Yin, Osbert Bastani', 'link': 'https://arxiv.org/abs/2504.12522', 'abstract': 'Recent work suggests that preference-tuning techniques--including Reinforcement Learning from Human Preferences (RLHF) methods like PPO and GRPO, as well as alternatives like DPO--reduce diversity, creating a dilemma given that such models are widely deployed in applications requiring diverse outputs. To address this, we introduce a framework for measuring effective semantic diversity--diversity among outputs that meet quality thresholds--which better reflects the practical utility of large language models (LLMs). Using open-ended tasks that require no human intervention, we find counterintuitive results: although preference-tuned models--especially those trained via RL--exhibit reduced lexical and syntactic diversity, they produce greater effective semantic diversity than SFT or base models, not from increasing diversity among high-quality outputs, but from generating more high-quality outputs overall. We discover that preference tuning reduces syntactic diversity while preserving semantic diversity--revealing a distinction between diversity in form and diversity in content that traditional metrics often overlook. Our analysis further shows that smaller models are consistently more parameter-efficient at generating unique content within a fixed sampling budget, offering insights into the relationship between model scaling and diversity. These findings have important implications for applications that require diverse yet high-quality outputs, from creative assistance to synthetic data generation.', 'abstract_zh': '最近的研究表明，偏好调优技术——包括强化学习从人类偏好中学习（RLHF）方法如PPO和GRPO，以及替代方法DPO——会降低模型的多样性，这给已经在要求多样化输出的应用中广泛部署的模型带来了困境。为了解决这一问题，我们提出了一个衡量有效语义多样性的框架——即满足质量阈值的输出之间的多样性——这更好地反映了大型语言模型（LLMs）的实际应用价值。通过无需人类干预的开放任务，我们发现了反直觉的结果：尽管偏好调优模型（尤其是通过RL训练的模型）显示出降低的词汇和句法多样性，但它们产生的有效语义多样性大于SFT或基础模型，这是由于总体上生成了更多高质量的输出，而不是高質量输出之间的多样性增加。我们发现偏好调优减少了句法多样性的同时保持了语义多样性——揭示了形式多样性和内容多样性的区别，这是传统度量往往忽视的。进一步的分析表明，较小的模型在固定采样预算下生成独特内容方面始终具有更高的参数效率，为我们理解模型缩放与多样性之间的关系提供了见解。这些发现对需要多样化且高质量输出的应用具有重要影响，包括创意辅助和合成数据生成等领域。', 'title_zh': '评估大型语言模型生成内容的多样性和质量'}
{'arxiv_id': 'arXiv:2504.12513', 'title': 'AdaVid: Adaptive Video-Language Pretraining', 'authors': 'Chaitanya Patel, Juan Carlos Niebles, Ehsan Adeli', 'link': 'https://arxiv.org/abs/2504.12513', 'abstract': 'Contrastive video-language pretraining has demonstrated great success in learning rich and robust video representations. However, deploying such video encoders on compute-constrained edge devices remains challenging due to their high computational demands. Additionally, existing models are typically trained to process only short video clips, often limited to 4 to 64 frames. In this paper, we introduce AdaVid, a flexible architectural framework designed to learn efficient video encoders that can dynamically adapt their computational footprint based on available resources. At the heart of AdaVid is an adaptive transformer block, inspired by Matryoshka Representation Learning, which allows the model to adjust its hidden embedding dimension at inference time. We show that AdaVid-EgoVLP, trained on video-narration pairs from the large-scale Ego4D dataset, matches the performance of the standard EgoVLP on short video-language benchmarks using only half the compute, and even outperforms EgoVLP when given equal computational resources. We further explore the trade-off between frame count and compute on the challenging Diving48 classification benchmark, showing that AdaVid enables the use of more frames without exceeding computational limits. To handle longer videos, we also propose a lightweight hierarchical network that aggregates short clip features, achieving a strong balance between compute efficiency and accuracy across several long video benchmarks.', 'abstract_zh': '自适应视频编码器学习的对比视频-语言预训练在学习丰富的稳健视频表示方面取得了巨大成功。然而，由于其高计算需求，在计算资源受限的边缘设备上部署这些视频编码器仍然具有挑战性。此外，现有模型通常仅限于处理长度较短的视频片段，通常仅限于4到64帧。在本文中，我们引入了AdaVid，一个灵活的架构框架，设计用于学习高效的视频编码器，可根据可用资源动态调整其计算足迹。AdaVid的核心是一个受Matryoshka表示学习启发的自适应变压器块，在推断时允许模型调整其隐藏嵌入维度。我们证明，通过在大规模Ego4D数据集上的视频叙述对训练得到的AdaVid-EgoVLP，在使用一半计算资源的情况下，在短视频-语言基准测试上匹配标准EgoVLP的性能，并且在相同计算资源下甚至优于EgoVLP。我们还在具有挑战性的Diving48分类基准测试中探讨了帧数和计算之间的权衡，显示AdaVid使使用更多帧而不超过计算限制成为可能。为了处理更长的视频，我们还提出了一种轻量级的分层网络，它聚合短片段特征，在多个长视频基准测试中实现了计算效率和准确性的良好平衡。', 'title_zh': 'AdaVid：自适应视频-语言预训练'}
{'arxiv_id': 'arXiv:2504.12511', 'title': 'Multimodal LLM Augmented Reasoning for Interpretable Visual Perception Analysis', 'authors': 'Shravan Chaudhari, Trilokya Akula, Yoon Kim, Tom Blake', 'link': 'https://arxiv.org/abs/2504.12511', 'abstract': 'In this paper, we advance the study of AI-augmented reasoning in the context of Human-Computer Interaction (HCI), psychology and cognitive science, focusing on the critical task of visual perception. Specifically, we investigate the applicability of Multimodal Large Language Models (MLLMs) in this domain. To this end, we leverage established principles and explanations from psychology and cognitive science related to complexity in human visual perception. We use them as guiding principles for the MLLMs to compare and interprete visual content. Our study aims to benchmark MLLMs across various explainability principles relevant to visual perception. Unlike recent approaches that primarily employ advanced deep learning models to predict complexity metrics from visual content, our work does not seek to develop a mere new predictive model. Instead, we propose a novel annotation-free analytical framework to assess utility of MLLMs as cognitive assistants for HCI tasks, using visual perception as a case study. The primary goal is to pave the way for principled study in quantifying and evaluating the interpretability of MLLMs for applications in improving human reasoning capability and uncovering biases in existing perception datasets annotated by humans.', 'abstract_zh': '在人机交互(HCI)、心理学和认知科学的背景下推进人工智能增强推理的研究：基于多模态大型语言模型在视觉感知中的应用', 'title_zh': '多模态LLM增强的可解释视觉感知分析'}
{'arxiv_id': 'arXiv:2504.12503', 'title': 'Continual Learning Strategies for 3D Engineering Regression Problems: A Benchmarking Study', 'authors': 'Kaira M. Samuel, Faez Ahmed', 'link': 'https://arxiv.org/abs/2504.12503', 'abstract': 'Engineering problems that apply machine learning often involve computationally intensive methods but rely on limited datasets. As engineering data evolves with new designs and constraints, models must incorporate new knowledge over time. However, high computational costs make retraining models from scratch infeasible. Continual learning (CL) offers a promising solution by enabling models to learn from sequential data while mitigating catastrophic forgetting, where a model forgets previously learned mappings. This work introduces CL to engineering design by benchmarking several CL methods on representative regression tasks. We apply these strategies to five engineering datasets and construct nine new engineering CL benchmarks to evaluate their ability to address forgetting and improve generalization. Preliminary results show that applying existing CL methods to these tasks improves performance over naive baselines. In particular, the Replay strategy achieved performance comparable to retraining in several benchmarks while reducing training time by nearly half, demonstrating its potential for real-world engineering workflows. The code and datasets used in this work will be available at: this https URL.', 'abstract_zh': '工程设计中应用机器学习的问题往往涉及计算密集的方法但依赖于有限的数据集。随着新设计和约束条件的发展，工程数据不断演变，模型必须随着时间 Incorporate 新知识。然而，高昂的计算成本使得从头开始重新训练模型在实际中不可行。连续学习（CL）通过使模型能够在不遗忘之前学得的知识的情况下学习序列数据，提供了一种有前景的解决方案。本文通过在代表性的回归任务上对几种连续学习方法进行基准测试，将连续学习引入工程设计。我们将这些策略应用于五个工程数据集，并构建了九个新的工程连续学习基准，以评估它们在应对遗忘和提高泛化方面的能力。初步结果表明，将现有连续学习方法应用于这些任务能够提高性能，并且特定的重播策略在几个基准中实现了与从头训练相当的性能，同时将训练时间几乎减少了半数，展示了其在真实工程工作流中的潜力。本文所使用的代码和数据集将在此处提供：this https URL。', 'title_zh': '3D工程回归问题的持续学习策略：一项基准研究'}
{'arxiv_id': 'arXiv:2504.12488', 'title': 'Co-Writing with AI, on Human Terms: Aligning Research with User Demands Across the Writing Process', 'authors': 'Mohi Reza, Jeb Thomas-Mitchell, Peter Dushniku, Nathan Laundry, Joseph Jay Williams, Anastasia Kuzminykh', 'link': 'https://arxiv.org/abs/2504.12488', 'abstract': "As generative AI tools like ChatGPT become integral to everyday writing, critical questions arise about how to preserve writers' sense of agency and ownership when using these tools. Yet, a systematic understanding of how AI assistance affects different aspects of the writing process - and how this shapes writers' agency - remains underexplored. To address this gap, we conducted a systematic review of 109 HCI papers using the PRISMA approach. From this literature, we identify four overarching design strategies for AI writing support: structured guidance, guided exploration, active co-writing, and critical feedback - mapped across the four key cognitive processes in writing: planning, translating, reviewing, and monitoring. We complement this analysis with interviews of 15 writers across diverse domains. Our findings reveal that writers' desired levels of AI intervention vary across the writing process: content-focused writers (e.g., academics) prioritize ownership during planning, while form-focused writers (e.g., creatives) value control over translating and reviewing. Writers' preferences are also shaped by contextual goals, values, and notions of originality and authorship. By examining when ownership matters, what writers want to own, and how AI interactions shape agency, we surface both alignment and gaps between research and user needs. Our findings offer actionable design guidance for developing human-centered writing tools for co-writing with AI, on human terms.", 'abstract_zh': '随着生成AI工具如ChatGPT成为日常写作不可或缺的部分，关键问题是如何在使用这些工具时保持写作者的能动性和所有权感。然而，关于AI辅助如何影响写作过程的不同方面以及这对写作者能动性的影响的系统性理解仍显得不足。为填补这一空白，我们采用PRISMA方法系统回顾了109篇人机交互（HCI）论文。从这些文献中，我们识别出四种总体设计策略，用于支持AI写作：结构化指导、引导探索、协作写作和批判性反馈，这些策略映射到写作的四个关键认知过程：规划、翻译、审阅和监控。我们还通过采访来自不同领域的15名写作者，补充了这一分析。研究表明，写作者希望在写作过程中的AI介入程度各不相同：内容导向的写作者（如学术人员）在规划阶段更重视所有权，而形式导向的写作者（如创意人员）在翻译和审阅阶段更重视控制权。写作者的偏好还受到其背景目标、价值观以及原创性和作者身份观念的影响。通过对何时所有权至关重要、写作者希望保留哪些方面以及AI互动如何塑造能动性进行考察，我们揭示了研究与用户需求之间的契合点和差距。我们的研究结果提供了关于如何根据人类需求开发兼顾人类视角的AI辅助写作工具的实用设计指导。', 'title_zh': '基于人类视角与AI共写：在整个写作过程中满足用户需求的研究对接'}
{'arxiv_id': 'arXiv:2504.12476', 'title': 'What do people expect from Artificial Intelligence? Public opinion on alignment in AI moderation from Germany and the United States', 'authors': 'Andreas Jungherr, Adrian Rauchfleisch', 'link': 'https://arxiv.org/abs/2504.12476', 'abstract': 'Recent advances in generative Artificial Intelligence have raised public awareness, shaping expectations and concerns about their societal implications. Central to these debates is the question of AI alignment -- how well AI systems meet public expectations regarding safety, fairness, and social values. However, little is known about what people expect from AI-enabled systems and how these expectations differ across national contexts. We present evidence from two surveys of public preferences for key functional features of AI-enabled systems in Germany (n = 1800) and the United States (n = 1756). We examine support for four types of alignment in AI moderation: accuracy and reliability, safety, bias mitigation, and the promotion of aspirational imaginaries. U.S. respondents report significantly higher AI use and consistently greater support for all alignment features, reflecting broader technological openness and higher societal involvement with AI. In both countries, accuracy and safety enjoy the strongest support, while more normatively charged goals -- like fairness and aspirational imaginaries -- receive more cautious backing, particularly in Germany. We also explore how individual experience with AI, attitudes toward free speech, political ideology, partisan affiliation, and gender shape these preferences. AI use and free speech support explain more variation in Germany. In contrast, U.S. responses show greater attitudinal uniformity, suggesting that higher exposure to AI may consolidate public expectations. These findings contribute to debates on AI governance and cross-national variation in public preferences. More broadly, our study demonstrates the value of empirically grounding AI alignment debates in public attitudes and of explicitly developing normatively grounded expectations into theoretical and policy discussions on the governance of AI-generated content.', 'abstract_zh': 'Recent Advances in Generative Artificial Intelligence Have Raised Public Awareness, Shaping Expectations and Concerns about Their Societal Implications: Evidence from Surveys in Germany and the United States', 'title_zh': '人们期望的人工智能是什么？来自德国和美国的公众意见关于AI内容审核的对齐观点'}
{'arxiv_id': 'arXiv:2504.12474', 'title': 'Integrating Structural and Semantic Signals in Text-Attributed Graphs with BiGTex', 'authors': 'Azadeh Beiranvand, Seyed Mehdi Vahidipour', 'link': 'https://arxiv.org/abs/2504.12474', 'abstract': "Text-attributed graphs (TAGs) present unique challenges in representation learning by requiring models to capture both the semantic richness of node-associated texts and the structural dependencies of the graph. While graph neural networks (GNNs) excel at modeling topological information, they lack the capacity to process unstructured text. Conversely, large language models (LLMs) are proficient in text understanding but are typically unaware of graph structure. In this work, we propose BiGTex (Bidirectional Graph Text), a novel architecture that tightly integrates GNNs and LLMs through stacked Graph-Text Fusion Units. Each unit allows for mutual attention between textual and structural representations, enabling information to flow in both directions, text influencing structure and structure guiding textual interpretation. The proposed architecture is trained using parameter-efficient fine-tuning (LoRA), keeping the LLM frozen while adapting to task-specific signals. Extensive experiments on five benchmark datasets demonstrate that BiGTex achieves state-of-the-art performance in node classification and generalizes effectively to link prediction. An ablation study further highlights the importance of soft prompting and bi-directional attention in the model's success.", 'abstract_zh': '基于文本的图（Text-attributed Graphs, TAGs）在表示学习中提出了独特挑战，要求模型同时捕捉节点关联文本的语义丰富性和图的结构依赖性。尽管图神经网络（GNNs）在建模拓扑信息方面表现出色，但它们缺乏处理未结构化文本的能力。相比之下，大型语言模型（LLMs）在文本理解方面表现出色，但通常不了解图结构。在本工作中，我们提出了一种名为BiGTex（双向图文本）的新型架构，该架构通过堆叠图-文本融合单元，紧密整合了GNNs和LLMs。每个单元允许文本表示和结构表示之间的相互注意力，使得信息可以在两个方向流动：文本影响结构，结构指导文本解释。所提出的架构通过参数高效微调（LoRA）进行训练，保持LLM冻结状态，同时适应特定任务信号。在五个基准数据集上的广泛实验表明，BiGTex在节点分类任务中达到了最先进的性能，并且在链接预测任务上具有良好的泛化能力。进一步的消融研究强调了软提示和双向注意力对于模型成功的重要性。', 'title_zh': '在Text-Attributed图中结合结构和语义信号的BiGTex方法'}
{'arxiv_id': 'arXiv:2504.12463', 'title': 'Dense Backpropagation Improves Training for Sparse Mixture-of-Experts', 'authors': 'Ashwinee Panda, Vatsal Baherwani, Zain Sarwar, Benjamin Therien, Supriyo Chakraborty, Tom Goldstein', 'link': 'https://arxiv.org/abs/2504.12463', 'abstract': 'Mixture of Experts (MoE) pretraining is more scalable than dense Transformer pretraining, because MoEs learn to route inputs to a sparse set of their feedforward parameters. However, this means that MoEs only receive a sparse backward update, leading to training instability and suboptimal performance. We present a lightweight approximation method that gives the MoE router a dense gradient update while continuing to sparsely activate its parameters. Our method, which we refer to as Default MoE, substitutes missing expert activations with default outputs consisting of an exponential moving average of expert outputs previously seen over the course of training. This allows the router to receive signals from every expert for each token, leading to significant improvements in training performance. Our Default MoE outperforms standard TopK routing in a variety of settings without requiring significant computational overhead. Code: this https URL.', 'abstract_zh': 'Mixture of Experts (MoE) 预训练比密集Transformer预训练更具可扩展性，因为MoE学习将输入路由到其前向参数的稀疏子集。然而，这意味着MoE只接收稀疏的反向更新，导致培训不稳定和性能不佳。我们提出了一种轻量级近似方法，该方法为MoE路由器提供密集梯度更新，同时继续稀疏激活其参数。我们称之为Default MoE的方法用默认输出替代缺失的专家激活，该默认输出为训练过程中先前见过的专家输出的指数移动平均值。这使得路由器能够为每个令牌从每个专家接收信号，从而显著提高训练性能。Default MoE在各种设置中优于标准TopK路由，且无需显著增加计算开销。代码：this https URL。', 'title_zh': '稠密反向传播有助于稀疏混合专家模型的训练'}
{'arxiv_id': 'arXiv:2504.12459', 'title': 'On Linear Representations and Pretraining Data Frequency in Language Models', 'authors': 'Jack Merullo, Noah A. Smith, Sarah Wiegreffe, Yanai Elazar', 'link': 'https://arxiv.org/abs/2504.12459', 'abstract': "Pretraining data has a direct impact on the behaviors and quality of language models (LMs), but we only understand the most basic principles of this relationship. While most work focuses on pretraining data's effect on downstream task behavior, we investigate its relationship to LM representations. Previous work has discovered that, in language models, some concepts are encoded `linearly' in the representations, but what factors cause these representations to form? We study the connection between pretraining data frequency and models' linear representations of factual relations. We find evidence that the formation of linear representations is strongly connected to pretraining term frequencies; specifically for subject-relation-object fact triplets, both subject-object co-occurrence frequency and in-context learning accuracy for the relation are highly correlated with linear representations. This is the case across all phases of pretraining. In OLMo-7B and GPT-J, we discover that a linear representation consistently (but not exclusively) forms when the subjects and objects within a relation co-occur at least 1k and 2k times, respectively, regardless of when these occurrences happen during pretraining. Finally, we train a regression model on measurements of linear representation quality in fully-trained LMs that can predict how often a term was seen in pretraining. Our model achieves low error even on inputs from a different model with a different pretraining dataset, providing a new method for estimating properties of the otherwise-unknown training data of closed-data models. We conclude that the strength of linear representations in LMs contains signal about the models' pretraining corpora that may provide new avenues for controlling and improving model behavior: particularly, manipulating the models' training data to meet specific frequency thresholds.", 'abstract_zh': '预训练数据对语言模型的行为和质量有直接影响，但我们仅理解其关系的基本原理。尽管大多数工作关注预训练数据对下游任务行为的影响，我们探讨了其与语言模型表示之间的关系。先前的研究发现，某些概念在语言模型中以“线性”方式编码在表示中，但这些表示是如何形成的呢？我们研究了预训练数据频率与模型对事实关系的线性表示之间的联系。我们发现证据表明，线性表示的形成与预训练词频强烈相关；特别是对于主语-关系-宾语事实 triplet，主语-宾语共现频率以及关系的上下文学习准确率与线性表示高度相关。这一结论适用于预训练的所有阶段。在 OLMo-7B 和 GPT-J 中，我们发现当关系中的主语和宾语分别共现至少 1000 和 2000 次时，会一致（但非唯一）形成线性表示，无论这些共现发生在预训练的哪个阶段。最后，我们在完全训练的语言模型的线性表示质量测量上训练了一个回归模型，该模型可以预测该术语在预训练中出现的频率。我们的模型即使在来自不同模型和不同预训练数据集的输入上也能实现低误差，为估计封闭数据模型的训练数据属性提供了一种新方法。我们得出结论，语言模型中线性表示的强度包含了有关模型预训练语料库的信号，这可能为控制和改进模型行为提供新的途径：特别是，通过调整模型的训练数据来满足特定的频率阈值。', 'title_zh': '语言模型中线性表示与预训练数据频率的研究'}
{'arxiv_id': 'arXiv:2504.12446', 'title': 'Deriving Equivalent Symbol-Based Decision Models from Feedforward Neural Networks', 'authors': 'Sebastian Seidel, Uwe M. Borghoff', 'link': 'https://arxiv.org/abs/2504.12446', 'abstract': 'Artificial intelligence (AI) has emerged as a transformative force across industries, driven by advances in deep learning and natural language processing, and fueled by large-scale data and computing resources. Despite its rapid adoption, the opacity of AI systems poses significant challenges to trust and acceptance.\nThis work explores the intersection of connectionist and symbolic approaches to artificial intelligence, focusing on the derivation of interpretable symbolic models, such as decision trees, from feedforward neural networks (FNNs). Decision trees provide a transparent framework for elucidating the operations of neural networks while preserving their functionality. The derivation is presented in a step-by-step approach and illustrated with several examples. A systematic methodology is proposed to bridge neural and symbolic paradigms by exploiting distributed representations in FNNs to identify symbolic components, including fillers, roles, and their interrelationships. The process traces neuron activation values and input configurations across network layers, mapping activations and their underlying inputs to decision tree edges. The resulting symbolic structures effectively capture FNN decision processes and enable scalability to deeper networks through iterative refinement of subpaths for each hidden layer.\nTo validate the theoretical framework, a prototype was developed using Keras .h5-data and emulating TensorFlow within the Java JDK/JavaFX environment. This prototype demonstrates the feasibility of extracting symbolic representations from neural networks, enhancing trust in AI systems, and promoting accountability.', 'abstract_zh': '人工智能（AI）作为一种颠覆性的力量，在行业中的应用日益广泛，这一进展得益于深度学习和自然语言处理的进步，并依托于大规模的数据和计算资源。尽管AI的采用速度非常快，但其透明度不足给信任和接受带来了重大挑战。\n\n本文探讨了连接主义和符号主义在人工智能领域的交汇，重点关注从前馈神经网络（FNNs）中推导出可解释的符号模型，例如决策树。决策树为阐明神经网络的操作提供了一个透明的框架，同时保留了它们的功能性。该推导采用逐步方法，并通过示例进行说明。本文提出了一种系统的方法，通过利用FNN中的分布式表示来识别符号组件，包括填充项、角色及其相互关系，从而连接神经和符号范式。该过程追踪网络层中神经元激活值和输入配置的变化，将激活及其底层输入映射到决策树的边。由此产生的符号结构有效地捕获了FNN的决策过程，并通过逐层迭代改进子路径实现对更深层网络的扩展应用。\n\n为了验证理论框架，本文在Keras .h5数据和Java JDK/JavaFX环境中仿TensorFlow开发了一个原型。该原型展示了从神经网络中提取符号表示的可行性，增强了对AI系统的信任，并促进了问责制。', 'title_zh': '从前馈神经网络导出等效符号基础决策模型'}
{'arxiv_id': 'arXiv:2504.12436', 'title': 'Sparsity Outperforms Low-Rank Projections in Few-Shot Adaptation', 'authors': 'Nairouz Mrabah, Nicolas Richet, Ismail Ben Ayed, Éric Granger', 'link': 'https://arxiv.org/abs/2504.12436', 'abstract': 'Adapting Vision-Language Models (VLMs) to new domains with few labeled samples remains a significant challenge due to severe overfitting and computational constraints. State-of-the-art solutions, such as low-rank reparameterization, mitigate these issues but often struggle with generalization and require extensive hyperparameter tuning. In this paper, a novel Sparse Optimization (SO) framework is proposed. Unlike low-rank approaches that typically constrain updates to a fixed subspace, our SO method leverages high sparsity to dynamically adjust very few parameters. We introduce two key paradigms. First, we advocate for \\textit{local sparsity and global density}, which updates a minimal subset of parameters per iteration while maintaining overall model expressiveness. As a second paradigm, we advocate for \\textit{local randomness and global importance}, which sparsifies the gradient using random selection while pruning the first moment based on importance. This combination significantly mitigates overfitting and ensures stable adaptation in low-data regimes. Extensive experiments on 11 diverse datasets show that SO achieves state-of-the-art few-shot adaptation performance while reducing memory overhead.', 'abstract_zh': '适配新领域的小样本视觉-语言模型的稀疏优化框架', 'title_zh': '稀疏投影优于低秩投影在少量样本适应中的表现'}
{'arxiv_id': 'arXiv:2504.12427', 'title': 'Position: The Most Expensive Part of an LLM should be its Training Data', 'authors': 'Nikhil Kandpal, Colin Raffel', 'link': 'https://arxiv.org/abs/2504.12427', 'abstract': "Training a state-of-the-art Large Language Model (LLM) is an increasingly expensive endeavor due to growing computational, hardware, energy, and engineering demands. Yet, an often-overlooked (and seldom paid) expense is the human labor behind these models' training data. Every LLM is built on an unfathomable amount of human effort: trillions of carefully written words sourced from books, academic papers, codebases, social media, and more. This position paper aims to assign a monetary value to this labor and argues that the most expensive part of producing an LLM should be the compensation provided to training data producers for their work. To support this position, we study 64 LLMs released between 2016 and 2024, estimating what it would cost to pay people to produce their training datasets from scratch. Even under highly conservative estimates of wage rates, the costs of these models' training datasets are 10-1000 times larger than the costs to train the models themselves, representing a significant financial liability for LLM providers. In the face of the massive gap between the value of training data and the lack of compensation for its creation, we highlight and discuss research directions that could enable fairer practices in the future.", 'abstract_zh': '大型语言模型（LLM）训练的人力成本及其经济评估：一项立场论文', 'title_zh': '位置：对于LLM而言，其最昂贵的部分应该是训练数据。'}
{'arxiv_id': 'arXiv:2504.12424', 'title': "Don't Just Translate, Agitate: Using Large Language Models as Devil's Advocates for AI Explanations", 'authors': 'Ashley Suh, Kenneth Alperin, Harry Li, Steven R Gomez', 'link': 'https://arxiv.org/abs/2504.12424', 'abstract': "This position paper highlights a growing trend in Explainable AI (XAI) research where Large Language Models (LLMs) are used to translate outputs from explainability techniques, like feature-attribution weights, into a natural language explanation. While this approach may improve accessibility or readability for users, recent findings suggest that translating into human-like explanations does not necessarily enhance user understanding and may instead lead to overreliance on AI systems. When LLMs summarize XAI outputs without surfacing model limitations, uncertainties, or inconsistencies, they risk reinforcing the illusion of interpretability rather than fostering meaningful transparency. We argue that - instead of merely translating XAI outputs - LLMs should serve as constructive agitators, or devil's advocates, whose role is to actively interrogate AI explanations by presenting alternative interpretations, potential biases, training data limitations, and cases where the model's reasoning may break down. In this role, LLMs can facilitate users in engaging critically with AI systems and generated explanations, with the potential to reduce overreliance caused by misinterpreted or specious explanations.", 'abstract_zh': '这一立场论文强调了在可解释人工智能（XAI）研究中一种日益增长的趋势，即使用大规模语言模型（LLMs）将特征归因权重等解释技术的输出翻译成自然语言解释。虽然这种方法可能提高用户的易用性或可读性，但最近的研究发现，将解释翻译成人类似乎的解释并不一定会增强用户的理解，反而可能导致过度依赖人工智能系统。当LLMs在总结XAI输出时未能揭示模型的局限性、不确定性或不一致时，它们可能会强化可解释性的错觉，而不是促进实质性的透明度。我们主张，_LLMs不应仅仅翻译XAI输出_，而应作为建设性的搅局者或魔鬼的代言人，其角色是积极参与质疑人工智能的解释，提出替代解释、潜在偏见、训练数据的局限性以及模型推理可能失效的情况。在这种角色中，LLMs可以帮助用户批判性地参与人工智能系统及其生成的解释，从而减少由误解或站不住脚的解释导致的过度依赖。', 'title_zh': '不只是翻译，还要质疑：使用大型语言模型作为人工智能解释的对立面'}
{'arxiv_id': 'arXiv:2504.12422', 'title': 'Mitigating LLM Hallucinations with Knowledge Graphs: A Case Study', 'authors': 'Harry Li, Gabriel Appleby, Kenneth Alperin, Steven R Gomez, Ashley Suh', 'link': 'https://arxiv.org/abs/2504.12422', 'abstract': "High-stakes domains like cyber operations need responsible and trustworthy AI methods. While large language models (LLMs) are becoming increasingly popular in these domains, they still suffer from hallucinations. This research paper provides learning outcomes from a case study with LinkQ, an open-source natural language interface that was developed to combat hallucinations by forcing an LLM to query a knowledge graph (KG) for ground-truth data during question-answering (QA). We conduct a quantitative evaluation of LinkQ using a well-known KGQA dataset, showing that the system outperforms GPT-4 but still struggles with certain question categories - suggesting that alternative query construction strategies will need to be investigated in future LLM querying systems. We discuss a qualitative study of LinkQ with two domain experts using a real-world cybersecurity KG, outlining these experts' feedback, suggestions, perceived limitations, and future opportunities for systems like LinkQ.", 'abstract_zh': '高风险领域如网络操作需要负责可靠的AI方法。尽管大型语言模型（LLMs）在这些领域中的应用越来越受欢迎，它们仍然存在幻觉问题。本文通过LinkQ的案例研究提供了关于这一问题的学习成果，LinkQ是一个开源自然语言接口，旨在通过强制LLM在问答（QA）过程中查询知识图谱（KG）以获取真实数据来对抗幻觉。我们使用一个知名的KGQA数据集对LinkQ进行了定量评估，结果显示该系统优于GPT-4，但在某些问题类别上仍存在问题，这表明未来需要在LLM查询系统中探索不同的查询构建策略。我们与两位网络安全领域的专家使用了一个真实世界的KG进行了LinkQ的定性研究，概述了这些专家的反馈、建议、感知到的局限性以及类似LinkQ的系统未来的发展机会。', 'title_zh': '使用知识图谱减轻大模型幻觉：一个案例研究'}
{'arxiv_id': 'arXiv:2504.12397', 'title': 'Activated LoRA: Fine-tuned LLMs for Intrinsics', 'authors': 'Kristjan Greenewald, Luis Lastras, Thomas Parnell, Vraj Shah, Lucian Popa, Giulio Zizzo, Chulaka Gunasekara, Ambrish Rawat, David Cox', 'link': 'https://arxiv.org/abs/2504.12397', 'abstract': "Low-Rank Adaptation (LoRA) has emerged as a highly efficient framework for finetuning the weights of large foundation models, and has become the go-to method for data-driven customization of LLMs. Despite the promise of highly customized behaviors and capabilities, switching between relevant LoRAs in a multiturn setting is highly inefficient, as the key-value (KV) cache of the entire turn history must be recomputed with the LoRA weights before generation can begin. To address this problem, we propose Activated LoRA (aLoRA), which modifies the LoRA framework to only adapt weights for the tokens in the sequence \\emph{after} the aLoRA is invoked. This change crucially allows aLoRA to accept the base model's KV cache of the input string, meaning that aLoRA can be instantly activated whenever needed in a chain without recomputing the cache. This enables building what we call \\emph{intrinsics}, i.e. highly specialized models invoked to perform well-defined operations on portions of an input chain or conversation that otherwise uses the base model by default. We use aLoRA to train a set of intrinsics models, demonstrating competitive accuracy with standard LoRA while achieving significant inference benefits.", 'abstract_zh': 'Activated LoRA (aLoRA): Efficient Activation of Specialized Models for Input Chains and Conversations', 'title_zh': '激活的LoRA：用于本质属性的微调大型语言模型'}
{'arxiv_id': 'arXiv:2504.12365', 'title': 'Themisto: Jupyter-Based Runtime Benchmark', 'authors': 'Konstantin Grotov, Sergey Titov', 'link': 'https://arxiv.org/abs/2504.12365', 'abstract': 'In this work, we present a benchmark that consists of Jupyter notebooks development trajectories and allows measuring how large language models (LLMs) can leverage runtime information for predicting code output and code generation. We demonstrate that the current generation of LLMs performs poorly on these tasks and argue that there exists a significantly understudied domain in the development of code-based models, which involves incorporating the runtime context.', 'abstract_zh': '本研究介绍了基于Jupyter笔记本开发轨迹的基准，用于衡量大型语言模型如何利用运行时信息来预测代码输出和代码生成。我们展示了当前一代大型语言模型在这些任务上表现不佳，并 argue 认为，在代码基础模型的发展中，集成运行时上下文这一领域存在显著未被充分研究的领域。', 'title_zh': 'Themisto: Jupyter为基础的运行时基准测试'}
{'arxiv_id': 'arXiv:2504.12360', 'title': 'A Method for Handling Negative Similarities in Explainable Graph Spectral Clustering of Text Documents -- Extended Version', 'authors': 'Mieczysław A. Kłopotek, Sławomir T. Wierzchoń, Bartłomiej Starosta, Dariusz Czerski, Piotr Borkowski', 'link': 'https://arxiv.org/abs/2504.12360', 'abstract': 'This paper investigates the problem of Graph Spectral Clustering with negative similarities, resulting from document embeddings different from the traditional Term Vector Space (like doc2vec, GloVe, etc.). Solutions for combinatorial Laplacians and normalized Laplacians are discussed. An experimental investigation shows the advantages and disadvantages of 6 different solutions proposed in the literature and in this research. The research demonstrates that GloVe embeddings frequently cause failures of normalized Laplacian based GSC due to negative similarities. Furthermore, application of methods curing similarity negativity leads to accuracy improvement for both combinatorial and normalized Laplacian based GSC. It also leads to applicability for GloVe embeddings of explanation methods developed originally bythe authors for Term Vector Space embeddings.', 'abstract_zh': '基于负相似性的图频域聚类问题研究：从文档嵌入视角探讨梳理性拉普拉斯和规范化拉普拉斯的解决方案及其优劣比较', 'title_zh': '一种处理文本文档可解释图谱聚类中负相似性的方法——扩展版'}
{'arxiv_id': 'arXiv:2504.12359', 'title': 'Unveiling Hidden Collaboration within Mixture-of-Experts in Large Language Models', 'authors': 'Yuanbo Tang, Yan Tang, Naifan Zhang, Meixuan Chen, Yang Li', 'link': 'https://arxiv.org/abs/2504.12359', 'abstract': 'Mixture-of-Experts based large language models (MoE LLMs) have shown significant promise in multitask adaptability by dynamically routing inputs to specialized experts. Despite their success, the collaborative mechanisms among experts are still not well understood, limiting both the interpretability and optimization of these models. In this paper, we focus on two critical issues: (1) identifying expert collaboration patterns, and (2) optimizing MoE LLMs through expert pruning. To address the first issue, we propose a hierarchical sparse dictionary learning (HSDL) method that uncovers the collaboration patterns among experts. For the second issue, we introduce the Contribution-Aware Expert Pruning (CAEP) algorithm, which effectively prunes low-contribution experts. Our extensive experiments demonstrate that expert collaboration patterns are closely linked to specific input types and exhibit semantic significance across various tasks. Moreover, pruning experiments show that our approach improves overall performance by 2.5\\% on average, outperforming existing methods. These findings offer valuable insights into enhancing the efficiency and interpretability of MoE LLMs, offering a clearer understanding of expert interactions and improving model optimization.', 'abstract_zh': '基于专家混合的大语言模型（MoE LLMs）通过动态将输入路由到专门的专家，显示出了显著的多任务适应性潜力。尽管取得了一定的成功，但专家间的协作机制仍不够明确，限制了这些模型的可解释性和优化。本文重点探讨两个关键问题：（1）识别专家协作模式；（2）通过专家修剪优化MoE LLMs。为了解决第一个问题，我们提出了层次稀疏字典学习（HSDL）方法，以揭示专家之间的协作模式。为了解决第二个问题，我们引入了贡献感知专家修剪（CAEP）算法，有效修剪掉低贡献的专家。实验结果表明，专家协作模式与特定输入类型密切相关，并在多种任务中展现出语义意义。此外，修剪实验表明，我们提出的方法平均提高了2.5%的整体性能，优于现有方法。这些发现为提高MoE LLMs的效率和可解释性提供了宝贵见解，清晰展示了专家交互，并提高了模型优化效果。', 'title_zh': '揭示大型语言模型中专家混合模型中隐藏的合作关系'}
{'arxiv_id': 'arXiv:2504.12358', 'title': 'Towards an AI Observatory for the Nuclear Sector: A tool for anticipatory governance', 'authors': 'Aditi Verma, Elizabeth Williams', 'link': 'https://arxiv.org/abs/2504.12358', 'abstract': 'AI models are rapidly becoming embedded in all aspects of nuclear energy research and work but the safety, security, and safeguards consequences of this embedding are not well understood. In this paper, we call for the creation of an anticipatory system of governance for AI in the nuclear sector as well as the creation of a global AI observatory as a means for operationalizing anticipatory governance. The paper explores the contours of the nuclear AI observatory and an anticipatory system of governance by drawing on work in science and technology studies, public policy, and foresight studies.', 'abstract_zh': 'AI模型在核能研究与工作中迅速嵌入，但其安全、安全性和管控后果尚不明确。本文呼吁在核能 sector 创建一种前瞻性的 AI 治理系统，以及建立一个全球 AI 观测站以实现前瞻治理的落实。文章通过科学与技术研究、公共政策和预见性研究的工作，探讨核能 AI 观测站和前瞻性治理系统的轮廓。', 'title_zh': '面向核能领域的AI观测站：一种前瞻性治理工具'}
{'arxiv_id': 'arXiv:2504.12355', 'title': 'Leveraging Large Language Models for Multi-Class and Multi-Label Detection of Drug Use and Overdose Symptoms on Social Media', 'authors': 'Muhammad Ahmad, Muhammad Waqas, ldar Batyrshin, Grigori Sidorov', 'link': 'https://arxiv.org/abs/2504.12355', 'abstract': 'Drug overdose remains a critical global health issue, often driven by misuse of opioids, painkillers, and psychiatric medications. Traditional research methods face limitations, whereas social media offers real-time insights into self-reported substance use and overdose symptoms. This study proposes an AI-driven NLP framework trained on annotated social media data to detect commonly used drugs and associated overdose symptoms. Using a hybrid annotation strategy with LLMs and human annotators, we applied traditional ML models, neural networks, and advanced transformer-based models. Our framework achieved 98% accuracy in multi-class and 97% in multi-label classification, outperforming baseline models by up to 8%. These findings highlight the potential of AI for supporting public health surveillance and personalized intervention strategies.', 'abstract_zh': '药物过量仍是全球关键的公共卫生问题，通常由阿片类药物、止痛药和精神科药物的滥用引起。传统研究方法面临局限性，而社交媒体提供了关于自我报告的药物使用和过量症状的实时洞察。本研究提出了一种基于标注社交媒体数据训练的AI驱动自然语言处理框架，用于检测常用药物及其相关的过量症状。通过结合大语言模型和人工标注者的混合标注策略，我们应用了传统的机器学习模型、神经网络以及先进的Transformer模型。我们的框架在多类别分类中达到了98%的准确率，在多标签分类中达到了97%的准确率，比基线模型高出最多8个百分点。这些发现突显了AI在支持公共卫生监测和个性化干预策略方面的潜力。', 'title_zh': '利用大型语言模型进行社交媒体上药物使用和过量症状的多类和多标签检测'}
{'arxiv_id': 'arXiv:2504.12354', 'title': 'WaterFlow: Learning Fast & Robust Watermarks using Stable Diffusion', 'authors': 'Vinay Shukla, Prachee Sharma, Ryan Rossi, Sungchul Kim, Tong Yu, Aditya Grover', 'link': 'https://arxiv.org/abs/2504.12354', 'abstract': 'The ability to embed watermarks in images is a fundamental problem of interest for computer vision, and is exacerbated by the rapid rise of generated imagery in recent times. Current state-of-the-art techniques suffer from computational and statistical challenges such as the slow execution speed for practical deployments. In addition, other works trade off fast watermarking speeds but suffer greatly in their robustness or perceptual quality. In this work, we propose WaterFlow (WF), a fast and extremely robust approach for high fidelity visual watermarking based on a learned latent-dependent watermark. Our approach utilizes a pretrained latent diffusion model to encode an arbitrary image into a latent space and produces a learned watermark that is then planted into the Fourier Domain of the latent. The transformation is specified via invertible flow layers that enhance the expressivity of the latent space of the pre-trained model to better preserve image quality while permitting robust and tractable detection. Most notably, WaterFlow demonstrates state-of-the-art performance on general robustness and is the first method capable of effectively defending against difficult combination attacks. We validate our findings on three widely used real and generated datasets: MS-COCO, DiffusionDB, and WikiArt.', 'abstract_zh': '图像中嵌入水印的能力是计算机视觉中的一个基本问题，近年来生成图像的迅速增长加剧了这一问题。当前最先进的技术面临着诸如实用部署时执行速度慢等计算和统计挑战。此外，其他工作虽然实现了快速的水印速度，但在鲁棒性和感知质量方面却遭受了极大的损失。在本文中，我们提出了一种名为WaterFlow（WF）的快速且极其鲁棒的高保真视觉水印方法，基于学习到的潜在依赖水印。该方法利用预训练的潜在扩散模型将任意图像编码到潜在空间中，并生成一个学习到的水印，然后将其植入到潜在的傅里叶域中。变换通过可逆流层指定，以增强预训练模型的潜在空间的表达能力，更好地保持图像质量的同时允许鲁棒且易于实现的检测。最值得注意的是，WaterFlow在通用鲁棒性方面展示了最先进的性能，并且是第一个能够有效防御复杂组合攻击的方法。我们在三个广泛使用的现实和生成数据集上验证了我们的发现：MS-COCO、DiffusionDB和WikiArt。', 'title_zh': 'WaterFlow: 使用稳定扩散学习快速且稳健的水印'}
{'arxiv_id': 'arXiv:2504.12352', 'title': 'Deep Generative Model-Based Generation of Synthetic Individual-Specific Brain MRI Segmentations', 'authors': 'Ruijie Wang, Luca Rossetto, Susan Mérillat, Christina Röcke, Mike Martin, Abraham Bernstein', 'link': 'https://arxiv.org/abs/2504.12352', 'abstract': "To the best of our knowledge, all existing methods that can generate synthetic brain magnetic resonance imaging (MRI) scans for a specific individual require detailed structural or volumetric information about the individual's brain. However, such brain information is often scarce, expensive, and difficult to obtain. In this paper, we propose the first approach capable of generating synthetic brain MRI segmentations -- specifically, 3D white matter (WM), gray matter (GM), and cerebrospinal fluid (CSF) segmentations -- for individuals using their easily obtainable and often readily available demographic, interview, and cognitive test information. Our approach features a novel deep generative model, CSegSynth, which outperforms existing prominent generative models, including conditional variational autoencoder (C-VAE), conditional generative adversarial network (C-GAN), and conditional latent diffusion model (C-LDM). We demonstrate the high quality of our synthetic segmentations through extensive evaluations. Also, in assessing the effectiveness of the individual-specific generation, we achieve superior volume prediction, with Pearson correlation coefficients reaching 0.80, 0.82, and 0.70 between the ground-truth WM, GM, and CSF volumes of test individuals and those volumes predicted based on generated individual-specific segmentations, respectively.", 'abstract_zh': '已知的能够为特定个体生成合成脑磁共振成像（MRI）扫描的方法都需要该个体详细的大脑结构或容积信息。然而，此类大脑信息往往稀缺、昂贵且难以获得。在本文中，我们提出了第一个能够使用个体可轻易获得且通常容易获取的 Demographic、访谈和认知测试信息来生成合成脑 MRI 分割的方法——特别是生成 3D 白质 (WM)、灰质 (GM) 和脑脊液 (CSF) 分割。我们的方法特点是一个新颖的深度生成模型 CSegSynth，其性能优于现有的主流生成模型，包括条件变分自编码器（C-VAE）、条件生成对抗网络（C-GAN）和条件潜在扩散模型（C-LDM）。通过广泛的评估证明了我们合成分割的质量。此外，在评估个体特定生成的有效性时，我们实现了卓越的容积预测， pearson 相关系数分别达到 0.80、0.82 和 0.70，对应于测试个体的真实 WM、GM 和 CSF 容积与基于生成的个体特定分割预测的容积之间的相关性。', 'title_zh': '基于深度生成模型的合成个体特定脑MRI分割生成'}
{'arxiv_id': 'arXiv:2504.12351', 'title': 'Prototype-Guided Diffusion for Digital Pathology: Achieving Foundation Model Performance with Minimal Clinical Data', 'authors': 'Ekaterina Redekop, Mara Pleasure, Vedrana Ivezic, Zichen Wang, Kimberly Flores, Anthony Sisk, William Speier, Corey Arnold', 'link': 'https://arxiv.org/abs/2504.12351', 'abstract': 'Foundation models in digital pathology use massive datasets to learn useful compact feature representations of complex histology images. However, there is limited transparency into what drives the correlation between dataset size and performance, raising the question of whether simply adding more data to increase performance is always necessary. In this study, we propose a prototype-guided diffusion model to generate high-fidelity synthetic pathology data at scale, enabling large-scale self-supervised learning and reducing reliance on real patient samples while preserving downstream performance. Using guidance from histological prototypes during sampling, our approach ensures biologically and diagnostically meaningful variations in the generated data. We demonstrate that self-supervised features trained on our synthetic dataset achieve competitive performance despite using ~60x-760x less data than models trained on large real-world datasets. Notably, models trained using our synthetic data showed statistically comparable or better performance across multiple evaluation metrics and tasks, even when compared to models trained on orders of magnitude larger datasets. Our hybrid approach, combining synthetic and real data, further enhanced performance, achieving top results in several evaluations. These findings underscore the potential of generative AI to create compelling training data for digital pathology, significantly reducing the reliance on extensive clinical datasets and highlighting the efficiency of our approach.', 'abstract_zh': '基于原型引导的扩散模型生成大规模高保真合成病理数据以实现大规模自监督学习并保持下游性能', 'title_zh': '基于原型引导的扩散方法：在最少临床数据支持下实现基础模型性能'}
{'arxiv_id': 'arXiv:2504.12350', 'title': 'A Large-Language Model Framework for Relative Timeline Extraction from PubMed Case Reports', 'authors': 'Jing Wang, Jeremy C Weiss', 'link': 'https://arxiv.org/abs/2504.12350', 'abstract': 'Timing of clinical events is central to characterization of patient trajectories, enabling analyses such as process tracing, forecasting, and causal reasoning. However, structured electronic health records capture few data elements critical to these tasks, while clinical reports lack temporal localization of events in structured form. We present a system that transforms case reports into textual time series-structured pairs of textual events and timestamps. We contrast manual and large language model (LLM) annotations (n=320 and n=390 respectively) of ten randomly-sampled PubMed open-access (PMOA) case reports (N=152,974) and assess inter-LLM agreement (n=3,103; N=93). We find that the LLM models have moderate event recall(O1-preview: 0.80) but high temporal concordance among identified events (O1-preview: 0.95). By establishing the task, annotation, and assessment systems, and by demonstrating high concordance, this work may serve as a benchmark for leveraging the PMOA corpus for temporal analytics.', 'abstract_zh': '临床事件的时间安排是描述患者轨迹的关键，有助于过程追踪、 forecasting 和因果推理等分析。然而，结构化的电子健康记录仅捕获少数关键数据元素，而临床报告缺少结构化的时间定位事件。我们提出了一种系统，将病例报告转换为文本时间序列结构化的文本事件及其时间戳配对。我们对比了人工标注和大规模语言模型（LLM）标注（分别数量为320和390）的十篇随机抽取的PubMed开放获取（PMOA）病例报告（总数为152,974），并评估了大规模语言模型间的同意度（标注数量分别为3,103，93）。我们发现，大规模语言模型具有中等事件召回率（0.80）但识别的事件具有高时间一致性（0.95）。通过建立任务、标注系统和评估系统，并展示高一致性，本工作可以作为利用PMOA语料库进行时间分析的基准。', 'title_zh': '一种用于从PubMed病例报告中提取相对时间线的大型语言模型框架'}
{'arxiv_id': 'arXiv:2504.12347', 'title': 'Mathematical Capabilities of Large Language Models in Finnish Matriculation Examination', 'authors': 'Mika Setälä, Pieta Sikström, Ville Heilala, Tommi Kärkkäinen', 'link': 'https://arxiv.org/abs/2504.12347', 'abstract': 'Large language models (LLMs) have shown increasing promise in educational settings, yet their mathematical reasoning has been considered evolving. This study evaluates the mathematical capabilities of various LLMs using the Finnish matriculation examination, a high-stakes digital test for upper secondary education. Initial tests yielded moderate performance corresponding to mid-range grades, but later evaluations demonstrated substantial improvements as the language models evolved. Remarkably, some models achieved near-perfect or perfect scores, matching top student performance and qualifying for university admission. Our findings highlight the rapid advances in the mathematical proficiency of LLMs and illustrate their potential to also support educational assessments at scale.', 'abstract_zh': '大型语言模型在数学推理方面的能力通过芬兰高中毕业考试的评估显示了快速进步，并彰显了其大规模支持教育评估的潜力。', 'title_zh': '大型语言模型在芬兰高考中的数学能力'}
{'arxiv_id': 'arXiv:2504.12335', 'title': "You've Changed: Detecting Modification of Black-Box Large Language Models", 'authors': 'Alden Dima, James Foulds, Shimei Pan, Philip Feldman', 'link': 'https://arxiv.org/abs/2504.12335', 'abstract': "Large Language Models (LLMs) are often provided as a service via an API, making it challenging for developers to detect changes in their behavior. We present an approach to monitor LLMs for changes by comparing the distributions of linguistic and psycholinguistic features of generated text. Our method uses a statistical test to determine whether the distributions of features from two samples of text are equivalent, allowing developers to identify when an LLM has changed. We demonstrate the effectiveness of our approach using five OpenAI completion models and Meta's Llama 3 70B chat model. Our results show that simple text features coupled with a statistical test can distinguish between language models. We also explore the use of our approach to detect prompt injection attacks. Our work enables frequent LLM change monitoring and avoids computationally expensive benchmark evaluations.", 'abstract_zh': '大规模语言模型（LLMs）通常通过API提供服务，这使得开发者难以检测其行为变化。我们提出了一种通过比较生成文本的语言学和心理语言学特征分布来监控LLM变化的方法。该方法使用统计测试来确定两段文本特征分布是否等价，从而使开发者能够识别LLM是否发生变化。我们使用五种OpenAI完成模型和Meta的Llama 3 70B聊天模型展示了该方法的有效性。我们的结果表明，简单的文本特征结合统计测试可以区分语言模型。我们还探讨了该方法用于检测提示注入攻击的应用。我们的工作实现了对LLM变化的频繁监控，并避免了计算成本高昂的标准评估。', 'title_zh': '你变了：检测黑盒大型语言模型的修改'}
{'arxiv_id': 'arXiv:2504.12333', 'title': 'Meta-Evaluating Local LLMs: Rethinking Performance Metrics for Serious Games', 'authors': 'Andrés Isaza-Giraldo, Paulo Bala, Lucas Pereira', 'link': 'https://arxiv.org/abs/2504.12333', 'abstract': 'The evaluation of open-ended responses in serious games presents a unique challenge, as correctness is often subjective. Large Language Models (LLMs) are increasingly being explored as evaluators in such contexts, yet their accuracy and consistency remain uncertain, particularly for smaller models intended for local execution. This study investigates the reliability of five small-scale LLMs when assessing player responses in \\textit{En-join}, a game that simulates decision-making within energy communities. By leveraging traditional binary classification metrics (including accuracy, true positive rate, and true negative rate), we systematically compare these models across different evaluation scenarios. Our results highlight the strengths and limitations of each model, revealing trade-offs between sensitivity, specificity, and overall performance. We demonstrate that while some models excel at identifying correct responses, others struggle with false positives or inconsistent evaluations. The findings highlight the need for context-aware evaluation frameworks and careful model selection when deploying LLMs as evaluators. This work contributes to the broader discourse on the trustworthiness of AI-driven assessment tools, offering insights into how different LLM architectures handle subjective evaluation tasks.', 'abstract_zh': '开放性响应在严肃游戏中的评价面临独特挑战，其正确性往往具有主观性。大规模语言模型（LLMs）日益被探索作为此类情境中的评价者，但其准确性和一致性仍存疑，特别是针对旨在本地执行的小规模模型。本研究探讨了五种小规模LLMs在评估《En-join》游戏中玩家响应时的可靠性，《En-join》是一款模拟能源社区中决策过程的游戏。通过利用传统的二分类评价指标（包括准确率、真阳性率和真阴性率），我们系统地比较了这些模型在不同评价场景中的表现。研究结果突显了每种模型的优势与局限，揭示了敏感性、特异性与整体性能之间的权衡。我们展示了某些模型在识别正确响应方面表现出色，而另一些模型则在误报或不一致的评价方面存在困难。研究结果强调了需要具备情境意识的评价框架，并在部署LLMs作为评价者时谨慎选择模型。该研究为广泛探讨由AI驱动的评估工具的可信度做出了贡献，提供了关于不同LLM架构如何处理主观评价任务的见解。', 'title_zh': '基于元评估的本地LLM评估：严肃游戏的性能指标重思'}
{'arxiv_id': 'arXiv:2504.12331', 'title': 'Span-level Emotion-Cause-Category Triplet Extraction with Instruction Tuning LLMs and Data Augmentation', 'authors': 'Xiangju Li, Dong Yang, Xiaogang Zhu, Faliang Huang, Peng Zhang, Zhongying Zhao', 'link': 'https://arxiv.org/abs/2504.12331', 'abstract': "Span-level emotion-cause-category triplet extraction represents a novel and complex challenge within emotion cause analysis. This task involves identifying emotion spans, cause spans, and their associated emotion categories within the text to form structured triplets. While prior research has predominantly concentrated on clause-level emotion-cause pair extraction and span-level emotion-cause detection, these methods often confront challenges originating from redundant information retrieval and difficulty in accurately determining emotion categories, particularly when emotions are expressed implicitly or ambiguously. To overcome these challenges, this study explores a fine-grained approach to span-level emotion-cause-category triplet extraction and introduces an innovative framework that leverages instruction tuning and data augmentation techniques based on large language models. The proposed method employs task-specific triplet extraction instructions and utilizes low-rank adaptation to fine-tune large language models, eliminating the necessity for intricate task-specific architectures. Furthermore, a prompt-based data augmentation strategy is developed to address data scarcity by guiding large language models in generating high-quality synthetic training data. Extensive experimental evaluations demonstrate that the proposed approach significantly outperforms existing baseline methods, achieving at least a 12.8% improvement in span-level emotion-cause-category triplet extraction metrics. The results demonstrate the method's effectiveness and robustness, offering a promising avenue for advancing research in emotion cause analysis. The source code is available at this https URL.", 'abstract_zh': '基于跨度的情感-成因-类别三元组提取代表了情感成因分析中的一项新颖而复杂的挑战。本研究探索了一种精细的跨度级别情感-成因-类别三元组提取方法，并引入了一个基于大语言模型的创新框架，该框架结合了指令调谐和数据增强技术。所提出的方法采用了特定任务的三元组提取指令，并利用低秩适应对大语言模型进行微调，从而避免了复杂的特定任务架构。此外，开发了一种基于提示的数据增强策略，以通过引导大语言模型生成高质量的合成训练数据来解决数据稀缺问题。大量的实验评估表明，所提出的方法在跨度级别情感-成因-类别三元组提取指标上显著优于现有基线方法，提高了至少12.8%。结果表明该方法的有效性和鲁棒性，为情感成因分析研究的发展提供了一条有前景的道路。相关代码可通过以下链接获取：这个 https URL。', 'title_zh': '基于指令调谐大语言模型和数据增强的短语级别情绪-因果-类别三元组抽取'}
{'arxiv_id': 'arXiv:2504.12330', 'title': 'HM-RAG: Hierarchical Multi-Agent Multimodal Retrieval Augmented Generation', 'authors': 'Pei Liu, Xin Liu, Ruoyu Yao, Junming Liu, Siyuan Meng, Ding Wang, Jun Ma', 'link': 'https://arxiv.org/abs/2504.12330', 'abstract': 'While Retrieval-Augmented Generation (RAG) augments Large Language Models (LLMs) with external knowledge, conventional single-agent RAG remains fundamentally limited in resolving complex queries demanding coordinated reasoning across heterogeneous data ecosystems. We present HM-RAG, a novel Hierarchical Multi-agent Multimodal RAG framework that pioneers collaborative intelligence for dynamic knowledge synthesis across structured, unstructured, and graph-based data. The framework is composed of three-tiered architecture with specialized agents: a Decomposition Agent that dissects complex queries into contextually coherent sub-tasks via semantic-aware query rewriting and schema-guided context augmentation; Multi-source Retrieval Agents that carry out parallel, modality-specific retrieval using plug-and-play modules designed for vector, graph, and web-based databases; and a Decision Agent that uses consistency voting to integrate multi-source answers and resolve discrepancies in retrieval results through Expert Model Refinement. This architecture attains comprehensive query understanding by combining textual, graph-relational, and web-derived evidence, resulting in a remarkable 12.95% improvement in answer accuracy and a 3.56% boost in question classification accuracy over baseline RAG systems on the ScienceQA and CrisisMMD benchmarks. Notably, HM-RAG establishes state-of-the-art results in zero-shot settings on both datasets. Its modular architecture ensures seamless integration of new data modalities while maintaining strict data governance, marking a significant advancement in addressing the critical challenges of multimodal reasoning and knowledge synthesis in RAG systems. Code is available at this https URL.', 'abstract_zh': '基于检索增强生成的分层多代理多模态框架：面向异构数据生态的协作智能动态知识合成', 'title_zh': 'HM-RAG: 分层多剂型多模态检索增强生成'}
{'arxiv_id': 'arXiv:2504.12329', 'title': 'Speculative Thinking: Enhancing Small-Model Reasoning with Large Model Guidance at Inference Time', 'authors': 'Wang Yang, Xiang Yue, Vipin Chaudhary, Xiaotian Han', 'link': 'https://arxiv.org/abs/2504.12329', 'abstract': 'Recent advances leverage post-training to enhance model reasoning performance, which typically requires costly training pipelines and still suffers from inefficient, overly lengthy outputs. We introduce Speculative Thinking, a training-free framework that enables large reasoning models to guide smaller ones during inference at the reasoning level, distinct from speculative decoding, which operates at the token level. Our approach is based on two observations: (1) reasoning-supportive tokens such as "wait" frequently appear after structural delimiters like "\\n\\n", serving as signals for reflection or continuation; and (2) larger models exhibit stronger control over reflective behavior, reducing unnecessary backtracking while improving reasoning quality. By strategically delegating reflective steps to a more capable model, our method significantly boosts the reasoning accuracy of reasoning models while shortening their output. With the assistance of the 32B reasoning model, the 1.5B model\'s accuracy on MATH500 increases from 83.2% to 89.4%, marking a substantial improvement of 6.2%. Simultaneously, the average output length is reduced from 5439 tokens to 4583 tokens, representing a 15.7% decrease. Moreover, when applied to a non-reasoning model (Qwen-2.5-7B-Instruct), our framework boosts its accuracy from 74.0% to 81.8% on the same benchmark, achieving a relative improvement of 7.8%.', 'abstract_zh': 'Recent Advances in Speculative Thinking for Enhancing Reasoning Performance of Large Language Models', 'title_zh': '推测性思考：在推理时通过大规模模型指导提升小模型推理能力'}
{'arxiv_id': 'arXiv:2504.12328', 'title': 'A Comprehensive Survey of Reward Models: Taxonomy, Applications, Challenges, and Future', 'authors': 'Jialun Zhong, Wei Shen, Yanzeng Li, Songyang Gao, Hua Lu, Yicheng Chen, Yang Zhang, Wei Zhou, Jinjie Gu, Lei Zou', 'link': 'https://arxiv.org/abs/2504.12328', 'abstract': "Reward Model (RM) has demonstrated impressive potential for enhancing Large Language Models (LLM), as RM can serve as a proxy for human preferences, providing signals to guide LLMs' behavior in various tasks. In this paper, we provide a comprehensive overview of relevant research, exploring RMs from the perspectives of preference collection, reward modeling, and usage. Next, we introduce the applications of RMs and discuss the benchmarks for evaluation. Furthermore, we conduct an in-depth analysis of the challenges existing in the field and dive into the potential research directions. This paper is dedicated to providing beginners with a comprehensive introduction to RMs and facilitating future studies. The resources are publicly available at github\\footnote{this https URL}.", 'abstract_zh': 'Reward Model (RM) 对增强大型语言模型 (LLM) 展现了令人 impress 的潜力，因为 RM 可以作为人类偏好的代理，为 LLMs 在各种任务中的行为提供指导信号。本文从偏好收集、奖励建模和应用的角度提供了一系列相关研究的全面概述。接着，我们介绍了 Reward Model 的应用并讨论了评估基准。此外，我们深入分析了该领域的现有挑战并探索了潜在的研究方向。本文旨在为初学者提供 Reward Model 的全面介绍，并促进未来的研究。相关资源可在 GitHub 上公开访问。', 'title_zh': '全面奖励模型综述：分类、应用、挑战与未来'}
{'arxiv_id': 'arXiv:2504.12326', 'title': 'Reconstructing Sepsis Trajectories from Clinical Case Reports using LLMs: the Textual Time Series Corpus for Sepsis', 'authors': 'Shahriar Noroozizadeh, Jeremy C. Weiss', 'link': 'https://arxiv.org/abs/2504.12326', 'abstract': 'Clinical case reports and discharge summaries may be the most complete and accurate summarization of patient encounters, yet they are finalized, i.e., timestamped after the encounter. Complementary data structured streams become available sooner but suffer from incompleteness. To train models and algorithms on more complete and temporally fine-grained data, we construct a pipeline to phenotype, extract, and annotate time-localized findings within case reports using large language models. We apply our pipeline to generate an open-access textual time series corpus for Sepsis-3 comprising 2,139 case reports from the Pubmed-Open Access (PMOA) Subset. To validate our system, we apply it on PMOA and timeline annotations from I2B2/MIMIC-IV and compare the results to physician-expert annotations. We show high recovery rates of clinical findings (event match rates: O1-preview--0.755, Llama 3.3 70B Instruct--0.753) and strong temporal ordering (concordance: O1-preview--0.932, Llama 3.3 70B Instruct--0.932). Our work characterizes the ability of LLMs to time-localize clinical findings in text, illustrating the limitations of LLM use for temporal reconstruction and providing several potential avenues of improvement via multimodal integration.', 'abstract_zh': '临床病例报告和出院总结可能是患者就诊过程中最完整和准确的总结，但它们是在就诊结束后才最终确定的，即带有时间戳。补充的数据结构化流可以在较早的时间获得，但会存在不完整性。为了在更多完整且时间分辨率更高的数据上训练模型和算法，我们构建了一套管道，使用大规模语言模型对病例报告中的时间本地化发现进行表型识别、提取和标注。我们将该管道应用于PubMed-Open Access (PMOA) 子集中的2,139份病例报告，生成了一个公开访问的关于Sepsis-3的时间序列文本语料库。为了验证我们的系统，我们将其应用于PMOA，并使用I2B2/MIMIC-IV的时间线注释进行比较，将结果与医生专家的注释进行了对比。结果显示了高临床发现恢复率（事件匹配率：O1-preview--0.755，Llama 3.3 70B Instruct--0.753）和强烈的时序顺序（一致性：O1-preview--0.932，Llama 3.3 70B Instruct--0.932）。我们的研究表征了LLM在文本中时间本地化临床发现的能力，展示了LLM在时间重建使用上的局限性，并通过多模态集成提供了几个改进的可能性。', 'title_zh': '使用大语言模型从临床案例报告重构脓毒症轨迹：脓毒症文本时间序列语料库'}
{'arxiv_id': 'arXiv:2504.12325', 'title': 'LLMTaxo: Leveraging Large Language Models for Constructing Taxonomy of Factual Claims from Social Media', 'authors': 'Haiqi Zhang, Zhengyuan Zhu, Zeyu Zhang, Chengkai Li', 'link': 'https://arxiv.org/abs/2504.12325', 'abstract': 'With the vast expansion of content on social media platforms, analyzing and comprehending online discourse has become increasingly complex. This paper introduces LLMTaxo, a novel framework leveraging large language models for the automated construction of taxonomy of factual claims from social media by generating topics from multi-level granularities. This approach aids stakeholders in more effectively navigating the social media landscapes. We implement this framework with different models across three distinct datasets and introduce specially designed taxonomy evaluation metrics for a comprehensive assessment. With the evaluations from both human evaluators and GPT-4, the results indicate that LLMTaxo effectively categorizes factual claims from social media, and reveals that certain models perform better on specific datasets.', 'abstract_zh': '随着社交媒体平台上内容的迅速扩展，分析和理解在线话语变得越来越复杂。本文介绍了LLMTaxo，这是一个利用大语言模型自动从社交媒体生成多级粒度主题，构建事实声明分类框架的新方法。该方法帮助利益相关者更有效地导航社交媒体景观。我们使用不同模型在三个不同的数据集上实现了此框架，并引入了专门设计的分类框架评估指标进行全面评估。通过人类评估者和GPT-4的评估结果表明，LLMTaxo有效分类了社交媒体上的事实声明，并揭示某些模型在特定数据集上表现更好。', 'title_zh': 'LLMTaxo: 利用大规模语言模型从社交媒体构建事实断言层次结构'}
{'arxiv_id': 'arXiv:2504.12324', 'title': 'Cross-Document Cross-Lingual Natural Language Inference via RST-enhanced Graph Fusion and Interpretability Prediction', 'authors': 'Mengying Yuan, Wangzi Xuan, Fei Li', 'link': 'https://arxiv.org/abs/2504.12324', 'abstract': "Natural Language Inference (NLI) is a fundamental task in both natural language processing and information retrieval. While NLI has developed many sub-directions such as sentence-level NLI, document-level NLI and cross-lingual NLI, Cross-Document Cross-Lingual NLI (CDCL-NLI) remains largely unexplored. In this paper, we propose a novel paradigm for CDCL-NLI that extends traditional NLI capabilities to multi-document, multilingual scenarios. To support this task, we construct a high-quality CDCL-NLI dataset including 1,110 instances and spanning 26 languages. To build a baseline for this task, we also propose an innovative method that integrates RST-enhanced graph fusion and interpretability prediction. Our method employs RST (Rhetorical Structure Theory) on RGAT (Relation-aware Graph Attention Network) for cross-document context modeling, coupled with a structure-aware semantic alignment mechanism based on lexical chains for cross-lingual understanding. For NLI interpretability, we develop an EDU-level attribution framework that generates extractive explanations. Extensive experiments demonstrate our approach's superior performance, achieving significant improvements over both traditional NLI models such as DocNLI and R2F, as well as LLMs like Llama3 and GPT-4o. Our work sheds light on the study of NLI and will bring research interest on cross-document cross-lingual context understanding, semantic retrieval and interpretability inference. Our dataset and code are available at \\href{this https URL}{CDCL-NLI-Link for peer review}.", 'abstract_zh': '跨文档跨语言自然语言推理（CDCL-NLI）：一种新的范式', 'title_zh': '跨文档跨语言自然语言推理：基于RST增强图融合与可解释性预测'}
{'arxiv_id': 'arXiv:2504.12323', 'title': 'The Other Side of the Coin: Exploring Fairness in Retrieval-Augmented Generation', 'authors': 'Zheng Zhang, Ning Li, Qi Liu, Rui Li, Weibo Gao, Qingyang Mao, Zhenya Huang, Baosheng Yu, Dacheng Tao', 'link': 'https://arxiv.org/abs/2504.12323', 'abstract': 'Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by retrieving relevant document from external knowledge sources. By referencing this external knowledge, RAG effectively reduces the generation of factually incorrect content and addresses hallucination issues within LLMs. Recently, there has been growing attention to improving the performance and efficiency of RAG systems from various perspectives. While these advancements have yielded significant results, the application of RAG in domains with considerable societal implications raises a critical question about fairness: What impact does the introduction of the RAG paradigm have on the fairness of LLMs? To address this question, we conduct extensive experiments by varying the LLMs, retrievers, and retrieval sources. Our experimental analysis reveals that the scale of the LLMs plays a significant role in influencing fairness outcomes within the RAG framework. When the model scale is smaller than 8B, the integration of retrieval mechanisms often exacerbates unfairness in small-scale LLMs (e.g., LLaMA3.2-1B, Mistral-7B, and LLaMA3-8B). To mitigate the fairness issues introduced by RAG for small-scale LLMs, we propose two approaches, FairFT and FairFilter. Specifically, in FairFT, we align the retriever with the LLM in terms of fairness, enabling it to retrieve documents that facilitate fairer model outputs. In FairFilter, we propose a fairness filtering mechanism to filter out biased content after retrieval. Finally, we validate our proposed approaches on real-world datasets, demonstrating their effectiveness in improving fairness while maintaining performance.', 'abstract_zh': 'Retrieval-Augmented Generation (RAG)增强的大语言模型（LLMs）的检索与生成：公平性影响及其改进方法', 'title_zh': '硬币的另一面：探索检索增强生成中的公平性'}
{'arxiv_id': 'arXiv:2504.12322', 'title': 'A Strategic Coordination Framework of Small LLMs Matches Large LLMs in Data Synthesis', 'authors': 'Xin Gao, Qizhi Pei, Zinan Tang, Yu Li, Honglin Lin, Jiang Wu, Conghui He, Lijun Wu', 'link': 'https://arxiv.org/abs/2504.12322', 'abstract': 'While data synthesis and distillation are promising strategies to enhance small language models, current approaches heavily rely on Large Language Models (LLMs), which suffer from high computational costs, environmental inefficiency, and potential biases inherited from monolithic architectures. In contrast, smaller LLMs are more accessible and sustainable, but their individual capabilities often fall short in generating high-quality, diverse, and reliable data. Inspired by collaborative human processes (e.g., peer review), we propose a multiple small LLMs involved framework, GRA, that aggregates specialized roles across small LLMs to iterative refinement and quality control typically achieved by a single large LLM. In this collaborative framework, multiple small LLMs assume distinct roles-Generator, Reviewer, and Adjudicator-to simulate a peer-review-inspired data synthesis pipeline. The Generator proposes initial data samples, the Reviewer critiques their quality and diversity, and the Adjudicator resolves conflicts to finalize the output. By decomposing the synthesis process into specialized sub-tasks, collaborative small LLMs can achieve data-level parity with large LLM-based distillation. Through experiments across multiple benchmarks, we demonstrate that GRA-produced data matches or exceeds the quality of single large LLM outputs, e.g., Qwen-2.5-72B-Instruct. Our results challenge the necessity of monolithic large models for high-quality data synthesis, advocating instead for strategic coordination of smaller agents. Our datasets, models, and code are publicly available at this https URL.', 'abstract_zh': '基于多个小型语言模型的 GRA 框架：模拟同行评议的数据合成与提炼', 'title_zh': '小型LLM的战略协调框架可以在数据合成方面匹配大型LLM'}
{'arxiv_id': 'arXiv:2504.12321', 'title': 'AttentionDefense: Leveraging System Prompt Attention for Explainable Defense Against Novel Jailbreaks', 'authors': 'Charlotte Siska, Anush Sankaran', 'link': 'https://arxiv.org/abs/2504.12321', 'abstract': "In the past few years, Language Models (LMs) have shown par-human capabilities in several domains. Despite their practical applications and exceeding user consumption, they are susceptible to jailbreaks when malicious input exploits the LM's weaknesses, causing it to deviate from its intended behavior. Current defensive strategies either classify the input prompt as adversarial or prevent LMs from generating harmful outputs. However, it is challenging to explain the reason behind the malicious nature of the jailbreak, which results in a wide variety of closed-box approaches. In this research, we propose and demonstrate that system-prompt attention from Small Language Models (SLMs) can be used to characterize adversarial prompts, providing a novel, explainable, and cheaper defense approach called AttentionDefense. Our research suggests that the attention mechanism is an integral component in understanding and explaining how LMs respond to malicious input that is not captured in the semantic meaning of text embeddings. The proposed AttentionDefense is evaluated against existing jailbreak benchmark datasets. Ablation studies show that SLM-based AttentionDefense has equivalent or better jailbreak detection performance compared to text embedding-based classifiers and GPT-4 zero-shot this http URL further validate the efficacy of the proposed approach, we generate a dataset of novel jailbreak variants of the existing benchmark dataset using a closed-loop LLM-based multi-agent system. We demonstrate that the proposed AttentionDefense approach performs robustly on this novel jailbreak dataset while existing approaches suffer in performance. Additionally, for practical purposes AttentionDefense is an ideal solution as it has the computation requirements of a small LM but the performance of a LLM detector.", 'abstract_zh': '过去几年，语言模型在多个领域展示了接近人类的能力。尽管它们在实际应用中得到了广泛使用并且超过了用户的接受度，但在恶意输入利用语言模型弱点进行“越狱”时，可能会使其偏离预期行为。当前的防御策略要么将输入提示分类为恶意的，要么阻止语言模型生成有害输出。然而，解释恶意越狱的原因颇具挑战性，这导致了大量封闭式的防御方法。在本研究中，我们提出并展示了小型语言模型（SLMs）系统提示注意力可以用于表征恶意提示，提供了一种新颖、可解释且成本更低的防御方法AttentionDefense。我们的研究建议，注意力机制是理解并解释语言模型如何响应文本嵌入语义意义之外的恶意输入的重要组成部分。提出的AttentionDefense已在现有的越狱基准数据集上进行了评估。消融研究显示，基于SLM的AttentionDefense在越狱检测性能上与基于文本嵌入的分类器和GPT-4零样本性能相当甚至更好。为进一步验证该方法的有效性，我们使用基于闭合环LLM多智能体系统生成了现有基准数据集的新变种越狱数据集。我们展示了提出的AttentionDefense方法在该新变种越狱数据集上表现出色，而现有方法则表现出性能下降。此外，出于实际应用考虑，AttentionDefense是一个理想解决方案，因为它具有小型语言模型的计算要求，但性能上接近大规模语言模型检测器。', 'title_zh': 'AttentionDefense：利用系统提示注意力进行可解释的新型 Jailbreak 安全防御'}
{'arxiv_id': 'arXiv:2504.12320', 'title': 'Has the Creativity of Large-Language Models peaked? An analysis of inter- and intra-LLM variability', 'authors': 'Jennifer Haase, Paul H. P. Hanel, Sebastian Pokutta', 'link': 'https://arxiv.org/abs/2504.12320', 'abstract': 'Following the widespread adoption of ChatGPT in early 2023, numerous studies reported that large language models (LLMs) can match or even surpass human performance in creative tasks. However, it remains unclear whether LLMs have become more creative over time, and how consistent their creative output is. In this study, we evaluated 14 widely used LLMs -- including GPT-4, Claude, Llama, Grok, Mistral, and DeepSeek -- across two validated creativity assessments: the Divergent Association Task (DAT) and the Alternative Uses Task (AUT). Contrary to expectations, we found no evidence of increased creative performance over the past 18-24 months, with GPT-4 performing worse than in previous studies. For the more widely used AUT, all models performed on average better than the average human, with GPT-4o and o3-mini performing best. However, only 0.28% of LLM-generated responses reached the top 10% of human creativity benchmarks. Beyond inter-model differences, we document substantial intra-model variability: the same LLM, given the same prompt, can produce outputs ranging from below-average to original. This variability has important implications for both creativity research and practical applications. Ignoring such variability risks misjudging the creative potential of LLMs, either inflating or underestimating their capabilities. The choice of prompts affected LLMs differently. Our findings underscore the need for more nuanced evaluation frameworks and highlight the importance of model selection, prompt design, and repeated assessment when using Generative AI (GenAI) tools in creative contexts.', 'abstract_zh': 'ChatGPT普及后大型语言模型的创造性表现：从2023年初至今它们变得更加富有创造力了吗？', 'title_zh': '大型语言模型的创造力是否已达到顶峰？跨模型与模型内部变异性分析'}
{'arxiv_id': 'arXiv:2504.12319', 'title': 'Specialized text classification: an approach to classifying Open Banking transactions', 'authors': 'Duc Tuyen TA, Wajdi Ben Saad, Ji Young Oh', 'link': 'https://arxiv.org/abs/2504.12319', 'abstract': 'With the introduction of the PSD2 regulation in the EU which established the Open Banking framework, a new window of opportunities has opened for banks and fintechs to explore and enrich Bank transaction descriptions with the aim of building a better understanding of customer behavior, while using this understanding to prevent fraud, reduce risks and offer more competitive and tailored services.\nAnd although the usage of natural language processing models and techniques has seen an incredible progress in various applications and domains over the past few years, custom applications based on domain-specific text corpus remain unaddressed especially in the banking sector.\nIn this paper, we introduce a language-based Open Banking transaction classification system with a focus on the french market and french language text. The system encompasses data collection, labeling, preprocessing, modeling, and evaluation stages. Unlike previous studies that focus on general classification approaches, this system is specifically tailored to address the challenges posed by training a language model with a specialized text corpus (Banking data in the French context). By incorporating language-specific techniques and domain knowledge, the proposed system demonstrates enhanced performance and efficiency compared to generic approaches.', 'abstract_zh': '在欧盟PSD2条例引入开放银行业务框架的背景下，银行和金融科技公司有机会通过丰富银行交易描述来深化客户行为理解，并利用这些理解预防欺诈、降低风险，提供更具竞争力和针对性的服务。虽然过去几年自然语言处理模型和方法在各种应用和领域中取得了惊人的进步，但基于领域特定文本语料库的定制应用特别是在银行业仍被忽视。本文介绍了一个基于语言的法国市场和法语文本的开放银行业务交易分类系统，该系统涵盖了数据收集、标注、预处理、建模和评估阶段。与以往侧重通用分类方法的研究不同，该系统专门针对使用特定领域文本语料库（法国银行数据）训练语言模型所面临的挑战进行设计。通过结合语言特定技术和领域知识，所提出系统在性能和效率上优于通用方法。', 'title_zh': '专门化的文本分类：一种Open Banking交易分类方法'}
{'arxiv_id': 'arXiv:2504.12318', 'title': 'AUTONAV: A Toolfor Autonomous Navigation of Robots', 'authors': 'Mir Md Sajid Sarwar, Sudip Samanta, Rajarshi Ray', 'link': 'https://arxiv.org/abs/2504.12318', 'abstract': 'We present a tool AUTONAV that automates the mapping, localization, and path-planning tasks for autonomous navigation of robots. The modular architecture allows easy integration of various algorithms for these tasks for comparison. We present the generated maps and path-plans by AUTONAV in indoor simulation scenarios.', 'abstract_zh': '我们提出了一种工具AUTONAV，该工具自动化了自主机器人导航的建图、定位和路径规划任务。模块化的架构允许轻松集成这些任务的各种算法以进行比较。我们在室内仿真场景中展示了AUTONAV生成的地图和路径规划。', 'title_zh': 'AUTONAV：一种自主导航机器人工具'}
{'arxiv_id': 'arXiv:2504.12316', 'title': 'Data Metabolism: An Efficient Data Design Schema For Vision Language Model', 'authors': 'Jingyuan Zhang, Hongzhi Zhang, Zhou Haonan, Chenxi Sun, Xingguang ji, Jiakang Wang, Fanheng Kong, Yahui Liu, Qi Wang, Fuzheng Zhang', 'link': 'https://arxiv.org/abs/2504.12316', 'abstract': 'Data curation plays a crucial role in training powerful Visual Language Models (VLMs). In this work, we introduce the concept of Data Metabolism and present our data-centric framework to build VLMs throughout the development lifecycle. Starting from a standard model architecture, we discuss and provide insights into two crucial development steps: data curation and iteration, forming a closed-loop system that continuously improves model performance. We show a detailed codebook on how to process existing massive datasets and build user-specific data flywheel. As a demonstration, we release a VLM, named Capybara-VL, which excels in typical multimodal tasks (e.g. , visual question answering, scientific reasoning, and text-rich tasks). Despite its relatively compact size, Capybara-VL surpasses several open-source models that are up to 10 times larger in size. Moreover, it achieves results that are on par with those of several leading proprietary models, demonstrating its remarkable competitiveness. These results highlight the power of our data-centric framework and the potential of training smaller and more efficient VLMs.', 'abstract_zh': '数据治理在训练强大视觉语言模型中的作用至关重要。在这项工作中，我们引入了数据新陈代谢的概念，并提出了一种以数据为中心的框架，贯穿视觉语言模型开发的整个生命周期。从标准模型架构出发，我们讨论并提供了数据治理和迭代两个关键步骤的见解，形成一个闭环系统，持续提高模型性能。我们详细介绍了如何处理现有大规模数据集并构建用户特定的数据飞轮。作为演示，我们发布了名为Capybara-VL的视觉语言模型，该模型在典型的多模态任务（如视觉问答、科学推理和图文任务）上表现出色。尽管其相对较小，Capybara-VL仍超越了多个开源模型，这些模型的规模是其的10倍以上。此外，它还达到了与多个领先私有模型相当的结果，展示了其显著的竞争优势。这些结果突显了我们以数据为中心的框架的力量以及训练更小、更高效的视觉语言模型的潜力。', 'title_zh': '数据代谢：一种高效的视觉语言模型数据设计方案'}
{'arxiv_id': 'arXiv:2504.12315', 'title': 'Capybara-OMNI: An Efficient Paradigm for Building Omni-Modal Language Models', 'authors': 'Xingguang Ji, Jiakang Wang, Hongzhi Zhang, Jingyuan Zhang, Haonan Zhou, Chenxi Sun, Yahui Liu, Qi Wang, Fuzheng Zhang', 'link': 'https://arxiv.org/abs/2504.12315', 'abstract': 'With the development of Multimodal Large Language Models (MLLMs), numerous outstanding accomplishments have emerged within the open-source community. Due to the complexity of creating and training multimodal data pairs, it is still a computational and time-consuming process to build powerful MLLMs. In this work, we introduce Capybara-OMNI, an MLLM that trains in a lightweight and efficient manner and supports understanding text, image, video, and audio modalities. We present in detail the framework design, the data construction, and the training recipe, to develop an MLLM step-by-step to obtain competitive performance. We also provide exclusive benchmarks utilized in our experiments to show how to properly verify understanding capabilities across different modalities. Results show that by following our guidance, we can efficiently build an MLLM that achieves competitive performance among models of the same scale on various multimodal benchmarks. Additionally, to enhance the multimodal instruction following and conversational capabilities of the model, we further discuss how to train the chat version upon an MLLM understanding model, which is more in line with user habits for tasks like real-time interaction with humans. We publicly disclose the Capybara-OMNI model, along with its chat-based version. The disclosure includes both the model weights, a portion of the training data, and the inference codes, which are made available on GitHub.', 'abstract_zh': '基于轻量高效训练的大规模多模态语言模型Capybara-OMNI及其应用研究', 'title_zh': 'Capybara-OMNI：一种高效的多模态语言模型构建范式'}
{'arxiv_id': 'arXiv:2504.12314', 'title': 'How to Detect and Defeat Molecular Mirage: A Metric-Driven Benchmark for Hallucination in LLM-based Molecular Comprehension', 'authors': 'Hao Li, Liuzhenghao Lv, He Cao, Zijing Liu, Zhiyuan Yan, Yu Wang, Yonghong Tian, Yu Li, Li Yuan', 'link': 'https://arxiv.org/abs/2504.12314', 'abstract': 'Large language models are increasingly used in scientific domains, especially for molecular understanding and analysis. However, existing models are affected by hallucination issues, resulting in errors in drug design and utilization. In this paper, we first analyze the sources of hallucination in LLMs for molecular comprehension tasks, specifically the knowledge shortcut phenomenon observed in the PubChem dataset. To evaluate hallucination in molecular comprehension tasks with computational efficiency, we introduce \\textbf{Mol-Hallu}, a novel free-form evaluation metric that quantifies the degree of hallucination based on the scientific entailment relationship between generated text and actual molecular properties. Utilizing the Mol-Hallu metric, we reassess and analyze the extent of hallucination in various LLMs performing molecular comprehension tasks. Furthermore, the Hallucination Reduction Post-processing stage~(HRPP) is proposed to alleviate molecular hallucinations, Experiments show the effectiveness of HRPP on decoder-only and encoder-decoder molecular LLMs. Our findings provide critical insights into mitigating hallucination and improving the reliability of LLMs in scientific applications.', 'abstract_zh': '大规模语言模型在科学领域日益广泛应用，特别是在分子理解和分析方面。然而，现有模型受到幻觉问题的影响，导致药物设计和利用中的错误。本文首先分析了大规模语言模型在分子理解任务中幻觉的来源，特别是观察到的PubChem数据集中的知识捷径现象。为了以计算高效的方式评估分子理解任务中的幻觉，我们引入了\\textbf{Mol-Hallu}这一新颖的自由形式评估指标，基于生成文本与实际分子属性的科学蕴含关系来量化幻觉的程度。利用Mol-Hallu指标，我们重新评估并分析了各种执行分子理解任务的大规模语言模型中的幻觉程度。此外，我们提出了幻觉减少后处理阶段（HRPP）来减轻分子幻觉，实验显示HRPP在仅解码器和编码器-解码器分子语言模型中的有效性。我们的研究结果为减轻幻觉和提高语言模型在科学应用中的可靠性提供了关键见解。', 'title_zh': '如何检测和战胜分子幻象：LLM基于分子理解中的幻觉评估基准'}
{'arxiv_id': 'arXiv:2504.12309', 'title': 'Large Language Model-Based Knowledge Graph System Construction for Sustainable Development Goals: An AI-Based Speculative Design Perspective', 'authors': 'Yi-De Lin, Guan-Ze Liao', 'link': 'https://arxiv.org/abs/2504.12309', 'abstract': "From 2000 to 2015, the UN's Millennium Development Goals guided global priorities. The subsequent Sustainable Development Goals (SDGs) adopted a more dynamic approach, with annual indicator updates. As 2030 nears and progress lags, innovative acceleration strategies are critical. This study develops an AI-powered knowledge graph system to analyze SDG interconnections, discover potential new goals, and visualize them online. Using official SDG texts, Elsevier's keyword dataset, and 1,127 TED Talk transcripts (2020-2023), a pilot on 269 talks from 2023 applies AI-speculative design, large language models, and retrieval-augmented generation. Key findings include: (1) Heatmap analysis reveals strong associations between Goal 10 and Goal 16, and minimal coverage of Goal 6. (2) In the knowledge graph, simulated dialogue over time reveals new central nodes, showing how richer data supports divergent thinking and goal clarity. (3) Six potential new goals are proposed, centered on equity, resilience, and technology-driven inclusion. This speculative-AI framework offers fresh insights for policymakers and lays groundwork for future multimodal and cross-system SDG applications.", 'abstract_zh': '从2000年至2015年，联合国 Millennium Development Goals 引导了全球优先事项。随后的可持续发展目标（SDGs）采取了更为动态的方法，每年更新指标。随着2030年的临近和进展滞后，创新加速策略变得至关重要。本研究开发了一个基于AI的知识图谱系统，以分析SDG之间的相互联系，发现潜在的新目标，并在线可视化它们。通过使用官方SDG文本、Elsevier的关键词数据集以及2020年至2023年1,127场TED Talks的转录，对2023年的269场Talks进行了试点研究，应用AI推测设计、大规模语言模型以及检索增强生成技术。主要发现包括：（1）热图分析显示，目标10与目标16之间存在强烈关联，而目标6的覆盖率最低。（2）在知识图谱中，模拟的对话随时间展开揭示了新的核心节点，展示了更丰富数据如何支持发散思维和目标明确性。（3）提出了六项潜在的新目标，集中在公平、韧性和技术驱动的包容性上。该推测性AI框架为政策制定者提供了新的见解，并为将来的跨模态和跨系统SDG应用奠定了基础。', 'title_zh': '基于大型语言模型的知识图谱系统构建：面向可持续发展目标的AI驱动推测性设计视角'}
