{'arxiv_id': 'arXiv:2510.05070', 'title': 'ResMimic: From General Motion Tracking to Humanoid Whole-body Loco-Manipulation via Residual Learning', 'authors': 'Siheng Zhao, Yanjie Ze, Yue Wang, C. Karen Liu, Pieter Abbeel, Guanya Shi, Rocky Duan', 'link': 'https://arxiv.org/abs/2510.05070', 'abstract': 'Humanoid whole-body loco-manipulation promises transformative capabilities for daily service and warehouse tasks. While recent advances in general motion tracking (GMT) have enabled humanoids to reproduce diverse human motions, these policies lack the precision and object awareness required for loco-manipulation. To this end, we introduce ResMimic, a two-stage residual learning framework for precise and expressive humanoid control from human motion data. First, a GMT policy, trained on large-scale human-only motion, serves as a task-agnostic base for generating human-like whole-body movements. An efficient but precise residual policy is then learned to refine the GMT outputs to improve locomotion and incorporate object interaction. To further facilitate efficient training, we design (i) a point-cloud-based object tracking reward for smoother optimization, (ii) a contact reward that encourages accurate humanoid body-object interactions, and (iii) a curriculum-based virtual object controller to stabilize early training. We evaluate ResMimic in both simulation and on a real Unitree G1 humanoid. Results show substantial gains in task success, training efficiency, and robustness over strong baselines. Videos are available at this https URL .', 'abstract_zh': 'humanoid全身移动与操作 promise 日常服务与仓储任务的变革能力。虽然近期对通用运动跟踪（GMT）的进展使类人机器人能够再现多种人类动作，但这些策略在移动操作中缺乏所需的精准度和物体意识。为此，我们引入了 ResMimic，这是一种基于人类动作数据的两阶段残差学习框架，以实现精确且表达力强的类人控制。首先，一个在大规模仅人类动作数据上训练的 GMT 策略充当通用任务基础，生成类似人类的全身动作。接着，学习一个高效且精确的残差策略来细化 GMT 输出，改善移动并整合物体交互。为了进一步促进高效训练，我们设计了 (i) 基于点云的目标追踪奖励以使优化更加平滑，(ii) 促进准确的人体-物体交互的接触奖励，以及 (iii) 基于课程的学习虚拟物体控制器以稳定早期训练。我们在仿真和实际的 Unitree G1 类人机器人上评估了 ResMimic 的性能。结果显示，与强大的基线模型相比，在任务成功率、训练效率和稳健性方面取得了显著提升。视频可在以下链接获取：this https URL。', 'title_zh': 'ResMimic: 从通用运动跟踪到类人全身运动操作的残差学习方法'}
{'arxiv_id': 'arXiv:2510.05061', 'title': 'Automaton Constrained Q-Learning', 'authors': 'Anastasios Manganaris, Vittorio Giammarino, Ahmed H. Qureshi', 'link': 'https://arxiv.org/abs/2510.05061', 'abstract': 'Real-world robotic tasks often require agents to achieve sequences of goals while respecting time-varying safety constraints. However, standard Reinforcement Learning (RL) paradigms are fundamentally limited in these settings. A natural approach to these problems is to combine RL with Linear-time Temporal Logic (LTL), a formal language for specifying complex, temporally extended tasks and safety constraints. Yet, existing RL methods for LTL objectives exhibit poor empirical performance in complex and continuous environments. As a result, no scalable methods support both temporally ordered goals and safety simultaneously, making them ill-suited for realistic robotics scenarios. We propose Automaton Constrained Q-Learning (ACQL), an algorithm that addresses this gap by combining goal-conditioned value learning with automaton-guided reinforcement. ACQL supports most LTL task specifications and leverages their automaton representation to explicitly encode stage-wise goal progression and both stationary and non-stationary safety constraints. We show that ACQL outperforms existing methods across a range of continuous control tasks, including cases where prior methods fail to satisfy either goal-reaching or safety constraints. We further validate its real-world applicability by deploying ACQL on a 6-DOF robotic arm performing a goal-reaching task in a cluttered, cabinet-like space with safety constraints. Our results demonstrate that ACQL is a robust and scalable solution for learning robotic behaviors according to rich temporal specifications.', 'abstract_zh': '实时机器人任务通常要求智能体在遵守时间变化的安全约束条件下实现一系列目标。然而，标准强化学习（RL）范式在这类设置中本质上是有限制的。将RL与线性时态逻辑（LTL）结合是一个自然的解决方案，LTL是一种用于描述复杂、时序扩展任务和安全约束的形式语言。然而，现有的针对LTL目标的RL方法在复杂和连续环境中表现出较差的经验性能。因此，目前没有可扩展的方法同时支持时序有序的目标和安全约束，使其不适合现实的机器人场景。我们提出了自动机约束Q-learning（ACQL）算法，该算法通过结合目标条件的价值学习和自动机引导的强化学习填补了这一空白。ACQL支持大多数LTL任务规范，并利用其自动机表示显式地编码阶段式目标进展以及静态和非静态的安全约束。我们展示了ACQL在一系列连续控制任务中优于现有方法，包括先前方法无法满足目标获取或安全约束的情况。我们进一步通过在包含安全约束的杂乱柜式空间中部署6-DOF机器人臂执行目标获取任务来验证其实际应用性。结果表明，ACQL是一种鲁棒且可扩展的解决方案，以用于根据丰富的时序规范学习机器人行为。', 'title_zh': '自动机约束的Q-learning'}
{'arxiv_id': 'arXiv:2510.05057', 'title': 'StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation', 'authors': 'Mingyu Liu, Jiuhe Shu, Hui Chen, Zeju Li, Canyu Zhao, Jiange Yang, Shenyuan Gao, Hao Chen, Chunhua Shen', 'link': 'https://arxiv.org/abs/2510.05057', 'abstract': 'A fundamental challenge in embodied intelligence is developing expressive and compact state representations for efficient world modeling and decision making. However, existing methods often fail to achieve this balance, yielding representations that are either overly redundant or lacking in task-critical information. We propose an unsupervised approach that learns a highly compressed two-token state representation using a lightweight encoder and a pre-trained Diffusion Transformer (DiT) decoder, capitalizing on its strong generative prior. Our representation is efficient, interpretable, and integrates seamlessly into existing VLA-based models, improving performance by 14.3% on LIBERO and 30% in real-world task success with minimal inference overhead. More importantly, we find that the difference between these tokens, obtained via latent interpolation, naturally serves as a highly effective latent action, which can be further decoded into executable robot actions. This emergent capability reveals that our representation captures structured dynamics without explicit supervision. We name our method StaMo for its ability to learn generalizable robotic Motion from compact State representation, which is encoded from static images, challenging the prevalent dependence to learning latent action on complex architectures and video data. The resulting latent actions also enhance policy co-training, outperforming prior methods by 10.4% with improved interpretability. Moreover, our approach scales effectively across diverse data sources, including real-world robot data, simulation, and human egocentric video.', 'abstract_zh': '一种体态智能的基本挑战是开发高效的简洁状态表示，以实现高效的世界建模和决策。现有的方法往往难以实现这一平衡，导致状态表示要么冗余过多，要么缺乏关键任务信息。我们提出一种无监督方法，利用轻量级编码器和预训练的扩散变压器（DiT）解码器学习高度压缩的两词元状态表示，利用其强大的生成先验。我们的表示方法高效、可解释，并能无缝集成到现有的基于VLA的模型中，在LIBERO上性能提升14.3%，在现实世界任务成功率上提升30%，且几乎没有任何推理开销。更重要的是，我们发现，通过潜在插值获得的这两个词元之间的差异自然地充当了一个高度有效的潜动作，可以进一步解码为可执行的机器人动作。这一新兴能力揭示了我们的表示方法能够在无需显式监督的情况下捕捉到结构化的动力学。我们将该方法命名为StaMo，强调其从静态图像中学习可泛化的机器人运动能力，挑战了学习潜动作对复杂架构和视频数据的依赖。生成的潜动作还增强了策略协同训练，在解释性增强的情况下优于先前的方法10.4%。此外，我们的方法能够有效地扩展到多种数据源，包括真实世界的机器人数据、仿真数据和人类主观视角视频。', 'title_zh': 'StaMo: 从紧凑状态表示中学习可泛化的机器人运动的无监督学习'}
{'arxiv_id': 'arXiv:2510.05001', 'title': 'Walking, Rolling, and Beyond: First-Principles and RL Locomotion on a TARS-Inspired Robot', 'authors': 'Aditya Sripada, Abhishek Warrier', 'link': 'https://arxiv.org/abs/2510.05001', 'abstract': "Robotic locomotion research typically draws from biologically inspired leg designs, yet many human-engineered settings can benefit from non-anthropomorphic forms. TARS3D translates the block-shaped 'TARS' robot from Interstellar into a 0.25 m, 0.99 kg research platform with seven actuated degrees of freedom. The film shows two primary gaits: a bipedal-like walk and a high-speed rolling mode. For TARS3D, we build reduced-order models for each, derive closed-form limit-cycle conditions, and validate the predictions on hardware. Experiments confirm that the robot respects its +/-150 degree hip limits, alternates left-right contacts without interference, and maintains an eight-step hybrid limit cycle in rolling mode. Because each telescopic leg provides four contact corners, the rolling gait is modeled as an eight-spoke double rimless wheel. The robot's telescopic leg redundancy implies a far richer gait repertoire than the two limit cycles treated analytically. So, we used deep reinforcement learning (DRL) in simulation to search the unexplored space. We observed that the learned policy can recover the analytic gaits under the right priors and discover novel behaviors as well. Our findings show that TARS3D's fiction-inspired bio-transcending morphology can realize multiple previously unexplored locomotion modes and that further learning-driven search is likely to reveal more. This combination of analytic synthesis and reinforcement learning opens a promising pathway for multimodal robotics.", 'abstract_zh': '基于《星际穿越》中TARS机器人的3D研究：从生物启发的腿设计到非anthropomorphic形态的转化', 'title_zh': '基于TARS启发的机器人第一性原理与RL行走与滚动及其扩展'}
{'arxiv_id': 'arXiv:2510.04991', 'title': 'Efficient Navigation in Unknown Indoor Environments with Vision-Language Models', 'authors': 'D. Schwartz, K. Kondo, J. P. How', 'link': 'https://arxiv.org/abs/2510.04991', 'abstract': 'We present a novel high-level planning framework that leverages vision-language models (VLMs) to improve autonomous navigation in unknown indoor environments with many dead ends. Traditional exploration methods often take inefficient routes due to limited global reasoning and reliance on local heuristics. In contrast, our approach enables a VLM to reason directly about an occupancy map in a zero-shot manner, selecting subgoals that are likely to lead to more efficient paths. At each planning step, we convert a 3D occupancy grid into a partial 2D map of the environment, and generate candidate subgoals. Each subgoal is then evaluated and ranked against other candidates by the model. We integrate this planning scheme into DYNUS \\cite{kondo2025dynus}, a state-of-the-art trajectory planner, and demonstrate improved navigation efficiency in simulation. The VLM infers structural patterns (e.g., rooms, corridors) from incomplete maps and balances the need to make progress toward a goal against the risk of entering unknown space. This reduces common greedy failures (e.g., detouring into small rooms) and achieves about 10\\% shorter paths on average.', 'abstract_zh': '一种利用视觉语言模型改进未知室内环境自主导航的新型高层次规划框架', 'title_zh': '使用视觉语言模型在未知室内环境中高效导航'}
{'arxiv_id': 'arXiv:2510.04898', 'title': 'HyperVLA: Efficient Inference in Vision-Language-Action Models via Hypernetworks', 'authors': 'Zheng Xiong, Kang Li, Zilin Wang, Matthew Jackson, Jakob Foerster, Shimon Whiteson', 'link': 'https://arxiv.org/abs/2510.04898', 'abstract': 'Built upon language and vision foundation models with strong generalization ability and trained on large-scale robotic data, Vision-Language-Action (VLA) models have recently emerged as a promising approach to learning generalist robotic policies. However, a key drawback of existing VLAs is their extremely high inference costs. In this paper, we propose HyperVLA to address this problem. Unlike existing monolithic VLAs that activate the whole model during both training and inference, HyperVLA uses a novel hypernetwork (HN)-based architecture that activates only a small task-specific policy during inference, while still retaining the high model capacity needed to accommodate diverse multi-task behaviors during training. Successfully training an HN-based VLA is nontrivial so HyperVLA contains several key algorithm design features that improve its performance, including properly utilizing the prior knowledge from existing vision foundation models, HN normalization, and an action generation strategy. Compared to monolithic VLAs, HyperVLA achieves a similar or even higher success rate for both zero-shot generalization and few-shot adaptation, while significantly reducing inference costs. Compared to OpenVLA, a state-of-the-art VLA model, HyperVLA reduces the number of activated parameters at test time by $90\\times$, and accelerates inference speed by $120\\times$. Code is publicly available at this https URL', 'abstract_zh': '基于强大泛化能力的语言和视觉基础模型以及大量机器人数据训练的Vision-Language-Action (VLA)模型近年来被视为学习通用机器人政策的一种前景广阔的approach。然而，现有VLAs的一个关键缺点是其极高的推理成本。本文提出HyperVLA以解决这一问题。与现有的一体化VLAs在训练和推理过程中激活整个模型不同，HyperVLA采用了一种新颖的基于超网络(HN)的架构，在推理过程中仅激活一个小的、特定于任务的策略，同时在训练过程中仍保持足够的模型容量以容纳多样化的多任务行为。成功训练基于HN的VLA并非易事，因此HyperVLA包含多项关键算法设计特征以提升其性能，包括合理利用现有的视觉基础模型的先验知识、超网络归一化以及动作生成策略。相比一体化VLAs，HyperVLA在零样本泛化和少量样本适应方面的成功率为相似甚至更高，同时显著降低了推理成本。与最先进的VLAs模型OpenVLA相比，HyperVLA测试时激活的参数数量减少了90倍，推理速度加快了120倍。代码已公开，详见这个网址。', 'title_zh': 'HyperVLA: 通过超网络在视觉-语言-行动模型中高效推理'}
{'arxiv_id': 'arXiv:2510.04883', 'title': 'CLEAR-IR: Clarity-Enhanced Active Reconstruction of Infrared Imagery', 'authors': 'Nathan Shankar, Pawel Ladosz, Hujun Yin', 'link': 'https://arxiv.org/abs/2510.04883', 'abstract': 'This paper presents a novel approach for enabling robust robotic perception in dark environments using infrared (IR) stream. IR stream is less susceptible to noise than RGB in low-light conditions. However, it is dominated by active emitter patterns that hinder high-level tasks such as object detection, tracking and localisation. To address this, a U-Net-based architecture is proposed that reconstructs clean IR images from emitter-populated input, improving both image quality and downstream robotic performance. This approach outperforms existing enhancement techniques and enables reliable operation of vision-driven robotic systems across illumination conditions from well-lit to extreme low-light scenes.', 'abstract_zh': '利用红外流在暗环境下实现稳健的机器人感知的新方法', 'title_zh': 'CLEAR-IR: 光学清晰度增强的主动红外成像重构'}
{'arxiv_id': 'arXiv:2510.04839', 'title': 'TAG-K: Tail-Averaged Greedy Kaczmarz for Computationally Efficient and Performant Online Inertial Parameter Estimation', 'authors': 'Shuo Sha, Anupam Bhakta, Zhenyuan Jiang, Kevin Qiu, Ishaan Mahajan, Gabriel Bravo, Brian Plancher', 'link': 'https://arxiv.org/abs/2510.04839', 'abstract': 'Accurate online inertial parameter estimation is essential for adaptive robotic control, enabling real-time adjustment to payload changes, environmental interactions, and system wear. Traditional methods such as Recursive Least Squares (RLS) and the Kalman Filter (KF) often struggle to track abrupt parameter shifts or incur high computational costs, limiting their effectiveness in dynamic environments and for computationally constrained robotic systems. As such, we introduce TAG-K, a lightweight extension of the Kaczmarz method that combines greedy randomized row selection for rapid convergence with tail averaging for robustness under noise and inconsistency. This design enables fast, stable parameter adaptation while retaining the low per-iteration complexity inherent to the Kaczmarz framework. We evaluate TAG-K in synthetic benchmarks and quadrotor tracking tasks against RLS, KF, and other Kaczmarz variants. TAG-K achieves 1.5x-1.9x faster solve times on laptop-class CPUs and 4.8x-20.7x faster solve times on embedded microcontrollers. More importantly, these speedups are paired with improved resilience to measurement noise and a 25% reduction in estimation error, leading to nearly 2x better end-to-end tracking performance.', 'abstract_zh': '准确的在线惯性参数估计对于自适应机器人控制至关重要，能够实现实时调整载荷变化、环境交互和系统磨损。传统方法如递推最小二乘法（RLS）和卡尔曼滤波器（KF）往往难以追踪参数的突变或产生高计算成本，限制了它们在动态环境和计算受限的机器人系统中的有效性。因此，我们引入了TAG-K，这是一种轻量级的Kaczmarz方法扩展，结合了贪婪随机行选择以实现快速收敛，并使用尾端平均以增强抗噪和一致性能力。这种设计能够实现快速稳定地参数适应，同时保留Kaczmarz框架固有的每迭代低复杂度。我们通过合成基准和旋翼无人机跟踪任务将TAG-K与RLS、KF以及其他Kaczmarz变种进行了对比评估。在笔记本级别CPU上，TAG-K的求解时间快1.5至1.9倍，在嵌入式微控制器上快4.8至20.7倍。更重要的是，这些加速与对测量噪声的改进抵抗力和25%的估计误差降低相结合，导致端到端跟踪性能提高了近2倍。', 'title_zh': 'TAG-K: 基于尾平均贪婪Kaczmarz的高效高性能在线惯性参数估计'}
{'arxiv_id': 'arXiv:2510.04774', 'title': 'Online automatic code generation for robot swarms: LLMs and self-organizing hierarchy', 'authors': 'Weixu Zhu, Marco Dorigo, Mary Katherine Heinrich', 'link': 'https://arxiv.org/abs/2510.04774', 'abstract': 'Our recently introduced self-organizing nervous system (SoNS) provides robot swarms with 1) ease of behavior design and 2) global estimation of the swarm configuration and its collective environment, facilitating the implementation of online automatic code generation for robot swarms. In a demonstration with 6 real robots and simulation trials with >30 robots, we show that when a SoNS-enhanced robot swarm gets stuck, it can automatically solicit and run code generated by an external LLM on the fly, completing its mission with an 85% success rate.', 'abstract_zh': '我们最近引入的自我组织神经系统（SoNS）为机器人群提供了1）易于行为设计和2）全局估计群集配置及其集体环境的功能，促进了机器人群的在线自动代码生成的实施。在使用6个真实机器人和超过30个机器人的模拟试验中，我们演示了当一个增强SoNS的机器人群陷入困境时，它可以自动请求并运行由外部LLM生成的代码，成功完成其任务的比例为85%。', 'title_zh': '基于LLMs和自组织层次结构的机器人集群在线自动代码生成'}
{'arxiv_id': 'arXiv:2510.04724', 'title': 'Performance-guided Task-specific Optimization for Multirotor Design', 'authors': 'Etor Arza, Welf Rehberg, Philipp Weiss, Mihir Kulkarni, Kostas Alexis', 'link': 'https://arxiv.org/abs/2510.04724', 'abstract': 'This paper introduces a methodology for task-specific design optimization of multirotor Micro Aerial Vehicles. By leveraging reinforcement learning, Bayesian optimization, and covariance matrix adaptation evolution strategy, we optimize aerial robot designs guided exclusively by their closed-loop performance in a considered task. Our approach systematically explores the design space of motor pose configurations while ensuring manufacturability constraints and minimal aerodynamic interference. Results demonstrate that optimized designs achieve superior performance compared to conventional multirotor configurations in agile waypoint navigation tasks, including against fully actuated designs from the literature. We build and test one of the optimized designs in the real world to validate the sim2real transferability of our approach.', 'abstract_zh': '本文介绍了一种多旋翼微空中车辆任务特定设计优化的方法。通过利用强化学习、贝叶斯优化和协方差矩阵自适应进化策略，我们以考虑任务的闭环性能为唯一依据优化空中机器人设计。该方法系统地探索了电机姿态配置的设计空间，同时确保制造约束条件并尽量减少气动干扰。结果表明，优化设计在敏捷航点导航任务中性能优于传统多旋翼配置，包括文献中完全可驱动的设计。我们构建并测试了一个优化设计的实际模型，以验证我们方法的仿真实验转移性。', 'title_zh': '基于性能导向的任务特定优化的多旋翼设计'}
{'arxiv_id': 'arXiv:2510.04696', 'title': 'Building Gradient by Gradient: Decentralised Energy Functions for Bimanual Robot Assembly', 'authors': 'Alexander L. Mitchell, Joe Watson, Ingmar Posner', 'link': 'https://arxiv.org/abs/2510.04696', 'abstract': 'There are many challenges in bimanual assembly, including high-level sequencing, multi-robot coordination, and low-level, contact-rich operations such as component mating. Task and motion planning (TAMP) methods, while effective in this domain, may be prohibitively slow to converge when adapting to disturbances that require new task sequencing and optimisation. These events are common during tight-tolerance assembly, where difficult-to-model dynamics such as friction or deformation require rapid replanning and reattempts. Moreover, defining explicit task sequences for assembly can be cumbersome, limiting flexibility when task replanning is required. To simplify this planning, we introduce a decentralised gradient-based framework that uses a piecewise continuous energy function through the automatic composition of adaptive potential functions. This approach generates sub-goals using only myopic optimisation, rather than long-horizon planning. It demonstrates effectiveness at solving long-horizon tasks due to the structure and adaptivity of the energy function. We show that our approach scales to physical bimanual assembly tasks for constructing tight-tolerance assemblies. In these experiments, we discover that our gradient-based rapid replanning framework generates automatic retries, coordinated motions and autonomous handovers in an emergent fashion.', 'abstract_zh': '双臂装配中的挑战及其分布式梯度基规划方法', 'title_zh': '建立梯度以梯度为基础：双臂机器人装配的去中心化能量函数'}
{'arxiv_id': 'arXiv:2510.04692', 'title': 'Bio-Inspired Robotic Houbara: From Development to Field Deployment for Behavioral Studies', 'authors': 'Lyes Saad Saoud, Irfan Hussain', 'link': 'https://arxiv.org/abs/2510.04692', 'abstract': "Biomimetic intelligence and robotics are transforming field ecology by enabling lifelike robotic surrogates that interact naturally with animals under real world conditions. Studying avian behavior in the wild remains challenging due to the need for highly realistic morphology, durable outdoor operation, and intelligent perception that can adapt to uncontrolled environments. We present a next generation bio inspired robotic platform that replicates the morphology and visual appearance of the female Houbara bustard to support controlled ethological studies and conservation oriented field research. The system introduces a fully digitally replicable fabrication workflow that combines high resolution structured light 3D scanning, parametric CAD modelling, articulated 3D printing, and photorealistic UV textured vinyl finishing to achieve anatomically accurate and durable robotic surrogates. A six wheeled rocker bogie chassis ensures stable mobility on sand and irregular terrain, while an embedded NVIDIA Jetson module enables real time RGB and thermal perception, lightweight YOLO based detection, and an autonomous visual servoing loop that aligns the robot's head toward detected targets without human intervention. A lightweight thermal visible fusion module enhances perception in low light conditions. Field trials in desert aviaries demonstrated reliable real time operation at 15 to 22 FPS with latency under 100 ms and confirmed that the platform elicits natural recognition and interactive responses from live Houbara bustards under harsh outdoor conditions. This integrated framework advances biomimetic field robotics by uniting reproducible digital fabrication, embodied visual intelligence, and ecological validation, providing a transferable blueprint for animal robot interaction research, conservation robotics, and public engagement.", 'abstract_zh': '仿生智能与机器人技术正在通过实现与真实环境条件下自然互动的生物似 Robbie 器官能改变田野生态学。由于需要高度现实的形态、耐用的户外操作以及能够适应未受控环境的智能感知，研究野生鸟类的行为依然具有挑战性。我们提出了一种下一代受生物启发的机器人平台，该平台复制了胡巴伯沙ibia雌鸟的形态和视觉外观，以支持受控的生态学研究和以保护为目标的实地研究。该系统引入了一个完全数字化可复制的制造工作流程，结合了高分辨率结构光3D扫描、参数化CAD建模、联动3D打印和逼真UV纹理乙烯基地板饰面，以实现解剖学准确且耐用的机器人器官。六轮摇臂底盘确保在沙地和不规则地形上的稳定移动，内置的NVIDIA Jetson模块实现了实时RGB和热成像感知、轻量级YOLO基于检测以及无需人工干预即可对准机器人头部的自主视觉伺服循环。轻量级的热成像可见光融合模块在低光条件下增强了感知。在沙漠鸟舍的实地试验中，该平台在15到22 FPS下显示了可靠的实时操作，延迟低于100毫秒，并证实该平台在严苛的户外环境中能够引发胡巴伯沙ilia雌鸟的自然识别和互动反应。该综合框架通过将可重复的数字化制造、嵌入式视觉智能和生态验证相结合，推动了仿生领域机器人技术的发展，为动物机器人互动研究、保护机器人技术和公众参与提供了可转移的设计蓝本。', 'title_zh': '生物启发的 Houbara 机器人：从开发到实地部署的行为研究'}
{'arxiv_id': 'arXiv:2510.04612', 'title': 'OKVIS2-X: Open Keyframe-based Visual-Inertial SLAM Configurable with Dense Depth or LiDAR, and GNSS', 'authors': 'Simon Boche, Jaehyung Jung, Sebastián Barbas Laina, Stefan Leutenegger', 'link': 'https://arxiv.org/abs/2510.04612', 'abstract': 'To empower mobile robots with usable maps as well as highest state estimation accuracy and robustness, we present OKVIS2-X: a state-of-the-art multi-sensor Simultaneous Localization and Mapping (SLAM) system building dense volumetric occupancy maps, while scalable to large environments and operating in realtime. Our unified SLAM framework seamlessly integrates different sensor modalities: visual, inertial, measured or learned depth, LiDAR and Global Navigation Satellite System (GNSS) measurements. Unlike most state-of-the-art SLAM systems, we advocate using dense volumetric map representations when leveraging depth or range-sensing capabilities. We employ an efficient submapping strategy that allows our system to scale to large environments, showcased in sequences of up to 9 kilometers. OKVIS2-X enhances its accuracy and robustness by tightly-coupling the estimator and submaps through map alignment factors. Our system provides globally consistent maps, directly usable for autonomous navigation. To further improve the accuracy of OKVIS2-X, we also incorporate the option of performing online calibration of camera extrinsics. Our system achieves the highest trajectory accuracy in EuRoC against state-of-the-art alternatives, outperforms all competitors in the Hilti22 VI-only benchmark, while also proving competitive in the LiDAR version, and showcases state of the art accuracy in the diverse and large-scale sequences from the VBR dataset.', 'abstract_zh': 'OKVIS2-X：一种构建稠密体占图的高性能多传感器SLAM系统', 'title_zh': 'OKVIS2-X：基于开放关键帧的视觉-惯性SLAM，支持密集深度或LiDAR及GNSS配置'}
{'arxiv_id': 'arXiv:2510.04592', 'title': 'MobRT: A Digital Twin-Based Framework for Scalable Learning in Mobile Manipulation', 'authors': 'Yilin Mei, Peng Qiu, Wei Zhang, WenChao Zhang, Wenjie Song', 'link': 'https://arxiv.org/abs/2510.04592', 'abstract': 'Recent advances in robotics have been largely driven by imitation learning, which depends critically on large-scale, high-quality demonstration data. However, collecting such data remains a significant challenge-particularly for mobile manipulators, which must coordinate base locomotion and arm manipulation in high-dimensional, dynamic, and partially observable environments. Consequently, most existing research remains focused on simpler tabletop scenarios, leaving mobile manipulation relatively underexplored. To bridge this gap, we present \\textit{MobRT}, a digital twin-based framework designed to simulate two primary categories of complex, whole-body tasks: interaction with articulated objects (e.g., opening doors and drawers) and mobile-base pick-and-place operations. \\textit{MobRT} autonomously generates diverse and realistic demonstrations through the integration of virtual kinematic control and whole-body motion planning, enabling coherent and physically consistent execution. We evaluate the quality of \\textit{MobRT}-generated data across multiple baseline algorithms, establishing a comprehensive benchmark and demonstrating a strong correlation between task success and the number of generated trajectories. Experiments integrating both simulated and real-world demonstrations confirm that our approach markedly improves policy generalization and performance, achieving robust results in both simulated and real-world environments.', 'abstract_zh': '最近机器人领域的进展很大程度上得益于模仿学习，这依赖于大规模、高质量示范数据。然而，收集这类数据仍然是一个重大挑战，尤其是在移动 manipulator 的情况下，它们必须在高维度、动态且部分可观测的环境中协调底座移动和手臂操作。因此，现有的大多数研究仍然集中在较为简单的桌面场景上，移动 manipulation 仍然相对未被充分探索。为弥补这一缺口，我们提出了 MobRT，一个基于数字孪生的框架，旨在模拟两类复杂的整体任务：与运动物体的交互（例如，开 door 和 drawer）和移动底座抓取-放置操作。MobRT 通过整合虚拟运动控制和整体运动规划，自主生成多样且真实的示范，实现统一且物理一致的执行。我们利用多种基线算法评估 MobRT 生成数据的质量，建立了全面的基准，并展示了任务成功率与生成轨迹数量之间的强烈关联。结合仿真和现实世界示范的实验确认，我们的方法显著提高了策略的泛化能力和性能，在仿真和现实世界环境中均取得了稳健的结果。', 'title_zh': 'MobRT：基于数字孪生的移动 manipulation 可扩展学习框架'}
{'arxiv_id': 'arXiv:2510.04585', 'title': 'Everything-Grasping (EG) Gripper: A Universal Gripper with Synergistic Suction-Grasping Capabilities for Cross-Scale and Cross-State Manipulation', 'authors': 'Jianshu Zhou, Jing Shu, Tianle Pan, Puchen Zhu, Jiajun An, Huayu Zhang, Junda Huang, Upinder Kaur, Xin Ma, Masayoshi Tomizuka', 'link': 'https://arxiv.org/abs/2510.04585', 'abstract': 'Grasping objects across vastly different sizes and physical states-including both solids and liquids-with a single robotic gripper remains a fundamental challenge in soft robotics. We present the Everything-Grasping (EG) Gripper, a soft end-effector that synergistically integrates distributed surface suction with internal granular jamming, enabling cross-scale and cross-state manipulation without requiring airtight sealing at the contact interface with target objects. The EG Gripper can handle objects with surface areas ranging from sub-millimeter scale 0.2 mm2 (glass bead) to over 62,000 mm2 (A4 sized paper and woven bag), enabling manipulation of objects nearly 3,500X smaller and 88X larger than its own contact area (approximated at 707 mm2 for a 30 mm-diameter base). We further introduce a tactile sensing framework that combines liquid detection and pressure-based suction feedback, enabling real-time differentiation between solid and liquid targets. Guided by the actile-Inferred Grasping Mode Selection (TIGMS) algorithm, the gripper autonomously selects grasping modes based on distributed pressure and voltage signals. Experiments across diverse tasks-including underwater grasping, fragile object handling, and liquid capture-demonstrate robust and repeatable performance. To our knowledge, this is the first soft gripper to reliably grasp both solid and liquid objects across scales using a unified compliant architecture.', 'abstract_zh': 'Everything-Grasping (EG) 柔性夹持器：跨越不同尺寸和物理状态抓取固体和液体物体', 'title_zh': 'Everything-抓取（EG）夹持器：一种具备协同吸抓能力的通用跨尺度跨状态操作夹持器'}
{'arxiv_id': 'arXiv:2510.04509', 'title': 'Velocity-Form Data-Enabled Predictive Control of Soft Robots under Unknown External Payloads', 'authors': 'Huanqing Wang, Kaixiang Zhang, Kyungjoon Lee, Yu Mei, Vaibhav Srivastava, Jun Sheng, Ziyou Song, Zhaojian Li', 'link': 'https://arxiv.org/abs/2510.04509', 'abstract': 'Data-driven control methods such as data-enabled predictive control (DeePC) have shown strong potential in efficient control of soft robots without explicit parametric models. However, in object manipulation tasks, unknown external payloads and disturbances can significantly alter the system dynamics and behavior, leading to offset error and degraded control performance. In this paper, we present a novel velocity-form DeePC framework that achieves robust and optimal control of soft robots under unknown payloads. The proposed framework leverages input-output data in an incremental representation to mitigate performance degradation induced by unknown payloads, eliminating the need for weighted datasets or disturbance estimators. We validate the method experimentally on a planar soft robot and demonstrate its superior performance compared to standard DeePC in scenarios involving unknown payloads.', 'abstract_zh': '数据驱动的控制方法，如数据启用的预测控制（DeePC），在无需显式参数模型的情况下有效地控制软机器人方面展示了强大的潜力。然而，在物体操作任务中，未知的外部载荷和干扰可以显著改变系统动力学和行为，导致偏移误差和控制性能下降。本文提出了一种新的基于速度形式的DeePC框架，能够在未知载荷下实现软机器人的鲁棒和最优控制。所提出的方法利用增量表示的输入-输出数据来减轻由未知载荷引起的性能下降，消除了对加权数据集或干扰估计器的需求。我们通过平面软机器人的实验验证了该方法，并在涉及未知载荷的场景中展示了其优于标准DeePC的性能。', 'title_zh': '未知外部载荷下基于速度形式数据驱动的软机器人预测控制'}
{'arxiv_id': 'arXiv:2510.04436', 'title': 'PAD-TRO: Projection-Augmented Diffusion for Direct Trajectory Optimization', 'authors': 'Jushan Chen, Santiago Paternain', 'link': 'https://arxiv.org/abs/2510.04436', 'abstract': 'Recently, diffusion models have gained popularity and attention in trajectory optimization due to their capability of modeling multi-modal probability distributions. However, addressing nonlinear equality constraints, i.e, dynamic feasi- bility, remains a great challenge in diffusion-based trajectory optimization. Recent diffusion-based trajectory optimization frameworks rely on a single-shooting style approach where the denoised control sequence is applied to forward propagate the dynamical system, which cannot explicitly enforce constraints on the states and frequently leads to sub-optimal solutions. In this work, we propose a novel direct trajectory optimization approach via model-based diffusion, which directly generates a sequence of states. To ensure dynamic feasibility, we propose a gradient-free projection mechanism that is incorporated into the reverse diffusion process. Our results show that, compared to a recent state-of-the-art baseline, our approach leads to zero dynamic feasibility error and approximately 4x higher success rate in a quadrotor waypoint navigation scenario involving dense static obstacles.', 'abstract_zh': '基于模型的扩散模型在动态可行性的直接轨迹优化方法', 'title_zh': 'PAD-TRO: 投影增强扩散直接轨迹优化'}
{'arxiv_id': 'arXiv:2510.04354', 'title': 'Reliable and Scalable Robot Policy Evaluation with Imperfect Simulators', 'authors': "Apurva Badithela, David Snyder, Lihan Zha, Joseph Mikhail, Matthew O'Kelly, Anushri Dixit, Anirudha Majumdar", 'link': 'https://arxiv.org/abs/2510.04354', 'abstract': 'Rapid progress in imitation learning, foundation models, and large-scale datasets has led to robot manipulation policies that generalize to a wide-range of tasks and environments. However, rigorous evaluation of these policies remains a challenge. Typically in practice, robot policies are often evaluated on a small number of hardware trials without any statistical assurances. We present SureSim, a framework to augment large-scale simulation with relatively small-scale real-world testing to provide reliable inferences on the real-world performance of a policy. Our key idea is to formalize the problem of combining real and simulation evaluations as a prediction-powered inference problem, in which a small number of paired real and simulation evaluations are used to rectify bias in large-scale simulation. We then leverage non-asymptotic mean estimation algorithms to provide confidence intervals on mean policy performance. Using physics-based simulation, we evaluate both diffusion policy and multi-task fine-tuned \\(\\pi_0\\) on a joint distribution of objects and initial conditions, and find that our approach saves over \\(20-25\\%\\) of hardware evaluation effort to achieve similar bounds on policy performance.', 'abstract_zh': '仿生学习、基础模型和大规模数据集的快速进展已使机器人操作策略能够泛化到广泛的任务和环境。然而，这些策略的实际评估仍存在挑战。通常情况下，机器人策略在实践中仅通过少量的硬件试验进行评估，缺乏统计保证。我们提出了SureSim框架，通过结合大规模模拟与小型规模的真实世界测试，为政策在实际环境中的性能提供可靠的推断。我们的核心思想是将真实与模拟评估的结合形式化为一个预测驱动的推理问题，在其中少量配对的真实和模拟评估被用于修正大规模模拟中的偏差。我们随后利用非渐近均值估计算法为均值政策性能提供置信区间。使用基于物理的模拟，我们在对象和初始条件的联合分布上评估了扩散策略和多任务微调的\\(\\pi_0\\)，发现我们的方法在实现类似政策性能边界的同时，节省了超过20-25%的硬件评估工作量。', 'title_zh': '不可靠模拟器条件下可信赖且可扩展的机器人策略评估'}
{'arxiv_id': 'arXiv:2510.04353', 'title': 'Stability-Aware Retargeting for Humanoid Multi-Contact Teleoperation', 'authors': 'Stephen McCrory, Romeo Orsolino, Dhruv Thanki, Luigi Penco, Robert Griffin', 'link': 'https://arxiv.org/abs/2510.04353', 'abstract': 'Teleoperation is a powerful method to generate reference motions and enable humanoid robots to perform a broad range of tasks. However, teleoperation becomes challenging when using hand contacts and non-coplanar surfaces, often leading to motor torque saturation or loss of stability through slipping. We propose a centroidal stability-based retargeting method that dynamically adjusts contact points and posture during teleoperation to enhance stability in these difficult scenarios. Central to our approach is an efficient analytical calculation of the stability margin gradient. This gradient is used to identify scenarios for which stability is highly sensitive to teleoperation setpoints and inform the local adjustment of these setpoints. We validate the framework in simulation and hardware by teleoperating manipulation tasks on a humanoid, demonstrating increased stability margins. We also demonstrate empirically that higher stability margins correlate with improved impulse resilience and joint torque margin.', 'abstract_zh': '基于质心稳定性的遥操作目标转换方法：在手部接触和非共面表面场景中动态调整接触点和姿态以增强稳定性', 'title_zh': '稳定性意识的人形多接触远程操控调整'}
{'arxiv_id': 'arXiv:2510.04278', 'title': 'Integrated Planning and Control on Manifolds: Factor Graph Representation and Toolkit', 'authors': 'Peiwen Yang, Weisong Wen, Runqiu Yang, Yuanyuan Zhang, Jiahao Hu, Yingming Chen, Naigui Xiao, Jiaqi Zhao', 'link': 'https://arxiv.org/abs/2510.04278', 'abstract': 'Model predictive control (MPC) faces significant limitations when applied to systems evolving on nonlinear manifolds, such as robotic attitude dynamics and constrained motion planning, where traditional Euclidean formulations struggle with singularities, over-parameterization, and poor convergence. To overcome these challenges, this paper introduces FactorMPC, a factor-graph based MPC toolkit that unifies system dynamics, constraints, and objectives into a modular, user-friendly, and efficient optimization structure. Our approach natively supports manifold-valued states with Gaussian uncertainties modeled in tangent spaces. By exploiting the sparsity and probabilistic structure of factor graphs, the toolkit achieves real-time performance even for high-dimensional systems with complex constraints. The velocity-extended on-manifold control barrier function (CBF)-based obstacle avoidance factors are designed for safety-critical applications. By bridging graphical models with safety-critical MPC, our work offers a scalable and geometrically consistent framework for integrated planning and control. The simulations and experimental results on the quadrotor demonstrate superior trajectory tracking and obstacle avoidance performance compared to baseline methods. To foster research reproducibility, we have provided open-source implementation offering plug-and-play factors.', 'abstract_zh': '基于因子图的模型预测控制（FactorMPC）：统一流动态、约束和目标的模块化优化结构', 'title_zh': '流形上的集成规划与控制：因子图表示与工具包'}
{'arxiv_id': 'arXiv:2510.04246', 'title': 'ContextVLA: Vision-Language-Action Model with Amortized Multi-Frame Context', 'authors': 'Huiwon Jang, Sihyun Yu, Heeseung Kwon, Hojin Jeon, Younggyo Seo, Jinwoo Shin', 'link': 'https://arxiv.org/abs/2510.04246', 'abstract': "Leveraging temporal context is crucial for success in partially observable robotic tasks. However, prior work in behavior cloning has demonstrated inconsistent performance gains when using multi-frame observations. In this paper, we introduce ContextVLA, a policy model that robustly improves robotic task performance by effectively leveraging multi-frame observations. Our approach is motivated by the key observation that Vision-Language-Action models (VLA), i.e., policy models built upon a Vision-Language Model (VLM), more effectively utilize multi-frame observations for action generation. This suggests that VLMs' inherent temporal understanding capability enables them to extract more meaningful context from multi-frame observations. However, the high dimensionality of video inputs introduces significant computational overhead, making VLA training and inference inefficient. To address this, ContextVLA compresses past observations into a single context token, allowing the policy to efficiently leverage temporal context for action generation. Our experiments show that ContextVLA consistently improves over single-frame VLAs and achieves the benefits of full multi-frame training but with reduced training and inference times.", 'abstract_zh': '利用时间上下文对于部分可观测机器人任务的成功至关重要。然而，先前的行为克隆工作中在使用多帧观察时显示出不一致的性能提升。本文介绍了ContextVLA，这是一种通过有效利用多帧观察来稳健地提高机器人任务性能的策略模型。我们的方法受到一个关键观察的启发，即视觉-语言-动作模型（VLA），即基于视觉-语言模型（VLM）构建的策略模型，能够更有效地利用多帧观察进行行动生成。这表明VLMs固有的时间理解能力使它们能够从多帧观察中提取更有意义的上下文。然而，视频输入的高维度引入了显著的计算开销，使得VLA的训练和推理效率低下。为了解决这一问题，ContextVLA 将过去的观察压缩为单个上下文标记，从而使策略能够高效地利用时间上下文进行行动生成。我们的实验表明，ContextVLA 一致地优于单帧VLA，并在减少训练和推理时间的同时获得了全多帧训练的好处。', 'title_zh': 'ContextVLA：带有折旧多帧上下文的视觉-语言-动作模型'}
{'arxiv_id': 'arXiv:2510.04234', 'title': 'Flexible Locomotion Learning with Diffusion Model Predictive Control', 'authors': 'Runhan Huang, Haldun Balim, Heng Yang, Yilun Du', 'link': 'https://arxiv.org/abs/2510.04234', 'abstract': 'Legged locomotion demands controllers that are both robust and adaptable, while remaining compatible with task and safety considerations. However, model-free reinforcement learning (RL) methods often yield a fixed policy that can be difficult to adapt to new behaviors at test time. In contrast, Model Predictive Control (MPC) provides a natural approach to flexible behavior synthesis by incorporating different objectives and constraints directly into its optimization process. However, classical MPC relies on accurate dynamics models, which are often difficult to obtain in complex environments and typically require simplifying assumptions. We present Diffusion-MPC, which leverages a learned generative diffusion model as an approximate dynamics prior for planning, enabling flexible test-time adaptation through reward and constraint based optimization. Diffusion-MPC jointly predicts future states and actions; at each reverse step, we incorporate reward planning and impose constraint projection, yielding trajectories that satisfy task objectives while remaining within physical limits. To obtain a planning model that adapts beyond imitation pretraining, we introduce an interactive training algorithm for diffusion based planner: we execute our reward-and-constraint planner in environment, then filter and reweight the collected trajectories by their realized returns before updating the denoiser. Our design enables strong test-time adaptability, allowing the planner to adjust to new reward specifications without retraining. We validate Diffusion-MPC on real world, demonstrating strong locomotion and flexible adaptation.', 'abstract_zh': '基于扩散模型的模型预测控制：兼容鲁棒性、适应性和安全性的腿足运动控制器', 'title_zh': '基于扩散模型预测控制的灵活运动学习'}
{'arxiv_id': 'arXiv:2510.04190', 'title': 'Zenbo Patrol: A Social Assistive Robot Based on Multimodal Deep Learning for Real-time Illegal Parking Recognition and Notification', 'authors': 'Jian-jie Zheng, Chih-kai Yang, Po-han Chen, Lyn Chao-ling Chen', 'link': 'https://arxiv.org/abs/2510.04190', 'abstract': 'In the study, the social robot act as a patrol to recognize and notify illegal parking in real-time. Dual-model pipeline method and large multimodal model were compared, and the GPT-4o multimodal model was adopted in license plate recognition without preprocessing. For moving smoothly on a flat ground, the robot navigated in a simulated parking lot in the experiments. The robot changes angle view of the camera automatically to capture the images around with the format of license plate number. From the captured images of the robot, the numbers on the plate are recognized through the GPT-4o model, and identifies legality of the numbers. When an illegal parking is detected, the robot sends Line messages to the system manager immediately. The contribution of the work is that a novel multimodal deep learning method has validated with high accuracy in license plate recognition, and a social assistive robot is also provided for solving problems in a real scenario, and can be applied in an indoor parking lot.', 'abstract_zh': '在研究中，社会机器人作为巡逻员实现实时识别和通知非法停车。对比了双模态管道方法和大型多模态模型，并在车牌识别中采用了无需预处理的GPT-4o多模态模型。为了在平坦地面上顺畅移动，机器人在实验中导航于模拟停车场中。机器人自动调整摄像头视角以捕捉带有车牌号格式的图像。通过GPT-4o模型识别机器人捕获的图像中的车牌号码，并判定其合法性。检测到非法停车时，机器人会立即向系统管理员发送Line消息。该工作的贡献在于，一种新颖的多模态深度学习方法在车牌识别中得到了高精度验证，并提供了一种用于解决实际场景问题的社会辅助机器人，可以在室内停车场应用。', 'title_zh': 'Zenbo巡逻：基于多模态深度学习的社会辅助机器人及其在实时非法停车识别与通知中的应用'}
{'arxiv_id': 'arXiv:2510.04178', 'title': 'Using Robotics to Improve Transcatheter Edge-to-Edge Repair of the Mitral Valve', 'authors': 'Léa Pistorius, Namrata U. Nayar, Phillip Tran, Sammy Elmariah, Pierre E. Dupont', 'link': 'https://arxiv.org/abs/2510.04178', 'abstract': 'Transcatheter valve repair presents significant challenges due to the mechanical limitations and steep learning curve associated with manual catheter systems. This paper investigates the use of robotics to facilitate transcatheter procedures in the context of mitral valve edge-to-edge repair. The complex handle-based control of a clinical repair device is replaced by intuitive robotic joint-based control via a game controller. Manual versus robotic performance is analyzed by decomposing the overall device delivery task into motion-specific steps and comparing capabilities on a step-by-step basis in a phantom model of the heart and vasculature. Metrics include procedure duration and clip placement accuracy. Results demonstrate that the robotic system can reduce procedural time and motion errors while also improving accuracy of clip placement. These findings suggest that robotic assistance can address key limitations of manual systems, offering a more reliable and user-friendly platform for complex transcatheter procedures.', 'abstract_zh': '经导管瓣膜修复因手动导管系统存在的机械限制和陡峭的学习曲线而面临重大挑战。本论文探讨了使用机器人技术来辅助经导管Mitral瓣环对合修复手术。基于复杂手柄控制的临床修复设备被通过游戏控制器实现的直观机器人关节控制所取代。通过在心脏和血管的人体模型中逐步比较手动与机器人操作的性能，分析了整体设备递送任务。评价指标包括手术时间及夹子放置精度。结果表明，机器人系统能够减少手术时间并降低运动误差，同时提高夹子放置的准确性。这些发现表明，机器人辅助可以解决手动系统的关键限制，提供一个更可靠且用户友好的平台，以进行复杂的经导管手术。', 'title_zh': '使用机器人技术提高经导管二尖瓣边缘对边修复效果'}
{'arxiv_id': 'arXiv:2510.04171', 'title': 'VBM-NET: Visual Base Pose Learning for Mobile Manipulation using Equivariant TransporterNet and GNNs', 'authors': 'Lakshadeep Naik, Adam Fischer, Daniel Duberg, Danica Kragic', 'link': 'https://arxiv.org/abs/2510.04171', 'abstract': 'In Mobile Manipulation, selecting an optimal mobile base pose is essential for successful object grasping. Previous works have addressed this problem either through classical planning methods or by learning state-based policies. They assume access to reliable state information, such as the precise object poses and environment models. In this work, we study base pose planning directly from top-down orthographic projections of the scene, which provide a global overview of the scene while preserving spatial structure. We propose VBM-NET, a learning-based method for base pose selection using such top-down orthographic projections. We use equivariant TransporterNet to exploit spatial symmetries and efficiently learn candidate base poses for grasping. Further, we use graph neural networks to represent a varying number of candidate base poses and use Reinforcement Learning to determine the optimal base pose among them. We show that VBM-NET can produce comparable solutions to the classical methods in significantly less computation time. Furthermore, we validate sim-to-real transfer by successfully deploying a policy trained in simulation to real-world mobile manipulation.', 'abstract_zh': '移动 manipulations 中，选择最优移动基座姿态对于成功抓取物体至关重要。以往工作通过经典规划方法或基于状态的策略学习来解决该问题，它们假设可以获得可靠的环境信息，如精确的物体姿态和环境模型。在本工作中，我们直接从场景的上方正交投影中研究基座姿态规划，这些投影提供了场景的全局概览同时保留了空间结构。我们提出了 VBM-NET，一种基于学习的基座姿态选择方法，使用此类上方正交投影。我们利用不变 TransporterNet 利用空间对称性并高效地学习候选基座姿态。进一步地，我们使用图神经网络表示不同数量的候选基座姿态，并使用强化学习确定这些候选基座姿态中的最优姿态。我们展示了 VBM-NET 在显著减少计算时间的情况下可以产生与经典方法相当的解决方案。此外，我们通过成功将仿真中训练的策略部署到实际移动 manipulation 中验证了从仿真到现实的迁移能力。', 'title_zh': 'VBM-NET：基于_equivariant_传输器网络和图神经网络的视觉基准姿态学习方法_用于移动操作'}
{'arxiv_id': 'arXiv:2510.04168', 'title': 'Learning to Capture Rocks using an Excavator: A Reinforcement Learning Approach with Guiding Reward Formulation', 'authors': 'Amirmasoud Molaei, Reza Ghabcheloo', 'link': 'https://arxiv.org/abs/2510.04168', 'abstract': 'Rock capturing with standard excavator buckets is a challenging task typically requiring the expertise of skilled operators. Unlike soil digging, it involves manipulating large, irregular rocks in unstructured environments where complex contact interactions with granular material make model-based control impractical. Existing autonomous excavation methods focus mainly on continuous media or rely on specialized grippers, limiting their applicability to real-world construction sites. This paper introduces a fully data-driven control framework for rock capturing that eliminates the need for explicit modeling of rock or soil properties. A model-free reinforcement learning agent is trained in the AGX Dynamics simulator using the Proximal Policy Optimization (PPO) algorithm and a guiding reward formulation. The learned policy outputs joint velocity commands directly to the boom, arm, and bucket of a CAT365 excavator model. Robustness is enhanced through extensive domain randomization of rock geometry, density, and mass, as well as the initial configurations of the bucket, rock, and goal position. To the best of our knowledge, this is the first study to develop and evaluate an RL-based controller for the rock capturing task. Experimental results show that the policy generalizes well to unseen rocks and varying soil conditions, achieving high success rates comparable to those of human participants while maintaining machine stability. These findings demonstrate the feasibility of learning-based excavation strategies for discrete object manipulation without requiring specialized hardware or detailed material models.', 'abstract_zh': '基于标准挖掘桶的岩石捕捉是一项具有挑战性的任务，通常需要熟练操作员的 expertise。与土壤挖掘不同，它涉及在结构不规则环境中操纵大尺寸、形状不规则的岩石，复杂的颗粒物质接触相互作用使得基于模型的控制不切实际。现有的自主挖掘方法主要集中在连续介质上，或者依赖于专门的夹持器，限制了它们在实际建筑工地的应用。本文提出了一种完全基于数据的控制框架，用于岩石捕捉，该框架消除了对岩石或土壤性质显式建模的需求。一种无模型的强化学习代理使用Proximal Policy Optimization（PPO）算法在AGX Dynamics模拟器中进行训练，并采用引导奖励公式。所学习的策略直接输出关节速度命令到CAT365挖掘机的臂、铲斗。通过广泛的利益领域随机化岩石几何形状、密度和质量以及铲斗、岩石和目标位置的初始配置，提高了鲁棒性。据我们所知，这是首次研究和发展基于强化学习的控制器用于岩石捕捉任务的研究。实验结果表明，该策略在未见过的岩石和不同土壤条件下的泛化能力很好，成功率达到与人类参与者相当的水平，同时保持机器的稳定性。这些发现证明了在不需要专门硬件或详细材料模型的情况下，学习导向的挖掘策略对于离散物体操作的可行性。', 'title_zh': '使用铲斗学习挖掘岩石：一种带有引导奖励形式的强化学习方法'}
{'arxiv_id': 'arXiv:2510.04161', 'title': 'HEHA: Hierarchical Planning for Heterogeneous Multi-Robot Exploration of Unknown Environments', 'authors': 'Longrui Yang, Yiyu Wang, Jingfan Tang, Yunpeng Lv, Shizhe Zhao, Chao Cao, Zhongqiang Ren', 'link': 'https://arxiv.org/abs/2510.04161', 'abstract': 'This paper considers the path planning problem for autonomous exploration of an unknown environment using multiple heterogeneous robots such as drones, wheeled, and legged robots, which have different capabilities to traverse complex terrains. A key challenge there is to intelligently allocate the robots to the unknown areas to be explored and determine the visiting order of those spaces subject to traversablity constraints, which leads to a large scale constrained optimization problem that needs to be quickly and iteratively solved every time when new space are explored. To address the challenge, we propose HEHA (Hierarchical Exploration with Heterogeneous Agents) by leveraging a recent hierarchical method that decompose the exploration into global planning and local planning. The major contribution in HEHA is its global planning, where we propose a new routing algorithm PEAF (Partial Anytime Focal search) that can quickly find bounded sub-optimal solutions to minimize the maximum path length among the agents subject to traversability constraints. Additionally, the local planner in HEHA also considers heterogeneity to avoid repeated and duplicated exploration among the robots. The experimental results show that, our HEHA can reduce up to 30% of the exploration time than the baselines.', 'abstract_zh': '基于异构代理的分层探索路径规划方法HEHA', 'title_zh': 'HEHA：异质多机器人未知环境分级规划探索方法'}
{'arxiv_id': 'arXiv:2510.04076', 'title': 'From Shadow to Light: Toward Safe and Efficient Policy Learning Across MPC, DeePC, RL, and LLM Agents', 'authors': 'Amin Vahidi-Moghaddam, Sayed Pedram Haeri Boroujeni, Iman Jebellat, Ehsan Jebellat, Niloufar Mehrabi, Zhaojian Li', 'link': 'https://arxiv.org/abs/2510.04076', 'abstract': 'One of the main challenges in modern control applications, particularly in robot and vehicle motion control, is achieving accurate, fast, and safe movement. To address this, optimal control policies have been developed to enforce safety while ensuring high performance. Since basic first-principles models of real systems are often available, model-based controllers are widely used. Model predictive control (MPC) is a leading approach that optimizes performance while explicitly handling safety constraints. However, obtaining accurate models for complex systems is difficult, which motivates data-driven alternatives. ML-based MPC leverages learned models to reduce reliance on hand-crafted dynamics, while reinforcement learning (RL) can learn near-optimal policies directly from interaction data. Data-enabled predictive control (DeePC) goes further by bypassing modeling altogether, directly learning safe policies from raw input-output data. Recently, large language model (LLM) agents have also emerged, translating natural language instructions into structured formulations of optimal control problems. Despite these advances, data-driven policies face significant limitations. They often suffer from slow response times, high computational demands, and large memory needs, making them less practical for real-world systems with fast dynamics, limited onboard computing, or strict memory constraints. To address this, various technique, such as reduced-order modeling, function-approximated policy learning, and convex relaxations, have been proposed to reduce computational complexity. In this paper, we present eight such approaches and demonstrate their effectiveness across real-world applications, including robotic arms, soft robots, and vehicle motion control.', 'abstract_zh': '现代控制应用中的一大挑战，尤其是在机器人和车辆运动控制领域，是在实现准确、快速和安全的运动方面的难题。为此，已经开发了最优控制策略，以确保安全性的同时保证高性能。由于实际系统的基础物理模型通常可用，因此基于模型的控制器被广泛使用。模型预测控制（MPC）是一种领先的方法，它在明确处理安全约束的同时优化性能。然而，获得复杂系统的精确模型是困难的，这促进了数据驱动的替代方案。基于机器学习的MPC利用学习到的模型减少对外人工设计动力学的依赖，而强化学习（RL）可以直接从交互数据中学习近最优策略。数据启用预测控制（DeePC）更进一步，完全绕过了建模，直接从原始输入输出数据中学习安全策略。最近，大型语言模型（LLM）代理也出现了，能够将自然语言指令转化为最优控制问题的结构化表述。尽管取得了这些进展，但数据驱动的策略仍然面临着显著的局限性。它们常常遭受响应时间长、计算需求高和内存需求大的问题，使得它们在具有快速动力学、有限机载计算能力或严格内存限制的实际系统中不太实用。为了解决这个问题，已经提出了各种技术，如降阶建模、函数逼近策略学习和凸松弛，以降低计算复杂性。在本文中，我们介绍了这八种方法，并展示了它们在实际应用中的有效性，包括机器人手臂、软体机器人和车辆运动控制。', 'title_zh': '从暗影到光明：迈向跨MPC、DeePC、RL和LLM代理的安全与高效策略学习'}
{'arxiv_id': 'arXiv:2510.04074', 'title': 'Feedback Matters: Augmenting Autonomous Dissection with Visual and Topological Feedback', 'authors': 'Chung-Pang Wang, Changwei Chen, Xiao Liang, Soofiyan Atar, Florian Richter, Michael Yip', 'link': 'https://arxiv.org/abs/2510.04074', 'abstract': 'Autonomous surgical systems must adapt to highly dynamic environments where tissue properties and visual cues evolve rapidly. Central to such adaptability is feedback: the ability to sense, interpret, and respond to changes during execution. While feedback mechanisms have been explored in surgical robotics, ranging from tool and tissue tracking to error detection, existing methods remain limited in handling the topological and perceptual challenges of tissue dissection. In this work, we propose a feedback-enabled framework for autonomous tissue dissection that explicitly reasons about topological changes from endoscopic images after each dissection action. This structured feedback guides subsequent actions, enabling the system to localize dissection progress and adapt policies online. To improve the reliability of such feedback, we introduce visibility metrics that quantify tissue exposure and formulate optimal controller designs that actively manipulate tissue to maximize visibility. Finally, we integrate these feedback mechanisms with both planning-based and learning-based dissection methods, and demonstrate experimentally that they significantly enhance autonomy, reduce errors, and improve robustness in complex surgical scenarios.', 'abstract_zh': '自主手术系统必须适应高度动态的环境，其中组织性质和视觉线索会迅速变化。反馈机制对于这种适应性至关重要，包括在执行过程中感知、解释和响应变化的能力。尽管在手术机器人中已经探索了反馈机制，从工具和组织追踪到错误检测，现有方法在处理组织分离过程中的拓扑和知觉挑战方面仍有限制。在本文中，我们提出了一种具有反馈机制的自主组织分离框架，该框架在每次分离操作后明确地从内窥镜图像中推理拓扑变化。这种结构化的反馈引导后续操作，使系统能够定位分离进度并在线调整策略。为了提高反馈的可靠性，我们引入了可视化度量标准，这些标准量化了组织的暴露程度，并制定了主动操纵组织以最大化可视化度量的最优控制器设计。最后，我们将这些反馈机制与基于规划和基于学习的分离方法结合，实验结果表明，它们显著增强了自主性、减少了错误并提高了复杂手术场景中的鲁棒性。', 'title_zh': '反馈很重要：借助视觉和拓扑反馈增强自主分解能力'}
{'arxiv_id': 'arXiv:2510.04041', 'title': 'SITCOM: Scaling Inference-Time COMpute for VLAs', 'authors': 'Ayudh Saxena, Harsh Shah, Sandeep Routray, Rishi Rajesh Shah, Esha Pahwa', 'link': 'https://arxiv.org/abs/2510.04041', 'abstract': 'Learning robust robotic control policies remains a major challenge due to the high cost of collecting labeled data, limited generalization to unseen environments, and difficulties in planning over long horizons. While Vision-Language-Action (VLA) models offer a promising solution by grounding natural language instructions into single-step control commands, they often lack mechanisms for lookahead and struggle with compounding errors in dynamic tasks. In this project, we introduce Scaling Inference-Time COMpute for VLAs (SITCOM), a framework that augments any pretrained VLA with model-based rollouts and reward-based trajectory selection, inspired by Model Predictive Control algorithm. SITCOM leverages a learned dynamics model to simulate multi-step action rollouts to select the best candidate plan for real-world execution, transforming one-shot VLAs into robust long-horizon planners. We develop an efficient transformer-based dynamics model trained on large-scale BridgeV2 data and fine-tuned on SIMPLER environments to bridge the Real2Sim gap, and score candidate rollouts using rewards from simulator. Through comprehensive evaluation across multiple tasks and settings in the SIMPLER environment, we demonstrate that SITCOM when combined with a good reward function can significantly improve task completion rate from 48% to 72% using trained dynamics model.', 'abstract_zh': '基于视觉-语言-行动模型的推理时长计算扩展框架（SITCOM）：多步动作模拟与奖励导向轨迹选择', 'title_zh': 'SITCOM: 扩展 VLAs 推理时的计算规模'}
{'arxiv_id': 'arXiv:2510.03948', 'title': 'A Real-Time Framework for Intermediate Map Construction and Kinematically Feasible Off-Road Planning Without OSM', 'authors': 'Otobong Jerome, Geesara Prathap Kulathunga, Devitt Dmitry, Eugene Murawjow, Alexandr Klimchik', 'link': 'https://arxiv.org/abs/2510.03948', 'abstract': 'Off-road environments present unique challenges for autonomous navigation due to their complex and unstructured nature. Traditional global path-planning methods, which typically aim to minimize path length and travel time, perform poorly on large-scale maps and fail to account for critical factors such as real-time performance, kinematic feasibility, and memory efficiency. This paper introduces a novel global path-planning method specifically designed for off-road environments, addressing these essential factors. The method begins by constructing an intermediate map within the pixel coordinate system, incorporating geographical features like off-road trails, waterways, restricted and passable areas, and trees. The planning problem is then divided into three sub-problems: graph-based path planning, kinematic feasibility checking, and path smoothing. This approach effectively meets real-time performance requirements while ensuring kinematic feasibility and efficient memory use. The method was tested in various off-road environments with large-scale maps up to several square kilometers in size, successfully identifying feasible paths in an average of 1.5 seconds and utilizing approximately 1.5GB of memory under extreme conditions. The proposed framework is versatile and applicable to a wide range of off-road autonomous navigation tasks, including search and rescue missions and agricultural operations.', 'abstract_zh': '越野环境下的自主导航提出了独特挑战，由于其复杂且未结构化的特性。传统的全局路径规划方法通常旨在最小化路径长度和出行时间，在大规模地图上的表现不佳，未能考虑实时性能、运动学可行性和内存效率等关键因素。本文提出了一种专门为越野环境设计的新型全局路径规划方法，以解决这些关键因素。该方法首先在像素坐标系中构建一个中间地图，包括越野路线、水道、受限制和可通行区域以及树木等地理特征。然后将规划问题分为三个子问题：基于图的路径规划、运动学可行性检查和路径平滑。该方法有效满足了实时性能要求，同时确保了运动学可行性和高效的内存使用。该方法在包含几平方公里的大规模地图的各种越野环境中进行了测试，在极端条件下平均1.5秒内即可成功识别可行路径，并且内存使用量约为1.5GB。所提出的框架具有广泛的适用性，适用于多种越野自主导航任务，包括搜索救援任务和农业作业。', 'title_zh': '一种实时的Intermediate地图构建框架及基于OSM无道路规划的运动学可行路径规划'}
{'arxiv_id': 'arXiv:2510.03919', 'title': 'TCB-VIO: Tightly-Coupled Focal-Plane Binary-Enhanced Visual Inertial Odometry', 'authors': 'Matthew Lisondra, Junseo Kim, Glenn Takashi Shimoda, Kourosh Zareinia, Sajad Saeedi', 'link': 'https://arxiv.org/abs/2510.03919', 'abstract': 'Vision algorithms can be executed directly on the image sensor when implemented on the next-generation sensors known as focal-plane sensor-processor arrays (FPSP)s, where every pixel has a processor. FPSPs greatly improve latency, reducing the problems associated with the bottleneck of data transfer from a vision sensor to a processor. FPSPs accelerate vision-based algorithms such as visual-inertial odometry (VIO). However, VIO frameworks suffer from spatial drift due to the vision-based pose estimation, whilst temporal drift arises from the inertial measurements. FPSPs circumvent the spatial drift by operating at a high frame rate to match the high-frequency output of the inertial measurements. In this paper, we present TCB-VIO, a tightly-coupled 6 degrees-of-freedom VIO by a Multi-State Constraint Kalman Filter (MSCKF), operating at a high frame-rate of 250 FPS and from IMU measurements obtained at 400 Hz. TCB-VIO outperforms state-of-the-art methods: ROVIO, VINS-Mono, and ORB-SLAM3.', 'abstract_zh': '基于多状态约束卡尔曼滤波器的高帧率紧密耦合6自由度视觉惯性里程计TCB-VIO', 'title_zh': 'TCB-VIO: 紧密耦合的焦平面二进制增强视觉惯性odometry'}
{'arxiv_id': 'arXiv:2510.03910', 'title': 'WAFFLE: A Wearable Approach to Bite Timing Estimation in Robot-Assisted Feeding', 'authors': 'Akhil Padmanabha, Jessie Yuan, Tanisha Mehta, Rajat Kumar Jenamani, Eric Hu, Victoria de León, Anthony Wertz, Janavi Gupta, Ben Dodson, Yunting Yan, Carmel Majidi, Tapomayukh Bhattacharjee, Zackory Erickson', 'link': 'https://arxiv.org/abs/2510.03910', 'abstract': "Millions of people around the world need assistance with feeding. Robotic feeding systems offer the potential to enhance autonomy and quality of life for individuals with impairments and reduce caregiver workload. However, their widespread adoption has been limited by technical challenges such as estimating bite timing, the appropriate moment for the robot to transfer food to a user's mouth. In this work, we introduce WAFFLE: Wearable Approach For Feeding with LEarned bite timing, a system that accurately predicts bite timing by leveraging wearable sensor data to be highly reactive to natural user cues such as head movements, chewing, and talking. We train a supervised regression model on bite timing data from 14 participants and incorporate a user-adjustable assertiveness threshold to convert predictions into proceed or stop commands. In a study with 15 participants without motor impairments with the Obi feeding robot, WAFFLE performs statistically on par with or better than baseline methods across measures of feeling of control, robot understanding, and workload, and is preferred by the majority of participants for both individual and social dining. We further demonstrate WAFFLE's generalizability in a study with 2 participants with motor impairments in their home environments using a Kinova 7DOF robot. Our findings support WAFFLE's effectiveness in enabling natural, reactive bite timing that generalizes across users, robot hardware, robot positioning, feeding trajectories, foods, and both individual and social dining contexts.", 'abstract_zh': '基于穿戴传感器学习咬食时机的辅助进食系统：WAFFLE', 'title_zh': 'WAFFLE: 一种基于穿戴设备的机器人辅助进食咀嚼时机估计方法'}
{'arxiv_id': 'arXiv:2510.03895', 'title': 'NoTVLA: Narrowing of Dense Action Trajectories for Generalizable Robot Manipulation', 'authors': 'Zheng Huang, Mingyu Liu, Xiaoyi Lin, Muzhi Zhu, Canyu Zhao, Zongze Du, Xiaoman Li, Yiduo Jia, Hao Zhong, Hao Chen, Chunhua Shen', 'link': 'https://arxiv.org/abs/2510.03895', 'abstract': "Vision-Language-Action (VLA) models represent a pivotal advance in embodied intelligence, yet they confront critical barriers to real-world deployment, most notably catastrophic forgetting. This issue stems from their overreliance on continuous action sequences or action chunks, which inadvertently create isolated data silos that disrupt knowledge retention across tasks. To tackle these challenges, we propose the Narrowing of Trajectory VLA (NoTVLA) framework: a novel approach that narrows its focus to sparse trajectories, thereby avoiding the catastrophic forgetting associated with dense trajectory fine-tuning. A key innovation of NoTVLA lies in its trajectory planning strategy: instead of centering on the target object's trajectory, it leverages temporal compression and spatial reasoning pruning specifically for the robot end effector's trajectory. Furthermore, training is conducted using these sparse trajectories rather than dense action trajectories, an optimization that delivers remarkable practical advantages with better performance in zero-shot. In multi-task evaluation scenarios, NoTVLA achieves superior performance and generalization compared to pi0 while operating under two critical constraints: it uses over an order of magnitude less computing power than pi0 and requires no wrist-mounted camera. This design ensures that NoTVLA's operational accuracy closely approximates that of single-task expert models. Crucially, it also preserves the model's inherent language capabilities, enabling zero-shot generalization in specific scenarios, supporting unified model deployment across multiple robot platforms, and fostering a degree of generalization even when perceiving tasks from novel perspectives.", 'abstract_zh': '窄轨迹视觉-语言-行动（NoTVLA）框架：克服关键挑战实现泛化性能提升', 'title_zh': 'NoTVLA: 紧凑密集动作轨迹用于通用机器人 manipulation'}
{'arxiv_id': 'arXiv:2510.03885', 'title': 'Seeing the Bigger Picture: 3D Latent Mapping for Mobile Manipulation Policy Learning', 'authors': 'Sunghwan Kim, Woojeh Chung, Zhirui Dai, Dwait Bhatt, Arth Shukla, Hao Su, Yulun Tian, Nikolay Atanasov', 'link': 'https://arxiv.org/abs/2510.03885', 'abstract': "In this paper, we demonstrate that mobile manipulation policies utilizing a 3D latent map achieve stronger spatial and temporal reasoning than policies relying solely on images. We introduce Seeing the Bigger Picture (SBP), an end-to-end policy learning approach that operates directly on a 3D map of latent features. In SBP, the map extends perception beyond the robot's current field of view and aggregates observations over long horizons. Our mapping approach incrementally fuses multiview observations into a grid of scene-specific latent features. A pre-trained, scene-agnostic decoder reconstructs target embeddings from these features and enables online optimization of the map features during task execution. A policy, trainable with behavior cloning or reinforcement learning, treats the latent map as a state variable and uses global context from the map obtained via a 3D feature aggregator. We evaluate SBP on scene-level mobile manipulation and sequential tabletop manipulation tasks. Our experiments demonstrate that SBP (i) reasons globally over the scene, (ii) leverages the map as long-horizon memory, and (iii) outperforms image-based policies in both in-distribution and novel scenes, e.g., improving the success rate by 25% for the sequential manipulation task.", 'abstract_zh': '在本文中，我们展示了利用3D潜空间映射的移动操作策略在空间和时间推理方面比仅依赖图像的策略更强大。我们引入了一种端到端的策略学习方法Seeing the Bigger Picture (SBP)，该方法直接操作3D特征映射。在SBP中，映射扩展了机器人的感知范围，超出了当前视野，并在长时间段内聚合观测结果。我们的建图方法逐步将多视图观测结果融合到场景特定的特征格网中。一个预先训练好的、场景无关的解码器从这些特征中重建目标嵌入，并在任务执行期间使映射特征的优化成为可能。一个使用行为克隆或强化学习训练的策略将潜空间映射视为状态变量，并利用3D特征聚合器从映射中获得的全局上下文。我们在场景级移动操作和序列式桌面操作任务上评估了SBP。我们的实验表明，SBP能够在全球范围内推理场景，利用映射作为长时记忆，并在分布内和新颖场景中优于基于图像的策略，例如，在序列操作任务中的成功率提高了25%。', 'title_zh': '从全局视角出发：面向移动 Manipulation 策略学习的 3D 潜在空间映射'}
{'arxiv_id': 'arXiv:2510.03875', 'title': 'COVER:COverage-VErified Roadmaps for Fixed-time Motion Planning in Continuous Semi-Static Environments', 'authors': 'Niranjan Kumar Ilampooranan, Constantinos Chamzas', 'link': 'https://arxiv.org/abs/2510.03875', 'abstract': 'Having the ability to answer motion-planning queries within a fixed time budget is critical for the widespread deployment of robotic systems. Semi-static environments, where most obstacles remain static but a limited set can vary across queries, exhibit structured variability that can be systematically exploited to provide stronger guarantees than in general motion-planning problems. However, prior approaches in this setting either lack formal guarantees or rely on restrictive discretizations of obstacle configurations, limiting their applicability in realistic domains. This paper introduces COVER, a novel framework that incrementally constructs a coverage-verified roadmap in semi-static environments. By partitioning the obstacle configuration space and solving for feasible paths within each partition, COVER systematically verifies feasibility of the roadmap in each partition and guarantees fixed-time motion planning queries within the verified regions. We validate COVER with a 7-DOF simulated Panda robot performing table and shelf tasks, demonstrating that COVER achieves broader coverage with higher query success rates than prior works.', 'abstract_zh': '能够在固定时间预算内回答运动规划查询的能力对于机器人系统的广泛部署至关重要。在大多数障碍物保持静止而少量障碍物可以在不同查询中变化的半静态环境中，结构化的多样性可以系统地加以利用，从而提供更多强于一般运动规划问题的保证。然而，当前在这个环境中的方法要么缺乏形式保证，要么依赖于障碍物配置的限制离散化，限制了它们在实际领域的应用。本文提出了一种新的框架COVER，该框架逐步构建半静态环境中的覆盖验证路网。通过分区障碍物配置空间并在每个分区中求解可行路径，COVER系统地验证每个分区中路网的可行性，并保证在验证区域内完成固定时间的运动规划查询。我们通过一个7-DOF模拟的Panda机器人执行桌子和架子任务来验证COVER，结果显示COVER在更大范围内实现了更高的查询成功率，优于以前的方法。', 'title_zh': 'COVER：Coverage-Verified 路径规划用于连续半静态环境下的固定时间运动规划'}
{'arxiv_id': 'arXiv:2510.03776', 'title': 'Trajectory prediction for heterogeneous agents: A performance analysis on small and imbalanced datasets', 'authors': 'Tiago Rodrigues de Almeida, Yufei Zhu, Andrey Rudenko, Tomasz P. Kucner, Johannes A. Stork, Martin Magnusson, Achim J. Lilienthal', 'link': 'https://arxiv.org/abs/2510.03776', 'abstract': 'Robots and other intelligent systems navigating in complex dynamic environments should predict future actions and intentions of surrounding agents to reach their goals efficiently and avoid collisions. The dynamics of those agents strongly depends on their tasks, roles, or observable labels. Class-conditioned motion prediction is thus an appealing way to reduce forecast uncertainty and get more accurate predictions for heterogeneous agents. However, this is hardly explored in the prior art, especially for mobile robots and in limited data applications. In this paper, we analyse different class-conditioned trajectory prediction methods on two datasets. We propose a set of conditional pattern-based and efficient deep learning-based baselines, and evaluate their performance on robotics and outdoors datasets (THÖR-MAGNI and Stanford Drone Dataset). Our experiments show that all methods improve accuracy in most of the settings when considering class labels. More importantly, we observe that there are significant differences when learning from imbalanced datasets, or in new environments where sufficient data is not available. In particular, we find that deep learning methods perform better on balanced datasets, but in applications with limited data, e.g., cold start of a robot in a new environment, or imbalanced classes, pattern-based methods may be preferable.', 'abstract_zh': '复杂的动态环境中，机器人及其他智能系统应预测周围代理的未来行动和意图，以高效地达到目标并避免碰撞。这些代理的动力学强烈依赖于其任务、角色或可观察标签。基于类别的运动预测是一种减少预测不确定性并为异质代理获得更准确预测的诱人方式。然而，这在先前的研究中很少被探索，特别是在移动机器人及其数据有限的应用中。本文在两个数据集上分析了不同的类别条件轨迹预测方法。我们提出了一组基于条件模式和高效的基于深度学习的基本方法，并在机器人和户外数据集（THÖR-MAGNI和斯坦福无人机数据集）上评估其性能。我们的实验表明，在考虑类别标签的情况下，所有方法在大多数情况下都能提高准确性。更重要的是，我们观察到在不平衡数据集学习或新环境中缺乏足够数据时，学习效果存在显著差异。特别是，我们发现，在平衡数据集上，深度学习方法表现更好，但在数据有限的应用中，例如机器人在新环境中冷启动或类别不平衡时，基于模式的方法可能更为优选。', 'title_zh': '异质性代理的轨迹预测：小规模与不平衡数据集上的性能分析'}
{'arxiv_id': 'arXiv:2510.03768', 'title': 'Model-Based Adaptive Precision Control for Tabletop Planar Pushing Under Uncertain Dynamics', 'authors': 'Aydin Ahmadi, Baris Akgun', 'link': 'https://arxiv.org/abs/2510.03768', 'abstract': "Data-driven planar pushing methods have recently gained attention as they reduce manual engineering effort and improve generalization compared to analytical approaches. However, most prior work targets narrow capabilities (e.g., side switching, precision, or single-task training), limiting broader applicability. We present a model-based framework for non-prehensile tabletop pushing that uses a single learned model to address multiple tasks without retraining. Our approach employs a recurrent GRU-based architecture with additional non-linear layers to capture object-environment dynamics while ensuring stability. A tailored state-action representation enables the model to generalize across uncertain dynamics, variable push lengths, and diverse tasks. For control, we integrate the learned dynamics with a sampling-based Model Predictive Path Integral (MPPI) controller, which generates adaptive, task-oriented actions. This framework supports side switching, variable-length pushes, and objectives such as precise positioning, trajectory following, and obstacle avoidance. Training is performed in simulation with domain randomization to support sim-to-real transfer. We first evaluate the architecture through ablation studies, showing improved prediction accuracy and stable rollouts. We then validate the full system in simulation and real-world experiments using a Franka Panda robot with markerless tracking. Results demonstrate high success rates in precise positioning under strict thresholds and strong performance in trajectory tracking and obstacle avoidance. Moreover, multiple tasks are solved simply by changing the controller's objective function, without retraining. While our current focus is on a single object type, we extend the framework by training on wider push lengths and designing a balanced controller that reduces the number of steps for longer-horizon goals.", 'abstract_zh': '基于数据驱动的平面推动物理方法最近引起了关注，因为它们减少了手动工程努力并相较于分析方法提高了泛化能力。然而，大多数先前工作针对狭窄的能力（例如，侧向切换、精确度或单任务训练），限制了更广泛的应用。我们提出了一种基于模型的无抓取桌面推动物理框架，利用单一学习模型解决多个任务而无需重新训练。我们的方法采用基于递归GRU的架构，并附加非线性层以捕获物体-环境动力学并确保稳定性。量身定制的状态-动作表示使模型能够在不确定的动力学、可变的推力长度以及多样化的任务中泛化。在控制方面，我们将学习的动力学与基于采样的模型预测路径积分（MPPI）控制器结合使用，从而生成适应性强、面向任务的动作。该框架支持侧向切换、可变长度的推力以及精确定位、轨迹跟随和障碍物避让等目标。训练在具有领域随机化的模拟中进行，以支持从模拟到现实的应用。我们首先通过消融研究评估了该架构，结果显示预测准确性提高且 rollout 稳定。然后，我们在使用 Franka Panda 机器人和无标记跟踪的模拟和真实世界实验中验证了整个系统。结果表明，在严格阈值下精确定位的成功率很高，并且在轨迹跟踪和障碍物避让方面表现出色。此外，通过改变控制器的目标函数，可以轻松解决多个任务，而无需重新训练。虽然当前的重点是单一物体类型，我们通过在更广泛的推力长度上进行训练并设计平衡控制器来减少长期目标所需步数，扩展了该框架。', 'title_zh': '基于模型的自适应精度控制在不确定动力学下的桌面平面推物 manipulotion'}
{'arxiv_id': 'arXiv:2510.03706', 'title': 'EmbodiSwap for Zero-Shot Robot Imitation Learning', 'authors': 'Eadom Dessalene, Pavan Mantripragada, Michael Maynord, Yiannis Aloimonos', 'link': 'https://arxiv.org/abs/2510.03706', 'abstract': 'We introduce EmbodiSwap - a method for producing photorealistic synthetic robot overlays over human video. We employ EmbodiSwap for zero-shot imitation learning, bridging the embodiment gap between in-the-wild ego-centric human video and a target robot embodiment. We train a closed-loop robot manipulation policy over the data produced by EmbodiSwap. We make novel use of V-JEPA as a visual backbone, repurposing V-JEPA from the domain of video understanding to imitation learning over synthetic robot videos. Adoption of V-JEPA outperforms alternative vision backbones more conventionally used within robotics. In real-world tests, our zero-shot trained V-JEPA model achieves an $82\\%$ success rate, outperforming a few-shot trained $\\pi_0$ network as well as $\\pi_0$ trained over data produced by EmbodiSwap. We release (i) code for generating the synthetic robot overlays which takes as input human videos and an arbitrary robot URDF and generates a robot dataset, (ii) the robot dataset we synthesize over EPIC-Kitchens, HOI4D and Ego4D, and (iii) model checkpoints and inference code, to facilitate reproducible research and broader adoption.', 'abstract_zh': '我们介绍EmbodiSwap——一种生成逼真的合成机器人叠加在人体视频上的方法。我们使用EmbodiSwap进行零样本模仿学习，填补了野生主观人体视频与目标机器人体感之间的差距。我们基于EmbodiSwap生成的数据训练了一个闭环机器人操作策略。我们将V-JEPA作为一种视觉骨干进行了新颖的应用，将其从视频理解领域重新利用到合成机器人视频的模仿学习中。V-JEPA的采用优于机器人领域常用的其他视觉骨干。在实际测试中，我们的零样本训练V-JEPA模型实现了82%的成功率，优于部分样本训练的$\\pi_0$网络以及基于EmbodiSwap生成的数据训练的$\\pi_0$模型。我们发布了(i)生成合成机器人叠加的代码，该代码输入人体视频和任意机器人URDF并生成机器人数据集，(ii)我们在EPIC-Kitchens、HOI4D和Ego4D上合成的机器人数据集，以及(iii)模型检查点和推理代码，以促进可重复研究和更广泛的采用。', 'title_zh': 'EmbodiSwapfor零样本机器人模仿学习'}
{'arxiv_id': 'arXiv:2510.03677', 'title': 'Robust Visual Embodiment: How Robots Discover Their Bodies in Real Environments', 'authors': 'Salim Rezvani, Ammar Jaleel Mahmood, Robin Chhabra', 'link': 'https://arxiv.org/abs/2510.03677', 'abstract': 'Robots with internal visual self-models promise unprecedented adaptability, yet existing autonomous modeling pipelines remain fragile under realistic sensing conditions such as noisy imagery and cluttered backgrounds. This paper presents the first systematic study quantifying how visual degradations--including blur, salt-and-pepper noise, and Gaussian noise--affect robotic self-modeling. Through both simulation and physical experiments, we demonstrate their impact on morphology prediction, trajectory planning, and damage recovery in state-of-the-art pipelines. To overcome these challenges, we introduce a task-aware denoising framework that couples classical restoration with morphology-preserving constraints, ensuring retention of structural cues critical for self-modeling. In addition, we integrate semantic segmentation to robustly isolate robots from cluttered and colorful scenes. Extensive experiments show that our approach restores near-baseline performance across simulated and physical platforms, while existing pipelines degrade significantly. These contributions advance the robustness of visual self-modeling and establish practical foundations for deploying self-aware robots in unpredictable real-world environments.', 'abstract_zh': '具有内部视觉自模型的机器人在现实传感条件下的视觉退化影响及其鲁棒性研究', 'title_zh': '稳健的视觉封装：机器人如何在真实环境中发现自己的身体'}
{'arxiv_id': 'arXiv:2510.03660', 'title': 'An Amphibious Untethered Inchworm Soft Robot for Fast Crawling Locomotion', 'authors': 'Mohammadjavad Javadi, Charlie Wadds, Robin Chhabra', 'link': 'https://arxiv.org/abs/2510.03660', 'abstract': "Untethered soft robots are essential for advancing the real-world deployment of soft robotic systems in diverse and multitasking environments. Inspired by soft-bodied inchworm, we present a fully untethered soft robot with a curved, flexible structure actuated by magnetic forces. The robot has a total mass of 102.63 g and demonstrates multimodal locomotion, achieving a maximum walking speed of 3.74 cm/s and a swimming speed of 0.82 cm/s. A compact and lightweight onboard control circuit enables wireless command transmission, while an integrated camera provides environmental perception. Through structural optimization and system-level integration, the robot successfully performs walking, steering, swimming, and payload transport without reliance on external infrastructure. The robot's dynamic performance and locomotion capabilities are systematically validated through experimental characterization.", 'abstract_zh': '脱离束缚的软机器人对于推动软机器人系统在多样化的多任务环境中的实际应用至关重要。受软体 Inchworm 启发，我们呈现了一种完全脱离束缚的软机器人，该机器人具有曲线柔性结构，并通过磁力驱动。该机器人总质量为 102.63 克，展示了多种运动模式，实现最大行走速度 3.74 cm/s 和游泳速度 0.82 cm/s。紧凑轻量的机载控制电路实现了无线指令传输，而集成摄像头提供了环境感知。通过结构优化和系统级集成，该机器人在无需外部基础设施的条件下成功实现了行走、转向、游泳和负载运输。通过实验特性化，系统验证了该机器人的动态性能和运动能力。', 'title_zh': '一种用于快速爬行运动的 Amphibious Untethered Inchworm 软机器人'}
{'arxiv_id': 'arXiv:2510.03644', 'title': 'Geometrically Exact Hard Magneto-Elastic Cosserat Shells: Static Formulation for Shape Morphing', 'authors': 'Mohammadjavad Javadi, Robin Chhabra', 'link': 'https://arxiv.org/abs/2510.03644', 'abstract': "Cosserat rod theory is the popular approach to modeling ferromagnetic soft robots as 1-Dimensional (1D) slender structures in most applications, such as biomedical. However, recent soft robots designed for locomotion and manipulation often exhibit a large width-to-length ratio that categorizes them as 2D shells. For analysis and shape-morphing control purposes, we develop an efficient coordinate-free static model of hard-magnetic shells found in soft magnetic grippers and walking soft robots. The approach is based on a novel formulation of Cosserat shell theory on the Special Euclidean group ($\\mathbf{SE}(3)$). The shell is assumed to be a 2D manifold of material points with six degrees of freedom (position & rotation) suitable for capturing the behavior of a uniformly distributed array of spheroidal hard magnetic particles embedded in the rheological elastomer. The shell's configuration manifold is the space of all smooth embeddings $\\mathbb{R}^2\\rightarrow\\mathbf{SE}(3)$. According to a novel definition of local deformation gradient based on the Lie group structure of $\\mathbf{SE}(3)$, we derive the strong and weak forms of equilibrium equations, following the principle of virtual work. We extract the linearized version of the weak form for numerical implementations. The resulting finite element approach can avoid well-known challenges such as singularity and locking phenomenon in modeling shell structures. The proposed model is analytically and experimentally validated through a series of test cases that demonstrate its superior efficacy, particularly when the shell undergoes severe rotations and displacements.", 'abstract_zh': 'Cosserat杆理论是 modelling 磁性软机器人作为大多数生物医学等应用中的一维纤细结构的流行方法，然而，最近设计用于运动和操作的软机器人通常具有较大的宽长比，归类为二维壳体。为了分析和形状变形控制的目的，我们发展了一种硬磁壳的高效的无坐标静力学模型，这种硬磁壳存在于软磁夹持器和walking软机器人中。该方法基于$SE(3)$特殊欧几里得群上的新型Cosserat壳理 论形式。壳体假定为具有六自由度（位置与旋转）的2D流形材料点，适用于捕捉均匀分布的嵌入在粘弹性橡 胶中的磁性球粒体的行为。壳体的配置流形是$\\mathbb{R}^2\\rightarrow SE(3)$的所有平滑嵌入的空间。根据基于$SE(3)$李群结构的新型局部变形梯度定义，我们遵循虚功原理推导出平衡方程的强形式和弱形式。我们提取弱形式的线性化版本进行数值实现。所得到的有限元方法可以避免建模壳体结构时遇到的奇异性和锁定现象。通过一系列测试案例，我们对所提出的模型进行了理论和实验验证，表明其优越性，尤其是在壳体经历严重旋转和位移时。', 'title_zh': '几何精确刚硬磁弹Cosserat shell模型：形状变形的静力公式'}
{'arxiv_id': 'arXiv:2510.03640', 'title': 'Safety-Oriented Dynamic Path Planning for Automated Vehicles', 'authors': 'Mostafa Emam, Matthias Gerdts', 'link': 'https://arxiv.org/abs/2510.03640', 'abstract': 'Ensuring safety in autonomous vehicles necessitates advanced path planning and obstacle avoidance capabilities, particularly in dynamic environments. This paper introduces a bi-level control framework that efficiently augments road boundaries by incorporating time-dependent grid projections of obstacle movements, thus enabling precise and adaptive path planning. The main control loop utilizes Nonlinear Model Predictive Control (NMPC) for real-time path optimization, wherein homotopy-based constraint relaxation is employed to improve the solvability of the optimal control problem (OCP). Furthermore, an independent backup loop runs concurrently to provide safe fallback trajectories when an optimal trajectory cannot be computed by the main loop within a critical time frame, thus enhancing safety and real-time performance. Our evaluation showcases the benefits of the proposed methods in various driving scenarios, highlighting the real-time applicability and robustness of our approach. Overall, the framework represents a significant step towards safer and more reliable autonomous driving in complex and dynamic environments.', 'abstract_zh': '确保自主车辆安全需要先进的路径规划和障碍物规避能力，特别是在动态环境中。本文引入了一种多层次控制框架，通过结合障碍物运动的时间依赖网格投影高效扩充道路边界，从而实现精确和适应性的路径规划。主要控制环路采用非线性模型预测控制(NMPC)进行实时路径优化，并利用同调约束松弛方法提高最优控制问题(OCP)的求解性。此外，一个独立的备用环路同时运行，以在主要环路在关键时间框架内无法计算最优轨迹时提供安全的备用轨迹，从而提高安全性和实时性能。我们的评估展示了所提出方法在各种驾驶场景下的优势，突显了我们方法的实时适用性和鲁棒性。总体而言，该框架代表了在复杂和动态环境中实现更安全、更可靠自主驾驶的重要一步。', 'title_zh': '面向安全的动态路径规划方法研究（应用于自动车辆）'}
{'arxiv_id': 'arXiv:2510.03599', 'title': 'Learning to Act Through Contact: A Unified View of Multi-Task Robot Learning', 'authors': 'Shafeef Omar, Majid Khadiv', 'link': 'https://arxiv.org/abs/2510.03599', 'abstract': 'We present a unified framework for multi-task locomotion and manipulation policy learning grounded in a contact-explicit representation. Instead of designing different policies for different tasks, our approach unifies the definition of a task through a sequence of contact goals-desired contact positions, timings, and active end-effectors. This enables leveraging the shared structure across diverse contact-rich tasks, leading to a single policy that can perform a wide range of tasks. In particular, we train a goal-conditioned reinforcement learning (RL) policy to realise given contact plans. We validate our framework on multiple robotic embodiments and tasks: a quadruped performing multiple gaits, a humanoid performing multiple biped and quadrupedal gaits, and a humanoid executing different bimanual object manipulation tasks. Each of these scenarios is controlled by a single policy trained to execute different tasks grounded in contacts, demonstrating versatile and robust behaviours across morphologically distinct systems. Our results show that explicit contact reasoning significantly improves generalisation to unseen scenarios, positioning contact-explicit policy learning as a promising foundation for scalable loco-manipulation.', 'abstract_zh': '我们提出了一种基于接触显式表示的多任务运动与 manipulation 策略学习统一框架。我们通过接触目标（包括期望的接触位置、时间以及主动执行器）的序列来统一任务定义，而不是为不同的任务设计不同的策略。这种方法使得能够利用不同丰富接触任务之间的共享结构，从而产生一个能够执行广泛任务的单一策略。特别是，我们训练了一个基于目标的强化学习（RL）策略以实现给定的接触计划。我们在多种机器人载体和任务上验证了我们的框架：四足机器人执行多种步态，类人机器人执行多种两足和四足步态，以及类人机器人执行不同双臂对象 manipulation 任务。这些情景均由一个单一策略控制，该策略被训练执行基于接触的不同任务，展示了不同形态系统中的通用且稳健的行为。我们的结果表明，明确的接触推理显著提高了对未见情景的泛化能力，将基于接触的策略学习定位为可扩展的运动与 manipulation 的有前途的基础。', 'title_zh': '通过接触学习行动：多任务机器人学习的统一视角'}
{'arxiv_id': 'arXiv:2510.03547', 'title': 'Shape-Space Graphs: Fast and Collision-Free Path Planning for Soft Robots', 'authors': 'Carina Veil, Moritz Flaschel, Ellen Kuhl', 'link': 'https://arxiv.org/abs/2510.03547', 'abstract': "Soft robots, inspired by elephant trunks or octopus arms, offer extraordinary flexibility to bend, twist, and elongate in ways that rigid robots cannot. However, their motion planning remains a challenge, especially in cluttered environments with obstacles, due to their highly nonlinear and infinite-dimensional kinematics. Here, we present a graph-based path planning tool for an elephant-trunk-inspired soft robotic arm designed with three artificial muscle fibers that allow for multimodal continuous deformation through contraction. Using a biomechanical model inspired by morphoelasticity and active filament theory, we precompute a shape library and construct a $k$-nearest neighbor graph in \\emph{shape space}, ensuring that each node corresponds to a mechanically accurate and physically valid robot shape. For the graph, we use signed distance functions to prune nodes and edges colliding with obstacles, and define multi-objective edge costs based on geometric distance and actuation effort, enabling energy-efficient planning with collision avoidance. We demonstrate that our algorithm reliably avoids obstacles and generates feasible paths within milliseconds from precomputed graphs using Dijkstra's algorithm. We show that including energy costs can drastically reduce the actuation effort compared to geometry-only planning, at the expense of longer tip trajectories. Our results highlight the potential of shape-space graph search for fast and reliable path planning in the field of soft robotics, paving the way for real-time applications in surgical, industrial, and assistive settings.", 'abstract_zh': '基于图形路径规划的受象鼻启发的软体机器人手臂设计及运动规划', 'title_zh': '形变空间图：软机器人快速无碰撞路径规划'}
{'arxiv_id': 'arXiv:2510.03532', 'title': 'Efficient Surgical Robotic Instrument Pose Reconstruction in Real World Conditions Using Unified Feature Detection', 'authors': 'Zekai Liang, Kazuya Miyata, Xiao Liang, Florian Richter, Michael C. Yip', 'link': 'https://arxiv.org/abs/2510.03532', 'abstract': 'Accurate camera-to-robot calibration is essential for any vision-based robotic control system and especially critical in minimally invasive surgical robots, where instruments conduct precise micro-manipulations. However, MIS robots have long kinematic chains and partial visibility of their degrees of freedom in the camera, which introduces challenges for conventional camera-to-robot calibration methods that assume stiff robots with good visibility. Previous works have investigated both keypoint-based and rendering-based approaches to address this challenge in real-world conditions; however, they often struggle with consistent feature detection or have long inference times, neither of which are ideal for online robot control. In this work, we propose a novel framework that unifies the detection of geometric primitives (keypoints and shaft edges) through a shared encoding, enabling efficient pose estimation via projection geometry. This architecture detects both keypoints and edges in a single inference and is trained on large-scale synthetic data with projective labeling. This method is evaluated across both feature detection and pose estimation, with qualitative and quantitative results demonstrating fast performance and state-of-the-art accuracy in challenging surgical environments.', 'abstract_zh': '准确的相机到机器人校准对于任何基于视觉的机器人控制系统至关重要，尤其是在微创手术机器人中尤其重要，因为器械执行精确的微操作。然而，微创手术机器人具有长的运动链和部分可见的自由度，这为假设刚性机器人且具有良好视野的传统相机到机器人校准方法带来了挑战。以往的工作已经研究了基于关键点和基于渲染的方法来解决这一挑战；然而，这些方法往往在一致的关键点检测或长推理时间方面存在问题，这两种情况都不适合在线机器人控制。在本文中，我们提出了一种新颖的框架，通过共享编码同时检测几何原语（关键点和轴边），从而通过投影几何实现高效的姿态估计。该架构在一次推理中同时检测关键点和边，并在带有投影标注的大规模合成数据上进行训练。该方法在特征检测和姿态估计两方面进行了评估，定性和定量结果表明，其在挑战性的手术环境中具有快速性能和最先进的准确性。', 'title_zh': '在实际条件下使用统一特征检测高效手术机器人器械姿态重构'}
{'arxiv_id': 'arXiv:2510.03529', 'title': 'LapSurgie: Humanoid Robots Performing Surgery via Teleoperated Handheld Laparoscopy', 'authors': 'Zekai Liang, Xiao Liang, Soofiyan Atar, Sreyan Das, Zoe Chiu, Peihan Zhang, Florian Richter, Shanglei Liu, Michael C. Yip', 'link': 'https://arxiv.org/abs/2510.03529', 'abstract': 'Robotic laparoscopic surgery has gained increasing attention in recent years for its potential to deliver more efficient and precise minimally invasive procedures. However, adoption of surgical robotic platforms remains largely confined to high-resource medical centers, exacerbating healthcare disparities in rural and low-resource regions. To close this gap, a range of solutions has been explored, from remote mentorship to fully remote telesurgery. Yet, the practical deployment of surgical robotic systems to underserved communities remains an unsolved challenge. Humanoid systems offer a promising path toward deployability, as they can directly operate in environments designed for humans without extensive infrastructure modifications -- including operating rooms. In this work, we introduce LapSurgie, the first humanoid-robot-based laparoscopic teleoperation framework. The system leverages an inverse-mapping strategy for manual-wristed laparoscopic instruments that abides to remote center-of-motion constraints, enabling precise hand-to-tool control of off-the-shelf surgical laparoscopic tools without additional setup requirements. A control console equipped with a stereo vision system provides real-time visual feedback. Finally, a comprehensive user study across platforms demonstrates the effectiveness of the proposed framework and provides initial evidence for the feasibility of deploying humanoid robots in laparoscopic procedures.', 'abstract_zh': '基于类人机器人的人体腹腔镜远程操作框架：LapSurgie', 'title_zh': 'lapSurgie: 通过遥操手持腹腔镜进行手术的人形机器人'}
{'arxiv_id': 'arXiv:2510.03504', 'title': 'Distributed Connectivity Maintenance and Recovery for Quadrotor Motion Planning', 'authors': 'Yutong Wang, Yichun Qu, Tengxiang Wang, Lishuo Pan, Nora Ayanian', 'link': 'https://arxiv.org/abs/2510.03504', 'abstract': 'Maintaining connectivity is crucial in many multi-robot applications, yet fragile to obstacles and visual occlusions. We present a real-time distributed framework for multi-robot navigation certified by high-order control barrier functions (HOCBFs) that controls inter-robot proximity to maintain connectivity while avoiding collisions. We incorporate control Lyapunov functions to enable connectivity recovery from initial disconnected configurations and temporary losses, providing robust connectivity during navigation in obstacle-rich environments. Our trajectory generation framework concurrently produces planning and control through a Bezier-parameterized trajectory, which naturally provides smooth curves with arbitrary degree of derivatives. The main contribution is the unified MPC-CLF-CBF framework, a continuous-time trajectory generation and control method for connectivity maintenance and recovery of multi-robot systems. We validate the framework through extensive simulations and a physical experiment with 4 Crazyflie nano-quadrotors.', 'abstract_zh': '保持连通性在许多多机器人应用中至关重要，但容易受障碍物和视觉遮挡的影响。我们提出了一种基于高阶控制屏障函数（HOCBFs）的实时分布式多机器人导航框架，该框架通过控制机器人之间的相对距离来维持连通性并避免碰撞。我们结合使用控制李雅普诺夫函数以使多机器人系统从初始断连配置和临时断连中恢复连通性，并在障碍物丰富的环境中提供鲁棒的连通性。我们的轨迹生成框架通过贝塞尔参数化轨迹同时实现规划与控制，自然地提供具有任意阶导数的光滑曲线。主要贡献是一种统一的MPC-CLF-CBF框架，这是一种用于多机器人系统连通性维护与恢复的连续时间轨迹生成与控制方法。我们通过广泛的仿真实验和4个 Crazyflie 纳米四旋翼的实际实验验证了该框架。', 'title_zh': '四旋翼飞行器运动规划中的分布式连通性维护与恢复'}
{'arxiv_id': 'arXiv:2510.03496', 'title': 'Digital-Twin Evaluation for Proactive Human-Robot Collision Avoidance via Prediction-Guided A-RRT*', 'authors': 'Vadivelan Murugesan, Rajasundaram Mathiazhagan, Sanjana Joshi, Aliasghar Arab', 'link': 'https://arxiv.org/abs/2510.03496', 'abstract': 'Human-robot collaboration requires precise prediction of human motion over extended horizons to enable proactive collision avoidance. Unlike existing planners that rely solely on kinodynamic models, we present a prediction-driven safe planning framework that leverages granular, joint-by-joint human motion forecasting validated in a physics-based digital twin. A capsule-based artificial potential field (APF) converts these granular predictions into collision risk metrics, triggering an Adaptive RRT* (A-RRT*) planner when thresholds are exceeded. The depth camera is used to extract 3D skeletal poses and a convolutional neural network-bidirectional long short-term memory (CNN-BiLSTM) model to predict individual joint trajectories ahead of time. A digital twin model integrates real-time human posture prediction placed in front of a simulated robot to evaluate motions and physical contacts. The proposed method enables validation of planned trajectories ahead of time and bridging potential latency gaps in updating planned trajectories in real-time. In 50 trials, our method achieved 100% proactive avoidance with > 250 mm clearance and sub-2 s replanning, demonstrating superior precision and reliability compared to existing kinematic-only planners through the integration of predictive human modeling with digital twin validation.', 'abstract_zh': '人类与机器人协作需要精确预测长时间尺度的人类运动以实现主动避障。我们的工作提出了一种预测驱动的安全规划框架，该框架利用基于物理的数字孪生验证的粒度化、关节级的人运动预测。基于胶囊的人工势场将这些粒度化预测转换为碰撞风险度量，并在阈值被超过时触发自适应RRT* (A-RRT*) 规划器。深度相机用于提取3D骨骼姿态，而卷积神经网络双向长短期记忆（CNN-BiLSTM）模型用于提前预测各关节轨迹。数字孪生模型将实时人类姿态预测置于模拟机器人之前，以评估运动和物理接触。所提出的方法能够提前验证规划轨迹并弥补实时更新规划轨迹时潜在的时延缺口。在50次试验中，我们的方法实现了超过250毫米的安全距离和亚2秒的重规划，通过将预测的人类建模与数字孪生验证集成，其精度和可靠性优于现有仅依赖kinematic模型的规划器。', 'title_zh': '基于预测引导A-RRT*的前瞻性人机碰撞规避数字 Twin 评估'}
{'arxiv_id': 'arXiv:2510.03481', 'title': 'Robust Permissive Controller Synthesis for Interval MDPs', 'authors': 'Khang Vo Huynh, David Parker, Lu Feng', 'link': 'https://arxiv.org/abs/2510.03481', 'abstract': 'We address the problem of robust permissive controller synthesis for robots operating under uncertain dynamics, modeled as Interval Markov Decision Processes (IMDPs). IMDPs generalize standard MDPs by allowing transition probabilities to vary within intervals, capturing epistemic uncertainty from sensing noise, actuation imprecision, and coarse system abstractions-common in robotics. Traditional controller synthesis typically yields a single deterministic strategy, limiting adaptability. In contrast, permissive controllers (multi-strategies) allow multiple actions per state, enabling runtime flexibility and resilience. However, prior work on permissive controller synthesis generally assumes exact transition probabilities, which is unrealistic in many robotic applications. We present the first framework for robust permissive controller synthesis on IMDPs, guaranteeing that all strategies compliant with the synthesized multi-strategy satisfy reachability or reward-based specifications under all admissible transitions. We formulate the problem as mixed-integer linear programs (MILPs) and propose two encodings: a baseline vertex-enumeration method and a scalable duality-based method that avoids explicit enumeration. Experiments on four benchmark domains show that both methods synthesize robust, maximally permissive controllers and scale to large IMDPs with up to hundreds of thousands of states.', 'abstract_zh': '我们针对机器人在不确定动力学条件下操作的鲁棒容错控制器综合问题，将其建模为区间马尔可夫决策过程（IMDPs）。我们提出了一种框架，用于在IMDPs上进行鲁棒容错控制器综合，确保所有与合成的多策略兼容的策略，在所有容许的转换下都能满足可达性或基于奖励的规范。我们将问题形式化为混合整数线性规划（MILPs），并提出两种编码方法：基于顶点枚举的基本方法和一种避免显式枚举的可扩展对偶方法。实验结果表明，这两种方法都能合成出鲁棒性和容错性最高的控制器，并适用于多达数十万个状态的大型IMDPs。', 'title_zh': '区间MDP中鲁棒许可控制器综合'}
{'arxiv_id': 'arXiv:2510.03472', 'title': 'Destination-to-Chutes Task Mapping Optimization for Multi-Robot Coordination in Robotic Sorting Systems', 'authors': 'Yulun Zhang, Alexandre O. G. Barbosa, Federico Pecora, Jiaoyang Li', 'link': 'https://arxiv.org/abs/2510.03472', 'abstract': 'We study optimizing a destination-to-chutes task mapping to improve throughput in Robotic Sorting Systems (RSS), where a team of robots sort packages on a sortation floor by transporting them from induct workstations to eject chutes based on their shipping destinations (e.g. Los Angeles or Pittsburgh). The destination-to-chutes task mapping is used to determine which chutes a robot can drop its package. Finding a high-quality task mapping is challenging because of the complexity of a real-world RSS. First, optimizing task mapping is interdependent with robot target assignment and path planning. Second, chutes will be CLOSED for a period of time once they receive sufficient packages to allow for downstream processing. Third, task mapping quality directly impacts the downstream processing, as scattered chutes for the same destination increase package handling time. In this paper, we first formally define task mappings and the problem of Task Mapping Optimization (TMO). We then present a simulator of RSS to evaluate task mappings. We then present a simple TMO method based on the Evolutionary Algorithm and Mixed Integer Linear Programming, demonstrating the advantage of our optimized task mappings over the greedily generated ones in various RSS setups with different map sizes, numbers of chutes, and destinations. Finally, we use Quality Diversity algorithms to analyze the throughput of a diverse set of task mappings. Our code is available online at this https URL.', 'abstract_zh': '我们在机器人分拣系统中优化目的地到滑槽的任务映射以提高 throughput', 'title_zh': '多机器人 coordination 在机器人分拣系统中的目的地到漏斗任务映射优化'}
{'arxiv_id': 'arXiv:2510.03471', 'title': 'A Simulation Evaluation Suite for Robust Adaptive Quadcopter Control', 'authors': 'Dingqi Zhang, Ran Tao, Sheng Cheng, Naira Hovakimyan, Mark W. Mueller', 'link': 'https://arxiv.org/abs/2510.03471', 'abstract': "Robust adaptive control methods are essential for maintaining quadcopter performance under external disturbances and model uncertainties. However, fragmented evaluations across tasks, simulators, and implementations hinder systematic comparison of these methods. This paper introduces an easy-to-deploy, modular simulation testbed for quadcopter control, built on RotorPy, that enables evaluation under a wide range of disturbances such as wind, payload shifts, rotor faults, and control latency. The framework includes a library of representative adaptive and non-adaptive controllers and provides task-relevant metrics to assess tracking accuracy and robustness. The unified modular environment enables reproducible evaluation across control methods and eliminates redundant reimplementation of components such as disturbance models, trajectory generators, and analysis tools. We illustrate the testbed's versatility through examples spanning multiple disturbance scenarios and trajectory types, including automated stress testing, to demonstrate its utility for systematic analysis. Code is available at this https URL.", 'abstract_zh': '鲁棒自适应控制方法对于在外部干扰和模型不确定性环境下保持四旋翼飞行器性能至关重要。然而，任务、模拟器和实现之间的碎片化评估阻碍了这些方法的系统比较。本文介绍了一个基于RotorPy的易于部署且模块化的四旋翼飞行器控制仿真测试床，能够在广泛的干扰条件下（如风、载荷变化、旋翼故障和控制延迟）进行评估。该框架包含一组代表性的自适应和非自适应控制器库，并提供了与任务相关的评估指标，以评估跟踪精度和鲁棒性。统一的模块化环境使得不同控制方法的可重复评估成为可能，并消除了干扰模型、轨迹生成器和分析工具等组件的冗余重新实现。通过涵盖多种干扰场景和轨迹类型的示例，本文展示了测试床的多功能性，并通过自动化压力测试来证明其在系统分析中的实用性。代码可在以下链接获取：this https URL。', 'title_zh': '鲁棒自适应 quadcopter 控制的仿真评估套件'}
{'arxiv_id': 'arXiv:2510.03460', 'title': 'Warm-Starting Optimization-Based Motion Planning for Robotic Manipulators via Point Cloud-Conditioned Flow Matching', 'authors': 'Sibo Tian, Minghui Zheng, Xiao Liang', 'link': 'https://arxiv.org/abs/2510.03460', 'abstract': 'Rapid robot motion generation is critical in Human-Robot Collaboration (HRC) systems, as robots need to respond to dynamic environments in real time by continuously observing their surroundings and replanning their motions to ensure both safe interactions and efficient task execution. Current sampling-based motion planners face challenges in scaling to high-dimensional configuration spaces and often require post-processing to interpolate and smooth the generated paths, resulting in time inefficiency in complex environments. Optimization-based planners, on the other hand, can incorporate multiple constraints and generate smooth trajectories directly, making them potentially more time-efficient. However, optimization-based planners are sensitive to initialization and may get stuck in local minima. In this work, we present a novel learning-based method that utilizes a Flow Matching model conditioned on a single-view point cloud to learn near-optimal solutions for optimization initialization. Our method does not require prior knowledge of the environment, such as obstacle locations and geometries, and can generate feasible trajectories directly from single-view depth camera input. Simulation studies on a UR5e robotic manipulator in cluttered workspaces demonstrate that the proposed generative initializer achieves a high success rate on its own, significantly improves the success rate of trajectory optimization compared with traditional and learning-based benchmark initializers, requires fewer optimization iterations, and exhibits strong generalization to unseen environments.', 'abstract_zh': '基于流匹配的单视角点云引导快速机器人运动生成在人机协作系统中的应用', 'title_zh': '基于点云条件流匹配的暖启动优化驱动运动规划方法在机器人 manipulator 中的应用'}
{'arxiv_id': 'arXiv:2510.03457', 'title': 'Optimal swimming with body compliance in an overdamped medium', 'authors': 'Jianfeng Lin, Tianyu Wang, Baxi Chong, Matthew Fernandez, Zhaochen Xu, Daniel I. Goldman', 'link': 'https://arxiv.org/abs/2510.03457', 'abstract': "Elongate animals and robots use undulatory body waves to locomote through diverse environments. Geometric mechanics provides a framework to model and optimize such systems in highly damped environments, connecting a prescribed shape change pattern (gait) with locomotion displacement. However, existing approaches assume precise execution of prescribed gaits, whereas in practice environmental interactions with compliant bodies of animals or robots frequently perturb the realized trajectories. In this work, we extend geometric mechanics to predict locomotor performance and search for optimal swimming strategy of compliant undulators. We introduce a compliant extension of Purcell's three-link swimmer by incorporating series-connected springs at the joints. Body dynamics are derived with resistive force theory. Geometric mechanics is incorporated into movement prediction and into an optimization framework that identifies strategies for controlling compliant swimmers to achieve maximal displacement. We validate our framework on a physical cable-driven three-link limbless robot, and demonstrate accurate prediction and optimization of locomotor performance under varied programmed, state-dependent compliance in a granular medium. Our results establish a systematic physics-based approach for modeling and controlling compliant swimming locomotion, highlighting compliance as a design feature that can be exploited for robust movement in homogeneous and heterogeneous environments.", 'abstract_zh': '延展形动物和机器人通过运用波状身体波动在多变环境中移动。几何力学提供了一种框架来模拟和优化此类系统在高度阻尼环境中的性能，将预设的形状变化模式（步态）与移动位移联系起来。然而，现有的方法假设预设步态的精确执行，而在实际中，环境与动物或机器人柔体的交互会频繁地扰动实现轨迹。本文扩展了几何力学，以预测柔体波动器的运动性能并寻找最优游动策略。我们通过在关节处引入串联弹簧，提出了一种Purcell三连杆泳者柔性的扩展版本。机体动力学通过阻力力理论推导得出。几何力学被纳入运动预测和一个优化框架中，该框架能够识别控制柔韧性游动器以实现最大位移的策略。我们通过一个物理驱动的三连杆无肢机器人验证了我们的框架，并在不同的程序化、状态依赖性柔顺性下在颗粒介质中展示了准确的运动性能预测和优化。我们的结果建立了一种系统的基础物理学方法，用于模拟和控制柔韧性游动运动，强调柔顺性作为可以在均质和非均质环境中实现稳健运动的一种设计特征。', 'title_zh': '具有身体顺应性的最优游泳在过阻尼介质中'}
{'arxiv_id': 'arXiv:2510.03342', 'title': 'Gemini Robotics 1.5: Pushing the Frontier of Generalist Robots with Advanced Embodied Reasoning, Thinking, and Motion Transfer', 'authors': "Abbas Abdolmaleki, Saminda Abeyruwan, Joshua Ainslie, Jean-Baptiste Alayrac, Montserrat Gonzalez Arenas, Ashwin Balakrishna, Nathan Batchelor, Alex Bewley, Jeff Bingham, Michael Bloesch, Konstantinos Bousmalis, Philemon Brakel, Anthony Brohan, Thomas Buschmann, Arunkumar Byravan, Serkan Cabi, Ken Caluwaerts, Federico Casarini, Christine Chan, Oscar Chang, London Chappellet-Volpini, Jose Enrique Chen, Xi Chen, Hao-Tien Lewis Chiang, Krzysztof Choromanski, Adrian Collister, David B. D'Ambrosio, Sudeep Dasari, Todor Davchev, Meet Kirankumar Dave, Coline Devin, Norman Di Palo, Tianli Ding, Carl Doersch, Adil Dostmohamed, Yilun Du, Debidatta Dwibedi, Sathish Thoppay Egambaram, Michael Elabd, Tom Erez, Xiaolin Fang, Claudio Fantacci, Cody Fong, Erik Frey, Chuyuan Fu, Ruiqi Gao, Marissa Giustina, Keerthana Gopalakrishnan, Laura Graesser, Oliver Groth, Agrim Gupta, Roland Hafner, Steven Hansen, Leonard Hasenclever, Sam Haves, Nicolas Heess, Brandon Hernaez, Alex Hofer, Jasmine Hsu, Lu Huang, Sandy H. Huang, Atil Iscen, Mithun George Jacob, Deepali Jain, Sally Jesmonth, Abhishek Jindal, Ryan Julian, Dmitry Kalashnikov, M. Emre Karagozler, Stefani Karp, Matija Kecman, J. Chase Kew, Donnie Kim, Frank Kim, Junkyung Kim, Thomas Kipf, Sean Kirmani, Ksenia Konyushkova, Li Yang Ku, Yuheng Kuang, Thomas Lampe, Antoine Laurens, Tuan Anh Le, Isabel Leal, Alex X. Lee, Tsang-Wei Edward Lee, Guy Lever, Jacky Liang, Li-Heng Lin, Fangchen Liu, Shangbang Long, Caden Lu, Sharath Maddineni, Anirudha Majumdar, Kevis-Kokitsi Maninis, Andrew Marmon, Sergio Martinez, Assaf Hurwitz Michaely, Niko Milonopoulos, Joss Moore", 'link': 'https://arxiv.org/abs/2510.03342', 'abstract': 'General-purpose robots need a deep understanding of the physical world, advanced reasoning, and general and dexterous control. This report introduces the latest generation of the Gemini Robotics model family: Gemini Robotics 1.5, a multi-embodiment Vision-Language-Action (VLA) model, and Gemini Robotics-ER 1.5, a state-of-the-art Embodied Reasoning (ER) model. We are bringing together three major innovations. First, Gemini Robotics 1.5 features a novel architecture and a Motion Transfer (MT) mechanism, which enables it to learn from heterogeneous, multi-embodiment robot data and makes the VLA more general. Second, Gemini Robotics 1.5 interleaves actions with a multi-level internal reasoning process in natural language. This enables the robot to "think before acting" and notably improves its ability to decompose and execute complex, multi-step tasks, and also makes the robot\'s behavior more interpretable to the user. Third, Gemini Robotics-ER 1.5 establishes a new state-of-the-art for embodied reasoning, i.e., for reasoning capabilities that are critical for robots, such as visual and spatial understanding, task planning, and progress estimation. Together, this family of models takes us a step towards an era of physical agents-enabling robots to perceive, think and then act so they can solve complex multi-step tasks.', 'abstract_zh': '通用机器人需要对物理世界有深入的理解、高级推理能力和通用的灵巧控制。本报告介绍了Gemini Robotics模型家族的最新一代：Gemini Robotics 1.5，这是一种多体态视觉-语言-行动（VLA）模型，以及Gemini Robotics-ER 1.5，这是一种最先进的体态推理（ER）模型。我们结合了三项重大创新。首先，Gemini Robotics 1.5具有新颖的架构和动作转移（MT）机制，使其能够从异构的多体态机器人数据中学习，并使VLA更具通用性。其次，Gemini Robotics 1.5在自然语言中交替进行动作和多层次的内部推理过程。这使机器人能够在行动前进行“思考”，显著提高了其分解和执行复杂多步骤任务的能力，也使机器人的行为更具用户可解释性。第三，Gemini Robotics-ER 1.5在体态推理领域建立了新的最先进的标准，例如对于机器人至关重要的视觉和空间理解、任务规划和进度估计能力。这些模型共同将我们带向一个物理代理的时代，使机器人能够感知、思考然后行动，以解决复杂的多步骤任务。', 'title_zh': 'Gemini Robotics 1.5: 推动通用机器人前沿的高级主体推理、思考与运动转移'}
{'arxiv_id': 'arXiv:2510.04807', 'title': 'Efficient Probabilistic Planning with Maximum-Coverage Distributionally Robust Backward Reachable Trees', 'authors': 'Alex Rose, Naman Aggarwal, Christopher Jewison, Jonathan P. How', 'link': 'https://arxiv.org/abs/2510.04807', 'abstract': 'This paper presents a new multi-query motion planning algorithm for linear Gaussian systems with the goal of reaching a Euclidean ball with high probability. We develop a new formulation for ball-shaped ambiguity sets of Gaussian distributions and leverage it to develop a distributionally robust belief roadmap construction algorithm. This algorithm synthe- sizes robust controllers which are certified to be safe for maximal size ball-shaped ambiguity sets of Gaussian distributions. Our algorithm achieves better coverage than the maximal coverage algorithm for planning over Gaussian distributions [1], and we identify mild conditions under which our algorithm achieves strictly better coverage. For the special case of no process noise or state constraints, we formally prove that our algorithm achieves maximal coverage. In addition, we present a second multi-query motion planning algorithm for linear Gaussian systems with the goal of reaching a region parameterized by the Minkowski sum of an ellipsoid and a Euclidean ball with high probability. This algorithm plans over ellipsoidal sets of maximal size ball-shaped ambiguity sets of Gaussian distributions, and provably achieves equal or better coverage than the best-known algorithm for planning over ellipsoidal ambiguity sets of Gaussian distributions [2]. We demonstrate the efficacy of both methods in a wide range of conditions via extensive simulation experiments.', 'abstract_zh': '一种针对线性高斯系统的新多查询运动规划算法：以高概率到达欧几里得球体', 'title_zh': '高效的最大覆盖分布鲁棒逆向可达树概率规划'}
{'arxiv_id': 'arXiv:2510.04666', 'title': 'Learning a Shape-adaptive Assist-as-needed Rehabilitation Policy from Therapist-informed Input', 'authors': 'Zhimin Hou, Jiacheng Hou, Xiao Chen, Hamid Sadeghian, Tianyu Ren, Sami Haddadin', 'link': 'https://arxiv.org/abs/2510.04666', 'abstract': 'Therapist-in-the-loop robotic rehabilitation has shown great promise in enhancing rehabilitation outcomes by integrating the strengths of therapists and robotic systems. However, its broader adoption remains limited due to insufficient safe interaction and limited adaptation capability. This article proposes a novel telerobotics-mediated framework that enables therapists to intuitively and safely deliver assist-as-needed~(AAN) therapy based on two primary contributions. First, our framework encodes the therapist-informed corrective force into via-points in a latent space, allowing the therapist to provide only minimal assistance while encouraging patient maintaining own motion preferences. Second, a shape-adaptive ANN rehabilitation policy is learned to partially and progressively deform the reference trajectory for movement therapy based on encoded patient motion preferences and therapist-informed via-points. The effectiveness of the proposed shape-adaptive AAN strategy was validated on a telerobotic rehabilitation system using two representative tasks. The results demonstrate its practicality for remote AAN therapy and its superiority over two state-of-the-art methods in reducing corrective force and improving movement smoothness.', 'abstract_zh': '基于治疗师主导的机器人康复循环框架在增强康复效果方面的潜力及其挑战与解决方案：一种新颖的远程康复策略', 'title_zh': '基于治疗师信息的适应形体辅助性康复政策学习'}
{'arxiv_id': 'arXiv:2510.04532', 'title': 'More Than Meets the Eye? Uncovering the Reasoning-Planning Disconnect in Training Vision-Language Driving Models', 'authors': 'Xurui Song, Shuo Huai, JingJing Jiang, Jiayi Kong, Jun Luo', 'link': 'https://arxiv.org/abs/2510.04532', 'abstract': "Vision-Language Model (VLM) driving agents promise explainable end-to-end autonomy by first producing natural-language reasoning and then predicting trajectory planning. However, whether planning is causally driven by this reasoning remains a critical but unverified assumption. To investigate this, we build DriveMind, a large-scale driving Visual Question Answering (VQA) corpus with plan-aligned Chain-of-Thought (CoT), automatically generated from nuPlan. Our data generation process converts sensors and annotations into structured inputs and, crucially, separates priors from to-be-reasoned signals, enabling clean information ablations. Using DriveMind, we train representative VLM agents with Supervised Fine-Tuning (SFT) and Group Relative Policy Optimization (GRPO) and evaluate them with nuPlan's metrics. Our results, unfortunately, indicate a consistent causal disconnect in reasoning-planning: removing ego/navigation priors causes large drops in planning scores, whereas removing CoT produces only minor changes. Attention analysis further shows that planning primarily focuses on priors rather than the CoT. Based on this evidence, we propose the Reasoning-Planning Decoupling Hypothesis, positing that the training-yielded reasoning is an ancillary byproduct rather than a causal mediator. To enable efficient diagnosis, we also introduce a novel, training-free probe that measures an agent's reliance on priors by evaluating its planning robustness against minor input perturbations. In summary, we provide the community with a new dataset and a diagnostic tool to evaluate the causal fidelity of future models.", 'abstract_zh': '基于视觉-语言模型的驾驶代理承诺实现可解释的端到端自主驾驶，首先产生自然语言推理，然后预测轨迹规划。然而，这种规划是否由这种推理因果驱动仍是一个关键但未验证的假设。为调查这一问题，我们构建了DriveMind，这是一个与计划对齐的链式思维大规模驾驶视觉问答语料库，自动生成自nuPlan。我们的数据生成过程将传感器和注释转换为结构化输入，并 crucial地将先验知识与待推理的信号分离，从而实现清洁的信息消融。使用DriveMind，我们使用监督微调（SFT）和组相对策略优化（GRPO）训练代表性视觉-语言模型代理，并使用nuPlan的指标进行评估。不幸的是，我们的结果显示了推理-规划中的一致因果脱节：移除自/导航先验会导致规划得分的大幅下降，而移除链式思维仅产生轻微变化。注意力分析进一步显示，规划主要关注先验而非链式思维。基于这些证据，我们提出了推理-规划脱耦假设，认为训练产生的推理只是一个辅助副产品，而非因果中介。为了实现高效的诊断，我们还引入了一种新的、无需训练的探针，通过评估代理在轻微输入扰动下的规划鲁棒性来衡量其对先验的依赖程度。总之，我们为社区提供了新的数据集和诊断工具，以评估未来模型的因果忠实度。', 'title_zh': '不仅仅是表面所见？揭示视觉-语言驾驶模型中推理-规划的缺口'}
{'arxiv_id': 'arXiv:2510.04333', 'title': 'RAP: 3D Rasterization Augmented End-to-End Planning', 'authors': 'Lan Feng, Yang Gao, Eloi Zablocki, Quanyi Li, Wuyang Li, Sichao Liu, Matthieu Cord, Alexandre Alahi', 'link': 'https://arxiv.org/abs/2510.04333', 'abstract': 'Imitation learning for end-to-end driving trains policies only on expert demonstrations. Once deployed in a closed loop, such policies lack recovery data: small mistakes cannot be corrected and quickly compound into failures. A promising direction is to generate alternative viewpoints and trajectories beyond the logged path. Prior work explores photorealistic digital twins via neural rendering or game engines, but these methods are prohibitively slow and costly, and thus mainly used for evaluation. In this work, we argue that photorealism is unnecessary for training end-to-end planners. What matters is semantic fidelity and scalability: driving depends on geometry and dynamics, not textures or lighting. Motivated by this, we propose 3D Rasterization, which replaces costly rendering with lightweight rasterization of annotated primitives, enabling augmentations such as counterfactual recovery maneuvers and cross-agent view synthesis. To transfer these synthetic views effectively to real-world deployment, we introduce a Raster-to-Real feature-space alignment that bridges the sim-to-real gap. Together, these components form Rasterization Augmented Planning (RAP), a scalable data augmentation pipeline for planning. RAP achieves state-of-the-art closed-loop robustness and long-tail generalization, ranking first on four major benchmarks: NAVSIM v1/v2, Waymo Open Dataset Vision-based E2E Driving, and Bench2Drive. Our results show that lightweight rasterization with feature alignment suffices to scale E2E training, offering a practical alternative to photorealistic rendering. Project page: this https URL.', 'abstract_zh': '基于模仿学习的端到端驾驶训练仅依赖于专家演示。部署成闭环后，这类策略缺乏恢复数据：小错误无法纠正并迅速复合成失败。一种有前景的方向是生成超越记录路径的替代视点和轨迹。先前的工作通过神经渲染或游戏引擎探索逼真的数字孪生，但这些方法耗时且成本高昂，因此主要用于评估。在本文中，我们argue逼真度并不是训练端到端规划器所需要的。重要的是语义保真度和扩展性：驾驶依赖于几何和动力学，而非纹理或照明。受此启发，我们提出了3D栅格化，用轻量级的标注原语的栅格化替代昂贵的渲染，使counterfactual恢复机动和跨agent视图合成成为可能。为有效地将这些合成视图转移到实际部署中，我们引入了一种栅格化到现实的特征空间对齐，以弥合仿真到现实的差距。这些组件共同构成了栅格化增强规划（RAP），这是一种扩展性的规划数据增强流水线。RAP在闭环稳健性和长尾泛化方面达到了最佳效果，在四个主要基准测试中排名第一：NASIM v1/v2、Waymo开放数据集基于视觉的端到端驾驶以及Bench2Drive。我们的结果显示，带有特征对齐的轻量级栅格化足以扩展端到端训练，为逼真渲染提供了一个实用的替代方案。项目页面：this https URL。', 'title_zh': 'RAP: 3D 光栅化增强端到端规划'}
{'arxiv_id': 'arXiv:2510.04280', 'title': 'A KL-regularization framework for learning to plan with adaptive priors', 'authors': 'Álvaro Serra-Gomez, Daniel Jarne Ornia, Dhruva Tirumala, Thomas Moerland', 'link': 'https://arxiv.org/abs/2510.04280', 'abstract': "Effective exploration remains a central challenge in model-based reinforcement learning (MBRL), particularly in high-dimensional continuous control tasks where sample efficiency is crucial. A prominent line of recent work leverages learned policies as proposal distributions for Model-Predictive Path Integral (MPPI) planning. Initial approaches update the sampling policy independently of the planner distribution, typically maximizing a learned value function with deterministic policy gradient and entropy regularization. However, because the states encountered during training depend on the MPPI planner, aligning the sampling policy with the planner improves the accuracy of value estimation and long-term performance. To this end, recent methods update the sampling policy by minimizing KL divergence to the planner distribution or by introducing planner-guided regularization into the policy update. In this work, we unify these MPPI-based reinforcement learning methods under a single framework by introducing Policy Optimization-Model Predictive Control (PO-MPC), a family of KL-regularized MBRL methods that integrate the planner's action distribution as a prior in policy optimization. By aligning the learned policy with the planner's behavior, PO-MPC allows more flexibility in the policy updates to trade off Return maximization and KL divergence minimization. We clarify how prior approaches emerge as special cases of this family, and we explore previously unstudied variations. Our experiments show that these extended configurations yield significant performance improvements, advancing the state of the art in MPPI-based RL.", 'abstract_zh': '基于模型的强化学习中有效的探索依然是一个核心挑战，特别是在高维度连续控制任务中，样本效率至关重要。最近的一项主要研究方向是利用学习得到的策略作为Model-Predictive Path Integral (MPPI) 规划的提议分布。早期的方法独立地更新采样策略，并通常通过确定性策略梯度和熵正则化最大化学习的价值函数。然而，由于训练过程中遇到的状态依赖于MPPI规划器，使采样策略与规划器对齐可以提高价值估计的准确性以及长期性能。为此，最近的方法通过最小化KL散度或通过引入规划器引导的正则化来更新采样策略。在这项工作中，我们通过引入Policy Optimization-Model Predictive Control (PO-MPC)框架，将这些基于MPPI的强化学习方法统一起来，这是一种通过将规划器的动作分布作为先验整合到策略优化中的KL正则化MBRL方法族。通过使学习到的策略与规划器的行为对齐，PO-MPC在策略更新中提供了更多灵活性，以平衡回报最大化和KL散度最小化。我们阐明了先前方法作为这一家族的特殊案例，并探索了未研究的变体。我们的实验表明，这些扩展配置显著提高了基于MPPI的RL的性能，推动了该领域的前沿。', 'title_zh': '基于自适应先验的KL-正则化规划学习框架'}
{'arxiv_id': 'arXiv:2510.03915', 'title': 'OpenFLAME: Federated Visual Positioning System to Enable Large-Scale Augmented Reality Applications', 'authors': 'Sagar Bharadwaj, Harrison Williams, Luke Wang, Michael Liang, Tao Jin, Srinivasan Seshan, Anthony Rowe', 'link': 'https://arxiv.org/abs/2510.03915', 'abstract': 'World-scale augmented reality (AR) applications need a ubiquitous 6DoF localization backend to anchor content to the real world consistently across devices. Large organizations such as Google and Niantic are 3D scanning outdoor public spaces in order to build their own Visual Positioning Systems (VPS). These centralized VPS solutions fail to meet the needs of many future AR applications -- they do not cover private indoor spaces because of privacy concerns, regulations, and the labor bottleneck of updating and maintaining 3D scans. In this paper, we present OpenFLAME, a federated VPS backend that allows independent organizations to 3D scan and maintain a separate VPS service for their own spaces. This enables access control of indoor 3D scans, distributed maintenance of the VPS backend, and encourages larger coverage. Sharding of VPS services introduces several unique challenges -- coherency of localization results across spaces, quality control of VPS services, selection of the right VPS service for a location, and many others. We introduce the concept of federated image-based localization and provide reference solutions for managing and merging data across maps without sharing private data.', 'abstract_zh': '面向全球的扩展现实（AR）应用需要一个通用的6DoF定位后端，以在不同设备上一致地将内容锚定到现实世界。谷歌和尼安蒂克等大型组织正在扫描户外公共空间以构建自己的视觉定位系统（VPS）。这些集中式的VPS解决方案无法满足未来AR应用的需求——由于隐私担忧、法规以及更新和维护3D扫描的劳动瓶颈，它们无法覆盖私人室内空间。本文介绍了OpenFLAME，一种允许独立组织单独扫描并维护其自身空间VPS服务的联邦VPS后端，这使得室内3D扫描的访问控制、VPS后端的分布式维护以及增加覆盖范围成为可能。VPS服务的分片带来了许多独特的挑战——跨空间的一致性定位结果、VPS服务的质量控制、选择合适的位置VPS服务等。我们引入了联邦图像ベース定位的概念，并提供了管理和合并地图数据而不共享私人数据的参考解决方案。', 'title_zh': '开放FLAME：联邦视觉定位系统，以实现大规模增强现实应用'}
{'arxiv_id': 'arXiv:2510.03896', 'title': 'Bridge Thinking and Acting: Unleashing Physical Potential of VLM with Generalizable Action Expert', 'authors': 'Mingyu Liu, Zheng Huang, Xiaoyi Lin, Muzhi Zhu, Canyu Zhao, Zongze Du, Yating Wang, Haoyi Zhu, Hao Chen, Chunhua Shen', 'link': 'https://arxiv.org/abs/2510.03896', 'abstract': 'Although Vision-Language Models (VLM) have demonstrated impressive planning and reasoning capabilities, translating these abilities into the physical world introduces significant challenges. Conventional Vision-Language-Action (VLA) models, which integrate reasoning and action into a monolithic architecture, generalize poorly because they are constrained by scarce, narrow-domain data. While recent dual-system approaches attempt to decouple "thinking" from "acting", they are often constrained by semantic ambiguities within the action module. This ambiguity makes large-scale, cross-task training infeasible. Consequently, these systems typically necessitate fine-tuning on newly collected data when deployed to novel environments, and the cooperation mechanism between the two systems remains ill-defined. To address these limitations, we introduce, for the first time, a framework centered around a generalizable action expert. Our approach utilizes sparse 3D trajectories as an intermediate representation, effectively bridging the high-level planning capabilities of the VLM with the low-level physical action module. During the planning phase, the VLM is only required to generate coarse 3D waypoints. These waypoints are then processed by our generalizable action expert, which refines them into dense, executable action sequences by sampling real-time point cloud observations of the environment. To promote training efficiency and robust generalization, we introduce a novel "Action Pre-training, Pointcloud Fine-tuning" paradigm. Our method combines the broad generalization capabilities of VLMs in visual understanding and planning with the fine-grained, action-level generalization of action expert.', 'abstract_zh': '虽然视觉语言模型（VLM）展现了令人印象深刻的规划和推理能力，但将其能力转化为物理世界引入了重大挑战。传统的视觉语言动作（VLA）模型由于受限于少量和领域狭窄的数据，在泛化能力上表现不佳。尽管近期的双系统方法试图将“思考”与“动作”解耦，但它们往往受到动作模块内语义歧义的限制，这使得大规模跨任务训练变得不可行。因此，当这些系统部署到新环境中时，通常需要对新收集的数据进行微调，且两个系统的合作机制仍不明确。为解决这些局限性，我们首次提出了一种以可泛化动作专家为中心的框架。我们的方法利用稀疏的3D轨迹作为中间表示，有效连接了VLM的高层规划能力和低层物理动作模块。在规划阶段，VLM仅需生成粗略的3D航点。这些航点随后由我们的可泛化动作专家处理，通过实时环境点云观察来细化生成密集的可执行动作序列。为了提高训练效率和增强泛化能力，我们引入了一种新颖的“动作预训练、点云微调”范式。该方法结合了VLM在视觉理解与规划上的广泛泛化能力，以及动作专家在动作级别上的细粒度泛化能力。', 'title_zh': '桥接思考与行动：释放VLM物理潜力的通用行动专家'}
{'arxiv_id': 'arXiv:2510.03827', 'title': 'LIBERO-PRO: Towards Robust and Fair Evaluation of Vision-Language-Action Models Beyond Memorization', 'authors': 'Xueyang Zhou, Yangming Xu, Guiyao Tie, Yongchao Chen, Guowen Zhang, Duanfeng Chu, Pan Zhou, Lichao Sun', 'link': 'https://arxiv.org/abs/2510.03827', 'abstract': "LIBERO has emerged as a widely adopted benchmark for evaluating Vision-Language-Action (VLA) models; however, its current training and evaluation settings are problematic, often leading to inflated performance estimates and preventing fair model comparison. To address these issues, we introduce LIBERO-PRO, an extended LIBERO benchmark that systematically evaluates model performance under reasonable perturbations across four dimensions: manipulated objects, initial states, task instructions, and environments. Experimental results reveal that, although existing models achieve over 90% accuracy under the standard LIBERO evaluation, their performance collapses to 0.0% under our generalized setting. Crucially, this discrepancy exposes the models' reliance on rote memorization of action sequences and environment layouts from the training set, rather than genuine task understanding or environmental perception. For instance, models persist in executing grasping actions when the target object is replaced with irrelevant items, and their outputs remain unchanged even when given corrupted instructions or even messy tokens. These findings expose the severe flaws in current evaluation practices, and we call on the community to abandon misleading methodologies in favor of robust assessments of model generalization and comprehension. Our code is available at: this https URL.", 'abstract_zh': 'LIBERO-PRO：一种系统评估模型在合理扰动下性能的扩展基准', 'title_zh': 'LIBERO-PRO：超越记忆化 toward 视听行模型的稳健与公平评估'}
{'arxiv_id': 'arXiv:2510.03823', 'title': 'Distributed Area Coverage with High Altitude Balloons Using Multi-Agent Reinforcement Learning', 'authors': 'Adam Haroon, Tristan Schuler', 'link': 'https://arxiv.org/abs/2510.03823', 'abstract': 'High Altitude Balloons (HABs) can leverage stratospheric wind layers for limited horizontal control, enabling applications in reconnaissance, environmental monitoring, and communications networks. Existing multi-agent HAB coordination approaches use deterministic methods like Voronoi partitioning and extremum seeking control for large global constellations, which perform poorly for smaller teams and localized missions. While single-agent HAB control using reinforcement learning has been demonstrated on HABs, coordinated multi-agent reinforcement learning (MARL) has not yet been investigated. This work presents the first systematic application of multi-agent reinforcement learning (MARL) to HAB coordination for distributed area coverage. We extend our previously developed reinforcement learning simulation environment (RLHAB) to support cooperative multi-agent learning, enabling multiple agents to operate simultaneously in realistic atmospheric conditions. We adapt QMIX for HAB area coverage coordination, leveraging Centralized Training with Decentralized Execution to address atmospheric vehicle coordination challenges. Our approach employs specialized observation spaces providing individual state, environmental context, and teammate data, with hierarchical rewards prioritizing coverage while encouraging spatial distribution. We demonstrate that QMIX achieves similar performance to the theoretically optimal geometric deterministic method for distributed area coverage, validating the MARL approach and providing a foundation for more complex autonomous multi-HAB missions where deterministic methods become intractable.', 'abstract_zh': '高空 balloon (HABs) 可利用平流层风层进行有限的水平控制，从而在侦察、环境监测和通信网络等方面应用。现有基于多代理的 HAB 协调方法使用如 Voronoi 分区和极值搜索控制等确定性方法，适用于大规模全球星座，但对较小团队和局部任务表现不佳。虽然已经证明使用强化学习（RL）可以控制单个高空气球，但多代理强化学习（MARL）尚未进行研究。本文首次系统地将多代理强化学习（MARL）应用于高空气球协调，以实现分布式区域覆盖。我们扩展了我们之前开发的强化学习仿真环境（RLHAB），以支持协同多代理学习，使多个代理能够在现实的气象条件下同时运行。我们改编 QMIX 以实现高空气球区域覆盖协调，利用集中训练与分散执行相结合的方法解决大气飞行器协调问题。我们的方法采用了专门的观测空间，提供个体状态、环境背景和队友数据，并通过分层奖励优先考虑覆盖同时鼓励空间分布。我们证明QMIX在分布式区域覆盖方面达到了理论最优的几何确定性方法的相似性能，验证了MARL方法，并为当确定性方法变得无法实现时的更复杂自主多高空气球任务奠定了基础。', 'title_zh': '使用多智能体强化学习的高-altitude气球分布式区域覆盖'}
{'arxiv_id': 'arXiv:2510.03592', 'title': 'Deep Reinforcement Learning for Multi-Agent Coordination', 'authors': 'Kehinde O. Aina, Sehoon Ha', 'link': 'https://arxiv.org/abs/2510.03592', 'abstract': 'We address the challenge of coordinating multiple robots in narrow and confined environments, where congestion and interference often hinder collective task performance. Drawing inspiration from insect colonies, which achieve robust coordination through stigmergy -- modifying and interpreting environmental traces -- we propose a Stigmergic Multi-Agent Deep Reinforcement Learning (S-MADRL) framework that leverages virtual pheromones to model local and social interactions, enabling decentralized emergent coordination without explicit communication. To overcome the convergence and scalability limitations of existing algorithms such as MADQN, MADDPG, and MAPPO, we leverage curriculum learning, which decomposes complex tasks into progressively harder sub-problems. Simulation results show that our framework achieves the most effective coordination of up to eight agents, where robots self-organize into asymmetric workload distributions that reduce congestion and modulate group performance. This emergent behavior, analogous to strategies observed in nature, demonstrates a scalable solution for decentralized multi-agent coordination in crowded environments with communication constraints.', 'abstract_zh': '基于昆虫群体行为的分布式多agent深度强化学习协调框架', 'title_zh': '多Agent协调的深度强化学习'}
{'arxiv_id': 'arXiv:2510.03545', 'title': 'SketchPlan: Diffusion Based Drone Planning From Human Sketches', 'authors': 'Sixten Norelius, Aaron O. Feldman, Mac Schwager', 'link': 'https://arxiv.org/abs/2510.03545', 'abstract': "We propose SketchPlan, a diffusion-based planner that interprets 2D hand-drawn sketches over depth images to generate 3D flight paths for drone navigation. SketchPlan comprises two components: a SketchAdapter that learns to map the human sketches to projected 2D paths, and DiffPath, a diffusion model that infers 3D trajectories from 2D projections and a first person view depth image. Our model achieves zero-shot sim-to-real transfer, generating accurate and safe flight paths in previously unseen real-world environments. To train the model, we build a synthetic dataset of 32k flight paths using a diverse set of photorealistic 3D Gaussian Splatting scenes. We automatically label the data by computing 2D projections of the 3D flight paths onto the camera plane, and use this to train the DiffPath diffusion model. However, since real human 2D sketches differ significantly from ideal 2D projections, we additionally label 872 of the 3D flight paths with real human sketches and use this to train the SketchAdapter to infer the 2D projection from the human sketch. We demonstrate SketchPlan's effectiveness in both simulated and real-world experiments, and show through ablations that training on a mix of human labeled and auto-labeled data together with a modular design significantly boosts its capabilities to correctly interpret human intent and infer 3D paths. In real-world drone tests, SketchPlan achieved 100\\% success in low/medium clutter and 40\\% in unseen high-clutter environments, outperforming key ablations by 20-60\\% in task completion.", 'abstract_zh': '基于扩散模型的草图规划器SketchPlan：从深度图像中的手绘草图生成无人机导航的3D飞行路径', 'title_zh': 'SketchPlan: 基于扩散模型的无人机规划方法来自人的草图'}
{'arxiv_id': 'arXiv:2510.03544', 'title': 'Agile Tradespace Exploration for Space Rendezvous Mission Design via Transformers', 'authors': "Yuji Takubo, Daniele Gammelli, Marco Pavone, Simone D'Amico", 'link': 'https://arxiv.org/abs/2510.03544', 'abstract': 'Spacecraft rendezvous enables on-orbit servicing, debris removal, and crewed docking, forming the foundation for a scalable space economy. Designing such missions requires rapid exploration of the tradespace between control cost and flight time across multiple candidate targets. However, multi-objective optimization in this setting is challenging, as the underlying constraints are often highly nonconvex, and mission designers must balance accuracy (e.g., solving the full problem) with efficiency (e.g., convex relaxations), slowing iteration and limiting design agility. To address these challenges, this paper proposes an AI-powered framework that enables agile mission design for a wide range of Earth orbit rendezvous scenarios. Given the orbital information of the target spacecraft, boundary conditions, and a range of flight times, this work proposes a Transformer-based architecture that generates, in a single parallelized inference step, a set of near-Pareto optimal trajectories across varying flight times, thereby enabling rapid mission trade studies. The model is further extended to accommodate variable flight times and perturbed orbital dynamics, supporting realistic multi-objective trade-offs. Validation on chance-constrained rendezvous problems with passive safety constraints demonstrates that the model generalizes across both flight times and dynamics, consistently providing high-quality initial guesses that converge to superior solutions in fewer iterations. Moreover, the framework efficiently approximates the Pareto front, achieving runtimes comparable to convex relaxation by exploiting parallelized inference. Together, these results position the proposed framework as a practical surrogate for nonconvex trajectory generation and mark an important step toward AI-driven trajectory design for accelerating preliminary mission planning in real-world rendezvous applications.', 'abstract_zh': '基于AI的太空探测器对接敏捷任务设计框架：促进在轨服务、碎片清除和载人对接，奠定可扩展太空经济的基础', 'title_zh': '基于变换器的敏捷 Tradespace 探索方法在空间对接任务设计中的应用'}
{'arxiv_id': 'arXiv:2510.03501', 'title': 'Real-Time Threaded Houbara Detection and Segmentation for Wildlife Conservation using Mobile Platforms', 'authors': 'Lyes Saad Saoud, Loic Lesobre, Enrico Sorato, Irfan Hussain', 'link': 'https://arxiv.org/abs/2510.03501', 'abstract': 'Real-time animal detection and segmentation in natural environments are vital for wildlife conservation, enabling non-invasive monitoring through remote camera streams. However, these tasks remain challenging due to limited computational resources and the cryptic appearance of many species. We propose a mobile-optimized two-stage deep learning framework that integrates a Threading Detection Model (TDM) to parallelize YOLOv10-based detection and MobileSAM-based segmentation. Unlike prior YOLO+SAM pipelines, our approach improves real-time performance by reducing latency through threading. YOLOv10 handles detection while MobileSAM performs lightweight segmentation, both executed concurrently for efficient resource use. On the cryptic Houbara Bustard, a conservation-priority species, our model achieves mAP50 of 0.9627, mAP75 of 0.7731, mAP95 of 0.7178, and a MobileSAM mIoU of 0.7421. YOLOv10 operates at 43.7 ms per frame, confirming real-time readiness. We introduce a curated Houbara dataset of 40,000 annotated images to support model training and evaluation across diverse conditions. The code and dataset used in this study are publicly available on GitHub at this https URL. For interactive demos and additional resources, visit this https URL.', 'abstract_zh': '移动优化的两阶段深度学习框架在自然环境中的实时动物检测与分割对于野生动物保护至关重要，能够通过远程摄像头流实现非侵入性监测。然而，由于计算资源有限和许多物种的隐蔽外观，这些任务仍具有挑战性。我们提出了一种移动优化的两阶段深度学习框架，结合了线程检测模型（TDM），以并行化YOLOv10检测和MobileSAM分割。与之前的YOLO+SAM管道不同，我们的方法通过线程减少延迟，以提高实时性能。YOLOv10负责检测，MobileSAM执行轻量级分割，两者并发执行以高效利用资源。对于保护优先物种隐蔽沙雉，我们的模型实现了mAP50为0.9627、mAP75为0.7731、mAP95为0.7178，且MobileSAM的mIoU为0.7421。YOLOv10每帧运行时间为43.7毫秒，证实了实时性。我们提供了包含40,000张标注图像的 curated 沙雉数据集，以支持模型在各种条件下的训练和评估。本研究中使用的代码和数据集已在 GitHub（链接地址）公开。更多信息和互动演示请访问（链接地址）。', 'title_zh': '基于移动平台的实时线程 Houbara 检测与分割用于野生动物保护'}
{'arxiv_id': 'arXiv:2510.03367', 'title': 'Viability-Preserving Passive Torque Control', 'authors': 'Zizhe Zhang, Yicong Wang, Zhiquan Zhang, Tianyu Li, Nadia Figueroa', 'link': 'https://arxiv.org/abs/2510.03367', 'abstract': 'Conventional passivity-based torque controllers for manipulators are typically unconstrained, which can lead to safety violations under external perturbations. In this paper, we employ viability theory to pre-compute safe sets in the state-space of joint positions and velocities. These viable sets, constructed via data-driven and analytical methods for self-collision avoidance, external object collision avoidance and joint-position and joint-velocity limits, provide constraints on joint accelerations and thus joint torques via the robot dynamics. A quadratic programming-based control framework enforces these constraints on a passive controller tracking a dynamical system, ensuring the robot states remain within the safe set in an infinite time horizon. We validate the proposed approach through simulations and hardware experiments on a 7-DoF Franka Emika manipulator. In comparison to a baseline constrained passive controller, our method operates at higher control-loop rates and yields smoother trajectories.', 'abstract_zh': '基于 viability 理论的 manipulator 动力学约束扭矩控制器', 'title_zh': '保 viability 的被动扭矩控制'}
{'arxiv_id': 'arXiv:2510.03300', 'title': 'Adaptive Cruise Control in Autonomous Vehicles: Challenges, Gaps, Comprehensive Review, and, Future Directions', 'authors': 'Shradha Bavalatti, Yash Kangralkar, Santosh Pattar, Veena P Badiger', 'link': 'https://arxiv.org/abs/2510.03300', 'abstract': 'The development of Autonomous Vehicles (AVs) has redefined the way of transportation by eliminating the need for human intervention in driving. This revolution is fueled by rapid advancements in adaptive cruise control (ACC), which make AVs capable of interpreting their surroundings and responding intelligently. While AVs offer significant advantages, such as enhanced safety and improved traffic efficiency, they also face several challenges that need to be addressed. Existing survey papers often lack a comprehensive analysis of these challenges and their potential solutions. Our paper stands out by meticulously identifying these gaps in current ACC research and offering impactful future directions to guide researchers in designing next-generation ACC systems. Our survey provides a detailed and systematic review, addressing the limitations of previous studies and proposing innovative approaches to achieve sustainable and fault-resilient urban transportation.', 'abstract_zh': '自主车辆的发展通过消除驾驶过程中的人为干预重新定义了交通方式。这种革命是由自适应巡航控制（ACC）的迅速进步推动的，使自主车辆能够解读其环境并做出智能响应。虽然自主车辆带来了诸如增强的安全性和提高的交通效率等优势，但它们也面临着需要解决的若干挑战。现有的综述论文往往缺乏对这些挑战及其潜在解决方案的全面分析。我们的论文通过细致地识别当前ACC研究中的空白区域，并提出具有影响的未来发展方向，以指导研究人员设计下一代ACC系统，脱颖而出。我们的综述提供了详细和系统的回顾，解决了先前研究的局限性，并提出了创新的方法以实现可持续和容错的城市交通。', 'title_zh': '自动驾驶车辆的自适应巡航控制：挑战、缺口、综合综述及未来方向'}
