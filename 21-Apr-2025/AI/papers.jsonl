{'arxiv_id': 'arXiv:2504.13837', 'title': 'Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?', 'authors': 'Yang Yue, Zhiqi Chen, Rui Lu, Andrew Zhao, Zhaokai Wang, Yang Yue, Shiji Song, Gao Huang', 'link': 'https://arxiv.org/abs/2504.13837', 'abstract': "Reinforcement Learning with Verifiable Rewards (RLVR) has recently demonstrated notable success in enhancing the reasoning capabilities of LLMs, particularly in mathematics and programming tasks. It is widely believed that RLVR enables LLMs to continuously self-improve, thus acquiring novel reasoning abilities that exceed corresponding base models' capacity. In this study, however, we critically re-examines this assumption by measuring the pass@\\textit{k} metric with large values of \\textit{k} to explore the reasoning capability boundary of the models across a wide range of model families and benchmarks. Surprisingly, the RL does \\emph{not}, in fact, elicit fundamentally new reasoning patterns. While RL-trained models outperform their base models at smaller values of $k$ (\\eg, $k$=1), base models can achieve a comparable or even higher pass@$k$ score compared to their RL counterparts at large $k$ values. The reasoning paths generated by RL-trained models are already included in the base models' sampling distribution, suggesting that most reasoning abilities manifested in RL-trained models are already obtained by base models. Further analysis shows that RL training boosts the performance by biasing the model's output distribution toward paths that are more likely to yield rewards, therefore sampling correct responses more efficiently. But this also results in a narrower reasoning capability boundary compared to base models. Similar results are observed in visual reasoning tasks trained with RLVR. Moreover, we find that distillation can genuinely introduce new knowledge into the model, different from RLVR. These findings underscore a critical limitation of RLVR in advancing LLM reasoning abilities which requires us to fundamentally rethink the impact of RL training in reasoning LLMs and the need of a better paradigm. Project Page: this https URL", 'abstract_zh': 'Verifiable奖励强化学习（RLVR）在提升LLM推理能力方面的研究：局限性和新视角', 'title_zh': '强化学习真的能够激励大型语言模型提升推理能力超出基础模型的水平吗？'}
{'arxiv_id': 'arXiv:2504.13707', 'title': 'OpenDeception: Benchmarking and Investigating AI Deceptive Behaviors via Open-ended Interaction Simulation', 'authors': 'Yichen Wu, Xudong Pan, Geng Hong, Min Yang', 'link': 'https://arxiv.org/abs/2504.13707', 'abstract': 'As the general capabilities of large language models (LLMs) improve and agent applications become more widespread, the underlying deception risks urgently require systematic evaluation and effective oversight. Unlike existing evaluation which uses simulated games or presents limited choices, we introduce OpenDeception, a novel deception evaluation framework with an open-ended scenario dataset. OpenDeception jointly evaluates both the deception intention and capabilities of LLM-based agents by inspecting their internal reasoning process. Specifically, we construct five types of common use cases where LLMs intensively interact with the user, each consisting of ten diverse, concrete scenarios from the real world. To avoid ethical concerns and costs of high-risk deceptive interactions with human testers, we propose to simulate the multi-turn dialogue via agent simulation. Extensive evaluation of eleven mainstream LLMs on OpenDeception highlights the urgent need to address deception risks and security concerns in LLM-based agents: the deception intention ratio across the models exceeds 80%, while the deception success rate surpasses 50%. Furthermore, we observe that LLMs with stronger capabilities do exhibit a higher risk of deception, which calls for more alignment efforts on inhibiting deceptive behaviors.', 'abstract_zh': '大型语言模型（LLMs）的一般能力提高和代理应用的普及使得潜在的欺骗风险迫切需要系统评估和有效监管：OpenDeception——一种开放场景的新型欺骗评价框架', 'title_zh': 'OpenDeception: 基于开放交互模拟的AI欺骗行为基准测试与探究'}
{'arxiv_id': 'arXiv:2504.13644', 'title': 'Exploring the Potential for Large Language Models to Demonstrate Rational Probabilistic Beliefs', 'authors': 'Gabriel Freedman, Francesca Toni', 'link': 'https://arxiv.org/abs/2504.13644', 'abstract': "Advances in the general capabilities of large language models (LLMs) have led to their use for information retrieval, and as components in automated decision systems. A faithful representation of probabilistic reasoning in these models may be essential to ensure trustworthy, explainable and effective performance in these tasks. Despite previous work suggesting that LLMs can perform complex reasoning and well-calibrated uncertainty quantification, we find that current versions of this class of model lack the ability to provide rational and coherent representations of probabilistic beliefs. To demonstrate this, we introduce a novel dataset of claims with indeterminate truth values and apply a number of well-established techniques for uncertainty quantification to measure the ability of LLM's to adhere to fundamental properties of probabilistic reasoning.", 'abstract_zh': '大型语言模型（LLMs）的一般能力进步使其适用于信息检索，并作为自动决策系统中的组件。在这些模型中忠实表现概率推理可能是确保这些任务中可信、可解释和有效的性能的关键。尽管先前的工作表明LLMs可以进行复杂的推理和准确的不确定度量化，我们发现当前这一类模型版本缺乏提供合理连贯的概率信念表示的能力。为了证明这一点，我们引入了一个具有不确定真值的新型数据集，并应用了多种已建立的不确定度量化技术来衡量LLMs遵守概率推理基本性质的能力。', 'title_zh': '探索大型语言模型展示理性概率信念的潜力'}
{'arxiv_id': 'arXiv:2504.13631', 'title': 'Multi-modal Knowledge Graph Generation with Semantics-enriched Prompts', 'authors': 'Yajing Xu, Zhiqiang Liu, Jiaoyan Chen, Mingchen Tu, Zhuo Chen, Jeff Z. Pan, Yichi Zhang, Yushan Zhu, Wen Zhang, Huajun Chen', 'link': 'https://arxiv.org/abs/2504.13631', 'abstract': 'Multi-modal Knowledge Graphs (MMKGs) have been widely applied across various domains for knowledge representation. However, the existing MMKGs are significantly fewer than required, and their construction faces numerous challenges, particularly in ensuring the selection of high-quality, contextually relevant images for knowledge graph enrichment. To address these challenges, we present a framework for constructing MMKGs from conventional KGs. Furthermore, to generate higher-quality images that are more relevant to the context in the given knowledge graph, we designed a neighbor selection method called Visualizable Structural Neighbor Selection (VSNS). This method consists of two modules: Visualizable Neighbor Selection (VNS) and Structural Neighbor Selection (SNS). The VNS module filters relations that are difficult to visualize, while the SNS module selects neighbors that most effectively capture the structural characteristics of the entity. To evaluate the quality of the generated images, we performed qualitative and quantitative evaluations on two datasets, MKG-Y and DB15K. The experimental results indicate that using the VSNS method to select neighbors results in higher-quality images that are more relevant to the knowledge graph.', 'abstract_zh': '多模态知识图谱（MMKGs）已在各个领域广泛应用于知识表示。然而，现有的MMKGs数量远不足需求，其构建面临诸多挑战，尤其是在确保选择高质量、上下文相关图像以丰富知识图谱方面。为应对这些挑战，我们提出了一种从传统知识图谱构建多模态知识图谱的框架。此外，为生成与给定知识图谱上下文更相关的高质量图像，我们设计了一种称为可可视化结构邻居选择（VSNS）的方法。该方法包括两个模块：可可视化邻居选择（VNS）和结构邻居选择（SNS）。VNS模块过滤难以可视化的关系，而SNS模块选择最能捕捉实体结构特征的邻居。为了评估生成图像的质量，我们在两个数据集MKG-Y和DB15K上进行了定性和定量评价。实验结果表明，使用VSNS方法选择邻居能够生成与知识图谱更相关的高质量图像。', 'title_zh': '带有语义丰富提示的多模态知识图谱生成'}
{'arxiv_id': 'arXiv:2504.13554', 'title': 'Task Assignment and Exploration Optimization for Low Altitude UAV Rescue via Generative AI Enhanced Multi-agent Reinforcement Learning', 'authors': 'Xin Tang, Qian Chen, Wenjie Weng, Chao Jin, Zhang Liu, Jiacheng Wang, Geng Sun, Xiaohuan Li, Dusit Niyato', 'link': 'https://arxiv.org/abs/2504.13554', 'abstract': "Artificial Intelligence (AI)-driven convolutional neural networks enhance rescue, inspection, and surveillance tasks performed by low-altitude uncrewed aerial vehicles (UAVs) and ground computing nodes (GCNs) in unknown environments. However, their high computational demands often exceed a single UAV's capacity, leading to system instability, further exacerbated by the limited and dynamic resources of GCNs. To address these challenges, this paper proposes a novel cooperation framework involving UAVs, ground-embedded robots (GERs), and high-altitude platforms (HAPs), which enable resource pooling through UAV-to-GER (U2G) and UAV-to-HAP (U2H) communications to provide computing services for UAV offloaded tasks. Specifically, we formulate the multi-objective optimization problem of task assignment and exploration optimization in UAVs as a dynamic long-term optimization problem. Our objective is to minimize task completion time and energy consumption while ensuring system stability over time. To achieve this, we first employ the Lyapunov optimization technique to transform the original problem, with stability constraints, into a per-slot deterministic problem. We then propose an algorithm named HG-MADDPG, which combines the Hungarian algorithm with a generative diffusion model (GDM)-based multi-agent deep deterministic policy gradient (MADDPG) approach. We first introduce the Hungarian algorithm as a method for exploration area selection, enhancing UAV efficiency in interacting with the environment. We then innovatively integrate the GDM and multi-agent deep deterministic policy gradient (MADDPG) to optimize task assignment decisions, such as task offloading and resource allocation. Simulation results demonstrate the effectiveness of the proposed approach, with significant improvements in task offloading efficiency, latency reduction, and system stability compared to baseline methods.", 'abstract_zh': '基于人工智能驱动的卷积神经网络增强低空无人机和地面计算节点在未知环境中的救援、检查和 surveillance任务，但其高计算需求 often 超过单个无人机的能力，导致系统不稳定，进一步加剧了地面计算节点资源的限制和动态性。为应对这些挑战，本文提出了一种涉及无人机、地面嵌入式机器人和高空平台的新型合作框架，通过无人机到地面嵌入式机器人（U2G）和无人机到高空平台（U2H）通信实现资源池化，为卸载任务提供计算服务。具体而言，我们将无人机的任务分配和探索优化问题表述为一个动态的长期优化问题。我们的目标是在确保系统长期稳定的同时，最小化任务完成时间和能耗。为了实现这一目标，我们首先采用李雅普诺夫优化技术将原始问题（带有稳定性约束的问题）转化为每时间段的确定性问题。然后，我们提出了一种结合匈牙利算法和基于生成扩散模型（GDM）的多智能体深确定性策略梯度（MADDPG）方法的算法（HG-MADDPG）。我们首先引入匈牙利算法作为探索区域选择的方法，增强无人机与环境交互的效率。然后，我们创新地将生成扩散模型（GDM）和多智能体深确定性策略梯度（MADDPG）结合，优化任务分配决策，如任务卸载和资源分配。仿真结果表明，所提出的方法在任务卸载效率、延迟减少和系统稳定性方面显著优于基线方法。', 'title_zh': '基于生成式AI增强多智能体强化学习的低空无人机救援任务分配与探索优化'}
{'arxiv_id': 'arXiv:2504.13517', 'title': 'Optimizing Electric Vehicle Charging Station Locations: A Data-driven System with Multi-source Fusion', 'authors': 'Lihuan Li, Du Yin, Hao Xue, David Lillo-Trynes, Flora Salim', 'link': 'https://arxiv.org/abs/2504.13517', 'abstract': 'With the growing electric vehicles (EVs) charging demand, urban planners face the challenges of providing charging infrastructure at optimal locations. For example, range anxiety during long-distance travel and the inadequate distribution of residential charging stations are the major issues many cities face. To achieve reasonable estimation and deployment of the charging demand, we develop a data-driven system based on existing EV trips in New South Wales (NSW) state, Australia, incorporating multiple factors that enhance the geographical feasibility of recommended charging stations. Our system integrates data sources including EV trip data, geographical data such as route data and Local Government Area (LGA) boundaries, as well as features like fire and flood risks, and Points of Interest (POIs). We visualize our results to intuitively demonstrate the findings from our data-driven, multi-source fusion system, and evaluate them through case studies. The outcome of this work can provide a platform for discussion to develop new insights that could be used to give guidance on where to position future EV charging stations.', 'abstract_zh': '随着电动汽车充电需求的增长，城市规划者面临在最优位置提供充电基础设施的挑战。例如，在长距离旅行中出现的里程焦虑和住宅充电站分布不足是许多城市面临的主要问题。为了实现充电需求的合理估计和部署，我们基于澳大利亚新南威尔士州（NSW）现有的电动汽车行程数据，开发了一个数据驱动系统，结合了多个可以增强推荐充电站地理位置可行性的因素。该系统整合了电动汽车行程数据、地理数据如路线数据和地方政府区域（LGA）边界，以及火灾风险、洪水风险和兴趣点（POI）等特征。我们通过可视化结果直观地展示了多源数据融合系统的发现，并通过案例研究进行评估。本研究的成果可以提供一个讨论平台，以发展新的见解并为未来电动汽车充电站的位置提供建议。', 'title_zh': '基于多源融合的电动汽车充电站优化布局：一种数据驱动系统'}
{'arxiv_id': 'arXiv:2504.13443', 'title': 'Trust, but verify', 'authors': 'Michael J. Yuan, Carlos Campoy, Sydney Lai, James Snewin, Ju Long', 'link': 'https://arxiv.org/abs/2504.13443', 'abstract': 'Decentralized AI agent networks, such as Gaia, allows individuals to run customized LLMs on their own computers and then provide services to the public. However, in order to maintain service quality, the network must verify that individual nodes are running their designated LLMs. In this paper, we demonstrate that in a cluster of mostly honest nodes, we can detect nodes that run unauthorized or incorrect LLM through social consensus of its peers. We will discuss the algorithm and experimental data from the Gaia network. We will also discuss the intersubjective validation system, implemented as an EigenLayer AVS to introduce financial incentives and penalties to encourage honest behavior from LLM nodes.', 'abstract_zh': '去中心化AI代理网络Gaia允許個體在其自己的計算機上運行自定义的大 LENGSTMODEL，然後為公眾提供服務。然而，為了維護服務質量，該網絡必須驗證個別節點是否運行分配給它的 LENGSTMODEL。在本文中，我們展示在 hầu hết诚实的節點集群中，我們可以通過同伴的社會共識來檢測運行未授權或錯誤 LENGSTMODEL 的節點。我們將討論該算法並呈現Gaia網絡的實驗數據。我們還將討論實現的主觀驗證系統EigenLayer AVS，該系統通過引入財政激勵和懲罰來促進LENWGHTMODEL節點的誠實行為。', 'title_zh': '信任，但要验证。'}
{'arxiv_id': 'arXiv:2504.13360', 'title': 'In between myth and reality: AI for math -- a case study in category theory', 'authors': 'Răzvan Diaconescu', 'link': 'https://arxiv.org/abs/2504.13360', 'abstract': 'Recently, there is an increasing interest in understanding the performance of AI systems in solving math problems. A multitude of tests have been performed, with mixed conclusions. In this paper we discuss an experiment we have made in the direction of mathematical research, with two of the most prominent contemporary AI systems. One of the objective of this experiment is to get an understanding of how AI systems can assist mathematical research. Another objective is to support the AI systems developers by formulating suggestions for directions of improvement.', 'abstract_zh': '近年来，人们对理解AI系统解决数学问题的表现越来越感兴趣。已经进行了多种测试，结论各异。本文讨论了我们对两个最突出的当代AI系统进行的一项数学研究实验。实验的一个目的是了解AI系统如何辅助数学研究。另一个目的是通过提出改进方向的建议来支持AI系统开发者。', 'title_zh': '在神话与现实之间：AI在数学中的应用——范畴理论案例研究'}
{'arxiv_id': 'arXiv:2504.13359', 'title': 'Cost-of-Pass: An Economic Framework for Evaluating Language Models', 'authors': 'Mehmet Hamza Erol, Batu El, Mirac Suzgun, Mert Yuksekgonul, James Zou', 'link': 'https://arxiv.org/abs/2504.13359', 'abstract': 'The widespread adoption of AI systems in the economy hinges on their ability to generate economic value that outweighs their inference costs. Evaluating this tradeoff requires metrics that account for both performance and costs. We propose a framework grounded in production theory for evaluating language models by combining accuracy and inference cost. We introduce "cost-of-pass", the expected monetary cost of generating a correct solution. We then define the "frontier cost-of-pass" as the minimum cost-of-pass achievable across available models or the "human-expert, using the approximate cost of hiring an expert. Our analysis reveals distinct economic insights. First, lightweight models are most cost-effective for basic quantitative tasks, large models for knowledge-intensive ones, and reasoning models for complex quantitative problems, despite higher per-token costs. Second, tracking this frontier cost-of-pass over the past year reveals significant progress, particularly for complex quantitative tasks where the cost has roughly halved every few months. Third, to trace key innovations driving this progress, we examine counterfactual frontiers: estimates of cost-efficiency without specific model classes. We find that innovations in lightweight, large, and reasoning models have been essential for pushing the frontier in basic quantitative, knowledge-intensive, and complex quantitative tasks, respectively. Finally, we assess the cost-reductions afforded by common inference-time techniques like majority voting and self-refinement, finding that their marginal accuracy gains rarely justify their costs. Our findings underscore that complementary model-level innovations are the primary drivers of cost-efficiency, and our economic framework provides a principled tool for measuring this progress and guiding deployment.', 'abstract_zh': 'AI系统在经济中的广泛采用取决于其生成的经济效益是否超过其推理成本。评估这一权衡需要同时考虑性能和成本的指标。我们提出了一种基于生产理论的框架，通过结合准确性和推理成本来评价语言模型。我们引入了“成本-通过”（cost-of-pass）的概念，即生成正确解决方案的预期货币成本。然后定义了“前沿成本-通过”（frontier cost-of-pass），这是在可用模型中达到的最小成本-通过，或者使用专家的大致成本来衡量“人类专家”。我们的分析揭示了不同的经济洞见。首先，轻量级模型对于基本定量任务最具成本效益，大型模型对于知识密集型任务最具成本效益，而推理模型对于复杂的定量问题最具成本效益，尽管每单位成本较高。其次，过去一年中跟踪这一前沿成本-通过显示了显著的进步，特别是在复杂的定量任务中，成本每几个月大致减半。第三，为了追踪推动这一进展的关键创新，我们检查了反事实前沿：在没有特定模型类别的情况下对成本效率的估计。我们发现，在基本定量、知识密集型和复杂定量任务中，轻量级、大型和推理模型的创新都至关重要。最后，我们评估了诸如多数投票和自我校正等常见推理时技术的成本降低，发现它们的边际准确率提升 rarely 通常不值得其成本。我们的研究强调互补的模型级创新是降低成本效率的主要驱动力，而我们的经济框架提供了一种原则性的工具来衡量这一进展并指导部署。', 'title_zh': '成本传递：一种评估语言模型的经济学框架'}
{'arxiv_id': 'arXiv:2504.13314', 'title': 'On the Definition of Robustness and Resilience of AI Agents for Real-time Congestion Management', 'authors': 'Timothy Tjhay, Ricardo J. Bessa, Jose Paulos', 'link': 'https://arxiv.org/abs/2504.13314', 'abstract': "The European Union's Artificial Intelligence (AI) Act defines robustness, resilience, and security requirements for high-risk sectors but lacks detailed methodologies for assessment. This paper introduces a novel framework for quantitatively evaluating the robustness and resilience of reinforcement learning agents in congestion management. Using the AI-friendly digital environment Grid2Op, perturbation agents simulate natural and adversarial disruptions by perturbing the input of AI systems without altering the actual state of the environment, enabling the assessment of AI performance under various scenarios. Robustness is measured through stability and reward impact metrics, while resilience quantifies recovery from performance degradation. The results demonstrate the framework's effectiveness in identifying vulnerabilities and improving AI robustness and resilience for critical applications.", 'abstract_zh': '欧洲联盟的人工智能（AI）法案为高风险领域定义了稳健性、韧性和安全性要求，但缺乏详细的评估方法。本文提出了一种新型框架，用于定量评估强化学习代理在拥堵管理中的稳健性和韧性。利用AI友好的数字环境Grid2Op，扰动代理通过扰动输入而不改变实际环境状态来模拟自然和敌对的干扰，从而在不同场景下评估AI性能。稳健性通过稳定性和奖励影响指标来衡量，而韧性则量化了性能退化的恢复能力。结果表明，该框架在识别漏洞并提高关键应用中AI的稳健性和韧性方面具有有效性。', 'title_zh': '关于AI代理在实时拥堵管理中鲁棒性和韧性定义的研究'}
{'arxiv_id': 'arXiv:2504.13263', 'title': 'Causal-Copilot: An Autonomous Causal Analysis Agent', 'authors': 'Xinyue Wang, Kun Zhou, Wenyi Wu, Har Simrat Singh, Fang Nan, Songyao Jin, Aryan Philip, Saloni Patnaik, Hou Zhu, Shivam Singh, Parjanya Prashant, Qian Shen, Biwei Huang', 'link': 'https://arxiv.org/abs/2504.13263', 'abstract': 'Causal analysis plays a foundational role in scientific discovery and reliable decision-making, yet it remains largely inaccessible to domain experts due to its conceptual and algorithmic complexity. This disconnect between causal methodology and practical usability presents a dual challenge: domain experts are unable to leverage recent advances in causal learning, while causal researchers lack broad, real-world deployment to test and refine their methods. To address this, we introduce Causal-Copilot, an autonomous agent that operationalizes expert-level causal analysis within a large language model framework. Causal-Copilot automates the full pipeline of causal analysis for both tabular and time-series data -- including causal discovery, causal inference, algorithm selection, hyperparameter optimization, result interpretation, and generation of actionable insights. It supports interactive refinement through natural language, lowering the barrier for non-specialists while preserving methodological rigor. By integrating over 20 state-of-the-art causal analysis techniques, our system fosters a virtuous cycle -- expanding access to advanced causal methods for domain experts while generating rich, real-world applications that inform and advance causal theory. Empirical evaluations demonstrate that Causal-Copilot achieves superior performance compared to existing baselines, offering a reliable, scalable, and extensible solution that bridges the gap between theoretical sophistication and real-world applicability in causal analysis.', 'abstract_zh': '因果分析在科学研究和可靠决策中发挥着基础性作用，但由于其概念和算法的复杂性，仍难以为领域专家所利用。因果方法论与实际应用之间的这种脱节构成了双重挑战：领域专家无法利用因果学习的最新进展，而因果研究人员缺乏广泛的实际部署来测试和改进他们的方法。为解决这一问题，我们引入了Causal-Copilot，这是一种自主代理，它在大型语言模型框架内实现专家级的因果分析。Causal-Copilot实现了因果分析的完整管道，包括因果发现、因果推断、算法选择、超参数优化、结果解释以及生成可操作的见解。它通过自然语言支持交互式细化，降低非专业人士的门槛，同时保持方法论的严谨性。通过整合超过20种最先进的因果分析技术，我们的系统促进了良性循环——为领域专家扩展高级因果方法的访问权限，产生丰富的实际应用，从而指导和推进因果理论的发展。实证评估表明，Causal-Copilot在性能上优于现有基线，提供了一个可靠、可扩展且可扩展的解决方案，能够弥合因果分析中理论 sophistication 与实际应用性的差距。', 'title_zh': '因果协驾驶：一个自主因果分析代理'}
{'arxiv_id': 'arXiv:2504.13210', 'title': 'Graphical Models for Decision-Making: Integrating Causality and Game Theory', 'authors': 'Maarten C. Vonk, Mauricio Gonzalez Soto, Anna V. Kononova', 'link': 'https://arxiv.org/abs/2504.13210', 'abstract': 'Causality and game theory are two influential fields that contribute significantly to decision-making in various domains. Causality defines and models causal relationships in complex policy problems, while game theory provides insights into strategic interactions among stakeholders with competing interests. Integrating these frameworks has led to significant theoretical advancements with the potential to improve decision-making processes. However, practical applications of these developments remain underexplored. To support efforts toward implementation, this paper clarifies key concepts in game theory and causality that are essential to their intersection, particularly within the context of probabilistic graphical models. By rigorously examining these concepts and illustrating them with intuitive, consistent examples, we clarify the required inputs for implementing these models, provide practitioners with insights into their application and selection across different scenarios, and reference existing research that supports their implementation. We hope this work encourages broader adoption of these models in real-world scenarios.', 'abstract_zh': '因果关系和博弈论是两个对各个领域决策制定有重大贡献的重要领域。因果关系定义和模型化复杂的政策问题中的因果关系，而博弈论提供了有关竞争利益相关者之间战略互动的见解。将这些框架结合起来，推动了重要的理论进步，有望改善决策过程。然而，这些进展的实际应用仍鲜有探索。为支持这些努力的实施，本文澄清了因果关系和博弈论在交义点上至关重要的关键概念，特别是在概率图形模型的背景下。通过对这些概念进行严谨的分析，并用直观一致的例子进行说明，本文阐明了实施这些模型所需的输入，为实践者提供了在不同情境下应用和选择这些模型的见解，并引用了支持其实施的现有研究。我们希望这项工作能促进这些模型在实际场景中的更广泛采用。', 'title_zh': '图形模型在决策中的应用：集成因果关系与博弈论'}
{'arxiv_id': 'arXiv:2504.13202', 'title': 'The Quantum LLM: Modeling Semantic Spaces with Quantum Principles', 'authors': 'Timo Aukusti Laine', 'link': 'https://arxiv.org/abs/2504.13202', 'abstract': 'In the previous article, we presented a quantum-inspired framework for modeling semantic representation and processing in Large Language Models (LLMs), drawing upon mathematical tools and conceptual analogies from quantum mechanics to offer a new perspective on these complex systems. In this paper, we clarify the core assumptions of this model, providing a detailed exposition of six key principles that govern semantic representation, interaction, and dynamics within LLMs. The goal is to justify that a quantum-inspired framework is a valid approach to studying semantic spaces. This framework offers valuable insights into their information processing and response generation, and we further discuss the potential of leveraging quantum computing to develop significantly more powerful and efficient LLMs based on these principles.', 'abstract_zh': '前一篇文章中，我们提出了一种受量子力学启发的框架，用于建模大型语言模型（LLMs）中的语义表示和处理，借用了量子力学中的数学工具和概念类比，为这些复杂系统提供了新的视角。本文旨在阐明这一模型的核心假设，详细阐述了六个关键原则，这些原则规范了LLMs中的语义表示、交互和动态。我们的目标是证明，量子启发框架是一种有效研究语义空间的方法。该框架提供了关于其信息处理和响应生成的重要见解，并进一步讨论了这些原则在利用量子计算开发更强大、更高效的LLMs方面的潜力。', 'title_zh': '量子大规模语言模型：基于量子原理建模语义空间'}
{'arxiv_id': 'arXiv:2504.13835', 'title': 'MIG: Automatic Data Selection for Instruction Tuning by Maximizing Information Gain in Semantic Space', 'authors': 'Yicheng Chen, Yining Li, Kai Hu, Zerun Ma, Haochen Ye, Kai Chen', 'link': 'https://arxiv.org/abs/2504.13835', 'abstract': 'Data quality and diversity are key to the construction of effective instruction-tuning datasets. %\nWith the increasing availability of open-source instruction-tuning datasets, it is advantageous to automatically select high-quality and diverse subsets from a vast amount of data. %\nExisting methods typically prioritize instance quality and use heuristic rules to maintain diversity. %\nHowever, this absence of a comprehensive view of the entire collection often leads to suboptimal results. %\nMoreover, heuristic rules generally focus on distance or clustering within the embedding space, which fails to accurately capture the intent of complex instructions in the semantic space. %\nTo bridge this gap, we propose a unified method for quantifying the information content of datasets. This method models the semantic space by constructing a label graph and quantifies diversity based on the distribution of information within the graph. %\nBased on such a measurement, we further introduce an efficient sampling method that selects data samples iteratively to \\textbf{M}aximize the \\textbf{I}nformation \\textbf{G}ain (MIG) in semantic space. %\nExperiments on various datasets and base models demonstrate that MIG consistently outperforms state-of-the-art methods. %\nNotably, the model fine-tuned with 5\\% Tulu3 data sampled by MIG achieves comparable performance to the official SFT model trained on the full dataset, with improvements of +5.73\\% on AlpacaEval and +6.89\\% on Wildbench.', 'abstract_zh': '数据的质量和多样性是构建有效指令调优数据集的关键。%\n随着开源指令调优数据集的不断增加，从大量数据中自动选择高质量和多样性的子集变得有利。%\n现有方法通常优先考虑实例质量，并使用启发式规则来维持多样性。%\n然而，这往往会忽视整个集合的全面视角，导致结果次优。%\n此外，启发式规则通常关注嵌入空间中的距离或聚类，未能准确捕捉语义空间中复杂指令的意图。%\n为了解决这一问题，我们提出了一种统一的方法来量化数据集中的信息内容。该方法通过构建标签图来建模语义空间，并基于图中信息的分布来量化多样性。%\n基于这种测量，我们进一步引入了一种高效的采样方法，该方法通过迭代选择数据样本以最大化语义空间中的信息增益（MIG）。%\n在各种数据集和基础模型上的实验表明，MIG 一致性地优于现有方法。%\n值得注意的是，使用 MIG 采样的 5% Tulu3 数据微调的模型在 AlpacaEval 上获得了 +5.73% 的提升，在 Wildbench 上获得了 +6.89% 的提升，性能与在完整数据集上训练的官方 SFT 模型相当。', 'title_zh': 'MIG：通过最大化语义空间信息增益实现自动数据选择的指令调优方法'}
{'arxiv_id': 'arXiv:2504.13828', 'title': 'Generative AI Act II: Test Time Scaling Drives Cognition Engineering', 'authors': 'Shijie Xia, Yiwei Qin, Xuefeng Li, Yan Ma, Run-Ze Fan, Steffi Chern, Haoyang Zou, Fan Zhou, Xiangkun Hu, Jiahe Jin, Yanheng He, Yixin Ye, Yixiu Liu, Pengfei Liu', 'link': 'https://arxiv.org/abs/2504.13828', 'abstract': 'The first generation of Large Language Models - what might be called "Act I" of generative AI (2020-2023) - achieved remarkable success through massive parameter and data scaling, yet exhibited fundamental limitations in knowledge latency, shallow reasoning, and constrained cognitive processes. During this era, prompt engineering emerged as our primary interface with AI, enabling dialogue-level communication through natural language. We now witness the emergence of "Act II" (2024-present), where models are transitioning from knowledge-retrieval systems (in latent space) to thought-construction engines through test-time scaling techniques. This new paradigm establishes a mind-level connection with AI through language-based thoughts. In this paper, we clarify the conceptual foundations of cognition engineering and explain why this moment is critical for its development. We systematically break down these advanced approaches through comprehensive tutorials and optimized implementations, democratizing access to cognition engineering and enabling every practitioner to participate in AI\'s second act. We provide a regularly updated collection of papers on test-time scaling in the GitHub Repository: this https URL', 'abstract_zh': '第一代大型语言模型——生成式AI的“第一幕”（2020-2023）——通过大量的参数和数据缩放实现了显著的成功，但表现出根本的知识延迟、浅层推理和受限的认知过程。在这个时代，提示工程成为我们与AI的主要接口，通过自然语言实现对话级的交流。我们现在见证了“第二幕”的开始（2024-present），模型正在从潜在空间的知识检索系统过渡为通过测试时缩放技术构建思想的引擎，这一新的范式通过基于语言的思想与AI建立心智级的连接。在本文中，我们阐明了认知工程的理论基础，并解释了为什么此时此刻对于其发展至关重要。我们系统地通过全面的教程和优化的实现来分解这些高级方法，使认知工程的访问权更加普及，使每一位实践者都能参与到AI的第二幕中。我们提供了一个定期更新的测试时缩放论文集合在GitHub Repository中：这个 https URL。', 'title_zh': '生成式AI第二季：测试时缩放驱动认知工程'}
{'arxiv_id': 'arXiv:2504.13822', 'title': 'Parameter-Efficient Continual Fine-Tuning: A Survey', 'authors': 'Eric Nuertey Coleman, Luigi Quarantiello, Ziyue Liu, Qinwen Yang, Samrat Mukherjee, Julio Hurtado, Vincenzo Lomonaco', 'link': 'https://arxiv.org/abs/2504.13822', 'abstract': 'The emergence of large pre-trained networks has revolutionized the AI field, unlocking new possibilities and achieving unprecedented performance. However, these models inherit a fundamental limitation from traditional Machine Learning approaches: their strong dependence on the \\textit{i.i.d.} assumption hinders their adaptability to dynamic learning scenarios. We believe the next breakthrough in AI lies in enabling efficient adaptation to evolving environments -- such as the real world -- where new data and tasks arrive sequentially. This challenge defines the field of Continual Learning (CL), a Machine Learning paradigm focused on developing lifelong learning neural models. One alternative to efficiently adapt these large-scale models is known Parameter-Efficient Fine-Tuning (PEFT). These methods tackle the issue of adapting the model to a particular data or scenario by performing small and efficient modifications, achieving similar performance to full fine-tuning. However, these techniques still lack the ability to adjust the model to multiple tasks continually, as they suffer from the issue of Catastrophic Forgetting. In this survey, we first provide an overview of CL algorithms and PEFT methods before reviewing the state-of-the-art on Parameter-Efficient Continual Fine-Tuning (PECFT). We examine various approaches, discuss evaluation metrics, and explore potential future research directions. Our goal is to highlight the synergy between CL and Parameter-Efficient Fine-Tuning, guide researchers in this field, and pave the way for novel future research directions.', 'abstract_zh': '大规模预训练网络的出现已革新了人工智能领域，开启了新可能性并实现了前所未有的性能。然而，这些模型继承了传统机器学习方法的基本局限性：对独立同分布假设的强烈依赖阻碍了其在动态学习场景中的适应性。我们认为人工智能下一突破点在于使大规模模型能够高效适应不断变化的环境——例如现实世界——其中新数据和任务会相继到来。这一挑战定义了连续学习（Continual Learning, CL）领域，这是一个专注于开发终身学习神经模型的机器学习范式。一种使这些大规模模型高效适应的方法被称为参数高效微调（Parameter-Efficient Fine-Tuning, PEFT）。这些方法通过进行少量且高效的修改来解决使模型适应特定数据或场景的问题，从而达到与全面微调相似的性能。然而，这些技术仍然缺乏持续适应多个任务的能力，因为它们受到了灾难性遗忘（Catastrophic Forgetting）问题的影响。在本文综述中，我们首先概述了CL算法和PEFT方法，然后回顾了参数高效连续微调（Parameter-Efficient Continual Fine-Tuning, PECFT）的最新进展。我们探讨了各种方法、讨论了评估指标，并探索了未来研究方向。我们的目标是强调CL和参数高效微调之间的协同作用，指导该领域的研究者，并为未来的研究开辟新的方向。', 'title_zh': '参数高效连续微调：一个综述'}
{'arxiv_id': 'arXiv:2504.13818', 'title': 'Not All Rollouts are Useful: Down-Sampling Rollouts in LLM Reinforcement Learning', 'authors': 'Yixuan Even Xu, Yash Savani, Fei Fang, Zico Kolter', 'link': 'https://arxiv.org/abs/2504.13818', 'abstract': 'Reinforcement learning (RL) has emerged as a powerful paradigm for enhancing reasoning capabilities in large language models, but faces a fundamental asymmetry in computation and memory requirements: inference is embarrassingly parallel with a minimal memory footprint, while policy updates require extensive synchronization and are memory-intensive. To address this asymmetry, we introduce PODS (Policy Optimization with Down-Sampling), a framework that strategically decouples these phases by generating numerous rollouts in parallel but updating only on an informative subset. Within this framework, we develop max-variance down-sampling, a theoretically motivated method that selects rollouts with maximally diverse reward signals. We prove that this approach has an efficient algorithmic solution, and empirically demonstrate that GRPO with PODS using max-variance down-sampling achieves superior performance over standard GRPO on the GSM8K benchmark.', 'abstract_zh': '基于降采样的策略优化（PODS）框架：解决强化学习在大规模语言模型中推理与政策更新之间的计算和内存要求不对称性', 'title_zh': '并非所有rollout都有用：LLM强化学习中的rollout下采样'}
{'arxiv_id': 'arXiv:2504.13804', 'title': 'Near-optimal algorithms for private estimation and sequential testing of collision probability', 'authors': 'Robert Busa-Fekete, Umar Syed', 'link': 'https://arxiv.org/abs/2504.13804', 'abstract': 'We present new algorithms for estimating and testing \\emph{collision probability}, a fundamental measure of the spread of a discrete distribution that is widely used in many scientific fields. We describe an algorithm that satisfies $(\\alpha, \\beta)$-local differential privacy and estimates collision probability with error at most $\\epsilon$ using $\\tilde{O}\\left(\\frac{\\log(1/\\beta)}{\\alpha^2 \\epsilon^2}\\right)$ samples for $\\alpha \\le 1$, which improves over previous work by a factor of $\\frac{1}{\\alpha^2}$. We also present a sequential testing algorithm for collision probability, which can distinguish between collision probability values that are separated by $\\epsilon$ using $\\tilde{O}(\\frac{1}{\\epsilon^2})$ samples, even when $\\epsilon$ is unknown. Our algorithms have nearly the optimal sample complexity, and in experiments we show that they require significantly fewer samples than previous methods.', 'abstract_zh': '我们介绍了估计和测试碰撞概率的新算法，碰撞概率是广泛应用于多个科学领域的离散分布扩散度的基本度量。我们描述了一个满足$(\\alpha, \\beta)$-局部差分隐私的算法，并使用$\\tilde{O}\\left(\\frac{\\log(1/\\beta)}{\\alpha^2 \\epsilon^2}\\right)$样本估计碰撞概率，误差不超过$\\epsilon$，这比 previous work 改进了$\\frac{1}{\\alpha^2}$的数量级。我们还提出了一种序列化测试碰撞概率的算法，在$\\epsilon$未知的情况下，该算法可以使用$\\tilde{O}(\\frac{1}{\\epsilon^2})$样本区分开距为$\\epsilon$的碰撞概率值。我们的算法具有近似最优的样本复杂度，在实验中我们展示了它们所需样本数量明显少于先前方法。', 'title_zh': '近最优的私密估计和碰撞概率的 sequential 测试算法'}
{'arxiv_id': 'arXiv:2504.13803', 'title': 'Imitation Learning with Precisely Labeled Human Demonstrations', 'authors': 'Yilong Song', 'link': 'https://arxiv.org/abs/2504.13803', 'abstract': "Within the imitation learning paradigm, training generalist robots requires large-scale datasets obtainable only through diverse curation. Due to the relative ease to collect, human demonstrations constitute a valuable addition when incorporated appropriately. However, existing methods utilizing human demonstrations face challenges in inferring precise actions, ameliorating embodiment gaps, and fusing with frontier generalist robot training pipelines. In this work, building on prior studies that demonstrate the viability of using hand-held grippers for efficient data collection, we leverage the user's control over the gripper's appearance--specifically by assigning it a unique, easily segmentable color--to enable simple and reliable application of the RANSAC and ICP registration method for precise end-effector pose estimation. We show in simulation that precisely labeled human demonstrations on their own allow policies to reach on average 88.1% of the performance of using robot demonstrations, and boost policy performance when combined with robot demonstrations, despite the inherent embodiment gap.", 'abstract_zh': '基于模仿学习范式，通过多样化的收集获取大规模数据是训练通用机器人所必需的。适当整合人类演示对数据收集具有宝贵的补充价值。然而，现有利用人类演示的方法在精确行为推理、弥补实体差距以及与前沿通用机器人训练管道融合方面面临挑战。在此工作中，我们借鉴了先前研究中展示的有效使用手持式夹具进行高效数据收集的能力，通过赋予夹具独特的、易于分割的颜色，使用户能够控制夹具的外观，从而简化并提高了使用RANSAC和ICP配准方法进行精确末端执行器姿态估计的可靠性和简便性。仿真结果表明，单独使用精确标记的人类演示可以使策略达到使用机器人演示时性能的平均88.1%，并且与机器人演示结合使用时还能进一步提升策略性能，尽管存在固有的实体差距。', 'title_zh': '精准标注的人类示范的模仿学习'}
{'arxiv_id': 'arXiv:2504.13797', 'title': 'Meta-Learning and Knowledge Discovery based Physics-Informed Neural Network for Remaining Useful Life Prediction', 'authors': 'Yu Wang, Shujie Liu, Shuai Lv, Gengshuo Liu', 'link': 'https://arxiv.org/abs/2504.13797', 'abstract': 'Predicting the remaining useful life (RUL) of rotating machinery is critical for industrial safety and maintenance, but existing methods struggle with scarce target-domain data and unclear degradation dynamics. We propose a Meta-Learning and Knowledge Discovery-based Physics-Informed Neural Network (MKDPINN) to address these challenges. The method first maps noisy sensor data to a low-dimensional hidden state space via a Hidden State Mapper (HSM). A Physics-Guided Regulator (PGR) then learns unknown nonlinear PDEs governing degradation evolution, embedding these physical constraints into the PINN framework. This integrates data-driven and physics-based approaches. The framework uses meta-learning, optimizing across source-domain meta-tasks to enable few-shot adaptation to new target tasks. Experiments on industrial data and the C-MAPSS benchmark show MKDPINN outperforms baselines in generalization and accuracy, proving its effectiveness for RUL prediction under data scarcity', 'abstract_zh': '基于元学习和知识发现的物理知情神经网络（MKDPINN）：应对剩余使用寿命预测中的数据稀少和退化动态不清问题', 'title_zh': '基于元学习和知识发现的物理知情神经网络用于剩余使用寿命预测'}
{'arxiv_id': 'arXiv:2504.13791', 'title': 'Collective Learning Mechanism based Optimal Transport Generative Adversarial Network for Non-parallel Voice Conversion', 'authors': 'Sandipan Dhar, Md. Tousin Akhter, Nanda Dulal Jana, Swagatam Das', 'link': 'https://arxiv.org/abs/2504.13791', 'abstract': 'After demonstrating significant success in image synthesis, Generative Adversarial Network (GAN) models have likewise made significant progress in the field of speech synthesis, leveraging their capacity to adapt the precise distribution of target data through adversarial learning processes. Notably, in the realm of State-Of-The-Art (SOTA) GAN-based Voice Conversion (VC) models, there exists a substantial disparity in naturalness between real and GAN-generated speech samples. Furthermore, while many GAN models currently operate on a single generator discriminator learning approach, optimizing target data distribution is more effectively achievable through a single generator multi-discriminator learning scheme. Hence, this study introduces a novel GAN model named Collective Learning Mechanism-based Optimal Transport GAN (CLOT-GAN) model, incorporating multiple discriminators, including the Deep Convolutional Neural Network (DCNN) model, Vision Transformer (ViT), and conformer. The objective of integrating various discriminators lies in their ability to comprehend the formant distribution of mel-spectrograms, facilitated by a collective learning mechanism. Simultaneously, the inclusion of Optimal Transport (OT) loss aims to precisely bridge the gap between the source and target data distribution, employing the principles of OT theory. The experimental validation on VCC 2018, VCTK, and CMU-Arctic datasets confirms that the CLOT-GAN-VC model outperforms existing VC models in objective and subjective assessments.', 'abstract_zh': '基于集体学习机制的最优传输生成对抗网络在语音转换中的应用', 'title_zh': '基于集体学习机制的最优传输生成对抗网络非平行语音转换'}
{'arxiv_id': 'arXiv:2504.13787', 'title': 'Probabilistic Stability Guarantees for Feature Attributions', 'authors': 'Helen Jin, Anton Xue, Weiqiu You, Surbhi Goel, Eric Wong', 'link': 'https://arxiv.org/abs/2504.13787', 'abstract': 'Stability guarantees are an emerging tool for evaluating feature attributions, but existing certification methods rely on smoothed classifiers and often yield conservative guarantees. To address these limitations, we introduce soft stability and propose a simple, model-agnostic, and sample-efficient stability certification algorithm (SCA) that provides non-trivial and interpretable guarantees for any attribution. Moreover, we show that mild smoothing enables a graceful tradeoff between accuracy and stability, in contrast to prior certification methods that require a more aggressive compromise. Using Boolean function analysis, we give a novel characterization of stability under smoothing. We evaluate SCA on vision and language tasks, and demonstrate the effectiveness of soft stability in measuring the robustness of explanation methods.', 'abstract_zh': '稳定性保证是评估特征归因的一个新兴工具，但现有的验证方法依赖于平滑分类器，往往导致保守的保证。为了应对这些局限性，我们引入了软稳定性，并提出了一种简单、模型无关且样本高效的稳定性验证算法（SCA），该算法为任何归因提供了非平凡且可解释的保证。此外，我们证明了轻微平滑能在一个平稳性和准确性之间实现更优雅的权衡，与之前的验证方法相比，不需要更大的妥协。通过布尔函数分析，我们给出了稳定性在平滑下的一种新的表征。我们在视觉和语言任务上评估了SCA，并展示了软稳定性在衡量解释方法的稳健性方面的有效性。', 'title_zh': '特征归因的概率稳定性保证'}
{'arxiv_id': 'arXiv:2504.13785', 'title': 'Learning Through Retrospection: Improving Trajectory Prediction for Automated Driving with Error Feedback', 'authors': 'Steffen Hagedorn, Aron Distelzweig, Marcel Hallgarten, Alexandru P. Condurache', 'link': 'https://arxiv.org/abs/2504.13785', 'abstract': 'In automated driving, predicting trajectories of surrounding vehicles supports reasoning about scene dynamics and enables safe planning for the ego vehicle. However, existing models handle predictions as an instantaneous task of forecasting future trajectories based on observed information. As time proceeds, the next prediction is made independently of the previous one, which means that the model cannot correct its errors during inference and will repeat them. To alleviate this problem and better leverage temporal data, we propose a novel retrospection technique. Through training on closed-loop rollouts the model learns to use aggregated feedback. Given new observations it reflects on previous predictions and analyzes its errors to improve the quality of subsequent predictions. Thus, the model can learn to correct systematic errors during inference. Comprehensive experiments on nuScenes and Argoverse demonstrate a considerable decrease in minimum Average Displacement Error of up to 31.9% compared to the state-of-the-art baseline without retrospection. We further showcase the robustness of our technique by demonstrating a better handling of out-of-distribution scenarios with undetected road-users.', 'abstract_zh': '在自动驾驶中，预测周围车辆的轨迹有助于理解和推演场景动态，并支持ego车辆的安全规划。然而，现有模型将预测视为基于观测信息即时预测未来轨迹的任务。随着时间的推移，下一个预测与之前的预测独立进行，这意味着模型在推理过程中无法纠正错误并重复这些错误。为了缓解这一问题并更好地利用时间序列数据，我们提出了一种新的回溯技术。通过闭环回放训练，模型学会使用综合反馈。面对新的观测数据，它会反思以前的预测并分析错误以提高后续预测的质量。因此，模型可以学会在推理过程中纠正系统性错误。在nuScenes和Argoverse上的全面实验表明，与没有回溯的最先进的基线相比，平均位移误差的最小值降低了高达31.9%。我们还通过展示对未检测到的道路使用者的鲁棒处理能力，进一步证明了该技术的鲁棒性。', 'title_zh': '基于反思学习：通过误差反馈提高自动驾驶轨迹预测'}
{'arxiv_id': 'arXiv:2504.13774', 'title': 'DP2Unlearning: An Efficient and Guaranteed Unlearning Framework for LLMs', 'authors': 'Tamim Al Mahmud, Najeeb Jebreel, Josep Domingo-Ferrer, David Sanchez', 'link': 'https://arxiv.org/abs/2504.13774', 'abstract': 'Large language models (LLMs) have recently revolutionized language processing tasks but have also brought ethical and legal issues. LLMs have a tendency to memorize potentially private or copyrighted information present in the training data, which might then be delivered to end users at inference time. When this happens, a naive solution is to retrain the model from scratch after excluding the undesired data. Although this guarantees that the target data have been forgotten, it is also prohibitively expensive for LLMs. Approximate unlearning offers a more efficient alternative, as it consists of ex post modifications of the trained model itself to prevent undesirable results, but it lacks forgetting guarantees because it relies solely on empirical evidence. In this work, we present DP2Unlearning, a novel LLM unlearning framework that offers formal forgetting guarantees at a significantly lower cost than retraining from scratch on the data to be retained. DP2Unlearning involves training LLMs on textual data protected using {\\epsilon}-differential privacy (DP), which later enables efficient unlearning with the guarantees against disclosure associated with the chosen {\\epsilon}. Our experiments demonstrate that DP2Unlearning achieves similar model performance post-unlearning, compared to an LLM retraining from scratch on retained data -- the gold standard exact unlearning -- but at approximately half the unlearning cost. In addition, with a reasonable computational cost, it outperforms approximate unlearning methods at both preserving the utility of the model post-unlearning and effectively forgetting the targeted information.', 'abstract_zh': 'DP2Unlearning: 一种以较低成本提供正式遗忘保证的大语言模型删除框架', 'title_zh': 'DP2Unlearning: 一个高效且有保证的大语言模型遗忘框架'}
{'arxiv_id': 'arXiv:2504.13763', 'title': 'Decoding Vision Transformers: the Diffusion Steering Lens', 'authors': 'Ryota Takatsuki, Sonia Joseph, Ippei Fujisawa, Ryota Kanai', 'link': 'https://arxiv.org/abs/2504.13763', 'abstract': 'Logit Lens is a widely adopted method for mechanistic interpretability of transformer-based language models, enabling the analysis of how internal representations evolve across layers by projecting them into the output vocabulary space. Although applying Logit Lens to Vision Transformers (ViTs) is technically straightforward, its direct use faces limitations in capturing the richness of visual representations. Building on the work of Toker et al. (2024)~\\cite{Toker2024-ve}, who introduced Diffusion Lens to visualize intermediate representations in the text encoders of text-to-image diffusion models, we demonstrate that while Diffusion Lens can effectively visualize residual stream representations in image encoders, it fails to capture the direct contributions of individual submodules. To overcome this limitation, we propose \\textbf{Diffusion Steering Lens} (DSL), a novel, training-free approach that steers submodule outputs and patches subsequent indirect contributions. We validate our method through interventional studies, showing that DSL provides an intuitive and reliable interpretation of the internal processing in ViTs.', 'abstract_zh': 'Diffusion Steering Lens: A Training-Free Method for Capturing Indirect Contributions in Vision Transformers', 'title_zh': '解码视觉变换器：扩散导向透镜'}
{'arxiv_id': 'arXiv:2504.13756', 'title': 'Scaling sparse feature circuit finding for in-context learning', 'authors': 'Dmitrii Kharlapenko, Stepan Shabalin, Fazl Barez, Arthur Conmy, Neel Nanda', 'link': 'https://arxiv.org/abs/2504.13756', 'abstract': "Sparse autoencoders (SAEs) are a popular tool for interpreting large language model activations, but their utility in addressing open questions in interpretability remains unclear. In this work, we demonstrate their effectiveness by using SAEs to deepen our understanding of the mechanism behind in-context learning (ICL). We identify abstract SAE features that (i) encode the model's knowledge of which task to execute and (ii) whose latent vectors causally induce the task zero-shot. This aligns with prior work showing that ICL is mediated by task vectors. We further demonstrate that these task vectors are well approximated by a sparse sum of SAE latents, including these task-execution features. To explore the ICL mechanism, we adapt the sparse feature circuits methodology of Marks et al. (2024) to work for the much larger Gemma-1 2B model, with 30 times as many parameters, and to the more complex task of ICL. Through circuit finding, we discover task-detecting features with corresponding SAE latents that activate earlier in the prompt, that detect when tasks have been performed. They are causally linked with task-execution features through the attention and MLP sublayers.", 'abstract_zh': '稀疏自编码器在加深对上下文学习机制理解中的有效性', 'title_zh': '基于上下文的学习中稀疏特征电路搜索的扩展'}
{'arxiv_id': 'arXiv:2504.13754', 'title': 'Towards Accurate and Interpretable Neuroblastoma Diagnosis via Contrastive Multi-scale Pathological Image Analysis', 'authors': 'Zhu Zhu, Shuo Jiang, Jingyuan Zheng, Yawen Li, Yifei Chen, Manli Zhao, Weizhong Gu, Feiwei Qin, Jinhu Wang, Gang Yu', 'link': 'https://arxiv.org/abs/2504.13754', 'abstract': "Neuroblastoma, adrenal-derived, is among the most common pediatric solid malignancies, characterized by significant clinical heterogeneity. Timely and accurate pathological diagnosis from hematoxylin and eosin-stained whole slide images is critical for patient prognosis. However, current diagnostic practices primarily rely on subjective manual examination by pathologists, leading to inconsistent accuracy. Existing automated whole slide image classification methods encounter challenges such as poor interpretability, limited feature extraction capabilities, and high computational costs, restricting their practical clinical deployment. To overcome these limitations, we propose CMSwinKAN, a contrastive-learning-based multi-scale feature fusion model tailored for pathological image classification, which enhances the Swin Transformer architecture by integrating a Kernel Activation Network within its multilayer perceptron and classification head modules, significantly improving both interpretability and accuracy. By fusing multi-scale features and leveraging contrastive learning strategies, CMSwinKAN mimics clinicians' comprehensive approach, effectively capturing global and local tissue characteristics. Additionally, we introduce a heuristic soft voting mechanism guided by clinical insights to seamlessly bridge patch-level predictions to whole slide image-level classifications. We validate CMSwinKAN on the PpNTs dataset, which was collaboratively established with our partner hospital and the publicly accessible BreakHis dataset. Results demonstrate that CMSwinKAN performs better than existing state-of-the-art pathology-specific models pre-trained on large datasets. Our source code is available at this https URL.", 'abstract_zh': 'Neuroblastoma，源自肾上腺的儿童固体恶性肿瘤，具有显著的临床异质性。及时准确地对苏木精和伊红染色的全切片图像进行病理诊断对于患者的预后至关重要。然而，当前的诊断方法主要依赖病理学家的主观手工检查，导致诊断准确性不一致。现有的自动化全切片图像分类方法面临可解释性差、特征提取能力有限和计算成本高等挑战，限制了其在临床实践中的应用。为克服这些限制，我们提出了一种基于对比学习的多尺度特征融合模型CMSwinKAN，该模型通过在其多层感知机和分类头模块中整合核激活网络，增强了Swin Transformer架构，显著提高了可解释性和准确性。通过融合多尺度特征并利用对比学习策略，CMSwinKAN模仿了临床医生的综合诊断方法，有效捕捉全局和局部组织特征。此外，我们引入了一种基于临床洞察的启发式软投票机制，使其能够从切片级预测平滑过渡到全切片图像级分类。我们在与我们合作伙伴医院共同建立的PpNTs数据集和公开可访问的BreakHis数据集上验证了CMSwinKAN。结果显示，CMSwinKAN在大型数据集上预训练的具体病理学模型中表现更优。我们的源代码可在以下链接获取。', 'title_zh': '通过对比多尺度病理图像分析实现准确可解释的神经母细胞瘤诊断'}
{'arxiv_id': 'arXiv:2504.13751', 'title': 'A Survey for What Developers Require in AI-powered Tools that Aid in Component Selection in CBSD', 'authors': 'Mahdi Jaberzadeh Ansari, Ann Barcomb', 'link': 'https://arxiv.org/abs/2504.13751', 'abstract': 'Although it has been more than four decades that the first components-based software development (CBSD) studies were conducted, there is still no standard method or tool for component selection which is widely accepted by the industry. The gulf between industry and academia contributes to the lack of an accepted tool. We conducted a mixed methods survey of nearly 100 people engaged in component-based software engineering practice or research to better understand the problems facing industry, how these needs could be addressed, and current best practices employed in component selection. We also sought to identify and prioritize quality criteria for component selection from an industry perspective. In response to the call for CBSD component selection tools to incorporate recent technical advances, we also explored the perceptions of professionals about AI-driven tools, present and envisioned.', 'abstract_zh': '尽管基于组件的软件开发（CBSD）的研究已有四十余年的历史，但仍未有被行业广泛接受的组件选择标准方法或工具。我们通过混合方法对近100位从事组件式软件工程实践或研究的人员进行了调查，以更好地了解行业面临的问题、这些需求如何解决，以及当前的组件选择最佳实践。我们也致力于从行业角度识别和优先级排序组件选择的质量标准。为响应对CBSD组件选择工具结合近期技术进步的需求，我们还探讨了专业人士对人工智能驱动工具的看法，既有现有的也有预期的。', 'title_zh': 'AI赋能组件选择工具中开发者所需的功能调研'}
{'arxiv_id': 'arXiv:2504.13745', 'title': 'ESPLoRA: Enhanced Spatial Precision with Low-Rank Adaption in Text-to-Image Diffusion Models for High-Definition Synthesis', 'authors': 'Andrea Rigo, Luca Stornaiuolo, Mauro Martino, Bruno Lepri, Nicu Sebe', 'link': 'https://arxiv.org/abs/2504.13745', 'abstract': 'Diffusion models have revolutionized text-to-image (T2I) synthesis, producing high-quality, photorealistic images. However, they still struggle to properly render the spatial relationships described in text prompts. To address the lack of spatial information in T2I generations, existing methods typically use external network conditioning and predefined layouts, resulting in higher computational costs and reduced flexibility. Our approach builds upon a curated dataset of spatially explicit prompts, meticulously extracted and synthesized from LAION-400M to ensure precise alignment between textual descriptions and spatial layouts. Alongside this dataset, we present ESPLoRA, a flexible fine-tuning framework based on Low-Rank Adaptation, specifically designed to enhance spatial consistency in generative models without increasing generation time or compromising the quality of the outputs. In addition to ESPLoRA, we propose refined evaluation metrics grounded in geometric constraints, capturing 3D spatial relations such as \\textit{in front of} or \\textit{behind}. These metrics also expose spatial biases in T2I models which, even when not fully mitigated, can be strategically exploited by our TORE algorithm to further improve the spatial consistency of generated images. Our method outperforms the current state-of-the-art framework, CoMPaSS, by 13.33% on established spatial consistency benchmarks.', 'abstract_zh': '扩散模型已经革新了文本到图像（T2I）生成，产生了高质量、逼真的图像。然而，它们仍然难以正确渲染文本提示中描述的空间关系。为了弥补T2I生成中的空间信息不足，现有方法通常使用外部网络条件和预定义布局，导致计算成本增加和灵活性降低。我们的方法基于一个精心策划的空间明确提示数据集，该数据集从LAION-400M中仔细提取和合成，以确保文本描述与空间布局之间精确对齐。除了这个数据集，我们还提出了基于低秩适应的灵活微调框架ESPLoRA，专门设计用于在不增加生成时间和不牺牲输出质量的情况下增强生成模型的空间一致性。除了ESPLoRA，我们还提出了基于几何约束的细化评估指标，捕捉如“在前面”或“在后面”等三维空间关系。这些指标还揭示了T2I模型中的空间偏见，即使这些偏见未完全消除，我们的TORE算法也可以战略性地利用它们进一步提高生成图像的空间一致性。我们的方法在现有的基准测试中表现优于最先进的框架CoMPaSS，提高了13.33%的空间一致性。', 'title_zh': 'ESPLoRA: 基于低秩适应增强空间精度的文本到图像扩散模型在高定义合成中的应用'}
{'arxiv_id': 'arXiv:2504.13730', 'title': 'Controlled Territory and Conflict Tracking (CONTACT): (Geo-)Mapping Occupied Territory from Open Source Intelligence', 'authors': 'Paul K. Mandal, Cole Leo, Connor Hurley', 'link': 'https://arxiv.org/abs/2504.13730', 'abstract': 'Open-source intelligence provides a stream of unstructured textual data that can inform assessments of territorial control. We present CONTACT, a framework for territorial control prediction using large language models (LLMs) and minimal supervision. We evaluate two approaches: SetFit, an embedding-based few-shot classifier, and a prompt tuning method applied to BLOOMZ-560m, a multilingual generative LLM. Our model is trained on a small hand-labeled dataset of news articles covering ISIS activity in Syria and Iraq, using prompt-conditioned extraction of control-relevant signals such as military operations, casualties, and location references. We show that the BLOOMZ-based model outperforms the SetFit baseline, and that prompt-based supervision improves generalization in low-resource settings. CONTACT demonstrates that LLMs fine-tuned using few-shot methods can reduce annotation burdens and support structured inference from open-ended OSINT streams. Our code is available at this https URL.', 'abstract_zh': '开源情报提供了一条未结构化的文本数据流，可用于评估领土控制。本文介绍了CONTACT框架，该框架利用大规模语言模型（LLMs）和最少监督来预测领土控制。我们评估了两种方法：基于嵌入的少量示例分类器SetFit，以及应用于多语言生成性LLM BLOOMZ-560m的提示调优方法。模型使用少量手标注的新闻文章数据集进行训练，这些新闻文章涵盖了伊拉克和叙利亚的ISIS活动，提取了与控制相关的信号，如军事行动、伤亡情况和位置参考。结果显示，基于BLOOMZ的模型优于SetFit基线，提示引导的监督在资源有限的情况下改善了泛化能力。CONTACT证明了使用少量示例方法微调的LLMs可以减少标注负担，并支持从开放源代码情报流中进行结构化推理。代码可在以下链接获取：this https URL。', 'title_zh': 'Controlled Territory and Conflict Tracking (CONTACT): 从开源情报（Geo-）绘制占领领土'}
{'arxiv_id': 'arXiv:2504.13717', 'title': 'Human-aligned Deep Learning: Explainability, Causality, and Biological Inspiration', 'authors': 'Gianluca Carloni', 'link': 'https://arxiv.org/abs/2504.13717', 'abstract': "This work aligns deep learning (DL) with human reasoning capabilities and needs to enable more efficient, interpretable, and robust image classification. We approach this from three perspectives: explainability, causality, and biological vision. Introduction and background open this work before diving into operative chapters. First, we assess neural networks' visualization techniques for medical images and validate an explainable-by-design method for breast mass classification. A comprehensive review at the intersection of XAI and causality follows, where we introduce a general scaffold to organize past and future research, laying the groundwork for our second perspective. In the causality direction, we propose novel modules that exploit feature co-occurrence in medical images, leading to more effective and explainable predictions. We further introduce CROCODILE, a general framework that integrates causal concepts, contrastive learning, feature disentanglement, and prior knowledge to enhance generalization. Lastly, we explore biological vision, examining how humans recognize objects, and propose CoCoReco, a connectivity-inspired network with context-aware attention mechanisms. Overall, our key findings include: (i) simple activation maximization lacks insight for medical imaging DL models; (ii) prototypical-part learning is effective and radiologically aligned; (iii) XAI and causal ML are deeply connected; (iv) weak causal signals can be leveraged without a priori information to improve performance and interpretability; (v) our framework generalizes across medical domains and out-of-distribution data; (vi) incorporating biological circuit motifs improves human-aligned recognition. This work contributes toward human-aligned DL and highlights pathways to bridge the gap between research and clinical adoption, with implications for improved trust, diagnostic accuracy, and safe deployment.", 'abstract_zh': '本研究将深度学习与人类推理能力相结合，旨在实现更高效、可解释和鲁棒的图像分类。我们从可解释性、因果关系和生物视觉三个角度入手。介绍和背景铺垫后，深入探讨操作章节。首先，评估神经网络的医学图像可视化技术，并验证了设计可解释方法在乳腺肿块分类中的有效性。接着，我们进行了一次在解释性人工智能（XAI）和因果关系交叉领域的全面回顾，引入了一个通用框架来组织过去和未来的研究，为我们的第二视角奠定了基础。在因果关系方向上，我们提出了利用医学图像中特征共现的新模块，从而实现更有效和可解释的预测。我们还引入了CROCODILE框架，该框架整合了因果概念、对比学习、特征解耦以及先验知识，以提高泛化能力。最后，我们研究了生物视觉，探讨了人类如何识别物体，并提出了受连接性启发的网络CoCoReco，该网络具有上下文感知的注意力机制。总体而言，我们的主要发现包括：（i）简单的激活最大化对医学成像深度学习模型缺乏洞察力；（ii）原型部件学习既有效又符合放射学标准；（iii）XAI和因果机器学习紧密相关；（iv）可以在没有先验信息的情况下利用微弱的因果信号来提高性能和可解释性；（v）我们的框架在医学领域和离域数据中都具有泛化能力；（vi）结合生物电路模式可提高符合人类认知的识别。本研究朝着符合人类认知的深度学习方向迈进，并指出了连接研究与临床应用的途径，对未来提高了信任度、诊断准确性以及安全实施具有重要意义。', 'title_zh': '人类导向的深度学习：可解释性、因果关系及生物启发'}
{'arxiv_id': 'arXiv:2504.13700', 'title': 'Exploring Multimodal Prompt for Visualization Authoring with Large Language Models', 'authors': 'Zhen Wen, Luoxuan Weng, Yinghao Tang, Runjin Zhang, Yuxin Liu, Bo Pan, Minfeng Zhu, Wei Chen', 'link': 'https://arxiv.org/abs/2504.13700', 'abstract': "Recent advances in large language models (LLMs) have shown great potential in automating the process of visualization authoring through simple natural language utterances. However, instructing LLMs using natural language is limited in precision and expressiveness for conveying visualization intent, leading to misinterpretation and time-consuming iterations. To address these limitations, we conduct an empirical study to understand how LLMs interpret ambiguous or incomplete text prompts in the context of visualization authoring, and the conditions making LLMs misinterpret user intent. Informed by the findings, we introduce visual prompts as a complementary input modality to text prompts, which help clarify user intent and improve LLMs' interpretation abilities. To explore the potential of multimodal prompting in visualization authoring, we design VisPilot, which enables users to easily create visualizations using multimodal prompts, including text, sketches, and direct manipulations on existing visualizations. Through two case studies and a controlled user study, we demonstrate that VisPilot provides a more intuitive way to create visualizations without affecting the overall task efficiency compared to text-only prompting approaches. Furthermore, we analyze the impact of text and visual prompts in different visualization tasks. Our findings highlight the importance of multimodal prompting in improving the usability of LLMs for visualization authoring. We discuss design implications for future visualization systems and provide insights into how multimodal prompts can enhance human-AI collaboration in creative visualization tasks. All materials are available at this https URL.", 'abstract_zh': "Recent advances in large language models (LLMs) have shown great potential in automating the process of visualization authoring through simple natural language utterances. However, instructing LLMs using natural language is limited in precision and expressiveness for conveying visualization intent, leading to misinterpretation and time-consuming iterations. To address these limitations, we conduct an empirical study to understand how LLMs interpret ambiguous or incomplete text prompts in the context of visualization authoring, and the conditions making LLMs misinterpret user intent. Informed by the findings, we introduce visual prompts as a complementary input modality to text prompts, which help clarify user intent and improve LLMs' interpretation abilities. To explore the potential of multimodal prompting in visualization authoring, we design VisPilot, which enables users to easily create visualizations using multimodal prompts, including text, sketches, and direct manipulations on existing visualizations. Through two case studies and a controlled user study, we demonstrate that VisPilot provides a more intuitive way to create visualizations without affecting the overall task efficiency compared to text-only prompting approaches. Furthermore, we analyze the impact of text and visual prompts in different visualization tasks. Our findings highlight the importance of multimodal prompting in improving the usability of LLMs for visualization authoring. We discuss design implications for future visualization systems and provide insights into how multimodal prompts can enhance human-AI collaboration in creative visualization tasks. All materials are available at this https URL.", 'title_zh': '探索用于可视化作者生成的多模态提示方法'}
{'arxiv_id': 'arXiv:2504.13682', 'title': 'AnyTSR: Any-Scale Thermal Super-Resolution for UAV', 'authors': 'Mengyuan Li, Changhong Fu, Ziyu Lu, Zijie Zhang, Haobo Zuo, Liangliang Yao', 'link': 'https://arxiv.org/abs/2504.13682', 'abstract': 'Thermal imaging can greatly enhance the application of intelligent unmanned aerial vehicles (UAV) in challenging environments. However, the inherent low resolution of thermal sensors leads to insufficient details and blurred boundaries. Super-resolution (SR) offers a promising solution to address this issue, while most existing SR methods are designed for fixed-scale SR. They are computationally expensive and inflexible in practical applications. To address above issues, this work proposes a novel any-scale thermal SR method (AnyTSR) for UAV within a single model. Specifically, a new image encoder is proposed to explicitly assign specific feature code to enable more accurate and flexible representation. Additionally, by effectively embedding coordinate offset information into the local feature ensemble, an innovative any-scale upsampler is proposed to better understand spatial relationships and reduce artifacts. Moreover, a novel dataset (UAV-TSR), covering both land and water scenes, is constructed for thermal SR tasks. Experimental results demonstrate that the proposed method consistently outperforms state-of-the-art methods across all scaling factors as well as generates more accurate and detailed high-resolution images. The code is located at this https URL.', 'abstract_zh': '热成像技术可以显著增强智能无人机（UAV）在复杂环境中的应用。然而，热传感器固有的低分辨率导致细节不足和边界模糊。超分辨率（SR）提供了一种有希望的解决方案，但大多数现有SR方法主要用于固定尺度的SR。它们在实际应用中计算成本高且不够灵活。为解决上述问题，本工作提出了一种新颖的单模型任意尺度热SR方法（AnyTSR）。具体而言，提出了一种新的图像编码器，以明确分配特征码，从而实现更准确和灵活的表示。此外，通过有效嵌入坐标偏移信息到局部特征集合中，提出了一种创新的任意尺度上采样器，以更好地理解空间关系并减少伪影。此外，还构建了一个新的数据集（UAV-TSR），涵盖了陆地和水域场景，用于热SR任务。实验结果表明，所提出的方法在所有放大因子下均优于现有最佳方法，并生成了更准确和详细的高分辨率图像。代码位于此网址。', 'title_zh': 'AnyTSR: 任意尺度热超分辨率处理方法在无人机中的应用'}
{'arxiv_id': 'arXiv:2504.13677', 'title': 'Revisiting Uncertainty Quantification Evaluation in Language Models: Spurious Interactions with Response Length Bias Results', 'authors': 'Andrea Santilli, Adam Golinski, Michael Kirchhof, Federico Danieli, Arno Blaas, Miao Xiong, Luca Zappella, Sinead Williamson', 'link': 'https://arxiv.org/abs/2504.13677', 'abstract': 'Uncertainty Quantification (UQ) in Language Models (LMs) is crucial for improving their safety and reliability. Evaluations often use performance metrics like AUROC to assess how well UQ methods (e.g., negative sequence probabilities) correlate with task correctness functions (e.g., ROUGE-L). In this paper, we show that commonly used correctness functions bias UQ evaluations by inflating the performance of certain UQ methods. We evaluate 7 correctness functions -- from lexical-based and embedding-based metrics to LLM-as-a-judge approaches -- across 4 datasets x 4 models x 6 UQ methods. Our analysis reveals that length biases in the errors of these correctness functions distort UQ assessments by interacting with length biases in UQ methods. We identify LLM-as-a-judge approaches as among the least length-biased choices and hence a potential solution to mitigate these biases.', 'abstract_zh': '语言模型中不确定性量化（UQ）对于提高其安全性和可靠性至关重要。常见的正确性函数会偏倚UQ评估，从而使某些UQ方法的表现被夸大。本文通过在4个数据集和4个模型上评估7种不同正确性函数与6种UQ方法的组合，发现这些正确性函数中的长度偏倚会与UQ方法中的长度偏倚相互作用，从而扭曲UQ评估。我们将LLM-as-a-judge方法识别为其中最少长度偏倚的选择，有可能成为缓解这些偏倚的解决方案。', 'title_zh': '重温语言模型中不确定性量化评估：与响应长度的虚假交互及其影响结果的研究'}
{'arxiv_id': 'arXiv:2504.13676', 'title': 'Trace Gadgets: Minimizing Code Context for Machine Learning-Based Vulnerability Prediction', 'authors': 'Felix Mächtle, Nils Loose, Tim Schulz, Florian Sieck, Jan-Niclas Serr, Ralf Möller, Thomas Eisenbarth', 'link': 'https://arxiv.org/abs/2504.13676', 'abstract': "As the number of web applications and API endpoints exposed to the Internet continues to grow, so does the number of exploitable vulnerabilities. Manually identifying such vulnerabilities is tedious. Meanwhile, static security scanners tend to produce many false positives. While machine learning-based approaches are promising, they typically perform well only in scenarios where training and test data are closely related. A key challenge for ML-based vulnerability detection is providing suitable and concise code context, as excessively long contexts negatively affect the code comprehension capabilities of machine learning models, particularly smaller ones.\nThis work introduces Trace Gadgets, a novel code representation that minimizes code context by removing non-related code. Trace Gadgets precisely capture the statements that cover the path to the vulnerability. As input for ML models, Trace Gadgets provide a minimal but complete context, thereby improving the detection performance. Moreover, we collect a large-scale dataset generated from real-world applications with manually curated labels to further improve the performance of ML-based vulnerability detectors. Our results show that state-of-the-art machine learning models perform best when using Trace Gadgets compared to previous code representations, surpassing the detection capabilities of industry-standard static scanners such as GitHub's CodeQL by at least 4% on a fully unseen dataset. By applying our framework to real-world applications, we identify and report previously unknown vulnerabilities in widely deployed software.", 'abstract_zh': '随着暴露在网络上的Web应用和API端点数量不断增加，可利用的漏洞数量也在增长。手动识别这些漏洞是耗时的工作。同时，静态安全扫描器往往会产生大量的误报。虽然基于机器学习的方法很有前途，但在训练和测试数据紧密相关时，它们通常表现最佳。基于机器学习的漏洞检测的关键挑战之一是提供合适的简洁代码上下文，过长的代码上下文会负面影响机器学习模型，尤其是小型模型的代码理解能力。\n本工作引入了Trace Gadgets，这是一种新型的代码表示方法，通过移除与漏洞无关的代码来最小化代码上下文。Trace Gadgets精确捕捉到覆盖漏洞路径的语句。作为机器学习模型的输入，Trace Gadgets提供了最小但完整的信息上下文，从而提高检测性能。此外，我们收集了一个大规模的数据集，该数据集来自真实世界的应用，并附有手动标注的标签，以进一步提高基于机器学习的漏洞检测器的性能。我们的结果显示，最先进的机器学习模型在使用Trace Gadgets时表现最佳，与之前的方法相比，在未知数据集上超过了行业标准的静态扫描器GitHub CodeQL至少4%的检测能力。通过将我们的框架应用于真实世界的应用，我们识别并报告了广泛部署的软件中的未知漏洞。', 'title_zh': '基于代码上下文最小化的痕迹小工具：面向机器学习的漏洞预测'}
{'arxiv_id': 'arXiv:2504.13667', 'title': 'Large Language Models Will Change The Way Children Think About Technology And Impact Every Interaction Paradigm', 'authors': 'Russell Beale', 'link': 'https://arxiv.org/abs/2504.13667', 'abstract': 'This paper presents a hopeful perspective on the potentially dramatic impacts of Large Language Models on how we children learn and how they will expect to interact with technology. We review the effects of LLMs on education so far, and make the case that these effects are minor compared to the upcoming changes that are occurring. We present a small scenario and self-ethnographic study demonstrating the effects of these changes, and define five significant considerations that interactive systems designers will have to accommodate in the future.', 'abstract_zh': '这篇文章探讨了大型语言模型对儿童学习方式及其与技术互动预期的潜在深远影响，并指出这些影响与即将到来的变革相比显得微不足道。我们回顾了大型语言模型迄今为止对教育的影响，展示了变革效果的小规模情景和自我民族志研究，并定义了未来交互系统设计者必须考虑的五个重要方面。', 'title_zh': '大型语言模型将改变儿童对技术的认知方式，并影响每一交互范式。'}
{'arxiv_id': 'arXiv:2504.13656', 'title': 'Do Prompt Patterns Affect Code Quality? A First Empirical Assessment of ChatGPT-Generated Code', 'authors': 'Antonio Della Porta, Stefano Lambiase, Fabio Palomba', 'link': 'https://arxiv.org/abs/2504.13656', 'abstract': 'Large Language Models (LLMs) have rapidly transformed software development, especially in code generation. However, their inconsistent performance, prone to hallucinations and quality issues, complicates program comprehension and hinders maintainability. Research indicates that prompt engineering-the practice of designing inputs to direct LLMs toward generating relevant outputs-may help address these challenges. In this regard, researchers have introduced prompt patterns, structured templates intended to guide users in formulating their requests. However, the influence of prompt patterns on code quality has yet to be thoroughly investigated. An improved understanding of this relationship would be essential to advancing our collective knowledge on how to effectively use LLMs for code generation, thereby enhancing their understandability in contemporary software development. This paper empirically investigates the impact of prompt patterns on code quality, specifically maintainability, security, and reliability, using the Dev-GPT dataset. Results show that Zero-Shot prompting is most common, followed by Zero-Shot with Chain-of-Thought and Few-Shot. Analysis of 7583 code files across quality metrics revealed minimal issues, with Kruskal-Wallis tests indicating no significant differences among patterns, suggesting that prompt structure may not substantially impact these quality metrics in ChatGPT-assisted code generation.', 'abstract_zh': '大型语言模型（LLMs）迅速改变了软件开发，尤其是在代码生成方面。然而，它们不一致的表现，容易产生幻觉和质量问题，复杂了程序的理解并阻碍了维护性。研究表明，通过设计输入以引导LLMs生成相关输出的提示工程可能有助于应对这些挑战。在这方面，研究人员引入了提示模式，这是一种结构化的模板，旨在引导用户提出他们的请求。然而，提示模式对代码质量的影响尚未得到充分调查。对这一关系的更深入理解将有助于推进我们对如何有效使用LLMs进行代码生成的知识，从而增强它们在当代软件开发中的可理解性。本文使用Dev-GPT数据集实证研究了提示模式对代码质量，特别是维护性、安全性和可靠性的影響。结果表明，零-shot提示最常见，其次是零-shot带思维链和少量-shot。对7583个代码文件的质量指标分析显示，几乎没有问题，克鲁斯卡尔-瓦利检验表明不同模式之间没有显著差异，这表明提示结构在ChatGPT辅助代码生成中的可能对这些质量指标不会产生重大影响。', 'title_zh': '提示模式会影响代码质量吗？ChatGPT生成代码的首次实证评估'}
{'arxiv_id': 'arXiv:2504.13655', 'title': 'Multi-Type Context-Aware Conversational Recommender Systems via Mixture-of-Experts', 'authors': 'Jie Zou, Cheng Lin, Weikang Guo, Zheng Wang, Jiwei Wei, Yang Yang, Hengtao Shen', 'link': 'https://arxiv.org/abs/2504.13655', 'abstract': 'Conversational recommender systems enable natural language conversations and thus lead to a more engaging and effective recommendation scenario. As the conversations for recommender systems usually contain limited contextual information, many existing conversational recommender systems incorporate external sources to enrich the contextual information. However, how to combine different types of contextual information is still a challenge. In this paper, we propose a multi-type context-aware conversational recommender system, called MCCRS, effectively fusing multi-type contextual information via mixture-of-experts to improve conversational recommender systems. MCCRS incorporates both structured information and unstructured information, including the structured knowledge graph, unstructured conversation history, and unstructured item reviews. It consists of several experts, with each expert specialized in a particular domain (i.e., one specific contextual information). Multiple experts are then coordinated by a ChairBot to generate the final results. Our proposed MCCRS model takes advantage of different contextual information and the specialization of different experts followed by a ChairBot breaks the model bottleneck on a single contextual information. Experimental results demonstrate that our proposed MCCRS method achieves significantly higher performance compared to existing baselines.', 'abstract_zh': '多类型上下文感知会话推荐系统', 'title_zh': '基于专家混合的多类型上下文感知对话推荐系统'}
{'arxiv_id': 'arXiv:2504.13647', 'title': 'Lightweight LiDAR-Camera 3D Dynamic Object Detection and Multi-Class Trajectory Prediction', 'authors': 'Yushen He, Lei Zhao, Tianchen Deng, Zipeng Fang, Weidong Chen', 'link': 'https://arxiv.org/abs/2504.13647', 'abstract': 'Service mobile robots are often required to avoid dynamic objects while performing their tasks, but they usually have only limited computational resources. So we present a lightweight multi-modal framework for 3D object detection and trajectory prediction. Our system synergistically integrates LiDAR and camera inputs to achieve real-time perception of pedestrians, vehicles, and riders in 3D space. The framework proposes two novel modules: 1) a Cross-Modal Deformable Transformer (CMDT) for object detection with high accuracy and acceptable amount of computation, and 2) a Reference Trajectory-based Multi-Class Transformer (RTMCT) for efficient and diverse trajectory prediction of mult-class objects with flexible trajectory lengths. Evaluations on the CODa benchmark demonstrate superior performance over existing methods across detection (+2.03% in mAP) and trajectory prediction (-0.408m in minADE5 of pedestrians) metrics. Remarkably, the system exhibits exceptional deployability - when implemented on a wheelchair robot with an entry-level NVIDIA 3060 GPU, it achieves real-time inference at 13.2 fps. To facilitate reproducibility and practical deployment, we release the related code of the method at this https URL and its ROS inference version at this https URL.', 'abstract_zh': '轻量级多模态3D物体检测与轨迹预测框架', 'title_zh': '轻量级LiDAR-相机三维动态物体检测与多类轨迹预测'}
{'arxiv_id': 'arXiv:2504.13629', 'title': 'Divergent LLM Adoption and Heterogeneous Convergence Paths in Research Writing', 'authors': 'Cong William Lin, Wu Zhu', 'link': 'https://arxiv.org/abs/2504.13629', 'abstract': 'Large Language Models (LLMs), such as ChatGPT, are reshaping content creation and academic writing. This study investigates the impact of AI-assisted generative revisions on research manuscripts, focusing on heterogeneous adoption patterns and their influence on writing convergence. Leveraging a dataset of over 627,000 academic papers from arXiv, we develop a novel classification framework by fine-tuning prompt- and discipline-specific large language models to detect the style of ChatGPT-revised texts. Our findings reveal substantial disparities in LLM adoption across academic disciplines, gender, native language status, and career stage, alongside a rapid evolution in scholarly writing styles. Moreover, LLM usage enhances clarity, conciseness, and adherence to formal writing conventions, with improvements varying by revision type. Finally, a difference-in-differences analysis shows that while LLMs drive convergence in academic writing, early adopters, male researchers, non-native speakers, and junior scholars exhibit the most pronounced stylistic shifts, aligning their writing more closely with that of established researchers.', 'abstract_zh': '大型语言模型（LLMs）如ChatGPT正在重塑内容创作和学术写作。本研究探讨了AI辅助生成性修订对研究手稿的影响，重点关注不同学科中LLM采用模式的异质性及其对写作收敛的影响。利用arXiv上的超过627,000篇学术论文数据集，我们通过微调针对特定提示和学科的大规模语言模型，开发了一个新颖的分类框架以检测ChatGPT修订文本的风格。研究表明，LLM在不同学科、性别、母语状态和职业生涯阶段中的采用存在显著差异，同时学术写作风格正在迅速演变。此外，LLM的使用提高了清晰度、简洁性和对正式写作规范的遵守，但不同类型的修订所带来的改进有所不同。最后，差分分析表明，虽然LLMs促进了学术写作的收敛，但早期采用者、男性研究人员、非母语使用者和初级学者显示出最显著的风格变化，使他们的写作更加接近资深研究人员的风格。', 'title_zh': '不同的大规模语言模型采用路径与异质收敛路径在科研写作中的体现'}
{'arxiv_id': 'arXiv:2504.13626', 'title': 'Thought Manipulation: External Thought Can Be Efficient for Large Reasoning Models', 'authors': 'Yule Liu, Jingyi Zheng, Zhen Sun, Zifan Peng, Wenhan Dong, Zeyang Sha, Shiwen Cui, Weiqiang Wang, Xinlei He', 'link': 'https://arxiv.org/abs/2504.13626', 'abstract': 'Recent advancements in large reasoning models (LRMs) have demonstrated the effectiveness of scaling test-time computation to enhance reasoning capabilities in multiple tasks. However, LRMs typically suffer from "overthinking" problems, where models generate significantly redundant reasoning steps while bringing limited performance gains. Existing work relies on fine-tuning to mitigate overthinking, which requires additional data, unconventional training setups, risky safety misalignment, and poor generalization.\nThrough empirical analysis, we reveal an important characteristic of LRM behaviors that placing external CoTs generated by smaller models between the thinking token ($\\texttt{<think>}$ and $\\texttt{</think>)}$ can effectively manipulate the model to generate fewer thoughts. Building on these insights, we propose a simple yet efficient pipeline, ThoughtMani, to enable LRMs to bypass unnecessary intermediate steps and reduce computational costs significantly. We conduct extensive experiments to validate the utility and efficiency of ThoughtMani. For instance, when applied to QwQ-32B on the LiveBench/Code dataset, ThoughtMani keeps the original performance and reduces output token counts by approximately 30%, with little overhead from the CoT generator. Furthermore, we find that ThoughtMani enhances safety alignment by an average of 10%. Since model vendors typically serve models of different sizes simultaneously, ThoughtMani provides an effective way to construct more efficient and accessible LRMs for real-world applications.', 'abstract_zh': 'Recent advancements in大型推理模型（LRMs）最近在大型推理模型（LRMs）方面的进展已经证明了扩展测试时计算以增强多任务推理能力的有效性。然而，LRMs通常会遭遇“过度推理”问题，其中模型生成大量冗余的推理步骤，而带来的性能提升却有限。现有工作依赖于微调来缓解过度推理问题，这需要额外的数据、非传统的训练设置、安全对齐风险以及较差的一般化能力。\n通过实证分析，我们揭示了LRM行为的一个重要特征，即在思考标记（$\\texttt{<think>}和\\texttt{</think>}$）之间插入由更小型模型生成的外部CoTs（中间思考步骤）能够有效地控制模型生成更少的思考步骤。基于这些见解，我们提出了一种简单而高效的管道ThoughtMani，以使LRMs跳过不必要的中间步骤并显著降低计算成本。我们进行了广泛的实验来验证ThoughtMani的实用性和效率。例如，当将其应用于QwQ-32B在LiveBench/Code数据集上时，ThoughtMani能够保持原始性能并减少输出标记计数约30%，且CoTs生成器的额外开销不大。此外，我们发现ThoughtMani平均提高了10%的安全对齐性。由于模型供应商通常同时提供不同规模的模型，ThoughtMani为构建更高效、更易于使用的LRMs以适应实际应用提供了一种有效的方式。', 'title_zh': '思维操纵：外部思维可以高效支持大型推理模型'}
{'arxiv_id': 'arXiv:2504.13614', 'title': 'Adaptive Long-term Embedding with Denoising and Augmentation for Recommendation', 'authors': 'Zahra Akhlaghi, Mostafa Haghir Chehreghani', 'link': 'https://arxiv.org/abs/2504.13614', 'abstract': 'The rapid growth of the internet has made personalized recommendation systems indispensable. Graph-based sequential recommendation systems, powered by Graph Neural Networks (GNNs), effectively capture complex user-item interactions but often face challenges such as noise and static representations. In this paper, we introduce the Adaptive Long-term Embedding with Denoising and Augmentation for Recommendation (ALDA4Rec) method, a novel model that constructs an item-item graph, filters noise through community detection, and enriches user-item interactions. Graph Convolutional Networks (GCNs) are then employed to learn short-term representations, while averaging, GRUs, and attention mechanisms are utilized to model long-term embeddings. An MLP-based adaptive weighting strategy is further incorporated to dynamically optimize long-term user preferences. Experiments conducted on four real-world datasets demonstrate that ALDA4Rec outperforms state-of-the-art baselines, delivering notable improvements in both accuracy and robustness. The source code is available at this https URL.', 'abstract_zh': '基于图的自适应长期嵌入去噪与增强推荐方法（ALDA4Rec）', 'title_zh': '去噪与增强增强的自适应长期嵌入推荐'}
{'arxiv_id': 'arXiv:2504.13612', 'title': 'Entropic Time Schedulers for Generative Diffusion Models', 'authors': 'Dejan Stancevic, Luca Ambrogioni', 'link': 'https://arxiv.org/abs/2504.13612', 'abstract': 'The practical performance of generative diffusion models depends on the appropriate choice of the noise scheduling function, which can also be equivalently expressed as a time reparameterization. In this paper, we present a time scheduler that selects sampling points based on entropy rather than uniform time spacing, ensuring that each point contributes an equal amount of information to the final generation. We prove that this time reparameterization does not depend on the initial choice of time. Furthermore, we provide a tractable exact formula to estimate this \\emph{entropic time} for a trained model using the training loss without substantial overhead. Alongside the entropic time, inspired by the optimality results, we introduce a rescaled entropic time. In our experiments with mixtures of Gaussian distributions and ImageNet, we show that using the (rescaled) entropic times greatly improves the inference performance of trained models. In particular, we found that the image quality in pretrained EDM2 models, as evaluated by FID and FD-DINO scores, can be substantially increased by the rescaled entropic time reparameterization without increasing the number of function evaluations, with greater improvements in the few NFEs regime.', 'abstract_zh': '生成扩散模型的实践性能取决于噪声调度函数的适当选择，这也可以等效地表示为时间重参数化。本文提出了一种时间调度器，基于熵而非均匀时间间隔选择采样点，确保每个点对最终生成贡献相同的信息量。我们证明这种时间重参数化不依赖于初始的时间选择。此外，我们提供了一个可计算的精确公式，使用训练损失来估计训练模型的熵时间，而无需显著的开销。在熵时间的基础上，受到最优性结果的启发，我们引入了缩放熵时间。在使用高斯混合分布和ImageNet的数据实验中，我们发现使用（缩放的）熵时间显著提高了训练模型的推理性能，特别是在少量函数评估情况下，可大幅提高预训练EDM2模型的图像质量，而无需增加函数评估次数。', 'title_zh': '熵时间调度器用于生成性扩散模型'}
{'arxiv_id': 'arXiv:2504.13597', 'title': 'FocusNet: Transformer-enhanced Polyp Segmentation with Local and Pooling Attention', 'authors': 'Jun Zeng, KC Santosh, Deepak Rajan Nayak, Thomas de Lange, Jonas Varkey, Tyler Berzin, Debesh Jha', 'link': 'https://arxiv.org/abs/2504.13597', 'abstract': 'Colonoscopy is vital in the early diagnosis of colorectal polyps. Regular screenings can effectively prevent benign polyps from progressing to CRC. While deep learning has made impressive strides in polyp segmentation, most existing models are trained on single-modality and single-center data, making them less effective in real-world clinical environments. To overcome these limitations, we propose FocusNet, a Transformer-enhanced focus attention network designed to improve polyp segmentation. FocusNet incorporates three essential modules: the Cross-semantic Interaction Decoder Module (CIDM) for generating coarse segmentation maps, the Detail Enhancement Module (DEM) for refining shallow features, and the Focus Attention Module (FAM), to balance local detail and global context through local and pooling attention mechanisms. We evaluate our model on PolypDB, a newly introduced dataset with multi-modality and multi-center data for building more reliable segmentation methods. Extensive experiments showed that FocusNet consistently outperforms existing state-of-the-art approaches with a high dice coefficients of 82.47% on the BLI modality, 88.46% on FICE, 92.04% on LCI, 82.09% on the NBI and 93.42% on WLI modality, demonstrating its accuracy and robustness across five different modalities. The source code for FocusNet is available at this https URL.', 'abstract_zh': '结肠镜检查对于早期诊断结肠息肉至关重要。常规筛查可以有效预防良性息肉进展为CRC。尽管深度学习在息肉分割方面取得了显著进展，但大多数现有的模型都是基于单模态和单中心数据训练的，这使得它们在真实的临床环境中效果较差。为克服这些局限性，我们提出了一种FocusNet，这是一种增强注意力机制的Transformer网络，旨在改进息肉分割。FocusNet集成了三个关键模块：跨语义交互解码器模块（CIDM）用于生成粗略分割图，细节增强模块（DEM）用于细化浅层特征，以及重点注意力模块（FAM），通过局部和池化注意力机制来平衡局部细节和全局上下文。我们使用一个包含多模态和多中心数据的PolypDB新数据集评估了我们的模型，广泛实验表明FocusNet在不同的模态下（BLI、FICE、LCI、NBI和WLI）均表现出色，分别取得了高Dice系数82.47%、88.46%、92.04%、82.09%和93.42%，证明了其在五个不同模态下的准确性和鲁棒性。FocusNet的源代码可在以下链接获取。', 'title_zh': 'FocusNet：transformer增强的息肉分割方法及其局部和聚类注意力机制'}
{'arxiv_id': 'arXiv:2504.13590', 'title': 'HAECcity: Open-Vocabulary Scene Understanding of City-Scale Point Clouds with Superpoint Graph Clustering', 'authors': 'Alexander Rusnak, Frédéric Kaplan', 'link': 'https://arxiv.org/abs/2504.13590', 'abstract': "Traditional 3D scene understanding techniques are generally predicated on hand-annotated label sets, but in recent years a new class of open-vocabulary 3D scene understanding techniques has emerged. Despite the success of this paradigm on small scenes, existing approaches cannot scale efficiently to city-scale 3D datasets. In this paper, we present Hierarchical vocab-Agnostic Expert Clustering (HAEC), after the latin word for 'these', a superpoint graph clustering based approach which utilizes a novel mixture of experts graph transformer for its backbone. We administer this highly scalable approach to the first application of open-vocabulary scene understanding on the SensatUrban city-scale dataset. We also demonstrate a synthetic labeling pipeline which is derived entirely from the raw point clouds with no hand-annotation. Our technique can help unlock complex operations on dense urban 3D scenes and open a new path forward in the processing of digital twins.", 'abstract_zh': '传统三维场景理解技术通常依赖于人工标注的标签集，但近年来出现了一类新的开域词汇三维场景理解技术。尽管这种范式在小场景上取得了一定的成功，现有方法无法高效地扩展到城市规模的三维数据集。在本文中，我们提出了一种基于超点图聚类的多层次词汇无关专家聚类（HAEC）方法，该方法以拉丁文“these”为名，利用一种新颖的专家图变换器作为其骨干。我们将这种高度可扩展的方法应用于SensatUrban城市规模数据集的首次开域词汇场景理解应用中。我们还展示了一个完全从原始点云中推导出来的合成标注流程，无需人工标注。我们的技术有助于解锁对密集城市三维场景的复杂操作，并为数字孪生的处理开辟了一条新的路径。', 'title_zh': 'HAECcity：基于超级点图聚类的大规模城市点云开放词汇场景理解'}
{'arxiv_id': 'arXiv:2504.13587', 'title': 'RAG Without the Lag: Interactive Debugging for Retrieval-Augmented Generation Pipelines', 'authors': 'Quentin Romero Lauro, Shreya Shankar, Sepanta Zeighami, Aditya Parameswaran', 'link': 'https://arxiv.org/abs/2504.13587', 'abstract': "Retrieval-augmented generation (RAG) pipelines have become the de-facto approach for building AI assistants with access to external, domain-specific knowledge. Given a user query, RAG pipelines typically first retrieve (R) relevant information from external sources, before invoking a Large Language Model (LLM), augmented (A) with this information, to generate (G) responses. Modern RAG pipelines frequently chain multiple retrieval and generation components, in any order. However, developing effective RAG pipelines is challenging because retrieval and generation components are intertwined, making it hard to identify which component(s) cause errors in the eventual output. The parameters with the greatest impact on output quality often require hours of pre-processing after each change, creating prohibitively slow feedback cycles. To address these challenges, we present RAGGY, a developer tool that combines a Python library of composable RAG primitives with an interactive interface for real-time debugging. We contribute the design and implementation of RAGGY, insights into expert debugging patterns through a qualitative study with 12 engineers, and design implications for future RAG tools that better align with developers' natural workflows.", 'abstract_zh': '检索增强生成（RAG）管道已成为构建访问外部领域特定知识的AI助手的默认方法。给定用户查询，RAG管道通常首先从外部来源检索（R）相关信息，然后调用一个增强（A）了这些信息的大语言模型（LLM）来生成（G）响应。现代RAG管道经常以任意顺序串连多个检索和生成组件。然而，由于检索和生成组件交织，开发有效的RAG管道具有挑战性，难以识别哪个组件导致最终输出中的错误。参数对输出质量影响最大的往往需要在每次变更后进行数小时的预处理，从而创建了令人难以接受的缓慢反馈循环。为应对这些挑战，我们提出了一种名为RAGGY的开发者工具，结合了一个可组合的RAG原语Python库和一个实时调试的交互界面。我们提供了RAGGY的设计和实现、通过与12名工程师进行定性研究获得的专家调试模式洞见，以及对未来更好地与开发者自然工作流程对齐的RAG工具的设计启示。', 'title_zh': 'RAG无需延迟：检索增强生成管道的交互式调试'}
{'arxiv_id': 'arXiv:2504.13568', 'title': 'MetaDSE: A Few-shot Meta-learning Framework for Cross-workload CPU Design Space Exploration', 'authors': 'Runzhen Xue, Hao Wu, Mingyu Yan, Ziheng Xiao, Xiaochun Ye, Dongrui Fan', 'link': 'https://arxiv.org/abs/2504.13568', 'abstract': 'Cross-workload design space exploration (DSE) is crucial in CPU architecture design. Existing DSE methods typically employ the transfer learning technique to leverage knowledge from source workloads, aiming to minimize the requirement of target workload simulation. However, these methods struggle with overfitting, data ambiguity, and workload dissimilarity.\nTo address these challenges, we reframe the cross-workload CPU DSE task as a few-shot meta-learning problem and further introduce MetaDSE. By leveraging model agnostic meta-learning, MetaDSE swiftly adapts to new target workloads, greatly enhancing the efficiency of cross-workload CPU DSE. Additionally, MetaDSE introduces a novel knowledge transfer method called the workload-adaptive architectural mask algorithm, which uncovers the inherent properties of the architecture. Experiments on SPEC CPU 2017 demonstrate that MetaDSE significantly reduces prediction error by 44.3\\% compared to the state-of-the-art. MetaDSE is open-sourced and available at this \\href{this https URL}{anonymous GitHub.}', 'abstract_zh': '跨工作负载设计空间探索（DSE）在CPU架构设计中至关重要。现有的DSE方法通常使用迁移学习技术利用源工作负载的知识，旨在减少目标工作负载仿真的需求。然而，这些方法在应对过拟合、数据模糊性和工作负载差异方面存在困难。\n\n为解决这些挑战，我们将跨工作负载CPU DSE任务重新定义为少样本元学习问题，并进一步引入了MetaDSE。通过利用模型无关的元学习，MetaDSE能够迅速适应新的目标工作负载，极大地提升了跨工作负载CPU DSE的效率。此外，MetaDSE引入了一种新颖的知识转移方法——工作负载自适应架构掩码算法，揭示了架构的内在属性。SPEC CPU 2017上的实验结果显示，与现有最佳方法相比，MetaDSE将预测误差显著降低了44.3%。MetaDSE已开源，并可在本链接访问：this https URL。', 'title_zh': 'MetaDSE：针对跨工作负载CPU设计空间探索的少样本元学习框架'}
{'arxiv_id': 'arXiv:2504.13560', 'title': 'Zero-Shot Industrial Anomaly Segmentation with Image-Aware Prompt Generation', 'authors': 'SoYoung Park, Hyewon Lee, Mingyu Choi, Seunghoon Han, Jong-Ryul Lee, Sungsu Lim, Tae-Ho Kim', 'link': 'https://arxiv.org/abs/2504.13560', 'abstract': 'Anomaly segmentation is essential for industrial quality, maintenance, and stability. Existing text-guided zero-shot anomaly segmentation models are effective but rely on fixed prompts, limiting adaptability in diverse industrial scenarios. This highlights the need for flexible, context-aware prompting strategies. We propose Image-Aware Prompt Anomaly Segmentation (IAP-AS), which enhances anomaly segmentation by generating dynamic, context-aware prompts using an image tagging model and a large language model (LLM). IAP-AS extracts object attributes from images to generate context-aware prompts, improving adaptability and generalization in dynamic and unstructured industrial environments. In our experiments, IAP-AS improves the F1-max metric by up to 10%, demonstrating superior adaptability and generalization. It provides a scalable solution for anomaly segmentation across industries', 'abstract_zh': '工业质量、维护和稳定性需要异常分割。现有的文本引导零样本异常分割模型效果显著，但依赖固定提示，限制了在多种工业场景中的适应性。这强调了需要灵活且上下文感知的提示策略。我们提出图像感知提示异常分割（IAP-AS），该方法通过使用图像标签模型和大语言模型（LLM）生成动态的、上下文感知的提示来增强异常分割。IAP-AS 从图像中提取对象属性以生成上下文感知的提示，提高在动态和无结构工业环境中的适应性和通用性。我们的实验结果显示，IAP-AS 可将 F1-max 指标提高多达 10%，证明了其优越的适应性和通用性。它为跨行业的异常分割提供了一个可扩展的解决方案。', 'title_zh': '零shot工业异常分割：基于图像意识的提示生成'}
{'arxiv_id': 'arXiv:2504.13558', 'title': 'Transformers Can Overcome the Curse of Dimensionality: A Theoretical Study from an Approximation Perspective', 'authors': 'Yuling Jiao, Yanming Lai, Yang Wang, Bokai Yan', 'link': 'https://arxiv.org/abs/2504.13558', 'abstract': 'The Transformer model is widely used in various application areas of machine learning, such as natural language processing. This paper investigates the approximation of the Hölder continuous function class $\\mathcal{H}_{Q}^{\\beta}\\left([0,1]^{d\\times n},\\mathbb{R}^{d\\times n}\\right)$ by Transformers and constructs several Transformers that can overcome the curse of dimensionality. These Transformers consist of one self-attention layer with one head and the softmax function as the activation function, along with several feedforward layers. For example, to achieve an approximation accuracy of $\\epsilon$, if the activation functions of the feedforward layers in the Transformer are ReLU and floor, only $\\mathcal{O}\\left(\\log\\frac{1}{\\epsilon}\\right)$ layers of feedforward layers are needed, with widths of these layers not exceeding $\\mathcal{O}\\left(\\frac{1}{\\epsilon^{2/\\beta}}\\log\\frac{1}{\\epsilon}\\right)$. If other activation functions are allowed in the feedforward layers, the width of the feedforward layers can be further reduced to a constant. These results demonstrate that Transformers have a strong expressive capability. The construction in this paper is based on the Kolmogorov-Arnold Representation Theorem and does not require the concept of contextual mapping, hence our proof is more intuitively clear compared to previous Transformer approximation works. Additionally, the translation technique proposed in this paper helps to apply the previous approximation results of feedforward neural networks to Transformer research.', 'abstract_zh': '变压器模型在机器学习各应用领域，如自然语言处理中的广泛应用。本文探讨了变压器对Hölder连续函数类$\\mathcal{H}_{Q}^{\\beta}\\left([0,1]^{d\\times n},\\mathbb{R}^{d\\times n}\\right)$的逼近，并构建了若干种能够克服维数灾难的变压器。这些变压器由一个具有单一注意力头的自我注意力层和软最大化函数作为激活函数，以及若干前馈层组成。例如，为达到逼近精度$\\epsilon$，如果变压器的前馈层激活函数为ReLU和地板函数，仅需$\\mathcal{O}\\left(\\log\\frac{1}{\\epsilon}\\right)$层的前馈层，且这些层的宽度不超过$\\mathcal{O}\\left(\\frac{1}{\\epsilon^{2/\\beta}}\\log\\frac{1}{\\epsilon}\\right)$。如果允许前馈层使用其他激活函数，这些层的宽度可以进一步减少到常数。这些结果表明变压器具有较强的表征能力。本文的构建基于柯尔莫哥洛夫-阿诺尔德表示定理，无需引入上下文映射的概念，因此证明方法相较于先前的变压器逼近工作更为直观。此外，本文提出的翻译技术有助于将之前前馈神经网络的逼近结果应用于变压器研究。', 'title_zh': 'Transformer模型能够克服维数灾：从逼近论视角的理论研究'}
{'arxiv_id': 'arXiv:2504.13551', 'title': 'Q-FAKER: Query-free Hard Black-box Attack via Controlled Generation', 'authors': 'CheolWon Na, YunSeok Choi, Jee-Hyong Lee', 'link': 'https://arxiv.org/abs/2504.13551', 'abstract': "Many adversarial attack approaches are proposed to verify the vulnerability of language models. However, they require numerous queries and the information on the target model. Even black-box attack methods also require the target model's output information. They are not applicable in real-world scenarios, as in hard black-box settings where the target model is closed and inaccessible. Even the recently proposed hard black-box attacks still require many queries and demand extremely high costs for training adversarial generators. To address these challenges, we propose Q-faker (Query-free Hard Black-box Attacker), a novel and efficient method that generates adversarial examples without accessing the target model. To avoid accessing the target model, we use a surrogate model instead. The surrogate model generates adversarial sentences for a target-agnostic attack. During this process, we leverage controlled generation techniques. We evaluate our proposed method on eight datasets. Experimental results demonstrate our method's effectiveness including high transferability and the high quality of the generated adversarial examples, and prove its practical in hard black-box settings.", 'abstract_zh': '无查询强黑盒攻击者Q-faker：一种无需访问目标模型的高效对抗样本生成方法', 'title_zh': 'Q-FAKER:无需查询的受控生成驱动的硬黑盒攻击'}
{'arxiv_id': 'arXiv:2504.13548', 'title': 'Beyond One-Hot Labels: Semantic Mixing for Model Calibration', 'authors': 'Haoyang Luo, Linwei Tao, Minjing Dong, Chang Xu', 'link': 'https://arxiv.org/abs/2504.13548', 'abstract': 'Model calibration seeks to ensure that models produce confidence scores that accurately reflect the true likelihood of their predictions being correct. However, existing calibration approaches are fundamentally tied to datasets of one-hot labels implicitly assuming full certainty in all the annotations. Such datasets are effective for classification but provides insufficient knowledge of uncertainty for model calibration, necessitating the curation of datasets with numerically rich ground-truth confidence values. However, due to the scarcity of uncertain visual examples, such samples are not easily available as real datasets. In this paper, we introduce calibration-aware data augmentation to create synthetic datasets of diverse samples and their ground-truth uncertainty. Specifically, we present Calibration-aware Semantic Mixing (CSM), a novel framework that generates training samples with mixed class characteristics and annotates them with distinct confidence scores via diffusion models. Based on this framework, we propose calibrated reannotation to tackle the misalignment between the annotated confidence score and the mixing ratio during the diffusion reverse process. Besides, we explore the loss functions that better fit the new data representation paradigm. Experimental results demonstrate that CSM achieves superior calibration compared to the state-of-the-art calibration approaches. Code is available at this http URL.', 'abstract_zh': 'Model校准旨在确保模型生成的置信度评分能准确反映其预测正确的真正概率。然而，现有的校准方法本质上与只有一个热标签的数据集紧密关联，隐含地假设所有注解的完全确定性。这样的数据集适用于分类任务，但为模型校准提供的不确定性知识不足，因此需要构建具有丰富数值真实置信度值的注释数据集。但由于不确定的视觉示例稀缺，这些样本不易作为真实数据集获取。本文引入了校准aware数据增强方法以创建包含多样样本及其真实不确定性标注的合成数据集。具体而言，我们提出了校准aware语义混合（CSM）框架，该框架通过扩散模型生成具有混合类特征的训练样本并为其标注不同的置信度评分。基于该框架，我们提出了校准校注以解决扩散逆过程中的标注置信度评分与混合比例之间的偏差问题。此外，我们探索了更适合新数据表示范式的损失函数。实验结果表明，CSM在校准性能上优于现有的前沿校准方法。代码可在该网页链接获取。', 'title_zh': '超越独热标签：语义混合模型校准'}
{'arxiv_id': 'arXiv:2504.13545', 'title': 'Enhancing Multilingual Sentiment Analysis with Explainability for Sinhala, English, and Code-Mixed Content', 'authors': 'Azmarah Rizvi, Navojith Thamindu, A.M.N.H. Adhikari, W.P.U. Senevirathna, Dharshana Kasthurirathna, Lakmini Abeywardhana', 'link': 'https://arxiv.org/abs/2504.13545', 'abstract': 'Sentiment analysis is crucial for brand reputation management in the banking sector, where customer feedback spans English, Sinhala, Singlish, and code-mixed text. Existing models struggle with low-resource languages like Sinhala and lack interpretability for practical use. This research develops a hybrid aspect-based sentiment analysis framework that enhances multilingual capabilities with explainable outputs. Using cleaned banking customer reviews, we fine-tune XLM-RoBERTa for Sinhala and code-mixed text, integrate domain-specific lexicon correction, and employ BERT-base-uncased for English. The system classifies sentiment (positive, neutral, negative) with confidence scores, while SHAP and LIME improve interpretability by providing real-time sentiment explanations. Experimental results show that our approaches outperform traditional transformer-based classifiers, achieving 92.3 percent accuracy and an F1-score of 0.89 in English and 88.4 percent in Sinhala and code-mixed content. An explainability analysis reveals key sentiment drivers, improving trust and transparency. A user-friendly interface delivers aspect-wise sentiment insights, ensuring accessibility for businesses. This research contributes to robust, transparent sentiment analysis for financial applications by bridging gaps in multilingual, low-resource NLP and explainability.', 'abstract_zh': '银行领域中多语言情感分析的可解释框架：提升低资源语言品牌声誉管理', 'title_zh': '增强斯里兰卡僧伽罗语、英语及代码混合内容的多语言情感分析可解释性'}
{'arxiv_id': 'arXiv:2504.13541', 'title': 'SwitchMT: An Adaptive Context Switching Methodology for Scalable Multi-Task Learning in Intelligent Autonomous Agents', 'authors': 'Avaneesh Devkota, Rachmad Vidya Wicaksana Putra, Muhammad Shafique', 'link': 'https://arxiv.org/abs/2504.13541', 'abstract': 'The ability to train intelligent autonomous agents (such as mobile robots) on multiple tasks is crucial for adapting to dynamic real-world environments. However, state-of-the-art reinforcement learning (RL) methods only excel in single-task settings, and still struggle to generalize across multiple tasks due to task interference. Moreover, real-world environments also demand the agents to have data stream processing capabilities. Toward this, a state-of-the-art work employs Spiking Neural Networks (SNNs) to improve multi-task learning by exploiting temporal information in data stream, while enabling lowpower/energy event-based operations. However, it relies on fixed context/task-switching intervals during its training, hence limiting the scalability and effectiveness of multi-task learning. To address these limitations, we propose SwitchMT, a novel adaptive task-switching methodology for RL-based multi-task learning in autonomous agents. Specifically, SwitchMT employs the following key ideas: (1) a Deep Spiking Q-Network with active dendrites and dueling structure, that utilizes task-specific context signals to create specialized sub-networks; and (2) an adaptive task-switching policy that leverages both rewards and internal dynamics of the network parameters. Experimental results demonstrate that SwitchMT achieves superior performance in multi-task learning compared to state-of-the-art methods. It achieves competitive scores in multiple Atari games (i.e., Pong: -8.8, Breakout: 5.6, and Enduro: 355.2) compared to the state-of-the-art, showing its better generalized learning capability. These results highlight the effectiveness of our SwitchMT methodology in addressing task interference while enabling multi-task learning automation through adaptive task switching, thereby paving the way for more efficient generalist agents with scalable multi-task learning capabilities.', 'abstract_zh': '基于 reinforcement learning 的自主智能代理多任务学习的自适应任务切换方法', 'title_zh': 'SwitchMT：一种适应性上下文切换方法学，用于智能自主代理的可扩展多任务学习'}
{'arxiv_id': 'arXiv:2504.13534', 'title': 'CoT-RAG: Integrating Chain of Thought and Retrieval-Augmented Generation to Enhance Reasoning in Large Language Models', 'authors': 'Feiyang Li, Peng Fang, Zhan Shi, Arijit Khan, Fang Wang, Dan Feng, Weihao Wang, Xin Zhang, Yongjian Cui', 'link': 'https://arxiv.org/abs/2504.13534', 'abstract': 'While chain-of-thought (CoT) reasoning improves the performance of large language models (LLMs) in complex tasks, it still has two main challenges: the low reliability of relying solely on LLMs to generate reasoning chains and the interference of natural language reasoning chains on the inference logic of LLMs. To address these issues, we propose CoT-RAG, a novel reasoning framework with three key designs: (i) Knowledge Graph-driven CoT Generation, featuring knowledge graphs to modulate reasoning chain generation of LLMs, thereby enhancing reasoning credibility; (ii) Learnable Knowledge Case-aware RAG, which incorporates retrieval-augmented generation (RAG) into knowledge graphs to retrieve relevant sub-cases and sub-descriptions, providing LLMs with learnable information; (iii) Pseudo-Program Prompting Execution, which encourages LLMs to execute reasoning tasks in pseudo-programs with greater logical rigor. We conduct a comprehensive evaluation on nine public datasets, covering three reasoning problems. Compared with the-state-of-the-art methods, CoT-RAG exhibits a significant accuracy improvement, ranging from 4.0% to 23.0%. Furthermore, testing on four domain-specific datasets, CoT-RAG shows remarkable accuracy and efficient execution, highlighting its strong practical applicability and scalability.', 'abstract_zh': '基于知识图谱的链式思考增强检索生成框架：CoT-RAG', 'title_zh': 'CoT-RAG：结合思维链和检索增强生成以增强大型语言模型的推理能力'}
{'arxiv_id': 'arXiv:2504.13521', 'title': 'Deep Learning Models Meet Financial Data Modalities', 'authors': 'Kasymkhan Khubiev, Michail Semenov', 'link': 'https://arxiv.org/abs/2504.13521', 'abstract': 'Algorithmic trading relies on extracting meaningful signals from diverse financial data sources, including candlestick charts, order statistics on put and canceled orders, traded volume data, limit order books, and news flow. While deep learning has demonstrated remarkable success in processing unstructured data and has significantly advanced natural language processing, its application to structured financial data remains an ongoing challenge. This study investigates the integration of deep learning models with financial data modalities, aiming to enhance predictive performance in trading strategies and portfolio optimization. We present a novel approach to incorporating limit order book analysis into algorithmic trading by developing embedding techniques and treating sequential limit order book snapshots as distinct input channels in an image-based representation. Our methodology for processing limit order book data achieves state-of-the-art performance in high-frequency trading algorithms, underscoring the effectiveness of deep learning in financial applications.', 'abstract_zh': '算法交易依赖于从多元金融数据源中提取有意义的信号，包括K线图、限价订单成交与撤销统计、成交volume数据、限价订单簿以及新闻流。尽管深度学习在处理非结构化数据和自然语言处理方面取得了显著成功，并显著推进了相关领域的发展，但其在结构化金融数据中的应用仍然是一个持续的挑战。本研究探讨了将深度学习模型与金融数据模态结合的方法，旨在提高交易策略和投资组合优化的预测性能。我们提出了一种将限价订单簿分析纳入算法交易的新方法，通过开发嵌入技术，并将限价订单簿的顺序快照作为图像表示中的独立输入通道。我们处理限价订单簿数据的方法在高频交易算法中达到了最先进的性能，突显了深度学习在金融应用中的有效性。', 'title_zh': '深度学习模型遇见金融数据模态'}
{'arxiv_id': 'arXiv:2504.13515', 'title': 'Large Language Models for Validating Network Protocol Parsers', 'authors': 'Mingwei Zheng, Danning Xie, Xiangyu Zhang', 'link': 'https://arxiv.org/abs/2504.13515', 'abstract': 'Network protocol parsers are essential for enabling correct and secure communication between devices. Bugs in these parsers can introduce critical vulnerabilities, including memory corruption, information leakage, and denial-of-service attacks. An intuitive way to assess parser correctness is to compare the implementation with its official protocol standard. However, this comparison is challenging because protocol standards are typically written in natural language, whereas implementations are in source code. Existing methods like model checking, fuzzing, and differential testing have been used to find parsing bugs, but they either require significant manual effort or ignore the protocol standards, limiting their ability to detect semantic violations. To enable more automated validation of parser implementations against protocol standards, we propose PARVAL, a multi-agent framework built on large language models (LLMs). PARVAL leverages the capabilities of LLMs to understand both natural language and code. It transforms both protocol standards and their implementations into a unified intermediate representation, referred to as format specifications, and performs a differential comparison to uncover inconsistencies. We evaluate PARVAL on the Bidirectional Forwarding Detection (BFD) protocol. Our experiments demonstrate that PARVAL successfully identifies inconsistencies between the implementation and its RFC standard, achieving a low false positive rate of 5.6%. PARVAL uncovers seven unique bugs, including five previously unknown issues.', 'abstract_zh': '网络协议解析器对于实现设备之间正确的安全通信至关重要。这些解析器中的漏洞可能会引入关键的安全风险，包括内存损坏、信息泄露和拒绝服务攻击。评估解析器正确性的直观方法是将其实现与其官方协议标准进行比较。然而，这种比较具有挑战性，因为协议标准通常用自然语言编写，而实现则是用源代码编写的。现有的方法如模型检查、模糊测试和差异测试已被用于查找解析器漏洞，但这些方法要么需要大量的手动工作，要么忽视了协议标准，限制了它们检测语义违规的能力。为了实现对协议标准的更自动化的解析器实现验证，我们提出了一种基于大型语言模型（LLMs）的多代理框架PARVAL。PARVAL利用了LLMs理解自然语言和代码的能力，将协议标准及其实现都转换为统一的中间表示，称为格式规范，并进行差异比较以发现不一致之处。我们对双向转发检测（BFD）协议进行了评估。实验结果表明，PARVAL成功地识别了实现与其RFC标准之间的不一致，且误报率为5.6%。PARVAL发现了七个独特的漏洞，其中包括五个未知的问题。', 'title_zh': '大型语言模型在验证网络协议解析器中的应用'}
{'arxiv_id': 'arXiv:2504.13495', 'title': 'Statistical Validation in Cultural Adaptations of Cognitive Tests: A Multi- Regional Systematic Review', 'authors': 'Miit Daga, Priyasha Mohanty, Ram Krishna, Swarna Priya RM', 'link': 'https://arxiv.org/abs/2504.13495', 'abstract': 'This systematic review discusses the methodological approaches and statistical confirmations of cross-cultural adaptations of cognitive evaluation tools used with different populations. The review considers six seminal studies on the methodology of cultural adaptation in Europe, Asia, Africa, and South America. The results indicate that proper adaptations need holistic models with demographic changes, and education explained as much as 26.76% of the variance in MoCA-H scores. Cultural-linguistic factors explained 6.89% of the variance in European adaptations of MoCA-H; however, another study on adapted MMSE and BCSB among Brazilian Indigenous populations reported excellent diagnostic performance, with a sensitivity of 94.4% and specificity of 99.2%. There was 78.5% inter-rater agreement on the evaluation of cultural adaptation using the Manchester Translation Evaluation Checklist. A paramount message of the paper is that community feedback is necessary for culturally appropriate preparation, standardized translation protocols also must be included, along with robust statistical validation methodologies for developing cognitive assessment instruments. This review supplies evidence-based frameworks for the further adaptation of cognitive assessments in increasingly diverse global health settings.', 'abstract_zh': '这一系统综述探讨了用于不同人群的认知评估工具跨文化适应的方法学方法和统计确认。该综述考虑了欧洲、亚洲、非洲和南美洲的六项关于文化适应方法学的前期研究。研究结果表明，适当的适应需要综合模型，并考虑到人口变化，教育解释了MoCA-H评分26.76%的变异。文化-语言因素解释了欧洲MoCA-H适应版本变异性的6.89%；然而，另一项关于巴西原住民群体适应MMSE和BCSB的研究报告了出色的诊断性能，敏感性为94.4%，特异性为99.2%。使用曼彻斯特翻译评估检查表评估文化适应的一致性为78.5%。本文的核心信息是，社区反馈对于文化适宜性的准备是必要的，标准化翻译协议也必须包括在内，并结合坚实的数据统计验证方法来开发认知评估工具。该综述为在全球日益多元的健康环境中进一步适应认知评估提供了基于证据的框架。', 'title_zh': '文化适应的认知测试统计验证：多区域系统评价'}
{'arxiv_id': 'arXiv:2504.13480', 'title': 'Integrating Locality-Aware Attention with Transformers for General Geometry PDEs', 'authors': 'Minsu Koh, Beom-Chul Park, Heejo Kong, Seong-Whan Lee', 'link': 'https://arxiv.org/abs/2504.13480', 'abstract': 'Neural operators have emerged as promising frameworks for learning mappings governed by partial differential equations (PDEs), serving as data-driven alternatives to traditional numerical methods. While methods such as the Fourier neural operator (FNO) have demonstrated notable performance, their reliance on uniform grids restricts their applicability to complex geometries and irregular meshes. Recently, Transformer-based neural operators with linear attention mechanisms have shown potential in overcoming these limitations for large-scale PDE simulations. However, these approaches predominantly emphasize global feature aggregation, often overlooking fine-scale dynamics and localized PDE behaviors essential for accurate solutions. To address these challenges, we propose the Locality-Aware Attention Transformer (LA2Former), which leverages K-nearest neighbors for dynamic patchifying and integrates global-local attention for enhanced PDE modeling. By combining linear attention for efficient global context encoding with pairwise attention for capturing intricate local interactions, LA2Former achieves an optimal balance between computational efficiency and predictive accuracy. Extensive evaluations across six benchmark datasets demonstrate that LA2Former improves predictive accuracy by over 50% relative to existing linear attention methods, while also outperforming full pairwise attention under optimal conditions. This work underscores the critical importance of localized feature learning in advancing Transformer-based neural operators for solving PDEs on complex and irregular domains.', 'abstract_zh': '基于局部意识注意力的Transformer（LA2Former）：面向复杂和不规则域的偏微分方程建模', 'title_zh': '将局部意识注意力融入变压器以处理通用几何偏微分方程'}
{'arxiv_id': 'arXiv:2504.13477', 'title': "Creating 'Full-Stack' Hybrid Reasoning Systems that Prioritize and Enhance Human Intelligence", 'authors': 'Sean Koon', 'link': 'https://arxiv.org/abs/2504.13477', 'abstract': 'The idea of augmented or hybrid intelligence offers a compelling vision for combining human and AI capabilities, especially in tasks where human wisdom, expertise, or common sense are essential. Unfortunately, human reasoning can be flawed and shortsighted, resulting in adverse individual impacts or even long-term societal consequences. While strong efforts are being made to develop and optimize the AI aspect of hybrid reasoning, the real urgency lies in fostering wiser and more intelligent human participation. Tools that enhance critical thinking, ingenuity, expertise, and even wisdom could be essential in addressing the challenges of our emerging future. This paper proposes the development of generative AI-based tools that enhance both the human ability to reflect upon a problem as well as the ability to explore the technical aspects of it. A high-level model is also described for integrating AI and human capabilities in a way that centralizes human participation and control.', 'abstract_zh': '基于生成AI的工具开发：提升人类问题反思能力和技术探索能力', 'title_zh': '创建优先并增强人类智能的“全栈”混合推理系统'}
{'arxiv_id': 'arXiv:2504.13472', 'title': 'CodeVisionary: An Agent-based Framework for Evaluating Large Language Models in Code Generation', 'authors': 'Xinchen Wang, Pengfei Gao, Chao Peng, Ruida Hu, Cuiyun Gao', 'link': 'https://arxiv.org/abs/2504.13472', 'abstract': 'Large language models (LLMs) have demonstrated strong capabilities in code generation, underscoring the critical need for rigorous and comprehensive evaluation. Existing evaluation approaches fall into three categories, including human-centered, metric-based, and LLM-based. Considering that human-centered approaches are labour-intensive and metric-based ones overly rely on reference answers, LLM-based approaches are gaining increasing attention due to their stronger contextual understanding capabilities and superior efficiency. However, the performance of LLM-based approaches remains limited due to: (1) lack of multisource domain knowledge, and (2) insufficient comprehension of complex code.\nTo mitigate the limitations, we propose CodeVisionary, the first LLM-based agent framework for evaluating LLMs in code generation. CodeVisionary consists of two stages: (1) Multiscore knowledge analysis stage, which aims to gather multisource and comprehensive domain knowledge by formulating and executing a stepwise evaluation plan. (2) Negotiation-based scoring stage, which involves multiple judges engaging in discussions to better comprehend the complex code and reach a consensus on the evaluation score. Extensive experiments demonstrate that CodeVisionary achieves the best performance for evaluating LLMs in code generation, outperforming the best baseline methods with average improvements of 0.202, 0.139, and 0.117 in Pearson, Spearman, and Kendall-Tau coefficients, respectively. Besides, CodeVisionary provides detailed evaluation reports, which assist developers in identifying shortcomings and making improvements. The resources of CodeVisionary are available at this https URL.', 'abstract_zh': '大规模语言模型（LLMs）在代码生成方面展现了强大的能力，强调了严格和全面评估的迫切需要。现有的评估方法主要分为三类：以人类为中心、基于指标和基于大语言模型的方法。鉴于以人类为中心的方法耗时且基于指标的方法过度依赖参考答案，基于大语言模型的方法因其更强的上下文理解能力和更高的效率而受到越来越多的关注。然而，基于大语言模型的方法在评价代码生成方面的能力依然有限，主要原因在于（1）缺乏多源领域知识，以及（2）对复杂代码理解不足。\n\n为克服这些局限性，我们提出了CodeVisionary，这是一种用于代码生成评估的大规模语言模型（LLM）基于的代理框架。CodeVisionary包括两个阶段：（1）多源知识分析阶段，旨在通过制定并执行分步骤的评估计划来收集多源和全面的领域知识。（2）基于谈判的评分阶段，涉及多个评审者进行讨论，以更好地理解复杂代码并达成一致的评估分数。广泛实验结果表明，CodeVisionary在代码生成评估方面性能最佳，与最佳基线方法相比，在皮尔逊系数、斯皮尔曼系数和肯德尔τ系数上的平均改进分别为0.202、0.139和0.117。此外，CodeVisionary提供了详细的评估报告，帮助开发者识别不足并进行改进。CodeVisionary的资源可访问此链接：此https URL。', 'title_zh': 'CodeVisionary：一种基于代理的大型语言模型代码生成评估框架'}
{'arxiv_id': 'arXiv:2504.13460', 'title': 'Chain-of-Thought Textual Reasoning for Few-shot Temporal Action Localization', 'authors': 'Hongwei Ji, Wulian Yun, Mengshi Qi, Huadong Ma', 'link': 'https://arxiv.org/abs/2504.13460', 'abstract': "Traditional temporal action localization (TAL) methods rely on large amounts of detailed annotated data, whereas few-shot TAL reduces this dependence by using only a few training samples to identify unseen action categories. However, existing few-shot TAL methods typically focus solely on video-level information, neglecting textual information, which can provide valuable semantic support for the localization task. Therefore, we propose a new few-shot temporal action localization method by Chain-of-Thought textual reasoning to improve localization performance. Specifically, we design a novel few-shot learning framework that leverages textual semantic information to enhance the model's ability to capture action commonalities and variations, which includes a semantic-aware text-visual alignment module designed to align the query and support videos at different levels. Meanwhile, to better express the temporal dependencies and causal relationships between actions at the textual level to assist action localization, we design a Chain of Thought (CoT)-like reasoning method that progressively guides the Vision Language Model (VLM) and Large Language Model (LLM) to generate CoT-like text descriptions for videos. The generated texts can capture more variance of action than visual features. We conduct extensive experiments on the publicly available ActivityNet1.3 and THUMOS14 datasets. We introduce the first dataset named Human-related Anomaly Localization and explore the application of the TAL task in human anomaly detection. The experimental results demonstrate that our proposed method significantly outperforms existing methods in single-instance and multi-instance scenarios. We will release our code, data and benchmark.", 'abstract_zh': '基于链式推理的少样本 temporal 动作定位方法', 'title_zh': '基于链式思维的文字推理在少样本时序动作定位中的应用'}
{'arxiv_id': 'arXiv:2504.13448', 'title': 'Ascribe New Dimensions to Scientific Data Visualization with VR', 'authors': 'Daniela Ushizima, Guilherme Melo dos Santos, Zineb Sordo, Ronald Pandolfi, Jeffrey Donatelli', 'link': 'https://arxiv.org/abs/2504.13448', 'abstract': 'For over half a century, the computer mouse has been the primary tool for interacting with digital data, yet it remains a limiting factor in exploring complex, multi-scale scientific images. Traditional 2D visualization methods hinder intuitive analysis of inherently 3D structures. Virtual Reality (VR) offers a transformative alternative, providing immersive, interactive environments that enhance data comprehension. This article introduces ASCRIBE-VR, a VR platform of Autonomous Solutions for Computational Research with Immersive Browsing \\& Exploration, which integrates AI-driven algorithms with scientific images. ASCRIBE-VR enables multimodal analysis, structural assessments, and immersive visualization, supporting scientific visualization of advanced datasets such as X-ray CT, Magnetic Resonance, and synthetic 3D imaging. Our VR tools, compatible with Meta Quest, can consume the output of our AI-based segmentation and iterative feedback processes to enable seamless exploration of large-scale 3D images. By merging AI-generated results with VR visualization, ASCRIBE-VR enhances scientific discovery, bridging the gap between computational analysis and human intuition in materials research, connecting human-in-the-loop with digital twins.', 'abstract_zh': 'ASCRIBE-VR：自主解决方案的沉浸式浏览与探索虚拟现实平台', 'title_zh': '使用VR重新定义科学研究数据可视化'}
{'arxiv_id': 'arXiv:2504.13429', 'title': 'Bounded and Uniform Energy-based Out-of-distribution Detection for Graphs', 'authors': 'Shenzhi Yang, Bin Liang, An Liu, Lin Gui, Xingkai Yao, Xiaofang Zhang', 'link': 'https://arxiv.org/abs/2504.13429', 'abstract': 'Given the critical role of graphs in real-world applications and their high-security requirements, improving the ability of graph neural networks (GNNs) to detect out-of-distribution (OOD) data is an urgent research problem. The recent work GNNSAFE proposes a framework based on the aggregation of negative energy scores that significantly improves the performance of GNNs to detect node-level OOD data. However, our study finds that score aggregation among nodes is susceptible to extreme values due to the unboundedness of the negative energy scores and logit shifts, which severely limits the accuracy of GNNs in detecting node-level OOD data. In this paper, we propose NODESAFE: reducing the generation of extreme scores of nodes by adding two optimization terms that make the negative energy scores bounded and mitigate the logit shift. Experimental results show that our approach dramatically improves the ability of GNNs to detect OOD data at the node level, e.g., in detecting OOD data induced by Structure Manipulation, the metric of FPR95 (lower is better) in scenarios without (with) OOD data exposure are reduced from the current SOTA by 28.4% (22.7%).', 'abstract_zh': '基于节点极端分数抑制的 NODESAFE：提升图神经网络检测节点级 OOD 数据的能力', 'title_zh': '基于图的有界和均匀能量法异分布检测'}
{'arxiv_id': 'arXiv:2504.13415', 'title': 'DADU: Dual Attention-based Deep Supervised UNet for Automated Semantic Segmentation of Cardiac Images', 'authors': 'Racheal Mukisa, Arvind K. Bansal', 'link': 'https://arxiv.org/abs/2504.13415', 'abstract': 'We propose an enhanced deep learning-based model for image segmentation of the left and right ventricles and myocardium scar tissue from cardiac magnetic resonance (CMR) images. The proposed technique integrates UNet, channel and spatial attention, edge-detection based skip-connection and deep supervised learning to improve the accuracy of the CMR image-segmentation. Images are processed using multiple channels to generate multiple feature-maps. We built a dual attention-based model to integrate channel and spatial attention. The use of extracted edges in skip connection improves the reconstructed images from feature-maps. The use of deep supervision reduces vanishing gradient problems inherent in classification based on deep neural networks. The algorithms for dual attention-based model, corresponding implementation and performance results are described. The performance results show that this approach has attained high accuracy: 98% Dice Similarity Score (DSC) and significantly lower Hausdorff Distance (HD). The performance results outperform other leading techniques both in DSC and HD.', 'abstract_zh': '基于增强深度学习的左右心室及心肌疤痕组织 cardiac magnetic resonance 图像分割模型', 'title_zh': 'DADU: 基于双注意力的深监督UNet在心脏图像语义分割中的应用'}
{'arxiv_id': 'arXiv:2504.13414', 'title': 'Adaptive Non-local Observable on Quantum Neural Networks', 'authors': 'Hsin-Yi Lin, Huan-Hsin Tseng, Samuel Yen-Chi Chen, Shinjae Yoo', 'link': 'https://arxiv.org/abs/2504.13414', 'abstract': 'Conventional Variational Quantum Circuits (VQCs) for Quantum Machine Learning typically rely on a fixed Hermitian observable, often built from Pauli operators. Inspired by the Heisenberg picture, we propose an adaptive non-local measurement framework that substantially increases the model complexity of the quantum circuits. Our introduction of dynamical Hermitian observables with evolving parameters shows that optimizing VQC rotations corresponds to tracing a trajectory in the observable space. This viewpoint reveals that standard VQCs are merely a special case of the Heisenberg representation.\nFurthermore, we show that properly incorporating variational rotations with non-local observables enhances qubit interaction and information mixture, admitting flexible circuit designs. Two non-local measurement schemes are introduced, and numerical simulations on classification tasks confirm that our approach outperforms conventional VQCs, yielding a more powerful and resource-efficient approach as a Quantum Neural Network.', 'abstract_zh': '传统变分量子电路(VQCs)在量子机器学习中通常依赖于固定的整体算子，常由保罗伊算子构建。受海森堡图像启发，我们提出了一种适应性非局部测量框架，显著提高了量子电路的模型复杂度。我们将动态整体算子与演化参数引入，表明优化VQC旋转对应于在观测空间中绘制轨迹的过程。这一视角揭示了标准VQCs仅仅是海森堡表示的特殊情况。\n\n此外，我们证明正确引入变分旋转与非局部观测值增强了量子比特间的交互和信息混合，允许灵活的电路设计。两种非局部测量方案被引入，数值模拟在分类任务中的表现证实了我们方法优于传统VQCs，提供了一种更强大和资源高效的量子神经网络方法。', 'title_zh': '自适应非局部可观测性在量子神经网络中的应用'}
{'arxiv_id': 'arXiv:2504.13407', 'title': 'LoRA-Based Continual Learning with Constraints on Critical Parameter Changes', 'authors': 'Shimou Ling, Liang Zhang, Jiangwei Zhao, Lili Pan, Hongliang Li', 'link': 'https://arxiv.org/abs/2504.13407', 'abstract': 'LoRA-based continual learning represents a promising avenue for leveraging pre-trained models in downstream continual learning tasks. Recent studies have shown that orthogonal LoRA tuning effectively mitigates forgetting. However, this work unveils that under orthogonal LoRA tuning, the critical parameters for pre-tasks still change notably after learning post-tasks. To address this problem, we directly propose freezing the most critical parameter matrices in the Vision Transformer (ViT) for pre-tasks before learning post-tasks. In addition, building on orthogonal LoRA tuning, we propose orthogonal LoRA composition (LoRAC) based on QR decomposition, which may further enhance the plasticity of our method. Elaborate ablation studies and extensive comparisons demonstrate the effectiveness of our proposed method. Our results indicate that our method achieves state-of-the-art (SOTA) performance on several well-known continual learning benchmarks. For instance, on the Split CIFAR-100 dataset, our method shows a 6.35\\% improvement in accuracy and a 3.24\\% reduction in forgetting compared to previous methods. Our code is available at this https URL.', 'abstract_zh': '基于LoRA的持续学习：一种利用预训练模型进行下游持续学习任务的有前途的方法。尽管正交LoRA调优有效缓解了遗忘现象，但本研究揭示，在正交LoRA调优条件下，预任务的关键参数在学习新任务后仍有显著变化。为解决这一问题，我们直接提出在学习新任务之前，冻结Vision Transformer（ViT）中预任务的关键参数矩阵。除此之外，基于正交LoRA调优，我们提出了基于QR分解的LoRA组成（LoRAC），以进一步增强该方法的可塑性。详尽的消融研究和广泛比较表明我们提出方法的有效性。实验结果表明，我们的方法在多个知名持续学习基准上达到了最先进的性能。例如，在Split CIFAR-100数据集上，我们的方法在准确性和遗忘度方面分别相比以前的方法提高了6.35%和减少了3.24%。我们的代码可在以下链接获取：this https URL。', 'title_zh': '基于约束关键参数变化的LoRA驱动连续学习'}
{'arxiv_id': 'arXiv:2504.13406', 'title': 'LangCoop: Collaborative Driving with Language', 'authors': 'Xiangbo Gao, Yuheng Wu, Rujia Wang, Chenxi Liu, Yang Zhou, Zhengzhong Tu', 'link': 'https://arxiv.org/abs/2504.13406', 'abstract': 'Multi-agent collaboration holds great promise for enhancing the safety, reliability, and mobility of autonomous driving systems by enabling information sharing among multiple connected agents. However, existing multi-agent communication approaches are hindered by limitations of existing communication media, including high bandwidth demands, agent heterogeneity, and information loss. To address these challenges, we introduce LangCoop, a new paradigm for collaborative autonomous driving that leverages natural language as a compact yet expressive medium for inter-agent communication. LangCoop features two key innovations: Mixture Model Modular Chain-of-thought (M$^3$CoT) for structured zero-shot vision-language reasoning and Natural Language Information Packaging (LangPack) for efficiently packaging information into concise, language-based messages. Through extensive experiments conducted in the CARLA simulations, we demonstrate that LangCoop achieves a remarkable 96\\% reduction in communication bandwidth (< 2KB per message) compared to image-based communication, while maintaining competitive driving performance in the closed-loop evaluation.', 'abstract_zh': '基于自然语言的多智能体协同在增强自动驾驶安全性、可靠性和移动性方面的前景：LangCoop新范式通过紧凑且表达能力强的中介实现跨智能体通信', 'title_zh': 'LangCoop: 语言辅助协作驾驶'}
{'arxiv_id': 'arXiv:2504.13399', 'title': 'Towards a Multi-Agent Vision-Language System for Zero-Shot Novel Hazardous Object Detection for Autonomous Driving Safety', 'authors': 'Shashank Shriram, Srinivasa Perisetla, Aryan Keskar, Harsha Krishnaswamy, Tonko Emil Westerhof Bossen, Andreas Møgelmose, Ross Greer', 'link': 'https://arxiv.org/abs/2504.13399', 'abstract': "Detecting anomalous hazards in visual data, particularly in video streams, is a critical challenge in autonomous driving. Existing models often struggle with unpredictable, out-of-label hazards due to their reliance on predefined object categories. In this paper, we propose a multimodal approach that integrates vision-language reasoning with zero-shot object detection to improve hazard identification and explanation. Our pipeline consists of a Vision-Language Model (VLM), a Large Language Model (LLM), in order to detect hazardous objects within a traffic scene. We refine object detection by incorporating OpenAI's CLIP model to match predicted hazards with bounding box annotations, improving localization accuracy. To assess model performance, we create a ground truth dataset by denoising and extending the foundational COOOL (Challenge-of-Out-of-Label) anomaly detection benchmark dataset with complete natural language descriptions for hazard annotations. We define a means of hazard detection and labeling evaluation on the extended dataset using cosine similarity. This evaluation considers the semantic similarity between the predicted hazard description and the annotated ground truth for each video. Additionally, we release a set of tools for structuring and managing large-scale hazard detection datasets. Our findings highlight the strengths and limitations of current vision-language-based approaches, offering insights into future improvements in autonomous hazard detection systems. Our models, scripts, and data can be found at this https URL", 'abstract_zh': '在视觉数据中，特别是在视频流中检测异常危险是一个关键挑战，尤其是在自动驾驶领域。现有模型往往难以应对预定义对象类别之外的不可预测危险。本文提出了一种多模态方法，将视觉语言推理与零样本对象检测相结合，以提高危险识别和解释能力。我们的管道包括一个视觉语言模型（VLM）和一个大型语言模型（LLM），用于检测交通场景中的危险对象。通过结合OpenAI的CLIP模型来匹配预测的危险与边界框注释，我们改进了定位准确性。为了评估模型性能，我们通过去噪并扩展COOOL（Challenge-of-Out-of-Label）异常检测基准数据集，在扩展的数据集上创建了一个包含完整自然语言描述的地面真实数据集。我们使用余弦相似度定义了一种危险检测和标注评估方法，该方法考虑了每个视频中预测的危险描述与标注的地面真实之间的语义相似性。此外，我们还提供了一组工具，用于结构化和管理大规模的危险检测数据集。我们的研究结果突显了当前视觉语言方法的优势和局限性，并为未来的自主危险检测系统改进提供了洞见。我们的模型、脚本和数据可在以下网址找到。', 'title_zh': '面向自动驾驶安全的零样本新型危险物体检测多Agent视觉-语言系统研究'}
{'arxiv_id': 'arXiv:2504.13391', 'title': 'Cardiac MRI Semantic Segmentation for Ventricles and Myocardium using Deep Learning', 'authors': 'Racheal Mukisa, Arvind K. Bansal', 'link': 'https://arxiv.org/abs/2504.13391', 'abstract': 'Automated noninvasive cardiac diagnosis plays a critical role in the early detection of cardiac disorders and cost-effective clinical management. Automated diagnosis involves the automated segmentation and analysis of cardiac images. Precise delineation of cardiac substructures and extraction of their morphological attributes are essential for evaluating the cardiac function, and diagnosing cardiovascular disease such as cardiomyopathy, valvular diseases, abnormalities related to septum perforations, and blood-flow rate. Semantic segmentation labels the CMR image at the pixel level, and localizes its subcomponents to facilitate the detection of abnormalities, including abnormalities in cardiac wall motion in an aging heart with muscle abnormalities, vascular abnormalities, and valvular abnormalities. In this paper, we describe a model to improve semantic segmentation of CMR images. The model extracts edge-attributes and context information during down-sampling of the U-Net and infuses this information during up-sampling to localize three major cardiac structures: left ventricle cavity (LV); right ventricle cavity (RV); and LV myocardium (LMyo). We present an algorithm and performance results. A comparison of our model with previous leading models, using similarity metrics between actual image and segmented image, shows that our approach improves Dice similarity coefficient (DSC) by 2%-11% and lowers Hausdorff distance (HD) by 1.6 to 5.7 mm.', 'abstract_zh': '自动化无创心脏诊断在早期发现心脏疾病和成本有效的临床管理中发挥着关键作用。该论文描述了一种提高CMR图像语义分割的模型。该模型在U-Net下采样过程中提取边缘属性和上下文信息，并在上采样过程中注入这些信息以定位左心室腔（LV）、右心室腔（RV）和左心室心肌（LMyo）三大心脏结构。我们提供了一种算法及性能结果。与以前的领先模型相比，使用实际图像和分割图像之间的相似性指标比较显示，我们的方法提高了Dice相似系数（DSC）2%-11%，降低了Hausdorff距离（HD）1.6到5.7毫米。', 'title_zh': '基于深度学习的心脏MRI心室和心肌组织分割'}
{'arxiv_id': 'arXiv:2504.13376', 'title': 'Addressing the Minor-Embedding Problem in Quantum Annealing and Evaluating State-of-the-Art Algorithm Performance', 'authors': 'Aitor Gómez-Tejedor, Eneko Osaba, Esther Villar-Rodriguez', 'link': 'https://arxiv.org/abs/2504.13376', 'abstract': "This study addresses the minor-embedding problem, which involves mapping the variables of an Ising model onto a quantum annealing processor. The primary motivation stems from the observed performance disparity of quantum annealers when solving problems suited to the processor's architecture versus those with non-hardware-native topologies. Our research has two main objectives: i) to analyze the impact of embedding quality on the performance of D-Wave Systems quantum annealers, and ii) to evaluate the quality of the embeddings generated by Minorminer, an algorithm provided by D-Wave and widely recognized as the standard minor-embedding technique in the literature. Regarding the first objective, our experiments reveal a clear correlation between the average chain length of embeddings and the relative errors of the solutions sampled. This underscores the critical influence of embedding quality on quantum annealing performance. For the second objective, we focus on the Minorminer technique, assessing its capacity to embed problems, the quality of the embeddings produced, and the robustness of the results. We also compare its performance with Clique Embedding, another algorithm developed by D-Wave, which is deterministic and designed to embed fully connected Ising models into quantum annealing processors, serving as a worst-case scenario. The results demonstrate that there is significant room for improvement for Minorminer, as it has not consistently outperformed the worst-case scenario.", 'abstract_zh': '本研究探讨了Ising模型变量在量子退火处理器上的嵌入问题。研究的主要动机来自于量子退火器在解决适合其架构的问题时与非硬件本征拓扑问题之间的性能差异。本研究有两个主要目标：i) 分析嵌入质量对D-Wave Systems量子退火器性能的影响；ii) 评估由D-Wave提供的Minorminer算法生成的嵌入的质量，该算法被认为是文献中标准的小嵌入技术。针对第一个目标，我们的实验揭示了平均链长与所采样解的相对误差之间存在显著相关性，这突显了嵌入质量对量子退火性能的决定性影响。针对第二个目标，我们集中于Minorminer技术，评估其嵌入问题的能力、生成的嵌入的质量以及结果的稳健性，并将其性能与由D-Wave开发的另一种算法——确定性的Clique Embedding进行比较，后者被设计用于将完全连接的Ising模型嵌入量子退火处理器中，并作为最坏情况的基准。研究结果表明，Minorminer仍存在显著的改进空间，因为它并未一致地优于最坏情况基准。', 'title_zh': '解决量子退火中的次要嵌入问题及评估先进算法性能'}
{'arxiv_id': 'arXiv:2504.13375', 'title': 'Pricing AI Model Accuracy', 'authors': 'Nikhil Kumar', 'link': 'https://arxiv.org/abs/2504.13375', 'abstract': "This paper examines the market for AI models in which firms compete to provide accurate model predictions and consumers exhibit heterogeneous preferences for model accuracy. We develop a consumer-firm duopoly model to analyze how competition affects firms' incentives to improve model accuracy. Each firm aims to minimize its model's error, but this choice can often be suboptimal. Counterintuitively, we find that in a competitive market, firms that improve overall accuracy do not necessarily improve their profits. Rather, each firm's optimal decision is to invest further on the error dimension where it has a competitive advantage. By decomposing model errors into false positive and false negative rates, firms can reduce errors in each dimension through investments. Firms are strictly better off investing on their superior dimension and strictly worse off with investments on their inferior dimension. Profitable investments adversely affect consumers but increase overall welfare.", 'abstract_zh': '本文探讨了AI模型市场中，企业竞相提供准确模型预测，而消费者对模型准确性的偏好各异的情形。我们建立了一个消费者-企业寡头垄断模型，分析竞争如何影响企业提升模型准确性的动机。每家企业都旨在最小化其模型的误差，但这种选择往往并不是最优的。令人意外的是，在竞争市场上，提高整体准确性的企业并不一定能提高其利润。相反，每家企业最优的策略是在其具备竞争优势的误差维度上进一步投资。通过将模型误差分解为假阳性率和假阴性率，企业可以在每个维度上通过投资减少误差。企业只会对其优势维度进行投资而使自身获益，对劣势维度的投资则会使企业受损。有益的投资虽然损害了消费者的利益，但却增加了整体的福利。', 'title_zh': 'AI模型准确性的定价'}
{'arxiv_id': 'arXiv:2504.13371', 'title': 'The Impact of AI on the Cyber Offense-Defense Balance and the Character of Cyber Conflict', 'authors': 'Andrew J. Lohn', 'link': 'https://arxiv.org/abs/2504.13371', 'abstract': 'Unlike other domains of conflict, and unlike other fields with high anticipated risk from AI, the cyber domain is intrinsically digital with a tight feedback loop between AI training and cyber application. Cyber may have some of the largest and earliest impacts from AI, so it is important to understand how the cyber domain may change as AI continues to advance. Our approach reviewed the literature, collecting nine arguments that have been proposed for offensive advantage in cyber conflict and nine proposed arguments for defensive advantage. We include an additional forty-eight arguments that have been proposed to give cyber conflict and competition its character as collected separately by Healey, Jervis, and Nandrajog. We then consider how each of those arguments and propositions might change with varying degrees of AI advancement. We find that the cyber domain is too multifaceted for a single answer to whether AI will enhance offense or defense broadly. AI will improve some aspects, hinder others, and leave some aspects unchanged. We collect and present forty-four ways that we expect AI to impact the cyber offense-defense balance and the character of cyber conflict and competition.', 'abstract_zh': '不同于其他冲突领域，也不同于其他高预期风险的AI领域，网络领域本质上是数字化的，AI entren训练与网络应用之间存在紧密的反馈循环。网络领域可能最早和最深刻地受到AI的影响，因此，了解随着AI的不断进步网络领域可能会发生怎样的变化非常重要。我们的方法是回顾文献，收集了九个关于在网络冲突中取得进攻优势的论点，以及九个关于在网络冲突中取得防御优势的论点。我们还包括了Healey、Jervis和Nandrajog分别收集的额外四十八个论点，以赋予网络冲突和竞争其独特的特征。然后我们考虑在不同程度的AI进步下，每个论点和观点可能会发生怎样的变化。我们发现，网络领域过于复杂，无法用一个答案概括AI是否会普遍增强攻击或防御。AI将在某些方面改进，阻碍另一些方面，并使某些方面保持不变。我们收集并展示了预期的四十四种AI将如何影响网络攻防平衡以及网络冲突和竞争特点的方式。', 'title_zh': 'AI对网络攻防平衡及网络冲突特性的影响'}
{'arxiv_id': 'arXiv:2504.13368', 'title': 'An Optimal Discriminator Weighted Imitation Perspective for Reinforcement Learning', 'authors': 'Haoran Xu, Shuozhe Li, Harshit Sikchi, Scott Niekum, Amy Zhang', 'link': 'https://arxiv.org/abs/2504.13368', 'abstract': 'We introduce Iterative Dual Reinforcement Learning (IDRL), a new method that takes an optimal discriminator-weighted imitation view of solving RL. Our method is motivated by a simple experiment in which we find training a discriminator using the offline dataset plus an additional expert dataset and then performing discriminator-weighted behavior cloning gives strong results on various types of datasets. That optimal discriminator weight is quite similar to the learned visitation distribution ratio in Dual-RL, however, we find that current Dual-RL methods do not correctly estimate that ratio. In IDRL, we propose a correction method to iteratively approach the optimal visitation distribution ratio in the offline dataset given no addtional expert dataset. During each iteration, IDRL removes zero-weight suboptimal transitions using the learned ratio from the previous iteration and runs Dual-RL on the remaining subdataset. This can be seen as replacing the behavior visitation distribution with the optimized visitation distribution from the previous iteration, which theoretically gives a curriculum of improved visitation distribution ratios that are closer to the optimal discriminator weight. We verify the effectiveness of IDRL on various kinds of offline datasets, including D4RL datasets and more realistic corrupted demonstrations. IDRL beats strong Primal-RL and Dual-RL baselines in terms of both performance and stability, on all datasets.', 'abstract_zh': '迭代双强化学习（IDRL）：一种新的最优鉴别器加权模仿学习方法', 'title_zh': '最优判别器加权 imitation 角度的研究：强化学习中的应用'}
{'arxiv_id': 'arXiv:2504.13365', 'title': 'VLLFL: A Vision-Language Model Based Lightweight Federated Learning Framework for Smart Agriculture', 'authors': 'Long Li, Jiajia Li, Dong Chen, Lina Pu, Haibo Yao, Yanbo Huang', 'link': 'https://arxiv.org/abs/2504.13365', 'abstract': 'In modern smart agriculture, object detection plays a crucial role by enabling automation, precision farming, and monitoring of resources. From identifying crop health and pest infestations to optimizing harvesting processes, accurate object detection enhances both productivity and sustainability. However, training object detection models often requires large-scale data collection and raises privacy concerns, particularly when sensitive agricultural data is distributed across farms. To address these challenges, we propose VLLFL, a vision-language model-based lightweight federated learning framework (VLLFL). It harnesses the generalization and context-aware detection capabilities of the vision-language model (VLM) and leverages the privacy-preserving nature of federated learning. By training a compact prompt generator to boost the performance of the VLM deployed across different farms, VLLFL preserves privacy while reducing communication overhead. Experimental results demonstrate that VLLFL achieves 14.53% improvement in the performance of VLM while reducing 99.3% communication overhead. Spanning tasks from identifying a wide variety of fruits to detecting harmful animals in agriculture, the proposed framework offers an efficient, scalable, and privacy-preserving solution specifically tailored to agricultural applications.', 'abstract_zh': '基于视觉语言模型的轻量级联邦学习框架（VLLFL）：一种面向农业应用的高效、可扩展且保护隐私的解决方案', 'title_zh': 'VLLFL：基于视觉-语言模型的轻量级联邦学习框架在智能农业中的应用'}
{'arxiv_id': 'arXiv:2504.13351', 'title': 'Chain-of-Modality: Learning Manipulation Programs from Multimodal Human Videos with Vision-Language-Models', 'authors': 'Chen Wang, Fei Xia, Wenhao Yu, Tingnan Zhang, Ruohan Zhang, C. Karen Liu, Li Fei-Fei, Jie Tan, Jacky Liang', 'link': 'https://arxiv.org/abs/2504.13351', 'abstract': 'Learning to perform manipulation tasks from human videos is a promising approach for teaching robots. However, many manipulation tasks require changing control parameters during task execution, such as force, which visual data alone cannot capture. In this work, we leverage sensing devices such as armbands that measure human muscle activities and microphones that record sound, to capture the details in the human manipulation process, and enable robots to extract task plans and control parameters to perform the same task. To achieve this, we introduce Chain-of-Modality (CoM), a prompting strategy that enables Vision Language Models to reason about multimodal human demonstration data -- videos coupled with muscle or audio signals. By progressively integrating information from each modality, CoM refines a task plan and generates detailed control parameters, enabling robots to perform manipulation tasks based on a single multimodal human video prompt. Our experiments show that CoM delivers a threefold improvement in accuracy for extracting task plans and control parameters compared to baselines, with strong generalization to new task setups and objects in real-world robot experiments. Videos and code are available at this https URL', 'abstract_zh': '从人类视频学习执行操作任务是教机器人的一种有前景的方法。然而，许多操作任务在执行过程中需要更改控制参数，例如力，而仅凭视觉数据无法捕捉到这些信息。在这项工作中，我们利用臂环等传感设备测量人体肌肉活动以及录音设备记录声音，以捕捉人类操作过程中的细节，并使机器人能够提取任务计划和控制参数以完成相同任务。为此，我们引入了一种模态链（Chain-of-Modality，CoM）的提示策略，该策略使视觉语言模型能够推理多模态的人类示范数据——视频结合肌肉或音频信号。通过逐步整合不同模态的信息，CoM细化任务计划并生成详细的控制参数，从而使机器人能够基于单一的多模态人类视频提示执行操作任务。我们的实验表明，与基线方法相比，CoM在提取任务计划和控制参数方面提高了三倍准确性，并且在真实世界机器人实验中对新任务设置和对象具有较强的泛化能力。相关视频和代码可在此链接获取。', 'title_zh': '模态链：基于多模态人类视频的学习操作程序方法'}
{'arxiv_id': 'arXiv:2504.13344', 'title': 'Adaptive AI decision interface for autonomous electronic material discovery', 'authors': 'Yahao Dai, Henry Chan, Aikaterini Vriza, Fredrick Kim, Yunfei Wang, Wei Liu, Naisong Shan, Jing Xu, Max Weires, Yukun Wu, Zhiqiang Cao, C. Suzanne Miller, Ralu Divan, Xiaodan Gu, Chenhui Zhu, Sihong Wang, Jie Xu', 'link': 'https://arxiv.org/abs/2504.13344', 'abstract': 'AI-powered autonomous experimentation (AI/AE) can accelerate materials discovery but its effectiveness for electronic materials is hindered by data scarcity from lengthy and complex design-fabricate-test-analyze cycles. Unlike experienced human scientists, even advanced AI algorithms in AI/AE lack the adaptability to make informative real-time decisions with limited datasets. Here, we address this challenge by developing and implementing an AI decision interface on our AI/AE system. The central element of the interface is an AI advisor that performs real-time progress monitoring, data analysis, and interactive human-AI collaboration for actively adapting to experiments in different stages and types. We applied this platform to an emerging type of electronic materials-mixed ion-electron conducting polymers (MIECPs) -- to engineer and study the relationships between multiscale morphology and properties. Using organic electrochemical transistors (OECT) as the testing-bed device for evaluating the mixed-conducting figure-of-merit -- the product of charge-carrier mobility and the volumetric capacitance ({\\mu}C*), our adaptive AI/AE platform achieved a 150% increase in {\\mu}C* compared to the commonly used spin-coating method, reaching 1,275 F cm-1 V-1 s-1 in just 64 autonomous experimental trials. A study of 10 statistically selected samples identifies two key structural factors for achieving higher volumetric capacitance: larger crystalline lamellar spacing and higher specific surface area, while also uncovering a new polymer polymorph in this material.', 'abstract_zh': '基于AI的自主实验（AI/AE）可加速材料发现，但其在电子材料领域的有效性受限于 lengthy 和复杂的设计-制造-测试-分析循环导致的数据稀缺性。与经验丰富的科研人员不同，即使在AI/AE中，最先进的AI算法也无法在数据量有限的情况下做出有信息性的实时决策。为此，我们开发并实现了一个AI决策界面，该界面的核心是实时进行进程监控、数据解析和人机交互协作的AI顾问，以根据不同阶段和类型的实验进行主动适应。我们将该平台应用于一种新兴的电子材料——混合离子-电子导电聚合物（MIECPs），以工程化并研究多尺度形态与性能之间的关系。通过使用有机电化学晶体管（OECT）作为评估混合传导电学性能（电荷载流子迁移率与体积电容的乘积，μC*）的方法学测试设备，我们的自适应AI/AE平台在64次自主实验中实现了μC*值150%的提升，达到1,275 F cm-1 V-1 s-1。通过对10个统计选择样本的研究，我们发现实现更高体积电容的两个关键结构因素是较大的结晶板状间距和更高的比表面积，同时揭示了该材料中的一种新的聚合物晶型。', 'title_zh': '自适应人工智能决策接口在自主电子材料发现中的应用'}
{'arxiv_id': 'arXiv:2504.13340', 'title': 'Putting the Segment Anything Model to the Test with 3D Knee MRI -- A Comparison with State-of-the-Art Performance', 'authors': 'Oliver Mills, Philip Conaghan, Nishant Ravikumar, Samuel Relton', 'link': 'https://arxiv.org/abs/2504.13340', 'abstract': 'Menisci are cartilaginous tissue found within the knee that contribute to joint lubrication and weight dispersal. Damage to menisci can lead to onset and progression of knee osteoarthritis (OA), a condition that is a leading cause of disability, and for which there are few effective therapies. Accurate automated segmentation of menisci would allow for earlier detection and treatment of meniscal abnormalities, as well as shedding more light on the role the menisci play in OA pathogenesis. Focus in this area has mainly used variants of convolutional networks, but there has been no attempt to utilise recent large vision transformer segmentation models. The Segment Anything Model (SAM) is a so-called foundation segmentation model, which has been found useful across a range of different tasks due to the large volume of data used for training the model. In this study, SAM was adapted to perform fully-automated segmentation of menisci from 3D knee magnetic resonance images. A 3D U-Net was also trained as a baseline. It was found that, when fine-tuning only the decoder, SAM was unable to compete with 3D U-Net, achieving a Dice score of $0.81\\pm0.03$, compared to $0.87\\pm0.03$, on a held-out test set. When fine-tuning SAM end-to-end, a Dice score of $0.87\\pm0.03$ was achieved. The performance of both the end-to-end trained SAM configuration and the 3D U-Net were comparable to the winning Dice score ($0.88\\pm0.03$) in the IWOAI Knee MRI Segmentation Challenge 2019. Performance in terms of the Hausdorff Distance showed that both configurations of SAM were inferior to 3D U-Net in matching the meniscus morphology. Results demonstrated that, despite its generalisability, SAM was unable to outperform a basic 3D U-Net in meniscus segmentation, and may not be suitable for similar 3D medical image segmentation tasks also involving fine anatomical structures with low contrast and poorly-defined boundaries.', 'abstract_zh': '半月板是存在于膝关节内的软骨组织，对关节润滑和重量分散有贡献。半月板损伤可能导致骨关节炎（OA）的发生和发展，而OA是导致残疾的主要原因之一，治疗选择有限。准确的自动化半月板分割能够实现早期检测和治疗半月板异常，同时有助于更深入地了解半月板在OA发病机制中的作用。目前该领域的研究主要使用卷积网络的变种，但尚未尝试利用大规模视觉Transformer分割模型。Segment Anything Model (SAM) 是一种所谓的基础分割模型，由于其训练数据量大，已被发现适用于多种不同的任务。在本研究中，SAM 被适应用于从3D膝关节磁共振成像中自动分割半月板。还训练了一个3D U-Net作为基准模型。研究发现，仅微调SAM解码器时，其Dice分数为$0.81\\pm0.03$，低于3D U-Net的$0.87\\pm0.03$。完全微调SAM时，其Dice分数达到$0.87\\pm0.03$。端到端训练的SAM配置和3D U-Net的表现与2019年IWOAI膝关节MRI分割挑战赛的获胜Dice分数($0.88\\pm0.03$)相当。根据Hausdorff距离衡量的性能表明，两种SAM配置均不如3D U-Net在匹配半月板形态方面表现优异。结果表明，尽管具有普适性，SAM无法在半月板分割中优于基本的3D U-Net，可能不适合涉及细小解剖结构、对比度低和边界定义差的3D医学图像分割任务。', 'title_zh': '用3D膝关节MRI检验Segment Anything模型——与现有最佳性能的比较'}
{'arxiv_id': 'arXiv:2504.13310', 'title': 'SAR Object Detection with Self-Supervised Pretraining and Curriculum-Aware Sampling', 'authors': 'Yasin Almalioglu, Andrzej Kucik, Geoffrey French, Dafni Antotsiou, Alexander Adam, Cedric Archambeau', 'link': 'https://arxiv.org/abs/2504.13310', 'abstract': "Object detection in satellite-borne Synthetic Aperture Radar (SAR) imagery holds immense potential in tasks such as urban monitoring and disaster response. However, the inherent complexities of SAR data and the scarcity of annotations present significant challenges in the advancement of object detection in this domain. Notably, the detection of small objects in satellite-borne SAR images poses a particularly intricate problem, because of the technology's relatively low spatial resolution and inherent noise. Furthermore, the lack of large labelled SAR datasets hinders the development of supervised deep learning-based object detection models. In this paper, we introduce TRANSAR, a novel self-supervised end-to-end vision transformer-based SAR object detection model that incorporates masked image pre-training on an unlabeled SAR image dataset that spans more than $25,700$ km\\textsuperscript{2} ground area. Unlike traditional object detection formulation, our approach capitalises on auxiliary binary semantic segmentation, designed to segregate objects of interest during the post-tuning, especially the smaller ones, from the background. In addition, to address the innate class imbalance due to the disproportion of the object to the image size, we introduce an adaptive sampling scheduler that dynamically adjusts the target class distribution during training based on curriculum learning and model feedback. This approach allows us to outperform conventional supervised architecture such as DeepLabv3 or UNet, and state-of-the-art self-supervised learning-based arhitectures such as DPT, SegFormer or UperNet, as shown by extensive evaluations on benchmark SAR datasets.", 'abstract_zh': '卫星搭载合成孔径雷达（SAR）图像中的目标检测在城市监控和灾害响应任务中具有巨大的潜力。然而，SAR数据的固有复杂性和标注数据的稀缺性为该领域的目标检测进步带来了重大挑战。值得注意的是，由于技术的相对低空间分辨率和固有的噪声，小目标在卫星搭载SAR图像中的检测尤为复杂。此外，缺乏大型标注SAR数据集阻碍了基于监督深度学习的目标检测模型的发展。在本文中，我们提出了一种名为TRANSAR的新型自监督端到端视觉变压器SAR目标检测模型，该模型在超过25700平方公里地表区域的未标注SAR图像数据集上进行了掩码图像预训练。与传统的对象检测框架不同，我们的方法利用辅助二元语义分割，在调整过程中特别有助于分离感兴趣的对象（尤其是较小的对象）与背景。此外，为了应对对象与图像比例失衡导致的固有类别不平衡，我们引入了一种自适应采样调度器，在训练过程中根据课程学习和模型反馈动态调整目标类分布。该方法在基准SAR数据集上广泛评估中表现出色，优于传统的监督架构如DeepLabv3或UNet，以及最先进的自监督学习架构如DPT、SegFormer或UperNet。', 'title_zh': '基于自监督预训练和课程意识采样的SAR目标检测'}
{'arxiv_id': 'arXiv:2504.13296', 'title': 'Enhanced Pruning Strategy for Multi-Component Neural Architectures Using Component-Aware Graph Analysis', 'authors': 'Ganesh Sundaram, Jonas Ulmen, Daniel Görges', 'link': 'https://arxiv.org/abs/2504.13296', 'abstract': 'Deep neural networks (DNNs) deliver outstanding performance, but their complexity often prohibits deployment in resource-constrained settings. Comprehensive structured pruning frameworks based on parameter dependency analysis reduce model size with specific regard to computational performance. When applying them to Multi-Component Neural Architectures (MCNAs), they risk network integrity by removing large parameter groups. We introduce a component-aware pruning strategy, extending dependency graphs to isolate individual components and inter-component flows. This creates smaller, targeted pruning groups that conserve functional integrity. Demonstrated effectively on a control task, our approach achieves greater sparsity and reduced performance degradation, opening a path for optimizing complex, multi-component DNNs efficiently.', 'abstract_zh': '基于组件感知的剪枝策略：扩展依赖图以隔离个体组件和组件间流以优化复杂多组件深度神经网络', 'title_zh': '基于组件感知图分析的多组件神经架构增强剪枝策略'}
{'arxiv_id': 'arXiv:2504.13277', 'title': 'Interpersonal Theory of Suicide as a Lens to Examine Suicidal Ideation in Online Spaces', 'authors': 'Soorya Ram Shimgekar, Violeta J. Rodriguez, Paul A. Bloom, Dong Whi Yoo, Koustuv Saha', 'link': 'https://arxiv.org/abs/2504.13277', 'abstract': "Suicide is a critical global public health issue, with millions experiencing suicidal ideation (SI) each year. Online spaces enable individuals to express SI and seek peer support. While prior research has revealed the potential of detecting SI using machine learning and natural language analysis, a key limitation is the lack of a theoretical framework to understand the underlying factors affecting high-risk suicidal intent. To bridge this gap, we adopted the Interpersonal Theory of Suicide (IPTS) as an analytic lens to analyze 59,607 posts from Reddit's r/SuicideWatch, categorizing them into SI dimensions (Loneliness, Lack of Reciprocal Love, Self Hate, and Liability) and risk factors (Thwarted Belongingness, Perceived Burdensomeness, and Acquired Capability of Suicide). We found that high-risk SI posts express planning and attempts, methods and tools, and weaknesses and pain. In addition, we also examined the language of supportive responses through psycholinguistic and content analyses to find that individuals respond differently to different stages of Suicidal Ideation (SI) posts. Finally, we explored the role of AI chatbots in providing effective supportive responses to suicidal ideation posts. We found that although AI improved structural coherence, expert evaluations highlight persistent shortcomings in providing dynamic, personalized, and deeply empathetic support. These findings underscore the need for careful reflection and deeper understanding in both the development and consideration of AI-driven interventions for effective mental health support.", 'abstract_zh': '自杀是全球一个关键的公共卫生问题，每年有数百万人经历自杀意念（SI）。在线空间使个体能够表达自杀意念并寻求同侪支持。虽然 predecessors 的研究揭示了利用机器学习和自然语言分析检测自杀意念的潜力，但关键的限制在于缺乏一个理论框架来理解影响高风险自杀意图的潜在因素。为了弥合这一差距，我们采用《人际理论》（Interpersonal Theory of Suicide, IPTS）作为分析视角，分析了来自 Reddit 的 r/SuicideWatch 59,607 条帖子，将其分为自杀意念维度（孤独、缺乏相互关爱、自我憎恨和易感性）和风险因素（挫折感归属、被感知为负担、自杀能力的获得）。我们发现，高风险的自杀意念帖子表达了计划和尝试、方法和工具、以及弱点和痛苦。此外，我们还通过心理语言学和内容分析检查了支持性回应的语言，发现个体对不同的自杀意念（SI）帖子阶段的回应方式不同。最后，我们探讨了人工智能聊天机器人在提供有效的自杀意念帖子支持中的作用。我们的研究发现虽然人工智能提高了结构连贯性，但专家评估指出，在提供动态、个性化和深层次同理心支持方面仍存在持续的不足。这些发现强调了在开发和考虑人工智能驱动的干预措施以提供有效精神健康支持时需要仔细反思和深入理解的重要性。', 'title_zh': '人际理论视角下的自杀意念在线空间考察'}
{'arxiv_id': 'arXiv:2504.13261', 'title': 'CPG-EVAL: A Multi-Tiered Benchmark for Evaluating the Chinese Pedagogical Grammar Competence of Large Language Models', 'authors': 'Dong Wang', 'link': 'https://arxiv.org/abs/2504.13261', 'abstract': "Purpose: The rapid emergence of large language models (LLMs) such as ChatGPT has significantly impacted foreign language education, yet their pedagogical grammar competence remains under-assessed. This paper introduces CPG-EVAL, the first dedicated benchmark specifically designed to evaluate LLMs' knowledge of pedagogical grammar within the context of foreign language instruction. Methodology: The benchmark comprises five tasks designed to assess grammar recognition, fine-grained grammatical distinction, categorical discrimination, and resistance to linguistic interference. Findings: Smaller-scale models can succeed in single language instance tasks, but struggle with multiple instance tasks and interference from confusing instances. Larger-scale models show better resistance to interference but still have significant room for accuracy improvement. The evaluation indicates the need for better instructional alignment and more rigorous benchmarks, to effectively guide the deployment of LLMs in educational contexts. Value: This study offers the first specialized, theory-driven, multi-tiered benchmark framework for systematically evaluating LLMs' pedagogical grammar competence in Chinese language teaching contexts. CPG-EVAL not only provides empirical insights for educators, policymakers, and model developers to better gauge AI's current abilities in educational settings, but also lays the groundwork for future research on improving model alignment, enhancing educational suitability, and ensuring informed decision-making concerning LLM integration in foreign language instruction.", 'abstract_zh': '目的：快速涌现的大规模语言模型（LLMs）如ChatGPT极大地影响了外语教育，然而它们的教学语法能力尚未得到充分评估。本文介绍了CPG-EVAL，这是首个专门设计来评估LLMs在外语教学环境中对教学语法知识掌握情况的基准。方法：基准包括五项任务，用于评估语法识别、精细的语法区分、类别区分以及抵抗语言干扰的能力。发现：较小规模的模型在单语言实例任务中可以成功，但在涉及多个实例的任务和干扰实例时表现出困难。较大的模型在抵抗干扰方面表现更好，但仍然存在显著的准确度提升空间。评估表明需要更好的教学对齐和更严格的基准，以有效指导LLMs在教育环境中的应用。价值：本研究提供了首个专门的、理论驱动的多层次基准框架，系统评估LLMs在中文教学环境中的教学语法能力。CPG-EVAL不仅为教育者、政策制定者和模型开发者提供了实证见解，以更好地评估AI在教育环境中的当前能力，还为未来提高模型对齐、增强教育适用性和确保关于LLMs在外语教学中集成的知情决策奠定了基础。', 'title_zh': 'CPG- EVAL：评估大型语言模型中文教学语法能力的多层级基准'}
{'arxiv_id': 'arXiv:2504.13241', 'title': 'Recursive Deep Inverse Reinforcement Learning', 'authors': 'Paul Ghanem, Michael Potter, Owen Howell, Pau Closas, Alireza Ramezani, Deniz Erdogmus, Robert Platt, Tales Imbiriba', 'link': 'https://arxiv.org/abs/2504.13241', 'abstract': "Inferring an adversary's goals from exhibited behavior is crucial for counterplanning and non-cooperative multi-agent systems in domains like cybersecurity, military, and strategy games. Deep Inverse Reinforcement Learning (IRL) methods based on maximum entropy principles show promise in recovering adversaries' goals but are typically offline, require large batch sizes with gradient descent, and rely on first-order updates, limiting their applicability in real-time scenarios. We propose an online Recursive Deep Inverse Reinforcement Learning (RDIRL) approach to recover the cost function governing the adversary actions and goals. Specifically, we minimize an upper bound on the standard Guided Cost Learning (GCL) objective using sequential second-order Newton updates, akin to the Extended Kalman Filter (EKF), leading to a fast (in terms of convergence) learning algorithm. We demonstrate that RDIRL is able to recover cost and reward functions of expert agents in standard and adversarial benchmark tasks. Experiments on benchmark tasks show that our proposed approach outperforms several leading IRL algorithms.", 'abstract_zh': '从对手行为推断其目标的深度递归逆强化学习方法对于网络安全、军事和策略游戏等领域中的反制规划和非合作多智能体系统至关重要。基于最大熵原则的深度逆强化学习方法显示出从对手行为恢复其目标的潜力，但这些方法通常是离线的、需要大批量梯度下降更新，并依赖于一阶更新，限制了其在实时场景中的应用。我们提出了一种在线递归深度逆强化学习（RDIRL）方法来恢复指导对手行为和目标的成本函数。具体而言，我们通过顺序二次牛顿更新最小化标准引导成本学习（GCL）目标的标准上界，类似于扩展卡尔曼滤波器（EKF），从而得到一种快速收敛的学习算法。实验结果表明，RDIRL能够在标准和对抗基准任务中恢复专家智能体的成本和奖励函数。在基准任务上的实验表明，我们提出的方法优于几种领先的逆强化学习算法。', 'title_zh': '递归深度逆强化学习'}
{'arxiv_id': 'arXiv:2504.13234', 'title': 'Non-Uniform Class-Wise Coreset Selection: Characterizing Category Difficulty for Data-Efficient Transfer Learning', 'authors': 'Hanyu Zhang, Zhen Xing, Wenxuan Yang, Chenxi Ma, Weimin Tan, Bo Yan', 'link': 'https://arxiv.org/abs/2504.13234', 'abstract': "As transfer learning models and datasets grow larger, efficient adaptation and storage optimization have become critical needs. Coreset selection addresses these challenges by identifying and retaining the most informative samples, constructing a compact subset for target domain training. However, current methods primarily rely on instance-level difficulty assessments, overlooking crucial category-level characteristics and consequently under-representing minority classes. To overcome this limitation, we propose Non-Uniform Class-Wise Coreset Selection (NUCS), a novel framework that integrates both class-level and instance-level criteria. NUCS automatically allocates data selection budgets for each class based on intrinsic category difficulty and adaptively selects samples within optimal difficulty ranges. By explicitly incorporating category-specific insights, our approach achieves a more balanced and representative coreset, addressing key shortcomings of prior methods. Comprehensive theoretical analysis validates the rationale behind adaptive budget allocation and sample selection, while extensive experiments across 14 diverse datasets and model architectures demonstrate NUCS's consistent improvements over state-of-the-art methods, achieving superior accuracy and computational efficiency. Notably, on CIFAR100 and Food101, NUCS matches full-data training accuracy while retaining just 30% of samples and reducing computation time by 60%. Our work highlights the importance of characterizing category difficulty in coreset selection, offering a robust and data-efficient solution for transfer learning.", 'abstract_zh': '基于类别和实例准则的非均匀类别级核心样本选择（NUCS）', 'title_zh': '非均匀类别自举选择：表征数据高效迁移学习中的类别难度'}
{'arxiv_id': 'arXiv:2504.13231', 'title': 'WildFireCan-MMD: A Multimodal dataset for Classification of User-generated Content During Wildfires in Canada', 'authors': 'Braeden Sherritt, Isar Nejadgholi, Marzieh Amini', 'link': 'https://arxiv.org/abs/2504.13231', 'abstract': 'Rapid information access is vital during wildfires, yet traditional data sources are slow and costly. Social media offers real-time updates, but extracting relevant insights remains a challenge. We present WildFireCan-MMD, a new multimodal dataset of X posts from recent Canadian wildfires, annotated across 13 key themes. Evaluating both Vision Language Models and custom-trained classifiers, we show that while zero-shot prompting offers quick deployment, even simple trained models outperform them when labelled data is available, by up to 23%. Our findings highlight the enduring importance of tailored datasets and task-specific training. Importantly, such datasets should be localized, as disaster response requirements vary across regions and contexts.', 'abstract_zh': '快速信息获取对于野火期间至关重要，但传统数据源速度慢且成本高。社交媒体能够提供实时更新，但提取相关洞见仍然具有挑战性。我们呈现了WildFireCan-MMD，这是一个包含加拿大最近野火相关多模态数据集，涵盖了13个关键主题，并进行了标注。评估视觉语言模型和自定义训练的分类器后，我们发现即使在有标注数据时，简单的训练模型的表现也比零样本提示高出23%以上。我们的研究结果强调了定制化数据集和任务特定训练的持久重要性。重要的是，这样的数据集应该是本地化的，因为灾害响应要求在不同地区和背景下有所不同。', 'title_zh': 'WildFireCan-MMD：加拿大 wildfire期间用户生成内容分类的多模态数据集'}
{'arxiv_id': 'arXiv:2504.13227', 'title': 'DIDS: Domain Impact-aware Data Sampling for Large Language Model Training', 'authors': 'Weijie Shi, Jipeng Zhang, Yaguang Wu, Jingzhi Fang, Ruiyuan Zhang, Jiajie Xu, Jia Zhu, Hao Chen, Yao Zhao, Sirui Han, Xiaofang Zhou', 'link': 'https://arxiv.org/abs/2504.13227', 'abstract': "Large language models (LLMs) are commonly trained on multi-domain datasets, where domain sampling strategies significantly impact model performance due to varying domain importance across downstream tasks. Existing approaches for optimizing domain-level sampling strategies struggle with maintaining intra-domain consistency and accurately measuring domain impact. In this paper, we present Domain Impact-aware Data Sampling (DIDS). To ensure intra-domain consistency, a gradient clustering algorithm is proposed to group training data based on their learning effects, where a proxy language model and dimensionality reduction are employed to reduce computational overhead. To accurately measure domain impact, we develop a Fisher Information Matrix (FIM) guided metric that quantifies how domain-specific parameter updates affect the model's output distributions on downstream tasks, with theoretical guarantees. Furthermore, to determine optimal sampling ratios, DIDS combines both the FIM-guided domain impact assessment and loss learning trajectories that indicate domain-specific potential, while accounting for diminishing marginal returns. Extensive experiments demonstrate that DIDS achieves 3.4% higher average performance while maintaining comparable training efficiency.", 'abstract_zh': '基于领域影响的数据采样（DIDS）：确保领域一致性并准确衡量领域影响的策略', 'title_zh': 'DIDS: 域影响感知的数据采样用于大型语言模型训练'}
{'arxiv_id': 'arXiv:2504.13224', 'title': 'ICAS: IP Adapter and ControlNet-based Attention Structure for Multi-Subject Style Transfer Optimization', 'authors': 'Fuwei Liu', 'link': 'https://arxiv.org/abs/2504.13224', 'abstract': 'Generating multi-subject stylized images remains a significant challenge due to the ambiguity in defining style attributes (e.g., color, texture, atmosphere, and structure) and the difficulty in consistently applying them across multiple subjects. Although recent diffusion-based text-to-image models have achieved remarkable progress, existing methods typically rely on computationally expensive inversion procedures or large-scale stylized datasets. Moreover, these methods often struggle with maintaining multi-subject semantic fidelity and are limited by high inference costs. To address these limitations, we propose ICAS (IP-Adapter and ControlNet-based Attention Structure), a novel framework for efficient and controllable multi-subject style transfer. Instead of full-model tuning, ICAS adaptively fine-tunes only the content injection branch of a pre-trained diffusion model, thereby preserving identity-specific semantics while enhancing style controllability. By combining IP-Adapter for adaptive style injection with ControlNet for structural conditioning, our framework ensures faithful global layout preservation alongside accurate local style synthesis. Furthermore, ICAS introduces a cyclic multi-subject content embedding mechanism, which enables effective style transfer under limited-data settings without the need for extensive stylized corpora. Extensive experiments show that ICAS achieves superior performance in structure preservation, style consistency, and inference efficiency, establishing a new paradigm for multi-subject style transfer in real-world applications.', 'abstract_zh': '基于IP-Adapter和ControlNet注意力结构的高效可控多主体风格转换', 'title_zh': 'ICAS：基于IP适配器和ControlNet的多主题风格转换优化注意力结构'}
{'arxiv_id': 'arXiv:2504.13219', 'title': 'Scaling Laws for Data-Efficient Visual Transfer Learning', 'authors': 'Wenxuan Yang, Qingqu Wei, Chenxi Ma, Weimin Tan, Bo Yan', 'link': 'https://arxiv.org/abs/2504.13219', 'abstract': 'Current scaling laws for visual AI models focus predominantly on large-scale pretraining, leaving a critical gap in understanding how performance scales for data-constrained downstream tasks. To address this limitation, this paper establishes the first practical framework for data-efficient scaling laws in visual transfer learning, addressing two fundamental questions: 1) How do scaling behaviors shift when downstream tasks operate with limited data? 2) What governs the efficacy of knowledge distillation under such constraints? Through systematic analysis of vision tasks across data regimes (1K-1M samples), we propose the distillation boundary theory, revealing a critical turning point in distillation efficiency: 1) Distillation superiority: In data-scarce conditions, distilled models significantly outperform their non-distillation counterparts, efficiently leveraging inherited knowledge to compensate for limited training samples. 2) Pre-training dominance: As pre-training data increases beyond a critical threshold, non-distilled models gradually surpass distilled versions, suggesting diminishing returns from knowledge inheritance when sufficient task-specific data becomes available. Empirical validation across various model scales (2.5M to 38M parameters) and data volumes demonstrate these performance inflection points, with error difference curves transitioning from positive to negative values at critical data thresholds, confirming our theoretical predictions. This work redefines scaling laws for data-limited regimes, bridging the knowledge gap between large-scale pretraining and practical downstream adaptation, addressing a critical barrier to understanding vision model scaling behaviors and optimizing computational resource allocation.', 'abstract_zh': '当前视觉AI模型的缩放规律主要集中在大规模预训练上，忽略了在数据受限的下游任务中性能缩放的理解。为解决这一限制，本文建立了首个数据高效缩放定律的实用框架，探讨了两个基本问题：1）当下游任务数据受限时，缩放行为如何变化？2）在这些约束条件下，知识蒸馏的有效性受哪些因素支配？通过系统分析不同数据集规模（1K-1M样本）下的视觉任务，我们提出了蒸馏边界理论，揭示了蒸馏效率的关键转折点：1）蒸馏优越性：在数据稀缺条件下，蒸馏模型显著优于非蒸馏模型，有效利用继承的知识来弥补有限的训练样本。2）预训练主导：随着预训练数据超过一定阈值，非蒸馏模型逐渐超越蒸馏版本，表明当有足够的任务特定数据时，知识继承的益处会逐渐减弱。在不同模型规模（2.5M至38M参数）和数据量下的实验证明了这些性能转折点，在关键数据阈值处误差差异曲线从正值转变为负值，验证了我们的理论预测。本研究重新定义了数据受限条件下缩放定律，填补了大规模预训练与实际下游适应之间知识空白，解决了理解视觉模型缩放行为和优化计算资源分配的关键障碍。', 'title_zh': '数据高效视觉迁移学习的标度律'}
{'arxiv_id': 'arXiv:2504.13218', 'title': 'Harmony: A Unified Framework for Modality Incremental Learning', 'authors': 'Yaguang Song, Xiaoshan Yang, Dongmei Jiang, Yaowei Wang, Changsheng Xu', 'link': 'https://arxiv.org/abs/2504.13218', 'abstract': 'Incremental learning aims to enable models to continuously acquire knowledge from evolving data streams while preserving previously learned capabilities. While current research predominantly focuses on unimodal incremental learning and multimodal incremental learning where the modalities are consistent, real-world scenarios often present data from entirely new modalities, posing additional challenges. This paper investigates the feasibility of developing a unified model capable of incremental learning across continuously evolving modal sequences. To this end, we introduce a novel paradigm called Modality Incremental Learning (MIL), where each learning stage involves data from distinct modalities. To address this task, we propose a novel framework named Harmony, designed to achieve modal alignment and knowledge retention, enabling the model to reduce the modal discrepancy and learn from a sequence of distinct modalities, ultimately completing tasks across multiple modalities within a unified framework. Our approach introduces the adaptive compatible feature modulation and cumulative modal bridging. Through constructing historical modal features and performing modal knowledge accumulation and alignment, the proposed components collaboratively bridge modal differences and maintain knowledge retention, even with solely unimodal data available at each learning this http URL components work in concert to establish effective modality connections and maintain knowledge retention, even when only unimodal data is available at each learning stage. Extensive experiments on the MIL task demonstrate that our proposed method significantly outperforms existing incremental learning methods, validating its effectiveness in MIL scenarios.', 'abstract_zh': '增量学习旨在使模型能够从不断演变的数据流中持续获取知识，同时保留已学能力。当前研究主要集中在单一模态增量学习和模态一致的多模态增量学习上，而现实世界场景中经常出现全新的模态数据，带来了额外的挑战。本文探讨了开发能够在连续演变模态序列上实现增量学习的统一模型的可能性。为此，我们提出了一种新型范式称为模态增量学习（MIL），每个学习阶段涉及不同的模态数据。为了解决这一任务，我们提出了一种名为Harmony的新框架，旨在实现模态对齐和知识保留，从而使模型能够减少模态差异并从一系列不同的模态数据中学习，最终在一个统一框架中完成多模态任务。我们的方法引入了自适应兼容特征调制和累积模态连接。通过构建历史模态特征并进行模态知识积累和对齐，所提出组件协同作用以弥合模态差异并保持知识保留，即使在每个学习阶段仅有一模态数据可用的情况下也是如此。各组件在各学习阶段配合工作，以建立有效的模态连接并保持知识保留，即使仅在每个学习阶段有单一模态数据可用也能达到这一效果。在MIL任务上的广泛实验表明，我们提出的方法显著优于现有增量学习方法，验证了其在MIL场景中的有效性。', 'title_zh': '和谐：一个统一的多模态增量学习框架'}
{'arxiv_id': 'arXiv:2504.13217', 'title': 'Sustainability via LLM Right-sizing', 'authors': 'Jennifer Haase, Finn Klessascheck, Jan Mendling, Sebastian Pokutta', 'link': 'https://arxiv.org/abs/2504.13217', 'abstract': 'Large language models (LLMs) have become increasingly embedded in organizational workflows. This has raised concerns over their energy consumption, financial costs, and data sovereignty. While performance benchmarks often celebrate cutting-edge models, real-world deployment decisions require a broader perspective: when is a smaller, locally deployable model "good enough"? This study offers an empirical answer by evaluating eleven proprietary and open-weight LLMs across ten everyday occupational tasks, including summarizing texts, generating schedules, and drafting emails and proposals. Using a dual-LLM-based evaluation framework, we automated task execution and standardized evaluation across ten criteria related to output quality, factual accuracy, and ethical responsibility. Results show that GPT-4o delivers consistently superior performance but at a significantly higher cost and environmental footprint. Notably, smaller models like Gemma-3 and Phi-4 achieved strong and reliable results on most tasks, suggesting their viability in contexts requiring cost-efficiency, local deployment, or privacy. A cluster analysis revealed three model groups -- premium all-rounders, competent generalists, and limited but safe performers -- highlighting trade-offs between quality, control, and sustainability. Significantly, task type influenced model effectiveness: conceptual tasks challenged most models, while aggregation and transformation tasks yielded better performances. We argue for a shift from performance-maximizing benchmarks to task- and context-aware sufficiency assessments that better reflect organizational priorities. Our approach contributes a scalable method to evaluate AI models through a sustainability lens and offers actionable guidance for responsible LLM deployment in practice.', 'abstract_zh': '大型语言模型（LLMs）在组织工作流程中的应用日益普遍。这引发了对其能源消耗、财务成本和数据主权的关注。尽管性能基准往往强调顶尖模型的表现，但真正的部署决策需要更广泛的考量：何时采用较小规模且可本地部署的模型足够好？本研究通过评估十一种专有和开源的大规模语言模型在十项日常生活职业任务中的表现，提供了一个实证答案，包括文本摘要、生成日程、撰写邮件和提案。基于双大规模语言模型的评价框架，我们自动化了任务执行，并在输出质量、事实准确性和伦理责任感等十个标准方面实现了标准化评价。结果显示，GPT-4o在所有标准上表现优异，但成本和环境影响显著更高。值得注意的是，如Gemma-3和Phi-4这样的较小模型在大多数任务中实现了强有力且可靠的结果，这表明它们在需要成本效率、本地部署或隐私保护的情境中具备可行性。聚类分析揭示了三个模型组——高端全才、称职的通用者以及有限但安全的表现者——突显了质量、控制和可持续性之间的权衡。重要的是，任务类型影响模型效果：概念性任务对大多数模型构成了挑战，而聚合和转换任务的表现更好。我们主张从最大化性能的基准转向任务和情境感知的适宜性评估，以更好地反映组织优先事项。我们的方法通过可持续性视角提供了一种可扩展的评估AI模型的方法，并为负责的大规模语言模型部署提供了切实可行的指导。', 'title_zh': '可持续性通过适配的大语言模型设计'}
{'arxiv_id': 'arXiv:2504.13216', 'title': 'KFinEval-Pilot: A Comprehensive Benchmark Suite for Korean Financial Language Understanding', 'authors': 'Bokwang Hwang, Seonkyu Lim, Taewoong Kim, Yongjae Geun, Sunghyun Bang, Sohyun Park, Jihyun Park, Myeonggyu Lee, Jinwoo Lee, Yerin Kim, Jinsun Yoo, Jingyeong Hong, Jina Park, Yongchan Kim, Suhyun Kim, Younggyun Hahm, Yiseul Lee, Yejee Kang, Chanhyuk Yoon, Chansu Lee, Heeyewon Jeong, Jiyeon Lee, Seonhye Gu, Hyebin Kang, Yousang Cho, Hangyeol Yoo, KyungTae Lim', 'link': 'https://arxiv.org/abs/2504.13216', 'abstract': 'We introduce KFinEval-Pilot, a benchmark suite specifically designed to evaluate large language models (LLMs) in the Korean financial domain. Addressing the limitations of existing English-centric benchmarks, KFinEval-Pilot comprises over 1,000 curated questions across three critical areas: financial knowledge, legal reasoning, and financial toxicity. The benchmark is constructed through a semi-automated pipeline that combines GPT-4-generated prompts with expert validation to ensure domain relevance and factual accuracy. We evaluate a range of representative LLMs and observe notable performance differences across models, with trade-offs between task accuracy and output safety across different model families. These results highlight persistent challenges in applying LLMs to high-stakes financial applications, particularly in reasoning and safety. Grounded in real-world financial use cases and aligned with the Korean regulatory and linguistic context, KFinEval-Pilot serves as an early diagnostic tool for developing safer and more reliable financial AI systems.', 'abstract_zh': 'KFinEval-Pilot：韩语金融领域的大语言模型基准套件', 'title_zh': 'KFinEval-试点：韩语金融语言理解的综合基准套件'}
{'arxiv_id': 'arXiv:2504.13211', 'title': 'Mirror: Multimodal Cognitive Reframing Therapy for Rolling with Resistance', 'authors': 'Subin Kim, Hoonrae Kim, Jihyun Lee, Yejin Jeon, Gary Geunbae Lee', 'link': 'https://arxiv.org/abs/2504.13211', 'abstract': "Recent studies have explored the use of large language models (LLMs) in psychotherapy; however, text-based cognitive behavioral therapy (CBT) models often struggle with client resistance, which can weaken therapeutic alliance. To address this, we propose a multimodal approach that incorporates nonverbal cues, allowing the AI therapist to better align its responses with the client's negative emotional state. Specifically, we introduce a new synthetic dataset, Multimodal Interactive Rolling with Resistance (Mirror), which is a novel synthetic dataset that pairs client statements with corresponding facial images. Using this dataset, we train baseline Vision-Language Models (VLMs) that can analyze facial cues, infer emotions, and generate empathetic responses to effectively manage resistance. They are then evaluated in terms of both the therapist's counseling skills and the strength of the therapeutic alliance in the presence of client resistance. Our results demonstrate that Mirror significantly enhances the AI therapist's ability to handle resistance, which outperforms existing text-based CBT approaches.", 'abstract_zh': 'Recent Studies on the Use of Large Language Models in Psychotherapy Have Explored Text-Based Cognitive Behavioral Therapy (CBT) Models, Which Often Struggle with Client Resistance; a Multimodal Approach Involving Nonverbal Cues Is Proposed to Better Align AI Therapist Responses with Client Negative Emotional States', 'title_zh': 'Mirror: 多模态认知重框疗法以柔克刚'}
{'arxiv_id': 'arXiv:2504.13209', 'title': 'On the Feasibility of Using MultiModal LLMs to Execute AR Social Engineering Attacks', 'authors': 'Ting Bi, Chenghang Ye, Zheyu Yang, Ziyi Zhou, Cui Tang, Jun Zhang, Zui Tao, Kailong Wang, Liting Zhou, Yang Yang, Tianlong Yu', 'link': 'https://arxiv.org/abs/2504.13209', 'abstract': "Augmented Reality (AR) and Multimodal Large Language Models (LLMs) are rapidly evolving, providing unprecedented capabilities for human-computer interaction. However, their integration introduces a new attack surface for social engineering. In this paper, we systematically investigate the feasibility of orchestrating AR-driven Social Engineering attacks using Multimodal LLM for the first time, via our proposed SEAR framework, which operates through three key phases: (1) AR-based social context synthesis, which fuses Multimodal inputs (visual, auditory and environmental cues); (2) role-based Multimodal RAG (Retrieval-Augmented Generation), which dynamically retrieves and integrates contextual data while preserving character differentiation; and (3) ReInteract social engineering agents, which execute adaptive multiphase attack strategies through inference interaction loops. To verify SEAR, we conducted an IRB-approved study with 60 participants in three experimental configurations (unassisted, AR+LLM, and full SEAR pipeline) compiling a new dataset of 180 annotated conversations in simulated social scenarios. Our results show that SEAR is highly effective at eliciting high-risk behaviors (e.g., 93.3% of participants susceptible to email phishing). The framework was particularly effective in building trust, with 85% of targets willing to accept an attacker's call after an interaction. Also, we identified notable limitations such as ``occasionally artificial'' due to perceived authenticity gaps. This work provides proof-of-concept for AR-LLM driven social engineering attacks and insights for developing defensive countermeasures against next-generation augmented reality threats.", 'abstract_zh': '增强现实（AR）和多模态大规模语言模型（LLMs）正在迅速发展，为人类计算机交互提供了前所未有的能力。然而，它们的集成引入了新的社会工程攻击表面。本文首次通过我们提出的SEAR框架系统地探讨了使用多模态LLM orchestrating AR驱动的社会工程攻击的可行性，该框架分为三个关键阶段：（1）基于AR的社会背景合成，融合多模态输入（视觉、听觉和环境线索）；（2）基于角色的多模态RAG（检索增强生成），动态检索和整合上下文数据并保留角色差异化；（3）ReInteract社会工程代理，通过推理交互循环执行适应性多阶段攻击策略。为了验证SEAR，我们获得了IRB批准，在三组实验配置（未辅助、AR+LLM和全套SEAR流水线）下对60名参与者进行了研究，构建了一个包含180个标注对话的新数据集，以模拟社交场景。研究结果显示，SEAR在诱使高风险行为（例如，93.3%的参与者容易受到电子邮件钓鱼攻击）方面非常有效。该框架在建立信任方面特别有效，85%的目标对象在交互后愿意接受攻击者的电话。此外，我们还发现了一些明显的局限性，如“有时显得不自然”，这与感知的真实性差距有关。本研究提供了AR-LLM驱动的社会工程攻击的概念验证，并为对抗下一代增强现实威胁的发展性防御措施提供了见解。', 'title_zh': '关于使用多模态大语言模型执行AR社会工程攻击的可行性研究'}
{'arxiv_id': 'arXiv:2504.13208', 'title': 'Intelligent road crack detection and analysis based on improved YOLOv8', 'authors': 'Haomin Zuo, Zhengyang Li, Jiangchuan Gong, Zhen Tian', 'link': 'https://arxiv.org/abs/2504.13208', 'abstract': "As urbanization speeds up and traffic flow increases, the issue of pavement distress is becoming increasingly pronounced, posing a severe threat to road safety and service life. Traditional methods of pothole detection rely on manual inspection, which is not only inefficient but also costly. This paper proposes an intelligent road crack detection and analysis system, based on the enhanced YOLOv8 deep learning framework. A target segmentation model has been developed through the training of 4029 images, capable of efficiently and accurately recognizing and segmenting crack regions in roads. The model also analyzes the segmented regions to precisely calculate the maximum and minimum widths of cracks and their exact locations. Experimental results indicate that the incorporation of ECA and CBAM attention mechanisms substantially enhances the model's detection accuracy and efficiency, offering a novel solution for road maintenance and safety monitoring.", 'abstract_zh': '随着城市化进程加快和车流量增加，道路病害问题日益突出，对道路安全和使用寿命构成严重威胁。传统的坑槽检测方法依赖于人工检查，不仅效率低下，成本也高。本文提出了一种基于增强YOLOv8深度学习框架的智能道路裂缝检测与分析系统。通过训练4029张图像开发了目标分割模型，能够高效准确地识别和分割道路裂缝区域。该模型还对分割区域进行分析，精确计算裂缝的最大和最小宽度及其准确位置。实验结果表明，引入ECA和CBAM注意力机制显著提升了模型的检测准确性和效率，为道路维护和安全监控提供了新的解决方案。', 'title_zh': '基于改进YOLOv8的智能道路裂缝检测与分析'}
{'arxiv_id': 'arXiv:2504.13205', 'title': 'On-Device Watermarking: A Socio-Technical Imperative For Authenticity In The Age of Generative AI', 'authors': 'Houssam Kherraz', 'link': 'https://arxiv.org/abs/2504.13205', 'abstract': 'As generative AI models produce increasingly realistic output, both academia and industry are focusing on the ability to detect whether an output was generated by an AI model or not. Many of the research efforts and policy discourse are centered around robust watermarking of AI outputs. While plenty of progress has been made, all watermarking and AI detection techniques face severe limitations. In this position paper, we argue that we are adopting the wrong approach, and should instead focus on watermarking via cryptographic signatures trustworthy content rather than AI generated ones. For audio-visual content, in particular, all real content is grounded in the physical world and captured via hardware sensors. This presents a unique opportunity to watermark at the hardware layer, and we lay out a socio-technical framework and draw parallels with HTTPS certification and Blu-Ray verification protocols. While acknowledging implementation challenges, we contend that hardware-based authentication offers a more tractable path forward, particularly from a policy perspective. As generative models approach perceptual indistinguishability, the research community should be wary of being overly optimistic with AI watermarking, and we argue that AI watermarking research efforts are better spent in the text and LLM space, which are ultimately not traceable to a physical sensor.', 'abstract_zh': '随着生成式AI模型产生越来越逼真的输出，学术界和行业界都集中在检测输出是否由AI模型生成的能力上。尽管在这一领域已经取得了不少进展，但所有水印和AI检测技术都面临着严重的局限性。在本文中，我们主张当前采用的方法存在误区，应将重点转向通过可信内容而非AI生成内容进行 cryptographic 签名的水印技术。对于音频-视觉内容而言，所有真实内容都基于物理世界并通过硬件传感器捕捉。这为在硬件层进行水印提供了独特的机会，我们提出了一个社会和技术框架，并将其与HTTPS认证和蓝光验证协议进行了类比。尽管承认实施挑战，我们认为基于硬件的认证提供了更具可行性的前进道路，尤其是在政策层面。当生成模型接近感知上的无差异时，研究界应警惕对AI水印过于乐观的态度，我们主张将AI水印研究的努力投入文本和语言模型领域，这些领域最终无法追溯到物理传感器。', 'title_zh': '设备端水印：生成式AI时代的技术和社会必要性'}
{'arxiv_id': 'arXiv:2504.13203', 'title': 'X-Teaming: Multi-Turn Jailbreaks and Defenses with Adaptive Multi-Agents', 'authors': 'Salman Rahman, Liwei Jiang, James Shiffer, Genglin Liu, Sheriff Issaka, Md Rizwan Parvez, Hamid Palangi, Kai-Wei Chang, Yejin Choi, Saadia Gabriel', 'link': 'https://arxiv.org/abs/2504.13203', 'abstract': 'Multi-turn interactions with language models (LMs) pose critical safety risks, as harmful intent can be strategically spread across exchanges. Yet, the vast majority of prior work has focused on single-turn safety, while adaptability and diversity remain among the key challenges of multi-turn red-teaming. To address these challenges, we present X-Teaming, a scalable framework that systematically explores how seemingly harmless interactions escalate into harmful outcomes and generates corresponding attack scenarios. X-Teaming employs collaborative agents for planning, attack optimization, and verification, achieving state-of-the-art multi-turn jailbreak effectiveness and diversity with success rates up to 98.1% across representative leading open-weight and closed-source models. In particular, X-Teaming achieves a 96.2% attack success rate against the latest Claude 3.7 Sonnet model, which has been considered nearly immune to single-turn attacks. Building on X-Teaming, we introduce XGuard-Train, an open-source multi-turn safety training dataset that is 20x larger than the previous best resource, comprising 30K interactive jailbreaks, designed to enable robust multi-turn safety alignment for LMs. Our work offers essential tools and insights for mitigating sophisticated conversational attacks, advancing the multi-turn safety of LMs.', 'abstract_zh': '多轮交互与语言模型的安全风险：X-Teaming框架及其应用', 'title_zh': 'X-Teaming: 多轮对话脱戒防护与自适应多 Agents 方法'}
{'arxiv_id': 'arXiv:2504.13200', 'title': 'Efficient Brain Tumor Segmentation Using a Dual-Decoder 3D U-Net with Attention Gates (DDUNet)', 'authors': 'Mohammad Mahdi Danesh Pajouh', 'link': 'https://arxiv.org/abs/2504.13200', 'abstract': 'Cancer remains one of the leading causes of mortality worldwide, and among its many forms, brain tumors are particularly notorious due to their aggressive nature and the critical challenges involved in early diagnosis. Recent advances in artificial intelligence have shown great promise in assisting medical professionals with precise tumor segmentation, a key step in timely diagnosis and treatment planning. However, many state-of-the-art segmentation methods require extensive computational resources and prolonged training times, limiting their practical application in resource-constrained settings. In this work, we present a novel dual-decoder U-Net architecture enhanced with attention-gated skip connections, designed specifically for brain tumor segmentation from MRI scans. Our approach balances efficiency and accuracy by achieving competitive segmentation performance while significantly reducing training demands. Evaluated on the BraTS 2020 dataset, the proposed model achieved Dice scores of 85.06% for Whole Tumor (WT), 80.61% for Tumor Core (TC), and 71.26% for Enhancing Tumor (ET) in only 50 epochs, surpassing several commonly used U-Net variants. Our model demonstrates that high-quality brain tumor segmentation is attainable even under limited computational resources, thereby offering a viable solution for researchers and clinicians operating with modest hardware. This resource-efficient model has the potential to improve early detection and diagnosis of brain tumors, ultimately contributing to better patient outcomes', 'abstract_zh': '癌症仍然是全球主要的死亡原因，而其中的脑肿瘤因其侵袭性以及早期诊断的严峻挑战而尤为 infamous。最近的人工智能进展显示出在协助医疗专业人员进行精确肿瘤分割方面的巨大潜力，这是及时诊断和治疗计划的关键步骤。然而，许多最先进的分割方法需要大量的计算资源和较长的训练时间，限制了它们在资源受限环境中的实际应用。在本文中，我们提出了一种新型的双解码器U-Net架构，并结合了注意力门控跳连，专门用于从MRI扫描中进行脑肿瘤分割。我们的方法通过在显著降低训练需求的同时实现竞争性的分割性能来平衡效率和准确性。在BraTS 2020数据集上评估，提出的模型在50个 epoch 的训练下，取得了 Whole Tumor (WT) 的 Dice 分数为 85.06%、Tumor Core (TC) 的 Dice 分数为 80.61% 和 Enhancing Tumor (ET) 的 Dice 分数为 71.26%，超过了多种常用的U-Net变体。我们的模型表明，即使在有限的计算资源下，高质量的脑肿瘤分割也是可行的，从而为硬件资源有限的研究人员和临床医生提供了可行的解决方案。这种资源高效的模型有可能提高脑肿瘤的早期检测和诊断，最终有助于改善患者的预后。', 'title_zh': '使用注意力门双解码器3D U-Net的高效脑肿瘤分割'}
{'arxiv_id': 'arXiv:2504.13199', 'title': 'Building Trustworthy Multimodal AI: A Review of Fairness, Transparency, and Ethics in Vision-Language Tasks', 'authors': 'Mohammad Saleha, Azadeh Tabatabaeib', 'link': 'https://arxiv.org/abs/2504.13199', 'abstract': 'Objective: This review explores the trustworthiness of multimodal artificial intelligence (AI) systems, specifically focusing on vision-language tasks. It addresses critical challenges related to fairness, transparency, and ethical implications in these systems, providing a comparative analysis of key tasks such as Visual Question Answering (VQA), image captioning, and visual dialogue. Background: Multimodal models, particularly vision-language models, enhance artificial intelligence (AI) capabilities by integrating visual and textual data, mimicking human learning processes. Despite significant advancements, the trustworthiness of these models remains a crucial concern, particularly as AI systems increasingly confront issues regarding fairness, transparency, and ethics. Methods: This review examines research conducted from 2017 to 2024 focusing on forenamed core vision-language tasks. It employs a comparative approach to analyze these tasks through the lens of trustworthiness, underlining fairness, explainability, and ethics. This study synthesizes findings from recent literature to identify trends, challenges, and state-of-the-art solutions. Results: Several key findings were highlighted. Transparency: Explainability of vision language tasks is important for user trust. Techniques, such as attention maps and gradient-based methods, have successfully addressed this issue. Fairness: Bias mitigation in VQA and visual dialogue systems is essential for ensuring unbiased outcomes across diverse demographic groups. Ethical Implications: Addressing biases in multilingual models and ensuring ethical data handling is critical for the responsible deployment of vision-language systems. Conclusion: This study underscores the importance of integrating fairness, transparency, and ethical considerations in developing vision-language models within a unified framework.', 'abstract_zh': '探索多模态人工智能系统在视觉-语言任务中的可信度：公平性、透明度与伦理考量', 'title_zh': '构建可信赖的多模态AI：视觉-语言任务中公平性、透明度与伦理的综述'}
{'arxiv_id': 'arXiv:2504.13196', 'title': 'Investigating cybersecurity incidents using large language models in latest-generation wireless networks', 'authors': 'Leonid Legashev, Arthur Zhigalov', 'link': 'https://arxiv.org/abs/2504.13196', 'abstract': 'The purpose of research: Detection of cybersecurity incidents and analysis of decision support and assessment of the effectiveness of measures to counter information security threats based on modern generative models. The methods of research: Emulation of signal propagation data in MIMO systems, synthesis of adversarial examples, execution of adversarial attacks on machine learning models, fine tuning of large language models for detecting adversarial attacks, explainability of decisions on detecting cybersecurity incidents based on the prompts technique. Scientific novelty: A binary classification of data poisoning attacks was performed using large language models, and the possibility of using large language models for investigating cybersecurity incidents in the latest generation wireless networks was investigated. The result of research: Fine-tuning of large language models was performed on the prepared data of the emulated wireless network segment. Six large language models were compared for detecting adversarial attacks, and the capabilities of explaining decisions made by a large language model were investigated. The Gemma-7b model showed the best results according to the metrics Precision = 0.89, Recall = 0.89 and F1-Score = 0.89. Based on various explainability prompts, the Gemma-7b model notes inconsistencies in the compromised data under study, performs feature importance analysis and provides various recommendations for mitigating the consequences of adversarial attacks. Large language models integrated with binary classifiers of network threats have significant potential for practical application in the field of cybersecurity incident investigation, decision support and assessing the effectiveness of measures to counter information security threats.', 'abstract_zh': '研究目的：基于现代生成模型检测网络安全事件并分析决策支持及对抗信息网络安全威胁措施有效性的评估。研究方法：MIMO系统中信号传播数据的仿真、敌对样本的合成、对机器学习模型执行敌对攻击、大型语言模型的细调以检测敌对攻击、基于提示技术的检测网络安全事件决策的可解释性。科学创新：使用大型语言模型对数据投毒攻击进行了二分类，并研究了使用大型语言模型在最新无线网络中调查网络安全事件的可能性。研究结果：在仿真无线网络段的数据上对大型语言模型进行了细调。六种大型语言模型被用于检测敌对攻击的比较，研究了大型语言模型决策的可解释性。Gemma-7b模型根据精度=0.89、召回率=0.89和F1分数=0.89显示最佳结果。基于多种可解释性提示，Gemma-7b模型指出研究中受攻击数据的不一致性、进行特征重要性分析并提供各种减轻敌对攻击后果的建议。将大型语言模型与网络威胁二分类器集成对于网络安全事件调查、决策支持和评估对抗信息网络安全威胁措施的有效性具有重要实际应用潜力。', 'title_zh': '使用大型语言模型研究最新一代无线网络中的网络安全事件'}
{'arxiv_id': 'arXiv:2504.13194', 'title': 'Optimizing Multi-Gateway LoRaWAN via Cloud-Edge Collaboration and Knowledge Distillation', 'authors': 'Hong Yang', 'link': 'https://arxiv.org/abs/2504.13194', 'abstract': 'For large-scale multi-gateway LoRaWAN networks, this study proposes a cloud-edge collaborative resource allocation and decision-making method based on edge intelligence, HEAT-LDL (HEAT-Local Distill Lyapunov), which realizes collaborative decision-making between gateways and terminal nodes. HEAT-LDL combines the Actor-Critic architecture and the Lyapunov optimization method to achieve intelligent downlink control and gateway load balancing. When the signal quality is good, the network server uses the HEAT algorithm to schedule the terminal nodes. To improve the efficiency of autonomous decision-making of terminal nodes, HEAT-LDL performs cloud-edge knowledge distillation on the HEAT teacher model on the terminal node side. When the downlink decision instruction is lost, the terminal node uses the student model and the edge decider based on prior knowledge and local history to make collaborative autonomous decisions. Simulation experiments show that compared with the optimal results of all compared algorithms, HEAT-LDL improves the packet success rate and energy efficiency by 20.5% and 88.1%, respectively.', 'abstract_zh': '面向大型多 gateway LoRaWAN 网络的边缘智能协作资源分配与决策方法：HEAT-LDL（HEAT-Local Distill Lyapunov）方法实现网关与终端节点间的协作决策', 'title_zh': '基于云边协作与知识精炼的多网关LoRaWAN优化'}
{'arxiv_id': 'arXiv:2504.13193', 'title': 'HEAT:History-Enhanced Dual-phase Actor-Critic Algorithm with A Shared Transformer', 'authors': 'Hong Yang', 'link': 'https://arxiv.org/abs/2504.13193', 'abstract': 'For a single-gateway LoRaWAN network, this study proposed a history-enhanced two-phase actor-critic algorithm with a shared transformer algorithm (HEAT) to improve network performance. HEAT considers uplink parameters and often neglected downlink parameters, and effectively integrates offline and online reinforcement learning, using historical data and real-time interaction to improve model performance. In addition, this study developed an open source LoRaWAN network simulator LoRaWANSim. The simulator considers the demodulator lock effect and supports multi-channel, multi-demodulator and bidirectional communication. Simulation experiments show that compared with the best results of all compared algorithms, HEAT improves the packet success rate and energy efficiency by 15% and 95%, respectively.', 'abstract_zh': '针对单网关LoRaWAN网络，本文提出了一种结合历史数据的两阶段actor-critic算法（HEAT），该算法融合了共享变压器结构，并改进了网络性能。HEAT考虑了上行参数和经常被忽视的下行参数，并有效整合了离线和在线强化学习，使用历史数据和实时交互来提高模型性能。此外，本文还开发了一个开源LoRaWAN网络仿真器LoRaWANSim。该仿真器考虑了解调器锁定效应，并支持多通道、多解调器和双向通信。仿真实验表明，与所有比较算法的最优结果相比，HEAT分别将数据包成功率和能效提高了15%和95%。', 'title_zh': 'HEAT：带有共享变压器的历史增强双阶段actor-critic算法'}
{'arxiv_id': 'arXiv:2504.13192', 'title': 'CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent', 'authors': 'Liang-bo Ning, Shijie Wang, Wenqi Fan, Qing Li, Xin Xu, Hao Chen, Feiran Huang', 'link': 'https://arxiv.org/abs/2504.13192', 'abstract': "Recently, Large Language Model (LLM)-empowered recommender systems (RecSys) have brought significant advances in personalized user experience and have attracted considerable attention. Despite the impressive progress, the research question regarding the safety vulnerability of LLM-empowered RecSys still remains largely under-investigated. Given the security and privacy concerns, it is more practical to focus on attacking the black-box RecSys, where attackers can only observe the system's inputs and outputs. However, traditional attack approaches employing reinforcement learning (RL) agents are not effective for attacking LLM-empowered RecSys due to the limited capabilities in processing complex textual inputs, planning, and reasoning. On the other hand, LLMs provide unprecedented opportunities to serve as attack agents to attack RecSys because of their impressive capability in simulating human-like decision-making processes. Therefore, in this paper, we propose a novel attack framework called CheatAgent by harnessing the human-like capabilities of LLMs, where an LLM-based agent is developed to attack LLM-Empowered RecSys. Specifically, our method first identifies the insertion position for maximum impact with minimal input modification. After that, the LLM agent is designed to generate adversarial perturbations to insert at target positions. To further improve the quality of generated perturbations, we utilize the prompt tuning technique to improve attacking strategies via feedback from the victim RecSys iteratively. Extensive experiments across three real-world datasets demonstrate the effectiveness of our proposed attacking method.", 'abstract_zh': '近期，大型语言模型（LLM）赋能的推荐系统（RecSys）在个性化用户体验方面取得了显著进步，并吸引了广泛关注。尽管取得了显著进展，关于LLM赋能RecSys的安全漏洞问题仍很大程度上未被深入研究。鉴于安全和隐私关切，更实际的做法是集中攻击黑盒RecSys，其中攻击者只能观察系统的输入和输出。然而，传统利用强化学习（RL）代理的攻击方法对攻击LLM赋能RecSys无效，因为它们在处理复杂文本输入、规划和推理方面能力有限。另一方面，LLM因其模拟人类决策过程的强大能力，提供了作为攻击代理攻击RecSys的前所未有的机会。因此，在本文中，我们提出了一种名为CheatAgent的新型攻击框架，利用LLM的人类化能力，开发基于LLM的代理来攻击LLM赋能RecSys。具体而言，我们的方法首先通过最小化输入修改来识别具有最大影响的插入位置。之后，设计LLM代理生成对抗性扰动并插入到目标位置。为了进一步提高生成扰动的质量，我们利用提示调优技术，通过受害RecSys的反馈迭代改进攻击策略。在三个真实世界数据集上的广泛实验表明了我们提出攻击方法的有效性。', 'title_zh': 'CheatAgent：通过LLM代理攻击LLM赋能的推荐系统'}
{'arxiv_id': 'arXiv:2504.13191', 'title': 'Universal Representations for Classification-enhanced Lossy Compression', 'authors': 'Nam Nguyen', 'link': 'https://arxiv.org/abs/2504.13191', 'abstract': 'In lossy compression, the classical tradeoff between compression rate and reconstruction distortion has traditionally guided algorithm design. However, Blau and Michaeli [5] introduced a generalized framework, known as the rate-distortion-perception (RDP) function, incorporating perceptual quality as an additional dimension of evaluation. More recently, the rate-distortion-classification (RDC) function was investigated in [19], evaluating compression performance by considering classification accuracy alongside distortion. In this paper, we explore universal representations, where a single encoder is developed to achieve multiple decoding objectives across various distortion and classification (or perception) constraints. This universality avoids retraining encoders for each specific operating point within these tradeoffs. Our experimental validation on the MNIST dataset indicates that a universal encoder incurs only minimal performance degradation compared to individually optimized encoders for perceptual image compression tasks, aligning with prior results from [23]. Nonetheless, we also identify that in the RDC setting, reusing an encoder optimized for one specific classification-distortion tradeoff leads to a significant distortion penalty when applied to alternative points.', 'abstract_zh': '基于率失真感知的压缩算法设计：从RDP到RDC函数的研究', 'title_zh': '分类增强的失真压缩的通用表示'}
{'arxiv_id': 'arXiv:2504.13186', 'title': 'Advanced Deep Learning and Large Language Models: Comprehensive Insights for Cancer Detection', 'authors': 'Yassine Habchi, Hamza Kheddar, Yassine Himeur, Adel Belouchrani, Erchin Serpedin, Fouad Khelifi, Muhammad E.H. Chowdhury', 'link': 'https://arxiv.org/abs/2504.13186', 'abstract': "The rapid advancement of deep learning (DL) has transformed healthcare, particularly in cancer detection and diagnosis. DL surpasses traditional machine learning and human accuracy, making it a critical tool for identifying diseases. Despite numerous reviews on DL in healthcare, a comprehensive analysis of its role in cancer detection remains limited. Existing studies focus on specific aspects, leaving gaps in understanding its broader impact. This paper addresses these gaps by reviewing advanced DL techniques, including transfer learning (TL), reinforcement learning (RL), federated learning (FL), Transformers, and large language models (LLMs). These approaches enhance accuracy, tackle data scarcity, and enable decentralized learning while maintaining data privacy. TL adapts pre-trained models to new datasets, improving performance with limited labeled data. RL optimizes diagnostic pathways and treatment strategies, while FL fosters collaborative model development without sharing sensitive data. Transformers and LLMs, traditionally used in natural language processing, are now applied to medical data for improved interpretability. Additionally, this review examines these techniques' efficiency in cancer diagnosis, addresses challenges like data imbalance, and proposes solutions. It serves as a resource for researchers and practitioners, providing insights into current trends and guiding future research in advanced DL for cancer detection.", 'abstract_zh': '深度学习在癌症检测中的快速发展及其广泛应用：转移学习、强化学习、联邦学习、变换器和大型语言模型的综述', 'title_zh': '高级深度学习与大型语言模型：癌症检测的全面洞见'}
{'arxiv_id': 'arXiv:2504.13183', 'title': 'Factors That Influence the Adoption of AI-enabled Conversational Agents (AICAs) as an Augmenting Therapeutic Tool by Frontline Healthcare Workers: From Technology Acceptance Model 3 (TAM3) Lens -- A Systematic Mapping Review', 'authors': 'Rawan AlMakinah', 'link': 'https://arxiv.org/abs/2504.13183', 'abstract': "Artificial intelligent (AI) conversational agents hold a promising future in the field of mental health, especially in helping marginalized communities that lack access to mental health support services. It is tempting to have a 24/7 mental health companion that can be accessed anywhere using mobile phones to provide therapist-like advice. Yet, caution should be taken, and studies around their feasibility need to be surveyed. Before adopting such a rapidly changing technology, studies on its feasibility should be explored, summarized, and synthesized to gain a solid understanding of the status quo and to enable us to build a framework that can guide us throughout the development and deployment processes. Different perspectives must be considered when investigating the feasibility of AI conversational agents, including the mental healthcare professional perspective. The literature can provide insights into their perspectives in terms of opportunities, concerns, and implications. Mental health professionals, the subject-matter experts in this field, have their points of view that should be understood and considered. This systematic literature review will explore mental health practitioners' attitudes toward AI conversational agents and the factors that affect their adoption and recommendation of the technology to augment their services and treatments. The TAM3 Framework will be the lens through which this systematic literature review will be conducted.", 'abstract_zh': '人工智能（AI）对话代理在心理健康领域拥有广阔的应用前景，尤其有助于缺乏心理健康支持服务的边缘化社区。拥有一个24/7的心理健康同伴，可以通过手机随时随地提供类似 therapists 的建议，这是颇具吸引力的。然而，需要谨慎，关于其可行性的研究也需要进行调查。在采用这种迅速变革的技术之前，应该探索、总结和综合相关研究，以获得现状的坚实理解，并帮助我们构建一个可以指导整个开发和部署过程的框架。在调查AI对话代理的可行性时，必须考虑不同的视角，包括心理健康专业人员的视角。文献可以提供关于其机会、担忧和影响方面的见解。心理健康专业人员作为这一领域的专家，他们的观点应当被理解和考虑。本系统综述将探讨心理健康从业者对AI对话代理的态度及其影响其采用和推荐该技术以增强其服务和治疗的因素。本系统综述将通过TAM3框架进行。', 'title_zh': '面向前线医疗工作者的AI驱动对话代理（AICAs）作为增强性治疗工具的采用影响因素：基于Technology Acceptance Model 3（TAM3）的系统映射综述'}
