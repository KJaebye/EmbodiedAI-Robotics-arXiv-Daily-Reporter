{'arxiv_id': 'arXiv:2504.13807', 'title': 'DiffOG: Differentiable Policy Trajectory Optimization with Generalizability', 'authors': 'Zhengtong Xu, Zichen Miao, Qiang Qiu, Zhe Zhang, Yu She', 'link': 'https://arxiv.org/abs/2504.13807', 'abstract': 'Imitation learning-based visuomotor policies excel at manipulation tasks but often produce suboptimal action trajectories compared to model-based methods. Directly mapping camera data to actions via neural networks can result in jerky motions and difficulties in meeting critical constraints, compromising safety and robustness in real-world deployment. For tasks that require high robustness or strict adherence to constraints, ensuring trajectory quality is crucial. However, the lack of interpretability in neural networks makes it challenging to generate constraint-compliant actions in a controlled manner. This paper introduces differentiable policy trajectory optimization with generalizability (DiffOG), a learning-based trajectory optimization framework designed to enhance visuomotor policies. By leveraging the proposed differentiable formulation of trajectory optimization with transformer, DiffOG seamlessly integrates policies with a generalizable optimization layer. Visuomotor policies enhanced by DiffOG generate smoother, constraint-compliant action trajectories in a more interpretable way. DiffOG exhibits strong generalization capabilities and high flexibility. We evaluated DiffOG across 11 simulated tasks and 2 real-world tasks. The results demonstrate that DiffOG significantly enhances the trajectory quality of visuomotor policies while having minimal impact on policy performance, outperforming trajectory processing baselines such as greedy constraint clipping and penalty-based trajectory optimization. Furthermore, DiffOG achieves superior performance compared to existing constrained visuomotor policy.', 'abstract_zh': '基于模仿学习的视觉运动策略在操作任务中表现出色，但与基于模型的方法相比，往往会生成次优的动作轨迹。直接通过神经网络将相机数据映射到动作可能会导致动作不连贯，并且难以满足关键约束，从而在实际部署中影响安全性和鲁棒性。对于需要高鲁棒性或严格遵守约束的任务，确保轨迹质量至关重要。然而，神经网络缺乏可解释性，使其难以以受控的方式生成符合约束的动作。本文提出了可泛化的可微策略轨迹优化（DiffOG），这是一种基于学习的轨迹优化框架，旨在提升视觉运动策略。通过利用带有变换器的可微轨迹优化公式，DiffOG 平滑地将策略与一个可泛化的优化层结合在一起。经过 DiffOG 提升的视觉运动策略生成更具可解释性的、符合约束的动作轨迹。DiffOG 具有较强的泛化能力和高度的灵活性。我们在 11 个模拟任务和 2 个真实世界任务上评估了 DiffOG。结果表明，DiffOG 显著提升了视觉运动策略的轨迹质量，同时对策略性能的影响极小，优于诸如贪婪约束截断和基于惩罚的轨迹优化等轨迹处理基线。此外，DiffOG 在现有的受约束的视觉运动策略中表现出优越的性能。', 'title_zh': 'DiffOG: 具有泛化能力的可微分策略轨迹优化'}
{'arxiv_id': 'arXiv:2504.13713', 'title': 'SLAM&Render: A Benchmark for the Intersection Between Neural Rendering, Gaussian Splatting and SLAM', 'authors': 'Samuel Cerezo, Gaetano Meli, Tomás Berriel Martins, Kirill Safronov, Javier Civera', 'link': 'https://arxiv.org/abs/2504.13713', 'abstract': 'Models and methods originally developed for novel view synthesis and scene rendering, such as Neural Radiance Fields (NeRF) and Gaussian Splatting, are increasingly being adopted as representations in Simultaneous Localization and Mapping (SLAM). However, existing datasets fail to include the specific challenges of both fields, such as multimodality and sequentiality in SLAM or generalization across viewpoints and illumination conditions in neural rendering. To bridge this gap, we introduce SLAM&Render, a novel dataset designed to benchmark methods in the intersection between SLAM and novel view rendering. It consists of 40 sequences with synchronized RGB, depth, IMU, robot kinematic data, and ground-truth pose streams. By releasing robot kinematic data, the dataset also enables the assessment of novel SLAM strategies when applied to robot manipulators. The dataset sequences span five different setups featuring consumer and industrial objects under four different lighting conditions, with separate training and test trajectories per scene, as well as object rearrangements. Our experimental results, obtained with several baselines from the literature, validate SLAM&Render as a relevant benchmark for this emerging research area.', 'abstract_zh': 'SLAM与新颖视图渲染交集中的SLAM&Render数据集', 'title_zh': 'SLAM&渲染：神经渲染、高斯点积和SLAM交叉领域的基准测试'}
{'arxiv_id': 'arXiv:2504.13697', 'title': 'Green Robotic Mixed Reality with Gaussian Splatting', 'authors': 'Chenxuan Liu, He Li, Zongze Li, Shuai Wang, Wei Xu, Kejiang Ye, Derrick Wing Kwan Ng, Chengzhong Xu', 'link': 'https://arxiv.org/abs/2504.13697', 'abstract': "Realizing green communication in robotic mixed reality (RoboMR) systems presents a challenge, due to the necessity of uploading high-resolution images at high frequencies through wireless channels. This paper proposes Gaussian splatting (GS) RoboMR (GSRMR), which achieves a lower energy consumption and makes a concrete step towards green RoboMR. The crux to GSRMR is to build a GS model which enables the simulator to opportunistically render a photo-realistic view from the robot's pose, thereby reducing the need for excessive image uploads. Since the GS model may involve discrepancies compared to the actual environments, a GS cross-layer optimization (GSCLO) framework is further proposed, which jointly optimizes content switching (i.e., deciding whether to upload image or not) and power allocation across different frames. The GSCLO problem is solved by an accelerated penalty optimization (APO) algorithm. Experiments demonstrate that the proposed GSRMR reduces the communication energy by over 10x compared with RoboMR. Furthermore, the proposed GSRMR with APO outperforms extensive baseline schemes, in terms of peak signal-to-noise ratio (PSNR) and structural similarity index measure (SSIM).", 'abstract_zh': "实现机器人混合现实（RoboMR）系统的绿色通信 presents a challenge due to the necessity of uploading high-resolution images at high frequencies through wireless channels. This paper proposes Gaussian splatting (GS) RoboMR (GSRMR), which achieves lower energy consumption and takes a concrete step towards green RoboMR. The key to GSRMR is to build a GS model that enables the simulator to opportunistically render a photo-realistic view from the robot's pose, thereby reducing the need for excessive image uploads. Since the GS model may involve discrepancies compared to the actual environments, a GS cross-layer optimization (GSCLO) framework is further proposed, which jointly optimizes content switching (i.e., deciding whether to upload image or not) and power allocation across different frames. The GSCLO problem is solved by an accelerated penalty optimization (APO) algorithm. Experiments demonstrate that the proposed GSRMR reduces communication energy by over 10 times compared with RoboMR. Furthermore, the proposed GSRMR with APO outperforms extensive baseline schemes in terms of peak signal-to-noise ratio (PSNR) and structural similarity index measure (SSIM).", 'title_zh': '绿色机器人混合现实技术：基于高斯光斑渲染'}
{'arxiv_id': 'arXiv:2504.13420', 'title': 'Testing the Fault-Tolerance of Multi-Sensor Fusion Perception in Autonomous Driving Systems', 'authors': 'Haoxiang Tian, Wenqiang Ding, Xingshuo Han, Guoquan Wu, An Guo, Junqi Zhang. Wei Chen, Jun Wei, Tianwei Zhang', 'link': 'https://arxiv.org/abs/2504.13420', 'abstract': 'High-level Autonomous Driving Systems (ADSs), such as Google Waymo and Baidu Apollo, typically rely on multi-sensor fusion (MSF) based approaches to perceive their surroundings. This strategy increases perception robustness by combining the respective strengths of the camera and LiDAR and directly affects the safety-critical driving decisions of autonomous vehicles (AVs). However, in real-world autonomous driving scenarios, cameras and LiDAR are subject to various faults, which can probably significantly impact the decision-making and behaviors of ADSs. Existing MSF testing approaches only discovered corner cases that the MSF-based perception cannot accurately detected by MSF-based perception, while lacking research on how sensor faults affect the system-level behaviors of ADSs.\nTo address this gap, we conduct the first exploration of the fault tolerance of MSF perception-based ADS for sensor faults. In this paper, we systematically and comprehensively build fault models for cameras and LiDAR in AVs and inject them into the MSF perception-based ADS to test its behaviors in test scenarios. To effectively and efficiently explore the parameter spaces of sensor fault models, we design a feedback-guided differential fuzzer to discover the safety violations of MSF perception-based ADS caused by the injected sensor faults. We evaluate FADE on the representative and practical industrial ADS, Baidu Apollo. Our evaluation results demonstrate the effectiveness and efficiency of FADE, and we conclude some useful findings from the experimental results. To validate the findings in the physical world, we use a real Baidu Apollo 6.0 EDU autonomous vehicle to conduct the physical experiments, and the results show the practical significance of our findings.', 'abstract_zh': '高层次自动驾驶系统中基于多传感器融合的容错研究：以摄像头和LiDAR故障为例', 'title_zh': '测试自动驾驶系统中多传感器融合感知的容错性'}
{'arxiv_id': 'arXiv:2504.13406', 'title': 'LangCoop: Collaborative Driving with Language', 'authors': 'Xiangbo Gao, Yuheng Wu, Rujia Wang, Chenxi Liu, Yang Zhou, Zhengzhong Tu', 'link': 'https://arxiv.org/abs/2504.13406', 'abstract': 'Multi-agent collaboration holds great promise for enhancing the safety, reliability, and mobility of autonomous driving systems by enabling information sharing among multiple connected agents. However, existing multi-agent communication approaches are hindered by limitations of existing communication media, including high bandwidth demands, agent heterogeneity, and information loss. To address these challenges, we introduce LangCoop, a new paradigm for collaborative autonomous driving that leverages natural language as a compact yet expressive medium for inter-agent communication. LangCoop features two key innovations: Mixture Model Modular Chain-of-thought (M$^3$CoT) for structured zero-shot vision-language reasoning and Natural Language Information Packaging (LangPack) for efficiently packaging information into concise, language-based messages. Through extensive experiments conducted in the CARLA simulations, we demonstrate that LangCoop achieves a remarkable 96\\% reduction in communication bandwidth (< 2KB per message) compared to image-based communication, while maintaining competitive driving performance in the closed-loop evaluation.', 'abstract_zh': '基于自然语言的多智能体协同在增强自动驾驶安全性、可靠性和移动性方面的前景：LangCoop新范式通过紧凑且表达能力强的中介实现跨智能体通信', 'title_zh': 'LangCoop: 语言辅助协作驾驶'}
{'arxiv_id': 'arXiv:2504.13413', 'title': 'A Model-Based Approach to Imitation Learning through Multi-Step Predictions', 'authors': 'Haldun Balim, Yang Hu, Yuyang Zhang, Na Li', 'link': 'https://arxiv.org/abs/2504.13413', 'abstract': 'Imitation learning is a widely used approach for training agents to replicate expert behavior in complex decision-making tasks. However, existing methods often struggle with compounding errors and limited generalization, due to the inherent challenge of error correction and the distribution shift between training and deployment. In this paper, we present a novel model-based imitation learning framework inspired by model predictive control, which addresses these limitations by integrating predictive modeling through multi-step state predictions. Our method outperforms traditional behavior cloning numerical benchmarks, demonstrating superior robustness to distribution shift and measurement noise both in available data and during execution. Furthermore, we provide theoretical guarantees on the sample complexity and error bounds of our method, offering insights into its convergence properties.', 'abstract_zh': '基于模型的预测控制启发 imitation 学习框架：通过多步状态预测克服分布偏移和测量噪声', 'title_zh': '基于模型的方法通过多步预测进行模仿学习'}
{'arxiv_id': 'arXiv:2504.13631', 'title': 'Multi-modal Knowledge Graph Generation with Semantics-enriched Prompts', 'authors': 'Yajing Xu, Zhiqiang Liu, Jiaoyan Chen, Mingchen Tu, Zhuo Chen, Jeff Z. Pan, Yichi Zhang, Yushan Zhu, Wen Zhang, Huajun Chen', 'link': 'https://arxiv.org/abs/2504.13631', 'abstract': 'Multi-modal Knowledge Graphs (MMKGs) have been widely applied across various domains for knowledge representation. However, the existing MMKGs are significantly fewer than required, and their construction faces numerous challenges, particularly in ensuring the selection of high-quality, contextually relevant images for knowledge graph enrichment. To address these challenges, we present a framework for constructing MMKGs from conventional KGs. Furthermore, to generate higher-quality images that are more relevant to the context in the given knowledge graph, we designed a neighbor selection method called Visualizable Structural Neighbor Selection (VSNS). This method consists of two modules: Visualizable Neighbor Selection (VNS) and Structural Neighbor Selection (SNS). The VNS module filters relations that are difficult to visualize, while the SNS module selects neighbors that most effectively capture the structural characteristics of the entity. To evaluate the quality of the generated images, we performed qualitative and quantitative evaluations on two datasets, MKG-Y and DB15K. The experimental results indicate that using the VSNS method to select neighbors results in higher-quality images that are more relevant to the knowledge graph.', 'abstract_zh': '多模态知识图谱（MMKGs）已在各个领域广泛应用于知识表示。然而，现有的MMKGs数量远不足需求，其构建面临诸多挑战，尤其是在确保选择高质量、上下文相关图像以丰富知识图谱方面。为应对这些挑战，我们提出了一种从传统知识图谱构建多模态知识图谱的框架。此外，为生成与给定知识图谱上下文更相关的高质量图像，我们设计了一种称为可可视化结构邻居选择（VSNS）的方法。该方法包括两个模块：可可视化邻居选择（VNS）和结构邻居选择（SNS）。VNS模块过滤难以可视化的关系，而SNS模块选择最能捕捉实体结构特征的邻居。为了评估生成图像的质量，我们在两个数据集MKG-Y和DB15K上进行了定性和定量评价。实验结果表明，使用VSNS方法选择邻居能够生成与知识图谱更相关的高质量图像。', 'title_zh': '带有语义丰富提示的多模态知识图谱生成'}
{'arxiv_id': 'arXiv:2504.13554', 'title': 'Task Assignment and Exploration Optimization for Low Altitude UAV Rescue via Generative AI Enhanced Multi-agent Reinforcement Learning', 'authors': 'Xin Tang, Qian Chen, Wenjie Weng, Chao Jin, Zhang Liu, Jiacheng Wang, Geng Sun, Xiaohuan Li, Dusit Niyato', 'link': 'https://arxiv.org/abs/2504.13554', 'abstract': "Artificial Intelligence (AI)-driven convolutional neural networks enhance rescue, inspection, and surveillance tasks performed by low-altitude uncrewed aerial vehicles (UAVs) and ground computing nodes (GCNs) in unknown environments. However, their high computational demands often exceed a single UAV's capacity, leading to system instability, further exacerbated by the limited and dynamic resources of GCNs. To address these challenges, this paper proposes a novel cooperation framework involving UAVs, ground-embedded robots (GERs), and high-altitude platforms (HAPs), which enable resource pooling through UAV-to-GER (U2G) and UAV-to-HAP (U2H) communications to provide computing services for UAV offloaded tasks. Specifically, we formulate the multi-objective optimization problem of task assignment and exploration optimization in UAVs as a dynamic long-term optimization problem. Our objective is to minimize task completion time and energy consumption while ensuring system stability over time. To achieve this, we first employ the Lyapunov optimization technique to transform the original problem, with stability constraints, into a per-slot deterministic problem. We then propose an algorithm named HG-MADDPG, which combines the Hungarian algorithm with a generative diffusion model (GDM)-based multi-agent deep deterministic policy gradient (MADDPG) approach. We first introduce the Hungarian algorithm as a method for exploration area selection, enhancing UAV efficiency in interacting with the environment. We then innovatively integrate the GDM and multi-agent deep deterministic policy gradient (MADDPG) to optimize task assignment decisions, such as task offloading and resource allocation. Simulation results demonstrate the effectiveness of the proposed approach, with significant improvements in task offloading efficiency, latency reduction, and system stability compared to baseline methods.", 'abstract_zh': '基于人工智能驱动的卷积神经网络增强低空无人机和地面计算节点在未知环境中的救援、检查和 surveillance任务，但其高计算需求 often 超过单个无人机的能力，导致系统不稳定，进一步加剧了地面计算节点资源的限制和动态性。为应对这些挑战，本文提出了一种涉及无人机、地面嵌入式机器人和高空平台的新型合作框架，通过无人机到地面嵌入式机器人（U2G）和无人机到高空平台（U2H）通信实现资源池化，为卸载任务提供计算服务。具体而言，我们将无人机的任务分配和探索优化问题表述为一个动态的长期优化问题。我们的目标是在确保系统长期稳定的同时，最小化任务完成时间和能耗。为了实现这一目标，我们首先采用李雅普诺夫优化技术将原始问题（带有稳定性约束的问题）转化为每时间段的确定性问题。然后，我们提出了一种结合匈牙利算法和基于生成扩散模型（GDM）的多智能体深确定性策略梯度（MADDPG）方法的算法（HG-MADDPG）。我们首先引入匈牙利算法作为探索区域选择的方法，增强无人机与环境交互的效率。然后，我们创新地将生成扩散模型（GDM）和多智能体深确定性策略梯度（MADDPG）结合，优化任务分配决策，如任务卸载和资源分配。仿真结果表明，所提出的方法在任务卸载效率、延迟减少和系统稳定性方面显著优于基线方法。', 'title_zh': '基于生成式AI增强多智能体强化学习的低空无人机救援任务分配与探索优化'}
{'arxiv_id': 'arXiv:2504.13517', 'title': 'Optimizing Electric Vehicle Charging Station Locations: A Data-driven System with Multi-source Fusion', 'authors': 'Lihuan Li, Du Yin, Hao Xue, David Lillo-Trynes, Flora Salim', 'link': 'https://arxiv.org/abs/2504.13517', 'abstract': 'With the growing electric vehicles (EVs) charging demand, urban planners face the challenges of providing charging infrastructure at optimal locations. For example, range anxiety during long-distance travel and the inadequate distribution of residential charging stations are the major issues many cities face. To achieve reasonable estimation and deployment of the charging demand, we develop a data-driven system based on existing EV trips in New South Wales (NSW) state, Australia, incorporating multiple factors that enhance the geographical feasibility of recommended charging stations. Our system integrates data sources including EV trip data, geographical data such as route data and Local Government Area (LGA) boundaries, as well as features like fire and flood risks, and Points of Interest (POIs). We visualize our results to intuitively demonstrate the findings from our data-driven, multi-source fusion system, and evaluate them through case studies. The outcome of this work can provide a platform for discussion to develop new insights that could be used to give guidance on where to position future EV charging stations.', 'abstract_zh': '随着电动汽车充电需求的增长，城市规划者面临在最优位置提供充电基础设施的挑战。例如，在长距离旅行中出现的里程焦虑和住宅充电站分布不足是许多城市面临的主要问题。为了实现充电需求的合理估计和部署，我们基于澳大利亚新南威尔士州（NSW）现有的电动汽车行程数据，开发了一个数据驱动系统，结合了多个可以增强推荐充电站地理位置可行性的因素。该系统整合了电动汽车行程数据、地理数据如路线数据和地方政府区域（LGA）边界，以及火灾风险、洪水风险和兴趣点（POI）等特征。我们通过可视化结果直观地展示了多源数据融合系统的发现，并通过案例研究进行评估。本研究的成果可以提供一个讨论平台，以发展新的见解并为未来电动汽车充电站的位置提供建议。', 'title_zh': '基于多源融合的电动汽车充电站优化布局：一种数据驱动系统'}
{'arxiv_id': 'arXiv:2504.13360', 'title': 'In between myth and reality: AI for math -- a case study in category theory', 'authors': 'Răzvan Diaconescu', 'link': 'https://arxiv.org/abs/2504.13360', 'abstract': 'Recently, there is an increasing interest in understanding the performance of AI systems in solving math problems. A multitude of tests have been performed, with mixed conclusions. In this paper we discuss an experiment we have made in the direction of mathematical research, with two of the most prominent contemporary AI systems. One of the objective of this experiment is to get an understanding of how AI systems can assist mathematical research. Another objective is to support the AI systems developers by formulating suggestions for directions of improvement.', 'abstract_zh': '近年来，人们对理解AI系统解决数学问题的表现越来越感兴趣。已经进行了多种测试，结论各异。本文讨论了我们对两个最突出的当代AI系统进行的一项数学研究实验。实验的一个目的是了解AI系统如何辅助数学研究。另一个目的是通过提出改进方向的建议来支持AI系统开发者。', 'title_zh': '在神话与现实之间：AI在数学中的应用——范畴理论案例研究'}
{'arxiv_id': 'arXiv:2504.13210', 'title': 'Graphical Models for Decision-Making: Integrating Causality and Game Theory', 'authors': 'Maarten C. Vonk, Mauricio Gonzalez Soto, Anna V. Kononova', 'link': 'https://arxiv.org/abs/2504.13210', 'abstract': 'Causality and game theory are two influential fields that contribute significantly to decision-making in various domains. Causality defines and models causal relationships in complex policy problems, while game theory provides insights into strategic interactions among stakeholders with competing interests. Integrating these frameworks has led to significant theoretical advancements with the potential to improve decision-making processes. However, practical applications of these developments remain underexplored. To support efforts toward implementation, this paper clarifies key concepts in game theory and causality that are essential to their intersection, particularly within the context of probabilistic graphical models. By rigorously examining these concepts and illustrating them with intuitive, consistent examples, we clarify the required inputs for implementing these models, provide practitioners with insights into their application and selection across different scenarios, and reference existing research that supports their implementation. We hope this work encourages broader adoption of these models in real-world scenarios.', 'abstract_zh': '因果关系和博弈论是两个对各个领域决策制定有重大贡献的重要领域。因果关系定义和模型化复杂的政策问题中的因果关系，而博弈论提供了有关竞争利益相关者之间战略互动的见解。将这些框架结合起来，推动了重要的理论进步，有望改善决策过程。然而，这些进展的实际应用仍鲜有探索。为支持这些努力的实施，本文澄清了因果关系和博弈论在交义点上至关重要的关键概念，特别是在概率图形模型的背景下。通过对这些概念进行严谨的分析，并用直观一致的例子进行说明，本文阐明了实施这些模型所需的输入，为实践者提供了在不同情境下应用和选择这些模型的见解，并引用了支持其实施的现有研究。我们希望这项工作能促进这些模型在实际场景中的更广泛采用。', 'title_zh': '图形模型在决策中的应用：集成因果关系与博弈论'}
{'arxiv_id': 'arXiv:2504.13835', 'title': 'MIG: Automatic Data Selection for Instruction Tuning by Maximizing Information Gain in Semantic Space', 'authors': 'Yicheng Chen, Yining Li, Kai Hu, Zerun Ma, Haochen Ye, Kai Chen', 'link': 'https://arxiv.org/abs/2504.13835', 'abstract': 'Data quality and diversity are key to the construction of effective instruction-tuning datasets. %\nWith the increasing availability of open-source instruction-tuning datasets, it is advantageous to automatically select high-quality and diverse subsets from a vast amount of data. %\nExisting methods typically prioritize instance quality and use heuristic rules to maintain diversity. %\nHowever, this absence of a comprehensive view of the entire collection often leads to suboptimal results. %\nMoreover, heuristic rules generally focus on distance or clustering within the embedding space, which fails to accurately capture the intent of complex instructions in the semantic space. %\nTo bridge this gap, we propose a unified method for quantifying the information content of datasets. This method models the semantic space by constructing a label graph and quantifies diversity based on the distribution of information within the graph. %\nBased on such a measurement, we further introduce an efficient sampling method that selects data samples iteratively to \\textbf{M}aximize the \\textbf{I}nformation \\textbf{G}ain (MIG) in semantic space. %\nExperiments on various datasets and base models demonstrate that MIG consistently outperforms state-of-the-art methods. %\nNotably, the model fine-tuned with 5\\% Tulu3 data sampled by MIG achieves comparable performance to the official SFT model trained on the full dataset, with improvements of +5.73\\% on AlpacaEval and +6.89\\% on Wildbench.', 'abstract_zh': '数据的质量和多样性是构建有效指令调优数据集的关键。%\n随着开源指令调优数据集的不断增加，从大量数据中自动选择高质量和多样性的子集变得有利。%\n现有方法通常优先考虑实例质量，并使用启发式规则来维持多样性。%\n然而，这往往会忽视整个集合的全面视角，导致结果次优。%\n此外，启发式规则通常关注嵌入空间中的距离或聚类，未能准确捕捉语义空间中复杂指令的意图。%\n为了解决这一问题，我们提出了一种统一的方法来量化数据集中的信息内容。该方法通过构建标签图来建模语义空间，并基于图中信息的分布来量化多样性。%\n基于这种测量，我们进一步引入了一种高效的采样方法，该方法通过迭代选择数据样本以最大化语义空间中的信息增益（MIG）。%\n在各种数据集和基础模型上的实验表明，MIG 一致性地优于现有方法。%\n值得注意的是，使用 MIG 采样的 5% Tulu3 数据微调的模型在 AlpacaEval 上获得了 +5.73% 的提升，在 Wildbench 上获得了 +6.89% 的提升，性能与在完整数据集上训练的官方 SFT 模型相当。', 'title_zh': 'MIG：通过最大化语义空间信息增益实现自动数据选择的指令调优方法'}
{'arxiv_id': 'arXiv:2504.13822', 'title': 'Parameter-Efficient Continual Fine-Tuning: A Survey', 'authors': 'Eric Nuertey Coleman, Luigi Quarantiello, Ziyue Liu, Qinwen Yang, Samrat Mukherjee, Julio Hurtado, Vincenzo Lomonaco', 'link': 'https://arxiv.org/abs/2504.13822', 'abstract': 'The emergence of large pre-trained networks has revolutionized the AI field, unlocking new possibilities and achieving unprecedented performance. However, these models inherit a fundamental limitation from traditional Machine Learning approaches: their strong dependence on the \\textit{i.i.d.} assumption hinders their adaptability to dynamic learning scenarios. We believe the next breakthrough in AI lies in enabling efficient adaptation to evolving environments -- such as the real world -- where new data and tasks arrive sequentially. This challenge defines the field of Continual Learning (CL), a Machine Learning paradigm focused on developing lifelong learning neural models. One alternative to efficiently adapt these large-scale models is known Parameter-Efficient Fine-Tuning (PEFT). These methods tackle the issue of adapting the model to a particular data or scenario by performing small and efficient modifications, achieving similar performance to full fine-tuning. However, these techniques still lack the ability to adjust the model to multiple tasks continually, as they suffer from the issue of Catastrophic Forgetting. In this survey, we first provide an overview of CL algorithms and PEFT methods before reviewing the state-of-the-art on Parameter-Efficient Continual Fine-Tuning (PECFT). We examine various approaches, discuss evaluation metrics, and explore potential future research directions. Our goal is to highlight the synergy between CL and Parameter-Efficient Fine-Tuning, guide researchers in this field, and pave the way for novel future research directions.', 'abstract_zh': '大规模预训练网络的出现已革新了人工智能领域，开启了新可能性并实现了前所未有的性能。然而，这些模型继承了传统机器学习方法的基本局限性：对独立同分布假设的强烈依赖阻碍了其在动态学习场景中的适应性。我们认为人工智能下一突破点在于使大规模模型能够高效适应不断变化的环境——例如现实世界——其中新数据和任务会相继到来。这一挑战定义了连续学习（Continual Learning, CL）领域，这是一个专注于开发终身学习神经模型的机器学习范式。一种使这些大规模模型高效适应的方法被称为参数高效微调（Parameter-Efficient Fine-Tuning, PEFT）。这些方法通过进行少量且高效的修改来解决使模型适应特定数据或场景的问题，从而达到与全面微调相似的性能。然而，这些技术仍然缺乏持续适应多个任务的能力，因为它们受到了灾难性遗忘（Catastrophic Forgetting）问题的影响。在本文综述中，我们首先概述了CL算法和PEFT方法，然后回顾了参数高效连续微调（Parameter-Efficient Continual Fine-Tuning, PECFT）的最新进展。我们探讨了各种方法、讨论了评估指标，并探索了未来研究方向。我们的目标是强调CL和参数高效微调之间的协同作用，指导该领域的研究者，并为未来的研究开辟新的方向。', 'title_zh': '参数高效连续微调：一个综述'}
{'arxiv_id': 'arXiv:2504.13804', 'title': 'Near-optimal algorithms for private estimation and sequential testing of collision probability', 'authors': 'Robert Busa-Fekete, Umar Syed', 'link': 'https://arxiv.org/abs/2504.13804', 'abstract': 'We present new algorithms for estimating and testing \\emph{collision probability}, a fundamental measure of the spread of a discrete distribution that is widely used in many scientific fields. We describe an algorithm that satisfies $(\\alpha, \\beta)$-local differential privacy and estimates collision probability with error at most $\\epsilon$ using $\\tilde{O}\\left(\\frac{\\log(1/\\beta)}{\\alpha^2 \\epsilon^2}\\right)$ samples for $\\alpha \\le 1$, which improves over previous work by a factor of $\\frac{1}{\\alpha^2}$. We also present a sequential testing algorithm for collision probability, which can distinguish between collision probability values that are separated by $\\epsilon$ using $\\tilde{O}(\\frac{1}{\\epsilon^2})$ samples, even when $\\epsilon$ is unknown. Our algorithms have nearly the optimal sample complexity, and in experiments we show that they require significantly fewer samples than previous methods.', 'abstract_zh': '我们介绍了估计和测试碰撞概率的新算法，碰撞概率是广泛应用于多个科学领域的离散分布扩散度的基本度量。我们描述了一个满足$(\\alpha, \\beta)$-局部差分隐私的算法，并使用$\\tilde{O}\\left(\\frac{\\log(1/\\beta)}{\\alpha^2 \\epsilon^2}\\right)$样本估计碰撞概率，误差不超过$\\epsilon$，这比 previous work 改进了$\\frac{1}{\\alpha^2}$的数量级。我们还提出了一种序列化测试碰撞概率的算法，在$\\epsilon$未知的情况下，该算法可以使用$\\tilde{O}(\\frac{1}{\\epsilon^2})$样本区分开距为$\\epsilon$的碰撞概率值。我们的算法具有近似最优的样本复杂度，在实验中我们展示了它们所需样本数量明显少于先前方法。', 'title_zh': '近最优的私密估计和碰撞概率的 sequential 测试算法'}
{'arxiv_id': 'arXiv:2504.13797', 'title': 'Meta-Learning and Knowledge Discovery based Physics-Informed Neural Network for Remaining Useful Life Prediction', 'authors': 'Yu Wang, Shujie Liu, Shuai Lv, Gengshuo Liu', 'link': 'https://arxiv.org/abs/2504.13797', 'abstract': 'Predicting the remaining useful life (RUL) of rotating machinery is critical for industrial safety and maintenance, but existing methods struggle with scarce target-domain data and unclear degradation dynamics. We propose a Meta-Learning and Knowledge Discovery-based Physics-Informed Neural Network (MKDPINN) to address these challenges. The method first maps noisy sensor data to a low-dimensional hidden state space via a Hidden State Mapper (HSM). A Physics-Guided Regulator (PGR) then learns unknown nonlinear PDEs governing degradation evolution, embedding these physical constraints into the PINN framework. This integrates data-driven and physics-based approaches. The framework uses meta-learning, optimizing across source-domain meta-tasks to enable few-shot adaptation to new target tasks. Experiments on industrial data and the C-MAPSS benchmark show MKDPINN outperforms baselines in generalization and accuracy, proving its effectiveness for RUL prediction under data scarcity', 'abstract_zh': '基于元学习和知识发现的物理知情神经网络（MKDPINN）：应对剩余使用寿命预测中的数据稀少和退化动态不清问题', 'title_zh': '基于元学习和知识发现的物理知情神经网络用于剩余使用寿命预测'}
{'arxiv_id': 'arXiv:2504.13791', 'title': 'Collective Learning Mechanism based Optimal Transport Generative Adversarial Network for Non-parallel Voice Conversion', 'authors': 'Sandipan Dhar, Md. Tousin Akhter, Nanda Dulal Jana, Swagatam Das', 'link': 'https://arxiv.org/abs/2504.13791', 'abstract': 'After demonstrating significant success in image synthesis, Generative Adversarial Network (GAN) models have likewise made significant progress in the field of speech synthesis, leveraging their capacity to adapt the precise distribution of target data through adversarial learning processes. Notably, in the realm of State-Of-The-Art (SOTA) GAN-based Voice Conversion (VC) models, there exists a substantial disparity in naturalness between real and GAN-generated speech samples. Furthermore, while many GAN models currently operate on a single generator discriminator learning approach, optimizing target data distribution is more effectively achievable through a single generator multi-discriminator learning scheme. Hence, this study introduces a novel GAN model named Collective Learning Mechanism-based Optimal Transport GAN (CLOT-GAN) model, incorporating multiple discriminators, including the Deep Convolutional Neural Network (DCNN) model, Vision Transformer (ViT), and conformer. The objective of integrating various discriminators lies in their ability to comprehend the formant distribution of mel-spectrograms, facilitated by a collective learning mechanism. Simultaneously, the inclusion of Optimal Transport (OT) loss aims to precisely bridge the gap between the source and target data distribution, employing the principles of OT theory. The experimental validation on VCC 2018, VCTK, and CMU-Arctic datasets confirms that the CLOT-GAN-VC model outperforms existing VC models in objective and subjective assessments.', 'abstract_zh': '基于集体学习机制的最优传输生成对抗网络在语音转换中的应用', 'title_zh': '基于集体学习机制的最优传输生成对抗网络非平行语音转换'}
{'arxiv_id': 'arXiv:2504.13787', 'title': 'Probabilistic Stability Guarantees for Feature Attributions', 'authors': 'Helen Jin, Anton Xue, Weiqiu You, Surbhi Goel, Eric Wong', 'link': 'https://arxiv.org/abs/2504.13787', 'abstract': 'Stability guarantees are an emerging tool for evaluating feature attributions, but existing certification methods rely on smoothed classifiers and often yield conservative guarantees. To address these limitations, we introduce soft stability and propose a simple, model-agnostic, and sample-efficient stability certification algorithm (SCA) that provides non-trivial and interpretable guarantees for any attribution. Moreover, we show that mild smoothing enables a graceful tradeoff between accuracy and stability, in contrast to prior certification methods that require a more aggressive compromise. Using Boolean function analysis, we give a novel characterization of stability under smoothing. We evaluate SCA on vision and language tasks, and demonstrate the effectiveness of soft stability in measuring the robustness of explanation methods.', 'abstract_zh': '稳定性保证是评估特征归因的一个新兴工具，但现有的验证方法依赖于平滑分类器，往往导致保守的保证。为了应对这些局限性，我们引入了软稳定性，并提出了一种简单、模型无关且样本高效的稳定性验证算法（SCA），该算法为任何归因提供了非平凡且可解释的保证。此外，我们证明了轻微平滑能在一个平稳性和准确性之间实现更优雅的权衡，与之前的验证方法相比，不需要更大的妥协。通过布尔函数分析，我们给出了稳定性在平滑下的一种新的表征。我们在视觉和语言任务上评估了SCA，并展示了软稳定性在衡量解释方法的稳健性方面的有效性。', 'title_zh': '特征归因的概率稳定性保证'}
{'arxiv_id': 'arXiv:2504.13751', 'title': 'A Survey for What Developers Require in AI-powered Tools that Aid in Component Selection in CBSD', 'authors': 'Mahdi Jaberzadeh Ansari, Ann Barcomb', 'link': 'https://arxiv.org/abs/2504.13751', 'abstract': 'Although it has been more than four decades that the first components-based software development (CBSD) studies were conducted, there is still no standard method or tool for component selection which is widely accepted by the industry. The gulf between industry and academia contributes to the lack of an accepted tool. We conducted a mixed methods survey of nearly 100 people engaged in component-based software engineering practice or research to better understand the problems facing industry, how these needs could be addressed, and current best practices employed in component selection. We also sought to identify and prioritize quality criteria for component selection from an industry perspective. In response to the call for CBSD component selection tools to incorporate recent technical advances, we also explored the perceptions of professionals about AI-driven tools, present and envisioned.', 'abstract_zh': '尽管基于组件的软件开发（CBSD）的研究已有四十余年的历史，但仍未有被行业广泛接受的组件选择标准方法或工具。我们通过混合方法对近100位从事组件式软件工程实践或研究的人员进行了调查，以更好地了解行业面临的问题、这些需求如何解决，以及当前的组件选择最佳实践。我们也致力于从行业角度识别和优先级排序组件选择的质量标准。为响应对CBSD组件选择工具结合近期技术进步的需求，我们还探讨了专业人士对人工智能驱动工具的看法，既有现有的也有预期的。', 'title_zh': 'AI赋能组件选择工具中开发者所需的功能调研'}
{'arxiv_id': 'arXiv:2504.13717', 'title': 'Human-aligned Deep Learning: Explainability, Causality, and Biological Inspiration', 'authors': 'Gianluca Carloni', 'link': 'https://arxiv.org/abs/2504.13717', 'abstract': "This work aligns deep learning (DL) with human reasoning capabilities and needs to enable more efficient, interpretable, and robust image classification. We approach this from three perspectives: explainability, causality, and biological vision. Introduction and background open this work before diving into operative chapters. First, we assess neural networks' visualization techniques for medical images and validate an explainable-by-design method for breast mass classification. A comprehensive review at the intersection of XAI and causality follows, where we introduce a general scaffold to organize past and future research, laying the groundwork for our second perspective. In the causality direction, we propose novel modules that exploit feature co-occurrence in medical images, leading to more effective and explainable predictions. We further introduce CROCODILE, a general framework that integrates causal concepts, contrastive learning, feature disentanglement, and prior knowledge to enhance generalization. Lastly, we explore biological vision, examining how humans recognize objects, and propose CoCoReco, a connectivity-inspired network with context-aware attention mechanisms. Overall, our key findings include: (i) simple activation maximization lacks insight for medical imaging DL models; (ii) prototypical-part learning is effective and radiologically aligned; (iii) XAI and causal ML are deeply connected; (iv) weak causal signals can be leveraged without a priori information to improve performance and interpretability; (v) our framework generalizes across medical domains and out-of-distribution data; (vi) incorporating biological circuit motifs improves human-aligned recognition. This work contributes toward human-aligned DL and highlights pathways to bridge the gap between research and clinical adoption, with implications for improved trust, diagnostic accuracy, and safe deployment.", 'abstract_zh': '本研究将深度学习与人类推理能力相结合，旨在实现更高效、可解释和鲁棒的图像分类。我们从可解释性、因果关系和生物视觉三个角度入手。介绍和背景铺垫后，深入探讨操作章节。首先，评估神经网络的医学图像可视化技术，并验证了设计可解释方法在乳腺肿块分类中的有效性。接着，我们进行了一次在解释性人工智能（XAI）和因果关系交叉领域的全面回顾，引入了一个通用框架来组织过去和未来的研究，为我们的第二视角奠定了基础。在因果关系方向上，我们提出了利用医学图像中特征共现的新模块，从而实现更有效和可解释的预测。我们还引入了CROCODILE框架，该框架整合了因果概念、对比学习、特征解耦以及先验知识，以提高泛化能力。最后，我们研究了生物视觉，探讨了人类如何识别物体，并提出了受连接性启发的网络CoCoReco，该网络具有上下文感知的注意力机制。总体而言，我们的主要发现包括：（i）简单的激活最大化对医学成像深度学习模型缺乏洞察力；（ii）原型部件学习既有效又符合放射学标准；（iii）XAI和因果机器学习紧密相关；（iv）可以在没有先验信息的情况下利用微弱的因果信号来提高性能和可解释性；（v）我们的框架在医学领域和离域数据中都具有泛化能力；（vi）结合生物电路模式可提高符合人类认知的识别。本研究朝着符合人类认知的深度学习方向迈进，并指出了连接研究与临床应用的途径，对未来提高了信任度、诊断准确性以及安全实施具有重要意义。', 'title_zh': '人类导向的深度学习：可解释性、因果关系及生物启发'}
{'arxiv_id': 'arXiv:2504.13676', 'title': 'Trace Gadgets: Minimizing Code Context for Machine Learning-Based Vulnerability Prediction', 'authors': 'Felix Mächtle, Nils Loose, Tim Schulz, Florian Sieck, Jan-Niclas Serr, Ralf Möller, Thomas Eisenbarth', 'link': 'https://arxiv.org/abs/2504.13676', 'abstract': "As the number of web applications and API endpoints exposed to the Internet continues to grow, so does the number of exploitable vulnerabilities. Manually identifying such vulnerabilities is tedious. Meanwhile, static security scanners tend to produce many false positives. While machine learning-based approaches are promising, they typically perform well only in scenarios where training and test data are closely related. A key challenge for ML-based vulnerability detection is providing suitable and concise code context, as excessively long contexts negatively affect the code comprehension capabilities of machine learning models, particularly smaller ones.\nThis work introduces Trace Gadgets, a novel code representation that minimizes code context by removing non-related code. Trace Gadgets precisely capture the statements that cover the path to the vulnerability. As input for ML models, Trace Gadgets provide a minimal but complete context, thereby improving the detection performance. Moreover, we collect a large-scale dataset generated from real-world applications with manually curated labels to further improve the performance of ML-based vulnerability detectors. Our results show that state-of-the-art machine learning models perform best when using Trace Gadgets compared to previous code representations, surpassing the detection capabilities of industry-standard static scanners such as GitHub's CodeQL by at least 4% on a fully unseen dataset. By applying our framework to real-world applications, we identify and report previously unknown vulnerabilities in widely deployed software.", 'abstract_zh': '随着暴露在网络上的Web应用和API端点数量不断增加，可利用的漏洞数量也在增长。手动识别这些漏洞是耗时的工作。同时，静态安全扫描器往往会产生大量的误报。虽然基于机器学习的方法很有前途，但在训练和测试数据紧密相关时，它们通常表现最佳。基于机器学习的漏洞检测的关键挑战之一是提供合适的简洁代码上下文，过长的代码上下文会负面影响机器学习模型，尤其是小型模型的代码理解能力。\n本工作引入了Trace Gadgets，这是一种新型的代码表示方法，通过移除与漏洞无关的代码来最小化代码上下文。Trace Gadgets精确捕捉到覆盖漏洞路径的语句。作为机器学习模型的输入，Trace Gadgets提供了最小但完整的信息上下文，从而提高检测性能。此外，我们收集了一个大规模的数据集，该数据集来自真实世界的应用，并附有手动标注的标签，以进一步提高基于机器学习的漏洞检测器的性能。我们的结果显示，最先进的机器学习模型在使用Trace Gadgets时表现最佳，与之前的方法相比，在未知数据集上超过了行业标准的静态扫描器GitHub CodeQL至少4%的检测能力。通过将我们的框架应用于真实世界的应用，我们识别并报告了广泛部署的软件中的未知漏洞。', 'title_zh': '基于代码上下文最小化的痕迹小工具：面向机器学习的漏洞预测'}
{'arxiv_id': 'arXiv:2504.13655', 'title': 'Multi-Type Context-Aware Conversational Recommender Systems via Mixture-of-Experts', 'authors': 'Jie Zou, Cheng Lin, Weikang Guo, Zheng Wang, Jiwei Wei, Yang Yang, Hengtao Shen', 'link': 'https://arxiv.org/abs/2504.13655', 'abstract': 'Conversational recommender systems enable natural language conversations and thus lead to a more engaging and effective recommendation scenario. As the conversations for recommender systems usually contain limited contextual information, many existing conversational recommender systems incorporate external sources to enrich the contextual information. However, how to combine different types of contextual information is still a challenge. In this paper, we propose a multi-type context-aware conversational recommender system, called MCCRS, effectively fusing multi-type contextual information via mixture-of-experts to improve conversational recommender systems. MCCRS incorporates both structured information and unstructured information, including the structured knowledge graph, unstructured conversation history, and unstructured item reviews. It consists of several experts, with each expert specialized in a particular domain (i.e., one specific contextual information). Multiple experts are then coordinated by a ChairBot to generate the final results. Our proposed MCCRS model takes advantage of different contextual information and the specialization of different experts followed by a ChairBot breaks the model bottleneck on a single contextual information. Experimental results demonstrate that our proposed MCCRS method achieves significantly higher performance compared to existing baselines.', 'abstract_zh': '多类型上下文感知会话推荐系统', 'title_zh': '基于专家混合的多类型上下文感知对话推荐系统'}
{'arxiv_id': 'arXiv:2504.13626', 'title': 'Thought Manipulation: External Thought Can Be Efficient for Large Reasoning Models', 'authors': 'Yule Liu, Jingyi Zheng, Zhen Sun, Zifan Peng, Wenhan Dong, Zeyang Sha, Shiwen Cui, Weiqiang Wang, Xinlei He', 'link': 'https://arxiv.org/abs/2504.13626', 'abstract': 'Recent advancements in large reasoning models (LRMs) have demonstrated the effectiveness of scaling test-time computation to enhance reasoning capabilities in multiple tasks. However, LRMs typically suffer from "overthinking" problems, where models generate significantly redundant reasoning steps while bringing limited performance gains. Existing work relies on fine-tuning to mitigate overthinking, which requires additional data, unconventional training setups, risky safety misalignment, and poor generalization.\nThrough empirical analysis, we reveal an important characteristic of LRM behaviors that placing external CoTs generated by smaller models between the thinking token ($\\texttt{<think>}$ and $\\texttt{</think>)}$ can effectively manipulate the model to generate fewer thoughts. Building on these insights, we propose a simple yet efficient pipeline, ThoughtMani, to enable LRMs to bypass unnecessary intermediate steps and reduce computational costs significantly. We conduct extensive experiments to validate the utility and efficiency of ThoughtMani. For instance, when applied to QwQ-32B on the LiveBench/Code dataset, ThoughtMani keeps the original performance and reduces output token counts by approximately 30%, with little overhead from the CoT generator. Furthermore, we find that ThoughtMani enhances safety alignment by an average of 10%. Since model vendors typically serve models of different sizes simultaneously, ThoughtMani provides an effective way to construct more efficient and accessible LRMs for real-world applications.', 'abstract_zh': 'Recent advancements in大型推理模型（LRMs）最近在大型推理模型（LRMs）方面的进展已经证明了扩展测试时计算以增强多任务推理能力的有效性。然而，LRMs通常会遭遇“过度推理”问题，其中模型生成大量冗余的推理步骤，而带来的性能提升却有限。现有工作依赖于微调来缓解过度推理问题，这需要额外的数据、非传统的训练设置、安全对齐风险以及较差的一般化能力。\n通过实证分析，我们揭示了LRM行为的一个重要特征，即在思考标记（$\\texttt{<think>}和\\texttt{</think>}$）之间插入由更小型模型生成的外部CoTs（中间思考步骤）能够有效地控制模型生成更少的思考步骤。基于这些见解，我们提出了一种简单而高效的管道ThoughtMani，以使LRMs跳过不必要的中间步骤并显著降低计算成本。我们进行了广泛的实验来验证ThoughtMani的实用性和效率。例如，当将其应用于QwQ-32B在LiveBench/Code数据集上时，ThoughtMani能够保持原始性能并减少输出标记计数约30%，且CoTs生成器的额外开销不大。此外，我们发现ThoughtMani平均提高了10%的安全对齐性。由于模型供应商通常同时提供不同规模的模型，ThoughtMani为构建更高效、更易于使用的LRMs以适应实际应用提供了一种有效的方式。', 'title_zh': '思维操纵：外部思维可以高效支持大型推理模型'}
{'arxiv_id': 'arXiv:2504.13614', 'title': 'Adaptive Long-term Embedding with Denoising and Augmentation for Recommendation', 'authors': 'Zahra Akhlaghi, Mostafa Haghir Chehreghani', 'link': 'https://arxiv.org/abs/2504.13614', 'abstract': 'The rapid growth of the internet has made personalized recommendation systems indispensable. Graph-based sequential recommendation systems, powered by Graph Neural Networks (GNNs), effectively capture complex user-item interactions but often face challenges such as noise and static representations. In this paper, we introduce the Adaptive Long-term Embedding with Denoising and Augmentation for Recommendation (ALDA4Rec) method, a novel model that constructs an item-item graph, filters noise through community detection, and enriches user-item interactions. Graph Convolutional Networks (GCNs) are then employed to learn short-term representations, while averaging, GRUs, and attention mechanisms are utilized to model long-term embeddings. An MLP-based adaptive weighting strategy is further incorporated to dynamically optimize long-term user preferences. Experiments conducted on four real-world datasets demonstrate that ALDA4Rec outperforms state-of-the-art baselines, delivering notable improvements in both accuracy and robustness. The source code is available at this https URL.', 'abstract_zh': '基于图的自适应长期嵌入去噪与增强推荐方法（ALDA4Rec）', 'title_zh': '去噪与增强增强的自适应长期嵌入推荐'}
{'arxiv_id': 'arXiv:2504.13612', 'title': 'Entropic Time Schedulers for Generative Diffusion Models', 'authors': 'Dejan Stancevic, Luca Ambrogioni', 'link': 'https://arxiv.org/abs/2504.13612', 'abstract': 'The practical performance of generative diffusion models depends on the appropriate choice of the noise scheduling function, which can also be equivalently expressed as a time reparameterization. In this paper, we present a time scheduler that selects sampling points based on entropy rather than uniform time spacing, ensuring that each point contributes an equal amount of information to the final generation. We prove that this time reparameterization does not depend on the initial choice of time. Furthermore, we provide a tractable exact formula to estimate this \\emph{entropic time} for a trained model using the training loss without substantial overhead. Alongside the entropic time, inspired by the optimality results, we introduce a rescaled entropic time. In our experiments with mixtures of Gaussian distributions and ImageNet, we show that using the (rescaled) entropic times greatly improves the inference performance of trained models. In particular, we found that the image quality in pretrained EDM2 models, as evaluated by FID and FD-DINO scores, can be substantially increased by the rescaled entropic time reparameterization without increasing the number of function evaluations, with greater improvements in the few NFEs regime.', 'abstract_zh': '生成扩散模型的实践性能取决于噪声调度函数的适当选择，这也可以等效地表示为时间重参数化。本文提出了一种时间调度器，基于熵而非均匀时间间隔选择采样点，确保每个点对最终生成贡献相同的信息量。我们证明这种时间重参数化不依赖于初始的时间选择。此外，我们提供了一个可计算的精确公式，使用训练损失来估计训练模型的熵时间，而无需显著的开销。在熵时间的基础上，受到最优性结果的启发，我们引入了缩放熵时间。在使用高斯混合分布和ImageNet的数据实验中，我们发现使用（缩放的）熵时间显著提高了训练模型的推理性能，特别是在少量函数评估情况下，可大幅提高预训练EDM2模型的图像质量，而无需增加函数评估次数。', 'title_zh': '熵时间调度器用于生成性扩散模型'}
{'arxiv_id': 'arXiv:2504.13568', 'title': 'MetaDSE: A Few-shot Meta-learning Framework for Cross-workload CPU Design Space Exploration', 'authors': 'Runzhen Xue, Hao Wu, Mingyu Yan, Ziheng Xiao, Xiaochun Ye, Dongrui Fan', 'link': 'https://arxiv.org/abs/2504.13568', 'abstract': 'Cross-workload design space exploration (DSE) is crucial in CPU architecture design. Existing DSE methods typically employ the transfer learning technique to leverage knowledge from source workloads, aiming to minimize the requirement of target workload simulation. However, these methods struggle with overfitting, data ambiguity, and workload dissimilarity.\nTo address these challenges, we reframe the cross-workload CPU DSE task as a few-shot meta-learning problem and further introduce MetaDSE. By leveraging model agnostic meta-learning, MetaDSE swiftly adapts to new target workloads, greatly enhancing the efficiency of cross-workload CPU DSE. Additionally, MetaDSE introduces a novel knowledge transfer method called the workload-adaptive architectural mask algorithm, which uncovers the inherent properties of the architecture. Experiments on SPEC CPU 2017 demonstrate that MetaDSE significantly reduces prediction error by 44.3\\% compared to the state-of-the-art. MetaDSE is open-sourced and available at this \\href{this https URL}{anonymous GitHub.}', 'abstract_zh': '跨工作负载设计空间探索（DSE）在CPU架构设计中至关重要。现有的DSE方法通常使用迁移学习技术利用源工作负载的知识，旨在减少目标工作负载仿真的需求。然而，这些方法在应对过拟合、数据模糊性和工作负载差异方面存在困难。\n\n为解决这些挑战，我们将跨工作负载CPU DSE任务重新定义为少样本元学习问题，并进一步引入了MetaDSE。通过利用模型无关的元学习，MetaDSE能够迅速适应新的目标工作负载，极大地提升了跨工作负载CPU DSE的效率。此外，MetaDSE引入了一种新颖的知识转移方法——工作负载自适应架构掩码算法，揭示了架构的内在属性。SPEC CPU 2017上的实验结果显示，与现有最佳方法相比，MetaDSE将预测误差显著降低了44.3%。MetaDSE已开源，并可在本链接访问：this https URL。', 'title_zh': 'MetaDSE：针对跨工作负载CPU设计空间探索的少样本元学习框架'}
{'arxiv_id': 'arXiv:2504.13558', 'title': 'Transformers Can Overcome the Curse of Dimensionality: A Theoretical Study from an Approximation Perspective', 'authors': 'Yuling Jiao, Yanming Lai, Yang Wang, Bokai Yan', 'link': 'https://arxiv.org/abs/2504.13558', 'abstract': 'The Transformer model is widely used in various application areas of machine learning, such as natural language processing. This paper investigates the approximation of the Hölder continuous function class $\\mathcal{H}_{Q}^{\\beta}\\left([0,1]^{d\\times n},\\mathbb{R}^{d\\times n}\\right)$ by Transformers and constructs several Transformers that can overcome the curse of dimensionality. These Transformers consist of one self-attention layer with one head and the softmax function as the activation function, along with several feedforward layers. For example, to achieve an approximation accuracy of $\\epsilon$, if the activation functions of the feedforward layers in the Transformer are ReLU and floor, only $\\mathcal{O}\\left(\\log\\frac{1}{\\epsilon}\\right)$ layers of feedforward layers are needed, with widths of these layers not exceeding $\\mathcal{O}\\left(\\frac{1}{\\epsilon^{2/\\beta}}\\log\\frac{1}{\\epsilon}\\right)$. If other activation functions are allowed in the feedforward layers, the width of the feedforward layers can be further reduced to a constant. These results demonstrate that Transformers have a strong expressive capability. The construction in this paper is based on the Kolmogorov-Arnold Representation Theorem and does not require the concept of contextual mapping, hence our proof is more intuitively clear compared to previous Transformer approximation works. Additionally, the translation technique proposed in this paper helps to apply the previous approximation results of feedforward neural networks to Transformer research.', 'abstract_zh': '变压器模型在机器学习各应用领域，如自然语言处理中的广泛应用。本文探讨了变压器对Hölder连续函数类$\\mathcal{H}_{Q}^{\\beta}\\left([0,1]^{d\\times n},\\mathbb{R}^{d\\times n}\\right)$的逼近，并构建了若干种能够克服维数灾难的变压器。这些变压器由一个具有单一注意力头的自我注意力层和软最大化函数作为激活函数，以及若干前馈层组成。例如，为达到逼近精度$\\epsilon$，如果变压器的前馈层激活函数为ReLU和地板函数，仅需$\\mathcal{O}\\left(\\log\\frac{1}{\\epsilon}\\right)$层的前馈层，且这些层的宽度不超过$\\mathcal{O}\\left(\\frac{1}{\\epsilon^{2/\\beta}}\\log\\frac{1}{\\epsilon}\\right)$。如果允许前馈层使用其他激活函数，这些层的宽度可以进一步减少到常数。这些结果表明变压器具有较强的表征能力。本文的构建基于柯尔莫哥洛夫-阿诺尔德表示定理，无需引入上下文映射的概念，因此证明方法相较于先前的变压器逼近工作更为直观。此外，本文提出的翻译技术有助于将之前前馈神经网络的逼近结果应用于变压器研究。', 'title_zh': 'Transformer模型能够克服维数灾：从逼近论视角的理论研究'}
{'arxiv_id': 'arXiv:2504.13551', 'title': 'Q-FAKER: Query-free Hard Black-box Attack via Controlled Generation', 'authors': 'CheolWon Na, YunSeok Choi, Jee-Hyong Lee', 'link': 'https://arxiv.org/abs/2504.13551', 'abstract': "Many adversarial attack approaches are proposed to verify the vulnerability of language models. However, they require numerous queries and the information on the target model. Even black-box attack methods also require the target model's output information. They are not applicable in real-world scenarios, as in hard black-box settings where the target model is closed and inaccessible. Even the recently proposed hard black-box attacks still require many queries and demand extremely high costs for training adversarial generators. To address these challenges, we propose Q-faker (Query-free Hard Black-box Attacker), a novel and efficient method that generates adversarial examples without accessing the target model. To avoid accessing the target model, we use a surrogate model instead. The surrogate model generates adversarial sentences for a target-agnostic attack. During this process, we leverage controlled generation techniques. We evaluate our proposed method on eight datasets. Experimental results demonstrate our method's effectiveness including high transferability and the high quality of the generated adversarial examples, and prove its practical in hard black-box settings.", 'abstract_zh': '无查询强黑盒攻击者Q-faker：一种无需访问目标模型的高效对抗样本生成方法', 'title_zh': 'Q-FAKER:无需查询的受控生成驱动的硬黑盒攻击'}
{'arxiv_id': 'arXiv:2504.13548', 'title': 'Beyond One-Hot Labels: Semantic Mixing for Model Calibration', 'authors': 'Haoyang Luo, Linwei Tao, Minjing Dong, Chang Xu', 'link': 'https://arxiv.org/abs/2504.13548', 'abstract': 'Model calibration seeks to ensure that models produce confidence scores that accurately reflect the true likelihood of their predictions being correct. However, existing calibration approaches are fundamentally tied to datasets of one-hot labels implicitly assuming full certainty in all the annotations. Such datasets are effective for classification but provides insufficient knowledge of uncertainty for model calibration, necessitating the curation of datasets with numerically rich ground-truth confidence values. However, due to the scarcity of uncertain visual examples, such samples are not easily available as real datasets. In this paper, we introduce calibration-aware data augmentation to create synthetic datasets of diverse samples and their ground-truth uncertainty. Specifically, we present Calibration-aware Semantic Mixing (CSM), a novel framework that generates training samples with mixed class characteristics and annotates them with distinct confidence scores via diffusion models. Based on this framework, we propose calibrated reannotation to tackle the misalignment between the annotated confidence score and the mixing ratio during the diffusion reverse process. Besides, we explore the loss functions that better fit the new data representation paradigm. Experimental results demonstrate that CSM achieves superior calibration compared to the state-of-the-art calibration approaches. Code is available at this http URL.', 'abstract_zh': 'Model校准旨在确保模型生成的置信度评分能准确反映其预测正确的真正概率。然而，现有的校准方法本质上与只有一个热标签的数据集紧密关联，隐含地假设所有注解的完全确定性。这样的数据集适用于分类任务，但为模型校准提供的不确定性知识不足，因此需要构建具有丰富数值真实置信度值的注释数据集。但由于不确定的视觉示例稀缺，这些样本不易作为真实数据集获取。本文引入了校准aware数据增强方法以创建包含多样样本及其真实不确定性标注的合成数据集。具体而言，我们提出了校准aware语义混合（CSM）框架，该框架通过扩散模型生成具有混合类特征的训练样本并为其标注不同的置信度评分。基于该框架，我们提出了校准校注以解决扩散逆过程中的标注置信度评分与混合比例之间的偏差问题。此外，我们探索了更适合新数据表示范式的损失函数。实验结果表明，CSM在校准性能上优于现有的前沿校准方法。代码可在该网页链接获取。', 'title_zh': '超越独热标签：语义混合模型校准'}
{'arxiv_id': 'arXiv:2504.13545', 'title': 'Enhancing Multilingual Sentiment Analysis with Explainability for Sinhala, English, and Code-Mixed Content', 'authors': 'Azmarah Rizvi, Navojith Thamindu, A.M.N.H. Adhikari, W.P.U. Senevirathna, Dharshana Kasthurirathna, Lakmini Abeywardhana', 'link': 'https://arxiv.org/abs/2504.13545', 'abstract': 'Sentiment analysis is crucial for brand reputation management in the banking sector, where customer feedback spans English, Sinhala, Singlish, and code-mixed text. Existing models struggle with low-resource languages like Sinhala and lack interpretability for practical use. This research develops a hybrid aspect-based sentiment analysis framework that enhances multilingual capabilities with explainable outputs. Using cleaned banking customer reviews, we fine-tune XLM-RoBERTa for Sinhala and code-mixed text, integrate domain-specific lexicon correction, and employ BERT-base-uncased for English. The system classifies sentiment (positive, neutral, negative) with confidence scores, while SHAP and LIME improve interpretability by providing real-time sentiment explanations. Experimental results show that our approaches outperform traditional transformer-based classifiers, achieving 92.3 percent accuracy and an F1-score of 0.89 in English and 88.4 percent in Sinhala and code-mixed content. An explainability analysis reveals key sentiment drivers, improving trust and transparency. A user-friendly interface delivers aspect-wise sentiment insights, ensuring accessibility for businesses. This research contributes to robust, transparent sentiment analysis for financial applications by bridging gaps in multilingual, low-resource NLP and explainability.', 'abstract_zh': '银行领域中多语言情感分析的可解释框架：提升低资源语言品牌声誉管理', 'title_zh': '增强斯里兰卡僧伽罗语、英语及代码混合内容的多语言情感分析可解释性'}
{'arxiv_id': 'arXiv:2504.13521', 'title': 'Deep Learning Models Meet Financial Data Modalities', 'authors': 'Kasymkhan Khubiev, Michail Semenov', 'link': 'https://arxiv.org/abs/2504.13521', 'abstract': 'Algorithmic trading relies on extracting meaningful signals from diverse financial data sources, including candlestick charts, order statistics on put and canceled orders, traded volume data, limit order books, and news flow. While deep learning has demonstrated remarkable success in processing unstructured data and has significantly advanced natural language processing, its application to structured financial data remains an ongoing challenge. This study investigates the integration of deep learning models with financial data modalities, aiming to enhance predictive performance in trading strategies and portfolio optimization. We present a novel approach to incorporating limit order book analysis into algorithmic trading by developing embedding techniques and treating sequential limit order book snapshots as distinct input channels in an image-based representation. Our methodology for processing limit order book data achieves state-of-the-art performance in high-frequency trading algorithms, underscoring the effectiveness of deep learning in financial applications.', 'abstract_zh': '算法交易依赖于从多元金融数据源中提取有意义的信号，包括K线图、限价订单成交与撤销统计、成交volume数据、限价订单簿以及新闻流。尽管深度学习在处理非结构化数据和自然语言处理方面取得了显著成功，并显著推进了相关领域的发展，但其在结构化金融数据中的应用仍然是一个持续的挑战。本研究探讨了将深度学习模型与金融数据模态结合的方法，旨在提高交易策略和投资组合优化的预测性能。我们提出了一种将限价订单簿分析纳入算法交易的新方法，通过开发嵌入技术，并将限价订单簿的顺序快照作为图像表示中的独立输入通道。我们处理限价订单簿数据的方法在高频交易算法中达到了最先进的性能，突显了深度学习在金融应用中的有效性。', 'title_zh': '深度学习模型遇见金融数据模态'}
{'arxiv_id': 'arXiv:2504.13495', 'title': 'Statistical Validation in Cultural Adaptations of Cognitive Tests: A Multi- Regional Systematic Review', 'authors': 'Miit Daga, Priyasha Mohanty, Ram Krishna, Swarna Priya RM', 'link': 'https://arxiv.org/abs/2504.13495', 'abstract': 'This systematic review discusses the methodological approaches and statistical confirmations of cross-cultural adaptations of cognitive evaluation tools used with different populations. The review considers six seminal studies on the methodology of cultural adaptation in Europe, Asia, Africa, and South America. The results indicate that proper adaptations need holistic models with demographic changes, and education explained as much as 26.76% of the variance in MoCA-H scores. Cultural-linguistic factors explained 6.89% of the variance in European adaptations of MoCA-H; however, another study on adapted MMSE and BCSB among Brazilian Indigenous populations reported excellent diagnostic performance, with a sensitivity of 94.4% and specificity of 99.2%. There was 78.5% inter-rater agreement on the evaluation of cultural adaptation using the Manchester Translation Evaluation Checklist. A paramount message of the paper is that community feedback is necessary for culturally appropriate preparation, standardized translation protocols also must be included, along with robust statistical validation methodologies for developing cognitive assessment instruments. This review supplies evidence-based frameworks for the further adaptation of cognitive assessments in increasingly diverse global health settings.', 'abstract_zh': '这一系统综述探讨了用于不同人群的认知评估工具跨文化适应的方法学方法和统计确认。该综述考虑了欧洲、亚洲、非洲和南美洲的六项关于文化适应方法学的前期研究。研究结果表明，适当的适应需要综合模型，并考虑到人口变化，教育解释了MoCA-H评分26.76%的变异。文化-语言因素解释了欧洲MoCA-H适应版本变异性的6.89%；然而，另一项关于巴西原住民群体适应MMSE和BCSB的研究报告了出色的诊断性能，敏感性为94.4%，特异性为99.2%。使用曼彻斯特翻译评估检查表评估文化适应的一致性为78.5%。本文的核心信息是，社区反馈对于文化适宜性的准备是必要的，标准化翻译协议也必须包括在内，并结合坚实的数据统计验证方法来开发认知评估工具。该综述为在全球日益多元的健康环境中进一步适应认知评估提供了基于证据的框架。', 'title_zh': '文化适应的认知测试统计验证：多区域系统评价'}
{'arxiv_id': 'arXiv:2504.13480', 'title': 'Integrating Locality-Aware Attention with Transformers for General Geometry PDEs', 'authors': 'Minsu Koh, Beom-Chul Park, Heejo Kong, Seong-Whan Lee', 'link': 'https://arxiv.org/abs/2504.13480', 'abstract': 'Neural operators have emerged as promising frameworks for learning mappings governed by partial differential equations (PDEs), serving as data-driven alternatives to traditional numerical methods. While methods such as the Fourier neural operator (FNO) have demonstrated notable performance, their reliance on uniform grids restricts their applicability to complex geometries and irregular meshes. Recently, Transformer-based neural operators with linear attention mechanisms have shown potential in overcoming these limitations for large-scale PDE simulations. However, these approaches predominantly emphasize global feature aggregation, often overlooking fine-scale dynamics and localized PDE behaviors essential for accurate solutions. To address these challenges, we propose the Locality-Aware Attention Transformer (LA2Former), which leverages K-nearest neighbors for dynamic patchifying and integrates global-local attention for enhanced PDE modeling. By combining linear attention for efficient global context encoding with pairwise attention for capturing intricate local interactions, LA2Former achieves an optimal balance between computational efficiency and predictive accuracy. Extensive evaluations across six benchmark datasets demonstrate that LA2Former improves predictive accuracy by over 50% relative to existing linear attention methods, while also outperforming full pairwise attention under optimal conditions. This work underscores the critical importance of localized feature learning in advancing Transformer-based neural operators for solving PDEs on complex and irregular domains.', 'abstract_zh': '基于局部意识注意力的Transformer（LA2Former）：面向复杂和不规则域的偏微分方程建模', 'title_zh': '将局部意识注意力融入变压器以处理通用几何偏微分方程'}
{'arxiv_id': 'arXiv:2504.13477', 'title': "Creating 'Full-Stack' Hybrid Reasoning Systems that Prioritize and Enhance Human Intelligence", 'authors': 'Sean Koon', 'link': 'https://arxiv.org/abs/2504.13477', 'abstract': 'The idea of augmented or hybrid intelligence offers a compelling vision for combining human and AI capabilities, especially in tasks where human wisdom, expertise, or common sense are essential. Unfortunately, human reasoning can be flawed and shortsighted, resulting in adverse individual impacts or even long-term societal consequences. While strong efforts are being made to develop and optimize the AI aspect of hybrid reasoning, the real urgency lies in fostering wiser and more intelligent human participation. Tools that enhance critical thinking, ingenuity, expertise, and even wisdom could be essential in addressing the challenges of our emerging future. This paper proposes the development of generative AI-based tools that enhance both the human ability to reflect upon a problem as well as the ability to explore the technical aspects of it. A high-level model is also described for integrating AI and human capabilities in a way that centralizes human participation and control.', 'abstract_zh': '基于生成AI的工具开发：提升人类问题反思能力和技术探索能力', 'title_zh': '创建优先并增强人类智能的“全栈”混合推理系统'}
{'arxiv_id': 'arXiv:2504.13448', 'title': 'Ascribe New Dimensions to Scientific Data Visualization with VR', 'authors': 'Daniela Ushizima, Guilherme Melo dos Santos, Zineb Sordo, Ronald Pandolfi, Jeffrey Donatelli', 'link': 'https://arxiv.org/abs/2504.13448', 'abstract': 'For over half a century, the computer mouse has been the primary tool for interacting with digital data, yet it remains a limiting factor in exploring complex, multi-scale scientific images. Traditional 2D visualization methods hinder intuitive analysis of inherently 3D structures. Virtual Reality (VR) offers a transformative alternative, providing immersive, interactive environments that enhance data comprehension. This article introduces ASCRIBE-VR, a VR platform of Autonomous Solutions for Computational Research with Immersive Browsing \\& Exploration, which integrates AI-driven algorithms with scientific images. ASCRIBE-VR enables multimodal analysis, structural assessments, and immersive visualization, supporting scientific visualization of advanced datasets such as X-ray CT, Magnetic Resonance, and synthetic 3D imaging. Our VR tools, compatible with Meta Quest, can consume the output of our AI-based segmentation and iterative feedback processes to enable seamless exploration of large-scale 3D images. By merging AI-generated results with VR visualization, ASCRIBE-VR enhances scientific discovery, bridging the gap between computational analysis and human intuition in materials research, connecting human-in-the-loop with digital twins.', 'abstract_zh': 'ASCRIBE-VR：自主解决方案的沉浸式浏览与探索虚拟现实平台', 'title_zh': '使用VR重新定义科学研究数据可视化'}
{'arxiv_id': 'arXiv:2504.13429', 'title': 'Bounded and Uniform Energy-based Out-of-distribution Detection for Graphs', 'authors': 'Shenzhi Yang, Bin Liang, An Liu, Lin Gui, Xingkai Yao, Xiaofang Zhang', 'link': 'https://arxiv.org/abs/2504.13429', 'abstract': 'Given the critical role of graphs in real-world applications and their high-security requirements, improving the ability of graph neural networks (GNNs) to detect out-of-distribution (OOD) data is an urgent research problem. The recent work GNNSAFE proposes a framework based on the aggregation of negative energy scores that significantly improves the performance of GNNs to detect node-level OOD data. However, our study finds that score aggregation among nodes is susceptible to extreme values due to the unboundedness of the negative energy scores and logit shifts, which severely limits the accuracy of GNNs in detecting node-level OOD data. In this paper, we propose NODESAFE: reducing the generation of extreme scores of nodes by adding two optimization terms that make the negative energy scores bounded and mitigate the logit shift. Experimental results show that our approach dramatically improves the ability of GNNs to detect OOD data at the node level, e.g., in detecting OOD data induced by Structure Manipulation, the metric of FPR95 (lower is better) in scenarios without (with) OOD data exposure are reduced from the current SOTA by 28.4% (22.7%).', 'abstract_zh': '基于节点极端分数抑制的 NODESAFE：提升图神经网络检测节点级 OOD 数据的能力', 'title_zh': '基于图的有界和均匀能量法异分布检测'}
{'arxiv_id': 'arXiv:2504.13414', 'title': 'Adaptive Non-local Observable on Quantum Neural Networks', 'authors': 'Hsin-Yi Lin, Huan-Hsin Tseng, Samuel Yen-Chi Chen, Shinjae Yoo', 'link': 'https://arxiv.org/abs/2504.13414', 'abstract': 'Conventional Variational Quantum Circuits (VQCs) for Quantum Machine Learning typically rely on a fixed Hermitian observable, often built from Pauli operators. Inspired by the Heisenberg picture, we propose an adaptive non-local measurement framework that substantially increases the model complexity of the quantum circuits. Our introduction of dynamical Hermitian observables with evolving parameters shows that optimizing VQC rotations corresponds to tracing a trajectory in the observable space. This viewpoint reveals that standard VQCs are merely a special case of the Heisenberg representation.\nFurthermore, we show that properly incorporating variational rotations with non-local observables enhances qubit interaction and information mixture, admitting flexible circuit designs. Two non-local measurement schemes are introduced, and numerical simulations on classification tasks confirm that our approach outperforms conventional VQCs, yielding a more powerful and resource-efficient approach as a Quantum Neural Network.', 'abstract_zh': '传统变分量子电路(VQCs)在量子机器学习中通常依赖于固定的整体算子，常由保罗伊算子构建。受海森堡图像启发，我们提出了一种适应性非局部测量框架，显著提高了量子电路的模型复杂度。我们将动态整体算子与演化参数引入，表明优化VQC旋转对应于在观测空间中绘制轨迹的过程。这一视角揭示了标准VQCs仅仅是海森堡表示的特殊情况。\n\n此外，我们证明正确引入变分旋转与非局部观测值增强了量子比特间的交互和信息混合，允许灵活的电路设计。两种非局部测量方案被引入，数值模拟在分类任务中的表现证实了我们方法优于传统VQCs，提供了一种更强大和资源高效的量子神经网络方法。', 'title_zh': '自适应非局部可观测性在量子神经网络中的应用'}
{'arxiv_id': 'arXiv:2504.13407', 'title': 'LoRA-Based Continual Learning with Constraints on Critical Parameter Changes', 'authors': 'Shimou Ling, Liang Zhang, Jiangwei Zhao, Lili Pan, Hongliang Li', 'link': 'https://arxiv.org/abs/2504.13407', 'abstract': 'LoRA-based continual learning represents a promising avenue for leveraging pre-trained models in downstream continual learning tasks. Recent studies have shown that orthogonal LoRA tuning effectively mitigates forgetting. However, this work unveils that under orthogonal LoRA tuning, the critical parameters for pre-tasks still change notably after learning post-tasks. To address this problem, we directly propose freezing the most critical parameter matrices in the Vision Transformer (ViT) for pre-tasks before learning post-tasks. In addition, building on orthogonal LoRA tuning, we propose orthogonal LoRA composition (LoRAC) based on QR decomposition, which may further enhance the plasticity of our method. Elaborate ablation studies and extensive comparisons demonstrate the effectiveness of our proposed method. Our results indicate that our method achieves state-of-the-art (SOTA) performance on several well-known continual learning benchmarks. For instance, on the Split CIFAR-100 dataset, our method shows a 6.35\\% improvement in accuracy and a 3.24\\% reduction in forgetting compared to previous methods. Our code is available at this https URL.', 'abstract_zh': '基于LoRA的持续学习：一种利用预训练模型进行下游持续学习任务的有前途的方法。尽管正交LoRA调优有效缓解了遗忘现象，但本研究揭示，在正交LoRA调优条件下，预任务的关键参数在学习新任务后仍有显著变化。为解决这一问题，我们直接提出在学习新任务之前，冻结Vision Transformer（ViT）中预任务的关键参数矩阵。除此之外，基于正交LoRA调优，我们提出了基于QR分解的LoRA组成（LoRAC），以进一步增强该方法的可塑性。详尽的消融研究和广泛比较表明我们提出方法的有效性。实验结果表明，我们的方法在多个知名持续学习基准上达到了最先进的性能。例如，在Split CIFAR-100数据集上，我们的方法在准确性和遗忘度方面分别相比以前的方法提高了6.35%和减少了3.24%。我们的代码可在以下链接获取：this https URL。', 'title_zh': '基于约束关键参数变化的LoRA驱动连续学习'}
{'arxiv_id': 'arXiv:2504.13376', 'title': 'Addressing the Minor-Embedding Problem in Quantum Annealing and Evaluating State-of-the-Art Algorithm Performance', 'authors': 'Aitor Gómez-Tejedor, Eneko Osaba, Esther Villar-Rodriguez', 'link': 'https://arxiv.org/abs/2504.13376', 'abstract': "This study addresses the minor-embedding problem, which involves mapping the variables of an Ising model onto a quantum annealing processor. The primary motivation stems from the observed performance disparity of quantum annealers when solving problems suited to the processor's architecture versus those with non-hardware-native topologies. Our research has two main objectives: i) to analyze the impact of embedding quality on the performance of D-Wave Systems quantum annealers, and ii) to evaluate the quality of the embeddings generated by Minorminer, an algorithm provided by D-Wave and widely recognized as the standard minor-embedding technique in the literature. Regarding the first objective, our experiments reveal a clear correlation between the average chain length of embeddings and the relative errors of the solutions sampled. This underscores the critical influence of embedding quality on quantum annealing performance. For the second objective, we focus on the Minorminer technique, assessing its capacity to embed problems, the quality of the embeddings produced, and the robustness of the results. We also compare its performance with Clique Embedding, another algorithm developed by D-Wave, which is deterministic and designed to embed fully connected Ising models into quantum annealing processors, serving as a worst-case scenario. The results demonstrate that there is significant room for improvement for Minorminer, as it has not consistently outperformed the worst-case scenario.", 'abstract_zh': '本研究探讨了Ising模型变量在量子退火处理器上的嵌入问题。研究的主要动机来自于量子退火器在解决适合其架构的问题时与非硬件本征拓扑问题之间的性能差异。本研究有两个主要目标：i) 分析嵌入质量对D-Wave Systems量子退火器性能的影响；ii) 评估由D-Wave提供的Minorminer算法生成的嵌入的质量，该算法被认为是文献中标准的小嵌入技术。针对第一个目标，我们的实验揭示了平均链长与所采样解的相对误差之间存在显著相关性，这突显了嵌入质量对量子退火性能的决定性影响。针对第二个目标，我们集中于Minorminer技术，评估其嵌入问题的能力、生成的嵌入的质量以及结果的稳健性，并将其性能与由D-Wave开发的另一种算法——确定性的Clique Embedding进行比较，后者被设计用于将完全连接的Ising模型嵌入量子退火处理器中，并作为最坏情况的基准。研究结果表明，Minorminer仍存在显著的改进空间，因为它并未一致地优于最坏情况基准。', 'title_zh': '解决量子退火中的次要嵌入问题及评估先进算法性能'}
{'arxiv_id': 'arXiv:2504.13375', 'title': 'Pricing AI Model Accuracy', 'authors': 'Nikhil Kumar', 'link': 'https://arxiv.org/abs/2504.13375', 'abstract': "This paper examines the market for AI models in which firms compete to provide accurate model predictions and consumers exhibit heterogeneous preferences for model accuracy. We develop a consumer-firm duopoly model to analyze how competition affects firms' incentives to improve model accuracy. Each firm aims to minimize its model's error, but this choice can often be suboptimal. Counterintuitively, we find that in a competitive market, firms that improve overall accuracy do not necessarily improve their profits. Rather, each firm's optimal decision is to invest further on the error dimension where it has a competitive advantage. By decomposing model errors into false positive and false negative rates, firms can reduce errors in each dimension through investments. Firms are strictly better off investing on their superior dimension and strictly worse off with investments on their inferior dimension. Profitable investments adversely affect consumers but increase overall welfare.", 'abstract_zh': '本文探讨了AI模型市场中，企业竞相提供准确模型预测，而消费者对模型准确性的偏好各异的情形。我们建立了一个消费者-企业寡头垄断模型，分析竞争如何影响企业提升模型准确性的动机。每家企业都旨在最小化其模型的误差，但这种选择往往并不是最优的。令人意外的是，在竞争市场上，提高整体准确性的企业并不一定能提高其利润。相反，每家企业最优的策略是在其具备竞争优势的误差维度上进一步投资。通过将模型误差分解为假阳性率和假阴性率，企业可以在每个维度上通过投资减少误差。企业只会对其优势维度进行投资而使自身获益，对劣势维度的投资则会使企业受损。有益的投资虽然损害了消费者的利益，但却增加了整体的福利。', 'title_zh': 'AI模型准确性的定价'}
{'arxiv_id': 'arXiv:2504.13371', 'title': 'The Impact of AI on the Cyber Offense-Defense Balance and the Character of Cyber Conflict', 'authors': 'Andrew J. Lohn', 'link': 'https://arxiv.org/abs/2504.13371', 'abstract': 'Unlike other domains of conflict, and unlike other fields with high anticipated risk from AI, the cyber domain is intrinsically digital with a tight feedback loop between AI training and cyber application. Cyber may have some of the largest and earliest impacts from AI, so it is important to understand how the cyber domain may change as AI continues to advance. Our approach reviewed the literature, collecting nine arguments that have been proposed for offensive advantage in cyber conflict and nine proposed arguments for defensive advantage. We include an additional forty-eight arguments that have been proposed to give cyber conflict and competition its character as collected separately by Healey, Jervis, and Nandrajog. We then consider how each of those arguments and propositions might change with varying degrees of AI advancement. We find that the cyber domain is too multifaceted for a single answer to whether AI will enhance offense or defense broadly. AI will improve some aspects, hinder others, and leave some aspects unchanged. We collect and present forty-four ways that we expect AI to impact the cyber offense-defense balance and the character of cyber conflict and competition.', 'abstract_zh': '不同于其他冲突领域，也不同于其他高预期风险的AI领域，网络领域本质上是数字化的，AI entren训练与网络应用之间存在紧密的反馈循环。网络领域可能最早和最深刻地受到AI的影响，因此，了解随着AI的不断进步网络领域可能会发生怎样的变化非常重要。我们的方法是回顾文献，收集了九个关于在网络冲突中取得进攻优势的论点，以及九个关于在网络冲突中取得防御优势的论点。我们还包括了Healey、Jervis和Nandrajog分别收集的额外四十八个论点，以赋予网络冲突和竞争其独特的特征。然后我们考虑在不同程度的AI进步下，每个论点和观点可能会发生怎样的变化。我们发现，网络领域过于复杂，无法用一个答案概括AI是否会普遍增强攻击或防御。AI将在某些方面改进，阻碍另一些方面，并使某些方面保持不变。我们收集并展示了预期的四十四种AI将如何影响网络攻防平衡以及网络冲突和竞争特点的方式。', 'title_zh': 'AI对网络攻防平衡及网络冲突特性的影响'}
{'arxiv_id': 'arXiv:2504.13368', 'title': 'An Optimal Discriminator Weighted Imitation Perspective for Reinforcement Learning', 'authors': 'Haoran Xu, Shuozhe Li, Harshit Sikchi, Scott Niekum, Amy Zhang', 'link': 'https://arxiv.org/abs/2504.13368', 'abstract': 'We introduce Iterative Dual Reinforcement Learning (IDRL), a new method that takes an optimal discriminator-weighted imitation view of solving RL. Our method is motivated by a simple experiment in which we find training a discriminator using the offline dataset plus an additional expert dataset and then performing discriminator-weighted behavior cloning gives strong results on various types of datasets. That optimal discriminator weight is quite similar to the learned visitation distribution ratio in Dual-RL, however, we find that current Dual-RL methods do not correctly estimate that ratio. In IDRL, we propose a correction method to iteratively approach the optimal visitation distribution ratio in the offline dataset given no addtional expert dataset. During each iteration, IDRL removes zero-weight suboptimal transitions using the learned ratio from the previous iteration and runs Dual-RL on the remaining subdataset. This can be seen as replacing the behavior visitation distribution with the optimized visitation distribution from the previous iteration, which theoretically gives a curriculum of improved visitation distribution ratios that are closer to the optimal discriminator weight. We verify the effectiveness of IDRL on various kinds of offline datasets, including D4RL datasets and more realistic corrupted demonstrations. IDRL beats strong Primal-RL and Dual-RL baselines in terms of both performance and stability, on all datasets.', 'abstract_zh': '迭代双强化学习（IDRL）：一种新的最优鉴别器加权模仿学习方法', 'title_zh': '最优判别器加权 imitation 角度的研究：强化学习中的应用'}
{'arxiv_id': 'arXiv:2504.13365', 'title': 'VLLFL: A Vision-Language Model Based Lightweight Federated Learning Framework for Smart Agriculture', 'authors': 'Long Li, Jiajia Li, Dong Chen, Lina Pu, Haibo Yao, Yanbo Huang', 'link': 'https://arxiv.org/abs/2504.13365', 'abstract': 'In modern smart agriculture, object detection plays a crucial role by enabling automation, precision farming, and monitoring of resources. From identifying crop health and pest infestations to optimizing harvesting processes, accurate object detection enhances both productivity and sustainability. However, training object detection models often requires large-scale data collection and raises privacy concerns, particularly when sensitive agricultural data is distributed across farms. To address these challenges, we propose VLLFL, a vision-language model-based lightweight federated learning framework (VLLFL). It harnesses the generalization and context-aware detection capabilities of the vision-language model (VLM) and leverages the privacy-preserving nature of federated learning. By training a compact prompt generator to boost the performance of the VLM deployed across different farms, VLLFL preserves privacy while reducing communication overhead. Experimental results demonstrate that VLLFL achieves 14.53% improvement in the performance of VLM while reducing 99.3% communication overhead. Spanning tasks from identifying a wide variety of fruits to detecting harmful animals in agriculture, the proposed framework offers an efficient, scalable, and privacy-preserving solution specifically tailored to agricultural applications.', 'abstract_zh': '基于视觉语言模型的轻量级联邦学习框架（VLLFL）：一种面向农业应用的高效、可扩展且保护隐私的解决方案', 'title_zh': 'VLLFL：基于视觉-语言模型的轻量级联邦学习框架在智能农业中的应用'}
{'arxiv_id': 'arXiv:2504.13296', 'title': 'Enhanced Pruning Strategy for Multi-Component Neural Architectures Using Component-Aware Graph Analysis', 'authors': 'Ganesh Sundaram, Jonas Ulmen, Daniel Görges', 'link': 'https://arxiv.org/abs/2504.13296', 'abstract': 'Deep neural networks (DNNs) deliver outstanding performance, but their complexity often prohibits deployment in resource-constrained settings. Comprehensive structured pruning frameworks based on parameter dependency analysis reduce model size with specific regard to computational performance. When applying them to Multi-Component Neural Architectures (MCNAs), they risk network integrity by removing large parameter groups. We introduce a component-aware pruning strategy, extending dependency graphs to isolate individual components and inter-component flows. This creates smaller, targeted pruning groups that conserve functional integrity. Demonstrated effectively on a control task, our approach achieves greater sparsity and reduced performance degradation, opening a path for optimizing complex, multi-component DNNs efficiently.', 'abstract_zh': '基于组件感知的剪枝策略：扩展依赖图以隔离个体组件和组件间流以优化复杂多组件深度神经网络', 'title_zh': '基于组件感知图分析的多组件神经架构增强剪枝策略'}
{'arxiv_id': 'arXiv:2504.13277', 'title': 'Interpersonal Theory of Suicide as a Lens to Examine Suicidal Ideation in Online Spaces', 'authors': 'Soorya Ram Shimgekar, Violeta J. Rodriguez, Paul A. Bloom, Dong Whi Yoo, Koustuv Saha', 'link': 'https://arxiv.org/abs/2504.13277', 'abstract': "Suicide is a critical global public health issue, with millions experiencing suicidal ideation (SI) each year. Online spaces enable individuals to express SI and seek peer support. While prior research has revealed the potential of detecting SI using machine learning and natural language analysis, a key limitation is the lack of a theoretical framework to understand the underlying factors affecting high-risk suicidal intent. To bridge this gap, we adopted the Interpersonal Theory of Suicide (IPTS) as an analytic lens to analyze 59,607 posts from Reddit's r/SuicideWatch, categorizing them into SI dimensions (Loneliness, Lack of Reciprocal Love, Self Hate, and Liability) and risk factors (Thwarted Belongingness, Perceived Burdensomeness, and Acquired Capability of Suicide). We found that high-risk SI posts express planning and attempts, methods and tools, and weaknesses and pain. In addition, we also examined the language of supportive responses through psycholinguistic and content analyses to find that individuals respond differently to different stages of Suicidal Ideation (SI) posts. Finally, we explored the role of AI chatbots in providing effective supportive responses to suicidal ideation posts. We found that although AI improved structural coherence, expert evaluations highlight persistent shortcomings in providing dynamic, personalized, and deeply empathetic support. These findings underscore the need for careful reflection and deeper understanding in both the development and consideration of AI-driven interventions for effective mental health support.", 'abstract_zh': '自杀是全球一个关键的公共卫生问题，每年有数百万人经历自杀意念（SI）。在线空间使个体能够表达自杀意念并寻求同侪支持。虽然 predecessors 的研究揭示了利用机器学习和自然语言分析检测自杀意念的潜力，但关键的限制在于缺乏一个理论框架来理解影响高风险自杀意图的潜在因素。为了弥合这一差距，我们采用《人际理论》（Interpersonal Theory of Suicide, IPTS）作为分析视角，分析了来自 Reddit 的 r/SuicideWatch 59,607 条帖子，将其分为自杀意念维度（孤独、缺乏相互关爱、自我憎恨和易感性）和风险因素（挫折感归属、被感知为负担、自杀能力的获得）。我们发现，高风险的自杀意念帖子表达了计划和尝试、方法和工具、以及弱点和痛苦。此外，我们还通过心理语言学和内容分析检查了支持性回应的语言，发现个体对不同的自杀意念（SI）帖子阶段的回应方式不同。最后，我们探讨了人工智能聊天机器人在提供有效的自杀意念帖子支持中的作用。我们的研究发现虽然人工智能提高了结构连贯性，但专家评估指出，在提供动态、个性化和深层次同理心支持方面仍存在持续的不足。这些发现强调了在开发和考虑人工智能驱动的干预措施以提供有效精神健康支持时需要仔细反思和深入理解的重要性。', 'title_zh': '人际理论视角下的自杀意念在线空间考察'}
{'arxiv_id': 'arXiv:2504.13241', 'title': 'Recursive Deep Inverse Reinforcement Learning', 'authors': 'Paul Ghanem, Michael Potter, Owen Howell, Pau Closas, Alireza Ramezani, Deniz Erdogmus, Robert Platt, Tales Imbiriba', 'link': 'https://arxiv.org/abs/2504.13241', 'abstract': "Inferring an adversary's goals from exhibited behavior is crucial for counterplanning and non-cooperative multi-agent systems in domains like cybersecurity, military, and strategy games. Deep Inverse Reinforcement Learning (IRL) methods based on maximum entropy principles show promise in recovering adversaries' goals but are typically offline, require large batch sizes with gradient descent, and rely on first-order updates, limiting their applicability in real-time scenarios. We propose an online Recursive Deep Inverse Reinforcement Learning (RDIRL) approach to recover the cost function governing the adversary actions and goals. Specifically, we minimize an upper bound on the standard Guided Cost Learning (GCL) objective using sequential second-order Newton updates, akin to the Extended Kalman Filter (EKF), leading to a fast (in terms of convergence) learning algorithm. We demonstrate that RDIRL is able to recover cost and reward functions of expert agents in standard and adversarial benchmark tasks. Experiments on benchmark tasks show that our proposed approach outperforms several leading IRL algorithms.", 'abstract_zh': '从对手行为推断其目标的深度递归逆强化学习方法对于网络安全、军事和策略游戏等领域中的反制规划和非合作多智能体系统至关重要。基于最大熵原则的深度逆强化学习方法显示出从对手行为恢复其目标的潜力，但这些方法通常是离线的、需要大批量梯度下降更新，并依赖于一阶更新，限制了其在实时场景中的应用。我们提出了一种在线递归深度逆强化学习（RDIRL）方法来恢复指导对手行为和目标的成本函数。具体而言，我们通过顺序二次牛顿更新最小化标准引导成本学习（GCL）目标的标准上界，类似于扩展卡尔曼滤波器（EKF），从而得到一种快速收敛的学习算法。实验结果表明，RDIRL能够在标准和对抗基准任务中恢复专家智能体的成本和奖励函数。在基准任务上的实验表明，我们提出的方法优于几种领先的逆强化学习算法。', 'title_zh': '递归深度逆强化学习'}
{'arxiv_id': 'arXiv:2504.13234', 'title': 'Non-Uniform Class-Wise Coreset Selection: Characterizing Category Difficulty for Data-Efficient Transfer Learning', 'authors': 'Hanyu Zhang, Zhen Xing, Wenxuan Yang, Chenxi Ma, Weimin Tan, Bo Yan', 'link': 'https://arxiv.org/abs/2504.13234', 'abstract': "As transfer learning models and datasets grow larger, efficient adaptation and storage optimization have become critical needs. Coreset selection addresses these challenges by identifying and retaining the most informative samples, constructing a compact subset for target domain training. However, current methods primarily rely on instance-level difficulty assessments, overlooking crucial category-level characteristics and consequently under-representing minority classes. To overcome this limitation, we propose Non-Uniform Class-Wise Coreset Selection (NUCS), a novel framework that integrates both class-level and instance-level criteria. NUCS automatically allocates data selection budgets for each class based on intrinsic category difficulty and adaptively selects samples within optimal difficulty ranges. By explicitly incorporating category-specific insights, our approach achieves a more balanced and representative coreset, addressing key shortcomings of prior methods. Comprehensive theoretical analysis validates the rationale behind adaptive budget allocation and sample selection, while extensive experiments across 14 diverse datasets and model architectures demonstrate NUCS's consistent improvements over state-of-the-art methods, achieving superior accuracy and computational efficiency. Notably, on CIFAR100 and Food101, NUCS matches full-data training accuracy while retaining just 30% of samples and reducing computation time by 60%. Our work highlights the importance of characterizing category difficulty in coreset selection, offering a robust and data-efficient solution for transfer learning.", 'abstract_zh': '基于类别和实例准则的非均匀类别级核心样本选择（NUCS）', 'title_zh': '非均匀类别自举选择：表征数据高效迁移学习中的类别难度'}
{'arxiv_id': 'arXiv:2504.13224', 'title': 'ICAS: IP Adapter and ControlNet-based Attention Structure for Multi-Subject Style Transfer Optimization', 'authors': 'Fuwei Liu', 'link': 'https://arxiv.org/abs/2504.13224', 'abstract': 'Generating multi-subject stylized images remains a significant challenge due to the ambiguity in defining style attributes (e.g., color, texture, atmosphere, and structure) and the difficulty in consistently applying them across multiple subjects. Although recent diffusion-based text-to-image models have achieved remarkable progress, existing methods typically rely on computationally expensive inversion procedures or large-scale stylized datasets. Moreover, these methods often struggle with maintaining multi-subject semantic fidelity and are limited by high inference costs. To address these limitations, we propose ICAS (IP-Adapter and ControlNet-based Attention Structure), a novel framework for efficient and controllable multi-subject style transfer. Instead of full-model tuning, ICAS adaptively fine-tunes only the content injection branch of a pre-trained diffusion model, thereby preserving identity-specific semantics while enhancing style controllability. By combining IP-Adapter for adaptive style injection with ControlNet for structural conditioning, our framework ensures faithful global layout preservation alongside accurate local style synthesis. Furthermore, ICAS introduces a cyclic multi-subject content embedding mechanism, which enables effective style transfer under limited-data settings without the need for extensive stylized corpora. Extensive experiments show that ICAS achieves superior performance in structure preservation, style consistency, and inference efficiency, establishing a new paradigm for multi-subject style transfer in real-world applications.', 'abstract_zh': '基于IP-Adapter和ControlNet注意力结构的高效可控多主体风格转换', 'title_zh': 'ICAS：基于IP适配器和ControlNet的多主题风格转换优化注意力结构'}
{'arxiv_id': 'arXiv:2504.13219', 'title': 'Scaling Laws for Data-Efficient Visual Transfer Learning', 'authors': 'Wenxuan Yang, Qingqu Wei, Chenxi Ma, Weimin Tan, Bo Yan', 'link': 'https://arxiv.org/abs/2504.13219', 'abstract': 'Current scaling laws for visual AI models focus predominantly on large-scale pretraining, leaving a critical gap in understanding how performance scales for data-constrained downstream tasks. To address this limitation, this paper establishes the first practical framework for data-efficient scaling laws in visual transfer learning, addressing two fundamental questions: 1) How do scaling behaviors shift when downstream tasks operate with limited data? 2) What governs the efficacy of knowledge distillation under such constraints? Through systematic analysis of vision tasks across data regimes (1K-1M samples), we propose the distillation boundary theory, revealing a critical turning point in distillation efficiency: 1) Distillation superiority: In data-scarce conditions, distilled models significantly outperform their non-distillation counterparts, efficiently leveraging inherited knowledge to compensate for limited training samples. 2) Pre-training dominance: As pre-training data increases beyond a critical threshold, non-distilled models gradually surpass distilled versions, suggesting diminishing returns from knowledge inheritance when sufficient task-specific data becomes available. Empirical validation across various model scales (2.5M to 38M parameters) and data volumes demonstrate these performance inflection points, with error difference curves transitioning from positive to negative values at critical data thresholds, confirming our theoretical predictions. This work redefines scaling laws for data-limited regimes, bridging the knowledge gap between large-scale pretraining and practical downstream adaptation, addressing a critical barrier to understanding vision model scaling behaviors and optimizing computational resource allocation.', 'abstract_zh': '当前视觉AI模型的缩放规律主要集中在大规模预训练上，忽略了在数据受限的下游任务中性能缩放的理解。为解决这一限制，本文建立了首个数据高效缩放定律的实用框架，探讨了两个基本问题：1）当下游任务数据受限时，缩放行为如何变化？2）在这些约束条件下，知识蒸馏的有效性受哪些因素支配？通过系统分析不同数据集规模（1K-1M样本）下的视觉任务，我们提出了蒸馏边界理论，揭示了蒸馏效率的关键转折点：1）蒸馏优越性：在数据稀缺条件下，蒸馏模型显著优于非蒸馏模型，有效利用继承的知识来弥补有限的训练样本。2）预训练主导：随着预训练数据超过一定阈值，非蒸馏模型逐渐超越蒸馏版本，表明当有足够的任务特定数据时，知识继承的益处会逐渐减弱。在不同模型规模（2.5M至38M参数）和数据量下的实验证明了这些性能转折点，在关键数据阈值处误差差异曲线从正值转变为负值，验证了我们的理论预测。本研究重新定义了数据受限条件下缩放定律，填补了大规模预训练与实际下游适应之间知识空白，解决了理解视觉模型缩放行为和优化计算资源分配的关键障碍。', 'title_zh': '数据高效视觉迁移学习的标度律'}
{'arxiv_id': 'arXiv:2504.13205', 'title': 'On-Device Watermarking: A Socio-Technical Imperative For Authenticity In The Age of Generative AI', 'authors': 'Houssam Kherraz', 'link': 'https://arxiv.org/abs/2504.13205', 'abstract': 'As generative AI models produce increasingly realistic output, both academia and industry are focusing on the ability to detect whether an output was generated by an AI model or not. Many of the research efforts and policy discourse are centered around robust watermarking of AI outputs. While plenty of progress has been made, all watermarking and AI detection techniques face severe limitations. In this position paper, we argue that we are adopting the wrong approach, and should instead focus on watermarking via cryptographic signatures trustworthy content rather than AI generated ones. For audio-visual content, in particular, all real content is grounded in the physical world and captured via hardware sensors. This presents a unique opportunity to watermark at the hardware layer, and we lay out a socio-technical framework and draw parallels with HTTPS certification and Blu-Ray verification protocols. While acknowledging implementation challenges, we contend that hardware-based authentication offers a more tractable path forward, particularly from a policy perspective. As generative models approach perceptual indistinguishability, the research community should be wary of being overly optimistic with AI watermarking, and we argue that AI watermarking research efforts are better spent in the text and LLM space, which are ultimately not traceable to a physical sensor.', 'abstract_zh': '随着生成式AI模型产生越来越逼真的输出，学术界和行业界都集中在检测输出是否由AI模型生成的能力上。尽管在这一领域已经取得了不少进展，但所有水印和AI检测技术都面临着严重的局限性。在本文中，我们主张当前采用的方法存在误区，应将重点转向通过可信内容而非AI生成内容进行 cryptographic 签名的水印技术。对于音频-视觉内容而言，所有真实内容都基于物理世界并通过硬件传感器捕捉。这为在硬件层进行水印提供了独特的机会，我们提出了一个社会和技术框架，并将其与HTTPS认证和蓝光验证协议进行了类比。尽管承认实施挑战，我们认为基于硬件的认证提供了更具可行性的前进道路，尤其是在政策层面。当生成模型接近感知上的无差异时，研究界应警惕对AI水印过于乐观的态度，我们主张将AI水印研究的努力投入文本和语言模型领域，这些领域最终无法追溯到物理传感器。', 'title_zh': '设备端水印：生成式AI时代的技术和社会必要性'}
{'arxiv_id': 'arXiv:2504.13203', 'title': 'X-Teaming: Multi-Turn Jailbreaks and Defenses with Adaptive Multi-Agents', 'authors': 'Salman Rahman, Liwei Jiang, James Shiffer, Genglin Liu, Sheriff Issaka, Md Rizwan Parvez, Hamid Palangi, Kai-Wei Chang, Yejin Choi, Saadia Gabriel', 'link': 'https://arxiv.org/abs/2504.13203', 'abstract': 'Multi-turn interactions with language models (LMs) pose critical safety risks, as harmful intent can be strategically spread across exchanges. Yet, the vast majority of prior work has focused on single-turn safety, while adaptability and diversity remain among the key challenges of multi-turn red-teaming. To address these challenges, we present X-Teaming, a scalable framework that systematically explores how seemingly harmless interactions escalate into harmful outcomes and generates corresponding attack scenarios. X-Teaming employs collaborative agents for planning, attack optimization, and verification, achieving state-of-the-art multi-turn jailbreak effectiveness and diversity with success rates up to 98.1% across representative leading open-weight and closed-source models. In particular, X-Teaming achieves a 96.2% attack success rate against the latest Claude 3.7 Sonnet model, which has been considered nearly immune to single-turn attacks. Building on X-Teaming, we introduce XGuard-Train, an open-source multi-turn safety training dataset that is 20x larger than the previous best resource, comprising 30K interactive jailbreaks, designed to enable robust multi-turn safety alignment for LMs. Our work offers essential tools and insights for mitigating sophisticated conversational attacks, advancing the multi-turn safety of LMs.', 'abstract_zh': '多轮交互与语言模型的安全风险：X-Teaming框架及其应用', 'title_zh': 'X-Teaming: 多轮对话脱戒防护与自适应多 Agents 方法'}
{'arxiv_id': 'arXiv:2504.13194', 'title': 'Optimizing Multi-Gateway LoRaWAN via Cloud-Edge Collaboration and Knowledge Distillation', 'authors': 'Hong Yang', 'link': 'https://arxiv.org/abs/2504.13194', 'abstract': 'For large-scale multi-gateway LoRaWAN networks, this study proposes a cloud-edge collaborative resource allocation and decision-making method based on edge intelligence, HEAT-LDL (HEAT-Local Distill Lyapunov), which realizes collaborative decision-making between gateways and terminal nodes. HEAT-LDL combines the Actor-Critic architecture and the Lyapunov optimization method to achieve intelligent downlink control and gateway load balancing. When the signal quality is good, the network server uses the HEAT algorithm to schedule the terminal nodes. To improve the efficiency of autonomous decision-making of terminal nodes, HEAT-LDL performs cloud-edge knowledge distillation on the HEAT teacher model on the terminal node side. When the downlink decision instruction is lost, the terminal node uses the student model and the edge decider based on prior knowledge and local history to make collaborative autonomous decisions. Simulation experiments show that compared with the optimal results of all compared algorithms, HEAT-LDL improves the packet success rate and energy efficiency by 20.5% and 88.1%, respectively.', 'abstract_zh': '面向大型多 gateway LoRaWAN 网络的边缘智能协作资源分配与决策方法：HEAT-LDL（HEAT-Local Distill Lyapunov）方法实现网关与终端节点间的协作决策', 'title_zh': '基于云边协作与知识精炼的多网关LoRaWAN优化'}
{'arxiv_id': 'arXiv:2504.13193', 'title': 'HEAT:History-Enhanced Dual-phase Actor-Critic Algorithm with A Shared Transformer', 'authors': 'Hong Yang', 'link': 'https://arxiv.org/abs/2504.13193', 'abstract': 'For a single-gateway LoRaWAN network, this study proposed a history-enhanced two-phase actor-critic algorithm with a shared transformer algorithm (HEAT) to improve network performance. HEAT considers uplink parameters and often neglected downlink parameters, and effectively integrates offline and online reinforcement learning, using historical data and real-time interaction to improve model performance. In addition, this study developed an open source LoRaWAN network simulator LoRaWANSim. The simulator considers the demodulator lock effect and supports multi-channel, multi-demodulator and bidirectional communication. Simulation experiments show that compared with the best results of all compared algorithms, HEAT improves the packet success rate and energy efficiency by 15% and 95%, respectively.', 'abstract_zh': '针对单网关LoRaWAN网络，本文提出了一种结合历史数据的两阶段actor-critic算法（HEAT），该算法融合了共享变压器结构，并改进了网络性能。HEAT考虑了上行参数和经常被忽视的下行参数，并有效整合了离线和在线强化学习，使用历史数据和实时交互来提高模型性能。此外，本文还开发了一个开源LoRaWAN网络仿真器LoRaWANSim。该仿真器考虑了解调器锁定效应，并支持多通道、多解调器和双向通信。仿真实验表明，与所有比较算法的最优结果相比，HEAT分别将数据包成功率和能效提高了15%和95%。', 'title_zh': 'HEAT：带有共享变压器的历史增强双阶段actor-critic算法'}
{'arxiv_id': 'arXiv:2504.13191', 'title': 'Universal Representations for Classification-enhanced Lossy Compression', 'authors': 'Nam Nguyen', 'link': 'https://arxiv.org/abs/2504.13191', 'abstract': 'In lossy compression, the classical tradeoff between compression rate and reconstruction distortion has traditionally guided algorithm design. However, Blau and Michaeli [5] introduced a generalized framework, known as the rate-distortion-perception (RDP) function, incorporating perceptual quality as an additional dimension of evaluation. More recently, the rate-distortion-classification (RDC) function was investigated in [19], evaluating compression performance by considering classification accuracy alongside distortion. In this paper, we explore universal representations, where a single encoder is developed to achieve multiple decoding objectives across various distortion and classification (or perception) constraints. This universality avoids retraining encoders for each specific operating point within these tradeoffs. Our experimental validation on the MNIST dataset indicates that a universal encoder incurs only minimal performance degradation compared to individually optimized encoders for perceptual image compression tasks, aligning with prior results from [23]. Nonetheless, we also identify that in the RDC setting, reusing an encoder optimized for one specific classification-distortion tradeoff leads to a significant distortion penalty when applied to alternative points.', 'abstract_zh': '基于率失真感知的压缩算法设计：从RDP到RDC函数的研究', 'title_zh': '分类增强的失真压缩的通用表示'}
{'arxiv_id': 'arXiv:2504.13186', 'title': 'Advanced Deep Learning and Large Language Models: Comprehensive Insights for Cancer Detection', 'authors': 'Yassine Habchi, Hamza Kheddar, Yassine Himeur, Adel Belouchrani, Erchin Serpedin, Fouad Khelifi, Muhammad E.H. Chowdhury', 'link': 'https://arxiv.org/abs/2504.13186', 'abstract': "The rapid advancement of deep learning (DL) has transformed healthcare, particularly in cancer detection and diagnosis. DL surpasses traditional machine learning and human accuracy, making it a critical tool for identifying diseases. Despite numerous reviews on DL in healthcare, a comprehensive analysis of its role in cancer detection remains limited. Existing studies focus on specific aspects, leaving gaps in understanding its broader impact. This paper addresses these gaps by reviewing advanced DL techniques, including transfer learning (TL), reinforcement learning (RL), federated learning (FL), Transformers, and large language models (LLMs). These approaches enhance accuracy, tackle data scarcity, and enable decentralized learning while maintaining data privacy. TL adapts pre-trained models to new datasets, improving performance with limited labeled data. RL optimizes diagnostic pathways and treatment strategies, while FL fosters collaborative model development without sharing sensitive data. Transformers and LLMs, traditionally used in natural language processing, are now applied to medical data for improved interpretability. Additionally, this review examines these techniques' efficiency in cancer diagnosis, addresses challenges like data imbalance, and proposes solutions. It serves as a resource for researchers and practitioners, providing insights into current trends and guiding future research in advanced DL for cancer detection.", 'abstract_zh': '深度学习在癌症检测中的快速发展及其广泛应用：转移学习、强化学习、联邦学习、变换器和大型语言模型的综述', 'title_zh': '高级深度学习与大型语言模型：癌症检测的全面洞见'}
{'arxiv_id': 'arXiv:2504.13183', 'title': 'Factors That Influence the Adoption of AI-enabled Conversational Agents (AICAs) as an Augmenting Therapeutic Tool by Frontline Healthcare Workers: From Technology Acceptance Model 3 (TAM3) Lens -- A Systematic Mapping Review', 'authors': 'Rawan AlMakinah', 'link': 'https://arxiv.org/abs/2504.13183', 'abstract': "Artificial intelligent (AI) conversational agents hold a promising future in the field of mental health, especially in helping marginalized communities that lack access to mental health support services. It is tempting to have a 24/7 mental health companion that can be accessed anywhere using mobile phones to provide therapist-like advice. Yet, caution should be taken, and studies around their feasibility need to be surveyed. Before adopting such a rapidly changing technology, studies on its feasibility should be explored, summarized, and synthesized to gain a solid understanding of the status quo and to enable us to build a framework that can guide us throughout the development and deployment processes. Different perspectives must be considered when investigating the feasibility of AI conversational agents, including the mental healthcare professional perspective. The literature can provide insights into their perspectives in terms of opportunities, concerns, and implications. Mental health professionals, the subject-matter experts in this field, have their points of view that should be understood and considered. This systematic literature review will explore mental health practitioners' attitudes toward AI conversational agents and the factors that affect their adoption and recommendation of the technology to augment their services and treatments. The TAM3 Framework will be the lens through which this systematic literature review will be conducted.", 'abstract_zh': '人工智能（AI）对话代理在心理健康领域拥有广阔的应用前景，尤其有助于缺乏心理健康支持服务的边缘化社区。拥有一个24/7的心理健康同伴，可以通过手机随时随地提供类似 therapists 的建议，这是颇具吸引力的。然而，需要谨慎，关于其可行性的研究也需要进行调查。在采用这种迅速变革的技术之前，应该探索、总结和综合相关研究，以获得现状的坚实理解，并帮助我们构建一个可以指导整个开发和部署过程的框架。在调查AI对话代理的可行性时，必须考虑不同的视角，包括心理健康专业人员的视角。文献可以提供关于其机会、担忧和影响方面的见解。心理健康专业人员作为这一领域的专家，他们的观点应当被理解和考虑。本系统综述将探讨心理健康从业者对AI对话代理的态度及其影响其采用和推荐该技术以增强其服务和治疗的因素。本系统综述将通过TAM3框架进行。', 'title_zh': '面向前线医疗工作者的AI驱动对话代理（AICAs）作为增强性治疗工具的采用影响因素：基于Technology Acceptance Model 3（TAM3）的系统映射综述'}
