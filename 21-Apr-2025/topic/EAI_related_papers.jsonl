{'arxiv_id': 'arXiv:2504.13803', 'title': 'Imitation Learning with Precisely Labeled Human Demonstrations', 'authors': 'Yilong Song', 'link': 'https://arxiv.org/abs/2504.13803', 'abstract': "Within the imitation learning paradigm, training generalist robots requires large-scale datasets obtainable only through diverse curation. Due to the relative ease to collect, human demonstrations constitute a valuable addition when incorporated appropriately. However, existing methods utilizing human demonstrations face challenges in inferring precise actions, ameliorating embodiment gaps, and fusing with frontier generalist robot training pipelines. In this work, building on prior studies that demonstrate the viability of using hand-held grippers for efficient data collection, we leverage the user's control over the gripper's appearance--specifically by assigning it a unique, easily segmentable color--to enable simple and reliable application of the RANSAC and ICP registration method for precise end-effector pose estimation. We show in simulation that precisely labeled human demonstrations on their own allow policies to reach on average 88.1% of the performance of using robot demonstrations, and boost policy performance when combined with robot demonstrations, despite the inherent embodiment gap.", 'abstract_zh': '基于模仿学习范式，通过多样化的收集获取大规模数据是训练通用机器人所必需的。适当整合人类演示对数据收集具有宝贵的补充价值。然而，现有利用人类演示的方法在精确行为推理、弥补实体差距以及与前沿通用机器人训练管道融合方面面临挑战。在此工作中，我们借鉴了先前研究中展示的有效使用手持式夹具进行高效数据收集的能力，通过赋予夹具独特的、易于分割的颜色，使用户能够控制夹具的外观，从而简化并提高了使用RANSAC和ICP配准方法进行精确末端执行器姿态估计的可靠性和简便性。仿真结果表明，单独使用精确标记的人类演示可以使策略达到使用机器人演示时性能的平均88.1%，并且与机器人演示结合使用时还能进一步提升策略性能，尽管存在固有的实体差距。', 'title_zh': '精准标注的人类示范的模仿学习'}
{'arxiv_id': 'arXiv:2504.13672', 'title': 'Magnecko: Design and Control of a Quadrupedal Magnetic Climbing Robot', 'authors': 'Stefan Leuthard, Timo Eugster, Nicolas Faesch, Riccardo Feingold, Connor Flynn, Michael Fritsche, Nicolas Hürlimann, Elena Morbach, Fabian Tischhauser, Matthias Müller, Markus Montenegro, Valerio Schelbert, Jia-Ruei Chiu, Philip Arm, Marco Hutter', 'link': 'https://arxiv.org/abs/2504.13672', 'abstract': "Climbing robots hold significant promise for applications such as industrial inspection and maintenance, particularly in hazardous or hard-to-reach environments. This paper describes the quadrupedal climbing robot Magnecko, developed with the major goal of providing a research platform for legged climbing locomotion. With its 12 actuated degrees of freedom arranged in an insect-style joint configuration, Magnecko's high manipulability and high range of motion allow it to handle challenging environments like overcoming concave 90 degree corners. A model predictive controller enables Magnecko to crawl on the ground on horizontal overhangs and on vertical walls. Thanks to the custom actuators and the electro-permanent magnets that are used for adhesion on ferrous surfaces, the system is powerful enough to carry additional payloads of at least 65 percent of its own weight in all orientations. The Magnecko platform serves as a foundation for climbing locomotion in complex three-dimensional environments.", 'abstract_zh': '攀爬机器人在工业检测与维护等领域应用前景显著，尤其在危险或难以到达的环境中。本文介绍了以提供腿式攀爬运动研究平台为主要目标的四足攀爬机器人Magnecko。Magnecko拥有12个可 actuated 的自由度，排列方式类似于昆虫关节，使其具备高操作灵活性和大活动范围，能够应对如克服凹面直角等挑战性环境。模型预测控制算法使Magnecko能够在水平悬挑和垂直墙面爬行。得益于定制化执行器和用于铁磁表面附着的电磁铁，该系统足以在所有姿态下承载自身重量至少65%的额外负载。Magnecko平台为复杂三维环境下的攀爬运动提供了基础。', 'title_zh': 'Magnecko：四足磁吸附爬行机器人设计与控制'}
{'arxiv_id': 'arXiv:2504.13647', 'title': 'Lightweight LiDAR-Camera 3D Dynamic Object Detection and Multi-Class Trajectory Prediction', 'authors': 'Yushen He, Lei Zhao, Tianchen Deng, Zipeng Fang, Weidong Chen', 'link': 'https://arxiv.org/abs/2504.13647', 'abstract': 'Service mobile robots are often required to avoid dynamic objects while performing their tasks, but they usually have only limited computational resources. So we present a lightweight multi-modal framework for 3D object detection and trajectory prediction. Our system synergistically integrates LiDAR and camera inputs to achieve real-time perception of pedestrians, vehicles, and riders in 3D space. The framework proposes two novel modules: 1) a Cross-Modal Deformable Transformer (CMDT) for object detection with high accuracy and acceptable amount of computation, and 2) a Reference Trajectory-based Multi-Class Transformer (RTMCT) for efficient and diverse trajectory prediction of mult-class objects with flexible trajectory lengths. Evaluations on the CODa benchmark demonstrate superior performance over existing methods across detection (+2.03% in mAP) and trajectory prediction (-0.408m in minADE5 of pedestrians) metrics. Remarkably, the system exhibits exceptional deployability - when implemented on a wheelchair robot with an entry-level NVIDIA 3060 GPU, it achieves real-time inference at 13.2 fps. To facilitate reproducibility and practical deployment, we release the related code of the method at this https URL and its ROS inference version at this https URL.', 'abstract_zh': '轻量级多模态3D物体检测与轨迹预测框架', 'title_zh': '轻量级LiDAR-相机三维动态物体检测与多类轨迹预测'}
{'arxiv_id': 'arXiv:2504.13619', 'title': 'Robust Humanoid Walking on Compliant and Uneven Terrain with Deep Reinforcement Learning', 'authors': 'Rohan P. Singh, Mitsuharu Morisawa, Mehdi Benallegue, Zhaoming Xie, Fumio Kanehiro', 'link': 'https://arxiv.org/abs/2504.13619', 'abstract': 'For the deployment of legged robots in real-world environments, it is essential to develop robust locomotion control methods for challenging terrains that may exhibit unexpected deformability and irregularity. In this paper, we explore the application of sim-to-real deep reinforcement learning (RL) for the design of bipedal locomotion controllers for humanoid robots on compliant and uneven terrains. Our key contribution is to show that a simple training curriculum for exposing the RL agent to randomized terrains in simulation can achieve robust walking on a real humanoid robot using only proprioceptive feedback. We train an end-to-end bipedal locomotion policy using the proposed approach, and show extensive real-robot demonstration on the HRP-5P humanoid over several difficult terrains inside and outside the lab environment. Further, we argue that the robustness of a bipedal walking policy can be improved if the robot is allowed to exhibit aperiodic motion with variable stepping frequency. We propose a new control policy to enable modification of the observed clock signal, leading to adaptive gait frequencies depending on the terrain and command velocity. Through simulation experiments, we show the effectiveness of this policy specifically for walking over challenging terrains by controlling swing and stance durations. The code for training and evaluation is available online at this https URL. Demo video is available at this https URL.', 'abstract_zh': '基于仿真实验到现实应用的强化学习 userList 完人力足运动控制器设计：应对 compliant 和 uneven 地形', 'title_zh': '基于深度强化学习的鲁棒类人形机器人在非刚性不平地形上的行走'}
{'arxiv_id': 'arXiv:2504.13618', 'title': 'On the Importance of Tactile Sensing for Imitation Learning: A Case Study on Robotic Match Lighting', 'authors': 'Niklas Funk, Changqi Chen, Tim Schneider, Georgia Chalvatzaki, Roberto Calandra, Jan Peters', 'link': 'https://arxiv.org/abs/2504.13618', 'abstract': 'The field of robotic manipulation has advanced significantly in the last years. At the sensing level, several novel tactile sensors have been developed, capable of providing accurate contact information. On a methodological level, learning from demonstrations has proven an efficient paradigm to obtain performant robotic manipulation policies. The combination of both holds the promise to extract crucial contact-related information from the demonstration data and actively exploit it during policy rollouts. However, despite its potential, it remains an underexplored direction. This work therefore proposes a multimodal, visuotactile imitation learning framework capable of efficiently learning fast and dexterous manipulation policies. We evaluate our framework on the dynamic, contact-rich task of robotic match lighting - a task in which tactile feedback influences human manipulation performance. The experimental results show that adding tactile information into the policies significantly improves performance by over 40%, thereby underlining the importance of tactile sensing for contact-rich manipulation tasks. Project website: this https URL .', 'abstract_zh': '机器人操控领域在过去几年取得了显著进展。在传感层面，开发出了多种新型触觉传感器，能够提供准确的接触信息。在方法层面，从演示中学习已被证明是一种有效的范式，可以获取高性能的机器人操控策略。这两种方法的结合有望从演示数据中提取关键的接触相关信息，并在策略实施中积极加以利用。然而，尽管具有巨大潜力，这一方向 still remains largely unexplored。本工作因此提出了一种多模态的视触觉模仿学习框架，能够高效地学习快速灵巧的操控策略。我们在一个动态且触觉信息丰富的机器人火柴点火任务中评估了该框架，这是一个触觉反馈影响人类操控性能的任务。实验结果表明，将触觉信息加入到策略中可以显著提高性能，超过40%，从而突显了触觉传感对于触觉丰富操控任务的重要性。项目网站: this https URL。', 'title_zh': '触觉感知对于模仿学习的重要性：一项关于机器人击灯任务的研究案例'}
{'arxiv_id': 'arXiv:2504.13582', 'title': 'Hysteresis-Aware Neural Network Modeling and Whole-Body Reinforcement Learning Control of Soft Robots', 'authors': 'Zongyuan Chen, Yan Xia, Jiayuan Liu, Jijia Liu, Wenhao Tang, Jiayu Chen, Feng Gao, Longfei Ma, Hongen Liao, Yu Wang, Chao Yu, Boyu Zhang, Fei Xing', 'link': 'https://arxiv.org/abs/2504.13582', 'abstract': "Soft robots exhibit inherent compliance and safety, which makes them particularly suitable for applications requiring direct physical interaction with humans, such as surgical procedures. However, their nonlinear and hysteretic behavior, resulting from the properties of soft materials, presents substantial challenges for accurate modeling and control. In this study, we present a soft robotic system designed for surgical applications and propose a hysteresis-aware whole-body neural network model that accurately captures and predicts the soft robot's whole-body motion, including its hysteretic behavior. Building upon the high-precision dynamic model, we construct a highly parallel simulation environment for soft robot control and apply an on-policy reinforcement learning algorithm to efficiently train whole-body motion control strategies. Based on the trained control policy, we developed a soft robotic system for surgical applications and validated it through phantom-based laser ablation experiments in a physical environment. The results demonstrate that the hysteresis-aware modeling reduces the Mean Squared Error (MSE) by 84.95 percent compared to traditional modeling methods. The deployed control algorithm achieved a trajectory tracking error ranging from 0.126 to 0.250 mm on the real soft robot, highlighting its precision in real-world conditions. The proposed method showed strong performance in phantom-based surgical experiments and demonstrates its potential for complex scenarios, including future real-world clinical applications.", 'abstract_zh': '软体机器人具有固有的柔顺性和安全性，特别适合需要与人类直接物理互动的应用，如手术程序。然而，由软材料性质引起的非线性和滞回行为给准确建模和控制带来了重大挑战。在本研究中，我们提出了一种设计用于手术应用的软体机器人系统，并提出了一种滞回意识的全身神经网络模型，能够准确捕捉和预测软体机器人的全身运动，包括其滞回行为。基于高精度动力学模型，我们构建了一个高度并行的软体机器人控制仿真环境，并应用了基于策略的强化学习算法高效训练全身运动控制策略。基于训练得到的控制策略，我们开发了一种用于手术应用的软体机器人系统，并通过物理环境中基于仿体的激光消融实验进行了验证。结果显示，滞回意识建模相比传统建模方法将均方误差（MSE）降低了84.95%。部署的控制算法在实际软体机器人上的轨迹跟踪误差范围为0.126至0.250毫米，突显了其在现实条件下的精确性。所提出的方法在基于仿体的手术实验中表现出色，并展示了其在未来复杂场景，包括实际临床应用中的潜力。', 'title_zh': '具有滞回效应意识的神经网络建模与软机器人全身强化学习控制'}
{'arxiv_id': 'arXiv:2504.13461', 'title': "An Addendum to NeBula: Towards Extending TEAM CoSTAR's Solution to Larger Scale Environments", 'authors': 'Ali Agha, Kyohei Otsu, Benjamin Morrell, David D. Fan, Sung-Kyun Kim, Muhammad Fadhil Ginting, Xianmei Lei, Jeffrey Edlund, Seyed Fakoorian, Amanda Bouman, Fernando Chavez, Taeyeon Kim, Gustavo J. Correa, Maira Saboia, Angel Santamaria-Navarro, Brett Lopez, Boseong Kim, Chanyoung Jung, Mamoru Sobue, Oriana Claudia Peltzer, Joshua Ott, Robert Trybula, Thomas Touma, Marcel Kaufmann, Tiago Stegun Vaquero, Torkom Pailevanian, Matteo Palieri, Yun Chang, Andrzej Reinke, Matthew Anderson, Frederik E.T. Schöller, Patrick Spieler, Lillian M. Clark, Avak Archanian, Kenny Chen, Hovhannes Melikyan, Anushri Dixit, Harrison Delecki, Daniel Pastor, Barry Ridge, Nicolas Marchal, Jose Uribe, Sharmita Dey, Kamak Ebadi, Kyle Coble, Alexander Nikitas Dimopoulos, Vivek Thangavelu, Vivek S. Varadharajan, Nicholas Palomo, Antoni Rosinol, Arghya Chatterjee, Christoforos Kanellakis, Bjorn Lindqvist, Micah Corah, Kyle Strickland, Ryan Stonebraker, Michael Milano, Christopher E. Denniston, Sami Sahnoune, Thomas Claudet, Seungwook Lee, Gautam Salhotra, Edward Terry, Rithvik Musuku, Robin Schmid, Tony Tran, Ara Kourchians, Justin Schachter, Hector Azpurua, Levi Resende, Arash Kalantari, Jeremy Nash, Josh Lee, Christopher Patterson, Jennifer G. Blank, Kartik Patath, Yuki Kubo, Ryan Alimo, Yasin Almalioglu, Aaron Curtis, Jacqueline Sly, Tesla Wells, Nhut T. Ho, Mykel Kochenderfer, Giovanni Beltrame, George Nikolakopoulos, David Shim, Luca Carlone, Joel Burdick', 'link': 'https://arxiv.org/abs/2504.13461', 'abstract': "This paper presents an appendix to the original NeBula autonomy solution developed by the TEAM CoSTAR (Collaborative SubTerranean Autonomous Robots), participating in the DARPA Subterranean Challenge. Specifically, this paper presents extensions to NeBula's hardware, software, and algorithmic components that focus on increasing the range and scale of the exploration environment. From the algorithmic perspective, we discuss the following extensions to the original NeBula framework: (i) large-scale geometric and semantic environment mapping; (ii) an adaptive positioning system; (iii) probabilistic traversability analysis and local planning; (iv) large-scale POMDP-based global motion planning and exploration behavior; (v) large-scale networking and decentralized reasoning; (vi) communication-aware mission planning; and (vii) multi-modal ground-aerial exploration solutions. We demonstrate the application and deployment of the presented systems and solutions in various large-scale underground environments, including limestone mine exploration scenarios as well as deployment in the DARPA Subterranean challenge.", 'abstract_zh': '本文提供了由TEAM CoSTAR（协作地下自治机器人团队）开发的原始NeBula自主解决方案的附录，参与了DARPA地下挑战赛。具体而言，本文介绍了针对NeBula硬件、软件和算法组件的扩展，重点在于扩大探索环境的范围和规模。从算法角度来看，我们讨论了原始NeBula框架的以下扩展：(i) 大区域几何和语义环境建图；(ii) 适应性定位系统；(iii) 或然可通行性分析和局部规划；(iv) 基于大规模POMDP的全局运动规划和探索行为；(v) 大规模网络和去中心化推理；(vi) 通信意识的任务规划；以及(vii) 多模态地面-空中探索解决方案。我们展示了所提出系统的应用和部署在各种大型地下环境中，包括石灰岩矿井探索场景以及DARPA地下挑战赛中的部署。', 'title_zh': 'NeBula的补充：朝向扩展TEAM CoSTAR解决方案以应对更大规模环境的方向'}
{'arxiv_id': 'arXiv:2504.13351', 'title': 'Chain-of-Modality: Learning Manipulation Programs from Multimodal Human Videos with Vision-Language-Models', 'authors': 'Chen Wang, Fei Xia, Wenhao Yu, Tingnan Zhang, Ruohan Zhang, C. Karen Liu, Li Fei-Fei, Jie Tan, Jacky Liang', 'link': 'https://arxiv.org/abs/2504.13351', 'abstract': 'Learning to perform manipulation tasks from human videos is a promising approach for teaching robots. However, many manipulation tasks require changing control parameters during task execution, such as force, which visual data alone cannot capture. In this work, we leverage sensing devices such as armbands that measure human muscle activities and microphones that record sound, to capture the details in the human manipulation process, and enable robots to extract task plans and control parameters to perform the same task. To achieve this, we introduce Chain-of-Modality (CoM), a prompting strategy that enables Vision Language Models to reason about multimodal human demonstration data -- videos coupled with muscle or audio signals. By progressively integrating information from each modality, CoM refines a task plan and generates detailed control parameters, enabling robots to perform manipulation tasks based on a single multimodal human video prompt. Our experiments show that CoM delivers a threefold improvement in accuracy for extracting task plans and control parameters compared to baselines, with strong generalization to new task setups and objects in real-world robot experiments. Videos and code are available at this https URL', 'abstract_zh': '从人类视频学习执行操作任务是教机器人的一种有前景的方法。然而，许多操作任务在执行过程中需要更改控制参数，例如力，而仅凭视觉数据无法捕捉到这些信息。在这项工作中，我们利用臂环等传感设备测量人体肌肉活动以及录音设备记录声音，以捕捉人类操作过程中的细节，并使机器人能够提取任务计划和控制参数以完成相同任务。为此，我们引入了一种模态链（Chain-of-Modality，CoM）的提示策略，该策略使视觉语言模型能够推理多模态的人类示范数据——视频结合肌肉或音频信号。通过逐步整合不同模态的信息，CoM细化任务计划并生成详细的控制参数，从而使机器人能够基于单一的多模态人类视频提示执行操作任务。我们的实验表明，与基线方法相比，CoM在提取任务计划和控制参数方面提高了三倍准确性，并且在真实世界机器人实验中对新任务设置和对象具有较强的泛化能力。相关视频和代码可在此链接获取。', 'title_zh': '模态链：基于多模态人类视频的学习操作程序方法'}
{'arxiv_id': 'arXiv:2504.13554', 'title': 'Task Assignment and Exploration Optimization for Low Altitude UAV Rescue via Generative AI Enhanced Multi-agent Reinforcement Learning', 'authors': 'Xin Tang, Qian Chen, Wenjie Weng, Chao Jin, Zhang Liu, Jiacheng Wang, Geng Sun, Xiaohuan Li, Dusit Niyato', 'link': 'https://arxiv.org/abs/2504.13554', 'abstract': "Artificial Intelligence (AI)-driven convolutional neural networks enhance rescue, inspection, and surveillance tasks performed by low-altitude uncrewed aerial vehicles (UAVs) and ground computing nodes (GCNs) in unknown environments. However, their high computational demands often exceed a single UAV's capacity, leading to system instability, further exacerbated by the limited and dynamic resources of GCNs. To address these challenges, this paper proposes a novel cooperation framework involving UAVs, ground-embedded robots (GERs), and high-altitude platforms (HAPs), which enable resource pooling through UAV-to-GER (U2G) and UAV-to-HAP (U2H) communications to provide computing services for UAV offloaded tasks. Specifically, we formulate the multi-objective optimization problem of task assignment and exploration optimization in UAVs as a dynamic long-term optimization problem. Our objective is to minimize task completion time and energy consumption while ensuring system stability over time. To achieve this, we first employ the Lyapunov optimization technique to transform the original problem, with stability constraints, into a per-slot deterministic problem. We then propose an algorithm named HG-MADDPG, which combines the Hungarian algorithm with a generative diffusion model (GDM)-based multi-agent deep deterministic policy gradient (MADDPG) approach. We first introduce the Hungarian algorithm as a method for exploration area selection, enhancing UAV efficiency in interacting with the environment. We then innovatively integrate the GDM and multi-agent deep deterministic policy gradient (MADDPG) to optimize task assignment decisions, such as task offloading and resource allocation. Simulation results demonstrate the effectiveness of the proposed approach, with significant improvements in task offloading efficiency, latency reduction, and system stability compared to baseline methods.", 'abstract_zh': '基于人工智能驱动的卷积神经网络增强低空无人机和地面计算节点在未知环境中的救援、检查和 surveillance 任务，但其高计算需求通常超出单个无人机的能力，导致系统不稳定，进一步加剧了地面计算节点有限且动态的资源限制。为解决这些挑战，本文提出一种涉及无人机、地面嵌入式机器人和高空平台的新型合作框架，通过无人机到地面嵌入式机器人（U2G）和无人机到高空平台（U2H）通信实现资源池化，为卸载到无人机的任务提供计算服务。具体而言，我们将无人机中的任务分配和探索优化问题形式化为动态长期优化问题。我们的目标是在确保系统长期稳定的同时，最小化任务完成时间和能耗。为此，我们首先采用李雅普诺夫优化技术将原始问题（带有稳定约束）转化为每时段的确定性问题。然后，我们提出了一个名为HG-MADDPG的算法，该算法结合了匈牙利算法和基于生成扩散模型（GDM）的多智能体深度确定性策略梯度（MADDPG）方法。我们首先介绍了匈牙利算法作为探索区域选择的方法，增强无人机与环境的交互效率。然后，我们创新性地将GDM和多智能体深度确定性策略梯度（MADDPG）结合，优化任务分配决策，如任务卸载和资源分配。仿真结果证明了所提出方法的有效性，与基准方法相比，在任务卸载效率、延迟减少和系统稳定性方面取得了显著改进。', 'title_zh': '基于生成AI增强的多agent强化学习的低空无人机救援任务分配与探索优化'}
{'arxiv_id': 'arXiv:2504.13541', 'title': 'SwitchMT: An Adaptive Context Switching Methodology for Scalable Multi-Task Learning in Intelligent Autonomous Agents', 'authors': 'Avaneesh Devkota, Rachmad Vidya Wicaksana Putra, Muhammad Shafique', 'link': 'https://arxiv.org/abs/2504.13541', 'abstract': 'The ability to train intelligent autonomous agents (such as mobile robots) on multiple tasks is crucial for adapting to dynamic real-world environments. However, state-of-the-art reinforcement learning (RL) methods only excel in single-task settings, and still struggle to generalize across multiple tasks due to task interference. Moreover, real-world environments also demand the agents to have data stream processing capabilities. Toward this, a state-of-the-art work employs Spiking Neural Networks (SNNs) to improve multi-task learning by exploiting temporal information in data stream, while enabling lowpower/energy event-based operations. However, it relies on fixed context/task-switching intervals during its training, hence limiting the scalability and effectiveness of multi-task learning. To address these limitations, we propose SwitchMT, a novel adaptive task-switching methodology for RL-based multi-task learning in autonomous agents. Specifically, SwitchMT employs the following key ideas: (1) a Deep Spiking Q-Network with active dendrites and dueling structure, that utilizes task-specific context signals to create specialized sub-networks; and (2) an adaptive task-switching policy that leverages both rewards and internal dynamics of the network parameters. Experimental results demonstrate that SwitchMT achieves superior performance in multi-task learning compared to state-of-the-art methods. It achieves competitive scores in multiple Atari games (i.e., Pong: -8.8, Breakout: 5.6, and Enduro: 355.2) compared to the state-of-the-art, showing its better generalized learning capability. These results highlight the effectiveness of our SwitchMT methodology in addressing task interference while enabling multi-task learning automation through adaptive task switching, thereby paving the way for more efficient generalist agents with scalable multi-task learning capabilities.', 'abstract_zh': '基于 reinforcement learning 的自主智能代理多任务学习的自适应任务切换方法', 'title_zh': 'SwitchMT：一种适应性上下文切换方法学，用于智能自主代理的可扩展多任务学习'}
{'arxiv_id': 'arXiv:2504.13344', 'title': 'Adaptive AI decision interface for autonomous electronic material discovery', 'authors': 'Yahao Dai, Henry Chan, Aikaterini Vriza, Fredrick Kim, Yunfei Wang, Wei Liu, Naisong Shan, Jing Xu, Max Weires, Yukun Wu, Zhiqiang Cao, C. Suzanne Miller, Ralu Divan, Xiaodan Gu, Chenhui Zhu, Sihong Wang, Jie Xu', 'link': 'https://arxiv.org/abs/2504.13344', 'abstract': 'AI-powered autonomous experimentation (AI/AE) can accelerate materials discovery but its effectiveness for electronic materials is hindered by data scarcity from lengthy and complex design-fabricate-test-analyze cycles. Unlike experienced human scientists, even advanced AI algorithms in AI/AE lack the adaptability to make informative real-time decisions with limited datasets. Here, we address this challenge by developing and implementing an AI decision interface on our AI/AE system. The central element of the interface is an AI advisor that performs real-time progress monitoring, data analysis, and interactive human-AI collaboration for actively adapting to experiments in different stages and types. We applied this platform to an emerging type of electronic materials-mixed ion-electron conducting polymers (MIECPs) -- to engineer and study the relationships between multiscale morphology and properties. Using organic electrochemical transistors (OECT) as the testing-bed device for evaluating the mixed-conducting figure-of-merit -- the product of charge-carrier mobility and the volumetric capacitance ({\\mu}C*), our adaptive AI/AE platform achieved a 150% increase in {\\mu}C* compared to the commonly used spin-coating method, reaching 1,275 F cm-1 V-1 s-1 in just 64 autonomous experimental trials. A study of 10 statistically selected samples identifies two key structural factors for achieving higher volumetric capacitance: larger crystalline lamellar spacing and higher specific surface area, while also uncovering a new polymer polymorph in this material.', 'abstract_zh': '基于AI的自主实验（AI/AE）可加速材料发现，但其在电子材料领域的有效性受限于 lengthy 和复杂的设计-制造-测试-分析循环导致的数据稀缺性。与经验丰富的科研人员不同，即使在AI/AE中，最先进的AI算法也无法在数据量有限的情况下做出有信息性的实时决策。为此，我们开发并实现了一个AI决策界面，该界面的核心是实时进行进程监控、数据解析和人机交互协作的AI顾问，以根据不同阶段和类型的实验进行主动适应。我们将该平台应用于一种新兴的电子材料——混合离子-电子导电聚合物（MIECPs），以工程化并研究多尺度形态与性能之间的关系。通过使用有机电化学晶体管（OECT）作为评估混合传导电学性能（电荷载流子迁移率与体积电容的乘积，μC*）的方法学测试设备，我们的自适应AI/AE平台在64次自主实验中实现了μC*值150%的提升，达到1,275 F cm-1 V-1 s-1。通过对10个统计选择样本的研究，我们发现实现更高体积电容的两个关键结构因素是较大的结晶板状间距和更高的比表面积，同时揭示了该材料中的一种新的聚合物晶型。', 'title_zh': '自适应人工智能决策接口在自主电子材料发现中的应用'}
{'arxiv_id': 'arXiv:2504.13209', 'title': 'On the Feasibility of Using MultiModal LLMs to Execute AR Social Engineering Attacks', 'authors': 'Ting Bi, Chenghang Ye, Zheyu Yang, Ziyi Zhou, Cui Tang, Jun Zhang, Zui Tao, Kailong Wang, Liting Zhou, Yang Yang, Tianlong Yu', 'link': 'https://arxiv.org/abs/2504.13209', 'abstract': "Augmented Reality (AR) and Multimodal Large Language Models (LLMs) are rapidly evolving, providing unprecedented capabilities for human-computer interaction. However, their integration introduces a new attack surface for social engineering. In this paper, we systematically investigate the feasibility of orchestrating AR-driven Social Engineering attacks using Multimodal LLM for the first time, via our proposed SEAR framework, which operates through three key phases: (1) AR-based social context synthesis, which fuses Multimodal inputs (visual, auditory and environmental cues); (2) role-based Multimodal RAG (Retrieval-Augmented Generation), which dynamically retrieves and integrates contextual data while preserving character differentiation; and (3) ReInteract social engineering agents, which execute adaptive multiphase attack strategies through inference interaction loops. To verify SEAR, we conducted an IRB-approved study with 60 participants in three experimental configurations (unassisted, AR+LLM, and full SEAR pipeline) compiling a new dataset of 180 annotated conversations in simulated social scenarios. Our results show that SEAR is highly effective at eliciting high-risk behaviors (e.g., 93.3% of participants susceptible to email phishing). The framework was particularly effective in building trust, with 85% of targets willing to accept an attacker's call after an interaction. Also, we identified notable limitations such as ``occasionally artificial'' due to perceived authenticity gaps. This work provides proof-of-concept for AR-LLM driven social engineering attacks and insights for developing defensive countermeasures against next-generation augmented reality threats.", 'abstract_zh': '增强现实（AR）和多模态大规模语言模型（LLMs）正在迅速发展，为人类计算机交互提供了前所未有的能力。然而，它们的集成引入了新的社会工程攻击表面。本文首次通过我们提出的SEAR框架系统地探讨了使用多模态LLM orchestrating AR驱动的社会工程攻击的可行性，该框架分为三个关键阶段：（1）基于AR的社会背景合成，融合多模态输入（视觉、听觉和环境线索）；（2）基于角色的多模态RAG（检索增强生成），动态检索和整合上下文数据并保留角色差异化；（3）ReInteract社会工程代理，通过推理交互循环执行适应性多阶段攻击策略。为了验证SEAR，我们获得了IRB批准，在三组实验配置（未辅助、AR+LLM和全套SEAR流水线）下对60名参与者进行了研究，构建了一个包含180个标注对话的新数据集，以模拟社交场景。研究结果显示，SEAR在诱使高风险行为（例如，93.3%的参与者容易受到电子邮件钓鱼攻击）方面非常有效。该框架在建立信任方面特别有效，85%的目标对象在交互后愿意接受攻击者的电话。此外，我们还发现了一些明显的局限性，如“有时显得不自然”，这与感知的真实性差距有关。本研究提供了AR-LLM驱动的社会工程攻击的概念验证，并为对抗下一代增强现实威胁的发展性防御措施提供了见解。', 'title_zh': '关于使用多模态大语言模型执行AR社会工程攻击的可行性研究'}
