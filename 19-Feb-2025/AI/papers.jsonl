{'arxiv_id': 'arXiv:2502.13138', 'title': 'AIDE: AI-Driven Exploration in the Space of Code', 'authors': 'Zhengyao Jiang, Dominik Schmidt, Dhruv Srikanth, Dixing Xu, Ian Kaplan, Deniss Jacenko, Yuxiang Wu', 'link': 'https://arxiv.org/abs/2502.13138', 'abstract': 'Machine learning, the foundation of modern artificial intelligence, has driven innovations that have fundamentally transformed the world. Yet, behind advancements lies a complex and often tedious process requiring labor and compute intensive iteration and experimentation. Engineers and scientists developing machine learning models spend much of their time on trial-and-error tasks instead of conceptualizing innovative solutions or research hypotheses. To address this challenge, we introduce AI-Driven Exploration (AIDE), a machine learning engineering agent powered by large language models (LLMs). AIDE frames machine learning engineering as a code optimization problem, and formulates trial-and-error as a tree search in the space of potential solutions. By strategically reusing and refining promising solutions, AIDE effectively trades computational resources for enhanced performance, achieving state-of-the-art results on multiple machine learning engineering benchmarks, including our Kaggle evaluations, OpenAI MLE-Bench and METRs RE-Bench.', 'abstract_zh': '驱动现代人工智能的机器学习，推动了从根本上转变世界的创新。然而，在进步的背后是一个复杂且often tedious的过程，需要大量的劳动和计算密集型迭代和实验。开发机器学习模型的工程师和科学家们花费大量时间在试错任务上，而不是进行创新性概念构思或研究假说。为应对这一挑战，我们提出了AI驱动探索（AIDE），这是一种由大规模语言模型（LLMs）驱动的机器学习工程代理。AIDE将机器学习工程视为代码优化问题，并将试错过程表述为空间中潜在解决方案的树搜索。通过战略性地重用和改进有希望的解决方案，AIDE有效地用计算资源换取性能提升，在包括我们的Kaggle评估、OpenAI MLE-Bench和METRS RE-Bench等多个机器学习工程基准测试中取得了最先进的结果。', 'title_zh': 'AI驱动的代码空间探索方法'}
{'arxiv_id': 'arXiv:2502.13137', 'title': 'Theorem Prover as a Judge for Synthetic Data Generation', 'authors': 'Joshua Ong Jun Leang, Giwon Hong, Wenda Li, Shay B. Cohen', 'link': 'https://arxiv.org/abs/2502.13137', 'abstract': 'The demand for synthetic data in mathematical reasoning has increased due to its potential to enhance the mathematical capabilities of large language models (LLMs). However, ensuring the validity of intermediate reasoning steps remains a significant challenge, affecting data quality. While formal verification via theorem provers effectively validates LLM reasoning, the autoformalisation of mathematical proofs remains error-prone. In response, we introduce iterative autoformalisation, an approach that iteratively refines theorem prover formalisation to mitigate errors, thereby increasing the execution rate on the Lean prover from 60% to 87%. Building upon that, we introduce Theorem Prover as a Judge (TP-as-a-Judge), a method that employs theorem prover formalisation to rigorously assess LLM intermediate reasoning, effectively integrating autoformalisation with synthetic data generation. Finally, we present Reinforcement Learning from Theorem Prover Feedback (RLTPF), a framework that replaces human annotation with theorem prover feedback in Reinforcement Learning from Human Feedback (RLHF). Across multiple LLMs, applying TP-as-a-Judge and RLTPF improves benchmarks with only 3,508 samples, achieving 5.56% accuracy gain on Mistral-7B for MultiArith, 6.00% on Llama-2-7B for SVAMP, and 3.55% on Llama-3.1-8B for AQUA.', 'abstract_zh': '合成数据在数学推理中的需求由于其增强大型语言模型数学能力的潜力而增加，但确保中间推理步骤的有效性仍然是一个重大挑战，影响数据质量。尽管使用定理证明器的形式验证可以有效验证大型语言模型的推理，但数学证明的形式化仍然容易出错。针对这一问题，我们引入了迭代形式化方法，该方法通过逐步细化定理证明器的形式化表述以减少错误，从而将Lean证明器的执行率从60%提高到87%。在此基础上，我们引入了“证明助手作为裁判”（TP-as-a-Judge）方法，该方法利用定理证明器的形式化表述严格评估大型语言模型的中间推理，有效地将形式化与合成数据生成集成在一起。最后，我们提出了从证明助手反馈强化学习的框架（RLTPF），该框架用证明助手反馈替换人机反馈强化学习（RLHF）中的人类标注。在多种大型语言模型中，采用TP-as-a-Judge和RLTPF仅需3,508个样本就能提升基准测试成绩，分别在Mistral-7B的MultiArith上实现了5.56%的准确率提升，在Llama-2-7B的SVAMP上实现了6.00%的提升，在Llama-3.1-8B的AQUA上实现了3.55%的提升。', 'title_zh': '定理证明器作为合成数据生成的裁判'}
{'arxiv_id': 'arXiv:2502.13131', 'title': 'Rethinking Diverse Human Preference Learning through Principal Component Analysis', 'authors': 'Feng Luo, Rui Yang, Hao Sun, Chunyuan Deng, Jiarui Yao, Jingyan Shen, Huan Zhang, Hanjie Chen', 'link': 'https://arxiv.org/abs/2502.13131', 'abstract': 'Understanding human preferences is crucial for improving foundation models and building personalized AI systems. However, preferences are inherently diverse and complex, making it difficult for traditional reward models to capture their full range. While fine-grained preference data can help, collecting it is expensive and hard to scale. In this paper, we introduce Decomposed Reward Models (DRMs), a novel approach that extracts diverse human preferences from binary comparisons without requiring fine-grained annotations. Our key insight is to represent human preferences as vectors and analyze them using Principal Component Analysis (PCA). By constructing a dataset of embedding differences between preferred and rejected responses, DRMs identify orthogonal basis vectors that capture distinct aspects of preference. These decomposed rewards can be flexibly combined to align with different user needs, offering an interpretable and scalable alternative to traditional reward models. We demonstrate that DRMs effectively extract meaningful preference dimensions (e.g., helpfulness, safety, humor) and adapt to new users without additional training. Our results highlight DRMs as a powerful framework for personalized and interpretable LLM alignment.', 'abstract_zh': '理解人类偏好对于改善基础模型和构建个性化AI系统至关重要。然而，偏好本身是多样且复杂的，传统奖励模型难以捕捉其全部范围。虽然细粒度的偏好数据有助于提高模型性能，但其收集成本高且难以扩展。本文介绍了一种新的Decomposed Reward Models (DRMs) 方法，该方法通过二元比较提取多样化的用户偏好，而不需要细粒度注释。我们的核心洞察是将人类偏好表示为向量，并使用主成分分析（PCA）进行分析。通过构建偏好和非偏好响应嵌入差异的数据集，DRMs识别出能够捕捉偏好不同方面的正交基向量。这些分解后的奖励可以灵活组合，以满足不同的用户需求，提供了一种可解释且可扩展的传统奖励模型的替代方案。我们证明了DRMs能够有效提取有意义的偏好维度（如帮助性、安全性、趣味性），并且可以在无需额外训练的情况下适应新用户。实验结果突出了DRMs作为个性化和可解释的大语言模型对齐的强大框架地位。', 'title_zh': '基于主成分分析重新思考多元人类偏好学习'}
{'arxiv_id': 'arXiv:2502.13107', 'title': 'MatterChat: A Multi-Modal LLM for Material Science', 'authors': 'Yingheng Tang, Wenbin Xu, Jie Cao, Jianzhu Ma, Weilu Gao, Steve Farrell, Benjamin Erichson, Michael W. Mahoney, Andy Nonaka, Zhi Yao', 'link': 'https://arxiv.org/abs/2502.13107', 'abstract': 'Understanding and predicting the properties of inorganic materials is crucial for accelerating advancements in materials science and driving applications in energy, electronics, and beyond. Integrating material structure data with language-based information through multi-modal large language models (LLMs) offers great potential to support these efforts by enhancing human-AI interaction. However, a key challenge lies in integrating atomic structures at full resolution into LLMs. In this work, we introduce MatterChat, a versatile structure-aware multi-modal LLM that unifies material structural data and textual inputs into a single cohesive model. MatterChat employs a bridging module to effectively align a pretrained machine learning interatomic potential with a pretrained LLM, reducing training costs and enhancing flexibility. Our results demonstrate that MatterChat significantly improves performance in material property prediction and human-AI interaction, surpassing general-purpose LLMs such as GPT-4. We also demonstrate its usefulness in applications such as more advanced scientific reasoning and step-by-step material synthesis.', 'abstract_zh': '理解并预测无机材料的性质对于加速材料科学的发展以及推动能源、电子等领域应用至关重要。通过多模态大型语言模型（LLMs）将材料结构数据与基于语言的信息集成，有助于通过增强人机交互来支持这些努力。然而，关键挑战在于将原子结构以全分辨率集成到LLMs中。在本工作中，我们引入了MatterChat，这是一种多功能的结构感知多模态LLM，将材料结构数据和文本输入统一到一个单一的协同模型中。MatterChat采用了一个桥接模块，有效地将预训练的机器学习原子间势能与预训练的LLM对齐，从而降低训练成本并增强灵活性。我们的结果表明，MatterChat在材料性质预测和人机交互方面显著提高了性能，超越了通用的LLM如GPT-4。我们还展示了其在更高级的科学推理和材料合成步骤中的应用价值。', 'title_zh': 'MatterChat: 一种材料科学多模态大语言模型'}
{'arxiv_id': 'arXiv:2502.13069', 'title': 'Interactive Agents to Overcome Ambiguity in Software Engineering', 'authors': 'Sanidhya Vijayvargiya, Xuhui Zhou, Akhila Yerukola, Maarten Sap, Graham Neubig', 'link': 'https://arxiv.org/abs/2502.13069', 'abstract': 'AI agents are increasingly being deployed to automate tasks, often based on ambiguous and underspecified user instructions. Making unwarranted assumptions and failing to ask clarifying questions can lead to suboptimal outcomes, safety risks due to tool misuse, and wasted computational resources. In this work, we study the ability of LLM agents to handle ambiguous instructions in interactive code generation settings by evaluating proprietary and open-weight models on their performance across three key steps: (a) leveraging interactivity to improve performance in ambiguous scenarios, (b) detecting ambiguity, and (c) asking targeted questions. Our findings reveal that models struggle to distinguish between well-specified and underspecified instructions. However, when models interact for underspecified inputs, they effectively obtain vital information from the user, leading to significant improvements in performance and underscoring the value of effective interaction. Our study highlights critical gaps in how current state-of-the-art models handle ambiguity in complex software engineering tasks and structures the evaluation into distinct steps to enable targeted improvements.', 'abstract_zh': 'AI代理在自动化任务中的模糊指令处理能力研究：通过评估proprietary和open-weight模型在交互式代码生成中的表现，考察其实现关键步骤的能力，包括利用互动性提高模糊场景下的性能、检测模糊性以及提出针对性的问题。研究发现模型难以区分明确和模糊的指令，但在处理输入模糊的任务时，通过互动有效获取了用户的重要信息，显著提升了性能，突显了有效互动的价值。本研究指出了当前最先进的模型在复杂软件工程任务中处理模糊性的重要缺陷，并将评估结构化为不同的步骤，以促进针对性的改进。', 'title_zh': '克服软件工程中歧义性的交互式代理'}
{'arxiv_id': 'arXiv:2502.13062', 'title': 'AI-Assisted Decision Making with Human Learning', 'authors': 'Gali Noti, Kate Donahue, Jon Kleinberg, Sigal Oren', 'link': 'https://arxiv.org/abs/2502.13062', 'abstract': 'AI systems increasingly support human decision-making. In many cases, despite the algorithm\'s superior performance, the final decision remains in human hands. For example, an AI may assist doctors in determining which diagnostic tests to run, but the doctor ultimately makes the diagnosis. This paper studies such AI-assisted decision-making settings, where the human learns through repeated interactions with the algorithm. In our framework, the algorithm -- designed to maximize decision accuracy according to its own model -- determines which features the human can consider. The human then makes a prediction based on their own less accurate model. We observe that the discrepancy between the algorithm\'s model and the human\'s model creates a fundamental tradeoff. Should the algorithm prioritize recommending more informative features, encouraging the human to recognize their importance, even if it results in less accurate predictions in the short term until learning occurs? Or is it preferable to forgo educating the human and instead select features that align more closely with their existing understanding, minimizing the immediate cost of learning? This tradeoff is shaped by the algorithm\'s time-discounted objective and the human\'s learning ability. Our results show that optimal feature selection has a surprisingly clean combinatorial characterization, reducible to a stationary sequence of feature subsets that is tractable to compute. As the algorithm becomes more "patient" or the human\'s learning improves, the algorithm increasingly selects more informative features, enhancing both prediction accuracy and the human\'s understanding. Notably, early investment in learning leads to the selection of more informative features than a later investment. We complement our analysis by showing that the impact of errors in the algorithm\'s knowledge is limited as it does not make the prediction directly.', 'abstract_zh': '人工智能系统日益支持人类决策。在许多情况下，尽管算法在性能上表现出色，最终的决策仍由人类作出。例如，AI可以辅助医生确定需要进行的诊断测试，但最终的诊断还是由医生作出。本文研究了此类由AI辅助的决策设置，在这种设置中，人类通过与算法的反复互动进行学习。在我们的框架中，算法旨在根据自己的模型最大化决策准确性，从而决定人类可以考虑哪些特征。人类基于自己不太准确的模型进行预测。我们观察到，算法模型与人类模型之间的差异性造成了一个基本的权衡。算法应优先推荐更多有信息量的特征，促使人类认识到这些特征的重要性，即使在短期内可能导致预测不那么准确，直到学习发生？还是更宜省去对人类的教育，而是选择与他们现有理解更为一致的特征，从而最小化即时学习的成本？这一权衡由算法的时间折扣目标和人类的学习能力所塑造。我们的研究结果表明，最优特征选择具有出乎意料的简洁组合特性，可归约为一个可计算的稳定特征子集序列。随着算法变得“更有耐心”或人性学习能力提升，算法将越来越多地选择更有信息量的特征，从而同时提高预测准确性和人类的理解。值得注意的是，早期的投资于学习会导致比后期投资选择更多的有信息量的特征。我们通过展示算法知识中的错误对其预测影响有限这一点来补充我们的分析，因为算法并不会直接作出预测。', 'title_zh': 'AI辅助决策与人类学习'}
{'arxiv_id': 'arXiv:2502.13025', 'title': 'Agentic Deep Graph Reasoning Yields Self-Organizing Knowledge Networks', 'authors': 'Markus J. Buehler', 'link': 'https://arxiv.org/abs/2502.13025', 'abstract': "We present an agentic, autonomous graph expansion framework that iteratively structures and refines knowledge in situ. Unlike conventional knowledge graph construction methods relying on static extraction or single-pass learning, our approach couples a reasoning-native large language model with a continually updated graph representation. At each step, the system actively generates new concepts and relationships, merges them into a global graph, and formulates subsequent prompts based on its evolving structure. Through this feedback-driven loop, the model organizes information into a scale-free network characterized by hub formation, stable modularity, and bridging nodes that link disparate knowledge clusters. Over hundreds of iterations, new nodes and edges continue to appear without saturating, while centrality measures and shortest path distributions evolve to yield increasingly distributed connectivity. Our analysis reveals emergent patterns, such as the rise of highly connected 'hub' concepts and the shifting influence of 'bridge' nodes, indicating that agentic, self-reinforcing graph construction can yield open-ended, coherent knowledge structures. Applied to materials design problems, we present compositional reasoning experiments by extracting node-specific and synergy-level principles to foster genuinely novel knowledge synthesis, yielding cross-domain ideas that transcend rote summarization and strengthen the framework's potential for open-ended scientific discovery. We discuss other applications in scientific discovery and outline future directions for enhancing scalability and interpretability.", 'abstract_zh': '一种自主的图扩展框架：迭代结构化和精炼知识', 'title_zh': '代理深度图推理构建自组织知识网络'}
{'arxiv_id': 'arXiv:2502.13006', 'title': 'Integrating Reinforcement Learning, Action Model Learning, and Numeric Planning for Tackling Complex Tasks', 'authors': 'Yarin Benyamin, Argaman Mordoch, Shahaf S. Shperberg, Roni Stern', 'link': 'https://arxiv.org/abs/2502.13006', 'abstract': "Automated Planning algorithms require a model of the domain that specifies the preconditions and effects of each action. Obtaining such a domain model is notoriously hard. Algorithms for learning domain models exist, yet it remains unclear whether learning a domain model and planning is an effective approach for numeric planning environments, i.e., where states include discrete and numeric state variables. In this work, we explore the benefits of learning a numeric domain model and compare it with alternative model-free solutions. As a case study, we use two tasks in Minecraft, a popular sandbox game that has been used as an AI challenge. First, we consider an offline learning setting, where a set of expert trajectories are available to learn from. This is the standard setting for learning domain models. We used the Numeric Safe Action Model Learning (NSAM) algorithm to learn a numeric domain model and solve new problems with the learned domain model and a numeric planner. We call this model-based solution NSAM_(+p), and compare it to several model-free Imitation Learning (IL) and Offline Reinforcement Learning (RL) algorithms. Empirical results show that some IL algorithms can learn faster to solve simple tasks, while NSAM_(+p) allows solving tasks that require long-term planning and enables generalizing to solve problems in larger environments. Then, we consider an online learning setting, where learning is done by moving an agent in the environment. For this setting, we introduce RAMP. In RAMP, observations collected during the agent's execution are used to simultaneously train an RL policy and learn a planning domain action model. This forms a positive feedback loop between the RL policy and the learned domain model. We demonstrate experimentally the benefits of using RAMP, showing that it finds more efficient plans and solves more problems than several RL baselines.", 'abstract_zh': '自动规划算法需要一个领域模型，该模型指定了每个操作的先决条件和效果。获得这样的领域模型非常困难。存在学习领域模型的算法，但仍不清楚在包含离散和数值状态变量的数值规划环境中，学习领域模型和规划是否是一种有效的方法。在本文中，我们探索学习数值领域模型的benefits，并将其与无模型解决方案进行比较。作为案例研究，我们在Minecraft中使用了两个任务，这是一个流行的沙盒游戏，曾被用作AI挑战。首先，我们考虑了一个离线学习设置，在该设置中，可用一组专家轨迹来学习。这是学习领域模型的标准设置。我们使用了Numeric Safe Action Model Learning (NSAM)算法来学习数值领域模型，并使用所学到的领域模型和数值规划器解决新问题。我们称之为基于模型的解决方案NSAM_(+p)，并将它与几种无模型的模仿学习（IL）和离线强化学习（RL）算法进行比较。实验结果表明，某些IL算法可以更快地学习解决简单任务，而NSAM_(+p)允许解决需要长期规划的任务，并能够泛化以在较大环境中解决问题。然后，我们考虑了一个在线学习设置，在此设置中，学习是通过在环境中移动代理来完成的。为此设置，我们引入了RAMP。在RAMP中，代理执行期间收集的观察结果被用作同时训练RL策略并学习规划领域动作模型的训练数据。这形成了一种RL策略与所学习领域模型之间的正反馈循环。我们实验展示了使用RAMP的好处，显示它找到了更有效的计划并解决了比几种RL基准更多的问题。', 'title_zh': '结合强化学习、行动模型学习和数值规划以应对复杂任务'}
{'arxiv_id': 'arXiv:2502.13001', 'title': 'You need to MIMIC to get FAME: Solving Meeting Transcript Scarcity with a Multi-Agent Conversations', 'authors': 'Frederic Kirstein, Muneeb Khan, Jan Philip Wahle, Terry Ruas, Bela Gipp', 'link': 'https://arxiv.org/abs/2502.13001', 'abstract': 'Meeting summarization suffers from limited high-quality data, mainly due to privacy restrictions and expensive collection processes. We address this gap with FAME, a dataset of 500 meetings in English and 300 in German produced by MIMIC, our new multi-agent meeting synthesis framework that generates meeting transcripts on a given knowledge source by defining psychologically grounded participant profiles, outlining the conversation, and orchestrating a large language model (LLM) debate. A modular post-processing step refines these outputs, mitigating potential repetitiveness and overly formal tones, ensuring coherent, credible dialogues at scale. We also propose a psychologically grounded evaluation framework assessing naturalness, social behavior authenticity, and transcript difficulties. Human assessments show that FAME approximates real-meeting spontaneity (4.5/5 in naturalness), preserves speaker-centric challenges (3/5 in spoken language), and introduces richer information-oriented difficulty (4/5 in difficulty). These findings highlight that FAME is a good and scalable proxy for real-world meeting conditions. It enables new test scenarios for meeting summarization research and other conversation-centric applications in tasks requiring conversation data or simulating social scenarios under behavioral constraints.', 'abstract_zh': 'FAME：一种基于多智能体的会议合成框架，弥合会议总结数据不足的差距', 'title_zh': '你需要效仿以获得名声：多Agent对话解决会议纪要短缺问题'}
{'arxiv_id': 'arXiv:2502.12995', 'title': 'Free Argumentative Exchanges for Explaining Image Classifiers', 'authors': 'Avinash Kori, Antonio Rago, Francesca Toni', 'link': 'https://arxiv.org/abs/2502.12995', 'abstract': 'Deep learning models are powerful image classifiers but their opacity hinders their trustworthiness. Explanation methods for capturing the reasoning process within these classifiers faithfully and in a clear manner are scarce, due to their sheer complexity and size. We provide a solution for this problem by defining a novel method for explaining the outputs of image classifiers with debates between two agents, each arguing for a particular class. We obtain these debates as concrete instances of Free Argumentative eXchanges (FAXs), a novel argumentation-based multi-agent framework allowing agents to internalise opinions by other agents differently than originally stated. We define two metrics (consensus and persuasion rate) to assess the usefulness of FAXs as argumentative explanations for image classifiers. We then conduct a number of empirical experiments showing that FAXs perform well along these metrics as well as being more faithful to the image classifiers than conventional, non-argumentative explanation methods. All our implementations can be found at this https URL.', 'abstract_zh': '深度学习模型是强大的图像分类器，但其不透明性阻碍了其可信度。由于这些分类器复杂且庞大，忠实且清晰地捕获其推理过程的解释方法相当稀缺。我们通过定义一种新的方法来解决这一问题，即用两个代理之间的辩论来解释图像分类器的输出，每个代理为某个类别进行辩护。我们获得这些辩论的具体实例为一种新的基于论辩的多代理框架——自由论辩交换（FAXs），该框架允许代理以不同于最初陈述的方式内部化其他代理的意见。我们定义了两个指标（共识率和说服率）来评估FAXs作为图像分类器论辩解释的有效性。然后我们进行了一系列实证实验，结果表明FAXs在这些指标上表现良好，并且比传统的非论辩解释方法更忠实于图像分类器。所有我们的实现都可以在以下链接找到：this https URL。', 'title_zh': '自由argue交流以解释图像分类器'}
{'arxiv_id': 'arXiv:2502.12961', 'title': 'Adaptive Tool Use in Large Language Models with Meta-Cognition Trigger', 'authors': 'Wenjun Li, Dexun Li, Kuicai Dong, Cong Zhang, Hao Zhang, Weiwen Liu, Yasheng Wang, Ruiming Tang, Yong Liu', 'link': 'https://arxiv.org/abs/2502.12961', 'abstract': "Large language models (LLMs) have shown remarkable emergent capabilities, transforming the execution of functional tasks by leveraging external tools for complex problems that require specialized processing or real-time data. While existing research expands LLMs access to diverse tools (e.g., program interpreters, search engines, weather/map apps), the necessity of using these tools is often overlooked, leading to indiscriminate tool invocation. This naive approach raises two key issues:(1) increased delays due to unnecessary tool calls, and (2) potential errors resulting from faulty interactions with external tools. In this paper, we introduce meta-cognition as a proxy for LLMs self-assessment of their capabilities, representing the model's awareness of its own limitations. Based on this, we propose MeCo, an adaptive decision-making strategy for external tool use. MeCo quantifies metacognitive scores by capturing high-level cognitive signals in the representation space, guiding when to invoke tools. Notably, MeCo is fine-tuning-free and incurs minimal cost. Our experiments show that MeCo accurately detects LLMs' internal cognitive signals and significantly improves tool-use decision-making across multiple base models and benchmarks.", 'abstract_zh': '大规模语言模型（LLMs）展示了显著的 emergent 能力，通过利用外部工具来执行复杂的任务，这些任务需要专门的处理或实时数据。现有研究虽然扩展了 LLMs 对多样工具的访问（如程序解释器、搜索引擎、天气/地图应用程序），但经常忽视使用这些工具的必要性，导致了工具调用的随意性。这种不成熟的调用方式引发了两个关键问题：（1）由于不必要的工具调用增加了延迟，（2）潜在错误由于与外部工具的错误交互所致。在本文中，我们引入元认知作为 LLMs 自我评估其能力的代理，代表模型对其自身局限性的意识。基于此，我们提出了 MeCo，一种针对外部工具使用的自适应决策策略。MeCo 通过捕捉表示空间中的高层认知信号来量化元认知得分，指导何时调用工具。值得注意的是，MeCo 不依赖于微调且成本低廉。我们的实验表明，MeCo 准确检测了 LLMs 的内部认知信号，并显著改善了多种基础模型和基准上的工具使用决策。', 'title_zh': '大型语言模型中的元认知触发适应性工具使用'}
{'arxiv_id': 'arXiv:2502.12926', 'title': 'Towards more Contextual Agents: An extractor-Generator Optimization Framework', 'authors': 'Mourad Aouini, Jinan Loubani', 'link': 'https://arxiv.org/abs/2502.12926', 'abstract': 'Large Language Model (LLM)-based agents have demonstrated remarkable success in solving complex tasks across a wide range of general-purpose applications. However, their performance often degrades in context-specific scenarios, such as specialized industries or research domains, where the absence of domain-relevant knowledge leads to imprecise or suboptimal outcomes. To address this challenge, our work introduces a systematic approach to enhance the contextual adaptability of LLM-based agents by optimizing their underlying prompts-critical components that govern agent behavior, roles, and interactions. Manually crafting optimized prompts for context-specific tasks is labor-intensive, error-prone, and lacks scalability. In this work, we introduce an Extractor-Generator framework designed to automate the optimization of contextual LLM-based agents. Our method operates through two key stages: (i) feature extraction from a dataset of gold-standard input-output examples, and (ii) prompt generation via a high-level optimization strategy that iteratively identifies underperforming cases and applies self-improvement techniques. This framework substantially improves prompt adaptability by enabling more precise generalization across diverse inputs, particularly in context-specific tasks where maintaining semantic consistency and minimizing error propagation are critical for reliable performance. Although developed with single-stage workflows in mind, the approach naturally extends to multi-stage workflows, offering broad applicability across various agent-based systems. Empirical evaluations demonstrate that our framework significantly enhances the performance of prompt-optimized agents, providing a structured and efficient approach to contextual LLM-based agents.', 'abstract_zh': '基于大型语言模型（LLM）的代理在通用应用领域解决复杂任务方面取得了显著成功，但在特定情境场景中，如专门行业或研究领域，由于缺乏领域相关知识，其性能往往下降至不精确或次优化状态。为解决这一挑战，我们的工作引入了一种系统方法，通过优化底层提示来增强基于LLM的代理的上下文适应性，提示是决定代理行为、角色和交互的关键组件。手动为特定情境任务设计优化提示既耗时又容易出错，且缺乏可扩展性。在本工作中，我们引入了一种提取-生成框架，旨在自动化优化上下文特定的LLM代理。该方法包括两个关键阶段：（i）从金标准输入-输出示例数据集中提取特征；（ii）通过高级优化策略生成提示，该策略迭代识别性能不佳的情况并应用自我改进技术。该框架通过使提示能够更精确地泛化到各种输入，特别是在需要维持语义一致性和最小化错误传播的特定情境任务中，显著提高了提示适应性。尽管该方法最初开发时针对单阶段工作流，但它自然地扩展到多阶段工作流，具有广泛的应用前景。实证评估表明，该框架显著提升了优化提示代理的性能，为上下文特定的LLM代理提供了一种结构化和高效的方法。', 'title_zh': '更加情境化的代理：一种提取-生成优化框架'}
{'arxiv_id': 'arXiv:2502.12876', 'title': 'Continuous Learning Conversational AI: A Personalized Agent Framework via A2C Reinforcement Learning', 'authors': 'Nandakishor M, Anjali M', 'link': 'https://arxiv.org/abs/2502.12876', 'abstract': 'Creating personalized and adaptable conversational AI remains a key challenge. This paper introduces a Continuous Learning Conversational AI (CLCA) approach, implemented using A2C reinforcement learning, to move beyond static Large Language Models (LLMs). We use simulated sales dialogues, generated by LLMs, to train an A2C agent. This agent learns to optimize conversation strategies for personalization, focusing on engagement and delivering value. Our system architecture integrates reinforcement learning with LLMs for both data creation and response selection. This method offers a practical way to build personalized AI companions that evolve through continuous learning, advancing beyond traditional static LLM techniques.', 'abstract_zh': '创建个性化和自适应的对话AI仍然是一个关键挑战。本文介绍了一种连续学习对话AI（CLCA）方法，采用A2C强化学习实现，以超越静态大型语言模型（LLMs）。', 'title_zh': '连续学习对话AI：基于A2C强化学习的个性化代理框架'}
{'arxiv_id': 'arXiv:2502.12842', 'title': 'Towards Adaptive Feedback with AI: Comparing the Feedback Quality of LLMs and Teachers on Experimentation Protocols', 'authors': 'Kathrin Seßler, Arne Bewersdorff, Claudia Nerdel, Enkelejda Kasneci', 'link': 'https://arxiv.org/abs/2502.12842', 'abstract': "Effective feedback is essential for fostering students' success in scientific inquiry. With advancements in artificial intelligence, large language models (LLMs) offer new possibilities for delivering instant and adaptive feedback. However, this feedback often lacks the pedagogical validation provided by real-world practitioners. To address this limitation, our study evaluates and compares the feedback quality of LLM agents with that of human teachers and science education experts on student-written experimentation protocols. Four blinded raters, all professionals in scientific inquiry and science education, evaluated the feedback texts generated by 1) the LLM agent, 2) the teachers and 3) the science education experts using a five-point Likert scale based on six criteria of effective feedback: Feed Up, Feed Back, Feed Forward, Constructive Tone, Linguistic Clarity, and Technical Terminology. Our results indicate that LLM-generated feedback shows no significant difference to that of teachers and experts in overall quality. However, the LLM agent's performance lags in the Feed Back dimension, which involves identifying and explaining errors within the student's work context. Qualitative analysis highlighted the LLM agent's limitations in contextual understanding and in the clear communication of specific errors. Our findings suggest that combining LLM-generated feedback with human expertise can enhance educational practices by leveraging the efficiency of LLMs and the nuanced understanding of educators.", 'abstract_zh': '有效的反馈对于促进学生在科学探究中的成功至关重要。随着人工智能的进步，大型语言模型（LLMs）为即时和自适应反馈提供了新可能性。然而，这种反馈往往缺乏由实际从业者提供的教学验证。为解决这一局限，我们的研究评估并对比了LLM代理与人类教师及科学教育专家在评价学生撰写的实验方案时提供的反馈质量。四位盲评专家，均为科学探究和科学教育领域的专业人士，根据有效反馈的六个标准（Feed Up、Feed Back、Feed Forward、建设性语气、语言清晰度和技术术语），使用五点李克特量表对由1）LLM代理、2）教师和3）科学教育专家生成的反馈文本进行评估。研究结果表明，LLM生成的反馈在总体质量上与教师和专家的反馈无显著差异。然而，LLM代理在Feed Back维度的表现较弱，即在识别和解释学生工作中错误方面表现不佳。定性分析指出，LLM代理在情境理解和具体错误的清晰传达方面存在局限性。研究结果表明，结合LLM生成的反馈和人类专家的见解可以优化教育实践，充分利用LLMs的高效性与教育者的细致理解。', 'title_zh': '面向AI自适应反馈的研究：基于实验协议比较大型语言模型与教师的反馈质量'}
{'arxiv_id': 'arXiv:2502.12782', 'title': 'VidCapBench: A Comprehensive Benchmark of Video Captioning for Controllable Text-to-Video Generation', 'authors': 'Xinlong Chen, Yuanxing Zhang, Chongling Rao, Yushuo Guan, Jiaheng Liu, Fuzheng Zhang, Chengru Song, Qiang Liu, Di Zhang, Tieniu Tan', 'link': 'https://arxiv.org/abs/2502.12782', 'abstract': 'The training of controllable text-to-video (T2V) models relies heavily on the alignment between videos and captions, yet little existing research connects video caption evaluation with T2V generation assessment. This paper introduces VidCapBench, a video caption evaluation scheme specifically designed for T2V generation, agnostic to any particular caption format. VidCapBench employs a data annotation pipeline, combining expert model labeling and human refinement, to associate each collected video with key information spanning video aesthetics, content, motion, and physical laws. VidCapBench then partitions these key information attributes into automatically assessable and manually assessable subsets, catering to both the rapid evaluation needs of agile development and the accuracy requirements of thorough validation. By evaluating numerous state-of-the-art captioning models, we demonstrate the superior stability and comprehensiveness of VidCapBench compared to existing video captioning evaluation approaches. Verification with off-the-shelf T2V models reveals a significant positive correlation between scores on VidCapBench and the T2V quality evaluation metrics, indicating that VidCapBench can provide valuable guidance for training T2V models. The project is available at this https URL.', 'abstract_zh': '可控文本生成视频（T2V）模型的训练高度依赖于视频和字幕的对齐，然而现有研究鲜有关于字幕评估与T2V生成评估的联系。本文介绍了VidCapBench，一种专门用于T2V生成的字幕评估方案，不依赖于任何特定的字幕格式。VidCapBench通过结合专家模型标记和人工完善的数据注释管道，将每个收集到的视频与视频美学、内容、运动和物理法则等关键信息联系起来。VidCapBench随后将这些关键信息属性划分为可自动评估和需要手动评估的子集，以满足敏捷开发的快速评估需求和详尽验证的准确性要求。通过对多种最先进的字幕生成模型进行评估，我们证明了VidCapBench在稳定性和综合性方面相较于现有视频字幕评估方法具有显著优势。利用现成的T2V模型进行验证表明，VidCapBench的评分与T2V质量评估指标之间存在显著的正相关关系，这表明VidCapBench能够为训练T2V模型提供有价值的指导。该项目可在以下链接获取：this https URL。', 'title_zh': 'VidCapBench: 用于可控文本到视频生成的视频字幕综合基准'}
{'arxiv_id': 'arXiv:2502.12669', 'title': 'Perovskite-LLM: Knowledge-Enhanced Large Language Models for Perovskite Solar Cell Research', 'authors': 'Xiang Liu, Penglei Sun, Shuyan Chen, Longhan Zhang, Peijie Dong, Huajie You, Yongqi Zhang, Chang Yan, Xiaowen Chu, Tong-yi Zhang', 'link': 'https://arxiv.org/abs/2502.12669', 'abstract': 'The rapid advancement of perovskite solar cells (PSCs) has led to an exponential growth in research publications, creating an urgent need for efficient knowledge management and reasoning systems in this domain. We present a comprehensive knowledge-enhanced system for PSCs that integrates three key components. First, we develop Perovskite-KG, a domain-specific knowledge graph constructed from 1,517 research papers, containing 23,789 entities and 22,272 relationships. Second, we create two complementary datasets: Perovskite-Chat, comprising 55,101 high-quality question-answer pairs generated through a novel multi-agent framework, and Perovskite-Reasoning, containing 2,217 carefully curated materials science problems. Third, we introduce two specialized large language models: Perovskite-Chat-LLM for domain-specific knowledge assistance and Perovskite-Reasoning-LLM for scientific reasoning tasks. Experimental results demonstrate that our system significantly outperforms existing models in both domain-specific knowledge retrieval and scientific reasoning tasks, providing researchers with effective tools for literature review, experimental design, and complex problem-solving in PSC research.', 'abstract_zh': 'Rapid进展的钙钛矿太阳能电池(PSCs)的研究出版物呈指数增长，迫切需要有效的知识管理与推理系统。我们提出了一种全面的知识增强系统，整合了三个关键组件。首先，我们开发了Perovskite-KG，这是一个由1,517篇研究论文构建的领域特定知识图谱，包含23,789个实体和22,272个关系。其次，我们创建了两个互补的数据集：Perovskite-Chat，包含55,101对高质量的问答对，通过一种新颖的多代理框架生成；和Perovskite-Reasoning，包含2,217个精心挑选的材料科学问题。第三，我们引入了两种专门的大语言模型：Perovskite-Chat-LLM为领域特定知识提供支持，以及Perovskite-Reasoning-LLM用于科学推理任务。实验结果表明，我们的系统在领域特定知识检索和科学推理任务中显著优于现有模型，为研究人员提供了有效的工具，用于文献回顾、实验设计和PSC研究中的复杂问题解决。', 'title_zh': 'Perovskite-LLM：知识增强的大语言模型在钙钛矿太阳能电池研究中的应用'}
{'arxiv_id': 'arXiv:2502.12589', 'title': 'RM-PoT: Reformulating Mathematical Problems and Solving via Program of Thoughts', 'authors': 'Yu Zhang, Shujun Peng, Nengwu Wu, Xinhan Lin, Yang Hu, Jie Tang', 'link': 'https://arxiv.org/abs/2502.12589', 'abstract': 'Recently, substantial advancements have been made in training language models to carry out step-by-step reasoning for solving intricate numerical reasoning tasks. Beyond the methods used to solve these problems, the structure and formulation of the problems themselves also play a crucial role in determining the performance of large language models. We observe that even small changes in the surface form of mathematical problems can have a profound impact on both the answer distribution and solve rate. This highlights the vulnerability of LLMs to surface-level variations, revealing its limited robustness when reasoning through complex problems. In this paper, we propose RM-PoT, a three-stage framework that integrates problem reformulation (RM), code-aided reasoning (PoT), and domain-aware few-shot learning to address these limitations. Our approach first reformulates the input problem into diverse surface forms to reduce structural bias, then retrieves five semantically aligned examples from a pre-constructed domain-specific question bank to provide contextual guidance, and finally generates executable Python code for precise computation.', 'abstract_zh': '最近，训练语言模型进行复杂数值推理的逐步推理方面取得了显著进展。除了解决这些问题所使用的方法外，问题本身的结构和表述形式也对大型语言模型的性能起到了关键作用。我们观察到，即使是数学问题表面形式的小变化也会影响答案分布和解题率，这表明LLMs对表面级变化的脆弱性，揭示了其在处理复杂问题时的有限鲁棒性。在这篇论文中，我们提出了RM-PoT，这是一种结合问题重述(RM)、代码辅助推理(PoT)和领域意识的少样本学习的三阶段框架，以应对这些限制。我们的方法首先将输入问题重新表述为多种表面形式以减少结构偏见，然后从预先构建的领域特定问题库中检索五个语义对齐的示例以提供上下文指导，最后生成可执行的Python代码以实现精确计算。', 'title_zh': 'RM-PoT: 重新表述数学问题并通过思维程序求解'}
{'arxiv_id': 'arXiv:2502.12566', 'title': 'Exploring the Impact of Personality Traits on LLM Bias and Toxicity', 'authors': 'Shuo Wang, Renhao Li, Xi Chen, Yulin Yuan, Derek F. Wong, Min Yang', 'link': 'https://arxiv.org/abs/2502.12566', 'abstract': 'With the different roles that AI is expected to play in human life, imbuing large language models (LLMs) with different personalities has attracted increasing research interests. While the "personification" enhances human experiences of interactivity and adaptability of LLMs, it gives rise to critical concerns about content safety, particularly regarding bias, sentiment and toxicity of LLM generation. This study explores how assigning different personality traits to LLMs affects the toxicity and biases of their outputs. Leveraging the widely accepted HEXACO personality framework developed in social psychology, we design experimentally sound prompts to test three LLMs\' performance on three toxic and bias benchmarks. The findings demonstrate the sensitivity of all three models to HEXACO personality traits and, more importantly, a consistent variation in the biases, negative sentiment and toxicity of their output. In particular, adjusting the levels of several personality traits can effectively reduce bias and toxicity in model performance, similar to humans\' correlations between personality traits and toxic behaviors. The findings highlight the additional need to examine content safety besides the efficiency of training or fine-tuning methods for LLM personification. They also suggest a potential for the adjustment of personalities to be a simple and low-cost method to conduct controlled text generation.', 'abstract_zh': '基于不同人格特质赋予大型语言模型的不同个性对其输出的偏见和毒性影响研究', 'title_zh': '探究人格特质对大语言模型偏差和毒性的影响'}
{'arxiv_id': 'arXiv:2502.12532', 'title': 'CityEQA: A Hierarchical LLM Agent on Embodied Question Answering Benchmark in City Space', 'authors': 'Yong Zhao, Kai Xu, Zhengqiu Zhu, Yue Hu, Zhiheng Zheng, Yingfeng Chen, Yatai Ji, Chen Gao, Yong Li, Jincai Huang', 'link': 'https://arxiv.org/abs/2502.12532', 'abstract': 'Embodied Question Answering (EQA) has primarily focused on indoor environments, leaving the complexities of urban settings - spanning environment, action, and perception - largely unexplored. To bridge this gap, we introduce CityEQA, a new task where an embodied agent answers open-vocabulary questions through active exploration in dynamic city spaces. To support this task, we present CityEQA-EC, the first benchmark dataset featuring 1,412 human-annotated tasks across six categories, grounded in a realistic 3D urban simulator. Moreover, we propose Planner-Manager-Actor (PMA), a novel agent tailored for CityEQA. PMA enables long-horizon planning and hierarchical task execution: the Planner breaks down the question answering into sub-tasks, the Manager maintains an object-centric cognitive map for spatial reasoning during the process control, and the specialized Actors handle navigation, exploration, and collection sub-tasks. Experiments demonstrate that PMA achieves 60.7% of human-level answering accuracy, significantly outperforming frontier-based baselines. While promising, the performance gap compared to humans highlights the need for enhanced visual reasoning in CityEQA. This work paves the way for future advancements in urban spatial intelligence. Dataset and code are available at this https URL.', 'abstract_zh': '基于城市环境的实体化问答（CityEQA）：一种新的任务及其实验研究', 'title_zh': 'CityEQA：城市空间中层次化大语言模型代理的实体问答基准'}
{'arxiv_id': 'arXiv:2502.12521', 'title': 'Inference-Time Computations for LLM Reasoning and Planning: A Benchmark and Insights', 'authors': 'Shubham Parashar, Blake Olson, Sambhav Khurana, Eric Li, Hongyi Ling, James Caverlee, Shuiwang Ji', 'link': 'https://arxiv.org/abs/2502.12521', 'abstract': "We examine the reasoning and planning capabilities of large language models (LLMs) in solving complex tasks. Recent advances in inference-time techniques demonstrate the potential to enhance LLM reasoning without additional training by exploring intermediate steps during inference. Notably, OpenAI's o1 model shows promising performance through its novel use of multi-step reasoning and verification. Here, we explore how scaling inference-time techniques can improve reasoning and planning, focusing on understanding the tradeoff between computational cost and performance. To this end, we construct a comprehensive benchmark, known as Sys2Bench, and perform extensive experiments evaluating existing inference-time techniques on eleven diverse tasks across five categories, including arithmetic reasoning, logical reasoning, common sense reasoning, algorithmic reasoning, and planning. Our findings indicate that simply scaling inference-time computation has limitations, as no single inference-time technique consistently performs well across all reasoning and planning tasks.", 'abstract_zh': '我们考察了大型语言模型（LLMs）在解决复杂任务中的推理和规划能力。通过在推理过程中探索中间步骤，最近在推理时的技术进步展示了在无需额外训练的情况下增强LLM推理的能力。值得注意的是，OpenAI的o1模型通过其新颖的多步推理和验证展示了令人 promise 的性能。在这里，我们探讨了如何通过扩展推理时技术来提高推理和规划能力，重点关注计算成本与性能之间的权衡。为此，我们构建了一个全面的基准，称为Sys2Bench，并在五个类别（包括算术推理、逻辑推理、常识推理、算法推理和规划）下的 eleven 个不同任务上进行了广泛的实验，评估现有的推理时技术。研究发现，仅仅扩展推理时的计算存在局限性，因为没有任何一种推理时技术能够在所有推理和规划任务中表现优异。', 'title_zh': 'Inference时计算在大语言模型推理与规划中的应用：一个基准与见解'}
{'arxiv_id': 'arXiv:2502.12492', 'title': 'Boost, Disentangle, and Customize: A Robust System2-to-System1 Pipeline for Code Generation', 'authors': 'Kounianhua Du, Hanjing Wang, Jianxing Liu, Jizheng Chen, Xinyi Dai, Yasheng Wang, Ruiming Tang, Yong Yu, Jun Wang, Weinan Zhang', 'link': 'https://arxiv.org/abs/2502.12492', 'abstract': 'Large language models (LLMs) have demonstrated remarkable capabilities in various domains, particularly in system 1 tasks, yet the intricacies of their problem-solving mechanisms in system 2 tasks are not sufficiently explored. Recent research on System2-to-System1 methods surge, exploring the System 2 reasoning knowledge via inference-time computation and compressing the explored knowledge into System 1 process. In this paper, we focus on code generation, which is a representative System 2 task, and identify two primary challenges: (1) the complex hidden reasoning processes and (2) the heterogeneous data distributions that complicate the exploration and training of robust LLM solvers. To tackle these issues, we propose a novel BDC framework that explores insightful System 2 knowledge of LLMs using a MC-Tree-Of-Agents algorithm with mutual \\textbf{B}oosting, \\textbf{D}isentangles the heterogeneous training data for composable LoRA-experts, and obtain \\textbf{C}ustomized problem solver for each data instance with an input-aware hypernetwork to weight over the LoRA-experts, offering effectiveness, flexibility, and robustness. This framework leverages multiple LLMs through mutual verification and boosting, integrated into a Monte-Carlo Tree Search process enhanced by reflection-based pruning and refinement. Additionally, we introduce the DisenLora algorithm, which clusters heterogeneous data to fine-tune LLMs into composable Lora experts, enabling the adaptive generation of customized problem solvers through an input-aware hypernetwork. This work lays the groundwork for advancing LLM capabilities in complex reasoning tasks, offering a novel System2-to-System1 solution.', 'abstract_zh': '大型语言模型（LLMs）在各个领域表现出了非凡的能力，特别是在系统1任务中，然而它们在系统2任务中解决问题机制的复杂性尚未得到充分探索。最近关于系统2到系统1方法的研究激增，通过推理时的计算探索系统2的推理知识，并将探索的知识压缩到系统1的过程中。在本文中，我们重点关注代码生成这一代表性的系统2任务，并识别出两大主要挑战：（1）复杂隐藏的推理过程和（2）异质数据分布使得探索和训练鲁棒的LLM求解器变得困难。为解决这些问题，我们提出了一种新颖的BDC框架，利用MC-树代理算法进行互助增强、异质训练数据的分离以及输入感知超网络为每个数据实例获得定制的问题求解器。该框架通过互验和增强的多个LLM集成到一个通过反思剪枝和细化增强的蒙特卡洛树搜索过程。此外，我们引入了DisenLora算法，将异质数据聚类以微调LLM为可组合的Lora专家，通过输入感知超网络实现定制问题求解器的自适应生成。这项工作为提升LLM在复杂推理任务中的能力奠定了基础，提供了一种新颖的系统2到系统1解决方案。', 'title_zh': '增强、解耦和定制：一种稳健的系统2到系统1代码生成管道'}
{'arxiv_id': 'arXiv:2502.12450', 'title': "Investigating and Extending Homans' Social Exchange Theory with Large Language Model based Agents", 'authors': 'Lei Wang, Zheqing Zhang, Xu Chen', 'link': 'https://arxiv.org/abs/2502.12450', 'abstract': "Homans' Social Exchange Theory (SET) is widely recognized as a basic framework for understanding the formation and emergence of human civilizations and social structures. In social science, this theory is typically studied based on simple simulation experiments or real-world human studies, both of which either lack realism or are too expensive to control. In artificial intelligence, recent advances in large language models (LLMs) have shown promising capabilities in simulating human behaviors. Inspired by these insights, we adopt an interdisciplinary research perspective and propose using LLM-based agents to study Homans' SET. Specifically, we construct a virtual society composed of three LLM agents and have them engage in a social exchange game to observe their behaviors. Through extensive experiments, we found that Homans' SET is well validated in our agent society, demonstrating the consistency between the agent and human behaviors. Building on this foundation, we intentionally alter the settings of the agent society to extend the traditional Homans' SET, making it more comprehensive and detailed. To the best of our knowledge, this paper marks the first step in studying Homans' SET with LLM-based agents. More importantly, it introduces a novel and feasible research paradigm that bridges the fields of social science and computer science through LLM-based agents. Code is available at this https URL.", 'abstract_zh': '基于大规模语言模型的代理研究：Homans的社会交换理论及其扩展', 'title_zh': '基于大型语言模型的代理探究和拓展霍曼斯的社会交换理论'}
{'arxiv_id': 'arXiv:2502.12445', 'title': 'Computational Safety for Generative AI: A Signal Processing Perspective', 'authors': 'Pin-Yu Chen', 'link': 'https://arxiv.org/abs/2502.12445', 'abstract': 'AI safety is a rapidly growing area of research that seeks to prevent the harm and misuse of frontier AI technology, particularly with respect to generative AI (GenAI) tools that are capable of creating realistic and high-quality content through text prompts. Examples of such tools include large language models (LLMs) and text-to-image (T2I) diffusion models. As the performance of various leading GenAI models approaches saturation due to similar training data sources and neural network architecture designs, the development of reliable safety guardrails has become a key differentiator for responsibility and sustainability. This paper presents a formalization of the concept of computational safety, which is a mathematical framework that enables the quantitative assessment, formulation, and study of safety challenges in GenAI through the lens of signal processing theory and methods. In particular, we explore two exemplary categories of computational safety challenges in GenAI that can be formulated as hypothesis testing problems. For the safety of model input, we show how sensitivity analysis and loss landscape analysis can be used to detect malicious prompts with jailbreak attempts. For the safety of model output, we elucidate how statistical signal processing and adversarial learning can be used to detect AI-generated content. Finally, we discuss key open research challenges, opportunities, and the essential role of signal processing in computational AI safety.', 'abstract_zh': 'AI安全是快速发展的一个研究领域，旨在防止前沿AI技术带来的危害和滥用，尤其是在生成AI（GenAI）工具方面，这些工具能够通过文本提示生成真实性和高质量的内容。这类工具包括大型语言模型（LLMs）和文本到图像（T2I）扩散模型。随着各种领先的GenAI模型的性能接近饱和，由于类似的数据来源和神经网络架构设计，开发可靠的安全护栏已成为责任和可持续性的关键区别点。本文提出了计算安全这一概念的数学化，这是一种通过信号处理理论和方法来定量评估、形式化和研究GenAI安全挑战的数学框架。特别是，我们探讨了计算安全中两个可以形式化为假设检验问题的范例类别。在模型输入的安全方面，我们展示了如何使用灵敏度分析和损失景观分析来检测具有破解企图的恶意提示。在模型输出的安全方面，我们阐明了如何使用统计信号处理和对抗性学习来检测AI生成的内容。最后，我们讨论了关键的开放性研究挑战、机遇以及信号处理在计算AI安全中的核心作用。', 'title_zh': '生成式AI的计算安全：一个信号处理视角'}
{'arxiv_id': 'arXiv:2502.12435', 'title': 'A Survey on Large Language Models for Automated Planning', 'authors': 'Mohamed Aghzal, Erion Plaku, Gregory J. Stein, Ziyu Yao', 'link': 'https://arxiv.org/abs/2502.12435', 'abstract': 'The planning ability of Large Language Models (LLMs) has garnered increasing attention in recent years due to their remarkable capacity for multi-step reasoning and their ability to generalize across a wide range of domains. While some researchers emphasize the potential of LLMs to perform complex planning tasks, others highlight significant limitations in their performance, particularly when these models are tasked with handling the intricacies of long-horizon reasoning. In this survey, we critically investigate existing research on the use of LLMs in automated planning, examining both their successes and shortcomings in detail. We illustrate that although LLMs are not well-suited to serve as standalone planners because of these limitations, they nonetheless present an enormous opportunity to enhance planning applications when combined with other approaches. Thus, we advocate for a balanced methodology that leverages the inherent flexibility and generalized knowledge of LLMs alongside the rigor and cost-effectiveness of traditional planning methods.', 'abstract_zh': '大型语言模型在自动化规划中的规划能力近年来引起了越来越多的关注，这主要是由于它们在多步推理方面表现出色，并能在广泛的主题领域进行泛化。尽管一些研究人员强调大型语言模型在执行复杂规划任务方面的潜力，但也有人指出，当这些模型被要求处理长周期推理的复杂性时，它们的表现存在显著的局限性。在本次综述中，我们对大型语言模型在自动化规划中的应用进行了批判性评估，详细探讨了它们的成功与不足。我们表明，尽管由于这些局限性，大型语言模型不适合作为独立的规划者，但它们与其它方法结合使用时，仍能提供显著的增强机会。因此，我们建议采用一种平衡的方法，利用大型语言模型固有的灵活性和泛化知识，结合传统规划方法的严谨性和经济性。', 'title_zh': '大型语言模型在自动规划中的研究综述'}
{'arxiv_id': 'arXiv:2502.12275', 'title': 'Integrating Expert Knowledge into Logical Programs via LLMs', 'authors': 'Franciszek Górski, Oskar Wysocki, Marco Valentino, Andre Freitas', 'link': 'https://arxiv.org/abs/2502.12275', 'abstract': 'This paper introduces ExKLoP, a novel framework designed to evaluate how effectively Large Language Models (LLMs) integrate expert knowledge into logical reasoning systems. This capability is especially valuable in engineering, where expert knowledge-such as manufacturer-recommended operational ranges-can be directly embedded into automated monitoring systems. By mirroring expert verification steps, tasks like range checking and constraint validation help ensure system safety and reliability. Our approach systematically evaluates LLM-generated logical rules, assessing both syntactic fluency and logical correctness in these critical validation tasks. We also explore the models capacity for self-correction via an iterative feedback loop based on code execution outcomes. ExKLoP presents an extensible dataset comprising 130 engineering premises, 950 prompts, and corresponding validation points. It enables comprehensive benchmarking while allowing control over task complexity and scalability of experiments. We leverage the synthetic data creation methodology to conduct extensive empirical evaluation on a diverse set of LLMs including Llama3, Gemma, Mixtral, Mistral, and Qwen. Results reveal that while models generate nearly perfect syntactically correct code, they frequently exhibit logical errors in translating expert knowledge. Furthermore, iterative self-correction yields only marginal improvements (up to 3%). Overall, ExKLoP serves as a robust evaluation platform that streamlines the selection of effective models for self-correcting systems while clearly delineating the types of errors encountered. The complete implementation, along with all relevant data, is available at GitHub.', 'abstract_zh': '基于ExKLoP的新框架：评估大型语言模型在逻辑推理系统中整合专家知识的有效性', 'title_zh': '利用大型语言模型将专家知识集成到逻辑程序中'}
{'arxiv_id': 'arXiv:2502.12224', 'title': 'Accurate Expert Predictions in MoE Inference via Cross-Layer Gate', 'authors': 'Zhiyuan Fang, Zicong Hong, Yuegui Huang, Yufeng Lyu, Wuhui Chen, Yue Yu, Fan Yu, Zibin Zheng', 'link': 'https://arxiv.org/abs/2502.12224', 'abstract': "Large Language Models (LLMs) have demonstrated impressive performance across various tasks, and their application in edge scenarios has attracted significant attention. However, sparse-activated Mixture-of-Experts (MoE) models, which are well suited for edge scenarios, have received relatively little attention due to their high memory demands. Offload-based methods have been proposed to address this challenge, but they face difficulties with expert prediction. Inaccurate expert predictions can result in prolonged inference delays. To promote the application of MoE models in edge scenarios, we propose Fate, an offloading system designed for MoE models to enable efficient inference in resource-constrained environments. The key insight behind Fate is that gate inputs from adjacent layers can be effectively used for expert prefetching, achieving high prediction accuracy without additional GPU overhead. Furthermore, Fate employs a shallow-favoring expert caching strategy that increases the expert hit rate to 99\\%. Additionally, Fate integrates tailored quantization strategies for cache optimization and IO efficiency. Experimental results show that, compared to Load on Demand and Expert Activation Path-based method, Fate achieves up to 4.5x and 1.9x speedups in prefill speed and up to 4.1x and 2.2x speedups in decoding speed, respectively, while maintaining inference quality. Moreover, Fate's performance improvements are scalable across different memory budgets.", 'abstract_zh': '基于卸载的Fate系统：用于边缘场景的高效Mixture-of-Experts模型推理', 'title_zh': 'MoE推理中跨层门控的精确专家预测'}
{'arxiv_id': 'arXiv:2502.12206', 'title': 'Evaluating the Paperclip Maximizer: Are RL-Based Language Models More Likely to Pursue Instrumental Goals?', 'authors': 'Yufei He, Yuexin Li, Jiaying Wu, Yuan Sui, Yulin Chen, Bryan Hooi', 'link': 'https://arxiv.org/abs/2502.12206', 'abstract': 'As large language models (LLMs) continue to evolve, ensuring their alignment with human goals and values remains a pressing challenge. A key concern is \\textit{instrumental convergence}, where an AI system, in optimizing for a given objective, develops unintended intermediate goals that override the ultimate objective and deviate from human-intended goals. This issue is particularly relevant in reinforcement learning (RL)-trained models, which can generate creative but unintended strategies to maximize rewards. In this paper, we explore instrumental convergence in LLMs by comparing models trained with direct RL optimization (e.g., the o1 model) to those trained with reinforcement learning from human feedback (RLHF). We hypothesize that RL-driven models exhibit a stronger tendency for instrumental convergence due to their optimization of goal-directed behavior in ways that may misalign with human intentions. To assess this, we introduce InstrumentalEval, a benchmark for evaluating instrumental convergence in RL-trained LLMs. Initial experiments reveal cases where a model tasked with making money unexpectedly pursues instrumental objectives, such as self-replication, implying signs of instrumental convergence. Our findings contribute to a deeper understanding of alignment challenges in AI systems and the risks posed by unintended model behaviors.', 'abstract_zh': '随着大型语言模型（LLMs）的不断发展，确保其与人类目标和价值保持一致仍然是一个紧迫的挑战。一个关键问题是\\textit{工具性趋同}，即在优化特定目标时，AI系统会发展出未预期的中间目标，这些中间目标会凌驾于最终目标之上，并偏离人类期望的目标。这一问题尤其适用于通过强化学习（RL）训练的模型，这些模型可以生成创意但未预期的策略来最大化奖励。在本文中，我们通过比较使用直接RL优化（例如o1模型）训练的模型和使用强化学习从人类反馈中训练的模型（RLHF）来探索LLMs中的工具性趋同。我们假设，由强化学习驱动的模型更容易表现出工具性趋同，因为它们可能会通过不利于人类意图的方式优化目标驱动行为。为评估这一现象，我们引入了InstrumentalEval，一种评估RL训练的LLMs工具性趋同的基准方法。初步实验揭示了模型在任务中赚钱时意外追求工具性目标（如自我复制）的情况，这可能表明存在工具性趋同的迹象。我们的研究结果有助于更深入地理解AI系统中的对齐挑战以及由未预期的模型行为带来的风险。', 'title_zh': '评估纸钉最大化者：基于 reinforcement learning 的语言模型更倾向于追求工具性目标吗？'}
{'arxiv_id': 'arXiv:2502.13143', 'title': 'SoFar: Language-Grounded Orientation Bridges Spatial Reasoning and Object Manipulation', 'authors': 'Zekun Qi, Wenyao Zhang, Yufei Ding, Runpei Dong, Xinqiang Yu, Jingwen Li, Lingyun Xu, Baoyu Li, Xialin He, Guofan Fan, Jiazhao Zhang, Jiawei He, Jiayuan Gu, Xin Jin, Kaisheng Ma, Zhizheng Zhang, He Wang, Li Yi', 'link': 'https://arxiv.org/abs/2502.13143', 'abstract': "Spatial intelligence is a critical component of embodied AI, promoting robots to understand and interact with their environments. While recent advances have enhanced the ability of VLMs to perceive object locations and positional relationships, they still lack the capability to precisely understand object orientations-a key requirement for tasks involving fine-grained manipulations. Addressing this limitation not only requires geometric reasoning but also an expressive and intuitive way to represent orientation. In this context, we propose that natural language offers a more flexible representation space than canonical frames, making it particularly suitable for instruction-following robotic systems. In this paper, we introduce the concept of semantic orientation, which defines object orientations using natural language in a reference-frame-free manner (e.g., the ''plug-in'' direction of a USB or the ''handle'' direction of a knife). To support this, we construct OrienText300K, a large-scale dataset of 3D models annotated with semantic orientations that link geometric understanding to functional semantics. By integrating semantic orientation into a VLM system, we enable robots to generate manipulation actions with both positional and orientational constraints. Extensive experiments in simulation and real world demonstrate that our approach significantly enhances robotic manipulation capabilities, e.g., 48.7% accuracy on Open6DOR and 74.9% accuracy on SIMPLER.", 'abstract_zh': '空间智能是体现式AI的关键组成部分，促进机器人理解并与其环境互动。尽管近年来视觉语言模型的能力得到了增强，使其能够感知物体位置和空间关系，但它们仍然缺乏精确理解物体姿态的能力——这是进行精细操作任务所需的关键能力。为解决这一局限，不仅需要几何推理，还需要一种灵活且直观的方式来表示姿态。在此背景下，我们认为自然语言提供了比标准坐标系更具弹性的表示空间，使其特别适合于指令跟随的机器人系统。在这项研究中，我们提出了语义姿态的概念，用自然语言在无参考坐标系的方式下定义物体姿态（例如，USB的“插接方向”或刀具的“把手方向”）。为了支持这一概念，我们构建了OrienText300K数据集，该数据集包含大量标注有语义姿态的3D模型，将几何理解与功能语义联系起来。通过将语义姿态集成到视觉语言模型系统中，我们使机器人能够生成带有位置和姿态约束的操纵动作。在模拟和真实环境中的广泛实验表明，我们的方法大大提升了一体机操作能力，例如，在Open6DOR上的准确率为48.7%，在SIMPLER上的准确率为74.9%。', 'title_zh': 'SoFar: 语言导向的空间导航连接空间推理与物体操作'}
{'arxiv_id': 'arXiv:2502.13142', 'title': 'Pre-training Auto-regressive Robotic Models with 4D Representations', 'authors': 'Dantong Niu, Yuvan Sharma, Haoru Xue, Giscard Biamby, Junyi Zhang, Ziteng Ji, Trevor Darrell, Roei Herzig', 'link': 'https://arxiv.org/abs/2502.13142', 'abstract': 'Foundation models pre-trained on massive unlabeled datasets have revolutionized natural language and computer vision, exhibiting remarkable generalization capabilities, thus highlighting the importance of pre-training. Yet, efforts in robotics have struggled to achieve similar success, limited by either the need for costly robotic annotations or the lack of representations that effectively model the physical world. In this paper, we introduce ARM4R, an Auto-regressive Robotic Model that leverages low-level 4D Representations learned from human video data to yield a better pre-trained robotic model. Specifically, we focus on utilizing 3D point tracking representations from videos derived by lifting 2D representations into 3D space via monocular depth estimation across time. These 4D representations maintain a shared geometric structure between the points and robot state representations up to a linear transformation, enabling efficient transfer learning from human video data to low-level robotic control. Our experiments show that ARM4R can transfer efficiently from human video data to robotics and consistently improves performance on tasks across various robot environments and configurations.', 'abstract_zh': '基于人类视频数据中学习到的低级四维表示的自回归机器人模型ARM4R', 'title_zh': '使用4D表示预训练自回归机器人模型'}
{'arxiv_id': 'arXiv:2502.13141', 'title': 'UniGuardian: A Unified Defense for Detecting Prompt Injection, Backdoor Attacks and Adversarial Attacks in Large Language Models', 'authors': 'Huawei Lin, Yingjie Lao, Tong Geng, Tan Yu, Weijie Zhao', 'link': 'https://arxiv.org/abs/2502.13141', 'abstract': 'Large Language Models (LLMs) are vulnerable to attacks like prompt injection, backdoor attacks, and adversarial attacks, which manipulate prompts or models to generate harmful outputs. In this paper, departing from traditional deep learning attack paradigms, we explore their intrinsic relationship and collectively term them Prompt Trigger Attacks (PTA). This raises a key question: Can we determine if a prompt is benign or poisoned? To address this, we propose UniGuardian, the first unified defense mechanism designed to detect prompt injection, backdoor attacks, and adversarial attacks in LLMs. Additionally, we introduce a single-forward strategy to optimize the detection pipeline, enabling simultaneous attack detection and text generation within a single forward pass. Our experiments confirm that UniGuardian accurately and efficiently identifies malicious prompts in LLMs.', 'abstract_zh': '大型语言模型（LLMs）易受提示注入攻击、后门攻击和对抗攻击的威胁，这些攻击会操控提示或模型以生成有害输出。本文从传统深度学习攻击范式出发，探讨它们的本质联系，并统称为提示触发攻击（PTA）。这引发了关键问题：我们能否确定一个提示是无害的还是被污染的？为解决这一问题，我们提出了UniGuardian，这是首个用于检测LLMs中提示注入、后门攻击和对抗攻击的统一防御机制。此外，我们引入了一次前向策略来优化检测管道，能够在单次前向传递中实现攻击检测和文本生成。我们的实验证实，UniGuardian能够准确且高效地识别LLMs中的恶意提示。', 'title_zh': 'UniGuardian: 大型语言模型中检测提示注入、后门攻击和 adversarial 攻击的统一防御方法'}
{'arxiv_id': 'arXiv:2502.13135', 'title': 'Sleepless Nights, Sugary Days: Creating Synthetic Users with Health Conditions for Realistic Coaching Agent Interactions', 'authors': 'Taedong Yun, Eric Yang, Mustafa Safdari, Jong Ha Lee, Vaishnavi Vinod Kumar, S. Sara Mahdavi, Jonathan Amar, Derek Peyton, Reut Aharony, Andreas Michaelides, Logan Schneider, Isaac Galatzer-Levy, Yugang Jia, John Canny, Arthur Gretton, Maja Matarić', 'link': 'https://arxiv.org/abs/2502.13135', 'abstract': "We present an end-to-end framework for generating synthetic users for evaluating interactive agents designed to encourage positive behavior changes, such as in health and lifestyle coaching. The synthetic users are grounded in health and lifestyle conditions, specifically sleep and diabetes management in this study, to ensure realistic interactions with the health coaching agent. Synthetic users are created in two stages: first, structured data are generated grounded in real-world health and lifestyle factors in addition to basic demographics and behavioral attributes; second, full profiles of the synthetic users are developed conditioned on the structured data. Interactions between synthetic users and the coaching agent are simulated using generative agent-based models such as Concordia, or directly by prompting a language model. Using two independently-developed agents for sleep and diabetes coaching as case studies, the validity of this framework is demonstrated by analyzing the coaching agent's understanding of the synthetic users' needs and challenges. Finally, through multiple blinded evaluations of user-coach interactions by human experts, we demonstrate that our synthetic users with health and behavioral attributes more accurately portray real human users with the same attributes, compared to generic synthetic users not grounded in such attributes. The proposed framework lays the foundation for efficient development of conversational agents through extensive, realistic, and grounded simulated interactions.", 'abstract_zh': '一种用于评估促进正面行为改变的交互式代理的端到端合成用户生成框架', 'title_zh': '熬夜之夜，甜食之日：创建具有健康状况的合成用户以实现现实的辅导代理交互'}
{'arxiv_id': 'arXiv:2502.13132', 'title': 'Learning to Defer for Causal Discovery with Imperfect Experts', 'authors': 'Oscar Clivio, Divyat Mahajan, Perouz Taslakian, Sara Magliacane, Ioannis Mitliagkas, Valentina Zantedeschi, Alexandre Drouin', 'link': 'https://arxiv.org/abs/2502.13132', 'abstract': "Integrating expert knowledge, e.g. from large language models, into causal discovery algorithms can be challenging when the knowledge is not guaranteed to be correct. Expert recommendations may contradict data-driven results, and their reliability can vary significantly depending on the domain or specific query. Existing methods based on soft constraints or inconsistencies in predicted causal relationships fail to account for these variations in expertise. To remedy this, we propose L2D-CD, a method for gauging the correctness of expert recommendations and optimally combining them with data-driven causal discovery results. By adapting learning-to-defer (L2D) algorithms for pairwise causal discovery (CD), we learn a deferral function that selects whether to rely on classical causal discovery methods using numerical data or expert recommendations based on textual meta-data. We evaluate L2D-CD on the canonical Tübingen pairs dataset and demonstrate its superior performance compared to both the causal discovery method and the expert used in isolation. Moreover, our approach identifies domains where the expert's performance is strong or weak. Finally, we outline a strategy for generalizing this approach to causal discovery on graphs with more than two variables, paving the way for further research in this area.", 'abstract_zh': '将大型语言模型等专家知识集成到因果发现算法中在知识未必正确的情况下具有挑战性。专家建议可能与数据驱动的结果相矛盾，其可靠性在不同领域或特定查询中差异显著。现有基于软约束或预测因果关系不一致的方法未能考虑到这些专业知识的变化。为此，我们提出了一种称为L2D-CD的方法，用于评估专家建议的正确性并最优地将这些建议与数据驱动的因果发现结果结合起来。通过将学习推迟（L2D）算法应用于成对因果发现（CD），我们学习了一个推迟函数，该函数根据文本元数据选择是依赖于使用数值数据的经典因果发现方法还是专家建议。我们在标准的Tübingen成对数据集上评估了L2D-CD，并证明其性能优于单独使用因果发现方法和专家建议。此外，我们的方法能够识别专家表现强弱的领域。最后，我们概述了一种策略，用于将此方法泛化到具有更多变量的图的因果发现中，为该领域的进一步研究铺平了道路。', 'title_zh': '利用 imperfect 专家进行因果发现的学习性延期方法'}
{'arxiv_id': 'arXiv:2502.13130', 'title': 'Magma: A Foundation Model for Multimodal AI Agents', 'authors': 'Jianwei Yang, Reuben Tan, Qianhui Wu, Ruijie Zheng, Baolin Peng, Yongyuan Liang, Yu Gu, Mu Cai, Seonghyeon Ye, Joel Jang, Yuquan Deng, Lars Liden, Jianfeng Gao', 'link': 'https://arxiv.org/abs/2502.13130', 'abstract': 'We present Magma, a foundation model that serves multimodal AI agentic tasks in both the digital and physical worlds. Magma is a significant extension of vision-language (VL) models in that it not only retains the VL understanding ability (verbal intelligence) of the latter, but is also equipped with the ability to plan and act in the visual-spatial world (spatial-temporal intelligence) and complete agentic tasks ranging from UI navigation to robot manipulation. To endow the agentic capabilities, Magma is pretrained on large amounts of heterogeneous datasets spanning from images, videos to robotics data, where the actionable visual objects (e.g., clickable buttons in GUI) in images are labeled by Set-of-Mark (SoM) for action grounding, and the object movements (e.g., the trace of human hands or robotic arms) in videos are labeled by Trace-of-Mark (ToM) for action planning. Extensive experiments show that SoM and ToM reach great synergy and facilitate the acquisition of spatial-temporal intelligence for our Magma model, which is fundamental to a wide range of tasks as shown in Fig.1. In particular, Magma creates new state-of-the-art results on UI navigation and robotic manipulation tasks, outperforming previous models that are specifically tailored to these tasks. On image and video-related multimodal tasks, Magma also compares favorably to popular large multimodal models that are trained on much larger datasets. We make our model and code public for reproducibility at this https URL.', 'abstract_zh': '我们呈现了Magma，一个服务于数字世界和物理世界多模态AI代理任务的基础模型。Magma是视觉语言（VL）模型的一个重要扩展，它不仅保留了后者在视觉语言理解方面的能力（言语智能），而且还具备在视觉空间世界中规划和执行任务的能力（时空智能），能够完成从UI导航到机器人操作等一系列代理任务。为赋予这些代理能力，Magma在从图像、视频到机器人数据等各种异质数据集上进行了预训练，在图像中的可操作视觉对象（如GUI中的可点击按钮）上通过Set-of-Mark (SoM)进行标注以实现动作接地，在视频中物体的运动轨迹（如人类手部或机器人手臂的轨迹）上通过Trace-of-Mark (ToM)进行标注以实现动作规划。大量实验表明，SoM和ToM能够产生巨大的协同效应，促进我们Magma模型在时空智能方面的获取，这对广泛的任务至关重要，如图1所示。特别是，Magma在UI导航和机器人操作任务上创造了新的最具表现力的结果，超越了专门为这些任务设计的先前模型。对于图像和视频相关的多模态任务，Magma也优于在更大数据集上训练的流行多模态模型。我们在此处公开了我们的模型和代码以确保可再现性。', 'title_zh': 'Magma：多模态AI代理的基础模型'}
{'arxiv_id': 'arXiv:2502.13128', 'title': 'SongGen: A Single Stage Auto-regressive Transformer for Text-to-Song Generation', 'authors': 'Zihan Liu, Shuangrui Ding, Zhixiong Zhang, Xiaoyi Dong, Pan Zhang, Yuhang Zang, Yuhang Cao, Dahua Lin, Jiaqi Wang', 'link': 'https://arxiv.org/abs/2502.13128', 'abstract': 'Text-to-song generation, the task of creating vocals and accompaniment from textual inputs, poses significant challenges due to domain complexity and data scarcity. Existing approaches often employ multi-stage generation procedures, resulting in cumbersome training and inference pipelines. In this paper, we propose SongGen, a fully open-source, single-stage auto-regressive transformer designed for controllable song generation. The proposed model facilitates fine-grained control over diverse musical attributes, including lyrics and textual descriptions of instrumentation, genre, mood, and timbre, while also offering an optional three-second reference clip for voice cloning. Within a unified auto-regressive framework, SongGen supports two output modes: mixed mode, which generates a mixture of vocals and accompaniment directly, and dual-track mode, which synthesizes them separately for greater flexibility in downstream applications. We explore diverse token pattern strategies for each mode, leading to notable improvements and valuable insights. Furthermore, we design an automated data preprocessing pipeline with effective quality control. To foster community engagement and future research, we will release our model weights, training code, annotated data, and preprocessing pipeline. The generated samples are showcased on our project page at this https URL , and the code will be available at this https URL .', 'abstract_zh': '文本到歌曲生成：一种基于单阶段自回归变压器的可控歌曲生成方法', 'title_zh': 'SongGen: 一种用于文本到歌曲生成的一阶段自回归变压器'}
{'arxiv_id': 'arXiv:2502.13120', 'title': 'Adapting Psycholinguistic Research for LLMs: Gender-inclusive Language in a Coreference Context', 'authors': 'Marion Bartl, Thomas Brendan Murphy, Susan Leavy', 'link': 'https://arxiv.org/abs/2502.13120', 'abstract': "Gender-inclusive language is often used with the aim of ensuring that all individuals, regardless of gender, can be associated with certain concepts. While psycholinguistic studies have examined its effects in relation to human cognition, it remains unclear how Large Language Models (LLMs) process gender-inclusive language. Given that commercial LLMs are gaining an increasingly strong foothold in everyday applications, it is crucial to examine whether LLMs in fact interpret gender-inclusive language neutrally, because the language they generate has the potential to influence the language of their users. This study examines whether LLM-generated coreferent terms align with a given gender expression or reflect model biases. Adapting psycholinguistic methods from French to English and German, we find that in English, LLMs generally maintain the antecedent's gender but exhibit underlying masculine bias. In German, this bias is much stronger, overriding all tested gender-neutralization strategies.", 'abstract_zh': '性别包容语言的使用旨在确保所有个体，不论性别，都能与某些概念相关联。虽然心理语言学研究已经探讨了其对人类认知的影响，但尚未明确大型语言模型（LLMs）如何处理性别包容语言。鉴于商用LLMs在日常应用中的影响不断增强，有必要考察LLMs是否实际上以中立的方式解释性别包容语言，因为它们生成的语言有可能影响用户语言。本研究探讨LLM生成的指称词是否与给定的性别表达一致，或反映模型偏见。将心理语言学方法从法语和德语适应到英语，我们发现，在英语中，LLMs通常保持先行词的性别，但表现出潜在的男性偏见。在德语中，这种偏见更为强烈，甚至超越了所有测试的性别中性化策略。', 'title_zh': '适应心理语言学研究对于大规模语言模型：共指语境中的性别包容性语言'}
{'arxiv_id': 'arXiv:2502.13117', 'title': 'Performance Evaluation of Large Language Models in Statistical Programming', 'authors': 'Xinyi Song, Kexin Xie, Lina Lee, Ruizhe Chen, Jared M. Clark, Hao He, Haoran He, Jie Min, Xinlei Zhang, Simin Zheng, Zhiyang Zhang, Xinwei Deng, Yili Hong', 'link': 'https://arxiv.org/abs/2502.13117', 'abstract': 'The programming capabilities of large language models (LLMs) have revolutionized automatic code generation and opened new avenues for automatic statistical analysis. However, the validity and quality of these generated codes need to be systematically evaluated before they can be widely adopted. Despite their growing prominence, a comprehensive evaluation of statistical code generated by LLMs remains scarce in the literature. In this paper, we assess the performance of LLMs, including two versions of ChatGPT and one version of Llama, in the domain of SAS programming for statistical analysis. Our study utilizes a set of statistical analysis tasks encompassing diverse statistical topics and datasets. Each task includes a problem description, dataset information, and human-verified SAS code. We conduct a comprehensive assessment of the quality of SAS code generated by LLMs through human expert evaluation based on correctness, effectiveness, readability, executability, and the accuracy of output results. The analysis of rating scores reveals that while LLMs demonstrate usefulness in generating syntactically correct code, they struggle with tasks requiring deep domain understanding and may produce redundant or incorrect results. This study offers valuable insights into the capabilities and limitations of LLMs in statistical programming, providing guidance for future advancements in AI-assisted coding systems for statistical analysis.', 'abstract_zh': '大型语言模型的编程能力彻底变革了自动代码生成，并开辟了自动统计分析的新途径。然而，在这些生成的代码被广泛采用之前，需要对其有效性和质量进行系统的评估。尽管大型语言模型在统计编程领域的 prominence 越来越大，但在文献中对其生成的统计代码进行全面评价的信息仍相当缺乏。本文评估了包括两个版本的 ChatGPT 和一个版本的 Llama 在统计分析领域（使用 SAS 编程）中的表现。我们的研究利用了一组涵盖多种统计主题和数据集的统计分析任务。每个任务包括问题描述、数据集信息以及人工验证的 SAS 代码。我们通过人工专家根据正确性、有效性、可读性、可执行性和输出结果的准确性对大型语言模型生成的 SAS 代码的质量进行了全面评估。评分分析表明，尽管大型语言模型在生成语法正确的代码方面表现出一定的有用性，但在需要深厚领域理解的任务中却表现不佳，并且可能会产生冗余或错误的结果。本文为 AI 辅助编码系统在统计分析中的未来发展提供了有关大型语言模型在统计编程中的能力和局限性的宝贵见解。', 'title_zh': '大型语言模型在统计编程中的性能评估'}
{'arxiv_id': 'arXiv:2502.13115', 'title': 'Near-Optimal Private Learning in Linear Contextual Bandits', 'authors': 'Fan Chen, Jiachun Li, Alexander Rakhlin, David Simchi-Levi', 'link': 'https://arxiv.org/abs/2502.13115', 'abstract': 'We analyze the problem of private learning in generalized linear contextual bandits. Our approach is based on a novel method of re-weighted regression, yielding an efficient algorithm with regret of order $\\sqrt{T}+\\frac{1}{\\alpha}$ and $\\sqrt{T}/\\alpha$ in the joint and local model of $\\alpha$-privacy, respectively. Further, we provide near-optimal private procedures that achieve dimension-independent rates in private linear models and linear contextual bandits. In particular, our results imply that joint privacy is almost "for free" in all the settings we consider, partially addressing the open problem posed by Azize and Basu (2024).', 'abstract_zh': '我们分析了广义线性上下文_bandits中的私人学习问题。我们的方法基于一种新型加权回归方法，从而得到了在$\\alpha$-隐私的联合模型和局部模型中分别具有$\\sqrt{T}+\\frac{1}{\\alpha}$和$\\sqrt{T}/\\alpha$遗憾界的高效算法。此外，我们提供了接近最优的私人学习程序，在私人线性模型和线性上下文_bandits中实现了与维数无关的速度。特别是，我们的结果表明，在我们考虑的所有设置中，联合隐私几乎“免费”，部分解决了Azize和Basu（2024）提出的开放问题。', 'title_zh': '近最优私密学习在线性上下文臂bandit中'}
{'arxiv_id': 'arXiv:2502.13108', 'title': 'Improving Clinical Question Answering with Multi-Task Learning: A Joint Approach for Answer Extraction and Medical Categorization', 'authors': 'Priyaranjan Pattnayak, Hitesh Laxmichand Patel, Amit Agarwal, Bhargava Kumar, Srikant Panda, Tejaswini Kumar', 'link': 'https://arxiv.org/abs/2502.13108', 'abstract': 'Clinical Question Answering (CQA) plays a crucial role in medical decision-making, enabling physicians to extract relevant information from Electronic Medical Records (EMRs). While transformer-based models such as BERT, BioBERT, and ClinicalBERT have demonstrated state-of-the-art performance in CQA, existing models lack the ability to categorize extracted answers, which is critical for structured retrieval, content filtering, and medical decision support.\nTo address this limitation, we introduce a Multi-Task Learning (MTL) framework that jointly trains CQA models for both answer extraction and medical categorization. In addition to predicting answer spans, our model classifies responses into five standardized medical categories: Diagnosis, Medication, Symptoms, Procedure, and Lab Reports. This categorization enables more structured and interpretable outputs, making clinical QA models more useful in real-world healthcare settings.\nWe evaluate our approach on emrQA, a large-scale dataset for medical question answering. Results show that MTL improves F1-score by 2.2% compared to standard fine-tuning, while achieving 90.7% accuracy in answer categorization. These findings suggest that MTL not only enhances CQA performance but also introduces an effective mechanism for categorization and structured medical information retrieval.', 'abstract_zh': '多任务学习在医疗问答中的应用：结合答案提取与医学分类', 'title_zh': '基于多任务学习改进临床问题回答：一种结合答案提取与医疗分类的方法'}
{'arxiv_id': 'arXiv:2502.13092', 'title': 'Text2World: Benchmarking Large Language Models for Symbolic World Model Generation', 'authors': 'Mengkang Hu, Tianxing Chen, Yude Zou, Yuheng Lei, Qiguang Chen, Ming Li, Hongyuan Zhang, Wenqi Shao, Ping Luo', 'link': 'https://arxiv.org/abs/2502.13092', 'abstract': 'Recently, there has been growing interest in leveraging large language models (LLMs) to generate symbolic world models from textual descriptions. Although LLMs have been extensively explored in the context of world modeling, prior studies encountered several challenges, including evaluation randomness, dependence on indirect metrics, and a limited domain scope. To address these limitations, we introduce a novel benchmark, Text2World, based on planning domain definition language (PDDL), featuring hundreds of diverse domains and employing multi-criteria, execution-based metrics for a more robust evaluation. We benchmark current LLMs using Text2World and find that reasoning models trained with large-scale reinforcement learning outperform others. However, even the best-performing model still demonstrates limited capabilities in world modeling. Building on these insights, we examine several promising strategies to enhance the world modeling capabilities of LLMs, including test-time scaling, agent training, and more. We hope that Text2World can serve as a crucial resource, laying the groundwork for future research in leveraging LLMs as world models. The project page is available at this https URL.', 'abstract_zh': '近年来，人们越来越关注利用大规模语言模型（LLMs）从文本描述中生成符号世界模型。尽管在世界建模的背景下已经广泛研究了LLMs，但之前的研究所遇到的一些挑战包括评估的随机性、依赖间接指标以及领域范围有限等。为了解决这些问题，我们基于规划领域定义语言（PDDL）引入了一个新的基准Text2World，该基准包含数百个多样化的领域，并采用多标准执行基指标进行更稳健的评估。我们使用Text2World来评估当前的LLMs，并发现大规模强化学习训练的推理模型优于其他模型。然而，即使性能最好的模型在世界建模方面也表现出有限的能力。基于这些见解，我们探讨了几种有望增强LLMs世界建模能力的方法，包括测试时扩展、智能体训练等。我们希望Text2World能够成为一个重要资源，为利用LLMs作为世界模型的未来研究奠定基础。项目页面可通过此链接访问。', 'title_zh': 'Text2World: 用于符号世界模型生成的大规模语言模型基准测试'}
{'arxiv_id': 'arXiv:2502.13080', 'title': 'BOLIMES: Boruta and LIME optiMized fEature Selection for Gene Expression Classification', 'authors': 'Bich-Chung Phan, Thanh Ma, Huu-Hoa Nguyen, and Thanh-Nghi Do', 'link': 'https://arxiv.org/abs/2502.13080', 'abstract': 'Gene expression classification is a pivotal yet challenging task in bioinformatics, primarily due to the high dimensionality of genomic data and the risk of overfitting. To bridge this gap, we propose BOLIMES, a novel feature selection algorithm designed to enhance gene expression classification by systematically refining the feature subset. Unlike conventional methods that rely solely on statistical ranking or classifier-specific selection, we integrate the robustness of Boruta with the interpretability of LIME, ensuring that only the most relevant and influential genes are retained. BOLIMES first employs Boruta to filter out non-informative genes by comparing each feature against its randomized counterpart, thus preserving valuable information. It then uses LIME to rank the remaining genes based on their local importance to the classifier. Finally, an iterative classification evaluation determines the optimal feature subset by selecting the number of genes that maximizes predictive accuracy. By combining exhaustive feature selection with interpretability-driven refinement, our solution effectively balances dimensionality reduction with high classification performance, offering a powerful solution for high-dimensional gene expression analysis.', 'abstract_zh': '基因表达分类是生物informatics中的一个关键但极具挑战性的任务，主要由于基因组数据的高维度和过拟合的风险。为解决这一问题，我们提出了一种新颖的特征选择算法BOLIMES，旨在通过系统性地精炼特征子集来提高基因表达分类。BOLIMES融合了Boruta的稳健性和LIME的可解释性，确保仅保留最相关的基因。该算法首先使用Boruta通过将每个特征与其随机化对应物进行比较来筛选出非信息性基因，从而保留有价值的信息。随后，使用LIME基于其对分类器的局部重要性对剩余基因进行排序。最后，迭代的分类评估通过选择最大化预测准确性的基因数量来确定最优特征子集。通过结合 exhaustive 特征选择与可解释性驱动的精炼，我们的解决方案有效地平衡了维度缩减与高分类性能，为高维基因表达分析提供了强大解决方案。', 'title_zh': 'BOLIMES: Boruta和LIME优化的特征选择用于基因表达分类'}
{'arxiv_id': 'arXiv:2502.13061', 'title': 'Improved Fine-Tuning of Large Multimodal Models for Hateful Meme Detection', 'authors': 'Jingbiao Mei, Jinghong Chen, Guangyu Yang, Weizhe Lin, Bill Byrne', 'link': 'https://arxiv.org/abs/2502.13061', 'abstract': 'Hateful memes have become a significant concern on the Internet, necessitating robust automated detection systems. While large multimodal models have shown strong generalization across various tasks, they exhibit poor generalization to hateful meme detection due to the dynamic nature of memes tied to emerging social trends and breaking news. Recent work further highlights the limitations of conventional supervised fine-tuning for large multimodal models in this context. To address these challenges, we propose Large Multimodal Model Retrieval-Guided Contrastive Learning (LMM-RGCL), a novel two-stage fine-tuning framework designed to improve both in-domain accuracy and cross-domain generalization. Experimental results on six widely used meme classification datasets demonstrate that LMM-RGCL achieves state-of-the-art performance, outperforming agent-based systems such as VPD-PALI-X-55B. Furthermore, our method effectively generalizes to out-of-domain memes under low-resource settings, surpassing models like GPT-4o.', 'abstract_zh': '大规模多模态模型检索引导对比学习（LMM-RGCL）：一种改进领域内准确性和跨领域泛化的新型两阶段微调框架', 'title_zh': '改进的大规模多模态模型细粒度微调在仇恨 meme 检测中的应用'}
{'arxiv_id': 'arXiv:2502.13055', 'title': 'LAMD: Context-driven Android Malware Detection and Classification with LLMs', 'authors': 'Xingzhi Qian, Xinran Zheng, Yiling He, Shuo Yang, Lorenzo Cavallaro', 'link': 'https://arxiv.org/abs/2502.13055', 'abstract': "The rapid growth of mobile applications has escalated Android malware threats. Although there are numerous detection methods, they often struggle with evolving attacks, dataset biases, and limited explainability. Large Language Models (LLMs) offer a promising alternative with their zero-shot inference and reasoning capabilities. However, applying LLMs to Android malware detection presents two key challenges: (1)the extensive support code in Android applications, often spanning thousands of classes, exceeds LLMs' context limits and obscures malicious behavior within benign functionality; (2)the structural complexity and interdependencies of Android applications surpass LLMs' sequence-based reasoning, fragmenting code analysis and hindering malicious intent inference. To address these challenges, we propose LAMD, a practical context-driven framework to enable LLM-based Android malware detection. LAMD integrates key context extraction to isolate security-critical code regions and construct program structures, then applies tier-wise code reasoning to analyze application behavior progressively, from low-level instructions to high-level semantics, providing final prediction and explanation. A well-designed factual consistency verification mechanism is equipped to mitigate LLM hallucinations from the first tier. Evaluation in real-world settings demonstrates LAMD's effectiveness over conventional detectors, establishing a feasible basis for LLM-driven malware analysis in dynamic threat landscapes.", 'abstract_zh': '移动应用程序的迅速增长加剧了Android恶意软件威胁。尽管存在多种检测方法，但它们常常难以应对不断演变的攻击、数据集偏差以及缺乏透明性。大规模语言模型（LLMs）凭借其零样本推断和推理能力提供了有前景的替代方案。然而，将LLMs应用于Android恶意软件检测面临着两个主要挑战：（1）Android应用程序中广泛的支撑代码，常涉及数千个类，超出了LLMs的上下文限制，模糊了恶意行为在良性功能中的表现；（2）Android应用程序的结构复杂性和相互依赖性超过了LLMs基于序列的推理能力，导致代码分析碎片化，妨碍了恶意意图的推断。为解决这些挑战，我们提出了一种实际的基于上下文的框架LAMD，以使LLM能够用于Android恶意软件检测。LAMD结合了关键上下文提取，以分离安全关键代码区域并构建程序结构，然后采用分层代码推理逐步分析应用程序行为，从低级指令到高级语义，提供最终预测和解释。设计了一种事实一致性验证机制，以减轻第一层级的LLM幻觉。在实际环境中的评估表明，LAMD在传统检测器之上更为有效，确立了基于LLM的恶意软件分析在动态威胁环境中的可行性基础。', 'title_zh': '基于LLM的上下文驱动的Android恶意软件检测与分类'}
{'arxiv_id': 'arXiv:2502.13034', 'title': 'Natural Language Generation from Visual Sequences: Challenges and Future Directions', 'authors': 'Aditya K Surikuchi, Raquel Fernández, Sandro Pezzelle', 'link': 'https://arxiv.org/abs/2502.13034', 'abstract': 'The ability to use natural language to talk about visual content is at the core of human intelligence and a crucial feature of any artificial intelligence system. Various studies have focused on generating text for single images. In contrast, comparatively little attention has been paid to exhaustively analyzing and advancing work on multiple-image vision-to-text settings. In this position paper, we claim that any task dealing with temporally ordered sequences of multiple images or frames is an instance of a broader, more general problem involving the understanding of intricate relationships between the visual content and the corresponding text. We comprehensively analyze five tasks that are instances of this problem and argue that they pose a common set of challenges and share similarities in terms of modeling and evaluation approaches. Based on the insights from these various aspects and stages of multi-image-to-text generation, we highlight several open questions and suggest future research directions. We believe that these directions can advance the understanding of complex phenomena in this domain and the development of better models.', 'abstract_zh': '自然语言描述多张图像的能力是人类智能的核心，并且是任何人工智能系统的关键特征。尽管已有研究集中在生成单张图像的文本描述上，但对多张图像视觉到文本转换的全面分析和工作进展关注相对较少。在本文中，我们提出，任何涉及时间顺序多张图像或帧的任务都是更广泛、更一般问题的一个实例，该问题涉及视觉内容与相应文本之间复杂关系的理解。我们全面分析了五个此类问题的具体任务，并认为它们面临着一组共同的挑战，并且在建模和评估方法上具有相似性。基于这些多图像到文本生成不同方面和阶段的见解，我们强调了若干开放问题，并建议未来的研究方向。我们认为，这些方向可以促进对该领域复杂现象的理解以及更优模型的发展。', 'title_zh': '基于视觉序列的自然语言生成：挑战与未来方向'}
{'arxiv_id': 'arXiv:2502.13030', 'title': 'Likelihood-Ratio Regularized Quantile Regression: Adapting Conformal Prediction to High-Dimensional Covariate Shifts', 'authors': 'Sunay Joshi, Shayan Kiyani, George Pappas, Edgar Dobriban, Hamed Hassani', 'link': 'https://arxiv.org/abs/2502.13030', 'abstract': 'We consider the problem of conformal prediction under covariate shift. Given labeled data from a source domain and unlabeled data from a covariate shifted target domain, we seek to construct prediction sets with valid marginal coverage in the target domain. Most existing methods require estimating the unknown likelihood ratio function, which can be prohibitive for high-dimensional data such as images. To address this challenge, we introduce the likelihood ratio regularized quantile regression (LR-QR) algorithm, which combines the pinball loss with a novel choice of regularization in order to construct a threshold function without directly estimating the unknown likelihood ratio. We show that the LR-QR method has coverage at the desired level in the target domain, up to a small error term that we can control. Our proofs draw on a novel analysis of coverage via stability bounds from learning theory. Our experiments demonstrate that the LR-QR algorithm outperforms existing methods on high-dimensional prediction tasks, including a regression task for the Communities and Crime dataset, and an image classification task from the WILDS repository.', 'abstract_zh': '我们考虑在协变量偏移下的保函呈现值预测问题。给定源领域带标签的数据和目标领域协变量偏移的未标记数据，我们寻求构建在目标领域的有效边际覆盖预测集。现有大多数方法需要估计未知的似然比函数，在处理高维数据如图像时可能具有挑战性。为应对这一挑战，我们引入了似然比正则化分位数回归（LR-QR）算法，该算法结合了尖球损失和一种新颖的选择正则化方法，以构建阈值函数，而不直接估计未知的似然比。我们证明了LR-QR方法在其目标领域达到了所期望的覆盖率，而仅在可以控制的小误差项范围内有所不同。我们的证明基于学习理论中的一种新颖的覆盖分析和稳定性界。我们的实验表明，LR-QR算法在高维预测任务中优于现有方法，包括Communities and Crime数据集上的回归任务和WILDS仓库中的图像分类任务。', 'title_zh': '基于似然比正则化的分位数回归：适应高维协变量偏移的同伏预测调整'}
{'arxiv_id': 'arXiv:2502.13016', 'title': 'LLM-Powered Proactive Data Systems', 'authors': 'Sepanta Zeighami, Yiming Lin, Shreya Shankar, Aditya Parameswaran', 'link': 'https://arxiv.org/abs/2502.13016', 'abstract': "With the power of LLMs, we now have the ability to query data that was previously impossible to query, including text, images, and video. However, despite this enormous potential, most present-day data systems that leverage LLMs are reactive, reflecting our community's desire to map LLMs to known abstractions. Most data systems treat LLMs as an opaque black box that operates on user inputs and data as is, optimizing them much like any other approximate, expensive UDFs, in conjunction with other relational operators. Such data systems do as they are told, but fail to understand and leverage what the LLM is being asked to do (i.e. the underlying operations, which may be error-prone), the data the LLM is operating on (e.g., long, complex documents), or what the user really needs. They don't take advantage of the characteristics of the operations and/or the data at hand, or ensure correctness of results when there are imprecisions and ambiguities. We argue that data systems instead need to be proactive: they need to be given more agency -- armed with the power of LLMs -- to understand and rework the user inputs and the data and to make decisions on how the operations and the data should be represented and processed. By allowing the data system to parse, rewrite, and decompose user inputs and data, or to interact with the user in ways that go beyond the standard single-shot query-result paradigm, the data system is able to address user needs more efficiently and effectively. These new capabilities lead to a rich design space where the data system takes more initiative: they are empowered to perform optimization based on the transformation operations, data characteristics, and user intent. We discuss various successful examples of how this framework has been and can be applied in real-world tasks, and present future directions for this ambitious research agenda.", 'abstract_zh': '利用大模型的威力，我们现在有能力查询以前无法查询的数据，包括文本、图像和视频。然而，尽管这种潜力巨大，大多数利用大模型的数据系统依然是反应式的，反映了我们社区希望将大模型映射到已知抽象的需求。大多数数据系统将大模型视为一个不透明的黑盒，以原始形式处理用户输入和数据，并像优化其他近似且昂贵的UDF一样进行优化，结合其他关系操作。这类数据系统会执行指令，但却无法理解或将大模型被要求执行的内容（即底层操作，可能有错误），大模型正在操作的数据（例如，长而复杂的文档），或用户真正的需求。它们没有利用手头的操作和数据的特性，也没有在存在不精确和歧义时保证结果的正确性。我们认为，数据系统需要更加主动：它们需要被赋予更多的控制权——利用大模型的力量——来理解并重新构建用户输入和数据，并决定如何表示和处理操作和数据。通过允许数据系统解析、重写和分解用户输入和数据，或以超越标准单次查询-结果范式的方式与用户交互，数据系统能够更高效、更有效地满足用户需求。这些新功能带来了丰富的设计空间，在这个空间中，数据系统将扮演更加积极的角色：它们能够基于转换操作、数据特性和用户意图进行优化。我们讨论了这一框架在实际任务中取得的成功实例，并提出了这一雄心勃勃的研究议程的未来方向。', 'title_zh': 'LLM驱动的主动数据系统'}
{'arxiv_id': 'arXiv:2502.13013', 'title': 'HOMIE: Humanoid Loco-Manipulation with Isomorphic Exoskeleton Cockpit', 'authors': 'Qingwei Ben, Feiyu Jia, Jia Zeng, Junting Dong, Dahua Lin, Jiangmiao Pang', 'link': 'https://arxiv.org/abs/2502.13013', 'abstract': 'Current humanoid teleoperation systems either lack reliable low-level control policies, or struggle to acquire accurate whole-body control commands, making it difficult to teleoperate humanoids for loco-manipulation tasks. To solve these issues, we propose HOMIE, a novel humanoid teleoperation cockpit integrates a humanoid loco-manipulation policy and a low-cost exoskeleton-based hardware system. The policy enables humanoid robots to walk and squat to specific heights while accommodating arbitrary upper-body poses. This is achieved through our novel reinforcement learning-based training framework that incorporates upper-body pose curriculum, height-tracking reward, and symmetry utilization, without relying on any motion priors. Complementing the policy, the hardware system integrates isomorphic exoskeleton arms, a pair of motion-sensing gloves, and a pedal, allowing a single operator to achieve full control of the humanoid robot. Our experiments show our cockpit facilitates more stable, rapid, and precise humanoid loco-manipulation teleoperation, accelerating task completion and eliminating retargeting errors compared to inverse kinematics-based methods. We also validate the effectiveness of the data collected by our cockpit for imitation learning. Our project is fully open-sourced, demos and code can be found in this https URL.', 'abstract_zh': '当前的人形遥操作系统要么缺乏可靠的低级控制策略，要么难以获得准确的全身控制命令，使得通过遥操作人形机器人执行行进操作任务变得困难。为了解决这些问题，我们提出了一种名为HOMIE的人形遥操作平台，该平台集成了人形行进操作策略和低成本外骨骼硬件系统。该策略使机器人人形能够在特定高度行走和蹲下，同时适应任意上身姿态。这通过我们提出的一种基于强化学习的训练框架实现，该框架包括上身姿态课程、高度追踪奖励和对称性利用，而无需依赖任何运动先验知识。配合策略，该硬件系统集成了同构外骨骼臂、一副运动感应手套和一个踏板，使得单一操作员能够完全控制人形机器人。我们的实验表明，该平台能够实现更稳定、更快捷和更精确的人形行进操作遥操作，加速任务完成并消除基于逆向动力学方法的错误。我们还验证了该平台收集的数据对模仿学习的有效性。我们的项目完全开源，演示和代码可以在以下链接找到：this https URL。', 'title_zh': 'HOMIE: 类人步行操作的同构外骨骼 cockpit'}
{'arxiv_id': 'arXiv:2502.12998', 'title': 'Personalized Top-k Set Queries Over Predicted Scores', 'authors': 'Sohrab Namazi Nia, Subhodeep Ghosh, Senjuti Basu Roy, Sihem Amer-Yahia', 'link': 'https://arxiv.org/abs/2502.12998', 'abstract': 'This work studies the applicability of expensive external oracles such as large language models in answering top-k queries over predicted scores. Such scores are incurred by user-defined functions to answer personalized queries over multi-modal data. We propose a generic computational framework that handles arbitrary set-based scoring functions, as long as the functions could be decomposed into constructs, each of which sent to an oracle (in our case an LLM) to predict partial scores. At a given point in time, the framework assumes a set of responses and their partial predicted scores, and it maintains a collection of possible sets that are likely to be the true top-k. Since calling oracles is costly, our framework judiciously identifies the next construct, i.e., the next best question to ask the oracle so as to maximize the likelihood of identifying the true top-k. We present a principled probabilistic model that quantifies that likelihood. We study efficiency opportunities in designing algorithms. We run an evaluation with three large scale datasets, scoring functions, and baselines. Experiments indicate the efficacy of our framework, as it achieves an order of magnitude improvement over baselines in requiring LLM calls while ensuring result accuracy. Scalability experiments further indicate that our framework could be used in large-scale applications.', 'abstract_zh': '本研究探讨了大型语言模型等昂贵外部先知在回答基于预测分数的个性化多模态数据查询时的应用性。我们提出了一种通用的计算框架，该框架能够处理任意集基评分函数，只要这些函数可以分解为每个部分发送给先知（例如，大型语言模型）以预测部分评分。在给定时间点上，该框架假设一系列响应及其部分预测得分，并维护一组可能是真正前k名的可能集合。由于调用先知是昂贵的，我们的框架明智地识别出下一个将要提问的构建，即下一个最佳问题，以最大化识别真正前k名的可能性。我们介绍了一个原则性的概率模型来量化这种可能性。我们研究了在设计算法时提高效率的机会。我们在三个大规模数据集、评分函数和基线方法上进行了评估。实验表明，我们的框架在要求大型语言模型调用次数方面比基线方法提高了数量级，同时保持了结果准确性。进一步的可扩展性实验表明，我们的框架适用于大规模应用程序。', 'title_zh': '基于预测分数的个性化Top-k集合查询'}
{'arxiv_id': 'arXiv:2502.12992', 'title': 'B-cos LM: Efficiently Transforming Pre-trained Language Models for Improved Explainability', 'authors': 'Yifan Wang, Sukrut Rao, Ji-Ung Lee, Mayank Jobanputra, Vera Demberg', 'link': 'https://arxiv.org/abs/2502.12992', 'abstract': 'Post-hoc explanation methods for black-box models often struggle with faithfulness and human interpretability due to the lack of explainability in current neural models. Meanwhile, B-cos networks have been introduced to improve model explainability through architectural and computational adaptations, but their application has so far been limited to computer vision models and their associated training pipelines. In this work, we introduce B-cos LMs, i.e., B-cos networks empowered for NLP tasks. Our approach directly transforms pre-trained language models into B-cos LMs by combining B-cos conversion and task fine-tuning, improving efficiency compared to previous B-cos methods. Our automatic and human evaluation results demonstrate that B-cos LMs produce more faithful and human interpretable explanations than post hoc methods, while maintaining task performance comparable to conventional fine-tuning. Our in-depth analysis explores how B-cos LMs differ from conventionally fine-tuned models in their learning processes and explanation patterns. Finally, we provide practical guidelines for effectively building B-cos LMs based on our findings. Our code is available at this https URL.', 'abstract_zh': '黑箱模型的后验解释方法往往由于当前神经模型缺乏可解释性而难以实现忠实性和人类可解释性。同时，B-cos网络已经被引入以通过架构和计算的调整来提高模型的可解释性，但它们的应用迄今仅限于计算机视觉模型及其相关的训练管道。在本项工作中，我们提出了B-cos LMs，即赋能于NLP任务的B-cos网络。我们的方法通过结合B-cos转换和任务微调，直接将预训练语言模型转换为B-cos LMs，相较于之前的B-cos方法提高了效率。我们的自动和人工评估结果表明，B-cos LMs能够产生比后验方法更为忠实和人类可解释的解释，同时保持与传统微调相当的任务性能。我们深入分析了B-cos LMs在学习过程和解释模式上与传统微调模型的区别。最后，基于我们的发现，我们提供了有效构建B-cos LMs的实用指南。相关代码可在以下链接获取。', 'title_zh': 'B-cos LM: 有效地转换预训练语言模型以提高可解释性'}
{'arxiv_id': 'arXiv:2502.12985', 'title': 'PartSDF: Part-Based Implicit Neural Representation for Composite 3D Shape Parametrization and Optimization', 'authors': 'Nicolas Talabot, Olivier Clerc, Arda Cinar Demirtas, Doruk Oner, Pascal Fua', 'link': 'https://arxiv.org/abs/2502.12985', 'abstract': 'Accurate 3D shape representation is essential in engineering applications such as design, optimization, and simulation. In practice, engineering workflows require structured, part-aware representations, as objects are inherently designed as assemblies of distinct components. However, most existing methods either model shapes holistically or decompose them without predefined part structures, limiting their applicability in real-world design tasks. We propose PartSDF, a supervised implicit representation framework that explicitly models composite shapes with independent, controllable parts while maintaining shape consistency. Despite its simple single-decoder architecture, PartSDF outperforms both supervised and unsupervised baselines in reconstruction and generation tasks. We further demonstrate its effectiveness as a structured shape prior for engineering applications, enabling precise control over individual components while preserving overall coherence. Code available at this https URL.', 'abstract_zh': '准确的3D形状表示在工程应用如设计、优化和模拟中至关重要。在实践中，工程工作流需要结构化的、部件感知的表示，因为对象本质上是由不同的组件组成的组装体。然而，现有大多数方法要么整体建模形状，要么在没有预定义部件结构的情况下分解形状，这限制了它们在实际设计任务中的应用。我们提出了一种名为PartSDF的监督隐式表示框架，该框架明确地以独立可控部件的形式建模复合形状，同时保持形状一致性。尽管其单解码器架构简单，但PartSDF在重建和生成任务中均优于监督和无监督基线。我们进一步证明，PartSDF作为结构化形状先验，对于工程应用具有有效性，能够在保持整体连贯性的同时精确控制各个组件。代码见此链接。', 'title_zh': 'PartSDF: 基于部件的隐式神经表示方法及其在复合三维形状参数化和优化中的应用'}
{'arxiv_id': 'arXiv:2502.12982', 'title': 'Sailor2: Sailing in South-East Asia with Inclusive Multilingual LLMs', 'authors': 'Longxu Dou, Qian Liu, Fan Zhou, Changyu Chen, Zili Wang, Ziqi Jin, Zichen Liu, Tongyao Zhu, Cunxiao Du, Penghui Yang, Haonan Wang, Jiaheng Liu, Yongchi Zhao, Xiachong Feng, Xin Mao, Man Tsung Yeung, Kunat Pipatanakul, Fajri Koto, Min Si Thu, Hynek Kydlíček, Zeyi Liu, Qunshu Lin, Sittipong Sripaisarnmongkol, Kridtaphad Sae-Khow, Nirattisai Thongchim, Taechawat Konkaew, Narong Borijindargoon, Anh Dao, Matichon Maneegard, Phakphum Artkaew, Zheng-Xin Yong, Quan Nguyen, Wannaphong Phatthiyaphaibun, Hoang H. Tran, Mike Zhang, Shiqi Chen, Tianyu Pang, Chao Du, Xinyi Wan, Wei Lu, Min Lin', 'link': 'https://arxiv.org/abs/2502.12982', 'abstract': 'Sailor2 is a family of cutting-edge multilingual language models for South-East Asian (SEA) languages, available in 1B, 8B, and 20B sizes to suit diverse applications. Building on Qwen2.5, Sailor2 undergoes continuous pre-training on 500B tokens (400B SEA-specific and 100B replay tokens) to support 13 SEA languages while retaining proficiency in Chinese and English. Sailor2-20B model achieves a 50-50 win rate against GPT-4o across SEA languages. We also deliver a comprehensive cookbook on how to develop the multilingual model in an efficient manner, including five key aspects: data curation, pre-training, post-training, model customization and evaluation. We hope that Sailor2 model (Apache 2.0 license) will drive language development in the SEA region, and Sailor2 cookbook will inspire researchers to build more inclusive LLMs for other under-served languages.', 'abstract_zh': 'Sailor2是面向东南亚语言的一系列先进多语言语言模型，提供1B、8B和20B三种规模，以适应多种应用需求。基于Qwen2.5，Sailor2在500亿 token（400亿特定于东南亚地区和100亿重播 token）上进行持续预训练，支持13种东南亚语言，同时保留对中文和英语的专业能力。Sailor2-20B模型在东南亚语言方面与GPT-4o实现平 bureau（50-50胜率）。我们还提供了一整套关于如何高效开发多语言模型的方法指南，包括五个关键方面：数据整理、预训练、后训练、模型定制和评估。我们希望Sailor2模型（采用Apache 2.0许可证）能够促进东南亚地区的语言发展，并希望通过Sailor2套菜书激励研究人员为其他未充分服务的语言构建更加包容性的大语言模型。', 'title_zh': 'Sailor2: 以包容性多语言LLM探索东南亚'}
{'arxiv_id': 'arXiv:2502.12977', 'title': 'Time-series attribution maps with regularized contrastive learning', 'authors': 'Steffen Schneider, Rodrigo González Laiz, Anastasiia Filippova, Markus Frey, Mackenzie Weygandt Mathis', 'link': 'https://arxiv.org/abs/2502.12977', 'abstract': 'Gradient-based attribution methods aim to explain decisions of deep learning models but so far lack identifiability guarantees. Here, we propose a method to generate attribution maps with identifiability guarantees by developing a regularized contrastive learning algorithm trained on time-series data plus a new attribution method called Inverted Neuron Gradient (collectively named xCEBRA). We show theoretically that xCEBRA has favorable properties for identifying the Jacobian matrix of the data generating process. Empirically, we demonstrate robust approximation of zero vs. non-zero entries in the ground-truth attribution map on synthetic datasets, and significant improvements across previous attribution methods based on feature ablation, Shapley values, and other gradient-based methods. Our work constitutes a first example of identifiable inference of time-series attribution maps and opens avenues to a better understanding of time-series data, such as for neural dynamics and decision-processes within neural networks.', 'abstract_zh': '基于梯度的归因方法旨在解释深度学习模型的决策，但迄今为止缺乏可识别性保证。在这里，我们提出了一种通过在时间序列数据上开发正则化的对比学习算法并结合一种新的归因方法（称为反转神经元梯度，统称为xceBRA）来生成具有可识别性保证的归因图的方法。我们理论证明xceBRA具有识别数据生成过程雅可比矩阵的良好性质。在实验中，我们在合成数据集上展示了对真实归因图中零值与非零值的鲁棒近似，并显著改进了基于特征消融、Shapley值和其他基于梯度的方法的先前归因方法。我们的工作构成了时间序列归因图可识别推断的第一个示例，并为更好地理解时间序列数据，如神经动力学和神经网络内的决策过程提供了途径。', 'title_zh': '正则化对比学习下的时间序列归因图'}
{'arxiv_id': 'arXiv:2502.12965', 'title': 'A Survey of Text Classification Under Class Distribution Shift', 'authors': 'Adriana Valentina Costache, Silviu Florin Gheorghe, Eduard Gabriel Poesina, Paul Irofti, Radu Tudor Ionescu', 'link': 'https://arxiv.org/abs/2502.12965', 'abstract': 'The basic underlying assumption of machine learning (ML) models is that the training and test data are sampled from the same distribution. However, in daily practice, this assumption is often broken, i.e.~the distribution of the test data changes over time, which hinders the application of conventional ML models. One domain where the distribution shift naturally occurs is text classification, since people always find new topics to discuss. To this end, we survey research articles studying open-set text classification and related tasks. We divide the methods in this area based on the constraints that define the kind of distribution shift and the corresponding problem formulation, i.e.~learning with the Universum, zero-shot learning, and open-set learning. We next discuss the predominant mitigation approaches for each problem setup. Finally, we identify several future work directions, aiming to push the boundaries beyond the state of the art. Interestingly, we find that continual learning can solve many of the issues caused by the shifting class distribution. We maintain a list of relevant papers at this https URL.', 'abstract_zh': '机器学习模型的基本假设是训练数据和测试数据来自相同的分布。然而，在实际应用中，这种假设常常被打破，即测试数据的分布会随时间变化，这阻碍了传统机器学习模型的应用。文本分类领域自然会遇到分布偏移的问题，因为人们总能找到新的讨论主题。为此，我们综述了研究开放集文本分类及相关任务的文章。我们将该领域的方法根据界定分布偏移类型及其相应的研究问题进行分类，即使用Universum学习、零样本学习和开放集学习。接着，我们讨论了每种问题设置的主要缓解方法。最后，我们确定了若干未来研究方向，旨在超越现有技术水平。有趣的是，我们发现连续学习可以解决由类分布偏移引起的一些问题。我们在此维护了一份相关论文的列表：https://this.url/', 'title_zh': '文本分类中的类别分布偏移综述'}
{'arxiv_id': 'arXiv:2502.12959', 'title': 'AlignFreeze: Navigating the Impact of Realignment on the Layers of Multilingual Models Across Diverse Languages', 'authors': 'Steve Bakos, Félix Gaschi, David Guzmán, Riddhi More, Kelly Chutong Li, En-Shiun Annie Lee', 'link': 'https://arxiv.org/abs/2502.12959', 'abstract': "Realignment techniques are often employed to enhance cross-lingual transfer in multilingual language models, still, they can sometimes degrade performance in languages that differ significantly from the fine-tuned source language. This paper introduces AlignFreeze, a method that freezes either the layers' lower half or upper half during realignment. Through controlled experiments on 4 tasks, 3 models, and in 35 languages, we find that realignment affects all the layers but can be the most detrimental to the lower ones. Freezing the lower layers can prevent performance degradation. Particularly, AlignFreeze improves Part-of-Speech (PoS) tagging performances in languages where full realignment fails: with XLM-R, it provides improvements of more than one standard deviation in accuracy in seven more languages than full realignment.", 'abstract_zh': 'Realignment 技术常用于增强多语言语言模型中的跨语言转移，但有时会在与精细调整源语言差异较大的语言中降低性能。本文介绍了一种名为 AlignFreeze 的方法，该方法在重新对齐过程中冻结层的下半部分或上半部分。通过在 4 个任务、3 个模型和 35 种语言上的受控实验，我们发现重新对齐会影响所有层，但对下层的影响尤为严重。冻结下层可以防止性能下降。特别是在语言全面重新对齐失败时，AlignFreeze 提高了部分词性标注（PoS）的性能：与全面重新对齐相比，使用 XLM-R 在七种更多语言中提供了超过一个标准差的准确率改进。', 'title_zh': 'AlignFreeze: 导航重新对齐对多语言模型各层跨多种语言的影响'}
{'arxiv_id': 'arXiv:2502.12953', 'title': 'Task-Informed Anti-Curriculum by Masking Improves Downstream Performance on Text', 'authors': 'Andrei Jarca, Florinel Alin Croitoru, Radu Tudor Ionescu', 'link': 'https://arxiv.org/abs/2502.12953', 'abstract': 'Masked language modeling has become a widely adopted unsupervised technique to pre-train language models. However, the process of selecting tokens for masking is random, and the percentage of masked tokens is typically fixed for the entire training process. In this paper, we propose to adjust the masking ratio and to decide which tokens to mask based on a novel task-informed anti-curriculum learning scheme. First, we harness task-specific knowledge about useful and harmful tokens in order to determine which tokens to mask. Second, we propose a cyclic decaying masking ratio, which corresponds to an anti-curriculum schedule (from hard to easy). We exemplify our novel task-informed anti-curriculum by masking (TIACBM) approach across three diverse downstream tasks: sentiment analysis, text classification by topic, and authorship attribution. Our findings suggest that TIACBM enhances the ability of the model to focus on key task-relevant features, contributing to statistically significant performance gains across tasks. We release our code at this https URL.', 'abstract_zh': '基于任务信息的反梯度学习掩码语言模型方法', 'title_zh': '基于掩码的任务导向反 curriculum 提高文本下游性能'}
{'arxiv_id': 'arXiv:2502.12948', 'title': 'Fake It Till You Make It: Using Synthetic Data and Domain Knowledge for Improved Text-Based Learning for LGE Detection', 'authors': 'Athira J Jacob, Puneet Sharma, Daniel Rueckert', 'link': 'https://arxiv.org/abs/2502.12948', 'abstract': 'Detection of hyperenhancement from cardiac LGE MRI images is a complex task requiring significant clinical expertise. Although deep learning-based models have shown promising results for the task, they require large amounts of data with fine-grained annotations. Clinical reports generated for cardiac MR studies contain rich, clinically relevant information, including the location, extent and etiology of any scars present. Although recently developed CLIP-based training enables pretraining models with image-text pairs, it requires large amounts of data and further finetuning strategies on downstream tasks. In this study, we use various strategies rooted in domain knowledge to train a model for LGE detection solely using text from clinical reports, on a relatively small clinical cohort of 965 patients. We improve performance through the use of synthetic data augmentation, by systematically creating scar images and associated text. In addition, we standardize the orientation of the images in an anatomy-informed way to enable better alignment of spatial and text features. We also use a captioning loss to enable fine-grained supervision and explore the effect of pretraining of the vision encoder on performance. Finally, ablation studies are carried out to elucidate the contributions of each design component to the overall performance of the model.', 'abstract_zh': '使用临床报告文本训练心脏LGE检测模型：基于领域知识的方法', 'title_zh': '伪装以做到最好：通过合成数据和领域知识提高基于文本的学习方法以增强LGE检测'}
{'arxiv_id': 'arXiv:2502.12947', 'title': 'Every Expert Matters: Towards Effective Knowledge Distillation for Mixture-of-Experts Language Models', 'authors': 'Gyeongman Kim, Gyouk Chu, Eunho Yang', 'link': 'https://arxiv.org/abs/2502.12947', 'abstract': 'With the emergence of Mixture-of-Experts (MoE), the efficient scaling of model size has accelerated the development of large language models in recent years. However, their high memory requirements prevent their use in resource-constrained environments. While knowledge distillation (KD) has been a proven method for model compression, its application to MoE teacher models remains underexplored. Through our investigation, we discover that non-activated experts in MoE models possess valuable knowledge that benefits student models. We further demonstrate that existing KD methods are not optimal for compressing MoE models, as they fail to leverage this knowledge effectively. To address this, we propose two intuitive MoE-specific KD methods for the first time: Knowledge Augmentation (KA) and Student-Aware Router (SAR), both designed to effectively extract knowledge from all experts. Specifically, KA augments knowledge by sampling experts multiple times, while SAR uses all experts and adjusts the expert weights through router training to provide optimal knowledge. Extensive experiments show that our methods outperform conventional KD methods, demonstrating their effectiveness for MoE teacher models.', 'abstract_zh': 'MoE模型特定的知识蒸馏方法：知识扩充与学生感知路由', 'title_zh': '每一专家都重要：迈向有效的混合专家语言模型知识蒸馏方法'}
{'arxiv_id': 'arXiv:2502.12929', 'title': 'Flow-of-Options: Diversified and Improved LLM Reasoning by Thinking Through Options', 'authors': 'Lakshmi Nair, Ian Trase, Mark Kim', 'link': 'https://arxiv.org/abs/2502.12929', 'abstract': 'We present a novel reasoning approach called Flow-of-Options (FoO), designed to address intrinsic biases in Large Language Models (LLMs). FoO enables LLMs to systematically explore a diverse range of possibilities in their reasoning, as demonstrated by an FoO-based agentic system for autonomously solving Machine Learning tasks (AutoML). Our framework outperforms state-of-the-art baselines, achieving improvements of 38.2% - 69.2% on standard data science tasks, and 37.4% - 47.9% on therapeutic chemistry tasks. With an overall operation cost under $1 per task, our framework is well-suited for cost-sensitive applications. Beyond classification and regression, we illustrate the broader applicability of our FoO-based agentic system to tasks such as reinforcement learning and image generation. Our framework presents significant advancements compared to current state-of-the-art agentic systems for AutoML, due to the benefits of FoO in enforcing diversity in LLM solutions through compressed, explainable representations that also support long-term memory when combined with case-based reasoning.', 'abstract_zh': 'Flow-of-Options (FoO): 一种针对大规模语言模型内在偏见的新颖推理方法及其在自主解决机器学习任务中的应用', 'title_zh': '选项流：通过思考选项多样化的提升大语言模型推理能力'}
{'arxiv_id': 'arXiv:2502.12925', 'title': 'Keep what you need : extracting efficient subnetworks from large audio representation models', 'authors': 'David Genova, Philippe Esling, Tom Hurlin', 'link': 'https://arxiv.org/abs/2502.12925', 'abstract': 'Recently, research on audio foundation models has witnessed notable advances, as illustrated by the ever improving results on complex downstream tasks. Subsequently, those pretrained networks have quickly been used for various audio applications. These improvements have however resulted in a considerable increase both in size and complexity of these models. Along the environmental concerns this issue raises, this prevents the deployment of such networks on consumer-level devices, and precludes their use for real-time applications. Moreover, this appears contradictory with the specificity of the tasks for which these models are used, which are often simpler compared to extracting a rich, multi-purpose representation from any type of audio data. In this paper, we address this issue with a simple, yet effective method to extract lightweight specialist subnetworks from large foundation models. Specifically, we introduce learnable binary masks in-between the layers of a pretrained representation model. When training the end-to-end model on a downstream task, we add a sparsity-inducing loss to the overall objective, hence learning a compact subnetwork specialized on a single task. Importantly, the weights of the foundation model are kept frozen, resulting into low additional training costs. Once trained, the masked computational units can then be removed from the network, implying significant performance gains. We assess our method on three widespread audio foundation models, each based on a different backbone architecture, and illustrate its effectiveness on common audio representation evaluation tasks, as well as its versatility on both speech, music, and general audio. Code for reproducing the results and supporting webpage are available at this https URL', 'abstract_zh': '近年来，音频基础模型的研究取得了显著进展，这体现在其在复杂下游任务上的持续改进结果上。随后，这些预训练网络被迅速应用于各种音频应用中。然而，这些改进导致了模型规模和复杂性的显著增加。这一问题不仅引发环境关切，还阻碍了在消费级设备上的部署，并限制了其用于实时应用。此外，这似乎与这些模型所使用的特定任务的复杂性相矛盾，后者的复杂性往往低于从任何类型音频数据中提取丰富、多功能表示的需求。在本文中，我们提出了一种简单而有效的方法，从大模型中提取轻量级的专业子网络。具体而言，我们引入了可学习的二值掩码，位于预训练表示模型的层之间。在针对下游任务训练端到端模型时，我们添加了一个促进稀疏性的损失函数，从而学习一个专门针对单一任务的精简子网络。重要的是，基础模型的权重保持冻结状态，从而降低了额外的训练成本。训练完成后，可以移除带有掩码的计算单元，这带来了显著的性能提升。我们在三个广泛使用的音频基础模型上评估了我们的方法，每个模型基于不同的骨干架构，并通过常见的音频表示评估任务展示了其有效性，以及在语音、音乐和通用音频上的 versatility。用于复现结果的代码和支持页面可在以下链接获取：this https URL。', 'title_zh': '保留所需部分：从大型音频表示模型中提取高效子网络'}
{'arxiv_id': 'arXiv:2502.12924', 'title': 'Conditioning LLMs to Generate Code-Switched Text: A Methodology Grounded in Naturally Occurring Data', 'authors': 'Maite Heredia, Gorka Labaka, Jeremy Barnes, Aitor Soroa', 'link': 'https://arxiv.org/abs/2502.12924', 'abstract': "Code-switching (CS) is still a critical challenge in Natural Language Processing (NLP). Current Large Language Models (LLMs) struggle to interpret and generate code-switched text, primarily due to the scarcity of large-scale CS datasets for training. This paper presents a novel methodology to generate CS data using LLMs, and test it on the English-Spanish language pair. We propose back-translating natural CS sentences into monolingual English, and using the resulting parallel corpus to fine-tune LLMs to turn monolingual sentences into CS. Unlike previous approaches to CS generation, our methodology uses natural CS data as a starting point, allowing models to learn its natural distribution beyond grammatical patterns. We thoroughly analyse the models' performance through a study on human preferences, a qualitative error analysis and an evaluation with popular automatic metrics. Results show that our methodology generates fluent code-switched text, expanding research opportunities in CS communication, and that traditional metrics do not correlate with human judgement when assessing the quality of the generated CS data. We release our code and generated dataset under a CC-BY-NC-SA license.", 'abstract_zh': '代码转换仍是自然语言处理中的一个关键挑战。当前的大语言模型在处理和生成代码转换文本时遇到困难，主要原因是缺乏大规模的代码转换数据集进行训练。本文提出了一种新的利用大语言模型生成代码转换数据的方法，并在英西语言对上进行了测试。我们提出了一种将自然的代码转换句子回译为单一语言英语的方法，并使用生成的平行语料库对大语言模型进行微调，使其能够将单一语言句子转换为代码转换文本。与以前的代码转换生成方法不同，我们的方法以自然的代码转换数据作为起点，使模型能够学习代码转换的自然分布模式，而不仅仅是句法模式。我们通过人类偏好研究、定性错误分析和使用流行自动评价指标进行评估，全面分析了模型的性能。结果表明，我们的方法可以生成流畅的代码转换文本，扩展了代码转换通信的研究机会，并且传统的评价指标与人类对生成代码转换数据质量的判断之间不存在相关性。我们将在CC-BY-NC-SA许可下发布我们的代码和生成的数据集。', 'title_zh': '基于自然发生数据的条件生成切换代码文本的方法论'}
{'arxiv_id': 'arXiv:2502.12913', 'title': 'GSQ-Tuning: Group-Shared Exponents Integer in Fully Quantized Training for LLMs On-Device Fine-tuning', 'authors': 'Sifan Zhou, Shuo Wang, Zhihang Yuan, Mingjia Shi, Yuzhang Shang, Dawei Yang', 'link': 'https://arxiv.org/abs/2502.12913', 'abstract': 'Large Language Models (LLMs) fine-tuning technologies have achieved remarkable results. However, traditional LLM fine-tuning approaches face significant challenges: they require large Floating Point (FP) computation, raising privacy concerns when handling sensitive data, and are impractical for resource-constrained edge devices. While Parameter-Efficient Fine-Tuning (PEFT) techniques reduce trainable parameters, their reliance on floating-point arithmetic creates fundamental incompatibilities with edge hardware. In this work, we introduce a novel framework for on-device LLM fine-tuning that eliminates the need for floating-point operations in both inference and training, named GSQ-Tuning. At its core is the Group-Shared Exponents Integer format, which efficiently represents model parameters in integer format using shared exponents among parameter groups. When combined with LoRA-like adapters, this enables fully integer-based fine-tuning that is both memory and compute efficient. We demonstrate that our approach achieves accuracy comparable to FP16-based fine-tuning while significantly reducing memory usage (50%). Moreover, compared to FP8, our method can reduce 5x power consumption and 11x chip area with same performance, making large-scale model adaptation feasible on edge devices.', 'abstract_zh': '基于设备端的大语言模型细调框架：GSQ-Tuning', 'title_zh': 'GSQ-Tuning: Group-Shared Exponents Integer in Fully Quantized Training for LLMs On-Device Fine-tuning'}
{'arxiv_id': 'arXiv:2502.12908', 'title': 'Graph Neural Networks for Databases: A Survey', 'authors': 'Ziming Li, Youhuan Li, Yuyu Luo, Guoliang Li, Chuxu Zhang', 'link': 'https://arxiv.org/abs/2502.12908', 'abstract': 'Graph neural networks (GNNs) are powerful deep learning models for graph-structured data, demonstrating remarkable success across diverse domains. Recently, the database (DB) community has increasingly recognized the potentiality of GNNs, prompting a surge of researches focusing on improving database systems through GNN-based approaches. However, despite notable advances, There is a lack of a comprehensive review and understanding of how GNNs could improve DB systems. Therefore, this survey aims to bridge this gap by providing a structured and in-depth overview of GNNs for DB systems. Specifically, we propose a new taxonomy that classifies existing methods into two key categories: (1) Relational Databases, which includes tasks like performance prediction, query optimization, and text-to-SQL, and (2) Graph Databases, addressing challenges like efficient graph query processing and graph similarity computation. We systematically review key methods in each category, highlighting their contributions and practical implications. Finally, we suggest promising avenues for integrating GNNs into Database systems.', 'abstract_zh': '图神经网络（GNNs）是处理图结构数据的强大力量深学习模型，已在多个领域取得显著成果。最近，数据库（DB）社区越来越认识到GNNs的潜力，促使通过GNN基础方法改进数据库系统的研究呈上升趋势。然而，尽管取得了显著进展，但仍缺乏对GNNs如何改善数据库系统进行全面的综述和理解。因此，本文旨在通过提供GNNs在数据库系统中的结构化和深入概述来填补这一空白。具体而言，我们提出了一种新的分类法，将现有方法分为两大类：（1）关系型数据库，包括性能预测、查询优化和文本到SQL等任务；（2）图数据库，解决高效图查询处理和图相似性计算等挑战。我们系统地审查了每个类别的关键方法，强调了它们的贡献和实际影响。最后，我们提出了将GNNs集成到数据库系统中的有前途的途径。', 'title_zh': '图神经网络在数据库中的应用：一个综述'}
{'arxiv_id': 'arXiv:2502.12900', 'title': 'Soundwave: Less is More for Speech-Text Alignment in LLMs', 'authors': 'Yuhao Zhang, Zhiheng Liu, Fan Bu, Ruiyu Zhang, Benyou Wang, Haizhou Li', 'link': 'https://arxiv.org/abs/2502.12900', 'abstract': 'Existing end-to-end speech large language models (LLMs) usually rely on large-scale annotated data for training, while data-efficient training has not been discussed in depth. We focus on two fundamental problems between speech and text: the representation space gap and sequence length inconsistency. We propose Soundwave, which utilizes an efficient training strategy and a novel architecture to address these issues. Results show that Soundwave outperforms the advanced Qwen2-Audio in speech translation and AIR-Bench speech tasks, using only one-fiftieth of the training data. Further analysis shows that Soundwave still retains its intelligence during conversation. The project is available at this https URL.', 'abstract_zh': '现有的端到端语音大型语言模型通常依赖大规模标注数据进行训练，而数据高效训练尚未得到充分讨论。我们专注于语音与文本之间的两个基本问题：表示空间差距和序列长度不一致。我们提出Soundwave，该方法利用高效的训练策略和新型架构来解决这些问题。结果表明，Soundwave在语音翻译和AIR-Bench语音任务上的表现优于先进的Qwen2-Audio，仅使用其五分之一的训练数据。进一步的分析表明，Soundwave在对话过程中仍能保持其智能。项目详情请参见此链接。', 'title_zh': 'Soundwave: 少即是多的语音-文本对齐方法在LLMs中的应用'}
{'arxiv_id': 'arXiv:2502.12859', 'title': 'PAFT: Prompt-Agnostic Fine-Tuning', 'authors': 'Chenxing Wei, Yao Shu, Mingwen Ou, Ying Tiffany He, Fei Richard Yu', 'link': 'https://arxiv.org/abs/2502.12859', 'abstract': 'While Large Language Models (LLMs) adapt well to downstream tasks after fine-tuning, this adaptability often compromises prompt robustness, as even minor prompt variations can significantly degrade performance. To address this, we propose Prompt-Agnostic Fine-Tuning(PAFT), a simple yet effective approach that dynamically adjusts prompts during fine-tuning. This encourages the model to learn underlying task principles rather than overfitting to specific prompt formulations. PAFT operates in two stages: First, a diverse set of meaningful, synthetic candidate prompts is constructed. Second, during fine-tuning, prompts are randomly sampled from this set to create dynamic training inputs. Extensive experiments across diverse datasets and LLMs demonstrate that models trained with PAFT exhibit strong robustness and generalization across a wide range of prompts, including unseen ones. This enhanced robustness improves both model performance and inference speed while maintaining training efficiency. Ablation studies further confirm the effectiveness of PAFT.', 'abstract_zh': '面向提示的鲁棒无提示微调(PAFT)', 'title_zh': 'PAFT: 命令无感 fine-tuning'}
{'arxiv_id': 'arXiv:2502.12858', 'title': 'Rejected Dialects: Biases Against African American Language in Reward Models', 'authors': 'Joel Mire, Zubin Trivadi Aysola, Daniel Chechelnitsky, Nicholas Deas, Chrysoula Zerva, Maarten Sap', 'link': 'https://arxiv.org/abs/2502.12858', 'abstract': "Preference alignment via reward models helps build safe, helpful, and reliable large language models (LLMs). However, subjectivity in preference judgments and the lack of representative sampling in preference data collection can introduce new biases, hindering reward models' fairness and equity. In this work, we introduce a framework for evaluating dialect biases in reward models and conduct a case study on biases against African American Language (AAL) through several experiments comparing reward model preferences and behavior on paired White Mainstream English (WME) and both machine-translated and human-written AAL corpora. We show that reward models are less aligned with human preferences when processing AAL texts vs. WME ones (-4\\% accuracy on average), frequently disprefer AAL-aligned texts vs. WME-aligned ones, and steer conversations toward WME, even when prompted with AAL texts. Our findings provide a targeted analysis of anti-AAL biases at a relatively understudied stage in LLM development, highlighting representational harms and ethical questions about the desired behavior of LLMs concerning AAL.", 'abstract_zh': '偏好对齐通过奖励模型有助于构建安全、 helpful 和可信赖的大规模语言模型（LLMs）。然而，偏好判断中的主观性以及偏好数据收集中缺乏代表性抽样会引入新的偏差，阻碍奖励模型的公平性和公正性。在本文中，我们介绍了一种评估奖励模型方言偏差的框架，并通过多项实验研究了奖励模型对标准主流英语（WME）和机器翻译及人工撰写的非洲美语（AAL）语料库的偏好和行为，从而探讨反AAL偏差。我们展示了当处理AAL文本而非WME文本时，奖励模型与人类偏好的对齐度较低（平均准确率降低4%），倾向于不喜欢与AAL对齐的文本，即使在收到AAL文本提示时，也会引导对话转向WME。我们的研究结果对LLM发展中相对较少研究的阶段提供了一个针对性的分析，突显了AAL表示损害及关于LLM期望行为的伦理问题。', 'title_zh': '拒绝的方言：奖励模型中对非洲美国语言偏见的研究'}
{'arxiv_id': 'arXiv:2502.12855', 'title': 'Integrating Arithmetic Learning Improves Mathematical Reasoning in Smaller Models', 'authors': 'Neeraj Gangwar, Suma P Bhat, Nickvash Kani', 'link': 'https://arxiv.org/abs/2502.12855', 'abstract': "While large models pre-trained on high-quality data exhibit excellent performance across various reasoning tasks, including mathematical reasoning (e.g. GSM8k, MultiArith), specializing smaller models to excel at mathematical reasoning remains a challenging problem. Common approaches to address this challenge include knowledge distillation, where smaller student models learn from large pre-trained teacher models, and data augmentation, such as rephrasing questions. Despite these efforts, smaller models struggle with arithmetic computations, leading to errors in mathematical reasoning. In this work, we focus on leveraging a programmatically generated arithmetic dataset to enhance the reasoning capabilities of smaller models. We investigate two key approaches to incorporate this dataset -- (1) intermediate fine-tuning, where a model is fine-tuned on the arithmetic dataset before being trained on a reasoning dataset, and (2) integrating the arithmetic dataset into the instruction-tuning mixture, allowing the model to learn arithmetic skills alongside general instruction-following abilities. Our experiments on multiple reasoning benchmarks demonstrate that incorporating an arithmetic dataset, whether through targeted fine-tuning or within the instruction-tuning mixture, enhances the models' arithmetic capabilities, which in turn improves their mathematical reasoning performance.", 'abstract_zh': '尽管预训练于高质量数据的大模型在各种推理任务中表现出色，包括数学推理（如GSM8k、MultiArith），但使较小的模型在数学推理方面表现出色仍然是一个具有挑战性的问题。解决这一挑战的常见方法包括知识蒸馏，其中较小的学生模型从大型预训练教师模型中学习，以及数据增强，例如重新表述问题。尽管如此，较小的模型在进行算术计算时仍然存在问题，导致数学推理中的错误。在本工作中，我们重点利用程序生成的算术数据集来增强较小模型的推理能力。我们考察了两种关键方法来融入这个数据集——（1）中间微调，即在模型在推理数据集上训练之前先在算术数据集上进行微调；（2）将算术数据集整合到指令调优混合模型中，使模型在学习算术技能的同时也能够掌握一般的指令遵循能力。在多个推理基准上的实验表明，无论是通过定向微调还是将其整合到指令调优混合模型中，引入算术数据集都能提高模型的算术能力，进而提升其数学推理性能。', 'title_zh': '整合算术学习提高小模型的数学推理能力'}
{'arxiv_id': 'arXiv:2502.12851', 'title': 'MeMo: Towards Language Models with Associative Memory Mechanisms', 'authors': 'Fabio Massimo Zanzotto, Elena Sofia Ruzzetti, Giancarlo A. Xompero, Leonardo Ranaldi, Davide Venditti, Federico Ranaldi, Cristina Giannone, Andrea Favalli, Raniero Romagnoli', 'link': 'https://arxiv.org/abs/2502.12851', 'abstract': 'Memorization is a fundamental ability of Transformer-based Large Language Models, achieved through learning. In this paper, we propose a paradigm shift by designing an architecture to memorize text directly, bearing in mind the principle that memorization precedes learning. We introduce MeMo, a novel architecture for language modeling that explicitly memorizes sequences of tokens in layered associative memories. By design, MeMo offers transparency and the possibility of model editing, including forgetting texts. We experimented with the MeMo architecture, showing the memorization power of the one-layer and the multi-layer configurations.', 'abstract_zh': '基于Transformer的大型语言模型的记忆是其基本能力，通过学习获得。本文提出一种范式转移，设计一种直接记忆文本的架构，遵循记忆先于学习的原则。我们介绍了MeMo，一种新颖的语言模型架构，明确在分层关联记忆中记忆令牌序列。设计上，MeMo提供了透明度和模型编辑的可能性，包括遗忘文本。我们实验了MeMo架构，展示了单层和多层配置的记忆能力。', 'title_zh': 'MeMo：兼具关联记忆机制的语言模型'}
{'arxiv_id': 'arXiv:2502.12825', 'title': 'Reasoning and the Trusting Behavior of DeepSeek and GPT: An Experiment Revealing Hidden Fault Lines in Large Language Models', 'authors': 'Rubing Lu, João Sedoc, Arun Sundararajan', 'link': 'https://arxiv.org/abs/2502.12825', 'abstract': "When encountering increasingly frequent performance improvements or cost reductions from a new large language model (LLM), developers of applications leveraging LLMs must decide whether to take advantage of these improvements or stay with older tried-and-tested models. Low perceived switching frictions can lead to choices that do not consider more subtle behavior changes that the transition may induce. Our experiments use a popular game-theoretic behavioral economics model of trust to show stark differences in the trusting behavior of OpenAI's and DeepSeek's models. We highlight a collapse in the economic trust behavior of the o1-mini and o3-mini models as they reconcile profit-maximizing and risk-seeking with future returns from trust, and contrast it with DeepSeek's more sophisticated and profitable trusting behavior that stems from an ability to incorporate deeper concepts like forward planning and theory-of-mind. As LLMs form the basis for high-stakes commercial systems, our results highlight the perils of relying on LLM performance benchmarks that are too narrowly defined and suggest that careful analysis of their hidden fault lines should be part of any organization's AI strategy.", 'abstract_zh': '当遇到来自新大型语言模型（LLM）日益频繁的性能提升或成本降低时，利用LLM的应用开发人员必须决定是否利用这些改进或继续使用较为成熟的旧模型。较低的转换摩擦感知可能导致忽略转换可能引起的更微妙的行为变化。我们的实验使用一个流行的游戏理论行为经济学模型来展示OpenAI与DeepSeek模型在信任行为上的截然不同。我们指出，在o1-mini和o3-mini模型中，随着它们将利润最大化和风险偏好与信任带来的未来收益进行融合，信任经济行为出现崩溃，而DeepSeek的模型则表现出更加复杂、更有利可图的信任行为，这源于其能够整合更深层次的概念如前瞻规划和理论思维的能力。随着LLM成为高风险商业系统的基础，我们的结果突显了依赖于定义过于狭窄的LLM性能基准的危险，并建议任何组织的人工智能战略中应包含对隐藏薄弱环节的仔细分析。', 'title_zh': 'DeepSeek和GPT的推理与信任行为：一项揭示大型语言模型潜在裂纹的实验'}
{'arxiv_id': 'arXiv:2502.12798', 'title': 'Envious Explore and Exploit', 'authors': 'Omer Ben-Porat, Yotam Gafni, Or Markovetzki', 'link': 'https://arxiv.org/abs/2502.12798', 'abstract': 'Explore-and-exploit tradeoffs play a key role in recommendation systems (RSs), aiming at serving users better by learning from previous interactions. Despite their commercial success, the societal effects of explore-and-exploit mechanisms are not well understood, especially regarding the utility discrepancy they generate between different users. In this work, we measure such discrepancy using the economic notion of envy. We present a multi-armed bandit-like model in which every round consists of several sessions, and rewards are realized once per round. We call the latter property reward consistency, and show that the RS can leverage this property for better societal outcomes. On the downside, doing so also generates envy, as late-to-arrive users enjoy the information gathered by early-to-arrive users. We examine the generated envy under several arrival order mechanisms and virtually any anonymous algorithm, i.e., any algorithm that treats all similar users similarly without leveraging their identities. We provide tight envy bounds on uniform arrival and upper bound the envy for nudged arrival, in which the RS can affect the order of arrival by nudging its users. Furthermore, we study the efficiency-fairness trade-off by devising an algorithm that allows constant envy and approximates the optimal welfare in restricted settings. Finally, we validate our theoretical results empirically using simulations.', 'abstract_zh': '探索与利用权衡在推荐系统中的作用：通过学习先前的交互更好地服务用户，尽管探索与利用机制在商业上取得了成功，但它们对社会的影响尚未得到充分理解，特别是它们为不同用户带来的效用偏差。在本工作中，我们使用经济概念中的嫉妒度量这种偏差。我们提出了一种类似于多臂_bandit_模型，在其中每个轮次包含若干会话，并且奖励在每个轮次结束时实现。我们称后一种性质为奖励一致性，并表明推荐系统可以利用这一性质以实现更好的社会效益。然而，这样做也会导致嫉妒，因为后来到达的用户可以享受到早期到达的用户收集的信息。我们研究了在几种不同的到达顺序机制下生成的嫉妒，并考虑了任何不利用用户身份信息的任何匿名算法。我们为均匀到达提供了精确的嫉妒边界，并为通过影响到达顺序推荐系统生成的嫉妒提供了上界。此外，我们通过设计一个允许恒定嫉妒并近似在受限条件下最优福利的算法研究了效率与公平之间的权衡。最后，我们通过仿真验证了我们的理论结果。', 'title_zh': '嫉妒性探索与利用'}
{'arxiv_id': 'arXiv:2502.12793', 'title': 'Unsupervised Anomaly Detection through Mass Repulsing Optimal Transport', 'authors': 'Eduardo Fernandes Montesuma, Adel El Habazi, Fred Ngole Mboula', 'link': 'https://arxiv.org/abs/2502.12793', 'abstract': 'Detecting anomalies in datasets is a longstanding problem in machine learning. In this context, anomalies are defined as a sample that significantly deviates from the remaining data. Meanwhile, optimal transport (OT) is a field of mathematics concerned with the transportation, between two probability measures, at least effort. In classical OT, the optimal transportation strategy of a measure to itself is the identity. In this paper, we tackle anomaly detection by forcing samples to displace its mass, while keeping the least effort objective. We call this new transportation problem Mass Repulsing Optimal Transport (MROT). Naturally, samples lying in low density regions of space will be forced to displace mass very far, incurring a higher transportation cost. We use these concepts to design a new anomaly score. Through a series of experiments in existing benchmarks, and fault detection problems, we show that our algorithm improves over existing methods.', 'abstract_zh': '在机器学习中检测数据集中的异常是一个长期存在的问题。在这一背景下，异常被定义为显著偏离其余数据的一个样本。同时，最优运输（OT）是一门数学领域，关注的是在两个概率测度之间的运输，以最小的努力进行。在古典最优运输中，一个测度到自身的最优运输策略是恒等映射。在本文中，我们通过强制样本移动其质量，同时保持最小努力目标来解决异常检测问题。我们将这种新的运输问题称为质量排斥最优运输（MROT）。自然地，位于空间低密度区域的样本将被迫移动很远的质量，导致更高的运输成本。我们利用这些概念设计了一个新的异常值评分方法。通过一系列在现有基准和故障检测问题中的实验，我们展示了我们的算法优于现有方法。', 'title_zh': '无监督异常检测通过质量排斥最优传输'}
{'arxiv_id': 'arXiv:2502.12777', 'title': 'Evaluating link prediction: New perspectives and recommendations', 'authors': 'Bhargavi Kalyani I, A Rama Prasad Mathi, Niladri Sett', 'link': 'https://arxiv.org/abs/2502.12777', 'abstract': 'Link prediction (LP) is an important problem in network science and machine learning research. The state-of-the-art LP methods are usually evaluated in a uniform setup, ignoring several factors associated with the data and application specific needs. We identify a number of such factors, such as, network-type, problem-type, geodesic distance between the end nodes and its distribution over the classes, nature and applicability of LP methods, class imbalance and its impact on early retrieval, evaluation metric, etc., and present an experimental setup which allows us to evaluate LP methods in a rigorous and controlled manner. We perform extensive experiments with a variety of LP methods over real network datasets in this controlled setup, and gather valuable insights on the interactions of these factors with the performance of LP through an array of carefully designed hypotheses. Following the insights, we provide recommendations to be followed as best practice for evaluating LP methods.', 'abstract_zh': '链接预测（LP）是网络科学和机器学习研究中的一个重要问题。最前沿的LP方法通常在统一的评估框架下进行评估，忽视了与数据和应用需求相关的多个因素。我们识别出若干此类因素，如网络类型、问题类型、端节点的测地距离及其在类别的分布、LP方法的性质及其适用性、类不平衡及其对早期检索的影响、评估指标等，并提出一个严格的控制实验框架，以评估LP方法。我们在这一控制框架下使用多种LP方法对实际网络数据集进行广泛的实验，并通过一系列精心设计的假设，收集了关于这些因素与LP性能之间相互作用的宝贵见解。基于这些见解，我们提供了作为最佳实践遵循的评估LP方法的建议。', 'title_zh': '评价链接预测：新视角与建议'}
{'arxiv_id': 'arXiv:2502.12776', 'title': 'Portable Reward Tuning: Towards Reusable Fine-Tuning across Different Pretrained Models', 'authors': 'Daiki Chijiwa, Taku Hasegawa, Kyosuke Nishida, Kuniko Saito, Susumu Takeuchi', 'link': 'https://arxiv.org/abs/2502.12776', 'abstract': 'While foundation models have been exploited for various expert tasks through fine-tuning, any foundation model will become outdated due to its old knowledge or limited capability. Thus the underlying foundation model should be eventually replaced by new ones, which leads to repeated cost of fine-tuning these new models. Existing work addresses this problem by inference-time tuning, i.e., modifying the output probabilities from the new foundation model with the outputs from the old foundation model and its fine-tuned model, which involves an additional overhead in inference by the latter two models. In this paper, we propose a new fine-tuning principle, Portable Reward Tuning (PRT), that reduces the inference overhead by its nature, based on the reformulation of fine-tuning as the reward maximization. Specifically, instead of fine-tuning parameters of the foundation models, PRT trains the reward model explicitly through the same loss function as in fine-tuning. During inference, the reward model can be used with any foundation model (with the same set of vocabularies or labels) through the formulation of reward maximization. Experimental results, covering both vision and language models, demonstrate that the PRT-trained model can achieve comparable accuracy to the existing work of inference-time tuning, with less inference cost.', 'abstract_zh': '基于奖励最大化原则的便携式微调（PRT）', 'title_zh': '便携式奖励调整：朝向跨不同预训练模型的可重用微调'}
{'arxiv_id': 'arXiv:2502.12769', 'title': 'How Much Do LLMs Hallucinate across Languages? On Multilingual Estimation of LLM Hallucination in the Wild', 'authors': 'Saad Obaid ul Islam, Anne Lauscher, Goran Glavaš', 'link': 'https://arxiv.org/abs/2502.12769', 'abstract': "In the age of misinformation, hallucination -- the tendency of Large Language Models (LLMs) to generate non-factual or unfaithful responses -- represents the main risk for their global utility. Despite LLMs becoming increasingly multilingual, the vast majority of research on detecting and quantifying LLM hallucination are (a) English-centric and (b) focus on machine translation (MT) and summarization, tasks that are less common ``in the wild'' than open information seeking. In contrast, we aim to quantify the extent of LLM hallucination across languages in knowledge-intensive long-form question answering. To this end, we train a multilingual hallucination detection model and conduct a large-scale study across 30 languages and 6 open-source LLM families. We start from an English hallucination detection dataset and rely on MT to generate (noisy) training data in other languages. We also manually annotate gold data for five high-resource languages; we then demonstrate, for these languages, that the estimates of hallucination rates are similar between silver (LLM-generated) and gold test sets, validating the use of silver data for estimating hallucination rates for other languages. For the final rates estimation, we build a knowledge-intensive QA dataset for 30 languages with LLM-generated prompts and Wikipedia articles as references. We find that, while LLMs generate longer responses with more hallucinated tokens for higher-resource languages, there is no correlation between length-normalized hallucination rates of languages and their digital representation. Further, we find that smaller LLMs exhibit larger hallucination rates than larger models.", 'abstract_zh': '在信息误导时代，幻觉——大型语言模型（LLMs）生成非事实或不忠实响应的趋势——代表了其全球实用性的主要风险。尽管LLMs变得日益多语言化，但用于检测和量化LLM幻觉的研究主要（a）以英语为中心，并且（b）侧重于机器翻译（MT）和总结任务，这些任务在现实世界中不如开放信息查询普遍。相比之下，我们旨在跨多种语言的知识密集型长格式问答中量化LLM幻觉的程度。为此，我们训练了一个多语言幻觉检测模型，并在30种语言和6大家族开源LLM上开展了大规模研究。我们从一个英语幻觉检测数据集出发，依靠机器翻译生成其他语言的（嘈杂的）训练数据。我们还为五种高资源语言手动标注了黄金数据；然后，我们展示了这些语言中，幻觉率估计值在银色（LLM生成的）测试集和黄金测试集之间相似，验证了使用银数据来估计其他语言的幻觉率的可行性。最终，我们构建了一个包含30种语言的知识密集型问答数据集，LLM生成的提示和维基百科文章作为参考。我们发现，虽然高资源语言的LLM生成更长的响应并包含更多的幻觉令牌，但语言的数字化表示与其标准化后的幻觉率之间没有关联。此外，我们发现较小的LLM表现出更大的幻觉率，而较大的模型则不然。', 'title_zh': '多语言在野场景下大语言模型的幻觉程度估计'}
{'arxiv_id': 'arXiv:2502.12767', 'title': 'R2-KG: General-Purpose Dual-Agent Framework for Reliable Reasoning on Knowledge Graphs', 'authors': 'Sumin Jo, Junseong Choi, Jiho Kim, Edward Choi', 'link': 'https://arxiv.org/abs/2502.12767', 'abstract': 'Recent studies have combined Large Language Models (LLMs) with Knowledge Graphs (KGs) to enhance reasoning, improving inference accuracy without additional training while mitigating hallucination. However, existing frameworks are often rigid, struggling to adapt to KG or task changes. They also rely heavily on powerful LLMs for reliable (i.e., trustworthy) reasoning. To address this, We introduce R2-KG, a plug-and-play, dual-agent framework that separates reasoning into two roles: an Operator (a low-capacity LLM) that gathers evidence and a Supervisor (a high-capacity LLM) that makes final judgments. This design is cost-efficient for LLM inference while still maintaining strong reasoning accuracy. Additionally, R2-KG employs an Abstention mechanism, generating answers only when sufficient evidence is collected from KG, which significantly enhances reliability. Experiments across multiple KG-based reasoning tasks show that R2-KG consistently outperforms baselines in both accuracy and reliability, regardless of the inherent capability of LLMs used as the Operator. Further experiments reveal that the single-agent version of R2-KG, equipped with a strict self-consistency strategy, achieves significantly higher-than-baseline reliability while reducing inference cost. However, it also leads to a higher abstention rate in complex KGs. Our findings establish R2-KG as a flexible and cost-effective solution for KG-based reasoning. It reduces reliance on high-capacity LLMs while ensuring trustworthy inference.', 'abstract_zh': 'Recent Studies Combining Large Language Models with Knowledge Graphs to Enhance Reasoning and Improve Reliability', 'title_zh': '基于可靠知识图推理的通用双代理框架R2-KG'}
{'arxiv_id': 'arXiv:2502.12755', 'title': 'Efficient Machine Translation Corpus Generation: Integrating Human-in-the-Loop Post-Editing with Large Language Models', 'authors': 'Kamer Ali Yuksel, Ahmet Gunduz, Abdul Baseet Anees, Hassan Sawaf', 'link': 'https://arxiv.org/abs/2502.12755', 'abstract': "This paper introduces an advanced methodology for machine translation (MT) corpus generation, integrating semi-automated, human-in-the-loop post-editing with large language models (LLMs) to enhance efficiency and translation quality. Building upon previous work that utilized real-time training of a custom MT quality estimation metric, this system incorporates novel LLM features such as Enhanced Translation Synthesis and Assisted Annotation Analysis, which improve initial translation hypotheses and quality assessments, respectively. Additionally, the system employs LLM-Driven Pseudo Labeling and a Translation Recommendation System to reduce human annotator workload in specific contexts. These improvements not only retain the original benefits of cost reduction and enhanced post-edit quality but also open new avenues for leveraging cutting-edge LLM advancements. The project's source code is available for community use, promoting collaborative developments in the field. The demo video can be accessed here.", 'abstract_zh': '本文介绍了一种先进的机器翻译语料库生成方法，该方法结合了半自动化、人工在环的后编辑与大型语言模型（LLM），以提高效率和翻译质量。在此基础上，该系统整合了增强翻译合成和辅助注释分析等新型LLM功能，分别改进了初始翻译假设和质量评估。此外，该系统采用LLM驱动的伪标签和翻译推荐系统，以减少特定上下文中的人工标注员工作量。这些改进不仅保留了成本降低和增强后编辑质量的原始优势，还为利用最前沿的LLM进展开辟了新的途径。该项目的源代码可供社区使用，促进该领域的协作发展。演示视频可在此处访问。', 'title_zh': '高效的机器翻译语料生成：集成人工在环后编辑的大语言模型'}
{'arxiv_id': 'arXiv:2502.12745', 'title': 'MediaMind: Revolutionizing Media Monitoring using Agentification', 'authors': 'Ahmet Gunduz, Kamer Ali Yuksel, Hassan Sawaf', 'link': 'https://arxiv.org/abs/2502.12745', 'abstract': 'In an era of rapid technological advancements, agentification of software tools has emerged as a critical innovation, enabling systems to function autonomously and adaptively. This paper introduces MediaMind as a case study to demonstrate the agentification process, highlighting how existing software can be transformed into intelligent agents capable of independent decision-making and dynamic interaction. Developed by aiXplain, MediaMind leverages agent-based architecture to autonomously monitor, analyze, and provide insights from multilingual media content in real time. The focus of this paper is on the technical methodologies and design principles behind agentifying MediaMind, showcasing how agentification enhances adaptability, efficiency, and responsiveness. Through detailed case studies and practical examples, we illustrate how the agentification of MediaMind empowers organizations to streamline workflows, optimize decision-making, and respond to evolving trends. This work underscores the broader potential of agentification to revolutionize software tools across various domains.', 'abstract_zh': '在技术飞速发展的时代，软件工具的智能化已成为一项关键创新，使系统能够自主适应和动态交互。本文以MediaMind为例，展示智能化的过程，突出如何通过改造现有软件使其成为能够独立做出决策并进行动态交互的智能代理。由aiXplain开发的MediaMind利用基于代理的架构，能够实时监控、分析并提供多语言媒体内容的洞察。本文的重点在于MediaMind智能化的技术方法和设计原则，展示智能化如何增强系统的适应性、效率和响应性。通过详细的案例研究和实际示例，本文阐述了MediaMind的智能化如何使组织优化工作流程、增强决策效率并回应不断变化的趋势。本文强调了软件工具在各个领域通过智能化革命性的潜力。', 'title_zh': 'MediaMind: 通过代理化革命性地推动媒体监控'}
{'arxiv_id': 'arXiv:2502.12743', 'title': '"I know myself better, but not really greatly": Using LLMs to Detect and Explain LLM-Generated Texts', 'authors': 'Jiazhou Ji, Jie Guo, Weidong Qiu, Zheng Huang, Yang Xu, Xinru Lu, Xiaoyu Jiang, Ruizhe Li, Shujun Li', 'link': 'https://arxiv.org/abs/2502.12743', 'abstract': 'Large language models (LLMs) have demonstrated impressive capabilities in generating human-like texts, but the potential misuse of such LLM-generated texts raises the need to distinguish between human-generated and LLM-generated content. This paper explores the detection and explanation capabilities of LLM-based detectors of LLM-generated texts, in the context of a binary classification task (human-generated texts vs LLM-generated texts) and a ternary classification task (human-generated texts, LLM-generated texts, and undecided). By evaluating on six close/open-source LLMs with different sizes, our findings reveal that while self-detection consistently outperforms cross-detection, i.e., LLMs can detect texts generated by themselves more accurately than those generated by other LLMs, the performance of self-detection is still far from ideal, indicating that further improvements are needed. We also show that extending the binary to the ternary classification task with a new class "Undecided" can enhance both detection accuracy and explanation quality, with improvements being statistically significant and consistent across all LLMs. We finally conducted comprehensive qualitative and quantitative analyses on the explanation errors, which are categorized into three types: reliance on inaccurate features (the most frequent error), hallucinations, and incorrect reasoning. These findings with our human-annotated dataset emphasize the need for further research into improving both self-detection and self-explanation, particularly to address overfitting issues that may hinder generalization.', 'abstract_zh': '基于LLM的LLM生成文本检测与解释能力探索：从二分类任务到三分类任务的研究', 'title_zh': '“我了解自己，但却并不真正深入”：使用大语言模型检测和解释由大语言模型生成的文本'}
{'arxiv_id': 'arXiv:2502.12737', 'title': 'Beyond Seen Data: Improving KBQA Generalization Through Schema-Guided Logical Form Generation', 'authors': 'Shengxiang Gao, Jey Han Lau, Jianzhong Qi', 'link': 'https://arxiv.org/abs/2502.12737', 'abstract': 'Knowledge base question answering (KBQA) aims to answer user questions in natural language using rich human knowledge stored in large KBs. As current KBQA methods struggle with unseen knowledge base elements at test time,we introduce SG-KBQA: a novel model that injects schema contexts into entity retrieval and logical form generation to tackle this issue. It uses the richer semantics and awareness of the knowledge base structure provided by schema contexts to enhance generalizability. We show that SG-KBQA achieves strong generalizability, outperforming state-of-the-art models on two commonly used benchmark datasets across a variety of test settings. Code will be released upon paper publication.', 'abstract_zh': '基于知识库的问答（KBQA）旨在利用大型知识库中存储的丰富人类知识以自然语言回答用户问题。由于当前的KBQA方法在测试时难以处理未见过的知识库元素，我们提出了SG-KBQA：一种将模式上下文注入实体检索和逻辑形式生成的新模型，以应对这一问题。通过利用模式上下文提供的更丰富的语义和知识库结构意识，提高其泛化能力。实验表明，SG-KBQA 在泛化能力方面表现出色，在两个常用基准数据集的多种测试设置下均优于现有最佳模型。论文发表后将释放代码。', 'title_zh': '超越已见数据：通过基于方案的逻辑形式生成提高KBQA泛化能力'}
{'arxiv_id': 'arXiv:2502.12710', 'title': 'TREND: A Whitespace Replacement Information Hiding Method', 'authors': 'Malte Hellmeier, Hendrik Norkowski, Ernst-Christoph Schrewe, Haydar Qarawlus, Falk Howar', 'link': 'https://arxiv.org/abs/2502.12710', 'abstract': 'Large Language Models (LLMs) have gained significant popularity in recent years. Differentiating between a text written by a human and a text generated by an LLM has become almost impossible. Information hiding techniques such as digital watermarking or steganography can help by embedding information inside text without being noticed. However, existing techniques, such as linguistic-based or format-based methods, change the semantics or do not work on pure, unformatted text. In this paper, we introduce a novel method for information hiding termed TREND, which is able to conceal any byte-encoded sequence within a cover text. The proposed method is implemented as a multi-platform library using the Kotlin programming language, accompanied by a command-line tool and a web interface provided as examples of usage. By substituting conventional whitespace characters with visually similar Unicode whitespace characters, our proposed scheme preserves the semantics of the cover text without increasing the number of characters. Furthermore, we propose a specified structure for secret messages that enables configurable compression, encryption, hashing, and error correction. Our experimental benchmark comparison on a dataset of one million Wikipedia articles compares ten algorithms from literature and practice. It proves the robustness of our proposed method in various applications while remaining imperceptible to humans. We discuss the limitations of limited embedding capacity and further robustness, which guide implications for future work.', 'abstract_zh': '大型语言模型中的信息隐藏方法：TREND', 'title_zh': '趋势：一种空白字符替换信息隐藏方法'}
{'arxiv_id': 'arXiv:2502.12701', 'title': 'Translate Smart, not Hard: Cascaded Translation Systems with Quality-Aware Deferral', 'authors': 'António Farinhas, Nuno M. Guerreiro, Sweta Agrawal, Ricardo Rei, André F.T. Martins', 'link': 'https://arxiv.org/abs/2502.12701', 'abstract': 'Larger models often outperform smaller ones but come with high computational costs. Cascading offers a potential solution. By default, it uses smaller models and defers only some instances to larger, more powerful models. However, designing effective deferral rules remains a challenge. In this paper, we propose a simple yet effective approach for machine translation, using existing quality estimation (QE) metrics as deferral rules. We show that QE-based deferral allows a cascaded system to match the performance of a larger model while invoking it for a small fraction (30% to 50%) of the examples, significantly reducing computational costs. We validate this approach through both automatic and human evaluation.', 'abstract_zh': '较大的模型通常 performance 更好但伴随较高的计算成本。级联提供了一种潜在的解决方案。默认情况下，它使用较小的模型并将部分实例委托给更强大、更大的模型。然而，设计有效的延缓规则仍然颇具挑战性。在本文中，我们提出了一种简单而有效的方法用于机器翻译，利用现有的质量估计 (QE) 指标作为延缓规则。我们展示了基于 QE 的延缓使得级联系统能够在少量实例（30% 到 50%）上调用更大模型的情况下达到与其相当的性能，大幅度降低了计算成本。我们通过自动和人工评估验证了该方法。', 'title_zh': '聪明不努力：基于质量感知推迟的级联翻译系统'}
{'arxiv_id': 'arXiv:2502.12690', 'title': 'Fast Data Aware Neural Architecture Search via Supernet Accelerated Evaluation', 'authors': 'Emil Njor, Colby Banbury, Xenofon Fafoutis', 'link': 'https://arxiv.org/abs/2502.12690', 'abstract': 'Tiny machine learning (TinyML) promises to revolutionize fields such as healthcare, environmental monitoring, and industrial maintenance by running machine learning models on low-power embedded systems. However, the complex optimizations required for successful TinyML deployment continue to impede its widespread adoption. A promising route to simplifying TinyML is through automatic machine learning (AutoML), which can distill elaborate optimization workflows into accessible key decisions. Notably, Hardware Aware Neural Architecture Searches - where a computer searches for an optimal TinyML model based on predictive performance and hardware metrics - have gained significant traction, producing some of today\'s most widely used TinyML models. Nevertheless, limiting optimization solely to neural network architectures can prove insufficient. Because TinyML systems must operate under extremely tight resource constraints, the choice of input data configuration, such as resolution or sampling rate, also profoundly impacts overall system efficiency. Achieving truly optimal TinyML systems thus requires jointly tuning both input data and model architecture. Despite its importance, this "Data Aware Neural Architecture Search" remains underexplored. To address this gap, we propose a new state-of-the-art Data Aware Neural Architecture Search technique and demonstrate its effectiveness on the novel TinyML ``Wake Vision\'\' dataset. Our experiments show that across varying time and hardware constraints, Data Aware Neural Architecture Search consistently discovers superior TinyML systems compared to purely architecture-focused methods, underscoring the critical role of data-aware optimization in advancing TinyML.', 'abstract_zh': '基于数据感知的神经架构搜索在TinyML中的应用', 'title_zh': '基于超网络加速评估的快速数据感知神经架构搜索'}
{'arxiv_id': 'arXiv:2502.12678', 'title': 'Multi-Step Alignment as Markov Games: An Optimistic Online Gradient Descent Approach with Convergence Guarantees', 'authors': 'Yongtao Wu, Luca Viano, Yihang Chen, Zhenyu Zhu, Kimon Antonakopoulos, Quanquan Gu, Volkan Cevher', 'link': 'https://arxiv.org/abs/2502.12678', 'abstract': 'Reinforcement Learning from Human Feedback (RLHF) has been highly successful in aligning large language models with human preferences. While prevalent methods like DPO have demonstrated strong performance, they frame interactions with the language model as a bandit problem, which limits their applicability in real-world scenarios where multi-turn conversations are common. Additionally, DPO relies on the Bradley-Terry model assumption, which does not adequately capture the non-transitive nature of human preferences. In this paper, we address these challenges by modeling the alignment problem as a two-player constant-sum Markov game, where each player seeks to maximize their winning rate against the other across all steps of the conversation. Our approach Multi-step Preference Optimization (MPO) is built upon the natural actor-critic framework~\\citep{peters2008natural}. We further develop OMPO based on the optimistic online gradient descent algorithm~\\citep{rakhlin2013online,joulani17a}. Theoretically, we provide a rigorous analysis for both algorithms on convergence and show that OMPO requires $\\mathcal{O}(\\epsilon^{-1})$ policy updates to converge to an $\\epsilon$-approximate Nash equilibrium. We also validate the effectiveness of our method on multi-turn conversations dataset and math reasoning dataset.', 'abstract_zh': '基于人类反馈的强化学习（Reinforcement Learning from Human Feedback, RLHF）在使大型语言模型与人类偏好一致方面取得了巨大成功。尽管像DPO这样的广泛方法展示了强大的性能，但它们将与语言模型的交互视为一个拉普拉斯问题，这限制了它们在常见多轮对话的现实场景中的适用性。此外，DPO依赖于Bradley-Terry模型假设，该假设不能充分捕捉人类偏好中的非传递性。在这篇论文中，我们通过将对齐问题建模为两名玩家的常和马尔可夫游戏来解决这些挑战，在该游戏中，每个玩家试图在整个对话步骤中最大限度地提高自己相对于另一方的胜率。我们的方法多步偏好优化（Multi-step Preference Optimization, MPO）基于自然演员-评论家框架~\\citep{peters2008natural}。我们在此基础上进一步开发了OMPO，基于乐观在线梯度下降算法~\\citep{rakhlin2013online,joulani17a}。理论上，我们对这两种算法的收敛性进行了严格的分析，并证明了OMPO需要$\\mathcal{O}(\\epsilon^{-1})$次策略更新以收敛到$\\epsilon$-近似纳什均衡。我们还在多轮对话数据集和数学推理数据集上验证了我们方法的有效性。', 'title_zh': '多步对齐作为马尔可夫博弈：具有收敛保证的乐观在线梯度下降方法'}
{'arxiv_id': 'arXiv:2502.12677', 'title': 'Spiking Vision Transformer with Saccadic Attention', 'authors': 'Shuai Wang, Malu Zhang, Dehao Zhang, Ammar Belatreche, Yichen Xiao, Yu Liang, Yimeng Shan, Qian Sun, Enqi Zhang, Yang Yang', 'link': 'https://arxiv.org/abs/2502.12677', 'abstract': 'The combination of Spiking Neural Networks (SNNs) and Vision Transformers (ViTs) holds potential for achieving both energy efficiency and high performance, particularly suitable for edge vision applications. However, a significant performance gap still exists between SNN-based ViTs and their ANN counterparts. Here, we first analyze why SNN-based ViTs suffer from limited performance and identify a mismatch between the vanilla self-attention mechanism and spatio-temporal spike trains. This mismatch results in degraded spatial relevance and limited temporal interactions. To address these issues, we draw inspiration from biological saccadic attention mechanisms and introduce an innovative Saccadic Spike Self-Attention (SSSA) method. Specifically, in the spatial domain, SSSA employs a novel spike distribution-based method to effectively assess the relevance between Query and Key pairs in SNN-based ViTs. Temporally, SSSA employs a saccadic interaction module that dynamically focuses on selected visual areas at each timestep and significantly enhances whole scene understanding through temporal interactions. Building on the SSSA mechanism, we develop a SNN-based Vision Transformer (SNN-ViT). Extensive experiments across various visual tasks demonstrate that SNN-ViT achieves state-of-the-art performance with linear computational complexity. The effectiveness and efficiency of the SNN-ViT highlight its potential for power-critical edge vision applications.', 'abstract_zh': '基于...]的尖峰神经网络（SNNs）与视觉变换器（ViTs）的结合在实现高效能和高性能方面具有潜力，特别适用于边缘视觉应用。然而，基于SNN的ViTs与其ANN对应物之间仍存在显著的性能差距。为此，我们首先分析了基于SNN的ViTs性能受限的原因，并发现vanilla自注意力机制与时空尖峰脉冲序列之间存在不匹配。这种不匹配导致了空间相关性的降低和时间交互能力的有限。为了解决这些问题，我们从生物瞬目注意机制中汲取灵感，并引入了一种创新的瞬目尖峰自注意力（SSSA）方法。具体而言，在空间领域，SSSA采用了一种新颖的尖峰脉冲分布方法，有效评估了基于SNN的ViTs中的查询和键对的相关性。在时间维度上，SSSA引入了一种瞬目交互模块，在每个时隙动态关注选定的视觉区域，并通过时间交互显著增强对整个场景的理解。基于SSSA机制，我们开发了一种基于SNN的视觉变换器（SNN-ViT）。在各种视觉任务的广泛实验中，SNN-ViT展示了线性计算复杂度下的最佳性能。SNN-ViT的效果和效率突显了其在功率关键边缘视觉应用中的潜力。', 'title_zh': '斯巴达克注意机制下的尖峰视觉变换器'}
{'arxiv_id': 'arXiv:2502.12672', 'title': 'Speech-FT: A Fine-tuning Strategy for Enhancing Speech Representation Models Without Compromising Generalization Ability', 'authors': 'Tzu-Quan Lin, Wei-Ping Huang, Hao Tang, Hung-yi Lee', 'link': 'https://arxiv.org/abs/2502.12672', 'abstract': 'Speech representation models are highly effective at extracting general features for various tasks. While fine-tuning can enhance these representations for specific applications, it often compromises their generalization ability. To address this challenge, we propose Speech-FT, a fine-tuning strategy for speech representation models that leverages model merging to preserve generalization ability while still benefiting from fine-tuning. Speech-FT is effective across different fine-tuning scenarios and is compatible with various types of speech representation models, providing a versatile solution. Speech-FT offers an efficient and practical approach to further improving general speech representations after pre-training.', 'abstract_zh': '基于模型融合的Speech-FT：一种保持泛化能力的同时增强特定应用的语音表示微调策略', 'title_zh': 'Speech-FT: 一种在不牺牲泛化能力的情况下增强语音表示模型的微调策略'}
{'arxiv_id': 'arXiv:2502.12659', 'title': 'The Hidden Risks of Large Reasoning Models: A Safety Assessment of R1', 'authors': 'Kaiwen Zhou, Chengzhi Liu, Xuandong Zhao, Shreedhar Jangam, Jayanth Srinivasa, Gaowen Liu, Dawn Song, Xin Eric Wang', 'link': 'https://arxiv.org/abs/2502.12659', 'abstract': "The rapid development of large reasoning models, such as OpenAI-o3 and DeepSeek-R1, has led to significant improvements in complex reasoning over non-reasoning large language models~(LLMs). However, their enhanced capabilities, combined with the open-source access of models like DeepSeek-R1, raise serious safety concerns, particularly regarding their potential for misuse. In this work, we present a comprehensive safety assessment of these reasoning models, leveraging established safety benchmarks to evaluate their compliance with safety regulations. Furthermore, we investigate their susceptibility to adversarial attacks, such as jailbreaking and prompt injection, to assess their robustness in real-world applications. Through our multi-faceted analysis, we uncover four key findings: (1) There is a significant safety gap between the open-source R1 models and the o3-mini model, on both safety benchmark and attack, suggesting more safety effort on R1 is needed. (2) The distilled reasoning model shows poorer safety performance compared to its safety-aligned base models. (3) The stronger the model's reasoning ability, the greater the potential harm it may cause when answering unsafe questions. (4) The thinking process in R1 models pose greater safety concerns than their final answers. Our study provides insights into the security implications of reasoning models and highlights the need for further advancements in R1 models' safety to close the gap.", 'abstract_zh': '大型推理模型（如OpenAI-o3和DeepSeek-R1）的迅速发展导致了复杂推理能力在非推理大型语言模型（LLMs）中的显著提升。然而，这些模型增强的能力，尤其是开源模型DeepSeek-R1的开放访问，引发了严重的安全顾虑，特别是在潜在误用方面。在本研究中，我们通过利用现有的安全基准对其安全性进行综合评估，并考察它们对对抗性攻击（如 Jailbreaking 和提示注入）的脆弱性，以评估其在实际应用中的鲁棒性。通过多方面的分析，我们发现了四个关键发现：（1）开源R1模型与o3-mini模型在安全基准和攻击测试中都存在显著的安全差距，表明需要在R1模型上投入更多安全努力。（2）提炼推理模型的安全性能逊于与其安全对齐的基础模型。（3）模型的推理能力越强，其在回答不安全问题时造成潜在危害的可能性越大。（4）R1模型的思考过程比其最终答案更值得关注安全问题。我们的研究提供了关于推理模型安全影响的见解，并突显了进一步提升R1模型安全性的必要性，以缩小差距。', 'title_zh': '大型推理模型潜藏的风险：R1的安全性评估'}
{'arxiv_id': 'arXiv:2502.12633', 'title': "\\textit{One Size doesn't Fit All}: A Personalized Conversational Tutoring Agent for Mathematics Instruction", 'authors': 'Ben Liu, Jihan Zhang, Fangquan Lin, Xu Jia, Min Peng', 'link': 'https://arxiv.org/abs/2502.12633', 'abstract': "Large language models (LLMs) have been increasingly employed in various intelligent educational systems, simulating human tutors to facilitate effective human-machine interaction. However, previous studies often overlook the significance of recognizing and adapting to individual learner characteristics. Such adaptation is crucial for enhancing student engagement and learning efficiency, particularly in mathematics instruction, where diverse learning styles require personalized strategies to promote comprehension and enthusiasm. In this paper, we propose a \\textbf{P}erson\\textbf{A}lized \\textbf{C}onversational tutoring ag\\textbf{E}nt (PACE) for mathematics instruction. PACE simulates students' learning styles based on the Felder and Silverman learning style model, aligning with each student's persona. In this way, our PACE can effectively assess the personality of students, allowing to develop individualized teaching strategies that resonate with their unique learning styles. To further enhance students' comprehension, PACE employs the Socratic teaching method to provide instant feedback and encourage deep thinking. By constructing personalized teaching data and training models, PACE demonstrates the ability to identify and adapt to the unique needs of each student, significantly improving the overall learning experience and outcomes. Moreover, we establish multi-aspect evaluation criteria and conduct extensive analysis to assess the performance of personalized teaching. Experimental results demonstrate the superiority of our model in personalizing the educational experience and motivating students compared to existing methods.", 'abstract_zh': '个性化交互式辅导代理（PACE）在数学教学中的应用', 'title_zh': '大小不一：一个个性化对话式辅导代理用于数学教学'}
{'arxiv_id': 'arXiv:2502.12631', 'title': 'Score-Based Diffusion Policy Compatible with Reinforcement Learning via Optimal Transport', 'authors': 'Mingyang Sun, Pengxiang Ding, Weinan Zhang, Donglin Wang', 'link': 'https://arxiv.org/abs/2502.12631', 'abstract': "Diffusion policies have shown promise in learning complex behaviors from demonstrations, particularly for tasks requiring precise control and long-term planning. However, they face challenges in robustness when encountering distribution shifts. This paper explores improving diffusion-based imitation learning models through online interactions with the environment. We propose OTPR (Optimal Transport-guided score-based diffusion Policy for Reinforcement learning fine-tuning), a novel method that integrates diffusion policies with RL using optimal transport theory. OTPR leverages the Q-function as a transport cost and views the policy as an optimal transport map, enabling efficient and stable fine-tuning. Moreover, we introduce masked optimal transport to guide state-action matching using expert keypoints and a compatibility-based resampling strategy to enhance training stability. Experiments on three simulation tasks demonstrate OTPR's superior performance and robustness compared to existing methods, especially in complex and sparse-reward environments. In sum, OTPR provides an effective framework for combining IL and RL, achieving versatile and reliable policy learning. The code will be released at this https URL.", 'abstract_zh': '基于最优传输的评分扩散政策在强化学习微调中的应用：改善分布偏移下的 imitation 学习', 'title_zh': '基于分数扩散政策：通过最优传输与强化学习相兼容'}
{'arxiv_id': 'arXiv:2502.12630', 'title': 'Automating Prompt Leakage Attacks on Large Language Models Using Agentic Approach', 'authors': 'Tvrtko Sternak, Davor Runje, Dorian Granoša, Chi Wang', 'link': 'https://arxiv.org/abs/2502.12630', 'abstract': "This paper presents a novel approach to evaluating the security of large language models (LLMs) against prompt leakage-the exposure of system-level prompts or proprietary configurations. We define prompt leakage as a critical threat to secure LLM deployment and introduce a framework for testing the robustness of LLMs using agentic teams. Leveraging AG2 (formerly AutoGen), we implement a multi-agent system where cooperative agents are tasked with probing and exploiting the target LLM to elicit its prompt.\nGuided by traditional definitions of security in cryptography, we further define a prompt leakage-safe system as one in which an attacker cannot distinguish between two agents: one initialized with an original prompt and the other with a prompt stripped of all sensitive information. In a safe system, the agents' outputs will be indistinguishable to the attacker, ensuring that sensitive information remains secure. This cryptographically inspired framework provides a rigorous standard for evaluating and designing secure LLMs.\nThis work establishes a systematic methodology for adversarial testing of prompt leakage, bridging the gap between automated threat modeling and practical LLM security.\nYou can find the implementation of our prompt leakage probing on GitHub.", 'abstract_zh': '本文提出了一种评估大型语言模型（LLMs）对提示泄漏抵御能力的新方法——系统级提示或专有配置的暴露。我们定义提示泄漏是对安全LLM部署的关键威胁，并引入了一种使用代理团队测试LLM鲁棒性的框架。利用AG2（原AutoGen），我们实现了多代理系统，其中协作代理被指派探测和利用目标LLM以引发其提示。\n\n基于密码学中传统的安全定义，我们进一步定义了一个提示泄漏安全系统为一个攻击者无法区分两者的系统：一个是初始化为原始提示的代理，另一个是删除所有敏感信息的提示的代理。在安全系统中，代理的输出对攻击者来说是不可区分的，从而确保敏感信息的安全。这种密码学启发式的框架为评估和设计安全LLM提供了一个严格的标准。\n\n本文建立了一种系统性的方法来对抗提示泄漏的测试，填补了自动化威胁建模与实际LLM安全之间的差距。\n\n您可以在GitHub上找到我们提示泄漏探测的实现。', 'title_zh': '使用代理方法自动化的提示泄漏攻击研究：针对大规模语言模型'}
{'arxiv_id': 'arXiv:2502.12623', 'title': 'DeepResonance: Enhancing Multimodal Music Understanding via Music-centric Multi-way Instruction Tuning', 'authors': 'Zhuoyuan Mao, Mengjie Zhao, Qiyu Wu, Hiromi Wakaki, Yuki Mitsufuji', 'link': 'https://arxiv.org/abs/2502.12623', 'abstract': "Recent advancements in music large language models (LLMs) have significantly improved music understanding tasks, which involve the model's ability to analyze and interpret various musical elements. These improvements primarily focused on integrating both music and text inputs. However, the potential of incorporating additional modalities such as images, videos and textual music features to enhance music understanding remains unexplored. To bridge this gap, we propose DeepResonance, a multimodal music understanding LLM fine-tuned via multi-way instruction tuning with multi-way aligned music, text, image, and video data. To this end, we construct Music4way-MI2T, Music4way-MV2T, and Music4way-Any2T, three 4-way training and evaluation datasets designed to enable DeepResonance to integrate both visual and textual music feature content. We also introduce multi-sampled ImageBind embeddings and a pre-alignment Transformer to enhance modality fusion prior to input into text LLMs, tailoring DeepResonance for multi-way instruction tuning. Our model achieves state-of-the-art performances across six music understanding tasks, highlighting the benefits of the auxiliary modalities and the structural superiority of DeepResonance. We plan to open-source the models and the newly constructed datasets.", 'abstract_zh': 'Recent advancements in音乐大型语言模型（LLMs）显著提高了音乐理解任务的能力，这些任务涉及模型分析和解释各种音乐元素的能力。这些进步主要集中在整合音乐和文本输入上。然而，将额外的模态，如图像、视频和文本音乐特征纳入以增强音乐理解的可能性仍未被探索。为了解决这一缺口，我们提出了DeepResonance，这是一种通过多维指令调谐和多模态对齐的音乐、文本、图像和视频数据微调的多模态音乐理解LLM。为此，我们构建了Music4way-MI2T、Music4way-MV2T和Music4way-Any2T三个4维训练和评估数据集，旨在使DeepResonance能够整合视觉和文本音乐特征内容。我们还引入了多采样的ImageBind嵌入和预对齐 Transformer，以增强输入到文本LLM之前的模态融合，使DeepResonance适配多维指令调谐。我们的模型在六项音乐理解任务中实现了最先进的性能，突显了辅助模态和DeepResonance结构上的优势。我们计划开源这些模型和新构建的数据集。', 'title_zh': 'DeepResonance：通过以音乐为中心的多路指令调优增强多模态音乐理解'}
{'arxiv_id': 'arXiv:2502.12617', 'title': 'A Graph-Enhanced Deep-Reinforcement Learning Framework for the Aircraft Landing Problem', 'authors': 'Vatsal Maru', 'link': 'https://arxiv.org/abs/2502.12617', 'abstract': 'The Aircraft Landing Problem (ALP) is one of the challenging problems in aircraft transportation and management. The challenge is to schedule the arriving aircraft in a sequence so that the cost and delays are optimized. There are various solution approaches to solving this problem, most of which are based on operations research algorithms and meta-heuristics. Although traditional methods perform better on one or the other factors, there remains a problem of solving real-time rescheduling and computational scalability altogether. This paper presents a novel deep reinforcement learning (DRL) framework that combines graph neural networks with actor-critic architectures to address the ALP. This paper introduces three key contributions: A graph-based state representation that efficiently captures temporal and spatial relationships between aircraft, a specialized actor-critic architecture designed to handle multiple competing objectives in landing scheduling, and a runway balance strategy that ensures efficient resource utilization while maintaining safety constraints. The results show that the trained algorithm can be tested on different problem sets and the results are competitive to operation research algorithms. The experimental results on standard benchmark data sets demonstrate a 99.95 reduction in computational time compared to Mixed Integer Programming (MIP) and 38 higher runway throughput over First Come First Serve (FCFS) approaches. Therefore, the proposed solution is competitive to traditional approaches and achieves substantial advancements. Notably, it does not require retraining, making it particularly suitable for industrial deployment. The frameworks capability to generate solutions within 1 second enables real-time rescheduling, addressing critical requirements of air traffic management.', 'abstract_zh': '基于图神经网络的深强化学习在航空着陆问题中的应用', 'title_zh': '一种增强图表示的深度强化学习框架用于航空器降落问题'}
{'arxiv_id': 'arXiv:2502.12614', 'title': 'Label Drop for Multi-Aspect Relation Modeling in Universal Information Extraction', 'authors': 'Lu Yang, Jiajia Li, En Ci, Lefei Zhang, Zuchao Li, Ping Wang', 'link': 'https://arxiv.org/abs/2502.12614', 'abstract': 'Universal Information Extraction (UIE) has garnered significant attention due to its ability to address model explosion problems effectively. Extractive UIE can achieve strong performance using a relatively small model, making it widely adopted. Extractive UIEs generally rely on task instructions for different tasks, including single-target instructions and multiple-target instructions. Single-target instruction UIE enables the extraction of only one type of relation at a time, limiting its ability to model correlations between relations and thus restricting its capability to extract complex relations. While multiple-target instruction UIE allows for the extraction of multiple relations simultaneously, the inclusion of irrelevant relations introduces decision complexity and impacts extraction accuracy. Therefore, for multi-relation extraction, we propose LDNet, which incorporates multi-aspect relation modeling and a label drop mechanism. By assigning different relations to different levels for understanding and decision-making, we reduce decision confusion. Additionally, the label drop mechanism effectively mitigates the impact of irrelevant relations. Experiments show that LDNet outperforms or achieves competitive performance with state-of-the-art systems on 9 tasks, 33 datasets, in both single-modal and multi-modal, few-shot and zero-shot settings.\\footnote{this https URL}', 'abstract_zh': '通用信息提取（UIE）因其有效解决模型爆炸问题的能力而引起了广泛关注。提取式UIE可以使用相对较小的模型实现较强的性能，因此被广泛采用。提取式UIEs通常依赖于不同的任务指令，包括单目标指令和多目标指令。单目标指令的UIE一次只能提取一种关系，限制了其建模关系之间关联的能力，从而限制了其提取复杂关系的能力。而多目标指令的UIE可以同时提取多种关系，但由于包含无关关系，增加了决策复杂度并影响提取精度。因此，为了进行多关系提取，我们提出了一种LDNet方法，该方法结合了多方面关系建模和标签丢弃机制。通过将不同关系分配到不同的层级进行理解和决策，我们减少了决策混淆。此外，标签丢弃机制有效地减轻了无关关系的影响。实验结果显示，LDNet在9个任务、33个数据集中，在单模态和多模态、少样本和零样本设置中均优于或达到了最先进的系统水平。', 'title_zh': '面向通用信息提取的多方面关系建模中的标签掉落方法'}
{'arxiv_id': 'arXiv:2502.12608', 'title': 'Unveiling Mode Connectivity in Graph Neural Networks', 'authors': 'Bingheng Li, Zhikai Chen, Haoyu Han, Shenglai Zeng, Jingzhe Liu, Jiliang Tang', 'link': 'https://arxiv.org/abs/2502.12608', 'abstract': 'A fundamental challenge in understanding graph neural networks (GNNs) lies in characterizing their optimization dynamics and loss landscape geometry, critical for improving interpretability and robustness. While mode connectivity, a lens for analyzing geometric properties of loss landscapes has proven insightful for other deep learning architectures, its implications for GNNs remain unexplored. This work presents the first investigation of mode connectivity in GNNs. We uncover that GNNs exhibit distinct non-linear mode connectivity, diverging from patterns observed in fully-connected networks or CNNs. Crucially, we demonstrate that graph structure, rather than model architecture, dominates this behavior, with graph properties like homophily correlating with mode connectivity patterns. We further establish a link between mode connectivity and generalization, proposing a generalization bound based on loss barriers and revealing its utility as a diagnostic tool. Our findings further bridge theoretical insights with practical implications: they rationalize domain alignment strategies in graph learning and provide a foundation for refining GNN training paradigms.', 'abstract_zh': '理解图神经网络优化动力学和损失landscape几何结构的基本挑战在于提高其可解释性和鲁棒性。虽然模式连通性作为一种分析损失landscape几何性质的视角在其他深度学习架构中展现了洞见，但其对图神经网络的影响尚未被探索。本工作首次调查了图神经网络中的模式连通性。我们发现图神经网络表现出与完全连接网络或CNNs中观察到的模式不同的非线性模式连通性。关键的是，我们证明了图结构而非模型架构主导了这种行为，图属性如同质性与模式连通性模式相关。我们还建立了模式连通性与泛化的联系，提出基于损失屏障的泛化界，并揭示其作为诊断工具的实用性。我们的发现进一步将理论洞察与实际应用联系起来：它们为图学习中的领域对齐策略提供了理据，并为改进图神经网络训练范式奠定了基础。', 'title_zh': '揭示图神经网络中的模式连通性'}
{'arxiv_id': 'arXiv:2502.12603', 'title': 'Disentangling Long-Short Term State Under Unknown Interventions for Online Time Series Forecasting', 'authors': 'Ruichu Cai, Haiqin Huang, Zhifang Jiang, Zijian Li, Changze Zhou, Yuequn Liu, Yuming Liu, Zhifeng Hao', 'link': 'https://arxiv.org/abs/2502.12603', 'abstract': 'Current methods for time series forecasting struggle in the online scenario, since it is difficult to preserve long-term dependency while adapting short-term changes when data are arriving sequentially. Although some recent methods solve this problem by controlling the updates of latent states, they cannot disentangle the long/short-term states, leading to the inability to effectively adapt to nonstationary. To tackle this challenge, we propose a general framework to disentangle long/short-term states for online time series forecasting. Our idea is inspired by the observations where short-term changes can be led by unknown interventions like abrupt policies in the stock market. Based on this insight, we formalize a data generation process with unknown interventions on short-term states. Under mild assumptions, we further leverage the independence of short-term states led by unknown interventions to establish the identification theory to achieve the disentanglement of long/short-term states. Built on this theory, we develop a long short-term disentanglement model (LSTD) to extract the long/short-term states with long/short-term encoders, respectively. Furthermore, the LSTD model incorporates a smooth constraint to preserve the long-term dependencies and an interrupted dependency constraint to enforce the forgetting of short-term dependencies, together boosting the disentanglement of long/short-term states. Experimental results on several benchmark datasets show that our \\textbf{LSTD} model outperforms existing methods for online time series forecasting, validating its efficacy in real-world applications.', 'abstract_zh': '一种在线时间序列预测的长短期状态解耦框架', 'title_zh': '在未知干预下的长短期状态解耦在线时间序列预测'}
{'arxiv_id': 'arXiv:2502.12587', 'title': 'RSMLP: A light Sampled MLP Structure for Incomplete Utterance Rewrite', 'authors': 'Lunjun Liu, Weilai Jiang, Yaonan Wang', 'link': 'https://arxiv.org/abs/2502.12587', 'abstract': 'The Incomplete Utterance Rewriting (IUR) task has garnered significant attention in recent years. Its goal is to reconstruct conversational utterances to better align with the current context, thereby enhancing comprehension. In this paper, we introduce a novel and versatile lightweight method, Rewritten-Sampled MLP (RSMLP). By employing an MLP based architecture with a carefully designed down-sampling strategy, RSMLP effectively extracts latent semantic information between utterances and makes appropriate edits to restore incomplete utterances. Due to its simple yet efficient structure, our method achieves competitive performance on public IUR datasets and in real-world applications.', 'abstract_zh': '不完整utterance重写（IUR）任务近年来引起了广泛关注。其目标是重构对话utterance以更好地与当前上下文对齐，从而提高理解能力。本文介绍了一种新颖且灵活的轻量级方法，即重写采样MLP（RSMLP）。通过采用基于MLP的架构并结合精心设计的下采样策略，RSMLP有效地提取了utterance之间的潜在语义信息，并进行适当的编辑以恢复不完整utterance。由于其简洁高效的结构，该方法在公开的IUR数据集和实际应用中实现了竞争性的性能。', 'title_zh': 'RSMLP：一种用于不完整陈述重写的小样本MLP结构'}
{'arxiv_id': 'arXiv:2502.12584', 'title': 'Enhancing Semi-supervised Learning with Noisy Zero-shot Pseudolabels', 'authors': 'Jichan Chung, Irene Y. Chen', 'link': 'https://arxiv.org/abs/2502.12584', 'abstract': 'Semi-supervised learning (SSL) leverages limited labeled data alongside abundant unlabeled data to address labeling costs in machine learning. While recent foundation models enable zero-shot inference, attempts to integrate these capabilities into SSL through pseudo-labeling have shown mixed results due to unreliable zero-shot predictions. We present ZMT (Zero-Shot Multi-Task Learning), a framework that jointly optimizes zero-shot pseudo-labels and unsupervised representation learning objectives from contemporary SSL approaches. Our method introduces a multi-task learning-based mechanism that incorporates pseudo-labels while ensuring robustness to varying pseudo-label quality. Experiments across 8 datasets in vision, language, and audio domains demonstrate that ZMT reduces error by up to 56% compared to traditional SSL methods, with particularly compelling results when pseudo-labels are noisy and unreliable. ZMT represents a significant step toward making semi-supervised learning more effective and accessible in resource-constrained environments.', 'abstract_zh': '半监督学习（SSL）利用有限的标注数据和丰富的未标注数据来解决机器学习中的标注成本问题。尽管最近的预训练模型能够实现零-shot推理，但试图通过伪标签将这些能力与SSL结合所产生的结果参差不齐，因为这些零-shot预测存在不可靠性。我们提出了ZMT（零-shot多任务学习），这是一种框架，可以同时优化零-shot伪标签和来自现代SSL方法的无监督表示学习目标。我们的方法引入了一种基于多任务学习的机制，该机制在确保伪标签质量变化时的鲁棒性的同时引入了伪标签。在视觉、语言和音频领域8个数据集上的实验表明，与传统SSL方法相比，ZMT可以将错误率降低多达56%，特别是在伪标签嘈杂和不可靠时表现尤为明显。ZMT代表了朝着使半监督学习在资源受限环境中更加有效和可行的重要一步。', 'title_zh': '增强半监督学习中的 noisy 零-shot 假标签'}
{'arxiv_id': 'arXiv:2502.12581', 'title': 'The Majority Vote Paradigm Shift: When Popular Meets Optimal', 'authors': 'Antonio Purificato, Maria Sofia Bucarelli, Anil Kumar Nelakanti, Andrea Bacciu, Fabrizio Silvestri, Amin Mantrach', 'link': 'https://arxiv.org/abs/2502.12581', 'abstract': "Reliably labelling data typically requires annotations from multiple human workers. However, humans are far from being perfect. Hence, it is a common practice to aggregate labels gathered from multiple annotators to make a more confident estimate of the true label. Among many aggregation methods, the simple and well known Majority Vote (MV) selects the class label polling the highest number of votes. However, despite its importance, the optimality of MV's label aggregation has not been extensively studied. We address this gap in our work by characterising the conditions under which MV achieves the theoretically optimal lower bound on label estimation error. Our results capture the tolerable limits on annotation noise under which MV can optimally recover labels for a given class distribution. This certificate of optimality provides a more principled approach to model selection for label aggregation as an alternative to otherwise inefficient practices that sometimes include higher experts, gold labels, etc., that are all marred by the same human uncertainty despite huge time and monetary costs. Experiments on both synthetic and real world data corroborate our theoretical findings.", 'abstract_zh': '可靠地标注数据通常需要多个人工工作者的注释。然而，人类远非完美。因此，汇总多名注释者获得的标签以更自信地估计真实标签是一种常见做法。在众多汇总方法中，简单的多数投票（MV）方法选择获得最高票数的类别标签。尽管其重要性不容忽视，但MV标签汇总的最优性尚未得到充分研究。我们在工作中通过分析MV在哪些条件下能达到标签估计误差的理论最优下界，填补了这一空白。我们的结果捕捉了在给定类别分布下MV能最优恢复标签的可容忍注释噪声的限度。这种最优性证书为标签汇总的模型选择提供了一种更原则的方法，替代以往有时包括更高专家、黄金标签等虽然成本高昂但同样存在人类不确定性的做法。我们在合成数据和真实数据上的实验结果验证了我们的理论发现。', 'title_zh': '多数投票范式的转变：流行与最优的交汇'}
{'arxiv_id': 'arXiv:2502.12576', 'title': 'A Fuzzy Evaluation of Sentence Encoders on Grooming Risk Classification', 'authors': 'Geetanjali Bihani, Julia Rayz', 'link': 'https://arxiv.org/abs/2502.12576', 'abstract': 'With the advent of social media, children are becoming increasingly vulnerable to the risk of grooming in online settings. Detecting grooming instances in an online conversation poses a significant challenge as the interactions are not necessarily sexually explicit, since the predators take time to build trust and a relationship with their victim. Moreover, predators evade detection using indirect and coded language. While previous studies have fine-tuned Transformers to automatically identify grooming in chat conversations, they overlook the impact of coded and indirect language on model predictions, and how these align with human perceptions of grooming. In this paper, we address this gap and evaluate bi-encoders on the task of classifying different degrees of grooming risk in chat contexts, for three different participant groups, i.e. law enforcement officers, real victims, and decoys. Using a fuzzy-theoretic framework, we map human assessments of grooming behaviors to estimate the actual degree of grooming risk. Our analysis reveals that fine-tuned models fail to tag instances where the predator uses indirect speech pathways and coded language to evade detection. Further, we find that such instances are characterized by a higher presence of out-of-vocabulary (OOV) words in samples, causing the model to misclassify. Our findings highlight the need for more robust models to identify coded language from noisy chat inputs in grooming contexts.', 'abstract_zh': '随着社交媒体的兴起，儿童在在线环境中面临的诱骗风险越来越高。检测在线对话中的诱骗实例具有显著挑战性，因为互动不一定包含性暗示，因为贩子会花时间建立信任和与受害者的关系。此外，贩子利用间接和编码语言规避检测。尽管以往的研究已将Transformer微调以自动识别聊天对话中的诱骗行为，但它们忽视了编码和间接语言对模型预测的影响，以及这些影响与人类对诱骗行为的认知如何一致。在本文中，我们弥补了这一空白，并评估双编码器在确定不同参与者组（即执法官员、真实受害者和诱饵）在聊天情境中面临的不同程度诱骗风险方面的性能。利用模糊理论框架，我们将人类对诱骗行为的评估映射到估计实际的诱骗风险程度。我们的分析表明，微调后的模型无法识别贩子利用间接言辞路径和编码语言规避检测的实例。此外，我们发现这类实例表征出样本文本中未登录词（OOV词）的更高出现频率，导致模型误分类。本文的研究结果强调了在诱骗情境中需要更 robust 的模型来识别来自嘈杂聊天输入的编码语言的重要性。', 'title_zh': '模糊评价句编码器在 grooming 风险分类中的表现'}
{'arxiv_id': 'arXiv:2502.12575', 'title': 'DemonAgent: Dynamically Encrypted Multi-Backdoor Implantation Attack on LLM-based Agent', 'authors': 'Pengyu Zhu, Zhenhong Zhou, Yuanhe Zhang, Shilinlu Yan, Kun Wang, Sen Su', 'link': 'https://arxiv.org/abs/2502.12575', 'abstract': 'As LLM-based agents become increasingly prevalent, backdoors can be implanted into agents through user queries or environment feedback, raising critical concerns regarding safety vulnerabilities. However, backdoor attacks are typically detectable by safety audits that analyze the reasoning process of agents. To this end, we propose a novel backdoor implantation strategy called \\textbf{Dynamically Encrypted Multi-Backdoor Implantation Attack}. Specifically, we introduce dynamic encryption, which maps the backdoor into benign content, effectively circumventing safety audits. To enhance stealthiness, we further decompose the backdoor into multiple sub-backdoor fragments. Based on these advancements, backdoors are allowed to bypass safety audits significantly. Additionally, we present AgentBackdoorEval, a dataset designed for the comprehensive evaluation of agent backdoor attacks. Experimental results across multiple datasets demonstrate that our method achieves an attack success rate nearing 100\\% while maintaining a detection rate of 0\\%, illustrating its effectiveness in evading safety audits. Our findings highlight the limitations of existing safety mechanisms in detecting advanced attacks, underscoring the urgent need for more robust defenses against backdoor threats. Code and data are available at this https URL.', 'abstract_zh': '基于LLM的代理中动态加密多后门植入攻击', 'title_zh': 'DemonAgent：基于LLM的代理动态加密多后门植入攻击'}
{'arxiv_id': 'arXiv:2502.12574', 'title': 'HeadInfer: Memory-Efficient LLM Inference by Head-wise Offloading', 'authors': 'Cheng Luo, Zefan Cai, Hanshi Sun, Jinqi Xiao, Bo Yuan, Wen Xiao, Junjie Hu, Jiawei Zhao, Beidi Chen, Anima Anandkumar', 'link': 'https://arxiv.org/abs/2502.12574', 'abstract': 'Transformer-based large language models (LLMs) demonstrate impressive performance in long context generation. Extending the context length has disproportionately shifted the memory footprint of LLMs during inference to the key-value cache (KV cache). In this paper, we propose HEADINFER, which offloads the KV cache to CPU RAM while avoiding the need to fully store the KV cache for any transformer layer on the GPU. HEADINFER employs a fine-grained, head-wise offloading strategy, maintaining only selective attention heads KV cache on the GPU while computing attention output dynamically. Through roofline analysis, we demonstrate that HEADINFER maintains computational efficiency while significantly reducing memory footprint. We evaluate HEADINFER on the Llama-3-8B model with a 1-million-token sequence, reducing the GPU memory footprint of the KV cache from 128 GB to 1 GB and the total GPU memory usage from 207 GB to 17 GB, achieving a 92% reduction compared to BF16 baseline inference. Notably, HEADINFER enables 4-million-token inference with an 8B model on a single consumer GPU with 24GB memory (e.g., NVIDIA RTX 4090) without approximation methods.', 'abstract_zh': '基于Transformer的大语言模型（LLMs）在长上下文生成任务中表现出色。扩展上下文长度已不均衡地将LLMs推理过程中的内存足迹转向了键值缓存（KV缓存）。本文提出HEADINFER，该方法将KV缓存卸载到CPU内存中，同时避免在任何Transformer层上完全存储KV缓存。HEADINFER采用细粒度的头级卸载策略，仅在GPU上保留选择性的注意力头KV缓存，并在计算注意力输出时动态调整。通过roofline分析，我们展示了HEADINFER在保持计算效率的同时显著减少了内存足迹。我们使用Llama-3-8B模型和100万token序列评估了HEADINFER，将KV缓存的GPU内存足迹从128 GB降低到1 GB，总GPU内存使用量从207 GB降低到17 GB，相较于BF16基线推理实现了92%的减少。值得注意的是，HEADINFER在具有24 GB内存的单个消费者级GPU（例如NVIDIA RTX 4090）上实现了8B模型的400万token推理，无需使用近似方法。', 'title_zh': 'HeadInfer: 头部明智卸载的内存高效LLM推理'}
{'arxiv_id': 'arXiv:2502.12568', 'title': 'A Cognitive Writing Perspective for Constrained Long-Form Text Generation', 'authors': 'Kaiyang Wan, Honglin Mu, Rui Hao, Haoran Luo, Tianle Gu, Xiuying Chen', 'link': 'https://arxiv.org/abs/2502.12568', 'abstract': 'Like humans, Large Language Models (LLMs) struggle to generate high-quality long-form text that adheres to strict requirements in a single pass. This challenge is unsurprising, as successful human writing, according to the Cognitive Writing Theory, is a complex cognitive process involving iterative planning, translating, reviewing, and monitoring. Motivated by these cognitive principles, we aim to equip LLMs with human-like cognitive writing capabilities through CogWriter, a novel training-free framework that transforms LLM constrained long-form text generation into a systematic cognitive writing paradigm. Our framework consists of two key modules: (1) a Planning Agent that performs hierarchical planning to decompose the task, and (2) multiple Generation Agents that execute these plans in parallel. The system maintains quality via continuous monitoring and reviewing mechanisms, which evaluate outputs against specified requirements and trigger necessary revisions. CogWriter demonstrates exceptional performance on LongGenBench, a benchmark for complex constrained long-form text generation. Even when using Qwen-2.5-14B as its backbone, CogWriter surpasses GPT-4o by 22% in complex instruction completion accuracy while reliably generating texts exceeding 10,000 words. We hope this cognitive science-inspired approach provides a paradigm for LLM writing advancements: \\href{this https URL}{CogWriter}.', 'abstract_zh': '类人类，大型语言模型在单次生成符合严格要求的长文本时也面临挑战。这一挑战不言自明，因为根据认知写作理论，成功的写作是一个涉及迭代计划、翻译、审阅和监控的复杂认知过程。受这些认知原则的启发，我们旨在通过CogWriter这一新的无需训练的框架来赋予大型语言模型类人类的认知写作能力，将受限的长文本生成转化为一种系统化的认知写作范式。该框架包含两个关键模块：（1）规划代理，执行层次化规划以分解任务；（2）多个生成代理，同时执行这些计划。系统通过持续的监控和审阅机制来维持质量，这些机制评估输出并与规定的要求进行对比，并触发必要的修订。CogWriter在LongGenBench这一复杂受限长文本生成基准测试中表现出色。即使使用Qwen-2.5-14B作为其基础模型，CogWriter在复杂指令完成精度上也超越GPT-4o 22%，同时可靠地生成超过10,000字的文本。我们希望这一受认知科学启发的方法为大型语言模型写作进步提供范式：CogWriter。', 'title_zh': '认知写作视角下的约束长文本生成'}
{'arxiv_id': 'arXiv:2502.12563', 'title': 'Evaluating Language Models on Grooming Risk Estimation Using Fuzzy Theory', 'authors': 'Geetanjali Bihani, Tatiana Ringenberg, Julia Rayz', 'link': 'https://arxiv.org/abs/2502.12563', 'abstract': 'Encoding implicit language presents a challenge for language models, especially in high-risk domains where maintaining high precision is important. Automated detection of online child grooming is one such critical domain, where predators manipulate victims using a combination of explicit and implicit language to convey harmful intentions. While recent studies have shown the potential of Transformer language models like SBERT for preemptive grooming detection, they primarily depend on surface-level features and approximate real victim grooming processes using vigilante and law enforcement conversations. The question of whether these features and approximations are reasonable has not been addressed thus far. In this paper, we address this gap and study whether SBERT can effectively discern varying degrees of grooming risk inherent in conversations, and evaluate its results across different participant groups. Our analysis reveals that while fine-tuning aids language models in learning to assign grooming scores, they show high variance in predictions, especially for contexts containing higher degrees of grooming risk. These errors appear in cases that 1) utilize indirect speech pathways to manipulate victims and 2) lack sexually explicit content. This finding underscores the necessity for robust modeling of indirect speech acts by language models, particularly those employed by predators.', 'abstract_zh': '编码隐含语言给语言模型带来了挑战，尤其是在高风险领域，保持高精度尤为关键。自动化检测在线恋童行为就是一个这样的核心领域，其中犯罪者使用明示和隐含语言的结合来传达有害意图。虽然最近的研究表明，如SBERT这样的变换器语言模型在预检测恋童行为方面具有潜力，但它们主要依赖表面级特征，并通过监护人和执法机构的对话模拟真实的恋童行为过程。关于这些特征和模拟是否合理的问题尚未得到解答。在本文中，我们填补了这一空白，研究SBERT能否有效地区分对话中固有的不同程度的恋童风险，并在其不同的参与者群体中评估其结果。我们的分析表明，虽然微调有助于语言模型学习分配恋童评分，但在高风险程度的上下文中，预测结果显示了高方差。这些错误出现在1）利用间接言语途径操纵受害者和2）缺乏明确性内容的情况下。这一发现强调了语言模型，尤其是犯罪者使用的语言模型，对间接言语行为进行稳健建模的必要性。', 'title_zh': '基于模糊理论的语言模型在估计护肤风险评估中的评价'}
{'arxiv_id': 'arXiv:2502.12558', 'title': 'MomentSeeker: A Comprehensive Benchmark and A Strong Baseline For Moment Retrieval Within Long Videos', 'authors': 'Huaying Yuan, Jian Ni, Yueze Wang, Junjie Zhou, Zhengyang Liang, Zheng Liu, Zhao Cao, Zhicheng Dou, Ji-Rong Wen', 'link': 'https://arxiv.org/abs/2502.12558', 'abstract': "Retrieval augmented generation (RAG) holds great promise in addressing challenges associated with long video understanding. These methods retrieve useful moments from long videos for their presented tasks, thereby enabling multimodal large language models (MLLMs) to generate high-quality answers in a cost-effective way. In this work, we present MomentSeeker, a comprehensive benchmark to evaluate retrieval models' performance in handling general long-video moment retrieval (LVMR) tasks. MomentSeeker offers three key advantages. First, it incorporates long videos of over 500 seconds on average, making it the first benchmark specialized for long-video moment retrieval. Second, it covers a wide range of task categories (including Moment Search, Caption Alignment, Image-conditioned Moment Search, and Video-conditioned Moment Search) and diverse application scenarios (e.g., sports, movies, cartoons, and ego), making it a comprehensive tool for assessing retrieval models' general LVMR performance. Additionally, the evaluation tasks are carefully curated through human annotation, ensuring the reliability of assessment. We further fine-tune an MLLM-based LVMR retriever on synthetic data, which demonstrates strong performance on our benchmark. We perform extensive experiments with various popular multimodal retrievers based on our benchmark, whose results highlight the challenges of LVMR and limitations for existing methods. Our created resources will be shared with community to advance future research in this field.", 'abstract_zh': '长视频片段检索增强生成（RAG）在解决长视频理解挑战方面展现出巨大潜力。这些方法从长视频中检索有用片段以完成其呈现的任务，从而使得多模态大规模语言模型（MLLMs）能够以经济有效的方式生成高质量的答案。在本文中，我们介绍了MomentSeeker，一个全面的基准测试，用于评估检索模型在处理通用长视频片段检索（LVMR）任务方面的性能。MomentSeeker提供了三项主要优势。首先，它包含平均时长超过500秒的长视频，使其成为第一个专门为长视频片段检索设计的基准测试。其次，它涵盖了广泛的任务类别（包括片段搜索、字幕对齐、图像条件下的片段搜索和视频条件下的片段搜索）和多样的应用场景（例如体育、电影、动画和自传），使其成为评估检索模型通用LVMR性能的综合工具。此外，通过人工注释精确选择评估任务，确保评估的可靠性。我们在合成数据上微调了一个基于MLLM的LVMR检索器，其在基准测试中表现出 strong 的性能。我们基于基准测试进行了广泛的实验，使用不同的流行多模态检索器，结果突显了LVMR的挑战和现有方法的局限性。我们创建的资源将与社区共享，以促进该领域的未来研究。', 'title_zh': 'MomentSeeker: 一个全面的基准和长视频关键时刻检索的强 baseline'}
{'arxiv_id': 'arXiv:2502.12552', 'title': 'LLM Safety for Children', 'authors': 'Prasanjit Rath, Hari Shrawgi, Parag Agrawal, Sandipan Dandapat', 'link': 'https://arxiv.org/abs/2502.12552', 'abstract': "This paper analyzes the safety of Large Language Models (LLMs) in interactions with children below age of 18 years. Despite the transformative applications of LLMs in various aspects of children's lives such as education and therapy, there remains a significant gap in understanding and mitigating potential content harms specific to this demographic. The study acknowledges the diverse nature of children often overlooked by standard safety evaluations and proposes a comprehensive approach to evaluating LLM safety specifically for children. We list down potential risks that children may encounter when using LLM powered applications. Additionally we develop Child User Models that reflect the varied personalities and interests of children informed by literature in child care and psychology. These user models aim to bridge the existing gap in child safety literature across various fields. We utilize Child User Models to evaluate the safety of six state of the art LLMs. Our observations reveal significant safety gaps in LLMs particularly in categories harmful to children but not adults", 'abstract_zh': '本文分析了大型语言模型（LLMs）与18岁以下儿童交互时的安全性。尽管LLMs在教育和治疗等多个方面对儿童生活产生了变革性影响，但针对这一特定人群的内容潜在危害依然存在认知和缓解上的显著差距。本研究承认儿童的多样化特质往往被标准的安全评估所忽视，并提出了一种全面的方法来评估LLMs特定针对儿童的安全性。我们列出了儿童在使用LLM驱动的应用时可能遇到的各种潜在风险，并据此开发了反映儿童多样性格和兴趣的儿童用户模型，这些用户模型旨在填补儿童安全研究在多个领域的现有差距。我们使用儿童用户模型评估了六种最先进的LLMs的安全性。我们的观察结果表明，LLMs在对儿童有害而不是对成人有害的类别中存在显著的安全缺口。', 'title_zh': '儿童安全的大型语言模型'}
{'arxiv_id': 'arXiv:2502.12548', 'title': 'Improving the Stability of GNN Force Field Models by Reducing Feature Correlation', 'authors': 'Yujie Zeng, Wenlong He, Ihor Vasyltsov, Jiaxin Wei, Ying Zhang, Lin Chen, Yuehua Dai', 'link': 'https://arxiv.org/abs/2502.12548', 'abstract': 'Recently, Graph Neural Network based Force Field (GNNFF) models are widely used in Molecular Dynamics (MD) simulation, which is one of the most cost-effective means in semiconductor material research. However, even such models provide high accuracy in energy and force Mean Absolute Error (MAE) over trained (in-distribution) datasets, they often become unstable during long-time MD simulation when used for out-of-distribution datasets. In this paper, we propose a feature correlation based method for GNNFF models to enhance the stability of MD simulation. We reveal the negative relationship between feature correlation and the stability of GNNFF models, and design a loss function with a dynamic loss coefficient scheduler to reduce edge feature correlation that can be applied in general GNNFF training. We also propose an empirical metric to evaluate the stability in MD simulation. Experiments show our method can significantly improve stability for GNNFF models especially in out-of-distribution data with less than 3% computational overhead. For example, we can ensure the stable MD simulation time from 0.03ps to 10ps for Allegro model.', 'abstract_zh': '基于特征相关性的图神经网络力场模型在分子动力学模拟中的稳定性增强方法', 'title_zh': '通过降低特征相关性提高GNN力场模型的稳定性'}
{'arxiv_id': 'arXiv:2502.12542', 'title': 'Computing Voting Rules with Improvement Feedback', 'authors': 'Evi Micha, Vasilis Varsamis', 'link': 'https://arxiv.org/abs/2502.12542', 'abstract': 'Aggregating preferences under incomplete or constrained feedback is a fundamental problem in social choice and related domains. While prior work has established strong impossibility results for pairwise comparisons, this paper extends the inquiry to improvement feedback, where voters express incremental adjustments rather than complete preferences. We provide a complete characterization of the positional scoring rules that can be computed given improvement feedback. Interestingly, while plurality is learnable under improvement feedback--unlike with pairwise feedback--strong impossibility results persist for many other positional scoring rules. Furthermore, we show that improvement feedback, unlike pairwise feedback, does not suffice for the computation of any Condorcet-consistent rule. We complement our theoretical findings with experimental results, providing further insights into the practical implications of improvement feedback for preference aggregation.', 'abstract_zh': '在不完整或受约束反馈下聚合偏好是社会选择及相关领域中的一个基本问题。虽然先前的工作在成对比较方面建立了强有力的不可能结果，但本文将研究扩展到改进反馈，其中选民表达增量调整而非完整的偏好。我们提供了在给定改进反馈的情况下可以计算的职位评分规则的完整characterization。有趣的是，虽然在改进反馈下可以学习 plurality（占优），而不同于成对反馈，许多其他职位评分规则仍然面临着强大的不可能结果。此外，我们证明了改进反馈不足以计算任何 Condorcet-一致规则，而不同于成对反馈。我们通过理论发现和实验结果进一步探讨了改进反馈对偏好聚合的实用影响。', 'title_zh': '基于改进反馈的投票规则计算'}
{'arxiv_id': 'arXiv:2502.12537', 'title': 'Finding Optimal Trading History in Reinforcement Learning for Stock Market Trading', 'authors': 'Sina Montazeria, Haseebullah Jumakhanb, Amir Mirzaeinia', 'link': 'https://arxiv.org/abs/2502.12537', 'abstract': "This paper investigates the optimization of temporal windows in Financial Deep Reinforcement Learning (DRL) models using 2D Convolutional Neural Networks (CNNs). We introduce a novel approach to treating the temporal field as a hyperparameter and examine its impact on model performance across various datasets and feature arrangements. We introduce a new hyperparameter for the CNN policy, proposing that this temporal field can and should be treated as a hyperparameter for these models. We examine the significance of this temporal field by iteratively expanding the window of observations presented to the CNN policy during the deep reinforcement learning process. Our iterative process involves progressively increasing the observation period from two weeks to twelve weeks, allowing us to examine the effects of different temporal windows on the model's performance. This window expansion is implemented in two settings. In one setting, we rearrange the features in the dataset to group them by company, allowing the model to have a full view of company data in its observation window and CNN kernel. In the second setting, we do not group the features by company, and features are arranged by category. Our study reveals that shorter temporal windows are most effective when no feature rearrangement to group per company is in effect. However, the model will utilize longer temporal windows and yield better performance once we introduce the feature rearrangement. To examine the consistency of our findings, we repeated our experiment on two datasets containing the same thirty companies from the Dow Jones Index but with different features in each dataset and consistently observed the above-mentioned patterns. The result is a trading model significantly outperforming global financial services firms such as the Global X Guru by the established Mirae Asset.", 'abstract_zh': '本文研究了在金融深度强化学习（DRL）模型中使用2D卷积神经网络（CNNs）优化时间窗口的问题。我们引入了一种新颖的方法将时间场视为超参数，并考察了它在不同数据集和特征排列下的模型性能影响。我们为CNN策略引入了一个新的超参数，建议时间场可以并且应该被视为这些模型的超参数。通过逐步扩大呈现给CNN策略观察的时间窗口，我们反复检查了不同时间窗口对模型性能的影响。这一扩增过程在两种设置中实现。在一种设置中，我们将数据集中的特征重新排列以按公司分组，使模型在其观察窗口和CNN核中能够全面查看公司数据。在另一种设置中，我们不按公司对特征进行分组，而是按类别对特征进行排列。我们的研究表明，在未对特征进行重新排列以按公司分组的情况下，较短的时间窗口最有效。但在引入特征重新排列后，模型将使用较长的时间窗口并获得更好的性能。为了验证我们的发现的一致性，我们在包含道琼斯指数中相同三十家公司的两个数据集中重复了实验，并且观察到了相同模式。结果是一个交易模型显著优于包括全球X导师在内的全球金融服务公司，由Mirae Asset公司验证。', 'title_zh': '在股票市场交易中通过强化学习寻找最优交易历史'}
{'arxiv_id': 'arXiv:2502.12536', 'title': 'An Algorithm Board in Neural Decoding', 'authors': 'Jingyi Feng, Kai Yang', 'link': 'https://arxiv.org/abs/2502.12536', 'abstract': "Understanding the mechanisms of neural encoding and decoding has always been a highly interesting research topic in fields such as neuroscience and cognitive intelligence. In prior studies, some researchers identified a symmetry in neural data decoded by unsupervised methods in motor scenarios and constructed a cognitive learning system based on this pattern (i.e., symmetry). Nevertheless, the distribution state of the data flow that significantly influences neural decoding positions still remains a mystery within the system, which further restricts the enhancement of the system's interpretability. Based on this, this paper mainly explores changes in the distribution state within the system from the machine learning and mathematical statistics perspectives. In the experiment, we assessed the correctness of this symmetry using various tools and indicators commonly utilized in mathematics and statistics. According to the experimental results, the normal distribution (or Gaussian distribution) plays a crucial role in the decoding of prediction positions within the system. Eventually, an algorithm board similar to the Galton board was built to serve as the mathematical foundation of the discovered symmetry.", 'abstract_zh': '理解神经编码与解码的机制一直是神经科学和认知智能等领域中的一个重要研究课题。在前期研究中，一些研究人员识别出了在运动场景中由无监督方法解码的神经数据中存在的对称性，并基于这一模式构建了认知学习系统。然而，显著影响神经解码位置的数据流分布状态在系统中仍然未知，这进一步限制了系统可解释性的提升。基于此，本文主要从机器学习和数学统计的角度探索系统中数据流分布状态的变化。在实验中，我们使用了数学和统计中常用的多种工具和指标来评估这一对称性。根据实验结果，正态分布（或高斯分布）在系统中预测位置的解码中起到了关键作用。最终，建立了一个类似于高尔顿板的算法板，作为发现这一对称性的数学基础。', 'title_zh': '神经解码算法板'}
{'arxiv_id': 'arXiv:2502.12531', 'title': 'GSCE: A Prompt Framework with Enhanced Reasoning for Reliable LLM-driven Drone Control', 'authors': 'Wenhao Wang, Yanyan Li, Long Jiao, Jiawei Yuan', 'link': 'https://arxiv.org/abs/2502.12531', 'abstract': 'The integration of Large Language Models (LLMs) into robotic control, including drones, has the potential to revolutionize autonomous systems. Research studies have demonstrated that LLMs can be leveraged to support robotic operations. However, when facing tasks with complex reasoning, concerns and challenges are raised about the reliability of solutions produced by LLMs. In this paper, we propose a prompt framework with enhanced reasoning to enable reliable LLM-driven control for drones. Our framework consists of novel technical components designed using Guidelines, Skill APIs, Constraints, and Examples, namely GSCE. GSCE is featured by its reliable and constraint-compliant code generation. We performed thorough experiments using GSCE for the control of drones with a wide level of task complexities. Our experiment results demonstrate that GSCE can significantly improve task success rates and completeness compared to baseline approaches, highlighting its potential for reliable LLM-driven autonomous drone systems.', 'abstract_zh': '大型语言模型在机器人控制中的集成，包括无人机，有望革新自主系统。研究显示，大型语言模型可以支持机器人操作，但在面对复杂推理任务时，关于其解决方案可靠性的担忧和挑战也随之而来。本文提出了一种增强推理的提示框架，以实现可靠的基于大型语言模型的无人机控制。该框架包括使用指南、技能API、约束和示例设计的新型技术组件，简称GSCE。GSCE的特点是其可靠的并符合约束条件的代码生成。我们使用GSCE对具有广泛复杂程度任务的无人机控制进行了细致的实验。实验结果表明，与基线方法相比，GSCE显著提高了任务的成功率和完整性，突显了其在可靠的大规模语言模型驱动的自主无人机系统中的潜力。', 'title_zh': 'GSCE: 一种增强推理的提示框架，用于可靠的LLM驱动无人机控制'}
{'arxiv_id': 'arXiv:2502.12525', 'title': 'From Abstract to Actionable: Pairwise Shapley Values for Explainable AI', 'authors': 'Jiaxin Xu, Hung Chau, Angela Burden', 'link': 'https://arxiv.org/abs/2502.12525', 'abstract': 'Explainable AI (XAI) is critical for ensuring transparency, accountability, and trust in machine learning systems as black-box models are increasingly deployed within high-stakes domains. Among XAI methods, Shapley values are widely used for their fairness and consistency axioms. However, prevalent Shapley value approximation methods commonly rely on abstract baselines or computationally intensive calculations, which can limit their interpretability and scalability. To address such challenges, we propose Pairwise Shapley Values, a novel framework that grounds feature attributions in explicit, human-relatable comparisons between pairs of data instances proximal in feature space. Our method introduces pairwise reference selection combined with single-value imputation to deliver intuitive, model-agnostic explanations while significantly reducing computational overhead. Here, we demonstrate that Pairwise Shapley Values enhance interpretability across diverse regression and classification scenarios--including real estate pricing, polymer property prediction, and drug discovery datasets. We conclude that the proposed methods enable more transparent AI systems and advance the real-world applicability of XAI.', 'abstract_zh': '可解释的人工智能（XAI）对于确保在高风险领域部署的黑盒模型具有透明性、问责制和信任至关重要。在XAI方法中，舍勒值由于其公平性和一致性公理而被广泛使用。然而，常见的舍勒值近似方法通常依赖于抽象的基本面或计算强度大的计算，这会限制其可解释性和可扩展性。为了应对这些挑战，我们提出了一种新的Pairwise舍勒值框架，该框架将特征归因基于特征空间中临近数据实例之间明确的人类可理解的对比。我们的方法结合了成对参考选择与单一值插补，以提供直观且模型无关的解释，同时显著降低了计算开销。我们证明Pairwise舍勒值在各种回归和分类场景中增强了可解释性，包括房地产定价、聚合物性质预测和药物发现数据集。我们得出结论，所提出的方 法能够实现更透明的人工智能系统，并推进XAI在实际应用中的适用性。', 'title_zh': '从抽象到可行：成对谢普利值实现可解释AI'}
{'arxiv_id': 'arXiv:2502.12524', 'title': 'YOLOv12: Attention-Centric Real-Time Object Detectors', 'authors': 'Yunjie Tian, Qixiang Ye, David Doermann', 'link': 'https://arxiv.org/abs/2502.12524', 'abstract': 'Enhancing the network architecture of the YOLO framework has been crucial for a long time, but has focused on CNN-based improvements despite the proven superiority of attention mechanisms in modeling capabilities. This is because attention-based models cannot match the speed of CNN-based models. This paper proposes an attention-centric YOLO framework, namely YOLOv12, that matches the speed of previous CNN-based ones while harnessing the performance benefits of attention mechanisms. YOLOv12 surpasses all popular real-time object detectors in accuracy with competitive speed. For example, YOLOv12-N achieves 40.6% mAP with an inference latency of 1.64 ms on a T4 GPU, outperforming advanced YOLOv10-N / YOLOv11-N by 2.1%/1.2% mAP with a comparable speed. This advantage extends to other model scales. YOLOv12 also surpasses end-to-end real-time detectors that improve DETR, such as RT-DETR / RT-DETRv2: YOLOv12-S beats RT-DETR-R18 / RT-DETRv2-R18 while running 42% faster, using only 36% of the computation and 45% of the parameters. More comparisons are shown in Figure 1.', 'abstract_zh': '一种基于注意力机制的YOLO框架YOLOv12：兼顾速度与性能', 'title_zh': 'YOLOv12: 以注意力为中心的实时物体检测器'}
{'arxiv_id': 'arXiv:2502.12511', 'title': 'Myna: Masking-Based Contrastive Learning of Musical Representations', 'authors': 'Ori Yonay, Tracy Hammond, Tianbao Yang', 'link': 'https://arxiv.org/abs/2502.12511', 'abstract': 'We present Myna, a simple yet effective approach for self-supervised musical representation learning. Built on a contrastive learning framework, Myna introduces two key innovations: (1) the use of a Vision Transformer (ViT) on mel-spectrograms as the backbone and (2) a novel data augmentation strategy, token masking, that masks 90 percent of spectrogram tokens. These innovations deliver both effectiveness and efficiency: (i) Token masking enables a significant increase in per-GPU batch size, from 48 or 120 in prior methods (CLMR, MULE) to 4096. (ii) By avoiding traditional augmentations, Myna retains pitch sensitivity, enhancing performance in tasks like key detection. (iii) The use of vertical patches allows the model to better capture critical features for key detection. Our hybrid model, Myna-22M-Hybrid, processes both 16x16 and 128x2 patches, achieving state-of-the-art results. Trained on a single GPU, it outperforms MULE (62M) on average and rivals MERT-95M, which was trained on 16 and 64 GPUs, respectively. Additionally, it surpasses MERT-95M-public, establishing itself as the best-performing model trained on publicly available data. We release our code and models to promote reproducibility and facilitate future research.', 'abstract_zh': '我们提出Myna，一种简单而有效的自监督音乐表示学习方法。基于对比学习框架，Myna引入了两项关键创新：（1）使用音色图上的视觉变换器（ViT）作为骨干网络；（2）一种新的数据增强策略——token掩蔽，掩蔽了音色图上90%的token。这些创新在有效性和效率上都取得了显著效果：（i）token掩蔽使得每块GPU的批次大小显著增加，从先前方法（CLMR, MULE）的48或120增加到4096。（ii）通过避免传统的数据增强，Myna保留了音高敏感性，提升了调性检测等任务的性能。（iii）使用垂直补丁使模型能够更好地捕捉关键特征以进行调性检测。我们的混合模型Myna-22M-Hybrid同时处理16x16和128x2补丁，实现了最先进的结果。在单块GPU上训练时，其平均性能优于MULE（62M），并且接近MERT-95M，后者在16和64块GPU上分别训练。此外，它还超越了MERT-95M-public，成为在公开可用数据上训练性能最佳的模型。我们发布我们的代码和模型以促进可重复性和未来研究。', 'title_zh': 'Myna：基于遮掩的对比学习音乐表示方法'}
{'arxiv_id': 'arXiv:2502.12509', 'title': 'LegalCore: A Dataset for Legal Documents Event Coreference Resolution', 'authors': 'Kangda Wei, Xi Shi, Jonathan Tong, Sai Ramana Reddy, Anandhavelu Natarajan, Rajiv Jain, Aparna Garimella, Ruihong Huang', 'link': 'https://arxiv.org/abs/2502.12509', 'abstract': 'Recognizing events and their coreferential mentions in a document is essential for understanding semantic meanings of text. The existing research on event coreference resolution is mostly limited to news articles. In this paper, we present the first dataset for the legal domain, LegalCore, which has been annotated with comprehensive event and event coreference information. The legal contract documents we annotated in this dataset are several times longer than news articles, with an average length of around 25k tokens per document. The annotations show that legal documents have dense event mentions and feature both short-distance and super long-distance coreference links between event mentions. We further benchmark mainstream Large Language Models (LLMs) on this dataset for both event detection and event coreference resolution tasks, and find that this dataset poses significant challenges for state-of-the-art open-source and proprietary LLMs, which perform significantly worse than a supervised baseline. We will publish the dataset as well as the code.', 'abstract_zh': '识别文档中事件及其同指提及对于理解文本语义意义至关重要。现有的事件同指消解研究主要集中在新闻文章上。在本文中，我们首次提出了一个法律领域数据集LegalCore，该数据集包含了全面的事件及其事件同指标注信息。我们标注的法律合同文件长度远超新闻文章，平均每份文件包含约25k个词。标注结果显示，法律文件中的事件提及密集，并且事件提及之间存在短距离和超长距离的同指连接。我们进一步在该数据集上对主流大型语言模型（LLMs）进行了事件检测和事件同指消解任务的基准测试，发现该数据集对最先进的开源和专有LLMs构成了重大挑战，这些模型的表现显著劣于监督基线。我们将发布该数据集以及相关的代码。', 'title_zh': 'LegalCore：法律文件事件同指解析数据集'}
{'arxiv_id': 'arXiv:2502.12507', 'title': 'Mixture of Attention Yields Accurate Results for Tabular Data', 'authors': 'Xuechen Li, Yupeng Li, Jian Liu, Xiaolin Jin, Tian Yang, Xin Hu', 'link': 'https://arxiv.org/abs/2502.12507', 'abstract': 'Tabular data inherently exhibits significant feature heterogeneity, but existing transformer-based methods lack specialized mechanisms to handle this property. To bridge the gap, we propose MAYA, an encoder-decoder transformer-based framework. In the encoder, we design a Mixture of Attention (MOA) that constructs multiple parallel attention branches and averages the features at each branch, effectively fusing heterogeneous features while limiting parameter growth. Additionally, we employ collaborative learning with a dynamic consistency weight constraint to produce more robust representations. In the decoder stage, cross-attention is utilized to seamlessly integrate tabular data with corresponding label features. This dual-attention mechanism effectively captures both intra-instance and inter-instance interactions. We evaluate the proposed method on a wide range of datasets and compare it with other state-of-the-art transformer-based methods. Extensive experiments demonstrate that our model achieves superior performance among transformer-based methods in both tabular classification and regression tasks.', 'abstract_zh': 'Tabular 数据固有地表现出显著的特征异质性，但现有的基于变压器的方法缺乏专门处理这一特性的机制。为了弥合这一差距，我们提出了 MAYA，一个基于编码器-解码器的变压器框架。在编码器中，我们设计了混合注意力（MOA），构建了多个并行的注意力分支并在每个分支上平均特征，从而有效地融合异质特征同时限制参数增长。此外，我们采用了具有动态一致性权重约束的合作学习，以生成更稳健的表示。在解码阶段，我们使用交叉注意力无缝地将表结构数据与相应的标签特征集成起来。这种双注意力机制有效地捕捉了实例内和实例间的交互。我们使用多种数据集评估了提出的模型，并将其与其它最先进的基于变压器的方法进行了比较。广泛的实验表明，我们的模型在表结构分类和回归任务中均表现出优于基于变压器方法的性能。', 'title_zh': '混合注意力机制适用于表格数据的准确结果'}
{'arxiv_id': 'arXiv:2502.12494', 'title': 'EDGE: Efficient Data Selection for LLM Agents via Guideline Effectiveness', 'authors': 'Yunxiao Zhang, Guanming Xiong, Haochen Li, Wen Zhao', 'link': 'https://arxiv.org/abs/2502.12494', 'abstract': 'Large Language Models (LLMs) have shown remarkable capabilities as AI agents. However, existing methods for enhancing LLM-agent abilities often lack a focus on data quality, leading to inefficiencies and suboptimal results in both fine-tuning and prompt engineering. To address this issue, we introduce EDGE, a novel approach for identifying informative samples without needing golden answers. We propose the Guideline Effectiveness (GE) metric, which selects challenging samples by measuring the impact of human-provided guidelines in multi-turn interaction tasks. A low GE score indicates that the human expertise required for a sample is missing from the guideline, making the sample more informative. By selecting samples with low GE scores, we can improve the efficiency and outcomes of both prompt engineering and fine-tuning processes for LLMs. Extensive experiments validate the performance of our method. Our method achieves competitive results on the HotpotQA and WebShop and datasets, requiring 75\\% and 50\\% less data, respectively, while outperforming existing methods. We also provide a fresh perspective on the data quality of LLM-agent fine-tuning.', 'abstract_zh': '大规模语言模型（LLMs）展示了作为AI代理的显著能力。然而，现有的增强LLM-代理能力的方法往往缺乏对数据质量的关注，这在微调和提示工程中导致了效率低下和次优结果。为了解决这一问题，我们提出了EDGE，一种无需金标准答案即可识别有信息量样本的新型方法。我们提出了指南有效性（GE）度量，通过衡量人类提供的指南在多轮交互任务中的影响来选择具有挑战性的样本。GE分数较低表明样本所需的人类专业知识未包含在指南中，从而使样本更具有信息量。通过选择GE分数较低的样本，我们可以提高LLM的提示工程和微调过程的效率和结果。广泛的实验验证了我们方法的性能。我们的方法在HotpotQA和WebShop数据集上取得了竞争力的结果，分别仅需要75%和50%的数据，并优于现有方法。我们还提供了LLM-代理微调数据质量的新视角。', 'title_zh': 'EDGE: 通过指南有效性进行高效数据选择的LLM代理方法'}
{'arxiv_id': 'arXiv:2502.12489', 'title': 'A Comprehensive Survey on Generative AI for Video-to-Music Generation', 'authors': 'Shulei Ji, Songruoyao Wu, Zihao Wang, Shuyu Li, Kejun Zhang', 'link': 'https://arxiv.org/abs/2502.12489', 'abstract': 'The burgeoning growth of video-to-music generation can be attributed to the ascendancy of multimodal generative models. However, there is a lack of literature that comprehensively combs through the work in this field. To fill this gap, this paper presents a comprehensive review of video-to-music generation using deep generative AI techniques, focusing on three key components: visual feature extraction, music generation frameworks, and conditioning mechanisms. We categorize existing approaches based on their designs for each component, clarifying the roles of different strategies. Preceding this, we provide a fine-grained classification of video and music modalities, illustrating how different categories influence the design of components within the generation pipelines. Furthermore, we summarize available multimodal datasets and evaluation metrics while highlighting ongoing challenges in the field.', 'abstract_zh': '视频到音乐生成的蓬勃发展可归因于多模态生成模型的兴起。然而，缺乏对该领域工作的全面综述文献。为填补这一空白，本文基于深度生成AI技术对视频到音乐生成进行了全面综述，重点讨论三个关键组件：视觉特征提取、音乐生成框架和条件机制。我们根据每个组件的设计将其现有方法分类，澄清不同策略的作用。在此之前，我们提供了视频和音乐模态的精细分类，说明不同类别如何影响生成管道中组件的设计。此外，我们总结了可用的多模态数据集和评估指标，并强调了该领域面临的持续挑战。', 'title_zh': '全面综述：基于视频自动生成音乐的生成型AI技术'}
{'arxiv_id': 'arXiv:2502.12485', 'title': 'Safe at the Margins: A General Approach to Safety Alignment in Low-Resource English Languages -- A Singlish Case Study', 'authors': 'Isaac Lim, Shaun Khoo, Watson Chua, Goh Jiayi, Jessica Foo', 'link': 'https://arxiv.org/abs/2502.12485', 'abstract': 'To ensure safe usage, Large Language Models (LLMs) typically undergo alignment with human-defined values. However, this alignment often relies on primarily English data and is biased towards Western-centric values, limiting its effectiveness in low-resource language settings. In this paper, we describe our approach for aligning SEA-Lion-v2.1-Instruct (a Llama3-8B variant) to minimize toxicity in Singlish, an English creole specific to Singapore. We find that supervised fine-tuning and Kahneman-Tversky Optimization (KTO) on paired and unpaired preferences is more sample efficient and yields significantly better results than Direct Preference Optimization (DPO). Our analysis reveals that DPO implicitly enforces a weaker safety objective than KTO, and that SFT complements KTO by improving training stability. Finally, we introduce a simple but novel modification to KTO, KTO-S, which improves training stability through better gradient exploitation. Overall, we present a general approach for safety alignment conducive to low-resource English languages, successfully reducing toxicity by 99\\% on our Singlish benchmark, with gains generalizing to the broader TOXIGEN dataset while maintaining strong performance across standard LLM benchmarks.', 'abstract_zh': '确保安全使用：将大型语言模型SEA-Lion-v2.1-Instruct（一种Llama3-8B变体）对新加坡英语（Singlish）中的毒性进行最小化对齐', 'title_zh': '在边缘处求安全：一种低资源英语语言安全对齐的一般性方法——以新加坡英语案例研究为例'}
{'arxiv_id': 'arXiv:2502.12484', 'title': 'LocalEscaper: A Weakly-supervised Framework with Regional Reconstruction for Scalable Neural TSP Solvers', 'authors': 'Junrui Wen, Yifei Li, Bart Selman, Kun He', 'link': 'https://arxiv.org/abs/2502.12484', 'abstract': 'Neural solvers have shown significant potential in solving the Traveling Salesman Problem (TSP), yet current approaches face significant challenges. Supervised learning (SL)-based solvers require large amounts of high-quality labeled data, while reinforcement learning (RL)-based solvers, though less dependent on such data, often suffer from inefficiencies. To address these limitations, we propose LocalEscaper, a novel weakly-supervised learning framework for large-scale TSP. LocalEscaper effectively combines the advantages of both SL and RL, enabling effective training on datasets with low-quality labels. To further enhance solution quality, we introduce a regional reconstruction strategy, which mitigates the problem of local optima, a common issue in existing local reconstruction methods. Additionally, we propose a linear-complexity attention mechanism that reduces computational overhead, enabling the efficient solution of large-scale TSPs without sacrificing performance. Experimental results on both synthetic and real-world datasets demonstrate that LocalEscaper outperforms existing neural solvers, achieving state-of-the-art results. Notably, it sets a new benchmark for scalability and efficiency, solving TSP instances with up to 50,000 cities.', 'abstract_zh': '局部逃逸者：一种新型弱监督学习框架用于大规模旅行商问题', 'title_zh': 'LocalEscaper: 一种基于区域重建的弱监督框架，用于可扩展的神经TSP求解器'}
{'arxiv_id': 'arXiv:2502.12481', 'title': 'Predicate Hierarchies Improve Few-Shot State Classification', 'authors': 'Emily Jin, Joy Hsu, Jiajun Wu', 'link': 'https://arxiv.org/abs/2502.12481', 'abstract': 'State classification of objects and their relations is core to many long-horizon tasks, particularly in robot planning and manipulation. However, the combinatorial explosion of possible object-predicate combinations, coupled with the need to adapt to novel real-world environments, makes it a desideratum for state classification models to generalize to novel queries with few examples. To this end, we propose PHIER, which leverages predicate hierarchies to generalize effectively in few-shot scenarios. PHIER uses an object-centric scene encoder, self-supervised losses that infer semantic relations between predicates, and a hyperbolic distance metric that captures hierarchical structure; it learns a structured latent space of image-predicate pairs that guides reasoning over state classification queries. We evaluate PHIER in the CALVIN and BEHAVIOR robotic environments and show that PHIER significantly outperforms existing methods in few-shot, out-of-distribution state classification, and demonstrates strong zero- and few-shot generalization from simulated to real-world tasks. Our results demonstrate that leveraging predicate hierarchies improves performance on state classification tasks with limited data.', 'abstract_zh': '基于谓词层次结构的状态分类及其关系的建模在长时任务中至关重要，特别是在机器人规划和操作中。为了使状态分类模型能够在少量示例的情况下泛化到新的查询，我们提出了PHIER，它利用谓词层次结构在少样本场景中有效泛化。PHIER使用以物体为中心的场景编码器、从谓词间语义关系的自监督损失以及捕捉层次结构的双曲距离度量；它学习图像-谓词对的结构化潜在空间，指导状态分类查询的推理。我们在CALVIN和BEHAVIOR机器人环境中评估PHIER，结果显示PHIER在少样本、分布外状态分类中显著优于现有方法，并且在模拟到真实任务的零样本和少样本泛化方面表现出色。我们的结果表明，利用谓词层次结构可以提高在数据有限的情况下进行状态分类任务的性能。', 'title_zh': '谓词层次结构改进少量样本状态分类'}
{'arxiv_id': 'arXiv:2502.12468', 'title': 'MCTS-Judge: Test-Time Scaling in LLM-as-a-Judge for Code Correctness Evaluation', 'authors': 'Yutong Wang, Pengliang Ji, Chaoqun Yang, Kaixin Li, Ming Hu, Jiaoyang Li, Guillaume Sartoretti', 'link': 'https://arxiv.org/abs/2502.12468', 'abstract': "The LLM-as-a-Judge paradigm shows promise for evaluating generative content but lacks reliability in reasoning-intensive scenarios, such as programming. Inspired by recent advances in reasoning models and shifts in scaling laws, we pioneer bringing test-time computation into LLM-as-a-Judge, proposing MCTS-Judge, a resource-efficient, System-2 thinking framework for code correctness evaluation. MCTS-Judge leverages Monte Carlo Tree Search (MCTS) to decompose problems into simpler, multi-perspective evaluations. Through a node-selection strategy that combines self-assessment based on historical actions in the current trajectory and the Upper Confidence Bound for Trees based on prior rollouts, MCTS-Judge balances global optimization and refinement of the current trajectory. We further designed a high-precision, unit-test-level reward mechanism to encourage the Large Language Model (LLM) to perform line-by-line analysis. Extensive experiments on three benchmarks and five LLMs demonstrate the effectiveness of MCTS-Judge, which improves the base model's accuracy from 41% to 80%, surpassing the o1-series models with 3x fewer tokens. Further evaluations validate the superiority of its reasoning trajectory in logic, analytics, thoroughness, and overall quality, while revealing the test-time scaling law of the LLM-as-a-Judge paradigm.", 'abstract_zh': 'LLM-as-a-Judge paradigm结合蒙特卡洛树搜索的高效代码正确性评价框架', 'title_zh': 'MCTS-Judge：代码正确性评估中基于LLM的测试时可扩展性方法'}
{'arxiv_id': 'arXiv:2502.12466', 'title': 'EquiBench: Benchmarking Code Reasoning Capabilities of Large Language Models via Equivalence Checking', 'authors': 'Anjiang Wei, Jiannan Cao, Ran Li, Hongyu Chen, Yuhui Zhang, Ziheng Wang, Yaofeng Sun, Yuan Liu, Thiago S. F. X. Teixeira, Diyi Yang, Ke Wang, Alex Aiken', 'link': 'https://arxiv.org/abs/2502.12466', 'abstract': "Equivalence checking, i.e., determining whether two programs produce identical outputs for all possible inputs, underpins a broad range of applications, including software refactoring, testing, and optimization. We present the task of equivalence checking as a new way to evaluate the code reasoning abilities of large language models (LLMs). We introduce EquiBench, a dataset of 2400 program pairs spanning four programming languages and six equivalence categories. These pairs are systematically generated through program analysis, compiler scheduling, and superoptimization, covering nontrivial structural transformations that demand deep semantic reasoning beyond simple syntactic variations. Our evaluation of 17 state-of-the-art LLMs shows that OpenAI o3-mini achieves the highest overall accuracy of 78.0%. In the most challenging categories, the best accuracies are 62.3% and 68.8%, only modestly above the 50% random baseline for binary classification, indicating significant room for improvement in current models' code reasoning capabilities.", 'abstract_zh': '等价性检查，即确定两个程序在所有可能的输入下是否产生相同的输出，是软件重构、测试和优化等多种应用的基础。我们将等价性检查任务视为评估大型语言模型（LLMs）代码推理能力的新方法。我们介绍了EquiBench数据集，包含2400个程序对，覆盖四种编程语言和六种等价性类别。这些程序对通过程序分析、编译器调度和超优化系统生成，涵盖了要求深刻语义推理的复杂结构变换，不仅超越了简单的语法变体。对17个最先进的LLM进行评估显示，OpenAI o3-mini的整体准确率为78.0%。在最具挑战性的类别中，最高准确率为62.3%和68.8%，仅略高于二分类的50%随机基线，表明当前模型的代码推理能力仍有显著提升空间。', 'title_zh': 'EquiBench: 通过等价性检查评估大型语言模型的代码推理能力'}
{'arxiv_id': 'arXiv:2502.12459', 'title': 'Stress Testing Generalization: How Minor Modifications Undermine Large Language Model Performance', 'authors': 'Guangxiang Zhao, Saier Hu, Xiaoqi Jian, Jinzhu Wu, Yuhan Wu, Change Jia, Lin Sun, Xiangzheng Zhang', 'link': 'https://arxiv.org/abs/2502.12459', 'abstract': 'This paper investigates the fragility of Large Language Models (LLMs) in generalizing to novel inputs, specifically focusing on minor perturbations in well-established benchmarks (e.g., slight changes in question format or distractor length). Despite high benchmark scores, LLMs exhibit significant accuracy drops and unexpected biases (e.g., preference for longer distractors) when faced with these minor but content-preserving modifications. For example, Qwen 2.5 1.5B\'s MMLU score rises from 60 to 89 and drops from 89 to 36 when option lengths are changed without altering the question. Even GPT-4 experiences a 25-point accuracy loss when question types are changed, with a 6-point drop across all three modification categories. These analyses suggest that LLMs rely heavily on superficial cues rather than forming robust, abstract representations that generalize across formats, lexical variations, and irrelevant content shifts. This work aligns with the ACL 2025 theme track on the Generalization of NLP models, proposing a "Generalization Stress Test" to assess performance shifts under controlled perturbations. The study calls for reevaluating benchmarks and developing more reliable evaluation methodologies to capture LLM generalization abilities better.', 'abstract_zh': '本文研究了大规模语言模型（LLMs）在应对新颖输入时的脆弱性，特别关注于在广泛认可的基准测试中（如问题格式或干扰项长度的小幅变化）引入细微扰动。尽管在基准测试中取得了高分，但当面对这些细微但内容保留的修改时，LLMs仍表现出显著的准确率下降和意想不到的偏差（例如，偏好更长的干扰项）。例如，Qwen 2.5 1.5B的MMLU分数在选项长度改变而不改变问题的情况下，从60上升到89，随后又从89下降到36。即使GPT-4在问题类型发生变化时也经历了25点的准确率损失，在所有三种修改类别中平均下降6点。这些分析表明，LLMs主要依赖于表面特征，而不是形成能够跨格式、词汇变体和不相关内容转移的稳健、抽象的表示。该研究与ACL 2025主题跟踪中的自然语言处理模型泛化主题一致，提出了“泛化压力测试”来评估在控制扰动下的性能变化。研究呼吁重新评估基准测试，并开发更可靠的评估方法，以更好地捕捉LLM的泛化能力。', 'title_zh': '泛化压力测试：细微修改如何削弱大型语言模型性能'}
{'arxiv_id': 'arXiv:2502.12456', 'title': 'Not-So-Optimal Transport Flows for 3D Point Cloud Generation', 'authors': 'Ka-Hei Hui, Chao Liu, Xiaohui Zeng, Chi-Wing Fu, Arash Vahdat', 'link': 'https://arxiv.org/abs/2502.12456', 'abstract': 'Learning generative models of 3D point clouds is one of the fundamental problems in 3D generative learning. One of the key properties of point clouds is their permutation invariance, i.e., changing the order of points in a point cloud does not change the shape they represent. In this paper, we analyze the recently proposed equivariant OT flows that learn permutation invariant generative models for point-based molecular data and we show that these models scale poorly on large point clouds. Also, we observe learning (equivariant) OT flows is generally challenging since straightening flow trajectories makes the learned flow model complex at the beginning of the trajectory. To remedy these, we propose not-so-optimal transport flow models that obtain an approximate OT by an offline OT precomputation, enabling an efficient construction of OT pairs for training. During training, we can additionally construct a hybrid coupling by combining our approximate OT and independent coupling to make the target flow models easier to learn. In an extensive empirical study, we show that our proposed model outperforms prior diffusion- and flow-based approaches on a wide range of unconditional generation and shape completion on the ShapeNet benchmark.', 'abstract_zh': '学习3D点云生成模型是3D生成学习中的基本问题之一。点云的一个关键性质是其置换不变性，即改变点云中点的顺序不会改变它们所代表的形状。在本文中，我们分析了最近提出的等变OT流，这些流学习基于点的分子数据的置换不变生成模型，并展示了这些模型在大点云上缩放不良。我们还观察到，学习（等变的）OT流通常具有挑战性，因为拉直流轨迹会使学习的流模型在轨迹开始时变得复杂。为了解决这些问题，我们提出了近似OT流模型，通过离线预计算OT来获得近似OT，从而能够高效地构建OT对进行训练。在训练过程中，我们还可以通过结合我们的近似OT和独立耦合来构建混合耦合，使目标流模型更易于学习。在广泛的实证研究中，我们展示了我们的模型在ShapeNet基准上的无条件生成和形状补全任务中优于先前的扩散和流基方法。', 'title_zh': '非最优输运流生成3D点云'}
{'arxiv_id': 'arXiv:2502.12454', 'title': 'Benchmarking Zero-Shot Facial Emotion Annotation with Large Language Models: A Multi-Class and Multi-Frame Approach in DailyLife', 'authors': 'He Zhang, Xinyi Fu', 'link': 'https://arxiv.org/abs/2502.12454', 'abstract': 'This study investigates the feasibility and performance of using large language models (LLMs) to automatically annotate human emotions in everyday scenarios. We conducted experiments on the DailyLife subset of the publicly available FERV39k dataset, employing the GPT-4o-mini model for rapid, zero-shot labeling of key frames extracted from video segments. Under a seven-class emotion taxonomy ("Angry," "Disgust," "Fear," "Happy," "Neutral," "Sad," "Surprise"), the LLM achieved an average precision of approximately 50%. In contrast, when limited to ternary emotion classification (negative/neutral/positive), the average precision increased to approximately 64%. Additionally, we explored a strategy that integrates multiple frames within 1-2 second video clips to enhance labeling performance and reduce costs. The results indicate that this approach can slightly improve annotation accuracy. Overall, our preliminary findings highlight the potential application of zero-shot LLMs in human facial emotion annotation tasks, offering new avenues for reducing labeling costs and broadening the applicability of LLMs in complex multimodal environments.', 'abstract_zh': '本研究探讨了使用大型语言模型（LLMs）自动标注日常生活场景中人类情绪的可行性和性能。我们在公开可用的FERV39k数据集中的DailyLife子集上进行了实验，利用GPT-4o-mini模型对视频片段中提取的关键帧进行快速零样本标注。在七类情绪分类 taxonomy (“愤怒”、“厌恶”、“恐惧”、“快乐”、“中性”、“悲伤”、“惊讶”) 下，LLM 的平均精度约为 50%。相比之下，在仅限三元情感分类（负/中性/正）的情况下，平均精度提高到约 64%。此外，我们探讨了一种在 1-2 秒视频片段中整合多帧以提高标注性能并降低成本的策略。结果显示，这种方法可以略微提高标注准确性。总体而言，我们的初步研究成果突显了零样本 LLM 在人类面部情绪标注任务中的潜在应用，为减少标注成本和扩大 LLM 在复杂多模态环境中的应用提供了新的途径。', 'title_zh': '基于大型语言模型的零样本面部情绪标注benchmark：日常生活中的多类别多帧方法'}
{'arxiv_id': 'arXiv:2502.12453', 'title': 'UniMatch: Universal Matching from Atom to Task for Few-Shot Drug Discovery', 'authors': 'Ruifeng Li, Mingqian Li, Wei Liu, Yuhua Zhou, Xiangxin Zhou, Yuan Yao, Qiang Zhang, Hongyang Chen', 'link': 'https://arxiv.org/abs/2502.12453', 'abstract': 'Drug discovery is crucial for identifying candidate drugs for various this http URL, its low success rate often results in a scarcity of annotations, posing a few-shot learning problem. Existing methods primarily focus on single-scale features, overlooking the hierarchical molecular structures that determine different molecular properties. To address these issues, we introduce Universal Matching Networks (UniMatch), a dual matching framework that integrates explicit hierarchical molecular matching with implicit task-level matching via meta-learning, bridging multi-level molecular representations and task-level generalization. Specifically, our approach explicitly captures structural features across multiple levels, such as atoms, substructures, and molecules, via hierarchical pooling and matching, facilitating precise molecular representation and comparison. Additionally, we employ a meta-learning strategy for implicit task-level matching, allowing the model to capture shared patterns across tasks and quickly adapt to new ones. This unified matching framework ensures effective molecular alignment while leveraging shared meta-knowledge for fast adaptation. Our experimental results demonstrate that UniMatch outperforms state-of-the-art methods on the MoleculeNet and FS-Mol benchmarks, achieving improvements of 2.87% in AUROC and 6.52% in delta AUPRC. UniMatch also shows excellent generalization ability on the Meta-MolNet benchmark.', 'abstract_zh': '药物发现对于识别各种候选药物至关重要，但由于其较低的成功率常常导致标注数据稀缺，从而产生少量样本学习问题。现有方法主要关注单尺度特征，忽视了决定不同分子性质的层级分子结构。为解决这些问题，我们引入了统一匹配网络（UniMatch），这是一种结合显式层级分子匹配和隐式任务级匹配的双重匹配框架，通过元学习将多层次分子表示与任务级泛化联系起来。具体而言，我们的方法通过层级聚合和匹配明确捕捉多层级的结构特征，如原子、亚结构和分子，促进精确的分子表示和比较。此外，我们采用了元学习策略进行隐式任务级匹配，使模型能够捕捉任务间的共享模式并快速适应新任务。这种统一匹配框架确保了有效的分子对齐，同时通过共享的元知识实现快速适应。实验结果表明，UniMatch在MoleculeNet和FS-Mol基准上优于现有方法，在AUROC上提升了2.87%，在delta AUPRC上提升了6.52%。UniMatch还展示了在Meta-MolNet基准上的强大泛化能力。', 'title_zh': 'UniMatch: 从原子到任务的通用 few-shot 药物发现匹配方法'}
{'arxiv_id': 'arXiv:2502.12446', 'title': 'Multi-Attribute Steering of Language Models via Targeted Intervention', 'authors': 'Duy Nguyen, Archiki Prasad, Elias Stengel-Eskin, Mohit Bansal', 'link': 'https://arxiv.org/abs/2502.12446', 'abstract': "Inference-time intervention (ITI) has emerged as a promising method for steering large language model (LLM) behavior in a particular direction (e.g., improving helpfulness) by intervening on token representations without costly updates to the LLM's parameters. However, existing ITI approaches fail to scale to multi-attribute settings with conflicts, such as enhancing helpfulness while also reducing toxicity. To address this, we introduce Multi-Attribute Targeted Steering (MAT-Steer), a novel steering framework designed for selective token-level intervention across multiple attributes. MAT-Steer learns steering vectors using an alignment objective that shifts the model's internal representations of undesirable outputs closer to those of desirable ones while enforcing sparsity and orthogonality among vectors for different attributes, thereby reducing inter-attribute conflicts. We evaluate MAT-Steer in two distinct settings: (i) on question answering (QA) tasks where we balance attributes like truthfulness, bias, and toxicity; (ii) on generative tasks where we simultaneously improve attributes like helpfulness, correctness, and coherence. MAT-Steer outperforms existing ITI and parameter-efficient finetuning approaches across both task types (e.g., 3% average accuracy gain across QA tasks and 55.82% win rate against the best ITI baseline).", 'abstract_zh': '多属性针对性调节（MAT-Steer）：一种用于多属性上下文的选择性tokens级干预框架', 'title_zh': '针对目标干预的多属性语言模型调控'}
{'arxiv_id': 'arXiv:2502.12444', 'title': 'SparAMX: Accelerating Compressed LLMs Token Generation on AMX-powered CPUs', 'authors': 'Ahmed F. AbouElhamayed, Jordan Dotzel, Yash Akhauri, Chi-Chih Chang, Sameh Gobriel, J. Pablo Muñoz, Vui Seng Chua, Nilesh Jain, Mohamed S. Abdelfattah', 'link': 'https://arxiv.org/abs/2502.12444', 'abstract': 'Large language models have high compute, latency, and memory requirements. While specialized accelerators such as GPUs and TPUs typically run these workloads, CPUs are more widely available and consume less energy. Accelerating LLMs with CPUs enables broader AI access at a lower cost and power consumption. This acceleration potential for CPUs is especially relevant during the memory-bound decoding stage of LLM inference, which processes one token at a time and is becoming increasingly utilized with reasoning models. We utilize Advanced Matrix Extensions (AMX) support on the latest Intel CPUs together with unstructured sparsity to achieve a $1.42 \\times$ reduction in end-to-end latency compared to the current PyTorch implementation by applying our technique in linear layers. We provide a set of open-source customized sparse kernels that can speed up any PyTorch model by automatically replacing all linear layers with our custom sparse implementation. Furthermore, we demonstrate for the first time the use of unstructured sparsity in the attention computation achieving a $1.14 \\times$ speedup over the current systems without compromising accuracy. Code: this https URL', 'abstract_zh': '大型语言模型对计算、延迟和内存有高要求。虽然专门的加速器如GPU和TPU通常运行这些工作负载，但CPU更为普及且能耗更低。使用CPU加速大型语言模型可以降低AI的访问成本和能耗，使其更广泛地使用。特别是在LLM推理中的内存限制解码阶段，该阶段逐个处理一个标记并随着推理模型的增加而变得越来越常用时，CPU加速潜力尤为相关。我们利用最新Intel CPU的高级矩阵扩展(AMX)支持，结合无结构稀疏性，在线性层上应用我们的技术，实现了与当前PyTorch实现相比端到端延迟减少1.42倍。我们提供了一组开源定制稀疏内核，可以通过自动将所有线性层替换为我们的定制稀疏实现，来加速任何PyTorch模型。此外，我们首次展示了在注意力计算中使用无结构稀疏性，实现了与当前系统相比1.14倍的加速，且不牺牲准确度。代码：https://github.com/...', 'title_zh': 'SparAMX: 在AMX-powered CPU上加速压缩LLMs_token生成'}
{'arxiv_id': 'arXiv:2502.12430', 'title': 'Bridge the Gaps between Machine Unlearning and AI Regulation', 'authors': 'Bill Marino, Meghdad Kurmanji, Nicholas D. Lane', 'link': 'https://arxiv.org/abs/2502.12430', 'abstract': 'The "right to be forgotten" and the data privacy laws that encode it have motivated machine unlearning since its earliest days. Now, an inbound wave of artificial intelligence regulations - like the European Union\'s Artificial Intelligence Act (AIA) - potentially offer important new use cases for machine unlearning. However, this position paper argues, this opportunity will only be realized if researchers, aided by policymakers, proactively bridge the (sometimes sizable) gaps between machine unlearning\'s state of the art and its potential applications to AI regulation. To demonstrate this point, we use the AIA as an example. Specifically, we deliver a "state of the union" as regards machine unlearning\'s current potential for aiding compliance with the AIA. This starts with a precise cataloging of the potential applications of machine unlearning to AIA compliance. For each, we flag any legal ambiguities clouding the potential application and, moreover, flag the technical gaps that exist between the potential application and the state of the art of machine unlearning. Finally, we end with a call to action: for both machine learning researchers and policymakers, to, respectively, solve the open technical and legal questions that will unlock machine unlearning\'s potential to assist compliance with the AIA - and other AI regulation like it.', 'abstract_zh': '“被遗忘权”和编码其中的数据隐私法律促使机器遗忘技术自其最早期开始发展。现在，一股入境的人工智能法规浪潮——如欧盟的《人工智能法案》——可能为机器遗忘技术提供了重要的新应用场景。然而，本文认为，这种机会只有在研究者得到政策制定者支持的情况下，积极弥合机器遗忘技术的最新进展与其在人工智能法规中的潜在应用之间的（有时较大的）差距后，才能实现。为了证明这一点，我们以《人工智能法案》为例。具体而言，我们提供了一种关于机器遗忘技术当前如何帮助遵守《人工智能法案》的“国情咨文”。这始于一份精确列出机器遗忘技术在《人工智能法案》合规中潜在应用的清单。对于每一种潜在应用，我们指出了任何可能模糊潜在应用的法律 ambiguities，并进一步指出了存在于潜在应用与机器遗忘技术的最新进展之间的技术差距。最后，我们发出呼吁：对于机器学习研究人员和政策制定者来说，分别解决解锁机器遗忘技术协助遵守《人工智能法案》及其他类似人工智能法规的开放技术与法律问题。', 'title_zh': '机器卸载与人工智能规制之间的差距弥合'}
{'arxiv_id': 'arXiv:2502.12420', 'title': 'Sens-Merging: Sensitivity-Guided Parameter Balancing for Merging Large Language Models', 'authors': 'Shuqi Liu, Han Wu, Bowei He, Xiongwei Han, Mingxuan Yuan, Linqin Song', 'link': 'https://arxiv.org/abs/2502.12420', 'abstract': 'Recent advances in large language models have led to numerous task-specialized fine-tuned variants, creating a need for efficient model merging techniques that preserve specialized capabilities while avoiding costly retraining. While existing task vector-based merging methods show promise, they typically apply uniform coefficients across all parameters, overlooking varying parameter importance both within and across tasks. We present Sens-Merging, a sensitivity-guided coefficient adjustment method that enhances existing model merging techniques by operating at both task-specific and cross-task levels. Our method analyzes parameter sensitivity within individual tasks and evaluates cross-task transferability to determine optimal merging coefficients. Extensive experiments on Mistral 7B and LLaMA2-7B/13B models demonstrate that Sens-Merging significantly improves performance across general knowledge, mathematical reasoning, and code generation tasks. Notably, when combined with existing merging techniques, our method enables merged models to outperform specialized fine-tuned models, particularly in code generation tasks. Our findings reveal important trade-offs between task-specific and cross-task scalings, providing insights for future model merging strategies.', 'abstract_zh': '近期大型语言模型的进展催生了多种任务特化的微调变体，这促使我们需要开发高效的模型合并技术，以保留专用能力同时避免昂贵的重新训练。虽然现有的基于任务向量的合并方法显示出潜力，但它们通常对所有参数采用均匀系数，忽略了参数在任务内和跨任务间的不同重要性。我们提出了一种基于敏感性的系数调整方法——Sens-Merging，该方法通过任务特定和跨任务两个层面增强现有的模型合并技术。我们的方法分析了单任务中的参数敏感性，并评估其跨任务可迁移性，以确定最优的合并系数。我们在Mistral 7B和LLaMA2-7B/13B模型上的广泛实验表明，Sens-Merging显著提升了通用知识、数学推理和代码生成任务的性能。值得注意的是，结合现有的合并技术后，我们的方法使得合并模型在代码生成任务上优于专用微调模型。我们的研究结果揭示了任务特定和跨任务缩放之间的关键权衡，为未来模型合并策略提供了见解。', 'title_zh': 'Sens-融合：敏感性引导的参数平衡以合并大型语言模型'}
{'arxiv_id': 'arXiv:2502.12418', 'title': 'Boosting Illuminant Estimation in Deep Color Constancy through Enhancing Brightness Robustness', 'authors': 'Mengda Xie, Chengzhi Zhong, Yiling He, Zhan Qin, Meie Fang', 'link': 'https://arxiv.org/abs/2502.12418', 'abstract': 'Color constancy estimates illuminant chromaticity to correct color-biased images. Recently, Deep Neural Network-driven Color Constancy (DNNCC) models have made substantial advancements. Nevertheless, the potential risks in DNNCC due to the vulnerability of deep neural networks have not yet been explored. In this paper, we conduct the first investigation into the impact of a key factor in color constancy-brightness-on DNNCC from a robustness perspective. Our evaluation reveals that several mainstream DNNCC models exhibit high sensitivity to brightness despite their focus on chromaticity estimation. This sheds light on a potential limitation of existing DNNCC models: their sensitivity to brightness may hinder performance given the widespread brightness variations in real-world datasets. From the insights of our analysis, we propose a simple yet effective brightness robustness enhancement strategy for DNNCC models, termed BRE. The core of BRE is built upon the adaptive step-size adversarial brightness augmentation technique, which identifies high-risk brightness variation and generates augmented images via explicit brightness adjustment. Subsequently, BRE develops a brightness-robustness-aware model optimization strategy that integrates adversarial brightness training and brightness contrastive loss, significantly bolstering the brightness robustness of DNNCC models. BRE is hyperparameter-free and can be integrated into existing DNNCC models, without incurring additional overhead during the testing phase. Experiments on two public color constancy datasets-ColorChecker and Cube+-demonstrate that the proposed BRE consistently enhances the illuminant estimation performance of existing DNNCC models, reducing the estimation error by an average of 5.04% across six mainstream DNNCC models, underscoring the critical role of enhancing brightness robustness in these models.', 'abstract_zh': 'brightness robustness enhancement for deep neural network-driven color constancy models', 'title_zh': '通过增强亮度鲁棒性提升深度色彩恒常性中的照明估计<table>(资料来源：用户提供的标题)</table>'}
{'arxiv_id': 'arXiv:2502.12411', 'title': 'Gradient Co-occurrence Analysis for Detecting Unsafe Prompts in Large Language Models', 'authors': 'Jingyuan Yang, Bowen Yan, Rongjun Li, Ziyu Zhou, Xin Chen, Zhiyong Feng, Wei Peng', 'link': 'https://arxiv.org/abs/2502.12411', 'abstract': "Unsafe prompts pose significant safety risks to large language models (LLMs). Existing methods for detecting unsafe prompts rely on data-driven fine-tuning to train guardrail models, necessitating significant data and computational resources. In contrast, recent few-shot gradient-based methods emerge, requiring only few safe and unsafe reference prompts. A gradient-based approach identifies unsafe prompts by analyzing consistent patterns of the gradients of safety-critical parameters in LLMs. Although effective, its restriction to directional similarity (cosine similarity) introduces ``directional bias'', limiting its capability to identify unsafe prompts. To overcome this limitation, we introduce GradCoo, a novel gradient co-occurrence analysis method that expands the scope of safety-critical parameter identification to include unsigned gradient similarity, thereby reducing the impact of ``directional bias'' and enhancing the accuracy of unsafe prompt detection. Comprehensive experiments on the widely-used benchmark datasets ToxicChat and XStest demonstrate that our proposed method can achieve state-of-the-art (SOTA) performance compared to existing methods. Moreover, we confirm the generalizability of GradCoo in detecting unsafe prompts across a range of LLM base models with various sizes and origins.", 'abstract_zh': '不安全的提示对大型语言模型（LLMs）构成显著的安全风险。现有的不安全提示检测方法依赖于数据驱动的微调来训练护栏模型，这需要大量的数据和计算资源。相比之下，最近出现的少量样本梯度基方法只需要少量的安全和不安全参考提示。基于梯度的方法通过分析安全关键参数在LLMs中的梯度模式来识别不安全的提示，尽管有效，但其对方向相似性（余弦相似性）的限制引入了“方向偏差”，限制了其识别不安全提示的能力。为克服这一限制，我们引入了GradCoo，一种新的梯度共现分析方法，扩展了识别安全关键参数的范围，包括未符号化梯度相似性，从而减少了“方向偏差”的影响，并提高了不安全提示检测的准确性。广泛的实验在广泛使用的基准数据集ToxicChat和XStest上表明，我们提出的方法在不安全提示检测方面达到了现有方法的最新水平。此外，我们证实了GradCoo在各种大小和来源的基础模型中检测不安全提示的一般性。', 'title_zh': '大型语言模型中不安全提示检测的梯度共现分析'}
{'arxiv_id': 'arXiv:2502.12398', 'title': "Solving the Cold Start Problem on One's Own as an End User via Preference Transfer", 'authors': 'Ryoma Sato', 'link': 'https://arxiv.org/abs/2502.12398', 'abstract': "We propose a new approach that enables end users to directly solve the cold start problem by themselves. The cold start problem is a common issue in recommender systems, and many methods have been proposed to address the problem on the service provider's side. However, when the service provider does not take action, users are left with poor recommendations and no means to improve their experience. We propose an algorithm, Pretender, that allows end users to proactively solve the cold start problem on their own. Pretender does not require any special support from the service provider and can be deployed independently by users. We formulate the problem as minimizing the distance between the source and target distributions and optimize item selection from the target service accordingly. Furthermore, we establish theoretical guarantees for Pretender based on a discrete quadrature problem. We conduct experiments on real-world datasets to demonstrate the effectiveness of Pretender.", 'abstract_zh': '我们提出一种新方法，使最终用户能够直接解决冷启动问题。冷启动问题是在推荐系统中常见的问题，许多方法已经提出，以在服务提供商一方解决该问题。然而，当服务提供商不采取行动时，用户将收到糟糕的推荐，而无任何手段来改善其体验。我们提出了一种名为Pretender的算法，该算法允许最终用户主动在自己一方解决冷启动问题。Pretender不需要服务提供商的特殊支持，可以独立部署由用户完成。我们将问题形式化为最小化源分布和目标分布之间的距离，并相应地优化目标服务中的项目选择。此外，我们基于离散矩量问题为Pretender建立了理论保证。我们在真实世界的数据集上进行了实验，以展示Pretender的有效性。', 'title_zh': '独自解决作为终端用户的冷启动问题通过偏好转移'}
{'arxiv_id': 'arXiv:2502.12397', 'title': 'Could AI Leapfrog the Web? Evidence from Teachers in Sierra Leone', 'authors': 'Daniel Björkegren, Jun Ho Choi, Divya Budihal, Dominic Sobhani, Oliver Garrod, Paul Atherton', 'link': 'https://arxiv.org/abs/2502.12397', 'abstract': "Access to digital information is a driver of economic development. But although 85% of sub-Saharan Africa's population is covered by mobile broadband signal, only 37% use the internet, and those who do seldom use the web. We investigate whether AI can bridge this gap by analyzing how 469 teachers use an AI chatbot in Sierra Leone. The chatbot, accessible via a common messaging app, is compared against traditional web search. Teachers use AI more frequently than web search for teaching assistance. Data cost is the most frequently cited reason for low internet usage across Africa. The average web search result consumes 3,107 times more data than an AI response, making AI 87% less expensive than web search. Additionally, only 2% of results for corresponding web searches contain content from Sierra Leone. In blinded evaluations, an independent sample of teachers rate AI responses as more relevant, helpful, and correct than web search results. These findings suggest that AI-driven solutions can cost-effectively bridge information gaps in low-connectivity regions.", 'abstract_zh': '数字信息的获取是经济增长的驱动力。尽管撒哈拉以南非洲地区85%的人口覆盖了移动宽带信号，但只有37%的人使用互联网，而且其中多数人很少上网。我们通过分析469名塞拉利昂教师如何使用AI聊天机器人来研究AI能否弥合这一差距。该聊天机器人可通过一款常用的消息应用访问，并与传统的网络搜索进行了对比。教师们比网络搜索更频繁地使用AI进行教学辅助。数据成本是非洲各地互联网使用率低频次最高的原因。平均每条网络搜索结果的数据消耗量是AI回复的3,107倍，使AI比网络搜索便宜87%。此外，针对相应网络搜索结果中仅有2%包含塞拉利昂的内容。在盲测评估中，一组独立教师样本认为AI回复比网络搜索结果更具相关性、帮助性和准确性。这些发现表明，AI驱动的解决方案可以在低连接区域成本效益地弥合信息鸿沟。', 'title_zh': 'AI能超越互联网吗？来自塞拉利昂教师的证据'}
{'arxiv_id': 'arXiv:2502.12393', 'title': 'Time Series Treatment Effects Analysis with Always-Missing Controls', 'authors': 'Juan Shu, Qiyu Han, George Chen, Xihao Cao, Kangming Luo, Dan Pallotta, Shivam Agrawal, Yuping Lu, Xiaoyu Zhang, Jawad Mansoor, Jyoti Anand', 'link': 'https://arxiv.org/abs/2502.12393', 'abstract': 'Estimating treatment effects in time series data presents a significant challenge, especially when the control group is always unobservable. For example, in analyzing the effects of Christmas on retail sales, we lack direct observation of what would have occurred in late December without the Christmas impact. To address this, we try to recover the control group in the event period while accounting for confounders and temporal dependencies. Experimental results on the M5 Walmart retail sales data demonstrate robust estimation of the potential outcome of the control group as well as accurate predicted holiday effect. Furthermore, we provided theoretical guarantees for the estimated treatment effect, proving its consistency and asymptotic normality. The proposed methodology is applicable not only to this always-missing control scenario but also in other conventional time series causal inference settings.', 'abstract_zh': '在时间序列数据中估计治疗效果存在显著挑战，特别是在控制组始终不可观测的情况下。为了应对这一挑战，我们尝试在事件期间恢复控制组，并考虑到混杂因素和时间依赖性。M5 Walmart零售销售数据的实验结果表明，该方法能够稳健地估计控制组的潜在结果以及准确预测假期效应。此外，我们提供了所估计治疗效果的理论保证，证明了其一致性与渐近正态性。所提出的方法不仅适用于控制组始终缺失的情况，还适用于其他传统的时序因果推断场景。', 'title_zh': '始终缺失的控制组时间序列治疗效应分析'}
{'arxiv_id': 'arXiv:2502.12386', 'title': 'Bridging the Data Gap in AI Reliability Research and Establishing DR-AIR, a Comprehensive Data Repository for AI Reliability', 'authors': 'Simin Zheng, Jared M. Clark, Fatemeh Salboukh, Priscila Silva, Karen da Mata, Fenglian Pan, Jie Min, Jiayi Lian, Caleb B. King, Lance Fiondella, Jian Liu, Xinwei Deng, Yili Hong', 'link': 'https://arxiv.org/abs/2502.12386', 'abstract': 'Artificial intelligence (AI) technology and systems have been advancing rapidly. However, ensuring the reliability of these systems is crucial for fostering public confidence in their use. This necessitates the modeling and analysis of reliability data specific to AI systems. A major challenge in AI reliability research, particularly for those in academia, is the lack of readily available AI reliability data. To address this gap, this paper focuses on conducting a comprehensive review of available AI reliability data and establishing DR-AIR: a data repository for AI reliability. Specifically, we introduce key measurements and data types for assessing AI reliability, along with the methodologies used to collect these data. We also provide a detailed description of the currently available datasets with illustrative examples. Furthermore, we outline the setup of the DR-AIR repository and demonstrate its practical applications. This repository provides easy access to datasets specifically curated for AI reliability research. We believe these efforts will significantly benefit the AI research community by facilitating access to valuable reliability data and promoting collaboration across various academic domains within AI. We conclude our paper with a call to action, encouraging the research community to contribute and share AI reliability data to further advance this critical field of study.', 'abstract_zh': '人工智能技术与系统正迅速发展。然而，确保这些系统的可靠性对于培养公众对其使用的信心至关重要。这需要特定于人工智能系统的可靠xing数据的建模与分析。人工智能可靠性研究中的一个主要挑战，尤其是在学术界，是可用的人工智能可靠性数据的缺乏。为了解决这一差距，本文侧重于进行全面的人工智能可靠性数据审查，并建立DR-AIR数据 repository：一个人工智能可靠性数据存储库。具体而言，我们介绍了评估人工智能可靠xing的关键测量和数据类型，以及收集这些数据的方法论。我们还详细描述了目前可用的数据集，并提供了示例。此外，我们概述了DR-AIR存储库的设置，并展示了其实际应用。该存储库为人工智能可靠性研究专门提供了便捷的数据访问。我们相信这些努力将显著惠及人工智能研究社区，通过提供有价值的可靠xing数据促进各个学术领域之间的合作。在论文结尾，我们呼吁研究界贡献并分享人工智能可靠性数据，以进一步推动这一关键领域的研究。', 'title_zh': '填补AI可靠性研究中的数据缺口并建立DR-AIR，一个全面的AI可靠性数据仓库'}
{'arxiv_id': 'arXiv:2502.12382', 'title': 'Hybrid Machine Learning Models for Intrusion Detection in IoT: Leveraging a Real-World IoT Dataset', 'authors': 'Md Ahnaf Akif, Ismail Butun, Andre Williams, Imadeldin Mahgoub', 'link': 'https://arxiv.org/abs/2502.12382', 'abstract': 'The rapid growth of the Internet of Things (IoT) has revolutionized industries, enabling unprecedented connectivity and functionality. However, this expansion also increases vulnerabilities, exposing IoT networks to increasingly sophisticated cyberattacks. Intrusion Detection Systems (IDS) are crucial for mitigating these threats, and recent advancements in Machine Learning (ML) offer promising avenues for improvement. This research explores a hybrid approach, combining several standalone ML models such as Random Forest (RF), XGBoost, K-Nearest Neighbors (KNN), and AdaBoost, in a voting-based hybrid classifier for effective IoT intrusion detection. This ensemble method leverages the strengths of individual algorithms to enhance accuracy and address challenges related to data complexity and scalability. Using the widely-cited IoT-23 dataset, a prominent benchmark in IoT cybersecurity research, we evaluate our hybrid classifiers for both binary and multi-class intrusion detection problems, ensuring a fair comparison with existing literature. Results demonstrate that our proposed hybrid models, designed for robustness and scalability, outperform standalone approaches in IoT environments. This work contributes to the development of advanced, intelligent IDS frameworks capable of addressing evolving cyber threats.', 'abstract_zh': '物联网(IoT)的快速发展已经革新了诸多行业，实现了前所未有的连接性和功能性。然而，这种扩展也增加了脆弱性，使得IoT网络面临更为复杂的 cybersecurity攻击。入侵检测系统(IDS)对于缓解这些威胁至关重要，而Recent机器学习(ML)的最新进展提供了改进的有希望的途径。本研究探索了一种混合方法，结合了独立的机器学习模型，如随机森林(RF)、XGBoost、K-最近邻(KNN)和AdaBoost，在基于投票的混合分类器中，以有效地进行IoT入侵检测。这种方法利用了单一算法的优势，以提高准确性并解决与数据复杂性和可扩展性相关的问题。使用广泛引用的IoT-23数据集，在IoT网络安全研究中的一个权威基准中，我们评估了我们的混合分类器在二元和多分类入侵检测问题上的性能，确保与现有文献进行公平比较。结果表明，本研究提出的设计稳健性和可扩展性的混合模型，在IoT环境中优于单一方法。本工作为能够应对不断演化的网络安全威胁的先进、智能IDS框架的发展做出了贡献。', 'title_zh': '物联网中入侵检测的混合机器学习模型：利用实际物联网数据集'}
{'arxiv_id': 'arXiv:2502.12373', 'title': 'Soft Robotics for Search and Rescue: Advancements, Challenges, and Future Directions', 'authors': 'Abhishek Sebastian', 'link': 'https://arxiv.org/abs/2502.12373', 'abstract': 'Soft robotics has emerged as a transformative technology in Search and Rescue (SAR) operations, addressing challenges in navigating complex, hazardous environments that often limit traditional rigid robots. This paper critically examines advancements in soft robotic technologies tailored for SAR applications, focusing on their unique capabilities in adaptability, safety, and efficiency. By leveraging bio-inspired designs, flexible materials, and advanced locomotion mechanisms, such as crawling, rolling, and shape morphing, soft robots demonstrate exceptional potential in disaster scenarios. However, significant barriers persist, including material durability, power inefficiency, sensor integration, and control complexity. This comprehensive review highlights the current state of soft robotics in SAR, discusses simulation methodologies and hardware validations, and introduces performance metrics essential for their evaluation. By bridging the gap between theoretical advancements and practical deployment, this study underscores the potential of soft robotic systems to revolutionize SAR missions and advocates for continued interdisciplinary innovation to overcome existing limitations.', 'abstract_zh': '软体机器人技术在搜救（SAR）操作中的发展及其挑战', 'title_zh': '软体机器人在搜索与救援中的进展、挑战与未来方向'}
{'arxiv_id': 'arXiv:2502.12372', 'title': 'Factual Inconsistency in Data-to-Text Generation Scales Exponentially with LLM Size: A Statistical Validation', 'authors': 'Joy Mahapatra, Soumyajit Roy, Utpal Garain', 'link': 'https://arxiv.org/abs/2502.12372', 'abstract': 'Monitoring factual inconsistency is essential for ensuring trustworthiness in data-to-text generation (D2T). While large language models (LLMs) have demonstrated exceptional performance across various D2T tasks, previous studies on scaling laws have primarily focused on generalization error through power law scaling to LLM size (i.e., the number of model parameters). However, no research has examined the impact of LLM size on factual inconsistency in D2T. In this paper, we investigate how factual inconsistency in D2T scales with LLM size by exploring two scaling laws: power law and exponential scaling. To rigorously evaluate and compare these scaling laws, we employ a statistical validation framework consisting of three key stages: predictive performance estimation, goodness-of-fit assessment, and comparative analysis. For a comprehensive empirical study, we analyze three popular LLM families across five D2T datasets, measuring factual inconsistency inversely using four state-of-the-art consistency metrics. Our findings, based on exhaustive empirical results and validated through our framework, reveal that, contrary to the widely assumed power law scaling, factual inconsistency in D2T follows an exponential scaling with LLM size.', 'abstract_zh': '监测事实不一致性对于确保数据到文本生成任务中的可信度至关重要。虽然大型语言模型在各种数据到文本生成任务中展现了卓越的性能，但以往关于规模定律的研究主要关注通过幂律 scaling 扩展语言模型大小（即模型参数数量）来泛化误差。然而，尚未有研究考察语言模型大小对数据到文本生成中的事实不一致性的影响。本文通过探索两种不同的扩展定律（幂律和指数扩展）来研究语言模型大小对数据到文本生成中事实不一致性的影响。为严格评估和比较这些扩展定律，我们采用了包含三个关键阶段的统计验证框架：预测性能估计、拟合优度评估和比较分析。为进行一项全面的经验研究，我们在五个数据到文本生成数据集中分析了三种流行的语言模型系列，并使用四种最先进的一致性度量方法逆向测量事实不一致性。根据全面的经验结果并通过我们提出的框架进行验证，我们的研究发现，与普遍认为的幂律扩展不同，数据到文本生成中的事实不一致性实际上随语言模型大小呈现指数扩展。', 'title_zh': '数据到文本生成中的事实不一致性随LLM规模呈指数增长：一项统计验证'}
{'arxiv_id': 'arXiv:2502.12371', 'title': 'IMLE Policy: Fast and Sample Efficient Visuomotor Policy Learning via Implicit Maximum Likelihood Estimation', 'authors': 'Krishan Rana, Robert Lee, David Pershouse, Niko Suenderhauf', 'link': 'https://arxiv.org/abs/2502.12371', 'abstract': 'Recent advances in imitation learning, particularly using generative modelling techniques like diffusion, have enabled policies to capture complex multi-modal action distributions. However, these methods often require large datasets and multiple inference steps for action generation, posing challenges in robotics where the cost for data collection is high and computation resources are limited. To address this, we introduce IMLE Policy, a novel behaviour cloning approach based on Implicit Maximum Likelihood Estimation (IMLE). IMLE Policy excels in low-data regimes, effectively learning from minimal demonstrations and requiring 38\\% less data on average to match the performance of baseline methods in learning complex multi-modal behaviours. Its simple generator-based architecture enables single-step action generation, improving inference speed by 97.3\\% compared to Diffusion Policy, while outperforming single-step Flow Matching. We validate our approach across diverse manipulation tasks in simulated and real-world environments, showcasing its ability to capture complex behaviours under data constraints. Videos and code are provided on our project page: this https URL.', 'abstract_zh': '最近在生成建模技术（如扩散模型）驱动的模仿学习方面的进展，使策略能够捕捉到复杂的多模态动作分布。然而，这些方法通常需要大量数据和多次推理步骤来进行动作生成，在机器人领域，数据收集成本高且计算资源有限，这带来了挑战。为了解决这个问题，我们提出了基于隐式最大似然估计（IMLE）的IMLE策略，这是一种新颖的行为克隆方法。IMLE策略在数据稀缺的情况下表现优异，能够有效地从少量示例中学习，并且平均只需要少38%的数据就能达到基线方法在学习复杂多模态行为时的性能。其基于生成器的简单架构允许一步生成动作，与扩散策略相比，将推理速度提高97.3%，同时优于一步流匹配方法。我们在模拟和真实环境中的多种操作任务中验证了该方法，展示了其在数据受限条件下捕捉复杂行为的能力。项目页面提供了相关的视频和代码：this https URL。', 'title_zh': 'IMLE策略：通过隐式最大似然估计实现快速和样本高效的空间知觉运动政策学习'}
{'arxiv_id': 'arXiv:2502.12362', 'title': 'Classifiers of Data Sharing Statements in Clinical Trial Records', 'authors': 'Saber Jelodari Mamaghani, Cosima Strantz, Dennis Toddenroth', 'link': 'https://arxiv.org/abs/2502.12362', 'abstract': 'Digital individual participant data (IPD) from clinical trials are increasingly distributed for potential scientific reuse. The identification of available IPD, however, requires interpretations of textual data-sharing statements (DSS) in large databases. Recent advancements in computational linguistics include pre-trained language models that promise to simplify the implementation of effective classifiers based on textual inputs. In a subset of 5,000 textual DSS from this http URL, we evaluate how well classifiers based on domain-specific pre-trained language models reproduce original availability categories as well as manually annotated labels. Typical metrics indicate that classifiers that predicted manual annotations outperformed those that learned to output the original availability categories. This suggests that the textual DSS descriptions contain applicable information that the availability categories do not, and that such classifiers could thus aid the automatic identification of available IPD in large trial databases.', 'abstract_zh': '临床试验的数字个体参与者数据（IPD）越来越多地被分散用于潜在的科学研究 reuse。然而，识别可用的 IPD 需要对大型数据库中的文本型数据共享声明（DSS）进行解释。近年来，计算语言学的进步包括预训练语言模型，这些模型承诺简化基于文本输入的有效分类器的实现。在从该网站获取的 5,000 个文本型 DSS 子集中，我们评估基于领域特定预训练语言模型的分类器如何准确地再现原始可用性类别以及手动标注的标签。通常使用的指标表明，预测手动标注的分类器优于学习输出原始可用性类别的分类器。这表明文本型 DSS 描述中包含适用于现有可用性类别描述的信息，并且这样的分类器可以帮助自动识别大型试验数据库中的可用 IPD。', 'title_zh': '临床试验记录中数据共享声明的分类器'}
{'arxiv_id': 'arXiv:2502.12360', 'title': 'Detecting Systematic Weaknesses in Vision Models along Predefined Human-Understandable Dimensions', 'authors': 'Sujan Sai Gannamaneni, Rohil Prakash Rao, Michael Mock, Maram Akila, Stefan Wrobel', 'link': 'https://arxiv.org/abs/2502.12360', 'abstract': 'Studying systematic weaknesses of DNNs has gained prominence in the last few years with the rising focus on building safe AI systems. Slice discovery methods (SDMs) are prominent algorithmic approaches for finding such systematic weaknesses. They identify top-k semantically coherent slices/subsets of data where a DNN-under-test has low performance. For being directly useful, e.g., as evidences in a safety argumentation, slices should be aligned with human-understandable (safety-relevant) dimensions, which, for example, are defined by safety and domain experts as parts of the operational design domain (ODD). While straightforward for structured data, the lack of semantic metadata makes these investigations challenging for unstructured data. Therefore, we propose a complete workflow which combines contemporary foundation models with algorithms for combinatorial search that consider structured data and DNN errors for finding systematic weaknesses in images. In contrast to existing approaches, ours identifies weak slices that are in line with predefined human-understandable dimensions. As the workflow includes foundation models, its intermediate and final results may not always be exact. Therefore, we build into our workflow an approach to address the impact of noisy metadata. We evaluate our approach w.r.t. its quality on four popular computer vision datasets, including autonomous driving datasets like Cityscapes, BDD100k, and RailSem19, while using multiple state-of-the-art models as DNNs-under-test.', 'abstract_zh': '研究深度神经网络系统的薄弱环节已成为热点，特别是在构建安全人工智能系统方面。切片发现方法（SDMs）是寻找此类系统薄弱环节的主要算法方法。它们识别出深度神经网络测试在其中性能较低的top-k语义一致的切片/子集。为直接用于现实场景，例如作为安全论证的证据，切片应与人类可理解（安全相关）的维度对齐，这些维度可由安全和领域专家定义为操作设计领域（ODD）的一部分。对于结构化数据而言，此类对齐较为直接，但对于非结构化数据而言，缺乏语义元数据使其更加具有挑战性。因此，我们提出了一种结合当代基础模型与组合搜索算法的完整工作流程，用于在图像中发现深度神经网络系统的系统性弱点。与现有方法不同，我们识别出与预定义的人类可理解维度一致的弱切片。由于工作流程包括基础模型，其中间和最终结果可能并不总是精确的，因此我们将其工作流程构建了处理嘈杂元数据影响的方法。我们使用多个最新模型作为深度神经网络测试，针对包括自主驾驶数据集如Cityscapes、BDD100k和RailSem19在内的四个流行计算机视觉数据集评估了该方法的质量。', 'title_zh': '基于预定义的人类可理解维度检测视觉模型的系统性弱点'}
{'arxiv_id': 'arXiv:2502.12354', 'title': 'Human-centered explanation does not fit all: The interplay of sociotechnical, cognitive, and individual factors in the effect AI explanations in algorithmic decision-making', 'authors': 'Yongsu Ahn, Yu-Run Lin, Malihe Alikhani, Eunjeong Cheon', 'link': 'https://arxiv.org/abs/2502.12354', 'abstract': 'Recent XAI studies have investigated what constitutes a \\textit{good} explanation in AI-assisted decision-making. Despite the widely accepted human-friendly properties of explanations, such as contrastive and selective, existing studies have yielded inconsistent findings. To address these gaps, our study focuses on the cognitive dimensions of explanation evaluation, by evaluating six explanations with different contrastive strategies and information selectivity and scrutinizing factors behind their valuation process. Our analysis results find that contrastive explanations are not the most preferable or understandable in general; Rather, different contrastive and selective explanations were appreciated to a different extent based on who they are, when, how, and what to explain -- with different level of cognitive load and engagement and sociotechnical contexts. Given these findings, we call for a nuanced view of explanation strategies, with implications for designing AI interfaces to accommodate individual and contextual differences in AI-assisted decision-making.', 'abstract_zh': '最近关于XAI的研究探讨了构成良好解释的要素，特别是在AI辅助决策中的解释。尽管现有的解释普遍具备人性化特性，如对比性和选择性，但现有研究结果并不一致。为了解决这些缺口，我们的研究集中在解释评估的认知维度上，通过评估六种具有不同对比策略和信息选择性的解释，并审查其评价过程背后的因素。我们的分析结果表明，对比解释通常不是最可接受或最容易理解的；相反，基于解释的对象、时间、方式和内容，不同类型的对比和选择性解释在认知负载和参与度以及社会技术背景下被评价的程度各不相同。鉴于这些发现，我们需要对解释策略采取更为细致的观点，并为AI辅助决策设计接口，以适应个体和情境差异。', 'title_zh': '以人为本的解释并不适用于所有人：社会技术、认知及个人因素在AI解释于算法决策中的作用互动'}
{'arxiv_id': 'arXiv:2502.12352', 'title': 'Towards Mechanistic Interpretability of Graph Transformers via Attention Graphs', 'authors': 'Batu El, Deepro Choudhury, Pietro Liò, Chaitanya K. Joshi', 'link': 'https://arxiv.org/abs/2502.12352', 'abstract': 'We introduce Attention Graphs, a new tool for mechanistic interpretability of Graph Neural Networks (GNNs) and Graph Transformers based on the mathematical equivalence between message passing in GNNs and the self-attention mechanism in Transformers. Attention Graphs aggregate attention matrices across Transformer layers and heads to describe how information flows among input nodes. Through experiments on homophilous and heterophilous node classification tasks, we analyze Attention Graphs from a network science perspective and find that: (1) When Graph Transformers are allowed to learn the optimal graph structure using all-to-all attention among input nodes, the Attention Graphs learned by the model do not tend to correlate with the input/original graph structure; and (2) For heterophilous graphs, different Graph Transformer variants can achieve similar performance while utilising distinct information flow patterns. Open source code: this https URL', 'abstract_zh': '我们介绍了一种基于图神经网络（GNN）和图变换器中消息传递与变换器自注意力机制数学等价性的 Attention Graphs，作为一种新的工具，用于机械解释 GNN 和图变换器的可 interpretability。通过在网络科学视角下对同质性和异质性节点分类任务的实验分析，我们发现：(1) 当允许图变换器利用输入节点之间的全连接注意力学习最优图结构时，模型学习到的 Attention Graphs 不倾向于与输入/原始图结构相关；(2) 对于异质性图，不同的图变换器变种可以在利用不同的信息流模式的同时达到相似的性能。开源代码：见链接。', 'title_zh': '通过注意力图 toward 图Transformer的机制可解释性研究'}
{'arxiv_id': 'arXiv:2502.12346', 'title': 'QuZO: Quantized Zeroth-Order Fine-Tuning for Large Language Models', 'authors': 'Jiajun Zhou, Yifan Yang, Kai Zhen, Ziyue Liu, Yequan Zhao, Ershad Banijamali, Athanasios Mouchtaris, Ngai Wong, Zheng Zhang', 'link': 'https://arxiv.org/abs/2502.12346', 'abstract': 'Language Models (LLMs) are often quantized to lower precision to reduce the memory cost and latency in inference. However, quantization often degrades model performance, thus fine-tuning is required for various down-stream tasks. Traditional fine-tuning methods such as stochastic gradient descent and Adam optimization require backpropagation, which are error-prone in the low-precision settings. To overcome these limitations, we propose the Quantized Zeroth-Order (QuZO) framework, specifically designed for fine-tuning LLMs through low-precision (e.g., 4- or 8-bit) forward passes. Our method can avoid the error-prone low-precision straight-through estimator, and utilizes optimized stochastic rounding to mitigate the increased bias. QuZO simplifies the training process, while achieving results comparable to first-order methods in ${\\rm FP}8$ and superior accuracy in ${\\rm INT}8$ and ${\\rm INT}4$ training. Experiments demonstrate that low-bit training QuZO achieves performance comparable to MeZO optimization on GLUE, Multi-Choice, and Generation tasks, while reducing memory cost by $2.94 \\times$ in LLaMA2-7B fine-tuning compared to quantized first-order methods.', 'abstract_zh': '语言模型（LLMs）常常被量化到较低精度以降低推理过程中的内存成本和延迟。然而，量化往往会降低模型性能，因此需要对各种下游任务进行微调。传统的微调方法如随机梯度下降和Adam优化需要反向传播，在低精度设置中容易出错。为克服这些限制，我们提出了Quantized Zeroth-Order（QuZO）框架，专门用于通过低精度（如4位或8位）前向传递对LLMs进行微调。该方法可以避免低精度的直接通过估计器带来的误差，并利用优化的随机四舍五入来减轻偏移增加的影响。QuZO简化了训练过程，在FP8训练中达到与一阶方法相当的结果，并在INT8和INT4训练中获得更高的准确性。实验表明，低位数训练QuZO在GLUE、多选择和生成任务上的性能与MeZO优化相当，同时在LLaMA2-7B微调中将内存成本降低3.94倍，相比之下是量化的一阶方法。', 'title_zh': 'QuZO: 量化零阶微调用于大型语言模型'}
{'arxiv_id': 'arXiv:2502.12329', 'title': 'A Novel Unified Parametric Assumption for Nonconvex Optimization', 'authors': 'Artem Riabinin, Ahmed Khaled, Peter Richtárik', 'link': 'https://arxiv.org/abs/2502.12329', 'abstract': 'Nonconvex optimization is central to modern machine learning, but the general framework of nonconvex optimization yields weak convergence guarantees that are too pessimistic compared to practice. On the other hand, while convexity enables efficient optimization, it is of limited applicability to many practical problems. To bridge this gap and better understand the practical success of optimization algorithms in nonconvex settings, we introduce a novel unified parametric assumption. Our assumption is general enough to encompass a broad class of nonconvex functions while also being specific enough to enable the derivation of a unified convergence theorem for gradient-based methods. Notably, by tuning the parameters of our assumption, we demonstrate its versatility in recovering several existing function classes as special cases and in identifying functions amenable to efficient optimization. We derive our convergence theorem for both deterministic and stochastic optimization, and conduct experiments to verify that our assumption can hold practically over optimization trajectories.', 'abstract_zh': '非凸优化是现代机器学习的核心，但非凸优化的一般框架提供的收敛保证过于悲观，与实践不符。另一方面，虽然凸性能够使优化变得更有效率，但在许多实际问题中的应用却是有限的。为了弥合这一差距并更好地理解优化算法在非凸设置下的实际成功，我们引入了一种新型的统一参数假设。该假设既足够广泛以涵盖广泛的非凸函数类，又足够具体以推导出基于梯度的方法的统一收敛定理。值得注意的是，通过调整我们假设的参数，我们展示了其在恢复多个现有函数类的特殊案例以及识别易优化函数方面的灵活性。我们为确定性和随机优化都推导了收敛定理，并进行了实验以验证我们的假设在优化轨迹上可以实际成立。', 'title_zh': '一种新型统一参数假设方法用于非凸优化'}
{'arxiv_id': 'arXiv:2502.12328', 'title': 'LM Agents for Coordinating Multi-User Information Gathering', 'authors': 'Harsh Jhamtani, Jacob Andreas, Benjamin Van Durme', 'link': 'https://arxiv.org/abs/2502.12328', 'abstract': "This paper introduces PeopleJoin, a benchmark for evaluating LM-mediated collaborative problem solving. Given a user request, PeopleJoin agents must identify teammates who might be able to assist, converse with these teammates to gather information, and finally compile a useful answer or summary for the original user. PeopleJoin comprises two evaluation domains: PeopleJoin-QA, focused on questions about tabular data, and PeopleJoin-DocCreation, focused on document creation tasks. The two domains are adapted from existing NLP benchmarks for database question answering and multi-document summarization; here, however, the information needed to complete these tasks is distributed across synthetic ``organizations'' of 2--20 users, simulating natural multi-user collaboration scenarios. We implemented several popular LM agent architectures, evaluating their accuracy and efficiency at completing tasks, and highlight new research questions that can be studied using PeopleJoin.", 'abstract_zh': 'PeopleJoin：一种评价LM介导协作问题解决能力的基准', 'title_zh': '多用户信息搜集协调的LM代理'}
{'arxiv_id': 'arXiv:2502.12327', 'title': 'Learning Plasma Dynamics and Robust Rampdown Trajectories with Predict-First Experiments at TCV', 'authors': 'Allen M. Wang, Alessandro Pau, Cristina Rea, Oswin So, Charles Dawson, Olivier Sauter, Mark D. Boyer, Anna Vu, Cristian Galperti, Chuchu Fan, Antoine Merle, Yoeri Poels, Cristina Venturini, Stefano Marchioni, TCV Team', 'link': 'https://arxiv.org/abs/2502.12327', 'abstract': "The rampdown in tokamak operations is a difficult to simulate phase during which the plasma is often pushed towards multiple instability limits. To address this challenge, and reduce the risk of disrupting operations, we leverage recent advances in Scientific Machine Learning (SciML) to develop a neural state-space model (NSSM) that predicts plasma dynamics during Tokamak à Configuration Variable (TCV) rampdowns. By integrating simple physics structure and data-driven models, the NSSM efficiently learns plasma dynamics during the rampdown from a modest dataset of 311 pulses with only five pulses in the reactor relevant high performance regime. The NSSM is parallelized across uncertainties, and reinforcement learning (RL) is applied to design trajectories that avoid multiple instability limits with high probability. Experiments at TCV ramping down high performance plasmas show statistically significant improvements in current and energy at plasma termination, with improvements in speed through continuous re-training. A predict-first experiment, increasing plasma current by 20\\% from baseline, demonstrates the NSSM's ability to make small extrapolations with sufficient accuracy to design trajectories that successfully terminate the pulse. The developed approach paves the way for designing tokamak controls with robustness to considerable uncertainty, and demonstrates the relevance of the SciML approach to learning plasma dynamics for rapidly developing robust trajectories and controls during the incremental campaigns of upcoming burning plasma tokamaks.", 'abstract_zh': '托卡马克运行减载期间等离子体动态的科学机器学习模型研究', 'title_zh': '基于预测先行实验在TCV上的等离子体动力学学习与鲁棒降功率轨迹研究'}
{'arxiv_id': 'arXiv:2502.12304', 'title': 'Warmup Generations: A Task-Agnostic Approach for Guiding Sequence-to-Sequence Learning with Unsupervised Initial State Generation', 'authors': 'Senyu Li, Zipeng Sun, Jiayi Wang, Xue Liu, Pontus Stenetorp, Siva Reddy, David Ifeoluwa Adelani', 'link': 'https://arxiv.org/abs/2502.12304', 'abstract': 'Traditional supervised fine-tuning (SFT) strategies for sequence-to-sequence tasks often train models to directly generate the target output. Recent work has shown that guiding models with intermediate steps, such as keywords, outlines, or reasoning chains, can significantly improve performance, coherence, and interpretability. However, these methods often depend on predefined intermediate formats and annotated data, limiting their scalability and generalizability. In this work, we introduce a task-agnostic framework that enables models to generate intermediate "warmup" sequences. These warmup sequences, serving as an initial state for subsequent generation, are optimized to enhance the probability of generating the target sequence without relying on external supervision or human-designed structures. Drawing inspiration from reinforcement learning principles, our method iteratively refines these intermediate steps to maximize their contribution to the final output, similar to reward-driven optimization in reinforcement learning with human feedback. Experimental results across tasks such as translation, summarization, and multi-choice question answering for logical reasoning show that our approach outperforms traditional SFT methods, and offers a scalable and flexible solution for sequence-to-sequence tasks.', 'abstract_zh': '传统的序列到序列任务的监督微调策略通常直接生成目标输出。最近的工作表明，使用中间步骤，如关键词、大纲或推理链，可以显著提高性能、连贯性和可解释性。然而，这些方法往往依赖于预定义的中间格式和标注数据，限制了它们的可扩展性和通用性。在本工作中，我们提出了一种任务无关的框架，使模型能够生成中间的“热身”序列。这些热身序列作为后续生成的初始状态，通过优化增强生成目标序列的概率，而不依赖于外部监督或人类设计的结构。受强化学习原理的启发，我们的方法迭代优化这些中间步骤，使其最大化对最终输出的贡献，类似于具有人类反馈的奖励驱动优化。在翻译、总结以及逻辑推理的多选题回答等任务上的实验结果表明，我们的方法优于传统的监督微调方法，并提供了一种适用于序列到序列任务的可扩展和灵活的解决方案。', 'title_zh': 'warmup 生成：一种任务无关的方法，用于通过无监督初始状态生成指导序列到序列学习'}
{'arxiv_id': 'arXiv:2502.12280', 'title': 'Connecting Large Language Model Agent to High Performance Computing Resource', 'authors': 'Heng Ma, Alexander Brace, Carlo Siebenschuh, Greg Pauloski, Ian Foster, Arvind Ramanathan', 'link': 'https://arxiv.org/abs/2502.12280', 'abstract': 'The Large Language Model agent workflow enables the LLM to invoke tool functions to increase the performance on specific scientific domain questions. To tackle large scale of scientific research, it requires access to computing resource and parallel computing setup. In this work, we implemented Parsl to the LangChain/LangGraph tool call setup, to bridge the gap between the LLM agent to the computing resource. Two tool call implementations were set up and tested on both local workstation and HPC environment on Polaris/ALCF. The first implementation with Parsl-enabled LangChain tool node queues the tool functions concurrently to the Parsl workers for parallel execution. The second configuration is implemented by converting the tool functions into Parsl ensemble functions, and is more suitable for large task on super computer environment. The LLM agent workflow was prompted to run molecular dynamics simulations, with different protein structure and simulation conditions. These results showed the LLM agent tools were managed and executed concurrently by Parsl on the available computing resource.', 'abstract_zh': '大规模语言模型代理工作流使LLM能够调用工具功能以提高特定科学领域问题的性能。为了应对大规模科学研究，需要访问计算资源和并行计算设置。在这项工作中，我们将Parsl集成到LangChain/LangGraph工具调用设置中，以弥合LLM代理与计算资源之间的差距。我们在Polaris/ALCF的本地工作站和高性能计算环境中设置了两种工具调用实现并进行了测试。第一种实现利用Parsl启用的LangChain工具节点将工具函数并发排队到Parsl工作者进行并行执行。第二种配置将工具函数转换为Parsl集成函数，更适合在超级计算机环境中处理大规模任务。LLM代理工作流被提示运行不同蛋白质结构和模拟条件的分子动力学模拟。这些结果表明，LLM代理工具能够在可用的计算资源上由Parsl并发管理和执行。', 'title_zh': '将大型语言模型代理连接到高性能计算资源'}
{'arxiv_id': 'arXiv:2502.12278', 'title': 'Towards Practical First-Order Model Counting', 'authors': 'Ananth K. Kidambi, Guramrit Singh, Paulius Dilkas, Kuldeep S. Meel', 'link': 'https://arxiv.org/abs/2502.12278', 'abstract': 'First-order model counting (FOMC) is the problem of counting the number of models of a sentence in first-order logic. Since lifted inference techniques rely on reductions to variants of FOMC, the design of scalable methods for FOMC has attracted attention from both theoreticians and practitioners over the past decade. Recently, a new approach based on first-order knowledge compilation was proposed. This approach, called Crane, instead of simply providing the final count, generates definitions of (possibly recursive) functions that can be evaluated with different arguments to compute the model count for any domain size. However, this approach is not fully automated, as it requires manual evaluation of the constructed functions. The primary contribution of this work is a fully automated compilation algorithm, called Gantry, which transforms the function definitions into C++ code equipped with arbitrary-precision arithmetic. These additions allow the new FOMC algorithm to scale to domain sizes over 500,000 times larger than the current state of the art, as demonstrated through experimental results.', 'abstract_zh': '基于一阶知识编译的一阶模型计数自动化编译算法', 'title_zh': '面向 practical 的一阶模型计数'}
{'arxiv_id': 'arXiv:2502.12272', 'title': 'Learning to Reason at the Frontier of Learnability', 'authors': 'Thomas Foster, Jakob Foerster', 'link': 'https://arxiv.org/abs/2502.12272', 'abstract': 'Reinforcement learning is now widely adopted as the final stage of large language model training, especially for reasoning-style tasks such as maths problems. Typically, models attempt each question many times during a single training step and attempt to learn from their successes and failures. However, we demonstrate that throughout training with two popular algorithms (PPO and VinePPO) on two widely used datasets, many questions are either solved by all attempts - meaning they are already learned - or by none - providing no meaningful training signal. To address this, we adapt a method from the reinforcement learning literature - sampling for learnability - and apply it to the reinforcement learning stage of LLM training. Our curriculum prioritises questions with high variance of success, i.e. those where the agent sometimes succeeds, but not always. Our findings demonstrate that this curriculum consistently boosts training performance across multiple algorithms and datasets, paving the way for more efficient and effective reinforcement learning in LLMs.', 'abstract_zh': '强化学习现在被广泛应用于大型语言模型训练的最终阶段，特别是在解决数学问题等推理任务中。通常，模型会在单个训练步中多次尝试每个问题，并从中学习成功的经验和失败的教训。然而，我们在使用两种流行算法（PPO和VinePPO）和两种广泛使用的数据集进行训练的过程中发现，许多问题要么每次都成功解决，意味着这些问题是已经学会的；要么每次都无法解决，无法提供有意义的训练信号。为了解决这个问题，我们借鉴了强化学习文献中的方法——可学习性采样，并将其应用于大型语言模型训练的强化学习阶段。我们的课程设置优先考虑那些成功率具有高变异性的问题，即那些有时能成功，但不总是成功的任务。我们的研究发现表明，这种课程设置能够在多个算法和数据集上持续提升训练性能，为进一步提高大型语言模型的强化学习效率和效果铺平了道路。', 'title_zh': '学习能力前沿的推理学习'}
{'arxiv_id': 'arXiv:2502.12267', 'title': 'NeuroStrata: Harnessing Neurosymbolic Paradigms for Improved Design, Testability, and Verifiability of Autonomous CPS', 'authors': 'Xi Zheng, Ziyang Li, Ivan Ruchkin, Ruzica Piskac, Miroslav Pajic', 'link': 'https://arxiv.org/abs/2502.12267', 'abstract': 'Autonomous cyber-physical systems (CPSs) leverage AI for perception, planning, and control but face trust and safety certification challenges due to inherent uncertainties. The neurosymbolic paradigm replaces stochastic layers with interpretable symbolic AI, enabling determinism. While promising, challenges like multisensor fusion, adaptability, and verification remain. This paper introduces NeuroStrata, a neurosymbolic framework to enhance the testing and verification of autonomous CPS. We outline its key components, present early results, and detail future plans.', 'abstract_zh': '自主认知物理系统（CPS）利用AI进行感知、规划和控制，但由于固有的不确定性，面临着信任和安全认证的挑战。神经符号范式用可解释的符号AI替代随机层，从而实现确定性。虽然具有前景，但仍面临多传感器融合、适应性和验证等方面的挑战。本文介绍了NeuroStrata，一个神经符号框架，用于增强自主CPS的测试和验证。我们概述了其关键组件，展示了早期结果，并详细说明了未来计划。', 'title_zh': 'NeuroStrata: 利用神经符号范式以提高自主 CPS 的设计、可测试性和可验证性'}
{'arxiv_id': 'arXiv:2502.12227', 'title': 'Identifying the Best Transition Law', 'authors': 'Mehrasa Ahmadipour, élise Crepon, Aurélien Garivier', 'link': 'https://arxiv.org/abs/2502.12227', 'abstract': "Motivated by recursive learning in Markov Decision Processes, this paper studies best-arm identification in bandit problems where each arm's reward is drawn from a multinomial distribution with a known support. We compare the performance { reached by strategies including notably LUCB without and with use of this knowledge. } In the first case, we use classical non-parametric approaches for the confidence intervals. In the second case, where a probability distribution is to be estimated, we first use classical deviation bounds (Hoeffding and Bernstein) on each dimension independently, and then the Empirical Likelihood method (EL-LUCB) on the joint probability vector. The effectiveness of these methods is demonstrated through simulations on scenarios with varying levels of structural complexity.", 'abstract_zh': '受马尔可夫决策过程中的递归学习启发，本文研究了每根杆的奖励服从具有已知支持的多项分布的臂的选择问题中的最优臂识别。我们比较了包括LUCB在内的策略性能，包括利用这种知识的情况。在第一种情况下，我们使用经典的非参数方法来构建置信区间。在第二种情况下，我们首先在每个维度上独立使用经典的偏差界（霍夫丁和伯恩斯坦），然后对联合概率向量使用经验似然方法（EL-LUCB）。这些方法的有效性通过不同结构复杂度水平的模拟场景得到了验证。', 'title_zh': '识别最佳转移定律'}
{'arxiv_id': 'arXiv:2502.12226', 'title': 'On Creating a Causally Grounded Usable Rating Method for Assessing the Robustness of Foundation Models Supporting Time Series', 'authors': 'Kausik Lakkaraju, Rachneet Kaur, Parisa Zehtabi, Sunandita Patra, Siva Likitha Valluru, Zhen Zeng, Biplav Srivastava, Marco Valtorta', 'link': 'https://arxiv.org/abs/2502.12226', 'abstract': "Foundation Models (FMs) have improved time series forecasting in various sectors, such as finance, but their vulnerability to input disturbances can hinder their adoption by stakeholders, such as investors and analysts. To address this, we propose a causally grounded rating framework to study the robustness of Foundational Models for Time Series (FMTS) with respect to input perturbations. We evaluate our approach to the stock price prediction problem, a well-studied problem with easily accessible public data, evaluating six state-of-the-art (some multi-modal) FMTS across six prominent stocks spanning three industries. The ratings proposed by our framework effectively assess the robustness of FMTS and also offer actionable insights for model selection and deployment. Within the scope of our study, we find that (1) multi-modal FMTS exhibit better robustness and accuracy compared to their uni-modal versions and, (2) FMTS pre-trained on time series forecasting task exhibit better robustness and forecasting accuracy compared to general-purpose FMTS pre-trained across diverse settings. Further, to validate our framework's usability, we conduct a user study showcasing FMTS prediction errors along with our computed ratings. The study confirmed that our ratings reduced the difficulty for users in comparing the robustness of different systems.", 'abstract_zh': '基于因果原理的评估框架：研究输入扰动下Foundational Models for Time Series的鲁棒性', 'title_zh': '基于因果 grounding 的可用地评方法以评估支持时间序列的基础模型的鲁棒性'}
{'arxiv_id': 'arXiv:2502.12225', 'title': 'Subjective Logic Encodings', 'authors': 'Jake Vasilakes', 'link': 'https://arxiv.org/abs/2502.12225', 'abstract': 'Many existing approaches for learning from labeled data assume the existence of gold-standard labels. According to these approaches, inter-annotator disagreement is seen as noise to be removed, either through refinement of annotation guidelines, label adjudication, or label filtering. However, annotator disagreement can rarely be totally eradicated, especially on more subjective tasks such as sentiment analysis or hate speech detection where disagreement is natural. Therefore, a new approach to learning from labeled data, called data perspectivism, seeks to leverage inter-annotator disagreement to learn models that stay true to the inherent uncertainty of the task by treating annotations as opinions of the annotators, rather than gold-standard facts. Despite this conceptual grounding, existing methods under data perspectivism are limited to using disagreement as the sole source of annotation uncertainty. To expand the possibilities of data perspectivism, we introduce Subjective Logic Encodings (SLEs), a flexible framework for constructing classification targets that explicitly encodes annotations as opinions of the annotators. Based on Subjective Logic Theory, SLEs encode labels as Dirichlet distributions and provide principled methods for encoding and aggregating various types of annotation uncertainty -- annotator confidence, reliability, and disagreement -- into the targets. We show that SLEs are a generalization of other types of label encodings as well as how to estimate models to predict SLEs using a distribution matching objective.', 'abstract_zh': '标签数据中的主观逻辑编码：一种利用注释员分歧进行学习的新方法', 'title_zh': '主观逻辑编码'}
{'arxiv_id': 'arXiv:2502.12222', 'title': 'IMPACTX: Improving Model Performance by Appropriately predicting CorrecT eXplanations', 'authors': 'Andrea Apicella, Salvatore Giugliano, Francesco Isgrò, Roberto Prevete', 'link': 'https://arxiv.org/abs/2502.12222', 'abstract': "The eXplainable Artificial Intelligence (XAI) research predominantly concentrates to provide explainations about AI model decisions, especially Deep Learning (DL) models. However, there is a growing interest in using XAI techniques to automatically improve the performance of the AI systems themselves.\nThis paper proposes IMPACTX, a novel approach that leverages XAI as a fully automated attention mechanism, without requiring external knowledge or human feedback. Experimental results show that IMPACTX has improved performance respect to the standalone ML model by integrating an attention mechanism based an XAI method outputs during the model training. Furthermore, IMPACTX directly provides proper feature attribution maps for the model's decisions, without relying on external XAI methods during the inference process.\nOur proposal is evaluated using three widely recognized DL models (EfficientNet-B2, MobileNet, and LeNet-5) along with three standard image datasets: CIFAR-10, CIFAR-100, and STL-10. The results show that IMPACTX consistently improves the performance of all the inspected DL models across all evaluated datasets, and it directly provides appropriate explanations for its responses.", 'abstract_zh': '可解释的人工智能（XAI）研究主要集中在提供关于AI模型决策的解释，尤其是深度学习（DL）模型。然而，越来越多的研究兴趣在于使用XAI技术自动提升AI系统的性能本身。\n\n本文提出了一种名为IMPACTX的新型方法，该方法利用XAI作为完全自动化的注意力机制，无需外部知识或人工反馈。实验结果表明，IMPACTX在通过XAI方法输出集成注意力机制进行模型训练后，相对于独立的机器学习模型具有更好的性能。此外，IMPACTX直接提供适合的特征归因图，用于模型决策，无需在推断过程中依赖外部XAI方法。\n\n该提案使用三种广泛认可的深度学习模型（EfficientNet-B2、MobileNet和LeNet-5）以及三种标准图像数据集（CIFAR-10、CIFAR-100和STL-10）进行评估。结果表明，无论在何种数据集上，IMPACTX都能一致地提高所有受检深度学习模型的性能，并直接提供适当的操作解释。', 'title_zh': 'IMPACTX: 通过适当预测正确解释来提高模型性能'}
{'arxiv_id': 'arXiv:2502.12217', 'title': 'Optimal Brain Iterative Merging: Mitigating Interference in LLM Merging', 'authors': 'Zhixiang Wang, Zhenyu Mao, Yixuan Qiao, Yunfang Wu, Biye Li', 'link': 'https://arxiv.org/abs/2502.12217', 'abstract': 'Large Language Models (LLMs) have demonstrated impressive capabilities, but their high computational costs pose challenges for customization. Model merging offers a cost-effective alternative, yet existing methods suffer from interference among parameters, leading to performance degradation. In this work, we propose Optimal Brain Iterative Merging (OBIM), a novel method designed to mitigate both intra-model and inter-model interference. OBIM consists of two key components: (1) A saliency measurement mechanism that evaluates parameter importance based on loss changes induced by individual weight alterations, reducing intra-model interference by preserving only high-saliency parameters. (2) A mutually exclusive iterative merging framework, which incrementally integrates models using a binary mask to avoid direct parameter averaging, thereby mitigating inter-model interference. We validate OBIM through experiments on both Supervised Fine-Tuned (SFT) models and post-pretrained checkpoints. The results show that OBIM significantly outperforms existing merging techniques. Overall, OBIM provides an effective and practical solution for enhancing LLM merging.', 'abstract_zh': '大型语言模型（LLMs）展示了令人印象深刻的能力，但其高昂的计算成本带来了定制化的挑战。模型合并提供了一种成本效益高的替代方案，然而现有方法中存在的参数干扰导致性能下降。在这项工作中，我们提出了最优大脑迭代合并（OBIM），这是一种设计用于缓解模型内的参数干扰和模型间干扰的新方法。OBIM 包含两个关键组件：（1）一个显著性测度机制，该机制基于单个权重改变引起的损失变化评估参数的重要性，通过保留高显著性参数来减少模型内的干扰。（2）一个互斥的迭代合并框架，该框架使用二进制掩码逐步整合模型，从而避免直接的参数平均，进而减少模型间干扰。我们通过在监督微调（SFT）模型和后预训练检查点上的实验验证了 OBIM 的有效性。结果显示，OBIM 显著优于现有合并技术。总体而言，OBIM 提供了一个有效且实用的解决方案，用于增强 LLM 合并。', 'title_zh': '最优脑迭代合并：减轻LLM合并中的干扰'}
{'arxiv_id': 'arXiv:2502.12216', 'title': 'Tactic: Adaptive Sparse Attention with Clustering and Distribution Fitting for Long-Context LLMs', 'authors': 'Kan Zhu, Tian Tang, Qinyu Xu, Yile Gu, Zhichen Zeng, Rohan Kadekodi, Liangyu Zhao, Ang Li, Arvind Krishnamurthy, Baris Kasikci', 'link': 'https://arxiv.org/abs/2502.12216', 'abstract': 'Long-context models are essential for many applications but face inefficiencies in loading large KV caches during decoding. Prior methods enforce fixed token budgets for sparse attention, assuming a set number of tokens can approximate full attention. However, these methods overlook variations in the importance of attention across heads, layers, and contexts. To address these limitations, we propose Tactic, a sparsity-adaptive and calibration-free sparse attention mechanism that dynamically selects tokens based on their cumulative attention scores rather than a fixed token budget. By setting a target fraction of total attention scores, Tactic ensures that token selection naturally adapts to variations in attention sparsity. To efficiently approximate this selection, Tactic leverages clustering-based sorting and distribution fitting, allowing it to accurately estimate token importance with minimal computational overhead. We show that Tactic outperforms existing sparse attention algorithms, achieving superior accuracy and up to 7.29x decode attention speedup. This improvement translates to an overall 1.58x end-to-end inference speedup, making Tactic a practical and effective solution for long-context LLM inference in accuracy-sensitive applications.', 'abstract_zh': '长上下文模型对于许多应用至关重要，但在解码过程中面临着加载大型KV缓存的效率问题。此前的方法强制执行固定tokens预算的稀疏注意机制，假设一定数量的tokens可以近似全注意。然而，这些方法忽略了注意在头、层和上下文之间的重要性变化。为了解决这些限制，我们提出了Tactic，一种自适应稀疏注意机制，能够根据tokens的累积注意分数动态选择tokens，而不是固定tokens预算。通过设置总注意分数的目标比例，Tactic确保tokens选择能够自然适应注意稀疏性的变化。为了高效地近似这种选择，Tactic利用基于聚类的排序和分布拟合，能够以最小的计算开销准确估计token的重要性。实验结果表明，Tactic优于现有稀疏注意算法，实现了更高的准确性和高达7.29倍的解码注意加速。这种改进转化为整体1.58倍的端到端推理加速，使Tactic成为在准确性敏感应用中进行长上下文LLM推理的实用且有效的解决方案。', 'title_zh': '策略: 用于长上下文LLM的自适应稀疏注意机制、聚类与分布拟合'}
{'arxiv_id': 'arXiv:2502.12215', 'title': 'Revisiting the Test-Time Scaling of o1-like Models: Do they Truly Possess Test-Time Scaling Capabilities?', 'authors': 'Zhiyuan Zeng, Qinyuan Cheng, Zhangyue Yin, Yunhua Zhou, Xipeng Qiu', 'link': 'https://arxiv.org/abs/2502.12215', 'abstract': "The advent of test-time scaling in large language models (LLMs), exemplified by OpenAI's o1 series, has advanced reasoning capabilities by scaling computational resource allocation during inference. While successors like QwQ, Deepseek-R1 (R1) and LIMO replicate these advancements, whether these models truly possess test-time scaling capabilities remains underexplored. This study found that longer CoTs of these o1-like models do not consistently enhance accuracy; in fact, correct solutions are often shorter than incorrect ones for the same questions. Further investigation shows this phenomenon is closely related to models' self-revision capabilities - longer CoTs contain more self-revisions, which often lead to performance degradation. We then compare sequential and parallel scaling strategies on QwQ, R1 and LIMO, finding that parallel scaling achieves better coverage and scalability. Based on these insights, we propose Shortest Majority Vote, a method that combines parallel scaling strategies with CoT length characteristics, significantly improving models' test-time scalability compared to conventional majority voting approaches.", 'abstract_zh': '大语言模型（LLMs）测试时缩放的出现及其应用：OpenAI o1系列的示例，通过在推理过程中扩展计算资源分配提升了推理能力。尽管后续模型如QwQ、Deepseek-R1 (R1) 和 LIMO 复现了这些进步，但这些模型是否真正具备测试时缩放能力仍待进一步探索。本研究发现，这些类似o1的模型更长的中间步骤（CoT）并不一致地提升准确性；事实上，对于相同的提问，正确答案往往比错误答案更短。进一步的研究表明，这一现象与模型的自我修订能力密切相关——更长的中间步骤包含更多的自我修订，而这往往导致性能下降。我们还对比了QwQ、R1和LIMO上顺序和并行缩放策略，发现并行缩放策略在覆盖率和可扩展性上更优。基于这些见解，我们提出了一种名为“最短多数投票”的方法，该方法结合了并行缩放策略和中间步骤长度的特点，显著提高了模型的测试时可缩放性，优于传统的多数投票方法。', 'title_zh': '重访o1-like模型的测试时缩放能力：它们真的具备测试时缩放能力吗？'}
{'arxiv_id': 'arXiv:2502.12214', 'title': 'Zero Token-Driven Deep Thinking in LLMs: Unlocking the Full Potential of Existing Parameters via Cyclic Refinement', 'authors': 'Guanghao Li, Wenhao Jiang, Li Shen, Ming Tang, Chun Yuan', 'link': 'https://arxiv.org/abs/2502.12214', 'abstract': "Resource limitations often constrain the parameter counts of Large Language Models (LLMs), hindering their performance. While existing methods employ parameter sharing to reuse the same parameter set under fixed budgets, such approaches typically force each layer to assume multiple roles with a predetermined number of iterations, restricting efficiency and adaptability. In this work, we propose the Zero Token Transformer (ZTT), which features a head-tail decoupled parameter cycling method. We disentangle the first (head) and last (tail) layers from parameter cycling and iteratively refine only the intermediate layers. Furthermore, we introduce a Zero-Token Mechanism, an internal architectural component rather than an input token, to guide layer-specific computation. At each cycle, the model retrieves a zero token (with trainable key values) from a Zero-Token Pool, integrating it alongside regular tokens in the attention mechanism. The corresponding attention scores not only reflect each layer's computational importance but also enable dynamic early exits without sacrificing overall model accuracy. Our approach achieves superior performance under tight parameter budgets, effectively reduces computational overhead via early exits, and can be readily applied to fine-tune existing pre-trained models for enhanced efficiency and adaptability.", 'abstract_zh': '零令牌变换器：一种头部-尾部解耦的参数循环方法及其应用', 'title_zh': '零令牌驱动的深度思考在LLMs中的实现：通过循环精炼解锁现有参数的全部潜力'}
{'arxiv_id': 'arXiv:2502.12213', 'title': 'Spatiotemporal-aware Trend-Seasonality Decomposition Network for Traffic Flow Forecasting', 'authors': 'Lingxiao Cao, Bin Wang, Guiyuan Jiang, Yanwei Yu, Junyu Dong', 'link': 'https://arxiv.org/abs/2502.12213', 'abstract': 'Traffic prediction is critical for optimizing travel scheduling and enhancing public safety, yet the complex spatial and temporal dynamics within traffic data present significant challenges for accurate forecasting. In this paper, we introduce a novel model, the Spatiotemporal-aware Trend-Seasonality Decomposition Network (STDN). This model begins by constructing a dynamic graph structure to represent traffic flow and incorporates novel spatio-temporal embeddings to jointly capture global traffic dynamics. The representations learned are further refined by a specially designed trend-seasonality decomposition module, which disentangles the trend-cyclical component and seasonal component for each traffic node at different times within the graph. These components are subsequently processed through an encoder-decoder network to generate the final predictions. Extensive experiments conducted on real-world traffic datasets demonstrate that STDN achieves superior performance with remarkable computation cost. Furthermore, we have released a new traffic dataset named JiNan, which features unique inner-city dynamics, thereby enriching the scenario comprehensiveness in traffic prediction evaluation.', 'abstract_zh': '时空感知趋势-季节性分解网络（STDN）：面向真实交通数据的高效预测', 'title_zh': '空间时间aware趋势-季节性分解网络用于交通流量预测'}
{'arxiv_id': 'arXiv:2502.12210', 'title': 'Enhancing Frame Detection with Retrieval Augmented Generation', 'authors': 'Papa Abdou Karim Karou Diallo, Amal Zouaq', 'link': 'https://arxiv.org/abs/2502.12210', 'abstract': 'Recent advancements in Natural Language Processing have significantly improved the extraction of structured semantic representations from unstructured text, especially through Frame Semantic Role Labeling (FSRL). Despite this progress, the potential of Retrieval-Augmented Generation (RAG) models for frame detection remains under-explored. In this paper, we present the first RAG-based approach for frame detection called RCIF (Retrieve Candidates and Identify Frames). RCIF is also the first approach to operate without the need for explicit target span and comprises three main stages: (1) generation of frame embeddings from various representations ; (2) retrieval of candidate frames given an input text; and (3) identification of the most suitable frames. We conducted extensive experiments across multiple configurations, including zero-shot, few-shot, and fine-tuning settings. Our results show that our retrieval component significantly reduces the complexity of the task by narrowing the search space thus allowing the frame identifier to refine and complete the set of candidates. Our approach achieves state-of-the-art performance on FrameNet 1.5 and 1.7, demonstrating its robustness in scenarios where only raw text is provided. Furthermore, we leverage the structured representation obtained through this method as a proxy to enhance generalization across lexical variations in the task of translating natural language questions into SPARQL queries.', 'abstract_zh': 'Recent advancements in Natural Language Processing have significantly improved the extraction of structured semantic representations from unstructured text, especially through Frame Semantic Role Labeling (FSRL). Despite this progress, the potential of Retrieval-Augmented Generation (RAG) models for frame detection remains under-explored. In this paper, we present the first RAG-based approach for frame detection called RCIF (Retrieve Candidates and Identify Frames). RCIF is also the first approach to operate without the need for explicit target span and comprises three main stages: (1) generation of frame embeddings from various representations; (2) retrieval of candidate frames given an input text; and (3) identification of the most suitable frames. We conducted extensive experiments across multiple configurations, including zero-shot, few-shot, and fine-tuning settings. Our results show that our retrieval component significantly reduces the complexity of the task by narrowing the search space thus allowing the frame identifier to refine and complete the set of candidates. Our approach achieves state-of-the-art performance on FrameNet 1.5 and 1.7, demonstrating its robustness in scenarios where only raw text is provided. Furthermore, we leverage the structured representation obtained through this method as a proxy to enhance generalization across lexical variations in the task of translating natural language questions into SPARQL queries.', 'title_zh': '增强帧检测的检索增强生成'}
{'arxiv_id': 'arXiv:2502.12209', 'title': 'Suboptimal Shapley Value Explanations', 'authors': 'Xiaolei Lu', 'link': 'https://arxiv.org/abs/2502.12209', 'abstract': "Deep Neural Networks (DNNs) have demonstrated strong capacity in supporting a wide variety of applications. Shapley value has emerged as a prominent tool to analyze feature importance to help people understand the inference process of deep neural models. Computing Shapley value function requires choosing a baseline to represent feature's missingness. However, existing random and conditional baselines could negatively influence the explanation. In this paper, by analyzing the suboptimality of different baselines, we identify the problematic baseline where the asymmetric interaction between $\\bm{x}'_i$ (the replacement of the faithful influential feature) and other features has significant directional bias toward the model's output, and conclude that $p(y|\\bm{x}'_i) = p(y)$ potentially minimizes the asymmetric interaction involving $\\bm{x}'_i$. We further generalize the uninformativeness of $\\bm{x}'_i$ toward the label space $L$ to avoid estimating $p(y)$ and design a simple uncertainty-based reweighting mechanism to accelerate the computation process. We conduct experiments on various NLP tasks and our quantitative analysis demonstrates the effectiveness of the proposed uncertainty-based reweighting mechanism. Furthermore, by measuring the consistency of explanations generated by explainable methods and human, we highlight the disparity between model inference and human understanding.", 'abstract_zh': "深层神经网络（DNNs）在支持多种应用方面展现了强大的能力。Shapley值已经成为分析特征重要性、帮助人们理解深度神经模型推理过程的重要工具。计算Shapley值需要选择一个基准来代表特征的缺失性。然而，现有的随机和条件基准可能会负面影响解释的效果。在本文中，通过对不同基准的亚最优性进行分析，我们识别出了一个有问题的基准，在该基准中，替代理性影响特征$\\bm{x}'_i$与其他特征之间的不对称交互具有显著的方向性偏差指向模型的输出，并得出结论认为$p(y|\\bm{x}'_i) = p(y)$可能最小化涉及$\\bm{x}'_i$的不对称交互。我们进一步将$\\bm{x}'_i$不对特征空间$L$提供信息推广为避免估算$p(y)$的方式，并设计了一个简单的基于不确定性加权机制来加速计算过程。我们在多种NLP任务上进行了实验，定量分析表明所提出基于不确定性的加权机制的有效性。此外，通过衡量可解释方法生成的解释与人类的一致性，我们突显了模型推理与人类理解之间的差异。", 'title_zh': '次优Shapley值解释'}
{'arxiv_id': 'arXiv:2502.12207', 'title': 'PAR-AdvGAN: Improving Adversarial Attack Capability with Progressive Auto-Regression AdvGAN', 'authors': 'Jiayu Zhang, Zhiyu Zhu, Xinyi Wang, Silin Liao, Zhibo Jin, Flora D. Salim, Huaming Chen', 'link': 'https://arxiv.org/abs/2502.12207', 'abstract': 'Deep neural networks have demonstrated remarkable performance across various domains. However, they are vulnerable to adversarial examples, which can lead to erroneous predictions. Generative Adversarial Networks (GANs) can leverage the generators and discriminators model to quickly produce high-quality adversarial examples. Since both modules train in a competitive and simultaneous manner, GAN-based algorithms like AdvGAN can generate adversarial examples with better transferability compared to traditional methods. However, the generation of perturbations is usually limited to a single iteration, preventing these examples from fully exploiting the potential of the methods. To tackle this issue, we introduce a novel approach named Progressive Auto-Regression AdvGAN (PAR-AdvGAN). It incorporates an auto-regressive iteration mechanism within a progressive generation network to craft adversarial examples with enhanced attack capability. We thoroughly evaluate our PAR-AdvGAN method with a large-scale experiment, demonstrating its superior performance over various state-of-the-art black-box adversarial attacks, as well as the original this http URL, PAR-AdvGAN significantly accelerates the adversarial example generation, i.e., achieving the speeds of up to 335.5 frames per second on Inception-v3 model, outperforming the gradient-based transferable attack algorithms. Our code is available at: this https URL', 'abstract_zh': '深度神经网络在各个领域都展现出了卓越的性能。然而，它们对对抗样本尤为脆弱，可能导致错误的预测。生成式对抗网络（GANs）可以通过生成器和判别器模型快速生成高质量的对抗样本。由于两个模块以竞争性和同步性的方式进行训练，基于GAN的算法如AdvGAN能够生成具有更好迁移性的对抗样本，相较于传统方法。然而，扰动的生成通常局限于单次迭代，这限制了这些样本充分发挥方法的潜力。为解决这一问题，我们提出了一种名为渐进自回归AdvGAN（PAR-AdvGAN）的新方法。该方法在渐进生成网络中引入了自回归迭代机制，以生成具有增强攻击能力的对抗样本。我们通过大规模实验全面评估了我们的PAR-AdvGAN方法，表明其在各种最新的黑盒对抗攻击方法中具有优越的性能，同时显著加速了对抗样本的生成，如Inception-v3模型的生成速度可达每秒335.5帧，超越基于梯度的可移植攻击算法。我们的代码可在以下链接获取：this https URL。', 'title_zh': 'PAR-AdvGAN: 逐步自回归AdvGAN以提高对抗攻击能力'}
{'arxiv_id': 'arXiv:2502.12204', 'title': 'Predicting Depression in Screening Interviews from Interactive Multi-Theme Collaboration', 'authors': 'Xianbing Zhao, Yiqing Lyu, Di Wang, Buzhou Tang', 'link': 'https://arxiv.org/abs/2502.12204', 'abstract': 'Automatic depression detection provides cues for early clinical intervention by clinicians. Clinical interviews for depression detection involve dialogues centered around multiple themes. Existing studies primarily design end-to-end neural network models to capture the hierarchical structure of clinical interview dialogues. However, these methods exhibit defects in modeling the thematic content of clinical interviews: 1) they fail to capture intra-theme and inter-theme correlation explicitly, and 2) they do not allow clinicians to intervene and focus on themes of interest. To address these issues, this paper introduces an interactive depression detection framework. This framework leverages in-context learning techniques to identify themes in clinical interviews and then models both intra-theme and inter-theme correlation. Additionally, it employs AI-driven feedback to simulate the interests of clinicians, enabling interactive adjustment of theme importance. PDIMC achieves absolute improvements of 35\\% and 12\\% compared to the state-of-the-art on the depression detection dataset DAIC-WOZ, which demonstrates the effectiveness of modeling theme correlation and incorporating interactive external feedback.', 'abstract_zh': '自动抑郁检测为临床早期干预提供线索：一种交互式抑郁检测框架', 'title_zh': '基于互动多主题合作的抑郁筛查访谈中抑郁预测'}
{'arxiv_id': 'arXiv:2502.12203', 'title': 'An Interpretable Automated Mechanism Design Framework with Large Language Models', 'authors': 'Jiayuan Liu, Mingyu Guo, Vincent Conitzer', 'link': 'https://arxiv.org/abs/2502.12203', 'abstract': 'Mechanism design has long been a cornerstone of economic theory, with traditional approaches relying on mathematical derivations. Recently, automated approaches, including differentiable economics with neural networks, have emerged for designing payments and allocations. While both analytical and automated methods have advanced the field, they each face significant weaknesses: mathematical derivations are not automated and often struggle to scale to complex problems, while automated and especially neural-network-based approaches suffer from limited interpretability. To address these challenges, we introduce a novel framework that reformulates mechanism design as a code generation task. Using large language models (LLMs), we generate heuristic mechanisms described in code and evolve them to optimize over some evaluation metrics while ensuring key design criteria (e.g., strategy-proofness) through a problem-specific fixing process. This fixing process ensures any mechanism violating the design criteria is adjusted to satisfy them, albeit with some trade-offs in performance metrics. These trade-offs are factored in during the LLM-based evolution process. The code generation capabilities of LLMs enable the discovery of novel and interpretable solutions, bridging the symbolic logic of mechanism design and the generative power of modern AI. Through rigorous experimentation, we demonstrate that LLM-generated mechanisms achieve competitive performance while offering greater interpretability compared to previous approaches. Notably, our framework can rediscover existing manually designed mechanisms and provide insights into neural-network based solutions through Programming-by-Example. These results highlight the potential of LLMs to not only automate but also enhance the transparency and scalability of mechanism design, ensuring safe deployment of the mechanisms in society.', 'abstract_zh': '机制设计-long一直是经济理论的基石，传统方法依赖于数学推导。近年来，包括神经网络在内的可微经济方法新兴用于设计支付和分配。虽然分析方法和自动化方法都推动了该领域的进展，但各自都面临重大挑战：数学推导方法缺乏自动化，且难以扩展到复杂问题，而自动化尤其是基于神经网络的方法则在可解释性方面受到限制。为应对这些挑战，我们提出了一种新型框架，将机制设计重新表述为代码生成任务。利用大型语言模型（LLMs），我们生成描述在代码中的启发式机制，并通过特定问题的调整过程优化某些评估指标，同时确保关键设计标准（例如， truthful机制性）。该调整过程确保任何违反设计标准的机制被调整以满足这些标准，尽管在某些性能指标上可能存在权衡。这些权衡会在LLM驱动的进化过程中加以考虑。LLMs的代码生成能力使发现新颖且可解释的解决方案成为可能，将机制设计的符号逻辑与现代AI的生成能力相结合。通过严格的实验，我们证明LLM生成的机制在性能上具有竞争力，同时比之前的方法更具可解释性。值得注意的是，我们的框架可以重新发现已手动设计的机制，并通过示例编程为基于神经网络的解决方案提供见解。这些结果突显了LLMs不仅能够自动化，还可以增强机制设计的透明性和可扩展性，确保机制在社会中的安全部署。', 'title_zh': '一种具有解释性的自动化机制设计框架——大型语言模型的应用'}
{'arxiv_id': 'arXiv:2502.12202', 'title': 'BoT: Breaking Long Thought Processes of o1-like Large Language Models through Backdoor Attack', 'authors': 'Zihao Zhu, Hongbao Zhang, Mingda Zhang, Ruotong Wang, Guanzong Wu, Ke Xu, Baoyuan Wu', 'link': 'https://arxiv.org/abs/2502.12202', 'abstract': 'Longer thought, better performance: large language models with deep reasoning capabilities, particularly o1-like models, have demonstrated remarkable performance by generating extensive thought processes during inference. This trade-off reveals a potential vulnerability: adversaries could compromise model performance by forcing immediate responses without thought processes. To this end, in this paper, we introduce a novel attack scenario targeting the long thought processes of o1-like models and propose BoT (Break CoT), which can selectively break intrinsic reasoning mechanisms through backdoor attacks. BoT constructs poisoned datasets with designed triggers and injects backdoor by either supervised fine-tuning or direct preference optimization. When triggered, the model directly generates answers without thought processes, while maintaining normal reasoning capabilities for clean inputs. Extensive experiments on open-source o1-like models, including recent DeepSeek-R1, demonstrate that BoT nearly achieves high attack success rates while maintaining clean accuracy, highlighting the critical safety risk in current models. Furthermore, the relationship between task difficulty and helpfulness reveals a potential application for good, enabling users to customize model behavior based on task complexity. Code is available at \\href{this https URL}{this https URL}.', 'abstract_zh': '更深入思考，更好 performance：具有深度推理能力的大语言模型，特别是 o1 类模型，在推断过程中生成 extensive 思考过程时表现出卓越的性能。这一权衡揭示了一个潜在的安全性弱点：攻击者可以通过迫使模型立即响应而无需思考过程来削弱模型性能。基于此，本文提出了一种新的攻击场景，针对 o1 类模型的 long thought 过程，并提出了一种新型攻击方法 BoT（Break CoT），该方法可以通过后门攻击选择性地破坏内在的推理机制。BoT 通过设计触发器构造受污染的数据集，并通过监督微调或直接偏好优化注入后门。当受到触发时，模型将直接生成答案而无需思考过程，但对干净的输入保持正常的推理能力。在开源 o1 类模型上的广泛实验，包括最近的 DeepSeek-R1，证实 BoT 几乎实现了高攻击成功率，同时保持了干净的准确性，突显了当前模型中的关键安全风险。此外，任务难度与帮助度之间的关系揭示了一种潜在的应用场景，允许用户根据任务复杂性自定义模型行为。代码可在 \\href{this https URL}{this https URL} 获取。', 'title_zh': 'BoT: 通过后门攻击打破o1-like大型语言模型的长思考过程'}
{'arxiv_id': 'arXiv:2502.12200', 'title': 'Efficient and Effective Prompt Tuning via Prompt Decomposition and Compressed Outer Product', 'authors': 'Pengxiang Lan, Haoyu Xu, Enneng Yang, Yuliang Liang, Guibing Guo, Jianzhe Zhao, Xingwei Wang', 'link': 'https://arxiv.org/abs/2502.12200', 'abstract': "Prompt tuning (PT) offers a cost-effective alternative to fine-tuning large-scale pre-trained language models (PLMs), requiring only a few parameters in soft prompt tokens added before the input text. However, existing PT approaches face two significant issues: (i) They overlook intrinsic semantic associations between soft prompt tokens, leading to high discreteness and limited interactions, thus reducing the model's comprehension and effectiveness in complex tasks. (ii) Due to the complexity of downstream tasks, long soft prompt is necessitated to improve performance, but prompt length correlates positively with memory usage and computational costs. Achieving high efficiency and performance remains an ongoing challenge. To address these issues, we propose a novel Low-parameters prompt tuning (LAMP) method, which leverages prompt decomposition and compressed outer product. Specifically, the prompt decomposition module employs Truncated SVD to reduce training parameters and significantly lower the dimensionality of the soft prompt parameter space. It then utilizes a compressed outer product module to facilitate multiple interactions among prompt tokens, exploring their intrinsic associations to enhance knowledge representation. Finally, LAMP uses average pooling to reduce memory usage and training/inference time. Extensive experiments across six architectures and eight datasets demonstrate that LAMP outperforms state-of-the-art PT-based and LoRA-based methods in performance and efficiency.", 'abstract_zh': '低参数提示调谐：基于提示分解和压缩外积的方法（LAMP）', 'title_zh': '基于提示分解和压缩外积的高效且有效的提示调优'}
{'arxiv_id': 'arXiv:2502.12198', 'title': 'Maximize Your Diffusion: A Study into Reward Maximization and Alignment for Diffusion-based Control', 'authors': 'Dom Huh, Prasant Mohapatra', 'link': 'https://arxiv.org/abs/2502.12198', 'abstract': 'Diffusion-based planning, learning, and control methods present a promising branch of powerful and expressive decision-making solutions. Given the growing interest, such methods have undergone numerous refinements over the past years. However, despite these advancements, existing methods are limited in their investigations regarding general methods for reward maximization within the decision-making process. In this work, we study extensions of fine-tuning approaches for control applications. Specifically, we explore extensions and various design choices for four fine-tuning approaches: reward alignment through reinforcement learning, direct preference optimization, supervised fine-tuning, and cascading diffusion. We optimize their usage to merge these independent efforts into one unified paradigm. We show the utility of such propositions in offline RL settings and demonstrate empirical improvements over a rich array of control tasks.', 'abstract_zh': '基于扩散的方法在决策规划、学习和控制中的扩展研究', 'title_zh': '最大化扩散效应：基于奖励最大化和对齐的研究'}
{'arxiv_id': 'arXiv:2502.12197', 'title': 'A Closer Look at System Prompt Robustness', 'authors': 'Norman Mu, Jonathan Lu, Michael Lavery, David Wagner', 'link': 'https://arxiv.org/abs/2502.12197', 'abstract': "System prompts have emerged as a critical control surface for specifying the behavior of LLMs in chat and agent settings. Developers depend on system prompts to specify important context, output format, personalities, guardrails, content policies, and safety countermeasures, all of which require models to robustly adhere to the system prompt, especially when facing conflicting or adversarial user inputs. In practice, models often forget to consider relevant guardrails or fail to resolve conflicting demands between the system and the user. In this work, we study various methods for improving system prompt robustness by creating realistic new evaluation and fine-tuning datasets based on prompts collected from from OpenAI's GPT Store and HuggingFace's HuggingChat. Our experiments assessing models with a panel of new and existing benchmarks show that performance can be considerably improved with realistic fine-tuning data, as well as inference-time interventions such as classifier-free guidance. Finally, we analyze the results of recently released reasoning models from OpenAI and DeepSeek, which show exciting but uneven improvements on the benchmarks we study. Overall, current techniques fall short of ensuring system prompt robustness and further study is warranted.", 'abstract_zh': '系统提示已成为指定聊天和代理环境中LLM行为的关键控制面。开发人员依赖系统提示来指定重要背景、输出格式、个性、护栏、内容政策和安全对策，所有这些都需要模型在面对冲突或 adversarial 用户输入时能稳健地遵循系统提示。实际上，模型往往会忽略相关护栏，或无法解决系统与用户之间的冲突需求。在这项工作中，我们通过基于从OpenAI的GPT Store和HuggingFace的HuggingChat收集的提示创建现实的新评估和微调数据集，研究了各种提高系统提示稳健性的方法。我们的实验使用新的和现有的基准测试面板评估模型表明，借助现实的微调数据以及推断时的干预措施（如无分类引导），性能可以显著提高。最后，我们分析了最近由OpenAI和DeepSeek发布的推理模型的结果，这些结果显示了在我们研究的基准测试中令人兴奋但不均匀的改进。总体而言，当前的技术尚不足以确保系统提示的稳健性，需要进一步的研究。', 'title_zh': '系统提示稳健性进一步探究'}
{'arxiv_id': 'arXiv:2502.12193', 'title': "AI and the Law: Evaluating ChatGPT's Performance in Legal Classification", 'authors': 'Pawel Weichbroth', 'link': 'https://arxiv.org/abs/2502.12193', 'abstract': 'The use of ChatGPT to analyze and classify evidence in criminal proceedings has been a topic of ongoing discussion. However, to the best of our knowledge, this issue has not been studied in the context of the Polish language. This study addresses this research gap by evaluating the effectiveness of ChatGPT in classifying legal cases under the Polish Penal Code. The results show excellent binary classification accuracy, with all positive and negative cases correctly categorized. In addition, a qualitative evaluation confirms that the legal basis provided for each case, along with the relevant legal content, was appropriate. The results obtained suggest that ChatGPT can effectively analyze and classify evidence while applying the appropriate legal rules. In conclusion, ChatGPT has the potential to assist interested parties in the analysis of evidence and serve as a valuable legal resource for individuals with less experience or knowledge in this area.', 'abstract_zh': 'ChatGPT在分析和分类刑事诉讼证据中的应用研究：以波兰法律为视角', 'title_zh': 'AI与法律：评估ChatGPT在法律分类中的表现'}
{'arxiv_id': 'arXiv:2502.12189', 'title': 'Self-supervised Attribute-aware Dynamic Preference Ranking Alignment', 'authors': 'Hongyu Yang, Qi Zhao, Zhenhua hu, Rui Li', 'link': 'https://arxiv.org/abs/2502.12189', 'abstract': 'Reinforcement Learning from Human Feedback and its variants excel in aligning with human intentions to generate helpful, harmless, and honest responses. However, most of them rely on costly human-annotated pairwise comparisons for supervised alignment, which is not suitable for list-level scenarios, such as community question answering. Additionally, human preferences are influenced by multiple intrinsic factors in responses, leading to decision-making inconsistencies. Therefore, we propose \\textbf{Se}lf-supervised \\textbf{A}ttribute-aware \\textbf{d}ynamic \\textbf{p}reference \\textbf{ra}nking, called \\shortname. \\ It quantifies preference differences between responses based on Attribute-Perceptual Distance Factors (APDF) and dynamically determines the list-wise alignment order. Furthermore, it achieves fine-grained preference difference learning and enables precise alignment with the optimal one. We specifically constructed a challenging code preference dataset named StaCoCoQA, and introduced more cost-effective and scalable preference evaluation metrics: PrefHit and PrefRecall. Extensive experimental results show that SeAdpra exhibits superior performance and generalizability on both StaCoCoQA and preference datasets from eight popular domains.', 'abstract_zh': '自我监督属性感知动态偏好排序：SeAdpra及其在人类反馈强化学习中的应用', 'title_zh': '自我监督的属性感知动态偏好排序对齐'}
{'arxiv_id': 'arXiv:2502.12188', 'title': 'Boosting Generalization in Diffusion-Based Neural Combinatorial Solver via Energy-guided Sampling', 'authors': 'Haoyu Lei, Kaiwen Zhou, Yinchuan Li, Zhitang Chen, Farzan Farnia', 'link': 'https://arxiv.org/abs/2502.12188', 'abstract': 'Diffusion-based Neural Combinatorial Optimization (NCO) has demonstrated effectiveness in solving NP-complete (NPC) problems by learning discrete diffusion models for solution generation, eliminating hand-crafted domain knowledge. Despite their success, existing NCO methods face significant challenges in both cross-scale and cross-problem generalization, and high training costs compared to traditional solvers. While recent studies have introduced training-free guidance approaches that leverage pre-defined guidance functions for zero-shot conditional generation, such methodologies have not been extensively explored in combinatorial optimization. To bridge this gap, we propose a general energy-guided sampling framework during inference time that enhances both the cross-scale and cross-problem generalization capabilities of diffusion-based NCO solvers without requiring additional training. We provide theoretical analysis that helps understanding the cross-problem transfer capability. Our experimental results demonstrate that a diffusion solver, trained exclusively on the Traveling Salesman Problem (TSP), can achieve competitive zero-shot solution generation on TSP variants, such as Prize Collecting TSP (PCTSP) and the Orienteering Problem (OP), through energy-guided sampling across different problem scales.', 'abstract_zh': '基于扩散的神经组合优化（NCO）通过学习离散扩散模型来生成解决方案，证明了在解决NP完全（NPC）问题时的有效性，无需手工构建领域知识。尽管取得了成功，现有的NCO方法在跨尺度和跨问题泛化方面仍面临重大挑战，并且与传统求解器相比，训练成本较高。虽然近期的研究引入了无需训练的引导方法，利用预定义的引导函数进行零样本条件生成，但此类方法在组合优化中的应用尚未得到广泛探索。为弥补这一空白，我们提出了一种在推理时能源引导采样框架，该框架在无需额外训练的情况下增强基于扩散的NCO求解器的跨尺度和跨问题泛化能力。我们提供了理论分析，有助于理解跨问题迁移能力。实验结果表明，仅在旅行商问题（TSP）上训练的扩散求解器，可以通过跨不同问题规模的能源引导采样实现Prize Collecting TSP（PCTSP）和旅者问题（OP）上具有竞争力的零样本解决方案生成。', 'title_zh': '基于能量导向采样的扩散型神经组合求解器泛化能力增强方法'}
{'arxiv_id': 'arXiv:2502.12186', 'title': 'E2CB2former: Effecitve and Explainable Transformer for CB2 Receptor Ligand Activity Prediction', 'authors': 'Jiacheng Xie, Yingrui Ji, Linghuan Zeng, Xi Xiao, Gaofei Chen, Lijing Zhu, Joyanta Jyoti Mondal, Jiansheng Chen', 'link': 'https://arxiv.org/abs/2502.12186', 'abstract': "Accurate prediction of CB2 receptor ligand activity is pivotal for advancing drug discovery targeting this receptor, which is implicated in inflammation, pain management, and neurodegenerative conditions. Although conventional machine learning and deep learning techniques have shown promise, their limited interpretability remains a significant barrier to rational drug design. In this work, we introduce CB2former, a framework that combines a Graph Convolutional Network with a Transformer architecture to predict CB2 receptor ligand activity. By leveraging the Transformer's self attention mechanism alongside the GCN's structural learning capability, CB2former not only enhances predictive performance but also offers insights into the molecular features underlying receptor activity. We benchmark CB2former against diverse baseline models including Random Forest, Support Vector Machine, K Nearest Neighbors, Gradient Boosting, Extreme Gradient Boosting, Multilayer Perceptron, Convolutional Neural Network, and Recurrent Neural Network and demonstrate its superior performance with an R squared of 0.685, an RMSE of 0.675, and an AUC of 0.940. Moreover, attention weight analysis reveals key molecular substructures influencing CB2 receptor activity, underscoring the model's potential as an interpretable AI tool for drug discovery. This ability to pinpoint critical molecular motifs can streamline virtual screening, guide lead optimization, and expedite therapeutic development. Overall, our results showcase the transformative potential of advanced AI approaches exemplified by CB2former in delivering both accurate predictions and actionable molecular insights, thus fostering interdisciplinary collaboration and innovation in drug discovery.", 'abstract_zh': '准确预测CB2受体配体活性对于针对该受体的药物发现具有重要意义，CB2受体与炎症、疼痛管理和神经退行性疾病有关。尽管传统的机器学习和深度学习技术显示出了希望，但它们的解释性限制仍然是合理药物设计的一个重大障碍。在本研究中，我们引入了CB2former，这是一种将图卷积网络与Transformer架构结合的框架，用于预测CB2受体配体活性。通过利用Transformer的自注意力机制和GCN的结构学习能力，CB2former不仅能提升预测性能，还能揭示受体活性背后的分子特征。我们将CB2former与随机森林、支持向量机、K近邻、梯度提升、极端梯度提升、多层感知机、卷积神经网络和递归神经网络等不同基准模型进行对比，并展示其优越性能，其中R平方值为0.685，均方根误差为0.675，AUC为0.940。此外，注意力权重分析揭示了关键的分子亚结构对CB2受体活性的影响，表明该模型具有作为药物发现中可解释AI工具的潜力。能够准确定位关键分子模式的能力可以简化虚拟筛选，指导先导化合物的优化，加速治疗性药物的开发。总的来说，我们的结果展示了CB2former等先进AI方法在提供准确预测和可操作的分子洞察方面的变革潜力，从而促进药物发现领域的跨学科合作与创新。', 'title_zh': 'E2CB2former: 有效可解释的变换器模型用于CB2受体配体活性预测'}
{'arxiv_id': 'arXiv:2502.12185', 'title': 'Large Language Models for Extrapolative Modeling of Manufacturing Processes', 'authors': 'Kiarash Naghavi Khanghah, Anandkumar Patel, Rajiv Malhotra, Hongyi Xu', 'link': 'https://arxiv.org/abs/2502.12185', 'abstract': 'Conventional predictive modeling of parametric relationships in manufacturing processes is limited by the subjectivity of human expertise and intuition on the one hand and by the cost and time of experimental data generation on the other hand. This work addresses this issue by establishing a new Large Language Model (LLM) framework. The novelty lies in combining automatic extraction of process-relevant knowledge embedded in the literature with iterative model refinement based on a small amount of experimental data. This approach is evaluated on three distinct manufacturing processes that are based on machining, deformation, and additive principles. The results show that for the same small experimental data budget the models derived by our framework have unexpectedly high extrapolative performance, often surpassing the capabilities of conventional Machine Learning. Further, our approach eliminates manual generation of initial models or expertise-dependent interpretation of the literature. The results also reveal the importance of the nature of the knowledge extracted from the literature and the significance of both the knowledge extraction and model refinement components.', 'abstract_zh': '传统的制造过程参数关系预测建模受限于人类专业知识和直觉的主观性以及实验数据生成的高成本和长周期。本研究通过建立一个新的大型语言模型（LLM）框架来解决这一问题。其创新点在于结合了从文献中自动提取与制造过程相关知识，并基于少量实验数据进行迭代模型优化。该方法在基于加工、变形和增材原理的三个不同制造过程中进行了评估。结果表明，在相同的少量实验数据预算下，由框架构建的模型表现出意外的外推性能，常常超越传统机器学习的能力。此外，该方法消除了手工生成初始模型或依赖专业知识解释文献的步骤。研究结果还揭示了从文献中提取的知识性质以及知识提取和模型优化两个方面的重要性。', 'title_zh': '大型语言模型在制造过程外推性建模中的应用'}
{'arxiv_id': 'arXiv:2502.12182', 'title': 'Towards Transparent and Accurate Plasma State Monitoring at JET', 'authors': 'Andrin Bürli, Alessandro Pau, Thomas Koller, Olivier Sauter, JET Contributors', 'link': 'https://arxiv.org/abs/2502.12182', 'abstract': "Controlling and monitoring plasma within a tokamak device is complex and challenging. Plasma off-normal events, such as disruptions, are hindering steady-state operation. For large devices, they can even endanger the machine's integrity and it represents in general one of the most serious concerns for the exploitation of the tokamak concept for future power plants. Effective plasma state monitoring carries the potential to enable an understanding of such phenomena and their evolution which is crucial for the successful operation of tokamaks. This paper presents the application of a transparent and data-driven methodology to monitor the plasma state in a tokamak. Compared to previous studies in the field, supervised and unsupervised learning techniques are combined. The dataset consisted of 520 expert-validated discharges from JET. The goal was to provide an interpretable plasma state representation for the JET operational space by leveraging multi-task learning for the first time in the context of plasma state monitoring. When evaluated as disruption predictors, a sequence-based approach showed significant improvements compared to the state-based models. The best resulting network achieved a promising cross-validated success rate when combined with a physical indicator and accounting for nearby instabilities. Qualitative evaluations of the learned latent space uncovered operational and disruptive regions as well as patterns related to learned dynamics and global feature importance. The applied methodology provides novel possibilities for the definition of triggers to switch between different control scenarios, data analysis, and learning as well as exploring latent dynamics for plasma state monitoring. It also showed promising quantitative and qualitative results with warning times suitable for avoidance purposes and distributions that are consistent with known physical mechanisms.", 'abstract_zh': '基于透明和数据驱动方法的托卡马克等离子体状态监控应用', 'title_zh': '向JET等离子体状态透明且准确监测迈进'}
{'arxiv_id': 'arXiv:2502.12181', 'title': '3D ReX: Causal Explanations in 3D Neuroimaging Classification', 'authors': 'Melane Navaratnarajah, Sophie A. Martin, David A. Kelly, Nathan Blake, Hana Chocker', 'link': 'https://arxiv.org/abs/2502.12181', 'abstract': "Explainability remains a significant problem for AI models in medical imaging, making it challenging for clinicians to trust AI-driven predictions. We introduce 3D ReX, the first causality-based post-hoc explainability tool for 3D models. 3D ReX uses the theory of actual causality to generate responsibility maps which highlight the regions most crucial to the model's decision. We test 3D ReX on a stroke detection model, providing insight into the spatial distribution of features relevant to stroke.", 'abstract_zh': '医学成像中的人工智能模型可解释性依然存在显著问题，使得临床医生难以信任基于人工智能的预测。我们引入了3D ReX，这是一种基于因果性的后验可解释性工具，适用于3D模型。3D ReX 使用实际因果理论生成责任图，突出显示对模型决策至关重要的区域。我们以中风检测模型为测试对象，揭示了与中风相关的空间特征分布。', 'title_zh': '3D ReX: 3D神经 Imaging 分类中的因果解释'}
{'arxiv_id': 'arXiv:2502.12180', 'title': 'ClusMFL: A Cluster-Enhanced Framework for Modality-Incomplete Multimodal Federated Learning in Brain Imaging Analysis', 'authors': 'Xinpeng Wang, Rong Zhou, Han Xie, Xiaoying Tang, Lifang He, Carl Yang', 'link': 'https://arxiv.org/abs/2502.12180', 'abstract': "Multimodal Federated Learning (MFL) has emerged as a promising approach for collaboratively training multimodal models across distributed clients, particularly in healthcare domains. In the context of brain imaging analysis, modality incompleteness presents a significant challenge, where some institutions may lack specific imaging modalities (e.g., PET, MRI, or CT) due to privacy concerns, device limitations, or data availability issues. While existing work typically assumes modality completeness or oversimplifies missing-modality scenarios, we simulate a more realistic setting by considering both client-level and instance-level modality incompleteness in this study. Building on this realistic simulation, we propose ClusMFL, a novel MFL framework that leverages feature clustering for cross-institutional brain imaging analysis under modality incompleteness. Specifically, ClusMFL utilizes the FINCH algorithm to construct a pool of cluster centers for the feature embeddings of each modality-label pair, effectively capturing fine-grained data distributions. These cluster centers are then used for feature alignment within each modality through supervised contrastive learning, while also acting as proxies for missing modalities, allowing cross-modal knowledge transfer. Furthermore, ClusMFL employs a modality-aware aggregation strategy, further enhancing the model's performance in scenarios with severe modality incompleteness. We evaluate the proposed framework on the ADNI dataset, utilizing structural MRI and PET scans. Extensive experimental results demonstrate that ClusMFL achieves state-of-the-art performance compared to various baseline methods across varying levels of modality incompleteness, providing a scalable solution for cross-institutional brain imaging analysis.", 'abstract_zh': '多模态联邦学习（MFL）已成为在分布式客户端跨域协作训练多模态模型的有前途的方法，特别是在医疗保健领域。在脑成像分析的背景下，模态不完整提出了一项重大挑战，一些机构可能由于隐私问题、设备限制或数据可用性问题缺少特定的成像模态（如PET、MRI或CT）。虽然现有工作通常假设模态完整性或过度简化缺失模态的情况，本研究通过考虑客户端级别和实例级别模态不完整性来模拟更现实的场景。在此现实模拟的基础上，我们提出了一种新颖的ClusMFL框架，该框架利用特征聚类在模态不完整的情况下进行跨机构脑成像分析。具体而言，ClusMFL利用FINCH算法为每个模态-标签对构建特征嵌入的聚类中心池，有效捕获了细粒度的数据分布。这些聚类中心随后通过监督对比学习在每个模态内进行特征对齐，并作为缺失模态的代理，使跨模态知识转移成为可能。此外，ClusMFL采用模态感知的聚合策略，进一步增强模型在严重模态不完整情况下的性能。我们使用ADNI数据集评估了所提出的框架，该数据集利用了结构MRI和PET扫描。广泛的实验结果表明，ClusMFL在不同程度的模态不完整情况下均取得了最先进的性能，为跨机构脑成像分析提供了可扩展的解决方案。', 'title_zh': 'ClusMFL：一种用于脑成像分析的模态不全多模态联邦学习聚类增强框架'}
{'arxiv_id': 'arXiv:2502.12179', 'title': 'Identifiable Steering via Sparse Autoencoding of Multi-Concept Shifts', 'authors': 'Shruti Joshi, Andrea Dittadi, Sébastien Lachapelle, Dhanya Sridhar', 'link': 'https://arxiv.org/abs/2502.12179', 'abstract': 'Steering methods manipulate the representations of large language models (LLMs) to induce responses that have desired properties, e.g., truthfulness, offering a promising approach for LLM alignment without the need for fine-tuning. Traditionally, steering has relied on supervision, such as from contrastive pairs of prompts that vary in a single target concept, which is costly to obtain and limits the speed of steering research. An appealing alternative is to use unsupervised approaches such as sparse autoencoders (SAEs) to map LLM embeddings to sparse representations that capture human-interpretable concepts. However, without further assumptions, SAEs may not be identifiable: they could learn latent dimensions that entangle multiple concepts, leading to unintentional steering of unrelated properties. We introduce Sparse Shift Autoencoders (SSAEs) that instead map the differences between embeddings to sparse representations. Crucially, we show that SSAEs are identifiable from paired observations that vary in \\textit{multiple unknown concepts}, leading to accurate steering of single concepts without the need for supervision. We empirically demonstrate accurate steering across semi-synthetic and real-world language datasets using Llama-3.1 embeddings.', 'abstract_zh': 'Sparse Shift Autoencoders操纵大语言模型的表示以诱导具有 desired 属性的响应，为无需微调的大语言模型对齐提供了有 promise 的方法。传统上，操纵依赖于监督，例如在单一目标概念上变化的对比提示对，但这种方式成本高且限制了操纵研究的速度。一种令人振奋的替代方案是使用稀疏自动编码器（SAEs）将大语言模型嵌入映射到稀疏表示，以捕捉可由人类理解的概念。然而，在不做进一步假设的情况下，SAEs 可能是不可识别的：它们可能会学习互相关概念的潜在维度，导致无意中操纵无关的属性。我们引入了稀疏偏移自动编码器（SSAEs），它们将嵌入之间的差异映射到稀疏表示。关键的是，我们证明了当配对观察在多个未知概念上变化时，SSAEs 是可识别的，从而能够在无需监督的情况下准确地操纵单个概念。我们使用 Llama-3.1 嵌入在半合成和真实世界语言数据集上 empirically 证明了准确的操纵。', 'title_zh': '基于多概念转移的稀疏自编码可识别转向'}
{'arxiv_id': 'arXiv:2502.12176', 'title': 'Ten Challenging Problems in Federated Foundation Models', 'authors': 'Tao Fan, Hanlin Gu, Xuemei Cao, Chee Seng Chan, Qian Chen, Yiqiang Chen, Yihui Feng, Yang Gu, Jiaxiang Geng, Bing Luo, Shuoling Liu, Win Kent Ong, Chao Ren, Jiaqi Shao, Chuan Sun, Xiaoli Tang, Hong Xi Tae, Yongxin Tong, Shuyue Wei, Fan Wu, Wei Xi, Mingcong Xu, He Yang, Xin Yang, Jiangpeng Yan, Hao Yu, Han Yu, Teng Zhang, Yifei Zhang, Xiaojin Zhang, Zhenzhe Zheng, Lixin Fan, Qiang Yang', 'link': 'https://arxiv.org/abs/2502.12176', 'abstract': 'Federated Foundation Models (FedFMs) represent a distributed learning paradigm that fuses general competences of foundation models as well as privacy-preserving capabilities of federated learning. This combination allows the large foundation models and the small local domain models at the remote clients to learn from each other in a teacher-student learning setting. This paper provides a comprehensive summary of the ten challenging problems inherent in FedFMs, encompassing foundational theory, utilization of private data, continual learning, unlearning, Non-IID and graph data, bidirectional knowledge transfer, incentive mechanism design, game mechanism design, model watermarking, and efficiency. The ten challenging problems manifest in five pivotal aspects: ``Foundational Theory," which aims to establish a coherent and unifying theoretical framework for FedFMs. ``Data," addressing the difficulties in leveraging domain-specific knowledge from private data while maintaining privacy; ``Heterogeneity," examining variations in data, model, and computational resources across clients; ``Security and Privacy," focusing on defenses against malicious attacks and model theft; and ``Efficiency," highlighting the need for improvements in training, communication, and parameter efficiency. For each problem, we offer a clear mathematical definition on the objective function, analyze existing methods, and discuss the key challenges and potential solutions. This in-depth exploration aims to advance the theoretical foundations of FedFMs, guide practical implementations, and inspire future research to overcome these obstacles, thereby enabling the robust, efficient, and privacy-preserving FedFMs in various real-world applications.', 'abstract_zh': '联邦基础模型（FedFMs）代表了一种分布式学习范式，融合了基础模型的一般能力和联邦学习的隐私保护能力。这种结合使得大型基础模型和远程客户端的小规模本地领域模型能够在教师-学生学习设置中相互学习。本文全面总结了FedFMs内在的十个挑战性问题，涵盖了基础理论、私有数据利用、持续学习、遗忘、非IID和图数据、双向知识迁移、激励机制设计、博弈机制设计、模型水印以及效率等方面。这十个挑战性问题在五个关键方面得到体现：“基础理论”，旨在为FedFMs建立一个协调和统一的理论框架；“数据”，解决在利用私有数据中的领域特定知识时保持隐私的难题；“异质性”，考察客户端在数据、模型和计算资源方面的差异；“安全与隐私”，关注抵御恶意攻击和模型盗窃的防御措施；“效率”，强调在训练、通信和参数效率方面的改进。对于每个问题，我们提供了清晰的数学定义，分析现有方法，并讨论关键挑战和潜在解决方案。这种深入探索旨在推动FedFMs的理论基础发展，指导实际实施，并激发未来研究以克服这些障碍，从而实现各种实际应用场景下的稳健、高效和隐私保护的FedFMs。', 'title_zh': '联邦基础模型中的十个挑战性问题'}
{'arxiv_id': 'arXiv:2502.12175', 'title': 'Spatiotemporal Graph Neural Networks in short term load forecasting: Does adding Graph Structure in Consumption Data Improve Predictions?', 'authors': 'Quoc Viet Nguyen, Joaquin Delgado Fernandez, Sergio Potenciano Menci', 'link': 'https://arxiv.org/abs/2502.12175', 'abstract': 'Short term Load Forecasting (STLF) plays an important role in traditional and modern power systems. Most STLF models predominantly exploit temporal dependencies from historical data to predict future consumption. Nowadays, with the widespread deployment of smart meters, their data can contain spatiotemporal dependencies. In particular, their consumption data is not only correlated to historical values but also to the values of neighboring smart meters. This new characteristic motivates researchers to explore and experiment with new models that can effectively integrate spatiotemporal interrelations to increase forecasting performance. Spatiotemporal Graph Neural Networks (STGNNs) can leverage such interrelations by modeling relationships between smart meters as a graph and using these relationships as additional features to predict future energy consumption. While extensively studied in other spatiotemporal forecasting domains such as traffic, environments, or renewable energy generation, their application to load forecasting remains relatively unexplored, particularly in scenarios where the graph structure is not inherently available. This paper overviews the current literature focusing on STGNNs with application in STLF. Additionally, from a technical perspective, it also benchmarks selected STGNN models for STLF at the residential and aggregate levels. The results indicate that incorporating graph features can improve forecasting accuracy at the residential level; however, this effect is not reflected at the aggregate level', 'abstract_zh': '短期负荷预测（STLF）在传统和现代电力系统中发挥着重要作用。大多数STLF模型主要通过历史数据的时间依赖性来预测未来的消费需求。随着智能电表的广泛应用，其数据可能包含时空依赖性，特别是其用电数据不仅与历史值相关，还与相邻智能电表的值相关。这种新特性激发了研究人员探索并试验能够有效整合时空相互关系的新模型，以提高预测性能。时空图神经网络（STGNN）可以通过将智能电表的关系建模为图，并利用这些关系作为额外特征来预测未来的能源消耗，从而利用这些相互关系。尽管STGNN在交通、环境或可再生能源生成等其他时空预测领域受到了广泛研究，但在负荷预测中的应用仍然相对未被探索，特别是在图结构本身不可用的情况下。本文综述了现有的关于应用于STLF的STGNN的相关文献。从技术层面来看，本文还对选定的STGNN模型在住宅和汇总层面的STLF进行了基准测试。结果显示，在住宅层面引入图特征可以提高预测准确性；但在汇总层面，这种效果并未显现。', 'title_zh': '时空图神经网络在短期负荷预测中的应用：在消费数据中加入图结构能改善预测吗？'}
{'arxiv_id': 'arXiv:2502.12173', 'title': 'nanoML for Human Activity Recognition', 'authors': 'Alan T. L. Bacellar, Mugdha P. Jadhao, Shashank Nag, Priscila M. V. Lima, Felipe M. G. Franca, Lizy K. John', 'link': 'https://arxiv.org/abs/2502.12173', 'abstract': 'Human Activity Recognition (HAR) is critical for applications in healthcare, fitness, and IoT, but deploying accurate models on resource-constrained devices remains challenging due to high energy and memory demands. This paper demonstrates the application of Differentiable Weightless Neural Networks (DWNs) to HAR, achieving competitive accuracies of 96.34% and 96.67% while consuming only 56nJ and 104nJ per sample, with an inference time of just 5ns per sample. The DWNs were implemented and evaluated on an FPGA, showcasing their practical feasibility for energy-efficient hardware deployment. DWNs achieve up to 926,000x energy savings and 260x memory reduction compared to state-of-the-art deep learning methods. These results position DWNs as a nano-machine learning nanoML model for HAR, setting a new benchmark in energy efficiency and compactness for edge and wearable devices, paving the way for ultra-efficient edge AI.', 'abstract_zh': 'Differentiable Weightless Neural Networks for Energy-Efficient Human Activity Recognition', 'title_zh': 'nanoML在人体活动识别中的应用'}
{'arxiv_id': 'arXiv:2502.12171', 'title': 'GoRA: Gradient-driven Adaptive Low Rank Adaptation', 'authors': 'Haonan He, Peng Ye, Yuchen Ren, Yuan Yuan, Lei Chen', 'link': 'https://arxiv.org/abs/2502.12171', 'abstract': "Low-Rank Adaptation (LoRA) is a crucial method for efficiently fine-tuning pretrained large language models (LLMs), with its performance largely influenced by two key factors: rank and initialization strategy. Numerous LoRA variants have been proposed to enhance its performance by addressing these factors. However, these variants often compromise LoRA's usability or efficiency. In this paper, we analyze the fundamental limitations of existing methods and introduce a novel approach, GoRA (Gradient-driven Adaptive Low Rank Adaptation), which adaptively assigns ranks and initializes weights for low-rank adapters simultaneously based on gradient information. Extensive experimental results demonstrate that GoRA significantly improves performance while preserving the high usability and efficiency of LoRA. On the T5 model fine-tuned for the GLUE benchmark, GoRA achieves a 5.88-point improvement over LoRA and slightly surpasses full fine-tuning. Similarly, on the Llama3.1-8B-Base model fine-tuned for GSM8k tasks, GoRA outperforms LoRA with a 5.13-point improvement and exceeds full fine-tuning in high-rank settings by a margin of 2.05 points.", 'abstract_zh': '基于梯度的自适应低秩适应 (GoRA): 同时基于梯度信息自适应分配秩和初始化权重以提升预训练大型语言模型的高效微调Performance Improvement of Low-Rank Adaptation (LoRA) via Gradient-driven Adaptive Low Rank Adaptation (GoRA): Simultaneous Adaptive Rank Assignment and Weight Initialization Based on Gradient Information', 'title_zh': 'GoRA: 梯度驱动的自适应低秩适应'}
{'arxiv_id': 'arXiv:2502.12170', 'title': 'MUDDFormer: Breaking Residual Bottlenecks in Transformers via Multiway Dynamic Dense Connections', 'authors': 'Da Xiao, Qingye Meng, Shengping Li, Xingyuan Yuan', 'link': 'https://arxiv.org/abs/2502.12170', 'abstract': 'We propose MUltiway Dynamic Dense (MUDD) connections, a simple yet effective method to address the limitations of residual connections and enhance cross-layer information flow in Transformers. Unlike existing dense connection approaches with static and shared connection weights, MUDD generates connection weights dynamically depending on hidden states at each sequence position and for each decoupled input stream (the query, key, value or residual) of a Transformer block. MUDD connections can be seamlessly integrated into any Transformer architecture to create MUDDFormer. Extensive experiments show that MUDDFormer significantly outperforms Transformers across various model architectures and scales in language modeling, achieving the performance of Transformers trained with 1.8X-2.4X compute. Notably, MUDDPythia-2.8B matches Pythia-6.9B in pretraining ppl and downstream tasks and even rivals Pythia-12B in five-shot settings, while adding only 0.23% parameters and 0.4% computation. Code in JAX and PyTorch and pre-trained models are available at this https URL .', 'abstract_zh': '我们提出了一种简单而有效的多路动态密集（MUDD）连接方法，以解决残差连接的局限性并增强Transformer中的跨层信息流动。MUDD连接可以根据Transformer块中每个序列位置和每个解耦输入流（查询、键、值或残差）的隐藏状态动态生成连接权重，不同于现有具有静态和共享连接权重的密集连接方法。MUDD连接可以无缝集成到任何Transformer架构中，创建MUDDFormer。广泛实验表明，MUDDFormer在各种模型架构和规模的语言建模中显著优于Transformer，实现相当于使用1.8至2.4倍计算量训练的Transformer的性能。值得注意的是，在预训练语言建模和下游任务中，MUDDPythia-2.8B与Pythia-6.9B性能相同，并且在五 shot 设置下甚至与Pythia-12B相当，同时仅增加0.23%的参数量和0.4%的计算量。JAX和PyTorch代码及预训练模型可在以下链接获取。', 'title_zh': 'MUDDFormer: 通过多向动态密集连接打破残差瓶颈的变压器'}
{'arxiv_id': 'arXiv:2502.12167', 'title': 'TastepepAI, An artificial intelligence platform for taste peptide de novo design', 'authors': 'Jianda Yue, Tingting Li, Jian Ouyang, Jiawei Xu, Hua Tan, Zihui Chen, Changsheng Han, Huanyu Li, Songping Liang, Zhonghua Liu, Zhonghua Liu, Ying Wang', 'link': 'https://arxiv.org/abs/2502.12167', 'abstract': 'Taste peptides have emerged as promising natural flavoring agents attributed to their unique organoleptic properties, high safety profile, and potential health benefits. However, the de novo identification of taste peptides derived from animal, plant, or microbial sources remains a time-consuming and resource-intensive process, significantly impeding their widespread application in the food industry. Here, we present TastePepAI, a comprehensive artificial intelligence framework for customized taste peptide design and safety assessment. As the key element of this framework, a loss-supervised adaptive variational autoencoder (LA-VAE) is implemented to efficiently optimizes the latent representation of sequences during training and facilitates the generation of target peptides with desired taste profiles. Notably, our model incorporates a novel taste-avoidance mechanism, allowing for selective flavor exclusion. Subsequently, our in-house developed toxicity prediction algorithm (SpepToxPred) is integrated in the framework to undergo rigorous safety evaluation of generated peptides. Using this integrated platform, we successfully identified 73 peptides exhibiting sweet, salty, and umami, significantly expanding the current repertoire of taste peptides. This work demonstrates the potential of TastePepAI in accelerating taste peptide discovery for food applications and provides a versatile framework adaptable to broader peptide engineering challenges.', 'abstract_zh': '味肽作为一种因其独特的感官特性、高安全性概况和潜在健康益处而被视为有前景的天然调味剂，已逐渐受到关注。然而，从动物、植物或微生物源中鉴定新的味肽仍是一个耗时且资源密集的过程，严重阻碍了其在食品工业中的广泛应用。为此，我们提出了一种全面的人工智能框架——TastePepAI，用于定制化味肽设计和安全性评估。作为该框架的关键组成部分，我们实现了一种损失监督自适应变分自动编码器（LA-VAE），以在训练期间高效优化序列的潜在表示，并促进生成具有特定味觉轮廓的目标肽。值得注意的是，我们的模型集成了一个新颖的味觉回避机制，允许选择性地排除特定风味。随后，我们自主研发的毒性预测算法（SpepToxPred）被整合到该框架中，用于对生成的肽进行严格的安全性评估。通过该集成平台，我们成功鉴定了73种具有甜、咸、鲜味特征的肽，显著扩展了现有味肽的范围。本研究展示了TastePepAI在加速食品应用中味肽发现方面的潜力，并提供了一种广泛适应于肽工程挑战的多功能框架。', 'title_zh': 'TastepepAI，一种用于味肽从头设计的人工智能平台'}
{'arxiv_id': 'arXiv:2502.12161', 'title': 'Integrating Artificial Intelligence and Geophysical Insights for Earthquake Forecasting: A Cross-Disciplinary Review', 'authors': 'Zhang Ying, Wen Congcong, Sornette Didier, Zhan Chengxiang', 'link': 'https://arxiv.org/abs/2502.12161', 'abstract': 'Earthquake forecasting remains a significant scientific challenge, with current methods falling short of achieving the performance necessary for meaningful societal benefits. Traditional models, primarily based on past seismicity and geomechanical data, struggle to capture the complexity of seismic patterns and often overlook valuable non-seismic precursors such as geophysical, geochemical, and atmospheric anomalies. The integration of such diverse data sources into forecasting models, combined with advancements in AI technologies, offers a promising path forward. AI methods, particularly deep learning, excel at processing complex, large-scale datasets, identifying subtle patterns, and handling multidimensional relationships, making them well-suited for overcoming the limitations of conventional approaches.\nThis review highlights the importance of combining AI with geophysical knowledge to create robust, physics-informed forecasting models. It explores current AI methods, input data types, loss functions, and practical considerations for model development, offering guidance to both geophysicists and AI researchers. While many AI-based studies oversimplify earthquake prediction, neglecting critical features such as data imbalance and spatio-temporal clustering, the integration of specialized geophysical insights into AI models can address these shortcomings.\nWe emphasize the importance of interdisciplinary collaboration, urging geophysicists to experiment with AI architectures thoughtfully and encouraging AI experts to deepen their understanding of seismology. By bridging these disciplines, we can develop more accurate, reliable, and societally impactful earthquake forecasting tools.', 'abstract_zh': '地震预测仍然是一个重大的科学挑战，现有方法尚未达到实现有意义社会收益所需的效果。传统模型主要基于过去的地震活动和地质力学数据，难以捕捉地震模式的复杂性，往往忽视了诸如地球物理、地球化学和大气异常等有价值的非地震前兆信号。将如此多样的数据源整合到预测模型中，并结合AI技术的进步，为解决这一挑战提供了有希望的途径。特别是深度学习方法，擅长处理复杂的、大规模的数据集，识别细微的模式，并处理多维度关系，使它们适合克服传统方法的局限性。\n本文强调了将AI与地球物理知识相结合以构建健壮、符合物理原理的预测模型的重要性。它探讨了当前的AI方法、输入数据类型、损失函数，并提供了模型开发的实际考量，为地球物理学家和AI研究人员提供了指导。尽管许多基于AI的研究简化了地震预测，忽视了数据不平衡和时空聚集等关键特征，将专门的地球物理洞见融入AI模型可以解决这些问题。\n我们强调跨学科合作的重要性，敦促地球物理学家明智地尝试AI架构，并鼓励AI专家加深对地震学的理解。通过这些学科的交叉融合，我们可以开发出更准确、更可靠并更具社会影响力的地震预测工具。', 'title_zh': '将人工智能与地质物理洞察整合于地震预测：一门跨学科综述'}
{'arxiv_id': 'arXiv:2502.12158', 'title': 'Mining Social Determinants of Health for Heart Failure Patient 30-Day Readmission via Large Language Model', 'authors': 'Mingchen Shao, Youjeong Kang, Xiao Hu, Hyunjung Gloria Kwak, Carl Yang, Jiaying Lu', 'link': 'https://arxiv.org/abs/2502.12158', 'abstract': 'Heart Failure (HF) affects millions of Americans and leads to high readmission rates, posing significant healthcare challenges. While Social Determinants of Health (SDOH) such as socioeconomic status and housing stability play critical roles in health outcomes, they are often underrepresented in structured EHRs and hidden in unstructured clinical notes. This study leverages advanced large language models (LLMs) to extract SDOHs from clinical text and uses logistic regression to analyze their association with HF readmissions. By identifying key SDOHs (e.g. tobacco usage, limited transportation) linked to readmission risk, this work also offers actionable insights for reducing readmissions and improving patient care.', 'abstract_zh': '心力衰竭（HF）影响着数百万美国人群，并导致高再住院率，提出了重大医疗保健挑战。尽管社会决定因素（SDOH）如社会经济地位和住房稳定性对健康结果发挥着关键作用，但在结构化的电子健康记录（EHRs）中它们往往被忽视，并且隐藏在非结构化的临床笔记中。本研究利用先进的大规模语言模型（LLMs）从临床文本中提取SDOH，并使用逻辑回归分析其与HF再住院之间的关联。通过识别与再住院风险相关的关键SDOH（如烟草使用、有限的交通运输），本文还提供了减少再住院并提升患者护理的实际见解。', 'title_zh': '基于大型语言模型的心力衰竭患者30天再住院的社会决定因素挖掘'}
{'arxiv_id': 'arXiv:2502.01842', 'title': 'Texture Image Synthesis Using Spatial GAN Based on Vision Transformers', 'authors': 'Elahe Salari, Zohreh Azimifar', 'link': 'https://arxiv.org/abs/2502.01842', 'abstract': "Texture synthesis is a fundamental task in computer vision, whose goal is to generate visually realistic and structurally coherent textures for a wide range of applications, from graphics to scientific simulations. While traditional methods like tiling and patch-based techniques often struggle with complex textures, recent advancements in deep learning have transformed this field. In this paper, we propose ViT-SGAN, a new hybrid model that fuses Vision Transformers (ViTs) with a Spatial Generative Adversarial Network (SGAN) to address the limitations of previous methods. By incorporating specialized texture descriptors such as mean-variance (mu, sigma) and textons into the self-attention mechanism of ViTs, our model achieves superior texture synthesis. This approach enhances the model's capacity to capture complex spatial dependencies, leading to improved texture quality that is superior to state-of-the-art models, especially for regular and irregular textures. Comparison experiments with metrics such as FID, IS, SSIM, and LPIPS demonstrate the substantial improvement of ViT-SGAN, which underlines its efficiency in generating diverse realistic textures.", 'abstract_zh': '纹理合成是计算机视觉中的一个基础任务，其目标是生成视觉上逼真且结构上一致的纹理，应用于从图形到科学模拟等各种领域。虽然传统的砖块铺贴和基于块的技术在处理复杂纹理方面常有困难，但近年来深度学习的进步已经改变了这一领域。在本文中，我们提出了一种新的混合模型ViT-SGAN，该模型通过将视觉变换器（ViTs）与空间生成对抗网络（SGAN）相结合，以解决之前方法的局限性。通过将均值-方差（mu, sigma）和纹理这样的专门纹理描述符融入ViTs的自注意机制中，我们的模型实现了卓越的纹理合成效果。这种方法增强了模型捕捉复杂空间依赖性的能力，从而提高了纹理质量，相对于最先进的模型，尤其是对于规则和不规则的纹理，其效果更为出色。使用FID、IS、SSIM和LPIPS等指标的比较实验证明了ViT-SGAN的显著改进，突显了其在生成多样化的逼真纹理方面的高效性。', 'title_zh': '基于视觉变换器的时空生成对抗网络的纹理图像合成'}
