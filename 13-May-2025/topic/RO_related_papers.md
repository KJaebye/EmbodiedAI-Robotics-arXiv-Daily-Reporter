# AcoustoBots: A swarm of robots for acoustophoretic multimodal interactions 

**Title (ZH)**: 声波机器人：一种声学偏转多模态交互机器人集群 

**Authors**: Narsimlu Kemsaram, James Hardwick, Jincheng Wang, Bonot Gautam, Ceylan Besevli, Giorgos Christopoulos, Sourabh Dogra, Lei Gao, Akin Delibasi, Diego Martinez Plasencia, Orestis Georgiou, Marianna Obrist, Ryuji Hirayama, Sriram Subramanian  

**Link**: [PDF](https://arxiv.org/pdf/2505.07808)  

**Abstract**: Acoustophoresis has enabled novel interaction capabilities, such as levitation, volumetric displays, mid-air haptic feedback, and directional sound generation, to open new forms of multimodal interactions. However, its traditional implementation as a singular static unit limits its dynamic range and application versatility. This paper introduces AcoustoBots - a novel convergence of acoustophoresis with a movable and reconfigurable phased array of transducers for enhanced application versatility. We mount a phased array of transducers on a swarm of robots to harness the benefits of multiple mobile acoustophoretic units. This offers a more flexible and interactive platform that enables a swarm of acoustophoretic multimodal interactions. Our novel AcoustoBots design includes a hinge actuation system that controls the orientation of the mounted phased array of transducers to achieve high flexibility in a swarm of acoustophoretic multimodal interactions. In addition, we designed a BeadDispenserBot that can deliver particles to trapping locations, which automates the acoustic levitation interaction. These attributes allow AcoustoBots to independently work for a common cause and interchange between modalities, allowing for novel augmentations (e.g., a swarm of haptics, audio, and levitation) and bilateral interactions with users in an expanded interaction area. We detail our design considerations, challenges, and methodological approach to extend acoustophoretic central control in distributed settings. This work demonstrates a scalable acoustic control framework with two mobile robots, laying the groundwork for future deployment in larger robotic swarms. Finally, we characterize the performance of our AcoustoBots and explore the potential interactive scenarios they can enable. 

**Abstract (ZH)**: 声波操控使新型交互能力成为可能，如悬浮、体积显示、空中触觉反馈和定向声音生成，从而开辟了新的多模态交互形式。然而，其传统实施作为单一静态单元限制了其动态范围和应用 versatility。本文介绍了AcoustoBots——将声波操控与可移动和可重构的 phased array 传感器集成，以增强应用 versatility。我们将 phased array 传感器安装在一群机器人上，利用多个移动声波操控单元的优势，提供更灵活和交互的平台，以实现声波操控多模态交互的群集。我们的新型AcoustoBots设计包括一个铰接驱动系统，控制安装的 phased array 传感器的朝向，以实现声波操控多模态交互群集的高度灵活性。此外，我们设计了珠粒分配机器人BeadDispenserBot，可以将颗粒输送到捕获位置，以实现声波悬浮交互的自动化。这些特性允许AcoustoBots独立工作以共同实现目标，并在不同模态之间进行切换，从而实现新颖的增强功能（例如，一群触觉、声音和悬浮）及与用户的双向交互，扩展交互区域。我们详细阐述了设计考虑、挑战和方法论，以扩展分布式设置中的声波操控中心控制。这项工作展示了具有两台移动机器人可扩展的声控框架，并为更大规模的机器人群部署奠定了基础。最后，我们评估了AcoustoBots的性能并探讨了它们能够实现的潜在交互场景。 

---
# Hybrid Control Strategies for Safe and Adaptive Robot-Assisted Dressing 

**Title (ZH)**: 混合控制策略实现安全自适应机器人辅助穿衣 

**Authors**: Yasmin Rafiq, Baslin A. James, Ke Xu, Robert M. Hierons, Sanja Dogramadzi  

**Link**: [PDF](https://arxiv.org/pdf/2505.07710)  

**Abstract**: Safety, reliability, and user trust are crucial in human-robot interaction (HRI) where the robots must address hazards in real-time. This study presents hazard driven low-level control strategies implemented in robot-assisted dressing (RAD) scenarios where hazards like garment snags and user discomfort in real-time can affect task performance and user safety. The proposed control mechanisms include: (1) Garment Snagging Control Strategy, which detects excessive forces and either seeks user intervention via a chatbot or autonomously adjusts its trajectory, and (2) User Discomfort/Pain Mitigation Strategy, which dynamically reduces velocity based on user feedback and aborts the task if necessary. We used physical dressing trials in order to evaluate these control strategies. Results confirm that integrating force monitoring with user feedback improves safety and task continuity. The findings emphasise the need for hybrid approaches that balance autonomous intervention, user involvement, and controlled task termination, supported by bi-directional interaction and real-time user-driven adaptability, paving the way for more responsive and personalised HRI systems. 

**Abstract (ZH)**: 人类与机器人交互中的安全性、可靠性和用户信任至关重要，其中机器人必须实时应对潜在风险。本文提出了在辅助穿衣（RAD）场景中基于风险的低级控制策略，以实时应对如衣物缠绊和用户不适等风险对任务表现和用户安全的影响。提出的控制机制包括：（1）衣物缠绊控制策略，检测到过大力量时，通过聊天机器人寻求用户干预或自主调整路径，（2）用户不适/疼痛缓解策略，根据用户反馈动态降低速度，并在必要时取消任务。我们通过物理穿衣实验来评估这些控制策略。结果表明，将力量监测与用户反馈相结合，可以提高安全性和任务连续性。研究强调了需要采用混合方法平衡自主干预、用户参与和可控任务终止，并支持双向交互和实时用户驱动的适应性，为更加响应性和个性化的交互式机器人系统铺平了道路。 

---
# FD-RIO: Fast Dense Radar Inertial Odometry 

**Title (ZH)**: FD-RIO：快速密集雷达惯性里程计 

**Authors**: Nader J. Abu-Alrub, Nathir A. Rawashdeh  

**Link**: [PDF](https://arxiv.org/pdf/2505.07694)  

**Abstract**: Radar-based odometry is a popular solution for ego-motion estimation in conditions where other exteroceptive sensors may degrade, whether due to poor lighting or challenging weather conditions; however, scanning radars have the downside of relatively lower sampling rate and spatial resolution. In this work, we present FD-RIO, a method to alleviate this problem by fusing noisy, drift-prone, but high-frequency IMU data with dense radar scans. To the best of our knowledge, this is the first attempt to fuse dense scanning radar odometry with IMU using a Kalman filter. We evaluate our methods using two publicly available datasets and report accuracies using standard KITTI evaluation metrics, in addition to ablation tests and runtime analysis. Our phase correlation -based approach is compact, intuitive, and is designed to be a practical solution deployable on a realistic hardware setup of a mobile platform. Despite its simplicity, FD-RIO is on par with other state-of-the-art methods and outperforms in some test sequences. 

**Abstract (ZH)**: 基于雷达的里程计在其他外感知传感器因光照不良或恶劣天气条件而性能下降的情况下，是一种流行的自我运动估计解决方案；然而，扫描雷达的缺点是相对较低的采样率和空间分辨率。本文提出了FD-RIO方法，通过将噪声较大、易漂移但频率高的IMU数据与密集的雷达扫描数据融合来缓解这一问题。据我们所知，这是首次尝试使用卡尔曼滤波器融合密集扫描雷达里程计与IMU数据。我们使用两个公开的数据集评估了该方法，并使用标准KITTI评估指标报告了准确性，同时进行了消融测试和运行时分析。基于相位相关的方法紧凑、直观，并设计为可在移动平台的实际硬件配置中部署的实用解决方案。尽管简单，FD-RIO与其它最先进的方法相比表现相当，在某些测试序列中性能更优。 

---
# On rapid parallel tuning of controllers of a swarm of MAVs -- distribution strategies of the updated gains 

**Title (ZH)**: 基于更新增益的分布策略 MAVs 舞异群控制器的快速并行调整 

**Authors**: Dariusz Horla, Wojciech Giernacki, Vít Krátký, Petr Štibinger, Tomáš Báča, Martin Saska  

**Link**: [PDF](https://arxiv.org/pdf/2505.07523)  

**Abstract**: In this paper, we present a reliable, scalable, time deterministic, model-free procedure to tune swarms of Micro Aerial Vehicles (MAVs) using basic sensory data. Two approaches to taking advantage of parallel tuning are presented. First, the tuning with averaging of the results on the basis of performance indices reported from the swarm with identical gains to decrease the negative effect of the noise in the measurements. Second, the tuning with parallel testing of varying set of gains across the swarm to reduce the tuning time. The presented methods were evaluated both in simulation and real-world experiments. The achieved results show the ability of the proposed approach to improve the results of the tuning while decreasing the tuning time, ensuring at the same time a reliable tuning mechanism. 

**Abstract (ZH)**: 本文提出了一种可靠、可扩展、具有时间确定性的模型-free调参方法，用于使用基本传感器数据调整微型空中车辆（MAVs）群。介绍了两种利用并行调参的方法。首先，通过在具有相同增益的群中平均性能指标结果来减少测量噪声的负面影响。其次，通过在群中并行测试不同的增益集来减少调参时间。本文的方法在仿真和实际试验中都进行了评估，实验结果表明所提出的方法能够提高调参结果，同时减少调参时间，确保调参机制的可靠性。 

---
# Cooperative Assembly with Autonomous Mobile Manipulators in an Underwater Scenario 

**Title (ZH)**: 水下场景中自主移动 manipulator 的协同装配 

**Authors**: Davide Torielli  

**Link**: [PDF](https://arxiv.org/pdf/2505.07441)  

**Abstract**: [...] Specifically, the problem addressed is an assembly one known as the peg-in-hole task. In this case, two autonomous manipulators must carry cooperatively (at kinematic level) a peg and must insert it into an hole fixed in the environment. Even if the peg-in-hole is a well-known problem, there are no specific studies related to the use of two different autonomous manipulators, especially in underwater scenarios. Among all the possible investigations towards the problem, this work focuses mainly on the kinematic control of the robots. The methods used are part of the Task Priority Inverse Kinematics (TPIK) approach, with a cooperation scheme that permits to exchange as less information as possible between the agents (that is really important being water a big impediment for communication). A force-torque sensor is exploited at kinematic level to help the insertion phase. The results show how the TPIK and the chosen cooperation scheme can be used for the stated problem. The simulated experiments done consider little errors in the hole's pose, that still permit to insert the peg but with a lot of frictions and possible stucks. It is shown how can be possible to improve (thanks to the data provided by the force-torque sensor) the insertion phase performed by the two manipulators in presence of these errors. [...] 

**Abstract (ZH)**: 具体的装配问题是针孔装配任务。在此任务中，两个自主机械臂必须在运动学层面合作拿起一个针并将其插入固定在环境中的孔中。尽管针孔装配是一个众所周知的问题，但在使用两种不同自主机械臂方面几乎没有具体研究，特别是在水下场景中。在这项工作涉及的所有可能的研究中，主要集中在机器人运动学控制方面。所采用的方法属于任务优先逆运动学（TPIK）方法，利用的合作方案尽量减少信息交换（由于水对通信的阻碍作用，这一点非常重要）。在运动学层面使用力-扭矩传感器来辅助插入阶段。结果显示，TPIK方法和选择的合作方案可以用于解决上述问题。模拟实验中考虑到孔的姿态存在小误差，但仍能插入针，但由于摩擦和可能的卡滞现象较为严重。展示了在这些误差存在的情况下，如何利用力-扭矩传感器提供的数据来改进两个机械臂的插入阶段。 

---
# Stiffness-based Analytic Centre Method for Cable-Driven Parallel Robots 

**Title (ZH)**: 基于刚度的分析中心方法在缆索驱动并联机器人中的应用 

**Authors**: Domenico Dona', Vincenzo Di Paola, Matteo Zoppi, Alberto Trevisani  

**Link**: [PDF](https://arxiv.org/pdf/2505.07348)  

**Abstract**: Nowadays, being fast and precise are key requirements in Robotics. This work introduces a novel methodology to tune the stiffness of Cable-Driven Parallel Robots (CDPRs) while simultaneously addressing the tension distribution problem. In particular, the approach relies on the Analytic-Centre method. Indeed, weighting the barrier functions makes natural the stiffness adaptation. The intrinsic ability to adjust the stiffness during the execution of the task enables the CDPRs to effectively meet above-mentioned requirements. The capabilities of the method are demonstrated through simulations by comparing it with the existing approach. 

**Abstract (ZH)**: 如今，快速性和精确性是机器人领域的关键要求。本文提出了一种新颖的方法，用于在同时解决张力分配问题的情况下调整缆索驱动并联机器人（CDPR）的 stiffness，并特别依赖于分析中心方法。该方法的固有能力可以在执行任务时调整 stiffness，从而使CDPR能够有效满足上述要求。通过与现有方法的仿真比较，展示了该方法的能力。 

---
# Autonomous Robotic Pruning in Orchards and Vineyards: a Review 

**Title (ZH)**: 果园和葡萄园中的自主机器人修剪：一篇综述 

**Authors**: Alessandro Navone, Mauro Martini, Marcello Chiaberge  

**Link**: [PDF](https://arxiv.org/pdf/2505.07318)  

**Abstract**: Manual pruning is labor intensive and represents up to 25% of annual labor costs in fruit production, notably in apple orchards and vineyards where operational challenges and cost constraints limit the adoption of large-scale machinery. In response, a growing body of research is investigating compact, flexible robotic platforms capable of precise pruning in varied terrains, particularly where traditional mechanization falls short.
This paper reviews recent advances in autonomous robotic pruning for orchards and vineyards, addressing a critical need in precision agriculture. Our review examines literature published between 2014 and 2024, focusing on innovative contributions across key system components. Special attention is given to recent developments in machine vision, perception, plant skeletonization, and control strategies, areas that have experienced significant influence from advancements in artificial intelligence and machine learning. The analysis situates these technological trends within broader agricultural challenges, including rising labor costs, a decline in the number of young farmers, and the diverse pruning requirements of different fruit species such as apple, grapevine, and cherry trees.
By comparing various robotic architectures and methodologies, this survey not only highlights the progress made toward autonomous pruning but also identifies critical open challenges and future research directions. The findings underscore the potential of robotic systems to bridge the gap between manual and mechanized operations, paving the way for more efficient, sustainable, and precise agricultural practices. 

**Abstract (ZH)**: 手工修剪劳动密集且占到果蔬生产年度劳动力成本的25%以上，特别是在苹果园和葡萄园中，由于操作挑战和成本限制，大规模机械的采用受到限制。为此，越来越多的研究开始探索紧凑灵活的机器人平台，能够精确地在各种地形上进行修剪，尤其是在传统机械化难以发挥作用的情况下。本文回顾了2014年至2024年间果园和葡萄园自动修剪的最新进展，重点关注精密农业中的关键系统组件的创新贡献。特别关注了机器视觉、感知、植物骨架化以及控制策略等领域的最新发展，这些领域受到了人工智能和机器学习 advances的显著影响。分析将这些技术趋势置于更广泛的农业挑战之中，包括劳动力成本上升、年轻农民数量下降以及不同果树种类（如苹果树、葡萄藤和樱桃树）多样化的修剪要求。通过对比各种机器人的架构和方法，本文不仅突出了自动修剪进展，还指出了关键的开放挑战和未来研究方向。研究结果强调了机器人系统在手工和机械化操作之间架起桥梁的潜力，为更高效、可持续和精确的农业实践铺平了道路。 

---
# A Framework for Joint Grasp and Motion Planning in Confined Spaces 

**Title (ZH)**: 受限空间内抓取与运动规划的框架 

**Authors**: Martin Rudorfer, Jiří Hartvich, Vojtěch Vonásek  

**Link**: [PDF](https://arxiv.org/pdf/2505.07259)  

**Abstract**: Robotic grasping is a fundamental skill across all domains of robot applications. There is a large body of research for grasping objects in table-top scenarios, where finding suitable grasps is the main challenge. In this work, we are interested in scenarios where the objects are in confined spaces and hence particularly difficult to reach. Planning how the robot approaches the object becomes a major part of the challenge, giving rise to methods for joint grasp and motion planning. The framework proposed in this paper provides 20 benchmark scenarios with systematically increasing difficulty, realistic objects with precomputed grasp annotations, and tools to create and share more scenarios. We further provide two baseline planners and evaluate them on the scenarios, demonstrating that the proposed difficulty levels indeed offer a meaningful progression. We invite the research community to build upon this framework by making all components publicly available as open source. 

**Abstract (ZH)**: 机器人抓取是机器人应用领域的一项基本技能。在桌面场景中进行物体抓取的研究成果丰富，其中寻找到合适的抓取方式是主要挑战。本文关注物体位于受限空间中的场景，这类场景下抓取物体尤其困难。规划机器人如何接近物体成为主要挑战之一，推动了抓取与运动规划的联合方法的发展。本文提出的研究框架提供了20个具有系统递增难度的基准场景、真实物体及其预计算的抓取标注，并提供工具以创建和共享更多场景。此外，我们还提供了两种基线规划算法，并在这些场景上进行了评估，验证了提出的难度级别确实具有意义。我们邀请研究社区在此框架基础上进行研究，并将所有组件公开为开源软件。 

---
# Terrain-aware Low Altitude Path Planning 

**Title (ZH)**: 地形-aware 低altura路径规划 

**Authors**: Yixuan Jia, Andrea Tagliabue, Navid Dadkhah Tehrani, Jonathan P. How  

**Link**: [PDF](https://arxiv.org/pdf/2505.07141)  

**Abstract**: In this paper, we study the problem of generating low altitude path plans for nap-of-the-earth (NOE) flight in real time with only RGB images from onboard cameras and the vehicle pose. We propose a novel training method that combines behavior cloning and self-supervised learning that enables the learned policy to outperform the policy trained with standard behavior cloning approach on this task. Simulation studies are performed on a custom canyon terrain. 

**Abstract (ZH)**: 本文研究了仅使用机载摄像头的RGB图像和车辆姿态在实时生成低 altitude 贴地飞行路径规划(NOE)问题的方法。我们提出了一种结合行为克隆和自我监督学习的新型训练方法，使得学习到的策略在这一任务上能超越使用标准行为克隆方法训练的策略。在自定义 Canyon 地形上进行了仿真研究。 

---
# Reinforcement Learning-Based Monocular Vision Approach for Autonomous UAV Landing 

**Title (ZH)**: 基于强化学习的单目视觉自主无人机着陆方法 

**Authors**: Tarik Houichime, Younes EL Amrani  

**Link**: [PDF](https://arxiv.org/pdf/2505.06963)  

**Abstract**: This paper introduces an innovative approach for the autonomous landing of Unmanned Aerial Vehicles (UAVs) using only a front-facing monocular camera, therefore obviating the requirement for depth estimation cameras. Drawing on the inherent human estimating process, the proposed method reframes the landing task as an optimization problem. The UAV employs variations in the visual characteristics of a specially designed lenticular circle on the landing pad, where the perceived color and form provide critical information for estimating both altitude and depth. Reinforcement learning algorithms are utilized to approximate the functions governing these estimations, enabling the UAV to ascertain ideal landing settings via training. This method's efficacy is assessed by simulations and experiments, showcasing its potential for robust and accurate autonomous landing without dependence on complex sensor setups. This research contributes to the advancement of cost-effective and efficient UAV landing solutions, paving the way for wider applicability across various fields. 

**Abstract (ZH)**: 本文提出了一种仅使用前置单目摄像头进行自主降落的无人机创新方法，从而省去了深度估计摄像头的需要。该方法借鉴了人类固有的估算过程，将降落任务重新定义为一个优化问题。无人机利用着陆垫上特制透镜圆环的视觉特征的变化，通过感知颜色和形态来估算高度和深度。利用强化学习算法近似这些估算函数，使无人机通过训练确定理想的着陆设置。该方法的有效性通过模拟和实验进行了评估，展示了其在无需复杂传感器配置的情况下实现稳健准确自主降落的潜力。该研究为低成本高效的无人机降落解决方案的发展做出了贡献，为在各种领域的广泛应用铺平了道路。 

---
# The First WARA Robotics Mobile Manipulation Challenge -- Lessons Learned 

**Title (ZH)**: 首次WARA机器人移动操作挑战——经验教训 

**Authors**: David Cáceres Domínguez, Marco Iannotta, Abhishek Kashyap, Shuo Sun, Yuxuan Yang, Christian Cella, Matteo Colombo, Martina Pelosi, Giuseppe F. Preziosa, Alessandra Tafuro, Isacco Zappa, Finn Busch, Yifei Dong, Alberta Longhini, Haofei Lu, Rafael I. Cabral Muchacho, Jonathan Styrud, Sebastiano Fregnan, Marko Guberina, Zheng Jia, Graziano Carriero, Sofia Lindqvist, Silvio Di Castro, Matteo Iovino  

**Link**: [PDF](https://arxiv.org/pdf/2505.06919)  

**Abstract**: The first WARA Robotics Mobile Manipulation Challenge, held in December 2024 at ABB Corporate Research in Västerås, Sweden, addressed the automation of task-intensive and repetitive manual labor in laboratory environments - specifically the transport and cleaning of glassware. Designed in collaboration with AstraZeneca, the challenge invited academic teams to develop autonomous robotic systems capable of navigating human-populated lab spaces and performing complex manipulation tasks, such as loading items into industrial dishwashers. This paper presents an overview of the challenge setup, its industrial motivation, and the four distinct approaches proposed by the participating teams. We summarize lessons learned from this edition and propose improvements in design to enable a more effective second iteration to take place in 2025. The initiative bridges an important gap in effective academia-industry collaboration within the domain of autonomous mobile manipulation systems by promoting the development and deployment of applied robotic solutions in real-world laboratory contexts. 

**Abstract (ZH)**: 第一次WARA Robotics移动 manipulation挑战赛：2024年12月在瑞典韦斯特罗斯ABB企业研究院举行的挑战赛，旨在解决实验室环境中密集型和重复性的手工劳动的自动化问题——尤其是玻璃器皿的运输和清洁。该挑战由AstraZeneca合作设计，邀请学术团队开发能够在有人类操作员的实验室空间内自主导航并执行复杂操作任务（如将物品加载到工业洗碗机中）的机器人系统。本文概述了挑战设置、其工业背景以及参赛团队提出的四个不同方法。我们总结了本版次的经验教训，并提出了改进设计的建议，以使2025年的第二次迭代更加有效。该倡议通过促进适用于真实实验室环境的自主移动 manipulation系统的开发和部署，填补了学术界与工业界有效合作的重要空白。 

---
# Realistic Counterfactual Explanations for Machine Learning-Controlled Mobile Robots using 2D LiDAR 

**Title (ZH)**: 基于2D LiDAR的机器学习控制移动机器人现实-counterfactual 解释 

**Authors**: Sindre Benjamin Remman, Anastasios M. Lekkas  

**Link**: [PDF](https://arxiv.org/pdf/2505.06906)  

**Abstract**: This paper presents a novel method for generating realistic counterfactual explanations (CFEs) in machine learning (ML)-based control for mobile robots using 2D LiDAR. ML models, especially artificial neural networks (ANNs), can provide advanced decision-making and control capabilities by learning from data. However, they often function as black boxes, making it challenging to interpret them. This is especially a problem in safety-critical control applications. To generate realistic CFEs, we parameterize the LiDAR space with simple shapes such as circles and rectangles, whose parameters are chosen by a genetic algorithm, and the configurations are transformed into LiDAR data by raycasting. Our model-agnostic approach generates CFEs in the form of synthetic LiDAR data that resembles a base LiDAR state but is modified to produce a pre-defined ML model control output based on a query from the user. We demonstrate our method on a mobile robot, the TurtleBot3, controlled using deep reinforcement learning (DRL) in real-world and simulated scenarios. Our method generates logical and realistic CFEs, which helps to interpret the DRL agent's decision making. This paper contributes towards advancing explainable AI in mobile robotics, and our method could be a tool for understanding, debugging, and improving ML-based autonomous control. 

**Abstract (ZH)**: 本文提出了一种使用2D LiDAR在基于机器学习的移动机器人控制中生成现实主义反事实解释的新方法。 

---
# Secure Safety Filter: Towards Safe Flight Control under Sensor Attacks 

**Title (ZH)**: 安全过滤器确保安全：面向传感器攻击下的飞行控制安全性研究 

**Authors**: Xiao Tan, Junior Sundar, Renzo Bruzzone, Pio Ong, Willian T. Lunardi, Martin Andreoni, Paulo Tabuada, Aaron D. Ames  

**Link**: [PDF](https://arxiv.org/pdf/2505.06845)  

**Abstract**: Modern autopilot systems are prone to sensor attacks that can jeopardize flight safety. To mitigate this risk, we proposed a modular solution: the secure safety filter, which extends the well-established control barrier function (CBF)-based safety filter to account for, and mitigate, sensor attacks. This module consists of a secure state reconstructor (which generates plausible states) and a safety filter (which computes the safe control input that is closest to the nominal one). Differing from existing work focusing on linear, noise-free systems, the proposed secure safety filter handles bounded measurement noise and, by leveraging reduced-order model techniques, is applicable to the nonlinear dynamics of drones. Software-in-the-loop simulations and drone hardware experiments demonstrate the effectiveness of the secure safety filter in rendering the system safe in the presence of sensor attacks. 

**Abstract (ZH)**: 现代自动驾驶系统易受传感器攻击的影响，这可能危及飞行安全。为降低这一风险，我们提出了一种模块化解决方案：安全过滤器模块，它将基于控制障碍函数（CBF）的安全过滤器扩展以考虑和缓解传感器攻击。该模块包括安全状态重构器（生成合理的状态）和安全过滤器（计算最接近名义值的安全控制输入）。与现有工作主要针对线性、无噪声系统不同，所提出的安全过滤器能够处理有界测量噪声，并通过利用降阶模型技术适用于无人机的非线性动力学。软件在环仿真和无人机硬件实验表明，在存在传感器攻击的情况下，安全过滤器能够使系统保持安全。 

---
# cpRRTC: GPU-Parallel RRT-Connect for Constrained Motion Planning 

**Title (ZH)**: cpRRTC: GPU并行RRT-Connect算法在受约束运动规划中的应用 

**Authors**: Jiaming Hu, Jiawei Wang, Henrik Christensen  

**Link**: [PDF](https://arxiv.org/pdf/2505.06791)  

**Abstract**: Motion planning is a fundamental problem in robotics that involves generating feasible trajectories for a robot to follow. Recent advances in parallel computing, particularly through CPU and GPU architectures, have significantly reduced planning times to the order of milliseconds. However, constrained motion planning especially using sampling based methods on GPUs remains underexplored. Prior work such as pRRTC leverages a tracking compiler with a CUDA backend to accelerate forward kinematics and collision checking. While effective in simple settings, their approach struggles with increased complexity in robot models or environments. In this paper, we propose a novel GPU based framework utilizing NVRTC for runtime compilation, enabling efficient handling of high complexity scenarios and supporting constrained motion planning. Experimental results demonstrate that our method achieves superior performance compared to existing approaches. 

**Abstract (ZH)**: 基于GPU的NVRTC驱动高效复杂约束运动规划方法 

---
# Digital-physical testbed for ship autonomy studies in the Marine Cybernetics Laboratory basin 

**Title (ZH)**: 海洋控制实验室水池中的数字物理试验台用于船舶自主性研究 

**Authors**: Emir Cem Gezer, Mael Korentin Ivan Moreau, Anders Sandneseng Høgden, Dong Trong Nguyen, Roger Skjetne, Asgeir Sørensen  

**Link**: [PDF](https://arxiv.org/pdf/2505.06787)  

**Abstract**: The algorithms developed for Maritime Autonomous Surface Ships (MASS) are often challenging to test on actual vessels due to high operational costs and safety considerations. Simulations offer a cost-effective alternative and eliminate risks, but they may not accurately represent real-world dynamics for the given tasks. Utilizing small-scale model ships and robotic vessels in conjunction with a laboratory basin provides an accessible testing environment for the early stages of validation processes. However, designing and developing a model vessel for a single test can be costly and cumbersome, and often researchers lack availability to such infrastructure. To address these challenges and enable streamlined testing, we have developed an in-house testbed that facilitates the development, testing, verification, and validation of MASS algorithms in a digital-physical laboratory. This infrastructure includes a set of small-scale model vessels, a simulation environment for each vessel, a comprehensive testbed environment, and a digital twin in Unity. With this, we aim to establish a full design and verification pipeline that starts with high-fidelity simulation models of each model vessel, to the model-scale testing in the laboratory basin, allowing possibilities for moving to semi-fullscale validation with the R/V milliAmpere 1 passenger ferry and full-scale validation using the R/V Gunnerus. In this work, we present our progress on the development of this testbed environment and its components, demonstrating its effectiveness in enabling ship guidance, navigation, and control (GNC) including autonomy. 

**Abstract (ZH)**: 针对海上自主表面船舶（MASS）开发的算法往往由于高昂的运营成本和安全考虑难以在实际船舶上进行测试。模拟提供了一种成本效益高的替代方案并消除了风险，但可能无法准确地代表给定任务的实际动态。通过结合使用小比例模型船和无人驾驶船舶，并在实验室水槽中进行测试，可以在验证过程的早期阶段提供一种易于访问的测试环境。然而，为单一测试设计和开发模型船只可能成本高昂且繁琐，且研究人员通常缺乏此类基础设施的可用性。为应对这些挑战并实现顺畅的测试过程，我们开发了一套内部测试床，用以在数字物理实验室中开发、测试、验证和验证MASS算法。该基础设施包括一组小比例模型船、每艘船的仿真环境、一个综合测试环境以及在Unity中的数字孪生。通过这一系统，我们旨在建立一条从每个模型船只的高保真仿真模型，到在实验室水槽中进行模型规模测试的完整设计和验证流程，允许过渡到半全尺度验证R/V milliAmpere 1乘客渡船，并最终进行全尺度验证R/V Gunnerus。在本文中，我们介绍了在此测试床环境及其组件的开发进展，并展示了其在船舶导航、制导与控制（GNC）包括自主性方面的有效性。 

---
# TPK: Trustworthy Trajectory Prediction Integrating Prior Knowledge For Interpretability and Kinematic Feasibility 

**Title (ZH)**: TPK: 可信赖的轨迹预测集成先验知识以提高可解释性和动力学可行性 

**Authors**: Marius Baden, Ahmed Abouelazm, Christian Hubschneider, Yin Wu, Daniel Slieter, J. Marius Zöllner  

**Link**: [PDF](https://arxiv.org/pdf/2505.06743)  

**Abstract**: Trajectory prediction is crucial for autonomous driving, enabling vehicles to navigate safely by anticipating the movements of surrounding road users. However, current deep learning models often lack trustworthiness as their predictions can be physically infeasible and illogical to humans. To make predictions more trustworthy, recent research has incorporated prior knowledge, like the social force model for modeling interactions and kinematic models for physical realism. However, these approaches focus on priors that suit either vehicles or pedestrians and do not generalize to traffic with mixed agent classes. We propose incorporating interaction and kinematic priors of all agent classes--vehicles, pedestrians, and cyclists with class-specific interaction layers to capture agent behavioral differences. To improve the interpretability of the agent interactions, we introduce DG-SFM, a rule-based interaction importance score that guides the interaction layer. To ensure physically feasible predictions, we proposed suitable kinematic models for all agent classes with a novel pedestrian kinematic model. We benchmark our approach on the Argoverse 2 dataset, using the state-of-the-art transformer HPTR as our baseline. Experiments demonstrate that our method improves interaction interpretability, revealing a correlation between incorrect predictions and divergence from our interaction prior. Even though incorporating the kinematic models causes a slight decrease in accuracy, they eliminate infeasible trajectories found in the dataset and the baseline model. Thus, our approach fosters trust in trajectory prediction as its interaction reasoning is interpretable, and its predictions adhere to physics. 

**Abstract (ZH)**: 轨迹预测对于自动驾驶至关重要，能够通过预见周围道路使用者的运动来安全导航。然而，当前的深度学习模型往往缺乏可信度，因为它们的预测可能在物理上是不可能的，且不符合人类逻辑。为了使预测更加可信，最近的研究将先验知识纳入其中，如使用社会力模型来建模交互，使用动力学模型来实现物理现实。然而，这些方法专注于适用于车辆或行人的先验知识，无法推广到包含多种代理类别的交通环境中。我们提出了一种结合所有代理类别（车辆、行人在内和自行车）的交互和动力学先验知识的方法，并使用类别特定的交互层来捕捉代理行为的差异。为了提高代理交互的可解释性，我们引入了一种基于规则的交互重要性评分DG-SFM，以指导交互层。为了确保预测的物理可行性，我们为所有代理类别提出了合适的动力学模型，并采用了一种新颖的行人类动力学模型。我们使用最先进的Transformer HPTR作为基准，在Argoverse 2数据集上对我们的方法进行了评估。实验表明，我们的方法提高了交互的可解释性，揭示了错误预测与偏离我们交互先验之间的关联。尽管结合动力学模型略微降低了准确性，但它们消除了数据集和基准模型中存在的不可行轨迹。因此，我们的方法促进了轨迹预测的信任，因为其交互推理是可解释的，并且其预测符合物理原理。 

---
# Emergent Multi-View Fidelity in Autonomous UAV Swarm Sport Injury Detection 

**Title (ZH)**: 自主无人机群运动损伤检测中 Emergent 多视角保真度 

**Authors**: Yu Cheng, Harun Šiljak  

**Link**: [PDF](https://arxiv.org/pdf/2505.06588)  

**Abstract**: Accurate, real-time collision detection is essential for ensuring player safety and effective refereeing in high-contact sports such as rugby, particularly given the severe risks associated with traumatic brain injuries (TBI). Traditional collision-monitoring methods employing fixed cameras or wearable sensors face limitations in visibility, coverage, and responsiveness. Previously, we introduced a framework using unmanned aerial vehicles (UAVs) for monitoring and real time kinematics extraction from videos of collision events. In this paper, we show that the strategies operating on the objective of ensuring at least one UAV captures every incident on the pitch have an emergent property of fulfilling a stronger key condition for successful kinematics extraction. Namely, they ensure that almost all collisions are captured by multiple drones, establishing multi-view fidelity and redundancy, while not requiring any drone-to-drone communication. 

**Abstract (ZH)**: 准确的实时碰撞检测对于确保如橄榄球等高接触运动中玩家的安全及有效裁判至关重要，尤其是在与重度脑损伤（TBI）相关的严重风险下。传统的使用固定摄像头或穿戴式传感器的碰撞监测方法在可见性、覆盖范围和响应性方面存在局限。此前，我们提出了使用无人驾驶航空 vehicle (UAV) 的框架，用于监测和实时从碰撞事件视频中提取动态信息。本文显示，旨在确保至少一架无人机捕获场内每个事件的策略具有一个 Emergent 属性，即它们确保几乎所有的碰撞被多架无人机同时捕获，从而建立多视角保真度和冗余性，同时无需无人机之间的通信。 

---
# Adaptive Wiping: Adaptive contact-rich manipulation through few-shot imitation learning with Force-Torque feedback and pre-trained object representations 

**Title (ZH)**: 自适应擦拭：通过力-力矩反馈和预训练物体表示的少量示范模仿学习实现接触丰富的自适应操作 

**Authors**: Chikaha Tsuji, Enrique Coronado, Pablo Osorio, Gentiane Venture  

**Link**: [PDF](https://arxiv.org/pdf/2505.06451)  

**Abstract**: Imitation learning offers a pathway for robots to perform repetitive tasks, allowing humans to focus on more engaging and meaningful activities. However, challenges arise from the need for extensive demonstrations and the disparity between training and real-world environments. This paper focuses on contact-rich tasks like wiping with soft and deformable objects, requiring adaptive force control to handle variations in wiping surface height and the sponge's physical properties. To address these challenges, we propose a novel method that integrates real-time force-torque (FT) feedback with pre-trained object representations. This approach allows robots to dynamically adjust to previously unseen changes in surface heights and sponges' physical properties. In real-world experiments, our method achieved 96% accuracy in applying reference forces, significantly outperforming the previous method that lacked an FT feedback loop, which only achieved 4% accuracy. To evaluate the adaptability of our approach, we conducted experiments under different conditions from the training setup, involving 40 scenarios using 10 sponges with varying physical properties and 4 types of wiping surface heights, demonstrating significant improvements in the robot's adaptability by analyzing force trajectories. The video of our work is available at: this https URL 

**Abstract (ZH)**: 模仿学习为机器人执行重复任务提供了途径，使人类能够集中精力进行更具吸引力和意义的活动。然而，这需要大量的示范，并且訓練环境与真实世界环境之间存在差距。本文专注于接触丰富的任务，如用柔软可变形物体擦拭，需要适应性的力控制来处理擦拭表面高度和海绵物理性质的变化。为解决这些挑战，我们提出了一种新方法，该方法将实时力-扭矩（FT）反馈与预训练的对象表示相结合。这种方法使机器人能够动态适应前所未见的表面高度和海绵物理性质的变化。在实际实验中，我们的方法在施加参考力方面的准确率达到96%，明显优于缺乏FT反馈回路的先前方法，后者仅达到4%的准确率。为了评估我们方法的适应性，我们在与训练设置不同的条件下进行了实验，使用10种具有不同物理性质的海绵进行40种场景实验，并通过分析力轨迹展示了机器人适应性的显著提高。我们的工作视频可在此处查看：this https URL 

---
# Learning Sequential Kinematic Models from Demonstrations for Multi-Jointed Articulated Objects 

**Title (ZH)**: 基于演示学习多关节 articulated 对象的序列运动学模型 

**Authors**: Anmol Gupta, Weiwei Gu, Omkar Patil, Jun Ki Lee, Nakul Gopalan  

**Link**: [PDF](https://arxiv.org/pdf/2505.06363)  

**Abstract**: As robots become more generalized and deployed in diverse environments, they must interact with complex objects, many with multiple independent joints or degrees of freedom (DoF) requiring precise control. A common strategy is object modeling, where compact state-space models are learned from real-world observations and paired with classical planning. However, existing methods often rely on prior knowledge or focus on single-DoF objects, limiting their applicability. They also fail to handle occluded joints and ignore the manipulation sequences needed to access them. We address this by learning object models from human demonstrations. We introduce Object Kinematic Sequence Machines (OKSMs), a novel representation capturing both kinematic constraints and manipulation order for multi-DoF objects. To estimate these models from point cloud data, we present Pokenet, a deep neural network trained on human demonstrations. We validate our approach on 8,000 simulated and 1,600 real-world annotated samples. Pokenet improves joint axis and state estimation by over 20 percent on real-world data compared to prior methods. Finally, we demonstrate OKSMs on a Sawyer robot using inverse kinematics-based planning to manipulate multi-DoF objects. 

**Abstract (ZH)**: 随着机器人在多样化环境中变得更加通用，它们必须与复杂对象交互，这些对象往往具有多个独立关节或自由度，需要精确控制。一种常见策略是对象建模，即从实际观察中学习紧凑的状态空间模型，并与经典规划相结合。然而，现有方法往往依赖先验知识或专注于单自由度对象，这限制了其适用性。它们也无法处理被遮挡的关节，并且忽略了解析它们所需的操控序列。我们通过从人类演示中学习对象模型来解决这个问题。我们提出了对象运动序列机（OKSMs），这是一种新颖的表现形式，可以捕捉多自由度对象的运动约束及其操作顺序。为了从点云数据中估算这些模型，我们呈现了Pokenet，这是一种基于人类演示训练的深度神经网络。我们在8,000个模拟和1,600个实际标注样本上验证了该方法的有效性。与先前方法相比，Pokenet在实际数据中的关节轴线和状态估计提高了超过20%。最后，我们在Sawyer机器人上展示了OKSMs，通过基于逆向运动学的规划来操控多自由度对象。 

---
# Investigating Robotaxi Crash Severity Using Geographical Random Forest 

**Title (ZH)**: 基于地理随机森林探讨Robotaxi碰撞严重性 

**Authors**: Junfeng Jiao, Seung Gyu Baik, Seung Jun Choi, Yiming Xu  

**Link**: [PDF](https://arxiv.org/pdf/2505.06762)  

**Abstract**: This paper quantitatively investigates the crash severity of Autonomous Vehicles (AVs) with spatially localized machine learning and macroscopic measures of the urban built environment. We address spatial heterogeneity and spatial autocorrelation, while focusing on land use patterns and human behavior. Our Geographical Random Forest (GRF) model, accompanied with a crash severity risk map of San Francisco, presents three findings that are useful for commercial operations of AVs and robotaxis. First, spatially localized machine learning performed better than regular machine learning, when predicting AV crash severity. Bias-variance tradeoff was evident as we adjust the localization weight hyperparameter. Second, land use was the most important built environment measure, compared to intersections, building footprints, public transit stops, and Points Of Interests (POIs). Third, it was predicted that city center areas with greater diversity and commercial activities were more likely to result in low-severity AV crashes, than residential neighborhoods. Residential land use may be associated with higher severity due to human behavior and less restrictive environment. This paper recommends to explicitly consider geographic locations, and to design safety measures specific to residential neighborhoods, when robotaxi operators train their AV systems. 

**Abstract (ZH)**: 本文利用空间局部化机器学习和宏观数字城市的测量方法，定量研究自动驾驶车辆（AVs）的碰撞 severity，并关注土地使用模式和人类行为。我们的地理随机森林（GRF）模型结合旧金山的碰撞 severity 风险地图展现了三条对自动驾驶车辆商用运营有用的发现：首先，空间局部化机器学习在预测AV碰撞 severity 方面优于常规机器学习，且在调整局部化权重超参数时显示了偏差-方差权衡。其次，在土地使用、交叉口、建筑物足迹、公共交通站点和兴趣点（POIs）之间，土地使用是最为重要的城市建成环境指标。第三，市中心具有更高多样性和商业活动的区域比住宅区更有可能导致低 severity 的AV碰撞。住宅土地使用可能因人类行为和较少限制的环境而导致更高 severity。本文建议，在自动驾驶出租车运营商训练其AV系统时，需明确考虑地理位置，并设计针对住宅区的特定安全措施。 

---
# A Multi-Agent Reinforcement Learning Approach for Cooperative Air-Ground-Human Crowdsensing in Emergency Rescue 

**Title (ZH)**: 多agent强化学习在应急救援中协同空地人 crowdsensing 方法 

**Authors**: Wenhao Lu, Zhengqiu Zhu, Yong Zhao, Yonglin Tian, Junjie Zeng, Jun Zhang, Zhong Liu, Fei-Yue Wang  

**Link**: [PDF](https://arxiv.org/pdf/2505.06997)  

**Abstract**: Mobile crowdsensing is evolving beyond traditional human-centric models by integrating heterogeneous entities like unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs). Optimizing task allocation among these diverse agents is critical, particularly in challenging emergency rescue scenarios characterized by complex environments, limited communication, and partial observability. This paper tackles the Heterogeneous-Entity Collaborative-Sensing Task Allocation (HECTA) problem specifically for emergency rescue, considering humans, UAVs, and UGVs. We introduce a novel ``Hard-Cooperative'' policy where UGVs prioritize recharging low-battery UAVs, alongside performing their sensing tasks. The primary objective is maximizing the task completion rate (TCR) under strict time constraints. We rigorously formulate this NP-hard problem as a decentralized partially observable Markov decision process (Dec-POMDP) to effectively handle sequential decision-making under uncertainty. To solve this, we propose HECTA4ER, a novel multi-agent reinforcement learning algorithm built upon a Centralized Training with Decentralized Execution architecture. HECTA4ER incorporates tailored designs, including specialized modules for complex feature extraction, utilization of action-observation history via hidden states, and a mixing network integrating global and local information, specifically addressing the challenges of partial observability. Furthermore, theoretical analysis confirms the algorithm's convergence properties. Extensive simulations demonstrate that HECTA4ER significantly outperforms baseline algorithms, achieving an average 18.42% increase in TCR. Crucially, a real-world case study validates the algorithm's effectiveness and robustness in dynamic sensing scenarios, highlighting its strong potential for practical application in emergency response. 

**Abstract (ZH)**: 移动群体感知正通过集成如无人驾驶航空车辆(UAVs)和无人驾驶地面车辆(UGVs)等异构实体，超越传统的以人类为中心的模型。本文针对紧急救援场景，具体解决异构实体协同感知任务分配(HECTA)问题，考虑人类、UAVs和UGVs。提出了一种新颖的“硬协同”策略，其中UGVs优先为低电量UAVs充电，并同时执行感知任务。主要目标是在严格的时间约束下最大化任务完成率(TCR)。将这一NP难问题严格形式化为去中心化的部分可观测马尔可夫决策过程(Dec-POMDP)，以有效处理不确定性下的顺序决策问题。为此，提出了一种基于集中训练与分散执行架构的新颖多智能体强化学习算法HECTA4ER。HECTA4ER包括针对部分可观测性的定制设计，如复杂特征提取模块、隐状态下的动作-观察历史利用以及结合全局和局部信息的混合网络。理论分析证实了算法的收敛性。广泛仿真表明，HECTA4ER在平均TCR方面显著优于基线算法，提高了18.42%。更重要的是，实地案例研究验证了该算法在动态感知场景中的有效性和鲁棒性，突显了其在紧急响应中的强大应用潜力。 

---
