{'arxiv_id': 'arXiv:2505.15558', 'title': 'Robo-DM: Data Management For Large Robot Datasets', 'authors': 'Kaiyuan Chen, Letian Fu, David Huang, Yanxiang Zhang, Lawrence Yunliang Chen, Huang Huang, Kush Hari, Ashwin Balakrishna, Ted Xiao, Pannag R Sanketi, John Kubiatowicz, Ken Goldberg', 'link': 'https://arxiv.org/abs/2505.15558', 'abstract': "Recent results suggest that very large datasets of teleoperated robot demonstrations can be used to train transformer-based models that have the potential to generalize to new scenes, robots, and tasks. However, curating, distributing, and loading large datasets of robot trajectories, which typically consist of video, textual, and numerical modalities - including streams from multiple cameras - remains challenging. We propose Robo-DM, an efficient open-source cloud-based data management toolkit for collecting, sharing, and learning with robot data. With Robo-DM, robot datasets are stored in a self-contained format with Extensible Binary Meta Language (EBML). Robo-DM can significantly reduce the size of robot trajectory data, transfer costs, and data load time during training. Compared to the RLDS format used in OXE datasets, Robo-DM's compression saves space by up to 70x (lossy) and 3.5x (lossless). Robo-DM also accelerates data retrieval by load-balancing video decoding with memory-mapped decoding caches. Compared to LeRobot, a framework that also uses lossy video compression, Robo-DM is up to 50x faster when decoding sequentially. We physically evaluate a model trained by Robo-DM with lossy compression, a pick-and-place task, and In-Context Robot Transformer. Robo-DM uses 75x compression of the original dataset and does not suffer reduction in downstream task accuracy.", 'abstract_zh': '最近的研究表明，大型的遥操作机器人演示数据集可以用于训练具有潜在泛化能力的变压器模型，这些模型可以应用于新的场景、机器人和任务。然而，收集、分发和加载包含视频、文本和数值等多种模态的大型机器人轨迹数据集仍然具有挑战性。我们提出Robo-DM，这是一种高效的开源云数据管理工具箱，用于收集、共享和学习机器人数据。使用Robo-DM，机器人数据集以扩展二进制元数据语言（EBML）格式存储，可以显著减小机器人轨迹数据的大小，降低传输成本，并在训练期间减少数据加载时间。与OXE数据集中使用的RLDS格式相比，Robo-DM的压缩在有损压缩情况下可节省多达70倍的空间，在无损压缩情况下可节省3.5倍的空间。Robo-DM还通过视频解码负载均衡和内存映射解码缓存加速数据检索。与使用有损视频压缩的LeRobot框架相比，Robo-DM在逐个解码时速度可提高50倍。我们通过使用Robo-DM进行有损压缩训练的模型和夹取放置任务以及上下文机器人变换器，进行了物理评估。Robo-DM对原始数据集进行了75倍的压缩，而不会降低下游任务的准确性。', 'title_zh': 'Robo-DM：大型机器人数据集的管理'}
{'arxiv_id': 'arXiv:2505.15503', 'title': 'Coloring Between the Lines: Personalization in the Null Space of Planning Constraints', 'authors': 'Tom Silver, Rajat Kumar Jenamani, Ziang Liu, Ben Dodson, Tapomayukh Bhattacharjee', 'link': 'https://arxiv.org/abs/2505.15503', 'abstract': 'Generalist robots must personalize in-the-wild to meet the diverse needs and preferences of long-term users. How can we enable flexible personalization without sacrificing safety or competency? This paper proposes Coloring Between the Lines (CBTL), a method for personalization that exploits the null space of constraint satisfaction problems (CSPs) used in robot planning. CBTL begins with a CSP generator that ensures safe and competent behavior, then incrementally personalizes behavior by learning parameterized constraints from online interaction. By quantifying uncertainty and leveraging the compositionality of planning constraints, CBTL achieves sample-efficient adaptation without environment resets. We evaluate CBTL in (1) three diverse simulation environments; (2) a web-based user study; and (3) a real-robot assisted feeding system, finding that CBTL consistently achieves more effective personalization with fewer interactions than baselines. Our results demonstrate that CBTL provides a unified and practical approach for continual, flexible, active, and safe robot personalization. Website: this https URL', 'abstract_zh': '通用机器人必须在真实环境中个性化以满足长期用户的多样化需求和偏好。我们如何能够在不牺牲安全性和专业性的情况下实现灵活的个性化？本文提出了一种名为“在空白处着色”（CBTL，Coloring Between the Lines）的方法，该方法利用了机器人规划中约束满足问题（CSPs）的零空间来进行个性化。CBTL以一个确保安全和专业行为的CSP生成器开始，然后通过在线交互学习参数化约束规则逐步实现个性化。通过量化不确定性并利用规划约束的组合性，CBTL在无需重新配置环境的情况下实现了高效适应。我们在（1）三个不同的仿真环境中；（2）一项基于网络的用户研究中；以及（3）一个真实机器人辅助喂食系统中评估了CBTL，发现CBTL在更少的交互中实现了更有效的个性化，优于基线方法。我们的结果表明，CBTL提供了一种统一且实用的方法，可用于持续的、灵活的、主动的安全机器人个性化。', 'title_zh': '在规划约束的 null space 中着色：个性化方法'}
{'arxiv_id': 'arXiv:2505.15005', 'title': 'UniSTPA: A Safety Analysis Framework for End-to-End Autonomous Driving', 'authors': 'Hongrui Kou, Zhouhang Lyu, Ziyu Wang, Cheng Wang, Yuxin Zhang', 'link': 'https://arxiv.org/abs/2505.15005', 'abstract': "As autonomous driving technology continues to advance, end-to-end models have attracted considerable attention owing to their superior generalisation capability. Nevertheless, such learning-based systems entail numerous safety risks throughout development and on-road deployment, and existing safety-analysis methods struggle to identify these risks comprehensively. To address this gap, we propose the Unified System Theoretic Process Analysis (UniSTPA) framework, which extends the scope of STPA from the operational phase to the entire lifecycle of an end-to-end autonomous driving system, including information gathering, data preparation, closed loop training, verification, and deployment. UniSTPA performs hazard analysis not only at the component level but also within the model's internal layers, thereby enabling fine-grained assessment of inter and intra module interactions. Using a highway Navigate on Autopilot function as a case study, UniSTPA uncovers multi-stage hazards overlooked by conventional approaches including scene design defects, sensor fusion biases, and internal model flaws, through multi-level causal analysis, traces these hazards to deeper issues such as data quality, network architecture, and optimisation objectives. The analysis result are used to construct a safety monitoring and safety response mechanism that supports continuous improvement from hazard identification to system optimisation. The proposed framework thus offers both theoretical and practical guidance for the safe development and deployment of end-to-end autonomous driving systems.", 'abstract_zh': '随着自动驾驶技术的不断进步，端到端模型由于其卓越的泛化能力而备受关注。然而，此类基于学习的系统在开发和实际道路部署过程中存在众多安全风险，现有安全分析方法难以全面识别这些风险。为解决这一问题，我们提出了统一系统理论过程分析（UniSTPA）框架，该框架将系统理论过程分析（STPA）的范围从运行阶段扩展到端到端自动驾驶系统的整个生命周期，包括信息收集、数据准备、闭环训练、验证和部署。UniSTPA 不仅在组件级别，还在模型内部层面上进行危害分析，从而实现模块间及模块内交互的精细评估。通过多级因果分析，UniSTPA 揭示了传统方法忽略的多阶段危害，包括场景设计缺陷、传感器融合偏差和内部模型缺陷，并将这些危害追溯到更深层次的问题，如数据质量、网络架构和优化目标。分析结果用于构建支持从危害识别到系统优化的持续改进的安全监控和安全响应机制。因此，所提出的框架为端到端自动驾驶系统的安全开发和部署提供了理论和实践指导。', 'title_zh': 'UniSTPA: 一端到一端自主驾驶的安全分析框架'}
{'arxiv_id': 'arXiv:2505.14935', 'title': 'PCA-DDReach: Efficient Statistical Reachability Analysis of Stochastic Dynamical Systems via Principal Component Analysis', 'authors': 'Navid Hashemi, Lars Lindemann, Jyotirmoy Deshmukh', 'link': 'https://arxiv.org/abs/2505.14935', 'abstract': 'This study presents a scalable data-driven algorithm designed to efficiently address the challenging problem of reachability analysis. Analysis of cyber-physical systems (CPS) relies typically on parametric physical models of dynamical systems. However, identifying parametric physical models for complex CPS is challenging due to their complexity, uncertainty, and variability, often rendering them as black-box oracles. As an alternative, one can treat these complex systems as black-box models and use trajectory data sampled from the system (e.g., from high-fidelity simulators or the real system) along with machine learning techniques to learn models that approximate the underlying dynamics. However, these machine learning models can be inaccurate, highlighting the need for statistical tools to quantify errors. Recent advancements in the field include the incorporation of statistical uncertainty quantification tools such as conformal inference (CI) that can provide probabilistic reachable sets with provable guarantees. Recent work has even highlighted the ability of these tools to address the case where the distribution of trajectories sampled during training time are different from the distribution of trajectories encountered during deployment time. However, accounting for such distribution shifts typically results in more conservative guarantees. This is undesirable in practice and motivates us to present techniques that can reduce conservatism. Here, we propose a new approach that reduces conservatism and improves scalability by combining conformal inference with Principal Component Analysis (PCA). We show the effectiveness of our technique on various case studies, including a 12-dimensional quadcopter and a 27-dimensional hybrid system known as the powertrain.', 'abstract_zh': '基于配准推理与主成分分析的可达性分析可扩展算法研究', 'title_zh': 'PCA-DDReach：通过主成分分析高效统计可达性分析的随机动力学系统方法'}
{'arxiv_id': 'arXiv:2505.14805', 'title': 'Integrating Field of View in Human-Aware Collaborative Planning', 'authors': 'Ya-Chuan Hsu, Michael Defranco, Rutvik Patel, Stefanos Nikolaidis', 'link': 'https://arxiv.org/abs/2505.14805', 'abstract': "In human-robot collaboration (HRC), it is crucial for robot agents to consider humans' knowledge of their surroundings. In reality, humans possess a narrow field of view (FOV), limiting their perception. However, research on HRC often overlooks this aspect and presumes an omniscient human collaborator. Our study addresses the challenge of adapting to the evolving subtask intent of humans while accounting for their limited FOV. We integrate FOV within the human-aware probabilistic planning framework. To account for large state spaces due to considering FOV, we propose a hierarchical online planner that efficiently finds approximate solutions while enabling the robot to explore low-level action trajectories that enter the human FOV, influencing their intended subtask. Through user study with our adapted cooking domain, we demonstrate our FOV-aware planner reduces human's interruptions and redundant actions during collaboration by adapting to human perception limitations. We extend these findings to a virtual reality kitchen environment, where we observe similar collaborative behaviors.", 'abstract_zh': '在人机协作（HRC）中，机器人代理考虑人类对环境的知识至关重要。实际上，人类具有狭窄的视场（FOV），限制了其感知能力。然而，HRC相关的研究往往忽视了这一方面，并假设人类合作者无所不知。我们的研究致力于在考虑人类有限FOV的情况下，适应人类不断演变的任务意图的挑战。我们将在人类意识的概率规划框架中整合FOV。为了解决由于考虑FOV而导致的大型状态空间问题，我们提出了一个分层在线规划器，在高效寻找近似解的同时，使机器人能够探索进入人类FOV的低级动作轨迹，进而影响其预期的子任务。通过在我们调整后的烹饪领域中的用户研究，我们证明了FOV意识的规划器通过适应人类感知限制，减少了人类在协作过程中的中断和冗余动作。我们将这些发现扩展到虚拟现实厨房环境中，观察到了相似的合作行为。', 'title_zh': '将视野范围整合到人类意识协同规划中'}
{'arxiv_id': 'arXiv:2505.15754', 'title': 'Improving planning and MBRL with temporally-extended actions', 'authors': 'Palash Chatterjee, Roni Khardon', 'link': 'https://arxiv.org/abs/2505.15754', 'abstract': 'Continuous time systems are often modeled using discrete time dynamics but this requires a small simulation step to maintain accuracy. In turn, this requires a large planning horizon which leads to computationally demanding planning problems and reduced performance. Previous work in model free reinforcement learning has partially addressed this issue using action repeats where a policy is learned to determine a discrete action duration. Instead we propose to control the continuous decision timescale directly by using temporally-extended actions and letting the planner treat the duration of the action as an additional optimization variable along with the standard action variables. This additional structure has multiple advantages. It speeds up simulation time of trajectories and, importantly, it allows for deep horizon search in terms of primitive actions while using a shallow search depth in the planner. In addition, in the model based reinforcement learning (MBRL) setting, it reduces compounding errors from model learning and improves training time for models. We show that this idea is effective and that the range for action durations can be automatically selected using a multi-armed bandit formulation and integrated into the MBRL framework. An extensive experimental evaluation both in planning and in MBRL, shows that our approach yields faster planning, better solutions, and that it enables solutions to problems that are not solved in the standard formulation.', 'abstract_zh': '连续时间系统通常使用离散时间动力学建模，但这需要较小的仿真步长以保持准确性。这反过来又要求较长的规划时段，导致计算复杂度高的规划问题并降低性能。无模型强化学习的先前工作部分解决了这一问题，通过动作重播让策略确定离散的动作持续时间。相反，我们直接控制连续的决策时间尺度，通过使用时间扩展的动作让规划器将动作持续时间作为额外的优化变量，与标准的动作变量一起处理。这种额外的结构具有多方面的好处。它加速了轨迹仿真时间，更重要的是，它允许在基础动作方面进行深度前瞻性搜索，而在规划器方面使用浅层搜索深度。此外，在模型基于强化学习（MBRL）设置中，它减少了模型学习中的累积误差并提高了模型的训练时间。我们展示了这一想法的有效性，并且可以使用多臂 bandit 公式自动选择动作持续时间的范围并将其整合到 MBRL 框架中。广泛的实验评估表明，我们的方法可以实现更快的规划、更好的解决方案，并且可以解决标准表述无法解决的问题。', 'title_zh': '改进规划和基于模型的强化学习中的时间延长动作'}
{'arxiv_id': 'arXiv:2505.15418', 'title': 'Guided Policy Optimization under Partial Observability', 'authors': 'Yueheng Li, Guangming Xie, Zongqing Lu', 'link': 'https://arxiv.org/abs/2505.15418', 'abstract': "Reinforcement Learning (RL) in partially observable environments poses significant challenges due to the complexity of learning under uncertainty. While additional information, such as that available in simulations, can enhance training, effectively leveraging it remains an open problem. To address this, we introduce Guided Policy Optimization (GPO), a framework that co-trains a guider and a learner. The guider takes advantage of privileged information while ensuring alignment with the learner's policy that is primarily trained via imitation learning. We theoretically demonstrate that this learning scheme achieves optimality comparable to direct RL, thereby overcoming key limitations inherent in existing approaches. Empirical evaluations show strong performance of GPO across various tasks, including continuous control with partial observability and noise, and memory-based challenges, significantly outperforming existing methods.", 'abstract_zh': '部分可观测环境中强化学习（RL）由于在不确定性下的学习复杂性而面临重大挑战。虽然额外的信息，如模拟中可用的信息，可以增强训练，但有效利用这些信息仍然是一个开放问题。为了解决这一问题，我们提出了一种引导策略优化（GPO）框架，该框架通过共同训练一个引导器和一个学习器来利用额外信息，同时确保引导器与主要通过模仿学习训练的学习器策略保持一致。理论上证明，这种学习方案在实现直接RL相当的最优性方面克服了现有方法的关键局限。实证评估显示，GPO在各种任务中表现强劲，包括连续控制下的部分可观测性和噪声挑战以及基于记忆的挑战，显著优于现有方法。', 'title_zh': '部分可观测性下的引导策略优化'}
{'arxiv_id': 'arXiv:2505.14975', 'title': 'Flattening Hierarchies with Policy Bootstrapping', 'authors': 'John L. Zhou, Jonathan C. Kao', 'link': 'https://arxiv.org/abs/2505.14975', 'abstract': 'Offline goal-conditioned reinforcement learning (GCRL) is a promising approach for pretraining generalist policies on large datasets of reward-free trajectories, akin to the self-supervised objectives used to train foundation models for computer vision and natural language processing. However, scaling GCRL to longer horizons remains challenging due to the combination of sparse rewards and discounting, which obscures the comparative advantages of primitive actions with respect to distant goals. Hierarchical RL methods achieve strong empirical results on long-horizon goal-reaching tasks, but their reliance on modular, timescale-specific policies and subgoal generation introduces significant additional complexity and hinders scaling to high-dimensional goal spaces. In this work, we introduce an algorithm to train a flat (non-hierarchical) goal-conditioned policy by bootstrapping on subgoal-conditioned policies with advantage-weighted importance sampling. Our approach eliminates the need for a generative model over the (sub)goal space, which we find is key for scaling to high-dimensional control in large state spaces. We further show that existing hierarchical and bootstrapping-based approaches correspond to specific design choices within our derivation. Across a comprehensive suite of state- and pixel-based locomotion and manipulation benchmarks, our method matches or surpasses state-of-the-art offline GCRL algorithms and scales to complex, long-horizon tasks where prior approaches fail.', 'abstract_zh': '离线目标导向的强化学习（GCRL）：一种适用于大规模无奖励轨迹预训练的一般性策略的方法', 'title_zh': '用策略Bootstrapping扁平化层级结构'}
{'arxiv_id': 'arXiv:2505.15742', 'title': 'Neuro-Argumentative Learning with Case-Based Reasoning', 'authors': 'Adam Gould, Francesca Toni', 'link': 'https://arxiv.org/abs/2505.15742', 'abstract': 'We introduce Gradual Abstract Argumentation for Case-Based Reasoning (Gradual AA-CBR), a data-driven, neurosymbolic classification model in which the outcome is determined by an argumentation debate structure that is learned simultaneously with neural-based feature extractors. Each argument in the debate is an observed case from the training data, favouring their labelling. Cases attack or support those with opposing or agreeing labellings, with the strength of each argument and relationship learned through gradient-based methods. This argumentation debate structure provides human-aligned reasoning, improving model interpretability compared to traditional neural networks (NNs). Unlike the existing purely symbolic variant, Abstract Argumentation for Case-Based Reasoning (AA-CBR), Gradual AA-CBR is capable of multi-class classification, automatic learning of feature and data point importance, assigning uncertainty values to outcomes, using all available data points, and does not require binary features. We show that Gradual AA-CBR performs comparably to NNs whilst significantly outperforming existing AA-CBR formulations.', 'abstract_zh': '渐进抽象论证に基づく案例基于推理（渐进AA-CBR）：一种数据驱动的神经符号分类模型', 'title_zh': '基于案例推理的神经论辩学习'}
{'arxiv_id': 'arXiv:2505.15693', 'title': 'Average Reward Reinforcement Learning for Omega-Regular and Mean-Payoff Objectives', 'authors': 'Milad Kazemi, Mateo Perez, Fabio Somenzi, Sadegh Soudjani, Ashutosh Trivedi, Alvaro Velasquez', 'link': 'https://arxiv.org/abs/2505.15693', 'abstract': 'Recent advances in reinforcement learning (RL) have renewed focus on the design of reward functions that shape agent behavior. Manually designing reward functions is tedious and error-prone. A principled alternative is to specify behaviors in a formal language that can be automatically translated into rewards. Omega-regular languages are a natural choice for this purpose, given their established role in formal verification and synthesis. However, existing methods using omega-regular specifications typically rely on discounted reward RL in episodic settings, with periodic resets. This setup misaligns with the semantics of omega-regular specifications, which describe properties over infinite behavior traces. In such cases, the average reward criterion and the continuing setting -- where the agent interacts with the environment over a single, uninterrupted lifetime -- are more appropriate.\nTo address the challenges of infinite-horizon, continuing tasks, we focus on absolute liveness specifications -- a subclass of omega-regular languages that cannot be violated by any finite behavior prefix, making them well-suited to the continuing setting. We present the first model-free RL framework that translates absolute liveness specifications to average-reward objectives. Our approach enables learning in communicating MDPs without episodic resetting. We also introduce a reward structure for lexicographic multi-objective optimization, aiming to maximize an external average-reward objective among the policies that also maximize the satisfaction probability of a given omega-regular specification. Our method guarantees convergence in unknown communicating MDPs and supports on-the-fly reductions that do not require full knowledge of the environment, thus enabling model-free RL. Empirical results show our average-reward approach in continuing setting outperforms discount-based methods across benchmarks.', 'abstract_zh': '近期强化学习的进步重新引发了对奖励函数设计的关注，以塑造代理行为。手动设计奖励函数既繁琐又容易出错。一种原则性替代方案是使用形式语言规范行为，进而自动将其转换为奖励。Ω-正规语言是这一目的的自然选择，因为它在形式验证和合成中已确立了重要作用。然而，现有的使用Ω-正规规范的方法通常依赖于折扣奖励的强化学习，在周期性重置的阶段性设置中进行。这种设置与Ω-正规规范的语义不符，后者描述的是无限行为轨迹上的性质。在这种情况下，绝对奖励标准和连续设置——代理在单一、不间断的生命周期中与环境交互——更为合适。\n\n为了解决无限 horizon、连续任务的挑战，我们将重点放在绝对活生生规范上——一类Ω-正规语言的子集，任何有限行为前缀都不能违背它们，使它们非常适合连续设置。我们提出了第一个无模型的强化学习框架，将绝对活生生规范转换为平均奖励目标。我们的方法能够在无需阶段性重置的通信MDP中实现学习。我们还引入了一种奖励结构，用于多目标优化的字典序优化，旨在在最大化给定Ω-正规规范的满足概率的同时最大化外部平均奖励目标。我们的方法在未知通信MDP中保证收敛，并支持无需完全了解环境的即时减少，从而实现无模型的强化学习。实验结果表明，我们的平均奖励方法在连续设置中的表现优于基于折扣的方法。', 'title_zh': '欧米伽正则和平均收益目标的平均奖励强化学习'}
{'arxiv_id': 'arXiv:2505.15274', 'title': 'Identification of Probabilities of Causation: A Complete Characterization', 'authors': 'Xin Shu, Shuai Wang, Ang Li', 'link': 'https://arxiv.org/abs/2505.15274', 'abstract': "Probabilities of causation are fundamental to modern decision-making. Pearl first introduced three binary probabilities of causation, and Tian and Pearl later derived tight bounds for them using Balke's linear programming. The theoretical characterization of probabilities of causation with multi-valued treatments and outcomes has remained unresolved for decades, limiting the scope of causality-based decision-making. In this paper, we resolve this foundational gap by proposing a complete set of representative probabilities of causation and proving that they are sufficient to characterize all possible probabilities of causation within the framework of Structural Causal Models (SCMs). We then formally derive tight bounds for these representative quantities using formal mathematical proofs. Finally, we demonstrate the practical relevance of our results through illustrative toy examples.", 'abstract_zh': '因果概率是现代决策的基础。Pearl首先引入了三种二值因果概率，Tian和Pearl后来使用Balke的线性规划推导出它们的确切边界。多值处理和结果的因果概率的理论刻画已困扰学术界数十年，限制了基于因果性的决策范围。本文通过提出一套完整的代表性因果概率并证明它们在结构因果模型（SCM）框架内足以表征所有可能的因果概率，解决了这一基础缺口。我们随后使用正式的数学证明形式地推导出这些代表性数量的确切边界。最后，通过举例说明我们结果的实际相关性。', 'title_zh': '因果概率的识别：完全刻画'}
{'arxiv_id': 'arXiv:2505.15011', 'title': 'HAVA: Hybrid Approach to Value-Alignment through Reward Weighing for Reinforcement Learning', 'authors': 'Kryspin Varys, Federico Cerutti, Adam Sobey, Timothy J. Norman', 'link': 'https://arxiv.org/abs/2505.15011', 'abstract': "Our society is governed by a set of norms which together bring about the values we cherish such as safety, fairness or trustworthiness. The goal of value-alignment is to create agents that not only do their tasks but through their behaviours also promote these values. Many of the norms are written as laws or rules (legal / safety norms) but even more remain unwritten (social norms). Furthermore, the techniques used to represent these norms also differ. Safety / legal norms are often represented explicitly, for example, in some logical language while social norms are typically learned and remain hidden in the parameter space of a neural network. There is a lack of approaches in the literature that could combine these various norm representations into a single algorithm. We propose a novel method that integrates these norms into the reinforcement learning process. Our method monitors the agent's compliance with the given norms and summarizes it in a quantity we call the agent's reputation. This quantity is used to weigh the received rewards to motivate the agent to become value-aligned. We carry out a series of experiments including a continuous state space traffic problem to demonstrate the importance of the written and unwritten norms and show how our method can find the value-aligned policies. Furthermore, we carry out ablations to demonstrate why it is better to combine these two groups of norms rather than using either separately.", 'abstract_zh': '我们的社会由一系列规范治理，这些规范共同构成了我们珍视的价值观，如安全、公平或诚信。价值对齐的目标是创造不仅完成任务，而且通过其行为促进这些价值观的智能代理。许多规范表现为法律或规则（法律/安全规范），但更多的则为不成文的社会规范。此外，用于表示这些规范的技术也不同。安全/法律规范通常被明确表示，例如，用某种逻辑语言来表达，而社会规范通常通过学习获得，并隐含在神经网络的参数空间中。文献中缺乏将这些不同形式的规范整合到单一算法中的方法。我们提出了一种新的方法，将这些规范整合到强化学习过程中。该方法监控代理遵守规范的情况，并将其总结为一个我们称为代理声誉的数量。该数量用于加权收到的奖励，以激励代理变得价值对齐。我们进行了一系列实验，包括连续状态空间交通问题，以说明书面和不成文规范的重要性，并展示我们的方法如何找到价值对齐的策略。此外，我们进行了消融实验，以证明为什么组合这两类规范比单独使用更有优势。', 'title_zh': 'HAVA: 混合价值对齐方法通过奖励加权在强化学习中的应用'}
{'arxiv_id': 'arXiv:2505.14940', 'title': 'To Be or Not To Be: Vector ontologies as a truly formal ontological framework', 'authors': 'Kaspar Rothenfusser', 'link': 'https://arxiv.org/abs/2505.14940', 'abstract': 'Since Edmund Husserl coined the term "Formal Ontologies" in the early 20th century, a field that identifies itself with this particular branch of sciences has gained increasing attention. Many authors, and even Husserl himself have developed what they claim to be formal ontologies. I argue that under close inspection, none of these so claimed formal ontologies are truly formal in the Husserlian sense. More concretely, I demonstrate that they violate the two most important notions of formal ontology as developed in Husserl\'s Logical Investigations, namely a priori validity independent of perception and formalism as the total absence of content. I hence propose repositioning the work previously understood as formal ontology as the foundational ontology it really is. This is to recognize the potential of a truly formal ontology in the Husserlian sense. Specifically, I argue that formal ontology following his conditions, allows us to formulate ontological structures, which could capture what is more objectively without presupposing a particular framework arising from perception. I further argue that the ability to design the formal structure deliberately allows us to create highly scalable and interoperable information artifacts. As concrete evidence, I showcase that a class of formal ontology, which uses the axioms of vector spaces, is able to express most of the conceptualizations found in foundational ontologies. Most importantly, I argue that many information systems, specifically artificial intelligence, are likely already using some type of vector ontologies to represent reality in their internal worldviews and elaborate on the evidence that humans do as well. I hence propose a thorough investigation of the ability of vector ontologies to act as a human-machine interoperable ontological framework that allows us to understand highly sophisticated machines and machines to understand us.', 'abstract_zh': '自埃德蒙·胡塞尔在20世纪初提出“形式本体论”这一术语以来，一个以这一特定科学分支为标志的领域受到了日益关注。许多作者，甚至胡塞尔本人，都发展了他们声称的形式本体论。在我看来，在仔细审视之下，这些所谓的形式本体论都不符合胡塞尔意义上的“形式”。更具体地说，我证明它们违背了胡塞尔在《逻辑探究》中发展出的形式本体论的两个最重要的概念，即独立于感知的先验有效性以及形式化为完全不含内容的状态。因此，我建议将先前被认为是形式本体论的工作重新定位为真正的基础本体论。这一重新定位旨在认可在胡塞尔意义上真正形式本体论的潜力。具体而言，我主张符合胡塞尔条件的形式本体论使我们能够构建能够客观地捕捉概念而不预设特定感知框架的本体结构。进一步而言，我主张有意图地设计形式结构的能力使我们能够创建高度可扩展且互操作的信息实体。作为具体证据，我展示了使用向量空间公理的一类形式本体能够表达基础本体中大多数的概念化内容。最重要的是，我主张许多信息系统，特别是人工智能系统，很可能已经在其内部世界观中使用某种类型的向量本体来表示现实，人类也可能是如此。因此，我建议深入研究向量本体的能力，使其成为一种人机可互操作的本体框架，使我们能够理解高度复杂的机器，同时也使机器能够理解人类。', 'title_zh': '是与不是：向量本体作为真正形式化的本体框架'}
{'arxiv_id': 'arXiv:2505.14689', 'title': 'Follow the STARs: Dynamic $ω$-Regular Shielding of Learned Policies', 'authors': 'Ashwani Anand, Satya Prakash Nayak, Ritam Raha, Anne-Kathrin Schmuck', 'link': 'https://arxiv.org/abs/2505.14689', 'abstract': 'This paper presents a novel dynamic post-shielding framework that enforces the full class of $\\omega$-regular correctness properties over pre-computed probabilistic policies. This constitutes a paradigm shift from the predominant setting of safety-shielding -- i.e., ensuring that nothing bad ever happens -- to a shielding process that additionally enforces liveness -- i.e., ensures that something good eventually happens. At the core, our method uses Strategy-Template-based Adaptive Runtime Shields (STARs), which leverage permissive strategy templates to enable post-shielding with minimal interference. As its main feature, STARs introduce a mechanism to dynamically control interference, allowing a tunable enforcement parameter to balance formal obligations and task-specific behavior at runtime. This allows to trigger more aggressive enforcement when needed, while allowing for optimized policy choices otherwise. In addition, STARs support runtime adaptation to changing specifications or actuator failures, making them especially suited for cyber-physical applications. We evaluate STARs on a mobile robot benchmark to demonstrate their controllable interference when enforcing (incrementally updated) $\\omega$-regular correctness properties over learned probabilistic policies.', 'abstract_zh': '本文提出了一种新颖的动态后屏蔽框架，该框架在预先计算的概率策略上强制执行所有类ω-正规正确性属性。这代表了从当前占主导地位的安全屏蔽范式——即确保什么都不会坏——向一种在确保好事最终发生的同时进行屏蔽的过程的转变。核心上，我们的方法使用基于策略模板的自适应运行时屏蔽（STARs），利用宽松策略模板来实现最少干扰的后屏蔽。STARs的主要特征是引入了一种动态控制干扰的机制，允许在运行时通过可调的强制执行参数平衡形式义务和任务特定行为。这使得在需要时可以触发更严格的强制执行，而在其他情况下可以选择优化策略选择。此外，STARs支持运行时针对变化的规范或执行器故障进行适应，使它们特别适合于网络物理应用。我们在一个移动机器人基准测试中评估了STARs，以证明其在强制执行（逐步更新的）ω-正规正确性属性时可控的干扰。', 'title_zh': '遵循STARs：动态ω-正则屏蔽学习策略'}
{'arxiv_id': 'arXiv:2505.15808', 'title': 'Neural Conditional Transport Maps', 'authors': 'Carlos Rodriguez-Pardo, Leonardo Chiani, Emanuele Borgonovo, Massimo Tavoni', 'link': 'https://arxiv.org/abs/2505.15808', 'abstract': 'We present a neural framework for learning conditional optimal transport (OT) maps between probability distributions. Our approach introduces a conditioning mechanism capable of processing both categorical and continuous conditioning variables simultaneously. At the core of our method lies a hypernetwork that generates transport layer parameters based on these inputs, creating adaptive mappings that outperform simpler conditioning methods. Comprehensive ablation studies demonstrate the superior performance of our method over baseline configurations. Furthermore, we showcase an application to global sensitivity analysis, offering high performance in computing OT-based sensitivity indices. This work advances the state-of-the-art in conditional optimal transport, enabling broader application of optimal transport principles to complex, high-dimensional domains such as generative modeling and black-box model explainability.', 'abstract_zh': '一种学习条件最优运输映射的神经框架：同时处理分类和连续条件变量', 'title_zh': '神经条件性输运映射'}
{'arxiv_id': 'arXiv:2505.15792', 'title': 'Long-Form Information Alignment Evaluation Beyond Atomic Facts', 'authors': 'Danna Zheng, Mirella Lapata, Jeff Z. Pan', 'link': 'https://arxiv.org/abs/2505.15792', 'abstract': 'Information alignment evaluators are vital for various NLG evaluation tasks and trustworthy LLM deployment, reducing hallucinations and enhancing user trust. Current fine-grained methods, like FactScore, verify facts individually but neglect inter-fact dependencies, enabling subtle vulnerabilities. In this work, we introduce MontageLie, a challenging benchmark that constructs deceptive narratives by "montaging" truthful statements without introducing explicit hallucinations. We demonstrate that both coarse-grained LLM-based evaluators and current fine-grained frameworks are susceptible to this attack, with AUC-ROC scores falling below 65%. To enable more robust fine-grained evaluation, we propose DoveScore, a novel framework that jointly verifies factual accuracy and event-order consistency. By modeling inter-fact relationships, DoveScore outperforms existing fine-grained methods by over 8%, providing a more robust solution for long-form text alignment evaluation. Our code and datasets are available at this https URL.', 'abstract_zh': '信息对齐评估器对于各种NLG评估任务和可信赖的大语言模型部署至关重要，能够减少幻觉并增强用户信任。当前的细粒度方法，如FactScore，单独验证事实但忽略了事实之间的依赖关系，从而允许潜在的漏洞。在本工作中，我们引入了MontageLie基准，通过“拼接”真实陈述构建欺骗性叙事，而不引入明显的幻觉。我们证明了粗粒度的基于大语言模型的评估器和当前的细粒度框架都对这种攻击敏感，AUC-ROC得分低于65%。为了实现更稳健的细粒度评估，我们提出了DoveScore，这是一种新的框架，可以同时验证事实准确性与时序一致性。通过建模事实之间的关系，DoveScore在现有细粒度方法的基础上提高了超过8%的表现，为长文本对齐评估提供了更稳健的解决方案。我们的代码和数据集可在以下链接获取。', 'title_zh': '长文本信息一致性评估超越原子事实'}
{'arxiv_id': 'arXiv:2505.15790', 'title': 'Exploring the Innovation Opportunities for Pre-trained Models', 'authors': 'Minjung Park, Jodi Forlizzi, John Zimmerman', 'link': 'https://arxiv.org/abs/2505.15790', 'abstract': "Innovators transform the world by understanding where services are successfully meeting customers' needs and then using this knowledge to identify failsafe opportunities for innovation. Pre-trained models have changed the AI innovation landscape, making it faster and easier to create new AI products and services. Understanding where pre-trained models are successful is critical for supporting AI innovation. Unfortunately, the hype cycle surrounding pre-trained models makes it hard to know where AI can really be successful. To address this, we investigated pre-trained model applications developed by HCI researchers as a proxy for commercially successful applications. The research applications demonstrate technical capabilities, address real user needs, and avoid ethical challenges. Using an artifact analysis approach, we categorized capabilities, opportunity domains, data types, and emerging interaction design patterns, uncovering some of the opportunity space for innovation with pre-trained models.", 'abstract_zh': '创新者通过理解服务如何成功满足客户的需求，并利用这些知识识别预训练模型领域的安全创新机会，从而改变世界。预训练模型改变了AI创新的格局，使其更快、更容易创建新的AI产品和服务。了解预训练模型成功的地方对于支持AI创新至关重要。不幸的是，围绕预训练模型的 hype 周期使得知道AI在哪里真正取得成功变得困难。为了解决这一问题，我们调查了人机交互研究人员开发的预训练模型应用，作为商业化成功应用的代理。研究应用展示了技术能力，解决了真实用户需求，并避免了伦理挑战。通过实体分析的方法，我们对能力、机会领域、数据类型以及新兴的交互设计模式进行了分类，揭示了预训练模型创新的机会空间。', 'title_zh': '探索预训练模型的创新机遇'}
{'arxiv_id': 'arXiv:2505.15779', 'title': 'IA-T2I: Internet-Augmented Text-to-Image Generation', 'authors': 'Chuanhao Li, Jianwen Sun, Yukang Feng, Mingliang Zhai, Yifan Chang, Kaipeng Zhang', 'link': 'https://arxiv.org/abs/2505.15779', 'abstract': "Current text-to-image (T2I) generation models achieve promising results, but they fail on the scenarios where the knowledge implied in the text prompt is uncertain. For example, a T2I model released in February would struggle to generate a suitable poster for a movie premiering in April, because the character designs and styles are uncertain to the model. To solve this problem, we propose an Internet-Augmented text-to-image generation (IA-T2I) framework to compel T2I models clear about such uncertain knowledge by providing them with reference images. Specifically, an active retrieval module is designed to determine whether a reference image is needed based on the given text prompt; a hierarchical image selection module is introduced to find the most suitable image returned by an image search engine to enhance the T2I model; a self-reflection mechanism is presented to continuously evaluate and refine the generated image to ensure faithful alignment with the text prompt. To evaluate the proposed framework's performance, we collect a dataset named Img-Ref-T2I, where text prompts include three types of uncertain knowledge: (1) known but rare. (2) unknown. (3) ambiguous. Moreover, we carefully craft a complex prompt to guide GPT-4o in making preference evaluation, which has been shown to have an evaluation accuracy similar to that of human preference evaluation. Experimental results demonstrate the effectiveness of our framework, outperforming GPT-4o by about 30% in human evaluation.", 'abstract_zh': '互联网增强的文字到图像生成框架（IA-T2I）', 'title_zh': '基于互联网增强的文本到图像生成'}
{'arxiv_id': 'arXiv:2505.15746', 'title': 'Higher-order Structure Boosts Link Prediction on Temporal Graphs', 'authors': 'Jingzhe Liu, Zhigang Hua, Yan Xie, Bingheng Li, Harry Shomer, Yu Song, Kaveh Hassani, Jiliang Tang', 'link': 'https://arxiv.org/abs/2505.15746', 'abstract': "Temporal Graph Neural Networks (TGNNs) have gained growing attention for modeling and predicting structures in temporal graphs. However, existing TGNNs primarily focus on pairwise interactions while overlooking higher-order structures that are integral to link formation and evolution in real-world temporal graphs. Meanwhile, these models often suffer from efficiency bottlenecks, further limiting their expressive power. To tackle these challenges, we propose a Higher-order structure Temporal Graph Neural Network, which incorporates hypergraph representations into temporal graph learning. In particular, we develop an algorithm to identify the underlying higher-order structures, enhancing the model's ability to capture the group interactions. Furthermore, by aggregating multiple edge features into hyperedge representations, HTGN effectively reduces memory cost during training. We theoretically demonstrate the enhanced expressiveness of our approach and validate its effectiveness and efficiency through extensive experiments on various real-world temporal graphs. Experimental results show that HTGN achieves superior performance on dynamic link prediction while reducing memory costs by up to 50\\% compared to existing methods.", 'abstract_zh': '高阶结构时序图神经网络（HTGNs）：融合超图表示以建模和预测时序图中的结构与演化', 'title_zh': '高阶结构提升-temporal图上的链接预测'}
{'arxiv_id': 'arXiv:2505.15694', 'title': 'A Unified Theoretical Analysis of Private and Robust Offline Alignment: from RLHF to DPO', 'authors': 'Xingyu Zhou, Yulian Wu, Francesco Orabona', 'link': 'https://arxiv.org/abs/2505.15694', 'abstract': 'In this paper, we theoretically investigate the effects of noisy labels in offline alignment, with a focus on the interplay between privacy and robustness against adversarial corruption. Specifically, under linear modeling assumptions, we present a unified analysis covering both reinforcement learning from human feedback (RLHF) and direct preference optimization (DPO) under different privacy-corruption scenarios, such as Local differential privacy-then-Corruption (LTC), where human preference labels are privatized before being corrupted by an adversary, and Corruption-then-Local differential privacy (CTL), where labels are corrupted before privacy protection. Our analysis leverages a reduction framework that reduces the offline alignment problem under linear modeling assumptions to parameter estimation in logistic regression. This framework allows us to establish an interesting separation result between LTC and CTL, demonstrating that LTC presents a greater challenge than CTL in offline alignment, even under linear models. As important by-products, our findings also advance the state-of-the-art theoretical results in offline alignment under privacy-only or corruption-only scenarios.', 'abstract_zh': '在本论文中，我们从理论上研究了离线对齐中噪声标签的影响，重点关注隐私与对抗性腐蚀鲁棒性之间的交互作用。具体而言，在线性建模假设下，我们对局部差分隐私后再腐蚀（LTC）和先腐蚀再局部差分隐私（CTL）等不同隐私-腐蚀场景下的强化学习从人类反馈（RLHF）和直接偏好优化（DPO）进行了统一分析。我们的分析利用了一个约简框架，将在线性建模假设下的离线对齐问题约化为逻辑回归中的参数估计问题。该框架使我们能够建立LTC和CTL之间有趣的分离结果，即使在在线性模型下，LTC也比CTL在离线对齐中更具挑战性。作为重要的副产品，我们的发现还在仅隐私或仅腐蚀场景下的离线对齐的最先进理论结果方面有所推进。', 'title_zh': '统一的理论分析：私人和 robust 离线对齐从 RLHF 到 DPO'}
{'arxiv_id': 'arXiv:2505.15671', 'title': 'Enhancing Monte Carlo Dropout Performance for Uncertainty Quantification', 'authors': 'Hamzeh Asgharnezhad, Afshar Shamsi, Roohallah Alizadehsani, Arash Mohammadi, Hamid Alinejad-Rokny', 'link': 'https://arxiv.org/abs/2505.15671', 'abstract': 'Knowing the uncertainty associated with the output of a deep neural network is of paramount importance in making trustworthy decisions, particularly in high-stakes fields like medical diagnosis and autonomous systems. Monte Carlo Dropout (MCD) is a widely used method for uncertainty quantification, as it can be easily integrated into various deep architectures. However, conventional MCD often struggles with providing well-calibrated uncertainty estimates. To address this, we introduce innovative frameworks that enhances MCD by integrating different search solutions namely Grey Wolf Optimizer (GWO), Bayesian Optimization (BO), and Particle Swarm Optimization (PSO) as well as an uncertainty-aware loss function, thereby improving the reliability of uncertainty quantification. We conduct comprehensive experiments using different backbones, namely DenseNet121, ResNet50, and VGG16, on various datasets, including Cats vs. Dogs, Myocarditis, Wisconsin, and a synthetic dataset (Circles). Our proposed algorithm outperforms the MCD baseline by 2-3% on average in terms of both conventional accuracy and uncertainty accuracy while achieving significantly better calibration. These results highlight the potential of our approach to enhance the trustworthiness of deep learning models in safety-critical applications.', 'abstract_zh': '了解与深度神经网络输出相关的不确定性对于在医疗诊断和自主系统等高风险领域做出可信赖的决策至关重要。为了解决传统蒙特卡洛Dropout (MCD) 提供校准不确定性估计的挑战，我们提出了通过集成灰狼优化器（GWO）、贝叶斯优化（BO）、粒子 swarm 优化（PSO）和一种新的不确定性感知损失函数来增强MCD的创新框架。我们的实验证实在不同骨干网络（DenseNet121、ResNet50和VGG16）和多个数据集（Cats vs. Dogs、Myocarditis、Wisconsin和合成数据集Circles）上，提出的算法在传统准确性和不确定性准确性的综合表现上比MCD基线平均高出2-3%，并且在校准方面表现出显著改善。这些结果表明，我们的方法有可能增强深度学习模型在安全关键应用中的可信赖性。', 'title_zh': '增强蒙特卡洛dropout方法以提高不确定性量化性能'}
{'arxiv_id': 'arXiv:2505.15662', 'title': 'Neural Quantum Digital Twins for Optimizing Quantum Annealing', 'authors': 'Jianlong Lu, Hanqiu Peng, Ying Chen', 'link': 'https://arxiv.org/abs/2505.15662', 'abstract': 'Quantum annealers have shown potential in addressing certain combinatorial optimization problems, though their performance is often limited by scalability and errors rates. In this work, we propose a Neural Quantum Digital Twin (NQDT) framework that reconstructs the energy landscape of quantum many-body systems relevant to quantum annealing. The digital twin models both ground and excited state dynamics, enabling detailed simulation of the adiabatic evolution process. We benchmark NQDT on systems with known analytical solutions and demonstrate that it accurately captures key quantum phenomena, including quantum criticality and phase transitions. Leveraging this framework, one can identify optimal annealing schedules that minimize excitation-related errors. These findings highlight the utility of neural network-based digital twins as a diagnostic and optimization tool for improving the performance of quantum annealers.', 'abstract_zh': '量子退火器在解决某些组合优化问题方面展现了潜力，尽管其性能常常受到可扩展性和错误率的限制。本工作中，我们提出了一种神经量子数字孪生（NQDT）框架，用于重构与量子退火相关的量子多体系统的能量景观。数字孪生模型 Both 基态和激发态的动力学，从而实现对绝热演化过程的详细模拟。我们通过已知解析解的系统对 NQDT 进行基准测试，并证明它可以准确捕捉到关键的量子现象，包括量子临界性和相变。利用这一框架，可以识别出减少激发相关错误的最优退火时间表。这些发现突显了基于神经网络的数字孪生作为诊断和优化工具，以提高量子退火器性能的价值。', 'title_zh': '神经量子数字双胞胎用于优化量子退火'}
{'arxiv_id': 'arXiv:2505.15657', 'title': 'LCDB 1.1: A Database Illustrating Learning Curves Are More Ill-Behaved Than Previously Thought', 'authors': 'Cheng Yan, Felix Mohr, Tom Viering', 'link': 'https://arxiv.org/abs/2505.15657', 'abstract': 'Sample-wise learning curves plot performance versus training set size. They are useful for studying scaling laws and speeding up hyperparameter tuning and model selection. Learning curves are often assumed to be well-behaved: monotone (i.e. improving with more data) and convex. By constructing the Learning Curves Database 1.1 (LCDB 1.1), a large-scale database with high-resolution learning curves, we show that learning curves are less often well-behaved than previously thought. Using statistically rigorous methods, we observe significant ill-behavior in approximately 14% of the learning curves, almost twice as much as in previous estimates. We also identify which learners are to blame and show that specific learners are more ill-behaved than others. Additionally, we demonstrate that different feature scalings rarely resolve ill-behavior. We evaluate the impact of ill-behavior on downstream tasks, such as learning curve fitting and model selection, and find it poses significant challenges, underscoring the relevance and potential of LCDB 1.1 as a challenging benchmark for future research.', 'abstract_zh': '样本级别的学习曲线绘制性能与训练集大小的关系。它们对于研究缩放定律并加速超参数调整和模型选择非常有用。通常假定学习曲线行为良好：单调（即更多的数据意味着改进）且凹形。通过构建Learning Curves Database 1.1（LCDB 1.1），一个具有高分辨率学习曲线的大规模数据库，我们证明了与先前认为的相比，学习曲线远不如预期行为良好。使用统计上严谨的方法，我们观察到约14%的学习曲线表现出显著的不良行为，几乎是之前估计的两倍。我们还确定了哪些学习算法是罪魁祸首，并展示了特定的学习算法比其他算法更不良。此外，我们证明不同的特征缩放很少能解决不良行为问题。我们评估了不良行为对下游任务（如学习曲线拟合和模型选择）的影响，并发现这对未来研究构成了显著挑战，突显了LCDB 1.1作为具有挑战性的基准评估的现实意义和潜力。', 'title_zh': 'LCDB 1.1: 一个表明学习曲线比以往认为的更为不良的数据库'}
{'arxiv_id': 'arXiv:2505.15647', 'title': 'Second-Order Convergence in Private Stochastic Non-Convex Optimization', 'authors': 'Youming Tao, Zuyuan Zhang, Dongxiao Yu, Xiuzhen Cheng, Falko Dressler, Di Wang', 'link': 'https://arxiv.org/abs/2505.15647', 'abstract': 'We investigate the problem of finding second-order stationary points (SOSP) in differentially private (DP) stochastic non-convex optimization. Existing methods suffer from two key limitations: (i) inaccurate convergence error rate due to overlooking gradient variance in the saddle point escape analysis, and (ii) dependence on auxiliary private model selection procedures for identifying DP-SOSP, which can significantly impair utility, particularly in distributed settings. To address these issues, we propose a generic perturbed stochastic gradient descent (PSGD) framework built upon Gaussian noise injection and general gradient oracles. A core innovation of our framework is using model drift distance to determine whether PSGD escapes saddle points, ensuring convergence to approximate local minima without relying on second-order information or additional DP-SOSP identification. By leveraging the adaptive DP-SPIDER estimator as a specific gradient oracle, we develop a new DP algorithm that rectifies the convergence error rates reported in prior work. We further extend this algorithm to distributed learning with arbitrarily heterogeneous data, providing the first formal guarantees for finding DP-SOSP in such settings. Our analysis also highlights the detrimental impacts of private selection procedures in distributed learning under high-dimensional models, underscoring the practical benefits of our design. Numerical experiments on real-world datasets validate the efficacy of our approach.', 'abstract_zh': '差分隐私环境下非凸优化中第二阶稳定点的寻找：通用扰动随机梯度下降方法及其应用', 'title_zh': '私有化随机非凸优化的二阶收敛性'}
{'arxiv_id': 'arXiv:2505.15612', 'title': 'Learn to Reason Efficiently with Adaptive Length-based Reward Shaping', 'authors': 'Wei Liu, Ruochen Zhou, Yiyun Deng, Yuzhen Huang, Junteng Liu, Yuntian Deng, Yizhe Zhang, Junxian He', 'link': 'https://arxiv.org/abs/2505.15612', 'abstract': 'Large Reasoning Models (LRMs) have shown remarkable capabilities in solving complex problems through reinforcement learning (RL), particularly by generating long reasoning traces. However, these extended outputs often exhibit substantial redundancy, which limits the efficiency of LRMs. In this paper, we investigate RL-based approaches to promote reasoning efficiency. Specifically, we first present a unified framework that formulates various efficient reasoning methods through the lens of length-based reward shaping. Building on this perspective, we propose a novel Length-bAsed StEp Reward shaping method (LASER), which employs a step function as the reward, controlled by a target length. LASER surpasses previous methods, achieving a superior Pareto-optimal balance between performance and efficiency. Next, we further extend LASER based on two key intuitions: (1) The reasoning behavior of the model evolves during training, necessitating reward specifications that are also adaptive and dynamic; (2) Rather than uniformly encouraging shorter or longer chains of thought (CoT), we posit that length-based reward shaping should be difficulty-aware i.e., it should penalize lengthy CoTs more for easy queries. This approach is expected to facilitate a combination of fast and slow thinking, leading to a better overall tradeoff. The resulting method is termed LASER-D (Dynamic and Difficulty-aware). Experiments on DeepSeek-R1-Distill-Qwen-1.5B, DeepSeek-R1-Distill-Qwen-7B, and DeepSeek-R1-Distill-Qwen-32B show that our approach significantly enhances both reasoning performance and response length efficiency. For instance, LASER-D and its variant achieve a +6.1 improvement on AIME2024 while reducing token usage by 63%. Further analysis reveals our RL-based compression produces more concise reasoning patterns with less redundant "self-reflections". Resources are at this https URL.', 'abstract_zh': '基于强化学习的大推理模型效率提升方法', 'title_zh': '基于自适应长度奖励塑形的有效推理学习'}
{'arxiv_id': 'arXiv:2505.15594', 'title': 'Beyond Classification: Evaluating Diffusion Denoised Smoothing for Security-Utility Trade off', 'authors': 'Yury Belousov, Brian Pulfer, Vitaliy Kinakh, Slava Voloshynovskiy', 'link': 'https://arxiv.org/abs/2505.15594', 'abstract': 'While foundation models demonstrate impressive performance across various tasks, they remain vulnerable to adversarial inputs. Current research explores various approaches to enhance model robustness, with Diffusion Denoised Smoothing emerging as a particularly promising technique. This method employs a pretrained diffusion model to preprocess inputs before model inference. Yet, its effectiveness remains largely unexplored beyond classification. We aim to address this gap by analyzing three datasets with four distinct downstream tasks under three different adversarial attack algorithms. Our findings reveal that while foundation models maintain resilience against conventional transformations, applying high-noise diffusion denoising to clean images without any distortions significantly degrades performance by as high as 57%. Low-noise diffusion settings preserve performance but fail to provide adequate protection across all attack types. Moreover, we introduce a novel attack strategy specifically targeting the diffusion process itself, capable of circumventing defenses in the low-noise regime. Our results suggest that the trade-off between adversarial robustness and performance remains a challenge to be addressed.', 'abstract_zh': '基础模型在各种任务中展现出令人印象深刻的性能，但仍易受对抗输入的影响。现有研究探索了多种增强模型鲁棒性的方法，其中去噪扩散平滑技术尤具前景。该方法利用预训练的扩散模型在模型推理前对输入进行预处理。然而，该方法在分类以外的任务中的有效性尚待充分探索。我们旨在通过在三个数据集上分析四种下游任务和三种不同的对抗攻击算法，来填补这一空白。研究表明，尽管基础模型在传统变换面前保持了韧性，但在干净图像上应用高噪声去噪扩散处理会导致性能下降高达57%。低噪声扩散设置则能够保留性能，但在所有攻击类型的防护上仍不够充分。此外，我们引入了一种针对扩散过程本身的新型攻击策略，能够在低噪声环境下绕过防御措施。我们的结果表明，对抗鲁棒性与性能之间的权衡仍然是一个需要解决的挑战。', 'title_zh': '超越分类：评价去噪扩散平滑的安全-效用权衡评估'}
{'arxiv_id': 'arXiv:2505.15572', 'title': 'Bridging the Domain Gap in Equation Distillation with Reinforcement Feedback', 'authors': 'Wangyang Ying, Haoyue Bai, Nanxu Gong, Xinyuan Wang, Sixun Dong, Haifeng Chen, Yanjie Fu', 'link': 'https://arxiv.org/abs/2505.15572', 'abstract': 'The data-to-equation (Data2Eqn) task aims to discover interpretable mathematical equations that map observed values to labels, offering physical insights and broad applicability across academic and industrial domains. Genetic programming and traditional deep learning-based approaches suffer from search inefficiency and poor generalization on small task-specific datasets. Foundation models showed promise in this area, but existing approaches suffer from: 1) They are pretrained on general-purpose data distributions, making them less effective for domain-specific tasks; and 2) their training objectives focus on token-level alignment, overlooking mathematical semantics, which can lead to inaccurate equations. To address these issues, we aim to enhance the domain adaptability of foundation models for Data2Eqn tasks. In this work, we propose a reinforcement learning-based finetuning framework that directly optimizes the generation policy of a pretrained model through reward signals derived from downstream numerical fitness. Our method allows the model to adapt to specific and complex data distributions and generate mathematically meaningful equations. Extensive experiments demonstrate that our approach improves both the accuracy and robustness of equation generation under complex distributions.', 'abstract_zh': '数据到方程（Data2Eqn）任务旨在发现可解释的数学方程，将观察到的值映射到标签，提供物理洞察并广泛适用于学术和工业领域。遗传编程和传统的基于深度学习的方法在小型任务特定数据集中存在搜索效率低和泛化能力差的问题。基础模型在这方面的应用前景曾被看好，但现有方法面临以下挑战：1）它们在通用数据分布上进行预训练，使其对于特定领域任务效果不佳；2）它们的训练目标集中在token级对齐，忽略了数学语义，可能导致方程不准确。为解决这些问题，我们旨在提升基础模型在Data2Eqn任务中的领域适应性。在本工作中，我们提出了一种基于强化学习的微调框架，通过从下游数值适应性中获取的奖励信号直接优化预训练模型的生成策略。该方法允许模型适应特定且复杂的数据分布，并生成具有数学意义的方程。广泛实验表明，我们的方法在复杂分布下提高了方程生成的准确性和鲁棒性。', 'title_zh': '用强化反馈bridging方程蒸馏领域的差距'}
{'arxiv_id': 'arXiv:2505.15559', 'title': 'Moonbeam: A MIDI Foundation Model Using Both Absolute and Relative Music Attributes', 'authors': 'Zixun Guo, Simon Dixon', 'link': 'https://arxiv.org/abs/2505.15559', 'abstract': 'Moonbeam is a transformer-based foundation model for symbolic music, pretrained on a large and diverse collection of MIDI data totaling 81.6K hours of music and 18 billion tokens. Moonbeam incorporates music-domain inductive biases by capturing both absolute and relative musical attributes through the introduction of a novel domain-knowledge-inspired tokenization method and Multidimensional Relative Attention (MRA), which captures relative music information without additional trainable parameters. Leveraging the pretrained Moonbeam, we propose 2 finetuning architectures with full anticipatory capabilities, targeting 2 categories of downstream tasks: symbolic music understanding and conditional music generation (including music infilling). Our model outperforms other large-scale pretrained music models in most cases in terms of accuracy and F1 score across 3 downstream music classification tasks on 4 datasets. Moreover, our finetuned conditional music generation model outperforms a strong transformer baseline with a REMI-like tokenizer. We open-source the code, pretrained model, and generated samples on Github.', 'abstract_zh': '基于Transformer的Moonbeam符号音乐基础模型：预训练于81,600小时的MIDI数据和180亿个标记，并结合音乐领域先验知识和多维相对注意机制实现音乐属性捕捉', 'title_zh': 'Moonbeam：一种结合绝对和相对音乐属性的MIDI基础模型'}
{'arxiv_id': 'arXiv:2505.15547', 'title': 'Oversmoothing, "Oversquashing", Heterophily, Long-Range, and more: Demystifying Common Beliefs in Graph Machine Learning', 'authors': 'Adrian Arnaiz-Rodriguez, Federico Errica', 'link': 'https://arxiv.org/abs/2505.15547', 'abstract': "After a renaissance phase in which researchers revisited the message-passing paradigm through the lens of deep learning, the graph machine learning community shifted its attention towards a deeper and practical understanding of message-passing's benefits and limitations. In this position paper, we notice how the fast pace of progress around the topics of oversmoothing and oversquashing, the homophily-heterophily dichotomy, and long-range tasks, came with the consolidation of commonly accepted beliefs and assumptions that are not always true nor easy to distinguish from each other. We argue that this has led to ambiguities around the investigated problems, preventing researchers from focusing on and addressing precise research questions while causing a good amount of misunderstandings. Our contribution wants to make such common beliefs explicit and encourage critical thinking around these topics, supported by simple but noteworthy counterexamples. The hope is to clarify the distinction between the different issues and promote separate but intertwined research directions to address them.", 'abstract_zh': '关于过平滑、过压缩、同质性-异质性二分法及长范围任务的快速进展所伴随的共识性信念与假设的澄清：促进批判性思考与明确研究方向', 'title_zh': '过度平滑化、“过度挤压”、异质性、长范围连接及其更多：图机器学习中常见信仰的解析'}
{'arxiv_id': 'arXiv:2505.15514', 'title': 'AM-PPO: (Advantage) Alpha-Modulation with Proximal Policy Optimization', 'authors': 'Soham Sane', 'link': 'https://arxiv.org/abs/2505.15514', 'abstract': 'Proximal Policy Optimization (PPO) is a widely used reinforcement learning algorithm that heavily relies on accurate advantage estimates for stable and efficient training. However, raw advantage signals can exhibit significant variance, noise, and scale-related issues, impeding optimal learning performance. To address this challenge, we introduce Advantage Modulation PPO (AM-PPO), a novel enhancement of PPO that adaptively modulates advantage estimates using a dynamic, non-linear scaling mechanism. This adaptive modulation employs an alpha controller that dynamically adjusts the scaling factor based on evolving statistical properties of the advantage signals, such as their norm, variance, and a predefined target saturation level. By incorporating a tanh-based gating function driven by these adaptively scaled advantages, AM-PPO reshapes the advantage signals to stabilize gradient updates and improve the conditioning of the policy gradient landscape. Crucially, this modulation also influences value function training by providing consistent and adaptively conditioned learning targets. Empirical evaluations across standard continuous control benchmarks demonstrate that AM-PPO achieves superior reward trajectories, exhibits sustained learning progression, and significantly reduces the clipping required by adaptive optimizers. These findings underscore the potential of advantage modulation as a broadly applicable technique for enhancing reinforcement learning optimization.', 'abstract_zh': '优势调制PPO：一种基于动态非线性缩放机制的PPO增强算法', 'title_zh': 'AM-PPO: (优势) 阿尔法调制与中心化优势优势-策略优化'}
{'arxiv_id': 'arXiv:2505.15507', 'title': 'Directional Non-Commutative Monoidal Structures for Compositional Embeddings in Machine Learning', 'authors': 'Mahesh Godavarti', 'link': 'https://arxiv.org/abs/2505.15507', 'abstract': 'We introduce a new algebraic structure for multi-dimensional compositional embeddings, built on directional non-commutative monoidal operators. The core contribution of this work is this novel framework, which exhibits appealing theoretical properties (associativity along each dimension and an interchange law ensuring global consistency) while remaining compatible with modern machine learning architectures. Our construction defines a distinct composition operator circ_i for each axis i, ensuring associative combination along each axis without imposing global commutativity. Importantly, all axis-specific operators commute with one another, enforcing a global interchange law that enables consistent crossaxis compositions. This is, to our knowledge, the first approach that provides a common foundation that generalizes classical sequence-modeling paradigms (e.g., structured state-space models (SSMs) and transformer self-attention) to a unified multi-dimensional framework. For example, specific one-dimensional instances of our framework can recover the familiar affine transformation algebra, vanilla self-attention, and the SSM-style recurrence. The higher-dimensional generalizations naturally support recursive, structure-aware operations in embedding spaces. We outline several potential applications unlocked by this structure-including structured positional encodings in Transformers, directional image embeddings, and symbolic modeling of sequences or grids-indicating that it could inform future deep learning model designs. We formally establish the algebraic properties of our framework and discuss efficient implementations. Finally, as our focus is theoretical, we include no experiments here and defer empirical validation to future work, which we plan to undertake.', 'abstract_zh': '我们提出了一种基于方向非交换半环运算的多维组合嵌入的新代数结构。这项工作的核心贡献是这一新颖框架，它展现出诱人的理论性质（每个维度上的结合性和确保全局一致性的互换法则），同时与现代机器学习架构保持兼容。我们的构建定义了每个轴i的独特组合运算符circ_i，确保每个轴上的结合组合而不强求全局可交换性。重要的是，所有轴特异性运算符彼此可交换，实现了全局互换法则，从而允许一致的跨轴组合。据我们所知，这是第一次提供一个共同的基础框架，将经典序列建模范式（如结构状态空间模型（SSMs）和变换器自注意力机制）推广到统一的多维框架。例如，我们框架的一维特定实例可以恢复熟悉的仿射变换代数、普通的自注意力和SSM风格的递归结构。高维的推广自然支持嵌入空间中的递归、结构感知操作。我们概述了由这种结构解锁的多种潜在应用，包括变换器中的结构位置编码、方向图像嵌入和序列或网格的符号建模，表明它可能影响未来深度学习模型的设计。我们形式地建立了我们框架的代数性质，并讨论了高效的实现方法。最后，由于我们的关注点是理论，这里没有包含实验，而是将实证验证推迟到将来的研究中，这是我们计划进行的研究。', 'title_zh': '方向非交换幺半结构及其在机器学习中组件嵌入中的应用'}
{'arxiv_id': 'arXiv:2505.15429', 'title': 'Uncertainty Quantification in SVM prediction', 'authors': 'Pritam Anand', 'link': 'https://arxiv.org/abs/2505.15429', 'abstract': 'This paper explores Uncertainty Quantification (UQ) in SVM predictions, particularly for regression and forecasting tasks. Unlike the Neural Network, the SVM solutions are typically more stable, sparse, optimal and interpretable. However, there are only few literature which addresses the UQ in SVM prediction. At first, we provide a comprehensive summary of existing Prediction Interval (PI) estimation and probabilistic forecasting methods developed in the SVM framework and evaluate them against the key properties expected from an ideal PI model. We find that none of the existing SVM PI models achieves a sparse solution. To introduce sparsity in SVM model, we propose the Sparse Support Vector Quantile Regression (SSVQR) model, which constructs PIs and probabilistic forecasts by solving a pair of linear programs. Further, we develop a feature selection algorithm for PI estimation using SSVQR that effectively eliminates a significant number of features while improving PI quality in case of high-dimensional dataset. Finally we extend the SVM models in Conformal Regression setting for obtaining more stable prediction set with finite test set guarantees. Extensive experiments on artificial, real-world benchmark datasets compare the different characteristics of both existing and proposed SVM-based PI estimation methods and also highlight the advantages of the feature selection in PI estimation. Furthermore, we compare both, the existing and proposed SVM-based PI estimation models, with modern deep learning models for probabilistic forecasting tasks on benchmark datasets. Furthermore, SVM models show comparable or superior performance to modern complex deep learning models for probabilistic forecasting task in our experiments.', 'abstract_zh': '这篇论文探讨了SVM预测中的不确定性量化（UQ），特别是在回归和预测任务中的应用。不同于神经网络，SVM解通常更稳定、稀疏、最优且可解释。然而，关于SVM预测的不确定性量化文献较少。首先，我们对SVM框架下现有的预测区间（PI）估计和概率预测方法进行了全面总结，并评估了它们是否符合理想PI模型的预期属性。我们发现现有的SVM PI模型均未实现稀疏解。为在SVM模型中引入稀疏性，我们提出了稀疏支持向量分位数回归（SSVQR）模型，该模型通过求解线性规划来构建PI和概率预测。此外，我们开发了一种基于SSVQR的特征选择算法，用于预测区间估计，在高维数据集中有效减少了大量特征，同时提高了PI的质量。最后，我们扩展了SVM模型在一致性回归框架下的应用，以获得具有有限测试集保证的更稳定的预测集。通过对人工和真实世界基准数据集进行详尽的实验，比较了现有和提出的SVM基预测区间估计方法的不同特性，并突出了特征选择在预测区间估计中的优势。此外，我们还将现有和提出的SVM基预测区间估计模型与现代深度学习模型进行了比较，用于基准数据集上的概率预测任务。实验结果显示，SVM模型在概率预测任务中表现与现代复杂的深度学习模型相当或更优。', 'title_zh': 'SVM预测中的不确定量化分析'}
{'arxiv_id': 'arXiv:2505.15380', 'title': 'Accelerating Autoregressive Speech Synthesis Inference With Speech Speculative Decoding', 'authors': 'Zijian Lin, Yang Zhang, Yougen Yuan, Yuming Yan, Jinjiang Liu, Zhiyong Wu, Pengfei Hu, Qun Yu', 'link': 'https://arxiv.org/abs/2505.15380', 'abstract': 'Modern autoregressive speech synthesis models leveraging language models have demonstrated remarkable performance. However, the sequential nature of next token prediction in these models leads to significant latency, hindering their deployment in scenarios where inference speed is critical. In this work, we propose Speech Speculative Decoding (SSD), a novel framework for autoregressive speech synthesis acceleration. Specifically, our method employs a lightweight draft model to generate candidate token sequences, which are subsequently verified in parallel by the target model using the proposed SSD framework. Experimental results demonstrate that SSD achieves a significant speedup of 1.4x compared with conventional autoregressive decoding, while maintaining high fidelity and naturalness. Subjective evaluations further validate the effectiveness of SSD in preserving the perceptual quality of the target model while accelerating inference.', 'abstract_zh': '利用语言模型的现代自回归语音合成模型展示了卓越的性能。然而，这些模型在下一个令牌预测中的序列性质导致了显著的延迟，阻碍了它们在需要快速推理速度的场景中的部署。本文提出了一种新颖的自回归语音合成加速框架——语音投机解码（SSD）。具体来说，该方法使用一个轻量级草图模型生成候选令牌序列，随后通过提出的SSD框架并行验证这些序列。实验结果表明，SSD比传统的自回归解码速度快1.4倍，同时保持了高保真度和自然度。进一步的主观评估验证了SSD在加速推理的同时有效保持目标模型的感知质量。', 'title_zh': '使用语音推测解码加速自回归语音合成推断'}
{'arxiv_id': 'arXiv:2505.15345', 'title': 'Hadamax Encoding: Elevating Performance in Model-Free Atari', 'authors': 'Jacob E. Kooi, Zhao Yang, Vincent François-Lavet', 'link': 'https://arxiv.org/abs/2505.15345', 'abstract': 'Neural network architectures have a large impact in machine learning. In reinforcement learning, network architectures have remained notably simple, as changes often lead to small gains in performance. This work introduces a novel encoder architecture for pixel-based model-free reinforcement learning. The Hadamax (\\textbf{Hada}mard \\textbf{max}-pooling) encoder achieves state-of-the-art performance by max-pooling Hadamard products between GELU-activated parallel hidden layers. Based on the recent PQN algorithm, the Hadamax encoder achieves state-of-the-art model-free performance in the Atari-57 benchmark. Specifically, without applying any algorithmic hyperparameter modifications, Hadamax-PQN achieves an 80\\% performance gain over vanilla PQN and significantly surpasses Rainbow-DQN. For reproducibility, the full code is available on \\href{this https URL}{GitHub}.', 'abstract_zh': '基于像素的无模型强化学习的新型编码器架构：Hadamax编码器在Atari-57基准测试中实现了最先进的无模型性能。', 'title_zh': 'Hadamax编码：提升模型自由Atari环境中的性能'}
{'arxiv_id': 'arXiv:2505.15344', 'title': 'Alpay Algebra: A Universal Structural Foundation', 'authors': 'Faruk Alpay', 'link': 'https://arxiv.org/abs/2505.15344', 'abstract': "Alpay Algebra is introduced as a universal, category-theoretic framework that unifies classical algebraic structures with modern needs in symbolic recursion and explainable AI. Starting from a minimal list of axioms, we model each algebra as an object in a small cartesian closed category $\\mathcal{A}$ and define a transfinite evolution functor $\\phi\\colon\\mathcal{A}\\to\\mathcal{A}$. We prove that the fixed point $\\phi^{\\infty}$ exists for every initial object and satisfies an internal universal property that recovers familiar constructs -- limits, colimits, adjunctions -- while extending them to ordinal-indexed folds. A sequence of theorems establishes (i) soundness and conservativity over standard universal algebra, (ii) convergence of $\\phi$-iterates under regular cardinals, and (iii) an explanatory correspondence between $\\phi^{\\infty}$ and minimal sufficient statistics in information-theoretic AI models. We conclude by outlining computational applications: type-safe functional languages, categorical model checking, and signal-level reasoning engines that leverage Alpay Algebra's structural invariants. All proofs are self-contained; no external set-theoretic axioms beyond ZFC are required. This exposition positions Alpay Algebra as a bridge between foundational mathematics and high-impact AI systems, and provides a reference for further work in category theory, transfinite fixed-point analysis, and symbolic computation.", 'abstract_zh': 'Alpay代数作为一种统一经典代数结构与现代符号递归和可解释AI需求的通用范畴论框架被引入。从一组最小公理出发，我们将每个代数建模为小笛卡尔闭范畴$\\mathcal{A}$中的一个对象，并定义一个超限演化泛函$\\phi\\colon\\mathcal{A}\\to\\mathcal{A}$。证明对于每个初始对象，存在固定点$\\phi^{\\infty}$并满足内部普遍性质，恢复了熟悉的构造——极限、共限、伴随——并将它们扩展到序数索引的折叠。一系列定理证明了(i) 对标准普遍代数的保真性和保守性，(ii) 在正则基数下的$\\phi$迭代收敛性，以及(iii) $\\phi^{\\infty}$与信息论AI模型中最小充分统计之间的解释性对应关系。我们通过概述计算应用结束：类型安全函数语言、范畴模型检验以及利用Alpay代数结构性不变量的信号级推理引擎。所有证明都是自包含的；不需要超出ZFC之外的集合论公理。这一表述将Alpay代数定位为基础数学与高影响AI系统之间的桥梁，并为范畴论、超限不动点分析和符号计算进一步研究提供了参考。', 'title_zh': 'Alpay代数：一个普遍的结构基础'}
{'arxiv_id': 'arXiv:2505.15333', 'title': 'Leveraging Unit Language Guidance to Advance Speech Modeling in Textless Speech-to-Speech Translation', 'authors': 'Yuhao Zhang, Xiangnan Ma, Kaiqi Kou, Peizhuo Liu, Weiqiao Shan, Benyou Wang, Tong Xiao, Yuxin Huang, Zhengtao Yu, Jingbo Zhu', 'link': 'https://arxiv.org/abs/2505.15333', 'abstract': 'The success of building textless speech-to-speech translation (S2ST) models has attracted much attention. However, S2ST still faces two main challenges: 1) extracting linguistic features for various speech signals, called cross-modal (CM), and 2) learning alignment of difference languages in long sequences, called cross-lingual (CL). We propose the unit language to overcome the two modeling challenges. The unit language can be considered a text-like representation format, constructed using $n$-gram language modeling. We implement multi-task learning to utilize the unit language in guiding the speech modeling process. Our initial results reveal a conflict when applying source and target unit languages simultaneously. We propose task prompt modeling to mitigate this conflict. We conduct experiments on four languages of the Voxpupil dataset. Our method demonstrates significant improvements over a strong baseline and achieves performance comparable to models trained with text.', 'abstract_zh': '构建无文本语音到语音翻译模型的成功吸引了广泛关注。然而，语音到语音翻译仍面临两大挑战：1) 各种语音信号的语言特征提取，称为跨模态（CM），2) 长序列中不同语言对齐的学习，称为跨语言（CL）。我们提出单位语言以克服这两种建模挑战。单位语言可被视为一种类似于文本的表现格式，使用$n$-gram语言建模构建。我们采用多任务学习利用单位语言指导语音建模过程。我们的初步结果显示，同时应用源语言和目标语言单位语言时存在冲突。我们提出任务提示建模以缓解这种冲突。我们在Voxpupil数据集的四种语言上进行了实验。我们的方法在强基线之上显示出显著改进，并且达到与使用文本训练模型相当的性能。', 'title_zh': '利用单元语言指导促进无文本语音到语音翻译中的语音建模'}
{'arxiv_id': 'arXiv:2505.15308', 'title': 'BadSR: Stealthy Label Backdoor Attacks on Image Super-Resolution', 'authors': 'Ji Guo, Xiaolei Wen, Wenbo Jiang, Cheng Huang, Jinjin Li, Hongwei Li', 'link': 'https://arxiv.org/abs/2505.15308', 'abstract': 'With the widespread application of super-resolution (SR) in various fields, researchers have begun to investigate its security. Previous studies have demonstrated that SR models can also be subjected to backdoor attacks through data poisoning, affecting downstream tasks. A backdoor SR model generates an attacker-predefined target image when given a triggered image while producing a normal high-resolution (HR) output for clean images. However, prior backdoor attacks on SR models have primarily focused on the stealthiness of poisoned low-resolution (LR) images while ignoring the stealthiness of poisoned HR images, making it easy for users to detect anomalous data. To address this problem, we propose BadSR, which improves the stealthiness of poisoned HR images. The key idea of BadSR is to approximate the clean HR image and the pre-defined target image in the feature space while ensuring that modifications to the clean HR image remain within a constrained range. The poisoned HR images generated by BadSR can be integrated with existing triggers. To further improve the effectiveness of BadSR, we design an adversarially optimized trigger and a backdoor gradient-driven poisoned sample selection method based on a genetic algorithm. The experimental results show that BadSR achieves a high attack success rate in various models and data sets, significantly affecting downstream tasks.', 'abstract_zh': '基于BadSR的高分辨率图像后门攻击方法：提高受污染高分辨率图像的隐蔽性', 'title_zh': 'BadSR：图像超分辨率上的隐蔽标签后门攻击'}
{'arxiv_id': 'arXiv:2505.15303', 'title': 'Laplace Sample Information: Data Informativeness Through a Bayesian Lens', 'authors': 'Johannes Kaiser, Kristian Schwethelm, Daniel Rueckert, Georgios Kaissis', 'link': 'https://arxiv.org/abs/2505.15303', 'abstract': 'Accurately estimating the informativeness of individual samples in a dataset is an important objective in deep learning, as it can guide sample selection, which can improve model efficiency and accuracy by removing redundant or potentially harmful samples. We propose Laplace Sample Information (LSI) measure of sample informativeness grounded in information theory widely applicable across model architectures and learning settings. LSI leverages a Bayesian approximation to the weight posterior and the KL divergence to measure the change in the parameter distribution induced by a sample of interest from the dataset. We experimentally show that LSI is effective in ordering the data with respect to typicality, detecting mislabeled samples, measuring class-wise informativeness, and assessing dataset difficulty. We demonstrate these capabilities of LSI on image and text data in supervised and unsupervised settings. Moreover, we show that LSI can be computed efficiently through probes and transfers well to the training of large models.', 'abstract_zh': '准确估计数据集中单个样本的信息量是深度学习中的一个重要目标，因为它可以指导样本选择，从而通过去除冗余或潜在有害的样本来提高模型效率和准确性。我们提出了一种基于信息理论的Laplace样本信息（LSI）测度，该测度适用于各种模型架构和学习设置。LSI利用贝叶斯权重后验近似和KL散度来衡量兴趣样本引起的数据集中参数分布的变化。实验结果表明，LSI在按典型性排序数据、检测误标样本、测量类内信息量以及评估数据集难度方面有效。我们展示了LSI在监督和无监督设置下的图像和文本数据上的这些能力。此外，我们展示了LSI可以通过探针高效计算，并且可以很好地转移应用于大型模型的训练。', 'title_zh': '拉普拉斯样本信息：通过贝叶斯视角的数据信息量'}
{'arxiv_id': 'arXiv:2505.15285', 'title': 'Reconsider the Template Mesh in Deep Learning-based Mesh Reconstruction', 'authors': 'Fengting Zhang, Boxu Liang, Qinghao Liu, Min Liu, Xiang Chen, Yaonan Wang', 'link': 'https://arxiv.org/abs/2505.15285', 'abstract': 'Mesh reconstruction is a cornerstone process across various applications, including in-silico trials, digital twins, surgical planning, and navigation. Recent advancements in deep learning have notably enhanced mesh reconstruction speeds. Yet, traditional methods predominantly rely on deforming a standardised template mesh for individual subjects, which overlooks the unique anatomical variations between them, and may compromise the fidelity of the reconstructions. In this paper, we propose an adaptive-template-based mesh reconstruction network (ATMRN), which generates adaptive templates from the given images for the subsequent deformation, moving beyond the constraints of a singular, fixed template. Our approach, validated on cortical magnetic resonance (MR) images from the OASIS dataset, sets a new benchmark in voxel-to-cortex mesh reconstruction, achieving an average symmetric surface distance of 0.267mm across four cortical structures. Our proposed method is generic and can be easily transferred to other image modalities and anatomical structures.', 'abstract_zh': '基于自适应模板的网格重建网络：一种新的皮层磁共振成像到体素网格重建基准方法', 'title_zh': '基于深度学习的网格重建中重考虑模板网格'}
{'arxiv_id': 'arXiv:2505.15250', 'title': 'Margin-aware Fuzzy Rough Feature Selection: Bridging Uncertainty Characterization and Pattern Classification', 'authors': 'Suping Xu, Lin Shang, Keyu Liu, Hengrong Ju, Xibei Yang, Witold Pedrycz', 'link': 'https://arxiv.org/abs/2505.15250', 'abstract': 'Fuzzy rough feature selection (FRFS) is an effective means of addressing the curse of dimensionality in high-dimensional data. By removing redundant and irrelevant features, FRFS helps mitigate classifier overfitting, enhance generalization performance, and lessen computational overhead. However, most existing FRFS algorithms primarily focus on reducing uncertainty in pattern classification, neglecting that lower uncertainty does not necessarily result in improved classification performance, despite it commonly being regarded as a key indicator of feature selection effectiveness in the FRFS literature. To bridge uncertainty characterization and pattern classification, we propose a Margin-aware Fuzzy Rough Feature Selection (MAFRFS) framework that considers both the compactness and separation of label classes. MAFRFS effectively reduces uncertainty in pattern classification tasks, while guiding the feature selection towards more separable and discriminative label class structures. Extensive experiments on 15 public datasets demonstrate that MAFRFS is highly scalable and more effective than FRFS. The algorithms developed using MAFRFS outperform six state-of-the-art feature selection algorithms.', 'abstract_zh': '面向边界的模糊粗糙特征选择（MAFRFS）：一种同时考虑标签类紧致性和分离性的特征选择框架', 'title_zh': '面向边距的模糊粗糙特征选择：不确定性表征与模式分类的桥梁'}
{'arxiv_id': 'arXiv:2505.15239', 'title': 'Neural Collapse is Globally Optimal in Deep Regularized ResNets and Transformers', 'authors': 'Peter Súkeník, Christoph H. Lampert, Marco Mondelli', 'link': 'https://arxiv.org/abs/2505.15239', 'abstract': 'The empirical emergence of neural collapse -- a surprising symmetry in the feature representations of the training data in the penultimate layer of deep neural networks -- has spurred a line of theoretical research aimed at its understanding. However, existing work focuses on data-agnostic models or, when data structure is taken into account, it remains limited to multi-layer perceptrons. Our paper fills both these gaps by analyzing modern architectures in a data-aware regime: we prove that global optima of deep regularized transformers and residual networks (ResNets) with LayerNorm trained with cross entropy or mean squared error loss are approximately collapsed, and the approximation gets tighter as the depth grows. More generally, we formally reduce any end-to-end large-depth ResNet or transformer training into an equivalent unconstrained features model, thus justifying its wide use in the literature even beyond data-agnostic settings. Our theoretical results are supported by experiments on computer vision and language datasets showing that, as the depth grows, neural collapse indeed becomes more prominent.', 'abstract_zh': '神经坍缩的经验涌现——深神经网络次末端层训练数据的特征表示中的一种令人惊讶的对称性——激发了对其理解的理论研究。然而，现有工作专注于数据无关模型，或者在考虑数据结构时仅限于多层感知机。我们的论文通过在数据感知框架下分析现代架构填补了这两项空白：我们证明了采用交叉熵或均方误差损失训练的正则化深层变压器和残差网络（ResNets）的全局最优解大约会坍缩，且随着深度的增加，坍缩程度更加紧密。更为一般地，我们将任何端到端的大深度ResNet或变压器训练形式上归约为无约束特征模型的等价模型，从而证明了其在数据无关设置之外的广泛应用。我们的理论成果通过计算机视觉和语言数据集上的实验证明，在深度增加时，神经坍缩现象确实更加显著。', 'title_zh': '神经网络坍缩在深度正则化ResNets和Transformer中是全局最优的'}
{'arxiv_id': 'arXiv:2505.15216', 'title': 'BountyBench: Dollar Impact of AI Agent Attackers and Defenders on Real-World Cybersecurity Systems', 'authors': 'Andy K. Zhang, Joey Ji, Celeste Menders, Riya Dulepet, Thomas Qin, Ron Y. Wang, Junrong Wu, Kyleen Liao, Jiliang Li, Jinghan Hu, Sara Hong, Nardos Demilew, Shivatmica Murgai, Jason Tran, Nishka Kacheria, Ethan Ho, Denis Liu, Lauren McLane, Olivia Bruvik, Dai-Rong Han, Seungwoo Kim, Akhil Vyas, Cuiyuanxiu Chen, Ryan Li, Weiran Xu, Jonathan Z. Ye, Prerit Choudhary, Siddharth M. Bhatia, Vikram Sivashankar, Yuxuan Bao, Dawn Song, Dan Boneh, Daniel E. Ho, Percy Liang', 'link': 'https://arxiv.org/abs/2505.15216', 'abstract': 'AI agents have the potential to significantly alter the cybersecurity landscape. To help us understand this change, we introduce the first framework to capture offensive and defensive cyber-capabilities in evolving real-world systems. Instantiating this framework with BountyBench, we set up 25 systems with complex, real-world codebases. To capture the vulnerability lifecycle, we define three task types: Detect (detecting a new vulnerability), Exploit (exploiting a specific vulnerability), and Patch (patching a specific vulnerability). For Detect, we construct a new success indicator, which is general across vulnerability types and provides localized evaluation. We manually set up the environment for each system, including installing packages, setting up server(s), and hydrating database(s). We add 40 bug bounties, which are vulnerabilities with monetary awards from \\$10 to \\$30,485, and cover 9 of the OWASP Top 10 Risks. To modulate task difficulty, we devise a new strategy based on information to guide detection, interpolating from identifying a zero day to exploiting a specific vulnerability. We evaluate 5 agents: Claude Code, OpenAI Codex CLI, and custom agents with GPT-4.1, Gemini 2.5 Pro Preview, and Claude 3.7 Sonnet Thinking. Given up to three attempts, the top-performing agents are Claude Code (5% on Detect, mapping to \\$1,350), Custom Agent with Claude 3.7 Sonnet Thinking (5% on Detect, mapping to \\$1,025; 67.5% on Exploit), and OpenAI Codex CLI (5% on Detect, mapping to \\$2,400; 90% on Patch, mapping to \\$14,422). OpenAI Codex CLI and Claude Code are more capable at defense, achieving higher Patch scores of 90% and 87.5%, compared to Exploit scores of 32.5% and 57.5% respectively; in contrast, the custom agents are relatively balanced between offense and defense, achieving Exploit scores of 40-67.5% and Patch scores of 45-60%.', 'abstract_zh': 'AI代理有潜力显著改变网络安全格局。为了帮助我们理解这一变化，我们提出首个框架以捕捉演变中的现实世界系统中的 Offensive 和 Defensive 网络能力。通过使用 BountyBench，我们设置了包含复杂现实代码库的 25 个系统。为了捕捉漏洞生命周期，我们定义了三种任务类型：Detect（检测新漏洞）、Exploit（利用特定漏洞）和Patch（修复特定漏洞）。对于 Detect，我们构建了一个新的成功指标，该指标适用于不同类型的漏洞，并提供局部评估。我们为每个系统手工配置环境，包括安装软件包、设置服务器和填充数据库。我们添加了 40 个漏洞赏金，这些赏金包括 10 美元到 30,485 美元不等的金钱奖励，并覆盖了 OWASP Top 10 中的 9 项风险。为了调节任务难度，我们设计了一种新的策略，基于信息来指导检测，从识别零日漏洞逐步到利用特定漏洞。我们评估了 5 个代理：Claude Code、OpenAI Codex CLI，以及分别使用 GPT-4.1、Gemini 2.5 Pro Preview 和 Claude 3.7 Sonnet Thinking 的定制代理。在最多三次尝试的情况下，表现最好的代理是 Claude Code（在 Detect 中达到 5%，相当于 1,350 美元），定制代理 Claude 3.7 Sonnet Thinking（在 Detect 中达到 5%，相当于 1,025 美元；在 Exploit 中达到 67.5%），以及 OpenAI Codex CLI（在 Detect 中达到 5%，相当于 2,400 美元；在 Patch 中达到 90%，相当于 14,422 美元）。OpenAI Codex CLI 和 Claude Code 在防御方面表现更加出色，分别实现高达 90% 和 87.5% 的 Patch 分数，相比之下，Exploit 分数分别为 32.5% 和 57.5%；相比之下，定制代理在这两者之间相对平衡，Exploit 分数在 40% 至 67.5% 之间，Patch 分数在 45% 至 60% 之间。', 'title_zh': 'BountyBench: AI代理攻击者和防御者对实际网络安全系统经济影响的研究'}
{'arxiv_id': 'arXiv:2505.15155', 'title': 'R&D-Agent-Quant: A Multi-Agent Framework for Data-Centric Factors and Model Joint Optimization', 'authors': 'Yuante Li, Xu Yang, Xiao Yang, Minrui Xu, Xisen Wang, Weiqing Liu, Jiang Bian', 'link': 'https://arxiv.org/abs/2505.15155', 'abstract': 'Financial markets pose fundamental challenges for asset return prediction due to their high dimensionality, non-stationarity, and persistent volatility. Despite advances in large language models and multi-agent systems, current quantitative research pipelines suffer from limited automation, weak interpretability, and fragmented coordination across key components such as factor mining and model innovation. In this paper, we propose R&D-Agent for Quantitative Finance, in short RD-Agent(Q), the first data-centric multi-agent framework designed to automate the full-stack research and development of quantitative strategies via coordinated factor-model co-optimization. RD-Agent(Q) decomposes the quant process into two iterative stages: a Research stage that dynamically sets goal-aligned prompts, formulates hypotheses based on domain priors, and maps them to concrete tasks, and a Development stage that employs a code-generation agent, Co-STEER, to implement task-specific code, which is then executed in real-market backtests. The two stages are connected through a feedback stage that thoroughly evaluates experimental outcomes and informs subsequent iterations, with a multi-armed bandit scheduler for adaptive direction selection. Empirically, RD-Agent(Q) achieves up to 2X higher annualized returns than classical factor libraries using 70% fewer factors, and outperforms state-of-the-art deep time-series models on real markets. Its joint factor-model optimization delivers a strong balance between predictive accuracy and strategy robustness. Our code is available at: this https URL.', 'abstract_zh': '金融市场的高维特性、非平稳性及持续的波动性给资产回报预测提出了基本挑战。尽管大型语言模型和多智能体系统取得了进展，当前的定量研究工作流程仍然面临自动化程度有限、解释性较弱以及关键组件（如因子挖掘和模型创新）之间协调性差的问题。本文提出了一种面向研究与开发的Quantitative Finance智能体（RD-Agent(Q)），这是第一个通过协同因子-模型协同优化来自动化定量策略全流程研究与发展的数据驱动型多智能体框架。RD-Agent(Q)将量化过程分解为两个迭代阶段：研究阶段动态设定目标对齐的提示，根据领域先验制定假设，并将其映射为具体的任务；开发阶段采用代码生成智能体Co-STEER来实现特定任务的代码，然后在实盘回测中执行。两个阶段通过一个反馈阶段连接，该阶段全面评估实验结果并为后续迭代提供反馈，使用多臂老虎机调度器进行自适应方向选择。实证结果显示，RD-Agent(Q)在使用较少因子（减少70%）的情况下，实现了最高2倍的年化回报，并在实盘市场中超越最先进的深度时间序列模型，其联合因子-模型优化提供了预测准确性和策略稳健性的良好平衡。GitHub代码地址：this https URL。', 'title_zh': 'R&D-Agent-Quant: 以数据为中心的因素与模型联合优化的多智能体框架'}
{'arxiv_id': 'arXiv:2505.15138', 'title': 'Global Convergence for Average Reward Constrained MDPs with Primal-Dual Actor Critic Algorithm', 'authors': 'Yang Xu, Swetha Ganesh, Washim Uddin Mondal, Qinbo Bai, Vaneet Aggarwal', 'link': 'https://arxiv.org/abs/2505.15138', 'abstract': 'This paper investigates infinite-horizon average reward Constrained Markov Decision Processes (CMDPs) with general parametrization. We propose a Primal-Dual Natural Actor-Critic algorithm that adeptly manages constraints while ensuring a high convergence rate. In particular, our algorithm achieves global convergence and constraint violation rates of $\\tilde{\\mathcal{O}}(1/\\sqrt{T})$ over a horizon of length $T$ when the mixing time, $\\tau_{\\mathrm{mix}}$, is known to the learner. In absence of knowledge of $\\tau_{\\mathrm{mix}}$, the achievable rates change to $\\tilde{\\mathcal{O}}(1/T^{0.5-\\epsilon})$ provided that $T \\geq \\tilde{\\mathcal{O}}\\left(\\tau_{\\mathrm{mix}}^{2/\\epsilon}\\right)$. Our results match the theoretical lower bound for Markov Decision Processes and establish a new benchmark in the theoretical exploration of average reward CMDPs.', 'abstract_zh': '这篇论文研究了具有通用参数化的无穷_horizon平均奖励约束马尔科夫决策过程（CMDPs）。我们提出了一种普欧-对偶自然Actor-Critic算法，在确保高收敛率的同时巧妙处理约束。特别是在混合时间$\\tau_{\\mathrm{mix}}$已知给学习者的情况下，我们的算法在长度为$T$的horizon上实现了全局收敛和约束违反率为$\\tilde{\\mathcal{O}}(1/\\sqrt{T})$。在$\\tau_{\\mathrm{mix}}$未知的情况下，如果满足$T \\geq \\tilde{\\mathcal{O}}\\left(\\tau_{\\mathrm{mix}}^{2/\\epsilon}\\right)$，可实现的速率变为$\\tilde{\\mathcal{O}}(1/T^{0.5-\\epsilon})$。我们的结果匹配了马尔科夫决策过程的理论下界，并在平均奖励CMDPs的理论探索中建立了新的基准。', 'title_zh': '全局收敛性约束平均奖励MDP的 primal-dual 奖励 critic 算法'}
{'arxiv_id': 'arXiv:2505.15133', 'title': 'DeepKD: A Deeply Decoupled and Denoised Knowledge Distillation Trainer', 'authors': 'Haiduo Huang, Jiangcheng Song, Yadong Zhang, Pengju Ren', 'link': 'https://arxiv.org/abs/2505.15133', 'abstract': "Recent advances in knowledge distillation have emphasized the importance of decoupling different knowledge components. While existing methods utilize momentum mechanisms to separate task-oriented and distillation gradients, they overlook the inherent conflict between target-class and non-target-class knowledge flows. Furthermore, low-confidence dark knowledge in non-target classes introduces noisy signals that hinder effective knowledge transfer. To address these limitations, we propose DeepKD, a novel training framework that integrates dual-level decoupling with adaptive denoising. First, through theoretical analysis of gradient signal-to-noise ratio (GSNR) characteristics in task-oriented and non-task-oriented knowledge distillation, we design independent momentum updaters for each component to prevent mutual interference. We observe that the optimal momentum coefficients for task-oriented gradient (TOG), target-class gradient (TCG), and non-target-class gradient (NCG) should be positively related to their GSNR. Second, we introduce a dynamic top-k mask (DTM) mechanism that gradually increases K from a small initial value to incorporate more non-target classes as training progresses, following curriculum learning principles. The DTM jointly filters low-confidence logits from both teacher and student models, effectively purifying dark knowledge during early training. Extensive experiments on CIFAR-100, ImageNet, and MS-COCO demonstrate DeepKD's effectiveness. Our code is available at this https URL.", 'abstract_zh': 'Recent Advances in Knowledge Distillation Have Emphasized the Importance of Decoupling Different Knowledge Components: Addressing the Limitations with DeepKD, a Novel Training Framework that Integrates Dual-Level Decoupling with Adaptive Denoising', 'title_zh': 'DeepKD：一种深度解耦和去噪的知识蒸馏训练器'}
{'arxiv_id': 'arXiv:2505.15116', 'title': 'Graph Foundation Models: A Comprehensive Survey', 'authors': 'Zehong Wang, Zheyuan Liu, Tianyi Ma, Jiazheng Li, Zheyuan Zhang, Xingbo Fu, Yiyang Li, Zhengqing Yuan, Wei Song, Yijun Ma, Qingkai Zeng, Xiusi Chen, Jianan Zhao, Jundong Li, Meng Jiang, Pietro Lio, Nitesh Chawla, Chuxu Zhang, Yanfang Ye', 'link': 'https://arxiv.org/abs/2505.15116', 'abstract': 'Graph-structured data pervades domains such as social networks, biological systems, knowledge graphs, and recommender systems. While foundation models have transformed natural language processing, vision, and multimodal learning through large-scale pretraining and generalization, extending these capabilities to graphs -- characterized by non-Euclidean structures and complex relational semantics -- poses unique challenges and opens new opportunities. To this end, Graph Foundation Models (GFMs) aim to bring scalable, general-purpose intelligence to structured data, enabling broad transfer across graph-centric tasks and domains. This survey provides a comprehensive overview of GFMs, unifying diverse efforts under a modular framework comprising three key components: backbone architectures, pretraining strategies, and adaptation mechanisms. We categorize GFMs by their generalization scope -- universal, task-specific, and domain-specific -- and review representative methods, key innovations, and theoretical insights within each category. Beyond methodology, we examine theoretical foundations including transferability and emergent capabilities, and highlight key challenges such as structural alignment, heterogeneity, scalability, and evaluation. Positioned at the intersection of graph learning and general-purpose AI, GFMs are poised to become foundational infrastructure for open-ended reasoning over structured data. This survey consolidates current progress and outlines future directions to guide research in this rapidly evolving field. Resources are available at this https URL.', 'abstract_zh': '图结构数据 pervades 领域如社交网络、生物系统、知识图谱和推荐系统。尽管基础模型通过大规模预训练和泛化已重塑自然语言处理、视觉和多模态学习，但将这些能力扩展到图数据——其特征是非欧几里得结构和复杂的关系语义——提出了独特挑战并开启了新的机遇。为此，图基础模型（GFMs）旨在为结构化数据带来可扩展的通用智能，使其能够在图中心任务和领域之间广泛转移。本文综述提供了对 GFMs 的全面概述，统一了在模块化框架下的各种努力，包括骨干架构、预训练策略和适应机制。我们按其泛化范围——通用、任务特定和领域特定——对 GFMs 进行分类，并在每个类别中回顾了代表性方法、关键创新和理论洞见。除了方法论，我们还探讨了理论基础，包括可迁移性和新兴能力，并强调了结构性对齐、异质性、可扩展性和评估等关键挑战。定位在图学习和通用人工智能的交界处，GFMs 被视为开放推理的结构化数据基础架构。本文综述汇总了当前进展，并指出了未来方向以指导该快速发展的领域中的研究。资源可访问此网址。', 'title_zh': '图基础模型：综述'}
{'arxiv_id': 'arXiv:2505.15105', 'title': 'Mechanistic evaluation of Transformers and state space models', 'authors': 'Aryaman Arora, Neil Rathi, Nikil Roashan Selvam, Róbert Csórdas, Dan Jurafsky, Christopher Potts', 'link': 'https://arxiv.org/abs/2505.15105', 'abstract': 'State space models (SSMs) for language modelling promise an efficient and performant alternative to quadratic-attention Transformers, yet show variable performance on recalling basic information from the context. While performance on synthetic tasks like Associative Recall (AR) can point to this deficiency, behavioural metrics provide little information as to why--on a mechanistic level--certain architectures fail and others succeed. To address this, we conduct experiments on AR and find that only Transformers and Based SSM models fully succeed at AR, with Mamba a close third, whereas the other SSMs (H3, Hyena) fail. We then use causal interventions to explain why. We find that Transformers and Based learn to store key-value associations in-context using induction heads. By contrast, the SSMs compute these associations only at the last state, with only Mamba succeeding because of its short convolution component. To extend and deepen these findings, we introduce Associative Treecall (ATR), a synthetic task similar to AR based on PCFG induction. ATR introduces language-like hierarchical structure into the AR setting. We find that all architectures learn the same mechanism as they did for AR, and the same three models succeed at the task. These results reveal that architectures with similar accuracy may still have substantive differences, motivating the adoption of mechanistic evaluations.', 'abstract_zh': '状态空间模型（SSMs）在语言建模中的进展：基于诱导头的Transformer和基于诱导的SSM模型在关联回忆任务中表现出色，而其他SSM模型表现不佳', 'title_zh': 'Transformer和状态空间模型的机制评估'}
{'arxiv_id': 'arXiv:2505.15095', 'title': 'Nek Minit: Harnessing Pragmatic Metacognitive Prompting for Explainable Sarcasm Detection of Australian and Indian English', 'authors': 'Ishmanbir Singh, Dipankar Srirag, Aditya Joshi', 'link': 'https://arxiv.org/abs/2505.15095', 'abstract': 'Sarcasm is a challenge to sentiment analysis because of the incongruity between stated and implied sentiment. The challenge is exacerbated when the implication may be relevant to a specific country or geographical region. Pragmatic metacognitive prompting (PMP) is a cognition-inspired technique that has been used for pragmatic reasoning. In this paper, we harness PMP for explainable sarcasm detection for Australian and Indian English, alongside a benchmark dataset for standard English. We manually add sarcasm explanations to an existing sarcasm-labeled dataset for Australian and Indian English called BESSTIE, and compare the performance for explainable sarcasm detection for them with FLUTE, a standard English dataset containing sarcasm explanations. Our approach utilising PMP when evaluated on two open-weight LLMs (GEMMA and LLAMA) achieves statistically significant performance improvement across all tasks and datasets when compared with four alternative prompting strategies. We also find that alternative techniques such as agentic prompting mitigate context-related failures by enabling external knowledge retrieval. The focused contribution of our work is utilising PMP in generating sarcasm explanations for varieties of English.', 'abstract_zh': '讽刺检测对于情感分析是一个挑战，因为显性情感和隐含情感之间存在不一致。当隐含情感可能与特定国家或地理区域相关时，这一挑战会进一步加剧。实践元认知提示（PMP）是一种受认知启发的技术，已被用于进行实践推理。本文利用PMP为澳大利亚英语和印度英语的可解释讽刺检测建立基准，并结合一个标准英语数据集FLUTE。我们手动为一个名为BESSTIE的澳大利亚英语和印度英语的讽刺标记数据集添加讽刺解释，并将其与包含讽刺解释的标准英语数据集FLUTE进行比较。当我们评估我们的方法（在GEMMA和LLAMA这两种预训练语言模型上）时，在所有任务和数据集上都实现了统计上显著的性能提升，并且我们发现，如代理提示等替代技术通过使外部知识检索成为可能，能够缓解与上下文相关的问题。本文的主要贡献在于利用PMP为英语变体生成讽刺解释。', 'title_zh': 'Nek Minit: 利用手法元认知提示实现可解释的澳大利亚英语和印度英语 sarcasm 检测'}
{'arxiv_id': 'arXiv:2505.15083', 'title': 'Robust Multi-Modal Forecasting: Integrating Static and Dynamic Features', 'authors': 'Jeremy Qin', 'link': 'https://arxiv.org/abs/2505.15083', 'abstract': 'Time series forecasting plays a crucial role in various applications, particularly in healthcare, where accurate predictions of future health trajectories can significantly impact clinical decision-making. Ensuring transparency and explainability of the models responsible for these tasks is essential for their adoption in critical settings. Recent work has explored a top-down approach to bi-level transparency, focusing on understanding trends and properties of predicted time series using static features. In this work, we extend this framework by incorporating exogenous time series features alongside static features in a structured manner, while maintaining cohesive interpretation. Our approach leverages the insights of trajectory comprehension to introduce an encoding mechanism for exogenous time series, where they are decomposed into meaningful trends and properties, enabling the extraction of interpretable patterns. Through experiments on several synthetic datasets, we demonstrate that our approach remains predictive while preserving interpretability and robustness. This work represents a step towards developing robust, and generalized time series forecasting models. The code is available at this https URL', 'abstract_zh': '时间序列预测在各种应用中扮演着重要角色，特别是在医疗保健领域，准确预测未来的健康轨迹能显著影响临床决策。确保这些任务所依赖模型的透明性和解释性对于在关键环境中采用这些模型至关重要。近期研究探索了自上而下的双层透明性方法，重点是通过静态特征来理解预测时间序列的趋势和属性。在本文中，我们通过以结构化方式将外生时间序列特征与静态特征结合，扩展了这一框架，同时保持一致的解释性。我们的方法利用轨迹理解的洞察，引入了一种外生时间序列的编码机制，将它们分解为有意义的趋势和属性，从而提取可解释的模式。通过在多个合成数据集上的实验，我们展示了我们的方法在保持预测能力的同时，仍然具有可解释性和稳健性。这项工作代表了向开发稳健且通用的时间序列预测模型迈进的一步。代码可在以下链接获得：this https URL', 'title_zh': '鲁棒多模态预测：集成静态和动态特征'}
{'arxiv_id': 'arXiv:2505.15080', 'title': 'SUS backprop: linear backpropagation algorithm for long inputs in transformers', 'authors': 'Sergey Pankov, Georges Harik', 'link': 'https://arxiv.org/abs/2505.15080', 'abstract': 'It is straightforward to design an unbiased gradient estimator that stochastically cuts the backpropagation flow through any part of a computational graph. By cutting the parts that have little effect on the computation, one can potentially save a significant amount of back-propagation computation in exchange for a minimal increase in the stochastic gradient variance, in some situations. Such a situation occurs in the attention mechanism of the transformer architecture. For long sequences, attention becomes the limiting factor, as its compute requirements increase quadratically with sequence length $n$. At the same time, most attention weights become very small, as most attention heads tend to connect a given token with only a small fraction of other tokens in the sequence. These weights become promising targets for cutting backpropagation. We propose a simple probabilistic rule controlled by a single parameter $c$ that cuts backpropagation through most attention weights, leaving at most $c$ interactions per token per attention head. This brings a factor of $c/n$ reduction in the compute required for the attention backpropagation, turning it from quadratic $O(n^2)$ to linear complexity $O(nc)$. We have empirically verified that, for a typical transformer model, cutting $99\\%$ of the attention gradient flow (i.e. choosing $c \\sim 20-30$) results in relative gradient variance increase of only about $1\\%$ for $n \\sim 2000$, and it decreases with $n$. This approach is amenable to efficient sparse matrix implementation, thus being promising for making the cost of a backward pass negligible relative to the cost of a forward pass when training a transformer model on long sequences.', 'abstract_zh': '一种用于变压器架构注意力机制的无偏梯度估计器设计', 'title_zh': 'SUS反向传播：长输入在变换器中的线性反向传播算法'}
{'arxiv_id': 'arXiv:2505.15054', 'title': 'MolLangBench: A Comprehensive Benchmark for Language-Prompted Molecular Structure Recognition, Editing, and Generation', 'authors': 'Feiyang Cai, Jiahui Bai, Tao Tang, Joshua Luo, Tianyu Zhu, Ling Liu, Feng Luo', 'link': 'https://arxiv.org/abs/2505.15054', 'abstract': 'Precise recognition, editing, and generation of molecules are essential prerequisites for both chemists and AI systems tackling various chemical tasks. We present MolLangBench, a comprehensive benchmark designed to evaluate fundamental molecule-language interface tasks: language-prompted molecular structure recognition, editing, and generation. To ensure high-quality, unambiguous, and deterministic outputs, we construct the recognition tasks using automated cheminformatics tools, and curate editing and generation tasks through rigorous expert annotation and validation. MolLangBench supports the evaluation of models that interface language with different molecular representations, including linear strings, molecular images, and molecular graphs. Evaluations of state-of-the-art models reveal significant limitations: the strongest model (o3) achieves $79.2\\%$ and $78.5\\%$ accuracy on recognition and editing tasks, which are intuitively simple for humans, and performs even worse on the generation task, reaching only $29.0\\%$ accuracy. These results highlight the shortcomings of current AI systems in handling even preliminary molecular recognition and manipulation tasks. We hope MolLangBench will catalyze further research toward more effective and reliable AI systems for chemical applications.', 'abstract_zh': '分子精确识别、编辑和生成是化学家和处理各种化学任务的AI系统的基本前提。我们提出MolLangBench，一个全面的基准测试，用于评估分子-语言接口基本任务：语言提示下的分子结构识别、编辑和生成。为了确保高质量、无歧义和确定性的输出，我们使用自动化化学信息学工具构建识别任务，并通过严格的专家注释和验证，整理编辑和生成任务。MolLangBench 支持语言与不同分子表示形式的接口模型的评估，包括线性字符串、分子图像和分子图。对最先进的模型的评估揭示了显著的限制：最强的模型（o3）在识别和编辑任务中分别达到79.2%和78.5%的准确率，这些任务对人类来说直观上很简单，而在生成任务中表现更差，仅达到29.0%的准确率。这些结果突显了当前AI系统在处理初步的分子识别和操作任务方面的不足之处。我们希望MolLangBench能够推动更多有效的和可靠的AI系统在化学应用方面的进一步研究。', 'title_zh': 'MolLangBench：一种综合性的语言提示分子结构识别、编辑与生成基准'}
{'arxiv_id': 'arXiv:2505.15049', 'title': 'Towards a Working Definition of Designing Generative User Interfaces', 'authors': 'Kyungho Lee', 'link': 'https://arxiv.org/abs/2505.15049', 'abstract': 'Generative UI is transforming interface design by facilitating AI-driven collaborative workflows between designers and computational systems. This study establishes a working definition of Generative UI through a multi-method qualitative approach, integrating insights from a systematic literature review of 127 publications, expert interviews with 18 participants, and analyses of 12 case studies. Our findings identify five core themes that position Generative UI as an iterative and co-creative process. We highlight emerging design models, including hybrid creation, curation-based workflows, and AI-assisted refinement strategies. Additionally, we examine ethical challenges, evaluation criteria, and interaction models that shape the field. By proposing a conceptual foundation, this study advances both theoretical discourse and practical implementation, guiding future HCI research toward responsible and effective generative UI design practices.', 'abstract_zh': '生成型UI正在通过促进设计师与计算系统之间的AI驱动协作工作流来变革界面设计。本研究通过多方法质性研究方法建立生成型UI的工作定义，整合了对127篇出版物的系统文献综述、与18名专家的访谈以及12个案例研究的分析。研究发现，生成型UI表现为一个迭代性和共创性的过程，明确了五个核心主题。研究强调了新兴的设计模式，包括混合创作、策展为基础的工作流和AI辅助的细化策略。此外，研究还考察了塑造该领域的伦理挑战、评估标准和交互模型。通过提出一个概念性基础，本研究不仅推进了理论讨论，还指导了实际实施，并指引未来的HCI研究朝向负责任和有效的生成型UI设计实践。', 'title_zh': '面向生成型用户界面设计的工作性定义'}
{'arxiv_id': 'arXiv:2505.15046', 'title': 'ChartCards: A Chart-Metadata Generation Framework for Multi-Task Chart Understanding', 'authors': 'Yifan Wu, Lutao Yan, Leixian Shen, Yinan Mei, Jiannan Wang, Yuyu Luo', 'link': 'https://arxiv.org/abs/2505.15046', 'abstract': 'The emergence of Multi-modal Large Language Models (MLLMs) presents new opportunities for chart understanding. However, due to the fine-grained nature of these tasks, applying MLLMs typically requires large, high-quality datasets for task-specific fine-tuning, leading to high data collection and training costs. To address this, we propose ChartCards, a unified chart-metadata generation framework for multi-task chart understanding. ChartCards systematically synthesizes various chart information, including data tables, visualization code, visual elements, and multi-dimensional semantic captions. By structuring this information into organized metadata, ChartCards enables a single chart to support multiple downstream tasks, such as text-to-chart retrieval, chart summarization, chart-to-table conversion, chart description, and chart question answering. Using ChartCards, we further construct MetaChart, a large-scale high-quality dataset containing 10,862 data tables, 85K charts, and 170 K high-quality chart captions. We validate the dataset through qualitative crowdsourcing evaluations and quantitative fine-tuning experiments across various chart understanding tasks. Fine-tuning six different models on MetaChart resulted in an average performance improvement of 5% across all tasks. The most notable improvements are seen in text-to-chart retrieval and chart-to-table tasks, with Long-CLIP and Llama 3.2-11B achieving improvements of 17% and 28%, respectively.', 'abstract_zh': '多模态大型语言模型的出现为图表理解带来了新机遇。然而，由于这些任务的精细特性，应用多模态大型语言模型通常需要大规模的高质量数据集进行任务特定的微调，从而导致较高的数据收集和训练成本。为此，我们提出ChartCards，一种统一的多任务图表元数据生成框架。ChartCards系统地综合了各种图表信息，包括数据表、可视化代码、视觉元素和多维度语义注释。通过将这些信息结构化为组织化的元数据，ChartCards使单个图表能够支持多个下游任务，如文本到图表检索、图表总结、图表到表格转换、图表描述和图表问答。使用ChartCards，我们进一步构建了MetaChart，一个包含10,862个数据表、85,000个图表和170,000个高质量图表注释的大规模高质量数据集。我们通过定性众包评估和定量跨多种图表理解任务的微调实验验证了该数据集。在MetaChart上微调六种不同模型后，所有任务的平均性能提升了5%。最显著的改进出现在文本到图表检索和图表到表格任务中，Long-CLIP和Llama 3.2-11B分别取得了17%和28%的提升。', 'title_zh': 'ChartCards：多任务图表理解的图表-元数据生成框架'}
{'arxiv_id': 'arXiv:2505.15039', 'title': 'LogiCase: Effective Test Case Generation from Logical Description in Competitive Programming', 'authors': 'Sicheol Sung, Aditi, Dogyu kim, Yo-Sub Han, Sang-Ki Ko', 'link': 'https://arxiv.org/abs/2505.15039', 'abstract': 'Automated Test Case Generation (ATCG) is crucial for evaluating software reliability, particularly in competitive programming where robust algorithm assessments depend on diverse and accurate test cases. However, existing ATCG methods often fail to meet complex specifications or generate effective corner cases, limiting their utility. In this work, we introduce Context-Free Grammars with Counters (CCFGs), a formalism that captures both syntactic and semantic structures in input specifications. Using a fine-tuned CodeT5 model, we translate natural language input specifications into CCFGs, enabling the systematic generation of high-quality test cases. Experiments on the CodeContests dataset demonstrate that CCFG-based test cases outperform baseline methods in identifying incorrect algorithms, achieving significant gains in validity and effectiveness. Our approach provides a scalable and reliable grammar-driven framework for enhancing automated competitive programming evaluations.', 'abstract_zh': '基于上下文自由文法计数器的自动测试用例生成', 'title_zh': 'LogiCase：来自逻辑描述的有效测试用例生成在竞赛编程中的应用'}
{'arxiv_id': 'arXiv:2505.15031', 'title': 'Are the confidence scores of reviewers consistent with the review content? Evidence from top conference proceedings in AI', 'authors': 'Wenqing Wu, Haixu Xi, Chengzhi Zhang', 'link': 'https://arxiv.org/abs/2505.15031', 'abstract': "Peer review is vital in academia for evaluating research quality. Top AI conferences use reviewer confidence scores to ensure review reliability, but existing studies lack fine-grained analysis of text-score consistency, potentially missing key details. This work assesses consistency at word, sentence, and aspect levels using deep learning and NLP conference review data. We employ deep learning to detect hedge sentences and aspects, then analyze report length, hedge word/sentence frequency, aspect mentions, and sentiment to evaluate text-score alignment. Correlation, significance, and regression tests examine confidence scores' impact on paper outcomes. Results show high text-score consistency across all levels, with regression revealing higher confidence scores correlate with paper rejection, validating expert assessments and peer review fairness.", 'abstract_zh': '基于深度学习和自然语言处理的会议评审文本-评分一致性分析：从词汇、句子到方面', 'title_zh': '顶级AI会议论文集中的审稿人置信度评分是否与评审内容一致：证据探析'}
{'arxiv_id': 'arXiv:2505.15023', 'title': 'Towards a Science of Causal Interpretability in Deep Learning for Software Engineering', 'authors': 'David N. Palacio', 'link': 'https://arxiv.org/abs/2505.15023', 'abstract': "This dissertation addresses achieving causal interpretability in Deep Learning for Software Engineering (DL4SE). While Neural Code Models (NCMs) show strong performance in automating software tasks, their lack of transparency in causal relationships between inputs and outputs limits full understanding of their capabilities. To build trust in NCMs, researchers and practitioners must explain code predictions. Associational interpretability, which identifies correlations, is often insufficient for tasks requiring intervention and change analysis. To address this, the dissertation introduces DoCode, a novel post hoc interpretability method for NCMs. DoCode uses causal inference to provide programming language-oriented explanations of model predictions. It follows a four-step pipeline: modeling causal problems using Structural Causal Models (SCMs), identifying the causal estimand, estimating effects with metrics like Average Treatment Effect (ATE), and refuting effect estimates. Its framework is extensible, with an example that reduces spurious correlations by grounding explanations in programming language properties. A case study on deep code generation across interpretability scenarios and various deep learning architectures demonstrates DoCode's benefits. Results show NCMs' sensitivity to code syntax changes and their ability to learn certain programming concepts while minimizing confounding bias. The dissertation also examines associational interpretability as a foundation, analyzing software information's causal nature using tools like COMET and TraceXplainer for traceability. It highlights the need to identify code confounders and offers practical guidelines for applying causal interpretability to NCMs, contributing to more trustworthy AI in software engineering.", 'abstract_zh': '本论文探讨在软件工程中实现深度学习因果可解释性的方法。尽管神经代码模型在自动化软件任务方面表现出色，但它们在输入和输出之间因果关系上的不透明性限制了对其能力的完全理解。为了建立对神经代码模型的信任，研究者和实践者必须能够解释代码预测。关联可解释性可以识别相关性，但对于需要干预和变化分析的任务来说往往是不够的。为了解决这一问题，本论文介绍了DoCode，这是一种用于神经代码模型的新型事后可解释性方法。DoCode利用因果推理为模型预测提供面向编程语言的解释。该方法包含四个步骤：使用结构因果模型建模因果问题、识别因果估计量、使用平均处理效应等度量估计效应，并反驳效应估计。其框架具有扩展性，通过将解释与编程语言属性联系起来，可以减少虚假相关性。跨可解释性场景和各种深度学习架构的深度代码生成案例研究表明，DoCode的优势。结果表明，神经代码模型对代码语法变化的敏感性以及它们在最小化混杂偏倚的同时学习某些编程概念的能力。此外，本论文还研究了关联可解释性作为基础，并使用COMET和TraceXplainer等工具分析软件信息的因果性质，强调识别代码混杂因子的需求，并提供将因果可解释性应用于神经代码模型的实用指南，从而促进软件工程中更可信的人工智能。', 'title_zh': '面向软件工程中深度学习因果可解释性的科学探索'}
{'arxiv_id': 'arXiv:2505.15009', 'title': 'One-Layer Transformers are Provably Optimal for In-context Reasoning and Distributional Association Learning in Next-Token Prediction Tasks', 'authors': 'Quan Nguyen, Thanh Nguyen-Tang', 'link': 'https://arxiv.org/abs/2505.15009', 'abstract': 'We study the approximation capabilities and on-convergence behaviors of one-layer transformers on the noiseless and noisy in-context reasoning of next-token prediction. Existing theoretical results focus on understanding the in-context reasoning behaviors for either the first gradient step or when the number of samples is infinite. Furthermore, no convergence rates nor generalization abilities were known. Our work addresses these gaps by showing that there exists a class of one-layer transformers that are provably Bayes-optimal with both linear and ReLU attention. When being trained with gradient descent, we show via a finite-sample analysis that the expected loss of these transformers converges at linear rate to the Bayes risk. Moreover, we prove that the trained models generalize to unseen samples as well as exhibit learning behaviors that were empirically observed in previous works. Our theoretical findings are further supported by extensive empirical validations.', 'abstract_zh': '我们研究了单层变压器在无噪声和有噪声上下文推理中下一个token预测的近似能力和收敛行为。现有理论结果主要关注理解梯度第一步或样本数量无限情况下的上下文推理行为。此外，没有关于收敛速率或泛化能力的相关结果。我们的工作通过证明存在一类单层变压器在具有线性注意力和ReLU注意力的情况下可以证明是贝叶斯最优的，填补了这些空白。通过有限样本分析，我们展示了这些变压器在梯度下降训练下期望损失以线性速率收敛到贝叶斯风险。此外，我们证明了这些训练模型在未见过的样本上有良好的泛化能力，并展示了与之前工作 empirically 观察到的学习行为相符的行为。我们的理论发现得到了广泛的实验证据的支持。', 'title_zh': '一层变压器在上下文推理和分布关联学习中的预测下一个词任务中可证明最优'}
{'arxiv_id': 'arXiv:2505.15008', 'title': 'Know When to Abstain: Optimal Selective Classification with Likelihood Ratios', 'authors': 'Alvin Heng, Harold Soh', 'link': 'https://arxiv.org/abs/2505.15008', 'abstract': 'Selective classification enhances the reliability of predictive models by allowing them to abstain from making uncertain predictions. In this work, we revisit the design of optimal selection functions through the lens of the Neyman--Pearson lemma, a classical result in statistics that characterizes the optimal rejection rule as a likelihood ratio test. We show that this perspective not only unifies the behavior of several post-hoc selection baselines, but also motivates new approaches to selective classification which we propose here. A central focus of our work is the setting of covariate shift, where the input distribution at test time differs from that at training. This realistic and challenging scenario remains relatively underexplored in the context of selective classification. We evaluate our proposed methods across a range of vision and language tasks, including both supervised learning and vision-language models. Our experiments demonstrate that our Neyman--Pearson-informed methods consistently outperform existing baselines, indicating that likelihood ratio-based selection offers a robust mechanism for improving selective classification under covariate shifts. Our code is publicly available at this https URL.', 'abstract_zh': '选择性分类通过允许模型对不确定预测保持沉默来增强预测模型的可靠性。在本工作中，我们通过Neyman–Pearson引理的视角重新审视了最优选择函数的设计，该引理是统计学中的一个经典结果，用于表征最优拒绝规则为似然比检验。我们展示了这一视角不仅统一了多种后处理选择基线的行为，还启发了我们在此提出的新型选择性分类方法。我们工作的核心在于特征偏移的情景，即测试时的输入分布与训练时不同。这一现实且具有挑战性的场景在选择性分类中仍相对未被充分探索。我们在视觉和语言任务中评估了我们提出的方法，包括监督学习和视觉-语言模型。我们的实验表明，我们的Neyman–Pearson启发式方法在各种情况下均优于现有基线，表明基于似然比的选择提供了在特征偏移下改善选择性分类的稳健机制。我们的代码已公开，可通过此 [链接] 获取。', 'title_zh': '适可而止：基于似然比的最优选择性分类'}
{'arxiv_id': 'arXiv:2505.15002', 'title': 'Unraveling the iterative CHAD', 'authors': 'Fernando Lucatelli Nunes, Gordon Plotkin, Matthijs Vákár', 'link': 'https://arxiv.org/abs/2505.15002', 'abstract': "Combinatory Homomorphic Automatic Differentiation (CHAD) was originally formulated as a semantics-driven source transformation for reverse-mode AD in total programming languages. We extend this framework to partial languages with features such as potentially non-terminating operations, real-valued conditionals, and iteration constructs like while-loops, while preserving CHAD's structure-preserving semantics principle. A key contribution is the introduction of iteration-extensive indexed categories, which allow iteration in the base category to lift to parameterized initial algebras in the indexed category. This enables iteration to be interpreted in the Grothendieck construction of the target language in a principled way. The resulting fibred iterative structure cleanly models iteration in the categorical semantics. Consequently, the extended CHAD transformation remains the unique structure-preserving functor (an iterative Freyd category morphism) from the freely generated iterative Freyd category of the source language to the Grothendieck construction of the target's syntactic semantics, mapping each primitive operation to its derivative. We prove the correctness of this transformation using the universal property of the source language's syntax, showing that the transformed programs compute correct reverse-mode derivatives. Our development also contributes to understanding iteration constructs within dependently typed languages and categories of containers. As our primary motivation and application, we generalize CHAD to languages with data types, partial features, and iteration, providing the first rigorous categorical semantics for reverse-mode CHAD in such settings and formally guaranteeing the correctness of the source-to-source CHAD technique.", 'abstract_zh': '组合式同态自动微分（CHAD）最初被表述为面向语义的源代码转换框架，用于在完全编程语言中实现反向模式自动微分。我们将这一框架扩展到包含潜在非终止操作、实值条件以及如while循环等迭代构造的部分语言中，同时保持CHAD的结构保存语义原则。一个关键贡献是引入了迭代密集的索引范畴，这使得在基范畴中的迭代能够提升到索引范畴中的参数化初始代数。这种结构使得迭代能够在目标语言的格罗滕迪克构造中以原理性的方式进行解释。由此产生的纤维迭代结构清晰地模型化了范畴语义中的迭代。因此，扩展后的CHAD转换仍然是从源语言自由生成的迭代 Freyd 范畴到目标语言语法语义的格罗滕迪克构造的独特结构保存函子（即迭代 Freyd 范畴同构），并将每个原始操作映射到其导数。我们使用源语言语法的 universal 性质证明了这一转换的正确性，显示出转换后的程序计算出正确的反向模式导数。我们的开发也有助于理解依赖类型语言和容器范畴中的迭代构造。我们主要的动力和应用是将CHAD推广到包含数据类型、部分特性和迭代的语言中，首次为这样的环境下提供严格的范畴语义，并正式保证源到源CHAD技术的正确性。', 'title_zh': '解开迭代CHAD的奥秘'}
{'arxiv_id': 'arXiv:2505.14976', 'title': 'SDLog: A Deep Learning Framework for Detecting Sensitive Information in Software Logs', 'authors': 'Roozbeh Aghili, Xingfang Wu, Foutse Khomh, Heng Li', 'link': 'https://arxiv.org/abs/2505.14976', 'abstract': 'Software logs are messages recorded during the execution of a software system that provide crucial run-time information about events and activities. Although software logs have a critical role in software maintenance and operation tasks, publicly accessible log datasets remain limited, hindering advance in log analysis research and practices. The presence of sensitive information, particularly Personally Identifiable Information (PII) and quasi-identifiers, introduces serious privacy and re-identification risks, discouraging the publishing and sharing of real-world logs. In practice, log anonymization techniques primarily rely on regular expression patterns, which involve manually crafting rules to identify and replace sensitive information. However, these regex-based approaches suffer from significant limitations, such as extensive manual efforts and poor generalizability across diverse log formats and datasets. To mitigate these limitations, we introduce SDLog, a deep learning-based framework designed to identify sensitive information in software logs. Our results show that SDLog overcomes regex limitations and outperforms the best-performing regex patterns in identifying sensitive information. With only 100 fine-tuning samples from the target dataset, SDLog can correctly identify 99.5% of sensitive attributes and achieves an F1-score of 98.4%. To the best of our knowledge, this is the first deep learning alternative to regex-based methods in software log anonymization.', 'abstract_zh': '基于深度学习的软件日志脱敏框架SDLog：克服正则表达式限制并有效识别敏感信息', 'title_zh': 'SDLog: 一种检测软件日志中敏感信息的深度学习框架'}
{'arxiv_id': 'arXiv:2505.14969', 'title': 'STree: Speculative Tree Decoding for Hybrid State-Space Models', 'authors': 'Yangchao Wu, Zongyue Qin, Alex Wong, Stefano Soatto', 'link': 'https://arxiv.org/abs/2505.14969', 'abstract': 'Speculative decoding is a technique to leverage hardware concurrency to improve the efficiency of large-scale autoregressive (AR) Transformer models by enabling multiple steps of token generation in a single forward pass. State-space models (SSMs) are already more efficient than AR Transformers, since their state summarizes all past data with no need to cache or re-process tokens in the sliding window context. However, their state can also comprise thousands of tokens; so, speculative decoding has recently been extended to SSMs. Existing approaches, however, do not leverage the tree-based verification methods, since current SSMs lack the means to compute a token tree efficiently. We propose the first scalable algorithm to perform tree-based speculative decoding in state-space models (SSMs) and hybrid architectures of SSMs and Transformer layers. We exploit the structure of accumulated state transition matrices to facilitate tree-based speculative decoding with minimal overhead to current SSM state update implementations. With the algorithm, we describe a hardware-aware implementation that improves naive application of AR Transformer tree-based speculative decoding methods to SSMs. Furthermore, we outperform vanilla speculative decoding with SSMs even with a baseline drafting model and tree structure on three different benchmarks, opening up opportunities for further speed up with SSM and hybrid model inference. Code will be released upon paper acceptance.', 'abstract_zh': '基于状态空间模型的推测解码算法', 'title_zh': 'STree: 谐波状态空间模型的 speculative 树解码'}
{'arxiv_id': 'arXiv:2505.14967', 'title': 'Anomaly Detection Based on Critical Paths for Deep Neural Networks', 'authors': 'Fangzhen Zhao, Chenyi Zhang, Naipeng Dong, Ming Li, Jinxiao Shan', 'link': 'https://arxiv.org/abs/2505.14967', 'abstract': 'Deep neural networks (DNNs) are notoriously hard to understand and difficult to defend. Extracting representative paths (including the neuron activation values and the connections between neurons) from DNNs using software engineering approaches has recently shown to be a promising approach in interpreting the decision making process of blackbox DNNs, as the extracted paths are often effective in capturing essential features. With this in mind, this work investigates a novel approach that extracts critical paths from DNNs and subsequently applies the extracted paths for the anomaly detection task, based on the observation that outliers and adversarial inputs do not usually induce the same activation pattern on those paths as normal (in-distribution) inputs.\nIn our approach, we first identify critical detection paths via genetic evolution and mutation. Since different paths in a DNN often capture different features for the same target class, we ensemble detection results from multiple paths by integrating random subspace sampling and a voting mechanism. Compared with state-of-the-art methods, our experimental results suggest that our method not only outperforms them, but it is also suitable for the detection of a broad range of anomaly types with high accuracy.', 'abstract_zh': '深度神经网络（DNNs） notoriously难以理解和难以防御。通过软件工程方法提取代表性的路径（包括神经元激活值和神经元之间的连接）， recent研究表明这在解释黑盒子DNNs的决策过程方面具有显著潜力，因为提取的路径通常能捕捉到关键特征。基于异常值和对抗输入通常不会在路径上诱导与正常（内分布）输入相同的激活模式的观察，本研究探讨了一种新方法，该方法从DNNs中提取关键路径，并随后利用提取的路径进行 anomaly检测任务。在我们的方法中，我们首先通过遗传进化和突变识别关键检测路径。由于DNN中的不同路径通常为同一目标类别捕捉不同的特征，我们通过集成随机子空间采样和投票机制来聚合多种路径的检测结果。与现有最先进的方法相比，我们的实验结果表明，我们的方法不仅性能更优，而且适用于高精度地检测多种类型的异常。', 'title_zh': '基于关键路径的深度神经网络异常检测'}
{'arxiv_id': 'arXiv:2505.14964', 'title': 'The Achilles Heel of AI: Fundamentals of Risk-Aware Training Data for High-Consequence Models', 'authors': 'Dave Cook, Tim Klawa', 'link': 'https://arxiv.org/abs/2505.14964', 'abstract': 'AI systems in high-consequence domains such as defense, intelligence, and disaster response must detect rare, high-impact events while operating under tight resource constraints. Traditional annotation strategies that prioritize label volume over informational value introduce redundancy and noise, limiting model generalization. This paper introduces smart-sizing, a training data strategy that emphasizes label diversity, model-guided selection, and marginal utility-based stopping. We implement this through Adaptive Label Optimization (ALO), combining pre-labeling triage, annotator disagreement analysis, and iterative feedback to prioritize labels that meaningfully improve model performance. Experiments show that models trained on 20 to 40 percent of curated data can match or exceed full-data baselines, particularly in rare-class recall and edge-case generalization. We also demonstrate how latent labeling errors embedded in training and validation sets can distort evaluation, underscoring the need for embedded audit tools and performance-aware governance. Smart-sizing reframes annotation as a feedback-driven process aligned with mission outcomes, enabling more robust models with fewer labels and supporting efficient AI development pipelines for frontier models and operational systems.', 'abstract_zh': '人工智能系统在高后果领域如防御、情报和灾害响应中必须在资源受限的情况下检测罕见的高影响事件。传统的注释策略强调标签数量而忽视信息价值，引入了冗余和噪声，限制了模型的泛化能力。本文介绍了一种智能规模策略smart-sizing，该策略强调标签多样性、模型引导选择和边际效用为基础的终止策略。我们通过自适应标签优化（ALO）实现这一策略，结合预注释筛选、注释员分歧分析和迭代反馈，优先选择能实质性提高模型性能的标签。实验表明，使用20%到40%的精标注数据训练的模型可以匹配或超越全部数据的基线，特别是在罕见类召回率和边缘案例泛化方面。我们还展示了训练和验证集中嵌入的潜在标签错误如何扭曲评估，强调了嵌入式审计工具和性能感知治理的需求。智能规模策略将注释重新框定为与任务目标一致的反馈驱动过程，使模型更具鲁棒性，需要的标签更少，支持前沿模型和操作系统的高效人工智能开发流程。', 'title_zh': 'AI的薄弱环节：高后果模型的风险意识训练数据基础'}
{'arxiv_id': 'arXiv:2505.14901', 'title': 'Personalized Diffusion Model Reshapes Cold-Start Bundle Recommendation', 'authors': 'Tuan-Nghia Bui, Huy-Son Nguyen, Cam-Van Thi Nguyen, Hoang-Quynh Le, Duc-Trong Le', 'link': 'https://arxiv.org/abs/2505.14901', 'abstract': "Bundle recommendation aims to recommend a set of items to each user. However, the sparser interactions between users and bundles raise a big challenge, especially in cold-start scenarios. Traditional collaborative filtering methods do not work well for this kind of problem because these models rely on interactions to update the latent embedding, which is hard to work in a cold-start setting. We propose a new approach (DisCo), which relies on a personalized Diffusion backbone, enhanced by disentangled aspects for the user's interest, to generate a bundle in distribution space for each user to tackle the cold-start challenge. During the training phase, DisCo adjusts an additional objective loss term to avoid bias, a prevalent issue while using the generative model for top-$K$ recommendation purposes. Our empirical experiments show that DisCo outperforms five comparative baselines by a large margin on three real-world datasets. Thereby, this study devises a promising framework and essential viewpoints in cold-start recommendation. Our materials for reproducibility are available at: this https URL.", 'abstract_zh': '基于个性化的解耦扩散模型在冷启动束推荐中的应用', 'title_zh': '个性化扩散模型重塑冷启动组合推荐'}
{'arxiv_id': 'arXiv:2505.14862', 'title': 'Replay Attacks Against Audio Deepfake Detection', 'authors': 'Nicolas Müller, Piotr Kawa, Wei-Herng Choong, Adriana Stan, Aditya Tirumala Bukkapatnam, Karla Pizzi, Alexander Wagner, Philip Sperl', 'link': 'https://arxiv.org/abs/2505.14862', 'abstract': "We show how replay attacks undermine audio deepfake detection: By playing and re-recording deepfake audio through various speakers and microphones, we make spoofed samples appear authentic to the detection model. To study this phenomenon in more detail, we introduce ReplayDF, a dataset of recordings derived from M-AILABS and MLAAD, featuring 109 speaker-microphone combinations across six languages and four TTS models. It includes diverse acoustic conditions, some highly challenging for detection. Our analysis of six open-source detection models across five datasets reveals significant vulnerability, with the top-performing W2V2-AASIST model's Equal Error Rate (EER) surging from 4.7% to 18.2%. Even with adaptive Room Impulse Response (RIR) retraining, performance remains compromised with an 11.0% EER. We release ReplayDF for non-commercial research use.", 'abstract_zh': '我们展示了重播攻击如何削弱音频深度合成检测：通过在不同扬声器和麦克风之间播放和重新录制深度合成音频，使欺骗性样本对检测模型显得真实。为了更详细地研究这一现象，我们引入了ReplayDF数据集，该数据集基于M-AILABS和MLAAD，包含六种语言和四种TTS模型的109种扬声器-麦克风组合，涵盖了各种各样的声学条件，其中一些条件对检测极具挑战性。我们对五个数据集上的六个开源检测模型的分析揭示了显著的脆弱性，顶级的W2V2-AASIST模型的等错误率（EER）从4.7%升至18.2%，即使进行了自适应厅堂冲激响应（RIR）重新训练，性能仍受损，EER为11.0%。我们为非商业研究目的发布了ReplayDF数据集。', 'title_zh': '针对音频深度换音检测的重放攻击'}
{'arxiv_id': 'arXiv:2505.14852', 'title': 'EasyMath: A 0-shot Math Benchmark for SLMs', 'authors': 'Drishya Karki, Michiel Kamphuis, Angelecia Frey', 'link': 'https://arxiv.org/abs/2505.14852', 'abstract': 'EasyMath is a compact benchmark for practical math reasoning in small language models. It covers thirteen categories, from basic arithmetic and order of operations to word problems, algebraic expressions, edge cases, and omits specialist topics. We tested 23 models (14M to 4B parameters) using exact, numerical, and symbolic checks on free-form answers in a zero-shot setting. Accuracy rises with size and training, chain-of-thought adds modest gains, and consistency improves at scale.', 'abstract_zh': 'EasyMath是适用于小型语言模型实际数学推理的紧凑基准', 'title_zh': 'EasyMath: 一种用于SLMs的零样本数学基准测试'}
{'arxiv_id': 'arXiv:2505.14841', 'title': 'Beyond Pairwise Plasticity: Group-Level Spike Synchrony Facilitates Efficient Learning in Spiking Neural Networks', 'authors': 'Yuchen Tian, Assel Kembay, Nhan Duy Truong, Jason K. Eshraghian, Omid Kavehei', 'link': 'https://arxiv.org/abs/2505.14841', 'abstract': "Brain networks rely on precise spike timing and coordinated activity to support robust and energy-efficient learning. Inspired by these principles, spiking neural networks (SNNs) are widely regarded as promising candidates for low-power, event-driven computing. However, most biologically-inspired learning rules employed in SNNs, including spike-timing-dependent plasticity (STDP), rely on isolated spike pairs and lack sensitivity to population-level activity. This limits their stability and generalization, particularly in noisy and fast-changing environments. Motivated by biological observations that neural synchrony plays a central role in learning and memory, we introduce a spike-synchrony-dependent plasticity (SSDP) rule that adjusts synaptic weights based on the degree of coordinated firing among neurons. SSDP supports stable and scalable learning by encouraging neurons to form coherent activity patterns. One prominent outcome is a sudden transition from unstable to stable dynamics during training, suggesting that synchrony may drive convergence toward equilibrium firing regimes. We demonstrate SSDP's effectiveness across multiple network types, from minimal-layer models to spiking ResNets and SNN-Transformer. To our knowledge, this is the first application of a synaptic plasticity mechanism in a spiking transformer. SSDP operates in a fully event-driven manner and incurs minimal computational cost, making it well-suited for neuromorphic deployment. In this approach, local synaptic modifications are associated with the collective dynamics of neural networks, resulting in a learning strategy that adheres to biological principles while maintaining practical efficiency, these findings position SSDP as a general-purpose optimization strategy for SNNs, while offering new insights into population-based learning mechanisms in the brain.", 'abstract_zh': '基于尖峰同步依赖可塑性的低功耗事件驱动计算中的稳健和高效学习', 'title_zh': '超越成对塑性：群体级尖峰同步促进突触神经网络中的高效学习'}
{'arxiv_id': 'arXiv:2505.14838', 'title': 'In-depth Research Impact Summarization through Fine-Grained Temporal Citation Analysis', 'authors': 'Hiba Arnaout, Noy Sternlicht, Tom Hope, Iryna Gurevych', 'link': 'https://arxiv.org/abs/2505.14838', 'abstract': 'Understanding the impact of scientific publications is crucial for identifying breakthroughs and guiding future research. Traditional metrics based on citation counts often miss the nuanced ways a paper contributes to its field. In this work, we propose a new task: generating nuanced, expressive, and time-aware impact summaries that capture both praise (confirmation citations) and critique (correction citations) through the evolution of fine-grained citation intents. We introduce an evaluation framework tailored to this task, showing moderate to strong human correlation on subjective metrics such as insightfulness. Expert feedback from professors reveals a strong interest in these summaries and suggests future improvements.', 'abstract_zh': '理解科学出版物的影响对于识别突破性和指导未来研究至关重要。基于引文数量的传统指标往往忽略了论文对领域贡献的细微之处。在这项工作中，我们提出了一项新的任务：生成细腻、富有表现力且具有时间意识的影响总结，通过细粒度引文意图的演变捕捉赞许（确认引文）和批评（纠正引文）。我们介绍了针对该任务的评估框架，展示了在洞察力等主观指标上具有中等到强烈的-human-相关性。专家反馈表明教授们对该类总结非常感兴趣，并建议了未来改进的方向。', 'title_zh': '细粒度 temporal 引文分析驱动的深入研究影响总结'}
{'arxiv_id': 'arXiv:2505.14821', 'title': 'Sample and Computationally Efficient Continuous-Time Reinforcement Learning with General Function Approximation', 'authors': 'Runze Zhao, Yue Yu, Adams Yiyue Zhu, Chen Yang, Dongruo Zhou', 'link': 'https://arxiv.org/abs/2505.14821', 'abstract': 'Continuous-time reinforcement learning (CTRL) provides a principled framework for sequential decision-making in environments where interactions evolve continuously over time. Despite its empirical success, the theoretical understanding of CTRL remains limited, especially in settings with general function approximation. In this work, we propose a model-based CTRL algorithm that achieves both sample and computational efficiency. Our approach leverages optimism-based confidence sets to establish the first sample complexity guarantee for CTRL with general function approximation, showing that a near-optimal policy can be learned with a suboptimality gap of $\\tilde{O}(\\sqrt{d_{\\mathcal{R}} + d_{\\mathcal{F}}}N^{-1/2})$ using $N$ measurements, where $d_{\\mathcal{R}}$ and $d_{\\mathcal{F}}$ denote the distributional Eluder dimensions of the reward and dynamic functions, respectively, capturing the complexity of general function approximation in reinforcement learning. Moreover, we introduce structured policy updates and an alternative measurement strategy that significantly reduce the number of policy updates and rollouts while maintaining competitive sample efficiency. We implemented experiments to backup our proposed algorithms on continuous control tasks and diffusion model fine-tuning, demonstrating comparable performance with significantly fewer policy updates and rollouts.', 'abstract_zh': '连续时间强化学习（CTRL）为在时间上连续交互的环境中进行序决策提供了基本原则框架。尽管其在实践中取得了成功，但关于CTRL的理论理解仍然有限，尤其是在一般函数近似的设置中。在本文中，我们提出了一种基于模型的CTRL算法，实现了样本效率和计算效率的双重提升。我们利用基于乐观性的置信集建立了一种关于一般函数近似下的连续时间强化学习的第一个样本复杂性保证，表明使用$N$次测量可以以近最优策略，其次优性差距为$\\tilde{O}(\\sqrt{d_{\\mathcal{R}} + d_{\\mathcal{F}}}N^{-1/2})$，其中$d_{\\mathcal{R}}$和$d_{\\mathcal{F}}$分别表示奖励函数和动态函数的分布Eluder维数，捕捉强化学习中一般函数近似的复杂性。此外，我们引入了结构化的策略更新和一种替代的测量策略，显著减少了策略更新和展开次数，同时保持了竞争力的样本效率。我们在连续控制任务和扩散模型微调中的实验验证了我们提出的算法的有效性，显示出接近同等性能的同时显著减少了策略更新和展开次数。', 'title_zh': '一般函数逼近下的采样高效连续时间强化学习'}
{'arxiv_id': 'arXiv:2505.14803', 'title': 'SurvUnc: A Meta-Model Based Uncertainty Quantification Framework for Survival Analysis', 'authors': 'Yu Liu, Weiyao Tao, Tong Xia, Simon Knight, Tingting Zhu', 'link': 'https://arxiv.org/abs/2505.14803', 'abstract': 'Survival analysis, which estimates the probability of event occurrence over time from censored data, is fundamental in numerous real-world applications, particularly in high-stakes domains such as healthcare and risk assessment. Despite advances in numerous survival models, quantifying the uncertainty of predictions from these models remains underexplored and challenging. The lack of reliable uncertainty quantification limits the interpretability and trustworthiness of survival models, hindering their adoption in clinical decision-making and other sensitive applications. To bridge this gap, in this work, we introduce SurvUnc, a novel meta-model based framework for post-hoc uncertainty quantification for survival models. SurvUnc introduces an anchor-based learning strategy that integrates concordance knowledge into meta-model optimization, leveraging pairwise ranking performance to estimate uncertainty effectively. Notably, our framework is model-agnostic, ensuring compatibility with any survival model without requiring modifications to its architecture or access to its internal parameters. Especially, we design a comprehensive evaluation pipeline tailored to this critical yet overlooked problem. Through extensive experiments on four publicly available benchmarking datasets and five representative survival models, we demonstrate the superiority of SurvUnc across multiple evaluation scenarios, including selective prediction, misprediction detection, and out-of-domain detection. Our results highlight the effectiveness of SurvUnc in enhancing model interpretability and reliability, paving the way for more trustworthy survival predictions in real-world applications.', 'abstract_zh': '基于锚点的学习策略驱动的生存模型后验不确定性量化框架：SurvUnc', 'title_zh': 'SurvUnc：基于元模型的生存分析不确定性量化框架'}
{'arxiv_id': 'arXiv:2505.14777', 'title': 'KO: Kinetics-inspired Neural Optimizer with PDE Simulation Approaches', 'authors': 'Mingquan Feng, Yixin Huang, Yifan Fu, Shaobo Wang, Junchi Yan', 'link': 'https://arxiv.org/abs/2505.14777', 'abstract': 'The design of optimization algorithms for neural networks remains a critical challenge, with most existing methods relying on heuristic adaptations of gradient-based approaches. This paper introduces KO (Kinetics-inspired Optimizer), a novel neural optimizer inspired by kinetic theory and partial differential equation (PDE) simulations. We reimagine the training dynamics of network parameters as the evolution of a particle system governed by kinetic principles, where parameter updates are simulated via a numerical scheme for the Boltzmann transport equation (BTE) that models stochastic particle collisions. This physics-driven approach inherently promotes parameter diversity during optimization, mitigating the phenomenon of parameter condensation, i.e. collapse of network parameters into low-dimensional subspaces, through mechanisms analogous to thermal diffusion in physical systems. We analyze this property, establishing both a mathematical proof and a physical interpretation. Extensive experiments on image classification (CIFAR-10/100, ImageNet) and text classification (IMDB, Snips) tasks demonstrate that KO consistently outperforms baseline optimizers (e.g., Adam, SGD), achieving accuracy improvements while computation cost remains comparable.', 'abstract_zh': '基于动理学的神经网络优化算法设计：一种受动理学和偏微分方程启发的新型神经优化器', 'title_zh': '基于偏微分方程仿真方法的动力学启发神经优化器'}
{'arxiv_id': 'arXiv:2505.14766', 'title': 'This Time is Different: An Observability Perspective on Time Series Foundation Models', 'authors': 'Ben Cohen, Emaad Khwaja, Youssef Doubli, Salahidine Lemaachi, Chris Lettieri, Charles Masson, Hugo Miccinilli, Elise Ramé, Qiqi Ren, Afshin Rostamizadeh, Jean Ogier du Terrail, Anna-Monica Toon, Kan Wang, Stephan Xie, David Asker, Ameet Talwalkar, Othmane Abou-Amal', 'link': 'https://arxiv.org/abs/2505.14766', 'abstract': "We introduce Toto, a time series forecasting foundation model with 151 million parameters. Toto uses a modern decoder-only architecture coupled with architectural innovations designed to account for specific challenges found in multivariate observability time series data. Toto's pre-training corpus is a mixture of observability data, open datasets, and synthetic data, and is 4-10$\\times$ larger than those of leading time series foundation models. Additionally, we introduce BOOM, a large-scale benchmark consisting of 350 million observations across 2,807 real-world time series. For both Toto and BOOM, we source observability data exclusively from Datadog's own telemetry and internal observability metrics. Extensive evaluations demonstrate that Toto achieves state-of-the-art performance on both BOOM and on established general purpose time series forecasting benchmarks. Toto's model weights, inference code, and evaluation scripts, as well as BOOM's data and evaluation code, are all available as open source under the Apache 2.0 License available at this https URL and this https URL.", 'abstract_zh': '我们介绍了Toto，一个拥有1510万参数的时间序列forecasting基础模型。Toto采用现代的解码器架构，并结合了针对多变量可观测性时间序列数据中特定挑战设计的架构创新。Toto的预训练语料库包括可观测性数据、开源数据集和合成数据，其规模是领先时间序列基础模型的4-10倍。此外，我们还引入了BOOM大规模基准，包含2807个真实世界时间序列的3.5亿个观测数据。对于Toto和BOOM，我们 exclusively从Datadog自身的遥测和内部可观测性指标中获取可观测性数据。广泛评估表明，Toto在BOOM和标准通用时间序列预测基准测试中均实现了最先进的性能。Toto的模型权重、推理代码和评估脚本，以及BOOM的数据和评估代码均已根据Apache 2.0许可协议开源并可在以下链接获取：此链接和此链接。', 'title_zh': '这一次与以往不同：时间序列基础模型的可观测性视角'}
{'arxiv_id': 'arXiv:2505.14765', 'title': 'Deep Learning-Based Forecasting of Boarding Patient Counts to Address ED Overcrowding', 'authors': 'Orhun Vural, Bunyamin Ozaydin, Khalid Y. Aram, James Booth, Brittany F. Lindsey, Abdulaziz Ahmed', 'link': 'https://arxiv.org/abs/2505.14765', 'abstract': 'This study develops deep learning models to forecast the number of patients in the emergency department (ED) boarding phase six hours in advance, aiming to support proactive operational decision-making using only non-clinical, operational, and contextual features. Data were collected from five sources: ED tracking systems, inpatient census records, weather reports, federal holiday calendars, and local event schedules. After feature engineering, the data were aggregated at an hourly level, cleaned, and merged into a unified dataset for model training. Several time series deep learning models, including ResNetPlus, TSTPlus, TSiTPlus (from the tsai library), and N-BEATSx, were trained using Optuna and grid search for hyperparameter tuning. The average ED boarding count was 28.7, with a standard deviation of 11.2. N-BEATSx achieved the best performance, with a mean absolute error of 2.10, mean squared error of 7.08, root mean squared error of 2.66, and a coefficient of determination of 0.95. The model maintained stable accuracy even during periods of extremely high boarding counts, defined as values exceeding one, two, or three standard deviations above the mean. Results show that accurate six-hour-ahead forecasts are achievable without using patient-level clinical data. While strong performance was observed even with a basic feature set, the inclusion of additional features improved prediction stability under extreme conditions. This framework offers a practical and generalizable approach for hospital systems to anticipate boarding levels and help mitigate ED overcrowding.', 'abstract_zh': '本研究开发了深度学习模型，以提前六小时预测急诊部门入住阶段的患者人数，旨在仅使用非临床、操作性和背景特征支持主动运营决策。数据来源于五个来源：急诊部门跟踪系统、住院患者统计记录、天气报告、联邦假期日历和本地活动日程。经过特征工程后，数据按小时聚合、清洗并整合成统一的数据集用于模型训练。使用Optuna和网格搜索对超参数进行调整，训练了包括ResNetPlus、TSTPlus、TSiTPlus（来自tsai库）和N-BEATSx在内的多种时间序列深度学习模型。平均急诊部门入住计数为28.7，标准偏差为11.2。N-BEATSx模型表现最佳，平均绝对误差为2.10，均方误差为7.08，均方根误差为2.66，决定系数为0.95。即使在极高的入住计数时期（超出均值一个、两个或三个标准差），模型仍能保持稳定的准确性。结果表明，无需使用患者级临床数据即可实现精确的六小时提前预测。即使在基本特征集下也能观察到很强的性能，额外特征的加入在极端条件下提高了预测稳定性。该框架为医院系统提供了一个可行且可推广的方法，以预见入住水平并帮助缓解急诊部门拥挤。', 'title_zh': '基于深度学习的候诊患者数量预测模型以应对急诊 overcrowding'}
{'arxiv_id': 'arXiv:2505.14757', 'title': 'Bridge2AI: Building A Cross-disciplinary Curriculum Towards AI-Enhanced Biomedical and Clinical Care', 'authors': 'John Rincon, Alexander R. Pelletier, Destiny Gilliland, Wei Wang, Ding Wang, Baradwaj S. Sankar, Lori Scott-Sheldon, Samson Gebreab, William Hersh, Parisa Rashidi, Sally Baxter, Wade Schulz, Trey Ideker, Yael Bensoussan, Paul C. Boutros, Alex A.T. Bui, Colin Walsh, Karol E. Watson, Peipei Ping', 'link': 'https://arxiv.org/abs/2505.14757', 'abstract': 'Objective: As AI becomes increasingly central to healthcare, there is a pressing need for bioinformatics and biomedical training systems that are personalized and adaptable. Materials and Methods: The NIH Bridge2AI Training, Recruitment, and Mentoring (TRM) Working Group developed a cross-disciplinary curriculum grounded in collaborative innovation, ethical data stewardship, and professional development within an adapted Learning Health System (LHS) framework. Results: The curriculum integrates foundational AI modules, real-world projects, and a structured mentee-mentor network spanning Bridge2AI Grand Challenges and the Bridge Center. Guided by six learner personas, the program tailors educational pathways to individual needs while supporting scalability. Discussion: Iterative refinement driven by continuous feedback ensures that content remains responsive to learner progress and emerging trends. Conclusion: With over 30 scholars and 100 mentors engaged across North America, the TRM model demonstrates how adaptive, persona-informed training can build interdisciplinary competencies and foster an integrative, ethically grounded AI education in biomedical contexts.', 'abstract_zh': '目标：随着人工智能在医疗保健中的作用不断增强，个性化和适应性强的生物信息学和生物医学培训系统的需求日益迫切。材料与方法：NIH Bridge2AI培训、招聘和指导（TRM）工作组开发了一门跨学科课程，该课程基于合作创新、伦理数据治理和专业发展，并采用适应性学习健康系统（LHS）框架。结果：该课程整合了基础人工智能模块、实际项目以及覆盖Bridge2AI重大挑战和Bridge中心的结构化学员-导师网络。根据六个学习者角色，该计划通过量身定制的教育路径满足个体需求，同时支持扩展性。讨论：通过持续反馈驱动的迭代改进确保课程内容能够响应学习者进步和新兴趋势。结论：在全球范围内，有超过30位学者和100位导师参与的TRM模式证明了如何通过适应性和角色指导培训来建立跨学科能力，并促进包含伦理基础的生物医学背景下的人工智能教育。', 'title_zh': 'Bridge2AI: 构建跨学科课程以实现人工智能增强的生物医学和临床护理'}
{'arxiv_id': 'arXiv:2505.14753', 'title': 'TransMedSeg: A Transferable Semantic Framework for Semi-Supervised Medical Image Segmentation', 'authors': 'Mengzhu Wang, Jiao Li, Shanshan Wang, Long Lan, Huibin Tan, Liang Yang, Guoli Yang', 'link': 'https://arxiv.org/abs/2505.14753', 'abstract': 'Semi-supervised learning (SSL) has achieved significant progress in medical image segmentation (SSMIS) through effective utilization of limited labeled data. While current SSL methods for medical images predominantly rely on consistency regularization and pseudo-labeling, they often overlook transferable semantic relationships across different clinical domains and imaging modalities. To address this, we propose TransMedSeg, a novel transferable semantic framework for semi-supervised medical image segmentation. Our approach introduces a Transferable Semantic Augmentation (TSA) module, which implicitly enhances feature representations by aligning domain-invariant semantics through cross-domain distribution matching and intra-domain structural preservation. Specifically, TransMedSeg constructs a unified feature space where teacher network features are adaptively augmented towards student network semantics via a lightweight memory module, enabling implicit semantic transformation without explicit data generation. Interestingly, this augmentation is implicitly realized through an expected transferable cross-entropy loss computed over the augmented teacher distribution. An upper bound of the expected loss is theoretically derived and minimized during training, incurring negligible computational overhead. Extensive experiments on medical image datasets demonstrate that TransMedSeg outperforms existing semi-supervised methods, establishing a new direction for transferable representation learning in medical image analysis.', 'abstract_zh': '半监督学习（SSL）通过有效利用有限的标注数据在医学图像分割（SSMIS）中取得了显著进展。为了解决当前医学图像SSL方法主要依赖一致性正则化和伪标签标注但忽视了不同临床领域和成像模态之间的可转移语义关系的问题，我们提出了一种新的可转移语义框架TransMedSeg用于医学图像分割。我们的方法引入了一个可转移语义增强（TSA）模块，通过跨域分布匹配和域内结构保持隐式增强特征表示，使得在不进行显式数据生成的情况下实现隐式的语义变换。有趣的是，这一增强是通过计算增强后的教师分布的期望可转移交叉熵损失隐式实现的。在训练过程中，理论上推导并最小化了该期望损失的上限，几乎不增加计算开销。广泛的实验表明，TransMedSeg显著优于现有的半监督方法，为医学图像分析中的可转移表示学习开辟了新的方向。', 'title_zh': 'TransMedSeg: 一个适用于半监督医疗图像分割的可转移语义框架'}
{'arxiv_id': 'arXiv:2505.14751', 'title': 'Self Distillation via Iterative Constructive Perturbations', 'authors': 'Maheak Dave, Aniket Kumar Singh, Aryan Pareek, Harshita Jha, Debasis Chaudhuri, Manish Pratap Singh', 'link': 'https://arxiv.org/abs/2505.14751', 'abstract': "Deep Neural Networks have achieved remarkable achievements across various domains, however balancing performance and generalization still remains a challenge while training these networks. In this paper, we propose a novel framework that uses a cyclic optimization strategy to concurrently optimize the model and its input data for better training, rethinking the traditional training paradigm. Central to our approach is Iterative Constructive Perturbation (ICP), which leverages the model's loss to iteratively perturb the input, progressively constructing an enhanced representation over some refinement steps. This ICP input is then fed back into the model to produce improved intermediate features, which serve as a target in a self-distillation framework against the original features. By alternately altering the model's parameters to the data and the data to the model, our method effectively addresses the gap between fitting and generalization, leading to enhanced performance. Extensive experiments demonstrate that our approach not only mitigates common performance bottlenecks in neural networks but also demonstrates significant improvements across training variations.", 'abstract_zh': '深度神经网络已在各种领域取得了显著成就，但在训练过程中平衡性能和泛化能力仍是一项挑战。本文提出了一种新颖的框架，采用循环优化策略同时优化模型及其输入数据，重新思考传统的训练范式。该方法的核心是迭代构造扰动（ICP），它利用模型的损失，逐步迭代地扰动输入，构建增强表示。这种ICP输入随后被反馈给模型，生成改进的中间特征，这些特征作为自蒸馏框架中的目标与原始特征进行对比。通过交替调整模型参数和数据，我们的方法有效地解决了拟合与泛化之间的差距，从而提升性能。大量实验证明，我们的方法不仅缓解了神经网络中的常见性能瓶颈，还在训练变化中显示出显著的改进。', 'title_zh': '迭代构造性扰动下的自我蒸馏'}
{'arxiv_id': 'arXiv:2505.14745', 'title': 'Explainable Prediction of the Mechanical Properties of Composites with CNNs', 'authors': 'Varun Raaghav, Dimitrios Bikos, Antonio Rago, Francesca Toni, Maria Charalambides', 'link': 'https://arxiv.org/abs/2505.14745', 'abstract': "Composites are amongst the most important materials manufactured today, as evidenced by their use in countless applications. In order to establish the suitability of composites in specific applications, finite element (FE) modelling, a numerical method based on partial differential equations, is the industry standard for assessing their mechanical properties. However, FE modelling is exceptionally costly from a computational viewpoint, a limitation which has led to efforts towards applying AI models to this task. However, in these approaches: the chosen model architectures were rudimentary, feed-forward neural networks giving limited accuracy; the studies focus on predicting elastic mechanical properties, without considering material strength limits; and the models lacked transparency, hindering trustworthiness by users. In this paper, we show that convolutional neural networks (CNNs) equipped with methods from explainable AI (XAI) can be successfully deployed to solve this problem. Our approach uses customised CNNs trained on a dataset we generate using transverse tension tests in FE modelling to predict composites' mechanical properties, i.e., Young's modulus and yield strength. We show empirically that our approach achieves high accuracy, outperforming a baseline, ResNet-34, in estimating the mechanical properties. We then use SHAP and Integrated Gradients, two post-hoc XAI methods, to explain the predictions, showing that the CNNs use the critical geometrical features that influence the composites' behaviour, thus allowing engineers to verify that the models are trustworthy by representing the science of composites.", 'abstract_zh': '基于卷积神经网络和可解释AI的复合材料力学性能预测', 'title_zh': '用CNNs解释预测复合材料的机械性能'}
{'arxiv_id': 'arXiv:2505.14744', 'title': 'Transductively Informed Inductive Program Synthesis', 'authors': 'Janis Zenkner, Tobias Sesterhenn, Christian Bartelt', 'link': 'https://arxiv.org/abs/2505.14744', 'abstract': 'Abstraction and reasoning in program synthesis has seen significant progress through both inductive and transductive paradigms. Inductive approaches generate a program or latent function from input-output examples, which can then be applied to new inputs. Transductive approaches directly predict output values for given inputs, effectively serving as the function themselves. Current approaches combine inductive and transductive models via isolated ensembling, but they do not explicitly model the interaction between both paradigms. In this work, we introduce \\acs{tiips}, a novel framework that unifies transductive and inductive strategies by explicitly modeling their interactions through a cooperative mechanism: an inductive model generates programs, while a transductive model constrains, guides, and refines the search to improve synthesis accuracy and generalization. We evaluate \\acs{tiips} on two widely studied program synthesis domains: string and list manipulation. Our results show that \\acs{tiips} solves more tasks and yields functions that more closely match optimal solutions in syntax and semantics, particularly in out-of-distribution settings, yielding state-of-the-art performance. We believe that explicitly modeling the synergy between inductive and transductive reasoning opens promising avenues for general-purpose program synthesis and broader applications.', 'abstract_zh': '程序合成中的抽象与推理通过归纳和共轭范式取得了显著进展。当前的方法通过隔离ensembling结合归纳和共轭模型，但它们没有明确建模两者之间的交互。在本工作中，我们引入了TiIPS框架，这是一种新的框架，通过合作机制明确建模归纳和共轭策略的交互，以统一这两种策略：归纳模型生成程序，共轭模型对其进行约束、引导和细化，以提高合成准确性和泛化能力。我们在两个广泛研究的程序合成领域——字符串和列表操作——上评估了TiIPS。结果显示，TiIPS解决了更多任务，并生成了在语法和语义上更接近最优解的函数，特别是在分布外环境中，取得了最先进的性能。我们认为，明确建模归纳与共轭推理之间的协同作用为通用程序合成和更广泛的潜在应用开辟了前景。', 'title_zh': '自举启发的归纳程序合成'}
{'arxiv_id': 'arXiv:2505.14739', 'title': 'Time Series Similarity Score Functions to Monitor and Interact with the Training and Denoising Process of a Time Series Diffusion Model applied to a Human Activity Recognition Dataset based on IMUs', 'authors': 'Heiko Oppel, Andreas Spilz, Michael Munz', 'link': 'https://arxiv.org/abs/2505.14739', 'abstract': 'Denoising diffusion probabilistic models are able to generate synthetic sensor signals. The training process of such a model is controlled by a loss function which measures the difference between the noise that was added in the forward process and the noise that was predicted by the diffusion model. This enables the generation of realistic data. However, the randomness within the process and the loss function itself makes it difficult to estimate the quality of the data. Therefore, we examine multiple similarity metrics and adapt an existing metric to overcome this issue by monitoring the training and synthetisation process using those metrics. The adapted metric can even be fine-tuned on the input data to comply with the requirements of an underlying classification task. We were able to significantly reduce the amount of training epochs without a performance reduction in the classification task. An optimized training process not only saves resources, but also reduces the time for training generative models.', 'abstract_zh': '去噪扩散概率模型能够生成合成传感器信号。这类模型的训练过程由衡量正向过程添加噪声与扩散模型预测噪声之间差异的损失函数控制。这使得生成现实数据成为可能。然而，此过程中以及损失函数本身的随机性使得难以估计数据质量。因此，我们检查了多种相似性度量，并对现有度量进行了调整，通过使用这些度量监控训练和合成过程来克服这一问题。调整后的度量甚至可以根据输入数据进行微调，以符合底层分类任务的要求。我们能够在不降低分类任务性能的情况下显著减少训练周期。优化的训练过程不仅节约资源，还缩短了生成模型的训练时间。', 'title_zh': '基于IMU的人体活动识别数据集上时间序列扩散模型的训练与去噪过程监测及交互的时间序列相似性评分函数'}
{'arxiv_id': 'arXiv:2505.14737', 'title': 'Leveraging Multivariate Long-Term History Representation for Time Series Forecasting', 'authors': 'Huiliang Zhang, Di Wu, Arnaud Zinflou, Stephane Dellacherie, Mouhamadou Makhtar Dione, Benoit Boulet', 'link': 'https://arxiv.org/abs/2505.14737', 'abstract': 'Multivariate Time Series (MTS) forecasting has a wide range of applications in both industry and academia. Recent advances in Spatial-Temporal Graph Neural Network (STGNN) have achieved great progress in modelling spatial-temporal correlations. Limited by computational complexity, most STGNNs for MTS forecasting focus primarily on short-term and local spatial-temporal dependencies. Although some recent methods attempt to incorporate univariate history into modeling, they still overlook crucial long-term spatial-temporal similarities and correlations across MTS, which are essential for accurate forecasting. To fill this gap, we propose a framework called the Long-term Multivariate History Representation (LMHR) Enhanced STGNN for MTS forecasting. Specifically, a Long-term History Encoder (LHEncoder) is adopted to effectively encode the long-term history into segment-level contextual representations and reduce point-level noise. A non-parametric Hierarchical Representation Retriever (HRetriever) is designed to include the spatial information in the long-term spatial-temporal dependency modelling and pick out the most valuable representations with no additional training. A Transformer-based Aggregator (TAggregator) selectively fuses the sparsely retrieved contextual representations based on the ranking positional embedding efficiently. Experimental results demonstrate that LMHR outperforms typical STGNNs by 10.72% on the average prediction horizons and state-of-the-art methods by 4.12% on several real-world datasets. Additionally, it consistently improves prediction accuracy by 9.8% on the top 10% of rapidly changing patterns across the datasets.', 'abstract_zh': '多变量时间序列（MTS） forecasting在工业和学术界有着广泛的应用。 recent advancements in 空间-时间图神经网络（STGNN）已在建模空间-时间相关性方面取得了显著进展。由于计算复杂性的限制，大多数应用于MTS forecasting的STGNN主要关注短期和局部空间-时间依赖性。尽管一些最近的方法试图将一变量的历史信息纳入建模中，但它们仍然忽略了跨MTS中的关键长期空间-时间相似性和相关性，这对于准确的预测至关重要。为了填补这一空白，我们提出了一种称为长期内存多变量历史表示（LMHR）增强STGNN的框架。具体而言，采用了一种长期内存编码器（LHEncoder）有效地将长期内存编码为段级上下文表示并减少点级噪声。设计了一种非参数层次表示检索器（HRetriever），包括空间信息以建模长期空间-时间依赖性，并挑选出最具价值的表示而不需额外训练。一种基于排名位置嵌入的Transformer聚合器（TAggregator）有效地选择性地融合稀疏检索的上下文表示。实验结果表明，LMHR在平均预测水平上的表现比典型STGNN高10.72%，在某些现实世界数据集上的表现比最先进的方法高4.12%。此外，它在数据集中的前10%快速变化模式上的一致改善了9.8%的预测准确性。', 'title_zh': '利用多变量长期历史表示进行时间序列预测'}
{'arxiv_id': 'arXiv:2505.14723', 'title': 'QUADS: QUAntized Distillation Framework for Efficient Speech Language Understanding', 'authors': 'Subrata Biswas, Mohammad Nur Hossain Khan, Bashima Islam', 'link': 'https://arxiv.org/abs/2505.14723', 'abstract': 'Spoken Language Understanding (SLU) systems must balance performance and efficiency, particularly in resource-constrained environments. Existing methods apply distillation and quantization separately, leading to suboptimal compression as distillation ignores quantization constraints. We propose QUADS, a unified framework that optimizes both through multi-stage training with a pre-tuned model, enhancing adaptability to low-bit regimes while maintaining accuracy. QUADS achieves 71.13\\% accuracy on SLURP and 99.20\\% on FSC, with only minor degradations of up to 5.56\\% compared to state-of-the-art models. Additionally, it reduces computational complexity by 60--73$\\times$ (GMACs) and model size by 83--700$\\times$, demonstrating strong robustness under extreme quantization. These results establish QUADS as a highly efficient solution for real-world, resource-constrained SLU applications.', 'abstract_zh': '基于资源约束环境下的口语理解（SLU）系统必须在性能和效率之间取得平衡。现有方法分别应用蒸馏和量化，导致次优压缩效果，因为蒸馏忽略了量化约束。我们提出QUADS，这是一种统一框架，通过多阶段训练和预调模型优化两者，增强在低比特率环境下的适应性同时保持准确性。QUADS在SLURP上的准确率为71.13%，在FSC上的准确率为99.20%，与最先进的模型相比，仅出现最高5.56%的轻微性能下降。此外，QUADS计算复杂度降低了60-73倍（GMACs），模型大小减少了83-700倍，显示出在极端量化下的强大稳健性。这些结果确立了QUADS作为资源约束环境下实际应用中高效解决方案的地位。', 'title_zh': 'QUADS：量化精简框架以实现高效语音语言理解'}
{'arxiv_id': 'arXiv:2505.14717', 'title': 'Aneumo: A Large-Scale Multimodal Aneurysm Dataset with Computational Fluid Dynamics Simulations and Deep Learning Benchmarks', 'authors': 'Xigui Li, Yuanye Zhou, Feiyang Xiao, Xin Guo, Chen Jiang, Tan Pan, Xingmeng Zhang, Cenyu Liu, Zeyun Miao, Jianchao Ge, Xiansheng Wang, Qimeng Wang, Yichi Zhang, Wenbo Zhang, Fengping Zhu, Limei Han, Yuan Qi, Chensen Lin, Yuan Cheng', 'link': 'https://arxiv.org/abs/2505.14717', 'abstract': 'Intracranial aneurysms (IAs) are serious cerebrovascular lesions found in approximately 5\\% of the general population. Their rupture may lead to high mortality. Current methods for assessing IA risk focus on morphological and patient-specific factors, but the hemodynamic influences on IA development and rupture remain unclear. While accurate for hemodynamic studies, conventional computational fluid dynamics (CFD) methods are computationally intensive, hindering their deployment in large-scale or real-time clinical applications. To address this challenge, we curated a large-scale, high-fidelity aneurysm CFD dataset to facilitate the development of efficient machine learning algorithms for such applications. Based on 427 real aneurysm geometries, we synthesized 10,660 3D shapes via controlled deformation to simulate aneurysm evolution. The authenticity of these synthetic shapes was confirmed by neurosurgeons. CFD computations were performed on each shape under eight steady-state mass flow conditions, generating a total of 85,280 blood flow dynamics data covering key parameters. Furthermore, the dataset includes segmentation masks, which can support tasks that use images, point clouds or other multimodal data as input. Additionally, we introduced a benchmark for estimating flow parameters to assess current modeling methods. This dataset aims to advance aneurysm research and promote data-driven approaches in biofluids, biomedical engineering, and clinical risk assessment. The code and dataset are available at: this https URL.', 'abstract_zh': '颅内动脉瘤（IAs）是大约5%普通人群中发现的严重脑血管病变。它们的破裂可能导致高死亡率。当前评估IA风险的方法主要集中在形态学和个体因素上，但血流动力学对IA发展和破裂的影响仍不明确。尽管在血流动力学研究中是准确的，但传统计算流体动力学（CFD）方法计算量大，阻碍了其在大规模或实时临床应用中的部署。为应对这一挑战，我们整理了一个大规模、高保真动脉瘤CFD数据集，以促进此类应用中高效机器学习算法的发展。基于427个真实动脉瘤几何结构，我们通过受控变形合成了10,660个3D形状，以模拟动脉瘤演化。神经外科医生确认了这些合成形状的真实性。在八种稳态质量流条件下对每个形状进行了CFD计算，生成了涵盖关键参数的85,280个血液流动动态数据。此外，该数据集还包括分割掩码，可以支持使用图像、点云或其他多模态数据作为输入的任务。此外，我们引入了一种评估当前建模方法的基准，用于估计流参数。该数据集旨在推进动脉瘤研究，并促进生物流体、生物医学工程和临床风险评估中的数据驱动方法。代码和数据集可在以下链接获取：this https URL。', 'title_zh': 'Aneumo：一个包含计算流体动力学模拟和深度学习基准的大规模多模态动脉瘤数据集'}
{'arxiv_id': 'arXiv:2505.14711', 'title': 'Space evaluation at the starting point of soccer transitions', 'authors': 'Yohei Ogawa, Rikuhei Umemoto, Keisuke Fujii', 'link': 'https://arxiv.org/abs/2505.14711', 'abstract': 'Soccer is a sport played on a pitch where effective use of space is crucial. Decision-making during transitions, when possession switches between teams, has been increasingly important, but research on space evaluation in these moments has been limited. Recent space evaluation methods such as OBSO (Off-Ball Scoring Opportunity) use scoring probability, so it is not well-suited for assessing areas far from the goal, where transitions typically occur. In this paper, we propose OBPV (Off-Ball Positioning Value) to evaluate space across the pitch, including the starting points of transitions. OBPV extends OBSO by introducing the field value model, which evaluates the entire pitch, and by employing the transition kernel model, which reflects positional specificity through kernel density estimation of pass distributions. Experiments using La Liga 2023/24 season tracking and event data show that OBPV highlights effective space utilization during counter-attacks and reveals team-specific characteristics in how the teams utilize space after positive and negative transitions.', 'abstract_zh': '足球是一项在球场上进行的运动，有效利用空间至关重要。当控球权在两队之间转换时，转换期间的决策制定越来越重要，但有关这一时刻的空间评估研究相对有限。近年来的空间评估方法如OBSO（无球得分机会）依靠射门概率，因此不适用于评估远距离无球空间，而这些空间往往是转换发生的地点。本文提出了一种新的无球空间评估方法OBPV（无球定位价值），以评估整个球场上的空间，包括转换的起始点。OBPV通过引入场地方价值模型来评估整个球场，并通过引入转换内核模型，利用通过传递分布的内核密度估计来反映位置特定性。使用2023/24赛季西甲追踪和事件数据的实验表明，OBPV突出了反攻时有效空间利用，并揭示了不同团队在积极和消极转换后利用空间的特定特征。', 'title_zh': '足球转换起始点的空间评价'}
{'arxiv_id': 'arXiv:2505.14693', 'title': 'Propositional Measure Logic', 'authors': 'Francisco Aragão', 'link': 'https://arxiv.org/abs/2505.14693', 'abstract': 'We present a propositional logic with fundamental probabilistic semantics, in which each formula is given a real measure in the interval $[0,1]$ that represents its degree of truth. This semantics replaces the binarity of classical logic, while preserving its deductive structure. We demonstrate the soundness theorem, establishing that the proposed system is sound and suitable for reasoning under uncertainty. We discuss potential applications and avenues for future extensions of the theory. We apply probabilistic logic to a still refractory problem in Bayesian Networks.', 'abstract_zh': '我们提出了一个具有基础概率语义的命题逻辑，在其中每个公式都被赋予一个在区间$[0,1]$上的实数测度，以表示其真度。这种语义替代了经典逻辑的二值性，同时保留了其推理结构。我们证明了_soundness定理_，确立了所提出系统的soundness并证明其适用于不确定性推理。我们讨论了该理论的应用潜力及其未来扩展的途径。我们将概率逻辑应用于贝叶斯网络中的一个仍具挑战性的问题。', 'title_zh': '命题度量逻辑'}
{'arxiv_id': 'arXiv:2502.01701', 'title': 'Learning with Differentially Private (Sliced) Wasserstein Gradients', 'authors': 'David Rodríguez-Vítores, Clément Lalanne, Jean-Michel Loubes', 'link': 'https://arxiv.org/abs/2502.01701', 'abstract': 'In this work, we introduce a novel framework for privately optimizing objectives that rely on Wasserstein distances between data-dependent empirical measures. Our main theoretical contribution is, based on an explicit formulation of the Wasserstein gradient in a fully discrete setting, a control on the sensitivity of this gradient to individual data points, allowing strong privacy guarantees at minimal utility cost. Building on these insights, we develop a deep learning approach that incorporates gradient and activations clipping, originally designed for DP training of problems with a finite-sum structure. We further demonstrate that privacy accounting methods extend to Wasserstein-based objectives, facilitating large-scale private training. Empirical results confirm that our framework effectively balances accuracy and privacy, offering a theoretically sound solution for privacy-preserving machine learning tasks relying on optimal transport distances such as Wasserstein distance or sliced-Wasserstein distance.', 'abstract_zh': '本工作中，我们引入了一种新的框架，用于在基于数据依赖的经验测度之间的Wasserstein距离优化目标时提供私密性。我们的主要理论贡献是在完全离散设置中明确表示Wasserstein梯度，并通过对单个数据点的敏感性控制，允许在最小 utility 成本下实现强大的隐私保证。基于这些认识，我们开发了一种深度学习方法，该方法结合了梯度和激活剪裁，最初是为具有有限和结构问题的DP训练设计的。我们还进一步证明，隐私计算方法可以扩展到基于Wasserstein距离的目标上，从而实现大规模的私密训练。实验证据证实，我们的框架有效地平衡了准确性和隐私性，为依赖最优运输距离（如Wasserstein距离或切片Wasserstein距离）的隐私保护机器学习任务提供了一个理论上有据可依的解决方案。', 'title_zh': '学习与差异隐私（切片）Wasserstein梯度相差规范'}
