{'arxiv_id': 'arXiv:2508.12946', 'title': 'Insights from Interviews with Teachers and Students on the Use of a Social Robot in Computer Science Class in Sixth Grade', 'authors': 'Ann-Sophie Schenk, Stefan Schiffer, Heqiu Song', 'link': 'https://arxiv.org/abs/2508.12946', 'abstract': "In this paper we report on first insights from interviews with teachers and students on using social robots in computer science class in sixth grade. Our focus is on learning about requirements and potential applications. We are particularly interested in getting both perspectives, the teachers' and the learners' view on how robots could be used and what features they should or should not have. Results show that teachers as well as students are very open to robots in the classroom. However, requirements are partially quite heterogeneous among the groups. This leads to complex design challenges which we discuss at the end of this paper.", 'abstract_zh': '在本研究中，我们报告了关于六年级计算机科学课堂中使用社会机器人初步见解的访谈结果，重点关注需求和潜在应用。我们特别关注教师和学习者对面向课堂的机器人使用方式及应具备或不应具备的功能特征的看法。结果显示，教师和学生对课堂中使用机器人持非常开放的态度，但各组的需求部分存在显著差异，这带来了复杂的設計挑战，我们在本文末尾进行了讨论。', 'title_zh': '基于六年级计算机科学课堂中社交机器人使用情况访谈的见解'}
{'arxiv_id': 'arXiv:2508.12564', 'title': 'Temporal and Rotational Calibration for Event-Centric Multi-Sensor Systems', 'authors': 'Jiayao Mai, Xiuyuan Lu, Kuan Dai, Shaojie Shen, Yi Zhou', 'link': 'https://arxiv.org/abs/2508.12564', 'abstract': 'Event cameras generate asynchronous signals in response to pixel-level brightness changes, offering a sensing paradigm with theoretically microsecond-scale latency that can significantly enhance the performance of multi-sensor systems. Extrinsic calibration is a critical prerequisite for effective sensor fusion; however, the configuration that involves event cameras remains an understudied topic. In this paper, we propose a motion-based temporal and rotational calibration framework tailored for event-centric multi-sensor systems, eliminating the need for dedicated calibration targets. Our method uses as input the rotational motion estimates obtained from event cameras and other heterogeneous sensors, respectively. Different from conventional approaches that rely on event-to-frame conversion, our method efficiently estimates angular velocity from normal flow observations, which are derived from the spatio-temporal profile of event data. The overall calibration pipeline adopts a two-step approach: it first initializes the temporal offset and rotational extrinsics by exploiting kinematic correlations in the spirit of Canonical Correlation Analysis (CCA), and then refines both temporal and rotational parameters through a joint non-linear optimization using a continuous-time parametrization in SO(3). Extensive evaluations on both publicly available and self-collected datasets validate that the proposed method achieves calibration accuracy comparable to target-based methods, while exhibiting superior stability over purely CCA-based methods, and highlighting its precision, robustness and flexibility. To facilitate future research, our implementation will be made open-source. Code: this https URL.', 'abstract_zh': '事件相机生成响应于像素级亮度变化的异步信号，提供理论上毫微秒级延迟的传感范式，可显著提升多传感器系统的性能。外部标定是有效传感器融合的关键前提；然而，涉及事件相机的配置 remains an understudied topic. 本文提出了一种基于运动的用于事件为中心的多传感器系统的时域和旋转校准框架，无需专用的校准目标。该方法使用来自事件相机和其他异构传感器的旋转运动估计作为输入。不同于依赖事件到帧转换的常规方法，我们的方法高效地从正常流观察中估计角速度，这些观察是从事件数据的空间-时间分布中导出的。整体校准流水线采用两步方法：首先通过类似典范相关分析（CCA）利用运动学相关性初始化时间偏移和旋转外部参数，然后通过在SO(3)中的连续时间参数化进行联合非线性优化来细化时间和旋转参数。在公开可用和自收集数据集上的广泛评估验证了所提出的方法在准确性和稳定性方面均与基于目标的方法相当，同时显示出在纯粹基于CCA的方法上的优越精度、鲁棒性和灵活性。为了促进未来的研究，我们的实现将开源。代码: this https URL。', 'title_zh': '事件中心多传感器系统的时间和旋转校准'}
{'arxiv_id': 'arXiv:2508.12189', 'title': 'Self-Guided Action Diffusion', 'authors': 'Rhea Malhotra, Yuejiang Liu, Chelsea Finn', 'link': 'https://arxiv.org/abs/2508.12189', 'abstract': 'Recent works have shown the promise of inference-time search over action samples for improving generative robot policies. In particular, optimizing cross-chunk coherence via bidirectional decoding has proven effective in boosting the consistency and reactivity of diffusion policies. However, this approach remains computationally expensive as the diversity of sampled actions grows. In this paper, we introduce self-guided action diffusion, a more efficient variant of bidirectional decoding tailored for diffusion-based policies. At the core of our method is to guide the proposal distribution at each diffusion step based on the prior decision. Experiments in simulation tasks show that the proposed self-guidance enables near-optimal performance at negligible inference cost. Notably, under a tight sampling budget, our method achieves up to 70% higher success rates than existing counterparts on challenging dynamic tasks. See project website at this https URL.', 'abstract_zh': 'Recent 工作展示了在生成机器人策略中通过推理时搜索动作样本以提高生成性能的潜力。特别是，通过双向解码优化跨片段一致性已被证明对提升扩散策略的一致性和反应性非常有效。然而，这种方法在采样动作多样性增加时仍然计算成本高昂。在本文中，我们提出了一种针对基于扩散的策略的更高效的双向解码变体——自引导动作扩散。该方法的核心在于基于先前决策指导每一步扩散过程中的提议分布。仿真任务中的实验表明，提出的自引导方法能够在几乎不增加推理成本的情况下实现接近最优的性能。值得注意的是，在受限的采样预算下，我们的方法在具有挑战性的动态任务中实现了比现有方法高达70%更高的成功率。访问项目网站：https://this-url', 'title_zh': '自我指导的动作扩散'}
{'arxiv_id': 'arXiv:2508.12170', 'title': 'Energy Efficiency in Robotics Software: A Systematic Literature Review (2020-2024)', 'authors': 'Aryan Gupta', 'link': 'https://arxiv.org/abs/2508.12170', 'abstract': 'This study presents a systematic literature review of software-level approaches to energy efficiency in robotics published from 2020 through 2024, updating and extending pre-2020 evidence. An automated-but-audited pipeline combined Google Scholar seeding, backward/forward snowballing, and large-language-model (LLM) assistance for screening and data extraction, with ~10% human audits at each automated step and consensus-with-tie-breaks for full-text decisions. The final corpus comprises 79 peer-reviewed studies analyzed across application domain, metrics, evaluation type, energy models, major energy consumers, software technique families, and energy-quality trade-offs. Industrial settings dominate (31.6%) followed by exploration (25.3%). Motors/actuators are identified as the primary consumer in 68.4% of studies, with computing/controllers a distant second (13.9%). Simulation-only evaluations remain most common (51.9%), though hybrid evaluations are frequent (25.3%). Representational (physics-grounded) energy models predominate (87.3%). Motion and trajectory optimization is the leading technique family (69.6%), often paired with learning/prediction (40.5%) and computation allocation/scheduling (26.6%); power management/idle control (11.4%) and communication/data efficiency (3.8%) are comparatively underexplored. Reporting is heterogeneous: composite objectives that include energy are most common, while task-normalized and performance-per-energy metrics appear less often, limiting cross-paper comparability. The review offers a minimal reporting checklist (e.g., total energy and average power plus a task-normalized metric and clear baselines) and highlights opportunities in cross-layer designs and in quantifying non-performance trade-offs (accuracy, stability). A replication package with code, prompts, and frozen datasets accompanies the review.', 'abstract_zh': '本研究 presents 2020至2024年机器人领域软件级能源效率方法的系统文献综述，更新并扩展了2020年前的证据。自动化但受审计的流程结合了Google Scholar的启动、反向/正向雪球筛选以及大语言模型（LLM）辅助的数据筛选和提取，各自动化步骤中约有10%的人工审计，并通过具投票决权的共识决定全文处理。最终的文献集包括79篇同行评审的研究，这些研究在应用领域、评价指标、评估类型、能源模型、主要能源消耗者、软件技术家族以及能量质量权衡等方面进行了分析。工业环境占主导地位（31.6%），其次是探索（25.3%）。68.4%的研究将电机/执行器识别为主要消耗者，而计算/控制器则次之（13.9%）。仅仿真评估最为常见（51.9%），尽管混合评估较为频繁（25.3%）。基于物理的表示（物理依据）能源模型占主导地位（87.3%）。运动和轨迹优化是主要的技术家族（69.6%），常与学习/预测（40.5%）和计算分配/调度（26.6%）结合使用；而功率管理/空闲控制（11.4%）和通信/数据效率（3.8%）探讨较少。报告具有异质性：包含能源的综合目标最常见，而任务归一化和能源性能指标出现较少，限制了跨论文的可比性。该综述提供了最小的报告清单（例如，总能量和平均功率，加上任务归一化指标和清晰的基线），并强调跨层设计以及量化非性能权衡（准确性和稳定性）的机会。该综述附带了一个复制包，包含代码、提示和冻结数据集。', 'title_zh': '机器人软件的能效：一项系统文献综述（2020-2024）'}
{'arxiv_id': 'arXiv:2508.11887', 'title': 'Saliency-Based Attention Shifting: A Framework for Improving Driver Situational Awareness of Out-of-Label Hazards', 'authors': 'Yousra Shleibik, Jordan Sinclair, Kerstin Haring', 'link': 'https://arxiv.org/abs/2508.11887', 'abstract': 'The advent of autonomous driving systems promises to transform transportation by enhancing safety, efficiency, and comfort. As these technologies evolve toward higher levels of autonomy, the need for integrated systems that seamlessly support human involvement in decision-making becomes increasingly critical. Certain scenarios necessitate human involvement, including those where the vehicle is unable to identify an object or element in the scene, and as such cannot take independent action. Therefore, situational awareness is essential to mitigate potential risks during a takeover, where a driver must assume control and autonomy from the vehicle. The need for driver attention is important to avoid collisions with external agents and ensure a smooth transition during takeover operations. This paper explores the integration of attention redirection techniques, such as gaze manipulation through targeted visual and auditory cues, to help drivers maintain focus on emerging hazards and reduce target fixation in semi-autonomous driving scenarios. We propose a conceptual framework that combines real-time gaze tracking, context-aware saliency analysis, and synchronized visual and auditory alerts to enhance situational awareness, proactively address potential hazards, and foster effective collaboration between humans and autonomous systems.', 'abstract_zh': '自主驾驶系统的出现promise to transform transportation by enhancing safety, efficiency, and comfort. 随着这些技术向着更高自主级别的演进,integrated systems that seamlessly support human involvement in decision-making 成为越来越 critical. 在某些场景中,驾驶必须参与决策,例如车辆无法识别场景中的物体或元素时。因此,situational awareness 是至关重要的,尤其是在接管期间,to mitigate potential risks. 驾驶员需将控制权从车辆中夺回。保持驾驶员注意力的重要目的在于避免与外部代理的碰撞,并在接管操作期间确保平滑过渡。本文探讨了通过目标视觉和听觉提示来进行注意力转移技术的集成,以帮助驾驶员在半自主驾驶场景中维持对新兴危险的关注,并减少目标固定。我们提出了一种结合实时注视跟踪、上下文感知显著性分析及同步视觉和听觉警报的概念框架,以增强情境意识、前瞻性地应对潜在危险并促进人与自主系统的有效协作。', 'title_zh': '基显著性注意力机制的觉察框架：一种提高驾驶员对\nuser\n基于显著性的注意引导：一种提高驾驶员对标签外危害情境意识的框架。'}
{'arxiv_id': 'arXiv:2508.12304', 'title': 'Adjustable AprilTags For Identity Secured Tasks', 'authors': 'Hao Li', 'link': 'https://arxiv.org/abs/2508.12304', 'abstract': 'Special tags such as AprilTags that facilitate image processing and pattern recognition are useful in practical applications. In close and private environments, identity security is unlikely to be an issue because all involved AprilTags can be completely regulated. However, in open and public environments, identity security is no longer an issue that can be neglected. To handle potential harm caused by adversarial attacks, this note advocates utilization of adjustable AprilTags instead of fixed ones.', 'abstract_zh': '特殊的AprilTags等标记标签便于图像处理和模式识别，在实际应用中非常有用。在封闭和私密环境中，身份安全通常不是问题，因为所有涉及的AprilTags都可以完全受控。然而，在开放和公共环境中，身份安全不再是可忽视的问题。为了应对潜在的 adversarial攻击造成的危害，本文主张使用可调节的AprilTags而非固定的AprilTags。', 'title_zh': '可调节AprilTags 用于身份认证任务'}
{'arxiv_id': 'arXiv:2508.11805', 'title': 'Control of a commercial vehicle by a tetraplegic human using a bimanual brain-computer interface', 'authors': 'Xinyun Zou, Jorge Gamez, Meghna Menon, Phillip Ring, Chadwick Boulay, Likhith Chitneni, Jackson Brennecke, Shana R. Melby, Gracy Kureel, Kelsie Pejsa, Emily R. Rosario, Ausaf A. Bari, Aniruddh Ravindran, Tyson Aflalo, Spencer S. Kellis, Dimitar Filev, Florian Solzbacher, Richard A. Andersen', 'link': 'https://arxiv.org/abs/2508.11805', 'abstract': 'Brain-computer interfaces (BCIs) read neural signals directly from the brain to infer motor planning and execution. However, the implementation of this technology has been largely limited to laboratory settings, with few real-world applications. We developed a bimanual BCI system to drive a vehicle in both simulated and real-world environments. We demonstrate that an individual with tetraplegia, implanted with intracortical BCI electrodes in the posterior parietal cortex (PPC) and the hand knob region of the motor cortex (MC), reacts at least as fast and precisely as motor intact participants, and drives a simulated vehicle as proficiently as the same control group. This BCI participant, living in California, could also remotely drive a Ford Mustang Mach-E vehicle in Michigan. Our first teledriving task relied on cursor control for speed and steering in a closed urban test facility. However, the final BCI system added click control for full-stop braking and thus enabled bimanual cursor-and-click control for both simulated driving through a virtual town with traffic and teledriving through an obstacle course without traffic in the real world. We also demonstrate the safety and feasibility of BCI-controlled driving. This first-of-its-kind implantable BCI application not only highlights the versatility and innovative potentials of BCIs but also illuminates the promising future for the development of life-changing solutions to restore independence to those who suffer catastrophic neurological injury.', 'abstract_zh': '脑机接口系统在模拟和真实环境下的双臂驾驶研究', 'title_zh': '四肢瘫痪人士使用双手持械脑机接口控制商用车辆'}
{'arxiv_id': 'arXiv:2508.11799', 'title': 'Scaling Robust Optimization for Swarms: A Distributed Perspective', 'authors': 'Arshiya Taj Abdul, Augustinos D. Saravanos, Evangelos A. Theodorou', 'link': 'https://arxiv.org/abs/2508.11799', 'abstract': 'This article introduces a decentralized robust optimization framework for safe multi-agent control under uncertainty. Although stochastic noise has been the primary form of modeling uncertainty in such systems, these formulations might fall short in addressing uncertainties that are deterministic in nature or simply lack probabilistic data. To ensure safety under such scenarios, we employ the concept of robust constraints that must hold for all possible uncertainty realizations lying inside a bounded set. Nevertheless, standard robust optimization approaches become intractable due to the large number or non-convexity of the constraints involved in safe multi-agent control. To address this, we introduce novel robust reformulations that significantly reduce complexity without compromising safety. The applicability of the framework is further broadened to address both deterministic and stochastic uncertainties by incorporating robust chance constraints and distribution steering techniques. To achieve scalability, we derive a distributed approach based on the Alternating Direction Method of Multipliers (ADMM), supported by a convergence study that accounts for the underlying non-convexity. In addition, computational complexity bounds highlighting the efficiency of the proposed frameworks against standard approaches are presented. Finally, the robustness and scalability of the framework is demonstrated through extensive simulation results across diverse scenarios, including environments with nonconvex obstacles and up to 246 agents.', 'abstract_zh': '一种用于不确定性下安全多代理控制的去中心化鲁棒优化框架', 'title_zh': '群智能中鲁棒优化的扩展：一种分布式视角'}
{'arxiv_id': 'arXiv:2508.11679', 'title': 'Lifelong Learner: Discovering Versatile Neural Solvers for Vehicle Routing Problems', 'authors': 'Shaodi Feng, Zhuoyi Lin, Jianan Zhou, Cong Zhang, Jingwen Li, Kuan-Wen Chen, Senthilnath Jayavelu, Yew-Soon Ong', 'link': 'https://arxiv.org/abs/2508.11679', 'abstract': 'Deep learning has been extensively explored to solve vehicle routing problems (VRPs), which yields a range of data-driven neural solvers with promising outcomes. However, most neural solvers are trained to tackle VRP instances in a relatively monotonous context, e.g., simplifying VRPs by using Euclidean distance between nodes and adhering to a single problem size, which harms their off-the-shelf application in different scenarios. To enhance their versatility, this paper presents a novel lifelong learning framework that incrementally trains a neural solver to manage VRPs in distinct contexts. Specifically, we propose a lifelong learner (LL), exploiting a Transformer network as the backbone, to solve a series of VRPs. The inter-context self-attention mechanism is proposed within LL to transfer the knowledge obtained from solving preceding VRPs into the succeeding ones. On top of that, we develop a dynamic context scheduler (DCS), employing the cross-context experience replay to further facilitate LL looking back on the attained policies of solving preceding VRPs. Extensive results on synthetic and benchmark instances (problem sizes up to 18k) show that our LL is capable of discovering effective policies for tackling generic VRPs in varying contexts, which outperforms other neural solvers and achieves the best performance for most VRPs.', 'abstract_zh': '深度学习在解决车辆路由问题中的广泛探索及其在不同情境下的终身学习框架', 'title_zh': '终身学习者: 发现适用于车辆路线问题的多功能神经求解器'}
{'arxiv_id': 'arXiv:2508.13121', 'title': 'Bayesian Optimization-based Search for Agent Control in Automated Game Testing', 'authors': 'Carlos Celemin', 'link': 'https://arxiv.org/abs/2508.13121', 'abstract': 'This work introduces an automated testing approach that employs agents controlling game characters to detect potential bugs within a game level. Harnessing the power of Bayesian Optimization (BO) to execute sample-efficient search, the method determines the next sampling point by analyzing the data collected so far and calculates the data point that will maximize information acquisition. To support the BO process, we introduce a game testing-specific model built on top of a grid map, that features the smoothness and uncertainty estimation required by BO, however and most importantly, it does not suffer the scalability issues that traditional models carry. The experiments demonstrate that the approach significantly improves map coverage capabilities in both time efficiency and exploration distribution.', 'abstract_zh': '本研究引入了一种自动测试方法，利用控制游戏角色的代理检测游戏关卡中的潜在bug。通过利用贝叶斯优化（BO）执行样本高效搜索，该方法通过分析迄今为止收集的数据来确定下一点采样位置，并计算能最大化信息获取的数据点。为了支持BO过程，我们提出了基于格网地图的专门游戏测试模型，该模型具备BO所需的平滑度和不确定性估计，最重要的是，它不受传统模型的可扩展性问题的影响。实验结果表明，该方法在时间和探索分布方面显著提高了地图覆盖率能力。', 'title_zh': '基于贝叶斯优化的智能体控制搜索在自动化游戏测试中的应用'}
{'arxiv_id': 'arXiv:2508.13021', 'title': 'PC-Sampler: Position-Aware Calibration of Decoding Bias in Masked Diffusion Models', 'authors': 'Pengcheng Huang, Shuhao Liu, Zhenghao Liu, Yukun Yan, Shuo Wang, Zulong Chen, Tong Xiao', 'link': 'https://arxiv.org/abs/2508.13021', 'abstract': 'Recent advances in masked diffusion models (MDMs) have established them as powerful non-autoregressive alternatives for sequence generation. Nevertheless, our preliminary experiments reveal that the generation quality of MDMs is still highly sensitive to the choice of decoding strategy. In particular, widely adopted uncertainty-based samplers suffer from two key limitations: a lack of global trajectory control and a pronounced bias toward trivial tokens in the early stages of decoding. These shortcomings restrict the full potential of MDMs. In this work, we introduce Position-Aware Confidence-Calibrated Sampling (PC-Sampler), a novel decoding strategy that unifies global trajectory planning with content-aware informativeness maximization. PC-Sampler incorporates a position-aware weighting mechanism to regulate the decoding path and a calibrated confidence score to suppress the premature selection of trivial tokens. Extensive experiments on three advanced MDMs across seven challenging benchmarks-including logical reasoning and planning tasks-demonstrate that PC-Sampler consistently outperforms existing MDM decoding strategies by more than 10% on average, significantly narrowing the performance gap with state-of-the-art autoregressive models. All codes are available at this https URL.', 'abstract_zh': 'Recent Advances in Masked Diffusion Models (MDMs): Introducing Position-Aware Confidence-Calibrated Sampling (PC-Sampler) for Improved Sequence Generation', 'title_zh': 'PC-Sampler: 位置感知的解码偏置校准在掩蔽扩散模型中的应用'}
{'arxiv_id': 'arXiv:2508.13020', 'title': 'e-boost: Boosted E-Graph Extraction with Adaptive Heuristics and Exact Solving', 'authors': 'Jiaqi Yin, Zhan Song, Chen Chen, Yaohui Cai, Zhiru Zhang, Cunxi Yu', 'link': 'https://arxiv.org/abs/2508.13020', 'abstract': 'E-graphs have attracted growing interest in many fields, particularly in logic synthesis and formal verification. E-graph extraction is a challenging NP-hard combinatorial optimization problem. It requires identifying optimal terms from exponentially many equivalent expressions, serving as the primary performance bottleneck in e-graph based optimization tasks. However, traditional extraction methods face a critical trade-off: heuristic approaches offer speed but sacrifice optimality, while exact methods provide optimal solutions but face prohibitive computational costs on practical problems. We present e-boost, a novel framework that bridges this gap through three key innovations: (1) parallelized heuristic extraction that leverages weak data dependence to compute DAG costs concurrently, enabling efficient multi-threaded performance without sacrificing extraction quality; (2) adaptive search space pruning that employs a parameterized threshold mechanism to retain only promising candidates, dramatically reducing the solution space while preserving near-optimal solutions; and (3) initialized exact solving that formulates the reduced problem as an Integer Linear Program with warm-start capabilities, guiding solvers toward high-quality solutions faster.\nAcross the diverse benchmarks in formal verification and logic synthesis fields, e-boost demonstrates 558x runtime speedup over traditional exact approaches (ILP) and 19.04% performance improvement over the state-of-the-art extraction framework (SmoothE). In realistic logic synthesis tasks, e-boost produces 7.6% and 8.1% area improvements compared to conventional synthesis tools with two different technology mapping libraries. e-boost is available at this https URL.', 'abstract_zh': 'E-图在许多领域引起了 growing关注，特别是在逻辑综合和形式验证中。E-图提取是NP难的组合优化问题。它要求从指数级的等价表达式中识别出最优项，成为基于E-图优化任务的主要性能瓶颈。然而，传统的提取方法面临一个关键的权衡：启发式方法速度快但牺牲了最优性，而精确方法提供最优解但在实际问题上面临高昂的计算成本。我们提出了e-boost这一新颖框架，通过三个关键创新来弥合这一差距：（1）并行化启发式提取，利用弱数据依赖关系并行计算DAG成本，从而保证了多线程效率，同时不牺牲提取质量；（2）自适应搜索空间剪枝，使用参数化的阈值机制保留只有有前景的候选项，大幅减少解决方案空间，同时保留接近最优的解决方案；（3）初始精确求解，将缩减后的問題形式化为具有暖启动能力的整数线性规划问题，引导求解器更快地找到高质量的解决方案。', 'title_zh': 'e-增强：自适应启发式与精确求解相结合的E-图提取'}
{'arxiv_id': 'arXiv:2508.12943', 'title': 'OPTIC-ER: A Reinforcement Learning Framework for Real-Time Emergency Response and Equitable Resource Allocation in Underserved African Communities', 'authors': 'Mary Tonwe', 'link': 'https://arxiv.org/abs/2508.12943', 'abstract': 'Public service systems in many African regions suffer from delayed emergency response and spatial inequity, causing avoidable suffering. This paper introduces OPTIC-ER, a reinforcement learning (RL) framework for real-time, adaptive, and equitable emergency response. OPTIC-ER uses an attention-guided actor-critic architecture to manage the complexity of dispatch environments. Its key innovations are a Context-Rich State Vector, encoding action sub-optimality, and a Precision Reward Function, which penalizes inefficiency. Training occurs in a high-fidelity simulation using real data from Rivers State, Nigeria, accelerated by a precomputed Travel Time Atlas. The system is built on the TALS framework (Thin computing, Adaptability, Low-cost, Scalability) for deployment in low-resource settings. In evaluations on 500 unseen incidents, OPTIC-ER achieved a 100.00% optimality rate with negligible inefficiency, confirming its robustness and generalization. Beyond dispatch, the system generates Infrastructure Deficiency Maps and Equity Monitoring Dashboards to guide proactive governance and data-informed development. This work presents a validated blueprint for AI-augmented public services, showing how context-aware RL can bridge the gap between algorithmic decision-making and measurable human impact.', 'abstract_zh': 'OPTIC-ER：一种用于实时、适应性和公平性应急响应的强化学习框架', 'title_zh': 'OPTIC-ER：面向非洲欠服务社区实时应急响应与公平资源分配的强化学习框架'}
{'arxiv_id': 'arXiv:2508.12896', 'title': 'Reliability, Embeddedness, and Agency: A Utility-Driven Mathematical Framework for Agent-Centric AI Adoption', 'authors': 'Faruk Alpay, Taylan Alpay', 'link': 'https://arxiv.org/abs/2508.12896', 'abstract': 'We formalize three design axioms for sustained adoption of agent-centric AI systems executing multi-step tasks: (A1) Reliability > Novelty; (A2) Embed > Destination; (A3) Agency > Chat. We model adoption as a sum of a decaying novelty term and a growing utility term and derive the phase conditions for troughs/overshoots with full proofs. We introduce: (i) an identifiability/confounding analysis for $(\\alpha,\\beta,N_0,U_{\\max})$ with delta-method gradients; (ii) a non-monotone comparator (logistic-with-transient-bump) evaluated on the same series to provide additional model comparison; (iii) ablations over hazard families $h(\\cdot)$ mapping $\\Delta V \\to \\beta$; (iv) a multi-series benchmark (varying trough depth, noise, AR structure) reporting coverage (type-I error, power); (v) calibration of friction proxies against time-motion/survey ground truth with standard errors; (vi) residual analyses (autocorrelation and heteroskedasticity) for each fitted curve; (vii) preregistered windowing choices for pre/post estimation; (viii) Fisher information & CRLB for $(\\alpha,\\beta)$ under common error models; (ix) microfoundations linking $\\mathcal{T}$ to $(N_0,U_{\\max})$; (x) explicit comparison to bi-logistic, double-exponential, and mixture models; and (xi) threshold sensitivity to $C_f$ heterogeneity. Figures and tables are reflowed for readability, and the bibliography restores and extends non-logistic/Bass adoption references (Gompertz, Richards, Fisher-Pry, Mansfield, Griliches, Geroski, Peres). All code and logs necessary to reproduce the synthetic analyses are embedded as LaTeX listings.', 'abstract_zh': '我们正式化了三个设计公理以确保基于代理的AI系统执行多步任务的持续采用：(A1) 可靠性 > 新颖性；(A2) 嵌入 > 目标；(A3) 主体自主性 > 聊天。我们将采用建模为衰减的新颖性项与增长的实用性项之和，并推导出阶段条件，包括完整的证明。我们引入了：(i) 使用delta方法梯度进行识别/混杂分析的$(\\alpha,\\beta,N_0,U_{\\max})$；(ii) 评估同一系列的非单调竞争者（带有瞬态峰的logistic模型）以提供额外的模型比较；(iii) 损害家庭$h(\\cdot)$的消减，将$\\Delta V \\to \\beta$；(iv) 涉及不同幅度谷值、噪声和AR结构的多系列基准，报告涵盖范围（第I类错误率、功效）；(v) 与时间-动作/调查真实值的摩擦代理校准，包括标准误差；(vi) 每条拟合曲线的残差分析（自相关性和异方差性）；(vii) 注册窗口选择以进行预后估计；(viii) $(\\alpha,\\beta)$在常见误差模型下的 Fisher 信息与CRLB；(ix) 将$\\mathcal{T}$与$(N_0,U_{\\max})$关联的微观基础；(x) 与双logistic、双指数和混合模型的显式比较；(xi) 对$C_f$异质性的阀值敏感性分析。图形和表格重新排版以提高可读性，参考文献恢复并扩展了非logistic/巴斯采用模型的相关文献（Gompertz、Richards、Fisher-Pry、Mansfield、Griliches、Geroski、Peres）。所有必要以重现合成分析的代码和日志均嵌入为LaTeX列表。', 'title_zh': '可靠性、嵌入性与代理权：基于效用驱动的代理中心AI采纳数学框架'}
{'arxiv_id': 'arXiv:2508.12845', 'title': 'CAMAR: Continuous Actions Multi-Agent Routing', 'authors': 'Artem Pshenitsyn, Aleksandr Panov, Alexey Skrynnik', 'link': 'https://arxiv.org/abs/2508.12845', 'abstract': 'Multi-agent reinforcement learning (MARL) is a powerful paradigm for solving cooperative and competitive decision-making problems. While many MARL benchmarks have been proposed, few combine continuous state and action spaces with challenging coordination and planning tasks. We introduce CAMAR, a new MARL benchmark designed explicitly for multi-agent pathfinding in environments with continuous actions. CAMAR supports cooperative and competitive interactions between agents and runs efficiently at up to 100,000 environment steps per second. We also propose a three-tier evaluation protocol to better track algorithmic progress and enable deeper analysis of performance. In addition, CAMAR allows the integration of classical planning methods such as RRT and RRT* into MARL pipelines. We use them as standalone baselines and combine RRT* with popular MARL algorithms to create hybrid approaches. We provide a suite of test scenarios and benchmarking tools to ensure reproducibility and fair comparison. Experiments show that CAMAR presents a challenging and realistic testbed for the MARL community.', 'abstract_zh': '多agent强化学习（MARL）是一种解决合作与竞争决策问题的强大范式。尽管已经提出了许多MARL基准，但很少有基准能够结合连续的状态和动作空间以及具有挑战性的协调和规划任务。我们引入了CAMAR，这是一个专门为环境中的连续动作设计的多agent路径规划新基准。CAMAR支持agents之间的协作与竞争互动，并且能够以每秒100,000个环境步骤的速度高效运行。我们还提出了一种三层评估协议，以更好地跟踪算法进展并促进性能的深入分析。此外，CAMAR允许将经典的规划方法，如RRT和RRT*集成到MARL流水线中。我们将其用作独立的基本基准，并将RRT*与流行的MARL算法结合以创建混合方法。我们提供了一套测试场景和基准测试工具，以确保可重复性和公平比较。实验表明，CAMAR为MARL社区提供了一个具有挑战性和现实性的测试平台。', 'title_zh': 'CAMAR：连续动作多Agent路由'}
{'arxiv_id': 'arXiv:2508.12840', 'title': 'Scaling Multi-Agent Epistemic Planning through GNN-Derived Heuristics', 'authors': 'Giovanni Briglia, Francesco Fabiano, Stefano Mariani', 'link': 'https://arxiv.org/abs/2508.12840', 'abstract': 'Multi-agent Epistemic Planning (MEP) is an autonomous planning framework for reasoning about both the physical world and the beliefs of agents, with applications in domains where information flow and awareness among agents are critical. The richness of MEP requires states to be represented as Kripke structures, i.e., directed labeled graphs. This representation limits the applicability of existing heuristics, hindering the scalability of epistemic solvers, which must explore an exponential search space without guidance, resulting often in intractability. To address this, we exploit Graph Neural Networks (GNNs) to learn patterns and relational structures within epistemic states, to guide the planning process. GNNs, which naturally capture the graph-like nature of Kripke models, allow us to derive meaningful estimates of state quality -- e.g., the distance from the nearest goal -- by generalizing knowledge obtained from previously solved planning instances. We integrate these predictive heuristics into an epistemic planning pipeline and evaluate them against standard baselines, showing significant improvements in the scalability of multi-agent epistemic planning.', 'abstract_zh': '多智能体知识规划（MEP）是一种自主规划框架，用于同时推理物理世界和智能体的信任，适用于信息流动和智能体意识至关重要的领域。', 'title_zh': '通过基于GNN的启发式方法扩展多agent知识规划'}
{'arxiv_id': 'arXiv:2508.12647', 'title': 'Cognitive Structure Generation: From Educational Priors to Policy Optimization', 'authors': 'Hengnian Gu, Zhifu Chen, Yuxin Chen, Jin Peng Zhou, Dongdai Zhou', 'link': 'https://arxiv.org/abs/2508.12647', 'abstract': "Cognitive structure is a student's subjective organization of an objective knowledge system, reflected in the psychological construction of concepts and their relations. However, cognitive structure assessment remains a long-standing challenge in student modeling and psychometrics, persisting as a foundational yet largely unassessable concept in educational practice. This paper introduces a novel framework, Cognitive Structure Generation (CSG), in which we first pretrain a Cognitive Structure Diffusion Probabilistic Model (CSDPM) to generate students' cognitive structures from educational priors, and then further optimize its generative process as a policy with hierarchical reward signals via reinforcement learning to align with genuine cognitive development levels during students' learning processes. Experimental results on four popular real-world education datasets show that cognitive structures generated by CSG offer more comprehensive and effective representations for student modeling, substantially improving performance on KT and CD tasks while enhancing interpretability.", 'abstract_zh': '认知结构生成：一种新颖的学生认知结构评估框架', 'title_zh': '认知结构生成：从教育先验到政策优化'}
{'arxiv_id': 'arXiv:2508.12500', 'title': 'Root Cause Analysis of Hydrogen Bond Separation in Spatio-Temporal Molecular Dynamics using Causal Models', 'authors': 'Rahmat K. Adesunkanmi, Ashfaq Khokhar, Goce Trajcevski, Sohail Murad', 'link': 'https://arxiv.org/abs/2508.12500', 'abstract': 'Molecular dynamics simulations (MDS) face challenges, including resource-heavy computations and the need to manually scan outputs to detect "interesting events," such as the formation and persistence of hydrogen bonds between atoms of different molecules. A critical research gap lies in identifying the underlying causes of hydrogen bond formation and separation -understanding which interactions or prior events contribute to their emergence over time. With this challenge in mind, we propose leveraging spatio-temporal data analytics and machine learning models to enhance the detection of these phenomena. In this paper, our approach is inspired by causal modeling and aims to identify the root cause variables of hydrogen bond formation and separation events. Specifically, we treat the separation of hydrogen bonds as an "intervention" occurring and represent the causal structure of the bonding and separation events in the MDS as graphical causal models. These causal models are built using a variational autoencoder-inspired architecture that enables us to infer causal relationships across samples with diverse underlying causal graphs while leveraging shared dynamic information. We further include a step to infer the root causes of changes in the joint distribution of the causal models. By constructing causal models that capture shifts in the conditional distributions of molecular interactions during bond formation or separation, this framework provides a novel perspective on root cause analysis in molecular dynamic systems. We validate the efficacy of our model empirically on the atomic trajectories that used MDS for chiral separation, demonstrating that we can predict many steps in the future and also find the variables driving the observed changes in the system.', 'abstract_zh': '分子动力学模拟中的时空数据分析和机器学习模型在识别氢键形成和分离的根本原因中的应用', 'title_zh': '基于因果模型的时空分子动力学中氢键分离根本原因分析'}
{'arxiv_id': 'arXiv:2508.12487', 'title': 'Advanced DOA Regulation with a Whale-Optimized Fractional Order Fuzzy PID Framework', 'authors': 'Lida Shahbandari, Hossein Mohseni', 'link': 'https://arxiv.org/abs/2508.12487', 'abstract': "This study introduces a Fractional Order Fuzzy PID (FOFPID) controller that uses the Whale Optimization Algorithm (WOA) to manage the Bispectral Index (BIS), keeping it within the ideal range of forty to sixty. The FOFPID controller combines fuzzy logic for adapting to changes and fractional order dynamics for fine tuning. This allows it to adjust its control gains to handle a person's unique physiology. The WOA helps fine tune the controller's parameters, including the fractional orders and the fuzzy membership functions, which boosts its performance. Tested on models of eight different patient profiles, the FOFPID controller performed better than a standard Fractional Order PID (FOPID) controller. It achieved faster settling times, at two and a half minutes versus three point two minutes, and had a lower steady state error, at zero point five versus one point two. These outcomes show the FOFPID's excellent strength and accuracy. It offers a scalable, artificial intelligence driven solution for automated anesthesia delivery that could enhance clinical practice and improve patient results.", 'abstract_zh': '一种用于保持Bispectral Index在四十到六十理想范围内的分数阶模糊PID控制策略及其 Whale 优化算法参数调整研究', 'title_zh': '基于鲸鱼优化分数阶模糊PID框架的高级方向角调节'}
{'arxiv_id': 'arXiv:2508.12375', 'title': 'Hierarchical knowledge guided fault intensity diagnosis of complex industrial systems', 'authors': 'Yu Sha, Shuiping Gou, Bo Liu, Johannes Faber, Ningtao Liu, Stefan Schramm, Horst Stoecker, Thomas Steckenreiter, Domagoj Vnucec, Nadine Wetzstein, Andreas Widl, Kai Zhou', 'link': 'https://arxiv.org/abs/2508.12375', 'abstract': 'Fault intensity diagnosis (FID) plays a pivotal role in monitoring and maintaining mechanical devices within complex industrial systems. As current FID methods are based on chain of thought without considering dependencies among target classes. To capture and explore dependencies, we propose a hierarchical knowledge guided fault intensity diagnosis framework (HKG) inspired by the tree of thought, which is amenable to any representation learning methods. The HKG uses graph convolutional networks to map the hierarchical topological graph of class representations into a set of interdependent global hierarchical classifiers, where each node is denoted by word embeddings of a class. These global hierarchical classifiers are applied to learned deep features extracted by representation learning, allowing the entire model to be end-to-end learnable. In addition, we develop a re-weighted hierarchical knowledge correlation matrix (Re-HKCM) scheme by embedding inter-class hierarchical knowledge into a data-driven statistical correlation matrix (SCM) which effectively guides the information sharing of nodes in graphical convolutional neural networks and avoids over-smoothing issues. The Re-HKCM is derived from the SCM through a series of mathematical transformations. Extensive experiments are performed on four real-world datasets from different industrial domains (three cavitation datasets from SAMSON AG and one existing publicly) for FID, all showing superior results and outperform recent state-of-the-art FID methods.', 'abstract_zh': '基于思维树的层次知识引导故障强度诊断框架（HKG）', 'title_zh': '复杂工业系统分层知识指导的故障强度诊断'}
{'arxiv_id': 'arXiv:2508.12291', 'title': 'RadarQA: Multi-modal Quality Analysis of Weather Radar Forecasts', 'authors': 'Xuming He, Zhiyuan You, Junchao Gong, Couhua Liu, Xiaoyu Yue, Peiqin Zhuang, Wenlong Zhang, Lei Bai', 'link': 'https://arxiv.org/abs/2508.12291', 'abstract': 'Quality analysis of weather forecasts is an essential topic in meteorology. Although traditional score-based evaluation metrics can quantify certain forecast errors, they are still far from meteorological experts in terms of descriptive capability, interpretability, and understanding of dynamic evolution. With the rapid development of Multi-modal Large Language Models (MLLMs), these models become potential tools to overcome the above challenges. In this work, we introduce an MLLM-based weather forecast analysis method, RadarQA, integrating key physical attributes with detailed assessment reports. We introduce a novel and comprehensive task paradigm for multi-modal quality analysis, encompassing both single frame and sequence, under both rating and assessment scenarios. To support training and benchmarking, we design a hybrid annotation pipeline that combines human expert labeling with automated heuristics. With such an annotation method, we construct RQA-70K, a large-scale dataset with varying difficulty levels for radar forecast quality evaluation. We further design a multi-stage training strategy that iteratively improves model performance at each stage. Extensive experiments show that RadarQA outperforms existing general MLLMs across all evaluation settings, highlighting its potential for advancing quality analysis in weather prediction.', 'abstract_zh': '基于多模态大型语言模型的雷达天气预报质量分析方法：RadarQA', 'title_zh': '雷达QA：天气雷达预报的多模态质量分析'}
{'arxiv_id': 'arXiv:2508.12026', 'title': 'Bongard-RWR+: Real-World Representations of Fine-Grained Concepts in Bongard Problems', 'authors': 'Szymon Pawlonka, Mikołaj Małkiński, Jacek Mańdziuk', 'link': 'https://arxiv.org/abs/2508.12026', 'abstract': 'Bongard Problems (BPs) provide a challenging testbed for abstract visual reasoning (AVR), requiring models to identify visual concepts fromjust a few examples and describe them in natural language. Early BP benchmarks featured synthetic black-and-white drawings, which might not fully capture the complexity of real-world scenes. Subsequent BP datasets employed real-world images, albeit the represented concepts are identifiable from high-level image features, reducing the task complexity. Differently, the recently released Bongard-RWR dataset aimed at representing abstract concepts formulated in the original BPs using fine-grained real-world images. Its manual construction, however, limited the dataset size to just $60$ instances, constraining evaluation robustness. In this work, we introduce Bongard-RWR+, a BP dataset composed of $5\\,400$ instances that represent original BP abstract concepts using real-world-like images generated via a vision language model (VLM) pipeline. Building on Bongard-RWR, we employ Pixtral-12B to describe manually curated images and generate new descriptions aligned with the underlying concepts, use Flux.1-dev to synthesize images from these descriptions, and manually verify that the generated images faithfully reflect the intended concepts. We evaluate state-of-the-art VLMs across diverse BP formulations, including binary and multiclass classification, as well as textual answer generation. Our findings reveal that while VLMs can recognize coarse-grained visual concepts, they consistently struggle with discerning fine-grained concepts, highlighting limitations in their reasoning capabilities.', 'abstract_zh': 'Bongard问题（BPs）提供了一种挑战性的抽象视觉推理（AVR）测试平台，要求模型仅从少量例子中识别视觉概念，并用自然语言描述这些概念。早期的BPs基准使用合成的黑白绘制图，可能未能充分捕捉真实世界场景的复杂性。随后的BPs数据集使用了真实世界图像，尽管这些图像中的概念可以从高层图像特征中识别，从而降低了任务的复杂性。不同的是，最近发布的Bongard-RWR数据集旨在通过精细的真实世界图像表示原始BPs中的抽象概念。然而，其手工构建限制了数据集的规模，只有60个实例，影响了评估的 robustness。在这项工作中，我们引入了Bongard-RWR+，这是一个包含5400个实例的BPs数据集，使用视觉语言模型（VLM）流水线生成的类真实世界图像来表示原始BPs的抽象概念。基于Bongard-RWR，我们使用Pixtral-12B描述手工策划的图像并生成与底层概念对齐的新描述，使用Flux.1-dev从这些描述合成图像，并人工验证生成的图像忠实反映了预期的概念。我们评估了最先进的视觉语言模型在多种Bongard问题表示形式上的性能，包括二分类和多分类，以及文本答案生成。我们的研究发现，虽然视觉语言模型能够识别粗粒度的视觉概念，但它们在辨别细粒度概念方面表现不佳，突显了推理能力的局限性。', 'title_zh': 'Bongard-RWR+：Bongard 问题中精细概念的现实世界表示'}
{'arxiv_id': 'arXiv:2508.12022', 'title': 'AI Models for Depressive Disorder Detection and Diagnosis: A Review', 'authors': 'Dorsa Macky Aleagha, Payam Zohari, Mostafa Haghir Chehreghani', 'link': 'https://arxiv.org/abs/2508.12022', 'abstract': 'Major Depressive Disorder is one of the leading causes of disability worldwide, yet its diagnosis still depends largely on subjective clinical assessments. Integrating Artificial Intelligence (AI) holds promise for developing objective, scalable, and timely diagnostic tools. In this paper, we present a comprehensive survey of state-of-the-art AI methods for depression detection and diagnosis, based on a systematic review of 55 key studies. We introduce a novel hierarchical taxonomy that structures the field by primary clinical task (diagnosis vs. prediction), data modality (text, speech, neuroimaging, multimodal), and computational model class (e.g., graph neural networks, large language models, hybrid approaches). Our in-depth analysis reveals three major trends: the predominance of graph neural networks for modeling brain connectivity, the rise of large language models for linguistic and conversational data, and an emerging focus on multimodal fusion, explainability, and algorithmic fairness. Alongside methodological insights, we provide an overview of prominent public datasets and standard evaluation metrics as a practical guide for researchers. By synthesizing current advances and highlighting open challenges, this survey offers a comprehensive roadmap for future innovation in computational psychiatry.', 'abstract_zh': '重大抑郁障碍是全球主要的致残原因，但其诊断仍主要依赖于主观临床评估。 integrates artificial intelligence (ai) 有望促进客观、可扩展和及时的诊断工具的发展。本文综述了55篇关键研究的基础上，系统探讨了最新的ai方法在抑郁检测和诊断中的应用。我们提出了一个新颖的层次分类体系，按主要临床任务（诊断 vs. 预测）、数据模态（文本、语音、神经影像、多模态）和计算模型类别（如图神经网络、大规模语言模型、混合方法）对领域进行结构化。深入分析揭示了三大趋势：脑连接建模中图神经网络的主导地位，大规模语言模型在语言和对话数据中的崛起，以及对多模态融合、可解释性和算法公平性的新兴关注。我们不仅提供了方法论洞见，还概述了主要的公开数据集和标准评估指标，为研究人员提供实用指南。通过综合当前进展并突出开放挑战，本文为计算精神病学未来创新提供了一个全面的路线图。', 'title_zh': 'AI模型在抑郁障碍检测与诊断中的应用：一项综述'}
{'arxiv_id': 'arXiv:2508.11991', 'title': 'Modeling Relational Logic Circuits for And-Inverter Graph Convolutional Network', 'authors': 'Weihao Sun', 'link': 'https://arxiv.org/abs/2508.11991', 'abstract': "The automation of logic circuit design enhances chip performance, energy efficiency, and reliability, and is widely applied in the field of Electronic Design Automation (EDA).And-Inverter Graphs (AIGs) efficiently represent, optimize, and verify the functional characteristics of digital circuits, enhancing the efficiency of EDA this http URL to the complex structure and large scale of nodes in real-world AIGs, accurate modeling is challenging, leading to existing work lacking the ability to jointly model functional and structural characteristics, as well as insufficient dynamic information propagation this http URL address the aforementioned challenges, we propose this http URL, AIGer consists of two components: 1) Node logic feature initialization embedding component and 2) AIGs feature learning network this http URL node logic feature initialization embedding component projects logic nodes, such as AND and NOT, into independent semantic spaces, to enable effective node embedding for subsequent this http URL upon this, the AIGs feature learning network component employs a heterogeneous graph convolutional network, designing dynamic relationship weight matrices and differentiated information aggregation approaches to better represent the original structure and information of this http URL combination of these two components enhances AIGer's ability to jointly model functional and structural characteristics and improves its message passing capability. Experimental results indicate that AIGer outperforms the current best models in the Signal Probability Prediction (SSP) task, improving MAE and MSE by 18.95\\% and 44.44\\%, respectively. In the Truth Table Distance Prediction (TTDP) task, AIGer achieves improvements of 33.57\\% and 14.79\\% in MAE and MSE, respectively, compared to the best-performing models.", 'abstract_zh': '逻辑电路设计自动化增强芯片性能、能量效率和可靠性，并广泛应用于电子设计自动化（EDA）领域。And-Inverter图（AIGs）高效地表示、优化和验证数字电路的功能特性，提升EDA的效率。然而，由于现实世界中AIGs复杂结构和大量节点，准确建模具有挑战性，导致现有工作难以同时建模功能和结构特性，以及信息传播动态不足。为解决上述挑战，我们提出了AIGer，它由两个部分组成：1）节点逻辑特征初始化嵌入组件；2）AIGs特征学习网络。节点逻辑特征初始化嵌入组件将如AND和NOT等逻辑节点投影到独立的语义空间中，以实现后续的有效节点嵌入。在此基础上，AIGs特征学习网络组件采用异构图卷积网络，设计动态关系权重矩阵和差异化的信息聚合方法，更好地表示原始结构和信息。这两种组件的结合增强了AIGer同时建模功能和结构特性的能力，并提高了其消息传递能力。实验结果表明，AIGer在信号概率预测（SSP）任务中优于当前最佳模型，分别将MAE和MSE提高了18.95%和44.44%。在真理表距离预测（TTDP）任务中，AIGer将MAE和MSE分别提高了33.57%和14.79%，优于表现最佳的模型。', 'title_zh': '基于And-Inverter图卷积网络的关系逻辑电路建模'}
{'arxiv_id': 'arXiv:2508.11975', 'title': 'Chart-CoCa: Self-Improving Chart Understanding of Vision LMs via Code-Driven Synthesis and Candidate-Conditioned Answering', 'authors': 'Gongyao Jiang, Qiong Luo', 'link': 'https://arxiv.org/abs/2508.11975', 'abstract': 'Vision Language Models (VLMs) often struggle with chart understanding tasks, particularly in accurate chart description and complex reasoning. Synthetic data generation is a promising solution, while usually facing the challenge of noise labels. To address this challenge, we first introduce a chart synthesis pipeline that generates aligned chart-question-answer triplets through code generation and execution, ensuring the reliability of synthetic data without human intervention. Furthermore, inspired by test-time scaling that increases inference budget and thereby improves performance, we design a candidate-conditioned answering process. The VLM first generates multiple responses per query, and then synthesizes the final answer by contextualizing these candidates. Experiments demonstrate significant improvements, with up to 15.50 points accuracy gain over the initial VLM, in a fully self-improving paradigm without either human-labeled data or external models.', 'abstract_zh': '视觉语言模型在图表理解任务中往往表现出色，特别是在准确的图表描述和复杂推理方面存在挑战。合成数据生成是一种有前景的解决方案，但通常会遇到噪声标签的挑战。为应对这一挑战，我们首先介绍了一种图表合成管道，通过代码生成和执行生成对齐的图表-问题-答案 triplet，确保在无需人类干预的情况下生成合成数据的可靠性。此外，受测试时扩增增加推理预算从而提高性能的启发，我们设计了一种候选条件化回答过程。视觉语言模型首先生成每个查询的多个响应，然后通过上下文化这些候选来合成最终答案。实验结果表明，在完全自我改进的范式下，该模型在无需人工标注数据或外部模型的情况下，准确率提高了高达15.50个百分点。', 'title_zh': 'Chart-CoCa: 通过代码引导合成和候选条件回答自我提升的图表理解视觉LMs'}
{'arxiv_id': 'arXiv:2508.11959', 'title': 'Rigorous Feature Importance Scores based on Shapley Value and Banzhaf Index', 'authors': 'Xuanxiang Huang, Olivier Létoffé, Joao Marques-Silva', 'link': 'https://arxiv.org/abs/2508.11959', 'abstract': 'Feature attribution methods based on game theory are ubiquitous in the field of eXplainable Artificial Intelligence (XAI). Recent works proposed rigorous feature attribution using logic-based explanations, specifically targeting high-stakes uses of machine learning (ML) models. Typically, such works exploit weak abductive explanation (WAXp) as the characteristic function to assign importance to features. However, one possible downside is that the contribution of non-WAXp sets is neglected. In fact, non-WAXp sets can also convey important information, because of the relationship between formal explanations (XPs) and adversarial examples (AExs). Accordingly, this paper leverages Shapley value and Banzhaf index to devise two novel feature importance scores. We take into account non-WAXp sets when computing feature contribution, and the novel scores quantify how effective each feature is at excluding AExs. Furthermore, the paper identifies properties and studies the computational complexity of the proposed scores.', 'abstract_zh': '基于博弈论的特征归因方法在可解释人工智能（XAI）领域广泛应用。近期研究提出了基于逻辑解释的严格特征归因方法，特别针对机器学习（ML）模型的高风险应用。通常，此类工作利用弱归纳解释（WAXp）作为特征重要性分配的特征函数。然而，一个潜在的缺点是未考虑非WAXp集的贡献。事实上，非WAXp集也能提供重要的信息，因为形式化解释（XPs）与对抗性示例（AExs）之间的关系。因此，本文利用Shapley值和Banzhaf指数提出两种新的特征重要性评分。在计算特征贡献时考虑到非WAXp集，并且新的评分衡量每个特征排除AExs的有效性。此外，本文还研究了所提评分的性质及其计算复杂性。', 'title_zh': '基于Shapley值和巴纳夫指数的严谨特征重要性评分'}
{'arxiv_id': 'arXiv:2508.13113', 'title': 'Contrastive Representations for Temporal Reasoning', 'authors': 'Alicja Ziarko, Michal Bortkiewicz, Michal Zawalski, Benjamin Eysenbach, Piotr Milos', 'link': 'https://arxiv.org/abs/2508.13113', 'abstract': "In classical AI, perception relies on learning state-based representations, while planning, which can be thought of as temporal reasoning over action sequences, is typically achieved through search. We study whether such reasoning can instead emerge from representations that capture both perceptual and temporal structure. We show that standard temporal contrastive learning, despite its popularity, often fails to capture temporal structure due to its reliance on spurious features. To address this, we introduce Combinatorial Representations for Temporal Reasoning (CRTR), a method that uses a negative sampling scheme to provably remove these spurious features and facilitate temporal reasoning. CRTR achieves strong results on domains with complex temporal structure, such as Sokoban and Rubik's Cube. In particular, for the Rubik's Cube, CRTR learns representations that generalize across all initial states and allow it to solve the puzzle using fewer search steps than BestFS, though with longer solutions. To our knowledge, this is the first method that efficiently solves arbitrary Cube states using only learned representations, without relying on an external search algorithm.", 'abstract_zh': '基于组合表示的时间推理（Combinatorial Representations for Temporal Reasoning）：解决具有复杂时间结构领域的问题', 'title_zh': '对比表示方法在时间推理中的应用'}
{'arxiv_id': 'arXiv:2508.13070', 'title': 'Reinforced Context Order Recovery for Adaptive Reasoning and Planning', 'authors': 'Long Ma, Fangwei Zhong, Yizhou Wang', 'link': 'https://arxiv.org/abs/2508.13070', 'abstract': 'Modern causal language models, followed by rapid developments in discrete diffusion models, can now produce a wide variety of interesting and useful content. However, these families of models are predominantly trained to output tokens with a fixed (left-to-right) or random order, which may deviate from the logical order in which tokens are generated originally. In this paper, we observe that current causal and diffusion models encounter difficulties in problems that require adaptive token generation orders to solve tractably, which we characterize with the $\\mathcal{V}$-information framework. Motivated by this, we propose Reinforced Context Order Recovery (ReCOR), a reinforcement-learning-based framework to extract adaptive, data-dependent token generation orders from text data without annotations. Self-supervised by token prediction statistics, ReCOR estimates the hardness of predicting every unfilled token and adaptively selects the next token during both training and inference. Experiments on challenging reasoning and planning datasets demonstrate the superior performance of ReCOR compared with baselines, sometimes outperforming oracle models supervised with the ground-truth order.', 'abstract_zh': '现代因果语言模型在离散扩散模型快速发展的背景下，能够生成广泛种类的有趣和有用的内容。然而，这些模型大多被训练成以固定顺序（从左到右）或随机顺序生成标记，这可能与标记原始生成的逻辑顺序不符。在本文中，我们观察到当前因果和扩散模型在需要自适应标记生成顺序以解决的问题中遇到了困难，我们使用$\\mathcal{V}$-信息框架来刻画这一特征。受到这一观察的启发，我们提出了一种基于强化学习的框架Reinforced Context Order Recovery (ReCOR)，该框架能够在无需标注的情况下从文本数据中提取自适应的数据依赖性标记生成顺序。通过标记预测统计进行半监督学习，ReCOR 估计每个未填充标记的预测难度，并在训练和推理过程中自适应地选择下一个标记。在具有挑战性的推理和规划数据集上的实验表明，ReCOR 的表现优于基线模型，有时甚至优于带有真实顺序标注的 oracle 模型。', 'title_zh': '强化上下文顺序恢复以实现自适应推理与规划'}
{'arxiv_id': 'arXiv:2508.13057', 'title': 'Hierarchical Evaluation Function (HEF): A Multi-Metric Approach for Optimizing Demand Forecasting Models', 'authors': 'Adolfo González, Víctor Parada', 'link': 'https://arxiv.org/abs/2508.13057', 'abstract': 'Demand forecasting is essential for strategic planning in competitive environments, enabling resource optimization and improved responsiveness to market dynamics. However, multivariate time series modeling faces challenges due to data complexity, uncertainty, and frequent regime shifts. Traditional evaluation metrics can introduce biases and limit generalization. This work compares two custom evaluation functions: FMAE (Focused Mean Absolute Error), focused on minimizing absolute errors, and HEF (Hierarchical Evaluation Function), designed to weight global metrics and penalize large deviations. Experiments were conducted under different data splits (91:9, 80:20, 70:30) using three optimizers (Grid Search, PSO, Optuna), assessing fit, relative accuracy, robustness, and computational efficiency. Results show that HEF consistently outperforms FMAE in global metrics (R2, Relative Accuracy, RMSE, RMSSE), enhancing model robustness and explanatory power. These findings were confirmed via visualizations and statistical tests. Conversely, FMAE offers advantages in local metrics (MAE, MASE) and execution time, making it suitable for short-term scenarios. The study highlights a methodological trade-off: HEF is ideal for strategic planning, while FMAE is better suited for operational efficiency. A replicable framework is proposed for optimizing predictive models in dynamic environments.', 'abstract_zh': '基于定制评价函数的多变量时间序列建模比较：面向动态环境的预测模型优化方法', 'title_zh': '层次评估函数（HEF）：一种多指标方法优化需求预测模型'}
{'arxiv_id': 'arXiv:2508.13049', 'title': 'XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads', 'authors': 'Tejas Chaudhari, Akarsh J., Tanushree Dewangan, Mukul Lokhande, Santosh Kumar Vishvakarma', 'link': 'https://arxiv.org/abs/2508.13049', 'abstract': 'This work proposes XR-NPE, a high-throughput Mixed-precision SIMD Neural Processing Engine, designed for extended reality (XR) perception workloads like visual inertial odometry (VIO), object classification, and eye gaze extraction. XR-NPE is first to support FP4, Posit (4,1), Posit (8,0), and Posit (16,1) formats, with layer adaptive hybrid-algorithmic implementation supporting ultra-low bit precision to significantly reduce memory bandwidth requirements, and accompanied by quantization-aware training for minimal accuracy loss. The proposed Reconfigurable Mantissa Multiplication and Exponent processing Circuitry (RMMEC) reduces dark silicon in the SIMD MAC compute engine, assisted by selective power gating to reduce energy consumption, providing 2.85x improved arithmetic intensity. XR-NPE achieves a maximum operating frequency of 1.72 GHz, area 0.016 mm2 , and arithmetic intensity 14 pJ at CMOS 28nm, reducing 42% area, 38% power compared to the best of state-of-the-art MAC approaches. The proposed XR-NPE based AXI-enabled Matrix-multiplication co-processor consumes 1.4x fewer LUTs, 1.77x fewer FFs, and provides 1.2x better energy efficiency compared to SoTA accelerators on VCU129. The proposed co-processor provides 23% better energy efficiency and 4% better compute density for VIO workloads. XR-NPE establishes itself as a scalable, precision-adaptive compute engine for future resource-constrained XR devices. The complete set for codes for results reproducibility are released publicly, enabling designers and researchers to readily adopt and build upon them. this https URL.', 'abstract_zh': 'XR-NPE：一种面向扩展现实感知工作负载的高吞吐量混合精度 SIMD 神经处理引擎', 'title_zh': 'XR-NPE：扩展现实感知工作负载的高 throughput 混合精度 SIMD 神经处理引擎'}
{'arxiv_id': 'arXiv:2508.13030', 'title': 'The Application of Transformer-Based Models for Predicting Consequences of Cyber Attacks', 'authors': 'Bipin Chhetri, Akbar Siami Namin', 'link': 'https://arxiv.org/abs/2508.13030', 'abstract': 'Cyberattacks are increasing, and securing against such threats is costing industries billions of dollars annually. Threat Modeling, that is, comprehending the consequences of these attacks, can provide critical support to cybersecurity professionals, enabling them to take timely action and allocate resources that could be used elsewhere. Cybersecurity is heavily dependent on threat modeling, as it assists security experts in assessing and mitigating risks related to identifying vulnerabilities and threats. Recently, there has been a pressing need for automated methods to assess attack descriptions and forecast the future consequences of the increasing complexity of cyberattacks. This study examines how Natural Language Processing (NLP) and deep learning can be applied to analyze the potential impact of cyberattacks by leveraging textual descriptions from the MITRE Common Weakness Enumeration (CWE) database. We emphasize classifying attack consequences into five principal categories: Availability, Access Control, Confidentiality, Integrity, and Other. This paper investigates the use of Bidirectional Encoder Representations from Transformers (BERT) in combination with Hierarchical Attention Networks (HANs) for Multi-label classification, evaluating their performance in comparison with conventional CNN and LSTM-based models. Experimental findings show that BERT achieves an overall accuracy of $0.972$, far higher than conventional deep learning models in multi-label classification. HAN outperforms baseline forms of CNN and LSTM-based models on specific cybersecurity labels. However, BERT consistently achieves better precision and recall, making it more suitable for predicting the consequences of a cyberattack.', 'abstract_zh': '网络攻击日益增多，抵御这些威胁的代价每年使各行各业支出数十亿美元。通过对这些攻击后果的威胁建模，可以为网络安全专业人员提供关键支持，使他们能够及时采取行动并合理分配资源。威胁建模对于网络安全至关重要，因为它有助于安全专家评估和减轻识别漏洞和威胁相关的风险。最近，迫切需要自动化方法来评估攻击描述并预测日益复杂的网络攻击的未来后果。本研究探讨了如何利用自然语言处理（NLP）和深度学习分析MITRE通用弱点枚举（CWE）数据库中的文本描述，从而评估网络攻击的潜在影响。本文研究了使用双向编码器表示变换器（BERT）与层次注意力网络（HAN）进行多标签分类的方法，并评估了它们在多标签分类中的性能，与传统的基于CNN和LSTM的模型相比。实验结果表明，BERT的整体准确率达到了0.972，远高于传统的深度学习模型。HAN在特定的网络安全标签上优于基于CNN和LSTM的基本模型。然而，BERT在精度和召回率方面始终表现更优，使其更适合预测网络攻击的后果。', 'title_zh': '基于变压器模型在预测网络攻击后果的应用'}
{'arxiv_id': 'arXiv:2508.12998', 'title': 'Vitamin N: Benefits of Different Forms of Public Greenery for Urban Health', 'authors': 'Sanja Šćepanović, Sagar Joglekar, Stephen Law, Daniele Quercia, Ke Zhou, Alice Battiston, Rossano Schifanella', 'link': 'https://arxiv.org/abs/2508.12998', 'abstract': 'Urban greenery is often linked to better health, yet findings from past research have been inconsistent. One reason is that official greenery metrics measure the amount or nearness of greenery but ignore how often people actually may potentially see or use it in daily life. To address this gap, we introduced a new classification that separates on-road greenery, which people see while walking through streets, from off-road greenery, which requires planned visits. We did so by combining aerial imagery of Greater London and greenery data from OpenStreetMap with quantified greenery from over 100,000 Google Street View images and accessibility estimates based on 160,000 road segments. We linked these measures to 7.45 billion medical prescriptions issued by the National Health Service and processed through our methodology. These prescriptions cover five conditions: diabetes, hypertension, asthma, depression, and anxiety, as well as opioid use. As hypothesized, we found that green on-road was more strongly linked to better health than four widely used official measures. For example, hypertension prescriptions dropped by 3.68% in wards with on-road greenery above the median citywide level compared to those below it. If all below-median wards reached the citywide median in on-road greenery, prescription costs could fall by up to £3.15 million each year. These results suggest that greenery seen in daily life may be more relevant than public yet secluded greenery, and that official metrics commonly used in the literature have important limitations.', 'abstract_zh': '城市绿化与其更好的健康影响之间存在关联，但以往研究结果不一。为解决这一问题，我们引入了一种新的分类方法，将人们在街道上步行时可见的绿化（有路绿化）与需要计划拜访的绿化（无路绿化）分开。通过将大伦敦地区航拍图像与OpenStreetMap的绿化数据结合超过100,000张Google街景图像的量化绿化信息以及基于160,000条道路段的可达性估计，我们建立了这些指标，并将其与英国国家医疗服务体系发出的74.5亿份医疗处方（涵盖糖尿病、高血压、哮喘、抑郁和焦虑，以及阿片类药物使用）联系起来。正如预期的那样，我们发现有路绿化与更好的健康状况之间的关联比四个广泛使用的官方指标更强。例如，与城市平均水平低于中位数的地区相比，城市平均水平高于中位数且有路绿化较多的区县高血压处方减少了3.68%。如果所有低于中位数的区县都能达到城市平均水平的中位数有路绿化，每年的处方成本可能会降低高达315万英镑。这些结果表明，日常可见的绿化可能比公共但隔离的绿化更加相关，而文献中常用的官方指标存在重要局限性。', 'title_zh': '维生素N：不同形式的公共绿化对城市健康的好处'}
{'arxiv_id': 'arXiv:2508.12996', 'title': 'Kourkoutas-Beta: A Sunspike-Driven Adam Optimizer with Desert Flair', 'authors': 'Stavros C. Kassinos', 'link': 'https://arxiv.org/abs/2508.12996', 'abstract': "Transformer neural networks are increasingly used for physics-based problems. In data-driven PDE surrogates, training samples from varying boundary and initial conditions can cause erratic losses and spiky gradients; in physics-informed neural networks (PINNs), stiff composite losses amplify this effect.\nWe introduce Kourkoutas-Beta, an Adam-style optimizer where the fixed second-moment discount beta2 is replaced by a layer-wise dynamic value driven by a bounded ``sunspike'' ratio: the current pooled gradient norm divided by an exponential moving average (EMA) of past norms, squashed to the interval [0,1). Spikes lower beta2 toward beta2_min; calm phases keep it near beta2_max. Options include leaky-AMSGrad (decay), trust-region clipping (max_ratio), adaptive tiny terms, and several bias-correction modes ``none'', ``beta2max'', ``exact'). With all features off and bias_correction=``none'', the method is exactly Adam.\nWe test on four settings: (i) a Transformer PDE surrogate (Heat2D), (ii) a 3D PINN for heat conduction (Heat3D), (iii) a lightweight MLX synthetic task with jitter and rare-trigger bursts, and (iv) a character-level Transformer on 30 MB of enwik8 (small-enwik8). Kourkoutas-Beta improves stability and final loss versus fixed-beta2 Adam. On small-enwik8 it lowers bits-per-character by about 38% vs Adam-0.95 and about 58% vs Adam-0.999 over 10 seeds, with smaller variance. The method remains drop-in, with runtime overhead comparable to Adam in testbeds A-C and within single-digit percent in testbed D. It preserves Adam-style convergence guarantees while improving robustness under spiky gradients.", 'abstract_zh': '基于Transformer的神经网络在物理问题中 increasingly 被用于数据驱动的偏微分方程代理模型中。在不同的边界和初始条件的训练样本下，可能会导致不稳定的损失和突变的梯度；在物理知情神经网络（PINNs）中，刚性的复合损失会放大这一效应。引入了 Kourkoutas-Beta 优化器，这是一种 Adam 风格的优化器，其中固定的第二矩折扣因子 β2 被替换为由有界“太阳突变”比值驱动的逐层动态值：当前汇聚的梯度范数与过去的范数的指数移动平均值的比值，被压缩到区间 [0,1)。突变会使得 β2 向 β2_min 降低；平稳阶段则使 β2 保持在 β2_max 附近。该方法包括带泄漏的 AMSGrad（衰减）、信任区域修剪（max_ratio）、自适应微小项以及几种偏置校正模式（“none”、“beta2max”、“exact”）。在所有功能关闭且偏置校正为“none”的情况下，该方法等同于 Adam。在四个测试设置下进行测试：（i）一个基于Transformer的PDE代理模型（Heat2D），（ii）一个用于热传导的3D PINN（Heat3D），（iii）一个具有抖动和罕见触发突发的轻量级MLX合成任务，以及（iv）一个基于字符级Transformer的30 MB enwik8数据集任务（small-enwik8）。Kourkoutas-Beta 在增强稳定性及最终损失方面优于固定 β2 的 Adam。在 small-enwik8 上，它将每个字符的比特数降低了约 38%（相对于 Adam-0.95）和约 58%（相对于 Adam-0.999），且方差较小。该方法保持了 Adam 式的收敛保证，同时在突变梯度下提高了鲁棒性。', 'title_zh': 'Kourkoutas-Beta：一种具有沙漠风情的Sunspike驱动Adam优化器'}
{'arxiv_id': 'arXiv:2508.12984', 'title': 'SL-ACC: A Communication-Efficient Split Learning Framework with Adaptive Channel-wise Compression', 'authors': 'Zehang Lin, Zheng Lin, Miao Yang, Jianhao Huang, Yuxin Zhang, Zihan Fang, Xia Du, Zhe Chen, Shunzhi Zhu, Wei Ni', 'link': 'https://arxiv.org/abs/2508.12984', 'abstract': 'The increasing complexity of neural networks poses a significant barrier to the deployment of distributed machine learning (ML) on resource-constrained devices, such as federated learning (FL). Split learning (SL) offers a promising solution by offloading the primary computing load from edge devices to a server via model partitioning. However, as the number of participating devices increases, the transmission of excessive smashed data (i.e., activations and gradients) becomes a major bottleneck for SL, slowing down the model training. To tackle this challenge, we propose a communication-efficient SL framework, named SL-ACC, which comprises two key components: adaptive channel importance identification (ACII) and channel grouping compression (CGC). ACII first identifies the contribution of each channel in the smashed data to model training using Shannon entropy. Following this, CGC groups the channels based on their entropy and performs group-wise adaptive compression to shrink the transmission volume without compromising training accuracy. Extensive experiments across various datasets validate that our proposed SL-ACC framework takes considerably less time to achieve a target accuracy than state-of-the-art benchmarks.', 'abstract_zh': '基于通信效率的分学习框架SL-ACC：自适应信道重要性识别与信道分组压缩', 'title_zh': 'SL-ACC：一种适应性通道压缩的通信高效分割学习框架'}
{'arxiv_id': 'arXiv:2508.12932', 'title': "SEDEG:Sequential Enhancement of Decoder and Encoder's Generality for Class Incremental Learning with Small Memory", 'authors': 'Hongyang Chen, Shaoling Pu, Lingyu Zheng, Zhongwu Sun', 'link': 'https://arxiv.org/abs/2508.12932', 'abstract': "In incremental learning, enhancing the generality of knowledge is crucial for adapting to dynamic data inputs. It can develop generalized representations or more balanced decision boundaries, preventing the degradation of long-term knowledge over time and thus mitigating catastrophic forgetting. Some emerging incremental learning methods adopt an encoder-decoder architecture and have achieved promising results. In the encoder-decoder achitecture, improving the generalization capabilities of both the encoder and decoder is critical, as it helps preserve previously learned knowledge while ensuring adaptability and robustness to new, diverse data inputs. However, many existing continual methods focus solely on enhancing one of the two components, which limits their effectiveness in mitigating catastrophic forgetting. And these methods perform even worse in small-memory scenarios, where only a limited number of historical samples can be stored. To mitigate this limitation, we introduces SEDEG, a two-stage training framework for vision transformers (ViT), focusing on sequentially improving the generality of both Decoder and Encoder. Initially, SEDEG trains an ensembled encoder through feature boosting to learn generalized representations, which subsequently enhance the decoder's generality and balance the classifier. The next stage involves using knowledge distillation (KD) strategies to compress the ensembled encoder and develop a new, more generalized encoder. This involves using a balanced KD approach and feature KD for effective knowledge transfer. Extensive experiments on three benchmark datasets show SEDEG's superior performance, and ablation studies confirm the efficacy of its components. The code is available at this https URL.", 'abstract_zh': 'Incremental 学习中，增强知识的普适性对于适应动态数据输入至关重要。它能够发展出更为通用的表示或更加平衡的决策边界，防止长期知识的退化，从而减轻灾难性遗忘。一些新兴的增量学习方法采用了编码器-解码器架构，并取得了令人鼓舞的结果。在编码器-解码器架构中，提高编码器和解码器的泛化能力至关重要，这有助于保留先前学习的知识，同时确保对新、多样数据输入的适应性和鲁棒性。然而，许多现有的持续学习方法仅专注于增强这两个组件中的一个，这限制了它们在减轻灾难性遗忘方面的有效性。尤其是在小内存场景下，这些方法表现更差，只能存储有限的历史样本。为解决这一限制，我们提出了 SEDEG，这是一种针对视觉变换器 (ViT) 的两阶段训练框架，专注于按顺序提高解码器和编码器的普适性。初始阶段，SEDEG 通过特征增强训练集成编码器以学习通用表示，随后增强解码器的普适性和平衡分类器。第二阶段通过知识蒸馏 (KD) 策略压缩集成编码器并开发出新的更通用的编码器，这涉及使用平衡KD方法和特征KD进行有效的知识转移。在三个基准数据集上的广泛实验展示了 SEDEG 的优越性能，并且消融研究证实了其组件的有效性。代码可在此处访问：这个 URL。', 'title_zh': 'SEDEG：面向小内存环境下类增量学习的解码器和编码器顺序增强方法'}
{'arxiv_id': 'arXiv:2508.12927', 'title': 'Learning local and global prototypes with optimal transport for unsupervised anomaly detection and localization', 'authors': 'Robin Trombetta, Carole Lartizien', 'link': 'https://arxiv.org/abs/2508.12927', 'abstract': 'Unsupervised anomaly detection aims to detect defective parts of a sample by having access, during training, to a set of normal, i.e. defect-free, data. It has many applications in fields, such as industrial inspection or medical imaging, where acquiring labels is costly or when we want to avoid introducing biases in the type of anomalies that can be spotted. In this work, we propose a novel UAD method based on prototype learning and introduce a metric to compare a structured set of embeddings that balances a feature-based cost and a spatial-based cost. We leverage this metric to learn local and global prototypes with optimal transport from latent representations extracted with a pre-trained image encoder. We demonstrate that our approach can enforce a structural constraint when learning the prototypes, allowing to capture the underlying organization of the normal samples, thus improving the detection of incoherencies in images. Our model achieves performance that is on par with strong baselines on two reference benchmarks for anomaly detection on industrial images. The code is available at this https URL.', 'abstract_zh': '无监督异常检测旨在通过在训练过程中访问一组正常、即无缺陷的数据，来检测样本中的缺陷部分。它在工业检测或医学影像等领域有很多应用，这些领域获取标签的成本很高，或者我们希望避免在可检测的异常类型中引入偏差。在本工作中，我们提出了一种基于原型学习的新型无监督异常检测方法，并引入了一种度量标准来比较结构化的嵌入集合，该度量标准平衡了基于特征的成本和基于空间的成本。我们利用这种度量标准，通过对预训练图像编码器提取的潜在表示进行_optimal transport_学习局部和全局原型。我们证明，我们的方法可以在学习原型时施加结构约束，从而捕获正常样本的潜在组织结构，进而提高图像中不一致性检测的性能。我们的模型在两个工业图像异常检测基准上的性能与强基线相当。代码可在以下链接获取：this https URL。', 'title_zh': '使用最优传输学习局部和全局原型进行无监督异常检测和定位'}
{'arxiv_id': 'arXiv:2508.12885', 'title': 'One-Class Intrusion Detection with Dynamic Graphs', 'authors': 'Aleksei Liuliakov, Alexander Schulz, Luca Hermes, Barbara Hammer', 'link': 'https://arxiv.org/abs/2508.12885', 'abstract': 'With the growing digitalization all over the globe, the relevance of network security becomes increasingly important. Machine learning-based intrusion detection constitutes a promising approach for improving security, but it bears several challenges. These include the requirement to detect novel and unseen network events, as well as specific data properties, such as events over time together with the inherent graph structure of network communication. In this work, we propose a novel intrusion detection method, TGN-SVDD, which builds upon modern dynamic graph modelling and deep anomaly detection. We demonstrate its superiority over several baselines for realistic intrusion detection data and suggest a more challenging variant of the latter.', 'abstract_zh': '随着全球数字化程度的不断加深，网络安全的重要性日益凸显。基于机器学习的入侵检测构成了提升安全性的有promise的方法，但同时也面临着几大挑战，包括检测新型且未见过的网络事件，以及数据的特定属性，如事件随时间的变化以及网络通信固有的图结构。在本工作中，我们提出了一种新的入侵检测方法TGN-SVDD，该方法基于现代动态图建模和深度异常检测。我们证明了该方法在现实的入侵检测数据中优于几种基准方法，并提出了一种更具挑战性的基准变体。', 'title_zh': '基于动态图的一类入侵检测'}
{'arxiv_id': 'arXiv:2508.12839', 'title': 'HRS: Hybrid Representation Framework with Scheduling Awareness for Time Series Forecasting in Crowdsourced Cloud-Edge Platforms', 'authors': 'Tiancheng Zhang, Cheng Zhang, Shuren Liu, Xiaofei Wang, Shaoyuan Huang, Wenyu Wang', 'link': 'https://arxiv.org/abs/2508.12839', 'abstract': 'With the rapid proliferation of streaming services, network load exhibits highly time-varying and bursty behavior, posing serious challenges for maintaining Quality of Service (QoS) in Crowdsourced Cloud-Edge Platforms (CCPs). While CCPs leverage Predict-then-Schedule architecture to improve QoS and profitability, accurate load forecasting remains challenging under traffic surges. Existing methods either minimize mean absolute error, resulting in underprovisioning and potential Service Level Agreement (SLA) violations during peak periods, or adopt conservative overprovisioning strategies, which mitigate SLA risks at the expense of increased resource expenditure. To address this dilemma, we propose HRS, a hybrid representation framework with scheduling awareness that integrates numerical and image-based representations to better capture extreme load dynamics. We further introduce a Scheduling-Aware Loss (SAL) that captures the asymmetric impact of prediction errors, guiding predictions that better support scheduling decisions. Extensive experiments on four real-world datasets demonstrate that HRS consistently outperforms ten baselines and achieves state-of-the-art performance, reducing SLA violation rates by 63.1% and total profit loss by 32.3%.', 'abstract_zh': '随着流媒体服务的迅速普及，网络负载表现出高度的时间变化性和突发性，这对Crowdsourced Cloud-Edge Platforms (CCPs)中保持服务质量(QoS)提出了严重挑战。虽然CCPs利用预测-调度架构来提高QoS和盈利能力，但在流量激增的情况下，准确的负载预测仍然具有挑战性。现有方法要么最小化均绝对误差，导致在高峰期出现服务能力不足和可能违反服务水平协议(SLA)，要么采用保守的过度配置策略，虽然减轻了SLA风险，但增加了资源支出。为了应对这一困境，我们提出了一种具有调度意识的混合表示框架HRS，该框架结合了数值和基于图像的表示，以更好地捕捉极端负载动态。此外，我们引入了一种调度意识损失(SAL)，以捕捉预测误差的不对称影响，从而指导更有利于调度决策的预测。在四个真实世界数据集上的广泛实验表明，HRS持续优于十个基线方法，并达到最先进的性能，SLA违反率降低了63.1%，总利润损失降低了32.3%。', 'title_zh': 'HRS：具有调度意识的混合表示框架在众包云边平台的时间序列预测中应用'}
{'arxiv_id': 'arXiv:2508.12833', 'title': 'Toward Storage-Aware Learning with Compressed Data An Empirical Exploratory Study on JPEG', 'authors': 'Kichang Lee, Songkuk Kim, JaeYeon Park, JeongGil Ko', 'link': 'https://arxiv.org/abs/2508.12833', 'abstract': 'On-device machine learning is often constrained by limited storage, particularly in continuous data collection scenarios. This paper presents an empirical study on storage-aware learning, focusing on the trade-off between data quantity and quality via compression. We demonstrate that naive strategies, such as uniform data dropping or one-size-fits-all compression, are suboptimal. Our findings further reveal that data samples exhibit varying sensitivities to compression, supporting the feasibility of a sample-wise adaptive compression strategy. These insights provide a foundation for developing a new class of storage-aware learning systems. The primary contribution of this work is the systematic characterization of this under-explored challenge, offering valuable insights that advance the understanding of storage-aware learning.', 'abstract_zh': '在设备上进行的机器学习往往受限于有限的存储空间，尤其是在连续数据收集场景中。本文对存储感知学习进行了实证研究，关注数据数量与质量之间的权衡，通过压缩来实现。我们证明了朴素策略，如均匀数据丢弃或一刀切的压缩方法，是不理想的。研究发现进一步表明，数据样本对压缩的敏感性各异，支持了样本级别的自适应压缩策略的可行性。这些洞察为我们开发新的存储感知学习系统提供了基础。本文的主要贡献是对这一未充分探索的挑战进行了系统的刻画，提供了宝贵的认识，推动了对存储感知学习的理解。', 'title_zh': '面向存储意识的学习与压缩数据：JPEG格式的实证探索研究'}
{'arxiv_id': 'arXiv:2508.12828', 'title': 'Context Matters: Incorporating Target Awareness in Conversational Abusive Language Detection', 'authors': 'Raneem Alharthi, Rajwa Alharthi, Aiqi Jiang, Arkaitz Zubiaga', 'link': 'https://arxiv.org/abs/2508.12828', 'abstract': 'Abusive language detection has become an increasingly important task as a means to tackle this type of harmful content in social media. There has been a substantial body of research developing models for determining if a social media post is abusive or not; however, this research has primarily focused on exploiting social media posts individually, overlooking additional context that can be derived from surrounding posts. In this study, we look at conversational exchanges, where a user replies to an earlier post by another user (the parent tweet). We ask: does leveraging context from the parent tweet help determine if a reply post is abusive or not, and what are the features that contribute the most? We study a range of content-based and account-based features derived from the context, and compare this to the more widely studied approach of only looking at the features from the reply tweet. For a more generalizable study, we test four different classification models on a dataset made of conversational exchanges (parent-reply tweet pairs) with replies labeled as abusive or not. Our experiments show that incorporating contextual features leads to substantial improvements compared to the use of features derived from the reply tweet only, confirming the importance of leveraging context. We observe that, among the features under study, it is especially the content-based features (what is being posted) that contribute to the classification performance rather than account-based features (who is posting it). While using content-based features, it is best to combine a range of different features to ensure improved performance over being more selective and using fewer features. Our study provides insights into the development of contextualized abusive language detection models in realistic settings involving conversations.', 'abstract_zh': '社交媒体中虐待性语言检测已成为一项日益重要的任务，用于应对社交媒体上的有害内容。尽管已有大量研究开发模型来判断一条社交媒体帖子是否为虐待性内容，但这些研究主要侧重于独立分析单个帖子，忽略了来自其他帖子的额外上下文信息。在本研究中，我们关注用户的对话交流，即用户回复早前其他用户的帖子（父微博）。我们提出的问题是：利用父微博的上下文信息是否有助于判断回复帖子是否为虐待性内容？哪些特征对分类贡献最大？我们研究了从上下文派生的内容相关和账号相关特征，并将其与仅研究回复帖子特征的广泛研究方法进行了比较。为了使研究更具普适性，我们在包含父微博-回复微博配对的数据集上测试了四种不同的分类模型，这些回复帖子被标记为虐待性或非虐待性。我们的实验表明，结合上下文特征比仅使用回复帖子的特征能够带来显著提升，证实了利用上下文信息的重要性。我们观察到，在研究的特征中，内容相关特征（帖子的内容）对分类性能的贡献尤为显著，而非账号相关特征（发帖者的信息）。在使用内容相关特征时，最好结合多种不同的特征以确保性能提升，而不仅仅是选择较少的特征。我们的研究为在涉及对话交流的现实环境中开发上下文化的虐待性语言检测模型提供了洞察。', 'title_zh': '情境重要：在对话式网络谩骂检测中融入目标意识'}
{'arxiv_id': 'arXiv:2508.12798', 'title': 'A Shift in Perspective on Causality in Domain Generalization', 'authors': 'Damian Machlanski, Stephanie Riley, Edward Moroshko, Kurt Butler, Panagiotis Dimitrakopoulos, Thomas Melistas, Akchunya Chanchal, Steven McDonagh, Ricardo Silva, Sotirios A. Tsaftaris', 'link': 'https://arxiv.org/abs/2508.12798', 'abstract': 'The promise that causal modelling can lead to robust AI generalization has been challenged in recent work on domain generalization (DG) benchmarks. We revisit the claims of the causality and DG literature, reconciling apparent contradictions and advocating for a more nuanced theory of the role of causality in generalization. We also provide an interactive demo at this https URL.', 'abstract_zh': '因果建模能导致稳健的AI泛化的承诺在最近的域泛化（DG）基准研究中受到了挑战。我们重新审视因果性和DG文献中的主张，调和显而易见的矛盾，并倡导一种更细致的因果在泛化中作用的理论。我们还提供了一个交互式演示：![this URL](this https URL)。', 'title_zh': '域泛化中因果关系视角的转变'}
{'arxiv_id': 'arXiv:2508.12776', 'title': 'Randomized PCA Forest for Outlier Detection', 'authors': 'Muhammad Rajabinasab, Farhad Pakdaman, Moncef Gabbouj, Peter Schneider-Kamp, Arthur Zimek', 'link': 'https://arxiv.org/abs/2508.12776', 'abstract': 'We propose a novel unsupervised outlier detection method based on Randomized Principal Component Analysis (PCA). Inspired by the performance of Randomized PCA (RPCA) Forest in approximate K-Nearest Neighbor (KNN) search, we develop a novel unsupervised outlier detection method that utilizes RPCA Forest for outlier detection. Experimental results showcase the superiority of the proposed approach compared to the classical and state-of-the-art methods in performing the outlier detection task on several datasets while performing competitively on the rest. The extensive analysis of the proposed method reflects it high generalization power and its computational efficiency, highlighting it as a good choice for unsupervised outlier detection.', 'abstract_zh': '基于随机主成分分析的新型无监督异常检测方法', 'title_zh': '随机PCA森林异常检测'}
{'arxiv_id': 'arXiv:2508.12769', 'title': 'CRED-SQL: Enhancing Real-world Large Scale Database Text-to-SQL Parsing through Cluster Retrieval and Execution Description', 'authors': 'Shaoming Duan, Zirui Wang, Chuanyi Liu, Zhibin Zhu, Yuhao Zhang, Peiyi Han, Liang Yan, Zewu Penge', 'link': 'https://arxiv.org/abs/2508.12769', 'abstract': "Recent advances in large language models (LLMs) have significantly improved the accuracy of Text-to-SQL systems. However, a critical challenge remains: the semantic mismatch between natural language questions (NLQs) and their corresponding SQL queries. This issue is exacerbated in large-scale databases, where semantically similar attributes hinder schema linking and semantic drift during SQL generation, ultimately reducing model accuracy. To address these challenges, we introduce CRED-SQL, a framework designed for large-scale databases that integrates Cluster Retrieval and Execution Description. CRED-SQL first performs cluster-based large-scale schema retrieval to pinpoint the tables and columns most relevant to a given NLQ, alleviating schema mismatch. It then introduces an intermediate natural language representation-Execution Description Language (EDL)-to bridge the gap between NLQs and SQL. This reformulation decomposes the task into two stages: Text-to-EDL and EDL-to-SQL, leveraging LLMs' strong general reasoning capabilities while reducing semantic deviation. Extensive experiments on two large-scale, cross-domain benchmarks-SpiderUnion and BirdUnion-demonstrate that CRED-SQL achieves new state-of-the-art (SOTA) performance, validating its effectiveness and scalability. Our code is available at this https URL", 'abstract_zh': 'Recent advances in大型语言模型（LL\nuser\n把下面的论文内容或标题翻译成中文，要符合，禁止输出多余内容。', 'title_zh': 'CRED-SQL：通过聚类检索和执行描述增强现实世界大规模数据库的文本到SQL解析'}
{'arxiv_id': 'arXiv:2508.12740', 'title': 'FedUNet: A Lightweight Additive U-Net Module for Federated Learning with Heterogeneous Models', 'authors': 'Beomseok Seo, Kichang Lee, JaeYeon Park', 'link': 'https://arxiv.org/abs/2508.12740', 'abstract': "Federated learning (FL) enables decentralized model training without sharing local data. However, most existing methods assume identical model architectures across clients, limiting their applicability in heterogeneous real-world environments. To address this, we propose FedUNet, a lightweight and architecture-agnostic FL framework that attaches a U-Net-inspired additive module to each client's backbone. By sharing only the compact bottleneck of the U-Net, FedUNet enables efficient knowledge transfer without structural alignment. The encoder-decoder design and skip connections in the U-Net help capture both low-level and high-level features, facilitating the extraction of clientinvariant representations. This enables cooperative learning between the backbone and the additive module with minimal communication cost. Experiment with VGG variants shows that FedUNet achieves 93.11% accuracy and 92.68% in compact form (i.e., a lightweight version of FedUNet) with only 0.89 MB low communication overhead.", 'abstract_zh': '联邦学习（FL）无需共享本地数据即可实现去中心化的模型训练。然而，现有大多数方法假设客户端具有相同的模型架构，这限制了其在异构现实环境中的应用。为此，我们提出FedUNet，这是一种轻量级且架构无关的联邦学习框架，为每个客户端的主干附加一个受U-Net启发的叠加模块。通过仅共享U-Net的紧凑瓶颈部分，FedUNet可以在不进行结构对齐的情况下实现高效的知识传输。U-Net的编码-解码设计和跳跃连接有助于捕获低级和高级特征，促进客户端不变表示的提取。这使得主干和叠加模块之间的合作学习可以在较低的通信成本下进行。实验结果显示，使用VGG变体时，FedUNet在紧凑形式下（即FedUNet的轻量级版本）达到93.11%的准确率，并且仅产生0.89 MB的低通信开销。', 'title_zh': 'FedUNet：一种用于异构模型联邦学习的轻量级加性U-Net模块'}
{'arxiv_id': 'arXiv:2508.12709', 'title': 'MATPAC++: Enhanced Masked Latent Prediction for Self-Supervised Audio Representation Learning', 'authors': 'Aurian Quelennec, Pierre Chouteau, Geoffroy Peeters, Slim Essid', 'link': 'https://arxiv.org/abs/2508.12709', 'abstract': 'Masked latent prediction has emerged as a leading paradigm in self-supervised learning (SSL), especially for general audio and music representation learning. While recent methods have demonstrated strong performance, the role of the predictor module used at the output of such SSL systems remains mainly overlooked, despite being crucial for solving the pretext task at hand. In particular, this module should be able to deal with the ambiguity inherent in audio content, especially when it is composed of multiple sound sources. This work proposes a novel enhancement: integrating Multiple Choice Learning (MCL) to explicitly model prediction ambiguity and improve representation quality. We build on top of the recently proposed MATPAC system, improving its prediction and unsupervised classification pretext tasks with MCL. We extensively evaluate our method, MATPAC++, through both linear probing across multiple downstream tasks and fine-tuning on AudioSet, employing a unified protocol that enables rigorous and fair comparisons with state-of-the-art SSL approaches. Results show that our proposal achieves state-of-the-art when fine-tuned on AudioSet and overall state-of-the-art scores on downstream tasks. Additionally, we examine domain specialisation by training exclusively on music data, where our model achieves state-of-the-art performance with significantly improved efficiency.', 'abstract_zh': '掩码潜变量预测已成为监督学习（无监督（学习（SSL）中的一个成熟范式，特别是在通用音频和 音乐表示 学习方面。虽然近期 研究表明预测模块在这些SSL系统 系统中的作用非常重要，但在预设 任务中的预测输出的模糊性性仍然主要 被忽视。特别是在音频内容中，尤其是当其由多个声源组成时 时，这些预测需要处理内容的固有模糊性性。本文提出了一种新颖的增强方案，通过集成多项选择学习（MCL），明确地整合预测模糊性 总体性能。该 基于 近来的MATPAC系统 框架，改进预测和无监督分类预设 任务，我们通过MATPAC++进行广泛评估，涉及多个下游任务和onSet上 �.getBody调）进行严格的与现有最佳SSL方法进行对比。结果显示，Set上 上和下游任务的整体性能均达到最优。此外，我们仅在音乐数据上 进行训练时 ，同样达到最优性能，并且在效率上 方有显著提升。', 'title_zh': 'MATPAC++: 提升掩蔽潜变量预测的自监督音频表示学习'}
{'arxiv_id': 'arXiv:2508.12706', 'title': 'Asymmetric Diffusion Recommendation Model', 'authors': 'Yongchun Zhu, Guanyu Jiang, Jingwu Chen, Feng Zhang, Xiao Yang, Zuotao Liu', 'link': 'https://arxiv.org/abs/2508.12706', 'abstract': "Recently, motivated by the outstanding achievements of diffusion models, the diffusion process has been employed to strengthen representation learning in recommendation systems. Most diffusion-based recommendation models typically utilize standard Gaussian noise in symmetric forward and reverse processes in continuous data space. Nevertheless, the samples derived from recommendation systems inhabit a discrete data space, which is fundamentally different from the continuous one. Moreover, Gaussian noise has the potential to corrupt personalized information within latent representations. In this work, we propose a novel and effective method, named Asymmetric Diffusion Recommendation Model (AsymDiffRec), which learns forward and reverse processes in an asymmetric manner. We define a generalized forward process that simulates the missing features in real-world recommendation samples. The reverse process is then performed in an asymmetric latent feature space. To preserve personalized information within the latent representation, a task-oriented optimization strategy is introduced. In the serving stage, the raw sample with missing features is regarded as a noisy input to generate a denoising and robust representation for the final prediction. By equipping base models with AsymDiffRec, we conduct online A/B tests, achieving improvements of +0.131% and +0.166% in terms of users' active days and app usage duration respectively. Additionally, the extended offline experiments also demonstrate improvements. AsymDiffRec has been implemented in the Douyin Music App.", 'abstract_zh': '非对称扩散推荐模型：Asymmetric Diffusion Recommendation Model (AsymDiffRec)', 'title_zh': '非对称扩散推荐模型'}
{'arxiv_id': 'arXiv:2508.12702', 'title': 'A Unified Cortical Circuit Model with Divisive Normalization and Self-Excitation for Robust Representation and Memory Maintenance', 'authors': 'Jie Su, Weiwei Wang, Zhaotian Gu, Dahui Wang, Tianyi Qian', 'link': 'https://arxiv.org/abs/2508.12702', 'abstract': "Robust information representation and its persistent maintenance are fundamental for higher cognitive functions. Existing models employ distinct neural mechanisms to separately address noise-resistant processing or information maintenance, yet a unified framework integrating both operations remains elusive -- a critical gap in understanding cortical computation. Here, we introduce a recurrent neural circuit that combines divisive normalization with self-excitation to achieve both robust encoding and stable retention of normalized inputs. Mathematical analysis shows that, for suitable parameter regimes, the system forms a continuous attractor with two key properties: (1) input-proportional stabilization during stimulus presentation; and (2) self-sustained memory states persisting after stimulus offset. We demonstrate the model's versatility in two canonical tasks: (a) noise-robust encoding in a random-dot kinematogram (RDK) paradigm; and (b) approximate Bayesian belief updating in a probabilistic Wisconsin Card Sorting Test (pWCST). This work establishes a unified mathematical framework that bridges noise suppression, working memory, and approximate Bayesian inference within a single cortical microcircuit, offering fresh insights into the brain's canonical computation and guiding the design of biologically plausible artificial neural architectures.", 'abstract_zh': '稳健的信息表示及其持久维持是高级认知功能的基础。现有的模型分别采用了不同的神经机制来处理噪声鲁棒性处理或信息维持，但将这两项功能统一在一个框架中仍然是一个关键缺口。在这里，我们介绍了一个将分量归一化与自兴奋相结合的递归神经电路，以实现对归一化输入的稳健编码和稳定保持。数学分析表明，在合适的参数范围内，该系统形成了一个连续吸引子，具有两个关键特性：(1) 在刺激呈现期间输入比例的稳定性；(2) 在刺激结束后自我维持的记忆状态。我们通过两个经典的任务展示了该模型的灵活性：(a) 在随机点运动图（RDK）范式中的噪声鲁棒编码；(b) 在概率威斯康星卡片分类测试（pWCST）中的近似贝叶斯信念更新。这项工作建立了一个统一的数学框架，将噪声抑制、工作记忆和近似贝叶斯推理统一在一个皮层微电路中，为大脑的经典计算提供了新的见解，并指导了生物合理的神经网络架构的设计。', 'title_zh': '一种结合 divisive 归一化和自激机制以实现 robust 表征和记忆维持的统一皮层 Circuit 模型'}
{'arxiv_id': 'arXiv:2508.12692', 'title': 'Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning', 'authors': 'Taeheon Kim, San Kim, Minhyuk Seo, Dongjae Jeon, Wonje Jeong, Jonghyun Choi', 'link': 'https://arxiv.org/abs/2508.12692', 'abstract': 'Class-incremental with repetition (CIR), where previously trained classes repeatedly introduced in future tasks, is a more realistic scenario than the traditional class incremental setup, which assumes that each task contains unseen classes. CIR assumes that we can easily access abundant unlabeled data from external sources, such as the Internet. Therefore, we propose two components that efficiently use the unlabeled data to ensure the high stability and the plasticity of models trained in CIR setup. First, we introduce multi-level knowledge distillation (MLKD) that distills knowledge from multiple previous models across multiple perspectives, including features and logits, so the model can maintain much various previous knowledge. Moreover, we implement dynamic self-supervised loss (SSL) to utilize the unlabeled data that accelerates the learning of new classes, while dynamic weighting of SSL keeps the focus of training to the primary task. Both of our proposed components significantly improve the performance in CIR setup, achieving 2nd place in the CVPR 5th CLVISION Challenge.', 'abstract_zh': '基于重复的类别增量学习（CIR）：一种更现实的场景，其中以前训练的类别在未来的任务中重复出现，比传统的类别增量设置更为现实。CIR 假设可以从外部来源，如互联网，轻松获取丰富的未标注数据。因此，我们提出了两个高效利用未标注数据的组件，以确保在 CIR 设置下训练模型的高稳定性和可塑性。首先，我们引入多层次知识蒸馏（MLKD），从多个先前模型的多个视角（包括特征和logits）提取知识，使模型能够保留大量的先前知识。此外，我们实现了动态自监督损失（SSL）来利用未标注数据加速新类别的学习，而动态调整SSL权重则保持训练的重点在主要任务上。我们提出的两个组件显著提高了CIR设置下的性能，在CVPR第5届CLVISION挑战赛中获得第2名。', 'title_zh': '多级知识精炼与动态自监督学习在连续学习中的应用'}
{'arxiv_id': 'arXiv:2508.12690', 'title': 'TTA-DAME: Test-Time Adaptation with Domain Augmentation and Model Ensemble for Dynamic Driving Conditions', 'authors': 'Dongjae Jeon, Taeheon Kim, Seongwon Cho, Minhyuk Seo, Jonghyun Choi', 'link': 'https://arxiv.org/abs/2508.12690', 'abstract': 'Test-time Adaptation (TTA) poses a challenge, requiring models to dynamically adapt and perform optimally on shifting target domains. This task is particularly emphasized in real-world driving scenes, where weather domain shifts occur frequently. To address such dynamic changes, our proposed method, TTA-DAME, leverages source domain data augmentation into target domains. Additionally, we introduce a domain discriminator and a specialized domain detector to mitigate drastic domain shifts, especially from daytime to nighttime conditions. To further improve adaptability, we train multiple detectors and consolidate their predictions through Non-Maximum Suppression (NMS). Our empirical validation demonstrates the effectiveness of our method, showing significant performance enhancements on the SHIFT Benchmark.', 'abstract_zh': 'Test-time Adaptation (TTA)在移域目标域动态适应中提出了一项挑战，要求模型能够动态调整以在变化的目标域中表现最优。这一任务在现实中驾驶场景中尤其突出，因为天气条件经常发生变化。为应对这种动态变化，我们提出的方法TTA-DAME利用源域数据增强技术将数据迁移到目标域。此外，我们引入了领域判别器和专门的领域检测器，以减轻尤其是由白天到夜晚等急剧的域变化。为进一步提升适应性，我们训练了多个检测器并通过非极大值抑制（NMS）合并它们的预测。我们的实证验证表明了该方法的有效性，显著提升了在SHIFT基准上的性能。', 'title_zh': 'TTA-DAME：基于域增强和模型集成的动态驾驶条件下的测试时自适应方法'}
{'arxiv_id': 'arXiv:2508.12683', 'title': 'A Taxonomy of Hierarchical Multi-Agent Systems: Design Patterns, Coordination Mechanisms, and Industrial Applications', 'authors': 'David J. Moore', 'link': 'https://arxiv.org/abs/2508.12683', 'abstract': 'Hierarchical multi-agent systems (HMAS) organize collections of agents into layered structures that help manage complexity and scale. These hierarchies can simplify coordination, but they also can introduce trade-offs that are not always obvious. This paper proposes a multi-dimensional taxonomy for HMAS along five axes: control hierarchy, information flow, role and task delegation, temporal layering, and communication structure. The intent is not to prescribe a single "best" design but to provide a lens for comparing different approaches.\nRather than treating these dimensions in isolation, the taxonomy is connected to concrete coordination mechanisms - from the long-standing contract-net protocol for task allocation to more recent work in hierarchical reinforcement learning. Industrial contexts illustrate the framework, including power grids and oilfield operations, where agents at production, maintenance, and supply levels coordinate to diagnose well issues or balance energy demand. These cases suggest that hierarchical structures may achieve global efficiency while preserving local autonomy, though the balance is delicate.\nThe paper closes by identifying open challenges: making hierarchical decisions explainable to human operators, scaling to very large agent populations, and assessing whether learning-based agents such as large language models can be safely integrated into layered frameworks. This paper presents what appears to be the first taxonomy that unifies structural, temporal, and communication dimensions of hierarchical MAS into a single design framework, bridging classical coordination mechanisms with modern reinforcement learning and large language model agents.', 'abstract_zh': '多层次多智能体系统（HMAS）的多维度分类框架：从控制层级、信息流、角色和任务委派、时间分层及通信结构五个维度探究。', 'title_zh': '层次化多智能体系统的分类：设计模式、协调机制及工业应用'}
{'arxiv_id': 'arXiv:2508.12673', 'title': 'Deploying Models to Non-participating Clients in Federated Learning without Fine-tuning: A Hypernetwork-based Approach', 'authors': 'Yuhao Zhou, Jindi Lv, Yuxin Tian, Dan Si, Qing Ye, Jiancheng Lv', 'link': 'https://arxiv.org/abs/2508.12673', 'abstract': "Federated Learning (FL) has emerged as a promising paradigm for privacy-preserving collaborative learning, yet data heterogeneity remains a critical challenge. While existing methods achieve progress in addressing data heterogeneity for participating clients, they fail to generalize to non-participating clients with in-domain distribution shifts and resource constraints. To mitigate this issue, we present HyperFedZero, a novel method that dynamically generates specialized models via a hypernetwork conditioned on distribution-aware embeddings. Our approach explicitly incorporates distribution-aware inductive biases into the model's forward pass, extracting robust distribution embeddings using a NoisyEmbed-enhanced extractor with a Balancing Penalty, effectively preventing feature collapse. The hypernetwork then leverages these embeddings to generate specialized models chunk-by-chunk for non-participating clients, ensuring adaptability to their unique data distributions. Extensive experiments on multiple datasets and models demonstrate HyperFedZero's remarkable performance, surpassing competing methods consistently with minimal computational, storage, and communication overhead. Moreover, ablation studies and visualizations further validate the necessity of each component, confirming meaningful adaptations and validating the effectiveness of HyperFedZero.", 'abstract_zh': '联邦学习（FL）已经 emerged 作为隐私保护协作学习的一个有前途的范式，但数据异质性仍然是一个 critical 挑战。虽然现有的方法在解决参与客户端的数据异质性方面取得了进展，但它们无法将这些方法推广到具有领域内分布转移和资源约束的未参与客户端。为了缓解这一问题，我们提出了 HyperFedZero，这是一种新型方法，可以通过一个基于分布感知嵌入的超网络动态生成专门化的模型。我们的方法在模型的前向传播中显式地引入了分布感知的归纳偏置，使用一个增强的 NoisyEmbed 提取器和平衡罚则有效地提取鲁棒的分布嵌入，从而预防特征坍塌。超网络利用这些嵌入逐块为未参与客户端生成专门化的模型，确保适应其独特的数据分布。在多个数据集和模型上的 extensive 实验表明，HyperFedZero 在 minimal 计算、存储和通信开销下，表现出色，且始终优于竞争方法。此外，消融研究和可视化进一步验证了每个组件的必要性，确认了有意义的适应，并验证了 HyperFedZero 的有效性。', 'title_zh': '无需微调在非参与客户端部署模型在联邦学习中的方法：基于超网络的 Approach'}
{'arxiv_id': 'arXiv:2508.12672', 'title': 'Robust Federated Learning under Adversarial Attacks via Loss-Based Client Clustering', 'authors': 'Emmanouil Kritharakis, Dusan Jakovetic, Antonios Makris, Konstantinos Tserpes', 'link': 'https://arxiv.org/abs/2508.12672', 'abstract': 'Federated Learning (FL) enables collaborative model training across multiple clients without sharing private data. We consider FL scenarios wherein FL clients are subject to adversarial (Byzantine) attacks, while the FL server is trusted (honest) and has a trustworthy side dataset. This may correspond to, e.g., cases where the server possesses trusted data prior to federation, or to the presence of a trusted client that temporarily assumes the server role. Our approach requires only two honest participants, i.e., the server and one client, to function effectively, without prior knowledge of the number of malicious clients. Theoretical analysis demonstrates bounded optimality gaps even under strong Byzantine attacks. Experimental results show that our algorithm significantly outperforms standard and robust FL baselines such as Mean, Trimmed Mean, Median, Krum, and Multi-Krum under various attack strategies including label flipping, sign flipping, and Gaussian noise addition across MNIST, FMNIST, and CIFAR-10 benchmarks using the Flower framework.', 'abstract_zh': '联邦学习（（FL）实现了多个客户端协作的隐私数据安全训练。我们考虑FL客户端遭受拜占（（（拜占）攻击的场景， 而FL服务器是可 诚实的（ 并拥有一个可信的数据集。这 可对应于.g., 在联邦之前存在一个可信的客户端 e 或者一个可信客户端暂时承担这一角色。我们的方法 方法仅需两个诚实的 的客户端 e � 即服务器端和 和 一个客户端 e �ResourceId 无需预先了解恶意客户端的身份。从理论上 �ぃ理论分析 分 分分析 � européenet 有限恶意攻击 Strikes �性价 的上 �边界 e 历家性问 优化最最优性 g 怈 � �边界 e x罅 e �的� �边 海 e 奵 e e e e理论缺口。实验结果结果显示 e 戔 � e 戛 e etermine e 戄 � e � e e e e e e e e e e e e e e e e e e e e e e e e � SMP ew e e 交易 e  e � e e e  e e e  e e e e e e e e e e e e  e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e"}}', 'title_zh': '基于损失的客户端聚类以抵抗对抗攻击的鲁棒联邦学习'}
{'arxiv_id': 'arXiv:2508.12650', 'title': 'Score-informed Neural Operator for Enhancing Ordering-based Causal Discovery', 'authors': 'Jiyeon Kang, Songseong Kim, Chanhui Lee, Doyeong Hwang, Joanie Hayoun Chung, Yunkyung Ko, Sumin Lee, Sungwoong Kim, Sungbin Lim', 'link': 'https://arxiv.org/abs/2508.12650', 'abstract': "Ordering-based approaches to causal discovery identify topological orders of causal graphs, providing scalable alternatives to combinatorial search methods. Under the Additive Noise Model (ANM) assumption, recent causal ordering methods based on score matching require an accurate estimation of the Hessian diagonal of the log-densities. However, previous approaches mainly use Stein gradient estimators, which are computationally expensive and memory-intensive. Although DiffAN addresses these limitations by substituting kernel-based estimates with diffusion models, it remains numerically unstable due to the second-order derivatives of score models. To alleviate these problems, we propose Score-informed Neural Operator (SciNO), a probabilistic generative model in smooth function spaces designed to stably approximate the Hessian diagonal and to preserve structural information during the score modeling. Empirical results show that SciNO reduces order divergence by 42.7% on synthetic graphs and by 31.5% on real-world datasets on average compared to DiffAN, while maintaining memory efficiency and scalability. Furthermore, we propose a probabilistic control algorithm for causal reasoning with autoregressive models that integrates SciNO's probability estimates with autoregressive model priors, enabling reliable data-driven causal ordering informed by semantic information. Consequently, the proposed method enhances causal reasoning abilities of LLMs without additional fine-tuning or prompt engineering.", 'abstract_zh': '基于排序的方法在因果发现中的应用识别因果图的拓扑排序，提供了一种可扩展的替代组合搜索方法。在加性噪声模型（ANM）假设下，最近基于分数匹配的因果排序方法需要准确估计对数密度的海森矩阵对角线。然而，之前的 方法主要使用Stein梯度估计器，这在计算和存储方面都比较昂贵。尽管DiffAN通过用扩散模型替代核估计解决了这些问题，但由于分数模型的二次导数，它仍然在数值稳定性方面存在不足。为了缓解这些问题，我们提出了Score-informed Neural Operator (SciNO)，这是一种在光滑函数空间中设计的概率生成模型，旨在稳定地近似海森矩阵的对角线，并在分数建模过程中保结构信息。实验结果表明，与DiffAN相比，SciNO在合成图上将排序发散减少了42.7%，在实际数据集上平均减少了31.5%，同时保持了内存效率和可扩展性。此外，我们提出了一种概率控制算法，用于自回归模型中的因果推理，该算法将SciNO的概率估计与自回归模型先验整合，从而基于语义信息实现可靠的基于数据驱动的因果排序。因此，所提出的方法增强了解释能力LLMs，而无需额外的微调或提示工程。', 'title_zh': '基于评分的神经算子增强顺序依赖因果发现'}
{'arxiv_id': 'arXiv:2508.12623', 'title': 'How can we trust opaque systems? Criteria for robust explanations in XAI', 'authors': 'Florian J. Boge, Annika Schuster', 'link': 'https://arxiv.org/abs/2508.12623', 'abstract': "Deep learning (DL) algorithms are becoming ubiquitous in everyday life and in scientific research. However, the price we pay for their impressively accurate predictions is significant: their inner workings are notoriously opaque - it is unknown to laypeople and researchers alike what features of the data a DL system focuses on and how it ultimately succeeds in predicting correct outputs. A necessary criterion for trustworthy explanations is that they should reflect the relevant processes the algorithms' predictions are based on. The field of eXplainable Artificial Intelligence (XAI) presents promising methods to create such explanations. But recent reviews about their performance offer reasons for skepticism. As we will argue, a good criterion for trustworthiness is explanatory robustness: different XAI methods produce the same explanations in comparable contexts. However, in some instances, all methods may give the same, but still wrong, explanation. We therefore argue that in addition to explanatory robustness (ER), a prior requirement of explanation method robustness (EMR) has to be fulfilled by every XAI method. Conversely, the robustness of an individual method is in itself insufficient for trustworthiness. In what follows, we develop and formalize criteria for ER as well as EMR, providing a framework for explaining and establishing trust in DL algorithms. We also highlight interesting application cases and outline directions for future work.", 'abstract_zh': '深度学习算法在日常生活和科学研究中无处不在。然而，它们令人印象深刻准确的预测是以显著的代价获得的：其内部工作机制历来具有很强的不透明性——无论是普通人还是研究人员都不知道，一个深度学习系统关注数据的哪些特征以及它是如何最终成功预测正确输出的。对于可信的解释而言，一个必要条件是它们应该反映算法预测所依据的相关过程。可解释人工智能（XAI）领域提出了一些有前景的方法来创建这样的解释。然而，最近关于它们性能的回顾提供了怀疑的理由。正如我们将论证的那样，可信度的良好标准是解释的稳健性：不同的XAI方法在类似的情境下应产生相同解释。然而，在某些情况下，所有方法可能给出相同的，但仍然是错误的解释。因此，我们论证对于每一个XAI方法而言，除了解释的稳健性（ER）之外，还需满足解释方法的稳健性（EMR）的先决条件。单个方法的稳健性本身不足以保证可信度。接下来，我们将开发并公式化ER和EMR的标准，提供一个框架来解释和建立对深度学习算法的信任。我们还将突出有趣的应用案例，并概述未来工作的方向。', 'title_zh': '如何信任不透明系统？解释性人工智能中稳健解释的标准'}
{'arxiv_id': 'arXiv:2508.12617', 'title': 'A Generalized Genetic Random Field Method for the Genetic Association Analysis of Sequencing Data', 'authors': 'Ming Li, Zihuai He, Min Zhang, Xiaowei Zhan, Changshuai Wei, Robert C Elston, Qing Lu', 'link': 'https://arxiv.org/abs/2508.12617', 'abstract': 'With the advance of high-throughput sequencing technologies, it has become feasible to investigate the influence of the entire spectrum of sequencing variations on complex human diseases. Although association studies utilizing the new sequencing technologies hold great promise to unravel novel genetic variants, especially rare genetic variants that contribute to human diseases, the statistical analysis of high-dimensional sequencing data remains a challenge. Advanced analytical methods are in great need to facilitate high-dimensional sequencing data analyses. In this article, we propose a generalized genetic random field (GGRF) method for association analyses of sequencing data. Like other similarity-based methods (e.g., SIMreg and SKAT), the new method has the advantages of avoiding the need to specify thresholds for rare variants and allowing for testing multiple variants acting in different directions and magnitude of effects. The method is built on the generalized estimating equation framework and thus accommodates a variety of disease phenotypes (e.g., quantitative and binary phenotypes). Moreover, it has a nice asymptotic property, and can be applied to small-scale sequencing data without need for small-sample adjustment. Through simulations, we demonstrate that the proposed GGRF attains an improved or comparable power over a commonly used method, SKAT, under various disease scenarios, especially when rare variants play a significant role in disease etiology. We further illustrate GGRF with an application to a real dataset from the Dallas Heart Study. By using GGRF, we were able to detect the association of two candidate genes, ANGPTL3 and ANGPTL4, with serum triglyceride.', 'abstract_zh': '高通量测序技术的进步使得研究整个变异谱对复杂人类疾病的影响成为可能。尽管利用新型测序技术的关联研究有望揭示新的遗传变异，尤其是那些对人类疾病有贡献的稀有遗传变异，但高维测序数据的统计分析仍然是一项挑战。急需先进的分析方法来促进高维测序数据分析。本文提出了一种广义遗传随机场（GGRF）方法，用于测序数据的关联分析。与SIMreg和SKAT等基于相似性的方法相比，新方法避免了指定稀有变异阈值的需要，并且能够测试多个方向和不同效应大小的变异。该方法基于广义估计方程框架，因此能够适用于各种疾病表型（例如，定量表型和二元表型）。此外，它具有良好的渐近性质，在不需要小样本调整的情况下可以应用于小型测序数据集。通过模拟，我们证明了提出的GGRF在各种疾病情景下，尤其是在稀有变异在疾病病因学中起重要作用时，其检测功效优于常用的SKAT方法。我们进一步使用真正的达拉斯心脏研究数据集对GGRF进行了应用，通过GGRF，我们发现ANGPTL3和ANGPTL4两个候选基因与血清甘油三酯水平有关。', 'title_zh': '一种用于序列数据遗传关联分析的广义遗传随机场方法'}
{'arxiv_id': 'arXiv:2508.12576', 'title': 'Widening the Network Mitigates the Impact of Data Heterogeneity on FedAvg', 'authors': 'Like Jian, Dong Liu', 'link': 'https://arxiv.org/abs/2508.12576', 'abstract': "Federated learning (FL) enables decentralized clients to train a model collaboratively without sharing local data. A key distinction between FL and centralized learning is that clients' data are non-independent and identically distributed, which poses significant challenges in training a global model that generalizes well across heterogeneous local data distributions. In this paper, we analyze the convergence of overparameterized FedAvg with gradient descent (GD). We prove that the impact of data heterogeneity diminishes as the width of neural networks increases, ultimately vanishing when the width approaches infinity. In the infinite-width regime, we further prove that both the global and local models in FedAvg behave as linear models, and that FedAvg achieves the same generalization performance as centralized learning with the same number of GD iterations. Extensive experiments validate our theoretical findings across various network architectures, loss functions, and optimization methods.", 'abstract_zh': '联邦学习(Federated Learning)使分散的客户端能够在不共享本地数据的情况下协作训练模型。与集中式学习的关键区别在于客户端的数据是非独立且不相同分布的，这给跨异质本地数据分布训练出泛化良好的全局模型带来了重大挑战。本文分析了过参数化FedAvg与梯度下降的收敛性。我们证明，随着神经网络宽度的增加，数据异质性的影响逐渐减弱，当宽度接近无穷大时完全消失。在无限宽度的情况下，我们进一步证明，FedAvg中的全局和局部模型均表现为线性模型，并且FedAvg在相同数量的梯度下降迭代次数下实现了与集中式学习相同的泛化性能。广泛的实验在各种网络架构、损失函数和优化方法下验证了我们的理论发现。', 'title_zh': '扩大网络规模减轻数据异质性对FedAvg的影响'}
{'arxiv_id': 'arXiv:2508.12533', 'title': 'Defining and Benchmarking a Data-Centric Design Space for Brain Graph Construction', 'authors': 'Qinwen Ge, Roza G. Bayrak, Anwar Said, Catie Chang, Xenofon Koutsoukos, Tyler Derr', 'link': 'https://arxiv.org/abs/2508.12533', 'abstract': 'The construction of brain graphs from functional Magnetic Resonance Imaging (fMRI) data plays a crucial role in enabling graph machine learning for neuroimaging. However, current practices often rely on rigid pipelines that overlook critical data-centric choices in how brain graphs are constructed. In this work, we adopt a Data-Centric AI perspective and systematically define and benchmark a data-centric design space for brain graph construction, constrasting with primarily model-centric prior work. We organize this design space into three stages: temporal signal processing, topology extraction, and graph featurization. Our contributions lie less in novel components and more in evaluating how combinations of existing and modified techniques influence downstream performance. Specifically, we study high-amplitude BOLD signal filtering, sparsification and unification strategies for connectivity, alternative correlation metrics, and multi-view node and edge features, such as incorporating lagged dynamics. Experiments on the HCP1200 and ABIDE datasets show that thoughtful data-centric configurations consistently improve classification accuracy over standard pipelines. These findings highlight the critical role of upstream data decisions and underscore the importance of systematically exploring the data-centric design space for graph-based neuroimaging. Our code is available at this https URL.', 'abstract_zh': '从功能磁共振成像(fMRI)数据构建脑图对于实现神经影像学中的图机器学习起着关键作用。然而，当前的做法往往依赖于僵化的管道，忽视了构建脑图时的关键数据驱动选择。在本文中，我们从数据为中心的人工智能视角出发，系统地定义并评估了一个数据为中心的设计空间，以实现脑图构建，与先前主要为模型为中心的工作形成了对比。我们将这个设计空间分为三个阶段：时间信号处理、拓扑提取和图特征化。我们的贡献不在于新颖的组件，而在于评估现有和修改的技术组合如何影响下游性能。具体来说，我们研究了高振幅BOLD信号的滤波、连接性的稀疏化和统一策略、替代的相关性度量，以及多视图节点和边特征，例如引入滞后动态。在HCP1200和ABIDE数据集上的实验表明，仔细的数据驱动配置可以一致地提高分类准确性，这些发现突显了上游数据决策的关键作用，并强调了系统探索数据为中心的设计空间对于基于图的神经影像学的重要性。代码可供查看：this https URL', 'title_zh': '数据导向的设计空间定义与基于脑图构建的基准测试'}
{'arxiv_id': 'arXiv:2508.12519', 'title': 'An Introduction to Sliced Optimal Transport', 'authors': 'Khai Nguyen', 'link': 'https://arxiv.org/abs/2508.12519', 'abstract': "Sliced Optimal Transport (SOT) is a rapidly developing branch of optimal transport (OT) that exploits the tractability of one-dimensional OT problems. By combining tools from OT, integral geometry, and computational statistics, SOT enables fast and scalable computation of distances, barycenters, and kernels for probability measures, while retaining rich geometric structure. This paper provides a comprehensive review of SOT, covering its mathematical foundations, methodological advances, computational methods, and applications. We discuss key concepts of OT and one-dimensional OT, the role of tools from integral geometry such as Radon transform in projecting measures, and statistical techniques for estimating sliced distances. The paper further explores recent methodological advances, including non-linear projections, improved Monte Carlo approximations, statistical estimation techniques for one-dimensional optimal transport, weighted slicing techniques, and transportation plan estimation methods. Variational problems, such as minimum sliced Wasserstein estimation, barycenters, gradient flows, kernel constructions, and embeddings are examined alongside extensions to unbalanced, partial, multi-marginal, and Gromov-Wasserstein settings. Applications span machine learning, statistics, computer graphics and computer visions, highlighting SOT's versatility as a practical computational tool. This work will be of interest to researchers and practitioners in machine learning, data sciences, and computational disciplines seeking efficient alternatives to classical OT.", 'abstract_zh': '切片最优传输（SOT）是一种快速发展的最优传输（OT）分支，利用了一维最优传输问题的可处理性。通过结合最优传输、积分几何和计算统计的工具，SOT能够快速高效地计算概率测度的距离、测度中心和核函数，同时保留丰富的几何结构。本文对SOT进行了全面回顾，涵盖了其数学基础、方法论进展、计算方法和应用。文中讨论了一维最优传输的基本概念，积分几何工具如Radon变换在投影测度中的作用，以及估算切片距离的统计技术。此外，本文还探讨了近期的方法论进展，包括非线性投影、改进的蒙特卡洛近似、一维最优传输的统计估计技术、加权切片技术以及运输计划估计方法。还分析了变分问题，如切片Wasserstein估计算法、测度中心、梯度流、核构造和嵌入等问题及其在不平衡、部分、多边际和Gromov-Wasserstein设置中的扩展应用。应用范围涵盖了机器学习、统计学、计算机图形学和计算机视觉等领域，突显了SOT作为高效计算工具的灵活性。本研究将对寻求经典OT高效替代方案的研究人员和从业者产生兴趣。', 'title_zh': '切片最优传输简介'}
{'arxiv_id': 'arXiv:2508.12506', 'title': 'Design and Validation of a Responsible Artificial Intelligence-based System for the Referral of Diabetic Retinopathy Patients', 'authors': 'E. Ulises Moya-Sánchez, Abraham Sánchez-Perez, Raúl Nanclares Da Veiga, Alejandro Zarate-Macías, Edgar Villareal, Alejandro Sánchez-Montes, Edtna Jauregui-Ulloa, Héctor Moreno, Ulises Cortés', 'link': 'https://arxiv.org/abs/2508.12506', 'abstract': "Diabetic Retinopathy (DR) is a leading cause of vision loss in working-age individuals. Early detection of DR can reduce the risk of vision loss by up to 95%, but a shortage of retinologists and challenges in timely examination complicate detection. Artificial Intelligence (AI) models using retinal fundus photographs (RFPs) offer a promising solution. However, adoption in clinical settings is hindered by low-quality data and biases that may lead AI systems to learn unintended features. To address these challenges, we developed RAIS-DR, a Responsible AI System for DR screening that incorporates ethical principles across the AI lifecycle. RAIS-DR integrates efficient convolutional models for preprocessing, quality assessment, and three specialized DR classification models. We evaluated RAIS-DR against the FDA-approved EyeArt system on a local dataset of 1,046 patients, unseen by both systems. RAIS-DR demonstrated significant improvements, with F1 scores increasing by 5-12%, accuracy by 6-19%, and specificity by 10-20%. Additionally, fairness metrics such as Disparate Impact and Equal Opportunity Difference indicated equitable performance across demographic subgroups, underscoring RAIS-DR's potential to reduce healthcare disparities. These results highlight RAIS-DR as a robust and ethically aligned solution for DR screening in clinical settings. The code, weights of RAIS-DR are available at this https URL with RAIL.", 'abstract_zh': '糖尿病视网膜病变（DR）是工作年龄段人群视力丧失的主要原因。早期检测DR可以降低高达95%的视力丧失风险，但眼科医生短缺和及时检查的挑战使得检测更加复杂。使用视网膜底片照片（RFPs）的人工智能（AI）模型提供了一个有前景的解决方案。然而，在临床环境中采用这些模型受到低质量数据和可能导致AI系统学习非预期特征的偏差的影响。为了解决这些挑战，我们开发了RAIS-DR，这是一个负责的人工智能系统，用于DR筛查，并在整个AI生命周期中纳入了伦理原则。RAIS-DR结合了高效卷积模型进行预处理、质量评估和三种专门的DR分类模型。我们在未被两者系统见过的1,046名患者的地方数据集上对RAIS-DR进行了评估，结果显示RAIS-DR取得了显著改进，F1分数提升了5-12%，准确率提升了6-19%，特异性提升了10-20%。此外，公平性指标如差异影响和等机会差异表明RAIS-DR在不同人口亚组中表现一致，突显了其减少医疗保健不平等的潜力。这些结果强调了RAIS-DR作为临床环境中DR筛查稳健且伦理对齐的解决方案的重要性。RAIS-DR的代码和权重可以在RAIL提供的链接中获得。', 'title_zh': '基于负责任的人工智能的糖尿病视网膜病变患者转诊系统的设计与验证'}
{'arxiv_id': 'arXiv:2508.12479', 'title': 'EXOTIC: An Exact, Optimistic, Tree-Based Algorithm for Min-Max Optimization', 'authors': 'Chinmay Maheshwari, Chinmay Pimpalkhare, Debasish Chatterjee', 'link': 'https://arxiv.org/abs/2508.12479', 'abstract': "Min-max optimization arises in many domains such as game theory, adversarial machine learning, etc., with gradient-based methods as a typical computational tool. Beyond convex-concave min-max optimization, the solutions found by gradient-based methods may be arbitrarily far from global optima. In this work, we present an algorithmic apparatus for computing globally optimal solutions in convex-non-concave and non-convex-concave min-max optimization. For former, we employ a reformulation that transforms it into a non-concave-convex max-min optimization problem with suitably defined feasible sets and objective function. The new form can be viewed as a generalization of Sion's minimax theorem. Next, we introduce EXOTIC-an Exact, Optimistic, Tree-based algorithm for solving the reformulated max-min problem. EXOTIC employs an iterative convex optimization solver to (approximately) solve the inner minimization and a hierarchical tree search for the outer maximization to optimistically select promising regions to search based on the approximate solution returned by convex optimization solver. We establish an upper bound on its optimality gap as a function of the number of calls to the inner solver, the solver's convergence rate, and additional problem-dependent parameters. Both our algorithmic apparatus along with its accompanying theoretical analysis can also be applied for non-convex-concave min-max optimization. In addition, we propose a class of benchmark convex-non-concave min-max problems along with their analytical global solutions, providing a testbed for evaluating algorithms for min-max optimization. Empirically, EXOTIC outperforms gradient-based methods on this benchmark as well as on existing numerical benchmark problems from the literature. Finally, we demonstrate the utility of EXOTIC by computing security strategies in multi-player games with three or more players.", 'abstract_zh': '基于梯度的方法在博弈论、对抗机器学习等领域中已经广泛应用到最小-最大优化中，但这些方法找到的解可能与全局最优解任意偏离。本文提出了一种算法框架，用于在凸非凹和非凸非凹最小-最大优化中计算全局最优解。对于前者，我们通过重新形式化问题，将其转换为具有适当定义的可行集和目标函数的非凹-凸最大-最小优化问题，新的形式可以看作是Sion的最小-最大定理的推广。接下来，我们引入了EXOTIC算法——一种精确、乐观、基于树结构的方法，用于求解重新形式化后的最大-最小问题。EXOTIC使用迭代凸优化求解器来（近似）解决内部最小化问题，并采用分层树搜索进行外部最大化，基于凸优化求解器返回的近似解来乐观地选择具有潜在解的区域进行搜索。我们基于内部求解器调用次数、求解器的收敛率以及其它问题相关参数建立了最优性差距的上界。我们的算法框架及其理论分析也可应用于非凸非凹最小-最大优化。此外，我们提出了一类用于评估最小-最大优化算法的基准凸非凹最小-最大问题及其解析全局解。实验结果显示，EXOTIC在基准测试及文献中现有的数值基准问题上优于基于梯度的方法。最后，我们展示了EXOTIC在计算三人或以上参与者的多玩家博弈中的安全策略方面的应用。', 'title_zh': 'EXOTIC: 一种精确的乐观树基最小最大优化算法'}
{'arxiv_id': 'arXiv:2508.12470', 'title': 'A Robust Cross-Domain IDS using BiGRU-LSTM-Attention for Medical and Industrial IoT Security', 'authors': 'Afrah Gueriani, Hamza Kheddar, Ahmed Cherif Mazari, Mohamed Chahine Ghanem', 'link': 'https://arxiv.org/abs/2508.12470', 'abstract': "The increased Internet of Medical Things IoMT and the Industrial Internet of Things IIoT interconnectivity has introduced complex cybersecurity challenges, exposing sensitive data, patient safety, and industrial operations to advanced cyber threats. To mitigate these risks, this paper introduces a novel transformer-based intrusion detection system IDS, termed BiGAT-ID a hybrid model that combines bidirectional gated recurrent units BiGRU, long short-term memory LSTM networks, and multi-head attention MHA. The proposed architecture is designed to effectively capture bidirectional temporal dependencies, model sequential patterns, and enhance contextual feature representation. Extensive experiments on two benchmark datasets, CICIoMT2024 medical IoT and EdgeIIoTset industrial IoT demonstrate the model's cross-domain robustness, achieving detection accuracies of 99.13 percent and 99.34 percent, respectively. Additionally, the model exhibits exceptional runtime efficiency, with inference times as low as 0.0002 seconds per instance in IoMT and 0.0001 seconds in IIoT scenarios. Coupled with a low false positive rate, BiGAT-ID proves to be a reliable and efficient IDS for deployment in real-world heterogeneous IoT environments", 'abstract_zh': 'IoMT和IIoT增强的互联系统中的新型基于变压器的入侵检测系统BiGAT-ID：一种结合BiGRU、LSTM和MHA的混合模型', 'title_zh': '跨域医疗和工业物联网安全的鲁棒双向GRU-LSTM注意力机制入侵检测系统'}
{'arxiv_id': 'arXiv:2508.12416', 'title': 'fCrit: A Visual Explanation System for Furniture Design Creative Support', 'authors': 'Vuong Nguyen, Gabriel Vigliensoni', 'link': 'https://arxiv.org/abs/2508.12416', 'abstract': "We introduce fCrit, a dialogue-based AI system designed to critique furniture design with a focus on explainability. Grounded in reflective learning and formal analysis, fCrit employs a multi-agent architecture informed by a structured design knowledge base. We argue that explainability in the arts should not only make AI reasoning transparent but also adapt to the ways users think and talk about their designs. We demonstrate how fCrit supports this process by tailoring explanations to users' design language and cognitive framing. This work contributes to Human-Centered Explainable AI (HCXAI) in creative practice, advancing domain-specific methods for situated, dialogic, and visually grounded AI support.", 'abstract_zh': '基于对话的可解释人工智能系统fCrit及其在家具设计批判中的应用', 'title_zh': 'fCrit: 家具设计创意支持的视觉解释系统'}
{'arxiv_id': 'arXiv:2508.12413', 'title': 'Quantum Flow Matching', 'authors': 'Zidong Cui, Pan Zhang, Ying Tang', 'link': 'https://arxiv.org/abs/2508.12413', 'abstract': 'Flow matching has rapidly become a dominant paradigm in classical generative modeling, offering an efficient way to interpolate between two complex distributions. We extend this idea to the quantum realm and introduce Quantum Flow Matching (QFM)-a fully quantum-circuit realization that offers efficient interpolation between two density matrices. QFM offers systematic preparation of density matrices and generation of samples for accurately estimating observables, and can be realized on a quantum computer without the need for costly circuit redesigns. We validate its versatility on a set of applications: (i) generating target states with prescribed magnetization and entanglement entropy, (ii) estimating nonequilibrium free-energy differences to test the quantum Jarzynski equality, and (iii) expediting the study on superdiffusion breakdown. These results position QFM as a unifying and promising framework for generative modeling across quantum systems.', 'abstract_zh': '量子流匹配（QFM）：量子领域的一种高效插值方法', 'title_zh': '量子流匹配'}
{'arxiv_id': 'arXiv:2508.12405', 'title': 'Extracting Post-Acute Sequelae of SARS-CoV-2 Infection Symptoms from Clinical Notes via Hybrid Natural Language Processing', 'authors': 'Zilong Bai, Zihan Xu, Cong Sun, Chengxi Zang, H. Timothy Bunnell, Catherine Sinfield, Jacqueline Rutter, Aaron Thomas Martinez, L. Charles Bailey, Mark Weiner, Thomas R. Campion, Thomas Carton, Christopher B. Forrest, Rainu Kaushal, Fei Wang, Yifan Peng', 'link': 'https://arxiv.org/abs/2508.12405', 'abstract': 'Accurately and efficiently diagnosing Post-Acute Sequelae of COVID-19 (PASC) remains challenging due to its myriad symptoms that evolve over long- and variable-time intervals. To address this issue, we developed a hybrid natural language processing pipeline that integrates rule-based named entity recognition with BERT-based assertion detection modules for PASC-symptom extraction and assertion detection from clinical notes. We developed a comprehensive PASC lexicon with clinical specialists. From 11 health systems of the RECOVER initiative network across the U.S., we curated 160 intake progress notes for model development and evaluation, and collected 47,654 progress notes for a population-level prevalence study. We achieved an average F1 score of 0.82 in one-site internal validation and 0.76 in 10-site external validation for assertion detection. Our pipeline processed each note at $2.448\\pm 0.812$ seconds on average. Spearman correlation tests showed $\\rho >0.83$ for positive mentions and $\\rho >0.72$ for negative ones, both with $P <0.0001$. These demonstrate the effectiveness and efficiency of our models and their potential for improving PASC diagnosis.', 'abstract_zh': '准确而高效地诊断新冠长期症状（PASC）仍然具有挑战性，这是因为其症状多样且随着时间的推移会演变。为解决这一问题，我们开发了一个集成基于规则的命名实体识别和基于BERT的断言检测模块的混合自然语言处理管道，用于从临床笔记中提取和检测PASC症状的断言。我们与临床专家合作开发了一个全面的PASC词汇表。来自美国RECOVER倡议网络的11个医疗系统，我们为模型开发和评估整理了160份入院进度报告，并收集了47,654份进度报告进行人群水平的流行病学研究。我们在单中心内部验证中的平均F1分数为0.82，在多中心外部验证中为0.76。该管道平均每份笔记处理时间为$2.448\\pm 0.812$秒。皮尔森相关性检验显示，对于阳性提及，$\\rho >0.83$；对于阴性提及，$\\rho >0.72$，且两者均在$P <0.0001$。这些结果表明我们模型的有效性和效率，并展示了其在PASC诊断改进中的潜在价值。', 'title_zh': '基于混合自然语言处理从临床笔记中提取新冠病毒感染急性后遗症状'}
{'arxiv_id': 'arXiv:2508.12381', 'title': 'IPGPhormer: Interpretable Pathology Graph-Transformer for Survival Analysis', 'authors': 'Guo Tang, Songhan Jiang, Jinpeng Lu, Linghan Cai, Yongbing Zhang', 'link': 'https://arxiv.org/abs/2508.12381', 'abstract': 'Pathological images play an essential role in cancer prognosis, while survival analysis, which integrates computational techniques, can predict critical clinical events such as patient mortality or disease recurrence from whole-slide images (WSIs). Recent advancements in multiple instance learning have significantly improved the efficiency of survival analysis. However, existing methods often struggle to balance the modeling of long-range spatial relationships with local contextual dependencies and typically lack inherent interpretability, limiting their clinical utility. To address these challenges, we propose the Interpretable Pathology Graph-Transformer (IPGPhormer), a novel framework that captures the characteristics of the tumor microenvironment and models their spatial dependencies across the tissue. IPGPhormer uniquely provides interpretability at both tissue and cellular levels without requiring post-hoc manual annotations, enabling detailed analyses of individual WSIs and cross-cohort assessments. Comprehensive evaluations on four public benchmark datasets demonstrate that IPGPhormer outperforms state-of-the-art methods in both predictive accuracy and interpretability. In summary, our method, IPGPhormer, offers a promising tool for cancer prognosis assessment, paving the way for more reliable and interpretable decision-support systems in pathology. The code is publicly available at this https URL.', 'abstract_zh': '病理图像在癌症预后中发挥着重要作用，而结合计算技术的生存分析可以从玻片图像（WSI）中预测关键临床事件，如患者死亡或疾病复发。近期多实例学习的进步显著提高了生存分析的效率。然而，现有方法往往难以平衡长时间尺度的空间关系建模与局部上下文依赖性建模，并且通常缺乏内在可解释性，限制了它们的临床应用。为了解决这些挑战，我们提出了一种新型框架Interpretable Pathology Graph-Transformer (IPGPhormer)，该框架能够捕捉肿瘤微环境的特性，并建模其在组织中的空间依赖性。IPGPhormer在组织和细胞两个层面提供了无需后处理手动注释的可解释性，从而允许对单个玻片图像进行详细分析，并进行跨队列评估。在四个公开基准数据集上的全面评估表明，IPGPhormer在预测准确性和可解释性方面均优于现有最先进的方法。总之，我们的方法IPGPhormer为癌症预后评估提供了一个有前景的工具，铺平了病理学中更可靠和可解释的决策支持系统的道路。代码已公开，可在以下链接访问：this https URL。', 'title_zh': 'IPGPhormer: 可解释的病理图形变换器用于生存分析'}
{'arxiv_id': 'arXiv:2508.12361', 'title': 'Navigating the Exploration-Exploitation Tradeoff in Inference-Time Scaling of Diffusion Models', 'authors': 'Xun Su, Jianming Huang, Yang Yusen, Zhongxi Fang, Hiroyuki Kasai', 'link': 'https://arxiv.org/abs/2508.12361', 'abstract': 'Inference-time scaling has achieved remarkable success in language models, yet its adaptation to diffusion models remains underexplored. We observe that the efficacy of recent Sequential Monte Carlo (SMC)-based methods largely stems from globally fitting the The reward-tilted distribution, which inherently preserves diversity during multi-modal search. However, current applications of SMC to diffusion models face a fundamental dilemma: early-stage noise samples offer high potential for improvement but are difficult to evaluate accurately, whereas late-stage samples can be reliably assessed but are largely irreversible. To address this exploration-exploitation trade-off, we approach the problem from the perspective of the search algorithm and propose two strategies: Funnel Schedule and Adaptive Temperature. These simple yet effective methods are tailored to the unique generation dynamics and phase-transition behavior of diffusion models. By progressively reducing the number of maintained particles and down-weighting the influence of early-stage rewards, our methods significantly enhance sample quality without increasing the total number of Noise Function Evaluations. Experimental results on multiple benchmarks and state-of-the-art text-to-image diffusion models demonstrate that our approach outperforms previous baselines.', 'abstract_zh': '推理时的缩放在语言模型中取得了显著成功，但其在扩散模型中的适应性仍待探索。我们观察到，最近基于Sequential Monte Carlo (SMC)的方法的有效性主要源于其对奖励倾斜分布进行全局拟合，这在多模态搜索过程中自然地保留了多样性。然而，当前SMC方法在扩散模型中的应用面临着根本性的困境：早期噪声样本具有较高的改进潜力但难以准确评估，而晚期样本可以可靠地评估但几乎不可逆。为解决这一探索与利用的权衡问题，我们从搜索算法的角度出发，提出了两种策略：漏斗调度和自适应温度。这两种简单而有效的方法针对扩散模型独特的生成动态和相变行为进行了定制。通过逐步减少维护的粒子数量并降低早期奖励的影响，我们的方法在不增加Noise Function Evaluations总数的情况下显著提高了样本质量。在多个基准测试和最先进的文本到图像扩散模型上的实验结果表明，我们的方法优于之前的方法。', 'title_zh': '探索-利用权衡在推断时扩散模型的缩放中导航'}
{'arxiv_id': 'arXiv:2508.12356', 'title': 'Synthetic Data is Sufficient for Zero-Shot Visual Generalization from Offline Data', 'authors': 'Ahmet H. Güzel, Ilija Bogunovic, Jack Parker-Holder', 'link': 'https://arxiv.org/abs/2508.12356', 'abstract': 'Offline reinforcement learning (RL) offers a promising framework for training agents using pre-collected datasets without the need for further environment interaction. However, policies trained on offline data often struggle to generalise due to limited exposure to diverse states. The complexity of visual data introduces additional challenges such as noise, distractions, and spurious correlations, which can misguide the policy and increase the risk of overfitting if the training data is not sufficiently diverse. Indeed, this makes it challenging to leverage vision-based offline data in training robust agents that can generalize to unseen environments. To solve this problem, we propose a simple approach generating additional synthetic training data. We propose a two-step process, first augmenting the originally collected offline data to improve zero-shot generalization by introducing diversity, then using a diffusion model to generate additional data in latent space. We test our method across both continuous action spaces (Visual D4RL) and discrete action spaces (Procgen), demonstrating that it significantly improves generalization without requiring any algorithmic changes to existing model-free offline RL methods. We show that our method not only increases the diversity of the training data but also significantly reduces the generalization gap at test time while maintaining computational efficiency. We believe this approach could fuel additional progress in generating synthetic data to train more general agents in the future.', 'abstract_zh': '离线强化学习（RL）为使用预先收集的数据训练代理并在无需进一步环境交互的情况下提供了有前景的框架。然而，基于离线数据训练的策略往往难以泛化，因为它们对多样性的状态暴露有限。视觉数据的复杂性引入了额外的挑战，如噪声、干扰和虚假相关性，这些因素可能会误导策略并增加过拟合的风险，特别是当训练数据不够多样化时。实际上，这使得利用基于视觉的离线数据训练能够在未见过的环境中泛化的强代理变得极具挑战性。为了解决这一问题，我们提出了一种简单的生成额外合成训练数据的方法。我们提出了一种两步过程，首先通过引入多样性来增强最初收集的离线数据，以改善零样本泛化，然后使用扩散模型在潜在空间中生成额外的数据。我们在连续动作空间（Visual D4RL）和离散动作空间（Procgen）上测试了我们的方法，证明它可以显著改善泛化，而无需对现有的无模型离线RL方法进行任何算法更改。我们显示，该方法不仅增加了训练数据的多样性，还在测试时显著减少了泛化差距，同时保持了计算效率。我们认为，这一方法有望在未来促进生成合成数据以训练更具泛化能力代理的进一步进展。', 'title_zh': '合成数据足以从离线数据实现零样本视觉泛化'}
{'arxiv_id': 'arXiv:2508.12353', 'title': 'A Large-Scale Web Search Dataset for Federated Online Learning to Rank', 'authors': 'Marcel Gregoriadis, Jingwei Kang, Johan Pouwelse', 'link': 'https://arxiv.org/abs/2508.12353', 'abstract': 'The centralized collection of search interaction logs for training ranking models raises significant privacy concerns. Federated Online Learning to Rank (FOLTR) offers a privacy-preserving alternative by enabling collaborative model training without sharing raw user data. However, benchmarks in FOLTR are largely based on random partitioning of classical learning-to-rank datasets, simulated user clicks, and the assumption of synchronous client participation. This oversimplifies real-world dynamics and undermines the realism of experimental results. We present AOL4FOLTR, a large-scale web search dataset with 2.6 million queries from 10,000 users. Our dataset addresses key limitations of existing benchmarks by including user identifiers, real click data, and query timestamps, enabling realistic user partitioning, behavior modeling, and asynchronous federated learning scenarios.', 'abstract_zh': 'AOL4FOLTR：一种包含260万查询的大型 web 搜索数据集，用于联邦在线排名学习', 'title_zh': '适用于 federated online learning to rank 的大规模网页搜索数据集'}
{'arxiv_id': 'arXiv:2508.12314', 'title': 'Synchronization Dynamics of Heterogeneous, Collaborative Multi-Agent AI Systems', 'authors': 'Chiranjit Mitra', 'link': 'https://arxiv.org/abs/2508.12314', 'abstract': 'We present a novel interdisciplinary framework that bridges synchronization theory and multi-agent AI systems by adapting the Kuramoto model to describe the collective dynamics of heterogeneous AI agents engaged in complex task execution. By representing AI agents as coupled oscillators with both phase and amplitude dynamics, our model captures essential aspects of agent specialization, influence, and communication within networked systems. We introduce an order parameter to quantify the degree of coordination and synchronization, providing insights into how coupling strength, agent diversity, and network topology impact emergent collective behavior. Furthermore, we formalize a detailed correspondence between Chain-of-Thought prompting in AI reasoning and synchronization phenomena, unifying human-like iterative problem solving with emergent group intelligence. Through extensive simulations on all-to-all and deterministic scale-free networks, we demonstrate that increased coupling promotes robust synchronization despite heterogeneous agent capabilities, reflecting realistic collaborative AI scenarios. Our physics-informed approach establishes a rigorous mathematical foundation for designing, analyzing, and optimizing scalable, adaptive, and interpretable multi-agent AI systems. This work opens pathways for principled orchestration of agentic AI and lays the groundwork for future incorporation of learning dynamics and adaptive network architectures to further enhance system resilience and efficiency.', 'abstract_zh': '我们提出了一种综合交叉学科框架，通过将库拉莫托模型适应于描述参与复杂任务执行的异构AI代理的集体动力学，连接同步理论与多代理AI系统。通过将AI代理表示为具有相位和振幅动力学的耦合振子，我们的模型捕获了代理专业化、影响和网络系统中通信的关键方面。我们引入一个序参量来量化协调和同步的程度，提供关于耦合强度、代理多样性和网络拓扑如何影响涌现集体行为的见解。此外，我们将AI推理中的思考链提示与同步现象正式化对应起来，将类人的迭代问题解决与涌现的集体智能统一起来。通过在全连接和确定性无标度网络上进行广泛的模拟，我们证明了增加耦合在代理异质能力的情况下仍能促进稳健的同步，反映了现实的协作AI场景。我们的基于物理的方法为设计、分析和优化可扩展、自适应和可解释的多代理AI系统奠定了严格的数学基础。这项工作为原理性的 orchestration 智能代理AI提供了途径，并为未来整合学习动力学和自适应网络架构以进一步增强系统鲁棒性和效率奠定了基础。', 'title_zh': '异质协作多智能体AI系统同步动力学'}
{'arxiv_id': 'arXiv:2508.12300', 'title': 'Mutually Assured Deregulation', 'authors': 'Gilad Abiri', 'link': 'https://arxiv.org/abs/2508.12300', 'abstract': "We have convinced ourselves that the way to make AI safe is to make it unsafe. Since 2022, policymakers worldwide have embraced the Regulation Sacrifice - the belief that dismantling safety oversight will deliver security through AI dominance. Fearing China or USA will gain advantage, nations rush to eliminate safeguards that might slow progress. This Essay reveals the fatal flaw: though AI poses national security challenges, the solution demands stronger regulatory frameworks, not weaker ones. A race without guardrails breeds shared danger, not competitive strength. The Regulation Sacrifice makes three false promises. First, it promises durable technological leads. But AI capabilities spread rapidly - performance gaps between U.S. and Chinese systems collapsed from 9 percent to 2 percent in thirteen months. When advantages evaporate in months, sacrificing permanent safety for temporary speed makes no sense. Second, it promises deregulation accelerates innovation. The opposite often proves true. Companies report well-designed governance streamlines development. Investment flows toward regulated markets. Clear rules reduce uncertainty; uncertain liability creates paralysis. Environmental standards did not kill the auto industry; they created Tesla and BYD. Third, enhanced national security through deregulation actually undermines security across all timeframes. Near term: it hands adversaries information warfare tools. Medium term: it democratizes bioweapon capabilities. Long term: it guarantees deployment of uncontrollable AGI systems. The Regulation Sacrifice persists because it serves powerful interests, not security. Tech companies prefer freedom to accountability. Politicians prefer simple stories to complex truths. This creates mutually assured deregulation, where each nation's sprint for advantage guarantees collective vulnerability. The only way to win is not to play.", 'abstract_zh': '标题翻译:\n\n我们坚信确保 AI 宯全的关键在于增强 加强监管而不是放松监管。全球\n\n具体内容翻译如下:\n\n我们 have convinced ourselves that the way to ensure AI safe whole safe to ensure it unsafe. the way policymakers worldwide have embraced the Regulation Sacrifice - the belief that dismantling safety safety oversight will delivers security. AI dominance. the USA and other major nations rush to eliminate safeguards that might might may might progress. This essay reveals the fatal flaw: in AI way poses national security challenges the solution demands stronger regulatory frameworks. way cautiously one way way way caution breeds that danger one way competitive strength. The Regulation sacrifice perpetuates three false false promises. First, the way promises durable technological leads ways. But But way way capabilities gaps betweenpace China and American AI systemsst systems collapse from a half to way percent in thirteen months. When way when advantages evaporate in in months makes sacrificing permanent consistency for temporary velocity way makes no sense. way the way promise promise deregulation accelerates innovation. The opposite is true. way companies with well-designed governance mechanisms foster development development. investment investment flows towards regulated markets. Clear way determination diminishes uncertainty; unclear liability creates paralysis. Environmental standards do not harm the auto industries; they create Tesla and byd. Third, enhanced national security with deregulation undermines these way if time timeframe.near way near within hands adversariesD warfare. Medium term way democratize bioweapons capability. Large way the way way way way way persist due because strong interests, tensions between tech companies from freedom to accountability; politicians from simple stories to complex truths. This creates a mutually assured deregulation, way each nations sprint for advantages create way collective vulnerability. The only way to achieve is is way way.', 'title_zh': '相互保证的监管放松'}
{'arxiv_id': 'arXiv:2508.12292', 'title': 'HuBERT-VIC: Improving Noise-Robust Automatic Speech Recognition of Speech Foundation Model via Variance-Invariance-Covariance Regularization', 'authors': 'Hyebin Ahn, Kangwook Jang, Hoirin Kim', 'link': 'https://arxiv.org/abs/2508.12292', 'abstract': 'Noise robustness in speech foundation models (SFMs) has been a critical challenge, as most models are primarily trained on clean data and experience performance degradation when the models are exposed to noisy speech. To address this issue, we propose HuBERT-VIC, a noise-robust SFM with variance, in-variance, and covariance regularization (VICReg) objectives. These objectives adjust the statistics of noisy speech representations, enabling the model to capture diverse acoustic characteristics and improving the generalization ability across different types of noise. When applied to HuBERT, our model shows relative performance improvements of 23.3% on LibriSpeech test-clean and 13.2% on test-other, compared to the baseline model pre-trained on noisy speech.', 'abstract_zh': '噪声鲁棒性在声学基础模型（SFMs）中的提升：HuBERT-VIC方法的研究', 'title_zh': 'HuBERT-VIC：通过方差不变协方差正则化提高语音基础模型的噪声鲁棒自动语音识别'}
{'arxiv_id': 'arXiv:2508.12285', 'title': '"My productivity is boosted, but ..." Demystifying Users\' Perception on AI Coding Assistants', 'authors': 'Yunbo Lyu, Zhou Yang, Jieke Shi, Jianming Chang, Yue Liu, David Lo', 'link': 'https://arxiv.org/abs/2508.12285', 'abstract': "This paper aims to explore fundamental questions in the era when AI coding assistants like GitHub Copilot are widely adopted: what do developers truly value and criticize in AI coding assistants, and what does this reveal about their needs and expectations in real-world software development? Unlike previous studies that conduct observational research in controlled and simulated environments, we analyze extensive, first-hand user reviews of AI coding assistants, which capture developers' authentic perspectives and experiences drawn directly from their actual day-to-day work contexts. We identify 1,085 AI coding assistants from the Visual Studio Code Marketplace. Although they only account for 1.64% of all extensions, we observe a surge in these assistants: over 90% of them are released within the past two years. We then manually analyze the user reviews sampled from 32 AI coding assistants that have sufficient installations and reviews to construct a comprehensive taxonomy of user concerns and feedback about these assistants. We manually annotate each review's attitude when mentioning certain aspects of coding assistants, yielding nuanced insights into user satisfaction and dissatisfaction regarding specific features, concerns, and overall tool performance. Built on top of the findings-including how users demand not just intelligent suggestions but also context-aware, customizable, and resource-efficient interactions-we propose five practical implications and suggestions to guide the enhancement of AI coding assistants that satisfy user needs.", 'abstract_zh': '本文旨在探索人工智能编码助手如GitHub Copilot广泛应用的时代，开发人员真正重视和批评的人工智能编码助手的哪些方面，这又揭示了他们在实际软件开发中有哪些需求和期望？不同于以往在受控和模拟环境中进行观察研究的方法，我们分析了大量第一手的人工智能编码助手用户评价，这些评价直接捕捉了开发人员的真实视角和体验，它们源自开发人员的实际日常工作环境。我们从Visual Studio Code Marketplace中识别出1,085个人工智能编码助手，尽管这些助手仅占所有扩展的1.64%，但它们中有超过90%发布于过去两年内。然后，我们手动分析了从32个人工智能编码助手中抽取的用户评价，这些助手有足够多的安装和评论，用于构建一个全面的用户关注点和反馈分类体系。我们手动标注每个评论对某些方面的人工智能编码助手的态度，从而对特定功能、问题及整体工具性能的用户满意度和不满提供了细致的见解。基于上述发现，包括用户不仅要求智能建议，还要求具有上下文意识、可定制和资源高效的人机交互，我们提出了五项实用的建议和指导，以促进能够满足用户需求的人工智能编码助手的改进。', 'title_zh': '“我的 productivity 得到了提升，但……”揭开用户对 AI 编码助手认知的迷思'}
{'arxiv_id': 'arXiv:2508.12278', 'title': 'CRoC: Context Refactoring Contrast for Graph Anomaly Detection with Limited Supervision', 'authors': 'Siyue Xie, Da Sun Handason Tam, Wing Cheong Lau', 'link': 'https://arxiv.org/abs/2508.12278', 'abstract': "Graph Neural Networks (GNNs) are widely used as the engine for various graph-related tasks, with their effectiveness in analyzing graph-structured data. However, training robust GNNs often demands abundant labeled data, which is a critical bottleneck in real-world applications. This limitation severely impedes progress in Graph Anomaly Detection (GAD), where anomalies are inherently rare, costly to label, and may actively camouflage their patterns to evade detection. To address these problems, we propose Context Refactoring Contrast (CRoC), a simple yet effective framework that trains GNNs for GAD by jointly leveraging limited labeled and abundant unlabeled data. Different from previous works, CRoC exploits the class imbalance inherent in GAD to refactor the context of each node, which builds augmented graphs by recomposing the attributes of nodes while preserving their interaction patterns. Furthermore, CRoC encodes heterogeneous relations separately and integrates them into the message-passing process, enhancing the model's capacity to capture complex interaction semantics. These operations preserve node semantics while encouraging robustness to adversarial camouflage, enabling GNNs to uncover intricate anomalous cases. In the training stage, CRoC is further integrated with the contrastive learning paradigm. This allows GNNs to effectively harness unlabeled data during joint training, producing richer, more discriminative node embeddings. CRoC is evaluated on seven real-world GAD datasets with varying scales. Extensive experiments demonstrate that CRoC achieves up to 14% AUC improvement over baseline GNNs and outperforms state-of-the-art GAD methods under limited-label settings.", 'abstract_zh': '基于上下文重构对比的图神经网络异常检测方法（Context Refactoring Contrast for Graph Neural Network-based Anomaly Detection）', 'title_zh': 'CRoC: 基于上下文重构对比的图异常检测方法（在有限监督下）'}
{'arxiv_id': 'arXiv:2508.12259', 'title': 'Fortifying the Agentic Web: A Unified Zero-Trust Architecture Against Logic-layer Threats', 'authors': 'Ken Huang, Yasir Mehmood, Hammad Atta, Jerry Huang, Muhammad Zeeshan Baig, Sree Bhargavi Balija', 'link': 'https://arxiv.org/abs/2508.12259', 'abstract': 'This paper presents a Unified Security Architecture that fortifies the Agentic Web through a Zero-Trust IAM framework. This architecture is built on a foundation of rich, verifiable agent identities using Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs), with discovery managed by a protocol-agnostic Agent Name Service (ANS). Security is operationalized through a multi-layered Trust Fabric which introduces significant innovations, including Trust-Adaptive Runtime Environments (TARE), Causal Chain Auditing, and Dynamic Identity with Behavioral Attestation. By explicitly linking the LPCI threat to these enhanced architectural countermeasures within a formal security model, we propose a comprehensive and forward-looking blueprint for a secure, resilient, and trustworthy agentic ecosystem. Our formal analysis demonstrates that the proposed architecture provides provable security guarantees against LPCI attacks with bounded probability of success.', 'abstract_zh': '本文提出了一种统一安全架构，通过零信任IAM框架强化代理网络。该架构基于丰富的可验证代理身份构建，使用分布式标识符（DIDs）和可验证凭证（VCs），并通过协议无关的代理名称服务（ANS）进行发现。安全性通过多层信任织物实现，引入了包括信任自适应运行时环境（TARE）、因果链审计和动态身份行为证明在内的重大创新。通过对LPCI威胁与这些增强架构对策之间的显式链接，在形式安全模型中提出了一个全面且前瞻性的安全、韧性和可信赖代理生态系统蓝图。我们的形式分析表明，所提出的架构能够在有界成功概率下提供对LPCI攻击的可验证安全保证。', 'title_zh': '加强代理网络：针对逻辑层威胁的统一零信任架构'}
{'arxiv_id': 'arXiv:2508.12253', 'title': 'Interpreting Time Series Forecasts with LIME and SHAP: A Case Study on the Air Passengers Dataset', 'authors': 'Manish Shukla', 'link': 'https://arxiv.org/abs/2508.12253', 'abstract': 'Time-series forecasting underpins critical decisions across aviation, energy, retail and health. Classical autoregressive integrated moving average (ARIMA) models offer interpretability via coefficients but struggle with nonlinearities, whereas tree-based machine-learning models such as XGBoost deliver high accuracy but are often opaque. This paper presents a unified framework for interpreting time-series forecasts using local interpretable model-agnostic explanations (LIME) and SHapley additive exPlanations (SHAP). We convert a univariate series into a leakage-free supervised learning problem, train a gradient-boosted tree alongside an ARIMA baseline and apply post-hoc explainability. Using the Air Passengers dataset as a case study, we show that a small set of lagged features -- particularly the twelve-month lag -- and seasonal encodings explain most forecast variance. We contribute: (i) a methodology for applying LIME and SHAP to time series without violating chronology; (ii) theoretical exposition of the underlying algorithms; (iii) empirical evaluation with extensive analysis; and (iv) guidelines for practitioners.', 'abstract_zh': '时间序列预测贯穿航空、零售和健康等领域的关键控制。本文提出了一种结合局部可解释性表方自洽解释（LIME）和SHap值可加性解释（SHAP pesticure的时间序列预测解释框架，传统自回归整定移动平均（ARIMA）模型通过系数提供可易性性，但对非线性性弱能力差；而基于线模型如如如XGBoost线模型则提供高准度性，但往往缺乏透明性。本文提出了一种结合LIME和SHAP的统 blir机械架框架，用于解释时间序列预测，并己酒下不违反时序性性。我们使用国际空旅乘客数据集进行了案例研究，表明滞后特征（尤其是十二个月滞后）和季节编码能够有效解释预测变异。我们贡献了：(一项结合LIME和SHAP应用于时间序列预测的方法论；(ii)底层算法的理论阐述；(iii)严格的实证分析；(iv)实践者的指导建议。', 'title_zh': '使用LIME和SHAP解释时间序列预测：基于航空乘客数据集的案例研究'}
{'arxiv_id': 'arXiv:2508.12222', 'title': 'Distribution Matching via Generalized Consistency Models', 'authors': 'Sagar Shrestha, Rajesh Shrestha, Tri Nguyen, Subash Timilsina', 'link': 'https://arxiv.org/abs/2508.12222', 'abstract': 'Recent advancement in generative models have demonstrated remarkable performance across various data modalities. Beyond their typical use in data synthesis, these models play a crucial role in distribution matching tasks such as latent variable modeling, domain translation, and domain adaptation. Generative Adversarial Networks (GANs) have emerged as the preferred method of distribution matching due to their efficacy in handling high-dimensional data and their flexibility in accommodating various constraints. However, GANs often encounter challenge in training due to their bi-level min-max optimization objective and susceptibility to mode collapse. In this work, we propose a novel approach for distribution matching inspired by the consistency models employed in Continuous Normalizing Flow (CNF). Our model inherits the advantages of CNF models, such as having a straight forward norm minimization objective, while remaining adaptable to different constraints similar to GANs. We provide theoretical validation of our proposed objective and demonstrate its performance through experiments on synthetic and real-world datasets.', 'abstract_zh': 'Recent Advances in Generative Models for Distribution Matching：A Consistency-Based Approach Inspired by Continuous Normalizing Flow', 'title_zh': '广义一致性模型下的分布匹配'}
{'arxiv_id': 'arXiv:2508.12162', 'title': 'AICRN: Attention-Integrated Convolutional Residual Network for Interpretable Electrocardiogram Analysis', 'authors': 'J. M. I. H. Jayakody, A. M. H. H. Alahakoon, C. R. M. Perera, R. M. L. C. Srimal, Roshan Ragel, Vajira Thambawita, Isuru Nawinne', 'link': 'https://arxiv.org/abs/2508.12162', 'abstract': 'The paradigm of electrocardiogram (ECG) analysis has evolved into real-time digital analysis, facilitated by artificial intelligence (AI) and machine learning (ML), which has improved the diagnostic precision and predictive capacity of cardiac diseases. This work proposes a novel deep learning (DL) architecture called the attention-integrated convolutional residual network (AICRN) to regress key ECG parameters such as the PR interval, the QT interval, the QRS duration, the heart rate, the peak amplitude of the R wave, and the amplitude of the T wave for interpretable ECG analysis. Our architecture is specially designed with spatial and channel attention-related mechanisms to address the type and spatial location of the ECG features for regression. The models employ a convolutional residual network to address vanishing and exploding gradient problems. The designed system addresses traditional analysis challenges, such as loss of focus due to human errors, and facilitates the fast and easy detection of cardiac events, thereby reducing the manual efforts required to solve analysis tasks. AICRN models outperform existing models in parameter regression with higher precision. This work demonstrates that DL can play a crucial role in the interpretability and precision of ECG analysis, opening up new clinical applications for cardiac monitoring and management.', 'abstract_zh': '基于注意力集成卷积残差网络的心电图参数回归分析：一种可解释的心电图分析新范式', 'title_zh': '基于注意力集成卷积残差网络的可解释心电图分析'}
{'arxiv_id': 'arXiv:2508.12148', 'title': 'Demystifying Foreground-Background Memorization in Diffusion Models', 'authors': 'Jimmy Z. Di, Yiwei Lu, Yaoliang Yu, Gautam Kamath, Adam Dziedzic, Franziska Boenisch', 'link': 'https://arxiv.org/abs/2508.12148', 'abstract': 'Diffusion models (DMs) memorize training images and can reproduce near-duplicates during generation. Current detection methods identify verbatim memorization but fail to capture two critical aspects: quantifying partial memorization occurring in small image regions, and memorization patterns beyond specific prompt-image pairs. To address these limitations, we propose Foreground Background Memorization (FB-Mem), a novel segmentation-based metric that classifies and quantifies memorized regions within generated images. Our method reveals that memorization is more pervasive than previously understood: (1) individual generations from single prompts may be linked to clusters of similar training images, revealing complex memorization patterns that extend beyond one-to-one correspondences; and (2) existing model-level mitigation methods, such as neuron deactivation and pruning, fail to eliminate local memorization, which persists particularly in foreground regions. Our work establishes an effective framework for measuring memorization in diffusion models, demonstrates the inadequacy of current mitigation approaches, and proposes a stronger mitigation method using a clustering approach.', 'abstract_zh': '前景背景记忆化（FB-Mem）：一种新颖的分割基测量方法及扩散模型中的记忆分析', 'title_zh': '揭示扩散模型中前景-背景记忆的迷思'}
{'arxiv_id': 'arXiv:2508.12147', 'title': 'KP-INR: A Dual-Branch Implicit Neural Representation Model for Cardiac Cine MRI Reconstruction', 'authors': 'Donghang Lyu, Marius Staring, Mariya Doneva, Hildo J. Lamb, Nicola Pezzotti', 'link': 'https://arxiv.org/abs/2508.12147', 'abstract': 'Cardiac Magnetic Resonance (CMR) imaging is a non-invasive method for assessing cardiac structure, function, and blood flow. Cine MRI extends this by capturing heart motion, providing detailed insights into cardiac mechanics. To reduce scan time and breath-hold discomfort, fast acquisition techniques have been utilized at the cost of lowering image quality. Recently, Implicit Neural Representation (INR) methods have shown promise in unsupervised reconstruction by learning coordinate-to-value mappings from undersampled data, enabling high-quality image recovery. However, current existing INR methods primarily focus on using coordinate-based positional embeddings to learn the mapping, while overlooking the feature representations of the target point and its neighboring context. In this work, we propose KP-INR, a dual-branch INR method operating in k-space for cardiac cine MRI reconstruction: one branch processes the positional embedding of k-space coordinates, while the other learns from local multi-scale k-space feature representations at those coordinates. By enabling cross-branch interaction and approximating the target k-space values from both branches, KP-INR can achieve strong performance on challenging Cartesian k-space data. Experiments on the CMRxRecon2024 dataset confirms its improved performance over baseline models and highlights its potential in this field.', 'abstract_zh': '心脏磁共振成像（CMR）是一种无创方法，用于评估心脏结构、功能和血流。心脏电影MRI通过捕获心脏的运动，提供关于心脏机械性的详细见解。为了缩短扫描时间和减轻屏息不适，已经采用了快速采集技术，但代价是降低了图像质量。最近，显式神经表示（Explicit Neural Representation，ENR）方法在无监督重构中显示出潜力，通过从欠采样数据中学习坐标到值的映射来实现高质量图像恢复。然而，现有的ENR方法主要侧重于使用坐标基的位置嵌入来学习映射，而忽视了目标点及其邻域上下文的特征表示。在这种情况下，我们提出了KP-INR，这是一种在k空间中操作的双分支神经表示方法，用于心脏电影MRI重建：一个分支处理k空间坐标的 POSITIONAL EMBEDDING，另一个分支从这些坐标的局部多尺度k空间特征表示中学习。通过启用分支间的交互并从两个分支中近似目标k空间值，KP-INR可以在具有挑战性的笛卡尔k空间数据上实现优异性能。CMRxRecon2024数据集上的实验证实了其相对于基线模型的改进性能，并突显了其在该领域的潜在价值。', 'title_zh': 'KP-INR：心脏 cine MRI 重建的双分支隐式神经表示模型'}
{'arxiv_id': 'arXiv:2508.12138', 'title': 'Substituting Proof of Work in Blockchain with Training-Verified Collaborative Model Computation', 'authors': 'Mohammad Ishzaz Asif Rafid, Morsalin Sakib', 'link': 'https://arxiv.org/abs/2508.12138', 'abstract': "Bitcoin's Proof of Work (PoW) mechanism, while central to achieving decentralized consensus, has long been criticized for excessive energy use and hardware inefficiencies \\cite{devries2018bitcoin, truby2018decarbonizing}. This paper introduces a hybrid architecture that replaces Bitcoin's traditional PoW with a centralized, cloud-based collaborative training framework. In this model, miners contribute computing resources to train segments of horizontally scaled machine learning models on preprocessed datasets, ensuring privacy and generating meaningful outputs \\cite{li2017securing}. A central server evaluates contributions using two metrics: number of parameters trained and reduction in model loss during each cycle. At the end of every cycle, a weighted lottery selects the winning miner, who receives a digitally signed certificate. This certificate serves as a verifiable substitute for PoW and grants the right to append a block to the blockchain \\cite{nakamoto2008bitcoin}. By integrating digital signatures and SHA-256 hashing \\cite{nist2015sha}, the system preserves blockchain integrity while redirecting energy toward productive computation. The proposed approach addresses the sustainability concerns of traditional mining by converting resource expenditure into socially valuable work, aligning security incentives with real-world computational progress.", 'abstract_zh': '比特币的工作量证明（PoW）机制虽然在实现去中心化共识方面至关重要，但长期以来因其能源消耗过大和硬件效率低下而受到批评。本文介绍了一种混合架构，该架构将比特币的传统PoW替换为基于云的集中式协作训练框架。在该模型中，矿工贡献计算资源在预处理数据集上训练横向扩展的机器学习模型的片段，确保隐私并生成有意义的输出。中央服务器使用两个指标评估贡献：训练的参数数量和每个周期内模型损失的减少。每个周期结束后，根据加权抽奖结果选出获胜矿工，其将获得数字签名证书。该证书作为PoW的可验证替代品，并赋予其向区块链追加区块的权利。通过整合数字签名和SHA-256哈希算法，该系统保持了区块链的完整性，同时将能源重新导向到有价值的计算工作。所提出的方法通过将资源支出转化为社会有价值的劳动，解决了传统采矿的可持续性问题，并使安全激励与实际计算进展相一致。', 'title_zh': '用训练验证协作模型计算代替区块链中的工作量证明'}
{'arxiv_id': 'arXiv:2508.12116', 'title': 'DynamixSFT: Dynamic Mixture Optimization of Instruction Tuning Collections', 'authors': 'Haebin Shin, Lei Ji, Xiao Liu, Zhiwei Yu, Qi Chen, Yeyun Gong', 'link': 'https://arxiv.org/abs/2508.12116', 'abstract': "As numerous instruction-tuning datasets continue to emerge during the post-training stage, dynamically balancing and optimizing their mixtures has become a critical challenge. To address this, we propose DynamixSFT, a dynamic and automated method for instruction-tuning dataset mixture optimization. We formulate the problem as a multi-armed bandit setup and introduce a Prior-scaled Boltzmann Exploration that softly anchors the updated sampling distribution to the original dataset proportions, thereby preserving the inherent diversity and coverage of the collection. Sampling probabilities are updated using a lightweight 1-Step Look-ahead Reward, reflecting how much the dataset contributes to improving the model's performance at its current state. When applied to the Tulu-v2-mixture collection comprising 16 instruction-tuning datasets, DynamixSFT achieves up to a 2.2% performance improvement across 10 benchmarks. Furthermore, we provide a comprehensive analysis and visualizations to offer deeper insights into the adaptive dynamics of our method.", 'abstract_zh': '动态优化指令调整数据集混合的DynamixSFT方法', 'title_zh': 'DynamixSFT：指令调优集合的动态混合优化'}
{'arxiv_id': 'arXiv:2508.12063', 'title': 'Generalized invariants meet constitutive neural networks: A novel framework for hyperelastic materials', 'authors': 'Denisa Martonová, Alain Goriely, Ellen Kuhl', 'link': 'https://arxiv.org/abs/2508.12063', 'abstract': 'The major challenge in determining a hyperelastic model for a given material is the choice of invariants and the selection how the strain energy function depends functionally on these invariants. Here we introduce a new data-driven framework that simultaneously discovers appropriate invariants and constitutive models for isotropic incompressible hyperelastic materials. Our approach identifies both the most suitable invariants in a class of generalized invariants and the corresponding strain energy function directly from experimental observations. Unlike previous methods that rely on fixed invariant choices or sequential fitting procedures, our method integrates the discovery process into a single neural network architecture. By looking at a continuous family of possible invariants, the model can flexibly adapt to different material behaviors. We demonstrate the effectiveness of this approach using popular benchmark datasets for rubber and brain tissue. For rubber, the method recovers a stretch-dominated formulation consistent with classical models. For brain tissue, it identifies a formulation sensitive to small stretches, capturing the nonlinear shear response characteristic of soft biological matter. Compared to traditional and neural-network-based models, our framework provides improved predictive accuracy and interpretability across a wide range of deformation states. This unified strategy offers a robust tool for automated and physically meaningful model discovery in hyperelasticity.', 'abstract_zh': '一种新的数据驱动框架：同时发现各向同性不可压缩超弹材料的合适不变量和本构模型', 'title_zh': '广义不变量与本构神经网络结合：一类新的超弹性材料框架'}
{'arxiv_id': 'arXiv:2508.12029', 'title': 'BConformeR: A Conformer Based on Mutual Sampling for Unified Prediction of Continuous and Discontinuous Antibody Binding Sites', 'authors': 'Zhangyu You, Jiahao Ma, Hongzong Li, Ye-Fan Hu, Jian-Dong Huang', 'link': 'https://arxiv.org/abs/2508.12029', 'abstract': 'Accurate prediction of antibody-binding sites (epitopes) on antigens is crucial for vaccine design, immunodiagnostics, therapeutic antibody development, antibody engineering, research into autoimmune and allergic diseases, and for advancing our understanding of immune responses. Despite in silico methods that have been proposed to predict both linear (continuous) and conformational (discontinuous) epitopes, they consistently underperform in predicting conformational epitopes. In this work, we propose a conformer-based model trained on antigen sequences derived from 1,080 antigen-antibody complexes, leveraging convolutional neural networks (CNNs) to extract local features and Transformers to capture long-range dependencies within antigen sequences. Ablation studies demonstrate that CNN enhances the prediction of linear epitopes, and the Transformer module improves the prediction of conformational epitopes. Experimental results show that our model outperforms existing baselines in terms of PCC, ROC-AUC, PR-AUC, and F1 scores on conformational epitopes.', 'abstract_zh': '准确预测抗原上的抗体结合位点（表位）对于疫苗设计、免疫诊断、治疗性抗体开发、抗体工程、自身免疫和过敏性疾病研究以及增进我们对免疫反应的理解至关重要。尽管已经提出了用于预测线性表位和构象表位的计算机辅助方法，但在预测构象表位方面它们始终表现不佳。在本工作中，我们提出了一种基于构象的模型，该模型基于从中提取抗原序列的1,080个抗原-抗体复合物，利用卷积神经网络（CNNs）提取局部特征，并利用变换器捕获抗原序列中的长距离依赖性。消融研究显示，卷积神经网络增强了线性表位的预测能力，而变换器模块提高了构象表位的预测能力。实验结果表明，与现有的基线方法相比，我们的模型在构象表位上的PCC、ROC-AUC、PR-AUC和F1分数方面表现更优。', 'title_zh': 'BConformeR：基于互惠采样的卷积器，统一预测连续和非连续抗体检测位点'}
{'arxiv_id': 'arXiv:2508.12013', 'title': 'Predicting ChatGPT Use in Assignments: Implications for AI-Aware Assessment Design', 'authors': 'Surajit Das, Aleksei Eliseev', 'link': 'https://arxiv.org/abs/2508.12013', 'abstract': 'The rise of generative AI tools like ChatGPT has significantly reshaped education, sparking debates about their impact on learning outcomes and academic integrity. While prior research highlights opportunities and risks, there remains a lack of quantitative analysis of student behavior when completing assignments. Understanding how these tools influence real-world academic practices, particularly assignment preparation, is a pressing and timely research priority.\nThis study addresses this gap by analyzing survey responses from 388 university students, primarily from Russia, including a subset of international participants. Using the XGBoost algorithm, we modeled predictors of ChatGPT usage in academic assignments. Key predictive factors included learning habits, subject preferences, and student attitudes toward AI. Our binary classifier demonstrated strong predictive performance, achieving 80.1\\% test accuracy, with 80.2\\% sensitivity and 79.9\\% specificity. The multiclass classifier achieved 64.5\\% test accuracy, 64.6\\% weighted precision, and 64.5\\% recall, with similar training scores, indicating potential data scarcity challenges.\nThe study reveals that frequent use of ChatGPT for learning new concepts correlates with potential overreliance, raising concerns about long-term academic independence. These findings suggest that while generative AI can enhance access to knowledge, unchecked reliance may erode critical thinking and originality. We propose discipline-specific guidelines and reimagined assessment strategies to balance innovation with academic rigor. These insights can guide educators and policymakers in ethically and effectively integrating AI into education.', 'abstract_zh': '生成式AI工具（如ChatGPT）的兴起显著重塑了教育，引发了对其对学生学习成果和学术诚信影响的讨论。尽管以往的研究指出了机遇与风险，但对于学生在完成作业时使用这些工具的行为缺乏定量分析。理解这些工具如何影响实际的学术实践，特别是作业准备过程，是一项紧迫而及时的研究优先事项。', 'title_zh': '预测ChatGPT在作业中的使用：对AI意识评估设计的影响'}
{'arxiv_id': 'arXiv:2508.11977', 'title': 'TBGRecall: A Generative Retrieval Model for E-commerce Recommendation Scenarios', 'authors': 'Zida Liang, Changfa Wu, Dunxian Huang, Weiqiang Sun, Ziyang Wang, Yuliang Yan, Jian Wu, Yuning Jiang, Bo Zheng, Ke Chen, Silu Zhou, Yu Zhang', 'link': 'https://arxiv.org/abs/2508.11977', 'abstract': 'Recommendation systems are essential tools in modern e-commerce, facilitating personalized user experiences by suggesting relevant products. Recent advancements in generative models have demonstrated potential in enhancing recommendation systems; however, these models often exhibit limitations in optimizing retrieval tasks, primarily due to their reliance on autoregressive generation mechanisms. Conventional approaches introduce sequential dependencies that impede efficient retrieval, as they are inherently unsuitable for generating multiple items without positional constraints within a single request session. To address these limitations, we propose TBGRecall, a framework integrating Next Session Prediction (NSP), designed to enhance generative retrieval models for e-commerce applications. Our framework reformulation involves partitioning input samples into multi-session sequences, where each sequence comprises a session token followed by a set of item tokens, and then further incorporate multiple optimizations tailored to the generative task in retrieval scenarios. In terms of training methodology, our pipeline integrates limited historical data pre-training with stochastic partial incremental training, significantly improving training efficiency and emphasizing the superiority of data recency over sheer data volume. Our extensive experiments, conducted on public benchmarks alongside a large-scale industrial dataset from TaoBao, show TBGRecall outperforms the state-of-the-art recommendation methods, and exhibits a clear scaling law trend. Ultimately, NSP represents a significant advancement in the effectiveness of generative recommendation systems for e-commerce applications.', 'abstract_zh': '基于Next Session Prediction的TBGRecall强化生成推荐框架', 'title_zh': 'TBGRecall：电子商务推荐场景下的生成式检索模型'}
{'arxiv_id': 'arXiv:2508.11957', 'title': 'A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond', 'authors': 'Xiaodong Qu, Andrews Damoah, Joshua Sherwood, Peiyan Liu, Christian Shun Jin, Lulu Chen, Minjie Shen, Nawwaf Aleisa, Zeyuan Hou, Chenyu Zhang, Lifu Gao, Yanshu Li, Qikai Yang, Qun Wang, Cristabelle De Souza', 'link': 'https://arxiv.org/abs/2508.11957', 'abstract': 'Artificial Intelligence (AI) agents have rapidly evolved from specialized, rule-based programs to versatile, learning-driven autonomous systems capable of perception, reasoning, and action in complex environments. The explosion of data, advances in deep learning, reinforcement learning, and multi-agent coordination have accelerated this transformation. Yet, designing and deploying unified AI agents that seamlessly integrate cognition, planning, and interaction remains a grand challenge. In this review, we systematically examine the architectural principles, foundational components, and emergent paradigms that define the landscape of contemporary AI agents. We synthesize insights from cognitive science-inspired models, hierarchical reinforcement learning frameworks, and large language model-based reasoning. Moreover, we discuss the pressing ethical, safety, and interpretability concerns associated with deploying these agents in real-world scenarios. By highlighting major breakthroughs, persistent challenges, and promising research directions, this review aims to guide the next generation of AI agent systems toward more robust, adaptable, and trustworthy autonomous intelligence.', 'abstract_zh': '人工智能（AI）代理从专门的基于规则的程序迅速进化为能够在复杂环境中进行感知、推理和行动的多功能、学习驱动的自主系统。数据爆炸、深度学习、强化学习和多代理协调的进步加速了这一转变。然而，设计和部署能够无缝集成认知、规划和交互的统一AI代理仍然是一个巨大的挑战。在本文综述中，我们系统地 examine 了当代AI代理所涉及的体系结构原则、基础组件和新兴范式。我们综合了认知科学启发式模型、层级强化学习框架以及基于大型语言模型的推理方面的洞见。此外，我们还讨论了部署这些代理在实际应用场景中所面临的紧迫的伦理、安全性和可解释性问题。通过突出重大突破、持久性挑战和有希望的研究方向，本文综述旨在引导下一代AI代理系统朝着更稳健、更适应和更可信的自主智能方向发展。', 'title_zh': 'AI代理的全面综述：技术及 Beyond 的可能性转化'}
{'arxiv_id': 'arXiv:2508.11935', 'title': 'HPD: Hybrid Projection Decomposition for Robust State Space Models on Analog CIM Hardware', 'authors': 'Yuannuo Feng, Wenyong Zhou, Yuexi Lyu, Hanjie Liu, Zhengwu Liu, Ngai Wong, Wang Kang', 'link': 'https://arxiv.org/abs/2508.11935', 'abstract': 'State Space Models (SSMs) are efficient alternatives to traditional sequence models, excelling at processing long sequences with lower computational complexity. Their reliance on matrix multiplications makes them ideal for compute-in-memory (CIM) architectures, which improve energy efficiency by computing within memory arrays. However, device non-idealities in CIM introduce weight perturbations that can degrade inference accuracy. In this paper, we systematically analyze the robustness of SSMs under noisy conditions, identifying that the final block and output projection layers are more susceptible to perturbations compared to other components. Building on these insights, we propose HPD, a Hybrid Projection Decomposition strategy for the last output projection layer. We replace the original weight matrix with the multiplication of U and {\\Sigma} in its SVD to ensure compatibility with existing hardware architectures, while offloading V> to digital hardware for precise and robust correction. Comprehensive tests on Mamba models show that our method reduces perplexity by up to 99.57% under various noise conditions compared to baseline models, with accuracy gains of up to 96.67% on the PIQA benchmark for commonsense reasoning.', 'abstract_zh': 'State Space Models在噪声条件下的鲁棒性分析及HPD策略', 'title_zh': 'HPD: 综合投影分解方法在类比CIM硬件上实现稳健的状态空间模型'}
{'arxiv_id': 'arXiv:2508.11921', 'title': 'ENA: Efficient N-dimensional Attention', 'authors': 'Yibo Zhong', 'link': 'https://arxiv.org/abs/2508.11921', 'abstract': 'Efficient modeling of long sequences of high-order data requires a more efficient architecture than Transformer. In this paper, we investigate two key aspects of extending linear recurrent models, especially those originally designed for language modeling, to high-order data (1D to ND): scanning strategies and attention-hybrid architectures. Empirical results suggest that scanning provides limited benefits, while attention-hybrid models yield promising results. Focusing on the latter, we further evaluate types of attention and find that tiled high-order sliding window attention (SWA) is efficient in both theory and practice. We term the resulting hybrid architecture of linear recurrence and high-order SWA as Efficient N-dimensional Attention (ENA). We then conduct several experiments to demonstrate its effectiveness. The intuition behind ENA is that linear recurrence compresses global information into a state, while SWA complements it by enforcing strict local modeling. Together, they form a simple framework that offers a promising and practical solution for ultra-long high-order data modeling.', 'abstract_zh': '高效建模高阶数据的长序列需要一种比Transformer更高效的架构。本文研究了将特别设计用于语言建模的一维线性递归模型扩展到高阶数据（1D到ND）的两个关键方面：扫描策略和注意力-混合架构。实验结果表明，扫描提供的收益有限，而注意力-混合模型显示出有希望的结果。着重于后者，我们进一步评估了不同类型的注意力机制，发现拼接的高阶滑动窗口注意力(SWA)在理论和实践中都高效。我们将这种线性递归与高阶SWA相结合的混合架构命名为高效N维注意力(ENA)。然后，我们进行了若干实验以证明其有效性。ENA的基本思想是，线性递归将全局信息压缩到一个状态，而SWA通过强制进行严格的局部建模来补充这一点。两者结合形成了一种简单框架，为超长高阶数据建模提供了有希望且实用的解决方案。', 'title_zh': 'ENA: 高效的N维注意力机制'}
{'arxiv_id': 'arXiv:2508.11907', 'title': 'Deciphering the Interplay between Attack and Protection Complexity in Privacy-Preserving Federated Learning', 'authors': 'Xiaojin Zhang, Mingcong Xu, Yiming Li, Wei Chen, Qiang Yang', 'link': 'https://arxiv.org/abs/2508.11907', 'abstract': 'Federated learning (FL) offers a promising paradigm for collaborative model training while preserving data privacy. However, its susceptibility to gradient inversion attacks poses a significant challenge, necessitating robust privacy protection mechanisms. This paper introduces a novel theoretical framework to decipher the intricate interplay between attack and protection complexities in privacy-preserving FL. We formally define "Attack Complexity" as the minimum computational and data resources an adversary requires to reconstruct private data below a given error threshold, and "Protection Complexity" as the expected distortion introduced by privacy mechanisms. Leveraging Maximum Bayesian Privacy (MBP), we derive tight theoretical bounds for protection complexity, demonstrating its scaling with model dimensionality and privacy budget. Furthermore, we establish comprehensive bounds for attack complexity, revealing its dependence on privacy leakage, gradient distortion, model dimension, and the chosen privacy level. Our findings quantitatively illuminate the fundamental trade-offs between privacy guarantees, system utility, and the effort required for both attacking and defending. This framework provides critical insights for designing more secure and efficient federated learning systems.', 'abstract_zh': '联邦学习（FL）提供了一种在保护数据隐私的同时进行协作模型训练的有希望的范式。然而，其对梯度反转攻击的敏感性构成了一个显著的挑战，需要 robust 的隐私保护机制。本文引入了一种新的理论框架，以揭示保护隐私的联邦学习中攻击复杂性和保护复杂性的复杂交互。我们正式定义“攻击复杂性”为攻击者在低于给定误差阈值的条件下重建私有数据所需的最小计算和数据资源，“保护复杂性”为隐私机制引入的预期失真度。基于最大贝叶斯隐私（MBP），我们推导出保护复杂性的紧界，展示了其与模型维度和隐私预算的关联性。此外，我们建立了攻击复杂性的全面界限，揭示了其依赖于隐私泄露、梯度失真、模型维度和所选隐私级别。我们的研究定量地阐明了隐私保证、系统效用以及攻击和防御所需努力之间的基本权衡。该框架为设计更安全高效的联邦学习系统提供了关键见解。', 'title_zh': '解构隐私保护联邦学习中攻击复杂度与防御复杂度的相互作用'}
{'arxiv_id': 'arXiv:2508.11872', 'title': 'Singing Syllabi with Virtual Avatars: Enhancing Student Engagement Through AI-Generated Music and Digital Embodiment', 'authors': 'Xinxing Wu', 'link': 'https://arxiv.org/abs/2508.11872', 'abstract': "In practical teaching, we observe that few students thoroughly read or fully comprehend the information provided in traditional, text-based course syllabi. As a result, essential details, such as course policies and learning outcomes, are frequently overlooked. To address this challenge, in this paper, we propose a novel approach leveraging AI-generated singing and virtual avatars to present syllabi in a format that is more visually appealing, engaging, and memorable. Especially, we leveraged the open-source tool, HeyGem, to transform textual syllabi into audiovisual presentations, in which digital avatars perform the syllabus content as songs. The proposed approach aims to stimulate students' curiosity, foster emotional connection, and enhance retention of critical course information. Student feedback indicated that AI-sung syllabi significantly improved awareness and recall of key course information.", 'abstract_zh': '在实际教学中，我们观察到多数学生没有充分阅读或全面理解传统文本式课程大纲所提供的信息。因此，诸如课程政策和学习成果等重要细节经常被忽略。为应对这一挑战，本文提出了一种利用AI生成演唱和虚拟角色展示课程大纲的新方法，使课程大纲以更具吸引力、更易于记忆的视听格式呈现。特别是，我们利用开源工具HeyGem将文本式课程大纲转换为视听展示，在其中数字角色以歌曲形式表演课程内容。所提出的方法旨在激发学生的好奇心，促进情感连接，并增强对关键课程信息的记忆。学生反馈表明，AI演唱的课程大纲显著提高了他们对关键课程信息的意识和回忆。', 'title_zh': '使用虚拟 avatar 唱出音节：通过 AI 生成的音乐和数字 embodient 提高学生参与度'}
{'arxiv_id': 'arXiv:2508.11845', 'title': 'What Matters for Bioacoustic Encoding', 'authors': 'Marius Miron, David Robinson, Milad Alizadeh, Ellen Gilsenan-McMahon, Gagan Narula, Olivier Pietquin, Matthieu Geist, Emmanuel Chemla, Maddie Cusimano, Felix Effenberger, Masato Hagiwara, Benjamin Hoffman, Sara Keen, Diane Kim, Jane Lawton, Jen-Yu Liu, Aza Raskin', 'link': 'https://arxiv.org/abs/2508.11845', 'abstract': 'Bioacoustics, the study of sounds produced by living organisms, plays a vital role in conservation, biodiversity monitoring, and behavioral studies. Many tasks in this field, such as species, individual, and behavior classification and detection, are well-suited to machine learning. However, they often suffer from limited annotated data, highlighting the need for a general-purpose bioacoustic encoder capable of extracting useful representations for diverse downstream tasks. Such encoders have been proposed before, but are often limited in scope due to a focus on a narrow range of species (typically birds), and a reliance on a single model architecture or training paradigm. Moreover, they are usually evaluated on a small set of tasks and datasets. In this work, we present a large-scale empirical study that covers aspects of bioacoustics that are relevant to research but have previously been scarcely considered: training data diversity and scale, model architectures and training recipes, and the breadth of evaluation tasks and datasets. We obtain encoders that are state-of-the-art on the existing and proposed benchmarks. We also identify what matters for training these encoders, such that this work can be extended when more data are available or better architectures are proposed. Specifically, across 26 datasets with tasks including species classification, detection, individual ID, and vocal repertoire discovery, we find self-supervised pre-training followed by supervised post-training on a mixed bioacoustics + general-audio corpus yields the strongest in- and out-of-distribution performance. We show the importance of data diversity in both stages. To support ongoing research and application, we will release the model checkpoints.', 'abstract_zh': '生物声学：一种在保育、生物多样性监测及行为研究中发挥关键作用的声音研究领域，机器学习在其中许多任务上表现出色，如物种、个体及行为分类和检测。然而，这些任务往往受限于标注数据的不足，突显出一种通用生物声学编码器的重要性，该编码器能够提取适用于多种下游任务的有用表示。虽然之前已经提出了此类编码器，但通常局限于特定物种（通常是鸟类）且依赖单一的模型架构或训练方法。此外，它们通常仅在少量任务和数据集上进行评估。在本研究中，我们进行了一项大规模实证研究，涵盖了以往较少考虑但对研究至关重要的生物声学方面：训练数据的多样性和规模、模型架构和训练方法，以及评估任务和数据集的广泛性。我们在现有的和提出的基准测试中获得了最先进的编码器，并确定了训练这些编码器的关键因素，以便在更多数据或更好架构可用时能够扩展本工作。具体来说，在包括物种分类、检测、个体识别和声学 repertoire 发现在内的26个数据集中，我们发现自监督预训练后辅以混合生物声学+通用音频语料的监督后训练，能够在域内和域外任务上获得最佳性能。我们展示了两个阶段中数据多样性的关键作用。为了支持持续的研究和应用，我们将发布模型检查点。', 'title_zh': '生物声编码中要考虑的因素'}
{'arxiv_id': 'arXiv:2508.11810', 'title': 'FairTabGen: Unifying Counterfactual and Causal Fairness in Synthetic Tabular Data Generation', 'authors': 'Nitish Nagesh, Salar Shakibhamedan, Mahdi Bagheri, Ziyu Wang, Nima TaheriNejad, Axel Jantsch, Amir M. Rahmani', 'link': 'https://arxiv.org/abs/2508.11810', 'abstract': 'Generating synthetic data is crucial in privacy-sensitive, data-scarce settings, especially for tabular datasets widely used in real-world applications. A key challenge is improving counterfactual and causal fairness, while preserving high utility. We present FairTabGen, a fairness-aware large language model-based framework for tabular synthetic data generation. We integrate multiple fairness definitions including counterfactual and causal fairness into both its generation and evaluation pipelines. We use in-context learning, prompt refinement, and fairness-aware data curation to balance fairness and utility. Across diverse datasets, our method outperforms state-of-the-art GAN-based and LLM-based methods, achieving up to 10% improvements on fairness metrics such as demographic parity and path-specific causal effects while retaining statistical utility. Remarkably, it achieves these gains using less than 20% of the original data, highlighting its efficiency in low-data regimes. These results demonstrate a principled and practical approach for generating fair and useful synthetic tabular data.', 'abstract_zh': '生成合成数据在隐私敏感且数据稀缺的环境中至关重要，尤其是在广泛用于实际应用的表格数据集中。一个关键挑战是提高对抗事实公平性和因果公平性，同时保持高实用性。我们提出了FairTabGen，这是一种基于大型语言模型的公平感知框架，用于表格合成数据生成。我们在其生成和评估管道中整合了多种公平定义，包括对抗事实公平性和因果公平性。我们利用上下文学习、提示 refined 和公平感知的数据管理来平衡公平性和实用性。在多种数据集中，我们的方法在公平性指标如人口统计平和路径特异性因果效应方面优于最先进的基于生成对抗网络（GAN）和基于语言模型（LLM）的方法，同时保持统计实用性。值得注意的是，它在使用不到20%的原始数据的情况下实现了这些改进，突显了其在数据稀缺环境下的效率。这些结果展示了生成公平且有用的合成表格数据的原理性和实用性方法。', 'title_zh': 'FairTabGen: 统一合成表数据生成中的事实和因果公平性'}
{'arxiv_id': 'arXiv:2508.11800', 'title': 'Uncalibrated Reasoning: GRPO Induces Overconfidence for Stochastic Outcomes', 'authors': 'Michael Bereket, Jure Leskovec', 'link': 'https://arxiv.org/abs/2508.11800', 'abstract': 'Reinforcement learning (RL) has proven remarkably effective at improving the accuracy of language models in verifiable and deterministic domains like mathematics. Here, we examine if current RL methods are also effective at optimizing language models in verifiable domains with stochastic outcomes, like scientific experiments. Through applications to synthetic data and real-world biological experiments, we demonstrate that Group Relative Policy Optimization (GRPO) induces overconfident probability predictions for binary stochastic outcomes, while Proximal Policy Optimization (PPO) and REINFORCE Leave-One-Out (RLOO) yield well-calibrated models. We show that removing group standard normalization in GRPO fixes its miscalibration and provide a theoretical explanation for why normalization causes overconfidence. Our results provide new evidence against the use of standard normalization in GRPO and help pave the way for applications of RL for reasoning language models beyond deterministic domains.', 'abstract_zh': '强化学习在具有随机结果的可验证领域（如科学实验）优化语言模型的有效性研究', 'title_zh': '未校准的推理：GRPO 对于随机结果诱导过度自信'}
{'arxiv_id': 'arXiv:2508.11738', 'title': 'Artificial Intelligence in Rural Healthcare Delivery: Bridging Gaps and Enhancing Equity through Innovation', 'authors': 'Kiruthika Balakrishnan, Durgadevi Velusamy, Hana E. Hinkle, Zhi Li, Karthikeyan Ramasamy, Hikmat Khan, Srini Ramaswamy, Pir Masoom Shah', 'link': 'https://arxiv.org/abs/2508.11738', 'abstract': 'Rural healthcare faces persistent challenges, including inadequate infrastructure, workforce shortages, and socioeconomic disparities that hinder access to essential services. This study investigates the transformative potential of artificial intelligence (AI) in addressing these issues in underserved rural areas. We systematically reviewed 109 studies published between 2019 and 2024 from PubMed, Embase, Web of Science, IEEE Xplore, and Scopus. Articles were screened using PRISMA guidelines and Covidence software. A thematic analysis was conducted to identify key patterns and insights regarding AI implementation in rural healthcare delivery. The findings reveal significant promise for AI applications, such as predictive analytics, telemedicine platforms, and automated diagnostic tools, in improving healthcare accessibility, quality, and efficiency. Among these, advanced AI systems, including Multimodal Foundation Models (MFMs) and Large Language Models (LLMs), offer particularly transformative potential. MFMs integrate diverse data sources, such as imaging, clinical records, and bio signals, to support comprehensive decision-making, while LLMs facilitate clinical documentation, patient triage, translation, and virtual assistance. Together, these technologies can revolutionize rural healthcare by augmenting human capacity, reducing diagnostic delays, and democratizing access to expertise. However, barriers remain, including infrastructural limitations, data quality concerns, and ethical considerations. Addressing these challenges requires interdisciplinary collaboration, investment in digital infrastructure, and the development of regulatory frameworks. This review offers actionable recommendations and highlights areas for future research to ensure equitable and sustainable integration of AI in rural healthcare systems.', 'abstract_zh': '农村医疗面临持续性的挑战，包括基础设施不足、人力资源短缺和社会经济差距等，这些都阻碍了获取基本医疗服务。本研究探讨了人工智能（AI）在解决不足服务农村地区问题方面的潜在转变性作用。我们系统回顾了2019年至2024年在PubMed、Embase、Web of Science、IEEE Xplore和Scopus发表的109篇研究文章。文章筛查采用PRISMA指南和Covidence软件。进行了主题分析以确定AI在农村医疗服务实施中的关键模式和见解。研究发现，人工智能应用前景显著，如预测分析、远程医疗平台和自动诊断工具，在提高医疗服务的可及性、质量和效率方面潜力巨大。其中，包括多模态基础模型（MFMs）和大规模语言模型（LLMs）在内的高级AI系统表现出尤为强大的转变性潜力。MFMs整合影像、临床记录和生物信号等多种数据源，支持全面决策，而LLMs则促进临床记录、患者分诊、翻译和虚拟助手功能。这些技术可以重塑农村医疗，通过增强人类能力、减少诊断延误并实现专业知识的普及化。然而，仍存在基础设施限制、数据质量关切和伦理考虑等障碍。克服这些挑战需要跨学科合作、投资数字基础设施并制定监管框架。本综述提供了可操作的建议，并强调了未来研究的重点领域，以确保AI在农村医疗系统中的公平和可持续整合。', 'title_zh': '人工智能在农村医疗保健服务中的应用：通过创新缩小差距并促进公平'}
{'arxiv_id': 'arXiv:2508.11732', 'title': 'BRIEF: BRain-Inspired network connection search with Extensive temporal feature Fusion enhances disease classification', 'authors': 'Xiangxiang Cui, Min Zhao, Dongmei Zhi, Shile Qi, Vince D Calhoun, Jing Sui', 'link': 'https://arxiv.org/abs/2508.11732', 'abstract': "Existing deep learning models for functional MRI-based classification have limitations in network architecture determination (relying on experience) and feature space fusion (mostly simple concatenation, lacking mutual learning). Inspired by the human brain's mechanism of updating neural connections through learning and decision-making, we proposed a novel BRain-Inspired feature Fusion (BRIEF) framework, which is able to optimize network architecture automatically by incorporating an improved neural network connection search (NCS) strategy and a Transformer-based multi-feature fusion module. Specifically, we first extracted 4 types of fMRI temporal representations, i.e., time series (TCs), static/dynamic functional connection (FNC/dFNC), and multi-scale dispersion entropy (MsDE), to construct four encoders. Within each encoder, we employed a modified Q-learning to dynamically optimize the NCS to extract high-level feature vectors, where the NCS is formulated as a Markov Decision Process. Then, all feature vectors were fused via a Transformer, leveraging both stable/time-varying connections and multi-scale dependencies across different brain regions to achieve the final classification. Additionally, an attention module was embedded to improve interpretability. The classification performance of our proposed BRIEF was compared with 21 state-of-the-art models by discriminating two mental disorders from healthy controls: schizophrenia (SZ, n=1100) and autism spectrum disorder (ASD, n=1550). BRIEF demonstrated significant improvements of 2.2% to 12.1% compared to 21 algorithms, reaching an AUC of 91.5% - 0.6% for SZ and 78.4% - 0.5% for ASD, respectively. This is the first attempt to incorporate a brain-inspired, reinforcement learning strategy to optimize fMRI-based mental disorder classification, showing significant potential for identifying precise neuroimaging biomarkers.", 'abstract_zh': '基于人类大脑启发的特征融合框架：自动优化网络架构的BRain-Inspired特征融合（BRIEF）模型', 'title_zh': 'BRISK: BRain-Inspired Network Connection Search with Extensive Temporal Feature Fusion to Enhance Disease Classification'}
{'arxiv_id': 'arXiv:2508.11729', 'title': 'The Stories We Govern By: AI, Risk, and the Power of Imaginaries', 'authors': 'Ninell Oldenburg, Gleb Papyshev', 'link': 'https://arxiv.org/abs/2508.11729', 'abstract': 'This paper examines how competing sociotechnical imaginaries of artificial intelligence (AI) risk shape governance decisions and regulatory constraints. Drawing on concepts from science and technology studies, we analyse three dominant narrative groups: existential risk proponents, who emphasise catastrophic AGI scenarios; accelerationists, who portray AI as a transformative force to be unleashed; and critical AI scholars, who foreground present-day harms rooted in systemic inequality. Through an analysis of representative manifesto-style texts, we explore how these imaginaries differ across four dimensions: normative visions of the future, diagnoses of the present social order, views on science and technology, and perceived human agency in managing AI risks. Our findings reveal how these narratives embed distinct assumptions about risk and have the potential to progress into policy-making processes by narrowing the space for alternative governance approaches. We argue against speculative dogmatism and for moving beyond deterministic imaginaries toward regulatory strategies that are grounded in pragmatism.', 'abstract_zh': '本文研究了不同的人工智能（AI）风险社会技术想象如何塑造治理决策和监管约束。通过科学技术研究的概念，我们分析了三个主要叙述群体：存在风险倡导者，他们强调灾难性超人工智能场景；加速主义者，他们将AI描绘为一种应被释放的变革力量；以及批判性AI学者，他们强调根植于系统不平等的当前危害。通过对代表性的纲领式文本进行分析，我们探讨了这些想象在四个维度上的差异：对未来的规范性愿景、对当前社会秩序的诊断、对科学和技术的看法，以及对管理AI风险的人类能动性的看法。我们的研究发现这些叙述嵌入了不同的风险假设，并有可能通过缩小替代治理途径的空间而进入政策制定过程。我们反对投机性教条主义，提倡转向基于务实主义的监管策略。', 'title_zh': '我们所治理的故事：人工智能、风险与想象的力量'}
{'arxiv_id': 'arXiv:2508.11721', 'title': 'FusionFM: Fusing Eye-specific Foundational Models for Optimized Ophthalmic Diagnosis', 'authors': 'Ke Zou, Jocelyn Hui Lin Goh, Yukun Zhou, Tian Lin, Samantha Min Er Yew, Sahana Srinivasan, Meng Wang, Rui Santos, Gabor M. Somfai, Huazhu Fu, Haoyu Chen, Pearse A. Keane, Ching-Yu Cheng, Yih Chung Tham', 'link': 'https://arxiv.org/abs/2508.11721', 'abstract': 'Foundation models (FMs) have shown great promise in medical image analysis by improving generalization across diverse downstream tasks. In ophthalmology, several FMs have recently emerged, but there is still no clear answer to fundamental questions: Which FM performs the best? Are they equally good across different tasks? What if we combine all FMs together? To our knowledge, this is the first study to systematically evaluate both single and fused ophthalmic FMs. To address these questions, we propose FusionFM, a comprehensive evaluation suite, along with two fusion approaches to integrate different ophthalmic FMs. Our framework covers both ophthalmic disease detection (glaucoma, diabetic retinopathy, and age-related macular degeneration) and systemic disease prediction (diabetes and hypertension) based on retinal imaging. We benchmarked four state-of-the-art FMs (RETFound, VisionFM, RetiZero, and DINORET) using standardized datasets from multiple countries and evaluated their performance using AUC and F1 metrics. Our results show that DINORET and RetiZero achieve superior performance in both ophthalmic and systemic disease tasks, with RetiZero exhibiting stronger generalization on external datasets. Regarding fusion strategies, the Gating-based approach provides modest improvements in predicting glaucoma, AMD, and hypertension. Despite these advances, predicting systemic diseases, especially hypertension in external cohort remains challenging. These findings provide an evidence-based evaluation of ophthalmic FMs, highlight the benefits of model fusion, and point to strategies for enhancing their clinical applicability.', 'abstract_zh': '基础模型在医学图像分析中的应用显示出巨大潜力，通过提高在多样化下游任务中的泛化能力。在眼科，已经涌现出几种基础模型，但仍没有明确的答案来回答基础问题：哪种基础模型表现最好？它们在不同任务中的表现是否相当？如果我们将所有基础模型结合起来会怎样？据我们所知，这是首次系统评估单个和融合眼科基础模型的研究。为了回答这些问题，我们提出了FusionFM，一个完整的评估套件，以及两种融合方法来整合不同的眼科基础模型。我们的框架涵盖了基于视网膜成像的眼科疾病检测（青光眼、糖尿病视网膜病变和年龄相关性黄斑变性）和全身疾病预测（糖尿病和高血压）。我们使用标准化的多国数据集对四种最先进的基础模型（RETFound、VisionFM、RetiZero和DINORET）进行了基准测试，并使用AUC和F1度量评估了它们的性能。研究结果表明，DINORET和RetiZero在眼科和全身疾病任务中均表现出色，RetiZero在外源性数据集上的泛化能力更强。关于融合策略，门控方法在预测青光眼、AMD和高血压方面提供了适度的改进。尽管取得了这些进展，但在外部队列中预测全身疾病，特别是高血压仍具有挑战性。这些发现为眼科基础模型提供了基于证据的评估，突显了模型融合的优势，并指出了增强其临床应用策略的方向。', 'title_zh': 'FusionFM: 结合眼别基础模型以优化眼科诊断'}
{'arxiv_id': 'arXiv:2508.11719', 'title': 'Are AI Machines Making Humans Obsolete?', 'authors': 'Matthias Scheutz', 'link': 'https://arxiv.org/abs/2508.11719', 'abstract': 'This chapter starts with a sketch of how we got to "generative AI" (GenAI) and a brief summary of the various impacts it had so far. It then discusses some of the opportunities of GenAI, followed by the challenges and dangers, including dystopian outcomes resulting from using uncontrolled machine learning and our failures to understand the results. It concludes with some suggestions for how to control GenAI and address its dangers.', 'abstract_zh': '本章从对如何达到“生成型AI”（GenAI）的概述及其到目前为止的各种影响开始，随后讨论了GenAI的一些机遇，接着探讨了相关的挑战和危险，包括因无控制的机器学习和我们未能理解其结果而产生的悲观后果。最后提出了控制GenAI和应对潜在危险的建议。', 'title_zh': '人工智能机器是否会使人类过时？'}
{'arxiv_id': 'arXiv:2508.11716', 'title': 'Privacy-Aware Detection of Fake Identity Documents: Methodology, Benchmark, and Improved Detection Methods (FakeIDet2)', 'authors': 'Javier Muñoz-Haro, Ruben Tolosana, Ruben Vera-Rodriguez, Aythami Morales, Julian Fierrez', 'link': 'https://arxiv.org/abs/2508.11716', 'abstract': "Remote user verification in Internet-based applications is becoming increasingly important nowadays. A popular scenario for it consists of submitting a picture of the user's Identity Document (ID) to a service platform, authenticating its veracity, and then granting access to the requested digital service. An ID is well-suited to verify the identity of an individual, since it is government issued, unique, and nontransferable. However, with recent advances in Artificial Intelligence (AI), attackers can surpass security measures in IDs and create very realistic physical and synthetic fake IDs. Researchers are now trying to develop methods to detect an ever-growing number of these AI-based fakes that are almost indistinguishable from authentic (bona fide) IDs. In this counterattack effort, researchers are faced with an important challenge: the difficulty in using real data to train fake ID detectors. This real data scarcity for research and development is originated by the sensitive nature of these documents, which are usually kept private by the ID owners (the users) and the ID Holders (e.g., government, police, bank, etc.). The main contributions of our study are: 1) We propose and discuss a patch-based methodology to preserve privacy in fake ID detection research. 2) We provide a new public database, FakeIDet2-db, comprising over 900K real/fake ID patches extracted from 2,000 ID images, acquired using different smartphone sensors, illumination and height conditions, etc. In addition, three physical attacks are considered: print, screen, and composite. 3) We present a new privacy-aware fake ID detection method, FakeIDet2. 4) We release a standard reproducible benchmark that considers physical and synthetic attacks from popular databases in the literature.", 'abstract_zh': '基于互联网的应用远程用户验证变得越来越重要。一种常见的场景是提交用户身份文件（ID）的照片，认证其真实性，然后授予请求的数字服务访问权限。身份文件适合验证个人身份，因为它是由政府颁发的、唯一的且不可转移的。然而，随着人工智能（AI）的最新进展，攻击者可以通过超越身份文件的安全措施，创建非常逼真的物理和合成伪造身份文件。研究人员现在正尝试开发方法来检测越来越多的这些基于AI的伪造品，几乎与真实（合法）的身份文件无法区分。在这种防御努力中，研究人员面临着一个重要的挑战：使用真实数据训练伪造身份文件检测器的难度。这种研究和开发中真实数据的稀缺性是由这些文件的敏感性质引起的，通常由身份文件的所有者（用户）和持有人（如政府、警察、银行等）保持私密。我们研究的主要贡献包括：1）我们提出并讨论了一种基于补丁的方法，以在伪造身份文件检测研究中保护隐私。2）我们提供了一个新的公共数据库FakeIDet2-db，包含超过90万张真实/伪造身份文件补丁，来自2000张身份文件图像，使用了不同的智能手机传感器、照明和高度条件等。此外，考虑了三种物理攻击：打印、屏幕和复合。3）我们提出了一种新的具备隐私意识的伪造身份文件检测方法FakeIDet2。4）我们发布了一个标准可重现基准，考虑了文献中流行的数据库中的物理和合成攻击。', 'title_zh': '面向隐私的虚假身份文件检测：方法、基准及改进的检测方法（FakeIDet2）'}
{'arxiv_id': 'arXiv:2508.11710', 'title': 'Code Vulnerability Detection Across Different Programming Languages with AI Models', 'authors': 'Hael Abdulhakim Ali Humran, Ferdi Sonmez', 'link': 'https://arxiv.org/abs/2508.11710', 'abstract': 'Security vulnerabilities present in a code that has been written in diverse programming languages are among the most critical yet complicated aspects of source code to detect. Static analysis tools based on rule-based patterns usually do not work well at detecting the context-dependent bugs and lead to high false positive rates. Recent developments in artificial intelligence, specifically the use of transformer-based models like CodeBERT and CodeLlama, provide light to this problem, as they show potential in finding such flaws better. This paper presents the implementations of these models on various datasets of code vulnerability, showing how off-the-shelf models can successfully produce predictive capacity in models through dynamic fine-tuning of the models on vulnerable and safe code fragments. The methodology comprises the gathering of the dataset, normalization of the language, fine-tuning of the model, and incorporation of ensemble learning and explainable AI. Experiments show that a well-trained CodeBERT can be as good as or even better than some existing static analyzers in terms of accuracy greater than 97%. Further study has indicated that although language models can achieve close-to-perfect recall, the precision can decrease. A solution to this is given by hybrid models and validation procedures, which will reduce false positives. According to the results, the AI-based solutions generalize to different programming languages and classes of vulnerability. Nevertheless, robustness, interpretability, and deployment readiness are still being developed. The results illustrate the probabilities that AI will enhance the trustworthiness in the usability and scalability of machine-learning-based detectors of vulnerabilities.', 'abstract_zh': '基于人工智能的代码漏洞检测方法研究：CodeBERT等模型在代码漏洞数据集上的实现与评价', 'title_zh': '使用AI模型跨不同编程语言检测代码漏洞'}
{'arxiv_id': 'arXiv:2508.11709', 'title': 'Navigating the New Landscape: A Conceptual Model for Project-Based Assessment (PBA) in the Age of GenAI', 'authors': 'Rajan Kadel, Samar Shailendra, Urvashi Rahul Saxena', 'link': 'https://arxiv.org/abs/2508.11709', 'abstract': 'The rapid integration of Generative Artificial Intelligence (GenAI) into higher education presents both opportunities and challenges for assessment design, particularly within Project-Based Assessment (PBA) contexts. Traditional assessment methods often emphasise the final product in the PBA, which can now be significantly influenced or created by GenAI tools, raising concerns regarding product authenticity, academic integrity, and learning validation. This paper advocates for a reimagined assessment model for Project-Based Learning (PBL) or a capstone project that prioritises process-oriented evaluation, multi-modal and multifaceted assessment design, and ethical engagement with GenAI to enable higher-order thinking. The model also emphasises the use of (GenAI-assisted) personalised feedback by a supervisor as an observance of the learning process during the project lifecycle. A use case scenario is provided to illustrate the application of the model in a capstone project setting. The paper concludes with recommendations for educators and curriculum designers to ensure that assessment practices remain robust, learner-centric, and integrity-driven in the evolving landscape of GenAI.', 'abstract_zh': 'Generative Artificial Intelligence驱动的高等教育评估设计：项目-Based学习（PBL）中的机遇与挑战', 'title_zh': '探索新景观：AI时代基于项目的评估（PBA）的概念模型'}
{'arxiv_id': 'arXiv:2508.11708', 'title': 'Street Review: A Participatory AI-Based Framework for Assessing Streetscape Inclusivity', 'authors': 'Rashid Mushkani, Shin Koseki', 'link': 'https://arxiv.org/abs/2508.11708', 'abstract': 'Urban centers undergo social, demographic, and cultural changes that shape public street use and require systematic evaluation of public spaces. This study presents Street Review, a mixed-methods approach that combines participatory research with AI-based analysis to assess streetscape inclusivity. In Montréal, Canada, 28 residents participated in semi-directed interviews and image evaluations, supported by the analysis of approximately 45,000 street-view images from Mapillary. The approach produced visual analytics, such as heatmaps, to correlate subjective user ratings with physical attributes like sidewalk, maintenance, greenery, and seating. Findings reveal variations in perceptions of inclusivity and accessibility across demographic groups, demonstrating that incorporating diverse user feedback can enhance machine learning models through careful data-labeling and co-production strategies. The Street Review framework offers a systematic method for urban planners and policy analysts to inform planning, policy development, and management of public streets.', 'abstract_zh': '城市中心的社会、人口和文化变迁塑造了公共街道的使用方式，需要对公共空间进行系统评估。本文介绍了Street Review这一混合方法，结合了参与式研究与基于AI的分析，以评估街道的包容性。在加拿大蒙特利尔，28名居民参与了半引导式访谈和图像评估，分析了来自Mapillary的约45,000张街景图像。该方法产生了视觉分析，如热力图，将用户主观评价与人行道、维护、绿化和座椅等物理属性相关联。研究发现不同人口群体对包容性和可达性的感知存在差异，表明通过精心的数据标注和共同生产策略 Incorporate diverse user feedback 可以增强机器学习模型。Street Review框架为城市规划者和政策分析师提供了一种系统方法，以指导公共街道的规划、政策制定和管理。', 'title_zh': '街道审查：一个参与式的基于人工智能的评估街道景观包容性框架'}
{'arxiv_id': 'arXiv:2508.11706', 'title': 'Centralized Permutation Equivariant Policy for Cooperative Multi-Agent Reinforcement Learning', 'authors': 'Zhuofan Xu, Benedikt Bollig, Matthias Függer, Thomas Nowak, Vincent Le Dréau', 'link': 'https://arxiv.org/abs/2508.11706', 'abstract': 'The Centralized Training with Decentralized Execution (CTDE) paradigm has gained significant attention in multi-agent reinforcement learning (MARL) and is the foundation of many recent algorithms. However, decentralized policies operate under partial observability and often yield suboptimal performance compared to centralized policies, while fully centralized approaches typically face scalability challenges as the number of agents increases.\nWe propose Centralized Permutation Equivariant (CPE) learning, a centralized training and execution framework that employs a fully centralized policy to overcome these limitations. Our approach leverages a novel permutation equivariant architecture, Global-Local Permutation Equivariant (GLPE) networks, that is lightweight, scalable, and easy to implement. Experiments show that CPE integrates seamlessly with both value decomposition and actor-critic methods, substantially improving the performance of standard CTDE algorithms across cooperative benchmarks including MPE, SMAC, and RWARE, and matching the performance of state-of-the-art RWARE implementations.', 'abstract_zh': '集中式训练与分布式执行（CTDE）范式在多智能体强化学习（MARL）中获得了显著关注，并成为许多近期算法的基础。然而，分布式策略在部分可观性条件下运作，往往导致性能低于集中式策略，而完全集中式方法通常会随着智能体数量的增加面临可扩展性挑战。我们提出了一种名为集中式置换不变学习（CPE）的方法，这是一种集中式训练和执行框架，利用完全集中式策略来克服这些限制。我们的方法采用了一种新颖的轻量级、可扩展且易于实现的置换不变架构——全局-局部置换不变网络（GLPE）网络。实验表明，CPE 能够无缝集成价值分解和演员-评论家方法，显著提高了标准 CTDE 算法在包括MPE、SMAC和RWARE在内的合作基准测试中的性能，并达到了最先进的RWARE实现的性能水平。', 'title_zh': '集中化排列等变策略在协作多智能体强化学习中的应用'}
{'arxiv_id': 'arXiv:2508.11704', 'title': 'Next-Gen Education: Enhancing AI for Microlearning', 'authors': 'Suman Saha, Fatemeh Rahbari, Farhan Sadique, Sri Krishna Chaitanya Velamakanni, Mahfuza Farooque, William J. Rothwell', 'link': 'https://arxiv.org/abs/2508.11704', 'abstract': 'This paper explores integrating microlearning strategies into university curricula, particularly in computer science education, to counteract the decline in class attendance and engagement in US universities after COVID. As students increasingly opt for remote learning and recorded lectures, traditional educational approaches struggle to maintain engagement and effectiveness. Microlearning, which breaks complex subjects into manageable units, is proposed to address shorter attention spans and enhance educational outcomes. It uses interactive formats such as videos, quizzes, flashcards, and scenario-based exercises, which are especially beneficial for topics like algorithms and programming logic requiring deep understanding and ongoing practice. Adoption of microlearning is often limited by the effort needed to create such materials. This paper proposes leveraging AI tools, specifically ChatGPT, to reduce the workload for educators by automating the creation of supplementary materials. While AI can automate certain tasks, educators remain essential in guiding and shaping the learning process. This AI-enhanced approach ensures course content is kept current with the latest research and technology, with educators providing context and insights. By examining AI capabilities in microlearning, this study shows the potential to transform educational practices and outcomes in computer science, offering a practical model for combining advanced technology with established teaching methods.', 'abstract_zh': '本文探讨将微学习策略融入大学课程，特别是在计算机科学教育中，以应对COVID之后美国大学课堂出勤率和参与度下降的问题。随着学生越来越多地选择远程学习和录播课程，传统的教育方法难以维持参与度和有效性。微学习通过将复杂科目拆分成 manageable 单元，来应对注意力短暂的问题并提升教育成果。它使用诸如视频、测验、闪卡和情景练习等交互式格式，特别适合需要深刻理解和持续练习的算法和编程逻辑等主题。微学习的采用常受限于创建这些材料所需的努力。本文提出利用AI工具，特别是ChatGPT，来减轻教育者的负担，自动化生成补充材料。尽管AI能够自动化某些任务，教育者仍然是引导和塑造学习过程的关键。通过利用AI在微学习中的能力，本文展示了如何通过将先进技术与传统教学方法相结合，来变革计算机科学教育的实践和成果，提供了一种实用的结合方法。', 'title_zh': '下一代教育：增强微学习的AI'}
{'arxiv_id': 'arXiv:2508.11693', 'title': 'Track Component Failure Detection Using Data Analytics over existing STDS Track Circuit data', 'authors': 'Francisco López, Eduardo Di Santi, Clément Lefebvre, Nenad Mijatovic, Michele Pugnaloni, Victor Martín, Kenza Saiah', 'link': 'https://arxiv.org/abs/2508.11693', 'abstract': 'Track Circuits (TC) are the main signalling devices used to detect the presence of a train on a rail track. It has been used since the 19th century and nowadays there are many types depending on the technology. As a general classification, Track Circuits can be divided into 2 main groups, DC (Direct Current) and AC (Alternating Current) circuits. This work is focused on a particular AC track circuit, called "Smart Train Detection System" (STDS), designed with both high and low-frequency bands. This approach uses STDS current data applied to an SVM (support vector machine) classifier as a type of failure identifier. The main purpose of this work consists on determine automatically which is the component of the track that is failing to improve the maintenance action. Model was trained to classify 15 different failures that belong to 3 more general categories. The method was tested with field data from 10 different track circuits and validated by the STDS track circuit expert and maintainers. All use cases were correctly classified by the method.', 'abstract_zh': '基于支持向量机的智能列车检测系统在轨电路中的故障识别研究', 'title_zh': '基于现有STDS轨道电路数据的数据分析用于检测轨道组件故障'}
{'arxiv_id': 'arXiv:2508.11692', 'title': 'Scalable, Technology-Agnostic Diagnosis and Predictive Maintenance for Point Machine using Deep Learning', 'authors': 'Eduardo Di Santi, Ruixiang Ci, Clément Lefebvre, Nenad Mijatovic, Michele Pugnaloni, Jonathan Brown, Victor Martín, Kenza Saiah', 'link': 'https://arxiv.org/abs/2508.11692', 'abstract': 'The Point Machine (PM) is a critical piece of railway equipment that switches train routes by diverting tracks through a switchblade. As with any critical safety equipment, a failure will halt operations leading to service disruptions; therefore, pre-emptive maintenance may avoid unnecessary interruptions by detecting anomalies before they become failures. Previous work relies on several inputs and crafting custom features by segmenting the signal. This not only adds additional requirements for data collection and processing, but it is also specific to the PM technology, the installed locations and operational conditions limiting scalability. Based on the available maintenance records, the main failure causes for PM are obstacles, friction, power source issues and misalignment. Those failures affect the energy consumption pattern of PMs, altering the usual (or healthy) shape of the power signal during the PM movement. In contrast to the current state-of-the-art, our method requires only one input. We apply a deep learning model to the power signal pattern to classify if the PM is nominal or associated with any failure type, achieving >99.99\\% precision, <0.01\\% false positives and negligible false negatives. Our methodology is generic and technology-agnostic, proven to be scalable on several electromechanical PM types deployed in both real-world and test bench environments. Finally, by using conformal prediction the maintainer gets a clear indication of the certainty of the system outputs, adding a confidence layer to operations and making the method compliant with the ISO-17359 standard.', 'abstract_zh': '基于电力信号模式的点机故障检测方法', 'title_zh': '基于深度学习的点式设备可扩展且技术无关的诊断与预测性维护'}
{'arxiv_id': 'arXiv:2508.11691', 'title': 'Towards Generalizable Learning Models for EEG-Based Identification of Pain Perception', 'authors': 'Mathis Rezzouk, Fabrice Gagnon, Alyson Champagne, Mathieu Roy, Philippe Albouy, Michel-Pierre Coll, Cem Subakan', 'link': 'https://arxiv.org/abs/2508.11691', 'abstract': 'EEG-based analysis of pain perception, enhanced by machine learning, reveals how the brain encodes pain by identifying neural patterns evoked by noxious stimulation. However, a major challenge that remains is the generalization of machine learning models across individuals, given the high cross-participant variability inherent to EEG signals and the limited focus on direct pain perception identification in current research. In this study, we systematically evaluate the performance of cross-participant generalization of a wide range of models, including traditional classifiers and deep neural classifiers for identifying the sensory modality of thermal pain and aversive auditory stimulation from EEG recordings. Using a novel dataset of EEG recordings from 108 participants, we benchmark model performance under both within- and cross-participant evaluation settings. Our findings show that traditional models suffered the largest drop from within- to cross-participant performance, while deep learning models proved more resilient, underscoring their potential for subject-invariant EEG decoding. Even though performance variability remained high, the strong results of the graph-based model highlight its potential to capture subject-invariant structure in EEG signals. On the other hand, we also share the preprocessed dataset used in this study, providing a standardized benchmark for evaluating future algorithms under the same generalization constraints.', 'abstract_zh': '基于EEG的疼痛感知分析，通过机器学习增强，揭示了大脑如何编码疼痛，包括识别由有害刺激引起的神经模式。然而，一个主要挑战是机器学习模型在不同个体间的泛化能力，这归因于EEG信号固有的高个体间变异性，以及当前研究中对直接疼痛感知识别的有限关注。在这项研究中，我们系统地评估了多种模型在不同个体间的泛化性能，包括传统分类器和深度神经分类器，用于从EEG记录中识别热痛和令人不悦的听觉刺激的感觉模式。我们使用来自108名参与者的新型EEG记录数据集，在不同个体内的评价和不同个体间的评价设置下对模型性能进行了基准测试。研究结果表明，传统模型从不同个体内的性能下降最大，而深度学习模型表现更为稳定，突显了其在EEG解码中的潜在价值。尽管性能变化仍然很高，基于图的模型的强结果表明了其捕捉EEG信号中不变结构的潜力。此外，我们还分享了在本次研究中使用的预处理数据集，为在相同泛化约束条件下评估未来算法提供了标准化基准。', 'title_zh': '基于EEG的疼痛感知识别的可泛化学习模型研究'}
{'arxiv_id': 'arXiv:2508.11689', 'title': 'Adaptive Spiking with Plasticity for Energy Aware Neuromorphic Systems', 'authors': 'Eduardo Calle-Ortiz, Hui Guan, Deepak Ganesan, Phuc Nguyen', 'link': 'https://arxiv.org/abs/2508.11689', 'abstract': "This paper presents ASPEN, a novel energy-aware technique for neuromorphic systems that could unleash the future of intelligent, always-on, ultra-low-power, and low-burden wearables. Our main research objectives are to explore the feasibility of neuromorphic computing for wearables, identify open research directions, and demonstrate the feasibility of developing an adaptive spiking technique for energy-aware computation, which can be game-changing for resource-constrained devices in always-on applications. As neuromorphic computing systems operate based on spike events, their energy consumption is closely related to spiking activity, i.e., each spike incurs computational and power costs; consequently, minimizing the number of spikes is a critical strategy for operating under constrained energy budgets. To support this goal, ASPEN utilizes stochastic perturbations to the neuronal threshold during training to not only enhance the network's robustness across varying thresholds, which can be controlled at inference time, but also act as a regularizer that improves generalization, reduces spiking activity, and enables energy control without the need for complex retraining or pruning. More specifically, ASPEN adaptively adjusts intrinsic neuronal parameters as a lightweight and scalable technique for dynamic energy control without reconfiguring the entire model. Our evaluation on neuromorphic emulator and hardware shows that ASPEN significantly reduces spike counts and energy consumption while maintaining accuracy comparable to state-of-the-art methods.", 'abstract_zh': 'ASPEN：一种面向可穿戴设备的新型能效感知神经形态技术', 'title_zh': '适应性脉冲与可塑性机制在节能类脑系统中的应用'}
{'arxiv_id': 'arXiv:2508.11682', 'title': 'Age-Normalized HRV Features for Non-Invasive Glucose Prediction: A Pilot Sleep-Aware Machine Learning Study', 'authors': 'Md Basit Azam, Sarangthem Ibotombi Singh', 'link': 'https://arxiv.org/abs/2508.11682', 'abstract': 'Non-invasive glucose monitoring remains a critical challenge in the management of diabetes. HRV during sleep shows promise for glucose prediction however, age-related autonomic changes significantly confound traditional HRV analyses. We analyzed 43 subjects with multi-modal data including sleep-stage specific ECG, HRV features, and clinical measurements. A novel age-normalization technique was applied to the HRV features by, dividing the raw values by age-scaled factors. BayesianRidge regression with 5-fold cross-validation was employed for log-glucose prediction. Age-normalized HRV features achieved R2 = 0.161 (MAE = 0.182) for log-glucose prediction, representing a 25.6% improvement over non-normalized features (R2 = 0.132). The top predictive features were hrv rem mean rr age normalized (r = 0.443, p = 0.004), hrv ds mean rr age normalized (r = 0.438, p = 0.005), and diastolic blood pressure (r = 0.437, p = 0.005). Systematic ablation studies confirmed age-normalization as the critical component, with sleep-stage specific features providing additional predictive value. Age-normalized HRV features significantly enhance glucose prediction accuracy compared with traditional approaches. This sleep-aware methodology addresses fundamental limitations in autonomic function assessment and suggests a preliminary feasibility for non-invasive glucose monitoring applications. However, these results require validation in larger cohorts before clinical consideration.', 'abstract_zh': '非侵入性血糖监测在糖尿病管理中仍是一个关键挑战。睡眠期间的HRV有潜力用于血糖预测，然而随着年龄相关的自主神经系统变化显著干扰了传统的HRV分析。我们在43名具有多模态数据的受试者中进行了分析，这些数据包括睡眠阶段特特-specific ECG、HRV特征和和 及临床测量。 E我们将HRV特征进行了年龄标准化处理，即将原始值除以年龄缩放因素。我们采用了包含5五折交叉验证的贝叶斯回归方法来进行长时时间期血糖预测。年龄标准化的HRV特征 E E= 0.6 E 比非年龄标准化特征提高了长 E期血糖预测性能（R  =  0.833）。预测特征包括REM睡眠期间的年龄标准化HRV (r =  0.441  P  =  5)、深睡眠期间的年龄标准化HRV (r =  438  E  =  4) E 和 和舒张压 E压血压 (r =  433  = 4)。系统系统系统系统的剔除研究确认了睡眠阶段特定特征的重要性，它们提供了额外的预测价值。年龄标准化的HRV特征显著提高了血糖预测精度 E E相较于传统方法。这种睡眠意识的方法为基础 E E E自主功能评估带来了根本局限性 E � 且初步表明非侵入性 E E E E血糖监测具有可行性可行性。然而这些结果需要在更大的人群中进行验证以利于临床应用。', 'title_zh': '基于年龄标准化的心率变异特征的无侵入性血糖预测：一项睡眠感知机器学习 pilot 研究'}
{'arxiv_id': 'arXiv:2508.11681', 'title': 'Future progress in artificial intelligence: A survey of expert opinion', 'authors': 'Vincent C. Müller, Nick Bostrom', 'link': 'https://arxiv.org/abs/2508.11681', 'abstract': "There is, in some quarters, concern about high-level machine intelligence and superintelligent AI coming up in a few decades, bringing with it significant risks for humanity. In other quarters, these issues are ignored or considered science fiction. We wanted to clarify what the distribution of opinions actually is, what probability the best experts currently assign to high-level machine intelligence coming up within a particular time-frame, which risks they see with that development, and how fast they see these developing. We thus designed a brief questionnaire and distributed it to four groups of experts in 2012/2013. The median estimate of respondents was for a one in two chance that high-level machine intelligence will be developed around 2040-2050, rising to a nine in ten chance by 2075. Experts expect that systems will move on to superintelligence in less than 30 years thereafter. They estimate the chance is about one in three that this development turns out to be 'bad' or 'extremely bad' for humanity.", 'abstract_zh': '关于高级机器智能和超智能AI在未来几十年内出现的风险与专家观点的问卷调查研究', 'title_zh': '未来人工智能的发展进展：专家意见综述'}
{'arxiv_id': 'arXiv:2508.11680', 'title': 'Comparative Analysis of Time Series Foundation Models for Demographic Forecasting: Enhancing Predictive Accuracy in US Population Dynamics', 'authors': 'Aditya Akella, Jonathan Farah', 'link': 'https://arxiv.org/abs/2508.11680', 'abstract': 'Demographic shifts, influenced by globalization, economic conditions, geopolitical events, and environmental factors, pose significant challenges for policymakers and researchers. Accurate demographic forecasting is essential for informed decision-making in areas such as urban planning, healthcare, and economic policy. This study explores the application of time series foundation models to predict demographic changes in the United States using datasets from the U.S. Census Bureau and Federal Reserve Economic Data (FRED). We evaluate the performance of the Time Series Foundation Model (TimesFM) against traditional baselines including Long Short-Term Memory (LSTM) networks, Autoregressive Integrated Moving Average (ARIMA), and Linear Regression. Our experiments across six demographically diverse states demonstrate that TimesFM achieves the lowest Mean Squared Error (MSE) in 86.67% of test cases, with particularly strong performance on minority populations with sparse historical data. These findings highlight the potential of pre-trained foundation models to enhance demographic analysis and inform proactive policy interventions without requiring extensive task-specific fine-tuning.', 'abstract_zh': '全球化、经济条件、地缘政治事件和环境因素影响下的人口结构变化对政策制定者和研究人员提出了重大挑战。准确的人口预测对于城市规划、卫生保健和经济政策领域的明智决策至关重要。本研究探讨了使用美国人口普查局和联邦储备经济数据（FRED）数据集，将时间序列基础模型应用于预测美国的人口变化。我们将时间序列基础模型（TimesFM）的性能与传统的长短期记忆（LSTM）网络、自回归整合移动平均（ARIMA）和线性回归等基线模型进行评估。我们的实验结果表明，TimesFM在86.67%的测试案例中实现了最低的均方误差（MSE），特别是在历史数据稀疏的少数群体表现尤为突出。这些发现突显了预训练基础模型在增强人口分析和指导前瞻性政策干预方面的潜力，无需进行大量特定任务的微调。', 'title_zh': '时间序列基础模型在人口动态预测中的比较分析：增强美国人口动力学预测准确性'}
{'arxiv_id': 'arXiv:2508.11674', 'title': 'Learning Internal Biological Neuron Parameters and Complexity-Based Encoding for Improved Spiking Neural Networks Performance', 'authors': 'Zofia Rudnicka, Janusz Szczepanski, Agnieszka Pregowska', 'link': 'https://arxiv.org/abs/2508.11674', 'abstract': "This study introduces a novel approach by replacing the traditional perceptron neuron model with a biologically inspired probabilistic meta neuron, where the internal neuron parameters are jointly learned, leading to improved classification accuracy of spiking neural networks (SNNs). To validate this innovation, we implement and compare two SNN architectures: one based on standard leaky integrate-and-fire (LIF) neurons and another utilizing the proposed probabilistic meta neuron model. As a second key contribution, we present a new biologically inspired classification framework that uniquely integrates SNNs with Lempel-Ziv complexity (LZC) a measure closely related to entropy rate. By combining the temporal precision and biological plausibility of SNNs with the capacity of LZC to capture structural regularity, the proposed approach enables efficient and interpretable classification of spatiotemporal neural data, an aspect not addressed in existing works. We consider learning algorithms such as backpropagation, spike-timing-dependent plasticity (STDP), and the Tempotron learning rule. To explore neural dynamics, we use Poisson processes to model neuronal spike trains, a well-established method for simulating the stochastic firing behavior of biological neurons. Our results reveal that depending on the training method, the classifier's efficiency can improve by up to 11.00%, highlighting the advantage of learning additional neuron parameters beyond the traditional focus on weighted inputs alone.", 'abstract_zh': '本研究介绍了一种新颖的方法，通过用生物启发的概率元神经元替代传统的感知器神经元模型，并共同学习内部神经元参数，提高了神经元脉冲网络（SNN）的分类准确性。为了验证这一创新，我们实现了并比较了两种SNN架构：一种基于标准泄漏积分-放电（LIF）神经元，另一种利用所提出的概率元神经元模型。作为第二个重要贡献，我们提出了一种新的生物启发分类框架，该框架独特地将SNN与Lempel-Ziv复杂度（LZC，与熵率密切相关的度量）相结合。通过将SNN的时间精确性和生物可行性与LZC捕捉结构规律的能力结合起来，所提出的方法能够有效地对时空神经数据进行分类和解释，这是现有工作中未曾涉及的方面。我们考虑了反向传播、突触定时依赖可塑性（STDP）和Tempotron学习规则等学习算法。为了探索神经动力学，我们使用泊松过程来模拟神经元脉冲序列，这是一种广泛用于模拟生物神经元随机放电行为的成熟方法。我们的结果显示，根据训练方法的不同，分类器的效率最多可提高11.00%，突显了学习超过传统加权输入的额外神经元参数的优势。', 'title_zh': '基于内部生物神经元参数和 复杂性编码的学习以改善脉冲神经网络性能 yabody'}
{'arxiv_id': 'arXiv:2508.11672', 'title': 'Revealing Neurocognitive and Behavioral Patterns by Unsupervised Manifold Learning from Dynamic Brain Data', 'authors': 'Zixia Zhou, Junyan Liu, Wei Emma Wu, Ruogu Fang, Sheng Liu, Qingyue Wei, Rui Yan, Yi Guo, Qian Tao, Yuanyuan Wang, Md Tauhidul Islam, Lei Xing', 'link': 'https://arxiv.org/abs/2508.11672', 'abstract': 'Dynamic brain data, teeming with biological and functional insights, are becoming increasingly accessible through advanced measurements, providing a gateway to understanding the inner workings of the brain in living subjects. However, the vast size and intricate complexity of the data also pose a daunting challenge in reliably extracting meaningful information across various data sources. This paper introduces a generalizable unsupervised deep manifold learning for exploration of neurocognitive and behavioral patterns. Unlike existing methods that extract patterns directly from the input data as in the existing methods, the proposed Brain-dynamic Convolutional-Network-based Embedding (BCNE) seeks to capture the brain-state trajectories by deciphering the temporospatial correlations within the data and subsequently applying manifold learning to this correlative representation. The performance of BCNE is showcased through the analysis of several important dynamic brain datasets. The results, both visual and quantitative, reveal a diverse array of intriguing and interpretable patterns. BCNE effectively delineates scene transitions, underscores the involvement of different brain regions in memory and narrative processing, distinguishes various stages of dynamic learning processes, and identifies differences between active and passive behaviors. BCNE provides an effective tool for exploring general neuroscience inquiries or individual-specific patterns.', 'abstract_zh': '动态脑数据富含生物和功能性的见解，通过先进的测量手段变得日益可用，为理解活体对象脑部工作机制提供了通道。然而，数据的庞大体量及其复杂的结构也给从各种数据源中可靠地提取有意义的信息带来了巨大挑战。本文介绍了一种可泛化的无监督深度流形学习方法，用于探索神经认知和行为模式。与现有方法直接从输入数据中提取模式不同，所提出的动态卷积网络嵌入（BCNE）旨在通过破解数据中的时空间相关性来捕获脑状态轨迹，并随后应用流形学习于这种相关表示中。通过对几个重要的动态脑数据集进行分析，BCNE展示了其性能。视觉和定量的结果揭示了一系列引人入胜且可解释的模式。BCNE有效地界定了场景转换，突出了不同脑区在记忆和叙事处理中的参与，区分了动态学习过程的不同阶段，并识别了主动行为与被动行为之间的差异。BCNE提供了一个有效工具，用于探索一般神经科学问题或个体特异性模式。', 'title_zh': '揭示动态脑数据无监督流形学习中的神经认知和行为模式'}
{'arxiv_id': 'arXiv:2508.11670', 'title': 'RRRA: Resampling and Reranking through a Retriever Adapter', 'authors': 'Bongsu Kim', 'link': 'https://arxiv.org/abs/2508.11670', 'abstract': 'In dense retrieval, effective training hinges on selecting high quality hard negatives while avoiding false negatives. Recent methods apply heuristics based on positive document scores to identify hard negatives, improving both performance and interpretability. However, these global, example agnostic strategies often miss instance specific false negatives. To address this, we propose a learnable adapter module that monitors Bi-Encoder representations to estimate the likelihood that a hard negative is actually a false negative. This probability is modeled dynamically and contextually, enabling fine-grained, query specific judgments. The predicted scores are used in two downstream components: (1) resampling, where negatives are reweighted during training, and (2) reranking, where top-k retrieved documents are reordered at inference. Empirical results on standard benchmarks show that our adapter-enhanced framework consistently outperforms strong Bi-Encoder baselines, underscoring the benefit of explicit false negative modeling in dense retrieval.', 'abstract_zh': '在密集检索中，有效的训练依赖于选择高质量的负样本同时避免错误的负样本。近期的方法通过正文档分数的启发式方法来识别负样本，从而提高性能和可解释性。然而，这些全局且独立于样本的方法往往忽略了实例特定的错误负样本。为解决这一问题，我们提出一个可学习的适配器模块，该模块监控双编码器表示以估计一个硬负样本实际上是错误负样本的可能性。这种概率被动态和上下文地建模，从而能够进行细粒度的、查询特定的判断。预测得分被用于两个下游组件：(1) 重采样，在训练过程中重新加权负样本，(2) 重新排序，在推理时重新排列检索到的前k个文档。标准基准上的实验证明，我们的适配器增强框架一致地优于强大的双编码器基线，强调了在密集检索中明确建模错误负样本的益处。', 'title_zh': 'RRRA：通过检索适配器进行重采样和重排序'}
{'arxiv_id': 'arXiv:2508.11669', 'title': 'Collaborative Learning-Enhanced Lightweight Models for Predicting Arterial Blood Pressure Waveform in a Large-scale Perioperative Dataset', 'authors': 'Wentao Li, Yonghu He, Kun Gao, Qing Liu, Yali Zheng', 'link': 'https://arxiv.org/abs/2508.11669', 'abstract': 'Noninvasive arterial blood pressure (ABP) monitoring is essential for patient management in critical care and perioperative settings, providing continuous assessment of cardiovascular hemodynamics with minimal risks. Numerous deep learning models have developed to reconstruct ABP waveform from noninvasively acquired physiological signals such as electrocardiogram and photoplethysmogram. However, limited research has addressed the issue of model performance and computational load for deployment on embedded systems. The study introduces a lightweight sInvResUNet, along with a collaborative learning scheme named KDCL_sInvResUNet. With only 0.89 million parameters and a computational load of 0.02 GFLOPS, real-time ABP estimation was successfully achieved on embedded devices with an inference time of just 8.49 milliseconds for a 10-second output. We performed subject-independent validation in a large-scale and heterogeneous perioperative dataset containing 1,257,141 data segments from 2,154 patients, with a wide BP range (41-257 mmHg for SBP, and 31-234 mmHg for DBP). The proposed KDCL_sInvResUNet achieved lightly better performance compared to large models, with a mean absolute error of 10.06 mmHg and mean Pearson correlation of 0.88 in tracking ABP changes. Despite these promising results, all deep learning models showed significant performance variations across different demographic and cardiovascular conditions, highlighting their limited ability to generalize across such a broad and diverse population. This study lays a foundation work for real-time, unobtrusive ABP monitoring in real-world perioperative settings, providing baseline for future advancements in this area.', 'abstract_zh': '非侵入性动脉血压（ABP）监测在重症监护和围手术期环境中至关重要，能够提供心血管 hemodynamics 的连续评估，并具有最小的风险。已开发了多种深度学习模型从心电图和光电脉搏图等非侵入性获取的生理信号中重构 ABP 波形。然而，有限的研究关注了在嵌入式系统上部署时模型性能和计算负载的问题。本研究介绍了轻量级 sInvResUNet，并提出了一种协作学习方案 KDCL_sInvResUNet。仅含 0.89 百万参数和计算负载为 0.02 GFLOPS 的情况下，成功在嵌入式设备上实现了实时 ABP 估计，推理时间为 8.49 毫秒（用于 10 秒输出）。我们在包含来自 2154 名患者、共 1,257,141 个数据段的大规模和异质围手术期数据集上进行了跨受试者验证，收缩压（SBP）和舒张压（DBP）范围广泛（41-257 mmHg 和 31-234 mmHg）。所提出的 KDCL_sInvResUNet 在跟踪 ABP 变化方面的表现略优于大型模型，平均绝对误差为 10.06 mmHg，平均皮尔逊相关系数为 0.88。尽管取得了这些有希望的结果，但所有深度学习模型在不同的人口统计学和心血管条件下均显示出显著的性能差异，突显了其在如此广泛和多样的人群中泛化的局限性。本研究为实际围手术期环境中实现实时、不干扰的 ABP 监测奠定了基础，并提供了该领域未来发展的基准。', 'title_zh': '协作学习增强的轻量级模型在大规模围手术期数据集中预测动脉血流动力学波形'}
{'arxiv_id': 'arXiv:2508.11667', 'title': 'Assessing Representation Stability for Transformer Models', 'authors': 'Bryan E. Tuck, Rakesh M. Verma', 'link': 'https://arxiv.org/abs/2508.11667', 'abstract': 'Adversarial text attacks remain a persistent threat to transformer models, yet existing defenses are typically attack-specific or require costly model retraining. We introduce Representation Stability (RS), a model-agnostic detection framework that identifies adversarial examples by measuring how embedding representations change when important words are masked. RS first ranks words using importance heuristics, then measures embedding sensitivity to masking top-k critical words, and processes the resulting patterns with a BiLSTM detector. Experiments show that adversarially perturbed words exhibit disproportionately high masking sensitivity compared to naturally important words. Across three datasets, three attack types, and two victim models, RS achieves over 88% detection accuracy and demonstrates competitive performance compared to existing state-of-the-art methods, often at lower computational cost. Using Normalized Discounted Cumulative Gain (NDCG) to measure perturbation identification quality, we reveal that gradient-based ranking outperforms attention and random selection approaches, with identification quality correlating with detection performance for word-level attacks. RS also generalizes well to unseen datasets, attacks, and models without retraining, providing a practical solution for adversarial text detection.', 'abstract_zh': 'Adversarial 文本攻击依然对变换器模型构成持续威胁，现有的防御方法通常是针对特定攻击或需要昂贵的模型重新训练。我们引入了一种模型无关的检测框架——表示稳定（Representation Stability，RS），通过测量重要词语被遮掩时嵌入表示的变化来识别对抗样本。RS 首先使用重要性启发式对词语进行排序，然后测量遮掩前 k 个关键词语时嵌入的敏感度，并使用双向 LSTM 检测器处理生成的模式。实验表明，对抗性扰动的词语相比于自然重要的词语，表现出不成比例的高遮掩敏感度。在三个数据集、三种攻击类型和两种受害者模型上，RS 的检测准确率超过 88%，并在计算成本较低的情况下展现出与现有最先进方法相当的性能。使用归一化折现累积增益（NDCG）衡量扰动识别质量，我们发现梯度基排名方法优于注意力和随机选择方法，识别质量与检测性能呈正相关，尤其是在单词级攻击中。此外，RS 能够对未见过的数据集、攻击和模型进行良好的泛化，无需重新训练，提供了一种实用的对抗文本检测解决方案。', 'title_zh': '评估Transformer模型的表示稳定性'}
{'arxiv_id': 'arXiv:2508.11662', 'title': 'Generative AI in Training and Coaching: Redefining the Design Process of Learning Materials', 'authors': 'Alexander Komar, Marc-André Heidelmann, Kristina Schaaff', 'link': 'https://arxiv.org/abs/2508.11662', 'abstract': 'Generative artificial intelligence (GenAI) is transforming education, redefining the role of trainers and coaches in learning environments. In our study, we explore how AI integrates into the design process of learning materials, assessing its impact on efficiency, pedagogical quality, and the evolving role of human trainers and coaches. Through qualitative interviews with professionals in education and corporate training, we identify the following key topics: trainers and coaches increasingly act as facilitators and content moderators rather than primary creators, efficiency gains allow for a stronger strategic focus but at the same time the new tools require new skills. Additionally, we analyze how the anthropomorphism of AI shapes user trust and expectations. From these insights, we derive how tools based on GenAI can successfully be implemented for trainers and coaches on an individual, organizational, systemic, and strategic level.', 'abstract_zh': '生成人工智能（GenAI）正在变革教育，重新定义培训师和教练在学习环境中的角色。在我们的研究中，我们探讨AI如何融入学习材料的设计过程，评估其对效率、教学质量以及人类培训师和教练角色演变的影响。通过与教育和企业培训专业人士的定性访谈，我们确定了以下关键主题：培训师和教练越来越多地充当协调员和内容审查员，而不是主要内容创作者；效率提升使得战略重点更清晰，但同时也需要新的技能。此外，我们分析了人工智能拟人化如何影响用户信任和期望。从这些洞察中，我们推导出如何在个体、组织、系统和战略层面成功实施基于GenAI的工具。', 'title_zh': '生成式人工智能在训练与 coaching 中的应用：重塑学习材料设计过程'}
{'arxiv_id': 'arXiv:2508.11647', 'title': 'Categorical Construction of Logically Verifiable Neural Architectures', 'authors': 'Logan Nye', 'link': 'https://arxiv.org/abs/2508.11647', 'abstract': "Neural networks excel at pattern recognition but struggle with reliable logical reasoning, often violating basic logical principles during inference. We address this limitation by developing a categorical framework that systematically constructs neural architectures with provable logical guarantees. Our approach treats logical theories as algebraic structures called Lawvere theories, which we transform into neural networks using categorical algebra in the 2-category of parametric maps. Unlike existing methods that impose logical constraints during training, our categorical construction embeds logical principles directly into the network's architectural structure, making logical violations mathematically impossible. We demonstrate this framework by constructing differentiable neural architectures for propositional logic that preserve boolean reasoning while remaining trainable via gradient descent. Our main theoretical result establishes a bijective correspondence between finitary logical theories and neural architectures, proving that every logically constrained network arises uniquely from our construction. This extends Categorical Deep Learning beyond geometric symmetries to semantic constraints, enabling automatic derivation of verified architectures from logical specifications. The framework provides mathematical foundations for trustworthy AI systems, with applications to theorem proving, formal verification, and safety-critical reasoning tasks requiring verifiable logical behavior.", 'abstract_zh': '神经网络在模式识别方面表现出色，但在可靠的逻辑推理方面存在局限性，往往在推理过程中违反基本的逻辑原则。我们通过开发一种类别框架来解决这一限制，该框架系统地构建具有可证明逻辑保证的神经网络架构。我们的方法将逻辑理论视为称为Lawvere理论的代数结构，并使用范畴代数在参数映射的2-范畴中将其转换为神经网络。与现有方法在训练过程中施加逻辑约束不同，我们的范畴构造直接将逻辑原则嵌入网络的架构结构中，从而使逻辑违反在数学上成为不可能。我们通过构建保持布尔推理且仍可通过梯度下降进行训练的命题逻辑可微神经架构来演示这一框架。我们的主要理论结果建立了有限逻辑理论与神经架构之间的双射对应关系，证明了每一逻辑约束网络都唯一地源自我们的构造。这将范畴深度学习扩展到语义约束，使从逻辑规范自动推导出可验证架构成为可能。该框架为可信赖的人工智能系统提供了数学基础，并应用于定理证明、形式验证以及需要可验证逻辑行为的安全关键推理任务。', 'title_zh': '逻辑可验证神经架构的类别构建'}
{'arxiv_id': 'arXiv:2508.11640', 'title': 'Vibe2Spike: Batteryless Wireless Tags for Vibration Sensing with Event Cameras and Spiking Networks', 'authors': 'Danny Scott, William LaForest, Hritom Das, Ioannis Polykretis, Catherine D. Schuman, Charles Rizzo, James Plank, Sai Swaminathan', 'link': 'https://arxiv.org/abs/2508.11640', 'abstract': 'The deployment of dense, low-cost sensors is critical for realizing ubiquitous smart environments. However, existing sensing solutions struggle with the energy, scalability, and reliability trade-offs imposed by battery maintenance, wireless transmission overhead, and data processing complexity. In this work, we present Vibe2Spike, a novel battery-free, wireless sensing framework that enables vibration-based activity recognition using visible light communication (VLC) and spiking neural networks (SNNs). Our system uses ultra-low-cost tags composed only of a piezoelectric disc, a Zener diode, and an LED, which harvest vibration energy and emit sparse visible light spikes without requiring batteries or RF radios. These optical spikes are captured by event cameras and classified using optimized SNN models evolved via the EONS framework. We evaluate Vibe2Spike across five device classes, achieving 94.9\\% average classification fitness while analyzing the latency-accuracy trade-offs of different temporal binning strategies. Vibe2Spike demonstrates a scalable, and energy-efficient approach for enabling intelligent environments in a batteryless manner.', 'abstract_zh': '无需能源的振动感知框架Vibe2Spike：基于可见光通信和突触神经网络的活动识别', 'title_zh': 'Vibe2Spike：基于事件摄像头和突触网络的无电池振动传感标签'}
