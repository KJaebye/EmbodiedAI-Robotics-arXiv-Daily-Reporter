# Whole-Body Proprioceptive Morphing: A Modular Soft Gripper for Robust Cross-Scale Grasping 

**Title (ZH)**: 全身本体感受重构：一种模块化软夹持器，用于稳健的跨尺度抓取 

**Authors**: Dong Heon Han, Xiaohao Xu, Yuxi Chen, Yusheng Zhou, Xinqi Zhang, Jiaqi Wang, Daniel Bruder, Xiaonan Huang  

**Link**: [PDF](https://arxiv.org/pdf/2510.27666)  

**Abstract**: Biological systems, such as the octopus, exhibit masterful cross-scale manipulation by adaptively reconfiguring their entire form, a capability that remains elusive in robotics. Conventional soft grippers, while compliant, are mostly constrained by a fixed global morphology, and prior shape-morphing efforts have been largely confined to localized deformations, failing to replicate this biological dexterity. Inspired by this natural exemplar, we introduce the paradigm of collaborative, whole-body proprioceptive morphing, realized in a modular soft gripper architecture. Our design is a distributed network of modular self-sensing pneumatic actuators that enables the gripper to intelligently reconfigure its entire topology, achieving multiple morphing states that are controllable to form diverse polygonal shapes. By integrating rich proprioceptive feedback from embedded sensors, our system can seamlessly transition from a precise pinch to a large envelope grasp. We experimentally demonstrate that this approach expands the grasping envelope and enhances generalization across diverse object geometries (standard and irregular) and scales (up to 10$\times$), while also unlocking novel manipulation modalities such as multi-object and internal hook grasping. This work presents a low-cost, easy-to-fabricate, and scalable framework that fuses distributed actuation with integrated sensing, offering a new pathway toward achieving biological levels of dexterity in robotic manipulation. 

**Abstract (ZH)**: 生物系统，如八足动物，通过适应性重构其整个形态展现卓越的跨尺度操控能力，这一能力在机器人领域仍然难以实现。常规的柔性夹爪虽然具有顺应性，但大多受限于固定的全局形态，此前的形态变化努力主要局限于局部变形，未能复制生物的灵活性。受这一自然范例的启发，我们提出了协作的全身本体感受性形态变化范式，这一范式在模块化柔性夹爪架构中得以实现。我们的设计是一种分布式网络的模块化自感知气动执行器，使夹爪能够智能地重新配置其整个拓扑结构，实现多种可控制的形态变换状态，形成多样化的多边形形状。通过整合嵌入式传感器提供的丰富本体感受反馈，我们的系统能够无缝切换从精确的夹持到大范围抓取。实验结果显示，这种方法扩大了抓取范围，并在多样化的物体几何形状（标准和非标准）和尺度（高达10倍）上实现了更好的泛化能力，同时解锁了诸如多物体抓取和内部钩爪抓取等新的操作模式。这项工作提供了一种低成本、易于制造且可扩展的框架，结合分布式驱动与集成传感技术，为实现类似生物水平的灵活性提供了一条新的途径。 

---
# Toward Accurate Long-Horizon Robotic Manipulation: Language-to-Action with Foundation Models via Scene Graphs 

**Title (ZH)**: 基于场景图的骨干模型从语言到动作的长时 Horizon 机器人操作研究 

**Authors**: Sushil Samuel Dinesh, Shinkyu Park  

**Link**: [PDF](https://arxiv.org/pdf/2510.27558)  

**Abstract**: This paper presents a framework that leverages pre-trained foundation models for robotic manipulation without domain-specific training. The framework integrates off-the-shelf models, combining multimodal perception from foundation models with a general-purpose reasoning model capable of robust task sequencing. Scene graphs, dynamically maintained within the framework, provide spatial awareness and enable consistent reasoning about the environment. The framework is evaluated through a series of tabletop robotic manipulation experiments, and the results highlight its potential for building robotic manipulation systems directly on top of off-the-shelf foundation models. 

**Abstract (ZH)**: 本文提出了一种框架，利用预训练的基础模型进行机器人 manipulation，无需领域特定的训练。该框架结合了基础模型的多模态感知和一个通用推理模型，该推理模型能够实现稳健的任务序列。框架中的场景图动态维护，提供空间意识并使环境的一致推理成为可能。通过一系列桌面机器人 manipulation 实验对该框架进行了评估，结果突显了其直接基于即用型基础模型构建机器人 manipulation 系统的潜力。 

---
# EBT-Policy: Energy Unlocks Emergent Physical Reasoning Capabilities 

**Title (ZH)**: EBT-Policy: 能源解锁 Emergent 物理推理能力 

**Authors**: Travis Davies, Yiqi Huang, Alexi Gladstone, Yunxin Liu, Xiang Chen, Heng Ji, Huxian Liu, Luhui Hu  

**Link**: [PDF](https://arxiv.org/pdf/2510.27545)  

**Abstract**: Implicit policies parameterized by generative models, such as Diffusion Policy, have become the standard for policy learning and Vision-Language-Action (VLA) models in robotics. However, these approaches often suffer from high computational cost, exposure bias, and unstable inference dynamics, which lead to divergence under distribution shifts. Energy-Based Models (EBMs) address these issues by learning energy landscapes end-to-end and modeling equilibrium dynamics, offering improved robustness and reduced exposure bias. Yet, policies parameterized by EBMs have historically struggled to scale effectively. Recent work on Energy-Based Transformers (EBTs) demonstrates the scalability of EBMs to high-dimensional spaces, but their potential for solving core challenges in physically embodied models remains underexplored. We introduce a new energy-based architecture, EBT-Policy, that solves core issues in robotic and real-world settings. Across simulated and real-world tasks, EBT-Policy consistently outperforms diffusion-based policies, while requiring less training and inference computation. Remarkably, on some tasks it converges within just two inference steps, a 50x reduction compared to Diffusion Policy's 100. Moreover, EBT-Policy exhibits emergent capabilities not seen in prior models, such as zero-shot recovery from failed action sequences using only behavior cloning and without explicit retry training. By leveraging its scalar energy for uncertainty-aware inference and dynamic compute allocation, EBT-Policy offers a promising path toward robust, generalizable robot behavior under distribution shifts. 

**Abstract (ZH)**: 基于生成模型参数化的隐式策略及其在机器人Vision-Language-Action（VLA）模型中的应用：EBT-Policy的提出与性能 

---
# Preliminary Prototyping of Avoidance Behaviors Triggered by a User's Physical Approach to a Robot 

**Title (ZH)**: 基于用户物理接近机器人触发的回避行为初步原型设计 

**Authors**: Tomoko Yonezawa, Hirotake Yamazoe, Atsuo Fujino, Daigo Suhara, Takaya Tamamoto, Yuto Nishiguchi  

**Link**: [PDF](https://arxiv.org/pdf/2510.27436)  

**Abstract**: Human-robot interaction frequently involves physical proximity or contact. In human-human settings, people flexibly accept, reject, or tolerate such approaches depending on the relationship and context. We explore the design of a robot's rejective internal state and corresponding avoidance behaviors, such as withdrawing or pushing away, when a person approaches. We model the accumulation and decay of discomfort as a function of interpersonal distance, and implement tolerance (endurance) and limit-exceeding avoidance driven by the Dominance axis of the PAD affect model. The behaviors and their intensities are realized on an arm robot. Results illustrate a coherent pipeline from internal state parameters to graded endurance motions and, once a limit is crossed, to avoidance actions. 

**Abstract (ZH)**: 人类与机器人交互常涉及身体 proximity 或接触。在人类交互环境中，人们根据关系和情境灵活接受、拒绝或容忍这种接近。我们探索当一个人接近时，机器人拒斥内部状态及其相应的回避行为，如撤回或推开的设计。我们建模人际距离与不适累积及衰减的关系，并基于 PAD 影响模型的支配轴实现容忍（耐受）和极限超越回避。这些行为及其强度在机械臂机器人上得到实现。结果展示了从内部状态参数到分等级的耐受动作，以及一旦达到极限即转变为回避动作的连贯管线。 

---
# Learning Soft Robotic Dynamics with Active Exploration 

**Title (ZH)**: 学习具有主动探索能力的软机器人动态模型 

**Authors**: Hehui Zheng, Bhavya Sukhija, Chenhao Li, Klemens Iten, Andreas Krause, Robert K. Katzschmann  

**Link**: [PDF](https://arxiv.org/pdf/2510.27428)  

**Abstract**: Soft robots offer unmatched adaptability and safety in unstructured environments, yet their compliant, high-dimensional, and nonlinear dynamics make modeling for control notoriously difficult. Existing data-driven approaches often fail to generalize, constrained by narrowly focused task demonstrations or inefficient random exploration. We introduce SoftAE, an uncertainty-aware active exploration framework that autonomously learns task-agnostic and generalizable dynamics models of soft robotic systems. SoftAE employs probabilistic ensemble models to estimate epistemic uncertainty and actively guides exploration toward underrepresented regions of the state-action space, achieving efficient coverage of diverse behaviors without task-specific supervision. We evaluate SoftAE on three simulated soft robotic platforms -- a continuum arm, an articulated fish in fluid, and a musculoskeletal leg with hybrid actuation -- and on a pneumatically actuated continuum soft arm in the real world. Compared with random exploration and task-specific model-based reinforcement learning, SoftAE produces more accurate dynamics models, enables superior zero-shot control on unseen tasks, and maintains robustness under sensing noise, actuation delays, and nonlinear material effects. These results demonstrate that uncertainty-driven active exploration can yield scalable, reusable dynamics models across diverse soft robotic morphologies, representing a step toward more autonomous, adaptable, and data-efficient control in compliant robots. 

**Abstract (ZH)**: 软体机器人在未结构化环境中的不可替代适应性和安全性使得其 compliant、高维度和非线性动力学建模控制极具挑战性。现有的数据驱动方法往往由于任务示范狭窄或无效的随机探索而难以泛化。我们引入了SoftAE，一个具有不确定性意识的主动探索框架，使其能够自主学习软体机器人系统的任务无关且可泛化的动力学模型。SoftAE 使用概率集成模型来估计epistemic不确定性，并主动引导探索进入状态-动作空间中未充分代表的区域，从而实现对多样行为的高效覆盖，无需特定任务的监督。我们分别在三种模拟软体机器人平台（连续臂、流体中的铰接鱼和混合驱动的肌肉骨骼腿）以及一个气动驱动的连续软臂上评估了SoftAE。与随机探索和特定任务的基于模型的强化学习相比，SoftAE 生产出更准确的动力学模型，能够在未见过的任务上实现更优的零样本控制，并在传感器噪声、驱动延迟和非线性材料效应下保持鲁棒性。这些结果表明，不确定性驱动的主动探索能够产生适用于各种软体机器人形态的大规模且可复用的动力学模型，代表着更自主、更具适应性且更数据高效的 控制系统向合规机器人领域迈出一步。 

---
# Towards a Multi-Embodied Grasping Agent 

**Title (ZH)**: 朝向多体态抓取代理的研究 

**Authors**: Roman Freiberg, Alexander Qualmann, Ngo Anh Vien, Gerhard Neumann  

**Link**: [PDF](https://arxiv.org/pdf/2510.27420)  

**Abstract**: Multi-embodiment grasping focuses on developing approaches that exhibit generalist behavior across diverse gripper designs. Existing methods often learn the kinematic structure of the robot implicitly and face challenges due to the difficulty of sourcing the required large-scale data. In this work, we present a data-efficient, flow-based, equivariant grasp synthesis architecture that can handle different gripper types with variable degrees of freedom and successfully exploit the underlying kinematic model, deducing all necessary information solely from the gripper and scene geometry. Unlike previous equivariant grasping methods, we translated all modules from the ground up to JAX and provide a model with batching capabilities over scenes, grippers, and grasps, resulting in smoother learning, improved performance and faster inference time. Our dataset encompasses grippers ranging from humanoid hands to parallel yaw grippers and includes 25,000 scenes and 20 million grasps. 

**Abstract (ZH)**: 多体感抓取专注于开发在多样化的抓取器设计中表现出通用行为的方法。现有方法往往隐式学习机器人的运动结构，并且由于获取足够规模数据的难度而面临挑战。在本工作中，我们提出了一种数据高效、基于流、等变抓取合成架构，能够处理不同自由度的抓取器类型，并成功利用潜在的运动学模型，仅从抓取器和场景几何中推导出所有必要的信息。与之前的等变抓取方法不同，我们将所有模块从基础重新翻译至JAX，并提供场景、抓取器和抓取批量处理能力，从而实现更平滑的学习、更好的性能和更快的推理时间。我们的数据集涵盖了从类人手到并行摆动抓取器的各种抓取器类型，包括25,000个场景和2000万个抓取。 

---
# Modified-Emergency Index (MEI): A Criticality Metric for Autonomous Driving in Lateral Conflict 

**Title (ZH)**: 修改后的紧急指数（MEI）：自主驾驶横向冲突的 Criticality 指标 

**Authors**: Hao Cheng, Yanbo Jiang, Qingyuan Shi, Qingwen Meng, Keyu Chen, Wenhao Yu, Jianqiang Wang, Sifa Zheng  

**Link**: [PDF](https://arxiv.org/pdf/2510.27333)  

**Abstract**: Effective, reliable, and efficient evaluation of autonomous driving safety is essential to demonstrate its trustworthiness. Criticality metrics provide an objective means of assessing safety. However, as existing metrics primarily target longitudinal conflicts, accurately quantifying the risks of lateral conflicts - prevalent in urban settings - remains challenging. This paper proposes the Modified-Emergency Index (MEI), a metric designed to quantify evasive effort in lateral conflicts. Compared to the original Emergency Index (EI), MEI refines the estimation of the time available for evasive maneuvers, enabling more precise risk quantification. We validate MEI on a public lateral conflict dataset based on Argoverse-2, from which we extract over 1,500 high-quality AV conflict cases, including more than 500 critical events. MEI is then compared with the well-established ACT and the widely used PET metrics. Results show that MEI consistently outperforms them in accurately quantifying criticality and capturing risk evolution. Overall, these findings highlight MEI as a promising metric for evaluating urban conflicts and enhancing the safety assessment framework for autonomous driving. The open-source implementation is available at this https URL. 

**Abstract (ZH)**: 有效的、可靠的且高效的自主驾驶安全性评估对于展示其可信度至关重要。临界指标提供了一种客观的安全评估手段。然而，由于现有的指标主要针对纵向冲突，准确量化城市环境中常见的横向冲突的风险仍然颇具挑战性。本文提出了一种改良的紧急指数（MEI），以量化横向冲突中的避碰努力。与原始紧急指数（EI）相比，MEI 对可用于避碰操作的时间进行了精细化估计，从而能够更精确地量化风险。我们基于Argoverse-2公共横向冲突数据集验证了MEI，从中提取了超过1,500个高质量的AV冲突案例，包括超过500个关键事件。然后将MEI与成熟的ACT指标和广泛使用的PET指标进行比较。结果表明，MEI在准确量化临界性和捕捉风险演变方面始终优于它们。总体而言，这些发现突出了MEI作为评估城市冲突和增强自主驾驶安全性评估框架的有前途的指标。开源实现可在以下链接获取：this https URL。 

---
# A Modular and Scalable System Architecture for Heterogeneous UAV Swarms Using ROS 2 and PX4-Autopilot 

**Title (ZH)**: 基于ROS 2和PX4自动驾驶器的模块化和可扩展异构无人机群系统架构 

**Authors**: Robert Pommeranz, Kevin Tebbe, Ralf Heynicke, Gerd Scholl  

**Link**: [PDF](https://arxiv.org/pdf/2510.27327)  

**Abstract**: In this paper a modular and scalable architecture for heterogeneous swarm-based Counter Unmanned Aerial Systems (C-UASs) built on PX4-Autopilot and Robot Operating System 2 (ROS 2) framework is presented. The proposed architecture emphasizes seamless integration of hardware components by introducing independent ROS 2 nodes for each component of a Unmanned Aerial Vehicle (UAV). Communication between swarm participants is abstracted in software, allowing the use of various technologies without architectural changes. Key functionalities are supported, e.g. leader following and formation flight to maneuver the swarm. The system also allows computer vision algorithms to be integrated for the detection and tracking of UAVs. Additionally, a ground station control is integrated for the coordination of swarm operations. Swarm-based Unmanned Aerial System (UAS) architecture is verified within a Gazebo simulation environment but also in real-world demonstrations. 

**Abstract (ZH)**: 基于PX4-Autopilot和ROS 2的异构 swarm-Based C-UAS模块化可扩展架构 

---
# Vectorized Online POMDP Planning 

**Title (ZH)**: 向量化的在线POMDP规划 

**Authors**: Marcus Hoerger, Muhammad Sudrajat, Hanna Kurniawati  

**Link**: [PDF](https://arxiv.org/pdf/2510.27191)  

**Abstract**: Planning under partial observability is an essential capability of autonomous robots. The Partially Observable Markov Decision Process (POMDP) provides a powerful framework for planning under partial observability problems, capturing the stochastic effects of actions and the limited information available through noisy observations. POMDP solving could benefit tremendously from massive parallelization of today's hardware, but parallelizing POMDP solvers has been challenging. They rely on interleaving numerical optimization over actions with the estimation of their values, which creates dependencies and synchronization bottlenecks between parallel processes that can quickly offset the benefits of parallelization. In this paper, we propose Vectorized Online POMDP Planner (VOPP), a novel parallel online solver that leverages a recent POMDP formulation that analytically solves part of the optimization component, leaving only the estimation of expectations for numerical computation. VOPP represents all data structures related to planning as a collection of tensors and implements all planning steps as fully vectorized computations over this representation. The result is a massively parallel solver with no dependencies and synchronization bottlenecks between parallel computations. Experimental results indicate that VOPP is at least 20X more efficient in computing near-optimal solutions compared to an existing state-of-the-art parallel online solver. 

**Abstract (ZH)**: 基于部分可观测性的规划是自主机器人的一项基本能力。部分可观测马尔可夫决策过程（POMDP）提供了一个强大的框架，用于解决部分可观测性问题，能够捕获动作的随机效应并通过嘈杂观测获取的有限信息。POMDP求解可以从当今硬件的巨大并行化中受益匪浅，但并行化POMDP求解器一直具有挑战性。现有的方法依赖于动作上的数值优化与价值估计的交替进行，这在并行过程中创建了依赖性和同步瓶颈，可能会迅速抵消并行化的益处。本文提出了向量在线POMDP规划器（VOPP），这是一种新颖的并行在线求解器，利用了最近提出的一种POMDP形式化方法，该方法部分地解析了优化组件，仅将期望的估计留给数值计算。VOPP将所有与规划相关的数据结构表示为张量集合，并将所有规划步骤实现为对这一表示的完全向量化计算。结果是一种无依赖性和同步瓶颈的并行求解器。实验结果表明，VOPP在计算近最优解方面至少比现有最先进的并行在线求解器快20倍。 

---
# Hybrid Gripper Finger Enabling In-Grasp Friction Modulation Using Inflatable Silicone Pockets 

**Title (ZH)**: 具有可调节摩擦的混合夹持器手指设计：基于可充气硅胶囊袋 

**Authors**: Hoang Hiep Ly, Cong-Nhat Nguyen, Doan-Quang Tran, Quoc-Khanh Dang, Ngoc Duy Tran, Thi Thoa Mac, Anh Nguyen, Xuan-Thuan Nguyen, Tung D. Ta  

**Link**: [PDF](https://arxiv.org/pdf/2510.27184)  

**Abstract**: Grasping objects with diverse mechanical properties, such as heavy, slippery, or fragile items, remains a significant challenge in robotics. Conventional grippers often rely on applying high normal forces, which can cause damage to objects. To address this limitation, we present a hybrid gripper finger that combines a rigid structural shell with a soft, inflatable silicone pocket. The gripper finger can actively modulate its surface friction by controlling the internal air pressure of the silicone pocket. Results from fundamental experiments indicate that increasing the internal pressure results in a proportional increase in the effective coefficient of friction. This enables the gripper to stably lift heavy and slippery objects without increasing the gripping force and to handle fragile or deformable objects, such as eggs, fruits, and paper cups, with minimal damage by increasing friction rather than applying excessive force. The experimental results demonstrate that the hybrid gripper finger with adaptable friction provides a robust and safer alternative to relying solely on high normal forces, thereby enhancing the gripper flexibility in handling delicate, fragile, and diverse objects. 

**Abstract (ZH)**: 具有可调节摩擦力的混合手指抓取具有多样化机械性能的物体：一种减少高正压力依赖性的替代方案 

---
# MobiDock: Design and Control of A Modular Self Reconfigurable Bimanual Mobile Manipulator via Robotic Docking 

**Title (ZH)**: MobiDock：模块化自重构双臂移动 manipulator 的设计与控制研究通过机器人对接 

**Authors**: Xuan-Thuan Nguyen, Khac Nam Nguyen, Ngoc Duy Tran, Thi Thoa Mac, Anh Nguyen, Hoang Hiep Ly, Tung D. Ta  

**Link**: [PDF](https://arxiv.org/pdf/2510.27178)  

**Abstract**: Multi-robot systems, particularly mobile manipulators, face challenges in control coordination and dynamic stability when working together. To address this issue, this study proposes MobiDock, a modular self-reconfigurable mobile manipulator system that allows two independent robots to physically connect and form a unified mobile bimanual platform. This process helps transform a complex multi-robot control problem into the management of a simpler, single system. The system utilizes an autonomous docking strategy based on computer vision with AprilTag markers and a new threaded screw-lock mechanism. Experimental results show that the docked configuration demonstrates better performance in dynamic stability and operational efficiency compared to two independently cooperating robots. Specifically, the unified system has lower Root Mean Square (RMS) Acceleration and Jerk values, higher angular precision, and completes tasks significantly faster. These findings confirm that physical reconfiguration is a powerful design principle that simplifies cooperative control, improving stability and performance for complex tasks in real-world environments. 

**Abstract (ZH)**: 多机器人系统，特别是移动 manipulator，在协同工作时面临控制协调和动态稳定性方面的挑战。为解决这一问题，本研究提出了一种模块化自重构移动 manipulator 系统 MobiDock，该系统允许两个独立的机器人物理连接并形成一个统一的双臂移动平台。这一过程有助于将复杂的多机器人控制问题转化为单一系统的管理问题。该系统采用基于计算机视觉和 AprilTag 标记的自主对接策略以及一种新的带有螺纹螺母锁紧机制。实验结果表明，对接配置在动态稳定性和操作效率方面优于两个独立合作的机器人。具体而言，统一系统具有较低的均方根加速度和冲击值，更高的角度精度，且能显著更快地完成任务。这些发现证实了物理重构是一种强大的设计原则，能够简化协作控制，提高复杂任务在实际环境中的稳定性和性能。 

---
# Confined Space Underwater Positioning Using Collaborative Robots 

**Title (ZH)**: 受限空间水下定位 Using协作机器人 

**Authors**: Xueliang Cheng, Kanzhong Yao, Andrew West, Ognjen Marjanovic, Barry Lennox, Keir Groves  

**Link**: [PDF](https://arxiv.org/pdf/2510.27151)  

**Abstract**: Positioning of underwater robots in confined and cluttered spaces remains a key challenge for field operations. Existing systems are mostly designed for large, open-water environments and struggle in industrial settings due to poor coverage, reliance on external infrastructure, and the need for feature-rich surroundings. Multipath effects from continuous sound reflections further degrade signal quality, reducing accuracy and reliability. Accurate and easily deployable positioning is essential for repeatable autonomous missions; however, this requirement has created a technological bottleneck limiting underwater robotic deployment. This paper presents the Collaborative Aquatic Positioning (CAP) system, which integrates collaborative robotics and sensor fusion to overcome these limitations. Inspired by the "mother-ship" concept, the surface vehicle acts as a mobile leader to assist in positioning a submerged robot, enabling localization even in GPS-denied and highly constrained environments. The system is validated in a large test tank through repeatable autonomous missions using CAP's position estimates for real-time trajectory control. Experimental results demonstrate a mean Euclidean distance (MED) error of 70 mm, achieved in real time without requiring fixed infrastructure, extensive calibration, or environmental features. CAP leverages advances in mobile robot sensing and leader-follower control to deliver a step change in accurate, practical, and infrastructure-free underwater localization. 

**Abstract (ZH)**: 水下机器人在受限和拥挤空间中的定位仍然是现场作业中的一个关键挑战。现有的系统主要设计用于开阔水域环境，在工业环境中由于覆盖范围差、依赖外部基础设施以及需要特征丰富的周围环境而难以适用。连续的声波反射导致的多路径效应进一步恶化信号质量，降低定位的准确性与可靠性。准确且易于部署的定位对于重复的自治任务至关重要；然而，这一要求形成了技术瓶颈，限制了水下机器人部署。本文提出了协作式水下定位（CAP）系统，该系统结合了协作机器人和传感器融合以克服这些限制。受“母舰”概念的启发，水面车辆作为移动的领导者协助定位潜航器，使得即使在GPS受限和高度受限的环境中也能实现定位。该系统通过在大型试验水箱中执行重复的自治任务并使用CAP的位置估计进行实时轨迹控制得到了验证。实验结果表明，CAP实现了实时平均欧几里得距离误差为70毫米，无需固定基础设施、大量校准或环境特征。CAP利用移动机器人感知和领导者-跟随者控制的最新进展，实现了准确、实用且无需基础设施的水下定位的跨越式进步。 

---
# Learning Generalizable Visuomotor Policy through Dynamics-Alignment 

**Title (ZH)**: 通过动力学对齐学习可泛化的视听运动策略 

**Authors**: Dohyeok Lee, Jung Min Lee, Munkyung Kim, Seokhun Ju, Jin Woo Koo, Kyungjae Lee, Dohyeong Kim, TaeHyun Cho, Jungwoo Lee  

**Link**: [PDF](https://arxiv.org/pdf/2510.27114)  

**Abstract**: Behavior cloning methods for robot learning suffer from poor generalization due to limited data support beyond expert demonstrations. Recent approaches leveraging video prediction models have shown promising results by learning rich spatiotemporal representations from large-scale datasets. However, these models learn action-agnostic dynamics that cannot distinguish between different control inputs, limiting their utility for precise manipulation tasks and requiring large pretraining datasets. We propose a Dynamics-Aligned Flow Matching Policy (DAP) that integrates dynamics prediction into policy learning. Our method introduces a novel architecture where policy and dynamics models provide mutual corrective feedback during action generation, enabling self-correction and improved generalization. Empirical validation demonstrates generalization performance superior to baseline methods on real-world robotic manipulation tasks, showing particular robustness in OOD scenarios including visual distractions and lighting variations. 

**Abstract (ZH)**: 基于动力模型对齐的流动匹配策略（Dynamics-Aligned Flow Matching Policy）用于提升机器人学习的任务通用性 

---
# SpikeATac: A Multimodal Tactile Finger with Taxelized Dynamic Sensing for Dexterous Manipulation 

**Title (ZH)**: SpikeATac: 具有税el化动态传感的多模态触觉手指用于灵巧操作 

**Authors**: Eric T. Chang, Peter Ballentine, Zhanpeng He, Do-Gon Kim, Kai Jiang, Hua-Hsuan Liang, Joaquin Palacios, William Wang, Pedro Piacenza, Ioannis Kymissis, Matei Ciocarlie  

**Link**: [PDF](https://arxiv.org/pdf/2510.27048)  

**Abstract**: In this work, we introduce SpikeATac, a multimodal tactile finger combining a taxelized and highly sensitive dynamic response (PVDF) with a static transduction method (capacitive) for multimodal touch sensing. Named for its `spiky' response, SpikeATac's 16-taxel PVDF film sampled at 4 kHz provides fast, sensitive dynamic signals to the very onset and breaking of contact. We characterize the sensitivity of the different modalities, and show that SpikeATac provides the ability to stop quickly and delicately when grasping fragile, deformable objects. Beyond parallel grasping, we show that SpikeATac can be used in a learning-based framework to achieve new capabilities on a dexterous multifingered robot hand. We use a learning recipe that combines reinforcement learning from human feedback with tactile-based rewards to fine-tune the behavior of a policy to modulate force. Our hardware platform and learning pipeline together enable a difficult dexterous and contact-rich task that has not previously been achieved: in-hand manipulation of fragile objects. Videos are available at \href{this https URL}{this http URL}. 

**Abstract (ZH)**: 本研究介绍了SpikeATac，一种多模态触觉手指，结合了税el化的动态高灵敏度响应（PVDF）和静态转换方法（电容式）以实现多模态触觉传感。SpikeATac以其“尖峰”响应而命名，其16税el的PVDF膜以4 kHz的频率采样，提供快速敏感的动态信号，用于接触的开始和结束。我们表征了不同模态的灵敏度，并展示了SpikeATac能够在抓取脆弱可变形物体时快速而细致地停止。除了并行抓取，我们还展示了SpikeATac可以在基于学习的框架中用于实现灵巧多指机器人手的新能力。我们使用了一种结合来自人类反馈的强化学习与基于触觉的奖励的学习方法，以微调策略的行为来调节力。我们的硬件平台和学习管道共同使一项以前未达成的复杂灵巧且触觉丰富的任务成为可能：在手内部操作脆弱物体。视频可在\href{this https URL}{this http URL}获取。 

---
# A Multi-Modal Neuro-Symbolic Approach for Spatial Reasoning-Based Visual Grounding in Robotics 

**Title (ZH)**: 基于空间推理的多模态神经符号方法在机器人中的视觉定位 

**Authors**: Simindokht Jahangard, Mehrzad Mohammadi, Abhinav Dhall, Hamid Rezatofighi  

**Link**: [PDF](https://arxiv.org/pdf/2510.27033)  

**Abstract**: Visual reasoning, particularly spatial reasoning, is a challenging cognitive task that requires understanding object relationships and their interactions within complex environments, especially in robotics domain. Existing vision_language models (VLMs) excel at perception tasks but struggle with fine-grained spatial reasoning due to their implicit, correlation-driven reasoning and reliance solely on images. We propose a novel neuro_symbolic framework that integrates both panoramic-image and 3D point cloud information, combining neural perception with symbolic reasoning to explicitly model spatial and logical relationships. Our framework consists of a perception module for detecting entities and extracting attributes, and a reasoning module that constructs a structured scene graph to support precise, interpretable queries. Evaluated on the JRDB-Reasoning dataset, our approach demonstrates superior performance and reliability in crowded, human_built environments while maintaining a lightweight design suitable for robotics and embodied AI applications. 

**Abstract (ZH)**: 视觉推理，特别是空间推理，是认知任务中的一个挑战性任务，需要理解物体关系及其在复杂环境中的互动，尤其是对于机器人领域。现有的视觉语言模型（VLMs）擅长感知任务，但在细粒度的空间推理方面表现不佳，这主要是因为它们依赖于隐式的、基于相关性的推理和单一的图像信息。我们提出了一种新的神经符号框架，该框架整合了全景图像和3D点云信息，结合神经感知与符号推理，明确建模空间和逻辑关系。该框架由一个感知模块用于检测实体和提取属性，以及一个推理模块用于构建结构化的场景图，以支持精确和可解释的查询。在JRDB-Reasoning数据集上，我们的方法在拥挤的人造环境中表现出色且可靠，同时保持了轻量级设计，适用于机器人和具身人工智能应用。 

---
# A Hermetic, Transparent Soft Growing Vine Robot System for Pipe Inspection 

**Title (ZH)**: 密闭透明的软生长藤条机器人系统用于管道检查 

**Authors**: William E. Heap, Yimeng Qin, Kai Hammond, Anish Bayya, Haonon Kong, Allison M. Okamura  

**Link**: [PDF](https://arxiv.org/pdf/2510.27010)  

**Abstract**: Rehabilitation of aging pipes requires accurate condition assessment and mapping far into the pipe interiors. Soft growing vine robot systems are particularly promising for navigating confined, sinuous paths such as in pipes, but are currently limited by complex subsystems and a lack of validation in real-world industrial settings. In this paper, we introduce the concept and implementation of a hermetic and transparent vine robot system for visual condition assessment and mapping within non-branching pipes. This design encloses all mechanical and electrical components within the vine robot's soft, airtight, and transparent body, protecting them from environmental interference while enabling visual sensing. Because this approach requires an enclosed mechanism for transporting sensors, we developed, modeled, and tested a passively adapting enclosed tip mount. Finally, we validated the hermetic and transparent vine robot system concept through a real-world condition assessment and mapping task in a wastewater pipe. This work advances the use of soft-growing vine robots in pipe inspection by developing and demonstrating a robust, streamlined, field-validated system suitable for continued development and deployment. 

**Abstract (ZH)**: 老化管道的康复需要准确的状况评估和深入管道内部的测绘。软生长藤蔓机器人系统尤其适用于导航狭小蜿蜒的管道路径，但目前受限于复杂的子系统和缺乏实际工业环境下的验证。本文介绍并实施了一种密封且透明的藤蔓机器人系统，用于非分叉管道内部的视觉状况评估和测绘。该设计将所有机械和电气组件封装在藤蔓机器人的软性、密封且透明的身体中，以防止外部干扰并允许视觉传感。由于该方法需要一个封闭机制来运输传感器，我们开发、建模并测试了被动适应的封闭末端装卡。最后，我们通过实际的污水管道状况评估和测绘任务验证了密封且透明的藤蔓机器人系统概念。这项工作通过开发并展示了一个坚实、简洁且在现场验证的系统，促进了软生长藤蔓机器人的管道检测应用，适合继续发展和部署。 

---
# RepV: Safety-Separable Latent Spaces for Scalable Neurosymbolic Plan Verification 

**Title (ZH)**: RepV: 安全可分的潜在空间以实现可扩展的神经符号计划验证 

**Authors**: Yunhao Yang, Neel P. Bhatt, Pranay Samineni, Rohan Siva, Zhanyang Wang, Ufuk Topcu  

**Link**: [PDF](https://arxiv.org/pdf/2510.26935)  

**Abstract**: As AI systems migrate to safety-critical domains, verifying that their actions comply with well-defined rules remains a challenge. Formal methods provide provable guarantees but demand hand-crafted temporal-logic specifications, offering limited expressiveness and accessibility. Deep learning approaches enable evaluation of plans against natural-language constraints, yet their opaque decision process invites misclassifications with potentially severe consequences. We introduce RepV, a neurosymbolic verifier that unifies both views by learning a latent space where safe and unsafe plans are linearly separable. Starting from a modest seed set of plans labeled by an off-the-shelf model checker, RepV trains a lightweight projector that embeds each plan, together with a language model-generated rationale, into a low-dimensional space; a frozen linear boundary then verifies compliance for unseen natural-language rules in a single forward pass.
Beyond binary classification, RepV provides a probabilistic guarantee on the likelihood of correct verification based on its position in the latent space. This guarantee enables a guarantee-driven refinement of the planner, improving rule compliance without human annotations. Empirical evaluations show that RepV improves compliance prediction accuracy by up to 15% compared to baseline methods while adding fewer than 0.2M parameters. Furthermore, our refinement framework outperforms ordinary fine-tuning baselines across various planning domains. These results show that safety-separable latent spaces offer a scalable, plug-and-play primitive for reliable neurosymbolic plan verification. Code and data are available at: this https URL. 

**Abstract (ZH)**: 随着AI系统迁移到安全关键领域，验证其行为是否符合预定义规则仍是一项挑战。形式化方法可以提供可证明的保证，但需要手工构建的时间逻辑规范，这在表达能力和可用性方面都有限。深度学习方法能够根据自然语言约束评估计划，然而其不透明的决策过程可能导致具有潜在严重后果的误分类。我们介绍了一种神经符号验证器RepV，它将这两种观点统一起来，在一个潜在空间中学习一个使安全和不安全计划线性可分的潜在空间。从一个由现成模型检查器标注的适度种子计划集开始，RepV训练一个轻量级投影器，将每个计划与其语言模型生成的理由嵌入到低维空间中；然后，一个冻结的线性边界在单次前向传递中验证未见过的自然语言规则的合规性。 

---
# Heterogeneous Robot Collaboration in Unstructured Environments with Grounded Generative Intelligence 

**Title (ZH)**: 无结构环境中基于 grounded 生成智能的异构机器人协作 

**Authors**: Zachary Ravichandran, Fernando Cladera, Ankit Prabhu, Jason Hughes, Varun Murali, Camillo Taylor, George J. Pappas, Vijay Kumar  

**Link**: [PDF](https://arxiv.org/pdf/2510.26915)  

**Abstract**: Heterogeneous robot teams operating in realistic settings often must accomplish complex missions requiring collaboration and adaptation to information acquired online. Because robot teams frequently operate in unstructured environments -- uncertain, open-world settings without prior maps -- subtasks must be grounded in robot capabilities and the physical world. While heterogeneous teams have typically been designed for fixed specifications, generative intelligence opens the possibility of teams that can accomplish a wide range of missions described in natural language. However, current large language model (LLM)-enabled teaming methods typically assume well-structured and known environments, limiting deployment in unstructured environments. We present SPINE-HT, a framework that addresses these limitations by grounding the reasoning abilities of LLMs in the context of a heterogeneous robot team through a three-stage process. Given language specifications describing mission goals and team capabilities, an LLM generates grounded subtasks which are validated for feasibility. Subtasks are then assigned to robots based on capabilities such as traversability or perception and refined given feedback collected during online operation. In simulation experiments with closed-loop perception and control, our framework achieves nearly twice the success rate compared to prior LLM-enabled heterogeneous teaming approaches. In real-world experiments with a Clearpath Jackal, a Clearpath Husky, a Boston Dynamics Spot, and a high-altitude UAV, our method achieves an 87\% success rate in missions requiring reasoning about robot capabilities and refining subtasks with online feedback. More information is provided at this https URL. 

**Abstract (ZH)**: 异构机器人团队在现实环境中的操作往往需要执行复杂的任务，要求团队协作并适应在线获取的信息。由于机器人团队经常在未结构化的环境中操作——不确定的、开放的世界环境，缺乏先验地图——子任务必须基于机器人能力和物理世界。虽然异构团队通常被设计为固定规格，但生成型智能为用自然语言描述的广泛任务提供了可能性。然而，当前的大型语言模型（LLM）驱动的团队合作方法通常假设结构化的和已知的环境，从而限制了其在未结构化环境中的部署。我们提出了一种SPINE-HT框架，该框架通过三阶段过程将LLM的推理能力与异构机器人团队的上下文相结合，从而解决了这些限制。给定描述任务目标和团队能力的语言规范，LLM生成基于现实的子任务，并进行可行性验证。然后根据机器人的能力（如通行性或感知能力）分配子任务，并在收集在线操作反馈后进行调整。在闭环感知和控制的仿真实验中，我们的框架的成功率几乎是先前LLM驱动的异构团队方法的两倍。在配备了Clearpath Jackal、Clearpath Husky、Boston Dynamics Spot和高空无人机的实际世界实验中，我们的方法在需要关于机器人能力推理并借助在线反馈调整子任务的任务中实现了87%的成功率。更多信息请参见此网址。 

---
# NaviTrace: Evaluating Embodied Navigation of Vision-Language Models 

**Title (ZH)**: NaviTrace：评估视觉语言模型的 embodied 导航能力 

**Authors**: Tim Windecker, Manthan Patel, Moritz Reuss, Richard Schwarzkopf, Cesar Cadena, Rudolf Lioutikov, Marco Hutter, Jonas Frey  

**Link**: [PDF](https://arxiv.org/pdf/2510.26909)  

**Abstract**: Vision-language models demonstrate unprecedented performance and generalization across a wide range of tasks and scenarios. Integrating these foundation models into robotic navigation systems opens pathways toward building general-purpose robots. Yet, evaluating these models' navigation capabilities remains constrained by costly real-world trials, overly simplified simulations, and limited benchmarks. We introduce NaviTrace, a high-quality Visual Question Answering benchmark where a model receives an instruction and embodiment type (human, legged robot, wheeled robot, bicycle) and must output a 2D navigation trace in image space. Across 1000 scenarios and more than 3000 expert traces, we systematically evaluate eight state-of-the-art VLMs using a newly introduced semantic-aware trace score. This metric combines Dynamic Time Warping distance, goal endpoint error, and embodiment-conditioned penalties derived from per-pixel semantics and correlates with human preferences. Our evaluation reveals consistent gap to human performance caused by poor spatial grounding and goal localization. NaviTrace establishes a scalable and reproducible benchmark for real-world robotic navigation. The benchmark and leaderboard can be found at this https URL. 

**Abstract (ZH)**: 视觉-语言模型在广泛的任务和场景中展示了前所未有的性能和泛化能力。将这些基础模型集成到机器人导航系统中为构建通用机器人开辟了途径。然而，评估这些模型的导航能力仍然受到昂贵的实地试验、过于简化的模拟以及有限基准的限制。我们引入了NaviTrace，这是一个高质量的视觉问答基准，在该基准中，模型接受一个指令和表现形式（人类、腿足式机器人、轮式机器人、自行车），并必须输出一个二维导航轨迹。在1000个场景和超过3000个专家轨迹上，我们系统地使用新引入的语义意识轨迹评分对该基准中的八种最先进的视觉-语言模型进行了评估。该指标结合了动态时间规整距离、目标端点误差以及来自像素级语义的条件惩罚，并与人类偏好相关。我们的评估揭示了由于空间语义理解和目标定位不佳而产生的与人类性能的一致差距。NaviTrace建立了可扩展且可重现的现实世界机器人导航基准。基准和排行榜可在以下链接找到：this https URL。 

---
# Design for One, Deploy for Many: Navigating Tree Mazes with Multiple Agents 

**Title (ZH)**: 为一设计，为多部署：多智能体导航树迷宫 

**Authors**: Jahir Argote-Gerald, Genki Miyauchi, Julian Rau, Paul Trodden, Roderich Gross  

**Link**: [PDF](https://arxiv.org/pdf/2510.26900)  

**Abstract**: Maze-like environments, such as cave and pipe networks, pose unique challenges for multiple robots to coordinate, including communication constraints and congestion. To address these challenges, we propose a distributed multi-agent maze traversal algorithm for environments that can be represented by acyclic graphs. It uses a leader-switching mechanism where one agent, assuming a head role, employs any single-agent maze solver while the other agents each choose an agent to follow. The head role gets transferred to neighboring agents where necessary, ensuring it follows the same path as a single agent would. The multi-agent maze traversal algorithm is evaluated in simulations with groups of up to 300 agents, various maze sizes, and multiple single-agent maze solvers. It is compared against strategies that are naïve, or assume either global communication or full knowledge of the environment. The algorithm outperforms the naïve strategy in terms of makespan and sum-of-fuel. It is superior to the global-communication strategy in terms of makespan but is inferior to it in terms of sum-of-fuel. The findings suggest it is asymptotically equivalent to the full-knowledge strategy with respect to either metric. Moreover, real-world experiments with up to 20 Pi-puck robots confirm the feasibility of the approach. 

**Abstract (ZH)**: 迷宫型环境中的多机器人分布式迷宫穿越算法：适用于有向图表示的洞穴和管道网络环境 

---
# Leveraging Foundation Models for Enhancing Robot Perception and Action 

**Title (ZH)**: 利用基础模型提升机器人感知与行动 

**Authors**: Reihaneh Mirjalili  

**Link**: [PDF](https://arxiv.org/pdf/2510.26855)  

**Abstract**: This thesis investigates how foundation models can be systematically leveraged to enhance robotic capabilities, enabling more effective localization, interaction, and manipulation in unstructured environments. The work is structured around four core lines of inquiry, each addressing a fundamental challenge in robotics while collectively contributing to a cohesive framework for semantics-aware robotic intelligence. 

**Abstract (ZH)**: 本论文研究了如何系统地利用基础模型来增强机器人的能力，以在非结构化环境中实现更有效的定位、交互和操作。工作围绕四个核心研究方向展开，每个方向均针对机器人领域的基本挑战，共同构建一种面向语义的机器人智能整体框架。 

---
# Force Characterization of Insect-Scale Aquatic Propulsion Based on Fluid-Structure Interaction 

**Title (ZH)**: 基于流固耦合的微型昆虫 aquatic 推进力特性研究 

**Authors**: Conor K. Trygstad, Nestor O. Perez-Arancibia  

**Link**: [PDF](https://arxiv.org/pdf/2510.26837)  

**Abstract**: We present force characterizations of two newly developed insect-scale propulsors--one single-tailed and one double-tailed--for microrobotic swimmers that leverage fluid-structure interaction (FSI) to generate thrust. The designs of these two devices were inspired by anguilliform swimming and are driven by soft tails excited by high-work-density (HWD) actuators powered by shape-memory alloy (SMA) wires. While these propulsors have been demonstrated to be suitable for microrobotic aquatic locomotion and controllable with simple architectures for trajectory tracking in the two-dimensional (2D) space, the characteristics and magnitudes of the associated forces have not been studied systematically. In the research presented here, we adopted a theoretical framework based on the notion of reactive forces and obtained experimental data for characterization using a custom-built micro-N-resolution force sensor. We measured maximum and cycle-averaged force values with multi-test means of respectively 0.45 mN and 2.97 micro-N, for the tested single-tail propulsor. For the dual-tail propulsor, we measured maximum and cycle-averaged force values with multi-test means of 0.61 mN and 22.6 micro-N, respectively. These results represent the first measurements of the instantaneous thrust generated by insect-scale propulsors of this type and provide insights into FSI for efficient microrobotic propulsion. 

**Abstract (ZH)**: 我们对两种新型昆虫尺度推进器进行了力特性分析——一种单尾推进器和一种双尾推进器，这些推进器利用流固交互（FSI）产生推力，用于微小型水下机器人游动。这两种装置的设计灵感来源于鳗iform游泳，并由软尾部驱动，软尾部通过形状记忆合金（SMA）线圈驱动的高功密度（HWD）执行器激发。尽管这两种推进器已经在二维空间的轨迹跟踪控制中被证明适合微小型水下机器人游动，但它们的力特性和力的大小尚未系统研究。在本研究中，我们采用基于反作用力概念的理论框架，并使用自制的微N级力传感器获取实验数据。我们测得测试的单尾推进器的最大力和循环平均力分别为0.45 mN和2.97 μN。对于双尾推进器，测得的最大力和循环平均力分别为0.61 mN和22.6 μN。这些结果代表了这种尺度推进器瞬时推力的首次测量，并为高效的微小型机器人推进提供了流固交互的见解。 

---
# Dual-Stream Diffusion for World-Model Augmented Vision-Language-Action Model 

**Title (ZH)**: 双流扩散的世界模型增强视觉-语言-动作模型 

**Authors**: John Won, Kyungmin Lee, Huiwon Jang, Dongyoung Kim, Jinwoo Shin  

**Link**: [PDF](https://arxiv.org/pdf/2510.27607)  

**Abstract**: Recently, augmenting Vision-Language-Action models (VLAs) with world modeling has shown promise in improving robotic policy learning. However, it remains challenging to jointly predict next-state observations and action sequences because of the inherent difference between the two modalities. To address this, we propose DUal-STream diffusion (DUST), a world-model augmented VLA framework that handles the modality conflict and enhances the performance of VLAs across diverse tasks. Specifically, we propose a multimodal diffusion transformer architecture that explicitly maintains separate modality streams while still enabling cross-modal knowledge sharing. In addition, we introduce independent noise perturbations for each modality and a decoupled flow-matching loss. This design enables the model to learn the joint distribution in a bidirectional manner while avoiding the need for a unified latent space. Based on the decoupling of modalities during training, we also introduce a joint sampling method that supports test-time scaling, where action and vision tokens evolve asynchronously at different rates. Through experiments on simulated benchmarks such as RoboCasa and GR-1, DUST achieves up to 6% gains over baseline methods, while our test-time scaling approach provides an additional 2-5% boost. On real-world tasks with the Franka Research 3, DUST improves success rates by 13%, confirming its effectiveness beyond simulation. Furthermore, pre-training on action-free videos from BridgeV2 yields significant transfer gains on RoboCasa, underscoring DUST's potential for large-scale VLA pretraining. 

**Abstract (ZH)**: 最近，通过世界建模增强视觉-语言-行动模型（VLAs）在提升机器人策略学习方面展示了潜力。然而，由于两种模态之间的固有差异，同时预测下一个状态观测和动作序列仍然是一个挑战。为了解决这个问题，我们提出了DUal-STream扩散（DUST）框架，这是一种增强型VLAs框架，能够处理模态冲突并提升VLAs在多种任务中的性能。具体来说，我们提出了一种多模态扩散变换器架构，明确维护独立的模态流，同时仍允许跨模态知识共享。此外，我们引入了独立的噪声扰动以及解耦的流匹配损失。这种设计使模型能够在双向方式下学习联合分布，避免了统一隐空间的需要。基于训练过程中模态的解耦，我们还提出了一种联合采样方法，支持测试时的扩展，在此方法中，动作和视觉标记以不同的速率异步演化。通过在RoboCasa和GR-1等仿真基准上的实验，DUST实现了基线方法的6%改进，而我们的测试时扩展方法提供了额外的2-5%的提升。在使用Franka Research 3进行的真实世界任务中，DUST将成功率提高了13%，证明了其实用性超越了仿真。此外，基于BridgeV2中的无动作视频进行预训练，在RoboCasa上实现了显著的迁移增益，突显了DUST在大规模VLAs预训练中的潜力。 

---
# WildfireX-SLAM: A Large-scale Low-altitude RGB-D Dataset for Wildfire SLAM and Beyond 

**Title (ZH)**: WildfireX-SLAM：一种用于wildfire SLAM及其相关领域的大规模低-altitude RGB-D数据集 

**Authors**: Zhicong Sun, Jacqueline Lo, Jinxing Hu  

**Link**: [PDF](https://arxiv.org/pdf/2510.27133)  

**Abstract**: 3D Gaussian splatting (3DGS) and its subsequent variants have led to remarkable progress in simultaneous localization and mapping (SLAM). While most recent 3DGS-based SLAM works focus on small-scale indoor scenes, developing 3DGS-based SLAM methods for large-scale forest scenes holds great potential for many real-world applications, especially for wildfire emergency response and forest management. However, this line of research is impeded by the absence of a comprehensive and high-quality dataset, and collecting such a dataset over real-world scenes is costly and technically infeasible. To this end, we have built a large-scale, comprehensive, and high-quality synthetic dataset for SLAM in wildfire and forest environments. Leveraging the Unreal Engine 5 Electric Dreams Environment Sample Project, we developed a pipeline to easily collect aerial and ground views, including ground-truth camera poses and a range of additional data modalities from unmanned aerial vehicle. Our pipeline also provides flexible controls on environmental factors such as light, weather, and types and conditions of wildfire, supporting the need for various tasks covering forest mapping, wildfire emergency response, and beyond. The resulting pilot dataset, WildfireX-SLAM, contains 5.5k low-altitude RGB-D aerial images from a large-scale forest map with a total size of 16 km2. On top of WildfireX-SLAM, a thorough benchmark is also conducted, which not only reveals the unique challenges of 3DGS-based SLAM in the forest but also highlights potential improvements for future works. The dataset and code will be publicly available. Project page: this https URL. 

**Abstract (ZH)**: 3D高斯点了拟及其后续变体在同时定位与映射中的进展及其在大规模森林场景中的应用潜力：构建适用于野火和森林环境的大型、全面和高质量合成数据集 

---
# Cooperative Integrated Estimation-Guidance for Simultaneous Interception of Moving Targets 

**Title (ZH)**: 协同集成估测-制导以同时拦截移动目标 

**Authors**: Lohitvel Gopikannan, Shashi Ranjan Kumar, Abhinav Sinha  

**Link**: [PDF](https://arxiv.org/pdf/2510.26948)  

**Abstract**: This paper proposes a cooperative integrated estimation-guidance framework for simultaneous interception of a non-maneuvering target using a team of unmanned autonomous vehicles, assuming only a subset of vehicles are equipped with dedicated sensors to measure the target's states. Unlike earlier approaches that focus solely on either estimation or guidance design, the proposed framework unifies both within a cooperative architecture. To circumvent the limitation posed by heterogeneity in target observability, sensorless vehicles estimate the target's state by leveraging information exchanged with neighboring agents over a directed communication topology through a prescribed-time observer. The proposed approach employs true proportional navigation guidance (TPNG), which uses an exact time-to-go formulation and is applicable across a wide spectrum of target motions. Furthermore, prescribed-time observer and controller are employed to achieve convergence to true target's state and consensus in time-to-go within set predefined times, respectively. Simulations demonstrate the effectiveness of the proposed framework under various engagement scenarios. 

**Abstract (ZH)**: 基于自主无人车辆团队的非机动目标协同综合估计与制导框架 

---
