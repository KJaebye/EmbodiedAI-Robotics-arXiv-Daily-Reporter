# UoR-NCL at SemEval-2025 Task 1: Using Generative LLMs and CLIP Models for Multilingual Multimodal Idiomaticity Representation 

**Title (ZH)**: UoR-NCL在SemEval-2025任务1中的研究：使用生成性大语言模型和CLIP模型进行多语言多模态习语表示 

**Authors**: Thanet Markchom, Tong Wu, Liting Huang, Huizhi Liang  

**Link**: [PDF](https://arxiv.org/pdf/2502.20984)  

**Abstract**: SemEval-2025 Task 1 focuses on ranking images based on their alignment with a given nominal compound that may carry idiomatic meaning in both English and Brazilian Portuguese. To address this challenge, this work uses generative large language models (LLMs) and multilingual CLIP models to enhance idiomatic compound representations. LLMs generate idiomatic meanings for potentially idiomatic compounds, enriching their semantic interpretation. These meanings are then encoded using multilingual CLIP models, serving as representations for image ranking. Contrastive learning and data augmentation techniques are applied to fine-tune these embeddings for improved performance. Experimental results show that multimodal representations extracted through this method outperformed those based solely on the original nominal compounds. The fine-tuning approach shows promising outcomes but is less effective than using embeddings without fine-tuning. The source code used in this paper is available at this https URL. 

**Abstract (ZH)**: SemEval-2025 任务 1 专注于根据给定可能具有隐喻意义的名词化合物对图像进行排序。为了应对这一挑战，本工作使用生成型大规模语言模型（LLMs）和多语言 CLIP 模型来增强隐喻化合物的表示。LLMs 为潜在的隐喻化合物生成隐喻意义，丰富其语义解释。这些意义随后通过多语言 CLIP 模型进行编码，用作图像排序的表示。对比学习和数据增强技术被应用于微调这些嵌入，以提高性能。实验结果表明，通过此方法提取的多模态表示优于仅基于原始名词化合物的表示。微调方法显示出有希望的结果，但其效果不如使用未微调的嵌入。本文使用的所有源代码均可在此处访问。 

---
# Multimodal Learning for Just-In-Time Software Defect Prediction in Autonomous Driving Systems 

**Title (ZH)**: 即时软件缺陷预测的多模态学习在自主驾驶系统中 

**Authors**: Faisal Mohammad, Duksan Ryu  

**Link**: [PDF](https://arxiv.org/pdf/2502.20806)  

**Abstract**: In recent years, the rise of autonomous driving technologies has highlighted the critical importance of reliable software for ensuring safety and performance. This paper proposes a novel approach for just-in-time software defect prediction (JIT-SDP) in autonomous driving software systems using multimodal learning. The proposed model leverages the multimodal transformers in which the pre-trained transformers and a combining module deal with the multiple data modalities of the software system datasets such as code features, change metrics, and contextual information. The key point for adapting multimodal learning is to utilize the attention mechanism between the different data modalities such as text, numerical, and categorical. In the combining module, the output of a transformer model on text data and tabular features containing categorical and numerical data are combined to produce the predictions using the fully connected layers. Experiments conducted on three open-source autonomous driving system software projects collected from the GitHub repository (Apollo, Carla, and Donkeycar) demonstrate that the proposed approach significantly outperforms state-of-the-art deep learning and machine learning models regarding evaluation metrics. Our findings highlight the potential of multimodal learning to enhance the reliability and safety of autonomous driving software through improved defect prediction. 

**Abstract (ZH)**: 基于多模态学习的即时软件缺陷预测在自主驾驶软件系统中的应用 

---
