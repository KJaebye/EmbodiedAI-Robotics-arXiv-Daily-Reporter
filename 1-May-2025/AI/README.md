# Is Intermediate Fusion All You Need for UAV-based Collaborative Perception? 

**Title (ZH)**: 基于无人机的协作感知中，中间融合是否足矣？ 

**Authors**: Jiuwu Hao, Liguo Sun, Yuting Wan, Yueyang Wu, Ti Xiang, Haolin Song, Pin Lv  

**Link**: [PDF](https://arxiv.org/pdf/2504.21774)  

**Abstract**: Collaborative perception enhances environmental awareness through inter-agent communication and is regarded as a promising solution to intelligent transportation systems. However, existing collaborative methods for Unmanned Aerial Vehicles (UAVs) overlook the unique characteristics of the UAV perspective, resulting in substantial communication overhead. To address this issue, we propose a novel communication-efficient collaborative perception framework based on late-intermediate fusion, dubbed LIF. The core concept is to exchange informative and compact detection results and shift the fusion stage to the feature representation level. In particular, we leverage vision-guided positional embedding (VPE) and box-based virtual augmented feature (BoBEV) to effectively integrate complementary information from various agents. Additionally, we innovatively introduce an uncertainty-driven communication mechanism that uses uncertainty evaluation to select high-quality and reliable shared areas. Experimental results demonstrate that our LIF achieves superior performance with minimal communication bandwidth, proving its effectiveness and practicality. Code and models are available at this https URL. 

**Abstract (ZH)**: 协作感知通过代理间通信增强环境意识，被视为智能交通系统的有前途的解决方案。然而，现有的基于无人机的协作方法忽略了无人机视角的独特特性，导致了显著的通信开销。为解决这一问题，我们提出了一种基于晚期中间融合的新型通信高效协作感知框架，命名为LIF。核心概念是交换信息丰富且紧凑的检测结果，并将融合阶段转移至特征表示级别。特别是在此基础上，我们利用基于视觉的定位嵌入(VPE)和基于框的虚拟 augmented 特征(BoBEV)有效整合了来自各种代理的互补信息。此外，我们创新性地引入了一种基于不确定性驱动的通信机制，使用不确定性评估来选择高质量和可靠的共享区域。实验结果表明，LIF 在最小通信带宽下实现了优越的性能，证明了其有效性和实用性。相关代码和模型可从此链接获取。 

---
# Automatic Mapping of AutomationML Files to Ontologies for Graph Queries and Validation 

**Title (ZH)**: 自动将AutomationML文件映射到本体以进行图查询和验证 

**Authors**: Tom Westermann, Malte Ramonat, Johannes Hujer, Felix Gehlhoff, Alexander Fay  

**Link**: [PDF](https://arxiv.org/pdf/2504.21694)  

**Abstract**: AutomationML has seen widespread adoption as an open data exchange format in the automation domain. It is an open and vendor neutral standard based on the extensible markup language XML. However, AutomationML extends XML with additional semantics, that limit the applicability of common XML-tools for applications like querying or data validation. This article provides practitioners with 1) an up-to-date ontology of the concepts in the AutomationML-standard, as well as 2) a declarative mapping to automatically transform any AutomationML model into RDF triples. Together, these artifacts allow practitioners an easy integration of AutomationML information into industrial knowledge graphs. A study on examples from the automation domain concludes that transforming AutomationML to OWL opens up new powerful ways for querying and validation that are impossible without transformation. 

**Abstract (ZH)**: AutomationML作为开放数据交换格式在自动化领域得到了广泛应用。它是一种基于可扩展标记语言XML的开放和供应商中立标准。然而，AutomationML通过添加附加语义扩展了XML，这限制了常用XML工具（如查询或数据验证）的适用性。本文为实践者提供了1) AutomationML标准中概念的最新本体论描述，以及2) 一种声明性映射，以自动将任何AutomationML模型转换为RDF三元组。这些成果使实践者能够轻松地将AutomationML信息集成到工业知识图谱中。研究表明，将AutomationML转换为OWL为查询和验证开辟了新的强大方式，这些方式在不进行转换的情况下是不可能实现的。 

---
# Extension-ranking Semantics for Abstract Argumentation Preprint 

**Title (ZH)**: 抽象论辩扩展-排序语义预印本 

**Authors**: Kenneth Skiba, Tjitze Rienstra, Matthias Thimm, Jesse Heyninck, Gabriele Kern-Isberner  

**Link**: [PDF](https://arxiv.org/pdf/2504.21683)  

**Abstract**: In this paper, we present a general framework for ranking sets of arguments in abstract argumentation based on their plausibility of acceptance. We present a generalisation of Dung's extension semantics as extension-ranking semantics, which induce a preorder over the power set of all arguments, allowing us to state that one set is "closer" to being acceptable than another. To evaluate the extension-ranking semantics, we introduce a number of principles that a well-behaved extension-ranking semantics should satisfy. We consider several simple base relations, each of which models a single central aspect of argumentative reasoning. The combination of these base relations provides us with a family of extension-ranking semantics. We also adapt a number of approaches from the literature for ranking extensions to be usable in the context of extension-ranking semantics, and evaluate their behaviour. 

**Abstract (ZH)**: 本文提出了一种基于可接受性的可信度对抽象论辩集进行排名的一般框架。我们将Dung的扩展语义推广为扩展排名语义，从而在所有论题集的幂集中诱导一个部分有序关系，使得我们可以断言一个集合比另一个集合更“接近”可接受。为了评估扩展排名语义，我们提出了若干个良好的扩展排名语义应满足的原则。我们考虑了几种简单的基础关系，每种关系模型了论辩推理的核心方面之一。这些基础关系的组合为我们提供了一系列的扩展排名语义。我们还对文献中用于排名扩展的方法进行了改编，以便在扩展排名语义的背景下使用，并对它们的行为进行了评估。 

---
# AdaR1: From Long-CoT to Hybrid-CoT via Bi-Level Adaptive Reasoning Optimization 

**Title (ZH)**: AdaR1: 从长共理性思考到混合共理性思考 via 双层自适应推理优化 

**Authors**: Haotian Luo, Haiying He, Yibo Wang, Jinluan Yang, Rui Liu, Naiqiang Tan, Xiaochun Cao, Dacheng Tao, Li Shen  

**Link**: [PDF](https://arxiv.org/pdf/2504.21659)  

**Abstract**: Recently, long-thought reasoning models achieve strong performance on complex reasoning tasks, but often incur substantial inference overhead, making efficiency a critical concern. Our empirical analysis reveals that the benefit of using Long-CoT varies across problems: while some problems require elaborate reasoning, others show no improvement, or even degraded accuracy. This motivates adaptive reasoning strategies that tailor reasoning depth to the input. However, prior work primarily reduces redundancy within long reasoning paths, limiting exploration of more efficient strategies beyond the Long-CoT paradigm. To address this, we propose a novel two-stage framework for adaptive and efficient reasoning. First, we construct a hybrid reasoning model by merging long and short CoT models to enable diverse reasoning styles. Second, we apply bi-level preference training to guide the model to select suitable reasoning styles (group-level), and prefer concise and correct reasoning within each style group (instance-level). Experiments demonstrate that our method significantly reduces inference costs compared to other baseline approaches, while maintaining performance. Notably, on five mathematical datasets, the average length of reasoning is reduced by more than 50%, highlighting the potential of adaptive strategies to optimize reasoning efficiency in large language models. Our code is coming soon at this https URL 

**Abstract (ZH)**: 最近，长期被认为的推理模型在复杂推理任务上取得了很强的效果，但往往会导致显著的推理开销，使效率成为一个关键问题。我们的实证分析表明，使用长-CoT的好处因问题而异：一些问题需要详细的推理，而另一些则没有改进，甚至准确度下降。这促使了适应性推理策略的发展，这些策略可以根据输入调整推理深度。然而，现有工作主要减少了长推理路径内的冗余，限制了超出长-CoT范式的更高效策略的探索。为此，我们提出了一种新的两阶段框架，以实现适应性和高效推理。首先，我们通过合并长-CoT模型和短-CoT模型构建了一种混合推理模型，以支持多种推理风格。其次，我们应用分级偏好训练来引导模型选择合适推理风格（群组级别），并在每个风格组中偏好简洁和正确的推理（实例级别）。实验表明，与其它基线方法相比，我们的方法显著降低了推理成本，同时保持了性能。值得注意的是，对于五个数学数据集，推理的平均长度减少了超过50%，突显了适应性策略在大型语言模型中优化推理效率的潜力。我们的代码将在此处提供：https://github.com/alibaba/Qwen 

---
# Designing Control Barrier Function via Probabilistic Enumeration for Safe Reinforcement Learning Navigation 

**Title (ZH)**: 基于概率枚举的安全强化学习导航控制屏障函数设计 

**Authors**: Luca Marzari, Francesco Trotti, Enrico Marchesini, Alessandro Farinelli  

**Link**: [PDF](https://arxiv.org/pdf/2504.21643)  

**Abstract**: Achieving safe autonomous navigation systems is critical for deploying robots in dynamic and uncertain real-world environments. In this paper, we propose a hierarchical control framework leveraging neural network verification techniques to design control barrier functions (CBFs) and policy correction mechanisms that ensure safe reinforcement learning navigation policies. Our approach relies on probabilistic enumeration to identify unsafe regions of operation, which are then used to construct a safe CBF-based control layer applicable to arbitrary policies. We validate our framework both in simulation and on a real robot, using a standard mobile robot benchmark and a highly dynamic aquatic environmental monitoring task. These experiments demonstrate the ability of the proposed solution to correct unsafe actions while preserving efficient navigation behavior. Our results show the promise of developing hierarchical verification-based systems to enable safe and robust navigation behaviors in complex scenarios. 

**Abstract (ZH)**: 实现安全自主导航系统对于在动态和不确定性高的实际环境中部署机器人至关重要。本文提出了一种基于神经网络验证技术的层次控制框架，用于设计控制障碍函数（CBFs）和策略纠正机制，以确保安全的强化学习导航策略。我们的方法依赖于概率枚举来识别操作的不安全区域，然后用于构建适用于任意策略的安全CBF控制层。我们在仿真和实际机器人上均对框架进行了验证，使用标准的移动机器人基准测试和高度动态的水下环境监测任务。这些实验展示了所提出解决方案能够纠正不安全行为的同时保持高效的导航行为的能力。我们的结果表明，基于层次验证的系统在复杂场景中实现安全稳健的导航行为具有很大的潜力。 

---
# A Study on Group Decision Making Problem Based on Fuzzy Reasoning and Bayesian Networks 

**Title (ZH)**: 基于模糊推理和贝叶斯网络的群体决策问题研究 

**Authors**: Shui-jin Rong, Wei Guo, Da-qing Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2504.21568)  

**Abstract**: Aiming at the group decision - making problem with multi - objective attributes, this study proposes a group decision - making system that integrates fuzzy inference and Bayesian network. A fuzzy rule base is constructed by combining threshold values, membership functions, expert experience, and domain knowledge to address quantitative challenges such as scale differences and expert linguistic variables. A hierarchical Bayesian network is designed, featuring a directed acyclic graph with nodes selected by experts, and maximum likelihood estimation is used to dynamically optimize the conditional probability table, modeling the nonlinear correlations among multidimensional indices for posterior probability aggregation. In a comprehensive student evaluation case, this method is compared with the traditional weighted scoring approach. The results indicate that the proposed method demonstrates effectiveness in both rule criterion construction and ranking consistency, with a classification accuracy of 86.0% and an F1 value improvement of 53.4% over the traditional method. Additionally, computational experiments on real - world datasets across various group decision scenarios assess the method's performance and robustness, providing evidence of its reliability in diverse contexts. 

**Abstract (ZH)**: 针对多目标属性的群体决策问题，本研究提出了一种集成模糊推理和贝叶斯网络的群体决策系统。通过结合阈值、隶属函数、专家经验和领域知识构建模糊规则库，以解决尺度差异和专家语言变量等量化挑战。设计了一种层次贝叶斯网络，采用专家选取节点的有向无环图，并使用最大似然估计动态优化条件概率表，建模多维指标之间的非线性相关关系，实现后验概率聚合。在综合的学生评估案例中，该方法与传统的加权评分方法进行了对比。实验结果表明，该方法在规则标准构建和排名一致性方面表现出有效性，分类准确率为86.0%，F1值提高了53.4%。此外，通过对不同群体决策场景下的实际数据集进行计算实验，评估了该方法的性能和稳健性，为其在不同情境下的可靠性提供了证据。 

---
# NGENT: Next-Generation AI Agents Must Integrate Multi-Domain Abilities to Achieve Artificial General Intelligence 

**Title (ZH)**: NGENT: 下一代AI代理需集成多域能力以实现人工通用智能 

**Authors**: Zhicong Li, Hangyu Mao, Jiangjin Yin, Mingzhe Xing, Zhiwei Xu, Yuanxing Zhang, Yang Xiao  

**Link**: [PDF](https://arxiv.org/pdf/2504.21433)  

**Abstract**: This paper argues that the next generation of AI agent (NGENT) should integrate across-domain abilities to advance toward Artificial General Intelligence (AGI). Although current AI agents are effective in specialized tasks such as robotics, role-playing, and tool-using, they remain confined to narrow domains. We propose that future AI agents should synthesize the strengths of these specialized systems into a unified framework capable of operating across text, vision, robotics, reinforcement learning, emotional intelligence, and beyond. This integration is not only feasible but also essential for achieving the versatility and adaptability that characterize human intelligence. The convergence of technologies across AI domains, coupled with increasing user demand for cross-domain capabilities, suggests that such integration is within reach. Ultimately, the development of these versatile agents is a critical step toward realizing AGI. This paper explores the rationale for this shift, potential pathways for achieving it. 

**Abstract (ZH)**: 下一代人工智能代理（NGENT）应跨域集成以迈向人工通用智能（AGI） 

---
# ShorterBetter: Guiding Reasoning Models to Find Optimal Inference Length for Efficient Reasoning 

**Title (ZH)**: 更短更优：引导推理模型寻找高效的推理最优推断长度 

**Authors**: Jingyang Yi, Jiazheng Wang  

**Link**: [PDF](https://arxiv.org/pdf/2504.21370)  

**Abstract**: Reasoning models such as OpenAI o3 and DeepSeek-R1 have demonstrated strong performance on reasoning-intensive tasks through extended Chain-of-Thought (CoT) prompting. While longer reasoning traces can facilitate a more thorough exploration of solution paths for complex problems, researchers have observed that these models often "overthink", leading to inefficient inference. In this paper, we introduce ShorterBetter, a simple yet effective reinforcement learning methed that enables reasoning language models to discover their own optimal CoT lengths without human intervention. By sampling multiple outputs per problem and defining the Sample Optimal Length (SOL) as the shortest correct response among all the outputs, our method dynamically guides the model toward optimal inference lengths. Applied to the DeepSeek-Distill-Qwen-1.5B model, ShorterBetter achieves up to an 80% reduction in output length on both in-domain and out-of-domain reasoning tasks while maintaining accuracy. Our analysis shows that overly long reasoning traces often reflect loss of reasoning direction, and thus suggests that the extended CoT produced by reasoning models is highly compressible. 

**Abstract (ZH)**: ShorterBetter：一种简单有效的强化学习方法，使推理语言模型自主发现最优的链式思考长度 

---
# IRL Dittos: Embodied Multimodal AI Agent Interactions in Open Spaces 

**Title (ZH)**: IRL Ditto们：开放空间中的具身多模态AI代理互动 

**Authors**: Seonghee Lee, Denae Ford, John Tang, Sasa Junuzovic, Asta Roseway, Ed Cutrell, Kori Inkpen  

**Link**: [PDF](https://arxiv.org/pdf/2504.21347)  

**Abstract**: We introduce the In Real Life (IRL) Ditto, an AI-driven embodied agent designed to represent remote colleagues in shared office spaces, creating opportunities for real-time exchanges even in their absence. IRL Ditto offers a unique hybrid experience by allowing in-person colleagues to encounter a digital version of their remote teammates, initiating greetings, updates, or small talk as they might in person. Our research question examines: How can the IRL Ditto influence interactions and relationships among colleagues in a shared office space? Through a four-day study, we assessed IRL Ditto's ability to strengthen social ties by simulating presence and enabling meaningful interactions across different levels of social familiarity. We find that enhancing social relationships depended deeply on the foundation of the relationship participants had with the source of the IRL Ditto. This study provides insights into the role of embodied agents in enriching workplace dynamics for distributed teams. 

**Abstract (ZH)**: We introduce the In Real Life (IRL) Ditto, 一个由AI驱动的具身代理，旨在代表远程同事在共享办公空间中参与，即使在远程同事缺席的情况下，也能创造实时交流的机会。IRL Ditto提供了一种独特的混合体验，允许在场同事遇到其远程队友的数字化版本，通过问候、更新或闲聊等方式进行互动。本研究的问题是：IRL Ditto如何影响共享办公空间中同事之间的互动和关系？通过为期四天的研究，我们评估了IRL Ditto增强社会纽带、模拟存在感并促进不同熟悉程度下的有意义互动的能力。我们发现，增强社会关系在很大程度上取决于参与者与IRL Ditto来源的关系基础。本研究提供了有关具身代理在丰富分布式团队的职场动态方面作用的见解。 

---
# Phi-4-reasoning Technical Report 

**Title (ZH)**: Phi-4推理技术报告 

**Authors**: Marah Abdin, Sahaj Agarwal, Ahmed Awadallah, Vidhisha Balachandran, Harkirat Behl, Lingjiao Chen, Gustavo de Rosa, Suriya Gunasekar, Mojan Javaheripi, Neel Joshi, Piero Kauffmann, Yash Lara, Caio César Teodoro Mendes, Arindam Mitra, Besmira Nushi, Dimitris Papailiopoulos, Olli Saarikivi, Shital Shah, Vaishnavi Shrivastava, Vibhav Vineet, Yue Wu, Safoora Yousefi, Guoqing Zheng  

**Link**: [PDF](https://arxiv.org/pdf/2504.21318)  

**Abstract**: We introduce Phi-4-reasoning, a 14-billion parameter reasoning model that achieves strong performance on complex reasoning tasks. Trained via supervised fine-tuning of Phi-4 on carefully curated set of "teachable" prompts-selected for the right level of complexity and diversity-and reasoning demonstrations generated using o3-mini, Phi-4-reasoning generates detailed reasoning chains that effectively leverage inference-time compute. We further develop Phi-4-reasoning-plus, a variant enhanced through a short phase of outcome-based reinforcement learning that offers higher performance by generating longer reasoning traces. Across a wide range of reasoning tasks, both models outperform significantly larger open-weight models such as DeepSeek-R1-Distill-Llama-70B model and approach the performance levels of full DeepSeek-R1 model. Our comprehensive evaluations span benchmarks in math and scientific reasoning, coding, algorithmic problem solving, planning, and spatial understanding. Interestingly, we observe a non-trivial transfer of improvements to general-purpose benchmarks as well. In this report, we provide insights into our training data, our training methodologies, and our evaluations. We show that the benefit of careful data curation for supervised fine-tuning (SFT) extends to reasoning language models, and can be further amplified by reinforcement learning (RL). Finally, our evaluation points to opportunities for improving how we assess the performance and robustness of reasoning models. 

**Abstract (ZH)**: Phi-4-reasoning及其增强模型的推理研究：一种140亿参数的强性能复杂推理模型 

---
# Reinforced MLLM: A Survey on RL-Based Reasoning in Multimodal Large Language Models 

**Title (ZH)**: 强化多模态大语言模型：基于RL的推理综述 

**Authors**: Guanghao Zhou, Panjia Qiu, Cen Chen, Jie Wang, Zheming Yang, Jian Xu, Minghui Qiu  

**Link**: [PDF](https://arxiv.org/pdf/2504.21277)  

**Abstract**: The integration of reinforcement learning (RL) into the reasoning capabilities of Multimodal Large Language Models (MLLMs) has rapidly emerged as a transformative research direction. While MLLMs significantly extend Large Language Models (LLMs) to handle diverse modalities such as vision, audio, and video, enabling robust reasoning across multimodal inputs remains a major challenge. This survey systematically reviews recent advances in RL-based reasoning for MLLMs, covering key algorithmic designs, reward mechanism innovations, and practical applications. We highlight two main RL paradigms--value-free and value-based methods--and analyze how RL enhances reasoning abilities by optimizing reasoning trajectories and aligning multimodal information. Furthermore, we provide an extensive overview of benchmark datasets, evaluation protocols, and existing limitations, and propose future research directions to address current bottlenecks such as sparse rewards, inefficient cross-modal reasoning, and real-world deployment constraints. Our goal is to offer a comprehensive and structured guide to researchers interested in advancing RL-based reasoning in the multimodal era. 

**Abstract (ZH)**: 将强化学习（RL）整合到多模态大规模语言模型（MLLMs）的推理能力中，已成为一项 transformative 研究方向。尽管 MLLMs 显著扩展了大规模语言模型（LLMs），使其能够处理多种模态如视觉、音频和视频，但跨模态输入的稳健推理仍然是一个主要挑战。本文系统地回顾了基于 RL 的推理方法在 MLLMs 中的最新进展，涵盖关键算法设计、奖励机制创新和实际应用。我们着重介绍了两种主要的 RL 原理——价值自由方法和价值依赖方法，并分析了 RL 如何通过优化推理轨迹和对齐多模态信息来增强推理能力。此外，本文还提供了基准数据集、评估协议的详尽概述及现有局限性，并提出了未来研究方向，以解决当前瓶颈问题，如稀疏奖励、低效的跨模态推理和现实世界部署限制。我们的目标是为有兴趣深化多模态时代基于 RL 的推理研究的科研人员提供一份全面和结构化的指南。 

---
# Theoretical Foundations for Semantic Cognition in Artificial Intelligence 

**Title (ZH)**: 人工智能中语义认知的理论基础 

**Authors**: Sebastian Dumbrava  

**Link**: [PDF](https://arxiv.org/pdf/2504.21218)  

**Abstract**: This monograph presents a modular cognitive architecture for artificial intelligence grounded in the formal modeling of belief as structured semantic state. Belief states are defined as dynamic ensembles of linguistic expressions embedded within a navigable manifold, where operators enable assimilation, abstraction, nullification, memory, and introspection. Drawing from philosophy, cognitive science, and neuroscience, we develop a layered framework that enables self-regulating epistemic agents capable of reflective, goal-directed thought. At the core of this framework is the epistemic vacuum: a class of semantically inert cognitive states that serves as the conceptual origin of belief space. From this foundation, the Null Tower arises as a generative structure recursively built through internal representational capacities. The theoretical constructs are designed to be implementable in both symbolic and neural systems, including large language models, hybrid agents, and adaptive memory architectures. This work offers a foundational substrate for constructing agents that reason, remember, and regulate their beliefs in structured, interpretable ways. 

**Abstract (ZH)**: 本论著介绍了基于正式的信念结构语义建模的人工智能模块化认知架构。该架构定义了动态的语言表达嵌入可导航流形中的信念状态，并通过操作符实现同化、抽象、消除、记忆和反省。借鉴哲学、认知科学和神经科学，我们构建了一个分层框架，使能够进行反思性、目标导向思考的自主知识代理成为可能。该框架的核心是知识真空：一类语义中立的认知状态，作为信念空间的概念起点。在此基础上，虚塔作为生成结构，通过内部表征能力递归构建。这些理论构造既可用于符号系统，也可用于神经系统，包括大型语言模型、混合代理和自适应记忆架构。本研究提供了构建以结构化和可解释方式推理、记忆和调节信念的代理的基础框架。 

---
# AffectEval: A Modular and Customizable Framework for Affective Computing 

**Title (ZH)**: AffectEval：一种模块化可定制的情感计算框架 

**Authors**: Emily Zhou, Khushboo Khatri, Yixue Zhao, Bhaskar Krishnamachari  

**Link**: [PDF](https://arxiv.org/pdf/2504.21184)  

**Abstract**: The field of affective computing focuses on recognizing, interpreting, and responding to human emotions, and has broad applications across education, child development, and human health and wellness. However, developing affective computing pipelines remains labor-intensive due to the lack of software frameworks that support multimodal, multi-domain emotion recognition applications. This often results in redundant effort when building pipelines for different applications. While recent frameworks attempt to address these challenges, they remain limited in reducing manual effort and ensuring cross-domain generalizability. We introduce AffectEval, a modular and customizable framework to facilitate the development of affective computing pipelines while reducing the manual effort and duplicate work involved in developing such pipelines. We validate AffectEval by replicating prior affective computing experiments, and we demonstrate that our framework reduces programming effort by up to 90%, as measured by the reduction in raw lines of code. 

**Abstract (ZH)**: 情感计算领域专注于识别、解释和响应人类情绪，并在教育、儿童发展和人类健康与福祉等领域拥有广泛的应用前景。然而，由于缺乏支持多模态、多领域情绪识别的应用软件框架，开发情感计算管道仍具有劳动密集型特征。这常常导致在为不同应用程序构建管道时出现重复劳动。尽管最近的框架试图解决这些挑战，但在减少手动努力和确保跨域通用性方面仍然有限。我们引入了AffectEval，这是一个模块化和可定制的框架，旨在促进情感计算管道的开发，同时减少开发此类管道所涉及的手动努力和重复劳动。我们通过复制先前的情感计算实验验证了AffectEval，并证明我们的框架通过减少原始代码行数最多90%的方式减少了编程努力。 

---
# A Formalism for Optimal Search with Dynamic Heuristics 

**Title (ZH)**: 一种带有动态启发式的最优搜索形式化方法 

**Authors**: Remo Christen, Florian Pommerening, Clemens Büchner, Malte Helmert  

**Link**: [PDF](https://arxiv.org/pdf/2504.21131)  

**Abstract**: While most heuristics studied in heuristic search depend only on the state, some accumulate information during search and thus also depend on the search history. Various existing approaches use such dynamic heuristics in $\mathrm{A}^*$-like algorithms and appeal to classic results for $\mathrm{A}^*$ to show optimality. However, doing so ignores the complexities of searching with a mutable heuristic. In this paper we formalize the idea of dynamic heuristics and use them in a generic algorithm framework. We study a particular instantiation that models $\mathrm{A}^*$ with dynamic heuristics and show general optimality results. Finally we show how existing approaches from classical planning can be viewed as special cases of this instantiation, making it possible to directly apply our optimality results. 

**Abstract (ZH)**: 虽然大多数在启发式搜索中研究的启发式方法仅依赖于状态，但有些启发式方法在搜索过程中累积信息，因此也依赖于搜索历史。现有方法在类似A*的算法中使用此类动态启发式方法，并依靠A*的经典结果来证明其最优性。然而，这样做忽略了使用可变启发式进行搜索的复杂性。在本文中，我们正式化动态启发式的思想，并在通用算法框架中使用它们。我们研究了一种特定实例，该实例使用动态启发式方法建模A*，并给出了通用的最优性结果。最后，我们展示了现有的经典规划方法可以被视为该实例的特例，从而使我们能够直接应用我们的最优性结果。 

---
# TRUST: An LLM-Based Dialogue System for Trauma Understanding and Structured Assessments 

**Title (ZH)**: TRUST：基于LLM的创伤理解与结构化评估对话系统 

**Authors**: Sichang Tu, Abigail Powers, Stephen Doogan, Jinho D. Choi  

**Link**: [PDF](https://arxiv.org/pdf/2504.21851)  

**Abstract**: Objectives: While Large Language Models (LLMs) have been widely used to assist clinicians and support patients, no existing work has explored dialogue systems for standard diagnostic interviews and assessments. This study aims to bridge the gap in mental healthcare accessibility by developing an LLM-powered dialogue system that replicates clinician behavior. Materials and Methods: We introduce TRUST, a framework of cooperative LLM modules capable of conducting formal diagnostic interviews and assessments for Post-Traumatic Stress Disorder (PTSD). To guide the generation of appropriate clinical responses, we propose a Dialogue Acts schema specifically designed for clinical interviews. Additionally, we develop a patient simulation approach based on real-life interview transcripts to replace time-consuming and costly manual testing by clinicians. Results: A comprehensive set of evaluation metrics is designed to assess the dialogue system from both the agent and patient simulation perspectives. Expert evaluations by conversation and clinical specialists show that TRUST performs comparably to real-life clinical interviews. Discussion: Our system performs at the level of average clinicians, with room for future enhancements in communication styles and response appropriateness. Conclusions: Our TRUST framework shows its potential to facilitate mental healthcare availability. 

**Abstract (ZH)**: 目标：虽然大型语言模型（LLMs）已被广泛用于辅助临床医生并支持患者，但目前尚未有研究探索用于标准化诊断访谈和评估的对话系统。本研究旨在通过开发一个由LLM驱动的对话系统来弥补心理健康服务可及性的缺口，该对话系统能够模仿临床医生的行为。材料与方法：我们介绍了TRUST框架，这是一种协作的LLM模块体系，能够进行创伤后应激障碍（PTSD）的标准诊断访谈和评估。为了引导生成合适的临床回应，我们提出了一个专门设计用于临床访谈的对话行为方案。此外，我们还开发了一种基于真实访谈记录的患者模拟方法，以替代耗时且成本高昂的临床手动测试。结果：设计了一套全面的评估指标，从代理和患者模拟的角度评估对话系统的表现。由对话和临床专家进行的专家评估表明，TRUST的表现与现实生活中的临床访谈相当。讨论：我们的系统达到了平均水平临床医生的水平，未来在沟通风格和回应适当性方面仍有机会进一步改进。结论：我们的TRUST框架展示了其在促进心理健康服务可及性方面的潜力。 

---
# Public Opinion and The Rise of Digital Minds: Perceived Risk, Trust, and Regulation Support 

**Title (ZH)**: 公众意见与数字思维的崛起：感知风险、信任与监管支持 

**Authors**: Justin B. Bullock, Janet V.T. Pauketat, Hsini Huang, Yi-Fan Wang, Jacy Reese Anthis  

**Link**: [PDF](https://arxiv.org/pdf/2504.21849)  

**Abstract**: Governance institutions must respond to societal risks, including those posed by generative AI. This study empirically examines how public trust in institutions and AI technologies, along with perceived risks, shape preferences for AI regulation. Using the nationally representative 2023 Artificial Intelligence, Morality, and Sentience (AIMS) survey, we assess trust in government, AI companies, and AI technologies, as well as public support for regulatory measures such as slowing AI development or outright bans on advanced AI. Our findings reveal broad public support for AI regulation, with risk perception playing a significant role in shaping policy preferences. Individuals with higher trust in government favor regulation, while those with greater trust in AI companies and AI technologies are less inclined to support restrictions. Trust in government and perceived risks significantly predict preferences for both soft (e.g., slowing development) and strong (e.g., banning AI systems) regulatory interventions. These results highlight the importance of public opinion in AI governance. As AI capabilities advance, effective regulation will require balancing public concerns about risks with trust in institutions. This study provides a foundational empirical baseline for policymakers navigating AI governance and underscores the need for further research into public trust, risk perception, and regulatory strategies in the evolving AI landscape. 

**Abstract (ZH)**: 治理机构必须应对包括生成性人工智能在内的一系列社会风险。本研究通过实证分析考察公众对机构和人工智能技术的信任以及感知风险如何影响对人工智能监管的偏好。利用2023年人工智能、道德与意识（AIMS）全国代表性调查，我们评估了公众对政府、人工智能公司和人工智能技术的信任，以及对如减缓人工智能发展或全面禁止高级人工智能等监管措施的支持程度。研究发现，公众普遍支持人工智能监管，感知风险在塑造政策偏好方面发挥着重要作用。政府信任较高的个体倾向于支持监管，而对人工智能公司和人工智能技术有较高信任的个体则不太支持限制措施。政府信任和感知风险显著预测对软性（如减缓发展）和强硬（如禁止人工智能系统）监管干预措施的偏好。这些结果突显了公众意见在人工智能治理中的重要性。随着人工智能能力的不断提升，有效的监管需要在平衡公众对风险的担忧与对机构的信任之间找到平衡。本研究为政策制定者在人工智能治理中的判断提供了基础性的实证基准，并强调了进一步研究公众信任、风险感知和监管策略在不断变化的人工智能格局中的重要性。 

---
# Characterizing AI Agents for Alignment and Governance 

**Title (ZH)**: 刻画AI代理以实现对齐与治理 

**Authors**: Atoosa Kasirzadeh, Iason Gabriel  

**Link**: [PDF](https://arxiv.org/pdf/2504.21848)  

**Abstract**: The creation of effective governance mechanisms for AI agents requires a deeper understanding of their core properties and how these properties relate to questions surrounding the deployment and operation of agents in the world. This paper provides a characterization of AI agents that focuses on four dimensions: autonomy, efficacy, goal complexity, and generality. We propose different gradations for each dimension, and argue that each dimension raises unique questions about the design, operation, and governance of these systems. Moreover, we draw upon this framework to construct "agentic profiles" for different kinds of AI agents. These profiles help to illuminate cross-cutting technical and non-technical governance challenges posed by different classes of AI agents, ranging from narrow task-specific assistants to highly autonomous general-purpose systems. By mapping out key axes of variation and continuity, this framework provides developers, policymakers, and members of the public with the opportunity to develop governance approaches that better align with collective societal goals. 

**Abstract (ZH)**: 有效治理机制的创建需要对AI代理的核心属性及其与代理部署和操作相关问题有更深入的理解。本文从自主性、有效性、目标复杂性和普适性四个维度对AI代理进行刻画，并提出每个维度的不同层次，认为每个维度都会对这些系统的设计、运行和治理提出独特的挑战。此外，我们利用这一框架构建不同类型的AI代理的“代理画像”，这些画像有助于揭示不同类别AI代理所提出的技术和非技术治理挑战，范围从狭义的任务特定辅助系统到高度自主的通用系统。通过映射关键的变异和连续性维度，这一框架为开发者、决策者和公众提供了更好地与集体社会目标相契合的治理方法的机会。 

---
# Active Light Modulation to Counter Manipulation of Speech Visual Content 

**Title (ZH)**: 主动_light_调制以对抗语音视觉内容操纵 

**Authors**: Hadleigh Schwartz, Xiaofeng Yan, Charles J. Carver, Xia Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2504.21846)  

**Abstract**: High-profile speech videos are prime targets for falsification, owing to their accessibility and influence. This work proposes Spotlight, a low-overhead and unobtrusive system for protecting live speech videos from visual falsification of speaker identity and lip and facial motion. Unlike predominant falsification detection methods operating in the digital domain, Spotlight creates dynamic physical signatures at the event site and embeds them into all video recordings via imperceptible modulated light. These physical signatures encode semantically-meaningful features unique to the speech event, including the speaker's identity and facial motion, and are cryptographically-secured to prevent spoofing. The signatures can be extracted from any video downstream and validated against the portrayed speech content to check its integrity. Key elements of Spotlight include (1) a framework for generating extremely compact (i.e., 150-bit), pose-invariant speech video features, based on locality-sensitive hashing; and (2) an optical modulation scheme that embeds >200 bps into video while remaining imperceptible both in video and live. Prototype experiments on extensive video datasets show Spotlight achieves AUCs $\geq$ 0.99 and an overall true positive rate of 100% in detecting falsified videos. Further, Spotlight is highly robust across recording conditions, video post-processing techniques, and white-box adversarial attacks on its video feature extraction methodologies. 

**Abstract (ZH)**: 高知名度演讲视频是视觉伪造的首要目标，由于其易获取性和影响力。本文提出Spotlight，一种低开销且不显性的系统，用于保护实时演讲视频免受演讲者身份和唇部及面部动作的视觉伪造。不同于主要在数字域操作的伪造检测方法，Spotlight 在事件现场创建动态的物理签名，并通过不可感知的调制光将它们嵌入到所有视频录制中。这些物理签名编码了演讲事件特有的语义特征，包括演讲者身份和面部动作，并通过加密手段防止伪造。可以从前端的任何视频中提取这些签名并验证其所述内容的完整性以检查其真实性。Spotlight 的关键要素包括（1）基于局部敏感哈希的生成极其紧凑（即150位）且姿态不变的演讲视频特征的框架；（2）一种光学调制方案，可在保持视频和实时环境下的不可感知性的同时，将超过200 bps的信息嵌入到视频中。在广泛视频数据集上的原型实验表明，Spotlight 在检测伪造视频时的AUC值≥0.99，总体真阳性率为100%。此外，Spotlight 对录制条件、视频后处理技术以及对其视频特征提取方法的白盒对抗攻击具有高度 robust 性。 

---
# Early Exit and Multi Stage Knowledge Distillation in VLMs for Video Summarization 

**Title (ZH)**: Early Exit和多阶段知识蒸馏在视频摘要的VLMs中的应用 

**Authors**: Anas Anwarul Haq Khan, Utkarsh Verma, Prateek Chanda, Ganesh Ramakrishnan  

**Link**: [PDF](https://arxiv.org/pdf/2504.21831)  

**Abstract**: We introduce DEEVISum (Distilled Early Exit Vision language model for Summarization), a lightweight, efficient, and scalable vision language model designed for segment wise video summarization. Leveraging multi modal prompts that combine textual and audio derived signals, DEEVISum incorporates Multi Stage Knowledge Distillation (MSKD) and Early Exit (EE) to strike a balance between performance and efficiency. MSKD offers a 1.33% absolute F1 improvement over baseline distillation (0.5%), while EE reduces inference time by approximately 21% with a 1.3 point drop in F1. Evaluated on the TVSum dataset, our best model PaLI Gemma2 3B + MSKD achieves an F1 score of 61.1, competing the performance of significantly larger models, all while maintaining a lower computational footprint. We publicly release our code and processed dataset to support further research. 

**Abstract (ZH)**: 我们介绍了DEEVISum（一种用于视频摘要的轻量级、高效且可扩展的多模态知识蒸馏和早期退出视觉语言模型） 

---
# DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via Reinforcement Learning for Subgoal Decomposition 

**Title (ZH)**: DeepSeek-Prover-V2: 通过强化学习促进子目标分解的正式数学推理优化 

**Authors**: Z.Z. Ren, Zhihong Shao, Junxiao Song, Huajian Xin, Haocheng Wang, Wanjia Zhao, Liyue Zhang, Zhe Fu, Qihao Zhu, Dejian Yang, Z.F. Wu, Zhibin Gou, Shirong Ma, Hongxuan Tang, Yuxuan Liu, Wenjun Gao, Daya Guo, Chong Ruan  

**Link**: [PDF](https://arxiv.org/pdf/2504.21801)  

**Abstract**: We introduce DeepSeek-Prover-V2, an open-source large language model designed for formal theorem proving in Lean 4, with initialization data collected through a recursive theorem proving pipeline powered by DeepSeek-V3. The cold-start training procedure begins by prompting DeepSeek-V3 to decompose complex problems into a series of subgoals. The proofs of resolved subgoals are synthesized into a chain-of-thought process, combined with DeepSeek-V3's step-by-step reasoning, to create an initial cold start for reinforcement learning. This process enables us to integrate both informal and formal mathematical reasoning into a unified model. The resulting model, DeepSeek-Prover-V2-671B, achieves state-of-the-art performance in neural theorem proving, reaching 88.9% pass ratio on the MiniF2F-test and solving 49 out of 658 problems from PutnamBench. In addition to standard benchmarks, we introduce ProverBench, a collection of 325 formalized problems, to enrich our evaluation, including 15 selected problems from the recent AIME competitions (years 24-25). Further evaluation on these 15 AIME problems shows that the model successfully solves 6 of them. In comparison, DeepSeek-V3 solves 8 of these problems using majority voting, highlighting that the gap between formal and informal mathematical reasoning in large language models is substantially narrowing. 

**Abstract (ZH)**: DeepSeek-Prover-V2：一种基于Lean 4的开源大型语言模型及其在形式定理证明中的应用 

---
# How Real Are Synthetic Therapy Conversations? Evaluating Fidelity in Prolonged Exposure Dialogues 

**Title (ZH)**: 合成治疗对话有多真实？延长暴露对话的信度评估 

**Authors**: Suhas BN, Dominik Mattioli, Saeed Abdullah, Rosa I. Arriaga, Chris W. Wiese, Andrew M. Sherrill  

**Link**: [PDF](https://arxiv.org/pdf/2504.21800)  

**Abstract**: The growing adoption of synthetic data in healthcare is driven by privacy concerns, limited access to real-world data, and the high cost of annotation. This work explores the use of synthetic Prolonged Exposure (PE) therapeutic conversations for Post-Traumatic Stress Disorder (PTSD) as a scalable alternative for training and evaluating clinical models. We systematically compare real and synthetic dialogues using linguistic, structural, and protocol-specific metrics, including turn-taking patterns and treatment fidelity. We also introduce and evaluate PE-specific metrics derived from linguistic analysis and semantic modeling, offering a novel framework for assessing clinical fidelity beyond surface fluency. Our findings show that although synthetic data holds promise for mitigating data scarcity and protecting patient privacy, it can struggle to capture the subtle dynamics of therapeutic interactions. In our dataset, synthetic dialogues match structural features of real-world dialogues (e.g., speaker switch ratio: 0.98 vs. 0.99), however, synthetic interactions do not adequately reflect key fidelity markers (e.g., distress monitoring). We highlight gaps in existing evaluation frameworks and advocate for fidelity-aware metrics that go beyond surface fluency to uncover clinically significant failures. Our findings clarify where synthetic data can effectively complement real-world datasets -- and where critical limitations remain. 

**Abstract (ZH)**: 合成数据在医疗保健中的 adoption 日益增长，驱动因素包括隐私 concern、真实世界数据访问受限以及标注成本高昂。本文探索用于创伤后应激障碍 (PTSD) 延长暴露（PE）治疗交流的合成数据在训练和评估临床模型中的应用，作为一种可扩展的替代方案。我们系统地比较了真实和合成对话，使用语言学、结构和协议特定的指标进行评估，包括对话轮换模式和治疗忠实度。我们还引入并评估了源自语言分析和语义建模的 PE 特定指标，提供了一种评估临床忠实度的新框架，超越表面流畅性。我们的研究发现，虽然合成数据有潜力缓解数据稀缺问题并保护患者隐私，但在捕捉治疗交互的细微动态方面仍存在问题。在我们的数据集中，合成对话在结构特征上与真实对话匹配（例如，说话人转换比例：0.98 对 0.99），然而，合成交互未能充分反映关键的忠实度标志（如，应激监测）。我们指出了现有评估框架中的不足，并倡导超越表面流畅性的忠实度感知指标，以揭示临床显著的失败。我们的研究结果明确了合成数据在补充真实数据集中的有效应用领域——以及依然存在的关键限制。 

---
# SWE-smith: Scaling Data for Software Engineering Agents 

**Title (ZH)**: SWE-Smith: 扩展数据以适应软件工程代理 

**Authors**: John Yang, Kilian Leret, Carlos E. Jimenez, Alexander Wettig, Kabir Khandpur, Yanzhe Zhang, Binyuan Hui, Ofir Press, Ludwig Schmidt, Diyi Yang  

**Link**: [PDF](https://arxiv.org/pdf/2504.21798)  

**Abstract**: Despite recent progress in Language Models (LMs) for software engineering, collecting training data remains a significant pain point. Existing datasets are small, with at most 1,000s of training instances from 11 or fewer GitHub repositories. The procedures to curate such datasets are often complex, necessitating hundreds of hours of human labor; companion execution environments also take up several terabytes of storage, severely limiting their scalability and usability. To address this pain point, we introduce SWE-smith, a novel pipeline for generating software engineering training data at scale. Given any Python codebase, SWE-smith constructs a corresponding execution environment, then automatically synthesizes 100s to 1,000s of task instances that break existing test(s) in the codebase. Using SWE-smith, we create a dataset of 50k instances sourced from 128 GitHub repositories, an order of magnitude larger than all previous works. We train SWE-agent-LM-32B, achieving 40.2% Pass@1 resolve rate on the SWE-bench Verified benchmark, state of the art among open source models. We open source SWE-smith (collection procedure, task instances, trajectories, models) to lower the barrier of entry for research in LM systems for automated software engineering. All assets available at this https URL. 

**Abstract (ZH)**: 尽管在软件工程领域的语言模型取得了最近的进步，但收集训练数据仍然是一个显著的痛点。现有的数据集规模较小，最多包含来自11个或更少的GitHub仓库的数千个训练实例。编纂这些数据集的过程通常非常复杂，需要数百小时的人工劳动；伴随的执行环境也需要占用数TB的存储空间，严重限制了其可扩展性和实用性。为解决这一痛点，我们引入了SWE-smith，这是一个新型的生成大规模软件工程训练数据的流水线。给定任何Python代码库，SWE-smith会构建相应的执行环境，然后自动合成数百到数千个任务实例，这些任务实例会破坏代码库中的现有测试。使用SWE-smith，我们创建了一个源自128个GitHub仓库的数据集，其中包含50,000个实例，是之前所有工作的十倍以上。我们训练了SWE-agent-LM-32B，并在SWE-bench Verified基准测试中实现了40.2%的Pass@1解决率，这是开源模型中的最新成果。我们开源了SWE-smith（数据收集流程、任务实例、轨迹、模型），以降低在自动软件工程领域使用语言模型系统进行研究的门槛。所有资源可通过此链接获得。 

---
# WebThinker: Empowering Large Reasoning Models with Deep Research Capability 

**Title (ZH)**: WebThinker: 道德深厚推理能力赋能大型模型 

**Authors**: Xiaoxi Li, Jiajie Jin, Guanting Dong, Hongjin Qian, Yutao Zhu, Yongkang Wu, Ji-Rong Wen, Zhicheng Dou  

**Link**: [PDF](https://arxiv.org/pdf/2504.21776)  

**Abstract**: Large reasoning models (LRMs), such as OpenAI-o1 and DeepSeek-R1, demonstrate impressive long-horizon reasoning capabilities. However, their reliance on static internal knowledge limits their performance on complex, knowledge-intensive tasks and hinders their ability to produce comprehensive research reports requiring synthesis of diverse web information. To address this, we propose \textbf{WebThinker}, a deep research agent that empowers LRMs to autonomously search the web, navigate web pages, and draft research reports during the reasoning process. WebThinker integrates a \textbf{Deep Web Explorer} module, enabling LRMs to dynamically search, navigate, and extract information from the web when encountering knowledge gaps. It also employs an \textbf{Autonomous Think-Search-and-Draft strategy}, allowing the model to seamlessly interleave reasoning, information gathering, and report writing in real time. To further enhance research tool utilization, we introduce an \textbf{RL-based training strategy} via iterative online Direct Preference Optimization (DPO). Extensive experiments on complex reasoning benchmarks (GPQA, GAIA, WebWalkerQA, HLE) and scientific report generation tasks (Glaive) demonstrate that WebThinker significantly outperforms existing methods and strong proprietary systems. Our approach enhances LRM reliability and applicability in complex scenarios, paving the way for more capable and versatile deep research systems. The code is available at this https URL. 

**Abstract (ZH)**: WebThinker：一种增强大型推理模型的深度研究代理 

---
# Learning Heterogeneous Performance-Fairness Trade-offs in Federated Learning 

**Title (ZH)**: 联邦学习中异质性能-公平性权衡的学习 

**Authors**: Rongguang Ye, Ming Tang  

**Link**: [PDF](https://arxiv.org/pdf/2504.21775)  

**Abstract**: Recent methods leverage a hypernet to handle the performance-fairness trade-offs in federated learning. This hypernet maps the clients' preferences between model performance and fairness to preference-specifc models on the trade-off curve, known as local Pareto front. However, existing methods typically adopt a uniform preference sampling distribution to train the hypernet across clients, neglecting the inherent heterogeneity of their local Pareto fronts. Meanwhile, from the perspective of generalization, they do not consider the gap between local and global Pareto fronts on the global dataset. To address these limitations, we propose HetPFL to effectively learn both local and global Pareto fronts. HetPFL comprises Preference Sampling Adaptation (PSA) and Preference-aware Hypernet Fusion (PHF). PSA adaptively determines the optimal preference sampling distribution for each client to accommodate heterogeneous local Pareto fronts. While PHF performs preference-aware fusion of clients' hypernets to ensure the performance of the global Pareto front. We prove that HetPFL converges linearly with respect to the number of rounds, under weaker assumptions than existing methods. Extensive experiments on four datasets show that HetPFL significantly outperforms seven baselines in terms of the quality of learned local and global Pareto fronts. 

**Abstract (ZH)**: 近期方法利用超网络来处理联邦学习中的性能-公平性权衡。该超网络将客户端在模型性能和公平性之间的偏好映射到权衡曲线上特定偏好模型上的局部帕累托前沿。然而，现有方法通常采用统一的偏好采样分布来训练超网络，忽略了客户端之间固有的局部帕累托前沿异质性。同时，从泛化的角度来看，它们未能考虑局部和全局帕累托前沿之间的差距。为了解决这些局限性，我们提出了HetPFL来有效学习局部和全局帕累托前沿。HetPFL包括偏好采样适应（PSA）和偏好感知超网络融合（PHF）。PSA动态确定每个客户端的最佳偏好采样分布，以适应异质性的局部帕累托前沿。而PHF执行客户端超网络的偏好感知融合，以确保全局帕累托前沿的性能。我们证明，HetPFL在较弱的假设条件下，随着轮次的增加具有线性收敛性。广泛的实验在四个数据集上表明，HetPFL在学习的局部和全局帕累托前沿质量方面显著优于七个基线方法。 

---
# MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced Knowledge Boundary Awareness 

**Title (ZH)**: MAC-调谐：增强知识边界意识的LLM多组件问题推理 

**Authors**: Junsheng Huang, Zhitao He, Sandeep Polisetty, Qingyun Wang, May Fung  

**Link**: [PDF](https://arxiv.org/pdf/2504.21773)  

**Abstract**: With the widespread application of large language models (LLMs), the issue of generating non-existing facts, known as hallucination, has garnered increasing attention. Previous research in enhancing LLM confidence estimation mainly focuses on the single problem setting. However, LLM awareness of its internal parameterized knowledge boundary under the more challenging multi-problem setting, which requires answering multiple problems accurately simultaneously, remains underexplored. To bridge this gap, we introduce a novel method, Multiple Answers and Confidence Stepwise Tuning (MAC-Tuning), that separates the learning of answer prediction and confidence estimation during fine-tuning on instruction data. Extensive experiments demonstrate that our method outperforms baselines by up to 25% in average precision. 

**Abstract (ZH)**: 随着大规模语言模型（LLMs）的广泛应用，生成非存在事实即幻觉的问题越来越受到关注。增强LLM置信度估计的研究主要集中在单一问题设置上。然而，在需要同时准确回答多个问题的更具挑战性的多问题设置下，LLM对其内部参数化知识边界的意识尚未得到充分探索。为了弥合这一差距，我们提出了一种名为Multiple Answers and Confidence Stepwise Tuning（MAC-Tuning）的新方法，在指令数据微调过程中分开学习答案预测和置信度估计。大量实验显示，与基线方法相比，我们的方法在平均精度上最高可提高25%。 

---
# Solving Copyright Infringement on Short Video Platforms: Novel Datasets and an Audio Restoration Deep Learning Pipeline 

**Title (ZH)**: 解决短视频平台上的版权侵权问题：新型数据集及音频恢复深度学习pipeline 

**Authors**: Minwoo Oh, Minsu Park, Eunil Park  

**Link**: [PDF](https://arxiv.org/pdf/2504.21772)  

**Abstract**: Short video platforms like YouTube Shorts and TikTok face significant copyright compliance challenges, as infringers frequently embed arbitrary background music (BGM) to obscure original soundtracks (OST) and evade content originality detection. To tackle this issue, we propose a novel pipeline that integrates Music Source Separation (MSS) and cross-modal video-music retrieval (CMVMR). Our approach effectively separates arbitrary BGM from the original OST, enabling the restoration of authentic video audio tracks. To support this work, we introduce two domain-specific datasets: OASD-20K for audio separation and OSVAR-160 for pipeline evaluation. OASD-20K contains 20,000 audio clips featuring mixed BGM and OST pairs, while OSVAR160 is a unique benchmark dataset comprising 1,121 video and mixed-audio pairs, specifically designed for short video restoration tasks. Experimental results demonstrate that our pipeline not only removes arbitrary BGM with high accuracy but also restores OSTs, ensuring content integrity. This approach provides an ethical and scalable solution to copyright challenges in user-generated content on short video platforms. 

**Abstract (ZH)**: 短视频平台如YouTube Shorts和TikTok面临显著的版权合规挑战，侵权者经常嵌入任意背景音乐(BGM)以遮盖原创音轨(OST)并规避内容原创性检测。为解决这一问题，我们提出了一种将音乐源分离(MSS)和跨模态视频-音乐检索(CMVMR)结合的新 Pipeline。该方法有效分离任意BGM与原始OST，使视频音频轨道的恢复成为可能。为了支持这项工作，我们引入了两个领域特定的数据集：OASD-20K用于音频分离和OSVAR-160用于Pipeline评估。OASD-20K包含20,000个混合BGM和OST的音频片段，而OSVAR-160是一个专门设计用于短视频恢复任务的独特基准数据集，包含1,121个视频和混合音频对。实验结果表明，我们的Pipeline不仅以高精度移除任意BGM，还恢复了OST，确保了内容完整性。该方法为解决短视频平台用户生成内容中的版权挑战提供了伦理和可扩展的解决方案。 

---
# Adaptive 3D UI Placement in Mixed Reality Using Deep Reinforcement Learning 

**Title (ZH)**: 使用深度强化学习的混合现实自适应3D UI布局 

**Authors**: Feiyu Lu, Mengyu Chen, Hsiang Hsu, Pranav Deshpande, Cheng Yao Wang, Blair MacIntyre  

**Link**: [PDF](https://arxiv.org/pdf/2504.21731)  

**Abstract**: Mixed Reality (MR) could assist users' tasks by continuously integrating virtual content with their view of the physical environment. However, where and how to place these content to best support the users has been a challenging problem due to the dynamic nature of MR experiences. In contrast to prior work that investigates optimization-based methods, we are exploring how reinforcement learning (RL) could assist with continuous 3D content placement that is aware of users' poses and their surrounding environments. Through an initial exploration and preliminary evaluation, our results demonstrate the potential of RL to position content that maximizes the reward for users on the go. We further identify future directions for research that could harness the power of RL for personalized and optimized UI and content placement in MR. 

**Abstract (ZH)**: 混合现实（MR）中的强化学习辅助连续3D内容放置研究 

---
# Cert-SSB: Toward Certified Sample-Specific Backdoor Defense 

**Title (ZH)**: Cert-SSB: 面向样本特定后门防御的认证方法 

**Authors**: Ting Qiao, Yingjia Wang, Xing Liu, Sixing Wu, Jianbing Li, Yiming Li  

**Link**: [PDF](https://arxiv.org/pdf/2504.21730)  

**Abstract**: Deep neural networks (DNNs) are vulnerable to backdoor attacks, where an attacker manipulates a small portion of the training data to implant hidden backdoors into the model. The compromised model behaves normally on clean samples but misclassifies backdoored samples into the attacker-specified target class, posing a significant threat to real-world DNN applications. Currently, several empirical defense methods have been proposed to mitigate backdoor attacks, but they are often bypassed by more advanced backdoor techniques. In contrast, certified defenses based on randomized smoothing have shown promise by adding random noise to training and testing samples to counteract backdoor attacks. In this paper, we reveal that existing randomized smoothing defenses implicitly assume that all samples are equidistant from the decision boundary. However, it may not hold in practice, leading to suboptimal certification performance. To address this issue, we propose a sample-specific certified backdoor defense method, termed Cert-SSB. Cert-SSB first employs stochastic gradient ascent to optimize the noise magnitude for each sample, ensuring a sample-specific noise level that is then applied to multiple poisoned training sets to retrain several smoothed models. After that, Cert-SSB aggregates the predictions of multiple smoothed models to generate the final robust prediction. In particular, in this case, existing certification methods become inapplicable since the optimized noise varies across different samples. To conquer this challenge, we introduce a storage-update-based certification method, which dynamically adjusts each sample's certification region to improve certification performance. We conduct extensive experiments on multiple benchmark datasets, demonstrating the effectiveness of our proposed method. Our code is available at this https URL. 

**Abstract (ZH)**: 深度神经网络（DNNs）易受后门攻击的威胁，攻击者可以通过操纵一小部分训练数据植入隐藏的后门，使受攻击模型在干净样本上表现正常，但在后门样本上将其错分类为目标类，对实际应用构成重大威胁。目前，已经提出了几种经验防御方法来减轻后门攻击，但它们往往被更先进的后门技术绕过。相比之下，基于随机化平滑的认证防御方法通过在训练和测试样本中添加随机噪声来对抗后门攻击，显示出前景。在本文中，我们揭示现有随机化平滑防御方法隐含地假设所有样本与决策边界等距，但在实践中可能不成立，导致认证性能不佳。为解决这一问题，我们提出了一种样本特定的认证后门防御方法，称为Cert-SSB。Cert-SSB首先使用随机梯度上升来优化每个样本的噪声幅度，确保针对每个样本的具体噪声级别，然后应用于多个中毒训练集以重新训练多个平滑模型。之后，Cert-SSB聚合多个平滑模型的预测生成最终鲁棒预测。特别是，在这种情况下，现有的认证方法不再适用，因为优化的噪声在不同样本之间变化。为克服这一挑战，我们引入了一种基于存储更新的认证方法，动态调整每个样本的认证区域以提高认证性能。我们在多个基准数据集上进行了广泛实验，证明了我们提出方法的有效性。我们的代码可以在以下链接中获取：this https URL。 

---
# Sionna RT: Technical Report 

**Title (ZH)**: Sionna RT: 技术报告 

**Authors**: Fayçal Aït Aoudia, Jakob Hoydis, Merlin Nimier-David, Sebastian Cammerer, Alexander Keller  

**Link**: [PDF](https://arxiv.org/pdf/2504.21719)  

**Abstract**: Sionna is an open-source, GPU-accelerated library that, as of version 0.14, incorporates a ray tracer for simulating radio wave propagation. A unique feature of Sionna RT is differentiability, enabling the calculation of gradients for the channel impulse responses (CIRs), radio maps, and other related metrics with respect to system and environmental parameters, such as material properties, antenna patterns, and array geometries. The release of Sionna 1.0 provides a complete overhaul of the ray tracer, significantly improving its speed, memory efficiency, and extensibility. This document details the algorithms employed by Sionna RT to simulate radio wave propagation efficiently, while also addressing their current limitations. Given that the computation of CIRs and radio maps requires distinct algorithms, these are detailed in separate sections. For CIRs, Sionna RT integrates shooting and bouncing of rays (SBR) with the image method and uses a hashing-based mechanism to efficiently eliminate duplicate paths. Radio maps are computed using a purely SBR-based approach. 

**Abstract (ZH)**: Sionna是开源的GPU加速库，其版本0.14集成了用于模拟无线电波传播的射线跟踪器。Sionna RT的独特之处在于其可微性，这使得能够计算信道冲激响应（CIRs）、无线电图及其他相关指标相对于系统和环境参数（如材料属性、天线模式和阵列几何形状）的梯度。Sionna 1.0的发布对射线跟踪器进行了全面的改造，显著提高了其速度、内存效率和可扩展性。本文详细介绍了Sionna RT用于高效模拟无线电波传播的算法，同时也指出了当前的限制。鉴于CIRs和无线电图的计算需要不同的算法，这些算法在单独的部分中进行了详细描述。对于CIRs，Sionna RT结合了射线追踪方法和图像方法，并使用基于哈希的机制有效地消除重复路径。无线电图是使用纯射线追踪方法进行计算的。 

---
# LLM-Empowered Embodied Agent for Memory-Augmented Task Planning in Household Robotics 

**Title (ZH)**: 基于LLM的具有记忆增强任务规划能力的物理体代理 

**Authors**: Marc Glocker, Peter Hönig, Matthias Hirschmanner, Markus Vincze  

**Link**: [PDF](https://arxiv.org/pdf/2504.21716)  

**Abstract**: We present an embodied robotic system with an LLM-driven agent-orchestration architecture for autonomous household object management. The system integrates memory-augmented task planning, enabling robots to execute high-level user commands while tracking past actions. It employs three specialized agents: a routing agent, a task planning agent, and a knowledge base agent, each powered by task-specific LLMs. By leveraging in-context learning, our system avoids the need for explicit model training. RAG enables the system to retrieve context from past interactions, enhancing long-term object tracking. A combination of Grounded SAM and LLaMa3.2-Vision provides robust object detection, facilitating semantic scene understanding for task planning. Evaluation across three household scenarios demonstrates high task planning accuracy and an improvement in memory recall due to RAG. Specifically, Qwen2.5 yields best performance for specialized agents, while LLaMA3.1 excels in routing tasks. The source code is available at: this https URL. 

**Abstract (ZH)**: 我们提出了一种由大语言模型驱动的代理协调架构，用于自主家庭物体管理的具身机器人系统。该系统集成了增强记忆的任务规划，使机器人能够执行高层用户命令并跟踪过去的行为。系统采用三个专门的代理：路由代理、任务规划代理和知识库代理，每个代理由任务特定的LLM提供动力。通过利用上下文学习，我们的系统避免了显式模型训练的需求。基于检索增强生成（RAG），系统能够从过去的交互中检索上下文，增强长期物体跟踪。Grounded SAM与LLaMa3.2-Vision的结合为任务规划提供了 robust 的物体检测能力，促进了语义场景理解。在三个家庭场景的评估中，展示了高任务规划准确性和由于RAG导致的记忆召回改进。具体来说，Qwen2.5在专门代理方面表现最佳，而LLaMA3.1在路由任务方面表现优异。源代码可在以下网址获取：this https URL。 

---
# Recursive KL Divergence Optimization: A Dynamic Framework for Representation Learning 

**Title (ZH)**: 递归KL散度优化：一种动态表示学习框架 

**Authors**: Anthony D Martin  

**Link**: [PDF](https://arxiv.org/pdf/2504.21707)  

**Abstract**: We propose a generalization of modern representation learning objectives by reframing them as recursive divergence alignment processes over localized conditional distributions While recent frameworks like Information Contrastive Learning I-Con unify multiple learning paradigms through KL divergence between fixed neighborhood conditionals we argue this view underplays a crucial recursive structure inherent in the learning process. We introduce Recursive KL Divergence Optimization RKDO a dynamic formalism where representation learning is framed as the evolution of KL divergences across data neighborhoods. This formulation captures contrastive clustering and dimensionality reduction methods as static slices while offering a new path to model stability and local adaptation. Our experiments demonstrate that RKDO offers dual efficiency advantages approximately 30 percent lower loss values compared to static approaches across three different datasets and 60 to 80 percent reduction in computational resources needed to achieve comparable results. This suggests that RKDOs recursive updating mechanism provides a fundamentally more efficient optimization landscape for representation learning with significant implications for resource constrained applications. 

**Abstract (ZH)**: 我们通过将现代表示学习目标重新框定为局部条件分布上的递归偏差对齐过程，提出了一种泛化的表示学习目标。虽然近年来的信息对比学习框架I-Con通过固定邻域条件间的KL散度统一了多种学习范式，我们认为这种观点忽视了学习过程中固有的递归结构。我们引入了递归KL散度优化（RKDO）作为一种动态形式，将表示学习框架化为数据邻域间KL散度的演变过程。该形式化描述捕获了对比聚类和维度减少方法的静态截面，并提供了一条新的途径以实现模型稳定性和局部适应性。我们的实验表明，与静态方法相比，RKDO在三个不同数据集上分别提供了约30%较低的损失值，并且在达到可比结果时所需的计算资源减少了60%至80%。这表明，RKDO的递归更新机制为表示学习提供了本质更高效的优化场景，对资源受限的应用具有重大意义。 

---
# Vision Transformers in Precision Agriculture: A Comprehensive Survey 

**Title (ZH)**: 精准农业中视觉变换器的应用：一项全面综述 

**Authors**: Saber Mehdipour, Seyed Abolghasem Mirroshandel, Seyed Amirhossein Tabatabaei  

**Link**: [PDF](https://arxiv.org/pdf/2504.21706)  

**Abstract**: Detecting plant diseases is a crucial aspect of modern agriculture - it plays a key role in maintaining crop health and increasing overall yield. Traditional approaches, though still valuable, often rely on manual inspection or conventional machine learning techniques, both of which face limitations in scalability and accuracy. Recently, Vision Transformers (ViTs) have emerged as a promising alternative, offering benefits such as improved handling of long-range dependencies and better scalability for visual tasks. This survey explores the application of ViTs in precision agriculture, covering tasks from classification to detection and segmentation. We begin by introducing the foundational architecture of ViTs and discuss their transition from Natural Language Processing (NLP) to computer vision. The discussion includes the concept of inductive bias in traditional models like Convolutional Neural Networks (CNNs), and how ViTs mitigate these biases. We provide a comprehensive review of recent literature, focusing on key methodologies, datasets, and performance metrics. The survey also includes a comparative analysis of CNNs and ViTs, with a look at hybrid models and performance enhancements. Technical challenges - such as data requirements, computational demands, and model interpretability - are addressed alongside potential solutions. Finally, we outline potential research directions and technological advancements that could further support the integration of ViTs in real-world agricultural settings. Our goal with this study is to offer practitioners and researchers a deeper understanding of how ViTs are poised to transform smart and precision agriculture. 

**Abstract (ZH)**: Vision Transformers在精准农业中的应用：从分类到检测和分割 

---
# XBreaking: Explainable Artificial Intelligence for Jailbreaking LLMs 

**Title (ZH)**: XBreaking: 可解释的人工智能在破环LLMs中的应用 

**Authors**: Marco Arazzi, Vignesh Kumar Kembu, Antonino Nocera, Vinod P  

**Link**: [PDF](https://arxiv.org/pdf/2504.21700)  

**Abstract**: Large Language Models are fundamental actors in the modern IT landscape dominated by AI solutions. However, security threats associated with them might prevent their reliable adoption in critical application scenarios such as government organizations and medical institutions. For this reason, commercial LLMs typically undergo a sophisticated censoring mechanism to eliminate any harmful output they could possibly produce. In response to this, LLM Jailbreaking is a significant threat to such protections, and many previous approaches have already demonstrated its effectiveness across diverse domains. Existing jailbreak proposals mostly adopt a generate-and-test strategy to craft malicious input. To improve the comprehension of censoring mechanisms and design a targeted jailbreak attack, we propose an Explainable-AI solution that comparatively analyzes the behavior of censored and uncensored models to derive unique exploitable alignment patterns. Then, we propose XBreaking, a novel jailbreak attack that exploits these unique patterns to break the security constraints of LLMs by targeted noise injection. Our thorough experimental campaign returns important insights about the censoring mechanisms and demonstrates the effectiveness and performance of our attack. 

**Abstract (ZH)**: 大型语言模型是现代由AI解决方案主导的IT景观中的基础参与者。然而，与它们相关的安全威胁可能阻止它们在关键应用场景如政府组织和医疗机构中的可靠采用。因此，商业大型语言模型通常会经历一种复杂的过滤机制以消除可能的危害输出。对此，大型语言模型的破解（Jailbreaking）是对这种保护的重大威胁，许多先前的方法已经在不同领域证明了其有效性。现有的破解提案主要采用生成并测试的策略来生成恶意输入。为了提高对过滤机制的理解并设计有针对性的破解攻击，我们提出了一种可解释AI解决方案，该方案通过比较分析过滤和未过滤模型的行为来推导出独特的可利用对齐模式。然后，我们提出XBreaking，这是一种新型的破解攻击，它利用这些独特的模式通过有针对性的噪声注入破坏大型语言模型的安全限制。我们的全面实验战役为我们提供了关于过滤机制的重要见解，并证明了我们攻击的有效性和性能。 

---
# Self-Supervised Monocular Visual Drone Model Identification through Improved Occlusion Handling 

**Title (ZH)**: 自我监督单目视觉无人机模型识别通过改进遮挡处理 

**Authors**: Stavrow A. Bahnam, Christophe De Wagter, Guido C.H.E. de Croon  

**Link**: [PDF](https://arxiv.org/pdf/2504.21695)  

**Abstract**: Ego-motion estimation is vital for drones when flying in GPS-denied environments. Vision-based methods struggle when flight speed increases and close-by objects lead to difficult visual conditions with considerable motion blur and large occlusions. To tackle this, vision is typically complemented by state estimation filters that combine a drone model with inertial measurements. However, these drone models are currently learned in a supervised manner with ground-truth data from external motion capture systems, limiting scalability to different environments and drones. In this work, we propose a self-supervised learning scheme to train a neural-network-based drone model using only onboard monocular video and flight controller data (IMU and motor feedback). We achieve this by first training a self-supervised relative pose estimation model, which then serves as a teacher for the drone model. To allow this to work at high speed close to obstacles, we propose an improved occlusion handling method for training self-supervised pose estimation models. Due to this method, the root mean squared error of resulting odometry estimates is reduced by an average of 15%. Moreover, the student neural drone model can be successfully obtained from the onboard data. It even becomes more accurate at higher speeds compared to its teacher, the self-supervised vision-based model. We demonstrate the value of the neural drone model by integrating it into a traditional filter-based VIO system (ROVIO), resulting in superior odometry accuracy on aggressive 3D racing trajectories near obstacles. Self-supervised learning of ego-motion estimation represents a significant step toward bridging the gap between flying in controlled, expensive lab environments and real-world drone applications. The fusion of vision and drone models will enable higher-speed flight and improve state estimation, on any drone in any environment. 

**Abstract (ZH)**: 基于自我监督学习的无人机 ego-运动估计训练方法 

---
# Enhancing Self-Supervised Fine-Grained Video Object Tracking with Dynamic Memory Prediction 

**Title (ZH)**: 基于动态记忆预测的自监督细粒度视频目标跟踪增强方法 

**Authors**: Zihan Zhou, Changrui Dai, Aibo Song, Xiaolin Fang  

**Link**: [PDF](https://arxiv.org/pdf/2504.21692)  

**Abstract**: Successful video analysis relies on accurate recognition of pixels across frames, and frame reconstruction methods based on video correspondence learning are popular due to their efficiency. Existing frame reconstruction methods, while efficient, neglect the value of direct involvement of multiple reference frames for reconstruction and decision-making aspects, especially in complex situations such as occlusion or fast movement. In this paper, we introduce a Dynamic Memory Prediction (DMP) framework that innovatively utilizes multiple reference frames to concisely and directly enhance frame reconstruction. Its core component is a Reference Frame Memory Engine that dynamically selects frames based on object pixel features to improve tracking accuracy. In addition, a Bidirectional Target Prediction Network is built to utilize multiple reference frames to improve the robustness of the model. Through experiments, our algorithm outperforms the state-of-the-art self-supervised techniques on two fine-grained video object tracking tasks: object segmentation and keypoint tracking. 

**Abstract (ZH)**: 基于多参考帧动态记忆预测的帧重建方法在复杂场景下的视频分析 

---
# Enhancing Health Mention Classification Performance: A Study on Advancements in Parameter Efficient Tuning 

**Title (ZH)**: 增强健康主题分类性能：关于参数高效调优的研究 

**Authors**: Reem Abdel-Salam, Mary Adewunmi  

**Link**: [PDF](https://arxiv.org/pdf/2504.21685)  

**Abstract**: Health Mention Classification (HMC) plays a critical role in leveraging social media posts for real-time tracking and public health monitoring. Nevertheless, the process of HMC presents significant challenges due to its intricate nature, primarily stemming from the contextual aspects of health mentions, such as figurative language and descriptive terminology, rather than explicitly reflecting a personal ailment. To address this problem, we argue that clearer mentions can be achieved through conventional fine-tuning with enhanced parameters of biomedical natural language methods (NLP). In this study, we explore different techniques such as the utilisation of part-of-speech (POS) tagger information, improving on PEFT techniques, and different combinations thereof. Extensive experiments are conducted on three widely used datasets: RHDM, PHM, and Illness. The results incorporated POS tagger information, and leveraging PEFT techniques significantly improves performance in terms of F1-score compared to state-of-the-art methods across all three datasets by utilising smaller models and efficient training. Furthermore, the findings highlight the effectiveness of incorporating POS tagger information and leveraging PEFT techniques for HMC. In conclusion, the proposed methodology presents a potentially effective approach to accurately classifying health mentions in social media posts while optimising the model size and training efficiency. 

**Abstract (ZH)**: 健康mention分类（HMC）在利用社交媒体帖子进行实时跟踪和公共卫生监测中发挥着关键作用。然而，HMC的过程由于其复杂性而面临重大挑战，主要源自健康mention的上下文方面，如隐喻语言和描述性术语，而不是明确反映个人疾病。为了解决这一问题，我们认为可以通过增强生物医学自然语言处理方法（NLP）的超参数进行常规微调来实现更清晰的mention。在本研究中，我们探索了不同的技术，如利用词性（POS）标注器信息、改进PEFT技术以及它们的不同组合。我们在三个广泛使用的数据集中进行了广泛的实验：RHDM、PHM和Illness。结果表明，在这些数据集中，利用POS标注器信息和利用PEFT技术显著提高了F1分数的表现，相比最先进的方法，使用较小的模型和高效的训练。此外，研究结果强调了结合POS标注器信息和利用PEFT技术在HMC中的有效性。总之，所提出的方法提供了一种潜在有效的途径，同时优化模型大小和训练效率来准确分类社交媒体帖子中的健康mention。 

---
# Sadeed: Advancing Arabic Diacritization Through Small Language Model 

**Title (ZH)**: Sadeed: 通过小语言模型提升阿拉伯语重音标注技术 

**Authors**: Zeina Aldallal, Sara Chrouf, Khalil Hennara, Mohamed Motaism Hamed, Muhammad Hreden, Safwan AlModhayan  

**Link**: [PDF](https://arxiv.org/pdf/2504.21635)  

**Abstract**: Arabic text diacritization remains a persistent challenge in natural language processing due to the language's morphological richness. In this paper, we introduce Sadeed, a novel approach based on a fine-tuned decoder-only language model adapted from Kuwain 1.5B Hennara et al. [2025], a compact model originally trained on diverse Arabic corpora. Sadeed is fine-tuned on carefully curated, high-quality diacritized datasets, constructed through a rigorous data-cleaning and normalization pipeline. Despite utilizing modest computational resources, Sadeed achieves competitive results compared to proprietary large language models and outperforms traditional models trained on similar domains. Additionally, we highlight key limitations in current benchmarking practices for Arabic diacritization. To address these issues, we introduce SadeedDiac-25, a new benchmark designed to enable fairer and more comprehensive evaluation across diverse text genres and complexity levels. Together, Sadeed and SadeedDiac-25 provide a robust foundation for advancing Arabic NLP applications, including machine translation, text-to-speech, and language learning tools. 

**Abstract (ZH)**: 阿拉伯文本重音标记仍然是自然语言处理中的一个持久性挑战，归因于该语言丰富的形态特征。本文介绍了一种名为Sadeed的新型方法，该方法基于经过微调的仅解码器语言模型，该模型源自Kuwain 1.5B Hennara等[2025]，一个最初在多样化的阿拉伯语语料库上进行训练的紧凑型模型。Sadeed在精心策划的高质量重音标记数据集上进行微调，这些数据集通过严格的数据清洗和规范化管道构建。尽管使用了有限的计算资源，Sadeed在与专有大型语言模型相比时取得了竞争力的结果，并且在相似领域训练的传统模型中表现更佳。此外，我们还指出了当前阿拉伯语重音标记基准测试做法中的关键局限性。为了解决这些问题，我们引入了SadeedDiac-25，这是一种新的基准测试，旨在促进对多种文本类型和复杂程度的公平和全面评估。Sadeed与SadeedDiac-25共同为推进阿拉伯语NLP应用（包括机器翻译、文本-to-语音以及语言学习工具）提供了坚实的基础。 

---
# Quantitative Auditing of AI Fairness with Differentially Private Synthetic Data 

**Title (ZH)**: 基于不同隐私合成数据的AI公平性定量审计 

**Authors**: Chih-Cheng Rex Yuan, Bow-Yaw Wang  

**Link**: [PDF](https://arxiv.org/pdf/2504.21634)  

**Abstract**: Fairness auditing of AI systems can identify and quantify biases. However, traditional auditing using real-world data raises security and privacy concerns. It exposes auditors to security risks as they become custodians of sensitive information and targets for cyberattacks. Privacy risks arise even without direct breaches, as data analyses can inadvertently expose confidential information. To address these, we propose a framework that leverages differentially private synthetic data to audit the fairness of AI systems. By applying privacy-preserving mechanisms, it generates synthetic data that mirrors the statistical properties of the original dataset while ensuring privacy. This method balances the goal of rigorous fairness auditing and the need for strong privacy protections. Through experiments on real datasets like Adult, COMPAS, and Diabetes, we compare fairness metrics of synthetic and real data. By analyzing the alignment and discrepancies between these metrics, we assess the capacity of synthetic data to preserve the fairness properties of real data. Our results demonstrate the framework's ability to enable meaningful fairness evaluations while safeguarding sensitive information, proving its applicability across critical and sensitive domains. 

**Abstract (ZH)**: AI系统公平性审计机制可以识别和量化偏差。然而，使用真实世界数据的传统审计引发了安全和隐私问题。这使得审计者成为敏感信息的保管者，并成为网络攻击的目标。即使没有直接泄露，数据分析也可能无意中暴露敏感信息。为解决这些问题，我们提出了一种框架，利用差分隐私合成数据来审计AI系统的公平性。通过应用隐私保护机制，该框架生成与原始数据集统计特性相似的合成数据，同时确保隐私。这种方法在严格公平性审计和强大的隐私保护需求之间取得了平衡。通过在Adult、COMPAS和Diabetes等真实数据集上进行实验，我们比较了合成数据和实际数据的公平性指标。通过分析这些指标之间的对齐和差异，我们评估了合成数据在保留实际数据公平性属性方面的能力。我们的结果表明，该框架能够确保在保护敏感信息的同时进行有意义的公平性评估，证明了其在关键和敏感领域中的适用性。 

---
# RDF-Based Structured Quality Assessment Representation of Multilingual LLM Evaluations 

**Title (ZH)**: 基于RDF的多语言大模型评估结构化质量表示 

**Authors**: Jonas Gwozdz, Andreas Both  

**Link**: [PDF](https://arxiv.org/pdf/2504.21605)  

**Abstract**: Large Language Models (LLMs) increasingly serve as knowledge interfaces, yet systematically assessing their reliability with conflicting information remains difficult. We propose an RDF-based framework to assess multilingual LLM quality, focusing on knowledge conflicts. Our approach captures model responses across four distinct context conditions (complete, incomplete, conflicting, and no-context information) in German and English. This structured representation enables the comprehensive analysis of knowledge leakage-where models favor training data over provided context-error detection, and multilingual consistency. We demonstrate the framework through a fire safety domain experiment, revealing critical patterns in context prioritization and language-specific performance, and demonstrating that our vocabulary was sufficient to express every assessment facet encountered in the 28-question study. 

**Abstract (ZH)**: 基于RDF的多语言大型语言模型质量评估框架：聚焦知识冲突分析 

---
# Leveraging Pre-trained Large Language Models with Refined Prompting for Online Task and Motion Planning 

**Title (ZH)**: 利用细粒度提示强化预训练大型语言模型进行在线任务与运动规划 

**Authors**: Huihui Guo, Huilong Pi, Yunchuan Qin, Zhuo Tang, Kenli Li  

**Link**: [PDF](https://arxiv.org/pdf/2504.21596)  

**Abstract**: With the rapid advancement of artificial intelligence, there is an increasing demand for intelligent robots capable of assisting humans in daily tasks and performing complex operations. Such robots not only require task planning capabilities but must also execute tasks with stability and robustness. In this paper, we present a closed-loop task planning and acting system, LLM-PAS, which is assisted by a pre-trained Large Language Model (LLM). While LLM-PAS plans long-horizon tasks in a manner similar to traditional task and motion planners, it also emphasizes the execution phase of the task. By transferring part of the constraint-checking process from the planning phase to the execution phase, LLM-PAS enables exploration of the constraint space and delivers more accurate feedback on environmental anomalies during execution. The reasoning capabilities of the LLM allow it to handle anomalies that cannot be addressed by the robust executor. To further enhance the system's ability to assist the planner during replanning, we propose the First Look Prompting (FLP) method, which induces LLM to generate effective PDDL goals. Through comparative prompting experiments and systematic experiments, we demonstrate the effectiveness and robustness of LLM-PAS in handling anomalous conditions during task execution. 

**Abstract (ZH)**: 随着人工智能的迅速发展，对能够协助人类完成日常任务并执行复杂操作的智能机器人需求不断增加。这类机器人不仅需要具备任务规划能力，还需在执行任务时表现出稳定性和鲁棒性。本文提出了一种闭环任务规划与执行系统LLM-PAS，该系统借助预训练的大语言模型（LLM）的支持。虽然LLM-PAS在任务规划阶段以类似于传统任务与运动规划器的方式进行长时间规划，但它更侧重于任务的执行阶段。通过将部分约束检查过程从规划阶段转移到执行阶段，LLM-PAS能够探索约束空间并在执行过程中提供更准确的环境异常反馈。大语言模型的推理能力使其能够处理鲁棒执行器无法解决的异常。为进一步增强系统在重新规划期间辅助规划者的能力，我们提出了初次观察提示（FLP）方法，诱导大语言模型生成有效的PDDL目标。通过比较性提示实验和系统性实验，我们证实了LLM-PAS在任务执行过程中处理异常条件的有效性和鲁棒性。 

---
# DNB-AI-Project at SemEval-2025 Task 5: An LLM-Ensemble Approach for Automated Subject Indexing 

**Title (ZH)**: DNB-AI-Project在SemEval-2025任务5中的LLM集成方法Automated主题索引研究 

**Authors**: Lisa Kluge, Maximilian Kähler  

**Link**: [PDF](https://arxiv.org/pdf/2504.21589)  

**Abstract**: This paper presents our system developed for the SemEval-2025 Task 5: LLMs4Subjects: LLM-based Automated Subject Tagging for a National Technical Library's Open-Access Catalog. Our system relies on prompting a selection of LLMs with varying examples of intellectually annotated records and asking the LLMs to similarly suggest keywords for new records. This few-shot prompting technique is combined with a series of post-processing steps that map the generated keywords to the target vocabulary, aggregate the resulting subject terms to an ensemble vote and, finally, rank them as to their relevance to the record. Our system is fourth in the quantitative ranking in the all-subjects track, but achieves the best result in the qualitative ranking conducted by subject indexing experts. 

**Abstract (ZH)**: SemEval-2025 任务5：LLM4Subjects：基于LLM的国家技术图书馆开放访问目录主题标签自动化系统 

---
# One Net to Rule Them All: Domain Randomization in Quadcopter Racing Across Different Platforms 

**Title (ZH)**: 一网统御：四旋翼飞行器在不同平台上跨域随机化训练 

**Authors**: Robin Ferede, Till Blaha, Erin Lucassen, Christophe De Wagter, Guido C.H.E. de Croon  

**Link**: [PDF](https://arxiv.org/pdf/2504.21586)  

**Abstract**: In high-speed quadcopter racing, finding a single controller that works well across different platforms remains challenging. This work presents the first neural network controller for drone racing that generalizes across physically distinct quadcopters. We demonstrate that a single network, trained with domain randomization, can robustly control various types of quadcopters. The network relies solely on the current state to directly compute motor commands. The effectiveness of this generalized controller is validated through real-world tests on two substantially different crafts (3-inch and 5-inch race quadcopters). We further compare the performance of this generalized controller with controllers specifically trained for the 3-inch and 5-inch drone, using their identified model parameters with varying levels of domain randomization (0%, 10%, 20%, 30%). While the generalized controller shows slightly slower speeds compared to the fine-tuned models, it excels in adaptability across different platforms. Our results show that no randomization fails sim-to-real transfer while increasing randomization improves robustness but reduces speed. Despite this trade-off, our findings highlight the potential of domain randomization for generalizing controllers, paving the way for universal AI controllers that can adapt to any platform. 

**Abstract (ZH)**: 在高速四旋翼飞行器竞速中，找到一个适用于不同平台的单一控制器仍旧具有挑战性。本文提出了首个能够跨不同物理特性四旋翼飞行器泛化的神经网络控制器。我们证明了一个经过领域随机化训练的单一网络能够 robust 地控制不同类型的四旋翼飞行器。该网络仅依赖当前状态直接计算电机指令。通过在两种显著不同的飞行器（3英寸和5英寸竞速四旋翼飞行器）上进行实地测试，验证了该泛化控制器的有效性。我们进一步将该泛化控制器的性能与针对3英寸和5英寸无人机分别训练的控制器进行了比较，使用不同水平的领域随机化（0%，10%，20%，30%）确定的模型参数。虽然泛化控制器在速度上略逊于精细调整的模型，但在不同平台上的适应性方面表现出色。我们的结果显示，没有任何随机化失败于仿真到现实的转移，而增加随机化提高了鲁棒性但降低了速度。尽管存在这种权衡，但我们的研究结果强调了领域随机化在控制器泛化中的潜在价值，为能够适应任何平台的通用人工智能控制器奠定了基础。 

---
# Multi-Goal Dexterous Hand Manipulation using Probabilistic Model-based Reinforcement Learning 

**Title (ZH)**: 基于概率模型的强化学习在多目标灵巧手操作中的应用 

**Authors**: Yingzhuo Jiang, Wenjun Huang, Rongdun Lin, Chenyang Miao, Tianfu Sun, Yunduan Cui  

**Link**: [PDF](https://arxiv.org/pdf/2504.21585)  

**Abstract**: This paper tackles the challenge of learning multi-goal dexterous hand manipulation tasks using model-based Reinforcement Learning. We propose Goal-Conditioned Probabilistic Model Predictive Control (GC-PMPC) by designing probabilistic neural network ensembles to describe the high-dimensional dexterous hand dynamics and introducing an asynchronous MPC policy to meet the control frequency requirements in real-world dexterous hand systems. Extensive evaluations on four simulated Shadow Hand manipulation scenarios with randomly generated goals demonstrate GC-PMPC's superior performance over state-of-the-art baselines. It successfully drives a cable-driven Dexterous hand, DexHand 021 with 12 Active DOFs and 5 tactile sensors, to learn manipulating a cubic die to three goal poses within approximately 80 minutes of interactions, demonstrating exceptional learning efficiency and control performance on a cost-effective dexterous hand platform. 

**Abstract (ZH)**: 基于模型的强化学习中多目标灵巧手 manipulation 任务的学习：目标条件概率模型预测控制方法的研究 

---
# MF-LLM: Simulating Collective Decision Dynamics via a Mean-Field Large Language Model Framework 

**Title (ZH)**: MF-LLM：通过大规模语言模型框架模拟集体决策动力学 

**Authors**: Qirui Mi, Mengyue Yang, Xiangning Yu, Zhiyu Zhao, Cheng Deng, Bo An, Haifeng Zhang, Xu Chen, Jun Wang  

**Link**: [PDF](https://arxiv.org/pdf/2504.21582)  

**Abstract**: Simulating collective decision-making involves more than aggregating individual behaviors; it arises from dynamic interactions among individuals. While large language models (LLMs) show promise for social simulation, existing approaches often exhibit deviations from real-world data. To address this gap, we propose the Mean-Field LLM (MF-LLM) framework, which explicitly models the feedback loop between micro-level decisions and macro-level population. MF-LLM alternates between two models: a policy model that generates individual actions based on personal states and group-level information, and a mean field model that updates the population distribution from the latest individual decisions. Together, they produce rollouts that simulate the evolving trajectories of collective decision-making. To better match real-world data, we introduce IB-Tune, a fine-tuning method for LLMs grounded in the information bottleneck principle, which maximizes the relevance of population distributions to future actions while minimizing redundancy with historical data. We evaluate MF-LLM on a real-world social dataset, where it reduces KL divergence to human population distributions by 47 percent over non-mean-field baselines, and enables accurate trend forecasting and intervention planning. It generalizes across seven domains and four LLM backbones, providing a scalable foundation for high-fidelity social simulation. 

**Abstract (ZH)**: 集体决策模拟不仅涉及个体行为的聚合，还源于个体间的动态交互。虽然大规模语言模型（LLMs）在社会模拟方面具有潜力，但现有方法往往与真实世界数据存在偏差。为此，我们提出了均场LLM（MF-LLM）框架，该框架明确建模了微观层面决策与宏观层面群体之间的反馈循环。MF-LLM 交替运行两个模型：策略模型基于个人状态和群体层面信息生成个体行为，均场模型更新群体分布以反映最新的个体决策。两者结合生成模拟集体决策演变轨迹的 rollout。为了更好地匹配真实世界数据，我们引入了基于信息瓶颈原则的 IB-Tune 微调方法，该方法最大限度地提高了群体分布对未来行为的相关性，同时减少了与历史数据的冗余性。我们在一个实际社会数据集上评估 MF-LLM，结果显示它在相对于非均场基准方法的 KL 散度上降低了47%，并能实现准确的趋势预测和干预规划。该方法在七个领域和四种 LLM 主干上具有泛化能力，为我们提供了高性能社会模拟的可扩展基础。 

---
# Towards proactive self-adaptive AI for non-stationary environments with dataset shifts 

**Title (ZH)**: 面向非稳态环境和数据集漂移的前瞻自适应人工智能 

**Authors**: David Fernández Narro, Pablo Ferri, Juan M. García-Gómez, Carlos Sáez  

**Link**: [PDF](https://arxiv.org/pdf/2504.21565)  

**Abstract**: Artificial Intelligence (AI) models deployed in production frequently face challenges in maintaining their performance in non-stationary environments. This issue is particularly noticeable in medical settings, where temporal dataset shifts often occur. These shifts arise when the distributions of training data differ from those of the data encountered during deployment over time. Further, new labeled data to continuously retrain AI is not typically available in a timely manner due to data access limitations. To address these challenges, we propose a proactive self-adaptive AI approach, or pro-adaptive, where we model the temporal trajectory of AI parameters, allowing us to short-term forecast parameter values. To this end, we use polynomial spline bases, within an extensible Functional Data Analysis framework. We validate our methodology with a logistic regression model addressing prior probability shift, covariate shift, and concept shift. This validation is conducted on both a controlled simulated dataset and a publicly available real-world COVID-19 dataset from Mexico, with various shifts occurring between 2020 and 2024. Our results indicate that this approach enhances the performance of AI against shifts compared to baseline stable models trained at different time distances from the present, without requiring updated training data. This work lays the foundation for pro-adaptive AI research against dynamic, non-stationary environments, being compatible with data protection, in resilient AI production environments for health. 

**Abstract (ZH)**: 人工智能模型在生产中部署时常面临在非平稳环境中保持性能的挑战。这一问题在医疗环境中尤为明显，因为时间序列数据集的变动经常发生。这些变动源于训练数据分布与部署过程中遇到的数据分布随时间变化而不同。此外，由于数据访问限制，及时获取新的带标签数据以不断重新训练AI通常不可行。为应对这些挑战，我们提出了一种前瞻性的自适应AI方法，或称pro-adaptive方法，其中我们建模了AI参数的时间轨迹，允许我们短期预测参数值。为此，我们利用多项式样条基函数，在扩展的功能数据分析框架中进行。我们使用逻辑回归模型来验证该方法，该模型解决了先验概率变化、协变量变化和概念变化的问题。这项验证工作在受控的模拟数据集和墨西哥公开的真实世界COVID-19数据集上进行，该数据集的时间跨度从2020年到2024年，包含了多个变化。结果显示，与基于不同时间距离训练的基线稳定模型相比，这种方法在无需更新训练数据的情况下，提高了AI对抗变化的性能。本工作中构建了针对动态、非平稳环境的前瞻性自适应AI研究基础，适用于保护数据的稳健AI生产环境，用于健康领域。 

---
# eNCApsulate: NCA for Precision Diagnosis on Capsule Endoscopes 

**Title (ZH)**: eNCApsulate: NCA for Precision Diagnosis of Capsule Endoscopes 

**Authors**: Henry John Krumb, Anirban Mukhopadhyay  

**Link**: [PDF](https://arxiv.org/pdf/2504.21562)  

**Abstract**: Wireless Capsule Endoscopy is a non-invasive imaging method for the entire gastrointestinal tract, and is a pain-free alternative to traditional endoscopy. It generates extensive video data that requires significant review time, and localizing the capsule after ingestion is a challenge. Techniques like bleeding detection and depth estimation can help with localization of pathologies, but deep learning models are typically too large to run directly on the capsule. Neural Cellular Automata (NCA) for bleeding segmentation and depth estimation are trained on capsule endoscopic images. For monocular depth estimation, we distill a large foundation model into the lean NCA architecture, by treating the outputs of the foundation model as pseudo ground truth. We then port the trained NCA to the ESP32 microcontroller, enabling efficient image processing on hardware as small as a camera capsule. NCA are more accurate (Dice) than other portable segmentation models, while requiring more than 100x fewer parameters stored in memory than other small-scale models. The visual results of NCA depth estimation look convincing, and in some cases beat the realism and detail of the pseudo ground truth. Runtime optimizations on the ESP32-S3 accelerate the average inference speed significantly, by more than factor 3. With several algorithmic adjustments and distillation, it is possible to eNCApsulate NCA models into microcontrollers that fit into wireless capsule endoscopes. This is the first work that enables reliable bleeding segmentation and depth estimation on a miniaturized device, paving the way for precise diagnosis combined with visual odometry as a means of precise localization of the capsule -- on the capsule. 

**Abstract (ZH)**: 无创胶囊内镜是一种无需侵入且无痛的消化道成像方法，它是传统内镜的一种替代方案。它会产生大量的视频数据，需要大量时间审查，并且在吞服后定位胶囊是一个挑战。出血检测和深度估计等技术有助于病灶定位，但深度学习模型通常太大而无法直接运行在胶囊上。通过使用神经细胞自动机（NCA）进行出血分割和深度估计，这些模型可在胶囊内窥镜图像上进行训练。对于单目深度估计，我们通过将大基底模型的输出作为伪地面真实值，将其精炼成轻量级的NCA架构。然后，我们将训练好的NCA移植到ESP32微控制器上，在与摄像头胶囊大小相当的硬件上实现了高效的图像处理。与其它便携式分割模型相比，NCA更准确（Dice值），存储在内存中的参数数量少于其他小型模型超过100倍。NCA的深度估计视觉结果令人信服，在某些情况下甚至超过伪地面真实的逼真度和细节。在ESP32-S3上的运行时优化显著加速了平均推理速度，超过3倍。通过多种算法调整和精炼，有可能将NCA模型封装到可以嵌入无线胶囊内镜的微控制器中。这是首个可在缩小设备上实现可靠的出血分割和深度估计的工作，为结合视觉里程计进行精确胶囊定位提供了可能。 

---
# Black-Box Visual Prompt Engineering for Mitigating Object Hallucination in Large Vision Language Models 

**Title (ZH)**: 黑盒视觉提示工程以减轻大型视觉语言模型中的物体幻象问题 

**Authors**: Sangmin Woo, Kang Zhou, Yun Zhou, Shuai Wang, Sheng Guan, Haibo Ding, Lin Lee Cheong  

**Link**: [PDF](https://arxiv.org/pdf/2504.21559)  

**Abstract**: Large Vision Language Models (LVLMs) often suffer from object hallucination, which undermines their reliability. Surprisingly, we find that simple object-based visual prompting -- overlaying visual cues (e.g., bounding box, circle) on images -- can significantly mitigate such hallucination; however, different visual prompts (VPs) vary in effectiveness. To address this, we propose Black-Box Visual Prompt Engineering (BBVPE), a framework to identify optimal VPs that enhance LVLM responses without needing access to model internals. Our approach employs a pool of candidate VPs and trains a router model to dynamically select the most effective VP for a given input image. This black-box approach is model-agnostic, making it applicable to both open-source and proprietary LVLMs. Evaluations on benchmarks such as POPE and CHAIR demonstrate that BBVPE effectively reduces object hallucination. 

**Abstract (ZH)**: 基于黑盒视觉提示工程的大型视觉语言模型对象幻觉缓解 

---
# Meta knowledge assisted Evolutionary Neural Architecture Search 

**Title (ZH)**: 元知识辅助进化神经架构搜索 

**Authors**: Yangyang Li, Guanlong Liu, Ronghua Shang, Licheng Jiao  

**Link**: [PDF](https://arxiv.org/pdf/2504.21545)  

**Abstract**: Evolutionary computation (EC)-based neural architecture search (NAS) has achieved remarkable performance in the automatic design of neural architectures. However, the high computational cost associated with evaluating searched architectures poses a challenge for these methods, and a fixed form of learning rate (LR) schedule means greater information loss on diverse searched architectures. This paper introduces an efficient EC-based NAS method to solve these problems via an innovative meta-learning framework. Specifically, a meta-learning-rate (Meta-LR) scheme is used through pretraining to obtain a suitable LR schedule, which guides the training process with lower information loss when evaluating each individual. An adaptive surrogate model is designed through an adaptive threshold to select the potential architectures in a few epochs and then evaluate the potential architectures with complete epochs. Additionally, a periodic mutation operator is proposed to increase the diversity of the population, which enhances the generalizability and robustness. Experiments on CIFAR-10, CIFAR-100, and ImageNet1K datasets demonstrate that the proposed method achieves high performance comparable to that of many state-of-the-art peer methods, with lower computational cost and greater robustness. 

**Abstract (ZH)**: 基于进化计算的神经架构搜索方法通过元学习框架解决评估开销和学习率调度问题 

---
# ClassWise-CRF: Category-Specific Fusion for Enhanced Semantic Segmentation of Remote Sensing Imagery 

**Title (ZH)**: 类别智融合-CRF：面向遥感影像语义分割的类别特定融合 

**Authors**: Qinfeng Zhu, Yunxi Jiang, Lei Fan  

**Link**: [PDF](https://arxiv.org/pdf/2504.21491)  

**Abstract**: We propose a result-level category-specific fusion architecture called ClassWise-CRF. This architecture employs a two-stage process: first, it selects expert networks that perform well in specific categories from a pool of candidate networks using a greedy algorithm; second, it integrates the segmentation predictions of these selected networks by adaptively weighting their contributions based on their segmentation performance in each category. Inspired by Conditional Random Field (CRF), the ClassWise-CRF architecture treats the segmentation predictions from multiple networks as confidence vector fields. It leverages segmentation metrics (such as Intersection over Union) from the validation set as priors and employs an exponential weighting strategy to fuse the category-specific confidence scores predicted by each network. This fusion method dynamically adjusts the weights of each network for different categories, achieving category-specific optimization. Building on this, the architecture further optimizes the fused results using unary and pairwise potentials in CRF to ensure spatial consistency and boundary accuracy. To validate the effectiveness of ClassWise-CRF, we conducted experiments on two remote sensing datasets, LoveDA and Vaihingen, using eight classic and advanced semantic segmentation networks. The results show that the ClassWise-CRF architecture significantly improves segmentation performance: on the LoveDA dataset, the mean Intersection over Union (mIoU) metric increased by 1.00% on the validation set and by 0.68% on the test set; on the Vaihingen dataset, the mIoU improved by 0.87% on the validation set and by 0.91% on the test set. These results fully demonstrate the effectiveness and generality of the ClassWise-CRF architecture in semantic segmentation of remote sensing images. The full code is available at this https URL. 

**Abstract (ZH)**: 一种类别级融合架构：ClassWise-CRF 

---
# TRIED: Truly Innovative and Effective Detection Benchmark, developed by WITNESS 

**Title (ZH)**: TRIED: 真正创新有效的检测基准，由WITNESS开发 

**Authors**: Shirin Anlen, Zuzanna Wojciak  

**Link**: [PDF](https://arxiv.org/pdf/2504.21489)  

**Abstract**: The rise of generative AI and deceptive synthetic media threatens the global information ecosystem, especially across the Global Majority. This report from WITNESS highlights the limitations of current AI detection tools, which often underperform in real-world scenarios due to challenges related to explainability, fairness, accessibility, and contextual relevance. In response, WITNESS introduces the Truly Innovative and Effective AI Detection (TRIED) Benchmark, a new framework for evaluating detection tools based on their real-world impact and capacity for innovation. Drawing on frontline experiences, deceptive AI cases, and global consultations, the report outlines how detection tools must evolve to become truly innovative and relevant by meeting diverse linguistic, cultural, and technological contexts. It offers practical guidance for developers, policymakers, and standards bodies to design accountable, transparent, and user-centered detection solutions, and incorporate sociotechnical considerations into future AI standards, procedures and evaluation frameworks. By adopting the TRIED Benchmark, stakeholders can drive innovation, safeguard public trust, strengthen AI literacy, and contribute to a more resilient global information credibility. 

**Abstract (ZH)**: 生成式AI的崛起和欺骗性合成媒体威胁全球信息生态系统，尤其是全球多数国家。 Witness报告指出当前AI检测工具的局限性，这些工具在实际场景中的表现经常不尽如人意，原因在于可解释性、公平性、可访问性及情境相关性方面的挑战。为应对这一挑战，Witness提出真正的创新和有效的AI检测标准（TRIED Benchmark），这是一种基于检测工具在实际影响和创新能力的新框架。该报告基于前线经验、欺骗性AI案例和全球咨询，概述了检测工具如何通过满足多样化的语言、文化和技术水平，成为真正创新和相关的方法。它为开发者、政策制定者和标准机构提供了实用指导，以设计可问责、透明和用户中心的检测解决方案，并将社会和技术考量纳入未来AI标准、程序和评估框架中。通过采用TRIED标准，利益相关者可以推动创新、保护公众信任、增强AI素养，并为更加韧性的全球信息可信度作出贡献。 

---
# A Comprehensive Study of Exploitable Patterns in Smart Contracts: From Vulnerability to Defense 

**Title (ZH)**: 智能合约中存在的可利用模式综合研究：从漏洞到防御 

**Authors**: Yuchen Ding, Hongli Peng, Xiaoqi Li  

**Link**: [PDF](https://arxiv.org/pdf/2504.21480)  

**Abstract**: With the rapid advancement of blockchain technology, smart contracts have enabled the implementation of increasingly complex functionalities. However, ensuring the security of smart contracts remains a persistent challenge across the stages of development, compilation, and execution. Vulnerabilities within smart contracts not only undermine the security of individual applications but also pose significant risks to the broader blockchain ecosystem, as demonstrated by the growing frequency of attacks since 2016, resulting in substantial financial losses. This paper provides a comprehensive analysis of key security risks in Ethereum smart contracts, specifically those written in Solidity and executed on the Ethereum Virtual Machine (EVM). We focus on two prevalent and critical vulnerability types (reentrancy and integer overflow) by examining their underlying mechanisms, replicating attack scenarios, and assessing effective countermeasures. 

**Abstract (ZH)**: 随着区块链技术的迅猛发展，智能合约实现了日益复杂的功能。然而，确保智能合约的安全性仍然是开发、编译和执行阶段的一项持久挑战。智能合约中的漏洞不仅削弱了单个应用的安全性，还对更广泛的区块链生态系统构成了重大风险，这在2016年以来日益频繁的攻击中表现得尤为明显，造成了重大经济损失。本文对以Solidity编写并在以太坊虚拟机（EVM）上执行的以太坊智能合约的关键安全风险进行了全面分析，重点关注重入攻击和整数溢出这两种常见的严重漏洞类型，通过分析其工作机制、复现攻击场景并评估有效防御措施。 

---
# GarmentDiffusion: 3D Garment Sewing Pattern Generation with Multimodal Diffusion Transformers 

**Title (ZH)**: GarmentDiffusion: 多模态扩散变换器驱动的3D服装缝制模板生成 

**Authors**: Xinyu Li, Qi Yao, Yuanda Wang  

**Link**: [PDF](https://arxiv.org/pdf/2504.21476)  

**Abstract**: Garment sewing patterns are fundamental design elements that bridge the gap between design concepts and practical manufacturing. The generative modeling of sewing patterns is crucial for creating diversified garments. However, existing approaches are limited either by reliance on a single input modality or by suboptimal generation efficiency. In this work, we present \textbf{\textit{GarmentDiffusion}}, a new generative model capable of producing centimeter-precise, vectorized 3D sewing patterns from multimodal inputs (text, image, and incomplete sewing pattern). Our method efficiently encodes 3D sewing pattern parameters into compact edge token representations, achieving a sequence length that is $\textbf{10}\times$ shorter than that of the autoregressive SewingGPT in DressCode. By employing a diffusion transformer, we simultaneously denoise all edge tokens along the temporal axis, while maintaining a constant number of denoising steps regardless of dataset-specific edge and panel statistics. With all combination of designs of our model, the sewing pattern generation speed is accelerated by $\textbf{100}\times$ compared to SewingGPT. We achieve new state-of-the-art results on DressCodeData, as well as on the largest sewing pattern dataset, namely GarmentCodeData. The project website is available at this https URL. 

**Abstract (ZH)**: 服装缝制图案是将设计理念与实际制造业连接起来的基本设计元素。缝制图案的生成模型对于创建多样化服装至关重要。然而，现有的方法要么依赖单一的输入模态，要么生成效率不佳。在本文中，我们提出了一种新的生成模型\textbf{\textit{GarmentDiffusion}}，该模型能够从多模态输入（文本、图像和不完整的缝制图案）生成厘米级精确的矢量3D缝制图案。我们的方法高效地将3D缝制图案参数编码为紧凑的边令牌表示，序列长度比DressCode中的自回归SewingGPT短10倍。通过使用扩散变压器，我们同时沿时间轴去噪所有边令牌，且去噪步骤数量始终保持不变，与数据集特定的边和面板统计数据无关。结合我们模型的所有设计组合，缝制图案生成速度比SewingGPT快100倍。我们在DressCodeData和最大的缝制图案数据集GarmentCodeData上均取得了新的state-of-the-art结果。项目网站可在以下链接访问。 

---
# Advancing Arabic Reverse Dictionary Systems: A Transformer-Based Approach with Dataset Construction Guidelines 

**Title (ZH)**: 基于变压器的方法及数据集构建指南：阿拉伯语逆词典系统的进步 

**Authors**: Serry Sibaee, Samar Ahmed, Abdullah Al Harbi, Omer Nacar, Adel Ammar, Yasser Habashi, Wadii Boulila  

**Link**: [PDF](https://arxiv.org/pdf/2504.21475)  

**Abstract**: This study addresses the critical gap in Arabic natural language processing by developing an effective Arabic Reverse Dictionary (RD) system that enables users to find words based on their descriptions or meanings. We present a novel transformer-based approach with a semi-encoder neural network architecture featuring geometrically decreasing layers that achieves state-of-the-art results for Arabic RD tasks. Our methodology incorporates a comprehensive dataset construction process and establishes formal quality standards for Arabic lexicographic definitions. Experiments with various pre-trained models demonstrate that Arabic-specific models significantly outperform general multilingual embeddings, with ARBERTv2 achieving the best ranking score (0.0644). Additionally, we provide a formal abstraction of the reverse dictionary task that enhances theoretical understanding and develop a modular, extensible Python library (RDTL) with configurable training pipelines. Our analysis of dataset quality reveals important insights for improving Arabic definition construction, leading to eight specific standards for building high-quality reverse dictionary resources. This work contributes significantly to Arabic computational linguistics and provides valuable tools for language learning, academic writing, and professional communication in Arabic. 

**Abstract (ZH)**: 本研究通过开发一个有效的阿拉伯语逆向词典（RD）系统来填补阿拉伯自然语言处理中的关键空白，该系统使用户能够根据描述或意义查找词语。我们提出了一种新颖的基于变换器的方法，采用几何递减层数的半编码神经网络架构，实现了阿拉伯语RD任务的最新成果。我们的方法包含全面的数据集构建过程，并建立了阿拉伯语词典定义的正式质量标准。使用各种预训练模型的实验表明，阿拉伯语特定模型显著优于通用多语言嵌入，其中ARBERTv2获得最佳排名得分（0.0644）。此外，我们还提供了一种逆向词典任务的形式化抽象，以增强其理论理解，并开发了一个模块化、可扩展的Python库（RDTL），其中包含可配置的训练管道。我们对数据集质量的分析揭示了提高阿拉伯语定义构建质量的重要见解，从而制定了八项构建高质量逆向词典资源的具体标准。本研究在阿拉伯语计算语言学领域做出了重要贡献，并为阿拉伯语语言学习、学术写作和专业沟通提供了有价值的工具。 

---
# Homa at SemEval-2025 Task 5: Aligning Librarian Records with OntoAligner for Subject Tagging 

**Title (ZH)**: Homa 于 SemEval-2025 任务 5：使用 OntoAligner 对齐图书管理员记录以进行主题标引 

**Authors**: Hadi Bayrami Asl Tekanlou, Jafar Razmara, Mahsa Sanaei, Mostafa Rahgouy, Hamed Babaei Giglou  

**Link**: [PDF](https://arxiv.org/pdf/2504.21474)  

**Abstract**: This paper presents our system, Homa, for SemEval-2025 Task 5: Subject Tagging, which focuses on automatically assigning subject labels to technical records from TIBKAT using the Gemeinsame Normdatei (GND) taxonomy. We leverage OntoAligner, a modular ontology alignment toolkit, to address this task by integrating retrieval-augmented generation (RAG) techniques. Our approach formulates the subject tagging problem as an alignment task, where records are matched to GND categories based on semantic similarity. We evaluate OntoAligner's adaptability for subject indexing and analyze its effectiveness in handling multilingual records. Experimental results demonstrate the strengths and limitations of this method, highlighting the potential of alignment techniques for improving subject tagging in digital libraries. 

**Abstract (ZH)**: 本文介绍了我们为SemEval-2025 Task 5: Subject Tagging设计的系统Homa，该系统专注于使用Gemeinsame Normdatei (GND)分类法自动为TIBKAT的技术记录分配主题标签。我们利用OntoAligner这一模块化的本体对齐工具包，通过整合检索增强生成（RAG）技术来解决这一任务。我们的方法将主题标注问题形式化为对齐任务，其中记录基于语义相似性匹配到GND类别。我们评估了OntoAligner在主题索引中的适应性，并分析了其在处理多语言记录方面的有效性。实验结果展示了该方法的优势和局限性，突出了对齐技术在改进数字图书馆中的主题标注方面的潜力。 

---
# xEEGNet: Towards Explainable AI in EEG Dementia Classification 

**Title (ZH)**: EEGNet: 向可解释人工智能在痴呆症EEG分类中的应用 

**Authors**: Andrea Zanola, Louis Fabrice Tshimanga, Federico Del Pup, Marco Baiesi, Manfredo Atzori  

**Link**: [PDF](https://arxiv.org/pdf/2504.21457)  

**Abstract**: This work presents xEEGNet, a novel, compact, and explainable neural network for EEG data analysis. It is fully interpretable and reduces overfitting through major parameter reduction. As an applicative use case, we focused on classifying common dementia conditions, Alzheimer's and frontotemporal dementia, versus controls. xEEGNet is broadly applicable to other neurological conditions involving spectral alterations. We initially used ShallowNet, a simple and popular model from the EEGNet-family. Its structure was analyzed and gradually modified to move from a "black box" to a more transparent model, without compromising performance. The learned kernels and weights were examined from a clinical standpoint to assess medical relevance. Model variants, including ShallowNet and the final xEEGNet, were evaluated using robust Nested-Leave-N-Subjects-Out cross-validation for unbiased performance estimates. Variability across data splits was explained using embedded EEG representations, grouped by class and set, with pairwise separability to quantify group distinction. Overfitting was assessed through training-validation loss correlation and training speed. xEEGNet uses only 168 parameters, 200 times fewer than ShallowNet, yet retains interpretability, resists overfitting, achieves comparable median performance (-1.5%), and reduces variability across splits. This variability is explained by embedded EEG representations: higher accuracy correlates with greater separation between test set controls and Alzheimer's cases, without significant influence from training data. xEEGNet's ability to filter specific EEG bands, learn band-specific topographies, and use relevant spectral features demonstrates its interpretability. While large deep learning models are often prioritized for performance, this study shows smaller architectures like xEEGNet can be equally effective in EEG pathology classification. 

**Abstract (ZH)**: 这种工作提出了一个新的、紧凑且可解释的神经网络xeEGNet，用于EEG数据分析。它具有完全可解释性并通过主要参数减少来降低过拟合。在应用案例中，我们专注于分类常见的痴呆症类型，阿尔茨海默病和额颞叶痴呆，与对照组。xeEGNet广泛适用于涉及频谱改变的其他神经系统疾病。我们最初使用了ShallowNet这一EEGNet家族中的一个简单且流行的模型，并对其结构进行了分析和逐步调整，使其从“黑盒”模型转变为更透明的模型，性能却不受影响。从临床角度来看，研究了学习到的核和权重的医学相关性。包括ShallowNet和最终的xeEGNet在内的模型变体通过嵌套留一交叉验证方法进行了评估，以获得无偏差的性能估算。通过分组的嵌入EEG表示和成对可分性来解释数据拆分之间的差异。通过训练-验证损失相关性和训练速度来评估过拟合。xeEGNet仅使用168个参数，比ShallowNet少200倍，但仍保持可解释性、抗过拟合、性能可媲美（-1.5%），并且降低了拆分间的变异性。这种变异性通过嵌入的EEG表示来解释：更高的准确率与测试集对照组和阿尔茨海默病病例之间的分离度增加相关，不受训练数据显著影响。xeEGNet能够过滤特定的EEG频率带、学习频率带特异性拓扑图以及使用相关频谱特征，展示了其可解释性。虽然大型深度学习模型通常优先考虑性能，但本研究表明，如xeEGNet这样的较小架构在EEG病理分类中同样有效。 

---
# SimPRIVE: a Simulation framework for Physical Robot Interaction with Virtual Environments 

**Title (ZH)**: SimPRIVE: 一种物理机器人与虚拟环境交互的仿真框架 

**Authors**: Federico Nesti, Gianluca D'Amico, Mauro Marinoni, Giorgio Buttazzo  

**Link**: [PDF](https://arxiv.org/pdf/2504.21454)  

**Abstract**: The use of machine learning in cyber-physical systems has attracted the interest of both industry and academia. However, no general solution has yet been found against the unpredictable behavior of neural networks and reinforcement learning agents. Nevertheless, the improvements of photo-realistic simulators have paved the way towards extensive testing of complex algorithms in different virtual scenarios, which would be expensive and dangerous to implement in the real world.
This paper presents SimPRIVE, a simulation framework for physical robot interaction with virtual environments, which operates as a vehicle-in-the-loop platform, rendering a virtual world while operating the vehicle in the real world.
Using SimPRIVE, any physical mobile robot running on ROS 2 can easily be configured to move its digital twin in a virtual world built with the Unreal Engine 5 graphic engine, which can be populated with objects, people, or other vehicles with programmable behavior.
SimPRIVE has been designed to accommodate custom or pre-built virtual worlds while being light-weight to contain execution times and allow fast rendering. Its main advantage lies in the possibility of testing complex algorithms on the full software and hardware stack while minimizing the risks and costs of a test campaign. The framework has been validated by testing a reinforcement learning agent trained for obstacle avoidance on an AgileX Scout Mini rover that navigates a virtual office environment where everyday objects and people are placed as obstacles. The physical rover moves with no collision in an indoor limited space, thanks to a LiDAR-based heuristic. 

**Abstract (ZH)**: 机器学习在 cyber-物理系统中的应用引起了工业和学术界的兴趣。然而，尚未找到针对神经网络和强化学习代理不可预测行为的通用解决方案。尽管如此，逼真的模拟器技术的进步为在不同的虚拟场景中广泛测试复杂算法铺平了道路，而在真实世界中实现这些测试将非常昂贵且危险。

本文提出了SimPRIVE，一种用于物理机器人与虚拟环境交互的模拟框架，它作为车辆在环平台运行，在真实世界中操作车辆的同时渲染虚拟世界。

使用SimPRIVE，任何运行在ROS 2上的物理移动机器人可以轻松配置其数字双胞胎在使用Unreal Engine 5图形引擎构建的虚拟世界中移动，该虚拟世界可以包含具有可编程行为的对象、人物或其他车辆。

SimPRIVE旨在容纳自定义或预构建的虚拟世界，同时保持轻量级以控制执行时间和允许快速渲染。其主要优势在于能够在完整的软件和硬件堆栈上测试复杂算法，同时将测试活动的风险和成本降到最低。该框架通过在使用基于LiDAR的启发式算法的AgileX Scout Mini移动机器人上测试训练用于避免障碍的强化学习代理，并使其在虚拟办公环境中导航，其中放置了日常物体和人物作为障碍物，得到了验证。移动机器人在室内有限空间内成功避开了障碍物，未发生碰撞。 

---
# Rethinking Visual Layer Selection in Multimodal LLMs 

**Title (ZH)**: 重塑多模态LLM中视觉层的选择 

**Authors**: Haoran Chen, Junyan Lin, Xinhao Chen, Yue Fan, Xin Jin, Hui Su, Jianfeng Dong, Jinlan Fu, Xiaoyu Shen  

**Link**: [PDF](https://arxiv.org/pdf/2504.21447)  

**Abstract**: Multimodal large language models (MLLMs) have achieved impressive performance across a wide range of tasks, typically using CLIP-ViT as their visual encoder due to its strong text-image alignment capabilities. While prior studies suggest that different CLIP-ViT layers capture different types of information, with shallower layers focusing on fine visual details and deeper layers aligning more closely with textual semantics, most MLLMs still select visual features based on empirical heuristics rather than systematic analysis. In this work, we propose a Layer-wise Representation Similarity approach to group CLIP-ViT layers with similar behaviors into {shallow, middle, and deep} categories and assess their impact on MLLM performance. Building on this foundation, we revisit the visual layer selection problem in MLLMs at scale, training LLaVA-style models ranging from 1.4B to 7B parameters. Through extensive experiments across 10 datasets and 4 tasks, we find that: (1) deep layers are essential for OCR tasks; (2) shallow and middle layers substantially outperform deep layers on reasoning tasks involving counting, positioning, and object localization; (3) a lightweight fusion of features across shallow, middle, and deep layers consistently outperforms specialized fusion baselines and single-layer selections, achieving gains on 9 out of 10 datasets. Our work offers the first principled study of visual layer selection in MLLMs, laying the groundwork for deeper investigations into visual representation learning for MLLMs. 

**Abstract (ZH)**: 多模态大型语言模型（MLLMs）在广泛的任务中表现出了显著的效果，通常使用CLIP-ViT作为其视觉编码器，这得益于其强大的文本-图像对齐能力。尽管前期研究指出不同CLIP-ViT层捕获不同类型的信息，浅层层侧重于精细的视觉细节，而深层层更紧密地与文本语义对齐，但大多数MLLMs仍然基于经验启发/rules选择视觉特征，而非系统的分析。在本工作中，我们提出了一种逐层表示相似性方法，将具有类似行为的CLIP-ViT层分为浅层、中层和深层三类，并评估它们对MLLM性能的影响。在此基础上，我们对大规模MLLM中视觉层的选择问题进行了重新审视，训练了从1.4B到7B参数的LLaVA风格模型。通过在10个数据集和4个任务上的广泛实验，我们发现：（1）深层层对于OCR任务是必不可少的；（2）浅层和中层显著优于深层层，在涉及计数、定位和对象定位的推理任务中表现更佳；（3）跨浅层、中层和深层层的轻量级特征融合始终优于专门的特征融合基准和单层选择，有9个数据集上取得了改进。我们的工作首次系统地研究了MLLM中的视觉层选择问题，为MLLM中的视觉表示学习的深入研究奠定了基础。 

---
# SeriesBench: A Benchmark for Narrative-Driven Drama Series Understanding 

**Title (ZH)**: SeriesBench：叙述驱动连续剧理解的基准测试 

**Authors**: Chenkai Zhang, Yiming Lei, Zeming Liu, Haitao Leng, ShaoGuo Liu, Tingting Gao, Qingjie Liu, Yunhong Wang  

**Link**: [PDF](https://arxiv.org/pdf/2504.21435)  

**Abstract**: With the rapid development of Multi-modal Large Language Models (MLLMs), an increasing number of benchmarks have been established to evaluate the video understanding capabilities of these models. However, these benchmarks focus on \textbf{standalone} videos and mainly assess ``visual elements'' like human actions and object states. In reality, contemporary videos often encompass complex and continuous narratives, typically presented as a \textbf{series}. To address this challenge, we propose \textbf{SeriesBench}, a benchmark consisting of 105 carefully curated narrative-driven series, covering 28 specialized tasks that require deep narrative understanding. Specifically, we first select a diverse set of drama series spanning various genres. Then, we introduce a novel long-span narrative annotation method, combined with a full-information transformation approach to convert manual annotations into diverse task formats. To further enhance model capacity for detailed analysis of plot structures and character relationships within series, we propose a novel narrative reasoning framework, \textbf{PC-DCoT}. Extensive results on \textbf{SeriesBench} indicate that existing MLLMs still face significant challenges in understanding narrative-driven series, while \textbf{PC-DCoT} enables these MLLMs to achieve performance improvements. Overall, our \textbf{SeriesBench} and \textbf{PC-DCoT} highlight the critical necessity of advancing model capabilities to understand narrative-driven series, guiding the future development of MLLMs. SeriesBench is publicly available at this https URL. 

**Abstract (ZH)**: 随着多模态大规模语言模型（MLLMs）的迅速发展，越来越多的基准已建立起来，用于评估这些模型的视频理解能力。然而，这些基准主要关注**独立**视频，并主要评估“视觉元素”如人类动作和对象状态。实际上，当代视频通常包含复杂的连续叙述，通常以一系列的形式呈现。为了解决这一挑战，我们提出了**SeriesBench**基准，该基准包含105个精心策划的故事驱动系列，涵盖了28个需要深刻叙述理解的专门任务。具体来说，我们首先选择了一系列涵盖各种类型的戏剧系列。然后，我们引入了一种新颖的长跨度叙述注释方法，并结合全面信息转换方法，将手动注释转换为多种任务格式。为了进一步增强模型对系列内情节结构和人物关系的详细分析能力，我们提出了一种新颖的叙述推理框架**PC-DCoT**。在**SeriesBench**上的广泛实验结果表明，现有MLLMs在理解故事驱动的系列方面仍面临重大挑战，而**PC-DCoT**使得这些MLLMs能够实现性能提升。总体而言，我们的**SeriesBench**和**PC-DCoT**突显了提高模型能力以理解故事驱动的系列刻不容缓的重要性，指导MLLMs的未来发展方向。SeriesBench可以在以下网址获取：这个 https URL。 

---
# UAV Marketplace Simulation Tool for BVLOS Operations 

**Title (ZH)**: UAV市场交易平台模拟工具（适用于视距外操作） 

**Authors**: Kıvanç Şerefoğlu, Önder Gürcan, Reyhan Aydoğan  

**Link**: [PDF](https://arxiv.org/pdf/2504.21428)  

**Abstract**: We present a simulation tool for evaluating team formation in autonomous multi-UAV (Unmanned Aerial Vehicle) missions that operate Beyond Visual Line of Sight (BVLOS). The tool models UAV collaboration and mission execution in dynamic and adversarial conditions, where Byzantine UAVs attempt to disrupt operations. Our tool allows researchers to integrate and compare various team formation strategies in a controlled environment with configurable mission parameters and adversarial behaviors. The log of each simulation run is stored in a structured way along with performance metrics so that statistical analysis could be done straightforwardly. The tool is versatile for testing and improving UAV coordination strategies in real-world applications. 

**Abstract (ZH)**: 一种评估自主多UAV任务中团队形成工具的研究：适用于超视距操作的拜占庭无人机干扰条件下的协同与任务执行模拟 

---
# MPEC: Manifold-Preserved EEG Classification via an Ensemble of Clustering-Based Classifiers 

**Title (ZH)**: MPEC：基于聚类分类器集成的流形保留EEG分类 

**Authors**: Shermin Shahbazi, Mohammad-Reza Nasiri, Majid Ramezani  

**Link**: [PDF](https://arxiv.org/pdf/2504.21427)  

**Abstract**: Accurate classification of EEG signals is crucial for brain-computer interfaces (BCIs) and neuroprosthetic applications, yet many existing methods fail to account for the non-Euclidean, manifold structure of EEG data, resulting in suboptimal performance. Preserving this manifold information is essential to capture the true geometry of EEG signals, but traditional classification techniques largely overlook this need. To this end, we propose MPEC (Manifold-Preserved EEG Classification via an Ensemble of Clustering-Based Classifiers), that introduces two key innovations: (1) a feature engineering phase that combines covariance matrices and Radial Basis Function (RBF) kernels to capture both linear and non-linear relationships among EEG channels, and (2) a clustering phase that employs a modified K-means algorithm tailored for the Riemannian manifold space, ensuring local geometric sensitivity. Ensembling multiple clustering-based classifiers, MPEC achieves superior results, validated by significant improvements on the BCI Competition IV dataset 2a. 

**Abstract (ZH)**: Manifold-Preserved EEG Classification via an Ensemble of Clustering-Based Classifiers 

---
# Optimizing Mouse Dynamics for User Authentication by Machine Learning: Addressing Data Sufficiency, Accuracy-Practicality Trade-off, and Model Performance Challenges 

**Title (ZH)**: 基于机器学习优化鼠标动态以实现用户身份认证：解决数据充足性、准确性和实用性权衡以及模型性能挑战 

**Authors**: Yi Wang, Chengyv Wu, Yang Liao, Maowei You  

**Link**: [PDF](https://arxiv.org/pdf/2504.21415)  

**Abstract**: User authentication is essential to ensure secure access to computer systems, yet traditional methods face limitations in usability, cost, and security. Mouse dynamics authentication, based on the analysis of users' natural interaction behaviors with mouse devices, offers a cost-effective, non-intrusive, and adaptable solution. However, challenges remain in determining the optimal data volume, balancing accuracy and practicality, and effectively capturing temporal behavioral patterns. In this study, we propose a statistical method using Gaussian kernel density estimate (KDE) and Kullback-Leibler (KL) divergence to estimate the sufficient data volume for training authentication models. We introduce the Mouse Authentication Unit (MAU), leveraging Approximate Entropy (ApEn) to optimize segment length for efficient and accurate behavioral representation. Furthermore, we design the Local-Time Mouse Authentication (LT-AMouse) framework, integrating 1D-ResNet for local feature extraction and GRU for modeling long-term temporal dependencies. Taking the Balabit and DFL datasets as examples, we significantly reduced the data scale, particularly by a factor of 10 for the DFL dataset, greatly alleviating the training burden. Additionally, we determined the optimal input recognition unit length for the user authentication system on different datasets based on the slope of Approximate Entropy. Training with imbalanced samples, our model achieved a successful defense AUC 98.52% for blind attack on the DFL dataset and 94.65% on the Balabit dataset, surpassing the current sota performance. 

**Abstract (ZH)**: 基于鼠标动力学的用户认证：一种使用高斯核密度估计和Kullback-Leibler散度确定充分数据量的方法及局部时间鼠标认证框架 

---
# Galvatron: An Automatic Distributed System for Efficient Foundation Model Training 

**Title (ZH)**: Galvatron: 一种高效的分布式系统自动训练基础模型 

**Authors**: Xinyi Liu, Yujie Wang, Shenhan Zhu, Fangcheng Fu, Qingshuo Liu, Guangming Lin, Bin Cui  

**Link**: [PDF](https://arxiv.org/pdf/2504.21411)  

**Abstract**: Galvatron is a distributed system for efficiently training large-scale Foundation Models. It overcomes the complexities of selecting optimal parallelism strategies by automatically identifying the most efficient hybrid strategy, incorporating data, tensor, pipeline, sharded data, and sequence parallelism, along with recomputation. The system's architecture includes a profiler for hardware and model analysis, a search engine for strategy optimization using decision trees and dynamic programming, and a runtime for executing these strategies efficiently. Benchmarking on various clusters demonstrates Galvatron's superior throughput compared to existing frameworks. This open-source system offers user-friendly interfaces and comprehensive documentation, making complex distributed training accessible and efficient. The source code of Galvatron is available at this https URL. 

**Abstract (ZH)**: Galvatron：一种高效训练大规模基础模型的分布式系统 

---
# FAST-Q: Fast-track Exploration with Adversarially Balanced State Representations for Counterfactual Action Estimation in Offline Reinforcement Learning 

**Title (ZH)**: FAST-Q: 快速探索与对抗均衡状态表示在离线强化学习中用于反事实动作评估中的应用 

**Authors**: Pulkit Agrawal, Rukma Talwadker, Aditya Pareek, Tridib Mukherjee  

**Link**: [PDF](https://arxiv.org/pdf/2504.21383)  

**Abstract**: Recent advancements in state-of-the-art (SOTA) offline reinforcement learning (RL) have primarily focused on addressing function approximation errors, which contribute to the overestimation of Q-values for out-of-distribution actions, a challenge that static datasets exacerbate. However, high stakes applications such as recommendation systems in online gaming, introduce further complexities due to player's psychology (intent) driven by gameplay experiences and the inherent volatility on the platform. These factors create highly sparse, partially overlapping state spaces across policies, further influenced by the experiment path selection logic which biases state spaces towards specific policies. Current SOTA methods constrain learning from such offline data by clipping known counterfactual actions as out-of-distribution due to poor generalization across unobserved states. Further aggravating conservative Q-learning and necessitating more online exploration. FAST-Q introduces a novel approach that (1) leverages Gradient Reversal Learning to construct balanced state representations, regularizing the policy-specific bias between the player's state and action thereby enabling counterfactual estimation; (2) supports offline counterfactual exploration in parallel with static data exploitation; and (3) proposes a Q-value decomposition strategy for multi-objective optimization, facilitating explainable recommendations over short and long-term objectives. These innovations demonstrate superiority of FAST-Q over prior SOTA approaches and demonstrates at least 0.15 percent increase in player returns, 2 percent improvement in lifetime value (LTV), 0.4 percent enhancement in the recommendation driven engagement, 2 percent improvement in the player's platform dwell time and an impressive 10 percent reduction in the costs associated with the recommendation, on our volatile gaming platform. 

**Abstract (ZH)**: FAST-Q：一种新颖的离线强化学习方法及其在在线游戏推荐系统中的应用 

---
# Retrieval-Enhanced Few-Shot Prompting for Speech Event Extraction 

**Title (ZH)**: 基于检索增强的少量示例提示语音事件提取 

**Authors**: Máté Gedeon  

**Link**: [PDF](https://arxiv.org/pdf/2504.21372)  

**Abstract**: Speech Event Extraction (SpeechEE) is a challenging task that lies at the intersection of Automatic Speech Recognition (ASR) and Natural Language Processing (NLP), requiring the identification of structured event information from spoken language. In this work, we present a modular, pipeline-based SpeechEE framework that integrates high-performance ASR with semantic search-enhanced prompting of Large Language Models (LLMs). Our system first classifies speech segments likely to contain events using a hybrid filtering mechanism including rule-based, BERT-based, and LLM-based models. It then employs few-shot LLM prompting, dynamically enriched via semantic similarity retrieval, to identify event triggers and extract corresponding arguments. We evaluate the pipeline using multiple LLMs (Llama3-8B, GPT-4o-mini, and o1-mini) highlighting significant performance gains with o1-mini, which achieves 63.3% F1 on trigger classification and 27.8% F1 on argument classification, outperforming prior benchmarks. Our results demonstrate that pipeline approaches, when empowered by retrieval-augmented LLMs, can rival or exceed end-to-end systems while maintaining interpretability and modularity. This work provides practical insights into LLM-driven event extraction and opens pathways for future hybrid models combining textual and acoustic features. 

**Abstract (ZH)**: 基于检索增强的大语言模型的模块化语音事件抽取框架 

---
# Revisiting Diffusion Autoencoder Training for Image Reconstruction Quality 

**Title (ZH)**: 重新审视扩散自编码器训练以提高图像重建质量 

**Authors**: Pramook Khungurn, Sukit Seripanitkarn, Phonphrm Thawatdamrongkit, Supasorn Suwajanakorn  

**Link**: [PDF](https://arxiv.org/pdf/2504.21368)  

**Abstract**: Diffusion autoencoders (DAEs) are typically formulated as a noise prediction model and trained with a linear-$\beta$ noise schedule that spends much of its sampling steps at high noise levels. Because high noise levels are associated with recovering large-scale image structures and low noise levels with recovering details, this configuration can result in low-quality and blurry images. However, it should be possible to improve details while spending fewer steps recovering structures because the latent code should already contain structural information. Based on this insight, we propose a new DAE training method that improves the quality of reconstructed images. We divide training into two phases. In the first phase, the DAE is trained as a vanilla autoencoder by always setting the noise level to the highest, forcing the encoder and decoder to populate the latent code with structural information. In the second phase, we incorporate a noise schedule that spends more time in the low-noise region, allowing the DAE to learn how to perfect the details. Our method results in images that have accurate high-level structures and low-level details while still preserving useful properties of the latent codes. 

**Abstract (ZH)**: 扩散自编码器（DAEs）通常被公式化为一个噪声预测模型，并使用线性-$\beta$噪声调度进行训练，其中大部分采样步骤处于高噪声水平。由于高噪声水平与恢复大规模图像结构相关，而低噪声水平与恢复细节相关，这种配置可能导致低质量和模糊的图像。然而，应该有可能在花费更少步骤恢复结构的同时改进细节，因为潜在代码中应包含结构信息。基于这一洞察，我们提出了一种新的DAE训练方法，以提高重建图像的质量。我们将训练分为两个阶段。在第一阶段，DAE作为普通的自编码器进行训练，始终将噪声水平设置为最高，迫使编码器和解码器向潜在代码填充结构信息。在第二阶段，我们引入一种噪声调度，使其在低噪声区域花费更多时间，允许DAE学习如何完美细节。我们的方法生成的图像具有准确的高层结构和低层细节，同时保留潜在代码的有用属性。 

---
# DGFNet: End-to-End Audio-Visual Source Separation Based on Dynamic Gating Fusion 

**Title (ZH)**: DGFNet：基于动态门控融合的端到端音频-视觉源分离 

**Authors**: Yinfeng Yu, Shiyu Sun  

**Link**: [PDF](https://arxiv.org/pdf/2504.21366)  

**Abstract**: Current Audio-Visual Source Separation methods primarily adopt two design strategies. The first strategy involves fusing audio and visual features at the bottleneck layer of the encoder, followed by processing the fused features through the decoder. However, when there is a significant disparity between the two modalities, this approach may lead to the loss of critical information. The second strategy avoids direct fusion and instead relies on the decoder to handle the interaction between audio and visual features. Nonetheless, if the encoder fails to integrate information across modalities adequately, the decoder may be unable to effectively capture the complex relationships between them. To address these issues, this paper proposes a dynamic fusion method based on a gating mechanism that dynamically adjusts the modality fusion degree. This approach mitigates the limitations of solely relying on the decoder and facilitates efficient collaboration between audio and visual features. Additionally, an audio attention module is introduced to enhance the expressive capacity of audio features, thereby further improving model performance. Experimental results demonstrate that our method achieves significant performance improvements on two benchmark datasets, validating its effectiveness and advantages in Audio-Visual Source Separation tasks. 

**Abstract (ZH)**: 当前的音频-视觉源分离方法主要采用两种设计策略。第一种策略是在编码器的瓶颈层融合音频和视觉特征，然后通过解码器处理融合后的特征。然而，当两种模态之间存在显著差异时，这种做法可能导致关键信息的丢失。第二种策略避免直接融合，而是依靠解码器来处理音频和视觉特征之间的交互。然而，如果编码器未能充分整合跨模态的信息，解码器可能无法有效捕捉它们之间的复杂关系。为了解决这些问题，本文提出了一种基于门控机制的动态融合方法，该方法动态调整模态融合程度。该方法减轻了仅依赖解码器的局限性，促进了音频和视觉特征的有效协作。此外，引入了音频注意力模块以增强音频特征的表达能力，进而进一步提高模型性能。实验结果表明，该方法在两个基准数据集上实现了显著的性能提升，验证了其在音频-视觉源分离任务中的有效性和优势。 

---
# A comparative study of deep learning and ensemble learning to extend the horizon of traffic forecasting 

**Title (ZH)**: 深度学习与集成学习的对比研究：扩展交通预测的预见期 

**Authors**: Xiao Zheng, Saeed Asadi Bagloee, Majid Sarvi  

**Link**: [PDF](https://arxiv.org/pdf/2504.21358)  

**Abstract**: Traffic forecasting is vital for Intelligent Transportation Systems, for which Machine Learning (ML) methods have been extensively explored to develop data-driven Artificial Intelligence (AI) solutions. Recent research focuses on modelling spatial-temporal correlations for short-term traffic prediction, leaving the favourable long-term forecasting a challenging and open issue. This paper presents a comparative study on large-scale real-world signalized arterials and freeway traffic flow datasets, aiming to evaluate promising ML methods in the context of large forecasting horizons up to 30 days. Focusing on modelling capacity for temporal dynamics, we develop one ensemble ML method, eXtreme Gradient Boosting (XGBoost), and a range of Deep Learning (DL) methods, including Recurrent Neural Network (RNN)-based methods and the state-of-the-art Transformer-based method. Time embedding is leveraged to enhance their understanding of seasonality and event factors. Experimental results highlight that while the attention mechanism/Transformer framework is effective for capturing long-range dependencies in sequential data, as the forecasting horizon extends, the key to effective traffic forecasting gradually shifts from temporal dependency capturing to periodicity modelling. Time embedding is particularly effective in this context, helping naive RNN outperform Informer by 31.1% for 30-day-ahead forecasting. Meanwhile, as an efficient and robust model, XGBoost, while learning solely from time features, performs competitively with DL methods. Moreover, we investigate the impacts of various factors like input sequence length, holiday traffic, data granularity, and training data size. The findings offer valuable insights and serve as a reference for future long-term traffic forecasting research and the improvement of AI's corresponding learning capabilities. 

**Abstract (ZH)**: 大规模实时信号交叉口和高速公路交通流数据的长程预测方法对比研究 

---
# Nexus-Gen: A Unified Model for Image Understanding, Generation, and Editing 

**Title (ZH)**: Nexus-Gen：统一的图像理解、生成和编辑模型 

**Authors**: Hong Zhang, Zhongjie Duan, Xingjun Wang, Yingda Chen, Yuze Zhao, Yu Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2504.21356)  

**Abstract**: Unified multimodal large language models (MLLMs) aim to integrate multimodal understanding and generation abilities through a single framework. Despite their versatility, existing open-source unified models exhibit performance gaps against domain-specific architectures. To bridge this gap, we present Nexus-Gen, a unified model that synergizes the language reasoning capabilities of LLMs with the image synthesis power of diffusion models. To align the embedding space of the LLM and diffusion model, we conduct a dual-phase alignment training process. (1) The autoregressive LLM learns to predict image embeddings conditioned on multimodal inputs, while (2) the vision decoder is trained to reconstruct high-fidelity images from these embeddings. During training the LLM, we identified a critical discrepancy between the autoregressive paradigm's training and inference phases, where error accumulation in continuous embedding space severely degrades generation quality. To avoid this issue, we introduce a prefilled autoregression strategy that prefills input sequence with position-embedded special tokens instead of continuous embeddings. Through dual-phase training, Nexus-Gen has developed the integrated capability to comprehensively address the image understanding, generation and editing tasks. All models, datasets, and codes are published at this https URL to facilitate further advancements across the field. 

**Abstract (ZH)**: 统一多模态大型语言模型（MLLMs）旨在通过单一框架集成多模态的理解和生成能力。为了弥合这一差距，我们提出了Nexus-Gen模型，该模型结合了大型语言模型的语言推理能力和扩散模型的图像合成能力。为了使语言模型和扩散模型的嵌入空间保持一致，我们采用了双重训练过程。在训练语言模型时，我们发现自回归范式的训练和推理阶段之间存在关键差异，连续嵌入空间中的误差积累严重降低了生成质量。为了避免这一问题，我们引入了预填充自回归策略，使用位置嵌入的特殊标记来填充输入序列，而不是连续嵌入。通过双重训练，Nexus-Gen具备了全面解决图像理解和生成编辑任务的集成能力。所有模型、数据集和代码均在此处发布，以促进该领域进一步的发展。 

---
# Vision-Language Model-Based Semantic-Guided Imaging Biomarker for Early Lung Cancer Detection 

**Title (ZH)**: 基于视觉-语言模型的语义引导影像生物标志物在早期肺癌检测中的应用 

**Authors**: Luoting Zhuang, Seyed Mohammad Hossein Tabatabaei, Ramin Salehi-Rad, Linh M. Tran, Denise R. Aberle, Ashley E. Prosper, William Hsu  

**Link**: [PDF](https://arxiv.org/pdf/2504.21344)  

**Abstract**: Objective: A number of machine learning models have utilized semantic features, deep features, or both to assess lung nodule malignancy. However, their reliance on manual annotation during inference, limited interpretability, and sensitivity to imaging variations hinder their application in real-world clinical settings. Thus, this research aims to integrate semantic features derived from radiologists' assessments of nodules, allowing the model to learn clinically relevant, robust, and explainable features for predicting lung cancer. Methods: We obtained 938 low-dose CT scans from the National Lung Screening Trial with 1,246 nodules and semantic features. The Lung Image Database Consortium dataset contains 1,018 CT scans, with 2,625 lesions annotated for nodule characteristics. Three external datasets were obtained from UCLA Health, the LUNGx Challenge, and the Duke Lung Cancer Screening. We finetuned a pretrained Contrastive Language-Image Pretraining model with a parameter-efficient fine-tuning approach to align imaging and semantic features and predict the one-year lung cancer diagnosis. Results: We evaluated the performance of the one-year diagnosis of lung cancer with AUROC and AUPRC and compared it to three state-of-the-art models. Our model demonstrated an AUROC of 0.90 and AUPRC of 0.78, outperforming baseline state-of-the-art models on external datasets. Using CLIP, we also obtained predictions on semantic features, such as nodule margin (AUROC: 0.81), nodule consistency (0.81), and pleural attachment (0.84), that can be used to explain model predictions. Conclusion: Our approach accurately classifies lung nodules as benign or malignant, providing explainable outputs, aiding clinicians in comprehending the underlying meaning of model predictions. This approach also prevents the model from learning shortcuts and generalizes across clinical settings. 

**Abstract (ZH)**: 目标：许多机器学习模型利用语义特征、深度特征或两者来评估肺结节的恶性程度。然而，这些模型在推理过程中依赖于手动注释、解释能力有限以及对成像变异的敏感性限制了其在临床场景中的应用。因此，本研究旨在结合放射科医生对结节的评估产生的语义特征，使模型能够学习与临床相关、稳健且可解释的特征，以预测肺癌。方法：我们获得了来自国家肺癌筛查试验的938例低剂量CT扫描，包含1,246个结节及其语义特征。Lung Image Database Consortium数据集包含1,018例CT扫描，其中2,625个病灶标注了结节特征。我们还获得了来自UCLA Health、LUNGx挑战赛和杜克肺癌筛查的三个外部数据集。我们使用参数高效微调方法对预训练的对比语言-图像预训练模型进行微调，以对齐影像和语义特征并预测一年后的肺癌诊断结果。结果：我们使用AUROC和AUPRC评估了一年肺癌诊断的性能，并将其与三种最新模型进行了比较。我们的模型的AUROC为0.90，AUPRC为0.78，在外部数据集上优于基线最新模型。使用CLIP，我们还获得了结节边缘（AUROC: 0.81）、结节一致性（0.81）和胸膜固定（0.84）等语义特征的预测，这些特征可用于解释模型预测。结论：我们的方法准确地将肺结节分类为良性或恶性，提供了可解释的输出，帮助临床医生理解模型预测的含义。此外，这种方法还能防止模型学习捷径，并在不同临床场景中泛化。 

---
# Q-function Decomposition with Intervention Semantics with Factored Action Spaces 

**Title (ZH)**: 带有干预语义的事实化动作空间Q函数分解 

**Authors**: Junkyu Lee, Tian Gao, Elliot Nelson, Miao Liu, Debarun Bhattacharjya, Songtao Lu  

**Link**: [PDF](https://arxiv.org/pdf/2504.21326)  

**Abstract**: Many practical reinforcement learning environments have a discrete factored action space that induces a large combinatorial set of actions, thereby posing significant challenges. Existing approaches leverage the regular structure of the action space and resort to a linear decomposition of Q-functions, which avoids enumerating all combinations of factored actions. In this paper, we consider Q-functions defined over a lower dimensional projected subspace of the original action space, and study the condition for the unbiasedness of decomposed Q-functions using causal effect estimation from the no unobserved confounder setting in causal statistics. This leads to a general scheme which we call action decomposed reinforcement learning that uses the projected Q-functions to approximate the Q-function in standard model-free reinforcement learning algorithms. The proposed approach is shown to improve sample complexity in a model-based reinforcement learning setting. We demonstrate improvements in sample efficiency compared to state-of-the-art baselines in online continuous control environments and a real-world offline sepsis treatment environment. 

**Abstract (ZH)**: 多种实际强化学习环境具有离散的事实性动作空间，导致大量的组合动作集，从而带来显著的挑战。现有的方法利用动作空间的有序结构，并采用Q函数的线性分解，从而避免枚举所有事实性动作的组合。在本文中，我们考虑定义在原动作空间低维投影子空间上的Q函数，并利用因果统计中的无未观测混杂变量假设下的因果效应估计研究分解后的Q函数的无偏性。这导致了一种一般方案，称为动作分解强化学习，利用投影后的Q函数近似标准模型自由强化学习算法中的Q函数。所提出的方法在基于模型的强化学习环境中展示了样本复杂度的改进。我们在线性连续控制环境和现实世界的脱机脓毒症治疗环境中展示了与最新基准相比的样本效率改进。 

---
# How to Backdoor the Knowledge Distillation 

**Title (ZH)**: 如何在知识精炼中植入后门 

**Authors**: Chen Wu, Qian Ma, Prasenjit Mitra, Sencun Zhu  

**Link**: [PDF](https://arxiv.org/pdf/2504.21323)  

**Abstract**: Knowledge distillation has become a cornerstone in modern machine learning systems, celebrated for its ability to transfer knowledge from a large, complex teacher model to a more efficient student model. Traditionally, this process is regarded as secure, assuming the teacher model is clean. This belief stems from conventional backdoor attacks relying on poisoned training data with backdoor triggers and attacker-chosen labels, which are not involved in the distillation process. Instead, knowledge distillation uses the outputs of a clean teacher model to guide the student model, inherently preventing recognition or response to backdoor triggers as intended by an attacker. In this paper, we challenge this assumption by introducing a novel attack methodology that strategically poisons the distillation dataset with adversarial examples embedded with backdoor triggers. This technique allows for the stealthy compromise of the student model while maintaining the integrity of the teacher model. Our innovative approach represents the first successful exploitation of vulnerabilities within the knowledge distillation process using clean teacher models. Through extensive experiments conducted across various datasets and attack settings, we demonstrate the robustness, stealthiness, and effectiveness of our method. Our findings reveal previously unrecognized vulnerabilities and pave the way for future research aimed at securing knowledge distillation processes against backdoor attacks. 

**Abstract (ZH)**: 知识蒸馏已成为现代机器学习系统中的基石，因其能够将大型复杂教师模型的知识转移到更高效的 student 模型中而备受推崇。传统上，这一过程被认为是安全的，假设教师模型是干净的。这一信念源于传统后门攻击依赖篡改训练数据和攻击者选择的标签，而这些数据和标签并不参与到知识蒸馏的过程中。相反，知识蒸馏利用干净教师模型的输出来指导 student 模型，从本质上防止 student 模型识别或响应攻击者意在植入的后门触发器。在本文中，我们通过引入一种新的攻击方法，该方法战略性地将带有后门触发器的对抗样本污染知识蒸馏数据集，挑战了这一假设。该技术能够在不破坏教师模型完整性的情况下秘密地渗透 student 模型。我们的创新方法是首次利用干净教师模型在知识蒸馏过程中成功利用漏洞的方法。通过在各种数据集和攻击设置下进行的广泛实验，我们展示了该方法的稳健性、隐蔽性和有效性。我们的研究结果揭示了之前未被认识的漏洞，并为未来研究确保知识蒸馏过程免受后门攻击铺平了道路。 

---
# Participatory AI, Public Sector AI, Differential Privacy, Conversational Interfaces, Explainable AI, Citizen Engagement in AI 

**Title (ZH)**: 参与式人工智能、公共部门人工智能、差异隐私、对话式接口、可解释人工智能、公民参与人工智能 

**Authors**: Wenjun Yang, Eyhab Al-Masri  

**Link**: [PDF](https://arxiv.org/pdf/2504.21297)  

**Abstract**: This paper introduces a conversational interface system that enables participatory design of differentially private AI systems in public sector applications. Addressing the challenge of balancing mathematical privacy guarantees with democratic accountability, we propose three key contributions: (1) an adaptive $\epsilon$-selection protocol leveraging TOPSIS multi-criteria decision analysis to align citizen preferences with differential privacy (DP) parameters, (2) an explainable noise-injection framework featuring real-time Mean Absolute Error (MAE) visualizations and GPT-4-powered impact analysis, and (3) an integrated legal-compliance mechanism that dynamically modulates privacy budgets based on evolving regulatory constraints. Our results advance participatory AI practices by demonstrating how conversational interfaces can enhance public engagement in algorithmic privacy mechanisms, ensuring that privacy-preserving AI in public sector governance remains both mathematically robust and democratically accountable. 

**Abstract (ZH)**: 本文介绍了一种对话式接口系统，使公民能够在公共部门应用中参与设计差异隐私的AI系统。为平衡数学上的隐私保证与民主问责制度，我们提出三项关键贡献：（1）基于TOPSIS多准则决策分析的自适应$\epsilon$选择协议，使公民偏好与差分隐私（DP）参数相契合；（2）一种可解释的噪声注入框架，配备实时均绝对误差（MAE）可视化和由GPT-4驱动的影响分析；（3）一种集成的法律合规机制，根据不断变化的监管约束动态调节隐私预算。我们的研究成果通过展示对话式接口如何增强公民对算法隐私机制的参与，推进了参与式AI实践，确保公共部门治理中的隐私保护AI在数学上保持稳健并符合民主问责要求。 

---
# Fairness in Graph Learning Augmented with Machine Learning: A Survey 

**Title (ZH)**: 图学习增强中的公平性：一个综述 

**Authors**: Renqiang Luo, Ziqi Xu, Xikun Zhang, Qing Qing, Huafei Huang, Enyan Dai, Zhe Wang, Bo Yang  

**Link**: [PDF](https://arxiv.org/pdf/2504.21296)  

**Abstract**: Augmenting specialised machine learning techniques into traditional graph learning models has achieved notable success across various domains, including federated graph learning, dynamic graph learning, and graph transformers. However, the intricate mechanisms of these specialised techniques introduce significant challenges in maintaining model fairness, potentially resulting in discriminatory outcomes in high-stakes applications such as recommendation systems, disaster response, criminal justice, and loan approval. This paper systematically examines the unique fairness challenges posed by Graph Learning augmented with Machine Learning (GL-ML). It highlights the complex interplay between graph learning mechanisms and machine learning techniques, emphasising how the augmentation of machine learning both enhances and complicates fairness. Additionally, we explore four critical techniques frequently employed to improve fairness in GL-ML methods. By thoroughly investigating the root causes and broader implications of fairness challenges in this rapidly evolving field, this work establishes a robust foundation for future research and innovation in GL-ML fairness. 

**Abstract (ZH)**: 将专门的机器学习技术增加到传统图学习模型中已经在多个领域取得了显著成功，包括联邦图学习、动态图学习和图变压器。然而，这些专门技术的复杂机制引入了保持模型公平性的重大挑战，可能导致推荐系统、灾害响应、刑事司法和贷款审批等高风险应用中出现歧视性结果。本文系统性地探究了将机器学习融入图学习（GL-ML）所带来的独特公平性挑战。它强调了图学习机制与机器学习技术之间的复杂交互作用，并突出显示机器学习的增强既提升了又复杂化了公平性。此外，我们探讨了四种常用的、旨在改进GL-ML方法中公平性的关键技术。通过全面调查这一迅速发展的领域中公平性挑战的根本原因及更广泛的含义，本文为GL-ML公平性未来的研究和创新奠定了坚实基础。 

---
# Orthogonal Factor-Based Biclustering Algorithm (BCBOF) for High-Dimensional Data and Its Application in Stock Trend Prediction 

**Title (ZH)**: 基于正交因子的双聚类算法（BCBOF）及其在股票趋势预测中的应用 

**Authors**: Yan Huang, Da-Qing Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2504.21289)  

**Abstract**: Biclustering is an effective technique in data mining and pattern recognition. Biclustering algorithms based on traditional clustering face two fundamental limitations when processing high-dimensional data: (1) The distance concentration phenomenon in high-dimensional spaces leads to data sparsity, rendering similarity measures ineffective; (2) Mainstream linear dimensionality reduction methods disrupt critical local structural patterns. To apply biclustering to high-dimensional datasets, we propose an orthogonal factor-based biclustering algorithm (BCBOF). First, we constructed orthogonal factors in the vector space of the high-dimensional dataset. Then, we performed clustering using the coordinates of the original data in the orthogonal subspace as clustering targets. Finally, we obtained biclustering results of the original dataset. Since dimensionality reduction was applied before clustering, the proposed algorithm effectively mitigated the data sparsity problem caused by high dimensionality. Additionally, we applied this biclustering algorithm to stock technical indicator combinations and stock price trend prediction. Biclustering results were transformed into fuzzy rules, and we incorporated profit-preserving and stop-loss rules into the rule set, ultimately forming a fuzzy inference system for stock price trend predictions and trading signals. To evaluate the performance of BCBOF, we compared it with existing biclustering methods using multiple evaluation metrics. The results showed that our algorithm outperformed other biclustering techniques. To validate the effectiveness of the fuzzy inference system, we conducted virtual trading experiments using historical data from 10 A-share stocks. The experimental results showed that the generated trading strategies yielded higher returns for investors. 

**Abstract (ZH)**: 基于正交因子的 biclustering 算法在高维数据中的应用及其用于股票技术指标组合和股票价格趋势预测中的模糊推理系统 

---
# Assessing LLM code generation quality through path planning tasks 

**Title (ZH)**: 通过路径规划任务评估LLM代码生成质量 

**Authors**: Wanyi Chen, Meng-Wen Su, Mary L. Cummings  

**Link**: [PDF](https://arxiv.org/pdf/2504.21276)  

**Abstract**: As LLM-generated code grows in popularity, more evaluation is needed to assess the risks of using such tools, especially for safety-critical applications such as path planning. Existing coding benchmarks are insufficient as they do not reflect the context and complexity of safety-critical applications. To this end, we assessed six LLMs' abilities to generate the code for three different path-planning algorithms and tested them on three maps of various difficulties. Our results suggest that LLM-generated code presents serious hazards for path planning applications and should not be applied in safety-critical contexts without rigorous testing. 

**Abstract (ZH)**: 随着大语言模型生成的代码日益流行，需要进行更多评估以评估使用这些工具的风险，特别是在路径规划等关键安全应用中。现有的编码基准不足以反映关键安全应用的上下文和复杂性。为此，我们评估了六种大语言模型生成三种不同路径规划算法代码的能力，并在三种不同难度的地图上进行了测试。结果显示，大语言模型生成的代码对路径规划应用存在严重风险，在关键安全情境下不应未经严格测试就使用。 

---
# Multi-Domain Causal Discovery in Bijective Causal Models 

**Title (ZH)**: 生物双射因果模型中的多领域因果发现 

**Authors**: Kasra Jalaldoust, Saber Salehkaleybar, Negar Kiyavash  

**Link**: [PDF](https://arxiv.org/pdf/2504.21261)  

**Abstract**: We consider the problem of causal discovery (a.k.a., causal structure learning) in a multi-domain setting. We assume that the causal functions are invariant across the domains, while the distribution of the exogenous noise may vary. Under causal sufficiency (i.e., no confounders exist), we show that the causal diagram can be discovered under less restrictive functional assumptions compared to previous work. What enables causal discovery in this setting is bijective generation mechanisms (BGM), which ensures that the functional relation between the exogenous noise $E$ and the endogenous variable $Y$ is bijective and differentiable in both directions at every level of the cause variable $X = x$. BGM generalizes a variety of models including additive noise model, LiNGAM, post-nonlinear model, and location-scale noise model. Further, we derive a statistical test to find the parents set of the target variable. Experiments on various synthetic and real-world datasets validate our theoretical findings. 

**Abstract (ZH)**: 多域环境下的因果发现：基于双射生成机制的因果结构学习 

---
# Memorization and Knowledge Injection in Gated LLMs 

**Title (ZH)**: 在门控大型语言模型中的记忆与知识注入 

**Authors**: Xu Pan, Ely Hahami, Zechen Zhang, Haim Sompolinsky  

**Link**: [PDF](https://arxiv.org/pdf/2504.21239)  

**Abstract**: Large Language Models (LLMs) currently struggle to sequentially add new memories and integrate new knowledge. These limitations contrast with the human ability to continuously learn from new experiences and acquire knowledge throughout life. Most existing approaches add memories either through large context windows or external memory buffers (e.g., Retrieval-Augmented Generation), and studies on knowledge injection rarely test scenarios resembling everyday life events. In this work, we introduce a continual learning framework, Memory Embedded in Gated LLMs (MEGa), which injects event memories directly into the weights of LLMs. Each memory is stored in a dedicated set of gated low-rank weights. During inference, a gating mechanism activates relevant memory weights by matching query embeddings to stored memory embeddings. This enables the model to both recall entire memories and answer related questions. On two datasets - fictional characters and Wikipedia events - MEGa outperforms baseline approaches in mitigating catastrophic forgetting. Our model draws inspiration from the complementary memory system of the human brain. 

**Abstract (ZH)**: Large Language Models (LLMs)目前难以顺序添加新记忆并整合新知识。这些限制与人类能够不断从新经历中学习并在一生中不断获取知识的能力形成对比。现有大多数方法通过大上下文窗口或外部记忆缓冲区（例如检索增强生成）来添加记忆，而知识注入的相关研究鲜少测试类似于日常生活事件的场景。本文引入了一种连续学习框架，即嵌入门控LLMs的记忆（MEGa），直接将事件记忆注入到LLMs的权重中。每个记忆存储于一组专用的门控低秩权重中。在推理过程中，门控机制通过匹配查询嵌入和存储的记忆嵌入来激活相关记忆权重，使得模型能够回忆完整记忆并回答相关问题。在两个数据集中——虚构角色和维基百科事件——MEGa在减轻灾难性遗忘方面优于基线方法。我们的模型受到人类互补记忆系统的启发。 

---
# Efficient Quantum-Safe Homomorphic Encryption for Quantum Computer Programs 

**Title (ZH)**: 量子安全同态加密在量子计算机程序中的高效实现 

**Authors**: Ben Goertzel  

**Link**: [PDF](https://arxiv.org/pdf/2504.21235)  

**Abstract**: We present a lattice-based scheme for homomorphic evaluation of quantum programs and proofs that remains secure against quantum adversaries. Classical homomorphic encryption is lifted to the quantum setting by replacing composite-order groups with Module Learning-With-Errors (MLWE) lattices and by generalizing polynomial functors to bounded natural super functors (BNSFs). A secret depolarizing BNSF mask hides amplitudes, while each quantum state is stored as an MLWE ciphertext pair. We formalize security with the qIND-CPA game that allows coherent access to the encryption oracle and give a four-hybrid reduction to decisional MLWE.
The design also covers practical issues usually left open. A typed QC-bridge keeps classical bits produced by measurements encrypted yet still usable as controls, with weak-measurement semantics for expectation-value workloads. Encrypted Pauli twirls add circuit privacy. If a fixed knowledge base is needed, its axioms are shipped as MLWE "capsules"; the evaluator can use them but cannot read them. A rho-calculus driver schedules encrypted tasks across several QPUs and records an auditable trace on an RChain-style ledger.
Performance analysis shows that the extra lattice arithmetic fits inside today's QPU idle windows: a 100-qubit, depth-10^3 teleportation-based proof runs in about 10 ms, the public key (seed only) is 32 bytes, and even a CCA-level key stays below 300 kB. A photonic Dirac-3 prototype that executes homomorphic teleportation plus knowledge-base-relative amplitude checks appears feasible with current hardware. These results indicate that fully homomorphic, knowledge-base-aware quantum reasoning is compatible with near-term quantum clouds and standard post-quantum security assumptions. 

**Abstract (ZH)**: 一种基于格的量子程序同态评估方案及其安全性证明 

---
# T2ID-CAS: Diffusion Model and Class Aware Sampling to Mitigate Class Imbalance in Neck Ultrasound Anatomical Landmark Detection 

**Title (ZH)**: T2ID-CAS: 基于扩散模型和类意识采样的颈部超声解剖标志检测中类不平衡缓解方法 

**Authors**: Manikanta Varaganti, Amulya Vankayalapati, Nour Awad, Gregory R. Dion, Laura J. Brattain  

**Link**: [PDF](https://arxiv.org/pdf/2504.21231)  

**Abstract**: Neck ultrasound (US) plays a vital role in airway management by providing non-invasive, real-time imaging that enables rapid and precise interventions. Deep learning-based anatomical landmark detection in neck US can further facilitate procedural efficiency. However, class imbalance within datasets, where key structures like tracheal rings and vocal folds are underrepresented, presents significant challenges for object detection models. To address this, we propose T2ID-CAS, a hybrid approach that combines a text-to-image latent diffusion model with class-aware sampling to generate high-quality synthetic samples for underrepresented classes. This approach, rarely explored in the ultrasound domain, improves the representation of minority classes. Experimental results using YOLOv9 for anatomical landmark detection in neck US demonstrated that T2ID-CAS achieved a mean Average Precision of 88.2, significantly surpassing the baseline of 66. This highlights its potential as a computationally efficient and scalable solution for mitigating class imbalance in AI-assisted ultrasound-guided interventions. 

**Abstract (ZH)**: 颈部超声（US）在呼吸道管理中发挥着重要作用，通过提供无创的实时成像，使快速而精确的干预成为可能。基于深度学习的颈部US解剖标志检测可以进一步提高程序效率。然而，数据集中的类别不平衡问题，如气管环和声带等关键结构的欠代表，对目标检测模型构成了重大挑战。为了解决这一问题，我们提出了T2ID-CAS，这是一种将文本到图像的潜扩散模型与类别意识采样相结合的混合方法，用于生成欠代表类别的高质量合成样本，这一方法在超声医学领域鲜有探索，能够改善少数类别的表示。实验结果表明，使用YOLOv9进行颈部US解剖标志检测时，T2ID-CAS达到了88.2的平均精确度均值，显著超过了基线模型66的精度，这突显了其作为减轻AI辅助超声引导干预中的类别不平衡问题的高效且可扩展解决方案的潜力。 

---
# CachePrune: Neural-Based Attribution Defense Against Indirect Prompt Injection Attacks 

**Title (ZH)**: CachePrune: 基于神经网络的归因防御以对抗间接提示注入攻击 

**Authors**: Rui Wang, Junda Wu, Yu Xia, Tong Yu, Ruiyi Zhang, Ryan Rossi, Lina Yao, Julian McAuley  

**Link**: [PDF](https://arxiv.org/pdf/2504.21228)  

**Abstract**: Large Language Models (LLMs) are identified as being susceptible to indirect prompt injection attack, where the model undesirably deviates from user-provided instructions by executing tasks injected in the prompt context. This vulnerability stems from LLMs' inability to distinguish between data and instructions within a prompt. In this paper, we propose CachePrune that defends against this attack by identifying and pruning task-triggering neurons from the KV cache of the input prompt context. By pruning such neurons, we encourage the LLM to treat the text spans of input prompt context as only pure data, instead of any indicator of instruction following. These neurons are identified via feature attribution with a loss function induced from an upperbound of the Direct Preference Optimization (DPO) objective. We show that such a loss function enables effective feature attribution with only a few samples. We further improve on the quality of feature attribution, by exploiting an observed triggering effect in instruction following. Our approach does not impose any formatting on the original prompt or introduce extra test-time LLM calls. Experiments show that CachePrune significantly reduces attack success rates without compromising the response quality. Note: This paper aims to defend against indirect prompt injection attacks, with the goal of developing more secure and robust AI systems. 

**Abstract (ZH)**: 大规模语言模型（LLMs）被识别为易受间接提示注入攻击的影响，模型可能会在提示上下文中执行注入的任务，从而偏离用户提供的指令。这种脆弱性源于LLMs无法区分提示中的数据和指令。在本文中，我们提出了CachePrune，通过识别并修剪输入提示上下文的KV缓存中的任务触发神经元来防御这种攻击。通过修剪这些神经元，我们鼓励LLM将输入提示上下文的文本跨度视为纯粹的数据，而不是任何指示指令的标志。这些神经元通过从直接偏好优化（DPO）目标的上界诱导的损失函数进行特征归因来识别。我们证明这种损失函数能够在少量样本的情况下实现有效的特征归因。我们还通过利用观察到的指令跟随触发效应进一步提高了特征归因的质量。我们的方法不对原始提示进行格式化，也不引入额外的测试时间LLM调用。实验表明，CachePrune在不牺牲响应质量的情况下显著降低了攻击成功率。 

---
# MemeBLIP2: A novel lightweight multimodal system to detect harmful memes 

**Title (ZH)**: MemeBLIP2: 一种新的轻量级多模态有害梗检测系统 

**Authors**: Jiaqi Liu, Ran Tong, Aowei Shen, Shuzheng Li, Changlin Yang, Lisha Xu  

**Link**: [PDF](https://arxiv.org/pdf/2504.21226)  

**Abstract**: Memes often merge visuals with brief text to share humor or opinions, yet some memes contain harmful messages such as hate speech. In this paper, we introduces MemeBLIP2, a light weight multimodal system that detects harmful memes by combining image and text features effectively. We build on previous studies by adding modules that align image and text representations into a shared space and fuse them for better classification. Using BLIP-2 as the core vision-language model, our system is evaluated on the PrideMM datasets. The results show that MemeBLIP2 can capture subtle cues in both modalities, even in cases with ironic or culturally specific content, thereby improving the detection of harmful material. 

**Abstract (ZH)**: memes often merge visuals with brief text to share humor or opinions, yet some memes contain harmful messages such as hate speech. In this paper, we introduce MemeBLIP2, a lightweight multimodal system that detects harmful memes by effectively combining image and text features. We build on previous studies by adding modules that align image and text representations into a shared space and fuse them for better classification. Using BLIP-2 as the core vision-language model, our system is evaluated on the PrideMM dataset. The results show that MemeBLIP2 can capture subtle cues in both modalities, even in cases with ironic or culturally specific content, thereby improving the detection of harmful material. 

---
# Pretraining Large Brain Language Model for Active BCI: Silent Speech 

**Title (ZH)**: 大型脑语言模型的预训练在主动BCI中的应用：沉默语音 

**Authors**: Jinzhao Zhou, Zehong Cao, Yiqun Duan, Connor Barkley, Daniel Leong, Xiaowei Jiang, Quoc-Toan Nguyen, Ziyi Zhao, Thomas Do, Yu-Cheng Chang, Sheng-Fu Liang, Chin-teng Lin  

**Link**: [PDF](https://arxiv.org/pdf/2504.21214)  

**Abstract**: This paper explores silent speech decoding in active brain-computer interface (BCI) systems, which offer more natural and flexible communication than traditional BCI applications. We collected a new silent speech dataset of over 120 hours of electroencephalogram (EEG) recordings from 12 subjects, capturing 24 commonly used English words for language model pretraining and decoding. Following the recent success of pretraining large models with self-supervised paradigms to enhance EEG classification performance, we propose Large Brain Language Model (LBLM) pretrained to decode silent speech for active BCI. To pretrain LBLM, we propose Future Spectro-Temporal Prediction (FSTP) pretraining paradigm to learn effective representations from unlabeled EEG data. Unlike existing EEG pretraining methods that mainly follow a masked-reconstruction paradigm, our proposed FSTP method employs autoregressive modeling in temporal and frequency domains to capture both temporal and spectral dependencies from EEG signals. After pretraining, we finetune our LBLM on downstream tasks, including word-level and semantic-level classification. Extensive experiments demonstrate significant performance gains of the LBLM over fully-supervised and pretrained baseline models. For instance, in the difficult cross-session setting, our model achieves 47.0\% accuracy on semantic-level classification and 39.6\% in word-level classification, outperforming baseline methods by 5.4\% and 7.3\%, respectively. Our research advances silent speech decoding in active BCI systems, offering an innovative solution for EEG language model pretraining and a new dataset for fundamental research. 

**Abstract (ZH)**: 本文探讨了在主动脑-计算机接口（BCI）系统中静默语音解码的应用，这些系统提供了比传统BCI应用更为自然和灵活的通信方式。我们收集了一个包含超过120小时电生理记录数据的静默语音新数据集，涵盖了24个常用英语单词，用于语言模型的预训练和解码。借鉴近年来利用自监督框架预训练大型模型以提高EEG分类性能的成功经验，我们提出了一个大型脑语言模型（LBLM），专门用于主动BCI的静默语音解码。为预训练LBLM，我们提出了未来谱时预测（FSTP）预训练框架，以从无标签的EEG数据中学习有效的表示。不同于现有主要遵循掩码重建框架的EEG预训练方法，我们提出的FSTP方法利用了时间和频率域的自回归建模来捕捉EEG信号中的时域和频域依赖关系。预训练后，我们在下游任务中对我们的LBLM进行微调，包括字节级和语义级分类。广泛的实验表明，与完全监督和预训练基线模型相比，LBLM在性能上获得了显著提升。例如，在困难的跨会话设置中，我们的模型在语义级分类中达到了47.0%的准确率，在字节级分类中达到了39.6%的准确率，分别比基线方法高出5.4%和7.3%。我们的研究推进了在主动BCI系统中静默语音解码的应用，提供了一种创新的EEG语言模型预训练解决方案，并为基本研究提供了新的数据集。 

---
# A Cost-Effective LLM-based Approach to Identify Wildlife Trafficking in Online Marketplaces 

**Title (ZH)**: 基于LLM的成本有效方法识别在线市场中的野生动物走私 

**Authors**: Juliana Barbosa, Ulhas Gondhali, Gohar Petrossian, Kinshuk Sharma, Sunandan Chakraborty, Jennifer Jacquet, Juliana Freire  

**Link**: [PDF](https://arxiv.org/pdf/2504.21211)  

**Abstract**: Wildlife trafficking remains a critical global issue, significantly impacting biodiversity, ecological stability, and public health. Despite efforts to combat this illicit trade, the rise of e-commerce platforms has made it easier to sell wildlife products, putting new pressure on wild populations of endangered and threatened species. The use of these platforms also opens a new opportunity: as criminals sell wildlife products online, they leave digital traces of their activity that can provide insights into trafficking activities as well as how they can be disrupted. The challenge lies in finding these traces. Online marketplaces publish ads for a plethora of products, and identifying ads for wildlife-related products is like finding a needle in a haystack. Learning classifiers can automate ad identification, but creating them requires costly, time-consuming data labeling that hinders support for diverse ads and research questions. This paper addresses a critical challenge in the data science pipeline for wildlife trafficking analytics: generating quality labeled data for classifiers that select relevant data. While large language models (LLMs) can directly label advertisements, doing so at scale is prohibitively expensive. We propose a cost-effective strategy that leverages LLMs to generate pseudo labels for a small sample of the data and uses these labels to create specialized classification models. Our novel method automatically gathers diverse and representative samples to be labeled while minimizing the labeling costs. Our experimental evaluation shows that our classifiers achieve up to 95% F1 score, outperforming LLMs at a lower cost. We present real use cases that demonstrate the effectiveness of our approach in enabling analyses of different aspects of wildlife trafficking. 

**Abstract (ZH)**: 野生动物交易仍然是一个关键的全球问题，严重影响生物多样性、生态稳定性和公共卫生。尽管采取了打击这一非法贸易的努力，电子商务平台的兴起使得野生动物制品的销售变得更加容易，对受威胁和濒危物种的野生种群施加了新的压力。同时，这些平台也为打击行动提供了新的机会：随着犯罪分子在网上出售野生动物制品，他们会留下数字痕迹，这些痕迹可以提供关于非法交易活动及其如何被中断的洞察。挑战在于发现这些痕迹。在线市场发布各种产品的广告，识别与野生动物相关的广告就像是在 haystack 中找 needles。利用学习分类器可以自动化广告识别，但创建它们需要耗时费力的数据标注，阻碍了对多样化广告和研究问题的支持。本文解决了数据科学管道中野生动物交易分析的关键挑战：为分类器生成高质量的标注数据以选择相关数据。虽然大型语言模型（LLMs）可以直接标注广告，但大规模这样做成本过高。我们提出了一种成本效益高的策略，利用LLMs生成数据的小样本的伪标签，并使用这些标签创建专门的分类模型。我们提出的新方法可以自动收集多样化的代表性样本进行标注，同时尽量减少标注成本。我们的实验评估表明，我们的分类器取得了高达95%的F1分数，成本比LLMs更低。我们展示了实际案例，证明了该方法在使不同方面野生动物交易分析成为可能方面的有效性。 

---
# FedHERO: A Federated Learning Approach for Node Classification Task on Heterophilic Graphs 

**Title (ZH)**: FedHERO：异质图节点分类任务的联邦学习方法 

**Authors**: Zihan Chen, Xingbo Fu, Yushun Dong, Jundong Li, Cong Shen  

**Link**: [PDF](https://arxiv.org/pdf/2504.21206)  

**Abstract**: Federated Graph Learning (FGL) empowers clients to collaboratively train Graph neural networks (GNNs) in a distributed manner while preserving data privacy. However, FGL methods usually require that the graph data owned by all clients is homophilic to ensure similar neighbor distribution patterns of nodes. Such an assumption ensures that the learned knowledge is consistent across the local models from all clients. Therefore, these local models can be properly aggregated as a global model without undermining the overall performance. Nevertheless, when the neighbor distribution patterns of nodes vary across different clients (e.g., when clients hold graphs with different levels of heterophily), their local models may gain different and even conflict knowledge from their node-level predictive tasks. Consequently, aggregating these local models usually leads to catastrophic performance deterioration on the global model. To address this challenge, we propose FedHERO, an FGL framework designed to harness and share insights from heterophilic graphs effectively. At the heart of FedHERO is a dual-channel GNN equipped with a structure learner, engineered to discern the structural knowledge encoded in the local graphs. With this specialized component, FedHERO enables the local model for each client to identify and learn patterns that are universally applicable across graphs with different patterns of node neighbor distributions. FedHERO not only enhances the performance of individual client models by leveraging both local and shared structural insights but also sets a new precedent in this field to effectively handle graph data with various node neighbor distribution patterns. We conduct extensive experiments to validate the superior performance of FedHERO against existing alternatives. 

**Abstract (ZH)**: 联邦图学习（FGL）赋能客户端以分布式方式协作训练图神经网络（GNNs）的同时保护数据隐私。然而，FGL方法通常要求所有客户端拥有的图数据是同质的，以确保节点邻居分布模式的一致性。这种假设保证了从所有客户端学习到的知识在局部模型之间是一致的，因此可以在不损害整体性能的前提下正确聚合为全局模型。然而，当不同客户端的节点邻居分布模式有所差异（例如，当客户端持有不同亲疏程度的图时），它们的局部模型可能会从节点级预测任务中获得不同的甚至相冲突的知识。因此，这些局部模型通常会导致全局模型性能的灾难性下降。为了解决这一挑战，我们提出了FedHERO，一种设计用于有效利用和分享异质图见解的FGL框架。FedHERO的核心是一个配备结构学习器的双通道GNN，专门用于识别局部图中编码的结构知识。通过这一专业组件，FedHERO使每个客户端的局部模型能够识别并学习适用于不同节点邻居分布模式图的通用模式。FedHERO不仅通过利用局部和共享的结构见解来提升客户端模型的性能，还为处理各种节点邻居分布模式的图数据设定了新标准。我们进行了广泛的实验证明了FedHERO相对于现有替代方法的优越性能。 

---
# SecRepoBench: Benchmarking LLMs for Secure Code Generation in Real-World Repositories 

**Title (ZH)**: SecRepoBench：面向真实世界代码仓库的LLM安全代码生成基准测试 

**Authors**: Connor Dilgren, Purva Chiniya, Luke Griffith, Yu Ding, Yizheng Chen  

**Link**: [PDF](https://arxiv.org/pdf/2504.21205)  

**Abstract**: This paper introduces SecRepoBench, a benchmark to evaluate LLMs on secure code generation in real-world repositories. SecRepoBench has 318 code generation tasks in 27 C/C++ repositories, covering 15 CWEs. We evaluate 19 state-of-the-art LLMs using our benchmark and find that the models struggle with generating correct and secure code. In addition, the performance of LLMs to generate self-contained programs as measured by prior benchmarks do not translate to comparative performance at generating secure and correct code at the repository level in SecRepoBench. We show that the state-of-the-art prompt engineering techniques become less effective when applied to the repository level secure code generation problem. We conduct extensive experiments, including an agentic technique to generate secure code, to demonstrate that our benchmark is currently the most difficult secure coding benchmark, compared to previous state-of-the-art benchmarks. Finally, our comprehensive analysis provides insights into potential directions for enhancing the ability of LLMs to generate correct and secure code in real-world repositories. 

**Abstract (ZH)**: SecRepoBench：一个用于评估LLM在真实世界代码库中安全代码生成性能的标准基准 

---
# Automatic Legal Writing Evaluation of LLMs 

**Title (ZH)**: 自动评估大语言模型的法律写作能力 

**Authors**: Ramon Pires, Roseval Malaquias Junior, Rodrigo Nogueira  

**Link**: [PDF](https://arxiv.org/pdf/2504.21202)  

**Abstract**: Despite the recent advances in Large Language Models, benchmarks for evaluating legal writing remain scarce due to the inherent complexity of assessing open-ended responses in this domain. One of the key challenges in evaluating language models on domain-specific tasks is finding test datasets that are public, frequently updated, and contain comprehensive evaluation guidelines. The Brazilian Bar Examination meets these requirements. We introduce oab-bench, a benchmark comprising 105 questions across seven areas of law from recent editions of the exam. The benchmark includes comprehensive evaluation guidelines and reference materials used by human examiners to ensure consistent grading. We evaluate the performance of four LLMs on oab-bench, finding that Claude-3.5 Sonnet achieves the best results with an average score of 7.93 out of 10, passing all 21 exams. We also investigated whether LLMs can serve as reliable automated judges for evaluating legal writing. Our experiments show that frontier models like OpenAI's o1 achieve a strong correlation with human scores when evaluating approved exams, suggesting their potential as reliable automated evaluators despite the inherently subjective nature of legal writing assessment. The source code and the benchmark -- containing questions, evaluation guidelines, model-generated responses, and their respective automated evaluations -- are publicly available. 

**Abstract (ZH)**: 尽管近年来大型语言模型取得了进展，但由于评估法律写作固有的复杂性，该领域的基准测试仍然稀缺。在评估语言模型的领域特定任务时，找到公共的、频繁更新的测试数据集并包含全面的评价指南是一项关键挑战。巴西律师资格考试符合这些要求。我们介绍了一个名为oab-bench的基准测试，包含来自最近几版考试的105个问题，涵盖七个法律领域。该基准测试包括全面的评价指南和由人类考官使用的参考材料，以确保评分的一致性。我们评估了四个大型语言模型在oab-bench上的性能，发现Claude-3.5 Sonnet平均得分为7.93（满分为10分），通过了全部21场考试。我们还研究了语言模型是否可以作为可靠的自动法官用于评估法律写作。实验结果表明，先锋模型如OpenAI的o1在评估批准的考试时与人工评分有较强的关联性，这表明它们有可能作为可靠的自动评估器，尽管法律写作评估本质上具有主观性。基准测试的源代码和包含问题、评价指南、模型生成的回答及其相应的自动评估等内容的数据集均已公开。 

---
# Turning Up the Heat: Assessing 2-m Temperature Forecast Errors in AI Weather Prediction Models During Heat Waves 

**Title (ZH)**: 提高误差标准：评估热浪期间AI气象预测模型的2米气温预报误差 

**Authors**: Kelsey E. Ennis, Elizabeth A. Barnes, Marybeth C. Arcodia, Martin A. Fernandez, Eric D. Maloney  

**Link**: [PDF](https://arxiv.org/pdf/2504.21195)  

**Abstract**: Extreme heat is the deadliest weather-related hazard in the United States. Furthermore, it is increasing in intensity, frequency, and duration, making skillful forecasts vital to protecting life and property. Traditional numerical weather prediction (NWP) models struggle with extreme heat for medium-range and subseasonal-to-seasonal (S2S) timescales. Meanwhile, artificial intelligence-based weather prediction (AIWP) models are progressing rapidly. However, it is largely unknown how well AIWP models forecast extremes, especially for medium-range and S2S timescales. This study investigates 2-m temperature forecasts for 60 heat waves across the four boreal seasons and over four CONUS regions at lead times up to 20 days, using two AIWP models (Google GraphCast and Pangu-Weather) and one traditional NWP model (NOAA United Forecast System Global Ensemble Forecast System (UFS GEFS)). First, case study analyses show that both AIWP models and the UFS GEFS exhibit consistent cold biases on regional scales in the 5-10 days of lead time before heat wave onset. GraphCast is the more skillful AIWP model, outperforming UFS GEFS and Pangu-Weather in most locations. Next, the two AIWP models are isolated and analyzed across all heat waves and seasons, with events split among the model's testing (2018-2023) and training (1979-2017) periods. There are cold biases before and during the heat waves in both models and all seasons, except Pangu-Weather in winter, which exhibits a mean warm bias before heat wave onset. Overall, results offer encouragement that AIWP models may be useful for medium-range and S2S predictability of extreme heat. 

**Abstract (ZH)**: 极端高温是与天气相关的 deadliest 危害，在美国。此外，极端高温的强度、频率和持续时间都在增加，使得准确的预报对保护生命和财产至关重要。传统的数值天气预报（NWP）模型在中等范围和亚季节到季节尺度（S2S）上难以应对极端高温。与此同时，基于人工智能的天气预报（AIWP）模型正在迅速发展。然而，AIWP 模型对极端事件的预报能力，特别是在中等范围和 S2S 尺度上，仍然知之甚少。本研究使用两种 AIWP 模型（Google GraphCast 和 Pangu-Weather）和一个传统 NWP 模型（NOAA 统一预报系统全球集合预报系统 UFS GEFS），分析了从 0 到 20 天的四个北极季节和四个CONUS 区域内的 60 次高温事件的 2 米温度预报。研究表明，AIWP 模型和 UFS GEFS 在高温事件前 5-10 天的区域尺度上都存在一致的冷偏差。GraphCast 在大多数地点表现更为出色，优于 UFS GEFS 和 Pangu-Weather。随后，本文将两种 AIWP 模型分别在所有高温事件和季节中进行分析，并将事件分为模型测试期（2018-2023）和训练期（1979-2017）。两个模型和所有季节在高温事件前后都存在冷偏差，除了冬季的 Pangu-Weather 表现出高温前的平均暖偏差。总体而言，研究结果表明 AIWP 模型可能在中等范围和 S2S 极端高温的可预报性方面具有应用潜力。 

---
# Geolocating Earth Imagery from ISS: Integrating Machine Learning with Astronaut Photography for Enhanced Geographic Mapping 

**Title (ZH)**: 基于国际空间站的地球成像地理定位：结合宇航员摄影与机器学习的地理制图增强方法 

**Authors**: Vedika Srivastava, Hemant Kumar Singh, Jaisal Singh  

**Link**: [PDF](https://arxiv.org/pdf/2504.21194)  

**Abstract**: This paper presents a novel approach to geolocating images captured from the International Space Station (ISS) using advanced machine learning algorithms. Despite having precise ISS coordinates, the specific Earth locations depicted in astronaut-taken photographs often remain unidentified. Our research addresses this gap by employing three distinct image processing pipelines: a Neural Network based approach, a SIFT based method, and GPT-4 model. Each pipeline is tailored to process high-resolution ISS imagery, identifying both natural and man-made geographical features. Through extensive evaluation on a diverse dataset of over 140 ISS images, our methods demonstrate significant promise in automated geolocation with varied levels of success. The NN approach showed a high success rate in accurately matching geographical features, while the SIFT pipeline excelled in processing zoomed-in images. GPT-4 model provided enriched geographical descriptions alongside location predictions. This research contributes to the fields of remote sensing and Earth observation by enhancing the accuracy and efficiency of geolocating space-based imagery, thereby aiding environmental monitoring and global mapping efforts. 

**Abstract (ZH)**: 本文提出了一种使用高级机器学习算法将国际空间站（ISS）拍摄的图像进行地理定位的新方法。尽管拥有精确的ISS坐标，宇航员拍摄的图片中展示的具体地球位置往往仍未被识别。我们的研究通过采用三种不同的图像处理管道填补了这一空白：基于神经网络的方法、基于SIFT的方法以及GPT-4模型。每种管道都针对高分辨率的ISS图像进行了定制，以识别自然和人造的地理特征。通过对包含超过140张ISS图像的多样数据集进行广泛的评估，我们的方法显示出在自动地理定位方面有显著的前景，且具有不同的成功率。基于神经网络的方法在准确匹配地理特征方面表现出较高的成功率，而基于SIFT的管道在处理放大图像方面表现出色。GPT-4模型则提供了地理位置预测及丰富的地理描述。本研究为遥感和地球观测领域作出了贡献，通过提高基于空间的图像的地理定位的准确性和效率，从而辅助环境监测和全球制图工作。 

---
# Small or Large? Zero-Shot or Finetuned? Guiding Language Model Choice for Specialized Applications in Healthcare 

**Title (ZH)**: 小模型还是大模型？零样本还是微调？指导医疗健康领域专业化应用的语言模型选择 

**Authors**: Lovedeep Gondara, Jonathan Simkin, Graham Sayle, Shebnum Devji, Gregory Arbour, Raymond Ng  

**Link**: [PDF](https://arxiv.org/pdf/2504.21191)  

**Abstract**: This study aims to guide language model selection by investigating: 1) the necessity of finetuning versus zero-shot usage, 2) the benefits of domain-adjacent versus generic pretrained models, 3) the value of further domain-specific pretraining, and 4) the continued relevance of Small Language Models (SLMs) compared to Large Language Models (LLMs) for specific tasks. Using electronic pathology reports from the British Columbia Cancer Registry (BCCR), three classification scenarios with varying difficulty and data size are evaluated. Models include various SLMs and an LLM. SLMs are evaluated both zero-shot and finetuned; the LLM is evaluated zero-shot only. Finetuning significantly improved SLM performance across all scenarios compared to their zero-shot results. The zero-shot LLM outperformed zero-shot SLMs but was consistently outperformed by finetuned SLMs. Domain-adjacent SLMs generally performed better than the generic SLM after finetuning, especially on harder tasks. Further domain-specific pretraining yielded modest gains on easier tasks but significant improvements on the complex, data-scarce task. The results highlight the critical role of finetuning for SLMs in specialized domains, enabling them to surpass zero-shot LLM performance on targeted classification tasks. Pretraining on domain-adjacent or domain-specific data provides further advantages, particularly for complex problems or limited finetuning data. While LLMs offer strong zero-shot capabilities, their performance on these specific tasks did not match that of appropriately finetuned SLMs. In the era of LLMs, SLMs remain relevant and effective, offering a potentially superior performance-resource trade-off compared to LLMs. 

**Abstract (ZH)**: 本研究旨在通过探讨以下内容来指导语言模型的选择：1）微调与零样本使用之间的必要性，2）领域相邻模型与通用预训练模型的优势，3）进一步领域特定预训练的价值，以及4）小型语言模型（SLMs）与大型语言模型（LLMs）在特定任务中的持续相关性。本研究使用不列颠哥伦比亚癌症登记处（BCCR）的电子病理报告，评估了三种具有不同难度和数据量的分类场景。模型包括各种SLMs和一个LLM。SLMs在零样本和微调两种情况下进行评估；而LLM仅在零样本情况下评估。微调在所有场景中显著提高了SLMs的性能，其性能优于零样本结果。零样本LLM在零样本情况下表现优于零样本SLMs，但在大多数情况下仍然被微调的SLMs所超越。领域相邻的SLMs在微调后通常优于通用的SLMs，尤其是在较难的任务上表现更好。进一步的领域特定预训练在较简单的任务上仅带来小幅收益，在复杂的、数据稀缺的任务上则取得了显著的改进。研究结果突显了在专业化领域中对SLMs进行微调的关键作用，使其在针对性的分类任务中能够超越LLMs的零样本表现。领域相邻或领域特定数据的预训练提供了进一步的优势，尤其是在复杂的问题或有限的微调数据条件下。虽然LLMs具有强大的零样本能力，但它们在这特定任务中的表现无法与适当地微调的SLMs相匹配。在LLM的时代，SLMs依然具有相关性和有效性，提供了一种与LLMs相比可能更为优异的性能与资源权衡。 

---
# TT-LoRA MoE: Unifying Parameter-Efficient Fine-Tuning and Sparse Mixture-of-Experts 

**Title (ZH)**: TT-LoRA MoE: 统一参数高效微调和稀疏混合专家模型 

**Authors**: Pradip Kunwar, Minh N. Vu, Maanak Gupta, Mahmoud Abdelsalam, Manish Bhattarai  

**Link**: [PDF](https://arxiv.org/pdf/2504.21190)  

**Abstract**: We propose Tensor-Trained Low-Rank Adaptation Mixture of Experts (TT-LoRA MoE), a novel computational framework integrating Parameter-Efficient Fine-Tuning (PEFT) with sparse MoE routing to address scalability challenges in large model deployments. Unlike traditional MoE approaches, which face substantial computational overhead as expert counts grow, TT-LoRA MoE decomposes training into two distinct, optimized stages. First, we independently train lightweight, tensorized low-rank adapters (TT-LoRA experts), each specialized for specific tasks. Subsequently, these expert adapters remain frozen, eliminating inter-task interference and catastrophic forgetting in multi-task setting. A sparse MoE router, trained separately, dynamically leverages base model representations to select exactly one specialized adapter per input at inference time, automating expert selection without explicit task specification. Comprehensive experiments confirm our architecture retains the memory efficiency of low-rank adapters, seamlessly scales to large expert pools, and achieves robust task-level optimization. This structured decoupling significantly enhances computational efficiency and flexibility: uses only 2% of LoRA, 0.3% of Adapters and 0.03% of AdapterFusion parameters and outperforms AdapterFusion by 4 value in multi-tasking, enabling practical and scalable multi-task inference deployments. 

**Abstract (ZH)**: 张量训练低秩适应专家混合模型（TT-LoRA MoE）：一种结合参数高效微调与稀疏专家路由的新型计算框架 

---
# Artificial Intelligence for Personalized Prediction of Alzheimer's Disease Progression: A Survey of Methods, Data Challenges, and Future Directions 

**Title (ZH)**: 人工智能在阿尔茨海默病个性化进展预测中的应用：方法、数据挑战及未来方向 

**Authors**: Gulsah Hancerliogullari Koksalmis, Bulent Soykan, Laura J. Brattain, Hsin-Hsiung Huang  

**Link**: [PDF](https://arxiv.org/pdf/2504.21189)  

**Abstract**: Alzheimer's Disease (AD) is marked by significant inter-individual variability in its progression, complicating accurate prognosis and personalized care planning. This heterogeneity underscores the critical need for predictive models capable of forecasting patient-specific disease trajectories. Artificial Intelligence (AI) offers powerful tools to address this challenge by analyzing complex, multi-modal, and longitudinal patient data. This paper provides a comprehensive survey of AI methodologies applied to personalized AD progression prediction. We review key approaches including state-space models for capturing temporal dynamics, deep learning techniques like Recurrent Neural Networks for sequence modeling, Graph Neural Networks (GNNs) for leveraging network structures, and the emerging concept of AI-driven digital twins for individualized simulation. Recognizing that data limitations often impede progress, we examine common challenges such as high dimensionality, missing data, and dataset imbalance. We further discuss AI-driven mitigation strategies, with a specific focus on synthetic data generation using Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) to augment and balance datasets. The survey synthesizes the strengths and limitations of current approaches, emphasizing the trend towards multimodal integration and the persistent need for model interpretability and generalizability. Finally, we identify critical open challenges, including robust external validation, clinical integration, and ethical considerations, and outline promising future research directions such as hybrid models, causal inference, and federated learning. This review aims to consolidate current knowledge and guide future efforts in developing clinically relevant AI tools for personalized AD prognostication. 

**Abstract (ZH)**: 阿尔茨海默病（AD）的进展存在显著的个体间差异，这 complicating 了准确的预后和个性化护理计划的制定。这种异质性突显了需要开发能够预测患者特定疾病轨迹的预测模型的迫切需求。人工智能（AI）通过分析复杂的多模态和纵向患者数据提供了强有力的工具来应对这一挑战。本文提供了 AI 方法在个性化 AD 进展预测中的全面综述。我们回顾了包括状态空间模型在内的关键方法，用于捕捉时间动态；深度学习技术如循环神经网络进行序列建模；图神经网络（GNNs）用于利用网络结构；以及新兴的 AI 驱动数字孪生概念用于个性化仿真。认识到数据限制常常阻碍进展，我们探讨了诸如高维性、缺失数据和数据集不平衡等常见挑战。我们进一步讨论了通过使用变分自编码器（VAEs）和生成对抗网络（GANs）生成合成数据来驱动的 AI 算法，以扩充和平衡数据集的策略。综述总结了当前方法的优势和局限性，强调了多模态整合的趋势以及持续需要模型的可解释性和泛化性。最后，我们确定了一些关键的开放挑战，包括稳健的外部验证、临床整合和伦理考量，并概述了混合模型、因果推断和联邦学习等有前途的未来研究方向。本文旨在汇总当前知识并指导未来为个性化 AD 预后开发临床相关 AI 工具的努力。 

---
# Light Weight CNN for classification of Brain Tumors from MRI Images 

**Title (ZH)**: 轻量级CNN在 MRI 图像肿瘤分类中的应用 

**Authors**: Natnael Alemayehu  

**Link**: [PDF](https://arxiv.org/pdf/2504.21188)  

**Abstract**: This study presents a convolutional neural network (CNN)-based approach for the multi-class classification of brain tumors using magnetic resonance imaging (MRI) scans. We utilize a publicly available dataset containing MRI images categorized into four classes: glioma, meningioma, pituitary tumor, and no tumor. Our primary objective is to build a light weight deep learning model that can automatically classify brain tumor types with high accuracy. To achieve this goal, we incorporate image preprocessing steps, including normalization, data augmentation, and a cropping technique designed to reduce background noise and emphasize relevant regions. The CNN architecture is optimized through hyperparameter tuning using Keras Tuner, enabling systematic exploration of network parameters. To ensure reliable evaluation, we apply 5-fold cross-validation, where each hyperparameter configuration is evaluated across multiple data splits to mitigate overfitting. Experimental results demonstrate that the proposed model achieves a classification accuracy of 98.78%, indicating its potential as a diagnostic aid in clinical settings. The proposed method offers a low-complexity yet effective solution for assisting in early brain tumor diagnosis. 

**Abstract (ZH)**: 基于卷积神经网络的磁共振成像多类脑肿瘤分类方法 

---
# Dance Style Recognition Using Laban Movement Analysis 

**Title (ZH)**: 基于劳班运动分析的舞蹈风格识别 

**Authors**: Muhammad Turab, Philippe Colantoni, Damien Muselet, Alain Tremeau  

**Link**: [PDF](https://arxiv.org/pdf/2504.21166)  

**Abstract**: The growing interest in automated movement analysis has presented new challenges in recognition of complex human activities including dance. This study focuses on dance style recognition using features extracted using Laban Movement Analysis. Previous studies for dance style recognition often focus on cross-frame movement analysis, which limits the ability to capture temporal context and dynamic transitions between movements. This gap highlights the need for a method that can add temporal context to LMA features. For this, we introduce a novel pipeline which combines 3D pose estimation, 3D human mesh reconstruction, and floor aware body modeling to effectively extract LMA features. To address the temporal limitation, we propose a sliding window approach that captures movement evolution across time in features. These features are then used to train various machine learning methods for classification, and their explainability explainable AI methods to evaluate the contribution of each feature to classification performance. Our proposed method achieves a highest classification accuracy of 99.18\% which shows that the addition of temporal context significantly improves dance style recognition performance. 

**Abstract (ZH)**: 基于劳班运动分析的舞蹈風格識別：結合時序上下文的新型管道研究 

---
# Evaluation and Verification of Physics-Informed Neural Models of the Grad-Shafranov Equation 

**Title (ZH)**: Grad-Shafranov 方程的物理信息神经网络模型的评估与验证 

**Authors**: Fauzan Nazranda Rizqa, Matthew Hole, Charles Gretton  

**Link**: [PDF](https://arxiv.org/pdf/2504.21155)  

**Abstract**: Our contributions are motivated by fusion reactors that rely on maintaining magnetohydrodynamic (MHD) equilibrium, where the balance between plasma pressure and confining magnetic fields is required for stable operation. In axisymmetric tokamak reactors in particular, and under the assumption of toroidal symmetry, this equilibrium can be mathematically modelled using the Grad-Shafranov Equation (GSE). Recent works have demonstrated the potential of using Physics-Informed Neural Networks (PINNs) to model the GSE. Existing studies did not examine realistic scenarios in which a single network generalizes to a variety of boundary conditions. Addressing that limitation, we evaluate a PINN architecture that incorporates boundary points as network inputs. Additionally, we compare PINN model accuracy and inference speeds with a Fourier Neural Operator (FNO) model. Finding the PINN model to be the most performant, and accurate in our setting, we use the network verification tool Marabou to perform a range of verification tasks. Although we find some discrepancies between evaluations of the networks natively in PyTorch, compared to via Marabou, we are able to demonstrate useful and practical verification workflows. Our study is the first investigation of verification of such networks. 

**Abstract (ZH)**: 我们的贡献源于磁聚变反应堆对维持磁流体动力学（MHD）平衡的需求，其中等离子体压力和约束磁场所的平衡是确保稳定运行所必需的。特别是在具有托卡马克对称性的轴对称装置中，假设存在环形对称性，这种平衡可以用Grad-Shafranov方程（GSE）进行数学建模。近期研究表明，可以利用物理信息神经网络（PINNs）来建模GSE。现有研究没有考察单个网络在多种边界条件下的泛化能力。为解决这一限制，我们评估了一种将边界点作为网络输入的PINN架构。此外，我们还将PINN模型的准确性和推理速度与Fourier神经算子（FNO）模型进行了比较。由于发现PINN模型在我们的设置中表现出更好的性能和更高的准确性，我们使用了网络验证工具Marabou进行一系列验证任务。尽管我们在PyTorch中直接评估网络和通过Marabou评估之间发现了一些差异，但我们能够展示有用的、实用的验证工作流程。我们的研究是首次探讨此类网络验证的研究。 

---
# Emotion Recognition in Contemporary Dance Performances Using Laban Movement Analysis 

**Title (ZH)**: 当代舞蹈表演中基于拉班运动分析的情绪识别 

**Authors**: Muhammad Turab, Philippe Colantoni, Damien Muselet, Alain Tremeau  

**Link**: [PDF](https://arxiv.org/pdf/2504.21154)  

**Abstract**: This paper presents a novel framework for emotion recognition in contemporary dance by improving existing Laban Movement Analysis (LMA) feature descriptors and introducing robust, novel descriptors that capture both quantitative and qualitative aspects of the movement. Our approach extracts expressive characteristics from 3D keypoints data of professional dancers performing contemporary dance under various emotional states, and trains multiple classifiers, including Random Forests and Support Vector Machines. Additionally, we provide in-depth explanation of features and their impact on model predictions using explainable machine learning methods. Overall, our study improves emotion recognition in contemporary dance and offers promising applications in performance analysis, dance training, and human--computer interaction, with a highest accuracy of 96.85\%. 

**Abstract (ZH)**: 本文提出了一种改进 Laban 运动分析 (LMA) 特征描述子并引入 robust、新颖描述子以捕捉运动的定量和定性方面的新颖框架，用于当代舞的情感识别。我们的方法从处于不同情绪状态的专业舞者进行当代舞的 3D 关键点数据中提取表现性特征，并训练包括随机森林和支持向量机在内的多个分类器。此外，我们使用可解释的机器学习方法提供了特征及其对模型预测影响的深入解释。总体而言，本研究提升了当代舞的情感识别，并在表演分析、舞蹈训练和人机交互方面具有前景，最高准确率为 96.85%。 

---
# SMOGAN: Synthetic Minority Oversampling with GAN Refinement for Imbalanced Regression 

**Title (ZH)**: SMOGAN：带有GAN精炼的少数派合成过采样方法用于 imbalance 回归 

**Authors**: Shayan Alahyari, Mike Domaratzki  

**Link**: [PDF](https://arxiv.org/pdf/2504.21152)  

**Abstract**: Imbalanced regression refers to prediction tasks where the target variable is skewed. This skewness hinders machine learning models, especially neural networks, which concentrate on dense regions and therefore perform poorly on underrepresented (minority) samples. Despite the importance of this problem, only a few methods have been proposed for imbalanced regression. Many of the available solutions for imbalanced regression adapt techniques from the class imbalance domain, such as linear interpolation and the addition of Gaussian noise, to create synthetic data in sparse regions. However, in many cases, the underlying distribution of the data is complex and non-linear. Consequently, these approaches generate synthetic samples that do not accurately represent the true feature-target relationship. To overcome these limitations, we propose SMOGAN, a two-step oversampling framework for imbalanced regression. In Stage 1, an existing oversampler generates initial synthetic samples in sparse target regions. In Stage 2, we introduce DistGAN, a distribution-aware GAN that serves as SMOGAN's filtering layer and refines these samples via adversarial loss augmented with a Maximum Mean Discrepancy objective, aligning them with the true joint feature-target distribution. Extensive experiments on 23 imbalanced datasets show that SMOGAN consistently outperforms the default oversampling method without the DistGAN filtering layer. 

**Abstract (ZH)**: 不平衡回归是指目标变量分布偏斜的预测任务。这种偏斜阻碍了机器学习模型，尤其是神经网络，这些模型倾向于关注密集区域，因此在少数样本上表现不佳。尽管这个问题很重要，但仅提出了一小部分方法来处理不平衡回归问题。许多现有的不平衡回归解决方案将类不平衡领域的技术（如线性插值和高斯噪声添加）适应为生成稀疏区域的合成数据。然而，在许多情况下，数据的真实分布是复杂且非线性的。因此，这些方法生成的合成样本并不能准确地代表真实特征-目标关系。为了克服这些局限性，我们提出了SMOGAN，一种两阶段的过采样框架，用于不平衡回归。在第一阶段，一个现有的过采样器生成初始的合成样本，以填补目标变量稀疏区域。在第二阶段，我们引入了DistGAN，这是一种分布感知的GAN，作为SMOGAN的过滤层，并通过对抗损失以及最大均值偏差目标进行优化，以校准这些样本，并使其与真实特征-目标联合分布一致。在23个不平衡数据集上的广泛实验表明，与未包含DistGAN过滤层的默认过采样方法相比，SMOGAN始终表现出更优的性能。 

---
# A Survey on Parameter-Efficient Fine-Tuning for Foundation Models in Federated Learning 

**Title (ZH)**: 联邦学习中基础模型参数高效微调综述 

**Authors**: Jieming Bian, Yuanzhe Peng, Lei Wang, Yin Huang, Jie Xu  

**Link**: [PDF](https://arxiv.org/pdf/2504.21099)  

**Abstract**: Foundation models have revolutionized artificial intelligence by providing robust, versatile architectures pre-trained on large-scale datasets. However, adapting these massive models to specific downstream tasks requires fine-tuning, which can be prohibitively expensive in computational resources. Parameter-Efficient Fine-Tuning (PEFT) methods address this challenge by selectively updating only a small subset of parameters. Meanwhile, Federated Learning (FL) enables collaborative model training across distributed clients without sharing raw data, making it ideal for privacy-sensitive applications. This survey provides a comprehensive review of the integration of PEFT techniques within federated learning environments. We systematically categorize existing approaches into three main groups: Additive PEFT (which introduces new trainable parameters), Selective PEFT (which fine-tunes only subsets of existing parameters), and Reparameterized PEFT (which transforms model architectures to enable efficient updates). For each category, we analyze how these methods address the unique challenges of federated settings, including data heterogeneity, communication efficiency, computational constraints, and privacy concerns. We further organize the literature based on application domains, covering both natural language processing and computer vision tasks. Finally, we discuss promising research directions, including scaling to larger foundation models, theoretical analysis of federated PEFT methods, and sustainable approaches for resource-constrained environments. 

**Abstract (ZH)**: 基于参数高效微调的联邦学习综述：挑战与进展 

---
# On the Potential of Large Language Models to Solve Semantics-Aware Process Mining Tasks 

**Title (ZH)**: 大型语言模型在解决语义感知的过程挖掘任务方面的潜力 

**Authors**: Adrian Rebmann, Fabian David Schmidt, Goran Glavaš, Han van der Aa  

**Link**: [PDF](https://arxiv.org/pdf/2504.21074)  

**Abstract**: Large language models (LLMs) have shown to be valuable tools for tackling process mining tasks. Existing studies report on their capability to support various data-driven process analyses and even, to some extent, that they are able to reason about how processes work. This reasoning ability suggests that there is potential for LLMs to tackle semantics-aware process mining tasks, which are tasks that rely on an understanding of the meaning of activities and their relationships. Examples of these include process discovery, where the meaning of activities can indicate their dependency, whereas in anomaly detection the meaning can be used to recognize process behavior that is abnormal. In this paper, we systematically explore the capabilities of LLMs for such tasks. Unlike prior work, which largely evaluates LLMs in their default state, we investigate their utility through both in-context learning and supervised fine-tuning. Concretely, we define five process mining tasks requiring semantic understanding and provide extensive benchmarking datasets for evaluation. Our experiments reveal that while LLMs struggle with challenging process mining tasks when used out of the box or with minimal in-context examples, they achieve strong performance when fine-tuned for these tasks across a broad range of process types and industries. 

**Abstract (ZH)**: 大型语言模型（LLMs）在处理过程挖掘任务中的应用研究表明，它们能够支持各种数据驱动的过程分析，并在一定程度上能够推理过程的工作机制。这种推理能力表明，大型语言模型有可能承担起具备语义意识的过程挖掘任务，即依赖于活动意义及其关系理解的任务。这些任务包括过程发现，其中活动的意义可能表明它们之间的依赖性，而在异常检测中，这种意义可用于识别异常的过程行为。在本文中，我们系统地探讨了大型语言模型在这些任务中的能力。与先前主要评估模型在默认状态下能力的研究不同，我们通过上下文学习和监督微调来探究它们的应用价值。具体来说，我们定义了五个需要语义理解的过程挖掘任务，并提供了广泛基准数据集进行评估。我们的实验证明，虽然大型语言模型在空白或仅提供少量上下文示例的情况下处理具有挑战性的过程挖掘任务时表现不佳，但在针对这些任务进行广泛类型和行业的微调后，它们能够实现强大的性能。 

---
# Erased but Not Forgotten: How Backdoors Compromise Concept Erasure 

**Title (ZH)**: 被擦除但未被遗忘：后门如何破坏概念擦除 

**Authors**: Jonas Henry Grebe, Tobias Braun, Marcus Rohrbach, Anna Rohrbach  

**Link**: [PDF](https://arxiv.org/pdf/2504.21072)  

**Abstract**: The expansion of large-scale text-to-image diffusion models has raised growing concerns about their potential to generate undesirable or harmful content, ranging from fabricated depictions of public figures to sexually explicit images. To mitigate these risks, prior work has devised machine unlearning techniques that attempt to erase unwanted concepts through fine-tuning. However, in this paper, we introduce a new threat model, Toxic Erasure (ToxE), and demonstrate how recent unlearning algorithms, including those explicitly designed for robustness, can be circumvented through targeted backdoor attacks. The threat is realized by establishing a link between a trigger and the undesired content. Subsequent unlearning attempts fail to erase this link, allowing adversaries to produce harmful content. We instantiate ToxE via two established backdoor attacks: one targeting the text encoder and another manipulating the cross-attention layers. Further, we introduce Deep Intervention Score-based Attack (DISA), a novel, deeper backdoor attack that optimizes the entire U-Net using a score-based objective, improving the attack's persistence across different erasure methods. We evaluate five recent concept erasure methods against our threat model. For celebrity identity erasure, our deep attack circumvents erasure with up to 82% success, averaging 57% across all erasure methods. For explicit content erasure, ToxE attacks can elicit up to 9 times more exposed body parts, with DISA yielding an average increase by a factor of 2.9. These results highlight a critical security gap in current unlearning strategies. 

**Abstract (ZH)**: 有毒擦除：对抗性回门攻击在大规模文本生成图像模型中的威胁 

---
# A Brief Review for Compression and Transfer Learning Techniques in DeepFake Detection 

**Title (ZH)**: 压缩与迁移学习技术在DeepFake检测中的 briefly回顾 

**Authors**: Andreas Karathanasis, John Violos, Ioannis Kompatsiaris, Symeon Papadopoulos  

**Link**: [PDF](https://arxiv.org/pdf/2504.21066)  

**Abstract**: Training and deploying deepfake detection models on edge devices offers the advantage of maintaining data privacy and confidentiality by processing it close to its source. However, this approach is constrained by the limited computational and memory resources available at the edge. To address this challenge, we explore compression techniques to reduce computational demands and inference time, alongside transfer learning methods to minimize training overhead. Using the Synthbuster, RAISE, and ForenSynths datasets, we evaluate the effectiveness of pruning, knowledge distillation (KD), quantization, fine-tuning, and adapter-based techniques. Our experimental results demonstrate that both compression and transfer learning can be effectively achieved, even with a high compression level of 90%, remaining at the same performance level when the training and validation data originate from the same DeepFake model. However, when the testing dataset is generated by DeepFake models not present in the training set, a domain generalization issue becomes evident. 

**Abstract (ZH)**: 在边缘设备上训练和部署深度假脸检测模型的优势在于通过靠近数据源进行处理来维护数据隐私和保密性。然而，这种方法受限于边缘设备上可用的有限计算和内存资源。为了解决这一挑战，我们探索了压缩技术以减少计算需求和推断时间，并结合迁移学习方法以最小化训练开销。使用Synthbuster、RAISE和ForenSynths数据集，我们评估了剪枝、知识蒸馏（KD）、量化、微调和基于适配器的技术的有效性。实验结果表明，即使在90%的高压缩水平下，压缩和迁移学习也能有效地实现，并且在训练和验证数据来自同一深度假脸模型的情况下保持相同性能水平。然而，当测试数据集由不在训练集中出现的深度假脸模型生成时，会出现领域泛化问题。 

---
# A 3D pocket-aware and affinity-guided diffusion model for lead optimization 

**Title (ZH)**: 基于口袋意识和亲和力引导的三维扩散模型用于先导优化 

**Authors**: Anjie Qiao, Junjie Xie, Weifeng Huang, Hao Zhang, Jiahua Rao, Shuangjia Zheng, Yuedong Yang, Zhen Wang, Guo-Bo Li, Jinping Lei  

**Link**: [PDF](https://arxiv.org/pdf/2504.21065)  

**Abstract**: Molecular optimization, aimed at improving binding affinity or other molecular properties, is a crucial task in drug discovery that often relies on the expertise of medicinal chemists. Recently, deep learning-based 3D generative models showed promise in enhancing the efficiency of molecular optimization. However, these models often struggle to adequately consider binding affinities with protein targets during lead optimization. Herein, we propose a 3D pocket-aware and affinity-guided diffusion model, named Diffleop, to optimize molecules with enhanced binding affinity. The model explicitly incorporates the knowledge of protein-ligand binding affinity to guide the denoising sampling for molecule generation with high affinity. The comprehensive evaluations indicated that Diffleop outperforms baseline models across multiple metrics, especially in terms of binding affinity. 

**Abstract (ZH)**: 基于3D口袋意识和亲和力导向的扩散模型Diffleop优化具有增强亲和力的分子 

---
# Frequency Feature Fusion Graph Network For Depression Diagnosis Via fNIRS 

**Title (ZH)**: 基于fNIRS的抑郁症诊断的频率特征融合图网络 

**Authors**: Chengkai Yang, Xingping Dong, Xiaofen Zong  

**Link**: [PDF](https://arxiv.org/pdf/2504.21064)  

**Abstract**: Data-driven approaches for depression diagnosis have emerged as a significant research focus in neuromedicine, driven by the development of relevant datasets. Recently, graph neural network (GNN)-based models have gained widespread adoption due to their ability to capture brain channel functional connectivity from both spatial and temporal perspectives. However, their effectiveness is hindered by the absence of a robust temporal biomarker. In this paper, we introduce a novel and effective biomarker for depression diagnosis by leveraging the discrete Fourier transform (DFT) and propose a customized graph network architecture based on Temporal Graph Convolutional Network (TGCN). Our model was trained on a dataset comprising 1,086 subjects, which is over 10 times larger than previous datasets in the field of depression diagnosis. Furthermore, to align with medical requirements, we performed propensity score matching (PSM) to create a refined subset, referred to as the PSM dataset. Experimental results demonstrate that incorporating our newly designed biomarker enhances the representation of temporal characteristics in brain channels, leading to improved F1 scores in both the real-world dataset and the PSM dataset. This advancement has the potential to contribute to the development of more effective depression diagnostic tools. In addition, we used SHapley Additive exPlaination (SHAP) to validate the interpretability of our model, ensuring its practical applicability in medical settings. 

**Abstract (ZH)**: 基于数据驱动的方法在神经医学中用于抑郁症诊断的研究进展：利用离散傅里叶变换和定制化时间图卷积网络的新型生物标志器及其应用 

---
# Token-Level Prompt Mixture with Parameter-Free Routing for Federated Domain Generalization 

**Title (ZH)**: 基于token级提示混合的无参路由联邦领域泛化 

**Authors**: Shuai Gong, Chaoran Cui, Xiaolin Dong, Xiushan Nie, Lei Zhu, Xiaojun Chang  

**Link**: [PDF](https://arxiv.org/pdf/2504.21063)  

**Abstract**: Federated domain generalization (FedDG) aims to learn a globally generalizable model from decentralized clients with heterogeneous data while preserving privacy. Recent studies have introduced prompt learning to adapt vision-language models (VLMs) in FedDG by learning a single global prompt. However, such a one-prompt-fits-all learning paradigm typically leads to performance degradation on personalized samples. Although the mixture of experts (MoE) offers a promising solution for specialization, existing MoE-based methods suffer from coarse image-level expert assignment and high communication costs from parameterized routers. To address these limitations, we propose TRIP, a Token-level prompt mixture with parameter-free routing framework for FedDG, which treats multiple prompts as distinct experts. Unlike existing image-level routing designs, TRIP assigns different tokens within an image to specific experts. To ensure communication efficiency, TRIP incorporates a parameter-free routing mechanism based on token clustering and optimal transport. The instance-specific prompt is then synthesized by aggregating experts, weighted by the number of tokens assigned to each. Additionally, TRIP develops an unbiased learning strategy for prompt experts, leveraging the VLM's zero-shot generalization capability. Extensive experiments across four benchmarks demonstrate that TRIP achieves optimal generalization results, with communication of only 1K parameters per round. Our code is available at this https URL. 

**Abstract (ZH)**: 联邦领域泛化（FedDG）的目标是以分散式客户端和异质数据为基础学习一个全局泛化模型，同时保护隐私。最近的研究通过学习单一全局提示将提示学习引入到了FedDG中，以适应视觉语言模型（VLMs）。然而，这种单一提示适应所有样本的学习范式通常会导致个性化样本性能下降。虽然专家组合（MoE）提供了专业知识化的一种有前景的解决方案，但现有的基于MoE的方法由于粗粒度的图像级专家分配和参数化路由器带来的高通信成本而受到限制。为了解决这些限制，我们提出了TRIP，即一个基于标记级别的提示组合与无参数路由框架，将多个提示视作不同的专家。与现有的图像级路由设计不同，TRIP 将图像内的不同标记分配给特定的专家。为了确保通信效率，TRIP 结合了基于标记聚类和最优传输的无参数路由机制。通过根据分配给每个专家的标记数量进行加权，合成特定实例的提示。此外，TRIP 开发了一种利用VLM零样本泛化能力的无偏学习策略。在四个基准系统的广泛实验中，TRIP 获得了最优泛化结果，每次通信仅需要传递1K参数。我们的代码可在以下链接获取。 

---
# Modeling and Performance Analysis for Semantic Communications Based on Empirical Results 

**Title (ZH)**: 基于经验结果的语义通信建模与性能分析 

**Authors**: Shuai Ma, Bin Shen, Chuanhui Zhang, Youlong Wu, Hang Li, Shiyin Li, Guangming Shi, Naofal Al-Dhahir  

**Link**: [PDF](https://arxiv.org/pdf/2504.21055)  

**Abstract**: Due to the black-box characteristics of deep learning based semantic encoders and decoders, finding a tractable method for the performance analysis of semantic communications is a challenging problem. In this paper, we propose an Alpha-Beta-Gamma (ABG) formula to model the relationship between the end-to-end measurement and SNR, which can be applied for both image reconstruction tasks and inference tasks. Specifically, for image reconstruction tasks, the proposed ABG formula can well fit the commonly used DL networks, such as SCUNet, and Vision Transformer, for semantic encoding with the multi scale-structural similarity index measure (MS-SSIM) measurement. Furthermore, we find that the upper bound of the MS-SSIM depends on the number of quantized output bits of semantic encoders, and we also propose a closed-form expression to fit the relationship between the MS-SSIM and quantized output bits. To the best of our knowledge, this is the first theoretical expression between end-to-end performance metrics and SNR for semantic communications. Based on the proposed ABG formula, we investigate an adaptive power control scheme for semantic communications over random fading channels, which can effectively guarantee quality of service (QoS) for semantic communications, and then design the optimal power allocation scheme to maximize the energy efficiency of the semantic communication system. Furthermore, by exploiting the bisection algorithm, we develop the power allocation scheme to maximize the minimum QoS of multiple users for OFDMA downlink semantic communication Extensive simulations verify the effectiveness and superiority of the proposed ABG formula and power allocation schemes. 

**Abstract (ZH)**: 基于深度学习的语义编码器和解码器的黑箱特性，对语义通信性能分析的可溯性方法是一个具挑战性的问题。本文提出了一种Alpha-Beta-Gamma (ABG) 公式来建模端到端测量与信噪比之间的关系，该公式适用于图像重构任务和推理任务。具体而言，在图像重构任务中，所提出的ABG公式可以很好地拟合常用的DL网络，如SCUNet和Vision Transformer，并使用多尺度结构相似性指数度量（MS-SSIM）。此外，我们发现MS-SSIM的上界取决于语义编码器的量化输出位数，并提出了一种闭式表达式来拟合MS-SSIM与量化输出位数之间的关系。据我们所知，这是首次在语义通信中理论表达端到端性能指标与信噪比之间的关系。基于所提出的ABG公式，研究了随机衰落信道中语义通信的自适应功率控制方案，可以有效保证语义通信的质量服务（QoS），并设计了优化功率分配方案以最大化语义通信系统的能量效率。此外，通过利用二分算法，开发了多用户OFDMA下行语义通信中同时最大化最小QoS的功率分配方案。广泛的仿真验证了所提ABG公式和功率分配方案的有效性和优越性。 

---
# FFCBA: Feature-based Full-target Clean-label Backdoor Attacks 

**Title (ZH)**: FFCBA：基于特征的全目标干净标签后门攻击 

**Authors**: Yangxu Yin, Honglong Chen, Yudong Gao, Peng Sun, Liantao Wu, Zhe Li, Weifeng Liu  

**Link**: [PDF](https://arxiv.org/pdf/2504.21054)  

**Abstract**: Backdoor attacks pose a significant threat to deep neural networks, as backdoored models would misclassify poisoned samples with specific triggers into target classes while maintaining normal performance on clean samples. Among these, multi-target backdoor attacks can simultaneously target multiple classes. However, existing multi-target backdoor attacks all follow the dirty-label paradigm, where poisoned samples are mislabeled, and most of them require an extremely high poisoning rate. This makes them easily detectable by manual inspection. In contrast, clean-label attacks are more stealthy, as they avoid modifying the labels of poisoned samples. However, they generally struggle to achieve stable and satisfactory attack performance and often fail to scale effectively to multi-target attacks. To address this issue, we propose the Feature-based Full-target Clean-label Backdoor Attacks (FFCBA) which consists of two paradigms: Feature-Spanning Backdoor Attacks (FSBA) and Feature-Migrating Backdoor Attacks (FMBA). FSBA leverages class-conditional autoencoders to generate noise triggers that align perturbed in-class samples with the original category's features, ensuring the effectiveness, intra-class consistency, inter-class specificity and natural-feature correlation of triggers. While FSBA supports swift and efficient attacks, its cross-model attack capability is relatively weak. FMBA employs a two-stage class-conditional autoencoder training process that alternates between using out-of-class samples and in-class samples. This allows FMBA to generate triggers with strong target-class features, making it highly effective for cross-model attacks. We conduct experiments on multiple datasets and models, the results show that FFCBA achieves outstanding attack performance and maintains desirable robustness against the state-of-the-art backdoor defenses. 

**Abstract (ZH)**: 基于特征的全目标清洁标签后门攻击（FFCBA） 

---
# NeuRel-Attack: Neuron Relearning for Safety Disalignment in Large Language Models 

**Title (ZH)**: NeuRel-攻击：大规模语言模型中安全性偏差的神经元重学习 

**Authors**: Yi Zhou, Wenpeng Xing, Dezhang Kong, Changting Lin, Meng Han  

**Link**: [PDF](https://arxiv.org/pdf/2504.21053)  

**Abstract**: Safety alignment in large language models (LLMs) is achieved through fine-tuning mechanisms that regulate neuron activations to suppress harmful content. In this work, we propose a novel approach to induce disalignment by identifying and modifying the neurons responsible for safety constraints. Our method consists of three key steps: Neuron Activation Analysis, where we examine activation patterns in response to harmful and harmless prompts to detect neurons that are critical for distinguishing between harmful and harmless inputs; Similarity-Based Neuron Identification, which systematically locates the neurons responsible for safe alignment; and Neuron Relearning for Safety Removal, where we fine-tune these selected neurons to restore the model's ability to generate previously restricted responses. Experimental results demonstrate that our method effectively removes safety constraints with minimal fine-tuning, highlighting a critical vulnerability in current alignment techniques. Our findings underscore the need for robust defenses against adversarial fine-tuning attacks on LLMs. 

**Abstract (ZH)**: 大型语言模型的安全对齐通过调优机制调节神经元激活以抑制有害内容实现。在本工作中，我们提出了一种新的方法来诱导不对齐，通过识别和修改负责安全约束的神经元。该方法包括三个关键步骤：神经元激活分析，其中我们检查有害和无害提示的激活模式以检测对于区分有害和无害输入至关重要的神经元；基于相似性的神经元识别，系统地定位负责安全对齐的神经元；神经元重新学习以去除安全性约束，其中我们调优这些选定的神经元以恢复模型生成之前受限响应的能力。实验结果表明，我们的方法能够通过最小的调优有效去除安全性约束，突显了当前对齐技术中的一个关键漏洞。我们的发现强调了抵御针对大型语言模型的对抗调优攻击的稳健防御措施的需求。 

---
# SFIBA: Spatial-based Full-target Invisible Backdoor Attacks 

**Title (ZH)**: 基于空间的全目标隐形后门攻击 

**Authors**: Yangxu Yin, Honglong Chen, Yudong Gao, Peng Sun, Zhishuai Li, Weifeng Liu  

**Link**: [PDF](https://arxiv.org/pdf/2504.21052)  

**Abstract**: Multi-target backdoor attacks pose significant security threats to deep neural networks, as they can preset multiple target classes through a single backdoor injection. This allows attackers to control the model to misclassify poisoned samples with triggers into any desired target class during inference, exhibiting superior attack performance compared with conventional backdoor attacks. However, existing multi-target backdoor attacks fail to guarantee trigger specificity and stealthiness in black-box settings, resulting in two main issues. First, they are unable to simultaneously target all classes when only training data can be manipulated, limiting their effectiveness in realistic attack scenarios. Second, the triggers often lack visual imperceptibility, making poisoned samples easy to detect. To address these problems, we propose a Spatial-based Full-target Invisible Backdoor Attack, called SFIBA. It restricts triggers for different classes to specific local spatial regions and morphologies in the pixel space to ensure specificity, while employing a frequency-domain-based trigger injection method to guarantee stealthiness. Specifically, for injection of each trigger, we first apply fast fourier transform to obtain the amplitude spectrum of clean samples in local spatial regions. Then, we employ discrete wavelet transform to extract the features from the amplitude spectrum and use singular value decomposition to integrate the trigger. Subsequently, we selectively filter parts of the trigger in pixel space to implement trigger morphology constraints and adjust injection coefficients based on visual effects. We conduct experiments on multiple datasets and models. The results demonstrate that SFIBA can achieve excellent attack performance and stealthiness, while preserving the model's performance on benign samples, and can also bypass existing backdoor defenses. 

**Abstract (ZH)**: 基于空间的全目标隐形后门攻击：SFIBA 

---
# Phishing URL Detection using Bi-LSTM 

**Title (ZH)**: 使用双向LSTM检测钓鱼URL 

**Authors**: Sneha Baskota  

**Link**: [PDF](https://arxiv.org/pdf/2504.21049)  

**Abstract**: Phishing attacks threaten online users, often leading to data breaches, financial losses, and identity theft. Traditional phishing detection systems struggle with high false positive rates and are usually limited by the types of attacks they can identify. This paper proposes a deep learning-based approach using a Bidirectional Long Short-Term Memory (Bi-LSTM) network to classify URLs into four categories: benign, phishing, defacement, and malware. The model leverages sequential URL data and captures contextual information, improving the accuracy of phishing detection. Experimental results on a dataset comprising over 650,000 URLs demonstrate the model's effectiveness, achieving 97% accuracy and significant improvements over traditional techniques. 

**Abstract (ZH)**: 基于双向长短期记忆网络的深度学习方法用于URL分类及钓鱼攻击检测 

---
# Multi-Agent Reinforcement Learning for Resources Allocation Optimization: A Survey 

**Title (ZH)**: 多代理 reinforcement 学习在资源分配优化中的应用：一个综述 

**Authors**: Mohamad A. Hady, Siyi Hu, Mahardhika Pratama, Jimmy Cao, Ryszard Kowalczyk  

**Link**: [PDF](https://arxiv.org/pdf/2504.21048)  

**Abstract**: Multi-Agent Reinforcement Learning (MARL) has become a powerful framework for numerous real-world applications, modeling distributed decision-making and learning from interactions with complex environments. Resource Allocation Optimization (RAO) benefits significantly from MARL's ability to tackle dynamic and decentralized contexts. MARL-based approaches are increasingly applied to RAO challenges across sectors playing pivotal roles to Industry 4.0 developments. This survey provides a comprehensive review of recent MARL algorithms for RAO, encompassing core concepts, classifications, and a structured taxonomy. By outlining the current research landscape and identifying primary challenges and future directions, this survey aims to support researchers and practitioners in leveraging MARL's potential to advance resource allocation solutions. 

**Abstract (ZH)**: 基于多代理强化学习的资源分配优化：综述 

---
# Model Connectomes: A Generational Approach to Data-Efficient Language Models 

**Title (ZH)**: 代际模型连接组：一种数据高效的语言模型方法 

**Authors**: Klemen Kotar, Greta Tuckute  

**Link**: [PDF](https://arxiv.org/pdf/2504.21047)  

**Abstract**: Biological neural networks are shaped both by evolution across generations and by individual learning within an organism's lifetime, whereas standard artificial neural networks undergo a single, large training procedure without inherited constraints. In this preliminary work, we propose a framework that incorporates this crucial generational dimension - an "outer loop" of evolution that shapes the "inner loop" of learning - so that artificial networks better mirror the effects of evolution and individual learning in biological organisms. Focusing on language, we train a model that inherits a "model connectome" from the outer evolution loop before exposing it to a developmental-scale corpus of 100M tokens. Compared with two closely matched control models, we show that the connectome model performs better or on par on natural language processing tasks as well as alignment to human behavior and brain data. These findings suggest that a model connectome serves as an efficient prior for learning in low-data regimes - narrowing the gap between single-generation artificial models and biologically evolved neural networks. 

**Abstract (ZH)**: 生物神经网络由世代间的进化和个体生命期内的学习共同塑造，而标准人工神经网络则通过一次性大规模训练过程进行训练，不包含继承性的约束。在本初步研究中，我们提出了一种框架，该框架将这一关键的世代维度纳入其中——外部进化的“外环”塑造内部学习的“内环”——从而使人工网络更好地模拟生物体中进化和个体学习的影响。我们重点关注语言方面，训练了一个从外环进化过程继承“模型连接组”的模型，并将其暴露给一个包含1亿个标记的发育规模语料库。与两个匹配的控制模型相比，我们表明，具有连接组的模型在自然语言处理任务以及与人类行为和脑数据的对齐方面表现更好或相当。这些发现表明，模型连接组在数据量有限的情况下充当高效先验，缩小了单代人工模型与生物进化神经网络之间的差距。 

---
# Leveraging LLM to Strengthen ML-Based Cross-Site Scripting Detection 

**Title (ZH)**: 利用大规模语言模型强化基于机器学习的跨站点脚本检测 

**Authors**: Dennis Miczek, Divyesh Gabbireddy, Suman Saha  

**Link**: [PDF](https://arxiv.org/pdf/2504.21045)  

**Abstract**: According to the Open Web Application Security Project (OWASP), Cross-Site Scripting (XSS) is a critical security vulnerability. Despite decades of research, XSS remains among the top 10 security vulnerabilities. Researchers have proposed various techniques to protect systems from XSS attacks, with machine learning (ML) being one of the most widely used methods. An ML model is trained on a dataset to identify potential XSS threats, making its effectiveness highly dependent on the size and diversity of the training data. A variation of XSS is obfuscated XSS, where attackers apply obfuscation techniques to alter the code's structure, making it challenging for security systems to detect its malicious intent. Our study's random forest model was trained on traditional (non-obfuscated) XSS data achieved 99.8% accuracy. However, when tested against obfuscated XSS samples, accuracy dropped to 81.9%, underscoring the importance of training ML models with obfuscated data to improve their effectiveness in detecting XSS attacks. A significant challenge is to generate highly complex obfuscated code despite the availability of several public tools. These tools can only produce obfuscation up to certain levels of complexity.
In our proposed system, we fine-tune a Large Language Model (LLM) to generate complex obfuscated XSS payloads automatically. By transforming original XSS samples into diverse obfuscated variants, we create challenging training data for ML model evaluation. Our approach achieved a 99.5% accuracy rate with the obfuscated dataset. We also found that the obfuscated samples generated by the LLMs were 28.1% more complex than those created by other tools, significantly improving the model's ability to handle advanced XSS attacks and making it more effective for real-world application security. 

**Abstract (ZH)**: 根据Open Web Application Security Project (OWASP) 的定义，跨站脚本攻击（XSS）是一种关键的安全漏洞。尽管经过了几十年的研究，XSS 仍然是最常出现的十大安全漏洞之一。研究人员提出多种技术来保护系统免受XSS攻击，其中机器学习（ML）是最常用的方法之一。一个ML模型通过训练数据集来识别潜在的XSS威胁，其效果高度依赖于训练数据集的大小和多样性。XSS的一种变体是混淆XSS，攻击者通过应用混淆技术改变代码结构，从而给安全系统带来检测其恶意意图的挑战。我们的研究中，针对传统（未混淆）XSS数据训练的随机森林模型准确率达到99.8%。然而，在针对混淆XSS样本进行测试时，准确率下降到81.9%，强调了使用混解决策树模型训练数据的重要性，以提高其检测XSS攻击的效果。生成高度复杂的混淆代码是一个重大挑战，尽管有一些公开的工具可供使用，但这些工具只能生成一定程度复杂性的混淆。在我们提出的研究系统中，我们微调了一个大型语言模型（LLM）来自动生成复杂的混淆XSS载荷。通过将原始XSS样本转换为多种多样的混淆变体，我们为ML模型评估创造了具有挑战性的训练数据。我们的方法在混淆数据集上的准确率达到99.5%。此外，我们发现，由LLM生成的混淆样本比其他工具生成的更为复杂，复杂度高出28.1%，显著提高了模型处理高级XSS攻击的能力，并使其更适用于真实世界的应用安全。 

---
# AGATE: Stealthy Black-box Watermarking for Multimodal Model Copyright Protection 

**Title (ZH)**: AGATE：多模态模型版权保护的隐蔽黑盒水印方案 

**Authors**: Jianbo Gao, Keke Gai, Jing Yu, Liehuang Zhu, Qi Wu  

**Link**: [PDF](https://arxiv.org/pdf/2504.21044)  

**Abstract**: Recent advancement in large-scale Artificial Intelligence (AI) models offering multimodal services have become foundational in AI systems, making them prime targets for model theft. Existing methods select Out-of-Distribution (OoD) data as backdoor watermarks and retrain the original model for copyright protection. However, existing methods are susceptible to malicious detection and forgery by adversaries, resulting in watermark evasion. In this work, we propose Model-\underline{ag}nostic Black-box Backdoor W\underline{ate}rmarking Framework (AGATE) to address stealthiness and robustness challenges in multimodal model copyright protection. Specifically, we propose an adversarial trigger generation method to generate stealthy adversarial triggers from ordinary dataset, providing visual fidelity while inducing semantic shifts. To alleviate the issue of anomaly detection among model outputs, we propose a post-transform module to correct the model output by narrowing the distance between adversarial trigger image embedding and text embedding. Subsequently, a two-phase watermark verification is proposed to judge whether the current model infringes by comparing the two results with and without the transform module. Consequently, we consistently outperform state-of-the-art methods across five datasets in the downstream tasks of multimodal image-text retrieval and image classification. Additionally, we validated the robustness of AGATE under two adversarial attack scenarios. 

**Abstract (ZH)**: Recent进展在大规模多模态人工智能模型的黑盒后门水印保护框架（AGATE） 

---
# CodeBC: A More Secure Large Language Model for Smart Contract Code Generation in Blockchain 

**Title (ZH)**: CodeBC：面向区块链智能合约代码生成的更安全大型语言模型 

**Authors**: Lingxiang wang, Hainan Zhang, Qinnan Zhang, Ziwei Wang, Hongwei Zheng, Jin Dong, Zhiming Zheng  

**Link**: [PDF](https://arxiv.org/pdf/2504.21043)  

**Abstract**: Large language models (LLMs) excel at generating code from natural language instructions, yet they often lack an understanding of security vulnerabilities. This limitation makes it difficult for LLMs to avoid security risks in generated code, particularly in high-security programming tasks such as smart contract development for blockchain. Researchers have attempted to enhance the vulnerability awareness of these models by training them to differentiate between vulnerable and fixed code snippets. However, this approach relies heavily on manually labeled vulnerability data, which is only available for popular languages like Python and C++. For low-resource languages like Solidity, used in smart contracts, large-scale annotated datasets are scarce and difficult to obtain. To address this challenge, we introduce CodeBC, a code generation model specifically designed for generating secure smart contracts in blockchain. CodeBC employs a three-stage fine-tuning approach based on CodeLlama, distinguishing itself from previous methods by not relying on pairwise vulnerability location annotations. Instead, it leverages vulnerability and security tags to teach the model the differences between vulnerable and secure code. During the inference phase, the model leverages security tags to generate secure and robust code. Experimental results demonstrate that CodeBC outperforms baseline models in terms of BLEU, CodeBLEU, and compilation pass rates, while significantly reducing vulnerability rates. These findings validate the effectiveness and cost-efficiency of our three-stage fine-tuning strategy, making CodeBC a promising solution for generating secure smart contract code. 

**Abstract (ZH)**: 一种专门用于生成区块链安全智能合约的代码生成模型：CodeBC 

---
# What's Pulling the Strings? Evaluating Integrity and Attribution in AI Training and Inference through Concept Shift 

**Title (ZH)**: 什么是操控背后的因素？通过概念偏移评估AI训练和推理中的完整性与归属问题 

**Authors**: Jiamin Chang, Haoyang Li, Hammond Pearce, Ruoxi Sun, Bo Li, Minhui Xue  

**Link**: [PDF](https://arxiv.org/pdf/2504.21042)  

**Abstract**: The growing adoption of artificial intelligence (AI) has amplified concerns about trustworthiness, including integrity, privacy, robustness, and bias. To assess and attribute these threats, we propose ConceptLens, a generic framework that leverages pre-trained multimodal models to identify the root causes of integrity threats by analyzing Concept Shift in probing samples. ConceptLens demonstrates strong detection performance for vanilla data poisoning attacks and uncovers vulnerabilities to bias injection, such as the generation of covert advertisements through malicious concept shifts. It identifies privacy risks in unaltered but high-risk samples, filters them before training, and provides insights into model weaknesses arising from incomplete or imbalanced training data. Additionally, at the model level, it attributes concepts that the target model is overly dependent on, identifies misleading concepts, and explains how disrupting key concepts negatively impacts the model. Furthermore, it uncovers sociological biases in generative content, revealing disparities across sociological contexts. Strikingly, ConceptLens reveals how safe training and inference data can be unintentionally and easily exploited, potentially undermining safety alignment. Our study informs actionable insights to breed trust in AI systems, thereby speeding adoption and driving greater innovation. 

**Abstract (ZH)**: 人工智能（AI） adoption 的增长加剧了对可信性、完整性和隐私等方面的担忧，包括稳健性与偏见问题。为了评估和归因这些威胁，我们提出 ConceptLens，这是一种通用框架，利用预训练的多模态模型通过分析探测样本中的概念偏移来识别完整性的根本原因。ConceptLens 在检测简约型数据中毒攻击方面表现出强大的性能，并揭示了偏见注入的脆弱性，例如通过恶意概念偏移生成隐蔽广告。它识别未经修改但高风险的隐私风险样本，在训练前进行过滤，并提供由于不完整或不平衡的训练数据引发的模型弱点见解。此外，在模型级别，它归因目标模型过度依赖的概念，识别误导性概念，并解释干扰关键概念如何对模型产生负面影响。同时，它揭示生成内容中的社会学偏见，揭示不同社会学背景下存在的差异性。令人惊讶的是，ConceptLens 揭示了安全的训练和推理数据可能会意外且容易利用，这可能削弱安全性对齐。我们的研究为培养对 AI 系统的信任提供了可操作的见解，从而加速其采纳并推动更大的创新。 

---
# Llama-3.1-FoundationAI-SecurityLLM-Base-8B Technical Report 

**Title (ZH)**: Llama-3.1-基础AI安全大语言模型-8B技术报告 

**Authors**: Paul Kassianik, Baturay Saglam, Alexander Chen, Blaine Nelson, Anu Vellore, Massimo Aufiero, Fraser Burch, Dhruv Kedia, Avi Zohary, Sajana Weerawardhena, Aman Priyanshu, Adam Swanda, Amy Chang, Hyrum Anderson, Kojin Oshiba, Omar Santos, Yaron Singer, Amin Karbasi  

**Link**: [PDF](https://arxiv.org/pdf/2504.21039)  

**Abstract**: As transformer-based large language models (LLMs) increasingly permeate society, they have revolutionized domains such as software engineering, creative writing, and digital arts. However, their adoption in cybersecurity remains limited due to challenges like scarcity of specialized training data and complexity of representing cybersecurity-specific knowledge. To address these gaps, we present Foundation-Sec-8B, a cybersecurity-focused LLM built on the Llama 3.1 architecture and enhanced through continued pretraining on a carefully curated cybersecurity corpus. We evaluate Foundation-Sec-8B across both established and new cybersecurity benchmarks, showing that it matches Llama 3.1-70B and GPT-4o-mini in certain cybersecurity-specific tasks. By releasing our model to the public, we aim to accelerate progress and adoption of AI-driven tools in both public and private cybersecurity contexts. 

**Abstract (ZH)**: 基于transformer的大规模语言模型在网络安全领域的聚焦研究：Foundation-Sec-8B的构建与评估 

---
# Prefill-Based Jailbreak: A Novel Approach of Bypassing LLM Safety Boundary 

**Title (ZH)**: 基于预填的脱管攻击：突破LLM安全边界的新方法 

**Authors**: Yakai Li, Jiekang Hu, Weiduan Sang, Luping Ma, Jing Xie, Weijuan Zhang, Aimin Yu, Shijie Zhao, Qingjia Huang, Qihang Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2504.21038)  

**Abstract**: Large Language Models (LLMs) are designed to generate helpful and safe content. However, adversarial attacks, commonly referred to as jailbreak, can bypass their safety protocols, prompting LLMs to generate harmful content or reveal sensitive data. Consequently, investigating jailbreak methodologies is crucial for exposing systemic vulnerabilities within LLMs, ultimately guiding the continuous implementation of security enhancements by developers. In this paper, we introduce a novel jailbreak attack method that leverages the prefilling feature of LLMs, a feature designed to enhance model output constraints. Unlike traditional jailbreak methods, the proposed attack circumvents LLMs' safety mechanisms by directly manipulating the probability distribution of subsequent tokens, thereby exerting control over the model's output. We propose two attack variants: Static Prefilling (SP), which employs a universal prefill text, and Optimized Prefilling (OP), which iteratively optimizes the prefill text to maximize the attack success rate. Experiments on six state-of-the-art LLMs using the AdvBench benchmark validate the effectiveness of our method and demonstrate its capability to substantially enhance attack success rates when combined with existing jailbreak approaches. The OP method achieved attack success rates of up to 99.82% on certain models, significantly outperforming baseline methods. This work introduces a new jailbreak attack method in LLMs, emphasizing the need for robust content validation mechanisms to mitigate the adversarial exploitation of prefilling features. All code and data used in this paper are publicly available. 

**Abstract (ZH)**: 大型语言模型（LLMs）设计用于生成有益和安全的内容。然而，通常称为“出狱”的对抗攻击可以使LLMs的安全协议失效，导致其生成有害内容或泄露敏感数据。因此，研究出狱方法对于揭示LLMs中的系统性漏洞至关重要，最终指导开发人员持续实施安全增强措施。在本文中，我们介绍了一种利用LLMs前填功能的新颖出狱攻击方法，前填功能旨在增强模型输出约束。与传统的出狱方法不同，所提出的攻击通过直接操控后续令牌的概率分布来绕过LLMs的安全机制，从而控制模型的输出。我们提出了两种攻击变体：静态前填（SP），使用通用前填文本，以及优化前填（OP），通过迭代优化前填文本以最大化攻击成功率。使用AdvBench基准在六个最先进的LLM上进行的实验验证了我们方法的有效性，并展示了其在结合现有出狱方法时显著提高攻击成功率的能力。OP方法在某些模型上的攻击成功率高达99.82%，明显优于基线方法。本文引入了LLMs的新出狱攻击方法，强调了需要强大的内容验证机制以减轻前填功能的对抗性利用。本文中使用的所有代码和数据均公开可用。 

---
# Security Bug Report Prediction Within and Across Projects: A Comparative Study of BERT and Random Forest 

**Title (ZH)**: 跨项目内外的安全漏洞报告预测：BERT与随机森林的比较研究 

**Authors**: Farnaz Soltaniani, Mohammad Ghafari, Mohammed Sayagh  

**Link**: [PDF](https://arxiv.org/pdf/2504.21037)  

**Abstract**: Early detection of security bug reports (SBRs) is crucial for preventing vulnerabilities and ensuring system reliability. While machine learning models have been developed for SBR prediction, their predictive performance still has room for improvement. In this study, we conduct a comprehensive comparison between BERT and Random Forest (RF), a competitive baseline for predicting SBRs. The results show that RF outperforms BERT with a 34% higher average G-measure for within-project predictions. Adding only SBRs from various projects improves both models' average performance. However, including both security and nonsecurity bug reports significantly reduces RF's average performance to 46%, while boosts BERT to its best average performance of 66%, surpassing RF. In cross-project SBR prediction, BERT achieves a remarkable 62% G-measure, which is substantially higher than RF. 

**Abstract (ZH)**: 早期检测安全漏洞报告对于预防漏洞和确保系统可靠性至关重要。尽管已开发出用于预测安全漏洞报告的机器学习模型，但其预测性能仍有机可提升。本研究全面比较了BERT和随机森林（RF）在预测安全漏洞报告方面的性能。结果显示，RF在项目内预测方面的平均G-测量值比BERT高34%。仅添加来自不同项目的安全漏洞报告可以提高两种模型的平均性能。然而，包含安全和非安全漏洞报告显著降低了RF的平均性能至46%，而提升了BERT的最佳平均性能至66%，超越了RF。在跨项目安全漏洞报告预测中，BERT实现了显著的62% G-测量值，高于RF。 

---
# Can Differentially Private Fine-tuning LLMs Protect Against Privacy Attacks? 

**Title (ZH)**: 差分隐私 Fine-tuning 大型语言模型能否保护against隐私攻击？ 

**Authors**: Hao Du, Shang Liu, Yang Cao  

**Link**: [PDF](https://arxiv.org/pdf/2504.21036)  

**Abstract**: Fine-tuning large language models (LLMs) has become an essential strategy for adapting them to specialized tasks; however, this process introduces significant privacy challenges, as sensitive training data may be inadvertently memorized and exposed. Although differential privacy (DP) offers strong theoretical guarantees against such leakage, its empirical privacy effectiveness on LLMs remains unclear, especially under different fine-tuning methods. In this paper, we systematically investigate the impact of DP across fine-tuning methods and privacy budgets, using both data extraction and membership inference attacks to assess empirical privacy risks. Our main findings are as follows: (1) Differential privacy reduces model utility, but its impact varies significantly across different fine-tuning methods. (2) Without DP, the privacy risks of models fine-tuned with different approaches differ considerably. (3) When DP is applied, even a relatively high privacy budget can substantially lower privacy risk. (4) The privacy-utility trade-off under DP training differs greatly among fine-tuning methods, with some methods being unsuitable for DP due to severe utility degradation. Our results provide practical guidance for privacy-conscious deployment of LLMs and pave the way for future research on optimizing the privacy-utility trade-off in fine-tuning methodologies. 

**Abstract (ZH)**: 大规模语言模型（LLMs）微调已成为使其适应专门任务的一种关键策略；然而，这一过程引入了重大的隐私挑战，因为敏感的训练数据可能会无意中被记忆并泄露。尽管差异化隐私（DP）提供了强理论保护以防止这种泄露，但其在LLMs上的实际隐私有效性仍不清楚，特别是在不同的微调方法下。在本文中，我们系统地研究了DP在不同微调方法和隐私预算下的影响，通过数据提取和成员推断攻击来评估实际的隐私风险。主要发现如下：（1）差异化隐私降低了模型的实用性，但其影响在不同的微调方法间差异显著。（2）在没有DP的情况下，使用不同方法微调的模型的隐私风险差异很大。（3）当应用DP时，即使是在相对较高的隐私预算下，也能显著降低隐私风险。（4）在DP训练下的隐私-实用性权衡在不同微调方法间存在巨大差异，某些方法因严重实用性下降而不适合DP。我们的结果为隐私意识较强的LLMs部署提供了实际指导，并为未来研究优化微调方法下的隐私-实用性权衡奠定了基础。 

---
# SAGA: A Security Architecture for Governing AI Agentic Systems 

**Title (ZH)**: SAGA: 一种治理AI代理系统的安全架构 

**Authors**: Georgios Syros, Anshuman Suri, Cristina Nita-Rotaru, Alina Oprea  

**Link**: [PDF](https://arxiv.org/pdf/2504.21034)  

**Abstract**: Large Language Model (LLM)-based agents increasingly interact, collaborate, and delegate tasks to one another autonomously with minimal human interaction. Industry guidelines for agentic system governance emphasize the need for users to maintain comprehensive control over their agents, mitigating potential damage from malicious agents. Several proposed agentic system designs address agent identity, authorization, and delegation, but remain purely theoretical, without concrete implementation and evaluation. Most importantly, they do not provide user-controlled agent management. To address this gap, we propose SAGA, a Security Architecture for Governing Agentic systems, that offers user oversight over their agents' lifecycle. In our design, users register their agents with a central entity, the Provider, that maintains agents contact information, user-defined access control policies, and helps agents enforce these policies on inter-agent communication. We introduce a cryptographic mechanism for deriving access control tokens, that offers fine-grained control over an agent's interaction with other agents, balancing security and performance consideration. We evaluate SAGA on several agentic tasks, using agents in different geolocations, and multiple on-device and cloud LLMs, demonstrating minimal performance overhead with no impact on underlying task utility in a wide range of conditions. Our architecture enables secure and trustworthy deployment of autonomous agents, accelerating the responsible adoption of this technology in sensitive environments. 

**Abstract (ZH)**: 基于大规模语言模型（LLM）的代理系统安全架构：用户控制下的自主代理治理与部署 

---
# Transcending Dimensions using Generative AI: Real-Time 3D Model Generation in Augmented Reality 

**Title (ZH)**: 超越维度：使用生成式AI进行实时增强现实中的3D模型生成 

**Authors**: Majid Behravan, Maryam Haghani, Denis Gracanin  

**Link**: [PDF](https://arxiv.org/pdf/2504.21033)  

**Abstract**: Traditional 3D modeling requires technical expertise, specialized software, and time-intensive processes, making it inaccessible for many users. Our research aims to lower these barriers by combining generative AI and augmented reality (AR) into a cohesive system that allows users to easily generate, manipulate, and interact with 3D models in real time, directly within AR environments. Utilizing cutting-edge AI models like Shap-E, we address the complex challenges of transforming 2D images into 3D representations in AR environments. Key challenges such as object isolation, handling intricate backgrounds, and achieving seamless user interaction are tackled through advanced object detection methods, such as Mask R-CNN. Evaluation results from 35 participants reveal an overall System Usability Scale (SUS) score of 69.64, with participants who engaged with AR/VR technologies more frequently rating the system significantly higher, at 80.71. This research is particularly relevant for applications in gaming, education, and AR-based e-commerce, offering intuitive, model creation for users without specialized skills. 

**Abstract (ZH)**: 传统3D建模需要专门的技术知识、专业的软件和耗时的过程，使其对许多用户来说难以触及。我们的研究旨在通过将生成性AI与增强现实(AR)结合，形成一个统一系统，让用户能够轻松地在实时时直接在AR环境中生成、操作和互动3D模型，从而降低这些障碍。利用如Shap-E等前沿AI模型，我们解决了在AR环境中将2D图像转换为3D表示的复杂挑战。通过高级对象检测方法（如Mask R-CNN）来应对诸如物体隔离、处理复杂背景和实现无缝用户交互等关键挑战。从35名参与者的表现来看，系统的总体SUS评分为69.64，而更频繁接触AR/VR技术的参与者对系统的评价更高，达到了80.71。这项研究特别适用于游戏、教育和基于AR的电子商务应用，为用户提供直观的3D模型创建功能，无需专门技能。 

---
# Selecting the Right LLM for eGov Explanations 

**Title (ZH)**: 选择合适的大型语言模型进行电子政务解释 

**Authors**: Lior Limonad, Fabiana Fournier, Hadar Mulian, George Manias, Spiros Borotis, Danai Kyrkou  

**Link**: [PDF](https://arxiv.org/pdf/2504.21032)  

**Abstract**: The perceived quality of the explanations accompanying e-government services is key to gaining trust in these institutions, consequently amplifying further usage of these services. Recent advances in generative AI, and concretely in Large Language Models (LLMs) allow the automation of such content articulations, eliciting explanations' interpretability and fidelity, and more generally, adapting content to various audiences. However, selecting the right LLM type for this has become a non-trivial task for e-government service providers. In this work, we adapted a previously developed scale to assist with this selection, providing a systematic approach for the comparative analysis of the perceived quality of explanations generated by various LLMs. We further demonstrated its applicability through the tax-return process, using it as an exemplar use case that could benefit from employing an LLM to generate explanations about tax refund decisions. This was attained through a user study with 128 survey respondents who were asked to rate different versions of LLM-generated explanations about tax refund decisions, providing a methodological basis for selecting the most appropriate LLM. Recognizing the practical challenges of conducting such a survey, we also began exploring the automation of this process by attempting to replicate human feedback using a selection of cutting-edge predictive techniques. 

**Abstract (ZH)**: 电子政务服务中伴随说明的感知质量是建立这些机构信任的关键，从而进一步放大这些服务的使用。生成式人工智能的最新进展，特别是大型语言模型（LLMs）的出现，使这类内容的自动化表达成为可能，引发了解释的可解释性和真实性，并且更广泛地适应不同的受众。然而，选择合适的LLM类型来实现这一点已成为电子政务服务提供商的一项非 trivial 任务。在本文中，我们调整了一种先前开发的量表来帮助进行这种选择，提供了一种系统的方法来进行各种LLM生成的解释感知质量的比较分析。我们还通过税务申报过程进一步展示了其应用性，将其作为可以受益于使用LLM生成税退款决定解释的示例用例。这通过一项包含128名调查响应者的用户研究来实现，要求他们评估不同版本的LLM生成的税退款决定解释，为选择最合适的LLM提供了方法论基础。鉴于进行此类调查的实际挑战，我们还开始探索通过使用一系列先进的预测技术来自动复制人类反馈的过程。 

---
# Advancing Multi-Agent Systems Through Model Context Protocol: Architecture, Implementation, and Applications 

**Title (ZH)**: 通过模型上下文协议推进多智能体系统：架构、实现与应用 

**Authors**: Naveen Krishnan  

**Link**: [PDF](https://arxiv.org/pdf/2504.21030)  

**Abstract**: Multi-agent systems represent a significant advancement in artificial intelligence, enabling complex problem-solving through coordinated specialized agents. However, these systems face fundamental challenges in context management, coordination efficiency, and scalable operation. This paper introduces a comprehensive framework for advancing multi-agent systems through Model Context Protocol (MCP), addressing these challenges through standardized context sharing and coordination mechanisms. We extend previous work on AI agent architectures by developing a unified theoretical foundation, advanced context management techniques, and scalable coordination patterns. Through detailed implementation case studies across enterprise knowledge management, collaborative research, and distributed problem-solving domains, we demonstrate significant performance improvements compared to traditional approaches. Our evaluation methodology provides a systematic assessment framework with benchmark tasks and datasets specifically designed for multi-agent systems. We identify current limitations, emerging research opportunities, and potential transformative applications across industries. This work contributes to the evolution of more capable, collaborative, and context-aware artificial intelligence systems that can effectively address complex real-world challenges. 

**Abstract (ZH)**: Model Context Protocol（MCP）驱动的多Agent系统综合框架：克服根本挑战，实现高效协作与可扩展操作 

---
# PICO: Secure Transformers via Robust Prompt Isolation and Cybersecurity Oversight 

**Title (ZH)**: PICO: 安全的变压器模型通过健壮的提示隔离和网络安全监督 

**Authors**: Ben Goertzel, Paulos Yibelo  

**Link**: [PDF](https://arxiv.org/pdf/2504.21029)  

**Abstract**: We propose a robust transformer architecture designed to prevent prompt injection attacks and ensure secure, reliable response generation. Our PICO (Prompt Isolation and Cybersecurity Oversight) framework structurally separates trusted system instructions from untrusted user inputs through dual channels that are processed independently and merged only by a controlled, gated fusion mechanism. In addition, we integrate a specialized Security Expert Agent within a Mixture-of-Experts (MoE) framework and incorporate a Cybersecurity Knowledge Graph (CKG) to supply domain-specific reasoning. Our training design further ensures that the system prompt branch remains immutable while the rest of the network learns to handle adversarial inputs safely. This PICO framework is presented via a general mathematical formulation, then elaborated in terms of the specifics of transformer architecture, and fleshed out via hypothetical case studies including Policy Puppetry attacks. While the most effective implementation may involve training transformers in a PICO-based way from scratch, we also present a cost-effective fine-tuning approach. 

**Abstract (ZH)**: 一种防止提示注入攻击并确保安全可靠响应生成的鲁棒变压器架构：PICO（提示隔离和网络安全监督）框架 

---
# Semantic-Aware Contrastive Fine-Tuning: Boosting Multimodal Malware Classification with Discriminative Embeddings 

**Title (ZH)**: 语义意识对比微调：通过 discriminative 嵌入提升多模态恶意软件分类 

**Authors**: Ivan Montoya Sanchez, Shaswata Mitra, Aritran Piplai, Sudip Mittal  

**Link**: [PDF](https://arxiv.org/pdf/2504.21028)  

**Abstract**: The rapid evolution of malware variants requires robust classification methods to enhance cybersecurity. While Large Language Models (LLMs) offer potential for generating malware descriptions to aid family classification, their utility is limited by semantic embedding overlaps and misalignment with binary behavioral features. We propose a contrastive fine-tuning (CFT) method that refines LLM embeddings via targeted selection of hard negative samples based on cosine similarity, enabling LLMs to distinguish between closely related malware families. Our approach combines high-similarity negatives to enhance discriminative power and mid-tier negatives to increase embedding diversity, optimizing both precision and generalization. Evaluated on the CIC-AndMal-2020 and BODMAS datasets, our refined embeddings are integrated into a multimodal classifier within a Model-Agnostic Meta-Learning (MAML) framework on a few-shot setting. Experiments demonstrate significant improvements: our method achieves 63.15% classification accuracy with as few as 20 samples on CIC-AndMal-2020, outperforming baselines by 11--21 percentage points and surpassing prior negative sampling strategies. Ablation studies confirm the superiority of similarity-based selection over random sampling, with gains of 10-23%. Additionally, fine-tuned LLMs generate attribute-aware descriptions that generalize to unseen variants, bridging textual and binary feature gaps. This work advances malware classification by enabling nuanced semantic distinctions and provides a scalable framework for adapting LLMs to cybersecurity challenges. 

**Abstract (ZH)**: 快速演变的恶意软件变种要求有 robust 的分类方法以增强网络安全。虽然大型语言模型（LLMs）有可能生成恶意软件描述以辅助家族分类，但其实用性受限于语义嵌入的重叠和与二进制行为特征的不对齐。我们提出了一种对比微调（CFT）方法，通过基于余弦相似度选择针对性的硬负样本来细化LLM嵌入，使LLM能够区分密切相关恶意软件家族。我们的方法结合高相似度负样本以增强判别力，并结合中等层级负样本以增加嵌入多样性，从而同时优化精度和泛化能力。我们在CIC-AndMal-2020和BODMAS数据集上进行了评估，将优化后的嵌入整合到一个模型无偏元学习（MAML）框架中的多模态分类器中，在少量样本设置下进行。实验结果显示了显著的改进：我们的方法在CIC-AndMal-2020数据集上仅使用20个样本就能达到63.15%的分类准确率，优于基线11-21个百分点，并超过了先前的负样本策略。消融研究证实，基于相似度的选择优于随机采样，提高了10-23%。此外，微调后的LLM生成的属性感知描述能够泛化到未见过的变种，弥补了文本和二进制特征之间的差距。这项工作通过使恶意软件分类能够进行细微的语义区分，推进了恶意软件分类，并提供了一个可扩展框架，使LLM能够应对网络安全挑战。 

---
# UrbanPlanBench: A Comprehensive Urban Planning Benchmark for Evaluating Large Language Models 

**Title (ZH)**: UrbanPlanBench: 一种全面的城市规划基准，用于评估大规模语言模型 

**Authors**: Yu Zheng, Longyi Liu, Yuming Lin, Jie Feng, Guozhen Zhang, Depeng Jin, Yong Li  

**Link**: [PDF](https://arxiv.org/pdf/2504.21027)  

**Abstract**: The advent of Large Language Models (LLMs) holds promise for revolutionizing various fields traditionally dominated by human expertise. Urban planning, a professional discipline that fundamentally shapes our daily surroundings, is one such field heavily relying on multifaceted domain knowledge and experience of human experts. The extent to which LLMs can assist human practitioners in urban planning remains largely unexplored. In this paper, we introduce a comprehensive benchmark, UrbanPlanBench, tailored to evaluate the efficacy of LLMs in urban planning, which encompasses fundamental principles, professional knowledge, and management and regulations, aligning closely with the qualifications expected of human planners. Through extensive evaluation, we reveal a significant imbalance in the acquisition of planning knowledge among LLMs, with even the most proficient models falling short of meeting professional standards. For instance, we observe that 70% of LLMs achieve subpar performance in understanding planning regulations compared to other aspects. Besides the benchmark, we present the largest-ever supervised fine-tuning (SFT) dataset, UrbanPlanText, comprising over 30,000 instruction pairs sourced from urban planning exams and textbooks. Our findings demonstrate that fine-tuned models exhibit enhanced performance in memorization tests and comprehension of urban planning knowledge, while there exists significant room for improvement, particularly in tasks requiring domain-specific terminology and reasoning. By making our benchmark, dataset, and associated evaluation and fine-tuning toolsets publicly available at this https URL, we aim to catalyze the integration of LLMs into practical urban planning, fostering a symbiotic collaboration between human expertise and machine intelligence. 

**Abstract (ZH)**: 大型语言模型的兴起有望革命性地改变传统上由人类专家主导的各个领域。城市规划作为一项从根本上塑造我们日常生活环境的专业学科，是依赖多方面领域知识和专家经验的领域之一。关于大型语言模型在城市规划中的辅助效果仍然 largely unexplored。本文介绍了专为评估大型语言模型在城市规划中的效果而设计的综合基准——UrbanPlanBench，涵盖了基本原理、专业知识、管理和法规，与城市规划师所需资格紧密契合。通过广泛评估，我们揭示了大型语言模型在获取规划知识方面存在显著不平衡，即使是技术最成熟的模型也无法达到专业标准。例如，我们观察到70%的模型在理解规划法规方面表现不佳，与其它方面相比。除了基准外，我们还呈现了迄今为止最大的监督微调数据集——UrbanPlanText，包含超过30,000个来自城市规划考试和教材的指令对。我们的研究结果表明，微调模型在记忆测试和理解城市规划知识方面表现出增强的效果，但在需要特定领域术语和推理的任务中仍有很多改进空间。通过在此网址公开我们的基准、数据集以及相关评估和微调工具集，我们旨在促进大型语言模型在实际城市规划中的集成，推动人类专业知识与机器智能的共生合作。 

---
# Creating and Evaluating Code-Mixed Nepali-English and Telugu-English Datasets for Abusive Language Detection Using Traditional and Deep Learning Models 

**Title (ZH)**: 使用传统和深度学习模型创建和评估代码混合尼泊尔英语和泰卢固英语数据集以检测 abusive 语言 

**Authors**: Manish Pandey, Nageshwar Prasad Yadav, Mokshada Adduru, Sawan Rai  

**Link**: [PDF](https://arxiv.org/pdf/2504.21026)  

**Abstract**: With the growing presence of multilingual users on social media, detecting abusive language in code-mixed text has become increasingly challenging. Code-mixed communication, where users seamlessly switch between English and their native languages, poses difficulties for traditional abuse detection models, as offensive content may be context-dependent or obscured by linguistic blending. While abusive language detection has been extensively explored for high-resource languages like English and Hindi, low-resource languages such as Telugu and Nepali remain underrepresented, leaving gaps in effective moderation. In this study, we introduce a novel, manually annotated dataset of 2 thousand Telugu-English and 5 Nepali-English code-mixed comments, categorized as abusive and non-abusive, collected from various social media platforms. The dataset undergoes rigorous preprocessing before being evaluated across multiple Machine Learning (ML), Deep Learning (DL), and Large Language Models (LLMs). We experimented with models including Logistic Regression, Random Forest, Support Vector Machines (SVM), Neural Networks (NN), LSTM, CNN, and LLMs, optimizing their performance through hyperparameter tuning, and evaluate it using 10-fold cross-validation and statistical significance testing (t-test). Our findings provide key insights into the challenges of detecting abusive language in code-mixed settings and offer a comparative analysis of computational approaches. This study contributes to advancing NLP for low-resource languages by establishing benchmarks for abusive language detection in Telugu-English and Nepali-English code-mixed text. The dataset and insights can aid in the development of more robust moderation strategies for multilingual social media environments. 

**Abstract (ZH)**: 随着社交媒体上多语言用户的增多，检测代码混合文本中的攻击性语言变得越来越具有挑战性。在用户无缝切换英语和母语的代码混合通信中，传统攻击性内容检测模型面临困难，因为冒犯内容可能是情境依赖的或被语言融合所掩盖。尽管已经对英语和印地语等高资源语言的攻击性语言检测进行了广泛研究，但泰卢固语和尼泊尔语等低资源语言仍处于被忽视的地位，留下了有效的监管空白。在这项研究中，我们介绍了两个新的人工标注数据集，包含2000个泰卢固-英语和500个尼泊尔-英语代码混合评论，分为攻击性和非攻击性两类，来源于多个社交媒体平台。数据集经过严格的预处理后，在多个机器学习（ML）、深度学习（DL）和大型语言模型（LLM）中进行评估。我们尝试了包括逻辑回归、随机森林、支持向量机（SVM）、神经网络（NN）、LSTM、CNN和LLM等模型，通过超参数调整优化其性能，并使用10折交叉验证和统计显著性检验（t检验）进行评估。我们的研究结果提供了在代码混合环境中检测攻击性语言的挑战的关键见解，并提供了计算方法的比较分析。这项研究通过为泰卢固-英语和尼泊尔-英语代码混合文本中的攻击性语言检测建立基准，促进了低资源语言的自然语言处理（NLP）发展。数据集及其见解有助于开发更 robust 的多语言社交媒体环境中的监管策略。 

---
# ConformalNL2LTL: Translating Natural Language Instructions into Temporal Logic Formulas with Conformal Correctness Guarantees 

**Title (ZH)**: 形变NL2LTL：具有形变正确性保证的自然语言指令到时间逻辑公式的翻译 

**Authors**: Jun Wang, David Smith Sundarsingh, Jyotirmoy V. Deshmukh, Yiannis Kantaros  

**Link**: [PDF](https://arxiv.org/pdf/2504.21022)  

**Abstract**: Linear Temporal Logic (LTL) has become a prevalent specification language for robotic tasks. To mitigate the significant manual effort and expertise required to define LTL-encoded tasks, several methods have been proposed for translating Natural Language (NL) instructions into LTL formulas, which, however, lack correctness guarantees. To address this, we introduce a new NL-to-LTL translation method, called ConformalNL2LTL, that can achieve user-defined translation success rates over unseen NL commands. Our method constructs LTL formulas iteratively by addressing a sequence of open-vocabulary Question-Answering (QA) problems with LLMs. To enable uncertainty-aware translation, we leverage conformal prediction (CP), a distribution-free uncertainty quantification tool for black-box models. CP enables our method to assess the uncertainty in LLM-generated answers, allowing it to proceed with translation when sufficiently confident and request help otherwise. We provide both theoretical and empirical results demonstrating that ConformalNL2LTL achieves user-specified translation accuracy while minimizing help rates. 

**Abstract (ZH)**: 基于自然语言到线性时序逻辑的自适应翻译：ConformalNL2LTL 

---
# Context-Enhanced Contrastive Search for Improved LLM Text Generation 

**Title (ZH)**: 上下文增强对比检索以改善LLM文本生成 

**Authors**: Jaydip Sen, Rohit Pandey, Hetvi Waghela  

**Link**: [PDF](https://arxiv.org/pdf/2504.21020)  

**Abstract**: Recently, Large Language Models (LLMs) have demonstrated remarkable advancements in Natural Language Processing (NLP). However, generating high-quality text that balances coherence, diversity, and relevance remains challenging. Traditional decoding methods, such as bean search and top-k sampling, often struggle with either repetitive or incoherent outputs, particularly in tasks that require long-form text generation. To address these limitations, the paper proposes a novel enhancement of the well-known Contrastive Search algorithm, Context-Enhanced Contrastive Search (CECS) with contextual calibration. The proposed scheme introduces several novelties including dynamic contextual importance weighting, multi-level Contrastive Search, and adaptive temperature control, to optimize the balance between fluency, creativity, and precision. The performance of CECS is evaluated using several standard metrics such as BLEU, ROUGE, and semantic similarity. Experimental results demonstrate significant improvements in both coherence and relevance of the generated texts by CECS outperforming the existing Contrastive Search techniques. The proposed algorithm has several potential applications in the real world including legal document drafting, customer service chatbots, and content marketing. 

**Abstract (ZH)**: 近期，大规模语言模型（LLMs）在自然语言处理（NLP）领域取得了显著进展。然而，生成高质量平衡连贯性、多样性和相关性的文本仍然是一个挑战。传统的解码方法，如贪心搜索和top-k采样，常常在长文本生成任务中产生重复或不连贯的输出。为了解决这些问题，论文提出了一种Contrastive Search算法的新型增强方法——基于上下文校准的Contrastive Search增强方法（CECS）。该方案引入了动态上下文重要性加权、多层次Contrastive Search和自适应温度控制等新颖特性，以优化流畅性、创造性和精确性的平衡。CECS的性能通过使用BLEU、ROUGE和语义相似性等标准指标进行评估。实验结果表明，CECS在生成文本的连贯性和相关性方面取得了显著改进，优于现有的Contrastive Search技术。所提出算法在实际应用中有多种潜在用途，包括法律文件起草、客户服务聊天机器人和内容营销等。 

---
# Kill two birds with one stone: generalized and robust AI-generated text detection via dynamic perturbations 

**Title (ZH)**: 一石二鸟：通过动态扰动实现通用且稳健的AI生成文本检测 

**Authors**: Yinghan Zhou, Juan Wen, Wanli Peng, Yiming Xue, Ziwei Zhang, Zhengxian Wu  

**Link**: [PDF](https://arxiv.org/pdf/2504.21019)  

**Abstract**: The growing popularity of large language models has raised concerns regarding the potential to misuse AI-generated text (AIGT). It becomes increasingly critical to establish an excellent AIGT detection method with high generalization and robustness. However, existing methods either focus on model generalization or concentrate on robustness. The unified mechanism, to simultaneously address the challenges of generalization and robustness, is less explored. In this paper, we argue that robustness can be view as a specific form of domain shift, and empirically reveal an intrinsic mechanism for model generalization of AIGT detection task. Then, we proposed a novel AIGT detection method (DP-Net) via dynamic perturbations introduced by a reinforcement learning with elaborated reward and action. Experimentally, extensive results show that the proposed DP-Net significantly outperforms some state-of-the-art AIGT detection methods for generalization capacity in three cross-domain scenarios. Meanwhile, the DP-Net achieves best robustness under two text adversarial attacks. The code is publicly available at this https URL. 

**Abstract (ZH)**: 大型语言模型 popularity 的增长引发了对 AI 生成文本 (AIGT) 滥用潜在风险的关注。建立一种兼具高泛化能力和鲁棒性的 AIGT 检测方法变得越来越关键。然而，现有方法要么专注于模型泛化，要么专注于鲁棒性。同时解决泛化和鲁棒性挑战的统一机制研究较少。本文认为鲁棒性可以被视为一种特定形式的领域转移，并通过强化学习引入动态扰动，采用有细化奖励和动作的方法，实证揭示了 AIGT 检测任务模型泛化的一种内在机制。然后，我们提出了一种新颖的 AIGT 检测方法（DP-Net）。实验结果显示，在三个跨领域场景中，所提出的 DP-Net 显著优于一些最新 AIGT 检测方法的泛化能力。同时，在两种文本对抗攻击下，DP-Net 达到了最佳鲁棒性。有关代码已公开，访问此URL：。 

---
# Analyzing Feedback Mechanisms in AI-Generated MCQs: Insights into Readability, Lexical Properties, and Levels of Challenge 

**Title (ZH)**: 分析AI生成的多项选择题中的反馈机制：可读性、词项特征及难度水平 insights 

**Authors**: Antoun Yaacoub, Zainab Assaghir, Lionel Prevost, Jérôme Da-Rugna  

**Link**: [PDF](https://arxiv.org/pdf/2504.21013)  

**Abstract**: Artificial Intelligence (AI)-generated feedback in educational settings has garnered considerable attention due to its potential to enhance learning outcomes. However, a comprehensive understanding of the linguistic characteristics of AI-generated feedback, including readability, lexical richness, and adaptability across varying challenge levels, remains limited. This study delves into the linguistic and structural attributes of feedback generated by Google's Gemini 1.5-flash text model for computer science multiple-choice questions (MCQs). A dataset of over 1,200 MCQs was analyzed, considering three difficulty levels (easy, medium, hard) and three feedback tones (supportive, neutral, challenging). Key linguistic metrics, such as length, readability scores (Flesch-Kincaid Grade Level), vocabulary richness, and lexical density, were computed and examined. A fine-tuned RoBERTa-based multi-task learning (MTL) model was trained to predict these linguistic properties, achieving a Mean Absolute Error (MAE) of 2.0 for readability and 0.03 for vocabulary richness. The findings reveal significant interaction effects between feedback tone and question difficulty, demonstrating the dynamic adaptation of AI-generated feedback within diverse educational contexts. These insights contribute to the development of more personalized and effective AI-driven feedback mechanisms, highlighting the potential for improved learning outcomes while underscoring the importance of ethical considerations in their design and deployment. 

**Abstract (ZH)**: 人工智能生成反馈在教育环境中的应用引起了广泛关注，因其有望提高学习效果。然而，有关人工智能生成反馈的语言特征，包括可读性、词汇丰富度和不同挑战水平下的适应性，的研究仍不够全面。本研究探讨了谷歌Gemini 1.5-flash文本模型生成的计算机科学多项选择题（MCQ）反馈的语义和结构特征。分析了超过1,200道MCQ，考虑了三种难度级别（简单、中等、困难）和三种反馈语气（支持性、中性、挑战性）。计算并分析了诸如长度、可读性评分（Flesch-Kincaid 年级水平）、词汇丰富度和词汇密度等关键语言指标。使用微调后的RoBERTa多任务学习（MTL）模型预测这些语言属性，可读性误差的均方绝对误差（MAE）为2.0，词汇丰富度误差为0.03。研究发现，反馈语气与问题难度之间的交互作用显著，表明人工智能生成的反馈在不同教育背景下能够动态适应。这些发现为开发更加个性化的、有效的基于人工智能的反馈机制提供了依据，强调了其设计和部署时需要考虑伦理问题，以提高学习效果。 

---
# Waking Up an AI: A Quantitative Framework for Prompt-Induced Phase Transition in Large Language Models 

**Title (ZH)**: 唤醒AI：大规模语言模型由提示引发的相变的定量框架 

**Authors**: Makoto Sato  

**Link**: [PDF](https://arxiv.org/pdf/2504.21012)  

**Abstract**: What underlies intuitive human thinking? One approach to this question is to compare the cognitive dynamics of humans and large language models (LLMs). However, such a comparison requires a method to quantitatively analyze AI cognitive behavior under controlled conditions. While anecdotal observations suggest that certain prompts can dramatically change LLM behavior, these observations have remained largely qualitative. Here, we propose a two-part framework to investigate this phenomenon: a Transition-Inducing Prompt (TIP) that triggers a rapid shift in LLM responsiveness, and a Transition Quantifying Prompt (TQP) that evaluates this change using a separate LLM. Through controlled experiments, we examined how LLMs react to prompts embedding two semantically distant concepts (e.g., mathematical aperiodicity and traditional crafts)--either fused together or presented separately--by changing their linguistic quality and affective tone. Whereas humans tend to experience heightened engagement when such concepts are meaningfully blended producing a novel concept--a form of conceptual fusion--current LLMs showed no significant difference in responsiveness between semantically fused and non-fused prompts. This suggests that LLMs may not yet replicate the conceptual integration processes seen in human intuition. Our method enables fine-grained, reproducible measurement of cognitive responsiveness, and may help illuminate key differences in how intuition and conceptual leaps emerge in artificial versus human minds. 

**Abstract (ZH)**: 直观人类思维的基础是什么？一种方法是将人类的认知动态与大语言模型（LLMs）进行比较。但是，这种比较需要一种在受控条件下定量分析AI认知行为的方法。虽然有些示例观察表明某些提示可以显著改变LLM的行为，但这些观察主要还是定性的。在此，我们提出了一种两部分框架来研究这一现象：一种触发LLM响应快速转变的转换诱导提示（TIP），以及一种用于通过另一个LLM评估这种变化的转换量化提示（TQP）。通过受控实验，我们考察了LLMs在嵌入两个语义上相距甚远的概念（例如，数学无周期性和传统工艺）时的反应——这些概念要么融合在一起，要么分开发表——是如何通过改变语言质量和情感色彩来影响其行为的。与人类往往在语义上融合有意义的概念时表现出更高的参与度——这种概念融合具有新颖性——不同，当前的LLMs在语义融合和非融合的提示之间没有显示出显著的响应差异。这表明LLMs可能尚未复制人类直观思维中观察到的概念整合过程。我们的方法可以实现认知响应的精细、可重复测量，并可能有助于阐明人工智能与人类思维中概念飞跃出现的关键差异。 

---
# Research on CNN-BiLSTM Network Traffic Anomaly Detection Model Based on MindSpore 

**Title (ZH)**: 基于MindSpore的CNN-BiLSTM网络流量异常检测模型研究 

**Authors**: Qiuyan Xiang, Shuang Wu, Dongze Wu, Yuxin Liu, Zhenkai Qin  

**Link**: [PDF](https://arxiv.org/pdf/2504.21008)  

**Abstract**: With the widespread adoption of the Internet of Things (IoT) and Industrial IoT (IIoT) technologies, network architectures have become increasingly complex, and the volume of traffic has grown substantially. This evolution poses significant challenges to traditional security mechanisms, particularly in detecting high-frequency, diverse, and highly covert network attacks. To address these challenges, this study proposes a novel network traffic anomaly detection model that integrates a Convolutional Neural Network (CNN) with a Bidirectional Long Short-Term Memory (BiLSTM) network, implemented on the MindSpore framework. Comprehensive experiments were conducted using the NF-BoT-IoT dataset. The results demonstrate that the proposed model achieves 99% across accuracy, precision, recall, and F1-score, indicating its strong performance and robustness in network intrusion detection tasks. 

**Abstract (ZH)**: 随着物联网（IoT）和工业物联网（IIoT）技术的广泛应用，网络架构变得日益复杂，网络流量显著增加。这种演变对传统的安全机制提出了重大挑战，特别是在检测高频率、多样化和隐蔽性强的网络攻击方面。为了应对这些挑战，本研究提出了一种将卷积神经网络（CNN）与双向长短期记忆网络（BiLSTM）相结合的新型网络流量异常检测模型，并在MindSpore框架上实现。通过使用NF-BoT-IoT数据集进行全面实验，结果表明，所提出模型在准确率、精确率、召回率和F1分数上均达到了99%，显示出其在网络入侵检测任务中的强大性能和稳健性。 

---
