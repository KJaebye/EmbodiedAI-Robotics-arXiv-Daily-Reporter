{'arxiv_id': 'arXiv:2507.17727', 'title': 'CA-Cut: Crop-Aligned Cutout for Data Augmentation to Learn More Robust Under-Canopy Navigation', 'authors': 'Robel Mamo, Taeyeong Choi', 'link': 'https://arxiv.org/abs/2507.17727', 'abstract': 'State-of-the-art visual under-canopy navigation methods are designed with deep learning-based perception models to distinguish traversable space from crop rows. While these models have demonstrated successful performance, they require large amounts of training data to ensure reliability in real-world field deployment. However, data collection is costly, demanding significant human resources for in-field sampling and annotation. To address this challenge, various data augmentation techniques are commonly employed during model training, such as color jittering, Gaussian blur, and horizontal flip, to diversify training data and enhance model robustness. In this paper, we hypothesize that utilizing only these augmentation techniques may lead to suboptimal performance, particularly in complex under-canopy environments with frequent occlusions, debris, and non-uniform spacing of crops. Instead, we propose a novel augmentation method, so-called Crop-Aligned Cutout (CA-Cut) which masks random regions out in input images that are spatially distributed around crop rows on the sides to encourage trained models to capture high-level contextual features even when fine-grained information is obstructed. Our extensive experiments with a public cornfield dataset demonstrate that masking-based augmentations are effective for simulating occlusions and significantly improving robustness in semantic keypoint predictions for visual navigation. In particular, we show that biasing the mask distribution toward crop rows in CA-Cut is critical for enhancing both prediction accuracy and generalizability across diverse environments achieving up to a 36.9% reduction in prediction error. In addition, we conduct ablation studies to determine the number of masks, the size of each mask, and the spatial distribution of masks to maximize overall performance.', 'abstract_zh': '利用作物行对齐剪切增强提高森林下视觉导航性能', 'title_zh': '基于作物对齐剪裁的数据增强方法以学习更鲁棒的林下导航'}
{'arxiv_id': 'arXiv:2507.17679', 'title': 'Safety Assurance for Quadrotor Kinodynamic Motion Planning', 'authors': 'Theodoros Tavoulareas, Marzia Cescon', 'link': 'https://arxiv.org/abs/2507.17679', 'abstract': "Autonomous drones have gained considerable attention for applications in real-world scenarios, such as search and rescue, inspection, and delivery. As their use becomes ever more pervasive in civilian applications, failure to ensure safe operation can lead to physical damage to the system, environmental pollution, and even loss of human life. Recent work has demonstrated that motion planning techniques effectively generate a collision-free trajectory during navigation. However, these methods, while creating the motion plans, do not inherently consider the safe operational region of the system, leading to potential safety constraints violation during deployment. In this paper, we propose a method that leverages run time safety assurance in a kinodynamic motion planning scheme to satisfy the system's operational constraints. First, we use a sampling-based geometric planner to determine a high-level collision-free path within a user-defined space. Second, we design a low-level safety assurance filter to provide safety guarantees to the control input of a Linear Quadratic Regulator (LQR) designed with the purpose of trajectory tracking. We demonstrate our proposed approach in a restricted 3D simulation environment using a model of the Crazyflie 2.0 drone.", 'abstract_zh': '自主无人机在实际应用场景中的运动规划方法：运行时安全保证与系统操作约束满足', 'title_zh': '四旋翼飞行器运动规划的安全保障'}
{'arxiv_id': 'arXiv:2507.17649', 'title': 'Event Detection for Active Lower Limb Prosthesis', 'authors': 'J. D. Clark, P. Ellison', 'link': 'https://arxiv.org/abs/2507.17649', 'abstract': 'Accurate event detection is key to the successful design of semi-passive and powered prosthetics. Kinematically, the natural knee is complex, with translation and rotation components that have a substantial impact on gait characteristics. When simplified to a pin joint, some of this behaviour is lost. This study investigates the role of cruciate ligament stretch in event detection. A bicondylar knee design was used, constrained by analogues of the anterior and posterior cruciate ligaments. This offers the ability to characterize knee kinematics by the stretch of the ligaments. The ligament stretch was recorded using LVDTs parallel to the ligaments of the Russell knee on a bent knee crutch. Which was used to capture data on a treadmill at 3 speeds. This study finds speed dependence within the stretch of the cruciate ligaments, prominently around 5\\% and 80\\% of the gait cycle for the posterior and anterior. The cycle profile remains consistent with speed; therefore, other static events such as the turning point feature at around 90\\% and 95\\% of the cycle, for the posterior and anterior, respectively, could be used as a predictive precursor for initial contact. Likewise at 90\\% and 95\\%, another pair of turning points that in this case could be used to predict foot flat. This concludes that the use of a bicondylar knee design could improve the detection of events during the gait cycle, and therefore could increase the accuracy of subsequent controllers for powered prosthetics.', 'abstract_zh': '准确的事件检测是设计半主动和主动假肢的关键。膝关节的自然运动复杂，包括影响步态特征的平移和旋转成分。简化为铰链关节时，会丢失一些行为特征。本研究探讨了交叉韧带拉伸在事件检测中的作用。采用双髁设计，受前后交叉韧带的类比约束，通过测量韧带的拉伸程度来表征膝关节运动。通过Russell膝的拐杖平台上的LVDT记录前后交叉韧带的拉伸情况，并在跑步机上以三种速度采集数据。研究发现，在步态周期的5%和80%左右，前后交叉韧带的拉伸程度存在速度依赖性；步态周期曲线保持一致，因此可以在90%和95%左右的前后步态周期分别使用前后旋转点作为初始接触的预测前兆；同样在90%和95%左右，可以使用另一对旋转点预测足底阶段。研究结论认为，采用双髁设计的膝关节可以改进步态周期中事件的检测，从而提高后续控制系统的准确性。', 'title_zh': '主动下肢假肢的事件检测'}
{'arxiv_id': 'arXiv:2507.17572', 'title': 'KernelSOS for Global Sampling-Based Optimal Control and Estimation via Semidefinite Programming', 'authors': 'Antoine Groudiev, Fabian Schramm, Éloïse Berthier, Justin Carpentier, Frederike Dümbgen', 'link': 'https://arxiv.org/abs/2507.17572', 'abstract': 'Global optimization has gained attraction over the past decades, thanks to the development of both theoretical foundations and efficient numerical routines to cope with optimization problems of various complexities. Among recent methods, Kernel Sum of Squares (KernelSOS) appears as a powerful framework, leveraging the potential of sum of squares methods from the polynomial optimization community with the expressivity of kernel methods widely used in machine learning. This paper applies the kernel sum of squares framework for solving control and estimation problems, which exhibit poor local minima. We demonstrate that KernelSOS performs well on a selection of problems from both domains. In particular, we show that KernelSOS is competitive with other sum of squares approaches on estimation problems, while being applicable to non-polynomial and non-parametric formulations. The sample-based nature of KernelSOS allows us to apply it to trajectory optimization problems with an integrated simulator treated as a black box, both as a standalone method and as a powerful initialization method for local solvers, facilitating the discovery of better solutions.', 'abstract_zh': '全球优化在近几十年来吸引了广泛关注，得益于理论基础和高效数值算法的发展，这些算法能够应对各种复杂性优化问题。近年来，Kernel Sum of Squares (KernelSOS) 出现作为一种强大的框架，结合多项式优化社区的sum of squares方法和机器学习中广泛使用的核方法的表达能力。本文将核sum of squares框架应用于控制和估计问题，这些问题存在较差的局部极小值。我们展示了KernelSOS在控制和估计问题上的优越性能，在估计问题上与现有的sum of squares方法竞争，同时适用于非多项式和非参数化形式。基于样本的特性使得KernelSOS能够作为一种独立方法或局部求解器的强初始化方法，应用于轨迹优化问题，其中集成模拟器被视为黑箱，从而促进更优解的发现。', 'title_zh': '基于半定规划的全局采样最优控制与估计的KernelSOS方法'}
{'arxiv_id': 'arXiv:2507.17561', 'title': 'Robot-mediated physical Human-Human Interaction in Neurorehabilitation: a position paper', 'authors': 'Lorenzo Vianello, Matthew Short, Julia Manczurowsky, Emek Barış Küçüktabak, Francesco Di Tommaso, Alessia Noccaro, Laura Bandini, Shoshana Clark, Alaina Fiorenza, Francesca Lunardini, Alberto Canton, Marta Gandolla, Alessandra L. G. Pedrocchi, Emilia Ambrosini, Manuel Murie-Fernandez, Carmen B. Roman, Jesus Tornero, Natacha Leon, Andrew Sawers, Jim Patton, Domenico Formica, Nevio Luigi Tagliamonte, Georg Rauter, Kilian Baur, Fabian Just, Christopher J. Hasson, Vesna D. Novak, Jose L. Pons', 'link': 'https://arxiv.org/abs/2507.17561', 'abstract': "Neurorehabilitation conventionally relies on the interaction between a patient and a physical therapist. Robotic systems can improve and enrich the physical feedback provided to patients after neurological injury, but they under-utilize the adaptability and clinical expertise of trained therapists. In this position paper, we advocate for a novel approach that integrates the therapist's clinical expertise and nuanced decision-making with the strength, accuracy, and repeatability of robotics: Robot-mediated physical Human-Human Interaction. This framework, which enables two individuals to physically interact through robotic devices, has been studied across diverse research groups and has recently emerged as a promising link between conventional manual therapy and rehabilitation robotics, harmonizing the strengths of both approaches. This paper presents the rationale of a multidisciplinary team-including engineers, doctors, and physical therapists-for conducting research that utilizes: a unified taxonomy to describe robot-mediated rehabilitation, a framework of interaction based on social psychology, and a technological approach that makes robotic systems seamless facilitators of natural human-human interaction.", 'abstract_zh': '神经康复 conventionally 依赖患者与物理治疗师的互动。机器人系统可以改善和丰富神经损伤后患者获得的物理反馈，但它们未能充分利用训练有素治疗师的适应性和临床专长。在本文中，我们提倡一种新方法，将治疗师的临床专长和细腻的决策与机器人技术的强大力量、精度和可重复性相结合：通过机器人介导的物理人-人互动。该框架通过机器人设备使两人能够进行物理互动，并已在多种研究团队中进行研究，最近已成为传统手工疗法和康复机器人之间有希望的联系，和谐结合了这两种方法的优势。本文阐述了一个跨学科团队（包括工程师、医生和物理治疗师）进行利用统一的康复机器人描述分类法、基于社会心理学的互动框架和技术方法，使机器人系统成为自然人-人互动无缝促进者的研究理据。', 'title_zh': '基于robots的物理人与人之间交互在神经康复中的应用：一个立场论文'}
{'arxiv_id': 'arXiv:2507.17531', 'title': 'When and Where Localization Fails: An Analysis of the Iterative Closest Point in Evolving Environment', 'authors': 'Abdel-Raouf Dannaoui, Johann Laconte, Christophe Debain, Francois Pomerleau, Paul Checchin', 'link': 'https://arxiv.org/abs/2507.17531', 'abstract': 'Robust relocalization in dynamic outdoor environments remains a key challenge for autonomous systems relying on 3D lidar. While long-term localization has been widely studied, short-term environmental changes, occurring over days or weeks, remain underexplored despite their practical significance. To address this gap, we present a highresolution, short-term multi-temporal dataset collected weekly from February to April 2025 across natural and semi-urban settings. Each session includes high-density point cloud maps, 360 deg panoramic images, and trajectory data. Projected lidar scans, derived from the point cloud maps and modeled with sensor-accurate occlusions, are used to evaluate alignment accuracy against the ground truth using two Iterative Closest Point (ICP) variants: Point-to-Point and Point-to-Plane. Results show that Point-to-Plane offers significantly more stable and accurate registration, particularly in areas with sparse features or dense vegetation. This study provides a structured dataset for evaluating short-term localization robustness, a reproducible framework for analyzing scan-to-map alignment under noise, and a comparative evaluation of ICP performance in evolving outdoor environments. Our analysis underscores how local geometry and environmental variability affect localization success, offering insights for designing more resilient robotic systems.', 'abstract_zh': '动态室外环境中鲁棒重定位仍然是依赖3D激光雷达的自主系统的一个关键挑战。尽管长期定位已被广泛研究，但发生在几天或几周内的短期环境变化仍未得到充分探索，尽管其具有重要的实际意义。为填补这一空白，我们提出了一个高分辨率的短期多时态数据集，该数据集从2025年2月到4月每周收集数据，覆盖自然和半城市环境。每个会话包括高密度点云地图、360度全景图像和轨迹数据。从点云地图中衍生出的投影激光雷达扫描，通过传感器准确的遮挡模型进行建模，并使用两种迭代最近点（ICP）变体（点到点和点到面）与地面 truth 进行对齐准确性的评估。结果表明，点到面在特征稀疏或植被密集的区域提供了显著更加稳定和准确的注册。本研究提供了一个结构化的数据集，用于评估短期定位的鲁棒性，一个在噪声下分析扫描到地图对齐的可重复框架，以及在演变的室外环境中ICP性能的比较评估。分析强调了局部几何形状和环境变化如何影响定位成功，为设计更具弹性的机器人系统提供了见解。', 'title_zh': '当局部化失败以及迭代最近点在演变环境中的分析'}
{'arxiv_id': 'arXiv:2507.17520', 'title': 'InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation', 'authors': 'Shuai Yang, Hao Li, Yilun Chen, Bin Wang, Yang Tian, Tai Wang, Hanqing Wang, Feng Zhao, Yiyi Liao, Jiangmiao Pang', 'link': 'https://arxiv.org/abs/2507.17520', 'abstract': "To operate effectively in the real world, robots must integrate multimodal reasoning with precise action generation. However, existing vision-language-action (VLA) models often sacrifice one for the other, narrow their abilities to task-specific manipulation data, and suffer catastrophic forgetting of pre-trained vision-language capabilities. To bridge this gap, we introduce InstructVLA, an end-to-end VLA model that preserves the flexible reasoning of large vision-language models (VLMs) while delivering leading manipulation performance. InstructVLA introduces a novel training paradigm, Vision-Language-Action Instruction Tuning (VLA-IT), which employs multimodal training with mixture-of-experts adaptation to jointly optimize textual reasoning and action generation on both standard VLM corpora and a curated 650K-sample VLA-IT dataset. On in-domain SimplerEnv tasks, InstructVLA achieves 30.5% improvement over SpatialVLA. To evaluate generalization, we introduce SimplerEnv-Instruct, an 80-task benchmark requiring closed-loop control and high-level instruction understanding, where it outperforms a fine-tuned OpenVLA by 92% and an action expert aided by GPT-4o by 29%. Additionally, InstructVLA surpasses baseline VLMs on multimodal tasks and exhibits inference-time scaling by leveraging textual reasoning to boost manipulation performance in both simulated and real-world settings. These results demonstrate InstructVLA's potential for bridging intuitive and steerable human-robot interaction with efficient policy learning.", 'abstract_zh': '基于指令的多模态视觉-语言-动作模型：融合灵活推理与精准操作能力', 'title_zh': 'InstructVLA：从理解到操作的视觉-语言-动作指令调优'}
{'arxiv_id': 'arXiv:2507.17519', 'title': 'Terrain-Aware Adaptation for Two-Dimensional UAV Path Planners', 'authors': 'Kostas Karakontis, Thanos Petsanis, Athanasios Ch. Kapoutsis, Pavlos Ch. Kapoutsis, Elias B. Kosmatopoulos', 'link': 'https://arxiv.org/abs/2507.17519', 'abstract': 'Multi-UAV Coverage Path Planning (mCPP) algorithms in popular commercial software typically treat a Region of Interest (RoI) only as a 2D plane, ignoring important3D structure characteristics. This leads to incomplete 3Dreconstructions, especially around occluded or vertical surfaces. In this paper, we propose a modular algorithm that can extend commercial two-dimensional path planners to facilitate terrain-aware planning by adjusting altitude and camera orientations. To demonstrate it, we extend the well-known DARP (Divide Areas for Optimal Multi-Robot Coverage Path Planning) algorithm and produce DARP-3D. We present simulation results in multiple 3D environments and a real-world flight test using DJI hardware. Compared to baseline, our approach consistently captures improved 3D reconstructions, particularly in areas with significant vertical features. An open-source implementation of the algorithm is available here:this https URL', 'abstract_zh': '多无人机覆盖路径规划（mCPP）中，商业软件通常仅将研究区域（RoI）视为2D平面，忽视了重要的3D结构特征。这导致在遮挡或垂直表面附近的3D重建不完整。本文提出了一种模块化算法，可以扩展商业2D路径规划器，通过调整高度和相机方向来实现地形感知规划。通过将其应用于著名算法DARP（Divide Areas for Optimal Multi-Robot Coverage Path Planning），我们产生了DARP-3D。我们在多个3D环境和使用DJI硬件的实地飞行测试中展示了仿真结果。与基线方法相比，我们的方法在具有显著垂直特征的区域中一致性地提高了3D重建的质量。该算法的开源实现可在以下链接获取：this https URL。', 'title_zh': 'Terrain-Aware Adaptation for Two-Dimensional UAV Path Plannerstranslated into中文为：地形意识自适应二维无人机路径规划者'}
{'arxiv_id': 'arXiv:2507.17445', 'title': "IndoorBEV: Joint Detection and Footprint Completion of Objects via Mask-based Prediction in Indoor Scenarios for Bird's-Eye View Perception", 'authors': 'Haichuan Li, Changda Tian, Panos Trahanias, Tomi Westerlund', 'link': 'https://arxiv.org/abs/2507.17445', 'abstract': "Detecting diverse objects within complex indoor 3D point clouds presents significant challenges for robotic perception, particularly with varied object shapes, clutter, and the co-existence of static and dynamic elements where traditional bounding box methods falter. To address these limitations, we propose IndoorBEV, a novel mask-based Bird's-Eye View (BEV) method for indoor mobile robots.\nIn a BEV method, a 3D scene is projected into a 2D BEV grid which handles naturally occlusions and provides a consistent top-down view aiding to distinguish static obstacles from dynamic agents. The obtained 2D BEV results is directly usable to downstream robotic tasks like navigation, motion prediction, and planning. Our architecture utilizes an axis compact encoder and a window-based backbone to extract rich spatial features from this BEV map. A query-based decoder head then employs learned object queries to concurrently predict object classes and instance masks in the BEV space. This mask-centric formulation effectively captures the footprint of both static and dynamic objects regardless of their shape, offering a robust alternative to bounding box regression. We demonstrate the effectiveness of IndoorBEV on a custom indoor dataset featuring diverse object classes including static objects\nand dynamic elements like robots and miscellaneous items, showcasing its potential for robust indoor scene understanding.", 'abstract_zh': '室内复杂三维点云中检测多样化对象对机器人感知提出了显著挑战，特别是在多变的对象形状、杂乱环境以及静动态元素共存的情况下，传统边界框方法表现不佳。为解决这些局限性，我们提出了一种新的基于掩码的鸟瞰图(BEV)方法—IndoorBEV，适用于室内移动机器人。', 'title_zh': '室内外BEV：基于掩码预测的室内场景鸟瞰图感知中对象的联合检测与足迹完成'}
{'arxiv_id': 'arXiv:2507.17401', 'title': 'The Wilhelm Tell Dataset of Affordance Demonstrations', 'authors': 'Rachel Ringe, Mihai Pomarlan, Nikolaos Tsiogkas, Stefano De Giorgis, Maria Hedblom, Rainer Malaka', 'link': 'https://arxiv.org/abs/2507.17401', 'abstract': 'Affordances - i.e. possibilities for action that an environment or objects in it provide - are important for robots operating in human environments to perceive. Existing approaches train such capabilities on annotated static images or shapes. This work presents a novel dataset for affordance learning of common household tasks. Unlike previous approaches, our dataset consists of video sequences demonstrating the tasks from first- and third-person perspectives, along with metadata about the affordances that are manifested in the task, and is aimed towards training perception systems to recognize affordance manifestations. The demonstrations were collected from several participants and in total record about seven hours of human activity. The variety of task performances also allows studying preparatory maneuvers that people may perform for a task, such as how they arrange their task space, which is also relevant for collaborative service robots.', 'abstract_zh': '环境提供的功能（即环境或其中物体提供的行动可能性）对于机器人在人类环境中操作非常重要。现有的方法通过标注静态图像或形状来训练这些能力。本研究提出了一种新的数据集，用于学习常见家庭任务的功能。不同于先前的方法，我们的数据集包括从第一人称和第三人称视角展示任务的视频序列，以及任务中表现的功能的元数据，并旨在训练感知系统以识别功能的体现。演示从多个参与者处收集，总共记录了大约七小时的人类活动。任务执行的多样性还允许研究人们为任务可能进行的预备动作，如他们如何规划任务空间，这也对协作服务机器人很重要。', 'title_zh': 'William Tell数据集中的功能演示'}
{'arxiv_id': 'arXiv:2507.17383', 'title': 'Confidence Calibration in Vision-Language-Action Models', 'authors': 'Thomas P Zollo, Richard Zemel', 'link': 'https://arxiv.org/abs/2507.17383', 'abstract': 'Trustworthy robot behavior requires not only high levels of task success but also that the robot can reliably quantify how likely it is to succeed. To this end, we present the first systematic study of confidence calibration in vision-language-action (VLA) foundation models, which map visual observations and natural-language instructions to low-level robot motor commands. We begin with extensive benchmarking to understand the critical relationship between task success and calibration error across multiple datasets and VLA variants, finding that task performance and calibration are not in tension. Next, we introduce prompt ensembles for VLAs, a lightweight, Bayesian-inspired algorithm that averages confidence across paraphrased instructions and consistently improves calibration. We further analyze calibration over the task time horizon, showing that confidence is often most reliable after making some progress, suggesting natural points for risk-aware intervention. Finally, we reveal differential miscalibration across action dimensions and propose action-wise Platt scaling, a method to recalibrate each action dimension independently to produce better confidence estimates. Our aim in this study is to begin to develop the tools and conceptual understanding necessary to render VLAs both highly performant and highly trustworthy via reliable uncertainty quantification.', 'abstract_zh': '可信的机器人行为不仅需要高任务成功率，还需要机器人能够可靠地量化其成功概率的可信度。为此，我们首次系统研究了视觉-语言-行动（VLA）基础模型中的信心校准问题，这些模型将视觉观测和自然语言指令映射到低级机器人动作命令。我们首先通过广泛的基准测试来理解任务成功与校准误差之间的关键关系，跨越多个数据集和VLA变体，发现任务性能和校准之间不存在冲突。接着，我们引入了视觉-语言-行动提示集合，这是一种轻量级、借鉴贝叶斯思想的算法，通过平均措辞相似指令的信心值来持续改进校准。我们进一步分析了任务时间范围内的校准情况，发现通常是在取得一定进展后信心最为可靠，这表明了风险感知干预的自然时机。最后，我们揭示了不同行动维度上的差异性校准偏差，并提出了按行动维度再校准的方法，该方法可以独立校准每个行动维度，以生成更好的信心估计。我们在此研究中的目标是开始开发必要的工具和概念理解，通过可靠的不确定性量化使VLA在性能和可信度方面达到高度。', 'title_zh': '视觉-语言-行动模型的置信度校准'}
{'arxiv_id': 'arXiv:2507.17379', 'title': 'Language-Conditioned Open-Vocabulary Mobile Manipulation with Pretrained Models', 'authors': 'Shen Tan, Dong Zhou, Xiangyu Shao, Junqiao Wang, Guanghui Sun', 'link': 'https://arxiv.org/abs/2507.17379', 'abstract': 'Open-vocabulary mobile manipulation (OVMM) that involves the handling of novel and unseen objects across different workspaces remains a significant challenge for real-world robotic applications. In this paper, we propose a novel Language-conditioned Open-Vocabulary Mobile Manipulation framework, named LOVMM, incorporating the large language model (LLM) and vision-language model (VLM) to tackle various mobile manipulation tasks in household environments. Our approach is capable of solving various OVMM tasks with free-form natural language instructions (e.g. "toss the food boxes on the office room desk to the trash bin in the corner", and "pack the bottles from the bed to the box in the guestroom"). Extensive experiments simulated in complex household environments show strong zero-shot generalization and multi-task learning abilities of LOVMM. Moreover, our approach can also generalize to multiple tabletop manipulation tasks and achieve better success rates compared to other state-of-the-art methods.', 'abstract_zh': '面向开放词汇的移动 manipulation (OVMM)：一种结合大规模语言模型和视觉语言模型的语言条件化开放词汇移动 manipulation 框架', 'title_zh': '基于预训练模型的语言条件化开放词汇移动操作'}
{'arxiv_id': 'arXiv:2507.17376', 'title': 'An Exploratory Study on Human-Robot Interaction using Semantics-based Situational Awareness', 'authors': 'Tianshu Ruan, Aniketh Ramesh, Rustam Stolkin, Manolis Chiou', 'link': 'https://arxiv.org/abs/2507.17376', 'abstract': "In this paper, we investigate the impact of high-level semantics (evaluation of the environment) on Human-Robot Teams (HRT) and Human-Robot Interaction (HRI) in the context of mobile robot deployments. Although semantics has been widely researched in AI, how high-level semantics can benefit the HRT paradigm is underexplored, often fuzzy, and intractable. We applied a semantics-based framework that could reveal different indicators of the environment (i.e. how much semantic information exists) in a mock-up disaster response mission. In such missions, semantics are crucial as the HRT should handle complex situations and respond quickly with correct decisions, where humans might have a high workload and stress. Especially when human operators need to shift their attention between robots and other tasks, they will struggle to build Situational Awareness (SA) quickly. The experiment suggests that the presented semantics: 1) alleviate the perceived workload of human operators; 2) increase the operator's trust in the SA; and 3) help to reduce the reaction time in switching the level of autonomy when needed. Additionally, we find that participants with higher trust in the system are encouraged by high-level semantics to use teleoperation mode more.", 'abstract_zh': '基于高阶语义对移动机器人部署环境下人机团队和人机交互的影响研究', 'title_zh': '基于语义的情境意识探索性研究：人机交互'}
{'arxiv_id': 'arXiv:2507.17338', 'title': 'Mobile Manipulation with Active Inference for Long-Horizon Rearrangement Tasks', 'authors': 'Corrado Pezzato, Ozan Çatal, Toon Van de Maele, Riddhi J. Pitliya, Tim Verbelen', 'link': 'https://arxiv.org/abs/2507.17338', 'abstract': 'Despite growing interest in active inference for robotic control, its application to complex, long-horizon tasks remains untested. We address this gap by introducing a fully hierarchical active inference architecture for goal-directed behavior in realistic robotic settings. Our model combines a high-level active inference model that selects among discrete skills realized via a whole-body active inference controller. This unified approach enables flexible skill composition, online adaptability, and recovery from task failures without requiring offline training. Evaluated on the Habitat Benchmark for mobile manipulation, our method outperforms state-of-the-art baselines across the three long-horizon tasks, demonstrating for the first time that active inference can scale to the complexity of modern robotics benchmarks.', 'abstract_zh': '尽管人们对在机器人控制中应用主动推断表现出浓厚兴趣，但其在复杂、长时 horizon 任务中的应用尚未得到验证。我们通过引入一种面向现实机器人环境的目标导向行为全层级主动推断架构来填补这一空白。该模型结合了高层主动推断模型和全身主动推断控制器实现的离散技能选择，这种统一的方法能够实现灵活的技能组合、在线适应性并在不需离线训练的情况下从任务失败中恢复。在 Habitat 移动操作基准测试中，我们的方法在三个长时 horizon 任务上的表现优于最新基线，首次证明了主动推断可以扩展到现代机器人基准的复杂性。', 'title_zh': '基于主动推断的移动操作 dài 期重构任务'}
{'arxiv_id': 'arXiv:2507.17317', 'title': 'HuNavSim 2.0', 'authors': 'Miguel Escudero-Jiménez, Noé Pérez-Higueras, Andrés Martínez-Silva, Fernando Caballero, Luis Merino', 'link': 'https://arxiv.org/abs/2507.17317', 'abstract': 'This work presents a new iteration of the Human Navigation Simulator (HuNavSim), a novel open-source tool for the simulation of different human-agent navigation behaviors in scenarios with mobile robots. The tool, programmed under the ROS 2 framework, can be used together with different well-known robotics simulators such as Gazebo or NVidia Isaac Sim. The main goal is to facilitate the development and evaluation of human-aware robot navigation systems in simulation. In this new version, several features have been improved and new ones added, such as the extended set of actions and conditions that can be combined in Behavior Trees to compound complex and realistic human behaviors.', 'abstract_zh': '本工作呈现了人类导航模拟器（HuNavSim）的新版本，这是一种新型开源工具，用于模拟不同的人机导航行为，适用于移动机器人场景的仿真。该工具基于ROS 2框架，可以与Gazebo或NVidia Isaac Sim等不同的知名机器人仿真器配合使用。主要目标是促进具有人类意识的机器人导航系统的开发和评估。在这一新版本中，已改进了多项功能并新增了一些功能，例如扩展了可以组合在行为树中的动作和条件集，以合成复杂的现实人类行为。', 'title_zh': 'HuNavSim 2.0'}
{'arxiv_id': 'arXiv:2507.17294', 'title': 'VLA-Touch: Enhancing Vision-Language-Action Models with Dual-Level Tactile Feedback', 'authors': 'Jianxin Bi, Kevin Yuchen Ma, Ce Hao, Mike Zheng Shou, Harold Soh', 'link': 'https://arxiv.org/abs/2507.17294', 'abstract': 'Tactile feedback is generally recognized to be crucial for effective interaction with the physical world. However, state-of-the-art Vision-Language-Action (VLA) models lack the ability to interpret and use tactile signals, limiting their effectiveness in contact-rich tasks. Incorporating tactile feedback into these systems is challenging due to the absence of large multi-modal datasets. We present VLA-Touch, an approach that enhances generalist robot policies with tactile sensing \\emph{without fine-tuning} the base VLA. Our method introduces two key innovations: (1) a pipeline that leverages a pretrained tactile-language model that provides semantic tactile feedback for high-level task planning, and (2) a diffusion-based controller that refines VLA-generated actions with tactile signals for contact-rich manipulation. Through real-world experiments, we demonstrate that our dual-level integration of tactile feedback improves task planning efficiency while enhancing execution precision. Code is open-sourced at \\href{this https URL}{this URL}.', 'abstract_zh': '触觉反馈通常被认定为与物理世界有效交互的关键。然而，最先进的视觉-语言-动作（VLA）模型缺乏解释和利用触觉信号的能力，限制了其在接触密集型任务中的有效性。由于缺乏大规模多模态数据集，将触觉反馈纳入这些系统具有挑战性。我们提出了VLA-Touch方法，该方法在不微调基VLA模型的情况下，增强通用机器人策略的触觉感知能力。我们的方法引入了两项关键创新：（1）一个利用预训练触觉-语言模型的流水线，该模型为高层任务规划提供语义触觉反馈；（2）一种基于扩散的控制器，该控制器使用触觉信号细化VLA生成的动作，以适应接触密集型操作。通过实际实验，我们展示了我们的多级触觉反馈集成提高了任务规划效率并增强了执行精度。代码已在<此网址>开源。', 'title_zh': 'VLA-触觉: 通过双层触觉反馈提升视觉-语言-动作模型'}
{'arxiv_id': 'arXiv:2507.17275', 'title': 'Prolonging Tool Life: Learning Skillful Use of General-purpose Tools through Lifespan-guided Reinforcement Learning', 'authors': 'Po-Yen Wu, Cheng-Yu Kuo, Yuki Kadokawa, Takamitsu Matsubara', 'link': 'https://arxiv.org/abs/2507.17275', 'abstract': "In inaccessible environments with uncertain task demands, robots often rely on general-purpose tools that lack predefined usage strategies. These tools are not tailored for particular operations, making their longevity highly sensitive to how they are used. This creates a fundamental challenge: how can a robot learn a tool-use policy that both completes the task and prolongs the tool's lifespan? In this work, we address this challenge by introducing a reinforcement learning (RL) framework that incorporates tool lifespan as a factor during policy optimization. Our framework leverages Finite Element Analysis (FEA) and Miner's Rule to estimate Remaining Useful Life (RUL) based on accumulated stress, and integrates the RUL into the RL reward to guide policy learning toward lifespan-guided behavior. To handle the fact that RUL can only be estimated after task execution, we introduce an Adaptive Reward Normalization (ARN) mechanism that dynamically adjusts reward scaling based on estimated RULs, ensuring stable learning signals. We validate our method across simulated and real-world tool use tasks, including Object-Moving and Door-Opening with multiple general-purpose tools. The learned policies consistently prolong tool lifespan (up to 8.01x in simulation) and transfer effectively to real-world settings, demonstrating the practical value of learning lifespan-guided tool use strategies.", 'abstract_zh': '在难以进入的环境中且任务需求不确定的情况下，机器人通常依赖于缺乏预定义使用策略的一般用途工具。这些工具未针对特定操作进行定制，使其使用寿命高度依赖于使用方式。这引发了一个基本挑战：机器人如何学习一种既能完成任务又能延长工具寿命的工具使用策略？在这项工作中，我们通过引入一个将工具寿命纳入策略优化过程的强化学习（RL）框架来应对这一挑战。该框架利用有限元分析（FEA）和 Miner’s Rule 来基于积累的应力估算剩余使用寿命（RUL），并将RUL整合到RL奖励中，以引导政策学习朝着寿命导向的行为。为处理在任务执行后才能估算RUL的情况，我们引入了一种自适应奖励归一化（ARN）机制，该机制根据估计的RUL动态调整奖励缩放，确保学习信号的稳定性。我们在模拟和真实世界工具使用任务中验证了该方法，包括涉及多种一般用途工具的Object-Moving和Door-Opening任务。学习到的策略一致地延长了工具寿命（在模拟中最多延长8.01倍），并在现实世界环境中有效转移，展示了学习寿命导向的工具使用策略的实用价值。', 'title_zh': '延长工具寿命：通过生命周期导向的强化学习学习高效使用通用工具的方法'}
{'arxiv_id': 'arXiv:2507.17253', 'title': 'Optimizing Delivery Logistics: Enhancing Speed and Safety with Drone Technology', 'authors': 'Maharshi Shastri, Ujjval Shrivastav', 'link': 'https://arxiv.org/abs/2507.17253', 'abstract': 'The increasing demand for fast and cost effective last mile delivery solutions has catalyzed significant advancements in drone based logistics. This research describes the development of an AI integrated drone delivery system, focusing on route optimization, object detection, secure package handling, and real time tracking. The proposed system leverages YOLOv4 Tiny for object detection, the NEO 6M GPS module for navigation, and the A7670 SIM module for real time communication. A comparative analysis of lightweight AI models and hardware components is conducted to determine the optimal configuration for real time UAV based delivery. Key challenges including battery efficiency, regulatory compliance, and security considerations are addressed through the integration of machine learning techniques, IoT devices, and encryption protocols. Preliminary studies demonstrate improvement in delivery time compared to conventional ground based logistics, along with high accuracy recipient authentication through facial recognition. The study also discusses ethical implications and societal acceptance of drone deliveries, ensuring compliance with FAA, EASA and DGCA regulatory standards. Note: This paper presents the architecture, design, and preliminary simulation results of the proposed system. Experimental results, simulation benchmarks, and deployment statistics are currently being acquired. A comprehensive analysis will be included in the extended version of this work.', 'abstract_zh': '基于AI的无人机配送系统开发：路径优化、物体检测、安全包裹处理及实时追踪的研究', 'title_zh': '优化配送物流：无人机技术提升速度与安全'}
{'arxiv_id': 'arXiv:2507.17210', 'title': 'FAST-Calib: LiDAR-Camera Extrinsic Calibration in One Second', 'authors': 'Chunran Zheng, Fu Zhang', 'link': 'https://arxiv.org/abs/2507.17210', 'abstract': 'This paper proposes FAST-Calib, a fast and user-friendly LiDAR-camera extrinsic calibration tool based on a custom-made 3D target. FAST-Calib supports both mechanical and solid-state LiDARs by leveraging an efficient and reliable edge extraction algorithm that is agnostic to LiDAR scan patterns. It also compensates for edge dilation artifacts caused by LiDAR spot spread through ellipse fitting, and supports joint optimization across multiple scenes. We validate FAST-Calib on three LiDAR models (Ouster, Avia, and Mid360), each paired with a wide-angle camera. Experimental results demonstrate superior accuracy and robustness compared to existing methods. With point-to-point registration errors consistently below 6.5mm and total processing time under 0.7s, FAST-Calib provides an efficient, accurate, and target-based automatic calibration pipeline. We have open-sourced our code and dataset on GitHub to benefit the robotics community.', 'abstract_zh': 'FAST-Calib：一种基于自定义3D目标的快速用户友好型LiDAR-相机外参校准工具', 'title_zh': 'FAST-Calib: lidar-camera 外参标定一秒完成'}
{'arxiv_id': 'arXiv:2507.17163', 'title': 'Reconfigurable Tendon-Driven Robots: Eliminating Inter-segmental Coupling via Independently Lockable Joints', 'authors': 'Botao Lin, Shuang Song, Jiaole Wang', 'link': 'https://arxiv.org/abs/2507.17163', 'abstract': "With a slender redundant body, the tendon-driven robot (TDR) has a large workspace and great maneuverability while working in complex environments. TDR comprises multiple independently controlled robot segments, each with a set of driving tendons. While increasing the number of robot segments enhances dexterity and expands the workspace, this structural expansion also introduces intensified inter-segmental coupling. Therefore, achieving precise TDR control requires more complex models and additional motors. This paper presents a reconfigurable tendon-driven robot (RTR) equipped with innovative lockable joints. Each joint's state (locked/free) can be individually controlled through a pair of antagonistic tendons, and its structure eliminates the need for a continuous power supply to maintain the state. Operators can selectively actuate the targeted robot segments, and this scheme fundamentally eliminates the inter-segmental coupling, thereby avoiding the requirement for complex coordinated control between segments. The workspace of RTR has been simulated and compared with traditional TDRs' workspace, and RTR's advantages are further revealed. The kinematics and statics models of the RTR have been derived and validation experiments have been conducted. Demonstrations have been performed using a seven-joint RTR prototype to show its reconfigurability and moving ability in complex environments with an actuator pack comprising only six motors.", 'abstract_zh': '一种配备可锁定关节的可重构腱驱机器人及其在复杂环境中的应用', 'title_zh': '可重构肌腱驱动机器人：通过可独立锁定的关节消除节段间耦合'}
{'arxiv_id': 'arXiv:2507.17152', 'title': 'JAM: Keypoint-Guided Joint Prediction after Classification-Aware Marginal Proposal for Multi-Agent Interaction', 'authors': 'Fangze Lin, Ying He, Fei Yu, Hong Zhang', 'link': 'https://arxiv.org/abs/2507.17152', 'abstract': 'Predicting the future motion of road participants is a critical task in autonomous driving. In this work, we address the challenge of low-quality generation of low-probability modes in multi-agent joint prediction. To tackle this issue, we propose a two-stage multi-agent interactive prediction framework named \\textit{keypoint-guided joint prediction after classification-aware marginal proposal} (JAM). The first stage is modeled as a marginal prediction process, which classifies queries by trajectory type to encourage the model to learn all categories of trajectories, providing comprehensive mode information for the joint prediction module. The second stage is modeled as a joint prediction process, which takes the scene context and the marginal proposals from the first stage as inputs to learn the final joint distribution. We explicitly introduce key waypoints to guide the joint prediction module in better capturing and leveraging the critical information from the initial predicted trajectories. We conduct extensive experiments on the real-world Waymo Open Motion Dataset interactive prediction benchmark. The results show that our approach achieves competitive performance. In particular, in the framework comparison experiments, the proposed JAM outperforms other prediction frameworks and achieves state-of-the-art performance in interactive trajectory prediction. The code is available at this https URL to facilitate future research.', 'abstract_zh': '基于分类感知边际 Proposal 和关键点引导的多Agent联合预测框架（JAM）：面向互动轨迹预测的未来道路参与者运动预测', 'title_zh': 'JAM：分类意识边缘提议引导的关键点导向联合预测多智能体交互'}
{'arxiv_id': 'arXiv:2507.17144', 'title': 'Falconry-like palm landing by a flapping-wing drone based on the human gesture interaction and distance-aware flight planning', 'authors': 'Kazuki Numazato, Keiichiro Kan, Masaki Kitagawa, Yunong Li, Johannes Kubel, Moju Zhao', 'link': 'https://arxiv.org/abs/2507.17144', 'abstract': "Flapping-wing drones have attracted significant attention due to their biomimetic flight. They are considered more human-friendly due to their characteristics such as low noise and flexible wings, making them suitable for human-drone interactions. However, few studies have explored the practical interaction between humans and flapping-wing drones. On establishing a physical interaction system with flapping-wing drones, we can acquire inspirations from falconers who guide birds of prey to land on their arms. This interaction interprets the human body as a dynamic landing platform, which can be utilized in various scenarios such as crowded or spatially constrained environments. Thus, in this study, we propose a falconry-like interaction system in which a flapping-wing drone performs a palm landing motion on a human hand. To achieve a safe approach toward humans, we design a trajectory planning method that considers both physical and psychological factors of the human safety such as the drone's velocity and distance from the user. We use a commercial flapping platform with our implemented motion planning and conduct experiments to evaluate the palm landing performance and safety. The results demonstrate that our approach enables safe and smooth hand landing interactions. To the best of our knowledge, it is the first time to achieve a contact-based interaction between flapping-wing drones and humans.", 'abstract_zh': '仿生扑翼无人机与人体的猎鹰式互动研究', 'title_zh': '基于人体手势交互和距离感知飞行规划的拍翼无人机类似猎鹰抓握的掌落地技术'}
{'arxiv_id': 'arXiv:2507.17141', 'title': 'Towards Human-level Intelligence via Human-like Whole-Body Manipulation', 'authors': 'Guang Gao, Jianan Wang, Jinbo Zuo, Junnan Jiang, Jingfan Zhang, Xianwen Zeng, Yuejiang Zhu, Lianyang Ma, Ke Chen, Minhua Sheng, Ruirui Zhang, Zhaohui An', 'link': 'https://arxiv.org/abs/2507.17141', 'abstract': "Building general-purpose intelligent robots has long been a fundamental goal of robotics. A promising approach is to mirror the evolutionary trajectory of humans: learning through continuous interaction with the environment, with early progress driven by the imitation of human behaviors. Achieving this goal presents three core challenges: (1) designing safe robotic hardware with human-level physical capabilities; (2) developing an intuitive and scalable whole-body teleoperation interface for data collection; and (3) creating algorithms capable of learning whole-body visuomotor policies from human demonstrations. To address these challenges in a unified framework, we propose Astribot Suite, a robot learning suite for whole-body manipulation aimed at general daily tasks across diverse environments. We demonstrate the effectiveness of our system on a wide range of activities that require whole-body coordination, extensive reachability, human-level dexterity, and agility. Our results show that Astribot's cohesive integration of embodiment, teleoperation interface, and learning pipeline marks a significant step towards real-world, general-purpose whole-body robotic manipulation, laying the groundwork for the next generation of intelligent robots.", 'abstract_zh': '构建通用智能机器人一直是机器人领域的基本目标。一种有前途的方法是模仿人类的进化轨迹：通过持续与环境互动来学习，早期进步主要通过模仿人类行为实现。实现这一目标面临三大核心挑战：（1）设计具有人类级物理能力的安全机器人硬件；（2）开发直观且可扩展的整体远程操作界面以收集数据；（3）创建能够从人类示范中学习整体体感运动策略的算法。为统一解决这些挑战，我们提出Astribot Suite，一个旨在实现跨不同环境日常任务的整体体感操作学习套件。我们通过一系列需要整体协调、广泛可达性、人类级灵巧性和敏捷性的活动展示了我们系统的有效性。结果显示，Astribot整合了体态、远程操控界面和学习流程，标志着向实用的、通用的整体体感操作机器人方向迈出重要一步，为下一代智能机器人奠定了基础。', 'title_zh': '通过类人全身操作迈向人类水平的智能'}
{'arxiv_id': 'arXiv:2507.17140', 'title': 'Multi-Objective Trajectory Planning for a Robotic Arm in Curtain Wall Installation', 'authors': 'Xiao Liu, Yunxiao Cheng, Weijun Wang, Tianlun Huang, Zhiyong Wang, Wei Feng', 'link': 'https://arxiv.org/abs/2507.17140', 'abstract': 'In the context of labor shortages and rising costs, construction robots are regarded as the key to revolutionizing traditional construction methods and improving efficiency and quality in the construction industry. In order to ensure that construction robots can perform tasks efficiently and accurately in complex construction environments, traditional single-objective trajectory optimization methods are difficult to meet the complex requirements of the changing construction environment. Therefore, we propose a multi-objective trajectory optimization for the robotic arm used in the curtain wall installation. First, we design a robotic arm for curtain wall installation, integrating serial, parallel, and folding arm elements, while considering its physical properties and motion characteristics. In addition, this paper proposes an NSGA-III-FO algorithm (NSGA-III with Focused Operator, NSGA-III-FO) that incorporates a focus operator screening mechanism to accelerate the convergence of the algorithm towards the Pareto front, thereby effectively balancing the multi-objective constraints of construction robots. The proposed algorithm is tested against NSGA-III, MOEA/D, and MSOPS-II in ten consecutive trials on the DTLZ3 and WFG3 test functions, showing significantly better convergence efficiency than the other algorithms. Finally, we conduct two sets of experiments on the designed robotic arm platform, which confirm the efficiency and practicality of the NSGA-III-FO algorithm in solving multi-objective trajectory planning problems for curtain wall installation tasks.', 'abstract_zh': '在劳动力短缺和成本上升的背景下，建筑机器人被视为革命传统建筑方法、提高建筑行业效率和质量的关键。为了确保建筑机器人能够在复杂的建筑环境中高效准确地完成任务，传统的单目标轨迹优化方法难以满足变化的建筑环境的复杂要求。因此，我们提出了一种针对幕墙安装使用的机器人手臂的多目标轨迹优化方法。首先，我们设计了一个集串联、并联和折叠臂元件于一体的机器人手臂，同时考虑了其物理特性和运动特性。此外，本文提出了一种NSGA-III-FO算法（NSGA-III带焦点操作员，NSGA-III-FO），该算法结合了一种焦点操作员筛选机制以加快算法向帕特奥前沿的收敛速度，从而有效地平衡建筑机器人的多目标约束。提出的算法在DTLZ3和WFG3测试函数上进行了十次连续试验，显示出比其他算法更高的收敛效率。最后，我们在设计的机器人手臂平台上进行了两组实验，确认NSGA-III-FO算法在解决幕墙安装任务的多目标轨迹规划问题中的高效性和实用性。', 'title_zh': '幕墙安装中机器人手臂多目标轨迹规划'}
{'arxiv_id': 'arXiv:2507.17136', 'title': 'Dynamic Parameter Identification of a Curtain Wall Installation Robotic Arm', 'authors': 'Xiao Liu, Yunxiao Cheng, Weijun Wang, Tianlun Huang, Wei Feng', 'link': 'https://arxiv.org/abs/2507.17136', 'abstract': 'In the construction industry, traditional methods fail to meet the modern demands for efficiency and quality. The curtain wall installation is a critical component of construction projects. We design a hydraulically driven robotic arm for curtain wall installation and a dynamic parameter identification method. We establish a Denavit-Hartenberg (D-H) model based on measured robotic arm structural parameters and integrate hydraulic cylinder dynamics to construct a composite parametric system driven by a Stribeck friction model. By designing high-signal-to-noise ratio displacement excitation signals for hydraulic cylinders and combining Fourier series to construct optimal excitation trajectories that satisfy joint constraints, this method effectively excites the characteristics of each parameter in the minimal parameter set of the dynamic model of the robotic arm. On this basis, a hierarchical progressive parameter identification strategy is proposed: least squares estimation is employed to separately identify and jointly calibrate the dynamic parameters of both the hydraulic cylinder and the robotic arm, yielding Stribeck model curves for each joint. Experimental validation on a robotic arm platform demonstrates residual standard deviations below 0.4 Nm between theoretical and measured joint torques, confirming high-precision dynamic parameter identification for the hydraulic-driven curtain wall installation robotic arm. This significantly contributes to enhancing the intelligence level of curtain wall installation operations.', 'abstract_zh': '在建筑行业，传统方法难以满足现代对效率和质量的需求。幕墙安装是建筑工程中的关键组成部分。我们设计了一种液压驱动的机器人臂进行幕墙安装，并提出了一种动态参数识别方法。基于测量的机器人臂结构参数建立了Denavit-Hartenberg（D-H）模型，并整合了液压缸动力学，构建了一个由Stribeck摩擦模型驱动的复合参数系统。通过为液压缸设计高信噪比的位移激发信号，并结合傅里叶级数构建满足关节约束的优化激发轨迹，该方法有效地激发了动态模型中参数集的特征。在此基础上，提出了一种分层渐进参数识别策略：使用最小二乘估计分别识别和联合校准液压缸和机器人臂的动力学参数，为每个关节生成Stribeck模型曲线。在机器人臂平台上的实验验证表明，理论和测量的关节扭矩残差标准偏差低于0.4 Nm，证实了液压驱动幕墙安装机器人臂的动力学参数识别具有高精度。这显著提高了幕墙安装操作的智能化水平。', 'title_zh': '幕墙安装机器人手臂的动态参数识别'}
{'arxiv_id': 'arXiv:2507.17132', 'title': 'Dynamic Modeling and Dimensional Optimization of Legged Mechanisms for Construction Robot', 'authors': 'Xiao Liu, Xianlong Yang, Weijun Wang, Wei Feng', 'link': 'https://arxiv.org/abs/2507.17132', 'abstract': "With the rapid development of the construction industry, issues such as harsh working environments, high-intensity and high-risk tasks, and labor shortages have become increasingly prominent. This drives higher demands for construction robots in terms of low energy consumption, high mobility, and high load capacity. This paper focuses on the design and optimization of leg structures for construction robots, aiming to improve their dynamic performance, reduce energy consumption, and enhance load-bearing capabilities. Firstly, based on the leg configuration of ants in nature, we design a structure for the robot's leg. Secondly, we propose a novel structural optimization method. Using the Lagrangian approach, a dynamic model of the leg was established. Combining the dynamic model with the leg's motion trajectory, we formulated multiple dynamic evaluation metrics and conducted a comprehensive optimization study on the geometric parameters of each leg segment. The results show that the optimized leg structure reduces peak joint torques and energy consumption by over 20%. Finally, dynamic simulation experiments were conducted using ADAMS. The results demonstrate a significant reduction in the driving power of each joint after optimization, validating the effectiveness and rationality of the proposed strategy. This study provides a theoretical foundation and technical support for the design of heavy-load, high-performance construction robots.", 'abstract_zh': '随着建筑业的快速发展，苛刻的工作环境、高强度和高风险的任务以及劳动力短缺等问题日益突出。这推动了对建筑机器人在低能耗、高 mobility 和大负载能力方面提出更高的要求。本文 focuses于建筑机器人腿结构的设计与优化，旨在提高其动态性能、降低能耗并增强承载能力。首先，基于自然界蚂蚁的腿配置，设计了机器人的腿部结构。其次，提出了一种新的结构优化方法。利用拉格朗日方法建立了腿部的动力学模型，并结合动力学模型和腿部运动轨迹，制定了多个动态评价指标，并对每个腿段的几何参数进行了综合优化研究。结果显示，优化后的腿部结构可降低峰值关节扭矩和能耗超过20%。最后，使用ADAMS进行了动态仿真实验。结果表明，在优化后，每个关节的驱动功率显著降低，验证了所提策略的有效性和合理性。本研究为重载高性能建筑机器人的设计提供了理论基础和技术支持。', 'title_zh': '施工机器人 legged 机构的动态建模与尺寸优化'}
{'arxiv_id': 'arXiv:2507.17130', 'title': 'MARSCalib: Multi-robot, Automatic, Robust, Spherical Target-based Extrinsic Calibration in Field and Extraterrestrial Environments', 'authors': 'Seokhwan Jeong, Hogyun Kim, Younggun Cho', 'link': 'https://arxiv.org/abs/2507.17130', 'abstract': 'This paper presents a novel spherical target-based LiDAR-camera extrinsic calibration method designed for outdoor environments with multi-robot systems, considering both target and sensor corruption. The method extracts the 2D ellipse center from the image and the 3D sphere center from the pointcloud, which are then paired to compute the transformation matrix. Specifically, the image is first decomposed using the Segment Anything Model (SAM). Then, a novel algorithm extracts an ellipse from a potentially corrupted sphere, and the extracted center of ellipse is corrected for errors caused by the perspective projection model. For the LiDAR pointcloud, points on the sphere tend to be highly noisy due to the absence of flat regions. To accurately extract the sphere from these noisy measurements, we apply a hierarchical weighted sum to the accumulated pointcloud. Through experiments, we demonstrated that the sphere can be robustly detected even under both types of corruption, outperforming other targets. We evaluated our method using three different types of LiDARs (spinning, solid-state, and non-repetitive) with cameras positioned in three different locations. Furthermore, we validated the robustness of our method to target corruption by experimenting with spheres subjected to various types of degradation. These experiments were conducted in both a planetary test and a field environment. Our code is available at this https URL.', 'abstract_zh': '基于球形靶标的一种新型室外多机器人系统LiDAR-相机外参标定方法', 'title_zh': 'MARSCalib：基于球目标的野外及外太空环境多机器人自动稳健外部标定'}
{'arxiv_id': 'arXiv:2507.17085', 'title': 'Deformable Cluster Manipulation via Whole-Arm Policy Learning', 'authors': 'Jayadeep Jacob, Wenzheng Zhang, Houston Warren, Paulo Borges, Tirthankar Bandyopadhyay, Fabio Ramos', 'link': 'https://arxiv.org/abs/2507.17085', 'abstract': 'Manipulating clusters of deformable objects presents a substantial challenge with widespread applicability, but requires contact-rich whole-arm interactions. A potential solution must address the limited capacity for realistic model synthesis, high uncertainty in perception, and the lack of efficient spatial abstractions, among others. We propose a novel framework for learning model-free policies integrating two modalities: 3D point clouds and proprioceptive touch indicators, emphasising manipulation with full body contact awareness, going beyond traditional end-effector modes. Our reinforcement learning framework leverages a distributional state representation, aided by kernel mean embeddings, to achieve improved training efficiency and real-time inference. Furthermore, we propose a novel context-agnostic occlusion heuristic to clear deformables from a target region for exposure tasks. We deploy the framework in a power line clearance scenario and observe that the agent generates creative strategies leveraging multiple arm links for de-occlusion. Finally, we perform zero-shot sim-to-real policy transfer, allowing the arm to clear real branches with unknown occlusion patterns, unseen topology, and uncertain dynamics.', 'abstract_zh': '一种基于3D点云和本体感觉指示的新型无模型策略框架：面向全触觉接触的可变形对象 manipulation，及其在电力线清障中的应用', 'title_zh': '基于整臂策略学习的可变形簇集操作'}
{'arxiv_id': 'arXiv:2507.17055', 'title': 'Shared Control of Holonomic Wheelchairs through Reinforcement Learning', 'authors': 'Jannis Bähler, Diego Paez-Granados, Jorge Peña-Queralta', 'link': 'https://arxiv.org/abs/2507.17055', 'abstract': 'Smart electric wheelchairs can improve user experience by supporting the driver with shared control. State-of-the-art work showed the potential of shared control in improving safety in navigation for non-holonomic robots. However, for holonomic systems, current approaches often lead to unintuitive behavior for the user and fail to utilize the full potential of omnidirectional driving. Therefore, we propose a reinforcement learning-based method, which takes a 2D user input and outputs a 3D motion while ensuring user comfort and reducing cognitive load on the driver. Our approach is trained in Isaac Gym and tested in simulation in Gazebo. We compare different RL agent architectures and reward functions based on metrics considering cognitive load and user comfort. We show that our method ensures collision-free navigation while smartly orienting the wheelchair and showing better or competitive smoothness compared to a previous non-learning-based method. We further perform a sim-to-real transfer and demonstrate, to the best of our knowledge, the first real-world implementation of RL-based shared control for an omnidirectional mobility platform.', 'abstract_zh': '智能电动轮椅可以通过共享控制提高用户体验。虽然现有研究显示了共享控制在提高非全向机器人导航安全性方面的潜力，但对于全向系统，当前方法往往导致用户难以理解的行为，并未能充分利用全向驱动的全部潜力。因此，我们提出了一种基于强化学习的方法，该方法接收二维用户输入并输出三维运动，同时确保用户舒适并减轻驾驶员的认知负担。我们的方法在Isaac Gym中训练，并在Gazebo中进行模拟测试。我们基于考虑认知负荷和用户舒适度的指标，比较了不同的RL智能体架构和奖励函数。我们证明，我们的方法在确保无碰撞导航的同时智能地调整轮椅方向，并在平滑度方面优于 previous 非学习基方法。我们进一步进行了从模拟到现实的过渡，并据我们所知，展示了首个基于RL的共享控制的全向移动平台的真实世界实现。', 'title_zh': '基于强化学习的非完整轮椅共控'}
{'arxiv_id': 'arXiv:2507.16988', 'title': 'RAPTAR: Radar Radiation Pattern Acquisition through Automated Collaborative Robotics', 'authors': 'Maaz Qureshi, Mohammad Omid Bagheri, Abdelrahman Elbadrawy, William Melek, George Shaker', 'link': 'https://arxiv.org/abs/2507.16988', 'abstract': 'Accurate characterization of modern on-chip antennas remains challenging, as current probe-station techniques offer limited angular coverage, rely on bespoke hardware, and require frequent manual alignment. This research introduces RAPTAR (Radiation Pattern Acquisition through Robotic Automation), a portable, state-of-the-art, and autonomous system based on collaborative robotics. RAPTAR enables 3D radiation-pattern measurement of integrated radar modules without dedicated anechoic facilities. The system is designed to address the challenges of testing radar modules mounted in diverse real-world configurations, including vehicles, UAVs, AR/VR headsets, and biomedical devices, where traditional measurement setups are impractical. A 7-degree-of-freedom Franka cobot holds the receiver probe and performs collision-free manipulation across a hemispherical spatial domain, guided by real-time motion planning and calibration accuracy with RMS error below 0.9 mm. The system achieves an angular resolution upto 2.5 degree and integrates seamlessly with RF instrumentation for near- and far-field power measurements. Experimental scans of a 60 GHz radar module show a mean absolute error of less than 2 dB compared to full-wave electromagnetic simulations ground truth. Benchmarking against baseline method demonstrates 36.5% lower mean absolute error, highlighting RAPTAR accuracy and repeatability.', 'abstract_zh': '基于协作机器人的射频天线辐射图自动测量系统README', 'title_zh': '基于自动化协作机器人的雷达辐射pattern获取方法'}
{'arxiv_id': 'arXiv:2507.16941', 'title': 'Multi-agent Reinforcement Learning for Robotized Coral Reef Sample Collection', 'authors': 'Daniel Correa, Tero Kaarlela, Jose Fuentes, Paulo Padrao, Alain Duran, Leonardo Bobadilla', 'link': 'https://arxiv.org/abs/2507.16941', 'abstract': 'This paper presents a reinforcement learning (RL) environment for developing an autonomous underwater robotic coral sampling agent, a crucial coral reef conservation and research task. Using software-in-the-loop (SIL) and hardware-in-the-loop (HIL), an RL-trained artificial intelligence (AI) controller is developed using a digital twin (DT) in simulation and subsequently verified in physical experiments. An underwater motion capture (MOCAP) system provides real-time 3D position and orientation feedback during verification testing for precise synchronization between the digital and physical domains. A key novelty of this approach is the combined use of a general-purpose game engine for simulation, deep RL, and real-time underwater motion capture for an effective zero-shot sim-to-real strategy.', 'abstract_zh': '本文提出了一种强化学习（RL）环境，用于开发自主水下机器人珊瑚采样代理，这是珊瑚礁保护与研究中的一项关键任务。通过软件在环（SIL）和硬件在环（HIL）的方法，使用数字孪生（DT）在仿真中开发了一个RL训练的AI控制器，并在物理实验中进行了验证。基于水下运动捕捉（MOCAP）系统提供了验证测试过程中的实时3D位置和姿态反馈，以实现数字域和物理域的精确同步。该方法的关键 novelty 是结合使用通用游戏引擎进行仿真、深度RL和实时水下运动捕捉，以实现有效的零样本仿真实现策略。', 'title_zh': '基于多代理 reinforcement 学习的机器人化珊瑚礁样本采集'}
{'arxiv_id': 'arXiv:2507.16865', 'title': 'ResKACNNet: A Residual ChebyKAN Network for Inertial Odometry', 'authors': 'Shanshan Zhang, Tianshui Wen, Siyue Wang, Qi Zhang, Ziheng Zhou, Huiru Zheng, Lingxiang Zheng, Yu Yang', 'link': 'https://arxiv.org/abs/2507.16865', 'abstract': 'Inertial Measurement Unit (IMU) has become a key technology for achieving low-cost and precise positioning. However, traditional CNN-based inertial positioning methods struggle to capture the nonlinear motion characteristics and long-term dependencies in IMU data. To address this limitation, we propose a novel inertial positioning network with a generic backbone called ResChebyKAN, which leverages the nonlinear approximation capabilities of Chebyshev polynomials to model complex motion patterns. Additionally, we introduce an Efficient Kernel-based Self-Attention (EKSA) module to effectively capture contextual information and enhance long-term dependency modeling. Experimental results on public datasets (e.g., RIDI, RoNIN, RNIN-VIO, OxIOD, IMUNet, and TLIO) demonstrate that our method reduces the absolute trajectory error by 3.79% to 42.32% compared to existing benchmark methods. Furthermore, we release a preprocessed dataset and empirically show that removing the gravity component from acceleration data significantly improves inertial positioning performance.', 'abstract_zh': '惯性测量单元（IMU）已成为实现低成本高精度定位的关键技术。然而，传统的基于CNN的惯性定位方法难以捕捉IMU数据中的非线性运动特性和长期依赖关系。为了解决这一限制，我们提出了一种新型惯性定位网络，其使用称为ResChebyKAN的通用骨干网络，通过Chebyshev多项式的非线性逼近能力来建模复杂的运动模式。此外，我们引入了一种高效的基于内核的自注意力（EKSA）模块，以有效地捕获上下文信息并提高长期依赖关系建模。在公共数据集（例如，RIDI、RoNIN、RNIN-VIO、OxIOD、IMUNet和TLIO）上的实验结果表明，与现有的基准方法相比，我们的方法可将绝对轨迹误差降低3.79%到42.32%。此外，我们发布了预处理数据集，并通过去除加速度数据中的重力分量实证表明，这显著提升了惯性定位性能。', 'title_zh': 'ResKACNNet: 一种残差ChebyKAN网络用于惯性里程计'}
{'arxiv_id': 'arXiv:2507.16859', 'title': 'Leveraging multi-source and heterogeneous signals for fatigue detection', 'authors': 'Luobin Cui, Yanlai Wu, Tang Ying, Weikai Li', 'link': 'https://arxiv.org/abs/2507.16859', 'abstract': 'Fatigue detection plays a critical role in safety-critical applications such as aviation, mining, and long-haul transport. However, most existing methods rely on high-end sensors and controlled environments, limiting their applicability in real world settings. This paper formally defines a practical yet underexplored problem setting for real world fatigue detection, where systems operating with context-appropriate sensors aim to leverage knowledge from differently instrumented sources including those using impractical sensors deployed in controlled environments. To tackle this challenge, we propose a heterogeneous and multi-source fatigue detection framework that adaptively utilizes the available modalities in the target domain while benefiting from the diverse configurations present in source domains. Our experiments, conducted using a realistic field-deployed sensor setup and two publicly available datasets, demonstrate the practicality, robustness, and improved generalization of our approach, paving the practical way for effective fatigue monitoring in sensor-constrained scenarios.', 'abstract_zh': '疲劳检测在航空、采矿和长途运输等安全关键应用中起着关键作用。然而，大多数现有方法依赖于高端传感器和受控环境，限制了其在实际环境中的应用。本文正式定义了一个实用但未充分探索的现实世界疲劳检测问题设置，其中运行于上下文适当传感器的系统旨在利用来自不同配备传感器源的知识，包括那些在受控环境中部署的不现实传感器。为应对这一挑战，我们提出了一种异构多源的疲劳检测框架，该框架能够根据目标域的可用模态进行自适应利用，并从源域中多样化的配置中受益。我们的实验使用一个现实的现场部署传感器设置和两个公开可用的数据集，证明了我们方法的实用性、稳健性和更好的泛化能力，为传感器受限场景下的有效疲劳监测奠定了实用基础。', 'title_zh': '多源异构信号融合在疲劳检测中的应用'}
{'arxiv_id': 'arXiv:2507.16853', 'title': 'MobileUse: A GUI Agent with Hierarchical Reflection for Autonomous Mobile Operation', 'authors': 'Ning Li, Xiangmou Qu, Jiamu Zhou, Jun Wang, Muning Wen, Kounianhua Du, Xingyu Lou, Qiuying Peng, Jun Wang, Weinan Zhang', 'link': 'https://arxiv.org/abs/2507.16853', 'abstract': "Recent advances in Multimodal Large Language Models (MLLMs) have enabled the development of mobile agents that can understand visual inputs and follow user instructions, unlocking new possibilities for automating complex tasks on mobile devices. However, applying these models to real-world mobile scenarios remains a significant challenge due to the long-horizon task execution, difficulty in error recovery, and the cold-start problem in unfamiliar environments. To address these challenges, we propose MobileUse, a GUI agent designed for robust and adaptive mobile task execution. To improve resilience in long-horizon tasks and dynamic environments, we introduce a hierarchical reflection architecture that enables the agent to self-monitor, detect, and recover from errors across multiple temporal scales-ranging from individual actions to overall task completion-while maintaining efficiency through a reflection-on-demand strategy. To tackle cold-start issues, we further introduce a proactive exploration module, which enriches the agent's understanding of the environment through self-planned exploration. Evaluations on AndroidWorld and AndroidLab benchmarks demonstrate that MobileUse establishes new state-of-the-art performance, achieving success rates of 62.9% and 44.2%, respectively. To facilitate real-world applications, we release an out-of-the-box toolkit for automated task execution on physical mobile devices, which is available at this https URL.", 'abstract_zh': 'Recent advances in 多模态大语言模型（MLLMs）使得能够开发出能够理解视觉输入并遵循用户指令的移动代理，从而为在移动设备上自动化复杂任务开启了新的可能性。然而，将这些模型应用于真实的移动场景仍然面临显著挑战，包括长时间任务执行的复杂性、错误恢复的难度以及在不熟悉环境中冷启动的问题。为了解决这些挑战，我们提出了MobileUse，一种适用于 robust 和自适应移动任务执行的 GUI 代理。为了提高长时任务和动态环境下的鲁棒性，我们引入了一种分层反射架构，使代理能够自我监控、检测并跨多个时间尺度恢复错误（从单个动作到整体任务完成），并通过按需反思策略保持高效。为了解决冷启动问题，我们进一步引入了一种主动性探索模块，该模块通过自我计划的探索丰富代理对环境的理解。在 AndroidWorld 和 AndroidLab 基准上的评估表明，MobileUse 达到了新的性能基准，分别实现了 62.9% 和 44.2% 的成功率。为了促进实际应用，我们提供了一个开箱即用的工具包，用于在物理移动设备上自动化任务执行，可通过以下链接获取：this https URL。', 'title_zh': '移动使用：具有分层反射的GUI代理以实现自主移动操作'}
{'arxiv_id': 'arXiv:2507.16846', 'title': 'Analytical Formulation of Autonomous Vehicle Freeway Merging Control with State-Dependent Discharge Rates', 'authors': 'Qing Tang, Xianbiao Hu', 'link': 'https://arxiv.org/abs/2507.16846', 'abstract': 'The core of the freeway merging control problem lies in dynamic queue propagation and dissipation linked to merging vehicle behavior. Traditionally, queuing is modeled through demand-supply interactions with time varying demand and fixed capacity. However, field observations show flow rates decrease during congestion at freeway merges due to the impact of intersecting traffic, a factor overlooked in fundamental diagrams. This manuscript introduces an analytical approach to characterize and control the dynamic multi-stage merging of autonomous vehicles, prioritizing traffic efficiency and safety. For the first time, the effective discharge rate at the merging point, reduced by the multi-stage dynamic merging process, is analytically derived using a closed form formulation. Leveraging this expression, performance metrics such as queue length and traffic delay are derived as the first objective. Additionally, a crash risk function is established to quantitatively assess potential collisions during the merging process, serving as the second objective. Finally, the problem is formulated as a dynamic programming model to jointly minimize delay and crash risk, with the merging location and speed as decision variables. Given the terminal state, the ramp vehicle merging task is formulated as a recursive optimization problem, employing backward induction to find the minimum cost solution. Numerical experiments using the NGSIM dataset validate the derived effective discharge rate. The results indicate that the proposed model outperforms two benchmark algorithms, leading to a more efficient and safer merging process.', 'abstract_zh': '高速公路汇流控制的核心问题在于与汇流车辆行为相关的动态队列传播和消散。传统上，排队通过需求-供给交互建模，需求随时间变化而固定容量。然而，现场观察表明，在高速公路汇流处拥堵时，流量率会由于交叉交通的影响而降低，这一因素被基础图所忽视。本文引入了一种分析方法，用于表征和控制自主车辆的动态多阶段汇流，优先考虑交通效率和安全。首次通过闭式公式推导了汇流点的有效排放率，该排放率受到多阶段动态汇流过程的影响。利用此表达式，推导出了排队长度和交通延误等性能指标，作为第一目标。此外，建立了碰撞风险函数，以定量评估汇流过程中潜在碰撞的风险，作为第二目标。最后，将问题形式化为基础规划模型，旨在同时最小化延误和碰撞风险，汇流位置和速度作为决策变量。给定终端状态，匝道车辆汇流任务被形式化为递归优化问题，采用逆向归纳法找到最小成本解。使用NGSIM数据集的数值实验验证了推导的有效排放率。结果表明，所提出的模型优于两个基准算法，导致更高效和更安全的汇流过程。', 'title_zh': '自主车辆高速公路变道控制的基于状态依赖排放速率的分析式表述'}
{'arxiv_id': 'arXiv:2507.16842', 'title': 'Sensor-Space Based Robust Kinematic Control of Redundant Soft Manipulator by Learning', 'authors': 'Yinan Meng, Kun Qian, Jiong Yang, Renbo Su, Zhenhong Li, Charlie C.L. Wang', 'link': 'https://arxiv.org/abs/2507.16842', 'abstract': 'The intrinsic compliance and high degree of freedom (DoF) of redundant soft manipulators facilitate safe interaction and flexible task execution. However, effective kinematic control remains highly challenging, as it must handle deformations caused by unknown external loads and avoid actuator saturation due to improper null-space regulation - particularly in confined environments. In this paper, we propose a Sensor-Space Imitation Learning Kinematic Control (SS-ILKC) framework to enable robust kinematic control under actuator saturation and restrictive environmental constraints. We employ a dual-learning strategy: a multi-goal sensor-space control framework based on reinforcement learning principle is trained in simulation to develop robust control policies for open spaces, while a generative adversarial imitation learning approach enables effective policy learning from sparse expert demonstrations for confined spaces. To enable zero-shot real-world deployment, a pre-processed sim-to-real transfer mechanism is proposed to mitigate the simulation-to-reality gap and accurately characterize actuator saturation limits. Experimental results demonstrate that our method can effectively control a pneumatically actuated soft manipulator, achieving precise path-following and object manipulation in confined environments under unknown loading conditions.', 'abstract_zh': '冗余软 manipulator 的固有顺应性和高自由度 facilitates 安全交互和灵活任务执行。然而，有效的运动控制仍然极具挑战性，因为它必须处理由未知外部载荷引起的变形，并避免因无效的零空间调节而导致执行器饱和，特别是在受限环境中。在本文中，我们提出了一种传感器空间模仿学习运动控制（SS-ILKC）框架，以在执行器饱和和受限环境约束下实现稳健的运动控制。我们采用了双学习策略：基于强化学习原理的多目标传感器空间控制框架在仿真中训练以开发开放空间中的稳健控制策略，而生成对抗模仿学习方法使在受限空间中从稀疏专家演示中有效地学习策略成为可能。为实现零样本现实世界部署，我们提出了一个预处理的仿真实践转移机制来减小仿真与现实之间的差距，并准确表征执行器饱和极限。实验结果表明，我们的方法能够在未知载荷条件下有效地控制气动驱动的软 manipulator，在受限环境中实现精确的路径跟踪和物体操作。', 'title_zh': '基于传感器空间的冗余软 manipulator 动态可靠运动学控制学习方法'}
{'arxiv_id': 'arXiv:2507.16841', 'title': 'AquaChat: An LLM-Guided ROV Framework for Adaptive Inspection of Aquaculture Net Pens', 'authors': 'Waseem Akram, Muhayy Ud Din, Abdelhaleem Saad, Irfan Hussain', 'link': 'https://arxiv.org/abs/2507.16841', 'abstract': 'Inspection of aquaculture net pens is essential for maintaining the structural integrity, biosecurity, and operational efficiency of fish farming systems. Traditional inspection approaches rely on pre-programmed missions or manual control, offering limited adaptability to dynamic underwater conditions and user-specific demands. In this study, we propose AquaChat, a novel Remotely Operated Vehicle (ROV) framework that integrates Large Language Models (LLMs) for intelligent and adaptive net pen inspection. The system features a multi-layered architecture: (1) a high-level planning layer that interprets natural language user commands using an LLM to generate symbolic task plans; (2) a mid-level task manager that translates plans into ROV control sequences; and (3) a low-level motion control layer that executes navigation and inspection tasks with precision. Real-time feedback and event-triggered replanning enhance robustness in challenging aquaculture environments. The framework is validated through experiments in both simulated and controlled aquatic environments representative of aquaculture net pens. Results demonstrate improved task flexibility, inspection accuracy, and operational efficiency. AquaChat illustrates the potential of integrating language-based AI with marine robotics to enable intelligent, user-interactive inspection systems for sustainable aquaculture operations.', 'abstract_zh': '水产养殖网笼的检查对于保持养殖系统的结构完整性、生物安全性和运营效率至关重要。传统的检查方法依赖于预编程的任务或手动控制，对动态的水下条件和用户特定需求适应性有限。本研究提出了一种名为AquaChat的新型遥控潜水器（ROV）框架，该框架结合了大型语言模型（LLMs）实现智能和自适应的网笼检查。该系统具有多层架构：（1）高层规划层，使用LLM解析自然语言用户命令生成符号任务计划；（2）中间任务管理器，将计划转换为ROV控制序列；（3）低层运动控制层，精确执行导航和检查任务。实时反馈和事件触发的重新规划增强了在挑战性水产养殖环境中的鲁棒性。该框架通过在代表水产养殖网笼的模拟和受控水生环境中进行的实验得到了验证。结果表明，任务的灵活性、检查的准确性以及运营效率均有所提高。AquaChat展示了将基于语言的AI与海洋机器人结合以实现智能、用户互动的检查系统对可持续水产养殖运营的潜力。', 'title_zh': 'AquaChat：一种基于LLM的ROV框架，用于适应性检查水产养殖网箱'}
{'arxiv_id': 'arXiv:2507.16839', 'title': 'Summarizing Normative Driving Behavior From Large-Scale NDS Datasets for Vehicle System Development', 'authors': 'Gregory Beale, Gibran Ali', 'link': 'https://arxiv.org/abs/2507.16839', 'abstract': 'This paper presents a methodology to process large-scale naturalistic driving studies (NDS) to describe the driving behavior for five vehicle metrics, including speed, speeding, lane keeping, following distance, and headway, contextualized by roadway characteristics, vehicle classes, and driver demographics. Such descriptions of normative driving behaviors can aid in the development of vehicle safety and intelligent transportation systems. The methodology is demonstrated using data from the Second Strategic Highway Research Program (SHRP 2) NDS, which includes over 34 million miles of driving across more than 3,400 drivers. Summaries of each driving metric were generated using vehicle, GPS, and forward radar data. Additionally, interactive online analytics tools were developed to visualize and compare driving behavior across groups through dynamic data selection and grouping. For example, among drivers on 65-mph roads for the SHRP 2 NDS, females aged 16-19 exceeded the speed limit by 7.5 to 15 mph slightly more often than their male counterparts, and younger drivers maintained headways under 1.5 seconds more frequently than older drivers. This work supports better vehicle systems and safer infrastructure by quantifying normative driving behaviors and offers a methodology for analyzing NDS datasets for cross group comparisons.', 'abstract_zh': '本文提出了一种处理大规模自然驾驶研究(NDS)的方法，以描述包括速度、超速、车道保持、跟随距离和车头时距在内的五辆车辆指标的驾驶行为，并结合道路特征、车辆类别和驾驶者人口统计信息进行描述。这些规范驾驶行为的描述有助于车辆安全和智能交通运输系统的开发。该方法使用来自第二次战略高速公路研究计划(SHRP 2) NDS的数据进行演示，涵盖了超过3400名驾驶者的超过3400万公里的驾驶数据。每项驾驶指标的摘要使用车辆、GPS和前向雷达数据生成。此外，还开发了互动在线分析工具，通过动态数据选择和分组来可视化并比较不同组的驾驶行为。例如，在SHRP 2 NDS中，16-19岁女性在限速65 mph的道路上的超速情况略高于男性同行，年轻驾驶员比老年驾驶员更频繁地维持车头时距在1.5秒以下。这项工作通过量化规范驾驶行为支持更好的车辆系统和更安全的基础设施，并提供了一种分析NDS数据集进行跨组比较的方法。', 'title_zh': '从大规模NDS数据集总结规范驾驶行为以用于车辆系统开发'}
{'arxiv_id': 'arXiv:2507.17665', 'title': 'Perspective-Invariant 3D Object Detection', 'authors': 'Ao Liang, Lingdong Kong, Dongyue Lu, Youquan Liu, Jian Fang, Huaici Zhao, Wei Tsang Ooi', 'link': 'https://arxiv.org/abs/2507.17665', 'abstract': 'With the rise of robotics, LiDAR-based 3D object detection has garnered significant attention in both academia and industry. However, existing datasets and methods predominantly focus on vehicle-mounted platforms, leaving other autonomous platforms underexplored. To bridge this gap, we introduce Pi3DET, the first benchmark featuring LiDAR data and 3D bounding box annotations collected from multiple platforms: vehicle, quadruped, and drone, thereby facilitating research in 3D object detection for non-vehicle platforms as well as cross-platform 3D detection. Based on Pi3DET, we propose a novel cross-platform adaptation framework that transfers knowledge from the well-studied vehicle platform to other platforms. This framework achieves perspective-invariant 3D detection through robust alignment at both geometric and feature levels. Additionally, we establish a benchmark to evaluate the resilience and robustness of current 3D detectors in cross-platform scenarios, providing valuable insights for developing adaptive 3D perception systems. Extensive experiments validate the effectiveness of our approach on challenging cross-platform tasks, demonstrating substantial gains over existing adaptation methods. We hope this work paves the way for generalizable and unified 3D perception systems across diverse and complex environments. Our Pi3DET dataset, cross-platform benchmark suite, and annotation toolkit have been made publicly available.', 'abstract_zh': '随着机器人技术的发展，基于LiDAR的3D物体检测在学术界和工业界引起了广泛关注。然而，现有的数据集和方法主要集中在车载平台，而其他自主平台则研究较少。为弥补这一不足，我们引入了Pi3DET，这是一个首个包含来自多种平台（车辆、四足机器人和无人机）的LiDAR数据及其3D边界框标注的数据集，从而促进了非车辆平台的3D物体检测研究以及跨平台3D检测研究。基于Pi3DET，我们提出了一种新的跨平台适应框架，该框架将来自研究成熟的车载平台的知识转移至其他平台。该框架通过几何和特征层面的鲁棒对齐实现视角不变的3D检测。此外，我们建立了一个基准来评估当前3D检测器在跨平台场景下的鲁棒性和鲁棒性，为开发适应性强的3D感知系统提供了宝贵的见解。广泛的实验验证了我们方法在挑战性的跨平台任务中的有效性，显示出相对于现有适应方法的显著改进。我们希望这项工作能为各种复杂环境中的可泛化和统一的3D感知系统铺平道路。我们的Pi3DET数据集、跨平台基准套件和标注工具箱已公开发布。', 'title_zh': '视角不变的3D物体检测'}
{'arxiv_id': 'arXiv:2507.17664', 'title': 'Talk2Event: Grounded Understanding of Dynamic Scenes from Event Cameras', 'authors': 'Lingdong Kong, Dongyue Lu, Ao Liang, Rong Li, Yuhao Dong, Tianshuai Hu, Lai Xing Ng, Wei Tsang Ooi, Benoit R. Cottereau', 'link': 'https://arxiv.org/abs/2507.17664', 'abstract': 'Event cameras offer microsecond-level latency and robustness to motion blur, making them ideal for understanding dynamic environments. Yet, connecting these asynchronous streams to human language remains an open challenge. We introduce Talk2Event, the first large-scale benchmark for language-driven object grounding in event-based perception. Built from real-world driving data, we provide over 30,000 validated referring expressions, each enriched with four grounding attributes -- appearance, status, relation to viewer, and relation to other objects -- bridging spatial, temporal, and relational reasoning. To fully exploit these cues, we propose EventRefer, an attribute-aware grounding framework that dynamically fuses multi-attribute representations through a Mixture of Event-Attribute Experts (MoEE). Our method adapts to different modalities and scene dynamics, achieving consistent gains over state-of-the-art baselines in event-only, frame-only, and event-frame fusion settings. We hope our dataset and approach will establish a foundation for advancing multimodal, temporally-aware, and language-driven perception in real-world robotics and autonomy.', 'abstract_zh': '事件相机提供微秒级延迟和对运动模糊的 robustness，使其成为理解动态环境的理想选择。然而，将这些异步流与人类语言连接起来仍然是一个开放的挑战。我们引入了 Talk2Event，这是一个用于基于事件感知的语言驱动对象定位的大规模基准。该基准源自真实世界的驾驶数据，提供了超过 30,000 个验证的指示短语，并且每个短语都附有四种定位属性——外观、状态、相对于观察者的关系以及与其他物体的关系，这些属性跨越了空间、时间和关系推理。为了充分利用这些线索，我们提出了 EventRefer，这是一个属性感知的定位框架，通过对多属性表示进行动态融合，利用事件-属性专家混合体（MoEE）来实现这一目的。该方法能够适应不同的模态和场景动态，实现了在基于事件、基于帧和事件-帧融合设置中对现有最佳基线的一致改进。我们希望我们的数据集和方法能够为推进多模态、时间感知和语言驱动的感知奠定基础，在实际机器人技术和自主驾驶领域发挥作用。', 'title_zh': 'Talk2Event：事件相机中动态场景的 grounded 理解'}
{'arxiv_id': 'arXiv:2507.17661', 'title': 'Monocular Semantic Scene Completion via Masked Recurrent Networks', 'authors': 'Xuzhi Wang, Xinran Wu, Song Wang, Lingdong Kong, Ziping Zhao', 'link': 'https://arxiv.org/abs/2507.17661', 'abstract': "Monocular Semantic Scene Completion (MSSC) aims to predict the voxel-wise occupancy and semantic category from a single-view RGB image. Existing methods adopt a single-stage framework that aims to simultaneously achieve visible region segmentation and occluded region hallucination, while also being affected by inaccurate depth estimation. Such methods often achieve suboptimal performance, especially in complex scenes. We propose a novel two-stage framework that decomposes MSSC into coarse MSSC followed by the Masked Recurrent Network. Specifically, we propose the Masked Sparse Gated Recurrent Unit (MS-GRU) which concentrates on the occupied regions by the proposed mask updating mechanism, and a sparse GRU design is proposed to reduce the computation cost. Additionally, we propose the distance attention projection to reduce projection errors by assigning different attention scores according to the distance to the observed surface. Experimental results demonstrate that our proposed unified framework, MonoMRN, effectively supports both indoor and outdoor scenes and achieves state-of-the-art performance on the NYUv2 and SemanticKITTI datasets. Furthermore, we conduct robustness analysis under various disturbances, highlighting the role of the Masked Recurrent Network in enhancing the model's resilience to such challenges. The source code is publicly available.", 'abstract_zh': '单目语义场景补全 (MSSC) 的目标是从单视角 RGB 图像中预测体素级的占有状态和语义类别。现有方法采用单一阶段框架，旨在同时实现可见区域分割和被遮挡区域的想象，但受不准确深度估计的影响。这些方法在复杂场景中往往无法获得最佳性能。我们提出了一种新颖的两阶段框架，将 MSSC 分解为粗略 MSSC 阶段，随后是 Masked Recurrent Network。具体地，我们提出了 Masked Sparse Gated Recurrent Unit (MS-GRU)，通过提出的掩码更新机制关注被占用区域，并提出稀疏 GRU 设计以降低计算成本。此外，我们提出了距离注意力投影，通过根据与观测表面的距离分配不同的注意力分数来减少投影误差。实验结果表明，我们提出的统一框架 MonoMRN 有效地支持室内和室外场景，并在 NYUv2 和 SemanticKITTI 数据集上实现了最新的性能。此外，我们在各种干扰下进行了鲁棒性分析，突显了 Masked Recurrent Network 在增强模型对这些挑战的抵抗力方面的作用。源代码已公开。', 'title_zh': '单目语义场景补全 via 遮蔽循环网络'}
{'arxiv_id': 'arXiv:2507.17596', 'title': 'PRIX: Learning to Plan from Raw Pixels for End-to-End Autonomous Driving', 'authors': 'Maciej K. Wozniak, Lianhang Liu, Yixi Cai, Patric Jensfelt', 'link': 'https://arxiv.org/abs/2507.17596', 'abstract': 'While end-to-end autonomous driving models show promising results, their practical deployment is often hindered by large model sizes, a reliance on expensive LiDAR sensors and computationally intensive BEV feature representations. This limits their scalability, especially for mass-market vehicles equipped only with cameras. To address these challenges, we propose PRIX (Plan from Raw Pixels). Our novel and efficient end-to-end driving architecture operates using only camera data, without explicit BEV representation and forgoing the need for LiDAR. PRIX leverages a visual feature extractor coupled with a generative planning head to predict safe trajectories from raw pixel inputs directly. A core component of our architecture is the Context-aware Recalibration Transformer (CaRT), a novel module designed to effectively enhance multi-level visual features for more robust planning. We demonstrate through comprehensive experiments that PRIX achieves state-of-the-art performance on the NavSim and nuScenes benchmarks, matching the capabilities of larger, multimodal diffusion planners while being significantly more efficient in terms of inference speed and model size, making it a practical solution for real-world deployment. Our work is open-source and the code will be at this https URL.', 'abstract_zh': 'PRIX（基于原始像素的规划）：一种仅使用摄像头数据的高效端到端驾驶架构', 'title_zh': 'PRIX: 从原始像素学习规划以实现端到端自主驾驶'}
{'arxiv_id': 'arXiv:2507.17585', 'title': 'From Scan to Action: Leveraging Realistic Scans for Embodied Scene Understanding', 'authors': 'Anna-Maria Halacheva, Jan-Nico Zaech, Sombit Dey, Luc Van Gool, Danda Pani Paudel', 'link': 'https://arxiv.org/abs/2507.17585', 'abstract': 'Real-world 3D scene-level scans offer realism and can enable better real-world generalizability for downstream applications. However, challenges such as data volume, diverse annotation formats, and tool compatibility limit their use. This paper demonstrates a methodology to effectively leverage these scans and their annotations. We propose a unified annotation integration using USD, with application-specific USD flavors. We identify challenges in utilizing holistic real-world scan datasets and present mitigation strategies. The efficacy of our approach is demonstrated through two downstream applications: LLM-based scene editing, enabling effective LLM understanding and adaptation of the data (80% success), and robotic simulation, achieving an 87% success rate in policy learning.', 'abstract_zh': '现实世界场景级三维扫描提供了真实的视觉效果，并能促进下游应用中的更好泛化能力。然而，数据量大、标注格式多样以及工具兼容性差等问题限制了其应用。本文提出了一种有效利用这些扫描及其标注的方法论。我们使用USD进行统一标注集成，并开发了适用于不同应用场景的USD变体。我们识别了利用整体现实世界扫描数据集面临的挑战，并提出了相应的缓解策略。通过两个下游应用，展示了我们方法的有效性：基于LLM的场景编辑，使LLM能够有效理解并适应数据（成功率为80%），以及机器人模拟，实现了在策略学习中87%的成功率。', 'title_zh': '从扫描到行动：利用现实扫描进行体域场景理解'}
{'arxiv_id': 'arXiv:2507.17530', 'title': 'Generalized Advantage Estimation for Distributional Policy Gradients', 'authors': 'Shahil Shaik, Jonathon M. Smereka, Yue Wang', 'link': 'https://arxiv.org/abs/2507.17530', 'abstract': 'Generalized Advantage Estimation (GAE) has been used to mitigate the computational complexity of reinforcement learning (RL) by employing an exponentially weighted estimation of the advantage function to reduce the variance in policy gradient estimates. Despite its effectiveness, GAE is not designed to handle value distributions integral to distributional RL, which can capture the inherent stochasticity in systems and is hence more robust to system noises. To address this gap, we propose a novel approach that utilizes the optimal transport theory to introduce a Wasserstein-like directional metric, which measures both the distance and the directional discrepancies between probability distributions. Using the exponentially weighted estimation, we leverage this Wasserstein-like directional metric to derive distributional GAE (DGAE). Similar to traditional GAE, our proposed DGAE provides a low-variance advantage estimate with controlled bias, making it well-suited for policy gradient algorithms that rely on advantage estimation for policy updates. We integrated DGAE into three different policy gradient methods. Algorithms were evaluated across various OpenAI Gym environments and compared with the baselines with traditional GAE to assess the performance.', 'abstract_zh': '广义优势估计（GAE）通过采用指数加权的优势函数估计来降低策略梯度估计的方差，从而缓解强化学习（RL）的计算复杂性。尽管GAE非常有效，但它并未针对分布型RL中的价值分布进行设计，而这些价值分布能够捕捉系统的固有随机性，并因此在面对系统噪声时更为 robust。为弥补这一不足，我们提出了一种新的方法，利用最优运输理论引入了一种仿Wasserstein方向度量，该度量可以同时衡量概率分布之间的距离和方向性差异。结合指数加权估计，我们利用这种仿Wasserstein方向度量推导出分布型GAE（DGAE）。类似于传统的GAE，我们提出的DGAE提供了低方差的优势估计，并且具有可控的偏差，使其非常适合依赖于优势估计进行策略更新的策略梯度算法。我们将DGAE整合到三种不同的策略梯度方法中。在各种OpenAI Gym环境中评估了算法，并与传统GAE的基线进行比较，以评估性能。', 'title_zh': '广义优势估计在分布性策略梯度中的应用'}
{'arxiv_id': 'arXiv:2507.17455', 'title': 'VLM-Guided Visual Place Recognition for Planet-Scale Geo-Localization', 'authors': 'Sania Waheed, Na Min An, Michael Milford, Sarvapali D. Ramchurn, Shoaib Ehsan', 'link': 'https://arxiv.org/abs/2507.17455', 'abstract': 'Geo-localization from a single image at planet scale (essentially an advanced or extreme version of the kidnapped robot problem) is a fundamental and challenging task in applications such as navigation, autonomous driving and disaster response due to the vast diversity of locations, environmental conditions, and scene variations. Traditional retrieval-based methods for geo-localization struggle with scalability and perceptual aliasing, while classification-based approaches lack generalization and require extensive training data. Recent advances in vision-language models (VLMs) offer a promising alternative by leveraging contextual understanding and reasoning. However, while VLMs achieve high accuracy, they are often prone to hallucinations and lack interpretability, making them unreliable as standalone solutions. In this work, we propose a novel hybrid geo-localization framework that combines the strengths of VLMs with retrieval-based visual place recognition (VPR) methods. Our approach first leverages a VLM to generate a prior, effectively guiding and constraining the retrieval search space. We then employ a retrieval step, followed by a re-ranking mechanism that selects the most geographically plausible matches based on feature similarity and proximity to the initially estimated coordinates. We evaluate our approach on multiple geo-localization benchmarks and show that it consistently outperforms prior state-of-the-art methods, particularly at street (up to 4.51%) and city level (up to 13.52%). Our results demonstrate that VLM-generated geographic priors in combination with VPR lead to scalable, robust, and accurate geo-localization systems.', 'abstract_zh': '从单张图像进行全球规模的地理定位（本质上是被劫持机器人问题的高级或极端版本）是导航、自动驾驶和灾害响应等领域中的一个基础且具有挑战性的任务，由于地理位置、环境条件和场景变化的广泛多样性。传统的基于检索的地理定位方法在可扩展性和感知性混叠方面存在困难，而基于分类的方法缺乏泛化能力且需要大量的训练数据。最近在视觉-语言模型（VLMs）方面的进展提供了一种有前途的替代方案，通过利用上下文理解和推理。然而，尽管VLMs在准确性方面表现出色，但它们往往容易产生幻觉且缺乏可解释性，使其作为独立解决方案不可靠。在本文中，我们提出了一种新颖的混合地理定位框架，将VLMs的优势与基于检索的视觉场所识别（VPR）方法结合起来。我们的方法首先利用VLM生成先验知识，有效地引导和限制检索搜索空间。随后采用检索步骤，并通过一个重新排名机制，根据特征相似性和与最初估计坐标的空间接近性，选择最地理上合理的一系列匹配。我们在多个地理定位基准上评估了我们的方法，并表明它在街道级别（高达4.51%）和城市级别（高达13.52%）上一致地优于先前的最佳方法。我们的结果表明，VLM生成的地理先验与VPR相结合，可以实现可扩展、稳健且准确的地理定位系统。', 'title_zh': '行星规模地理定位的VLM引导视觉地点识别'}
{'arxiv_id': 'arXiv:2507.17220', 'title': 'PIG-Nav: Key Insights for Pretrained Image Goal Navigation Models', 'authors': 'Jiansong Wan, Chengming Zhou, Jinkua Liu, Xiangge Huang, Xiaoyu Chen, Xiaohan Yi, Qisen Yang, Baiting Zhu, Xin-Qiang Cai, Lixing Liu, Rushuai Yang, Chuheng Zhang, Sherif Abdelfattah, Hayong Shin, Pushi Zhang, Li Zhao, Jiang Bian', 'link': 'https://arxiv.org/abs/2507.17220', 'abstract': 'Recent studies have explored pretrained (foundation) models for vision-based robotic navigation, aiming to achieve generalizable navigation and positive transfer across diverse environments while enhancing zero-shot performance in unseen settings. In this work, we introduce PIG-Nav (Pretrained Image-Goal Navigation), a new approach that further investigates pretraining strategies for vision-based navigation models and contributes in two key areas. Model-wise, we identify two critical design choices that consistently improve the performance of pretrained navigation models: (1) integrating an early-fusion network structure to combine visual observations and goal images via appropriately pretrained Vision Transformer (ViT) image encoder, and (2) introducing suitable auxiliary tasks to enhance global navigation representation learning, thus further improving navigation performance. Dataset-wise, we propose a novel data preprocessing pipeline for efficiently labeling large-scale game video datasets for navigation model training. We demonstrate that augmenting existing open navigation datasets with diverse gameplay videos improves model performance. Our model achieves an average improvement of 22.6% in zero-shot settings and a 37.5% improvement in fine-tuning settings over existing visual navigation foundation models in two complex simulated environments and one real-world environment. These results advance the state-of-the-art in pretrained image-goal navigation models. Notably, our model maintains competitive performance while requiring significantly less fine-tuning data, highlighting its potential for real-world deployment with minimal labeled supervision.', 'abstract_zh': 'Recent Studies on Pretrained Models for Vision-Based Robotic Navigation: Introducing PIG-Nav (Pretrained Image-Goal Navigation)', 'title_zh': 'PIG-Nav：预训练图像目标导航模型的关键见解'}
{'arxiv_id': 'arXiv:2507.17089', 'title': 'IONext: Unlocking the Next Era of Inertial Odometry', 'authors': 'Shanshan Zhang, Siyue Wang, Tianshui Wen, Qi Zhang, Ziheng Zhou, Lingxiang Zheng, Yu Yang', 'link': 'https://arxiv.org/abs/2507.17089', 'abstract': 'Researchers have increasingly adopted Transformer-based models for inertial odometry. While Transformers excel at modeling long-range dependencies, their limited sensitivity to local, fine-grained motion variations and lack of inherent inductive biases often hinder localization accuracy and generalization. Recent studies have shown that incorporating large-kernel convolutions and Transformer-inspired architectural designs into CNN can effectively expand the receptive field, thereby improving global motion perception. Motivated by these insights, we propose a novel CNN-based module called the Dual-wing Adaptive Dynamic Mixer (DADM), which adaptively captures both global motion patterns and local, fine-grained motion features from dynamic inputs. This module dynamically generates selective weights based on the input, enabling efficient multi-scale feature aggregation. To further improve temporal modeling, we introduce the Spatio-Temporal Gating Unit (STGU), which selectively extracts representative and task-relevant motion features in the temporal domain. This unit addresses the limitations of temporal modeling observed in existing CNN approaches. Built upon DADM and STGU, we present a new CNN-based inertial odometry backbone, named Next Era of Inertial Odometry (IONext). Extensive experiments on six public datasets demonstrate that IONext consistently outperforms state-of-the-art (SOTA) Transformer- and CNN-based methods. For instance, on the RNIN dataset, IONext reduces the average ATE by 10% and the average RTE by 12% compared to the representative model iMOT.', 'abstract_zh': '基于双翼自适应动态混合模块和时空门控单元的新型惯性里程计', 'title_zh': 'IONext: 解锁惯性里程计的下一个时代'}
{'arxiv_id': 'arXiv:2507.17049', 'title': 'Evaluating Uncertainty and Quality of Visual Language Action-enabled Robots', 'authors': 'Pablo Valle, Chengjie Lu, Shaukat Ali, Aitor Arrieta', 'link': 'https://arxiv.org/abs/2507.17049', 'abstract': "Visual Language Action (VLA) models are a multi-modal class of Artificial Intelligence (AI) systems that integrate visual perception, natural language understanding, and action planning to enable agents to interpret their environment, comprehend instructions, and perform embodied tasks autonomously. Recently, significant progress has been made to advance this field. These kinds of models are typically evaluated through task success rates, which fail to capture the quality of task execution and the mode's confidence in its decisions. In this paper, we propose eight uncertainty metrics and five quality metrics specifically designed for VLA models for robotic manipulation tasks. We assess their effectiveness through a large-scale empirical study involving 908 successful task executions from three state-of-the-art VLA models across four representative robotic manipulation tasks. Human domain experts manually labeled task quality, allowing us to analyze the correlation between our proposed metrics and expert judgments. The results reveal that several metrics show moderate to strong correlation with human assessments, highlighting their utility for evaluating task quality and model confidence. Furthermore, we found that some of the metrics can discriminate between high-, medium-, and low-quality executions from unsuccessful tasks, which can be interesting when test oracles are not available. Our findings challenge the adequacy of current evaluation practices that rely solely on binary success rates and pave the way for improved real-time monitoring and adaptive enhancement of VLA-enabled robotic systems.", 'abstract_zh': '视觉语言行动（VLA）模型是一种多模态的人工智能系统，通过整合视觉感知、自然语言理解和行动规划，使智能体能够解释其环境、理解指令并执行自主的实体任务。近年来，该领域取得了显著进步。这类模型通常通过任务成功率来评估，但无法捕捉任务执行的质量和模型决策的置信度。本文提出八项不确定性度量和五项质量度量，专门用于评估视觉语言行动模型在机器人操作任务中的表现。我们通过涵盖三个先进VLA模型在四类代表性机器人操作任务中908次成功执行任务的大型实证研究，评估其有效性。人类领域专家手工标注了任务质量，使我们能够分析我们提出的度量与专家判断之间的相关性。结果显示，多项度量与人类评估之间存在中等到较强的关联性，突显了其评估任务质量和模型置信度的实用性。此外，我们发现某些度量能够区分成功的高、中、低质量执行，这在测试判据不可用时可能非常有趣。我们的研究挑战了当前仅依赖二元成功率的评估实践，并为改进视觉语言行动增强的机器人系统的实时监控和自适应改进开辟了新途径。', 'title_zh': '评估视觉语言驱动机器人中的不确定性和质量'}
{'arxiv_id': 'arXiv:2507.16983', 'title': 'Hierarchical Reinforcement Learning Framework for Adaptive Walking Control Using General Value Functions of Lower-Limb Sensor Signals', 'authors': 'Sonny T. Jones, Grange M. Simpson, Patrick M. Pilarski, Ashley N. Dalrymple', 'link': 'https://arxiv.org/abs/2507.16983', 'abstract': 'Rehabilitation technology is a natural setting to study the shared learning and decision-making of human and machine agents. In this work, we explore the use of Hierarchical Reinforcement Learning (HRL) to develop adaptive control strategies for lower-limb exoskeletons, aiming to enhance mobility and autonomy for individuals with motor impairments. Inspired by prominent models of biological sensorimotor processing, our investigated HRL approach breaks down the complex task of exoskeleton control adaptation into a higher-level framework for terrain strategy adaptation and a lower-level framework for providing predictive information; this latter element is implemented via the continual learning of general value functions (GVFs). GVFs generated temporal abstractions of future signal values from multiple wearable lower-limb sensors, including electromyography, pressure insoles, and goniometers. We investigated two methods for incorporating actual and predicted sensor signals into a policy network with the intent to improve the decision-making capacity of the control system of a lower-limb exoskeleton during ambulation across varied terrains. As a key result, we found that the addition of predictions made from GVFs increased overall network accuracy. Terrain-specific performance increases were seen while walking on even ground, uneven ground, up and down ramps, and turns, terrains that are often misclassified without predictive information. This suggests that predictive information can aid decision-making during uncertainty, e.g., on terrains that have a high chance of being misclassified. This work, therefore, contributes new insights into the nuances of HRL and the future development of exoskeletons to facilitate safe transitioning and traversing across different walking environments.', 'abstract_zh': '康复技术是研究人类和机器智能共享学习与决策的有效环境。本文探讨了层次强化学习（HRL）在开发下肢外骨骼适应控制策略中的应用，旨在增强运动障碍个体的行动能力和自主性。受生物传感器运动处理模型启发，我们研究的HRL方法将外骨骼控制适应的复杂任务分解为一个更高层次的地形策略适应框架和一个较低层次的提供预测信息框架；后者通过持续学习一般价值函数（GVFs）实现。GVFs从包括肌电图、压力内底和关节角度传感器在内的多种可穿戴下肢传感器中生成了未来信号值的时间抽象。我们研究了两种方法，将实际和预测的传感器信号纳入策略网络中，旨在提高下肢外骨骼行走过程中复杂地形环境中控制系统决策能力。一个关键结果表明，GVFs预测的引入提高了整体网络的准确性。在平坦地面、不平地面、斜坡上上下下及转弯等地形上行走时，特定地形性能的提升表明预测信息可以在不确定性环境中帮助决策，特别是在高概率误分类的地形上。因此，本文为HRL的细微机制以及未来外骨骼的发展提供了新的见解，以促进在不同行走环境中的安全过渡和穿越。', 'title_zh': '基于下肢传感器信号通用价值函数的分层级强化学习适应性行走控制框架'}
{'arxiv_id': 'arXiv:2507.16874', 'title': 'Budget Allocation Policies for Real-Time Multi-Agent Path Finding', 'authors': 'Raz Beck, Roni Stern', 'link': 'https://arxiv.org/abs/2507.16874', 'abstract': 'Multi-Agent Pathfinding (MAPF) is the problem of finding paths for a set of agents such that each agent reaches its desired destination while avoiding collisions with the other agents. Many MAPF solvers are designed to run offline, that is, first generate paths for all agents and then execute them. Real-Time MAPF (RT-MAPF) embodies a realistic MAPF setup in which one cannot wait until a complete path for each agent has been found before they start to move. Instead, planning and execution are interleaved, where the agents must commit to a fixed number of steps in a constant amount of computation time, referred to as the planning budget. Existing solutions to RT-MAPF iteratively call windowed versions of MAPF algorithms in every planning period, without explicitly considering the size of the planning budget. We address this gap and explore different policies for allocating the planning budget in windowed versions of standard MAPF algorithms, namely Prioritized Planning (PrP) and MAPF-LNS2. Our exploration shows that the baseline approach in which all agents draw from a shared planning budget pool is ineffective in over-constrained situations. Instead, policies that distribute the planning budget over the agents are able to solve more problems with a smaller makespan.', 'abstract_zh': '实时多代理路径规划（RT-MAPF）中规划预算分配策略的研究', 'title_zh': '实时多agent路径寻找中的预算分配策略'}
