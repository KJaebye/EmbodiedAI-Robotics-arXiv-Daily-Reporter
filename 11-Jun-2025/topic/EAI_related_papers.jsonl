{'arxiv_id': 'arXiv:2506.08931', 'title': 'CLONE: Closed-Loop Whole-Body Humanoid Teleoperation for Long-Horizon Tasks', 'authors': 'Yixuan Li, Yutang Lin, Jieming Cui, Tengyu Liu, Wei Liang, Yixin Zhu, Siyuan Huang', 'link': 'https://arxiv.org/abs/2506.08931', 'abstract': "Humanoid teleoperation plays a vital role in demonstrating and collecting data for complex humanoid-scene interactions. However, current teleoperation systems face critical limitations: they decouple upper- and lower-body control to maintain stability, restricting natural coordination, and operate open-loop without real-time position feedback, leading to accumulated drift. The fundamental challenge is achieving precise, coordinated whole-body teleoperation over extended durations while maintaining accurate global positioning. Here we show that an MoE-based teleoperation system, CLONE, with closed-loop error correction enables unprecedented whole-body teleoperation fidelity, maintaining minimal positional drift over long-range trajectories using only head and hand tracking from an MR headset. Unlike previous methods that either sacrifice coordination for stability or suffer from unbounded drift, CLONE learns diverse motion skills while preventing tracking error accumulation through real-time feedback, enabling complex coordinated movements such as ``picking up objects from the ground.'' These results establish a new milestone for whole-body humanoid teleoperation for long-horizon humanoid-scene interaction tasks.", 'abstract_zh': '基于MoE的人机遥控系统CLONE在长时间大范围全身人形场景遥控中的卓越表现', 'title_zh': 'CLONE: 闭环全身人形机器人力控远程操作长时任务'}
{'arxiv_id': 'arXiv:2506.08890', 'title': 'Human-Robot Teaming Field Deployments: A Comparison Between Verbal and Non-verbal Communication', 'authors': 'Tauhid Tanjim, Promise Ekpo, Huajie Cao, Jonathan St. George, Kevin Ching, Hee Rin Lee, Angelique Taylor', 'link': 'https://arxiv.org/abs/2506.08890', 'abstract': "Healthcare workers (HCWs) encounter challenges in hospitals, such as retrieving medical supplies quickly from crash carts, which could potentially result in medical errors and delays in patient care. Robotic crash carts (RCCs) have shown promise in assisting healthcare teams during medical tasks through guided object searches and task reminders. Limited exploration has been done to determine what communication modalities are most effective and least disruptive to patient care in real-world settings. To address this gap, we conducted a between-subjects experiment comparing the RCC's verbal and non-verbal communication of object search with a standard crash cart in resuscitation scenarios to understand the impact of robot communication on workload and attitudes toward using robots in the workplace. Our findings indicate that verbal communication significantly reduced mental demand and effort compared to visual cues and with a traditional crash cart. Although frustration levels were slightly higher during collaborations with the robot compared to a traditional cart, these research insights provide valuable implications for human-robot teamwork in high-stakes environments.", 'abstract_zh': '机器人监护车在急救场景中通过语音与非言语沟通方式辅助医疗任务对工作负荷及工作场所使用机器人态度的影响：一项实证研究', 'title_zh': '人机协同现场部署：口头沟通与非口头沟通的比较'}
{'arxiv_id': 'arXiv:2506.08851', 'title': 'Deploying SICNav in the Field: Safe and Interactive Crowd Navigation using MPC and Bilevel Optimization', 'authors': 'Sepehr Samavi, Garvish Bhutani, Florian Shkurti, Angela P. Schoellig', 'link': 'https://arxiv.org/abs/2506.08851', 'abstract': "Safe and efficient navigation in crowded environments remains a critical challenge for robots that provide a variety of service tasks such as food delivery or autonomous wheelchair mobility. Classical robot crowd navigation methods decouple human motion prediction from robot motion planning, which neglects the closed-loop interactions between humans and robots. This lack of a model for human reactions to the robot plan (e.g. moving out of the way) can cause the robot to get stuck. Our proposed Safe and Interactive Crowd Navigation (SICNav) method is a bilevel Model Predictive Control (MPC) framework that combines prediction and planning into one optimization problem, explicitly modeling interactions among agents. In this paper, we present a systems overview of the crowd navigation platform we use to deploy SICNav in previously unseen indoor and outdoor environments. We provide a preliminary analysis of the system's operation over the course of nearly 7 km of autonomous navigation over two hours in both indoor and outdoor environments.", 'abstract_zh': '安全高效的拥挤环境导航仍然是为食物配送或自主轮椅移动等各类服务任务提供服务的机器人面临的关键挑战。经典的机器人人群导航方法将人类运动预测与机器人运动规划分离，忽略了人类与机器人之间的闭环交互。忽视了对机器人计划的人类反应模型（例如，主动避让）可能导致机器人陷入困境。我们提出的Safe and Interactive Crowd Navigation（SICNav）方法是一种二层模型预测控制（MPC）框架，将预测和规划结合为一个优化问题，明确地建模了代理之间的交互。在本文中，我们介绍了用于部署SICNav的 crowds navigation 平台的系统概述，该平台已在未见过的室内和室外环境中进行部署。我们提供了系统运行的初步分析，涵盖两小时内在室内和室外环境中近7公里的自主导航。', 'title_zh': '将SICNav应用于现实场景：基于MPC和双层优化的的安全互动人群导航'}
{'arxiv_id': 'arXiv:2506.08840', 'title': 'MoRE: Mixture of Residual Experts for Humanoid Lifelike Gaits Learning on Complex Terrains', 'authors': 'Dewei Wang, Xinmiao Wang, Xinzhe Liu, Jiyuan Shi, Yingnan Zhao, Chenjia Bai, Xuelong Li', 'link': 'https://arxiv.org/abs/2506.08840', 'abstract': 'Humanoid robots have demonstrated robust locomotion capabilities using Reinforcement Learning (RL)-based approaches. Further, to obtain human-like behaviors, existing methods integrate human motion-tracking or motion prior in the RL framework. However, these methods are limited in flat terrains with proprioception only, restricting their abilities to traverse challenging terrains with human-like gaits. In this work, we propose a novel framework using a mixture of latent residual experts with multi-discriminators to train an RL policy, which is capable of traversing complex terrains in controllable lifelike gaits with exteroception. Our two-stage training pipeline first teaches the policy to traverse complex terrains using a depth camera, and then enables gait-commanded switching between human-like gait patterns. We also design gait rewards to adjust human-like behaviors like robot base height. Simulation and real-world experiments demonstrate that our framework exhibits exceptional performance in traversing complex terrains, and achieves seamless transitions between multiple human-like gait patterns.', 'abstract_zh': '基于混合潜在残差专家和多判别器的强化学习框架：具备外部感知的复杂地形可控仿人步态导航', 'title_zh': 'MoRE: 混合剩余专家模型用于复杂地形上的人形类生动力学学习'}
{'arxiv_id': 'arXiv:2506.08822', 'title': 'FreqPolicy: Efficient Flow-based Visuomotor Policy via Frequency Consistency', 'authors': 'Yifei Su, Ning Liu, Dong Chen, Zhen Zhao, Kun Wu, Meng Li, Zhiyuan Xu, Zhengping Che, Jian Tang', 'link': 'https://arxiv.org/abs/2506.08822', 'abstract': 'Generative modeling-based visuomotor policies have been widely adopted in robotic manipulation attributed to their ability to model multimodal action distributions. However, the high inference cost of multi-step sampling limits their applicability in real-time robotic systems. To address this issue, existing approaches accelerate the sampling process in generative modeling-based visuomotor policies by adapting acceleration techniques originally developed for image generation. Despite this progress, a major distinction remains: image generation typically involves producing independent samples without temporal dependencies, whereas robotic manipulation involves generating time-series action trajectories that require continuity and temporal coherence. To effectively exploit temporal information in robotic manipulation, we propose FreqPolicy, a novel approach that first imposes frequency consistency constraints on flow-based visuomotor policies. Our work enables the action model to capture temporal structure effectively while supporting efficient, high-quality one-step action generation. We introduce a frequency consistency constraint that enforces alignment of frequency-domain action features across different timesteps along the flow, thereby promoting convergence of one-step action generation toward the target distribution. In addition, we design an adaptive consistency loss to capture structural temporal variations inherent in robotic manipulation tasks. We assess FreqPolicy on 53 tasks across 3 simulation benchmarks, proving its superiority over existing one-step action generators. We further integrate FreqPolicy into the vision-language-action (VLA) model and achieve acceleration without performance degradation on the 40 tasks of Libero. Besides, we show efficiency and effectiveness in real-world robotic scenarios with an inference frequency 93.5Hz. The code will be publicly available.', 'abstract_zh': '基于生成模型的视运动策略在机器人操作中的应用得益于其建模多模态动作分布的能力。然而，多步采样的高推断成本限制了其在实时机器人系统中的应用。为了解决这一问题，现有方法通过适应为图像生成开发的加速技术来加速基于生成模型的视运动策略的采样过程。尽管取得了进展，但仍存在一个重要区别：图像生成通常涉及生成独立样本而不包含时间依赖性，而机器人操作涉及生成需要连续性和时间一致性的时序动作轨迹。为了有效利用机器人操作中的时间信息，我们提出了FreqPolicy这一新颖方法，首先在流基于的视运动策略上施加频率一致性约束。我们的工作使得动作模型能够有效地捕捉时间结构，并支持高效、高质量的一步动作生成。我们引入了一种频率一致性约束，该约束要求沿流的不同时间步长中动作特征的频率域对齐，从而促进一步动作生成向目标分布收敛。此外，我们设计了一种自适应一致性损失，以捕捉机器人操作任务中固有的结构时间变化。我们在3个仿真基准上的53个任务上评估了FreqPolicy，证明了它在现有的一步动作生成器中的优越性。我们进一步将FreqPolicy集成到视语言动作（VLA）模型中，在Libero的40个任务上实现了加速且不降低性能。此外，我们展示了其在实际机器人场景中的高效性和有效性，推断频率为93.5Hz。代码将公开。', 'title_zh': 'FreqPolicy: 通过频率一致性实现高效的基于流的视运动策略'}
{'arxiv_id': 'arXiv:2506.08795', 'title': 'Towards Biosignals-Free Autonomous Prosthetic Hand Control via Imitation Learning', 'authors': 'Kaijie Shi, Wanglong Lu, Hanli Zhao, Vinicius Prado da Fonseca, Ting Zou, Xianta Jiang', 'link': 'https://arxiv.org/abs/2506.08795', 'abstract': "Limb loss affects millions globally, impairing physical function and reducing quality of life. Most traditional surface electromyographic (sEMG) and semi-autonomous methods require users to generate myoelectric signals for each control, imposing physically and mentally taxing demands. This study aims to develop a fully autonomous control system that enables a prosthetic hand to automatically grasp and release objects of various shapes using only a camera attached to the wrist. By placing the hand near an object, the system will automatically execute grasping actions with a proper grip force in response to the hand's movements and the environment. To release the object being grasped, just naturally place the object close to the table and the system will automatically open the hand. Such a system would provide individuals with limb loss with a very easy-to-use prosthetic control interface and greatly reduce mental effort while using. To achieve this goal, we developed a teleoperation system to collect human demonstration data for training the prosthetic hand control model using imitation learning, which mimics the prosthetic hand actions from human. Through training the model using only a few objects' data from one single participant, we have shown that the imitation learning algorithm can achieve high success rates, generalizing to more individuals and unseen objects with a variation of weights. The demonstrations are available at \\href{this https URL}{this https URL}", 'abstract_zh': '截肢影响全球数百万人，妨碍物理功能并降低生活质量。大多数传统的表面肌电图（sEMG）和半自主方法要求用户为每个控制生成肌电信号，这给用户带来了身体和精神上的负担。本研究旨在开发一种完全自主的控制系统，使假手能够在佩戴手腕摄像头的情况下自动抓取和释放各种形状的物体。通过将手置于物体附近，系统将根据手的运动和环境自动执行适当握力的抓取动作。松开被抓取的物体时，只需自然地将物体靠近桌面，系统将自动打开手掌。这样一种系统将为截肢人士提供一个非常易于使用的假手控制界面，并在使用时大大减少精神负担。为了实现这一目标，我们开发了一个遥控系统来收集人类示范数据，使用模仿学习训练假手控制模型，该模型模仿人类的假手动作。通过仅使用单个参与者几种物体的数据训练模型，我们已经证明模仿学习算法可以在不同的个体和未见过的物体上实现高的成功率，并通过调整权重进行泛化。示范数据可在 \\href{this https URL}{this https URL} 获取。', 'title_zh': '基于 imitation learning 的无生物信号自主假手控制'}
{'arxiv_id': 'arXiv:2506.08708', 'title': 'PhyBlock: A Progressive Benchmark for Physical Understanding and Planning via 3D Block Assembly', 'authors': 'Liang Ma, Jiajun Wen, Min Lin, Rongtao Xu, Xiwen Liang, Bingqian Lin, Jun Ma, Yongxin Wang, Ziming Wei, Haokun Lin, Mingfei Han, Meng Cao, Bokui Chen, Ivan Laptev, Xiaodan Liang', 'link': 'https://arxiv.org/abs/2506.08708', 'abstract': 'While vision-language models (VLMs) have demonstrated promising capabilities in reasoning and planning for embodied agents, their ability to comprehend physical phenomena, particularly within structured 3D environments, remains severely limited. To close this gap, we introduce PhyBlock, a progressive benchmark designed to assess VLMs on physical understanding and planning through robotic 3D block assembly tasks. PhyBlock integrates a novel four-level cognitive hierarchy assembly task alongside targeted Visual Question Answering (VQA) samples, collectively aimed at evaluating progressive spatial reasoning and fundamental physical comprehension, including object properties, spatial relationships, and holistic scene understanding. PhyBlock includes 2600 block tasks (400 assembly tasks, 2200 VQA tasks) and evaluates models across three key dimensions: partial completion, failure diagnosis, and planning robustness. We benchmark 21 state-of-the-art VLMs, highlighting their strengths and limitations in physically grounded, multi-step planning. Our empirical findings indicate that the performance of VLMs exhibits pronounced limitations in high-level planning and reasoning capabilities, leading to a notable decline in performance for the growing complexity of the tasks. Error analysis reveals persistent difficulties in spatial orientation and dependency reasoning. Surprisingly, chain-of-thought prompting offers minimal improvements, suggesting spatial tasks heavily rely on intuitive model comprehension. We position PhyBlock as a unified testbed to advance embodied reasoning, bridging vision-language understanding and real-world physical problem-solving.', 'abstract_zh': 'PhyBlock：一种用于评估视觉-语言模型物理理解与规划能力的渐进式基准', 'title_zh': 'PhyBlock：通过3D拼块组装的渐进式物理理解和规划基准'}
{'arxiv_id': 'arXiv:2506.08639', 'title': 'Deep Reinforcement Learning-Based Motion Planning and PDE Control for Flexible Manipulators', 'authors': 'Amir Hossein Barjini, Seyed Adel Alizadeh Kolagar, Sadeq Yaqubi, Jouni Mattila', 'link': 'https://arxiv.org/abs/2506.08639', 'abstract': 'This article presents a motion planning and control framework for flexible robotic manipulators, integrating deep reinforcement learning (DRL) with a nonlinear partial differential equation (PDE) controller. Unlike conventional approaches that focus solely on control, we demonstrate that the desired trajectory significantly influences endpoint vibrations. To address this, a DRL motion planner, trained using the soft actor-critic (SAC) algorithm, generates optimized trajectories that inherently minimize vibrations. The PDE nonlinear controller then computes the required torques to track the planned trajectory while ensuring closed-loop stability using Lyapunov analysis. The proposed methodology is validated through both simulations and real-world experiments, demonstrating superior vibration suppression and tracking accuracy compared to traditional methods. The results underscore the potential of combining learning-based motion planning with model-based control for enhancing the precision and stability of flexible robotic manipulators.', 'abstract_zh': '一种将深度强化学习与非线性偏微分方程控制器集成的柔性机器人 manipulator 运动规划与控制框架', 'title_zh': '基于深度强化学习的柔性 manipulator 运动规划与偏微分方程控制'}
{'arxiv_id': 'arXiv:2506.08578', 'title': 'Noise Analysis and Hierarchical Adaptive Body State Estimator For Biped Robot Walking With ESVC Foot', 'authors': 'Boyang Chen, Xizhe Zang, Chao Song, Yue Zhang, Xuehe Zhang, Jie Zhao', 'link': 'https://arxiv.org/abs/2506.08578', 'abstract': 'The ESVC(Ellipse-based Segmental Varying Curvature) foot, a robot foot design inspired by the rollover shape of the human foot, significantly enhances the energy efficiency of the robot walking gait. However, due to the tilt of the supporting leg, the error of the contact model are amplified, making robot state estimation more challenging. Therefore, this paper focuses on the noise analysis and state estimation for robot walking with the ESVC foot. First, through physical robot experiments, we investigate the effect of the ESVC foot on robot measurement noise and process noise. and a noise-time regression model using sliding window strategy is developed. Then, a hierarchical adaptive state estimator for biped robots with the ESVC foot is proposed. The state estimator consists of two stages: pre-estimation and post-estimation. In the pre-estimation stage, a data fusion-based estimation is employed to process the sensory data. During post-estimation, the acceleration of center of mass is first estimated, and then the noise covariance matrices are adjusted based on the regression model. Following that, an EKF(Extended Kalman Filter) based approach is applied to estimate the centroid state during robot walking. Physical experiments demonstrate that the proposed adaptive state estimator for biped robot walking with the ESVC foot not only provides higher precision than both EKF and Adaptive EKF, but also converges faster under varying noise conditions.', 'abstract_zh': '基于椭圆段变曲率(EVSC)脚的两足机器人姿态估计与噪声分析研究', 'title_zh': '噪声分析及基于ESVC足的 biped机器人步行分层自适应身体状态估计器'}
{'arxiv_id': 'arXiv:2506.08440', 'title': 'TGRPO :Fine-tuning Vision-Language-Action Model via Trajectory-wise Group Relative Policy Optimization', 'authors': 'Zengjue Chen, Runliang Niu, He Kong, Qi Wang', 'link': 'https://arxiv.org/abs/2506.08440', 'abstract': "Recent advances in Vision-Language-Action (VLA) model have demonstrated strong generalization capabilities across diverse scenes, tasks, and robotic platforms when pretrained at large-scale datasets. However, these models still require task-specific fine-tuning in novel environments, a process that relies almost exclusively on supervised fine-tuning (SFT) using static trajectory datasets. Such approaches neither allow robot to interact with environment nor do they leverage feedback from live execution. Also, their success is critically dependent on the size and quality of the collected trajectories. Reinforcement learning (RL) offers a promising alternative by enabling closed-loop interaction and aligning learned policies directly with task objectives. In this work, we draw inspiration from the ideas of GRPO and propose the Trajectory-wise Group Relative Policy Optimization (TGRPO) method. By fusing step-level and trajectory-level advantage signals, this method improves GRPO's group-level advantage estimation, thereby making the algorithm more suitable for online reinforcement learning training of VLA. Experimental results on ten manipulation tasks from the libero-object benchmark demonstrate that TGRPO consistently outperforms various baseline methods, capable of generating more robust and efficient policies across multiple tested scenarios. Our source codes are available at: this https URL", 'abstract_zh': 'Recent Advances in Vision-Language-Action (VLA) Model: Trajectory-wise Group Relative Policy Optimization for Robotic Manipulation Tasks', 'title_zh': 'TGRPO：基于轨迹-wise 组相对策略优化的视觉-语言-动作模型微调'}
{'arxiv_id': 'arXiv:2506.08416', 'title': 'Periodic Bipedal Gait Learning Using Reward Composition Based on a Novel Gait Planner for Humanoid Robots', 'authors': 'Bolin Li, Linwei Sun, Xuecong Huang, Yuzhi Jiang, Lijun Zhu', 'link': 'https://arxiv.org/abs/2506.08416', 'abstract': "This paper presents a periodic bipedal gait learning method using reward composition, integrated with a real-time gait planner for humanoid robots. First, we introduce a novel gait planner that incorporates dynamics to design the desired joint trajectory. In the gait design process, the 3D robot model is decoupled into two 2D models, which are then approximated as hybrid inverted pendulums (H-LIP) for trajectory planning. The gait planner operates in parallel in real time within the robot's learning environment. Second, based on this gait planner, we design three effective reward functions within a reinforcement learning framework, forming a reward composition to achieve periodic bipedal gait. This reward composition reduces the robot's learning time and enhances locomotion performance. Finally, a gait design example and performance comparison are presented to demonstrate the effectiveness of the proposed method.", 'abstract_zh': '本文提出了一种基于奖励组成的学习周期性双足步态方法，并结合实时步态规划器应用于类人机器人。首先，我们介绍了一种新的步态规划器，该规划器包含动力学设计来规划期望的关节轨迹。在步态设计过程中，3D 机器人模型被分解为两个2D模型，然后近似为混合倒摆（H-LIP）以进行轨迹规划。该步态规划器在机器人学习环境中实时并行运行。其次，基于此步态规划器，我们在强化学习框架内设计了三种有效的奖励函数，组成奖励函数以实现周期性双足步态。这种奖励函数组成减少了机器人学习时间并提升了运动性能。最后，给出了一个步态设计实例和性能对比，以展示所提方法的有效性。', 'title_zh': '基于新型步态规划器的基于奖励组成的人形机器人双足周期步态学习'}
{'arxiv_id': 'arXiv:2506.08296', 'title': 'HiBerNAC: Hierarchical Brain-emulated Robotic Neural Agent Collective for Disentangling Complex Manipulation', 'authors': 'Hongjun Wu, Heng Zhang, Pengsong Zhang, Jin Wang, Cong Wang', 'link': 'https://arxiv.org/abs/2506.08296', 'abstract': 'Recent advances in multimodal vision-language-action (VLA) models have revolutionized traditional robot learning, enabling systems to interpret vision, language, and action in unified frameworks for complex task planning. However, mastering complex manipulation tasks remains an open challenge, constrained by limitations in persistent contextual memory, multi-agent coordination under uncertainty, and dynamic long-horizon planning across variable sequences. To address this challenge, we propose \\textbf{HiBerNAC}, a \\textbf{Hi}erarchical \\textbf{B}rain-\\textbf{e}mulated \\textbf{r}obotic \\textbf{N}eural \\textbf{A}gent \\textbf{C}ollective, inspired by breakthroughs in neuroscience, particularly in neural circuit mechanisms and hierarchical decision-making. Our framework combines: (1) multimodal VLA planning and reasoning with (2) neuro-inspired reflection and multi-agent mechanisms, specifically designed for complex robotic manipulation tasks. By leveraging neuro-inspired functional modules with decentralized multi-agent collaboration, our approach enables robust and enhanced real-time execution of complex manipulation tasks. In addition, the agentic system exhibits scalable collective intelligence via dynamic agent specialization, adapting its coordination strategy to variable task horizons and complexity. Through extensive experiments on complex manipulation tasks compared with state-of-the-art VLA models, we demonstrate that \\textbf{HiBerNAC} reduces average long-horizon task completion time by 23\\%, and achieves non-zero success rates (12\\textendash 31\\%) on multi-path tasks where prior state-of-the-art VLA models consistently fail. These results provide indicative evidence for bridging biological cognition and robotic learning mechanisms.', 'abstract_zh': 'Recent Advances in Multimodal Vision-Language-Action (VLA) Models Have Revolutionized Traditional Robot Learning, Enabling Systems to Interpret Vision, Language, and Action in Unified Frameworks for Complex Task Planning. However, Mastering Complex Manipulation Tasks Remains an Open Challenge, Constrained by Limitations in Persistent Contextual Memory, Multi-Agent Coordination Under Uncertainty, and Dynamic Long-Horizon Planning Across Variable Sequences. To Address This Challenge, We Propose HiBerNAC, a Hierarchical Brain-Emulated Robotic Neural Agent Collective, Inspired by Breakthroughs in Neuroscience, Particularly in Neural Circuit Mechanisms and Hierarchical Decision-Making.', 'title_zh': 'HiBerNAC：分层次类脑机器人神经代理集体用于解缠复杂操作'}
{'arxiv_id': 'arXiv:2506.08149', 'title': 'Ego-centric Learning of Communicative World Models for Autonomous Driving', 'authors': 'Hang Wang, Dechen Gao, Junshan Zhang', 'link': 'https://arxiv.org/abs/2506.08149', 'abstract': 'We study multi-agent reinforcement learning (MARL) for tasks in complex high-dimensional environments, such as autonomous driving. MARL is known to suffer from the \\textit{partial observability} and \\textit{non-stationarity} issues. To tackle these challenges, information sharing is often employed, which however faces major hurdles in practice, including overwhelming communication overhead and scalability concerns. By making use of generative AI embodied in world model together with its latent representation, we develop {\\it CALL}, \\underline{C}ommunic\\underline{a}tive Wor\\underline{l}d Mode\\underline{l}, for MARL, where 1) each agent first learns its world model that encodes its state and intention into low-dimensional latent representation with smaller memory footprint, which can be shared with other agents of interest via lightweight communication; and 2) each agent carries out ego-centric learning while exploiting lightweight information sharing to enrich her world model, and then exploits its generalization capacity to improve prediction for better planning. We characterize the gain on the prediction accuracy from the information sharing and its impact on performance gap. Extensive experiments are carried out on the challenging local trajectory planning tasks in the CARLA platform to demonstrate the performance gains of using \\textit{CALL}.', 'abstract_zh': '基于生成AI的世界模型的多智能体强化学习：COMMWorldModel', 'title_zh': '以自我为中心的学习交流世界模型用于自主驾驶'}
{'arxiv_id': 'arXiv:2506.08045', 'title': 'UAVs Meet Agentic AI: A Multidomain Survey of Autonomous Aerial Intelligence and Agentic UAVs', 'authors': 'Ranjan Sapkota, Konstantinos I. Roumeliotis, Manoj Karkee', 'link': 'https://arxiv.org/abs/2506.08045', 'abstract': 'Agentic UAVs represent a new frontier in autonomous aerial intelligence, integrating perception, decision-making, memory, and collaborative planning to operate adaptively in complex, real-world environments. Driven by recent advances in Agentic AI, these systems surpass traditional UAVs by exhibiting goal-driven behavior, contextual reasoning, and interactive autonomy. We provide a comprehensive foundation for understanding the architectural components and enabling technologies that distinguish Agentic UAVs from traditional autonomous UAVs. Furthermore, a detailed comparative analysis highlights advancements in autonomy with AI agents, learning, and mission flexibility. This study explores seven high-impact application domains precision agriculture, construction & mining, disaster response, environmental monitoring, infrastructure inspection, logistics, security, and wildlife conservation, illustrating the broad societal value of agentic aerial intelligence. Furthermore, we identify key challenges in technical constraints, regulatory limitations, and data-model reliability, and we present emerging solutions across hardware innovation, learning architectures, and human-AI interaction. Finally, a future roadmap is proposed, outlining pathways toward self-evolving aerial ecosystems, system-level collaboration, and sustainable, equitable deployments. This survey establishes a foundational framework for the future development, deployment, and governance of agentic aerial systems (Agentic UAVs) across diverse societal and industrial domains.', 'abstract_zh': '自主无人机代表了自主空中智能的新前沿，融合了感知、决策、记忆和协作规划能力，能够在复杂的真实世界环境中灵活操作。随着自主人工智能的 Recent 进展，这些系统通过表现出目标驱动的行为、情境推理和交互式自主超越了传统的无人机。我们提供了理解自主无人机与传统自主无人机差异性的综合架构和使能技术基础。此外，详细的比较分析突显了自主性、学习与任务灵活性的进展。本研究探讨了七个高影响应用领域——精准农业、建筑业与采矿业、灾害响应、环境监测、基础设施检查、物流、安全以及野生动物保护——展示了自主空中智能的广泛社会价值。此外，我们确定了技术约束、监管限制和数据-模型可靠性等关键挑战，并提出了硬件创新、学习架构和人-机交互领域的新兴解决方案。最后，我们提出了未来的路线图，概述了自演化空中生态系统、系统级协作以及可持续、公平部署的路径。这篇综述为自主空中系统（自主无人机）在不同社会和工业领域的未来开发、部署和治理奠定了基础框架。', 'title_zh': 'UAVs遇上了能动AI：自主航空智能与能动无人机的多领域综述'}
{'arxiv_id': 'arXiv:2506.09049', 'title': 'VIKI-R: Coordinating Embodied Multi-Agent Cooperation via Reinforcement Learning', 'authors': 'Li Kang, Xiufeng Song, Heng Zhou, Yiran Qin, Jie Yang, Xiaohong Liu, Philip Torr, Lei Bai, Zhenfei Yin', 'link': 'https://arxiv.org/abs/2506.09049', 'abstract': 'Coordinating multiple embodied agents in dynamic environments remains a core challenge in artificial intelligence, requiring both perception-driven reasoning and scalable cooperation strategies. While recent works have leveraged large language models (LLMs) for multi-agent planning, a few have begun to explore vision-language models (VLMs) for visual reasoning. However, these VLM-based approaches remain limited in their support for diverse embodiment types. In this work, we introduce VIKI-Bench, the first hierarchical benchmark tailored for embodied multi-agent cooperation, featuring three structured levels: agent activation, task planning, and trajectory perception. VIKI-Bench includes diverse robot embodiments, multi-view visual observations, and structured supervision signals to evaluate reasoning grounded in visual inputs. To demonstrate the utility of VIKI-Bench, we propose VIKI-R, a two-stage framework that fine-tunes a pretrained vision-language model (VLM) using Chain-of-Thought annotated demonstrations, followed by reinforcement learning under multi-level reward signals. Our extensive experiments show that VIKI-R significantly outperforms baselines method across all task levels. Furthermore, we show that reinforcement learning enables the emergence of compositional cooperation patterns among heterogeneous agents. Together, VIKI-Bench and VIKI-R offer a unified testbed and method for advancing multi-agent, visual-driven cooperation in embodied AI systems.', 'abstract_zh': '协调多智能体在动态环境中的交互仍然是人工智能领域的核心挑战，需要感知驱动的推理能力和可扩展的合作策略。虽然最近的研究利用了大型语言模型（LLMs）进行多智能体规划，少数研究开始探索视觉-语言模型（VLMs）进行视觉推理。然而，这些基于VLM的方法在支持多种载体类型方面仍有限制。在本文中，我们引入了VIKI-Bench，这是第一个专门针对智能体协作设计的分层基准，包括三个结构化的层级：智能体激活、任务规划和轨迹感知。VIKI-Bench 包括多种机器人载体、多视角视觉观察以及基于视觉输入的结构化监督信号，以评价视觉推理能力。为了展示VIKI-Bench 的 usefulness，我们提出了VIKI-R 两阶段框架，该框架首先使用带有Chain-of-Thought标注示范来微调预训练的视觉-语言模型（VLM），然后在多层次奖励信号下进行强化学习。我们的大量实验表明，VIKI-R 在所有任务层级上显著优于基线方法。此外，我们展示了强化学习使得异质智能体之间组合协作模式的涌现。总之，VIKI-Bench 和 VIKI-R 提供了一个统一的测试平台和方法，以推进基于视觉驱动的多智能体协作在具身人工智能系统中的发展。', 'title_zh': 'VIKI-R：通过强化学习协调具身多智能体合作'}
{'arxiv_id': 'arXiv:2506.08892', 'title': 'Help or Hindrance: Understanding the Impact of Robot Communication in Action Teams', 'authors': 'Tauhid Tanjim, Jonathan St. George, Kevin Ching, Hee Rin Lee, Angelique Taylor', 'link': 'https://arxiv.org/abs/2506.08892', 'abstract': 'The human-robot interaction (HRI) field has recognized the importance of enabling robots to interact with teams. Human teams rely on effective communication for successful collaboration in time-sensitive environments. Robots can play a role in enhancing team coordination through real-time assistance. Despite significant progress in human-robot teaming research, there remains an essential gap in how robots can effectively communicate with action teams using multimodal interaction cues in time-sensitive environments. This study addresses this knowledge gap in an experimental in-lab study to investigate how multimodal robot communication in action teams affects workload and human perception of robots. We explore team collaboration in a medical training scenario where a robotic crash cart (RCC) provides verbal and non-verbal cues to help users remember to perform iterative tasks and search for supplies. Our findings show that verbal cues for object search tasks and visual cues for task reminders reduce team workload and increase perceived ease of use and perceived usefulness more effectively than a robot with no feedback. Our work contributes to multimodal interaction research in the HRI field, highlighting the need for more human-robot teaming research to understand best practices for integrating collaborative robots in time-sensitive environments such as in hospitals, search and rescue, and manufacturing applications.', 'abstract_zh': '人机交互（HRI）领域已认识到使机器人能够与团队互动的重要性。人类团队依赖有效的沟通在时间敏感环境中实现成功的合作。机器人可以通过实时协助在团队协调中发挥作用。尽管在人机团队合作研究方面取得了显著进展，但在时间敏感环境中，如何通过多模态交互提示有效与行动团队沟通的问题仍是一个重要缺口。本研究通过实验室内研究解决这一知识缺口，探讨多模态机器人通信如何影响工作负荷和人类对机器人的感知。我们探讨了在医疗培训场景中，机器人急救车（RCC）通过口头和非口头提示帮助用户记得执行迭代任务和寻找物资的方式。研究发现，在物体搜索任务中使用口头提示，在任务提醒中使用视觉提示，比没有反馈的机器人更能有效减少团队工作负荷并提高对机器人的使用便捷性和有用性的感知。我们的研究为HRI领域的多模态交互研究做出了贡献，强调了在医院、搜索与救援和制造等时间敏感环境中更好地整合协作机器人所需的人机团队合作研究的重要性。', 'title_zh': '助益还是障碍：理解机器人沟通在行动团队中的影响'}
{'arxiv_id': 'arXiv:2506.08807', 'title': 'Confidence Boosts Trust-Based Resilience in Cooperative Multi-Robot Systems', 'authors': 'Luca Ballotta, Áron Vékássy, Stephanie Gil, Michal Yemini', 'link': 'https://arxiv.org/abs/2506.08807', 'abstract': 'Wireless communication-based multi-robot systems open the door to cyberattacks that can disrupt safety and performance of collaborative robots. The physical channel supporting inter-robot communication offers an attractive opportunity to decouple the detection of malicious robots from task-relevant data exchange between legitimate robots. Yet, trustworthiness indications coming from physical channels are uncertain and must be handled with this in mind. In this paper, we propose a resilient protocol for multi-robot operation wherein a parameter {\\lambda}t accounts for how confident a robot is about the legitimacy of nearby robots that the physical channel indicates. Analytical results prove that our protocol achieves resilient coordination with arbitrarily many malicious robots under mild assumptions. Tuning {\\lambda}t allows a designer to trade between near-optimal inter-robot coordination and quick task execution; see Fig. 1. This is a fundamental performance tradeoff and must be carefully evaluated based on the task at hand. The effectiveness of our approach is numerically verified with experiments involving platoons of autonomous cars where some vehicles are maliciously spoofed.', 'abstract_zh': '基于无线通信的多机器人系统打开了通往干扰协作机器人安全性和性能的网络攻击的大门。支撑机器人间通信的物理信道提供了从合法机器人之间的任务相关数据交换中分离出恶意机器人检测的机会。然而，来自物理信道的信任指示具有不确定性，必须予以考虑。在本文中，我们提出了一种鲁棒的多机器人操作协议，其中参数λt表示机器人对其根据物理信道指示的附近机器人的合法性有多大的信心。理论结果证明，在温和假设下，我们的协议可以实现对任意数量恶意机器人的鲁棒协调。调整λt允许设计者在接近最优的机器人间协调和快速任务执行之间进行权衡；参见图1。这是基本的性能权衡，必须根据具体任务仔细评估。通过涉及恶意欺骗部分自主车辆的车队进行实验，验证了我们方法的有效性。', 'title_zh': '自信增强基于信任的协作多机器人系统韧性'}
{'arxiv_id': 'arXiv:2506.08805', 'title': 'Communicating Through Avatars in Industry 5.0: A Focus Group Study on Human-Robot Collaboration', 'authors': 'Stina Klein, Pooja Prajod, Katharina Weitz, Matteo Lavit Nicora, Dimitra Tsovaltzi, Elisabeth André', 'link': 'https://arxiv.org/abs/2506.08805', 'abstract': "The integration of collaborative robots (cobots) in industrial settings raises concerns about worker well-being, particularly due to reduced social interactions. Avatars - designed to facilitate worker interactions and engagement - are promising solutions to enhance the human-robot collaboration (HRC) experience. However, real-world perspectives on avatar-supported HRC remain unexplored. To address this gap, we conducted a focus group study with employees from a German manufacturing company that uses cobots. Before the discussion, participants engaged with a scripted, industry-like HRC demo in a lab setting. This qualitative approach provided valuable insights into the avatar's potential roles, improvements to its behavior, and practical considerations for deploying them in industrial workcells. Our findings also emphasize the importance of personalized communication and task assistance. Although our study's limitations restrict its generalizability, it serves as an initial step in recognizing the potential of adaptive, context-aware avatar interactions in real-world industrial environments.", 'abstract_zh': '协作机器人（cobots）在工业环境中的集成引发了关于工人福祉的担忧，尤其是由于减少了社会互动。设计用于促进工人互动和参与的虚拟角色（avatar）是增强人类-机器人协作（HRC）体验的有前景的解决方案。然而，关于支持 avatar 的 HRC 的实际观点尚未被探索。为填补这一空白，我们对一家使用协作机器人的德国制造公司员工进行了焦点小组研究。在讨论前，参与者在实验室环境中参与了一个针对工业场景的 HRC 演示。通过这种质性研究方法，我们获得了有关 avatar 的潜在角色、其行为改进以及在工业工作站部署时的实际考虑的宝贵见解。研究结果还强调了个性化沟通和支持任务的重要性。尽管我们的研究存在局限性，限制了其普遍性，但它为识别适应性强、上下文感知的 avatar 交互在真实工业环境中的潜力提供了一个初步步骤。', 'title_zh': '在 Industry 4.0 的背景下通过 avatar 进行沟通：人类与机器人协作的焦点小组研究'}
{'arxiv_id': 'arXiv:2506.08630', 'title': 'Modular Recurrence in Contextual MDPs for Universal Morphology Control', 'authors': 'Laurens Engwegen, Daan Brinks, Wendelin Böhmer', 'link': 'https://arxiv.org/abs/2506.08630', 'abstract': 'A universal controller for any robot morphology would greatly improve computational and data efficiency. By utilizing contextual information about the properties of individual robots and exploiting their modular structure in the architecture of deep reinforcement learning agents, steps have been made towards multi-robot control. Generalization to new, unseen robots, however, remains a challenge. In this paper we hypothesize that the relevant contextual information is partially observable, but that it can be inferred through interactions for better generalization to contexts that are not seen during training. To this extent, we implement a modular recurrent architecture and evaluate its generalization performance on a large set of MuJoCo robots. The results show a substantial improved performance on robots with unseen dynamics, kinematics, and topologies, in four different environments.', 'abstract_zh': '一种适用于任意机器人形态的通用控制器将大大提高计算和数据效率。通过利用关于个体机器人特性的上下文信息并利用其模块化结构在深度强化学习代理的架构中，我们已在多机器人控制方面取得了一些进展。然而，将控制扩展到新的、未见过的机器人仍然是一个挑战。在本文中，我们假设相关的上下文信息是部分可观测的，但可以通过交互来推断，从而更好地泛化到训练过程中未见过的上下文中。为此，我们实现了一种模块化的循环结构，并在大量MuJoCo机器人的集合上评估其泛化性能。结果表明，该方法在四种不同环境中对未见过的动力学、运动学和拓扑结构的机器人表现出显著提高的性能。', 'title_zh': 'Contextual MDPs 中的模块化复发控制通用形态学控制'}
{'arxiv_id': 'arXiv:2506.08462', 'title': 'Hybrid Reasoning for Perception, Explanation, and Autonomous Action in Manufacturing', 'authors': 'Christos Margadji, Sebastian W. Pattinson', 'link': 'https://arxiv.org/abs/2506.08462', 'abstract': 'Industrial processes must be robust and adaptable, as environments and tasks are often unpredictable, while operational errors remain costly and difficult to detect. AI-based control systems offer a path forward, yet typically depend on supervised learning with extensive labelled datasets, which limits their ability to generalize across variable and data-scarce industrial settings. Foundation models could enable broader reasoning and knowledge integration, but rarely deliver the quantitative precision demanded by engineering applications. Here, we introduceControl and Interpretation of Production via Hybrid Expertise and Reasoning (CIPHER): a vision-language-action (VLA) model framework aiming to replicate human-like reasoning for industrial control, instantiated in a commercial-grade 3D printer. It integrates a process expert, a regression model enabling quantitative characterization of system states required for engineering tasks. CIPHER also incorporates retrieval-augmented generation to access external expert knowledge and support physics-informed, chain-of-thought reasoning. This hybrid architecture exhibits strong generalization to out-of-distribution tasks. It interprets visual or textual inputs from process monitoring, explains its decisions, and autonomously generates precise machine instructions, without requiring explicit annotations. CIPHER thus lays the foundations for autonomous systems that act with precision, reason with context, and communicate decisions transparently, supporting safe and trusted deployment in industrial settings.', 'abstract_zh': '基于混合专家知识与推理的生产控制与解释（CIPHER）：一种视角-语言-动作模型框架', 'title_zh': '制造领域中的混合推理以实现感知、解释和自主行动'}
{'arxiv_id': 'arXiv:2506.08460', 'title': 'MOBODY: Model Based Off-Dynamics Offline Reinforcement Learning', 'authors': 'Yihong Guo, Yu Yang, Pan Xu, Anqi Liu', 'link': 'https://arxiv.org/abs/2506.08460', 'abstract': 'We study the off-dynamics offline reinforcement learning problem, where the goal is to learn a policy from offline datasets collected from source and target domains with mismatched transition. Existing off-dynamics offline RL methods typically either filter source transitions that resemble those of the target domain or apply reward augmentation to source data, both constrained by the limited transitions available from the target domain. As a result, the learned policy is unable to explore target domain beyond the offline datasets. We propose MOBODY, a Model-Based Off-Dynamics offline RL algorithm that addresses this limitation by enabling exploration of the target domain via learned dynamics. MOBODY generates new synthetic transitions in the target domain through model rollouts, which are used as data augmentation during offline policy learning. Unlike existing model-based methods that learn dynamics from a single domain, MOBODY tackles the challenge of mismatched dynamics by leveraging both source and target datasets. Directly merging these datasets can bias the learned model toward source dynamics. Instead, MOBODY learns target dynamics by discovering a shared latent representation of states and transitions across domains through representation learning. To stabilize training, MOBODY incorporates a behavior cloning loss that regularizes the policy. Specifically, we introduce a Q-weighted behavior cloning loss that regularizes the policy toward actions with high target-domain Q-values, rather than uniformly imitating all actions in the dataset. These Q-values are learned from an enhanced target dataset composed of offline target data, augmented source data, and rollout data from the learned target dynamics. We evaluate MOBODY on MuJoCo benchmarks and show that it significantly outperforms state-of-the-art baselines, with especially pronounced improvements in challenging scenarios.', 'abstract_zh': '我们研究了离线动力学离线强化学习问题，其目标是从源域和目标域之间存在转换不匹配的离线数据集中学习策略。现有的离线动力学离线RL方法通常要么过滤掉与目标域相似的源域转换，要么对源数据进行奖励增强，这两种方法都受到目标域可用转换有限的限制。因此，学到的策略无法探索超出离线数据集的目标域。我们提出了MOBODY，一种基于模型的离线动力学离线RL算法，通过利用学到的动力学来探索目标域来解决这一限制。MOBODY通过模型rollout生成新的合成转换，这些转换在离线策略学习期间用作数据增强。与从单个域学习动力学的现有基于模型的方法不同，MOBODY通过利用源域和目标域的数据集来应对动力学不匹配的挑战。直接将这些数据集合并会导致学到的模型偏向源域动力学。相反，MOBODY通过代表性学习在各域之间发现状态和转换的共享潜在表示来学习目标动力学。为了稳定训练，MOBODY引入了一种Q加权行为克隆损失来正则化策略。具体而言，我们引入了一种Q加权行为克隆损失，该损失将策略正则化为具有高目标域Q值的动作，而不是均匀地模仿数据集中的所有动作。这些Q值是从扩展的目标数据集中学习而来的，该数据集包括离线目标数据、增强的源数据和学习到的目标动力学生成的rollout数据。我们在MuJoCo基准上评估了MOBODY，并展示了它显著优于最先进的基线方法，特别是在具有挑战性的场景中表现尤为突出。', 'title_zh': 'MOBODY：基于模型的离线动力学 Offline 强化学习'}
{'arxiv_id': 'arXiv:2506.08319', 'title': 'DEKC: Data-Enable Control for Tethered Space Robot Deployment in the Presence of Uncertainty via Koopman Operator Theory', 'authors': 'Ao Jin, Qinyi Wang, Sijie Wen, Ya Liu, Ganghui Shen, Panfeng Huang, Fan Zhang', 'link': 'https://arxiv.org/abs/2506.08319', 'abstract': 'This work focuses the deployment of tethered space robot in the presence of unknown uncertainty. A data-enable framework called DEKC which contains offline training part and online execution part is proposed to deploy tethered space robot in the presence of uncertainty. The main idea of this work is modeling the unknown uncertainty as a dynamical system, which enables high accuracy and convergence of capturing uncertainty. The core part of proposed framework is a proxy model of uncertainty, which is derived from data-driven Koopman theory and is separated with controller design. In the offline stage, the lifting functions associated with Koopman operator are parameterized with deep neural networks. Then by solving an optimization problem, the lifting functions are learned from sampling data. In the online execution stage, the proxy model cooperates the learned lifting functions obtained in the offline phase to capture the unknown uncertainty. Then the output of proxy model is compensated to the baseline controller such that the effect of uncertainty can be attenuated or even eliminated. Furthermore, considering some scenarios in which the performance of proxy model may weaken, a receding-horizon scheme is proposed to update the proxy model online. Finally, the extensive numerical simulations demonstrate the effectiveness of our proposed framework. The implementation of proposed DEKC framework is publicly available at this https URL.', 'abstract_zh': '本工作聚焦在未知不确定性环境下的系留空间机器人部署。提出了一种名为DEKC的数据使能框架，该框架包含离线训练部分和在线执行部分，以在不确定性环境下部署系留空间机器人。本文的主要思路是将未知不确定性建模为动力系统，从而实现不确定性捕捉的高精度和收敛性。所提框架的核心部分是不确定性代理模型，该模型源自数据驱动的科昂曼理论，并与控制设计分离。在离线阶段，与科昂曼算子关联的提升函数采用深度神经网络参数化。然后通过求解优化问题，从采样数据中学习提升函数。在在线执行阶段，代理模型与离线阶段学习到的提升函数合作，捕捉未知不确定性。然后将代理模型的输出补偿到基线控制器，以减轻或消除不确定性的影响。此外，考虑到代理模型在某些场景中性能可能减弱的情况，提出了一种前瞻式的方案在线更新代理模型。最后，广泛的数值仿真实验验证了所提框架的有效性。所提出的DEKC框架的实现可以在以下网址获取。', 'title_zh': 'DEKC: 数据驱动控制在不确定性环境下系留太空机器人部署的方法基于柯普曼算子理论'}
{'arxiv_id': 'arXiv:2506.08052', 'title': 'ReCogDrive: A Reinforced Cognitive Framework for End-to-End Autonomous Driving', 'authors': 'Yongkang Li, Kaixin Xiong, Xiangyu Guo, Fang Li, Sixu Yan, Gangwei Xu, Lijun Zhou, Long Chen, Haiyang Sun, Bing Wang, Guang Chen, Hangjun Ye, Wenyu Liu, Xinggang Wang', 'link': 'https://arxiv.org/abs/2506.08052', 'abstract': 'Although end-to-end autonomous driving has made remarkable progress, its performance degrades significantly in rare and long-tail scenarios. Recent approaches attempt to address this challenge by leveraging the rich world knowledge of Vision-Language Models (VLMs), but these methods suffer from several limitations: (1) a significant domain gap between the pre-training data of VLMs and real-world driving data, (2) a dimensionality mismatch between the discrete language space and the continuous action space, and (3) imitation learning tends to capture the average behavior present in the dataset, which may be suboptimal even dangerous. In this paper, we propose ReCogDrive, an autonomous driving system that integrates VLMs with diffusion planner, which adopts a three-stage paradigm for training. In the first stage, we use a large-scale driving question-answering datasets to train the VLMs, mitigating the domain discrepancy between generic content and real-world driving scenarios. In the second stage, we employ a diffusion-based planner to perform imitation learning, mapping representations from the latent language space to continuous driving actions. Finally, we fine-tune the diffusion planner using reinforcement learning with NAVSIM non-reactive simulator, enabling the model to generate safer, more human-like driving trajectories. We evaluate our approach on the planning-oriented NAVSIM benchmark, achieving a PDMS of 89.6 and setting a new state-of-the-art that surpasses the previous vision-only SOTA by 5.6 PDMS.', 'abstract_zh': '尽管端到端自动驾驶取得了显著进展，但在罕见和长尾场景下的性能显著下降。近期方法尝试通过利用视觉语言模型（VLMs）丰富的世界知识来应对这一挑战，但这些方法存在几项局限性：（1）VLMs的预训练数据与真实世界驾驶数据之间存在显著Domain gap；（2）离散的语言空间与连续的动作空间之间存在维度不匹配；（3）模仿学习倾向于捕获数据集中存在的平均行为，这可能是次优的甚至是危险的。本文提出ReCogDrive，这是一种将VLMs与扩散规划器相结合的自动驾驶系统，采用三阶段训练 paradigm。在第一阶段，我们使用大规模的驾驶问答数据集训练VLMs，以缓解通用内容与真实世界驾驶场景之间的Domain discrepancy。在第二阶段，我们使用基于扩散的规划器进行模仿学习，将潜语言空间的表示映射到连续的驾驶动作。最后，我们使用基于强化学习的NAVSIM非反应式模拟器fine-tune扩散规划器，使模型能够生成更安全、更接近人类的驾驶轨迹。我们在以规划为导向的NAVSIM基准上评估了我们的方法，实现了89.6的PDMS，并且性能超过了之前的纯视觉SOTA，领先5.6 PDMS。', 'title_zh': 'ReCogDrive：端到端自动驾驶的强化认知框架'}
{'arxiv_id': 'arXiv:2506.08532', 'title': 'Safe and Economical UAV Trajectory Planning in Low-Altitude Airspace: A Hybrid DRL-LLM Approach with Compliance Awareness', 'authors': 'Yanwei Gong, Xiaolin Chang', 'link': 'https://arxiv.org/abs/2506.08532', 'abstract': 'The rapid growth of the low-altitude economy has driven the widespread adoption of unmanned aerial vehicles (UAVs). This growing deployment presents new challenges for UAV trajectory planning in complex urban environments. However, existing studies often overlook key factors, such as urban airspace constraints and economic efficiency, which are essential in low-altitude economy contexts. Deep reinforcement learning (DRL) is regarded as a promising solution to these issues, while its practical adoption remains limited by low learning efficiency. To overcome this limitation, we propose a novel UAV trajectory planning framework that combines DRL with large language model (LLM) reasoning to enable safe, compliant, and economically viable path planning. Experimental results demonstrate that our method significantly outperforms existing baselines across multiple metrics, including data collection rate, collision avoidance, successful landing, regulatory compliance, and energy efficiency. These results validate the effectiveness of our approach in addressing UAV trajectory planning key challenges under constraints of the low-altitude economy networking.', 'abstract_zh': '低空经济快速发展的广泛应用推动了无人机（UAV）的普及。复杂城市环境下的无人机航迹规划面临新挑战。然而，现有研究往往忽视了低空经济背景下至关重要的因素，如城市 airspace约束和经济效率。深度强化学习（DRL）被视为解决这些问题的有希望的方法，但由于学习效率低，其实用应用受到限制。为克服这一限制，我们提出了一种结合DRL和大型语言模型（LLM）推理的新型无人机航迹规划框架，以实现安全、合规和经济可行的路径规划。实验结果表明，我们的方法在数据收集率、碰撞避险、成功降落、法规遵从性和能效等多个指标上显著优于现有baseline方法。这些结果验证了该方法在低空经济网络约束条件下解决无人机航迹规划关键挑战的有效性。', 'title_zh': '低空 airspace中安全经济的无人机航迹规划：一种具有合规意识的混合DRL-LLM方法'}
{'arxiv_id': 'arXiv:2506.08098', 'title': 'Cognitive Weave: Synthesizing Abstracted Knowledge with a Spatio-Temporal Resonance Graph', 'authors': 'Akash Vishwakarma, Hojin Lee, Mohith Suresh, Priyam Shankar Sharma, Rahul Vishwakarma, Sparsh Gupta, Yuvraj Anupam Chauhan', 'link': 'https://arxiv.org/abs/2506.08098', 'abstract': "The emergence of capable large language model (LLM) based agents necessitates memory architectures that transcend mere data storage, enabling continuous learning, nuanced reasoning, and dynamic adaptation. Current memory systems often grapple with fundamental limitations in structural flexibility, temporal awareness, and the ability to synthesize higher-level insights from raw interaction data. This paper introduces Cognitive Weave, a novel memory framework centered around a multi-layered spatio-temporal resonance graph (STRG). This graph manages information as semantically rich insight particles (IPs), which are dynamically enriched with resonance keys, signifiers, and situational imprints via a dedicated semantic oracle interface (SOI). These IPs are interconnected through typed relational strands, forming an evolving knowledge tapestry. A key component of Cognitive Weave is the cognitive refinement process, an autonomous mechanism that includes the synthesis of insight aggregates (IAs) condensed, higher-level knowledge structures derived from identified clusters of related IPs. We present comprehensive experimental results demonstrating Cognitive Weave's marked enhancement over existing approaches in long-horizon planning tasks, evolving question-answering scenarios, and multi-session dialogue coherence. The system achieves a notable 34% average improvement in task completion rates and a 42% reduction in mean query latency when compared to state-of-the-art baselines. Furthermore, this paper explores the ethical considerations inherent in such advanced memory systems, discusses the implications for long-term memory in LLMs, and outlines promising future research trajectories.", 'abstract_zh': '具备强大能力的大语言模型（LLM）代理的出现 necessitates 内存架构超越 mere 数据存储，以实现持续学习、细致推理和动态适应。当前的内存系统往往在结构灵活性、时间意识和从原始交互数据中综合高级洞察方面面临根本性的限制。本文介绍了一种新型的记忆框架认知编织（Cognitive Weave），该框架以多层时空共振图（STRG）为核心。该图以语义丰富的洞察颗粒（IPs）来管理信息，并通过专用语义Oracle接口（SOI）动态增强这些IPs的共振键、标识符和情境印记。这些IPs通过类型化的关系纽带相互连接，形成一个不断演变的知识织锦。认知编织的关键组成部分是认知精炼过程，这是一种自主机制，包括从识别相关的IPs群集汇总形成的洞察聚合（IAs）的综合，这些IAs是凝练的、高级的知识结构。本文展示了认知编织在长周期规划任务、不断演化的问答场景和多会话对话连贯性方面显著优于现有方法的实验结果。与最先进的基线相比，该系统在任务完成率上平均提高了34%，查询延迟减少了42%。此外，本文探讨了此类高级记忆系统中固有的伦理问题，讨论了其对LLM长期记忆的影响，并概述了有希望的未来研究方向。', 'title_zh': '认知织就：基于时空共振图综合抽象知识'}
{'arxiv_id': 'arXiv:2506.08965', 'title': 'GFRIEND: Generative Few-shot Reward Inference through EfficieNt DPO', 'authors': 'Yiyang Zhao, Huiyu Bai, Xuejiao Zhao', 'link': 'https://arxiv.org/abs/2506.08965', 'abstract': 'The ability to train high-performing reward models with few-shot data is critical for enhancing the efficiency and scalability of Reinforcement Learning from Human Feedback (RLHF). We propose a data augmentation and expansion framework that enables generative reward models trained on small datasets to achieve comparable performance to those trained on large-scale datasets. Traditional methods to train a generative reward model, such as Direct Preference Optimization (DPO), are constrained by inefficiencies in sample pairing and limited data diversity. This work introduces preference refinement, which employs Chain-of-Thought (CoT) sampling to uncover diverse and high-quality preference relationships. It also incorporates a perplexity-based scoring mechanism to assign nuanced preference levels and utilizes Multi-level Direct Preference Optimization (M-DPO) to enable the model to capture finer-grained preference differences between samples. Experimental results demonstrate that the proposed method significantly enhances data efficiency and model performance, enabling reward models trained in a few-shot setting to achieve results on par with those trained on large-scale datasets. This study underscores the potential of data-efficient strategies in advancing reward model optimization, offering a robust solution for low-resource RLHF applications.', 'abstract_zh': '少量样本数据下训练高性能奖励模型的能力对于增强人类反馈强化学习（RLHF）的效率和可扩展性至关重要。我们提出了一种数据增强和扩展框架，该框架使在小数据集上训练的生成奖励模型能够达到在大规模数据集上训练的模型的相似性能。传统的生成奖励模型的训练方法，如直接偏好优化（DPO），受限于样本配对的低效率和数据多样性有限。本研究引入了偏好细化方法，该方法采用Chain-of-Thought（CoT）采样来揭示多样且高质量的偏好关系，并引入了一个基于困惑度的评分机制来分配细腻的偏好等级，同时利用多层次直接偏好优化（M-DPO）使模型能够捕获样本之间的细微偏好差异。实验结果表明，所提出的方法显著提高了数据效率和模型性能，使得在少量样本设置下训练的奖励模型能达到在大规模数据集上训练的模型的同等效果。本研究强调了高效数据策略在奖励模型优化中的潜力，提供了低资源RLHF应用的一个稳健解决方案。', 'title_zh': 'GFRIEND: 生成少量样本奖励推断通过高效DPO'}
{'arxiv_id': 'arXiv:2506.08961', 'title': 'Towards Robust Deep Reinforcement Learning against Environmental State Perturbation', 'authors': 'Chenxu Wang, Huaping Liu', 'link': 'https://arxiv.org/abs/2506.08961', 'abstract': 'Adversarial attacks and robustness in Deep Reinforcement Learning (DRL) have been widely studied in various threat models; however, few consider environmental state perturbations, which are natural in embodied scenarios. To improve the robustness of DRL agents, we formulate the problem of environmental state perturbation, introducing a preliminary non-targeted attack method as a calibration adversary, and then propose a defense framework, named Boosted Adversarial Training (BAT), which first tunes the agents via supervised learning to avoid catastrophic failure and subsequently adversarially trains the agent with reinforcement learning. Extensive experimental results substantiate the vulnerability of mainstream agents under environmental state perturbations and the effectiveness of our proposed attack. The defense results demonstrate that while existing robust reinforcement learning algorithms may not be suitable, our BAT framework can significantly enhance the robustness of agents against environmental state perturbations across various situations.', 'abstract_zh': '深度强化学习中的对抗攻击与鲁棒性在各种威胁模型中的研究很少考虑环境状态扰动，而在实际 bodied 场景中这是自然存在的。为了提高 DRL 代理的鲁棒性，我们制定了环境状态扰动的问题，引入了一种初步的非目标攻击方法作为校准对手，并提出了一种防御框架，名为增强对抗训练（BAT），该框架首先通过监督学习调校代理以避免灾难性失败，随后使用强化学习对代理进行对抗训练。广泛的实验结果证实了主流代理在环境状态扰动下的脆弱性以及我们提出的攻击的有效性。防御结果表明，虽然现有的鲁棒强化学习算法可能并不适用，但我们的 BAT 框架可以在各种情况下显著增强代理对环境状态扰动的鲁棒性。', 'title_zh': '面向环境状态扰动的稳健深度强化学习'}
{'arxiv_id': 'arXiv:2506.08507', 'title': 'MasHost Builds It All: Autonomous Multi-Agent System Directed by Reinforcement Learning', 'authors': 'Kuo Yang, Xingjie Yang, Linhui Yu, Qing Xu, Yan Fang, Xu Wang, Zhengyang Zhou, Yang Wang', 'link': 'https://arxiv.org/abs/2506.08507', 'abstract': 'Large Language Model (LLM)-driven Multi-agent systems (Mas) have recently emerged as a powerful paradigm for tackling complex real-world tasks. However, existing Mas construction methods typically rely on manually crafted interaction mechanisms or heuristic rules, introducing human biases and constraining the autonomous ability. Even with recent advances in adaptive Mas construction, existing systems largely remain within the paradigm of semi-autonomous patterns. In this work, we propose MasHost, a Reinforcement Learning (RL)-based framework for autonomous and query-adaptive Mas design. By formulating Mas construction as a graph search problem, our proposed MasHost jointly samples agent roles and their interactions through a unified probabilistic sampling mechanism. Beyond the accuracy and efficiency objectives pursued in prior works, we introduce component rationality as an additional and novel design principle in Mas. To achieve this multi-objective optimization, we propose Hierarchical Relative Policy Optimization (HRPO), a novel RL strategy that collaboratively integrates group-relative advantages and action-wise rewards. To our knowledge, our proposed MasHost is the first RL-driven framework for autonomous Mas graph construction. Extensive experiments on six benchmarks demonstrate that MasHost consistently outperforms most competitive baselines, validating its effectiveness, efficiency, and structure rationality.', 'abstract_zh': '基于大型语言模型（LLM）的多智能体系统（MAS）驱动的自主和查询自适应设计框架', 'title_zh': 'MasHost 自建一切：基于强化学习的自主多Agent系统'}
{'arxiv_id': 'arXiv:2506.08441', 'title': 'Time-Aware World Model for Adaptive Prediction and Control', 'authors': 'Anh N. Nhu, Sanghyun Son, Ming Lin', 'link': 'https://arxiv.org/abs/2506.08441', 'abstract': "In this work, we introduce the Time-Aware World Model (TAWM), a model-based approach that explicitly incorporates temporal dynamics. By conditioning on the time-step size, {\\Delta}t, and training over a diverse range of {\\Delta}t values -- rather than sampling at a fixed time-step -- TAWM learns both high- and low-frequency task dynamics across diverse control problems. Grounded in the information-theoretic insight that the optimal sampling rate depends on a system's underlying dynamics, this time-aware formulation improves both performance and data efficiency. Empirical evaluations show that TAWM consistently outperforms conventional models across varying observation rates in a variety of control tasks, using the same number of training samples and iterations. Our code can be found online at: this http URL.", 'abstract_zh': '基于时间的 WORLD 模型 (TAWM):一种explicitly Incorporate 时间动态的模型驱动方法', 'title_zh': '时间感知世界模型及其在自适应预测与控制中的应用'}
{'arxiv_id': 'arXiv:2506.08185', 'title': 'Surgeon Style Fingerprinting and Privacy Risk Quantification via Discrete Diffusion Models in a Vision-Language-Action Framework', 'authors': 'Huixin Zhan, Jason H. Moore', 'link': 'https://arxiv.org/abs/2506.08185', 'abstract': 'Surgeons exhibit distinct operating styles due to differences in training, experience, and motor behavior - yet current AI systems often ignore this personalization signal. We propose a novel approach to model fine-grained, surgeon-specific fingerprinting in robotic surgery using a discrete diffusion framework integrated with a vision-language-action (VLA) pipeline. Our method formulates gesture prediction as a structured sequence denoising task, conditioned on multimodal inputs including endoscopic video, surgical intent language, and a privacy-aware embedding of surgeon identity and skill. Personalized surgeon fingerprinting is encoded through natural language prompts using third-party language models, allowing the model to retain individual behavioral style without exposing explicit identity. We evaluate our method on the JIGSAWS dataset and demonstrate that it accurately reconstructs gesture sequences while learning meaningful motion fingerprints unique to each surgeon. To quantify the privacy implications of personalization, we perform membership inference attacks and find that more expressive embeddings improve task performance but simultaneously increase susceptibility to identity leakage. These findings demonstrate that while personalized embeddings improve performance, they also increase vulnerability to identity leakage, revealing the importance of balancing personalization with privacy risk in surgical modeling. Code is available at: this https URL.', 'abstract_zh': '外科医生由于训练、经验和运动行为的不同表现出独特的手术风格——然而当前的AI系统往往忽略了这一个性化信号。我们提出了一种新的方法，利用离散扩散框架结合视语言行动（VLA）管线，在机器人手术中建模精细、医生特定的指纹。该方法将手势预测形式化为结构化序列去噪任务，基于内窥镜视频、手术意图语言和隐私意识的外科医生身份和技能嵌入的多模态输入。通过第三方语言模型使用自然语言提示进行个性化外科医生指纹编码，使模型能够保留个体行为风格而不泄露明确的身份信息。我们在JIGSAWS数据集上评估了该方法，证明它可以准确重建手势序列并学习每个外科医生独有的有意义的运动指纹。为了量化个性化的隐私影响，我们进行了成员归属推断攻击，发现更具表现力的嵌入提高了任务性能，但同时也增加了身份泄露的风险。这些发现表明，虽然个性化嵌入提高了性能，但也增加了身份泄露的风险，揭示了在手术建模中平衡个性化与隐私风险的重要性。代码可在该链接获取：this https URL。', 'title_zh': '基于视觉-语言-动作框架的外科医生风格指纹识别与隐私风险量化'}
