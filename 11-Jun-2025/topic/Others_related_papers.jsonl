{'arxiv_id': 'arXiv:2506.08756', 'title': 'Bayesian Inverse Physics for Neuro-Symbolic Robot Learning', 'authors': 'Octavio Arriaga, Rebecca Adam, Melvin Laux, Lisa Gutzeit, Marco Ragni, Jan Peters, Frank Kirchner', 'link': 'https://arxiv.org/abs/2506.08756', 'abstract': 'Real-world robotic applications, from autonomous exploration to assistive technologies, require adaptive, interpretable, and data-efficient learning paradigms. While deep learning architectures and foundation models have driven significant advances in diverse robotic applications, they remain limited in their ability to operate efficiently and reliably in unknown and dynamic environments. In this position paper, we critically assess these limitations and introduce a conceptual framework for combining data-driven learning with deliberate, structured reasoning. Specifically, we propose leveraging differentiable physics for efficient world modeling, Bayesian inference for uncertainty-aware decision-making, and meta-learning for rapid adaptation to new tasks. By embedding physical symbolic reasoning within neural models, robots could generalize beyond their training data, reason about novel situations, and continuously expand their knowledge. We argue that such hybrid neuro-symbolic architectures are essential for the next generation of autonomous systems, and to this end, we provide a research roadmap to guide and accelerate their development.', 'abstract_zh': '现实世界中的机器人应用，从自主探索到辅助技术，需要适应性强、可解释性强和数据高效的学习范式。虽然深度学习架构和基础模型在多种机器人应用中推动了显著的进步，但在未知和动态环境中高效可靠地运行方面仍然有限。在本文中，我们批判性地评估了这些局限性，并提出了一种结合数据驱动学习与故意的结构化推理的概念框架。具体而言，我们建议利用可微物理学进行高效的世界建模，使用贝叶斯推断进行不确定性意识的决策，以及使用元学习进行快速的新任务适应。通过将物理符号推理嵌入神经模型中，机器人可以泛化到训练数据之外，推理新情况，并持续扩展其知识。我们认为，这种混合神经符号架构是下一代自主系统的关键，为此，我们提供了一条研究 roadmap，以指导和加速其发展。', 'title_zh': '基于贝叶斯逆物理的神经符号机器人学习'}
{'arxiv_id': 'arXiv:2506.08344', 'title': 'Re4MPC: Reactive Nonlinear MPC for Multi-model Motion Planning via Deep Reinforcement Learning', 'authors': 'Neşet Ünver Akmandor, Sarvesh Prajapati, Mark Zolotas, Taşkın Padır', 'link': 'https://arxiv.org/abs/2506.08344', 'abstract': 'Traditional motion planning methods for robots with many degrees-of-freedom, such as mobile manipulators, are often computationally prohibitive for real-world settings. In this paper, we propose a novel multi-model motion planning pipeline, termed Re4MPC, which computes trajectories using Nonlinear Model Predictive Control (NMPC). Re4MPC generates trajectories in a computationally efficient manner by reactively selecting the model, cost, and constraints of the NMPC problem depending on the complexity of the task and robot state. The policy for this reactive decision-making is learned via a Deep Reinforcement Learning (DRL) framework. We introduce a mathematical formulation to integrate NMPC into this DRL framework. To validate our methodology and design choices, we evaluate DRL training and test outcomes in a physics-based simulation involving a mobile manipulator. Experimental results demonstrate that Re4MPC is more computationally efficient and achieves higher success rates in reaching end-effector goals than the NMPC baseline, which computes whole-body trajectories without our learning mechanism.', 'abstract_zh': '一种基于深度强化学习的高效多模型运动规划方法', 'title_zh': 'Re4MPC: 基于深度强化学习的多模型反应非线性模型预测控制运动规划'}
{'arxiv_id': 'arXiv:2506.08061', 'title': 'Adaptive Per-Tree Canopy Volume Estimation Using Mobile LiDAR in Structured and Unstructured Orchards', 'authors': 'Ali Abedi, Fernando Cladera, Mohsen Farajijalal, Reza Ehsani', 'link': 'https://arxiv.org/abs/2506.08061', 'abstract': 'We present a real-time system for per-tree canopy volume estimation using mobile LiDAR data collected during routine robotic navigation. Unlike prior approaches that rely on static scans or assume uniform orchard structures, our method adapts to varying field geometries via an integrated pipeline of LiDAR-inertial odometry, adaptive segmentation, and geometric reconstruction. We evaluate the system across two commercial orchards, one pistachio orchard with regular spacing and one almond orchard with dense, overlapping crowns. A hybrid clustering strategy combining DBSCAN and spectral clustering enables robust per-tree segmentation, achieving 93% success in pistachio and 80% in almond, with strong agreement to drone derived canopy volume estimates. This work advances scalable, non-intrusive tree monitoring for structurally diverse orchard environments.', 'abstract_zh': '基于移动LiDAR数据的实时单棵树冠体积估计算法：适应性分割与几何重建在商用果园中的应用', 'title_zh': '基于移动LiDAR的结构化与非结构化果园树木冠体积自适应估测'}
{'arxiv_id': 'arXiv:2506.08039', 'title': 'AI Magnetic Levitation (Maglev) Conveyor for Automated Assembly Production', 'authors': 'Ray Wai Man Kong', 'link': 'https://arxiv.org/abs/2506.08039', 'abstract': 'Efficiency, speed, and precision are essential in modern manufacturing. AI Maglev Conveyor system, combining magnetic levitation (maglev) technology with artificial intelligence (AI), revolutionizes automated production processes. This system reduces maintenance costs and downtime by eliminating friction, enhancing operational efficiency. It transports goods swiftly with minimal energy consumption, optimizing resource use and supporting sustainability. AI integration enables real-time monitoring and adaptive control, allowing businesses to respond to production demand fluctuations and streamline supply chain operations.\nThe AI Maglev Conveyor offers smooth, silent operation, accommodating diverse product types and sizes for flexible manufacturing without extensive reconfiguration. AI algorithms optimize routing, reduce cycle times, and improve throughput, creating an agile production line adaptable to market changes.\nThis applied research paper introduces the Maglev Conveyor system, featuring an electromagnetic controller and multiple movers to enhance automation. It offers cost savings as an alternative to setups using six-axis robots or linear motors, with precise adjustments for robotic arm loading. Operating at high speeds minimizes treatment time for delicate components while maintaining precision. Its adaptable design accommodates various materials, facilitating integration of processing stations alongside electronic product assembly. Positioned between linear-axis and robotic systems in cost, the Maglev Conveyor is ideal for flat parts requiring minimal travel, transforming production efficiency across industries. It explores its technical advantages, flexibility, cost reductions, and overall benefits.', 'abstract_zh': 'AI磁浮传送系统：提高效率、速度和精度的自动化生产革命', 'title_zh': '基于AI磁悬浮（Maglev）输送机的自动化装配生产系统'}
{'arxiv_id': 'arXiv:2506.08719', 'title': 'Efficient Learning of Vehicle Controller Parameters via Multi-Fidelity Bayesian Optimization: From Simulation to Experiment', 'authors': 'Yongpeng Zhao, Maik Pfefferkorn, Maximilian Templer, Rolf Findeisen', 'link': 'https://arxiv.org/abs/2506.08719', 'abstract': 'Parameter tuning for vehicle controllers remains a costly and time-intensive challenge in automotive development. Traditional approaches rely on extensive real-world testing, making the process inefficient. We propose a multi-fidelity Bayesian optimization approach that efficiently learns optimal controller parameters by leveraging both low-fidelity simulation data and a very limited number of real-world experiments. Our approach significantly reduces the need for manual tuning and expensive field testing while maintaining the standard two-stage development workflow used in industry. The core contribution is the integration of an auto-regressive multi-fidelity Gaussian process model into Bayesian optimization, enabling knowledge transfer between different fidelity levels without requiring additional low-fidelity evaluations during real-world testing. We validate our approach through both simulation studies and realworld experiments. The results demonstrate that our method achieves high-quality controller performance with only very few real-world experiments, highlighting its potential as a practical and scalable solution for intelligent vehicle control tuning in industrial applications.', 'abstract_zh': '车辆控制器参数调优仍然是汽车开发中的一个 costly 和时间密集型挑战。传统方法依赖于广泛的实地测试，使过程效率低下。我们提出了一种多保真度贝叶斯优化方法，通过利用低保真度仿真数据和非常有限数量的真实世界试验来高效地学习最优控制器参数。该方法显著减少了手动调优和昂贵的实地测试需求，同时保持了工业中惯用的标准两阶段开发流程。核心贡献是将自回归多保真度高斯过程模型集成到贝叶斯优化中，能够在真实世界测试过程中无需额外的低保真度评估，实现不同保真度级别之间的知识迁移。我们通过仿真研究和实际试验验证了该方法。结果表明，该方法仅通过极少的真实世界试验就能实现高质量的控制器性能，突显了其在智能车辆控制调优方面作为实用和可扩展解决方案的潜力。', 'title_zh': '通过多保真度贝叶斯优化高效学习车辆控制器参数：从仿真到实验'}
{'arxiv_id': 'arXiv:2506.08463', 'title': 'How to Provably Improve Return Conditioned Supervised Learning?', 'authors': 'Zhishuai Liu, Yu Yang, Ruhan Wang, Pan Xu, Dongruo Zhou', 'link': 'https://arxiv.org/abs/2506.08463', 'abstract': 'In sequential decision-making problems, Return-Conditioned Supervised Learning (RCSL) has gained increasing recognition for its simplicity and stability in modern decision-making tasks. Unlike traditional offline reinforcement learning (RL) algorithms, RCSL frames policy learning as a supervised learning problem by taking both the state and return as input. This approach eliminates the instability often associated with temporal difference (TD) learning in offline RL. However, RCSL has been criticized for lacking the stitching property, meaning its performance is inherently limited by the quality of the policy used to generate the offline dataset. To address this limitation, we propose a principled and simple framework called Reinforced RCSL. The key innovation of our framework is the introduction of a concept we call the in-distribution optimal return-to-go. This mechanism leverages our policy to identify the best achievable in-dataset future return based on the current state, avoiding the need for complex return augmentation techniques. Our theoretical analysis demonstrates that Reinforced RCSL can consistently outperform the standard RCSL approach. Empirical results further validate our claims, showing significant performance improvements across a range of benchmarks.', 'abstract_zh': '基于返回条件的监督学习在序贯决策问题中的强化Reinforced RCSL框架', 'title_zh': '如何证明性提高基于回报条件的监督学习？'}
{'arxiv_id': 'arXiv:2506.08048', 'title': 'Towards Reliable AR-Guided Surgical Navigation: Interactive Deformation Modeling with Data-Driven Biomechanics and Prompts', 'authors': 'Zheng Han, Jun Zhou, Jialun Pei, Jing Qin, Yingfang Fan, Qi Dou', 'link': 'https://arxiv.org/abs/2506.08048', 'abstract': "In augmented reality (AR)-guided surgical navigation, preoperative organ models are superimposed onto the patient's intraoperative anatomy to visualize critical structures such as vessels and tumors. Accurate deformation modeling is essential to maintain the reliability of AR overlays by ensuring alignment between preoperative models and the dynamically changing anatomy. Although the finite element method (FEM) offers physically plausible modeling, its high computational cost limits intraoperative applicability. Moreover, existing algorithms often fail to handle large anatomical changes, such as those induced by pneumoperitoneum or ligament dissection, leading to inaccurate anatomical correspondences and compromised AR guidance. To address these challenges, we propose a data-driven biomechanics algorithm that preserves FEM-level accuracy while improving computational efficiency. In addition, we introduce a novel human-in-the-loop mechanism into the deformation modeling process. This enables surgeons to interactively provide prompts to correct anatomical misalignments, thereby incorporating clinical expertise and allowing the model to adapt dynamically to complex surgical scenarios. Experiments on a publicly available dataset demonstrate that our algorithm achieves a mean target registration error of 3.42 mm. Incorporating surgeon prompts through the interactive framework further reduces the error to 2.78 mm, surpassing state-of-the-art methods in volumetric accuracy. These results highlight the ability of our framework to deliver efficient and accurate deformation modeling while enhancing surgeon-algorithm collaboration, paving the way for safer and more reliable computer-assisted surgeries.", 'abstract_zh': '基于增强现实（AR）引导的手术导航中的预手术器官模型在患者术中解剖结构上叠加，以可视化血管和肿瘤等关键结构。准确的形变建模对于通过确保预手术模型与动态变化的解剖结构之间的对齐来维持AR叠加的可靠性至关重要。尽管有限元方法（FEM）提供物理上合理的建模，但其高昂的计算成本限制了其在术中的应用。此外，现有算法往往无法处理大范围的解剖变化，如腹腔镜引起的气腹变化或韧带剥离引起的解剖变化，导致解剖对应不准确并且削弱了AR导航。为解决这些挑战，我们提出了一种数据驱动的生物力学算法，该算法在保持FEM级别的准确性的基础上提高了计算效率。此外，我们引入了一种新型的人在环机制到形变建模过程中。这使得外科医生能够互动地提供提示以纠正解剖对齐错误，从而结合临床专业知识并使模型能够动态适应复杂的手术场景。在公共数据集上的实验显示，我们的算法实现了平均目标注册误差为3.42毫米。通过交互框架整合外科医生的提示进一步将误差减少到2.78毫米，超越了最新方法在体素精度方面的表现。这些结果突显了我们框架在实现高效准确的形变建模的同时增强外科医生与算法协作的能力，为更加安全可靠的计算机辅助手术铺平了道路。', 'title_zh': '基于数据驱动生物力学和提示的交互变形建模：迈向可靠的AR引导外科导航'}
{'arxiv_id': 'arXiv:2506.09050', 'title': 'ALE-Bench: A Benchmark for Long-Horizon Objective-Driven Algorithm Engineering', 'authors': 'Yuki Imajuku, Kohki Horie, Yoichi Iwata, Kensho Aoki, Naohiro Takahashi, Takuya Akiba', 'link': 'https://arxiv.org/abs/2506.09050', 'abstract': 'How well do AI systems perform in algorithm engineering for hard optimization problems in domains such as package-delivery routing, crew scheduling, factory production planning, and power-grid balancing? We introduce ALE-Bench, a new benchmark for evaluating AI systems on score-based algorithmic programming contests. Drawing on real tasks from the AtCoder Heuristic Contests, ALE-Bench presents optimization problems that are computationally hard and admit no known exact solution. Unlike short-duration, pass/fail coding benchmarks, ALE-Bench encourages iterative solution refinement over long time horizons. Our software framework supports interactive agent architectures that leverage test-run feedback and visualizations. Our evaluation of frontier LLMs revealed that while they demonstrate high performance on specific problems, a notable gap remains compared to humans in terms of consistency across problems and long-horizon problem-solving capabilities. This highlights the need for this benchmark to foster future AI advancements.', 'abstract_zh': 'AI系统在硬优化问题领域（如包裹配送路由、机组调度、工厂生产规划和电网平衡）的算法工程中表现如何？我们引入ALE-Bench，一个新的基准，用于评估AI系统在基于评分的算法编程竞赛中的性能。ALE-Bench采用来自AtCoder启发式竞赛的真實任务，呈现计算复杂且目前缺乏确切解决方案的优化问题。与短暂的通过/失败编码基准不同，ALE-Bench鼓励在长时间范围内进行解决方案的迭代优化。我们的软件框架支持利用测试运行反馈和可视化技术的交互式代理架构。我们对前沿的大语言模型的评估显示，尽管它们在特定问题上表现出色，但在问题一致性及长时间问题解决能力方面仍与人类存在明显差距。这突显了建立此基准以促进未来AI进步的需求。', 'title_zh': 'ALE-Bench: 一种长时域目标驱动的算法工程基准测试'}
{'arxiv_id': 'arXiv:2506.08970', 'title': 'A Survey of Link Prediction in N-ary Knowledge Graphs', 'authors': 'Jiyao Wei, Saiping Guan, Da Li, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng', 'link': 'https://arxiv.org/abs/2506.08970', 'abstract': 'N-ary Knowledge Graphs (NKGs) are a specialized type of knowledge graph designed to efficiently represent complex real-world facts. Unlike traditional knowledge graphs, where a fact typically involves two entities, NKGs can capture n-ary facts containing more than two entities. Link prediction in NKGs aims to predict missing elements within these n-ary facts, which is essential for completing NKGs and improving the performance of downstream applications. This task has recently gained significant attention. In this paper, we present the first comprehensive survey of link prediction in NKGs, providing an overview of the field, systematically categorizing existing methods, and analyzing their performance and application scenarios. We also outline promising directions for future research.', 'abstract_zh': 'N-元知识图谱中的链接预测研究综述', 'title_zh': 'N-元知识图谱中的链接预测综述'}
{'arxiv_id': 'arXiv:2506.08957', 'title': 'IntTrajSim: Trajectory Prediction for Simulating Multi-Vehicle driving at Signalized Intersections', 'authors': 'Yash Ranjan, Rahul Sengupta, Anand Rangarajan, Sanjay Ranka', 'link': 'https://arxiv.org/abs/2506.08957', 'abstract': 'Traffic simulators are widely used to study the operational efficiency of road infrastructure, but their rule-based approach limits their ability to mimic real-world driving behavior. Traffic intersections are critical components of the road infrastructure, both in terms of safety risk (nearly 28% of fatal crashes and 58% of nonfatal crashes happen at intersections) as well as the operational efficiency of a road corridor. This raises an important question: can we create a data-driven simulator that can mimic the macro- and micro-statistics of the driving behavior at a traffic intersection? Deep Generative Modeling-based trajectory prediction models provide a good starting point to model the complex dynamics of vehicles at an intersection. But they are not tested in a "live" micro-simulation scenario and are not evaluated on traffic engineering-related metrics. In this study, we propose traffic engineering-related metrics to evaluate generative trajectory prediction models and provide a simulation-in-the-loop pipeline to do so. We also provide a multi-headed self-attention-based trajectory prediction model that incorporates the signal information, which outperforms our previous models on the evaluation metrics.', 'abstract_zh': '基于深度生成建模的交通交叉口数据驱动轨迹预测模型评价及模拟框架', 'title_zh': 'IntTrajSim：基于信号交叉口多车辆驾驶轨迹预测的仿真'}
{'arxiv_id': 'arXiv:2506.08898', 'title': 'Preference-Driven Multi-Objective Combinatorial Optimization with Conditional Computation', 'authors': 'Mingfeng Fan, Jianan Zhou, Yifeng Zhang, Yaoxin Wu, Jinbiao Chen, Guillaume Adrien Sartoretti', 'link': 'https://arxiv.org/abs/2506.08898', 'abstract': 'Recent deep reinforcement learning methods have achieved remarkable success in solving multi-objective combinatorial optimization problems (MOCOPs) by decomposing them into multiple subproblems, each associated with a specific weight vector. However, these methods typically treat all subproblems equally and solve them using a single model, hindering the effective exploration of the solution space and thus leading to suboptimal performance. To overcome the limitation, we propose POCCO, a novel plug-and-play framework that enables adaptive selection of model structures for subproblems, which are subsequently optimized based on preference signals rather than explicit reward values. Specifically, we design a conditional computation block that routes subproblems to specialized neural architectures. Moreover, we propose a preference-driven optimization algorithm that learns pairwise preferences between winning and losing solutions. We evaluate the efficacy and versatility of POCCO by applying it to two state-of-the-art neural methods for MOCOPs. Experimental results across four classic MOCOP benchmarks demonstrate its significant superiority and strong generalization.', 'abstract_zh': '近期的深度强化学习方法通过将多目标组合优化问题分解为多个子问题，并为每个子问题分配特定的权重向量，取得了显著的成功。然而，这些方法通常平等对待所有子问题，并使用单个模型来解决它们，这阻碍了对解空间的有效探索，从而导致性能不佳。为克服这一局限，我们提出了一种名为POCCO的新型插件式框架，该框架能够为子问题自适应地选择模型结构，随后根据偏好信号而非显式奖励值对其进行优化。具体地，我们设计了一个条件计算模块，将子问题路由到专门的神经架构中。此外，我们提出了一种基于偏好的优化算法，该算法学习胜者和败者解对之间的成对偏好。通过将其应用于两种最先进的神经方法解决多目标组合优化问题，我们评估了POCCO的有效性和灵活性。在四个经典多目标组合优化问题基准上的实验结果表明，POCCO在显著性和通用性方面具有显著优势。', 'title_zh': '基于偏好驱动的条件计算多目标组合优化'}
{'arxiv_id': 'arXiv:2506.08747', 'title': 'A Sample Efficient Conditional Independence Test in the Presence of Discretization', 'authors': 'Boyang Sun, Yu Yao, Xinshuai Dong, Zongfang Liu, Tongliang Liu, Yumou Qiu, Kun Zhang', 'link': 'https://arxiv.org/abs/2506.08747', 'abstract': "In many real-world scenarios, interested variables are often represented as discretized values due to measurement limitations. Applying Conditional Independence (CI) tests directly to such discretized data, however, can lead to incorrect conclusions. To address this, recent advancements have sought to infer the correct CI relationship between the latent variables through binarizing observed data. However, this process inevitably results in a loss of information, which degrades the test's performance. Motivated by this, this paper introduces a sample-efficient CI test that does not rely on the binarization process. We find that the independence relationships of latent continuous variables can be established by addressing an over-identifying restriction problem with Generalized Method of Moments (GMM). Based on this insight, we derive an appropriate test statistic and establish its asymptotic distribution correctly reflecting CI by leveraging nodewise regression. Theoretical findings and Empirical results across various datasets demonstrate that the superiority and effectiveness of our proposed test. Our code implementation is provided in this https URL", 'abstract_zh': '在很多现实场景中，感兴趣的变量往往由于测量限制而表现为离散值。直接将条件独立性（CI）测试应用于此类离散数据可能会导致错误的结论。为了应对这一问题，最近的研究尝试通过二值化观测数据来推断潜在变量之间的正确CI关系。然而，这一过程不可避免地会丢失信息，从而降低测试性能。受此启发，本文介绍了一种样本高效的CI测试，无需依赖二值化过程。我们发现，通过使用广义矩方法（GMM）解决过识别限制问题，可以建立潜在连续变量的独立关系。基于这一洞察，我们推导出适当的检验统计量，并通过节点回归正确建立其渐近分布，准确反映CI。理论发现和多种数据集上的实证结果证明了我们所提出的测试的优越性和有效性。我们的代码实现可通过以下链接获取：https://your-link-url.com', 'title_zh': 'discretization环境下样本效率的条件独立性检验'}
{'arxiv_id': 'arXiv:2506.08627', 'title': 'FoldA: Computing Partial-Order Alignments Using Directed Net Unfoldings', 'authors': 'Douwe Geurtjens, Xixi Lu', 'link': 'https://arxiv.org/abs/2506.08627', 'abstract': 'Conformance checking is a fundamental task of process mining, which quantifies the extent to which the observed process executions match a normative process model. The state-of-the-art approaches compute alignments by exploring the state space formed by the synchronous product of the process model and the trace. This often leads to state space explosion, particularly when the model exhibits a high degree of choice and concurrency. Moreover, as alignments inherently impose a sequential structure, they fail to fully represent the concurrent behavior present in many real-world processes. To address these limitations, this paper proposes a new technique for computing partial-order alignments {on the fly using directed Petri net unfoldings, named FoldA. We evaluate our technique on 485 synthetic model-log pairs and compare it against Astar- and Dijkstra-alignments on 13 real-life model-log pairs and 6 benchmark pairs. The results show that our unfolding alignment, although it requires more computation time, generally reduces the number of queued states and provides a more accurate representation of concurrency.', 'abstract_zh': '过程合规性检查是过程挖掘中的一个基础任务，它量化观察到的过程执行与规范性过程模型之间的符合程度。现有的先进方法通过探索由过程模型和轨迹同步积形成的状态空间来计算对齐，这往往会导致状态空间爆炸，尤其是在模型表现出高度的选择性和并发性时。此外，由于对齐本质上施加了序列结构，它们无法充分代表许多现实世界过程中存在的并发行为。为了解决这些限制，本文提出了一种新的技术——使用有向Petri网扩展来计算偏序对齐（on the fly），名为FoldA。我们在485个合成模型-日志对上评估了该技术，并在13个现实世界模型-日志对和6个基准对上与Astar-和Dijkstra-对齐进行了比较。结果显示，尽管我们的扩展对齐需要更多计算时间，但通常减少了排队状态的数量，并更准确地代表了并发性。', 'title_zh': 'FoldA: 使用有向网展开计算部分序对齐'}
{'arxiv_id': 'arXiv:2506.08580', 'title': 'HGFormer: A Hierarchical Graph Transformer Framework for Two-Stage Colonel Blotto Games via Reinforcement Learning', 'authors': 'Yang Lv, Jinlong Lei, Peng Yi', 'link': 'https://arxiv.org/abs/2506.08580', 'abstract': 'Two-stage Colonel Blotto game represents a typical adversarial resource allocation problem, in which two opposing agents sequentially allocate resources in a network topology across two phases: an initial resource deployment followed by multiple rounds of dynamic reallocation adjustments. The sequential dependency between game stages and the complex constraints imposed by the graph topology make it difficult for traditional approaches to attain a globally optimal strategy. To address these challenges, we propose a hierarchical graph Transformer framework called HGformer. By incorporating an enhanced graph Transformer encoder with structural biases and a two-agent hierarchical decision model, our approach enables efficient policy generation in large-scale adversarial environments. Moreover, we design a layer-by-layer feedback reinforcement learning algorithm that feeds the long-term returns from lower-level decisions back into the optimization of the higher-level strategy, thus bridging the coordination gap between the two decision-making stages. Experimental results demonstrate that, compared to existing hierarchical decision-making or graph neural network methods, HGformer significantly improves resource allocation efficiency and adversarial payoff, achieving superior overall performance in complex dynamic game scenarios.', 'abstract_zh': '两级Colonel Blotto博弈代表了一种典型的 adversarial 资源分配问题，其中两个对立的代理在两个阶段的网络拓扑中依次分配资源：初始资源部署后，再进行多轮动态再分配调整。博弈阶段之间的顺序依赖性和由图拓扑施加的复杂约束使传统方法难以获得全局最优策略。为了应对这些挑战，我们提出了一种分层图Transformer框架HGformer。通过引入增强的图Transformer编码器和结构偏置，以及一种两代理分层决策模型，我们的方法能够在大规模对抗环境中高效生成策略。此外，我们设计了一种逐层反馈强化学习算法，将低层决策的长期回报反馈到高层策略的优化中，从而弥合两个决策阶段之间的协调差距。实验结果表明，与现有的分层决策方法或图神经网络方法相比，HGformer显著提高了资源分配效率和对抗收益，在复杂动态博弈场景中实现了卓越的整体性能。', 'title_zh': 'HGFormer: 一种基于强化学习的两阶段 Colonel Blotto 游戏分层图变换器框架'}
{'arxiv_id': 'arXiv:2506.08518', 'title': 'FEDTAIL: Federated Long-Tailed Domain Generalization with Sharpness-Guided Gradient Matching', 'authors': 'Sunny Gupta, Nikita Jangid, Shounak Das, Amit Sethi', 'link': 'https://arxiv.org/abs/2506.08518', 'abstract': 'Domain Generalization (DG) seeks to train models that perform reliably on unseen target domains without access to target data during training. While recent progress in smoothing the loss landscape has improved generalization, existing methods often falter under long-tailed class distributions and conflicting optimization objectives. We introduce FedTAIL, a federated domain generalization framework that explicitly addresses these challenges through sharpness-guided, gradient-aligned optimization. Our method incorporates a gradient coherence regularizer to mitigate conflicts between classification and adversarial objectives, leading to more stable convergence. To combat class imbalance, we perform class-wise sharpness minimization and propose a curvature-aware dynamic weighting scheme that adaptively emphasizes underrepresented tail classes. Furthermore, we enhance conditional distribution alignment by integrating sharpness-aware perturbations into entropy regularization, improving robustness under domain shift. FedTAIL unifies optimization harmonization, class-aware regularization, and conditional alignment into a scalable, federated-compatible framework. Extensive evaluations across standard domain generalization benchmarks demonstrate that FedTAIL achieves state-of-the-art performance, particularly in the presence of domain shifts and label imbalance, validating its effectiveness in both centralized and federated settings. Code: this https URL', 'abstract_zh': '联邦域自适应（FedTAIL）：通过尖括号导向的梯度对齐优化统一优化 harmonization、类感知正则化和条件对齐的联邦域泛化框架', 'title_zh': 'FEDTAIL：基于锋度引导梯度匹配的联邦长尾域泛化'}
{'arxiv_id': 'arXiv:2506.08424', 'title': 'SHIELD: Multi-task Multi-distribution Vehicle Routing Solver with Sparsity and Hierarchy', 'authors': 'Yong Liang Goh, Zhiguang Cao, Yining Ma, Jianan Zhou, Mohammad Haroon Dupty, Wee Sun Lee', 'link': 'https://arxiv.org/abs/2506.08424', 'abstract': 'Recent advances toward foundation models for routing problems have shown great potential of a unified deep model for various VRP variants. However, they overlook the complex real-world customer distributions. In this work, we advance the Multi-Task VRP (MTVRP) setting to the more realistic yet challenging Multi-Task Multi-Distribution VRP (MTMDVRP) setting, and introduce SHIELD, a novel model that leverages both sparsity and hierarchy principles. Building on a deeper decoder architecture, we first incorporate the Mixture-of-Depths (MoD) technique to enforce sparsity. This improves both efficiency and generalization by allowing the model to dynamically select nodes to use or skip each decoder layer, providing the needed capacity to adaptively allocate computation for learning the task/distribution specific and shared representations. We also develop a context-based clustering layer that exploits the presence of hierarchical structures in the problems to produce better local representations. These two designs inductively bias the network to identify key features that are common across tasks and distributions, leading to significantly improved generalization on unseen ones. Our empirical results demonstrate the superiority of our approach over existing methods on 9 real-world maps with 16 VRP variants each.', 'abstract_zh': '最近针对路由问题的基础模型研究展示了统一深度模型在各种VRP变体中的巨大潜力。然而，它们忽略了复杂的现实世界客户分布。在本工作中，我们将多任务VRP (MTVRP) 设置推进到更具现实意义且更具挑战性的多任务多分布VRP (MTMDVRP) 设置，并引入了SHIELD模型，该模型结合了稀疏性和分层原则。基于更深层的解码器架构，我们首先引入了Mixture-of-Depths (MoD) 技术以增强稀疏性。这通过使模型能够动态选择使用或跳过每个解码器层来提高效率和泛化能力，提供了根据不同任务/分布特定和共享表示自适应分配计算所需的能力。我们还开发了一种基于上下文的聚类层，利用问题中存在的分层结构来产生更好的局部表示。这两种设计使网络在识别跨任务和分布的常见特征方面具有引导性，从而在未见过的任务上显著提高了泛化能力。我们的实证结果证明了在9张现实世界地图上的16个不同的VRP变体上，我们的方法优于现有方法。', 'title_zh': 'SHIELD：具有稀疏性和层次性的多任务多分布车辆路由求解器'}
{'arxiv_id': 'arXiv:2506.08401', 'title': 'Single-Node Trigger Backdoor Attacks in Graph-Based Recommendation Systems', 'authors': 'Runze Li, Di Jin, Xiaobao Wang, Dongxiao He, Bingdao Feng, Zhen Wang', 'link': 'https://arxiv.org/abs/2506.08401', 'abstract': "Graph recommendation systems have been widely studied due to their ability to effectively capture the complex interactions between users and items. However, these systems also exhibit certain vulnerabilities when faced with attacks. The prevailing shilling attack methods typically manipulate recommendation results by injecting a large number of fake nodes and edges. However, such attack strategies face two primary challenges: low stealth and high destructiveness. To address these challenges, this paper proposes a novel graph backdoor attack method that aims to enhance the exposure of target items to the target user in a covert manner, without affecting other unrelated nodes. Specifically, we design a single-node trigger generator, which can effectively expose multiple target items to the target user by inserting only one fake user node. Additionally, we introduce constraint conditions between the target nodes and irrelevant nodes to mitigate the impact of fake nodes on the recommendation system's performance. Experimental results show that the exposure of the target items reaches no less than 50% in 99% of the target users, while the impact on the recommendation system's performance is controlled within approximately 5%.", 'abstract_zh': '图推荐系统的图后门攻击方法：隐蔽增加目标项的暴露同时控制推荐系统性能影响', 'title_zh': '基于图的推荐系统中的单节点触发后门攻击'}
{'arxiv_id': 'arXiv:2506.08399', 'title': 'SafeCoT: Improving VLM Safety with Minimal Reasoning', 'authors': 'Jiachen Ma, Zhanhui Zhou, Chao Yang, Chaochao Lu', 'link': 'https://arxiv.org/abs/2506.08399', 'abstract': 'Ensuring safe and appropriate responses from vision-language models (VLMs) remains a critical challenge, particularly in high-risk or ambiguous scenarios. We introduce SafeCoT, a lightweight, interpretable framework that leverages rule-based chain-of-thought (CoT) supervision to improve refusal behavior in VLMs. Unlike prior methods that rely on large-scale safety annotations or complex modeling, SafeCoT uses minimal supervision to help models reason about safety risks and make context-aware refusals. Experiments across multiple benchmarks show that SafeCoT significantly reduces overrefusal and enhances generalization, even with limited training data. Our approach offers a scalable solution for aligning VLMs with safety-critical objectives.', 'abstract_zh': '确保视觉语言模型在高风险或模糊场景下提供安全且适当的回应仍是一项关键挑战。我们提出了一种名为SafeCoT的轻量级可解释框架，该框架利用基于规则的链式思考（CoT）监督来提高视觉语言模型的拒绝行为。与依赖大规模安全注释或复杂模型的先前方法不同，SafeCoT采用最少的监督来帮助模型推理安全风险并做出情境相关的拒绝。多项基准测试的结果表明，SafeCoT显著减少了过度拒绝并增强了泛化能力，即使在有限的训练数据下也是如此。我们的方法为使视觉语言模型与安全关键目标保持一致提供了可扩展的解决方案。', 'title_zh': 'SafeCoT：通过最小推理提高VLM安全性'}
{'arxiv_id': 'arXiv:2506.08306', 'title': 'AstroCompress: A benchmark dataset for multi-purpose compression of astronomical data', 'authors': 'Tuan Truong, Rithwik Sudharsan, Yibo Yang, Peter Xiangyuan Ma, Ruihan Yang, Stephan Mandt, Joshua S. Bloom', 'link': 'https://arxiv.org/abs/2506.08306', 'abstract': 'The site conditions that make astronomical observatories in space and on the ground so desirable -- cold and dark -- demand a physical remoteness that leads to limited data transmission capabilities. Such transmission limitations directly bottleneck the amount of data acquired and in an era of costly modern observatories, any improvements in lossless data compression has the potential scale to billions of dollars worth of additional science that can be accomplished on the same instrument. Traditional lossless methods for compressing astrophysical data are manually designed. Neural data compression, on the other hand, holds the promise of learning compression algorithms end-to-end from data and outperforming classical techniques by leveraging the unique spatial, temporal, and wavelength structures of astronomical images. This paper introduces AstroCompress: a neural compression challenge for astrophysics data, featuring four new datasets (and one legacy dataset) with 16-bit unsigned integer imaging data in various modes: space-based, ground-based, multi-wavelength, and time-series imaging. We provide code to easily access the data and benchmark seven lossless compression methods (three neural and four non-neural, including all practical state-of-the-art algorithms). Our results on lossless compression indicate that lossless neural compression techniques can enhance data collection at observatories, and provide guidance on the adoption of neural compression in scientific applications. Though the scope of this paper is restricted to lossless compression, we also comment on the potential exploration of lossy compression methods in future studies.', 'abstract_zh': '空间和地面天文观测站的理想场所条件——寒冷和黑暗——要求物理上的远离，这导致了有限的数据传输能力。这种传输限制直接制约了获取的数据量，在现代观测站成本高昂的时代，任何在无损数据压缩上的改进都有可能带来数以十亿计美元的额外科学成果。传统无损压缩天体物理数据的方法是手动设计的。相比之下，神经数据压缩有望从数据中端到端学习压缩算法，并通过利用天文图像的独特空间、时间和波长结构超越经典技术。本文介绍了AstroCompress：一个针对天体物理学数据的神经压缩挑战，包含四个新数据集（以及一个遗产数据集），涵盖16位无符号整数成像数据的各种模式：基于空间的、地面的、多波段的和时间序列成像。我们提供了易于访问数据和评估七种无损压缩方法（三种神经和四种非神经，包括所有实际的最新算法）的代码。我们的无损压缩结果表明，无损神经压缩技术可以提高观测站的数据采集能力，并为在科学应用中采用神经压缩提供指导。尽管本文的范围仅限于无损压缩，我们还对未来研究中探索有损压缩方法的可能性进行了评论。', 'title_zh': 'AstroCompress：一个多用途的天文书证数据压缩基准数据集'}
{'arxiv_id': 'arXiv:2506.08150', 'title': 'Compiling Metric Temporal Answer Set Programming', 'authors': 'Arvid Becker, Pedro Cabalar, Martin Diéguez, Javier Romero, Susana Hahn, Torsten Schaub', 'link': 'https://arxiv.org/abs/2506.08150', 'abstract': "We develop a computational approach to Metric Answer Set Programming (ASP) to allow for expressing quantitative temporal constrains, like durations and deadlines. A central challenge is to maintain scalability when dealing with fine-grained timing constraints, which can significantly exacerbate ASP's grounding bottleneck. To address this issue, we leverage extensions of ASP with difference constraints, a simplified form of linear constraints, to handle time-related aspects externally. Our approach effectively decouples metric ASP from the granularity of time, resulting in a solution that is unaffected by time precision.", 'abstract_zh': '我们开发了一种计算方法来扩展度量回答集编程（ASP），以表达定量的时间约束，如持续时间和截止时间。主要挑战在于在处理细粒度的时间约束时保持可扩展性，这可能会显著加剧ASP的底座瓶颈。为解决这一问题，我们利用带有差分约束的ASP扩展，这是一种简化的线性约束形式，将时间相关的方面外部处理。这种方法有效地将度量ASP与时间的粒度分离，从而得到一个不受时间精度影响的解决方案。', 'title_zh': '编译度量时序回答集程序设计'}
{'arxiv_id': 'arXiv:2506.08026', 'title': 'TIP-Search: Time-Predictable Inference Scheduling for Market Prediction under Uncertain Load', 'authors': 'Xibai Wang', 'link': 'https://arxiv.org/abs/2506.08026', 'abstract': 'This paper proposes TIP-Search, a time-predictable inference scheduling framework for real-time market prediction under uncertain workloads. Motivated by the strict latency demands in high-frequency financial systems, TIP-Search dynamically selects a deep learning model from a heterogeneous pool, aiming to maximize predictive accuracy while satisfying per-task deadline constraints. Our approach profiles latency and generalization performance offline, then performs online task-aware selection without relying on explicit input domain labels. We evaluate TIP-Search on three real-world limit order book datasets (FI-2010, Binance BTC/USDT, LOBSTER AAPL) and demonstrate that it outperforms static baselines with up to 8.5% improvement in accuracy and 100% deadline satisfaction. Our results highlight the effectiveness of TIP-Search in robust low-latency financial inference under uncertainty.', 'abstract_zh': 'TIP-Search：面向不确定工作负载的实时市场预测可预测时间推理调度框架', 'title_zh': 'TIP-Search: 时间可预测推断调度以应对不确定负载的市场预测'}
{'arxiv_id': 'arXiv:2506.09018', 'title': 'Edit Flows: Flow Matching with Edit Operations', 'authors': 'Marton Havasi, Brian Karrer, Itai Gat, Ricky T. Q. Chen', 'link': 'https://arxiv.org/abs/2506.09018', 'abstract': 'Autoregressive generative models naturally generate variable-length sequences, while non-autoregressive models struggle, often imposing rigid, token-wise structures. We propose Edit Flows, a non-autoregressive model that overcomes these limitations by defining a discrete flow over sequences through edit operations-insertions, deletions, and substitutions. By modeling these operations within a Continuous-time Markov Chain over the sequence space, Edit Flows enable flexible, position-relative generation that aligns more closely with the structure of sequence data. Our training method leverages an expanded state space with auxiliary variables, making the learning process efficient and tractable. Empirical results show that Edit Flows outperforms both autoregressive and mask models on image captioning and significantly outperforms the mask construction in text and code generation.', 'abstract_zh': '非自回归生成模型通过编辑操作克服长度限制，实现灵活的序列生成', 'title_zh': '编辑流：基于编辑操作的流匹配'}
{'arxiv_id': 'arXiv:2506.08999', 'title': 'Employing self-supervised learning models for cross-linguistic child speech maturity classification', 'authors': 'Theo Zhang, Madurya Suresh, Anne S. Warlaumont, Kasia Hitczenko, Alejandrina Cristia, Margaret Cychosz', 'link': 'https://arxiv.org/abs/2506.08999', 'abstract': 'Speech technology systems struggle with many downstream tasks for child speech due to small training corpora and the difficulties that child speech pose. We apply a novel dataset, SpeechMaturity, to state-of-the-art transformer models to address a fundamental classification task: identifying child vocalizations. Unlike previous corpora, our dataset captures maximally ecologically-valid child vocalizations across an unprecedented sample, comprising children acquiring 25+ languages in the U.S., Bolivia, Vanuatu, Papua New Guinea, Solomon Islands, and France. The dataset contains 242,004 labeled vocalizations, magnitudes larger than previous work. Models were trained to distinguish between cry, laughter, mature (consonant+vowel), and immature speech (just consonant or vowel). Models trained on the dataset outperform state-of-the-art models trained on previous datasets, achieved classification accuracy comparable to humans, and were robust across rural and urban settings.', 'abstract_zh': '由于儿童语音的小规模训练语料库和其带来的挑战，语音技术系统在处理儿童语音的下游任务中表现不佳。我们应用一种新颖的数据集SpeechMaturity到最先进的变压器模型上，以解决一项基础分类任务：识别儿童语音。与之前的语料库不同，我们的数据集捕捉了前所未有的样本中最大化生态有效的儿童语音，包括在美国、玻利维亚、瓦努阿图、巴布亚新几内亚、所罗门群岛和法国学习25种以上语言的儿童。该数据集包含242,004个标注的语音样本，规模远超以往工作。模型被训练以区分哭声、笑声、成熟的（辅音+元音）语音和不成熟的（仅辅音或元音）语音。在该数据集上训练的模型超越了在先前数据集上训练的最先进的模型，并且分类准确度与人类相当，且具有跨农村和城市环境的稳定性。', 'title_zh': '利用自监督学习模型进行跨语言儿童言语成熟度分类'}
{'arxiv_id': 'arXiv:2506.08978', 'title': 'Propositional Logic for Probing Generalization in Neural Networks', 'authors': 'Anna Langedijk, Jaap Jumelet, Willem Zuidema', 'link': 'https://arxiv.org/abs/2506.08978', 'abstract': 'The extent to which neural networks are able to acquire and represent symbolic rules remains a key topic of research and debate. Much current work focuses on the impressive capabilities of large language models, as well as their often ill-understood failures on a wide range of reasoning tasks. In this paper, in contrast, we investigate the generalization behavior of three key neural architectures (Transformers, Graph Convolution Networks and LSTMs) in a controlled task rooted in propositional logic. The task requires models to generate satisfying assignments for logical formulas, making it a structured and interpretable setting for studying compositionality. We introduce a balanced extension of an existing dataset to eliminate superficial patterns and enable testing on unseen operator combinations. Using this dataset, we evaluate the ability of the three architectures to generalize beyond the training distribution. While all models perform well in-distribution, we find that generalization to unseen patterns, particularly those involving negation, remains a significant challenge. Transformers fail to apply negation compositionally, unless structural biases are introduced. Our findings highlight persistent limitations in the ability of standard architectures to learn systematic representations of logical operators, suggesting the need for stronger inductive biases to support robust rule-based reasoning.', 'abstract_zh': '神经网络获取和表示符号规则的能力：三种关键神经架构在命题逻辑任务中的泛化行为', 'title_zh': '命题逻辑在探测试神经网络泛化能力中的应用'}
{'arxiv_id': 'arXiv:2506.08977', 'title': 'Tailored Architectures for Time Series Forecasting: Evaluating Deep Learning Models on Gaussian Process-Generated Data', 'authors': 'Victoria Hankemeier, Malte Schilling', 'link': 'https://arxiv.org/abs/2506.08977', 'abstract': 'Developments in Deep Learning have significantly improved time series forecasting by enabling more accurate modeling of complex temporal dependencies inherent in sequential data. The effectiveness of such models is often demonstrated on limited sets of specific real-world data. Although this allows for comparative analysis, it still does not demonstrate how specific data characteristics align with the architectural strengths of individual models. Our research aims at uncovering clear connections between time series characteristics and particular models. We introduce a novel dataset generated using Gaussian Processes, specifically designed to display distinct, known characteristics for targeted evaluations of model adaptability to them. Furthermore, we present TimeFlex, a new model that incorporates a modular architecture tailored to handle diverse temporal dynamics, including trends and periodic patterns. This model is compared to current state-of-the-art models, offering a deeper understanding of how models perform under varied time series conditions.', 'abstract_zh': '深度学习的发展显著改善了时间序列 forecasting，使其能够更准确地建模序列数据中固有的复杂时间依赖关系。虽然这些模型的有效性通常通过有限的具体现实数据集进行展示，但仍不足以说明特定数据特征如何与个体模型的架构优势相匹配。我们的研究旨在揭示时间序列特征与特定模型之间清晰的联系。我们引入了一个使用高斯过程生成的新数据集，专门设计用于展示不同的已知特征，以便有针对性地评估模型对这些特征的适应性。此外，我们提出了TimeFlex模型，该模型具有模块化的架构，能够处理多种时间动态，包括趋势和周期模式。我们将该模型与当前最先进的模型进行比较，提供了对模型在各种时间序列条件下的表现的更深入理解。', 'title_zh': '为时间序列预测定制的架构：基于高斯过程生成数据的深度学习模型评估'}
{'arxiv_id': 'arXiv:2506.08917', 'title': 'Quantum Adiabatic Generation of Human-Like Passwords', 'authors': 'Sascha Mücke, Raoul Heese, Thore Gerlach, David Biesner, Loong Kuan Lee, Nico Piatkowski', 'link': 'https://arxiv.org/abs/2506.08917', 'abstract': 'Generative Artificial Intelligence (GenAI) for Natural Language Processing (NLP) is the predominant AI technology to date. An important perspective for Quantum Computing (QC) is the question whether QC has the potential to reduce the vast resource requirements for training and operating GenAI models. While large-scale generative NLP tasks are currently out of reach for practical quantum computers, the generation of short semantic structures such as passwords is not. Generating passwords that mimic real user behavior has many applications, for example to test an authentication system against realistic threat models. Classical password generation via deep learning have recently been investigated with significant progress in their ability to generate novel, realistic password candidates. In the present work we investigate the utility of adiabatic quantum computers for this task. More precisely, we study different encodings of token strings and propose novel approaches based on the Quadratic Unconstrained Binary Optimization (QUBO) and the Unit-Disk Maximum Independent Set (UD-MIS) problems. Our approach allows us to estimate the token distribution from data and adiabatically prepare a quantum state from which we eventually sample the generated passwords via measurements. Our results show that relatively small samples of 128 passwords, generated on the QuEra Aquila 256-qubit neutral atom quantum computer, contain human-like passwords such as "Tunas200992" or "teedem28iglove".', 'abstract_zh': '生成式人工智能（GenAI）在自然语言处理（NLP）中的应用是目前主导的AI技术。量子计算（QC）的一个重要视角是探讨QC是否有潜力减少训练和运行GenAI模型所需的大量资源。虽然大规模生成式NLP任务目前超出了实用量子计算机的能力范围，但生成类似密码这样的短语义结构是可行的。模拟真实用户行为生成密码有许多应用，例如测试认证系统以抵御现实威胁模型。通过深度学习的经典密码生成方法最近有了显著进步，能够在生成新颖、真实的密码候选方面取得进展。本研究探讨了使用费米абatic量子计算机执行此任务的适用性。具体而言，我们研究了不同类型的词元字符串编码，并提出了基于二次无约束二元优化（QUBO）和单位圆盘最大独立集（UD-MIS）问题的新颖方法。我们的方法允许我们从数据中估算词元分布，并通过量子态的测量从中抽样生成的密码。实验结果显示，使用QuEra Aquila 256量子比特中性原子量子计算机生成的128个密码样本中包含了类似人类行为的密码，如“Tunas200992”或“teedem28iglove”。', 'title_zh': '量子渐近生成类人类密码'}
{'arxiv_id': 'arXiv:2506.08889', 'title': 'SeerAttention-R: Sparse Attention Adaptation for Long Reasoning', 'authors': 'Yizhao Gao, Shuming Guo, Shijie Cao, Yuqing Xia, Yu Cheng, Lei Wang, Lingxiao Ma, Yutao Sun, Tianzhu Ye, Li Dong, Hayden Kwok-Hay So, Yu Hua, Ting Cao, Fan Yang, Mao Yang', 'link': 'https://arxiv.org/abs/2506.08889', 'abstract': 'We introduce SeerAttention-R, a sparse attention framework specifically tailored for the long decoding of reasoning models. Extended from SeerAttention, SeerAttention-R retains the design of learning attention sparsity through a self-distilled gating mechanism, while removing query pooling to accommodate auto-regressive decoding. With a lightweight plug-in gating, SeerAttention-R is flexible and can be easily integrated into existing pretrained model without modifying the original parameters. We demonstrate that SeerAttention-R, trained on just 0.4B tokens, maintains near-lossless reasoning accuracy with 4K token budget in AIME benchmark under large sparse attention block sizes (64/128). Using TileLang, we develop a highly optimized sparse decoding kernel that achieves near-theoretical speedups of up to 9x over FlashAttention-3 on H100 GPU at 90% sparsity. Code is available at: this https URL.', 'abstract_zh': 'SeerAttention-R：一种特定于长推理解码的稀疏注意力框架', 'title_zh': 'SeerAttention-R：稀疏注意机制适应于长跨度推理'}
{'arxiv_id': 'arXiv:2506.08860', 'title': 'On The Impact of Merge Request Deviations on Code Review Practices', 'authors': 'Samah Kansab, Francis Bordeleau, Ali Tizghadam', 'link': 'https://arxiv.org/abs/2506.08860', 'abstract': 'Code review is a key practice in software engineering, ensuring quality and collaboration. However, industrial Merge Request (MR) workflows often deviate from standardized review processes, with many MRs serving non-review purposes (e.g., drafts, rebases, or dependency updates). We term these cases deviations and hypothesize that ignoring them biases analytics and undermines ML models for review analysis.\nWe identify seven deviation categories, occurring in 37.02% of MRs, and propose a few-shot learning detection method (91% accuracy). By excluding deviations, ML models predicting review completion time improve performance in 53.33% of cases (up to 2.25x) and exhibit significant shifts in feature importance (47% overall, 60% top-*k*).\nOur contributions include: (1) a taxonomy of MR deviations, (2) an AI-driven detection approach, and (3) empirical evidence of their impact on ML-based review analytics. This work aids practitioners in optimizing review efforts and ensuring reliable insights.', 'abstract_zh': '代码审查是软件工程中的关键实践，保障质量和协作。然而，工业合并请求（MR）工作流程常偏离标准的审查流程，许多MR非审查用途（如草稿、重构或依赖更新）。我们把这些情况称为偏差，并假设忽略它们会偏斜分析并削弱审查分析的机器学习模型。', 'title_zh': 'merge请求偏差对代码审查实践的影响'}
{'arxiv_id': 'arXiv:2506.08854', 'title': 'Spatial Transcriptomics Expression Prediction from Histopathology Based on Cross-Modal Mask Reconstruction and Contrastive Learning', 'authors': 'Junzhuo Liu, Markus Eckstein, Zhixiang Wang, Friedrich Feuerhake, Dorit Merhof', 'link': 'https://arxiv.org/abs/2506.08854', 'abstract': 'Spatial transcriptomics is a technology that captures gene expression levels at different spatial locations, widely used in tumor microenvironment analysis and molecular profiling of histopathology, providing valuable insights into resolving gene expression and clinical diagnosis of cancer. Due to the high cost of data acquisition, large-scale spatial transcriptomics data remain challenging to obtain. In this study, we develop a contrastive learning-based deep learning method to predict spatially resolved gene expression from whole-slide images. Evaluation across six different disease datasets demonstrates that, compared to existing studies, our method improves Pearson Correlation Coefficient (PCC) in the prediction of highly expressed genes, highly variable genes, and marker genes by 6.27%, 6.11%, and 11.26% respectively. Further analysis indicates that our method preserves gene-gene correlations and applies to datasets with limited samples. Additionally, our method exhibits potential in cancer tissue localization based on biomarker expression.', 'abstract_zh': '空间转录组学是一种在不同空间位置捕获基因表达水平的技术，广泛应用于肿瘤微环境分析和病理组织学的分子分型，提供了解决基因表达和癌症临床诊断的重要见解。由于数据获取成本高，大规模的空间转录组学数据仍具有挑战性。在本研究中，我们开发了一种基于对比学习的深度学习方法，用于从全切片图像预测空间解析的基因表达。在六个不同疾病数据集上的评估表明，与现有研究相比，我们的方法在预测高表达基因、高变异性基因和标记基因方面的皮尔逊相关系数（PCC）分别提高了6.27%、6.11%和11.26%。进一步分析表明，我们的方法能够保持基因-基因相关性，并适用于样本量有限的数据集。此外，我们的方法在基于生物标志物表达识别癌组织方面具有潜在应用价值。', 'title_zh': '基于跨模态掩码重构与对比学习的病理图像空间转录组表达预测'}
{'arxiv_id': 'arXiv:2506.08835', 'title': 'CulturalFrames: Assessing Cultural Expectation Alignment in Text-to-Image Models and Evaluation Metrics', 'authors': 'Shravan Nayak, Mehar Bhatia, Xiaofeng Zhang, Verena Rieser, Lisa Anne Hendricks, Sjoerd van Steenkiste, Yash Goyal, Karolina Stańczak, Aishwarya Agrawal', 'link': 'https://arxiv.org/abs/2506.08835', 'abstract': 'The increasing ubiquity of text-to-image (T2I) models as tools for visual content generation raises concerns about their ability to accurately represent diverse cultural contexts. In this work, we present the first study to systematically quantify the alignment of T2I models and evaluation metrics with respect to both explicit as well as implicit cultural expectations. To this end, we introduce CulturalFrames, a novel benchmark designed for rigorous human evaluation of cultural representation in visual generations. Spanning 10 countries and 5 socio-cultural domains, CulturalFrames comprises 983 prompts, 3637 corresponding images generated by 4 state-of-the-art T2I models, and over 10k detailed human annotations. We find that T2I models not only fail to meet the more challenging implicit expectations but also the less challenging explicit expectations. Across models and countries, cultural expectations are missed an average of 44% of the time. Among these failures, explicit expectations are missed at a surprisingly high average rate of 68%, while implicit expectation failures are also significant, averaging 49%. Furthermore, we demonstrate that existing T2I evaluation metrics correlate poorly with human judgments of cultural alignment, irrespective of their internal reasoning. Collectively, our findings expose critical gaps, providing actionable directions for developing more culturally informed T2I models and evaluation methodologies.', 'abstract_zh': 'steadily increasing 的普及性使文本-to-图像 (T2I) 模型作为视觉内容生成工具的应用越来越广泛，这引发了对其准确代表多元文化背景能力的担忧。本文首次系统地量化了T2I模型和评估指标与显性及隐性文化期望之间的对齐情况。为此，我们提出了 CulturalFrames，一个旨在严格评估视觉生成中文化表现的新基准。该基准覆盖10个国家和5个社会文化领域，包括983个提示词、由4个最新T2I模型生成的3637张相应图像，以及超过10000条详细的人类注释。我们发现，T2I模型不仅未能满足更具挑战性的隐性期望，就连较简单的显性期望也未能达到。在国家和模型之间，文化期望平均被忽视44%。在这类失败中，显性期望的失败率出人意料地高达68%，而隐性期望的失败率也相当显著，平均为49%。此外，我们还证明现有的T2I评估指标与人类对文化对齐性的判断几乎没有关联，无论其内部逻辑如何。综合我们的发现揭示了关键的差距，并提供了开发更具文化认知的T2I模型和评估方法的实用指导。', 'title_zh': '文化框架：评估文本到图像模型中的文化期望对齐及其评价指标'}
{'arxiv_id': 'arXiv:2506.08790', 'title': 'Do Generative AI Tools Ensure Green Code? An Investigative Study', 'authors': 'Samarth Sikand, Rohit Mehra, Vibhu Saujanya Sharma, Vikrant Kaulgud, Sanjay Podder, Adam P. Burden', 'link': 'https://arxiv.org/abs/2506.08790', 'abstract': 'Software sustainability is emerging as a primary concern, aiming to optimize resource utilization, minimize environmental impact, and promote a greener, more resilient digital ecosystem. The sustainability or "greenness" of software is typically determined by the adoption of sustainable coding practices. With a maturing ecosystem around generative AI, many software developers now rely on these tools to generate code using natural language prompts. Despite their potential advantages, there is a significant lack of studies on the sustainability aspects of AI-generated code. Specifically, how environmentally friendly is the AI-generated code based upon its adoption of sustainable coding practices? In this paper, we present the results of an early investigation into the sustainability aspects of AI-generated code across three popular generative AI tools - ChatGPT, BARD, and Copilot. The results highlight the default non-green behavior of tools for generating code, across multiple rules and scenarios. It underscores the need for further in-depth investigations and effective remediation strategies.', 'abstract_zh': '软件可持续性正逐渐成为主要关切点，旨在优化资源利用、减少环境影响，并促进更绿色、更具 resilience 的数字生态系统。软件的可持续性或“绿色性”通常由可持续编码实践的采纳来确定。随着生成式 AI 生态系统的发展成熟，许多软件开发人员现在开始依赖这些工具通过自然语言提示生成代码。尽管生成式 AI 具有潜在优势，但关于 AI 生成代码的可持续性方面目前的研究严重不足。特别是，在采纳可持续编码实践的基础上，AI 生成的代码有多环保？在本文中，我们对最受欢迎的三种生成式 AI 工具（ChatGPT、BARD 和 Copilot）生成代码的可持续性方面进行了初步调查，并揭示了这些工具在多种规则和情景下的默认非绿色行为。这突显了进一步深入调查和有效补救策略的必要性。', 'title_zh': '生成式AI工具能否确保绿色代码？一项调查研究'}
{'arxiv_id': 'arXiv:2506.08785', 'title': 'POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration', 'authors': 'Mukul Lokhande, Santosh Kumar Vishvakarma', 'link': 'https://arxiv.org/abs/2506.08785', 'abstract': 'The increasing complexity of AI models requires flexible hardware capable of supporting diverse precision formats, particularly for energy-constrained edge platforms. This work presents PARV-CE, a SIMD-enabled, multi-precision MAC engine that performs efficient multiply-accumulate operations using a unified data-path for 4/8/16-bit fixed-point, floating point, and posit formats. The architecture incorporates a layer adaptive precision strategy to align computational accuracy with workload sensitivity, optimizing both performance and energy usage. PARV-CE integrates quantization-aware execution with a reconfigurable SIMD pipeline, enabling high-throughput processing with minimal overhead through hardware-software co-design. The results demonstrate up to 2x improvement in PDP and 3x reduction in resource usage compared to SoTA designs, while retaining accuracy within 1.8% FP32 baseline. The architecture supports both on-device training and inference across a range of workloads, including DNNs, RNNs, RL, and Transformer models. The empirical analysis establish PARVCE incorporated POLARON as a scalable and energy-efficient solution for precision-adaptive AI acceleration at edge.', 'abstract_zh': 'AI模型日益增加的复杂性要求具有灵活硬件的支持以适应多种精度格式，特别是在能量受限的边缘平台。本工作提出了PARV-CE，这是一种支持单指令多数据（SIMD）且具备多种精度MAC引擎，能够在统一数据路径下高效地执行4/8/16位定点、浮点和Posit格式的乘累加操作。该架构集成了层自适应精度策略，使计算精度与工作负载敏感性保持一致，从而优化性能和能耗。PARV-CE将感知量化执行与可重构SIMD管道相结合，通过硬件软件协同设计实现高吞吐量处理同时减少开销。实验结果表明，与现有最佳设计相比，PARV-CE在每周期定点吞吐量（PDP）上提高了2倍，资源使用量降低了3倍，同时保持在FP32基线准确性范围内1.8%。该架构支持多种工作负载的设备上训练和推理，包括DNN、RNN、RL和Transformer模型。实证分析表明，PARVCE结合Polaron是边缘上可扩展且能效高的精度自适应AI加速解决方案。', 'title_zh': 'Polaron：精度意识的-edge学习与适配运行时可配置的AI加速'}
{'arxiv_id': 'arXiv:2506.08743', 'title': 'Bridging RDF Knowledge Graphs with Graph Neural Networks for Semantically-Rich Recommender Systems', 'authors': 'Michael Färber, David Lamprecht, Yuni Susanti', 'link': 'https://arxiv.org/abs/2506.08743', 'abstract': 'Graph Neural Networks (GNNs) have substantially advanced the field of recommender systems. However, despite the creation of more than a thousand knowledge graphs (KGs) under the W3C standard RDF, their rich semantic information has not yet been fully leveraged in GNN-based recommender systems. To address this gap, we propose a comprehensive integration of RDF KGs with GNNs that utilizes both the topological information from RDF object properties and the content information from RDF datatype properties. Our main focus is an in-depth evaluation of various GNNs, analyzing how different semantic feature initializations and types of graph structure heterogeneity influence their performance in recommendation tasks. Through experiments across multiple recommendation scenarios involving multi-million-node RDF graphs, we demonstrate that harnessing the semantic richness of RDF KGs significantly improves recommender systems and lays the groundwork for GNN-based recommender systems for the Linked Open Data cloud. The code and data are available on our GitHub repository: this https URL', 'abstract_zh': 'RDF知识图谱与图神经网络的综合集成及其在推荐系统中的应用研究', 'title_zh': '基于图神经网络的RDF知识图谱在语义丰富的推荐系统中的融合'}
{'arxiv_id': 'arXiv:2506.08738', 'title': 'Societal AI Research Has Become Less Interdisciplinary', 'authors': 'Dror Kris Markus, Fabrizio Gilardi, Daria Stetsenko', 'link': 'https://arxiv.org/abs/2506.08738', 'abstract': "As artificial intelligence (AI) systems become deeply embedded in everyday life, calls to align AI development with ethical and societal values have intensified. Interdisciplinary collaboration is often championed as a key pathway for fostering such engagement. Yet it remains unclear whether interdisciplinary research teams are actually leading this shift in practice. This study analyzes over 100,000 AI-related papers published on ArXiv between 2014 and 2024 to examine how ethical values and societal concerns are integrated into technical AI research. We develop a classifier to identify societal content and measure the extent to which research papers express these considerations. We find a striking shift: while interdisciplinary teams remain more likely to produce societally-oriented research, computer science-only teams now account for a growing share of the field's overall societal output. These teams are increasingly integrating societal concerns into their papers and tackling a wide range of domains - from fairness and safety to healthcare and misinformation. These findings challenge common assumptions about the drivers of societal AI and raise important questions. First, what are the implications for emerging understandings of AI safety and governance if most societally-oriented research is being undertaken by exclusively technical teams? Second, for scholars in the social sciences and humanities: in a technical field increasingly responsive to societal demands, what distinctive perspectives can we still offer to help shape the future of AI?", 'abstract_zh': '随着人工智能（AI）系统在日常生活中越来越深入，要求将AI发展与伦理和社会价值相一致的呼声不断增强。跨学科合作常被推崇为促进这种参与的关键途径。然而，目前尚不清楚跨学科研究团队是否真正引领了这种实践转变。本研究分析了2014年至2024年间发表在ArXiv上的超过10万篇AI相关论文，以考察伦理价值观和社会关切如何融入技术AI研究。我们开发了一个分类器来识别社会内容，并衡量研究论文表达这些考虑的程度。我们发现一个显著转变：尽管跨学科团队仍更有可能产生以社会为导向的研究，但仅计算机科学团队现在在整体社会输出中占据了快速增长的份额。这些团队越来越多地将其社会关切融入论文，并涵盖了广泛领域——从公平性和安全性到医疗保健和假信息。这些发现挑战了关于社会AI驱动力的常见认知，并提出了重要问题。首先，如果大多数社会导向的研究是由纯粹技术团队来完成的，这对新兴的AI安全性与治理理解有何影响？其次，对于社会科学和人文学科的学者而言：在一个越来越回应社会需求的技术领域，我们仍能提供哪些独特的视角来帮助塑造AI的未来？', 'title_zh': '社会AI研究的跨学科性已经减弱。'}
{'arxiv_id': 'arXiv:2506.08737', 'title': 'Exploration by Random Reward Perturbation', 'authors': 'Haozhe Ma, Guoji Fu, Zhengding Luo, Jiele Wu, Tze-Yun Leong', 'link': 'https://arxiv.org/abs/2506.08737', 'abstract': 'We introduce Random Reward Perturbation (RRP), a novel exploration strategy for reinforcement learning (RL). Our theoretical analyses demonstrate that adding zero-mean noise to environmental rewards effectively enhances policy diversity during training, thereby expanding the range of exploration. RRP is fully compatible with the action-perturbation-based exploration strategies, such as $\\epsilon$-greedy, stochastic policies, and entropy regularization, providing additive improvements to exploration effects. It is general, lightweight, and can be integrated into existing RL algorithms with minimal implementation effort and negligible computational overhead. RRP establishes a theoretical connection between reward shaping and noise-driven exploration, highlighting their complementary potential. Experiments show that RRP significantly boosts the performance of Proximal Policy Optimization and Soft Actor-Critic, achieving higher sample efficiency and escaping local optima across various tasks, under both sparse and dense reward scenarios.', 'abstract_zh': '随机奖励扰动：强化学习的一种新颖探索策略', 'title_zh': '随机奖励扰动探索'}
{'arxiv_id': 'arXiv:2506.08729', 'title': 'Geometric deep learning for local growth prediction on abdominal aortic aneurysm surfaces', 'authors': 'Dieuwertje Alblas, Patryk Rygiel, Julian Suk, Kaj O. Kappe, Marieke Hofman, Christoph Brune, Kak Khee Yeung, Jelmer M. Wolterink', 'link': 'https://arxiv.org/abs/2506.08729', 'abstract': "Abdominal aortic aneurysms (AAAs) are progressive focal dilatations of the abdominal aorta. AAAs may rupture, with a survival rate of only 20\\%. Current clinical guidelines recommend elective surgical repair when the maximum AAA diameter exceeds 55 mm in men or 50 mm in women. Patients that do not meet these criteria are periodically monitored, with surveillance intervals based on the maximum AAA diameter. However, this diameter does not take into account the complex relation between the 3D AAA shape and its growth, making standardized intervals potentially unfit. Personalized AAA growth predictions could improve monitoring strategies. We propose to use an SE(3)-symmetric transformer model to predict AAA growth directly on the vascular model surface enriched with local, multi-physical features. In contrast to other works which have parameterized the AAA shape, this representation preserves the vascular surface's anatomical structure and geometric fidelity. We train our model using a longitudinal dataset of 113 computed tomography angiography (CTA) scans of 24 AAA patients at irregularly sampled intervals. After training, our model predicts AAA growth to the next scan moment with a median diameter error of 1.18 mm. We further demonstrate our model's utility to identify whether a patient will become eligible for elective repair within two years (acc = 0.93). Finally, we evaluate our model's generalization on an external validation set consisting of 25 CTAs from 7 AAA patients from a different hospital. Our results show that local directional AAA growth prediction from the vascular surface is feasible and may contribute to personalized surveillance strategies.", 'abstract_zh': '腹主动脉瘤（AAA）是腹主动脉进行性的局部扩张。AAA有可能破裂，其生存率为仅20%。当前临床指南建议，当男性AAA的最大直径超过55 mm或女性超过50 mm时，应进行选择性外科修复。不符合这些标准的患者将定期进行监测，监测间隔基于AAA的最大直径。然而，这一直径没有考虑到3D AAA形状与其生长之间的复杂关系，使标准化的间隔可能不合适。个性化的AAA生长预测可以改善监测策略。我们提出使用一种SE(3)-对称的变压器模型，直接在富含局部多物理特征的血管模型表面预测AAA生长。与将AAA形状参数化的其他工作不同，这种表示方式保留了血管表面的解剖结构和几何保真度。我们使用24名AAA患者的113个不规则采样间隔的计算机断层扫描血管造影（CTA）扫描 longitudinally 数据集对模型进行训练。训练后，我们的模型在下一扫描时刻预测AAA生长的中位直径误差为1.18 mm。进一步验证了该模型的实用性，可以预测患者在未来两年内是否符合选择性修复的条件（acc = 0.93）。最后，我们在一个外部验证集中评估了我们的模型，该集由另一家医院的7名AAA患者共25个CTA组成。结果表明，从血管表面进行局部方向性的AAA生长预测是可行的，并可能有助于个性化的监测策略。', 'title_zh': '几何深度学习在腹部主动脉瘤表面局部生长预测中的应用'}
{'arxiv_id': 'arXiv:2506.08698', 'title': 'Variational Autoencoder-Based Approach to Latent Feature Analysis on Efficient Representation of Power Load Monitoring Data', 'authors': 'Boyu Xie, Tangtang Xie', 'link': 'https://arxiv.org/abs/2506.08698', 'abstract': 'With the development of smart grids, High-Dimensional and Incomplete (HDI) Power Load Monitoring (PLM) data challenges the performance of Power Load Forecasting (PLF) models. In this paper, we propose a potential characterization model VAE-LF based on Variational Autoencoder (VAE) for efficiently representing and complementing PLM missing data. VAE-LF learns a low-dimensional latent representation of the data using an Encoder-Decoder structure by splitting the HDI PLM data into vectors and feeding them sequentially into the VAE-LF model, and generates the complementary data. Experiments on the UK-DALE dataset show that VAE-LF outperforms other benchmark models in both 5% and 10% sparsity test cases, with significantly lower RMSE and MAE, and especially outperforms on low sparsity ratio data. The method provides an efficient data-completion solution for electric load management in smart grids.', 'abstract_zh': '基于变分自编码器的PLM潜在特征模型VAE-LF：高效表示与补充高维不完全功率负载监测数据', 'title_zh': '基于变分自编码器的潜在特征分析方法在电力负荷监测数据高效表示中的应用'}
{'arxiv_id': 'arXiv:2506.08660', 'title': 'Towards Robust Real-World Multivariate Time Series Forecasting: A Unified Framework for Dependency, Asynchrony, and Missingness', 'authors': 'Jinkwan Jang, Hyungjin Park, Jinmyeong Choi, Taesup Kim', 'link': 'https://arxiv.org/abs/2506.08660', 'abstract': 'Real-world time series data are inherently multivariate, often exhibiting complex inter-channel dependencies. Each channel is typically sampled at its own period and is prone to missing values due to various practical and operational constraints. These characteristics pose fundamental challenges related to channel dependency, sampling asynchrony, and missingness, all of which must be addressed to enable robust and reliable forecasting in practical settings. However, most existing architectures are built on oversimplified assumptions, such as identical sampling periods across channels and fully observed inputs at test time, which often do not hold in real-world scenarios. To bridge this gap, we propose ChannelTokenFormer, a Transformer-based forecasting model with a flexible architecture designed to explicitly capture cross-channel interactions, accommodate channel-wise asynchronous sampling, and effectively handle missing values. Extensive experiments on three benchmark datasets modified to reflect practical settings, along with one real-world industrial dataset, demonstrate the superior robustness and accuracy of ChannelTokenFormer under challenging real-world conditions.', 'abstract_zh': '基于Transformer的ChannelTokenFormer：灵活捕捉跨通道交互的时空序列预测模型', 'title_zh': '面向鲁棒的实际多变量时间序列预测：依赖性、非同步性和缺失性的一体化框架'}
{'arxiv_id': 'arXiv:2506.08652', 'title': 'JoFormer (Journey-based Transformer): Theory and Empirical Analysis on the Tiny Shakespeare Dataset', 'authors': 'Mahesh Godavarti', 'link': 'https://arxiv.org/abs/2506.08652', 'abstract': 'Transformers have demonstrated remarkable success in sequence modeling, yet effectively incorporating positional information remains a challenging and active area of research. In this paper, we introduce JoFormer, a journey-based Transformer architecture grounded in a recently proposed non-commutative algebra for composing transformations across positions. JoFormer represents relative positions through learnable directional transforms that are sequentially composed along the input, thereby extending and generalizing existing approaches based on relative position representations. We derive the JoFormer attention mechanism from first principles and show that it subsumes standard methods such as rotary transformations as special cases. To evaluate its effectiveness, we compare JoFormer to the RoFormer baseline on the Tiny Shakespeare character-level language modeling task. Our results demonstrate that\nJoFormer consistently achieves lower perplexity and faster convergence, highlighting the advantages of its more expressive, journey-based treatment of position. Notably, the per-token JoFormer is still a primitive, conceptual variant with layer-independent angles, yet it already demonstrates strong performance-underscoring its promise as a proof of concept for more expressive architectures. We conclude by discussing how JoFormer offers a principled approach to integrating positional structure into Transformer architectures. The code used in this work is available at this https URL.', 'abstract_zh': '基于旅程的变换器架构JoFormer及其在序列建模中的应用', 'title_zh': '基于旅程的变换器：Tiny Shakespeare 数据集上的理论与实证分析'}
{'arxiv_id': 'arXiv:2506.08634', 'title': "MOSAIC-F: A Framework for Enhancing Students' Oral Presentation Skills through Personalized Feedback", 'authors': 'Alvaro Becerra, Daniel Andres, Pablo Villegas, Roberto Daza, Ruth Cobos', 'link': 'https://arxiv.org/abs/2506.08634', 'abstract': "In this article, we present a novel multimodal feedback framework called MOSAIC-F, an acronym for a data-driven Framework that integrates Multimodal Learning Analytics (MMLA), Observations, Sensors, Artificial Intelligence (AI), and Collaborative assessments for generating personalized feedback on student learning activities. This framework consists of four key steps. First, peers and professors' assessments are conducted through standardized rubrics (that include both quantitative and qualitative evaluations). Second, multimodal data are collected during learning activities, including video recordings, audio capture, gaze tracking, physiological signals (heart rate, motion data), and behavioral interactions. Third, personalized feedback is generated using AI, synthesizing human-based evaluations and data-based multimodal insights such as posture, speech patterns, stress levels, and cognitive load, among others. Finally, students review their own performance through video recordings and engage in self-assessment and feedback visualization, comparing their own evaluations with peers and professors' assessments, class averages, and AI-generated recommendations. By combining human-based and data-based evaluation techniques, this framework enables more accurate, personalized and actionable feedback. We tested MOSAIC-F in the context of improving oral presentation skills.", 'abstract_zh': '一种名为MOSAIC-F的多模态反馈框架：一种结合多模态学习分析、观察、传感器、人工智能和协作评估以生成个性化学习活动反馈的数据驱动框架', 'title_zh': 'MOSAIC-F：一种通过个性化反馈提升学生口头presentation技能的框架'}
{'arxiv_id': 'arXiv:2506.08618', 'title': 'HSG-12M: A Large-Scale Spatial Multigraph Dataset', 'authors': 'Xianquan Yan, Hakan Akgün, Kenji Kawaguchi, N. Duane Loh, Ching Hua Lee', 'link': 'https://arxiv.org/abs/2506.08618', 'abstract': "Existing graph benchmarks assume non-spatial, simple edges, collapsing physically distinct paths into a single link. We introduce HSG-12M, the first large-scale dataset of $\\textbf{spatial multigraphs}-$graphs embedded in a metric space where multiple geometrically distinct trajectories between two nodes are retained as separate edges. HSG-12M contains 11.6 million static and 5.1 million dynamic $\\textit{Hamiltonian spectral graphs}$ across 1401 characteristic-polynomial classes, derived from 177 TB of spectral potential data. Each graph encodes the full geometry of a 1-D crystal's energy spectrum on the complex plane, producing diverse, physics-grounded topologies that transcend conventional node-coordinate datasets. To enable future extensions, we release $\\texttt{Poly2Graph}$: a high-performance, open-source pipeline that maps arbitrary 1-D crystal Hamiltonians to spectral graphs. Benchmarks with popular GNNs expose new challenges in learning from multi-edge geometry at scale. Beyond its practical utility, we show that spectral graphs serve as universal topological fingerprints of polynomials, vectors, and matrices, forging a new algebra-to-graph link. HSG-12M lays the groundwork for geometry-aware graph learning and new opportunities of data-driven scientific discovery in condensed matter physics and beyond.", 'abstract_zh': '现有的图基准假设非空间的简单边，将物理上不同的路径Collapse为单一链接。我们引入HSG-12M，这是第一个大规模的空间多图数据集——这些图嵌在度量空间中，保留了两个节点之间多条几何上不同的轨迹作为单独的边。HSG-12M包含1160万静态和510万动态哈密尔顿谱图，跨越1401个特征多项式类，源自177TB的谱潜力数据。每个图编码了一维晶体能量谱在复平面上的完整几何结构，产生多样且基于物理的拓扑结构，超越了传统的节点坐标数据集。为了便于未来扩展，我们发布了Poly2Graph：一个高性能的开源管道，将任意一维晶体哈密尔顿量映射到谱图。流行的GNN基准揭示了大规模学习多边几何的新挑战。除了其实用价值外，我们展示谱图作为多项式、向量和矩阵的通用拓扑指纹，建立了一种新的代数到图的新联系。HSG-12M为几何感知的图学习和凝聚态物理等领域驱动数据科学的新机遇奠定了基础。', 'title_zh': 'HSG-12M: 一个大规模空域多图数据集'}
{'arxiv_id': 'arXiv:2506.08604', 'title': 'Flow Matching Meets PDEs: A Unified Framework for Physics-Constrained Generation', 'authors': 'Giacomo Baldan, Qiang Liu, Alberto Guardone, Nils Thuerey', 'link': 'https://arxiv.org/abs/2506.08604', 'abstract': 'Generative machine learning methods, such as diffusion models and flow matching, have shown great potential in modeling complex system behaviors and building efficient surrogate models. However, these methods typically learn the underlying physics implicitly from data. We propose Physics-Based Flow Matching (PBFM), a novel generative framework that explicitly embeds physical constraints, both PDE residuals and algebraic relations, into the flow matching objective. We also introduce temporal unrolling at training time that improves the accuracy of the final, noise-free sample prediction. Our method jointly minimizes the flow matching loss and the physics-based residual loss without requiring hyperparameter tuning of their relative weights. Additionally, we analyze the role of the minimum noise level, $\\sigma_{\\min}$, in the context of physical constraints and evaluate a stochastic sampling strategy that helps to reduce physical residuals. Through extensive benchmarks on three representative PDE problems, we show that our approach yields up to an $8\\times$ more accurate physical residuals compared to FM, while clearly outperforming existing algorithms in terms of distributional accuracy. PBFM thus provides a principled and efficient framework for surrogate modeling, uncertainty quantification, and accelerated simulation in physics and engineering applications.', 'abstract_zh': '基于物理的流匹配生成模型（PBFM）：一种嵌入物理约束的高效生成框架', 'title_zh': '流匹配与偏微分方程：一种物理约束生成的统一框架'}
{'arxiv_id': 'arXiv:2506.08602', 'title': 'WGLE:Backdoor-free and Multi-bit Black-box Watermarking for Graph Neural Networks', 'authors': 'Tingzhi Li, Xuefeng Liu', 'link': 'https://arxiv.org/abs/2506.08602', 'abstract': 'Graph Neural Networks (GNNs) are increasingly deployed in graph-related applications, making ownership verification critical to protect their intellectual property against model theft. Fingerprinting and black-box watermarking are two main methods. However, the former relies on determining model similarity, which is computationally expensive and prone to ownership collisions after model post-processing such as model pruning or fine-tuning. The latter embeds backdoors, exposing watermarked models to the risk of backdoor attacks. Moreover, both methods enable ownership verification but do not convey additional information. As a result, each distributed model requires a unique trigger graph, and all trigger graphs must be used to query the suspect model during verification. Multiple queries increase the financial cost and the risk of detection.\nTo address these challenges, this paper proposes WGLE, a novel black-box watermarking paradigm for GNNs that enables embedding the multi-bit string as the ownership information without using backdoors. WGLE builds on a key insight we term Layer-wise Distance Difference on an Edge (LDDE), which quantifies the difference between the feature distance and the prediction distance of two connected nodes. By predefining positive or negative LDDE values for multiple selected edges, WGLE embeds the watermark encoding the intended information without introducing incorrect mappings that compromise the primary task. WGLE is evaluated on six public datasets and six mainstream GNN architectures along with state-of-the-art methods. The results show that WGLE achieves 100% ownership verification accuracy, an average fidelity degradation of 0.85%, comparable robustness against potential attacks, and low embedding overhead. The code is available in the repository.', 'abstract_zh': '隐水印方法WGLE：面向图神经网络的无后门黑盒水印范式', 'title_zh': 'WGLE：无后门多比特黑盒图神经网络水印'}
{'arxiv_id': 'arXiv:2506.08596', 'title': 'Transformers Meet Hyperspectral Imaging: A Comprehensive Study of Models, Challenges and Open Problems', 'authors': 'Guyang Zhang, Waleed Abdulla', 'link': 'https://arxiv.org/abs/2506.08596', 'abstract': "Transformers have become the architecture of choice for learning long-range dependencies, yet their adoption in hyperspectral imaging (HSI) is still emerging. We reviewed more than 300 papers published up to 2025 and present the first end-to-end survey dedicated to Transformer-based HSI classification. The study categorizes every stage of a typical pipeline-pre-processing, patch or pixel tokenization, positional encoding, spatial-spectral feature extraction, multi-head self-attention variants, skip connections, and loss design-and contrasts alternative design choices with the unique spatial-spectral properties of HSI. We map the field's progress against persistent obstacles: scarce labeled data, extreme spectral dimensionality, computational overhead, and limited model explainability. Finally, we outline a research agenda prioritizing valuable public data sets, lightweight on-edge models, illumination and sensor shifts robustness, and intrinsically interpretable attention mechanisms. Our goal is to guide researchers in selecting, combining, or extending Transformer components that are truly fit for purpose for next-generation HSI applications.", 'abstract_zh': 'Transformer架构在长距离依赖学习中的应用已成为首选，但在高光谱成像(HSI)中的采用仍处于起步阶段。我们回顾了截至2025年发表的超过300篇论文，并提供了首篇专注于Transformerベース的HSI分类的端到端综述。研究将典型管道中的每一个阶段分类——预处理、patch或像素 token化、位置编码、空间光谱特征提取、多头自注意力变体、跳跃连接和损失设计——并与HSI的独特空间光谱性质对比了各种设计选择。我们映射了该领域在持续挑战下的进展：稀缺的标注数据、极端的光谱维度、计算开销以及模型解释性有限。最后，我们勾勒出研究议程，优先考虑有价值的数据集、轻量级边缘模型、抗照明和传感器偏移、以及固有的可解释注意力机制。我们的目标是指导研究人员选择、组合或扩展真正适合新一代HSI应用目的的Transformer组件。', 'title_zh': '变压器与高光谱成像结合：模型、挑战与开放问题的研究综述'}
{'arxiv_id': 'arXiv:2506.08594', 'title': 'Solving excited states for long-range interacting trapped ions with neural networks', 'authors': 'Yixuan Ma, Chang Liu, Weikang Li, Shun-Yao Zhang, L.-M. Duan, Yukai Wu, Dong-Ling Deng', 'link': 'https://arxiv.org/abs/2506.08594', 'abstract': 'The computation of excited states in strongly interacting quantum many-body systems is of fundamental importance. Yet, it is notoriously challenging due to the exponential scaling of the Hilbert space dimension with the system size. Here, we introduce a neural network-based algorithm that can simultaneously output multiple low-lying excited states of a quantum many-body spin system in an accurate and efficient fashion. This algorithm, dubbed the neural quantum excited-state (NQES) algorithm, requires no explicit orthogonalization of the states and is generally applicable to higher dimensions. We demonstrate, through concrete examples including the Haldane-Shastry model with all-to-all interactions, that the NQES algorithm is capable of efficiently computing multiple excited states and their related observable expectations. In addition, we apply the NQES algorithm to two classes of long-range interacting trapped-ion systems in a two-dimensional Wigner crystal. For non-decaying all-to-all interactions with alternating signs, our computed low-lying excited states bear spatial correlation patterns similar to those of the ground states, which closely match recent experimental observations that the quasi-adiabatically prepared state accurately reproduces analytical ground-state correlations. For a system of up to 300 ions with power-law decaying antiferromagnetic interactions, we successfully uncover its gap scaling and correlation features. Our results establish a scalable and efficient algorithm for computing excited states of interacting quantum many-body systems, which holds potential applications ranging from benchmarking quantum devices to photoisomerization.', 'abstract_zh': '基于神经网络的强相互作用量子多体系统激发态计算算法', 'title_zh': '用神经网络解决长程相互作用囚禁离子的激发态问题'}
{'arxiv_id': 'arXiv:2506.08577', 'title': 'Diffusion-based Time Series Forecasting for Sewerage Systems', 'authors': 'Nicholas A. Pearson, Francesca Cairoli, Luca Bortolussi, Davide Russo, Francesca Zanello', 'link': 'https://arxiv.org/abs/2506.08577', 'abstract': "We introduce a novel deep learning approach that harnesses the power of generative artificial intelligence to enhance the accuracy of contextual forecasting in sewerage systems. By developing a diffusion-based model that processes multivariate time series data, our system excels at capturing complex correlations across diverse environmental signals, enabling robust predictions even during extreme weather events. To strengthen the model's reliability, we further calibrate its predictions with a conformal inference technique, tailored for probabilistic time series data, ensuring that the resulting prediction intervals are statistically reliable and cover the true target values with a desired confidence level. Our empirical tests on real sewerage system data confirm the model's exceptional capability to deliver reliable contextual predictions, maintaining accuracy even under severe weather conditions.", 'abstract_zh': '我们提出一种新颖的深度学习方法，利用生成人工智能的力量来增强污水系统中上下文预测的准确性。通过开发一种基于扩散的模型来处理多变量时间序列数据，我们的系统能够捕捉复杂多样的环境信号之间的关联，即使在极端天气事件期间也能提供稳健的预测。为进一步提高模型的可靠性，我们使用一种针对概率时间序列数据的 conforms 推断技术来校准其预测，确保预测区间在统计上是可靠的，并以所需的置信水平覆盖真实的目标值。实证研究表明，该模型在严重天气条件下仍能提供可靠的上下文预测，保持较高的准确性。', 'title_zh': '基于扩散的时间序列预测方法在污水处理系统中的应用'}
{'arxiv_id': 'arXiv:2506.08570', 'title': 'Auto-Regressive vs Flow-Matching: a Comparative Study of Modeling Paradigms for Text-to-Music Generation', 'authors': 'Or Tal, Felix Kreuk, Yossi Adi', 'link': 'https://arxiv.org/abs/2506.08570', 'abstract': 'Recent progress in text-to-music generation has enabled models to synthesize high-quality musical segments, full compositions, and even respond to fine-grained control signals, e.g. chord progressions. State-of-the-art (SOTA) systems differ significantly across many dimensions, such as training datasets, modeling paradigms, and architectural choices. This diversity complicates efforts to evaluate models fairly and pinpoint which design choices most influence performance. While factors like data and architecture are important, in this study we focus exclusively on the modeling paradigm. We conduct a systematic empirical analysis to isolate its effects, offering insights into associated trade-offs and emergent behaviors that can guide future text-to-music generation systems. Specifically, we compare the two arguably most common modeling paradigms: Auto-Regressive decoding and Conditional Flow-Matching. We conduct a controlled comparison by training all models from scratch using identical datasets, training configurations, and similar backbone architectures. Performance is evaluated across multiple axes, including generation quality, robustness to inference configurations, scalability, adherence to both textual and temporally aligned conditioning, and editing capabilities in the form of audio inpainting. This comparative study sheds light on distinct strengths and limitations of each paradigm, providing actionable insights that can inform future architectural and training decisions in the evolving landscape of text-to-music generation. Audio sampled examples are available at: this https URL', 'abstract_zh': 'Recent进展在文本到音乐生成领域的最新进展使模型能够合成高质量的音乐片段、完整的曲目，甚至响应细微的控制信号，例如和弦进行。当前最先进的系统在多个维度上存在显著差异，例如训练数据集、建模范式和架构选择。这种多样性使公平地评估模型和确定哪些设计选择对性能影响最大变得复杂。虽然数据和架构因素很重要，但在本研究中，我们仅集中在建模范式上。我们进行了一种系统的实证分析，以分离其影响，提供了关于相关权衡和新兴行为的见解，这些见解可以指导未来文本到音乐生成系统的开发。具体而言，我们将比较两种公认的常见建模范式：自回归解码和条件流匹配。我们通过使用相同的训练数据集、训练配置和类似的基础架构进行零样本训练，进行受控比较。性能在多个维度上进行评估，包括生成质量、推理配置的鲁棒性、可扩展性、对文本和时间对齐条件的遵循以及以音频填补形式的编辑能力。这种比较研究揭示了每种范式的独特优势和局限性，提供了可以指导未来架构和训练决策的可操作见解。音频示例样本请参阅：this https URL。', 'title_zh': '自回归模型 vs 流匹配模型：文本到音乐生成建模范式的比较研究'}
{'arxiv_id': 'arXiv:2506.08569', 'title': 'Flow-Lenia: Emergent evolutionary dynamics in mass conservative continuous cellular automata', 'authors': 'Erwan Plantec, Gautier Hamon, Mayalen Etcheverry, Bert Wang-Chak Chan, Pierre-Yves Oudeyer, Clément Moulin-Frier', 'link': 'https://arxiv.org/abs/2506.08569', 'abstract': 'Central to the artificial life endeavour is the creation of artificial systems spontaneously generating properties found in the living world such as autopoiesis, self-replication, evolution and open-endedness. While numerous models and paradigms have been proposed, cellular automata (CA) have taken a very important place in the field notably as they enable the study of phenomenons like self-reproduction and autopoiesis. Continuous CA like Lenia have been showed to produce life-like patterns reminiscent, on an aesthetic and ontological point of view, of biological organisms we call creatures. We propose in this paper Flow-Lenia, a mass conservative extension of Lenia. We present experiments demonstrating its effectiveness in generating spatially-localized patters (SLPs) with complex behaviors and show that the update rule parameters can be optimized to generate complex creatures showing behaviors of interest. Furthermore, we show that Flow-Lenia allows us to embed the parameters of the model, defining the properties of the emerging patterns, within its own dynamics thus allowing for multispecies simulations. By using the evolutionary activity framework as well as other metrics, we shed light on the emergent evolutionary dynamics taking place in this system.', 'abstract_zh': '基于人工生命的追求，创建能够自发产生类似于生物界特征（如自主生成、自我复制、进化和开放性）的人工系统是核心内容。尽管已经提出了众多模型和范式，细胞自动机（CA）在这一领域中占据了非常重要的位置，特别是它们能够研究类似于自复制和自主生成的现象。连续细胞自动机（如Lenia）已被证明能够生成类似于生物有机体的生物样模式，在美学和本体论意义上尤为如此。本文提出Flow-Lenia，这是一种保持质量守恒的Lenia扩展。我们展示了其在生成具有复杂行为的空间局域模式（SLPs）方面的有效性，并证明可以通过优化更新规则参数来生成具有特定行为的复杂生物。此外，我们展示了Flow-Lenia使得能够将模型参数嵌入其中，从而定义出现模式的属性，进而实现多物种模拟。通过使用进化的活动框架以及其他指标，我们揭示了该系统中发生的涌现性进化动力学。', 'title_zh': '流体-Lenia：守恒连续细胞自动机中的 emergent 进化动力学'}
{'arxiv_id': 'arXiv:2506.08563', 'title': 'KP-PINNs: Kernel Packet Accelerated Physics Informed Neural Networks', 'authors': 'Siyuan Yang, Cheng Song, Zhilu Lai, Wenjia Wang', 'link': 'https://arxiv.org/abs/2506.08563', 'abstract': 'Differential equations are involved in modeling many engineering problems. Many efforts have been devoted to solving differential equations. Due to the flexibility of neural networks, Physics Informed Neural Networks (PINNs) have recently been proposed to solve complex differential equations and have demonstrated superior performance in many applications. While the L2 loss function is usually a default choice in PINNs, it has been shown that the corresponding numerical solution is incorrect and unstable for some complex equations. In this work, we propose a new PINNs framework named Kernel Packet accelerated PINNs (KP-PINNs), which gives a new expression of the loss function using the reproducing kernel Hilbert space (RKHS) norm and uses the Kernel Packet (KP) method to accelerate the computation. Theoretical results show that KP-PINNs can be stable across various differential equations. Numerical experiments illustrate that KP-PINNs can solve differential equations effectively and efficiently. This framework provides a promising direction for improving the stability and accuracy of PINNs-based solvers in scientific computing.', 'abstract_zh': '基于核包络的物理约束神经网络（KP-PINNs）：一种新的损失函数表达及加速计算框架', 'title_zh': 'KP-PINNs: 核包络加速物理信息神经网络'}
{'arxiv_id': 'arXiv:2506.08533', 'title': 'Robust Evolutionary Multi-Objective Network Architecture Search for Reinforcement Learning (EMNAS-RL)', 'authors': 'Nihal Acharya Adde, Alexandra Gianzina, Hanno Gottschalk, Andreas Ebert', 'link': 'https://arxiv.org/abs/2506.08533', 'abstract': 'This paper introduces Evolutionary Multi-Objective Network Architecture Search (EMNAS) for the first time to optimize neural network architectures in large-scale Reinforcement Learning (RL) for Autonomous Driving (AD). EMNAS uses genetic algorithms to automate network design, tailored to enhance rewards and reduce model size without compromising performance. Additionally, parallelization techniques are employed to accelerate the search, and teacher-student methodologies are implemented to ensure scalable optimization. This research underscores the potential of transfer learning as a robust framework for optimizing performance across iterative learning processes by effectively leveraging knowledge from earlier generations to enhance learning efficiency and stability in subsequent generations. Experimental results demonstrate that tailored EMNAS outperforms manually designed models, achieving higher rewards with fewer parameters. The findings of these strategies contribute positively to EMNAS for RL in autonomous driving, advancing the field toward better-performing networks suitable for real-world scenarios.', 'abstract_zh': '进化多目标网络架构搜索（EMNAS）在自主驾驶中的大规模强化学习优化', 'title_zh': '鲁棒进化多目标网络架构搜索在强化学习中的应用（EMNAS-RL）'}
{'arxiv_id': 'arXiv:2506.08505', 'title': 'Explaining, Fast and Slow: Abstraction and Refinement of Provable Explanations', 'authors': 'Shahaf Bassan, Yizhak Yisrael Elboher, Tobias Ladner, Matthias Althoff, Guy Katz', 'link': 'https://arxiv.org/abs/2506.08505', 'abstract': "Despite significant advancements in post-hoc explainability techniques for neural networks, many current methods rely on heuristics and do not provide formally provable guarantees over the explanations provided. Recent work has shown that it is possible to obtain explanations with formal guarantees by identifying subsets of input features that are sufficient to determine that predictions remain unchanged using neural network verification techniques. Despite the appeal of these explanations, their computation faces significant scalability challenges. In this work, we address this gap by proposing a novel abstraction-refinement technique for efficiently computing provably sufficient explanations of neural network predictions. Our method abstracts the original large neural network by constructing a substantially reduced network, where a sufficient explanation of the reduced network is also provably sufficient for the original network, hence significantly speeding up the verification process. If the explanation is in sufficient on the reduced network, we iteratively refine the network size by gradually increasing it until convergence. Our experiments demonstrate that our approach enhances the efficiency of obtaining provably sufficient explanations for neural network predictions while additionally providing a fine-grained interpretation of the network's predictions across different abstraction levels.", 'abstract_zh': '尽管在神经网络的后验解释技术方面取得了显著进展，但当前许多方法仍然依赖于启发式方法，并不能提供形式上可证明的解释保证。最近的研究表明，通过使用神经网络验证技术识别出输入特征的子集，可以使预测保持不变，从而能够获得具有形式上可证明保证的解释。尽管这些解释具有吸引力，但其计算面临显著的可扩展性挑战。在本文中，我们通过提出一种新的抽象化-细化技术来解决这一问题，该技术可以高效地计算神经网络预测的形式上可证明充分的解释。我们的方法通过构建一个大幅减少的网络来抽象原始的大规模神经网络，其中减少网络的充分解释也是原始网络的充分解释，从而显著加快验证过程。如果解释在减少网络上是充分的，我们将通过逐步增加网络规模进行迭代细化，直到收敛。我们的实验表明，我们的方法不仅提高了获得神经网络预测形式上可证明充分解释的效率，还通过不同抽象层级提供了网络预测的细致解释。', 'title_zh': '快与慢的解释：可验证解释的抽象与细化'}
{'arxiv_id': 'arXiv:2506.08479', 'title': 'Efficient Context Selection for Long-Context QA: No Tuning, No Iteration, Just Adaptive-$k$', 'authors': 'Chihiro Taguchi, Seiji Maekawa, Nikita Bhutani', 'link': 'https://arxiv.org/abs/2506.08479', 'abstract': 'Retrieval-augmented generation (RAG) and long-context language models (LCLMs) both address context limitations of LLMs in open-domain question answering (QA). However, optimal external context to retrieve remains an open problem: fixing the retrieval size risks either wasting tokens or omitting key evidence. Existing adaptive methods like Self-RAG and Self-Route rely on iterative LLM prompting and perform well on factoid QA, but struggle with aggregation QA, where the optimal context size is both unknown and variable. We present Adaptive-$k$ retrieval, a simple and effective single-pass method that adaptively selects the number of passages based on the distribution of the similarity scores between the query and the candidate passages. It does not require model fine-tuning, extra LLM inferences or changes to existing retriever-reader pipelines. On both factoid and aggregation QA benchmarks, Adaptive-$k$ matches or outperforms fixed-$k$ baselines while using up to 10x fewer tokens than full-context input, yet still retrieves 70% of relevant passages. It improves accuracy across five LCLMs and two embedding models, highlighting that dynamically adjusting context size leads to more efficient and accurate QA.', 'abstract_zh': 'Retrieval-augmented generation (RAG)和长上下文语言模型（LCLMs）都解决了大规模语言模型在开放域问答中的上下文限制问题。然而，检索到的最佳外部上下文仍然存在开放问题：固定检索大小的风险是既浪费令牌又可能省略关键证据。现有的自适应方法如Self-RAG和Self-Route依赖于迭代的LLM提示，在事实型问答中表现良好，但在聚合型问答中遇到困难，因为在聚合型问答中，最优的上下文大小既未知又变化。我们提出了一种简单的单步自适应检索（Adaptive-$k$ retrieval）方法，该方法根据查询与候选段落相似得分的分布，自适应地选择段落数量。该方法不需要模型微调、额外的LLM推理或更改现有的检索-阅读管道。在事实型和聚合型问答基准测试中，Adaptive-$k$ 在使用比全长上下文输入少10倍的令牌的情况下，与固定-$k$ 基线持平或表现出色，同时仍检索到70%的相关段落。该方法在五个LCLMs和两种嵌入模型上提高了准确性，突显了动态调整上下文大小可以提高问答的效率和准确性。', 'title_zh': '长上下文QA中的高效背景选择：无需调优，无需迭代，只需自适应-$k$'}
{'arxiv_id': 'arXiv:2506.08459', 'title': 'Diffusion Models for Safety Validation of Autonomous Driving Systems', 'authors': 'Juanran Wang, Marc R. Schlichting, Harrison Delecki, Mykel J. Kochenderfer', 'link': 'https://arxiv.org/abs/2506.08459', 'abstract': 'Safety validation of autonomous driving systems is extremely challenging due to the high risks and costs of real-world testing as well as the rarity and diversity of potential failures. To address these challenges, we train a denoising diffusion model to generate potential failure cases of an autonomous vehicle given any initial traffic state. Experiments on a four-way intersection problem show that in a variety of scenarios, the diffusion model can generate realistic failure samples while capturing a wide variety of potential failures. Our model does not require any external training dataset, can perform training and inference with modest computing resources, and does not assume any prior knowledge of the system under test, with applicability to safety validation for traffic intersections.', 'abstract_zh': '自动驾驶系统的安全性验证由于实际测试的风险和成本高以及潜在故障的稀有性和多样性而极具挑战性。为应对这些挑战，我们训练了一个去噪扩散模型，给定任何初始交通状态，生成自动驾驶车辆的潜在故障案例。在四向交叉路口问题上的实验表明，在多种场景下，扩散模型可以生成现实的故障样本，同时捕捉到各种潜在的故障。我们的模型不需要任何外部训练数据集，可以在有限的计算资源下进行训练和推理，并不对待测试系统有任何先验知识假设，适用于交通交叉路口的安全验证。', 'title_zh': '自动驾驶系统安全验证的扩散模型'}
{'arxiv_id': 'arXiv:2506.08426', 'title': 'HASFL: Heterogeneity-aware Split Federated Learning over Edge Computing Systems', 'authors': 'Zheng Lin, Zhe Chen, Xianhao Chen, Wei Ni, Yue Gao', 'link': 'https://arxiv.org/abs/2506.08426', 'abstract': 'Split federated learning (SFL) has emerged as a promising paradigm to democratize machine learning (ML) on edge devices by enabling layer-wise model partitioning. However, existing SFL approaches suffer significantly from the straggler effect due to the heterogeneous capabilities of edge devices. To address the fundamental challenge, we propose adaptively controlling batch sizes (BSs) and model splitting (MS) for edge devices to overcome resource heterogeneity. We first derive a tight convergence bound of SFL that quantifies the impact of varied BSs and MS on learning performance. Based on the convergence bound, we propose HASFL, a heterogeneity-aware SFL framework capable of adaptively controlling BS and MS to balance communication-computing latency and training convergence in heterogeneous edge networks. Extensive experiments with various datasets validate the effectiveness of HASFL and demonstrate its superiority over state-of-the-art benchmarks.', 'abstract_zh': '适应异构性控制批大小和模型划分的自感知联邦学习（HASFL）', 'title_zh': 'HASFL：边缘计算系统中aware分裂联邦学习'}
{'arxiv_id': 'arXiv:2506.08417', 'title': 'Offline RL with Smooth OOD Generalization in Convex Hull and its Neighborhood', 'authors': 'Qingmao Yao, Zhichao Lei, Tianyuan Chen, Ziyue Yuan, Xuefan Chen, Jianxiang Liu, Faguo Wu, Xiao Zhang', 'link': 'https://arxiv.org/abs/2506.08417', 'abstract': 'Offline Reinforcement Learning (RL) struggles with distributional shifts, leading to the $Q$-value overestimation for out-of-distribution (OOD) actions. Existing methods address this issue by imposing constraints; however, they often become overly conservative when evaluating OOD regions, which constrains the $Q$-function generalization. This over-constraint issue results in poor $Q$-value estimation and hinders policy improvement. In this paper, we introduce a novel approach to achieve better $Q$-value estimation by enhancing $Q$-function generalization in OOD regions within Convex Hull and its Neighborhood (CHN). Under the safety generalization guarantees of the CHN, we propose the Smooth Bellman Operator (SBO), which updates OOD $Q$-values by smoothing them with neighboring in-sample $Q$-values. We theoretically show that SBO approximates true $Q$-values for both in-sample and OOD actions within the CHN. Our practical algorithm, Smooth Q-function OOD Generalization (SQOG), empirically alleviates the over-constraint issue, achieving near-accurate $Q$-value estimation. On the D4RL benchmarks, SQOG outperforms existing state-of-the-art methods in both performance and computational efficiency.', 'abstract_zh': 'Convex Hull and its Neighborhood Based Smooth Q-function OOD Generalization', 'title_zh': '离线强化学习中凸包及其邻域内的平滑OOD泛化'}
{'arxiv_id': 'arXiv:2506.08357', 'title': 'MD-ViSCo: A Unified Model for Multi-Directional Vital Sign Waveform Conversion', 'authors': 'Franck Meyer, Kyunghoon Hur, Edward Choi', 'link': 'https://arxiv.org/abs/2506.08357', 'abstract': 'Despite the remarkable progress of deep-learning methods generating a target vital sign waveform from a source vital sign waveform, most existing models are designed exclusively for a specific source-to-target pair. This requires distinct model architectures, optimization procedures, and pre-processing pipelines, resulting in multiple models that hinder usability in clinical settings. To address this limitation, we propose the Multi-Directional Vital-Sign Converter (MD-ViSCo), a unified framework capable of generating any target waveform such as electrocardiogram (ECG), photoplethysmogram (PPG), or arterial blood pressure (ABP) from any single input waveform with a single model. MD-ViSCo employs a shallow 1-Dimensional U-Net integrated with a Swin Transformer that leverages Adaptive Instance Normalization (AdaIN) to capture distinct waveform styles. To evaluate the efficacy of MD-ViSCo, we conduct multi-directional waveform generation on two publicly available datasets. Our framework surpasses state-of-the-art baselines (NabNet & PPG2ABP) on average across all waveform types, lowering Mean absolute error (MAE) by 8.8% and improving Pearson correlation (PC) by 4.9% over two datasets. In addition, the generated ABP waveforms satisfy the Association for the Advancement of Medical Instrumentation (AAMI) criterion and achieve Grade B on the British Hypertension Society (BHS) standard, outperforming all baselines. By eliminating the need for developing a distinct model for each task, we believe that this work offers a unified framework that can deal with any kind of vital sign waveforms with a single model in healthcare monitoring.', 'abstract_zh': '多方向生理信号转换器：使用单一模型生成任意目标波形', 'title_zh': 'MD-ViSCo: 统一的心脏生命体征波形多方向转换模型'}
{'arxiv_id': 'arXiv:2506.08354', 'title': 'Text Embeddings Should Capture Implicit Semantics, Not Just Surface Meaning', 'authors': 'Yiqun Sun, Qiang Huang, Anthony K. H. Tung, Jun Yu', 'link': 'https://arxiv.org/abs/2506.08354', 'abstract': 'This position paper argues that the text embedding research community should move beyond surface meaning and embrace implicit semantics as a central modeling goal. Text embedding models have become foundational in modern NLP, powering a wide range of applications and drawing increasing research attention. Yet, much of this progress remains narrowly focused on surface-level semantics. In contrast, linguistic theory emphasizes that meaning is often implicit, shaped by pragmatics, speaker intent, and sociocultural context. Current embedding models are typically trained on data that lacks such depth and evaluated on benchmarks that reward the capture of surface meaning. As a result, they struggle with tasks requiring interpretive reasoning, speaker stance, or social meaning. Our pilot study highlights this gap, showing that even state-of-the-art models perform only marginally better than simplistic baselines on implicit semantics tasks. To address this, we call for a paradigm shift: embedding research should prioritize more diverse and linguistically grounded training data, design benchmarks that evaluate deeper semantic understanding, and explicitly frame implicit meaning as a core modeling objective, better aligning embeddings with real-world language complexity.', 'abstract_zh': '这一立场论文argues认为，文本嵌入研究社区应超越表面意义，拥抱潜在语义作为核心建模目标。', 'title_zh': '文本嵌入应捕捉隐含语义，而不仅仅是表面意义'}
{'arxiv_id': 'arXiv:2506.08326', 'title': 'Graph Prompting for Graph Learning Models: Recent Advances and Future Directions', 'authors': 'Xingbo Fu, Zehong Wang, Zihan Chen, Jiazheng Li, Yaochen Zhu, Zhenyu Lei, Cong Shen, Yanfang Ye, Chuxu Zhang, Jundong Li', 'link': 'https://arxiv.org/abs/2506.08326', 'abstract': 'Graph learning models have demonstrated great prowess in learning expressive representations from large-scale graph data in a wide variety of real-world scenarios. As a prevalent strategy for training powerful graph learning models, the "pre-training, adaptation" scheme first pre-trains graph learning models on unlabeled graph data in a self-supervised manner and then adapts them to specific downstream tasks. During the adaptation phase, graph prompting emerges as a promising approach that learns trainable prompts while keeping the pre-trained graph learning models unchanged. In this paper, we present a systematic review of recent advancements in graph prompting. First, we introduce representative graph pre-training methods that serve as the foundation step of graph prompting. Next, we review mainstream techniques in graph prompting and elaborate on how they design learnable prompts for graph prompting. Furthermore, we summarize the real-world applications of graph prompting from different domains. Finally, we discuss several open challenges in existing studies with promising future directions in this field.', 'abstract_zh': '图学习模型在广泛的真实世界场景中展示了从大规模图数据中学习丰富表示的强大能力。作为一种训练强大图学习模型的普遍策略，“预训练、适应”方案首先在自监督方式下于无标签图数据上预训练图学习模型，然后将这些模型适应到特定的下游任务。在适应阶段，图提示作为一种有前途的方法出现，它能够学习可训练的提示而不改变预训练的图学习模型。在本文中，我们对图提示领域的最新进展进行了系统综述。首先，我们介绍了作为图提示基础步骤的代表性的图预训练方法。接着，我们回顾了图提示中的主流技术，并解释了它们是如何设计用于图提示的可学习提示的。此外，我们总结了图提示在不同领域的实际应用。最后，我们讨论了现有研究中的几个开放挑战，并提出了该领域有前景的未来方向。', 'title_zh': '图提示技术在图学习模型中的应用：近期进展与未来方向'}
{'arxiv_id': 'arXiv:2506.08309', 'title': 'Learnable Spatial-Temporal Positional Encoding for Link Prediction', 'authors': 'Katherine Tieu, Dongqi Fu, Zihao Li, Ross Maciejewski, Jingrui He', 'link': 'https://arxiv.org/abs/2506.08309', 'abstract': "Accurate predictions rely on the expressiveness power of graph deep learning frameworks like graph neural networks and graph transformers, where a positional encoding mechanism has become much more indispensable in recent state-of-the-art works to record the canonical position information. However, the current positional encoding is limited in three aspects: (1) most positional encoding methods use pre-defined, and fixed functions, which are inadequate to adapt to the complex attributed graphs; (2) a few pioneering works proposed the learnable positional encoding but are still limited to the structural information, not considering the real-world time-evolving topological and feature information; (3) most positional encoding methods are equipped with transformers' attention mechanism to fully leverage their capabilities, where the dense or relational attention is often unaffordable on large-scale structured data. Hence, we aim to develop Learnable Spatial-Temporal Positional Encoding in an effective and efficient manner and propose a simple temporal link prediction model named L-STEP. Briefly, for L-STEP, we (1) prove the proposed positional learning scheme can preserve the graph property from the spatial-temporal spectral viewpoint, (2) verify that MLPs can fully exploit the expressiveness and reach transformers' performance on that encoding, (3) change different initial positional encoding inputs to show robustness, (4) analyze the theoretical complexity and obtain less empirical running time than SOTA, and (5) demonstrate its temporal link prediction out-performance on 13 classic datasets and with 10 algorithms in both transductive and inductive settings using 3 different sampling strategies. Also, \\name\\ obtains the leading performance in the newest large-scale TGB benchmark. Our code is available at this https URL.", 'abstract_zh': '可学习的空间-时间位置编码及其在L-STEP时间链接预测模型中的应用', 'title_zh': '可学习的时空位置编码用于链接预测'}
{'arxiv_id': 'arXiv:2506.08297', 'title': 'SEMA: a Scalable and Efficient Mamba like Attention via Token Localization and Averaging', 'authors': 'Nhat Thanh Tran, Fanghui Xue, Shuai Zhang, Jiancheng Lyu, Yunling Zheng, Yingyong Qi, Jack Xin', 'link': 'https://arxiv.org/abs/2506.08297', 'abstract': 'Attention is the critical component of a transformer. Yet the quadratic computational complexity of vanilla full attention in the input size and the inability of its linear attention variant to focus have been challenges for computer vision tasks. We provide a mathematical definition of generalized attention and formulate both vanilla softmax attention and linear attention within the general framework. We prove that generalized attention disperses, that is, as the number of keys tends to infinity, the query assigns equal weights to all keys. Motivated by the dispersion property and recent development of Mamba form of attention, we design Scalable and Efficient Mamba like Attention (SEMA) which utilizes token localization to avoid dispersion and maintain focusing, complemented by theoretically consistent arithmetic averaging to capture global aspect of attention. We support our approach on Imagenet-1k where classification results show that SEMA is a scalable and effective alternative beyond linear attention, outperforming recent vision Mamba models on increasingly larger scales of images at similar model parameter sizes.', 'abstract_zh': '通用注意力是一种变压器的关键组件。然而，标准全注意力在输入大小上的二次计算复杂度及其线性注意力变体难以聚焦的问题，阻碍了其在计算机视觉任务中的应用。我们提供了通用注意力的数学定义，并将标准softmax注意力和线性注意力统一在一般框架内。我们证明了通用注意力具有分散性，即随着键的数量趋于无穷，查询将等权重地分配给所有键。受分散性性质及Mamba形式注意力的最新进展启发，我们设计了基于令牌定位的可扩展高效Mamba类似注意力（SEMA），利用理论一致的算术平均来捕获注意力的全局特性，并避免分散性以保持聚焦。在ImageNet-1k上，分类结果表明SEMA是一种可扩展且有效的替代方案，在相似的模型参数量下，其在越来越大的图像规模上优于最近的视觉Mamba模型。', 'title_zh': 'SEMA：一种基于令牌本地化和平均的可扩展且高效的类似Mamba注意力机制'}
{'arxiv_id': 'arXiv:2506.08267', 'title': 'Sparse Interpretable Deep Learning with LIES Networks for Symbolic Regression', 'authors': 'Mansooreh Montazerin, Majd Al Aawar, Antonio Ortega, Ajitesh Srivastava', 'link': 'https://arxiv.org/abs/2506.08267', 'abstract': 'Symbolic regression (SR) aims to discover closed-form mathematical expressions that accurately describe data, offering interpretability and analytical insight beyond standard black-box models. Existing SR methods often rely on population-based search or autoregressive modeling, which struggle with scalability and symbolic consistency. We introduce LIES (Logarithm, Identity, Exponential, Sine), a fixed neural network architecture with interpretable primitive activations that are optimized to model symbolic expressions. We develop a framework to extract compact formulae from LIES networks by training with an appropriate oversampling strategy and a tailored loss function to promote sparsity and to prevent gradient instability. After training, it applies additional pruning strategies to further simplify the learned expressions into compact formulae. Our experiments on SR benchmarks show that the LIES framework consistently produces sparse and accurate symbolic formulae outperforming all baselines. We also demonstrate the importance of each design component through ablation studies.', 'abstract_zh': '符号回归（SR）的目标是发现能够准确描述数据的闭式数学表达式，提供超越标准黑盒模型的可解释性和分析洞察。现有的SR方法通常依赖于基于群体的搜索或自回归建模，这在可扩展性和符号一致性方面存在挑战。我们引入了LIES（对数、恒等、指数、正弦）架构，这是一种具有可解释基础激活的固定神经网络架构，并通过优化来建模符号表达式。我们开发了一个框架，通过合适的过采样策略和特定的损失函数来提取紧凑公式，该框架促进稀疏性并防止梯度不稳定性。训练后，应用额外的剪枝策略进一步简化学习到的表达式为紧凑公式。我们在SR基准上的实验表明，LIES框架始终生成比所有基线更好的稀疏且准确的符号公式。我们还通过消融研究展示了每个设计组件的重要性。', 'title_zh': '基于LIES网络的稀疏可解释深度学习符号回归'}
{'arxiv_id': 'arXiv:2506.08260', 'title': 'Automatic Generation of Inference Making Questions for Reading Comprehension Assessments', 'authors': 'Wanjing Anya Ma, Michael Flor, Zuowei Wang', 'link': 'https://arxiv.org/abs/2506.08260', 'abstract': 'Inference making is an essential but complex skill in reading comprehension (RC). Some inferences require resolving references across sentences, and some rely on using prior knowledge to fill in the detail that is not explicitly written in the text. Diagnostic RC questions can help educators provide more effective and targeted reading instruction and interventions for school-age students. We introduce a taxonomy of inference types for RC and use it to analyze the distribution of items within a diagnostic RC item bank. Next, we present experiments using GPT-4o to generate bridging-inference RC items for given reading passages via few-shot prompting, comparing conditions with and without chain-of-thought prompts. Generated items were evaluated on three aspects: overall item quality, appropriate inference type, and LLM reasoning, achieving high inter-rater agreements above 0.90. Our results show that GPT-4o produced 93.8% good-quality questions suitable for operational use in grade 3-12 contexts; however, only 42.6% of the generated questions accurately matched the targeted inference type. We conclude that combining automatic item generation with human judgment offers a promising path toward scalable, high-quality diagnostic RC assessments.', 'abstract_zh': '推理能力是阅读理解中一项重要但复杂的技能。一些推理需要解决句子间的指代问题，而另一些则依赖于利用先验知识填补文本中未明确写出的细节。诊断性阅读理解问题可以帮助教育工作者为学龄学生提供更有效和针对性的阅读指导和干预。我们引入了阅读理解推理类型的分类体系，并利用其分析诊断性阅读理解题库中各题目的分布情况。接着，我们使用GPT-4o通过少量示例提示生成连接推理型阅读理解题目，并通过具和不具思维链提示条件进行对比实验。生成的题目在整体质量、合适的推理类型和LLM推理方面获得了超过0.90的一致性评价。结果显示，GPT-4o生成了适用于3至12年级诊断性阅读理解评估的高质量题目，占93.8%；然而，仅有42.6%的生成题目准确匹配了目标推理类型。我们的研究结论表明，结合自动题目生成与人工判断是实现大规模、高质量诊断性阅读理解评估的一种有前景的方法。', 'title_zh': '自动生成推理题 questão 用于阅读理解评估'}
{'arxiv_id': 'arXiv:2506.08255', 'title': 'SHIELD: Secure Hypernetworks for Incremental Expansion Learning Defense', 'authors': 'Patryk Krukowski, Łukasz Gorczyca, Piotr Helm, Kamil Książek, Przemysław Spurek', 'link': 'https://arxiv.org/abs/2506.08255', 'abstract': "Traditional deep neural networks suffer from several limitations, including catastrophic forgetting. When models are adapted to new datasets, they tend to quickly forget previously learned knowledge. Another significant issue is the lack of robustness to even small perturbations in the input data. In practice, we can often easily perform adversarial attacks and change the network's predictions, adding minimal noise to the input. Dedicated architectures and training procedures can solve each of the above problems separately. Unfortunately, currently, no model can simultaneously address both catastrophic forgetting and vulnerability to adversarial attacks. We introduce SHIELD (Secure Hypernetworks for Incremental Expansion and Learning Defense), a novel approach that integrates a hypernetwork-based continual learning approach with interval arithmetic. SHIELD use the hypernetwork to transfer trainable task embedding vectors into the weights of a target model dedicated to specific data. This paradigm allows for the dynamic generation of separate networks for each subtask, while the hypernetwork aggregates and analyzes information across all tasks. The target model takes in the input a data sample with a defined interval range, and by creating a hypercube, produces a prediction for the given range. Therefore, such target models provide strict guarantees against all possible attacks for data samples within the interval range. Our approach enhances security without sacrificing network adaptability, addressing the overlooked challenge of safety in continual learning.", 'abstract_zh': 'SHIELD：基于超网络的持续学习和安全防御新方法', 'title_zh': 'SHIELD：安全超网络用于增量扩展学习防御'}
{'arxiv_id': 'arXiv:2506.08244', 'title': 'Parameter-free approximate equivariance for tasks with finite group symmetry', 'authors': 'Riccardo Ali, Pietro Liò, Jamie Vicary', 'link': 'https://arxiv.org/abs/2506.08244', 'abstract': 'Equivariant neural networks incorporate symmetries through group actions, embedding them as an inductive bias to improve performance on a wide variety of tasks. However, existing equivariant methods can be computationally intensive, with high parameter counts, and are often tied to a specific architecture. We propose a simple zero-parameter approach that imposes approximate equivariance for a finite group in the latent representation, as an additional term in the loss function. We conduct experiments which allow the network to learn a group representation on the latent space, and show in every case it prefers to learn the regular representation. Fixing this action on the latent space, this yields a simple method to impose approximate equivariance as an additional loss penalty. We benchmark our approach on three datasets and compare it against several existing equivariant methods, showing that in many cases it achieves similar or better performance for a fraction of the parameters.', 'abstract_zh': '不变神经网络通过集团动作 Incorporate 不变性，将其作为归纳偏见嵌入，以提高各种任务上的性能。然而，现有的不变方法可能计算密集，参数数量高，并且通常与特定架构绑定。我们提出了一种简单的无参方法，在潜在表示中对有限集团施加近似不变性，作为损失函数中的附加项。我们进行了实验，使网络在潜在空间中学习一个集团表示，并在每种情况下都显示它倾向于学习正则表示。固定潜在空间中的此动作，这提供了一种简单的方法来将近似不变性作为附加损失惩罚来施加。我们将该方法在三个数据集上进行基准测试，并与几种现有的不变方法进行比较，结果显示在许多情况下，它以更少的参数实现了相似或更好的性能。', 'title_zh': '具有有限群对称性的任务的参数自由近似等变性'}
{'arxiv_id': 'arXiv:2506.08228', 'title': 'Scaling Laws of Motion Forecasting and Planning -- A Technical Report', 'authors': 'Mustafa Baniodeh, Kratarth Goel, Scott Ettinger, Carlos Fuertes, Ari Seff, Tim Shen, Cole Gulino, Chenjie Yang, Ghassen Jerfel, Dokook Choe, Rui Wang, Vinutha Kallem, Sergio Casas, Rami Al-Rfou, Benjamin Sapp, Dragomir Anguelov', 'link': 'https://arxiv.org/abs/2506.08228', 'abstract': 'We study the empirical scaling laws of a family of encoder-decoder autoregressive transformer models on the task of joint motion forecasting and planning in the autonomous driving domain. Using a 500 thousand hours driving dataset, we demonstrate that, similar to language modeling, model performance improves as a power-law function of the total compute budget, and we observe a strong correlation between model training loss and model evaluation metrics. Most interestingly, closed-loop metrics also improve with scaling, which has important implications for the suitability of open-loop metrics for model development and hill climbing. We also study the optimal scaling of the number of transformer parameters and the training data size for a training compute-optimal model. We find that as the training compute budget grows, optimal scaling requires increasing the model size 1.5x as fast as the dataset size. We also study inference-time compute scaling, where we observe that sampling and clustering the output of smaller models makes them competitive with larger models, up to a crossover point beyond which a larger models becomes more inference-compute efficient. Overall, our experimental results demonstrate that optimizing the training and inference-time scaling properties of motion forecasting and planning models is a key lever for improving their performance to address a wide variety of driving scenarios. Finally, we briefly study the utility of training on general logged driving data of other agents to improve the performance of the ego-agent, an important research area to address the scarcity of robotics data for large capacity models training.', 'abstract_zh': '我们研究了一组编码器-解码器自回归 transformer 模型在自动驾驶领域联合运动预测与规划任务中的经验标度律。利用包含五百多万小时驾驶数据的 datasets，我们表明，类似语言建模，模型性能随着总计算预算的增加呈幂律函数增强，并观察到模型训练损失与模型评估指标间存在强烈相关性。更有趣的是，闭环指标也随标度增强而改善，这对开放环指标在模型开发和优化中的适用性有着重要影响。我们还研究了训练过程中 transformer 参数数量和训练数据规模的最优标度，发现随着训练计算预算的增长，最优标度要求模型规模以比数据集规模快1.5倍的速度增长。我们还研究了推理时计算资源的标度，发现通过采样和聚类较小模型的输出可以使它们与较大模型竞争，直到某个交叉点之后，较大模型在推理计算效率上更具优势。总体而言，我们的实验结果表明，优化运动预测与规划模型的训练和推理时标度特性是提升其性能的关键手段，以应对各种驾驶场景。最后，我们简要研究了利用其他代理的一般记录驾驶数据进行训练以提高自主代理性能的实用性，这是解决大规模模型训练中机器人数据稀缺问题的重要研究领域。', 'title_zh': '运动预测与规划的标度律——技术报告'}
{'arxiv_id': 'arXiv:2506.08167', 'title': 'UniVarFL: Uniformity and Variance Regularized Federated Learning for Heterogeneous Data', 'authors': 'Sunny Gupta, Nikita Jangid, Amit Sethi', 'link': 'https://arxiv.org/abs/2506.08167', 'abstract': "Federated Learning (FL) often suffers from severe performance degradation when faced with non-IID data, largely due to local classifier bias. Traditional remedies such as global model regularization or layer freezing either incur high computational costs or struggle to adapt to feature shifts. In this work, we propose UniVarFL, a novel FL framework that emulates IID-like training dynamics directly at the client level, eliminating the need for global model dependency. UniVarFL leverages two complementary regularization strategies during local training: Classifier Variance Regularization, which aligns class-wise probability distributions with those expected under IID conditions, effectively mitigating local classifier bias; and Hyperspherical Uniformity Regularization, which encourages a uniform distribution of feature representations across the hypersphere, thereby enhancing the model's ability to generalize under diverse data distributions. Extensive experiments on multiple benchmark datasets demonstrate that UniVarFL outperforms existing methods in accuracy, highlighting its potential as a highly scalable and efficient solution for real-world FL deployments, especially in resource-constrained settings. Code: this https URL", 'abstract_zh': 'federated学习（FL）在面对非IID数据时往往会遭受严重的性能下降，主要原因是客户端分类器偏差。传统的解决方案如全局模型正则化或层冻结要么计算成本高昂，要么难以应对特征偏移。在本文中，我们提出UniVarFL，这是一种新型的FL框架，能够在客户端直接模拟类似于IID的训练动态，从而消除对全局模型的依赖。UniVarFL在局部训练期间利用两种互补的正则化策略：分类器方差正则化，通过使类内概率分布与在IID条件下的预期对齐，有效缓解了分类器偏差；超球体均匀性正则化，鼓励特征表示在超球体上的均匀分布，从而增强模型在不同数据分布下的泛化能力。在多个基准数据集上的广泛实验表明，UniVarFL在准确率上优于现有方法，突显了其作为高扩展性和高效解决方案的潜力，尤其是在资源受限的环境中部署FL尤其有前景。代码: [这个链接]。', 'title_zh': 'UnivarFL：异质数据下的均匀性与方差正则化联邦学习'}
{'arxiv_id': 'arXiv:2506.08153', 'title': 'A Metrics-Oriented Architectural Model to Characterize Complexity on Machine Learning-Enabled Systems', 'authors': 'Renato Cordeiro Ferreira', 'link': 'https://arxiv.org/abs/2506.08153', 'abstract': 'How can the complexity of ML-enabled systems be managed effectively? The goal of this research is to investigate how complexity affects ML-Enabled Systems (MLES). To address this question, this research aims to introduce a metrics-based architectural model to characterize the complexity of MLES. The goal is to support architectural decisions, providing a guideline for the inception and growth of these systems. This paper showcases the first step for creating the metrics-based architectural model: an extension of a reference architecture that can describe MLES to collect their metrics.', 'abstract_zh': '如何有效管理由ML驱动系统的复杂性？本研究旨在探讨复杂性如何影响由ML驱动系统（MLES）。为了回答这一问题，本研究旨在引入基于度量的架构模型来刻画MLES的复杂性。目标是支持架构决策，为这些系统的诞生和发展提供指导。本文展示了创建基于度量的架构模型的第一步：对参考架构进行扩展，以便描述MLES并收集其度量数据。', 'title_zh': '基于机器学习赋能系统复杂性特征的指标导向架构模型'}
{'arxiv_id': 'arXiv:2506.08139', 'title': 'Nearness of Neighbors Attention for Regression in Supervised Finetuning', 'authors': 'Aviad Susman, Mayte Suárez-Fariñas, Joseph T Colonel', 'link': 'https://arxiv.org/abs/2506.08139', 'abstract': "It is common in supervised machine learning to combine the feature extraction capabilities of neural networks with the predictive power of traditional algorithms, such as k-nearest neighbors (k-NN) or support vector machines. This procedure involves performing supervised fine-tuning (SFT) on a domain-appropriate feature extractor, followed by training a traditional predictor on the resulting SFT embeddings. When used in this manner, traditional predictors often deliver increased performance over the SFT model itself, despite the fine-tuned feature extractor yielding embeddings specifically optimized for prediction by the neural network's final dense layer. This suggests that directly incorporating traditional algorithms into SFT as prediction layers may further improve performance. However, many traditional algorithms have not been implemented as neural network layers due to their non-differentiable nature and their unique optimization requirements. As a step towards solving this problem, we introduce the Nearness of Neighbors Attention (NONA) regression layer. NONA uses the mechanics of neural network attention and a novel learned attention-masking scheme to yield a differentiable proxy of the k-NN regression algorithm. Results on multiple unstructured datasets show improved performance over both dense layer prediction and k-NN on SFT embeddings for regression.", 'abstract_zh': '监督机器学习中将神经网络的特征提取能力与传统算法的预测能力结合：一种通过近邻注意力机制改进细调效果的方法', 'title_zh': '邻居近邻attention在监督微调中的回归应用'}
{'arxiv_id': 'arXiv:2506.08113', 'title': 'Benchmarking Pre-Trained Time Series Models for Electricity Price Forecasting', 'authors': 'Timothée Hornek Amir Sartipi, Igor Tchappi, Gilbert Fridgen', 'link': 'https://arxiv.org/abs/2506.08113', 'abstract': 'Accurate electricity price forecasting (EPF) is crucial for effective decision-making in power trading on the spot market. While recent advances in generative artificial intelligence (GenAI) and pre-trained large language models (LLMs) have inspired the development of numerous time series foundation models (TSFMs) for time series forecasting, their effectiveness in EPF remains uncertain. To address this gap, we benchmark several state-of-the-art pretrained models--Chronos-Bolt, Chronos-T5, TimesFM, Moirai, Time-MoE, and TimeGPT--against established statistical and machine learning (ML) methods for EPF. Using 2024 day-ahead auction (DAA) electricity prices from Germany, France, the Netherlands, Austria, and Belgium, we generate daily forecasts with a one-day horizon. Chronos-Bolt and Time-MoE emerge as the strongest among the TSFMs, performing on par with traditional models. However, the biseasonal MSTL model, which captures daily and weekly seasonality, stands out for its consistent performance across countries and evaluation metrics, with no TSFM statistically outperforming it.', 'abstract_zh': '准确的电价预测（EPF）对于电力交易现货市场的有效决策至关重要。尽管近期生成式人工智能（GenAI）和预训练大型语言模型（LLMs）的进步激发了许多时间序列基础模型（TSFMs）的发展，但其在EPF中的有效性仍然不确定。为了弥补这一差距，我们将Chronos-Bolt、Chronos-T5、TimesFM、Moirai、Time-MoE和TimeGPT等几种最先进的预训练模型与传统的统计和机器学习（ML）方法进行对比，用于电价预测。基于德国、法国、荷兰、奥地利和比利时的2024天前竞价（DAA）的每日电价数据，我们生成了一天前瞻性的日度预报。Chronos-Bolt和Time-MoE在TSFMs中表现最强，与传统模型相当。然而，能够捕捉日度和周度季节性的二季节模型在各国和各种评价指标下表现出一致性，没有TSFM在其上具有统计上的优越性。', 'title_zh': '预训练时间序列模型在电价预测中的基准比较'}
{'arxiv_id': 'arXiv:2506.08074', 'title': 'Hierarchical Lexical Graph for Enhanced Multi-Hop Retrieval', 'authors': 'Abdellah Ghassel, Ian Robinson, Gabriel Tanase, Hal Cooper, Bryan Thompson, Zhen Han, Vassilis N. Ioannidis, Soji Adeshina, Huzefa Rangwala', 'link': 'https://arxiv.org/abs/2506.08074', 'abstract': 'Retrieval-Augmented Generation (RAG) grounds large language models in external evidence, yet it still falters when answers must be pieced together across semantically distant documents. We close this gap with the Hierarchical Lexical Graph (HLG), a three-tier index that (i) traces every atomic proposition to its source, (ii) clusters propositions into latent topics, and (iii) links entities and relations to expose cross-document paths. On top of HLG we build two complementary, plug-and-play retrievers: StatementGraphRAG, which performs fine-grained entity-aware beam search over propositions for high-precision factoid questions, and TopicGraphRAG, which selects coarse topics before expanding along entity links to supply broad yet relevant context for exploratory queries. Additionally, existing benchmarks lack the complexity required to rigorously evaluate multi-hop summarization systems, often focusing on single-document queries or limited datasets. To address this, we introduce a synthetic dataset generation pipeline that curates realistic, multi-document question-answer pairs, enabling robust evaluation of multi-hop retrieval systems. Extensive experiments across five datasets demonstrate that our methods outperform naive chunk-based RAG achieving an average relative improvement of 23.1% in retrieval recall and correctness. Open-source Python library is available at this https URL.', 'abstract_zh': 'Hierarchical Lexical Graph增强的检索生成（HLG-RAG）：面向多跳检索的多层次词图索引方法', 'title_zh': '层次词图以增强多跳检索'}
{'arxiv_id': 'arXiv:2506.08073', 'title': 'Domain Switching on the Pareto Front: Multi-Objective Deep Kernel Learning in Automated Piezoresponse Force Microscopy', 'authors': 'Yu Liu, Utkarsh Pratiush, Kamyar Barakati, Hiroshi Funakubo, Ching-Che Lin, Jaegyu Kim, Lane W. Martin, Sergei V. Kalinin', 'link': 'https://arxiv.org/abs/2506.08073', 'abstract': 'Ferroelectric polarization switching underpins the functional performance of a wide range of materials and devices, yet its dependence on complex local microstructural features renders systematic exploration by manual or grid-based spectroscopic measurements impractical. Here, we introduce a multi-objective kernel-learning workflow that infers the microstructural rules governing switching behavior directly from high-resolution imaging data. Applied to automated piezoresponse force microscopy (PFM) experiments, our framework efficiently identifies the key relationships between domain-wall configurations and local switching kinetics, revealing how specific wall geometries and defect distributions modulate polarization reversal. Post-experiment analysis projects abstract reward functions, such as switching ease and domain symmetry, onto physically interpretable descriptors including domain configuration and proximity to boundaries. This enables not only high-throughput active learning, but also mechanistic insight into the microstructural control of switching phenomena. While demonstrated for ferroelectric domain switching, our approach provides a powerful, generalizable tool for navigating complex, non-differentiable design spaces, from structure-property correlations in molecular discovery to combinatorial optimization across diverse imaging modalities.', 'abstract_zh': '多目标核学习工作流从高分辨率成像数据中推断调控切换行为的微观结构规则', 'title_zh': '域切换在帕累托前沿上的应用：自动压电力显微镜中的多目标深度核学习'}
{'arxiv_id': 'arXiv:2506.08070', 'title': 'Info-Coevolution: An Efficient Framework for Data Model Coevolution', 'authors': 'Ziheng Qin, Hailun Xu, Wei Chee Yew, Qi Jia, Yang Luo, Kanchan Sarkar, Danhui Guan, Kai Wang, Yang You', 'link': 'https://arxiv.org/abs/2506.08070', 'abstract': 'Machine learning relies heavily on data, yet the continuous growth of real-world data poses challenges for efficient dataset construction and training. A fundamental yet unsolved question is: given our current model and data, does a new data (sample/batch) need annotation/learning? Conventional approaches retain all available data, leading to non-optimal data and training efficiency. Active learning aims to reduce data redundancy by selecting a subset of samples to annotate, while it increases pipeline complexity and introduces bias. In this work, we propose Info-Coevolution, a novel framework that efficiently enables models and data to coevolve through online selective annotation with no bias. Leveraging task-specific models (and open-source models), it selectively annotates and integrates online and web data to improve datasets efficiently. For real-world datasets like ImageNet-1K, Info-Coevolution reduces annotation and training costs by 32\\% without performance loss. It is able to automatically give the saving ratio without tuning the ratio. It can further reduce the annotation ratio to 50\\% with semi-supervised learning. We also explore retrieval-based dataset enhancement using unlabeled open-source data. Code is available at this https URL.', 'abstract_zh': '机器学习高度依赖数据，而现实世界数据的持续增长为高效的数据集构建和训练带来了挑战。一个基本但未解决的问题是：在当前模型和数据条件下，是否需要对新数据（样本/批）进行注解/学习？传统方法保留所有可用数据，导致非最优的数据和训练效率。主动学习通过选择部分样本进行注解来减少数据冗余，但增加了管道复杂性并引入了偏差。在本工作中，我们提出了一种新颖的Info-Coevolution框架，通过在线选择性注解使模型和数据有效协同进化，且无偏差。利用任务特定模型（以及开源模型），它有选择地注解和整合在线和网络数据，以提高数据集的效率。对于如ImageNet-1K等真实世界数据集，Info-Coevolution在不损失性能的情况下，将注解和训练成本降低32%。它能够自动提供节约比例，无需调整比例。通过半监督学习，进一步将注解比例降低至50%。我们还探讨了使用未标注的开源数据进行检索增强的数据集增强方法。代码可通过以下链接获得。', 'title_zh': '信息共演化：一种高效的数据模型共演化框架'}
{'arxiv_id': 'arXiv:2506.08066', 'title': 'WWAggr: A Window Wasserstein-based Aggregation for Ensemble Change Point Detection', 'authors': 'Alexander Stepikin, Evgenia Romanenkova, Alexey Zaytsev', 'link': 'https://arxiv.org/abs/2506.08066', 'abstract': 'Change Point Detection (CPD) aims to identify moments of abrupt distribution shifts in data streams. Real-world high-dimensional CPD remains challenging due to data pattern complexity and violation of common assumptions. Resorting to standalone deep neural networks, the current state-of-the-art detectors have yet to achieve perfect quality. Concurrently, ensembling provides more robust solutions, boosting the performance. In this paper, we investigate ensembles of deep change point detectors and realize that standard prediction aggregation techniques, e.g., averaging, are suboptimal and fail to account for problem peculiarities. Alternatively, we introduce WWAggr -- a novel task-specific method of ensemble aggregation based on the Wasserstein distance. Our procedure is versatile, working effectively with various ensembles of deep CPD models. Moreover, unlike existing solutions, we practically lift a long-standing problem of the decision threshold selection for CPD.', 'abstract_zh': '基于 Wasserstein 距离的深度变更点检测集成方法', 'title_zh': 'WWAggr: 基于窗口 Wasserstein 距离的集成变化点检测聚合方法'}
{'arxiv_id': 'arXiv:2506.08062', 'title': 'FairDICE: Fairness-Driven Offline Multi-Objective Reinforcement Learning', 'authors': 'Woosung Kim, Jinho Lee, Jongmin Lee, Byung-Jun Lee', 'link': 'https://arxiv.org/abs/2506.08062', 'abstract': 'Multi-objective reinforcement learning (MORL) aims to optimize policies in the presence of conflicting objectives, where linear scalarization is commonly used to reduce vector-valued returns into scalar signals. While effective for certain preferences, this approach cannot capture fairness-oriented goals such as Nash social welfare or max-min fairness, which require nonlinear and non-additive trade-offs. Although several online algorithms have been proposed for specific fairness objectives, a unified approach for optimizing nonlinear welfare criteria in the offline setting-where learning must proceed from a fixed dataset-remains unexplored. In this work, we present FairDICE, the first offline MORL framework that directly optimizes nonlinear welfare objective. FairDICE leverages distribution correction estimation to jointly account for welfare maximization and distributional regularization, enabling stable and sample-efficient learning without requiring explicit preference weights or exhaustive weight search. Across multiple offline benchmarks, FairDICE demonstrates strong fairness-aware performance compared to existing baselines.', 'abstract_zh': '多目标强化学习中的公平性导向优化：FairDICE', 'title_zh': 'FairDICE：公平驱动的离线多目标强化学习'}
{'arxiv_id': 'arXiv:2506.08059', 'title': 'CaliciBoost: Performance-Driven Evaluation of Molecular Representations for Caco-2 Permeability Prediction', 'authors': 'Huong Van Le, Weibin Ren, Junhong Kim, Yukyung Yun, Young Bin Park, Young Jun Kim, Bok Kyung Han, Inho Choi, Jong IL Park, Hwi-Yeol Yun, Jae-Mun Choi', 'link': 'https://arxiv.org/abs/2506.08059', 'abstract': 'Caco-2 permeability serves as a critical in vitro indicator for predicting the oral absorption of drug candidates during early-stage drug discovery. To enhance the accuracy and efficiency of computational predictions, we systematically investigated the impact of eight molecular feature representation types including 2D/3D descriptors, structural fingerprints, and deep learning-based embeddings combined with automated machine learning techniques to predict Caco-2 permeability. Using two datasets of differing scale and diversity (TDC benchmark and curated OCHEM data), we assessed model performance across representations and identified PaDEL, Mordred, and RDKit descriptors as particularly effective for Caco-2 prediction. Notably, the AutoML-based model CaliciBoost achieved the best MAE performance. Furthermore, for both PaDEL and Mordred representations, the incorporation of 3D descriptors resulted in a 15.73% reduction in MAE compared to using 2D features alone, as confirmed by feature importance analysis. These findings highlight the effectiveness of AutoML approaches in ADMET modeling and offer practical guidance for feature selection in data-limited prediction tasks.', 'abstract_zh': 'Caco-2通透性作为预测药物候选物口服吸收的关键体外指标，在早期药物发现阶段起到重要作用。为了提高计算预测的准确性和效率，我们系统研究了包括2D/3D描述符、结构指纹和基于深度学习的嵌入式表示在内的八种分子特征表示类型，并结合自动化机器学习技术以预测Caco-2通透性。通过使用不同规模和多样性的两个数据集（TDC基准和OCHEM整理数据），我们评估了不同表示方法的模型性能，并发现PaDEL、Mordred和RDKit描述符特别适用于Caco-2预测。特别地，基于自动化机器学习的CaliciBoost模型在MAE性能上表现最佳。此外，对于PaDEL和Mordred表示方法，将3D描述符纳入其中比仅使用2D特征可使MAE降低15.73%，这一结论得到了特征重要性分析的验证。这些发现突显了自动化机器学习方法在ADMET建模中的有效性，并为基于数据有限的预测任务提供了实用的特征选择指导。', 'title_zh': 'CaliciBoost：基于性能的分子表示法用于Caco-2通透性预测评价'}
{'arxiv_id': 'arXiv:2506.08054', 'title': 'STAMImputer: Spatio-Temporal Attention MoE for Traffic Data Imputation', 'authors': 'Yiming Wang, Hao Peng, Senzhang Wang, Haohua Du, Chunyang Liu, Jia Wu, Guanlin Wu', 'link': 'https://arxiv.org/abs/2506.08054', 'abstract': 'Traffic data imputation is fundamentally important to support various applications in intelligent transportation systems such as traffic flow prediction. However, existing time-to-space sequential methods often fail to effectively extract features in block-wise missing data scenarios. Meanwhile, the static graph structure for spatial feature propagation significantly constrains the models flexibility in handling the distribution shift issue for the nonstationary traffic data. To address these issues, this paper proposes a SpatioTemporal Attention Mixture of experts network named STAMImputer for traffic data imputation. Specifically, we introduce a Mixture of Experts (MoE) framework to capture latent spatio-temporal features and their influence weights, effectively imputing block missing. A novel Low-rank guided Sampling Graph ATtention (LrSGAT) mechanism is designed to dynamically balance the local and global correlations across road networks. The sampled attention vectors are utilized to generate dynamic graphs that capture real-time spatial correlations. Extensive experiments are conducted on four traffic datasets for evaluation. The result shows STAMImputer achieves significantly performance improvement compared with existing SOTA approaches. Our codes are available at this https URL.', 'abstract_zh': '时空注意力混合专家网络在交通数据插补中的应用', 'title_zh': 'STAMImputer: 基于时空注意力混合模型的交通数据插补'}
{'arxiv_id': 'arXiv:2506.08049', 'title': 'Physics-Informed Teleconnection-Aware Transformer for Global Subseasonal-to-Seasonal Forecasting', 'authors': 'Tengfei Lyu, Weijia Zhang, Hao Liu', 'link': 'https://arxiv.org/abs/2506.08049', 'abstract': 'Subseasonal-to-seasonal (S2S) forecasting, which predicts climate conditions from several weeks to months in advance, presents significant challenges due to the chaotic dynamics of atmospheric systems and complex interactions across multiple scales. Current approaches often fail to explicitly model underlying physical processes and teleconnections that are crucial at S2S timescales. We introduce TelePiT, a novel deep learning architecture that enhances global S2S forecasting through integrated multi-scale physics and teleconnection awareness. Our approach consists of three key components: (1) Spherical Harmonic Embedding, which accurately encodes global atmospheric variables onto spherical geometry; (2) Multi-Scale Physics-Informed Neural ODE, which explicitly captures atmospheric physical processes across multiple learnable frequency bands; (3) Teleconnection-Aware Transformer, which models critical global climate interactions through tactfully injecting teleconnection patterns into the self-attention. Extensive experiments demonstrate that TelePiT significantly outperforms state-of-the-art data-driven baselines and operational numerical weather prediction systems, with remarkable improvements for atmospheric variables including a 57.7% reduction in RMSE for 2-meter temperature compared to previous best models.', 'abstract_zh': '季节到季节（S2S）预测：一种通过集成多尺度物理和遥相关意识增强的新型深度学习架构', 'title_zh': '基于物理信息的遥相关感知变换器在全局次季节至季节预测中的应用'}
{'arxiv_id': 'arXiv:2506.08047', 'title': 'Evaluation of Machine Learning Models in Student Academic Performance Prediction', 'authors': 'A.G.R. Sandeepa, Sanka Mohottala', 'link': 'https://arxiv.org/abs/2506.08047', 'abstract': "This research investigates the use of machine learning methods to forecast students' academic performance in a school setting. Students' data with behavioral, academic, and demographic details were used in implementations with standard classical machine learning models including multi-layer perceptron classifier (MLPC). MLPC obtained 86.46% maximum accuracy for test set across all implementations. Under 10-fold cross validation, MLPC obtained 79.58% average accuracy for test set while for train set, it was 99.65%. MLP's better performance over other machine learning models strongly suggest the potential use of neural networks as data-efficient models. Feature selection approach played a crucial role in improving the performance and multiple evaluation approaches were used in order to compare with existing literature. Explainable machine learning methods were utilized to demystify the black box models and to validate the feature selection approach.", 'abstract_zh': '本研究调查了使用机器学习方法预测学校中学生学业成绩的应用。使用包含行为、学术和人口统计学细节的学生数据实施了标准的经典机器学习模型，包括多层感知机分类器（MLPC）。在所有实施中，MLPC在测试集上的最高准确率为86.46%，在10折交叉验证中，MLPC在测试集上的平均准确率为79.58%，而在训练集上的准确率为99.65%。MLP相比其他机器学习模型的更好性能强烈表明，神经网络作为数据高效模型具有潜在应用价值。特征选择方法在提高性能方面起着关键作用，并使用了多种评估方法以与现有文献进行比较。可解释的机器学习方法被利用来揭示黑盒模型，并验证特征选择方法。', 'title_zh': '机器学习模型在学生学业成绩预测中的评估'}
{'arxiv_id': 'arXiv:2506.08041', 'title': 'The World of AI: A Novel Approach to AI Literacy for First-year Engineering Students', 'authors': 'Siddharth Siddharth, Brainerd Prince, Amol Harsh, Shreyas Ramachandran', 'link': 'https://arxiv.org/abs/2506.08041', 'abstract': "This work presents a novel course titled The World of AI designed for first-year undergraduate engineering students with little to no prior exposure to AI. The central problem addressed by this course is that engineering students often lack foundational knowledge of AI and its broader societal implications at the outset of their academic journeys. We believe the way to address this gap is to design and deliver an interdisciplinary course that can a) be accessed by first-year undergraduate engineering students across any domain, b) enable them to understand the basic workings of AI systems sans mathematics, and c) make them appreciate AI's far-reaching implications on our lives. The course was divided into three modules co-delivered by faculty from both engineering and humanities. The planetary module explored AI's dual role as both a catalyst for sustainability and a contributor to environmental challenges. The societal impact module focused on AI biases and concerns around privacy and fairness. Lastly, the workplace module highlighted AI-driven job displacement, emphasizing the importance of adaptation. The novelty of this course lies in its interdisciplinary curriculum design and pedagogical approach, which combines technical instruction with societal discourse. Results revealed that students' comprehension of AI challenges improved across diverse metrics like (a) increased awareness of AI's environmental impact, and (b) efficient corrective solutions for AI fairness. Furthermore, it also indicated the evolution in students' perception of AI's transformative impact on our lives.", 'abstract_zh': '适用于缺乏人工智能背景的理工科大一学生的《人工智能世界》课程创新设计及其影响', 'title_zh': '人工智能的世界：一种面向大一工程学生的新型人工智能素养教学方法'}
{'arxiv_id': 'arXiv:2506.08029', 'title': 'Inverse Design in Distributed Circuits Using Single-Step Reinforcement Learning', 'authors': 'Jiayu Li, Masood Mortazavi, Ning Yan, Yihong Ma, Reza Zafarani', 'link': 'https://arxiv.org/abs/2506.08029', 'abstract': 'The goal of inverse design in distributed circuits is to generate near-optimal designs that meet a desirable transfer function specification. Existing design exploration methods use some combination of strategies involving artificial grids, differentiable evaluation procedures, and specific template topologies. However, real-world design practices often require non-differentiable evaluation procedures, varying topologies, and near-continuous placement spaces. In this paper, we propose DCIDA, a design exploration framework that learns a near-optimal design sampling policy for a target transfer function. DCIDA decides all design factors in a compound single-step action by sampling from a set of jointly-trained conditional distributions generated by the policy. Utilizing an injective interdependent ``map", DCIDA transforms raw sampled design ``actions" into uniquely equivalent physical representations, enabling the framework to learn the conditional dependencies among joint ``raw\'\' design decisions. Our experiments demonstrate DCIDA\'s Transformer-based policy network achieves significant reductions in design error compared to state-of-the-art approaches, with significantly better fit in cases involving more complex transfer functions.', 'abstract_zh': '分布式电路中逆向设计的目标是生成接近最优的设计，以满足期望的传输函数规范。现有的设计探索方法结合使用了涉及人工网格、可微评估程序以及特定模板拓扑的策略。然而，实际的设计实践往往需要非可微评估程序、可变拓扑结构以及接近连续的放置空间。本文提出了一种DCIDA设计探索框架，该框架学习目标传输函数的近最优设计采样策略。DCIDA通过从由策略联合训练生成的条件分布集中采样，一次性决定所有设计因素。利用一个注入性相互依赖的“映射”，DCIDA将原始采样设计“动作”转换为唯一等价的物理表示，从而使框架能够学习联合“原始”设计决策之间的条件依赖关系。我们的实验结果表明，DCIDA基于Transformer的策略网络在设计误差方面比最先进的方法实现了显著减少，尤其是在涉及更复杂传输函数的情况下，匹配效果明显更好。', 'title_zh': '使用单步强化学习在分布式电路中进行逆向设计'}
{'arxiv_id': 'arXiv:2506.08023', 'title': 'Aligning Proteins and Language: A Foundation Model for Protein Retrieval', 'authors': 'Qifeng Wu, Zhengzhe Liu, Han Zhu, Yizhou Zhao, Daisuke Kihara, Min Xu', 'link': 'https://arxiv.org/abs/2506.08023', 'abstract': 'This paper aims to retrieve proteins with similar structures and semantics from large-scale protein dataset, facilitating the functional interpretation of protein structures derived by structural determination methods like cryo-Electron Microscopy (cryo-EM). Motivated by the recent progress of vision-language models (VLMs), we propose a CLIP-style framework for aligning 3D protein structures with functional annotations using contrastive learning. For model training, we propose a large-scale dataset of approximately 200,000 protein-caption pairs with rich functional descriptors. We evaluate our model in both in-domain and more challenging cross-database retrieval on Protein Data Bank (PDB) and Electron Microscopy Data Bank (EMDB) dataset, respectively. In both cases, our approach demonstrates promising zero-shot retrieval performance, highlighting the potential of multimodal foundation models for structure-function understanding in protein biology.', 'abstract_zh': '本文旨在从大规模蛋白数据集中检索具有相似结构和语义的蛋白质，以便于通过如冷冻电子显微镜（cryo-EM）等结构测定方法得到的蛋白结构的功能解读。受近期视觉语言模型（VLMs）进展的启发，我们提出了一种CLIP风格的框架，通过对比学习将3D蛋白结构与功能注释进行对齐。在模型训练中，我们提出了一种包含约200,000个蛋白-描述词对的大规模数据集，其中包含丰富的功能描述。我们在蛋白质数据银行（PDB）和电子显微镜数据银行（EMDB）数据集上分别进行了同域和更具挑战性的跨数据库检索评估。在两种情况下，我们的方法都展示了有前途的零样本检索性能，突显了多模态基础模型在蛋白生物学结构-功能理解方面的潜力。', 'title_zh': '蛋白质与语言对齐：一种蛋白质检索的基础模型'}
{'arxiv_id': 'arXiv:2506.08020', 'title': 'Bi-level Unbalanced Optimal Transport for Partial Domain Adaptation', 'authors': 'Zi-Ying Chen, Chuan-Xian Ren, Hong Yan', 'link': 'https://arxiv.org/abs/2506.08020', 'abstract': 'Partial domain adaptation (PDA) problem requires aligning cross-domain samples while distinguishing the outlier classes for accurate knowledge transfer. The widely used weighting framework tries to address the outlier classes by introducing the reweighed source domain with a similar label distribution to the target domain. However, the empirical modeling of weights can only characterize the sample-wise relations, which leads to insufficient exploration of cluster structures, and the weights could be sensitive to the inaccurate prediction and cause confusion on the outlier classes. To tackle these issues, we propose a Bi-level Unbalanced Optimal Transport (BUOT) model to simultaneously characterize the sample-wise and class-wise relations in a unified transport framework. Specifically, a cooperation mechanism between sample-level and class-level transport is introduced, where the sample-level transport provides essential structure information for the class-level knowledge transfer, while the class-level transport supplies discriminative information for the outlier identification. The bi-level transport plan provides guidance for the alignment process. By incorporating the label-aware transport cost, the local transport structure is ensured and a fast computation formulation is derived to improve the efficiency. Extensive experiments on benchmark datasets validate the competitiveness of BUOT.', 'abstract_zh': '部分领域适应（PDA）问题要求在对齐跨领域样本的同时区分异常类别以实现准确的知识迁移。广泛使用的加权框架通过引入与目标域标签分布相似的重加权源域来处理异常类别，然而，经验性的建模方式只能表征样本间的关联关系，导致对聚类结构的探索不足，并且权重可能会受到不准确预测的影响而对异常类别造成混淆。为解决这些问题，我们提出了一种双层不平衡最优传输（BUOT）模型，以同时在一个统一的传输框架中表征样本级和类级关系。具体而言，在样本级传输与类级传输之间引入了一种合作机制，其中样本级传输为类级知识迁移提供必要的结构信息，而类级传输为异常类别识别提供区分性信息。双层传输计划为对齐过程提供了指导。通过引入标签感知传输代价，确保了局部传输结构，并推导出高效的计算公式以提高计算效率。在基准数据集上的广泛实验验证了BUOT的竞争性。', 'title_zh': '两层不均衡最优运输在部分领域适应中的应用'}
