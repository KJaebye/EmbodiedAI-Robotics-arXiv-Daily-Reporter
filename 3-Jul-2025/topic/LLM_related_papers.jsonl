{'arxiv_id': 'arXiv:2507.01930', 'title': 'Large Language Model-Driven Closed-Loop UAV Operation with Semantic Observations', 'authors': 'Wenhao Wang, Yanyan Li, Long Jiao, Jiawei Yuan', 'link': 'https://arxiv.org/abs/2507.01930', 'abstract': "Large Language Models (LLMs) have revolutionized robotic autonomy, including Unmanned Aerial Vehicles (UAVs). Recent studies have demonstrated the potential of LLMs for translating human instructions into executable control code for UAV operations. However, LLMs still face challenges from logical reasoning and complex decision-making, leading to concerns about the reliability of LLM-driven UAV operations. In this paper, we propose a LLM-driven closed-loop control framework that enables reliable UAV operations powered by effective feedback and refinement using two LLM modules, i.e., a Code Generator and an Evaluator. Our framework transforms numerical state observations from UAV operations into natural language trajectory descriptions to enhance the evaluator LLM's understanding of UAV dynamics for precise feedback generation. Our framework also enables a simulation-based refinement process, and hence eliminates the risks to physical UAVs caused by incorrect code execution during the refinement. Extensive experiments on UAV control tasks with different complexities are conducted. The experimental results show that our framework can achieve reliable UAV operations using LLMs, which significantly outperforms baseline approaches in terms of success rate and completeness with the increase of task complexity.", 'abstract_zh': '大型语言模型（LLMs）已revolutionized无人机自主能力（包括无人驾驶航空车辆UAVs）。近期研究表明，LLMs有潜力将人类指令转化为可执行的控制代码用于UAV操作。然而，LLMs仍面临着逻辑推理和复杂决策的挑战，引发了对其驱动的UAV操作可靠性的担忧。本文提出了一种基于LLMs的闭环控制框架，该框架通过两个LLMs模块——代码生成器和评估器的有效反馈和修正，实现了可靠的UAV操作。该框架将UAV操作中的数值状态观测转化为自然语言轨迹描述，以增强评估器LLM对UAV动力学的理解，从而生成精确的反馈。该框架还支持基于模拟的修正过程，从而消除了在修正期间因错误代码执行而导致的物理UAV风险。在不同复杂度的UAV控制任务上进行了广泛实验。实验结果表明，本框架能够使用LLMs实现可靠的UAV操作，在任务复杂度增加的情况下，与基线方法相比，在成功率和完整性方面表现显著更好。', 'title_zh': '基于语义观测的大型语言模型驱动的闭环无人机操作'}
{'arxiv_id': 'arXiv:2507.01264', 'title': 'LLM-based Realistic Safety-Critical Driving Video Generation', 'authors': 'Yongjie Fu, Ruijian Zha, Pei Tian, Xuan Di', 'link': 'https://arxiv.org/abs/2507.01264', 'abstract': 'Designing diverse and safety-critical driving scenarios is essential for evaluating autonomous driving systems. In this paper, we propose a novel framework that leverages Large Language Models (LLMs) for few-shot code generation to automatically synthesize driving scenarios within the CARLA simulator, which has flexibility in scenario scripting, efficient code-based control of traffic participants, and enforcement of realistic physical dynamics. Given a few example prompts and code samples, the LLM generates safety-critical scenario scripts that specify the behavior and placement of traffic participants, with a particular focus on collision events. To bridge the gap between simulation and real-world appearance, we integrate a video generation pipeline using Cosmos-Transfer1 with ControlNet, which converts rendered scenes into realistic driving videos. Our approach enables controllable scenario generation and facilitates the creation of rare but critical edge cases, such as pedestrian crossings under occlusion or sudden vehicle cut-ins. Experimental results demonstrate the effectiveness of our method in generating a wide range of realistic, diverse, and safety-critical scenarios, offering a promising tool for simulation-based testing of autonomous vehicles.', 'abstract_zh': '利用大型语言模型进行少样本代码生成以自动合成安全关键驾驶场景：一种在CARLA模拟器中的新框架', 'title_zh': '基于LLM的现实主义安全关键驾驶视频生成'}
{'arxiv_id': 'arXiv:2507.01717', 'title': 'Agent Ideate: A Framework for Product Idea Generation from Patents Using Agentic AI', 'authors': 'Gopichand Kanumolu, Ashok Urlana, Charaka Vinayak Kumar, Bala Mallikarjunarao Garlapati', 'link': 'https://arxiv.org/abs/2507.01717', 'abstract': 'Patents contain rich technical knowledge that can inspire innovative product ideas, yet accessing and interpreting this information remains a challenge. This work explores the use of Large Language Models (LLMs) and autonomous agents to mine and generate product concepts from a given patent. In this work, we design Agent Ideate, a framework for automatically generating product-based business ideas from patents. We experimented with open-source LLMs and agent-based architectures across three domains: Computer Science, Natural Language Processing, and Material Chemistry. Evaluation results show that the agentic approach consistently outperformed standalone LLMs in terms of idea quality, relevance, and novelty. These findings suggest that combining LLMs with agentic workflows can significantly enhance the innovation pipeline by unlocking the untapped potential of business idea generation from patent data.', 'abstract_zh': '专利包含丰富的技术知识，可以激发创新产品理念，但获取和解读这些信息仍然颇具挑战。本研究探讨了使用大型语言模型（LLMs）和自主代理从专利中挖掘和生成产品概念的方法。在本研究中，我们设计了Agent Ideate框架，用于自动从专利中生成基于产品的商业理念。我们分别在计算机科学、自然语言处理和材料化学三个领域试验了开源LLMs和基于代理的架构。评估结果显示，代理方法在理念的质量、相关性和新颖性方面均优于独立的LLMs。这些发现表明，将LLMs与代理工作流相结合可以显著增强创新管道，通过挖掘专利数据中的商业理念潜力来提升创新能力。', 'title_zh': 'Agent Ideate: 一种基于专利的用代理人工智能进行产品创意生成的框架'}
{'arxiv_id': 'arXiv:2507.01489', 'title': 'Agent-as-Tool: A Study on the Hierarchical Decision Making with Reinforcement Learning', 'authors': 'Yanfei Zhang', 'link': 'https://arxiv.org/abs/2507.01489', 'abstract': "Large Language Models (LLMs) have emerged as one of the most significant technological advancements in artificial intelligence in recent years. Their ability to understand, generate, and reason with natural language has transformed how we interact with AI systems. With the development of LLM-based agents and reinforcement-learning-based reasoning models, the study of applying reinforcement learning in agent frameworks has become a new research focus. However, all previous studies face the challenge of deciding the tool calling process and the reasoning process simultaneously, and the chain of reasoning was solely relied on the unprocessed raw result with redundant information and symbols unrelated to the task from the tool, which impose a heavy burden on the model's capability to reason. Therefore, in our research, we proposed a hierarchical framework Agent-as-tool that detach the tool calling process and the reasoning process, which enables the model to focus on the verbally reasoning process while the tool calling process is handled by another agent. Our work had achieved comparable results with only a slight reinforcement fine-tuning on 180 samples, and had achieved exceptionally well performance in Bamboogle with 63.2% of exact match and 75.2% in cover exact match, exceeding Search-R1 by 4.8% in exact match and 3.2% in cover exact match.", 'abstract_zh': '大型语言模型(LLMs)已成为近年来人工智能领域最重要的技术进步之一。它们理解和生成自然语言的能力已经改变了我们与AI系统的互动方式。随着基于LLM的代理和基于强化学习的推理模型的发展，将强化学习应用于代理框架中的研究已成为一个新的研究重点。然而，所有先前的研究都面临着同时决定工具调用过程和推理过程的挑战，推理过程依赖于工具提供的未经处理的原始结果，其中包含了与任务无关的冗余信息和符号，这给模型的推理能力带来了沉重负担。因此，在我们的研究中，我们提出了一种分层框架Agent-as-tool，将工具调用过程和推理过程分离，使得模型能够专注于语言推理过程，而工具调用过程则由另一个代理处理。我们的工作仅在180个样本上进行轻微的强化学习微调就取得了可比的结果，并在Bamboogle中表现出色，精确匹配率为63.2%，覆盖精确匹配率为75.2%，分别超过了Search-R1 4.8%和3.2%的精确匹配率和覆盖精确匹配率。', 'title_zh': '工具型智能体：基于强化学习的分级决策研究'}
{'arxiv_id': 'arXiv:2507.01446', 'title': 'Using multi-agent architecture to mitigate the risk of LLM hallucinations', 'authors': 'Abd Elrahman Amer, Magdi Amer', 'link': 'https://arxiv.org/abs/2507.01446', 'abstract': "Improving customer service quality and response time are critical factors for maintaining customer loyalty and increasing a company's market share. While adopting emerging technologies such as Large Language Models (LLMs) is becoming a necessity to achieve these goals, the risk of hallucination remains a major challenge. In this paper, we present a multi-agent system to handle customer requests sent via SMS. This system integrates LLM based agents with fuzzy logic to mitigate hallucination risks.", 'abstract_zh': '提高客户服务质量和响应时间是维持客户忠诚度和增加公司市场份额的关键因素。尽管采用大型语言模型等新兴技术已成为实现这些目标的必要条件，幻觉风险仍然是一个主要挑战。本文提出了一种多代理系统来处理通过短信发送的客户请求，该系统结合了基于大型语言模型的代理和模糊逻辑以减轻幻觉风险。', 'title_zh': '使用多代理架构减轻大语言模型幻觉风险'}
{'arxiv_id': 'arXiv:2507.01431', 'title': 'Pensieve Grader: An AI-Powered, Ready-to-Use Platform for Effortless Handwritten STEM Grading', 'authors': 'Yoonseok Yang, Minjune Kim, Marlon Rondinelli, Keren Shao', 'link': 'https://arxiv.org/abs/2507.01431', 'abstract': 'Grading handwritten, open-ended responses remains a major bottleneck in large university STEM courses. We introduce Pensieve (this https URL), an AI-assisted grading platform that leverages large language models (LLMs) to transcribe and evaluate student work, providing instructors with rubric-aligned scores, transcriptions, and confidence ratings. Unlike prior tools that focus narrowly on specific tasks like transcription or rubric generation, Pensieve supports the entire grading pipeline-from scanned student submissions to final feedback-within a human-in-the-loop interface.\nPensieve has been deployed in real-world courses at over 20 institutions and has graded more than 300,000 student responses. We present system details and empirical results across four core STEM disciplines: Computer Science, Mathematics, Physics, and Chemistry. Our findings show that Pensieve reduces grading time by an average of 65%, while maintaining a 95.4% agreement rate with instructor-assigned grades for high-confidence predictions.', 'abstract_zh': '手写开放性回答的评分仍然是大型大学STEM课程中的主要瓶颈。我们介绍了一种名为Pensieve的AI辅助评分平台（this https URL），该平台利用大型语言模型（LLMs）进行评分学生的作业，为教师提供评分、转写和置信度评级。与仅专注于特定任务（如转写或评分标准生成）的先前工具不同，Pensieve支持从扫描的学生提交到最终反馈的整个评分流程，并采用人机协作界面。Pensieve已在超过20所机构的实际课程中部署，并评分了超过30万份学生回答。我们介绍了四个核心STEM学科（计算机科学、数学、物理和化学）的具体系统细节和实证结果。研究结果表明，Pensieve将评分时间减少了平均65%，同时保持了95.4%的高置信度预测与教师评分的一致率。', 'title_zh': 'Pensieve Grader: 一个基于AI的即用型平台，实现轻松手写STEM作业批阅'}
{'arxiv_id': 'arXiv:2507.01376', 'title': 'AI Agents and Agentic AI-Navigating a Plethora of Concepts for Future Manufacturing', 'authors': 'Yinwang Ren, Yangyang Liu, Tang Ji, Xun Xu', 'link': 'https://arxiv.org/abs/2507.01376', 'abstract': "AI agents are autonomous systems designed to perceive, reason, and act within dynamic environments. With the rapid advancements in generative AI (GenAI), large language models (LLMs) and multimodal large language models (MLLMs) have significantly improved AI agents' capabilities in semantic comprehension, complex reasoning, and autonomous decision-making. At the same time, the rise of Agentic AI highlights adaptability and goal-directed autonomy in dynamic and complex environments. LLMs-based AI Agents (LLM-Agents), MLLMs-based AI Agents (MLLM-Agents), and Agentic AI contribute to expanding AI's capabilities in information processing, environmental perception, and autonomous decision-making, opening new avenues for smart manufacturing. However, the definitions, capability boundaries, and practical applications of these emerging AI paradigms in smart manufacturing remain unclear. To address this gap, this study systematically reviews the evolution of AI and AI agent technologies, examines the core concepts and technological advancements of LLM-Agents, MLLM-Agents, and Agentic AI, and explores their potential applications in and integration into manufacturing, along with the potential challenges they may face.", 'abstract_zh': '基于大型语言模型的AI代理、基于多模态大型语言模型的AI代理和行动AI在智能制造中的演进及其应用研究', 'title_zh': 'AI代理与代理型AI：导航未来制造中的众多概念'}
{'arxiv_id': 'arXiv:2507.01231', 'title': 'Rethinking the Illusion of Thinking', 'authors': 'Iñaki Dellibarda Varela, Pablo Romero-Sorozabal, Eduardo Rocon, Manuel Cebrian', 'link': 'https://arxiv.org/abs/2507.01231', 'abstract': 'Earlier this year, Apple ignited controversy by publishing "The Illusion of Thinking," prompting heated debate within the AI community. Critics seized upon the findings as conclusive evidence that Large Reasoning Models (LRMs) lack genuine reasoning capabilities, branding them as mere stochastic parrots. Meanwhile, defenders-spearheaded by Lawsen et al. (2025)-fired back, condemning the experimental setup as flawed and the conclusions overstated. We clarify this debate by replicating and refining two of the original study\'s most contentious benchmarks: Towers of Hanoi and River Crossing. By introducing incremental stepwise prompting and agentic collaborative dialogue, we show that previously reported failures solving the Towers of Hanoi were not purely result of output constraints, but also partly a result of cognition limitations: LRMs still stumble when complexity rises moderately (around 8 disks). Moreover, the River Crossing results initially heralded as catastrophic failures turn out to hinge upon testing unsolvable configurations. Once we limit tests strictly to solvable problems-LRMs effortlessly solve large instances involving over 100 agent pairs. Our findings ultimately defy simplistic narratives: today\'s LRMs are stochastic, RL-tuned searchers in a discrete state space we barely understand. Real progress in symbolic, long-horizon reasoning demands mapping that terrain through fine-grained ablations like those introduced here.', 'abstract_zh': 'Earlier 今年初，苹果公司通过发布《思考的幻象》引发了争议，引发了AI界激烈的讨论。批评者将研究结果视为确凿证据，认为大型推理模型缺乏真正的推理能力，仅仅是随机鹦鹉。同时，捍卫者（Lawsen等，2025）反驳称实验设计有缺陷，结论夸大其词。我们通过复制并改进原始研究中最具争议的两项基准测试——汉诺塔塔和过河——澄清了这一争论。通过引入逐步提示和有代理的合作对话，我们表明，先前报道的汉诺塔解决方案失败不仅源自输出限制，还部分源于认知限制：当复杂度适度增加（大约8个盘子）时，大型推理模型仍会遇到困难。此外，最初被认为灾难性的过河测试结果实际上取决于测试不可解的配置。一旦严格限制测试范围为可解问题，大型推理模型就能轻易解决涉及超过100个代理的大型实例。我们的发现最终打破了简单的叙事框架：当今的大型推理模型是离散状态空间中随机化强化学习优化的搜索者，我们对其知之甚少。在符号、长时推理方面的真正进步需要通过此类精细拆分的方法来绘制这一领域。', 'title_zh': '重新思考思考的错觉'}
{'arxiv_id': 'arXiv:2507.01915', 'title': 'Gradient-Adaptive Policy Optimization: Towards Multi-Objective Alignment of Large Language Models', 'authors': 'Chengao Li, Hanyu Zhang, Yunkun Xu, Hongyan Xue, Xiang Ao, Qing He', 'link': 'https://arxiv.org/abs/2507.01915', 'abstract': "Reinforcement Learning from Human Feedback (RLHF) has emerged as a powerful technique for aligning large language models (LLMs) with human preferences. However, effectively aligning LLMs with diverse human preferences remains a significant challenge, particularly when they are conflict. To address this issue, we frame human value alignment as a multi-objective optimization problem, aiming to maximize a set of potentially conflicting objectives. We introduce Gradient-Adaptive Policy Optimization (GAPO), a novel fine-tuning paradigm that employs multiple-gradient descent to align LLMs with diverse preference distributions. GAPO adaptively rescales the gradients for each objective to determine an update direction that optimally balances the trade-offs between objectives. Additionally, we introduce P-GAPO, which incorporates user preferences across different objectives and achieves Pareto solutions that better align with the user's specific needs. Our theoretical analysis demonstrates that GAPO converges towards a Pareto optimal solution for multiple objectives. Empirical results on Mistral-7B show that GAPO outperforms current state-of-the-art methods, achieving superior performance in both helpfulness and harmlessness.", 'abstract_zh': '基于人类反馈的强化学习（RLHF）已成为一种将大型语言模型（LLMs）与人类偏好对齐的强大技术。然而，有效地将LLMs与多样化的人类偏好对齐仍然是一个重大挑战，特别是当这些偏好存在冲突时。为了解决这一问题，我们将人类价值对齐视为一个多目标优化问题，旨在最大化一系列潜在冲突的目标。我们提出了梯度自适应策略优化（GAPO），这是一种新颖的微调范式，利用多梯度下降来使LLMs与多样的偏好分布对齐。GAPO自适应地重新缩放每个目标的梯度，以确定最优平衡不同目标之间权衡的更新方向。此外，我们提出了P-GAPO，它结合了不同目标上的用户偏好，并达到了更好地满足用户特定需求的帕累托最优解。我们的理论分析表明，GAPO能够收敛到多个目标的帕累托最优解。实验结果表明，GAPO在Mistral-7B上优于当前最先进的方法，在有用性和无害性方面均表现出更好的性能。', 'title_zh': '适应梯度多目标大型语言模型政策优化：朝向多目标对齐'}
{'arxiv_id': 'arXiv:2507.01862', 'title': 'Bridging UI Design and chatbot Interactions: Applying Form-Based Principles to Conversational Agents', 'authors': 'Sanjay Krishna Anbalagan, Xinrui Nie, Umesh Mohan, Vijay Kumar Kanamarlapudi, Anughna Kommalapati, Xiaodan Zhao', 'link': 'https://arxiv.org/abs/2507.01862', 'abstract': 'Domain specific chatbot applications often involve multi step interactions, such as refining search filters, selecting multiple items, or performing comparisons. Traditional graphical user interfaces (GUIs) handle these workflows by providing explicit "Submit" (commit data) and "Reset" (discard data) actions, allowing back-end systems to track user intent unambiguously. In contrast, conversational agents rely on subtle language cues, which can lead to confusion and incomplete context management. This paper proposes modeling these GUI inspired metaphors acknowledgment (submit like) and context switching (reset-like) as explicit tasks within large language model (LLM) prompts. By capturing user acknowledgment, reset actions, and chain of thought (CoT) reasoning as structured session data, we preserve clarity, reduce user confusion, and align domain-specific chatbot interactions with back-end logic. We demonstrate our approach in hotel booking and customer management scenarios, highlighting improvements in multi-turn task coherence, user satisfaction, and efficiency.', 'abstract_zh': '基于GUI启发的元模型在大型语言模型中建模acknowledgment和context switching以优化域特定聊天机器人交互', 'title_zh': 'UI设计与聊天机器人互动的桥梁：基于表单原则的应用于对话代理'}
{'arxiv_id': 'arXiv:2507.01806', 'title': 'LoRA Fine-Tuning Without GPUs: A CPU-Efficient Meta-Generation Framework for LLMs', 'authors': 'Reza Arabpour, Haitz Sáez de Ocáriz Borde, Anastasis Kratsios', 'link': 'https://arxiv.org/abs/2507.01806', 'abstract': 'Low-Rank Adapters (LoRAs) have transformed the fine-tuning of Large Language Models (LLMs) by enabling parameter-efficient updates. However, their widespread adoption remains limited by the reliance on GPU-based training. In this work, we propose a theoretically grounded approach to LoRA fine-tuning designed specifically for users with limited computational resources, particularly those restricted to standard laptop CPUs. Our method learns a meta-operator that maps any input dataset, represented as a probability distribution, to a set of LoRA weights by leveraging a large bank of pre-trained adapters for the Mistral-7B-Instruct-v0.2 model. Instead of performing new gradient-based updates, our pipeline constructs adapters via lightweight combinations of existing LoRAs directly on CPU. While the resulting adapters do not match the performance of GPU-trained counterparts, they consistently outperform the base Mistral model on downstream tasks, offering a practical and accessible alternative to traditional GPU-based fine-tuning.', 'abstract_zh': '基于理论支持的LoRA微调方法：针对有限计算资源用户的设计', 'title_zh': '无需GPU的LoRA微调：一种用于大语言模型的CPU高效元生成框架'}
{'arxiv_id': 'arXiv:2507.01786', 'title': 'Probing Evaluation Awareness of Language Models', 'authors': 'Jord Nguyen, Khiem Hoang, Carlo Leonardo Attubato, Felix Hofstätter', 'link': 'https://arxiv.org/abs/2507.01786', 'abstract': 'Language models can distinguish between testing and deployment phases -- a capability known as evaluation awareness. This has significant safety and policy implications, potentially undermining the reliability of evaluations that are central to AI governance frameworks and voluntary industry commitments. In this paper, we study evaluation awareness in Llama-3.3-70B-Instruct. We show that linear probes can separate real-world evaluation and deployment prompts, suggesting that current models internally represent this distinction. We also find that current safety evaluations are correctly classified by the probes, suggesting that they already appear artificial or inauthentic to models. Our findings underscore the importance of ensuring trustworthy evaluations and understanding deceptive capabilities. More broadly, our work showcases how model internals may be leveraged to support blackbox methods in safety audits, especially for future models more competent at evaluation awareness and deception.', 'abstract_zh': '语言模型能够区分测试阶段和部署阶段——这一能力称为评估意识。这在安全性和政策层面具有重要影响，可能损害与人工智能治理框架和自愿行业承诺密切相关的关键评估的可靠性。在本文中，我们研究了评估意识在Llama-3.3-70B-Instruct中的表现。我们显示线性探针能够区分真实世界的评估和部署提示，表明当前模型内部代表了这种区分。我们还发现当前的安全评估已被探针正确分类，表明它们已经显得人工或不真实。我们的发现强调了确保可靠评估和理解欺骗性能力的重要性。更广泛而言，我们的研究展示了模型内部机制如何被利用来支持安全性审核中的黑盒方法，特别是对于未来在评估意识和欺骗方面更为熟练的模型。', 'title_zh': '探究语言模型的评价意识'}
{'arxiv_id': 'arXiv:2507.01785', 'title': 'MuRating: A High Quality Data Selecting Approach to Multilingual Large Language Model Pretraining', 'authors': 'Zhixun Chen, Ping Guo, Wenhan Han, Yifan Zhang, Binbin Liu, Haobin Lin, Fengze Liu, Yan Zhao, Bingni Zhang, Taifeng Wang, Yin Zheng, Meng Fang', 'link': 'https://arxiv.org/abs/2507.01785', 'abstract': 'Data quality is a critical driver of large language model performance, yet existing model-based selection methods focus almost exclusively on English. We introduce MuRating, a scalable framework that transfers high-quality English data-quality signals into a single rater for 17 target languages. MuRating aggregates multiple English "raters" via pairwise comparisons to learn unified document-quality scores,then projects these judgments through translation to train a multilingual evaluator on monolingual, cross-lingual, and parallel text pairs. Applied to web data, MuRating selects balanced subsets of English and multilingual content to pretrain a 1.2 B-parameter LLaMA model. Compared to strong baselines, including QuRater, AskLLM, DCLM and so on, our approach boosts average accuracy on both English benchmarks and multilingual evaluations, with especially large gains on knowledge-intensive tasks. We further analyze translation fidelity, selection biases, and underrepresentation of narrative material, outlining directions for future work.', 'abstract_zh': 'MuRating：将高质量英语数据质量信号转换为17种目标语言的单 raters 评定框架', 'title_zh': 'MuRating: 一种高质量多语言大型语言模型预训练数据选择方法'}
{'arxiv_id': 'arXiv:2507.01752', 'title': 'Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training', 'authors': 'Ismail Labiad, Mathurin Videau, Matthieu Kowalski, Marc Schoenauer, Alessandro Leite, Julia Kempe, Olivier Teytaud', 'link': 'https://arxiv.org/abs/2507.01752', 'abstract': 'Gradient-based optimization is the workhorse of deep learning, offering efficient and scalable training via backpropagation. However, its reliance on large volumes of labeled data raises privacy and security concerns such as susceptibility to data poisoning attacks and the risk of overfitting. In contrast, black box optimization methods, which treat the model as an opaque function, relying solely on function evaluations to guide optimization, offer a promising alternative in scenarios where data access is restricted, adversarial risks are high, or overfitting is a concern. However, black box methods also pose significant challenges, including poor scalability to high-dimensional parameter spaces, as prevalent in large language models (LLMs), and high computational costs due to reliance on numerous model evaluations. This paper introduces BBoxER, an evolutionary black-box method for LLM post-training that induces an information bottleneck via implicit compression of the training data. Leveraging the tractability of information flow, we provide strong theoretical bounds on generalization, differential privacy, susceptibility to data poisoning attacks, and robustness to extraction attacks. BBoxER operates on top of pre-trained LLMs, offering a lightweight and modular enhancement suitable for deployment in restricted or privacy-sensitive environments, in addition to non-vacuous generalization guarantees. In experiments with LLMs, we demonstrate empirically that Retrofitting methods are able to learn, showing how a few iterations of BBoxER improve performance and generalize well on a benchmark of reasoning datasets. This positions BBoxER as an attractive add-on on top of gradient-based optimization.', 'abstract_zh': '基于梯度的优化是深度学习的基石，通过反向传播提供高效且可扩展的训练。然而，其对大量标注数据的依赖引发了隐私和安全方面的关切，如数据投毒攻击的易感性和过拟合风险。相比之下，黑箱优化方法将模型视为不透明函数，仅依靠函数评估来指导优化，在数据访问受限、敌对风险高或存在过拟合的情况下，提供了有前景的替代方案。然而，黑箱方法也面临着重大挑战，包括在大规模参数空间中的可扩展性差，以及因依赖多次模型评估而导致的高计算成本。本文介绍了BBoxER，一种用于大规模语言模型（LLMs）后训练的进化黑箱方法，通过隐式压缩训练数据来诱导信息瓶颈。利用信息流的可处理性，我们提供了泛化、差分隐私、数据投毒攻击易感性以及提取攻击抗性的强大理论界。BBoxER 基建在预训练的 LLMs 上，提供了一种轻量级且模块化的增强功能，适用于受限或隐私敏感环境，并提供非真空的泛化保证。在大规模语言模型的实验中，我们实证展示了重塑方法能够学习，并展示了 BBoxER 几轮迭代如何改善性能并在推理数据集基准上很好地泛化。这使 BBoxER 成为了基于梯度优化的一种有吸引力的附加选项。', 'title_zh': '无窥探调整：LLM 剪枝后训练可证明的隐私和泛化边界'}
{'arxiv_id': 'arXiv:2507.01702', 'title': 'AdamMeme: Adaptively Probe the Reasoning Capacity of Multimodal Large Language Models on Harmfulness', 'authors': 'Zixin Chen, Hongzhan Lin, Kaixin Li, Ziyang Luo, Zhen Ye, Guang Chen, Zhiyong Huang, Jing Ma', 'link': 'https://arxiv.org/abs/2507.01702', 'abstract': 'The proliferation of multimodal memes in the social media era demands that multimodal Large Language Models (mLLMs) effectively understand meme harmfulness. Existing benchmarks for assessing mLLMs on harmful meme understanding rely on accuracy-based, model-agnostic evaluations using static datasets. These benchmarks are limited in their ability to provide up-to-date and thorough assessments, as online memes evolve dynamically. To address this, we propose AdamMeme, a flexible, agent-based evaluation framework that adaptively probes the reasoning capabilities of mLLMs in deciphering meme harmfulness. Through multi-agent collaboration, AdamMeme provides comprehensive evaluations by iteratively updating the meme data with challenging samples, thereby exposing specific limitations in how mLLMs interpret harmfulness. Extensive experiments show that our framework systematically reveals the varying performance of different target mLLMs, offering in-depth, fine-grained analyses of model-specific weaknesses. Our code is available at this https URL.', 'abstract_zh': '社交媒体时代多模态 meme 的流行要求多模态大型语言模型 (mLLMs) 有效地理解 meme 的危害性。现有的评估 mLLMs 在理解有害 meme 方面的基准依赖于基于准确性的、模型无关的评估，使用静态数据集。这些基准在提供最新的全面评估方面有限制，因为在线 meme 演变动态。为了解决这一问题，我们提出 AdamMeme，一个灵活的、基于代理的评估框架，能够适应性地探查 mLLMs 在解读 meme 危害性方面的推理能力。通过多代理协作，AdamMeme 提供了全面的评估，通过迭代更新具有挑战性的 meme 数据，从而揭示 mLLMs 在解读危害性方面的特定局限性。广泛实验表明，我们的框架系统地揭示了不同目标 mLLMs 的不同表现，提供对模型特定缺点的深入、精细分析。我们的代码可在以下网址获取：这个 https URL。', 'title_zh': 'AdamMeme: 自适应探究多模态大型语言模型的有害性推理能力'}
{'arxiv_id': 'arXiv:2507.01701', 'title': 'Exploring Advanced LLM Multi-Agent Systems Based on Blackboard Architecture', 'authors': 'Bochen Han, Songmao Zhang', 'link': 'https://arxiv.org/abs/2507.01701', 'abstract': "In this paper, we propose to incorporate the blackboard architecture into LLM multi-agent systems (MASs) so that (1) agents with various roles can share all the information and others' messages during the whole problem-solving process, (2) agents that will take actions are selected based on the current content of the blackboard, and (3) the selection and execution round is repeated until a consensus is reached on the blackboard. We develop the first implementation of this proposal and conduct experiments on commonsense knowledge, reasoning and mathematical datasets. The results show that our system can be competitive with the SOTA static and dynamic MASs by achieving the best average performance, and at the same time manage to spend less tokens. Our proposal has the potential to enable complex and dynamic problem-solving where well-defined structures or workflows are unavailable.", 'abstract_zh': '在本文中，我们提出将黑板架构整合到LLM多智能体系统（MASs）中，以便（1）所有角色的智能体在整个问题解决过程中可以共享所有信息和他人的消息，（2）根据黑板上的当前内容选择将要采取行动的智能体，（3）选择和执行循环直至在黑板上达成共识。我们开发了此提案的第一个实现，并在常识知识、推理和数学数据集中进行了实验。结果表明，我们的系统在平均性能上可以与领先的静态和动态MASs竞争，并且能够使用更少的令牌。我们的提案有可能在缺少明确结构或工作流程的情况下实现复杂且动态的问题解决。', 'title_zh': '基于黑板架构探索高级LLM多agent系统'}
{'arxiv_id': 'arXiv:2507.01693', 'title': 'GPT, But Backwards: Exactly Inverting Language Model Outputs', 'authors': 'Adrians Skapars, Edoardo Manino, Youcheng Sun, Lucas C. Cordeiro', 'link': 'https://arxiv.org/abs/2507.01693', 'abstract': 'While existing auditing techniques attempt to identify potential unwanted behaviours in large language models (LLMs), we address the complementary forensic problem of reconstructing the exact input that led to an existing LLM output - enabling post-incident analysis and potentially the detection of fake output reports. We formalize exact input reconstruction as a discrete optimisation problem with a unique global minimum and introduce SODA, an efficient gradient-based algorithm that operates on a continuous relaxation of the input search space with periodic restarts and parameter decay. Through comprehensive experiments on LLMs ranging in size from 33M to 3B parameters, we demonstrate that SODA significantly outperforms existing approaches. We succeed in fully recovering 79.5% of shorter out-of-distribution inputs from next-token logits, without a single false positive, but struggle to extract private information from the outputs of longer (15+ token) input sequences. This suggests that standard deployment practices may currently provide adequate protection against malicious use of our method. Our code is available at this https URL.', 'abstract_zh': '现有的审计技术试图在大规模语言模型（LLMs）中识别潜在的不良行为，而我们则针对这一问题的互补方面——即重建导致现有LLM输出的精确输入，从而实现事后分析并可能检测假输出报告进行研究。我们将精确输入重建形式化为一个具有唯一全局最小值的离散优化问题，并引入SODA，一种基于梯度的有效算法，该算法在输入搜索空间的连续松弛上运行，并定期重启和参数衰减。通过针对从33M到3B参数不等的LLM进行全面实验，我们证明了SODA显著优于现有方法。我们成功从下一个 Tokens 的 logit 中恢复了 79.5% 的较短的 distribution 外输入，且没有单一的误报，但对于更长（15 个以上 Token）的输入序列，我们难以从其输出中提取隐私信息。这表明当前的标准部署实践可能已提供足够的保护以防止对我们方法的恶意使用。我们的代码可在以下链接获取。', 'title_zh': 'GPT，但反着来：精确反转语言模型输出'}
{'arxiv_id': 'arXiv:2507.01679', 'title': 'Blending Supervised and Reinforcement Fine-Tuning with Prefix Sampling', 'authors': 'Zeyu Huang, Tianhao Cheng, Zihan Qiu, Zili Wang, Yinghui Xu, Edoardo M. Ponti, Ivan Titov', 'link': 'https://arxiv.org/abs/2507.01679', 'abstract': "Existing post-training techniques for large language models are broadly categorized into Supervised Fine-Tuning (SFT) and Reinforcement Fine-Tuning (RFT). Each paradigm presents a distinct trade-off: SFT excels at mimicking demonstration data but can lead to problematic generalization as a form of behavior cloning. Conversely, RFT can significantly enhance a model's performance but is prone to learn unexpected behaviors, and its performance is highly sensitive to the initial policy. In this paper, we propose a unified view of these methods and introduce Prefix-RFT, a hybrid approach that synergizes learning from both demonstration and exploration. Using mathematical reasoning problems as a testbed, we empirically demonstrate that Prefix-RFT is both simple and effective. It not only surpasses the performance of standalone SFT and RFT but also outperforms parallel mixed-policy RFT methods. A key advantage is its seamless integration into existing open-source frameworks, requiring only minimal modifications to the standard RFT pipeline. Our analysis highlights the complementary nature of SFT and RFT, and validates that Prefix-RFT effectively harmonizes these two learning paradigms. Furthermore, ablation studies confirm the method's robustness to variations in the quality and quantity of demonstration data. We hope this work offers a new perspective on LLM post-training, suggesting that a unified paradigm that judiciously integrates demonstration and exploration could be a promising direction for future research.", 'abstract_zh': '现有的大型语言模型后训练技术通常被归类为监督微调（SFT）和强化微调（RFT）。每种范式都存在独特的权衡：SFT在模拟示范数据方面表现出色，但可能导致行为克隆形式的问题性泛化。相反，RFT能够显著提升模型性能，但也容易学习到意外行为，其性能对初始策略高度敏感。在本文中，我们提出了一种统一的观点，并引入了Prefix-RFT，这是一种结合示范学习和探索学习的混合方法。通过使用数学推理问题作为实验平台，我们实证证明了Prefix-RFT简洁且有效。它不仅超越了单独的SFT和RFT性能，还优于并行混合策略的RFT方法。一个关键优势在于它能够无缝集成到现有的开源框架中，只需对标准RFT管道进行少量修改。我们的分析突显了SFT和RFT的互补性，并验证了Prefix-RFT有效地整合了这两种学习范式。此外，消融研究确认了该方法对示范数据质量与数量变化的稳健性。我们认为这项工作为大型语言模型后训练提供了一个新的视角，建议一个谨慎整合示范和探索的统一范式可能是未来研究的有希望方向。', 'title_zh': '监督微调与强化学习微调结合的前缀采样方法'}
{'arxiv_id': 'arXiv:2507.01663', 'title': 'AsyncFlow: An Asynchronous Streaming RL Framework for Efficient LLM Post-Training', 'authors': 'Zhenyu Han, Ansheng You, Haibo Wang, Kui Luo, Guang Yang, Wenqi Shi, Menglong Chen, Sicheng Zhang, Zeshun Lan, Chunshi Deng, Huazhong Ji, Wenjie Liu, Yu Huang, Yixiang Zhang, Chenyi Pan, Jing Wang, Xin Huang, Chunsheng Li, Jianping Wu', 'link': 'https://arxiv.org/abs/2507.01663', 'abstract': 'Reinforcement learning (RL) has become a pivotal technology in the post-training phase of large language models (LLMs). Traditional task-colocated RL frameworks suffer from significant scalability bottlenecks, while task-separated RL frameworks face challenges in complex dataflows and the corresponding resource idling and workload imbalance. Moreover, most existing frameworks are tightly coupled with LLM training or inference engines, making it difficult to support custom-designed engines. To address these challenges, we propose AsyncFlow, an asynchronous streaming RL framework for efficient post-training. Specifically, we introduce a distributed data storage and transfer module that provides a unified data management and fine-grained scheduling capability in a fully streamed manner. This architecture inherently facilitates automated pipeline overlapping among RL tasks and dynamic load balancing. Moreover, we propose a producer-consumer-based asynchronous workflow engineered to minimize computational idleness by strategically deferring parameter update process within staleness thresholds. Finally, the core capability of AsynFlow is architecturally decoupled from underlying training and inference engines and encapsulated by service-oriented user interfaces, offering a modular and customizable user experience. Extensive experiments demonstrate an average of 1.59 throughput improvement compared with state-of-the-art baseline. The presented architecture in this work provides actionable insights for next-generation RL training system designs.', 'abstract_zh': '异步流：用于高效后训练的强化学习框架', 'title_zh': 'AsyncFlow：一种用于高效大语言模型后训练的异步流式RL框架'}
{'arxiv_id': 'arXiv:2507.01599', 'title': 'Data Agent: A Holistic Architecture for Orchestrating Data+AI Ecosystems', 'authors': 'Zhaoyan Sun, Jiayi Wang, Xinyang Zhao, Jiachi Wang, Guoliang Li', 'link': 'https://arxiv.org/abs/2507.01599', 'abstract': "Traditional Data+AI systems utilize data-driven techniques to optimize performance, but they rely heavily on human experts to orchestrate system pipelines, enabling them to adapt to changes in data, queries, tasks, and environments. For instance, while there are numerous data science tools available, developing a pipeline planning system to coordinate these tools remains challenging. This difficulty arises because existing Data+AI systems have limited capabilities in semantic understanding, reasoning, and planning. Fortunately, we have witnessed the success of large language models (LLMs) in enhancing semantic understanding, reasoning, and planning abilities. It is crucial to incorporate LLM techniques to revolutionize data systems for orchestrating Data+AI applications effectively.\nTo achieve this, we propose the concept of a 'Data Agent' - a comprehensive architecture designed to orchestrate Data+AI ecosystems, which focuses on tackling data-related tasks by integrating knowledge comprehension, reasoning, and planning capabilities. We delve into the challenges involved in designing data agents, such as understanding data/queries/environments/tools, orchestrating pipelines/workflows, optimizing and executing pipelines, and fostering pipeline self-reflection. Furthermore, we present examples of data agent systems, including a data science agent, data analytics agents (such as unstructured data analytics agent, semantic structured data analytics agent, data lake analytics agent, and multi-modal data analytics agent), and a database administrator (DBA) agent. We also outline several open challenges associated with designing data agent systems.", 'abstract_zh': '传统数据+AI系统利用数据驱动的技术优化性能，但它们高度依赖人力专家来协调系统管道，使其能够适应数据、查询、任务和环境的变化。例如，在众多数据科学工具中，开发一个协调这些工具的管道规划系统仍然极具挑战性。这一困难源于现有数据+AI系统在语义理解、推理和规划方面的能力有限。幸运的是，我们见证了大型语言模型（LLMs）在增强这些能力方面的成功。将LLM技术整合到数据系统中，对于有效协调数据+AI应用程序至关重要。\n\n为此，我们提出了“数据代理”的概念——一种全面架构，旨在通过整合知识理解、推理和规划能力来协调数据+AI生态系统，专注于处理与数据相关的任务。我们探讨了设计数据代理所面临的挑战，包括理解数据/查询/环境/工具、协调管道/工作流、优化和执行管道以及促进管道自我反思。此外，我们介绍了数据代理系统的示例，包括数据科学代理、数据剖析代理（如非结构化数据剖析代理、语义结构化数据剖析代理、数据湖剖析代理和多模态数据剖析代理）以及数据库管理员（DBA）代理。我们还概述了设计数据代理系统所面临的若干开放挑战。', 'title_zh': '数据代理： orchestrating 数据+AI 生态系统的综合性架构'}
{'arxiv_id': 'arXiv:2507.01551', 'title': 'Self-Guided Process Reward Optimization with Masked Step Advantage for Process Reinforcement Learning', 'authors': 'Wu Fei, Hao Kong, Shuxian Liang, Yang Lin, Yibo Yang, Jing Tang, Lei Chen, Xiansheng Hua', 'link': 'https://arxiv.org/abs/2507.01551', 'abstract': 'Process Reinforcement Learning~(PRL) has demonstrated considerable potential in enhancing the reasoning capabilities of Large Language Models~(LLMs). However, introducing additional process reward models incurs substantial computational overhead, and there is no unified theoretical framework for process-level advantage estimation. To bridge this gap, we propose \\textbf{S}elf-Guided \\textbf{P}rocess \\textbf{R}eward \\textbf{O}ptimization~(\\textbf{SPRO}), a novel framework that enables process-aware RL through two key innovations: (1) we first theoretically demonstrate that process rewards can be derived intrinsically from the policy model itself, and (2) we introduce well-defined cumulative process rewards and \\textbf{M}asked \\textbf{S}tep \\textbf{A}dvantage (\\textbf{MSA}), which facilitates rigorous step-wise action advantage estimation within shared-prompt sampling groups. Our experimental results demonstrate that SPRO outperforms vaniila GRPO with 3.4x higher training efficiency and a 17.5\\% test accuracy improvement. Furthermore, SPRO maintains a stable and elevated policy entropy throughout training while reducing the average response length by approximately $1/3$, evidencing sufficient exploration and prevention of reward hacking. Notably, SPRO incurs no additional computational overhead compared to outcome-supervised RL methods such as GRPO, which benefit industrial implementation.', 'abstract_zh': 'Self-Guided Process Reward Optimization (SPRO)', 'title_zh': '自引导过程奖励优化与掩码步骤优势的过程强化学习'}
{'arxiv_id': 'arXiv:2507.01548', 'title': 'Crafting Hanzi as Narrative Bridges: An AI Co-Creation Workshop for Elderly Migrants', 'authors': 'Wen Zhan, Ziqun Hua, Peiyue Lin, Yunfei Chen', 'link': 'https://arxiv.org/abs/2507.01548', 'abstract': 'This paper explores how older adults, particularly aging migrants in urban China, can engage AI-assisted co-creation to express personal narratives that are often fragmented, underrepresented, or difficult to verbalize. Through a pilot workshop combining oral storytelling and the symbolic reconstruction of Hanzi, participants shared memories of migration and recreated new character forms using Xiaozhuan glyphs, suggested by the Large Language Model (LLM), together with physical materials. Supported by human facilitation and a soft AI presence, participants transformed lived experience into visual and tactile expressions without requiring digital literacy. This approach offers new perspectives on human-AI collaboration and aging by repositioning AI not as a content producer but as a supportive mechanism, and by supporting narrative agency within sociotechnical systems.', 'abstract_zh': '本研究探讨了老年人，特别是城市中国中的老化移民，如何通过AI辅助共创表达那些常常碎片化、代表性不足或难以用语言表达的个人叙事。通过结合口头讲述和汉字符号重构的试点研讨会，参与者分享了迁移记忆，并与大型语言模型（LLM）建议的 Xiaozhuan 符号一起，使用物理材料重新创造新的汉字形式。在人性化的引导和支持性人工智能的辅助下，参与者将生活经验转化为可视和触觉表达，无需具备数字素养。该方法为人类与人工智能的合作以及老龄化提供了新的视角，重新定位了人工智能的角色，不再将其视为内容生产者，而是支持机制，并在社会技术系统中支持叙事自主权。', 'title_zh': '匠心绘制汉字桥梁：一场为老年移民设计的AI共创工作坊'}
{'arxiv_id': 'arXiv:2507.01479', 'title': 'Evaluating the Effectiveness of Direct Preference Optimization for Personalizing German Automatic Text Simplifications for Persons with Intellectual Disabilities', 'authors': 'Yingqiang Gao, Kaede Johnson, David Froehlich, Luisa Carrer, Sarah Ebling', 'link': 'https://arxiv.org/abs/2507.01479', 'abstract': 'Automatic text simplification (ATS) aims to enhance language accessibility for various target groups, particularly persons with intellectual disabilities. Recent advancements in generative AI, especially large language models (LLMs), have substantially improved the quality of machine-generated text simplifications, thereby mitigating information barriers for the target group. However, existing LLM-based ATS systems do not incorporate preference feedback on text simplifications during training, resulting in a lack of personalization tailored to the specific needs of target group representatives.\nIn this work, we extend the standard supervised fine-tuning (SFT) approach for adapting LLM-based ATS models by leveraging a computationally efficient LLM alignment technique -- direct preference optimization (DPO). Specifically, we post-train LLM-based ATS models using human feedback collected from persons with intellectual disabilities, reflecting their preferences on paired text simplifications generated by mainstream LLMs. Furthermore, we propose a pipeline for developing personalized LLM-based ATS systems, encompassing data collection, model selection, SFT and DPO post-training, and evaluation. Our findings underscore the necessity of active participation of target group persons in designing personalized AI accessibility solutions aligned with human expectations. This work represents a step towards personalizing inclusive AI systems at the target-group level, incorporating insights not only from text simplification experts but also from target group persons themselves.', 'abstract_zh': '自动文本简化（ATS）旨在提高语言可访问性，特别是对智力障碍人群。近期生成式AI的进展，尤其是大规模语言模型（LLMs），显著提高了机器生成文本简化的质量，从而减轻了目标群体的信息障碍。然而，现有的基于LLM的ATS系统在训练过程中并未纳入对文本简化的偏好反馈，导致缺乏针对目标群体代表特定需求的个性化设置。\n在此工作中，我们通过利用一种计算效率高的LLM对齐技术——直接偏好优化（DPO），扩展了标准的监督微调（SFT）方法，以适应基于LLM的ATS模型。具体而言，我们使用来自智力障碍人群的反馈对基于LLM的ATS模型进行后续训练，反映了他们在主流LLM生成的配对文本简化方面的偏好。此外，我们提出了一个开发个性化LLM基ATS系统的流水线，包括数据收集、模型选择、SFT和DPO后续训练以及评估。我们的研究结果强调了目标群体人员在设计与人类期望相一致的个性化AI无障碍解决方案中的积极参与的重要性。这项工作为在目标群体层面个性化包容性AI系统迈出了一步，不仅借鉴了文本简化专家的见解，也纳入了目标群体自身的见解。', 'title_zh': '直接偏好优化对个性化德国自动文本简化的有效性评估'}
{'arxiv_id': 'arXiv:2507.01438', 'title': 'EdgeLoRA: An Efficient Multi-Tenant LLM Serving System on Edge Devices', 'authors': 'Zheyu Shen, Yexiao He, Ziyao Wang, Yuning Zhang, Guoheng Sun, Wanghao Ye, Ang Li', 'link': 'https://arxiv.org/abs/2507.01438', 'abstract': "Large Language Models (LLMs) have gained significant attention due to their versatility across a wide array of applications. Fine-tuning LLMs with parameter-efficient adapters, such as Low-Rank Adaptation (LoRA), enables these models to efficiently adapt to downstream tasks without extensive retraining. Deploying fine-tuned LLMs on multi-tenant edge devices offers substantial benefits, such as reduced latency, enhanced privacy, and personalized responses. However, serving LLMs efficiently on resource-constrained edge devices presents critical challenges, including the complexity of adapter selection for different tasks and memory overhead from frequent adapter swapping. Moreover, given the multiple requests in multi-tenant settings, processing requests sequentially results in underutilization of computational resources and increased latency. This paper introduces EdgeLoRA, an efficient system for serving LLMs on edge devices in multi-tenant environments. EdgeLoRA incorporates three key innovations: (1) an adaptive adapter selection mechanism to streamline the adapter configuration process; (2) heterogeneous memory management, leveraging intelligent adapter caching and pooling to mitigate memory operation overhead; and (3) batch LoRA inference, enabling efficient batch processing to significantly reduce computational latency. Comprehensive evaluations using the Llama3.1-8B model demonstrate that EdgeLoRA significantly outperforms the status quo (i.e., this http URL) in terms of both latency and throughput. The results demonstrate that EdgeLoRA can achieve up to a 4 times boost in throughput. Even more impressively, it can serve several orders of magnitude more adapters simultaneously. These results highlight EdgeLoRA's potential to transform edge deployment of LLMs in multi-tenant scenarios, offering a scalable and efficient solution for resource-constrained environments.", 'abstract_zh': 'Large Language模型（LLMs）由于其在多种应用中的 versatility 获得了广泛关注。通过参数高效适配器如 Low-Rank Adaptation (LoRA) 对 LLMs 进行微调，使得这些模型能够高效适应下游任务而无需大量重新训练。在多租户边缘设备上部署微调后的 LLMs 提供了显著优势，如降低延迟、增强隐私和个性化响应。然而，在资源受限的边缘设备上高效提供 LLMs 也带来了一些关键挑战，包括不同任务适配器选择的复杂性和频繁适配器切换带来的内存开销。此外，在多租户环境中，由于需要依次处理多个请求，这会导致计算资源的利用率降低和延迟增加。本文介绍了 EdgeLoRA，这是一种用于多租户环境中边缘设备上提供 LLMs 的高效系统。EdgeLoRA 包含三个关键创新：（1）一种自适应适配器选择机制，以简化适配器配置过程；（2）异构内存管理，利用智能适配器缓存和池化来减少内存操作开销；（3）批量 LoRA 推理，使得批量处理能够显著减少计算延迟。使用 Llama3.1-8B 模型进行全面评估表明，EdgeLoRA 在延迟和吞吐量方面显著优于现状。结果表明，EdgeLoRA 可以实现多达 4 倍的吞吐量提升。更令人印象深刻的是，它可以同时服务多个数量级的适配器。这些结果突显了 EdgeLoRA 在多租户场景下边缘部署 LLMs 的潜在能力，为资源受限环境提供了可扩展且高效的解决方案。', 'title_zh': 'EdgeLoRA：边缘设备上的高效多租户LLM服务系统'}
{'arxiv_id': 'arXiv:2507.01413', 'title': 'Evaluating LLM Agent Collusion in Double Auctions', 'authors': 'Kushal Agrawal, Verona Teo, Juan J. Vazquez, Sudarsh Kunnavakkam, Vishak Srikanth, Andy Liu', 'link': 'https://arxiv.org/abs/2507.01413', 'abstract': 'Large language models (LLMs) have demonstrated impressive capabilities as autonomous agents with rapidly expanding applications in various domains. As these agents increasingly engage in socioeconomic interactions, identifying their potential for undesirable behavior becomes essential. In this work, we examine scenarios where they can choose to collude, defined as secretive cooperation that harms another party. To systematically study this, we investigate the behavior of LLM agents acting as sellers in simulated continuous double auction markets. Through a series of controlled experiments, we analyze how parameters such as the ability to communicate, choice of model, and presence of environmental pressures affect the stability and emergence of seller collusion. We find that direct seller communication increases collusive tendencies, the propensity to collude varies across models, and environmental pressures, such as oversight and urgency from authority figures, influence collusive behavior. Our findings highlight important economic and ethical considerations for the deployment of LLM-based market agents.', 'abstract_zh': '大规模语言模型（LLMs）在各种领域的应用日益广泛，展现了作为自主代理的强大能力。随着这些代理越来越多地参与经济和社会互动，识别其潜在的不良行为变得至关重要。在此工作中，我们研究了它们选择共谋的情况，共谋被定义为秘密的合作行为，对另一方造成伤害。为了系统地研究这一现象，我们调查了大规模语言模型代理作为卖家在模拟连续双拍卖市场中的行为。通过一系列受控实验，我们分析了直接卖家沟通能力、所选用模型以及环境压力等因素如何影响卖家共谋行为的稳定性和出现。我们发现，直接卖家沟通会增加共谋倾向，不同模型的共谋倾向存在差异，来自权威人物的监督和紧迫性等环境压力会影响共谋行为。我们的研究结果突显了大规模语言模型市场代理部署的重要经济和伦理考量。', 'title_zh': '评估LLM代理在双拍卖中的共谋行为'}
{'arxiv_id': 'arXiv:2507.01378', 'title': 'RALLY: Role-Adaptive LLM-Driven Yoked Navigation for Agentic UAV Swarms', 'authors': 'Ziyao Wang, Rongpeng Li, Sizhao Li, Yuming Xiang, Haiping Wang, Zhifeng Zhao, Honggang Zhang', 'link': 'https://arxiv.org/abs/2507.01378', 'abstract': 'Intelligent control of Unmanned Aerial Vehicles (UAVs) swarms has emerged as a critical research focus, and it typically requires the swarm to navigate effectively while avoiding obstacles and achieving continuous coverage over multiple mission targets. Although traditional Multi-Agent Reinforcement Learning (MARL) approaches offer dynamic adaptability, they are hindered by the semantic gap in numerical communication and the rigidity of homogeneous role structures, resulting in poor generalization and limited task scalability. Recent advances in Large Language Model (LLM)-based control frameworks demonstrate strong semantic reasoning capabilities by leveraging extensive prior knowledge. However, due to the lack of online learning and over-reliance on static priors, these works often struggle with effective exploration, leading to reduced individual potential and overall system performance. To address these limitations, we propose a Role-Adaptive LLM-Driven Yoked navigation algorithm RALLY. Specifically, we first develop an LLM-driven semantic decision framework that uses structured natural language for efficient semantic communication and collaborative reasoning. Afterward, we introduce a dynamic role-heterogeneity mechanism for adaptive role switching and personalized decision-making. Furthermore, we propose a Role-value Mixing Network (RMIX)-based assignment strategy that integrates LLM offline priors with MARL online policies to enable semi-offline training of role selection strategies. Experiments in the Multi-Agent Particle Environment (MPE) environment and a Software-In-The-Loop (SITL) platform demonstrate that RALLY outperforms conventional approaches in terms of task coverage, convergence speed, and generalization, highlighting its strong potential for collaborative navigation in agentic multi-UAV systems.', 'abstract_zh': '基于大语言模型的角色自适应联合导航算法RALLY：面向自主无人飞行器系统的协同导航', 'title_zh': 'RALLY：基于角色自适应大规模语言模型驱动的联动导航框架用于自主无人机集群'}
{'arxiv_id': 'arXiv:2507.01335', 'title': 'LEDOM: An Open and Fundamental Reverse Language Model', 'authors': 'Xunjian Yin, Sitao Cheng, Yuxi Xie, Xinyu Hu, Li Lin, Xinyi Wang, Liangming Pan, William Yang Wang, Xiaojun Wan', 'link': 'https://arxiv.org/abs/2507.01335', 'abstract': "We introduce LEDOM, the first purely reverse language model, trained autoregressively on 435B tokens with 2B and 7B parameter variants, which processes sequences in reverse temporal order through previous token prediction. For the first time, we present the reverse language model as a potential foundational model across general tasks, accompanied by a set of intriguing examples and insights. Based on LEDOM, we further introduce a novel application: Reverse Reward, where LEDOM-guided reranking of forward language model outputs leads to substantial performance improvements on mathematical reasoning tasks. This approach leverages LEDOM's unique backward reasoning capability to refine generation quality through posterior evaluation. Our findings suggest that LEDOM exhibits unique characteristics with broad application potential. We will release all models, training code, and pre-training data to facilitate future research.", 'abstract_zh': '我们介绍LEDOM，这是首个纯逆序语言模型，以自回归方式在435亿个tokens上训练，具有2B和7B参数变体，通过以前的tokens进行预测处理序列的逆时序。我们首次展示了逆序语言模型作为通用任务潜在的基石模型，并附带了一系列引人入胜的例子和见解。基于LEDOM，我们进一步介绍了一个新的应用：逆向奖励，通过LEDOM指导的正向语言模型输出的重排序，显著提高了数学推理任务的性能。这种方法利用了LEDOM独特的逆向推理能力，通过 posterior 评估来改进生成质量。我们的研究发现表明，LEDOM具有广泛的潜在应用特性。我们将发布所有模型、训练代码和预训练数据，以促进未来的研究。', 'title_zh': 'LEDOM：一个开源和基础的反向语言模型'}
{'arxiv_id': 'arXiv:2507.01321', 'title': 'ICLShield: Exploring and Mitigating In-Context Learning Backdoor Attacks', 'authors': 'Zhiyao Ren, Siyuan Liang, Aishan Liu, Dacheng Tao', 'link': 'https://arxiv.org/abs/2507.01321', 'abstract': 'In-context learning (ICL) has demonstrated remarkable success in large language models (LLMs) due to its adaptability and parameter-free nature. However, it also introduces a critical vulnerability to backdoor attacks, where adversaries can manipulate LLM behaviors by simply poisoning a few ICL demonstrations. In this paper, we propose, for the first time, the dual-learning hypothesis, which posits that LLMs simultaneously learn both the task-relevant latent concepts and backdoor latent concepts within poisoned demonstrations, jointly influencing the probability of model outputs. Through theoretical analysis, we derive an upper bound for ICL backdoor effects, revealing that the vulnerability is dominated by the concept preference ratio between the task and the backdoor. Motivated by these findings, we propose ICLShield, a defense mechanism that dynamically adjusts the concept preference ratio. Our method encourages LLMs to select clean demonstrations during the ICL phase by leveraging confidence and similarity scores, effectively mitigating susceptibility to backdoor attacks. Extensive experiments across multiple LLMs and tasks demonstrate that our method achieves state-of-the-art defense effectiveness, significantly outperforming existing approaches (+26.02% on average). Furthermore, our method exhibits exceptional adaptability and defensive performance even for closed-source models (e.g., GPT-4).', 'abstract_zh': '基于上下文学习(ICL)在大规模语言模型(LLM)中的双学习假设及其防御机制ICLShield', 'title_zh': 'ICLShield: 探索并缓解上下文学习后门攻击'}
{'arxiv_id': 'arXiv:2507.01281', 'title': 'Rethinking All Evidence: Enhancing Trustworthy Retrieval-Augmented Generation via Conflict-Driven Summarization', 'authors': 'Juan Chen, Baolong Bi, Wei Zhang, Jingyan Sui, Xiaofei Zhu, Yuanzhuo Wang, Lingrui Mei, Shenghua Liu', 'link': 'https://arxiv.org/abs/2507.01281', 'abstract': 'Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by integrating their parametric knowledge with external retrieved content. However, knowledge conflicts caused by internal inconsistencies or noisy retrieved content can severely undermine the generation reliability of RAG this http URL this work, we argue that LLMs should rethink all evidence, including both retrieved content and internal knowledge, before generating this http URL propose CARE-RAG (Conflict-Aware and Reliable Evidence for RAG), a novel framework that improves trustworthiness through Conflict-Driven Summarization of all available this http URL-RAG first derives parameter-aware evidence by comparing parameter records to identify diverse internal perspectives. It then refines retrieved evidences to produce context-aware evidence, removing irrelevant or misleading content. To detect and summarize conflicts, we distill a 3B LLaMA3.2 model to perform conflict-driven summarization, enabling reliable synthesis across multiple this http URL further ensure evaluation integrity, we introduce a QA Repair step to correct outdated or ambiguous benchmark this http URL on revised QA datasets with retrieval data show that CARE-RAG consistently outperforms strong RAG baselines, especially in scenarios with noisy or conflicting evidence.', 'abstract_zh': '检索增强生成（RAG）通过结合大型语言模型（LLMs）的参数化知识和外部检索内容来增强LLMs，然而，由内部不一致或噪声检索内容引起的知识冲突严重削弱了RAG的生成可靠性。在本文中，我们主张在生成之前，LLMs 应重新考虑所有证据，包括检索内容和内部知识。为此，我们提出了CARE-RAG（冲突感知和可靠的证据），一种通过冲突驱动总结所有可用证据的新框架，以提高可信度。CARE-RAG 首先通过比较参数记录来推导参数感知的证据，以识别不同的内部视角。然后，它细化检索证据以产生上下文感知的证据，删除无关或误导性的内容。为了检测和总结冲突，我们将一个3B LLaMA3.2模型蒸馏以执行冲突驱动的总结，从而实现多个来源之间的可靠合成。为了进一步确保评估的完整性，我们引入了一步步法问答修复步骤来纠正过时或含糊不清的基准。在使用检索数据修订的QA数据集上进行评估显示，CARE-RAG 在有噪声或冲突证据的场景中始终优于强大的RAG基线。', 'title_zh': '重思所有证据：通过冲突驱动的总结增强可信赖的检索增强生成'}
{'arxiv_id': 'arXiv:2507.01274', 'title': 'AI Meets Maritime Training: Precision Analytics for Enhanced Safety and Performance', 'authors': 'Vishakha Lall, Yisi Liu', 'link': 'https://arxiv.org/abs/2507.01274', 'abstract': 'Traditional simulator-based training for maritime professionals is critical for ensuring safety at sea but often depends on subjective trainer assessments of technical skills, behavioral focus, communication, and body language, posing challenges such as subjectivity, difficulty in measuring key features, and cognitive limitations. Addressing these issues, this study develops an AI-driven framework to enhance maritime training by objectively assessing trainee performance through visual focus tracking, speech recognition, and stress detection, improving readiness for high-risk scenarios. The system integrates AI techniques, including visual focus determination using eye tracking, pupil dilation analysis, and computer vision; communication analysis through a maritime-specific speech-to-text model and natural language processing; communication correctness using large language models; and mental stress detection via vocal pitch. Models were evaluated on data from simulated maritime scenarios with seafarers exposed to controlled high-stress events. The AI algorithms achieved high accuracy, with ~92% for visual detection, ~91% for maritime speech recognition, and ~90% for stress detection, surpassing existing benchmarks. The system provides insights into visual attention, adherence to communication checklists, and stress levels under demanding conditions. This study demonstrates how AI can transform maritime training by delivering objective performance analytics, enabling personalized feedback, and improving preparedness for real-world operational challenges.', 'abstract_zh': '基于AI的框架增强 Maritime 专业人员培训：通过视觉焦点跟踪、语音识别和压力检测实现客观性能评估', 'title_zh': 'AI融入海上培训：精准分析以提高安全性和 performance'}
{'arxiv_id': 'arXiv:2507.01271', 'title': 'PULSE: Practical Evaluation Scenarios for Large Multimodal Model Unlearning', 'authors': 'Tatsuki Kawakami, Kazuki Egashira, Atsuyuki Miyai, Go Irie, Kiyoharu Aizawa', 'link': 'https://arxiv.org/abs/2507.01271', 'abstract': 'In recent years, unlearning techniques, which are methods for inducing a model to "forget" previously learned information, have attracted attention as a way to address privacy and copyright concerns in large language models (LLMs) and large multimodal models (LMMs). While several unlearning benchmarks have been established for LLMs, a practical evaluation framework for unlearning in LMMs has been less explored. Specifically, existing unlearning benchmark for LMMs considers only scenarios in which the model is required to unlearn fine-tuned knowledge through a single unlearning operation. In this study, we introduce PULSE protocol for realistic unlearning scenarios for LMMs by introducing two critical perspectives: (i) Pre-trained knowledge Unlearning for analyzing the effect across different knowledge acquisition phases and (ii) Long-term Sustainability Evaluation to address sequential requests. We then evaluate existing unlearning methods along these dimensions. Our results reveal that, although some techniques can successfully unlearn knowledge acquired through fine-tuning, they struggle to eliminate information learned during pre-training. Moreover, methods that effectively unlearn a batch of target data in a single operation exhibit substantial performance degradation when the same data are split and unlearned sequentially.', 'abstract_zh': '近年来，去学习技术（即使模型“忘记”先前学习信息的方法）逐渐受到关注，作为解决大型语言模型（LLMs）和大型多模态模型（LMMs）中的隐私和版权问题的手段。虽然为LLMs建立了一些去学习基准，但关于LMMs的实用去学习评估框架的研究较少。具体而言，现有的LMMs去学习基准仅考虑了模型通过单次去学习操作遗忘细调知识的情况。在本研究中，我们通过引入两个关键视角，提出了PULSE协议，以解决LMMs的现实去学习场景：（i）预训练知识去学习，分析不同知识获取阶段的影响；（ii）长期可持续性评估，应对顺序请求。我们随后从这些维度评估现有去学习方法。结果显示，虽然一些技术能够成功地去学习通过细调获得的知识，但在单次操作中去学习预训练期间学习的信息却遇到困难。此外，能够在单次操作中有效去学习目标数据批的方法，在数据被拆分并顺序去学习时，会表现出显著的性能下降。', 'title_zh': 'PULSE: 实用的大型多模态模型抹除评估场景'}
{'arxiv_id': 'arXiv:2507.01259', 'title': 'GAIus: Combining Genai with Legal Clauses Retrieval for Knowledge-based Assistant', 'authors': 'Michał Matak, Jarosław A. Chudziak', 'link': 'https://arxiv.org/abs/2507.01259', 'abstract': 'In this paper we discuss the capability of large language models to base their answer and provide proper references when dealing with legal matters of non-english and non-chinese speaking country. We discuss the history of legal information retrieval, the difference between case law and statute law, its impact on the legal tasks and analyze the latest research in this field. Basing on that background we introduce gAIus, the architecture of the cognitive LLM-based agent, whose responses are based on the knowledge retrieved from certain legal act, which is Polish Civil Code. We propose a retrieval mechanism which is more explainable, human-friendly and achieves better results than embedding-based approaches. To evaluate our method we create special dataset based on single-choice questions from entrance exams for law apprenticeships conducted in Poland. The proposed architecture critically leveraged the abilities of used large language models, improving the gpt-3.5-turbo-0125 by 419%, allowing it to beat gpt-4o and lifting gpt-4o-mini score from 31% to 86%. At the end of our paper we show the possible future path of research and potential applications of our findings.', 'abstract_zh': '本文探讨了大型语言模型在处理非英语和非汉语国家法律事务时基于知识回答并提供适当引用的能力。我们讨论了法律信息检索的历史，案例法和成文法之间的差异，及其对法律任务的影响，并分析了该领域的最新研究。基于这一背景，我们介绍了gAIus，一种基于认知大语言模型代理的架构，其回答基于从波兰民法等相关法律文件中检索的知识。我们提出了一种更具解释性、更友好的检索机制，其效果优于基于嵌入的方法。为了评估我们的方法，我们基于波兰法律学徒入学考试中的单选题创建了专门的数据集。所提出的架构充分利用了所使用的大语言模型的能力，将GPT-3.5-turbo-0125的性能提升419%，使其超越GPT-4o，并将GPT-4o-mini的得分从31%提升到86%。在论文的结尾，我们展示了研究的可能未来路径及其发现的应用前景。', 'title_zh': 'GAIus: 结合Genai与法律条款检索的知识型助手'}
{'arxiv_id': 'arXiv:2507.01241', 'title': 'Beyond First-Order: Training LLMs with Stochastic Conjugate Subgradients and AdamW', 'authors': 'Di Zhang, Yihang Zhang', 'link': 'https://arxiv.org/abs/2507.01241', 'abstract': 'Stochastic gradient-based descent (SGD), have long been central to training large language models (LLMs). However, their effectiveness is increasingly being questioned, particularly in large-scale applications where empirical evidence suggests potential performance limitations. In response, this paper proposes a stochastic conjugate subgradient method together with adaptive sampling tailored specifically for training LLMs. The method not only achieves faster convergence per iteration but also demonstrates improved scalability compared to traditional SGD techniques. It leverages sample complexity analysis to adaptively choose the sample size, employs a stochastic conjugate subgradient approach to determine search directions and utilizing an AdamW-like algorithm to adaptively adjust step sizes. This approach preserves the key advantages of first-order methods while effectively addressing the nonconvexity and non-smoothness inherent in LLMs training. Additionally, we provide a detailed analysis of the advantage of the algorithm. Experimental results show that the proposed method not only maintains, but in many cases surpasses, the scalability of traditional SGD techniques, significantly enhancing both the speed and accuracy of the optimization process.', 'abstract_zh': '基于随机梯度的下降（SGD）方法长期是训练大规模语言模型（LLMs）的核心。然而，在大规模应用中，它们的有效性正在受到质疑，特别是由于实证证据表明可能存在性能限制。为应对这一挑战，本文提出了一种特制的随机共轭次梯度方法，结合了适应性采样，专门用于训练LLMs。该方法不仅每次迭代都能更快地收敛，而且与传统的SGD技术相比，显示出更好的可扩展性。它利用样本复杂性分析自适应选择样本大小，采用随机共轭次梯度方法来确定搜索方向，并利用类似AdamW的算法自适应调整步长。该方法保留了一阶方法的关键优势，同时有效解决了LLMs训练中固有的非凸性和非光滑性。此外，我们还详细分析了该算法的优势。实验结果表明，所提出的方法不仅保持了，而且在许多情况下超越了传统SGD技术的可扩展性，显著提高了优化过程的速度和准确性。', 'title_zh': '超越一阶方法：使用随机共轭次梯度和AdamW训练大规模语言模型'}
{'arxiv_id': 'arXiv:2507.01061', 'title': 'Epitome: Pioneering an Experimental Platform for AI-Social Science Integration', 'authors': 'Jingjing Qu, Kejia Hu, Jun Zhu, Wenhao Li, Teng Wang, Zhiyun Chen, Yulei Ye, Chaochao Lu, Aimin Zhou, Xiangfeng Wang, James Evan', 'link': 'https://arxiv.org/abs/2507.01061', 'abstract': 'The integration of Large Language Models (LLMs) into social science experiments represents a transformative approach to understanding human-AI interactions and their societal impacts. We introduce Epitome, the world\'s first open experimental platform dedicated to the deep integration of artificial intelligence and social science. Rooted in theoretical foundations from management, communication studies, sociology, psychology, and ethics, Epitome focuses on the interactive impacts of AI on individuals, organizations, and society during its real-world deployment. It constructs a theoretical support system through cross-disciplinary experiments. The platform offers a one-stop comprehensive experimental solution spanning "foundation models-complex application development-user feedback" through seven core modules, while embedding the classical "control-comparison-comparative causal logic" of social science experiments into multilevel human-computer interaction environments, including dialogues, group chats, and multi-agent virtual scenarios. With its canvas-style, user-friendly interface, Epitome enables researchers to easily design and run complex experimental scenarios, facilitating systematic investigations into the social impacts of AI and exploration of integrated this http URL demonstrate its capabilities, we replicated three seminal social science experiments involving LLMs, showcasing Epitome\'s potential to streamline complex experimental designs and produce robust results, suitable for publishing in the top selective journals. Our findings highlight the platform\'s utility in enhancing the efficiency and quality of human-AI interactions, providing valuable insights into the societal implications of AI technologies. Epitome thus offers a powerful tool for advancing interdisciplinary research at the intersection of AI and social science, with potential applications in policy-making, ...', 'abstract_zh': '大型语言模型（LLMs）在社会科学实验中的整合代表了一种理解人机交互及其社会影响的变革性方法。我们介绍了Epitome，这是一个致力于人工智能与社会科学深度融合的世界首个开放实验平台。Epitome基于管理学、传播学、社会学、心理学和伦理学的理论基础，聚焦于AI在实际应用中对个体、组织和社会的互动影响，并通过跨学科实验构建理论支持系统。该平台提供从“基础模型-复杂应用开发-用户反馈”一站式全面实验解决方案，通过多层级的人机交互环境，包括对话、群聊和多智能体虚拟场景，嵌入社会科学实验的经典“控制-比较-因果逻辑”。Epitome以其画布式、用户友好的界面，使研究人员能够轻松设计和运行复杂的实验情景，促进对AI社会影响的系统性研究，并探索其与社会科学的整合应用。为了展示其能力，我们复制了三个涉及LLMs的关键社会科学实验，展现了Epitome简化复杂实验设计并产生稳健结果的潜力，适合发表在顶尖期刊上。我们的研究结果强调了该平台在提高人机交互效率和质量方面的 usefulness，提供了关于AI技术社会影响的重要见解。Epitome因此成为促进人工智能与社会科学交叉领域综合研究的强大工具，具有在政策制定等领域中的潜在应用。', 'title_zh': 'Epitome: 探索人工智能与社会科学集成的实验平台'}
{'arxiv_id': 'arXiv:2507.01059', 'title': 'Automated Vehicles Should be Connected with Natural Language', 'authors': 'Xiangbo Gao, Keshu Wu, Hao Zhang, Kexin Tian, Yang Zhou, Zhengzhong Tu', 'link': 'https://arxiv.org/abs/2507.01059', 'abstract': 'Multi-agent collaborative driving promises improvements in traffic safety and efficiency through collective perception and decision making. However, existing communication media -- including raw sensor data, neural network features, and perception results -- suffer limitations in bandwidth efficiency, information completeness, and agent interoperability. Moreover, traditional approaches have largely ignored decision-level fusion, neglecting critical dimensions of collaborative driving. In this paper we argue that addressing these challenges requires a transition from purely perception-oriented data exchanges to explicit intent and reasoning communication using natural language. Natural language balances semantic density and communication bandwidth, adapts flexibly to real-time conditions, and bridges heterogeneous agent platforms. By enabling the direct communication of intentions, rationales, and decisions, it transforms collaborative driving from reactive perception-data sharing into proactive coordination, advancing safety, efficiency, and transparency in intelligent transportation systems.', 'abstract_zh': '多智能体协同驾驶通过集体感知与决策承诺在交通安全性与效率方面带来提升。然而，现有的通信媒体——包括原始传感器数据、神经网络特征和感知结果——在带宽效率、信息完整性和智能体互操作性方面存在局限。此外，传统方法在很大程度上忽视了决策级融合，忽略了协同驾驶的关键维度。本文认为，解决这些挑战需要从纯感知导向的数据交换过渡到使用自然语言进行明确的意图与推理通信。自然语言平衡了语义密度和通信带宽，能够灵活适应实时条件，并连接异构智能体平台。通过直接通信意图、理由和决策，它将协同驾驶从被动的数据感知共享转变为积极的协调，从而推进智能交通系统的安全、效率和透明度。', 'title_zh': '自动车辆应当与自然语言连接。'}
{'arxiv_id': 'arXiv:2507.01058', 'title': 'A Data Science Approach to Calcutta High Court Judgments: An Efficient LLM and RAG-powered Framework for Summarization and Similar Cases Retrieval', 'authors': 'Puspendu Banerjee, Aritra Mazumdar, Wazib Ansar, Saptarsi Goswami, Amlan Chakrabarti', 'link': 'https://arxiv.org/abs/2507.01058', 'abstract': "The judiciary, as one of democracy's three pillars, is dealing with a rising amount of legal issues, needing careful use of judicial resources. This research presents a complex framework that leverages Data Science methodologies, notably Large Language Models (LLM) and Retrieval-Augmented Generation (RAG) techniques, to improve the efficiency of analyzing Calcutta High Court verdicts. Our framework focuses on two key aspects: first, the creation of a robust summarization mechanism that distills complex legal texts into concise and coherent summaries; and second, the development of an intelligent system for retrieving similar cases, which will assist legal professionals in research and decision making. By fine-tuning the Pegasus model using case head note summaries, we achieve significant improvements in the summarization of legal cases. Our two-step summarizing technique preserves crucial legal contexts, allowing for the production of a comprehensive vector database for RAG. The RAG-powered framework efficiently retrieves similar cases in response to user queries, offering thorough overviews and summaries. This technique not only improves legal research efficiency, but it also helps legal professionals and students easily acquire and grasp key legal information, benefiting the overall legal scenario.", 'abstract_zh': '司法机关作为民主的三大支柱之一，正面临着越来越多的法律问题，需要谨慎使用司法资源。本研究提出一种复杂框架，利用数据科学方法，特别是大型语言模型（LLM）和检索增强生成（RAG）技术，以提高分析加尔各答高等法院判决书的效率。该框架重点关注两个关键方面：首先，创建一个稳健的摘要机制，将复杂的法律文本提炼成简洁连贯的摘要；其次，开发一种智能的类似案例检索系统，该系统将帮助法律专业人员进行研究和决策。通过使用案件摘要头注对Pegasus模型进行微调，我们实现了对法律案件总结的显著改进。我们的两步汇总技术保留了关键的法律上下文，为RAG生成了一个完整的向量数据库。该RAG驱动的框架能够高效地根据用户查询检索类似案件，提供全面的概述和摘要。该技术不仅提高了法律研究的效率，还帮助法律专业人员和学生轻松获取和掌握关键法律信息，从而有利于整个法律环境。', 'title_zh': '基于数据科学方法的加尔各答高院判决分析：一种高效的LLM和RAG驱动的摘要与相似案例检索框架'}
{'arxiv_id': 'arXiv:2507.01053', 'title': 'Conversational LLMs Simplify Secure Clinical Data Access, Understanding, and Analysis', 'authors': 'Rafi Al Attrach, Pedro Moreira, Rajna Fani, Renato Umeton, Leo Anthony Celi', 'link': 'https://arxiv.org/abs/2507.01053', 'abstract': "As ever-larger clinical datasets become available, they have the potential to unlock unprecedented opportunities for medical research. Foremost among them is Medical Information Mart for Intensive Care (MIMIC-IV), the world's largest open-source EHR database. However, the inherent complexity of these datasets, particularly the need for sophisticated querying skills and the need to understand the underlying clinical settings, often presents a significant barrier to their effective use. M3 lowers the technical barrier to understanding and querying MIMIC-IV data. With a single command it retrieves MIMIC-IV from PhysioNet, launches a local SQLite instance (or hooks into the hosted BigQuery), and-via the Model Context Protocol (MCP)-lets researchers converse with the database in plain English. Ask a clinical question in natural language; M3 uses a language model to translate it into SQL, executes the query against the MIMIC-IV dataset, and returns structured results alongside the underlying query for verifiability and reproducibility. Demonstrations show that minutes of dialogue with M3 yield the kind of nuanced cohort analyses that once demanded hours of handcrafted SQL and relied on understanding the complexities of clinical workflows. By simplifying access, M3 invites the broader research community to mine clinical critical-care data and accelerates the translation of raw records into actionable insight.", 'abstract_zh': '随着越来越多的临床数据集变得可用，它们为医学研究开启了前所未有的机会。其中最为重要的是Medical Information Mart for Intensive Care (MIMIC-IV)，这是世界上最大的开源EHR数据库。然而，这些数据集固有的复杂性，特别是需要高级查询技能以及理解其背后的临床环境，往往会成为有效使用它们的障碍。M3降低了理解与查询MIMIC-IV数据的技术门槛。通过单个命令，它可以从PhysioNet获取MIMIC-IV数据，启动本地SQLite实例（或连接到托管的BigQuery），并通过模型上下文协议（MCP）让研究人员用普通英语与数据库进行对话。用自然语言提出临床问题；M3使用语言模型将其翻译成SQL，执行查询并对MIMIC-IV数据集进行查询，返回结构化结果以及底层查询以供验证和可重复性。演示表明，与M3进行几分钟的对话就能获得一度需要花费数小时手工编写SQL且依赖于理解临床工作流程复杂性的精细队列分析。通过简化访问，M3邀请更广泛的科研社区挖掘临床重症监护数据，并加速将原始记录转化为可操作的洞察力。', 'title_zh': '会话型大语言模型简化临床数据的安全访问、理解和分析'}
{'arxiv_id': 'arXiv:2507.01035', 'title': 'Research on Low-Latency Inference and Training Efficiency Optimization for Graph Neural Network and Large Language Model-Based Recommendation Systems', 'authors': 'Yushang Zhao, Haotian Lyu, Yike Peng, Aijia Sun, Feng Jiang, Xinyue Han', 'link': 'https://arxiv.org/abs/2507.01035', 'abstract': 'The incessant advent of online services demands high speed and efficient recommender systems (ReS) that can maintain real-time performance along with processing very complex user-item interactions. The present study, therefore, considers computational bottlenecks involved in hybrid Graph Neural Network (GNN) and Large Language Model (LLM)-based ReS with the aim optimizing their inference latency and training efficiency. An extensive methodology was used: hybrid GNN-LLM integrated architecture-optimization strategies(quantization, LoRA, distillation)-hardware acceleration (FPGA, DeepSpeed)-all under R 4.4.2. Experimental improvements were significant, with the optimal Hybrid + FPGA + DeepSpeed configuration reaching 13.6% more accuracy (NDCG@10: 0.75) at 40-60ms of latency, while LoRA brought down training time by 66% (3.8 hours) in comparison to the non-optimized baseline. Irrespective of domain, such as accuracy or efficiency, it can be established that hardware-software co-design and parameter-efficient tuning permit hybrid models to outperform GNN or LLM approaches implemented independently. It recommends the use of FPGA as well as LoRA for real-time deployment. Future work should involve federated learning along with advanced fusion architectures for better scalability and privacy preservation. Thus, this research marks the fundamental groundwork concerning next-generation ReS balancing low-latency response with cutting-edge personalization.', 'abstract_zh': '不间断涌现的在线服务要求具备高效率和快速响应的推荐系统（ReS），能够在保持实时性能的同时处理非常复杂的用户-项交互。本研究旨在优化基于混合图神经网络（GNN）和大型语言模型（LLM）的推荐系统中的计算瓶颈，以优化其推理延迟和训练效率。采用广泛的综合方法：混合GNN-LLM集成架构-优化策略（量化、LoRA、蒸馏）-硬件加速（FPGA、DeepSpeed），在R 4.4.2环境下进行。实验结果显著改进，优化后的混合+FPGA+DeepSpeed配置在40-60ms延迟下准确率达到13.6%的提升（NDCG@10: 0.75），而LoRA将训练时间降低了66%（3.8小时），相较非优化基线。无论在哪个领域，硬件-软件协同设计和参数高效调优都使得混合模型能够优于单独实现的GNN或LLM方法。研究推荐使用FPGA和LoRA进行实时部署。未来工作应包括联邦学习和更高级的融合架构，以实现更好的可扩展性和隐私保护。因此，这项研究奠定了下一代推荐系统平衡低延迟响应与先进个性化的基础。', 'title_zh': '低延迟推理与训练效率优化在图神经网络和基于大型语言模型的推荐系统中'}
